2020-01-20 22:18:12.690087: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-01-20 22:18:16.877829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:08:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2020-01-20 22:18:16.877898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-20 22:18:17.300573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-20 22:18:17.300643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-20 22:18:17.300656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-20 22:18:17.301131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=DeprecationWarning)
----------+++ 
CrossVal ['a']
TypeExperiment 10
CrossVal ['a']
Traceback (most recent call last):
  File "main.py", line 1902, in <module>
    Run_Csfn_with_Best_WMn_architecture(UserInfoB)
  File "main.py", line 1877, in Run_Csfn_with_Best_WMn_architecture
    applyPreprocess.main(paramFunc.Run(UserInfoB, terminal=True), 'experiment')
  File "/array/ssd/msmajdi/code/thalamus/keras/Parameters/paramFunc.py", line 178, in Run
    UserInfoB = temp_Experiments_preSet_V2(UserInfoB)
  File "/array/ssd/msmajdi/code/thalamus/keras/Parameters/paramFunc.py", line 159, in temp_Experiments_preSet_V2
    a,b,c,d,e = TypeExperimentFuncs().main(TypeExperiment=UserInfoB['TypeExperiment'], perm_Index=UserInfoB['permutation_Index'])
ValueError: too many values to unpack (expected 5)
2020-01-20 22:18:20.340218: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-01-20 22:18:23.240279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:08:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2020-01-20 22:18:23.240342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-20 22:18:23.671314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-20 22:18:23.671375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-20 22:18:23.671387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-20 22:18:23.671851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=DeprecationWarning)
----------+++ 
CrossVal ['b']
TypeExperiment 10
CrossVal ['b']
Traceback (most recent call last):
  File "main.py", line 1902, in <module>
    Run_Csfn_with_Best_WMn_architecture(UserInfoB)
  File "main.py", line 1877, in Run_Csfn_with_Best_WMn_architecture
    applyPreprocess.main(paramFunc.Run(UserInfoB, terminal=True), 'experiment')
  File "/array/ssd/msmajdi/code/thalamus/keras/Parameters/paramFunc.py", line 178, in Run
    UserInfoB = temp_Experiments_preSet_V2(UserInfoB)
  File "/array/ssd/msmajdi/code/thalamus/keras/Parameters/paramFunc.py", line 159, in temp_Experiments_preSet_V2
    a,b,c,d,e = TypeExperimentFuncs().main(TypeExperiment=UserInfoB['TypeExperiment'], perm_Index=UserInfoB['permutation_Index'])
ValueError: too many values to unpack (expected 5)
2020-01-20 22:18:26.743745: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-01-20 22:18:29.412382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:08:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2020-01-20 22:18:29.412427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-20 22:18:29.840631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-20 22:18:29.840672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-20 22:18:29.840685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-20 22:18:29.841138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=DeprecationWarning)
----------+++ 
CrossVal ['c']
TypeExperiment 10
CrossVal ['c']
Traceback (most recent call last):
  File "main.py", line 1902, in <module>
    Run_Csfn_with_Best_WMn_architecture(UserInfoB)
  File "main.py", line 1877, in Run_Csfn_with_Best_WMn_architecture
    applyPreprocess.main(paramFunc.Run(UserInfoB, terminal=True), 'experiment')
  File "/array/ssd/msmajdi/code/thalamus/keras/Parameters/paramFunc.py", line 178, in Run
    UserInfoB = temp_Experiments_preSet_V2(UserInfoB)
  File "/array/ssd/msmajdi/code/thalamus/keras/Parameters/paramFunc.py", line 159, in temp_Experiments_preSet_V2
    a,b,c,d,e = TypeExperimentFuncs().main(TypeExperiment=UserInfoB['TypeExperiment'], perm_Index=UserInfoB['permutation_Index'])
ValueError: too many values to unpack (expected 5)
2020-01-20 22:18:34.544912: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-01-20 22:18:39.103071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:08:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2020-01-20 22:18:39.103133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-20 22:18:39.517108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-20 22:18:39.517179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-20 22:18:39.517191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-20 22:18:39.517695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=DeprecationWarning)
----------+++ 
CrossVal ['d']
TypeExperiment 10
CrossVal ['d']
Traceback (most recent call last):
  File "main.py", line 1902, in <module>
    Run_Csfn_with_Best_WMn_architecture(UserInfoB)
  File "main.py", line 1877, in Run_Csfn_with_Best_WMn_architecture
    applyPreprocess.main(paramFunc.Run(UserInfoB, terminal=True), 'experiment')
  File "/array/ssd/msmajdi/code/thalamus/keras/Parameters/paramFunc.py", line 178, in Run
    UserInfoB = temp_Experiments_preSet_V2(UserInfoB)
  File "/array/ssd/msmajdi/code/thalamus/keras/Parameters/paramFunc.py", line 159, in temp_Experiments_preSet_V2
    a,b,c,d,e = TypeExperimentFuncs().main(TypeExperiment=UserInfoB['TypeExperiment'], perm_Index=UserInfoB['permutation_Index'])
ValueError: too many values to unpack (expected 5)
2020-01-20 22:21:52.505796: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-01-20 22:21:54.971090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:08:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2020-01-20 22:21:54.971157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-20 22:21:55.394348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-20 22:21:55.394416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-20 22:21:55.394430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-20 22:21:55.394916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=DeprecationWarning)
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<01:53,  2.33it/s]Loading train:   1%|          | 2/266 [00:00<01:40,  2.62it/s]Loading train:   1%|          | 3/266 [00:00<01:27,  3.01it/s]Loading train:   2%|▏         | 4/266 [00:01<01:18,  3.33it/s]Loading train:   2%|▏         | 5/266 [00:01<01:14,  3.49it/s]Loading train:   2%|▏         | 6/266 [00:01<01:12,  3.60it/s]Loading train:   3%|▎         | 7/266 [00:01<01:10,  3.69it/s]Loading train:   3%|▎         | 8/266 [00:02<01:08,  3.77it/s]Loading train:   3%|▎         | 9/266 [00:02<01:07,  3.82it/s]Loading train:   4%|▍         | 10/266 [00:02<01:06,  3.84it/s]Loading train:   4%|▍         | 11/266 [00:02<01:05,  3.88it/s]Loading train:   5%|▍         | 12/266 [00:03<01:05,  3.89it/s]Loading train:   5%|▍         | 13/266 [00:03<01:05,  3.88it/s]Loading train:   5%|▌         | 14/266 [00:03<01:04,  3.91it/s]Loading train:   6%|▌         | 15/266 [00:03<01:04,  3.88it/s]Loading train:   6%|▌         | 16/266 [00:04<01:03,  3.91it/s]Loading train:   6%|▋         | 17/266 [00:04<01:03,  3.92it/s]Loading train:   7%|▋         | 18/266 [00:04<01:03,  3.93it/s]Loading train:   7%|▋         | 19/266 [00:04<01:02,  3.92it/s]Loading train:   8%|▊         | 20/266 [00:05<01:02,  3.93it/s]Loading train:   8%|▊         | 21/266 [00:05<01:02,  3.94it/s]Loading train:   8%|▊         | 22/266 [00:05<01:01,  3.95it/s]Loading train:   9%|▊         | 23/266 [00:05<01:01,  3.95it/s]Loading train:   9%|▉         | 24/266 [00:06<01:00,  4.00it/s]Loading train:   9%|▉         | 25/266 [00:06<00:59,  4.02it/s]Loading train:  10%|▉         | 26/266 [00:06<00:59,  4.06it/s]Loading train:  10%|█         | 27/266 [00:06<00:59,  4.05it/s]Loading train:  11%|█         | 28/266 [00:07<00:58,  4.06it/s]Loading train:  11%|█         | 29/266 [00:07<00:58,  4.04it/s]Loading train:  11%|█▏        | 30/266 [00:07<00:57,  4.07it/s]Loading train:  12%|█▏        | 31/266 [00:07<00:57,  4.08it/s]Loading train:  12%|█▏        | 32/266 [00:08<00:57,  4.10it/s]Loading train:  12%|█▏        | 33/266 [00:08<00:56,  4.10it/s]Loading train:  13%|█▎        | 34/266 [00:08<00:57,  4.06it/s]Loading train:  13%|█▎        | 35/266 [00:08<00:56,  4.07it/s]Loading train:  14%|█▎        | 36/266 [00:09<00:56,  4.10it/s]Loading train:  14%|█▍        | 37/266 [00:09<00:55,  4.10it/s]Loading train:  14%|█▍        | 38/266 [00:09<00:55,  4.11it/s]Loading train:  15%|█▍        | 39/266 [00:09<00:55,  4.07it/s]Loading train:  15%|█▌        | 40/266 [00:10<00:55,  4.10it/s]Loading train:  15%|█▌        | 41/266 [00:10<00:54,  4.13it/s]Loading train:  16%|█▌        | 42/266 [00:10<00:51,  4.35it/s]Loading train:  16%|█▌        | 43/266 [00:10<00:49,  4.52it/s]Loading train:  17%|█▋        | 44/266 [00:10<00:47,  4.65it/s]Loading train:  17%|█▋        | 45/266 [00:11<00:46,  4.74it/s]Loading train:  17%|█▋        | 46/266 [00:11<00:45,  4.79it/s]Loading train:  18%|█▊        | 47/266 [00:11<00:45,  4.84it/s]Loading train:  18%|█▊        | 48/266 [00:11<00:44,  4.87it/s]Loading train:  18%|█▊        | 49/266 [00:11<00:44,  4.91it/s]Loading train:  19%|█▉        | 50/266 [00:12<00:44,  4.90it/s]Loading train:  19%|█▉        | 51/266 [00:12<00:43,  4.90it/s]Loading train:  20%|█▉        | 52/266 [00:12<00:43,  4.91it/s]Loading train:  20%|█▉        | 53/266 [00:12<00:43,  4.92it/s]Loading train:  20%|██        | 54/266 [00:12<00:43,  4.90it/s]Loading train:  21%|██        | 55/266 [00:13<00:43,  4.91it/s]Loading train:  21%|██        | 56/266 [00:13<00:42,  4.89it/s]Loading train:  21%|██▏       | 57/266 [00:13<00:42,  4.91it/s]Loading train:  22%|██▏       | 58/266 [00:13<00:42,  4.92it/s]Loading train:  22%|██▏       | 59/266 [00:14<00:42,  4.87it/s]Loading train:  23%|██▎       | 60/266 [00:14<00:42,  4.83it/s]Loading train:  23%|██▎       | 61/266 [00:14<00:42,  4.80it/s]Loading train:  23%|██▎       | 62/266 [00:14<00:42,  4.78it/s]Loading train:  24%|██▎       | 63/266 [00:14<00:42,  4.77it/s]Loading train:  24%|██▍       | 64/266 [00:15<00:42,  4.75it/s]Loading train:  24%|██▍       | 65/266 [00:15<00:42,  4.73it/s]Loading train:  25%|██▍       | 66/266 [00:15<00:42,  4.73it/s]Loading train:  25%|██▌       | 67/266 [00:15<00:42,  4.68it/s]Loading train:  26%|██▌       | 68/266 [00:15<00:42,  4.70it/s]Loading train:  26%|██▌       | 69/266 [00:16<00:41,  4.71it/s]Loading train:  26%|██▋       | 70/266 [00:16<00:41,  4.72it/s]Loading train:  27%|██▋       | 71/266 [00:16<00:41,  4.73it/s]Loading train:  27%|██▋       | 72/266 [00:16<00:41,  4.72it/s]Loading train:  27%|██▋       | 73/266 [00:16<00:41,  4.69it/s]Loading train:  28%|██▊       | 74/266 [00:17<00:40,  4.69it/s]Loading train:  28%|██▊       | 75/266 [00:17<00:40,  4.69it/s]Loading train:  29%|██▊       | 76/266 [00:17<00:40,  4.70it/s]Loading train:  29%|██▉       | 77/266 [00:17<00:40,  4.71it/s]Loading train:  29%|██▉       | 78/266 [00:18<00:41,  4.54it/s]Loading train:  30%|██▉       | 79/266 [00:18<00:42,  4.43it/s]Loading train:  30%|███       | 80/266 [00:18<00:42,  4.33it/s]Loading train:  30%|███       | 81/266 [00:18<00:43,  4.26it/s]Loading train:  31%|███       | 82/266 [00:19<00:57,  3.19it/s]Loading train:  31%|███       | 83/266 [00:19<01:05,  2.79it/s]Loading train:  32%|███▏      | 84/266 [00:20<01:19,  2.29it/s]Loading train:  32%|███▏      | 85/266 [00:20<01:27,  2.08it/s]Loading train:  32%|███▏      | 86/266 [00:21<01:32,  1.95it/s]Loading train:  33%|███▎      | 87/266 [00:22<01:31,  1.95it/s]Loading train:  33%|███▎      | 88/266 [00:22<01:33,  1.91it/s]Loading train:  33%|███▎      | 89/266 [00:23<01:42,  1.72it/s]Loading train:  34%|███▍      | 90/266 [00:23<01:45,  1.68it/s]Loading train:  34%|███▍      | 91/266 [00:24<01:38,  1.77it/s]Loading train:  35%|███▍      | 92/266 [00:25<01:37,  1.78it/s]Loading train:  35%|███▍      | 93/266 [00:25<01:31,  1.88it/s]Loading train:  35%|███▌      | 94/266 [00:25<01:28,  1.95it/s]Loading train:  36%|███▌      | 95/266 [00:26<01:26,  1.98it/s]Loading train:  36%|███▌      | 96/266 [00:26<01:22,  2.06it/s]Loading train:  36%|███▋      | 97/266 [00:27<01:23,  2.02it/s]Loading train:  37%|███▋      | 98/266 [00:27<01:21,  2.07it/s]Loading train:  37%|███▋      | 99/266 [00:28<01:14,  2.25it/s]Loading train:  38%|███▊      | 100/266 [00:28<01:11,  2.32it/s]Loading train:  38%|███▊      | 101/266 [00:29<01:16,  2.17it/s]Loading train:  38%|███▊      | 102/266 [00:29<01:18,  2.08it/s]Loading train:  39%|███▊      | 103/266 [00:30<01:15,  2.16it/s]Loading train:  39%|███▉      | 104/266 [00:30<01:12,  2.24it/s]Loading train:  39%|███▉      | 105/266 [00:30<01:09,  2.32it/s]Loading train:  40%|███▉      | 106/266 [00:31<01:04,  2.47it/s]Loading train:  40%|████      | 107/266 [00:31<01:04,  2.45it/s]Loading train:  41%|████      | 108/266 [00:32<01:04,  2.45it/s]Loading train:  41%|████      | 109/266 [00:32<01:05,  2.41it/s]Loading train:  41%|████▏     | 110/266 [00:33<01:12,  2.14it/s]Loading train:  42%|████▏     | 111/266 [00:33<01:13,  2.12it/s]Loading train:  42%|████▏     | 112/266 [00:34<01:18,  1.96it/s]Loading train:  42%|████▏     | 113/266 [00:34<01:18,  1.95it/s]Loading train:  43%|████▎     | 114/266 [00:35<01:24,  1.80it/s]Loading train:  43%|████▎     | 115/266 [00:36<01:30,  1.68it/s]Loading train:  44%|████▎     | 116/266 [00:36<01:30,  1.66it/s]Loading train:  44%|████▍     | 117/266 [00:37<01:31,  1.63it/s]Loading train:  44%|████▍     | 118/266 [00:37<01:31,  1.62it/s]Loading train:  45%|████▍     | 119/266 [00:38<01:42,  1.43it/s]Loading train:  45%|████▌     | 120/266 [00:39<01:43,  1.41it/s]Loading train:  45%|████▌     | 121/266 [00:40<01:48,  1.33it/s]Loading train:  46%|████▌     | 122/266 [00:41<01:47,  1.34it/s]Loading train:  46%|████▌     | 123/266 [00:41<01:47,  1.34it/s]Loading train:  47%|████▋     | 124/266 [00:42<01:46,  1.34it/s]Loading train:  47%|████▋     | 125/266 [00:43<01:43,  1.36it/s]Loading train:  47%|████▋     | 126/266 [00:44<01:42,  1.37it/s]Loading train:  48%|████▊     | 127/266 [00:44<01:40,  1.39it/s]Loading train:  48%|████▊     | 128/266 [00:45<01:38,  1.40it/s]Loading train:  48%|████▊     | 129/266 [00:46<01:36,  1.42it/s]Loading train:  49%|████▉     | 130/266 [00:46<01:35,  1.43it/s]Loading train:  49%|████▉     | 131/266 [00:47<01:37,  1.38it/s]Loading train:  50%|████▉     | 132/266 [00:48<01:35,  1.41it/s]Loading train:  50%|█████     | 133/266 [00:48<01:30,  1.47it/s]Loading train:  50%|█████     | 134/266 [00:49<01:29,  1.48it/s]Loading train:  51%|█████     | 135/266 [00:50<01:31,  1.42it/s]Loading train:  51%|█████     | 136/266 [00:51<01:32,  1.40it/s]Loading train:  52%|█████▏    | 137/266 [00:51<01:28,  1.46it/s]Loading train:  52%|█████▏    | 138/266 [00:52<01:26,  1.47it/s]Loading train:  52%|█████▏    | 139/266 [00:52<01:24,  1.51it/s]Loading train:  53%|█████▎    | 140/266 [00:53<01:22,  1.53it/s]Loading train:  53%|█████▎    | 141/266 [00:54<01:21,  1.53it/s]Loading train:  53%|█████▎    | 142/266 [00:54<01:23,  1.48it/s]Loading train:  54%|█████▍    | 143/266 [00:55<01:20,  1.52it/s]Loading train:  54%|█████▍    | 144/266 [00:56<01:19,  1.54it/s]Loading train:  55%|█████▍    | 145/266 [00:56<01:16,  1.58it/s]Loading train:  55%|█████▍    | 146/266 [00:57<01:16,  1.57it/s]Loading train:  55%|█████▌    | 147/266 [00:58<01:13,  1.61it/s]Loading train:  56%|█████▌    | 148/266 [00:58<01:16,  1.54it/s]Loading train:  56%|█████▌    | 149/266 [00:59<01:15,  1.54it/s]Loading train:  56%|█████▋    | 150/266 [00:59<01:14,  1.56it/s]Loading train:  57%|█████▋    | 151/266 [01:00<01:13,  1.58it/s]Loading train:  57%|█████▋    | 152/266 [01:01<01:11,  1.59it/s]Loading train:  58%|█████▊    | 153/266 [01:01<01:09,  1.62it/s]Loading train:  58%|█████▊    | 154/266 [01:02<01:07,  1.65it/s]Loading train:  58%|█████▊    | 155/266 [01:02<01:01,  1.82it/s]Loading train:  59%|█████▊    | 156/266 [01:03<01:00,  1.82it/s]Loading train:  59%|█████▉    | 157/266 [01:03<00:57,  1.89it/s]Loading train:  59%|█████▉    | 158/266 [01:04<00:56,  1.90it/s]Loading train:  60%|█████▉    | 159/266 [01:04<00:55,  1.94it/s]Loading train:  60%|██████    | 160/266 [01:05<00:55,  1.92it/s]Loading train:  61%|██████    | 161/266 [01:05<00:52,  1.99it/s]Loading train:  61%|██████    | 162/266 [01:06<00:52,  1.96it/s]Loading train:  61%|██████▏   | 163/266 [01:06<00:51,  2.00it/s]Loading train:  62%|██████▏   | 164/266 [01:07<00:49,  2.06it/s]Loading train:  62%|██████▏   | 165/266 [01:07<00:49,  2.06it/s]Loading train:  62%|██████▏   | 166/266 [01:08<00:50,  2.00it/s]Loading train:  63%|██████▎   | 167/266 [01:08<00:48,  2.05it/s]Loading train:  63%|██████▎   | 168/266 [01:09<00:48,  2.04it/s]Loading train:  64%|██████▎   | 169/266 [01:09<00:49,  1.96it/s]Loading train:  64%|██████▍   | 170/266 [01:10<00:49,  1.93it/s]Loading train:  64%|██████▍   | 171/266 [01:10<00:48,  1.97it/s]Loading train:  65%|██████▍   | 172/266 [01:11<00:49,  1.91it/s]Loading train:  65%|██████▌   | 173/266 [01:11<00:49,  1.89it/s]Loading train:  65%|██████▌   | 174/266 [01:12<00:48,  1.88it/s]Loading train:  66%|██████▌   | 175/266 [01:13<00:47,  1.90it/s]Loading train:  66%|██████▌   | 176/266 [01:13<00:51,  1.75it/s]Loading train:  67%|██████▋   | 177/266 [01:14<00:52,  1.70it/s]Loading train:  67%|██████▋   | 178/266 [01:14<00:52,  1.67it/s]Loading train:  67%|██████▋   | 179/266 [01:15<00:51,  1.69it/s]Loading train:  68%|██████▊   | 180/266 [01:16<00:52,  1.65it/s]Loading train:  68%|██████▊   | 181/266 [01:16<00:50,  1.68it/s]Loading train:  68%|██████▊   | 182/266 [01:17<00:50,  1.66it/s]Loading train:  69%|██████▉   | 183/266 [01:17<00:49,  1.66it/s]Loading train:  69%|██████▉   | 184/266 [01:18<00:50,  1.64it/s]Loading train:  70%|██████▉   | 185/266 [01:19<00:50,  1.60it/s]Loading train:  70%|██████▉   | 186/266 [01:19<00:50,  1.60it/s]Loading train:  70%|███████   | 187/266 [01:20<00:50,  1.57it/s]Loading train:  71%|███████   | 188/266 [01:21<00:50,  1.55it/s]Loading train:  71%|███████   | 189/266 [01:21<00:49,  1.55it/s]Loading train:  71%|███████▏  | 190/266 [01:22<00:48,  1.57it/s]Loading train:  72%|███████▏  | 191/266 [01:23<00:46,  1.60it/s]Loading train:  72%|███████▏  | 192/266 [01:23<00:45,  1.63it/s]Loading train:  73%|███████▎  | 193/266 [01:24<00:44,  1.63it/s]Loading train:  73%|███████▎  | 194/266 [01:24<00:46,  1.53it/s]Loading train:  73%|███████▎  | 195/266 [01:25<00:43,  1.62it/s]Loading train:  74%|███████▎  | 196/266 [01:26<00:43,  1.61it/s]Loading train:  74%|███████▍  | 197/266 [01:26<00:42,  1.64it/s]Loading train:  74%|███████▍  | 198/266 [01:27<00:41,  1.64it/s]Loading train:  75%|███████▍  | 199/266 [01:27<00:41,  1.60it/s]Loading train:  75%|███████▌  | 200/266 [01:28<00:41,  1.60it/s]Loading train:  76%|███████▌  | 201/266 [01:29<00:39,  1.64it/s]Loading train:  76%|███████▌  | 202/266 [01:29<00:38,  1.67it/s]Loading train:  76%|███████▋  | 203/266 [01:30<00:36,  1.74it/s]Loading train:  77%|███████▋  | 204/266 [01:30<00:36,  1.69it/s]Loading train:  77%|███████▋  | 205/266 [01:31<00:36,  1.68it/s]Loading train:  77%|███████▋  | 206/266 [01:31<00:32,  1.83it/s]Loading train:  78%|███████▊  | 207/266 [01:32<00:33,  1.79it/s]Loading train:  78%|███████▊  | 208/266 [01:33<00:34,  1.70it/s]Loading train:  79%|███████▊  | 209/266 [01:33<00:33,  1.70it/s]Loading train:  79%|███████▉  | 210/266 [01:34<00:33,  1.66it/s]Loading train:  79%|███████▉  | 211/266 [01:34<00:32,  1.70it/s]Loading train:  80%|███████▉  | 212/266 [01:35<00:34,  1.57it/s]Loading train:  80%|████████  | 213/266 [01:36<00:34,  1.52it/s]Loading train:  80%|████████  | 214/266 [01:36<00:32,  1.62it/s]Loading train:  81%|████████  | 215/266 [01:37<00:31,  1.63it/s]Loading train:  81%|████████  | 216/266 [01:38<00:29,  1.69it/s]Loading train:  82%|████████▏ | 217/266 [01:38<00:29,  1.68it/s]Loading train:  82%|████████▏ | 218/266 [01:39<00:28,  1.68it/s]Loading train:  82%|████████▏ | 219/266 [01:39<00:28,  1.65it/s]Loading train:  83%|████████▎ | 220/266 [01:40<00:26,  1.71it/s]Loading train:  83%|████████▎ | 221/266 [01:41<00:26,  1.72it/s]Loading train:  83%|████████▎ | 222/266 [01:41<00:24,  1.76it/s]Loading train:  84%|████████▍ | 223/266 [01:42<00:26,  1.65it/s]Loading train:  84%|████████▍ | 224/266 [01:42<00:24,  1.72it/s]Loading train:  85%|████████▍ | 225/266 [01:43<00:23,  1.76it/s]Loading train:  85%|████████▍ | 226/266 [01:43<00:22,  1.77it/s]Loading train:  85%|████████▌ | 227/266 [01:44<00:21,  1.79it/s]Loading train:  86%|████████▌ | 228/266 [01:45<00:21,  1.77it/s]Loading train:  86%|████████▌ | 229/266 [01:45<00:20,  1.79it/s]Loading train:  86%|████████▋ | 230/266 [01:46<00:20,  1.78it/s]Loading train:  87%|████████▋ | 231/266 [01:46<00:21,  1.66it/s]Loading train:  87%|████████▋ | 232/266 [01:47<00:20,  1.65it/s]Loading train:  88%|████████▊ | 233/266 [01:47<00:19,  1.73it/s]Loading train:  88%|████████▊ | 234/266 [01:48<00:18,  1.73it/s]Loading train:  88%|████████▊ | 235/266 [01:49<00:17,  1.75it/s]Loading train:  89%|████████▊ | 236/266 [01:49<00:17,  1.75it/s]Loading train:  89%|████████▉ | 237/266 [01:50<00:16,  1.77it/s]Loading train:  89%|████████▉ | 238/266 [01:50<00:15,  1.79it/s]Loading train:  90%|████████▉ | 239/266 [01:51<00:15,  1.72it/s]Loading train:  90%|█████████ | 240/266 [01:51<00:14,  1.79it/s]Loading train:  91%|█████████ | 241/266 [01:52<00:13,  1.81it/s]Loading train:  91%|█████████ | 242/266 [01:52<00:13,  1.83it/s]Loading train:  91%|█████████▏| 243/266 [01:53<00:12,  1.86it/s]Loading train:  92%|█████████▏| 244/266 [01:53<00:11,  1.89it/s]Loading train:  92%|█████████▏| 245/266 [01:54<00:11,  1.88it/s]Loading train:  92%|█████████▏| 246/266 [01:55<00:11,  1.76it/s]Loading train:  93%|█████████▎| 247/266 [01:55<00:10,  1.81it/s]Loading train:  93%|█████████▎| 248/266 [01:56<00:10,  1.80it/s]Loading train:  94%|█████████▎| 249/266 [01:56<00:09,  1.77it/s]Loading train:  94%|█████████▍| 250/266 [01:57<00:08,  1.82it/s]Loading train:  94%|█████████▍| 251/266 [01:57<00:08,  1.75it/s]Loading train:  95%|█████████▍| 252/266 [01:58<00:08,  1.69it/s]Loading train:  95%|█████████▌| 253/266 [01:59<00:07,  1.69it/s]Loading train:  95%|█████████▌| 254/266 [01:59<00:07,  1.67it/s]Loading train:  96%|█████████▌| 255/266 [02:00<00:06,  1.67it/s]Loading train:  96%|█████████▌| 256/266 [02:00<00:05,  1.71it/s]Loading train:  97%|█████████▋| 257/266 [02:01<00:05,  1.62it/s]Loading train:  97%|█████████▋| 258/266 [02:02<00:04,  1.62it/s]Loading train:  97%|█████████▋| 259/266 [02:02<00:04,  1.60it/s]Loading train:  98%|█████████▊| 260/266 [02:03<00:03,  1.62it/s]Loading train:  98%|█████████▊| 261/266 [02:04<00:02,  1.71it/s]Loading train:  98%|█████████▊| 262/266 [02:04<00:02,  1.78it/s]Loading train:  99%|█████████▉| 263/266 [02:05<00:01,  1.69it/s]Loading train:  99%|█████████▉| 264/266 [02:05<00:01,  1.68it/s]Loading train: 100%|█████████▉| 265/266 [02:06<00:00,  1.66it/s]Loading train: 100%|██████████| 266/266 [02:06<00:00,  1.72it/s]Loading train: 100%|██████████| 266/266 [02:06<00:00,  2.09it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/266 [00:00<00:05, 47.84it/s]concatenating: train:   4%|▍         | 11/266 [00:00<00:05, 49.12it/s]concatenating: train:   6%|▋         | 17/266 [00:00<00:04, 50.44it/s]concatenating: train:   9%|▊         | 23/266 [00:00<00:04, 51.71it/s]concatenating: train:  11%|█         | 29/266 [00:00<00:04, 52.99it/s]concatenating: train:  13%|█▎        | 35/266 [00:00<00:04, 53.86it/s]concatenating: train:  15%|█▌        | 41/266 [00:00<00:04, 54.65it/s]concatenating: train:  18%|█▊        | 48/266 [00:00<00:03, 57.61it/s]concatenating: train:  21%|██        | 55/266 [00:00<00:03, 59.92it/s]concatenating: train:  23%|██▎       | 62/266 [00:01<00:03, 60.80it/s]concatenating: train:  26%|██▌       | 69/266 [00:01<00:03, 60.72it/s]concatenating: train:  29%|██▊       | 76/266 [00:01<00:03, 59.18it/s]concatenating: train:  31%|███       | 82/266 [00:01<00:03, 58.31it/s]concatenating: train:  33%|███▎      | 88/266 [00:01<00:03, 53.51it/s]concatenating: train:  35%|███▌      | 94/266 [00:01<00:03, 50.13it/s]concatenating: train:  38%|███▊      | 100/266 [00:01<00:03, 49.89it/s]concatenating: train:  40%|███▉      | 106/266 [00:01<00:03, 50.46it/s]concatenating: train:  42%|████▏     | 112/266 [00:02<00:03, 51.24it/s]concatenating: train:  44%|████▍     | 118/266 [00:02<00:02, 50.74it/s]concatenating: train:  47%|████▋     | 124/266 [00:02<00:03, 46.55it/s]concatenating: train:  48%|████▊     | 129/266 [00:02<00:03, 43.95it/s]concatenating: train:  50%|█████     | 134/266 [00:02<00:03, 42.35it/s]concatenating: train:  52%|█████▏    | 139/266 [00:02<00:02, 43.11it/s]concatenating: train:  54%|█████▍    | 144/266 [00:02<00:02, 43.29it/s]concatenating: train:  56%|█████▌    | 149/266 [00:02<00:02, 43.58it/s]concatenating: train:  58%|█████▊    | 154/266 [00:03<00:02, 44.60it/s]concatenating: train:  60%|██████    | 160/266 [00:03<00:02, 47.44it/s]concatenating: train:  62%|██████▏   | 166/266 [00:03<00:02, 49.42it/s]concatenating: train:  65%|██████▍   | 172/266 [00:03<00:01, 50.90it/s]concatenating: train:  67%|██████▋   | 178/266 [00:03<00:01, 50.70it/s]concatenating: train:  69%|██████▉   | 184/266 [00:03<00:01, 50.63it/s]concatenating: train:  71%|███████▏  | 190/266 [00:03<00:01, 50.44it/s]concatenating: train:  74%|███████▎  | 196/266 [00:03<00:01, 50.24it/s]concatenating: train:  76%|███████▌  | 202/266 [00:03<00:01, 50.17it/s]concatenating: train:  78%|███████▊  | 208/266 [00:04<00:01, 49.17it/s]concatenating: train:  80%|████████  | 213/266 [00:04<00:01, 49.13it/s]concatenating: train:  82%|████████▏ | 219/266 [00:04<00:00, 49.62it/s]concatenating: train:  84%|████████▍ | 224/266 [00:04<00:00, 49.73it/s]concatenating: train:  86%|████████▋ | 230/266 [00:04<00:00, 49.90it/s]concatenating: train:  88%|████████▊ | 235/266 [00:04<00:00, 49.59it/s]concatenating: train:  90%|█████████ | 240/266 [00:04<00:00, 49.54it/s]concatenating: train:  92%|█████████▏| 245/266 [00:04<00:00, 48.97it/s]concatenating: train:  94%|█████████▍| 250/266 [00:04<00:00, 48.58it/s]concatenating: train:  96%|█████████▌| 255/266 [00:05<00:00, 47.46it/s]concatenating: train:  98%|█████████▊| 260/266 [00:05<00:00, 46.66it/s]concatenating: train: 100%|█████████▉| 265/266 [00:05<00:00, 45.35it/s]concatenating: train: 100%|██████████| 266/266 [00:05<00:00, 50.23it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:00<00:01,  1.67it/s]Loading test:  50%|█████     | 2/4 [00:01<00:01,  1.71it/s]Loading test:  75%|███████▌  | 3/4 [00:01<00:00,  1.69it/s]Loading test: 100%|██████████| 4/4 [00:02<00:00,  1.62it/s]Loading test: 100%|██████████| 4/4 [00:02<00:00,  1.64it/s]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 58.29it/s]
Loading trainS:   0%|          | 0/266 [00:00<?, ?it/s]Loading trainS:   0%|          | 1/266 [00:00<03:14,  1.36it/s]Loading trainS:   1%|          | 2/266 [00:01<03:03,  1.44it/s]Loading trainS:   1%|          | 3/266 [00:01<02:48,  1.56it/s]Loading trainS:   2%|▏         | 4/266 [00:02<02:35,  1.69it/s]Loading trainS:   2%|▏         | 5/266 [00:02<02:35,  1.68it/s]Loading trainS:   2%|▏         | 6/266 [00:03<02:37,  1.65it/s]Loading trainS:   3%|▎         | 7/266 [00:04<02:33,  1.68it/s]Loading trainS:   3%|▎         | 8/266 [00:04<02:31,  1.70it/s]Loading trainS:   3%|▎         | 9/266 [00:05<02:40,  1.60it/s]Loading trainS:   4%|▍         | 10/266 [00:06<02:43,  1.56it/s]Loading trainS:   4%|▍         | 11/266 [00:06<02:43,  1.56it/s]Loading trainS:   5%|▍         | 12/266 [00:07<02:45,  1.54it/s]Loading trainS:   5%|▍         | 13/266 [00:08<02:44,  1.54it/s]Loading trainS:   5%|▌         | 14/266 [00:08<02:44,  1.54it/s]Loading trainS:   6%|▌         | 15/266 [00:09<02:45,  1.51it/s]Loading trainS:   6%|▌         | 16/266 [00:09<02:40,  1.56it/s]Loading trainS:   6%|▋         | 17/266 [00:10<02:37,  1.59it/s]Loading trainS:   7%|▋         | 18/266 [00:11<02:34,  1.61it/s]Loading trainS:   7%|▋         | 19/266 [00:11<02:30,  1.64it/s]Loading trainS:   8%|▊         | 20/266 [00:12<02:35,  1.58it/s]Loading trainS:   8%|▊         | 21/266 [00:13<02:32,  1.60it/s]Loading trainS:   8%|▊         | 22/266 [00:13<02:35,  1.57it/s]Loading trainS:   9%|▊         | 23/266 [00:14<02:30,  1.61it/s]Loading trainS:   9%|▉         | 24/266 [00:14<02:28,  1.63it/s]Loading trainS:   9%|▉         | 25/266 [00:15<02:34,  1.56it/s]Loading trainS:  10%|▉         | 26/266 [00:16<02:37,  1.52it/s]Loading trainS:  10%|█         | 27/266 [00:16<02:34,  1.55it/s]Loading trainS:  11%|█         | 28/266 [00:17<02:26,  1.63it/s]Loading trainS:  11%|█         | 29/266 [00:18<02:24,  1.64it/s]Loading trainS:  11%|█▏        | 30/266 [00:18<02:21,  1.67it/s]Loading trainS:  12%|█▏        | 31/266 [00:19<02:15,  1.73it/s]Loading trainS:  12%|█▏        | 32/266 [00:19<02:16,  1.72it/s]Loading trainS:  12%|█▏        | 33/266 [00:20<02:18,  1.68it/s]Loading trainS:  13%|█▎        | 34/266 [00:20<02:11,  1.76it/s]Loading trainS:  13%|█▎        | 35/266 [00:21<02:12,  1.74it/s]Loading trainS:  14%|█▎        | 36/266 [00:22<02:16,  1.68it/s]Loading trainS:  14%|█▍        | 37/266 [00:22<02:16,  1.67it/s]Loading trainS:  14%|█▍        | 38/266 [00:23<02:14,  1.69it/s]Loading trainS:  15%|█▍        | 39/266 [00:23<02:19,  1.63it/s]Loading trainS:  15%|█▌        | 40/266 [00:24<02:16,  1.66it/s]Loading trainS:  15%|█▌        | 41/266 [00:25<02:20,  1.60it/s]Loading trainS:  16%|█▌        | 42/266 [00:25<02:15,  1.65it/s]Loading trainS:  16%|█▌        | 43/266 [00:26<02:07,  1.75it/s]Loading trainS:  17%|█▋        | 44/266 [00:26<02:03,  1.79it/s]Loading trainS:  17%|█▋        | 45/266 [00:27<02:01,  1.82it/s]Loading trainS:  17%|█▋        | 46/266 [00:27<01:56,  1.89it/s]Loading trainS:  18%|█▊        | 47/266 [00:28<01:55,  1.90it/s]Loading trainS:  18%|█▊        | 48/266 [00:28<01:50,  1.97it/s]Loading trainS:  18%|█▊        | 49/266 [00:29<01:46,  2.05it/s]Loading trainS:  19%|█▉        | 50/266 [00:29<01:50,  1.96it/s]Loading trainS:  19%|█▉        | 51/266 [00:30<01:48,  1.98it/s]Loading trainS:  20%|█▉        | 52/266 [00:30<01:49,  1.96it/s]Loading trainS:  20%|█▉        | 53/266 [00:31<01:49,  1.94it/s]Loading trainS:  20%|██        | 54/266 [00:31<01:52,  1.89it/s]Loading trainS:  21%|██        | 55/266 [00:32<01:47,  1.96it/s]Loading trainS:  21%|██        | 56/266 [00:32<01:46,  1.97it/s]Loading trainS:  21%|██▏       | 57/266 [00:33<01:42,  2.03it/s]Loading trainS:  22%|██▏       | 58/266 [00:33<01:46,  1.95it/s]Loading trainS:  22%|██▏       | 59/266 [00:34<01:45,  1.96it/s]Loading trainS:  23%|██▎       | 60/266 [00:34<01:43,  1.98it/s]Loading trainS:  23%|██▎       | 61/266 [00:35<01:40,  2.03it/s]Loading trainS:  23%|██▎       | 62/266 [00:35<01:42,  1.99it/s]Loading trainS:  24%|██▎       | 63/266 [00:36<01:42,  1.98it/s]Loading trainS:  24%|██▍       | 64/266 [00:36<01:46,  1.89it/s]Loading trainS:  24%|██▍       | 65/266 [00:37<01:50,  1.82it/s]Loading trainS:  25%|██▍       | 66/266 [00:38<01:46,  1.87it/s]Loading trainS:  25%|██▌       | 67/266 [00:38<01:46,  1.87it/s]Loading trainS:  26%|██▌       | 68/266 [00:39<01:45,  1.87it/s]Loading trainS:  26%|██▌       | 69/266 [00:39<01:41,  1.93it/s]Loading trainS:  26%|██▋       | 70/266 [00:40<01:42,  1.92it/s]Loading trainS:  27%|██▋       | 71/266 [00:40<01:44,  1.87it/s]Loading trainS:  27%|██▋       | 72/266 [00:41<01:44,  1.86it/s]Loading trainS:  27%|██▋       | 73/266 [00:41<01:42,  1.88it/s]Loading trainS:  28%|██▊       | 74/266 [00:42<01:42,  1.88it/s]Loading trainS:  28%|██▊       | 75/266 [00:42<01:40,  1.90it/s]Loading trainS:  29%|██▊       | 76/266 [00:43<01:36,  1.96it/s]Loading trainS:  29%|██▉       | 77/266 [00:43<01:40,  1.88it/s]Loading trainS:  29%|██▉       | 78/266 [00:44<01:40,  1.86it/s]Loading trainS:  30%|██▉       | 79/266 [00:45<01:44,  1.79it/s]Loading trainS:  30%|███       | 80/266 [00:45<01:47,  1.73it/s]Loading trainS:  30%|███       | 81/266 [00:46<01:48,  1.70it/s]Loading trainS:  31%|███       | 82/266 [00:46<01:49,  1.67it/s]Loading trainS:  31%|███       | 83/266 [00:47<01:50,  1.65it/s]Loading trainS:  32%|███▏      | 84/266 [00:48<01:46,  1.70it/s]Loading trainS:  32%|███▏      | 85/266 [00:48<01:49,  1.65it/s]Loading trainS:  32%|███▏      | 86/266 [00:49<01:47,  1.67it/s]Loading trainS:  33%|███▎      | 87/266 [00:49<01:49,  1.63it/s]Loading trainS:  33%|███▎      | 88/266 [00:50<01:49,  1.63it/s]Loading trainS:  33%|███▎      | 89/266 [00:51<01:47,  1.64it/s]Loading trainS:  34%|███▍      | 90/266 [00:51<01:47,  1.64it/s]Loading trainS:  34%|███▍      | 91/266 [00:52<01:46,  1.65it/s]Loading trainS:  35%|███▍      | 92/266 [00:52<01:46,  1.64it/s]Loading trainS:  35%|███▍      | 93/266 [00:53<01:47,  1.60it/s]Loading trainS:  35%|███▌      | 94/266 [00:54<01:46,  1.61it/s]Loading trainS:  36%|███▌      | 95/266 [00:54<01:41,  1.68it/s]Loading trainS:  36%|███▌      | 96/266 [00:55<01:38,  1.72it/s]Loading trainS:  36%|███▋      | 97/266 [00:56<01:44,  1.62it/s]Loading trainS:  37%|███▋      | 98/266 [00:56<01:39,  1.69it/s]Loading trainS:  37%|███▋      | 99/266 [00:56<01:27,  1.91it/s]Loading trainS:  38%|███▊      | 100/266 [00:57<01:27,  1.89it/s]Loading trainS:  38%|███▊      | 101/266 [00:57<01:24,  1.95it/s]Loading trainS:  38%|███▊      | 102/266 [00:58<01:25,  1.92it/s]Loading trainS:  39%|███▊      | 103/266 [00:59<01:25,  1.91it/s]Loading trainS:  39%|███▉      | 104/266 [00:59<01:22,  1.95it/s]Loading trainS:  39%|███▉      | 105/266 [01:00<01:24,  1.91it/s]Loading trainS:  40%|███▉      | 106/266 [01:00<01:21,  1.97it/s]Loading trainS:  40%|████      | 107/266 [01:01<01:20,  1.97it/s]Loading trainS:  41%|████      | 108/266 [01:01<01:20,  1.95it/s]Loading trainS:  41%|████      | 109/266 [01:02<01:24,  1.85it/s]Loading trainS:  41%|████▏     | 110/266 [01:02<01:24,  1.85it/s]Loading trainS:  42%|████▏     | 111/266 [01:03<01:23,  1.87it/s]Loading trainS:  42%|████▏     | 112/266 [01:03<01:21,  1.89it/s]Loading trainS:  42%|████▏     | 113/266 [01:04<01:19,  1.92it/s]Loading trainS:  43%|████▎     | 114/266 [01:04<01:22,  1.85it/s]Loading trainS:  43%|████▎     | 115/266 [01:05<01:18,  1.94it/s]Loading trainS:  44%|████▎     | 116/266 [01:05<01:18,  1.91it/s]Loading trainS:  44%|████▍     | 117/266 [01:06<01:18,  1.89it/s]Loading trainS:  44%|████▍     | 118/266 [01:06<01:16,  1.94it/s]Loading trainS:  45%|████▍     | 119/266 [01:07<01:23,  1.76it/s]Loading trainS:  45%|████▌     | 120/266 [01:08<01:28,  1.65it/s]Loading trainS:  45%|████▌     | 121/266 [01:08<01:33,  1.55it/s]Loading trainS:  46%|████▌     | 122/266 [01:09<01:34,  1.52it/s]Loading trainS:  46%|████▌     | 123/266 [01:10<01:35,  1.50it/s]Loading trainS:  47%|████▋     | 124/266 [01:11<01:36,  1.47it/s]Loading trainS:  47%|████▋     | 125/266 [01:11<01:37,  1.45it/s]Loading trainS:  47%|████▋     | 126/266 [01:12<01:40,  1.39it/s]Loading trainS:  48%|████▊     | 127/266 [01:13<01:33,  1.49it/s]Loading trainS:  48%|████▊     | 128/266 [01:13<01:22,  1.67it/s]Loading trainS:  48%|████▊     | 129/266 [01:13<01:14,  1.84it/s]Loading trainS:  49%|████▉     | 130/266 [01:14<01:03,  2.14it/s]Loading trainS:  49%|████▉     | 131/266 [01:14<01:01,  2.21it/s]Loading trainS:  50%|████▉     | 132/266 [01:15<01:00,  2.21it/s]Loading trainS:  50%|█████     | 133/266 [01:15<01:04,  2.07it/s]Loading trainS:  50%|█████     | 134/266 [01:16<01:02,  2.10it/s]Loading trainS:  51%|█████     | 135/266 [01:16<01:03,  2.05it/s]Loading trainS:  51%|█████     | 136/266 [01:17<01:04,  2.02it/s]Loading trainS:  52%|█████▏    | 137/266 [01:17<01:01,  2.09it/s]Loading trainS:  52%|█████▏    | 138/266 [01:18<01:03,  2.02it/s]Loading trainS:  52%|█████▏    | 139/266 [01:18<01:02,  2.05it/s]Loading trainS:  53%|█████▎    | 140/266 [01:19<01:01,  2.06it/s]Loading trainS:  53%|█████▎    | 141/266 [01:19<01:01,  2.02it/s]Loading trainS:  53%|█████▎    | 142/266 [01:20<01:01,  2.02it/s]Loading trainS:  54%|█████▍    | 143/266 [01:20<00:58,  2.11it/s]Loading trainS:  54%|█████▍    | 144/266 [01:20<00:49,  2.47it/s]Loading trainS:  55%|█████▍    | 145/266 [01:21<00:46,  2.62it/s]Loading trainS:  55%|█████▍    | 146/266 [01:21<00:43,  2.74it/s]Loading trainS:  55%|█████▌    | 147/266 [01:21<00:47,  2.52it/s]Loading trainS:  56%|█████▌    | 148/266 [01:22<00:49,  2.38it/s]Loading trainS:  56%|█████▌    | 149/266 [01:22<00:50,  2.34it/s]Loading trainS:  56%|█████▋    | 150/266 [01:23<00:50,  2.28it/s]Loading trainS:  57%|█████▋    | 151/266 [01:23<00:52,  2.20it/s]Loading trainS:  57%|█████▋    | 152/266 [01:24<00:52,  2.19it/s]Loading trainS:  58%|█████▊    | 153/266 [01:24<00:52,  2.14it/s]Loading trainS:  58%|█████▊    | 154/266 [01:25<00:58,  1.93it/s]Loading trainS:  58%|█████▊    | 155/266 [01:25<00:53,  2.07it/s]Loading trainS:  59%|█████▊    | 156/266 [01:26<00:53,  2.06it/s]Loading trainS:  59%|█████▉    | 157/266 [01:26<00:48,  2.24it/s]Loading trainS:  59%|█████▉    | 158/266 [01:26<00:43,  2.48it/s]Loading trainS:  60%|█████▉    | 159/266 [01:27<00:45,  2.33it/s]Loading trainS:  60%|██████    | 160/266 [01:27<00:45,  2.32it/s]Loading trainS:  61%|██████    | 161/266 [01:28<00:43,  2.42it/s]Loading trainS:  61%|██████    | 162/266 [01:28<00:44,  2.34it/s]Loading trainS:  61%|██████▏   | 163/266 [01:29<00:41,  2.47it/s]Loading trainS:  62%|██████▏   | 164/266 [01:29<00:40,  2.54it/s]Loading trainS:  62%|██████▏   | 165/266 [01:29<00:38,  2.64it/s]Loading trainS:  62%|██████▏   | 166/266 [01:30<00:37,  2.66it/s]Loading trainS:  63%|██████▎   | 167/266 [01:30<00:38,  2.59it/s]Loading trainS:  63%|██████▎   | 168/266 [01:30<00:38,  2.52it/s]Loading trainS:  64%|██████▎   | 169/266 [01:31<00:39,  2.44it/s]Loading trainS:  64%|██████▍   | 170/266 [01:31<00:39,  2.44it/s]Loading trainS:  64%|██████▍   | 171/266 [01:32<00:38,  2.48it/s]Loading trainS:  65%|██████▍   | 172/266 [01:32<00:36,  2.57it/s]Loading trainS:  65%|██████▌   | 173/266 [01:33<00:41,  2.22it/s]Loading trainS:  65%|██████▌   | 174/266 [01:33<00:43,  2.09it/s]Loading trainS:  66%|██████▌   | 175/266 [01:34<00:43,  2.07it/s]Loading trainS:  66%|██████▌   | 176/266 [01:34<00:43,  2.07it/s]Loading trainS:  67%|██████▋   | 177/266 [01:35<00:42,  2.11it/s]Loading trainS:  67%|██████▋   | 178/266 [01:35<00:42,  2.09it/s]Loading trainS:  67%|██████▋   | 179/266 [01:36<00:40,  2.15it/s]Loading trainS:  68%|██████▊   | 180/266 [01:36<00:39,  2.20it/s]Loading trainS:  68%|██████▊   | 181/266 [01:36<00:38,  2.21it/s]Loading trainS:  68%|██████▊   | 182/266 [01:37<00:41,  2.04it/s]Loading trainS:  69%|██████▉   | 183/266 [01:37<00:37,  2.19it/s]Loading trainS:  69%|██████▉   | 184/266 [01:38<00:36,  2.24it/s]Loading trainS:  70%|██████▉   | 185/266 [01:38<00:34,  2.33it/s]Loading trainS:  70%|██████▉   | 186/266 [01:39<00:35,  2.23it/s]Loading trainS:  70%|███████   | 187/266 [01:39<00:36,  2.16it/s]Loading trainS:  71%|███████   | 188/266 [01:40<00:35,  2.19it/s]Loading trainS:  71%|███████   | 189/266 [01:40<00:33,  2.27it/s]Loading trainS:  71%|███████▏  | 190/266 [01:40<00:33,  2.29it/s]Loading trainS:  72%|███████▏  | 191/266 [01:41<00:32,  2.28it/s]Loading trainS:  72%|███████▏  | 192/266 [01:41<00:33,  2.23it/s]Loading trainS:  73%|███████▎  | 193/266 [01:42<00:32,  2.25it/s]Loading trainS:  73%|███████▎  | 194/266 [01:42<00:33,  2.13it/s]Loading trainS:  73%|███████▎  | 195/266 [01:43<00:35,  1.99it/s]Loading trainS:  74%|███████▎  | 196/266 [01:43<00:36,  1.94it/s]Loading trainS:  74%|███████▍  | 197/266 [01:44<00:35,  1.96it/s]Loading trainS:  74%|███████▍  | 198/266 [01:44<00:34,  1.99it/s]Loading trainS:  75%|███████▍  | 199/266 [01:45<00:29,  2.29it/s]Loading trainS:  75%|███████▌  | 200/266 [01:45<00:25,  2.57it/s]Loading trainS:  76%|███████▌  | 201/266 [01:45<00:23,  2.74it/s]Loading trainS:  76%|███████▌  | 202/266 [01:46<00:21,  2.97it/s]Loading trainS:  76%|███████▋  | 203/266 [01:46<00:23,  2.69it/s]Loading trainS:  77%|███████▋  | 204/266 [01:46<00:25,  2.45it/s]Loading trainS:  77%|███████▋  | 205/266 [01:47<00:24,  2.46it/s]Loading trainS:  77%|███████▋  | 206/266 [01:47<00:24,  2.43it/s]Loading trainS:  78%|███████▊  | 207/266 [01:48<00:23,  2.49it/s]Loading trainS:  78%|███████▊  | 208/266 [01:48<00:24,  2.38it/s]Loading trainS:  79%|███████▊  | 209/266 [01:49<00:25,  2.24it/s]Loading trainS:  79%|███████▉  | 210/266 [01:49<00:29,  1.93it/s]Loading trainS:  79%|███████▉  | 211/266 [01:50<00:29,  1.87it/s]Loading trainS:  80%|███████▉  | 212/266 [01:51<00:30,  1.75it/s]Loading trainS:  80%|████████  | 213/266 [01:51<00:30,  1.74it/s]Loading trainS:  80%|████████  | 214/266 [01:52<00:28,  1.81it/s]Loading trainS:  81%|████████  | 215/266 [01:52<00:29,  1.74it/s]Loading trainS:  81%|████████  | 216/266 [01:53<00:27,  1.80it/s]Loading trainS:  82%|████████▏ | 217/266 [01:53<00:27,  1.78it/s]Loading trainS:  82%|████████▏ | 218/266 [01:54<00:28,  1.71it/s]Loading trainS:  82%|████████▏ | 219/266 [01:55<00:28,  1.68it/s]Loading trainS:  83%|████████▎ | 220/266 [01:55<00:26,  1.73it/s]Loading trainS:  83%|████████▎ | 221/266 [01:56<00:25,  1.77it/s]Loading trainS:  83%|████████▎ | 222/266 [01:56<00:23,  1.85it/s]Loading trainS:  84%|████████▍ | 223/266 [01:57<00:22,  1.92it/s]Loading trainS:  84%|████████▍ | 224/266 [01:57<00:22,  1.90it/s]Loading trainS:  85%|████████▍ | 225/266 [01:58<00:21,  1.87it/s]Loading trainS:  85%|████████▍ | 226/266 [01:58<00:22,  1.79it/s]Loading trainS:  85%|████████▌ | 227/266 [01:59<00:21,  1.84it/s]Loading trainS:  86%|████████▌ | 228/266 [01:59<00:20,  1.88it/s]Loading trainS:  86%|████████▌ | 229/266 [02:00<00:19,  1.91it/s]Loading trainS:  86%|████████▋ | 230/266 [02:01<00:20,  1.79it/s]Loading trainS:  87%|████████▋ | 231/266 [02:01<00:20,  1.75it/s]Loading trainS:  87%|████████▋ | 232/266 [02:02<00:20,  1.68it/s]Loading trainS:  88%|████████▊ | 233/266 [02:02<00:20,  1.62it/s]Loading trainS:  88%|████████▊ | 234/266 [02:03<00:18,  1.74it/s]Loading trainS:  88%|████████▊ | 235/266 [02:03<00:17,  1.77it/s]Loading trainS:  89%|████████▊ | 236/266 [02:04<00:16,  1.80it/s]Loading trainS:  89%|████████▉ | 237/266 [02:05<00:17,  1.68it/s]Loading trainS:  89%|████████▉ | 238/266 [02:05<00:16,  1.72it/s]Loading trainS:  90%|████████▉ | 239/266 [02:06<00:16,  1.60it/s]Loading trainS:  90%|█████████ | 240/266 [02:07<00:16,  1.56it/s]Loading trainS:  91%|█████████ | 241/266 [02:07<00:15,  1.58it/s]Loading trainS:  91%|█████████ | 242/266 [02:08<00:14,  1.68it/s]Loading trainS:  91%|█████████▏| 243/266 [02:08<00:14,  1.62it/s]Loading trainS:  92%|█████████▏| 244/266 [02:09<00:12,  1.69it/s]Loading trainS:  92%|█████████▏| 245/266 [02:10<00:12,  1.74it/s]Loading trainS:  92%|█████████▏| 246/266 [02:10<00:11,  1.68it/s]Loading trainS:  93%|█████████▎| 247/266 [02:11<00:11,  1.66it/s]Loading trainS:  93%|█████████▎| 248/266 [02:11<00:10,  1.66it/s]Loading trainS:  94%|█████████▎| 249/266 [02:12<00:10,  1.64it/s]Loading trainS:  94%|█████████▍| 250/266 [02:13<00:09,  1.72it/s]Loading trainS:  94%|█████████▍| 251/266 [02:13<00:08,  1.70it/s]Loading trainS:  95%|█████████▍| 252/266 [02:14<00:08,  1.66it/s]Loading trainS:  95%|█████████▌| 253/266 [02:14<00:08,  1.58it/s]Loading trainS:  95%|█████████▌| 254/266 [02:15<00:07,  1.56it/s]Loading trainS:  96%|█████████▌| 255/266 [02:16<00:07,  1.54it/s]Loading trainS:  96%|█████████▌| 256/266 [02:16<00:06,  1.51it/s]Loading trainS:  97%|█████████▋| 257/266 [02:17<00:05,  1.51it/s]Loading trainS:  97%|█████████▋| 258/266 [02:18<00:05,  1.55it/s]Loading trainS:  97%|█████████▋| 259/266 [02:18<00:04,  1.59it/s]Loading trainS:  98%|█████████▊| 260/266 [02:19<00:03,  1.61it/s]Loading trainS:  98%|█████████▊| 261/266 [02:20<00:03,  1.61it/s]Loading trainS:  98%|█████████▊| 262/266 [02:20<00:02,  1.60it/s]Loading trainS:  99%|█████████▉| 263/266 [02:21<00:01,  1.59it/s]Loading trainS:  99%|█████████▉| 264/266 [02:21<00:01,  1.57it/s]Loading trainS: 100%|█████████▉| 265/266 [02:22<00:00,  1.58it/s]Loading trainS: 100%|██████████| 266/266 [02:23<00:00,  1.58it/s]Loading trainS: 100%|██████████| 266/266 [02:23<00:00,  1.86it/s]
Loading testS:   0%|          | 0/4 [00:00<?, ?it/s]Loading testS:  25%|██▌       | 1/4 [00:00<00:01,  1.65it/s]Loading testS:  50%|█████     | 2/4 [00:01<00:01,  1.55it/s]Loading testS:  75%|███████▌  | 3/4 [00:01<00:00,  1.88it/s]Loading testS: 100%|██████████| 4/4 [00:02<00:00,  1.99it/s]Loading testS: 100%|██████████| 4/4 [00:02<00:00,  1.96it/s]----------+++ 
CrossVal ['a']
TypeExperiment 10
CrossVal ['a']
(0/4) test vimp2_A_CSFn2
(1/4) test vimp2_ANON967_CSFn2
(2/4) test vimp2_B_CSFn2
(3/4) test vimp2_E_CSFn2
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_NoInit_wBiasCorrection_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
Error in label values min 0.0 max 2.0      1-THALAMUS
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 108, 116, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 108, 116, 40) 400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 108, 116, 40) 160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 108, 116, 40) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 108, 116, 40) 14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 108, 116, 40) 160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 108, 116, 40) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 54, 58, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 54, 58, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 54, 58, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 54, 58, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 54, 58, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 54, 58, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 54, 58, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 54, 58, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 54, 58, 120)  0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 27, 29, 120)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 27, 29, 120)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 27, 29, 160)  172960      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 27, 29, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 27, 29, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 27, 29, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 27, 29, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 27, 29, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 27, 29, 280)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 27, 29, 280)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 54, 58, 80)   89680       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 58, 200)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 54, 58, 80)   144080      concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 54, 58, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 54, 58, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 54, 58, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 54, 58, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 54, 58, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 54, 58, 280)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 54, 58, 280)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 108, 116, 40) 44840       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 108, 116, 80) 0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 108, 116, 40) 28840       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 108, 116, 40) 160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 108, 116, 40) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 108, 116, 40) 14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 108, 116, 40) 160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 108, 116, 40) 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 108, 116, 120 0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 108, 116, 120 0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 108, 116, 2)  242         dropout_5[0][0]                  
==================================================================================================
Total params: 887,922
Trainable params: 886,322
Non-trainable params: 1,600
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97286605 0.02713395]
Train on 17214 samples, validate on 256 samples
Epoch 1/300
 - 85s - loss: 0.1175 - acc: 0.9856 - mDice: 0.7748 - val_loss: 0.2882 - val_acc: 0.9929 - val_mDice: 0.4274

Epoch 00001: val_mDice improved from -inf to 0.42738, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_NoInit_wBiasCorrection_CV_a/1-THALAMUS/sd2/best_model_weights.h5
Epoch 2/300
 - 78s - loss: 0.0757 - acc: 0.9921 - mDice: 0.8529 - val_loss: 0.2835 - val_acc: 0.9920 - val_mDice: 0.4372

Epoch 00002: val_mDice improved from 0.42738 to 0.43720, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_NoInit_wBiasCorrection_CV_a/1-THALAMUS/sd2/best_model_weights.h5
Epoch 3/300
 - 83s - loss: 0.0687 - acc: 0.9928 - mDice: 0.8664 - val_loss: 0.2780 - val_acc: 0.9924 - val_mDice: 0.4465

Epoch 00003: val_mDice improved from 0.43720 to 0.44649, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_NoInit_wBiasCorrection_CV_a/1-THALAMUS/sd2/best_model_weights.h5
Epoch 4/300
 - 85s - loss: 0.0611 - acc: 0.9935 - mDice: 0.8811 - val_loss: 0.4212 - val_acc: 0.9804 - val_mDice: 0.1630

Epoch 00004: val_mDice did not improve from 0.44649
Epoch 5/300
 - 85s - loss: 0.0581 - acc: 0.9938 - mDice: 0.8870 - val_loss: 0.2822 - val_acc: 0.9918 - val_mDice: 0.4280

Epoch 00005: val_mDice did not improve from 0.44649
Epoch 6/300
 - 85s - loss: 0.0532 - acc: 0.9942 - mDice: 0.8966 - val_loss: 0.2403 - val_acc: 0.9943 - val_mDice: 0.5034

Epoch 00006: val_mDice improved from 0.44649 to 0.50343, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_NoInit_wBiasCorrection_CV_a/1-THALAMUS/sd2/best_model_weights.h5
Epoch 7/300
 - 84s - loss: 0.0522 - acc: 0.9943 - mDice: 0.8986 - val_loss: 0.2392 - val_acc: 0.9921 - val_mDice: 0.4868

Epoch 00007: val_mDice did not improve from 0.50343
Epoch 8/300
 - 84s - loss: 0.0494 - acc: 0.9946 - mDice: 0.9040 - val_loss: 0.2502 - val_acc: 0.9936 - val_mDice: 0.4826

Epoch 00008: val_mDice did not improve from 0.50343
Epoch 9/300
 - 85s - loss: 0.0450 - acc: 0.9949 - mDice: 0.9126 - val_loss: 0.2585 - val_acc: 0.9938 - val_mDice: 0.4826

Epoch 00009: val_mDice did not improve from 0.50343
Epoch 10/300
 - 84s - loss: 0.0442 - acc: 0.9950 - mDice: 0.9142 - val_loss: 0.2647 - val_acc: 0.9913 - val_mDice: 0.4563

Epoch 00010: val_mDice did not improve from 0.50343
Epoch 11/300
 - 85s - loss: 0.0432 - acc: 0.9951 - mDice: 0.9161 - val_loss: 0.2503 - val_acc: 0.9893 - val_mDice: 0.4717

Epoch 00011: val_mDice did not improve from 0.50343
Epoch 12/300
 - 85s - loss: 0.0415 - acc: 0.9952 - mDice: 0.9194 - val_loss: 0.2655 - val_acc: 0.9902 - val_mDice: 0.4298

Epoch 00012: val_mDice did not improve from 0.50343
Epoch 13/300
 - 86s - loss: 0.0410 - acc: 0.9953 - mDice: 0.9204 - val_loss: 0.1973 - val_acc: 0.9938 - val_mDice: 0.4959

Epoch 00013: val_mDice did not improve from 0.50343
Epoch 14/300
 - 86s - loss: 0.0395 - acc: 0.9954 - mDice: 0.9232 - val_loss: 0.2140 - val_acc: 0.9937 - val_mDice: 0.5073

Epoch 00014: val_mDice improved from 0.50343 to 0.50731, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_NoInit_wBiasCorrection_CV_a/1-THALAMUS/sd2/best_model_weights.h5
Epoch 15/300
 - 85s - loss: 0.0385 - acc: 0.9955 - mDice: 0.9253 - val_loss: 0.2383 - val_acc: 0.9926 - val_mDice: 0.4951

Epoch 00015: val_mDice did not improve from 0.50731
Epoch 16/300
 - 86s - loss: 0.0385 - acc: 0.9956 - mDice: 0.9253 - val_loss: 0.1580 - val_acc: 0.9921 - val_mDice: 0.4894

Epoch 00016: val_mDice did not improve from 0.50731
Epoch 17/300
 - 86s - loss: 0.0363 - acc: 0.9957 - mDice: 0.9295 - val_loss: -1.4568e-02 - val_acc: 0.9940 - val_mDice: 0.4997

Epoch 00017: val_mDice did not improve from 0.50731
Epoch 18/300
 - 85s - loss: 0.0362 - acc: 0.9957 - mDice: 0.9298 - val_loss: 0.1310 - val_acc: 0.9922 - val_mDice: 0.4885

Epoch 00018: val_mDice did not improve from 0.50731
Epoch 19/300
 - 85s - loss: 0.0359 - acc: 0.9957 - mDice: 0.9303 - val_loss: 0.1072 - val_acc: 0.9936 - val_mDice: 0.4848

Epoch 00019: val_mDice did not improve from 0.50731
Epoch 20/300
 - 85s - loss: 0.0353 - acc: 0.9958 - mDice: 0.9315 - val_loss: 0.1458 - val_acc: 0.9936 - val_mDice: 0.4943

Epoch 00020: val_mDice did not improve from 0.50731
Epoch 21/300
 - 85s - loss: 0.0359 - acc: 0.9959 - mDice: 0.9303 - val_loss: 0.0340 - val_acc: 0.9940 - val_mDice: 0.4971

Epoch 00021: val_mDice did not improve from 0.50731
Epoch 22/300
 - 85s - loss: 0.0345 - acc: 0.9959 - mDice: 0.9330 - val_loss: 0.0600 - val_acc: 0.9890 - val_mDice: 0.3756

Epoch 00022: val_mDice did not improve from 0.50731
Epoch 23/300
 - 85s - loss: 0.0349 - acc: 0.9958 - mDice: 0.9324 - val_loss: 0.0150 - val_acc: 0.9940 - val_mDice: 0.5053

Epoch 00023: val_mDice did not improve from 0.50731
Epoch 24/300
 - 84s - loss: 0.0341 - acc: 0.9959 - mDice: 0.9338 - val_loss: 0.0946 - val_acc: 0.9927 - val_mDice: 0.4965

Epoch 00024: val_mDice did not improve from 0.50731
Epoch 25/300
 - 84s - loss: 0.0329 - acc: 0.9960 - mDice: 0.9362 - val_loss: 0.0719 - val_acc: 0.9937 - val_mDice: 0.4794

Epoch 00025: val_mDice did not improve from 0.50731
Epoch 26/300
 - 84s - loss: 0.0326 - acc: 0.9960 - mDice: 0.9367 - val_loss: 0.0309 - val_acc: 0.9941 - val_mDice: 0.5038

Epoch 00026: val_mDice did not improve from 0.50731
Epoch 27/300
 - 84s - loss: 0.0323 - acc: 0.9960 - mDice: 0.9373 - val_loss: -1.6809e-02 - val_acc: 0.9940 - val_mDice: 0.5005

Epoch 00027: val_mDice did not improve from 0.50731
Epoch 28/300
 - 84s - loss: 0.0341 - acc: 0.9959 - mDice: 0.9339 - val_loss: 0.0709 - val_acc: 0.9940 - val_mDice: 0.5025

Epoch 00028: val_mDice did not improve from 0.50731
Epoch 29/300
 - 84s - loss: 0.0326 - acc: 0.9961 - mDice: 0.9368 - val_loss: 0.1979 - val_acc: 0.9886 - val_mDice: 0.4740

Epoch 00029: val_mDice did not improve from 0.50731

Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 30/300
 - 84s - loss: 0.0301 - acc: 0.9963 - mDice: 0.9415 - val_loss: 0.0724 - val_acc: 0.9937 - val_mDice: 0.5026

Epoch 00030: val_mDice did not improve from 0.50731
Epoch 31/300
 - 84s - loss: 0.0305 - acc: 0.9963 - mDice: 0.9408 - val_loss: 0.0129 - val_acc: 0.9933 - val_mDice: 0.4699

Epoch 00031: val_mDice did not improve from 0.50731
Epoch 32/300
 - 84s - loss: 0.0290 - acc: 0.9963 - mDice: 0.9437 - val_loss: 0.0013 - val_acc: 0.9938 - val_mDice: 0.4870

Epoch 00032: val_mDice did not improve from 0.50731
Epoch 33/300
 - 84s - loss: 0.0290 - acc: 0.9963 - mDice: 0.9437 - val_loss: -3.5130e-02 - val_acc: 0.9937 - val_mDice: 0.4826

Epoch 00033: val_mDice did not improve from 0.50731
Epoch 34/300
 - 84s - loss: 0.0289 - acc: 0.9964 - mDice: 0.9439 - val_loss: -3.7471e-02 - val_acc: 0.9939 - val_mDice: 0.4854
