2019-08-17 16:59:23.469733: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-08-17 16:59:23.803594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:85:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2019-08-17 16:59:23.803668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-08-17 16:59:24.152440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-17 16:59:24.152494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-08-17 16:59:24.152505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-08-17 16:59:24.152967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using TensorFlow backend.
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<03:06,  1.42it/s]Loading train:   1%|          | 2/266 [00:01<02:49,  1.56it/s]Loading train:   1%|          | 3/266 [00:01<02:30,  1.75it/s]Loading train:   2%|▏         | 4/266 [00:01<02:12,  1.98it/s]Loading train:   2%|▏         | 5/266 [00:02<02:02,  2.14it/s]Loading train:   2%|▏         | 6/266 [00:03<02:25,  1.78it/s]Loading train:   3%|▎         | 7/266 [00:03<02:33,  1.69it/s]Loading train:   3%|▎         | 8/266 [00:04<02:24,  1.79it/s]Loading train:   3%|▎         | 9/266 [00:04<02:14,  1.92it/s]Loading train:   4%|▍         | 10/266 [00:05<02:24,  1.77it/s]Loading train:   4%|▍         | 11/266 [00:05<02:27,  1.73it/s]Loading train:   5%|▍         | 12/266 [00:06<02:27,  1.72it/s]Loading train:   5%|▍         | 13/266 [00:07<02:56,  1.43it/s]Loading train:   5%|▌         | 14/266 [00:08<03:03,  1.37it/s]Loading train:   6%|▌         | 15/266 [00:09<03:15,  1.28it/s]Loading train:   6%|▌         | 16/266 [00:10<03:16,  1.27it/s]Loading train:   6%|▋         | 17/266 [00:10<03:21,  1.24it/s]Loading train:   7%|▋         | 18/266 [00:11<02:51,  1.45it/s]Loading train:   7%|▋         | 19/266 [00:11<02:43,  1.52it/s]Loading train:   8%|▊         | 20/266 [00:12<03:02,  1.35it/s]Loading train:   8%|▊         | 21/266 [00:13<02:47,  1.46it/s]Loading train:   8%|▊         | 22/266 [00:14<03:10,  1.28it/s]Loading train:   9%|▊         | 23/266 [00:14<02:47,  1.45it/s]Loading train:   9%|▉         | 24/266 [00:15<02:34,  1.56it/s]Loading train:   9%|▉         | 25/266 [00:16<02:42,  1.49it/s]Loading train:  10%|▉         | 26/266 [00:16<02:32,  1.57it/s]Loading train:  10%|█         | 27/266 [00:17<02:25,  1.64it/s]Loading train:  11%|█         | 28/266 [00:17<02:22,  1.66it/s]Loading train:  11%|█         | 29/266 [00:18<02:26,  1.61it/s]Loading train:  11%|█▏        | 30/266 [00:19<02:43,  1.45it/s]Loading train:  12%|█▏        | 31/266 [00:20<02:50,  1.37it/s]Loading train:  12%|█▏        | 32/266 [00:20<02:43,  1.43it/s]Loading train:  12%|█▏        | 33/266 [00:21<03:05,  1.26it/s]Loading train:  13%|█▎        | 34/266 [00:22<03:25,  1.13it/s]Loading train:  13%|█▎        | 35/266 [00:24<03:49,  1.01it/s]Loading train:  14%|█▎        | 36/266 [00:25<03:50,  1.00s/it]Loading train:  14%|█▍        | 37/266 [00:25<03:29,  1.09it/s]Loading train:  14%|█▍        | 38/266 [00:26<03:41,  1.03it/s]Loading train:  15%|█▍        | 39/266 [00:28<03:46,  1.00it/s]Loading train:  15%|█▌        | 40/266 [00:29<04:00,  1.06s/it]Loading train:  15%|█▌        | 41/266 [00:30<04:08,  1.10s/it]Loading train:  16%|█▌        | 42/266 [00:31<03:57,  1.06s/it]Loading train:  16%|█▌        | 43/266 [00:32<03:47,  1.02s/it]Loading train:  17%|█▋        | 44/266 [00:33<03:50,  1.04s/it]Loading train:  17%|█▋        | 45/266 [00:34<04:00,  1.09s/it]Loading train:  17%|█▋        | 46/266 [00:35<03:41,  1.01s/it]Loading train:  18%|█▊        | 47/266 [00:37<04:16,  1.17s/it]Loading train:  18%|█▊        | 48/266 [00:38<04:44,  1.31s/it]Loading train:  18%|█▊        | 49/266 [00:39<04:46,  1.32s/it]Loading train:  19%|█▉        | 50/266 [00:41<05:06,  1.42s/it]Loading train:  19%|█▉        | 51/266 [00:42<04:45,  1.33s/it]Loading train:  20%|█▉        | 52/266 [00:44<04:44,  1.33s/it]Loading train:  20%|█▉        | 53/266 [00:45<04:39,  1.31s/it]Loading train:  20%|██        | 54/266 [00:46<04:27,  1.26s/it]Loading train:  21%|██        | 55/266 [00:47<04:34,  1.30s/it]Loading train:  21%|██        | 56/266 [00:49<04:32,  1.30s/it]Loading train:  21%|██▏       | 57/266 [00:50<04:32,  1.30s/it]Loading train:  22%|██▏       | 58/266 [00:51<04:02,  1.17s/it]Loading train:  22%|██▏       | 59/266 [00:52<04:13,  1.23s/it]Loading train:  23%|██▎       | 60/266 [00:54<04:29,  1.31s/it]Loading train:  23%|██▎       | 61/266 [00:55<04:19,  1.26s/it]Loading train:  23%|██▎       | 62/266 [00:56<04:06,  1.21s/it]Loading train:  24%|██▎       | 63/266 [00:57<04:05,  1.21s/it]Loading train:  24%|██▍       | 64/266 [00:58<03:57,  1.18s/it]Loading train:  24%|██▍       | 65/266 [01:00<04:07,  1.23s/it]Loading train:  25%|██▍       | 66/266 [01:01<04:12,  1.26s/it]Loading train:  25%|██▌       | 67/266 [01:02<04:23,  1.33s/it]Loading train:  26%|██▌       | 68/266 [01:04<04:46,  1.45s/it]Loading train:  26%|██▌       | 69/266 [01:06<04:41,  1.43s/it]Loading train:  26%|██▋       | 70/266 [01:07<04:47,  1.46s/it]Loading train:  27%|██▋       | 71/266 [01:08<04:23,  1.35s/it]Loading train:  27%|██▋       | 72/266 [01:09<03:42,  1.15s/it]Loading train:  27%|██▋       | 73/266 [01:10<03:59,  1.24s/it]Loading train:  28%|██▊       | 74/266 [01:12<04:04,  1.28s/it]Loading train:  28%|██▊       | 75/266 [01:13<04:30,  1.42s/it]Loading train:  29%|██▊       | 76/266 [01:15<04:19,  1.37s/it]Loading train:  29%|██▉       | 77/266 [01:16<04:12,  1.34s/it]Loading train:  29%|██▉       | 78/266 [01:17<04:10,  1.33s/it]Loading train:  30%|██▉       | 79/266 [01:18<04:04,  1.31s/it]Loading train:  30%|███       | 80/266 [01:20<04:15,  1.37s/it]Loading train:  30%|███       | 81/266 [01:21<04:06,  1.33s/it]Loading train:  31%|███       | 82/266 [01:23<04:11,  1.37s/it]Loading train:  31%|███       | 83/266 [01:24<03:50,  1.26s/it]Loading train:  32%|███▏      | 84/266 [01:25<03:40,  1.21s/it]Loading train:  32%|███▏      | 85/266 [01:26<03:40,  1.22s/it]Loading train:  32%|███▏      | 86/266 [01:28<04:02,  1.35s/it]Loading train:  33%|███▎      | 87/266 [01:29<03:54,  1.31s/it]Loading train:  33%|███▎      | 88/266 [01:30<03:54,  1.32s/it]Loading train:  33%|███▎      | 89/266 [01:32<03:51,  1.31s/it]Loading train:  34%|███▍      | 90/266 [01:33<03:40,  1.25s/it]Loading train:  34%|███▍      | 91/266 [01:34<03:49,  1.31s/it]Loading train:  35%|███▍      | 92/266 [01:36<03:58,  1.37s/it]Loading train:  35%|███▍      | 93/266 [01:37<03:50,  1.33s/it]Loading train:  35%|███▌      | 94/266 [01:38<03:27,  1.21s/it]Loading train:  36%|███▌      | 95/266 [01:39<03:27,  1.21s/it]Loading train:  36%|███▌      | 96/266 [01:41<03:55,  1.39s/it]Loading train:  36%|███▋      | 97/266 [01:42<04:04,  1.45s/it]Loading train:  37%|███▋      | 98/266 [01:44<04:07,  1.48s/it]Loading train:  37%|███▋      | 99/266 [01:46<04:11,  1.51s/it]Loading train:  38%|███▊      | 100/266 [01:47<03:57,  1.43s/it]Loading train:  38%|███▊      | 101/266 [01:48<03:58,  1.45s/it]Loading train:  38%|███▊      | 102/266 [01:50<04:12,  1.54s/it]Loading train:  39%|███▊      | 103/266 [01:51<04:06,  1.51s/it]Loading train:  39%|███▉      | 104/266 [01:53<04:03,  1.51s/it]Loading train:  39%|███▉      | 105/266 [01:54<03:56,  1.47s/it]Loading train:  40%|███▉      | 106/266 [01:56<04:03,  1.52s/it]Loading train:  40%|████      | 107/266 [01:58<04:06,  1.55s/it]Loading train:  41%|████      | 108/266 [01:59<04:05,  1.55s/it]Loading train:  41%|████      | 109/266 [02:01<03:55,  1.50s/it]Loading train:  41%|████▏     | 110/266 [02:02<03:45,  1.44s/it]Loading train:  42%|████▏     | 111/266 [02:03<03:44,  1.45s/it]Loading train:  42%|████▏     | 112/266 [02:05<03:35,  1.40s/it]Loading train:  42%|████▏     | 113/266 [02:06<03:32,  1.39s/it]Loading train:  43%|████▎     | 114/266 [02:08<03:41,  1.46s/it]Loading train:  43%|████▎     | 115/266 [02:09<03:41,  1.46s/it]Loading train:  44%|████▎     | 116/266 [02:11<03:41,  1.48s/it]Loading train:  44%|████▍     | 117/266 [02:12<03:37,  1.46s/it]Loading train:  44%|████▍     | 118/266 [02:13<02:59,  1.21s/it]Loading train:  45%|████▍     | 119/266 [02:14<03:14,  1.33s/it]Loading train:  45%|████▌     | 120/266 [02:16<03:27,  1.42s/it]Loading train:  45%|████▌     | 121/266 [02:17<03:29,  1.44s/it]Loading train:  46%|████▌     | 122/266 [02:19<03:22,  1.41s/it]Loading train:  46%|████▌     | 123/266 [02:20<03:08,  1.32s/it]Loading train:  47%|████▋     | 124/266 [02:21<03:16,  1.38s/it]Loading train:  47%|████▋     | 125/266 [02:22<03:05,  1.32s/it]Loading train:  47%|████▋     | 126/266 [02:24<03:09,  1.36s/it]Loading train:  48%|████▊     | 127/266 [02:25<03:09,  1.36s/it]Loading train:  48%|████▊     | 128/266 [02:27<03:20,  1.45s/it]Loading train:  48%|████▊     | 129/266 [02:28<03:22,  1.48s/it]Loading train:  49%|████▉     | 130/266 [02:30<03:24,  1.51s/it]Loading train:  49%|████▉     | 131/266 [02:31<03:18,  1.47s/it]Loading train:  50%|████▉     | 132/266 [02:33<03:21,  1.51s/it]Loading train:  50%|█████     | 133/266 [02:34<03:13,  1.45s/it]Loading train:  50%|█████     | 134/266 [02:36<03:12,  1.46s/it]Loading train:  51%|█████     | 135/266 [02:37<03:11,  1.46s/it]Loading train:  51%|█████     | 136/266 [02:39<03:05,  1.42s/it]Loading train:  52%|█████▏    | 137/266 [02:40<03:08,  1.46s/it]Loading train:  52%|█████▏    | 138/266 [02:42<03:07,  1.47s/it]Loading train:  52%|█████▏    | 139/266 [02:43<03:14,  1.53s/it]Loading train:  53%|█████▎    | 140/266 [02:45<03:04,  1.46s/it]Loading train:  53%|█████▎    | 141/266 [02:46<03:01,  1.45s/it]Loading train:  53%|█████▎    | 142/266 [02:48<03:00,  1.45s/it]Loading train:  54%|█████▍    | 143/266 [02:49<03:01,  1.48s/it]Loading train:  54%|█████▍    | 144/266 [02:50<02:34,  1.27s/it]Loading train:  55%|█████▍    | 145/266 [02:52<02:54,  1.44s/it]Loading train:  55%|█████▍    | 146/266 [02:53<03:04,  1.54s/it]Loading train:  55%|█████▌    | 147/266 [02:55<03:02,  1.54s/it]Loading train:  56%|█████▌    | 148/266 [02:57<03:01,  1.53s/it]Loading train:  56%|█████▌    | 149/266 [02:58<02:59,  1.53s/it]Loading train:  56%|█████▋    | 150/266 [02:59<02:54,  1.50s/it]Loading train:  57%|█████▋    | 151/266 [03:01<03:03,  1.60s/it]Loading train:  57%|█████▋    | 152/266 [03:03<02:55,  1.54s/it]Loading train:  58%|█████▊    | 153/266 [03:04<02:47,  1.48s/it]Loading train:  58%|█████▊    | 154/266 [03:05<02:43,  1.46s/it]Loading train:  58%|█████▊    | 155/266 [03:07<02:38,  1.43s/it]Loading train:  59%|█████▊    | 156/266 [03:08<02:35,  1.42s/it]Loading train:  59%|█████▉    | 157/266 [03:09<02:25,  1.33s/it]Loading train:  59%|█████▉    | 158/266 [03:11<02:31,  1.40s/it]Loading train:  60%|█████▉    | 159/266 [03:12<02:32,  1.42s/it]Loading train:  60%|██████    | 160/266 [03:13<02:17,  1.29s/it]Loading train:  61%|██████    | 161/266 [03:15<02:14,  1.28s/it]Loading train:  61%|██████    | 162/266 [03:16<02:18,  1.34s/it]Loading train:  61%|██████▏   | 163/266 [03:17<02:17,  1.34s/it]Loading train:  62%|██████▏   | 164/266 [03:19<02:20,  1.38s/it]Loading train:  62%|██████▏   | 165/266 [03:20<02:22,  1.41s/it]Loading train:  62%|██████▏   | 166/266 [03:22<02:19,  1.40s/it]Loading train:  63%|██████▎   | 167/266 [03:23<02:25,  1.47s/it]Loading train:  63%|██████▎   | 168/266 [03:25<02:14,  1.37s/it]Loading train:  64%|██████▎   | 169/266 [03:26<02:15,  1.39s/it]Loading train:  64%|██████▍   | 170/266 [03:27<02:14,  1.41s/it]Loading train:  64%|██████▍   | 171/266 [03:29<02:15,  1.43s/it]Loading train:  65%|██████▍   | 172/266 [03:30<02:06,  1.34s/it]Loading train:  65%|██████▌   | 173/266 [03:32<02:09,  1.39s/it]Loading train:  65%|██████▌   | 174/266 [03:33<02:02,  1.34s/it]Loading train:  66%|██████▌   | 175/266 [03:34<02:07,  1.40s/it]Loading train:  66%|██████▌   | 176/266 [03:36<02:11,  1.46s/it]Loading train:  67%|██████▋   | 177/266 [03:37<02:14,  1.51s/it]Loading train:  67%|██████▋   | 178/266 [03:39<02:14,  1.53s/it]Loading train:  67%|██████▋   | 179/266 [03:40<02:00,  1.39s/it]Loading train:  68%|██████▊   | 180/266 [03:42<02:01,  1.41s/it]Loading train:  68%|██████▊   | 181/266 [03:43<02:02,  1.44s/it]Loading train:  68%|██████▊   | 182/266 [03:45<02:01,  1.45s/it]Loading train:  69%|██████▉   | 183/266 [03:46<02:03,  1.49s/it]Loading train:  69%|██████▉   | 184/266 [03:48<02:00,  1.46s/it]Loading train:  70%|██████▉   | 185/266 [03:49<02:02,  1.51s/it]Loading train:  70%|██████▉   | 186/266 [03:51<01:55,  1.45s/it]Loading train:  70%|███████   | 187/266 [03:52<01:51,  1.41s/it]Loading train:  71%|███████   | 188/266 [03:53<01:53,  1.46s/it]Loading train:  71%|███████   | 189/266 [03:55<02:00,  1.57s/it]Loading train:  71%|███████▏  | 190/266 [03:57<01:53,  1.50s/it]Loading train:  72%|███████▏  | 191/266 [03:58<01:56,  1.55s/it]Loading train:  72%|███████▏  | 192/266 [04:00<01:55,  1.56s/it]Loading train:  73%|███████▎  | 193/266 [04:01<01:53,  1.56s/it]Loading train:  73%|███████▎  | 194/266 [04:02<01:36,  1.35s/it]Loading train:  73%|███████▎  | 195/266 [04:04<01:40,  1.41s/it]Loading train:  74%|███████▎  | 196/266 [04:05<01:36,  1.38s/it]Loading train:  74%|███████▍  | 197/266 [04:06<01:35,  1.38s/it]Loading train:  74%|███████▍  | 198/266 [04:08<01:35,  1.40s/it]Loading train:  75%|███████▍  | 199/266 [04:09<01:33,  1.39s/it]Loading train:  75%|███████▌  | 200/266 [04:11<01:33,  1.42s/it]Loading train:  76%|███████▌  | 201/266 [04:13<01:39,  1.53s/it]Loading train:  76%|███████▌  | 202/266 [04:14<01:43,  1.62s/it]Loading train:  76%|███████▋  | 203/266 [04:16<01:40,  1.59s/it]Loading train:  77%|███████▋  | 204/266 [04:17<01:30,  1.46s/it]Loading train:  77%|███████▋  | 205/266 [04:18<01:25,  1.40s/it]Loading train:  77%|███████▋  | 206/266 [04:20<01:21,  1.36s/it]Loading train:  78%|███████▊  | 207/266 [04:21<01:24,  1.44s/it]Loading train:  78%|███████▊  | 208/266 [04:22<01:18,  1.35s/it]Loading train:  79%|███████▊  | 209/266 [04:24<01:18,  1.37s/it]Loading train:  79%|███████▉  | 210/266 [04:25<01:21,  1.45s/it]Loading train:  79%|███████▉  | 211/266 [04:27<01:16,  1.39s/it]Loading train:  80%|███████▉  | 212/266 [04:28<01:19,  1.47s/it]Loading train:  80%|████████  | 213/266 [04:29<01:12,  1.36s/it]Loading train:  80%|████████  | 214/266 [04:31<01:12,  1.39s/it]Loading train:  81%|████████  | 215/266 [04:32<01:09,  1.37s/it]Loading train:  81%|████████  | 216/266 [04:34<01:10,  1.41s/it]Loading train:  82%|████████▏ | 217/266 [04:35<01:11,  1.47s/it]Loading train:  82%|████████▏ | 218/266 [04:37<01:10,  1.47s/it]Loading train:  82%|████████▏ | 219/266 [04:38<01:03,  1.35s/it]Loading train:  83%|████████▎ | 220/266 [04:39<00:52,  1.15s/it]Loading train:  83%|████████▎ | 221/266 [04:40<00:53,  1.19s/it]Loading train:  83%|████████▎ | 222/266 [04:41<00:56,  1.29s/it]Loading train:  84%|████████▍ | 223/266 [04:43<00:56,  1.32s/it]Loading train:  84%|████████▍ | 224/266 [04:44<00:53,  1.28s/it]Loading train:  85%|████████▍ | 225/266 [04:45<00:49,  1.21s/it]Loading train:  85%|████████▍ | 226/266 [04:47<00:53,  1.33s/it]Loading train:  85%|████████▌ | 227/266 [04:48<00:50,  1.30s/it]Loading train:  86%|████████▌ | 228/266 [04:49<00:51,  1.35s/it]Loading train:  86%|████████▌ | 229/266 [04:50<00:48,  1.32s/it]Loading train:  86%|████████▋ | 230/266 [04:52<00:49,  1.37s/it]Loading train:  87%|████████▋ | 231/266 [04:53<00:48,  1.38s/it]Loading train:  87%|████████▋ | 232/266 [04:55<00:47,  1.40s/it]Loading train:  88%|████████▊ | 233/266 [04:56<00:46,  1.40s/it]Loading train:  88%|████████▊ | 234/266 [04:58<00:44,  1.38s/it]Loading train:  88%|████████▊ | 235/266 [04:59<00:43,  1.41s/it]Loading train:  89%|████████▊ | 236/266 [05:00<00:42,  1.42s/it]Loading train:  89%|████████▉ | 237/266 [05:02<00:42,  1.45s/it]Loading train:  89%|████████▉ | 238/266 [05:03<00:40,  1.46s/it]Loading train:  90%|████████▉ | 239/266 [05:05<00:40,  1.48s/it]Loading train:  90%|█████████ | 240/266 [05:07<00:39,  1.51s/it]Loading train:  91%|█████████ | 241/266 [05:08<00:36,  1.46s/it]Loading train:  91%|█████████ | 242/266 [05:09<00:30,  1.27s/it]Loading train:  91%|█████████▏| 243/266 [05:10<00:28,  1.23s/it]Loading train:  92%|█████████▏| 244/266 [05:11<00:27,  1.23s/it]Loading train:  92%|█████████▏| 245/266 [05:12<00:25,  1.23s/it]Loading train:  92%|█████████▏| 246/266 [05:14<00:24,  1.23s/it]Loading train:  93%|█████████▎| 247/266 [05:15<00:24,  1.28s/it]Loading train:  93%|█████████▎| 248/266 [05:16<00:22,  1.24s/it]Loading train:  94%|█████████▎| 249/266 [05:18<00:22,  1.34s/it]Loading train:  94%|█████████▍| 250/266 [05:19<00:21,  1.36s/it]Loading train:  94%|█████████▍| 251/266 [05:21<00:20,  1.39s/it]Loading train:  95%|█████████▍| 252/266 [05:22<00:19,  1.36s/it]Loading train:  95%|█████████▌| 253/266 [05:23<00:17,  1.38s/it]Loading train:  95%|█████████▌| 254/266 [05:24<00:15,  1.33s/it]Loading train:  96%|█████████▌| 255/266 [05:26<00:14,  1.34s/it]Loading train:  96%|█████████▌| 256/266 [05:27<00:13,  1.37s/it]Loading train:  97%|█████████▋| 257/266 [05:28<00:10,  1.15s/it]Loading train:  97%|█████████▋| 258/266 [05:29<00:10,  1.27s/it]Loading train:  97%|█████████▋| 259/266 [05:31<00:09,  1.34s/it]Loading train:  98%|█████████▊| 260/266 [05:33<00:08,  1.40s/it]Loading train:  98%|█████████▊| 261/266 [05:34<00:07,  1.44s/it]Loading train:  98%|█████████▊| 262/266 [05:35<00:05,  1.37s/it]Loading train:  99%|█████████▉| 263/266 [05:37<00:04,  1.38s/it]Loading train:  99%|█████████▉| 264/266 [05:38<00:02,  1.39s/it]Loading train: 100%|█████████▉| 265/266 [05:40<00:01,  1.41s/it]Loading train: 100%|██████████| 266/266 [05:41<00:00,  1.37s/it]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   1%|          | 2/266 [00:00<00:22, 11.87it/s]concatenating: train:   1%|          | 3/266 [00:00<00:24, 10.93it/s]concatenating: train:   2%|▏         | 5/266 [00:00<00:26,  9.82it/s]concatenating: train:   2%|▏         | 6/266 [00:00<00:28,  9.22it/s]concatenating: train:   3%|▎         | 7/266 [00:00<00:36,  7.05it/s]concatenating: train:   3%|▎         | 8/266 [00:01<00:35,  7.26it/s]concatenating: train:   3%|▎         | 9/266 [00:01<00:41,  6.20it/s]concatenating: train:   4%|▍         | 10/266 [00:01<00:38,  6.61it/s]concatenating: train:   4%|▍         | 11/266 [00:01<00:43,  5.82it/s]concatenating: train:   5%|▍         | 12/266 [00:01<00:40,  6.21it/s]concatenating: train:   5%|▍         | 13/266 [00:01<00:40,  6.31it/s]concatenating: train:   6%|▌         | 15/266 [00:02<00:34,  7.32it/s]concatenating: train:   7%|▋         | 18/266 [00:02<00:26,  9.32it/s]concatenating: train:   8%|▊         | 20/266 [00:02<00:35,  6.85it/s]concatenating: train:   8%|▊         | 22/266 [00:03<00:39,  6.10it/s]concatenating: train:   9%|▊         | 23/266 [00:03<00:46,  5.22it/s]concatenating: train:   9%|▉         | 24/266 [00:03<00:46,  5.22it/s]concatenating: train:   9%|▉         | 25/266 [00:03<00:39,  6.09it/s]concatenating: train:  10%|▉         | 26/266 [00:03<00:35,  6.70it/s]concatenating: train:  11%|█         | 29/266 [00:03<00:27,  8.63it/s]concatenating: train:  12%|█▏        | 33/266 [00:03<00:21, 10.74it/s]concatenating: train:  13%|█▎        | 35/266 [00:04<00:30,  7.49it/s]concatenating: train:  14%|█▍        | 37/266 [00:04<00:32,  7.01it/s]concatenating: train:  15%|█▍        | 39/266 [00:05<00:33,  6.79it/s]concatenating: train:  15%|█▌        | 40/266 [00:05<00:32,  7.01it/s]concatenating: train:  15%|█▌        | 41/266 [00:05<00:33,  6.76it/s]concatenating: train:  16%|█▌        | 43/266 [00:05<00:27,  8.11it/s]concatenating: train:  17%|█▋        | 45/266 [00:05<00:28,  7.72it/s]concatenating: train:  17%|█▋        | 46/266 [00:05<00:30,  7.28it/s]concatenating: train:  18%|█▊        | 47/266 [00:06<00:43,  5.01it/s]concatenating: train:  18%|█▊        | 48/266 [00:06<00:44,  4.95it/s]concatenating: train:  18%|█▊        | 49/266 [00:06<00:45,  4.79it/s]concatenating: train:  19%|█▉        | 50/266 [00:06<00:45,  4.80it/s]concatenating: train:  19%|█▉        | 51/266 [00:07<00:38,  5.61it/s]concatenating: train:  20%|█▉        | 53/266 [00:07<00:30,  7.09it/s]concatenating: train:  21%|██        | 56/266 [00:07<00:23,  8.93it/s]concatenating: train:  22%|██▏       | 59/266 [00:07<00:23,  8.81it/s]concatenating: train:  23%|██▎       | 61/266 [00:08<00:33,  6.14it/s]concatenating: train:  23%|██▎       | 62/266 [00:08<00:35,  5.75it/s]concatenating: train:  24%|██▎       | 63/266 [00:08<00:40,  4.97it/s]concatenating: train:  24%|██▍       | 64/266 [00:08<00:35,  5.62it/s]concatenating: train:  26%|██▋       | 70/266 [00:08<00:25,  7.65it/s]concatenating: train:  27%|██▋       | 72/266 [00:09<00:26,  7.26it/s]concatenating: train:  28%|██▊       | 74/266 [00:09<00:32,  5.83it/s]concatenating: train:  29%|██▊       | 76/266 [00:10<00:34,  5.46it/s]concatenating: train:  29%|██▉       | 77/266 [00:10<00:37,  5.00it/s]concatenating: train:  29%|██▉       | 78/266 [00:10<00:32,  5.72it/s]concatenating: train:  30%|██▉       | 79/266 [00:10<00:30,  6.08it/s]concatenating: train:  30%|███       | 80/266 [00:10<00:30,  6.09it/s]concatenating: train:  30%|███       | 81/266 [00:10<00:29,  6.32it/s]concatenating: train:  31%|███       | 82/266 [00:11<00:28,  6.45it/s]concatenating: train:  31%|███       | 83/266 [00:11<00:27,  6.54it/s]concatenating: train:  32%|███▏      | 84/266 [00:11<00:29,  6.25it/s]concatenating: train:  32%|███▏      | 85/266 [00:11<00:27,  6.50it/s]concatenating: train:  32%|███▏      | 86/266 [00:11<00:26,  6.90it/s]concatenating: train:  33%|███▎      | 88/266 [00:11<00:24,  7.27it/s]concatenating: train:  33%|███▎      | 89/266 [00:12<00:24,  7.30it/s]concatenating: train:  34%|███▍      | 90/266 [00:12<00:27,  6.41it/s]concatenating: train:  34%|███▍      | 91/266 [00:12<00:29,  5.91it/s]concatenating: train:  35%|███▍      | 92/266 [00:12<00:29,  5.87it/s]concatenating: train:  35%|███▍      | 93/266 [00:12<00:27,  6.40it/s]concatenating: train:  35%|███▌      | 94/266 [00:12<00:26,  6.61it/s]concatenating: train:  36%|███▌      | 95/266 [00:13<00:28,  6.07it/s]concatenating: train:  36%|███▌      | 96/266 [00:13<00:28,  5.99it/s]concatenating: train:  36%|███▋      | 97/266 [00:13<00:29,  5.77it/s]concatenating: train:  37%|███▋      | 98/266 [00:13<00:28,  5.91it/s]concatenating: train:  37%|███▋      | 99/266 [00:13<00:26,  6.23it/s]concatenating: train:  38%|███▊      | 100/266 [00:13<00:25,  6.63it/s]concatenating: train:  38%|███▊      | 102/266 [00:14<00:23,  6.98it/s]concatenating: train:  39%|███▊      | 103/266 [00:14<00:28,  5.65it/s]concatenating: train:  39%|███▉      | 104/266 [00:14<00:32,  5.04it/s]concatenating: train:  39%|███▉      | 105/266 [00:14<00:37,  4.32it/s]concatenating: train:  40%|███▉      | 106/266 [00:15<00:36,  4.34it/s]concatenating: train:  40%|████      | 107/266 [00:15<00:33,  4.73it/s]concatenating: train:  41%|████      | 108/266 [00:15<00:29,  5.36it/s]concatenating: train:  41%|████      | 109/266 [00:15<00:28,  5.45it/s]concatenating: train:  41%|████▏     | 110/266 [00:15<00:26,  5.79it/s]concatenating: train:  42%|████▏     | 111/266 [00:15<00:24,  6.42it/s]concatenating: train:  42%|████▏     | 112/266 [00:16<00:26,  5.75it/s]concatenating: train:  42%|████▏     | 113/266 [00:16<00:28,  5.33it/s]concatenating: train:  43%|████▎     | 114/266 [00:16<00:28,  5.26it/s]concatenating: train:  43%|████▎     | 115/266 [00:16<00:27,  5.41it/s]concatenating: train:  44%|████▎     | 116/266 [00:16<00:27,  5.42it/s]concatenating: train:  44%|████▍     | 117/266 [00:17<00:29,  4.97it/s]concatenating: train:  44%|████▍     | 118/266 [00:17<00:29,  4.98it/s]concatenating: train:  45%|████▍     | 119/266 [00:17<00:29,  5.05it/s]concatenating: train:  45%|████▌     | 120/266 [00:17<00:27,  5.36it/s]concatenating: train:  45%|████▌     | 121/266 [00:17<00:27,  5.28it/s]concatenating: train:  46%|████▌     | 122/266 [00:18<00:25,  5.61it/s]concatenating: train:  46%|████▌     | 123/266 [00:18<00:24,  5.95it/s]concatenating: train:  47%|████▋     | 124/266 [00:18<00:22,  6.22it/s]concatenating: train:  47%|████▋     | 125/266 [00:18<00:24,  5.72it/s]concatenating: train:  47%|████▋     | 126/266 [00:18<00:24,  5.83it/s]concatenating: train:  48%|████▊     | 127/266 [00:18<00:22,  6.26it/s]concatenating: train:  48%|████▊     | 128/266 [00:18<00:20,  6.66it/s]concatenating: train:  48%|████▊     | 129/266 [00:19<00:21,  6.28it/s]concatenating: train:  49%|████▉     | 130/266 [00:19<00:24,  5.49it/s]concatenating: train:  49%|████▉     | 131/266 [00:19<00:23,  5.86it/s]concatenating: train:  50%|████▉     | 132/266 [00:19<00:23,  5.72it/s]concatenating: train:  50%|█████     | 133/266 [00:19<00:26,  5.08it/s]concatenating: train:  50%|█████     | 134/266 [00:20<00:26,  4.97it/s]concatenating: train:  51%|█████     | 135/266 [00:20<00:29,  4.41it/s]concatenating: train:  51%|█████     | 136/266 [00:20<00:28,  4.49it/s]concatenating: train:  52%|█████▏    | 137/266 [00:20<00:29,  4.34it/s]concatenating: train:  52%|█████▏    | 138/266 [00:21<00:28,  4.45it/s]concatenating: train:  52%|█████▏    | 139/266 [00:21<00:28,  4.50it/s]concatenating: train:  53%|█████▎    | 140/266 [00:21<00:25,  4.94it/s]concatenating: train:  53%|█████▎    | 141/266 [00:21<00:24,  5.14it/s]concatenating: train:  53%|█████▎    | 142/266 [00:21<00:23,  5.19it/s]concatenating: train:  54%|█████▍    | 143/266 [00:21<00:21,  5.74it/s]concatenating: train:  54%|█████▍    | 144/266 [00:22<00:20,  5.84it/s]concatenating: train:  55%|█████▍    | 145/266 [00:22<00:20,  5.83it/s]concatenating: train:  55%|█████▍    | 146/266 [00:22<00:22,  5.31it/s]concatenating: train:  55%|█████▌    | 147/266 [00:22<00:22,  5.28it/s]concatenating: train:  56%|█████▌    | 148/266 [00:22<00:25,  4.69it/s]concatenating: train:  56%|█████▌    | 149/266 [00:23<00:23,  4.92it/s]concatenating: train:  56%|█████▋    | 150/266 [00:23<00:21,  5.39it/s]concatenating: train:  57%|█████▋    | 151/266 [00:23<00:28,  3.97it/s]concatenating: train:  57%|█████▋    | 152/266 [00:23<00:26,  4.27it/s]concatenating: train:  58%|█████▊    | 153/266 [00:24<00:24,  4.62it/s]concatenating: train:  58%|█████▊    | 154/266 [00:24<00:31,  3.59it/s]concatenating: train:  58%|█████▊    | 155/266 [00:24<00:31,  3.55it/s]concatenating: train:  59%|█████▊    | 156/266 [00:25<00:30,  3.57it/s]concatenating: train:  59%|█████▉    | 157/266 [00:25<00:27,  3.91it/s]concatenating: train:  59%|█████▉    | 158/266 [00:25<00:26,  4.14it/s]concatenating: train:  60%|█████▉    | 159/266 [00:25<00:25,  4.25it/s]concatenating: train:  60%|██████    | 160/266 [00:25<00:22,  4.68it/s]concatenating: train:  61%|██████    | 161/266 [00:26<00:22,  4.77it/s]concatenating: train:  61%|██████    | 162/266 [00:26<00:19,  5.40it/s]concatenating: train:  61%|██████▏   | 163/266 [00:26<00:19,  5.34it/s]concatenating: train:  62%|██████▏   | 164/266 [00:26<00:20,  5.01it/s]concatenating: train:  62%|██████▏   | 165/266 [00:26<00:19,  5.07it/s]concatenating: train:  62%|██████▏   | 166/266 [00:27<00:24,  4.01it/s]concatenating: train:  63%|██████▎   | 167/266 [00:27<00:25,  3.86it/s]concatenating: train:  63%|██████▎   | 168/266 [00:27<00:23,  4.17it/s]concatenating: train:  64%|██████▎   | 169/266 [00:27<00:20,  4.63it/s]concatenating: train:  64%|██████▍   | 170/266 [00:27<00:19,  5.05it/s]concatenating: train:  64%|██████▍   | 171/266 [00:28<00:18,  5.01it/s]concatenating: train:  65%|██████▍   | 172/266 [00:28<00:18,  4.97it/s]concatenating: train:  65%|██████▌   | 173/266 [00:28<00:18,  4.98it/s]concatenating: train:  65%|██████▌   | 174/266 [00:28<00:18,  4.93it/s]concatenating: train:  66%|██████▌   | 175/266 [00:28<00:18,  4.98it/s]concatenating: train:  66%|██████▌   | 176/266 [00:29<00:20,  4.38it/s]concatenating: train:  67%|██████▋   | 177/266 [00:29<00:19,  4.63it/s]concatenating: train:  67%|██████▋   | 178/266 [00:29<00:17,  5.05it/s]concatenating: train:  67%|██████▋   | 179/266 [00:29<00:16,  5.43it/s]concatenating: train:  68%|██████▊   | 180/266 [00:29<00:14,  5.77it/s]concatenating: train:  68%|██████▊   | 181/266 [00:30<00:13,  6.17it/s]concatenating: train:  68%|██████▊   | 182/266 [00:30<00:13,  6.06it/s]concatenating: train:  69%|██████▉   | 183/266 [00:30<00:13,  6.35it/s]concatenating: train:  69%|██████▉   | 184/266 [00:30<00:12,  6.36it/s]concatenating: train:  70%|██████▉   | 185/266 [00:30<00:12,  6.69it/s]concatenating: train:  70%|██████▉   | 186/266 [00:30<00:12,  6.49it/s]concatenating: train:  70%|███████   | 187/266 [00:30<00:12,  6.18it/s]concatenating: train:  71%|███████   | 188/266 [00:31<00:12,  6.16it/s]concatenating: train:  71%|███████   | 189/266 [00:31<00:12,  6.28it/s]concatenating: train:  71%|███████▏  | 190/266 [00:31<00:13,  5.75it/s]concatenating: train:  72%|███████▏  | 191/266 [00:31<00:12,  5.77it/s]concatenating: train:  72%|███████▏  | 192/266 [00:31<00:12,  5.91it/s]concatenating: train:  73%|███████▎  | 193/266 [00:32<00:12,  5.72it/s]concatenating: train:  73%|███████▎  | 194/266 [00:32<00:13,  5.34it/s]concatenating: train:  73%|███████▎  | 195/266 [00:32<00:12,  5.90it/s]concatenating: train:  74%|███████▎  | 196/266 [00:32<00:14,  4.71it/s]concatenating: train:  74%|███████▍  | 197/266 [00:32<00:14,  4.61it/s]concatenating: train:  74%|███████▍  | 198/266 [00:33<00:13,  4.94it/s]concatenating: train:  75%|███████▍  | 199/266 [00:33<00:13,  5.05it/s]concatenating: train:  75%|███████▌  | 200/266 [00:33<00:13,  4.83it/s]concatenating: train:  76%|███████▌  | 201/266 [00:33<00:12,  5.15it/s]concatenating: train:  76%|███████▋  | 203/266 [00:33<00:10,  5.84it/s]concatenating: train:  77%|███████▋  | 204/266 [00:34<00:09,  6.32it/s]concatenating: train:  77%|███████▋  | 205/266 [00:34<00:10,  5.77it/s]concatenating: train:  77%|███████▋  | 206/266 [00:34<00:09,  6.26it/s]concatenating: train:  78%|███████▊  | 207/266 [00:34<00:09,  5.95it/s]concatenating: train:  78%|███████▊  | 208/266 [00:34<00:09,  5.91it/s]concatenating: train:  79%|███████▊  | 209/266 [00:34<00:09,  5.92it/s]concatenating: train:  79%|███████▉  | 210/266 [00:35<00:09,  6.10it/s]concatenating: train:  79%|███████▉  | 211/266 [00:35<00:08,  6.43it/s]concatenating: train:  80%|███████▉  | 212/266 [00:35<00:07,  6.85it/s]concatenating: train:  80%|████████  | 213/266 [00:35<00:08,  6.26it/s]concatenating: train:  80%|████████  | 214/266 [00:35<00:08,  5.82it/s]concatenating: train:  81%|████████  | 215/266 [00:35<00:08,  6.25it/s]concatenating: train:  81%|████████  | 216/266 [00:36<00:08,  6.07it/s]concatenating: train:  82%|████████▏ | 217/266 [00:36<00:08,  5.70it/s]concatenating: train:  82%|████████▏ | 218/266 [00:36<00:08,  5.86it/s]concatenating: train:  82%|████████▏ | 219/266 [00:36<00:08,  5.39it/s]concatenating: train:  83%|████████▎ | 220/266 [00:36<00:08,  5.45it/s]concatenating: train:  83%|████████▎ | 221/266 [00:36<00:07,  5.90it/s]concatenating: train:  83%|████████▎ | 222/266 [00:37<00:07,  5.55it/s]concatenating: train:  84%|████████▍ | 223/266 [00:37<00:07,  5.87it/s]concatenating: train:  84%|████████▍ | 224/266 [00:37<00:06,  6.25it/s]concatenating: train:  85%|████████▍ | 225/266 [00:37<00:06,  6.44it/s]concatenating: train:  85%|████████▍ | 226/266 [00:37<00:05,  6.91it/s]concatenating: train:  85%|████████▌ | 227/266 [00:37<00:06,  5.65it/s]concatenating: train:  86%|████████▌ | 228/266 [00:38<00:07,  4.93it/s]concatenating: train:  86%|████████▌ | 229/266 [00:38<00:07,  4.92it/s]concatenating: train:  86%|████████▋ | 230/266 [00:38<00:06,  5.53it/s]concatenating: train:  87%|████████▋ | 232/266 [00:38<00:05,  6.20it/s]concatenating: train:  88%|████████▊ | 233/266 [00:38<00:05,  6.46it/s]concatenating: train:  88%|████████▊ | 234/266 [00:39<00:04,  6.54it/s]concatenating: train:  88%|████████▊ | 235/266 [00:39<00:04,  6.86it/s]concatenating: train:  89%|████████▊ | 236/266 [00:39<00:05,  5.09it/s]concatenating: train:  89%|████████▉ | 237/266 [00:39<00:05,  5.22it/s]concatenating: train:  89%|████████▉ | 238/266 [00:39<00:05,  5.39it/s]concatenating: train:  90%|████████▉ | 239/266 [00:39<00:04,  5.78it/s]concatenating: train:  90%|█████████ | 240/266 [00:40<00:03,  6.56it/s]concatenating: train:  91%|█████████ | 241/266 [00:40<00:03,  7.07it/s]concatenating: train:  91%|█████████ | 242/266 [00:40<00:03,  6.97it/s]concatenating: train:  91%|█████████▏| 243/266 [00:40<00:03,  7.02it/s]concatenating: train:  92%|█████████▏| 244/266 [00:40<00:03,  6.61it/s]concatenating: train:  92%|█████████▏| 245/266 [00:40<00:03,  6.07it/s]concatenating: train:  92%|█████████▏| 246/266 [00:41<00:03,  5.48it/s]concatenating: train:  93%|█████████▎| 247/266 [00:41<00:03,  5.47it/s]concatenating: train:  93%|█████████▎| 248/266 [00:41<00:03,  5.53it/s]concatenating: train:  94%|█████████▎| 249/266 [00:41<00:03,  5.29it/s]concatenating: train:  94%|█████████▍| 250/266 [00:41<00:02,  5.98it/s]concatenating: train:  95%|█████████▍| 252/266 [00:41<00:02,  6.78it/s]concatenating: train:  95%|█████████▌| 254/266 [00:42<00:01,  7.93it/s]concatenating: train:  96%|█████████▌| 255/266 [00:42<00:02,  5.22it/s]concatenating: train:  96%|█████████▌| 256/266 [00:42<00:01,  5.46it/s]concatenating: train:  97%|█████████▋| 257/266 [00:42<00:01,  5.31it/s]concatenating: train:  97%|█████████▋| 258/266 [00:42<00:01,  5.42it/s]concatenating: train:  97%|█████████▋| 259/266 [00:43<00:01,  5.84it/s]concatenating: train:  98%|█████████▊| 260/266 [00:43<00:00,  6.37it/s]concatenating: train:  98%|█████████▊| 261/266 [00:43<00:00,  6.97it/s]concatenating: train:  98%|█████████▊| 262/266 [00:43<00:00,  6.90it/s]concatenating: train:  99%|█████████▉| 263/266 [00:43<00:00,  7.15it/s]concatenating: train:  99%|█████████▉| 264/266 [00:43<00:00,  7.27it/s]concatenating: train: 100%|█████████▉| 265/266 [00:43<00:00,  7.30it/s]concatenating: train: 100%|██████████| 266/266 [00:44<00:00,  7.13it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:01<00:05,  1.27s/it]Loading test:  40%|████      | 2/5 [00:03<00:04,  1.52s/it]Loading test:  60%|██████    | 3/5 [00:05<00:03,  1.56s/it]Loading test:  80%|████████  | 4/5 [00:06<00:01,  1.56s/it]Loading test: 100%|██████████| 5/5 [00:08<00:00,  1.70s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation:  20%|██        | 1/5 [00:00<00:00,  6.26it/s]concatenating: validation:  40%|████      | 2/5 [00:00<00:00,  6.35it/s]concatenating: validation:  60%|██████    | 3/5 [00:00<00:00,  6.52it/s]concatenating: validation:  80%|████████  | 4/5 [00:00<00:00,  6.74it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00,  6.98it/s]
Loading trainS:   0%|          | 0/266 [00:00<?, ?it/s]Loading trainS:   0%|          | 1/266 [00:01<06:38,  1.50s/it]Loading trainS:   1%|          | 2/266 [00:02<06:27,  1.47s/it]Loading trainS:   1%|          | 3/266 [00:04<06:29,  1.48s/it]Loading trainS:   2%|▏         | 4/266 [00:05<06:17,  1.44s/it]Loading trainS:   2%|▏         | 5/266 [00:07<06:19,  1.46s/it]Loading trainS:   2%|▏         | 6/266 [00:08<05:44,  1.32s/it]Loading trainS:   3%|▎         | 7/266 [00:09<05:31,  1.28s/it]Loading trainS:   3%|▎         | 8/266 [00:10<05:49,  1.36s/it]Loading trainS:   3%|▎         | 9/266 [00:12<06:17,  1.47s/it]Loading trainS:   4%|▍         | 10/266 [00:14<06:22,  1.49s/it]Loading trainS:   4%|▍         | 11/266 [00:16<06:47,  1.60s/it]Loading trainS:   5%|▍         | 12/266 [00:18<07:15,  1.71s/it]Loading trainS:   5%|▍         | 13/266 [00:19<07:20,  1.74s/it]Loading trainS:   5%|▌         | 14/266 [00:21<07:14,  1.72s/it]Loading trainS:   6%|▌         | 15/266 [00:23<07:04,  1.69s/it]Loading trainS:   6%|▌         | 16/266 [00:24<06:58,  1.67s/it]Loading trainS:   6%|▋         | 17/266 [00:27<07:35,  1.83s/it]Loading trainS:   7%|▋         | 18/266 [00:28<07:37,  1.84s/it]Loading trainS:   7%|▋         | 19/266 [00:30<06:48,  1.66s/it]Loading trainS:   8%|▊         | 20/266 [00:31<06:47,  1.66s/it]Loading trainS:   8%|▊         | 21/266 [00:33<06:29,  1.59s/it]Loading trainS:   8%|▊         | 22/266 [00:34<05:45,  1.42s/it]Loading trainS:   9%|▊         | 23/266 [00:34<04:56,  1.22s/it]Loading trainS:   9%|▉         | 24/266 [00:35<04:31,  1.12s/it]Loading trainS:   9%|▉         | 25/266 [00:37<04:47,  1.19s/it]Loading trainS:  10%|▉         | 26/266 [00:38<05:21,  1.34s/it]Loading trainS:  10%|█         | 27/266 [00:40<05:25,  1.36s/it]Loading trainS:  11%|█         | 28/266 [00:41<05:30,  1.39s/it]Loading trainS:  11%|█         | 29/266 [00:43<05:34,  1.41s/it]Loading trainS:  11%|█▏        | 30/266 [00:43<04:38,  1.18s/it]Loading trainS:  12%|█▏        | 31/266 [00:45<05:03,  1.29s/it]Loading trainS:  12%|█▏        | 32/266 [00:46<05:10,  1.33s/it]Loading trainS:  12%|█▏        | 33/266 [00:48<05:22,  1.38s/it]Loading trainS:  13%|█▎        | 34/266 [00:49<05:33,  1.44s/it]Loading trainS:  13%|█▎        | 35/266 [00:51<05:29,  1.42s/it]Loading trainS:  14%|█▎        | 36/266 [00:52<05:33,  1.45s/it]Loading trainS:  14%|█▍        | 37/266 [00:54<05:23,  1.41s/it]Loading trainS:  14%|█▍        | 38/266 [00:55<04:54,  1.29s/it]Loading trainS:  15%|█▍        | 39/266 [00:56<04:49,  1.28s/it]Loading trainS:  15%|█▌        | 40/266 [00:57<05:09,  1.37s/it]Loading trainS:  15%|█▌        | 41/266 [00:59<05:32,  1.48s/it]Loading trainS:  16%|█▌        | 42/266 [01:00<05:15,  1.41s/it]Loading trainS:  16%|█▌        | 43/266 [01:02<05:12,  1.40s/it]Loading trainS:  17%|█▋        | 44/266 [01:03<05:17,  1.43s/it]Loading trainS:  17%|█▋        | 45/266 [01:05<05:16,  1.43s/it]Loading trainS:  17%|█▋        | 46/266 [01:06<05:07,  1.40s/it]Loading trainS:  18%|█▊        | 47/266 [01:07<05:04,  1.39s/it]Loading trainS:  18%|█▊        | 48/266 [01:09<05:00,  1.38s/it]Loading trainS:  18%|█▊        | 49/266 [01:10<05:09,  1.43s/it]Loading trainS:  19%|█▉        | 50/266 [01:11<04:39,  1.29s/it]Loading trainS:  19%|█▉        | 51/266 [01:13<04:37,  1.29s/it]Loading trainS:  20%|█▉        | 52/266 [01:14<04:41,  1.32s/it]Loading trainS:  20%|█▉        | 53/266 [01:15<04:34,  1.29s/it]Loading trainS:  20%|██        | 54/266 [01:16<04:13,  1.19s/it]Loading trainS:  21%|██        | 55/266 [01:18<04:24,  1.25s/it]Loading trainS:  21%|██        | 56/266 [01:19<04:37,  1.32s/it]Loading trainS:  21%|██▏       | 57/266 [01:21<04:59,  1.43s/it]Loading trainS:  22%|██▏       | 58/266 [01:22<04:24,  1.27s/it]Loading trainS:  22%|██▏       | 59/266 [01:23<04:03,  1.18s/it]Loading trainS:  23%|██▎       | 60/266 [01:24<04:28,  1.30s/it]Loading trainS:  23%|██▎       | 61/266 [01:26<04:33,  1.34s/it]Loading trainS:  23%|██▎       | 62/266 [01:27<04:38,  1.36s/it]Loading trainS:  24%|██▎       | 63/266 [01:28<04:27,  1.32s/it]Loading trainS:  24%|██▍       | 64/266 [01:30<04:28,  1.33s/it]Loading trainS:  24%|██▍       | 65/266 [01:31<04:14,  1.27s/it]Loading trainS:  25%|██▍       | 66/266 [01:32<03:50,  1.15s/it]Loading trainS:  25%|██▌       | 67/266 [01:33<04:01,  1.21s/it]Loading trainS:  26%|██▌       | 68/266 [01:34<03:56,  1.20s/it]Loading trainS:  26%|██▌       | 69/266 [01:36<04:10,  1.27s/it]Loading trainS:  26%|██▋       | 70/266 [01:37<04:12,  1.29s/it]Loading trainS:  27%|██▋       | 71/266 [01:38<04:18,  1.32s/it]Loading trainS:  27%|██▋       | 72/266 [01:39<04:08,  1.28s/it]Loading trainS:  27%|██▋       | 73/266 [01:41<03:53,  1.21s/it]Loading trainS:  28%|██▊       | 74/266 [01:42<04:10,  1.31s/it]Loading trainS:  28%|██▊       | 75/266 [01:44<04:32,  1.43s/it]Loading trainS:  29%|██▊       | 76/266 [01:45<04:33,  1.44s/it]Loading trainS:  29%|██▉       | 77/266 [01:47<04:28,  1.42s/it]Loading trainS:  29%|██▉       | 78/266 [01:48<04:14,  1.35s/it]Loading trainS:  30%|██▉       | 79/266 [01:49<04:15,  1.36s/it]Loading trainS:  30%|███       | 80/266 [01:50<04:08,  1.34s/it]Loading trainS:  30%|███       | 81/266 [01:52<04:05,  1.33s/it]Loading trainS:  31%|███       | 82/266 [01:53<03:34,  1.16s/it]Loading trainS:  31%|███       | 83/266 [01:54<03:35,  1.18s/it]Loading trainS:  32%|███▏      | 84/266 [01:55<03:36,  1.19s/it]Loading trainS:  32%|███▏      | 85/266 [01:56<03:30,  1.16s/it]Loading trainS:  32%|███▏      | 86/266 [01:57<03:31,  1.18s/it]Loading trainS:  33%|███▎      | 87/266 [01:58<03:29,  1.17s/it]Loading trainS:  33%|███▎      | 88/266 [02:00<03:48,  1.28s/it]Loading trainS:  33%|███▎      | 89/266 [02:01<03:39,  1.24s/it]Loading trainS:  34%|███▍      | 90/266 [02:03<03:44,  1.28s/it]Loading trainS:  34%|███▍      | 91/266 [02:04<03:39,  1.25s/it]Loading trainS:  35%|███▍      | 92/266 [02:04<03:12,  1.11s/it]Loading trainS:  35%|███▍      | 93/266 [02:06<03:20,  1.16s/it]Loading trainS:  35%|███▌      | 94/266 [02:07<03:31,  1.23s/it]Loading trainS:  36%|███▌      | 95/266 [02:08<03:35,  1.26s/it]Loading trainS:  36%|███▌      | 96/266 [02:10<03:32,  1.25s/it]Loading trainS:  36%|███▋      | 97/266 [02:11<03:28,  1.23s/it]Loading trainS:  37%|███▋      | 98/266 [02:12<03:36,  1.29s/it]Loading trainS:  37%|███▋      | 99/266 [02:14<03:32,  1.27s/it]Loading trainS:  38%|███▊      | 100/266 [02:15<03:31,  1.27s/it]Loading trainS:  38%|███▊      | 101/266 [02:16<03:27,  1.26s/it]Loading trainS:  38%|███▊      | 102/266 [02:18<03:39,  1.34s/it]Loading trainS:  39%|███▊      | 103/266 [02:19<04:06,  1.51s/it]Loading trainS:  39%|███▉      | 104/266 [02:21<03:44,  1.39s/it]Loading trainS:  39%|███▉      | 105/266 [02:22<03:41,  1.37s/it]Loading trainS:  40%|███▉      | 106/266 [02:23<03:31,  1.32s/it]Loading trainS:  40%|████      | 107/266 [02:25<03:37,  1.37s/it]Loading trainS:  41%|████      | 108/266 [02:26<03:36,  1.37s/it]Loading trainS:  41%|████      | 109/266 [02:27<03:22,  1.29s/it]Loading trainS:  41%|████▏     | 110/266 [02:28<03:10,  1.22s/it]Loading trainS:  42%|████▏     | 111/266 [02:30<03:24,  1.32s/it]Loading trainS:  42%|████▏     | 112/266 [02:31<03:14,  1.26s/it]Loading trainS:  42%|████▏     | 113/266 [02:32<03:17,  1.29s/it]Loading trainS:  43%|████▎     | 114/266 [02:33<03:15,  1.29s/it]Loading trainS:  43%|████▎     | 115/266 [02:35<03:20,  1.33s/it]Loading trainS:  44%|████▎     | 116/266 [02:36<03:25,  1.37s/it]Loading trainS:  44%|████▍     | 117/266 [02:37<03:11,  1.29s/it]Loading trainS:  44%|████▍     | 118/266 [02:39<03:06,  1.26s/it]Loading trainS:  45%|████▍     | 119/266 [02:40<02:58,  1.22s/it]Loading trainS:  45%|████▌     | 120/266 [02:41<03:14,  1.33s/it]Loading trainS:  45%|████▌     | 121/266 [02:43<03:17,  1.36s/it]Loading trainS:  46%|████▌     | 122/266 [02:44<03:19,  1.38s/it]Loading trainS:  46%|████▌     | 123/266 [02:46<03:20,  1.40s/it]Loading trainS:  47%|████▋     | 124/266 [02:47<03:22,  1.43s/it]Loading trainS:  47%|████▋     | 125/266 [02:49<03:22,  1.44s/it]Loading trainS:  47%|████▋     | 126/266 [02:50<03:24,  1.46s/it]Loading trainS:  48%|████▊     | 127/266 [02:52<03:20,  1.44s/it]Loading trainS:  48%|████▊     | 128/266 [02:53<03:20,  1.45s/it]Loading trainS:  48%|████▊     | 129/266 [02:54<03:10,  1.39s/it]Loading trainS:  49%|████▉     | 130/266 [02:55<03:02,  1.34s/it]Loading trainS:  49%|████▉     | 131/266 [02:57<03:01,  1.35s/it]Loading trainS:  50%|████▉     | 132/266 [02:58<02:58,  1.33s/it]Loading trainS:  50%|█████     | 133/266 [02:59<02:54,  1.31s/it]Loading trainS:  50%|█████     | 134/266 [03:00<02:42,  1.23s/it]Loading trainS:  51%|█████     | 135/266 [03:02<03:01,  1.39s/it]Loading trainS:  51%|█████     | 136/266 [03:04<03:00,  1.39s/it]Loading trainS:  52%|█████▏    | 137/266 [03:05<02:58,  1.39s/it]Loading trainS:  52%|█████▏    | 138/266 [03:06<02:38,  1.24s/it]Loading trainS:  52%|█████▏    | 139/266 [03:07<02:22,  1.12s/it]Loading trainS:  53%|█████▎    | 140/266 [03:08<02:27,  1.17s/it]Loading trainS:  53%|█████▎    | 141/266 [03:09<02:27,  1.18s/it]Loading trainS:  53%|█████▎    | 142/266 [03:10<02:17,  1.11s/it]Loading trainS:  54%|█████▍    | 143/266 [03:12<02:29,  1.22s/it]Loading trainS:  54%|█████▍    | 144/266 [03:13<02:36,  1.28s/it]Loading trainS:  55%|█████▍    | 145/266 [03:14<02:28,  1.23s/it]Loading trainS:  55%|█████▍    | 146/266 [03:15<02:31,  1.26s/it]Loading trainS:  55%|█████▌    | 147/266 [03:17<02:30,  1.26s/it]Loading trainS:  56%|█████▌    | 148/266 [03:18<02:30,  1.28s/it]Loading trainS:  56%|█████▌    | 149/266 [03:19<02:22,  1.22s/it]Loading trainS:  56%|█████▋    | 150/266 [03:20<02:19,  1.20s/it]Loading trainS:  57%|█████▋    | 151/266 [03:22<02:22,  1.24s/it]Loading trainS:  57%|█████▋    | 152/266 [03:23<02:34,  1.35s/it]Loading trainS:  58%|█████▊    | 153/266 [03:25<02:32,  1.35s/it]Loading trainS:  58%|█████▊    | 154/266 [03:26<02:18,  1.23s/it]Loading trainS:  58%|█████▊    | 155/266 [03:27<02:11,  1.19s/it]Loading trainS:  59%|█████▊    | 156/266 [03:28<02:16,  1.24s/it]Loading trainS:  59%|█████▉    | 157/266 [03:29<02:17,  1.26s/it]Loading trainS:  59%|█████▉    | 158/266 [03:31<02:21,  1.31s/it]Loading trainS:  60%|█████▉    | 159/266 [03:32<02:19,  1.30s/it]Loading trainS:  60%|██████    | 160/266 [03:33<02:14,  1.27s/it]Loading trainS:  61%|██████    | 161/266 [03:34<02:07,  1.21s/it]Loading trainS:  61%|██████    | 162/266 [03:35<02:00,  1.16s/it]Loading trainS:  61%|██████▏   | 163/266 [03:36<01:59,  1.16s/it]Loading trainS:  62%|██████▏   | 164/266 [03:38<01:55,  1.14s/it]Loading trainS:  62%|██████▏   | 165/266 [03:39<02:00,  1.19s/it]Loading trainS:  62%|██████▏   | 166/266 [03:40<02:00,  1.20s/it]Loading trainS:  63%|██████▎   | 167/266 [03:41<02:00,  1.22s/it]Loading trainS:  63%|██████▎   | 168/266 [03:43<02:05,  1.28s/it]Loading trainS:  64%|██████▎   | 169/266 [03:44<02:03,  1.27s/it]Loading trainS:  64%|██████▍   | 170/266 [03:45<02:00,  1.26s/it]Loading trainS:  64%|██████▍   | 171/266 [03:47<02:03,  1.30s/it]Loading trainS:  65%|██████▍   | 172/266 [03:48<02:04,  1.32s/it]Loading trainS:  65%|██████▌   | 173/266 [03:50<02:08,  1.39s/it]Loading trainS:  65%|██████▌   | 174/266 [03:51<02:01,  1.32s/it]Loading trainS:  66%|██████▌   | 175/266 [03:52<01:56,  1.28s/it]Loading trainS:  66%|██████▌   | 176/266 [03:53<01:50,  1.23s/it]Loading trainS:  67%|██████▋   | 177/266 [03:54<01:49,  1.23s/it]Loading trainS:  67%|██████▋   | 178/266 [03:56<01:53,  1.29s/it]Loading trainS:  67%|██████▋   | 179/266 [03:57<02:04,  1.43s/it]Loading trainS:  68%|██████▊   | 180/266 [03:59<01:56,  1.36s/it]Loading trainS:  68%|██████▊   | 181/266 [04:00<01:57,  1.39s/it]Loading trainS:  68%|██████▊   | 182/266 [04:01<01:47,  1.27s/it]Loading trainS:  69%|██████▉   | 183/266 [04:03<01:51,  1.34s/it]Loading trainS:  69%|██████▉   | 184/266 [04:04<01:49,  1.33s/it]Loading trainS:  70%|██████▉   | 185/266 [04:05<01:50,  1.36s/it]Loading trainS:  70%|██████▉   | 186/266 [04:07<01:47,  1.34s/it]Loading trainS:  70%|███████   | 187/266 [04:08<01:43,  1.31s/it]Loading trainS:  71%|███████   | 188/266 [04:09<01:45,  1.35s/it]Loading trainS:  71%|███████   | 189/266 [04:11<01:42,  1.33s/it]Loading trainS:  71%|███████▏  | 190/266 [04:12<01:37,  1.29s/it]Loading trainS:  72%|███████▏  | 191/266 [04:13<01:37,  1.30s/it]Loading trainS:  72%|███████▏  | 192/266 [04:14<01:32,  1.24s/it]Loading trainS:  73%|███████▎  | 193/266 [04:16<01:34,  1.29s/it]Loading trainS:  73%|███████▎  | 194/266 [04:17<01:35,  1.32s/it]Loading trainS:  73%|███████▎  | 195/266 [04:18<01:33,  1.32s/it]Loading trainS:  74%|███████▎  | 196/266 [04:20<01:29,  1.27s/it]Loading trainS:  74%|███████▍  | 197/266 [04:20<01:18,  1.14s/it]Loading trainS:  74%|███████▍  | 198/266 [04:22<01:27,  1.28s/it]Loading trainS:  75%|███████▍  | 199/266 [04:23<01:25,  1.27s/it]Loading trainS:  75%|███████▌  | 200/266 [04:24<01:16,  1.16s/it]Loading trainS:  76%|███████▌  | 201/266 [04:26<01:21,  1.25s/it]Loading trainS:  76%|███████▌  | 202/266 [04:27<01:21,  1.27s/it]Loading trainS:  76%|███████▋  | 203/266 [04:28<01:23,  1.32s/it]Loading trainS:  77%|███████▋  | 204/266 [04:30<01:26,  1.39s/it]Loading trainS:  77%|███████▋  | 205/266 [04:31<01:26,  1.41s/it]Loading trainS:  77%|███████▋  | 206/266 [04:33<01:25,  1.42s/it]Loading trainS:  78%|███████▊  | 207/266 [04:34<01:17,  1.32s/it]Loading trainS:  78%|███████▊  | 208/266 [04:35<01:05,  1.13s/it]Loading trainS:  79%|███████▊  | 209/266 [04:36<01:07,  1.18s/it]Loading trainS:  79%|███████▉  | 210/266 [04:37<01:09,  1.24s/it]Loading trainS:  79%|███████▉  | 211/266 [04:38<01:07,  1.23s/it]Loading trainS:  80%|███████▉  | 212/266 [04:40<01:06,  1.24s/it]Loading trainS:  80%|████████  | 213/266 [04:41<01:12,  1.37s/it]Loading trainS:  80%|████████  | 214/266 [04:43<01:11,  1.38s/it]Loading trainS:  81%|████████  | 215/266 [04:44<01:08,  1.34s/it]Loading trainS:  81%|████████  | 216/266 [04:45<01:01,  1.22s/it]Loading trainS:  82%|████████▏ | 217/266 [04:46<00:56,  1.16s/it]Loading trainS:  82%|████████▏ | 218/266 [04:47<00:59,  1.23s/it]Loading trainS:  82%|████████▏ | 219/266 [04:49<00:58,  1.24s/it]Loading trainS:  83%|████████▎ | 220/266 [04:50<00:59,  1.28s/it]Loading trainS:  83%|████████▎ | 221/266 [04:51<00:57,  1.29s/it]Loading trainS:  83%|████████▎ | 222/266 [04:53<00:58,  1.32s/it]Loading trainS:  84%|████████▍ | 223/266 [04:54<00:56,  1.32s/it]Loading trainS:  84%|████████▍ | 224/266 [04:55<00:55,  1.33s/it]Loading trainS:  85%|████████▍ | 225/266 [04:57<00:54,  1.32s/it]Loading trainS:  85%|████████▍ | 226/266 [04:58<00:53,  1.33s/it]Loading trainS:  85%|████████▌ | 227/266 [05:00<00:54,  1.39s/it]Loading trainS:  86%|████████▌ | 228/266 [05:01<00:51,  1.35s/it]Loading trainS:  86%|████████▌ | 229/266 [05:02<00:48,  1.31s/it]Loading trainS:  86%|████████▋ | 230/266 [05:03<00:48,  1.35s/it]Loading trainS:  87%|████████▋ | 231/266 [05:05<00:49,  1.40s/it]Loading trainS:  87%|████████▋ | 232/266 [05:06<00:43,  1.29s/it]Loading trainS:  88%|████████▊ | 233/266 [05:07<00:40,  1.23s/it]Loading trainS:  88%|████████▊ | 234/266 [05:08<00:40,  1.26s/it]Loading trainS:  88%|████████▊ | 235/266 [05:10<00:39,  1.29s/it]Loading trainS:  89%|████████▊ | 236/266 [05:11<00:35,  1.17s/it]Loading trainS:  89%|████████▉ | 237/266 [05:12<00:34,  1.18s/it]Loading trainS:  89%|████████▉ | 238/266 [05:13<00:33,  1.21s/it]Loading trainS:  90%|████████▉ | 239/266 [05:14<00:30,  1.14s/it]Loading trainS:  90%|█████████ | 240/266 [05:15<00:30,  1.18s/it]Loading trainS:  91%|█████████ | 241/266 [05:17<00:33,  1.33s/it]Loading trainS:  91%|█████████ | 242/266 [05:18<00:31,  1.33s/it]Loading trainS:  91%|█████████▏| 243/266 [05:20<00:32,  1.41s/it]Loading trainS:  92%|█████████▏| 244/266 [05:21<00:30,  1.40s/it]Loading trainS:  92%|█████████▏| 245/266 [05:23<00:28,  1.37s/it]Loading trainS:  92%|█████████▏| 246/266 [05:24<00:27,  1.37s/it]Loading trainS:  93%|█████████▎| 247/266 [05:26<00:27,  1.43s/it]Loading trainS:  93%|█████████▎| 248/266 [05:27<00:25,  1.43s/it]Loading trainS:  94%|█████████▎| 249/266 [05:28<00:23,  1.38s/it]Loading trainS:  94%|█████████▍| 250/266 [05:29<00:20,  1.29s/it]Loading trainS:  94%|█████████▍| 251/266 [05:31<00:19,  1.31s/it]Loading trainS:  95%|█████████▍| 252/266 [05:32<00:18,  1.34s/it]Loading trainS:  95%|█████████▌| 253/266 [05:34<00:17,  1.37s/it]Loading trainS:  95%|█████████▌| 254/266 [05:35<00:15,  1.33s/it]Loading trainS:  96%|█████████▌| 255/266 [05:36<00:12,  1.17s/it]Loading trainS:  96%|█████████▌| 256/266 [05:37<00:10,  1.08s/it]Loading trainS:  97%|█████████▋| 257/266 [05:37<00:09,  1.02s/it]Loading trainS:  97%|█████████▋| 258/266 [05:39<00:08,  1.04s/it]Loading trainS:  97%|█████████▋| 259/266 [05:40<00:07,  1.13s/it]Loading trainS:  98%|█████████▊| 260/266 [05:41<00:06,  1.12s/it]Loading trainS:  98%|█████████▊| 261/266 [05:42<00:05,  1.02s/it]Loading trainS:  98%|█████████▊| 262/266 [05:43<00:03,  1.03it/s]Loading trainS:  99%|█████████▉| 263/266 [05:44<00:03,  1.01s/it]Loading trainS:  99%|█████████▉| 264/266 [05:45<00:01,  1.00it/s]Loading trainS: 100%|█████████▉| 265/266 [05:46<00:01,  1.03s/it]Loading trainS: 100%|██████████| 266/266 [05:47<00:00,  1.01it/s]
Loading testS:   0%|          | 0/5 [00:00<?, ?it/s]Loading testS:  20%|██        | 1/5 [00:01<00:05,  1.27s/it]Loading testS:  40%|████      | 2/5 [00:02<00:03,  1.14s/it]Loading testS:  60%|██████    | 3/5 [00:03<00:02,  1.13s/it]Loading testS:  80%|████████  | 4/5 [00:04<00:01,  1.08s/it]Loading testS: 100%|██████████| 5/5 [00:05<00:00,  1.07s/it]
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.67it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.81it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  6.52it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  8.32it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:04,  8.07it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.51it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  7.05it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02,  9.21it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.93it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:01<00:02,  8.52it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:01, 10.70it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01, 11.35it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01, 11.67it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:02<00:01,  9.31it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:02<00:00, 11.51it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:02<00:00, 11.73it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.81it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  8.40it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 12.28it/s]---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 5  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
Error in label values min 0.0 max 2.0      1-THALAMUS
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 108, 116, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 108, 116, 20) 200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 108, 116, 20) 80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 108, 116, 20) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 108, 116, 20) 3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 108, 116, 20) 80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 108, 116, 20) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 54, 58, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 54, 58, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 54, 58, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 54, 58, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 54, 58, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 54, 58, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 54, 58, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 54, 58, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 54, 58, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 27, 29, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 27, 29, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 27, 29, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 27, 29, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 27, 29, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 27, 29, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 27, 29, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 27, 29, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 27, 29, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 27, 29, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 54, 58, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 58, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 54, 58, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 54, 58, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 54, 58, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 54, 58, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 54, 58, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 54, 58, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 54, 58, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 54, 58, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 108, 116, 20) 11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 108, 116, 40) 0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 108, 116, 20) 7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 108, 116, 20) 80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 108, 116, 20) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 108, 116, 20) 3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 108, 116, 20) 80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 108, 116, 20) 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 108, 116, 60) 0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 108, 116, 60) 0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 108, 116, 2)  122         dropout_5[0][0]                  
==================================================================================================
Total params: 223,162
Trainable params: 26,422
Non-trainable params: 196,740
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97286605 0.02713395]
Train on 17214 samples, validate on 320 samples
Epoch 1/300
 - 34s - loss: 0.6333 - acc: 0.9406 - mDice: 0.3807 - val_loss: 1.0012 - val_acc: 0.9765 - val_mDice: 0.5237

Epoch 00001: val_mDice improved from -inf to 0.52367, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 31s - loss: 0.1790 - acc: 0.9776 - mDice: 0.7160 - val_loss: 0.8303 - val_acc: 0.9841 - val_mDice: 0.6686

Epoch 00002: val_mDice improved from 0.52367 to 0.66860, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 30s - loss: 0.1355 - acc: 0.9803 - mDice: 0.7774 - val_loss: 0.7352 - val_acc: 0.9880 - val_mDice: 0.7462

Epoch 00003: val_mDice improved from 0.66860 to 0.74622, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 30s - loss: 0.1158 - acc: 0.9822 - mDice: 0.8074 - val_loss: 0.7495 - val_acc: 0.9904 - val_mDice: 0.7591

Epoch 00004: val_mDice improved from 0.74622 to 0.75910, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 30s - loss: 0.1064 - acc: 0.9837 - mDice: 0.8223 - val_loss: 0.6221 - val_acc: 0.9878 - val_mDice: 0.7285

Epoch 00005: val_mDice did not improve from 0.75910
Epoch 6/300
 - 30s - loss: 0.0980 - acc: 0.9850 - mDice: 0.8358 - val_loss: 0.6527 - val_acc: 0.9917 - val_mDice: 0.7782

Epoch 00006: val_mDice improved from 0.75910 to 0.77815, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 30s - loss: 0.0929 - acc: 0.9862 - mDice: 0.8442 - val_loss: 0.6836 - val_acc: 0.9920 - val_mDice: 0.7721

Epoch 00007: val_mDice did not improve from 0.77815
Epoch 8/300
 - 30s - loss: 0.0887 - acc: 0.9872 - mDice: 0.8511 - val_loss: 0.5300 - val_acc: 0.9910 - val_mDice: 0.7658

Epoch 00008: val_mDice did not improve from 0.77815
Epoch 9/300
 - 30s - loss: 0.0853 - acc: 0.9887 - mDice: 0.8564 - val_loss: 0.8088 - val_acc: 0.9901 - val_mDice: 0.7343

Epoch 00009: val_mDice did not improve from 0.77815
Epoch 10/300
 - 30s - loss: 0.0777 - acc: 0.9914 - mDice: 0.8624 - val_loss: 0.6967 - val_acc: 0.9917 - val_mDice: 0.7816

Epoch 00010: val_mDice improved from 0.77815 to 0.78163, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 30s - loss: 0.0749 - acc: 0.9919 - mDice: 0.8655 - val_loss: 0.6698 - val_acc: 0.9913 - val_mDice: 0.7466

Epoch 00011: val_mDice did not improve from 0.78163
Epoch 12/300
 - 30s - loss: 0.0727 - acc: 0.9921 - mDice: 0.8688 - val_loss: 0.7107 - val_acc: 0.9918 - val_mDice: 0.7846

Epoch 00012: val_mDice improved from 0.78163 to 0.78457, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 30s - loss: 0.0710 - acc: 0.9923 - mDice: 0.8717 - val_loss: 0.8884 - val_acc: 0.9840 - val_mDice: 0.6701

Epoch 00013: val_mDice did not improve from 0.78457
Epoch 14/300
 - 30s - loss: 0.0696 - acc: 0.9924 - mDice: 0.8739 - val_loss: 0.6291 - val_acc: 0.9922 - val_mDice: 0.7930

Epoch 00014: val_mDice improved from 0.78457 to 0.79296, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 30s - loss: 0.0674 - acc: 0.9926 - mDice: 0.8776 - val_loss: 0.5828 - val_acc: 0.9918 - val_mDice: 0.7881

Epoch 00015: val_mDice did not improve from 0.79296
Epoch 16/300
 - 30s - loss: 0.0669 - acc: 0.9927 - mDice: 0.8786 - val_loss: 0.3478 - val_acc: 0.9927 - val_mDice: 0.7994

Epoch 00016: val_mDice improved from 0.79296 to 0.79937, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 30s - loss: 0.0662 - acc: 0.9927 - mDice: 0.8797 - val_loss: 0.7367 - val_acc: 0.9918 - val_mDice: 0.7700

Epoch 00017: val_mDice did not improve from 0.79937
Epoch 18/300
 - 29s - loss: 0.0650 - acc: 0.9928 - mDice: 0.8817 - val_loss: 0.3742 - val_acc: 0.9906 - val_mDice: 0.7211

Epoch 00018: val_mDice did not improve from 0.79937
Epoch 19/300
 - 30s - loss: 0.0640 - acc: 0.9929 - mDice: 0.8835 - val_loss: 0.6620 - val_acc: 0.9921 - val_mDice: 0.7941

Epoch 00019: val_mDice did not improve from 0.79937
Epoch 20/300
 - 30s - loss: 0.0639 - acc: 0.9930 - mDice: 0.8836 - val_loss: 0.6523 - val_acc: 0.9926 - val_mDice: 0.7970

Epoch 00020: val_mDice did not improve from 0.79937
Epoch 21/300
 - 30s - loss: 0.0619 - acc: 0.9931 - mDice: 0.8871 - val_loss: 0.7365 - val_acc: 0.9920 - val_mDice: 0.7926

Epoch 00021: val_mDice did not improve from 0.79937
Epoch 22/300
 - 30s - loss: 0.0618 - acc: 0.9931 - mDice: 0.8871 - val_loss: 0.6285 - val_acc: 0.9926 - val_mDice: 0.8013

Epoch 00022: val_mDice improved from 0.79937 to 0.80128, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 23/300
 - 30s - loss: 0.0602 - acc: 0.9932 - mDice: 0.8898 - val_loss: 0.7829 - val_acc: 0.9904 - val_mDice: 0.7719

Epoch 00023: val_mDice did not improve from 0.80128
Epoch 24/300
 - 30s - loss: 0.0605 - acc: 0.9932 - mDice: 0.8893 - val_loss: 0.6227 - val_acc: 0.9921 - val_mDice: 0.7969

Epoch 00024: val_mDice did not improve from 0.80128
Epoch 25/300
 - 30s - loss: 0.0594 - acc: 0.9933 - mDice: 0.8913 - val_loss: 0.1602 - val_acc: 0.9930 - val_mDice: 0.7991

Epoch 00025: val_mDice did not improve from 0.80128
Epoch 26/300
 - 30s - loss: 0.0591 - acc: 0.9934 - mDice: 0.8918 - val_loss: 0.6511 - val_acc: 0.9928 - val_mDice: 0.8016

Epoch 00026: val_mDice improved from 0.80128 to 0.80162, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 27/300
 - 30s - loss: 0.0581 - acc: 0.9935 - mDice: 0.8935 - val_loss: 0.1292 - val_acc: 0.9920 - val_mDice: 0.7696

Epoch 00027: val_mDice did not improve from 0.80162
Epoch 28/300
 - 30s - loss: 0.0586 - acc: 0.9934 - mDice: 0.8927 - val_loss: 0.2532 - val_acc: 0.9932 - val_mDice: 0.8079

Epoch 00028: val_mDice improved from 0.80162 to 0.80795, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 29/300
 - 30s - loss: 0.0572 - acc: 0.9935 - mDice: 0.8950 - val_loss: 0.6802 - val_acc: 0.9923 - val_mDice: 0.7962

Epoch 00029: val_mDice did not improve from 0.80795
Epoch 30/300
 - 30s - loss: 0.0572 - acc: 0.9936 - mDice: 0.8951 - val_loss: 0.6390 - val_acc: 0.9925 - val_mDice: 0.8010

Epoch 00030: val_mDice did not improve from 0.80795
Epoch 31/300
 - 30s - loss: 0.0566 - acc: 0.9936 - mDice: 0.8961 - val_loss: 0.7042 - val_acc: 0.9925 - val_mDice: 0.7856

Epoch 00031: val_mDice did not improve from 0.80795
Epoch 32/300
 - 30s - loss: 0.0557 - acc: 0.9937 - mDice: 0.8976 - val_loss: 0.2136 - val_acc: 0.9923 - val_mDice: 0.7748

Epoch 00032: val_mDice did not improve from 0.80795
Epoch 33/300
 - 30s - loss: 0.0560 - acc: 0.9937 - mDice: 0.8970 - val_loss: 0.1662 - val_acc: 0.9922 - val_mDice: 0.7698

Epoch 00033: val_mDice did not improve from 0.80795
Epoch 34/300
 - 30s - loss: 0.0562 - acc: 0.9936 - mDice: 0.8968 - val_loss: 0.2692 - val_acc: 0.9917 - val_mDice: 0.7517

Epoch 00034: val_mDice did not improve from 0.80795
Epoch 35/300
 - 30s - loss: 0.0556 - acc: 0.9937 - mDice: 0.8977 - val_loss: 0.0710 - val_acc: 0.9926 - val_mDice: 0.7992

Epoch 00035: val_mDice did not improve from 0.80795
Epoch 36/300
 - 30s - loss: 0.0548 - acc: 0.9938 - mDice: 0.8992 - val_loss: 0.3491 - val_acc: 0.9927 - val_mDice: 0.8027

Epoch 00036: val_mDice did not improve from 0.80795
Epoch 37/300
 - 30s - loss: 0.0552 - acc: 0.9937 - mDice: 0.8984 - val_loss: 0.7788 - val_acc: 0.9909 - val_mDice: 0.7851

Epoch 00037: val_mDice did not improve from 0.80795
Epoch 38/300
 - 30s - loss: 0.0540 - acc: 0.9938 - mDice: 0.9005 - val_loss: 0.5615 - val_acc: 0.9929 - val_mDice: 0.8056

Epoch 00038: val_mDice did not improve from 0.80795
Epoch 39/300
 - 30s - loss: 0.0547 - acc: 0.9938 - mDice: 0.8995 - val_loss: 0.1176 - val_acc: 0.9926 - val_mDice: 0.7813

Epoch 00039: val_mDice did not improve from 0.80795
Epoch 40/300
 - 30s - loss: 0.0536 - acc: 0.9939 - mDice: 0.9012 - val_loss: 0.4133 - val_acc: 0.9921 - val_mDice: 0.7626

Epoch 00040: val_mDice did not improve from 0.80795
Epoch 41/300
 - 30s - loss: 0.0537 - acc: 0.9939 - mDice: 0.9011 - val_loss: 0.6714 - val_acc: 0.9926 - val_mDice: 0.8018

Epoch 00041: val_mDice did not improve from 0.80795
Epoch 42/300
 - 30s - loss: 0.0535 - acc: 0.9939 - mDice: 0.9015 - val_loss: 0.0888 - val_acc: 0.9918 - val_mDice: 0.7584

Epoch 00042: val_mDice did not improve from 0.80795
Epoch 43/300
 - 30s - loss: 0.0530 - acc: 0.9939 - mDice: 0.9024 - val_loss: 0.5991 - val_acc: 0.9931 - val_mDice: 0.8067

Epoch 00043: val_mDice did not improve from 0.80795
Epoch 44/300
 - 30s - loss: 0.0525 - acc: 0.9940 - mDice: 0.9033 - val_loss: 0.4548 - val_acc: 0.9930 - val_mDice: 0.8052

Epoch 00044: val_mDice did not improve from 0.80795
Epoch 45/300
 - 30s - loss: 0.0523 - acc: 0.9940 - mDice: 0.9036 - val_loss: 0.7331 - val_acc: 0.9924 - val_mDice: 0.7916

Epoch 00045: val_mDice did not improve from 0.80795
Epoch 46/300
 - 30s - loss: 0.0521 - acc: 0.9940 - mDice: 0.9039 - val_loss: 0.7101 - val_acc: 0.9919 - val_mDice: 0.7914

Epoch 00046: val_mDice did not improve from 0.80795
Epoch 47/300
 - 30s - loss: 0.0523 - acc: 0.9940 - mDice: 0.9035 - val_loss: 0.0504 - val_acc: 0.9932 - val_mDice: 0.8088

Epoch 00047: val_mDice improved from 0.80795 to 0.80880, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 48/300
 - 30s - loss: 0.0521 - acc: 0.9940 - mDice: 0.9040 - val_loss: 0.6649 - val_acc: 0.9932 - val_mDice: 0.8083

Epoch 00048: val_mDice did not improve from 0.80880
Epoch 49/300
 - 30s - loss: 0.0513 - acc: 0.9941 - mDice: 0.9054 - val_loss: 0.8233 - val_acc: 0.9890 - val_mDice: 0.7454

Epoch 00049: val_mDice did not improve from 0.80880
Epoch 50/300
 - 30s - loss: 0.0510 - acc: 0.9941 - mDice: 0.9058 - val_loss: 0.3730 - val_acc: 0.9929 - val_mDice: 0.7964

Epoch 00050: val_mDice did not improve from 0.80880
Epoch 51/300
 - 30s - loss: 0.0511 - acc: 0.9941 - mDice: 0.9057 - val_loss: 0.0757 - val_acc: 0.9922 - val_mDice: 0.7715

Epoch 00051: val_mDice did not improve from 0.80880
Epoch 52/300
 - 30s - loss: 0.0511 - acc: 0.9941 - mDice: 0.9057 - val_loss: 0.2725 - val_acc: 0.9896 - val_mDice: 0.6895

Epoch 00052: val_mDice did not improve from 0.80880
Epoch 53/300
 - 30s - loss: 0.0508 - acc: 0.9941 - mDice: 0.9062 - val_loss: 0.7957 - val_acc: 0.9898 - val_mDice: 0.7562

Epoch 00053: val_mDice did not improve from 0.80880
Epoch 54/300
 - 30s - loss: 0.0507 - acc: 0.9941 - mDice: 0.9063 - val_loss: 0.0852 - val_acc: 0.9924 - val_mDice: 0.7764

Epoch 00054: val_mDice did not improve from 0.80880
Epoch 55/300
 - 30s - loss: 0.0501 - acc: 0.9942 - mDice: 0.9075 - val_loss: 0.0691 - val_acc: 0.9926 - val_mDice: 0.7819

Epoch 00055: val_mDice did not improve from 0.80880
Epoch 56/300
 - 30s - loss: 0.0503 - acc: 0.9942 - mDice: 0.9071 - val_loss: 0.5835 - val_acc: 0.9930 - val_mDice: 0.8065

Epoch 00056: val_mDice did not improve from 0.80880
Epoch 57/300
 - 30s - loss: 0.0498 - acc: 0.9942 - mDice: 0.9080 - val_loss: 0.7406 - val_acc: 0.9921 - val_mDice: 0.7960

Epoch 00057: val_mDice did not improve from 0.80880
Epoch 58/300
 - 30s - loss: 0.0494 - acc: 0.9943 - mDice: 0.9087 - val_loss: 0.6525 - val_acc: 0.9928 - val_mDice: 0.7968

Epoch 00058: val_mDice did not improve from 0.80880
Epoch 59/300
 - 30s - loss: 0.0497 - acc: 0.9942 - mDice: 0.9081 - val_loss: 0.8021 - val_acc: 0.9899 - val_mDice: 0.7625

Epoch 00059: val_mDice did not improve from 0.80880
Epoch 60/300
 - 30s - loss: 0.0498 - acc: 0.9942 - mDice: 0.9080 - val_loss: 0.0522 - val_acc: 0.9929 - val_mDice: 0.8045

Epoch 00060: val_mDice did not improve from 0.80880
Epoch 61/300
 - 30s - loss: 0.0487 - acc: 0.9943 - mDice: 0.9098 - val_loss: 0.0843 - val_acc: 0.9920 - val_mDice: 0.7623

Epoch 00061: val_mDice did not improve from 0.80880
Epoch 62/300
 - 30s - loss: 0.0492 - acc: 0.9943 - mDice: 0.9091 - val_loss: 0.7186 - val_acc: 0.9923 - val_mDice: 0.7996

Epoch 00062: val_mDice did not improve from 0.80880
Epoch 63/300
 - 30s - loss: 0.0492 - acc: 0.9943 - mDice: 0.9090 - val_loss: 0.6619 - val_acc: 0.9927 - val_mDice: 0.8043

Epoch 00063: val_mDice did not improve from 0.80880
Epoch 64/300
 - 30s - loss: 0.0490 - acc: 0.9943 - mDice: 0.9094 - val_loss: 0.6895 - val_acc: 0.9926 - val_mDice: 0.8019

Epoch 00064: val_mDice did not improve from 0.80880
Epoch 65/300
 - 30s - loss: 0.0489 - acc: 0.9943 - mDice: 0.9095 - val_loss: 0.6602 - val_acc: 0.9925 - val_mDice: 0.8033

Epoch 00065: val_mDice did not improve from 0.80880
Epoch 66/300
 - 30s - loss: 0.0488 - acc: 0.9943 - mDice: 0.9098 - val_loss: 0.0481 - val_acc: 0.9935 - val_mDice: 0.8114

Epoch 00066: val_mDice improved from 0.80880 to 0.81136, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 67/300
 - 30s - loss: 0.0486 - acc: 0.9943 - mDice: 0.9101 - val_loss: 0.0916 - val_acc: 0.9917 - val_mDice: 0.7520

Epoch 00067: val_mDice did not improve from 0.81136
Epoch 68/300
 - 30s - loss: 0.0488 - acc: 0.9943 - mDice: 0.9097 - val_loss: 0.4562 - val_acc: 0.9921 - val_mDice: 0.7663

Epoch 00068: val_mDice did not improve from 0.81136
Epoch 69/300
 - 30s - loss: 0.0480 - acc: 0.9944 - mDice: 0.9111 - val_loss: 0.0776 - val_acc: 0.9921 - val_mDice: 0.7684

Epoch 00069: val_mDice did not improve from 0.81136
Epoch 70/300
 - 30s - loss: 0.0482 - acc: 0.9944 - mDice: 0.9109 - val_loss: 0.6971 - val_acc: 0.9930 - val_mDice: 0.8048

Epoch 00070: val_mDice did not improve from 0.81136
Epoch 71/300
 - 30s - loss: 0.0481 - acc: 0.9944 - mDice: 0.9109 - val_loss: 0.7000 - val_acc: 0.9924 - val_mDice: 0.7960

Epoch 00071: val_mDice did not improve from 0.81136
Epoch 72/300
 - 30s - loss: 0.0504 - acc: 0.9942 - mDice: 0.9069 - val_loss: 0.7398 - val_acc: 0.9923 - val_mDice: 0.7991

Epoch 00072: val_mDice did not improve from 0.81136
Epoch 73/300
 - 30s - loss: 0.0482 - acc: 0.9944 - mDice: 0.9107 - val_loss: 0.0546 - val_acc: 0.9929 - val_mDice: 0.8006

Epoch 00073: val_mDice did not improve from 0.81136
Epoch 74/300
 - 30s - loss: 0.0477 - acc: 0.9944 - mDice: 0.9117 - val_loss: 0.6147 - val_acc: 0.9929 - val_mDice: 0.8029

Epoch 00074: val_mDice did not improve from 0.81136
Epoch 75/300
 - 30s - loss: 0.0475 - acc: 0.9944 - mDice: 0.9120 - val_loss: 0.7387 - val_acc: 0.9918 - val_mDice: 0.7925

Epoch 00075: val_mDice did not improve from 0.81136
Epoch 76/300
 - 30s - loss: 0.0475 - acc: 0.9944 - mDice: 0.9120 - val_loss: 0.0601 - val_acc: 0.9930 - val_mDice: 0.7954

Epoch 00076: val_mDice did not improve from 0.81136
Epoch 77/300
 - 30s - loss: 0.0467 - acc: 0.9945 - mDice: 0.9134 - val_loss: 0.0556 - val_acc: 0.9930 - val_mDice: 0.8039

Epoch 00077: val_mDice did not improve from 0.81136
Epoch 78/300
 - 30s - loss: 0.0472 - acc: 0.9945 - mDice: 0.9126 - val_loss: 0.6978 - val_acc: 0.9930 - val_mDice: 0.8099

Epoch 00078: val_mDice did not improve from 0.81136
Epoch 79/300
 - 30s - loss: 0.0472 - acc: 0.9945 - mDice: 0.9127 - val_loss: 0.7310 - val_acc: 0.9927 - val_mDice: 0.8073

Epoch 00079: val_mDice did not improve from 0.81136
Epoch 80/300
 - 30s - loss: 0.0466 - acc: 0.9945 - mDice: 0.9137 - val_loss: 0.6451 - val_acc: 0.9929 - val_mDice: 0.7927

Epoch 00080: val_mDice did not improve from 0.81136
Epoch 81/300
 - 30s - loss: 0.0468 - acc: 0.9945 - mDice: 0.9132 - val_loss: 0.7905 - val_acc: 0.9912 - val_mDice: 0.7893

Epoch 00081: val_mDice did not improve from 0.81136
Epoch 82/300
 - 30s - loss: 0.0466 - acc: 0.9945 - mDice: 0.9136 - val_loss: 0.6500 - val_acc: 0.9929 - val_mDice: 0.7985

Epoch 00082: val_mDice did not improve from 0.81136
Epoch 83/300
 - 30s - loss: 0.0470 - acc: 0.9945 - mDice: 0.9130 - val_loss: 0.6351 - val_acc: 0.9931 - val_mDice: 0.8065

Epoch 00083: val_mDice did not improve from 0.81136
Epoch 84/300
 - 30s - loss: 0.0463 - acc: 0.9945 - mDice: 0.9141 - val_loss: 0.7318 - val_acc: 0.9923 - val_mDice: 0.8002

Epoch 00084: val_mDice did not improve from 0.81136
Epoch 85/300
 - 30s - loss: 0.0461 - acc: 0.9946 - mDice: 0.9145 - val_loss: 0.6617 - val_acc: 0.9930 - val_mDice: 0.8065

Epoch 00085: val_mDice did not improve from 0.81136
Epoch 86/300
 - 30s - loss: 0.0464 - acc: 0.9946 - mDice: 0.9140 - val_loss: 0.7327 - val_acc: 0.9922 - val_mDice: 0.7981

Epoch 00086: val_mDice did not improve from 0.81136
Epoch 87/300
 - 30s - loss: 0.0461 - acc: 0.9946 - mDice: 0.9145 - val_loss: 0.7564 - val_acc: 0.9919 - val_mDice: 0.7968

Epoch 00087: val_mDice did not improve from 0.81136
Epoch 88/300
 - 30s - loss: 0.0455 - acc: 0.9946 - mDice: 0.9156 - val_loss: 0.6640 - val_acc: 0.9932 - val_mDice: 0.8084

Epoch 00088: val_mDice did not improve from 0.81136
Epoch 89/300
 - 30s - loss: 0.0460 - acc: 0.9946 - mDice: 0.9148 - val_loss: 0.7205 - val_acc: 0.9925 - val_mDice: 0.8014

Epoch 00089: val_mDice did not improve from 0.81136
Epoch 90/300
 - 30s - loss: 0.0460 - acc: 0.9946 - mDice: 0.9147 - val_loss: 0.6641 - val_acc: 0.9931 - val_mDice: 0.8052

Epoch 00090: val_mDice did not improve from 0.81136
Epoch 91/300
 - 30s - loss: 0.0458 - acc: 0.9946 - mDice: 0.9151 - val_loss: 0.5965 - val_acc: 0.9932 - val_mDice: 0.8124

Epoch 00091: val_mDice improved from 0.81136 to 0.81241, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 92/300
 - 30s - loss: 0.0460 - acc: 0.9946 - mDice: 0.9146 - val_loss: 0.2627 - val_acc: 0.9931 - val_mDice: 0.8105

Epoch 00092: val_mDice did not improve from 0.81241
Epoch 93/300
 - 30s - loss: 0.0461 - acc: 0.9945 - mDice: 0.9145 - val_loss: 0.7259 - val_acc: 0.9930 - val_mDice: 0.8120

Epoch 00093: val_mDice did not improve from 0.81241
Epoch 94/300
 - 30s - loss: 0.0458 - acc: 0.9946 - mDice: 0.9150 - val_loss: 0.7866 - val_acc: 0.9907 - val_mDice: 0.7714

Epoch 00094: val_mDice did not improve from 0.81241
Epoch 95/300
 - 30s - loss: 0.0453 - acc: 0.9946 - mDice: 0.9160 - val_loss: 0.2006 - val_acc: 0.9931 - val_mDice: 0.7980

Epoch 00095: val_mDice did not improve from 0.81241
Epoch 96/300
 - 30s - loss: 0.0454 - acc: 0.9946 - mDice: 0.9158 - val_loss: 0.6462 - val_acc: 0.9930 - val_mDice: 0.8087

Epoch 00096: val_mDice did not improve from 0.81241
Epoch 97/300
 - 30s - loss: 0.0452 - acc: 0.9946 - mDice: 0.9161 - val_loss: 0.7167 - val_acc: 0.9930 - val_mDice: 0.8108

Epoch 00097: val_mDice did not improve from 0.81241
Epoch 98/300
 - 30s - loss: 0.0452 - acc: 0.9946 - mDice: 0.9161 - val_loss: 0.6963 - val_acc: 0.9931 - val_mDice: 0.8106

Epoch 00098: val_mDice did not improve from 0.81241
Epoch 99/300
 - 30s - loss: 0.0449 - acc: 0.9946 - mDice: 0.9166 - val_loss: 0.7556 - val_acc: 0.9919 - val_mDice: 0.7963

Epoch 00099: val_mDice did not improve from 0.81241
Epoch 100/300
 - 30s - loss: 0.0450 - acc: 0.9947 - mDice: 0.9166 - val_loss: 0.7645 - val_acc: 0.9918 - val_mDice: 0.7942

Epoch 00100: val_mDice did not improve from 0.81241
Epoch 101/300
 - 30s - loss: 0.0449 - acc: 0.9947 - mDice: 0.9166 - val_loss: 0.6890 - val_acc: 0.9928 - val_mDice: 0.8055

Epoch 00101: val_mDice did not improve from 0.81241
Epoch 102/300
 - 30s - loss: 0.0449 - acc: 0.9946 - mDice: 0.9167 - val_loss: 0.5913 - val_acc: 0.9935 - val_mDice: 0.8143

Epoch 00102: val_mDice improved from 0.81241 to 0.81430, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 103/300
 - 30s - loss: 0.0452 - acc: 0.9946 - mDice: 0.9162 - val_loss: 0.8001 - val_acc: 0.9904 - val_mDice: 0.7734

Epoch 00103: val_mDice did not improve from 0.81430
Epoch 104/300
 - 30s - loss: 0.0459 - acc: 0.9946 - mDice: 0.9150 - val_loss: 0.7429 - val_acc: 0.9928 - val_mDice: 0.8062

Epoch 00104: val_mDice did not improve from 0.81430
Epoch 105/300
 - 30s - loss: 0.0446 - acc: 0.9947 - mDice: 0.9172 - val_loss: 0.6929 - val_acc: 0.9928 - val_mDice: 0.8058

Epoch 00105: val_mDice did not improve from 0.81430
Epoch 106/300
 - 30s - loss: 0.0441 - acc: 0.9947 - mDice: 0.9181 - val_loss: 0.6399 - val_acc: 0.9932 - val_mDice: 0.8090

Epoch 00106: val_mDice did not improve from 0.81430
Epoch 107/300
 - 30s - loss: 0.0452 - acc: 0.9946 - mDice: 0.9162 - val_loss: 0.7464 - val_acc: 0.9925 - val_mDice: 0.8036

Epoch 00107: val_mDice did not improve from 0.81430
Epoch 108/300
 - 30s - loss: 0.0445 - acc: 0.9947 - mDice: 0.9174 - val_loss: 0.7394 - val_acc: 0.9929 - val_mDice: 0.8074

Epoch 00108: val_mDice did not improve from 0.81430
Epoch 109/300
 - 30s - loss: 0.0446 - acc: 0.9947 - mDice: 0.9173 - val_loss: 0.6257 - val_acc: 0.9931 - val_mDice: 0.8067

Epoch 00109: val_mDice did not improve from 0.81430
Epoch 110/300
 - 30s - loss: 0.0445 - acc: 0.9947 - mDice: 0.9174 - val_loss: 0.7303 - val_acc: 0.9928 - val_mDice: 0.8026

Epoch 00110: val_mDice did not improve from 0.81430
Epoch 111/300
 - 30s - loss: 0.0444 - acc: 0.9947 - mDice: 0.9176 - val_loss: 0.7449 - val_acc: 0.9918 - val_mDice: 0.7951

Epoch 00111: val_mDice did not improve from 0.81430
Epoch 112/300
 - 30s - loss: 0.0440 - acc: 0.9947 - mDice: 0.9183 - val_loss: 0.7150 - val_acc: 0.9926 - val_mDice: 0.7995

Epoch 00112: val_mDice did not improve from 0.81430
Epoch 113/300
 - 30s - loss: 0.0437 - acc: 0.9948 - mDice: 0.9189 - val_loss: 0.7618 - val_acc: 0.9918 - val_mDice: 0.7902

Epoch 00113: val_mDice did not improve from 0.81430
Epoch 114/300
 - 30s - loss: 0.0439 - acc: 0.9947 - mDice: 0.9185 - val_loss: 0.6279 - val_acc: 0.9931 - val_mDice: 0.8104

Epoch 00114: val_mDice did not improve from 0.81430
Epoch 115/300
 - 30s - loss: 0.0440 - acc: 0.9947 - mDice: 0.9182 - val_loss: 0.6504 - val_acc: 0.9931 - val_mDice: 0.8058

Epoch 00115: val_mDice did not improve from 0.81430
Epoch 116/300
 - 30s - loss: 0.0439 - acc: 0.9947 - mDice: 0.9184 - val_loss: 0.6014 - val_acc: 0.9935 - val_mDice: 0.8153

Epoch 00116: val_mDice improved from 0.81430 to 0.81533, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 117/300
 - 30s - loss: 0.0441 - acc: 0.9947 - mDice: 0.9181 - val_loss: 0.7505 - val_acc: 0.9924 - val_mDice: 0.8002

Epoch 00117: val_mDice did not improve from 0.81533
Epoch 118/300
 - 31s - loss: 0.0439 - acc: 0.9948 - mDice: 0.9184 - val_loss: 0.7610 - val_acc: 0.9921 - val_mDice: 0.7967

Epoch 00118: val_mDice did not improve from 0.81533
Epoch 119/300
 - 30s - loss: 0.0436 - acc: 0.9948 - mDice: 0.9190 - val_loss: 0.7291 - val_acc: 0.9928 - val_mDice: 0.8083

Epoch 00119: val_mDice did not improve from 0.81533
Epoch 120/300
 - 30s - loss: 0.0436 - acc: 0.9948 - mDice: 0.9190 - val_loss: 0.7084 - val_acc: 0.9930 - val_mDice: 0.8085

Epoch 00120: val_mDice did not improve from 0.81533
Epoch 121/300
 - 30s - loss: 0.0439 - acc: 0.9948 - mDice: 0.9185 - val_loss: 0.0640 - val_acc: 0.9924 - val_mDice: 0.7873

Epoch 00121: val_mDice did not improve from 0.81533
Epoch 122/300
 - 30s - loss: 0.0436 - acc: 0.9948 - mDice: 0.9190 - val_loss: 0.6818 - val_acc: 0.9931 - val_mDice: 0.8039

Epoch 00122: val_mDice did not improve from 0.81533
Epoch 123/300
 - 31s - loss: 0.0433 - acc: 0.9948 - mDice: 0.9194 - val_loss: 0.7309 - val_acc: 0.9919 - val_mDice: 0.7928

Epoch 00123: val_mDice did not improve from 0.81533
Epoch 124/300
 - 30s - loss: 0.0435 - acc: 0.9948 - mDice: 0.9192 - val_loss: 0.6749 - val_acc: 0.9926 - val_mDice: 0.7927

Epoch 00124: val_mDice did not improve from 0.81533
Epoch 125/300
 - 30s - loss: 0.0433 - acc: 0.9948 - mDice: 0.9195 - val_loss: 0.0546 - val_acc: 0.9931 - val_mDice: 0.8009

Epoch 00125: val_mDice did not improve from 0.81533
Epoch 126/300
 - 31s - loss: 0.0431 - acc: 0.9948 - mDice: 0.9199 - val_loss: 0.0634 - val_acc: 0.9928 - val_mDice: 0.7886

Epoch 00126: val_mDice did not improve from 0.81533
Epoch 127/300
 - 30s - loss: 0.0433 - acc: 0.9948 - mDice: 0.9195 - val_loss: 0.5564 - val_acc: 0.9931 - val_mDice: 0.8002

Epoch 00127: val_mDice did not improve from 0.81533
Epoch 128/300
 - 30s - loss: 0.0433 - acc: 0.9948 - mDice: 0.9196 - val_loss: 0.3682 - val_acc: 0.9930 - val_mDice: 0.8052

Epoch 00128: val_mDice did not improve from 0.81533
Epoch 129/300
 - 30s - loss: 0.0428 - acc: 0.9948 - mDice: 0.9204 - val_loss: 0.0484 - val_acc: 0.9935 - val_mDice: 0.8109

Epoch 00129: val_mDice did not improve from 0.81533
Epoch 130/300
 - 31s - loss: 0.0437 - acc: 0.9948 - mDice: 0.9188 - val_loss: 0.7130 - val_acc: 0.9930 - val_mDice: 0.8086

Epoch 00130: val_mDice did not improve from 0.81533
Epoch 131/300
 - 30s - loss: 0.0430 - acc: 0.9948 - mDice: 0.9200 - val_loss: 0.7134 - val_acc: 0.9931 - val_mDice: 0.8105

Epoch 00131: val_mDice did not improve from 0.81533
Epoch 132/300
 - 30s - loss: 0.0436 - acc: 0.9948 - mDice: 0.9191 - val_loss: 0.5791 - val_acc: 0.9929 - val_mDice: 0.8003

Epoch 00132: val_mDice did not improve from 0.81533
Epoch 133/300
 - 29s - loss: 0.0429 - acc: 0.9948 - mDice: 0.9202 - val_loss: 0.0529 - val_acc: 0.9932 - val_mDice: 0.8036

Epoch 00133: val_mDice did not improve from 0.81533
Epoch 134/300
 - 30s - loss: 0.0443 - acc: 0.9947 - mDice: 0.9177 - val_loss: 0.7727 - val_acc: 0.9913 - val_mDice: 0.7897

Epoch 00134: val_mDice did not improve from 0.81533
Epoch 135/300
 - 29s - loss: 0.0426 - acc: 0.9949 - mDice: 0.9207 - val_loss: 0.0491 - val_acc: 0.9933 - val_mDice: 0.8098

Epoch 00135: val_mDice did not improve from 0.81533
Epoch 136/300
 - 30s - loss: 0.0426 - acc: 0.9948 - mDice: 0.9208 - val_loss: 0.7733 - val_acc: 0.9916 - val_mDice: 0.7871

Epoch 00136: val_mDice did not improve from 0.81533
Epoch 137/300
 - 29s - loss: 0.0425 - acc: 0.9949 - mDice: 0.9209 - val_loss: 0.7222 - val_acc: 0.9929 - val_mDice: 0.8091

Epoch 00137: val_mDice did not improve from 0.81533
Epoch 138/300
 - 30s - loss: 0.0429 - acc: 0.9948 - mDice: 0.9202 - val_loss: 0.0467 - val_acc: 0.9936 - val_mDice: 0.8137

Epoch 00138: val_mDice did not improve from 0.81533
Epoch 139/300
 - 29s - loss: 0.0427 - acc: 0.9948 - mDice: 0.9207 - val_loss: 0.6613 - val_acc: 0.9932 - val_mDice: 0.8078

Epoch 00139: val_mDice did not improve from 0.81533
Epoch 140/300
 - 29s - loss: 0.0423 - acc: 0.9949 - mDice: 0.9213 - val_loss: 0.6207 - val_acc: 0.9931 - val_mDice: 0.8033

Epoch 00140: val_mDice did not improve from 0.81533
Epoch 141/300
 - 30s - loss: 0.0427 - acc: 0.9948 - mDice: 0.9206 - val_loss: 0.7506 - val_acc: 0.9925 - val_mDice: 0.8016

Epoch 00141: val_mDice did not improve from 0.81533
Epoch 142/300
 - 30s - loss: 0.0422 - acc: 0.9949 - mDice: 0.9215 - val_loss: 0.7305 - val_acc: 0.9925 - val_mDice: 0.8020

Epoch 00142: val_mDice did not improve from 0.81533
Epoch 143/300
 - 33s - loss: 0.0422 - acc: 0.9949 - mDice: 0.9215 - val_loss: 0.6938 - val_acc: 0.9929 - val_mDice: 0.8062

Epoch 00143: val_mDice did not improve from 0.81533
Epoch 144/300
 - 31s - loss: 0.0420 - acc: 0.9949 - mDice: 0.9218 - val_loss: 0.7126 - val_acc: 0.9926 - val_mDice: 0.8043

Epoch 00144: val_mDice did not improve from 0.81533
Epoch 145/300
 - 30s - loss: 0.0420 - acc: 0.9949 - mDice: 0.9218 - val_loss: 0.7388 - val_acc: 0.9927 - val_mDice: 0.8020

Epoch 00145: val_mDice did not improve from 0.81533
Epoch 146/300
 - 30s - loss: 0.0424 - acc: 0.9949 - mDice: 0.9212 - val_loss: 0.6802 - val_acc: 0.9932 - val_mDice: 0.8140

Epoch 00146: val_mDice did not improve from 0.81533
Epoch 147/300
 - 31s - loss: 0.0422 - acc: 0.9949 - mDice: 0.9214 - val_loss: 0.5462 - val_acc: 0.9934 - val_mDice: 0.8124

Epoch 00147: val_mDice did not improve from 0.81533
Epoch 148/300
 - 30s - loss: 0.0422 - acc: 0.9949 - mDice: 0.9215 - val_loss: 0.4946 - val_acc: 0.9922 - val_mDice: 0.7734

Epoch 00148: val_mDice did not improve from 0.81533
Epoch 149/300
 - 30s - loss: 0.0419 - acc: 0.9949 - mDice: 0.9220 - val_loss: 0.7213 - val_acc: 0.9929 - val_mDice: 0.8092

Epoch 00149: val_mDice did not improve from 0.81533
Epoch 150/300
 - 30s - loss: 0.0423 - acc: 0.9949 - mDice: 0.9213 - val_loss: 0.6922 - val_acc: 0.9930 - val_mDice: 0.8078

Epoch 00150: val_mDice did not improve from 0.81533
Epoch 151/300
 - 29s - loss: 0.0421 - acc: 0.9949 - mDice: 0.9217 - val_loss: 0.7032 - val_acc: 0.9931 - val_mDice: 0.8109

Epoch 00151: val_mDice did not improve from 0.81533
Epoch 152/300
 - 30s - loss: 0.0421 - acc: 0.9949 - mDice: 0.9217 - val_loss: 0.7431 - val_acc: 0.9918 - val_mDice: 0.7939

Epoch 00152: val_mDice did not improve from 0.81533
Epoch 153/300
 - 30s - loss: 0.0421 - acc: 0.9949 - mDice: 0.9216 - val_loss: 0.7166 - val_acc: 0.9930 - val_mDice: 0.8091

Epoch 00153: val_mDice did not improve from 0.81533
Epoch 154/300
 - 29s - loss: 0.0417 - acc: 0.9949 - mDice: 0.9223 - val_loss: 0.7227 - val_acc: 0.9930 - val_mDice: 0.8098

Epoch 00154: val_mDice did not improve from 0.81533
Epoch 155/300
 - 30s - loss: 0.0422 - acc: 0.9949 - mDice: 0.9216 - val_loss: 0.6800 - val_acc: 0.9934 - val_mDice: 0.8134

Epoch 00155: val_mDice did not improve from 0.81533
Epoch 156/300
 - 31s - loss: 0.0419 - acc: 0.9949 - mDice: 0.9220 - val_loss: 0.7596 - val_acc: 0.9915 - val_mDice: 0.7861

Epoch 00156: val_mDice did not improve from 0.81533
Restoring model weights from the end of the best epoch
Epoch 00156: early stopping
{'val_loss': [1.0011537354439497, 0.8303116098977625, 0.7352141800802201, 0.7494723566342145, 0.6221474851481616, 0.6526788859628141, 0.6836389787495136, 0.5299528520554304, 0.8087879677768797, 0.696743265260011, 0.6697939299046993, 0.7106982214609161, 0.8883655122481287, 0.6291389566613361, 0.5828412994742393, 0.34781721036415547, 0.7366649934556335, 0.374195100273937, 0.6620266111567616, 0.6522692138096318, 0.7365078917937353, 0.6285327840596437, 0.7829231002833694, 0.6227030070731416, 0.16015144262928516, 0.6511265331646428, 0.1291589557658881, 0.25318928773049265, 0.6802426010835916, 0.639002971118316, 0.7042146685998887, 0.21355270757339895, 0.1661565627437085, 0.2691760513698682, 0.0710473523940891, 0.3490957604954019, 0.778782376088202, 0.5614573259372264, 0.11757855117321014, 0.4132602571044117, 0.6714041240047663, 0.0888113456312567, 0.5991201986325905, 0.4548099488019943, 0.733084432198666, 0.7101312321610749, 0.05035667133051902, 0.6649493824224919, 0.8232684633694589, 0.37300851684994996, 0.07572218496352434, 0.27251747576519847, 0.7956968820653856, 0.08517267426941544, 0.06909495254512876, 0.5835362777579576, 0.7405688455328345, 0.6525322203524411, 0.8020568497013301, 0.052158706123009324, 0.08429316314868629, 0.718561853049323, 0.6619414133019745, 0.6895293006673455, 0.6601620800793171, 0.04812380520161241, 0.0915704658254981, 0.4561650862451643, 0.07761139003559947, 0.6970937638543546, 0.7000313515309244, 0.7397813372081146, 0.05464626383036375, 0.6147150787292048, 0.7386610945686698, 0.060119632398709655, 0.05563223490025848, 0.6978455752832815, 0.7310171332210302, 0.6450764134060591, 0.7905079720076174, 0.6499671631027013, 0.6350651952670887, 0.7318120772251859, 0.6616501739481464, 0.7326921947533265, 0.7564172245329246, 0.6640151358442381, 0.720484975608997, 0.6641374343307689, 0.5964652239345014, 0.26273462653625757, 0.725876257638447, 0.7865842394530773, 0.20055625645909458, 0.6461832334753126, 0.7166927556972951, 0.6962913270108402, 0.7556112634483725, 0.7644872111268342, 0.6889719958417118, 0.5913487082580104, 0.8000610859598964, 0.7429139271844178, 0.6929326582467183, 0.6399168889038265, 0.7464420333271846, 0.7393667255528271, 0.6256895371479914, 0.7302598360693082, 0.7448749182512984, 0.7150030162883922, 0.761782510438934, 0.6278773481026292, 0.6504493409302086, 0.6013738380279392, 0.7505218503065407, 0.760957362013869, 0.7291296721668914, 0.7083697001216933, 0.06399683363270015, 0.681803620653227, 0.7308626874582842, 0.6749497127020732, 0.05462456063833088, 0.06337519607041031, 0.5564025474013761, 0.36824330035597086, 0.048354132450185716, 0.7129683502716944, 0.7134158709086478, 0.5791004858911037, 0.05287124018650502, 0.7727172230370343, 0.04907596891280264, 0.773284827824682, 0.7222006403608248, 0.04672372306231409, 0.6612749809864908, 0.6206876134965569, 0.7505555783864111, 0.7305000737542287, 0.6937533247983083, 0.7126422567525879, 0.7388331614201888, 0.6801950864028186, 0.5461688243085518, 0.4945748479804024, 0.7213010269915685, 0.6921864666510373, 0.7031810109037906, 0.7430542006623, 0.7166274284245446, 0.722734238835983, 0.6799502222565934, 0.7596189130563289], 'val_acc': [0.9765375535935163, 0.9840951357036829, 0.9880250822752714, 0.990372059866786, 0.9877970851957798, 0.9916631821542978, 0.9919742345809937, 0.9910088907927275, 0.9901198782026768, 0.9917217902839184, 0.9912960063666105, 0.9918061047792435, 0.9840100686997175, 0.9921775255352259, 0.9918455109000206, 0.9927185662090778, 0.9918061122298241, 0.9905761145055294, 0.9921296425163746, 0.9925554264336824, 0.9919752310961485, 0.9925719015300274, 0.9904381725937128, 0.9920685086399317, 0.9930151458829641, 0.9928150903433561, 0.9920004140585661, 0.9931939970701933, 0.9922967553138733, 0.9924895782023668, 0.9924693703651428, 0.9923458881676197, 0.9921585619449615, 0.9917447473853827, 0.9926287587732077, 0.9927075859159231, 0.9908766839653254, 0.9928924161940813, 0.9925511889159679, 0.9920547939836979, 0.9926414899528027, 0.9918347783386707, 0.9931069388985634, 0.9930485747754574, 0.992415240034461, 0.9919318240135908, 0.9932326562702656, 0.9931899979710579, 0.9890056326985359, 0.9929440505802631, 0.9922376219183207, 0.9896179977804422, 0.9897634275257587, 0.9924144893884659, 0.9925856105983257, 0.993017390370369, 0.992137111723423, 0.9927859101444483, 0.9898647107183933, 0.9929385632276535, 0.9919814523309469, 0.9922690596431494, 0.9927342645823956, 0.9925708826631308, 0.9925364553928375, 0.9934858456254005, 0.9916831403970718, 0.9920944534242153, 0.9920904729515314, 0.9929854590445757, 0.9924199748784304, 0.9922915138304234, 0.9928994104266167, 0.9928909242153168, 0.9918402675539255, 0.9929555226117373, 0.9930263590067625, 0.992954783141613, 0.9927405249327421, 0.9928704630583525, 0.9911690391600132, 0.9928764551877975, 0.9931306317448616, 0.9923049919307232, 0.9929904490709305, 0.9922047071158886, 0.9918637257069349, 0.993229677900672, 0.9924845825880766, 0.9931201562285423, 0.9932271651923656, 0.9930725060403347, 0.9930348545312881, 0.9906616602092981, 0.9930612836033106, 0.9929916933178902, 0.9930251333862543, 0.9931436106562614, 0.9919290784746408, 0.9917754251509905, 0.9928130954504013, 0.9935015588998795, 0.990414472296834, 0.9928258210420609, 0.9927821550518274, 0.9931580852717161, 0.9924681223928928, 0.9929143711924553, 0.9930777605623007, 0.9927612114697695, 0.9918185751885176, 0.9926339983940125, 0.9917846545577049, 0.9931351374834776, 0.9930904768407345, 0.9935062862932682, 0.992410508915782, 0.9921029396355152, 0.9928482752293348, 0.9930134061723948, 0.9924376979470253, 0.9930712822824717, 0.9919400550425053, 0.9925871025770903, 0.9930587969720364, 0.9927981290966272, 0.9930904824286699, 0.9929956831037998, 0.9934638850390911, 0.9930378422141075, 0.9931234084069729, 0.9929490517824888, 0.9932194408029318, 0.9913431406021118, 0.9933478981256485, 0.991568373516202, 0.9928956627845764, 0.9935811292380095, 0.99316431209445, 0.993108443915844, 0.9925037939101458, 0.9925242625176907, 0.992926336824894, 0.9926000870764256, 0.992664186283946, 0.993176780641079, 0.993425227701664, 0.9921944718807936, 0.9929048959165812, 0.9930004365742207, 0.9930984620004892, 0.9917923826724291, 0.992951050400734, 0.9930201396346092, 0.9933902975171804, 0.9914641138166189], 'val_mDice': [0.5236655403859913, 0.6685963459312916, 0.7462249882519245, 0.7591046113520861, 0.7284942269325256, 0.7781520299613476, 0.7721399515867233, 0.7657500077039003, 0.7342748250812292, 0.7816306874155998, 0.746571971103549, 0.7845708541572094, 0.6700880592688918, 0.7929556258022785, 0.7880542520433664, 0.7993722055107355, 0.7699904777109623, 0.7210630597546697, 0.7941280025988817, 0.7969631906598806, 0.7925555389374495, 0.8012751303613186, 0.7718748319894075, 0.7969013508409262, 0.7990510109812021, 0.8016226906329393, 0.7696309313178062, 0.807949872687459, 0.7962232269346714, 0.8009920362383127, 0.7855571247637272, 0.7748457510024309, 0.7697657682001591, 0.7517100498080254, 0.7991717662662268, 0.802705567330122, 0.7850848417729139, 0.8055588603019714, 0.7813302427530289, 0.7626377418637276, 0.8017852064222097, 0.7584115862846375, 0.8066800609230995, 0.8051651157438755, 0.7915987819433212, 0.7914090156555176, 0.8087999001145363, 0.8082609437406063, 0.7454284001141787, 0.7963908091187477, 0.7714678905904293, 0.6894671311601996, 0.7562132738530636, 0.776391914114356, 0.7819049805402756, 0.8064979966729879, 0.7960218656808138, 0.7968257460743189, 0.7624699268490076, 0.8045444451272488, 0.7623469643294811, 0.7995859906077385, 0.8042633440345526, 0.8018543012440205, 0.8032987639307976, 0.811361214146018, 0.7519758958369493, 0.7663042936474085, 0.76844098046422, 0.8047866635024548, 0.7959712482988834, 0.7990698516368866, 0.8006316144019365, 0.8029110915958881, 0.792517838999629, 0.7953896280378103, 0.803905138745904, 0.8098751679062843, 0.8072782307863235, 0.7927113585174084, 0.7893020566552877, 0.7985459081828594, 0.8064793515950441, 0.8001852408051491, 0.8065434359014034, 0.7980895880609751, 0.7967865653336048, 0.8084158692508936, 0.8014494832605124, 0.8052048459649086, 0.8124099019914865, 0.8105183020234108, 0.8120117429643869, 0.7714306004345417, 0.7979883719235659, 0.8086873590946198, 0.8107552211731672, 0.8106444031000137, 0.7963108830153942, 0.7942459546029568, 0.8055458404123783, 0.8142956160008907, 0.7734446506947279, 0.8062359411269426, 0.8058018237352371, 0.8090332522988319, 0.8035847451537848, 0.8074383623898029, 0.8066536393016577, 0.8025613240897655, 0.7951065991073847, 0.7994960993528366, 0.7902249414473772, 0.8103785756975412, 0.8057720772922039, 0.8153309486806393, 0.8001568540930748, 0.796681409701705, 0.8082604687660933, 0.8084792457520962, 0.787344928830862, 0.8038695901632309, 0.792847815901041, 0.7927262783050537, 0.8008769247680902, 0.7886101398617029, 0.8001537248492241, 0.8052374981343746, 0.8109445869922638, 0.8085683919489384, 0.810511726886034, 0.8002783451229334, 0.8035898767411709, 0.789705878123641, 0.809828108176589, 0.7871289364993572, 0.8091063424944878, 0.8137359376996756, 0.8077861275523901, 0.8033206686377525, 0.8016013354063034, 0.80201156437397, 0.8061995171010494, 0.8042931836098433, 0.8020276669412851, 0.8139718603342772, 0.8124157786369324, 0.7734012138098478, 0.809176554903388, 0.8078162185847759, 0.810868488624692, 0.7939009554684162, 0.8090933784842491, 0.8098481502383947, 0.8133508544415236, 0.7861329708248377], 'loss': [0.6333124553688425, 0.17896133433260042, 0.1354511601782654, 0.11584208164274505, 0.10636186771907637, 0.09802733480660249, 0.09285345854004169, 0.08869506265659483, 0.08527192233801857, 0.07768590602709106, 0.07487947899431416, 0.07272455403504435, 0.07095137518927225, 0.0695983409008159, 0.06744008857518369, 0.06685393565446156, 0.06617399014595758, 0.06499942235992293, 0.06395190760867236, 0.06385927949504555, 0.06185517641286672, 0.06183628066361428, 0.060249592461825055, 0.060539713503142134, 0.059384812759864174, 0.0590742499552095, 0.05810004371538995, 0.058559646201723055, 0.05720167245879896, 0.057167160363598014, 0.05657497299067911, 0.055713404109371485, 0.056038842375607835, 0.05619661004109514, 0.0556409310891859, 0.054828384518277096, 0.05524314007289778, 0.05403887522394432, 0.05465270441959956, 0.05364997126270257, 0.05372154568720739, 0.05347160850530913, 0.05296527209506781, 0.05247393174462026, 0.05229754426581624, 0.05210791103670832, 0.052332004033391784, 0.05207026882985057, 0.051278696250569966, 0.05101607065676839, 0.05106469782021066, 0.05110295810280631, 0.050778572488391356, 0.05072246987489066, 0.05008215292123077, 0.05029099814760861, 0.04979813326528031, 0.04939951480129212, 0.049705268237560184, 0.049793327959784375, 0.04873311855491894, 0.04918101222661296, 0.049227171286332895, 0.04898291603475203, 0.04890631720600289, 0.04879261646646994, 0.04858617668431908, 0.04882133076452407, 0.048038986488480775, 0.048164317947245926, 0.04813071751026336, 0.050411677129321694, 0.048240777554794015, 0.04770640684918229, 0.04750872489644479, 0.047500976203030044, 0.046740412132117035, 0.04718986708608961, 0.04715849129534826, 0.04657849249858169, 0.046834641646633195, 0.046605093526489796, 0.04695202463046902, 0.04632999515523406, 0.04611718708713552, 0.046371160586446476, 0.04613391639353354, 0.04551677888407966, 0.04597390121327497, 0.046027572422378274, 0.045780792863537687, 0.046049393552464866, 0.04608739850962773, 0.045840912338930985, 0.045263329823579855, 0.045398779229010054, 0.04519400749806987, 0.04522479039871057, 0.04491838827846952, 0.04495031948978164, 0.04492975763766223, 0.044884734258031446, 0.04515129548253062, 0.04585644158744515, 0.044576861871274645, 0.044072899614466504, 0.04516335175006602, 0.04448929796562567, 0.0445647381161257, 0.04448259065337362, 0.04436429055279745, 0.04400839068409325, 0.043665429426826115, 0.04388321180987735, 0.0440255613951916, 0.043938268330309595, 0.04407274433387528, 0.043931075323001285, 0.04357113941583752, 0.043573607157937906, 0.04386621663301224, 0.04356933484249751, 0.04333600160580653, 0.043464455163197, 0.04329243077278359, 0.043090345609149296, 0.04332427946763877, 0.043259738619963344, 0.042805333566290654, 0.043686824024374564, 0.0430370190740151, 0.04355652149053827, 0.04292263617180526, 0.04433813264031464, 0.042646981593543014, 0.04255718865154948, 0.04253768507208131, 0.042902387707622204, 0.042651839237917696, 0.04229389581505992, 0.04267371803339459, 0.04219152293367864, 0.04218254279008972, 0.04202032901508559, 0.0420174505475026, 0.042371202605214146, 0.042222960355532656, 0.04218720673884583, 0.041907310951988054, 0.0423215181680715, 0.04208341725231207, 0.04209513062022802, 0.04212311305628534, 0.04174625031512429, 0.042158375110594504, 0.041911131462688864], 'acc': [0.9405915234941243, 0.9775792049713441, 0.9803046395834888, 0.9822451057951528, 0.9836628622982135, 0.9850420162862528, 0.9861985096896001, 0.9872223525508793, 0.9887005052417499, 0.9913826573389505, 0.9918819746863652, 0.9921075828235795, 0.9922837646799496, 0.9923832965905456, 0.9925748710503793, 0.9926503790966431, 0.9927057765343746, 0.9928260062496269, 0.9929122313730695, 0.9929539317506884, 0.9930944220521412, 0.9931132237268849, 0.9932478481265911, 0.9932433730552902, 0.9933350032057595, 0.9933869298207741, 0.99345970123338, 0.9934207707508469, 0.9935471415796719, 0.9935562582994928, 0.9936038703609319, 0.9936942963687693, 0.9936628786060776, 0.9936328373180251, 0.993693048902487, 0.9937932781534936, 0.9937220765099205, 0.9938475128955316, 0.9937819404387095, 0.9939001153137843, 0.9938670328869226, 0.9939048208743836, 0.9939461739702868, 0.9939831176036269, 0.99402417261398, 0.9940149066990311, 0.9940132775885089, 0.9940193957175557, 0.9940946450753676, 0.9941237277653321, 0.9941122007242572, 0.9941271048701847, 0.9941410167757139, 0.9941407008856393, 0.9942035165151071, 0.9941888048256318, 0.99423265084581, 0.9942593752292165, 0.9942232714763596, 0.9942425197323427, 0.9943222481295583, 0.9942673357075704, 0.99427141301984, 0.9943067514690024, 0.994316896169848, 0.9943140632698757, 0.9943319812280259, 0.9943268013025419, 0.9943922144327622, 0.9943749934756909, 0.9943955134220817, 0.9941749586742681, 0.9943638791103901, 0.9943993280293205, 0.9944456436291408, 0.9944458973107194, 0.9944716452776631, 0.9944691801924344, 0.9944591077692323, 0.9944995432500018, 0.9944877636353702, 0.9945207769078246, 0.9945013846367151, 0.994531926819848, 0.9945586461825309, 0.9945541486322388, 0.9945552249853379, 0.9946038160116897, 0.9945637661294127, 0.994558449661024, 0.9945567496786608, 0.994556261650483, 0.9945420727256672, 0.9945822485900166, 0.9946253871798613, 0.9946134378439987, 0.9946196274196726, 0.9946471792667935, 0.9946387881696384, 0.9946590044626697, 0.9946768526570008, 0.9946471378060048, 0.994646260287408, 0.9946032830601552, 0.9946814374224544, 0.9947254952617648, 0.994639282811321, 0.9946940598399766, 0.994682613871468, 0.9946884261103365, 0.9947021326371099, 0.9947457393245912, 0.9947641115439566, 0.9947497174689146, 0.9947338308955065, 0.9947424791645086, 0.9947128364457283, 0.9947544703351173, 0.994773887176609, 0.9947696902949428, 0.994752821294054, 0.9947660785664855, 0.9948057007108179, 0.9947692367608669, 0.9947955638284507, 0.9948174608727428, 0.9947891219285248, 0.9948009791323792, 0.9948277604888787, 0.9947514708025248, 0.9948261124796606, 0.9947908203319569, 0.9948357037582699, 0.9946993601727987, 0.994850279237247, 0.9948474944946698, 0.994869283112109, 0.9948336289044497, 0.9948446325091268, 0.994881704859968, 0.9948276592156912, 0.9948809133515591, 0.9948915905122545, 0.9949020596626427, 0.9948831762366696, 0.9948940450228008, 0.9948837934324823, 0.9948723008162582, 0.9948952808133038, 0.9948822912389259, 0.9948973880906103, 0.9949018300112856, 0.9949022740440749, 0.9949317588420561, 0.9948907248633406, 0.9949198258633645], 'mDice': [0.38072572241500374, 0.7160056887138897, 0.7773619281424314, 0.8073824864862078, 0.8223040312566698, 0.8357813499233401, 0.8442328446789792, 0.851094417238507, 0.8563947061898471, 0.862356822637782, 0.8654978413871042, 0.8688478542354806, 0.8717395185773292, 0.873943583176113, 0.8775799355607173, 0.8785877103546265, 0.8796856708887827, 0.8816660350244663, 0.8834540449092374, 0.8836344735844287, 0.8870511910039206, 0.8870562124615197, 0.8897868602744264, 0.8893238839973511, 0.8912760458009727, 0.8918026859327879, 0.8934556509236004, 0.892696120631782, 0.8950472207965232, 0.8950937616225387, 0.8961362003504475, 0.8976121092695828, 0.8970338704002379, 0.8967880347166464, 0.8977305385118247, 0.8991786602746461, 0.898424465017506, 0.9005217102466733, 0.8994642651439807, 0.9012152490486206, 0.9010706375918627, 0.9015353542663944, 0.902415061490079, 0.9032554987749184, 0.9035594809605184, 0.9039026743321105, 0.9035157804720713, 0.9039780888959646, 0.9053643594098947, 0.9058202384337324, 0.905733158312235, 0.9056695495608017, 0.9062472856445042, 0.9063452795932168, 0.9074739936933542, 0.9070914042069409, 0.9079641056792085, 0.9086646628917212, 0.9081428519549569, 0.9079854155966279, 0.9098425172853652, 0.9090737308222644, 0.9089790179683201, 0.9094124290604368, 0.9095472090679468, 0.9097587667692133, 0.910126069939149, 0.9097158469305618, 0.9110805693577984, 0.9108744271820647, 0.910913636089687, 0.9068976397836778, 0.9107343527834992, 0.9116760936849303, 0.9120168016944957, 0.9120252359144722, 0.9133776179503463, 0.912590903986258, 0.9126510601073063, 0.9136663526002298, 0.9132194205334312, 0.913616977087557, 0.9130071668213802, 0.9141094988337292, 0.9144795948417258, 0.9140435375305257, 0.9144680003567525, 0.9155625891253357, 0.9147544475165175, 0.9146503018656993, 0.9150884461150818, 0.9146213191954727, 0.9145448900922827, 0.9149875593708965, 0.9160159092422034, 0.9157761699288817, 0.9161341801481379, 0.9160958519516, 0.9166285066747549, 0.9165722625075808, 0.9166038919301264, 0.9166940264659185, 0.9162241155239463, 0.914963771355918, 0.91723264058708, 0.9181397653933503, 0.9162042884858793, 0.9173945607008301, 0.9172722316998783, 0.9174096393601825, 0.9176214322252142, 0.9182686611890544, 0.9188648061745671, 0.9184707712044045, 0.9182294826412278, 0.9183729624338262, 0.9181441754514752, 0.9183894484746992, 0.9190249122974418, 0.919029548655158, 0.9185161352282245, 0.9190453229097867, 0.9194422533208241, 0.9192259725868405, 0.9195353732273057, 0.9198919372565796, 0.9194823379672833, 0.9195893774731201, 0.9204037090177194, 0.9188379376236814, 0.9199883035975244, 0.9190608928313554, 0.920201254386831, 0.9177341621775542, 0.9206957705790703, 0.9208420685211014, 0.9208878149578515, 0.9202345705301044, 0.9206879521352538, 0.9213303615784582, 0.9206367690859321, 0.9214992481642544, 0.9215172356992452, 0.9218081302020668, 0.9218187853200546, 0.9211765702723405, 0.9214375589704685, 0.9215060575465174, 0.9220117035817363, 0.9212685791654178, 0.9216961585659591, 0.9216778415330018, 0.9216319859422595, 0.9222975575897604, 0.9215581104483105, 0.9220111869596723]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:00<00:03,  1.05it/s]predicting test subjects:  40%|████      | 2/5 [00:01<00:02,  1.32it/s]predicting test subjects:  60%|██████    | 3/5 [00:01<00:01,  1.63it/s]predicting test subjects:  80%|████████  | 4/5 [00:01<00:00,  1.90it/s]predicting test subjects: 100%|██████████| 5/5 [00:02<00:00,  2.17it/s]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:00<01:58,  2.23it/s]predicting train subjects:   1%|          | 2/266 [00:00<01:56,  2.26it/s]predicting train subjects:   1%|          | 3/266 [00:01<01:51,  2.36it/s]predicting train subjects:   2%|▏         | 4/266 [00:01<01:54,  2.29it/s]predicting train subjects:   2%|▏         | 5/266 [00:02<01:47,  2.43it/s]predicting train subjects:   2%|▏         | 6/266 [00:02<01:43,  2.50it/s]predicting train subjects:   3%|▎         | 7/266 [00:02<01:38,  2.63it/s]predicting train subjects:   3%|▎         | 8/266 [00:03<01:38,  2.62it/s]predicting train subjects:   3%|▎         | 9/266 [00:03<01:40,  2.55it/s]predicting train subjects:   4%|▍         | 10/266 [00:03<01:38,  2.59it/s]predicting train subjects:   4%|▍         | 11/266 [00:04<01:38,  2.58it/s]predicting train subjects:   5%|▍         | 12/266 [00:04<01:41,  2.50it/s]predicting train subjects:   5%|▍         | 13/266 [00:05<01:40,  2.52it/s]predicting train subjects:   5%|▌         | 14/266 [00:05<01:37,  2.58it/s]predicting train subjects:   6%|▌         | 15/266 [00:05<01:37,  2.58it/s]predicting train subjects:   6%|▌         | 16/266 [00:06<01:36,  2.58it/s]predicting train subjects:   6%|▋         | 17/266 [00:06<01:38,  2.54it/s]predicting train subjects:   7%|▋         | 18/266 [00:07<01:34,  2.61it/s]predicting train subjects:   7%|▋         | 19/266 [00:07<01:33,  2.65it/s]predicting train subjects:   8%|▊         | 20/266 [00:07<01:31,  2.70it/s]predicting train subjects:   8%|▊         | 21/266 [00:08<01:31,  2.68it/s]predicting train subjects:   8%|▊         | 22/266 [00:08<01:29,  2.73it/s]predicting train subjects:   9%|▊         | 23/266 [00:08<01:27,  2.79it/s]predicting train subjects:   9%|▉         | 24/266 [00:09<01:30,  2.67it/s]predicting train subjects:   9%|▉         | 25/266 [00:09<01:30,  2.65it/s]predicting train subjects:  10%|▉         | 26/266 [00:10<01:35,  2.51it/s]predicting train subjects:  10%|█         | 27/266 [00:10<01:34,  2.53it/s]predicting train subjects:  11%|█         | 28/266 [00:10<01:29,  2.66it/s]predicting train subjects:  11%|█         | 29/266 [00:11<01:26,  2.74it/s]predicting train subjects:  11%|█▏        | 30/266 [00:11<01:26,  2.74it/s]predicting train subjects:  12%|█▏        | 31/266 [00:11<01:28,  2.64it/s]predicting train subjects:  12%|█▏        | 32/266 [00:12<01:28,  2.66it/s]predicting train subjects:  12%|█▏        | 33/266 [00:12<01:26,  2.69it/s]predicting train subjects:  13%|█▎        | 34/266 [00:13<01:27,  2.65it/s]predicting train subjects:  13%|█▎        | 35/266 [00:13<01:25,  2.70it/s]predicting train subjects:  14%|█▎        | 36/266 [00:13<01:24,  2.72it/s]predicting train subjects:  14%|█▍        | 37/266 [00:14<01:26,  2.66it/s]predicting train subjects:  14%|█▍        | 38/266 [00:14<01:28,  2.57it/s]predicting train subjects:  15%|█▍        | 39/266 [00:14<01:27,  2.59it/s]predicting train subjects:  15%|█▌        | 40/266 [00:15<01:30,  2.50it/s]predicting train subjects:  15%|█▌        | 41/266 [00:15<01:31,  2.46it/s]predicting train subjects:  16%|█▌        | 42/266 [00:16<01:39,  2.25it/s]predicting train subjects:  16%|█▌        | 43/266 [00:16<01:40,  2.21it/s]predicting train subjects:  17%|█▋        | 44/266 [00:17<01:35,  2.32it/s]predicting train subjects:  17%|█▋        | 45/266 [00:17<01:33,  2.36it/s]predicting train subjects:  17%|█▋        | 46/266 [00:17<01:30,  2.44it/s]predicting train subjects:  18%|█▊        | 47/266 [00:18<01:26,  2.53it/s]predicting train subjects:  18%|█▊        | 48/266 [00:18<01:33,  2.34it/s]predicting train subjects:  18%|█▊        | 49/266 [00:19<01:35,  2.28it/s]predicting train subjects:  19%|█▉        | 50/266 [00:19<01:31,  2.37it/s]predicting train subjects:  19%|█▉        | 51/266 [00:20<01:30,  2.37it/s]predicting train subjects:  20%|█▉        | 52/266 [00:20<01:29,  2.38it/s]predicting train subjects:  20%|█▉        | 53/266 [00:20<01:26,  2.47it/s]predicting train subjects:  20%|██        | 54/266 [00:21<01:26,  2.44it/s]predicting train subjects:  21%|██        | 55/266 [00:21<01:28,  2.38it/s]predicting train subjects:  21%|██        | 56/266 [00:22<01:23,  2.51it/s]predicting train subjects:  21%|██▏       | 57/266 [00:22<01:21,  2.57it/s]predicting train subjects:  22%|██▏       | 58/266 [00:22<01:22,  2.53it/s]predicting train subjects:  22%|██▏       | 59/266 [00:23<01:23,  2.48it/s]predicting train subjects:  23%|██▎       | 60/266 [00:23<01:24,  2.43it/s]predicting train subjects:  23%|██▎       | 61/266 [00:24<01:23,  2.46it/s]predicting train subjects:  23%|██▎       | 62/266 [00:24<01:28,  2.32it/s]predicting train subjects:  24%|██▎       | 63/266 [00:25<01:29,  2.27it/s]predicting train subjects:  24%|██▍       | 64/266 [00:25<01:30,  2.23it/s]predicting train subjects:  24%|██▍       | 65/266 [00:25<01:28,  2.28it/s]predicting train subjects:  25%|██▍       | 66/266 [00:26<01:28,  2.27it/s]predicting train subjects:  25%|██▌       | 67/266 [00:26<01:20,  2.46it/s]predicting train subjects:  26%|██▌       | 68/266 [00:27<01:28,  2.25it/s]predicting train subjects:  26%|██▌       | 69/266 [00:27<01:27,  2.26it/s]predicting train subjects:  26%|██▋       | 70/266 [00:28<01:23,  2.35it/s]predicting train subjects:  27%|██▋       | 71/266 [00:28<01:22,  2.38it/s]predicting train subjects:  27%|██▋       | 72/266 [00:28<01:21,  2.38it/s]predicting train subjects:  27%|██▋       | 73/266 [00:29<01:23,  2.32it/s]predicting train subjects:  28%|██▊       | 74/266 [00:29<01:23,  2.31it/s]predicting train subjects:  28%|██▊       | 75/266 [00:30<01:24,  2.25it/s]predicting train subjects:  29%|██▊       | 76/266 [00:30<01:23,  2.27it/s]predicting train subjects:  29%|██▉       | 77/266 [00:31<01:21,  2.33it/s]predicting train subjects:  29%|██▉       | 78/266 [00:31<01:25,  2.21it/s]predicting train subjects:  30%|██▉       | 79/266 [00:32<01:25,  2.18it/s]predicting train subjects:  30%|███       | 80/266 [00:32<01:26,  2.14it/s]predicting train subjects:  30%|███       | 81/266 [00:32<01:21,  2.27it/s]predicting train subjects:  31%|███       | 82/266 [00:33<01:23,  2.20it/s]predicting train subjects:  31%|███       | 83/266 [00:33<01:20,  2.26it/s]predicting train subjects:  32%|███▏      | 84/266 [00:34<01:22,  2.20it/s]predicting train subjects:  32%|███▏      | 85/266 [00:34<01:22,  2.18it/s]predicting train subjects:  32%|███▏      | 86/266 [00:35<01:17,  2.32it/s]predicting train subjects:  33%|███▎      | 87/266 [00:35<01:16,  2.34it/s]predicting train subjects:  33%|███▎      | 88/266 [00:36<01:13,  2.41it/s]predicting train subjects:  33%|███▎      | 89/266 [00:36<01:15,  2.36it/s]predicting train subjects:  34%|███▍      | 90/266 [00:36<01:15,  2.34it/s]predicting train subjects:  34%|███▍      | 91/266 [00:37<01:15,  2.32it/s]predicting train subjects:  35%|███▍      | 92/266 [00:37<01:18,  2.21it/s]predicting train subjects:  35%|███▍      | 93/266 [00:38<01:17,  2.22it/s]predicting train subjects:  35%|███▌      | 94/266 [00:38<01:21,  2.11it/s]predicting train subjects:  36%|███▌      | 95/266 [00:39<01:21,  2.10it/s]predicting train subjects:  36%|███▌      | 96/266 [00:39<01:20,  2.10it/s]predicting train subjects:  36%|███▋      | 97/266 [00:40<01:21,  2.08it/s]predicting train subjects:  37%|███▋      | 98/266 [00:40<01:18,  2.15it/s]predicting train subjects:  37%|███▋      | 99/266 [00:41<01:18,  2.12it/s]predicting train subjects:  38%|███▊      | 100/266 [00:41<01:12,  2.30it/s]predicting train subjects:  38%|███▊      | 101/266 [00:41<01:12,  2.29it/s]predicting train subjects:  38%|███▊      | 102/266 [00:42<01:13,  2.24it/s]predicting train subjects:  39%|███▊      | 103/266 [00:42<01:09,  2.36it/s]predicting train subjects:  39%|███▉      | 104/266 [00:43<01:03,  2.54it/s]predicting train subjects:  39%|███▉      | 105/266 [00:43<00:59,  2.70it/s]predicting train subjects:  40%|███▉      | 106/266 [00:43<01:00,  2.65it/s]predicting train subjects:  40%|████      | 107/266 [00:44<01:04,  2.46it/s]predicting train subjects:  41%|████      | 108/266 [00:44<01:05,  2.41it/s]predicting train subjects:  41%|████      | 109/266 [00:45<01:07,  2.34it/s]predicting train subjects:  41%|████▏     | 110/266 [00:45<01:07,  2.30it/s]predicting train subjects:  42%|████▏     | 111/266 [00:45<01:03,  2.45it/s]predicting train subjects:  42%|████▏     | 112/266 [00:46<00:59,  2.61it/s]predicting train subjects:  42%|████▏     | 113/266 [00:46<01:00,  2.53it/s]predicting train subjects:  43%|████▎     | 114/266 [00:47<01:03,  2.39it/s]predicting train subjects:  43%|████▎     | 115/266 [00:47<01:07,  2.22it/s]predicting train subjects:  44%|████▎     | 116/266 [00:48<01:03,  2.36it/s]predicting train subjects:  44%|████▍     | 117/266 [00:48<01:00,  2.45it/s]predicting train subjects:  44%|████▍     | 118/266 [00:48<00:58,  2.52it/s]predicting train subjects:  45%|████▍     | 119/266 [00:49<01:00,  2.43it/s]predicting train subjects:  45%|████▌     | 120/266 [00:49<01:02,  2.35it/s]predicting train subjects:  45%|████▌     | 121/266 [00:50<01:02,  2.30it/s]predicting train subjects:  46%|████▌     | 122/266 [00:50<01:01,  2.35it/s]predicting train subjects:  46%|████▌     | 123/266 [00:51<01:01,  2.32it/s]predicting train subjects:  47%|████▋     | 124/266 [00:51<01:03,  2.25it/s]predicting train subjects:  47%|████▋     | 125/266 [00:51<01:03,  2.24it/s]predicting train subjects:  47%|████▋     | 126/266 [00:52<01:00,  2.30it/s]predicting train subjects:  48%|████▊     | 127/266 [00:52<01:03,  2.17it/s]predicting train subjects:  48%|████▊     | 128/266 [00:53<01:04,  2.14it/s]predicting train subjects:  48%|████▊     | 129/266 [00:53<01:02,  2.19it/s]predicting train subjects:  49%|████▉     | 130/266 [00:54<01:04,  2.11it/s]predicting train subjects:  49%|████▉     | 131/266 [00:54<01:05,  2.05it/s]predicting train subjects:  50%|████▉     | 132/266 [00:55<01:06,  2.03it/s]predicting train subjects:  50%|█████     | 133/266 [00:55<01:03,  2.09it/s]predicting train subjects:  50%|█████     | 134/266 [00:56<01:06,  1.99it/s]predicting train subjects:  51%|█████     | 135/266 [00:56<01:06,  1.98it/s]predicting train subjects:  51%|█████     | 136/266 [00:57<01:02,  2.07it/s]predicting train subjects:  52%|█████▏    | 137/266 [00:57<00:59,  2.17it/s]predicting train subjects:  52%|█████▏    | 138/266 [00:58<00:58,  2.18it/s]predicting train subjects:  52%|█████▏    | 139/266 [00:58<00:56,  2.24it/s]predicting train subjects:  53%|█████▎    | 140/266 [00:59<00:55,  2.25it/s]predicting train subjects:  53%|█████▎    | 141/266 [00:59<00:53,  2.32it/s]predicting train subjects:  53%|█████▎    | 142/266 [00:59<00:53,  2.31it/s]predicting train subjects:  54%|█████▍    | 143/266 [01:00<00:54,  2.27it/s]predicting train subjects:  54%|█████▍    | 144/266 [01:00<00:54,  2.24it/s]predicting train subjects:  55%|█████▍    | 145/266 [01:01<00:54,  2.22it/s]predicting train subjects:  55%|█████▍    | 146/266 [01:01<00:50,  2.40it/s]predicting train subjects:  55%|█████▌    | 147/266 [01:01<00:49,  2.42it/s]predicting train subjects:  56%|█████▌    | 148/266 [01:02<00:49,  2.39it/s]predicting train subjects:  56%|█████▌    | 149/266 [01:02<00:50,  2.33it/s]predicting train subjects:  56%|█████▋    | 150/266 [01:03<00:49,  2.34it/s]predicting train subjects:  57%|█████▋    | 151/266 [01:03<00:49,  2.31it/s]predicting train subjects:  57%|█████▋    | 152/266 [01:04<00:49,  2.32it/s]predicting train subjects:  58%|█████▊    | 153/266 [01:04<00:48,  2.35it/s]predicting train subjects:  58%|█████▊    | 154/266 [01:05<00:48,  2.30it/s]predicting train subjects:  58%|█████▊    | 155/266 [01:05<00:45,  2.45it/s]predicting train subjects:  59%|█████▊    | 156/266 [01:05<00:44,  2.48it/s]predicting train subjects:  59%|█████▉    | 157/266 [01:06<00:41,  2.65it/s]predicting train subjects:  59%|█████▉    | 158/266 [01:06<00:41,  2.63it/s]predicting train subjects:  60%|█████▉    | 159/266 [01:06<00:42,  2.53it/s]predicting train subjects:  60%|██████    | 160/266 [01:07<00:42,  2.51it/s]predicting train subjects:  61%|██████    | 161/266 [01:07<00:39,  2.69it/s]predicting train subjects:  61%|██████    | 162/266 [01:08<00:40,  2.56it/s]predicting train subjects:  61%|██████▏   | 163/266 [01:08<00:39,  2.58it/s]predicting train subjects:  62%|██████▏   | 164/266 [01:08<00:34,  2.97it/s]predicting train subjects:  62%|██████▏   | 165/266 [01:09<00:34,  2.95it/s]predicting train subjects:  62%|██████▏   | 166/266 [01:09<00:34,  2.87it/s]predicting train subjects:  63%|██████▎   | 167/266 [01:09<00:31,  3.11it/s]predicting train subjects:  63%|██████▎   | 168/266 [01:10<00:35,  2.73it/s]predicting train subjects:  64%|██████▎   | 169/266 [01:10<00:33,  2.88it/s]predicting train subjects:  64%|██████▍   | 170/266 [01:10<00:32,  2.96it/s]predicting train subjects:  64%|██████▍   | 171/266 [01:11<00:34,  2.76it/s]predicting train subjects:  65%|██████▍   | 172/266 [01:11<00:33,  2.85it/s]predicting train subjects:  65%|██████▌   | 173/266 [01:11<00:31,  2.98it/s]predicting train subjects:  65%|██████▌   | 174/266 [01:12<00:32,  2.85it/s]predicting train subjects:  66%|██████▌   | 175/266 [01:12<00:32,  2.76it/s]predicting train subjects:  66%|██████▌   | 176/266 [01:12<00:30,  2.91it/s]predicting train subjects:  67%|██████▋   | 177/266 [01:13<00:33,  2.68it/s]predicting train subjects:  67%|██████▋   | 178/266 [01:13<00:34,  2.58it/s]predicting train subjects:  67%|██████▋   | 179/266 [01:14<00:31,  2.75it/s]predicting train subjects:  68%|██████▊   | 180/266 [01:14<00:32,  2.65it/s]predicting train subjects:  68%|██████▊   | 181/266 [01:14<00:31,  2.70it/s]predicting train subjects:  68%|██████▊   | 182/266 [01:15<00:32,  2.62it/s]predicting train subjects:  69%|██████▉   | 183/266 [01:15<00:29,  2.81it/s]predicting train subjects:  69%|██████▉   | 184/266 [01:15<00:29,  2.77it/s]predicting train subjects:  70%|██████▉   | 185/266 [01:16<00:32,  2.52it/s]predicting train subjects:  70%|██████▉   | 186/266 [01:16<00:31,  2.51it/s]predicting train subjects:  70%|███████   | 187/266 [01:17<00:30,  2.61it/s]predicting train subjects:  71%|███████   | 188/266 [01:17<00:29,  2.61it/s]predicting train subjects:  71%|███████   | 189/266 [01:17<00:30,  2.49it/s]predicting train subjects:  71%|███████▏  | 190/266 [01:18<00:31,  2.43it/s]predicting train subjects:  72%|███████▏  | 191/266 [01:18<00:30,  2.48it/s]predicting train subjects:  72%|███████▏  | 192/266 [01:19<00:34,  2.18it/s]predicting train subjects:  73%|███████▎  | 193/266 [01:19<00:33,  2.20it/s]predicting train subjects:  73%|███████▎  | 194/266 [01:20<00:32,  2.23it/s]predicting train subjects:  73%|███████▎  | 195/266 [01:20<00:31,  2.26it/s]predicting train subjects:  74%|███████▎  | 196/266 [01:21<00:30,  2.26it/s]predicting train subjects:  74%|███████▍  | 197/266 [01:21<00:31,  2.20it/s]predicting train subjects:  74%|███████▍  | 198/266 [01:22<00:31,  2.15it/s]predicting train subjects:  75%|███████▍  | 199/266 [01:22<00:29,  2.25it/s]predicting train subjects:  75%|███████▌  | 200/266 [01:22<00:28,  2.30it/s]predicting train subjects:  76%|███████▌  | 201/266 [01:23<00:28,  2.28it/s]predicting train subjects:  76%|███████▌  | 202/266 [01:23<00:27,  2.35it/s]predicting train subjects:  76%|███████▋  | 203/266 [01:24<00:26,  2.35it/s]predicting train subjects:  77%|███████▋  | 204/266 [01:24<00:27,  2.29it/s]predicting train subjects:  77%|███████▋  | 205/266 [01:25<00:26,  2.30it/s]predicting train subjects:  77%|███████▋  | 206/266 [01:25<00:25,  2.32it/s]predicting train subjects:  78%|███████▊  | 207/266 [01:25<00:25,  2.32it/s]predicting train subjects:  78%|███████▊  | 208/266 [01:26<00:24,  2.35it/s]predicting train subjects:  79%|███████▊  | 209/266 [01:26<00:25,  2.25it/s]predicting train subjects:  79%|███████▉  | 210/266 [01:27<00:22,  2.45it/s]predicting train subjects:  79%|███████▉  | 211/266 [01:27<00:23,  2.30it/s]predicting train subjects:  80%|███████▉  | 212/266 [01:27<00:22,  2.40it/s]predicting train subjects:  80%|████████  | 213/266 [01:28<00:20,  2.52it/s]predicting train subjects:  80%|████████  | 214/266 [01:28<00:20,  2.51it/s]predicting train subjects:  81%|████████  | 215/266 [01:29<00:20,  2.53it/s]predicting train subjects:  81%|████████  | 216/266 [01:29<00:19,  2.62it/s]predicting train subjects:  82%|████████▏ | 217/266 [01:29<00:18,  2.61it/s]predicting train subjects:  82%|████████▏ | 218/266 [01:30<00:19,  2.47it/s]predicting train subjects:  82%|████████▏ | 219/266 [01:30<00:18,  2.59it/s]predicting train subjects:  83%|████████▎ | 220/266 [01:31<00:18,  2.52it/s]predicting train subjects:  83%|████████▎ | 221/266 [01:31<00:17,  2.50it/s]predicting train subjects:  83%|████████▎ | 222/266 [01:31<00:17,  2.52it/s]predicting train subjects:  84%|████████▍ | 223/266 [01:32<00:17,  2.47it/s]predicting train subjects:  84%|████████▍ | 224/266 [01:32<00:16,  2.59it/s]predicting train subjects:  85%|████████▍ | 225/266 [01:33<00:16,  2.49it/s]predicting train subjects:  85%|████████▍ | 226/266 [01:33<00:15,  2.50it/s]predicting train subjects:  85%|████████▌ | 227/266 [01:33<00:16,  2.35it/s]predicting train subjects:  86%|████████▌ | 228/266 [01:34<00:15,  2.48it/s]predicting train subjects:  86%|████████▌ | 229/266 [01:34<00:15,  2.47it/s]predicting train subjects:  86%|████████▋ | 230/266 [01:35<00:14,  2.48it/s]predicting train subjects:  87%|████████▋ | 231/266 [01:35<00:15,  2.30it/s]predicting train subjects:  87%|████████▋ | 232/266 [01:35<00:13,  2.44it/s]predicting train subjects:  88%|████████▊ | 233/266 [01:36<00:13,  2.43it/s]predicting train subjects:  88%|████████▊ | 234/266 [01:36<00:12,  2.51it/s]predicting train subjects:  88%|████████▊ | 235/266 [01:37<00:12,  2.48it/s]predicting train subjects:  89%|████████▊ | 236/266 [01:37<00:12,  2.49it/s]predicting train subjects:  89%|████████▉ | 237/266 [01:37<00:11,  2.49it/s]predicting train subjects:  89%|████████▉ | 238/266 [01:38<00:11,  2.41it/s]predicting train subjects:  90%|████████▉ | 239/266 [01:38<00:10,  2.47it/s]predicting train subjects:  90%|█████████ | 240/266 [01:39<00:10,  2.54it/s]predicting train subjects:  91%|█████████ | 241/266 [01:39<00:09,  2.64it/s]predicting train subjects:  91%|█████████ | 242/266 [01:39<00:09,  2.65it/s]predicting train subjects:  91%|█████████▏| 243/266 [01:40<00:08,  2.63it/s]predicting train subjects:  92%|█████████▏| 244/266 [01:40<00:08,  2.53it/s]predicting train subjects:  92%|█████████▏| 245/266 [01:41<00:08,  2.60it/s]predicting train subjects:  92%|█████████▏| 246/266 [01:41<00:07,  2.64it/s]predicting train subjects:  93%|█████████▎| 247/266 [01:41<00:07,  2.50it/s]predicting train subjects:  93%|█████████▎| 248/266 [01:42<00:07,  2.34it/s]predicting train subjects:  94%|█████████▎| 249/266 [01:42<00:07,  2.32it/s]predicting train subjects:  94%|█████████▍| 250/266 [01:43<00:07,  2.23it/s]predicting train subjects:  94%|█████████▍| 251/266 [01:43<00:06,  2.22it/s]predicting train subjects:  95%|█████████▍| 252/266 [01:44<00:06,  2.13it/s]predicting train subjects:  95%|█████████▌| 253/266 [01:44<00:06,  2.07it/s]predicting train subjects:  95%|█████████▌| 254/266 [01:45<00:05,  2.16it/s]predicting train subjects:  96%|█████████▌| 255/266 [01:45<00:05,  2.18it/s]predicting train subjects:  96%|█████████▌| 256/266 [01:46<00:04,  2.16it/s]predicting train subjects:  97%|█████████▋| 257/266 [01:46<00:04,  2.20it/s]predicting train subjects:  97%|█████████▋| 258/266 [01:47<00:03,  2.17it/s]predicting train subjects:  97%|█████████▋| 259/266 [01:47<00:03,  2.20it/s]predicting train subjects:  98%|█████████▊| 260/266 [01:47<00:02,  2.14it/s]predicting train subjects:  98%|█████████▊| 261/266 [01:48<00:02,  2.06it/s]predicting train subjects:  98%|█████████▊| 262/266 [01:49<00:02,  1.98it/s]predicting train subjects:  99%|█████████▉| 263/266 [01:49<00:01,  2.10it/s]predicting train subjects:  99%|█████████▉| 264/266 [01:49<00:00,  2.09it/s]predicting train subjects: 100%|█████████▉| 265/266 [01:50<00:00,  2.01it/s]predicting train subjects: 100%|██████████| 266/266 [01:50<00:00,  1.97it/s]
predicting test subjects sagittal:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects sagittal:  20%|██        | 1/5 [00:00<00:01,  2.56it/s]predicting test subjects sagittal:  40%|████      | 2/5 [00:00<00:01,  2.42it/s]predicting test subjects sagittal:  60%|██████    | 3/5 [00:01<00:00,  2.41it/s]predicting test subjects sagittal:  80%|████████  | 4/5 [00:01<00:00,  2.41it/s]predicting test subjects sagittal: 100%|██████████| 5/5 [00:02<00:00,  2.33it/s]
predicting train subjects sagittal:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects sagittal:   0%|          | 1/266 [00:00<02:10,  2.03it/s]predicting train subjects sagittal:   1%|          | 2/266 [00:01<02:13,  1.98it/s]predicting train subjects sagittal:   1%|          | 3/266 [00:01<02:03,  2.12it/s]predicting train subjects sagittal:   2%|▏         | 4/266 [00:01<02:08,  2.03it/s]predicting train subjects sagittal:   2%|▏         | 5/266 [00:02<02:13,  1.95it/s]predicting train subjects sagittal:   2%|▏         | 6/266 [00:03<02:15,  1.91it/s]predicting train subjects sagittal:   3%|▎         | 7/266 [00:03<02:14,  1.93it/s]predicting train subjects sagittal:   3%|▎         | 8/266 [00:04<02:11,  1.96it/s]predicting train subjects sagittal:   3%|▎         | 9/266 [00:04<02:08,  2.00it/s]predicting train subjects sagittal:   4%|▍         | 10/266 [00:05<02:05,  2.04it/s]predicting train subjects sagittal:   4%|▍         | 11/266 [00:05<02:01,  2.10it/s]predicting train subjects sagittal:   5%|▍         | 12/266 [00:05<01:58,  2.15it/s]predicting train subjects sagittal:   5%|▍         | 13/266 [00:06<01:52,  2.25it/s]predicting train subjects sagittal:   5%|▌         | 14/266 [00:06<01:54,  2.20it/s]predicting train subjects sagittal:   6%|▌         | 15/266 [00:07<01:53,  2.21it/s]predicting train subjects sagittal:   6%|▌         | 16/266 [00:07<01:58,  2.11it/s]predicting train subjects sagittal:   6%|▋         | 17/266 [00:08<02:02,  2.04it/s]predicting train subjects sagittal:   7%|▋         | 18/266 [00:08<02:05,  1.97it/s]predicting train subjects sagittal:   7%|▋         | 19/266 [00:09<02:03,  1.99it/s]predicting train subjects sagittal:   8%|▊         | 20/266 [00:09<02:04,  1.98it/s]predicting train subjects sagittal:   8%|▊         | 21/266 [00:10<02:04,  1.97it/s]predicting train subjects sagittal:   8%|▊         | 22/266 [00:10<02:09,  1.88it/s]predicting train subjects sagittal:   9%|▊         | 23/266 [00:11<02:01,  2.00it/s]predicting train subjects sagittal:   9%|▉         | 24/266 [00:11<01:58,  2.05it/s]predicting train subjects sagittal:   9%|▉         | 25/266 [00:12<01:53,  2.11it/s]predicting train subjects sagittal:  10%|▉         | 26/266 [00:12<01:52,  2.14it/s]predicting train subjects sagittal:  10%|█         | 27/266 [00:13<02:00,  1.98it/s]predicting train subjects sagittal:  11%|█         | 28/266 [00:13<01:52,  2.12it/s]predicting train subjects sagittal:  11%|█         | 29/266 [00:14<01:56,  2.03it/s]predicting train subjects sagittal:  11%|█▏        | 30/266 [00:14<01:50,  2.13it/s]predicting train subjects sagittal:  12%|█▏        | 31/266 [00:15<01:53,  2.07it/s]predicting train subjects sagittal:  12%|█▏        | 32/266 [00:15<01:54,  2.04it/s]predicting train subjects sagittal:  12%|█▏        | 33/266 [00:16<01:53,  2.05it/s]predicting train subjects sagittal:  13%|█▎        | 34/266 [00:16<01:54,  2.03it/s]predicting train subjects sagittal:  13%|█▎        | 35/266 [00:17<01:57,  1.96it/s]predicting train subjects sagittal:  14%|█▎        | 36/266 [00:17<02:00,  1.90it/s]predicting train subjects sagittal:  14%|█▍        | 37/266 [00:18<02:00,  1.90it/s]predicting train subjects sagittal:  14%|█▍        | 38/266 [00:18<02:00,  1.89it/s]predicting train subjects sagittal:  15%|█▍        | 39/266 [00:19<02:01,  1.87it/s]predicting train subjects sagittal:  15%|█▌        | 40/266 [00:19<01:56,  1.94it/s]predicting train subjects sagittal:  15%|█▌        | 41/266 [00:20<01:59,  1.88it/s]predicting train subjects sagittal:  16%|█▌        | 42/266 [00:20<01:53,  1.98it/s]predicting train subjects sagittal:  16%|█▌        | 43/266 [00:21<01:49,  2.04it/s]predicting train subjects sagittal:  17%|█▋        | 44/266 [00:21<01:41,  2.19it/s]predicting train subjects sagittal:  17%|█▋        | 45/266 [00:22<01:39,  2.21it/s]predicting train subjects sagittal:  17%|█▋        | 46/266 [00:22<01:36,  2.27it/s]predicting train subjects sagittal:  18%|█▊        | 47/266 [00:23<01:38,  2.21it/s]predicting train subjects sagittal:  18%|█▊        | 48/266 [00:23<01:40,  2.17it/s]predicting train subjects sagittal:  18%|█▊        | 49/266 [00:23<01:36,  2.26it/s]predicting train subjects sagittal:  19%|█▉        | 50/266 [00:24<01:34,  2.29it/s]predicting train subjects sagittal:  19%|█▉        | 51/266 [00:24<01:33,  2.29it/s]predicting train subjects sagittal:  20%|█▉        | 52/266 [00:25<01:29,  2.39it/s]predicting train subjects sagittal:  20%|█▉        | 53/266 [00:25<01:28,  2.41it/s]predicting train subjects sagittal:  20%|██        | 54/266 [00:25<01:29,  2.37it/s]predicting train subjects sagittal:  21%|██        | 55/266 [00:26<01:29,  2.36it/s]predicting train subjects sagittal:  21%|██        | 56/266 [00:26<01:27,  2.39it/s]predicting train subjects sagittal:  21%|██▏       | 57/266 [00:27<01:32,  2.26it/s]predicting train subjects sagittal:  22%|██▏       | 58/266 [00:27<01:33,  2.23it/s]predicting train subjects sagittal:  22%|██▏       | 59/266 [00:28<01:30,  2.29it/s]predicting train subjects sagittal:  23%|██▎       | 60/266 [00:28<01:28,  2.32it/s]predicting train subjects sagittal:  23%|██▎       | 61/266 [00:28<01:23,  2.46it/s]predicting train subjects sagittal:  23%|██▎       | 62/266 [00:29<01:26,  2.35it/s]predicting train subjects sagittal:  24%|██▎       | 63/266 [00:29<01:21,  2.48it/s]predicting train subjects sagittal:  24%|██▍       | 64/266 [00:30<01:20,  2.52it/s]predicting train subjects sagittal:  24%|██▍       | 65/266 [00:30<01:21,  2.46it/s]predicting train subjects sagittal:  25%|██▍       | 66/266 [00:31<01:23,  2.40it/s]predicting train subjects sagittal:  25%|██▌       | 67/266 [00:31<01:23,  2.39it/s]predicting train subjects sagittal:  26%|██▌       | 68/266 [00:31<01:22,  2.41it/s]predicting train subjects sagittal:  26%|██▌       | 69/266 [00:32<01:21,  2.43it/s]predicting train subjects sagittal:  26%|██▋       | 70/266 [00:32<01:15,  2.61it/s]predicting train subjects sagittal:  27%|██▋       | 71/266 [00:32<01:14,  2.62it/s]predicting train subjects sagittal:  27%|██▋       | 72/266 [00:33<01:18,  2.47it/s]predicting train subjects sagittal:  27%|██▋       | 73/266 [00:33<01:20,  2.39it/s]predicting train subjects sagittal:  28%|██▊       | 74/266 [00:34<01:17,  2.47it/s]predicting train subjects sagittal:  28%|██▊       | 75/266 [00:34<01:14,  2.57it/s]predicting train subjects sagittal:  29%|██▊       | 76/266 [00:35<01:16,  2.47it/s]predicting train subjects sagittal:  29%|██▉       | 77/266 [00:35<01:10,  2.67it/s]predicting train subjects sagittal:  29%|██▉       | 78/266 [00:35<01:14,  2.52it/s]predicting train subjects sagittal:  30%|██▉       | 79/266 [00:36<01:19,  2.34it/s]predicting train subjects sagittal:  30%|███       | 80/266 [00:36<01:27,  2.12it/s]predicting train subjects sagittal:  30%|███       | 81/266 [00:37<01:28,  2.10it/s]predicting train subjects sagittal:  31%|███       | 82/266 [00:37<01:32,  1.98it/s]predicting train subjects sagittal:  31%|███       | 83/266 [00:38<01:26,  2.11it/s]predicting train subjects sagittal:  32%|███▏      | 84/266 [00:38<01:19,  2.29it/s]predicting train subjects sagittal:  32%|███▏      | 85/266 [00:39<01:21,  2.23it/s]predicting train subjects sagittal:  32%|███▏      | 86/266 [00:39<01:23,  2.16it/s]predicting train subjects sagittal:  33%|███▎      | 87/266 [00:40<01:17,  2.30it/s]predicting train subjects sagittal:  33%|███▎      | 88/266 [00:40<01:17,  2.30it/s]predicting train subjects sagittal:  33%|███▎      | 89/266 [00:40<01:17,  2.29it/s]predicting train subjects sagittal:  34%|███▍      | 90/266 [00:41<01:13,  2.39it/s]predicting train subjects sagittal:  34%|███▍      | 91/266 [00:41<01:08,  2.55it/s]predicting train subjects sagittal:  35%|███▍      | 92/266 [00:41<01:05,  2.65it/s]predicting train subjects sagittal:  35%|███▍      | 93/266 [00:42<01:05,  2.63it/s]predicting train subjects sagittal:  35%|███▌      | 94/266 [00:42<01:03,  2.71it/s]predicting train subjects sagittal:  36%|███▌      | 95/266 [00:43<01:05,  2.63it/s]predicting train subjects sagittal:  36%|███▌      | 96/266 [00:43<00:59,  2.85it/s]predicting train subjects sagittal:  36%|███▋      | 97/266 [00:43<00:57,  2.93it/s]predicting train subjects sagittal:  37%|███▋      | 98/266 [00:44<00:59,  2.84it/s]predicting train subjects sagittal:  37%|███▋      | 99/266 [00:44<00:56,  2.98it/s]predicting train subjects sagittal:  38%|███▊      | 100/266 [00:44<00:53,  3.08it/s]predicting train subjects sagittal:  38%|███▊      | 101/266 [00:44<00:52,  3.16it/s]predicting train subjects sagittal:  38%|███▊      | 102/266 [00:45<00:52,  3.14it/s]predicting train subjects sagittal:  39%|███▊      | 103/266 [00:45<00:52,  3.11it/s]predicting train subjects sagittal:  39%|███▉      | 104/266 [00:46<00:56,  2.88it/s]predicting train subjects sagittal:  39%|███▉      | 105/266 [00:46<00:54,  2.93it/s]predicting train subjects sagittal:  40%|███▉      | 106/266 [00:46<00:55,  2.88it/s]predicting train subjects sagittal:  40%|████      | 107/266 [00:47<00:53,  2.96it/s]predicting train subjects sagittal:  41%|████      | 108/266 [00:47<00:55,  2.86it/s]predicting train subjects sagittal:  41%|████      | 109/266 [00:47<00:52,  2.97it/s]predicting train subjects sagittal:  41%|████▏     | 110/266 [00:47<00:50,  3.09it/s]predicting train subjects sagittal:  42%|████▏     | 111/266 [00:48<00:50,  3.08it/s]predicting train subjects sagittal:  42%|████▏     | 112/266 [00:48<00:51,  3.01it/s]predicting train subjects sagittal:  42%|████▏     | 113/266 [00:48<00:49,  3.11it/s]predicting train subjects sagittal:  43%|████▎     | 114/266 [00:49<00:46,  3.25it/s]predicting train subjects sagittal:  43%|████▎     | 115/266 [00:49<00:45,  3.35it/s]predicting train subjects sagittal:  44%|████▎     | 116/266 [00:49<00:43,  3.44it/s]predicting train subjects sagittal:  44%|████▍     | 117/266 [00:50<00:44,  3.34it/s]predicting train subjects sagittal:  44%|████▍     | 118/266 [00:50<00:42,  3.47it/s]predicting train subjects sagittal:  45%|████▍     | 119/266 [00:50<00:46,  3.14it/s]predicting train subjects sagittal:  45%|████▌     | 120/266 [00:51<00:50,  2.92it/s]predicting train subjects sagittal:  45%|████▌     | 121/266 [00:51<00:52,  2.77it/s]predicting train subjects sagittal:  46%|████▌     | 122/266 [00:51<00:51,  2.80it/s]predicting train subjects sagittal:  46%|████▌     | 123/266 [00:52<00:48,  2.92it/s]predicting train subjects sagittal:  47%|████▋     | 124/266 [00:52<00:48,  2.92it/s]predicting train subjects sagittal:  47%|████▋     | 125/266 [00:52<00:47,  2.94it/s]predicting train subjects sagittal:  47%|████▋     | 126/266 [00:53<00:47,  2.94it/s]predicting train subjects sagittal:  48%|████▊     | 127/266 [00:53<00:46,  2.97it/s]predicting train subjects sagittal:  48%|████▊     | 128/266 [00:53<00:47,  2.92it/s]predicting train subjects sagittal:  48%|████▊     | 129/266 [00:54<00:47,  2.90it/s]predicting train subjects sagittal:  49%|████▉     | 130/266 [00:54<00:48,  2.81it/s]predicting train subjects sagittal:  49%|████▉     | 131/266 [00:55<00:51,  2.63it/s]predicting train subjects sagittal:  50%|████▉     | 132/266 [00:55<00:57,  2.33it/s]predicting train subjects sagittal:  50%|█████     | 133/266 [00:56<01:02,  2.14it/s]predicting train subjects sagittal:  50%|█████     | 134/266 [00:56<01:01,  2.14it/s]predicting train subjects sagittal:  51%|█████     | 135/266 [00:57<00:59,  2.19it/s]predicting train subjects sagittal:  51%|█████     | 136/266 [00:57<01:00,  2.14it/s]predicting train subjects sagittal:  52%|█████▏    | 137/266 [00:58<01:05,  1.98it/s]predicting train subjects sagittal:  52%|█████▏    | 138/266 [00:58<01:07,  1.89it/s]predicting train subjects sagittal:  52%|█████▏    | 139/266 [00:59<01:07,  1.87it/s]predicting train subjects sagittal:  53%|█████▎    | 140/266 [00:59<00:59,  2.11it/s]predicting train subjects sagittal:  53%|█████▎    | 141/266 [01:00<00:59,  2.10it/s]predicting train subjects sagittal:  53%|█████▎    | 142/266 [01:00<01:02,  1.98it/s]predicting train subjects sagittal:  54%|█████▍    | 143/266 [01:01<01:04,  1.91it/s]predicting train subjects sagittal:  54%|█████▍    | 144/266 [01:01<00:58,  2.10it/s]predicting train subjects sagittal:  55%|█████▍    | 145/266 [01:02<00:57,  2.11it/s]predicting train subjects sagittal:  55%|█████▍    | 146/266 [01:02<00:58,  2.05it/s]predicting train subjects sagittal:  55%|█████▌    | 147/266 [01:03<00:59,  2.00it/s]predicting train subjects sagittal:  56%|█████▌    | 148/266 [01:03<01:00,  1.96it/s]predicting train subjects sagittal:  56%|█████▌    | 149/266 [01:04<01:01,  1.91it/s]predicting train subjects sagittal:  56%|█████▋    | 150/266 [01:04<00:59,  1.94it/s]predicting train subjects sagittal:  57%|█████▋    | 151/266 [01:05<00:59,  1.95it/s]predicting train subjects sagittal:  57%|█████▋    | 152/266 [01:05<00:54,  2.09it/s]predicting train subjects sagittal:  58%|█████▊    | 153/266 [01:06<00:58,  1.92it/s]predicting train subjects sagittal:  58%|█████▊    | 154/266 [01:06<00:57,  1.94it/s]predicting train subjects sagittal:  58%|█████▊    | 155/266 [01:07<00:56,  1.97it/s]predicting train subjects sagittal:  59%|█████▊    | 156/266 [01:07<00:47,  2.30it/s]predicting train subjects sagittal:  59%|█████▉    | 157/266 [01:07<00:47,  2.30it/s]predicting train subjects sagittal:  59%|█████▉    | 158/266 [01:08<00:44,  2.44it/s]predicting train subjects sagittal:  60%|█████▉    | 159/266 [01:08<00:44,  2.39it/s]predicting train subjects sagittal:  60%|██████    | 160/266 [01:09<00:42,  2.47it/s]predicting train subjects sagittal:  61%|██████    | 161/266 [01:09<00:39,  2.67it/s]predicting train subjects sagittal:  61%|██████    | 162/266 [01:09<00:43,  2.42it/s]predicting train subjects sagittal:  61%|██████▏   | 163/266 [01:10<00:45,  2.28it/s]predicting train subjects sagittal:  62%|██████▏   | 164/266 [01:10<00:45,  2.22it/s]predicting train subjects sagittal:  62%|██████▏   | 165/266 [01:11<00:43,  2.31it/s]predicting train subjects sagittal:  62%|██████▏   | 166/266 [01:11<00:37,  2.67it/s]predicting train subjects sagittal:  63%|██████▎   | 167/266 [01:11<00:38,  2.56it/s]predicting train subjects sagittal:  63%|██████▎   | 168/266 [01:12<00:41,  2.35it/s]predicting train subjects sagittal:  64%|██████▎   | 169/266 [01:12<00:44,  2.17it/s]predicting train subjects sagittal:  64%|██████▍   | 170/266 [01:13<00:41,  2.32it/s]predicting train subjects sagittal:  64%|██████▍   | 171/266 [01:13<00:38,  2.49it/s]predicting train subjects sagittal:  65%|██████▍   | 172/266 [01:14<00:37,  2.49it/s]predicting train subjects sagittal:  65%|██████▌   | 173/266 [01:14<00:40,  2.27it/s]predicting train subjects sagittal:  65%|██████▌   | 174/266 [01:15<00:40,  2.24it/s]predicting train subjects sagittal:  66%|██████▌   | 175/266 [01:15<00:35,  2.54it/s]predicting train subjects sagittal:  66%|██████▌   | 176/266 [01:15<00:38,  2.32it/s]predicting train subjects sagittal:  67%|██████▋   | 177/266 [01:16<00:42,  2.12it/s]predicting train subjects sagittal:  67%|██████▋   | 178/266 [01:16<00:43,  2.02it/s]predicting train subjects sagittal:  67%|██████▋   | 179/266 [01:17<00:39,  2.22it/s]predicting train subjects sagittal:  68%|██████▊   | 180/266 [01:17<00:38,  2.21it/s]predicting train subjects sagittal:  68%|██████▊   | 181/266 [01:18<00:41,  2.07it/s]predicting train subjects sagittal:  68%|██████▊   | 182/266 [01:18<00:41,  2.03it/s]predicting train subjects sagittal:  69%|██████▉   | 183/266 [01:19<00:39,  2.09it/s]predicting train subjects sagittal:  69%|██████▉   | 184/266 [01:19<00:38,  2.14it/s]predicting train subjects sagittal:  70%|██████▉   | 185/266 [01:20<00:37,  2.13it/s]predicting train subjects sagittal:  70%|██████▉   | 186/266 [01:20<00:41,  1.94it/s]predicting train subjects sagittal:  70%|███████   | 187/266 [01:21<00:38,  2.07it/s]predicting train subjects sagittal:  71%|███████   | 188/266 [01:21<00:34,  2.23it/s]predicting train subjects sagittal:  71%|███████   | 189/266 [01:22<00:35,  2.16it/s]predicting train subjects sagittal:  71%|███████▏  | 190/266 [01:22<00:33,  2.28it/s]predicting train subjects sagittal:  72%|███████▏  | 191/266 [01:23<00:36,  2.06it/s]predicting train subjects sagittal:  72%|███████▏  | 192/266 [01:23<00:34,  2.16it/s]predicting train subjects sagittal:  73%|███████▎  | 193/266 [01:24<00:34,  2.09it/s]predicting train subjects sagittal:  73%|███████▎  | 194/266 [01:24<00:36,  1.97it/s]predicting train subjects sagittal:  73%|███████▎  | 195/266 [01:25<00:35,  2.03it/s]predicting train subjects sagittal:  74%|███████▎  | 196/266 [01:25<00:32,  2.15it/s]predicting train subjects sagittal:  74%|███████▍  | 197/266 [01:26<00:35,  1.94it/s]predicting train subjects sagittal:  74%|███████▍  | 198/266 [01:26<00:34,  1.96it/s]predicting train subjects sagittal:  75%|███████▍  | 199/266 [01:26<00:31,  2.16it/s]predicting train subjects sagittal:  75%|███████▌  | 200/266 [01:27<00:31,  2.12it/s]predicting train subjects sagittal:  76%|███████▌  | 201/266 [01:27<00:30,  2.11it/s]predicting train subjects sagittal:  76%|███████▌  | 202/266 [01:28<00:31,  2.02it/s]predicting train subjects sagittal:  76%|███████▋  | 203/266 [01:28<00:28,  2.18it/s]predicting train subjects sagittal:  77%|███████▋  | 204/266 [01:29<00:30,  2.05it/s]predicting train subjects sagittal:  77%|███████▋  | 205/266 [01:29<00:31,  1.93it/s]predicting train subjects sagittal:  77%|███████▋  | 206/266 [01:30<00:28,  2.09it/s]predicting train subjects sagittal:  78%|███████▊  | 207/266 [01:30<00:26,  2.23it/s]predicting train subjects sagittal:  78%|███████▊  | 208/266 [01:31<00:27,  2.12it/s]predicting train subjects sagittal:  79%|███████▊  | 209/266 [01:31<00:30,  1.87it/s]predicting train subjects sagittal:  79%|███████▉  | 210/266 [01:32<00:27,  2.07it/s]predicting train subjects sagittal:  79%|███████▉  | 211/266 [01:32<00:26,  2.10it/s]predicting train subjects sagittal:  80%|███████▉  | 212/266 [01:33<00:27,  2.00it/s]predicting train subjects sagittal:  80%|████████  | 213/266 [01:33<00:25,  2.06it/s]predicting train subjects sagittal:  80%|████████  | 214/266 [01:34<00:22,  2.30it/s]predicting train subjects sagittal:  81%|████████  | 215/266 [01:34<00:20,  2.53it/s]predicting train subjects sagittal:  81%|████████  | 216/266 [01:34<00:20,  2.46it/s]predicting train subjects sagittal:  82%|████████▏ | 217/266 [01:35<00:21,  2.33it/s]predicting train subjects sagittal:  82%|████████▏ | 218/266 [01:35<00:21,  2.22it/s]predicting train subjects sagittal:  82%|████████▏ | 219/266 [01:36<00:19,  2.43it/s]predicting train subjects sagittal:  83%|████████▎ | 220/266 [01:36<00:16,  2.72it/s]predicting train subjects sagittal:  83%|████████▎ | 221/266 [01:36<00:17,  2.64it/s]predicting train subjects sagittal:  83%|████████▎ | 222/266 [01:37<00:17,  2.51it/s]predicting train subjects sagittal:  84%|████████▍ | 223/266 [01:37<00:19,  2.25it/s]predicting train subjects sagittal:  84%|████████▍ | 224/266 [01:38<00:16,  2.48it/s]predicting train subjects sagittal:  85%|████████▍ | 225/266 [01:38<00:16,  2.44it/s]predicting train subjects sagittal:  85%|████████▍ | 226/266 [01:38<00:16,  2.36it/s]predicting train subjects sagittal:  85%|████████▌ | 227/266 [01:39<00:18,  2.12it/s]predicting train subjects sagittal:  86%|████████▌ | 228/266 [01:39<00:16,  2.25it/s]predicting train subjects sagittal:  86%|████████▌ | 229/266 [01:40<00:16,  2.19it/s]predicting train subjects sagittal:  86%|████████▋ | 230/266 [01:41<00:18,  1.95it/s]predicting train subjects sagittal:  87%|████████▋ | 231/266 [01:41<00:17,  2.01it/s]predicting train subjects sagittal:  87%|████████▋ | 232/266 [01:41<00:16,  2.07it/s]predicting train subjects sagittal:  88%|████████▊ | 233/266 [01:42<00:16,  2.02it/s]predicting train subjects sagittal:  88%|████████▊ | 234/266 [01:43<00:16,  1.97it/s]predicting train subjects sagittal:  88%|████████▊ | 235/266 [01:43<00:13,  2.28it/s]predicting train subjects sagittal:  89%|████████▊ | 236/266 [01:43<00:11,  2.54it/s]predicting train subjects sagittal:  89%|████████▉ | 237/266 [01:44<00:11,  2.54it/s]predicting train subjects sagittal:  89%|████████▉ | 238/266 [01:44<00:12,  2.23it/s]predicting train subjects sagittal:  90%|████████▉ | 239/266 [01:45<00:12,  2.13it/s]predicting train subjects sagittal:  90%|█████████ | 240/266 [01:45<00:11,  2.36it/s]predicting train subjects sagittal:  91%|█████████ | 241/266 [01:45<00:10,  2.45it/s]predicting train subjects sagittal:  91%|█████████ | 242/266 [01:46<00:10,  2.18it/s]predicting train subjects sagittal:  91%|█████████▏| 243/266 [01:46<00:11,  2.05it/s]predicting train subjects sagittal:  92%|█████████▏| 244/266 [01:47<00:09,  2.27it/s]predicting train subjects sagittal:  92%|█████████▏| 245/266 [01:47<00:09,  2.18it/s]predicting train subjects sagittal:  92%|█████████▏| 246/266 [01:48<00:09,  2.18it/s]predicting train subjects sagittal:  93%|█████████▎| 247/266 [01:48<00:08,  2.28it/s]predicting train subjects sagittal:  93%|█████████▎| 248/266 [01:48<00:07,  2.37it/s]predicting train subjects sagittal:  94%|█████████▎| 249/266 [01:49<00:07,  2.15it/s]predicting train subjects sagittal:  94%|█████████▍| 250/266 [01:50<00:08,  1.97it/s]predicting train subjects sagittal:  94%|█████████▍| 251/266 [01:50<00:07,  2.11it/s]predicting train subjects sagittal:  95%|█████████▍| 252/266 [01:51<00:06,  2.05it/s]predicting train subjects sagittal:  95%|█████████▌| 253/266 [01:51<00:06,  1.88it/s]predicting train subjects sagittal:  95%|█████████▌| 254/266 [01:52<00:06,  1.95it/s]predicting train subjects sagittal:  96%|█████████▌| 255/266 [01:52<00:05,  2.06it/s]predicting train subjects sagittal:  96%|█████████▌| 256/266 [01:53<00:05,  1.99it/s]predicting train subjects sagittal:  97%|█████████▋| 257/266 [01:53<00:04,  1.93it/s]predicting train subjects sagittal:  97%|█████████▋| 258/266 [01:54<00:03,  2.07it/s]predicting train subjects sagittal:  97%|█████████▋| 259/266 [01:54<00:03,  1.97it/s]predicting train subjects sagittal:  98%|█████████▊| 260/266 [01:55<00:02,  2.02it/s]predicting train subjects sagittal:  98%|█████████▊| 261/266 [01:55<00:02,  2.01it/s]predicting train subjects sagittal:  98%|█████████▊| 262/266 [01:56<00:02,  1.97it/s]predicting train subjects sagittal:  99%|█████████▉| 263/266 [01:56<00:01,  1.88it/s]predicting train subjects sagittal:  99%|█████████▉| 264/266 [01:57<00:00,  2.11it/s]predicting train subjects sagittal: 100%|█████████▉| 265/266 [01:57<00:00,  2.00it/s]predicting train subjects sagittal: 100%|██████████| 266/266 [01:58<00:00,  1.89it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 63.38it/s]
saving BB  train1-THALAMUS:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   2%|▏         | 5/266 [00:00<00:06, 42.61it/s]saving BB  train1-THALAMUS:   3%|▎         | 9/266 [00:00<00:06, 40.48it/s]saving BB  train1-THALAMUS:   5%|▌         | 14/266 [00:00<00:06, 40.49it/s]saving BB  train1-THALAMUS:   7%|▋         | 18/266 [00:00<00:06, 38.50it/s]saving BB  train1-THALAMUS:   8%|▊         | 22/266 [00:00<00:06, 36.60it/s]saving BB  train1-THALAMUS:   9%|▉         | 25/266 [00:00<00:09, 25.96it/s]saving BB  train1-THALAMUS:  11%|█         | 28/266 [00:00<00:10, 23.57it/s]saving BB  train1-THALAMUS:  13%|█▎        | 35/266 [00:01<00:07, 29.19it/s]saving BB  train1-THALAMUS:  16%|█▌        | 42/266 [00:01<00:06, 34.79it/s]saving BB  train1-THALAMUS:  18%|█▊        | 47/266 [00:01<00:06, 33.67it/s]saving BB  train1-THALAMUS:  20%|█▉        | 52/266 [00:01<00:06, 33.28it/s]saving BB  train1-THALAMUS:  21%|██        | 56/266 [00:01<00:06, 31.41it/s]saving BB  train1-THALAMUS:  23%|██▎       | 61/266 [00:01<00:06, 32.47it/s]saving BB  train1-THALAMUS:  24%|██▍       | 65/266 [00:01<00:06, 30.34it/s]saving BB  train1-THALAMUS:  26%|██▌       | 69/266 [00:02<00:06, 30.66it/s]saving BB  train1-THALAMUS:  29%|██▉       | 77/266 [00:02<00:05, 37.62it/s]saving BB  train1-THALAMUS:  31%|███       | 83/266 [00:02<00:04, 41.99it/s]saving BB  train1-THALAMUS:  33%|███▎      | 88/266 [00:02<00:04, 36.60it/s]saving BB  train1-THALAMUS:  35%|███▍      | 93/266 [00:02<00:04, 37.39it/s]saving BB  train1-THALAMUS:  37%|███▋      | 98/266 [00:02<00:04, 34.13it/s]saving BB  train1-THALAMUS:  39%|███▊      | 103/266 [00:02<00:04, 36.88it/s]saving BB  train1-THALAMUS:  41%|████      | 108/266 [00:02<00:04, 36.60it/s]saving BB  train1-THALAMUS:  42%|████▏     | 112/266 [00:03<00:04, 37.13it/s]saving BB  train1-THALAMUS:  45%|████▍     | 119/266 [00:03<00:03, 42.84it/s]saving BB  train1-THALAMUS:  47%|████▋     | 126/266 [00:03<00:02, 48.17it/s]saving BB  train1-THALAMUS:  50%|████▉     | 132/266 [00:03<00:03, 43.69it/s]saving BB  train1-THALAMUS:  52%|█████▏    | 137/266 [00:03<00:02, 43.97it/s]saving BB  train1-THALAMUS:  53%|█████▎    | 142/266 [00:03<00:02, 42.82it/s]saving BB  train1-THALAMUS:  55%|█████▌    | 147/266 [00:03<00:03, 35.42it/s]saving BB  train1-THALAMUS:  57%|█████▋    | 151/266 [00:04<00:03, 32.41it/s]saving BB  train1-THALAMUS:  59%|█████▊    | 156/266 [00:04<00:03, 34.61it/s]saving BB  train1-THALAMUS:  61%|██████    | 162/266 [00:04<00:02, 39.17it/s]saving BB  train1-THALAMUS:  64%|██████▍   | 171/266 [00:04<00:02, 46.55it/s]saving BB  train1-THALAMUS:  67%|██████▋   | 178/266 [00:04<00:01, 50.67it/s]saving BB  train1-THALAMUS:  69%|██████▉   | 184/266 [00:04<00:01, 44.65it/s]saving BB  train1-THALAMUS:  71%|███████▏  | 190/266 [00:04<00:01, 42.45it/s]saving BB  train1-THALAMUS:  73%|███████▎  | 195/266 [00:04<00:01, 40.48it/s]saving BB  train1-THALAMUS:  75%|███████▌  | 200/266 [00:05<00:01, 35.82it/s]saving BB  train1-THALAMUS:  77%|███████▋  | 204/266 [00:05<00:01, 35.65it/s]saving BB  train1-THALAMUS:  78%|███████▊  | 208/266 [00:05<00:01, 33.34it/s]saving BB  train1-THALAMUS:  80%|████████  | 213/266 [00:05<00:01, 36.70it/s]saving BB  train1-THALAMUS:  83%|████████▎ | 221/266 [00:05<00:01, 43.60it/s]saving BB  train1-THALAMUS:  86%|████████▌ | 228/266 [00:05<00:00, 47.99it/s]saving BB  train1-THALAMUS:  88%|████████▊ | 234/266 [00:05<00:00, 47.51it/s]saving BB  train1-THALAMUS:  90%|█████████ | 240/266 [00:05<00:00, 43.18it/s]saving BB  train1-THALAMUS:  92%|█████████▏| 245/266 [00:06<00:00, 42.84it/s]saving BB  train1-THALAMUS:  94%|█████████▍| 250/266 [00:06<00:00, 39.53it/s]saving BB  train1-THALAMUS:  96%|█████████▌| 255/266 [00:06<00:00, 38.73it/s]saving BB  train1-THALAMUS:  98%|█████████▊| 260/266 [00:06<00:00, 39.22it/s]saving BB  train1-THALAMUS: 100%|█████████▉| 265/266 [00:06<00:00, 41.35it/s]saving BB  train1-THALAMUS: 100%|██████████| 266/266 [00:06<00:00, 40.09it/s]
saving BB  test1-THALAMUS Sagittal:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS Sagittal: 100%|██████████| 5/5 [00:00<00:00, 68.32it/s]
saving BB  train1-THALAMUS Sagittal:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS Sagittal:   3%|▎         | 7/266 [00:00<00:03, 67.07it/s]saving BB  train1-THALAMUS Sagittal:   4%|▍         | 11/266 [00:00<00:04, 52.68it/s]saving BB  train1-THALAMUS Sagittal:   5%|▌         | 14/266 [00:00<00:06, 39.18it/s]saving BB  train1-THALAMUS Sagittal:   6%|▋         | 17/266 [00:00<00:07, 35.18it/s]saving BB  train1-THALAMUS Sagittal:   8%|▊         | 21/266 [00:00<00:06, 36.44it/s]saving BB  train1-THALAMUS Sagittal:   9%|▉         | 25/266 [00:00<00:06, 36.03it/s]saving BB  train1-THALAMUS Sagittal:  11%|█         | 29/266 [00:00<00:07, 33.72it/s]saving BB  train1-THALAMUS Sagittal:  12%|█▏        | 33/266 [00:00<00:06, 34.61it/s]saving BB  train1-THALAMUS Sagittal:  14%|█▍        | 37/266 [00:01<00:06, 35.66it/s]saving BB  train1-THALAMUS Sagittal:  17%|█▋        | 45/266 [00:01<00:05, 41.97it/s]saving BB  train1-THALAMUS Sagittal:  20%|█▉        | 53/266 [00:01<00:04, 47.92it/s]saving BB  train1-THALAMUS Sagittal:  22%|██▏       | 59/266 [00:01<00:04, 43.82it/s]saving BB  train1-THALAMUS Sagittal:  24%|██▍       | 64/266 [00:01<00:04, 40.75it/s]saving BB  train1-THALAMUS Sagittal:  26%|██▌       | 69/266 [00:01<00:05, 37.24it/s]saving BB  train1-THALAMUS Sagittal:  28%|██▊       | 74/266 [00:01<00:04, 39.92it/s]saving BB  train1-THALAMUS Sagittal:  30%|██▉       | 79/266 [00:02<00:05, 33.46it/s]saving BB  train1-THALAMUS Sagittal:  32%|███▏      | 86/266 [00:02<00:04, 39.28it/s]saving BB  train1-THALAMUS Sagittal:  35%|███▍      | 93/266 [00:02<00:03, 44.04it/s]saving BB  train1-THALAMUS Sagittal:  37%|███▋      | 99/266 [00:02<00:04, 40.85it/s]saving BB  train1-THALAMUS Sagittal:  39%|███▉      | 104/266 [00:02<00:04, 39.57it/s]saving BB  train1-THALAMUS Sagittal:  41%|████      | 109/266 [00:02<00:04, 31.57it/s]saving BB  train1-THALAMUS Sagittal:  42%|████▏     | 113/266 [00:02<00:04, 31.50it/s]saving BB  train1-THALAMUS Sagittal:  44%|████▍     | 117/266 [00:03<00:04, 29.87it/s]saving BB  train1-THALAMUS Sagittal:  47%|████▋     | 124/266 [00:03<00:03, 35.90it/s]saving BB  train1-THALAMUS Sagittal:  49%|████▉     | 131/266 [00:03<00:03, 40.25it/s]saving BB  train1-THALAMUS Sagittal:  51%|█████     | 136/266 [00:03<00:03, 39.52it/s]saving BB  train1-THALAMUS Sagittal:  53%|█████▎    | 141/266 [00:03<00:03, 38.37it/s]saving BB  train1-THALAMUS Sagittal:  55%|█████▍    | 146/266 [00:03<00:03, 33.03it/s]saving BB  train1-THALAMUS Sagittal:  56%|█████▋    | 150/266 [00:03<00:03, 31.15it/s]saving BB  train1-THALAMUS Sagittal:  58%|█████▊    | 154/266 [00:04<00:03, 30.88it/s]saving BB  train1-THALAMUS Sagittal:  61%|██████▏   | 163/266 [00:04<00:02, 37.99it/s]saving BB  train1-THALAMUS Sagittal:  63%|██████▎   | 168/266 [00:04<00:02, 40.06it/s]saving BB  train1-THALAMUS Sagittal:  65%|██████▌   | 173/266 [00:04<00:02, 41.22it/s]saving BB  train1-THALAMUS Sagittal:  67%|██████▋   | 179/266 [00:04<00:01, 44.41it/s]saving BB  train1-THALAMUS Sagittal:  69%|██████▉   | 184/266 [00:04<00:02, 35.98it/s]saving BB  train1-THALAMUS Sagittal:  71%|███████   | 189/266 [00:04<00:02, 37.94it/s]saving BB  train1-THALAMUS Sagittal:  73%|███████▎  | 194/266 [00:04<00:01, 37.30it/s]saving BB  train1-THALAMUS Sagittal:  76%|███████▌  | 202/266 [00:05<00:01, 43.80it/s]saving BB  train1-THALAMUS Sagittal:  79%|███████▊  | 209/266 [00:05<00:01, 48.43it/s]saving BB  train1-THALAMUS Sagittal:  81%|████████  | 215/266 [00:05<00:01, 41.17it/s]saving BB  train1-THALAMUS Sagittal:  83%|████████▎ | 220/266 [00:05<00:01, 36.05it/s]saving BB  train1-THALAMUS Sagittal:  85%|████████▍ | 225/266 [00:05<00:01, 31.14it/s]saving BB  train1-THALAMUS Sagittal:  86%|████████▌ | 229/266 [00:05<00:01, 29.29it/s]saving BB  train1-THALAMUS Sagittal:  89%|████████▉ | 238/266 [00:05<00:00, 36.22it/s]saving BB  train1-THALAMUS Sagittal:  92%|█████████▏| 244/266 [00:06<00:00, 40.76it/s]saving BB  train1-THALAMUS Sagittal:  94%|█████████▍| 250/266 [00:06<00:00, 39.74it/s]saving BB  train1-THALAMUS Sagittal:  96%|█████████▌| 255/266 [00:06<00:00, 37.63it/s]saving BB  train1-THALAMUS Sagittal:  98%|█████████▊| 260/266 [00:06<00:00, 35.60it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 266/266 [00:06<00:00, 39.88it/s]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:03<13:46,  3.12s/it]Loading train:   1%|          | 2/266 [00:05<13:23,  3.04s/it]Loading train:   1%|          | 3/266 [00:08<12:22,  2.83s/it]Loading train:   2%|▏         | 4/266 [00:10<11:25,  2.62s/it]Loading train:   2%|▏         | 5/266 [00:13<11:23,  2.62s/it]Loading train:   2%|▏         | 6/266 [00:15<10:58,  2.53s/it]Loading train:   3%|▎         | 7/266 [00:17<11:01,  2.55s/it]Loading train:   3%|▎         | 8/266 [00:20<10:50,  2.52s/it]Loading train:   3%|▎         | 9/266 [00:23<11:10,  2.61s/it]Loading train:   4%|▍         | 10/266 [00:25<10:07,  2.37s/it]Loading train:   4%|▍         | 11/266 [00:27<09:44,  2.29s/it]Loading train:   5%|▍         | 12/266 [00:29<09:15,  2.19s/it]Loading train:   5%|▍         | 13/266 [00:31<09:13,  2.19s/it]Loading train:   5%|▌         | 14/266 [00:33<09:22,  2.23s/it]Loading train:   6%|▌         | 15/266 [00:35<09:10,  2.19s/it]Loading train:   6%|▌         | 16/266 [00:38<09:40,  2.32s/it]Loading train:   6%|▋         | 17/266 [00:40<09:39,  2.33s/it]Loading train:   7%|▋         | 18/266 [00:43<09:38,  2.33s/it]Loading train:   7%|▋         | 19/266 [00:45<09:18,  2.26s/it]Loading train:   8%|▊         | 20/266 [00:47<09:13,  2.25s/it]Loading train:   8%|▊         | 21/266 [00:49<09:14,  2.26s/it]Loading train:   8%|▊         | 22/266 [00:51<08:34,  2.11s/it]Loading train:   9%|▊         | 23/266 [00:53<07:56,  1.96s/it]Loading train:   9%|▉         | 24/266 [00:54<07:42,  1.91s/it]Loading train:   9%|▉         | 25/266 [00:56<07:33,  1.88s/it]Loading train:  10%|▉         | 26/266 [00:58<07:22,  1.84s/it]Loading train:  10%|█         | 27/266 [01:00<07:09,  1.80s/it]Loading train:  11%|█         | 28/266 [01:02<07:24,  1.87s/it]Loading train:  11%|█         | 29/266 [01:03<07:04,  1.79s/it]Loading train:  11%|█▏        | 30/266 [01:05<06:58,  1.77s/it]Loading train:  12%|█▏        | 31/266 [01:07<06:44,  1.72s/it]Loading train:  12%|█▏        | 32/266 [01:08<06:32,  1.68s/it]Loading train:  12%|█▏        | 33/266 [01:10<06:29,  1.67s/it]Loading train:  13%|█▎        | 34/266 [01:11<06:19,  1.63s/it]Loading train:  13%|█▎        | 35/266 [01:13<06:52,  1.78s/it]Loading train:  14%|█▎        | 36/266 [01:15<07:06,  1.85s/it]Loading train:  14%|█▍        | 37/266 [01:18<07:31,  1.97s/it]Loading train:  14%|█▍        | 38/266 [01:20<07:24,  1.95s/it]Loading train:  15%|█▍        | 39/266 [01:21<07:14,  1.91s/it]Loading train:  15%|█▌        | 40/266 [01:24<07:33,  2.01s/it]Loading train:  15%|█▌        | 41/266 [01:25<07:17,  1.94s/it]Loading train:  16%|█▌        | 42/266 [01:27<06:23,  1.71s/it]Loading train:  16%|█▌        | 43/266 [01:28<06:13,  1.67s/it]Loading train:  17%|█▋        | 44/266 [01:30<05:51,  1.59s/it]Loading train:  17%|█▋        | 45/266 [01:32<06:11,  1.68s/it]Loading train:  17%|█▋        | 46/266 [01:33<06:08,  1.68s/it]Loading train:  18%|█▊        | 47/266 [01:34<05:33,  1.52s/it]Loading train:  18%|█▊        | 48/266 [01:36<05:27,  1.50s/it]Loading train:  18%|█▊        | 49/266 [01:37<05:29,  1.52s/it]Loading train:  19%|█▉        | 50/266 [01:39<06:02,  1.68s/it]Loading train:  19%|█▉        | 51/266 [01:41<06:22,  1.78s/it]Loading train:  20%|█▉        | 52/266 [01:43<06:33,  1.84s/it]Loading train:  20%|█▉        | 53/266 [01:45<06:30,  1.83s/it]Loading train:  20%|██        | 54/266 [01:47<06:25,  1.82s/it]Loading train:  21%|██        | 55/266 [01:48<05:37,  1.60s/it]Loading train:  21%|██        | 56/266 [01:49<05:20,  1.53s/it]Loading train:  21%|██▏       | 57/266 [01:51<05:14,  1.51s/it]Loading train:  22%|██▏       | 58/266 [01:52<05:01,  1.45s/it]Loading train:  22%|██▏       | 59/266 [01:54<05:00,  1.45s/it]Loading train:  23%|██▎       | 60/266 [01:55<05:17,  1.54s/it]Loading train:  23%|██▎       | 61/266 [01:57<05:20,  1.56s/it]Loading train:  23%|██▎       | 62/266 [01:58<05:08,  1.51s/it]Loading train:  24%|██▎       | 63/266 [02:00<04:53,  1.45s/it]Loading train:  24%|██▍       | 64/266 [02:01<05:03,  1.50s/it]Loading train:  24%|██▍       | 65/266 [02:03<05:06,  1.52s/it]Loading train:  25%|██▍       | 66/266 [02:04<04:52,  1.46s/it]Loading train:  25%|██▌       | 67/266 [02:06<04:57,  1.50s/it]Loading train:  26%|██▌       | 68/266 [02:08<05:17,  1.61s/it]Loading train:  26%|██▌       | 69/266 [02:09<04:57,  1.51s/it]Loading train:  26%|██▋       | 70/266 [02:10<04:37,  1.42s/it]Loading train:  27%|██▋       | 71/266 [02:12<04:58,  1.53s/it]Loading train:  27%|██▋       | 72/266 [02:14<04:56,  1.53s/it]Loading train:  27%|██▋       | 73/266 [02:15<05:20,  1.66s/it]Loading train:  28%|██▊       | 74/266 [02:17<05:36,  1.75s/it]Loading train:  28%|██▊       | 75/266 [02:19<05:06,  1.61s/it]Loading train:  29%|██▊       | 76/266 [02:20<04:58,  1.57s/it]Loading train:  29%|██▉       | 77/266 [02:22<05:00,  1.59s/it]Loading train:  29%|██▉       | 78/266 [02:24<05:46,  1.84s/it]Loading train:  30%|██▉       | 79/266 [02:27<06:32,  2.10s/it]Loading train:  30%|███       | 80/266 [02:29<06:28,  2.09s/it]Loading train:  30%|███       | 81/266 [02:31<06:18,  2.05s/it]Loading train:  31%|███       | 82/266 [02:33<06:02,  1.97s/it]Loading train:  31%|███       | 83/266 [02:34<05:46,  1.89s/it]Loading train:  32%|███▏      | 84/266 [02:36<05:39,  1.86s/it]Loading train:  32%|███▏      | 85/266 [02:38<05:19,  1.76s/it]Loading train:  32%|███▏      | 86/266 [02:39<05:07,  1.71s/it]Loading train:  33%|███▎      | 87/266 [02:41<05:17,  1.77s/it]Loading train:  33%|███▎      | 88/266 [02:43<05:20,  1.80s/it]Loading train:  33%|███▎      | 89/266 [02:45<05:29,  1.86s/it]Loading train:  34%|███▍      | 90/266 [02:47<05:15,  1.79s/it]Loading train:  34%|███▍      | 91/266 [02:49<05:12,  1.79s/it]Loading train:  35%|███▍      | 92/266 [02:50<05:04,  1.75s/it]Loading train:  35%|███▍      | 93/266 [02:52<05:08,  1.78s/it]Loading train:  35%|███▌      | 94/266 [02:54<05:02,  1.76s/it]Loading train:  36%|███▌      | 95/266 [02:55<04:46,  1.67s/it]Loading train:  36%|███▌      | 96/266 [02:57<04:55,  1.74s/it]Loading train:  36%|███▋      | 97/266 [03:00<05:31,  1.96s/it]Loading train:  37%|███▋      | 98/266 [03:02<06:01,  2.15s/it]Loading train:  37%|███▋      | 99/266 [03:04<05:59,  2.15s/it]Loading train:  38%|███▊      | 100/266 [03:06<05:30,  1.99s/it]Loading train:  38%|███▊      | 101/266 [03:08<05:33,  2.02s/it]Loading train:  38%|███▊      | 102/266 [03:10<05:26,  1.99s/it]Loading train:  39%|███▊      | 103/266 [03:12<05:16,  1.94s/it]Loading train:  39%|███▉      | 104/266 [03:14<05:04,  1.88s/it]Loading train:  39%|███▉      | 105/266 [03:15<04:56,  1.84s/it]Loading train:  40%|███▉      | 106/266 [03:17<05:02,  1.89s/it]Loading train:  40%|████      | 107/266 [03:19<04:47,  1.81s/it]Loading train:  41%|████      | 108/266 [03:21<04:45,  1.81s/it]Loading train:  41%|████      | 109/266 [03:23<04:40,  1.78s/it]Loading train:  41%|████▏     | 110/266 [03:24<04:33,  1.75s/it]Loading train:  42%|████▏     | 111/266 [03:26<04:50,  1.88s/it]Loading train:  42%|████▏     | 112/266 [03:28<04:51,  1.89s/it]Loading train:  42%|████▏     | 113/266 [03:30<04:50,  1.90s/it]Loading train:  43%|████▎     | 114/266 [03:32<04:31,  1.79s/it]Loading train:  43%|████▎     | 115/266 [03:33<04:14,  1.68s/it]Loading train:  44%|████▎     | 116/266 [03:35<04:04,  1.63s/it]Loading train:  44%|████▍     | 117/266 [03:36<03:53,  1.57s/it]Loading train:  44%|████▍     | 118/266 [03:38<03:47,  1.54s/it]Loading train:  45%|████▍     | 119/266 [03:39<03:50,  1.57s/it]Loading train:  45%|████▌     | 120/266 [03:41<03:43,  1.53s/it]Loading train:  45%|████▌     | 121/266 [03:42<03:46,  1.56s/it]Loading train:  46%|████▌     | 122/266 [03:44<03:51,  1.61s/it]Loading train:  46%|████▌     | 123/266 [03:46<04:03,  1.70s/it]Loading train:  47%|████▋     | 124/266 [03:48<04:08,  1.75s/it]Loading train:  47%|████▋     | 125/266 [03:49<04:00,  1.71s/it]Loading train:  47%|████▋     | 126/266 [03:51<03:56,  1.69s/it]Loading train:  48%|████▊     | 127/266 [03:53<03:59,  1.72s/it]Loading train:  48%|████▊     | 128/266 [03:55<04:01,  1.75s/it]Loading train:  48%|████▊     | 129/266 [03:56<04:03,  1.78s/it]Loading train:  49%|████▉     | 130/266 [03:59<04:18,  1.90s/it]Loading train:  49%|████▉     | 131/266 [04:01<04:28,  1.99s/it]Loading train:  50%|████▉     | 132/266 [04:03<04:17,  1.92s/it]Loading train:  50%|█████     | 133/266 [04:05<04:22,  1.98s/it]Loading train:  50%|█████     | 134/266 [04:07<04:32,  2.06s/it]Loading train:  51%|█████     | 135/266 [04:09<04:41,  2.15s/it]Loading train:  51%|█████     | 136/266 [04:11<04:37,  2.13s/it]Loading train:  52%|█████▏    | 137/266 [04:13<04:12,  1.96s/it]Loading train:  52%|█████▏    | 138/266 [04:15<03:59,  1.87s/it]Loading train:  52%|█████▏    | 139/266 [04:17<04:00,  1.89s/it]Loading train:  53%|█████▎    | 140/266 [04:18<03:49,  1.82s/it]Loading train:  53%|█████▎    | 141/266 [04:20<03:38,  1.75s/it]Loading train:  53%|█████▎    | 142/266 [04:21<03:30,  1.69s/it]Loading train:  54%|█████▍    | 143/266 [04:23<03:11,  1.55s/it]Loading train:  54%|█████▍    | 144/266 [04:25<03:21,  1.65s/it]Loading train:  55%|█████▍    | 145/266 [04:26<03:27,  1.72s/it]Loading train:  55%|█████▍    | 146/266 [04:28<03:37,  1.81s/it]Loading train:  55%|█████▌    | 147/266 [04:30<03:37,  1.82s/it]Loading train:  56%|█████▌    | 148/266 [04:33<03:54,  1.99s/it]Loading train:  56%|█████▌    | 149/266 [04:35<03:49,  1.97s/it]Loading train:  56%|█████▋    | 150/266 [04:36<03:38,  1.88s/it]Loading train:  57%|█████▋    | 151/266 [04:38<03:31,  1.84s/it]Loading train:  57%|█████▋    | 152/266 [04:40<03:24,  1.80s/it]Loading train:  58%|█████▊    | 153/266 [04:42<03:25,  1.82s/it]Loading train:  58%|█████▊    | 154/266 [04:43<03:23,  1.82s/it]Loading train:  58%|█████▊    | 155/266 [04:45<03:06,  1.68s/it]Loading train:  59%|█████▊    | 156/266 [04:46<02:48,  1.53s/it]Loading train:  59%|█████▉    | 157/266 [04:47<02:46,  1.52s/it]Loading train:  59%|█████▉    | 158/266 [04:49<02:46,  1.54s/it]Loading train:  60%|█████▉    | 159/266 [04:51<03:02,  1.70s/it]Loading train:  60%|██████    | 160/266 [04:53<03:06,  1.76s/it]Loading train:  61%|██████    | 161/266 [04:55<03:08,  1.80s/it]Loading train:  61%|██████    | 162/266 [04:57<03:04,  1.77s/it]Loading train:  61%|██████▏   | 163/266 [04:58<02:53,  1.69s/it]Loading train:  62%|██████▏   | 164/266 [05:00<02:57,  1.74s/it]Loading train:  62%|██████▏   | 165/266 [05:01<02:49,  1.68s/it]Loading train:  62%|██████▏   | 166/266 [05:03<02:44,  1.65s/it]Loading train:  63%|██████▎   | 167/266 [05:04<02:28,  1.50s/it]Loading train:  63%|██████▎   | 168/266 [05:06<02:33,  1.57s/it]Loading train:  64%|██████▎   | 169/266 [05:08<02:33,  1.58s/it]Loading train:  64%|██████▍   | 170/266 [05:09<02:27,  1.53s/it]Loading train:  64%|██████▍   | 171/266 [05:10<02:23,  1.51s/it]Loading train:  65%|██████▍   | 172/266 [05:12<02:23,  1.53s/it]Loading train:  65%|██████▌   | 173/266 [05:14<02:30,  1.62s/it]Loading train:  65%|██████▌   | 174/266 [05:16<02:31,  1.65s/it]Loading train:  66%|██████▌   | 175/266 [05:17<02:34,  1.69s/it]Loading train:  66%|██████▌   | 176/266 [05:20<02:46,  1.85s/it]Loading train:  67%|██████▋   | 177/266 [05:22<02:47,  1.88s/it]Loading train:  67%|██████▋   | 178/266 [05:24<02:49,  1.93s/it]Loading train:  67%|██████▋   | 179/266 [05:25<02:46,  1.92s/it]Loading train:  68%|██████▊   | 180/266 [05:27<02:36,  1.82s/it]Loading train:  68%|██████▊   | 181/266 [05:28<02:24,  1.70s/it]Loading train:  68%|██████▊   | 182/266 [05:30<02:21,  1.68s/it]Loading train:  69%|██████▉   | 183/266 [05:31<02:08,  1.55s/it]Loading train:  69%|██████▉   | 184/266 [05:34<02:22,  1.74s/it]Loading train:  70%|██████▉   | 185/266 [05:35<02:13,  1.65s/it]Loading train:  70%|██████▉   | 186/266 [05:37<02:15,  1.70s/it]Loading train:  70%|███████   | 187/266 [05:38<02:10,  1.66s/it]Loading train:  71%|███████   | 188/266 [05:40<02:14,  1.73s/it]Loading train:  71%|███████   | 189/266 [05:42<02:06,  1.65s/it]Loading train:  71%|███████▏  | 190/266 [05:43<01:59,  1.58s/it]Loading train:  72%|███████▏  | 191/266 [05:45<02:09,  1.72s/it]Loading train:  72%|███████▏  | 192/266 [05:47<02:17,  1.86s/it]Loading train:  73%|███████▎  | 193/266 [05:49<02:15,  1.86s/it]Loading train:  73%|███████▎  | 194/266 [05:52<02:27,  2.04s/it]Loading train:  73%|███████▎  | 195/266 [05:53<02:16,  1.92s/it]Loading train:  74%|███████▎  | 196/266 [05:55<02:05,  1.80s/it]Loading train:  74%|███████▍  | 197/266 [05:56<01:51,  1.61s/it]Loading train:  74%|███████▍  | 198/266 [05:58<01:51,  1.65s/it]Loading train:  75%|███████▍  | 199/266 [05:59<01:52,  1.68s/it]Loading train:  75%|███████▌  | 200/266 [06:01<01:45,  1.60s/it]Loading train:  76%|███████▌  | 201/266 [06:03<01:49,  1.69s/it]Loading train:  76%|███████▌  | 202/266 [06:05<01:56,  1.82s/it]Loading train:  76%|███████▋  | 203/266 [06:07<01:56,  1.85s/it]Loading train:  77%|███████▋  | 204/266 [06:09<01:56,  1.87s/it]Loading train:  77%|███████▋  | 205/266 [06:11<01:53,  1.86s/it]Loading train:  77%|███████▋  | 206/266 [06:12<01:43,  1.72s/it]Loading train:  78%|███████▊  | 207/266 [06:14<01:38,  1.67s/it]Loading train:  78%|███████▊  | 208/266 [06:15<01:34,  1.63s/it]Loading train:  79%|███████▊  | 209/266 [06:17<01:30,  1.60s/it]Loading train:  79%|███████▉  | 210/266 [06:18<01:31,  1.64s/it]Loading train:  79%|███████▉  | 211/266 [06:20<01:37,  1.77s/it]Loading train:  80%|███████▉  | 212/266 [06:22<01:38,  1.83s/it]Loading train:  80%|████████  | 213/266 [06:24<01:38,  1.86s/it]Loading train:  80%|████████  | 214/266 [06:26<01:29,  1.72s/it]Loading train:  81%|████████  | 215/266 [06:27<01:19,  1.55s/it]Loading train:  81%|████████  | 216/266 [06:29<01:20,  1.62s/it]Loading train:  82%|████████▏ | 217/266 [06:30<01:21,  1.67s/it]Loading train:  82%|████████▏ | 218/266 [06:32<01:21,  1.70s/it]Loading train:  82%|████████▏ | 219/266 [06:34<01:25,  1.81s/it]Loading train:  83%|████████▎ | 220/266 [06:36<01:23,  1.82s/it]Loading train:  83%|████████▎ | 221/266 [06:39<01:31,  2.03s/it]Loading train:  83%|████████▎ | 222/266 [06:41<01:31,  2.07s/it]Loading train:  84%|████████▍ | 223/266 [06:43<01:28,  2.05s/it]Loading train:  84%|████████▍ | 224/266 [06:45<01:30,  2.16s/it]Loading train:  85%|████████▍ | 225/266 [06:47<01:22,  2.00s/it]Loading train:  85%|████████▍ | 226/266 [06:48<01:11,  1.78s/it]Loading train:  85%|████████▌ | 227/266 [06:49<00:59,  1.54s/it]Loading train:  86%|████████▌ | 228/266 [06:50<00:56,  1.48s/it]Loading train:  86%|████████▌ | 229/266 [06:51<00:48,  1.32s/it]Loading train:  86%|████████▋ | 230/266 [06:53<00:53,  1.48s/it]Loading train:  87%|████████▋ | 231/266 [06:55<00:58,  1.66s/it]Loading train:  87%|████████▋ | 232/266 [06:57<00:56,  1.66s/it]Loading train:  88%|████████▊ | 233/266 [06:59<00:55,  1.67s/it]Loading train:  88%|████████▊ | 234/266 [07:00<00:52,  1.63s/it]Loading train:  88%|████████▊ | 235/266 [07:01<00:44,  1.42s/it]Loading train:  89%|████████▊ | 236/266 [07:02<00:38,  1.27s/it]Loading train:  89%|████████▉ | 237/266 [07:03<00:32,  1.14s/it]Loading train:  89%|████████▉ | 238/266 [07:04<00:29,  1.05s/it]Loading train:  90%|████████▉ | 239/266 [07:05<00:27,  1.03s/it]Loading train:  90%|█████████ | 240/266 [07:06<00:25,  1.00it/s]Loading train:  91%|█████████ | 241/266 [07:07<00:24,  1.01it/s]Loading train:  91%|█████████ | 242/266 [07:07<00:22,  1.06it/s]Loading train:  91%|█████████▏| 243/266 [07:08<00:21,  1.07it/s]Loading train:  92%|█████████▏| 244/266 [07:09<00:19,  1.13it/s]Loading train:  92%|█████████▏| 245/266 [07:10<00:19,  1.07it/s]Loading train:  92%|█████████▏| 246/266 [07:11<00:19,  1.04it/s]Loading train:  93%|█████████▎| 247/266 [07:12<00:18,  1.05it/s]Loading train:  93%|█████████▎| 248/266 [07:13<00:16,  1.07it/s]Loading train:  94%|█████████▎| 249/266 [07:14<00:16,  1.00it/s]Loading train:  94%|█████████▍| 250/266 [07:15<00:17,  1.08s/it]Loading train:  94%|█████████▍| 251/266 [07:17<00:16,  1.10s/it]Loading train:  95%|█████████▍| 252/266 [07:18<00:15,  1.12s/it]Loading train:  95%|█████████▌| 253/266 [07:19<00:14,  1.10s/it]Loading train:  95%|█████████▌| 254/266 [07:20<00:13,  1.11s/it]Loading train:  96%|█████████▌| 255/266 [07:21<00:12,  1.12s/it]Loading train:  96%|█████████▌| 256/266 [07:22<00:11,  1.13s/it]Loading train:  97%|█████████▋| 257/266 [07:23<00:09,  1.08s/it]Loading train:  97%|█████████▋| 258/266 [07:24<00:08,  1.09s/it]Loading train:  97%|█████████▋| 259/266 [07:25<00:07,  1.07s/it]Loading train:  98%|█████████▊| 260/266 [07:26<00:06,  1.07s/it]Loading train:  98%|█████████▊| 261/266 [07:28<00:05,  1.13s/it]Loading train:  98%|█████████▊| 262/266 [07:29<00:04,  1.19s/it]Loading train:  99%|█████████▉| 263/266 [07:30<00:03,  1.16s/it]Loading train:  99%|█████████▉| 264/266 [07:31<00:02,  1.12s/it]Loading train: 100%|█████████▉| 265/266 [07:32<00:01,  1.13s/it]Loading train: 100%|██████████| 266/266 [07:33<00:00,  1.13s/it]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 4/266 [00:00<00:07, 33.15it/s]concatenating: train:   3%|▎         | 9/266 [00:00<00:07, 36.29it/s]concatenating: train:   9%|▉         | 24/266 [00:00<00:05, 46.88it/s]concatenating: train:  15%|█▍        | 39/266 [00:00<00:03, 58.85it/s]concatenating: train:  20%|█▉        | 52/266 [00:00<00:03, 70.38it/s]concatenating: train:  25%|██▌       | 67/266 [00:00<00:02, 82.66it/s]concatenating: train:  30%|██▉       | 79/266 [00:00<00:02, 77.19it/s]concatenating: train:  33%|███▎      | 89/266 [00:01<00:02, 68.46it/s]concatenating: train:  37%|███▋      | 98/266 [00:01<00:02, 65.46it/s]concatenating: train:  40%|███▉      | 106/266 [00:01<00:02, 56.32it/s]concatenating: train:  45%|████▍     | 119/266 [00:01<00:02, 67.41it/s]concatenating: train:  48%|████▊     | 128/266 [00:01<00:02, 68.04it/s]concatenating: train:  53%|█████▎    | 142/266 [00:01<00:01, 80.12it/s]concatenating: train:  58%|█████▊    | 153/266 [00:01<00:01, 84.80it/s]concatenating: train:  61%|██████▏   | 163/266 [00:01<00:01, 86.47it/s]concatenating: train:  66%|██████▌   | 175/266 [00:02<00:00, 93.93it/s]concatenating: train:  70%|██████▉   | 186/266 [00:02<00:00, 97.19it/s]concatenating: train:  77%|███████▋  | 204/266 [00:02<00:00, 111.14it/s]concatenating: train:  82%|████████▏ | 217/266 [00:02<00:00, 110.22it/s]concatenating: train:  89%|████████▊ | 236/266 [00:02<00:00, 123.23it/s]concatenating: train:  94%|█████████▍| 250/266 [00:02<00:00, 101.21it/s]concatenating: train:  99%|█████████▉| 264/266 [00:02<00:00, 105.48it/s]concatenating: train: 100%|██████████| 266/266 [00:02<00:00, 95.85it/s] 
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:01<00:05,  1.48s/it]Loading test:  40%|████      | 2/5 [00:02<00:04,  1.43s/it]Loading test:  60%|██████    | 3/5 [00:04<00:02,  1.47s/it]Loading test:  80%|████████  | 4/5 [00:05<00:01,  1.40s/it]Loading test: 100%|██████████| 5/5 [00:07<00:00,  1.47s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 50.90it/s]2019-08-17 18:42:24.054008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-08-17 18:42:24.054100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-17 18:42:24.054129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-08-17 18:42:24.054139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-08-17 18:42:24.054599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.21it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.13it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  5.93it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.59it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.69it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.47it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.24it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.07it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.58it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.12it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.82it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.20it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.62it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.69it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.51it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.32it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.59it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.55it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.70it/s]
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 84, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 84, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 84, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 84, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 84, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 84, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 84, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 42, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 42, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 42, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 42, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 42, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 42, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 42, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 42, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 42, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 21, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 21, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 21, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 21, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 21, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 21, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 21, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 21, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 21, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 21, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 42, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 42, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 42, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 42, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 42, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 42, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 42, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 42, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 42, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 42, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 84, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 84, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 84, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 84, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 84, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 84, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 84, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 84, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 84, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 84, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 84, 13)   793         dropout_5[0][0]                  
==================================================================================================
Total params: 223,833
Trainable params: 27,093
Non-trainable params: 196,740
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.31837756e-02 3.27472736e-02 7.65749954e-02 9.51482823e-03
 2.75380795e-02 7.20456227e-03 8.58750646e-02 1.13816124e-01
 8.93681224e-02 1.35781277e-02 2.89749030e-01 1.90585339e-01
 2.64677373e-04]
Train on 9519 samples, validate on 175 samples
Epoch 1/300
 - 14s - loss: 2.8246 - acc: 0.7727 - mDice: 0.1036 - val_loss: 5.1632 - val_acc: 0.9062 - val_mDice: 0.0875

Epoch 00001: val_mDice improved from -inf to 0.08750, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 9s - loss: 1.4821 - acc: 0.8794 - mDice: 0.2590 - val_loss: 1.9120 - val_acc: 0.8989 - val_mDice: 0.2763

Epoch 00002: val_mDice improved from 0.08750 to 0.27632, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 8s - loss: 1.1480 - acc: 0.8862 - mDice: 0.3298 - val_loss: 1.2864 - val_acc: 0.9169 - val_mDice: 0.4018

Epoch 00003: val_mDice improved from 0.27632 to 0.40180, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 8s - loss: 0.9660 - acc: 0.8916 - mDice: 0.3780 - val_loss: 1.3615 - val_acc: 0.8843 - val_mDice: 0.4093

Epoch 00004: val_mDice improved from 0.40180 to 0.40932, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 9s - loss: 0.8262 - acc: 0.8979 - mDice: 0.4291 - val_loss: 1.1070 - val_acc: 0.9108 - val_mDice: 0.4770

Epoch 00005: val_mDice improved from 0.40932 to 0.47699, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 8s - loss: 0.7310 - acc: 0.9034 - mDice: 0.4736 - val_loss: 2.0558 - val_acc: 0.9161 - val_mDice: 0.3621

Epoch 00006: val_mDice did not improve from 0.47699
Epoch 7/300
 - 8s - loss: 0.6725 - acc: 0.9068 - mDice: 0.5018 - val_loss: 0.9897 - val_acc: 0.9298 - val_mDice: 0.5168

Epoch 00007: val_mDice improved from 0.47699 to 0.51685, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 8s - loss: 0.6338 - acc: 0.9089 - mDice: 0.5211 - val_loss: 0.9998 - val_acc: 0.9187 - val_mDice: 0.5301

Epoch 00008: val_mDice improved from 0.51685 to 0.53015, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 9s - loss: 0.6027 - acc: 0.9110 - mDice: 0.5377 - val_loss: 1.0231 - val_acc: 0.9104 - val_mDice: 0.5153

Epoch 00009: val_mDice did not improve from 0.53015
Epoch 10/300
 - 8s - loss: 0.5782 - acc: 0.9126 - mDice: 0.5514 - val_loss: 0.8484 - val_acc: 0.9352 - val_mDice: 0.5681

Epoch 00010: val_mDice improved from 0.53015 to 0.56806, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 8s - loss: 0.5542 - acc: 0.9138 - mDice: 0.5634 - val_loss: 0.8962 - val_acc: 0.9343 - val_mDice: 0.5622

Epoch 00011: val_mDice did not improve from 0.56806
Epoch 12/300
 - 8s - loss: 0.5397 - acc: 0.9152 - mDice: 0.5717 - val_loss: 0.7656 - val_acc: 0.9370 - val_mDice: 0.5709

Epoch 00012: val_mDice improved from 0.56806 to 0.57092, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 8s - loss: 0.5259 - acc: 0.9161 - mDice: 0.5799 - val_loss: 0.7908 - val_acc: 0.9364 - val_mDice: 0.5852

Epoch 00013: val_mDice improved from 0.57092 to 0.58519, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 8s - loss: 0.5176 - acc: 0.9173 - mDice: 0.5844 - val_loss: 0.7606 - val_acc: 0.9350 - val_mDice: 0.5819

Epoch 00014: val_mDice did not improve from 0.58519
Epoch 15/300
 - 9s - loss: 0.5057 - acc: 0.9185 - mDice: 0.5914 - val_loss: 0.8737 - val_acc: 0.9224 - val_mDice: 0.5490

Epoch 00015: val_mDice did not improve from 0.58519
Epoch 16/300
 - 9s - loss: 0.5020 - acc: 0.9186 - mDice: 0.5934 - val_loss: 0.8625 - val_acc: 0.9333 - val_mDice: 0.5853

Epoch 00016: val_mDice improved from 0.58519 to 0.58526, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 8s - loss: 0.4892 - acc: 0.9200 - mDice: 0.6007 - val_loss: 0.9279 - val_acc: 0.9248 - val_mDice: 0.5675

Epoch 00017: val_mDice did not improve from 0.58526
Epoch 18/300
 - 8s - loss: 0.4832 - acc: 0.9203 - mDice: 0.6040 - val_loss: 0.8268 - val_acc: 0.9289 - val_mDice: 0.5649

Epoch 00018: val_mDice did not improve from 0.58526
Epoch 19/300
 - 8s - loss: 0.4778 - acc: 0.9211 - mDice: 0.6072 - val_loss: 0.8367 - val_acc: 0.9262 - val_mDice: 0.5647

Epoch 00019: val_mDice did not improve from 0.58526
Epoch 20/300
 - 8s - loss: 0.4785 - acc: 0.9208 - mDice: 0.6073 - val_loss: 0.7938 - val_acc: 0.9376 - val_mDice: 0.5929

Epoch 00020: val_mDice improved from 0.58526 to 0.59286, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 21/300
 - 8s - loss: 0.4641 - acc: 0.9222 - mDice: 0.6154 - val_loss: 1.0431 - val_acc: 0.9116 - val_mDice: 0.5278

Epoch 00021: val_mDice did not improve from 0.59286
Epoch 22/300
 - 8s - loss: 0.4588 - acc: 0.9227 - mDice: 0.6188 - val_loss: 0.7846 - val_acc: 0.9346 - val_mDice: 0.5903

Epoch 00022: val_mDice did not improve from 0.59286
Epoch 23/300
 - 9s - loss: 0.4513 - acc: 0.9236 - mDice: 0.6230 - val_loss: 0.7936 - val_acc: 0.9387 - val_mDice: 0.5995

Epoch 00023: val_mDice improved from 0.59286 to 0.59954, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 24/300
 - 8s - loss: 0.4482 - acc: 0.9239 - mDice: 0.6252 - val_loss: 0.7235 - val_acc: 0.9394 - val_mDice: 0.5963

Epoch 00024: val_mDice did not improve from 0.59954
Epoch 25/300
 - 8s - loss: 0.4443 - acc: 0.9243 - mDice: 0.6274 - val_loss: 0.7969 - val_acc: 0.9367 - val_mDice: 0.5917

Epoch 00025: val_mDice did not improve from 0.59954
Epoch 26/300
 - 8s - loss: 0.4410 - acc: 0.9248 - mDice: 0.6298 - val_loss: 0.9185 - val_acc: 0.9196 - val_mDice: 0.5556

Epoch 00026: val_mDice did not improve from 0.59954
Epoch 27/300
 - 8s - loss: 0.5464 - acc: 0.9173 - mDice: 0.5725 - val_loss: 0.7138 - val_acc: 0.9409 - val_mDice: 0.5958

Epoch 00027: val_mDice did not improve from 0.59954
Epoch 28/300
 - 8s - loss: 0.4510 - acc: 0.9237 - mDice: 0.6231 - val_loss: 0.7951 - val_acc: 0.9358 - val_mDice: 0.5944

Epoch 00028: val_mDice did not improve from 0.59954
Epoch 29/300
 - 8s - loss: 0.4371 - acc: 0.9252 - mDice: 0.6320 - val_loss: 0.7293 - val_acc: 0.9347 - val_mDice: 0.5911

Epoch 00029: val_mDice did not improve from 0.59954
Epoch 30/300
 - 8s - loss: 0.4322 - acc: 0.9259 - mDice: 0.6354 - val_loss: 0.8659 - val_acc: 0.9375 - val_mDice: 0.5955

Epoch 00030: val_mDice did not improve from 0.59954
Epoch 31/300
 - 8s - loss: 0.4278 - acc: 0.9261 - mDice: 0.6380 - val_loss: 0.7200 - val_acc: 0.9408 - val_mDice: 0.6088

Epoch 00031: val_mDice improved from 0.59954 to 0.60879, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 32/300
 - 8s - loss: 0.4245 - acc: 0.9266 - mDice: 0.6401 - val_loss: 0.6949 - val_acc: 0.9405 - val_mDice: 0.5890

Epoch 00032: val_mDice did not improve from 0.60879
Epoch 33/300
 - 9s - loss: 0.4227 - acc: 0.9268 - mDice: 0.6413 - val_loss: 0.6872 - val_acc: 0.9378 - val_mDice: 0.5979

Epoch 00033: val_mDice did not improve from 0.60879
Epoch 34/300
 - 8s - loss: 0.4172 - acc: 0.9272 - mDice: 0.6447 - val_loss: 0.8139 - val_acc: 0.9365 - val_mDice: 0.5909

Epoch 00034: val_mDice did not improve from 0.60879
Epoch 35/300
 - 8s - loss: 0.4168 - acc: 0.9272 - mDice: 0.6451 - val_loss: 0.9111 - val_acc: 0.9185 - val_mDice: 0.5490

Epoch 00035: val_mDice did not improve from 0.60879
Epoch 36/300
 - 8s - loss: 0.4133 - acc: 0.9278 - mDice: 0.6473 - val_loss: 0.8829 - val_acc: 0.9294 - val_mDice: 0.5778

Epoch 00036: val_mDice did not improve from 0.60879
Epoch 37/300
 - 9s - loss: 0.4130 - acc: 0.9279 - mDice: 0.6477 - val_loss: 0.9196 - val_acc: 0.9365 - val_mDice: 0.5276

Epoch 00037: val_mDice did not improve from 0.60879
Epoch 38/300
 - 9s - loss: 0.4105 - acc: 0.9282 - mDice: 0.6494 - val_loss: 0.9445 - val_acc: 0.9139 - val_mDice: 0.5263

Epoch 00038: val_mDice did not improve from 0.60879
Epoch 39/300
 - 9s - loss: 0.4904 - acc: 0.9199 - mDice: 0.6025 - val_loss: 0.7910 - val_acc: 0.9382 - val_mDice: 0.5945

Epoch 00039: val_mDice did not improve from 0.60879
Epoch 40/300
 - 9s - loss: 0.4194 - acc: 0.9272 - mDice: 0.6434 - val_loss: 0.7160 - val_acc: 0.9404 - val_mDice: 0.5743

Epoch 00040: val_mDice did not improve from 0.60879
Epoch 41/300
 - 9s - loss: 0.4162 - acc: 0.9278 - mDice: 0.6473 - val_loss: 0.6812 - val_acc: 0.9408 - val_mDice: 0.6005

Epoch 00041: val_mDice did not improve from 0.60879
Epoch 42/300
 - 10s - loss: 0.4101 - acc: 0.9280 - mDice: 0.6500 - val_loss: 0.7348 - val_acc: 0.9374 - val_mDice: 0.5954

Epoch 00042: val_mDice did not improve from 0.60879
Epoch 43/300
 - 9s - loss: 0.4052 - acc: 0.9287 - mDice: 0.6527 - val_loss: 0.6013 - val_acc: 0.9422 - val_mDice: 0.6066

Epoch 00043: val_mDice did not improve from 0.60879
Epoch 44/300
 - 9s - loss: 0.3992 - acc: 0.9294 - mDice: 0.6568 - val_loss: 2.9794 - val_acc: 0.9220 - val_mDice: 0.3687

Epoch 00044: val_mDice did not improve from 0.60879
Epoch 45/300
 - 9s - loss: 0.4909 - acc: 0.9216 - mDice: 0.6008 - val_loss: 0.8852 - val_acc: 0.9287 - val_mDice: 0.5881

Epoch 00045: val_mDice did not improve from 0.60879
Epoch 46/300
 - 9s - loss: 0.4143 - acc: 0.9281 - mDice: 0.6465 - val_loss: 0.9032 - val_acc: 0.9284 - val_mDice: 0.5831

Epoch 00046: val_mDice did not improve from 0.60879
Epoch 47/300
 - 9s - loss: 0.4036 - acc: 0.9290 - mDice: 0.6535 - val_loss: 0.7344 - val_acc: 0.9421 - val_mDice: 0.6098

Epoch 00047: val_mDice improved from 0.60879 to 0.60976, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 48/300
 - 8s - loss: 0.3999 - acc: 0.9297 - mDice: 0.6559 - val_loss: 0.7401 - val_acc: 0.9327 - val_mDice: 0.5813

Epoch 00048: val_mDice did not improve from 0.60976
Epoch 49/300
 - 9s - loss: 0.3947 - acc: 0.9301 - mDice: 0.6595 - val_loss: 0.6489 - val_acc: 0.9403 - val_mDice: 0.5876

Epoch 00049: val_mDice did not improve from 0.60976
Epoch 50/300
 - 8s - loss: 0.3954 - acc: 0.9299 - mDice: 0.6590 - val_loss: 0.7538 - val_acc: 0.9429 - val_mDice: 0.6086

Epoch 00050: val_mDice did not improve from 0.60976
Epoch 51/300
 - 8s - loss: 0.3925 - acc: 0.9305 - mDice: 0.6610 - val_loss: 0.5995 - val_acc: 0.9416 - val_mDice: 0.5990

Epoch 00051: val_mDice did not improve from 0.60976
Epoch 52/300
 - 8s - loss: 0.3895 - acc: 0.9305 - mDice: 0.6629 - val_loss: 0.8351 - val_acc: 0.9378 - val_mDice: 0.6006

Epoch 00052: val_mDice did not improve from 0.60976
Epoch 53/300
 - 9s - loss: 0.3894 - acc: 0.9308 - mDice: 0.6632 - val_loss: 0.8540 - val_acc: 0.9402 - val_mDice: 0.5970

Epoch 00053: val_mDice did not improve from 0.60976
Epoch 54/300
 - 8s - loss: 0.3871 - acc: 0.9309 - mDice: 0.6646 - val_loss: 0.7648 - val_acc: 0.9448 - val_mDice: 0.6106

Epoch 00054: val_mDice improved from 0.60976 to 0.61062, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 55/300
 - 8s - loss: 0.3885 - acc: 0.9311 - mDice: 0.6640 - val_loss: 0.6702 - val_acc: 0.9426 - val_mDice: 0.6061

Epoch 00055: val_mDice did not improve from 0.61062
Epoch 56/300
 - 8s - loss: 0.3888 - acc: 0.9314 - mDice: 0.6655 - val_loss: 0.9161 - val_acc: 0.9269 - val_mDice: 0.5659

Epoch 00056: val_mDice did not improve from 0.61062
Epoch 57/300
 - 8s - loss: 0.3884 - acc: 0.9309 - mDice: 0.6639 - val_loss: 0.7984 - val_acc: 0.9425 - val_mDice: 0.6034

Epoch 00057: val_mDice did not improve from 0.61062
Epoch 58/300
 - 8s - loss: 0.3826 - acc: 0.9315 - mDice: 0.6675 - val_loss: 0.7611 - val_acc: 0.9410 - val_mDice: 0.6086

Epoch 00058: val_mDice did not improve from 0.61062
Epoch 59/300
 - 8s - loss: 0.3813 - acc: 0.9317 - mDice: 0.6686 - val_loss: 0.7901 - val_acc: 0.9428 - val_mDice: 0.6099

Epoch 00059: val_mDice did not improve from 0.61062
Epoch 60/300
 - 9s - loss: 0.3789 - acc: 0.9318 - mDice: 0.6699 - val_loss: 0.7380 - val_acc: 0.9372 - val_mDice: 0.6005

Epoch 00060: val_mDice did not improve from 0.61062
Epoch 61/300
 - 8s - loss: 0.3781 - acc: 0.9320 - mDice: 0.6706 - val_loss: 0.6958 - val_acc: 0.9427 - val_mDice: 0.6065

Epoch 00061: val_mDice did not improve from 0.61062
Epoch 62/300
 - 8s - loss: 0.3800 - acc: 0.9319 - mDice: 0.6696 - val_loss: 0.6305 - val_acc: 0.9338 - val_mDice: 0.5842

Epoch 00062: val_mDice did not improve from 0.61062
Epoch 63/300
 - 8s - loss: 0.3768 - acc: 0.9321 - mDice: 0.6714 - val_loss: 0.8089 - val_acc: 0.9286 - val_mDice: 0.5781

Epoch 00063: val_mDice did not improve from 0.61062
Epoch 64/300
 - 8s - loss: 0.3739 - acc: 0.9324 - mDice: 0.6733 - val_loss: 0.7708 - val_acc: 0.9433 - val_mDice: 0.6123

Epoch 00064: val_mDice improved from 0.61062 to 0.61233, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 65/300
 - 8s - loss: 0.3715 - acc: 0.9328 - mDice: 0.6750 - val_loss: 0.8256 - val_acc: 0.9402 - val_mDice: 0.6060

Epoch 00065: val_mDice did not improve from 0.61233
Epoch 66/300
 - 8s - loss: 0.3742 - acc: 0.9326 - mDice: 0.6734 - val_loss: 0.7091 - val_acc: 0.9344 - val_mDice: 0.5907

Epoch 00066: val_mDice did not improve from 0.61233
Epoch 67/300
 - 8s - loss: 0.3718 - acc: 0.9328 - mDice: 0.6751 - val_loss: 0.6196 - val_acc: 0.9438 - val_mDice: 0.6100

Epoch 00067: val_mDice did not improve from 0.61233
Epoch 68/300
 - 8s - loss: 0.3747 - acc: 0.9328 - mDice: 0.6747 - val_loss: 0.8792 - val_acc: 0.9382 - val_mDice: 0.5941

Epoch 00068: val_mDice did not improve from 0.61233
Epoch 69/300
 - 9s - loss: 0.3695 - acc: 0.9331 - mDice: 0.6766 - val_loss: 0.5446 - val_acc: 0.9440 - val_mDice: 0.6164

Epoch 00069: val_mDice improved from 0.61233 to 0.61635, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 70/300
 - 9s - loss: 0.3707 - acc: 0.9330 - mDice: 0.6762 - val_loss: 0.7851 - val_acc: 0.9425 - val_mDice: 0.5771

Epoch 00070: val_mDice did not improve from 0.61635
Epoch 71/300
 - 8s - loss: 0.3682 - acc: 0.9332 - mDice: 0.6774 - val_loss: 0.6086 - val_acc: 0.9443 - val_mDice: 0.6087

Epoch 00071: val_mDice did not improve from 0.61635
Epoch 72/300
 - 8s - loss: 0.3652 - acc: 0.9334 - mDice: 0.6795 - val_loss: 0.7874 - val_acc: 0.9437 - val_mDice: 0.6095

Epoch 00072: val_mDice did not improve from 0.61635
Epoch 73/300
 - 8s - loss: 0.3681 - acc: 0.9331 - mDice: 0.6775 - val_loss: 0.8973 - val_acc: 0.9210 - val_mDice: 0.5458

Epoch 00073: val_mDice did not improve from 0.61635
Epoch 74/300
 - 8s - loss: 0.3647 - acc: 0.9334 - mDice: 0.6798 - val_loss: 0.9009 - val_acc: 0.9267 - val_mDice: 0.5627

Epoch 00074: val_mDice did not improve from 0.61635
Epoch 75/300
 - 8s - loss: 0.3633 - acc: 0.9335 - mDice: 0.6809 - val_loss: 0.6052 - val_acc: 0.9452 - val_mDice: 0.6127

Epoch 00075: val_mDice did not improve from 0.61635
Epoch 76/300
 - 8s - loss: 0.3626 - acc: 0.9337 - mDice: 0.6813 - val_loss: 0.7661 - val_acc: 0.9356 - val_mDice: 0.5980

Epoch 00076: val_mDice did not improve from 0.61635
Epoch 77/300
 - 9s - loss: 0.3617 - acc: 0.9337 - mDice: 0.6819 - val_loss: 0.5823 - val_acc: 0.9453 - val_mDice: 0.6070

Epoch 00077: val_mDice did not improve from 0.61635
Epoch 78/300
 - 8s - loss: 0.3613 - acc: 0.9340 - mDice: 0.6824 - val_loss: 0.8145 - val_acc: 0.9408 - val_mDice: 0.5992

Epoch 00078: val_mDice did not improve from 0.61635
Epoch 79/300
 - 8s - loss: 0.3603 - acc: 0.9340 - mDice: 0.6831 - val_loss: 0.6196 - val_acc: 0.9389 - val_mDice: 0.6000

Epoch 00079: val_mDice did not improve from 0.61635
Epoch 80/300
 - 8s - loss: 0.3614 - acc: 0.9339 - mDice: 0.6822 - val_loss: 0.8226 - val_acc: 0.9419 - val_mDice: 0.6083

Epoch 00080: val_mDice did not improve from 0.61635
Epoch 81/300
 - 8s - loss: 0.3570 - acc: 0.9343 - mDice: 0.6852 - val_loss: 0.6362 - val_acc: 0.9407 - val_mDice: 0.6001

Epoch 00081: val_mDice did not improve from 0.61635
Epoch 82/300
 - 8s - loss: 0.3587 - acc: 0.9340 - mDice: 0.6841 - val_loss: 0.6237 - val_acc: 0.9381 - val_mDice: 0.5885

Epoch 00082: val_mDice did not improve from 0.61635
Epoch 83/300
 - 8s - loss: 0.3585 - acc: 0.9344 - mDice: 0.6844 - val_loss: 0.6145 - val_acc: 0.9428 - val_mDice: 0.6086

Epoch 00083: val_mDice did not improve from 0.61635
Epoch 84/300
 - 9s - loss: 0.3575 - acc: 0.9343 - mDice: 0.6851 - val_loss: 0.7723 - val_acc: 0.9407 - val_mDice: 0.6081

Epoch 00084: val_mDice did not improve from 0.61635
Epoch 85/300
 - 9s - loss: 0.3558 - acc: 0.9346 - mDice: 0.6861 - val_loss: 0.7979 - val_acc: 0.9440 - val_mDice: 0.6112

Epoch 00085: val_mDice did not improve from 0.61635
Epoch 86/300
 - 8s - loss: 0.3528 - acc: 0.9349 - mDice: 0.6881 - val_loss: 0.5812 - val_acc: 0.9448 - val_mDice: 0.6126

Epoch 00086: val_mDice did not improve from 0.61635
Epoch 87/300
 - 8s - loss: 0.3522 - acc: 0.9348 - mDice: 0.6887 - val_loss: 0.7302 - val_acc: 0.9437 - val_mDice: 0.6116

Epoch 00087: val_mDice did not improve from 0.61635
Epoch 88/300
 - 8s - loss: 0.3519 - acc: 0.9348 - mDice: 0.6888 - val_loss: 0.8274 - val_acc: 0.9397 - val_mDice: 0.5986

Epoch 00088: val_mDice did not improve from 0.61635
Epoch 89/300
 - 8s - loss: 0.3539 - acc: 0.9347 - mDice: 0.6877 - val_loss: 0.5148 - val_acc: 0.9454 - val_mDice: 0.6182

Epoch 00089: val_mDice improved from 0.61635 to 0.61822, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 90/300
 - 8s - loss: 0.3489 - acc: 0.9351 - mDice: 0.6909 - val_loss: 0.8244 - val_acc: 0.9339 - val_mDice: 0.5884

Epoch 00090: val_mDice did not improve from 0.61822
Epoch 91/300
 - 8s - loss: 0.3493 - acc: 0.9350 - mDice: 0.6907 - val_loss: 0.8236 - val_acc: 0.9449 - val_mDice: 0.6148

Epoch 00091: val_mDice did not improve from 0.61822
Epoch 92/300
 - 8s - loss: 0.3483 - acc: 0.9352 - mDice: 0.6913 - val_loss: 0.7768 - val_acc: 0.9391 - val_mDice: 0.6003

Epoch 00092: val_mDice did not improve from 0.61822
Epoch 93/300
 - 8s - loss: 0.3503 - acc: 0.9348 - mDice: 0.6901 - val_loss: 0.8385 - val_acc: 0.9436 - val_mDice: 0.5887

Epoch 00093: val_mDice did not improve from 0.61822
Epoch 94/300
 - 9s - loss: 0.3638 - acc: 0.9335 - mDice: 0.6809 - val_loss: 0.7745 - val_acc: 0.9436 - val_mDice: 0.6128

Epoch 00094: val_mDice did not improve from 0.61822
Epoch 95/300
 - 9s - loss: 0.3483 - acc: 0.9352 - mDice: 0.6914 - val_loss: 0.7726 - val_acc: 0.9448 - val_mDice: 0.6085

Epoch 00095: val_mDice did not improve from 0.61822
Epoch 96/300
 - 8s - loss: 0.3483 - acc: 0.9351 - mDice: 0.6916 - val_loss: 0.8526 - val_acc: 0.9390 - val_mDice: 0.5942

Epoch 00096: val_mDice did not improve from 0.61822
Epoch 97/300
 - 8s - loss: 0.3485 - acc: 0.9352 - mDice: 0.6914 - val_loss: 0.6319 - val_acc: 0.9454 - val_mDice: 0.6135

Epoch 00097: val_mDice did not improve from 0.61822
Epoch 98/300
 - 8s - loss: 0.3453 - acc: 0.9356 - mDice: 0.6936 - val_loss: 0.6871 - val_acc: 0.9399 - val_mDice: 0.6045

Epoch 00098: val_mDice did not improve from 0.61822
Epoch 99/300
 - 8s - loss: 0.3453 - acc: 0.9355 - mDice: 0.6936 - val_loss: 0.9610 - val_acc: 0.9414 - val_mDice: 0.5542

Epoch 00099: val_mDice did not improve from 0.61822
Epoch 100/300
 - 8s - loss: 0.3472 - acc: 0.9357 - mDice: 0.6939 - val_loss: 0.6022 - val_acc: 0.9413 - val_mDice: 0.6060

Epoch 00100: val_mDice did not improve from 0.61822
Epoch 101/300
 - 8s - loss: 0.3449 - acc: 0.9358 - mDice: 0.6939 - val_loss: 0.6005 - val_acc: 0.9450 - val_mDice: 0.6160

Epoch 00101: val_mDice did not improve from 0.61822
Epoch 102/300
 - 8s - loss: 0.3435 - acc: 0.9357 - mDice: 0.6947 - val_loss: 0.5488 - val_acc: 0.9469 - val_mDice: 0.6100

Epoch 00102: val_mDice did not improve from 0.61822
Epoch 103/300
 - 8s - loss: 0.3415 - acc: 0.9359 - mDice: 0.6962 - val_loss: 0.5173 - val_acc: 0.9467 - val_mDice: 0.6153

Epoch 00103: val_mDice did not improve from 0.61822
Epoch 104/300
 - 9s - loss: 0.3431 - acc: 0.9358 - mDice: 0.6952 - val_loss: 0.6015 - val_acc: 0.9379 - val_mDice: 0.5964

Epoch 00104: val_mDice did not improve from 0.61822
Epoch 105/300
 - 11s - loss: 0.3431 - acc: 0.9359 - mDice: 0.6952 - val_loss: 0.7549 - val_acc: 0.9445 - val_mDice: 0.6131

Epoch 00105: val_mDice did not improve from 0.61822
Epoch 106/300
 - 10s - loss: 0.3421 - acc: 0.9359 - mDice: 0.6960 - val_loss: 0.8968 - val_acc: 0.9303 - val_mDice: 0.5731

Epoch 00106: val_mDice did not improve from 0.61822
Epoch 107/300
 - 10s - loss: 0.3423 - acc: 0.9360 - mDice: 0.6960 - val_loss: 0.5349 - val_acc: 0.9422 - val_mDice: 0.6117

Epoch 00107: val_mDice did not improve from 0.61822
Epoch 108/300
 - 10s - loss: 0.3399 - acc: 0.9362 - mDice: 0.6975 - val_loss: 0.6361 - val_acc: 0.9348 - val_mDice: 0.5944

Epoch 00108: val_mDice did not improve from 0.61822
Epoch 109/300
 - 11s - loss: 0.3400 - acc: 0.9361 - mDice: 0.6973 - val_loss: 0.8045 - val_acc: 0.9404 - val_mDice: 0.5441

Epoch 00109: val_mDice did not improve from 0.61822
Epoch 110/300
 - 10s - loss: 0.3382 - acc: 0.9362 - mDice: 0.6985 - val_loss: 0.6799 - val_acc: 0.9411 - val_mDice: 0.6049

Epoch 00110: val_mDice did not improve from 0.61822
Epoch 111/300
 - 10s - loss: 0.3380 - acc: 0.9363 - mDice: 0.6987 - val_loss: 0.6616 - val_acc: 0.9313 - val_mDice: 0.5772

Epoch 00111: val_mDice did not improve from 0.61822
Epoch 112/300
 - 11s - loss: 0.3386 - acc: 0.9362 - mDice: 0.6984 - val_loss: 0.6231 - val_acc: 0.9450 - val_mDice: 0.6089

Epoch 00112: val_mDice did not improve from 0.61822
Epoch 113/300
 - 10s - loss: 0.3373 - acc: 0.9365 - mDice: 0.6992 - val_loss: 0.6149 - val_acc: 0.9434 - val_mDice: 0.6096

Epoch 00113: val_mDice did not improve from 0.61822
Epoch 114/300
 - 10s - loss: 0.3372 - acc: 0.9366 - mDice: 0.6993 - val_loss: 0.6942 - val_acc: 0.9458 - val_mDice: 0.6171

Epoch 00114: val_mDice did not improve from 0.61822
Epoch 115/300
 - 10s - loss: 0.3374 - acc: 0.9364 - mDice: 0.6993 - val_loss: 0.7662 - val_acc: 0.9371 - val_mDice: 0.6008

Epoch 00115: val_mDice did not improve from 0.61822
Epoch 116/300
 - 10s - loss: 0.3370 - acc: 0.9364 - mDice: 0.6996 - val_loss: 0.5814 - val_acc: 0.9458 - val_mDice: 0.6121

Epoch 00116: val_mDice did not improve from 0.61822
Epoch 117/300
 - 9s - loss: 0.3365 - acc: 0.9366 - mDice: 0.7001 - val_loss: 0.8056 - val_acc: 0.9460 - val_mDice: 0.6106

Epoch 00117: val_mDice did not improve from 0.61822
Epoch 118/300
 - 10s - loss: 0.3377 - acc: 0.9367 - mDice: 0.7009 - val_loss: 0.8051 - val_acc: 0.9465 - val_mDice: 0.6168

Epoch 00118: val_mDice did not improve from 0.61822
Epoch 119/300
 - 10s - loss: 0.3360 - acc: 0.9365 - mDice: 0.7003 - val_loss: 0.5811 - val_acc: 0.9450 - val_mDice: 0.6145

Epoch 00119: val_mDice did not improve from 0.61822
Epoch 120/300
 - 10s - loss: 0.3345 - acc: 0.9367 - mDice: 0.7013 - val_loss: 0.8507 - val_acc: 0.9441 - val_mDice: 0.5943

Epoch 00120: val_mDice did not improve from 0.61822
Epoch 121/300
 - 10s - loss: 0.3341 - acc: 0.9368 - mDice: 0.7018 - val_loss: 0.6242 - val_acc: 0.9461 - val_mDice: 0.6030

Epoch 00121: val_mDice did not improve from 0.61822
Epoch 122/300
 - 10s - loss: 0.3333 - acc: 0.9367 - mDice: 0.7021 - val_loss: 0.5976 - val_acc: 0.9421 - val_mDice: 0.6087

Epoch 00122: val_mDice did not improve from 0.61822
Epoch 123/300
 - 10s - loss: 0.3325 - acc: 0.9370 - mDice: 0.7029 - val_loss: 0.6778 - val_acc: 0.9401 - val_mDice: 0.5671

Epoch 00123: val_mDice did not improve from 0.61822
Epoch 124/300
 - 11s - loss: 0.3557 - acc: 0.9347 - mDice: 0.6860 - val_loss: 2.4227 - val_acc: 0.9327 - val_mDice: 0.4529

Epoch 00124: val_mDice did not improve from 0.61822
Epoch 125/300
 - 10s - loss: 0.3343 - acc: 0.9370 - mDice: 0.7013 - val_loss: 0.6654 - val_acc: 0.9396 - val_mDice: 0.6011

Epoch 00125: val_mDice did not improve from 0.61822
Epoch 126/300
 - 11s - loss: 0.3336 - acc: 0.9368 - mDice: 0.7018 - val_loss: 0.6152 - val_acc: 0.9464 - val_mDice: 0.6175

Epoch 00126: val_mDice did not improve from 0.61822
Epoch 127/300
 - 10s - loss: 0.3324 - acc: 0.9372 - mDice: 0.7030 - val_loss: 0.6003 - val_acc: 0.9432 - val_mDice: 0.6124

Epoch 00127: val_mDice did not improve from 0.61822
Epoch 128/300
 - 10s - loss: 0.3316 - acc: 0.9372 - mDice: 0.7033 - val_loss: 0.8001 - val_acc: 0.9441 - val_mDice: 0.6088

Epoch 00128: val_mDice did not improve from 0.61822
Epoch 129/300
 - 10s - loss: 0.3301 - acc: 0.9372 - mDice: 0.7044 - val_loss: 0.7784 - val_acc: 0.9392 - val_mDice: 0.6048

Epoch 00129: val_mDice did not improve from 0.61822
Restoring model weights from the end of the best epoch
Epoch 00129: early stopping
{'val_loss': [5.163234983171735, 1.9120362145560128, 1.2863816363470895, 1.361497930118016, 1.1070080314363753, 2.055775897843497, 0.9897085513387408, 0.9998464073453631, 1.0230699266706194, 0.8483658943857465, 0.8961858068193708, 0.7655844688415527, 0.790759631565639, 0.760635427066258, 0.8737450327192035, 0.8624701755387443, 0.9279252801622663, 0.8267525519643512, 0.8367217353412083, 0.7938332557678223, 1.0431450775691442, 0.7845724906240191, 0.793580344745091, 0.7235419920512608, 0.7968797939164298, 0.9185262407575335, 0.7138386198452541, 0.7951315811702183, 0.7293433376720974, 0.865872859954834, 0.719974764755794, 0.6949355431965419, 0.6872366751943316, 0.8139187438147408, 0.9110825742994036, 0.8828577058655875, 0.9196128334317889, 0.9444772175380162, 0.7910111801964896, 0.716002345085144, 0.6811592067990985, 0.7348316056387765, 0.601310738495418, 2.9793837581362044, 0.8851504581315177, 0.9032377770968846, 0.7343501278332302, 0.7401027083396912, 0.6488932711737496, 0.7537741150174823, 0.5994977355003357, 0.8350588423865182, 0.854010454245976, 0.7648356642041888, 0.6702403596469334, 0.9161440134048462, 0.7983935901096889, 0.7611491169248309, 0.7901461890765599, 0.7380418522017342, 0.6957746999604362, 0.6304524115153721, 0.8089345949036735, 0.7708251476287842, 0.8256157296044486, 0.709057901586805, 0.6196161508560181, 0.8792176416942051, 0.5446443898337228, 0.7850831236158099, 0.6086121456963676, 0.7873926418168204, 0.8973141057150704, 0.9008578402655465, 0.6052086523600987, 0.7661246912819999, 0.5823418412889753, 0.8144932474408831, 0.6195601650646755, 0.8226189698491778, 0.6361765520913261, 0.6236877867153713, 0.6144547547612872, 0.7723055567060199, 0.7978961723191398, 0.5812203628676278, 0.7302409751074654, 0.8274055804525103, 0.5147891555513654, 0.8244102341788155, 0.8236151593072074, 0.7767894353185382, 0.8384561538696289, 0.7744930812290737, 0.7726058108466012, 0.8526163016046796, 0.6319144879068647, 0.6870590448379517, 0.9610140408788409, 0.6022460120064872, 0.6005480970655169, 0.5488461000578744, 0.5173239878245762, 0.6015256898743766, 0.754885366984776, 0.8967593056815011, 0.5349248903138297, 0.6360974737576076, 0.8045000093323844, 0.6798797334943499, 0.6616224050521851, 0.6230982627187457, 0.6148599215916225, 0.6942410469055176, 0.7662029947553363, 0.5813887374741691, 0.8056467260633197, 0.8051264371190753, 0.5811344299997602, 0.850727345262255, 0.6242190258843558, 0.5975909233093262, 0.6778048021452767, 2.422706059047154, 0.6654463410377502, 0.6151779123714992, 0.6003313149724688, 0.8001044137137276, 0.7784395813941956], 'val_acc': [0.9061643055507115, 0.8988867061478751, 0.9169296196528843, 0.8842987843922206, 0.9108268022537231, 0.9160871079989842, 0.9298338549477714, 0.918710104056767, 0.910422546522958, 0.9351648347718375, 0.9343171034540448, 0.9370094111987523, 0.9363919496536255, 0.934954217502049, 0.9223770328930446, 0.933332017489842, 0.9248469386781965, 0.9289377331733704, 0.9262153335980007, 0.9376007403646197, 0.9115947314671108, 0.9346114652497428, 0.9386773960930961, 0.9394126108714512, 0.9367464695658002, 0.9195800679070609, 0.9408856630325317, 0.9358241728373936, 0.9347448945045471, 0.9374895351273673, 0.9407613788332257, 0.9405468191419329, 0.9377629501479012, 0.9364782742091587, 0.918469386441367, 0.9293772918837411, 0.9364822081157139, 0.9138670989445278, 0.938168500150953, 0.9403924771717617, 0.9407561506543841, 0.9374424474579948, 0.9422161323683602, 0.9219819477626255, 0.9286656209400722, 0.9284484556743077, 0.9421350104468209, 0.932713236127581, 0.9403165834290641, 0.9428689054080418, 0.9416143383298602, 0.9378152659961155, 0.9402315446308681, 0.9448299407958984, 0.9426491260528564, 0.9269217678478786, 0.9424633724348885, 0.9410439559391567, 0.942789111818586, 0.9371729493141174, 0.9427263140678406, 0.933762422629765, 0.9286446741649083, 0.943341178553445, 0.9401661327907017, 0.9344191466059003, 0.9437951445579529, 0.9381685086659023, 0.9440227576664516, 0.9424607583454677, 0.9442582385880607, 0.9436564530645098, 0.9210426551955087, 0.9267058968544006, 0.9451910001891, 0.9355965341840472, 0.9453414508274623, 0.940805869443076, 0.9388814738818577, 0.9418851477759225, 0.9407299842153277, 0.9380612203053066, 0.9428362165178571, 0.9407221334321159, 0.9439534374645778, 0.9447998404502869, 0.9437140226364136, 0.9396781665938241, 0.9453741567475455, 0.933856623513358, 0.9449045062065125, 0.9391483579363141, 0.9436028259141105, 0.9436211585998535, 0.9447880642754691, 0.9389939819063459, 0.9454343318939209, 0.9398783445358276, 0.9413893478257316, 0.9413304669516427, 0.9449816857065473, 0.9469427125794547, 0.946738634790693, 0.9378505945205688, 0.9444505402020046, 0.9303349086216518, 0.9421742558479309, 0.9347514425005231, 0.9404055561338153, 0.9410504954201835, 0.9313173890113831, 0.9450366241591317, 0.9434484669140407, 0.9458346537181309, 0.9371258616447449, 0.9457600797925677, 0.9460112537656512, 0.9465293032782418, 0.945032707282475, 0.9440724934850421, 0.9461106743131366, 0.9421206286975315, 0.940099435193198, 0.9326582891600472, 0.9396219168390546, 0.9463710103716169, 0.9431776574679783, 0.9440515381949288, 0.9391640595027378], 'val_mDice': [0.0875020974448749, 0.27632468938827515, 0.4018017479351589, 0.4093234964779445, 0.47699491466794697, 0.3620507972581046, 0.5168476104736328, 0.5301472970417568, 0.5153208800724575, 0.5680599723543439, 0.5622406601905823, 0.5709203311375209, 0.5851887209074838, 0.5819323062896729, 0.5489686131477356, 0.5852630478995187, 0.5675167441368103, 0.5648701786994934, 0.5646577903202602, 0.5928629977362496, 0.5278304134096418, 0.590346268245152, 0.5995417237281799, 0.5962731838226318, 0.5916937334196908, 0.555563611643655, 0.5958039505141122, 0.5943682789802551, 0.5910738025392804, 0.5955330559185573, 0.6087920665740967, 0.589042169707162, 0.5978548952511379, 0.5908668296677726, 0.5489902751786369, 0.57778057881764, 0.5276150277682713, 0.5262670516967773, 0.5945203815187726, 0.5743208016668048, 0.6005316802433559, 0.5954468250274658, 0.606556875365121, 0.3687196203640529, 0.5880759102957589, 0.5831360476357597, 0.6097578746931893, 0.5812534775052752, 0.5876330733299255, 0.6086236579077584, 0.5989530427115304, 0.6006327271461487, 0.5969673224857875, 0.610620881829943, 0.6061175550733294, 0.5658611740384784, 0.6034302370888847, 0.6085712058203561, 0.6099469661712646, 0.6005007539476667, 0.6064778140613011, 0.5841505782944816, 0.578140105519976, 0.6123275075639997, 0.6059914571898324, 0.5907179117202759, 0.6100289140428815, 0.5941046816962106, 0.6163537161690849, 0.5770724586078099, 0.6086958987372262, 0.6094739948000226, 0.5457784022603717, 0.5626953755106244, 0.6127486910138812, 0.598007151058742, 0.6069963148662022, 0.5992189475468227, 0.60003148657935, 0.6083288363048008, 0.6001198291778564, 0.5885468465941293, 0.6085678168705532, 0.6080916353634426, 0.6112435119492667, 0.6125539541244507, 0.6115865537098476, 0.5985873597008842, 0.6182215639523098, 0.588415435382298, 0.6148428831781659, 0.600339242390224, 0.5887486934661865, 0.6127974476133075, 0.6085287162235805, 0.5941598670823234, 0.6134628142629351, 0.6044992549078805, 0.554226815700531, 0.605971736567361, 0.6159577880586896, 0.6099593979971749, 0.6152947800500053, 0.5963740519114903, 0.6131355166435242, 0.5730812634740557, 0.6116850887026105, 0.5943773133414132, 0.5440782564026969, 0.6048803159168789, 0.577166029385158, 0.6089340959276471, 0.6095993944576809, 0.6170927200998578, 0.600797780922481, 0.612079416002546, 0.6106122136116028, 0.6167509640966143, 0.6145134312765939, 0.5942856073379517, 0.6030482309205192, 0.6087248580796378, 0.5671062554631915, 0.4528822260243552, 0.6011249678475517, 0.6174748965672084, 0.6124275326728821, 0.6088268331118992, 0.604753417628152], 'loss': [2.8246088959938063, 1.4820623829254822, 1.1479737366156264, 0.9660497393123691, 0.8261959018458312, 0.7309634690525677, 0.6724913383446918, 0.6338318334944246, 0.602690804948926, 0.5781822253055013, 0.5542265736752416, 0.5397339232617384, 0.5259160191424943, 0.5176246152578852, 0.5056571704159891, 0.5020393915932297, 0.4891743758030581, 0.48322436286441567, 0.477799583588444, 0.47849393479212177, 0.46405410783194934, 0.4588370314947083, 0.4513100052890513, 0.4482146701131226, 0.44428691883800486, 0.4410491665755391, 0.5463937750752076, 0.45104862543724833, 0.4370550634242592, 0.4321712316873382, 0.4278136084956123, 0.4244918457060905, 0.42266055031764005, 0.417206668273931, 0.416824136402492, 0.41329368018142215, 0.41301031470336336, 0.41050288073342067, 0.4904288208457098, 0.4194087644393034, 0.4161593635639031, 0.4100620936090073, 0.4051760099730405, 0.39920630917377314, 0.4908571848912905, 0.4143323780502488, 0.4036109303148219, 0.39993412552704916, 0.3947335194077408, 0.39544373883120537, 0.39253190242451447, 0.38951852851610796, 0.38935726910456975, 0.3871114996253774, 0.3884934609784638, 0.3887578332132371, 0.3884049202761163, 0.3825908740981435, 0.38125889797410567, 0.378946327711682, 0.37812888706190045, 0.3799920947295751, 0.37681315959670836, 0.3738908085117747, 0.37149915784168475, 0.3742009273708988, 0.3718469103058417, 0.37466600418641843, 0.3694636089196412, 0.37069564631649243, 0.3681656888101341, 0.36522390970112784, 0.36811714758641556, 0.36471886652797597, 0.36326885583120455, 0.36255898612401405, 0.36174401028502673, 0.36134065290824346, 0.3602527486030664, 0.36140525358566555, 0.35695700878568, 0.35868803786560194, 0.3584505848454282, 0.3575106570200705, 0.35580174760641153, 0.35283539808401354, 0.35220340447198417, 0.3518985729437188, 0.3538982644684989, 0.3489350035437542, 0.34933166479360583, 0.3482955407915978, 0.3502580476090216, 0.3638104566450517, 0.3482521227746341, 0.34829972202392895, 0.3484755281121406, 0.34533919552279463, 0.3453227955104799, 0.3472373652062455, 0.34491130688358523, 0.3434602591323682, 0.3414852188995799, 0.3430840658163471, 0.3430682008244408, 0.3420693228031635, 0.34233113114592634, 0.3399469493874132, 0.3400141582235793, 0.33817353027184255, 0.33800119082395963, 0.33861384486085117, 0.337294647042172, 0.33723139804518387, 0.33742926476795465, 0.3369511834794151, 0.3365061822771863, 0.3377426980310459, 0.33598167489388747, 0.33448981613543793, 0.3341193215030997, 0.33333757355979843, 0.33250006525841364, 0.355732250923068, 0.33434973584026434, 0.33357883982140424, 0.3323512953336355, 0.33160862879212605, 0.3301470799817547], 'acc': [0.7727016814680007, 0.879397823143336, 0.8862350014080357, 0.8916290465529845, 0.897865874093049, 0.9034329391049292, 0.906754545910492, 0.9088695313715361, 0.9110444748347791, 0.9125647137415285, 0.9138168619327504, 0.9152387117610683, 0.9161446241160779, 0.9173002305533258, 0.9184720725719637, 0.9186393955335207, 0.9200499348247712, 0.9202606458287741, 0.9210772117918211, 0.9208114515559139, 0.9221637702085902, 0.9226685447193943, 0.9235898248224351, 0.9239307185947074, 0.924255981404236, 0.9247560885000384, 0.9173233937485802, 0.9237300919902864, 0.9251760346434399, 0.9259024595172356, 0.9261230055881856, 0.9265555075980971, 0.9268306946664288, 0.927169952150628, 0.9272411185185541, 0.927803829902485, 0.9278634748096688, 0.9281579282982834, 0.9199420917070467, 0.927201144271243, 0.9278244397096467, 0.928025865256755, 0.9287211444400691, 0.9293639926753108, 0.9216419176615039, 0.9280886145208623, 0.929025311644857, 0.9296510849182865, 0.930058933191032, 0.929882643327754, 0.9304836929339122, 0.9305437238342384, 0.930783965981098, 0.9309148240557787, 0.9310970320673047, 0.9313821993163183, 0.9309484671238955, 0.9314937929118277, 0.9316503652154754, 0.9318121522586753, 0.9319846668605583, 0.9318593399954739, 0.9321121344083948, 0.9324157494170686, 0.9328184276020869, 0.9326316530256915, 0.9327810056596033, 0.9328361784338588, 0.9330734138178692, 0.9330311576625556, 0.9331956633951424, 0.9333742636882378, 0.9330861866943775, 0.9333796715934257, 0.9334724630762492, 0.9336925978319449, 0.9337006992421639, 0.9339860868574204, 0.9340186495592594, 0.933913719022909, 0.9342534546466895, 0.933994358797411, 0.9343942016635526, 0.9343296255505827, 0.9346116190635929, 0.9348752613841066, 0.9348072218273803, 0.9347627050787201, 0.93472761188138, 0.9350943373824784, 0.93498803458052, 0.9352145186992412, 0.9348332433906444, 0.9335479784542828, 0.9352079048128186, 0.935141212969771, 0.9352175023002476, 0.9356406720474321, 0.9355410047158034, 0.9357219900400126, 0.9357776399457238, 0.935666211783003, 0.9358973396539513, 0.9357907692729106, 0.9359096766945845, 0.9359345932206707, 0.9360305081647113, 0.9362143257082804, 0.9361455389175711, 0.9362311138614835, 0.9363233974744122, 0.9362252220873046, 0.9365059171282503, 0.9365659954480506, 0.936392157934884, 0.936397160254227, 0.9365552689601098, 0.9366860065293394, 0.9365395388691875, 0.9367167201471975, 0.9368162676684182, 0.9366795357967552, 0.9369579238204824, 0.9347218187344476, 0.9369791138571643, 0.9367984670502685, 0.9371866224154991, 0.9371926580823912, 0.9372354194088285], 'mDice': [0.10363422674984475, 0.25899317432306485, 0.3297565483830283, 0.3780472208026177, 0.4290981622776172, 0.4736111078684114, 0.5017511151846072, 0.5210925218863377, 0.5377497119630056, 0.5513861172839691, 0.5634359930828723, 0.5717185959744345, 0.5799429361616593, 0.5844185548440313, 0.5914419129411016, 0.5934462493639907, 0.6006989542996386, 0.6040010654772263, 0.607165633874451, 0.6073218010368311, 0.6154204960292171, 0.6187722266302701, 0.6230388304392998, 0.6251685681657664, 0.6274468822005367, 0.6297792901586041, 0.5724865091937795, 0.6230589378617719, 0.6319991798007146, 0.6353810013235962, 0.6379563925471398, 0.6400885951157089, 0.6412532575579548, 0.6447353126785061, 0.6450889537734937, 0.6472853063998546, 0.6476828942016865, 0.6494435840312242, 0.6025064890218615, 0.6433936011604632, 0.6472962087337079, 0.6499689021635512, 0.6526931012887791, 0.6567504548365259, 0.6007555179115553, 0.6465405821111451, 0.6534826041820834, 0.65588321057998, 0.6595063084175462, 0.6590227084521023, 0.6609662393146558, 0.6629426292742434, 0.6631773777438357, 0.6646299994045702, 0.6640486507145769, 0.6655083130683102, 0.6638548878489303, 0.6675083841116868, 0.6685927610635782, 0.6699056112098773, 0.670576175078961, 0.6695778882419603, 0.6714311009420669, 0.6733111706472819, 0.6750389022202987, 0.6734424096744769, 0.6751124376834396, 0.6747320216172181, 0.6766076322137364, 0.6761803012495845, 0.677383581884945, 0.6795049944411357, 0.6775070466042467, 0.6798190831612083, 0.6808563058072497, 0.6813269022232671, 0.6819246946757225, 0.6824247702315946, 0.6830644726076976, 0.6822031373448677, 0.6852289847634346, 0.6841209505345468, 0.6844359676381322, 0.6851459519429071, 0.6861312818422026, 0.6881295849087484, 0.6887217707550818, 0.6888118692776375, 0.6876531484460415, 0.6908994569712319, 0.690668779507018, 0.6913029151386618, 0.6901222002870684, 0.6809112978076745, 0.6914414076985951, 0.6916176640620464, 0.6913766934097985, 0.6936094291208421, 0.6935920078334393, 0.6939264118126653, 0.6939146225098515, 0.6946696530922282, 0.6962010675912295, 0.6951951724364109, 0.6951665031032059, 0.6959863682481493, 0.6959975640404836, 0.6974851456819581, 0.6972789563154871, 0.6985400419661523, 0.6987483151971648, 0.6983579666515097, 0.6991802974400468, 0.6993218183592596, 0.6993179775634375, 0.6996238713805972, 0.7000596657534685, 0.7008774179985999, 0.7002776075729441, 0.7012711777408054, 0.7017982884707703, 0.7020957423416128, 0.7029234837278472, 0.6860162820156313, 0.7012850657795793, 0.7018431960277816, 0.7030410799412607, 0.7033407819134584, 0.7044126430921838]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:03<00:14,  3.62s/it]predicting test subjects:  40%|████      | 2/5 [00:06<00:10,  3.40s/it]predicting test subjects:  60%|██████    | 3/5 [00:08<00:06,  3.10s/it]predicting test subjects:  80%|████████  | 4/5 [00:11<00:02,  2.96s/it]predicting test subjects: 100%|██████████| 5/5 [00:14<00:00,  3.01s/it]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:03<15:38,  3.54s/it]predicting train subjects:   1%|          | 2/266 [00:06<15:23,  3.50s/it]predicting train subjects:   1%|          | 3/266 [00:09<14:35,  3.33s/it]predicting train subjects:   2%|▏         | 4/266 [00:12<13:37,  3.12s/it]predicting train subjects:   2%|▏         | 5/266 [00:15<13:47,  3.17s/it]predicting train subjects:   2%|▏         | 6/266 [00:19<14:05,  3.25s/it]predicting train subjects:   3%|▎         | 7/266 [00:22<14:14,  3.30s/it]predicting train subjects:   3%|▎         | 8/266 [00:26<14:23,  3.35s/it]predicting train subjects:   3%|▎         | 9/266 [00:29<14:27,  3.38s/it]predicting train subjects:   4%|▍         | 10/266 [00:33<14:31,  3.40s/it]predicting train subjects:   4%|▍         | 11/266 [00:36<14:34,  3.43s/it]predicting train subjects:   5%|▍         | 12/266 [00:39<14:35,  3.45s/it]predicting train subjects:   5%|▍         | 13/266 [00:43<14:31,  3.44s/it]predicting train subjects:   5%|▌         | 14/266 [00:46<14:32,  3.46s/it]predicting train subjects:   6%|▌         | 15/266 [00:50<14:25,  3.45s/it]predicting train subjects:   6%|▌         | 16/266 [00:53<14:22,  3.45s/it]predicting train subjects:   6%|▋         | 17/266 [00:57<14:19,  3.45s/it]predicting train subjects:   7%|▋         | 18/266 [01:00<14:18,  3.46s/it]predicting train subjects:   7%|▋         | 19/266 [01:04<14:13,  3.46s/it]predicting train subjects:   8%|▊         | 20/266 [01:07<14:07,  3.45s/it]predicting train subjects:   8%|▊         | 21/266 [01:11<14:03,  3.44s/it]predicting train subjects:   8%|▊         | 22/266 [01:14<14:05,  3.47s/it]predicting train subjects:   9%|▊         | 23/266 [01:18<14:03,  3.47s/it]predicting train subjects:   9%|▉         | 24/266 [01:21<13:43,  3.40s/it]predicting train subjects:   9%|▉         | 25/266 [01:24<13:33,  3.37s/it]predicting train subjects:  10%|▉         | 26/266 [01:27<13:20,  3.34s/it]predicting train subjects:  10%|█         | 27/266 [01:31<13:14,  3.32s/it]predicting train subjects:  11%|█         | 28/266 [01:34<13:06,  3.30s/it]predicting train subjects:  11%|█         | 29/266 [01:37<13:03,  3.30s/it]predicting train subjects:  11%|█▏        | 30/266 [01:41<13:00,  3.31s/it]predicting train subjects:  12%|█▏        | 31/266 [01:44<12:54,  3.30s/it]predicting train subjects:  12%|█▏        | 32/266 [01:47<12:51,  3.30s/it]predicting train subjects:  12%|█▏        | 33/266 [01:50<12:46,  3.29s/it]predicting train subjects:  13%|█▎        | 34/266 [01:54<12:34,  3.25s/it]predicting train subjects:  13%|█▎        | 35/266 [01:57<12:28,  3.24s/it]predicting train subjects:  14%|█▎        | 36/266 [02:00<12:28,  3.25s/it]predicting train subjects:  14%|█▍        | 37/266 [02:03<12:23,  3.25s/it]predicting train subjects:  14%|█▍        | 38/266 [02:06<12:15,  3.23s/it]predicting train subjects:  15%|█▍        | 39/266 [02:10<12:13,  3.23s/it]predicting train subjects:  15%|█▌        | 40/266 [02:13<12:11,  3.23s/it]predicting train subjects:  15%|█▌        | 41/266 [02:16<12:09,  3.24s/it]predicting train subjects:  16%|█▌        | 42/266 [02:19<11:34,  3.10s/it]predicting train subjects:  16%|█▌        | 43/266 [02:22<11:10,  3.01s/it]predicting train subjects:  17%|█▋        | 44/266 [02:24<10:49,  2.93s/it]predicting train subjects:  17%|█▋        | 45/266 [02:27<10:40,  2.90s/it]predicting train subjects:  17%|█▋        | 46/266 [02:30<10:37,  2.90s/it]predicting train subjects:  18%|█▊        | 47/266 [02:33<10:34,  2.90s/it]predicting train subjects:  18%|█▊        | 48/266 [02:36<10:22,  2.86s/it]predicting train subjects:  18%|█▊        | 49/266 [02:39<10:17,  2.84s/it]predicting train subjects:  19%|█▉        | 50/266 [02:41<10:12,  2.83s/it]predicting train subjects:  19%|█▉        | 51/266 [02:44<10:07,  2.83s/it]predicting train subjects:  20%|█▉        | 52/266 [02:47<10:02,  2.82s/it]predicting train subjects:  20%|█▉        | 53/266 [02:50<10:00,  2.82s/it]predicting train subjects:  20%|██        | 54/266 [02:53<09:54,  2.80s/it]predicting train subjects:  21%|██        | 55/266 [02:56<09:54,  2.82s/it]predicting train subjects:  21%|██        | 56/266 [02:58<09:55,  2.84s/it]predicting train subjects:  21%|██▏       | 57/266 [03:01<09:53,  2.84s/it]predicting train subjects:  22%|██▏       | 58/266 [03:04<09:30,  2.74s/it]predicting train subjects:  22%|██▏       | 59/266 [03:06<09:21,  2.71s/it]predicting train subjects:  23%|██▎       | 60/266 [03:09<09:10,  2.67s/it]predicting train subjects:  23%|██▎       | 61/266 [03:12<09:02,  2.64s/it]predicting train subjects:  23%|██▎       | 62/266 [03:14<08:54,  2.62s/it]predicting train subjects:  24%|██▎       | 63/266 [03:17<08:41,  2.57s/it]predicting train subjects:  24%|██▍       | 64/266 [03:19<08:27,  2.51s/it]predicting train subjects:  24%|██▍       | 65/266 [03:21<08:18,  2.48s/it]predicting train subjects:  25%|██▍       | 66/266 [03:24<08:21,  2.51s/it]predicting train subjects:  25%|██▌       | 67/266 [03:26<08:18,  2.50s/it]predicting train subjects:  26%|██▌       | 68/266 [03:29<08:19,  2.52s/it]predicting train subjects:  26%|██▌       | 69/266 [03:32<08:17,  2.52s/it]predicting train subjects:  26%|██▋       | 70/266 [03:34<08:22,  2.56s/it]predicting train subjects:  27%|██▋       | 71/266 [03:37<08:19,  2.56s/it]predicting train subjects:  27%|██▋       | 72/266 [03:39<08:18,  2.57s/it]predicting train subjects:  27%|██▋       | 73/266 [03:42<08:09,  2.54s/it]predicting train subjects:  28%|██▊       | 74/266 [03:44<08:08,  2.54s/it]predicting train subjects:  28%|██▊       | 75/266 [03:47<08:00,  2.52s/it]predicting train subjects:  29%|██▊       | 76/266 [03:49<08:00,  2.53s/it]predicting train subjects:  29%|██▉       | 77/266 [03:52<07:56,  2.52s/it]predicting train subjects:  29%|██▉       | 78/266 [03:55<08:42,  2.78s/it]predicting train subjects:  30%|██▉       | 79/266 [03:59<09:14,  2.96s/it]predicting train subjects:  30%|███       | 80/266 [04:02<09:35,  3.09s/it]predicting train subjects:  30%|███       | 81/266 [04:05<09:41,  3.14s/it]predicting train subjects:  31%|███       | 82/266 [04:09<09:51,  3.21s/it]predicting train subjects:  31%|███       | 83/266 [04:12<09:52,  3.24s/it]predicting train subjects:  32%|███▏      | 84/266 [04:15<09:53,  3.26s/it]predicting train subjects:  32%|███▏      | 85/266 [04:19<09:54,  3.29s/it]predicting train subjects:  32%|███▏      | 86/266 [04:22<09:56,  3.31s/it]predicting train subjects:  33%|███▎      | 87/266 [04:25<10:02,  3.37s/it]predicting train subjects:  33%|███▎      | 88/266 [04:29<09:54,  3.34s/it]predicting train subjects:  33%|███▎      | 89/266 [04:32<09:53,  3.35s/it]predicting train subjects:  34%|███▍      | 90/266 [04:36<09:51,  3.36s/it]predicting train subjects:  34%|███▍      | 91/266 [04:39<10:16,  3.52s/it]predicting train subjects:  35%|███▍      | 92/266 [04:43<10:22,  3.58s/it]predicting train subjects:  35%|███▍      | 93/266 [04:47<10:30,  3.64s/it]predicting train subjects:  35%|███▌      | 94/266 [04:51<10:44,  3.74s/it]predicting train subjects:  36%|███▌      | 95/266 [04:55<10:51,  3.81s/it]predicting train subjects:  36%|███▌      | 96/266 [04:58<10:33,  3.73s/it]predicting train subjects:  36%|███▋      | 97/266 [05:02<10:22,  3.68s/it]predicting train subjects:  37%|███▋      | 98/266 [05:06<10:30,  3.75s/it]predicting train subjects:  37%|███▋      | 99/266 [05:09<09:42,  3.49s/it]predicting train subjects:  38%|███▊      | 100/266 [05:12<09:25,  3.40s/it]predicting train subjects:  38%|███▊      | 101/266 [05:15<09:14,  3.36s/it]predicting train subjects:  38%|███▊      | 102/266 [05:19<09:23,  3.44s/it]predicting train subjects:  39%|███▊      | 103/266 [05:22<09:21,  3.44s/it]predicting train subjects:  39%|███▉      | 104/266 [05:25<09:04,  3.36s/it]predicting train subjects:  39%|███▉      | 105/266 [05:29<09:04,  3.38s/it]predicting train subjects:  40%|███▉      | 106/266 [05:32<08:58,  3.37s/it]predicting train subjects:  40%|████      | 107/266 [05:36<09:07,  3.44s/it]predicting train subjects:  41%|████      | 108/266 [05:39<09:03,  3.44s/it]predicting train subjects:  41%|████      | 109/266 [05:43<09:07,  3.49s/it]predicting train subjects:  41%|████▏     | 110/266 [05:46<08:59,  3.46s/it]predicting train subjects:  42%|████▏     | 111/266 [05:50<09:08,  3.54s/it]predicting train subjects:  42%|████▏     | 112/266 [05:53<09:00,  3.51s/it]predicting train subjects:  42%|████▏     | 113/266 [05:57<08:53,  3.49s/it]predicting train subjects:  43%|████▎     | 114/266 [06:01<09:02,  3.57s/it]predicting train subjects:  43%|████▎     | 115/266 [06:04<08:54,  3.54s/it]predicting train subjects:  44%|████▎     | 116/266 [06:08<08:49,  3.53s/it]predicting train subjects:  44%|████▍     | 117/266 [06:11<08:45,  3.53s/it]predicting train subjects:  44%|████▍     | 118/266 [06:15<08:36,  3.49s/it]predicting train subjects:  45%|████▍     | 119/266 [06:18<08:47,  3.59s/it]predicting train subjects:  45%|████▌     | 120/266 [06:22<09:06,  3.75s/it]predicting train subjects:  45%|████▌     | 121/266 [06:26<09:06,  3.77s/it]predicting train subjects:  46%|████▌     | 122/266 [06:30<09:03,  3.77s/it]predicting train subjects:  46%|████▌     | 123/266 [06:34<09:02,  3.79s/it]predicting train subjects:  47%|████▋     | 124/266 [06:38<09:06,  3.85s/it]predicting train subjects:  47%|████▋     | 125/266 [06:42<09:16,  3.95s/it]predicting train subjects:  47%|████▋     | 126/266 [06:46<09:25,  4.04s/it]predicting train subjects:  48%|████▊     | 127/266 [06:50<09:26,  4.08s/it]predicting train subjects:  48%|████▊     | 128/266 [06:55<09:21,  4.07s/it]predicting train subjects:  48%|████▊     | 129/266 [06:59<09:20,  4.09s/it]predicting train subjects:  49%|████▉     | 130/266 [07:03<09:13,  4.07s/it]predicting train subjects:  49%|████▉     | 131/266 [07:07<09:02,  4.02s/it]predicting train subjects:  50%|████▉     | 132/266 [07:11<09:01,  4.04s/it]predicting train subjects:  50%|█████     | 133/266 [07:15<08:57,  4.04s/it]predicting train subjects:  50%|█████     | 134/266 [07:19<08:56,  4.07s/it]predicting train subjects:  51%|█████     | 135/266 [07:23<08:54,  4.08s/it]predicting train subjects:  51%|█████     | 136/266 [07:27<08:37,  3.98s/it]predicting train subjects:  52%|█████▏    | 137/266 [07:31<08:27,  3.94s/it]predicting train subjects:  52%|█████▏    | 138/266 [07:35<08:29,  3.98s/it]predicting train subjects:  52%|█████▏    | 139/266 [07:38<08:20,  3.94s/it]predicting train subjects:  53%|█████▎    | 140/266 [07:42<08:09,  3.88s/it]predicting train subjects:  53%|█████▎    | 141/266 [07:46<08:05,  3.89s/it]predicting train subjects:  53%|█████▎    | 142/266 [07:50<08:01,  3.89s/it]predicting train subjects:  54%|█████▍    | 143/266 [07:54<08:02,  3.92s/it]predicting train subjects:  54%|█████▍    | 144/266 [07:58<07:47,  3.83s/it]predicting train subjects:  55%|█████▍    | 145/266 [08:02<07:53,  3.91s/it]predicting train subjects:  55%|█████▍    | 146/266 [08:06<07:48,  3.90s/it]predicting train subjects:  55%|█████▌    | 147/266 [08:09<07:40,  3.87s/it]predicting train subjects:  56%|█████▌    | 148/266 [08:13<07:31,  3.83s/it]predicting train subjects:  56%|█████▌    | 149/266 [08:17<07:30,  3.85s/it]predicting train subjects:  56%|█████▋    | 150/266 [08:21<07:31,  3.89s/it]predicting train subjects:  57%|█████▋    | 151/266 [08:25<07:30,  3.92s/it]predicting train subjects:  57%|█████▋    | 152/266 [08:29<07:29,  3.94s/it]predicting train subjects:  58%|█████▊    | 153/266 [08:33<07:26,  3.95s/it]predicting train subjects:  58%|█████▊    | 154/266 [08:37<07:30,  4.02s/it]predicting train subjects:  58%|█████▊    | 155/266 [08:40<06:56,  3.75s/it]predicting train subjects:  59%|█████▊    | 156/266 [08:43<06:30,  3.55s/it]predicting train subjects:  59%|█████▉    | 157/266 [08:46<06:10,  3.40s/it]predicting train subjects:  59%|█████▉    | 158/266 [08:50<06:00,  3.34s/it]predicting train subjects:  60%|█████▉    | 159/266 [08:53<05:51,  3.28s/it]predicting train subjects:  60%|██████    | 160/266 [08:56<05:48,  3.29s/it]predicting train subjects:  61%|██████    | 161/266 [08:59<05:34,  3.19s/it]predicting train subjects:  61%|██████    | 162/266 [09:02<05:28,  3.16s/it]predicting train subjects:  61%|██████▏   | 163/266 [09:05<05:23,  3.14s/it]predicting train subjects:  62%|██████▏   | 164/266 [09:08<05:22,  3.17s/it]predicting train subjects:  62%|██████▏   | 165/266 [09:12<05:28,  3.26s/it]predicting train subjects:  62%|██████▏   | 166/266 [09:15<05:16,  3.17s/it]predicting train subjects:  63%|██████▎   | 167/266 [09:18<05:06,  3.09s/it]predicting train subjects:  63%|██████▎   | 168/266 [09:21<04:56,  3.03s/it]predicting train subjects:  64%|██████▎   | 169/266 [09:24<04:49,  2.98s/it]predicting train subjects:  64%|██████▍   | 170/266 [09:26<04:37,  2.90s/it]predicting train subjects:  64%|██████▍   | 171/266 [09:29<04:33,  2.88s/it]predicting train subjects:  65%|██████▍   | 172/266 [09:32<04:34,  2.92s/it]predicting train subjects:  65%|██████▌   | 173/266 [09:35<04:43,  3.05s/it]predicting train subjects:  65%|██████▌   | 174/266 [09:39<04:46,  3.11s/it]predicting train subjects:  66%|██████▌   | 175/266 [09:42<04:52,  3.21s/it]predicting train subjects:  66%|██████▌   | 176/266 [09:46<04:56,  3.29s/it]predicting train subjects:  67%|██████▋   | 177/266 [09:49<05:00,  3.37s/it]predicting train subjects:  67%|██████▋   | 178/266 [09:52<04:51,  3.31s/it]predicting train subjects:  67%|██████▋   | 179/266 [09:56<04:46,  3.29s/it]predicting train subjects:  68%|██████▊   | 180/266 [09:59<04:39,  3.25s/it]predicting train subjects:  68%|██████▊   | 181/266 [10:02<04:33,  3.22s/it]predicting train subjects:  68%|██████▊   | 182/266 [10:05<04:30,  3.22s/it]predicting train subjects:  69%|██████▉   | 183/266 [10:09<04:34,  3.31s/it]predicting train subjects:  69%|██████▉   | 184/266 [10:12<04:30,  3.30s/it]predicting train subjects:  70%|██████▉   | 185/266 [10:15<04:27,  3.31s/it]predicting train subjects:  70%|██████▉   | 186/266 [10:19<04:25,  3.32s/it]predicting train subjects:  70%|███████   | 187/266 [10:22<04:24,  3.35s/it]predicting train subjects:  71%|███████   | 188/266 [10:25<04:22,  3.37s/it]predicting train subjects:  71%|███████   | 189/266 [10:29<04:16,  3.33s/it]predicting train subjects:  71%|███████▏  | 190/266 [10:32<04:12,  3.32s/it]predicting train subjects:  72%|███████▏  | 191/266 [10:36<04:13,  3.38s/it]predicting train subjects:  72%|███████▏  | 192/266 [10:38<04:00,  3.25s/it]predicting train subjects:  73%|███████▎  | 193/266 [10:42<03:56,  3.24s/it]predicting train subjects:  73%|███████▎  | 194/266 [10:45<04:04,  3.40s/it]predicting train subjects:  73%|███████▎  | 195/266 [10:49<04:01,  3.41s/it]predicting train subjects:  74%|███████▎  | 196/266 [10:52<03:55,  3.37s/it]predicting train subjects:  74%|███████▍  | 197/266 [10:55<03:51,  3.35s/it]predicting train subjects:  74%|███████▍  | 198/266 [10:59<03:51,  3.41s/it]predicting train subjects:  75%|███████▍  | 199/266 [11:03<03:52,  3.47s/it]predicting train subjects:  75%|███████▌  | 200/266 [11:06<03:49,  3.48s/it]predicting train subjects:  76%|███████▌  | 201/266 [11:10<03:46,  3.48s/it]predicting train subjects:  76%|███████▌  | 202/266 [11:13<03:46,  3.54s/it]predicting train subjects:  76%|███████▋  | 203/266 [11:17<03:41,  3.52s/it]predicting train subjects:  77%|███████▋  | 204/266 [11:20<03:39,  3.55s/it]predicting train subjects:  77%|███████▋  | 205/266 [11:24<03:39,  3.61s/it]predicting train subjects:  77%|███████▋  | 206/266 [11:28<03:33,  3.56s/it]predicting train subjects:  78%|███████▊  | 207/266 [11:31<03:26,  3.49s/it]predicting train subjects:  78%|███████▊  | 208/266 [11:34<03:21,  3.47s/it]predicting train subjects:  79%|███████▊  | 209/266 [11:38<03:20,  3.51s/it]predicting train subjects:  79%|███████▉  | 210/266 [11:41<03:13,  3.46s/it]predicting train subjects:  79%|███████▉  | 211/266 [11:45<03:09,  3.45s/it]predicting train subjects:  80%|███████▉  | 212/266 [11:48<03:06,  3.45s/it]predicting train subjects:  80%|████████  | 213/266 [11:51<02:56,  3.33s/it]predicting train subjects:  80%|████████  | 214/266 [11:54<02:46,  3.20s/it]predicting train subjects:  81%|████████  | 215/266 [11:57<02:42,  3.19s/it]predicting train subjects:  81%|████████  | 216/266 [12:00<02:39,  3.19s/it]predicting train subjects:  82%|████████▏ | 217/266 [12:04<02:38,  3.23s/it]predicting train subjects:  82%|████████▏ | 218/266 [12:07<02:33,  3.20s/it]predicting train subjects:  82%|████████▏ | 219/266 [12:10<02:32,  3.25s/it]predicting train subjects:  83%|████████▎ | 220/266 [12:13<02:26,  3.20s/it]predicting train subjects:  83%|████████▎ | 221/266 [12:17<02:26,  3.25s/it]predicting train subjects:  83%|████████▎ | 222/266 [12:20<02:27,  3.34s/it]predicting train subjects:  84%|████████▍ | 223/266 [12:24<02:22,  3.32s/it]predicting train subjects:  84%|████████▍ | 224/266 [12:27<02:17,  3.26s/it]predicting train subjects:  85%|████████▍ | 225/266 [12:30<02:13,  3.26s/it]predicting train subjects:  85%|████████▍ | 226/266 [12:33<02:07,  3.19s/it]predicting train subjects:  85%|████████▌ | 227/266 [12:36<02:06,  3.25s/it]predicting train subjects:  86%|████████▌ | 228/266 [12:39<02:01,  3.20s/it]predicting train subjects:  86%|████████▌ | 229/266 [12:43<01:58,  3.21s/it]predicting train subjects:  86%|████████▋ | 230/266 [12:46<01:56,  3.25s/it]predicting train subjects:  87%|████████▋ | 231/266 [12:49<01:53,  3.25s/it]predicting train subjects:  87%|████████▋ | 232/266 [12:53<01:51,  3.28s/it]predicting train subjects:  88%|████████▊ | 233/266 [12:56<01:48,  3.30s/it]predicting train subjects:  88%|████████▊ | 234/266 [12:59<01:42,  3.21s/it]predicting train subjects:  88%|████████▊ | 235/266 [13:02<01:39,  3.21s/it]predicting train subjects:  89%|████████▊ | 236/266 [13:05<01:36,  3.20s/it]predicting train subjects:  89%|████████▉ | 237/266 [13:09<01:33,  3.22s/it]predicting train subjects:  89%|████████▉ | 238/266 [13:12<01:31,  3.26s/it]predicting train subjects:  90%|████████▉ | 239/266 [13:15<01:28,  3.28s/it]predicting train subjects:  90%|█████████ | 240/266 [13:19<01:25,  3.27s/it]predicting train subjects:  91%|█████████ | 241/266 [13:22<01:21,  3.25s/it]predicting train subjects:  91%|█████████ | 242/266 [13:25<01:17,  3.24s/it]predicting train subjects:  91%|█████████▏| 243/266 [13:28<01:14,  3.25s/it]predicting train subjects:  92%|█████████▏| 244/266 [13:31<01:11,  3.25s/it]predicting train subjects:  92%|█████████▏| 245/266 [13:34<01:05,  3.11s/it]predicting train subjects:  92%|█████████▏| 246/266 [13:38<01:03,  3.16s/it]predicting train subjects:  93%|█████████▎| 247/266 [13:40<00:57,  3.04s/it]predicting train subjects:  93%|█████████▎| 248/266 [13:43<00:52,  2.94s/it]predicting train subjects:  94%|█████████▎| 249/266 [13:46<00:51,  3.05s/it]predicting train subjects:  94%|█████████▍| 250/266 [13:50<00:50,  3.15s/it]predicting train subjects:  94%|█████████▍| 251/266 [13:53<00:47,  3.18s/it]predicting train subjects:  95%|█████████▍| 252/266 [13:56<00:44,  3.19s/it]predicting train subjects:  95%|█████████▌| 253/266 [13:59<00:42,  3.23s/it]predicting train subjects:  95%|█████████▌| 254/266 [14:03<00:38,  3.24s/it]predicting train subjects:  96%|█████████▌| 255/266 [14:06<00:35,  3.23s/it]predicting train subjects:  96%|█████████▌| 256/266 [14:09<00:32,  3.25s/it]predicting train subjects:  97%|█████████▋| 257/266 [14:13<00:29,  3.28s/it]predicting train subjects:  97%|█████████▋| 258/266 [14:16<00:26,  3.29s/it]predicting train subjects:  97%|█████████▋| 259/266 [14:19<00:22,  3.26s/it]predicting train subjects:  98%|█████████▊| 260/266 [14:22<00:19,  3.29s/it]predicting train subjects:  98%|█████████▊| 261/266 [14:26<00:16,  3.26s/it]predicting train subjects:  98%|█████████▊| 262/266 [14:29<00:13,  3.26s/it]predicting train subjects:  99%|█████████▉| 263/266 [14:32<00:09,  3.28s/it]predicting train subjects:  99%|█████████▉| 264/266 [14:35<00:06,  3.23s/it]predicting train subjects: 100%|█████████▉| 265/266 [14:39<00:03,  3.31s/it]predicting train subjects: 100%|██████████| 266/266 [14:42<00:00,  3.40s/it]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<04:20,  1.02it/s]Loading train:   1%|          | 2/266 [00:01<04:03,  1.08it/s]Loading train:   1%|          | 3/266 [00:02<03:41,  1.19it/s]Loading train:   2%|▏         | 4/266 [00:03<03:25,  1.28it/s]Loading train:   2%|▏         | 5/266 [00:03<03:22,  1.29it/s]Loading train:   2%|▏         | 6/266 [00:04<03:12,  1.35it/s]Loading train:   3%|▎         | 7/266 [00:05<03:07,  1.38it/s]Loading train:   3%|▎         | 8/266 [00:05<03:07,  1.38it/s]Loading train:   3%|▎         | 9/266 [00:06<03:05,  1.39it/s]Loading train:   4%|▍         | 10/266 [00:07<03:02,  1.40it/s]Loading train:   4%|▍         | 11/266 [00:08<03:02,  1.40it/s]Loading train:   5%|▍         | 12/266 [00:08<03:03,  1.38it/s]Loading train:   5%|▍         | 13/266 [00:09<03:06,  1.35it/s]Loading train:   5%|▌         | 14/266 [00:10<02:55,  1.43it/s]Loading train:   6%|▌         | 15/266 [00:10<02:56,  1.42it/s]Loading train:   6%|▌         | 16/266 [00:11<02:57,  1.41it/s]Loading train:   6%|▋         | 17/266 [00:12<02:54,  1.43it/s]Loading train:   7%|▋         | 18/266 [00:13<02:57,  1.39it/s]Loading train:   7%|▋         | 19/266 [00:13<02:58,  1.38it/s]Loading train:   8%|▊         | 20/266 [00:14<03:04,  1.34it/s]Loading train:   8%|▊         | 21/266 [00:15<03:12,  1.28it/s]Loading train:   8%|▊         | 22/266 [00:16<03:13,  1.26it/s]Loading train:   9%|▊         | 23/266 [00:17<03:10,  1.28it/s]Loading train:   9%|▉         | 24/266 [00:17<03:03,  1.32it/s]Loading train:   9%|▉         | 25/266 [00:18<02:50,  1.41it/s]Loading train:  10%|▉         | 26/266 [00:19<02:49,  1.41it/s]Loading train:  10%|█         | 27/266 [00:19<02:48,  1.42it/s]Loading train:  11%|█         | 28/266 [00:20<02:37,  1.52it/s]Loading train:  11%|█         | 29/266 [00:21<02:42,  1.45it/s]Loading train:  11%|█▏        | 30/266 [00:21<02:51,  1.38it/s]Loading train:  12%|█▏        | 31/266 [00:22<02:50,  1.38it/s]Loading train:  12%|█▏        | 32/266 [00:23<02:45,  1.42it/s]Loading train:  12%|█▏        | 33/266 [00:23<02:44,  1.42it/s]Loading train:  13%|█▎        | 34/266 [00:24<02:37,  1.47it/s]Loading train:  13%|█▎        | 35/266 [00:25<02:39,  1.45it/s]Loading train:  14%|█▎        | 36/266 [00:25<02:37,  1.46it/s]Loading train:  14%|█▍        | 37/266 [00:26<02:39,  1.43it/s]Loading train:  14%|█▍        | 38/266 [00:27<02:44,  1.39it/s]Loading train:  15%|█▍        | 39/266 [00:28<02:41,  1.40it/s]Loading train:  15%|█▌        | 40/266 [00:28<02:34,  1.46it/s]Loading train:  15%|█▌        | 41/266 [00:29<02:30,  1.49it/s]Loading train:  16%|█▌        | 42/266 [00:30<02:31,  1.47it/s]Loading train:  16%|█▌        | 43/266 [00:30<02:29,  1.50it/s]Loading train:  17%|█▋        | 44/266 [00:31<02:26,  1.52it/s]Loading train:  17%|█▋        | 45/266 [00:32<02:26,  1.51it/s]Loading train:  17%|█▋        | 46/266 [00:32<02:32,  1.45it/s]Loading train:  18%|█▊        | 47/266 [00:33<02:32,  1.44it/s]Loading train:  18%|█▊        | 48/266 [00:34<02:26,  1.49it/s]Loading train:  18%|█▊        | 49/266 [00:34<02:26,  1.48it/s]Loading train:  19%|█▉        | 50/266 [00:35<02:28,  1.46it/s]Loading train:  19%|█▉        | 51/266 [00:36<02:26,  1.47it/s]Loading train:  20%|█▉        | 52/266 [00:36<02:27,  1.45it/s]Loading train:  20%|█▉        | 53/266 [00:37<02:28,  1.43it/s]Loading train:  20%|██        | 54/266 [00:38<02:21,  1.49it/s]Loading train:  21%|██        | 55/266 [00:38<02:14,  1.56it/s]Loading train:  21%|██        | 56/266 [00:39<02:11,  1.60it/s]Loading train:  21%|██▏       | 57/266 [00:39<02:06,  1.65it/s]Loading train:  22%|██▏       | 58/266 [00:40<02:10,  1.59it/s]Loading train:  22%|██▏       | 59/266 [00:41<02:08,  1.61it/s]Loading train:  23%|██▎       | 60/266 [00:41<02:07,  1.61it/s]Loading train:  23%|██▎       | 61/266 [00:42<02:05,  1.63it/s]Loading train:  23%|██▎       | 62/266 [00:43<02:13,  1.52it/s]Loading train:  24%|██▎       | 63/266 [00:43<02:10,  1.56it/s]Loading train:  24%|██▍       | 64/266 [00:44<02:07,  1.58it/s]Loading train:  24%|██▍       | 65/266 [00:45<02:09,  1.55it/s]Loading train:  25%|██▍       | 66/266 [00:45<02:08,  1.56it/s]Loading train:  25%|██▌       | 67/266 [00:46<02:08,  1.55it/s]Loading train:  26%|██▌       | 68/266 [00:46<02:02,  1.61it/s]Loading train:  26%|██▌       | 69/266 [00:47<01:56,  1.68it/s]Loading train:  26%|██▋       | 70/266 [00:48<02:03,  1.59it/s]Loading train:  27%|██▋       | 71/266 [00:48<02:06,  1.54it/s]Loading train:  27%|██▋       | 72/266 [00:49<02:06,  1.54it/s]Loading train:  27%|██▋       | 73/266 [00:50<02:02,  1.58it/s]Loading train:  28%|██▊       | 74/266 [00:50<01:59,  1.61it/s]Loading train:  28%|██▊       | 75/266 [00:51<01:59,  1.60it/s]Loading train:  29%|██▊       | 76/266 [00:51<01:50,  1.71it/s]Loading train:  29%|██▉       | 77/266 [00:52<01:48,  1.74it/s]Loading train:  29%|██▉       | 78/266 [00:53<02:01,  1.55it/s]Loading train:  30%|██▉       | 79/266 [00:53<01:59,  1.56it/s]Loading train:  30%|███       | 80/266 [00:54<02:05,  1.48it/s]Loading train:  30%|███       | 81/266 [00:55<02:02,  1.51it/s]Loading train:  31%|███       | 82/266 [00:55<02:04,  1.48it/s]Loading train:  31%|███       | 83/266 [00:56<02:11,  1.39it/s]Loading train:  32%|███▏      | 84/266 [00:57<02:11,  1.39it/s]Loading train:  32%|███▏      | 85/266 [00:58<02:06,  1.43it/s]Loading train:  32%|███▏      | 86/266 [00:58<01:59,  1.51it/s]Loading train:  33%|███▎      | 87/266 [00:59<01:59,  1.49it/s]Loading train:  33%|███▎      | 88/266 [01:00<02:00,  1.48it/s]Loading train:  33%|███▎      | 89/266 [01:00<01:57,  1.50it/s]Loading train:  34%|███▍      | 90/266 [01:01<02:02,  1.43it/s]Loading train:  34%|███▍      | 91/266 [01:02<01:55,  1.51it/s]Loading train:  35%|███▍      | 92/266 [01:02<01:55,  1.50it/s]Loading train:  35%|███▍      | 93/266 [01:03<01:56,  1.48it/s]Loading train:  35%|███▌      | 94/266 [01:04<01:58,  1.45it/s]Loading train:  36%|███▌      | 95/266 [01:04<01:54,  1.49it/s]Loading train:  36%|███▌      | 96/266 [01:05<01:56,  1.46it/s]Loading train:  36%|███▋      | 97/266 [01:06<01:56,  1.45it/s]Loading train:  37%|███▋      | 98/266 [01:06<01:58,  1.42it/s]Loading train:  37%|███▋      | 99/266 [01:07<01:54,  1.46it/s]Loading train:  38%|███▊      | 100/266 [01:08<02:02,  1.36it/s]Loading train:  38%|███▊      | 101/266 [01:09<01:54,  1.44it/s]Loading train:  38%|███▊      | 102/266 [01:09<01:48,  1.51it/s]Loading train:  39%|███▊      | 103/266 [01:10<01:52,  1.45it/s]Loading train:  39%|███▉      | 104/266 [01:11<01:50,  1.46it/s]Loading train:  39%|███▉      | 105/266 [01:11<01:48,  1.48it/s]Loading train:  40%|███▉      | 106/266 [01:12<01:46,  1.50it/s]Loading train:  40%|████      | 107/266 [01:12<01:42,  1.55it/s]Loading train:  41%|████      | 108/266 [01:13<01:39,  1.59it/s]Loading train:  41%|████      | 109/266 [01:14<01:38,  1.59it/s]Loading train:  41%|████▏     | 110/266 [01:14<01:41,  1.54it/s]Loading train:  42%|████▏     | 111/266 [01:15<01:40,  1.54it/s]Loading train:  42%|████▏     | 112/266 [01:16<01:37,  1.58it/s]Loading train:  42%|████▏     | 113/266 [01:16<01:36,  1.59it/s]Loading train:  43%|████▎     | 114/266 [01:17<01:38,  1.55it/s]Loading train:  43%|████▎     | 115/266 [01:17<01:34,  1.59it/s]Loading train:  44%|████▎     | 116/266 [01:18<01:33,  1.60it/s]Loading train:  44%|████▍     | 117/266 [01:19<01:34,  1.57it/s]Loading train:  44%|████▍     | 118/266 [01:19<01:24,  1.75it/s]Loading train:  45%|████▍     | 119/266 [01:20<01:33,  1.58it/s]Loading train:  45%|████▌     | 120/266 [01:21<01:34,  1.55it/s]Loading train:  45%|████▌     | 121/266 [01:21<01:33,  1.55it/s]Loading train:  46%|████▌     | 122/266 [01:22<01:31,  1.58it/s]Loading train:  46%|████▌     | 123/266 [01:23<01:34,  1.51it/s]Loading train:  47%|████▋     | 124/266 [01:23<01:37,  1.46it/s]Loading train:  47%|████▋     | 125/266 [01:24<01:30,  1.56it/s]Loading train:  47%|████▋     | 126/266 [01:25<01:34,  1.48it/s]Loading train:  48%|████▊     | 127/266 [01:25<01:34,  1.47it/s]Loading train:  48%|████▊     | 128/266 [01:26<01:34,  1.45it/s]Loading train:  48%|████▊     | 129/266 [01:27<01:33,  1.47it/s]Loading train:  49%|████▉     | 130/266 [01:27<01:33,  1.45it/s]Loading train:  49%|████▉     | 131/266 [01:28<01:35,  1.41it/s]Loading train:  50%|████▉     | 132/266 [01:29<01:32,  1.44it/s]Loading train:  50%|█████     | 133/266 [01:29<01:29,  1.48it/s]Loading train:  50%|█████     | 134/266 [01:30<01:28,  1.49it/s]Loading train:  51%|█████     | 135/266 [01:31<01:28,  1.49it/s]Loading train:  51%|█████     | 136/266 [01:31<01:22,  1.58it/s]Loading train:  52%|█████▏    | 137/266 [01:32<01:22,  1.56it/s]Loading train:  52%|█████▏    | 138/266 [01:33<01:23,  1.54it/s]Loading train:  52%|█████▏    | 139/266 [01:33<01:17,  1.63it/s]Loading train:  53%|█████▎    | 140/266 [01:34<01:16,  1.64it/s]Loading train:  53%|█████▎    | 141/266 [01:35<01:21,  1.53it/s]Loading train:  53%|█████▎    | 142/266 [01:35<01:17,  1.59it/s]Loading train:  54%|█████▍    | 143/266 [01:36<01:16,  1.61it/s]Loading train:  54%|█████▍    | 144/266 [01:36<01:19,  1.53it/s]Loading train:  55%|█████▍    | 145/266 [01:37<01:19,  1.53it/s]Loading train:  55%|█████▍    | 146/266 [01:38<01:13,  1.63it/s]Loading train:  55%|█████▌    | 147/266 [01:38<01:15,  1.58it/s]Loading train:  56%|█████▌    | 148/266 [01:39<01:16,  1.55it/s]Loading train:  56%|█████▌    | 149/266 [01:40<01:13,  1.58it/s]Loading train:  56%|█████▋    | 150/266 [01:40<01:11,  1.61it/s]Loading train:  57%|█████▋    | 151/266 [01:41<01:17,  1.48it/s]Loading train:  57%|█████▋    | 152/266 [01:42<01:16,  1.50it/s]Loading train:  58%|█████▊    | 153/266 [01:42<01:19,  1.43it/s]Loading train:  58%|█████▊    | 154/266 [01:43<01:20,  1.38it/s]Loading train:  58%|█████▊    | 155/266 [01:44<01:18,  1.41it/s]Loading train:  59%|█████▊    | 156/266 [01:44<01:11,  1.55it/s]Loading train:  59%|█████▉    | 157/266 [01:45<01:04,  1.70it/s]Loading train:  59%|█████▉    | 158/266 [01:45<01:04,  1.69it/s]Loading train:  60%|█████▉    | 159/266 [01:46<01:03,  1.69it/s]Loading train:  60%|██████    | 160/266 [01:47<01:03,  1.67it/s]Loading train:  61%|██████    | 161/266 [01:47<01:05,  1.60it/s]Loading train:  61%|██████    | 162/266 [01:48<01:03,  1.63it/s]Loading train:  61%|██████▏   | 163/266 [01:49<01:04,  1.60it/s]Loading train:  62%|██████▏   | 164/266 [01:49<01:00,  1.67it/s]Loading train:  62%|██████▏   | 165/266 [01:50<00:57,  1.74it/s]Loading train:  62%|██████▏   | 166/266 [01:50<00:56,  1.76it/s]Loading train:  63%|██████▎   | 167/266 [01:51<00:58,  1.70it/s]Loading train:  63%|██████▎   | 168/266 [01:51<00:59,  1.64it/s]Loading train:  64%|██████▎   | 169/266 [01:52<00:58,  1.65it/s]Loading train:  64%|██████▍   | 170/266 [01:53<00:56,  1.70it/s]Loading train:  64%|██████▍   | 171/266 [01:53<00:56,  1.70it/s]Loading train:  65%|██████▍   | 172/266 [01:54<00:56,  1.65it/s]Loading train:  65%|██████▌   | 173/266 [01:54<00:56,  1.64it/s]Loading train:  65%|██████▌   | 174/266 [01:55<00:57,  1.60it/s]Loading train:  66%|██████▌   | 175/266 [01:56<00:59,  1.53it/s]Loading train:  66%|██████▌   | 176/266 [01:57<00:59,  1.51it/s]Loading train:  67%|██████▋   | 177/266 [01:57<00:57,  1.54it/s]Loading train:  67%|██████▋   | 178/266 [01:58<00:55,  1.58it/s]Loading train:  67%|██████▋   | 179/266 [01:58<00:53,  1.63it/s]Loading train:  68%|██████▊   | 180/266 [01:59<00:54,  1.57it/s]Loading train:  68%|██████▊   | 181/266 [02:00<00:56,  1.51it/s]Loading train:  68%|██████▊   | 182/266 [02:00<00:53,  1.57it/s]Loading train:  69%|██████▉   | 183/266 [02:01<00:53,  1.56it/s]Loading train:  69%|██████▉   | 184/266 [02:02<00:52,  1.57it/s]Loading train:  70%|██████▉   | 185/266 [02:02<00:53,  1.50it/s]Loading train:  70%|██████▉   | 186/266 [02:03<00:52,  1.51it/s]Loading train:  70%|███████   | 187/266 [02:04<00:53,  1.47it/s]Loading train:  71%|███████   | 188/266 [02:04<00:51,  1.52it/s]Loading train:  71%|███████   | 189/266 [02:05<00:50,  1.52it/s]Loading train:  71%|███████▏  | 190/266 [02:06<00:51,  1.47it/s]Loading train:  72%|███████▏  | 191/266 [02:06<00:50,  1.47it/s]Loading train:  72%|███████▏  | 192/266 [02:07<00:50,  1.48it/s]Loading train:  73%|███████▎  | 193/266 [02:08<00:48,  1.51it/s]Loading train:  73%|███████▎  | 194/266 [02:08<00:48,  1.48it/s]Loading train:  73%|███████▎  | 195/266 [02:09<00:44,  1.58it/s]Loading train:  74%|███████▎  | 196/266 [02:09<00:41,  1.69it/s]Loading train:  74%|███████▍  | 197/266 [02:10<00:44,  1.55it/s]Loading train:  74%|███████▍  | 198/266 [02:11<00:44,  1.54it/s]Loading train:  75%|███████▍  | 199/266 [02:11<00:43,  1.56it/s]Loading train:  75%|███████▌  | 200/266 [02:12<00:42,  1.56it/s]Loading train:  76%|███████▌  | 201/266 [02:13<00:41,  1.56it/s]Loading train:  76%|███████▌  | 202/266 [02:13<00:41,  1.56it/s]Loading train:  76%|███████▋  | 203/266 [02:14<00:39,  1.58it/s]Loading train:  77%|███████▋  | 204/266 [02:15<00:39,  1.57it/s]Loading train:  77%|███████▋  | 205/266 [02:15<00:39,  1.56it/s]Loading train:  77%|███████▋  | 206/266 [02:16<00:38,  1.55it/s]Loading train:  78%|███████▊  | 207/266 [02:17<00:38,  1.52it/s]Loading train:  78%|███████▊  | 208/266 [02:17<00:37,  1.56it/s]Loading train:  79%|███████▊  | 209/266 [02:18<00:35,  1.60it/s]Loading train:  79%|███████▉  | 210/266 [02:19<00:36,  1.53it/s]Loading train:  79%|███████▉  | 211/266 [02:19<00:36,  1.52it/s]Loading train:  80%|███████▉  | 212/266 [02:20<00:35,  1.54it/s]Loading train:  80%|████████  | 213/266 [02:20<00:30,  1.74it/s]Loading train:  80%|████████  | 214/266 [02:21<00:32,  1.61it/s]Loading train:  81%|████████  | 215/266 [02:22<00:33,  1.52it/s]Loading train:  81%|████████  | 216/266 [02:22<00:33,  1.47it/s]Loading train:  82%|████████▏ | 217/266 [02:23<00:33,  1.46it/s]Loading train:  82%|████████▏ | 218/266 [02:24<00:31,  1.50it/s]Loading train:  82%|████████▏ | 219/266 [02:24<00:30,  1.53it/s]Loading train:  83%|████████▎ | 220/266 [02:25<00:29,  1.56it/s]Loading train:  83%|████████▎ | 221/266 [02:26<00:27,  1.62it/s]Loading train:  83%|████████▎ | 222/266 [02:26<00:26,  1.63it/s]Loading train:  84%|████████▍ | 223/266 [02:27<00:26,  1.60it/s]Loading train:  84%|████████▍ | 224/266 [02:28<00:27,  1.52it/s]Loading train:  85%|████████▍ | 225/266 [02:28<00:26,  1.56it/s]Loading train:  85%|████████▍ | 226/266 [02:29<00:25,  1.56it/s]Loading train:  85%|████████▌ | 227/266 [02:29<00:23,  1.63it/s]Loading train:  86%|████████▌ | 228/266 [02:30<00:24,  1.57it/s]Loading train:  86%|████████▌ | 229/266 [02:31<00:22,  1.63it/s]Loading train:  86%|████████▋ | 230/266 [02:31<00:21,  1.66it/s]Loading train:  87%|████████▋ | 231/266 [02:32<00:21,  1.62it/s]Loading train:  87%|████████▋ | 232/266 [02:32<00:20,  1.62it/s]Loading train:  88%|████████▊ | 233/266 [02:33<00:20,  1.63it/s]Loading train:  88%|████████▊ | 234/266 [02:34<00:20,  1.56it/s]Loading train:  88%|████████▊ | 235/266 [02:34<00:20,  1.53it/s]Loading train:  89%|████████▊ | 236/266 [02:35<00:19,  1.57it/s]Loading train:  89%|████████▉ | 237/266 [02:36<00:19,  1.47it/s]Loading train:  89%|████████▉ | 238/266 [02:36<00:18,  1.49it/s]Loading train:  90%|████████▉ | 239/266 [02:37<00:18,  1.48it/s]Loading train:  90%|█████████ | 240/266 [02:38<00:17,  1.49it/s]Loading train:  91%|█████████ | 241/266 [02:38<00:16,  1.51it/s]Loading train:  91%|█████████ | 242/266 [02:39<00:16,  1.46it/s]Loading train:  91%|█████████▏| 243/266 [02:40<00:15,  1.51it/s]Loading train:  92%|█████████▏| 244/266 [02:40<00:14,  1.47it/s]Loading train:  92%|█████████▏| 245/266 [02:41<00:14,  1.43it/s]Loading train:  92%|█████████▏| 246/266 [02:42<00:13,  1.50it/s]Loading train:  93%|█████████▎| 247/266 [02:42<00:12,  1.51it/s]Loading train:  93%|█████████▎| 248/266 [02:43<00:12,  1.48it/s]Loading train:  94%|█████████▎| 249/266 [02:44<00:12,  1.41it/s]Loading train:  94%|█████████▍| 250/266 [02:45<00:11,  1.36it/s]Loading train:  94%|█████████▍| 251/266 [02:45<00:09,  1.51it/s]Loading train:  95%|█████████▍| 252/266 [02:46<00:09,  1.50it/s]Loading train:  95%|█████████▌| 253/266 [02:47<00:08,  1.46it/s]Loading train:  95%|█████████▌| 254/266 [02:47<00:08,  1.45it/s]Loading train:  96%|█████████▌| 255/266 [02:48<00:07,  1.39it/s]Loading train:  96%|█████████▌| 256/266 [02:49<00:07,  1.35it/s]Loading train:  97%|█████████▋| 257/266 [02:50<00:06,  1.37it/s]Loading train:  97%|█████████▋| 258/266 [02:50<00:05,  1.38it/s]Loading train:  97%|█████████▋| 259/266 [02:51<00:05,  1.37it/s]Loading train:  98%|█████████▊| 260/266 [02:52<00:04,  1.39it/s]Loading train:  98%|█████████▊| 261/266 [02:53<00:03,  1.39it/s]Loading train:  98%|█████████▊| 262/266 [02:53<00:03,  1.32it/s]Loading train:  99%|█████████▉| 263/266 [02:54<00:02,  1.37it/s]Loading train:  99%|█████████▉| 264/266 [02:55<00:01,  1.36it/s]Loading train: 100%|█████████▉| 265/266 [02:55<00:00,  1.38it/s]Loading train: 100%|██████████| 266/266 [02:56<00:00,  1.31it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   1%|          | 2/266 [00:00<00:22, 11.94it/s]concatenating: train:   2%|▏         | 5/266 [00:00<00:19, 13.56it/s]concatenating: train:   3%|▎         | 7/266 [00:00<00:17, 14.60it/s]concatenating: train:   4%|▍         | 10/266 [00:00<00:15, 16.46it/s]concatenating: train:   5%|▍         | 13/266 [00:00<00:13, 18.62it/s]concatenating: train:   6%|▌         | 15/266 [00:00<00:13, 18.96it/s]concatenating: train:   7%|▋         | 19/266 [00:00<00:11, 21.25it/s]concatenating: train:  11%|█         | 28/266 [00:01<00:08, 26.60it/s]concatenating: train:  12%|█▏        | 32/266 [00:01<00:08, 28.31it/s]concatenating: train:  24%|██▎       | 63/266 [00:01<00:05, 38.90it/s]concatenating: train:  33%|███▎      | 87/266 [00:01<00:03, 51.48it/s]concatenating: train:  46%|████▌     | 123/266 [00:01<00:02, 69.23it/s]concatenating: train:  58%|█████▊    | 154/266 [00:01<00:01, 88.53it/s]concatenating: train:  67%|██████▋   | 177/266 [00:01<00:00, 99.47it/s]concatenating: train:  79%|███████▊  | 209/266 [00:01<00:00, 124.86it/s]concatenating: train:  88%|████████▊ | 233/266 [00:02<00:00, 128.86it/s]concatenating: train:  99%|█████████▉| 264/266 [00:02<00:00, 154.29it/s]concatenating: train: 100%|██████████| 266/266 [00:02<00:00, 122.31it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:00<00:03,  1.27it/s]Loading test:  40%|████      | 2/5 [00:01<00:02,  1.38it/s]Loading test:  60%|██████    | 3/5 [00:02<00:01,  1.38it/s]Loading test:  80%|████████  | 4/5 [00:02<00:00,  1.43it/s]Loading test: 100%|██████████| 5/5 [00:03<00:00,  1.45it/s]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation:  40%|████      | 2/5 [00:00<00:00, 10.81it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 26.46it/s]2019-08-17 19:19:50.798265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-08-17 19:19:50.798364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-17 19:19:50.798379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-08-17 19:19:50.798388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-08-17 19:19:50.798793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.58it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.55it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  5.89it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.58it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:04,  7.84it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.49it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.75it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.52it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  7.94it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.91it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.67it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.18it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.53it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.30it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.57it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.91it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.12it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.16it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.24it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 76, 108, 1)   0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 76, 108, 30)  300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 76, 108, 30)  120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 76, 108, 30)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 76, 108, 30)  8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 76, 108, 30)  120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 76, 108, 30)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 38, 54, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 38, 54, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 38, 54, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 38, 54, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 38, 54, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 38, 54, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 38, 54, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 38, 54, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 54, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 19, 27, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 19, 27, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 19, 27, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 19, 27, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 19, 27, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 19, 27, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 19, 27, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 19, 27, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 19, 27, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 19, 27, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 38, 54, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 38, 54, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 38, 54, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 38, 54, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 54, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 38, 54, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 38, 54, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 38, 54, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 38, 54, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 38, 54, 210)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 76, 108, 30)  25230       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 76, 108, 60)  0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 76, 108, 30)  16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 76, 108, 30)  120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 76, 108, 30)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 76, 108, 30)  8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 76, 108, 30)  120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 76, 108, 30)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 76, 108, 90)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 76, 108, 90)  0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 76, 108, 2)   182         dropout_5[0][0]                  
==================================================================================================
Total params: 500,342
Trainable params: 58,532
Non-trainable params: 441,810
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97453182 0.02546818]
Train on 27987 samples, validate on 500 samples
Epoch 1/300
 - 51s - loss: 0.2290 - acc: 0.9571 - mDice: 0.7436 - val_loss: 0.0735 - val_acc: 0.9931 - val_mDice: 0.8746

Epoch 00001: val_mDice improved from -inf to 0.87458, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 46s - loss: 0.0650 - acc: 0.9929 - mDice: 0.8839 - val_loss: 0.0614 - val_acc: 0.9945 - val_mDice: 0.8875

Epoch 00002: val_mDice improved from 0.87458 to 0.88748, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 46s - loss: 0.0551 - acc: 0.9940 - mDice: 0.8989 - val_loss: 0.0605 - val_acc: 0.9945 - val_mDice: 0.8891

Epoch 00003: val_mDice improved from 0.88748 to 0.88911, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 45s - loss: 0.0503 - acc: 0.9944 - mDice: 0.9072 - val_loss: 0.0593 - val_acc: 0.9945 - val_mDice: 0.8912

Epoch 00004: val_mDice improved from 0.88911 to 0.89123, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 44s - loss: 0.0475 - acc: 0.9947 - mDice: 0.9120 - val_loss: 0.0642 - val_acc: 0.9945 - val_mDice: 0.8829

Epoch 00005: val_mDice did not improve from 0.89123
Epoch 6/300
 - 44s - loss: 0.0444 - acc: 0.9950 - mDice: 0.9176 - val_loss: 0.0628 - val_acc: 0.9945 - val_mDice: 0.8852

Epoch 00006: val_mDice did not improve from 0.89123
Epoch 7/300
 - 44s - loss: 0.0428 - acc: 0.9951 - mDice: 0.9205 - val_loss: 0.0600 - val_acc: 0.9947 - val_mDice: 0.8901

Epoch 00007: val_mDice did not improve from 0.89123
Epoch 8/300
 - 45s - loss: 0.0417 - acc: 0.9952 - mDice: 0.9223 - val_loss: 0.0588 - val_acc: 0.9947 - val_mDice: 0.8924

Epoch 00008: val_mDice improved from 0.89123 to 0.89241, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 46s - loss: 0.0404 - acc: 0.9953 - mDice: 0.9247 - val_loss: 0.0587 - val_acc: 0.9949 - val_mDice: 0.8924

Epoch 00009: val_mDice improved from 0.89241 to 0.89242, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 46s - loss: 0.0395 - acc: 0.9954 - mDice: 0.9262 - val_loss: 0.0577 - val_acc: 0.9949 - val_mDice: 0.8941

Epoch 00010: val_mDice improved from 0.89242 to 0.89407, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 46s - loss: 0.0387 - acc: 0.9955 - mDice: 0.9277 - val_loss: 0.0589 - val_acc: 0.9948 - val_mDice: 0.8920

Epoch 00011: val_mDice did not improve from 0.89407
Epoch 12/300
 - 45s - loss: 0.0379 - acc: 0.9956 - mDice: 0.9291 - val_loss: 0.0578 - val_acc: 0.9946 - val_mDice: 0.8939

Epoch 00012: val_mDice did not improve from 0.89407
Epoch 13/300
 - 45s - loss: 0.0377 - acc: 0.9956 - mDice: 0.9295 - val_loss: 0.0611 - val_acc: 0.9947 - val_mDice: 0.8884

Epoch 00013: val_mDice did not improve from 0.89407
Epoch 14/300
 - 45s - loss: 0.0368 - acc: 0.9957 - mDice: 0.9310 - val_loss: 0.0606 - val_acc: 0.9946 - val_mDice: 0.8894

Epoch 00014: val_mDice did not improve from 0.89407
Epoch 15/300
 - 44s - loss: 0.0365 - acc: 0.9957 - mDice: 0.9317 - val_loss: 0.0567 - val_acc: 0.9947 - val_mDice: 0.8958

Epoch 00015: val_mDice improved from 0.89407 to 0.89581, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 44s - loss: 0.0358 - acc: 0.9958 - mDice: 0.9329 - val_loss: 0.0583 - val_acc: 0.9947 - val_mDice: 0.8935

Epoch 00016: val_mDice did not improve from 0.89581
Epoch 17/300
 - 43s - loss: 0.0352 - acc: 0.9959 - mDice: 0.9339 - val_loss: 0.0589 - val_acc: 0.9946 - val_mDice: 0.8922

Epoch 00017: val_mDice did not improve from 0.89581
Epoch 18/300
 - 44s - loss: 0.0348 - acc: 0.9959 - mDice: 0.9347 - val_loss: 0.0643 - val_acc: 0.9946 - val_mDice: 0.8827

Epoch 00018: val_mDice did not improve from 0.89581
Epoch 19/300
 - 44s - loss: 0.0348 - acc: 0.9959 - mDice: 0.9347 - val_loss: 0.0598 - val_acc: 0.9946 - val_mDice: 0.8907

Epoch 00019: val_mDice did not improve from 0.89581
Epoch 20/300
 - 44s - loss: 0.0344 - acc: 0.9959 - mDice: 0.9353 - val_loss: 0.0584 - val_acc: 0.9949 - val_mDice: 0.8932

Epoch 00020: val_mDice did not improve from 0.89581
Epoch 21/300
 - 44s - loss: 0.0341 - acc: 0.9960 - mDice: 0.9359 - val_loss: 0.0587 - val_acc: 0.9947 - val_mDice: 0.8929

Epoch 00021: val_mDice did not improve from 0.89581
Epoch 22/300
 - 44s - loss: 0.0338 - acc: 0.9960 - mDice: 0.9366 - val_loss: 0.0615 - val_acc: 0.9946 - val_mDice: 0.8877

Epoch 00022: val_mDice did not improve from 0.89581
Epoch 23/300
 - 44s - loss: 0.0334 - acc: 0.9960 - mDice: 0.9372 - val_loss: 0.0613 - val_acc: 0.9943 - val_mDice: 0.8884

Epoch 00023: val_mDice did not improve from 0.89581
Epoch 24/300
 - 43s - loss: 0.0332 - acc: 0.9961 - mDice: 0.9377 - val_loss: 0.0572 - val_acc: 0.9950 - val_mDice: 0.8952

Epoch 00024: val_mDice did not improve from 0.89581
Epoch 25/300
 - 44s - loss: 0.0331 - acc: 0.9961 - mDice: 0.9378 - val_loss: 0.0583 - val_acc: 0.9947 - val_mDice: 0.8936

Epoch 00025: val_mDice did not improve from 0.89581
Epoch 26/300
 - 43s - loss: 0.0326 - acc: 0.9961 - mDice: 0.9387 - val_loss: 0.0588 - val_acc: 0.9948 - val_mDice: 0.8926

Epoch 00026: val_mDice did not improve from 0.89581
Epoch 27/300
 - 44s - loss: 0.0326 - acc: 0.9961 - mDice: 0.9388 - val_loss: 0.0580 - val_acc: 0.9946 - val_mDice: 0.8940

Epoch 00027: val_mDice did not improve from 0.89581
Epoch 28/300
 - 44s - loss: 0.0326 - acc: 0.9961 - mDice: 0.9387 - val_loss: 0.0601 - val_acc: 0.9947 - val_mDice: 0.8905

Epoch 00028: val_mDice did not improve from 0.89581
Epoch 29/300
 - 44s - loss: 0.0321 - acc: 0.9962 - mDice: 0.9397 - val_loss: 0.0597 - val_acc: 0.9944 - val_mDice: 0.8913

Epoch 00029: val_mDice did not improve from 0.89581
Epoch 30/300
 - 44s - loss: 0.0320 - acc: 0.9962 - mDice: 0.9398 - val_loss: 0.0592 - val_acc: 0.9948 - val_mDice: 0.8920

Epoch 00030: val_mDice did not improve from 0.89581
Epoch 31/300
 - 44s - loss: 0.0319 - acc: 0.9962 - mDice: 0.9400 - val_loss: 0.0619 - val_acc: 0.9947 - val_mDice: 0.8872

Epoch 00031: val_mDice did not improve from 0.89581
Epoch 32/300
 - 44s - loss: 0.0316 - acc: 0.9962 - mDice: 0.9405 - val_loss: 0.0582 - val_acc: 0.9947 - val_mDice: 0.8938

Epoch 00032: val_mDice did not improve from 0.89581
Epoch 33/300
 - 44s - loss: 0.0315 - acc: 0.9962 - mDice: 0.9407 - val_loss: 0.0584 - val_acc: 0.9945 - val_mDice: 0.8934

Epoch 00033: val_mDice did not improve from 0.89581
Epoch 34/300
 - 45s - loss: 0.0313 - acc: 0.9963 - mDice: 0.9410 - val_loss: 0.0596 - val_acc: 0.9948 - val_mDice: 0.8913

Epoch 00034: val_mDice did not improve from 0.89581
Epoch 35/300
 - 44s - loss: 0.0312 - acc: 0.9963 - mDice: 0.9413 - val_loss: 0.0554 - val_acc: 0.9949 - val_mDice: 0.8983

Epoch 00035: val_mDice improved from 0.89581 to 0.89828, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 36/300
 - 44s - loss: 0.0312 - acc: 0.9963 - mDice: 0.9412 - val_loss: 0.0590 - val_acc: 0.9950 - val_mDice: 0.8924

Epoch 00036: val_mDice did not improve from 0.89828
Epoch 37/300
 - 44s - loss: 0.0310 - acc: 0.9963 - mDice: 0.9416 - val_loss: 0.0580 - val_acc: 0.9949 - val_mDice: 0.8940

Epoch 00037: val_mDice did not improve from 0.89828
Epoch 38/300
 - 44s - loss: 0.0309 - acc: 0.9963 - mDice: 0.9418 - val_loss: 0.0574 - val_acc: 0.9948 - val_mDice: 0.8949

Epoch 00038: val_mDice did not improve from 0.89828
Epoch 39/300
 - 46s - loss: 0.0308 - acc: 0.9963 - mDice: 0.9420 - val_loss: 0.0621 - val_acc: 0.9948 - val_mDice: 0.8868

Epoch 00039: val_mDice did not improve from 0.89828
Epoch 40/300
 - 46s - loss: 0.0308 - acc: 0.9963 - mDice: 0.9421 - val_loss: 0.0592 - val_acc: 0.9947 - val_mDice: 0.8919

Epoch 00040: val_mDice did not improve from 0.89828
Epoch 41/300
 - 47s - loss: 0.0306 - acc: 0.9963 - mDice: 0.9424 - val_loss: 0.0572 - val_acc: 0.9948 - val_mDice: 0.8955

Epoch 00041: val_mDice did not improve from 0.89828
Epoch 42/300
 - 49s - loss: 0.0305 - acc: 0.9963 - mDice: 0.9426 - val_loss: 0.0572 - val_acc: 0.9949 - val_mDice: 0.8954

Epoch 00042: val_mDice did not improve from 0.89828
Epoch 43/300
 - 49s - loss: 0.0304 - acc: 0.9964 - mDice: 0.9428 - val_loss: 0.0618 - val_acc: 0.9942 - val_mDice: 0.8873

Epoch 00043: val_mDice did not improve from 0.89828
Epoch 44/300
 - 48s - loss: 0.0303 - acc: 0.9964 - mDice: 0.9430 - val_loss: 0.0568 - val_acc: 0.9950 - val_mDice: 0.8960

Epoch 00044: val_mDice did not improve from 0.89828
Epoch 45/300
 - 49s - loss: 0.0302 - acc: 0.9964 - mDice: 0.9432 - val_loss: 0.0570 - val_acc: 0.9948 - val_mDice: 0.8957

Epoch 00045: val_mDice did not improve from 0.89828
Epoch 46/300
 - 49s - loss: 0.0301 - acc: 0.9964 - mDice: 0.9433 - val_loss: 0.0575 - val_acc: 0.9947 - val_mDice: 0.8949

Epoch 00046: val_mDice did not improve from 0.89828
Epoch 47/300
 - 47s - loss: 0.0300 - acc: 0.9964 - mDice: 0.9435 - val_loss: 0.0592 - val_acc: 0.9949 - val_mDice: 0.8917

Epoch 00047: val_mDice did not improve from 0.89828
Epoch 48/300
 - 46s - loss: 0.0299 - acc: 0.9964 - mDice: 0.9437 - val_loss: 0.0585 - val_acc: 0.9949 - val_mDice: 0.8931

Epoch 00048: val_mDice did not improve from 0.89828
Epoch 49/300
 - 46s - loss: 0.0300 - acc: 0.9964 - mDice: 0.9435 - val_loss: 0.0623 - val_acc: 0.9942 - val_mDice: 0.8867

Epoch 00049: val_mDice did not improve from 0.89828
Epoch 50/300
 - 45s - loss: 0.0298 - acc: 0.9964 - mDice: 0.9438 - val_loss: 0.0575 - val_acc: 0.9948 - val_mDice: 0.8950

Epoch 00050: val_mDice did not improve from 0.89828
Epoch 51/300
 - 46s - loss: 0.0298 - acc: 0.9964 - mDice: 0.9439 - val_loss: 0.0576 - val_acc: 0.9947 - val_mDice: 0.8946

Epoch 00051: val_mDice did not improve from 0.89828
Epoch 52/300
 - 44s - loss: 0.0296 - acc: 0.9964 - mDice: 0.9442 - val_loss: 0.0599 - val_acc: 0.9947 - val_mDice: 0.8907

Epoch 00052: val_mDice did not improve from 0.89828
Epoch 53/300
 - 44s - loss: 0.0298 - acc: 0.9964 - mDice: 0.9438 - val_loss: 0.0576 - val_acc: 0.9948 - val_mDice: 0.8947

Epoch 00053: val_mDice did not improve from 0.89828
Epoch 54/300
 - 44s - loss: 0.0294 - acc: 0.9964 - mDice: 0.9446 - val_loss: 0.0602 - val_acc: 0.9949 - val_mDice: 0.8900

Epoch 00054: val_mDice did not improve from 0.89828
Epoch 55/300
 - 44s - loss: 0.0294 - acc: 0.9964 - mDice: 0.9445 - val_loss: 0.0603 - val_acc: 0.9946 - val_mDice: 0.8901

Epoch 00055: val_mDice did not improve from 0.89828
Epoch 56/300
 - 45s - loss: 0.0294 - acc: 0.9964 - mDice: 0.9446 - val_loss: 0.0584 - val_acc: 0.9945 - val_mDice: 0.8933

Epoch 00056: val_mDice did not improve from 0.89828
Epoch 57/300
 - 44s - loss: 0.0294 - acc: 0.9964 - mDice: 0.9446 - val_loss: 0.0570 - val_acc: 0.9949 - val_mDice: 0.8957

Epoch 00057: val_mDice did not improve from 0.89828
Epoch 58/300
 - 45s - loss: 0.0293 - acc: 0.9965 - mDice: 0.9448 - val_loss: 0.0598 - val_acc: 0.9949 - val_mDice: 0.8908

Epoch 00058: val_mDice did not improve from 0.89828
Epoch 59/300
 - 45s - loss: 0.0294 - acc: 0.9964 - mDice: 0.9445 - val_loss: 0.0560 - val_acc: 0.9950 - val_mDice: 0.8973

Epoch 00059: val_mDice did not improve from 0.89828
Epoch 60/300
 - 45s - loss: 0.0291 - acc: 0.9965 - mDice: 0.9450 - val_loss: 0.0593 - val_acc: 0.9948 - val_mDice: 0.8916

Epoch 00060: val_mDice did not improve from 0.89828
Epoch 61/300
 - 44s - loss: 0.0292 - acc: 0.9965 - mDice: 0.9450 - val_loss: 0.0557 - val_acc: 0.9949 - val_mDice: 0.8979

Epoch 00061: val_mDice did not improve from 0.89828
Epoch 62/300
 - 44s - loss: 0.0290 - acc: 0.9965 - mDice: 0.9452 - val_loss: 0.0591 - val_acc: 0.9947 - val_mDice: 0.8920

Epoch 00062: val_mDice did not improve from 0.89828
Epoch 63/300
 - 45s - loss: 0.0290 - acc: 0.9965 - mDice: 0.9453 - val_loss: 0.0584 - val_acc: 0.9947 - val_mDice: 0.8934

Epoch 00063: val_mDice did not improve from 0.89828
Epoch 64/300
 - 45s - loss: 0.0289 - acc: 0.9965 - mDice: 0.9455 - val_loss: 0.0580 - val_acc: 0.9949 - val_mDice: 0.8940

Epoch 00064: val_mDice did not improve from 0.89828
Epoch 65/300
 - 44s - loss: 0.0290 - acc: 0.9965 - mDice: 0.9453 - val_loss: 0.0585 - val_acc: 0.9949 - val_mDice: 0.8930

Epoch 00065: val_mDice did not improve from 0.89828
Epoch 66/300
 - 45s - loss: 0.0290 - acc: 0.9965 - mDice: 0.9452 - val_loss: 0.0595 - val_acc: 0.9947 - val_mDice: 0.8913

Epoch 00066: val_mDice did not improve from 0.89828
Epoch 67/300
 - 45s - loss: 0.0289 - acc: 0.9965 - mDice: 0.9455 - val_loss: 0.0591 - val_acc: 0.9947 - val_mDice: 0.8921

Epoch 00067: val_mDice did not improve from 0.89828
Epoch 68/300
 - 45s - loss: 0.0289 - acc: 0.9965 - mDice: 0.9455 - val_loss: 0.0602 - val_acc: 0.9948 - val_mDice: 0.8903

Epoch 00068: val_mDice did not improve from 0.89828
Epoch 69/300
 - 45s - loss: 0.0287 - acc: 0.9965 - mDice: 0.9459 - val_loss: 0.0587 - val_acc: 0.9948 - val_mDice: 0.8927

Epoch 00069: val_mDice did not improve from 0.89828
Epoch 70/300
 - 45s - loss: 0.0289 - acc: 0.9965 - mDice: 0.9454 - val_loss: 0.0585 - val_acc: 0.9947 - val_mDice: 0.8931

Epoch 00070: val_mDice did not improve from 0.89828
Epoch 71/300
 - 44s - loss: 0.0286 - acc: 0.9965 - mDice: 0.9461 - val_loss: 0.0593 - val_acc: 0.9949 - val_mDice: 0.8916

Epoch 00071: val_mDice did not improve from 0.89828
Epoch 72/300
 - 44s - loss: 0.0286 - acc: 0.9965 - mDice: 0.9460 - val_loss: 0.0585 - val_acc: 0.9950 - val_mDice: 0.8931

Epoch 00072: val_mDice did not improve from 0.89828
Epoch 73/300
 - 45s - loss: 0.0285 - acc: 0.9965 - mDice: 0.9462 - val_loss: 0.0570 - val_acc: 0.9948 - val_mDice: 0.8958

Epoch 00073: val_mDice did not improve from 0.89828
Epoch 74/300
 - 45s - loss: 0.0286 - acc: 0.9965 - mDice: 0.9460 - val_loss: 0.0599 - val_acc: 0.9948 - val_mDice: 0.8909

Epoch 00074: val_mDice did not improve from 0.89828
Epoch 75/300
 - 45s - loss: 0.0285 - acc: 0.9965 - mDice: 0.9462 - val_loss: 0.0579 - val_acc: 0.9950 - val_mDice: 0.8940

Epoch 00075: val_mDice did not improve from 0.89828
Restoring model weights from the end of the best epoch
Epoch 00075: early stopping
{'val_loss': [0.07348121032118797, 0.06137424856424332, 0.06047733873128891, 0.05929142236709595, 0.06419361531734466, 0.06284993700683117, 0.06000589765608311, 0.05877227708697319, 0.058662078157067296, 0.05772093459963799, 0.05888545550405979, 0.057759931311011314, 0.06106278859078884, 0.06060774028301239, 0.0567487858235836, 0.05832428298890591, 0.058917468413710594, 0.0643455844372511, 0.059800510108470914, 0.05840784944593906, 0.05871308408677578, 0.061517088860273364, 0.06127370223402977, 0.057187569886446, 0.0582658089697361, 0.05881565324962139, 0.05804947391152382, 0.0600828155875206, 0.059652640298008916, 0.05920657478272915, 0.06194317676126957, 0.05821263119578361, 0.058362508192658424, 0.0596332598477602, 0.05544152446091175, 0.058950118720531464, 0.05803828276693821, 0.05739873722195625, 0.06207803227007389, 0.05923592485487461, 0.0572248674929142, 0.057195305824279785, 0.061836642771959306, 0.056797541305422784, 0.056985531002283096, 0.05747837647795677, 0.05920759402215481, 0.058534147962927816, 0.06234958060085773, 0.057507889717817305, 0.05760130062699318, 0.0598992295563221, 0.05760563760995865, 0.06024343073368073, 0.060326777026057245, 0.058432525023818016, 0.056978335976600646, 0.05977684296667576, 0.05596342347562313, 0.05925099849700928, 0.055724161490797994, 0.05909295901656151, 0.05838146358728409, 0.05795706622302532, 0.05853263922035694, 0.05954489596188069, 0.05911268182098865, 0.060155005753040315, 0.058742893114686015, 0.05845352411270142, 0.05934010408818722, 0.05848670341074467, 0.056951585412025454, 0.059868793562054635, 0.05793138854205608], 'val_acc': [0.9930979609489441, 0.9945090234279632, 0.9944977998733521, 0.9944827020168304, 0.9944610118865966, 0.9945017099380493, 0.994652533531189, 0.9947054088115692, 0.9948715925216675, 0.9948920547962189, 0.9947811961174011, 0.9946259737014771, 0.9946756839752198, 0.9946328103542328, 0.994719785451889, 0.9947061419487, 0.9946159839630127, 0.9946284055709839, 0.9945867538452149, 0.9948520958423615, 0.9946651995182038, 0.9946101367473602, 0.9943372428417205, 0.9949524879455567, 0.9947007834911347, 0.9947609663009643, 0.994595754146576, 0.9947368323802948, 0.9944493114948273, 0.9947919130325318, 0.9946630001068115, 0.9946980953216553, 0.994461989402771, 0.9948457658290863, 0.9949273824691772, 0.9949561357498169, 0.9949320137500763, 0.9947845876216889, 0.9947680234909058, 0.9947363555431366, 0.9948479533195496, 0.9949001014232636, 0.9942319750785827, 0.995023888349533, 0.9948367536067962, 0.9947263658046722, 0.9948857247829437, 0.9949198305606842, 0.9942015111446381, 0.9947758316993713, 0.9946866452693939, 0.9946978569030762, 0.99480921626091, 0.9949395775794982, 0.9945830821990966, 0.9945211946964264, 0.9948501467704773, 0.9948657393455506, 0.9950377702713012, 0.9948433220386506, 0.9949424982070922, 0.9947487771511078, 0.9946544766426086, 0.9948562324047089, 0.9949283599853516, 0.9946676433086395, 0.994720995426178, 0.9948021352291108, 0.994834303855896, 0.9947207629680633, 0.9949035048484802, 0.9949907422065735, 0.9948089718818665, 0.9948438048362732, 0.9949956119060517], 'val_mDice': [0.8745792627334594, 0.8874818027019501, 0.8891064643859863, 0.8912333309650421, 0.8828588426113129, 0.8852174282073975, 0.8901325404644013, 0.8924075543880463, 0.892423290014267, 0.8940662503242492, 0.8920273900032043, 0.8938607633113861, 0.8884060919284821, 0.8894123613834382, 0.8958051562309265, 0.8934825539588929, 0.8922408163547516, 0.8826838791370392, 0.890675961971283, 0.8932279169559478, 0.8928957283496857, 0.8876979887485504, 0.888360345363617, 0.8952233910560607, 0.8935883522033692, 0.8926234126091004, 0.8940035164356231, 0.8904999673366547, 0.8913034915924072, 0.8919725298881531, 0.8871666729450226, 0.8938487470149994, 0.8933922708034515, 0.8913399934768677, 0.8982784032821656, 0.8923874616622924, 0.8940297186374664, 0.8948933064937592, 0.886799955368042, 0.891905564069748, 0.8954668045043945, 0.8953510642051696, 0.887348347902298, 0.8959743678569794, 0.895699018239975, 0.8948754370212555, 0.8917085289955139, 0.8931104660034179, 0.8866858780384064, 0.8949759542942047, 0.8945923209190368, 0.8907455801963806, 0.8947353720664978, 0.8899551153182983, 0.8900736391544342, 0.8932823002338409, 0.8957293331623077, 0.8908310413360596, 0.8973014056682587, 0.8915965259075165, 0.8979040443897247, 0.8919696927070617, 0.8933815002441406, 0.8939748585224152, 0.8929847121238709, 0.8912790954113007, 0.8920635640621185, 0.8903231143951416, 0.8926994204521179, 0.8930588722229004, 0.8916106998920441, 0.8931152105331421, 0.8958487689495087, 0.8908569097518921, 0.8939706444740295], 'loss': [0.22897702003699236, 0.06502091176878427, 0.0551486360135793, 0.05028566686435136, 0.04752083468211763, 0.044384116893707075, 0.04275648814480984, 0.04173437591482279, 0.04038135578702998, 0.03954737666011598, 0.03870391288140828, 0.037882318884010766, 0.03770282902519675, 0.036845764535593954, 0.03646010851695365, 0.03576698748284833, 0.03522427924103561, 0.03480129273348833, 0.03480433035266145, 0.034437139373371554, 0.034132881669263926, 0.03376213846388182, 0.033432620244444974, 0.03315833278177921, 0.03310386958502186, 0.03259354136642222, 0.03255495279119594, 0.032575664279096146, 0.032062688085630946, 0.03196811423093793, 0.0318656771672031, 0.03161615662708813, 0.031493215776792774, 0.03133806875508992, 0.031200613143270533, 0.031223152912190803, 0.031002218786571282, 0.030881992594995872, 0.030794065203538307, 0.03075045618873622, 0.030584170204025332, 0.030452946022668827, 0.03037513504669006, 0.030274038103196437, 0.030158864575350584, 0.030064883420107623, 0.029977993359140684, 0.02989145961579496, 0.03000077176839779, 0.02982605746786002, 0.029753543051379595, 0.029586188098364552, 0.029793790121334398, 0.02936301662205242, 0.029425389981790128, 0.02935871507638511, 0.029384756795818406, 0.029296653747412707, 0.02942287743228152, 0.029143257622332882, 0.02915559407942151, 0.029040998819402575, 0.02901731422998595, 0.02891586852600457, 0.02900210908905705, 0.029035787599227623, 0.028903199094756797, 0.028914872899943832, 0.02868444609506046, 0.028939266202978462, 0.028551643987645776, 0.028638438077829665, 0.028511234057069092, 0.028616589500338897, 0.028532692238059668], 'acc': [0.9571306551655385, 0.9929317822856578, 0.9940051269347242, 0.9944304012321994, 0.9946871743532062, 0.9949610593337085, 0.9951175472086111, 0.9952055977574711, 0.9953349008775538, 0.9954091999467497, 0.9955036352760697, 0.9955766241079436, 0.9956037480037099, 0.9956854616355746, 0.9957314571494496, 0.9958011833495315, 0.9958615745170692, 0.9958954896919895, 0.9959049452414751, 0.9959463569564818, 0.9959734430943339, 0.9960088633530886, 0.9960429213879068, 0.9960712006366635, 0.9960827072785164, 0.9961297600864022, 0.9961340049819539, 0.9961462939765653, 0.9961961913382282, 0.9961951238470889, 0.9962102333146642, 0.9962292872756633, 0.9962425170980832, 0.9962577001370473, 0.996275336096583, 0.9962859661389075, 0.9962929095316194, 0.9963050623813592, 0.9963282001624644, 0.9963195661676059, 0.9963306057392245, 0.9963437659259896, 0.9963560462227996, 0.9963606660140393, 0.9963754327767369, 0.9963791836120353, 0.9963886479146953, 0.9963885567858445, 0.9963925230216422, 0.9964056138432277, 0.9964110924763393, 0.9964292281995348, 0.9964159598993532, 0.9964382566494859, 0.9964417958922354, 0.9964338905874265, 0.9964412479307438, 0.9964583331431062, 0.9964405487246225, 0.9964593306982995, 0.9964639015271357, 0.9964830428239434, 0.996474836499386, 0.9964772483545786, 0.9964709789392525, 0.9964624299992658, 0.9964888152570319, 0.9964789443449323, 0.9964951802949309, 0.9964765381100869, 0.996507449455403, 0.9965101727170185, 0.9965100658963457, 0.9965041072975083, 0.9965118691460958], 'mDice': [0.7435916529864357, 0.8838678190816947, 0.8988867871936896, 0.9072303545156825, 0.9120341695470562, 0.9175803543253123, 0.9204549855024275, 0.922267024583166, 0.9246795341214358, 0.926167025975264, 0.9276714627883414, 0.9291457748874811, 0.9294661798396925, 0.9310096199371835, 0.931699572803166, 0.9329487311412834, 0.9339298551270112, 0.9346949100519941, 0.9346855758564322, 0.9353499981684628, 0.9359025707193589, 0.9365753301253897, 0.937178602401614, 0.9376763884105512, 0.9377716184152252, 0.9387058623436713, 0.9387755141162146, 0.9387329047667651, 0.9396704069823618, 0.9398466476005692, 0.9400324811845806, 0.9404926941351955, 0.9407198601296023, 0.9410034637233599, 0.9412521102205497, 0.9412080596896977, 0.9416161303535195, 0.9418397034914516, 0.941993651359152, 0.9420797928108742, 0.9423875299200145, 0.9426271030236428, 0.9427706367287063, 0.9429564148035362, 0.9431688827955825, 0.9433419746286374, 0.9435026184340427, 0.9436640658915973, 0.9434574016885972, 0.9437811644032066, 0.9439159181185567, 0.9442213057628308, 0.9438379116817724, 0.9446366039589039, 0.9445189975864162, 0.9446475785781355, 0.9445944144104175, 0.9447561162381999, 0.9445258824201789, 0.9450435383520815, 0.9450176538823736, 0.9452297986309794, 0.9452745817471502, 0.9454660981006509, 0.9453044349572136, 0.9452444870453127, 0.9454829290726988, 0.9454677976178311, 0.9458902599740251, 0.9454205177044712, 0.946136234261264, 0.9459746793143026, 0.9462148743895348, 0.9460165888570481, 0.9461722429015822]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:01<00:04,  1.01s/it]predicting test subjects:  40%|████      | 2/5 [00:01<00:02,  1.23it/s]predicting test subjects:  60%|██████    | 3/5 [00:01<00:01,  1.51it/s]predicting test subjects:  80%|████████  | 4/5 [00:02<00:00,  1.73it/s]predicting test subjects: 100%|██████████| 5/5 [00:02<00:00,  1.93it/s]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:00<01:56,  2.27it/s]predicting train subjects:   1%|          | 2/266 [00:00<01:53,  2.33it/s]predicting train subjects:   1%|          | 3/266 [00:01<01:45,  2.49it/s]predicting train subjects:   2%|▏         | 4/266 [00:01<01:44,  2.51it/s]predicting train subjects:   2%|▏         | 5/266 [00:02<01:47,  2.43it/s]predicting train subjects:   2%|▏         | 6/266 [00:02<01:45,  2.46it/s]predicting train subjects:   3%|▎         | 7/266 [00:02<01:44,  2.47it/s]predicting train subjects:   3%|▎         | 8/266 [00:03<01:40,  2.56it/s]predicting train subjects:   3%|▎         | 9/266 [00:03<01:37,  2.65it/s]predicting train subjects:   4%|▍         | 10/266 [00:03<01:34,  2.71it/s]predicting train subjects:   4%|▍         | 11/266 [00:04<01:36,  2.64it/s]predicting train subjects:   5%|▍         | 12/266 [00:04<01:38,  2.57it/s]predicting train subjects:   5%|▍         | 13/266 [00:05<01:38,  2.58it/s]predicting train subjects:   5%|▌         | 14/266 [00:05<01:35,  2.63it/s]predicting train subjects:   6%|▌         | 15/266 [00:05<01:36,  2.60it/s]predicting train subjects:   6%|▌         | 16/266 [00:06<01:34,  2.65it/s]predicting train subjects:   6%|▋         | 17/266 [00:06<01:32,  2.69it/s]predicting train subjects:   7%|▋         | 18/266 [00:06<01:33,  2.67it/s]predicting train subjects:   7%|▋         | 19/266 [00:07<01:34,  2.62it/s]predicting train subjects:   8%|▊         | 20/266 [00:07<01:32,  2.66it/s]predicting train subjects:   8%|▊         | 21/266 [00:08<01:31,  2.67it/s]predicting train subjects:   8%|▊         | 22/266 [00:08<01:29,  2.71it/s]predicting train subjects:   9%|▊         | 23/266 [00:08<01:30,  2.67it/s]predicting train subjects:   9%|▉         | 24/266 [00:09<01:29,  2.70it/s]predicting train subjects:   9%|▉         | 25/266 [00:09<01:28,  2.72it/s]predicting train subjects:  10%|▉         | 26/266 [00:09<01:29,  2.70it/s]predicting train subjects:  10%|█         | 27/266 [00:10<01:31,  2.60it/s]predicting train subjects:  11%|█         | 28/266 [00:10<01:30,  2.64it/s]predicting train subjects:  11%|█         | 29/266 [00:11<01:27,  2.72it/s]predicting train subjects:  11%|█▏        | 30/266 [00:11<01:25,  2.75it/s]predicting train subjects:  12%|█▏        | 31/266 [00:11<01:24,  2.77it/s]predicting train subjects:  12%|█▏        | 32/266 [00:12<01:24,  2.76it/s]predicting train subjects:  12%|█▏        | 33/266 [00:12<01:24,  2.75it/s]predicting train subjects:  13%|█▎        | 34/266 [00:12<01:25,  2.72it/s]predicting train subjects:  13%|█▎        | 35/266 [00:13<01:22,  2.79it/s]predicting train subjects:  14%|█▎        | 36/266 [00:13<01:20,  2.86it/s]predicting train subjects:  14%|█▍        | 37/266 [00:13<01:20,  2.84it/s]predicting train subjects:  14%|█▍        | 38/266 [00:14<01:23,  2.73it/s]predicting train subjects:  15%|█▍        | 39/266 [00:14<01:22,  2.76it/s]predicting train subjects:  15%|█▌        | 40/266 [00:14<01:19,  2.83it/s]predicting train subjects:  15%|█▌        | 41/266 [00:15<01:19,  2.83it/s]predicting train subjects:  16%|█▌        | 42/266 [00:15<01:17,  2.90it/s]predicting train subjects:  16%|█▌        | 43/266 [00:15<01:14,  2.98it/s]predicting train subjects:  17%|█▋        | 44/266 [00:16<01:10,  3.14it/s]predicting train subjects:  17%|█▋        | 45/266 [00:16<01:08,  3.22it/s]predicting train subjects:  17%|█▋        | 46/266 [00:16<01:06,  3.30it/s]predicting train subjects:  18%|█▊        | 47/266 [00:17<01:06,  3.27it/s]predicting train subjects:  18%|█▊        | 48/266 [00:17<01:05,  3.31it/s]predicting train subjects:  18%|█▊        | 49/266 [00:17<01:06,  3.24it/s]predicting train subjects:  19%|█▉        | 50/266 [00:18<01:09,  3.13it/s]predicting train subjects:  19%|█▉        | 51/266 [00:18<01:08,  3.12it/s]predicting train subjects:  20%|█▉        | 52/266 [00:18<01:08,  3.12it/s]predicting train subjects:  20%|█▉        | 53/266 [00:19<01:07,  3.15it/s]predicting train subjects:  20%|██        | 54/266 [00:19<01:05,  3.25it/s]predicting train subjects:  21%|██        | 55/266 [00:19<01:03,  3.32it/s]predicting train subjects:  21%|██        | 56/266 [00:19<01:03,  3.29it/s]predicting train subjects:  21%|██▏       | 57/266 [00:20<01:04,  3.25it/s]predicting train subjects:  22%|██▏       | 58/266 [00:20<01:03,  3.27it/s]predicting train subjects:  22%|██▏       | 59/266 [00:20<01:04,  3.18it/s]predicting train subjects:  23%|██▎       | 60/266 [00:21<01:02,  3.28it/s]predicting train subjects:  23%|██▎       | 61/266 [00:21<01:00,  3.41it/s]predicting train subjects:  23%|██▎       | 62/266 [00:21<00:58,  3.50it/s]predicting train subjects:  24%|██▎       | 63/266 [00:21<00:57,  3.55it/s]predicting train subjects:  24%|██▍       | 64/266 [00:22<00:56,  3.59it/s]predicting train subjects:  24%|██▍       | 65/266 [00:22<00:56,  3.59it/s]predicting train subjects:  25%|██▍       | 66/266 [00:22<00:57,  3.48it/s]predicting train subjects:  25%|██▌       | 67/266 [00:23<01:00,  3.28it/s]predicting train subjects:  26%|██▌       | 68/266 [00:23<00:59,  3.31it/s]predicting train subjects:  26%|██▌       | 69/266 [00:23<00:57,  3.40it/s]predicting train subjects:  26%|██▋       | 70/266 [00:23<00:56,  3.49it/s]predicting train subjects:  27%|██▋       | 71/266 [00:24<00:55,  3.53it/s]predicting train subjects:  27%|██▋       | 72/266 [00:24<00:54,  3.56it/s]predicting train subjects:  27%|██▋       | 73/266 [00:24<00:53,  3.60it/s]predicting train subjects:  28%|██▊       | 74/266 [00:25<00:53,  3.62it/s]predicting train subjects:  28%|██▊       | 75/266 [00:25<00:52,  3.65it/s]predicting train subjects:  29%|██▊       | 76/266 [00:25<00:51,  3.69it/s]predicting train subjects:  29%|██▉       | 77/266 [00:25<00:52,  3.59it/s]predicting train subjects:  29%|██▉       | 78/266 [00:26<01:04,  2.89it/s]predicting train subjects:  30%|██▉       | 79/266 [00:26<01:06,  2.81it/s]predicting train subjects:  30%|███       | 80/266 [00:27<01:06,  2.80it/s]predicting train subjects:  30%|███       | 81/266 [00:27<01:10,  2.64it/s]predicting train subjects:  31%|███       | 82/266 [00:27<01:09,  2.66it/s]predicting train subjects:  31%|███       | 83/266 [00:28<01:07,  2.72it/s]predicting train subjects:  32%|███▏      | 84/266 [00:28<01:09,  2.62it/s]predicting train subjects:  32%|███▏      | 85/266 [00:29<01:09,  2.62it/s]predicting train subjects:  32%|███▏      | 86/266 [00:29<01:09,  2.61it/s]predicting train subjects:  33%|███▎      | 87/266 [00:29<01:08,  2.62it/s]predicting train subjects:  33%|███▎      | 88/266 [00:30<01:06,  2.69it/s]predicting train subjects:  33%|███▎      | 89/266 [00:30<01:05,  2.68it/s]predicting train subjects:  34%|███▍      | 90/266 [00:30<01:06,  2.66it/s]predicting train subjects:  34%|███▍      | 91/266 [00:31<01:05,  2.68it/s]predicting train subjects:  35%|███▍      | 92/266 [00:31<01:03,  2.75it/s]predicting train subjects:  35%|███▍      | 93/266 [00:32<01:02,  2.77it/s]predicting train subjects:  35%|███▌      | 94/266 [00:32<01:01,  2.82it/s]predicting train subjects:  36%|███▌      | 95/266 [00:32<00:59,  2.85it/s]predicting train subjects:  36%|███▌      | 96/266 [00:33<01:00,  2.81it/s]predicting train subjects:  36%|███▋      | 97/266 [00:33<01:02,  2.72it/s]predicting train subjects:  37%|███▋      | 98/266 [00:33<01:02,  2.69it/s]predicting train subjects:  37%|███▋      | 99/266 [00:34<00:56,  2.93it/s]predicting train subjects:  38%|███▊      | 100/266 [00:34<00:55,  2.98it/s]predicting train subjects:  38%|███▊      | 101/266 [00:34<00:55,  2.96it/s]predicting train subjects:  38%|███▊      | 102/266 [00:35<00:53,  3.05it/s]predicting train subjects:  39%|███▊      | 103/266 [00:35<00:53,  3.07it/s]predicting train subjects:  39%|███▉      | 104/266 [00:35<00:51,  3.12it/s]predicting train subjects:  39%|███▉      | 105/266 [00:36<00:50,  3.16it/s]predicting train subjects:  40%|███▉      | 106/266 [00:36<00:49,  3.21it/s]predicting train subjects:  40%|████      | 107/266 [00:36<00:50,  3.14it/s]predicting train subjects:  41%|████      | 108/266 [00:36<00:50,  3.14it/s]predicting train subjects:  41%|████      | 109/266 [00:37<00:49,  3.19it/s]predicting train subjects:  41%|████▏     | 110/266 [00:37<00:49,  3.18it/s]predicting train subjects:  42%|████▏     | 111/266 [00:37<00:48,  3.20it/s]predicting train subjects:  42%|████▏     | 112/266 [00:38<00:48,  3.19it/s]predicting train subjects:  42%|████▏     | 113/266 [00:38<00:48,  3.18it/s]predicting train subjects:  43%|████▎     | 114/266 [00:38<00:47,  3.22it/s]predicting train subjects:  43%|████▎     | 115/266 [00:39<00:46,  3.22it/s]predicting train subjects:  44%|████▎     | 116/266 [00:39<00:46,  3.21it/s]predicting train subjects:  44%|████▍     | 117/266 [00:39<00:47,  3.13it/s]predicting train subjects:  44%|████▍     | 118/266 [00:40<00:46,  3.17it/s]predicting train subjects:  45%|████▍     | 119/266 [00:40<00:47,  3.09it/s]predicting train subjects:  45%|████▌     | 120/266 [00:40<00:50,  2.90it/s]predicting train subjects:  45%|████▌     | 121/266 [00:41<00:52,  2.77it/s]predicting train subjects:  46%|████▌     | 122/266 [00:41<00:53,  2.69it/s]predicting train subjects:  46%|████▌     | 123/266 [00:41<00:51,  2.77it/s]predicting train subjects:  47%|████▋     | 124/266 [00:42<00:52,  2.70it/s]predicting train subjects:  47%|████▋     | 125/266 [00:42<00:51,  2.73it/s]predicting train subjects:  47%|████▋     | 126/266 [00:43<00:51,  2.72it/s]predicting train subjects:  48%|████▊     | 127/266 [00:43<00:50,  2.77it/s]predicting train subjects:  48%|████▊     | 128/266 [00:43<00:49,  2.77it/s]predicting train subjects:  48%|████▊     | 129/266 [00:44<00:48,  2.81it/s]predicting train subjects:  49%|████▉     | 130/266 [00:44<00:47,  2.85it/s]predicting train subjects:  49%|████▉     | 131/266 [00:44<00:46,  2.88it/s]predicting train subjects:  50%|████▉     | 132/266 [00:45<00:47,  2.83it/s]predicting train subjects:  50%|█████     | 133/266 [00:45<00:48,  2.74it/s]predicting train subjects:  50%|█████     | 134/266 [00:45<00:47,  2.79it/s]predicting train subjects:  51%|█████     | 135/266 [00:46<00:46,  2.83it/s]predicting train subjects:  51%|█████     | 136/266 [00:46<00:46,  2.78it/s]predicting train subjects:  52%|█████▏    | 137/266 [00:46<00:45,  2.85it/s]predicting train subjects:  52%|█████▏    | 138/266 [00:47<00:45,  2.83it/s]predicting train subjects:  52%|█████▏    | 139/266 [00:47<00:45,  2.77it/s]predicting train subjects:  53%|█████▎    | 140/266 [00:48<00:45,  2.79it/s]predicting train subjects:  53%|█████▎    | 141/266 [00:48<00:43,  2.87it/s]predicting train subjects:  53%|█████▎    | 142/266 [00:48<00:42,  2.93it/s]predicting train subjects:  54%|█████▍    | 143/266 [00:49<00:41,  2.96it/s]predicting train subjects:  54%|█████▍    | 144/266 [00:49<00:40,  3.04it/s]predicting train subjects:  55%|█████▍    | 145/266 [00:49<00:40,  2.98it/s]predicting train subjects:  55%|█████▍    | 146/266 [00:50<00:39,  3.03it/s]predicting train subjects:  55%|█████▌    | 147/266 [00:50<00:39,  2.98it/s]predicting train subjects:  56%|█████▌    | 148/266 [00:50<00:39,  2.99it/s]predicting train subjects:  56%|█████▌    | 149/266 [00:51<00:40,  2.89it/s]predicting train subjects:  56%|█████▋    | 150/266 [00:51<00:39,  2.92it/s]predicting train subjects:  57%|█████▋    | 151/266 [00:51<00:39,  2.88it/s]predicting train subjects:  57%|█████▋    | 152/266 [00:52<00:38,  2.95it/s]predicting train subjects:  58%|█████▊    | 153/266 [00:52<00:38,  2.95it/s]predicting train subjects:  58%|█████▊    | 154/266 [00:52<00:37,  2.99it/s]predicting train subjects:  58%|█████▊    | 155/266 [00:53<00:34,  3.20it/s]predicting train subjects:  59%|█████▊    | 156/266 [00:53<00:32,  3.41it/s]predicting train subjects:  59%|█████▉    | 157/266 [00:53<00:30,  3.56it/s]predicting train subjects:  59%|█████▉    | 158/266 [00:53<00:29,  3.64it/s]predicting train subjects:  60%|█████▉    | 159/266 [00:54<00:29,  3.67it/s]predicting train subjects:  60%|██████    | 160/266 [00:54<00:29,  3.54it/s]predicting train subjects:  61%|██████    | 161/266 [00:54<00:29,  3.51it/s]predicting train subjects:  61%|██████    | 162/266 [00:54<00:29,  3.56it/s]predicting train subjects:  61%|██████▏   | 163/266 [00:55<00:27,  3.69it/s]predicting train subjects:  62%|██████▏   | 164/266 [00:55<00:28,  3.60it/s]predicting train subjects:  62%|██████▏   | 165/266 [00:55<00:27,  3.70it/s]predicting train subjects:  62%|██████▏   | 166/266 [00:55<00:26,  3.78it/s]predicting train subjects:  63%|██████▎   | 167/266 [00:56<00:26,  3.75it/s]predicting train subjects:  63%|██████▎   | 168/266 [00:56<00:26,  3.74it/s]predicting train subjects:  64%|██████▎   | 169/266 [00:56<00:25,  3.78it/s]predicting train subjects:  64%|██████▍   | 170/266 [00:57<00:26,  3.69it/s]predicting train subjects:  64%|██████▍   | 171/266 [00:57<00:25,  3.68it/s]predicting train subjects:  65%|██████▍   | 172/266 [00:57<00:24,  3.77it/s]predicting train subjects:  65%|██████▌   | 173/266 [00:57<00:25,  3.60it/s]predicting train subjects:  65%|██████▌   | 174/266 [00:58<00:27,  3.35it/s]predicting train subjects:  66%|██████▌   | 175/266 [00:58<00:27,  3.33it/s]predicting train subjects:  66%|██████▌   | 176/266 [00:58<00:27,  3.22it/s]predicting train subjects:  67%|██████▋   | 177/266 [00:59<00:26,  3.31it/s]predicting train subjects:  67%|██████▋   | 178/266 [00:59<00:27,  3.25it/s]predicting train subjects:  67%|██████▋   | 179/266 [00:59<00:25,  3.35it/s]predicting train subjects:  68%|██████▊   | 180/266 [01:00<00:25,  3.42it/s]predicting train subjects:  68%|██████▊   | 181/266 [01:00<00:25,  3.28it/s]predicting train subjects:  68%|██████▊   | 182/266 [01:00<00:25,  3.34it/s]predicting train subjects:  69%|██████▉   | 183/266 [01:00<00:25,  3.27it/s]predicting train subjects:  69%|██████▉   | 184/266 [01:01<00:25,  3.26it/s]predicting train subjects:  70%|██████▉   | 185/266 [01:01<00:25,  3.23it/s]predicting train subjects:  70%|██████▉   | 186/266 [01:01<00:24,  3.27it/s]predicting train subjects:  70%|███████   | 187/266 [01:02<00:24,  3.29it/s]predicting train subjects:  71%|███████   | 188/266 [01:02<00:23,  3.32it/s]predicting train subjects:  71%|███████   | 189/266 [01:02<00:22,  3.38it/s]predicting train subjects:  71%|███████▏  | 190/266 [01:03<00:22,  3.39it/s]predicting train subjects:  72%|███████▏  | 191/266 [01:03<00:23,  3.21it/s]predicting train subjects:  72%|███████▏  | 192/266 [01:03<00:23,  3.09it/s]predicting train subjects:  73%|███████▎  | 193/266 [01:04<00:23,  3.10it/s]predicting train subjects:  73%|███████▎  | 194/266 [01:04<00:25,  2.87it/s]predicting train subjects:  73%|███████▎  | 195/266 [01:04<00:24,  2.95it/s]predicting train subjects:  74%|███████▎  | 196/266 [01:05<00:23,  2.96it/s]predicting train subjects:  74%|███████▍  | 197/266 [01:05<00:23,  2.96it/s]predicting train subjects:  74%|███████▍  | 198/266 [01:05<00:22,  3.04it/s]predicting train subjects:  75%|███████▍  | 199/266 [01:06<00:21,  3.13it/s]predicting train subjects:  75%|███████▌  | 200/266 [01:06<00:21,  3.06it/s]predicting train subjects:  76%|███████▌  | 201/266 [01:06<00:20,  3.19it/s]predicting train subjects:  76%|███████▌  | 202/266 [01:07<00:19,  3.25it/s]predicting train subjects:  76%|███████▋  | 203/266 [01:07<00:18,  3.33it/s]predicting train subjects:  77%|███████▋  | 204/266 [01:07<00:18,  3.38it/s]predicting train subjects:  77%|███████▋  | 205/266 [01:07<00:18,  3.22it/s]predicting train subjects:  77%|███████▋  | 206/266 [01:08<00:18,  3.19it/s]predicting train subjects:  78%|███████▊  | 207/266 [01:08<00:18,  3.19it/s]predicting train subjects:  78%|███████▊  | 208/266 [01:08<00:17,  3.25it/s]predicting train subjects:  79%|███████▊  | 209/266 [01:09<00:17,  3.26it/s]predicting train subjects:  79%|███████▉  | 210/266 [01:09<00:16,  3.32it/s]predicting train subjects:  79%|███████▉  | 211/266 [01:09<00:16,  3.26it/s]predicting train subjects:  80%|███████▉  | 212/266 [01:10<00:17,  3.13it/s]predicting train subjects:  80%|████████  | 213/266 [01:10<00:16,  3.18it/s]predicting train subjects:  80%|████████  | 214/266 [01:10<00:15,  3.36it/s]predicting train subjects:  81%|████████  | 215/266 [01:10<00:14,  3.43it/s]predicting train subjects:  81%|████████  | 216/266 [01:11<00:14,  3.45it/s]predicting train subjects:  82%|████████▏ | 217/266 [01:11<00:13,  3.58it/s]predicting train subjects:  82%|████████▏ | 218/266 [01:11<00:13,  3.65it/s]predicting train subjects:  82%|████████▏ | 219/266 [01:12<00:13,  3.54it/s]predicting train subjects:  83%|████████▎ | 220/266 [01:12<00:13,  3.50it/s]predicting train subjects:  83%|████████▎ | 221/266 [01:12<00:12,  3.47it/s]predicting train subjects:  83%|████████▎ | 222/266 [01:12<00:12,  3.54it/s]predicting train subjects:  84%|████████▍ | 223/266 [01:13<00:12,  3.55it/s]predicting train subjects:  84%|████████▍ | 224/266 [01:13<00:11,  3.68it/s]predicting train subjects:  85%|████████▍ | 225/266 [01:13<00:10,  3.77it/s]predicting train subjects:  85%|████████▍ | 226/266 [01:13<00:10,  3.68it/s]predicting train subjects:  85%|████████▌ | 227/266 [01:14<00:10,  3.62it/s]predicting train subjects:  86%|████████▌ | 228/266 [01:14<00:10,  3.52it/s]predicting train subjects:  86%|████████▌ | 229/266 [01:14<00:10,  3.66it/s]predicting train subjects:  86%|████████▋ | 230/266 [01:15<00:09,  3.72it/s]predicting train subjects:  87%|████████▋ | 231/266 [01:15<00:09,  3.72it/s]predicting train subjects:  87%|████████▋ | 232/266 [01:15<00:09,  3.51it/s]predicting train subjects:  88%|████████▊ | 233/266 [01:15<00:09,  3.52it/s]predicting train subjects:  88%|████████▊ | 234/266 [01:16<00:09,  3.46it/s]predicting train subjects:  88%|████████▊ | 235/266 [01:16<00:09,  3.39it/s]predicting train subjects:  89%|████████▊ | 236/266 [01:16<00:08,  3.51it/s]predicting train subjects:  89%|████████▉ | 237/266 [01:17<00:08,  3.57it/s]predicting train subjects:  89%|████████▉ | 238/266 [01:17<00:07,  3.55it/s]predicting train subjects:  90%|████████▉ | 239/266 [01:17<00:07,  3.63it/s]predicting train subjects:  90%|█████████ | 240/266 [01:17<00:07,  3.49it/s]predicting train subjects:  91%|█████████ | 241/266 [01:18<00:07,  3.41it/s]predicting train subjects:  91%|█████████ | 242/266 [01:18<00:06,  3.52it/s]predicting train subjects:  91%|█████████▏| 243/266 [01:18<00:06,  3.44it/s]predicting train subjects:  92%|█████████▏| 244/266 [01:19<00:06,  3.50it/s]predicting train subjects:  92%|█████████▏| 245/266 [01:19<00:05,  3.52it/s]predicting train subjects:  92%|█████████▏| 246/266 [01:19<00:05,  3.44it/s]predicting train subjects:  93%|█████████▎| 247/266 [01:19<00:05,  3.37it/s]predicting train subjects:  93%|█████████▎| 248/266 [01:20<00:05,  3.33it/s]predicting train subjects:  94%|█████████▎| 249/266 [01:20<00:05,  3.10it/s]predicting train subjects:  94%|█████████▍| 250/266 [01:21<00:05,  3.03it/s]predicting train subjects:  94%|█████████▍| 251/266 [01:21<00:05,  2.99it/s]predicting train subjects:  95%|█████████▍| 252/266 [01:21<00:04,  2.98it/s]predicting train subjects:  95%|█████████▌| 253/266 [01:22<00:04,  2.97it/s]predicting train subjects:  95%|█████████▌| 254/266 [01:22<00:03,  3.01it/s]predicting train subjects:  96%|█████████▌| 255/266 [01:22<00:03,  2.98it/s]predicting train subjects:  96%|█████████▌| 256/266 [01:23<00:03,  3.00it/s]predicting train subjects:  97%|█████████▋| 257/266 [01:23<00:03,  2.96it/s]predicting train subjects:  97%|█████████▋| 258/266 [01:23<00:02,  3.01it/s]predicting train subjects:  97%|█████████▋| 259/266 [01:24<00:02,  2.96it/s]predicting train subjects:  98%|█████████▊| 260/266 [01:24<00:02,  2.99it/s]predicting train subjects:  98%|█████████▊| 261/266 [01:24<00:01,  2.90it/s]predicting train subjects:  98%|█████████▊| 262/266 [01:25<00:01,  2.86it/s]predicting train subjects:  99%|█████████▉| 263/266 [01:25<00:01,  2.91it/s]predicting train subjects:  99%|█████████▉| 264/266 [01:25<00:00,  2.93it/s]predicting train subjects: 100%|█████████▉| 265/266 [01:26<00:00,  2.93it/s]predicting train subjects: 100%|██████████| 266/266 [01:26<00:00,  2.95it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 66.97it/s]
saving BB  train1-THALAMUS:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   2%|▏         | 6/266 [00:00<00:04, 58.64it/s]saving BB  train1-THALAMUS:   5%|▍         | 13/266 [00:00<00:04, 59.77it/s]saving BB  train1-THALAMUS:   8%|▊         | 20/266 [00:00<00:03, 61.57it/s]saving BB  train1-THALAMUS:  10%|█         | 27/266 [00:00<00:03, 63.19it/s]saving BB  train1-THALAMUS:  13%|█▎        | 35/266 [00:00<00:03, 65.60it/s]saving BB  train1-THALAMUS:  16%|█▌        | 43/266 [00:00<00:03, 67.62it/s]saving BB  train1-THALAMUS:  19%|█▉        | 51/266 [00:00<00:03, 70.26it/s]saving BB  train1-THALAMUS:  22%|██▏       | 59/266 [00:00<00:02, 71.73it/s]saving BB  train1-THALAMUS:  26%|██▌       | 68/266 [00:00<00:02, 74.62it/s]saving BB  train1-THALAMUS:  29%|██▉       | 77/266 [00:01<00:02, 76.43it/s]saving BB  train1-THALAMUS:  32%|███▏      | 85/266 [00:01<00:02, 74.77it/s]saving BB  train1-THALAMUS:  35%|███▍      | 93/266 [00:01<00:02, 73.84it/s]saving BB  train1-THALAMUS:  38%|███▊      | 101/266 [00:01<00:02, 72.31it/s]saving BB  train1-THALAMUS:  41%|████      | 109/266 [00:01<00:02, 73.71it/s]saving BB  train1-THALAMUS:  44%|████▍     | 117/266 [00:01<00:02, 73.76it/s]saving BB  train1-THALAMUS:  47%|████▋     | 125/266 [00:01<00:01, 72.50it/s]saving BB  train1-THALAMUS:  50%|█████     | 133/266 [00:01<00:01, 71.68it/s]saving BB  train1-THALAMUS:  53%|█████▎    | 141/266 [00:01<00:01, 71.02it/s]saving BB  train1-THALAMUS:  56%|█████▌    | 149/266 [00:02<00:01, 70.54it/s]saving BB  train1-THALAMUS:  59%|█████▉    | 157/266 [00:02<00:01, 71.52it/s]saving BB  train1-THALAMUS:  62%|██████▏   | 166/266 [00:02<00:01, 74.89it/s]saving BB  train1-THALAMUS:  66%|██████▌   | 175/266 [00:02<00:01, 77.13it/s]saving BB  train1-THALAMUS:  69%|██████▉   | 184/266 [00:02<00:01, 78.98it/s]saving BB  train1-THALAMUS:  72%|███████▏  | 192/266 [00:02<00:00, 79.27it/s]saving BB  train1-THALAMUS:  75%|███████▌  | 200/266 [00:02<00:00, 77.44it/s]saving BB  train1-THALAMUS:  78%|███████▊  | 208/266 [00:02<00:00, 76.99it/s]saving BB  train1-THALAMUS:  81%|████████  | 216/266 [00:02<00:00, 76.83it/s]saving BB  train1-THALAMUS:  84%|████████▍ | 224/266 [00:03<00:00, 76.94it/s]saving BB  train1-THALAMUS:  87%|████████▋ | 232/266 [00:03<00:00, 70.72it/s]saving BB  train1-THALAMUS:  90%|█████████ | 240/266 [00:03<00:00, 71.61it/s]saving BB  train1-THALAMUS:  93%|█████████▎| 248/266 [00:03<00:00, 73.57it/s]saving BB  train1-THALAMUS:  96%|█████████▌| 256/266 [00:03<00:00, 72.75it/s]saving BB  train1-THALAMUS:  99%|█████████▉| 264/266 [00:03<00:00, 71.85it/s]saving BB  train1-THALAMUS: 100%|██████████| 266/266 [00:03<00:00, 73.03it/s]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:01<08:13,  1.86s/it]Loading train:   1%|          | 2/266 [00:03<07:49,  1.78s/it]Loading train:   1%|          | 3/266 [00:04<07:17,  1.66s/it]Loading train:   2%|▏         | 4/266 [00:06<06:46,  1.55s/it]Loading train:   2%|▏         | 5/266 [00:07<06:54,  1.59s/it]Loading train:   2%|▏         | 6/266 [00:08<06:19,  1.46s/it]Loading train:   3%|▎         | 7/266 [00:10<05:52,  1.36s/it]Loading train:   3%|▎         | 8/266 [00:11<05:38,  1.31s/it]Loading train:   3%|▎         | 9/266 [00:12<05:23,  1.26s/it]Loading train:   4%|▍         | 10/266 [00:13<05:15,  1.23s/it]Loading train:   4%|▍         | 11/266 [00:14<05:03,  1.19s/it]Loading train:   5%|▍         | 12/266 [00:15<05:03,  1.20s/it]Loading train:   5%|▍         | 13/266 [00:17<04:59,  1.18s/it]Loading train:   5%|▌         | 14/266 [00:18<04:55,  1.17s/it]Loading train:   6%|▌         | 15/266 [00:19<04:58,  1.19s/it]Loading train:   6%|▌         | 16/266 [00:20<05:00,  1.20s/it]Loading train:   6%|▋         | 17/266 [00:21<04:49,  1.16s/it]Loading train:   7%|▋         | 18/266 [00:22<04:40,  1.13s/it]Loading train:   7%|▋         | 19/266 [00:23<04:33,  1.11s/it]Loading train:   8%|▊         | 20/266 [00:25<04:36,  1.12s/it]Loading train:   8%|▊         | 21/266 [00:26<04:39,  1.14s/it]Loading train:   8%|▊         | 22/266 [00:27<04:43,  1.16s/it]Loading train:   9%|▊         | 23/266 [00:28<04:49,  1.19s/it]Loading train:   9%|▉         | 24/266 [00:29<04:37,  1.15s/it]Loading train:   9%|▉         | 25/266 [00:30<04:28,  1.12s/it]Loading train:  10%|▉         | 26/266 [00:31<04:21,  1.09s/it]Loading train:  10%|█         | 27/266 [00:32<04:11,  1.05s/it]Loading train:  11%|█         | 28/266 [00:33<04:09,  1.05s/it]Loading train:  11%|█         | 29/266 [00:34<04:09,  1.05s/it]Loading train:  11%|█▏        | 30/266 [00:35<04:01,  1.03s/it]Loading train:  12%|█▏        | 31/266 [00:36<04:00,  1.02s/it]Loading train:  12%|█▏        | 32/266 [00:37<03:51,  1.01it/s]Loading train:  12%|█▏        | 33/266 [00:38<03:43,  1.04it/s]Loading train:  13%|█▎        | 34/266 [00:39<03:35,  1.08it/s]Loading train:  13%|█▎        | 35/266 [00:40<03:30,  1.10it/s]Loading train:  14%|█▎        | 36/266 [00:41<03:26,  1.11it/s]Loading train:  14%|█▍        | 37/266 [00:42<03:25,  1.11it/s]Loading train:  14%|█▍        | 38/266 [00:42<03:24,  1.12it/s]Loading train:  15%|█▍        | 39/266 [00:43<03:22,  1.12it/s]Loading train:  15%|█▌        | 40/266 [00:44<03:21,  1.12it/s]Loading train:  15%|█▌        | 41/266 [00:45<03:24,  1.10it/s]Loading train:  16%|█▌        | 42/266 [00:46<03:32,  1.05it/s]Loading train:  16%|█▌        | 43/266 [00:47<03:24,  1.09it/s]Loading train:  17%|█▋        | 44/266 [00:48<03:14,  1.14it/s]Loading train:  17%|█▋        | 45/266 [00:49<03:12,  1.15it/s]Loading train:  17%|█▋        | 46/266 [00:50<03:09,  1.16it/s]Loading train:  18%|█▊        | 47/266 [00:50<03:10,  1.15it/s]Loading train:  18%|█▊        | 48/266 [00:51<03:10,  1.15it/s]Loading train:  18%|█▊        | 49/266 [00:52<03:04,  1.17it/s]Loading train:  19%|█▉        | 50/266 [00:53<03:11,  1.13it/s]Loading train:  19%|█▉        | 51/266 [00:54<03:12,  1.12it/s]Loading train:  20%|█▉        | 52/266 [00:55<03:12,  1.11it/s]Loading train:  20%|█▉        | 53/266 [00:56<03:09,  1.12it/s]Loading train:  20%|██        | 54/266 [00:57<03:06,  1.14it/s]Loading train:  21%|██        | 55/266 [00:58<03:05,  1.14it/s]Loading train:  21%|██        | 56/266 [00:58<02:57,  1.18it/s]Loading train:  21%|██▏       | 57/266 [00:59<02:58,  1.17it/s]Loading train:  22%|██▏       | 58/266 [01:00<02:57,  1.17it/s]Loading train:  22%|██▏       | 59/266 [01:01<02:59,  1.15it/s]Loading train:  23%|██▎       | 60/266 [01:02<02:56,  1.17it/s]Loading train:  23%|██▎       | 61/266 [01:03<02:50,  1.21it/s]Loading train:  23%|██▎       | 62/266 [01:03<02:52,  1.19it/s]Loading train:  24%|██▎       | 63/266 [01:04<02:47,  1.21it/s]Loading train:  24%|██▍       | 64/266 [01:05<02:39,  1.27it/s]Loading train:  24%|██▍       | 65/266 [01:06<02:50,  1.18it/s]Loading train:  25%|██▍       | 66/266 [01:07<02:47,  1.19it/s]Loading train:  25%|██▌       | 67/266 [01:07<02:40,  1.24it/s]Loading train:  26%|██▌       | 68/266 [01:08<02:39,  1.24it/s]Loading train:  26%|██▌       | 69/266 [01:09<02:41,  1.22it/s]Loading train:  26%|██▋       | 70/266 [01:10<02:40,  1.22it/s]Loading train:  27%|██▋       | 71/266 [01:11<02:49,  1.15it/s]Loading train:  27%|██▋       | 72/266 [01:12<02:48,  1.15it/s]Loading train:  27%|██▋       | 73/266 [01:13<02:41,  1.20it/s]Loading train:  28%|██▊       | 74/266 [01:13<02:40,  1.20it/s]Loading train:  28%|██▊       | 75/266 [01:14<02:39,  1.20it/s]Loading train:  29%|██▊       | 76/266 [01:15<02:34,  1.23it/s]Loading train:  29%|██▉       | 77/266 [01:16<02:37,  1.20it/s]Loading train:  29%|██▉       | 78/266 [01:17<02:47,  1.12it/s]Loading train:  30%|██▉       | 79/266 [01:18<02:51,  1.09it/s]Loading train:  30%|███       | 80/266 [01:19<02:54,  1.07it/s]Loading train:  30%|███       | 81/266 [01:20<02:53,  1.07it/s]Loading train:  31%|███       | 82/266 [01:21<02:49,  1.08it/s]Loading train:  31%|███       | 83/266 [01:22<02:49,  1.08it/s]Loading train:  32%|███▏      | 84/266 [01:22<02:48,  1.08it/s]Loading train:  32%|███▏      | 85/266 [01:23<02:49,  1.07it/s]Loading train:  32%|███▏      | 86/266 [01:24<02:53,  1.04it/s]Loading train:  33%|███▎      | 87/266 [01:25<02:49,  1.05it/s]Loading train:  33%|███▎      | 88/266 [01:26<02:46,  1.07it/s]Loading train:  33%|███▎      | 89/266 [01:28<02:59,  1.01s/it]Loading train:  34%|███▍      | 90/266 [01:28<02:57,  1.01s/it]Loading train:  34%|███▍      | 91/266 [01:29<02:54,  1.00it/s]Loading train:  35%|███▍      | 92/266 [01:30<02:49,  1.03it/s]Loading train:  35%|███▍      | 93/266 [01:31<02:46,  1.04it/s]Loading train:  35%|███▌      | 94/266 [01:32<02:43,  1.05it/s]Loading train:  36%|███▌      | 95/266 [01:33<02:50,  1.00it/s]Loading train:  36%|███▌      | 96/266 [01:35<03:16,  1.15s/it]Loading train:  36%|███▋      | 97/266 [01:37<03:40,  1.31s/it]Loading train:  37%|███▋      | 98/266 [01:38<03:40,  1.31s/it]Loading train:  37%|███▋      | 99/266 [01:39<03:30,  1.26s/it]Loading train:  38%|███▊      | 100/266 [01:40<03:28,  1.26s/it]Loading train:  38%|███▊      | 101/266 [01:41<03:15,  1.18s/it]Loading train:  38%|███▊      | 102/266 [01:42<03:02,  1.11s/it]Loading train:  39%|███▊      | 103/266 [01:43<02:52,  1.06s/it]Loading train:  39%|███▉      | 104/266 [01:44<02:45,  1.02s/it]Loading train:  39%|███▉      | 105/266 [01:45<02:41,  1.00s/it]Loading train:  40%|███▉      | 106/266 [01:46<02:37,  1.02it/s]Loading train:  40%|████      | 107/266 [01:47<02:29,  1.07it/s]Loading train:  41%|████      | 108/266 [01:48<02:27,  1.07it/s]Loading train:  41%|████      | 109/266 [01:49<02:31,  1.04it/s]Loading train:  41%|████▏     | 110/266 [01:50<02:32,  1.03it/s]Loading train:  42%|████▏     | 111/266 [01:51<02:27,  1.05it/s]Loading train:  42%|████▏     | 112/266 [01:52<02:26,  1.05it/s]Loading train:  42%|████▏     | 113/266 [01:53<02:26,  1.04it/s]Loading train:  43%|████▎     | 114/266 [01:53<02:23,  1.06it/s]Loading train:  43%|████▎     | 115/266 [01:54<02:22,  1.06it/s]Loading train:  44%|████▎     | 116/266 [01:55<02:20,  1.07it/s]Loading train:  44%|████▍     | 117/266 [01:56<02:22,  1.05it/s]Loading train:  44%|████▍     | 118/266 [01:57<02:24,  1.03it/s]Loading train:  45%|████▍     | 119/266 [01:58<02:26,  1.00it/s]Loading train:  45%|████▌     | 120/266 [01:59<02:28,  1.02s/it]Loading train:  45%|████▌     | 121/266 [02:00<02:26,  1.01s/it]Loading train:  46%|████▌     | 122/266 [02:01<02:24,  1.00s/it]Loading train:  46%|████▌     | 123/266 [02:02<02:21,  1.01it/s]Loading train:  47%|████▋     | 124/266 [02:04<02:25,  1.02s/it]Loading train:  47%|████▋     | 125/266 [02:05<02:23,  1.02s/it]Loading train:  47%|████▋     | 126/266 [02:06<02:22,  1.02s/it]Loading train:  48%|████▊     | 127/266 [02:07<02:22,  1.02s/it]Loading train:  48%|████▊     | 128/266 [02:08<02:21,  1.03s/it]Loading train:  48%|████▊     | 129/266 [02:09<02:18,  1.01s/it]Loading train:  49%|████▉     | 130/266 [02:10<02:21,  1.04s/it]Loading train:  49%|████▉     | 131/266 [02:11<02:17,  1.02s/it]Loading train:  50%|████▉     | 132/266 [02:12<02:17,  1.03s/it]Loading train:  50%|█████     | 133/266 [02:13<02:19,  1.05s/it]Loading train:  50%|█████     | 134/266 [02:14<02:14,  1.02s/it]Loading train:  51%|█████     | 135/266 [02:15<02:16,  1.04s/it]Loading train:  51%|█████     | 136/266 [02:16<02:14,  1.04s/it]Loading train:  52%|█████▏    | 137/266 [02:17<02:15,  1.05s/it]Loading train:  52%|█████▏    | 138/266 [02:18<02:17,  1.07s/it]Loading train:  52%|█████▏    | 139/266 [02:19<02:13,  1.05s/it]Loading train:  53%|█████▎    | 140/266 [02:20<02:11,  1.04s/it]Loading train:  53%|█████▎    | 141/266 [02:21<02:11,  1.05s/it]Loading train:  53%|█████▎    | 142/266 [02:22<02:08,  1.03s/it]Loading train:  54%|█████▍    | 143/266 [02:23<02:05,  1.02s/it]Loading train:  54%|█████▍    | 144/266 [02:24<02:02,  1.01s/it]Loading train:  55%|█████▍    | 145/266 [02:25<01:58,  1.02it/s]Loading train:  55%|█████▍    | 146/266 [02:26<02:02,  1.02s/it]Loading train:  55%|█████▌    | 147/266 [02:27<02:01,  1.02s/it]Loading train:  56%|█████▌    | 148/266 [02:28<01:57,  1.01it/s]Loading train:  56%|█████▌    | 149/266 [02:29<01:57,  1.00s/it]Loading train:  56%|█████▋    | 150/266 [02:30<01:54,  1.01it/s]Loading train:  57%|█████▋    | 151/266 [02:31<01:50,  1.04it/s]Loading train:  57%|█████▋    | 152/266 [02:32<01:51,  1.02it/s]Loading train:  58%|█████▊    | 153/266 [02:33<01:52,  1.00it/s]Loading train:  58%|█████▊    | 154/266 [02:34<01:57,  1.05s/it]Loading train:  58%|█████▊    | 155/266 [02:35<01:49,  1.01it/s]Loading train:  59%|█████▊    | 156/266 [02:36<01:45,  1.05it/s]Loading train:  59%|█████▉    | 157/266 [02:37<01:43,  1.05it/s]Loading train:  59%|█████▉    | 158/266 [02:38<01:41,  1.07it/s]Loading train:  60%|█████▉    | 159/266 [02:39<01:38,  1.08it/s]Loading train:  60%|██████    | 160/266 [02:40<01:38,  1.08it/s]Loading train:  61%|██████    | 161/266 [02:40<01:32,  1.14it/s]Loading train:  61%|██████    | 162/266 [02:41<01:25,  1.21it/s]Loading train:  61%|██████▏   | 163/266 [02:42<01:22,  1.24it/s]Loading train:  62%|██████▏   | 164/266 [02:43<01:24,  1.21it/s]Loading train:  62%|██████▏   | 165/266 [02:43<01:21,  1.25it/s]Loading train:  62%|██████▏   | 166/266 [02:44<01:17,  1.29it/s]Loading train:  63%|██████▎   | 167/266 [02:45<01:25,  1.15it/s]Loading train:  63%|██████▎   | 168/266 [02:46<01:24,  1.17it/s]Loading train:  64%|██████▎   | 169/266 [02:47<01:24,  1.15it/s]Loading train:  64%|██████▍   | 170/266 [02:48<01:28,  1.08it/s]Loading train:  64%|██████▍   | 171/266 [02:49<01:25,  1.11it/s]Loading train:  65%|██████▍   | 172/266 [02:50<01:21,  1.15it/s]Loading train:  65%|██████▌   | 173/266 [02:51<01:20,  1.15it/s]Loading train:  65%|██████▌   | 174/266 [02:51<01:15,  1.22it/s]Loading train:  66%|██████▌   | 175/266 [02:52<01:15,  1.21it/s]Loading train:  66%|██████▌   | 176/266 [02:53<01:15,  1.19it/s]Loading train:  67%|██████▋   | 177/266 [02:54<01:12,  1.22it/s]Loading train:  67%|██████▋   | 178/266 [02:55<01:09,  1.26it/s]Loading train:  67%|██████▋   | 179/266 [02:55<01:09,  1.26it/s]Loading train:  68%|██████▊   | 180/266 [02:56<01:07,  1.27it/s]Loading train:  68%|██████▊   | 181/266 [02:57<01:08,  1.23it/s]Loading train:  68%|██████▊   | 182/266 [02:58<01:07,  1.25it/s]Loading train:  69%|██████▉   | 183/266 [02:58<01:05,  1.26it/s]Loading train:  69%|██████▉   | 184/266 [02:59<01:03,  1.29it/s]Loading train:  70%|██████▉   | 185/266 [03:00<01:06,  1.22it/s]Loading train:  70%|██████▉   | 186/266 [03:01<01:08,  1.18it/s]Loading train:  70%|███████   | 187/266 [03:02<01:08,  1.15it/s]Loading train:  71%|███████   | 188/266 [03:03<01:06,  1.17it/s]Loading train:  71%|███████   | 189/266 [03:04<01:07,  1.14it/s]Loading train:  71%|███████▏  | 190/266 [03:05<01:06,  1.15it/s]Loading train:  72%|███████▏  | 191/266 [03:06<01:14,  1.00it/s]Loading train:  72%|███████▏  | 192/266 [03:07<01:18,  1.07s/it]Loading train:  73%|███████▎  | 193/266 [03:08<01:18,  1.07s/it]Loading train:  73%|███████▎  | 194/266 [03:10<01:31,  1.27s/it]Loading train:  73%|███████▎  | 195/266 [03:11<01:21,  1.15s/it]Loading train:  74%|███████▎  | 196/266 [03:12<01:12,  1.04s/it]Loading train:  74%|███████▍  | 197/266 [03:12<01:07,  1.03it/s]Loading train:  74%|███████▍  | 198/266 [03:13<01:07,  1.01it/s]Loading train:  75%|███████▍  | 199/266 [03:14<01:06,  1.01it/s]Loading train:  75%|███████▌  | 200/266 [03:15<01:04,  1.03it/s]Loading train:  76%|███████▌  | 201/266 [03:16<01:03,  1.02it/s]Loading train:  76%|███████▌  | 202/266 [03:17<01:00,  1.06it/s]Loading train:  76%|███████▋  | 203/266 [03:18<00:57,  1.10it/s]Loading train:  77%|███████▋  | 204/266 [03:19<00:54,  1.14it/s]Loading train:  77%|███████▋  | 205/266 [03:20<00:57,  1.06it/s]Loading train:  77%|███████▋  | 206/266 [03:21<00:55,  1.08it/s]Loading train:  78%|███████▊  | 207/266 [03:22<00:56,  1.05it/s]Loading train:  78%|███████▊  | 208/266 [03:23<00:53,  1.09it/s]Loading train:  79%|███████▊  | 209/266 [03:24<00:53,  1.07it/s]Loading train:  79%|███████▉  | 210/266 [03:25<00:51,  1.09it/s]Loading train:  79%|███████▉  | 211/266 [03:25<00:49,  1.11it/s]Loading train:  80%|███████▉  | 212/266 [03:26<00:51,  1.05it/s]Loading train:  80%|████████  | 213/266 [03:27<00:51,  1.04it/s]Loading train:  80%|████████  | 214/266 [03:28<00:49,  1.06it/s]Loading train:  81%|████████  | 215/266 [03:29<00:47,  1.07it/s]Loading train:  81%|████████  | 216/266 [03:30<00:46,  1.07it/s]Loading train:  82%|████████▏ | 217/266 [03:31<00:45,  1.09it/s]Loading train:  82%|████████▏ | 218/266 [03:32<00:42,  1.14it/s]Loading train:  82%|████████▏ | 219/266 [03:33<00:42,  1.10it/s]Loading train:  83%|████████▎ | 220/266 [03:34<00:41,  1.11it/s]Loading train:  83%|████████▎ | 221/266 [03:34<00:38,  1.16it/s]Loading train:  83%|████████▎ | 222/266 [03:35<00:37,  1.18it/s]Loading train:  84%|████████▍ | 223/266 [03:36<00:38,  1.13it/s]Loading train:  84%|████████▍ | 224/266 [03:37<00:36,  1.16it/s]Loading train:  85%|████████▍ | 225/266 [03:38<00:33,  1.21it/s]Loading train:  85%|████████▍ | 226/266 [03:39<00:33,  1.20it/s]Loading train:  85%|████████▌ | 227/266 [03:40<00:33,  1.15it/s]Loading train:  86%|████████▌ | 228/266 [03:40<00:32,  1.17it/s]Loading train:  86%|████████▌ | 229/266 [03:41<00:30,  1.23it/s]Loading train:  86%|████████▋ | 230/266 [03:42<00:28,  1.27it/s]Loading train:  87%|████████▋ | 231/266 [03:43<00:30,  1.15it/s]Loading train:  87%|████████▋ | 232/266 [03:44<00:28,  1.18it/s]Loading train:  88%|████████▊ | 233/266 [03:45<00:30,  1.09it/s]Loading train:  88%|████████▊ | 234/266 [03:46<00:30,  1.04it/s]Loading train:  88%|████████▊ | 235/266 [03:47<00:29,  1.05it/s]Loading train:  89%|████████▊ | 236/266 [03:48<00:27,  1.11it/s]Loading train:  89%|████████▉ | 237/266 [03:48<00:24,  1.17it/s]Loading train:  89%|████████▉ | 238/266 [03:49<00:25,  1.10it/s]Loading train:  90%|████████▉ | 239/266 [03:50<00:24,  1.12it/s]Loading train:  90%|█████████ | 240/266 [03:51<00:22,  1.13it/s]Loading train:  91%|█████████ | 241/266 [03:52<00:22,  1.11it/s]Loading train:  91%|█████████ | 242/266 [03:53<00:21,  1.10it/s]Loading train:  91%|█████████▏| 243/266 [03:54<00:20,  1.12it/s]Loading train:  92%|█████████▏| 244/266 [03:55<00:19,  1.15it/s]Loading train:  92%|█████████▏| 245/266 [03:56<00:18,  1.12it/s]Loading train:  92%|█████████▏| 246/266 [03:56<00:17,  1.14it/s]Loading train:  93%|█████████▎| 247/266 [03:57<00:16,  1.16it/s]Loading train:  93%|█████████▎| 248/266 [03:58<00:16,  1.08it/s]Loading train:  94%|█████████▎| 249/266 [03:59<00:16,  1.04it/s]Loading train:  94%|█████████▍| 250/266 [04:01<00:16,  1.04s/it]Loading train:  94%|█████████▍| 251/266 [04:02<00:15,  1.06s/it]Loading train:  95%|█████████▍| 252/266 [04:03<00:15,  1.08s/it]Loading train:  95%|█████████▌| 253/266 [04:04<00:13,  1.08s/it]Loading train:  95%|█████████▌| 254/266 [04:05<00:13,  1.14s/it]Loading train:  96%|█████████▌| 255/266 [04:06<00:11,  1.08s/it]Loading train:  96%|█████████▌| 256/266 [04:07<00:10,  1.07s/it]Loading train:  97%|█████████▋| 257/266 [04:08<00:09,  1.07s/it]Loading train:  97%|█████████▋| 258/266 [04:09<00:08,  1.12s/it]Loading train:  97%|█████████▋| 259/266 [04:11<00:07,  1.10s/it]Loading train:  98%|█████████▊| 260/266 [04:12<00:06,  1.11s/it]Loading train:  98%|█████████▊| 261/266 [04:13<00:05,  1.07s/it]Loading train:  98%|█████████▊| 262/266 [04:14<00:04,  1.08s/it]Loading train:  99%|█████████▉| 263/266 [04:15<00:03,  1.05s/it]Loading train:  99%|█████████▉| 264/266 [04:16<00:02,  1.08s/it]Loading train: 100%|█████████▉| 265/266 [04:17<00:01,  1.09s/it]Loading train: 100%|██████████| 266/266 [04:18<00:00,  1.08s/it]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   5%|▍         | 12/266 [00:00<00:02, 110.51it/s]concatenating: train:  15%|█▍        | 39/266 [00:00<00:01, 132.98it/s]concatenating: train:  23%|██▎       | 62/266 [00:00<00:01, 151.62it/s]concatenating: train:  32%|███▏      | 86/266 [00:00<00:01, 170.29it/s]concatenating: train:  41%|████      | 109/266 [00:00<00:00, 183.36it/s]concatenating: train:  48%|████▊     | 129/266 [00:00<00:00, 186.67it/s]concatenating: train:  56%|█████▌    | 148/266 [00:03<00:06, 18.63it/s] concatenating: train:  66%|██████▌   | 176/266 [00:03<00:03, 25.88it/s]concatenating: train:  78%|███████▊  | 207/266 [00:03<00:01, 35.66it/s]concatenating: train:  88%|████████▊ | 234/266 [00:04<00:00, 48.11it/s]concatenating: train: 100%|█████████▉| 265/266 [00:04<00:00, 64.44it/s]concatenating: train: 100%|██████████| 266/266 [00:04<00:00, 63.41it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:01<00:05,  1.47s/it]Loading test:  40%|████      | 2/5 [00:02<00:04,  1.42s/it]Loading test:  60%|██████    | 3/5 [00:03<00:02,  1.35s/it]Loading test:  80%|████████  | 4/5 [00:05<00:01,  1.30s/it]Loading test: 100%|██████████| 5/5 [00:06<00:00,  1.34s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 633.83it/s]2019-08-17 20:22:35.024187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-08-17 20:22:35.024294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-17 20:22:35.024311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-08-17 20:22:35.024321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-08-17 20:22:35.024761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.03it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  5.88it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.43it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.94it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  6.28it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.18it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  6.49it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.43it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.84it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.28it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  9.01it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.26it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.32it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.49it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.25it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.59it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.98it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  8.02it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.75it/s]
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 26, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 13, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 26, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 26, 210)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 30)   25230       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 52, 60)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 30)   16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 90)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 90)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 13)   1183        dropout_5[0][0]                  
==================================================================================================
Total params: 501,343
Trainable params: 59,533
Non-trainable params: 441,810
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.34733092e-02 3.28973349e-02 7.69258930e-02 9.55842902e-03
 2.76642701e-02 7.23758191e-03 8.42747177e-02 1.14337675e-01
 8.97776433e-02 1.36403482e-02 2.91076778e-01 1.88895704e-01
 2.40316000e-04]
Train on 16808 samples, validate on 308 samples
Epoch 1/300
 - 18s - loss: 1.7350 - acc: 0.8388 - mDice: 0.2393 - val_loss: 1.7076 - val_acc: 0.9259 - val_mDice: 0.3871

Epoch 00001: val_mDice improved from -inf to 0.38714, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 13s - loss: 0.8495 - acc: 0.9095 - mDice: 0.4212 - val_loss: 1.4606 - val_acc: 0.9334 - val_mDice: 0.4522

Epoch 00002: val_mDice improved from 0.38714 to 0.45217, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 13s - loss: 0.6915 - acc: 0.9192 - mDice: 0.4902 - val_loss: 1.6034 - val_acc: 0.9389 - val_mDice: 0.4395

Epoch 00003: val_mDice did not improve from 0.45217
Epoch 4/300
 - 14s - loss: 0.5801 - acc: 0.9285 - mDice: 0.5488 - val_loss: 1.2421 - val_acc: 0.9476 - val_mDice: 0.5177

Epoch 00004: val_mDice improved from 0.45217 to 0.51767, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 13s - loss: 0.5290 - acc: 0.9340 - mDice: 0.5828 - val_loss: 1.0520 - val_acc: 0.9524 - val_mDice: 0.5771

Epoch 00005: val_mDice improved from 0.51767 to 0.57712, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 13s - loss: 0.4898 - acc: 0.9374 - mDice: 0.6058 - val_loss: 1.0052 - val_acc: 0.9502 - val_mDice: 0.5889

Epoch 00006: val_mDice improved from 0.57712 to 0.58888, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 13s - loss: 0.4293 - acc: 0.9413 - mDice: 0.6410 - val_loss: 0.9781 - val_acc: 0.9478 - val_mDice: 0.5900

Epoch 00007: val_mDice improved from 0.58888 to 0.59003, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 13s - loss: 0.4201 - acc: 0.9420 - mDice: 0.6475 - val_loss: 1.3079 - val_acc: 0.9364 - val_mDice: 0.5260

Epoch 00008: val_mDice did not improve from 0.59003
Epoch 9/300
 - 14s - loss: 0.4176 - acc: 0.9420 - mDice: 0.6489 - val_loss: 1.0004 - val_acc: 0.9469 - val_mDice: 0.5947

Epoch 00009: val_mDice improved from 0.59003 to 0.59467, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 13s - loss: 0.4198 - acc: 0.9422 - mDice: 0.6493 - val_loss: 0.8899 - val_acc: 0.9470 - val_mDice: 0.5737

Epoch 00010: val_mDice did not improve from 0.59467
Epoch 11/300
 - 14s - loss: 0.4120 - acc: 0.9431 - mDice: 0.6578 - val_loss: 0.9746 - val_acc: 0.9481 - val_mDice: 0.5793

Epoch 00011: val_mDice did not improve from 0.59467
Epoch 12/300
 - 13s - loss: 0.4082 - acc: 0.9432 - mDice: 0.6580 - val_loss: 0.9140 - val_acc: 0.9486 - val_mDice: 0.5837

Epoch 00012: val_mDice did not improve from 0.59467
Epoch 13/300
 - 14s - loss: 0.3920 - acc: 0.9434 - mDice: 0.6641 - val_loss: 1.0096 - val_acc: 0.9451 - val_mDice: 0.5845

Epoch 00013: val_mDice did not improve from 0.59467
Epoch 14/300
 - 13s - loss: 0.3861 - acc: 0.9440 - mDice: 0.6711 - val_loss: 1.0672 - val_acc: 0.9525 - val_mDice: 0.5698

Epoch 00014: val_mDice did not improve from 0.59467
Epoch 15/300
 - 13s - loss: 0.3631 - acc: 0.9461 - mDice: 0.6851 - val_loss: 1.0780 - val_acc: 0.9496 - val_mDice: 0.5370

Epoch 00015: val_mDice did not improve from 0.59467
Epoch 16/300
 - 13s - loss: 0.3799 - acc: 0.9450 - mDice: 0.6763 - val_loss: 0.9491 - val_acc: 0.9489 - val_mDice: 0.5884

Epoch 00016: val_mDice did not improve from 0.59467
Epoch 17/300
 - 14s - loss: 0.3655 - acc: 0.9454 - mDice: 0.6828 - val_loss: 0.7635 - val_acc: 0.9523 - val_mDice: 0.6131

Epoch 00017: val_mDice improved from 0.59467 to 0.61313, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 13s - loss: 0.3336 - acc: 0.9481 - mDice: 0.7037 - val_loss: 0.8699 - val_acc: 0.9527 - val_mDice: 0.6115

Epoch 00018: val_mDice did not improve from 0.61313
Epoch 19/300
 - 14s - loss: 0.3624 - acc: 0.9466 - mDice: 0.6902 - val_loss: 0.8650 - val_acc: 0.9529 - val_mDice: 0.6045

Epoch 00019: val_mDice did not improve from 0.61313
Epoch 20/300
 - 13s - loss: 0.3337 - acc: 0.9483 - mDice: 0.7067 - val_loss: 0.8748 - val_acc: 0.9512 - val_mDice: 0.6012

Epoch 00020: val_mDice did not improve from 0.61313
Epoch 21/300
 - 13s - loss: 0.3867 - acc: 0.9448 - mDice: 0.6746 - val_loss: 1.3644 - val_acc: 0.9390 - val_mDice: 0.4872

Epoch 00021: val_mDice did not improve from 0.61313
Epoch 22/300
 - 14s - loss: 0.3586 - acc: 0.9466 - mDice: 0.6889 - val_loss: 1.1325 - val_acc: 0.9515 - val_mDice: 0.5591

Epoch 00022: val_mDice did not improve from 0.61313
Epoch 23/300
 - 13s - loss: 0.3428 - acc: 0.9475 - mDice: 0.6979 - val_loss: 0.8194 - val_acc: 0.9524 - val_mDice: 0.6043

Epoch 00023: val_mDice did not improve from 0.61313
Epoch 24/300
 - 13s - loss: 0.3226 - acc: 0.9491 - mDice: 0.7120 - val_loss: 0.8060 - val_acc: 0.9520 - val_mDice: 0.6081

Epoch 00024: val_mDice did not improve from 0.61313
Epoch 25/300
 - 14s - loss: 0.3131 - acc: 0.9497 - mDice: 0.7195 - val_loss: 0.8348 - val_acc: 0.9515 - val_mDice: 0.5870

Epoch 00025: val_mDice did not improve from 0.61313
Epoch 26/300
 - 13s - loss: 0.3430 - acc: 0.9475 - mDice: 0.6991 - val_loss: 0.7394 - val_acc: 0.9521 - val_mDice: 0.6064

Epoch 00026: val_mDice did not improve from 0.61313
Epoch 27/300
 - 14s - loss: 0.3211 - acc: 0.9491 - mDice: 0.7143 - val_loss: 0.7667 - val_acc: 0.9534 - val_mDice: 0.6134

Epoch 00027: val_mDice improved from 0.61313 to 0.61336, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 28/300
 - 13s - loss: 0.3187 - acc: 0.9498 - mDice: 0.7204 - val_loss: 0.8658 - val_acc: 0.9505 - val_mDice: 0.5783

Epoch 00028: val_mDice did not improve from 0.61336
Epoch 29/300
 - 13s - loss: 0.3909 - acc: 0.9450 - mDice: 0.6791 - val_loss: 0.7873 - val_acc: 0.9540 - val_mDice: 0.6027

Epoch 00029: val_mDice did not improve from 0.61336
Epoch 30/300
 - 13s - loss: 0.3349 - acc: 0.9483 - mDice: 0.7064 - val_loss: 0.7956 - val_acc: 0.9511 - val_mDice: 0.6042

Epoch 00030: val_mDice did not improve from 0.61336
Epoch 31/300
 - 14s - loss: 0.3282 - acc: 0.9487 - mDice: 0.7098 - val_loss: 0.7836 - val_acc: 0.9490 - val_mDice: 0.6058

Epoch 00031: val_mDice did not improve from 0.61336
Epoch 32/300
 - 14s - loss: 0.3785 - acc: 0.9457 - mDice: 0.6831 - val_loss: 0.7013 - val_acc: 0.9522 - val_mDice: 0.6146

Epoch 00032: val_mDice improved from 0.61336 to 0.61457, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 33/300
 - 14s - loss: 0.3413 - acc: 0.9474 - mDice: 0.6998 - val_loss: 0.7735 - val_acc: 0.9509 - val_mDice: 0.6083

Epoch 00033: val_mDice did not improve from 0.61457
Epoch 34/300
 - 13s - loss: 0.3159 - acc: 0.9498 - mDice: 0.7195 - val_loss: 0.6784 - val_acc: 0.9546 - val_mDice: 0.6015

Epoch 00034: val_mDice did not improve from 0.61457
Epoch 35/300
 - 14s - loss: 0.3243 - acc: 0.9497 - mDice: 0.7180 - val_loss: 0.7532 - val_acc: 0.9481 - val_mDice: 0.5845

Epoch 00035: val_mDice did not improve from 0.61457
Epoch 36/300
 - 13s - loss: 0.3096 - acc: 0.9502 - mDice: 0.7247 - val_loss: 0.7263 - val_acc: 0.9525 - val_mDice: 0.6045

Epoch 00036: val_mDice did not improve from 0.61457
Epoch 37/300
 - 14s - loss: 0.3126 - acc: 0.9502 - mDice: 0.7240 - val_loss: 0.7190 - val_acc: 0.9537 - val_mDice: 0.6081

Epoch 00037: val_mDice did not improve from 0.61457
Epoch 38/300
 - 14s - loss: 0.2993 - acc: 0.9509 - mDice: 0.7295 - val_loss: 0.7493 - val_acc: 0.9522 - val_mDice: 0.6060

Epoch 00038: val_mDice did not improve from 0.61457
Epoch 39/300
 - 17s - loss: 0.2967 - acc: 0.9511 - mDice: 0.7327 - val_loss: 0.7887 - val_acc: 0.9499 - val_mDice: 0.5902

Epoch 00039: val_mDice did not improve from 0.61457
Epoch 40/300
 - 17s - loss: 0.3169 - acc: 0.9502 - mDice: 0.7237 - val_loss: 0.7811 - val_acc: 0.9487 - val_mDice: 0.5795

Epoch 00040: val_mDice did not improve from 0.61457
Epoch 41/300
 - 17s - loss: 0.3484 - acc: 0.9480 - mDice: 0.7024 - val_loss: 0.7023 - val_acc: 0.9519 - val_mDice: 0.6065

Epoch 00041: val_mDice did not improve from 0.61457
Epoch 42/300
 - 17s - loss: 0.3432 - acc: 0.9482 - mDice: 0.7049 - val_loss: 0.7795 - val_acc: 0.9505 - val_mDice: 0.5920

Epoch 00042: val_mDice did not improve from 0.61457
Epoch 43/300
 - 17s - loss: 0.3850 - acc: 0.9438 - mDice: 0.6744 - val_loss: 1.0054 - val_acc: 0.9449 - val_mDice: 0.5936

Epoch 00043: val_mDice did not improve from 0.61457
Epoch 44/300
 - 17s - loss: 0.3321 - acc: 0.9481 - mDice: 0.7075 - val_loss: 0.8575 - val_acc: 0.9536 - val_mDice: 0.5971

Epoch 00044: val_mDice did not improve from 0.61457
Epoch 45/300
 - 17s - loss: 0.3055 - acc: 0.9501 - mDice: 0.7244 - val_loss: 0.8422 - val_acc: 0.9486 - val_mDice: 0.5985

Epoch 00045: val_mDice did not improve from 0.61457
Epoch 46/300
 - 17s - loss: 0.3838 - acc: 0.9460 - mDice: 0.6807 - val_loss: 0.8901 - val_acc: 0.9495 - val_mDice: 0.5693

Epoch 00046: val_mDice did not improve from 0.61457
Epoch 47/300
 - 17s - loss: 0.3276 - acc: 0.9490 - mDice: 0.7132 - val_loss: 0.6845 - val_acc: 0.9535 - val_mDice: 0.6129

Epoch 00047: val_mDice did not improve from 0.61457
Epoch 48/300
 - 16s - loss: 0.3075 - acc: 0.9507 - mDice: 0.7283 - val_loss: 1.0320 - val_acc: 0.9538 - val_mDice: 0.5731

Epoch 00048: val_mDice did not improve from 0.61457
Epoch 49/300
 - 17s - loss: 0.3322 - acc: 0.9482 - mDice: 0.7078 - val_loss: 0.6874 - val_acc: 0.9539 - val_mDice: 0.6096

Epoch 00049: val_mDice did not improve from 0.61457
Epoch 50/300
 - 14s - loss: 0.3068 - acc: 0.9507 - mDice: 0.7290 - val_loss: 0.6944 - val_acc: 0.9518 - val_mDice: 0.6046

Epoch 00050: val_mDice did not improve from 0.61457
Epoch 51/300
 - 14s - loss: 0.3028 - acc: 0.9506 - mDice: 0.7275 - val_loss: 0.6905 - val_acc: 0.9519 - val_mDice: 0.6044

Epoch 00051: val_mDice did not improve from 0.61457
Epoch 52/300
 - 14s - loss: 0.3268 - acc: 0.9489 - mDice: 0.7118 - val_loss: 0.7295 - val_acc: 0.9497 - val_mDice: 0.5944

Epoch 00052: val_mDice did not improve from 0.61457
Epoch 53/300
 - 14s - loss: 0.3186 - acc: 0.9496 - mDice: 0.7211 - val_loss: 0.7017 - val_acc: 0.9530 - val_mDice: 0.6088

Epoch 00053: val_mDice did not improve from 0.61457
Epoch 54/300
 - 14s - loss: 0.3051 - acc: 0.9513 - mDice: 0.7330 - val_loss: 0.5458 - val_acc: 0.9541 - val_mDice: 0.6030

Epoch 00054: val_mDice did not improve from 0.61457
Epoch 55/300
 - 14s - loss: 0.2914 - acc: 0.9518 - mDice: 0.7381 - val_loss: 0.7075 - val_acc: 0.9532 - val_mDice: 0.6013

Epoch 00055: val_mDice did not improve from 0.61457
Epoch 56/300
 - 13s - loss: 0.3089 - acc: 0.9507 - mDice: 0.7279 - val_loss: 0.7270 - val_acc: 0.9504 - val_mDice: 0.5980

Epoch 00056: val_mDice did not improve from 0.61457
Epoch 57/300
 - 13s - loss: 0.3195 - acc: 0.9497 - mDice: 0.7188 - val_loss: 0.6499 - val_acc: 0.9518 - val_mDice: 0.6055

Epoch 00057: val_mDice did not improve from 0.61457
Epoch 58/300
 - 13s - loss: 0.3020 - acc: 0.9511 - mDice: 0.7322 - val_loss: 0.9153 - val_acc: 0.9461 - val_mDice: 0.5697

Epoch 00058: val_mDice did not improve from 0.61457
Epoch 59/300
 - 13s - loss: 0.3114 - acc: 0.9509 - mDice: 0.7286 - val_loss: 0.7268 - val_acc: 0.9519 - val_mDice: 0.5997

Epoch 00059: val_mDice did not improve from 0.61457
Epoch 60/300
 - 13s - loss: 0.3389 - acc: 0.9489 - mDice: 0.7076 - val_loss: 0.8783 - val_acc: 0.9515 - val_mDice: 0.5978

Epoch 00060: val_mDice did not improve from 0.61457
Epoch 61/300
 - 13s - loss: 0.3048 - acc: 0.9508 - mDice: 0.7276 - val_loss: 0.6699 - val_acc: 0.9527 - val_mDice: 0.6038

Epoch 00061: val_mDice did not improve from 0.61457
Epoch 62/300
 - 13s - loss: 0.2996 - acc: 0.9516 - mDice: 0.7341 - val_loss: 0.6345 - val_acc: 0.9542 - val_mDice: 0.6031

Epoch 00062: val_mDice did not improve from 0.61457
Epoch 63/300
 - 13s - loss: 0.2956 - acc: 0.9514 - mDice: 0.7334 - val_loss: 0.6344 - val_acc: 0.9543 - val_mDice: 0.6075

Epoch 00063: val_mDice did not improve from 0.61457
Epoch 64/300
 - 13s - loss: 0.2884 - acc: 0.9520 - mDice: 0.7395 - val_loss: 0.4665 - val_acc: 0.9542 - val_mDice: 0.5918

Epoch 00064: val_mDice did not improve from 0.61457
Epoch 65/300
 - 13s - loss: 0.2965 - acc: 0.9516 - mDice: 0.7357 - val_loss: 0.9483 - val_acc: 0.9478 - val_mDice: 0.5457

Epoch 00065: val_mDice did not improve from 0.61457
Epoch 66/300
 - 13s - loss: 0.3392 - acc: 0.9489 - mDice: 0.7088 - val_loss: 0.6988 - val_acc: 0.9516 - val_mDice: 0.5943

Epoch 00066: val_mDice did not improve from 0.61457
Epoch 67/300
 - 13s - loss: 0.3001 - acc: 0.9516 - mDice: 0.7337 - val_loss: 0.8738 - val_acc: 0.9519 - val_mDice: 0.5913

Epoch 00067: val_mDice did not improve from 0.61457
Epoch 68/300
 - 13s - loss: 0.2868 - acc: 0.9522 - mDice: 0.7412 - val_loss: 0.6893 - val_acc: 0.9527 - val_mDice: 0.6031

Epoch 00068: val_mDice did not improve from 0.61457
Epoch 69/300
 - 13s - loss: 0.2764 - acc: 0.9528 - mDice: 0.7474 - val_loss: 0.7067 - val_acc: 0.9510 - val_mDice: 0.5966

Epoch 00069: val_mDice did not improve from 0.61457
Epoch 70/300
 - 13s - loss: 0.2928 - acc: 0.9520 - mDice: 0.7399 - val_loss: 0.7964 - val_acc: 0.9477 - val_mDice: 0.5625

Epoch 00070: val_mDice did not improve from 0.61457
Epoch 71/300
 - 13s - loss: 0.2820 - acc: 0.9524 - mDice: 0.7425 - val_loss: 0.6866 - val_acc: 0.9518 - val_mDice: 0.5997

Epoch 00071: val_mDice did not improve from 0.61457
Epoch 72/300
 - 13s - loss: 0.2686 - acc: 0.9532 - mDice: 0.7521 - val_loss: 0.6825 - val_acc: 0.9537 - val_mDice: 0.6035

Epoch 00072: val_mDice did not improve from 0.61457
Restoring model weights from the end of the best epoch
Epoch 00072: early stopping
{'val_loss': [1.707557345752592, 1.4605772131449217, 1.6033745276463496, 1.2420563353346539, 1.0519600789268295, 1.005247608988316, 0.9781297269192609, 1.3078804964368993, 1.0003731868096761, 0.8899475479280794, 0.974595495439195, 0.9139822556987985, 1.0096372596242211, 1.0672020888947822, 1.0779797655421417, 0.949068233370781, 0.7635104474309203, 0.86986078476751, 0.8649666144863352, 0.87480292459587, 1.3643502465316228, 1.132452892986211, 0.8194099082188173, 0.8059938286806082, 0.8347726713914376, 0.7394333477918204, 0.7666732047672395, 0.8657501326365904, 0.7872920262736159, 0.7955522179216533, 0.7836219302632592, 0.70127213465703, 0.7734869826923717, 0.6783573056583281, 0.7531847535789787, 0.7263013139947668, 0.7189770756990879, 0.7493035828138327, 0.7886599503554307, 0.7810784429311752, 0.7022683717213668, 0.7794638396083534, 1.005445418419776, 0.8575351414355364, 0.8422264973451565, 0.8901496624404733, 0.6845488039317069, 1.03203622861342, 0.6874208910898729, 0.6943706806216922, 0.6904895264994014, 0.7294700463096817, 0.7016852196160849, 0.5457939308185082, 0.7074730481420245, 0.7269807570166402, 0.6498821993152817, 0.9153226468857233, 0.7267787497151982, 0.8783442608334802, 0.6699392809109255, 0.634537545117465, 0.6344195190188172, 0.4664613217502445, 0.9483347904759568, 0.6988435962370464, 0.8737601155971552, 0.689253389254793, 0.7067045695208883, 0.7963689768856222, 0.6866482291128728, 0.682547695257447], 'val_acc': [0.9259274280690527, 0.9334067381047583, 0.938948081685351, 0.9476280847153107, 0.9523745612664656, 0.9502048457597757, 0.9477769813754342, 0.9363953405386441, 0.9468968487405157, 0.94695568355647, 0.9480795620323775, 0.9485670715183406, 0.9451077692694478, 0.9525498682028287, 0.9496176904672152, 0.9489164673662805, 0.9523085096439758, 0.9527107655227959, 0.9529340812912235, 0.9511546202294239, 0.9389636737185639, 0.951478790927243, 0.9524249786680395, 0.952010732966584, 0.9514716062452886, 0.9521344064118026, 0.9534119816569538, 0.9505230412854777, 0.9539835127917203, 0.9510669572786852, 0.9490257393230092, 0.9522196553744279, 0.950858034096755, 0.954643920257494, 0.9480963717033337, 0.952473013431995, 0.9537193558432839, 0.9522016365806778, 0.949909453268175, 0.9486871218526518, 0.9519110740005196, 0.9504954176289695, 0.9448832509579597, 0.9536064805148484, 0.9486270860418097, 0.9494784040884539, 0.9534720135973646, 0.953802204364306, 0.9538706591377011, 0.9517693747947742, 0.9519374846638023, 0.9497449610914502, 0.9529532983705595, 0.9540783584891975, 0.9532450631067351, 0.9503801643074333, 0.9517958040361281, 0.9460827503111455, 0.9518738470294259, 0.9514836243220738, 0.952692731634363, 0.95423206493452, 0.9542861000283972, 0.9541624254220492, 0.9478394153056207, 0.9515880733341365, 0.951931475044845, 0.9527323648527071, 0.9510237365574031, 0.9476653232976988, 0.951775382865559, 0.9537049547418371], 'val_mDice': [0.38714120217732023, 0.45216784558512946, 0.4394800899090705, 0.517669048208695, 0.577119045056306, 0.5888810540948596, 0.5900311688711117, 0.525996032860372, 0.5946701134180093, 0.5737301724684702, 0.57928894305384, 0.5836876309537268, 0.5844762557512754, 0.5698216044670575, 0.5369990928606554, 0.5884128344523443, 0.6131301353891174, 0.6115397737397776, 0.6044873471383925, 0.6012442082940758, 0.48722281587588323, 0.5591106230949426, 0.6043469371733727, 0.6081145442538447, 0.586976792324673, 0.6064469078918556, 0.6133649523382063, 0.5783170593249334, 0.6026958741924979, 0.6041896908314197, 0.6058494320937565, 0.6145726461689194, 0.608296044848182, 0.6015099221235746, 0.5845407452676203, 0.6045292120475274, 0.6080725936146526, 0.6060088213000979, 0.5901557052290285, 0.5794963650889211, 0.6064679912932507, 0.5920283502185499, 0.5935533735659215, 0.597129526850465, 0.5984542398870766, 0.5693240839165526, 0.6128730061766389, 0.5731346135015611, 0.6095694827956039, 0.6045758778398688, 0.6043599441454008, 0.5944126662495849, 0.6088459640741348, 0.6029691363309885, 0.6012902370133957, 0.597975717349486, 0.6055391678562412, 0.5696989847468091, 0.5996783563455979, 0.5978050605430232, 0.6038430534399949, 0.6030569448099508, 0.6074865715844291, 0.5917547805742784, 0.5456928963010962, 0.5942669824346319, 0.591333873279683, 0.6031457377331597, 0.5966335807914858, 0.5624658629878775, 0.5996683683101233, 0.6035184751857411], 'loss': [1.7349721997947933, 0.8495126511867928, 0.691475527980735, 0.5801028409837145, 0.5290074279192287, 0.48982579357875977, 0.42927598503588044, 0.42006165449503546, 0.41759270309749413, 0.4198444499352726, 0.41203615379327824, 0.40824791063146326, 0.3920356483508552, 0.3860959775713953, 0.36311091872367446, 0.379896834896951, 0.36546201267054057, 0.33356785249392346, 0.3623546076311718, 0.33374587317014637, 0.3866531207363189, 0.35858665941117324, 0.34283797741503674, 0.3225965418244248, 0.3130663596466006, 0.34299166636742734, 0.321062492032042, 0.3187132911461413, 0.39086178183796744, 0.33494390960408643, 0.3282422579714992, 0.3784598096148392, 0.34125272995627876, 0.3158559953312486, 0.324347129709547, 0.3096335705250913, 0.31264900290245445, 0.2992603250826642, 0.2966715087019251, 0.3169060227368515, 0.3484317064710823, 0.34316726528579766, 0.3850094625129693, 0.33206996038336234, 0.3054947580065913, 0.38384188335390673, 0.3276087237838505, 0.3075325918915384, 0.3321596886049504, 0.3067854543024588, 0.30277481816641666, 0.32684693095415673, 0.31862278945960354, 0.30509077634720905, 0.2913935351771068, 0.3088598915121772, 0.319538596870359, 0.30203690890866425, 0.31137610854902814, 0.33885396021581843, 0.3048133172382065, 0.2995540878599397, 0.2956200046735199, 0.28839366324157273, 0.29646829492113297, 0.3391669907778686, 0.3001461206451732, 0.28683651133002924, 0.2764267693213881, 0.2928111519006705, 0.2820480206625794, 0.26864175440327775], 'acc': [0.8388365857703864, 0.9095385765983967, 0.9191671646617243, 0.9284880411363907, 0.9340070172371268, 0.9374152013073643, 0.9413238818208017, 0.9420148566585107, 0.9419920397394899, 0.9421501089240301, 0.9431433566960762, 0.9432194190740812, 0.9434237383139354, 0.9440314112987364, 0.9460522112592182, 0.9449644588263815, 0.9453800697587094, 0.9480782033275389, 0.9466162971205396, 0.9483420169109507, 0.9448324654753125, 0.9465796608887418, 0.9475116760872024, 0.9490512098615252, 0.9497414155766148, 0.94754140218742, 0.9491102218854887, 0.9497537568871149, 0.9450167832787068, 0.9482626958241751, 0.9486875265113289, 0.9456857979822476, 0.9474199912637146, 0.9497996987344991, 0.9496967931167675, 0.950245168466105, 0.9502174213124366, 0.9508681748237909, 0.9511345639037609, 0.9501959016951761, 0.9479736474115243, 0.9482158544743305, 0.9438393708426631, 0.948108875577022, 0.9501041299399735, 0.946004948541983, 0.9489978960529502, 0.9506747078847341, 0.9482401888720028, 0.9507184034228495, 0.9506006669935756, 0.9489234380427569, 0.9496044239746508, 0.951289133088524, 0.9518006527171369, 0.9506769945782063, 0.9497070694355554, 0.951091636289647, 0.9508831140712464, 0.9489286325974784, 0.9508080635040729, 0.9515635514616796, 0.9513569022859067, 0.9520216067381441, 0.9515701971526148, 0.9489359813948463, 0.9515720225625921, 0.9522197404996036, 0.9528257841512965, 0.9519680292052578, 0.9523542431821034, 0.9532330344045009], 'mDice': [0.2392727275114588, 0.4212172584823629, 0.49022196350652, 0.5487597007472875, 0.5828111507441814, 0.6057707723558148, 0.6410120461155607, 0.6475380495694182, 0.6488566016304045, 0.6493102761747042, 0.6577930064328451, 0.6580066551329805, 0.6640520889040744, 0.6711112092089959, 0.6850874162057875, 0.6763052522625486, 0.6827661306559614, 0.7037476647799495, 0.6902163434048484, 0.706650990246308, 0.6745616624478441, 0.6889422268299532, 0.6979126691789868, 0.7120028745200394, 0.7194603248430627, 0.6990731760880766, 0.7142622525892843, 0.7203864167767556, 0.6790837050548115, 0.706405088709741, 0.7097526515086228, 0.68311849470538, 0.6998157752433997, 0.7195192308283488, 0.7179618215969437, 0.7246856048228002, 0.723991504159784, 0.7295498083895697, 0.7327053134694433, 0.723693415926843, 0.7023665666764602, 0.7048976858036113, 0.674424134060095, 0.7075207180306776, 0.7243855253308799, 0.680661197796088, 0.7132298107773619, 0.7282515052370887, 0.7077863800318567, 0.728951435190391, 0.7274857534291573, 0.7118032943175442, 0.7211263175807301, 0.732979520687258, 0.738149938073855, 0.7279396296214172, 0.7188047117942404, 0.7321934380073425, 0.7285769989750375, 0.7075907764606167, 0.72759984183998, 0.7340510844943184, 0.7333598286197164, 0.739496822011919, 0.7356593964682597, 0.7088120826464617, 0.7337079721794192, 0.741174691471527, 0.7473613733141153, 0.7398594076408765, 0.7424699252684986, 0.7521472567322707]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:02<00:11,  2.97s/it]predicting test subjects:  40%|████      | 2/5 [00:05<00:08,  2.80s/it]predicting test subjects:  60%|██████    | 3/5 [00:07<00:05,  2.56s/it]predicting test subjects:  80%|████████  | 4/5 [00:09<00:02,  2.39s/it]predicting test subjects: 100%|██████████| 5/5 [00:11<00:00,  2.42s/it]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:03<13:20,  3.02s/it]predicting train subjects:   1%|          | 2/266 [00:05<12:50,  2.92s/it]predicting train subjects:   1%|          | 3/266 [00:07<11:55,  2.72s/it]predicting train subjects:   2%|▏         | 4/266 [00:09<10:55,  2.50s/it]predicting train subjects:   2%|▏         | 5/266 [00:12<10:57,  2.52s/it]predicting train subjects:   2%|▏         | 6/266 [00:15<11:25,  2.63s/it]predicting train subjects:   3%|▎         | 7/266 [00:18<11:36,  2.69s/it]predicting train subjects:   3%|▎         | 8/266 [00:21<11:49,  2.75s/it]predicting train subjects:   3%|▎         | 9/266 [00:23<11:48,  2.76s/it]predicting train subjects:   4%|▍         | 10/266 [00:26<11:53,  2.79s/it]predicting train subjects:   4%|▍         | 11/266 [00:29<11:50,  2.79s/it]predicting train subjects:   5%|▍         | 12/266 [00:32<11:46,  2.78s/it]predicting train subjects:   5%|▍         | 13/266 [00:35<11:41,  2.77s/it]predicting train subjects:   5%|▌         | 14/266 [00:37<11:49,  2.81s/it]predicting train subjects:   6%|▌         | 15/266 [00:40<11:53,  2.84s/it]predicting train subjects:   6%|▌         | 16/266 [00:43<11:48,  2.84s/it]predicting train subjects:   6%|▋         | 17/266 [00:46<11:48,  2.85s/it]predicting train subjects:   7%|▋         | 18/266 [00:49<11:48,  2.86s/it]predicting train subjects:   7%|▋         | 19/266 [00:52<11:45,  2.86s/it]predicting train subjects:   8%|▊         | 20/266 [00:55<11:52,  2.90s/it]predicting train subjects:   8%|▊         | 21/266 [00:58<11:47,  2.89s/it]predicting train subjects:   8%|▊         | 22/266 [01:01<11:40,  2.87s/it]predicting train subjects:   9%|▊         | 23/266 [01:03<11:36,  2.87s/it]predicting train subjects:   9%|▉         | 24/266 [01:06<11:24,  2.83s/it]predicting train subjects:   9%|▉         | 25/266 [01:09<11:04,  2.76s/it]predicting train subjects:  10%|▉         | 26/266 [01:11<10:44,  2.69s/it]predicting train subjects:  10%|█         | 27/266 [01:14<10:35,  2.66s/it]predicting train subjects:  11%|█         | 28/266 [01:16<10:28,  2.64s/it]predicting train subjects:  11%|█         | 29/266 [01:19<10:25,  2.64s/it]predicting train subjects:  11%|█▏        | 30/266 [01:22<10:21,  2.63s/it]predicting train subjects:  12%|█▏        | 31/266 [01:25<10:35,  2.70s/it]predicting train subjects:  12%|█▏        | 32/266 [01:27<10:23,  2.66s/it]predicting train subjects:  12%|█▏        | 33/266 [01:30<10:11,  2.62s/it]predicting train subjects:  13%|█▎        | 34/266 [01:32<10:02,  2.60s/it]predicting train subjects:  13%|█▎        | 35/266 [01:35<09:58,  2.59s/it]predicting train subjects:  14%|█▎        | 36/266 [01:37<10:03,  2.62s/it]predicting train subjects:  14%|█▍        | 37/266 [01:40<09:59,  2.62s/it]predicting train subjects:  14%|█▍        | 38/266 [01:43<09:55,  2.61s/it]predicting train subjects:  15%|█▍        | 39/266 [01:45<09:52,  2.61s/it]predicting train subjects:  15%|█▌        | 40/266 [01:48<09:42,  2.58s/it]predicting train subjects:  15%|█▌        | 41/266 [01:50<09:40,  2.58s/it]predicting train subjects:  16%|█▌        | 42/266 [01:53<09:12,  2.47s/it]predicting train subjects:  16%|█▌        | 43/266 [01:55<08:57,  2.41s/it]predicting train subjects:  17%|█▋        | 44/266 [01:57<08:37,  2.33s/it]predicting train subjects:  17%|█▋        | 45/266 [01:59<08:25,  2.29s/it]predicting train subjects:  17%|█▋        | 46/266 [02:01<08:23,  2.29s/it]predicting train subjects:  18%|█▊        | 47/266 [02:04<08:15,  2.26s/it]predicting train subjects:  18%|█▊        | 48/266 [02:06<08:12,  2.26s/it]predicting train subjects:  18%|█▊        | 49/266 [02:08<08:04,  2.23s/it]predicting train subjects:  19%|█▉        | 50/266 [02:10<08:03,  2.24s/it]predicting train subjects:  19%|█▉        | 51/266 [02:13<08:00,  2.23s/it]predicting train subjects:  20%|█▉        | 52/266 [02:15<07:52,  2.21s/it]predicting train subjects:  20%|█▉        | 53/266 [02:17<07:47,  2.20s/it]predicting train subjects:  20%|██        | 54/266 [02:19<07:43,  2.19s/it]predicting train subjects:  21%|██        | 55/266 [02:21<07:40,  2.18s/it]predicting train subjects:  21%|██        | 56/266 [02:23<07:40,  2.19s/it]predicting train subjects:  21%|██▏       | 57/266 [02:26<07:38,  2.19s/it]predicting train subjects:  22%|██▏       | 58/266 [02:28<07:41,  2.22s/it]predicting train subjects:  22%|██▏       | 59/266 [02:30<07:39,  2.22s/it]predicting train subjects:  23%|██▎       | 60/266 [02:32<07:22,  2.15s/it]predicting train subjects:  23%|██▎       | 61/266 [02:34<07:10,  2.10s/it]predicting train subjects:  23%|██▎       | 62/266 [02:36<06:58,  2.05s/it]predicting train subjects:  24%|██▎       | 63/266 [02:38<06:59,  2.07s/it]predicting train subjects:  24%|██▍       | 64/266 [02:40<06:48,  2.02s/it]predicting train subjects:  24%|██▍       | 65/266 [02:42<06:41,  2.00s/it]predicting train subjects:  25%|██▍       | 66/266 [02:44<06:40,  2.00s/it]predicting train subjects:  25%|██▌       | 67/266 [02:46<06:35,  1.99s/it]predicting train subjects:  26%|██▌       | 68/266 [02:48<06:33,  1.99s/it]predicting train subjects:  26%|██▌       | 69/266 [02:50<06:33,  2.00s/it]predicting train subjects:  26%|██▋       | 70/266 [02:52<06:37,  2.03s/it]predicting train subjects:  27%|██▋       | 71/266 [02:54<06:34,  2.02s/it]predicting train subjects:  27%|██▋       | 72/266 [02:56<06:33,  2.03s/it]predicting train subjects:  27%|██▋       | 73/266 [02:58<06:27,  2.01s/it]predicting train subjects:  28%|██▊       | 74/266 [03:00<06:24,  2.00s/it]predicting train subjects:  28%|██▊       | 75/266 [03:02<06:21,  2.00s/it]predicting train subjects:  29%|██▊       | 76/266 [03:04<06:22,  2.01s/it]predicting train subjects:  29%|██▉       | 77/266 [03:06<06:17,  2.00s/it]predicting train subjects:  29%|██▉       | 78/266 [03:09<06:49,  2.18s/it]predicting train subjects:  30%|██▉       | 79/266 [03:11<07:09,  2.30s/it]predicting train subjects:  30%|███       | 80/266 [03:14<07:23,  2.39s/it]predicting train subjects:  30%|███       | 81/266 [03:16<07:32,  2.45s/it]predicting train subjects:  31%|███       | 82/266 [03:19<07:37,  2.49s/it]predicting train subjects:  31%|███       | 83/266 [03:22<07:44,  2.54s/it]predicting train subjects:  32%|███▏      | 84/266 [03:24<07:47,  2.57s/it]predicting train subjects:  32%|███▏      | 85/266 [03:27<07:44,  2.56s/it]predicting train subjects:  32%|███▏      | 86/266 [03:30<07:48,  2.60s/it]predicting train subjects:  33%|███▎      | 87/266 [03:32<07:51,  2.63s/it]predicting train subjects:  33%|███▎      | 88/266 [03:35<07:48,  2.63s/it]predicting train subjects:  33%|███▎      | 89/266 [03:38<07:47,  2.64s/it]predicting train subjects:  34%|███▍      | 90/266 [03:40<07:36,  2.59s/it]predicting train subjects:  34%|███▍      | 91/266 [03:43<07:30,  2.58s/it]predicting train subjects:  35%|███▍      | 92/266 [03:45<07:32,  2.60s/it]predicting train subjects:  35%|███▍      | 93/266 [03:48<07:37,  2.65s/it]predicting train subjects:  35%|███▌      | 94/266 [03:50<07:28,  2.61s/it]predicting train subjects:  36%|███▌      | 95/266 [03:53<07:27,  2.61s/it]predicting train subjects:  36%|███▌      | 96/266 [03:55<07:10,  2.53s/it]predicting train subjects:  36%|███▋      | 97/266 [03:58<07:14,  2.57s/it]predicting train subjects:  37%|███▋      | 98/266 [04:01<07:11,  2.57s/it]predicting train subjects:  37%|███▋      | 99/266 [04:03<06:34,  2.36s/it]predicting train subjects:  38%|███▊      | 100/266 [04:05<06:19,  2.29s/it]predicting train subjects:  38%|███▊      | 101/266 [04:07<06:20,  2.30s/it]predicting train subjects:  38%|███▊      | 102/266 [04:09<06:19,  2.32s/it]predicting train subjects:  39%|███▊      | 103/266 [04:12<06:15,  2.30s/it]predicting train subjects:  39%|███▉      | 104/266 [04:14<06:17,  2.33s/it]predicting train subjects:  39%|███▉      | 105/266 [04:16<06:10,  2.30s/it]predicting train subjects:  40%|███▉      | 106/266 [04:19<06:09,  2.31s/it]predicting train subjects:  40%|████      | 107/266 [04:21<06:06,  2.30s/it]predicting train subjects:  41%|████      | 108/266 [04:23<06:06,  2.32s/it]predicting train subjects:  41%|████      | 109/266 [04:26<06:06,  2.33s/it]predicting train subjects:  41%|████▏     | 110/266 [04:28<06:00,  2.31s/it]predicting train subjects:  42%|████▏     | 111/266 [04:30<05:54,  2.29s/it]predicting train subjects:  42%|████▏     | 112/266 [04:32<05:51,  2.29s/it]predicting train subjects:  42%|████▏     | 113/266 [04:35<05:49,  2.28s/it]predicting train subjects:  43%|████▎     | 114/266 [04:37<05:44,  2.27s/it]predicting train subjects:  43%|████▎     | 115/266 [04:39<05:46,  2.29s/it]predicting train subjects:  44%|████▎     | 116/266 [04:41<05:40,  2.27s/it]predicting train subjects:  44%|████▍     | 117/266 [04:44<05:38,  2.27s/it]predicting train subjects:  44%|████▍     | 118/266 [04:46<05:40,  2.30s/it]predicting train subjects:  45%|████▍     | 119/266 [04:49<05:50,  2.39s/it]predicting train subjects:  45%|████▌     | 120/266 [04:51<05:56,  2.44s/it]predicting train subjects:  45%|████▌     | 121/266 [04:54<06:01,  2.49s/it]predicting train subjects:  46%|████▌     | 122/266 [04:56<06:01,  2.51s/it]predicting train subjects:  46%|████▌     | 123/266 [04:59<06:03,  2.54s/it]predicting train subjects:  47%|████▋     | 124/266 [05:02<06:09,  2.60s/it]predicting train subjects:  47%|████▋     | 125/266 [05:04<06:10,  2.63s/it]predicting train subjects:  47%|████▋     | 126/266 [05:07<06:06,  2.62s/it]predicting train subjects:  48%|████▊     | 127/266 [05:10<06:04,  2.62s/it]predicting train subjects:  48%|████▊     | 128/266 [05:12<06:03,  2.64s/it]predicting train subjects:  48%|████▊     | 129/266 [05:15<06:01,  2.64s/it]predicting train subjects:  49%|████▉     | 130/266 [05:18<05:56,  2.62s/it]predicting train subjects:  49%|████▉     | 131/266 [05:20<05:51,  2.60s/it]predicting train subjects:  50%|████▉     | 132/266 [05:23<05:45,  2.58s/it]predicting train subjects:  50%|█████     | 133/266 [05:25<05:44,  2.59s/it]predicting train subjects:  50%|█████     | 134/266 [05:28<05:40,  2.58s/it]predicting train subjects:  51%|█████     | 135/266 [05:30<05:33,  2.54s/it]predicting train subjects:  51%|█████     | 136/266 [05:33<05:34,  2.57s/it]predicting train subjects:  52%|█████▏    | 137/266 [05:35<05:30,  2.56s/it]predicting train subjects:  52%|█████▏    | 138/266 [05:38<05:26,  2.55s/it]predicting train subjects:  52%|█████▏    | 139/266 [05:40<05:21,  2.53s/it]predicting train subjects:  53%|█████▎    | 140/266 [05:43<05:18,  2.53s/it]predicting train subjects:  53%|█████▎    | 141/266 [05:46<05:20,  2.57s/it]predicting train subjects:  53%|█████▎    | 142/266 [05:49<05:30,  2.66s/it]predicting train subjects:  54%|█████▍    | 143/266 [05:51<05:24,  2.64s/it]predicting train subjects:  54%|█████▍    | 144/266 [05:54<05:24,  2.66s/it]predicting train subjects:  55%|█████▍    | 145/266 [05:57<05:33,  2.75s/it]predicting train subjects:  55%|█████▍    | 146/266 [05:59<05:25,  2.71s/it]predicting train subjects:  55%|█████▌    | 147/266 [06:02<05:24,  2.73s/it]predicting train subjects:  56%|█████▌    | 148/266 [06:05<05:33,  2.82s/it]predicting train subjects:  56%|█████▌    | 149/266 [06:08<05:30,  2.83s/it]predicting train subjects:  56%|█████▋    | 150/266 [06:11<05:24,  2.79s/it]predicting train subjects:  57%|█████▋    | 151/266 [06:14<05:22,  2.81s/it]predicting train subjects:  57%|█████▋    | 152/266 [06:16<05:20,  2.81s/it]predicting train subjects:  58%|█████▊    | 153/266 [06:19<05:10,  2.75s/it]predicting train subjects:  58%|█████▊    | 154/266 [06:22<05:09,  2.77s/it]predicting train subjects:  58%|█████▊    | 155/266 [06:24<04:42,  2.54s/it]predicting train subjects:  59%|█████▊    | 156/266 [06:26<04:26,  2.42s/it]predicting train subjects:  59%|█████▉    | 157/266 [06:28<04:10,  2.30s/it]predicting train subjects:  59%|█████▉    | 158/266 [06:30<04:01,  2.23s/it]predicting train subjects:  60%|█████▉    | 159/266 [06:32<03:52,  2.17s/it]predicting train subjects:  60%|██████    | 160/266 [06:34<03:45,  2.13s/it]predicting train subjects:  61%|██████    | 161/266 [06:36<03:45,  2.15s/it]predicting train subjects:  61%|██████    | 162/266 [06:39<03:43,  2.15s/it]predicting train subjects:  61%|██████▏   | 163/266 [06:41<03:45,  2.19s/it]predicting train subjects:  62%|██████▏   | 164/266 [06:43<03:44,  2.20s/it]predicting train subjects:  62%|██████▏   | 165/266 [06:45<03:37,  2.16s/it]predicting train subjects:  62%|██████▏   | 166/266 [06:47<03:35,  2.15s/it]predicting train subjects:  63%|██████▎   | 167/266 [06:49<03:29,  2.11s/it]predicting train subjects:  63%|██████▎   | 168/266 [06:52<03:31,  2.16s/it]predicting train subjects:  64%|██████▎   | 169/266 [06:54<03:34,  2.21s/it]predicting train subjects:  64%|██████▍   | 170/266 [06:56<03:29,  2.18s/it]predicting train subjects:  64%|██████▍   | 171/266 [06:58<03:28,  2.19s/it]predicting train subjects:  65%|██████▍   | 172/266 [07:00<03:23,  2.17s/it]predicting train subjects:  65%|██████▌   | 173/266 [07:03<03:29,  2.26s/it]predicting train subjects:  65%|██████▌   | 174/266 [07:05<03:27,  2.26s/it]predicting train subjects:  66%|██████▌   | 175/266 [07:07<03:27,  2.28s/it]predicting train subjects:  66%|██████▌   | 176/266 [07:09<03:19,  2.22s/it]predicting train subjects:  67%|██████▋   | 177/266 [07:12<03:17,  2.22s/it]predicting train subjects:  67%|██████▋   | 178/266 [07:14<03:13,  2.20s/it]predicting train subjects:  67%|██████▋   | 179/266 [07:16<03:11,  2.20s/it]predicting train subjects:  68%|██████▊   | 180/266 [07:18<03:12,  2.23s/it]predicting train subjects:  68%|██████▊   | 181/266 [07:20<03:06,  2.19s/it]predicting train subjects:  68%|██████▊   | 182/266 [07:23<03:10,  2.26s/it]predicting train subjects:  69%|██████▉   | 183/266 [07:25<03:13,  2.33s/it]predicting train subjects:  69%|██████▉   | 184/266 [07:28<03:12,  2.35s/it]predicting train subjects:  70%|██████▉   | 185/266 [07:30<03:13,  2.39s/it]predicting train subjects:  70%|██████▉   | 186/266 [07:33<03:10,  2.38s/it]predicting train subjects:  70%|███████   | 187/266 [07:35<03:07,  2.38s/it]predicting train subjects:  71%|███████   | 188/266 [07:37<03:06,  2.40s/it]predicting train subjects:  71%|███████   | 189/266 [07:40<03:04,  2.40s/it]predicting train subjects:  71%|███████▏  | 190/266 [07:42<03:00,  2.37s/it]predicting train subjects:  72%|███████▏  | 191/266 [07:45<03:01,  2.43s/it]predicting train subjects:  72%|███████▏  | 192/266 [07:47<02:51,  2.32s/it]predicting train subjects:  73%|███████▎  | 193/266 [07:49<02:47,  2.29s/it]predicting train subjects:  73%|███████▎  | 194/266 [07:52<02:59,  2.49s/it]predicting train subjects:  73%|███████▎  | 195/266 [07:54<02:59,  2.53s/it]predicting train subjects:  74%|███████▎  | 196/266 [07:57<02:55,  2.50s/it]predicting train subjects:  74%|███████▍  | 197/266 [07:59<02:52,  2.51s/it]predicting train subjects:  74%|███████▍  | 198/266 [08:02<02:48,  2.48s/it]predicting train subjects:  75%|███████▍  | 199/266 [08:04<02:40,  2.40s/it]predicting train subjects:  75%|███████▌  | 200/266 [08:06<02:38,  2.40s/it]predicting train subjects:  76%|███████▌  | 201/266 [08:09<02:37,  2.43s/it]predicting train subjects:  76%|███████▌  | 202/266 [08:11<02:36,  2.45s/it]predicting train subjects:  76%|███████▋  | 203/266 [08:14<02:34,  2.45s/it]predicting train subjects:  77%|███████▋  | 204/266 [08:16<02:32,  2.46s/it]predicting train subjects:  77%|███████▋  | 205/266 [08:19<02:30,  2.47s/it]predicting train subjects:  77%|███████▋  | 206/266 [08:21<02:29,  2.49s/it]predicting train subjects:  78%|███████▊  | 207/266 [08:24<02:24,  2.45s/it]predicting train subjects:  78%|███████▊  | 208/266 [08:26<02:23,  2.47s/it]predicting train subjects:  79%|███████▊  | 209/266 [08:29<02:20,  2.47s/it]predicting train subjects:  79%|███████▉  | 210/266 [08:31<02:19,  2.49s/it]predicting train subjects:  79%|███████▉  | 211/266 [08:34<02:15,  2.47s/it]predicting train subjects:  80%|███████▉  | 212/266 [08:36<02:15,  2.51s/it]predicting train subjects:  80%|████████  | 213/266 [08:38<02:06,  2.39s/it]predicting train subjects:  80%|████████  | 214/266 [08:41<02:01,  2.34s/it]predicting train subjects:  81%|████████  | 215/266 [08:43<02:00,  2.37s/it]predicting train subjects:  81%|████████  | 216/266 [08:45<01:56,  2.34s/it]predicting train subjects:  82%|████████▏ | 217/266 [08:48<01:54,  2.34s/it]predicting train subjects:  82%|████████▏ | 218/266 [08:50<01:50,  2.31s/it]predicting train subjects:  82%|████████▏ | 219/266 [08:52<01:48,  2.31s/it]predicting train subjects:  83%|████████▎ | 220/266 [08:54<01:44,  2.28s/it]predicting train subjects:  83%|████████▎ | 221/266 [08:57<01:43,  2.31s/it]predicting train subjects:  83%|████████▎ | 222/266 [08:59<01:39,  2.27s/it]predicting train subjects:  84%|████████▍ | 223/266 [09:01<01:36,  2.24s/it]predicting train subjects:  84%|████████▍ | 224/266 [09:03<01:31,  2.18s/it]predicting train subjects:  85%|████████▍ | 225/266 [09:06<01:31,  2.22s/it]predicting train subjects:  85%|████████▍ | 226/266 [09:08<01:28,  2.22s/it]predicting train subjects:  85%|████████▌ | 227/266 [09:10<01:27,  2.24s/it]predicting train subjects:  86%|████████▌ | 228/266 [09:12<01:24,  2.22s/it]predicting train subjects:  86%|████████▌ | 229/266 [09:15<01:22,  2.23s/it]predicting train subjects:  86%|████████▋ | 230/266 [09:17<01:22,  2.28s/it]predicting train subjects:  87%|████████▋ | 231/266 [09:19<01:19,  2.27s/it]predicting train subjects:  87%|████████▋ | 232/266 [09:21<01:15,  2.21s/it]predicting train subjects:  88%|████████▊ | 233/266 [09:23<01:12,  2.20s/it]predicting train subjects:  88%|████████▊ | 234/266 [09:26<01:10,  2.22s/it]predicting train subjects:  88%|████████▊ | 235/266 [09:28<01:08,  2.21s/it]predicting train subjects:  89%|████████▊ | 236/266 [09:30<01:06,  2.22s/it]predicting train subjects:  89%|████████▉ | 237/266 [09:32<01:04,  2.24s/it]predicting train subjects:  89%|████████▉ | 238/266 [09:35<01:05,  2.32s/it]predicting train subjects:  90%|████████▉ | 239/266 [09:37<01:03,  2.37s/it]predicting train subjects:  90%|█████████ | 240/266 [09:40<00:59,  2.30s/it]predicting train subjects:  91%|█████████ | 241/266 [09:42<00:56,  2.28s/it]predicting train subjects:  91%|█████████ | 242/266 [09:44<00:55,  2.29s/it]predicting train subjects:  91%|█████████▏| 243/266 [09:46<00:52,  2.27s/it]predicting train subjects:  92%|█████████▏| 244/266 [09:48<00:49,  2.24s/it]predicting train subjects:  92%|█████████▏| 245/266 [09:51<00:46,  2.21s/it]predicting train subjects:  92%|█████████▏| 246/266 [09:53<00:44,  2.20s/it]predicting train subjects:  93%|█████████▎| 247/266 [09:55<00:43,  2.30s/it]predicting train subjects:  93%|█████████▎| 248/266 [09:58<00:41,  2.28s/it]predicting train subjects:  94%|█████████▎| 249/266 [10:00<00:41,  2.45s/it]predicting train subjects:  94%|█████████▍| 250/266 [10:03<00:41,  2.61s/it]predicting train subjects:  94%|█████████▍| 251/266 [10:06<00:40,  2.67s/it]predicting train subjects:  95%|█████████▍| 252/266 [10:09<00:38,  2.75s/it]predicting train subjects:  95%|█████████▌| 253/266 [10:12<00:36,  2.79s/it]predicting train subjects:  95%|█████████▌| 254/266 [10:15<00:33,  2.81s/it]predicting train subjects:  96%|█████████▌| 255/266 [10:18<00:30,  2.79s/it]predicting train subjects:  96%|█████████▌| 256/266 [10:21<00:28,  2.83s/it]predicting train subjects:  97%|█████████▋| 257/266 [10:24<00:25,  2.89s/it]predicting train subjects:  97%|█████████▋| 258/266 [10:27<00:23,  2.92s/it]predicting train subjects:  97%|█████████▋| 259/266 [10:29<00:20,  2.91s/it]predicting train subjects:  98%|█████████▊| 260/266 [10:32<00:17,  2.93s/it]predicting train subjects:  98%|█████████▊| 261/266 [10:35<00:14,  2.91s/it]predicting train subjects:  98%|█████████▊| 262/266 [10:38<00:11,  2.92s/it]predicting train subjects:  99%|█████████▉| 263/266 [10:41<00:08,  2.93s/it]predicting train subjects:  99%|█████████▉| 264/266 [10:44<00:05,  2.94s/it]predicting train subjects: 100%|█████████▉| 265/266 [10:47<00:02,  2.88s/it]predicting train subjects: 100%|██████████| 266/266 [10:50<00:00,  2.88s/it]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:01<08:42,  1.97s/it]Loading train:   1%|          | 2/266 [00:03<08:30,  1.93s/it]Loading train:   1%|          | 3/266 [00:05<08:18,  1.89s/it]Loading train:   2%|▏         | 4/266 [00:07<07:50,  1.80s/it]Loading train:   2%|▏         | 5/266 [00:09<07:50,  1.80s/it]Loading train:   2%|▏         | 6/266 [00:10<07:04,  1.63s/it]Loading train:   3%|▎         | 7/266 [00:11<06:20,  1.47s/it]Loading train:   3%|▎         | 8/266 [00:12<06:10,  1.44s/it]Loading train:   3%|▎         | 9/266 [00:13<05:45,  1.34s/it]Loading train:   4%|▍         | 10/266 [00:14<05:30,  1.29s/it]Loading train:   4%|▍         | 11/266 [00:16<05:10,  1.22s/it]Loading train:   5%|▍         | 12/266 [00:17<05:11,  1.23s/it]Loading train:   5%|▍         | 13/266 [00:18<05:03,  1.20s/it]Loading train:   5%|▌         | 14/266 [00:19<04:55,  1.17s/it]Loading train:   6%|▌         | 15/266 [00:20<04:46,  1.14s/it]Loading train:   6%|▌         | 16/266 [00:21<04:47,  1.15s/it]Loading train:   6%|▋         | 17/266 [00:23<05:21,  1.29s/it]Loading train:   7%|▋         | 18/266 [00:24<05:21,  1.30s/it]Loading train:   7%|▋         | 19/266 [00:25<05:12,  1.26s/it]Loading train:   8%|▊         | 20/266 [00:26<04:46,  1.16s/it]Loading train:   8%|▊         | 21/266 [00:27<04:40,  1.15s/it]Loading train:   8%|▊         | 22/266 [00:29<04:40,  1.15s/it]Loading train:   9%|▊         | 23/266 [00:30<04:45,  1.17s/it]Loading train:   9%|▉         | 24/266 [00:31<04:55,  1.22s/it]Loading train:   9%|▉         | 25/266 [00:32<04:47,  1.19s/it]Loading train:  10%|▉         | 26/266 [00:34<05:07,  1.28s/it]Loading train:  10%|█         | 27/266 [00:35<05:26,  1.37s/it]Loading train:  11%|█         | 28/266 [00:37<05:24,  1.36s/it]Loading train:  11%|█         | 29/266 [00:38<05:00,  1.27s/it]Loading train:  11%|█▏        | 30/266 [00:39<04:47,  1.22s/it]Loading train:  12%|█▏        | 31/266 [00:40<04:42,  1.20s/it]Loading train:  12%|█▏        | 32/266 [00:42<05:08,  1.32s/it]Loading train:  12%|█▏        | 33/266 [00:43<05:23,  1.39s/it]Loading train:  13%|█▎        | 34/266 [00:45<05:27,  1.41s/it]Loading train:  13%|█▎        | 35/266 [00:46<05:22,  1.40s/it]Loading train:  14%|█▎        | 36/266 [00:47<05:16,  1.37s/it]Loading train:  14%|█▍        | 37/266 [00:49<05:07,  1.34s/it]Loading train:  14%|█▍        | 38/266 [00:50<05:04,  1.34s/it]Loading train:  15%|█▍        | 39/266 [00:51<04:36,  1.22s/it]Loading train:  15%|█▌        | 40/266 [00:52<04:28,  1.19s/it]Loading train:  15%|█▌        | 41/266 [00:53<04:26,  1.19s/it]Loading train:  16%|█▌        | 42/266 [00:54<04:28,  1.20s/it]Loading train:  16%|█▌        | 43/266 [00:56<04:47,  1.29s/it]Loading train:  17%|█▋        | 44/266 [00:57<04:26,  1.20s/it]Loading train:  17%|█▋        | 45/266 [00:58<04:11,  1.14s/it]Loading train:  17%|█▋        | 46/266 [00:59<04:15,  1.16s/it]Loading train:  18%|█▊        | 47/266 [01:01<04:37,  1.27s/it]Loading train:  18%|█▊        | 48/266 [01:02<04:15,  1.17s/it]Loading train:  18%|█▊        | 49/266 [01:02<03:43,  1.03s/it]Loading train:  19%|█▉        | 50/266 [01:03<03:25,  1.05it/s]Loading train:  19%|█▉        | 51/266 [01:04<03:21,  1.07it/s]Loading train:  20%|█▉        | 52/266 [01:05<03:42,  1.04s/it]Loading train:  20%|█▉        | 53/266 [01:06<03:51,  1.09s/it]Loading train:  20%|██        | 54/266 [01:07<03:33,  1.00s/it]Loading train:  21%|██        | 55/266 [01:08<03:43,  1.06s/it]Loading train:  21%|██        | 56/266 [01:10<04:02,  1.15s/it]Loading train:  21%|██▏       | 57/266 [01:10<03:36,  1.03s/it]Loading train:  22%|██▏       | 58/266 [01:12<03:45,  1.09s/it]Loading train:  22%|██▏       | 59/266 [01:13<03:31,  1.02s/it]Loading train:  23%|██▎       | 60/266 [01:13<03:08,  1.09it/s]Loading train:  23%|██▎       | 61/266 [01:14<02:49,  1.21it/s]Loading train:  23%|██▎       | 62/266 [01:14<02:36,  1.30it/s]Loading train:  24%|██▎       | 63/266 [01:15<02:27,  1.38it/s]Loading train:  24%|██▍       | 64/266 [01:16<02:22,  1.41it/s]Loading train:  24%|██▍       | 65/266 [01:16<02:19,  1.44it/s]Loading train:  25%|██▍       | 66/266 [01:17<02:17,  1.46it/s]Loading train:  25%|██▌       | 67/266 [01:18<02:13,  1.50it/s]Loading train:  26%|██▌       | 68/266 [01:18<02:09,  1.53it/s]Loading train:  26%|██▌       | 69/266 [01:19<02:06,  1.55it/s]Loading train:  26%|██▋       | 70/266 [01:20<02:07,  1.53it/s]Loading train:  27%|██▋       | 71/266 [01:20<02:07,  1.53it/s]Loading train:  27%|██▋       | 72/266 [01:21<02:06,  1.54it/s]Loading train:  27%|██▋       | 73/266 [01:22<02:08,  1.51it/s]Loading train:  28%|██▊       | 74/266 [01:22<02:07,  1.51it/s]Loading train:  28%|██▊       | 75/266 [01:23<02:04,  1.53it/s]Loading train:  29%|██▊       | 76/266 [01:24<02:03,  1.54it/s]Loading train:  29%|██▉       | 77/266 [01:24<02:02,  1.54it/s]Loading train:  29%|██▉       | 78/266 [01:25<02:14,  1.40it/s]Loading train:  30%|██▉       | 79/266 [01:26<02:20,  1.33it/s]Loading train:  30%|███       | 80/266 [01:27<02:30,  1.24it/s]Loading train:  30%|███       | 81/266 [01:28<02:37,  1.18it/s]Loading train:  31%|███       | 82/266 [01:29<02:41,  1.14it/s]Loading train:  31%|███       | 83/266 [01:30<02:43,  1.12it/s]Loading train:  32%|███▏      | 84/266 [01:31<02:45,  1.10it/s]Loading train:  32%|███▏      | 85/266 [01:32<02:47,  1.08it/s]Loading train:  32%|███▏      | 86/266 [01:32<02:43,  1.10it/s]Loading train:  33%|███▎      | 87/266 [01:33<02:46,  1.07it/s]Loading train:  33%|███▎      | 88/266 [01:34<02:47,  1.06it/s]Loading train:  33%|███▎      | 89/266 [01:35<02:48,  1.05it/s]Loading train:  34%|███▍      | 90/266 [01:36<02:40,  1.09it/s]Loading train:  34%|███▍      | 91/266 [01:37<02:35,  1.13it/s]Loading train:  35%|███▍      | 92/266 [01:38<02:30,  1.15it/s]Loading train:  35%|███▍      | 93/266 [01:39<02:26,  1.18it/s]Loading train:  35%|███▌      | 94/266 [01:39<02:22,  1.21it/s]Loading train:  36%|███▌      | 95/266 [01:40<02:21,  1.21it/s]Loading train:  36%|███▌      | 96/266 [01:41<02:41,  1.05it/s]Loading train:  36%|███▋      | 97/266 [01:43<03:01,  1.08s/it]Loading train:  37%|███▋      | 98/266 [01:44<03:10,  1.13s/it]Loading train:  37%|███▋      | 99/266 [01:45<02:56,  1.06s/it]Loading train:  38%|███▊      | 100/266 [01:46<02:57,  1.07s/it]Loading train:  38%|███▊      | 101/266 [01:47<02:39,  1.04it/s]Loading train:  38%|███▊      | 102/266 [01:48<02:25,  1.13it/s]Loading train:  39%|███▊      | 103/266 [01:48<02:16,  1.19it/s]Loading train:  39%|███▉      | 104/266 [01:49<02:09,  1.25it/s]Loading train:  39%|███▉      | 105/266 [01:50<02:05,  1.28it/s]Loading train:  40%|███▉      | 106/266 [01:50<02:01,  1.31it/s]Loading train:  40%|████      | 107/266 [01:51<02:03,  1.29it/s]Loading train:  41%|████      | 108/266 [01:52<02:03,  1.28it/s]Loading train:  41%|████      | 109/266 [01:53<02:01,  1.29it/s]Loading train:  41%|████▏     | 110/266 [01:53<01:57,  1.33it/s]Loading train:  42%|████▏     | 111/266 [01:54<01:53,  1.37it/s]Loading train:  42%|████▏     | 112/266 [01:55<01:53,  1.35it/s]Loading train:  42%|████▏     | 113/266 [01:56<01:49,  1.39it/s]Loading train:  43%|████▎     | 114/266 [01:56<01:49,  1.39it/s]Loading train:  43%|████▎     | 115/266 [01:57<01:47,  1.41it/s]Loading train:  44%|████▎     | 116/266 [01:58<01:44,  1.44it/s]Loading train:  44%|████▍     | 117/266 [01:58<01:44,  1.42it/s]Loading train:  44%|████▍     | 118/266 [01:59<01:42,  1.44it/s]Loading train:  45%|████▍     | 119/266 [02:00<01:46,  1.38it/s]Loading train:  45%|████▌     | 120/266 [02:01<01:52,  1.30it/s]Loading train:  45%|████▌     | 121/266 [02:02<01:55,  1.25it/s]Loading train:  46%|████▌     | 122/266 [02:02<01:55,  1.25it/s]Loading train:  46%|████▌     | 123/266 [02:03<01:55,  1.24it/s]Loading train:  47%|████▋     | 124/266 [02:04<01:54,  1.24it/s]Loading train:  47%|████▋     | 125/266 [02:05<01:53,  1.24it/s]Loading train:  47%|████▋     | 126/266 [02:06<01:51,  1.26it/s]Loading train:  48%|████▊     | 127/266 [02:06<01:52,  1.24it/s]Loading train:  48%|████▊     | 128/266 [02:07<01:51,  1.24it/s]Loading train:  48%|████▊     | 129/266 [02:08<01:50,  1.24it/s]Loading train:  49%|████▉     | 130/266 [02:09<01:48,  1.26it/s]Loading train:  49%|████▉     | 131/266 [02:10<01:46,  1.27it/s]Loading train:  50%|████▉     | 132/266 [02:10<01:44,  1.28it/s]Loading train:  50%|█████     | 133/266 [02:11<01:43,  1.28it/s]Loading train:  50%|█████     | 134/266 [02:12<01:43,  1.28it/s]Loading train:  51%|█████     | 135/266 [02:13<01:42,  1.28it/s]Loading train:  51%|█████     | 136/266 [02:13<01:40,  1.29it/s]Loading train:  52%|█████▏    | 137/266 [02:14<01:47,  1.20it/s]Loading train:  52%|█████▏    | 138/266 [02:15<01:48,  1.17it/s]Loading train:  52%|█████▏    | 139/266 [02:16<01:46,  1.19it/s]Loading train:  53%|█████▎    | 140/266 [02:17<01:44,  1.21it/s]Loading train:  53%|█████▎    | 141/266 [02:18<01:42,  1.22it/s]Loading train:  53%|█████▎    | 142/266 [02:19<01:43,  1.20it/s]Loading train:  54%|█████▍    | 143/266 [02:19<01:43,  1.19it/s]Loading train:  54%|█████▍    | 144/266 [02:20<01:41,  1.20it/s]Loading train:  55%|█████▍    | 145/266 [02:21<01:39,  1.21it/s]Loading train:  55%|█████▍    | 146/266 [02:22<01:39,  1.20it/s]Loading train:  55%|█████▌    | 147/266 [02:23<01:37,  1.22it/s]Loading train:  56%|█████▌    | 148/266 [02:24<01:37,  1.21it/s]Loading train:  56%|█████▌    | 149/266 [02:24<01:36,  1.21it/s]Loading train:  56%|█████▋    | 150/266 [02:25<01:34,  1.22it/s]Loading train:  57%|█████▋    | 151/266 [02:26<01:34,  1.21it/s]Loading train:  57%|█████▋    | 152/266 [02:27<01:34,  1.20it/s]Loading train:  58%|█████▊    | 153/266 [02:28<01:33,  1.21it/s]Loading train:  58%|█████▊    | 154/266 [02:29<01:32,  1.21it/s]Loading train:  58%|█████▊    | 155/266 [02:29<01:27,  1.26it/s]Loading train:  59%|█████▊    | 156/266 [02:30<01:21,  1.35it/s]Loading train:  59%|█████▉    | 157/266 [02:30<01:16,  1.42it/s]Loading train:  59%|█████▉    | 158/266 [02:31<01:12,  1.49it/s]Loading train:  60%|█████▉    | 159/266 [02:32<01:11,  1.51it/s]Loading train:  60%|██████    | 160/266 [02:32<01:10,  1.51it/s]Loading train:  61%|██████    | 161/266 [02:33<01:08,  1.54it/s]Loading train:  61%|██████    | 162/266 [02:34<01:08,  1.53it/s]Loading train:  61%|██████▏   | 163/266 [02:34<01:06,  1.55it/s]Loading train:  62%|██████▏   | 164/266 [02:35<01:03,  1.61it/s]Loading train:  62%|██████▏   | 165/266 [02:35<01:03,  1.60it/s]Loading train:  62%|██████▏   | 166/266 [02:36<01:03,  1.59it/s]Loading train:  63%|██████▎   | 167/266 [02:37<01:02,  1.58it/s]Loading train:  63%|██████▎   | 168/266 [02:37<01:02,  1.58it/s]Loading train:  64%|██████▎   | 169/266 [02:38<01:01,  1.58it/s]Loading train:  64%|██████▍   | 170/266 [02:39<00:59,  1.62it/s]Loading train:  64%|██████▍   | 171/266 [02:39<00:58,  1.63it/s]Loading train:  65%|██████▍   | 172/266 [02:40<00:57,  1.64it/s]Loading train:  65%|██████▌   | 173/266 [02:40<00:57,  1.61it/s]Loading train:  65%|██████▌   | 174/266 [02:41<00:56,  1.62it/s]Loading train:  66%|██████▌   | 175/266 [02:42<00:58,  1.56it/s]Loading train:  66%|██████▌   | 176/266 [02:42<00:58,  1.53it/s]Loading train:  67%|██████▋   | 177/266 [02:43<00:58,  1.53it/s]Loading train:  67%|██████▋   | 178/266 [02:44<00:58,  1.51it/s]Loading train:  67%|██████▋   | 179/266 [02:44<00:57,  1.51it/s]Loading train:  68%|██████▊   | 180/266 [02:45<00:55,  1.54it/s]Loading train:  68%|██████▊   | 181/266 [02:46<00:55,  1.54it/s]Loading train:  68%|██████▊   | 182/266 [02:46<00:54,  1.53it/s]Loading train:  69%|██████▉   | 183/266 [02:47<00:54,  1.54it/s]Loading train:  69%|██████▉   | 184/266 [02:48<00:54,  1.51it/s]Loading train:  70%|██████▉   | 185/266 [02:48<00:54,  1.49it/s]Loading train:  70%|██████▉   | 186/266 [02:49<00:52,  1.52it/s]Loading train:  70%|███████   | 187/266 [02:50<00:51,  1.53it/s]Loading train:  71%|███████   | 188/266 [02:50<00:50,  1.53it/s]Loading train:  71%|███████   | 189/266 [02:51<00:49,  1.55it/s]Loading train:  71%|███████▏  | 190/266 [02:52<00:48,  1.55it/s]Loading train:  72%|███████▏  | 191/266 [02:53<01:01,  1.21it/s]Loading train:  72%|███████▏  | 192/266 [02:54<01:05,  1.13it/s]Loading train:  73%|███████▎  | 193/266 [02:55<01:08,  1.06it/s]Loading train:  73%|███████▎  | 194/266 [02:56<01:15,  1.05s/it]Loading train:  73%|███████▎  | 195/266 [02:57<01:07,  1.05it/s]Loading train:  74%|███████▎  | 196/266 [02:58<01:04,  1.09it/s]Loading train:  74%|███████▍  | 197/266 [02:59<01:00,  1.13it/s]Loading train:  74%|███████▍  | 198/266 [02:59<00:57,  1.19it/s]Loading train:  75%|███████▍  | 199/266 [03:00<00:55,  1.21it/s]Loading train:  75%|███████▌  | 200/266 [03:01<00:54,  1.20it/s]Loading train:  76%|███████▌  | 201/266 [03:02<00:53,  1.21it/s]Loading train:  76%|███████▌  | 202/266 [03:03<00:51,  1.25it/s]Loading train:  76%|███████▋  | 203/266 [03:03<00:49,  1.27it/s]Loading train:  77%|███████▋  | 204/266 [03:04<00:49,  1.26it/s]Loading train:  77%|███████▋  | 205/266 [03:05<00:47,  1.27it/s]Loading train:  77%|███████▋  | 206/266 [03:06<00:47,  1.26it/s]Loading train:  78%|███████▊  | 207/266 [03:06<00:46,  1.26it/s]Loading train:  78%|███████▊  | 208/266 [03:07<00:45,  1.29it/s]Loading train:  79%|███████▊  | 209/266 [03:08<00:45,  1.24it/s]Loading train:  79%|███████▉  | 210/266 [03:09<00:44,  1.25it/s]Loading train:  79%|███████▉  | 211/266 [03:10<00:42,  1.30it/s]Loading train:  80%|███████▉  | 212/266 [03:10<00:40,  1.34it/s]Loading train:  80%|████████  | 213/266 [03:11<00:39,  1.35it/s]Loading train:  80%|████████  | 214/266 [03:12<00:37,  1.38it/s]Loading train:  81%|████████  | 215/266 [03:12<00:37,  1.36it/s]Loading train:  81%|████████  | 216/266 [03:13<00:36,  1.37it/s]Loading train:  82%|████████▏ | 217/266 [03:14<00:35,  1.38it/s]Loading train:  82%|████████▏ | 218/266 [03:15<00:34,  1.39it/s]Loading train:  82%|████████▏ | 219/266 [03:15<00:33,  1.39it/s]Loading train:  83%|████████▎ | 220/266 [03:16<00:33,  1.38it/s]Loading train:  83%|████████▎ | 221/266 [03:17<00:32,  1.40it/s]Loading train:  83%|████████▎ | 222/266 [03:17<00:31,  1.41it/s]Loading train:  84%|████████▍ | 223/266 [03:18<00:30,  1.42it/s]Loading train:  84%|████████▍ | 224/266 [03:19<00:29,  1.42it/s]Loading train:  85%|████████▍ | 225/266 [03:20<00:28,  1.42it/s]Loading train:  85%|████████▍ | 226/266 [03:20<00:27,  1.44it/s]Loading train:  85%|████████▌ | 227/266 [03:21<00:26,  1.47it/s]Loading train:  86%|████████▌ | 228/266 [03:22<00:25,  1.46it/s]Loading train:  86%|████████▌ | 229/266 [03:22<00:25,  1.44it/s]Loading train:  86%|████████▋ | 230/266 [03:23<00:25,  1.44it/s]Loading train:  87%|████████▋ | 231/266 [03:24<00:24,  1.41it/s]Loading train:  87%|████████▋ | 232/266 [03:24<00:24,  1.42it/s]Loading train:  88%|████████▊ | 233/266 [03:25<00:22,  1.44it/s]Loading train:  88%|████████▊ | 234/266 [03:26<00:22,  1.42it/s]Loading train:  88%|████████▊ | 235/266 [03:26<00:21,  1.46it/s]Loading train:  89%|████████▊ | 236/266 [03:27<00:20,  1.50it/s]Loading train:  89%|████████▉ | 237/266 [03:28<00:19,  1.49it/s]Loading train:  89%|████████▉ | 238/266 [03:28<00:18,  1.50it/s]Loading train:  90%|████████▉ | 239/266 [03:29<00:17,  1.52it/s]Loading train:  90%|█████████ | 240/266 [03:30<00:17,  1.49it/s]Loading train:  91%|█████████ | 241/266 [03:30<00:17,  1.46it/s]Loading train:  91%|█████████ | 242/266 [03:31<00:16,  1.45it/s]Loading train:  91%|█████████▏| 243/266 [03:32<00:15,  1.48it/s]Loading train:  92%|█████████▏| 244/266 [03:32<00:14,  1.47it/s]Loading train:  92%|█████████▏| 245/266 [03:33<00:13,  1.51it/s]Loading train:  92%|█████████▏| 246/266 [03:34<00:13,  1.49it/s]Loading train:  93%|█████████▎| 247/266 [03:34<00:12,  1.49it/s]Loading train:  93%|█████████▎| 248/266 [03:35<00:12,  1.50it/s]Loading train:  94%|█████████▎| 249/266 [03:36<00:12,  1.40it/s]Loading train:  94%|█████████▍| 250/266 [03:37<00:11,  1.35it/s]Loading train:  94%|█████████▍| 251/266 [03:38<00:11,  1.34it/s]Loading train:  95%|█████████▍| 252/266 [03:38<00:10,  1.29it/s]Loading train:  95%|█████████▌| 253/266 [03:39<00:10,  1.28it/s]Loading train:  95%|█████████▌| 254/266 [03:40<00:09,  1.25it/s]Loading train:  96%|█████████▌| 255/266 [03:41<00:08,  1.26it/s]Loading train:  96%|█████████▌| 256/266 [03:42<00:07,  1.25it/s]Loading train:  97%|█████████▋| 257/266 [03:42<00:07,  1.21it/s]Loading train:  97%|█████████▋| 258/266 [03:43<00:06,  1.25it/s]Loading train:  97%|█████████▋| 259/266 [03:44<00:05,  1.25it/s]Loading train:  98%|█████████▊| 260/266 [03:45<00:04,  1.23it/s]Loading train:  98%|█████████▊| 261/266 [03:46<00:04,  1.22it/s]Loading train:  98%|█████████▊| 262/266 [03:47<00:03,  1.22it/s]Loading train:  99%|█████████▉| 263/266 [03:47<00:02,  1.23it/s]Loading train:  99%|█████████▉| 264/266 [03:48<00:01,  1.20it/s]Loading train: 100%|█████████▉| 265/266 [03:49<00:00,  1.22it/s]Loading train: 100%|██████████| 266/266 [03:50<00:00,  1.23it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:  12%|█▏        | 33/266 [00:00<00:00, 324.22it/s]concatenating: train:  25%|██▌       | 67/266 [00:00<00:00, 328.25it/s]concatenating: train:  39%|███▉      | 104/266 [00:00<00:00, 338.44it/s]concatenating: train:  52%|█████▏    | 138/266 [00:00<00:00, 338.25it/s]concatenating: train:  64%|██████▎   | 169/266 [00:00<00:00, 328.36it/s]concatenating: train:  76%|███████▌  | 201/266 [00:00<00:00, 320.54it/s]concatenating: train:  87%|████████▋ | 231/266 [00:00<00:00, 312.68it/s]concatenating: train: 100%|██████████| 266/266 [00:00<00:00, 327.65it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:01<00:04,  1.18s/it]Loading test:  40%|████      | 2/5 [00:02<00:03,  1.18s/it]Loading test:  60%|██████    | 3/5 [00:03<00:02,  1.13s/it]Loading test:  80%|████████  | 4/5 [00:04<00:01,  1.09s/it]Loading test: 100%|██████████| 5/5 [00:05<00:00,  1.16s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 481.31it/s]2019-08-17 20:54:47.708049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-08-17 20:54:47.708146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-17 20:54:47.708163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-08-17 20:54:47.708173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-08-17 20:54:47.708572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.44it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.49it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  6.06it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.72it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.58it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.49it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  6.78it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.73it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.03it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.56it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  9.35it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.76it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.82it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.65it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.36it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.55it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.72it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.49it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.90it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 5  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 84, 48, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 84, 48, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 84, 48, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 84, 48, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 84, 48, 40)   14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 84, 48, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 84, 48, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 42, 24, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 42, 24, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 42, 24, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 42, 24, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 42, 24, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 42, 24, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 42, 24, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 42, 24, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 42, 24, 120)  0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 21, 12, 120)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 21, 12, 120)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 21, 12, 160)  172960      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 21, 12, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 21, 12, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 21, 12, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 21, 12, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 21, 12, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 21, 12, 280)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 21, 12, 280)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 42, 24, 80)   89680       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 42, 24, 200)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 42, 24, 80)   144080      concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 42, 24, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 42, 24, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 42, 24, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 42, 24, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 42, 24, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 42, 24, 280)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 42, 24, 280)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 84, 48, 40)   44840       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 84, 48, 80)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 84, 48, 40)   28840       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 84, 48, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 84, 48, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 84, 48, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 84, 48, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 48, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 48, 120)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 84, 48, 120)  0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 84, 48, 13)   1573        dropout_5[0][0]                  
==================================================================================================
Total params: 889,253
Trainable params: 104,573
Non-trainable params: 784,680
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.33614583e-02 3.28393641e-02 7.67903364e-02 9.54158543e-03
 2.76155209e-02 7.22483889e-03 8.45521910e-02 1.14136193e-01
 8.96194397e-02 1.36163115e-02 2.90563850e-01 1.89870856e-01
 2.68054358e-04]
Train on 10225 samples, validate on 188 samples
Epoch 1/300
 - 18s - loss: 2.5588 - acc: 0.6553 - mDice: 0.1217 - val_loss: 1.3013 - val_acc: 0.9035 - val_mDice: 0.2861

Epoch 00001: val_mDice improved from -inf to 0.28613, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 13s - loss: 1.2425 - acc: 0.8730 - mDice: 0.2957 - val_loss: 0.8894 - val_acc: 0.9039 - val_mDice: 0.4095

Epoch 00002: val_mDice improved from 0.28613 to 0.40947, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 13s - loss: 0.9814 - acc: 0.8750 - mDice: 0.3743 - val_loss: 0.7539 - val_acc: 0.9072 - val_mDice: 0.4693

Epoch 00003: val_mDice improved from 0.40947 to 0.46926, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 13s - loss: 0.8529 - acc: 0.8785 - mDice: 0.4230 - val_loss: 0.7458 - val_acc: 0.9128 - val_mDice: 0.4808

Epoch 00004: val_mDice improved from 0.46926 to 0.48079, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 13s - loss: 0.7653 - acc: 0.8817 - mDice: 0.4596 - val_loss: 0.6879 - val_acc: 0.9176 - val_mDice: 0.4981

Epoch 00005: val_mDice improved from 0.48079 to 0.49808, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 13s - loss: 0.7197 - acc: 0.8841 - mDice: 0.4823 - val_loss: 0.7097 - val_acc: 0.9176 - val_mDice: 0.4988

Epoch 00006: val_mDice improved from 0.49808 to 0.49881, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 13s - loss: 0.6538 - acc: 0.8863 - mDice: 0.5120 - val_loss: 0.6714 - val_acc: 0.9209 - val_mDice: 0.5122

Epoch 00007: val_mDice improved from 0.49881 to 0.51224, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 13s - loss: 0.6155 - acc: 0.8884 - mDice: 0.5315 - val_loss: 0.6460 - val_acc: 0.9233 - val_mDice: 0.5240

Epoch 00008: val_mDice improved from 0.51224 to 0.52396, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 14s - loss: 0.5814 - acc: 0.8903 - mDice: 0.5491 - val_loss: 0.5877 - val_acc: 0.9267 - val_mDice: 0.5538

Epoch 00009: val_mDice improved from 0.52396 to 0.55379, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 14s - loss: 0.5566 - acc: 0.8915 - mDice: 0.5630 - val_loss: 0.5642 - val_acc: 0.9265 - val_mDice: 0.5648

Epoch 00010: val_mDice improved from 0.55379 to 0.56480, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 14s - loss: 0.5288 - acc: 0.8926 - mDice: 0.5784 - val_loss: 0.5724 - val_acc: 0.9284 - val_mDice: 0.5592

Epoch 00011: val_mDice did not improve from 0.56480
Epoch 12/300
 - 13s - loss: 0.5115 - acc: 0.8938 - mDice: 0.5900 - val_loss: 0.8286 - val_acc: 0.9232 - val_mDice: 0.5085

Epoch 00012: val_mDice did not improve from 0.56480
Epoch 13/300
 - 14s - loss: 0.5196 - acc: 0.8938 - mDice: 0.5829 - val_loss: 0.5547 - val_acc: 0.9291 - val_mDice: 0.5710

Epoch 00013: val_mDice improved from 0.56480 to 0.57103, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 14s - loss: 0.4793 - acc: 0.8957 - mDice: 0.6075 - val_loss: 0.5450 - val_acc: 0.9301 - val_mDice: 0.5748

Epoch 00014: val_mDice improved from 0.57103 to 0.57482, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 14s - loss: 0.4677 - acc: 0.8967 - mDice: 0.6148 - val_loss: 0.5423 - val_acc: 0.9299 - val_mDice: 0.5762

Epoch 00015: val_mDice improved from 0.57482 to 0.57617, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 14s - loss: 0.4504 - acc: 0.8977 - mDice: 0.6256 - val_loss: 0.6303 - val_acc: 0.9283 - val_mDice: 0.5422

Epoch 00016: val_mDice did not improve from 0.57617
Epoch 17/300
 - 14s - loss: 0.4902 - acc: 0.8967 - mDice: 0.6019 - val_loss: 0.5511 - val_acc: 0.9325 - val_mDice: 0.5775

Epoch 00017: val_mDice improved from 0.57617 to 0.57748, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 14s - loss: 0.4373 - acc: 0.8997 - mDice: 0.6333 - val_loss: 0.5989 - val_acc: 0.9305 - val_mDice: 0.5697

Epoch 00018: val_mDice did not improve from 0.57748
Epoch 19/300
 - 13s - loss: 0.4238 - acc: 0.9009 - mDice: 0.6426 - val_loss: 0.5459 - val_acc: 0.9322 - val_mDice: 0.5735

Epoch 00019: val_mDice did not improve from 0.57748
Epoch 20/300
 - 14s - loss: 0.4322 - acc: 0.9011 - mDice: 0.6408 - val_loss: 0.5296 - val_acc: 0.9335 - val_mDice: 0.5825

Epoch 00020: val_mDice improved from 0.57748 to 0.58254, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 21/300
 - 13s - loss: 0.4091 - acc: 0.9026 - mDice: 0.6522 - val_loss: 0.5507 - val_acc: 0.9341 - val_mDice: 0.5757

Epoch 00021: val_mDice did not improve from 0.58254
Epoch 22/300
 - 14s - loss: 0.4014 - acc: 0.9039 - mDice: 0.6575 - val_loss: 0.5455 - val_acc: 0.9357 - val_mDice: 0.5779

Epoch 00022: val_mDice did not improve from 0.58254
Epoch 23/300
 - 14s - loss: 0.4565 - acc: 0.9029 - mDice: 0.6257 - val_loss: 0.6299 - val_acc: 0.9306 - val_mDice: 0.5448

Epoch 00023: val_mDice did not improve from 0.58254
Epoch 24/300
 - 14s - loss: 0.3961 - acc: 0.9059 - mDice: 0.6608 - val_loss: 0.5433 - val_acc: 0.9354 - val_mDice: 0.5784

Epoch 00024: val_mDice did not improve from 0.58254
Epoch 25/300
 - 14s - loss: 0.3850 - acc: 0.9077 - mDice: 0.6684 - val_loss: 0.5062 - val_acc: 0.9383 - val_mDice: 0.5953

Epoch 00025: val_mDice improved from 0.58254 to 0.59535, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 26/300
 - 13s - loss: 0.3790 - acc: 0.9096 - mDice: 0.6728 - val_loss: 0.5278 - val_acc: 0.9368 - val_mDice: 0.5855

Epoch 00026: val_mDice did not improve from 0.59535
Epoch 27/300
 - 14s - loss: 0.3754 - acc: 0.9143 - mDice: 0.6754 - val_loss: 0.5661 - val_acc: 0.9387 - val_mDice: 0.5733

Epoch 00027: val_mDice did not improve from 0.59535
Epoch 28/300
 - 14s - loss: 0.3689 - acc: 0.9214 - mDice: 0.6794 - val_loss: 0.5160 - val_acc: 0.9412 - val_mDice: 0.5899

Epoch 00028: val_mDice did not improve from 0.59535
Epoch 29/300
 - 13s - loss: 0.3757 - acc: 0.9254 - mDice: 0.6749 - val_loss: 0.5251 - val_acc: 0.9402 - val_mDice: 0.5849

Epoch 00029: val_mDice did not improve from 0.59535
Epoch 30/300
 - 14s - loss: 0.3608 - acc: 0.9337 - mDice: 0.6842 - val_loss: 0.5474 - val_acc: 0.9400 - val_mDice: 0.5760

Epoch 00030: val_mDice did not improve from 0.59535
Epoch 31/300
 - 13s - loss: 0.3538 - acc: 0.9355 - mDice: 0.6889 - val_loss: 0.5497 - val_acc: 0.9435 - val_mDice: 0.5842

Epoch 00031: val_mDice did not improve from 0.59535
Epoch 32/300
 - 14s - loss: 0.3500 - acc: 0.9359 - mDice: 0.6916 - val_loss: 0.5385 - val_acc: 0.9427 - val_mDice: 0.5844

Epoch 00032: val_mDice did not improve from 0.59535
Epoch 33/300
 - 14s - loss: 0.3461 - acc: 0.9364 - mDice: 0.6945 - val_loss: 0.6239 - val_acc: 0.9283 - val_mDice: 0.5386

Epoch 00033: val_mDice did not improve from 0.59535
Epoch 34/300
 - 13s - loss: 0.3465 - acc: 0.9365 - mDice: 0.6941 - val_loss: 0.5573 - val_acc: 0.9412 - val_mDice: 0.5756

Epoch 00034: val_mDice did not improve from 0.59535
Epoch 35/300
 - 14s - loss: 0.3472 - acc: 0.9369 - mDice: 0.6975 - val_loss: 0.5803 - val_acc: 0.9350 - val_mDice: 0.5625

Epoch 00035: val_mDice did not improve from 0.59535
Epoch 36/300
 - 13s - loss: 0.3356 - acc: 0.9374 - mDice: 0.7018 - val_loss: 0.6237 - val_acc: 0.9419 - val_mDice: 0.5609

Epoch 00036: val_mDice did not improve from 0.59535
Epoch 37/300
 - 14s - loss: 0.3352 - acc: 0.9378 - mDice: 0.7021 - val_loss: 0.5856 - val_acc: 0.9366 - val_mDice: 0.5644

Epoch 00037: val_mDice did not improve from 0.59535
Epoch 38/300
 - 13s - loss: 0.3296 - acc: 0.9381 - mDice: 0.7061 - val_loss: 0.5331 - val_acc: 0.9423 - val_mDice: 0.5850

Epoch 00038: val_mDice did not improve from 0.59535
Epoch 39/300
 - 14s - loss: 0.3276 - acc: 0.9385 - mDice: 0.7077 - val_loss: 0.5838 - val_acc: 0.9419 - val_mDice: 0.5708

Epoch 00039: val_mDice did not improve from 0.59535
Epoch 40/300
 - 13s - loss: 0.3212 - acc: 0.9390 - mDice: 0.7121 - val_loss: 0.5029 - val_acc: 0.9445 - val_mDice: 0.5993

Epoch 00040: val_mDice improved from 0.59535 to 0.59932, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute4_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 41/300
 - 14s - loss: 0.3202 - acc: 0.9391 - mDice: 0.7128 - val_loss: 0.5309 - val_acc: 0.9426 - val_mDice: 0.5865

Epoch 00041: val_mDice did not improve from 0.59932
Epoch 42/300
 - 13s - loss: 0.3175 - acc: 0.9394 - mDice: 0.7148 - val_loss: 0.5757 - val_acc: 0.9400 - val_mDice: 0.5720

Epoch 00042: val_mDice did not improve from 0.59932
Epoch 43/300
 - 14s - loss: 0.3330 - acc: 0.9387 - mDice: 0.7083 - val_loss: 0.5793 - val_acc: 0.9375 - val_mDice: 0.5709

Epoch 00043: val_mDice did not improve from 0.59932
Epoch 44/300
 - 13s - loss: 0.3180 - acc: 0.9396 - mDice: 0.7144 - val_loss: 0.5292 - val_acc: 0.9405 - val_mDice: 0.5872

Epoch 00044: val_mDice did not improve from 0.59932
Epoch 45/300
 - 14s - loss: 0.3101 - acc: 0.9403 - mDice: 0.7204 - val_loss: 0.5453 - val_acc: 0.9377 - val_mDice: 0.5766

Epoch 00045: val_mDice did not improve from 0.59932
Epoch 46/300
 - 14s - loss: 0.3060 - acc: 0.9407 - mDice: 0.7234 - val_loss: 0.5376 - val_acc: 0.9418 - val_mDice: 0.5814

Epoch 00046: val_mDice did not improve from 0.59932
Epoch 47/300
 - 14s - loss: 0.3066 - acc: 0.9406 - mDice: 0.7230 - val_loss: 0.5681 - val_acc: 0.9427 - val_mDice: 0.5809

Epoch 00047: val_mDice did not improve from 0.59932
Epoch 48/300
 - 14s - loss: 0.3045 - acc: 0.9409 - mDice: 0.7246 - val_loss: 0.5327 - val_acc: 0.9426 - val_mDice: 0.5891

Epoch 00048: val_mDice did not improve from 0.59932
Epoch 49/300
 - 13s - loss: 0.3041 - acc: 0.9410 - mDice: 0.7250 - val_loss: 0.5456 - val_acc: 0.9391 - val_mDice: 0.5750

Epoch 00049: val_mDice did not improve from 0.59932
Epoch 50/300
 - 13s - loss: 0.2992 - acc: 0.9414 - mDice: 0.7289 - val_loss: 0.5368 - val_acc: 0.9422 - val_mDice: 0.5851

Epoch 00050: val_mDice did not improve from 0.59932
Epoch 51/300
 - 13s - loss: 0.2967 - acc: 0.9416 - mDice: 0.7304 - val_loss: 0.5170 - val_acc: 0.9412 - val_mDice: 0.5907

Epoch 00051: val_mDice did not improve from 0.59932
Epoch 52/300
 - 13s - loss: 0.2948 - acc: 0.9418 - mDice: 0.7318 - val_loss: 0.5539 - val_acc: 0.9351 - val_mDice: 0.5723

Epoch 00052: val_mDice did not improve from 0.59932
Epoch 53/300
 - 13s - loss: 0.2953 - acc: 0.9418 - mDice: 0.7314 - val_loss: 0.5616 - val_acc: 0.9394 - val_mDice: 0.5759

Epoch 00053: val_mDice did not improve from 0.59932
Epoch 54/300
 - 14s - loss: 0.2988 - acc: 0.9421 - mDice: 0.7332 - val_loss: 0.5679 - val_acc: 0.9433 - val_mDice: 0.5730

Epoch 00054: val_mDice did not improve from 0.59932
Epoch 55/300
 - 13s - loss: 0.2909 - acc: 0.9423 - mDice: 0.7347 - val_loss: 0.5248 - val_acc: 0.9405 - val_mDice: 0.5884

Epoch 00055: val_mDice did not improve from 0.59932
Epoch 56/300
 - 14s - loss: 0.2932 - acc: 0.9422 - mDice: 0.7336 - val_loss: 0.8419 - val_acc: 0.9410 - val_mDice: 0.5350

Epoch 00056: val_mDice did not improve from 0.59932
Epoch 57/300
 - 14s - loss: 0.3386 - acc: 0.9374 - mDice: 0.7002 - val_loss: 0.5215 - val_acc: 0.9439 - val_mDice: 0.5925

Epoch 00057: val_mDice did not improve from 0.59932
Epoch 58/300
 - 13s - loss: 0.2961 - acc: 0.9419 - mDice: 0.7329 - val_loss: 0.5337 - val_acc: 0.9413 - val_mDice: 0.5848

Epoch 00058: val_mDice did not improve from 0.59932
Epoch 59/300
 - 14s - loss: 0.2968 - acc: 0.9416 - mDice: 0.7304 - val_loss: 0.5141 - val_acc: 0.9433 - val_mDice: 0.5931

Epoch 00059: val_mDice did not improve from 0.59932
Epoch 60/300
 - 14s - loss: 0.2852 - acc: 0.9427 - mDice: 0.7391 - val_loss: 0.5181 - val_acc: 0.9430 - val_mDice: 0.5928

Epoch 00060: val_mDice did not improve from 0.59932
Epoch 61/300
 - 13s - loss: 0.2840 - acc: 0.9428 - mDice: 0.7400 - val_loss: 0.5207 - val_acc: 0.9437 - val_mDice: 0.5912

Epoch 00061: val_mDice did not improve from 0.59932
Epoch 62/300
 - 14s - loss: 0.2828 - acc: 0.9430 - mDice: 0.7408 - val_loss: 0.6157 - val_acc: 0.9330 - val_mDice: 0.5441

Epoch 00062: val_mDice did not improve from 0.59932
Epoch 63/300
 - 13s - loss: 0.2836 - acc: 0.9430 - mDice: 0.7402 - val_loss: 0.5370 - val_acc: 0.9429 - val_mDice: 0.5878

Epoch 00063: val_mDice did not improve from 0.59932
Epoch 64/300
 - 13s - loss: 0.2784 - acc: 0.9434 - mDice: 0.7442 - val_loss: 0.5635 - val_acc: 0.9407 - val_mDice: 0.5701

Epoch 00064: val_mDice did not improve from 0.59932
Epoch 65/300
 - 14s - loss: 0.2784 - acc: 0.9435 - mDice: 0.7443 - val_loss: 0.5148 - val_acc: 0.9422 - val_mDice: 0.5920

Epoch 00065: val_mDice did not improve from 0.59932
Epoch 66/300
 - 14s - loss: 0.2767 - acc: 0.9437 - mDice: 0.7456 - val_loss: 0.5228 - val_acc: 0.9413 - val_mDice: 0.5887

Epoch 00066: val_mDice did not improve from 0.59932
Epoch 67/300
 - 14s - loss: 0.2765 - acc: 0.9437 - mDice: 0.7457 - val_loss: 0.5402 - val_acc: 0.9427 - val_mDice: 0.5824

Epoch 00067: val_mDice did not improve from 0.59932
Epoch 68/300
 - 14s - loss: 0.2747 - acc: 0.9439 - mDice: 0.7471 - val_loss: 0.5948 - val_acc: 0.9445 - val_mDice: 0.5740

Epoch 00068: val_mDice did not improve from 0.59932
Epoch 69/300
 - 14s - loss: 0.2746 - acc: 0.9437 - mDice: 0.7472 - val_loss: 0.5410 - val_acc: 0.9424 - val_mDice: 0.5843

Epoch 00069: val_mDice did not improve from 0.59932
Epoch 70/300
 - 13s - loss: 0.2760 - acc: 0.9437 - mDice: 0.7462 - val_loss: 0.5209 - val_acc: 0.9417 - val_mDice: 0.5899

Epoch 00070: val_mDice did not improve from 0.59932
Epoch 71/300
 - 14s - loss: 0.2721 - acc: 0.9441 - mDice: 0.7492 - val_loss: 0.5375 - val_acc: 0.9435 - val_mDice: 0.5852

Epoch 00071: val_mDice did not improve from 0.59932
Epoch 72/300
 - 14s - loss: 0.2722 - acc: 0.9440 - mDice: 0.7491 - val_loss: 0.6022 - val_acc: 0.9430 - val_mDice: 0.5627

Epoch 00072: val_mDice did not improve from 0.59932
Epoch 73/300
 - 14s - loss: 0.2721 - acc: 0.9441 - mDice: 0.7492 - val_loss: 1.0205 - val_acc: 0.9418 - val_mDice: 0.5505

Epoch 00073: val_mDice did not improve from 0.59932
Epoch 74/300
 - 14s - loss: 0.2761 - acc: 0.9442 - mDice: 0.7502 - val_loss: 0.5557 - val_acc: 0.9409 - val_mDice: 0.5742

Epoch 00074: val_mDice did not improve from 0.59932
Epoch 75/300
 - 13s - loss: 0.2678 - acc: 0.9445 - mDice: 0.7524 - val_loss: 0.5354 - val_acc: 0.9399 - val_mDice: 0.5821

Epoch 00075: val_mDice did not improve from 0.59932
Epoch 76/300
 - 14s - loss: 0.2685 - acc: 0.9444 - mDice: 0.7520 - val_loss: 0.5865 - val_acc: 0.9428 - val_mDice: 0.5686

Epoch 00076: val_mDice did not improve from 0.59932
Epoch 77/300
 - 13s - loss: 0.2671 - acc: 0.9445 - mDice: 0.7529 - val_loss: 0.5244 - val_acc: 0.9427 - val_mDice: 0.5879

Epoch 00077: val_mDice did not improve from 0.59932
Epoch 78/300
 - 14s - loss: 0.2799 - acc: 0.9438 - mDice: 0.7474 - val_loss: 0.5617 - val_acc: 0.9404 - val_mDice: 0.5710

Epoch 00078: val_mDice did not improve from 0.59932
Epoch 79/300
 - 14s - loss: 0.2676 - acc: 0.9445 - mDice: 0.7526 - val_loss: 0.5234 - val_acc: 0.9421 - val_mDice: 0.5878

Epoch 00079: val_mDice did not improve from 0.59932
Epoch 80/300
 - 14s - loss: 0.2659 - acc: 0.9448 - mDice: 0.7540 - val_loss: 0.5312 - val_acc: 0.9443 - val_mDice: 0.5856

Epoch 00080: val_mDice did not improve from 0.59932
Restoring model weights from the end of the best epoch
Epoch 00080: early stopping
{'val_loss': [1.3012950914971373, 0.8893937512915185, 0.7538978330632473, 0.745824636297023, 0.6878566424897377, 0.7096780227853897, 0.671393151612992, 0.6459532792263842, 0.5876504984941888, 0.5641543703510407, 0.572416273520348, 0.8285599864543752, 0.5546732158102887, 0.5450143430461275, 0.5423379597511697, 0.6303091445501815, 0.5511473689941649, 0.5989458164636124, 0.5459424907222707, 0.5295625731666037, 0.5506746008041057, 0.5455147329163044, 0.6299019170568344, 0.5432799217548776, 0.5061802886267925, 0.5278364534073687, 0.5660996183435968, 0.516044278094109, 0.5250586689786708, 0.5473914352503229, 0.5497273999325772, 0.5384512448564489, 0.6239140319063309, 0.557280995427294, 0.5802689480020645, 0.6236921818332469, 0.5855712367499128, 0.5330566618036716, 0.5837770386579189, 0.5028821572344354, 0.5308820678198591, 0.5756694788628436, 0.57934518697414, 0.5292119821335407, 0.5452603697776794, 0.5376314327437827, 0.568135142009309, 0.5326869551171648, 0.5456096802620177, 0.5367864563744119, 0.5170253898869169, 0.5538816721515453, 0.5616462950376754, 0.5678639640199378, 0.5247609970417428, 0.8419146468030646, 0.5215476662554639, 0.5337007293041717, 0.5141457820192297, 0.5181354309650178, 0.52073531613705, 0.615712490487606, 0.5370435318414201, 0.5635122298560244, 0.5147666927981884, 0.5227764166416006, 0.5402061124431327, 0.5947629758652221, 0.5409967617151585, 0.5208627134561539, 0.5375353896871526, 0.6022107861143478, 1.0205459658135758, 0.5556799813787988, 0.5354007029152931, 0.5865091259809251, 0.5243814435411007, 0.5616588491074582, 0.5234143860796665, 0.5311725437641144], 'val_acc': [0.9034888642899533, 0.9039070352594903, 0.9072446981643109, 0.9128026353551987, 0.9175729776950593, 0.917608602249876, 0.920901413293595, 0.9232878754747674, 0.9266875690602242, 0.9264514078485205, 0.9283669559245414, 0.9231942200914343, 0.9291426615512117, 0.930108333521701, 0.9298919718316261, 0.9282798703680647, 0.9324790131538472, 0.9304697913058261, 0.9321729337915461, 0.9334684172843365, 0.9341042897802718, 0.935663622110448, 0.930624155288047, 0.9354024047547198, 0.9383311220940124, 0.936828521972007, 0.9387466609477997, 0.9411859493306343, 0.9401516571958014, 0.9399735528103849, 0.943474809540079, 0.9426792986849521, 0.9282666704756148, 0.9411872701441988, 0.935034361291439, 0.9418587367585365, 0.9365646731346211, 0.9423112368330042, 0.9419313206317577, 0.9445262380102848, 0.9425579493350171, 0.9400039131337024, 0.9375290103415226, 0.9405131194185703, 0.937686008975861, 0.9417624397480742, 0.9427030644518264, 0.9426410680121564, 0.9391319041556501, 0.9421661198139191, 0.9411740563017257, 0.9351108714621118, 0.9394234501300974, 0.9432874848233893, 0.9405461112235455, 0.9409880631781639, 0.9439431435250222, 0.9412756264209747, 0.9433204550692376, 0.9430447347620701, 0.9436871916689771, 0.9330396696608118, 0.9428574062408285, 0.9406872518519138, 0.9422479271888733, 0.9412769757686777, 0.9427004177519616, 0.9444668648090768, 0.9424167586133835, 0.9416608569469858, 0.943453701886725, 0.942960298441826, 0.9417901622488144, 0.9408521734653635, 0.9399326887536557, 0.9427518565604027, 0.9427096399855106, 0.940382535153247, 0.9420540060134645, 0.9443336382825324], 'val_mDice': [0.28612605545749054, 0.40946590551670564, 0.46925640962225323, 0.4807898164429563, 0.49807528866098283, 0.498810479615597, 0.5122402953974744, 0.5239572845240856, 0.553792397709603, 0.5647957531061578, 0.5591701392797713, 0.5085220742732921, 0.5710289303926711, 0.5748201992283476, 0.5761698890239635, 0.5422209526630158, 0.577484354059747, 0.5696779682915262, 0.5734682748926446, 0.582539920477157, 0.5757328462093434, 0.5779076630764819, 0.5447715834734288, 0.5783649603737161, 0.5953457767659045, 0.5855216460025057, 0.5732720893748263, 0.5898539610999696, 0.5848858267702954, 0.5760202826337611, 0.5841915385520204, 0.5844419623943086, 0.5386491440078045, 0.5756203307116285, 0.5624856257692297, 0.5608590625702067, 0.5644416117921789, 0.5849973920811998, 0.5708459986651198, 0.5993196235058156, 0.5865113063061491, 0.5720082242438134, 0.5709427981934649, 0.5872360112819266, 0.5765841096005542, 0.5813589533592792, 0.5809349680834628, 0.5890827933524517, 0.5750208072205807, 0.5850669300936638, 0.5907394315334077, 0.5723370462656021, 0.5759394961468717, 0.5729765077220633, 0.5884193429287444, 0.535037098729864, 0.5925370939868562, 0.5848474743518424, 0.5930970333358074, 0.5927796363830566, 0.5911762733408745, 0.544061912184066, 0.5878286523387787, 0.5700685889162915, 0.5919989734253985, 0.5887314613829268, 0.5824282356399171, 0.574027235203601, 0.5842714205067209, 0.5898780372548611, 0.5851979312744546, 0.5626532651008443, 0.5505047722699794, 0.574246865637759, 0.5821214559230399, 0.5685891017634818, 0.5878747226075923, 0.5710483136329245, 0.5877778809121315, 0.5855893324664299], 'loss': [2.5588047816292874, 1.242543028444416, 0.9813706662077776, 0.8528614093738547, 0.7652601650699719, 0.7196990541549068, 0.6538034307344619, 0.6155091693173994, 0.5813663699516166, 0.5565531927099437, 0.5287592749140956, 0.5114666921585288, 0.5196087113365276, 0.4792734316042408, 0.4676754428734115, 0.4504189604943422, 0.4902152702540232, 0.4373486466104652, 0.42379049960441867, 0.4322468231826073, 0.40909730783301634, 0.4013800972248348, 0.4564698815782962, 0.39607954724785166, 0.3850146338234321, 0.378979746680388, 0.37536944671190164, 0.368936200232261, 0.3756570359896914, 0.3608083280491071, 0.353822817283621, 0.3499593873187207, 0.34610636412077256, 0.3465433530236223, 0.3471961294672017, 0.33564775832416377, 0.3351684238916504, 0.3295935734851436, 0.32759205709168265, 0.3211724870362317, 0.32022866431833186, 0.31752059679742545, 0.3330181574763179, 0.31803125026465046, 0.3101060568994881, 0.3060235252881691, 0.3066316223669169, 0.3045084087364831, 0.30409931874216917, 0.2991791598517038, 0.2967128678609806, 0.29484842495405295, 0.29525657191253235, 0.29877592262545544, 0.29092959108737393, 0.293179203799418, 0.33864509141241134, 0.29611260194358735, 0.2967739900196094, 0.28518606667705154, 0.28400052686775223, 0.2828449687048392, 0.28361535582390857, 0.2783943870102572, 0.2783798114157539, 0.27674917370299545, 0.27651799067599847, 0.274695702170393, 0.27456513258530635, 0.2760466438488156, 0.2720819831914599, 0.272191935544492, 0.2721193583641192, 0.2760765075975059, 0.2677970822253845, 0.2685215236359529, 0.2670501938367531, 0.2799211152462621, 0.2675698854229561, 0.26591035199048757], 'acc': [0.655323453083598, 0.8729795616821439, 0.8749971637515975, 0.8785303399731885, 0.8817473176347598, 0.8840571273218448, 0.8862517715083358, 0.8883755387770226, 0.8903090691508174, 0.8914530452131351, 0.8926220058228975, 0.8937873537208165, 0.8937679249383418, 0.8957063309429327, 0.8967341940968427, 0.897745128948706, 0.8966884728165886, 0.8997328701112556, 0.900916360264011, 0.9010688594034657, 0.9026470146435689, 0.9039079790301894, 0.9028506171149555, 0.9058963743865053, 0.9076698880032397, 0.9096274301591887, 0.9143316053528074, 0.9213614303500262, 0.9253955398911661, 0.9336839022438217, 0.9355390122875317, 0.9358880315841265, 0.9364051148477568, 0.9365039355597461, 0.9369002260030919, 0.9374093809745714, 0.9378001659307037, 0.9380578598358229, 0.938512873533011, 0.9389529974361503, 0.9391452728390403, 0.9394014866835914, 0.9387480832253808, 0.939553254828185, 0.9402790394563838, 0.9406567008979163, 0.94061352556667, 0.9408816030672535, 0.9410415208718595, 0.9414428561415824, 0.9416101504946105, 0.9418011884817575, 0.9418202557015827, 0.9420749408108681, 0.9422646466560644, 0.9421811320962417, 0.9373625664081433, 0.9418844628742097, 0.9415981929867658, 0.9426674855950409, 0.9428347085390814, 0.9430026298338743, 0.9429784694044397, 0.9433712694056168, 0.9434621806249642, 0.9437118930455234, 0.9436738383216206, 0.9438697289138085, 0.9437368997443276, 0.9437269064208406, 0.9440616377991394, 0.9440067970082346, 0.9441077481855099, 0.9442052320921042, 0.9444546553791298, 0.944367601556708, 0.944533027034517, 0.9438197357730352, 0.9445254091528633, 0.9448065597445574], 'mDice': [0.12170882058537094, 0.2957413947086754, 0.3743223062645835, 0.4229667318625089, 0.45961675332053076, 0.48233655729037334, 0.5120290421623472, 0.5315063297019903, 0.5491389506894977, 0.5630071779626505, 0.5784444231858755, 0.5899756243293035, 0.5828932115676059, 0.6074814604080685, 0.6148209600984904, 0.6256107585937295, 0.6018689518161391, 0.63330511971033, 0.6425659446669674, 0.6408455205721494, 0.6522411580190682, 0.6575343148341097, 0.6256531495919729, 0.660813531257704, 0.6684011331688804, 0.6727778859126831, 0.6754273849477977, 0.6794285402612756, 0.6748911524168728, 0.6841957206248072, 0.6889116583360145, 0.6916408050614056, 0.6945424068236409, 0.6941117747780163, 0.6974981259600166, 0.7017650212227278, 0.7020572741632065, 0.706064998374883, 0.7076579889050323, 0.7121251792371419, 0.712845754506827, 0.7148383823758524, 0.7082650842176964, 0.7144133798359076, 0.7203784745304975, 0.7234077676584202, 0.723041663688669, 0.7245960465853255, 0.7249643828874696, 0.7288618546826332, 0.730377876233938, 0.7318108565649951, 0.7314336570958928, 0.7331552537554342, 0.7347456799742645, 0.7335565626475514, 0.7002342120359463, 0.7329116296068672, 0.7303598087399397, 0.7390853207385336, 0.7400098499867036, 0.7408291110199646, 0.7402234438870531, 0.7442373653787272, 0.7443259480821475, 0.7455651381196486, 0.7457215066061044, 0.7471028948179959, 0.7471668756678518, 0.7461939199046576, 0.7492274244140588, 0.7490516545428624, 0.7491508884068515, 0.7502043062142463, 0.7524465545465427, 0.7519929438173625, 0.7528705458477831, 0.7473831029567859, 0.7526060017804936, 0.7540323285426953]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:02<00:11,  2.86s/it]predicting test subjects:  40%|████      | 2/5 [00:05<00:07,  2.65s/it]predicting test subjects:  60%|██████    | 3/5 [00:06<00:04,  2.42s/it]predicting test subjects:  80%|████████  | 4/5 [00:08<00:02,  2.26s/it]predicting test subjects: 100%|██████████| 5/5 [00:11<00:00,  2.30s/it]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:02<12:35,  2.85s/it]predicting train subjects:   1%|          | 2/266 [00:05<12:10,  2.77s/it]predicting train subjects:   1%|          | 3/266 [00:07<11:25,  2.61s/it]predicting train subjects:   2%|▏         | 4/266 [00:09<10:37,  2.43s/it]predicting train subjects:   2%|▏         | 5/266 [00:12<10:44,  2.47s/it]predicting train subjects:   2%|▏         | 6/266 [00:14<11:01,  2.54s/it]predicting train subjects:   3%|▎         | 7/266 [00:17<11:16,  2.61s/it]predicting train subjects:   3%|▎         | 8/266 [00:20<11:24,  2.65s/it]predicting train subjects:   3%|▎         | 9/266 [00:23<11:23,  2.66s/it]predicting train subjects:   4%|▍         | 10/266 [00:25<11:25,  2.68s/it]predicting train subjects:   4%|▍         | 11/266 [00:28<11:28,  2.70s/it]predicting train subjects:   5%|▍         | 12/266 [00:31<11:33,  2.73s/it]predicting train subjects:   5%|▍         | 13/266 [00:34<11:25,  2.71s/it]predicting train subjects:   5%|▌         | 14/266 [00:36<11:37,  2.77s/it]predicting train subjects:   6%|▌         | 15/266 [00:39<11:41,  2.79s/it]predicting train subjects:   6%|▌         | 16/266 [00:42<11:33,  2.77s/it]predicting train subjects:   6%|▋         | 17/266 [00:45<11:25,  2.75s/it]predicting train subjects:   7%|▋         | 18/266 [00:48<11:23,  2.76s/it]predicting train subjects:   7%|▋         | 19/266 [00:50<11:23,  2.77s/it]predicting train subjects:   8%|▊         | 20/266 [00:53<11:15,  2.74s/it]predicting train subjects:   8%|▊         | 21/266 [00:56<11:08,  2.73s/it]predicting train subjects:   8%|▊         | 22/266 [00:58<11:07,  2.74s/it]predicting train subjects:   9%|▊         | 23/266 [01:01<11:05,  2.74s/it]predicting train subjects:   9%|▉         | 24/266 [01:04<10:45,  2.67s/it]predicting train subjects:   9%|▉         | 25/266 [01:06<10:37,  2.65s/it]predicting train subjects:  10%|▉         | 26/266 [01:09<10:29,  2.62s/it]predicting train subjects:  10%|█         | 27/266 [01:12<10:28,  2.63s/it]predicting train subjects:  11%|█         | 28/266 [01:14<10:19,  2.61s/it]predicting train subjects:  11%|█         | 29/266 [01:17<10:16,  2.60s/it]predicting train subjects:  11%|█▏        | 30/266 [01:19<10:17,  2.62s/it]predicting train subjects:  12%|█▏        | 31/266 [01:22<10:13,  2.61s/it]predicting train subjects:  12%|█▏        | 32/266 [01:24<10:06,  2.59s/it]predicting train subjects:  12%|█▏        | 33/266 [01:27<10:01,  2.58s/it]predicting train subjects:  13%|█▎        | 34/266 [01:30<09:53,  2.56s/it]predicting train subjects:  13%|█▎        | 35/266 [01:32<09:51,  2.56s/it]predicting train subjects:  14%|█▎        | 36/266 [01:35<09:47,  2.55s/it]predicting train subjects:  14%|█▍        | 37/266 [01:37<09:48,  2.57s/it]predicting train subjects:  14%|█▍        | 38/266 [01:40<09:42,  2.55s/it]predicting train subjects:  15%|█▍        | 39/266 [01:42<09:35,  2.54s/it]predicting train subjects:  15%|█▌        | 40/266 [01:45<09:37,  2.55s/it]predicting train subjects:  15%|█▌        | 41/266 [01:47<09:35,  2.56s/it]predicting train subjects:  16%|█▌        | 42/266 [01:50<09:05,  2.44s/it]predicting train subjects:  16%|█▌        | 43/266 [01:52<08:39,  2.33s/it]predicting train subjects:  17%|█▋        | 44/266 [01:54<08:26,  2.28s/it]predicting train subjects:  17%|█▋        | 45/266 [01:56<08:09,  2.21s/it]predicting train subjects:  17%|█▋        | 46/266 [01:58<08:00,  2.19s/it]predicting train subjects:  18%|█▊        | 47/266 [02:00<07:52,  2.16s/it]predicting train subjects:  18%|█▊        | 48/266 [02:02<07:43,  2.13s/it]predicting train subjects:  18%|█▊        | 49/266 [02:04<07:35,  2.10s/it]predicting train subjects:  19%|█▉        | 50/266 [02:06<07:35,  2.11s/it]predicting train subjects:  19%|█▉        | 51/266 [02:08<07:31,  2.10s/it]predicting train subjects:  20%|█▉        | 52/266 [02:11<07:34,  2.12s/it]predicting train subjects:  20%|█▉        | 53/266 [02:13<07:26,  2.10s/it]predicting train subjects:  20%|██        | 54/266 [02:15<07:25,  2.10s/it]predicting train subjects:  21%|██        | 55/266 [02:17<07:25,  2.11s/it]predicting train subjects:  21%|██        | 56/266 [02:19<07:29,  2.14s/it]predicting train subjects:  21%|██▏       | 57/266 [02:21<07:25,  2.13s/it]predicting train subjects:  22%|██▏       | 58/266 [02:23<07:26,  2.14s/it]predicting train subjects:  22%|██▏       | 59/266 [02:26<07:25,  2.15s/it]predicting train subjects:  23%|██▎       | 60/266 [02:27<07:12,  2.10s/it]predicting train subjects:  23%|██▎       | 61/266 [02:30<07:06,  2.08s/it]predicting train subjects:  23%|██▎       | 62/266 [02:32<07:02,  2.07s/it]predicting train subjects:  24%|██▎       | 63/266 [02:34<06:56,  2.05s/it]predicting train subjects:  24%|██▍       | 64/266 [02:36<06:50,  2.03s/it]predicting train subjects:  24%|██▍       | 65/266 [02:38<06:42,  2.00s/it]predicting train subjects:  25%|██▍       | 66/266 [02:39<06:39,  2.00s/it]predicting train subjects:  25%|██▌       | 67/266 [02:42<06:38,  2.00s/it]predicting train subjects:  26%|██▌       | 68/266 [02:43<06:35,  2.00s/it]predicting train subjects:  26%|██▌       | 69/266 [02:45<06:31,  1.99s/it]predicting train subjects:  26%|██▋       | 70/266 [02:47<06:26,  1.97s/it]predicting train subjects:  27%|██▋       | 71/266 [02:49<06:24,  1.97s/it]predicting train subjects:  27%|██▋       | 72/266 [02:51<06:21,  1.96s/it]predicting train subjects:  27%|██▋       | 73/266 [02:53<06:16,  1.95s/it]predicting train subjects:  28%|██▊       | 74/266 [02:55<06:19,  1.98s/it]predicting train subjects:  28%|██▊       | 75/266 [02:57<06:18,  1.98s/it]predicting train subjects:  29%|██▊       | 76/266 [02:59<06:10,  1.95s/it]predicting train subjects:  29%|██▉       | 77/266 [03:01<06:05,  1.94s/it]predicting train subjects:  29%|██▉       | 78/266 [03:04<06:43,  2.15s/it]predicting train subjects:  30%|██▉       | 79/266 [03:06<07:03,  2.26s/it]predicting train subjects:  30%|███       | 80/266 [03:09<07:23,  2.38s/it]predicting train subjects:  30%|███       | 81/266 [03:11<07:33,  2.45s/it]predicting train subjects:  31%|███       | 82/266 [03:14<07:35,  2.48s/it]predicting train subjects:  31%|███       | 83/266 [03:17<07:43,  2.53s/it]predicting train subjects:  32%|███▏      | 84/266 [03:19<07:42,  2.54s/it]predicting train subjects:  32%|███▏      | 85/266 [03:22<07:47,  2.58s/it]predicting train subjects:  32%|███▏      | 86/266 [03:25<07:46,  2.59s/it]predicting train subjects:  33%|███▎      | 87/266 [03:27<07:40,  2.57s/it]predicting train subjects:  33%|███▎      | 88/266 [03:30<07:36,  2.56s/it]predicting train subjects:  33%|███▎      | 89/266 [03:32<07:33,  2.56s/it]predicting train subjects:  34%|███▍      | 90/266 [03:35<07:27,  2.54s/it]predicting train subjects:  34%|███▍      | 91/266 [03:37<07:25,  2.55s/it]predicting train subjects:  35%|███▍      | 92/266 [03:40<07:21,  2.54s/it]predicting train subjects:  35%|███▍      | 93/266 [03:42<07:23,  2.57s/it]predicting train subjects:  35%|███▌      | 94/266 [03:45<07:17,  2.55s/it]predicting train subjects:  36%|███▌      | 95/266 [03:47<07:15,  2.55s/it]predicting train subjects:  36%|███▌      | 96/266 [03:50<06:56,  2.45s/it]predicting train subjects:  36%|███▋      | 97/266 [03:52<07:00,  2.49s/it]predicting train subjects:  37%|███▋      | 98/266 [03:55<06:58,  2.49s/it]predicting train subjects:  37%|███▋      | 99/266 [03:56<06:19,  2.27s/it]predicting train subjects:  38%|███▊      | 100/266 [03:58<06:02,  2.18s/it]predicting train subjects:  38%|███▊      | 101/266 [04:01<06:06,  2.22s/it]predicting train subjects:  38%|███▊      | 102/266 [04:03<06:02,  2.21s/it]predicting train subjects:  39%|███▊      | 103/266 [04:05<06:03,  2.23s/it]predicting train subjects:  39%|███▉      | 104/266 [04:08<06:09,  2.28s/it]predicting train subjects:  39%|███▉      | 105/266 [04:10<06:10,  2.30s/it]predicting train subjects:  40%|███▉      | 106/266 [04:12<06:08,  2.30s/it]predicting train subjects:  40%|████      | 107/266 [04:15<06:05,  2.30s/it]predicting train subjects:  41%|████      | 108/266 [04:17<05:59,  2.28s/it]predicting train subjects:  41%|████      | 109/266 [04:19<06:04,  2.32s/it]predicting train subjects:  41%|████▏     | 110/266 [04:21<05:59,  2.31s/it]predicting train subjects:  42%|████▏     | 111/266 [04:24<05:59,  2.32s/it]predicting train subjects:  42%|████▏     | 112/266 [04:26<06:00,  2.34s/it]predicting train subjects:  42%|████▏     | 113/266 [04:29<06:04,  2.38s/it]predicting train subjects:  43%|████▎     | 114/266 [04:31<05:58,  2.36s/it]predicting train subjects:  43%|████▎     | 115/266 [04:33<05:52,  2.34s/it]predicting train subjects:  44%|████▎     | 116/266 [04:36<05:49,  2.33s/it]predicting train subjects:  44%|████▍     | 117/266 [04:38<05:46,  2.32s/it]predicting train subjects:  44%|████▍     | 118/266 [04:40<05:49,  2.36s/it]predicting train subjects:  45%|████▍     | 119/266 [04:43<05:57,  2.43s/it]predicting train subjects:  45%|████▌     | 120/266 [04:46<06:07,  2.51s/it]predicting train subjects:  45%|████▌     | 121/266 [04:48<06:18,  2.61s/it]predicting train subjects:  46%|████▌     | 122/266 [04:51<06:16,  2.62s/it]predicting train subjects:  46%|████▌     | 123/266 [04:54<06:27,  2.71s/it]predicting train subjects:  47%|████▋     | 124/266 [04:57<06:29,  2.74s/it]predicting train subjects:  47%|████▋     | 125/266 [05:00<06:39,  2.83s/it]predicting train subjects:  47%|████▋     | 126/266 [05:03<06:33,  2.81s/it]predicting train subjects:  48%|████▊     | 127/266 [05:05<06:25,  2.78s/it]predicting train subjects:  48%|████▊     | 128/266 [05:08<06:21,  2.77s/it]predicting train subjects:  48%|████▊     | 129/266 [05:11<06:16,  2.75s/it]predicting train subjects:  49%|████▉     | 130/266 [05:14<06:16,  2.77s/it]predicting train subjects:  49%|████▉     | 131/266 [05:16<06:11,  2.76s/it]predicting train subjects:  50%|████▉     | 132/266 [05:19<06:11,  2.77s/it]predicting train subjects:  50%|█████     | 133/266 [05:22<06:07,  2.76s/it]predicting train subjects:  50%|█████     | 134/266 [05:25<06:00,  2.73s/it]predicting train subjects:  51%|█████     | 135/266 [05:27<06:05,  2.79s/it]predicting train subjects:  51%|█████     | 136/266 [05:31<06:13,  2.87s/it]predicting train subjects:  52%|█████▏    | 137/266 [05:33<06:02,  2.81s/it]predicting train subjects:  52%|█████▏    | 138/266 [05:36<05:54,  2.77s/it]predicting train subjects:  52%|█████▏    | 139/266 [05:39<05:51,  2.77s/it]predicting train subjects:  53%|█████▎    | 140/266 [05:41<05:45,  2.74s/it]predicting train subjects:  53%|█████▎    | 141/266 [05:44<05:38,  2.71s/it]predicting train subjects:  53%|█████▎    | 142/266 [05:47<05:35,  2.71s/it]predicting train subjects:  54%|█████▍    | 143/266 [05:49<05:36,  2.74s/it]predicting train subjects:  54%|█████▍    | 144/266 [05:52<05:26,  2.68s/it]predicting train subjects:  55%|█████▍    | 145/266 [05:55<05:24,  2.68s/it]predicting train subjects:  55%|█████▍    | 146/266 [05:58<05:26,  2.72s/it]predicting train subjects:  55%|█████▌    | 147/266 [06:00<05:20,  2.69s/it]predicting train subjects:  56%|█████▌    | 148/266 [06:03<05:16,  2.68s/it]predicting train subjects:  56%|█████▌    | 149/266 [06:06<05:16,  2.70s/it]predicting train subjects:  56%|█████▋    | 150/266 [06:08<05:10,  2.68s/it]predicting train subjects:  57%|█████▋    | 151/266 [06:11<05:05,  2.66s/it]predicting train subjects:  57%|█████▋    | 152/266 [06:14<05:05,  2.68s/it]predicting train subjects:  58%|█████▊    | 153/266 [06:16<05:00,  2.66s/it]predicting train subjects:  58%|█████▊    | 154/266 [06:19<05:03,  2.71s/it]predicting train subjects:  58%|█████▊    | 155/266 [06:21<04:47,  2.59s/it]predicting train subjects:  59%|█████▊    | 156/266 [06:23<04:29,  2.45s/it]predicting train subjects:  59%|█████▉    | 157/266 [06:25<04:13,  2.32s/it]predicting train subjects:  59%|█████▉    | 158/266 [06:28<04:04,  2.26s/it]predicting train subjects:  60%|█████▉    | 159/266 [06:29<03:51,  2.17s/it]predicting train subjects:  60%|██████    | 160/266 [06:31<03:43,  2.11s/it]predicting train subjects:  61%|██████    | 161/266 [06:33<03:37,  2.07s/it]predicting train subjects:  61%|██████    | 162/266 [06:35<03:31,  2.03s/it]predicting train subjects:  61%|██████▏   | 163/266 [06:37<03:31,  2.05s/it]predicting train subjects:  62%|██████▏   | 164/266 [06:40<03:31,  2.08s/it]predicting train subjects:  62%|██████▏   | 165/266 [06:42<03:25,  2.04s/it]predicting train subjects:  62%|██████▏   | 166/266 [06:44<03:22,  2.03s/it]predicting train subjects:  63%|██████▎   | 167/266 [06:46<03:20,  2.02s/it]predicting train subjects:  63%|██████▎   | 168/266 [06:48<03:16,  2.00s/it]predicting train subjects:  64%|██████▎   | 169/266 [06:49<03:11,  1.97s/it]predicting train subjects:  64%|██████▍   | 170/266 [06:51<03:09,  1.97s/it]predicting train subjects:  64%|██████▍   | 171/266 [06:53<03:07,  1.97s/it]predicting train subjects:  65%|██████▍   | 172/266 [06:55<03:01,  1.93s/it]predicting train subjects:  65%|██████▌   | 173/266 [06:57<03:05,  1.99s/it]predicting train subjects:  65%|██████▌   | 174/266 [07:00<03:10,  2.07s/it]predicting train subjects:  66%|██████▌   | 175/266 [07:02<03:12,  2.11s/it]predicting train subjects:  66%|██████▌   | 176/266 [07:04<03:10,  2.12s/it]predicting train subjects:  67%|██████▋   | 177/266 [07:06<03:10,  2.14s/it]predicting train subjects:  67%|██████▋   | 178/266 [07:08<03:09,  2.15s/it]predicting train subjects:  67%|██████▋   | 179/266 [07:11<03:09,  2.18s/it]predicting train subjects:  68%|██████▊   | 180/266 [07:13<03:11,  2.23s/it]predicting train subjects:  68%|██████▊   | 181/266 [07:15<03:09,  2.23s/it]predicting train subjects:  68%|██████▊   | 182/266 [07:18<03:13,  2.30s/it]predicting train subjects:  69%|██████▉   | 183/266 [07:20<03:06,  2.25s/it]predicting train subjects:  69%|██████▉   | 184/266 [07:22<03:02,  2.22s/it]predicting train subjects:  70%|██████▉   | 185/266 [07:24<02:59,  2.21s/it]predicting train subjects:  70%|██████▉   | 186/266 [07:26<02:57,  2.22s/it]predicting train subjects:  70%|███████   | 187/266 [07:28<02:54,  2.20s/it]predicting train subjects:  71%|███████   | 188/266 [07:31<02:51,  2.20s/it]predicting train subjects:  71%|███████   | 189/266 [07:33<02:48,  2.19s/it]predicting train subjects:  71%|███████▏  | 190/266 [07:35<02:46,  2.19s/it]predicting train subjects:  72%|███████▏  | 191/266 [07:37<02:47,  2.23s/it]predicting train subjects:  72%|███████▏  | 192/266 [07:39<02:42,  2.20s/it]predicting train subjects:  73%|███████▎  | 193/266 [07:42<02:40,  2.19s/it]predicting train subjects:  73%|███████▎  | 194/266 [07:44<02:46,  2.32s/it]predicting train subjects:  73%|███████▎  | 195/266 [07:47<02:47,  2.36s/it]predicting train subjects:  74%|███████▎  | 196/266 [07:49<02:41,  2.31s/it]predicting train subjects:  74%|███████▍  | 197/266 [07:51<02:35,  2.25s/it]predicting train subjects:  74%|███████▍  | 198/266 [07:53<02:29,  2.20s/it]predicting train subjects:  75%|███████▍  | 199/266 [07:55<02:26,  2.19s/it]predicting train subjects:  75%|███████▌  | 200/266 [07:57<02:21,  2.15s/it]predicting train subjects:  76%|███████▌  | 201/266 [07:59<02:19,  2.14s/it]predicting train subjects:  76%|███████▌  | 202/266 [08:02<02:16,  2.14s/it]predicting train subjects:  76%|███████▋  | 203/266 [08:04<02:14,  2.14s/it]predicting train subjects:  77%|███████▋  | 204/266 [08:06<02:11,  2.13s/it]predicting train subjects:  77%|███████▋  | 205/266 [08:08<02:08,  2.11s/it]predicting train subjects:  77%|███████▋  | 206/266 [08:10<02:06,  2.11s/it]predicting train subjects:  78%|███████▊  | 207/266 [08:12<02:06,  2.14s/it]predicting train subjects:  78%|███████▊  | 208/266 [08:14<02:04,  2.15s/it]predicting train subjects:  79%|███████▊  | 209/266 [08:17<02:03,  2.16s/it]predicting train subjects:  79%|███████▉  | 210/266 [08:19<02:00,  2.15s/it]predicting train subjects:  79%|███████▉  | 211/266 [08:21<01:57,  2.13s/it]predicting train subjects:  80%|███████▉  | 212/266 [08:23<01:55,  2.14s/it]predicting train subjects:  80%|████████  | 213/266 [08:25<01:50,  2.08s/it]predicting train subjects:  80%|████████  | 214/266 [08:27<01:45,  2.02s/it]predicting train subjects:  81%|████████  | 215/266 [08:29<01:42,  2.01s/it]predicting train subjects:  81%|████████  | 216/266 [08:31<01:40,  2.01s/it]predicting train subjects:  82%|████████▏ | 217/266 [08:33<01:36,  1.97s/it]predicting train subjects:  82%|████████▏ | 218/266 [08:35<01:32,  1.93s/it]predicting train subjects:  82%|████████▏ | 219/266 [08:36<01:30,  1.92s/it]predicting train subjects:  83%|████████▎ | 220/266 [08:38<01:27,  1.89s/it]predicting train subjects:  83%|████████▎ | 221/266 [08:40<01:25,  1.89s/it]predicting train subjects:  83%|████████▎ | 222/266 [08:42<01:22,  1.87s/it]predicting train subjects:  84%|████████▍ | 223/266 [08:44<01:20,  1.86s/it]predicting train subjects:  84%|████████▍ | 224/266 [08:46<01:16,  1.83s/it]predicting train subjects:  85%|████████▍ | 225/266 [08:47<01:15,  1.85s/it]predicting train subjects:  85%|████████▍ | 226/266 [08:49<01:14,  1.85s/it]predicting train subjects:  85%|████████▌ | 227/266 [08:51<01:11,  1.84s/it]predicting train subjects:  86%|████████▌ | 228/266 [08:53<01:09,  1.84s/it]predicting train subjects:  86%|████████▌ | 229/266 [08:55<01:07,  1.84s/it]predicting train subjects:  86%|████████▋ | 230/266 [08:57<01:06,  1.85s/it]predicting train subjects:  87%|████████▋ | 231/266 [08:59<01:05,  1.87s/it]predicting train subjects:  87%|████████▋ | 232/266 [09:00<01:03,  1.87s/it]predicting train subjects:  88%|████████▊ | 233/266 [09:02<01:02,  1.88s/it]predicting train subjects:  88%|████████▊ | 234/266 [09:04<01:00,  1.88s/it]predicting train subjects:  88%|████████▊ | 235/266 [09:06<00:58,  1.90s/it]predicting train subjects:  89%|████████▊ | 236/266 [09:08<00:57,  1.91s/it]predicting train subjects:  89%|████████▉ | 237/266 [09:10<00:55,  1.91s/it]predicting train subjects:  89%|████████▉ | 238/266 [09:12<00:53,  1.90s/it]predicting train subjects:  90%|████████▉ | 239/266 [09:14<00:51,  1.91s/it]predicting train subjects:  90%|█████████ | 240/266 [09:16<00:49,  1.91s/it]predicting train subjects:  91%|█████████ | 241/266 [09:18<00:47,  1.91s/it]predicting train subjects:  91%|█████████ | 242/266 [09:20<00:45,  1.91s/it]predicting train subjects:  91%|█████████▏| 243/266 [09:21<00:44,  1.92s/it]predicting train subjects:  92%|█████████▏| 244/266 [09:23<00:42,  1.92s/it]predicting train subjects:  92%|█████████▏| 245/266 [09:25<00:39,  1.90s/it]predicting train subjects:  92%|█████████▏| 246/266 [09:27<00:38,  1.90s/it]predicting train subjects:  93%|█████████▎| 247/266 [09:29<00:36,  1.91s/it]predicting train subjects:  93%|█████████▎| 248/266 [09:31<00:34,  1.90s/it]predicting train subjects:  94%|█████████▎| 249/266 [09:33<00:34,  2.04s/it]predicting train subjects:  94%|█████████▍| 250/266 [09:36<00:34,  2.16s/it]predicting train subjects:  94%|█████████▍| 251/266 [09:38<00:33,  2.25s/it]predicting train subjects:  95%|█████████▍| 252/266 [09:41<00:32,  2.30s/it]predicting train subjects:  95%|█████████▌| 253/266 [09:43<00:30,  2.35s/it]predicting train subjects:  95%|█████████▌| 254/266 [09:46<00:28,  2.38s/it]predicting train subjects:  96%|█████████▌| 255/266 [09:48<00:26,  2.39s/it]predicting train subjects:  96%|█████████▌| 256/266 [09:50<00:24,  2.41s/it]predicting train subjects:  97%|█████████▋| 257/266 [09:53<00:21,  2.42s/it]predicting train subjects:  97%|█████████▋| 258/266 [09:55<00:19,  2.41s/it]predicting train subjects:  97%|█████████▋| 259/266 [09:58<00:16,  2.42s/it]predicting train subjects:  98%|█████████▊| 260/266 [10:00<00:14,  2.45s/it]predicting train subjects:  98%|█████████▊| 261/266 [10:03<00:12,  2.45s/it]predicting train subjects:  98%|█████████▊| 262/266 [10:05<00:09,  2.46s/it]predicting train subjects:  99%|█████████▉| 263/266 [10:08<00:07,  2.44s/it]predicting train subjects:  99%|█████████▉| 264/266 [10:10<00:04,  2.44s/it]predicting train subjects: 100%|█████████▉| 265/266 [10:12<00:02,  2.43s/it]predicting train subjects: 100%|██████████| 266/266 [10:15<00:00,  2.43s/it]

