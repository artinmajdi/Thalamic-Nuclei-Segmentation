2019-07-23 14:39:10.857272: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-23 14:39:13.684569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:04:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2019-07-23 14:39:14.026753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 1 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:89:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2019-07-23 14:39:14.028273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0, 1
2019-07-23 14:39:14.959871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-23 14:39:14.961598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 1 
2019-07-23 14:39:14.963512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N N 
2019-07-23 14:39:14.964910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 1:   N N 
2019-07-23 14:39:14.967518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)
2019-07-23 14:39:14.970717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 15123 MB memory) -> physical GPU (device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:89:00.0, compute capability: 6.0)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using TensorFlow backend.
Loading train:   0%|          | 0/533 [00:00<?, ?it/s]Loading train:   0%|          | 1/533 [00:12<1:47:23, 12.11s/it]---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 0,7  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  normal |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 0,7  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  normal |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_normal_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_Main_Ps_ET_Init_3T_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 0,7  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  normal |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_normal_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_Main_Ps_ET_Init_3T_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 0,7  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  normal |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_normal_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_Main_Ps_ET_Init_3T_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0,7  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  normal |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0,7  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  normal |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_normal_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_Main_Ps_ET_Init_3T_CV_a
---------------------------------------------------------------
Traceback (most recent call last):
  File "main.py", line 1368, in <module>
    EXP27a3_Resnet2_LogDice_fineTune_ET_Ps_Main(UserInfoB)
  File "main.py", line 1201, in EXP27a3_Resnet2_LogDice_fineTune_ET_Ps_Main
    Run(UserInfoB, IV)
  File "main.py", line 220, in Run
    else: Loop_Over_Nuclei(UserInfoB)
  File "main.py", line 102, in Loop_Over_Nuclei
    if UserI['simulation'].nucleus_Index and (not check_if_num_Layers_fit(UserI)): Run_Main(UserI)
  File "main.py", line 214, in Run_Main
    Loop_slicing_orientations(UserInfoB, InitValues)
  File "main.py", line 212, in Loop_slicing_orientations
    subRun(UserInfoB)
  File "main.py", line 206, in subRun
    else: normal_run(params)
  File "main.py", line 192, in normal_run
    Data, params = datasets.loadDataset(params)                             
  File "/array/ssd/msmajdi/code/thalamus/keras/otherFuncs/datasets.py", line 384, in loadDataset
    Data = main_ReadingDataset(params)
  File "/array/ssd/msmajdi/code/thalamus/keras/otherFuncs/datasets.py", line 364, in main_ReadingDataset
    DataAll.Train_ForTest = readingAllSubjects(params.directories.Train.Input.Subjects, 'train')
  File "/array/ssd/msmajdi/code/thalamus/keras/otherFuncs/datasets.py", line 329, in readingAllSubjects
    origMsk , msk = readingNuclei(params, subject, imF.shape)
  File "/array/ssd/msmajdi/code/thalamus/keras/otherFuncs/datasets.py", line 191, in readingNuclei
    msk1N = inputPreparationForUnet(msk1N, subject, params)
  File "/array/ssd/msmajdi/code/thalamus/keras/otherFuncs/datasets.py", line 98, in inputPreparationForUnet
    im = np.expand_dims(im ,axis=3).astype('float32')
KeyboardInterrupt
Exception ignored in: <bound method tqdm.__del__ of Loading train:   0%|          | 1/533 [00:17<1:47:23, 12.11s/it]>
Traceback (most recent call last):
  File "/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/tqdm/_tqdm.py", line 931, in __del__
    self.close()
  File "/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/tqdm/_tqdm.py", line 1133, in close
    self._decr_instances(self)
  File "/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/tqdm/_tqdm.py", line 496, in _decr_instances
    cls.monitor.exit()
  File "/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/tqdm/_monitor.py", line 52, in exit
    self.join()
  File "/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/threading.py", line 1053, in join
    raise RuntimeError("cannot join current thread")
RuntimeError: cannot join current thread
2019-07-23 15:04:19.448224: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-23 15:04:21.965730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:04:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2019-07-23 15:04:22.245120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 1 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:89:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2019-07-23 15:04:22.245219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0, 1
2019-07-23 15:04:23.496362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-23 15:04:23.496414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 1 
2019-07-23 15:04:23.496427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N N 
2019-07-23 15:04:23.496436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 1:   N N 
2019-07-23 15:04:23.497294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)
2019-07-23 15:04:23.498464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 15123 MB memory) -> physical GPU (device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:89:00.0, compute capability: 6.0)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using TensorFlow backend.
Loading train:   0%|          | 0/533 [00:00<?, ?it/s]Loading train:   0%|          | 1/533 [00:02<21:09,  2.39s/it]Loading train:   0%|          | 2/533 [00:04<19:14,  2.17s/it]Loading train:   1%|          | 3/533 [00:05<17:32,  1.99s/it]Loading train:   1%|          | 4/533 [00:07<16:18,  1.85s/it]Loading train:   1%|          | 5/533 [00:09<17:02,  1.94s/it]Loading train:   1%|          | 6/533 [00:10<16:20,  1.86s/it]Loading train:   1%|▏         | 7/533 [00:18<32:21,  3.69s/it]Loading train:   2%|▏         | 8/533 [00:20<27:25,  3.13s/it]Loading train:   2%|▏         | 9/533 [00:22<24:40,  2.82s/it]Loading train:   2%|▏         | 10/533 [00:24<22:30,  2.58s/it]Loading train:   2%|▏         | 11/533 [00:26<20:59,  2.41s/it]Loading train:   2%|▏         | 12/533 [00:28<18:32,  2.14s/it]Loading train:   2%|▏         | 13/533 [00:30<17:50,  2.06s/it]Loading train:   3%|▎         | 14/533 [00:32<17:45,  2.05s/it]Loading train:   3%|▎         | 15/533 [00:34<17:28,  2.02s/it]Loading train:   3%|▎         | 16/533 [00:36<17:44,  2.06s/it]Loading train:   3%|▎         | 17/533 [00:39<20:31,  2.39s/it]Loading train:   3%|▎         | 18/533 [00:42<22:13,  2.59s/it]---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 0,7  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  normal |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 0,7  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  normal |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_normal_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_Main_Ps_ET_Init_3T_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 0,7  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  normal |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_normal_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_Main_Ps_ET_Init_3T_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 0,7  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  normal |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_normal_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_Main_Ps_ET_Init_3T_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0,7  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  normal |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0,7  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  normal |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_normal_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_Main_Ps_ET_Init_3T_CV_a
---------------------------------------------------------------
Traceback (most recent call last):
  File "main.py", line 1369, in <module>
    EXP27a3_Resnet2_LogDice_fineTune_ET_Ps_Main(UserInfoB)
  File "main.py", line 1202, in EXP27a3_Resnet2_LogDice_fineTune_ET_Ps_Main
    Run(UserInfoB, IV)
  File "main.py", line 220, in Run
    else: Loop_Over_Nuclei(UserInfoB)
  File "main.py", line 102, in Loop_Over_Nuclei
    if UserI['simulation'].nucleus_Index and (not check_if_num_Layers_fit(UserI)): Run_Main(UserI)
  File "main.py", line 214, in Run_Main
    Loop_slicing_orientations(UserInfoB, InitValues)
  File "main.py", line 212, in Loop_slicing_orientations
    subRun(UserInfoB)
  File "main.py", line 206, in subRun
    else: normal_run(params)
  File "main.py", line 192, in normal_run
    Data, params = datasets.loadDataset(params)                             
  File "/array/ssd/msmajdi/code/thalamus/keras/otherFuncs/datasets.py", line 384, in loadDataset
    Data = main_ReadingDataset(params)
  File "/array/ssd/msmajdi/code/thalamus/keras/otherFuncs/datasets.py", line 364, in main_ReadingDataset
    DataAll.Train_ForTest = readingAllSubjects(params.directories.Train.Input.Subjects, 'train')
  File "/array/ssd/msmajdi/code/thalamus/keras/otherFuncs/datasets.py", line 336, in readingAllSubjects
    im, msk = upsample_Image(im, msk , scale)    
  File "/array/ssd/msmajdi/code/thalamus/keras/otherFuncs/datasets.py", line 315, in upsample_Image
    Image3[i ,: ,: ,ch] = warp( np.squeeze(Image[i ,: ,: ,ch]), tform.inverse, output_shape=newShape, order=3)
  File "/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/skimage/transform/_warps.py", line 846, in warp
    order=order, mode=mode, cval=cval)
  File "skimage/transform/_warps_cy.pyx", line 131, in skimage.transform._warps_cy._warp_fast
  File "/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/numpy/core/numeric.py", line 433, in asarray
    def asarray(a, dtype=None, order=None):
KeyboardInterrupt
Exception ignored in: <bound method tqdm.__del__ of Loading train:   3%|▎         | 18/533 [00:44<22:13,  2.59s/it]>
Traceback (most recent call last):
  File "/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/tqdm/_tqdm.py", line 931, in __del__
    self.close()
  File "/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/tqdm/_tqdm.py", line 1133, in close
    self._decr_instances(self)
  File "/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/tqdm/_tqdm.py", line 496, in _decr_instances
    cls.monitor.exit()
  File "/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/tqdm/_monitor.py", line 52, in exit
    self.join()
  File "/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/threading.py", line 1053, in join
    raise RuntimeError("cannot join current thread")
RuntimeError: cannot join current thread
