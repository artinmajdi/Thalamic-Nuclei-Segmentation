2020-01-28 15:57:15.721177: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-01-28 15:57:22.507698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:04:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2020-01-28 15:57:22.507766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-28 15:57:22.955678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-28 15:57:22.955742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-28 15:57:22.955754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-28 15:57:22.956230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=DeprecationWarning)
Loading test:   0%|          | 0/11 [00:00<?, ?it/s]Loading test:   9%|▉         | 1/11 [00:30<05:05, 30.56s/it]Loading test:  18%|█▊        | 2/11 [01:09<04:58, 33.19s/it]Loading test:  27%|██▋       | 3/11 [01:51<04:45, 35.72s/it]Loading test:  36%|███▋      | 4/11 [02:29<04:14, 36.30s/it]Loading test:  45%|████▌     | 5/11 [03:07<03:40, 36.80s/it]Loading test:  55%|█████▍    | 6/11 [03:45<03:06, 37.22s/it]Loading test:  64%|██████▎   | 7/11 [04:22<02:29, 37.34s/it]Loading test:  73%|███████▎  | 8/11 [04:45<01:38, 32.87s/it]Loading test:  82%|████████▏ | 9/11 [05:13<01:02, 31.47s/it]Loading test:  91%|█████████ | 10/11 [05:38<00:29, 29.46s/it]Loading test: 100%|██████████| 11/11 [06:10<00:00, 30.40s/it]Loading test: 100%|██████████| 11/11 [06:10<00:00, 33.72s/it]
concatenating: validation:   0%|          | 0/11 [00:00<?, ?it/s]concatenating: validation:   9%|▉         | 1/11 [00:00<00:05,  1.81it/s]concatenating: validation:  18%|█▊        | 2/11 [00:01<00:05,  1.79it/s]concatenating: validation:  27%|██▋       | 3/11 [00:01<00:04,  1.78it/s]concatenating: validation:  36%|███▋      | 4/11 [00:02<00:03,  1.79it/s]concatenating: validation:  45%|████▌     | 5/11 [00:02<00:03,  1.79it/s]concatenating: validation:  55%|█████▍    | 6/11 [00:03<00:02,  1.80it/s]concatenating: validation:  64%|██████▎   | 7/11 [00:03<00:02,  1.80it/s]concatenating: validation:  73%|███████▎  | 8/11 [00:04<00:01,  1.81it/s]concatenating: validation:  82%|████████▏ | 9/11 [00:04<00:01,  1.82it/s]concatenating: validation:  91%|█████████ | 10/11 [00:05<00:00,  1.83it/s]concatenating: validation: 100%|██████████| 11/11 [00:06<00:00,  1.84it/s]concatenating: validation: 100%|██████████| 11/11 [00:06<00:00,  1.81it/s]
Loading testS:   0%|          | 0/11 [00:00<?, ?it/s]Loading testS:   9%|▉         | 1/11 [00:36<06:02, 36.29s/it]Loading testS:  18%|█▊        | 2/11 [01:13<05:27, 36.44s/it]Loading testS:  27%|██▋       | 3/11 [01:49<04:52, 36.57s/it]Loading testS:  36%|███▋      | 4/11 [02:27<04:17, 36.82s/it]Loading testS:  45%|████▌     | 5/11 [03:05<03:42, 37.14s/it]Loading testS:  55%|█████▍    | 6/11 [03:42<03:06, 37.24s/it]Loading testS:  64%|██████▎   | 7/11 [04:20<02:29, 37.43s/it]Loading testS:  73%|███████▎  | 8/11 [04:58<01:52, 37.58s/it]Loading testS:  82%|████████▏ | 9/11 [05:37<01:16, 38.05s/it]Loading testS:  91%|█████████ | 10/11 [06:16<00:38, 38.31s/it]Loading testS: 100%|██████████| 11/11 [06:55<00:00, 38.57s/it]Loading testS: 100%|██████████| 11/11 [06:55<00:00, 37.80s/it]----------+++ 
CrossVal ['a']
CrossVal ['a']
(0/11) test vimp2_ctrl_991_08302013_JF
(1/11) test vimp2_967_08132013_KW
(2/11) test vimp2_ANON695_03132013
(3/11) test vimp2_A_3T_ET
(4/11) test vimp2_A_7T_ET
(5/11) test vimp2_G_3T_ET
(6/11) test vimp2_G_7T_ET
(7/11) test vimp2_J_3T_ET
(8/11) test vimp2_J_7T_ET
(9/11) test vimp2_M_3T_ET
(10/11) test vimp2_M_7T_ET
---
---
---
---
---
---
---
---
---
---
---
---
---
---
---
---
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 0  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 0  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6_uncropped
SubExperiment: sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a
---------------------------------------------------------------
---
---
---
---
---
---
---
---
---
---
---
---
---
---
---
---
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 256, 440, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 256, 440, 20) 200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 256, 440, 20) 80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 256, 440, 20) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 256, 440, 20) 3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 256, 440, 20) 80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 256, 440, 20) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 128, 220, 20) 0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 128, 220, 20) 0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 128, 220, 40) 7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 128, 220, 40) 160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 128, 220, 40) 0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 128, 220, 40) 14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 128, 220, 40) 160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 128, 220, 40) 0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 128, 220, 60) 0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 64, 110, 60)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 64, 110, 60)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 64, 110, 80)  43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 64, 110, 80)  320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 64, 110, 80)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 64, 110, 80)  57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 64, 110, 80)  320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64, 110, 80)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 110, 140) 0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 64, 110, 140) 0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 128, 220, 40) 22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 128, 220, 100 0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 128, 220, 40) 36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 128, 220, 40) 160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 128, 220, 40) 0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 128, 220, 40) 14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 128, 220, 40) 160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 128, 220, 40) 0           batch_normalization_8[0][0]      
predicting test subjects:   0%|          | 0/11 [00:00<?, ?it/s]predicting test subjects:   9%|▉         | 1/11 [00:10<01:45, 10.58s/it]predicting test subjects:  18%|█▊        | 2/11 [00:19<01:30, 10.05s/it]predicting test subjects:  27%|██▋       | 3/11 [00:27<01:15,  9.43s/it]predicting test subjects:  36%|███▋      | 4/11 [00:35<01:04,  9.14s/it]predicting test subjects:  45%|████▌     | 5/11 [00:44<00:53,  8.96s/it]predicting test subjects:  55%|█████▍    | 6/11 [00:52<00:44,  8.84s/it]predicting test subjects:  64%|██████▎   | 7/11 [01:01<00:34,  8.73s/it]predicting test subjects:  73%|███████▎  | 8/11 [01:09<00:25,  8.62s/it]predicting test subjects:  82%|████████▏ | 9/11 [01:18<00:17,  8.59s/it]predicting test subjects:  91%|█████████ | 10/11 [01:31<00:10, 10.09s/it]predicting test subjects: 100%|██████████| 11/11 [01:45<00:00, 11.23s/it]predicting test subjects: 100%|██████████| 11/11 [01:45<00:00,  9.62s/it]
predicting train subjects: 0it [00:00, ?it/s]predicting train subjects: 0it [00:00, ?it/s]
predicting test subjects sagittal:   0%|          | 0/11 [00:00<?, ?it/s]predicting test subjects sagittal:   9%|▉         | 1/11 [00:13<02:10, 13.03s/it]predicting test subjects sagittal:  18%|█▊        | 2/11 [00:22<01:47, 11.93s/it]predicting test subjects sagittal:  27%|██▋       | 3/11 [00:30<01:27, 10.92s/it]predicting test subjects sagittal:  36%|███▋      | 4/11 [00:39<01:11, 10.19s/it]predicting test subjects sagittal:  45%|████▌     | 5/11 [00:47<00:58,  9.69s/it]predicting test subjects sagittal:  55%|█████▍    | 6/11 [00:56<00:46,  9.38s/it]predicting test subjects sagittal:  64%|██████▎   | 7/11 [01:04<00:36,  9.06s/it]predicting test subjects sagittal:  73%|███████▎  | 8/11 [01:13<00:26,  8.88s/it]predicting test subjects sagittal:  82%|████████▏ | 9/11 [01:21<00:17,  8.77s/it]predicting test subjects sagittal:  91%|█████████ | 10/11 [01:30<00:08,  8.67s/it]predicting test subjects sagittal: 100%|██████████| 11/11 [01:38<00:00,  8.59s/it]predicting test subjects sagittal: 100%|██████████| 11/11 [01:38<00:00,  8.98s/it]
predicting train subjects sagittal: 0it [00:00, ?it/s]predicting train subjects sagittal: 0it [00:00, ?it/s]
saving BB  test1-THALAMUS:   0%|          | 0/11 [00:00<?, ?it/s]saving BB  test1-THALAMUS:   9%|▉         | 1/11 [00:06<01:03,  6.33s/it]saving BB  test1-THALAMUS:  18%|█▊        | 2/11 [00:12<00:57,  6.39s/it]saving BB  test1-THALAMUS:  27%|██▋       | 3/11 [00:19<00:51,  6.38s/it]saving BB  test1-THALAMUS:  36%|███▋      | 4/11 [00:26<00:45,  6.54s/it]saving BB  test1-THALAMUS:  45%|████▌     | 5/11 [00:32<00:39,  6.64s/it]saving BB  test1-THALAMUS:  55%|█████▍    | 6/11 [00:36<00:28,  5.64s/it]saving BB  test1-THALAMUS:  64%|██████▎   | 7/11 [00:42<00:22,  5.71s/it]saving BB  test1-THALAMUS:  73%|███████▎  | 8/11 [00:49<00:18,  6.09s/it]saving BB  test1-THALAMUS:  82%|████████▏ | 9/11 [00:55<00:12,  6.23s/it]saving BB  test1-THALAMUS:  91%|█████████ | 10/11 [01:01<00:06,  6.04s/it]saving BB  test1-THALAMUS: 100%|██████████| 11/11 [01:08<00:00,  6.28s/it]saving BB  test1-THALAMUS: 100%|██████████| 11/11 [01:08<00:00,  6.19s/it]
saving BB  test1-THALAMUS Sagittal:   0%|          | 0/11 [00:00<?, ?it/s]saving BB  test1-THALAMUS Sagittal:   9%|▉         | 1/11 [00:04<00:43,  4.40s/it]saving BB  test1-THALAMUS Sagittal:  18%|█▊        | 2/11 [00:09<00:41,  4.60s/it]saving BB  test1-THALAMUS Sagittal:  27%|██▋       | 3/11 [00:15<00:40,  5.07s/it]saving BB  test1-THALAMUS Sagittal:  36%|███▋      | 4/11 [00:22<00:38,  5.47s/it]saving BB  test1-THALAMUS Sagittal:  45%|████▌     | 5/11 [00:28<00:34,  5.79s/it]saving BB  test1-THALAMUS Sagittal:  55%|█████▍    | 6/11 [00:34<00:29,  5.82s/it]saving BB  test1-THALAMUS Sagittal:  64%|██████▎   | 7/11 [00:41<00:24,  6.16s/it]saving BB  test1-THALAMUS Sagittal:  73%|███████▎  | 8/11 [00:47<00:18,  6.19s/it]saving BB  test1-THALAMUS Sagittal:  82%|████████▏ | 9/11 [00:54<00:12,  6.43s/it]saving BB  test1-THALAMUS Sagittal:  91%|█████████ | 10/11 [01:01<00:06,  6.62s/it]saving BB  test1-THALAMUS Sagittal: 100%|██████████| 11/11 [01:09<00:00,  6.81s/it]saving BB  test1-THALAMUS Sagittal: 100%|██████████| 11/11 [01:09<00:00,  6.27s/it]
Loading test:   0%|          | 0/11 [00:00<?, ?it/s]Loading test:   9%|▉         | 1/11 [03:57<39:36, 237.62s/it]Loading test:  18%|█▊        | 2/11 [08:12<36:25, 242.87s/it]Loading test:  27%|██▋       | 3/11 [12:04<31:56, 239.62s/it]Loading test:  36%|███▋      | 4/11 [16:41<29:15, 250.78s/it]Loading test:  45%|████▌     | 5/11 [21:31<26:14, 262.47s/it]Loading test:  55%|█████▍    | 6/11 [26:36<22:55, 275.14s/it]Loading test:  64%|██████▎   | 7/11 [31:51<19:09, 287.36s/it]Loading test:  73%|███████▎  | 8/11 [37:12<14:51, 297.30s/it]Loading test:  82%|████████▏ | 9/11 [42:32<10:08, 304.20s/it]Loading test:  91%|█████████ | 10/11 [47:53<05:09, 309.06s/it]Loading test: 100%|██████████| 11/11 [53:56<00:00, 325.39s/it]Loading test: 100%|██████████| 11/11 [53:56<00:00, 294.24s/it]
concatenating: validation:   0%|          | 0/11 [00:00<?, ?it/s]concatenating: validation:  91%|█████████ | 10/11 [00:00<00:00, 97.96it/s]concatenating: validation: 100%|██████████| 11/11 [00:00<00:00, 98.05it/s]
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 128, 220, 140 0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 128, 220, 140 0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 256, 440, 20) 11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 256, 440, 40) 0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 256, 440, 20) 7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 256, 440, 20) 80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 256, 440, 20) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 256, 440, 20) 3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 256, 440, 20) 80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 256, 440, 20) 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 256, 440, 60) 0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 256, 440, 60) 0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 256, 440, 2)  122         dropout_5[0][0]                  
==================================================================================================
Total params: 223,162
Trainable params: 222,362
Non-trainable params: 800
__________________________________________________________________________________________________
---
---
---
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6_uncropped
SubExperiment: sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a
---------------------------------------------------------------
---
---
---
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 48, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 48, 80, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 48, 80, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 48, 80, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 48, 80, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 48, 80, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 48, 80, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 24, 40, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 40, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 24, 40, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 24, 40, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 24, 40, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 24, 40, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 24, 40, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 24, 40, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 24, 40, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 12, 20, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 20, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 12, 20, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 12, 20, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 12, 20, 80)   0           batch_normalization_5[0][0]      2020-01-28 17:10:59.067884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-28 17:10:59.067968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-28 17:10:59.067980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-28 17:10:59.067987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-28 17:10:59.068287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)

predicting test subjects:   0%|          | 0/11 [00:00<?, ?it/s]predicting test subjects:   9%|▉         | 1/11 [01:05<10:59, 65.91s/it]predicting test subjects:  18%|█▊        | 2/11 [02:31<10:46, 71.85s/it]predicting test subjects:  27%|██▋       | 3/11 [03:41<09:30, 71.29s/it]predicting test subjects:  36%|███▋      | 4/11 [05:00<08:34, 73.50s/it]predicting test subjects:  45%|████▌     | 5/11 [06:15<07:23, 73.99s/it]predicting test subjects:  55%|█████▍    | 6/11 [07:32<06:14, 74.93s/it]predicting test subjects:  64%|██████▎   | 7/11 [08:44<04:55, 73.93s/it]predicting test subjects:  73%|███████▎  | 8/11 [10:46<04:25, 88.37s/it]predicting test subjects:  82%|████████▏ | 9/11 [12:43<03:14, 97.08s/it]predicting test subjects:  91%|█████████ | 10/11 [14:01<01:31, 91.42s/it]predicting test subjects: 100%|██████████| 11/11 [15:14<00:00, 85.87s/it]predicting test subjects: 100%|██████████| 11/11 [15:14<00:00, 83.16s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6_uncropped/results/sE12_Cascade_FM00_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a’: File exists
mkdir: cannot create directory ‘sd0’: File exists
mkdir: cannot create directory ‘sd1’: File exists
mkdir: cannot create directory ‘sd2’: File exists

  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [02:24<24:05, 144.58s/it]
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 12, 20, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 12, 20, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 12, 20, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 12, 20, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 20, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 24, 40, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 24, 40, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 24, 40, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 24, 40, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 24, 40, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 24, 40, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 24, 40, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 24, 40, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 24, 40, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 40, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 48, 80, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 48, 80, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 48, 80, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 48, 80, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 48, 80, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 48, 80, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 48, 80, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 48, 80, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 48, 80, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 48, 80, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 48, 80, 13)   793         dropout_5[0][0]                  
==================================================================================================
Total params: 223,833
Trainable params: 223,033
Non-trainable params: 800
__________________________________________________________________________________________________
CrossVal ['a']
Traceback (most recent call last):
  File "main.py", line 1959, in <module>
    EXP_WMn_test_new_Cases(UserInfoB)
  File "main.py", line 1874, in EXP_WMn_test_new_Cases
    merge_results_and_apply_25D(UserInfoB)
  File "main.py", line 1800, in merge_results_and_apply_25D
    smallFuncs.apply_MajorityVoting(params)
  File "/array/ssd/msmajdi/code/thalamus/keras/otherFuncs/smallFuncs.py", line 784, in apply_MajorityVoting
    pred3Dims = pred if ix == 0 else np.concatenate((pred3Dims,pred),axis=3)
  File "<__array_function__ internals>", line 6, in concatenate
ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 91 and the array at index 1 has size 256
  9%|▉         | 1/11 [02:25<24:13, 145.36s/it]
