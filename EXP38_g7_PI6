2019-08-17 16:59:29.490806: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-08-17 16:59:29.832441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:89:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2019-08-17 16:59:29.832494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-08-17 16:59:30.253160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-17 16:59:30.253222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-08-17 16:59:30.253238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-08-17 16:59:30.253840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:89:00.0, compute capability: 6.0)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using TensorFlow backend.
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:01<05:00,  1.14s/it]Loading train:   1%|          | 2/266 [00:01<04:21,  1.01it/s]Loading train:   1%|          | 3/266 [00:02<03:43,  1.18it/s]Loading train:   2%|▏         | 4/266 [00:03<03:41,  1.19it/s]Loading train:   2%|▏         | 5/266 [00:03<03:38,  1.20it/s]Loading train:   2%|▏         | 6/266 [00:04<03:37,  1.19it/s]Loading train:   3%|▎         | 7/266 [00:05<03:30,  1.23it/s]Loading train:   3%|▎         | 8/266 [00:06<03:43,  1.15it/s]Loading train:   3%|▎         | 9/266 [00:07<03:25,  1.25it/s]Loading train:   4%|▍         | 10/266 [00:08<03:42,  1.15it/s]Loading train:   4%|▍         | 11/266 [00:09<03:40,  1.16it/s]Loading train:   5%|▍         | 12/266 [00:10<03:51,  1.09it/s]Loading train:   5%|▍         | 13/266 [00:10<03:32,  1.19it/s]Loading train:   5%|▌         | 14/266 [00:11<03:13,  1.30it/s]Loading train:   6%|▌         | 15/266 [00:12<03:11,  1.31it/s]Loading train:   6%|▌         | 16/266 [00:13<03:21,  1.24it/s]Loading train:   6%|▋         | 17/266 [00:13<03:06,  1.34it/s]Loading train:   7%|▋         | 18/266 [00:14<02:49,  1.46it/s]Loading train:   7%|▋         | 19/266 [00:15<03:29,  1.18it/s]Loading train:   8%|▊         | 20/266 [00:16<03:52,  1.06it/s]Loading train:   8%|▊         | 21/266 [00:17<03:50,  1.06it/s]Loading train:   8%|▊         | 22/266 [00:18<03:36,  1.13it/s]Loading train:   9%|▊         | 23/266 [00:19<03:51,  1.05it/s]Loading train:   9%|▉         | 24/266 [00:20<03:55,  1.03it/s]Loading train:   9%|▉         | 25/266 [00:21<03:34,  1.12it/s]Loading train:  10%|▉         | 26/266 [00:21<03:29,  1.14it/s]Loading train:  10%|█         | 27/266 [00:23<03:55,  1.01it/s]Loading train:  11%|█         | 28/266 [00:24<04:05,  1.03s/it]Loading train:  11%|█         | 29/266 [00:24<03:38,  1.09it/s]Loading train:  11%|█▏        | 30/266 [00:25<03:42,  1.06it/s]Loading train:  12%|█▏        | 31/266 [00:26<03:37,  1.08it/s]Loading train:  12%|█▏        | 32/266 [00:27<03:32,  1.10it/s]Loading train:  12%|█▏        | 33/266 [00:28<03:54,  1.01s/it]Loading train:  13%|█▎        | 34/266 [00:30<04:01,  1.04s/it]Loading train:  13%|█▎        | 35/266 [00:30<03:46,  1.02it/s]Loading train:  14%|█▎        | 36/266 [00:31<03:50,  1.00s/it]Loading train:  14%|█▍        | 37/266 [00:33<04:28,  1.17s/it]Loading train:  14%|█▍        | 38/266 [00:35<04:50,  1.28s/it]Loading train:  15%|█▍        | 39/266 [00:36<04:52,  1.29s/it]Loading train:  15%|█▌        | 40/266 [00:37<04:51,  1.29s/it]Loading train:  15%|█▌        | 41/266 [00:38<04:43,  1.26s/it]Loading train:  16%|█▌        | 42/266 [00:40<04:49,  1.29s/it]Loading train:  16%|█▌        | 43/266 [00:41<04:33,  1.23s/it]Loading train:  17%|█▋        | 44/266 [00:42<04:44,  1.28s/it]Loading train:  17%|█▋        | 45/266 [00:43<04:20,  1.18s/it]Loading train:  17%|█▋        | 46/266 [00:44<04:24,  1.20s/it]Loading train:  18%|█▊        | 47/266 [00:46<04:32,  1.24s/it]Loading train:  18%|█▊        | 48/266 [00:47<04:32,  1.25s/it]Loading train:  18%|█▊        | 49/266 [00:48<04:01,  1.11s/it]Loading train:  19%|█▉        | 50/266 [00:49<04:32,  1.26s/it]Loading train:  19%|█▉        | 51/266 [00:50<04:06,  1.15s/it]Loading train:  20%|█▉        | 52/266 [00:52<04:11,  1.18s/it]Loading train:  20%|█▉        | 53/266 [00:53<04:30,  1.27s/it]Loading train:  20%|██        | 54/266 [00:54<04:38,  1.31s/it]Loading train:  21%|██        | 55/266 [00:56<04:56,  1.41s/it]Loading train:  21%|██        | 56/266 [00:58<05:12,  1.49s/it]Loading train:  21%|██▏       | 57/266 [00:59<04:40,  1.34s/it]Loading train:  22%|██▏       | 58/266 [01:00<04:21,  1.26s/it]Loading train:  22%|██▏       | 59/266 [01:01<04:17,  1.24s/it]Loading train:  23%|██▎       | 60/266 [01:02<04:27,  1.30s/it]Loading train:  23%|██▎       | 61/266 [01:04<04:42,  1.38s/it]Loading train:  23%|██▎       | 62/266 [01:05<04:22,  1.29s/it]Loading train:  24%|██▎       | 63/266 [01:07<04:57,  1.46s/it]Loading train:  24%|██▍       | 64/266 [01:08<04:46,  1.42s/it]Loading train:  24%|██▍       | 65/266 [01:10<04:35,  1.37s/it]Loading train:  25%|██▍       | 66/266 [01:11<04:33,  1.37s/it]Loading train:  25%|██▌       | 67/266 [01:12<04:19,  1.30s/it]Loading train:  26%|██▌       | 68/266 [01:13<04:03,  1.23s/it]Loading train:  26%|██▌       | 69/266 [01:15<04:13,  1.29s/it]Loading train:  26%|██▋       | 70/266 [01:16<04:07,  1.26s/it]Loading train:  27%|██▋       | 71/266 [01:17<04:12,  1.29s/it]Loading train:  27%|██▋       | 72/266 [01:18<04:13,  1.31s/it]Loading train:  27%|██▋       | 73/266 [01:20<04:13,  1.31s/it]Loading train:  28%|██▊       | 74/266 [01:21<04:16,  1.34s/it]Loading train:  28%|██▊       | 75/266 [01:22<04:11,  1.32s/it]Loading train:  29%|██▊       | 76/266 [01:23<03:51,  1.22s/it]Loading train:  29%|██▉       | 77/266 [01:25<03:46,  1.20s/it]Loading train:  29%|██▉       | 78/266 [01:26<04:05,  1.30s/it]Loading train:  30%|██▉       | 79/266 [01:28<04:17,  1.38s/it]Loading train:  30%|███       | 80/266 [01:29<04:29,  1.45s/it]Loading train:  30%|███       | 81/266 [01:31<04:23,  1.42s/it]Loading train:  31%|███       | 82/266 [01:33<04:47,  1.56s/it]Loading train:  31%|███       | 83/266 [01:34<04:25,  1.45s/it]Loading train:  32%|███▏      | 84/266 [01:35<04:05,  1.35s/it]Loading train:  32%|███▏      | 85/266 [01:36<04:13,  1.40s/it]Loading train:  32%|███▏      | 86/266 [01:38<04:13,  1.41s/it]Loading train:  33%|███▎      | 87/266 [01:39<04:18,  1.44s/it]Loading train:  33%|███▎      | 88/266 [01:40<04:03,  1.37s/it]Loading train:  33%|███▎      | 89/266 [01:42<03:47,  1.28s/it]Loading train:  34%|███▍      | 90/266 [01:43<03:42,  1.26s/it]Loading train:  34%|███▍      | 91/266 [01:44<03:33,  1.22s/it]Loading train:  35%|███▍      | 92/266 [01:45<03:39,  1.26s/it]Loading train:  35%|███▍      | 93/266 [01:47<03:43,  1.29s/it]Loading train:  35%|███▌      | 94/266 [01:48<03:34,  1.25s/it]Loading train:  36%|███▌      | 95/266 [01:49<03:44,  1.31s/it]Loading train:  36%|███▌      | 96/266 [01:51<04:02,  1.42s/it]Loading train:  36%|███▋      | 97/266 [01:53<04:17,  1.52s/it]Loading train:  37%|███▋      | 98/266 [01:54<04:22,  1.56s/it]Loading train:  37%|███▋      | 99/266 [01:55<03:54,  1.40s/it]Loading train:  38%|███▊      | 100/266 [01:57<03:48,  1.37s/it]Loading train:  38%|███▊      | 101/266 [01:58<03:56,  1.43s/it]Loading train:  38%|███▊      | 102/266 [02:00<03:57,  1.45s/it]Loading train:  39%|███▊      | 103/266 [02:01<04:04,  1.50s/it]Loading train:  39%|███▉      | 104/266 [02:03<04:05,  1.52s/it]Loading train:  39%|███▉      | 105/266 [02:04<03:59,  1.49s/it]Loading train:  40%|███▉      | 106/266 [02:06<04:11,  1.57s/it]Loading train:  40%|████      | 107/266 [02:08<04:09,  1.57s/it]Loading train:  41%|████      | 108/266 [02:09<04:06,  1.56s/it]Loading train:  41%|████      | 109/266 [02:11<03:58,  1.52s/it]Loading train:  41%|████▏     | 110/266 [02:12<03:35,  1.38s/it]Loading train:  42%|████▏     | 111/266 [02:13<03:35,  1.39s/it]Loading train:  42%|████▏     | 112/266 [02:14<03:28,  1.35s/it]Loading train:  42%|████▏     | 113/266 [02:16<03:32,  1.39s/it]Loading train:  43%|████▎     | 114/266 [02:17<03:21,  1.33s/it]Loading train:  43%|████▎     | 115/266 [02:19<03:28,  1.38s/it]Loading train:  44%|████▎     | 116/266 [02:20<03:12,  1.28s/it]Loading train:  44%|████▍     | 117/266 [02:21<03:06,  1.25s/it]Loading train:  44%|████▍     | 118/266 [02:22<03:01,  1.23s/it]Loading train:  45%|████▍     | 119/266 [02:22<02:29,  1.02s/it]Loading train:  45%|████▌     | 120/266 [02:24<02:54,  1.19s/it]Loading train:  45%|████▌     | 121/266 [02:26<03:10,  1.31s/it]Loading train:  46%|████▌     | 122/266 [02:27<03:17,  1.37s/it]Loading train:  46%|████▌     | 123/266 [02:28<03:09,  1.32s/it]Loading train:  47%|████▋     | 124/266 [02:30<03:23,  1.43s/it]Loading train:  47%|████▋     | 125/266 [02:31<03:20,  1.42s/it]Loading train:  47%|████▋     | 126/266 [02:33<03:17,  1.41s/it]Loading train:  48%|████▊     | 127/266 [02:34<03:16,  1.42s/it]Loading train:  48%|████▊     | 128/266 [02:36<03:11,  1.39s/it]Loading train:  48%|████▊     | 129/266 [02:37<03:18,  1.45s/it]Loading train:  49%|████▉     | 130/266 [02:38<03:10,  1.40s/it]Loading train:  49%|████▉     | 131/266 [02:40<03:13,  1.43s/it]Loading train:  50%|████▉     | 132/266 [02:41<03:16,  1.47s/it]Loading train:  50%|█████     | 133/266 [02:43<03:20,  1.51s/it]Loading train:  50%|█████     | 134/266 [02:45<03:37,  1.65s/it]Loading train:  51%|█████     | 135/266 [02:47<03:37,  1.66s/it]Loading train:  51%|█████     | 136/266 [02:47<02:55,  1.35s/it]Loading train:  52%|█████▏    | 137/266 [02:49<02:54,  1.35s/it]Loading train:  52%|█████▏    | 138/266 [02:50<03:02,  1.42s/it]Loading train:  52%|█████▏    | 139/266 [02:52<03:01,  1.43s/it]Loading train:  53%|█████▎    | 140/266 [02:53<03:03,  1.45s/it]Loading train:  53%|█████▎    | 141/266 [02:55<02:58,  1.42s/it]Loading train:  53%|█████▎    | 142/266 [02:56<02:57,  1.43s/it]Loading train:  54%|█████▍    | 143/266 [02:57<02:27,  1.20s/it]Loading train:  54%|█████▍    | 144/266 [02:58<02:30,  1.23s/it]Loading train:  55%|█████▍    | 145/266 [02:59<02:30,  1.25s/it]Loading train:  55%|█████▍    | 146/266 [03:01<02:33,  1.28s/it]Loading train:  55%|█████▌    | 147/266 [03:02<02:36,  1.32s/it]Loading train:  56%|█████▌    | 148/266 [03:03<02:27,  1.25s/it]Loading train:  56%|█████▌    | 149/266 [03:05<02:34,  1.32s/it]Loading train:  56%|█████▋    | 150/266 [03:06<02:39,  1.38s/it]Loading train:  57%|█████▋    | 151/266 [03:08<02:44,  1.43s/it]Loading train:  57%|█████▋    | 152/266 [03:10<03:00,  1.58s/it]Loading train:  58%|█████▊    | 153/266 [03:11<02:47,  1.48s/it]Loading train:  58%|█████▊    | 154/266 [03:11<02:14,  1.20s/it]Loading train:  58%|█████▊    | 155/266 [03:13<02:19,  1.25s/it]Loading train:  59%|█████▊    | 156/266 [03:14<02:22,  1.29s/it]Loading train:  59%|█████▉    | 157/266 [03:15<02:19,  1.28s/it]Loading train:  59%|█████▉    | 158/266 [03:17<02:26,  1.35s/it]Loading train:  60%|█████▉    | 159/266 [03:18<02:23,  1.34s/it]Loading train:  60%|██████    | 160/266 [03:20<02:23,  1.35s/it]Loading train:  61%|██████    | 161/266 [03:21<02:30,  1.43s/it]Loading train:  61%|██████    | 162/266 [03:23<02:31,  1.46s/it]Loading train:  61%|██████▏   | 163/266 [03:24<02:23,  1.40s/it]Loading train:  62%|██████▏   | 164/266 [03:25<02:20,  1.37s/it]Loading train:  62%|██████▏   | 165/266 [03:27<02:13,  1.33s/it]Loading train:  62%|██████▏   | 166/266 [03:28<02:17,  1.37s/it]Loading train:  63%|██████▎   | 167/266 [03:30<02:34,  1.56s/it]Loading train:  63%|██████▎   | 168/266 [03:32<02:29,  1.53s/it]Loading train:  64%|██████▎   | 169/266 [03:33<02:21,  1.46s/it]Loading train:  64%|██████▍   | 170/266 [03:34<02:16,  1.42s/it]Loading train:  64%|██████▍   | 171/266 [03:35<02:09,  1.36s/it]Loading train:  65%|██████▍   | 172/266 [03:37<02:07,  1.36s/it]Loading train:  65%|██████▌   | 173/266 [03:38<02:05,  1.35s/it]Loading train:  65%|██████▌   | 174/266 [03:40<02:13,  1.45s/it]Loading train:  66%|██████▌   | 175/266 [03:41<02:15,  1.49s/it]Loading train:  66%|██████▌   | 176/266 [03:43<02:11,  1.46s/it]Loading train:  67%|██████▋   | 177/266 [03:44<02:06,  1.42s/it]Loading train:  67%|██████▋   | 178/266 [03:45<02:02,  1.39s/it]Loading train:  67%|██████▋   | 179/266 [03:47<01:58,  1.36s/it]Loading train:  68%|██████▊   | 180/266 [03:48<02:02,  1.42s/it]Loading train:  68%|██████▊   | 181/266 [03:50<02:11,  1.55s/it]Loading train:  68%|██████▊   | 182/266 [03:52<02:12,  1.58s/it]Loading train:  69%|██████▉   | 183/266 [03:53<01:55,  1.39s/it]Loading train:  69%|██████▉   | 184/266 [03:54<01:48,  1.33s/it]Loading train:  70%|██████▉   | 185/266 [03:55<01:53,  1.40s/it]Loading train:  70%|██████▉   | 186/266 [03:57<01:45,  1.31s/it]Loading train:  70%|███████   | 187/266 [03:58<01:40,  1.28s/it]Loading train:  71%|███████   | 188/266 [03:59<01:37,  1.24s/it]Loading train:  71%|███████   | 189/266 [04:00<01:38,  1.28s/it]Loading train:  71%|███████▏  | 190/266 [04:02<01:40,  1.32s/it]Loading train:  72%|███████▏  | 191/266 [04:03<01:41,  1.36s/it]Loading train:  72%|███████▏  | 192/266 [04:04<01:39,  1.35s/it]Loading train:  73%|███████▎  | 193/266 [04:06<01:37,  1.33s/it]Loading train:  73%|███████▎  | 194/266 [04:07<01:36,  1.34s/it]Loading train:  73%|███████▎  | 195/266 [04:09<01:38,  1.39s/it]Loading train:  74%|███████▎  | 196/266 [04:10<01:42,  1.46s/it]Loading train:  74%|███████▍  | 197/266 [04:11<01:35,  1.39s/it]Loading train:  74%|███████▍  | 198/266 [04:13<01:27,  1.28s/it]Loading train:  75%|███████▍  | 199/266 [04:14<01:33,  1.40s/it]Loading train:  75%|███████▌  | 200/266 [04:16<01:32,  1.39s/it]Loading train:  76%|███████▌  | 201/266 [04:17<01:33,  1.43s/it]Loading train:  76%|███████▌  | 202/266 [04:18<01:29,  1.40s/it]Loading train:  76%|███████▋  | 203/266 [04:20<01:28,  1.41s/it]Loading train:  77%|███████▋  | 204/266 [04:21<01:19,  1.29s/it]Loading train:  77%|███████▋  | 205/266 [04:23<01:25,  1.40s/it]Loading train:  77%|███████▋  | 206/266 [04:24<01:31,  1.52s/it]Loading train:  78%|███████▊  | 207/266 [04:26<01:32,  1.57s/it]Loading train:  78%|███████▊  | 208/266 [04:28<01:30,  1.57s/it]Loading train:  79%|███████▊  | 209/266 [04:29<01:27,  1.53s/it]Loading train:  79%|███████▉  | 210/266 [04:31<01:25,  1.54s/it]Loading train:  79%|███████▉  | 211/266 [04:32<01:22,  1.50s/it]Loading train:  80%|███████▉  | 212/266 [04:33<01:19,  1.46s/it]Loading train:  80%|████████  | 213/266 [04:35<01:21,  1.54s/it]Loading train:  80%|████████  | 214/266 [04:36<01:16,  1.47s/it]Loading train:  81%|████████  | 215/266 [04:38<01:15,  1.47s/it]Loading train:  81%|████████  | 216/266 [04:39<01:10,  1.41s/it]Loading train:  82%|████████▏ | 217/266 [04:40<01:07,  1.38s/it]Loading train:  82%|████████▏ | 218/266 [04:42<01:02,  1.31s/it]Loading train:  82%|████████▏ | 219/266 [04:43<01:01,  1.32s/it]Loading train:  83%|████████▎ | 220/266 [04:44<00:53,  1.17s/it]Loading train:  83%|████████▎ | 221/266 [04:45<00:58,  1.30s/it]Loading train:  83%|████████▎ | 222/266 [04:46<00:52,  1.18s/it]Loading train:  84%|████████▍ | 223/266 [04:48<00:52,  1.23s/it]Loading train:  84%|████████▍ | 224/266 [04:49<00:53,  1.27s/it]Loading train:  85%|████████▍ | 225/266 [04:50<00:51,  1.25s/it]Loading train:  85%|████████▍ | 226/266 [04:52<00:51,  1.30s/it]Loading train:  85%|████████▌ | 227/266 [04:53<00:51,  1.33s/it]Loading train:  86%|████████▌ | 228/266 [04:54<00:51,  1.35s/it]Loading train:  86%|████████▌ | 229/266 [04:56<00:51,  1.39s/it]Loading train:  86%|████████▋ | 230/266 [04:57<00:52,  1.45s/it]Loading train:  87%|████████▋ | 231/266 [04:59<00:49,  1.41s/it]Loading train:  87%|████████▋ | 232/266 [05:00<00:50,  1.48s/it]Loading train:  88%|████████▊ | 233/266 [05:02<00:48,  1.48s/it]Loading train:  88%|████████▊ | 234/266 [05:03<00:48,  1.51s/it]Loading train:  88%|████████▊ | 235/266 [05:05<00:47,  1.53s/it]Loading train:  89%|████████▊ | 236/266 [05:06<00:42,  1.42s/it]Loading train:  89%|████████▉ | 237/266 [05:08<00:42,  1.47s/it]Loading train:  89%|████████▉ | 238/266 [05:09<00:41,  1.47s/it]Loading train:  90%|████████▉ | 239/266 [05:10<00:36,  1.36s/it]Loading train:  90%|█████████ | 240/266 [05:12<00:35,  1.36s/it]Loading train:  91%|█████████ | 241/266 [05:13<00:32,  1.29s/it]Loading train:  91%|█████████ | 242/266 [05:15<00:34,  1.44s/it]Loading train:  91%|█████████▏| 243/266 [05:16<00:32,  1.41s/it]Loading train:  92%|█████████▏| 244/266 [05:17<00:28,  1.32s/it]Loading train:  92%|█████████▏| 245/266 [05:19<00:29,  1.38s/it]Loading train:  92%|█████████▏| 246/266 [05:20<00:26,  1.33s/it]Loading train:  93%|█████████▎| 247/266 [05:21<00:25,  1.36s/it]Loading train:  93%|█████████▎| 248/266 [05:22<00:20,  1.14s/it]Loading train:  94%|█████████▎| 249/266 [05:23<00:21,  1.26s/it]Loading train:  94%|█████████▍| 250/266 [05:25<00:21,  1.33s/it]Loading train:  94%|█████████▍| 251/266 [05:26<00:21,  1.40s/it]Loading train:  95%|█████████▍| 252/266 [05:28<00:19,  1.41s/it]Loading train:  95%|█████████▌| 253/266 [05:29<00:17,  1.38s/it]Loading train:  95%|█████████▌| 254/266 [05:31<00:17,  1.43s/it]Loading train:  96%|█████████▌| 255/266 [05:32<00:15,  1.43s/it]Loading train:  96%|█████████▌| 256/266 [05:34<00:14,  1.41s/it]Loading train:  97%|█████████▋| 257/266 [05:35<00:13,  1.47s/it]Loading train:  97%|█████████▋| 258/266 [05:37<00:11,  1.50s/it]Loading train:  97%|█████████▋| 259/266 [05:39<00:11,  1.60s/it]Loading train:  98%|█████████▊| 260/266 [05:40<00:09,  1.63s/it]Loading train:  98%|█████████▊| 261/266 [05:42<00:08,  1.63s/it]Loading train:  98%|█████████▊| 262/266 [05:44<00:06,  1.63s/it]Loading train:  99%|█████████▉| 263/266 [05:45<00:05,  1.73s/it]Loading train:  99%|█████████▉| 264/266 [05:47<00:03,  1.68s/it]Loading train: 100%|█████████▉| 265/266 [05:48<00:01,  1.58s/it]Loading train: 100%|██████████| 266/266 [05:50<00:00,  1.59s/it]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   0%|          | 1/266 [00:00<00:35,  7.37it/s]concatenating: train:   1%|          | 2/266 [00:00<00:33,  7.85it/s]concatenating: train:   1%|          | 3/266 [00:00<00:33,  7.92it/s]concatenating: train:   2%|▏         | 4/266 [00:00<00:31,  8.36it/s]concatenating: train:   2%|▏         | 5/266 [00:00<00:51,  5.06it/s]concatenating: train:   2%|▏         | 6/266 [00:01<00:50,  5.16it/s]concatenating: train:   3%|▎         | 7/266 [00:01<00:48,  5.34it/s]concatenating: train:   3%|▎         | 8/266 [00:01<00:55,  4.63it/s]concatenating: train:   3%|▎         | 9/266 [00:01<00:59,  4.34it/s]concatenating: train:   4%|▍         | 10/266 [00:01<00:52,  4.89it/s]concatenating: train:   4%|▍         | 11/266 [00:02<00:45,  5.58it/s]concatenating: train:   5%|▍         | 12/266 [00:02<00:41,  6.06it/s]concatenating: train:   5%|▍         | 13/266 [00:02<00:39,  6.40it/s]concatenating: train:   5%|▌         | 14/266 [00:02<00:45,  5.51it/s]concatenating: train:   6%|▌         | 15/266 [00:02<00:47,  5.25it/s]concatenating: train:   6%|▌         | 16/266 [00:02<00:42,  5.86it/s]concatenating: train:   6%|▋         | 17/266 [00:02<00:39,  6.24it/s]concatenating: train:   7%|▋         | 18/266 [00:03<00:40,  6.11it/s]concatenating: train:   7%|▋         | 19/266 [00:03<00:38,  6.34it/s]concatenating: train:   8%|▊         | 20/266 [00:03<00:37,  6.56it/s]concatenating: train:   8%|▊         | 21/266 [00:03<00:36,  6.67it/s]concatenating: train:   8%|▊         | 22/266 [00:03<00:41,  5.89it/s]concatenating: train:   9%|▊         | 23/266 [00:03<00:41,  5.79it/s]concatenating: train:   9%|▉         | 24/266 [00:04<00:43,  5.56it/s]concatenating: train:   9%|▉         | 25/266 [00:04<00:52,  4.58it/s]concatenating: train:  10%|▉         | 26/266 [00:04<00:58,  4.12it/s]concatenating: train:  10%|█         | 27/266 [00:05<01:03,  3.76it/s]concatenating: train:  11%|█         | 28/266 [00:05<00:58,  4.04it/s]concatenating: train:  11%|█         | 29/266 [00:05<00:58,  4.08it/s]concatenating: train:  11%|█▏        | 30/266 [00:05<01:01,  3.86it/s]concatenating: train:  12%|█▏        | 31/266 [00:06<00:58,  4.04it/s]concatenating: train:  12%|█▏        | 32/266 [00:06<00:57,  4.04it/s]concatenating: train:  12%|█▏        | 33/266 [00:06<00:49,  4.75it/s]concatenating: train:  13%|█▎        | 34/266 [00:06<00:44,  5.18it/s]concatenating: train:  13%|█▎        | 35/266 [00:06<00:54,  4.24it/s]concatenating: train:  14%|█▎        | 36/266 [00:07<00:46,  4.91it/s]concatenating: train:  14%|█▍        | 37/266 [00:07<00:46,  4.94it/s]concatenating: train:  14%|█▍        | 38/266 [00:07<00:41,  5.52it/s]concatenating: train:  15%|█▍        | 39/266 [00:07<00:42,  5.28it/s]concatenating: train:  15%|█▌        | 40/266 [00:07<00:42,  5.33it/s]concatenating: train:  16%|█▌        | 42/266 [00:08<00:42,  5.31it/s]concatenating: train:  16%|█▌        | 43/266 [00:08<00:52,  4.21it/s]concatenating: train:  17%|█▋        | 44/266 [00:08<00:47,  4.64it/s]concatenating: train:  17%|█▋        | 45/266 [00:08<00:44,  5.00it/s]concatenating: train:  17%|█▋        | 46/266 [00:09<00:45,  4.88it/s]concatenating: train:  18%|█▊        | 47/266 [00:09<00:45,  4.80it/s]concatenating: train:  18%|█▊        | 48/266 [00:09<00:44,  4.86it/s]concatenating: train:  18%|█▊        | 49/266 [00:09<00:40,  5.34it/s]concatenating: train:  19%|█▉        | 50/266 [00:09<00:40,  5.37it/s]concatenating: train:  19%|█▉        | 51/266 [00:10<00:41,  5.16it/s]concatenating: train:  20%|█▉        | 52/266 [00:10<00:42,  4.99it/s]concatenating: train:  20%|█▉        | 53/266 [00:10<00:41,  5.14it/s]concatenating: train:  20%|██        | 54/266 [00:10<00:38,  5.50it/s]concatenating: train:  21%|██        | 55/266 [00:10<00:37,  5.56it/s]concatenating: train:  21%|██        | 56/266 [00:10<00:40,  5.24it/s]concatenating: train:  21%|██▏       | 57/266 [00:11<00:41,  5.04it/s]concatenating: train:  22%|██▏       | 58/266 [00:11<00:40,  5.19it/s]concatenating: train:  22%|██▏       | 59/266 [00:11<00:41,  4.98it/s]concatenating: train:  23%|██▎       | 60/266 [00:11<00:42,  4.87it/s]concatenating: train:  23%|██▎       | 61/266 [00:12<00:42,  4.79it/s]concatenating: train:  23%|██▎       | 62/266 [00:12<00:43,  4.74it/s]concatenating: train:  24%|██▎       | 63/266 [00:12<00:39,  5.14it/s]concatenating: train:  24%|██▍       | 64/266 [00:12<00:37,  5.33it/s]concatenating: train:  24%|██▍       | 65/266 [00:12<00:43,  4.62it/s]concatenating: train:  25%|██▍       | 66/266 [00:13<00:43,  4.62it/s]concatenating: train:  25%|██▌       | 67/266 [00:13<00:40,  4.87it/s]concatenating: train:  26%|██▌       | 68/266 [00:13<00:39,  4.99it/s]concatenating: train:  26%|██▌       | 69/266 [00:13<00:37,  5.25it/s]concatenating: train:  26%|██▋       | 70/266 [00:13<00:48,  4.04it/s]concatenating: train:  27%|██▋       | 71/266 [00:14<00:50,  3.83it/s]concatenating: train:  27%|██▋       | 72/266 [00:14<00:47,  4.12it/s]concatenating: train:  27%|██▋       | 73/266 [00:14<00:42,  4.57it/s]concatenating: train:  28%|██▊       | 74/266 [00:14<00:39,  4.91it/s]concatenating: train:  28%|██▊       | 75/266 [00:14<00:35,  5.45it/s]concatenating: train:  29%|██▊       | 76/266 [00:15<00:36,  5.14it/s]concatenating: train:  29%|██▉       | 77/266 [00:15<00:37,  5.07it/s]concatenating: train:  29%|██▉       | 78/266 [00:15<00:33,  5.59it/s]concatenating: train:  30%|██▉       | 79/266 [00:15<00:29,  6.39it/s]concatenating: train:  30%|███       | 80/266 [00:15<00:27,  6.76it/s]concatenating: train:  30%|███       | 81/266 [00:15<00:29,  6.35it/s]concatenating: train:  31%|███       | 82/266 [00:16<00:37,  4.85it/s]concatenating: train:  31%|███       | 83/266 [00:16<00:34,  5.33it/s]concatenating: train:  32%|███▏      | 84/266 [00:16<00:31,  5.69it/s]concatenating: train:  32%|███▏      | 85/266 [00:16<00:32,  5.50it/s]concatenating: train:  32%|███▏      | 86/266 [00:16<00:31,  5.63it/s]concatenating: train:  33%|███▎      | 87/266 [00:16<00:28,  6.24it/s]concatenating: train:  33%|███▎      | 88/266 [00:17<00:38,  4.59it/s]concatenating: train:  33%|███▎      | 89/266 [00:17<00:37,  4.76it/s]concatenating: train:  34%|███▍      | 90/266 [00:17<00:33,  5.26it/s]concatenating: train:  34%|███▍      | 91/266 [00:17<00:31,  5.48it/s]concatenating: train:  35%|███▍      | 92/266 [00:18<00:31,  5.58it/s]concatenating: train:  35%|███▍      | 93/266 [00:18<00:31,  5.53it/s]concatenating: train:  35%|███▌      | 94/266 [00:18<00:30,  5.58it/s]concatenating: train:  36%|███▌      | 95/266 [00:18<00:35,  4.89it/s]concatenating: train:  36%|███▌      | 96/266 [00:18<00:32,  5.23it/s]concatenating: train:  36%|███▋      | 97/266 [00:18<00:30,  5.50it/s]concatenating: train:  37%|███▋      | 98/266 [00:19<00:37,  4.50it/s]concatenating: train:  37%|███▋      | 99/266 [00:19<00:34,  4.80it/s]concatenating: train:  38%|███▊      | 100/266 [00:19<00:34,  4.86it/s]concatenating: train:  38%|███▊      | 101/266 [00:19<00:31,  5.21it/s]concatenating: train:  38%|███▊      | 102/266 [00:20<00:33,  4.93it/s]concatenating: train:  39%|███▊      | 103/266 [00:20<00:33,  4.89it/s]concatenating: train:  39%|███▉      | 104/266 [00:20<00:28,  5.62it/s]concatenating: train:  40%|███▉      | 106/266 [00:20<00:22,  7.16it/s]concatenating: train:  41%|████      | 108/266 [00:21<00:31,  5.02it/s]concatenating: train:  41%|████      | 109/266 [00:21<00:34,  4.58it/s]concatenating: train:  41%|████▏     | 110/266 [00:21<00:30,  5.13it/s]concatenating: train:  42%|████▏     | 111/266 [00:21<00:30,  5.09it/s]concatenating: train:  42%|████▏     | 112/266 [00:21<00:29,  5.25it/s]concatenating: train:  42%|████▏     | 113/266 [00:22<00:25,  6.04it/s]concatenating: train:  43%|████▎     | 114/266 [00:22<00:24,  6.28it/s]concatenating: train:  43%|████▎     | 115/266 [00:22<00:22,  6.68it/s]concatenating: train:  44%|████▎     | 116/266 [00:22<00:28,  5.23it/s]concatenating: train:  44%|████▍     | 117/266 [00:22<00:27,  5.32it/s]concatenating: train:  44%|████▍     | 118/266 [00:22<00:27,  5.46it/s]concatenating: train:  45%|████▍     | 119/266 [00:23<00:26,  5.45it/s]concatenating: train:  45%|████▌     | 120/266 [00:23<00:23,  6.22it/s]concatenating: train:  45%|████▌     | 121/266 [00:23<00:21,  6.73it/s]concatenating: train:  46%|████▌     | 122/266 [00:23<00:22,  6.48it/s]concatenating: train:  46%|████▌     | 123/266 [00:23<00:20,  6.83it/s]concatenating: train:  47%|████▋     | 124/266 [00:23<00:24,  5.85it/s]concatenating: train:  47%|████▋     | 125/266 [00:24<00:26,  5.25it/s]concatenating: train:  47%|████▋     | 126/266 [00:24<00:25,  5.55it/s]concatenating: train:  48%|████▊     | 127/266 [00:24<00:26,  5.31it/s]concatenating: train:  48%|████▊     | 128/266 [00:24<00:22,  6.09it/s]concatenating: train:  48%|████▊     | 129/266 [00:24<00:21,  6.37it/s]concatenating: train:  49%|████▉     | 130/266 [00:24<00:20,  6.63it/s]concatenating: train:  49%|████▉     | 131/266 [00:24<00:19,  6.89it/s]concatenating: train:  50%|████▉     | 132/266 [00:25<00:26,  5.03it/s]concatenating: train:  50%|█████     | 133/266 [00:25<00:32,  4.09it/s]concatenating: train:  50%|█████     | 134/266 [00:25<00:30,  4.33it/s]concatenating: train:  51%|█████     | 135/266 [00:26<00:29,  4.43it/s]concatenating: train:  51%|█████     | 136/266 [00:26<00:28,  4.59it/s]concatenating: train:  52%|█████▏    | 137/266 [00:26<00:24,  5.20it/s]concatenating: train:  52%|█████▏    | 138/266 [00:26<00:23,  5.41it/s]concatenating: train:  52%|█████▏    | 139/266 [00:26<00:28,  4.43it/s]concatenating: train:  53%|█████▎    | 140/266 [00:27<00:29,  4.24it/s]concatenating: train:  53%|█████▎    | 141/266 [00:27<00:28,  4.44it/s]concatenating: train:  53%|█████▎    | 142/266 [00:27<00:26,  4.73it/s]concatenating: train:  54%|█████▍    | 143/266 [00:27<00:24,  4.95it/s]concatenating: train:  54%|█████▍    | 144/266 [00:27<00:22,  5.42it/s]concatenating: train:  55%|█████▍    | 145/266 [00:27<00:19,  6.05it/s]concatenating: train:  55%|█████▍    | 146/266 [00:28<00:18,  6.44it/s]concatenating: train:  55%|█████▌    | 147/266 [00:28<00:18,  6.33it/s]concatenating: train:  56%|█████▌    | 148/266 [00:28<00:18,  6.41it/s]concatenating: train:  56%|█████▌    | 149/266 [00:28<00:18,  6.17it/s]concatenating: train:  56%|█████▋    | 150/266 [00:28<00:17,  6.53it/s]concatenating: train:  57%|█████▋    | 151/266 [00:28<00:17,  6.65it/s]concatenating: train:  57%|█████▋    | 152/266 [00:29<00:18,  6.28it/s]concatenating: train:  58%|█████▊    | 154/266 [00:29<00:15,  7.25it/s]concatenating: train:  58%|█████▊    | 155/266 [00:29<00:14,  7.76it/s]concatenating: train:  59%|█████▉    | 157/266 [00:29<00:12,  8.61it/s]concatenating: train:  59%|█████▉    | 158/266 [00:29<00:17,  6.28it/s]concatenating: train:  60%|█████▉    | 159/266 [00:29<00:16,  6.57it/s]concatenating: train:  60%|██████    | 160/266 [00:30<00:16,  6.57it/s]concatenating: train:  61%|██████    | 161/266 [00:30<00:14,  7.26it/s]concatenating: train:  61%|██████    | 162/266 [00:30<00:15,  6.93it/s]concatenating: train:  61%|██████▏   | 163/266 [00:30<00:15,  6.71it/s]concatenating: train:  62%|██████▏   | 164/266 [00:30<00:14,  7.06it/s]concatenating: train:  62%|██████▏   | 165/266 [00:30<00:13,  7.27it/s]concatenating: train:  62%|██████▏   | 166/266 [00:30<00:14,  6.93it/s]concatenating: train:  63%|██████▎   | 168/266 [00:31<00:12,  7.81it/s]concatenating: train:  64%|██████▍   | 170/266 [00:31<00:10,  9.30it/s]concatenating: train:  65%|██████▍   | 172/266 [00:31<00:11,  7.84it/s]concatenating: train:  65%|██████▌   | 173/266 [00:31<00:12,  7.42it/s]concatenating: train:  65%|██████▌   | 174/266 [00:31<00:15,  6.05it/s]concatenating: train:  66%|██████▌   | 175/266 [00:32<00:18,  4.98it/s]concatenating: train:  66%|██████▌   | 176/266 [00:32<00:18,  4.93it/s]concatenating: train:  67%|██████▋   | 178/266 [00:32<00:14,  6.26it/s]concatenating: train:  69%|██████▉   | 183/266 [00:32<00:10,  8.23it/s]concatenating: train:  70%|██████▉   | 185/266 [00:32<00:08,  9.99it/s]concatenating: train:  70%|███████   | 187/266 [00:32<00:07, 11.20it/s]concatenating: train:  71%|███████   | 189/266 [00:33<00:06, 12.06it/s]concatenating: train:  72%|███████▏  | 191/266 [00:33<00:05, 12.86it/s]concatenating: train:  73%|███████▎  | 194/266 [00:33<00:05, 14.19it/s]concatenating: train:  74%|███████▎  | 196/266 [00:33<00:05, 11.97it/s]concatenating: train:  74%|███████▍  | 198/266 [00:33<00:06, 10.32it/s]concatenating: train:  75%|███████▌  | 200/266 [00:34<00:08,  7.79it/s]concatenating: train:  76%|███████▌  | 202/266 [00:34<00:07,  8.18it/s]concatenating: train:  76%|███████▋  | 203/266 [00:34<00:07,  7.91it/s]concatenating: train:  77%|███████▋  | 204/266 [00:34<00:08,  7.66it/s]concatenating: train:  77%|███████▋  | 205/266 [00:34<00:09,  6.45it/s]concatenating: train:  77%|███████▋  | 206/266 [00:35<00:08,  7.10it/s]concatenating: train:  78%|███████▊  | 208/266 [00:35<00:07,  7.67it/s]concatenating: train:  79%|███████▊  | 209/266 [00:35<00:06,  8.25it/s]concatenating: train:  79%|███████▉  | 210/266 [00:35<00:06,  8.19it/s]concatenating: train:  79%|███████▉  | 211/266 [00:35<00:07,  7.49it/s]concatenating: train:  80%|███████▉  | 212/266 [00:35<00:07,  7.07it/s]concatenating: train:  80%|████████  | 214/266 [00:36<00:06,  7.90it/s]concatenating: train:  81%|████████  | 215/266 [00:36<00:06,  7.87it/s]concatenating: train:  81%|████████  | 216/266 [00:36<00:06,  8.32it/s]concatenating: train:  82%|████████▏ | 218/266 [00:36<00:05,  8.63it/s]concatenating: train:  82%|████████▏ | 219/266 [00:36<00:05,  8.37it/s]concatenating: train:  83%|████████▎ | 221/266 [00:36<00:04,  9.29it/s]concatenating: train:  84%|████████▍ | 223/266 [00:36<00:04,  9.23it/s]concatenating: train:  84%|████████▍ | 224/266 [00:37<00:04,  8.75it/s]concatenating: train:  85%|████████▍ | 225/266 [00:37<00:04,  8.45it/s]concatenating: train:  85%|████████▍ | 226/266 [00:37<00:04,  8.25it/s]concatenating: train:  85%|████████▌ | 227/266 [00:37<00:05,  7.53it/s]concatenating: train:  86%|████████▌ | 228/266 [00:37<00:05,  7.09it/s]concatenating: train:  86%|████████▌ | 229/266 [00:37<00:05,  7.29it/s]concatenating: train:  86%|████████▋ | 230/266 [00:37<00:04,  7.86it/s]concatenating: train:  87%|████████▋ | 232/266 [00:38<00:04,  8.24it/s]concatenating: train:  88%|████████▊ | 234/266 [00:38<00:03,  8.88it/s]concatenating: train:  89%|████████▊ | 236/266 [00:38<00:02, 10.46it/s]concatenating: train:  89%|████████▉ | 238/266 [00:38<00:02, 11.00it/s]concatenating: train:  90%|█████████ | 240/266 [00:38<00:02,  9.74it/s]concatenating: train:  91%|█████████ | 242/266 [00:39<00:02,  8.02it/s]concatenating: train:  91%|█████████▏| 243/266 [00:39<00:03,  7.48it/s]concatenating: train:  92%|█████████▏| 245/266 [00:39<00:03,  6.79it/s]concatenating: train:  92%|█████████▏| 246/266 [00:39<00:03,  6.57it/s]concatenating: train:  93%|█████████▎| 247/266 [00:39<00:02,  6.73it/s]concatenating: train:  93%|█████████▎| 248/266 [00:40<00:02,  6.53it/s]concatenating: train:  94%|█████████▎| 249/266 [00:40<00:02,  6.44it/s]concatenating: train:  94%|█████████▍| 250/266 [00:40<00:02,  6.74it/s]concatenating: train:  94%|█████████▍| 251/266 [00:40<00:02,  6.44it/s]concatenating: train:  95%|█████████▍| 252/266 [00:40<00:02,  6.43it/s]concatenating: train:  95%|█████████▌| 253/266 [00:40<00:02,  5.80it/s]concatenating: train:  95%|█████████▌| 254/266 [00:41<00:02,  5.61it/s]concatenating: train:  96%|█████████▌| 255/266 [00:41<00:01,  5.91it/s]concatenating: train:  96%|█████████▌| 256/266 [00:41<00:01,  5.72it/s]concatenating: train:  97%|█████████▋| 257/266 [00:41<00:01,  5.31it/s]concatenating: train:  97%|█████████▋| 258/266 [00:41<00:01,  5.87it/s]concatenating: train:  97%|█████████▋| 259/266 [00:41<00:01,  6.39it/s]concatenating: train:  98%|█████████▊| 260/266 [00:42<00:00,  6.35it/s]concatenating: train:  98%|█████████▊| 261/266 [00:42<00:00,  6.54it/s]concatenating: train:  98%|█████████▊| 262/266 [00:42<00:00,  6.79it/s]concatenating: train:  99%|█████████▉| 263/266 [00:42<00:00,  6.78it/s]concatenating: train:  99%|█████████▉| 264/266 [00:42<00:00,  6.67it/s]concatenating: train: 100%|█████████▉| 265/266 [00:42<00:00,  6.54it/s]concatenating: train: 100%|██████████| 266/266 [00:43<00:00,  6.82it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:00<00:03,  1.25it/s]Loading test:  40%|████      | 2/5 [00:01<00:02,  1.17it/s]Loading test:  60%|██████    | 3/5 [00:03<00:02,  1.04s/it]Loading test:  80%|████████  | 4/5 [00:04<00:01,  1.17s/it]Loading test: 100%|██████████| 5/5 [00:05<00:00,  1.02it/s]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation:  20%|██        | 1/5 [00:00<00:00,  7.05it/s]concatenating: validation:  40%|████      | 2/5 [00:00<00:00,  6.85it/s]concatenating: validation:  60%|██████    | 3/5 [00:00<00:00,  7.05it/s]concatenating: validation:  80%|████████  | 4/5 [00:00<00:00,  7.26it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00,  7.10it/s]
Loading trainS:   0%|          | 0/266 [00:00<?, ?it/s]Loading trainS:   0%|          | 1/266 [00:00<04:10,  1.06it/s]Loading trainS:   1%|          | 2/266 [00:02<05:10,  1.17s/it]Loading trainS:   1%|          | 3/266 [00:04<05:32,  1.27s/it]Loading trainS:   2%|▏         | 4/266 [00:04<04:58,  1.14s/it]Loading trainS:   2%|▏         | 5/266 [00:06<04:59,  1.15s/it]Loading trainS:   2%|▏         | 6/266 [00:07<05:34,  1.29s/it]Loading trainS:   3%|▎         | 7/266 [00:09<05:54,  1.37s/it]Loading trainS:   3%|▎         | 8/266 [00:10<06:05,  1.41s/it]Loading trainS:   3%|▎         | 9/266 [00:12<06:54,  1.61s/it]Loading trainS:   4%|▍         | 10/266 [00:14<07:04,  1.66s/it]Loading trainS:   4%|▍         | 11/266 [00:16<06:42,  1.58s/it]Loading trainS:   5%|▍         | 12/266 [00:17<07:04,  1.67s/it]Loading trainS:   5%|▍         | 13/266 [00:19<06:46,  1.61s/it]Loading trainS:   5%|▌         | 14/266 [00:20<06:12,  1.48s/it]Loading trainS:   6%|▌         | 15/266 [00:21<05:40,  1.36s/it]Loading trainS:   6%|▌         | 16/266 [00:22<05:13,  1.26s/it]Loading trainS:   6%|▋         | 17/266 [00:23<05:04,  1.22s/it]Loading trainS:   7%|▋         | 18/266 [00:25<05:19,  1.29s/it]Loading trainS:   7%|▋         | 19/266 [00:26<05:33,  1.35s/it]Loading trainS:   8%|▊         | 20/266 [00:28<05:40,  1.38s/it]Loading trainS:   8%|▊         | 21/266 [00:29<05:57,  1.46s/it]Loading trainS:   8%|▊         | 22/266 [00:31<06:06,  1.50s/it]Loading trainS:   9%|▊         | 23/266 [00:32<06:01,  1.49s/it]Loading trainS:   9%|▉         | 24/266 [00:34<05:52,  1.45s/it]Loading trainS:   9%|▉         | 25/266 [00:35<05:15,  1.31s/it]Loading trainS:  10%|▉         | 26/266 [00:36<05:06,  1.28s/it]Loading trainS:  10%|█         | 27/266 [00:38<05:24,  1.36s/it]Loading trainS:  11%|█         | 28/266 [00:39<05:01,  1.27s/it]Loading trainS:  11%|█         | 29/266 [00:40<05:03,  1.28s/it]Loading trainS:  11%|█▏        | 30/266 [00:41<04:59,  1.27s/it]Loading trainS:  12%|█▏        | 31/266 [00:42<05:01,  1.28s/it]Loading trainS:  12%|█▏        | 32/266 [00:44<05:11,  1.33s/it]Loading trainS:  12%|█▏        | 33/266 [00:45<04:56,  1.27s/it]Loading trainS:  13%|█▎        | 34/266 [00:47<05:25,  1.40s/it]Loading trainS:  13%|█▎        | 35/266 [00:49<05:57,  1.55s/it]Loading trainS:  14%|█▎        | 36/266 [00:51<06:24,  1.67s/it]Loading trainS:  14%|█▍        | 37/266 [00:52<06:01,  1.58s/it]Loading trainS:  14%|█▍        | 38/266 [00:54<06:13,  1.64s/it]Loading trainS:  15%|█▍        | 39/266 [00:55<06:13,  1.65s/it]Loading trainS:  15%|█▌        | 40/266 [00:57<06:04,  1.61s/it]Loading trainS:  15%|█▌        | 41/266 [00:59<06:11,  1.65s/it]Loading trainS:  16%|█▌        | 42/266 [01:00<06:07,  1.64s/it]Loading trainS:  16%|█▌        | 43/266 [01:02<05:55,  1.59s/it]Loading trainS:  17%|█▋        | 44/266 [01:03<05:15,  1.42s/it]Loading trainS:  17%|█▋        | 45/266 [01:04<05:23,  1.47s/it]Loading trainS:  17%|█▋        | 46/266 [01:06<05:08,  1.40s/it]Loading trainS:  18%|█▊        | 47/266 [01:07<05:19,  1.46s/it]Loading trainS:  18%|█▊        | 48/266 [01:09<05:11,  1.43s/it]Loading trainS:  18%|█▊        | 49/266 [01:10<05:11,  1.43s/it]Loading trainS:  19%|█▉        | 50/266 [01:11<04:59,  1.39s/it]Loading trainS:  19%|█▉        | 51/266 [01:12<04:33,  1.27s/it]Loading trainS:  20%|█▉        | 52/266 [01:13<04:18,  1.21s/it]Loading trainS:  20%|█▉        | 53/266 [01:15<04:21,  1.23s/it]Loading trainS:  20%|██        | 54/266 [01:16<04:24,  1.25s/it]Loading trainS:  21%|██        | 55/266 [01:17<04:39,  1.33s/it]Loading trainS:  21%|██        | 56/266 [01:19<04:50,  1.38s/it]Loading trainS:  21%|██▏       | 57/266 [01:20<04:42,  1.35s/it]Loading trainS:  22%|██▏       | 58/266 [01:22<04:52,  1.40s/it]Loading trainS:  22%|██▏       | 59/266 [01:23<04:50,  1.40s/it]Loading trainS:  23%|██▎       | 60/266 [01:24<04:35,  1.34s/it]Loading trainS:  23%|██▎       | 61/266 [01:25<04:00,  1.17s/it]Loading trainS:  23%|██▎       | 62/266 [01:27<04:25,  1.30s/it]Loading trainS:  24%|██▎       | 63/266 [01:28<04:27,  1.32s/it]Loading trainS:  24%|██▍       | 64/266 [01:29<04:13,  1.26s/it]Loading trainS:  24%|██▍       | 65/266 [01:30<04:07,  1.23s/it]Loading trainS:  25%|██▍       | 66/266 [01:32<04:25,  1.33s/it]Loading trainS:  25%|██▌       | 67/266 [01:33<04:23,  1.32s/it]Loading trainS:  26%|██▌       | 68/266 [01:34<04:09,  1.26s/it]Loading trainS:  26%|██▌       | 69/266 [01:36<04:10,  1.27s/it]Loading trainS:  26%|██▋       | 70/266 [01:37<04:21,  1.33s/it]Loading trainS:  27%|██▋       | 71/266 [01:38<04:07,  1.27s/it]Loading trainS:  27%|██▋       | 72/266 [01:40<04:17,  1.33s/it]Loading trainS:  27%|██▋       | 73/266 [01:41<04:11,  1.30s/it]Loading trainS:  28%|██▊       | 74/266 [01:42<03:48,  1.19s/it]Loading trainS:  28%|██▊       | 75/266 [01:43<03:51,  1.21s/it]Loading trainS:  29%|██▊       | 76/266 [01:44<03:31,  1.11s/it]Loading trainS:  29%|██▉       | 77/266 [01:45<03:45,  1.19s/it]Loading trainS:  29%|██▉       | 78/266 [01:47<03:49,  1.22s/it]Loading trainS:  30%|██▉       | 79/266 [01:48<03:36,  1.16s/it]Loading trainS:  30%|███       | 80/266 [01:49<03:50,  1.24s/it]Loading trainS:  30%|███       | 81/266 [01:50<03:42,  1.20s/it]Loading trainS:  31%|███       | 82/266 [01:52<03:47,  1.23s/it]Loading trainS:  31%|███       | 83/266 [01:53<03:52,  1.27s/it]Loading trainS:  32%|███▏      | 84/266 [01:54<03:46,  1.25s/it]Loading trainS:  32%|███▏      | 85/266 [01:55<03:42,  1.23s/it]Loading trainS:  32%|███▏      | 86/266 [01:56<03:34,  1.19s/it]Loading trainS:  33%|███▎      | 87/266 [01:58<03:47,  1.27s/it]Loading trainS:  33%|███▎      | 88/266 [01:59<03:36,  1.22s/it]Loading trainS:  33%|███▎      | 89/266 [02:01<04:07,  1.40s/it]Loading trainS:  34%|███▍      | 90/266 [02:02<03:58,  1.35s/it]Loading trainS:  34%|███▍      | 91/266 [02:04<04:14,  1.45s/it]Loading trainS:  35%|███▍      | 92/266 [02:05<03:58,  1.37s/it]Loading trainS:  35%|███▍      | 93/266 [02:06<03:59,  1.39s/it]Loading trainS:  35%|███▌      | 94/266 [02:08<04:10,  1.46s/it]Loading trainS:  36%|███▌      | 95/266 [02:09<04:00,  1.41s/it]Loading trainS:  36%|███▌      | 96/266 [02:11<03:59,  1.41s/it]Loading trainS:  36%|███▋      | 97/266 [02:12<03:56,  1.40s/it]Loading trainS:  37%|███▋      | 98/266 [02:13<03:24,  1.22s/it]Loading trainS:  37%|███▋      | 99/266 [02:14<03:11,  1.15s/it]Loading trainS:  38%|███▊      | 100/266 [02:15<03:21,  1.21s/it]Loading trainS:  38%|███▊      | 101/266 [02:16<03:26,  1.25s/it]Loading trainS:  38%|███▊      | 102/266 [02:18<03:35,  1.31s/it]Loading trainS:  39%|███▊      | 103/266 [02:19<03:37,  1.33s/it]Loading trainS:  39%|███▉      | 104/266 [02:20<03:06,  1.15s/it]Loading trainS:  39%|███▉      | 105/266 [02:21<03:04,  1.15s/it]Loading trainS:  40%|███▉      | 106/266 [02:23<03:17,  1.23s/it]Loading trainS:  40%|████      | 107/266 [02:24<03:17,  1.24s/it]Loading trainS:  41%|████      | 108/266 [02:25<03:22,  1.28s/it]Loading trainS:  41%|████      | 109/266 [02:26<03:02,  1.16s/it]Loading trainS:  41%|████▏     | 110/266 [02:28<03:19,  1.28s/it]Loading trainS:  42%|████▏     | 111/266 [02:29<03:23,  1.31s/it]Loading trainS:  42%|████▏     | 112/266 [02:30<03:16,  1.27s/it]Loading trainS:  42%|████▏     | 113/266 [02:32<03:16,  1.29s/it]Loading trainS:  43%|████▎     | 114/266 [02:32<02:43,  1.07s/it]Loading trainS:  43%|████▎     | 115/266 [02:34<03:06,  1.24s/it]Loading trainS:  44%|████▎     | 116/266 [02:35<03:12,  1.29s/it]Loading trainS:  44%|████▍     | 117/266 [02:37<03:15,  1.31s/it]Loading trainS:  44%|████▍     | 118/266 [02:38<03:18,  1.34s/it]Loading trainS:  45%|████▍     | 119/266 [02:39<03:20,  1.37s/it]Loading trainS:  45%|████▌     | 120/266 [02:41<03:24,  1.40s/it]Loading trainS:  45%|████▌     | 121/266 [02:42<03:20,  1.38s/it]Loading trainS:  46%|████▌     | 122/266 [02:43<03:14,  1.35s/it]Loading trainS:  46%|████▌     | 123/266 [02:45<03:17,  1.38s/it]Loading trainS:  47%|████▋     | 124/266 [02:47<03:25,  1.45s/it]Loading trainS:  47%|████▋     | 125/266 [02:48<03:40,  1.56s/it]Loading trainS:  47%|████▋     | 126/266 [02:50<03:33,  1.53s/it]Loading trainS:  48%|████▊     | 127/266 [02:51<03:26,  1.49s/it]Loading trainS:  48%|████▊     | 128/266 [02:53<03:22,  1.47s/it]Loading trainS:  48%|████▊     | 129/266 [02:54<03:22,  1.48s/it]Loading trainS:  49%|████▉     | 130/266 [02:56<03:34,  1.57s/it]Loading trainS:  49%|████▉     | 131/266 [02:57<03:30,  1.56s/it]Loading trainS:  50%|████▉     | 132/266 [02:59<03:34,  1.60s/it]Loading trainS:  50%|█████     | 133/266 [03:01<03:25,  1.54s/it]Loading trainS:  50%|█████     | 134/266 [03:02<03:14,  1.47s/it]Loading trainS:  51%|█████     | 135/266 [03:03<03:12,  1.47s/it]Loading trainS:  51%|█████     | 136/266 [03:05<03:09,  1.46s/it]Loading trainS:  52%|█████▏    | 137/266 [03:06<02:58,  1.38s/it]Loading trainS:  52%|█████▏    | 138/266 [03:07<02:57,  1.39s/it]Loading trainS:  52%|█████▏    | 139/266 [03:08<02:36,  1.23s/it]Loading trainS:  53%|█████▎    | 140/266 [03:10<02:39,  1.27s/it]Loading trainS:  53%|█████▎    | 141/266 [03:11<02:49,  1.36s/it]Loading trainS:  53%|█████▎    | 142/266 [03:13<02:54,  1.40s/it]Loading trainS:  54%|█████▍    | 143/266 [03:14<02:51,  1.40s/it]Loading trainS:  54%|█████▍    | 144/266 [03:15<02:52,  1.41s/it]Loading trainS:  55%|█████▍    | 145/266 [03:17<02:55,  1.45s/it]Loading trainS:  55%|█████▍    | 146/266 [03:18<02:46,  1.39s/it]Loading trainS:  55%|█████▌    | 147/266 [03:19<02:38,  1.33s/it]Loading trainS:  56%|█████▌    | 148/266 [03:21<02:38,  1.35s/it]Loading trainS:  56%|█████▌    | 149/266 [03:22<02:30,  1.28s/it]Loading trainS:  56%|█████▋    | 150/266 [03:23<02:34,  1.33s/it]Loading trainS:  57%|█████▋    | 151/266 [03:25<02:32,  1.33s/it]Loading trainS:  57%|█████▋    | 152/266 [03:26<02:32,  1.33s/it]Loading trainS:  58%|█████▊    | 153/266 [03:28<02:38,  1.40s/it]Loading trainS:  58%|█████▊    | 154/266 [03:29<02:36,  1.40s/it]Loading trainS:  58%|█████▊    | 155/266 [03:30<02:33,  1.38s/it]Loading trainS:  59%|█████▊    | 156/266 [03:31<02:20,  1.28s/it]Loading trainS:  59%|█████▉    | 157/266 [03:33<02:15,  1.24s/it]Loading trainS:  59%|█████▉    | 158/266 [03:34<02:06,  1.17s/it]Loading trainS:  60%|█████▉    | 159/266 [03:35<02:01,  1.14s/it]Loading trainS:  60%|██████    | 160/266 [03:36<01:57,  1.11s/it]Loading trainS:  61%|██████    | 161/266 [03:37<02:00,  1.15s/it]Loading trainS:  61%|██████    | 162/266 [03:38<02:00,  1.15s/it]Loading trainS:  61%|██████▏   | 163/266 [03:39<01:59,  1.16s/it]Loading trainS:  62%|██████▏   | 164/266 [03:40<01:58,  1.16s/it]Loading trainS:  62%|██████▏   | 165/266 [03:42<02:02,  1.21s/it]Loading trainS:  62%|██████▏   | 166/266 [03:43<02:02,  1.22s/it]Loading trainS:  63%|██████▎   | 167/266 [03:44<01:59,  1.20s/it]Loading trainS:  63%|██████▎   | 168/266 [03:46<02:04,  1.27s/it]Loading trainS:  64%|██████▎   | 169/266 [03:47<02:03,  1.27s/it]Loading trainS:  64%|██████▍   | 170/266 [03:48<01:59,  1.24s/it]Loading trainS:  64%|██████▍   | 171/266 [03:49<01:50,  1.16s/it]Loading trainS:  65%|██████▍   | 172/266 [03:50<01:47,  1.14s/it]Loading trainS:  65%|██████▌   | 173/266 [03:52<01:54,  1.23s/it]Loading trainS:  65%|██████▌   | 174/266 [03:53<01:55,  1.25s/it]Loading trainS:  66%|██████▌   | 175/266 [03:54<01:52,  1.24s/it]Loading trainS:  66%|██████▌   | 176/266 [03:56<01:56,  1.30s/it]Loading trainS:  67%|██████▋   | 177/266 [03:57<01:52,  1.27s/it]Loading trainS:  67%|██████▋   | 178/266 [03:58<01:54,  1.30s/it]Loading trainS:  67%|██████▋   | 179/266 [03:59<01:50,  1.28s/it]Loading trainS:  68%|██████▊   | 180/266 [04:01<01:54,  1.33s/it]Loading trainS:  68%|██████▊   | 181/266 [04:02<01:50,  1.31s/it]Loading trainS:  68%|██████▊   | 182/266 [04:03<01:50,  1.32s/it]Loading trainS:  69%|██████▉   | 183/266 [04:05<01:49,  1.32s/it]Loading trainS:  69%|██████▉   | 184/266 [04:06<01:48,  1.32s/it]Loading trainS:  70%|██████▉   | 185/266 [04:07<01:42,  1.27s/it]Loading trainS:  70%|██████▉   | 186/266 [04:08<01:40,  1.26s/it]Loading trainS:  70%|███████   | 187/266 [04:10<01:41,  1.29s/it]Loading trainS:  71%|███████   | 188/266 [04:11<01:43,  1.32s/it]Loading trainS:  71%|███████   | 189/266 [04:12<01:35,  1.24s/it]Loading trainS:  71%|███████▏  | 190/266 [04:14<01:39,  1.31s/it]Loading trainS:  72%|███████▏  | 191/266 [04:15<01:40,  1.34s/it]Loading trainS:  72%|███████▏  | 192/266 [04:16<01:31,  1.23s/it]Loading trainS:  73%|███████▎  | 193/266 [04:18<01:34,  1.30s/it]Loading trainS:  73%|███████▎  | 194/266 [04:19<01:37,  1.35s/it]Loading trainS:  73%|███████▎  | 195/266 [04:20<01:39,  1.40s/it]Loading trainS:  74%|███████▎  | 196/266 [04:22<01:38,  1.41s/it]Loading trainS:  74%|███████▍  | 197/266 [04:23<01:35,  1.39s/it]Loading trainS:  74%|███████▍  | 198/266 [04:24<01:30,  1.33s/it]Loading trainS:  75%|███████▍  | 199/266 [04:25<01:17,  1.15s/it]Loading trainS:  75%|███████▌  | 200/266 [04:26<01:15,  1.15s/it]Loading trainS:  76%|███████▌  | 201/266 [04:28<01:16,  1.18s/it]Loading trainS:  76%|███████▌  | 202/266 [04:29<01:17,  1.22s/it]Loading trainS:  76%|███████▋  | 203/266 [04:30<01:22,  1.31s/it]Loading trainS:  77%|███████▋  | 204/266 [04:32<01:21,  1.31s/it]Loading trainS:  77%|███████▋  | 205/266 [04:33<01:19,  1.31s/it]Loading trainS:  77%|███████▋  | 206/266 [04:34<01:11,  1.19s/it]Loading trainS:  78%|███████▊  | 207/266 [04:35<01:12,  1.23s/it]Loading trainS:  78%|███████▊  | 208/266 [04:36<01:09,  1.20s/it]Loading trainS:  79%|███████▊  | 209/266 [04:38<01:08,  1.21s/it]Loading trainS:  79%|███████▉  | 210/266 [04:39<01:09,  1.25s/it]Loading trainS:  79%|███████▉  | 211/266 [04:40<01:10,  1.28s/it]Loading trainS:  80%|███████▉  | 212/266 [04:42<01:09,  1.28s/it]Loading trainS:  80%|████████  | 213/266 [04:43<01:07,  1.27s/it]Loading trainS:  80%|████████  | 214/266 [04:44<01:02,  1.19s/it]Loading trainS:  81%|████████  | 215/266 [04:44<00:52,  1.03s/it]Loading trainS:  81%|████████  | 216/266 [04:46<00:56,  1.13s/it]Loading trainS:  82%|████████▏ | 217/266 [04:48<01:05,  1.34s/it]Loading trainS:  82%|████████▏ | 218/266 [04:49<01:04,  1.35s/it]Loading trainS:  82%|████████▏ | 219/266 [04:51<01:04,  1.38s/it]Loading trainS:  83%|████████▎ | 220/266 [04:52<01:00,  1.31s/it]Loading trainS:  83%|████████▎ | 221/266 [04:53<00:57,  1.29s/it]Loading trainS:  83%|████████▎ | 222/266 [04:54<00:56,  1.28s/it]Loading trainS:  84%|████████▍ | 223/266 [04:55<00:49,  1.15s/it]Loading trainS:  84%|████████▍ | 224/266 [04:56<00:50,  1.19s/it]Loading trainS:  85%|████████▍ | 225/266 [04:58<00:50,  1.22s/it]Loading trainS:  85%|████████▍ | 226/266 [04:59<00:48,  1.22s/it]Loading trainS:  85%|████████▌ | 227/266 [05:00<00:50,  1.31s/it]Loading trainS:  86%|████████▌ | 228/266 [05:02<00:53,  1.40s/it]Loading trainS:  86%|████████▌ | 229/266 [05:03<00:53,  1.44s/it]Loading trainS:  86%|████████▋ | 230/266 [05:05<00:49,  1.37s/it]Loading trainS:  87%|████████▋ | 231/266 [05:06<00:50,  1.43s/it]Loading trainS:  87%|████████▋ | 232/266 [05:08<00:48,  1.43s/it]Loading trainS:  88%|████████▊ | 233/266 [05:09<00:45,  1.37s/it]Loading trainS:  88%|████████▊ | 234/266 [05:10<00:42,  1.33s/it]Loading trainS:  88%|████████▊ | 235/266 [05:11<00:39,  1.26s/it]Loading trainS:  89%|████████▊ | 236/266 [05:12<00:37,  1.25s/it]Loading trainS:  89%|████████▉ | 237/266 [05:14<00:35,  1.22s/it]Loading trainS:  89%|████████▉ | 238/266 [05:15<00:36,  1.32s/it]Loading trainS:  90%|████████▉ | 239/266 [05:17<00:36,  1.37s/it]Loading trainS:  90%|█████████ | 240/266 [05:18<00:35,  1.38s/it]Loading trainS:  91%|█████████ | 241/266 [05:19<00:29,  1.19s/it]Loading trainS:  91%|█████████ | 242/266 [05:20<00:29,  1.22s/it]Loading trainS:  91%|█████████▏| 243/266 [05:21<00:27,  1.18s/it]Loading trainS:  92%|█████████▏| 244/266 [05:22<00:25,  1.16s/it]Loading trainS:  92%|█████████▏| 245/266 [05:23<00:23,  1.13s/it]Loading trainS:  92%|█████████▏| 246/266 [05:24<00:20,  1.03s/it]Loading trainS:  93%|█████████▎| 247/266 [05:25<00:19,  1.05s/it]Loading trainS:  93%|█████████▎| 248/266 [05:26<00:18,  1.04s/it]Loading trainS:  94%|█████████▎| 249/266 [05:27<00:17,  1.05s/it]Loading trainS:  94%|█████████▍| 250/266 [05:28<00:16,  1.02s/it]Loading trainS:  94%|█████████▍| 251/266 [05:29<00:15,  1.05s/it]Loading trainS:  95%|█████████▍| 252/266 [05:31<00:14,  1.06s/it]Loading trainS:  95%|█████████▌| 253/266 [05:31<00:12,  1.04it/s]Loading trainS:  95%|█████████▌| 254/266 [05:33<00:13,  1.09s/it]Loading trainS:  96%|█████████▌| 255/266 [05:34<00:12,  1.11s/it]Loading trainS:  96%|█████████▌| 256/266 [05:35<00:10,  1.08s/it]Loading trainS:  97%|█████████▋| 257/266 [05:36<00:09,  1.08s/it]Loading trainS:  97%|█████████▋| 258/266 [05:37<00:07,  1.03it/s]Loading trainS:  97%|█████████▋| 259/266 [05:38<00:06,  1.02it/s]Loading trainS:  98%|█████████▊| 260/266 [05:38<00:05,  1.06it/s]Loading trainS:  98%|█████████▊| 261/266 [05:39<00:04,  1.22it/s]Loading trainS:  98%|█████████▊| 262/266 [05:39<00:02,  1.39it/s]Loading trainS:  99%|█████████▉| 263/266 [05:40<00:01,  1.52it/s]Loading trainS:  99%|█████████▉| 264/266 [05:40<00:01,  1.67it/s]Loading trainS: 100%|█████████▉| 265/266 [05:41<00:00,  1.77it/s]Loading trainS: 100%|██████████| 266/266 [05:41<00:00,  1.77it/s]
Loading testS:   0%|          | 0/5 [00:00<?, ?it/s]Loading testS:  20%|██        | 1/5 [00:00<00:01,  2.20it/s]Loading testS:  40%|████      | 2/5 [00:00<00:01,  2.26it/s]Loading testS:  60%|██████    | 3/5 [00:01<00:00,  2.17it/s]Loading testS:  80%|████████  | 4/5 [00:01<00:00,  2.11it/s]Loading testS: 100%|██████████| 5/5 [00:02<00:00,  2.05it/s]
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  6.02it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:05,  7.18it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.51it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  7.16it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:04,  8.09it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  7.03it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02,  9.11it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.65it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:02,  7.95it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:01,  9.92it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01, 10.31it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01, 10.55it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.39it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.27it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.90it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.93it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  7.67it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 11.15it/s]---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 7  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 7  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
Error in label values min 0.0 max 2.0      1-THALAMUS
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 108, 116, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 108, 116, 20) 200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 108, 116, 20) 80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 108, 116, 20) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 108, 116, 20) 3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 108, 116, 20) 80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 108, 116, 20) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 54, 58, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 54, 58, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 54, 58, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 54, 58, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 54, 58, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 54, 58, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 54, 58, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 54, 58, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 54, 58, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 27, 29, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 27, 29, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 27, 29, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 27, 29, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 27, 29, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 27, 29, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 27, 29, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 27, 29, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 27, 29, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 27, 29, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 54, 58, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 58, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 54, 58, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 54, 58, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 54, 58, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 54, 58, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 54, 58, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 54, 58, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 54, 58, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 54, 58, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 108, 116, 20) 11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 108, 116, 40) 0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 108, 116, 20) 7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 108, 116, 20) 80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 108, 116, 20) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 108, 116, 20) 3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 108, 116, 20) 80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 108, 116, 20) 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 108, 116, 60) 0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 108, 116, 60) 0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 108, 116, 2)  122         dropout_5[0][0]                  
==================================================================================================
Total params: 223,162
Trainable params: 26,802
Non-trainable params: 196,360
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97286605 0.02713395]
Train on 17214 samples, validate on 320 samples
Epoch 1/300
 - 36s - loss: 0.4336 - acc: 0.9432 - mDice: 0.5106 - val_loss: 2.6584 - val_acc: 0.9757 - val_mDice: 0.1214

Epoch 00001: val_mDice improved from -inf to 0.12135, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 32s - loss: 0.1299 - acc: 0.9862 - mDice: 0.7843 - val_loss: 0.7786 - val_acc: 0.9904 - val_mDice: 0.7322

Epoch 00002: val_mDice improved from 0.12135 to 0.73218, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 31s - loss: 0.0992 - acc: 0.9897 - mDice: 0.8259 - val_loss: 0.7266 - val_acc: 0.9917 - val_mDice: 0.7747

Epoch 00003: val_mDice improved from 0.73218 to 0.77474, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 31s - loss: 0.0886 - acc: 0.9906 - mDice: 0.8425 - val_loss: 1.1565 - val_acc: 0.9522 - val_mDice: 0.4741

Epoch 00004: val_mDice did not improve from 0.77474
Epoch 5/300
 - 31s - loss: 0.0840 - acc: 0.9910 - mDice: 0.8499 - val_loss: 0.6383 - val_acc: 0.9924 - val_mDice: 0.7828

Epoch 00005: val_mDice improved from 0.77474 to 0.78282, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 31s - loss: 0.0804 - acc: 0.9914 - mDice: 0.8558 - val_loss: 0.6309 - val_acc: 0.9916 - val_mDice: 0.7611

Epoch 00006: val_mDice did not improve from 0.78282
Epoch 7/300
 - 31s - loss: 0.0776 - acc: 0.9916 - mDice: 0.8603 - val_loss: 0.5660 - val_acc: 0.9925 - val_mDice: 0.7881

Epoch 00007: val_mDice improved from 0.78282 to 0.78810, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 31s - loss: 0.0752 - acc: 0.9918 - mDice: 0.8644 - val_loss: 0.5232 - val_acc: 0.9918 - val_mDice: 0.7690

Epoch 00008: val_mDice did not improve from 0.78810
Epoch 9/300
 - 31s - loss: 0.0735 - acc: 0.9920 - mDice: 0.8673 - val_loss: 0.7402 - val_acc: 0.9916 - val_mDice: 0.7825

Epoch 00009: val_mDice did not improve from 0.78810
Epoch 10/300
 - 31s - loss: 0.0716 - acc: 0.9922 - mDice: 0.8705 - val_loss: 0.5926 - val_acc: 0.9929 - val_mDice: 0.8039

Epoch 00010: val_mDice improved from 0.78810 to 0.80392, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 31s - loss: 0.0707 - acc: 0.9923 - mDice: 0.8721 - val_loss: 1.4273 - val_acc: 0.9845 - val_mDice: 0.4966

Epoch 00011: val_mDice did not improve from 0.80392
Epoch 12/300
 - 31s - loss: 0.0762 - acc: 0.9918 - mDice: 0.8633 - val_loss: 0.4140 - val_acc: 0.9928 - val_mDice: 0.7993

Epoch 00012: val_mDice did not improve from 0.80392
Epoch 13/300
 - 31s - loss: 0.0686 - acc: 0.9924 - mDice: 0.8755 - val_loss: 0.6669 - val_acc: 0.9925 - val_mDice: 0.8007

Epoch 00013: val_mDice did not improve from 0.80392
Epoch 14/300
 - 31s - loss: 0.0675 - acc: 0.9925 - mDice: 0.8773 - val_loss: 0.5000 - val_acc: 0.9897 - val_mDice: 0.6750

Epoch 00014: val_mDice did not improve from 0.80392
Epoch 15/300
 - 31s - loss: 0.0667 - acc: 0.9926 - mDice: 0.8787 - val_loss: 0.3883 - val_acc: 0.9918 - val_mDice: 0.7455

Epoch 00015: val_mDice did not improve from 0.80392
Epoch 16/300
 - 31s - loss: 0.0652 - acc: 0.9927 - mDice: 0.8813 - val_loss: 0.6063 - val_acc: 0.9914 - val_mDice: 0.7325

Epoch 00016: val_mDice did not improve from 0.80392
Epoch 17/300
 - 31s - loss: 0.0649 - acc: 0.9928 - mDice: 0.8818 - val_loss: 0.3563 - val_acc: 0.9930 - val_mDice: 0.8035

Epoch 00017: val_mDice did not improve from 0.80392
Epoch 18/300
 - 32s - loss: 0.0651 - acc: 0.9928 - mDice: 0.8815 - val_loss: 0.5948 - val_acc: 0.9916 - val_mDice: 0.7446

Epoch 00018: val_mDice did not improve from 0.80392
Epoch 19/300
 - 31s - loss: 0.0646 - acc: 0.9928 - mDice: 0.8823 - val_loss: 0.4162 - val_acc: 0.9926 - val_mDice: 0.7945

Epoch 00019: val_mDice did not improve from 0.80392
Epoch 20/300
 - 31s - loss: 0.0642 - acc: 0.9929 - mDice: 0.8830 - val_loss: 0.8189 - val_acc: 0.9899 - val_mDice: 0.7711

Epoch 00020: val_mDice did not improve from 0.80392
Epoch 21/300
 - 31s - loss: 0.0635 - acc: 0.9929 - mDice: 0.8842 - val_loss: 0.7363 - val_acc: 0.9913 - val_mDice: 0.7794

Epoch 00021: val_mDice did not improve from 0.80392
Epoch 22/300
 - 31s - loss: 0.0629 - acc: 0.9930 - mDice: 0.8853 - val_loss: 0.6515 - val_acc: 0.9932 - val_mDice: 0.8071

Epoch 00022: val_mDice improved from 0.80392 to 0.80715, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 23/300
 - 32s - loss: 0.0618 - acc: 0.9930 - mDice: 0.8871 - val_loss: 0.5365 - val_acc: 0.9902 - val_mDice: 0.6935

Epoch 00023: val_mDice did not improve from 0.80715
Epoch 24/300
 - 31s - loss: 0.0614 - acc: 0.9931 - mDice: 0.8878 - val_loss: 0.7063 - val_acc: 0.9911 - val_mDice: 0.7815

Epoch 00024: val_mDice did not improve from 0.80715
Epoch 25/300
 - 31s - loss: 0.0607 - acc: 0.9932 - mDice: 0.8890 - val_loss: 0.6114 - val_acc: 0.9935 - val_mDice: 0.8132

Epoch 00025: val_mDice improved from 0.80715 to 0.81316, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 26/300
 - 31s - loss: 0.0612 - acc: 0.9931 - mDice: 0.8881 - val_loss: 0.4422 - val_acc: 0.9892 - val_mDice: 0.6583

Epoch 00026: val_mDice did not improve from 0.81316
Epoch 27/300
 - 31s - loss: 0.0612 - acc: 0.9931 - mDice: 0.8881 - val_loss: 0.7526 - val_acc: 0.9925 - val_mDice: 0.8091

Epoch 00027: val_mDice did not improve from 0.81316
Epoch 28/300
 - 31s - loss: 0.0596 - acc: 0.9933 - mDice: 0.8909 - val_loss: 0.4640 - val_acc: 0.9919 - val_mDice: 0.7611

Epoch 00028: val_mDice did not improve from 0.81316
Epoch 29/300
 - 31s - loss: 0.0602 - acc: 0.9932 - mDice: 0.8898 - val_loss: 0.3160 - val_acc: 0.9924 - val_mDice: 0.7744

Epoch 00029: val_mDice did not improve from 0.81316
Epoch 30/300
 - 32s - loss: 0.0594 - acc: 0.9933 - mDice: 0.8911 - val_loss: 0.2854 - val_acc: 0.9935 - val_mDice: 0.8156

Epoch 00030: val_mDice improved from 0.81316 to 0.81557, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 31/300
 - 31s - loss: 0.0590 - acc: 0.9933 - mDice: 0.8919 - val_loss: 0.2993 - val_acc: 0.9927 - val_mDice: 0.7864

Epoch 00031: val_mDice did not improve from 0.81557
Epoch 32/300
 - 32s - loss: 0.0587 - acc: 0.9934 - mDice: 0.8924 - val_loss: 0.2631 - val_acc: 0.9933 - val_mDice: 0.8173

Epoch 00032: val_mDice improved from 0.81557 to 0.81732, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 33/300
 - 31s - loss: 0.0580 - acc: 0.9934 - mDice: 0.8937 - val_loss: 0.2770 - val_acc: 0.9917 - val_mDice: 0.7593

Epoch 00033: val_mDice did not improve from 0.81732
Epoch 34/300
 - 31s - loss: 0.0593 - acc: 0.9933 - mDice: 0.8915 - val_loss: 0.5765 - val_acc: 0.9932 - val_mDice: 0.8069

Epoch 00034: val_mDice did not improve from 0.81732
Epoch 35/300
 - 31s - loss: 0.0582 - acc: 0.9934 - mDice: 0.8933 - val_loss: 0.7711 - val_acc: 0.9920 - val_mDice: 0.8056

Epoch 00035: val_mDice did not improve from 0.81732
Epoch 36/300
 - 31s - loss: 0.0579 - acc: 0.9934 - mDice: 0.8938 - val_loss: 0.7566 - val_acc: 0.9926 - val_mDice: 0.7997

Epoch 00036: val_mDice did not improve from 0.81732
Epoch 37/300
 - 31s - loss: 0.0583 - acc: 0.9934 - mDice: 0.8931 - val_loss: 0.2684 - val_acc: 0.9931 - val_mDice: 0.8008

Epoch 00037: val_mDice did not improve from 0.81732
Epoch 38/300
 - 31s - loss: 0.0571 - acc: 0.9935 - mDice: 0.8952 - val_loss: 0.5895 - val_acc: 0.9928 - val_mDice: 0.7883

Epoch 00038: val_mDice did not improve from 0.81732
Epoch 39/300
 - 31s - loss: 0.0576 - acc: 0.9935 - mDice: 0.8944 - val_loss: 0.6945 - val_acc: 0.9935 - val_mDice: 0.8171

Epoch 00039: val_mDice did not improve from 0.81732
Epoch 40/300
 - 31s - loss: 0.0571 - acc: 0.9935 - mDice: 0.8952 - val_loss: 0.6363 - val_acc: 0.9934 - val_mDice: 0.8116

Epoch 00040: val_mDice did not improve from 0.81732
Epoch 41/300
 - 31s - loss: 0.0574 - acc: 0.9935 - mDice: 0.8947 - val_loss: 0.4409 - val_acc: 0.9881 - val_mDice: 0.6238

Epoch 00041: val_mDice did not improve from 0.81732
Epoch 42/300
 - 31s - loss: 0.0569 - acc: 0.9935 - mDice: 0.8956 - val_loss: 0.2102 - val_acc: 0.9930 - val_mDice: 0.8086

Epoch 00042: val_mDice did not improve from 0.81732
Epoch 43/300
 - 31s - loss: 0.0564 - acc: 0.9936 - mDice: 0.8964 - val_loss: 0.7568 - val_acc: 0.9928 - val_mDice: 0.8148

Epoch 00043: val_mDice did not improve from 0.81732
Epoch 44/300
 - 31s - loss: 0.0568 - acc: 0.9936 - mDice: 0.8958 - val_loss: 0.7139 - val_acc: 0.9929 - val_mDice: 0.8132

Epoch 00044: val_mDice did not improve from 0.81732
Epoch 45/300
 - 31s - loss: 0.0565 - acc: 0.9936 - mDice: 0.8962 - val_loss: 0.7689 - val_acc: 0.9915 - val_mDice: 0.7960

Epoch 00045: val_mDice did not improve from 0.81732
Epoch 46/300
 - 31s - loss: 0.0564 - acc: 0.9936 - mDice: 0.8965 - val_loss: 0.2047 - val_acc: 0.9903 - val_mDice: 0.7002

Epoch 00046: val_mDice did not improve from 0.81732
Epoch 47/300
 - 31s - loss: 0.0566 - acc: 0.9936 - mDice: 0.8963 - val_loss: 0.1378 - val_acc: 0.9931 - val_mDice: 0.7996

Epoch 00047: val_mDice did not improve from 0.81732
Epoch 48/300
 - 31s - loss: 0.0579 - acc: 0.9935 - mDice: 0.8939 - val_loss: 0.8256 - val_acc: 0.9890 - val_mDice: 0.7612

Epoch 00048: val_mDice did not improve from 0.81732
Epoch 49/300
 - 31s - loss: 0.0559 - acc: 0.9936 - mDice: 0.8973 - val_loss: 0.7029 - val_acc: 0.9929 - val_mDice: 0.8139

Epoch 00049: val_mDice did not improve from 0.81732
Epoch 50/300
 - 31s - loss: 0.0561 - acc: 0.9936 - mDice: 0.8969 - val_loss: 0.3119 - val_acc: 0.9926 - val_mDice: 0.7812

Epoch 00050: val_mDice did not improve from 0.81732
Epoch 51/300
 - 31s - loss: 0.0553 - acc: 0.9937 - mDice: 0.8984 - val_loss: 0.1273 - val_acc: 0.9933 - val_mDice: 0.8091

Epoch 00051: val_mDice did not improve from 0.81732
Epoch 52/300
 - 31s - loss: 0.0549 - acc: 0.9937 - mDice: 0.8991 - val_loss: 0.5959 - val_acc: 0.9922 - val_mDice: 0.7615

Epoch 00052: val_mDice did not improve from 0.81732
Epoch 53/300
 - 31s - loss: 0.0557 - acc: 0.9937 - mDice: 0.8976 - val_loss: 0.7495 - val_acc: 0.9931 - val_mDice: 0.8176

Epoch 00053: val_mDice improved from 0.81732 to 0.81764, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 54/300
 - 32s - loss: 0.0554 - acc: 0.9937 - mDice: 0.8982 - val_loss: 0.7166 - val_acc: 0.9932 - val_mDice: 0.8178

Epoch 00054: val_mDice improved from 0.81764 to 0.81783, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 55/300
 - 32s - loss: 0.0553 - acc: 0.9937 - mDice: 0.8984 - val_loss: 0.7738 - val_acc: 0.9911 - val_mDice: 0.7904

Epoch 00055: val_mDice did not improve from 0.81783
Epoch 56/300
 - 31s - loss: 0.0555 - acc: 0.9937 - mDice: 0.8980 - val_loss: 0.7237 - val_acc: 0.9932 - val_mDice: 0.8165

Epoch 00056: val_mDice did not improve from 0.81783
Epoch 57/300
 - 31s - loss: 0.0554 - acc: 0.9937 - mDice: 0.8981 - val_loss: 0.2701 - val_acc: 0.9911 - val_mDice: 0.7275

Epoch 00057: val_mDice did not improve from 0.81783
Epoch 58/300
 - 31s - loss: 0.0548 - acc: 0.9938 - mDice: 0.8992 - val_loss: 0.0830 - val_acc: 0.9926 - val_mDice: 0.7778

Epoch 00058: val_mDice did not improve from 0.81783
Epoch 59/300
 - 32s - loss: 0.0545 - acc: 0.9938 - mDice: 0.8997 - val_loss: 0.1148 - val_acc: 0.9918 - val_mDice: 0.7516

Epoch 00059: val_mDice did not improve from 0.81783
Epoch 60/300
 - 31s - loss: 0.0545 - acc: 0.9938 - mDice: 0.8998 - val_loss: 0.7029 - val_acc: 0.9929 - val_mDice: 0.7986

Epoch 00060: val_mDice did not improve from 0.81783
Epoch 61/300
 - 31s - loss: 0.0549 - acc: 0.9937 - mDice: 0.8990 - val_loss: 0.2632 - val_acc: 0.9902 - val_mDice: 0.6925

Epoch 00061: val_mDice did not improve from 0.81783
Epoch 62/300
 - 32s - loss: 0.0545 - acc: 0.9938 - mDice: 0.8998 - val_loss: 0.6447 - val_acc: 0.9937 - val_mDice: 0.8200

Epoch 00062: val_mDice improved from 0.81783 to 0.82000, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 63/300
 - 31s - loss: 0.0548 - acc: 0.9938 - mDice: 0.8993 - val_loss: 0.7833 - val_acc: 0.9917 - val_mDice: 0.8023

Epoch 00063: val_mDice did not improve from 0.82000
Epoch 64/300
 - 31s - loss: 0.0544 - acc: 0.9938 - mDice: 0.9000 - val_loss: 0.5032 - val_acc: 0.9930 - val_mDice: 0.7955

Epoch 00064: val_mDice did not improve from 0.82000
Epoch 65/300
 - 31s - loss: 0.0540 - acc: 0.9938 - mDice: 0.9006 - val_loss: 0.7658 - val_acc: 0.9904 - val_mDice: 0.7742

Epoch 00065: val_mDice did not improve from 0.82000
Epoch 66/300
 - 31s - loss: 0.0541 - acc: 0.9938 - mDice: 0.9005 - val_loss: 0.7104 - val_acc: 0.9936 - val_mDice: 0.8224

Epoch 00066: val_mDice improved from 0.82000 to 0.82244, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 67/300
 - 31s - loss: 0.0539 - acc: 0.9938 - mDice: 0.9008 - val_loss: 0.1558 - val_acc: 0.9923 - val_mDice: 0.7656

Epoch 00067: val_mDice did not improve from 0.82244
Epoch 68/300
 - 31s - loss: 0.0538 - acc: 0.9938 - mDice: 0.9010 - val_loss: 0.7849 - val_acc: 0.9925 - val_mDice: 0.8079

Epoch 00068: val_mDice did not improve from 0.82244
Epoch 69/300
 - 31s - loss: 0.0540 - acc: 0.9938 - mDice: 0.9007 - val_loss: 0.7575 - val_acc: 0.9922 - val_mDice: 0.8072

Epoch 00069: val_mDice did not improve from 0.82244
Epoch 70/300
 - 31s - loss: 0.0535 - acc: 0.9939 - mDice: 0.9016 - val_loss: 0.6785 - val_acc: 0.9934 - val_mDice: 0.8197

Epoch 00070: val_mDice did not improve from 0.82244
Epoch 71/300
 - 31s - loss: 0.0532 - acc: 0.9939 - mDice: 0.9021 - val_loss: 0.7474 - val_acc: 0.9926 - val_mDice: 0.8118

Epoch 00071: val_mDice did not improve from 0.82244
Epoch 72/300
 - 31s - loss: 0.0532 - acc: 0.9939 - mDice: 0.9020 - val_loss: 0.1597 - val_acc: 0.9917 - val_mDice: 0.7443

Epoch 00072: val_mDice did not improve from 0.82244
Epoch 73/300
 - 31s - loss: 0.0533 - acc: 0.9939 - mDice: 0.9018 - val_loss: 0.6076 - val_acc: 0.9935 - val_mDice: 0.8114

Epoch 00073: val_mDice did not improve from 0.82244
Epoch 74/300
 - 31s - loss: 0.0529 - acc: 0.9939 - mDice: 0.9025 - val_loss: 0.7184 - val_acc: 0.9934 - val_mDice: 0.8188

Epoch 00074: val_mDice did not improve from 0.82244
Epoch 75/300
 - 31s - loss: 0.0535 - acc: 0.9939 - mDice: 0.9015 - val_loss: 0.4401 - val_acc: 0.9932 - val_mDice: 0.8001

Epoch 00075: val_mDice did not improve from 0.82244
Epoch 76/300
 - 31s - loss: 0.0529 - acc: 0.9939 - mDice: 0.9025 - val_loss: 0.7149 - val_acc: 0.9935 - val_mDice: 0.8221

Epoch 00076: val_mDice did not improve from 0.82244
Epoch 77/300
 - 31s - loss: 0.0528 - acc: 0.9939 - mDice: 0.9026 - val_loss: 0.6866 - val_acc: 0.9933 - val_mDice: 0.8120

Epoch 00077: val_mDice did not improve from 0.82244
Epoch 78/300
 - 31s - loss: 0.0532 - acc: 0.9939 - mDice: 0.9020 - val_loss: 0.6009 - val_acc: 0.9934 - val_mDice: 0.8139

Epoch 00078: val_mDice did not improve from 0.82244
Epoch 79/300
 - 31s - loss: 0.0528 - acc: 0.9939 - mDice: 0.9026 - val_loss: 0.7001 - val_acc: 0.9934 - val_mDice: 0.8124

Epoch 00079: val_mDice did not improve from 0.82244
Epoch 80/300
 - 31s - loss: 0.0528 - acc: 0.9939 - mDice: 0.9027 - val_loss: 0.7573 - val_acc: 0.9928 - val_mDice: 0.8158

Epoch 00080: val_mDice did not improve from 0.82244
Epoch 81/300
 - 31s - loss: 0.0530 - acc: 0.9939 - mDice: 0.9023 - val_loss: 0.7034 - val_acc: 0.9933 - val_mDice: 0.8179

Epoch 00081: val_mDice did not improve from 0.82244
Epoch 82/300
 - 31s - loss: 0.0525 - acc: 0.9940 - mDice: 0.9033 - val_loss: 0.7191 - val_acc: 0.9935 - val_mDice: 0.8209

Epoch 00082: val_mDice did not improve from 0.82244
Epoch 83/300
 - 31s - loss: 0.0522 - acc: 0.9940 - mDice: 0.9037 - val_loss: 0.7748 - val_acc: 0.9918 - val_mDice: 0.8034

Epoch 00083: val_mDice did not improve from 0.82244
Epoch 84/300
 - 31s - loss: 0.0526 - acc: 0.9940 - mDice: 0.9031 - val_loss: 0.2671 - val_acc: 0.9922 - val_mDice: 0.7626

Epoch 00084: val_mDice did not improve from 0.82244
Epoch 85/300
 - 31s - loss: 0.0523 - acc: 0.9940 - mDice: 0.9036 - val_loss: 0.6965 - val_acc: 0.9939 - val_mDice: 0.8273

Epoch 00085: val_mDice improved from 0.82244 to 0.82732, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 86/300
 - 31s - loss: 0.0521 - acc: 0.9940 - mDice: 0.9040 - val_loss: 0.7177 - val_acc: 0.9934 - val_mDice: 0.8172

Epoch 00086: val_mDice did not improve from 0.82732
Epoch 87/300
 - 31s - loss: 0.0523 - acc: 0.9940 - mDice: 0.9035 - val_loss: 0.6255 - val_acc: 0.9930 - val_mDice: 0.7948

Epoch 00087: val_mDice did not improve from 0.82732
Epoch 88/300
 - 31s - loss: 0.0522 - acc: 0.9940 - mDice: 0.9038 - val_loss: 0.6862 - val_acc: 0.9937 - val_mDice: 0.8244

Epoch 00088: val_mDice did not improve from 0.82732
Epoch 89/300
 - 31s - loss: 0.0518 - acc: 0.9940 - mDice: 0.9044 - val_loss: 0.7927 - val_acc: 0.9917 - val_mDice: 0.7977

Epoch 00089: val_mDice did not improve from 0.82732
Epoch 90/300
 - 31s - loss: 0.0520 - acc: 0.9940 - mDice: 0.9041 - val_loss: 0.5638 - val_acc: 0.9932 - val_mDice: 0.8015

Epoch 00090: val_mDice did not improve from 0.82732
Epoch 91/300
 - 32s - loss: 0.0521 - acc: 0.9940 - mDice: 0.9040 - val_loss: 0.4833 - val_acc: 0.9927 - val_mDice: 0.7928

Epoch 00091: val_mDice did not improve from 0.82732
Epoch 92/300
 - 31s - loss: 0.0512 - acc: 0.9941 - mDice: 0.9055 - val_loss: 0.6772 - val_acc: 0.9935 - val_mDice: 0.8203

Epoch 00092: val_mDice did not improve from 0.82732
Epoch 93/300
 - 31s - loss: 0.0516 - acc: 0.9940 - mDice: 0.9048 - val_loss: 0.6618 - val_acc: 0.9936 - val_mDice: 0.8158

Epoch 00093: val_mDice did not improve from 0.82732
Epoch 94/300
 - 31s - loss: 0.0513 - acc: 0.9941 - mDice: 0.9053 - val_loss: 0.5320 - val_acc: 0.9936 - val_mDice: 0.8097

Epoch 00094: val_mDice did not improve from 0.82732
Epoch 95/300
 - 31s - loss: 0.0516 - acc: 0.9941 - mDice: 0.9048 - val_loss: 0.7818 - val_acc: 0.9918 - val_mDice: 0.8053

Epoch 00095: val_mDice did not improve from 0.82732
Epoch 96/300
 - 31s - loss: 0.0514 - acc: 0.9941 - mDice: 0.9052 - val_loss: 0.6733 - val_acc: 0.9937 - val_mDice: 0.8177

Epoch 00096: val_mDice did not improve from 0.82732
Epoch 97/300
 - 31s - loss: 0.0513 - acc: 0.9941 - mDice: 0.9053 - val_loss: 0.6736 - val_acc: 0.9935 - val_mDice: 0.8196

Epoch 00097: val_mDice did not improve from 0.82732
Epoch 98/300
 - 31s - loss: 0.0512 - acc: 0.9941 - mDice: 0.9055 - val_loss: 0.7368 - val_acc: 0.9930 - val_mDice: 0.8152

Epoch 00098: val_mDice did not improve from 0.82732
Epoch 99/300
 - 31s - loss: 0.0517 - acc: 0.9940 - mDice: 0.9046 - val_loss: 0.7193 - val_acc: 0.9933 - val_mDice: 0.8175

Epoch 00099: val_mDice did not improve from 0.82732
Epoch 100/300
 - 31s - loss: 0.0512 - acc: 0.9941 - mDice: 0.9054 - val_loss: 0.8659 - val_acc: 0.9859 - val_mDice: 0.7310

Epoch 00100: val_mDice did not improve from 0.82732
Epoch 101/300
 - 31s - loss: 0.0507 - acc: 0.9941 - mDice: 0.9064 - val_loss: 0.6740 - val_acc: 0.9937 - val_mDice: 0.8224

Epoch 00101: val_mDice did not improve from 0.82732
Epoch 102/300
 - 31s - loss: 0.0514 - acc: 0.9941 - mDice: 0.9052 - val_loss: 0.3350 - val_acc: 0.9931 - val_mDice: 0.7963

Epoch 00102: val_mDice did not improve from 0.82732
Epoch 103/300
 - 31s - loss: 0.0511 - acc: 0.9941 - mDice: 0.9057 - val_loss: 0.5935 - val_acc: 0.9881 - val_mDice: 0.6260

Epoch 00103: val_mDice did not improve from 0.82732
Epoch 104/300
 - 31s - loss: 0.0508 - acc: 0.9941 - mDice: 0.9062 - val_loss: 0.5065 - val_acc: 0.9933 - val_mDice: 0.8057

Epoch 00104: val_mDice did not improve from 0.82732
Epoch 105/300
 - 31s - loss: 0.0508 - acc: 0.9941 - mDice: 0.9062 - val_loss: 0.5492 - val_acc: 0.9934 - val_mDice: 0.8211

Epoch 00105: val_mDice did not improve from 0.82732
Epoch 106/300
 - 31s - loss: 0.0512 - acc: 0.9941 - mDice: 0.9055 - val_loss: 0.4227 - val_acc: 0.9911 - val_mDice: 0.7189

Epoch 00106: val_mDice did not improve from 0.82732
Epoch 107/300
 - 31s - loss: 0.0504 - acc: 0.9942 - mDice: 0.9070 - val_loss: 0.5823 - val_acc: 0.9935 - val_mDice: 0.8212

Epoch 00107: val_mDice did not improve from 0.82732
Epoch 108/300
 - 31s - loss: 0.0502 - acc: 0.9942 - mDice: 0.9073 - val_loss: 0.6649 - val_acc: 0.9936 - val_mDice: 0.8245

Epoch 00108: val_mDice did not improve from 0.82732
Epoch 109/300
 - 31s - loss: 0.0504 - acc: 0.9941 - mDice: 0.9069 - val_loss: 0.6119 - val_acc: 0.9936 - val_mDice: 0.8201

Epoch 00109: val_mDice did not improve from 0.82732
Epoch 110/300
 - 31s - loss: 0.0510 - acc: 0.9941 - mDice: 0.9059 - val_loss: 0.6445 - val_acc: 0.9936 - val_mDice: 0.8222

Epoch 00110: val_mDice did not improve from 0.82732
Epoch 111/300
 - 31s - loss: 0.0505 - acc: 0.9941 - mDice: 0.9068 - val_loss: 0.6773 - val_acc: 0.9936 - val_mDice: 0.8217

Epoch 00111: val_mDice did not improve from 0.82732
Epoch 112/300
 - 32s - loss: 0.0505 - acc: 0.9942 - mDice: 0.9068 - val_loss: 0.3953 - val_acc: 0.9929 - val_mDice: 0.7882

Epoch 00112: val_mDice did not improve from 0.82732
Epoch 113/300
 - 31s - loss: 0.0501 - acc: 0.9942 - mDice: 0.9074 - val_loss: 0.3618 - val_acc: 0.9930 - val_mDice: 0.7909

Epoch 00113: val_mDice did not improve from 0.82732
Epoch 114/300
 - 30s - loss: 0.0501 - acc: 0.9942 - mDice: 0.9075 - val_loss: 0.6134 - val_acc: 0.9935 - val_mDice: 0.8156

Epoch 00114: val_mDice did not improve from 0.82732
Epoch 115/300
 - 30s - loss: 0.0503 - acc: 0.9942 - mDice: 0.9070 - val_loss: 0.7608 - val_acc: 0.9921 - val_mDice: 0.8089

Epoch 00115: val_mDice did not improve from 0.82732
Epoch 116/300
 - 31s - loss: 0.0505 - acc: 0.9941 - mDice: 0.9067 - val_loss: 0.6151 - val_acc: 0.9937 - val_mDice: 0.8225

Epoch 00116: val_mDice did not improve from 0.82732
Epoch 117/300
 - 31s - loss: 0.0507 - acc: 0.9941 - mDice: 0.9064 - val_loss: 0.8365 - val_acc: 0.9888 - val_mDice: 0.7647

Epoch 00117: val_mDice did not improve from 0.82732
Epoch 118/300
 - 30s - loss: 0.0500 - acc: 0.9942 - mDice: 0.9076 - val_loss: 0.5846 - val_acc: 0.9934 - val_mDice: 0.8128

Epoch 00118: val_mDice did not improve from 0.82732
Epoch 119/300
 - 30s - loss: 0.0504 - acc: 0.9941 - mDice: 0.9070 - val_loss: 0.7348 - val_acc: 0.9934 - val_mDice: 0.8238

Epoch 00119: val_mDice did not improve from 0.82732
Epoch 120/300
 - 31s - loss: 0.0502 - acc: 0.9942 - mDice: 0.9073 - val_loss: 0.2585 - val_acc: 0.9920 - val_mDice: 0.7562

Epoch 00120: val_mDice did not improve from 0.82732
Epoch 121/300
 - 31s - loss: 0.0498 - acc: 0.9942 - mDice: 0.9080 - val_loss: 0.4224 - val_acc: 0.9911 - val_mDice: 0.7327

Epoch 00121: val_mDice did not improve from 0.82732
Epoch 122/300
 - 30s - loss: 0.0498 - acc: 0.9942 - mDice: 0.9080 - val_loss: 0.8012 - val_acc: 0.9914 - val_mDice: 0.7986

Epoch 00122: val_mDice did not improve from 0.82732
Epoch 123/300
 - 30s - loss: 0.0500 - acc: 0.9942 - mDice: 0.9077 - val_loss: 0.1785 - val_acc: 0.9931 - val_mDice: 0.8001

Epoch 00123: val_mDice did not improve from 0.82732
Epoch 124/300
 - 31s - loss: 0.0496 - acc: 0.9942 - mDice: 0.9083 - val_loss: 0.2599 - val_acc: 0.9938 - val_mDice: 0.8217

Epoch 00124: val_mDice did not improve from 0.82732
Epoch 125/300
 - 31s - loss: 0.0493 - acc: 0.9942 - mDice: 0.9088 - val_loss: 0.6545 - val_acc: 0.9936 - val_mDice: 0.8225

Epoch 00125: val_mDice did not improve from 0.82732
Restoring model weights from the end of the best epoch
Epoch 00125: early stopping
{'val_loss': [2.658412331715226, 0.7786414793226868, 0.7265685725724325, 1.1564833975862712, 0.6383247044868767, 0.6309242708375677, 0.5659900393802673, 0.5231877561891451, 0.7402369066840038, 0.5926335831172764, 1.427321678493172, 0.4140066960826516, 0.6669220903422683, 0.4999704951187596, 0.3882672187173739, 0.6063222949160263, 0.3563247794518247, 0.594842214602977, 0.41615510371048003, 0.8188545003067702, 0.7362996859010309, 0.65145659877453, 0.5364979626610875, 0.7062691386090592, 0.6114384103566408, 0.4422298700083047, 0.7526007674168795, 0.46396086108870804, 0.3159698183881119, 0.2854146060999483, 0.2992942719720304, 0.2630849576089531, 0.27697735861875117, 0.576491292216815, 0.7710945386206731, 0.7566175219835714, 0.2684225357370451, 0.5895442251348868, 0.6945032528601587, 0.6363182157510892, 0.4408840610412881, 0.21019392285961658, 0.7568355040857568, 0.713895094813779, 0.7688693255186081, 0.20465870457701385, 0.13776764494832605, 0.8255805296357721, 0.7029244872974232, 0.31189512799028307, 0.12731823197100312, 0.5959435944678262, 0.7494927002117038, 0.7165782229276374, 0.7737871997524053, 0.7236909337807447, 0.2700526373228058, 0.08301016758196056, 0.1148161863675341, 0.7028865533648059, 0.2632017055293545, 0.644708636100404, 0.7833327498519793, 0.5032398699549958, 0.7658328110119328, 0.7103766429936513, 0.15584053751081228, 0.7849464054452255, 0.7575023378012702, 0.678453647880815, 0.7473783233435825, 0.15968932560645044, 0.6076011697296053, 0.7184343952685595, 0.4400666969595477, 0.7148649604059756, 0.6865988377248868, 0.600908693857491, 0.7001389610813931, 0.7573001423152164, 0.7033702057087794, 0.7190555793931708, 0.7748017964186147, 0.267063781269826, 0.6965140618849546, 0.7177068860037252, 0.6255405421834439, 0.6862401376711205, 0.7926679070806131, 0.5637713398318738, 0.483348366105929, 0.6772109604207799, 0.6618485735962167, 0.5319905772339553, 0.7818067530170083, 0.6733120428398252, 0.673613469582051, 0.7367763726506382, 0.7192825165111572, 0.8658638966735452, 0.6740184151567519, 0.3349785692989826, 0.5934885042952374, 0.5065462256316096, 0.5492433345643803, 0.4226577798835933, 0.5822753884131089, 0.6648597202729434, 0.6118621968198568, 0.644506769371219, 0.6772932480089366, 0.3953488451661542, 0.3618409908376634, 0.6134390220977366, 0.7607680216897279, 0.6151235882425681, 0.8364584959344938, 0.584595226100646, 0.7347578592598438, 0.25848266668617725, 0.4224131191149354, 0.8012073840945959, 0.17851825861725956, 0.2598656228510663, 0.6545233518118039], 'val_acc': [0.9756732489913702, 0.99039626121521, 0.9917215537279844, 0.9521683994680643, 0.9924107566475868, 0.9915531780570745, 0.9924768507480621, 0.9918442685157061, 0.9915821105241776, 0.9929320681840181, 0.9844603147357702, 0.992825323715806, 0.9924935679882765, 0.9896696396172047, 0.9917671922594309, 0.9913835637271404, 0.993016142398119, 0.991643225774169, 0.9926020670682192, 0.9898884017020464, 0.9913077279925346, 0.9932019729167223, 0.9902490805834532, 0.9910517875105143, 0.9934733714908361, 0.9892109259963036, 0.9925017934292555, 0.9919290840625763, 0.9924429226666689, 0.9935122858732939, 0.9927100725471973, 0.9933446571230888, 0.9916896130889654, 0.9931820333003998, 0.9920004196465015, 0.9926339965313673, 0.993135379627347, 0.992838803678751, 0.9935334902256727, 0.9933915324509144, 0.9880914110690355, 0.9929926916956902, 0.9928333126008511, 0.9929001461714506, 0.9914563894271851, 0.990307716652751, 0.9930854979902506, 0.9889562409371138, 0.9928964115679264, 0.9925676453858614, 0.9933005031198263, 0.9921677950769663, 0.9930864907801151, 0.9932092074304819, 0.9910879675298929, 0.9932341650128365, 0.9910547863692045, 0.99260731972754, 0.9917781632393599, 0.9928567670285702, 0.9902343656867743, 0.9936502315104008, 0.9916554465889931, 0.993037099018693, 0.990415470674634, 0.9935778882354498, 0.9923269264400005, 0.992487832903862, 0.9922423716634512, 0.993376825004816, 0.9925763756036758, 0.9917060788720846, 0.9935282431542873, 0.9933683648705482, 0.9931665696203709, 0.9935409799218178, 0.993330692872405, 0.9934476781636477, 0.9933997821062803, 0.9928385522216558, 0.9933154731988907, 0.993469376116991, 0.9918200671672821, 0.9922171887010336, 0.9939038977026939, 0.9934247471392155, 0.9930016826838255, 0.9937477614730597, 0.9917050767689943, 0.9932194408029318, 0.9927464984357357, 0.9935132842510939, 0.9935641698539257, 0.9935726467519999, 0.9918001089245081, 0.9937130846083164, 0.9935449622571468, 0.9929994344711304, 0.9932668302208185, 0.9858794007450342, 0.9936921279877424, 0.9931156728416681, 0.9880998954176903, 0.9933194573968649, 0.9933538921177387, 0.9911031872034073, 0.9935037977993488, 0.9935978278517723, 0.9936192780733109, 0.9936322644352913, 0.9935556929558516, 0.9929031450301409, 0.9929505437612534, 0.9934815894812346, 0.9921426009386778, 0.993671927601099, 0.9887783844023943, 0.9934070091694593, 0.9934297185391188, 0.992000674828887, 0.9911263789981604, 0.9914321843534708, 0.9931124225258827, 0.9938018806278706, 0.9936093091964722], 'val_mDice': [0.1213545171884789, 0.7321823015809059, 0.7747419737279415, 0.4740931373089552, 0.7828246988356113, 0.7611079700291157, 0.7880995608866215, 0.7689720951020718, 0.7824805472046137, 0.8039191551506519, 0.4966466115934054, 0.7993014995008707, 0.8006800338625908, 0.6749970116652548, 0.7454797113314271, 0.732487253844738, 0.8035319950431585, 0.7445791224017739, 0.794474771246314, 0.7710808049887419, 0.779434647411108, 0.8071487676352262, 0.6934826704673469, 0.7814970333129168, 0.8131570369005203, 0.6582573964260519, 0.8091071993112564, 0.7611099071800709, 0.7743971236050129, 0.8155666571110487, 0.7864218484610319, 0.8173239696770906, 0.7593343406915665, 0.8068919461220503, 0.8055894169956446, 0.7997446227818727, 0.8007741067558527, 0.7883206196129322, 0.8170795347541571, 0.8116238005459309, 0.6238412321545184, 0.8086113352328539, 0.81479930318892, 0.8132493123412132, 0.7959501259028912, 0.7002170570194721, 0.7995757088065147, 0.7611659541726112, 0.813941303640604, 0.7812218740582466, 0.8090654667466879, 0.7615148229524493, 0.8176426962018013, 0.8178322482854128, 0.7903795130550861, 0.8164605963975191, 0.7274569105356932, 0.7777738943696022, 0.7515774853527546, 0.7986072916537523, 0.6925488985143602, 0.8199984766542912, 0.8023388404399157, 0.7955373544245958, 0.7742205914109945, 0.8224390726536512, 0.7655581412836909, 0.8079268410801888, 0.8072458673268557, 0.8197094965726137, 0.811823233962059, 0.7442670408636332, 0.8113576006144285, 0.8187988493591547, 0.8000781014561653, 0.8221351355314255, 0.8119714260101318, 0.8139240741729736, 0.8123908471316099, 0.8158388920128345, 0.8178695850074291, 0.8209453336894512, 0.8033506479114294, 0.7626408245414495, 0.8273166697472334, 0.8172109816223383, 0.7948415726423264, 0.8244286198168993, 0.7976875361055136, 0.8014888036996126, 0.7927929796278477, 0.820264145731926, 0.8157602977007627, 0.8097027335315943, 0.8052953239530325, 0.8176959585398436, 0.819645868614316, 0.815233550965786, 0.8174865040928125, 0.730998357757926, 0.8223677147179842, 0.7963121123611927, 0.626036023022607, 0.8056909404695034, 0.8211198821663857, 0.7189283845946193, 0.8212356735020876, 0.8244650717824697, 0.820101834833622, 0.8221753593534231, 0.8216689806431532, 0.7882132567465305, 0.7909196615219116, 0.8155859354883432, 0.8089097402989864, 0.822466341778636, 0.7647458557039499, 0.8127921726554632, 0.8238119911402464, 0.7562085846439004, 0.7326998794451356, 0.7985961064696312, 0.800116304308176, 0.8216505125164986, 0.8224648330360651], 'loss': [0.43356658453477775, 0.1299018060737223, 0.09922357716131144, 0.0885530006678467, 0.08397550003927068, 0.08036533761537974, 0.07763802717392544, 0.07519412338750986, 0.07348429489341073, 0.0715637373896728, 0.07068213227016593, 0.07621049526544334, 0.06857228287034393, 0.0675157136493192, 0.06671026812748819, 0.0651732540731717, 0.06486896286333661, 0.06505345546624117, 0.0646249241927844, 0.0641694209129709, 0.06350315169090315, 0.06286015251913912, 0.06179177089772519, 0.06140042513139755, 0.06067813637019229, 0.061239973702202334, 0.06118921243001446, 0.059612297065719654, 0.06023870025791398, 0.05944252540903306, 0.05902491627425298, 0.05873913971002376, 0.057961432064806695, 0.05926114213718373, 0.0582198575351128, 0.05788675348362164, 0.058309710929863846, 0.05712241846801887, 0.057586340359850906, 0.05712276810211657, 0.057417768563465386, 0.056905216217020244, 0.05642745068288783, 0.05676460190715864, 0.05654217536306151, 0.05638129674517154, 0.0566017421918338, 0.057892743091235196, 0.05588596940353951, 0.056131053242438125, 0.05529209769560206, 0.05485276789801024, 0.05570579947436522, 0.05536406146250107, 0.05527178117421303, 0.055473600866224784, 0.05544569813328794, 0.05480355084499887, 0.05449674592466045, 0.05451050415449862, 0.05492224569909731, 0.054478414225130944, 0.05475342143995706, 0.0543766365920755, 0.053983844418056585, 0.05408178356643738, 0.05388267844113805, 0.053797366812373335, 0.05398233966436399, 0.053453468824216845, 0.05317248050887382, 0.05320991160685874, 0.05332546710857215, 0.052934329240451196, 0.053501022163965954, 0.05290881780844969, 0.05284383757929568, 0.053184383978262806, 0.05283630530546735, 0.05282556882146081, 0.05304692788658774, 0.05245549489296146, 0.05224708134969159, 0.05261244942327334, 0.05228552643646412, 0.05206730089362343, 0.05233518837275815, 0.05215974278904716, 0.051838458456948226, 0.05201485877235731, 0.05206292690593454, 0.05123400543349482, 0.051614628424988096, 0.05133794605397826, 0.051602233097388296, 0.05137203500476382, 0.05131284412950108, 0.05124508192003348, 0.051735190111346065, 0.051245547074487405, 0.05070124101532147, 0.051390434181302756, 0.05108186654660834, 0.050805927203294916, 0.05081861340607987, 0.05123037249204782, 0.050383166059119314, 0.050176009669531174, 0.05040620254904319, 0.05097034856187102, 0.05047716979342941, 0.05047646476135681, 0.05011754248785103, 0.05005151204495628, 0.050337611544287356, 0.05052999036211966, 0.05069752474154996, 0.05000427674943179, 0.05038546413257657, 0.050234231899199316, 0.04981005370384921, 0.04980936987264738, 0.04996783631507827, 0.04964026581183071, 0.04934270295475825], 'acc': [0.9432287672275974, 0.9861573330461598, 0.9897371717580757, 0.9906420625362771, 0.9910265972379665, 0.9913928962285695, 0.9916160131243168, 0.9918172322832584, 0.9919972766480325, 0.9921506915176124, 0.9922710961133218, 0.9917951754068295, 0.9924345547498914, 0.9925232975895956, 0.9925961278312309, 0.99273052003113, 0.9927819910483783, 0.9927654625564222, 0.9928284311136663, 0.992855135795061, 0.9929253654750337, 0.9930034495402784, 0.9930488546440046, 0.9931111989833481, 0.9931711170874753, 0.9931272837887717, 0.9931374120770451, 0.9932860566152296, 0.9932306157915216, 0.993307729326669, 0.9933353459792117, 0.9933502868352846, 0.9934179826980547, 0.9933238058150043, 0.9934278655525864, 0.9934359095411543, 0.993419926043544, 0.9935220641043871, 0.9934903607490906, 0.9935293666394286, 0.9934907973858348, 0.993540931928029, 0.9936063784997305, 0.9935641458769411, 0.9935821105520581, 0.9936061266740883, 0.9936102230858828, 0.9934642196837321, 0.9936492158600133, 0.9936398357080225, 0.9937075920757051, 0.9937211537701862, 0.9936713716689338, 0.9936969761193609, 0.9936896135226156, 0.9936962427682434, 0.9936983203090164, 0.9937667637332829, 0.9937615615504121, 0.9937760778887286, 0.9937338968582016, 0.9937655086355008, 0.9937721598892105, 0.9937950899560263, 0.9938157669021732, 0.9938017216393019, 0.9938173766915662, 0.9938413535619262, 0.9938153594410266, 0.9938508641142262, 0.993876497851053, 0.9938958256768476, 0.9938838104621672, 0.9939094480078188, 0.9938673309932481, 0.9939287287080636, 0.9939306763679125, 0.9939278163421829, 0.9939334993857158, 0.9939079965062572, 0.9939199331968216, 0.9939530750413493, 0.9939680134182236, 0.9939648468167271, 0.9939761187565704, 0.9939943144680717, 0.9939697406371463, 0.9939863149250261, 0.9940345677623658, 0.9940174391519819, 0.994029073560364, 0.9940580141811652, 0.994039724814126, 0.9940529308682523, 0.9940539551928053, 0.9940787635434584, 0.9940933011073164, 0.994079348018004, 0.9940330253891708, 0.994082113848035, 0.9941199404846796, 0.994092704160601, 0.9940915521988681, 0.9941127211689963, 0.9941197915111558, 0.9940757635676571, 0.9941595486679379, 0.9941621742985923, 0.9941387114464454, 0.9941109725998796, 0.9941234975391887, 0.9941515182803369, 0.9941859304925713, 0.9941939468983229, 0.9941577355357791, 0.9941325488303255, 0.9941350986792178, 0.9942150056895388, 0.9941490568238794, 0.9941740176798756, 0.9942013594876242, 0.9942147396742931, 0.9941874646871808, 0.9942391538185097, 0.9942445959365643], 'mDice': [0.5105891577422055, 0.7843453141265427, 0.8258946133335805, 0.8425119730727354, 0.8498756977355867, 0.8558299162599203, 0.8603260142747514, 0.8644029940408712, 0.867261075933345, 0.8704880468518778, 0.8721223081205314, 0.8633017254385422, 0.875514600229025, 0.8773494736857707, 0.8787361734126993, 0.8813198478542943, 0.8818380663283295, 0.8815496776236105, 0.8822549640183611, 0.8830398557229616, 0.8842006820661205, 0.8852856844660157, 0.8871224668087743, 0.88775726381018, 0.8890258201991028, 0.8880637053885471, 0.8881476543790942, 0.8908584324258454, 0.889802951859558, 0.8911456634694447, 0.8918919246745495, 0.8923666837102683, 0.8937085649755838, 0.8914727853110987, 0.8932683758512945, 0.8938368740599233, 0.8931074575484803, 0.8951675369859475, 0.8943970088165397, 0.8951706520090317, 0.8946790108492916, 0.8955586216473838, 0.8963794121277433, 0.8958124974830178, 0.8961994830941827, 0.8964641186866082, 0.8963376157088772, 0.8938769040324346, 0.8973165691639885, 0.896910074288468, 0.8983801176936643, 0.8991110570078682, 0.8976262714702992, 0.8982472880052553, 0.898382919942985, 0.8980485106769361, 0.8981285287941376, 0.8992137619257112, 0.8997462413875265, 0.8997500597343387, 0.8990181603677683, 0.8997974690277983, 0.8992910566501146, 0.8999676981065918, 0.9006336032824883, 0.9004723187092359, 0.9008252505739766, 0.9009678367401119, 0.9006627306811303, 0.9015803508702036, 0.9020674013365737, 0.9020266697231424, 0.9018144140166523, 0.902474383783213, 0.9015095321520206, 0.9025332193500948, 0.9026427950138302, 0.9020444627449157, 0.90264658674042, 0.9026687678676374, 0.9022864499781291, 0.9033210985306263, 0.9036776856829289, 0.9030571988100677, 0.9036148253240084, 0.9040273317438088, 0.9035249717063545, 0.9038413701758812, 0.904426664269814, 0.9041039583934258, 0.9040084085467801, 0.9054760343316292, 0.9047948075210618, 0.9052844398927783, 0.9048425491794942, 0.9052161399711781, 0.9053407216011141, 0.9054632410917796, 0.9045910529313609, 0.9054441010341199, 0.9064007666906829, 0.9052062212582926, 0.9057226692036052, 0.9062286531023549, 0.9062030164500459, 0.9054892498247158, 0.9069612072474508, 0.9073407886210282, 0.9069220851256317, 0.9059317313836706, 0.9067899565102817, 0.9067984419277879, 0.9074474422236665, 0.9075474101200438, 0.9070451481979152, 0.9067388531831245, 0.9064392607234504, 0.9076329763929811, 0.9069628801594576, 0.9072563407506152, 0.9079715808232626, 0.9079838340548643, 0.9077042207992685, 0.908267638423488, 0.9087943181947811]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:00<00:03,  1.28it/s]predicting test subjects:  40%|████      | 2/5 [00:01<00:01,  1.59it/s]predicting test subjects:  60%|██████    | 3/5 [00:01<00:01,  1.90it/s]predicting test subjects:  80%|████████  | 4/5 [00:01<00:00,  2.23it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  2.54it/s]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:00<01:34,  2.80it/s]predicting train subjects:   1%|          | 2/266 [00:00<01:33,  2.82it/s]predicting train subjects:   1%|          | 3/266 [00:01<01:29,  2.95it/s]predicting train subjects:   2%|▏         | 4/266 [00:01<01:29,  2.93it/s]predicting train subjects:   2%|▏         | 5/266 [00:01<01:28,  2.94it/s]predicting train subjects:   2%|▏         | 6/266 [00:01<01:25,  3.04it/s]predicting train subjects:   3%|▎         | 7/266 [00:02<01:24,  3.06it/s]predicting train subjects:   3%|▎         | 8/266 [00:02<01:27,  2.95it/s]predicting train subjects:   3%|▎         | 9/266 [00:02<01:25,  3.02it/s]predicting train subjects:   4%|▍         | 10/266 [00:03<01:25,  3.01it/s]predicting train subjects:   4%|▍         | 11/266 [00:03<01:28,  2.89it/s]predicting train subjects:   5%|▍         | 12/266 [00:04<01:26,  2.94it/s]predicting train subjects:   5%|▍         | 13/266 [00:04<01:26,  2.93it/s]predicting train subjects:   5%|▌         | 14/266 [00:04<01:24,  2.99it/s]predicting train subjects:   6%|▌         | 15/266 [00:05<01:24,  2.97it/s]predicting train subjects:   6%|▌         | 16/266 [00:05<01:24,  2.97it/s]predicting train subjects:   6%|▋         | 17/266 [00:05<01:26,  2.89it/s]predicting train subjects:   7%|▋         | 18/266 [00:06<01:22,  2.99it/s]predicting train subjects:   7%|▋         | 19/266 [00:06<01:20,  3.06it/s]predicting train subjects:   8%|▊         | 20/266 [00:06<01:19,  3.08it/s]predicting train subjects:   8%|▊         | 21/266 [00:06<01:18,  3.13it/s]predicting train subjects:   8%|▊         | 22/266 [00:07<01:17,  3.14it/s]predicting train subjects:   9%|▊         | 23/266 [00:07<01:21,  2.97it/s]predicting train subjects:   9%|▉         | 24/266 [00:07<01:18,  3.08it/s]predicting train subjects:   9%|▉         | 25/266 [00:08<01:17,  3.10it/s]predicting train subjects:  10%|▉         | 26/266 [00:08<01:15,  3.17it/s]predicting train subjects:  10%|█         | 27/266 [00:08<01:13,  3.25it/s]predicting train subjects:  11%|█         | 28/266 [00:09<01:12,  3.29it/s]predicting train subjects:  11%|█         | 29/266 [00:09<01:10,  3.34it/s]predicting train subjects:  11%|█▏        | 30/266 [00:09<01:09,  3.39it/s]predicting train subjects:  12%|█▏        | 31/266 [00:10<01:10,  3.32it/s]predicting train subjects:  12%|█▏        | 32/266 [00:10<01:08,  3.41it/s]predicting train subjects:  12%|█▏        | 33/266 [00:10<01:08,  3.41it/s]predicting train subjects:  13%|█▎        | 34/266 [00:10<01:09,  3.34it/s]predicting train subjects:  13%|█▎        | 35/266 [00:11<01:10,  3.29it/s]predicting train subjects:  14%|█▎        | 36/266 [00:11<01:08,  3.35it/s]predicting train subjects:  14%|█▍        | 37/266 [00:11<01:07,  3.39it/s]predicting train subjects:  14%|█▍        | 38/266 [00:12<01:10,  3.25it/s]predicting train subjects:  15%|█▍        | 39/266 [00:12<01:08,  3.33it/s]predicting train subjects:  15%|█▌        | 40/266 [00:12<01:10,  3.23it/s]predicting train subjects:  15%|█▌        | 41/266 [00:13<01:09,  3.22it/s]predicting train subjects:  16%|█▌        | 42/266 [00:13<01:09,  3.22it/s]predicting train subjects:  16%|█▌        | 43/266 [00:13<01:04,  3.45it/s]predicting train subjects:  17%|█▋        | 44/266 [00:13<01:01,  3.62it/s]predicting train subjects:  17%|█▋        | 45/266 [00:14<00:59,  3.71it/s]predicting train subjects:  17%|█▋        | 46/266 [00:14<00:57,  3.85it/s]predicting train subjects:  18%|█▊        | 47/266 [00:14<00:54,  3.99it/s]predicting train subjects:  18%|█▊        | 48/266 [00:14<00:55,  3.94it/s]predicting train subjects:  18%|█▊        | 49/266 [00:15<00:54,  3.95it/s]predicting train subjects:  19%|█▉        | 50/266 [00:15<00:57,  3.74it/s]predicting train subjects:  19%|█▉        | 51/266 [00:15<00:57,  3.71it/s]predicting train subjects:  20%|█▉        | 52/266 [00:15<00:58,  3.65it/s]predicting train subjects:  20%|█▉        | 53/266 [00:16<00:58,  3.65it/s]predicting train subjects:  20%|██        | 54/266 [00:16<00:58,  3.64it/s]predicting train subjects:  21%|██        | 55/266 [00:16<00:55,  3.81it/s]predicting train subjects:  21%|██        | 56/266 [00:17<00:52,  3.97it/s]predicting train subjects:  21%|██▏       | 57/266 [00:17<00:52,  3.98it/s]predicting train subjects:  22%|██▏       | 58/266 [00:17<00:54,  3.84it/s]predicting train subjects:  22%|██▏       | 59/266 [00:17<00:54,  3.77it/s]predicting train subjects:  23%|██▎       | 60/266 [00:18<00:52,  3.90it/s]predicting train subjects:  23%|██▎       | 61/266 [00:18<00:50,  4.04it/s]predicting train subjects:  23%|██▎       | 62/266 [00:18<00:50,  4.07it/s]predicting train subjects:  24%|██▎       | 63/266 [00:18<00:51,  3.92it/s]predicting train subjects:  24%|██▍       | 64/266 [00:19<00:49,  4.04it/s]predicting train subjects:  24%|██▍       | 65/266 [00:19<00:48,  4.14it/s]predicting train subjects:  25%|██▍       | 66/266 [00:19<00:47,  4.23it/s]predicting train subjects:  25%|██▌       | 67/266 [00:19<00:46,  4.27it/s]predicting train subjects:  26%|██▌       | 68/266 [00:19<00:46,  4.29it/s]predicting train subjects:  26%|██▌       | 69/266 [00:20<00:45,  4.33it/s]predicting train subjects:  26%|██▋       | 70/266 [00:20<00:45,  4.28it/s]predicting train subjects:  27%|██▋       | 71/266 [00:20<00:45,  4.30it/s]predicting train subjects:  27%|██▋       | 72/266 [00:20<00:44,  4.32it/s]predicting train subjects:  27%|██▋       | 73/266 [00:21<00:45,  4.27it/s]predicting train subjects:  28%|██▊       | 74/266 [00:21<00:47,  4.07it/s]predicting train subjects:  28%|██▊       | 75/266 [00:21<00:46,  4.11it/s]predicting train subjects:  29%|██▊       | 76/266 [00:21<00:46,  4.12it/s]predicting train subjects:  29%|██▉       | 77/266 [00:22<00:44,  4.21it/s]predicting train subjects:  29%|██▉       | 78/266 [00:22<00:48,  3.87it/s]predicting train subjects:  30%|██▉       | 79/266 [00:22<00:51,  3.67it/s]predicting train subjects:  30%|███       | 80/266 [00:23<00:53,  3.51it/s]predicting train subjects:  30%|███       | 81/266 [00:23<00:53,  3.43it/s]predicting train subjects:  31%|███       | 82/266 [00:23<00:55,  3.30it/s]predicting train subjects:  31%|███       | 83/266 [00:23<00:55,  3.32it/s]predicting train subjects:  32%|███▏      | 84/266 [00:24<00:56,  3.21it/s]predicting train subjects:  32%|███▏      | 85/266 [00:24<00:57,  3.13it/s]predicting train subjects:  32%|███▏      | 86/266 [00:24<00:56,  3.21it/s]predicting train subjects:  33%|███▎      | 87/266 [00:25<00:55,  3.21it/s]predicting train subjects:  33%|███▎      | 88/266 [00:25<00:56,  3.15it/s]predicting train subjects:  33%|███▎      | 89/266 [00:25<00:55,  3.19it/s]predicting train subjects:  34%|███▍      | 90/266 [00:26<00:53,  3.28it/s]predicting train subjects:  34%|███▍      | 91/266 [00:26<00:54,  3.21it/s]predicting train subjects:  35%|███▍      | 92/266 [00:26<00:55,  3.15it/s]predicting train subjects:  35%|███▍      | 93/266 [00:27<00:53,  3.22it/s]predicting train subjects:  35%|███▌      | 94/266 [00:27<00:52,  3.27it/s]predicting train subjects:  36%|███▌      | 95/266 [00:27<00:51,  3.34it/s]predicting train subjects:  36%|███▌      | 96/266 [00:28<00:54,  3.14it/s]predicting train subjects:  36%|███▋      | 97/266 [00:28<00:53,  3.14it/s]predicting train subjects:  37%|███▋      | 98/266 [00:28<00:52,  3.22it/s]predicting train subjects:  37%|███▋      | 99/266 [00:28<00:53,  3.14it/s]predicting train subjects:  38%|███▊      | 100/266 [00:29<00:50,  3.30it/s]predicting train subjects:  38%|███▊      | 101/266 [00:29<00:47,  3.49it/s]predicting train subjects:  38%|███▊      | 102/266 [00:29<00:47,  3.46it/s]predicting train subjects:  39%|███▊      | 103/266 [00:30<00:46,  3.48it/s]predicting train subjects:  39%|███▉      | 104/266 [00:30<00:45,  3.59it/s]predicting train subjects:  39%|███▉      | 105/266 [00:30<00:43,  3.67it/s]predicting train subjects:  40%|███▉      | 106/266 [00:30<00:44,  3.58it/s]predicting train subjects:  40%|████      | 107/266 [00:31<00:44,  3.53it/s]predicting train subjects:  41%|████      | 108/266 [00:31<00:42,  3.68it/s]predicting train subjects:  41%|████      | 109/266 [00:31<00:41,  3.80it/s]predicting train subjects:  41%|████▏     | 110/266 [00:31<00:42,  3.71it/s]predicting train subjects:  42%|████▏     | 111/266 [00:32<00:43,  3.60it/s]predicting train subjects:  42%|████▏     | 112/266 [00:32<00:41,  3.73it/s]predicting train subjects:  42%|████▏     | 113/266 [00:32<00:42,  3.63it/s]predicting train subjects:  43%|████▎     | 114/266 [00:33<00:41,  3.69it/s]predicting train subjects:  43%|████▎     | 115/266 [00:33<00:41,  3.61it/s]predicting train subjects:  44%|████▎     | 116/266 [00:33<00:43,  3.44it/s]predicting train subjects:  44%|████▍     | 117/266 [00:33<00:43,  3.44it/s]predicting train subjects:  44%|████▍     | 118/266 [00:34<00:42,  3.51it/s]predicting train subjects:  45%|████▍     | 119/266 [00:34<00:42,  3.49it/s]predicting train subjects:  45%|████▌     | 120/266 [00:34<00:42,  3.46it/s]predicting train subjects:  45%|████▌     | 121/266 [00:35<00:42,  3.40it/s]predicting train subjects:  46%|████▌     | 122/266 [00:35<00:42,  3.42it/s]predicting train subjects:  46%|████▌     | 123/266 [00:35<00:43,  3.32it/s]predicting train subjects:  47%|████▋     | 124/266 [00:36<00:44,  3.22it/s]predicting train subjects:  47%|████▋     | 125/266 [00:36<00:42,  3.29it/s]predicting train subjects:  47%|████▋     | 126/266 [00:36<00:42,  3.30it/s]predicting train subjects:  48%|████▊     | 127/266 [00:36<00:42,  3.28it/s]predicting train subjects:  48%|████▊     | 128/266 [00:37<00:41,  3.32it/s]predicting train subjects:  48%|████▊     | 129/266 [00:37<00:42,  3.23it/s]predicting train subjects:  49%|████▉     | 130/266 [00:37<00:42,  3.22it/s]predicting train subjects:  49%|████▉     | 131/266 [00:38<00:41,  3.24it/s]predicting train subjects:  50%|████▉     | 132/266 [00:38<00:40,  3.31it/s]predicting train subjects:  50%|█████     | 133/266 [00:38<00:39,  3.35it/s]predicting train subjects:  50%|█████     | 134/266 [00:39<00:40,  3.29it/s]predicting train subjects:  51%|█████     | 135/266 [00:39<00:39,  3.34it/s]predicting train subjects:  51%|█████     | 136/266 [00:39<00:39,  3.27it/s]predicting train subjects:  52%|█████▏    | 137/266 [00:39<00:38,  3.38it/s]predicting train subjects:  52%|█████▏    | 138/266 [00:40<00:37,  3.41it/s]predicting train subjects:  52%|█████▏    | 139/266 [00:40<00:36,  3.50it/s]predicting train subjects:  53%|█████▎    | 140/266 [00:40<00:36,  3.41it/s]predicting train subjects:  53%|█████▎    | 141/266 [00:41<00:36,  3.47it/s]predicting train subjects:  53%|█████▎    | 142/266 [00:41<00:35,  3.54it/s]predicting train subjects:  54%|█████▍    | 143/266 [00:41<00:35,  3.51it/s]predicting train subjects:  54%|█████▍    | 144/266 [00:41<00:34,  3.56it/s]predicting train subjects:  55%|█████▍    | 145/266 [00:42<00:33,  3.56it/s]predicting train subjects:  55%|█████▍    | 146/266 [00:42<00:33,  3.60it/s]predicting train subjects:  55%|█████▌    | 147/266 [00:42<00:32,  3.64it/s]predicting train subjects:  56%|█████▌    | 148/266 [00:43<00:33,  3.51it/s]predicting train subjects:  56%|█████▌    | 149/266 [00:43<00:33,  3.51it/s]predicting train subjects:  56%|█████▋    | 150/266 [00:43<00:32,  3.57it/s]predicting train subjects:  57%|█████▋    | 151/266 [00:43<00:31,  3.62it/s]predicting train subjects:  57%|█████▋    | 152/266 [00:44<00:32,  3.47it/s]predicting train subjects:  58%|█████▊    | 153/266 [00:44<00:32,  3.52it/s]predicting train subjects:  58%|█████▊    | 154/266 [00:44<00:31,  3.56it/s]predicting train subjects:  58%|█████▊    | 155/266 [00:44<00:28,  3.84it/s]predicting train subjects:  59%|█████▊    | 156/266 [00:45<00:26,  4.10it/s]predicting train subjects:  59%|█████▉    | 157/266 [00:45<00:25,  4.30it/s]predicting train subjects:  59%|█████▉    | 158/266 [00:45<00:24,  4.39it/s]predicting train subjects:  60%|█████▉    | 159/266 [00:45<00:24,  4.45it/s]predicting train subjects:  60%|██████    | 160/266 [00:46<00:23,  4.48it/s]predicting train subjects:  61%|██████    | 161/266 [00:46<00:23,  4.56it/s]predicting train subjects:  61%|██████    | 162/266 [00:46<00:22,  4.64it/s]predicting train subjects:  61%|██████▏   | 163/266 [00:46<00:22,  4.58it/s]predicting train subjects:  62%|██████▏   | 164/266 [00:46<00:21,  4.66it/s]predicting train subjects:  62%|██████▏   | 165/266 [00:47<00:21,  4.73it/s]predicting train subjects:  62%|██████▏   | 166/266 [00:47<00:20,  4.78it/s]predicting train subjects:  63%|██████▎   | 167/266 [00:47<00:20,  4.76it/s]predicting train subjects:  63%|██████▎   | 168/266 [00:47<00:21,  4.64it/s]predicting train subjects:  64%|██████▎   | 169/266 [00:47<00:20,  4.68it/s]predicting train subjects:  64%|██████▍   | 170/266 [00:48<00:20,  4.58it/s]predicting train subjects:  64%|██████▍   | 171/266 [00:48<00:20,  4.65it/s]predicting train subjects:  65%|██████▍   | 172/266 [00:48<00:20,  4.49it/s]predicting train subjects:  65%|██████▌   | 173/266 [00:48<00:21,  4.32it/s]predicting train subjects:  65%|██████▌   | 174/266 [00:49<00:21,  4.30it/s]predicting train subjects:  66%|██████▌   | 175/266 [00:49<00:21,  4.29it/s]predicting train subjects:  66%|██████▌   | 176/266 [00:49<00:21,  4.20it/s]predicting train subjects:  67%|██████▋   | 177/266 [00:49<00:21,  4.17it/s]predicting train subjects:  67%|██████▋   | 178/266 [00:50<00:22,  3.97it/s]predicting train subjects:  67%|██████▋   | 179/266 [00:50<00:21,  3.99it/s]predicting train subjects:  68%|██████▊   | 180/266 [00:50<00:21,  4.06it/s]predicting train subjects:  68%|██████▊   | 181/266 [00:50<00:20,  4.09it/s]predicting train subjects:  68%|██████▊   | 182/266 [00:51<00:20,  4.04it/s]predicting train subjects:  69%|██████▉   | 183/266 [00:51<00:20,  4.09it/s]predicting train subjects:  69%|██████▉   | 184/266 [00:51<00:19,  4.17it/s]predicting train subjects:  70%|██████▉   | 185/266 [00:51<00:19,  4.17it/s]predicting train subjects:  70%|██████▉   | 186/266 [00:52<00:19,  4.18it/s]predicting train subjects:  70%|███████   | 187/266 [00:52<00:18,  4.23it/s]predicting train subjects:  71%|███████   | 188/266 [00:52<00:18,  4.23it/s]predicting train subjects:  71%|███████   | 189/266 [00:52<00:18,  4.12it/s]predicting train subjects:  71%|███████▏  | 190/266 [00:53<00:19,  3.92it/s]predicting train subjects:  72%|███████▏  | 191/266 [00:53<00:19,  3.77it/s]predicting train subjects:  72%|███████▏  | 192/266 [00:53<00:21,  3.47it/s]predicting train subjects:  73%|███████▎  | 193/266 [00:53<00:20,  3.57it/s]predicting train subjects:  73%|███████▎  | 194/266 [00:54<00:21,  3.37it/s]predicting train subjects:  73%|███████▎  | 195/266 [00:54<00:19,  3.58it/s]predicting train subjects:  74%|███████▎  | 196/266 [00:54<00:20,  3.43it/s]predicting train subjects:  74%|███████▍  | 197/266 [00:55<00:19,  3.60it/s]predicting train subjects:  74%|███████▍  | 198/266 [00:55<00:18,  3.61it/s]predicting train subjects:  75%|███████▍  | 199/266 [00:55<00:17,  3.74it/s]predicting train subjects:  75%|███████▌  | 200/266 [00:55<00:17,  3.86it/s]predicting train subjects:  76%|███████▌  | 201/266 [00:56<00:16,  3.91it/s]predicting train subjects:  76%|███████▌  | 202/266 [00:56<00:17,  3.76it/s]predicting train subjects:  76%|███████▋  | 203/266 [00:56<00:17,  3.67it/s]predicting train subjects:  77%|███████▋  | 204/266 [00:56<00:16,  3.72it/s]predicting train subjects:  77%|███████▋  | 205/266 [00:57<00:17,  3.56it/s]predicting train subjects:  77%|███████▋  | 206/266 [00:57<00:16,  3.72it/s]predicting train subjects:  78%|███████▊  | 207/266 [00:57<00:16,  3.63it/s]predicting train subjects:  78%|███████▊  | 208/266 [00:58<00:16,  3.61it/s]predicting train subjects:  79%|███████▊  | 209/266 [00:58<00:15,  3.58it/s]predicting train subjects:  79%|███████▉  | 210/266 [00:58<00:14,  3.74it/s]predicting train subjects:  79%|███████▉  | 211/266 [00:58<00:14,  3.73it/s]predicting train subjects:  80%|███████▉  | 212/266 [00:59<00:14,  3.80it/s]predicting train subjects:  80%|████████  | 213/266 [00:59<00:13,  3.85it/s]predicting train subjects:  80%|████████  | 214/266 [00:59<00:12,  4.08it/s]predicting train subjects:  81%|████████  | 215/266 [00:59<00:12,  4.20it/s]predicting train subjects:  81%|████████  | 216/266 [00:59<00:11,  4.27it/s]predicting train subjects:  82%|████████▏ | 217/266 [01:00<00:11,  4.36it/s]predicting train subjects:  82%|████████▏ | 218/266 [01:00<00:10,  4.42it/s]predicting train subjects:  82%|████████▏ | 219/266 [01:00<00:10,  4.47it/s]predicting train subjects:  83%|████████▎ | 220/266 [01:00<00:10,  4.49it/s]predicting train subjects:  83%|████████▎ | 221/266 [01:01<00:10,  4.50it/s]predicting train subjects:  83%|████████▎ | 222/266 [01:01<00:09,  4.48it/s]predicting train subjects:  84%|████████▍ | 223/266 [01:01<00:09,  4.42it/s]predicting train subjects:  84%|████████▍ | 224/266 [01:01<00:09,  4.44it/s]predicting train subjects:  85%|████████▍ | 225/266 [01:01<00:09,  4.46it/s]predicting train subjects:  85%|████████▍ | 226/266 [01:02<00:08,  4.51it/s]predicting train subjects:  85%|████████▌ | 227/266 [01:02<00:08,  4.51it/s]predicting train subjects:  86%|████████▌ | 228/266 [01:02<00:08,  4.51it/s]predicting train subjects:  86%|████████▌ | 229/266 [01:02<00:08,  4.49it/s]predicting train subjects:  86%|████████▋ | 230/266 [01:03<00:07,  4.52it/s]predicting train subjects:  87%|████████▋ | 231/266 [01:03<00:07,  4.45it/s]predicting train subjects:  87%|████████▋ | 232/266 [01:03<00:07,  4.42it/s]predicting train subjects:  88%|████████▊ | 233/266 [01:03<00:07,  4.40it/s]predicting train subjects:  88%|████████▊ | 234/266 [01:04<00:07,  4.40it/s]predicting train subjects:  88%|████████▊ | 235/266 [01:04<00:07,  4.38it/s]predicting train subjects:  89%|████████▊ | 236/266 [01:04<00:07,  4.21it/s]predicting train subjects:  89%|████████▉ | 237/266 [01:04<00:07,  3.99it/s]predicting train subjects:  89%|████████▉ | 238/266 [01:05<00:07,  3.77it/s]predicting train subjects:  90%|████████▉ | 239/266 [01:05<00:07,  3.74it/s]predicting train subjects:  90%|█████████ | 240/266 [01:05<00:06,  3.72it/s]predicting train subjects:  91%|█████████ | 241/266 [01:05<00:06,  3.86it/s]predicting train subjects:  91%|█████████ | 242/266 [01:06<00:06,  3.94it/s]predicting train subjects:  91%|█████████▏| 243/266 [01:06<00:05,  4.03it/s]predicting train subjects:  92%|█████████▏| 244/266 [01:06<00:05,  4.01it/s]predicting train subjects:  92%|█████████▏| 245/266 [01:06<00:05,  3.96it/s]predicting train subjects:  92%|█████████▏| 246/266 [01:07<00:05,  3.95it/s]predicting train subjects:  93%|█████████▎| 247/266 [01:07<00:04,  3.97it/s]predicting train subjects:  93%|█████████▎| 248/266 [01:07<00:04,  4.09it/s]predicting train subjects:  94%|█████████▎| 249/266 [01:07<00:04,  3.89it/s]predicting train subjects:  94%|█████████▍| 250/266 [01:08<00:04,  3.60it/s]predicting train subjects:  94%|█████████▍| 251/266 [01:08<00:04,  3.59it/s]predicting train subjects:  95%|█████████▍| 252/266 [01:08<00:03,  3.51it/s]predicting train subjects:  95%|█████████▌| 253/266 [01:09<00:03,  3.38it/s]predicting train subjects:  95%|█████████▌| 254/266 [01:09<00:03,  3.37it/s]predicting train subjects:  96%|█████████▌| 255/266 [01:09<00:03,  3.30it/s]predicting train subjects:  96%|█████████▌| 256/266 [01:10<00:02,  3.36it/s]predicting train subjects:  97%|█████████▋| 257/266 [01:10<00:02,  3.44it/s]predicting train subjects:  97%|█████████▋| 258/266 [01:10<00:02,  3.44it/s]predicting train subjects:  97%|█████████▋| 259/266 [01:10<00:02,  3.39it/s]predicting train subjects:  98%|█████████▊| 260/266 [01:11<00:01,  3.44it/s]predicting train subjects:  98%|█████████▊| 261/266 [01:11<00:01,  3.34it/s]predicting train subjects:  98%|█████████▊| 262/266 [01:11<00:01,  3.40it/s]predicting train subjects:  99%|█████████▉| 263/266 [01:12<00:00,  3.29it/s]predicting train subjects:  99%|█████████▉| 264/266 [01:12<00:00,  3.31it/s]predicting train subjects: 100%|█████████▉| 265/266 [01:12<00:00,  3.39it/s]predicting train subjects: 100%|██████████| 266/266 [01:12<00:00,  3.40it/s]
predicting test subjects sagittal:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects sagittal:  20%|██        | 1/5 [00:00<00:00,  4.06it/s]predicting test subjects sagittal:  40%|████      | 2/5 [00:00<00:00,  3.83it/s]predicting test subjects sagittal:  60%|██████    | 3/5 [00:00<00:00,  3.95it/s]predicting test subjects sagittal:  80%|████████  | 4/5 [00:01<00:00,  4.09it/s]predicting test subjects sagittal: 100%|██████████| 5/5 [00:01<00:00,  4.04it/s]
predicting train subjects sagittal:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects sagittal:   0%|          | 1/266 [00:00<01:24,  3.15it/s]predicting train subjects sagittal:   1%|          | 2/266 [00:00<01:21,  3.22it/s]predicting train subjects sagittal:   1%|          | 3/266 [00:00<01:20,  3.28it/s]predicting train subjects sagittal:   2%|▏         | 4/266 [00:01<01:15,  3.46it/s]predicting train subjects sagittal:   2%|▏         | 5/266 [00:01<01:16,  3.42it/s]predicting train subjects sagittal:   2%|▏         | 6/266 [00:01<01:16,  3.39it/s]predicting train subjects sagittal:   3%|▎         | 7/266 [00:02<01:20,  3.23it/s]predicting train subjects sagittal:   3%|▎         | 8/266 [00:02<01:20,  3.21it/s]predicting train subjects sagittal:   3%|▎         | 9/266 [00:02<01:22,  3.12it/s]predicting train subjects sagittal:   4%|▍         | 10/266 [00:03<01:21,  3.16it/s]predicting train subjects sagittal:   4%|▍         | 11/266 [00:03<01:22,  3.08it/s]predicting train subjects sagittal:   5%|▍         | 12/266 [00:03<01:21,  3.12it/s]predicting train subjects sagittal:   5%|▍         | 13/266 [00:04<01:22,  3.06it/s]predicting train subjects sagittal:   5%|▌         | 14/266 [00:04<01:21,  3.10it/s]predicting train subjects sagittal:   6%|▌         | 15/266 [00:04<01:19,  3.15it/s]predicting train subjects sagittal:   6%|▌         | 16/266 [00:05<01:21,  3.08it/s]predicting train subjects sagittal:   6%|▋         | 17/266 [00:05<01:19,  3.12it/s]predicting train subjects sagittal:   7%|▋         | 18/266 [00:05<01:21,  3.06it/s]predicting train subjects sagittal:   7%|▋         | 19/266 [00:05<01:19,  3.11it/s]predicting train subjects sagittal:   8%|▊         | 20/266 [00:06<01:17,  3.16it/s]predicting train subjects sagittal:   8%|▊         | 21/266 [00:06<01:18,  3.14it/s]predicting train subjects sagittal:   8%|▊         | 22/266 [00:06<01:15,  3.21it/s]predicting train subjects sagittal:   9%|▊         | 23/266 [00:07<01:15,  3.23it/s]predicting train subjects sagittal:   9%|▉         | 24/266 [00:07<01:13,  3.30it/s]predicting train subjects sagittal:   9%|▉         | 25/266 [00:07<01:11,  3.35it/s]predicting train subjects sagittal:  10%|▉         | 26/266 [00:08<01:11,  3.38it/s]predicting train subjects sagittal:  10%|█         | 27/266 [00:08<01:11,  3.33it/s]predicting train subjects sagittal:  11%|█         | 28/266 [00:08<01:10,  3.39it/s]predicting train subjects sagittal:  11%|█         | 29/266 [00:08<01:11,  3.33it/s]predicting train subjects sagittal:  11%|█▏        | 30/266 [00:09<01:12,  3.24it/s]predicting train subjects sagittal:  12%|█▏        | 31/266 [00:09<01:13,  3.19it/s]predicting train subjects sagittal:  12%|█▏        | 32/266 [00:09<01:12,  3.21it/s]predicting train subjects sagittal:  12%|█▏        | 33/266 [00:10<01:11,  3.25it/s]predicting train subjects sagittal:  13%|█▎        | 34/266 [00:10<01:10,  3.29it/s]predicting train subjects sagittal:  13%|█▎        | 35/266 [00:10<01:09,  3.33it/s]predicting train subjects sagittal:  14%|█▎        | 36/266 [00:11<01:10,  3.27it/s]predicting train subjects sagittal:  14%|█▍        | 37/266 [00:11<01:10,  3.27it/s]predicting train subjects sagittal:  14%|█▍        | 38/266 [00:11<01:09,  3.27it/s]predicting train subjects sagittal:  15%|█▍        | 39/266 [00:12<01:09,  3.25it/s]predicting train subjects sagittal:  15%|█▌        | 40/266 [00:12<01:08,  3.30it/s]predicting train subjects sagittal:  15%|█▌        | 41/266 [00:12<01:06,  3.36it/s]predicting train subjects sagittal:  16%|█▌        | 42/266 [00:12<01:02,  3.59it/s]predicting train subjects sagittal:  16%|█▌        | 43/266 [00:13<00:58,  3.81it/s]predicting train subjects sagittal:  17%|█▋        | 44/266 [00:13<00:56,  3.94it/s]predicting train subjects sagittal:  17%|█▋        | 45/266 [00:13<00:56,  3.92it/s]predicting train subjects sagittal:  17%|█▋        | 46/266 [00:13<00:54,  4.07it/s]predicting train subjects sagittal:  18%|█▊        | 47/266 [00:14<00:52,  4.19it/s]predicting train subjects sagittal:  18%|█▊        | 48/266 [00:14<00:52,  4.16it/s]predicting train subjects sagittal:  18%|█▊        | 49/266 [00:14<00:53,  4.05it/s]predicting train subjects sagittal:  19%|█▉        | 50/266 [00:14<00:52,  4.08it/s]predicting train subjects sagittal:  19%|█▉        | 51/266 [00:15<00:55,  3.90it/s]predicting train subjects sagittal:  20%|█▉        | 52/266 [00:15<00:53,  4.03it/s]predicting train subjects sagittal:  20%|█▉        | 53/266 [00:15<00:52,  4.06it/s]predicting train subjects sagittal:  20%|██        | 54/266 [00:15<00:51,  4.11it/s]predicting train subjects sagittal:  21%|██        | 55/266 [00:16<00:50,  4.19it/s]predicting train subjects sagittal:  21%|██        | 56/266 [00:16<00:49,  4.21it/s]predicting train subjects sagittal:  21%|██▏       | 57/266 [00:16<00:50,  4.18it/s]predicting train subjects sagittal:  22%|██▏       | 58/266 [00:16<00:48,  4.26it/s]predicting train subjects sagittal:  22%|██▏       | 59/266 [00:16<00:48,  4.30it/s]predicting train subjects sagittal:  23%|██▎       | 60/266 [00:17<00:48,  4.22it/s]predicting train subjects sagittal:  23%|██▎       | 61/266 [00:17<00:48,  4.23it/s]predicting train subjects sagittal:  23%|██▎       | 62/266 [00:17<00:48,  4.24it/s]predicting train subjects sagittal:  24%|██▎       | 63/266 [00:17<00:46,  4.34it/s]predicting train subjects sagittal:  24%|██▍       | 64/266 [00:18<00:45,  4.40it/s]predicting train subjects sagittal:  24%|██▍       | 65/266 [00:18<00:46,  4.34it/s]predicting train subjects sagittal:  25%|██▍       | 66/266 [00:18<00:48,  4.10it/s]predicting train subjects sagittal:  25%|██▌       | 67/266 [00:18<00:50,  3.97it/s]predicting train subjects sagittal:  26%|██▌       | 68/266 [00:19<00:49,  4.00it/s]predicting train subjects sagittal:  26%|██▌       | 69/266 [00:19<00:48,  4.10it/s]predicting train subjects sagittal:  26%|██▋       | 70/266 [00:19<00:46,  4.18it/s]predicting train subjects sagittal:  27%|██▋       | 71/266 [00:19<00:46,  4.22it/s]predicting train subjects sagittal:  27%|██▋       | 72/266 [00:20<00:46,  4.19it/s]predicting train subjects sagittal:  27%|██▋       | 73/266 [00:20<00:48,  3.99it/s]predicting train subjects sagittal:  28%|██▊       | 74/266 [00:20<00:47,  4.01it/s]predicting train subjects sagittal:  28%|██▊       | 75/266 [00:20<00:47,  4.00it/s]predicting train subjects sagittal:  29%|██▊       | 76/266 [00:21<00:49,  3.87it/s]predicting train subjects sagittal:  29%|██▉       | 77/266 [00:21<00:48,  3.91it/s]predicting train subjects sagittal:  29%|██▉       | 78/266 [00:21<00:50,  3.73it/s]predicting train subjects sagittal:  30%|██▉       | 79/266 [00:21<00:54,  3.46it/s]predicting train subjects sagittal:  30%|███       | 80/266 [00:22<00:56,  3.31it/s]predicting train subjects sagittal:  30%|███       | 81/266 [00:22<00:58,  3.18it/s]predicting train subjects sagittal:  31%|███       | 82/266 [00:22<00:57,  3.21it/s]predicting train subjects sagittal:  31%|███       | 83/266 [00:23<00:56,  3.23it/s]predicting train subjects sagittal:  32%|███▏      | 84/266 [00:23<00:56,  3.21it/s]predicting train subjects sagittal:  32%|███▏      | 85/266 [00:23<00:57,  3.13it/s]predicting train subjects sagittal:  32%|███▏      | 86/266 [00:24<01:01,  2.95it/s]predicting train subjects sagittal:  33%|███▎      | 87/266 [00:24<01:00,  2.98it/s]predicting train subjects sagittal:  33%|███▎      | 88/266 [00:24<00:59,  3.00it/s]predicting train subjects sagittal:  33%|███▎      | 89/266 [00:25<01:02,  2.81it/s]predicting train subjects sagittal:  34%|███▍      | 90/266 [00:25<01:00,  2.92it/s]predicting train subjects sagittal:  34%|███▍      | 91/266 [00:26<01:00,  2.91it/s]predicting train subjects sagittal:  35%|███▍      | 92/266 [00:26<00:57,  3.02it/s]predicting train subjects sagittal:  35%|███▍      | 93/266 [00:26<00:55,  3.11it/s]predicting train subjects sagittal:  35%|███▌      | 94/266 [00:26<00:56,  3.05it/s]predicting train subjects sagittal:  36%|███▌      | 95/266 [00:27<00:54,  3.13it/s]predicting train subjects sagittal:  36%|███▌      | 96/266 [00:27<00:50,  3.35it/s]predicting train subjects sagittal:  36%|███▋      | 97/266 [00:27<00:51,  3.28it/s]predicting train subjects sagittal:  37%|███▋      | 98/266 [00:28<00:50,  3.33it/s]predicting train subjects sagittal:  37%|███▋      | 99/266 [00:28<00:48,  3.45it/s]predicting train subjects sagittal:  38%|███▊      | 100/266 [00:28<00:45,  3.65it/s]predicting train subjects sagittal:  38%|███▊      | 101/266 [00:28<00:44,  3.71it/s]predicting train subjects sagittal:  38%|███▊      | 102/266 [00:29<00:43,  3.81it/s]predicting train subjects sagittal:  39%|███▊      | 103/266 [00:29<00:43,  3.75it/s]predicting train subjects sagittal:  39%|███▉      | 104/266 [00:29<00:43,  3.73it/s]predicting train subjects sagittal:  39%|███▉      | 105/266 [00:29<00:44,  3.63it/s]predicting train subjects sagittal:  40%|███▉      | 106/266 [00:30<00:45,  3.55it/s]predicting train subjects sagittal:  40%|████      | 107/266 [00:30<00:43,  3.68it/s]predicting train subjects sagittal:  41%|████      | 108/266 [00:30<00:42,  3.75it/s]predicting train subjects sagittal:  41%|████      | 109/266 [00:31<00:41,  3.82it/s]predicting train subjects sagittal:  41%|████▏     | 110/266 [00:31<00:42,  3.65it/s]predicting train subjects sagittal:  42%|████▏     | 111/266 [00:31<00:42,  3.66it/s]predicting train subjects sagittal:  42%|████▏     | 112/266 [00:31<00:43,  3.57it/s]predicting train subjects sagittal:  42%|████▏     | 113/266 [00:32<00:41,  3.70it/s]predicting train subjects sagittal:  43%|████▎     | 114/266 [00:32<00:39,  3.82it/s]predicting train subjects sagittal:  43%|████▎     | 115/266 [00:32<00:38,  3.91it/s]predicting train subjects sagittal:  44%|████▎     | 116/266 [00:32<00:37,  3.97it/s]predicting train subjects sagittal:  44%|████▍     | 117/266 [00:33<00:38,  3.87it/s]predicting train subjects sagittal:  44%|████▍     | 118/266 [00:33<00:39,  3.78it/s]predicting train subjects sagittal:  45%|████▍     | 119/266 [00:33<00:40,  3.65it/s]predicting train subjects sagittal:  45%|████▌     | 120/266 [00:34<00:41,  3.55it/s]predicting train subjects sagittal:  45%|████▌     | 121/266 [00:34<00:41,  3.52it/s]predicting train subjects sagittal:  46%|████▌     | 122/266 [00:34<00:41,  3.50it/s]predicting train subjects sagittal:  46%|████▌     | 123/266 [00:34<00:41,  3.45it/s]predicting train subjects sagittal:  47%|████▋     | 124/266 [00:35<00:41,  3.39it/s]predicting train subjects sagittal:  47%|████▋     | 125/266 [00:35<00:41,  3.38it/s]predicting train subjects sagittal:  47%|████▋     | 126/266 [00:35<00:41,  3.41it/s]predicting train subjects sagittal:  48%|████▊     | 127/266 [00:36<00:42,  3.27it/s]predicting train subjects sagittal:  48%|████▊     | 128/266 [00:36<00:43,  3.19it/s]predicting train subjects sagittal:  48%|████▊     | 129/266 [00:36<00:43,  3.14it/s]predicting train subjects sagittal:  49%|████▉     | 130/266 [00:37<00:42,  3.17it/s]predicting train subjects sagittal:  49%|████▉     | 131/266 [00:37<00:42,  3.19it/s]predicting train subjects sagittal:  50%|████▉     | 132/266 [00:37<00:41,  3.24it/s]predicting train subjects sagittal:  50%|█████     | 133/266 [00:38<00:40,  3.27it/s]predicting train subjects sagittal:  50%|█████     | 134/266 [00:38<00:39,  3.33it/s]predicting train subjects sagittal:  51%|█████     | 135/266 [00:38<00:38,  3.39it/s]predicting train subjects sagittal:  51%|█████     | 136/266 [00:38<00:38,  3.42it/s]predicting train subjects sagittal:  52%|█████▏    | 137/266 [00:39<00:36,  3.51it/s]predicting train subjects sagittal:  52%|█████▏    | 138/266 [00:39<00:37,  3.43it/s]predicting train subjects sagittal:  52%|█████▏    | 139/266 [00:39<00:37,  3.37it/s]predicting train subjects sagittal:  53%|█████▎    | 140/266 [00:40<00:37,  3.33it/s]predicting train subjects sagittal:  53%|█████▎    | 141/266 [00:40<00:37,  3.29it/s]predicting train subjects sagittal:  53%|█████▎    | 142/266 [00:40<00:36,  3.37it/s]predicting train subjects sagittal:  54%|█████▍    | 143/266 [00:40<00:35,  3.45it/s]predicting train subjects sagittal:  54%|█████▍    | 144/266 [00:41<00:36,  3.34it/s]predicting train subjects sagittal:  55%|█████▍    | 145/266 [00:41<00:36,  3.36it/s]predicting train subjects sagittal:  55%|█████▍    | 146/266 [00:41<00:35,  3.41it/s]predicting train subjects sagittal:  55%|█████▌    | 147/266 [00:42<00:34,  3.50it/s]predicting train subjects sagittal:  56%|█████▌    | 148/266 [00:42<00:34,  3.46it/s]predicting train subjects sagittal:  56%|█████▌    | 149/266 [00:42<00:33,  3.48it/s]predicting train subjects sagittal:  56%|█████▋    | 150/266 [00:42<00:34,  3.38it/s]predicting train subjects sagittal:  57%|█████▋    | 151/266 [00:43<00:33,  3.46it/s]predicting train subjects sagittal:  57%|█████▋    | 152/266 [00:43<00:32,  3.55it/s]predicting train subjects sagittal:  58%|█████▊    | 153/266 [00:43<00:31,  3.57it/s]predicting train subjects sagittal:  58%|█████▊    | 154/266 [00:44<00:32,  3.47it/s]predicting train subjects sagittal:  58%|█████▊    | 155/266 [00:44<00:29,  3.74it/s]predicting train subjects sagittal:  59%|█████▊    | 156/266 [00:44<00:27,  4.05it/s]predicting train subjects sagittal:  59%|█████▉    | 157/266 [00:44<00:25,  4.25it/s]predicting train subjects sagittal:  59%|█████▉    | 158/266 [00:44<00:24,  4.42it/s]predicting train subjects sagittal:  60%|█████▉    | 159/266 [00:45<00:23,  4.53it/s]predicting train subjects sagittal:  60%|██████    | 160/266 [00:45<00:22,  4.64it/s]predicting train subjects sagittal:  61%|██████    | 161/266 [00:45<00:22,  4.64it/s]predicting train subjects sagittal:  61%|██████    | 162/266 [00:45<00:22,  4.67it/s]predicting train subjects sagittal:  61%|██████▏   | 163/266 [00:45<00:21,  4.73it/s]predicting train subjects sagittal:  62%|██████▏   | 164/266 [00:46<00:21,  4.77it/s]predicting train subjects sagittal:  62%|██████▏   | 165/266 [00:46<00:21,  4.81it/s]predicting train subjects sagittal:  62%|██████▏   | 166/266 [00:46<00:21,  4.75it/s]predicting train subjects sagittal:  63%|██████▎   | 167/266 [00:46<00:20,  4.74it/s]predicting train subjects sagittal:  63%|██████▎   | 168/266 [00:47<00:20,  4.78it/s]predicting train subjects sagittal:  64%|██████▎   | 169/266 [00:47<00:20,  4.83it/s]predicting train subjects sagittal:  64%|██████▍   | 170/266 [00:47<00:20,  4.78it/s]predicting train subjects sagittal:  64%|██████▍   | 171/266 [00:47<00:19,  4.80it/s]predicting train subjects sagittal:  65%|██████▍   | 172/266 [00:47<00:19,  4.72it/s]predicting train subjects sagittal:  65%|██████▌   | 173/266 [00:48<00:20,  4.52it/s]predicting train subjects sagittal:  65%|██████▌   | 174/266 [00:48<00:20,  4.39it/s]predicting train subjects sagittal:  66%|██████▌   | 175/266 [00:48<00:22,  4.06it/s]predicting train subjects sagittal:  66%|██████▌   | 176/266 [00:48<00:21,  4.10it/s]predicting train subjects sagittal:  67%|██████▋   | 177/266 [00:49<00:21,  4.13it/s]predicting train subjects sagittal:  67%|██████▋   | 178/266 [00:49<00:21,  4.16it/s]predicting train subjects sagittal:  67%|██████▋   | 179/266 [00:49<00:21,  4.08it/s]predicting train subjects sagittal:  68%|██████▊   | 180/266 [00:49<00:21,  4.05it/s]predicting train subjects sagittal:  68%|██████▊   | 181/266 [00:50<00:20,  4.08it/s]predicting train subjects sagittal:  68%|██████▊   | 182/266 [00:50<00:20,  4.06it/s]predicting train subjects sagittal:  69%|██████▉   | 183/266 [00:50<00:20,  4.07it/s]predicting train subjects sagittal:  69%|██████▉   | 184/266 [00:50<00:21,  3.86it/s]predicting train subjects sagittal:  70%|██████▉   | 185/266 [00:51<00:22,  3.62it/s]predicting train subjects sagittal:  70%|██████▉   | 186/266 [00:51<00:21,  3.71it/s]predicting train subjects sagittal:  70%|███████   | 187/266 [00:51<00:21,  3.68it/s]predicting train subjects sagittal:  71%|███████   | 188/266 [00:51<00:20,  3.75it/s]predicting train subjects sagittal:  71%|███████   | 189/266 [00:52<00:20,  3.83it/s]predicting train subjects sagittal:  71%|███████▏  | 190/266 [00:52<00:20,  3.78it/s]predicting train subjects sagittal:  72%|███████▏  | 191/266 [00:52<00:19,  3.80it/s]predicting train subjects sagittal:  72%|███████▏  | 192/266 [00:53<00:19,  3.76it/s]predicting train subjects sagittal:  73%|███████▎  | 193/266 [00:53<00:19,  3.73it/s]predicting train subjects sagittal:  73%|███████▎  | 194/266 [00:53<00:19,  3.68it/s]predicting train subjects sagittal:  73%|███████▎  | 195/266 [00:53<00:19,  3.64it/s]predicting train subjects sagittal:  74%|███████▎  | 196/266 [00:54<00:18,  3.74it/s]predicting train subjects sagittal:  74%|███████▍  | 197/266 [00:54<00:18,  3.65it/s]predicting train subjects sagittal:  74%|███████▍  | 198/266 [00:54<00:18,  3.59it/s]predicting train subjects sagittal:  75%|███████▍  | 199/266 [00:54<00:18,  3.70it/s]predicting train subjects sagittal:  75%|███████▌  | 200/266 [00:55<00:17,  3.72it/s]predicting train subjects sagittal:  76%|███████▌  | 201/266 [00:55<00:18,  3.61it/s]predicting train subjects sagittal:  76%|███████▌  | 202/266 [00:55<00:18,  3.54it/s]predicting train subjects sagittal:  76%|███████▋  | 203/266 [00:56<00:16,  3.72it/s]predicting train subjects sagittal:  77%|███████▋  | 204/266 [00:56<00:16,  3.84it/s]predicting train subjects sagittal:  77%|███████▋  | 205/266 [00:56<00:15,  3.91it/s]predicting train subjects sagittal:  77%|███████▋  | 206/266 [00:56<00:15,  3.90it/s]predicting train subjects sagittal:  78%|███████▊  | 207/266 [00:57<00:15,  3.77it/s]predicting train subjects sagittal:  78%|███████▊  | 208/266 [00:57<00:16,  3.57it/s]predicting train subjects sagittal:  79%|███████▊  | 209/266 [00:57<00:16,  3.46it/s]predicting train subjects sagittal:  79%|███████▉  | 210/266 [00:58<00:16,  3.39it/s]predicting train subjects sagittal:  79%|███████▉  | 211/266 [00:58<00:15,  3.47it/s]predicting train subjects sagittal:  80%|███████▉  | 212/266 [00:58<00:15,  3.41it/s]predicting train subjects sagittal:  80%|████████  | 213/266 [00:58<00:14,  3.63it/s]predicting train subjects sagittal:  80%|████████  | 214/266 [00:59<00:13,  3.79it/s]predicting train subjects sagittal:  81%|████████  | 215/266 [00:59<00:12,  4.01it/s]predicting train subjects sagittal:  81%|████████  | 216/266 [00:59<00:12,  4.09it/s]predicting train subjects sagittal:  82%|████████▏ | 217/266 [00:59<00:11,  4.12it/s]predicting train subjects sagittal:  82%|████████▏ | 218/266 [00:59<00:11,  4.09it/s]predicting train subjects sagittal:  82%|████████▏ | 219/266 [01:00<00:11,  4.12it/s]predicting train subjects sagittal:  83%|████████▎ | 220/266 [01:00<00:10,  4.23it/s]predicting train subjects sagittal:  83%|████████▎ | 221/266 [01:00<00:10,  4.32it/s]predicting train subjects sagittal:  83%|████████▎ | 222/266 [01:00<00:10,  4.29it/s]predicting train subjects sagittal:  84%|████████▍ | 223/266 [01:01<00:09,  4.36it/s]predicting train subjects sagittal:  84%|████████▍ | 224/266 [01:01<00:09,  4.39it/s]predicting train subjects sagittal:  85%|████████▍ | 225/266 [01:01<00:09,  4.42it/s]predicting train subjects sagittal:  85%|████████▍ | 226/266 [01:01<00:09,  4.39it/s]predicting train subjects sagittal:  85%|████████▌ | 227/266 [01:02<00:08,  4.40it/s]predicting train subjects sagittal:  86%|████████▌ | 228/266 [01:02<00:08,  4.46it/s]predicting train subjects sagittal:  86%|████████▌ | 229/266 [01:02<00:08,  4.47it/s]predicting train subjects sagittal:  86%|████████▋ | 230/266 [01:02<00:08,  4.49it/s]predicting train subjects sagittal:  87%|████████▋ | 231/266 [01:02<00:08,  4.34it/s]predicting train subjects sagittal:  87%|████████▋ | 232/266 [01:03<00:07,  4.32it/s]predicting train subjects sagittal:  88%|████████▊ | 233/266 [01:03<00:07,  4.14it/s]predicting train subjects sagittal:  88%|████████▊ | 234/266 [01:03<00:07,  4.14it/s]predicting train subjects sagittal:  88%|████████▊ | 235/266 [01:03<00:07,  4.12it/s]predicting train subjects sagittal:  89%|████████▊ | 236/266 [01:04<00:07,  4.21it/s]predicting train subjects sagittal:  89%|████████▉ | 237/266 [01:04<00:06,  4.23it/s]predicting train subjects sagittal:  89%|████████▉ | 238/266 [01:04<00:06,  4.18it/s]predicting train subjects sagittal:  90%|████████▉ | 239/266 [01:04<00:06,  4.01it/s]predicting train subjects sagittal:  90%|█████████ | 240/266 [01:05<00:06,  4.00it/s]predicting train subjects sagittal:  91%|█████████ | 241/266 [01:05<00:06,  4.11it/s]predicting train subjects sagittal:  91%|█████████ | 242/266 [01:05<00:05,  4.20it/s]predicting train subjects sagittal:  91%|█████████▏| 243/266 [01:05<00:05,  4.26it/s]predicting train subjects sagittal:  92%|█████████▏| 244/266 [01:06<00:05,  4.21it/s]predicting train subjects sagittal:  92%|█████████▏| 245/266 [01:06<00:05,  4.00it/s]predicting train subjects sagittal:  92%|█████████▏| 246/266 [01:06<00:04,  4.12it/s]predicting train subjects sagittal:  93%|█████████▎| 247/266 [01:06<00:04,  4.17it/s]predicting train subjects sagittal:  93%|█████████▎| 248/266 [01:07<00:04,  4.21it/s]predicting train subjects sagittal:  94%|█████████▎| 249/266 [01:07<00:04,  3.95it/s]predicting train subjects sagittal:  94%|█████████▍| 250/266 [01:07<00:04,  3.86it/s]predicting train subjects sagittal:  94%|█████████▍| 251/266 [01:07<00:03,  3.78it/s]predicting train subjects sagittal:  95%|█████████▍| 252/266 [01:08<00:03,  3.52it/s]predicting train subjects sagittal:  95%|█████████▌| 253/266 [01:08<00:03,  3.52it/s]predicting train subjects sagittal:  95%|█████████▌| 254/266 [01:08<00:03,  3.37it/s]predicting train subjects sagittal:  96%|█████████▌| 255/266 [01:09<00:03,  3.35it/s]predicting train subjects sagittal:  96%|█████████▌| 256/266 [01:09<00:02,  3.41it/s]predicting train subjects sagittal:  97%|█████████▋| 257/266 [01:09<00:02,  3.32it/s]predicting train subjects sagittal:  97%|█████████▋| 258/266 [01:10<00:02,  3.26it/s]predicting train subjects sagittal:  97%|█████████▋| 259/266 [01:10<00:02,  3.33it/s]predicting train subjects sagittal:  98%|█████████▊| 260/266 [01:10<00:01,  3.35it/s]predicting train subjects sagittal:  98%|█████████▊| 261/266 [01:10<00:01,  3.36it/s]predicting train subjects sagittal:  98%|█████████▊| 262/266 [01:11<00:01,  3.41it/s]predicting train subjects sagittal:  99%|█████████▉| 263/266 [01:11<00:00,  3.47it/s]predicting train subjects sagittal:  99%|█████████▉| 264/266 [01:11<00:00,  3.35it/s]predicting train subjects sagittal: 100%|█████████▉| 265/266 [01:12<00:00,  3.37it/s]predicting train subjects sagittal: 100%|██████████| 266/266 [01:12<00:00,  3.44it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 73.91it/s]
saving BB  train1-THALAMUS:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   3%|▎         | 7/266 [00:00<00:04, 63.75it/s]saving BB  train1-THALAMUS:   5%|▌         | 14/266 [00:00<00:04, 62.83it/s]saving BB  train1-THALAMUS:   8%|▊         | 21/266 [00:00<00:03, 62.40it/s]saving BB  train1-THALAMUS:  11%|█         | 28/266 [00:00<00:03, 63.95it/s]saving BB  train1-THALAMUS:  13%|█▎        | 35/266 [00:00<00:03, 65.54it/s]saving BB  train1-THALAMUS:  16%|█▌        | 43/266 [00:00<00:03, 67.08it/s]saving BB  train1-THALAMUS:  19%|█▉        | 51/266 [00:00<00:03, 69.39it/s]saving BB  train1-THALAMUS:  22%|██▏       | 59/266 [00:00<00:02, 71.22it/s]saving BB  train1-THALAMUS:  26%|██▌       | 68/266 [00:00<00:02, 74.54it/s]saving BB  train1-THALAMUS:  29%|██▉       | 77/266 [00:01<00:02, 77.21it/s]saving BB  train1-THALAMUS:  32%|███▏      | 85/266 [00:01<00:02, 75.65it/s]saving BB  train1-THALAMUS:  35%|███▍      | 93/266 [00:01<00:02, 73.26it/s]saving BB  train1-THALAMUS:  38%|███▊      | 101/266 [00:01<00:02, 73.57it/s]saving BB  train1-THALAMUS:  41%|████      | 109/266 [00:01<00:02, 74.46it/s]saving BB  train1-THALAMUS:  44%|████▍     | 117/266 [00:01<00:01, 74.86it/s]saving BB  train1-THALAMUS:  47%|████▋     | 125/266 [00:01<00:01, 73.88it/s]saving BB  train1-THALAMUS:  50%|█████     | 133/266 [00:01<00:01, 73.03it/s]saving BB  train1-THALAMUS:  53%|█████▎    | 141/266 [00:01<00:01, 72.17it/s]saving BB  train1-THALAMUS:  56%|█████▌    | 149/266 [00:02<00:01, 71.93it/s]saving BB  train1-THALAMUS:  59%|█████▉    | 157/266 [00:02<00:01, 73.10it/s]saving BB  train1-THALAMUS:  62%|██████▏   | 166/266 [00:02<00:01, 76.29it/s]saving BB  train1-THALAMUS:  66%|██████▌   | 175/266 [00:02<00:01, 78.41it/s]saving BB  train1-THALAMUS:  69%|██████▉   | 184/266 [00:02<00:01, 79.92it/s]saving BB  train1-THALAMUS:  73%|███████▎  | 193/266 [00:02<00:00, 80.50it/s]saving BB  train1-THALAMUS:  76%|███████▌  | 202/266 [00:02<00:00, 76.86it/s]saving BB  train1-THALAMUS:  79%|███████▉  | 210/266 [00:02<00:00, 75.43it/s]saving BB  train1-THALAMUS:  82%|████████▏ | 218/266 [00:02<00:00, 72.85it/s]saving BB  train1-THALAMUS:  85%|████████▌ | 227/266 [00:03<00:00, 75.47it/s]saving BB  train1-THALAMUS:  89%|████████▊ | 236/266 [00:03<00:00, 78.05it/s]saving BB  train1-THALAMUS:  92%|█████████▏| 245/266 [00:03<00:00, 79.59it/s]saving BB  train1-THALAMUS:  95%|█████████▌| 254/266 [00:03<00:00, 77.57it/s]saving BB  train1-THALAMUS:  98%|█████████▊| 262/266 [00:03<00:00, 75.20it/s]saving BB  train1-THALAMUS: 100%|██████████| 266/266 [00:03<00:00, 74.15it/s]
saving BB  test1-THALAMUS Sagittal:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS Sagittal: 100%|██████████| 5/5 [00:00<00:00, 75.34it/s]
saving BB  train1-THALAMUS Sagittal:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS Sagittal:   3%|▎         | 7/266 [00:00<00:03, 68.14it/s]saving BB  train1-THALAMUS Sagittal:   5%|▌         | 14/266 [00:00<00:03, 67.06it/s]saving BB  train1-THALAMUS Sagittal:   8%|▊         | 21/266 [00:00<00:03, 66.62it/s]saving BB  train1-THALAMUS Sagittal:  11%|█         | 29/266 [00:00<00:03, 67.74it/s]saving BB  train1-THALAMUS Sagittal:  14%|█▍        | 37/266 [00:00<00:03, 69.33it/s]saving BB  train1-THALAMUS Sagittal:  17%|█▋        | 45/266 [00:00<00:03, 70.88it/s]saving BB  train1-THALAMUS Sagittal:  20%|█▉        | 53/266 [00:00<00:02, 72.01it/s]saving BB  train1-THALAMUS Sagittal:  23%|██▎       | 61/266 [00:00<00:02, 73.64it/s]saving BB  train1-THALAMUS Sagittal:  26%|██▋       | 70/266 [00:00<00:02, 76.50it/s]saving BB  train1-THALAMUS Sagittal:  30%|██▉       | 79/266 [00:01<00:02, 77.94it/s]saving BB  train1-THALAMUS Sagittal:  33%|███▎      | 87/266 [00:01<00:02, 75.82it/s]saving BB  train1-THALAMUS Sagittal:  36%|███▌      | 95/266 [00:01<00:02, 74.69it/s]saving BB  train1-THALAMUS Sagittal:  39%|███▊      | 103/266 [00:01<00:02, 71.43it/s]saving BB  train1-THALAMUS Sagittal:  42%|████▏     | 111/266 [00:01<00:02, 72.57it/s]saving BB  train1-THALAMUS Sagittal:  45%|████▍     | 119/266 [00:01<00:02, 72.59it/s]saving BB  train1-THALAMUS Sagittal:  48%|████▊     | 127/266 [00:01<00:01, 71.83it/s]saving BB  train1-THALAMUS Sagittal:  51%|█████     | 135/266 [00:01<00:01, 71.22it/s]saving BB  train1-THALAMUS Sagittal:  54%|█████▍    | 143/266 [00:01<00:01, 71.15it/s]saving BB  train1-THALAMUS Sagittal:  57%|█████▋    | 151/266 [00:02<00:01, 70.86it/s]saving BB  train1-THALAMUS Sagittal:  60%|█████▉    | 159/266 [00:02<00:01, 73.08it/s]saving BB  train1-THALAMUS Sagittal:  63%|██████▎   | 168/266 [00:02<00:01, 76.22it/s]saving BB  train1-THALAMUS Sagittal:  67%|██████▋   | 177/266 [00:02<00:01, 78.64it/s]saving BB  train1-THALAMUS Sagittal:  70%|██████▉   | 186/266 [00:02<00:00, 80.36it/s]saving BB  train1-THALAMUS Sagittal:  73%|███████▎  | 195/266 [00:02<00:00, 77.65it/s]saving BB  train1-THALAMUS Sagittal:  76%|███████▋  | 203/266 [00:02<00:00, 76.25it/s]saving BB  train1-THALAMUS Sagittal:  79%|███████▉  | 211/266 [00:02<00:00, 74.37it/s]saving BB  train1-THALAMUS Sagittal:  82%|████████▏ | 219/266 [00:02<00:00, 75.38it/s]saving BB  train1-THALAMUS Sagittal:  85%|████████▌ | 227/266 [00:03<00:00, 76.54it/s]saving BB  train1-THALAMUS Sagittal:  89%|████████▊ | 236/266 [00:03<00:00, 77.89it/s]saving BB  train1-THALAMUS Sagittal:  92%|█████████▏| 245/266 [00:03<00:00, 79.23it/s]saving BB  train1-THALAMUS Sagittal:  95%|█████████▌| 253/266 [00:03<00:00, 76.64it/s]saving BB  train1-THALAMUS Sagittal:  98%|█████████▊| 261/266 [00:03<00:00, 75.05it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 266/266 [00:03<00:00, 74.32it/s]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:01<07:16,  1.65s/it]Loading train:   1%|          | 2/266 [00:03<07:10,  1.63s/it]Loading train:   1%|          | 3/266 [00:04<06:28,  1.48s/it]Loading train:   2%|▏         | 4/266 [00:05<05:49,  1.33s/it]Loading train:   2%|▏         | 5/266 [00:06<06:02,  1.39s/it]Loading train:   2%|▏         | 6/266 [00:07<05:20,  1.23s/it]Loading train:   3%|▎         | 7/266 [00:08<05:07,  1.19s/it]Loading train:   3%|▎         | 8/266 [00:09<04:47,  1.11s/it]Loading train:   3%|▎         | 9/266 [00:10<04:35,  1.07s/it]Loading train:   4%|▍         | 10/266 [00:11<04:23,  1.03s/it]Loading train:   4%|▍         | 11/266 [00:12<04:22,  1.03s/it]Loading train:   5%|▍         | 12/266 [00:13<04:16,  1.01s/it]Loading train:   5%|▍         | 13/266 [00:14<04:09,  1.02it/s]Loading train:   5%|▌         | 14/266 [00:15<04:00,  1.05it/s]Loading train:   6%|▌         | 15/266 [00:16<03:57,  1.06it/s]Loading train:   6%|▌         | 16/266 [00:17<03:58,  1.05it/s]Loading train:   6%|▋         | 17/266 [00:18<03:53,  1.07it/s]Loading train:   7%|▋         | 18/266 [00:19<03:51,  1.07it/s]Loading train:   7%|▋         | 19/266 [00:20<03:52,  1.06it/s]Loading train:   8%|▊         | 20/266 [00:20<03:40,  1.11it/s]Loading train:   8%|▊         | 21/266 [00:21<03:41,  1.10it/s]Loading train:   8%|▊         | 22/266 [00:22<03:46,  1.08it/s]Loading train:   9%|▊         | 23/266 [00:23<03:53,  1.04it/s]Loading train:   9%|▉         | 24/266 [00:24<03:52,  1.04it/s]Loading train:   9%|▉         | 25/266 [00:25<03:43,  1.08it/s]Loading train:  10%|▉         | 26/266 [00:26<03:37,  1.11it/s]Loading train:  10%|█         | 27/266 [00:27<03:35,  1.11it/s]Loading train:  11%|█         | 28/266 [00:28<03:30,  1.13it/s]Loading train:  11%|█         | 29/266 [00:29<03:33,  1.11it/s]Loading train:  11%|█▏        | 30/266 [00:30<03:30,  1.12it/s]Loading train:  12%|█▏        | 31/266 [00:31<03:34,  1.10it/s]Loading train:  12%|█▏        | 32/266 [00:32<03:38,  1.07it/s]Loading train:  12%|█▏        | 33/266 [00:32<03:35,  1.08it/s]Loading train:  13%|█▎        | 34/266 [00:33<03:34,  1.08it/s]Loading train:  13%|█▎        | 35/266 [00:34<03:33,  1.08it/s]Loading train:  14%|█▎        | 36/266 [00:35<03:24,  1.13it/s]Loading train:  14%|█▍        | 37/266 [00:36<03:21,  1.14it/s]Loading train:  14%|█▍        | 38/266 [00:37<03:21,  1.13it/s]Loading train:  15%|█▍        | 39/266 [00:38<03:15,  1.16it/s]Loading train:  15%|█▌        | 40/266 [00:39<03:15,  1.16it/s]Loading train:  15%|█▌        | 41/266 [00:39<03:17,  1.14it/s]Loading train:  16%|█▌        | 42/266 [00:40<03:12,  1.17it/s]Loading train:  16%|█▌        | 43/266 [00:41<03:00,  1.23it/s]Loading train:  17%|█▋        | 44/266 [00:42<03:00,  1.23it/s]Loading train:  17%|█▋        | 45/266 [00:43<02:56,  1.25it/s]Loading train:  17%|█▋        | 46/266 [00:43<03:02,  1.20it/s]Loading train:  18%|█▊        | 47/266 [00:44<02:50,  1.28it/s]Loading train:  18%|█▊        | 48/266 [00:45<02:52,  1.27it/s]Loading train:  18%|█▊        | 49/266 [00:46<02:47,  1.30it/s]Loading train:  19%|█▉        | 50/266 [00:46<02:41,  1.34it/s]Loading train:  19%|█▉        | 51/266 [00:47<02:40,  1.34it/s]Loading train:  20%|█▉        | 52/266 [00:48<02:38,  1.35it/s]Loading train:  20%|█▉        | 53/266 [00:49<02:37,  1.35it/s]Loading train:  20%|██        | 54/266 [00:49<02:32,  1.39it/s]Loading train:  21%|██        | 55/266 [00:50<02:30,  1.40it/s]Loading train:  21%|██        | 56/266 [00:51<02:28,  1.41it/s]Loading train:  21%|██▏       | 57/266 [00:51<02:27,  1.41it/s]Loading train:  22%|██▏       | 58/266 [00:52<02:28,  1.40it/s]Loading train:  22%|██▏       | 59/266 [00:53<02:22,  1.45it/s]Loading train:  23%|██▎       | 60/266 [00:53<02:29,  1.38it/s]Loading train:  23%|██▎       | 61/266 [00:54<02:23,  1.43it/s]Loading train:  23%|██▎       | 62/266 [00:55<02:20,  1.45it/s]Loading train:  24%|██▎       | 63/266 [00:55<02:16,  1.49it/s]Loading train:  24%|██▍       | 64/266 [00:56<02:14,  1.50it/s]Loading train:  24%|██▍       | 65/266 [00:57<02:14,  1.50it/s]Loading train:  25%|██▍       | 66/266 [00:57<02:14,  1.48it/s]Loading train:  25%|██▌       | 67/266 [00:58<02:15,  1.47it/s]Loading train:  26%|██▌       | 68/266 [00:59<02:10,  1.52it/s]Loading train:  26%|██▌       | 69/266 [00:59<02:06,  1.55it/s]Loading train:  26%|██▋       | 70/266 [01:00<02:04,  1.58it/s]Loading train:  27%|██▋       | 71/266 [01:01<02:09,  1.50it/s]Loading train:  27%|██▋       | 72/266 [01:01<02:10,  1.49it/s]Loading train:  27%|██▋       | 73/266 [01:02<02:07,  1.52it/s]Loading train:  28%|██▊       | 74/266 [01:03<02:01,  1.58it/s]Loading train:  28%|██▊       | 75/266 [01:03<01:59,  1.60it/s]Loading train:  29%|██▊       | 76/266 [01:04<01:59,  1.59it/s]Loading train:  29%|██▉       | 77/266 [01:05<02:02,  1.55it/s]Loading train:  29%|██▉       | 78/266 [01:06<02:25,  1.29it/s]Loading train:  30%|██▉       | 79/266 [01:07<02:33,  1.22it/s]Loading train:  30%|███       | 80/266 [01:07<02:37,  1.18it/s]Loading train:  30%|███       | 81/266 [01:08<02:36,  1.18it/s]Loading train:  31%|███       | 82/266 [01:09<02:34,  1.19it/s]Loading train:  31%|███       | 83/266 [01:10<02:37,  1.17it/s]Loading train:  32%|███▏      | 84/266 [01:11<02:40,  1.13it/s]Loading train:  32%|███▏      | 85/266 [01:12<02:46,  1.09it/s]Loading train:  32%|███▏      | 86/266 [01:13<02:46,  1.08it/s]Loading train:  33%|███▎      | 87/266 [01:14<02:44,  1.09it/s]Loading train:  33%|███▎      | 88/266 [01:15<02:46,  1.07it/s]Loading train:  33%|███▎      | 89/266 [01:16<02:45,  1.07it/s]Loading train:  34%|███▍      | 90/266 [01:17<02:46,  1.06it/s]Loading train:  34%|███▍      | 91/266 [01:18<02:48,  1.04it/s]Loading train:  35%|███▍      | 92/266 [01:19<02:43,  1.06it/s]Loading train:  35%|███▍      | 93/266 [01:19<02:39,  1.08it/s]Loading train:  35%|███▌      | 94/266 [01:20<02:38,  1.08it/s]Loading train:  36%|███▌      | 95/266 [01:21<02:35,  1.10it/s]Loading train:  36%|███▌      | 96/266 [01:22<02:49,  1.00it/s]Loading train:  36%|███▋      | 97/266 [01:24<03:09,  1.12s/it]Loading train:  37%|███▋      | 98/266 [01:25<03:08,  1.12s/it]Loading train:  37%|███▋      | 99/266 [01:26<02:59,  1.08s/it]Loading train:  38%|███▊      | 100/266 [01:27<03:00,  1.09s/it]Loading train:  38%|███▊      | 101/266 [01:28<02:41,  1.02it/s]Loading train:  38%|███▊      | 102/266 [01:29<02:28,  1.10it/s]Loading train:  39%|███▊      | 103/266 [01:29<02:21,  1.15it/s]Loading train:  39%|███▉      | 104/266 [01:30<02:13,  1.22it/s]Loading train:  39%|███▉      | 105/266 [01:31<02:10,  1.23it/s]Loading train:  40%|███▉      | 106/266 [01:32<02:07,  1.26it/s]Loading train:  40%|████      | 107/266 [01:32<02:04,  1.28it/s]Loading train:  41%|████      | 108/266 [01:33<02:02,  1.29it/s]Loading train:  41%|████      | 109/266 [01:34<02:02,  1.28it/s]Loading train:  41%|████▏     | 110/266 [01:35<02:03,  1.26it/s]Loading train:  42%|████▏     | 111/266 [01:35<02:03,  1.25it/s]Loading train:  42%|████▏     | 112/266 [01:36<02:02,  1.26it/s]Loading train:  42%|████▏     | 113/266 [01:37<01:59,  1.28it/s]Loading train:  43%|████▎     | 114/266 [01:38<01:56,  1.31it/s]Loading train:  43%|████▎     | 115/266 [01:38<01:52,  1.34it/s]Loading train:  44%|████▎     | 116/266 [01:39<01:51,  1.34it/s]Loading train:  44%|████▍     | 117/266 [01:40<01:48,  1.37it/s]Loading train:  44%|████▍     | 118/266 [01:41<01:48,  1.37it/s]Loading train:  45%|████▍     | 119/266 [01:41<01:50,  1.33it/s]Loading train:  45%|████▌     | 120/266 [01:42<01:51,  1.31it/s]Loading train:  45%|████▌     | 121/266 [01:43<01:56,  1.25it/s]Loading train:  46%|████▌     | 122/266 [01:44<02:00,  1.19it/s]Loading train:  46%|████▌     | 123/266 [01:45<02:03,  1.16it/s]Loading train:  47%|████▋     | 124/266 [01:46<02:05,  1.13it/s]Loading train:  47%|████▋     | 125/266 [01:47<02:03,  1.14it/s]Loading train:  47%|████▋     | 126/266 [01:48<02:00,  1.16it/s]Loading train:  48%|████▊     | 127/266 [01:48<02:00,  1.15it/s]Loading train:  48%|████▊     | 128/266 [01:49<02:01,  1.14it/s]Loading train:  48%|████▊     | 129/266 [01:50<02:01,  1.13it/s]Loading train:  49%|████▉     | 130/266 [01:51<01:57,  1.16it/s]Loading train:  49%|████▉     | 131/266 [01:52<01:59,  1.13it/s]Loading train:  50%|████▉     | 132/266 [01:53<01:54,  1.17it/s]Loading train:  50%|█████     | 133/266 [01:54<01:52,  1.18it/s]Loading train:  50%|█████     | 134/266 [01:54<01:50,  1.19it/s]Loading train:  51%|█████     | 135/266 [01:55<01:46,  1.23it/s]Loading train:  51%|█████     | 136/266 [01:56<01:45,  1.23it/s]Loading train:  52%|█████▏    | 137/266 [01:57<01:45,  1.22it/s]Loading train:  52%|█████▏    | 138/266 [01:58<01:43,  1.23it/s]Loading train:  52%|█████▏    | 139/266 [01:58<01:42,  1.24it/s]Loading train:  53%|█████▎    | 140/266 [01:59<01:42,  1.23it/s]Loading train:  53%|█████▎    | 141/266 [02:00<01:42,  1.22it/s]Loading train:  53%|█████▎    | 142/266 [02:01<01:44,  1.19it/s]Loading train:  54%|█████▍    | 143/266 [02:02<01:44,  1.17it/s]Loading train:  54%|█████▍    | 144/266 [02:03<01:41,  1.20it/s]Loading train:  55%|█████▍    | 145/266 [02:03<01:40,  1.21it/s]Loading train:  55%|█████▍    | 146/266 [02:04<01:39,  1.20it/s]Loading train:  55%|█████▌    | 147/266 [02:05<01:40,  1.19it/s]Loading train:  56%|█████▌    | 148/266 [02:06<01:42,  1.15it/s]Loading train:  56%|█████▌    | 149/266 [02:07<01:42,  1.14it/s]Loading train:  56%|█████▋    | 150/266 [02:08<01:42,  1.13it/s]Loading train:  57%|█████▋    | 151/266 [02:09<01:39,  1.15it/s]Loading train:  57%|█████▋    | 152/266 [02:10<01:37,  1.17it/s]Loading train:  58%|█████▊    | 153/266 [02:10<01:34,  1.20it/s]Loading train:  58%|█████▊    | 154/266 [02:11<01:32,  1.21it/s]Loading train:  58%|█████▊    | 155/266 [02:12<01:26,  1.29it/s]Loading train:  59%|█████▊    | 156/266 [02:12<01:19,  1.39it/s]Loading train:  59%|█████▉    | 157/266 [02:13<01:13,  1.47it/s]Loading train:  59%|█████▉    | 158/266 [02:14<01:10,  1.53it/s]Loading train:  60%|█████▉    | 159/266 [02:14<01:10,  1.52it/s]Loading train:  60%|██████    | 160/266 [02:15<01:08,  1.56it/s]Loading train:  61%|██████    | 161/266 [02:15<01:05,  1.59it/s]Loading train:  61%|██████    | 162/266 [02:16<01:06,  1.57it/s]Loading train:  61%|██████▏   | 163/266 [02:17<01:05,  1.58it/s]Loading train:  62%|██████▏   | 164/266 [02:17<01:02,  1.64it/s]Loading train:  62%|██████▏   | 165/266 [02:18<01:02,  1.62it/s]Loading train:  62%|██████▏   | 166/266 [02:19<01:04,  1.56it/s]Loading train:  63%|██████▎   | 167/266 [02:19<01:02,  1.58it/s]Loading train:  63%|██████▎   | 168/266 [02:20<01:01,  1.59it/s]Loading train:  64%|██████▎   | 169/266 [02:20<01:01,  1.58it/s]Loading train:  64%|██████▍   | 170/266 [02:21<01:02,  1.55it/s]Loading train:  64%|██████▍   | 171/266 [02:22<01:00,  1.56it/s]Loading train:  65%|██████▍   | 172/266 [02:22<01:00,  1.55it/s]Loading train:  65%|██████▌   | 173/266 [02:23<01:01,  1.52it/s]Loading train:  65%|██████▌   | 174/266 [02:24<01:02,  1.48it/s]Loading train:  66%|██████▌   | 175/266 [02:25<01:04,  1.42it/s]Loading train:  66%|██████▌   | 176/266 [02:25<01:02,  1.44it/s]Loading train:  67%|██████▋   | 177/266 [02:26<01:02,  1.43it/s]Loading train:  67%|██████▋   | 178/266 [02:27<01:01,  1.43it/s]Loading train:  67%|██████▋   | 179/266 [02:27<01:02,  1.38it/s]Loading train:  68%|██████▊   | 180/266 [02:28<01:04,  1.34it/s]Loading train:  68%|██████▊   | 181/266 [02:29<01:02,  1.36it/s]Loading train:  68%|██████▊   | 182/266 [02:30<01:00,  1.38it/s]Loading train:  69%|██████▉   | 183/266 [02:30<01:01,  1.35it/s]Loading train:  69%|██████▉   | 184/266 [02:31<00:59,  1.39it/s]Loading train:  70%|██████▉   | 185/266 [02:32<00:57,  1.41it/s]Loading train:  70%|██████▉   | 186/266 [02:33<00:56,  1.43it/s]Loading train:  70%|███████   | 187/266 [02:33<00:55,  1.43it/s]Loading train:  71%|███████   | 188/266 [02:34<00:55,  1.40it/s]Loading train:  71%|███████   | 189/266 [02:35<00:55,  1.38it/s]Loading train:  71%|███████▏  | 190/266 [02:35<00:56,  1.35it/s]Loading train:  72%|███████▏  | 191/266 [02:37<01:05,  1.14it/s]Loading train:  72%|███████▏  | 192/266 [02:38<01:08,  1.08it/s]Loading train:  73%|███████▎  | 193/266 [02:39<01:11,  1.03it/s]Loading train:  73%|███████▎  | 194/266 [02:40<01:18,  1.10s/it]Loading train:  73%|███████▎  | 195/266 [02:41<01:12,  1.03s/it]Loading train:  74%|███████▎  | 196/266 [02:42<01:08,  1.03it/s]Loading train:  74%|███████▍  | 197/266 [02:43<01:05,  1.06it/s]Loading train:  74%|███████▍  | 198/266 [02:44<01:00,  1.12it/s]Loading train:  75%|███████▍  | 199/266 [02:44<00:58,  1.14it/s]Loading train:  75%|███████▌  | 200/266 [02:45<00:55,  1.19it/s]Loading train:  76%|███████▌  | 201/266 [02:46<00:52,  1.23it/s]Loading train:  76%|███████▌  | 202/266 [02:47<00:50,  1.28it/s]Loading train:  76%|███████▋  | 203/266 [02:47<00:47,  1.33it/s]Loading train:  77%|███████▋  | 204/266 [02:48<00:45,  1.36it/s]Loading train:  77%|███████▋  | 205/266 [02:49<00:44,  1.36it/s]Loading train:  77%|███████▋  | 206/266 [02:49<00:43,  1.40it/s]Loading train:  78%|███████▊  | 207/266 [02:50<00:42,  1.38it/s]Loading train:  78%|███████▊  | 208/266 [02:51<00:42,  1.37it/s]Loading train:  79%|███████▊  | 209/266 [02:52<00:40,  1.39it/s]Loading train:  79%|███████▉  | 210/266 [02:52<00:40,  1.39it/s]Loading train:  79%|███████▉  | 211/266 [02:53<00:39,  1.38it/s]Loading train:  80%|███████▉  | 212/266 [02:54<00:40,  1.35it/s]Loading train:  80%|████████  | 213/266 [02:54<00:37,  1.42it/s]Loading train:  80%|████████  | 214/266 [02:55<00:36,  1.44it/s]Loading train:  81%|████████  | 215/266 [02:56<00:35,  1.43it/s]Loading train:  81%|████████  | 216/266 [02:57<00:35,  1.43it/s]Loading train:  82%|████████▏ | 217/266 [02:57<00:33,  1.47it/s]Loading train:  82%|████████▏ | 218/266 [02:58<00:34,  1.39it/s]Loading train:  82%|████████▏ | 219/266 [02:59<00:34,  1.37it/s]Loading train:  83%|████████▎ | 220/266 [02:59<00:33,  1.39it/s]Loading train:  83%|████████▎ | 221/266 [03:00<00:31,  1.42it/s]Loading train:  83%|████████▎ | 222/266 [03:01<00:32,  1.35it/s]Loading train:  84%|████████▍ | 223/266 [03:02<00:34,  1.25it/s]Loading train:  84%|████████▍ | 224/266 [03:03<00:34,  1.20it/s]Loading train:  85%|████████▍ | 225/266 [03:03<00:32,  1.25it/s]Loading train:  85%|████████▍ | 226/266 [03:05<00:34,  1.15it/s]Loading train:  85%|████████▌ | 227/266 [03:05<00:33,  1.18it/s]Loading train:  86%|████████▌ | 228/266 [03:06<00:33,  1.14it/s]Loading train:  86%|████████▌ | 229/266 [03:07<00:31,  1.17it/s]Loading train:  86%|████████▋ | 230/266 [03:08<00:31,  1.14it/s]Loading train:  87%|████████▋ | 231/266 [03:09<00:30,  1.16it/s]Loading train:  87%|████████▋ | 232/266 [03:10<00:29,  1.17it/s]Loading train:  88%|████████▊ | 233/266 [03:11<00:28,  1.15it/s]Loading train:  88%|████████▊ | 234/266 [03:11<00:27,  1.17it/s]Loading train:  88%|████████▊ | 235/266 [03:12<00:25,  1.21it/s]Loading train:  89%|████████▊ | 236/266 [03:13<00:25,  1.17it/s]Loading train:  89%|████████▉ | 237/266 [03:14<00:26,  1.10it/s]Loading train:  89%|████████▉ | 238/266 [03:15<00:25,  1.10it/s]Loading train:  90%|████████▉ | 239/266 [03:16<00:24,  1.11it/s]Loading train:  90%|█████████ | 240/266 [03:17<00:22,  1.13it/s]Loading train:  91%|█████████ | 241/266 [03:18<00:22,  1.10it/s]Loading train:  91%|█████████ | 242/266 [03:18<00:20,  1.14it/s]Loading train:  91%|█████████▏| 243/266 [03:20<00:21,  1.08it/s]Loading train:  92%|█████████▏| 244/266 [03:20<00:19,  1.11it/s]Loading train:  92%|█████████▏| 245/266 [03:21<00:18,  1.15it/s]Loading train:  92%|█████████▏| 246/266 [03:22<00:17,  1.13it/s]Loading train:  93%|█████████▎| 247/266 [03:23<00:16,  1.16it/s]Loading train:  93%|█████████▎| 248/266 [03:24<00:14,  1.22it/s]Loading train:  94%|█████████▎| 249/266 [03:25<00:16,  1.05it/s]Loading train:  94%|█████████▍| 250/266 [03:26<00:15,  1.01it/s]Loading train:  94%|█████████▍| 251/266 [03:27<00:15,  1.01s/it]Loading train:  95%|█████████▍| 252/266 [03:28<00:14,  1.03s/it]Loading train:  95%|█████████▌| 253/266 [03:29<00:13,  1.06s/it]Loading train:  95%|█████████▌| 254/266 [03:30<00:12,  1.04s/it]Loading train:  96%|█████████▌| 255/266 [03:31<00:11,  1.06s/it]Loading train:  96%|█████████▌| 256/266 [03:32<00:10,  1.06s/it]Loading train:  97%|█████████▋| 257/266 [03:33<00:09,  1.03s/it]Loading train:  97%|█████████▋| 258/266 [03:34<00:08,  1.01s/it]Loading train:  97%|█████████▋| 259/266 [03:35<00:07,  1.01s/it]Loading train:  98%|█████████▊| 260/266 [03:36<00:06,  1.01s/it]Loading train:  98%|█████████▊| 261/266 [03:37<00:04,  1.01it/s]Loading train:  98%|█████████▊| 262/266 [03:38<00:03,  1.01it/s]Loading train:  99%|█████████▉| 263/266 [03:39<00:02,  1.02it/s]Loading train:  99%|█████████▉| 264/266 [03:59<00:13,  6.53s/it]Loading train: 100%|█████████▉| 265/266 [04:00<00:05,  5.02s/it]Loading train: 100%|██████████| 266/266 [04:01<00:00,  3.90s/it]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   3%|▎         | 7/266 [00:00<00:03, 67.87it/s]concatenating: train:   6%|▋         | 17/266 [00:00<00:03, 72.75it/s]concatenating: train:   8%|▊         | 22/266 [00:00<00:05, 46.42it/s]concatenating: train:  14%|█▎        | 36/266 [00:00<00:03, 57.73it/s]concatenating: train:  16%|█▌        | 43/266 [00:00<00:03, 57.80it/s]concatenating: train:  19%|█▉        | 50/266 [00:00<00:04, 52.19it/s]concatenating: train:  21%|██        | 56/266 [00:00<00:03, 53.46it/s]concatenating: train:  31%|███       | 82/266 [00:01<00:02, 70.18it/s]concatenating: train:  37%|███▋      | 98/266 [00:01<00:02, 82.70it/s]concatenating: train:  44%|████▎     | 116/266 [00:01<00:01, 95.62it/s]concatenating: train:  49%|████▉     | 130/266 [00:01<00:01, 90.94it/s]concatenating: train:  56%|█████▋    | 150/266 [00:01<00:01, 108.42it/s]concatenating: train:  65%|██████▌   | 174/266 [00:01<00:00, 129.33it/s]concatenating: train:  72%|███████▏  | 192/266 [00:01<00:00, 140.43it/s]concatenating: train:  79%|███████▉  | 210/266 [00:01<00:00, 126.66it/s]concatenating: train:  85%|████████▍ | 226/266 [00:01<00:00, 134.37it/s]concatenating: train:  95%|█████████▌| 253/266 [00:02<00:00, 157.81it/s]concatenating: train: 100%|██████████| 266/266 [00:02<00:00, 121.53it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:01<00:06,  1.56s/it]Loading test:  40%|████      | 2/5 [00:03<00:04,  1.56s/it]Loading test:  60%|██████    | 3/5 [00:04<00:03,  1.57s/it]Loading test:  80%|████████  | 4/5 [00:06<00:01,  1.54s/it]Loading test: 100%|██████████| 5/5 [00:07<00:00,  1.59s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 56.29it/s]2019-08-17 18:24:22.834351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-08-17 18:24:22.834460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-17 18:24:22.834481: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-08-17 18:24:22.834496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-08-17 18:24:22.835020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:89:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.48it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.33it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.14it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.53it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  6.06it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  6.94it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.24it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.82it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.40it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.88it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.10it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:02,  8.38it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:03<00:02,  7.07it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:03<00:01,  7.64it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  6.64it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.35it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.88it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  8.62it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  6.81it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.77it/s]
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 7  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 7  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 84, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 84, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 84, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 84, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 84, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 84, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 84, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 42, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 42, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 42, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 42, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 42, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 42, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 42, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 42, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 42, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 21, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 21, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 21, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 21, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 21, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 21, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 21, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 21, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 21, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 21, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 42, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 42, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 42, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 42, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 42, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 42, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 42, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 42, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 42, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 42, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 84, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 84, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 84, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 84, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 84, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 84, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 84, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 84, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 84, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 84, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 84, 13)   793         dropout_5[0][0]                  
==================================================================================================
Total params: 223,833
Trainable params: 27,473
Non-trainable params: 196,360
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.29809447e-02 3.26421492e-02 7.63291764e-02 9.48428398e-03
 2.74496775e-02 7.18143437e-03 8.68586277e-02 1.13462851e-01
 8.90812352e-02 1.35345395e-02 2.88818886e-01 1.91911216e-01
 2.64977577e-04]
Train on 9482 samples, validate on 175 samples
Epoch 1/300
 - 15s - loss: 2.6294 - acc: 0.7447 - mDice: 0.1185 - val_loss: 2.0251 - val_acc: 0.9124 - val_mDice: 0.2476

Epoch 00001: val_mDice improved from -inf to 0.24760, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 9s - loss: 1.1430 - acc: 0.8840 - mDice: 0.3219 - val_loss: 1.5543 - val_acc: 0.9177 - val_mDice: 0.3669

Epoch 00002: val_mDice improved from 0.24760 to 0.36694, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 9s - loss: 0.8388 - acc: 0.8960 - mDice: 0.4263 - val_loss: 1.3885 - val_acc: 0.9258 - val_mDice: 0.4022

Epoch 00003: val_mDice improved from 0.36694 to 0.40215, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 9s - loss: 0.6891 - acc: 0.9073 - mDice: 0.4931 - val_loss: 1.2806 - val_acc: 0.9321 - val_mDice: 0.4600

Epoch 00004: val_mDice improved from 0.40215 to 0.46001, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 8s - loss: 0.5960 - acc: 0.9167 - mDice: 0.5402 - val_loss: 0.9606 - val_acc: 0.9400 - val_mDice: 0.5372

Epoch 00005: val_mDice improved from 0.46001 to 0.53720, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 8s - loss: 0.5387 - acc: 0.9226 - mDice: 0.5709 - val_loss: 0.9610 - val_acc: 0.9388 - val_mDice: 0.5233

Epoch 00006: val_mDice did not improve from 0.53720
Epoch 7/300
 - 9s - loss: 0.5120 - acc: 0.9251 - mDice: 0.5865 - val_loss: 0.8840 - val_acc: 0.9449 - val_mDice: 0.5947

Epoch 00007: val_mDice improved from 0.53720 to 0.59469, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 9s - loss: 0.4926 - acc: 0.9272 - mDice: 0.5981 - val_loss: 0.8657 - val_acc: 0.9469 - val_mDice: 0.6141

Epoch 00008: val_mDice improved from 0.59469 to 0.61413, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 9s - loss: 0.4726 - acc: 0.9291 - mDice: 0.6101 - val_loss: 0.8092 - val_acc: 0.9477 - val_mDice: 0.6133

Epoch 00009: val_mDice did not improve from 0.61413
Epoch 10/300
 - 10s - loss: 0.4640 - acc: 0.9299 - mDice: 0.6152 - val_loss: 0.6843 - val_acc: 0.9416 - val_mDice: 0.6090

Epoch 00010: val_mDice did not improve from 0.61413
Epoch 11/300
 - 9s - loss: 0.4571 - acc: 0.9308 - mDice: 0.6203 - val_loss: 0.8194 - val_acc: 0.9444 - val_mDice: 0.6133

Epoch 00011: val_mDice did not improve from 0.61413
Epoch 12/300
 - 10s - loss: 0.4488 - acc: 0.9316 - mDice: 0.6252 - val_loss: 0.6982 - val_acc: 0.9453 - val_mDice: 0.6188

Epoch 00012: val_mDice improved from 0.61413 to 0.61881, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 9s - loss: 0.4403 - acc: 0.9320 - mDice: 0.6303 - val_loss: 0.9005 - val_acc: 0.9442 - val_mDice: 0.5821

Epoch 00013: val_mDice did not improve from 0.61881
Epoch 14/300
 - 10s - loss: 0.4332 - acc: 0.9328 - mDice: 0.6350 - val_loss: 0.8079 - val_acc: 0.9483 - val_mDice: 0.6158

Epoch 00014: val_mDice did not improve from 0.61881
Epoch 15/300
 - 9s - loss: 0.4285 - acc: 0.9334 - mDice: 0.6382 - val_loss: 0.8240 - val_acc: 0.9495 - val_mDice: 0.6200

Epoch 00015: val_mDice improved from 0.61881 to 0.62003, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 10s - loss: 0.4247 - acc: 0.9335 - mDice: 0.6407 - val_loss: 0.5849 - val_acc: 0.9477 - val_mDice: 0.6314

Epoch 00016: val_mDice improved from 0.62003 to 0.63141, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 9s - loss: 0.4164 - acc: 0.9343 - mDice: 0.6458 - val_loss: 0.7085 - val_acc: 0.9447 - val_mDice: 0.5611

Epoch 00017: val_mDice did not improve from 0.63141
Epoch 18/300
 - 10s - loss: 0.4146 - acc: 0.9344 - mDice: 0.6473 - val_loss: 0.6034 - val_acc: 0.9440 - val_mDice: 0.6185

Epoch 00018: val_mDice did not improve from 0.63141
Epoch 19/300
 - 9s - loss: 0.4133 - acc: 0.9346 - mDice: 0.6481 - val_loss: 0.6443 - val_acc: 0.9396 - val_mDice: 0.5921

Epoch 00019: val_mDice did not improve from 0.63141
Epoch 20/300
 - 9s - loss: 0.4061 - acc: 0.9351 - mDice: 0.6528 - val_loss: 0.5706 - val_acc: 0.9508 - val_mDice: 0.6333

Epoch 00020: val_mDice improved from 0.63141 to 0.63335, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 21/300
 - 10s - loss: 0.4052 - acc: 0.9347 - mDice: 0.6532 - val_loss: 0.6847 - val_acc: 0.9397 - val_mDice: 0.6131

Epoch 00021: val_mDice did not improve from 0.63335
Epoch 22/300
 - 9s - loss: 0.4021 - acc: 0.9353 - mDice: 0.6555 - val_loss: 0.7512 - val_acc: 0.9424 - val_mDice: 0.6044

Epoch 00022: val_mDice did not improve from 0.63335
Epoch 23/300
 - 9s - loss: 0.4001 - acc: 0.9355 - mDice: 0.6569 - val_loss: 0.6714 - val_acc: 0.9489 - val_mDice: 0.6254

Epoch 00023: val_mDice did not improve from 0.63335
Epoch 24/300
 - 10s - loss: 0.3982 - acc: 0.9356 - mDice: 0.6582 - val_loss: 0.5661 - val_acc: 0.9489 - val_mDice: 0.6177

Epoch 00024: val_mDice did not improve from 0.63335
Epoch 25/300
 - 9s - loss: 0.3930 - acc: 0.9358 - mDice: 0.6614 - val_loss: 0.5336 - val_acc: 0.9446 - val_mDice: 0.6256

Epoch 00025: val_mDice did not improve from 0.63335
Epoch 26/300
 - 9s - loss: 0.3955 - acc: 0.9356 - mDice: 0.6601 - val_loss: 0.8727 - val_acc: 0.9466 - val_mDice: 0.6054

Epoch 00026: val_mDice did not improve from 0.63335
Epoch 27/300
 - 9s - loss: 0.3913 - acc: 0.9361 - mDice: 0.6633 - val_loss: 2.3734 - val_acc: 0.9352 - val_mDice: 0.4797

Epoch 00027: val_mDice did not improve from 0.63335
Epoch 28/300
 - 9s - loss: 0.4138 - acc: 0.9338 - mDice: 0.6484 - val_loss: 0.5472 - val_acc: 0.9516 - val_mDice: 0.6377

Epoch 00028: val_mDice improved from 0.63335 to 0.63767, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 29/300
 - 9s - loss: 0.3907 - acc: 0.9362 - mDice: 0.6633 - val_loss: 0.5213 - val_acc: 0.9495 - val_mDice: 0.6245

Epoch 00029: val_mDice did not improve from 0.63767
Epoch 30/300
 - 9s - loss: 0.3856 - acc: 0.9365 - mDice: 0.6666 - val_loss: 0.5314 - val_acc: 0.9463 - val_mDice: 0.6268

Epoch 00030: val_mDice did not improve from 0.63767
Epoch 31/300
 - 9s - loss: 0.3871 - acc: 0.9364 - mDice: 0.6658 - val_loss: 0.6353 - val_acc: 0.9442 - val_mDice: 0.6252

Epoch 00031: val_mDice did not improve from 0.63767
Epoch 32/300
 - 10s - loss: 0.3844 - acc: 0.9368 - mDice: 0.6674 - val_loss: 0.6554 - val_acc: 0.9510 - val_mDice: 0.6299

Epoch 00032: val_mDice did not improve from 0.63767
Epoch 33/300
 - 9s - loss: 0.3840 - acc: 0.9368 - mDice: 0.6677 - val_loss: 0.5843 - val_acc: 0.9503 - val_mDice: 0.6349

Epoch 00033: val_mDice did not improve from 0.63767
Epoch 34/300
 - 10s - loss: 0.4135 - acc: 0.9346 - mDice: 0.6533 - val_loss: 2.0775 - val_acc: 0.8731 - val_mDice: 0.3804

Epoch 00034: val_mDice did not improve from 0.63767
Epoch 35/300
 - 9s - loss: 0.4046 - acc: 0.9351 - mDice: 0.6540 - val_loss: 0.8373 - val_acc: 0.9491 - val_mDice: 0.6197

Epoch 00035: val_mDice did not improve from 0.63767
Epoch 36/300
 - 9s - loss: 0.3874 - acc: 0.9366 - mDice: 0.6654 - val_loss: 0.7790 - val_acc: 0.9511 - val_mDice: 0.6342

Epoch 00036: val_mDice did not improve from 0.63767
Epoch 37/300
 - 9s - loss: 0.3797 - acc: 0.9372 - mDice: 0.6704 - val_loss: 0.6189 - val_acc: 0.9503 - val_mDice: 0.6340

Epoch 00037: val_mDice did not improve from 0.63767
Epoch 38/300
 - 11s - loss: 0.3779 - acc: 0.9374 - mDice: 0.6719 - val_loss: 0.6364 - val_acc: 0.9511 - val_mDice: 0.6384

Epoch 00038: val_mDice improved from 0.63767 to 0.63842, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 39/300
 - 12s - loss: 0.3780 - acc: 0.9374 - mDice: 0.6720 - val_loss: 0.4704 - val_acc: 0.9470 - val_mDice: 0.6286

Epoch 00039: val_mDice did not improve from 0.63842
Epoch 40/300
 - 11s - loss: 0.3756 - acc: 0.9374 - mDice: 0.6735 - val_loss: 0.4985 - val_acc: 0.9463 - val_mDice: 0.6283

Epoch 00040: val_mDice did not improve from 0.63842
Epoch 41/300
 - 11s - loss: 0.3726 - acc: 0.9378 - mDice: 0.6755 - val_loss: 0.6210 - val_acc: 0.9505 - val_mDice: 0.6354

Epoch 00041: val_mDice did not improve from 0.63842
Epoch 42/300
 - 11s - loss: 0.3733 - acc: 0.9376 - mDice: 0.6750 - val_loss: 0.5724 - val_acc: 0.9391 - val_mDice: 0.6095

Epoch 00042: val_mDice did not improve from 0.63842
Epoch 43/300
 - 12s - loss: 0.4362 - acc: 0.9325 - mDice: 0.6391 - val_loss: 0.4901 - val_acc: 0.9492 - val_mDice: 0.6300

Epoch 00043: val_mDice did not improve from 0.63842
Epoch 44/300
 - 11s - loss: 0.3895 - acc: 0.9361 - mDice: 0.6636 - val_loss: 0.6191 - val_acc: 0.9504 - val_mDice: 0.6356

Epoch 00044: val_mDice did not improve from 0.63842
Epoch 45/300
 - 12s - loss: 0.3787 - acc: 0.9373 - mDice: 0.6711 - val_loss: 0.6214 - val_acc: 0.9510 - val_mDice: 0.6373

Epoch 00045: val_mDice did not improve from 0.63842
Epoch 46/300
 - 12s - loss: 0.3731 - acc: 0.9377 - mDice: 0.6751 - val_loss: 0.6896 - val_acc: 0.9511 - val_mDice: 0.6358

Epoch 00046: val_mDice did not improve from 0.63842
Epoch 47/300
 - 12s - loss: 0.3720 - acc: 0.9378 - mDice: 0.6758 - val_loss: 0.7250 - val_acc: 0.9508 - val_mDice: 0.6330

Epoch 00047: val_mDice did not improve from 0.63842
Epoch 48/300
 - 11s - loss: 0.3695 - acc: 0.9380 - mDice: 0.6774 - val_loss: 0.4905 - val_acc: 0.9511 - val_mDice: 0.6338

Epoch 00048: val_mDice did not improve from 0.63842
Epoch 49/300
 - 12s - loss: 0.3708 - acc: 0.9380 - mDice: 0.6768 - val_loss: 0.4812 - val_acc: 0.9509 - val_mDice: 0.6323

Epoch 00049: val_mDice did not improve from 0.63842
Epoch 50/300
 - 11s - loss: 0.3674 - acc: 0.9383 - mDice: 0.6789 - val_loss: 0.6635 - val_acc: 0.9493 - val_mDice: 0.6288

Epoch 00050: val_mDice did not improve from 0.63842
Epoch 51/300
 - 11s - loss: 0.3667 - acc: 0.9385 - mDice: 0.6796 - val_loss: 0.5818 - val_acc: 0.9474 - val_mDice: 0.5991

Epoch 00051: val_mDice did not improve from 0.63842
Epoch 52/300
 - 11s - loss: 0.3677 - acc: 0.9382 - mDice: 0.6788 - val_loss: 1.2870 - val_acc: 0.9413 - val_mDice: 0.5521

Epoch 00052: val_mDice did not improve from 0.63842
Epoch 53/300
 - 12s - loss: 0.3642 - acc: 0.9385 - mDice: 0.6812 - val_loss: 0.5212 - val_acc: 0.9523 - val_mDice: 0.6339

Epoch 00053: val_mDice did not improve from 0.63842
Epoch 54/300
 - 13s - loss: 0.3656 - acc: 0.9383 - mDice: 0.6803 - val_loss: 0.8323 - val_acc: 0.9493 - val_mDice: 0.6176

Epoch 00054: val_mDice did not improve from 0.63842
Epoch 55/300
 - 12s - loss: 0.3654 - acc: 0.9384 - mDice: 0.6805 - val_loss: 0.6114 - val_acc: 0.9507 - val_mDice: 0.6308

Epoch 00055: val_mDice did not improve from 0.63842
Epoch 56/300
 - 13s - loss: 0.3636 - acc: 0.9387 - mDice: 0.6818 - val_loss: 0.7599 - val_acc: 0.9510 - val_mDice: 0.6309

Epoch 00056: val_mDice did not improve from 0.63842
Epoch 57/300
 - 12s - loss: 0.3636 - acc: 0.9385 - mDice: 0.6816 - val_loss: 0.5238 - val_acc: 0.9513 - val_mDice: 0.6351

Epoch 00057: val_mDice did not improve from 0.63842
Epoch 58/300
 - 12s - loss: 0.3628 - acc: 0.9386 - mDice: 0.6822 - val_loss: 0.8313 - val_acc: 0.9481 - val_mDice: 0.6163

Epoch 00058: val_mDice did not improve from 0.63842
Epoch 59/300
 - 12s - loss: 0.3640 - acc: 0.9386 - mDice: 0.6814 - val_loss: 0.6093 - val_acc: 0.9515 - val_mDice: 0.6400

Epoch 00059: val_mDice improved from 0.63842 to 0.64001, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 60/300
 - 13s - loss: 0.3638 - acc: 0.9386 - mDice: 0.6817 - val_loss: 0.8897 - val_acc: 0.9463 - val_mDice: 0.6017

Epoch 00060: val_mDice did not improve from 0.64001
Epoch 61/300
 - 13s - loss: 0.3612 - acc: 0.9390 - mDice: 0.6835 - val_loss: 0.4741 - val_acc: 0.9500 - val_mDice: 0.6355

Epoch 00061: val_mDice did not improve from 0.64001
Epoch 62/300
 - 13s - loss: 0.3637 - acc: 0.9386 - mDice: 0.6819 - val_loss: 0.6557 - val_acc: 0.9509 - val_mDice: 0.6294

Epoch 00062: val_mDice did not improve from 0.64001
Epoch 63/300
 - 13s - loss: 0.3579 - acc: 0.9390 - mDice: 0.6856 - val_loss: 0.5494 - val_acc: 0.9494 - val_mDice: 0.6318

Epoch 00063: val_mDice did not improve from 0.64001
Epoch 64/300
 - 12s - loss: 0.3617 - acc: 0.9388 - mDice: 0.6831 - val_loss: 0.6264 - val_acc: 0.9504 - val_mDice: 0.6291

Epoch 00064: val_mDice did not improve from 0.64001
Epoch 65/300
 - 13s - loss: 0.3600 - acc: 0.9390 - mDice: 0.6843 - val_loss: 0.6148 - val_acc: 0.9469 - val_mDice: 0.6243

Epoch 00065: val_mDice did not improve from 0.64001
Epoch 66/300
 - 12s - loss: 0.3562 - acc: 0.9391 - mDice: 0.6868 - val_loss: 0.8503 - val_acc: 0.9498 - val_mDice: 0.6178

Epoch 00066: val_mDice did not improve from 0.64001
Epoch 67/300
 - 13s - loss: 0.3564 - acc: 0.9392 - mDice: 0.6868 - val_loss: 0.6908 - val_acc: 0.9476 - val_mDice: 0.6259

Epoch 00067: val_mDice did not improve from 0.64001
Epoch 68/300
 - 12s - loss: 0.3545 - acc: 0.9392 - mDice: 0.6879 - val_loss: 0.5503 - val_acc: 0.9508 - val_mDice: 0.6312

Epoch 00068: val_mDice did not improve from 0.64001
Epoch 69/300
 - 14s - loss: 0.3548 - acc: 0.9393 - mDice: 0.6878 - val_loss: 0.5050 - val_acc: 0.9466 - val_mDice: 0.6192

Epoch 00069: val_mDice did not improve from 0.64001
Epoch 70/300
 - 11s - loss: 0.3567 - acc: 0.9391 - mDice: 0.6863 - val_loss: 0.4519 - val_acc: 0.9493 - val_mDice: 0.6372

Epoch 00070: val_mDice did not improve from 0.64001
Epoch 71/300
 - 13s - loss: 0.3546 - acc: 0.9393 - mDice: 0.6880 - val_loss: 0.4234 - val_acc: 0.9510 - val_mDice: 0.6306

Epoch 00071: val_mDice did not improve from 0.64001
Epoch 72/300
 - 11s - loss: 0.3560 - acc: 0.9392 - mDice: 0.6870 - val_loss: 0.7097 - val_acc: 0.9481 - val_mDice: 0.6131

Epoch 00072: val_mDice did not improve from 0.64001
Epoch 73/300
 - 13s - loss: 0.3542 - acc: 0.9395 - mDice: 0.6882 - val_loss: 0.6400 - val_acc: 0.9477 - val_mDice: 0.5995

Epoch 00073: val_mDice did not improve from 0.64001
Epoch 74/300
 - 11s - loss: 0.3522 - acc: 0.9394 - mDice: 0.6895 - val_loss: 0.6994 - val_acc: 0.9498 - val_mDice: 0.6174

Epoch 00074: val_mDice did not improve from 0.64001
Epoch 75/300
 - 13s - loss: 0.3537 - acc: 0.9394 - mDice: 0.6885 - val_loss: 0.5865 - val_acc: 0.9478 - val_mDice: 0.6290

Epoch 00075: val_mDice did not improve from 0.64001
Epoch 76/300
 - 11s - loss: 0.3544 - acc: 0.9394 - mDice: 0.6884 - val_loss: 0.4744 - val_acc: 0.9453 - val_mDice: 0.6198

Epoch 00076: val_mDice did not improve from 0.64001
Epoch 77/300
 - 13s - loss: 0.3535 - acc: 0.9395 - mDice: 0.6886 - val_loss: 0.8286 - val_acc: 0.9493 - val_mDice: 0.6225

Epoch 00077: val_mDice did not improve from 0.64001
Epoch 78/300
 - 11s - loss: 0.3518 - acc: 0.9396 - mDice: 0.6899 - val_loss: 0.5969 - val_acc: 0.9478 - val_mDice: 0.6260

Epoch 00078: val_mDice did not improve from 0.64001
Epoch 79/300
 - 12s - loss: 0.3511 - acc: 0.9397 - mDice: 0.6904 - val_loss: 0.5891 - val_acc: 0.9444 - val_mDice: 0.5732

Epoch 00079: val_mDice did not improve from 0.64001
Epoch 80/300
 - 12s - loss: 0.3518 - acc: 0.9397 - mDice: 0.6900 - val_loss: 0.5663 - val_acc: 0.9505 - val_mDice: 0.6341

Epoch 00080: val_mDice did not improve from 0.64001
Epoch 81/300
 - 13s - loss: 0.3513 - acc: 0.9397 - mDice: 0.6902 - val_loss: 0.4401 - val_acc: 0.9505 - val_mDice: 0.6356

Epoch 00081: val_mDice did not improve from 0.64001
Epoch 82/300
 - 12s - loss: 0.3486 - acc: 0.9400 - mDice: 0.6922 - val_loss: 0.8032 - val_acc: 0.9492 - val_mDice: 0.6227

Epoch 00082: val_mDice did not improve from 0.64001
Epoch 83/300
 - 13s - loss: 0.3475 - acc: 0.9399 - mDice: 0.6929 - val_loss: 0.6479 - val_acc: 0.9472 - val_mDice: 0.6131

Epoch 00083: val_mDice did not improve from 0.64001
Epoch 84/300
 - 11s - loss: 0.3495 - acc: 0.9398 - mDice: 0.6914 - val_loss: 0.6360 - val_acc: 0.9491 - val_mDice: 0.6193

Epoch 00084: val_mDice did not improve from 0.64001
Epoch 85/300
 - 12s - loss: 0.3478 - acc: 0.9399 - mDice: 0.6928 - val_loss: 0.6304 - val_acc: 0.9469 - val_mDice: 0.6247

Epoch 00085: val_mDice did not improve from 0.64001
Epoch 86/300
 - 12s - loss: 0.3481 - acc: 0.9399 - mDice: 0.6926 - val_loss: 0.7084 - val_acc: 0.9464 - val_mDice: 0.5839

Epoch 00086: val_mDice did not improve from 0.64001
Epoch 87/300
 - 12s - loss: 0.3470 - acc: 0.9399 - mDice: 0.6934 - val_loss: 0.8468 - val_acc: 0.9472 - val_mDice: 0.6006

Epoch 00087: val_mDice did not improve from 0.64001
Epoch 88/300
 - 12s - loss: 0.3487 - acc: 0.9399 - mDice: 0.6922 - val_loss: 0.4905 - val_acc: 0.9417 - val_mDice: 0.6142

Epoch 00088: val_mDice did not improve from 0.64001
Epoch 89/300
 - 12s - loss: 0.3476 - acc: 0.9400 - mDice: 0.6930 - val_loss: 0.8226 - val_acc: 0.9485 - val_mDice: 0.6261

Epoch 00089: val_mDice did not improve from 0.64001
Epoch 90/300
 - 12s - loss: 0.3461 - acc: 0.9400 - mDice: 0.6938 - val_loss: 0.6185 - val_acc: 0.9517 - val_mDice: 0.6323

Epoch 00090: val_mDice did not improve from 0.64001
Epoch 91/300
 - 13s - loss: 0.3462 - acc: 0.9401 - mDice: 0.6940 - val_loss: 0.4803 - val_acc: 0.9462 - val_mDice: 0.6215

Epoch 00091: val_mDice did not improve from 0.64001
Epoch 92/300
 - 12s - loss: 0.3455 - acc: 0.9401 - mDice: 0.6944 - val_loss: 0.5269 - val_acc: 0.9517 - val_mDice: 0.6388

Epoch 00092: val_mDice did not improve from 0.64001
Epoch 93/300
 - 12s - loss: 0.3462 - acc: 0.9401 - mDice: 0.6942 - val_loss: 0.4333 - val_acc: 0.9522 - val_mDice: 0.6400

Epoch 00093: val_mDice improved from 0.64001 to 0.64005, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 94/300
 - 12s - loss: 0.3454 - acc: 0.9401 - mDice: 0.6944 - val_loss: 0.6395 - val_acc: 0.9492 - val_mDice: 0.6276

Epoch 00094: val_mDice did not improve from 0.64005
Epoch 95/300
 - 12s - loss: 0.3459 - acc: 0.9401 - mDice: 0.6942 - val_loss: 0.6549 - val_acc: 0.9491 - val_mDice: 0.6310

Epoch 00095: val_mDice did not improve from 0.64005
Epoch 96/300
 - 11s - loss: 0.3442 - acc: 0.9403 - mDice: 0.6952 - val_loss: 0.5963 - val_acc: 0.9441 - val_mDice: 0.6268

Epoch 00096: val_mDice did not improve from 0.64005
Epoch 97/300
 - 9s - loss: 0.3447 - acc: 0.9405 - mDice: 0.6953 - val_loss: 0.4794 - val_acc: 0.9488 - val_mDice: 0.6328

Epoch 00097: val_mDice did not improve from 0.64005
Epoch 98/300
 - 9s - loss: 0.3437 - acc: 0.9402 - mDice: 0.6955 - val_loss: 0.6114 - val_acc: 0.9497 - val_mDice: 0.6336

Epoch 00098: val_mDice did not improve from 0.64005
Epoch 99/300
 - 9s - loss: 0.3457 - acc: 0.9401 - mDice: 0.6943 - val_loss: 0.4351 - val_acc: 0.9520 - val_mDice: 0.6370

Epoch 00099: val_mDice did not improve from 0.64005
Epoch 100/300
 - 9s - loss: 0.3419 - acc: 0.9404 - mDice: 0.6969 - val_loss: 0.4484 - val_acc: 0.9494 - val_mDice: 0.6371

Epoch 00100: val_mDice did not improve from 0.64005
Epoch 101/300
 - 9s - loss: 0.3418 - acc: 0.9404 - mDice: 0.6970 - val_loss: 0.6163 - val_acc: 0.9473 - val_mDice: 0.6236

Epoch 00101: val_mDice did not improve from 0.64005
Epoch 102/300
 - 9s - loss: 0.3448 - acc: 0.9401 - mDice: 0.6949 - val_loss: 0.8272 - val_acc: 0.9494 - val_mDice: 0.6223

Epoch 00102: val_mDice did not improve from 0.64005
Epoch 103/300
 - 9s - loss: 0.3435 - acc: 0.9404 - mDice: 0.6959 - val_loss: 0.6389 - val_acc: 0.9450 - val_mDice: 0.6192

Epoch 00103: val_mDice did not improve from 0.64005
Epoch 104/300
 - 9s - loss: 0.3425 - acc: 0.9402 - mDice: 0.6966 - val_loss: 0.5509 - val_acc: 0.9510 - val_mDice: 0.6249

Epoch 00104: val_mDice did not improve from 0.64005
Epoch 105/300
 - 9s - loss: 0.3447 - acc: 0.9402 - mDice: 0.6951 - val_loss: 0.8502 - val_acc: 0.9491 - val_mDice: 0.6167

Epoch 00105: val_mDice did not improve from 0.64005
Epoch 106/300
 - 9s - loss: 0.3408 - acc: 0.9404 - mDice: 0.6977 - val_loss: 0.5999 - val_acc: 0.9490 - val_mDice: 0.6270

Epoch 00106: val_mDice did not improve from 0.64005
Epoch 107/300
 - 9s - loss: 0.3412 - acc: 0.9403 - mDice: 0.6974 - val_loss: 0.8149 - val_acc: 0.9494 - val_mDice: 0.6202

Epoch 00107: val_mDice did not improve from 0.64005
Epoch 108/300
 - 9s - loss: 0.3393 - acc: 0.9405 - mDice: 0.6987 - val_loss: 0.6602 - val_acc: 0.9519 - val_mDice: 0.6375

Epoch 00108: val_mDice did not improve from 0.64005
Epoch 109/300
 - 9s - loss: 0.3403 - acc: 0.9404 - mDice: 0.6980 - val_loss: 0.7583 - val_acc: 0.9502 - val_mDice: 0.6321

Epoch 00109: val_mDice did not improve from 0.64005
Epoch 110/300
 - 9s - loss: 0.3395 - acc: 0.9406 - mDice: 0.6986 - val_loss: 0.5899 - val_acc: 0.9495 - val_mDice: 0.6280

Epoch 00110: val_mDice did not improve from 0.64005
Epoch 111/300
 - 9s - loss: 0.3389 - acc: 0.9407 - mDice: 0.6991 - val_loss: 0.4922 - val_acc: 0.9471 - val_mDice: 0.6252

Epoch 00111: val_mDice did not improve from 0.64005
Epoch 112/300
 - 9s - loss: 0.3395 - acc: 0.9406 - mDice: 0.6987 - val_loss: 0.6157 - val_acc: 0.9518 - val_mDice: 0.6372

Epoch 00112: val_mDice did not improve from 0.64005
Epoch 113/300
 - 9s - loss: 0.3376 - acc: 0.9407 - mDice: 0.6999 - val_loss: 0.4607 - val_acc: 0.9487 - val_mDice: 0.6378

Epoch 00113: val_mDice did not improve from 0.64005
Epoch 114/300
 - 9s - loss: 0.3383 - acc: 0.9407 - mDice: 0.6994 - val_loss: 0.6027 - val_acc: 0.9472 - val_mDice: 0.6269

Epoch 00114: val_mDice did not improve from 0.64005
Epoch 115/300
 - 9s - loss: 0.3381 - acc: 0.9405 - mDice: 0.6994 - val_loss: 0.8914 - val_acc: 0.9456 - val_mDice: 0.5951

Epoch 00115: val_mDice did not improve from 0.64005
Epoch 116/300
 - 9s - loss: 0.3415 - acc: 0.9404 - mDice: 0.6974 - val_loss: 0.4308 - val_acc: 0.9466 - val_mDice: 0.6375

Epoch 00116: val_mDice did not improve from 0.64005
Epoch 117/300
 - 8s - loss: 0.3737 - acc: 0.9374 - mDice: 0.6775 - val_loss: 1.0191 - val_acc: 0.9402 - val_mDice: 0.5429

Epoch 00117: val_mDice did not improve from 0.64005
Epoch 118/300
 - 9s - loss: 0.3759 - acc: 0.9373 - mDice: 0.6730 - val_loss: 0.4103 - val_acc: 0.9460 - val_mDice: 0.6289

Epoch 00118: val_mDice did not improve from 0.64005
Epoch 119/300
 - 9s - loss: 0.3508 - acc: 0.9396 - mDice: 0.6906 - val_loss: 0.4424 - val_acc: 0.9511 - val_mDice: 0.6369

Epoch 00119: val_mDice did not improve from 0.64005
Epoch 120/300
 - 8s - loss: 0.3432 - acc: 0.9401 - mDice: 0.6958 - val_loss: 0.4324 - val_acc: 0.9499 - val_mDice: 0.6343

Epoch 00120: val_mDice did not improve from 0.64005
Epoch 121/300
 - 8s - loss: 0.3387 - acc: 0.9407 - mDice: 0.6992 - val_loss: 0.5335 - val_acc: 0.9401 - val_mDice: 0.6179

Epoch 00121: val_mDice did not improve from 0.64005
Epoch 122/300
 - 9s - loss: 0.3374 - acc: 0.9408 - mDice: 0.7002 - val_loss: 0.6208 - val_acc: 0.9476 - val_mDice: 0.6290

Epoch 00122: val_mDice did not improve from 0.64005
Epoch 123/300
 - 9s - loss: 0.3407 - acc: 0.9406 - mDice: 0.6983 - val_loss: 0.7989 - val_acc: 0.9505 - val_mDice: 0.6287

Epoch 00123: val_mDice did not improve from 0.64005
Epoch 124/300
 - 8s - loss: 0.3365 - acc: 0.9409 - mDice: 0.7008 - val_loss: 0.6122 - val_acc: 0.9476 - val_mDice: 0.6309

Epoch 00124: val_mDice did not improve from 0.64005
Epoch 125/300
 - 9s - loss: 0.3356 - acc: 0.9409 - mDice: 0.7014 - val_loss: 0.5579 - val_acc: 0.9495 - val_mDice: 0.6347

Epoch 00125: val_mDice did not improve from 0.64005
Epoch 126/300
 - 8s - loss: 0.3365 - acc: 0.9407 - mDice: 0.7007 - val_loss: 0.4808 - val_acc: 0.9502 - val_mDice: 0.6277

Epoch 00126: val_mDice did not improve from 0.64005
Epoch 127/300
 - 8s - loss: 0.3345 - acc: 0.9410 - mDice: 0.7022 - val_loss: 0.5494 - val_acc: 0.9500 - val_mDice: 0.6349

Epoch 00127: val_mDice did not improve from 0.64005
Epoch 128/300
 - 8s - loss: 0.3352 - acc: 0.9410 - mDice: 0.7018 - val_loss: 0.4950 - val_acc: 0.9495 - val_mDice: 0.6164

Epoch 00128: val_mDice did not improve from 0.64005
Epoch 129/300
 - 9s - loss: 0.3372 - acc: 0.9407 - mDice: 0.7003 - val_loss: 0.5752 - val_acc: 0.9498 - val_mDice: 0.6321

Epoch 00129: val_mDice did not improve from 0.64005
Epoch 130/300
 - 9s - loss: 0.3349 - acc: 0.9408 - mDice: 0.7020 - val_loss: 0.8527 - val_acc: 0.9482 - val_mDice: 0.6140

Epoch 00130: val_mDice did not improve from 0.64005
Epoch 131/300
 - 8s - loss: 0.3354 - acc: 0.9409 - mDice: 0.7017 - val_loss: 0.6885 - val_acc: 0.9504 - val_mDice: 0.6330

Epoch 00131: val_mDice did not improve from 0.64005
Epoch 132/300
 - 8s - loss: 0.3331 - acc: 0.9408 - mDice: 0.7032 - val_loss: 0.7732 - val_acc: 0.9511 - val_mDice: 0.6301

Epoch 00132: val_mDice did not improve from 0.64005
Epoch 133/300
 - 8s - loss: 0.3330 - acc: 0.9411 - mDice: 0.7033 - val_loss: 0.4736 - val_acc: 0.9510 - val_mDice: 0.6335

Epoch 00133: val_mDice did not improve from 0.64005
Restoring model weights from the end of the best epoch
Epoch 00133: early stopping
{'val_loss': [2.02508773122515, 1.554266027041844, 1.3885118961334229, 1.2806394611086165, 0.9605796422277179, 0.9610418081283569, 0.8839671526636396, 0.8657411677496774, 0.8091953567096165, 0.6842762146677289, 0.8193933367729187, 0.6982448526791164, 0.9005154200962612, 0.8079081773757935, 0.8239874073437282, 0.5848900931222099, 0.7084538510867527, 0.6034432394163949, 0.6443042414528983, 0.570578260081155, 0.6847032138279506, 0.7512011187417167, 0.6713956253869193, 0.5661452753203255, 0.5335636905261448, 0.8726515769958496, 2.373408700738634, 0.5472236701420375, 0.5213213818413871, 0.5314116137368339, 0.6353164911270142, 0.6554378611700875, 0.5843080878257751, 2.0774577174867903, 0.8372639417648315, 0.7790354234831673, 0.6188721401350838, 0.6364003590175084, 0.47044999258858816, 0.49845958607537405, 0.6210457001413617, 0.5723625762122018, 0.49007563080106464, 0.6190717901502337, 0.6214070320129395, 0.689632739339556, 0.7250076617513385, 0.490537907396044, 0.48120828185762676, 0.6634621790477208, 0.5818023341042655, 1.2870302370616369, 0.5212038840566363, 0.8323019998414176, 0.6113589491162982, 0.7599443793296814, 0.5238088965415955, 0.8312960011618478, 0.6093260220118931, 0.8897094811711993, 0.47406730481556486, 0.655721264226096, 0.5494189858436584, 0.626447183745248, 0.6148340361458915, 0.8502669504710606, 0.6907821553094047, 0.5502692971910749, 0.505041914326804, 0.4519010101045881, 0.4234467106206076, 0.70966146673475, 0.6400383455412728, 0.699403200830732, 0.5865202120372227, 0.47437301703861784, 0.8285607780729022, 0.5968703542436872, 0.589141207081931, 0.5662718159811837, 0.44008350372314453, 0.8031923004559108, 0.6478627238954816, 0.6360352890832084, 0.6303547620773315, 0.7084421174866813, 0.8467665144375393, 0.49048149585723877, 0.8225860255105155, 0.6184775659016201, 0.48027299983160837, 0.5269348536218915, 0.43329189504895893, 0.6395040239606585, 0.6549185344151088, 0.596348796572004, 0.47936329671314787, 0.6114074076925006, 0.4351027352469308, 0.4483551723616464, 0.6163178256579808, 0.8272094641413007, 0.6388581820896694, 0.5509419441223145, 0.8502430319786072, 0.5998902406011309, 0.8148881367274693, 0.6601714066096714, 0.7583030036517552, 0.5898657866886684, 0.49222898483276367, 0.6157259770802089, 0.46073557649339947, 0.6027355108942304, 0.8914312549999782, 0.430787878377097, 1.0191263045583452, 0.41025796106883455, 0.4423807518822806, 0.4323958286217281, 0.5334957667759487, 0.6208418948309762, 0.7989028862544468, 0.612213134765625, 0.55794415303639, 0.4808300222669329, 0.549439719745091, 0.49497287614004953, 0.5751900672912598, 0.8526982920510429, 0.6885257193020412, 0.7731887442725045, 0.47361384119306293], 'val_acc': [0.9123508674757821, 0.9177106278283256, 0.9258477176938739, 0.9320735250200544, 0.9399921468326023, 0.938834377697536, 0.9449411375182015, 0.9469322221619743, 0.9477184755461556, 0.9415619969367981, 0.9443616015570504, 0.945276038987296, 0.9442229100636074, 0.9483307259423392, 0.949461008821215, 0.9476766075406756, 0.9447318230356488, 0.9439730473927089, 0.9395656755992344, 0.9507705313818795, 0.9397030387605939, 0.9423521757125854, 0.9488657798085894, 0.94894426209586, 0.9445852892739433, 0.9466470394815717, 0.9351909926959446, 0.9515907934733799, 0.9495329771723066, 0.946253274168287, 0.9441614406449454, 0.9510020869118827, 0.9502773370061602, 0.8730572972978864, 0.9491392033440726, 0.9510596394538879, 0.9502982582364764, 0.9511146119662693, 0.9469858663422721, 0.946287282875606, 0.9504644104412624, 0.9390960250582013, 0.9491653527532306, 0.950370226587568, 0.9509942531585693, 0.9511198231152126, 0.9508058513913836, 0.9511342218944004, 0.9508948240961347, 0.9492621677262443, 0.9473600387573242, 0.9412964582443237, 0.9522605793816703, 0.9492503915514264, 0.9507496016366142, 0.9509720121111188, 0.9512676426342556, 0.9481488721711295, 0.9514979209218707, 0.9462951251438686, 0.9499960797173637, 0.9509157623563494, 0.9494060703686306, 0.9503532137189593, 0.9469426955495562, 0.9498103090694973, 0.9475863405636379, 0.9508437940052578, 0.946555461202349, 0.9492713298116412, 0.9509641698428563, 0.948130556515285, 0.9476517694337028, 0.9497998441968646, 0.947817896093641, 0.9453048195157733, 0.9493288908685956, 0.9478375315666199, 0.9444374697549003, 0.9505180631365094, 0.9504840459142413, 0.9492098603929792, 0.9472213642937797, 0.9490777083805629, 0.9469139065061297, 0.9463696905544826, 0.9471886583736965, 0.941662745816367, 0.9485439658164978, 0.9517203058515277, 0.9461917792047773, 0.9517045872552055, 0.95224358354296, 0.9491509880338397, 0.9490606955119542, 0.9441143274307251, 0.9488317711012704, 0.9497043490409851, 0.9519885012081691, 0.9493733644485474, 0.9473430258887154, 0.9494008421897888, 0.9450222424098423, 0.9510243364742824, 0.9491313440459115, 0.9489612664495196, 0.949409978730338, 0.9518772874559674, 0.9501936265400478, 0.949467556817191, 0.9470839841025216, 0.9518027305603027, 0.9487153376851764, 0.9472278867449079, 0.9455873966217041, 0.9465986234801156, 0.9402237108775547, 0.9460400257791791, 0.9510871171951294, 0.9498665503093174, 0.9401190451213292, 0.9476111871855599, 0.9505128264427185, 0.9476491383143834, 0.9495094077927726, 0.9502250126429966, 0.9499960626874652, 0.9495355827467782, 0.9498286247253418, 0.9481855034828186, 0.9503715293748038, 0.9510583451816014, 0.9509654556001935], 'val_mDice': [0.24759665983063833, 0.3669428825378418, 0.4021501200539725, 0.46001432623182026, 0.5371980667114258, 0.5232629946299961, 0.5946929284504482, 0.6141314847128732, 0.6132537978036063, 0.6089740991592407, 0.613314322062901, 0.6188138042177472, 0.5820843236786979, 0.6158130764961243, 0.6200345584324428, 0.6314145496913365, 0.5610538039888654, 0.6185231719698224, 0.5920623711177281, 0.6333480647632054, 0.613089919090271, 0.6044208492551532, 0.6254167216164725, 0.6176898564611163, 0.6256223065512521, 0.6053858995437622, 0.4796815173966544, 0.63766838823046, 0.6245240228516715, 0.6268422092710223, 0.6252039500645229, 0.6298787764140538, 0.6349191835948399, 0.380353753055845, 0.6197119440351214, 0.6342452849660601, 0.6340491090502057, 0.6384161455290658, 0.6285669463021415, 0.6283062696456909, 0.6354401537350246, 0.6095349192619324, 0.6300493819372994, 0.6356201001576015, 0.6373101472854614, 0.635789726461683, 0.6329953500202724, 0.6338283589908055, 0.6323065076555524, 0.6288433756147113, 0.5990962130682809, 0.5521465284483773, 0.6338739395141602, 0.6176301666668483, 0.6307867765426636, 0.6309462359973362, 0.6351059760366168, 0.6162834337779454, 0.6400104505675179, 0.6017038481576102, 0.6355453048433576, 0.6293978009905133, 0.6317707811083112, 0.6290649856839862, 0.6243071811539787, 0.6177521177700588, 0.6258691719600132, 0.6311609319278172, 0.6192066499165126, 0.6372263942446027, 0.6305679593767438, 0.6131418262209211, 0.599510133266449, 0.6173857791083199, 0.6289993013654437, 0.6197762063571385, 0.622450019632067, 0.6259554880005973, 0.5732183456420898, 0.6341163686343602, 0.6355559996196202, 0.6226927808352879, 0.6130527087620327, 0.6193442004067558, 0.6246867435319083, 0.5838729228292193, 0.6005623936653137, 0.614206041608538, 0.6261097873960223, 0.632330025945391, 0.6214686461857387, 0.6388045038495745, 0.6400464773178101, 0.6276122161320278, 0.6309843063354492, 0.6267968671662467, 0.6328151226043701, 0.6336462242262704, 0.6369966353688922, 0.6371220520564488, 0.6235813753945487, 0.622344970703125, 0.6191843662943158, 0.6249035767146519, 0.6167082445962089, 0.6269963383674622, 0.6202475002833775, 0.637498778956277, 0.6320795161383492, 0.6280312708445958, 0.6251614689826965, 0.6372224518230983, 0.6378197244235447, 0.626852137701852, 0.5950541240828378, 0.6374686104910714, 0.5428913320813861, 0.6289276395525251, 0.6368627207619804, 0.6342967663492475, 0.617857677595956, 0.6289610181535993, 0.6287486978939602, 0.6308753660746983, 0.6347281336784363, 0.6276576178414481, 0.6348756466593061, 0.6164411646979195, 0.6321084158761161, 0.6140233789171491, 0.6329927870205471, 0.6301433529172625, 0.6334638595581055], 'loss': [2.629393182030159, 1.1429801089832536, 0.8388345827661067, 0.6890625984979013, 0.5959986123486024, 0.5387319421823507, 0.5120306547823095, 0.49262756202900315, 0.47255096669263463, 0.4640046029283487, 0.4571084259142732, 0.44880639123805993, 0.4402667586561045, 0.43323322502627853, 0.42847163483352757, 0.4246630893493347, 0.41643021544734277, 0.41461107206480385, 0.4132813509130146, 0.4061144787383668, 0.40523626399653745, 0.40205648013419476, 0.4000674112515469, 0.39819787395224243, 0.3930481123071862, 0.395499923433641, 0.3913008522016794, 0.4137665264919774, 0.39068043956749554, 0.38562585344623346, 0.3870573174825225, 0.38439263365384874, 0.3840198689587281, 0.4135309779814994, 0.40455958109519524, 0.3874408417715098, 0.3797247992666229, 0.3779217083100603, 0.3780123591297313, 0.37555017123190165, 0.3726311519198266, 0.37325049856623826, 0.4361904147581017, 0.3894636237251686, 0.3787307325004903, 0.37306442385960975, 0.3719628459163618, 0.3695216248418128, 0.370782188400139, 0.3674489656120281, 0.3667100910847762, 0.3677306517257743, 0.36424717449156246, 0.36557077226244533, 0.3654469124402358, 0.36355329940928055, 0.36362418138234076, 0.36282526427144063, 0.3640433636440353, 0.36377372955551784, 0.36122367015445167, 0.3636509196475648, 0.35785857185586245, 0.36169815012559287, 0.3599777393729796, 0.3561995399448344, 0.35635418608781533, 0.35447628525484715, 0.3547787242513044, 0.35673086401456217, 0.35463711243469337, 0.3559527058335855, 0.3542253916913813, 0.35220771389931876, 0.3537218015585185, 0.3543615834518365, 0.35352670998669855, 0.351763223745581, 0.3510644921922553, 0.35175556118567264, 0.35125800945843805, 0.3485626960839181, 0.3475463802088818, 0.34954259431932927, 0.3477954703892517, 0.3481012405448512, 0.34696586203459473, 0.3486992328937887, 0.3475528341183505, 0.3461468737541787, 0.34622306685185184, 0.34553455885918527, 0.34618463162454566, 0.3454044854696278, 0.34589486151298776, 0.34415355000383263, 0.3446514389040198, 0.34372992055171203, 0.3457356336888219, 0.3419190139691052, 0.3418027074735292, 0.3448395763638401, 0.34348708907905645, 0.3424678583596231, 0.344720480651248, 0.34078844876335634, 0.34115714505487693, 0.33926873235002497, 0.3403401297435205, 0.33947447325151897, 0.33886362063786674, 0.3394597349061767, 0.3376058634952814, 0.3382655063074768, 0.3381242011197381, 0.3414815939056096, 0.3737319112452644, 0.3758948390945506, 0.3507953991783844, 0.3431957742693152, 0.33865933411610677, 0.3374001794451275, 0.3407054885458127, 0.33647380024037565, 0.33559674036525466, 0.33651356049238745, 0.33445775217206336, 0.3352146907034767, 0.3372119165716531, 0.3349347321689443, 0.3353586978133885, 0.33307530461446916, 0.3330338398531705], 'acc': [0.744733344000544, 0.8840251732943707, 0.8960141247773669, 0.9073063661418015, 0.9166754539745615, 0.9225576976084352, 0.9250989729431304, 0.92721397916719, 0.9291227190988876, 0.9299401046228519, 0.9308198092733599, 0.9315651469129069, 0.9320392971349603, 0.9328482568553167, 0.933386027083772, 0.9335025207600597, 0.9342572770272597, 0.9343519968791392, 0.9345826016300164, 0.935089248540758, 0.9347319348882809, 0.935307442601334, 0.935498496671941, 0.9355867191649418, 0.935837751688572, 0.9356366505705337, 0.9361010942497325, 0.9337538650608647, 0.9361887381464539, 0.936529346720324, 0.9363612749108381, 0.9367621492117524, 0.9367638580207205, 0.9346114757367263, 0.9351453605494754, 0.9365932562134482, 0.9371656700795875, 0.9374337708414469, 0.9373754874182965, 0.9373781907611244, 0.9378153747884665, 0.9376051733826213, 0.9325284638552694, 0.9361122486159359, 0.9372688650431147, 0.9376880367881913, 0.937765008008724, 0.9379526841768708, 0.9380486802923054, 0.9382966209302797, 0.9384573513484409, 0.9381659282734816, 0.9384795159660948, 0.9383380794746417, 0.9384454236933764, 0.9386690266145933, 0.9385272976316699, 0.9385813108679364, 0.9386439399361183, 0.9386288987586981, 0.9389968840187296, 0.938558226483101, 0.9389708819356153, 0.9388385939336582, 0.93900221781096, 0.9391391416612845, 0.9391721015840461, 0.9391835444186263, 0.939313295432672, 0.9390974936795069, 0.9393173047722304, 0.9391876016204252, 0.9394637640456414, 0.9393950735081904, 0.9394197495293954, 0.9394255434755182, 0.9394771415230293, 0.9396280204286759, 0.9397311168515564, 0.939652646462944, 0.9396699593806915, 0.9399560705264192, 0.9399461948879155, 0.9398164187923963, 0.93988057123008, 0.93987832621818, 0.9399489246197226, 0.9398616872566005, 0.9399622741491829, 0.9399603186994382, 0.9400847614678972, 0.9401391596639239, 0.9401351493688808, 0.940089253138651, 0.9400658777207168, 0.9402622956436059, 0.9404589023627301, 0.9402145601933175, 0.9401275210429837, 0.9404200050579901, 0.9403871932605027, 0.9401429470670145, 0.9404118444516774, 0.9401644833026066, 0.9401572901874221, 0.9404041683389728, 0.9403200501682537, 0.9405401495281993, 0.9404095750372009, 0.9405657196819367, 0.9406515273507752, 0.940602877225033, 0.9406534365223722, 0.9406690784105142, 0.9405136857699604, 0.9403966581034424, 0.9373793245820249, 0.9372860796590868, 0.9396141113874857, 0.9401481879006406, 0.9407115987372584, 0.9408317392975236, 0.940618764144714, 0.9408709038613945, 0.9408550165016876, 0.9407410978064007, 0.940971828040079, 0.940966563306763, 0.9407216920376931, 0.9408398054868605, 0.9408903883695854, 0.9408402154903778, 0.9410834973609239], 'mDice': [0.11852000271824877, 0.3219089441675598, 0.4263434122821194, 0.4930715721962548, 0.5401525065016832, 0.5709026459147974, 0.5864899360261067, 0.5981098103940651, 0.610057723984842, 0.6151879696850031, 0.6203272920372969, 0.6251950602419792, 0.6303249075050169, 0.6349582734099924, 0.6381943610066025, 0.640728502755325, 0.6458371630627202, 0.6472777337420467, 0.6480711964433441, 0.6527802972722169, 0.6531978879666887, 0.6554880547287142, 0.6568646612637055, 0.6582064999731451, 0.6614223883338579, 0.6600564474346416, 0.6632662716482138, 0.6484113705231153, 0.6632658958284192, 0.6665573605654286, 0.6657770108482652, 0.6673778465618391, 0.667664534707181, 0.6533365625541588, 0.6540039684847422, 0.6653543900422622, 0.6703550302637853, 0.671889126087085, 0.6719962202202693, 0.6734533027942813, 0.6755372181242464, 0.675043749396898, 0.6391070627809149, 0.6635964110264218, 0.6711383008725581, 0.6750589348147926, 0.6757828988900192, 0.6774459989154874, 0.6767683897660116, 0.6789174188015658, 0.6796101951770103, 0.6788316055758294, 0.6812154510885672, 0.6803127316653138, 0.6804502678304704, 0.6818408322620935, 0.6815927420781901, 0.6822039675320334, 0.6813983736071398, 0.6817392268605283, 0.683471659911481, 0.681877270828091, 0.6855905676436208, 0.6830942851032192, 0.6843180795229832, 0.686753271740465, 0.6867746691164702, 0.687909938028859, 0.6877656899985068, 0.6863196664810985, 0.6879561257950744, 0.6870245817994498, 0.6882317579891379, 0.6894823666414464, 0.6885316930750558, 0.6884168459503642, 0.6886279826877338, 0.6898678245863263, 0.6904484427219151, 0.689966178963743, 0.6902246257344069, 0.6922347694101074, 0.6928921084669516, 0.6913825029362307, 0.6927834140854631, 0.6925569485823481, 0.6933711056617764, 0.6922049373168278, 0.6929889188942289, 0.6937637319546716, 0.6940246771544099, 0.6943827913647789, 0.6941656796169341, 0.6943927143500641, 0.6942036068406796, 0.6952093944120096, 0.6952583832947973, 0.6954866478876132, 0.6943252672628119, 0.6969342798755229, 0.6970239561259357, 0.694865505797429, 0.6959258359686983, 0.6965507306370698, 0.6950741397808986, 0.6976991134765053, 0.6974281225997018, 0.6987398386982216, 0.6979679575928955, 0.6986255845020803, 0.6991090208285722, 0.6986853142273474, 0.699948063884398, 0.6994485310601977, 0.6994130326157204, 0.697394070306475, 0.6775160693551538, 0.6730218494750608, 0.6906064720853827, 0.6958126654933712, 0.6991561441903275, 0.7002307069977988, 0.6983079848297536, 0.7008189041512446, 0.7013908066821989, 0.7006793027687516, 0.7022308720060855, 0.7018182198600511, 0.700318990038357, 0.7020396427423283, 0.7016764702084849, 0.7031571722136246, 0.7032682447714083]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:02<00:11,  2.91s/it]predicting test subjects:  40%|████      | 2/5 [00:05<00:08,  2.70s/it]predicting test subjects:  60%|██████    | 3/5 [00:07<00:05,  2.51s/it]predicting test subjects:  80%|████████  | 4/5 [00:09<00:02,  2.34s/it]predicting test subjects: 100%|██████████| 5/5 [00:11<00:00,  2.39s/it]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:02<13:13,  2.99s/it]predicting train subjects:   1%|          | 2/266 [00:05<12:47,  2.91s/it]predicting train subjects:   1%|          | 3/266 [00:07<11:55,  2.72s/it]predicting train subjects:   2%|▏         | 4/266 [00:09<10:53,  2.49s/it]predicting train subjects:   2%|▏         | 5/266 [00:12<11:09,  2.57s/it]predicting train subjects:   2%|▏         | 6/266 [00:15<11:30,  2.65s/it]predicting train subjects:   3%|▎         | 7/266 [00:18<11:41,  2.71s/it]predicting train subjects:   3%|▎         | 8/266 [00:21<11:52,  2.76s/it]predicting train subjects:   3%|▎         | 9/266 [00:24<11:57,  2.79s/it]predicting train subjects:   4%|▍         | 10/266 [00:27<12:08,  2.85s/it]predicting train subjects:   4%|▍         | 11/266 [00:30<12:14,  2.88s/it]predicting train subjects:   5%|▍         | 12/266 [00:32<11:53,  2.81s/it]predicting train subjects:   5%|▍         | 13/266 [00:35<11:41,  2.77s/it]predicting train subjects:   5%|▌         | 14/266 [00:38<11:52,  2.83s/it]predicting train subjects:   6%|▌         | 15/266 [00:41<11:45,  2.81s/it]predicting train subjects:   6%|▌         | 16/266 [00:43<11:44,  2.82s/it]predicting train subjects:   6%|▋         | 17/266 [00:46<11:43,  2.82s/it]predicting train subjects:   7%|▋         | 18/266 [00:49<11:32,  2.79s/it]predicting train subjects:   7%|▋         | 19/266 [00:52<11:35,  2.82s/it]predicting train subjects:   8%|▊         | 20/266 [00:55<11:40,  2.85s/it]predicting train subjects:   8%|▊         | 21/266 [00:58<11:46,  2.88s/it]predicting train subjects:   8%|▊         | 22/266 [01:01<11:44,  2.89s/it]predicting train subjects:   9%|▊         | 23/266 [01:03<11:31,  2.85s/it]predicting train subjects:   9%|▉         | 24/266 [01:06<11:15,  2.79s/it]predicting train subjects:   9%|▉         | 25/266 [01:09<11:08,  2.77s/it]predicting train subjects:  10%|▉         | 26/266 [01:11<10:56,  2.74s/it]predicting train subjects:  10%|█         | 27/266 [01:14<10:45,  2.70s/it]predicting train subjects:  11%|█         | 28/266 [01:17<10:45,  2.71s/it]predicting train subjects:  11%|█         | 29/266 [01:20<10:39,  2.70s/it]predicting train subjects:  11%|█▏        | 30/266 [01:22<10:30,  2.67s/it]predicting train subjects:  12%|█▏        | 31/266 [01:25<10:30,  2.68s/it]predicting train subjects:  12%|█▏        | 32/266 [01:27<10:18,  2.64s/it]predicting train subjects:  12%|█▏        | 33/266 [01:30<10:13,  2.63s/it]predicting train subjects:  13%|█▎        | 34/266 [01:33<10:13,  2.64s/it]predicting train subjects:  13%|█▎        | 35/266 [01:35<10:07,  2.63s/it]predicting train subjects:  14%|█▎        | 36/266 [01:38<09:58,  2.60s/it]predicting train subjects:  14%|█▍        | 37/266 [01:40<09:54,  2.60s/it]predicting train subjects:  14%|█▍        | 38/266 [01:43<09:58,  2.62s/it]predicting train subjects:  15%|█▍        | 39/266 [01:46<09:58,  2.64s/it]predicting train subjects:  15%|█▌        | 40/266 [01:48<10:02,  2.67s/it]predicting train subjects:  15%|█▌        | 41/266 [01:51<10:01,  2.67s/it]predicting train subjects:  16%|█▌        | 42/266 [01:53<09:25,  2.53s/it]predicting train subjects:  16%|█▌        | 43/266 [01:55<08:54,  2.40s/it]predicting train subjects:  17%|█▋        | 44/266 [01:58<08:45,  2.36s/it]predicting train subjects:  17%|█▋        | 45/266 [02:00<08:25,  2.29s/it]predicting train subjects:  17%|█▋        | 46/266 [02:02<08:10,  2.23s/it]predicting train subjects:  18%|█▊        | 47/266 [02:04<08:03,  2.21s/it]predicting train subjects:  18%|█▊        | 48/266 [02:06<07:54,  2.18s/it]predicting train subjects:  18%|█▊        | 49/266 [02:08<07:47,  2.16s/it]predicting train subjects:  19%|█▉        | 50/266 [02:10<07:47,  2.16s/it]predicting train subjects:  19%|█▉        | 51/266 [02:13<07:54,  2.21s/it]predicting train subjects:  20%|█▉        | 52/266 [02:15<07:53,  2.21s/it]predicting train subjects:  20%|█▉        | 53/266 [02:17<07:45,  2.18s/it]predicting train subjects:  20%|██        | 54/266 [02:19<07:40,  2.17s/it]predicting train subjects:  21%|██        | 55/266 [02:21<07:32,  2.14s/it]predicting train subjects:  21%|██        | 56/266 [02:23<07:30,  2.15s/it]predicting train subjects:  21%|██▏       | 57/266 [02:26<07:26,  2.13s/it]predicting train subjects:  22%|██▏       | 58/266 [02:28<07:26,  2.15s/it]predicting train subjects:  22%|██▏       | 59/266 [02:30<07:23,  2.14s/it]predicting train subjects:  23%|██▎       | 60/266 [02:32<07:21,  2.14s/it]predicting train subjects:  23%|██▎       | 61/266 [02:34<07:20,  2.15s/it]predicting train subjects:  23%|██▎       | 62/266 [02:37<07:38,  2.25s/it]predicting train subjects:  24%|██▎       | 63/266 [02:39<07:38,  2.26s/it]predicting train subjects:  24%|██▍       | 64/266 [02:41<07:17,  2.16s/it]predicting train subjects:  24%|██▍       | 65/266 [02:43<07:24,  2.21s/it]predicting train subjects:  25%|██▍       | 66/266 [02:45<07:12,  2.16s/it]predicting train subjects:  25%|██▌       | 67/266 [02:48<07:25,  2.24s/it]predicting train subjects:  26%|██▌       | 68/266 [02:50<07:20,  2.22s/it]predicting train subjects:  26%|██▌       | 69/266 [02:52<07:03,  2.15s/it]predicting train subjects:  26%|██▋       | 70/266 [02:54<07:02,  2.15s/it]predicting train subjects:  27%|██▋       | 71/266 [02:56<06:47,  2.09s/it]predicting train subjects:  27%|██▋       | 72/266 [02:58<06:38,  2.06s/it]predicting train subjects:  27%|██▋       | 73/266 [03:00<06:45,  2.10s/it]predicting train subjects:  28%|██▊       | 74/266 [03:02<06:37,  2.07s/it]predicting train subjects:  28%|██▊       | 75/266 [03:04<06:31,  2.05s/it]predicting train subjects:  29%|██▊       | 76/266 [03:06<06:28,  2.05s/it]predicting train subjects:  29%|██▉       | 77/266 [03:08<06:19,  2.01s/it]predicting train subjects:  29%|██▉       | 78/266 [03:11<07:01,  2.24s/it]predicting train subjects:  30%|██▉       | 79/266 [03:13<07:18,  2.34s/it]predicting train subjects:  30%|███       | 80/266 [03:16<07:30,  2.42s/it]predicting train subjects:  30%|███       | 81/266 [03:19<07:37,  2.47s/it]predicting train subjects:  31%|███       | 82/266 [03:21<07:39,  2.50s/it]predicting train subjects:  31%|███       | 83/266 [03:24<07:48,  2.56s/it]predicting train subjects:  32%|███▏      | 84/266 [03:27<07:48,  2.58s/it]predicting train subjects:  32%|███▏      | 85/266 [03:29<08:02,  2.66s/it]predicting train subjects:  32%|███▏      | 86/266 [03:32<07:56,  2.65s/it]predicting train subjects:  33%|███▎      | 87/266 [03:35<07:53,  2.65s/it]predicting train subjects:  33%|███▎      | 88/266 [03:37<07:47,  2.62s/it]predicting train subjects:  33%|███▎      | 89/266 [03:40<07:51,  2.66s/it]predicting train subjects:  34%|███▍      | 90/266 [03:43<08:05,  2.76s/it]predicting train subjects:  34%|███▍      | 91/266 [03:46<08:06,  2.78s/it]predicting train subjects:  35%|███▍      | 92/266 [03:48<07:58,  2.75s/it]predicting train subjects:  35%|███▍      | 93/266 [03:51<07:48,  2.71s/it]predicting train subjects:  35%|███▌      | 94/266 [03:54<07:47,  2.72s/it]predicting train subjects:  36%|███▌      | 95/266 [03:56<07:39,  2.69s/it]predicting train subjects:  36%|███▌      | 96/266 [03:59<07:16,  2.57s/it]predicting train subjects:  36%|███▋      | 97/266 [04:01<07:17,  2.59s/it]predicting train subjects:  37%|███▋      | 98/266 [04:04<07:17,  2.61s/it]predicting train subjects:  37%|███▋      | 99/266 [04:06<06:40,  2.40s/it]predicting train subjects:  38%|███▊      | 100/266 [04:08<06:29,  2.35s/it]predicting train subjects:  38%|███▊      | 101/266 [04:10<06:24,  2.33s/it]predicting train subjects:  38%|███▊      | 102/266 [04:13<06:23,  2.34s/it]predicting train subjects:  39%|███▊      | 103/266 [04:15<06:17,  2.31s/it]predicting train subjects:  39%|███▉      | 104/266 [04:17<06:11,  2.30s/it]predicting train subjects:  39%|███▉      | 105/266 [04:19<05:57,  2.22s/it]predicting train subjects:  40%|███▉      | 106/266 [04:22<05:52,  2.20s/it]predicting train subjects:  40%|████      | 107/266 [04:24<05:51,  2.21s/it]predicting train subjects:  41%|████      | 108/266 [04:26<05:55,  2.25s/it]predicting train subjects:  41%|████      | 109/266 [04:28<05:53,  2.25s/it]predicting train subjects:  41%|████▏     | 110/266 [04:31<05:49,  2.24s/it]predicting train subjects:  42%|████▏     | 111/266 [04:33<05:51,  2.27s/it]predicting train subjects:  42%|████▏     | 112/266 [04:35<05:46,  2.25s/it]predicting train subjects:  42%|████▏     | 113/266 [04:37<05:49,  2.29s/it]predicting train subjects:  43%|████▎     | 114/266 [04:40<05:51,  2.31s/it]predicting train subjects:  43%|████▎     | 115/266 [04:42<05:54,  2.34s/it]predicting train subjects:  44%|████▎     | 116/266 [04:44<05:44,  2.30s/it]predicting train subjects:  44%|████▍     | 117/266 [04:47<05:40,  2.28s/it]predicting train subjects:  44%|████▍     | 118/266 [04:49<05:32,  2.25s/it]predicting train subjects:  45%|████▍     | 119/266 [04:52<05:51,  2.39s/it]predicting train subjects:  45%|████▌     | 120/266 [04:54<05:52,  2.41s/it]predicting train subjects:  45%|████▌     | 121/266 [04:57<05:53,  2.43s/it]predicting train subjects:  46%|████▌     | 122/266 [04:59<05:51,  2.44s/it]predicting train subjects:  46%|████▌     | 123/266 [05:02<05:52,  2.46s/it]predicting train subjects:  47%|████▋     | 124/266 [05:04<05:59,  2.53s/it]predicting train subjects:  47%|████▋     | 125/266 [05:07<05:58,  2.54s/it]predicting train subjects:  47%|████▋     | 126/266 [05:09<05:59,  2.57s/it]predicting train subjects:  48%|████▊     | 127/266 [05:12<06:03,  2.61s/it]predicting train subjects:  48%|████▊     | 128/266 [05:15<06:00,  2.61s/it]predicting train subjects:  48%|████▊     | 129/266 [05:17<05:56,  2.61s/it]predicting train subjects:  49%|████▉     | 130/266 [05:20<05:56,  2.62s/it]predicting train subjects:  49%|████▉     | 131/266 [05:23<05:57,  2.65s/it]predicting train subjects:  50%|████▉     | 132/266 [05:25<05:54,  2.64s/it]predicting train subjects:  50%|█████     | 133/266 [05:28<05:58,  2.70s/it]predicting train subjects:  50%|█████     | 134/266 [05:31<05:48,  2.64s/it]predicting train subjects:  51%|█████     | 135/266 [05:33<05:41,  2.61s/it]predicting train subjects:  51%|█████     | 136/266 [05:36<05:42,  2.63s/it]predicting train subjects:  52%|█████▏    | 137/266 [05:38<05:32,  2.58s/it]predicting train subjects:  52%|█████▏    | 138/266 [05:41<05:31,  2.59s/it]predicting train subjects:  52%|█████▏    | 139/266 [05:43<05:26,  2.57s/it]predicting train subjects:  53%|█████▎    | 140/266 [05:46<05:30,  2.63s/it]predicting train subjects:  53%|█████▎    | 141/266 [05:49<05:28,  2.62s/it]predicting train subjects:  53%|█████▎    | 142/266 [05:52<05:26,  2.63s/it]predicting train subjects:  54%|█████▍    | 143/266 [05:54<05:21,  2.61s/it]predicting train subjects:  54%|█████▍    | 144/266 [05:57<05:16,  2.60s/it]predicting train subjects:  55%|█████▍    | 145/266 [05:59<05:13,  2.59s/it]predicting train subjects:  55%|█████▍    | 146/266 [06:02<05:12,  2.60s/it]predicting train subjects:  55%|█████▌    | 147/266 [06:04<05:01,  2.54s/it]predicting train subjects:  56%|█████▌    | 148/266 [06:07<04:58,  2.53s/it]predicting train subjects:  56%|█████▌    | 149/266 [06:09<05:02,  2.59s/it]predicting train subjects:  56%|█████▋    | 150/266 [06:12<04:59,  2.58s/it]predicting train subjects:  57%|█████▋    | 151/266 [06:15<04:54,  2.56s/it]predicting train subjects:  57%|█████▋    | 152/266 [06:17<04:44,  2.49s/it]predicting train subjects:  58%|█████▊    | 153/266 [06:19<04:34,  2.43s/it]predicting train subjects:  58%|█████▊    | 154/266 [06:22<04:31,  2.43s/it]predicting train subjects:  58%|█████▊    | 155/266 [06:24<04:23,  2.38s/it]predicting train subjects:  59%|█████▊    | 156/266 [06:26<04:04,  2.22s/it]predicting train subjects:  59%|█████▉    | 157/266 [06:28<03:49,  2.10s/it]predicting train subjects:  59%|█████▉    | 158/266 [06:29<03:35,  1.99s/it]predicting train subjects:  60%|█████▉    | 159/266 [06:31<03:26,  1.93s/it]predicting train subjects:  60%|██████    | 160/266 [06:33<03:22,  1.91s/it]predicting train subjects:  61%|██████    | 161/266 [06:35<03:24,  1.95s/it]predicting train subjects:  61%|██████    | 162/266 [06:37<03:17,  1.90s/it]predicting train subjects:  61%|██████▏   | 163/266 [06:38<03:10,  1.85s/it]predicting train subjects:  62%|██████▏   | 164/266 [06:40<03:03,  1.80s/it]predicting train subjects:  62%|██████▏   | 165/266 [06:42<03:10,  1.89s/it]predicting train subjects:  62%|██████▏   | 166/266 [06:45<03:20,  2.00s/it]predicting train subjects:  63%|██████▎   | 167/266 [06:46<03:16,  1.98s/it]predicting train subjects:  63%|██████▎   | 168/266 [06:48<03:12,  1.97s/it]predicting train subjects:  64%|██████▎   | 169/266 [06:50<03:08,  1.94s/it]predicting train subjects:  64%|██████▍   | 170/266 [06:52<03:06,  1.94s/it]predicting train subjects:  64%|██████▍   | 171/266 [06:54<03:14,  2.04s/it]predicting train subjects:  65%|██████▍   | 172/266 [06:56<03:10,  2.03s/it]predicting train subjects:  65%|██████▌   | 173/266 [06:59<03:12,  2.06s/it]predicting train subjects:  65%|██████▌   | 174/266 [07:01<03:15,  2.12s/it]predicting train subjects:  66%|██████▌   | 175/266 [07:03<03:13,  2.13s/it]predicting train subjects:  66%|██████▌   | 176/266 [07:05<03:10,  2.12s/it]predicting train subjects:  67%|██████▋   | 177/266 [07:08<03:16,  2.21s/it]predicting train subjects:  67%|██████▋   | 178/266 [07:10<03:22,  2.30s/it]predicting train subjects:  67%|██████▋   | 179/266 [07:12<03:15,  2.24s/it]predicting train subjects:  68%|██████▊   | 180/266 [07:15<03:20,  2.33s/it]predicting train subjects:  68%|██████▊   | 181/266 [07:17<03:13,  2.28s/it]predicting train subjects:  68%|██████▊   | 182/266 [07:19<03:07,  2.24s/it]predicting train subjects:  69%|██████▉   | 183/266 [07:21<03:02,  2.20s/it]predicting train subjects:  69%|██████▉   | 184/266 [07:23<02:56,  2.15s/it]predicting train subjects:  70%|██████▉   | 185/266 [07:25<02:52,  2.13s/it]predicting train subjects:  70%|██████▉   | 186/266 [07:28<02:54,  2.18s/it]predicting train subjects:  70%|███████   | 187/266 [07:30<02:51,  2.17s/it]predicting train subjects:  71%|███████   | 188/266 [07:32<02:46,  2.14s/it]predicting train subjects:  71%|███████   | 189/266 [07:34<02:42,  2.11s/it]predicting train subjects:  71%|███████▏  | 190/266 [07:36<02:40,  2.11s/it]predicting train subjects:  72%|███████▏  | 191/266 [07:38<02:41,  2.16s/it]predicting train subjects:  72%|███████▏  | 192/266 [07:40<02:34,  2.09s/it]predicting train subjects:  73%|███████▎  | 193/266 [07:42<02:27,  2.02s/it]predicting train subjects:  73%|███████▎  | 194/266 [07:44<02:36,  2.17s/it]predicting train subjects:  73%|███████▎  | 195/266 [07:47<02:34,  2.17s/it]predicting train subjects:  74%|███████▎  | 196/266 [07:49<02:33,  2.20s/it]predicting train subjects:  74%|███████▍  | 197/266 [07:51<02:31,  2.19s/it]predicting train subjects:  74%|███████▍  | 198/266 [07:53<02:30,  2.22s/it]predicting train subjects:  75%|███████▍  | 199/266 [07:56<02:30,  2.24s/it]predicting train subjects:  75%|███████▌  | 200/266 [07:58<02:26,  2.22s/it]predicting train subjects:  76%|███████▌  | 201/266 [08:00<02:20,  2.17s/it]predicting train subjects:  76%|███████▌  | 202/266 [08:02<02:18,  2.16s/it]predicting train subjects:  76%|███████▋  | 203/266 [08:04<02:18,  2.20s/it]predicting train subjects:  77%|███████▋  | 204/266 [08:06<02:16,  2.20s/it]predicting train subjects:  77%|███████▋  | 205/266 [08:09<02:12,  2.16s/it]predicting train subjects:  77%|███████▋  | 206/266 [08:11<02:09,  2.16s/it]predicting train subjects:  78%|███████▊  | 207/266 [08:13<02:05,  2.13s/it]predicting train subjects:  78%|███████▊  | 208/266 [08:15<02:05,  2.16s/it]predicting train subjects:  79%|███████▊  | 209/266 [08:17<02:05,  2.20s/it]predicting train subjects:  79%|███████▉  | 210/266 [08:20<02:04,  2.22s/it]predicting train subjects:  79%|███████▉  | 211/266 [08:22<02:02,  2.22s/it]predicting train subjects:  80%|███████▉  | 212/266 [08:24<02:03,  2.28s/it]predicting train subjects:  80%|████████  | 213/266 [08:26<01:56,  2.20s/it]predicting train subjects:  80%|████████  | 214/266 [08:28<01:50,  2.13s/it]predicting train subjects:  81%|████████  | 215/266 [08:30<01:46,  2.09s/it]predicting train subjects:  81%|████████  | 216/266 [08:32<01:42,  2.05s/it]predicting train subjects:  82%|████████▏ | 217/266 [08:34<01:41,  2.06s/it]predicting train subjects:  82%|████████▏ | 218/266 [08:36<01:36,  2.01s/it]predicting train subjects:  82%|████████▏ | 219/266 [08:38<01:33,  1.99s/it]predicting train subjects:  83%|████████▎ | 220/266 [08:40<01:28,  1.93s/it]predicting train subjects:  83%|████████▎ | 221/266 [08:42<01:25,  1.89s/it]predicting train subjects:  83%|████████▎ | 222/266 [08:43<01:21,  1.86s/it]predicting train subjects:  84%|████████▍ | 223/266 [08:46<01:22,  1.93s/it]predicting train subjects:  84%|████████▍ | 224/266 [08:48<01:27,  2.07s/it]predicting train subjects:  85%|████████▍ | 225/266 [08:50<01:25,  2.09s/it]predicting train subjects:  85%|████████▍ | 226/266 [08:52<01:21,  2.04s/it]predicting train subjects:  85%|████████▌ | 227/266 [08:54<01:19,  2.03s/it]predicting train subjects:  86%|████████▌ | 228/266 [08:56<01:16,  2.01s/it]predicting train subjects:  86%|████████▌ | 229/266 [08:58<01:14,  2.03s/it]predicting train subjects:  86%|████████▋ | 230/266 [09:00<01:11,  1.98s/it]predicting train subjects:  87%|████████▋ | 231/266 [09:02<01:11,  2.03s/it]predicting train subjects:  87%|████████▋ | 232/266 [09:05<01:13,  2.17s/it]predicting train subjects:  88%|████████▊ | 233/266 [09:07<01:10,  2.13s/it]predicting train subjects:  88%|████████▊ | 234/266 [09:08<01:05,  2.04s/it]predicting train subjects:  88%|████████▊ | 235/266 [09:10<01:01,  1.98s/it]predicting train subjects:  89%|████████▊ | 236/266 [09:13<01:02,  2.09s/it]predicting train subjects:  89%|████████▉ | 237/266 [09:15<00:59,  2.06s/it]predicting train subjects:  89%|████████▉ | 238/266 [09:17<00:56,  2.01s/it]predicting train subjects:  90%|████████▉ | 239/266 [09:19<00:55,  2.05s/it]predicting train subjects:  90%|█████████ | 240/266 [09:21<00:56,  2.18s/it]predicting train subjects:  91%|█████████ | 241/266 [09:24<00:57,  2.32s/it]predicting train subjects:  91%|█████████ | 242/266 [09:26<00:57,  2.40s/it]predicting train subjects:  91%|█████████▏| 243/266 [09:29<00:56,  2.46s/it]predicting train subjects:  92%|█████████▏| 244/266 [09:32<00:55,  2.54s/it]predicting train subjects:  92%|█████████▏| 245/266 [09:34<00:53,  2.55s/it]predicting train subjects:  92%|█████████▏| 246/266 [09:37<00:51,  2.57s/it]predicting train subjects:  93%|█████████▎| 247/266 [09:40<00:49,  2.62s/it]predicting train subjects:  93%|█████████▎| 248/266 [09:42<00:46,  2.58s/it]predicting train subjects:  94%|█████████▎| 249/266 [09:45<00:47,  2.80s/it]predicting train subjects:  94%|█████████▍| 250/266 [09:49<00:46,  2.93s/it]predicting train subjects:  94%|█████████▍| 251/266 [09:52<00:45,  3.02s/it]predicting train subjects:  95%|█████████▍| 252/266 [09:55<00:42,  3.06s/it]predicting train subjects:  95%|█████████▌| 253/266 [09:58<00:40,  3.11s/it]predicting train subjects:  95%|█████████▌| 254/266 [10:01<00:37,  3.12s/it]predicting train subjects:  96%|█████████▌| 255/266 [10:05<00:34,  3.14s/it]predicting train subjects:  96%|█████████▌| 256/266 [10:08<00:31,  3.14s/it]predicting train subjects:  97%|█████████▋| 257/266 [10:11<00:28,  3.18s/it]predicting train subjects:  97%|█████████▋| 258/266 [10:14<00:25,  3.20s/it]predicting train subjects:  97%|█████████▋| 259/266 [10:17<00:22,  3.20s/it]predicting train subjects:  98%|█████████▊| 260/266 [10:21<00:19,  3.20s/it]predicting train subjects:  98%|█████████▊| 261/266 [10:24<00:15,  3.18s/it]predicting train subjects:  98%|█████████▊| 262/266 [10:27<00:12,  3.17s/it]predicting train subjects:  99%|█████████▉| 263/266 [10:30<00:09,  3.20s/it]predicting train subjects:  99%|█████████▉| 264/266 [10:33<00:06,  3.19s/it]predicting train subjects: 100%|█████████▉| 265/266 [10:37<00:03,  3.19s/it]predicting train subjects: 100%|██████████| 266/266 [10:39<00:00,  3.10s/it]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<03:28,  1.27it/s]Loading train:   1%|          | 2/266 [00:01<03:27,  1.27it/s]Loading train:   1%|          | 3/266 [00:02<03:13,  1.36it/s]Loading train:   2%|▏         | 4/266 [00:02<02:56,  1.49it/s]Loading train:   2%|▏         | 5/266 [00:03<03:01,  1.44it/s]Loading train:   2%|▏         | 6/266 [00:04<02:50,  1.52it/s]Loading train:   3%|▎         | 7/266 [00:04<02:46,  1.55it/s]Loading train:   3%|▎         | 8/266 [00:05<02:36,  1.65it/s]Loading train:   3%|▎         | 9/266 [00:05<02:39,  1.62it/s]Loading train:   4%|▍         | 10/266 [00:06<02:29,  1.71it/s]Loading train:   4%|▍         | 11/266 [00:06<02:25,  1.75it/s]Loading train:   5%|▍         | 12/266 [00:07<02:21,  1.79it/s]Loading train:   5%|▍         | 13/266 [00:07<02:18,  1.83it/s]Loading train:   5%|▌         | 14/266 [00:08<02:20,  1.79it/s]Loading train:   6%|▌         | 15/266 [00:09<02:18,  1.82it/s]Loading train:   6%|▌         | 16/266 [00:09<02:34,  1.62it/s]Loading train:   6%|▋         | 17/266 [00:10<02:34,  1.61it/s]Loading train:   7%|▋         | 18/266 [00:10<02:29,  1.66it/s]Loading train:   7%|▋         | 19/266 [00:11<02:29,  1.66it/s]Loading train:   8%|▊         | 20/266 [00:12<02:24,  1.70it/s]Loading train:   8%|▊         | 21/266 [00:12<02:21,  1.73it/s]Loading train:   8%|▊         | 22/266 [00:13<02:18,  1.76it/s]Loading train:   9%|▊         | 23/266 [00:13<02:17,  1.76it/s]Loading train:   9%|▉         | 24/266 [00:14<02:16,  1.78it/s]Loading train:   9%|▉         | 25/266 [00:14<02:12,  1.82it/s]Loading train:  10%|▉         | 26/266 [00:15<02:13,  1.79it/s]Loading train:  10%|█         | 27/266 [00:16<02:14,  1.78it/s]Loading train:  11%|█         | 28/266 [00:16<02:19,  1.70it/s]Loading train:  11%|█         | 29/266 [00:17<02:19,  1.70it/s]Loading train:  11%|█▏        | 30/266 [00:17<02:14,  1.75it/s]Loading train:  12%|█▏        | 31/266 [00:18<02:12,  1.77it/s]Loading train:  12%|█▏        | 32/266 [00:18<02:13,  1.75it/s]Loading train:  12%|█▏        | 33/266 [00:19<02:11,  1.77it/s]Loading train:  13%|█▎        | 34/266 [00:20<02:12,  1.75it/s]Loading train:  13%|█▎        | 35/266 [00:20<02:11,  1.75it/s]Loading train:  14%|█▎        | 36/266 [00:21<02:12,  1.74it/s]Loading train:  14%|█▍        | 37/266 [00:21<02:17,  1.67it/s]Loading train:  14%|█▍        | 38/266 [00:22<02:24,  1.57it/s]Loading train:  15%|█▍        | 39/266 [00:23<02:19,  1.63it/s]Loading train:  15%|█▌        | 40/266 [00:23<02:17,  1.65it/s]Loading train:  15%|█▌        | 41/266 [00:24<02:09,  1.74it/s]Loading train:  16%|█▌        | 42/266 [00:24<02:03,  1.81it/s]Loading train:  16%|█▌        | 43/266 [00:25<02:08,  1.73it/s]Loading train:  17%|█▋        | 44/266 [00:26<02:10,  1.71it/s]Loading train:  17%|█▋        | 45/266 [00:26<02:03,  1.79it/s]Loading train:  17%|█▋        | 46/266 [00:27<02:07,  1.73it/s]Loading train:  18%|█▊        | 47/266 [00:27<02:05,  1.75it/s]Loading train:  18%|█▊        | 48/266 [00:28<02:07,  1.71it/s]Loading train:  18%|█▊        | 49/266 [00:28<02:04,  1.75it/s]Loading train:  19%|█▉        | 50/266 [00:29<02:08,  1.69it/s]Loading train:  19%|█▉        | 51/266 [00:30<02:10,  1.65it/s]Loading train:  20%|█▉        | 52/266 [00:30<02:12,  1.61it/s]Loading train:  20%|█▉        | 53/266 [00:31<02:06,  1.69it/s]Loading train:  20%|██        | 54/266 [00:31<02:04,  1.70it/s]Loading train:  21%|██        | 55/266 [00:32<02:07,  1.66it/s]Loading train:  21%|██        | 56/266 [00:33<02:04,  1.69it/s]Loading train:  21%|██▏       | 57/266 [00:33<01:59,  1.76it/s]Loading train:  22%|██▏       | 58/266 [00:34<02:00,  1.72it/s]Loading train:  22%|██▏       | 59/266 [00:34<01:56,  1.78it/s]Loading train:  23%|██▎       | 60/266 [00:35<01:53,  1.82it/s]Loading train:  23%|██▎       | 61/266 [00:35<02:00,  1.71it/s]Loading train:  23%|██▎       | 62/266 [00:36<02:09,  1.58it/s]Loading train:  24%|██▎       | 63/266 [00:37<02:00,  1.68it/s]Loading train:  24%|██▍       | 64/266 [00:37<01:56,  1.74it/s]Loading train:  24%|██▍       | 65/266 [00:38<02:00,  1.66it/s]Loading train:  25%|██▍       | 66/266 [00:38<01:56,  1.72it/s]Loading train:  25%|██▌       | 67/266 [00:39<01:53,  1.76it/s]Loading train:  26%|██▌       | 68/266 [00:39<01:49,  1.81it/s]Loading train:  26%|██▌       | 69/266 [00:40<01:44,  1.89it/s]Loading train:  26%|██▋       | 70/266 [00:41<01:48,  1.81it/s]Loading train:  27%|██▋       | 71/266 [00:41<01:42,  1.90it/s]Loading train:  27%|██▋       | 72/266 [00:42<01:48,  1.79it/s]Loading train:  27%|██▋       | 73/266 [00:42<01:50,  1.74it/s]Loading train:  28%|██▊       | 74/266 [00:43<01:54,  1.68it/s]Loading train:  28%|██▊       | 75/266 [00:43<01:52,  1.69it/s]Loading train:  29%|██▊       | 76/266 [00:44<01:46,  1.78it/s]Loading train:  29%|██▉       | 77/266 [00:44<01:44,  1.81it/s]Loading train:  29%|██▉       | 78/266 [00:45<01:49,  1.72it/s]Loading train:  30%|██▉       | 79/266 [00:46<01:54,  1.63it/s]Loading train:  30%|███       | 80/266 [00:46<01:52,  1.65it/s]Loading train:  30%|███       | 81/266 [00:47<01:55,  1.61it/s]Loading train:  31%|███       | 82/266 [00:48<01:55,  1.59it/s]Loading train:  31%|███       | 83/266 [00:48<01:51,  1.64it/s]Loading train:  32%|███▏      | 84/266 [00:49<01:47,  1.70it/s]Loading train:  32%|███▏      | 85/266 [00:49<01:47,  1.68it/s]Loading train:  32%|███▏      | 86/266 [00:50<01:50,  1.63it/s]Loading train:  33%|███▎      | 87/266 [00:51<01:55,  1.55it/s]Loading train:  33%|███▎      | 88/266 [00:51<01:54,  1.56it/s]Loading train:  33%|███▎      | 89/266 [00:52<01:47,  1.65it/s]Loading train:  34%|███▍      | 90/266 [00:52<01:40,  1.74it/s]Loading train:  34%|███▍      | 91/266 [00:53<01:45,  1.65it/s]Loading train:  35%|███▍      | 92/266 [00:54<01:51,  1.56it/s]Loading train:  35%|███▍      | 93/266 [00:54<01:45,  1.64it/s]Loading train:  35%|███▌      | 94/266 [00:55<01:52,  1.53it/s]Loading train:  36%|███▌      | 95/266 [00:56<01:42,  1.66it/s]Loading train:  36%|███▌      | 96/266 [00:56<01:49,  1.56it/s]Loading train:  36%|███▋      | 97/266 [00:57<01:47,  1.57it/s]Loading train:  37%|███▋      | 98/266 [00:58<01:49,  1.53it/s]Loading train:  37%|███▋      | 99/266 [00:58<01:47,  1.55it/s]Loading train:  38%|███▊      | 100/266 [00:59<01:45,  1.57it/s]Loading train:  38%|███▊      | 101/266 [01:00<01:44,  1.58it/s]Loading train:  38%|███▊      | 102/266 [01:00<01:36,  1.69it/s]Loading train:  39%|███▊      | 103/266 [01:01<01:34,  1.73it/s]Loading train:  39%|███▉      | 104/266 [01:01<01:29,  1.80it/s]Loading train:  39%|███▉      | 105/266 [01:02<01:28,  1.81it/s]Loading train:  40%|███▉      | 106/266 [01:02<01:25,  1.88it/s]Loading train:  40%|████      | 107/266 [01:03<01:29,  1.78it/s]Loading train:  41%|████      | 108/266 [01:03<01:24,  1.87it/s]Loading train:  41%|████      | 109/266 [01:04<01:22,  1.90it/s]Loading train:  41%|████▏     | 110/266 [01:04<01:21,  1.92it/s]Loading train:  42%|████▏     | 111/266 [01:05<01:20,  1.93it/s]Loading train:  42%|████▏     | 112/266 [01:05<01:19,  1.94it/s]Loading train:  42%|████▏     | 113/266 [01:06<01:21,  1.87it/s]Loading train:  43%|████▎     | 114/266 [01:06<01:22,  1.84it/s]Loading train:  43%|████▎     | 115/266 [01:07<01:30,  1.66it/s]Loading train:  44%|████▎     | 116/266 [01:08<01:28,  1.69it/s]Loading train:  44%|████▍     | 117/266 [01:08<01:25,  1.74it/s]Loading train:  44%|████▍     | 118/266 [01:09<01:21,  1.81it/s]Loading train:  45%|████▍     | 119/266 [01:09<01:22,  1.78it/s]Loading train:  45%|████▌     | 120/266 [01:10<01:19,  1.85it/s]Loading train:  45%|████▌     | 121/266 [01:10<01:15,  1.93it/s]Loading train:  46%|████▌     | 122/266 [01:11<01:24,  1.71it/s]Loading train:  46%|████▌     | 123/266 [01:12<01:25,  1.67it/s]Loading train:  47%|████▋     | 124/266 [01:12<01:27,  1.63it/s]Loading train:  47%|████▋     | 125/266 [01:13<01:26,  1.62it/s]Loading train:  47%|████▋     | 126/266 [01:14<01:27,  1.59it/s]Loading train:  48%|████▊     | 127/266 [01:14<01:26,  1.61it/s]Loading train:  48%|████▊     | 128/266 [01:15<01:22,  1.66it/s]Loading train:  48%|████▊     | 129/266 [01:15<01:20,  1.69it/s]Loading train:  49%|████▉     | 130/266 [01:16<01:22,  1.64it/s]Loading train:  49%|████▉     | 131/266 [01:17<01:34,  1.42it/s]Loading train:  50%|████▉     | 132/266 [01:18<01:34,  1.42it/s]Loading train:  50%|█████     | 133/266 [01:18<01:33,  1.42it/s]Loading train:  50%|█████     | 134/266 [01:19<01:38,  1.35it/s]Loading train:  51%|█████     | 135/266 [01:20<01:34,  1.39it/s]Loading train:  51%|█████     | 136/266 [01:20<01:31,  1.42it/s]Loading train:  52%|█████▏    | 137/266 [01:21<01:28,  1.46it/s]Loading train:  52%|█████▏    | 138/266 [01:22<01:28,  1.45it/s]Loading train:  52%|█████▏    | 139/266 [01:22<01:23,  1.52it/s]Loading train:  53%|█████▎    | 140/266 [01:23<01:27,  1.45it/s]Loading train:  53%|█████▎    | 141/266 [01:24<01:26,  1.44it/s]Loading train:  53%|█████▎    | 142/266 [01:25<01:25,  1.45it/s]Loading train:  54%|█████▍    | 143/266 [01:25<01:20,  1.53it/s]Loading train:  54%|█████▍    | 144/266 [01:26<01:21,  1.51it/s]Loading train:  55%|█████▍    | 145/266 [01:26<01:20,  1.50it/s]Loading train:  55%|█████▍    | 146/266 [01:27<01:20,  1.48it/s]Loading train:  55%|█████▌    | 147/266 [01:28<01:16,  1.55it/s]Loading train:  56%|█████▌    | 148/266 [01:28<01:18,  1.51it/s]Loading train:  56%|█████▌    | 149/266 [01:29<01:16,  1.54it/s]Loading train:  56%|█████▋    | 150/266 [01:30<01:15,  1.54it/s]Loading train:  57%|█████▋    | 151/266 [01:30<01:14,  1.54it/s]Loading train:  57%|█████▋    | 152/266 [01:31<01:18,  1.46it/s]Loading train:  58%|█████▊    | 153/266 [01:32<01:19,  1.42it/s]Loading train:  58%|█████▊    | 154/266 [01:33<01:23,  1.35it/s]Loading train:  58%|█████▊    | 155/266 [01:33<01:19,  1.40it/s]Loading train:  59%|█████▊    | 156/266 [01:34<01:17,  1.42it/s]Loading train:  59%|█████▉    | 157/266 [01:35<01:17,  1.40it/s]Loading train:  59%|█████▉    | 158/266 [01:35<01:14,  1.45it/s]Loading train:  60%|█████▉    | 159/266 [01:36<01:13,  1.45it/s]Loading train:  60%|██████    | 160/266 [01:37<01:08,  1.55it/s]Loading train:  61%|██████    | 161/266 [01:37<01:11,  1.47it/s]Loading train:  61%|██████    | 162/266 [01:38<01:14,  1.40it/s]Loading train:  61%|██████▏   | 163/266 [01:39<01:17,  1.32it/s]Loading train:  62%|██████▏   | 164/266 [01:40<01:11,  1.42it/s]Loading train:  62%|██████▏   | 165/266 [01:40<01:11,  1.41it/s]Loading train:  62%|██████▏   | 166/266 [01:41<01:15,  1.32it/s]Loading train:  63%|██████▎   | 167/266 [01:42<01:10,  1.41it/s]Loading train:  63%|██████▎   | 168/266 [01:42<01:01,  1.59it/s]Loading train:  64%|██████▎   | 169/266 [01:43<01:02,  1.55it/s]Loading train:  64%|██████▍   | 170/266 [01:44<01:02,  1.54it/s]Loading train:  64%|██████▍   | 171/266 [01:44<01:00,  1.56it/s]Loading train:  65%|██████▍   | 172/266 [01:45<00:57,  1.63it/s]Loading train:  65%|██████▌   | 173/266 [01:46<01:00,  1.53it/s]Loading train:  65%|██████▌   | 174/266 [01:46<01:04,  1.42it/s]Loading train:  66%|██████▌   | 175/266 [01:47<01:06,  1.38it/s]Loading train:  66%|██████▌   | 176/266 [01:48<01:03,  1.41it/s]Loading train:  67%|██████▋   | 177/266 [01:48<01:00,  1.48it/s]Loading train:  67%|██████▋   | 178/266 [01:49<00:56,  1.55it/s]Loading train:  67%|██████▋   | 179/266 [01:50<00:54,  1.60it/s]Loading train:  68%|██████▊   | 180/266 [01:50<00:50,  1.71it/s]Loading train:  68%|██████▊   | 181/266 [01:51<00:51,  1.64it/s]Loading train:  68%|██████▊   | 182/266 [01:51<00:51,  1.64it/s]Loading train:  69%|██████▉   | 183/266 [01:52<00:54,  1.51it/s]Loading train:  69%|██████▉   | 184/266 [01:53<00:53,  1.54it/s]Loading train:  70%|██████▉   | 185/266 [01:53<00:53,  1.50it/s]Loading train:  70%|██████▉   | 186/266 [01:54<00:49,  1.60it/s]Loading train:  70%|███████   | 187/266 [01:55<00:52,  1.52it/s]Loading train:  71%|███████   | 188/266 [01:55<00:52,  1.49it/s]Loading train:  71%|███████   | 189/266 [01:56<00:50,  1.53it/s]Loading train:  71%|███████▏  | 190/266 [01:57<00:50,  1.50it/s]Loading train:  72%|███████▏  | 191/266 [01:57<00:51,  1.46it/s]Loading train:  72%|███████▏  | 192/266 [01:58<00:50,  1.46it/s]Loading train:  73%|███████▎  | 193/266 [01:59<00:49,  1.47it/s]Loading train:  73%|███████▎  | 194/266 [01:59<00:47,  1.53it/s]Loading train:  73%|███████▎  | 195/266 [02:00<00:42,  1.66it/s]Loading train:  74%|███████▎  | 196/266 [02:00<00:42,  1.65it/s]Loading train:  74%|███████▍  | 197/266 [02:01<00:43,  1.58it/s]Loading train:  74%|███████▍  | 198/266 [02:02<00:43,  1.58it/s]Loading train:  75%|███████▍  | 199/266 [02:02<00:42,  1.57it/s]Loading train:  75%|███████▌  | 200/266 [02:03<00:43,  1.52it/s]Loading train:  76%|███████▌  | 201/266 [02:04<00:42,  1.53it/s]Loading train:  76%|███████▌  | 202/266 [02:04<00:42,  1.50it/s]Loading train:  76%|███████▋  | 203/266 [02:05<00:41,  1.52it/s]Loading train:  77%|███████▋  | 204/266 [02:06<00:38,  1.60it/s]Loading train:  77%|███████▋  | 205/266 [02:06<00:40,  1.50it/s]Loading train:  77%|███████▋  | 206/266 [02:07<00:41,  1.45it/s]Loading train:  78%|███████▊  | 207/266 [02:08<00:40,  1.44it/s]Loading train:  78%|███████▊  | 208/266 [02:09<00:39,  1.47it/s]Loading train:  79%|███████▊  | 209/266 [02:09<00:38,  1.50it/s]Loading train:  79%|███████▉  | 210/266 [02:10<00:37,  1.51it/s]Loading train:  79%|███████▉  | 211/266 [02:10<00:33,  1.63it/s]Loading train:  80%|███████▉  | 212/266 [02:11<00:32,  1.66it/s]Loading train:  80%|████████  | 213/266 [02:11<00:28,  1.87it/s]Loading train:  80%|████████  | 214/266 [02:12<00:28,  1.83it/s]Loading train:  81%|████████  | 215/266 [02:13<00:30,  1.68it/s]Loading train:  81%|████████  | 216/266 [02:13<00:31,  1.58it/s]Loading train:  82%|████████▏ | 217/266 [02:14<00:29,  1.64it/s]Loading train:  82%|████████▏ | 218/266 [02:15<00:31,  1.50it/s]Loading train:  82%|████████▏ | 219/266 [02:15<00:30,  1.52it/s]Loading train:  83%|████████▎ | 220/266 [02:16<00:29,  1.54it/s]Loading train:  83%|████████▎ | 221/266 [02:16<00:28,  1.58it/s]Loading train:  83%|████████▎ | 222/266 [02:17<00:25,  1.74it/s]Loading train:  84%|████████▍ | 223/266 [02:18<00:26,  1.62it/s]Loading train:  84%|████████▍ | 224/266 [02:18<00:28,  1.50it/s]Loading train:  85%|████████▍ | 225/266 [02:19<00:28,  1.46it/s]Loading train:  85%|████████▍ | 226/266 [02:20<00:28,  1.40it/s]Loading train:  85%|████████▌ | 227/266 [02:21<00:28,  1.35it/s]Loading train:  86%|████████▌ | 228/266 [02:21<00:28,  1.35it/s]Loading train:  86%|████████▌ | 229/266 [02:22<00:26,  1.41it/s]Loading train:  86%|████████▋ | 230/266 [02:23<00:25,  1.42it/s]Loading train:  87%|████████▋ | 231/266 [02:23<00:24,  1.43it/s]Loading train:  87%|████████▋ | 232/266 [02:24<00:23,  1.43it/s]Loading train:  88%|████████▊ | 233/266 [02:25<00:22,  1.49it/s]Loading train:  88%|████████▊ | 234/266 [02:26<00:21,  1.47it/s]Loading train:  88%|████████▊ | 235/266 [02:26<00:22,  1.36it/s]Loading train:  89%|████████▊ | 236/266 [02:27<00:21,  1.42it/s]Loading train:  89%|████████▉ | 237/266 [02:28<00:19,  1.49it/s]Loading train:  89%|████████▉ | 238/266 [02:28<00:19,  1.42it/s]Loading train:  90%|████████▉ | 239/266 [02:29<00:18,  1.48it/s]Loading train:  90%|█████████ | 240/266 [02:30<00:17,  1.52it/s]Loading train:  91%|█████████ | 241/266 [02:30<00:16,  1.56it/s]Loading train:  91%|█████████ | 242/266 [02:31<00:15,  1.55it/s]Loading train:  91%|█████████▏| 243/266 [02:32<00:15,  1.49it/s]Loading train:  92%|█████████▏| 244/266 [02:32<00:14,  1.54it/s]Loading train:  92%|█████████▏| 245/266 [02:33<00:13,  1.54it/s]Loading train:  92%|█████████▏| 246/266 [02:33<00:12,  1.58it/s]Loading train:  93%|█████████▎| 247/266 [02:34<00:12,  1.50it/s]Loading train:  93%|█████████▎| 248/266 [02:35<00:11,  1.51it/s]Loading train:  94%|█████████▎| 249/266 [02:36<00:12,  1.40it/s]Loading train:  94%|█████████▍| 250/266 [02:36<00:11,  1.41it/s]Loading train:  94%|█████████▍| 251/266 [02:37<00:10,  1.42it/s]Loading train:  95%|█████████▍| 252/266 [02:38<00:09,  1.44it/s]Loading train:  95%|█████████▌| 253/266 [02:39<00:09,  1.38it/s]Loading train:  95%|█████████▌| 254/266 [02:39<00:08,  1.40it/s]Loading train:  96%|█████████▌| 255/266 [02:40<00:08,  1.37it/s]Loading train:  96%|█████████▌| 256/266 [02:41<00:07,  1.40it/s]Loading train:  97%|█████████▋| 257/266 [02:41<00:06,  1.40it/s]Loading train:  97%|█████████▋| 258/266 [02:42<00:05,  1.35it/s]Loading train:  97%|█████████▋| 259/266 [02:43<00:05,  1.34it/s]Loading train:  98%|█████████▊| 260/266 [02:44<00:04,  1.37it/s]Loading train:  98%|█████████▊| 261/266 [02:44<00:03,  1.34it/s]Loading train:  98%|█████████▊| 262/266 [02:45<00:03,  1.30it/s]Loading train:  99%|█████████▉| 263/266 [02:46<00:02,  1.31it/s]Loading train:  99%|█████████▉| 264/266 [02:47<00:01,  1.27it/s]Loading train: 100%|█████████▉| 265/266 [02:48<00:00,  1.32it/s]Loading train: 100%|██████████| 266/266 [02:48<00:00,  1.35it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   1%|          | 2/266 [00:00<00:16, 15.86it/s]concatenating: train:   2%|▏         | 5/266 [00:00<00:14, 17.68it/s]concatenating: train:   3%|▎         | 8/266 [00:00<00:13, 19.53it/s]concatenating: train:   4%|▍         | 11/266 [00:00<00:11, 21.62it/s]concatenating: train:   5%|▌         | 14/266 [00:00<00:10, 23.12it/s]concatenating: train:   7%|▋         | 18/266 [00:00<00:09, 25.31it/s]concatenating: train:   8%|▊         | 21/266 [00:00<00:10, 22.31it/s]concatenating: train:   9%|▉         | 24/266 [00:01<00:11, 21.27it/s]concatenating: train:  10%|█         | 27/266 [00:01<00:10, 23.30it/s]concatenating: train:  12%|█▏        | 32/266 [00:01<00:08, 27.73it/s]concatenating: train:  24%|██▍       | 64/266 [00:01<00:05, 38.19it/s]concatenating: train:  36%|███▌      | 96/266 [00:01<00:03, 51.85it/s]concatenating: train:  48%|████▊     | 128/266 [00:01<00:01, 69.09it/s]concatenating: train:  63%|██████▎   | 167/266 [00:01<00:01, 91.64it/s]concatenating: train:  81%|████████  | 215/266 [00:01<00:00, 120.81it/s]concatenating: train: 100%|██████████| 266/266 [00:01<00:00, 144.76it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:00<00:02,  1.34it/s]Loading test:  40%|████      | 2/5 [00:01<00:02,  1.44it/s]Loading test:  60%|██████    | 3/5 [00:01<00:01,  1.57it/s]Loading test:  80%|████████  | 4/5 [00:02<00:00,  1.72it/s]Loading test: 100%|██████████| 5/5 [00:02<00:00,  1.67it/s]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation:  40%|████      | 2/5 [00:00<00:00, 12.94it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 13.80it/s]2019-08-17 19:01:40.684448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-08-17 19:01:40.684550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-17 19:01:40.684567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-08-17 19:01:40.684576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-08-17 19:01:40.685006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:89:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.54it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.57it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  6.25it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  8.04it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:03,  8.88it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  7.72it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02,  9.81it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02, 10.08it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:01<00:02,  8.28it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:01, 10.19it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01, 10.35it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  8.84it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:02,  6.45it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  7.71it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  7.63it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:03<00:01,  5.40it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:04<00:00,  5.69it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  4.57it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.60it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 7  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 7  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 76, 108, 1)   0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 76, 108, 30)  300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 76, 108, 30)  120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 76, 108, 30)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 76, 108, 30)  8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 76, 108, 30)  120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 76, 108, 30)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 38, 54, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 38, 54, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 38, 54, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 38, 54, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 38, 54, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 38, 54, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 38, 54, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 38, 54, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 54, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 19, 27, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 19, 27, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 19, 27, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 19, 27, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 19, 27, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 19, 27, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 19, 27, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 19, 27, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 19, 27, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 19, 27, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 38, 54, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 38, 54, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 38, 54, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 38, 54, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 54, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 38, 54, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 38, 54, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 38, 54, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 38, 54, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 38, 54, 210)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 76, 108, 30)  25230       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 76, 108, 60)  0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 76, 108, 30)  16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 76, 108, 30)  120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 76, 108, 30)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 76, 108, 30)  8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 76, 108, 30)  120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 76, 108, 30)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 76, 108, 90)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 76, 108, 90)  0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 76, 108, 2)   182         dropout_5[0][0]                  
==================================================================================================
Total params: 500,342
Trainable params: 59,402
Non-trainable params: 440,940
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97453182 0.02546818]
Train on 27987 samples, validate on 500 samples
Epoch 1/300
 - 55s - loss: 0.2609 - acc: 0.9596 - mDice: 0.6804 - val_loss: 0.0842 - val_acc: 0.9930 - val_mDice: 0.8567

Epoch 00001: val_mDice improved from -inf to 0.85674, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 52s - loss: 0.0935 - acc: 0.9886 - mDice: 0.8420 - val_loss: 0.0711 - val_acc: 0.9940 - val_mDice: 0.8789

Epoch 00002: val_mDice improved from 0.85674 to 0.87889, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 51s - loss: 0.0812 - acc: 0.9900 - mDice: 0.8627 - val_loss: 0.0711 - val_acc: 0.9936 - val_mDice: 0.8788

Epoch 00003: val_mDice did not improve from 0.87889
Epoch 4/300
 - 50s - loss: 0.0753 - acc: 0.9908 - mDice: 0.8729 - val_loss: 0.0772 - val_acc: 0.9943 - val_mDice: 0.8682

Epoch 00004: val_mDice did not improve from 0.87889
Epoch 5/300
 - 52s - loss: 0.0709 - acc: 0.9915 - mDice: 0.8806 - val_loss: 0.0908 - val_acc: 0.9941 - val_mDice: 0.8450

Epoch 00005: val_mDice did not improve from 0.87889
Epoch 6/300
 - 52s - loss: 0.0643 - acc: 0.9929 - mDice: 0.8850 - val_loss: 0.0639 - val_acc: 0.9944 - val_mDice: 0.8835

Epoch 00006: val_mDice improved from 0.87889 to 0.88349, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 52s - loss: 0.0603 - acc: 0.9935 - mDice: 0.8897 - val_loss: 0.0637 - val_acc: 0.9941 - val_mDice: 0.8834

Epoch 00007: val_mDice did not improve from 0.88349
Epoch 8/300
 - 53s - loss: 0.0587 - acc: 0.9937 - mDice: 0.8923 - val_loss: 0.0679 - val_acc: 0.9943 - val_mDice: 0.8767

Epoch 00008: val_mDice did not improve from 0.88349
Epoch 9/300
 - 53s - loss: 0.0568 - acc: 0.9938 - mDice: 0.8956 - val_loss: 0.0642 - val_acc: 0.9941 - val_mDice: 0.8828

Epoch 00009: val_mDice did not improve from 0.88349
Epoch 10/300
 - 53s - loss: 0.0551 - acc: 0.9940 - mDice: 0.8985 - val_loss: 0.0630 - val_acc: 0.9945 - val_mDice: 0.8849

Epoch 00010: val_mDice improved from 0.88349 to 0.88493, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 53s - loss: 0.0535 - acc: 0.9941 - mDice: 0.9012 - val_loss: 0.0629 - val_acc: 0.9943 - val_mDice: 0.8851

Epoch 00011: val_mDice improved from 0.88493 to 0.88507, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 52s - loss: 0.0520 - acc: 0.9943 - mDice: 0.9039 - val_loss: 0.0675 - val_acc: 0.9940 - val_mDice: 0.8773

Epoch 00012: val_mDice did not improve from 0.88507
Epoch 13/300
 - 53s - loss: 0.0514 - acc: 0.9943 - mDice: 0.9051 - val_loss: 0.0609 - val_acc: 0.9944 - val_mDice: 0.8887

Epoch 00013: val_mDice improved from 0.88507 to 0.88874, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 53s - loss: 0.0500 - acc: 0.9945 - mDice: 0.9075 - val_loss: 0.0640 - val_acc: 0.9944 - val_mDice: 0.8832

Epoch 00014: val_mDice did not improve from 0.88874
Epoch 15/300
 - 53s - loss: 0.0493 - acc: 0.9945 - mDice: 0.9086 - val_loss: 0.0649 - val_acc: 0.9935 - val_mDice: 0.8816

Epoch 00015: val_mDice did not improve from 0.88874
Epoch 16/300
 - 52s - loss: 0.0485 - acc: 0.9946 - mDice: 0.9101 - val_loss: 0.0593 - val_acc: 0.9946 - val_mDice: 0.8911

Epoch 00016: val_mDice improved from 0.88874 to 0.89110, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 51s - loss: 0.0475 - acc: 0.9947 - mDice: 0.9118 - val_loss: 0.0634 - val_acc: 0.9943 - val_mDice: 0.8844

Epoch 00017: val_mDice did not improve from 0.89110
Epoch 18/300
 - 52s - loss: 0.0471 - acc: 0.9947 - mDice: 0.9126 - val_loss: 0.0610 - val_acc: 0.9941 - val_mDice: 0.8883

Epoch 00018: val_mDice did not improve from 0.89110
Epoch 19/300
 - 51s - loss: 0.0463 - acc: 0.9948 - mDice: 0.9140 - val_loss: 0.0594 - val_acc: 0.9945 - val_mDice: 0.8910

Epoch 00019: val_mDice did not improve from 0.89110
Epoch 20/300
 - 52s - loss: 0.0460 - acc: 0.9948 - mDice: 0.9146 - val_loss: 0.0624 - val_acc: 0.9942 - val_mDice: 0.8861

Epoch 00020: val_mDice did not improve from 0.89110
Epoch 21/300
 - 50s - loss: 0.0453 - acc: 0.9949 - mDice: 0.9158 - val_loss: 0.0662 - val_acc: 0.9936 - val_mDice: 0.8797

Epoch 00021: val_mDice did not improve from 0.89110
Epoch 22/300
 - 49s - loss: 0.0449 - acc: 0.9949 - mDice: 0.9165 - val_loss: 0.0629 - val_acc: 0.9939 - val_mDice: 0.8853

Epoch 00022: val_mDice did not improve from 0.89110
Epoch 23/300
 - 48s - loss: 0.0445 - acc: 0.9950 - mDice: 0.9173 - val_loss: 0.0626 - val_acc: 0.9942 - val_mDice: 0.8858

Epoch 00023: val_mDice did not improve from 0.89110
Epoch 24/300
 - 48s - loss: 0.0441 - acc: 0.9950 - mDice: 0.9179 - val_loss: 0.0617 - val_acc: 0.9938 - val_mDice: 0.8872

Epoch 00024: val_mDice did not improve from 0.89110
Epoch 25/300
 - 48s - loss: 0.0435 - acc: 0.9950 - mDice: 0.9189 - val_loss: 0.0628 - val_acc: 0.9940 - val_mDice: 0.8855

Epoch 00025: val_mDice did not improve from 0.89110
Epoch 26/300
 - 47s - loss: 0.0432 - acc: 0.9951 - mDice: 0.9196 - val_loss: 0.0665 - val_acc: 0.9941 - val_mDice: 0.8791

Epoch 00026: val_mDice did not improve from 0.89110
Epoch 27/300
 - 48s - loss: 0.0429 - acc: 0.9951 - mDice: 0.9201 - val_loss: 0.0623 - val_acc: 0.9945 - val_mDice: 0.8862

Epoch 00027: val_mDice did not improve from 0.89110
Epoch 28/300
 - 48s - loss: 0.0427 - acc: 0.9951 - mDice: 0.9205 - val_loss: 0.0639 - val_acc: 0.9937 - val_mDice: 0.8836

Epoch 00028: val_mDice did not improve from 0.89110
Epoch 29/300
 - 49s - loss: 0.0423 - acc: 0.9952 - mDice: 0.9211 - val_loss: 0.0634 - val_acc: 0.9938 - val_mDice: 0.8847

Epoch 00029: val_mDice did not improve from 0.89110
Epoch 30/300
 - 48s - loss: 0.0420 - acc: 0.9952 - mDice: 0.9216 - val_loss: 0.0650 - val_acc: 0.9943 - val_mDice: 0.8816

Epoch 00030: val_mDice did not improve from 0.89110
Epoch 31/300
 - 47s - loss: 0.0419 - acc: 0.9952 - mDice: 0.9219 - val_loss: 0.0670 - val_acc: 0.9944 - val_mDice: 0.8782

Epoch 00031: val_mDice did not improve from 0.89110
Epoch 32/300
 - 47s - loss: 0.0415 - acc: 0.9952 - mDice: 0.9225 - val_loss: 0.0641 - val_acc: 0.9942 - val_mDice: 0.8832

Epoch 00032: val_mDice did not improve from 0.89110
Epoch 33/300
 - 47s - loss: 0.0414 - acc: 0.9953 - mDice: 0.9228 - val_loss: 0.0613 - val_acc: 0.9943 - val_mDice: 0.8881

Epoch 00033: val_mDice did not improve from 0.89110
Epoch 34/300
 - 47s - loss: 0.0412 - acc: 0.9953 - mDice: 0.9231 - val_loss: 0.0631 - val_acc: 0.9938 - val_mDice: 0.8849

Epoch 00034: val_mDice did not improve from 0.89110
Epoch 35/300
 - 47s - loss: 0.0408 - acc: 0.9953 - mDice: 0.9239 - val_loss: 0.0625 - val_acc: 0.9940 - val_mDice: 0.8860

Epoch 00035: val_mDice did not improve from 0.89110
Epoch 36/300
 - 47s - loss: 0.0407 - acc: 0.9953 - mDice: 0.9240 - val_loss: 0.0617 - val_acc: 0.9940 - val_mDice: 0.8874

Epoch 00036: val_mDice did not improve from 0.89110
Epoch 37/300
 - 47s - loss: 0.0406 - acc: 0.9953 - mDice: 0.9242 - val_loss: 0.0644 - val_acc: 0.9938 - val_mDice: 0.8828

Epoch 00037: val_mDice did not improve from 0.89110
Epoch 38/300
 - 47s - loss: 0.0405 - acc: 0.9953 - mDice: 0.9244 - val_loss: 0.0653 - val_acc: 0.9934 - val_mDice: 0.8811

Epoch 00038: val_mDice did not improve from 0.89110
Epoch 39/300
 - 47s - loss: 0.0401 - acc: 0.9954 - mDice: 0.9251 - val_loss: 0.0617 - val_acc: 0.9942 - val_mDice: 0.8874

Epoch 00039: val_mDice did not improve from 0.89110
Epoch 40/300
 - 47s - loss: 0.0400 - acc: 0.9954 - mDice: 0.9253 - val_loss: 0.0637 - val_acc: 0.9944 - val_mDice: 0.8838

Epoch 00040: val_mDice did not improve from 0.89110
Epoch 41/300
 - 47s - loss: 0.0401 - acc: 0.9954 - mDice: 0.9252 - val_loss: 0.0651 - val_acc: 0.9935 - val_mDice: 0.8818

Epoch 00041: val_mDice did not improve from 0.89110
Epoch 42/300
 - 47s - loss: 0.0397 - acc: 0.9954 - mDice: 0.9258 - val_loss: 0.0624 - val_acc: 0.9942 - val_mDice: 0.8863

Epoch 00042: val_mDice did not improve from 0.89110
Epoch 43/300
 - 48s - loss: 0.0396 - acc: 0.9954 - mDice: 0.9261 - val_loss: 0.0633 - val_acc: 0.9938 - val_mDice: 0.8847

Epoch 00043: val_mDice did not improve from 0.89110
Epoch 44/300
 - 47s - loss: 0.0395 - acc: 0.9954 - mDice: 0.9261 - val_loss: 0.0614 - val_acc: 0.9942 - val_mDice: 0.8879

Epoch 00044: val_mDice did not improve from 0.89110
Epoch 45/300
 - 47s - loss: 0.0393 - acc: 0.9954 - mDice: 0.9265 - val_loss: 0.0629 - val_acc: 0.9945 - val_mDice: 0.8854

Epoch 00045: val_mDice did not improve from 0.89110
Epoch 46/300
 - 47s - loss: 0.0391 - acc: 0.9955 - mDice: 0.9269 - val_loss: 0.0651 - val_acc: 0.9939 - val_mDice: 0.8818

Epoch 00046: val_mDice did not improve from 0.89110
Epoch 47/300
 - 48s - loss: 0.0388 - acc: 0.9955 - mDice: 0.9275 - val_loss: 0.0627 - val_acc: 0.9943 - val_mDice: 0.8857

Epoch 00047: val_mDice did not improve from 0.89110
Epoch 48/300
 - 48s - loss: 0.0391 - acc: 0.9955 - mDice: 0.9270 - val_loss: 0.0646 - val_acc: 0.9938 - val_mDice: 0.8826

Epoch 00048: val_mDice did not improve from 0.89110
Epoch 49/300
 - 48s - loss: 0.0388 - acc: 0.9955 - mDice: 0.9274 - val_loss: 0.0627 - val_acc: 0.9944 - val_mDice: 0.8856

Epoch 00049: val_mDice did not improve from 0.89110
Epoch 50/300
 - 48s - loss: 0.0386 - acc: 0.9955 - mDice: 0.9278 - val_loss: 0.0636 - val_acc: 0.9941 - val_mDice: 0.8842

Epoch 00050: val_mDice did not improve from 0.89110
Epoch 51/300
 - 48s - loss: 0.0385 - acc: 0.9955 - mDice: 0.9281 - val_loss: 0.0680 - val_acc: 0.9929 - val_mDice: 0.8768

Epoch 00051: val_mDice did not improve from 0.89110
Epoch 52/300
 - 48s - loss: 0.0383 - acc: 0.9955 - mDice: 0.9284 - val_loss: 0.0685 - val_acc: 0.9932 - val_mDice: 0.8761

Epoch 00052: val_mDice did not improve from 0.89110
Epoch 53/300
 - 48s - loss: 0.0382 - acc: 0.9955 - mDice: 0.9285 - val_loss: 0.0638 - val_acc: 0.9941 - val_mDice: 0.8836

Epoch 00053: val_mDice did not improve from 0.89110
Epoch 54/300
 - 47s - loss: 0.0381 - acc: 0.9955 - mDice: 0.9287 - val_loss: 0.0626 - val_acc: 0.9939 - val_mDice: 0.8860

Epoch 00054: val_mDice did not improve from 0.89110
Epoch 55/300
 - 48s - loss: 0.0381 - acc: 0.9956 - mDice: 0.9287 - val_loss: 0.0624 - val_acc: 0.9942 - val_mDice: 0.8861

Epoch 00055: val_mDice did not improve from 0.89110
Epoch 56/300
 - 48s - loss: 0.0378 - acc: 0.9956 - mDice: 0.9292 - val_loss: 0.0645 - val_acc: 0.9937 - val_mDice: 0.8827

predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:00<00:03,  1.02it/s]predicting test subjects:  40%|████      | 2/5 [00:01<00:02,  1.29it/s]predicting test subjects:  60%|██████    | 3/5 [00:01<00:01,  1.56it/s]predicting test subjects:  80%|████████  | 4/5 [00:02<00:00,  1.72it/s]predicting test subjects: 100%|██████████| 5/5 [00:02<00:00,  1.93it/s]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:00<01:53,  2.34it/s]predicting train subjects:   1%|          | 2/266 [00:00<01:52,  2.34it/s]predicting train subjects:   1%|          | 3/266 [00:01<01:44,  2.51it/s]predicting train subjects:   2%|▏         | 4/266 [00:01<01:40,  2.61it/s]predicting train subjects:   2%|▏         | 5/266 [00:01<01:42,  2.55it/s]predicting train subjects:   2%|▏         | 6/266 [00:02<01:49,  2.37it/s]predicting train subjects:   3%|▎         | 7/266 [00:02<01:46,  2.43it/s]predicting train subjects:   3%|▎         | 8/266 [00:03<01:42,  2.53it/s]predicting train subjects:   3%|▎         | 9/266 [00:03<01:38,  2.61it/s]predicting train subjects:   4%|▍         | 10/266 [00:03<01:35,  2.67it/s]predicting train subjects:   4%|▍         | 11/266 [00:04<01:36,  2.65it/s]predicting train subjects:   5%|▍         | 12/266 [00:04<01:40,  2.53it/s]predicting train subjects:   5%|▍         | 13/266 [00:05<01:39,  2.55it/s]predicting train subjects:   5%|▌         | 14/266 [00:05<01:40,  2.52it/s]predicting train subjects:   6%|▌         | 15/266 [00:05<01:37,  2.56it/s]predicting train subjects:   6%|▌         | 16/266 [00:06<01:35,  2.62it/s]predicting train subjects:   6%|▋         | 17/266 [00:06<01:37,  2.55it/s]predicting train subjects:   7%|▋         | 18/266 [00:07<01:38,  2.52it/s]predicting train subjects:   7%|▋         | 19/266 [00:07<01:34,  2.61it/s]predicting train subjects:   8%|▊         | 20/266 [00:07<01:32,  2.67it/s]predicting train subjects:   8%|▊         | 21/266 [00:08<01:34,  2.58it/s]predicting train subjects:   8%|▊         | 22/266 [00:08<01:32,  2.63it/s]predicting train subjects:   9%|▊         | 23/266 [00:08<01:31,  2.64it/s]predicting train subjects:   9%|▉         | 24/266 [00:09<01:40,  2.41it/s]predicting train subjects:   9%|▉         | 25/266 [00:09<01:38,  2.44it/s]predicting train subjects:  10%|▉         | 26/266 [00:10<01:33,  2.56it/s]predicting train subjects:  10%|█         | 27/266 [00:10<01:29,  2.68it/s]predicting train subjects:  11%|█         | 28/266 [00:10<01:26,  2.74it/s]predicting train subjects:  11%|█         | 29/266 [00:11<01:27,  2.71it/s]predicting train subjects:  11%|█▏        | 30/266 [00:11<01:30,  2.61it/s]predicting train subjects:  12%|█▏        | 31/266 [00:11<01:27,  2.68it/s]predicting train subjects:  12%|█▏        | 32/266 [00:12<01:23,  2.79it/s]predicting train subjects:  12%|█▏        | 33/266 [00:12<01:22,  2.83it/s]predicting train subjects:  13%|█▎        | 34/266 [00:13<01:21,  2.83it/s]predicting train subjects:  13%|█▎        | 35/266 [00:13<01:20,  2.88it/s]predicting train subjects:  14%|█▎        | 36/266 [00:13<01:21,  2.81it/s]predicting train subjects:  14%|█▍        | 37/266 [00:14<01:31,  2.50it/s]predicting train subjects:  14%|█▍        | 38/266 [00:14<01:28,  2.59it/s]predicting train subjects:  15%|█▍        | 39/266 [00:14<01:26,  2.62it/s]predicting train subjects:  15%|█▌        | 40/266 [00:15<01:26,  2.62it/s]predicting train subjects:  15%|█▌        | 41/266 [00:15<01:23,  2.71it/s]predicting train subjects:  16%|█▌        | 42/266 [00:16<01:20,  2.79it/s]predicting train subjects:  16%|█▌        | 43/266 [00:16<01:18,  2.83it/s]predicting train subjects:  17%|█▋        | 44/266 [00:16<01:15,  2.94it/s]predicting train subjects:  17%|█▋        | 45/266 [00:16<01:11,  3.10it/s]predicting train subjects:  17%|█▋        | 46/266 [00:17<01:10,  3.12it/s]predicting train subjects:  18%|█▊        | 47/266 [00:17<01:10,  3.11it/s]predicting train subjects:  18%|█▊        | 48/266 [00:17<01:07,  3.23it/s]predicting train subjects:  18%|█▊        | 49/266 [00:18<01:05,  3.32it/s]predicting train subjects:  19%|█▉        | 50/266 [00:18<01:04,  3.34it/s]predicting train subjects:  19%|█▉        | 51/266 [00:18<01:06,  3.22it/s]predicting train subjects:  20%|█▉        | 52/266 [00:19<01:05,  3.26it/s]predicting train subjects:  20%|█▉        | 53/266 [00:19<01:03,  3.34it/s]predicting train subjects:  20%|██        | 54/266 [00:19<01:03,  3.36it/s]predicting train subjects:  21%|██        | 55/266 [00:19<01:03,  3.34it/s]predicting train subjects:  21%|██        | 56/266 [00:20<01:02,  3.35it/s]predicting train subjects:  21%|██▏       | 57/266 [00:20<01:01,  3.42it/s]predicting train subjects:  22%|██▏       | 58/266 [00:20<01:00,  3.43it/s]predicting train subjects:  22%|██▏       | 59/266 [00:21<01:03,  3.29it/s]predicting train subjects:  23%|██▎       | 60/266 [00:21<01:05,  3.13it/s]predicting train subjects:  23%|██▎       | 61/266 [00:21<01:02,  3.29it/s]predicting train subjects:  23%|██▎       | 62/266 [00:22<00:59,  3.41it/s]predicting train subjects:  24%|██▎       | 63/266 [00:22<01:00,  3.36it/s]predicting train subjects:  24%|██▍       | 64/266 [00:22<00:58,  3.43it/s]predicting train subjects:  24%|██▍       | 65/266 [00:22<01:00,  3.31it/s]predicting train subjects:  25%|██▍       | 66/266 [00:23<01:03,  3.16it/s]predicting train subjects:  25%|██▌       | 67/266 [00:23<01:02,  3.16it/s]predicting train subjects:  26%|██▌       | 68/266 [00:23<01:01,  3.22it/s]predicting train subjects:  26%|██▌       | 69/266 [00:24<01:05,  3.02it/s]predicting train subjects:  26%|██▋       | 70/266 [00:24<01:01,  3.21it/s]predicting train subjects:  27%|██▋       | 71/266 [00:24<00:59,  3.26it/s]predicting train subjects:  27%|██▋       | 72/266 [00:25<00:57,  3.39it/s]predicting train subjects:  27%|██▋       | 73/266 [00:25<00:55,  3.49it/s]predicting train subjects:  28%|██▊       | 74/266 [00:25<00:53,  3.56it/s]predicting train subjects:  28%|██▊       | 75/266 [00:25<00:56,  3.40it/s]predicting train subjects:  29%|██▊       | 76/266 [00:26<00:56,  3.35it/s]predicting train subjects:  29%|██▉       | 77/266 [00:26<00:57,  3.27it/s]predicting train subjects:  29%|██▉       | 78/266 [00:27<01:05,  2.89it/s]predicting train subjects:  30%|██▉       | 79/266 [00:27<01:05,  2.86it/s]predicting train subjects:  30%|███       | 80/266 [00:27<01:05,  2.84it/s]predicting train subjects:  30%|███       | 81/266 [00:28<01:14,  2.50it/s]predicting train subjects:  31%|███       | 82/266 [00:28<01:13,  2.49it/s]predicting train subjects:  31%|███       | 83/266 [00:29<01:11,  2.56it/s]predicting train subjects:  32%|███▏      | 84/266 [00:29<01:08,  2.66it/s]predicting train subjects:  32%|███▏      | 85/266 [00:29<01:13,  2.46it/s]predicting train subjects:  32%|███▏      | 86/266 [00:30<01:10,  2.56it/s]predicting train subjects:  33%|███▎      | 87/266 [00:30<01:09,  2.56it/s]predicting train subjects:  33%|███▎      | 88/266 [00:30<01:07,  2.63it/s]predicting train subjects:  33%|███▎      | 89/266 [00:31<01:06,  2.65it/s]predicting train subjects:  34%|███▍      | 90/266 [00:31<01:05,  2.69it/s]predicting train subjects:  34%|███▍      | 91/266 [00:32<01:04,  2.73it/s]predicting train subjects:  35%|███▍      | 92/266 [00:32<01:04,  2.70it/s]predicting train subjects:  35%|███▍      | 93/266 [00:32<01:06,  2.59it/s]predicting train subjects:  35%|███▌      | 94/266 [00:33<01:05,  2.61it/s]predicting train subjects:  36%|███▌      | 95/266 [00:33<01:03,  2.70it/s]predicting train subjects:  36%|███▌      | 96/266 [00:33<01:01,  2.75it/s]predicting train subjects:  36%|███▋      | 97/266 [00:34<01:06,  2.54it/s]predicting train subjects:  37%|███▋      | 98/266 [00:34<01:07,  2.50it/s]predicting train subjects:  37%|███▋      | 99/266 [00:35<01:03,  2.64it/s]predicting train subjects:  38%|███▊      | 100/266 [00:35<01:04,  2.58it/s]predicting train subjects:  38%|███▊      | 101/266 [00:35<00:59,  2.77it/s]predicting train subjects:  38%|███▊      | 102/266 [00:36<00:56,  2.93it/s]predicting train subjects:  39%|███▊      | 103/266 [00:36<00:54,  3.01it/s]predicting train subjects:  39%|███▉      | 104/266 [00:36<00:53,  3.00it/s]predicting train subjects:  39%|███▉      | 105/266 [00:37<00:52,  3.09it/s]predicting train subjects:  40%|███▉      | 106/266 [00:37<00:51,  3.11it/s]predicting train subjects:  40%|████      | 107/266 [00:37<00:51,  3.11it/s]predicting train subjects:  41%|████      | 108/266 [00:38<00:49,  3.19it/s]predicting train subjects:  41%|████      | 109/266 [00:38<00:51,  3.05it/s]predicting train subjects:  41%|████▏     | 110/266 [00:38<00:49,  3.13it/s]predicting train subjects:  42%|████▏     | 111/266 [00:38<00:49,  3.10it/s]predicting train subjects:  42%|████▏     | 112/266 [00:39<00:49,  3.09it/s]predicting train subjects:  42%|████▏     | 113/266 [00:39<00:48,  3.17it/s]predicting train subjects:  43%|████▎     | 114/266 [00:39<00:48,  3.10it/s]predicting train subjects:  43%|████▎     | 115/266 [00:40<00:49,  3.05it/s]predicting train subjects:  44%|████▎     | 116/266 [00:40<00:49,  3.00it/s]predicting train subjects:  44%|████▍     | 117/266 [00:41<00:51,  2.91it/s]predicting train subjects:  44%|████▍     | 118/266 [00:41<00:49,  2.97it/s]predicting train subjects:  45%|████▍     | 119/266 [00:41<00:51,  2.84it/s]predicting train subjects:  45%|████▌     | 120/266 [00:42<00:53,  2.73it/s]predicting train subjects:  45%|████▌     | 121/266 [00:42<00:53,  2.69it/s]predicting train subjects:  46%|████▌     | 122/266 [00:42<00:53,  2.71it/s]predicting train subjects:  46%|████▌     | 123/266 [00:43<00:53,  2.67it/s]predicting train subjects:  47%|████▋     | 124/266 [00:43<00:58,  2.41it/s]predicting train subjects:  47%|████▋     | 125/266 [00:44<00:57,  2.46it/s]predicting train subjects:  47%|████▋     | 126/266 [00:44<00:55,  2.54it/s]predicting train subjects:  48%|████▊     | 127/266 [00:44<00:54,  2.57it/s]predicting train subjects:  48%|████▊     | 128/266 [00:45<00:52,  2.63it/s]predicting train subjects:  48%|████▊     | 129/266 [00:45<00:51,  2.66it/s]predicting train subjects:  49%|████▉     | 130/266 [00:45<00:50,  2.72it/s]predicting train subjects:  49%|████▉     | 131/266 [00:46<00:51,  2.62it/s]predicting train subjects:  50%|████▉     | 132/266 [00:46<00:49,  2.69it/s]predicting train subjects:  50%|█████     | 133/266 [00:47<00:48,  2.74it/s]predicting train subjects:  50%|█████     | 134/266 [00:47<00:47,  2.80it/s]predicting train subjects:  51%|█████     | 135/266 [00:47<00:47,  2.76it/s]predicting train subjects:  51%|█████     | 136/266 [00:48<00:46,  2.79it/s]predicting train subjects:  52%|█████▏    | 137/266 [00:48<00:44,  2.87it/s]predicting train subjects:  52%|█████▏    | 138/266 [00:48<00:44,  2.86it/s]predicting train subjects:  52%|█████▏    | 139/266 [00:49<00:45,  2.80it/s]predicting train subjects:  53%|█████▎    | 140/266 [00:49<00:44,  2.82it/s]predicting train subjects:  53%|█████▎    | 141/266 [00:49<00:44,  2.78it/s]predicting train subjects:  53%|█████▎    | 142/266 [00:50<00:44,  2.80it/s]predicting train subjects:  54%|█████▍    | 143/266 [00:50<00:45,  2.70it/s]predicting train subjects:  54%|█████▍    | 144/266 [00:51<00:44,  2.75it/s]predicting train subjects:  55%|█████▍    | 145/266 [00:51<00:44,  2.74it/s]predicting train subjects:  55%|█████▍    | 146/266 [00:51<00:44,  2.69it/s]predicting train subjects:  55%|█████▌    | 147/266 [00:52<00:44,  2.70it/s]predicting train subjects:  56%|█████▌    | 148/266 [00:52<00:42,  2.77it/s]predicting train subjects:  56%|█████▌    | 149/266 [00:52<00:41,  2.82it/s]predicting train subjects:  56%|█████▋    | 150/266 [00:53<00:41,  2.81it/s]predicting train subjects:  57%|█████▋    | 151/266 [00:53<00:41,  2.79it/s]predicting train subjects:  57%|█████▋    | 152/266 [00:53<00:41,  2.76it/s]predicting train subjects:  58%|█████▊    | 153/266 [00:54<00:40,  2.79it/s]predicting train subjects:  58%|█████▊    | 154/266 [00:54<00:42,  2.61it/s]predicting train subjects:  58%|█████▊    | 155/266 [00:54<00:38,  2.87it/s]predicting train subjects:  59%|█████▊    | 156/266 [00:55<00:35,  3.14it/s]predicting train subjects:  59%|█████▉    | 157/266 [00:55<00:32,  3.37it/s]predicting train subjects:  59%|█████▉    | 158/266 [00:55<00:30,  3.53it/s]predicting train subjects:  60%|█████▉    | 159/266 [00:55<00:29,  3.59it/s]predicting train subjects:  60%|██████    | 160/266 [00:56<00:28,  3.69it/s]predicting train subjects:  61%|██████    | 161/266 [00:56<00:27,  3.77it/s]predicting train subjects:  61%|██████    | 162/266 [00:56<00:27,  3.77it/s]predicting train subjects:  61%|██████▏   | 163/266 [00:57<00:29,  3.47it/s]predicting train subjects:  62%|██████▏   | 164/266 [00:57<00:31,  3.20it/s]predicting train subjects:  62%|██████▏   | 165/266 [00:57<00:30,  3.36it/s]predicting train subjects:  62%|██████▏   | 166/266 [00:57<00:28,  3.55it/s]predicting train subjects:  63%|██████▎   | 167/266 [00:58<00:26,  3.71it/s]predicting train subjects:  63%|██████▎   | 168/266 [00:58<00:27,  3.60it/s]predicting train subjects:  64%|██████▎   | 169/266 [00:58<00:27,  3.52it/s]predicting train subjects:  64%|██████▍   | 170/266 [00:59<00:27,  3.49it/s]predicting train subjects:  64%|██████▍   | 171/266 [00:59<00:26,  3.57it/s]predicting train subjects:  65%|██████▍   | 172/266 [00:59<00:26,  3.53it/s]predicting train subjects:  65%|██████▌   | 173/266 [01:00<00:28,  3.24it/s]predicting train subjects:  65%|██████▌   | 174/266 [01:00<00:27,  3.30it/s]predicting train subjects:  66%|██████▌   | 175/266 [01:00<00:26,  3.37it/s]predicting train subjects:  66%|██████▌   | 176/266 [01:00<00:26,  3.41it/s]predicting train subjects:  67%|██████▋   | 177/266 [01:01<00:27,  3.26it/s]predicting train subjects:  67%|██████▋   | 178/266 [01:01<00:26,  3.26it/s]predicting train subjects:  67%|██████▋   | 179/266 [01:01<00:27,  3.20it/s]predicting train subjects:  68%|██████▊   | 180/266 [01:02<00:26,  3.30it/s]predicting train subjects:  68%|██████▊   | 181/266 [01:02<00:25,  3.28it/s]predicting train subjects:  68%|██████▊   | 182/266 [01:02<00:27,  3.03it/s]predicting train subjects:  69%|██████▉   | 183/266 [01:03<00:26,  3.13it/s]predicting train subjects:  69%|██████▉   | 184/266 [01:03<00:25,  3.17it/s]predicting train subjects:  70%|██████▉   | 185/266 [01:03<00:26,  3.10it/s]predicting train subjects:  70%|██████▉   | 186/266 [01:04<00:24,  3.23it/s]predicting train subjects:  70%|███████   | 187/266 [01:04<00:23,  3.30it/s]predicting train subjects:  71%|███████   | 188/266 [01:04<00:24,  3.21it/s]predicting train subjects:  71%|███████   | 189/266 [01:05<00:24,  3.10it/s]predicting train subjects:  71%|███████▏  | 190/266 [01:05<00:26,  2.85it/s]predicting train subjects:  72%|███████▏  | 191/266 [01:05<00:25,  2.91it/s]predicting train subjects:  72%|███████▏  | 192/266 [01:06<00:25,  2.91it/s]predicting train subjects:  73%|███████▎  | 193/266 [01:06<00:23,  3.10it/s]predicting train subjects:  73%|███████▎  | 194/266 [01:06<00:25,  2.83it/s]predicting train subjects:  73%|███████▎  | 195/266 [01:07<00:24,  2.88it/s]predicting train subjects:  74%|███████▎  | 196/266 [01:07<00:22,  3.05it/s]predicting train subjects:  74%|███████▍  | 197/266 [01:07<00:21,  3.15it/s]predicting train subjects:  74%|███████▍  | 198/266 [01:08<00:24,  2.79it/s]predicting train subjects:  75%|███████▍  | 199/266 [01:08<00:22,  2.98it/s]predicting train subjects:  75%|███████▌  | 200/266 [01:08<00:21,  3.02it/s]predicting train subjects:  76%|███████▌  | 201/266 [01:09<00:21,  2.99it/s]predicting train subjects:  76%|███████▌  | 202/266 [01:09<00:20,  3.11it/s]predicting train subjects:  76%|███████▋  | 203/266 [01:09<00:19,  3.23it/s]predicting train subjects:  77%|███████▋  | 204/266 [01:10<00:19,  3.14it/s]predicting train subjects:  77%|███████▋  | 205/266 [01:10<00:20,  3.01it/s]predicting train subjects:  77%|███████▋  | 206/266 [01:10<00:22,  2.68it/s]predicting train subjects:  78%|███████▊  | 207/266 [01:11<00:21,  2.77it/s]predicting train subjects:  78%|███████▊  | 208/266 [01:11<00:19,  2.94it/s]predicting train subjects:  79%|███████▊  | 209/266 [01:11<00:18,  3.03it/s]predicting train subjects:  79%|███████▉  | 210/266 [01:12<00:18,  3.03it/s]predicting train subjects:  79%|███████▉  | 211/266 [01:12<00:17,  3.09it/s]predicting train subjects:  80%|███████▉  | 212/266 [01:12<00:16,  3.22it/s]predicting train subjects:  80%|████████  | 213/266 [01:12<00:15,  3.37it/s]predicting train subjects:  80%|████████  | 214/266 [01:13<00:16,  3.12it/s]predicting train subjects:  81%|████████  | 215/266 [01:13<00:16,  3.18it/s]predicting train subjects:  81%|████████  | 216/266 [01:13<00:15,  3.17it/s]predicting train subjects:  82%|████████▏ | 217/266 [01:14<00:15,  3.21it/s]predicting train subjects:  82%|████████▏ | 218/266 [01:14<00:14,  3.36it/s]predicting train subjects:  82%|████████▏ | 219/266 [01:14<00:13,  3.36it/s]predicting train subjects:  83%|████████▎ | 220/266 [01:15<00:13,  3.46it/s]predicting train subjects:  83%|████████▎ | 221/266 [01:15<00:12,  3.50it/s]predicting train subjects:  83%|████████▎ | 222/266 [01:15<00:12,  3.62it/s]predicting train subjects:  84%|████████▍ | 223/266 [01:15<00:12,  3.53it/s]predicting train subjects:  84%|████████▍ | 224/266 [01:16<00:11,  3.50it/s]predicting train subjects:  85%|████████▍ | 225/266 [01:16<00:12,  3.23it/s]predicting train subjects:  85%|████████▍ | 226/266 [01:16<00:11,  3.40it/s]predicting train subjects:  85%|████████▌ | 227/266 [01:17<00:11,  3.40it/s]predicting train subjects:  86%|████████▌ | 228/266 [01:17<00:11,  3.34it/s]predicting train subjects:  86%|████████▌ | 229/266 [01:17<00:10,  3.37it/s]predicting train subjects:  86%|████████▋ | 230/266 [01:18<00:10,  3.47it/s]predicting train subjects:  87%|████████▋ | 231/266 [01:18<00:10,  3.38it/s]predicting train subjects:  87%|████████▋ | 232/266 [01:18<00:10,  3.20it/s]predicting train subjects:  88%|████████▊ | 233/266 [01:19<00:10,  3.06it/s]predicting train subjects:  88%|████████▊ | 234/266 [01:19<00:09,  3.22it/s]predicting train subjects:  88%|████████▊ | 235/266 [01:19<00:09,  3.23it/s]predicting train subjects:  89%|████████▊ | 236/266 [01:19<00:08,  3.37it/s]predicting train subjects:  89%|████████▉ | 237/266 [01:20<00:08,  3.41it/s]predicting train subjects:  89%|████████▉ | 238/266 [01:20<00:08,  3.32it/s]predicting train subjects:  90%|████████▉ | 239/266 [01:20<00:07,  3.45it/s]predicting train subjects:  90%|█████████ | 240/266 [01:21<00:07,  3.55it/s]predicting train subjects:  91%|█████████ | 241/266 [01:21<00:06,  3.60it/s]predicting train subjects:  91%|█████████ | 242/266 [01:21<00:07,  3.40it/s]predicting train subjects:  91%|█████████▏| 243/266 [01:21<00:06,  3.51it/s]predicting train subjects:  92%|█████████▏| 244/266 [01:22<00:06,  3.48it/s]predicting train subjects:  92%|█████████▏| 245/266 [01:22<00:06,  3.48it/s]predicting train subjects:  92%|█████████▏| 246/266 [01:22<00:05,  3.36it/s]predicting train subjects:  93%|█████████▎| 247/266 [01:23<00:05,  3.38it/s]predicting train subjects:  93%|█████████▎| 248/266 [01:23<00:05,  3.35it/s]predicting train subjects:  94%|█████████▎| 249/266 [01:23<00:05,  3.24it/s]predicting train subjects:  94%|█████████▍| 250/266 [01:24<00:05,  3.07it/s]predicting train subjects:  94%|█████████▍| 251/266 [01:24<00:04,  3.03it/s]predicting train subjects:  95%|█████████▍| 252/266 [01:24<00:04,  3.03it/s]predicting train subjects:  95%|█████████▌| 253/266 [01:25<00:04,  2.97it/s]predicting train subjects:  95%|█████████▌| 254/266 [01:25<00:04,  2.98it/s]predicting train subjects:  96%|█████████▌| 255/266 [01:25<00:03,  2.93it/s]predicting train subjects:  96%|█████████▌| 256/266 [01:26<00:03,  2.89it/s]predicting train subjects:  97%|█████████▋| 257/266 [01:26<00:03,  2.81it/s]predicting train subjects:  97%|█████████▋| 258/266 [01:26<00:03,  2.60it/s]predicting train subjects:  97%|█████████▋| 259/266 [01:27<00:02,  2.69it/s]predicting train subjects:  98%|█████████▊| 260/266 [01:27<00:02,  2.77it/s]predicting train subjects:  98%|█████████▊| 261/266 [01:27<00:01,  2.84it/s]predicting train subjects:  98%|█████████▊| 262/266 [01:28<00:01,  2.85it/s]predicting train subjects:  99%|█████████▉| 263/266 [01:28<00:01,  2.88it/s]predicting train subjects:  99%|█████████▉| 264/266 [01:29<00:00,  2.87it/s]predicting train subjects: 100%|█████████▉| 265/266 [01:29<00:00,  2.76it/s]predicting train subjects: 100%|██████████| 266/266 [01:29<00:00,  2.71it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 61.85it/s]
saving BB  train1-THALAMUS:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   3%|▎         | 7/266 [00:00<00:04, 62.43it/s]saving BB  train1-THALAMUS:   5%|▌         | 14/266 [00:00<00:04, 62.34it/s]saving BB  train1-THALAMUS:   8%|▊         | 21/266 [00:00<00:03, 62.66it/s]saving BB  train1-THALAMUS:  11%|█         | 28/266 [00:00<00:03, 63.95it/s]saving BB  train1-THALAMUS:  13%|█▎        | 35/266 [00:00<00:03, 65.45it/s]saving BB  train1-THALAMUS:  16%|█▌        | 42/266 [00:00<00:03, 66.29it/s]saving BB  train1-THALAMUS:  19%|█▉        | 50/266 [00:00<00:03, 68.49it/s]saving BB  train1-THALAMUS:  22%|██▏       | 58/266 [00:00<00:02, 70.56it/s]saving BB  train1-THALAMUS:  25%|██▍       | 66/266 [00:00<00:02, 71.94it/s]saving BB  train1-THALAMUS:  27%|██▋       | 73/266 [00:01<00:04, 47.32it/s]saving BB  train1-THALAMUS:  30%|███       | 80/266 [00:01<00:03, 52.39it/s]saving BB  train1-THALAMUS:  33%|███▎      | 87/266 [00:01<00:03, 56.28it/s]saving BB  train1-THALAMUS:  35%|███▌      | 94/266 [00:01<00:02, 59.12it/s]saving BB  train1-THALAMUS:  38%|███▊      | 101/266 [00:01<00:02, 60.77it/s]saving BB  train1-THALAMUS:  41%|████      | 108/266 [00:01<00:02, 59.40it/s]saving BB  train1-THALAMUS:  44%|████▎     | 116/266 [00:01<00:02, 62.87it/s]saving BB  train1-THALAMUS:  47%|████▋     | 124/266 [00:01<00:02, 65.18it/s]saving BB  train1-THALAMUS:  50%|████▉     | 132/266 [00:02<00:02, 66.82it/s]saving BB  train1-THALAMUS:  53%|█████▎    | 140/266 [00:02<00:01, 68.00it/s]saving BB  train1-THALAMUS:  56%|█████▌    | 148/266 [00:02<00:01, 69.37it/s]saving BB  train1-THALAMUS:  59%|█████▊    | 156/266 [00:02<00:01, 70.46it/s]saving BB  train1-THALAMUS:  62%|██████▏   | 165/266 [00:02<00:01, 73.53it/s]saving BB  train1-THALAMUS:  65%|██████▌   | 174/266 [00:02<00:01, 75.82it/s]saving BB  train1-THALAMUS:  69%|██████▉   | 183/266 [00:02<00:01, 77.48it/s]saving BB  train1-THALAMUS:  72%|███████▏  | 191/266 [00:02<00:00, 77.27it/s]saving BB  train1-THALAMUS:  75%|███████▍  | 199/266 [00:02<00:00, 75.42it/s]saving BB  train1-THALAMUS:  78%|███████▊  | 207/266 [00:03<00:00, 74.69it/s]saving BB  train1-THALAMUS:  81%|████████  | 215/266 [00:03<00:00, 75.01it/s]saving BB  train1-THALAMUS:  84%|████████▍ | 223/266 [00:03<00:00, 75.70it/s]saving BB  train1-THALAMUS:  87%|████████▋ | 231/266 [00:03<00:00, 76.46it/s]saving BB  train1-THALAMUS:  90%|█████████ | 240/266 [00:03<00:00, 77.79it/s]saving BB  train1-THALAMUS:  93%|█████████▎| 248/266 [00:03<00:00, 78.33it/s]saving BB  train1-THALAMUS:  96%|█████████▌| 256/266 [00:03<00:00, 75.67it/s]saving BB  train1-THALAMUS:  99%|█████████▉| 264/266 [00:03<00:00, 73.22it/s]saving BB  train1-THALAMUS: 100%|██████████| 266/266 [00:03<00:00, 68.67it/s]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:01<07:57,  1.80s/it]Loading train:   1%|          | 2/266 [00:03<07:37,  1.73s/it]Loading train:   1%|          | 3/266 [00:04<07:20,  1.68s/it]Loading train:   2%|▏         | 4/266 [00:06<06:45,  1.55s/it]Loading train:   2%|▏         | 5/266 [00:07<06:53,  1.58s/it]Loading train:   2%|▏         | 6/266 [00:09<06:19,  1.46s/it]Loading train:   3%|▎         | 7/266 [00:10<05:58,  1.38s/it]Loading train:   3%|▎         | 8/266 [00:11<05:41,  1.32s/it]Loading train:   3%|▎         | 9/266 [00:12<05:28,  1.28s/it]Loading train:   4%|▍         | 10/266 [00:13<05:15,  1.23s/it]Loading train:   4%|▍         | 11/266 [00:14<05:08,  1.21s/it]Loading train:   5%|▍         | 12/266 [00:15<04:59,  1.18s/it]Loading train:   5%|▍         | 13/266 [00:17<04:55,  1.17s/it]Loading train:   5%|▌         | 14/266 [00:18<05:01,  1.19s/it]Loading train:   6%|▌         | 15/266 [00:19<04:54,  1.17s/it]Loading train:   6%|▌         | 16/266 [00:20<04:50,  1.16s/it]Loading train:   6%|▋         | 17/266 [00:21<04:47,  1.15s/it]Loading train:   7%|▋         | 18/266 [00:22<04:44,  1.15s/it]Loading train:   7%|▋         | 19/266 [00:24<04:44,  1.15s/it]Loading train:   8%|▊         | 20/266 [00:25<04:45,  1.16s/it]Loading train:   8%|▊         | 21/266 [00:26<04:51,  1.19s/it]Loading train:   8%|▊         | 22/266 [00:27<04:49,  1.19s/it]Loading train:   9%|▊         | 23/266 [00:28<04:50,  1.20s/it]Loading train:   9%|▉         | 24/266 [00:29<04:38,  1.15s/it]Loading train:   9%|▉         | 25/266 [00:30<04:30,  1.12s/it]Loading train:  10%|▉         | 26/266 [00:32<04:26,  1.11s/it]Loading train:  10%|█         | 27/266 [00:33<04:22,  1.10s/it]Loading train:  11%|█         | 28/266 [00:34<04:18,  1.09s/it]Loading train:  11%|█         | 29/266 [00:35<04:24,  1.11s/it]Loading train:  11%|█▏        | 30/266 [00:36<04:43,  1.20s/it]Loading train:  12%|█▏        | 31/266 [00:37<04:31,  1.16s/it]Loading train:  12%|█▏        | 32/266 [00:39<04:37,  1.18s/it]Loading train:  12%|█▏        | 33/266 [00:40<04:33,  1.17s/it]Loading train:  13%|█▎        | 34/266 [00:41<04:26,  1.15s/it]Loading train:  13%|█▎        | 35/266 [00:42<04:26,  1.15s/it]Loading train:  14%|█▎        | 36/266 [00:43<04:28,  1.17s/it]Loading train:  14%|█▍        | 37/266 [00:44<04:34,  1.20s/it]Loading train:  14%|█▍        | 38/266 [00:45<04:20,  1.14s/it]Loading train:  15%|█▍        | 39/266 [00:47<04:18,  1.14s/it]Loading train:  15%|█▌        | 40/266 [00:48<04:25,  1.18s/it]Loading train:  15%|█▌        | 41/266 [00:49<04:25,  1.18s/it]Loading train:  16%|█▌        | 42/266 [00:50<04:32,  1.22s/it]Loading train:  16%|█▌        | 43/266 [00:51<04:15,  1.15s/it]Loading train:  17%|█▋        | 44/266 [00:53<04:18,  1.17s/it]Loading train:  17%|█▋        | 45/266 [00:54<04:11,  1.14s/it]Loading train:  17%|█▋        | 46/266 [00:55<04:15,  1.16s/it]Loading train:  18%|█▊        | 47/266 [00:56<04:15,  1.17s/it]Loading train:  18%|█▊        | 48/266 [00:57<04:15,  1.17s/it]Loading train:  18%|█▊        | 49/266 [00:58<04:08,  1.14s/it]Loading train:  19%|█▉        | 50/266 [00:59<04:13,  1.17s/it]Loading train:  19%|█▉        | 51/266 [01:01<04:20,  1.21s/it]Loading train:  20%|█▉        | 52/266 [01:02<04:15,  1.19s/it]Loading train:  20%|█▉        | 53/266 [01:03<04:16,  1.21s/it]Loading train:  20%|██        | 54/266 [01:05<04:24,  1.25s/it]Loading train:  21%|██        | 55/266 [01:06<04:13,  1.20s/it]Loading train:  21%|██        | 56/266 [01:07<04:04,  1.17s/it]Loading train:  21%|██▏       | 57/266 [01:08<04:13,  1.21s/it]Loading train:  22%|██▏       | 58/266 [01:09<04:06,  1.18s/it]Loading train:  22%|██▏       | 59/266 [01:10<04:01,  1.17s/it]Loading train:  23%|██▎       | 60/266 [01:11<03:50,  1.12s/it]Loading train:  23%|██▎       | 61/266 [01:12<03:42,  1.08s/it]Loading train:  23%|██▎       | 62/266 [01:13<03:38,  1.07s/it]Loading train:  24%|██▎       | 63/266 [01:14<03:27,  1.02s/it]Loading train:  24%|██▍       | 64/266 [01:15<03:29,  1.04s/it]Loading train:  24%|██▍       | 65/266 [01:16<03:31,  1.05s/it]Loading train:  25%|██▍       | 66/266 [01:17<03:24,  1.02s/it]Loading train:  25%|██▌       | 67/266 [01:19<03:35,  1.08s/it]Loading train:  26%|██▌       | 68/266 [01:20<03:37,  1.10s/it]Loading train:  26%|██▌       | 69/266 [01:21<03:25,  1.04s/it]Loading train:  26%|██▋       | 70/266 [01:22<03:27,  1.06s/it]Loading train:  27%|██▋       | 71/266 [01:23<03:21,  1.04s/it]Loading train:  27%|██▋       | 72/266 [01:24<03:17,  1.02s/it]Loading train:  27%|██▋       | 73/266 [01:25<03:14,  1.01s/it]Loading train:  28%|██▊       | 74/266 [01:26<03:12,  1.00s/it]Loading train:  28%|██▊       | 75/266 [01:27<03:15,  1.03s/it]Loading train:  29%|██▊       | 76/266 [01:28<03:13,  1.02s/it]Loading train:  29%|██▉       | 77/266 [01:29<03:10,  1.01s/it]Loading train:  29%|██▉       | 78/266 [01:30<03:25,  1.09s/it]Loading train:  30%|██▉       | 79/266 [01:31<03:28,  1.12s/it]Loading train:  30%|███       | 80/266 [01:32<03:29,  1.12s/it]Loading train:  30%|███       | 81/266 [01:33<03:31,  1.14s/it]Loading train:  31%|███       | 82/266 [01:35<03:32,  1.16s/it]Loading train:  31%|███       | 83/266 [01:36<03:28,  1.14s/it]Loading train:  32%|███▏      | 84/266 [01:37<03:30,  1.15s/it]Loading train:  32%|███▏      | 85/266 [01:38<03:38,  1.21s/it]Loading train:  32%|███▏      | 86/266 [01:40<03:37,  1.21s/it]Loading train:  33%|███▎      | 87/266 [01:41<03:43,  1.25s/it]Loading train:  33%|███▎      | 88/266 [01:42<03:36,  1.22s/it]Loading train:  33%|███▎      | 89/266 [01:43<03:40,  1.25s/it]Loading train:  34%|███▍      | 90/266 [01:44<03:33,  1.21s/it]Loading train:  34%|███▍      | 91/266 [01:46<03:32,  1.21s/it]Loading train:  35%|███▍      | 92/266 [01:47<03:27,  1.19s/it]Loading train:  35%|███▍      | 93/266 [01:48<03:26,  1.20s/it]Loading train:  35%|███▌      | 94/266 [01:49<03:32,  1.24s/it]Loading train:  36%|███▌      | 95/266 [01:51<03:30,  1.23s/it]Loading train:  36%|███▌      | 96/266 [01:52<03:53,  1.37s/it]Loading train:  36%|███▋      | 97/266 [01:54<04:06,  1.46s/it]
Epoch 00056: val_mDice did not improve from 0.89110
Restoring model weights from the end of the best epoch
Epoch 00056: early stopping
{'val_loss': [0.08417455889284611, 0.07106223776936531, 0.07109139524400235, 0.07717969976365566, 0.09081046730279922, 0.0638809435069561, 0.06367367766797542, 0.06789686605334282, 0.06424383483827115, 0.06301324814558029, 0.06290329694747925, 0.06752062365412712, 0.06086241491138935, 0.06396610662341118, 0.06494261175394059, 0.059340324625372885, 0.06342712379992008, 0.06103150695562363, 0.05937486737966537, 0.06241649724543095, 0.06618766747415065, 0.06288068592548371, 0.06261871643364429, 0.061732204258441926, 0.0628031637519598, 0.06650311350822449, 0.062310585379600526, 0.06394180916249752, 0.06335593685507775, 0.06501097641885281, 0.06700957641005516, 0.06407802291214466, 0.06131595335900784, 0.06310147643089295, 0.06252881474792957, 0.0617076899856329, 0.06439723297953606, 0.06533928737044334, 0.06166634112596512, 0.06374945044517517, 0.06509095653891564, 0.06236508190631866, 0.06331475041806697, 0.061414570361375806, 0.06285320520401001, 0.06507550068199634, 0.0627432994544506, 0.06458860374987126, 0.06273561790585518, 0.06360015459358692, 0.06797400489449501, 0.0684556845575571, 0.06383425854146481, 0.06255051903426648, 0.06239911280572415, 0.06450164653360843], 'val_acc': [0.993012672662735, 0.994027042388916, 0.9936040461063385, 0.9942526698112488, 0.9941432774066925, 0.9944266498088836, 0.9940779745578766, 0.9942614614963532, 0.9941206097602844, 0.9945494711399079, 0.9943077445030213, 0.9940248548984527, 0.9944461524486542, 0.9944315314292907, 0.993517541885376, 0.99455726146698, 0.9942836284637451, 0.9941028237342835, 0.9944831907749176, 0.994239765405655, 0.9935830891132355, 0.9939108192920685, 0.9941566824913025, 0.9938399076461792, 0.9939522445201874, 0.9940740764141083, 0.994467830657959, 0.9936939597129821, 0.9938352823257446, 0.9943406522274018, 0.9943652510643005, 0.99424147605896, 0.994281667470932, 0.9938028752803802, 0.9939995110034943, 0.9940316796302795, 0.9937894880771637, 0.9934420168399811, 0.9942251443862915, 0.9944056987762451, 0.9934953629970551, 0.9941910386085511, 0.9937636435031891, 0.9942482948303223, 0.9944568693637847, 0.9939342141151428, 0.9943345487117767, 0.9938355207443237, 0.9944410383701324, 0.9941381514072418, 0.9928813338279724, 0.9932329416275024, 0.9941418170928955, 0.993885725736618, 0.9941500902175904, 0.9937417209148407], 'val_mDice': [0.8567393898963929, 0.8788919627666474, 0.8788399875164032, 0.8682186543941498, 0.845003092288971, 0.8834917783737183, 0.8834378659725189, 0.8766906917095184, 0.8827675700187683, 0.8849258422851562, 0.8850665390491486, 0.8772851407527924, 0.8887425243854523, 0.8832018494606018, 0.8816248893737793, 0.89110107421875, 0.8843985557556152, 0.8882863223552704, 0.8909615337848663, 0.8860835015773774, 0.8796948313713073, 0.88531693816185, 0.8857873022556305, 0.887169474363327, 0.8855483114719391, 0.8791207253932953, 0.8862341940402985, 0.8835913300514221, 0.8846517324447631, 0.8816200137138367, 0.8781980454921723, 0.8832072854042053, 0.8881283283233643, 0.8849441409111023, 0.8860453724861145, 0.8873851537704468, 0.8828130543231965, 0.8811259746551514, 0.8874245345592499, 0.8837787330150604, 0.8817654073238372, 0.8862558722496032, 0.8846826434135437, 0.8878735423088073, 0.8854104399681091, 0.881787121295929, 0.8856585085391998, 0.882557624578476, 0.8855929613113404, 0.8841539859771729, 0.8768170237541199, 0.876050877571106, 0.8835712611675263, 0.8860323369503021, 0.8860715448856353, 0.8826820194721222], 'loss': [0.2609425349803341, 0.09352917262077902, 0.08122383156704077, 0.07530054478200723, 0.07087058384495498, 0.06425117421113256, 0.06025102714825836, 0.058667397267317026, 0.05680209535397394, 0.055103511446939514, 0.0535396028705524, 0.052006752340739815, 0.051358975644038074, 0.049969367496582776, 0.049330802710030236, 0.04849950624017226, 0.04751935508005675, 0.04710034197250606, 0.04631812062324654, 0.04598115834576522, 0.04529856344165239, 0.04491813275322153, 0.0444739219384938, 0.04409240861683706, 0.043549636506867544, 0.04319079148083926, 0.04290980691670643, 0.0426754643374898, 0.04234667034952098, 0.04204962606064188, 0.041858847891909134, 0.04152505279296008, 0.04139447830957918, 0.04118767866638051, 0.04075598698686411, 0.04069294184369132, 0.04060447088489963, 0.040483576015628804, 0.04009293406436663, 0.040004246390236024, 0.040070860440580815, 0.039728620169488554, 0.03957568968379979, 0.039548976939779455, 0.03933587232494476, 0.03909553952405178, 0.038800228610738625, 0.039056443762537724, 0.03881671243210559, 0.03858599765723736, 0.03847286060631358, 0.03825703276660118, 0.038223587076492184, 0.038092984985671326, 0.03809839629235024, 0.03781285569405604], 'acc': [0.9595764265064428, 0.9886207684028501, 0.9900134049858332, 0.9908129240418101, 0.9914955377949307, 0.992937701780594, 0.9934985441027183, 0.9936768812211835, 0.9938345222107343, 0.993997593254344, 0.994144685897864, 0.994268939409642, 0.9943384231233681, 0.9944639307328877, 0.9945200544425553, 0.9946016781041404, 0.99469193586707, 0.9947243203758857, 0.9947953634026623, 0.9948282004314233, 0.9948937842077256, 0.9949257550065947, 0.9949652934656243, 0.9950098326706522, 0.9950487673906633, 0.9950858474259089, 0.9951125754417959, 0.9951435620686707, 0.9951647604615435, 0.9951910204062249, 0.9952196423257837, 0.9952413100953841, 0.9952676573950416, 0.9952718061611456, 0.9953077199072573, 0.99531960757415, 0.9953341693230225, 0.9953276349868057, 0.9953698607491549, 0.9953719681110158, 0.9953836263957572, 0.9954063400504256, 0.9954194743184239, 0.9954182914557613, 0.9954363256229671, 0.9954577330782741, 0.9954818172116974, 0.9954629838434699, 0.9954786899708541, 0.9955067170898549, 0.9955149228159593, 0.9955364791369922, 0.9955350911582778, 0.9955473710206236, 0.9955550718312607, 0.9955602742410249], 'mDice': [0.680391610198501, 0.8419582729158658, 0.8627171745001961, 0.8729219257599433, 0.8806382745720547, 0.8849579206735293, 0.8896691045219477, 0.8923355119721693, 0.8955590455151364, 0.8985100814003599, 0.9012390204950915, 0.9039327508107419, 0.9050605451642847, 0.9075130922245639, 0.9086401605182689, 0.9101059966397088, 0.9118406230449149, 0.9125820851110461, 0.9139773140435101, 0.9145745846876511, 0.9157880601057623, 0.9164720542941075, 0.9172583844780381, 0.9179375426163647, 0.9189094929793608, 0.9195524352912237, 0.9200559548252831, 0.9204728431004303, 0.9210635897503041, 0.9215994598751611, 0.9219358613918963, 0.9225387049542536, 0.9227700839515633, 0.9231466127965987, 0.9239219519645364, 0.9240343676833481, 0.9241943205225424, 0.9244163473472721, 0.9251200519953399, 0.9252850697896452, 0.925157650878721, 0.9257772952775017, 0.9260525322549957, 0.9261020307210871, 0.9264884082374923, 0.9269214196084512, 0.9274561402285457, 0.9269965139897889, 0.9274274131580195, 0.9278439233215922, 0.9280502854399808, 0.928437531043399, 0.9285005492195804, 0.9287380094602653, 0.9287261716523908, 0.9292484155680737]}
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 7  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 7  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max Loading train:  37%|███▋      | 98/266 [01:55<04:07,  1.47s/it]Loading train:  37%|███▋      | 99/266 [01:57<03:57,  1.42s/it]Loading train:  38%|███▊      | 100/266 [01:58<03:52,  1.40s/it]Loading train:  38%|███▊      | 101/266 [01:59<03:35,  1.31s/it]Loading train:  38%|███▊      | 102/266 [02:00<03:26,  1.26s/it]Loading train:  39%|███▊      | 103/266 [02:01<03:19,  1.22s/it]Loading train:  39%|███▉      | 104/266 [02:03<03:12,  1.19s/it]Loading train:  39%|███▉      | 105/266 [02:04<03:16,  1.22s/it]Loading train:  40%|███▉      | 106/266 [02:05<03:08,  1.18s/it]Loading train:  40%|████      | 107/266 [02:06<03:08,  1.18s/it]Loading train:  41%|████      | 108/266 [02:07<03:08,  1.19s/it]Loading train:  41%|████      | 109/266 [02:09<03:05,  1.18s/it]Loading train:  41%|████▏     | 110/266 [02:10<03:03,  1.18s/it]Loading train:  42%|████▏     | 111/266 [02:11<03:02,  1.17s/it]Loading train:  42%|████▏     | 112/266 [02:12<02:58,  1.16s/it]Loading train:  42%|████▏     | 113/266 [02:13<03:04,  1.21s/it]Loading train:  43%|████▎     | 114/266 [02:14<03:02,  1.20s/it]Loading train:  43%|████▎     | 115/266 [02:16<02:56,  1.17s/it]Loading train:  44%|████▎     | 116/266 [02:17<02:57,  1.18s/it]Loading train:  44%|████▍     | 117/266 [02:18<02:53,  1.17s/it]Loading train:  44%|████▍     | 118/266 [02:19<02:54,  1.18s/it]Loading train:  45%|████▍     | 119/266 [02:20<02:58,  1.22s/it]Loading train:  45%|████▌     | 120/266 [02:22<03:03,  1.26s/it]Loading train:  45%|████▌     | 121/266 [02:23<03:02,  1.26s/it]Loading train:  46%|████▌     | 122/266 [02:24<03:01,  1.26s/it]Loading train:  46%|████▌     | 123/266 [02:26<03:03,  1.28s/it]Loading train:  47%|████▋     | 124/266 [02:27<03:06,  1.31s/it]Loading train:  47%|████▋     | 125/266 [02:28<03:11,  1.36s/it]Loading train:  47%|████▋     | 126/266 [02:30<03:01,  1.30s/it]Loading train:  48%|████▊     | 127/266 [02:31<03:04,  1.33s/it]Loading train:  48%|████▊     | 128/266 [02:32<02:53,  1.26s/it]Loading train:  48%|████▊     | 129/266 [02:33<02:45,  1.21s/it]Loading train:  49%|████▉     | 130/266 [02:35<02:50,  1.26s/it]Loading train:  49%|████▉     | 131/266 [02:36<02:46,  1.23s/it]Loading train:  50%|████▉     | 132/266 [02:37<02:51,  1.28s/it]Loading train:  50%|█████     | 133/266 [02:38<02:40,  1.21s/it]Loading train:  50%|█████     | 134/266 [02:39<02:34,  1.17s/it]Loading train:  51%|█████     | 135/266 [02:40<02:29,  1.14s/it]Loading train:  51%|█████     | 136/266 [02:41<02:19,  1.07s/it]Loading train:  52%|█████▏    | 137/266 [02:42<02:16,  1.06s/it]Loading train:  52%|█████▏    | 138/266 [02:43<02:16,  1.07s/it]Loading train:  52%|█████▏    | 139/266 [02:45<02:32,  1.20s/it]Loading train:  53%|█████▎    | 140/266 [02:46<02:25,  1.15s/it]Loading train:  53%|█████▎    | 141/266 [02:47<02:35,  1.24s/it]Loading train:  53%|█████▎    | 142/266 [02:49<02:36,  1.27s/it]Loading train:  54%|█████▍    | 143/266 [02:50<02:30,  1.23s/it]Loading train:  54%|█████▍    | 144/266 [02:51<02:24,  1.19s/it]Loading train:  55%|█████▍    | 145/266 [02:52<02:36,  1.29s/it]Loading train:  55%|█████▍    | 146/266 [02:54<02:40,  1.34s/it]Loading train:  55%|█████▌    | 147/266 [02:55<02:39,  1.34s/it]Loading train:  56%|█████▌    | 148/266 [02:57<02:43,  1.38s/it]Loading train:  56%|█████▌    | 149/266 [02:58<02:38,  1.36s/it]Loading train:  56%|█████▋    | 150/266 [02:59<02:39,  1.37s/it]Loading train:  57%|█████▋    | 151/266 [03:01<02:36,  1.36s/it]Loading train:  57%|█████▋    | 152/266 [03:02<02:30,  1.32s/it]Loading train:  58%|█████▊    | 153/266 [03:03<02:27,  1.31s/it]Loading train:  58%|█████▊    | 154/266 [03:05<02:30,  1.34s/it]Loading train:  58%|█████▊    | 155/266 [03:06<02:21,  1.27s/it]Loading train:  59%|█████▊    | 156/266 [03:07<02:16,  1.24s/it]Loading train:  59%|█████▉    | 157/266 [03:08<02:02,  1.12s/it]Loading train:  59%|█████▉    | 158/266 [03:09<02:00,  1.11s/it]Loading train:  60%|█████▉    | 159/266 [03:10<02:02,  1.15s/it]Loading train:  60%|██████    | 160/266 [03:11<02:03,  1.17s/it]Loading train:  61%|██████    | 161/266 [03:13<02:07,  1.21s/it]Loading train:  61%|██████    | 162/266 [03:14<01:57,  1.13s/it]Loading train:  61%|██████▏   | 163/266 [03:15<01:54,  1.12s/it]Loading train:  62%|██████▏   | 164/266 [03:16<01:56,  1.14s/it]Loading train:  62%|██████▏   | 165/266 [03:17<02:00,  1.20s/it]Loading train:  62%|██████▏   | 166/266 [03:19<02:02,  1.22s/it]Loading train:  63%|██████▎   | 167/266 [03:20<01:58,  1.20s/it]Loading train:  63%|██████▎   | 168/266 [03:21<01:55,  1.18s/it]Loading train:  64%|██████▎   | 169/266 [03:22<01:51,  1.15s/it]Loading train:  64%|██████▍   | 170/266 [03:23<01:57,  1.22s/it]Loading train:  64%|██████▍   | 171/266 [03:24<01:46,  1.12s/it]Loading train:  65%|██████▍   | 172/266 [03:25<01:42,  1.09s/it]Loading train:  65%|██████▌   | 173/266 [03:26<01:43,  1.11s/it]Loading train:  65%|██████▌   | 174/266 [03:27<01:42,  1.11s/it]Loading train:  66%|██████▌   | 175/266 [03:29<01:45,  1.16s/it]Loading train:  66%|██████▌   | 176/266 [03:30<01:45,  1.18s/it]Loading train:  67%|██████▋   | 177/266 [03:31<01:50,  1.24s/it]Loading train:  67%|██████▋   | 178/266 [03:32<01:44,  1.19s/it]Loading train:  67%|██████▋   | 179/266 [03:34<01:42,  1.18s/it]Loading train:  68%|██████▊   | 180/266 [03:35<01:39,  1.16s/it]Loading train:  68%|██████▊   | 181/266 [03:36<01:37,  1.15s/it]Loading train:  68%|██████▊   | 182/266 [03:37<01:39,  1.19s/it]Loading train:  69%|██████▉   | 183/266 [03:38<01:36,  1.16s/it]Loading train:  69%|██████▉   | 184/266 [03:40<01:39,  1.21s/it]Loading train:  70%|██████▉   | 185/266 [03:41<01:34,  1.17s/it]Loading train:  70%|██████▉   | 186/266 [03:42<01:29,  1.12s/it]Loading train:  70%|███████   | 187/266 [03:43<01:25,  1.08s/it]Loading train:  71%|███████   | 188/266 [03:44<01:22,  1.06s/it]Loading train:  71%|███████   | 189/266 [03:45<01:26,  1.12s/it]Loading train:  71%|███████▏  | 190/266 [03:46<01:23,  1.10s/it]Loading train:  72%|███████▏  | 191/266 [03:47<01:29,  1.20s/it]Loading train:  72%|███████▏  | 192/266 [03:49<01:30,  1.22s/it]Loading train:  73%|███████▎  | 193/266 [03:50<01:34,  1.29s/it]Loading train:  73%|███████▎  | 194/266 [03:52<01:39,  1.38s/it]Loading train:  73%|███████▎  | 195/266 [03:53<01:31,  1.28s/it]Loading train:  74%|███████▎  | 196/266 [03:54<01:25,  1.23s/it]Loading train:  74%|███████▍  | 197/266 [03:55<01:19,  1.15s/it]Loading train:  74%|███████▍  | 198/266 [03:56<01:18,  1.16s/it]Loading train:  75%|███████▍  | 199/266 [03:57<01:16,  1.14s/it]Loading train:  75%|███████▌  | 200/266 [03:58<01:18,  1.18s/it]Loading train:  76%|███████▌  | 201/266 [03:59<01:15,  1.16s/it]Loading train:  76%|███████▌  | 202/266 [04:00<01:12,  1.14s/it]Loading train:  76%|███████▋  | 203/266 [04:02<01:10,  1.12s/it]Loading train:  77%|███████▋  | 204/266 [04:03<01:11,  1.15s/it]Loading train:  77%|███████▋  | 205/266 [04:04<01:09,  1.14s/it]Loading train:  77%|███████▋  | 206/266 [04:05<01:06,  1.11s/it]Loading train:  78%|███████▊  | 207/266 [04:06<01:03,  1.08s/it]Loading train:  78%|███████▊  | 208/266 [04:07<01:01,  1.05s/it]Loading train:  79%|███████▊  | 209/266 [04:08<00:59,  1.05s/it]Loading train:  79%|███████▉  | 210/266 [04:09<01:01,  1.09s/it]Loading train:  79%|███████▉  | 211/266 [04:10<00:59,  1.09s/it]Loading train:  80%|███████▉  | 212/266 [04:11<00:59,  1.09s/it]Loading train:  80%|████████  | 213/266 [04:12<00:56,  1.06s/it]Loading train:  80%|████████  | 214/266 [04:13<00:54,  1.04s/it]Loading train:  81%|████████  | 215/266 [04:14<00:53,  1.04s/it]Loading train:  81%|████████  | 216/266 [04:15<00:52,  1.04s/it]Loading train:  82%|████████▏ | 217/266 [04:17<00:52,  1.07s/it]Loading train:  82%|████████▏ | 218/266 [04:18<00:51,  1.07s/it]Loading train:  82%|████████▏ | 219/266 [04:19<00:49,  1.06s/it]Loading train:  83%|████████▎ | 220/266 [04:20<00:50,  1.09s/it]Loading train:  83%|████████▎ | 221/266 [04:21<00:47,  1.04s/it]Loading train:  83%|████████▎ | 222/266 [04:22<00:46,  1.06s/it]Loading train:  84%|████████▍ | 223/266 [04:23<00:47,  1.11s/it]Loading train:  84%|████████▍ | 224/266 [04:24<00:46,  1.11s/it]Loading train:  85%|████████▍ | 225/266 [04:26<00:49,  1.21s/it]Loading train:  85%|████████▍ | 226/266 [04:27<00:47,  1.19s/it]Loading train:  85%|████████▌ | 227/266 [04:28<00:48,  1.25s/it]Loading train:  86%|████████▌ | 228/266 [04:29<00:46,  1.23s/it]Loading train:  86%|████████▌ | 229/266 [04:31<00:47,  1.29s/it]Loading train:  86%|████████▋ | 230/266 [04:32<00:44,  1.23s/it]Loading train:  87%|████████▋ | 231/266 [04:33<00:41,  1.19s/it]Loading train:  87%|████████▋ | 232/266 [04:34<00:41,  1.21s/it]Loading train:  88%|████████▊ | 233/266 [04:35<00:38,  1.17s/it]Loading train:  88%|████████▊ | 234/266 [04:37<00:38,  1.20s/it]Loading train:  88%|████████▊ | 235/266 [04:38<00:37,  1.20s/it]Loading train:  89%|████████▊ | 236/266 [04:39<00:36,  1.21s/it]Loading train:  89%|████████▉ | 237/266 [04:40<00:36,  1.25s/it]Loading train:  89%|████████▉ | 238/266 [04:42<00:34,  1.24s/it]Loading train:  90%|████████▉ | 239/266 [04:43<00:32,  1.20s/it]Loading train:  90%|█████████ | 240/266 [04:44<00:33,  1.30s/it]Loading train:  91%|█████████ | 241/266 [04:45<00:29,  1.19s/it]Loading train:  91%|█████████ | 242/266 [04:46<00:27,  1.16s/it]Loading train:  91%|█████████▏| 243/266 [04:48<00:28,  1.25s/it]Loading train:  92%|█████████▏| 244/266 [04:49<00:26,  1.20s/it]Loading train:  92%|█████████▏| 245/266 [04:50<00:23,  1.14s/it]Loading train:  92%|█████████▏| 246/266 [04:51<00:22,  1.15s/it]Loading train:  93%|█████████▎| 247/266 [04:52<00:21,  1.14s/it]Loading train:  93%|█████████▎| 248/266 [04:53<00:20,  1.14s/it]Loading train:  94%|█████████▎| 249/266 [04:55<00:20,  1.20s/it]Loading train:  94%|█████████▍| 250/266 [04:56<00:18,  1.17s/it]Loading train:  94%|█████████▍| 251/266 [04:57<00:17,  1.16s/it]Loading train:  95%|█████████▍| 252/266 [04:58<00:16,  1.17s/it]Loading train:  95%|█████████▌| 253/266 [04:59<00:16,  1.23s/it]Loading train:  95%|█████████▌| 254/266 [05:00<00:14,  1.18s/it]Loading train:  96%|█████████▌| 255/266 [05:02<00:12,  1.16s/it]Loading train:  96%|█████████▌| 256/266 [05:03<00:11,  1.15s/it]Loading train:  97%|█████████▋| 257/266 [05:04<00:10,  1.14s/it]Loading train:  97%|█████████▋| 258/266 [05:05<00:09,  1.16s/it]Loading train:  97%|█████████▋| 259/266 [05:06<00:08,  1.16s/it]Loading train:  98%|█████████▊| 260/266 [05:07<00:06,  1.14s/it]Loading train:  98%|█████████▊| 261/266 [05:08<00:05,  1.17s/it]Loading train:  98%|█████████▊| 262/266 [05:10<00:04,  1.16s/it]Loading train:  99%|█████████▉| 263/266 [05:11<00:03,  1.15s/it]Loading train:  99%|█████████▉| 264/266 [05:12<00:02,  1.19s/it]Loading train: 100%|█████████▉| 265/266 [05:13<00:01,  1.19s/it]Loading train: 100%|██████████| 266/266 [05:15<00:00,  1.25s/it]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   1%|          | 2/266 [00:00<00:14, 18.49it/s]concatenating: train:   2%|▏         | 6/266 [00:00<00:12, 21.05it/s]concatenating: train:   7%|▋         | 19/266 [00:00<00:08, 28.09it/s]concatenating: train:  13%|█▎        | 35/266 [00:00<00:06, 37.27it/s]concatenating: train:  25%|██▌       | 67/266 [00:00<00:03, 50.66it/s]concatenating: train:  38%|███▊      | 101/266 [00:00<00:02, 68.03it/s]concatenating: train:  49%|████▉     | 131/266 [00:00<00:01, 88.34it/s]concatenating: train:  58%|█████▊    | 155/266 [00:00<00:01, 101.88it/s]concatenating: train:  67%|██████▋   | 177/266 [00:01<00:00, 109.81it/s]concatenating: train:  74%|███████▎  | 196/266 [00:01<00:00, 120.11it/s]concatenating: train:  80%|████████  | 214/266 [00:01<00:00, 123.26it/s]concatenating: train:  87%|████████▋ | 232/266 [00:01<00:00, 133.92it/s]concatenating: train:  94%|█████████▎| 249/266 [00:01<00:00, 101.88it/s]concatenating: train:  99%|█████████▉| 263/266 [00:01<00:00, 109.77it/s]concatenating: train: 100%|██████████| 266/266 [00:01<00:00, 145.54it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:01<00:06,  1.53s/it]Loading test:  40%|████      | 2/5 [00:03<00:04,  1.52s/it]Loading test:  60%|██████    | 3/5 [00:04<00:02,  1.45s/it]Loading test:  80%|████████  | 4/5 [00:05<00:01,  1.40s/it]Loading test: 100%|██████████| 5/5 [00:07<00:00,  1.44s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation:  80%|████████  | 4/5 [00:00<00:00, 30.27it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 32.73it/s]2019-08-17 19:55:15.556070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-08-17 19:55:15.556151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-17 19:55:15.556166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-08-17 19:55:15.556175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-08-17 19:55:15.556567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:89:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.78it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.70it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.61it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.28it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:04,  8.05it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  7.12it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02,  9.14it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.55it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:02,  7.91it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.99it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.46it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.73it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.79it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.75it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.97it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.88it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.73it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.90it/s]4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 26, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 13, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 26, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 26, 210)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 30)   25230       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 52, 60)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 30)   16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 90)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 90)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 13)   1183        dropout_5[0][0]                  
==================================================================================================
Total params: 501,343
Trainable params: 60,403
Non-trainable params: 440,940
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.34660930e-02 3.28935948e-02 7.69171474e-02 9.55734233e-03
 2.76611250e-02 7.23698158e-03 8.43844986e-02 1.14324677e-01
 8.97674365e-02 1.36387974e-02 2.91043685e-01 1.88870532e-01
 2.38089480e-04]
Train on 16945 samples, validate on 311 samples
Epoch 1/300
 - 21s - loss: 1.3998 - acc: 0.8212 - mDice: 0.3429 - val_loss: 2.6077 - val_acc: 0.9405 - val_mDice: 0.3670

Epoch 00001: val_mDice improved from -inf to 0.36704, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 16s - loss: 0.5099 - acc: 0.9331 - mDice: 0.5934 - val_loss: 1.1295 - val_acc: 0.9539 - val_mDice: 0.5956

Epoch 00002: val_mDice improved from 0.36704 to 0.59564, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 15s - loss: 0.4511 - acc: 0.9399 - mDice: 0.6291 - val_loss: 1.5138 - val_acc: 0.9521 - val_mDice: 0.5542

Epoch 00003: val_mDice did not improve from 0.59564
Epoch 4/300
 - 15s - loss: 0.4213 - acc: 0.9428 - mDice: 0.6485 - val_loss: 1.0696 - val_acc: 0.9546 - val_mDice: 0.6010

Epoch 00004: val_mDice improved from 0.59564 to 0.60101, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 15s - loss: 0.4108 - acc: 0.9442 - mDice: 0.6586 - val_loss: 1.1815 - val_acc: 0.9524 - val_mDice: 0.6010

Epoch 00005: val_mDice improved from 0.60101 to 0.60104, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 15s - loss: 0.4032 - acc: 0.9448 - mDice: 0.6604 - val_loss: 1.1693 - val_acc: 0.9521 - val_mDice: 0.5835

Epoch 00006: val_mDice did not improve from 0.60104
Epoch 7/300
 - 15s - loss: 0.3971 - acc: 0.9456 - mDice: 0.6670 - val_loss: 1.1543 - val_acc: 0.9552 - val_mDice: 0.5830

Epoch 00007: val_mDice did not improve from 0.60104
Epoch 8/300
 - 15s - loss: 0.3700 - acc: 0.9469 - mDice: 0.6794 - val_loss: 1.0596 - val_acc: 0.9516 - val_mDice: 0.5991

Epoch 00008: val_mDice did not improve from 0.60104
Epoch 9/300
 - 16s - loss: 0.3757 - acc: 0.9469 - mDice: 0.6804 - val_loss: 1.1661 - val_acc: 0.9544 - val_mDice: 0.5936

Epoch 00009: val_mDice did not improve from 0.60104
Epoch 10/300
 - 15s - loss: 0.3803 - acc: 0.9464 - mDice: 0.6766 - val_loss: 2.1462 - val_acc: 0.9469 - val_mDice: 0.4810

Epoch 00010: val_mDice did not improve from 0.60104
Epoch 11/300
 - 13s - loss: 0.3809 - acc: 0.9462 - mDice: 0.6764 - val_loss: 1.1617 - val_acc: 0.9531 - val_mDice: 0.5941

Epoch 00011: val_mDice did not improve from 0.60104
Epoch 12/300
 - 13s - loss: 0.3610 - acc: 0.9480 - mDice: 0.6898 - val_loss: 1.1823 - val_acc: 0.9513 - val_mDice: 0.5930

Epoch 00012: val_mDice did not improve from 0.60104
Epoch 13/300
 - 14s - loss: 0.3549 - acc: 0.9484 - mDice: 0.6940 - val_loss: 1.0714 - val_acc: 0.9509 - val_mDice: 0.5972

Epoch 00013: val_mDice did not improve from 0.60104
Epoch 14/300
 - 14s - loss: 0.3511 - acc: 0.9485 - mDice: 0.6960 - val_loss: 1.1339 - val_acc: 0.9548 - val_mDice: 0.5790

Epoch 00014: val_mDice did not improve from 0.60104
Epoch 15/300
 - 13s - loss: 0.3660 - acc: 0.9479 - mDice: 0.6905 - val_loss: 1.0780 - val_acc: 0.9536 - val_mDice: 0.5999

Epoch 00015: val_mDice did not improve from 0.60104
Epoch 16/300
 - 13s - loss: 0.3476 - acc: 0.9487 - mDice: 0.6977 - val_loss: 1.0636 - val_acc: 0.9549 - val_mDice: 0.5939

Epoch 00016: val_mDice did not improve from 0.60104
Epoch 17/300
 - 13s - loss: 0.3582 - acc: 0.9478 - mDice: 0.6921 - val_loss: 0.9812 - val_acc: 0.9555 - val_mDice: 0.5976

Epoch 00017: val_mDice did not improve from 0.60104
Epoch 18/300
 - 14s - loss: 0.3549 - acc: 0.9483 - mDice: 0.6943 - val_loss: 0.9029 - val_acc: 0.9563 - val_mDice: 0.5963

Epoch 00018: val_mDice did not improve from 0.60104
Epoch 19/300
 - 14s - loss: 0.3417 - acc: 0.9495 - mDice: 0.7058 - val_loss: 0.9585 - val_acc: 0.9550 - val_mDice: 0.6019

Epoch 00019: val_mDice improved from 0.60104 to 0.60194, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 20/300
 - 13s - loss: 0.3655 - acc: 0.9469 - mDice: 0.6881 - val_loss: 2.2257 - val_acc: 0.9446 - val_mDice: 0.4583

Epoch 00020: val_mDice did not improve from 0.60194
Epoch 21/300
 - 13s - loss: 0.3579 - acc: 0.9485 - mDice: 0.6946 - val_loss: 1.0462 - val_acc: 0.9542 - val_mDice: 0.5980

Epoch 00021: val_mDice did not improve from 0.60194
Epoch 22/300
 - 13s - loss: 0.3459 - acc: 0.9491 - mDice: 0.7037 - val_loss: 1.0948 - val_acc: 0.9536 - val_mDice: 0.5958

Epoch 00022: val_mDice did not improve from 0.60194
Epoch 23/300
 - 13s - loss: 0.3371 - acc: 0.9496 - mDice: 0.7075 - val_loss: 1.0993 - val_acc: 0.9558 - val_mDice: 0.5764

Epoch 00023: val_mDice did not improve from 0.60194
Epoch 24/300
 - 13s - loss: 0.3248 - acc: 0.9501 - mDice: 0.7132 - val_loss: 1.0924 - val_acc: 0.9529 - val_mDice: 0.5883

Epoch 00024: val_mDice did not improve from 0.60194
Epoch 25/300
 - 14s - loss: 0.3351 - acc: 0.9493 - mDice: 0.7074 - val_loss: 1.1169 - val_acc: 0.9543 - val_mDice: 0.5934

Epoch 00025: val_mDice did not improve from 0.60194
Epoch 26/300
 - 13s - loss: 0.3383 - acc: 0.9495 - mDice: 0.7073 - val_loss: 1.1814 - val_acc: 0.9524 - val_mDice: 0.5905

Epoch 00026: val_mDice did not improve from 0.60194
Epoch 27/300
 - 13s - loss: 0.3443 - acc: 0.9493 - mDice: 0.7076 - val_loss: 1.0381 - val_acc: 0.9570 - val_mDice: 0.5779

Epoch 00027: val_mDice did not improve from 0.60194
Epoch 28/300
 - 13s - loss: 0.3259 - acc: 0.9496 - mDice: 0.7106 - val_loss: 1.0820 - val_acc: 0.9534 - val_mDice: 0.6013

Epoch 00028: val_mDice did not improve from 0.60194
Epoch 29/300
 - 13s - loss: 0.3208 - acc: 0.9501 - mDice: 0.7150 - val_loss: 0.9722 - val_acc: 0.9541 - val_mDice: 0.5998

Epoch 00029: val_mDice did not improve from 0.60194
Epoch 30/300
 - 13s - loss: 0.3187 - acc: 0.9503 - mDice: 0.7182 - val_loss: 1.0510 - val_acc: 0.9543 - val_mDice: 0.5988

Epoch 00030: val_mDice did not improve from 0.60194
Epoch 31/300
 - 14s - loss: 0.3156 - acc: 0.9506 - mDice: 0.7198 - val_loss: 1.1579 - val_acc: 0.9550 - val_mDice: 0.5804

Epoch 00031: val_mDice did not improve from 0.60194
Epoch 32/300
 - 14s - loss: 0.3182 - acc: 0.9508 - mDice: 0.7245 - val_loss: 1.1192 - val_acc: 0.9546 - val_mDice: 0.5806

Epoch 00032: val_mDice did not improve from 0.60194
Epoch 33/300
 - 14s - loss: 0.3080 - acc: 0.9511 - mDice: 0.7250 - val_loss: 0.9972 - val_acc: 0.9543 - val_mDice: 0.6026

Epoch 00033: val_mDice improved from 0.60194 to 0.60260, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 34/300
 - 13s - loss: 0.3320 - acc: 0.9496 - mDice: 0.7113 - val_loss: 1.1851 - val_acc: 0.9492 - val_mDice: 0.5870

Epoch 00034: val_mDice did not improve from 0.60260
Epoch 35/300
 - 14s - loss: 0.3344 - acc: 0.9495 - mDice: 0.7113 - val_loss: 1.1194 - val_acc: 0.9515 - val_mDice: 0.5591

Epoch 00035: val_mDice did not improve from 0.60260
Epoch 36/300
 - 14s - loss: 0.3105 - acc: 0.9507 - mDice: 0.7219 - val_loss: 1.2958 - val_acc: 0.9553 - val_mDice: 0.5583

Epoch 00036: val_mDice did not improve from 0.60260
Epoch 37/300
 - 14s - loss: 0.3155 - acc: 0.9505 - mDice: 0.7207 - val_loss: 1.0147 - val_acc: 0.9555 - val_mDice: 0.5996

Epoch 00037: val_mDice did not improve from 0.60260
Epoch 38/300
 - 13s - loss: 0.3094 - acc: 0.9510 - mDice: 0.7247 - val_loss: 1.0109 - val_acc: 0.9544 - val_mDice: 0.5879

Epoch 00038: val_mDice did not improve from 0.60260
Epoch 39/300
 - 14s - loss: 0.3326 - acc: 0.9490 - mDice: 0.7093 - val_loss: 1.1591 - val_acc: 0.9546 - val_mDice: 0.5740

Epoch 00039: val_mDice did not improve from 0.60260
Epoch 40/300
 - 14s - loss: 0.3148 - acc: 0.9504 - mDice: 0.7231 - val_loss: 0.9173 - val_acc: 0.9541 - val_mDice: 0.5963

Epoch 00040: val_mDice did not improve from 0.60260
Epoch 41/300
 - 13s - loss: 0.3050 - acc: 0.9510 - mDice: 0.7273 - val_loss: 1.0419 - val_acc: 0.9516 - val_mDice: 0.5942

Epoch 00041: val_mDice did not improve from 0.60260
Epoch 42/300
 - 13s - loss: 0.2953 - acc: 0.9515 - mDice: 0.7322 - val_loss: 0.9088 - val_acc: 0.9536 - val_mDice: 0.5989

Epoch 00042: val_mDice did not improve from 0.60260
Epoch 43/300
 - 13s - loss: 0.3105 - acc: 0.9514 - mDice: 0.7308 - val_loss: 0.9591 - val_acc: 0.9537 - val_mDice: 0.5963

Epoch 00043: val_mDice did not improve from 0.60260
Epoch 44/300
 - 14s - loss: 0.2901 - acc: 0.9518 - mDice: 0.7358 - val_loss: 0.9627 - val_acc: 0.9533 - val_mDice: 0.5988

Epoch 00044: val_mDice did not improve from 0.60260
Epoch 45/300
 - 13s - loss: 0.2964 - acc: 0.9517 - mDice: 0.7342 - val_loss: 0.9622 - val_acc: 0.9521 - val_mDice: 0.6010

Epoch 00045: val_mDice did not improve from 0.60260
Epoch 46/300
 - 13s - loss: 0.3069 - acc: 0.9514 - mDice: 0.7321 - val_loss: 1.0402 - val_acc: 0.9522 - val_mDice: 0.5912

Epoch 00046: val_mDice did not improve from 0.60260
Epoch 47/300
 - 13s - loss: 0.2983 - acc: 0.9512 - mDice: 0.7309 - val_loss: 1.6673 - val_acc: 0.9492 - val_mDice: 0.5213

Epoch 00047: val_mDice did not improve from 0.60260
Epoch 48/300
 - 14s - loss: 0.3081 - acc: 0.9513 - mDice: 0.7286 - val_loss: 1.0274 - val_acc: 0.9530 - val_mDice: 0.5948

Epoch 00048: val_mDice did not improve from 0.60260
Epoch 49/300
 - 13s - loss: 0.3040 - acc: 0.9516 - mDice: 0.7333 - val_loss: 0.9780 - val_acc: 0.9533 - val_mDice: 0.6005

Epoch 00049: val_mDice did not improve from 0.60260
Epoch 50/300
 - 13s - loss: 0.3118 - acc: 0.9513 - mDice: 0.7287 - val_loss: 0.9515 - val_acc: 0.9552 - val_mDice: 0.6016

Epoch 00050: val_mDice did not improve from 0.60260
Epoch 51/300
 - 14s - loss: 0.2926 - acc: 0.9519 - mDice: 0.7366 - val_loss: 1.8578 - val_acc: 0.9490 - val_mDice: 0.5005

Epoch 00051: val_mDice did not improve from 0.60260
Epoch 52/300
 - 14s - loss: 0.3099 - acc: 0.9506 - mDice: 0.7231 - val_loss: 1.0396 - val_acc: 0.9524 - val_mDice: 0.5949

Epoch 00052: val_mDice did not improve from 0.60260
Epoch 53/300
 - 13s - loss: 0.3037 - acc: 0.9510 - mDice: 0.7298 - val_loss: 1.0264 - val_acc: 0.9547 - val_mDice: 0.5921

Epoch 00053: val_mDice did not improve from 0.60260
Epoch 54/300
 - 13s - loss: 0.2962 - acc: 0.9517 - mDice: 0.7362 - val_loss: 0.9469 - val_acc: 0.9502 - val_mDice: 0.5958

Epoch 00054: val_mDice did not improve from 0.60260
Epoch 55/300
 - 14s - loss: 0.3068 - acc: 0.9514 - mDice: 0.7320 - val_loss: 0.9739 - val_acc: 0.9527 - val_mDice: 0.5965

Epoch 00055: val_mDice did not improve from 0.60260
Epoch 56/300
 - 13s - loss: 0.2956 - acc: 0.9514 - mDice: 0.7336 - val_loss: 0.9945 - val_acc: 0.9549 - val_mDice: 0.5990

Epoch 00056: val_mDice did not improve from 0.60260
Epoch 57/300
 - 14s - loss: 0.2865 - acc: 0.9522 - mDice: 0.7411 - val_loss: 0.8928 - val_acc: 0.9525 - val_mDice: 0.5960

Epoch 00057: val_mDice did not improve from 0.60260
Epoch 58/300
 - 14s - loss: 0.2817 - acc: 0.9523 - mDice: 0.7426 - val_loss: 0.9543 - val_acc: 0.9553 - val_mDice: 0.5946

Epoch 00058: val_mDice did not improve from 0.60260
Epoch 59/300
 - 13s - loss: 0.2898 - acc: 0.9519 - mDice: 0.7374 - val_loss: 1.0651 - val_acc: 0.9553 - val_mDice: 0.5673

Epoch 00059: val_mDice did not improve from 0.60260
Epoch 60/300
 - 13s - loss: 0.3072 - acc: 0.9504 - mDice: 0.7264 - val_loss: 1.1313 - val_acc: 0.9531 - val_mDice: 0.5917

Epoch 00060: val_mDice did not improve from 0.60260
Epoch 61/300
 - 14s - loss: 0.2942 - acc: 0.9520 - mDice: 0.7374 - val_loss: 1.0325 - val_acc: 0.9557 - val_mDice: 0.5833

Epoch 00061: val_mDice did not improve from 0.60260
Epoch 62/300
 - 14s - loss: 0.2840 - acc: 0.9522 - mDice: 0.7417 - val_loss: 1.1431 - val_acc: 0.9540 - val_mDice: 0.5761

Epoch 00062: val_mDice did not improve from 0.60260
Epoch 63/300
 - 14s - loss: 0.3195 - acc: 0.9506 - mDice: 0.7259 - val_loss: 1.1833 - val_acc: 0.9555 - val_mDice: 0.5490

Epoch 00063: val_mDice did not improve from 0.60260
Epoch 64/300
 - 14s - loss: 0.2999 - acc: 0.9511 - mDice: 0.7289 - val_loss: 0.9616 - val_acc: 0.9520 - val_mDice: 0.5965

Epoch 00064: val_mDice did not improve from 0.60260
Epoch 65/300
 - 14s - loss: 0.3031 - acc: 0.9509 - mDice: 0.7286 - val_loss: 1.1179 - val_acc: 0.9535 - val_mDice: 0.5982

Epoch 00065: val_mDice did not improve from 0.60260
Epoch 66/300
 - 13s - loss: 0.2879 - acc: 0.9521 - mDice: 0.7396 - val_loss: 1.0202 - val_acc: 0.9558 - val_mDice: 0.6032

Epoch 00066: val_mDice improved from 0.60260 to 0.60318, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 67/300
 - 14s - loss: 0.2800 - acc: 0.9525 - mDice: 0.7437 - val_loss: 1.1260 - val_acc: 0.9529 - val_mDice: 0.6017

Epoch 00067: val_mDice did not improve from 0.60318
Epoch 68/300
 - 14s - loss: 0.2909 - acc: 0.9517 - mDice: 0.7364 - val_loss: 1.1253 - val_acc: 0.9532 - val_mDice: 0.6012

Epoch 00068: val_mDice did not improve from 0.60318
Epoch 69/300
 - 14s - loss: 0.2939 - acc: 0.9517 - mDice: 0.7363 - val_loss: 1.1302 - val_acc: 0.9529 - val_mDice: 0.5935

Epoch 00069: val_mDice did not improve from 0.60318
Epoch 70/300
 - 14s - loss: 0.2880 - acc: 0.9523 - mDice: 0.7422 - val_loss: 1.0110 - val_acc: 0.9541 - val_mDice: 0.5933

Epoch 00070: val_mDice did not improve from 0.60318
Epoch 71/300
 - 14s - loss: 0.2814 - acc: 0.9527 - mDice: 0.7452 - val_loss: 0.9767 - val_acc: 0.9540 - val_mDice: 0.5930

Epoch 00071: val_mDice did not improve from 0.60318
Epoch 72/300
 - 14s - loss: 0.2894 - acc: 0.9521 - mDice: 0.7406 - val_loss: 1.0107 - val_acc: 0.9541 - val_mDice: 0.5944

Epoch 00072: val_mDice did not improve from 0.60318
Epoch 73/300
 - 14s - loss: 0.2819 - acc: 0.9524 - mDice: 0.7438 - val_loss: 0.9439 - val_acc: 0.9527 - val_mDice: 0.5923

Epoch 00073: val_mDice did not improve from 0.60318
Epoch 74/300
 - 14s - loss: 0.2885 - acc: 0.9526 - mDice: 0.7445 - val_loss: 1.0928 - val_acc: 0.9529 - val_mDice: 0.5963

Epoch 00074: val_mDice did not improve from 0.60318
Epoch 75/300
 - 13s - loss: 0.3011 - acc: 0.9511 - mDice: 0.7328 - val_loss: 0.8826 - val_acc: 0.9527 - val_mDice: 0.5984

Epoch 00075: val_mDice did not improve from 0.60318
Epoch 76/300
 - 14s - loss: 0.2886 - acc: 0.9519 - mDice: 0.7386 - val_loss: 1.0342 - val_acc: 0.9534 - val_mDice: 0.5971

Epoch 00076: val_mDice did not improve from 0.60318
Epoch 77/300
 - 13s - loss: 0.2759 - acc: 0.9528 - mDice: 0.7471 - val_loss: 0.9793 - val_acc: 0.9530 - val_mDice: 0.5913

Epoch 00077: val_mDice did not improve from 0.60318
Epoch 78/300
 - 14s - loss: 0.2736 - acc: 0.9529 - mDice: 0.7487 - val_loss: 0.8396 - val_acc: 0.9549 - val_mDice: 0.5928

Epoch 00078: val_mDice did not improve from 0.60318
Epoch 79/300
 - 13s - loss: 0.3090 - acc: 0.9512 - mDice: 0.7298 - val_loss: 1.1594 - val_acc: 0.9524 - val_mDice: 0.5951

Epoch 00079: val_mDice did not improve from 0.60318
Epoch 80/300
 - 14s - loss: 0.2908 - acc: 0.9522 - mDice: 0.7400 - val_loss: 1.1905 - val_acc: 0.9524 - val_mDice: 0.5914

Epoch 00080: val_mDice did not improve from 0.60318
Epoch 81/300
 - 14s - loss: 0.2839 - acc: 0.9526 - mDice: 0.7458 - val_loss: 1.1181 - val_acc: 0.9527 - val_mDice: 0.5960

Epoch 00081: val_mDice did not improve from 0.60318
Epoch 82/300
 - 13s - loss: 0.2798 - acc: 0.9528 - mDice: 0.7485 - val_loss: 0.9750 - val_acc: 0.9531 - val_mDice: 0.5985

Epoch 00082: val_mDice did not improve from 0.60318
Epoch 83/300
 - 14s - loss: 0.2748 - acc: 0.9530 - mDice: 0.7499 - val_loss: 0.9772 - val_acc: 0.9542 - val_mDice: 0.5938

Epoch 00083: val_mDice did not improve from 0.60318
Epoch 84/300
 - 13s - loss: 0.2705 - acc: 0.9530 - mDice: 0.7509 - val_loss: 0.9670 - val_acc: 0.9551 - val_mDice: 0.5949

Epoch 00084: val_mDice did not improve from 0.60318
Epoch 85/300
 - 13s - loss: 0.2674 - acc: 0.9532 - mDice: 0.7532 - val_loss: 1.0299 - val_acc: 0.9535 - val_mDice: 0.5926

Epoch 00085: val_mDice did not improve from 0.60318
Epoch 86/300
 - 14s - loss: 0.2726 - acc: 0.9529 - mDice: 0.7507 - val_loss: 1.0839 - val_acc: 0.9502 - val_mDice: 0.5888

Epoch 00086: val_mDice did not improve from 0.60318
Epoch 87/300
 - 14s - loss: 0.2713 - acc: 0.9532 - mDice: 0.7523 - val_loss: 0.9246 - val_acc: 0.9543 - val_mDice: 0.5844

Epoch 00087: val_mDice did not improve from 0.60318
Epoch 88/300
 - 14s - loss: 0.2769 - acc: 0.9530 - mDice: 0.7507 - val_loss: 0.9756 - val_acc: 0.9516 - val_mDice: 0.5925

Epoch 00088: val_mDice did not improve from 0.60318
Epoch 89/300
 - 14s - loss: 0.2706 - acc: 0.9532 - mDice: 0.7513 - val_loss: 1.0150 - val_acc: 0.9509 - val_mDice: 0.5915

Epoch 00089: val_mDice did not improve from 0.60318
Epoch 90/300
 - 14s - loss: 0.2809 - acc: 0.9529 - mDice: 0.7487 - val_loss: 0.9856 - val_acc: 0.9527 - val_mDice: 0.5918

Epoch 00090: val_mDice did not improve from 0.60318
Epoch 91/300
 - 14s - loss: 0.2791 - acc: 0.9529 - mDice: 0.7481 - val_loss: 0.9327 - val_acc: 0.9538 - val_mDice: 0.5992

Epoch 00091: val_mDice did not improve from 0.60318
Epoch 92/300
 - 15s - loss: 0.3152 - acc: 0.9502 - mDice: 0.7266 - val_loss: 1.2243 - val_acc: 0.9526 - val_mDice: 0.5847

Epoch 00092: val_mDice did not improve from 0.60318
Epoch 93/300
 - 15s - loss: 0.3062 - acc: 0.9506 - mDice: 0.7284 - val_loss: 1.0737 - val_acc: 0.9549 - val_mDice: 0.5914

Epoch 00093: val_mDice did not improve from 0.60318
Epoch 94/300
 - 15s - loss: 0.2731 - acc: 0.9526 - mDice: 0.7486 - val_loss: 1.0272 - val_acc: 0.9538 - val_mDice: 0.5983

Epoch 00094: val_mDice did not improve from 0.60318
Epoch 95/300
 - 15s - loss: 0.2739 - acc: 0.9530 - mDice: 0.7510 - val_loss: 1.0130 - val_acc: 0.9553 - val_mDice: 0.5993

Epoch 00095: val_mDice did not improve from 0.60318
Epoch 96/300
 - 15s - loss: 0.2789 - acc: 0.9529 - mDice: 0.7498 - val_loss: 0.9428 - val_acc: 0.9541 - val_mDice: 0.5987

Epoch 00096: val_mDice did not improve from 0.60318
Epoch 97/300
 - 14s - loss: 0.2775 - acc: 0.9531 - mDice: 0.7534 - val_loss: 0.9509 - val_acc: 0.9546 - val_mDice: 0.5977

Epoch 00097: val_mDice did not improve from 0.60318
Epoch 98/300
 - 14s - loss: 0.2773 - acc: 0.9531 - mDice: 0.7514 - val_loss: 1.1657 - val_acc: 0.9520 - val_mDice: 0.5895

Epoch 00098: val_mDice did not improve from 0.60318
Epoch 99/300
 - 15s - loss: 0.2745 - acc: 0.9529 - mDice: 0.7502 - val_loss: 2.2457 - val_acc: 0.9500 - val_mDice: 0.5041

Epoch 00099: val_mDice did not improve from 0.60318
Epoch 100/300
 - 15s - loss: 0.2850 - acc: 0.9527 - mDice: 0.7455 - val_loss: 1.0705 - val_acc: 0.9550 - val_mDice: 0.5907

Epoch 00100: val_mDice did not improve from 0.60318
Epoch 101/300
 - 14s - loss: 0.2678 - acc: 0.9533 - mDice: 0.7557 - val_loss: 1.1130 - val_acc: 0.9528 - val_mDice: 0.5978

Epoch 00101: val_mDice did not improve from 0.60318
Epoch 102/300
 - 15s - loss: 0.2684 - acc: 0.9535 - mDice: 0.7565 - val_loss: 0.9780 - val_acc: 0.9546 - val_mDice: 0.5895

Epoch 00102: val_mDice did not improve from 0.60318
Epoch 103/300
 - 15s - loss: 0.2759 - acc: 0.9533 - mDice: 0.7540 - val_loss: 1.0831 - val_acc: 0.9541 - val_mDice: 0.5995

Epoch 00103: val_mDice did not improve from 0.60318
Epoch 104/300
 - 15s - loss: 0.2837 - acc: 0.9526 - mDice: 0.7475 - val_loss: 1.0583 - val_acc: 0.9541 - val_mDice: 0.5962

Epoch 00104: val_mDice did not improve from 0.60318
Epoch 105/300
 - 15s - loss: 0.2672 - acc: 0.9529 - mDice: 0.7532 - val_loss: 1.0592 - val_acc: 0.9527 - val_mDice: 0.5935

Epoch 00105: val_mDice did not improve from 0.60318
Epoch 106/300
 - 15s - loss: 0.2660 - acc: 0.9534 - mDice: 0.7563 - val_loss: 0.9731 - val_acc: 0.9529 - val_mDice: 0.5934

Epoch 00106: val_mDice did not improve from 0.60318
Restoring model weights from the end of the best epoch
Epoch 00106: early stopping
{'val_loss': [2.6076941306184724, 1.1294767120643443, 1.5137702516037552, 1.06961599461902, 1.1814935422020327, 1.1692904619158655, 1.1542706980199293, 1.0595868461768343, 1.1660689539081415, 2.146243827136, 1.161680853251859, 1.1823167486589439, 1.0714427520224519, 1.1338677622880966, 1.0779645421880617, 1.0636461235319303, 0.981249216093511, 0.9029251461627016, 0.9585204045872213, 2.2257305962479768, 1.0461532607722512, 1.0948307721177866, 1.0992678129787996, 1.092421610830681, 1.1169458846187286, 1.1814221216551362, 1.038087227145192, 1.0819676240540776, 0.9721958665985769, 1.050971203103326, 1.157935634303323, 1.1192271709442139, 0.9971564274125544, 1.1850903160702377, 1.1193582557405306, 1.2958022426945603, 1.0147183449322004, 1.0109319522066516, 1.1591275305609994, 0.917276766522521, 1.041939506385104, 0.9087995120183447, 0.9590705180858109, 0.9627119137926501, 0.9621797110106785, 1.040230694307775, 1.6672998695511527, 1.0274325183733484, 0.9780165476431034, 0.951463398826084, 1.8577647646140438, 1.0396058557501175, 1.0263783594419718, 0.9469069602788452, 0.9738563766816805, 0.9944654028515341, 0.8928149196879274, 0.9542970272122472, 1.0651146430294613, 1.1312667185087295, 1.0324816473810619, 1.1431065608067528, 1.183331525402437, 0.9616115330883162, 1.117892662236928, 1.020234516004274, 1.1259560878253827, 1.1252564362391015, 1.130227607162819, 1.010959143040648, 0.9767482915108611, 1.010662754632269, 0.9439457062739651, 1.092846916227862, 0.88260758632249, 1.034219882495917, 0.9792656145295147, 0.8395590487017126, 1.1594282565009555, 1.1904856190804116, 1.1180727527839194, 0.9750297380030347, 0.9771650619445507, 0.9670084525151268, 1.0299075280355103, 1.0838702700529068, 0.9245585645893379, 0.9756124376100742, 1.0149610941433063, 0.9855601952390272, 0.9327293843318412, 1.2243208971437534, 1.0737274588112662, 1.0271859933709024, 1.0130268701403087, 0.9427540014794402, 0.9509414430599887, 1.1657033917221609, 2.2457181232535186, 1.0704845561858543, 1.1130113714760905, 0.9779628517160078, 1.0831104800632145, 1.0583372533896345, 1.0592169238440095, 0.973139620287242], 'val_acc': [0.9404918861925794, 0.9538887258127955, 0.9521335505212618, 0.9545689089121926, 0.9524023030731839, 0.9520586347656618, 0.9552051030171262, 0.9516186601096027, 0.9543703068107654, 0.9468870713013161, 0.953132418765899, 0.9512928469388048, 0.9509063591144475, 0.9548162472976366, 0.953634264001509, 0.954854314925203, 0.9554809636625063, 0.9562777012490766, 0.9550148547653984, 0.9445527903136717, 0.9541527172760181, 0.9536152148553413, 0.9558020586752815, 0.9529493048643376, 0.9543465404648489, 0.9524153756558703, 0.9570173494685501, 0.953352415676669, 0.9541194076706743, 0.9543061078169721, 0.9550172241937692, 0.9546319267374143, 0.9543489175594121, 0.9492391798273927, 0.9514735871955896, 0.9552764419190753, 0.9554833576226924, 0.9543703399670469, 0.9546129130473857, 0.9541051464448788, 0.9516412431787448, 0.9535878779803825, 0.9537008429646875, 0.9533250688356601, 0.9520812375752489, 0.9522084726014705, 0.9492046903950608, 0.9529611861207478, 0.9532584705153462, 0.955197968475305, 0.9489537987295071, 0.9524034894164353, 0.9546759364305969, 0.9501702829572549, 0.952687682637831, 0.954938731776173, 0.952510513485053, 0.955255042893327, 0.955285978087275, 0.9531003307682908, 0.9556653106710918, 0.9539731528214703, 0.9555226142766775, 0.9519694418769175, 0.9535462463400372, 0.9557949210669834, 0.9529207527062518, 0.9532335069018545, 0.9529421747305769, 0.9540885086994846, 0.9540242907318655, 0.9541455758346239, 0.9527019553629148, 0.9529457364434981, 0.9527316948225261, 0.9533595680423872, 0.9529754705367748, 0.9548673926825691, 0.9523868426632651, 0.9524486864111431, 0.952671043742508, 0.95307654391531, 0.9542097955271363, 0.9550635958407853, 0.9534677652300746, 0.9501750451958831, 0.9542763800483042, 0.9515841800683564, 0.950899232813783, 0.9526960023729748, 0.9538197500146087, 0.952606827691437, 0.9548650150130416, 0.9537959802189058, 0.955293101896427, 0.9540647174384433, 0.9545855690811992, 0.9519980057259465, 0.9500002397218318, 0.9550207745990569, 0.952814927246793, 0.9545819962522991, 0.9541336878702955, 0.954078987288705, 0.9526686630065034, 0.9528969762026306], 'val_mDice': [0.3670380681908878, 0.5956375852850089, 0.5541784647385024, 0.6010149717330933, 0.6010408837024805, 0.5834942598530717, 0.5829894470344402, 0.5990532729595037, 0.5935910642147064, 0.48096942235610873, 0.5941189883031263, 0.5930354093048733, 0.5971585792456409, 0.5790326574224368, 0.5998711692846089, 0.5938786727247514, 0.5976135624374991, 0.59632264628671, 0.6019368382991318, 0.4582546066816213, 0.5979721862882663, 0.5958258608338151, 0.5763713840598845, 0.5882653357323343, 0.5933997244888564, 0.5904970009993894, 0.5778898861247244, 0.6013171798354943, 0.5998007699224344, 0.5987573634006587, 0.5803795633208714, 0.5806065807388526, 0.602596379840489, 0.5869652981064327, 0.559074205600947, 0.5582633573334317, 0.5995756559241623, 0.5878635789612099, 0.5740061308889144, 0.5963224470615387, 0.5941701714440557, 0.5988647264108014, 0.5962811025200933, 0.5987680685673495, 0.6010032129920181, 0.591247425968624, 0.5212826822731655, 0.5948464199661059, 0.6005163838625721, 0.601644454326277, 0.500505739182138, 0.5949128461804037, 0.5920910654152322, 0.5958058934215564, 0.5965063168017427, 0.5990001628732374, 0.5959501989976386, 0.5946083481863764, 0.5672851911120093, 0.5917046795512318, 0.5833345697623741, 0.5760883955806014, 0.5490171490566523, 0.5965106114984708, 0.5982492087450825, 0.6031849342622941, 0.6017179388037832, 0.6012316646587427, 0.5935066576651822, 0.5933091257641936, 0.5930435860176179, 0.5943739989179507, 0.5922763832512392, 0.5962993535677337, 0.5984261799663593, 0.5971455416878704, 0.5913428357559768, 0.5927843130478139, 0.5950896894241836, 0.591374723713881, 0.5959541127325254, 0.598528139269237, 0.593777782568211, 0.5949140151309814, 0.5926259504541324, 0.5888237650371441, 0.5843628722084296, 0.5925117274955921, 0.5915415434112886, 0.5918240982715723, 0.5991797930174702, 0.5847494711925746, 0.5913970774201335, 0.5982628157092827, 0.5992905921587224, 0.5986813600519463, 0.5976575906253704, 0.5894922650991146, 0.5041183401917338, 0.5906769596878738, 0.5978421584202929, 0.589511288755193, 0.5995166928438511, 0.596216021243399, 0.593463592494799, 0.5934305602139599], 'loss': [1.3998416875554736, 0.5099237639754879, 0.45105100974251505, 0.4213399440973478, 0.4107830316822027, 0.40316952924596133, 0.39713553113900796, 0.37002209101535116, 0.375689681290736, 0.3803267590888449, 0.38092989146304923, 0.36102086282754303, 0.3549004336239209, 0.35111839593107563, 0.3659659943755801, 0.34761396827828606, 0.3582459664179463, 0.3548722629720885, 0.34173074128107883, 0.36553592570554755, 0.3579316633962607, 0.3459067009180547, 0.3370517155929947, 0.3247839977393709, 0.33509688824635053, 0.3383408115391325, 0.3442570920907209, 0.32593381657259907, 0.3208073214219713, 0.3186756987844677, 0.31562201111989935, 0.31821711008335574, 0.30801832542267477, 0.3319879929799181, 0.3344070836396019, 0.31048791208566906, 0.3154695647045658, 0.3094412616728048, 0.3325514773609857, 0.3147829217381729, 0.305013756391115, 0.29527693045951864, 0.31054719300282746, 0.29013713555865034, 0.29638643714487467, 0.3068868923975184, 0.2982983381461872, 0.30813273419915976, 0.3040128331526995, 0.31177559680522243, 0.2925691776797637, 0.3099350750129741, 0.3036504243372745, 0.29622340362379423, 0.30677913756770137, 0.2955840589744076, 0.2865304272587794, 0.2817119314681819, 0.2898459832606396, 0.30718307644260706, 0.2941902735638527, 0.284030967790773, 0.31947479687035346, 0.2999339340868584, 0.3030756551736081, 0.28791794831614187, 0.2799568651048931, 0.29094954428155007, 0.2939406325152997, 0.2880020875535415, 0.2813806427056264, 0.2893521294951896, 0.28192542572927604, 0.28851071004496104, 0.30111326083351847, 0.2886201872713765, 0.27591911004018066, 0.2735978857311537, 0.30895143990919066, 0.29084295358021867, 0.2839294150273826, 0.2798487509324087, 0.2747805098774652, 0.270461430808864, 0.267418573250212, 0.27259943767718137, 0.27132332830627465, 0.2769279819862369, 0.2706328255214252, 0.2808573149094085, 0.2790934681523054, 0.31523664812311447, 0.30622792071598265, 0.27314496266345917, 0.2738532306223571, 0.2788544246653745, 0.2775302186463216, 0.27729338983512974, 0.274460783985098, 0.28503728954972823, 0.2678034485054776, 0.26840053274941744, 0.2758851912335401, 0.28369864500458875, 0.26723521982156695, 0.2660398500160539], 'acc': [0.8211555493218942, 0.9330899800372074, 0.9398832771059826, 0.9428395853875555, 0.9442139642363138, 0.944775780329278, 0.9455686790924152, 0.9468609498256988, 0.9469476391094981, 0.9463523874841422, 0.9461661126452514, 0.9480016054604813, 0.9483836049631164, 0.9485018318049075, 0.9478804778827612, 0.9486637938230148, 0.9478492048434642, 0.9482841057459419, 0.9494876198165006, 0.9469371615837865, 0.9484654713359404, 0.9491409517101357, 0.9496312027977927, 0.9500944362378958, 0.949340037115558, 0.9495159474119883, 0.9493134108114538, 0.9496329471965778, 0.9501185085823417, 0.95032925073219, 0.950594879737397, 0.9508450822198451, 0.9510585726380313, 0.949570508561116, 0.94954095767219, 0.9506560782304236, 0.9504510329233296, 0.9509694178957755, 0.9489700402718232, 0.9504411901721352, 0.9510125006219566, 0.9514579656870537, 0.9514266045334839, 0.9518138442499583, 0.9516990871055178, 0.951438805827633, 0.9512357051374638, 0.9513341760382114, 0.9516402920567908, 0.9513230671851675, 0.9519285966281379, 0.9506130371518668, 0.9510118224762224, 0.9517253656308536, 0.9513502174789978, 0.9514334150632597, 0.952156036925126, 0.9522740002507198, 0.9518896630465299, 0.950444702677897, 0.9519728839520544, 0.9522162497694354, 0.9505975643910993, 0.9511171049268311, 0.9509418757132775, 0.9520681245413527, 0.9524865294142999, 0.951669689545979, 0.9516762381952116, 0.9523369639839314, 0.9526625912813494, 0.9521379666751941, 0.9524007353609591, 0.9525653176794505, 0.9511249633305331, 0.9518541545071549, 0.9527521798237125, 0.9529105424705104, 0.9512145545989864, 0.9522109903850258, 0.9525713851473683, 0.9528272618724027, 0.9530177476062083, 0.9530264130029822, 0.9532474103526895, 0.9528605210531352, 0.9531522773472247, 0.9530495888682444, 0.9531652399768306, 0.9529487803538804, 0.9528892206280377, 0.9502212616081046, 0.9505813925024963, 0.9525549952594816, 0.9530106968287346, 0.9529045859280854, 0.9531266519403556, 0.9530750358481083, 0.9528940001853837, 0.9526557359733424, 0.9533010335157107, 0.9534602230824212, 0.9532764804648172, 0.9526376226863597, 0.9529457469364998, 0.9534293643209075], 'mDice': [0.3429471807712104, 0.5934405749826946, 0.6291190684105521, 0.6484795332517762, 0.6586179064944558, 0.6604295022792259, 0.6669776650367145, 0.6793524119030167, 0.6804158263728485, 0.6765566232036299, 0.6764095506157345, 0.689804443112866, 0.6939710095133462, 0.6960202853705687, 0.6905404535427527, 0.6976736069218041, 0.6921359766335148, 0.6943380279715485, 0.7057715799647399, 0.6881248180090273, 0.6945619938576879, 0.7036518002020711, 0.7075393552377746, 0.7131843601014629, 0.7074303446916326, 0.7073245221761589, 0.7076018269556608, 0.7105863894569238, 0.7150054795969267, 0.7181929941372943, 0.7198046802348815, 0.7245417160951272, 0.7250333612877629, 0.7113479506867444, 0.7113102114140794, 0.7219432658521642, 0.7207192886575692, 0.7247168419810656, 0.7092756376958731, 0.7231337337516409, 0.7273043486775814, 0.7322110910090629, 0.7307916691993394, 0.7358378655406077, 0.7342035600167525, 0.732127361204041, 0.7309465734049014, 0.7285594262356391, 0.7332653925987991, 0.728703695927865, 0.7365621566139304, 0.72306860217868, 0.7297754871454799, 0.7361990481254519, 0.7320400884138092, 0.7335798418884187, 0.7411371560074228, 0.7425765777520635, 0.7373634658052564, 0.7263938896984574, 0.7373533489324942, 0.7417233276944063, 0.725897264501696, 0.7289065600813367, 0.7285868299855142, 0.7395783862767933, 0.7436811982371808, 0.7363922706780162, 0.7363096674517848, 0.7422306646320032, 0.7452081861521298, 0.74055151047345, 0.7438231457577725, 0.7445306174872582, 0.732805676202079, 0.7385952194625559, 0.7470719666915786, 0.7487080680230052, 0.7298171982964994, 0.7400327713027328, 0.7458221826732035, 0.7485245593918851, 0.7499224585957779, 0.750899808074071, 0.7532396811093859, 0.7507112764017742, 0.7522591972252584, 0.7507353609696571, 0.7513069263353007, 0.7487007726185018, 0.7480620247454515, 0.7266090568732146, 0.728447090914623, 0.7485952105765569, 0.7510442334172577, 0.7498269627916668, 0.753397037969574, 0.7513568991755061, 0.750226394340119, 0.7455324349624283, 0.7557264103513792, 0.7565272257334364, 0.7539510471555609, 0.7474990733677956, 0.7532276116876554, 0.7563327087980345]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:03<00:12,  3.25s/it]predicting test subjects:  40%|████      | 2/5 [00:05<00:09,  3.07s/it]predicting test subjects:  60%|██████    | 3/5 [00:08<00:05,  2.83s/it]predicting test subjects:  80%|████████  | 4/5 [00:10<00:02,  2.69s/it]predicting test subjects: 100%|██████████| 5/5 [00:13<00:00,  2.74s/it]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:03<14:21,  3.25s/it]predicting train subjects:   1%|          | 2/266 [00:06<13:39,  3.10s/it]predicting train subjects:   1%|          | 3/266 [00:08<12:51,  2.94s/it]predicting train subjects:   2%|▏         | 4/266 [00:10<12:06,  2.77s/it]predicting train subjects:   2%|▏         | 5/266 [00:14<12:32,  2.88s/it]predicting train subjects:   2%|▏         | 6/266 [00:17<13:09,  3.04s/it]predicting train subjects:   3%|▎         | 7/266 [00:20<13:20,  3.09s/it]predicting train subjects:   3%|▎         | 8/266 [00:24<13:45,  3.20s/it]predicting train subjects:   3%|▎         | 9/266 [00:27<13:57,  3.26s/it]predicting train subjects:   4%|▍         | 10/266 [00:30<13:52,  3.25s/it]predicting train subjects:   4%|▍         | 11/266 [00:34<14:04,  3.31s/it]predicting train subjects:   5%|▍         | 12/266 [00:37<13:56,  3.29s/it]predicting train subjects:   5%|▍         | 13/266 [00:40<13:47,  3.27s/it]predicting train subjects:   5%|▌         | 14/266 [00:44<13:46,  3.28s/it]predicting train subjects:   6%|▌         | 15/266 [00:47<13:49,  3.30s/it]predicting train subjects:   6%|▌         | 16/266 [00:50<13:47,  3.31s/it]predicting train subjects:   6%|▋         | 17/266 [00:53<13:32,  3.26s/it]predicting train subjects:   7%|▋         | 18/266 [00:57<13:21,  3.23s/it]predicting train subjects:   7%|▋         | 19/266 [01:00<13:14,  3.22s/it]predicting train subjects:   8%|▊         | 20/266 [01:03<13:12,  3.22s/it]predicting train subjects:   8%|▊         | 21/266 [01:06<13:12,  3.23s/it]predicting train subjects:   8%|▊         | 22/266 [01:10<13:19,  3.28s/it]predicting train subjects:   9%|▊         | 23/266 [01:13<13:26,  3.32s/it]predicting train subjects:   9%|▉         | 24/266 [01:16<13:00,  3.23s/it]predicting train subjects:   9%|▉         | 25/266 [01:19<12:49,  3.19s/it]predicting train subjects:  10%|▉         | 26/266 [01:22<12:32,  3.13s/it]predicting train subjects:  10%|█         | 27/266 [01:25<12:19,  3.09s/it]predicting train subjects:  11%|█         | 28/266 [01:28<12:32,  3.16s/it]predicting train subjects:  11%|█         | 29/266 [01:31<12:21,  3.13s/it]predicting train subjects:  11%|█▏        | 30/266 [01:34<12:09,  3.09s/it]predicting train subjects:  12%|█▏        | 31/266 [01:37<11:49,  3.02s/it]predicting train subjects:  12%|█▏        | 32/266 [01:41<12:08,  3.11s/it]predicting train subjects:  12%|█▏        | 33/266 [01:43<11:41,  3.01s/it]predicting train subjects:  13%|█▎        | 34/266 [01:46<11:25,  2.96s/it]predicting train subjects:  13%|█▎        | 35/266 [01:49<11:18,  2.94s/it]predicting train subjects:  14%|█▎        | 36/266 [01:52<11:18,  2.95s/it]predicting train subjects:  14%|█▍        | 37/266 [01:55<10:47,  2.83s/it]predicting train subjects:  14%|█▍        | 38/266 [01:57<10:24,  2.74s/it]predicting train subjects:  15%|█▍        | 39/266 [02:00<10:11,  2.70s/it]predicting train subjects:  15%|█▌        | 40/266 [02:02<10:04,  2.67s/it]predicting train subjects:  15%|█▌        | 41/266 [02:05<10:05,  2.69s/it]predicting train subjects:  16%|█▌        | 42/266 [02:07<09:37,  2.58s/it]predicting train subjects:  16%|█▌        | 43/266 [02:10<09:25,  2.54s/it]predicting train subjects:  17%|█▋        | 44/266 [02:12<09:07,  2.47s/it]predicting train subjects:  17%|█▋        | 45/266 [02:15<08:54,  2.42s/it]predicting train subjects:  17%|█▋        | 46/266 [02:17<08:30,  2.32s/it]predicting train subjects:  18%|█▊        | 47/266 [02:19<08:25,  2.31s/it]predicting train subjects:  18%|█▊        | 48/266 [02:21<08:13,  2.27s/it]predicting train subjects:  18%|█▊        | 49/266 [02:23<08:10,  2.26s/it]predicting train subjects:  19%|█▉        | 50/266 [02:26<08:05,  2.25s/it]predicting train subjects:  19%|█▉        | 51/266 [02:28<08:10,  2.28s/it]predicting train subjects:  20%|█▉        | 52/266 [02:30<08:03,  2.26s/it]predicting train subjects:  20%|█▉        | 53/266 [02:32<07:57,  2.24s/it]predicting train subjects:  20%|██        | 54/266 [02:34<07:48,  2.21s/it]predicting train subjects:  21%|██        | 55/266 [02:37<07:50,  2.23s/it]predicting train subjects:  21%|██        | 56/266 [02:39<07:46,  2.22s/it]predicting train subjects:  21%|██▏       | 57/266 [02:41<07:44,  2.22s/it]predicting train subjects:  22%|██▏       | 58/266 [02:43<07:38,  2.20s/it]predicting train subjects:  22%|██▏       | 59/266 [02:46<07:36,  2.21s/it]predicting train subjects:  23%|██▎       | 60/266 [02:48<07:25,  2.16s/it]predicting train subjects:  23%|██▎       | 61/266 [02:50<07:13,  2.12s/it]predicting train subjects:  23%|██▎       | 62/266 [02:52<07:04,  2.08s/it]predicting train subjects:  24%|██▎       | 63/266 [02:54<06:57,  2.06s/it]predicting train subjects:  24%|██▍       | 64/266 [02:56<07:01,  2.09s/it]predicting train subjects:  24%|██▍       | 65/266 [02:58<06:54,  2.06s/it]predicting train subjects:  25%|██▍       | 66/266 [03:00<06:52,  2.06s/it]predicting train subjects:  25%|██▌       | 67/266 [03:02<06:53,  2.08s/it]predicting train subjects:  26%|██▌       | 68/266 [03:04<06:50,  2.07s/it]predicting train subjects:  26%|██▌       | 69/266 [03:06<06:51,  2.09s/it]predicting train subjects:  26%|██▋       | 70/266 [03:08<06:46,  2.07s/it]predicting train subjects:  27%|██▋       | 71/266 [03:10<06:42,  2.06s/it]predicting train subjects:  27%|██▋       | 72/266 [03:12<06:37,  2.05s/it]predicting train subjects:  27%|██▋       | 73/266 [03:14<06:34,  2.05s/it]predicting train subjects:  28%|██▊       | 74/266 [03:16<06:35,  2.06s/it]predicting train subjects:  28%|██▊       | 75/266 [03:18<06:37,  2.08s/it]predicting train subjects:  29%|██▊       | 76/266 [03:20<06:30,  2.06s/it]predicting train subjects:  29%|██▉       | 77/266 [03:22<06:26,  2.04s/it]predicting train subjects:  29%|██▉       | 78/266 [03:25<06:58,  2.23s/it]predicting train subjects:  30%|██▉       | 79/266 [03:28<07:18,  2.34s/it]predicting train subjects:  30%|███       | 80/266 [03:30<07:33,  2.44s/it]predicting train subjects:  30%|███       | 81/266 [03:33<07:49,  2.54s/it]predicting train subjects:  31%|███       | 82/266 [03:36<07:51,  2.56s/it]predicting train subjects:  31%|███       | 83/266 [03:38<07:53,  2.59s/it]predicting train subjects:  32%|███▏      | 84/266 [03:41<07:51,  2.59s/it]predicting train subjects:  32%|███▏      | 85/266 [03:44<07:50,  2.60s/it]predicting train subjects:  32%|███▏      | 86/266 [03:46<07:47,  2.60s/it]predicting train subjects:  33%|███▎      | 87/266 [03:49<07:44,  2.59s/it]predicting train subjects:  33%|███▎      | 88/266 [03:51<07:38,  2.58s/it]predicting train subjects:  33%|███▎      | 89/266 [03:54<07:37,  2.59s/it]predicting train subjects:  34%|███▍      | 90/266 [03:57<07:37,  2.60s/it]predicting train subjects:  34%|███▍      | 91/266 [03:59<07:31,  2.58s/it]predicting train subjects:  35%|███▍      | 92/266 [04:02<07:30,  2.59s/it]predicting train subjects:  35%|███▍      | 93/266 [04:04<07:29,  2.60s/it]predicting train subjects:  35%|███▌      | 94/266 [04:07<07:28,  2.61s/it]predicting train subjects:  36%|███▌      | 95/266 [04:10<07:29,  2.63s/it]predicting train subjects:  36%|███▌      | 96/266 [04:12<07:15,  2.56s/it]predicting train subjects:  36%|███▋      | 97/266 [04:15<07:23,  2.63s/it]predicting train subjects:  37%|███▋      | 98/266 [04:17<07:21,  2.63s/it]predicting train subjects:  37%|███▋      | 99/266 [04:19<06:41,  2.41s/it]predicting train subjects:  38%|███▊      | 100/266 [04:22<06:25,  2.32s/it]predicting train subjects:  38%|███▊      | 101/266 [04:24<06:24,  2.33s/it]predicting train subjects:  38%|███▊      | 102/266 [04:26<06:21,  2.33s/it]predicting train subjects:  39%|███▊      | 103/266 [04:28<06:17,  2.31s/it]predicting train subjects:  39%|███▉      | 104/266 [04:31<06:13,  2.31s/it]predicting train subjects:  39%|███▉      | 105/266 [04:33<06:10,  2.30s/it]predicting train subjects:  40%|███▉      | 106/266 [04:35<06:11,  2.32s/it]predicting train subjects:  40%|████      | 107/266 [04:38<06:09,  2.32s/it]predicting train subjects:  41%|████      | 108/266 [04:40<06:07,  2.33s/it]predicting train subjects:  41%|████      | 109/266 [04:42<06:10,  2.36s/it]predicting train subjects:  41%|████▏     | 110/266 [04:45<06:08,  2.36s/it]predicting train subjects:  42%|████▏     | 111/266 [04:47<06:01,  2.33s/it]predicting train subjects:  42%|████▏     | 112/266 [04:49<05:59,  2.34s/it]predicting train subjects:  42%|████▏     | 113/266 [04:52<05:57,  2.33s/it]predicting train subjects:  43%|████▎     | 114/266 [04:54<05:52,  2.32s/it]predicting train subjects:  43%|████▎     | 115/266 [04:56<05:51,  2.33s/it]predicting train subjects:  44%|████▎     | 116/266 [04:59<05:46,  2.31s/it]predicting train subjects:  44%|████▍     | 117/266 [05:01<05:45,  2.32s/it]predicting train subjects:  44%|████▍     | 118/266 [05:03<05:43,  2.32s/it]predicting train subjects:  45%|████▍     | 119/266 [05:06<05:55,  2.42s/it]predicting train subjects:  45%|████▌     | 120/266 [05:09<06:02,  2.48s/it]predicting train subjects:  45%|████▌     | 121/266 [05:11<06:06,  2.53s/it]predicting train subjects:  46%|████▌     | 122/266 [05:14<06:12,  2.58s/it]predicting train subjects:  46%|████▌     | 123/266 [05:17<06:12,  2.61s/it]predicting train subjects:  47%|████▋     | 124/266 [05:19<06:09,  2.60s/it]predicting train subjects:  47%|████▋     | 125/266 [05:22<06:08,  2.61s/it]predicting train subjects:  47%|████▋     | 126/266 [05:24<06:04,  2.61s/it]predicting train subjects:  48%|████▊     | 127/266 [05:27<06:04,  2.62s/it]predicting train subjects:  48%|████▊     | 128/266 [05:30<05:59,  2.61s/it]predicting train subjects:  48%|████▊     | 129/266 [05:32<05:56,  2.60s/it]predicting train subjects:  49%|████▉     | 130/266 [05:35<05:56,  2.62s/it]predicting train subjects:  49%|████▉     | 131/266 [05:38<05:58,  2.66s/it]predicting train subjects:  50%|████▉     | 132/266 [05:40<05:55,  2.65s/it]predicting train subjects:  50%|█████     | 133/266 [05:43<05:52,  2.65s/it]predicting train subjects:  50%|█████     | 134/266 [05:46<05:48,  2.64s/it]predicting train subjects:  51%|█████     | 135/266 [05:48<05:44,  2.63s/it]predicting train subjects:  51%|█████     | 136/266 [05:51<05:42,  2.64s/it]predicting train subjects:  52%|█████▏    | 137/266 [05:53<05:37,  2.62s/it]predicting train subjects:  52%|█████▏    | 138/266 [05:56<05:32,  2.59s/it]predicting train subjects:  52%|█████▏    | 139/266 [05:58<05:25,  2.56s/it]predicting train subjects:  53%|█████▎    | 140/266 [06:01<05:23,  2.57s/it]predicting train subjects:  53%|█████▎    | 141/266 [06:04<05:21,  2.57s/it]predicting train subjects:  53%|█████▎    | 142/266 [06:06<05:21,  2.59s/it]predicting train subjects:  54%|█████▍    | 143/266 [06:09<05:18,  2.59s/it]predicting train subjects:  54%|█████▍    | 144/266 [06:11<05:15,  2.59s/it]predicting train subjects:  55%|█████▍    | 145/266 [06:14<05:13,  2.59s/it]predicting train subjects:  55%|█████▍    | 146/266 [06:17<05:10,  2.59s/it]predicting train subjects:  55%|█████▌    | 147/266 [06:19<05:06,  2.57s/it]predicting train subjects:  56%|█████▌    | 148/266 [06:22<05:02,  2.57s/it]predicting train subjects:  56%|█████▌    | 149/266 [06:24<04:56,  2.54s/it]predicting train subjects:  56%|█████▋    | 150/266 [06:27<04:56,  2.56s/it]predicting train subjects:  57%|█████▋    | 151/266 [06:29<04:55,  2.57s/it]predicting train subjects:  57%|█████▋    | 152/266 [06:32<04:52,  2.57s/it]predicting train subjects:  58%|█████▊    | 153/266 [06:35<04:51,  2.58s/it]predicting train subjects:  58%|█████▊    | 154/266 [06:37<04:50,  2.60s/it]predicting train subjects:  58%|█████▊    | 155/266 [06:39<04:27,  2.41s/it]predicting train subjects:  59%|█████▊    | 156/266 [06:41<04:10,  2.28s/it]predicting train subjects:  59%|█████▉    | 157/266 [06:43<03:59,  2.20s/it]predicting train subjects:  59%|█████▉    | 158/266 [06:45<03:49,  2.13s/it]predicting train subjects:  60%|█████▉    | 159/266 [06:47<03:41,  2.07s/it]predicting train subjects:  60%|██████    | 160/266 [06:49<03:34,  2.03s/it]predicting train subjects:  61%|██████    | 161/266 [06:51<03:29,  1.99s/it]predicting train subjects:  61%|██████    | 162/266 [06:53<03:25,  1.98s/it]predicting train subjects:  61%|██████▏   | 163/266 [06:55<03:22,  1.96s/it]predicting train subjects:  62%|██████▏   | 164/266 [06:57<03:21,  1.97s/it]predicting train subjects:  62%|██████▏   | 165/266 [06:59<03:15,  1.93s/it]predicting train subjects:  62%|██████▏   | 166/266 [07:00<03:12,  1.93s/it]predicting train subjects:  63%|██████▎   | 167/266 [07:03<03:14,  1.97s/it]predicting train subjects:  63%|██████▎   | 168/266 [07:04<03:12,  1.96s/it]predicting train subjects:  64%|██████▎   | 169/266 [07:06<03:07,  1.93s/it]predicting train subjects:  64%|██████▍   | 170/266 [07:08<03:05,  1.94s/it]predicting train subjects:  64%|██████▍   | 171/266 [07:10<03:02,  1.92s/it]predicting train subjects:  65%|██████▍   | 172/266 [07:12<02:59,  1.91s/it]predicting train subjects:  65%|██████▌   | 173/266 [07:14<03:04,  1.99s/it]predicting train subjects:  65%|██████▌   | 174/266 [07:16<03:07,  2.04s/it]predicting train subjects:  66%|██████▌   | 175/266 [07:19<03:09,  2.08s/it]predicting train subjects:  66%|██████▌   | 176/266 [07:21<03:11,  2.13s/it]predicting train subjects:  67%|██████▋   | 177/266 [07:23<03:07,  2.11s/it]predicting train subjects:  67%|██████▋   | 178/266 [07:25<03:06,  2.12s/it]predicting train subjects:  67%|██████▋   | 179/266 [07:27<03:04,  2.12s/it]predicting train subjects:  68%|██████▊   | 180/266 [07:29<03:02,  2.13s/it]predicting train subjects:  68%|██████▊   | 181/266 [07:31<02:59,  2.11s/it]predicting train subjects:  68%|██████▊   | 182/266 [07:34<02:59,  2.14s/it]predicting train subjects:  69%|██████▉   | 183/266 [07:36<02:56,  2.13s/it]predicting train subjects:  69%|██████▉   | 184/266 [07:38<02:53,  2.12s/it]predicting train subjects:  70%|██████▉   | 185/266 [07:40<02:51,  2.12s/it]predicting train subjects:  70%|██████▉   | 186/266 [07:42<02:50,  2.13s/it]predicting train subjects:  70%|███████   | 187/266 [07:44<02:49,  2.14s/it]predicting train subjects:  71%|███████   | 188/266 [07:46<02:47,  2.15s/it]predicting train subjects:  71%|███████   | 189/266 [07:48<02:43,  2.12s/it]predicting train subjects:  71%|███████▏  | 190/266 [07:51<02:40,  2.12s/it]predicting train subjects:  72%|███████▏  | 191/266 [07:53<02:42,  2.17s/it]predicting train subjects:  72%|███████▏  | 192/266 [07:55<02:37,  2.13s/it]predicting train subjects:  73%|███████▎  | 193/266 [07:57<02:36,  2.14s/it]predicting train subjects:  73%|███████▎  | 194/266 [08:00<02:43,  2.27s/it]predicting train subjects:  73%|███████▎  | 195/266 [08:02<02:41,  2.28s/it]predicting train subjects:  74%|███████▎  | 196/266 [08:04<02:39,  2.28s/it]predicting train subjects:  74%|███████▍  | 197/266 [08:06<02:36,  2.27s/it]predicting train subjects:  74%|███████▍  | 198/266 [08:09<02:34,  2.27s/it]predicting train subjects:  75%|███████▍  | 199/266 [08:11<02:32,  2.27s/it]predicting train subjects:  75%|███████▌  | 200/266 [08:13<02:29,  2.26s/it]predicting train subjects:  76%|███████▌  | 201/266 [08:15<02:26,  2.25s/it]predicting train subjects:  76%|███████▌  | 202/266 [08:18<02:24,  2.26s/it]predicting train subjects:  76%|███████▋  | 203/266 [08:20<02:23,  2.27s/it]predicting train subjects:  77%|███████▋  | 204/266 [08:22<02:21,  2.28s/it]predicting train subjects:  77%|███████▋  | 205/266 [08:25<02:18,  2.27s/it]predicting train subjects:  77%|███████▋  | 206/266 [08:27<02:14,  2.24s/it]predicting train subjects:  78%|███████▊  | 207/266 [08:29<02:13,  2.26s/it]predicting train subjects:  78%|███████▊  | 208/266 [08:31<02:11,  2.27s/it]predicting train subjects:  79%|███████▊  | 209/266 [08:34<02:08,  2.26s/it]predicting train subjects:  79%|███████▉  | 210/266 [08:36<02:05,  2.24s/it]predicting train subjects:  79%|███████▉  | 211/266 [08:38<02:03,  2.24s/it]predicting train subjects:  80%|███████▉  | 212/266 [08:40<02:02,  2.27s/it]predicting train subjects:  80%|████████  | 213/266 [08:42<01:55,  2.19s/it]predicting train subjects:  80%|████████  | 214/266 [08:44<01:51,  2.15s/it]predicting train subjects:  81%|████████  | 215/266 [08:46<01:48,  2.12s/it]predicting train subjects:  81%|████████  | 216/266 [08:49<01:45,  2.10s/it]predicting train subjects:  82%|████████▏ | 217/266 [08:51<01:42,  2.09s/it]predicting train subjects:  82%|████████▏ | 218/266 [08:53<01:39,  2.07s/it]predicting train subjects:  82%|████████▏ | 219/266 [08:55<01:36,  2.05s/it]predicting train subjects:  83%|████████▎ | 220/266 [08:57<01:34,  2.04s/it]predicting train subjects:  83%|████████▎ | 221/266 [08:59<01:31,  2.04s/it]predicting train subjects:  83%|████████▎ | 222/266 [09:01<01:28,  2.01s/it]predicting train subjects:  84%|████████▍ | 223/266 [09:03<01:26,  2.00s/it]predicting train subjects:  84%|████████▍ | 224/266 [09:05<01:24,  2.01s/it]predicting train subjects:  85%|████████▍ | 225/266 [09:07<01:22,  2.01s/it]predicting train subjects:  85%|████████▍ | 226/266 [09:09<01:20,  2.02s/it]predicting train subjects:  85%|████████▌ | 227/266 [09:11<01:19,  2.03s/it]predicting train subjects:  86%|████████▌ | 228/266 [09:13<01:17,  2.03s/it]predicting train subjects:  86%|████████▌ | 229/266 [09:15<01:15,  2.04s/it]predicting train subjects:  86%|████████▋ | 230/266 [09:17<01:13,  2.05s/it]predicting train subjects:  87%|████████▋ | 231/266 [09:19<01:12,  2.06s/it]predicting train subjects:  87%|████████▋ | 232/266 [09:21<01:10,  2.07s/it]predicting train subjects:  88%|████████▊ | 233/266 [09:23<01:08,  2.07s/it]predicting train subjects:  88%|████████▊ | 234/266 [09:25<01:06,  2.08s/it]predicting train subjects:  88%|████████▊ | 235/266 [09:27<01:04,  2.08s/it]predicting train subjects:  89%|████████▊ | 236/266 [09:29<01:02,  2.09s/it]predicting train subjects:  89%|████████▉ | 237/266 [09:32<01:00,  2.09s/it]predicting train subjects:  89%|████████▉ | 238/266 [09:34<00:58,  2.08s/it]predicting train subjects:  90%|████████▉ | 239/266 [09:36<00:56,  2.10s/it]predicting train subjects:  90%|█████████ | 240/266 [09:38<00:54,  2.09s/it]predicting train subjects:  91%|█████████ | 241/266 [09:40<00:53,  2.12s/it]predicting train subjects:  91%|█████████ | 242/266 [09:42<00:50,  2.11s/it]predicting train subjects:  91%|█████████▏| 243/266 [09:44<00:48,  2.10s/it]predicting train subjects:  92%|█████████▏| 244/266 [09:46<00:46,  2.10s/it]predicting train subjects:  92%|█████████▏| 245/266 [09:48<00:44,  2.10s/it]predicting train subjects:  92%|█████████▏| 246/266 [09:50<00:41,  2.09s/it]predicting train subjects:  93%|█████████▎| 247/266 [09:52<00:39,  2.07s/it]predicting train subjects:  93%|█████████▎| 248/266 [09:54<00:37,  2.06s/it]predicting train subjects:  94%|█████████▎| 249/266 [09:57<00:37,  2.23s/it]predicting train subjects:  94%|█████████▍| 250/266 [10:00<00:37,  2.34s/it]predicting train subjects:  94%|█████████▍| 251/266 [10:02<00:36,  2.45s/it]predicting train subjects:  95%|█████████▍| 252/266 [10:05<00:35,  2.54s/it]predicting train subjects:  95%|█████████▌| 253/266 [10:08<00:33,  2.55s/it]predicting train subjects:  95%|█████████▌| 254/266 [10:10<00:30,  2.58s/it]predicting train subjects:  96%|█████████▌| 255/266 [10:13<00:28,  2.60s/it]predicting train subjects:  96%|█████████▌| 256/266 [10:16<00:25,  2.60s/it]predicting train subjects:  97%|█████████▋| 257/266 [10:18<00:23,  2.60s/it]predicting train subjects:  97%|█████████▋| 258/266 [10:21<00:20,  2.61s/it]predicting train subjects:  97%|█████████▋| 259/266 [10:24<00:18,  2.64s/it]predicting train subjects:  98%|█████████▊| 260/266 [10:26<00:15,  2.65s/it]predicting train subjects:  98%|█████████▊| 261/266 [10:29<00:13,  2.64s/it]predicting train subjects:  98%|█████████▊| 262/266 [10:32<00:10,  2.64s/it]predicting train subjects:  99%|█████████▉| 263/266 [10:34<00:07,  2.66s/it]predicting train subjects:  99%|█████████▉| 264/266 [10:37<00:05,  2.71s/it]predicting train subjects: 100%|█████████▉| 265/266 [10:40<00:02,  2.72s/it]predicting train subjects: 100%|██████████| 266/266 [10:43<00:00,  2.78s/it]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:02<09:09,  2.07s/it]Loading train:   1%|          | 2/266 [00:03<08:40,  1.97s/it]Loading train:   1%|          | 3/266 [00:05<08:17,  1.89s/it]Loading train:   2%|▏         | 4/266 [00:06<07:30,  1.72s/it]Loading train:   2%|▏         | 5/266 [00:08<07:26,  1.71s/it]Loading train:   2%|▏         | 6/266 [00:09<06:55,  1.60s/it]Loading train:   3%|▎         | 7/266 [00:11<06:22,  1.48s/it]Loading train:   3%|▎         | 8/266 [00:12<05:56,  1.38s/it]Loading train:   3%|▎         | 9/266 [00:13<05:37,  1.31s/it]Loading train:   4%|▍         | 10/266 [00:14<05:34,  1.31s/it]Loading train:   4%|▍         | 11/266 [00:15<05:20,  1.26s/it]Loading train:   5%|▍         | 12/266 [00:17<05:27,  1.29s/it]Loading train:   5%|▍         | 13/266 [00:18<05:20,  1.27s/it]Loading train:   5%|▌         | 14/266 [00:19<05:00,  1.19s/it]Loading train:   6%|▌         | 15/266 [00:20<04:55,  1.18s/it]Loading train:   6%|▌         | 16/266 [00:21<04:59,  1.20s/it]Loading train:   6%|▋         | 17/266 [00:22<04:49,  1.16s/it]Loading train:   7%|▋         | 18/266 [00:24<04:55,  1.19s/it]Loading train:   7%|▋         | 19/266 [00:25<04:57,  1.20s/it]Loading train:   8%|▊         | 20/266 [00:26<04:57,  1.21s/it]Loading train:   8%|▊         | 21/266 [00:27<04:58,  1.22s/it]Loading train:   8%|▊         | 22/266 [00:28<04:54,  1.21s/it]Loading train:   9%|▊         | 23/266 [00:30<05:00,  1.24s/it]Loading train:   9%|▉         | 24/266 [00:31<04:54,  1.22s/it]Loading train:   9%|▉         | 25/266 [00:32<04:44,  1.18s/it]Loading train:  10%|▉         | 26/266 [00:33<04:33,  1.14s/it]Loading train:  10%|█         | 27/266 [00:34<04:25,  1.11s/it]Loading train:  11%|█         | 28/266 [00:35<04:19,  1.09s/it]Loading train:  11%|█         | 29/266 [00:36<04:31,  1.15s/it]Loading train:  11%|█▏        | 30/266 [00:38<04:26,  1.13s/it]Loading train:  12%|█▏        | 31/266 [00:39<04:40,  1.19s/it]Loading train:  12%|█▏        | 32/266 [00:40<04:43,  1.21s/it]Loading train:  12%|█▏        | 33/266 [00:41<04:32,  1.17s/it]Loading train:  13%|█▎        | 34/266 [00:42<04:27,  1.15s/it]Loading train:  13%|█▎        | 35/266 [00:44<04:27,  1.16s/it]Loading train:  14%|█▎        | 36/266 [00:45<04:21,  1.14s/it]Loading train:  14%|█▍        | 37/266 [00:46<04:18,  1.13s/it]Loading train:  14%|█▍        | 38/266 [00:47<04:38,  1.22s/it]Loading train:  15%|█▍        | 39/266 [00:48<04:29,  1.19s/it]Loading train:  15%|█▌        | 40/266 [00:49<04:20,  1.15s/it]Loading train:  15%|█▌        | 41/266 [00:51<04:31,  1.21s/it]Loading train:  16%|█▌        | 42/266 [00:52<04:23,  1.18s/it]Loading train:  16%|█▌        | 43/266 [00:53<04:09,  1.12s/it]Loading train:  17%|█▋        | 44/266 [00:54<04:05,  1.11s/it]Loading train:  17%|█▋        | 45/266 [00:55<03:55,  1.07s/it]Loading train:  17%|█▋        | 46/266 [00:56<03:47,  1.04s/it]Loading train:  18%|█▊        | 47/266 [00:57<03:51,  1.06s/it]Loading train:  18%|█▊        | 48/266 [00:58<03:51,  1.06s/it]Loading train:  18%|█▊        | 49/266 [00:59<03:56,  1.09s/it]Loading train:  19%|█▉        | 50/266 [01:00<03:46,  1.05s/it]Loading train:  19%|█▉        | 51/266 [01:01<03:42,  1.04s/it]Loading train:  20%|█▉        | 52/266 [01:02<03:34,  1.00s/it]Loading train:  20%|█▉        | 53/266 [01:03<03:29,  1.02it/s]Loading train:  20%|██        | 54/266 [01:04<03:32,  1.00s/it]Loading train:  21%|██        | 55/266 [01:05<03:37,  1.03s/it]Loading train:  21%|██        | 56/266 [01:06<03:37,  1.03s/it]Loading train:  21%|██▏       | 57/266 [01:07<03:27,  1.01it/s]Loading train:  22%|██▏       | 58/266 [01:08<03:27,  1.00it/s]Loading train:  22%|██▏       | 59/266 [01:09<03:24,  1.01it/s]Loading train:  23%|██▎       | 60/266 [01:10<03:20,  1.03it/s]Loading train:  23%|██▎       | 61/266 [01:11<03:14,  1.06it/s]Loading train:  23%|██▎       | 62/266 [01:12<03:10,  1.07it/s]Loading train:  24%|██▎       | 63/266 [01:13<03:16,  1.03it/s]Loading train:  24%|██▍       | 64/266 [01:14<03:14,  1.04it/s]Loading train:  24%|██▍       | 65/266 [01:15<03:14,  1.03it/s]Loading train:  25%|██▍       | 66/266 [01:16<03:18,  1.01it/s]Loading train:  25%|██▌       | 67/266 [01:17<03:15,  1.02it/s]Loading train:  26%|██▌       | 68/266 [01:18<03:06,  1.06it/s]Loading train:  26%|██▌       | 69/266 [01:18<03:03,  1.07it/s]Loading train:  26%|██▋       | 70/266 [01:20<03:12,  1.02it/s]Loading train:  27%|██▋       | 71/266 [01:20<03:07,  1.04it/s]Loading train:  27%|██▋       | 72/266 [01:21<03:04,  1.05it/s]Loading train:  27%|██▋       | 73/266 [01:22<03:10,  1.01it/s]Loading train:  28%|██▊       | 74/266 [01:23<03:07,  1.03it/s]Loading train:  28%|██▊       | 75/266 [01:24<02:57,  1.08it/s]Loading train:  29%|██▊       | 76/266 [01:25<02:52,  1.10it/s]Loading train:  29%|██▉       | 77/266 [01:26<02:55,  1.08it/s]Loading train:  29%|██▉       | 78/266 [01:27<03:08,  1.00s/it]Loading train:  30%|██▉       | 79/266 [01:28<03:08,  1.01s/it]Loading train:  30%|███       | 80/266 [01:29<03:07,  1.01s/it]Loading train:  30%|███       | 81/266 [01:30<03:10,  1.03s/it]Loading train:  31%|███       | 82/266 [01:31<03:13,  1.05s/it]Loading train:  31%|███       | 83/266 [01:33<03:19,  1.09s/it]Loading train:  32%|███▏      | 84/266 [01:34<03:12,  1.06s/it]Loading train:  32%|███▏      | 85/266 [01:35<03:17,  1.09s/it]Loading train:  32%|███▏      | 86/266 [01:36<03:16,  1.09s/it]Loading train:  33%|███▎      | 87/266 [01:37<03:12,  1.08s/it]Loading train:  33%|███▎      | 88/266 [01:38<03:10,  1.07s/it]Loading train:  33%|███▎      | 89/266 [01:39<03:10,  1.08s/it]Loading train:  34%|███▍      | 90/266 [01:40<03:17,  1.12s/it]Loading train:  34%|███▍      | 91/266 [01:41<03:12,  1.10s/it]Loading train:  35%|███▍      | 92/266 [01:43<03:18,  1.14s/it]Loading train:  35%|███▍      | 93/266 [01:44<03:11,  1.11s/it]Loading train:  35%|███▌      | 94/266 [01:45<03:10,  1.11s/it]Loading train:  36%|███▌      | 95/266 [01:46<03:15,  1.14s/it]Loading train:  36%|███▌      | 96/266 [01:47<03:26,  1.21s/it]Loading train:  36%|███▋      | 97/266 [01:49<03:49,  1.36s/it]Loading train:  37%|███▋      | 98/266 [01:51<04:06,  1.47s/it]Loading train:  37%|███▋      | 99/266 [01:52<04:01,  1.44s/it]Loading train:  38%|███▊      | 100/266 [01:54<03:58,  1.44s/it]Loading train:  38%|███▊      | 101/266 [01:55<03:35,  1.30s/it]Loading train:  38%|███▊      | 102/266 [01:55<03:13,  1.18s/it]Loading train:  39%|███▊      | 103/266 [01:56<03:00,  1.11s/it]Loading train:  39%|███▉      | 104/266 [01:57<02:56,  1.09s/it]Loading train:  39%|███▉      | 105/266 [01:58<02:52,  1.07s/it]Loading train:  40%|███▉      | 106/266 [01:59<02:47,  1.05s/it]Loading train:  40%|████      | 107/266 [02:01<02:53,  1.09s/it]Loading train:  41%|████      | 108/266 [02:02<02:45,  1.05s/it]Loading train:  41%|████      | 109/266 [02:03<02:46,  1.06s/it]Loading train:  41%|████▏     | 110/266 [02:04<02:46,  1.06s/it]Loading train:  42%|████▏     | 111/266 [02:05<02:44,  1.06s/it]Loading train:  42%|████▏     | 112/266 [02:06<02:33,  1.00it/s]Loading train:  42%|████▏     | 113/266 [02:07<02:33,  1.00s/it]Loading train:  43%|████▎     | 114/266 [02:08<02:26,  1.04it/s]Loading train:  43%|████▎     | 115/266 [02:09<02:26,  1.03it/s]Loading train:  44%|████▎     | 116/266 [02:09<02:22,  1.05it/s]Loading train:  44%|████▍     | 117/266 [02:11<02:31,  1.02s/it]Loading train:  44%|████▍     | 118/266 [02:12<02:26,  1.01it/s]Loading train:  45%|████▍     | 119/266 [02:13<02:33,  1.05s/it]Loading train:  45%|████▌     | 120/266 [02:14<02:37,  1.08s/it]Loading train:  45%|████▌     | 121/266 [02:15<02:36,  1.08s/it]Loading train:  46%|████▌     | 122/266 [02:16<02:34,  1.07s/it]Loading train:  46%|████▌     | 123/266 [02:17<02:36,  1.09s/it]Loading train:  47%|████▋     | 124/266 [02:18<02:29,  1.05s/it]Loading train:  47%|████▋     | 125/266 [02:19<02:32,  1.08s/it]Loading train:  47%|████▋     | 126/266 [02:20<02:34,  1.10s/it]Loading train:  48%|████▊     | 127/266 [02:21<02:29,  1.08s/it]Loading train:  48%|████▊     | 128/266 [02:23<02:31,  1.09s/it]Loading train:  48%|████▊     | 129/266 [02:24<02:33,  1.12s/it]Loading train:  49%|████▉     | 130/266 [02:25<02:30,  1.11s/it]Loading train:  49%|████▉     | 131/266 [02:26<02:26,  1.08s/it]Loading train:  50%|████▉     | 132/266 [02:27<02:24,  1.07s/it]Loading train:  50%|█████     | 133/266 [02:28<02:21,  1.06s/it]Loading train:  50%|█████     | 134/266 [02:29<02:23,  1.08s/it]Loading train:  51%|█████     | 135/266 [02:30<02:22,  1.09s/it]Loading train:  51%|█████     | 136/266 [02:31<02:21,  1.09s/it]Loading train:  52%|█████▏    | 137/266 [02:32<02:22,  1.11s/it]Loading train:  52%|█████▏    | 138/266 [02:33<02:19,  1.09s/it]Loading train:  52%|█████▏    | 139/266 [02:35<02:20,  1.11s/it]Loading train:  53%|█████▎    | 140/266 [02:36<02:23,  1.14s/it]Loading train:  53%|█████▎    | 141/266 [02:37<02:24,  1.16s/it]Loading train:  53%|█████▎    | 142/266 [02:38<02:24,  1.16s/it]Loading train:  54%|█████▍    | 143/266 [02:39<02:23,  1.17s/it]Loading train:  54%|█████▍    | 144/266 [02:41<02:24,  1.19s/it]Loading train:  55%|█████▍    | 145/266 [02:42<02:22,  1.18s/it]Loading train:  55%|█████▍    | 146/266 [02:43<02:16,  1.14s/it]Loading train:  55%|█████▌    | 147/266 [02:44<02:15,  1.14s/it]Loading train:  56%|█████▌    | 148/266 [02:45<02:11,  1.12s/it]Loading train:  56%|█████▌    | 149/266 [02:46<02:16,  1.17s/it]Loading train:  56%|█████▋    | 150/266 [02:48<02:16,  1.18s/it]Loading train:  57%|█████▋    | 151/266 [02:49<02:13,  1.16s/it]Loading train:  57%|█████▋    | 152/266 [02:50<02:09,  1.13s/it]Loading train:  58%|█████▊    | 153/266 [02:51<02:06,  1.12s/it]Loading train:  58%|█████▊    | 154/266 [02:52<02:05,  1.12s/it]Loading train:  58%|█████▊    | 155/266 [02:53<01:58,  1.07s/it]Loading train:  59%|█████▊    | 156/266 [02:54<01:53,  1.04s/it]Loading train:  59%|█████▉    | 157/266 [02:55<01:53,  1.04s/it]Loading train:  59%|█████▉    | 158/266 [02:56<01:46,  1.02it/s]Loading train:  60%|█████▉    | 159/266 [02:56<01:36,  1.11it/s]Loading train:  60%|██████    | 160/266 [02:57<01:29,  1.18it/s]Loading train:  61%|██████    | 161/266 [02:58<01:23,  1.25it/s]Loading train:  61%|██████    | 162/266 [02:59<01:31,  1.14it/s]Loading train:  61%|██████▏   | 163/266 [03:00<01:31,  1.12it/s]Loading train:  62%|██████▏   | 164/266 [03:01<01:29,  1.13it/s]Loading train:  62%|██████▏   | 165/266 [03:02<01:28,  1.14it/s]Loading train:  62%|██████▏   | 166/266 [03:02<01:28,  1.13it/s]Loading train:  63%|██████▎   | 167/266 [03:03<01:26,  1.14it/s]Loading train:  63%|██████▎   | 168/266 [03:04<01:26,  1.14it/s]Loading train:  64%|██████▎   | 169/266 [03:05<01:25,  1.13it/s]Loading train:  64%|██████▍   | 170/266 [03:06<01:19,  1.20it/s]Loading train:  64%|██████▍   | 171/266 [03:07<01:16,  1.24it/s]Loading train:  65%|██████▍   | 172/266 [03:07<01:13,  1.28it/s]Loading train:  65%|██████▌   | 173/266 [03:08<01:12,  1.29it/s]Loading train:  65%|██████▌   | 174/266 [03:09<01:08,  1.34it/s]Loading train:  66%|██████▌   | 175/266 [03:09<01:06,  1.38it/s]Loading train:  66%|██████▌   | 176/266 [03:10<01:05,  1.37it/s]Loading train:  67%|██████▋   | 177/266 [03:11<01:03,  1.40it/s]Loading train:  67%|██████▋   | 178/266 [03:11<01:02,  1.41it/s]Loading train:  67%|██████▋   | 179/266 [03:12<01:02,  1.38it/s]Loading train:  68%|██████▊   | 180/266 [03:13<01:00,  1.41it/s]Loading train:  68%|██████▊   | 181/266 [03:14<01:03,  1.35it/s]Loading train:  68%|██████▊   | 182/266 [03:14<01:01,  1.37it/s]Loading train:  69%|██████▉   | 183/266 [03:15<01:01,  1.35it/s]Loading train:  69%|██████▉   | 184/266 [03:16<01:00,  1.35it/s]Loading train:  70%|██████▉   | 185/266 [03:17<00:58,  1.39it/s]Loading train:  70%|██████▉   | 186/266 [03:17<00:57,  1.39it/s]Loading train:  70%|███████   | 187/266 [03:18<00:55,  1.42it/s]Loading train:  71%|███████   | 188/266 [03:19<00:54,  1.42it/s]Loading train:  71%|███████   | 189/266 [03:19<00:54,  1.42it/s]Loading train:  71%|███████▏  | 190/266 [03:20<00:54,  1.39it/s]Loading train:  72%|███████▏  | 191/266 [03:21<01:04,  1.16it/s]Loading train:  72%|███████▏  | 192/266 [03:22<01:06,  1.11it/s]Loading train:  73%|███████▎  | 193/266 [03:23<01:07,  1.08it/s]Loading train:  73%|███████▎  | 194/266 [03:25<01:17,  1.08s/it]Loading train:  73%|███████▎  | 195/266 [03:26<01:12,  1.02s/it]Loading train:  74%|███████▎  | 196/266 [03:26<01:06,  1.05it/s]Loading train:  74%|███████▍  | 197/266 [03:27<01:02,  1.11it/s]Loading train:  74%|███████▍  | 198/266 [03:28<00:59,  1.15it/s]Loading train:  75%|███████▍  | 199/266 [03:29<00:55,  1.20it/s]Loading train:  75%|███████▌  | 200/266 [03:30<00:55,  1.18it/s]Loading train:  76%|███████▌  | 201/266 [03:31<00:56,  1.16it/s]Loading train:  76%|███████▌  | 202/266 [03:32<00:57,  1.12it/s]Loading train:  76%|███████▋  | 203/266 [03:32<00:53,  1.17it/s]Loading train:  77%|███████▋  | 204/266 [03:33<00:51,  1.19it/s]Loading train:  77%|███████▋  | 205/266 [03:34<00:50,  1.22it/s]Loading train:  77%|███████▋  | 206/266 [03:35<00:49,  1.21it/s]Loading train:  78%|███████▊  | 207/266 [03:36<00:49,  1.18it/s]Loading train:  78%|███████▊  | 208/266 [03:36<00:47,  1.23it/s]Loading train:  79%|███████▊  | 209/266 [03:37<00:47,  1.20it/s]Loading train:  79%|███████▉  | 210/266 [03:38<00:46,  1.21it/s]Loading train:  79%|███████▉  | 211/266 [03:39<00:44,  1.23it/s]Loading train:  80%|███████▉  | 212/266 [03:40<00:45,  1.18it/s]Loading train:  80%|████████  | 213/266 [03:41<00:44,  1.19it/s]Loading train:  80%|████████  | 214/266 [03:41<00:43,  1.21it/s]Loading train:  81%|████████  | 215/266 [03:42<00:41,  1.23it/s]Loading train:  81%|████████  | 216/266 [03:43<00:41,  1.21it/s]Loading train:  82%|████████▏ | 217/266 [03:44<00:40,  1.22it/s]Loading train:  82%|████████▏ | 218/266 [03:45<00:39,  1.23it/s]Loading train:  82%|████████▏ | 219/266 [03:45<00:39,  1.20it/s]Loading train:  83%|████████▎ | 220/266 [03:46<00:38,  1.21it/s]Loading train:  83%|████████▎ | 221/266 [03:47<00:36,  1.24it/s]Loading train:  83%|████████▎ | 222/266 [03:48<00:36,  1.21it/s]Loading train:  84%|████████▍ | 223/266 [03:49<00:34,  1.24it/s]Loading train:  84%|████████▍ | 224/266 [03:49<00:33,  1.25it/s]Loading train:  85%|████████▍ | 225/266 [03:50<00:33,  1.24it/s]Loading train:  85%|████████▍ | 226/266 [03:51<00:31,  1.27it/s]Loading train:  85%|████████▌ | 227/266 [03:52<00:30,  1.28it/s]Loading train:  86%|████████▌ | 228/266 [03:53<00:30,  1.27it/s]Loading train:  86%|████████▌ | 229/266 [03:53<00:29,  1.27it/s]Loading train:  86%|████████▋ | 230/266 [03:54<00:28,  1.27it/s]Loading train:  87%|████████▋ | 231/266 [03:55<00:27,  1.28it/s]Loading train:  87%|████████▋ | 232/266 [03:56<00:26,  1.29it/s]Loading train:  88%|████████▊ | 233/266 [03:56<00:25,  1.29it/s]Loading train:  88%|████████▊ | 234/266 [03:57<00:24,  1.31it/s]Loading train:  88%|████████▊ | 235/266 [03:58<00:23,  1.32it/s]Loading train:  89%|████████▊ | 236/266 [03:59<00:22,  1.32it/s]Loading train:  89%|████████▉ | 237/266 [03:59<00:21,  1.33it/s]Loading train:  89%|████████▉ | 238/266 [04:00<00:20,  1.35it/s]Loading train:  90%|████████▉ | 239/266 [04:01<00:20,  1.35it/s]Loading train:  90%|█████████ | 240/266 [04:02<00:19,  1.35it/s]Loading train:  91%|█████████ | 241/266 [04:02<00:18,  1.37it/s]Loading train:  91%|█████████ | 242/266 [04:03<00:18,  1.33it/s]Loading train:  91%|█████████▏| 243/266 [04:04<00:17,  1.32it/s]Loading train:  92%|█████████▏| 244/266 [04:05<00:16,  1.33it/s]Loading train:  92%|█████████▏| 245/266 [04:05<00:16,  1.31it/s]Loading train:  92%|█████████▏| 246/266 [04:06<00:14,  1.34it/s]Loading train:  93%|█████████▎| 247/266 [04:07<00:13,  1.36it/s]Loading train:  93%|█████████▎| 248/266 [04:08<00:13,  1.37it/s]Loading train:  94%|█████████▎| 249/266 [04:09<00:13,  1.28it/s]Loading train:  94%|█████████▍| 250/266 [04:09<00:12,  1.26it/s]Loading train:  94%|█████████▍| 251/266 [04:10<00:11,  1.26it/s]Loading train:  95%|█████████▍| 252/266 [04:11<00:11,  1.26it/s]Loading train:  95%|█████████▌| 253/266 [04:12<00:10,  1.25it/s]Loading train:  95%|█████████▌| 254/266 [04:13<00:09,  1.24it/s]Loading train:  96%|█████████▌| 255/266 [04:13<00:09,  1.21it/s]Loading train:  96%|█████████▌| 256/266 [04:14<00:08,  1.22it/s]Loading train:  97%|█████████▋| 257/266 [04:15<00:07,  1.21it/s]Loading train:  97%|█████████▋| 258/266 [04:16<00:06,  1.18it/s]Loading train:  97%|█████████▋| 259/266 [04:17<00:05,  1.18it/s]Loading train:  98%|█████████▊| 260/266 [04:18<00:05,  1.15it/s]Loading train:  98%|█████████▊| 261/266 [04:19<00:04,  1.15it/s]Loading train:  98%|█████████▊| 262/266 [04:19<00:03,  1.18it/s]Loading train:  99%|█████████▉| 263/266 [04:20<00:02,  1.19it/s]Loading train:  99%|█████████▉| 264/266 [04:21<00:01,  1.18it/s]Loading train: 100%|█████████▉| 265/266 [04:22<00:00,  1.16it/s]Loading train: 100%|██████████| 266/266 [04:23<00:00,  1.17it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   1%|          | 3/266 [00:00<00:09, 27.20it/s]concatenating: train:   6%|▋         | 17/266 [00:00<00:06, 35.82it/s]concatenating: train:  20%|█▉        | 52/266 [00:00<00:04, 49.00it/s]concatenating: train:  33%|███▎      | 87/266 [00:00<00:02, 65.98it/s]concatenating: train:  47%|████▋     | 125/266 [00:00<00:01, 87.66it/s]concatenating: train:  60%|█████▉    | 159/266 [00:00<00:00, 112.61it/s]concatenating: train:  73%|███████▎  | 195/266 [00:00<00:00, 141.76it/s]concatenating: train:  85%|████████▌ | 227/266 [00:00<00:00, 169.58it/s]concatenating: train:  98%|█████████▊| 262/266 [00:00<00:00, 199.92it/s]concatenating: train: 100%|██████████| 266/266 [00:00<00:00, 283.42it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:01<00:05,  1.31s/it]Loading test:  40%|████      | 2/5 [00:02<00:03,  1.28s/it]Loading test:  60%|██████    | 3/5 [00:03<00:02,  1.22s/it]Loading test:  80%|████████  | 4/5 [00:04<00:01,  1.17s/it]Loading test: 100%|██████████| 5/5 [00:06<00:00,  1.23s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 319.40it/s]2019-08-17 20:36:02.380651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-08-17 20:36:02.380742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-17 20:36:02.380760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-08-17 20:36:02.380770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-08-17 20:36:02.381212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:89:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.43it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.46it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  6.01it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.67it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.63it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.46it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  6.71it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.63it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.27it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.36it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  9.09it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.25it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.56it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.62it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.38it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.61it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.68it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.60it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.85it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 7  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 7  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 7  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 84, 48, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 84, 48, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 84, 48, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 84, 48, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 84, 48, 40)   14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 84, 48, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 84, 48, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 42, 24, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 42, 24, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 42, 24, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 42, 24, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 42, 24, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 42, 24, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 42, 24, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 42, 24, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 42, 24, 120)  0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 21, 12, 120)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 21, 12, 120)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 21, 12, 160)  172960      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 21, 12, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 21, 12, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 21, 12, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 21, 12, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 21, 12, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 21, 12, 280)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 21, 12, 280)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 42, 24, 80)   89680       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 42, 24, 200)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 42, 24, 80)   144080      concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 42, 24, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 42, 24, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 42, 24, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 42, 24, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 42, 24, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 42, 24, 280)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 42, 24, 280)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 84, 48, 40)   44840       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 84, 48, 80)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 84, 48, 40)   28840       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 84, 48, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 84, 48, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 84, 48, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 84, 48, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 48, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 48, 120)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 84, 48, 120)  0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 84, 48, 13)   1573        dropout_5[0][0]                  
==================================================================================================
Total params: 889,253
Trainable params: 106,133
Non-trainable params: 783,120
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.33169821e-02 3.28163127e-02 7.67364338e-02 9.53488776e-03
 2.75961364e-02 7.21975120e-03 8.47464450e-02 1.14056075e-01
 8.95565317e-02 1.36067536e-02 2.90359891e-01 1.90183578e-01
 2.70222181e-04]
Train on 10147 samples, validate on 184 samples
Epoch 1/300
 - 20s - loss: 1.4846 - acc: 0.8001 - mDice: 0.3529 - val_loss: 2.0969 - val_acc: 0.9265 - val_mDice: 0.3854

Epoch 00001: val_mDice improved from -inf to 0.38541, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 15s - loss: 0.5135 - acc: 0.9212 - mDice: 0.5866 - val_loss: 0.4719 - val_acc: 0.9275 - val_mDice: 0.6126

Epoch 00002: val_mDice improved from 0.38541 to 0.61262, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 14s - loss: 0.4613 - acc: 0.9312 - mDice: 0.6175 - val_loss: 0.5231 - val_acc: 0.9456 - val_mDice: 0.6072

Epoch 00003: val_mDice did not improve from 0.61262
Epoch 4/300
 - 14s - loss: 0.4322 - acc: 0.9337 - mDice: 0.6362 - val_loss: 0.4302 - val_acc: 0.9438 - val_mDice: 0.6371

Epoch 00004: val_mDice improved from 0.61262 to 0.63712, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 14s - loss: 0.4140 - acc: 0.9354 - mDice: 0.6481 - val_loss: 0.4685 - val_acc: 0.9473 - val_mDice: 0.6183

Epoch 00005: val_mDice did not improve from 0.63712
Epoch 6/300
 - 15s - loss: 0.3983 - acc: 0.9367 - mDice: 0.6583 - val_loss: 0.5703 - val_acc: 0.9279 - val_mDice: 0.5707

Epoch 00006: val_mDice did not improve from 0.63712
Epoch 7/300
 - 14s - loss: 0.3880 - acc: 0.9377 - mDice: 0.6652 - val_loss: 0.4490 - val_acc: 0.9377 - val_mDice: 0.6263

Epoch 00007: val_mDice did not improve from 0.63712
Epoch 8/300
 - 14s - loss: 0.3766 - acc: 0.9386 - mDice: 0.6729 - val_loss: 0.4251 - val_acc: 0.9487 - val_mDice: 0.6432

Epoch 00008: val_mDice improved from 0.63712 to 0.64315, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 14s - loss: 0.3717 - acc: 0.9390 - mDice: 0.6764 - val_loss: 0.4565 - val_acc: 0.9389 - val_mDice: 0.6204

Epoch 00009: val_mDice did not improve from 0.64315
Epoch 10/300
 - 14s - loss: 0.3645 - acc: 0.9395 - mDice: 0.6812 - val_loss: 0.4427 - val_acc: 0.9467 - val_mDice: 0.6317

Epoch 00010: val_mDice did not improve from 0.64315
Epoch 11/300
 - 14s - loss: 0.3614 - acc: 0.9399 - mDice: 0.6836 - val_loss: 0.4608 - val_acc: 0.9473 - val_mDice: 0.6284

Epoch 00011: val_mDice did not improve from 0.64315
Epoch 12/300
 - 15s - loss: 0.3556 - acc: 0.9403 - mDice: 0.6875 - val_loss: 0.4825 - val_acc: 0.9451 - val_mDice: 0.6105

Epoch 00012: val_mDice did not improve from 0.64315
Epoch 13/300
 - 14s - loss: 0.3448 - acc: 0.9410 - mDice: 0.6949 - val_loss: 0.5257 - val_acc: 0.9281 - val_mDice: 0.5842

Epoch 00013: val_mDice did not improve from 0.64315
Epoch 14/300
 - 14s - loss: 0.3405 - acc: 0.9413 - mDice: 0.6981 - val_loss: 0.4818 - val_acc: 0.9461 - val_mDice: 0.6114

Epoch 00014: val_mDice did not improve from 0.64315
Epoch 15/300
 - 14s - loss: 0.3362 - acc: 0.9416 - mDice: 0.7010 - val_loss: 0.4096 - val_acc: 0.9463 - val_mDice: 0.6508

Epoch 00015: val_mDice improved from 0.64315 to 0.65080, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 14s - loss: 0.3316 - acc: 0.9420 - mDice: 0.7042 - val_loss: 0.4492 - val_acc: 0.9465 - val_mDice: 0.6286

Epoch 00016: val_mDice did not improve from 0.65080
Epoch 17/300
 - 14s - loss: 0.3600 - acc: 0.9394 - mDice: 0.6865 - val_loss: 0.4514 - val_acc: 0.9440 - val_mDice: 0.6262

Epoch 00017: val_mDice did not improve from 0.65080
Epoch 18/300
 - 14s - loss: 0.3336 - acc: 0.9417 - mDice: 0.7028 - val_loss: 0.4602 - val_acc: 0.9485 - val_mDice: 0.6254

Epoch 00018: val_mDice did not improve from 0.65080
Epoch 19/300
 - 15s - loss: 0.3253 - acc: 0.9424 - mDice: 0.7088 - val_loss: 0.4658 - val_acc: 0.9466 - val_mDice: 0.6205

Epoch 00019: val_mDice did not improve from 0.65080
Epoch 20/300
 - 14s - loss: 0.3190 - acc: 0.9430 - mDice: 0.7134 - val_loss: 0.4427 - val_acc: 0.9476 - val_mDice: 0.6327

Epoch 00020: val_mDice did not improve from 0.65080
Epoch 21/300
 - 15s - loss: 0.3180 - acc: 0.9431 - mDice: 0.7142 - val_loss: 0.4156 - val_acc: 0.9453 - val_mDice: 0.6482

Epoch 00021: val_mDice did not improve from 0.65080
Epoch 22/300
 - 14s - loss: 0.3129 - acc: 0.9433 - mDice: 0.7179 - val_loss: 0.5007 - val_acc: 0.9471 - val_mDice: 0.6104

Epoch 00022: val_mDice did not improve from 0.65080
Epoch 23/300
 - 15s - loss: 0.3220 - acc: 0.9430 - mDice: 0.7152 - val_loss: 0.9049 - val_acc: 0.9405 - val_mDice: 0.5462

Epoch 00023: val_mDice did not improve from 0.65080
Epoch 24/300
 - 15s - loss: 0.3219 - acc: 0.9425 - mDice: 0.7111 - val_loss: 0.4698 - val_acc: 0.9444 - val_mDice: 0.6166

Epoch 00024: val_mDice did not improve from 0.65080
Epoch 25/300
 - 15s - loss: 0.3097 - acc: 0.9436 - mDice: 0.7203 - val_loss: 0.4213 - val_acc: 0.9484 - val_mDice: 0.6451

Epoch 00025: val_mDice did not improve from 0.65080
Epoch 26/300
 - 15s - loss: 0.3076 - acc: 0.9437 - mDice: 0.7221 - val_loss: 0.4116 - val_acc: 0.9450 - val_mDice: 0.6502

Epoch 00026: val_mDice did not improve from 0.65080
Epoch 27/300
 - 15s - loss: 0.3107 - acc: 0.9439 - mDice: 0.7239 - val_loss: 0.4589 - val_acc: 0.9487 - val_mDice: 0.6270

Epoch 00027: val_mDice did not improve from 0.65080
Epoch 28/300
 - 14s - loss: 0.3022 - acc: 0.9441 - mDice: 0.7258 - val_loss: 0.4566 - val_acc: 0.9387 - val_mDice: 0.6237

Epoch 00028: val_mDice did not improve from 0.65080
Epoch 29/300
 - 15s - loss: 0.3004 - acc: 0.9443 - mDice: 0.7271 - val_loss: 0.4354 - val_acc: 0.9462 - val_mDice: 0.6368

Epoch 00029: val_mDice did not improve from 0.65080
Epoch 30/300
 - 15s - loss: 0.2975 - acc: 0.9446 - mDice: 0.7293 - val_loss: 0.4337 - val_acc: 0.9424 - val_mDice: 0.6363

Epoch 00030: val_mDice did not improve from 0.65080
Epoch 31/300
 - 15s - loss: 0.2965 - acc: 0.9445 - mDice: 0.7301 - val_loss: 0.4556 - val_acc: 0.9486 - val_mDice: 0.6343

Epoch 00031: val_mDice did not improve from 0.65080
Epoch 32/300
 - 15s - loss: 0.2960 - acc: 0.9447 - mDice: 0.7305 - val_loss: 0.4165 - val_acc: 0.9449 - val_mDice: 0.6469

Epoch 00032: val_mDice did not improve from 0.65080
Epoch 33/300
 - 15s - loss: 0.2950 - acc: 0.9446 - mDice: 0.7312 - val_loss: 0.4152 - val_acc: 0.9468 - val_mDice: 0.6483

Epoch 00033: val_mDice did not improve from 0.65080
Epoch 34/300
 - 15s - loss: 0.2930 - acc: 0.9449 - mDice: 0.7329 - val_loss: 0.4453 - val_acc: 0.9417 - val_mDice: 0.6296

Epoch 00034: val_mDice did not improve from 0.65080
Epoch 35/300
 - 15s - loss: 0.2973 - acc: 0.9450 - mDice: 0.7339 - val_loss: 0.4212 - val_acc: 0.9456 - val_mDice: 0.6443

Epoch 00035: val_mDice did not improve from 0.65080
Epoch 36/300
 - 15s - loss: 0.2887 - acc: 0.9450 - mDice: 0.7360 - val_loss: 0.4410 - val_acc: 0.9428 - val_mDice: 0.6327

Epoch 00036: val_mDice did not improve from 0.65080
Epoch 37/300
 - 15s - loss: 0.3289 - acc: 0.9419 - mDice: 0.7094 - val_loss: 0.5519 - val_acc: 0.9444 - val_mDice: 0.5981

Epoch 00037: val_mDice did not improve from 0.65080
Epoch 38/300
 - 15s - loss: 0.3076 - acc: 0.9434 - mDice: 0.7215 - val_loss: 0.4324 - val_acc: 0.9460 - val_mDice: 0.6370

Epoch 00038: val_mDice did not improve from 0.65080
Epoch 39/300
 - 15s - loss: 0.2965 - acc: 0.9444 - mDice: 0.7300 - val_loss: 0.4102 - val_acc: 0.9464 - val_mDice: 0.6517

Epoch 00039: val_mDice improved from 0.65080 to 0.65174, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 40/300
 - 15s - loss: 0.2908 - acc: 0.9449 - mDice: 0.7344 - val_loss: 0.4435 - val_acc: 0.9406 - val_mDice: 0.6315

Epoch 00040: val_mDice did not improve from 0.65174
Epoch 41/300
 - 15s - loss: 0.2852 - acc: 0.9453 - mDice: 0.7385 - val_loss: 0.4454 - val_acc: 0.9443 - val_mDice: 0.6308

Epoch 00041: val_mDice did not improve from 0.65174
Epoch 42/300
 - 15s - loss: 0.2839 - acc: 0.9455 - mDice: 0.7395 - val_loss: 0.4158 - val_acc: 0.9446 - val_mDice: 0.6471

Epoch 00042: val_mDice did not improve from 0.65174
Epoch 43/300
 - 15s - loss: 0.2830 - acc: 0.9456 - mDice: 0.7405 - val_loss: 0.4107 - val_acc: 0.9486 - val_mDice: 0.6517

Epoch 00043: val_mDice improved from 0.65174 to 0.65175, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute6_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 44/300
 - 15s - loss: 0.2877 - acc: 0.9457 - mDice: 0.7415 - val_loss: 0.4202 - val_acc: 0.9431 - val_mDice: 0.6453

Epoch 00044: val_mDice did not improve from 0.65175
Epoch 45/300
 - 15s - loss: 0.2795 - acc: 0.9458 - mDice: 0.7429 - val_loss: 0.4227 - val_acc: 0.9423 - val_mDice: 0.6433

Epoch 00045: val_mDice did not improve from 0.65175
Epoch 46/300
 - 15s - loss: 0.2802 - acc: 0.9459 - mDice: 0.7427 - val_loss: 0.4173 - val_acc: 0.9476 - val_mDice: 0.6479

Epoch 00046: val_mDice did not improve from 0.65175
Epoch 47/300
 - 15s - loss: 0.2773 - acc: 0.9461 - mDice: 0.7449 - val_loss: 0.4251 - val_acc: 0.9482 - val_mDice: 0.6432

Epoch 00047: val_mDice did not improve from 0.65175
Epoch 48/300
 - 15s - loss: 0.2777 - acc: 0.9461 - mDice: 0.7444 - val_loss: 0.4294 - val_acc: 0.9456 - val_mDice: 0.6408

Epoch 00048: val_mDice did not improve from 0.65175
Epoch 49/300
 - 15s - loss: 0.2755 - acc: 0.9461 - mDice: 0.7461 - val_loss: 0.4650 - val_acc: 0.9355 - val_mDice: 0.6179

Epoch 00049: val_mDice did not improve from 0.65175
Epoch 50/300
 - 15s - loss: 0.2753 - acc: 0.9463 - mDice: 0.7463 - val_loss: 0.4354 - val_acc: 0.9447 - val_mDice: 0.6350

Epoch 00050: val_mDice did not improve from 0.65175
Epoch 51/300
 - 15s - loss: 0.2750 - acc: 0.9462 - mDice: 0.7465 - val_loss: 0.4371 - val_acc: 0.9426 - val_mDice: 0.6348

Epoch 00051: val_mDice did not improve from 0.65175
Epoch 52/300
 - 15s - loss: 0.2748 - acc: 0.9462 - mDice: 0.7467 - val_loss: 0.4207 - val_acc: 0.9471 - val_mDice: 0.6441

Epoch 00052: val_mDice did not improve from 0.65175
Epoch 53/300
 - 15s - loss: 0.2724 - acc: 0.9463 - mDice: 0.7484 - val_loss: 0.4291 - val_acc: 0.9434 - val_mDice: 0.6386

Epoch 00053: val_mDice did not improve from 0.65175
Epoch 54/300
 - 15s - loss: 0.2721 - acc: 0.9464 - mDice: 0.7488 - val_loss: 0.4244 - val_acc: 0.9460 - val_mDice: 0.6422

Epoch 00054: val_mDice did not improve from 0.65175
Epoch 55/300
 - 15s - loss: 0.2717 - acc: 0.9465 - mDice: 0.7491 - val_loss: 0.4408 - val_acc: 0.9422 - val_mDice: 0.6324

Epoch 00055: val_mDice did not improve from 0.65175
Epoch 56/300
 - 15s - loss: 0.2693 - acc: 0.9466 - mDice: 0.7509 - val_loss: 0.4340 - val_acc: 0.9432 - val_mDice: 0.6371

Epoch 00056: val_mDice did not improve from 0.65175
Epoch 57/300
 - 15s - loss: 0.2684 - acc: 0.9467 - mDice: 0.7516 - val_loss: 0.4417 - val_acc: 0.9464 - val_mDice: 0.6331

Epoch 00057: val_mDice did not improve from 0.65175
Epoch 58/300
 - 15s - loss: 0.2683 - acc: 0.9467 - mDice: 0.7518 - val_loss: 0.4386 - val_acc: 0.9404 - val_mDice: 0.6336

Epoch 00058: val_mDice did not improve from 0.65175
Epoch 59/300
 - 16s - loss: 0.2884 - acc: 0.9457 - mDice: 0.7407 - val_loss: 0.4498 - val_acc: 0.9437 - val_mDice: 0.6273

Epoch 00059: val_mDice did not improve from 0.65175
Epoch 60/300
 - 16s - loss: 0.2726 - acc: 0.9465 - mDice: 0.7484 - val_loss: 0.4197 - val_acc: 0.9473 - val_mDice: 0.6455

Epoch 00060: val_mDice did not improve from 0.65175
Epoch 61/300
 - 16s - loss: 0.2667 - acc: 0.9468 - mDice: 0.7530 - val_loss: 0.4280 - val_acc: 0.9462 - val_mDice: 0.6398

Epoch 00061: val_mDice did not improve from 0.65175
Epoch 62/300
 - 17s - loss: 0.2667 - acc: 0.9468 - mDice: 0.7532 - val_loss: 0.4312 - val_acc: 0.9428 - val_mDice: 0.6371

Epoch 00062: val_mDice did not improve from 0.65175
Epoch 63/300
 - 16s - loss: 0.2667 - acc: 0.9469 - mDice: 0.7533 - val_loss: 0.4476 - val_acc: 0.9467 - val_mDice: 0.6306

Epoch 00063: val_mDice did not improve from 0.65175
Epoch 64/300
 - 15s - loss: 0.2637 - acc: 0.9470 - mDice: 0.7555 - val_loss: 0.4377 - val_acc: 0.9465 - val_mDice: 0.6351

Epoch 00064: val_mDice did not improve from 0.65175
Epoch 65/300
 - 15s - loss: 0.2643 - acc: 0.9470 - mDice: 0.7549 - val_loss: 0.4375 - val_acc: 0.9427 - val_mDice: 0.6331

Epoch 00065: val_mDice did not improve from 0.65175
Epoch 66/300
 - 15s - loss: 0.2620 - acc: 0.9471 - mDice: 0.7567 - val_loss: 0.4466 - val_acc: 0.9416 - val_mDice: 0.6281

Epoch 00066: val_mDice did not improve from 0.65175
Epoch 67/300
 - 15s - loss: 0.2632 - acc: 0.9471 - mDice: 0.7557 - val_loss: 0.4184 - val_acc: 0.9484 - val_mDice: 0.6460

Epoch 00067: val_mDice did not improve from 0.65175
Epoch 68/300
 - 15s - loss: 0.2598 - acc: 0.9473 - mDice: 0.7584 - val_loss: 0.4363 - val_acc: 0.9477 - val_mDice: 0.6362

Epoch 00068: val_mDice did not improve from 0.65175
Epoch 69/300
 - 15s - loss: 0.2602 - acc: 0.9473 - mDice: 0.7581 - val_loss: 0.4282 - val_acc: 0.9453 - val_mDice: 0.6399

Epoch 00069: val_mDice did not improve from 0.65175
Epoch 70/300
 - 15s - loss: 0.2594 - acc: 0.9474 - mDice: 0.7588 - val_loss: 0.4301 - val_acc: 0.9437 - val_mDice: 0.6387

Epoch 00070: val_mDice did not improve from 0.65175
Epoch 71/300
 - 15s - loss: 0.2592 - acc: 0.9473 - mDice: 0.7590 - val_loss: 0.4287 - val_acc: 0.9444 - val_mDice: 0.6399

Epoch 00071: val_mDice did not improve from 0.65175
Epoch 72/300
 - 15s - loss: 0.2584 - acc: 0.9473 - mDice: 0.7596 - val_loss: 0.4290 - val_acc: 0.9466 - val_mDice: 0.6402

Epoch 00072: val_mDice did not improve from 0.65175
Epoch 73/300
 - 15s - loss: 0.2577 - acc: 0.9475 - mDice: 0.7602 - val_loss: 0.4305 - val_acc: 0.9477 - val_mDice: 0.6395

Epoch 00073: val_mDice did not improve from 0.65175
Epoch 74/300
 - 15s - loss: 0.2570 - acc: 0.9475 - mDice: 0.7606 - val_loss: 0.4277 - val_acc: 0.9461 - val_mDice: 0.6421

Epoch 00074: val_mDice did not improve from 0.65175
Epoch 75/300
 - 14s - loss: 0.2582 - acc: 0.9476 - mDice: 0.7598 - val_loss: 0.4737 - val_acc: 0.9375 - val_mDice: 0.6125

Epoch 00075: val_mDice did not improve from 0.65175
Epoch 76/300
 - 14s - loss: 0.2557 - acc: 0.9477 - mDice: 0.7617 - val_loss: 0.4204 - val_acc: 0.9478 - val_mDice: 0.6464

Epoch 00076: val_mDice did not improve from 0.65175
Epoch 77/300
 - 14s - loss: 0.2553 - acc: 0.9476 - mDice: 0.7620 - val_loss: 0.4465 - val_acc: 0.9438 - val_mDice: 0.6293

Epoch 00077: val_mDice did not improve from 0.65175
Epoch 78/300
 - 14s - loss: 0.2543 - acc: 0.9478 - mDice: 0.7630 - val_loss: 0.4272 - val_acc: 0.9450 - val_mDice: 0.6405

Epoch 00078: val_mDice did not improve from 0.65175
Epoch 79/300
 - 14s - loss: 0.2578 - acc: 0.9476 - mDice: 0.7606 - val_loss: 0.4475 - val_acc: 0.9460 - val_mDice: 0.6311

Epoch 00079: val_mDice did not improve from 0.65175
Epoch 80/300
 - 14s - loss: 0.2531 - acc: 0.9478 - mDice: 0.7638 - val_loss: 0.4365 - val_acc: 0.9464 - val_mDice: 0.6360

Epoch 00080: val_mDice did not improve from 0.65175
Epoch 81/300
 - 14s - loss: 0.2537 - acc: 0.9478 - mDice: 0.7632 - val_loss: 0.4401 - val_acc: 0.9466 - val_mDice: 0.6346

Epoch 00081: val_mDice did not improve from 0.65175
Epoch 82/300
 - 14s - loss: 0.2539 - acc: 0.9479 - mDice: 0.7633 - val_loss: 0.4297 - val_acc: 0.9450 - val_mDice: 0.6395

Epoch 00082: val_mDice did not improve from 0.65175
Epoch 83/300
 - 14s - loss: 0.2513 - acc: 0.9479 - mDice: 0.7652 - val_loss: 0.4393 - val_acc: 0.9458 - val_mDice: 0.6360

Epoch 00083: val_mDice did not improve from 0.65175
Restoring model weights from the end of the best epoch
Epoch 00083: early stopping
{'val_loss': [2.0969396233558655, 0.47190993765126105, 0.5230648909573969, 0.4302350143375604, 0.4685342373407405, 0.5702714955677157, 0.4489800593127375, 0.4251335778314134, 0.4565263876448507, 0.4427032438309296, 0.46083189579455747, 0.4824583339302436, 0.5257421557022177, 0.4818304158423258, 0.4096343225759009, 0.4492063671350479, 0.4513665334038112, 0.46019208755182184, 0.46577056950849033, 0.44271764839472977, 0.41560229043597763, 0.5007121676336164, 0.9049351082547851, 0.469798743724823, 0.42134856011556543, 0.4116066039904304, 0.45892824297365936, 0.4565905403831731, 0.4353908089839894, 0.43367406207582226, 0.45555877912303677, 0.4164852179262949, 0.4152338838447695, 0.44533729844767117, 0.4212358052963796, 0.44095686369616055, 0.5519134045942969, 0.4323728353432987, 0.41018918124230014, 0.44345937345338904, 0.44537872885880264, 0.4157670218011607, 0.4106714323810909, 0.42016015882077423, 0.42268687583830045, 0.4172584864756335, 0.4251097061711809, 0.4294498047750929, 0.4649984700524289, 0.43536481066890387, 0.43714149199102237, 0.42065200209617615, 0.42912012047093845, 0.42441649573004764, 0.4408445267573647, 0.43403221116117807, 0.44169874489307404, 0.4386425455627234, 0.44981487969989364, 0.4196930741486342, 0.42804840433856717, 0.4312272541548895, 0.4475985600248627, 0.4376882369751516, 0.4375114353454631, 0.4466343654886536, 0.41842369929603906, 0.4363488610024038, 0.4282379966715108, 0.4301451969405879, 0.4286885475334914, 0.4290416078722995, 0.43049483811077865, 0.42765677655520645, 0.4737329450638398, 0.4203926133720771, 0.4464956745505333, 0.427165106586788, 0.447527047732602, 0.4364895007532576, 0.4400962510186693, 0.4297058909483578, 0.4393295626277509], 'val_acc': [0.9265401207882425, 0.9274971426829047, 0.9455807234929956, 0.943774529773256, 0.9473208836887194, 0.9278651106616725, 0.9376765768165174, 0.9487348522828973, 0.9388654497654542, 0.9467413030240847, 0.9473141671522803, 0.945135931605878, 0.9281144815942516, 0.9460835100516028, 0.9462843297616296, 0.9464986635291058, 0.9439834563628487, 0.9485245761664017, 0.946641541045645, 0.9475783407688141, 0.945342168211937, 0.9471213966608047, 0.9405368456374044, 0.9443635642528534, 0.9484221378098363, 0.9450119047061257, 0.9487025057492049, 0.9386928975582123, 0.946242565046186, 0.9424077453820602, 0.9485879158196242, 0.9449269914108774, 0.9468059844296911, 0.9416946969602419, 0.9456198332102402, 0.9428498582995456, 0.9443716478088627, 0.9459635226622872, 0.9463638656813166, 0.9406406328729962, 0.9442571064700251, 0.9446371929801028, 0.9486337498478268, 0.9431194339109503, 0.9422810459914415, 0.9475877809783687, 0.948180843954501, 0.9456333032120829, 0.935474082827568, 0.944714024015095, 0.9425641084494798, 0.9470728836629702, 0.943429466822873, 0.9459716256545938, 0.9422109658303468, 0.9432057045076204, 0.9463557879561963, 0.9404141838135927, 0.9437003997356995, 0.9473438094491544, 0.9461980844321458, 0.9427959510813588, 0.9466954534468444, 0.9464649732993997, 0.9427258586106093, 0.9415922709133314, 0.9484126988960349, 0.9476699997549471, 0.9452680226253427, 0.9437462162712346, 0.9444269181593604, 0.9466065090635548, 0.9476605744465537, 0.9460511615742808, 0.9374851837106373, 0.9478236572897952, 0.9438379005245541, 0.9450105862772983, 0.9459756690522899, 0.9464474424071934, 0.9465984235639158, 0.9449890009734941, 0.9457829102225925], 'val_mDice': [0.3854124324153299, 0.6126171667938647, 0.6071548202763433, 0.6371235329171886, 0.6183392897896145, 0.5707457752331443, 0.6262598588414814, 0.643151611737583, 0.6204111958327501, 0.6316596587067065, 0.6283857025530027, 0.6104595654684565, 0.5841756689807643, 0.6114122252101484, 0.6507977720188058, 0.6286354784084403, 0.6261983876642974, 0.6254159717456155, 0.6205236166715622, 0.6327275413533916, 0.6481579088646433, 0.6103681549429893, 0.5461885588972465, 0.6166025918463002, 0.6451167509607647, 0.6501696291177169, 0.62697241746861, 0.6237017648375552, 0.6367926506892495, 0.6363247632980347, 0.6343013527600662, 0.6469457343868588, 0.6483097452184429, 0.629595636025719, 0.6443136658357538, 0.6327001880044523, 0.59808249771595, 0.6369963042114092, 0.6517364026411719, 0.631457054744596, 0.6308070738678393, 0.6470922426037167, 0.6517487498729125, 0.6453081900658815, 0.6432552233986233, 0.6478536951801052, 0.6431759388550468, 0.6407768946626912, 0.6179140333248221, 0.6350160182818122, 0.634763777256012, 0.6440968766160633, 0.638639144923376, 0.6422200507443884, 0.6323674580325251, 0.6370555797348851, 0.6330818864314453, 0.6336357101150181, 0.6272561498310255, 0.6454611880623776, 0.6397785162148268, 0.6371191811302434, 0.6306128786957782, 0.6351392528285151, 0.6330594873946646, 0.6281260984099429, 0.6460335073263749, 0.6362427868272947, 0.6398667842149734, 0.6386825073024501, 0.6399426065061403, 0.6402267690586008, 0.6395342110291772, 0.6421363917381867, 0.6125056056872659, 0.6464245235142501, 0.6292664259672165, 0.6405491990887601, 0.631056217395741, 0.6360106001729551, 0.6345502047435098, 0.6395384999720947, 0.6360267161027245], 'loss': [1.4845947292246489, 0.513454795803027, 0.4613326695255074, 0.4321649275713511, 0.414039770675972, 0.3982957600578012, 0.38803158309690655, 0.3766178810045474, 0.3716785933121538, 0.36453800448070106, 0.36137846630054515, 0.35555918830021666, 0.3447650233001865, 0.34050689590814914, 0.33617807223231283, 0.33160971730838823, 0.3600468244343024, 0.3336082776097743, 0.32526337787049314, 0.3190123155438466, 0.31797291153555984, 0.31287532093208437, 0.32197788957775525, 0.32194254304242625, 0.3096667781796751, 0.3076079338480595, 0.310733820063452, 0.30215036314238913, 0.30044314259964455, 0.2974671342607389, 0.29647897737677303, 0.29603773394546873, 0.29499003131647844, 0.292978888314217, 0.29731818147512495, 0.2887222237442237, 0.3289103468580294, 0.30756593817582306, 0.296470901972439, 0.2907836163697177, 0.2852106490451925, 0.2838849064850791, 0.2829534337680845, 0.28772398713740077, 0.27951072329275123, 0.2802142712433632, 0.2772997569641926, 0.2777155019989786, 0.27546531313262435, 0.2752622610843392, 0.2750223914666682, 0.2747993069886574, 0.2723750970369961, 0.27205168743009955, 0.2716947954088946, 0.2692906044176133, 0.2683925316922827, 0.26831848359441623, 0.2883590467019399, 0.2726189536720329, 0.2666992508179685, 0.26667256263414485, 0.26670957779701066, 0.2637329330388649, 0.26432843319979915, 0.2620119651520888, 0.2631767906554758, 0.2597943007567134, 0.2601551716434811, 0.25940405033992125, 0.2592284197911636, 0.2583898202919709, 0.2577409805588456, 0.2570020205030961, 0.2581691956701003, 0.25569423776172445, 0.25527542820702376, 0.25432924116681077, 0.2577684912391868, 0.2530791205708776, 0.25372413053375825, 0.2538530778958902, 0.2512716237395764], 'acc': [0.8001406102112576, 0.9211595241654809, 0.9312090206183835, 0.9336845104337456, 0.9354170275472286, 0.9366998347999239, 0.9376638603760267, 0.9385593553076733, 0.9389688092945385, 0.9394638410069924, 0.9398662588731919, 0.9402964911496591, 0.9410243808629889, 0.9413085714330623, 0.9416030303379509, 0.9419512568089226, 0.9393890218933522, 0.9416586091756421, 0.9424391258957704, 0.9430116124901264, 0.9430830579644249, 0.9433102738661073, 0.9429888316559841, 0.9425281683094833, 0.94357146452692, 0.9437119101813077, 0.9439195939516379, 0.9441455406567916, 0.9443034120906312, 0.9445634057477882, 0.9444966516119278, 0.9446676526149999, 0.944641571004038, 0.9448780012598317, 0.9449500592633446, 0.9449993560581333, 0.9419362032320672, 0.9433740931296449, 0.94440264726867, 0.9449404517840878, 0.9452820835741351, 0.9454984206912247, 0.9456455882246229, 0.9457107760982113, 0.9458263378795573, 0.9459155762008791, 0.946084352805836, 0.9461192533431105, 0.9461462388570125, 0.946287760038358, 0.9461962718135137, 0.9461954887822378, 0.9463299470217085, 0.9463866758172684, 0.9464584135875287, 0.9466031372071346, 0.9467053806193182, 0.9466900046475358, 0.9456793923407126, 0.9465106489435844, 0.9468042266842319, 0.9468023926093095, 0.9468503696079429, 0.9470201469388774, 0.9470138897199848, 0.9471037638437646, 0.9470706917246399, 0.9473250154627947, 0.947266111787909, 0.9473920392322813, 0.9473325213423102, 0.9473496045257536, 0.9474979205778623, 0.9474567858129813, 0.9476303997633786, 0.9476714374526353, 0.9476436210040495, 0.9477968736388971, 0.9476341641605975, 0.9478388412064304, 0.9478069702439605, 0.9478512351132501, 0.9479334101167538], 'mDice': [0.35287530337388473, 0.586625858517225, 0.617540351055967, 0.6361855768130614, 0.6481447630977941, 0.6582715172150622, 0.6652340714045907, 0.6729205423380291, 0.6763949739447812, 0.6811707195206982, 0.6835595505853421, 0.6874641968050977, 0.6949492864354063, 0.6980815890670187, 0.7009962194656942, 0.7042119152865246, 0.6865480110200506, 0.7027532978693206, 0.7088210530336049, 0.7133593845099572, 0.7142467563688267, 0.7178964212021358, 0.7152392185825756, 0.7111241655936203, 0.7203064665273221, 0.7220970901277978, 0.7238984004939214, 0.7258157450142219, 0.727116958359797, 0.729301473701295, 0.7300558779126166, 0.7305052821784462, 0.7312256355725968, 0.7329094514031944, 0.7338902827811568, 0.7359642893431327, 0.709383236312791, 0.7214867631543431, 0.7299658143016357, 0.7343792031289933, 0.7384721569983468, 0.7394675518640029, 0.7405120024977616, 0.7415343672169292, 0.7428691696859856, 0.7427098145681824, 0.7448650134235952, 0.7443993187566291, 0.7461283594396322, 0.7462917752156437, 0.7464602893592689, 0.7467116982852037, 0.7484272738754003, 0.7487901477751691, 0.7490605726974685, 0.7509120902757146, 0.7516291807752131, 0.7518310769738923, 0.7406922975784337, 0.7484082322326495, 0.7529711064956829, 0.7532303166516346, 0.7532758813920815, 0.7554576266125598, 0.7548822459533577, 0.7566796664100475, 0.7557404287415701, 0.7583670617970878, 0.7580985715380558, 0.7587593202580604, 0.7589827677505033, 0.7595587426175552, 0.7601886550240814, 0.7606248300898142, 0.7597994874225551, 0.7616924008700934, 0.761970325116396, 0.7629511032631283, 0.7605591906553844, 0.7638361126763064, 0.7632310147284052, 0.7632750688990643, 0.7651719834706555]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:02<00:11,  2.87s/it]predicting test subjects:  40%|████      | 2/5 [00:05<00:07,  2.67s/it]predicting test subjects:  60%|██████    | 3/5 [00:06<00:04,  2.44s/it]predicting test subjects:  80%|████████  | 4/5 [00:08<00:02,  2.28s/it]predicting test subjects: 100%|██████████| 5/5 [00:11<00:00,  2.29s/it]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:02<11:59,  2.71s/it]predicting train subjects:   1%|          | 2/266 [00:05<11:42,  2.66s/it]predicting train subjects:   1%|          | 3/266 [00:07<10:57,  2.50s/it]predicting train subjects:   2%|▏         | 4/266 [00:09<10:12,  2.34s/it]predicting train subjects:   2%|▏         | 5/266 [00:11<10:25,  2.40s/it]predicting train subjects:   2%|▏         | 6/266 [00:14<10:52,  2.51s/it]predicting train subjects:   3%|▎         | 7/266 [00:17<11:03,  2.56s/it]predicting train subjects:   3%|▎         | 8/266 [00:20<11:15,  2.62s/it]predicting train subjects:   3%|▎         | 9/266 [00:22<11:15,  2.63s/it]predicting train subjects:   4%|▍         | 10/266 [00:25<11:20,  2.66s/it]predicting train subjects:   4%|▍         | 11/266 [00:28<11:21,  2.67s/it]predicting train subjects:   5%|▍         | 12/266 [00:30<11:24,  2.69s/it]predicting train subjects:   5%|▍         | 13/266 [00:33<11:17,  2.68s/it]predicting train subjects:   5%|▌         | 14/266 [00:36<11:16,  2.69s/it]predicting train subjects:   6%|▌         | 15/266 [00:38<11:14,  2.69s/it]predicting train subjects:   6%|▌         | 16/266 [00:41<11:17,  2.71s/it]predicting train subjects:   6%|▋         | 17/266 [00:44<11:13,  2.71s/it]predicting train subjects:   7%|▋         | 18/266 [00:47<11:14,  2.72s/it]predicting train subjects:   7%|▋         | 19/266 [00:49<11:10,  2.71s/it]predicting train subjects:   8%|▊         | 20/266 [00:52<11:08,  2.72s/it]predicting train subjects:   8%|▊         | 21/266 [00:55<11:03,  2.71s/it]predicting train subjects:   8%|▊         | 22/266 [00:57<10:59,  2.70s/it]predicting train subjects:   9%|▊         | 23/266 [01:00<10:57,  2.70s/it]predicting train subjects:   9%|▉         | 24/266 [01:03<10:49,  2.68s/it]predicting train subjects:   9%|▉         | 25/266 [01:05<10:36,  2.64s/it]predicting train subjects:  10%|▉         | 26/266 [01:08<10:18,  2.58s/it]predicting train subjects:  10%|█         | 27/266 [01:10<10:11,  2.56s/it]predicting train subjects:  11%|█         | 28/266 [01:13<10:03,  2.54s/it]predicting train subjects:  11%|█         | 29/266 [01:15<09:53,  2.50s/it]predicting train subjects:  11%|█▏        | 30/266 [01:18<09:43,  2.47s/it]predicting train subjects:  12%|█▏        | 31/266 [01:20<09:39,  2.46s/it]predicting train subjects:  12%|█▏        | 32/266 [01:23<09:42,  2.49s/it]predicting train subjects:  12%|█▏        | 33/266 [01:25<09:42,  2.50s/it]predicting train subjects:  13%|█▎        | 34/266 [01:28<09:36,  2.49s/it]predicting train subjects:  13%|█▎        | 35/266 [01:30<09:33,  2.48s/it]predicting train subjects:  14%|█▎        | 36/266 [01:33<09:32,  2.49s/it]predicting train subjects:  14%|█▍        | 37/266 [01:35<09:33,  2.50s/it]predicting train subjects:  14%|█▍        | 38/266 [01:38<09:30,  2.50s/it]predicting train subjects:  15%|█▍        | 39/266 [01:40<09:28,  2.50s/it]predicting train subjects:  15%|█▌        | 40/266 [01:43<09:26,  2.51s/it]predicting train subjects:  15%|█▌        | 41/266 [01:45<09:22,  2.50s/it]predicting train subjects:  16%|█▌        | 42/266 [01:47<08:50,  2.37s/it]predicting train subjects:  16%|█▌        | 43/266 [01:49<08:25,  2.27s/it]predicting train subjects:  17%|█▋        | 44/266 [01:51<08:09,  2.21s/it]predicting train subjects:  17%|█▋        | 45/266 [01:53<07:56,  2.15s/it]predicting train subjects:  17%|█▋        | 46/266 [01:55<07:45,  2.11s/it]predicting train subjects:  18%|█▊        | 47/266 [01:57<07:36,  2.09s/it]predicting train subjects:  18%|█▊        | 48/266 [01:59<07:34,  2.09s/it]predicting train subjects:  18%|█▊        | 49/266 [02:01<07:31,  2.08s/it]predicting train subjects:  19%|█▉        | 50/266 [02:04<07:31,  2.09s/it]predicting train subjects:  19%|█▉        | 51/266 [02:06<07:31,  2.10s/it]predicting train subjects:  20%|█▉        | 52/266 [02:08<07:27,  2.09s/it]predicting train subjects:  20%|█▉        | 53/266 [02:10<07:24,  2.09s/it]predicting train subjects:  20%|██        | 54/266 [02:12<07:23,  2.09s/it]predicting train subjects:  21%|██        | 55/266 [02:14<07:19,  2.08s/it]predicting train subjects:  21%|██        | 56/266 [02:16<07:19,  2.09s/it]predicting train subjects:  21%|██▏       | 57/266 [02:18<07:13,  2.08s/it]predicting train subjects:  22%|██▏       | 58/266 [02:20<07:14,  2.09s/it]predicting train subjects:  22%|██▏       | 59/266 [02:22<07:10,  2.08s/it]predicting train subjects:  23%|██▎       | 60/266 [02:24<06:58,  2.03s/it]predicting train subjects:  23%|██▎       | 61/266 [02:26<06:50,  2.00s/it]predicting train subjects:  23%|██▎       | 62/266 [02:28<06:43,  1.98s/it]predicting train subjects:  24%|██▎       | 63/266 [02:30<06:37,  1.96s/it]predicting train subjects:  24%|██▍       | 64/266 [02:32<06:34,  1.95s/it]predicting train subjects:  24%|██▍       | 65/266 [02:34<06:29,  1.94s/it]predicting train subjects:  25%|██▍       | 66/266 [02:36<06:24,  1.92s/it]predicting train subjects:  25%|██▌       | 67/266 [02:38<06:22,  1.92s/it]predicting train subjects:  26%|██▌       | 68/266 [02:40<06:20,  1.92s/it]predicting train subjects:  26%|██▌       | 69/266 [02:42<06:22,  1.94s/it]predicting train subjects:  26%|██▋       | 70/266 [02:44<06:19,  1.94s/it]predicting train subjects:  27%|██▋       | 71/266 [02:46<06:19,  1.95s/it]predicting train subjects:  27%|██▋       | 72/266 [02:47<06:20,  1.96s/it]predicting train subjects:  27%|██▋       | 73/266 [02:49<06:17,  1.95s/it]predicting train subjects:  28%|██▊       | 74/266 [02:51<06:15,  1.95s/it]predicting train subjects:  28%|██▊       | 75/266 [02:53<06:14,  1.96s/it]predicting train subjects:  29%|██▊       | 76/266 [02:55<06:13,  1.97s/it]predicting train subjects:  29%|██▉       | 77/266 [02:57<06:11,  1.96s/it]predicting train subjects:  29%|██▉       | 78/266 [03:00<06:41,  2.13s/it]predicting train subjects:  30%|██▉       | 79/266 [03:02<07:01,  2.25s/it]predicting train subjects:  30%|███       | 80/266 [03:05<07:17,  2.35s/it]predicting train subjects:  30%|███       | 81/266 [03:07<07:24,  2.40s/it]predicting train subjects:  31%|███       | 82/266 [03:10<07:26,  2.43s/it]predicting train subjects:  31%|███       | 83/266 [03:12<07:29,  2.46s/it]predicting train subjects:  32%|███▏      | 84/266 [03:15<07:31,  2.48s/it]predicting train subjects:  32%|███▏      | 85/266 [03:18<07:33,  2.51s/it]predicting train subjects:  32%|███▏      | 86/266 [03:20<07:32,  2.51s/it]predicting train subjects:  33%|███▎      | 87/266 [03:23<07:25,  2.49s/it]predicting train subjects:  33%|███▎      | 88/266 [03:25<07:27,  2.52s/it]predicting train subjects:  33%|███▎      | 89/266 [03:28<07:27,  2.53s/it]predicting train subjects:  34%|███▍      | 90/266 [03:30<07:24,  2.53s/it]predicting train subjects:  34%|███▍      | 91/266 [03:33<07:26,  2.55s/it]predicting train subjects:  35%|███▍      | 92/266 [03:35<07:22,  2.54s/it]predicting train subjects:  35%|███▍      | 93/266 [03:38<07:22,  2.56s/it]predicting train subjects:  35%|███▌      | 94/266 [03:40<07:17,  2.54s/it]predicting train subjects:  36%|███▌      | 95/266 [03:43<07:14,  2.54s/it]predicting train subjects:  36%|███▌      | 96/266 [03:45<06:53,  2.43s/it]predicting train subjects:  36%|███▋      | 97/266 [03:48<06:52,  2.44s/it]predicting train subjects:  37%|███▋      | 98/266 [03:50<06:50,  2.45s/it]predicting train subjects:  37%|███▋      | 99/266 [03:52<06:21,  2.28s/it]predicting train subjects:  38%|███▊      | 100/266 [03:54<06:07,  2.21s/it]predicting train subjects:  38%|███▊      | 101/266 [03:56<06:01,  2.19s/it]predicting train subjects:  38%|███▊      | 102/266 [03:58<05:55,  2.17s/it]predicting train subjects:  39%|███▊      | 103/266 [04:00<05:51,  2.16s/it]predicting train subjects:  39%|███▉      | 104/266 [04:03<05:52,  2.18s/it]predicting train subjects:  39%|███▉      | 105/266 [04:05<05:50,  2.18s/it]predicting train subjects:  40%|███▉      | 106/266 [04:07<05:47,  2.17s/it]predicting train subjects:  40%|████      | 107/266 [04:09<05:43,  2.16s/it]predicting train subjects:  41%|████      | 108/266 [04:11<05:46,  2.19s/it]predicting train subjects:  41%|████      | 109/266 [04:14<05:45,  2.20s/it]predicting train subjects:  41%|████▏     | 110/266 [04:16<05:43,  2.20s/it]predicting train subjects:  42%|████▏     | 111/266 [04:18<05:44,  2.22s/it]predicting train subjects:  42%|████▏     | 112/266 [04:20<05:39,  2.20s/it]predicting train subjects:  42%|████▏     | 113/266 [04:22<05:35,  2.19s/it]predicting train subjects:  43%|████▎     | 114/266 [04:25<05:32,  2.19s/it]predicting train subjects:  43%|████▎     | 115/266 [04:27<05:32,  2.20s/it]predicting train subjects:  44%|████▎     | 116/266 [04:29<05:27,  2.18s/it]predicting train subjects:  44%|████▍     | 117/266 [04:31<05:22,  2.16s/it]predicting train subjects:  44%|████▍     | 118/266 [04:33<05:17,  2.14s/it]predicting train subjects:  45%|████▍     | 119/266 [04:36<05:30,  2.25s/it]predicting train subjects:  45%|████▌     | 120/266 [04:38<05:44,  2.36s/it]predicting train subjects:  45%|████▌     | 121/266 [04:41<05:51,  2.42s/it]predicting train subjects:  46%|████▌     | 122/266 [04:43<05:52,  2.45s/it]predicting train subjects:  46%|████▌     | 123/266 [04:46<05:53,  2.47s/it]predicting train subjects:  47%|████▋     | 124/266 [04:48<05:53,  2.49s/it]predicting train subjects:  47%|████▋     | 125/266 [04:51<05:51,  2.49s/it]predicting train subjects:  47%|████▋     | 126/266 [04:53<05:49,  2.50s/it]predicting train subjects:  48%|████▊     | 127/266 [04:56<05:45,  2.48s/it]predicting train subjects:  48%|████▊     | 128/266 [04:58<05:44,  2.50s/it]predicting train subjects:  48%|████▊     | 129/266 [05:01<05:43,  2.51s/it]predicting train subjects:  49%|████▉     | 130/266 [05:04<05:44,  2.53s/it]predicting train subjects:  49%|████▉     | 131/266 [05:06<05:43,  2.54s/it]predicting train subjects:  50%|████▉     | 132/266 [05:09<05:42,  2.55s/it]predicting train subjects:  50%|█████     | 133/266 [05:11<05:38,  2.55s/it]predicting train subjects:  50%|█████     | 134/266 [05:14<05:37,  2.56s/it]predicting train subjects:  51%|█████     | 135/266 [05:16<05:32,  2.54s/it]predicting train subjects:  51%|█████     | 136/266 [05:19<05:30,  2.54s/it]predicting train subjects:  52%|█████▏    | 137/266 [05:21<05:27,  2.54s/it]predicting train subjects:  52%|█████▏    | 138/266 [05:24<05:18,  2.49s/it]predicting train subjects:  52%|█████▏    | 139/266 [05:26<05:16,  2.50s/it]predicting train subjects:  53%|█████▎    | 140/266 [05:29<05:12,  2.48s/it]predicting train subjects:  53%|█████▎    | 141/266 [05:31<05:10,  2.48s/it]predicting train subjects:  53%|█████▎    | 142/266 [05:34<05:06,  2.47s/it]predicting train subjects:  54%|█████▍    | 143/266 [05:36<05:03,  2.47s/it]predicting train subjects:  54%|█████▍    | 144/266 [05:39<05:10,  2.54s/it]predicting train subjects:  55%|█████▍    | 145/266 [05:41<05:07,  2.54s/it]predicting train subjects:  55%|█████▍    | 146/266 [05:44<05:03,  2.53s/it]predicting train subjects:  55%|█████▌    | 147/266 [05:46<05:04,  2.56s/it]predicting train subjects:  56%|█████▌    | 148/266 [05:49<04:57,  2.52s/it]predicting train subjects:  56%|█████▌    | 149/266 [05:51<04:50,  2.49s/it]predicting train subjects:  56%|█████▋    | 150/266 [05:54<04:50,  2.50s/it]predicting train subjects:  57%|█████▋    | 151/266 [05:56<04:43,  2.47s/it]predicting train subjects:  57%|█████▋    | 152/266 [05:59<04:39,  2.45s/it]predicting train subjects:  58%|█████▊    | 153/266 [06:01<04:35,  2.44s/it]predicting train subjects:  58%|█████▊    | 154/266 [06:04<04:34,  2.45s/it]predicting train subjects:  58%|█████▊    | 155/266 [06:05<04:13,  2.28s/it]predicting train subjects:  59%|█████▊    | 156/266 [06:07<03:56,  2.15s/it]predicting train subjects:  59%|█████▉    | 157/266 [06:09<03:41,  2.03s/it]predicting train subjects:  59%|█████▉    | 158/266 [06:11<03:31,  1.96s/it]predicting train subjects:  60%|█████▉    | 159/266 [06:13<03:25,  1.92s/it]predicting train subjects:  60%|██████    | 160/266 [06:14<03:19,  1.88s/it]predicting train subjects:  61%|██████    | 161/266 [06:16<03:15,  1.86s/it]predicting train subjects:  61%|██████    | 162/266 [06:18<03:12,  1.85s/it]predicting train subjects:  61%|██████▏   | 163/266 [06:20<03:10,  1.85s/it]predicting train subjects:  62%|██████▏   | 164/266 [06:22<03:05,  1.82s/it]predicting train subjects:  62%|██████▏   | 165/266 [06:24<03:04,  1.83s/it]predicting train subjects:  62%|██████▏   | 166/266 [06:25<03:00,  1.81s/it]predicting train subjects:  63%|██████▎   | 167/266 [06:27<02:58,  1.80s/it]predicting train subjects:  63%|██████▎   | 168/266 [06:29<02:55,  1.79s/it]predicting train subjects:  64%|██████▎   | 169/266 [06:31<02:53,  1.79s/it]predicting train subjects:  64%|██████▍   | 170/266 [06:32<02:52,  1.80s/it]predicting train subjects:  64%|██████▍   | 171/266 [06:34<02:50,  1.79s/it]predicting train subjects:  65%|██████▍   | 172/266 [06:36<02:49,  1.80s/it]predicting train subjects:  65%|██████▌   | 173/266 [06:38<02:54,  1.88s/it]predicting train subjects:  65%|██████▌   | 174/266 [06:40<02:57,  1.92s/it]predicting train subjects:  66%|██████▌   | 175/266 [06:42<02:57,  1.95s/it]predicting train subjects:  66%|██████▌   | 176/266 [06:44<02:57,  1.97s/it]predicting train subjects:  67%|██████▋   | 177/266 [06:46<02:56,  1.98s/it]predicting train subjects:  67%|██████▋   | 178/266 [06:48<02:58,  2.03s/it]predicting train subjects:  67%|██████▋   | 179/266 [06:50<03:00,  2.08s/it]predicting train subjects:  68%|██████▊   | 180/266 [06:53<02:56,  2.06s/it]predicting train subjects:  68%|██████▊   | 181/266 [06:55<02:54,  2.05s/it]predicting train subjects:  68%|██████▊   | 182/266 [06:57<02:52,  2.06s/it]predicting train subjects:  69%|██████▉   | 183/266 [06:59<02:51,  2.07s/it]predicting train subjects:  69%|██████▉   | 184/266 [07:01<02:49,  2.07s/it]predicting train subjects:  70%|██████▉   | 185/266 [07:03<02:48,  2.08s/it]predicting train subjects:  70%|██████▉   | 186/266 [07:05<02:47,  2.09s/it]predicting train subjects:  70%|███████   | 187/266 [07:07<02:44,  2.08s/it]predicting train subjects:  71%|███████   | 188/266 [07:09<02:41,  2.07s/it]predicting train subjects:  71%|███████   | 189/266 [07:11<02:39,  2.07s/it]predicting train subjects:  71%|███████▏  | 190/266 [07:13<02:38,  2.09s/it]predicting train subjects:  72%|███████▏  | 191/266 [07:15<02:38,  2.12s/it]predicting train subjects:  72%|███████▏  | 192/266 [07:17<02:31,  2.05s/it]predicting train subjects:  73%|███████▎  | 193/266 [07:19<02:27,  2.02s/it]predicting train subjects:  73%|███████▎  | 194/266 [07:22<02:35,  2.15s/it]predicting train subjects:  73%|███████▎  | 195/266 [07:24<02:33,  2.16s/it]predicting train subjects:  74%|███████▎  | 196/266 [07:26<02:31,  2.16s/it]predicting train subjects:  74%|███████▍  | 197/266 [07:28<02:28,  2.16s/it]predicting train subjects:  74%|███████▍  | 198/266 [07:30<02:27,  2.17s/it]predicting train subjects:  75%|███████▍  | 199/266 [07:33<02:26,  2.19s/it]predicting train subjects:  75%|███████▌  | 200/266 [07:35<02:23,  2.18s/it]predicting train subjects:  76%|███████▌  | 201/266 [07:37<02:22,  2.19s/it]predicting train subjects:  76%|███████▌  | 202/266 [07:39<02:20,  2.20s/it]predicting train subjects:  76%|███████▋  | 203/266 [07:41<02:17,  2.18s/it]predicting train subjects:  77%|███████▋  | 204/266 [07:44<02:16,  2.20s/it]predicting train subjects:  77%|███████▋  | 205/266 [07:46<02:12,  2.18s/it]predicting train subjects:  77%|███████▋  | 206/266 [07:48<02:11,  2.19s/it]predicting train subjects:  78%|███████▊  | 207/266 [07:50<02:09,  2.19s/it]predicting train subjects:  78%|███████▊  | 208/266 [07:52<02:06,  2.17s/it]predicting train subjects:  79%|███████▊  | 209/266 [07:55<02:04,  2.19s/it]predicting train subjects:  79%|███████▉  | 210/266 [07:57<02:02,  2.18s/it]predicting train subjects:  79%|███████▉  | 211/266 [07:59<01:58,  2.16s/it]predicting train subjects:  80%|███████▉  | 212/266 [08:01<01:56,  2.15s/it]predicting train subjects:  80%|████████  | 213/266 [08:03<01:50,  2.08s/it]predicting train subjects:  80%|████████  | 214/266 [08:05<01:46,  2.04s/it]predicting train subjects:  81%|████████  | 215/266 [08:07<01:41,  2.00s/it]predicting train subjects:  81%|████████  | 216/266 [08:09<01:39,  1.98s/it]predicting train subjects:  82%|████████▏ | 217/266 [08:11<01:35,  1.96s/it]predicting train subjects:  82%|████████▏ | 218/266 [08:13<01:33,  1.96s/it]predicting train subjects:  82%|████████▏ | 219/266 [08:14<01:31,  1.96s/it]predicting train subjects:  83%|████████▎ | 220/266 [08:16<01:30,  1.96s/it]predicting train subjects:  83%|████████▎ | 221/266 [08:18<01:28,  1.96s/it]predicting train subjects:  83%|████████▎ | 222/266 [08:20<01:26,  1.97s/it]predicting train subjects:  84%|████████▍ | 223/266 [08:22<01:24,  1.96s/it]predicting train subjects:  84%|████████▍ | 224/266 [08:24<01:21,  1.93s/it]predicting train subjects:  85%|████████▍ | 225/266 [08:26<01:20,  1.95s/it]predicting train subjects:  85%|████████▍ | 226/266 [08:28<01:17,  1.94s/it]predicting train subjects:  85%|████████▌ | 227/266 [08:30<01:14,  1.92s/it]predicting train subjects:  86%|████████▌ | 228/266 [08:32<01:14,  1.95s/it]predicting train subjects:  86%|████████▌ | 229/266 [08:34<01:11,  1.93s/it]predicting train subjects:  86%|████████▋ | 230/266 [08:36<01:09,  1.93s/it]predicting train subjects:  87%|████████▋ | 231/266 [08:38<01:07,  1.93s/it]predicting train subjects:  87%|████████▋ | 232/266 [08:40<01:06,  1.94s/it]predicting train subjects:  88%|████████▊ | 233/266 [08:42<01:04,  1.95s/it]predicting train subjects:  88%|████████▊ | 234/266 [08:44<01:02,  1.95s/it]predicting train subjects:  88%|████████▊ | 235/266 [08:46<00:59,  1.93s/it]predicting train subjects:  89%|████████▊ | 236/266 [08:47<00:57,  1.92s/it]predicting train subjects:  89%|████████▉ | 237/266 [08:49<00:55,  1.91s/it]predicting train subjects:  89%|████████▉ | 238/266 [08:51<00:53,  1.90s/it]predicting train subjects:  90%|████████▉ | 239/266 [08:53<00:50,  1.89s/it]predicting train subjects:  90%|█████████ | 240/266 [08:55<00:49,  1.89s/it]predicting train subjects:  91%|█████████ | 241/266 [08:57<00:47,  1.90s/it]predicting train subjects:  91%|█████████ | 242/266 [08:59<00:45,  1.90s/it]predicting train subjects:  91%|█████████▏| 243/266 [09:01<00:44,  1.93s/it]predicting train subjects:  92%|█████████▏| 244/266 [09:03<00:42,  1.92s/it]predicting train subjects:  92%|█████████▏| 245/266 [09:05<00:40,  1.92s/it]predicting train subjects:  92%|█████████▏| 246/266 [09:07<00:38,  1.92s/it]predicting train subjects:  93%|█████████▎| 247/266 [09:08<00:36,  1.92s/it]predicting train subjects:  93%|█████████▎| 248/266 [09:10<00:34,  1.93s/it]predicting train subjects:  94%|█████████▎| 249/266 [09:13<00:35,  2.08s/it]predicting train subjects:  94%|█████████▍| 250/266 [09:15<00:35,  2.19s/it]predicting train subjects:  94%|█████████▍| 251/266 [09:18<00:34,  2.27s/it]predicting train subjects:  95%|█████████▍| 252/266 [09:20<00:32,  2.35s/it]predicting train subjects:  95%|█████████▌| 253/266 [09:23<00:31,  2.39s/it]predicting train subjects:  95%|█████████▌| 254/266 [09:25<00:28,  2.42s/it]predicting train subjects:  96%|█████████▌| 255/266 [09:28<00:26,  2.42s/it]predicting train subjects:  96%|█████████▌| 256/266 [09:30<00:24,  2.44s/it]predicting train subjects:  97%|█████████▋| 257/266 [09:33<00:22,  2.47s/it]predicting train subjects:  97%|█████████▋| 258/266 [09:35<00:19,  2.49s/it]predicting train subjects:  97%|█████████▋| 259/266 [09:38<00:17,  2.53s/it]predicting train subjects:  98%|█████████▊| 260/266 [09:40<00:15,  2.52s/it]predicting train subjects:  98%|█████████▊| 261/266 [09:43<00:12,  2.53s/it]predicting train subjects:  98%|█████████▊| 262/266 [09:45<00:10,  2.51s/it]predicting train subjects:  99%|█████████▉| 263/266 [09:48<00:07,  2.51s/it]predicting train subjects:  99%|█████████▉| 264/266 [09:50<00:04,  2.50s/it]predicting train subjects: 100%|█████████▉| 265/266 [09:53<00:02,  2.50s/it]predicting train subjects: 100%|██████████| 266/266 [09:55<00:00,  2.52s/it]

