*** DATASET ALREADY EXIST; PLEASE REMOVE 'train' & 'test' SUBFOLDERS ***
(0/532) train vimp2_1448_08132015_SRI
(1/532) train vimp2_1452_10162014_SRI
(2/532) train vimp2_1510_04202015_SRI
(3/532) train vimp2_1519_04212015_SRI
(4/532) train vimp2_1530_04232015_SRI
(5/532) train vimp2_1557_05062015_SRI
(6/532) train vimp2_1559_05062015_SRI
(7/532) train vimp2_1564_05072015_SRI
(8/532) train vimp2_1604_10092015_SRI
(9/532) train vimp2_1620_05292015_SRI
(10/532) train vimp2_1621_05292015_SRI
(11/532) train vimp2_1621_10162015_SRI
(12/532) train vimp2_1622_05292015_SRI
(13/532) train vimp2_1623_05292015_SRI
(14/532) train vimp2_1632_10232015_SRI
(15/532) train vimp2_1648_10282015_SRI
(16/532) train vimp2_1689_06262015_SRI
(17/532) train vimp2_1709_07072015_SRI
(18/532) train vimp2_1712_11162015_SRI
(19/532) train vimp2_1724_11202015_SRI
(20/532) train vimp2_1751_12022015_SRI
(21/532) train vimp2_1756_12032015_SRI
(22/532) train vimp2_1761_12042015_SRI
(23/532) train vimp2_1844_01142016_SRI
(24/532) train vimp2_1847_01152016_SRI
(25/532) train vimp2_1888_01292016_SRI
(26/532) train vimp2_1907_02052016_SRI
(27/532) train vimp2_2039_03182016_SRI
(28/532) train vimp2_2119_04142016_SRI
(29/532) train vimp2_2309_07072016_SRI
(30/532) train vimp2_2390_07272016_SRI
(31/532) train vimp2_2398_07292016_SRI
(32/532) train vimp2_2450_08172016_SRI
(33/532) train vimp2_2459_08192016_SRI
(34/532) train vimp2_2460_08192016_SRI
(35/532) train vimp2_2476_08242016_SRI
(36/532) train vimp2_2484_08252016_SRI
(37/532) train vimp2_2485_08252016_SRI
(38/532) train vimp2_2499_08302016_SRI
(39/532) train vimp2_2617_10262016_SRI
(40/532) train vimp2_2618_10262016_SRI
(41/532) train vimp2_2628_10282016_SRI
(42/532) train vimp2_2878_01262017_SRI
(43/532) train vimp2_2914_02162017_Test_NewCases_SRI
(44/532) train vimp2_2926_02222017_Test_NewCases_SRI
(45/532) train vimp2_2946_03032017_Test_NewCases_SRI
(46/532) train vimp2_2948_03042017_Test_NewCases_SRI
(47/532) train vimp2_2966_03092017_Test_NewCases_SRI
(48/532) train vimp2_2972_03102017_Test_NewCases_SRI
(49/532) train vimp2_2998_03222017_Test_NewCases_SRI
(50/532) train vimp2_3131_05182017_SRI
(51/532) train vimp2_3187_06092017_SRI
(52/532) train vimp2_3349_08012017_SRI
(53/532) train vimp2_676_04252014_SRI
(54/532) train vimp2_804_06042014_SRI
(55/532) train vimp2_1082_12092014_SRI
(56/532) train vimp2_1116_12152014_SRI
(57/532) train vimp2_1278_02062015_SRI
(58/532) train vimp2_1443_08122015_SRI
(59/532) train vimp2_1662_10302015_SRI
(60/532) train vimp2_2438_08122016_SRI
(61/532) train vimp2_2846_01112017_SRI
(62/532) train vimp2_1139_12192014_SRI
(63/532) train vimp2_1220_01212015_SRI
(64/532) train vimp2_1400_03132015_SRI
(65/532) train vimp2_1510_09022015_SRI
(66/532) train vimp2_1739_11242015_SRI
(67/532) train vimp2_2462_08192016_Test_NewCases_SRI
(68/532) train vimp2_702_04302014_SRI
(69/532) train vimp2_969_07142014_SRI
(70/532) train vimp2_1100_08062014_SRI
(71/532) train vimp2_1276_02052015_SRI
(72/532) train vimp2_1410_03172015_SRI
(73/532) train vimp2_1595_05202015_SRI
(74/532) train vimp2_1875_01262016_SRI
(75/532) train vimp2_2951_03062017_Test_NewCases_SRI
(76/532) train vimp2_1082_12092014_SRI_Aug0_Rot_-3_sd1
(77/532) train vimp2_1082_12092014_SRI_Aug0_Rot_-6_sd2
(78/532) train vimp2_1082_12092014_SRI_Aug0_Rot_7_sd0
(79/532) train vimp2_1082_12092014_SRI_Aug1_Rot_-2_sd2
(80/532) train vimp2_1082_12092014_SRI_Aug1_Rot_-3_sd0
(81/532) train vimp2_1082_12092014_SRI_Aug1_Rot_-7_sd1
(82/532) train vimp2_1100_08062014_SRI_Aug0_Rot_2_sd1
(83/532) train vimp2_1100_08062014_SRI_Aug0_Rot_-2_sd2
(84/532) train vimp2_1100_08062014_SRI_Aug0_Rot_4_sd0
(85/532) train vimp2_1100_08062014_SRI_Aug1_Rot_-2_sd2
(86/532) train vimp2_1100_08062014_SRI_Aug1_Rot_-3_sd0
(87/532) train vimp2_1100_08062014_SRI_Aug1_Rot_5_sd1
(88/532) train vimp2_1116_12152014_SRI_Aug0_Rot_3_sd0
(89/532) train vimp2_1116_12152014_SRI_Aug0_Rot_3_sd2
(90/532) train vimp2_1116_12152014_SRI_Aug0_Rot_-7_sd1
(91/532) train vimp2_1116_12152014_SRI_Aug1_Rot_3_sd1
(92/532) train vimp2_1116_12152014_SRI_Aug1_Rot_6_sd2
(93/532) train vimp2_1116_12152014_SRI_Aug1_Rot_-7_sd0
(94/532) train vimp2_1139_12192014_SRI_Aug0_Rot_-2_sd1
(95/532) train vimp2_1139_12192014_SRI_Aug0_Rot_3_sd0
(96/532) train vimp2_1139_12192014_SRI_Aug0_Rot_-5_sd2
(97/532) train vimp2_1139_12192014_SRI_Aug1_Rot_-1_sd0
(98/532) train vimp2_1139_12192014_SRI_Aug1_Rot_3_sd2
(99/532) train vimp2_1139_12192014_SRI_Aug1_Rot_-6_sd1
(100/532) train vimp2_1220_01212015_SRI_Aug0_Rot_1_sd2
(101/532) train vimp2_1220_01212015_SRI_Aug0_Rot_6_sd1
(102/532) train vimp2_1220_01212015_SRI_Aug0_Rot_-7_sd0
(103/532) train vimp2_1220_01212015_SRI_Aug1_Rot_-1_sd0
(104/532) train vimp2_1220_01212015_SRI_Aug1_Rot_-1_sd2
(105/532) train vimp2_1220_01212015_SRI_Aug1_Rot_-4_sd1
(106/532) train vimp2_1276_02052015_SRI_Aug0_Rot_-1_sd0
(107/532) train vimp2_1276_02052015_SRI_Aug0_Rot_2_sd2
(108/532) train vimp2_1276_02052015_SRI_Aug0_Rot_7_sd1
(109/532) train vimp2_1276_02052015_SRI_Aug1_Rot_-2_sd1
(110/532) train vimp2_1276_02052015_SRI_Aug1_Rot_-4_sd2
(111/532) train vimp2_1276_02052015_SRI_Aug1_Rot_-6_sd0
(112/532) train vimp2_1278_02062015_SRI_Aug0_Rot_3_sd1
(113/532) train vimp2_1278_02062015_SRI_Aug0_Rot_3_sd2
(114/532) train vimp2_1278_02062015_SRI_Aug0_Rot_-5_sd0
(115/532) train vimp2_1278_02062015_SRI_Aug1_Rot_1_sd1
(116/532) train vimp2_1278_02062015_SRI_Aug1_Rot_-4_sd0
(117/532) train vimp2_1278_02062015_SRI_Aug1_Rot_5_sd2
(118/532) train vimp2_1400_03132015_SRI_Aug0_Rot_2_sd2
(119/532) train vimp2_1400_03132015_SRI_Aug0_Rot_-4_sd0
(120/532) train vimp2_1400_03132015_SRI_Aug0_Rot_-4_sd1
(121/532) train vimp2_1400_03132015_SRI_Aug1_Rot_1_sd1
(122/532) train vimp2_1400_03132015_SRI_Aug1_Rot_-2_sd2
(123/532) train vimp2_1400_03132015_SRI_Aug1_Rot_-6_sd0
(124/532) train vimp2_1410_03172015_SRI_Aug0_Rot_2_sd1
(125/532) train vimp2_1410_03172015_SRI_Aug0_Rot_-3_sd0
(126/532) train vimp2_1410_03172015_SRI_Aug0_Rot_-5_sd2
(127/532) train vimp2_1410_03172015_SRI_Aug1_Rot_-3_sd1
(128/532) train vimp2_1410_03172015_SRI_Aug1_Rot_5_sd2
(129/532) train vimp2_1410_03172015_SRI_Aug1_Rot_6_sd0
(130/532) train vimp2_1443_08122015_SRI_Aug0_Rot_1_sd2
(131/532) train vimp2_1443_08122015_SRI_Aug0_Rot_-5_sd0
(132/532) train vimp2_1443_08122015_SRI_Aug0_Rot_-7_sd1
(133/532) train vimp2_1443_08122015_SRI_Aug1_Rot_-1_sd1
(134/532) train vimp2_1443_08122015_SRI_Aug1_Rot_2_sd0
(135/532) train vimp2_1443_08122015_SRI_Aug1_Rot_7_sd2
(136/532) train vimp2_1448_08132015_SRI_Aug0_Rot_-1_sd0
(137/532) train vimp2_1448_08132015_SRI_Aug0_Rot_2_sd2
(138/532) train vimp2_1448_08132015_SRI_Aug0_Rot_-6_sd1
(139/532) train vimp2_1448_08132015_SRI_Aug1_Rot_1_sd1
(140/532) train vimp2_1448_08132015_SRI_Aug1_Rot_-3_sd0
(141/532) train vimp2_1448_08132015_SRI_Aug1_Rot_5_sd2
(142/532) train vimp2_1452_10162014_SRI_Aug0_Rot_-4_sd1
(143/532) train vimp2_1452_10162014_SRI_Aug0_Rot_-5_sd0
(144/532) train vimp2_1452_10162014_SRI_Aug0_Rot_6_sd2
(145/532) train vimp2_1452_10162014_SRI_Aug1_Rot_-4_sd1
(146/532) train vimp2_1452_10162014_SRI_Aug1_Rot_-4_sd2
(147/532) train vimp2_1452_10162014_SRI_Aug1_Rot_7_sd0
(148/532) train vimp2_1510_04202015_SRI_Aug0_Rot_1_sd2
(149/532) train vimp2_1510_04202015_SRI_Aug0_Rot_3_sd0
(150/532) train vimp2_1510_04202015_SRI_Aug0_Rot_-7_sd1
(151/532) train vimp2_1510_04202015_SRI_Aug1_Rot_-1_sd2
(152/532) train vimp2_1510_04202015_SRI_Aug1_Rot_3_sd0
(153/532) train vimp2_1510_04202015_SRI_Aug1_Rot_4_sd1
(154/532) train vimp2_1510_09022015_SRI_Aug0_Rot_-2_sd1
(155/532) train vimp2_1510_09022015_SRI_Aug0_Rot_3_sd0
(156/532) train vimp2_1510_09022015_SRI_Aug0_Rot_3_sd2
(157/532) train vimp2_1510_09022015_SRI_Aug1_Rot_3_sd0
(158/532) train vimp2_1510_09022015_SRI_Aug1_Rot_-5_sd2
(159/532) train vimp2_1510_09022015_SRI_Aug1_Rot_7_sd1
(160/532) train vimp2_1519_04212015_SRI_Aug0_Rot_1_sd0
(161/532) train vimp2_1519_04212015_SRI_Aug0_Rot_2_sd2
(162/532) train vimp2_1519_04212015_SRI_Aug0_Rot_5_sd1
(163/532) train vimp2_1519_04212015_SRI_Aug1_Rot_1_sd1
(164/532) train vimp2_1519_04212015_SRI_Aug1_Rot_2_sd2
(165/532) train vimp2_1519_04212015_SRI_Aug1_Rot_-6_sd0
(166/532) train vimp2_1530_04232015_SRI_Aug0_Rot_1_sd0
(167/532) train vimp2_1530_04232015_SRI_Aug0_Rot_1_sd2
(168/532) train vimp2_1530_04232015_SRI_Aug0_Rot_-5_sd1
(169/532) train vimp2_1530_04232015_SRI_Aug1_Rot_3_sd0
(170/532) train vimp2_1530_04232015_SRI_Aug1_Rot_-3_sd2
(171/532) train vimp2_1530_04232015_SRI_Aug1_Rot_-4_sd1
(172/532) train vimp2_1557_05062015_SRI_Aug0_Rot_-2_sd2
(173/532) train vimp2_1557_05062015_SRI_Aug0_Rot_4_sd1
(174/532) train vimp2_1557_05062015_SRI_Aug0_Rot_5_sd0
(175/532) train vimp2_1557_05062015_SRI_Aug1_Rot_-1_sd0
(176/532) train vimp2_1557_05062015_SRI_Aug1_Rot_-2_sd2
(177/532) train vimp2_1557_05062015_SRI_Aug1_Rot_3_sd1
(178/532) train vimp2_1559_05062015_SRI_Aug0_Rot_4_sd1
(179/532) train vimp2_1559_05062015_SRI_Aug0_Rot_-7_sd0
(180/532) train vimp2_1559_05062015_SRI_Aug0_Rot_7_sd2
(181/532) train vimp2_1559_05062015_SRI_Aug1_Rot_3_sd0
(182/532) train vimp2_1559_05062015_SRI_Aug1_Rot_-6_sd1
(183/532) train vimp2_1559_05062015_SRI_Aug1_Rot_-7_sd2
(184/532) train vimp2_1564_05072015_SRI_Aug0_Rot_-2_sd1
(185/532) train vimp2_1564_05072015_SRI_Aug0_Rot_6_sd2
(186/532) train vimp2_1564_05072015_SRI_Aug0_Rot_-7_sd0
(187/532) train vimp2_1564_05072015_SRI_Aug1_Rot_-1_sd0
(188/532) train vimp2_1564_05072015_SRI_Aug1_Rot_-4_sd1
(189/532) train vimp2_1564_05072015_SRI_Aug1_Rot_6_sd2
(190/532) train vimp2_1595_05202015_SRI_Aug0_Rot_3_sd0
(191/532) train vimp2_1595_05202015_SRI_Aug0_Rot_-6_sd2
(192/532) train vimp2_1595_05202015_SRI_Aug0_Rot_-7_sd1
(193/532) train vimp2_1595_05202015_SRI_Aug1_Rot_1_sd0
(194/532) train vimp2_1595_05202015_SRI_Aug1_Rot_2_sd1
(195/532) train vimp2_1595_05202015_SRI_Aug1_Rot_-2_sd2
(196/532) train vimp2_1604_10092015_SRI_Aug0_Rot_-1_sd2
(197/532) train vimp2_1604_10092015_SRI_Aug0_Rot_-4_sd1
(198/532) train vimp2_1604_10092015_SRI_Aug0_Rot_7_sd0
(199/532) train vimp2_1604_10092015_SRI_Aug1_Rot_1_sd2
(200/532) train vimp2_1604_10092015_SRI_Aug1_Rot_2_sd1
(201/532) train vimp2_1604_10092015_SRI_Aug1_Rot_5_sd0
(202/532) train vimp2_1620_05292015_SRI_Aug0_Rot_-6_sd1
(203/532) train vimp2_1620_05292015_SRI_Aug0_Rot_7_sd0
(204/532) train vimp2_1620_05292015_SRI_Aug0_Rot_7_sd2
(205/532) train vimp2_1620_05292015_SRI_Aug1_Rot_1_sd1
(206/532) train vimp2_1620_05292015_SRI_Aug1_Rot_3_sd2
(207/532) train vimp2_1620_05292015_SRI_Aug1_Rot_-4_sd0
(208/532) train vimp2_1621_05292015_SRI_Aug0_Rot_0_sd1
(209/532) train vimp2_1621_05292015_SRI_Aug0_Rot_4_sd2
(210/532) train vimp2_1621_05292015_SRI_Aug0_Rot_-7_sd0
(211/532) train vimp2_1621_05292015_SRI_Aug1_Rot_1_sd0
(212/532) train vimp2_1621_05292015_SRI_Aug1_Rot_2_sd1
(213/532) train vimp2_1621_05292015_SRI_Aug1_Rot_6_sd2
(214/532) train vimp2_1621_10162015_SRI_Aug0_Rot_1_sd1
(215/532) train vimp2_1621_10162015_SRI_Aug0_Rot_-2_sd0
(216/532) train vimp2_1621_10162015_SRI_Aug0_Rot_3_sd2
(217/532) train vimp2_1621_10162015_SRI_Aug1_Rot_-1_sd1
(218/532) train vimp2_1621_10162015_SRI_Aug1_Rot_2_sd0
(219/532) train vimp2_1621_10162015_SRI_Aug1_Rot_-4_sd2
(220/532) train vimp2_1622_05292015_SRI_Aug0_Rot_-1_sd0
(221/532) train vimp2_1622_05292015_SRI_Aug0_Rot_-1_sd1
(222/532) train vimp2_1622_05292015_SRI_Aug0_Rot_-5_sd2
(223/532) train vimp2_1622_05292015_SRI_Aug1_Rot_3_sd0
(224/532) train vimp2_1622_05292015_SRI_Aug1_Rot_3_sd2
(225/532) train vimp2_1622_05292015_SRI_Aug1_Rot_-5_sd1
(226/532) train vimp2_1623_05292015_SRI_Aug0_Rot_-3_sd0
(227/532) train vimp2_1623_05292015_SRI_Aug0_Rot_-3_sd2
(228/532) train vimp2_1623_05292015_SRI_Aug0_Rot_-4_sd1
(229/532) train vimp2_1623_05292015_SRI_Aug1_Rot_6_sd2
(230/532) train vimp2_1623_05292015_SRI_Aug1_Rot_7_sd0
(231/532) train vimp2_1623_05292015_SRI_Aug1_Rot_7_sd1
(232/532) train vimp2_1632_10232015_SRI_Aug0_Rot_0_sd2
(233/532) train vimp2_1632_10232015_SRI_Aug0_Rot_1_sd1
(234/532) train vimp2_1632_10232015_SRI_Aug0_Rot_-6_sd0
(235/532) train vimp2_1632_10232015_SRI_Aug1_Rot_-3_sd1
(236/532) train vimp2_1632_10232015_SRI_Aug1_Rot_4_sd2
(237/532) train vimp2_1632_10232015_SRI_Aug1_Rot_7_sd0
(238/532) train vimp2_1648_10282015_SRI_Aug0_Rot_-1_sd2
(239/532) train vimp2_1648_10282015_SRI_Aug0_Rot_3_sd0
(240/532) train vimp2_1648_10282015_SRI_Aug0_Rot_-4_sd1
(241/532) train vimp2_1648_10282015_SRI_Aug1_Rot_1_sd0
(242/532) train vimp2_1648_10282015_SRI_Aug1_Rot_2_sd2
(243/532) train vimp2_1648_10282015_SRI_Aug1_Rot_-3_sd1
(244/532) train vimp2_1662_10302015_SRI_Aug0_Rot_-3_sd0
(245/532) train vimp2_1662_10302015_SRI_Aug0_Rot_3_sd2
(246/532) train vimp2_1662_10302015_SRI_Aug0_Rot_-6_sd1
(247/532) train vimp2_1662_10302015_SRI_Aug1_Rot_-3_sd1
(248/532) train vimp2_1662_10302015_SRI_Aug1_Rot_-7_sd0
(249/532) train vimp2_1662_10302015_SRI_Aug1_Rot_-7_sd2
(250/532) train vimp2_1689_06262015_SRI_Aug0_Rot_-4_sd2
(251/532) train vimp2_1689_06262015_SRI_Aug0_Rot_5_sd0
(252/532) train vimp2_1689_06262015_SRI_Aug0_Rot_-7_sd1
(253/532) train vimp2_1689_06262015_SRI_Aug1_Rot_-1_sd0
(254/532) train vimp2_1689_06262015_SRI_Aug1_Rot_-2_sd1
(255/532) train vimp2_1689_06262015_SRI_Aug1_Rot_6_sd2
(256/532) train vimp2_1709_07072015_SRI_Aug0_Rot_5_sd1
(257/532) train vimp2_1709_07072015_SRI_Aug0_Rot_6_sd0
(258/532) train vimp2_1709_07072015_SRI_Aug0_Rot_-6_sd2
(259/532) train vimp2_1709_07072015_SRI_Aug1_Rot_0_sd2
(260/532) train vimp2_1709_07072015_SRI_Aug1_Rot_1_sd0
(261/532) train vimp2_1709_07072015_SRI_Aug1_Rot_-1_sd1
(262/532) train vimp2_1712_11162015_SRI_Aug0_Rot_3_sd0
(263/532) train vimp2_1712_11162015_SRI_Aug0_Rot_-3_sd1
(264/532) train vimp2_1712_11162015_SRI_Aug0_Rot_-3_sd2
(265/532) train vimp2_1712_11162015_SRI_Aug1_Rot_-4_sd0
(266/532) train vimp2_1712_11162015_SRI_Aug1_Rot_7_sd1
(267/532) train vimp2_1712_11162015_SRI_Aug1_Rot_7_sd2
(268/532) train vimp2_1724_11202015_SRI_Aug0_Rot_4_sd0
(269/532) train vimp2_1724_11202015_SRI_Aug0_Rot_4_sd1
(270/532) train vimp2_1724_11202015_SRI_Aug0_Rot_-4_sd2
(271/532) train vimp2_1724_11202015_SRI_Aug1_Rot_2_sd1
(272/532) train vimp2_1724_11202015_SRI_Aug1_Rot_-3_sd2
(273/532) train vimp2_1724_11202015_SRI_Aug1_Rot_4_sd0
(274/532) train vimp2_1739_11242015_SRI_Aug0_Rot_-3_sd0
(275/532) train vimp2_1739_11242015_SRI_Aug0_Rot_-4_sd2
(276/532) train vimp2_1739_11242015_SRI_Aug0_Rot_-5_sd1
(277/532) train vimp2_1739_11242015_SRI_Aug1_Rot_5_sd0
(278/532) train vimp2_1739_11242015_SRI_Aug1_Rot_-5_sd1
(279/532) train vimp2_1739_11242015_SRI_Aug1_Rot_7_sd2
(280/532) train vimp2_1751_12022015_SRI_Aug0_Rot_-1_sd1
(281/532) train vimp2_1751_12022015_SRI_Aug0_Rot_5_sd2
(282/532) train vimp2_1751_12022015_SRI_Aug0_Rot_6_sd0
(283/532) train vimp2_1751_12022015_SRI_Aug1_Rot_-4_sd2
(284/532) train vimp2_1751_12022015_SRI_Aug1_Rot_5_sd0
(285/532) train vimp2_1751_12022015_SRI_Aug1_Rot_-6_sd1
(286/532) train vimp2_1756_12032015_SRI_Aug0_Rot_-3_sd0
(287/532) train vimp2_1756_12032015_SRI_Aug0_Rot_5_sd2
(288/532) train vimp2_1756_12032015_SRI_Aug0_Rot_6_sd1
(289/532) train vimp2_1756_12032015_SRI_Aug1_Rot_-1_sd0
(290/532) train vimp2_1756_12032015_SRI_Aug1_Rot_5_sd1
(291/532) train vimp2_1756_12032015_SRI_Aug1_Rot_-7_sd2
(292/532) train vimp2_1761_12042015_SRI_Aug0_Rot_2_sd1
(293/532) train vimp2_1761_12042015_SRI_Aug0_Rot_7_sd0
(294/532) train vimp2_1761_12042015_SRI_Aug0_Rot_7_sd2
(295/532) train vimp2_1761_12042015_SRI_Aug1_Rot_1_sd2
(296/532) train vimp2_1761_12042015_SRI_Aug1_Rot_4_sd0
(297/532) train vimp2_1761_12042015_SRI_Aug1_Rot_-5_sd1
(298/532) train vimp2_1844_01142016_SRI_Aug0_Rot_1_sd1
(299/532) train vimp2_1844_01142016_SRI_Aug0_Rot_-1_sd2
(300/532) train vimp2_1844_01142016_SRI_Aug0_Rot_-2_sd0
(301/532) train vimp2_1844_01142016_SRI_Aug1_Rot_-2_sd1
(302/532) train vimp2_1844_01142016_SRI_Aug1_Rot_-2_sd2
(303/532) train vimp2_1844_01142016_SRI_Aug1_Rot_6_sd0
(304/532) train vimp2_1847_01152016_SRI_Aug0_Rot_-3_sd1
(305/532) train vimp2_1847_01152016_SRI_Aug0_Rot_4_sd2
(306/532) train vimp2_1847_01152016_SRI_Aug0_Rot_-5_sd0
(307/532) train vimp2_1847_01152016_SRI_Aug1_Rot_-2_sd2
(308/532) train vimp2_1847_01152016_SRI_Aug1_Rot_5_sd0
(309/532) train vimp2_1847_01152016_SRI_Aug1_Rot_-6_sd1
(310/532) train vimp2_1875_01262016_SRI_Aug0_Rot_3_sd0
(311/532) train vimp2_1875_01262016_SRI_Aug0_Rot_-3_sd1
(312/532) train vimp2_1875_01262016_SRI_Aug0_Rot_-3_sd2
(313/532) train vimp2_1875_01262016_SRI_Aug1_Rot_-2_sd1
(314/532) train vimp2_1875_01262016_SRI_Aug1_Rot_-4_sd2
(315/532) train vimp2_1875_01262016_SRI_Aug1_Rot_6_sd0
(316/532) train vimp2_1888_01292016_SRI_Aug0_Rot_2_sd0
(317/532) train vimp2_1888_01292016_SRI_Aug0_Rot_4_sd2
(318/532) train vimp2_1888_01292016_SRI_Aug0_Rot_-6_sd1
(319/532) train vimp2_1888_01292016_SRI_Aug1_Rot_-1_sd2
(320/532) train vimp2_1888_01292016_SRI_Aug1_Rot_-2_sd1
(321/532) train vimp2_1888_01292016_SRI_Aug1_Rot_4_sd0
(322/532) train vimp2_1907_02052016_SRI_Aug0_Rot_0_sd2
(323/532) train vimp2_1907_02052016_SRI_Aug0_Rot_-2_sd0
(324/532) train vimp2_1907_02052016_SRI_Aug0_Rot_-7_sd1
(325/532) train vimp2_1907_02052016_SRI_Aug1_Rot_-1_sd1
(326/532) train vimp2_1907_02052016_SRI_Aug1_Rot_2_sd0
(327/532) train vimp2_1907_02052016_SRI_Aug1_Rot_5_sd2
(328/532) train vimp2_2039_03182016_SRI_Aug0_Rot_-1_sd0
(329/532) train vimp2_2039_03182016_SRI_Aug0_Rot_2_sd2
(330/532) train vimp2_2039_03182016_SRI_Aug0_Rot_5_sd1
(331/532) train vimp2_2039_03182016_SRI_Aug1_Rot_-1_sd1
(332/532) train vimp2_2039_03182016_SRI_Aug1_Rot_-5_sd0
(333/532) train vimp2_2039_03182016_SRI_Aug1_Rot_5_sd2
(334/532) train vimp2_2119_04142016_SRI_Aug0_Rot_-2_sd2
(335/532) train vimp2_2119_04142016_SRI_Aug0_Rot_-3_sd0
(336/532) train vimp2_2119_04142016_SRI_Aug0_Rot_-4_sd1
(337/532) train vimp2_2119_04142016_SRI_Aug1_Rot_2_sd2
(338/532) train vimp2_2119_04142016_SRI_Aug1_Rot_-3_sd0
(339/532) train vimp2_2119_04142016_SRI_Aug1_Rot_3_sd1
(340/532) train vimp2_2309_07072016_SRI_Aug0_Rot_-1_sd1
(341/532) train vimp2_2309_07072016_SRI_Aug0_Rot_-6_sd2
(342/532) train vimp2_2309_07072016_SRI_Aug0_Rot_7_sd0
(343/532) train vimp2_2309_07072016_SRI_Aug1_Rot_-5_sd0
(344/532) train vimp2_2309_07072016_SRI_Aug1_Rot_5_sd1
(345/532) train vimp2_2309_07072016_SRI_Aug1_Rot_-6_sd2
(346/532) train vimp2_2390_07272016_SRI_Aug0_Rot_1_sd0
(347/532) train vimp2_2390_07272016_SRI_Aug0_Rot_-5_sd1
(348/532) train vimp2_2390_07272016_SRI_Aug0_Rot_-5_sd2
(349/532) train vimp2_2390_07272016_SRI_Aug1_Rot_-3_sd1
(350/532) train vimp2_2390_07272016_SRI_Aug1_Rot_5_sd0
(351/532) train vimp2_2390_07272016_SRI_Aug1_Rot_5_sd2
(352/532) train vimp2_2398_07292016_SRI_Aug0_Rot_-2_sd1
(353/532) train vimp2_2398_07292016_SRI_Aug0_Rot_-6_sd0
(354/532) train vimp2_2398_07292016_SRI_Aug0_Rot_6_sd2
(355/532) train vimp2_2398_07292016_SRI_Aug1_Rot_-2_sd0
(356/532) train vimp2_2398_07292016_SRI_Aug1_Rot_-3_sd2
(357/532) train vimp2_2398_07292016_SRI_Aug1_Rot_-4_sd1
(358/532) train vimp2_2438_08122016_SRI_Aug0_Rot_-1_sd1
(359/532) train vimp2_2438_08122016_SRI_Aug0_Rot_-5_sd2
(360/532) train vimp2_2438_08122016_SRI_Aug0_Rot_6_sd0
(361/532) train vimp2_2438_08122016_SRI_Aug1_Rot_4_sd0
(362/532) train vimp2_2438_08122016_SRI_Aug1_Rot_-4_sd2
(363/532) train vimp2_2438_08122016_SRI_Aug1_Rot_-6_sd1
(364/532) train vimp2_2450_08172016_SRI_Aug0_Rot_2_sd2
(365/532) train vimp2_2450_08172016_SRI_Aug0_Rot_5_sd1
(366/532) train vimp2_2450_08172016_SRI_Aug0_Rot_-7_sd0
(367/532) train vimp2_2450_08172016_SRI_Aug1_Rot_2_sd0
(368/532) train vimp2_2450_08172016_SRI_Aug1_Rot_-4_sd2
(369/532) train vimp2_2450_08172016_SRI_Aug1_Rot_6_sd1
(370/532) train vimp2_2459_08192016_SRI_Aug0_Rot_-2_sd1
(371/532) train vimp2_2459_08192016_SRI_Aug0_Rot_-5_sd0
(372/532) train vimp2_2459_08192016_SRI_Aug0_Rot_6_sd2
(373/532) train vimp2_2459_08192016_SRI_Aug1_Rot_-2_sd0
(374/532) train vimp2_2459_08192016_SRI_Aug1_Rot_-4_sd2
(375/532) train vimp2_2459_08192016_SRI_Aug1_Rot_-5_sd1
(376/532) train vimp2_2460_08192016_SRI_Aug0_Rot_2_sd1
(377/532) train vimp2_2460_08192016_SRI_Aug0_Rot_5_sd2
(378/532) train vimp2_2460_08192016_SRI_Aug0_Rot_6_sd0
(379/532) train vimp2_2460_08192016_SRI_Aug1_Rot_-4_sd0
(380/532) train vimp2_2460_08192016_SRI_Aug1_Rot_5_sd1
(381/532) train vimp2_2460_08192016_SRI_Aug1_Rot_-6_sd2
(382/532) train vimp2_2462_08192016_Test_NewCases_SRI_Aug0_Rot_-1_sd0
(383/532) train vimp2_2462_08192016_Test_NewCases_SRI_Aug0_Rot_-2_sd2
(384/532) train vimp2_2462_08192016_Test_NewCases_SRI_Aug0_Rot_3_sd1
(385/532) train vimp2_2462_08192016_Test_NewCases_SRI_Aug1_Rot_5_sd1
(386/532) train vimp2_2462_08192016_Test_NewCases_SRI_Aug1_Rot_5_sd2
(387/532) train vimp2_2462_08192016_Test_NewCases_SRI_Aug1_Rot_-6_sd0
(388/532) train vimp2_2476_08242016_SRI_Aug0_Rot_3_sd1
(389/532) train vimp2_2476_08242016_SRI_Aug0_Rot_3_sd2
(390/532) train vimp2_2476_08242016_SRI_Aug0_Rot_6_sd0
(391/532) train vimp2_2476_08242016_SRI_Aug1_Rot_5_sd1
(392/532) train vimp2_2476_08242016_SRI_Aug1_Rot_6_sd0
(393/532) train vimp2_2476_08242016_SRI_Aug1_Rot_7_sd2
(394/532) train vimp2_2484_08252016_SRI_Aug0_Rot_5_sd1
(395/532) train vimp2_2484_08252016_SRI_Aug0_Rot_6_sd0
(396/532) train vimp2_2484_08252016_SRI_Aug0_Rot_-7_sd2
(397/532) train vimp2_2484_08252016_SRI_Aug1_Rot_-1_sd0
(398/532) train vimp2_2484_08252016_SRI_Aug1_Rot_-1_sd1
(399/532) train vimp2_2484_08252016_SRI_Aug1_Rot_-5_sd2
(400/532) train vimp2_2485_08252016_SRI_Aug0_Rot_-1_sd0
(401/532) train vimp2_2485_08252016_SRI_Aug0_Rot_3_sd1
(402/532) train vimp2_2485_08252016_SRI_Aug0_Rot_-7_sd2
(403/532) train vimp2_2485_08252016_SRI_Aug1_Rot_4_sd2
(404/532) train vimp2_2485_08252016_SRI_Aug1_Rot_7_sd0
(405/532) train vimp2_2485_08252016_SRI_Aug1_Rot_7_sd1
(406/532) train vimp2_2499_08302016_SRI_Aug0_Rot_3_sd1
(407/532) train vimp2_2499_08302016_SRI_Aug0_Rot_-6_sd0
(408/532) train vimp2_2499_08302016_SRI_Aug0_Rot_7_sd2
(409/532) train vimp2_2499_08302016_SRI_Aug1_Rot_1_sd0
(410/532) train vimp2_2499_08302016_SRI_Aug1_Rot_2_sd1
(411/532) train vimp2_2499_08302016_SRI_Aug1_Rot_4_sd2
(412/532) train vimp2_2617_10262016_SRI_Aug0_Rot_-3_sd2
(413/532) train vimp2_2617_10262016_SRI_Aug0_Rot_4_sd0
(414/532) train vimp2_2617_10262016_SRI_Aug0_Rot_-7_sd1
(415/532) train vimp2_2617_10262016_SRI_Aug1_Rot_-4_sd2
(416/532) train vimp2_2617_10262016_SRI_Aug1_Rot_5_sd0
(417/532) train vimp2_2617_10262016_SRI_Aug1_Rot_5_sd1
(418/532) train vimp2_2618_10262016_SRI_Aug0_Rot_-1_sd1
(419/532) train vimp2_2618_10262016_SRI_Aug0_Rot_-2_sd0
(420/532) train vimp2_2618_10262016_SRI_Aug0_Rot_-3_sd2
(421/532) train vimp2_2618_10262016_SRI_Aug1_Rot_5_sd0
(422/532) train vimp2_2618_10262016_SRI_Aug1_Rot_-5_sd1
(423/532) train vimp2_2618_10262016_SRI_Aug1_Rot_7_sd2
(424/532) train vimp2_2628_10282016_SRI_Aug0_Rot_3_sd1
(425/532) train vimp2_2628_10282016_SRI_Aug0_Rot_4_sd2
(426/532) train vimp2_2628_10282016_SRI_Aug0_Rot_6_sd0
(427/532) train vimp2_2628_10282016_SRI_Aug1_Rot_-7_sd0
(428/532) train vimp2_2628_10282016_SRI_Aug1_Rot_-7_sd1
(429/532) train vimp2_2628_10282016_SRI_Aug1_Rot_-7_sd2
(430/532) train vimp2_2846_01112017_SRI_Aug0_Rot_1_sd1
(431/532) train vimp2_2846_01112017_SRI_Aug0_Rot_-3_sd0
(432/532) train vimp2_2846_01112017_SRI_Aug0_Rot_7_sd2
(433/532) train vimp2_2846_01112017_SRI_Aug1_Rot_1_sd2
(434/532) train vimp2_2846_01112017_SRI_Aug1_Rot_3_sd1
(435/532) train vimp2_2846_01112017_SRI_Aug1_Rot_5_sd0
(436/532) train vimp2_2878_01262017_SRI_Aug0_Rot_-3_sd0
(437/532) train vimp2_2878_01262017_SRI_Aug0_Rot_4_sd2
(438/532) train vimp2_2878_01262017_SRI_Aug0_Rot_-6_sd1
(439/532) train vimp2_2878_01262017_SRI_Aug1_Rot_3_sd1
(440/532) train vimp2_2878_01262017_SRI_Aug1_Rot_-5_sd2
(441/532) train vimp2_2878_01262017_SRI_Aug1_Rot_7_sd0
(442/532) train vimp2_2914_02162017_Test_NewCases_SRI_Aug0_Rot_-3_sd2
(443/532) train vimp2_2914_02162017_Test_NewCases_SRI_Aug0_Rot_6_sd0
(444/532) train vimp2_2914_02162017_Test_NewCases_SRI_Aug0_Rot_7_sd1
(445/532) train vimp2_2914_02162017_Test_NewCases_SRI_Aug1_Rot_-3_sd2
(446/532) train vimp2_2914_02162017_Test_NewCases_SRI_Aug1_Rot_6_sd1
(447/532) train vimp2_2914_02162017_Test_NewCases_SRI_Aug1_Rot_-7_sd0
(448/532) train vimp2_2926_02222017_Test_NewCases_SRI_Aug0_Rot_-1_sd0
(449/532) train vimp2_2926_02222017_Test_NewCases_SRI_Aug0_Rot_3_sd2
(450/532) train vimp2_2926_02222017_Test_NewCases_SRI_Aug0_Rot_-7_sd1
(451/532) train vimp2_2926_02222017_Test_NewCases_SRI_Aug1_Rot_1_sd0
(452/532) train vimp2_2926_02222017_Test_NewCases_SRI_Aug1_Rot_-5_sd2
(453/532) train vimp2_2926_02222017_Test_NewCases_SRI_Aug1_Rot_7_sd1
(454/532) train vimp2_2946_03032017_Test_NewCases_SRI_Aug0_Rot_0_sd1
(455/532) train vimp2_2946_03032017_Test_NewCases_SRI_Aug0_Rot_1_sd2
(456/532) train vimp2_2946_03032017_Test_NewCases_SRI_Aug0_Rot_-5_sd0
(457/532) train vimp2_2946_03032017_Test_NewCases_SRI_Aug1_Rot_0_sd0
(458/532)2019-07-08 22:55:21.639573: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-08 22:55:21.995537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:05:00.0
totalMemory: 15.89GiB freeMemory: 13.16GiB
2019-07-08 22:55:21.995604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-08 22:55:22.590111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-08 22:55:22.590177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-08 22:55:22.590192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-08 22:55:22.590826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12743 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)
mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a’: File exists
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using TensorFlow backend.
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:02<09:34,  2.02s/it]Loading train:   1%|          | 2/285 [00:03<08:23,  1.78s/it]Loading train:   1%|          | 3/285 [00:04<08:01,  1.71s/it]Loading train:   1%|▏         | 4/285 [00:06<07:50,  1.67s/it]Loading train:   2%|▏         | 5/285 [00:08<07:56,  1.70s/it]Loading train:   2%|▏         | 6/285 [00:09<07:24,  1.59s/it]Loading train:   2%|▏         | 7/285 [00:11<07:34,  1.63s/it]Loading train:   3%|▎         | 8/285 [00:12<07:11,  1.56s/it]Loading train:   3%|▎         | 9/285 [00:14<07:23,  1.61s/it]Loading train:   4%|▎         | 10/285 [00:15<06:57,  1.52s/it]Loading train:   4%|▍         | 11/285 [00:16<06:20,  1.39s/it]Loading train:   4%|▍         | 12/285 [00:18<06:19,  1.39s/it]Loading train:   5%|▍         | 13/285 [00:19<05:41,  1.26s/it]Loading train:   5%|▍         | 14/285 [00:20<05:42,  1.26s/it]Loading train:   5%|▌         | 15/285 [00:21<05:49,  1.30s/it]Loading train:   6%|▌         | 16/285 [00:23<06:33,  1.46s/it]Loading train:   6%|▌         | 17/285 [00:24<06:17,  1.41s/it]Loading train:   6%|▋         | 18/285 [00:26<06:15,  1.41s/it]Loading train:   7%|▋         | 19/285 [00:27<05:49,  1.31s/it]Loading train:   7%|▋         | 20/285 [00:28<05:49,  1.32s/it]Loading train:   7%|▋         | 21/285 [00:29<05:49,  1.32s/it]Loading train:   8%|▊         | 22/285 [00:31<05:35,  1.28s/it]Loading train:   8%|▊         | 23/285 [00:32<05:36,  1.29s/it]Loading train:   8%|▊         | 24/285 [00:33<05:23,  1.24s/it]Loading train:   9%|▉         | 25/285 [00:34<05:25,  1.25s/it]Loading train:   9%|▉         | 26/285 [00:36<05:39,  1.31s/it]Loading train:   9%|▉         | 27/285 [00:37<05:12,  1.21s/it]Loading train:  10%|▉         | 28/285 [00:38<05:15,  1.23s/it]Loading train:  10%|█         | 29/285 [00:39<05:26,  1.27s/it]Loading train:  11%|█         | 30/285 [00:41<05:26,  1.28s/it]Loading train:  11%|█         | 31/285 [00:42<05:33,  1.31s/it]Loading train:  11%|█         | 32/285 [00:43<05:30,  1.31s/it]Loading train:  12%|█▏        | 33/285 [00:45<05:41,  1.35s/it]Loading train:  12%|█▏        | 34/285 [00:47<06:15,  1.49s/it]Loading train:  12%|█▏        | 35/285 [00:48<06:34,  1.58s/it]Loading train:  13%|█▎        | 36/285 [00:50<05:59,  1.44s/it]Loading train:  13%|█▎        | 37/285 [00:51<05:36,  1.36s/it]Loading train:  13%|█▎        | 38/285 [00:52<05:43,  1.39s/it]Loading train:  14%|█▎        | 39/285 [00:54<05:56,  1.45s/it]Loading train:  14%|█▍        | 40/285 [00:55<05:36,  1.37s/it]Loading train:  14%|█▍        | 41/285 [00:56<05:22,  1.32s/it]Loading train:  15%|█▍        | 42/285 [00:58<05:55,  1.46s/it]Loading train:  15%|█▌        | 43/285 [01:00<05:56,  1.47s/it]Loading train:  15%|█▌        | 44/285 [01:01<06:19,  1.58s/it]Loading train:  16%|█▌        | 45/285 [01:02<05:41,  1.42s/it]Loading train:  16%|█▌        | 46/285 [01:04<05:31,  1.38s/it]Loading train:  16%|█▋        | 47/285 [01:05<05:22,  1.35s/it]Loading train:  17%|█▋        | 48/285 [01:07<05:33,  1.41s/it]Loading train:  17%|█▋        | 49/285 [01:08<05:29,  1.40s/it]Loading train:  18%|█▊        | 50/285 [01:09<05:18,  1.36s/it]Loading train:  18%|█▊        | 51/285 [01:11<05:38,  1.45s/it]Loading train:  18%|█▊        | 52/285 [01:12<05:31,  1.42s/it]Loading train:  19%|█▊        | 53/285 [01:14<05:31,  1.43s/it]Loading train:  19%|█▉        | 54/285 [01:15<05:36,  1.46s/it]Loading train:  19%|█▉        | 55/285 [01:16<05:24,  1.41s/it]Loading train:  20%|█▉        | 56/285 [01:18<05:30,  1.44s/it]Loading train:  20%|██        | 57/285 [01:19<05:19,  1.40s/it]Loading train:  20%|██        | 58/285 [01:21<05:24,  1.43s/it]Loading train:  21%|██        | 59/285 [01:23<05:45,  1.53s/it]Loading train:  21%|██        | 60/285 [01:24<05:40,  1.51s/it]Loading train:  21%|██▏       | 61/285 [01:25<05:27,  1.46s/it]Loading train:  22%|██▏       | 62/285 [01:27<05:31,  1.48s/it]Loading train:  22%|██▏       | 63/285 [01:29<05:41,  1.54s/it]Loading train:  22%|██▏       | 64/285 [01:31<06:20,  1.72s/it]Loading train:  23%|██▎       | 65/285 [01:33<06:51,  1.87s/it]Loading train:  23%|██▎       | 66/285 [01:35<06:59,  1.92s/it]Loading train:  24%|██▎       | 67/285 [01:36<06:25,  1.77s/it]Loading train:  24%|██▍       | 68/285 [01:38<05:47,  1.60s/it]Loading train:  24%|██▍       | 69/285 [01:39<05:20,  1.48s/it]Loading train:  25%|██▍       | 70/285 [01:40<05:31,  1.54s/it]Loading train:  25%|██▍       | 71/285 [01:42<05:13,  1.47s/it]Loading train:  25%|██▌       | 72/285 [01:43<05:15,  1.48s/it]Loading train:  26%|██▌       | 73/285 [01:45<05:10,  1.47s/it]Loading train:  26%|██▌       | 74/285 [01:47<05:48,  1.65s/it]Loading train:  26%|██▋       | 75/285 [01:49<05:57,  1.70s/it]Loading train:  27%|██▋       | 76/285 [01:50<05:42,  1.64s/it]Loading train:  27%|██▋       | 77/285 [01:51<04:59,  1.44s/it]Loading train:  27%|██▋       | 78/285 [01:52<04:46,  1.38s/it]Loading train:  28%|██▊       | 79/285 [01:55<05:37,  1.64s/it]Loading train:  28%|██▊       | 80/285 [01:56<05:36,  1.64s/it]Loading train:  28%|██▊       | 81/285 [01:58<05:21,  1.58s/it]Loading train:  29%|██▉       | 82/285 [01:59<05:20,  1.58s/it]Loading train:  29%|██▉       | 83/285 [02:01<05:22,  1.60s/it]Loading train:  29%|██▉       | 84/285 [02:02<05:16,  1.58s/it]Loading train:  30%|██▉       | 85/285 [02:04<05:33,  1.67s/it]Loading train:  30%|███       | 86/285 [02:06<05:59,  1.81s/it]Loading train:  31%|███       | 87/285 [02:08<06:10,  1.87s/it]Loading train:  31%|███       | 88/285 [02:10<05:57,  1.82s/it]Loading train:  31%|███       | 89/285 [02:11<05:21,  1.64s/it]Loading train:  32%|███▏      | 90/285 [02:13<05:10,  1.59s/it]Loading train:  32%|███▏      | 91/285 [02:15<05:16,  1.63s/it]Loading train:  32%|███▏      | 92/285 [02:17<05:39,  1.76s/it]Loading train:  33%|███▎      | 93/285 [02:18<05:08,  1.60s/it]Loading train:  33%|███▎      | 94/285 [02:19<04:52,  1.53s/it]Loading train:  33%|███▎      | 95/285 [02:21<05:06,  1.62s/it]Loading train:  34%|███▎      | 96/285 [02:23<05:09,  1.64s/it]Loading train:  34%|███▍      | 97/285 [02:24<04:55,  1.57s/it]Loading train:  34%|███▍      | 98/285 [02:26<04:47,  1.54s/it]Loading train:  35%|███▍      | 99/285 [02:27<04:31,  1.46s/it]Loading train:  35%|███▌      | 100/285 [02:28<04:26,  1.44s/it]Loading train:  35%|███▌      | 101/285 [02:30<04:33,  1.49s/it]Loading train:  36%|███▌      | 102/285 [02:32<05:19,  1.75s/it]Loading train:  36%|███▌      | 103/285 [02:34<05:27,  1.80s/it]Loading train:  36%|███▋      | 104/285 [02:36<05:46,  1.91s/it]Loading train:  37%|███▋      | 105/285 [02:38<05:44,  1.92s/it]Loading train:  37%|███▋      | 106/285 [02:40<05:26,  1.82s/it]Loading train:  38%|███▊      | 107/285 [02:42<05:19,  1.79s/it]Loading train:  38%|███▊      | 108/285 [02:43<04:54,  1.66s/it]Loading train:  38%|███▊      | 109/285 [02:44<04:27,  1.52s/it]Loading train:  39%|███▊      | 110/285 [02:45<04:14,  1.45s/it]Loading train:  39%|███▉      | 111/285 [02:47<03:59,  1.38s/it]Loading train:  39%|███▉      | 112/285 [02:48<03:47,  1.32s/it]Loading train:  40%|███▉      | 113/285 [02:50<04:11,  1.46s/it]Loading train:  40%|████      | 114/285 [02:51<04:22,  1.53s/it]Loading train:  40%|████      | 115/285 [02:53<04:34,  1.61s/it]Loading train:  41%|████      | 116/285 [02:54<04:20,  1.54s/it]Loading train:  41%|████      | 117/285 [02:56<04:01,  1.44s/it]Loading train:  41%|████▏     | 118/285 [02:57<04:07,  1.48s/it]Loading train:  42%|████▏     | 119/285 [02:59<04:07,  1.49s/it]Loading train:  42%|████▏     | 120/285 [03:00<04:17,  1.56s/it]Loading train:  42%|████▏     | 121/285 [03:02<04:11,  1.54s/it]Loading train:  43%|████▎     | 122/285 [03:03<04:03,  1.50s/it]Loading train:  43%|████▎     | 123/285 [03:05<04:10,  1.54s/it]Loading train:  44%|████▎     | 124/285 [03:06<04:04,  1.52s/it]Loading train:  44%|████▍     | 125/285 [03:08<04:01,  1.51s/it]Loading train:  44%|████▍     | 126/285 [03:09<03:40,  1.38s/it]Loading train:  45%|████▍     | 127/285 [03:11<03:44,  1.42s/it]Loading train:  45%|████▍     | 128/285 [03:13<04:13,  1.62s/it]Loading train:  45%|████▌     | 129/285 [03:14<04:12,  1.62s/it]Loading train:  46%|████▌     | 130/285 [03:16<04:03,  1.57s/it]Loading train:  46%|████▌     | 131/285 [03:17<03:40,  1.43s/it]Loading train:  46%|████▋     | 132/285 [03:18<03:34,  1.40s/it]Loading train:  47%|████▋     | 133/285 [03:20<03:37,  1.43s/it]Loading train:  47%|████▋     | 134/285 [03:22<03:57,  1.57s/it]Loading train:  47%|████▋     | 135/285 [03:23<03:52,  1.55s/it]Loading train:  48%|████▊     | 136/285 [03:24<03:39,  1.47s/it]Loading train:  48%|████▊     | 137/285 [03:26<03:35,  1.46s/it]Loading train:  48%|████▊     | 138/285 [03:27<03:20,  1.36s/it]Loading train:  49%|████▉     | 139/285 [03:28<03:19,  1.36s/it]Loading train:  49%|████▉     | 140/285 [03:30<03:24,  1.41s/it]Loading train:  49%|████▉     | 141/285 [03:31<03:24,  1.42s/it]Loading train:  50%|████▉     | 142/285 [03:33<03:19,  1.40s/it]Loading train:  50%|█████     | 143/285 [03:35<03:53,  1.65s/it]Loading train:  51%|█████     | 144/285 [03:36<03:49,  1.63s/it]Loading train:  51%|█████     | 145/285 [03:38<03:52,  1.66s/it]Loading train:  51%|█████     | 146/285 [03:39<03:35,  1.55s/it]Loading train:  52%|█████▏    | 147/285 [03:41<03:24,  1.48s/it]Loading train:  52%|█████▏    | 148/285 [03:43<03:41,  1.61s/it]Loading train:  52%|█████▏    | 149/285 [03:44<03:33,  1.57s/it]Loading train:  53%|█████▎    | 150/285 [03:46<03:40,  1.63s/it]Loading train:  53%|█████▎    | 151/285 [03:47<03:33,  1.59s/it]Loading train:  53%|█████▎    | 152/285 [03:49<03:17,  1.49s/it]Loading train:  54%|█████▎    | 153/285 [03:50<03:06,  1.41s/it]Loading train:  54%|█████▍    | 154/285 [03:51<02:55,  1.34s/it]Loading train:  54%|█████▍    | 155/285 [03:52<02:48,  1.30s/it]Loading train:  55%|█████▍    | 156/285 [03:54<02:52,  1.34s/it]Loading train:  55%|█████▌    | 157/285 [03:55<03:03,  1.44s/it]Loading train:  55%|█████▌    | 158/285 [03:57<02:57,  1.40s/it]Loading train:  56%|█████▌    | 159/285 [03:58<03:12,  1.53s/it]Loading train:  56%|█████▌    | 160/285 [04:00<03:18,  1.59s/it]Loading train:  56%|█████▋    | 161/285 [04:01<03:06,  1.51s/it]Loading train:  57%|█████▋    | 162/285 [04:03<03:06,  1.51s/it]Loading train:  57%|█████▋    | 163/285 [04:04<03:02,  1.49s/it]Loading train:  58%|█████▊    | 164/285 [04:06<02:50,  1.41s/it]Loading train:  58%|█████▊    | 165/285 [04:07<02:59,  1.49s/it]Loading train:  58%|█████▊    | 166/285 [04:09<02:52,  1.45s/it]Loading train:  59%|█████▊    | 167/285 [04:10<02:47,  1.42s/it]Loading train:  59%|█████▉    | 168/285 [04:11<02:44,  1.41s/it]Loading train:  59%|█████▉    | 169/285 [04:12<02:29,  1.29s/it]Loading train:  60%|█████▉    | 170/285 [04:14<02:23,  1.25s/it]Loading train:  60%|██████    | 171/285 [04:15<02:24,  1.27s/it]Loading train:  60%|██████    | 172/285 [04:16<02:18,  1.23s/it]Loading train:  61%|██████    | 173/285 [04:17<02:20,  1.25s/it]Loading train:  61%|██████    | 174/285 [04:18<02:09,  1.17s/it]Loading train:  61%|██████▏   | 175/285 [04:20<02:15,  1.23s/it]Loading train:  62%|██████▏   | 176/285 [04:22<02:33,  1.40s/it]Loading train:  62%|██████▏   | 177/285 [04:23<02:30,  1.39s/it]Loading train:  62%|██████▏   | 178/285 [04:24<02:34,  1.45s/it]Loading train:  63%|██████▎   | 179/285 [04:26<02:38,  1.50s/it]Loading train:  63%|██████▎   | 180/285 [04:27<02:32,  1.46s/it]Loading train:  64%|██████▎   | 181/285 [04:29<02:33,  1.48s/it]Loading train:  64%|██████▍   | 182/285 [04:30<02:33,  1.49s/it]Loading train:  64%|██████▍   | 183/285 [04:32<02:29,  1.46s/it]Loading train:  65%|██████▍   | 184/285 [04:33<02:17,  1.37s/it]Loading train:  65%|██████▍   | 185/285 [04:34<02:07,  1.28s/it]Loading train:  65%|██████▌   | 186/285 [04:36<02:30,  1.52s/it]Loading train:  66%|██████▌   | 187/285 [04:38<02:28,  1.52s/it]Loading train:  66%|██████▌   | 188/285 [04:39<02:23,  1.48s/it]Loading train:  66%|██████▋   | 189/285 [04:40<02:17,  1.43s/it]Loading train:  67%|██████▋   | 190/285 [04:42<02:11,  1.38s/it]Loading train:  67%|██████▋   | 191/285 [04:43<02:07,  1.36s/it]Loading train:  67%|██████▋   | 192/285 [04:44<01:59,  1.29s/it]Loading train:  68%|██████▊   | 193/285 [04:45<01:54,  1.25s/it]Loading train:  68%|██████▊   | 194/285 [04:47<02:01,  1.33s/it]Loading train:  68%|██████▊   | 195/285 [04:48<01:53,  1.27s/it]Loading train:  69%|██████▉   | 196/285 [04:49<01:54,  1.29s/it]Loading train:  69%|██████▉   | 197/285 [04:51<01:53,  1.29s/it]Loading train:  69%|██████▉   | 198/285 [04:52<01:59,  1.37s/it]Loading train:  70%|██████▉   | 199/285 [04:53<01:57,  1.37s/it]Loading train:  70%|███████   | 200/285 [04:55<01:55,  1.36s/it]Loading train:  71%|███████   | 201/285 [04:57<02:05,  1.50s/it]Loading train:  71%|███████   | 202/285 [04:59<02:15,  1.63s/it]Loading train:  71%|███████   | 203/285 [05:00<02:12,  1.62s/it]Loading train:  72%|███████▏  | 204/285 [05:02<02:06,  1.56s/it]Loading train:  72%|███████▏  | 205/285 [05:03<01:55,  1.44s/it]Loading train:  72%|███████▏  | 206/285 [05:04<01:54,  1.44s/it]Loading train:  73%|███████▎  | 207/285 [05:06<01:54,  1.47s/it]Loading train:  73%|███████▎  | 208/285 [05:08<02:04,  1.61s/it]Loading train:  73%|███████▎  | 209/285 [05:10<02:10,  1.71s/it]Loading train:  74%|███████▎  | 210/285 [05:11<01:57,  1.56s/it]Loading train:  74%|███████▍  | 211/285 [05:12<01:46,  1.43s/it]Loading train:  74%|███████▍  | 212/285 [05:14<01:51,  1.52s/it]Loading train:  75%|███████▍  | 213/285 [05:15<01:43,  1.44s/it]Loading train:  75%|███████▌  | 214/285 [05:16<01:35,  1.35s/it]Loading train:  75%|███████▌  | 215/285 [05:18<01:45,  1.50s/it]Loading train:  76%|███████▌  | 216/285 [05:19<01:36,  1.40s/it]Loading train:  76%|███████▌  | 217/285 [05:21<01:36,  1.41s/it]Loading train:  76%|███████▋  | 218/285 [05:22<01:45,  1.57s/it]Loading train:  77%|███████▋  | 219/285 [05:24<01:48,  1.64s/it]Loading train:  77%|███████▋  | 220/285 [05:26<01:46,  1.63s/it]Loading train:  78%|███████▊  | 221/285 [05:27<01:34,  1.48s/it]Loading train:  78%|███████▊  | 222/285 [05:29<01:40,  1.59s/it]Loading train:  78%|███████▊  | 223/285 [05:30<01:38,  1.59s/it]Loading train:  79%|███████▊  | 224/285 [05:32<01:30,  1.49s/it]Loading train:  79%|███████▉  | 225/285 [05:33<01:24,  1.40s/it]Loading train:  79%|███████▉  | 226/285 [05:35<01:34,  1.61s/it]Loading train:  80%|███████▉  | 227/285 [05:36<01:31,  1.57s/it]Loading train:  80%|████████  | 228/285 [05:38<01:26,  1.53s/it]Loading train:  80%|████████  | 229/285 [05:40<01:29,  1.60s/it]Loading train:  81%|████████  | 230/285 [05:41<01:31,  1.66s/it]Loading train:  81%|████████  | 231/285 [05:43<01:21,  1.51s/it]Loading train:  81%|████████▏ | 232/285 [05:44<01:18,  1.49s/it]Loading train:  82%|████████▏ | 233/285 [05:45<01:12,  1.39s/it]Loading train:  82%|████████▏ | 234/285 [05:47<01:22,  1.62s/it]Loading train:  82%|████████▏ | 235/285 [05:49<01:19,  1.60s/it]Loading train:  83%|████████▎ | 236/285 [05:50<01:14,  1.52s/it]Loading train:  83%|████████▎ | 237/285 [05:52<01:14,  1.55s/it]Loading train:  84%|████████▎ | 238/285 [05:53<01:09,  1.48s/it]Loading train:  84%|████████▍ | 239/285 [05:55<01:12,  1.58s/it]Loading train:  84%|████████▍ | 240/285 [05:56<01:06,  1.48s/it]Loading train:  85%|████████▍ | 241/285 [05:58<01:04,  1.46s/it]Loading train:  85%|████████▍ | 242/285 [05:59<01:00,  1.41s/it]Loading train:  85%|████████▌ | 243/285 [06:00<00:56,  1.35s/it]Loading train:  86%|████████▌ | 244/285 [06:02<00:56,  1.38s/it]Loading train:  86%|████████▌ | 245/285 [06:03<00:52,  1.32s/it]Loading train:  86%|████████▋ | 246/285 [06:04<00:53,  1.36s/it]Loading train:  87%|████████▋ | 247/285 [06:07<01:02,  1.64s/it]Loading train:  87%|████████▋ | 248/285 [06:08<01:03,  1.71s/it]Loading train:  87%|████████▋ | 249/285 [06:10<01:00,  1.69s/it]Loading train:  88%|████████▊ | 250/285 [06:12<00:57,  1.65s/it]Loading train:  88%|████████▊ | 251/285 [06:13<00:50,  1.49s/it]Loading train:  88%|████████▊ | 252/285 [06:14<00:45,  1.37s/it]Loading train:  89%|████████▉ | 253/285 [06:15<00:43,  1.37s/it]Loading train:  89%|████████▉ | 254/285 [06:17<00:42,  1.36s/it]Loading train:  89%|████████▉ | 255/285 [06:18<00:40,  1.34s/it]Loading train:  90%|████████▉ | 256/285 [06:19<00:38,  1.31s/it]Loading train:  90%|█████████ | 257/285 [06:20<00:35,  1.26s/it]Loading train:  91%|█████████ | 258/285 [06:21<00:33,  1.26s/it]Loading train:  91%|█████████ | 259/285 [06:23<00:32,  1.27s/it]Loading train:  91%|█████████ | 260/285 [06:24<00:30,  1.24s/it]Loading train:  92%|█████████▏| 261/285 [06:26<00:33,  1.40s/it]Loading train:  92%|█████████▏| 262/285 [06:28<00:36,  1.59s/it]Loading train:  92%|█████████▏| 263/285 [06:29<00:33,  1.54s/it]Loading train:  93%|█████████▎| 264/285 [06:31<00:36,  1.72s/it]Loading train:  93%|█████████▎| 265/285 [06:33<00:36,  1.82s/it]Loading train:  93%|█████████▎| 266/285 [06:35<00:32,  1.69s/it]Loading train:  94%|█████████▎| 267/285 [06:36<00:26,  1.49s/it]Loading train:  94%|█████████▍| 268/285 [06:37<00:24,  1.46s/it]Loading train:  94%|█████████▍| 269/285 [06:39<00:22,  1.42s/it]Loading train:  95%|█████████▍| 270/285 [06:40<00:19,  1.33s/it]Loading train:  95%|█████████▌| 271/285 [06:41<00:20,  1.43s/it]Loading train:  95%|█████████▌| 272/285 [06:43<00:19,  1.49s/it]Loading train:  96%|█████████▌| 273/285 [06:44<00:16,  1.38s/it]Loading train:  96%|█████████▌| 274/285 [06:45<00:15,  1.38s/it]Loading train:  96%|█████████▋| 275/285 [06:47<00:13,  1.34s/it]Loading train:  97%|█████████▋| 276/285 [06:48<00:11,  1.31s/it]Loading train:  97%|█████████▋| 277/285 [06:49<00:10,  1.26s/it]Loading train:  98%|█████████▊| 278/285 [06:50<00:08,  1.22s/it]Loading train:  98%|█████████▊| 279/285 [06:51<00:07,  1.24s/it]Loading train:  98%|█████████▊| 280/285 [06:53<00:06,  1.23s/it]Loading train:  99%|█████████▊| 281/285 [06:54<00:05,  1.30s/it]Loading train:  99%|█████████▉| 282/285 [06:55<00:03,  1.23s/it]Loading train:  99%|█████████▉| 283/285 [06:57<00:02,  1.35s/it]Loading train: 100%|█████████▉| 284/285 [06:58<00:01,  1.38s/it]Loading train: 100%|██████████| 285/285 [07:00<00:00,  1.33s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|          | 3/285 [00:00<00:11, 23.89it/s]concatenating: train:   3%|▎         | 8/285 [00:00<00:09, 28.21it/s]concatenating: train:   5%|▍         | 13/285 [00:00<00:08, 32.20it/s]concatenating: train:   6%|▋         | 18/285 [00:00<00:07, 33.47it/s]concatenating: train:   8%|▊         | 23/285 [00:00<00:07, 36.83it/s]concatenating: train:  10%|█         | 29/285 [00:00<00:06, 41.31it/s]concatenating: train:  12%|█▏        | 34/285 [00:00<00:06, 37.33it/s]concatenating: train:  14%|█▍        | 40/285 [00:00<00:05, 41.41it/s]concatenating: train:  16%|█▌        | 46/285 [00:01<00:05, 44.44it/s]concatenating: train:  18%|█▊        | 51/285 [00:01<00:05, 41.00it/s]concatenating: train:  20%|██        | 58/285 [00:01<00:05, 45.36it/s]concatenating: train:  22%|██▏       | 63/285 [00:01<00:04, 45.64it/s]concatenating: train:  24%|██▍       | 68/285 [00:01<00:05, 38.61it/s]concatenating: train:  26%|██▋       | 75/285 [00:01<00:04, 43.61it/s]concatenating: train:  28%|██▊       | 80/285 [00:01<00:04, 42.14it/s]concatenating: train:  33%|███▎      | 95/285 [00:01<00:03, 53.40it/s]concatenating: train:  38%|███▊      | 107/285 [00:02<00:02, 63.79it/s]concatenating: train:  41%|████      | 116/285 [00:02<00:02, 66.39it/s]concatenating: train:  44%|████▍     | 125/285 [00:02<00:02, 58.41it/s]concatenating: train:  47%|████▋     | 135/285 [00:02<00:02, 65.92it/s]concatenating: train:  50%|█████     | 143/285 [00:02<00:02, 64.70it/s]concatenating: train:  53%|█████▎    | 151/285 [00:02<00:02, 61.03it/s]concatenating: train:  55%|█████▌    | 158/285 [00:02<00:02, 63.11it/s]concatenating: train:  58%|█████▊    | 165/285 [00:02<00:02, 58.82it/s]concatenating: train:  60%|██████    | 172/285 [00:03<00:02, 53.31it/s]concatenating: train:  63%|██████▎   | 179/285 [00:03<00:01, 55.77it/s]concatenating: train:  66%|██████▌   | 187/285 [00:03<00:01, 61.29it/s]concatenating: train:  68%|██████▊   | 195/285 [00:03<00:01, 65.34it/s]concatenating: train:  71%|███████   | 202/285 [00:03<00:01, 64.46it/s]concatenating: train:  74%|███████▍  | 212/285 [00:03<00:01, 72.09it/s]concatenating: train:  78%|███████▊  | 223/285 [00:03<00:00, 76.44it/s]concatenating: train:  81%|████████▏ | 232/285 [00:03<00:00, 68.87it/s]concatenating: train:  85%|████████▌ | 243/285 [00:04<00:00, 76.94it/s]concatenating: train:  88%|████████▊ | 252/285 [00:04<00:00, 79.67it/s]concatenating: train:  92%|█████████▏| 261/285 [00:04<00:00, 68.31it/s]concatenating: train:  94%|█████████▍| 269/285 [00:04<00:00, 55.41it/s]concatenating: train:  97%|█████████▋| 277/285 [00:04<00:00, 59.40it/s]concatenating: train: 100%|██████████| 285/285 [00:04<00:00, 59.78it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.61s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.57s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.50s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 30.17it/s]
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:12,  3.32it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:10,  3.90it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:09,  4.01it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:01<00:07,  5.12it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:07,  4.79it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  5.62it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.41it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.02it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  6.97it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:02<00:05,  4.23it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:03<00:05,  3.92it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:03<00:03,  5.12it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  5.73it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:03<00:03,  4.26it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:04<00:02,  4.81it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:04<00:03,  3.87it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:04<00:01,  4.82it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:05<00:01,  5.52it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:05<00:01,  4.79it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:05<00:00,  5.52it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:05<00:00,  5.29it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:05<00:00,  7.51it/s] train vimp2_2946_03032017_Test_NewCases_SRI_Aug1_Rot_-6_sd1
(459/532) train vimp2_2946_03032017_Test_NewCases_SRI_Aug1_Rot_-6_sd2
(460/532) train vimp2_2948_03042017_Test_NewCases_SRI_Aug0_Rot_2_sd1
(461/532) train vimp2_2948_03042017_Test_NewCases_SRI_Aug0_Rot_-2_sd2
(462/532) train vimp2_2948_03042017_Test_NewCases_SRI_Aug0_Rot_-6_sd0
(463/532) train vimp2_2948_03042017_Test_NewCases_SRI_Aug1_Rot_1_sd2
(464/532) train vimp2_2948_03042017_Test_NewCases_SRI_Aug1_Rot_-6_sd1
(465/532) train vimp2_2948_03042017_Test_NewCases_SRI_Aug1_Rot_7_sd0
(466/532) train vimp2_2951_03062017_Test_NewCases_SRI_Aug0_Rot_-1_sd2
(467/532) train vimp2_2951_03062017_Test_NewCases_SRI_Aug0_Rot_7_sd0
(468/532) train vimp2_2951_03062017_Test_NewCases_SRI_Aug0_Rot_-7_sd1
(469/532) train vimp2_2951_03062017_Test_NewCases_SRI_Aug1_Rot_-3_sd0
(470/532) train vimp2_2951_03062017_Test_NewCases_SRI_Aug1_Rot_4_sd2
(471/532) train vimp2_2951_03062017_Test_NewCases_SRI_Aug1_Rot_-7_sd1
(472/532) train vimp2_2966_03092017_Test_NewCases_SRI_Aug0_Rot_-1_sd2
(473/532) train vimp2_2966_03092017_Test_NewCases_SRI_Aug0_Rot_5_sd1
(474/532) train vimp2_2966_03092017_Test_NewCases_SRI_Aug0_Rot_-6_sd0
(475/532) train vimp2_2966_03092017_Test_NewCases_SRI_Aug1_Rot_1_sd2
(476/532) train vimp2_2966_03092017_Test_NewCases_SRI_Aug1_Rot_5_sd1
(477/532) train vimp2_2966_03092017_Test_NewCases_SRI_Aug1_Rot_7_sd0
(478/532) train vimp2_2972_03102017_Test_NewCases_SRI_Aug0_Rot_2_sd0
(479/532) train vimp2_2972_03102017_Test_NewCases_SRI_Aug0_Rot_-3_sd1
(480/532) train vimp2_2972_03102017_Test_NewCases_SRI_Aug0_Rot_-3_sd2
(481/532) train vimp2_2972_03102017_Test_NewCases_SRI_Aug1_Rot_1_sd2
(482/532) train vimp2_2972_03102017_Test_NewCases_SRI_Aug1_Rot_4_sd0
(483/532) train vimp2_2972_03102017_Test_NewCases_SRI_Aug1_Rot_-7_sd1
(484/532) train vimp2_2998_03222017_Test_NewCases_SRI_Aug0_Rot_1_sd2
(485/532) train vimp2_2998_03222017_Test_NewCases_SRI_Aug0_Rot_4_sd0
(486/532) train vimp2_2998_03222017_Test_NewCases_SRI_Aug0_Rot_5_sd1
(487/532) train vimp2_2998_03222017_Test_NewCases_SRI_Aug1_Rot_5_sd1
(488/532) train vimp2_2998_03222017_Test_NewCases_SRI_Aug1_Rot_6_sd0
(489/532) train vimp2_2998_03222017_Test_NewCases_SRI_Aug1_Rot_6_sd2
(490/532) train vimp2_3131_05182017_SRI_Aug0_Rot_2_sd2
(491/532) train vimp2_3131_05182017_SRI_Aug0_Rot_-5_sd1
(492/532) train vimp2_3131_05182017_SRI_Aug0_Rot_-7_sd0
(493/532) train vimp2_3131_05182017_SRI_Aug1_Rot_-4_sd0
(494/532) train vimp2_3131_05182017_SRI_Aug1_Rot_-4_sd2
(495/532) train vimp2_3131_05182017_SRI_Aug1_Rot_-7_sd1
(496/532) train vimp2_3187_06092017_SRI_Aug0_Rot_-1_sd0
(497/532) train vimp2_3187_06092017_SRI_Aug0_Rot_4_sd1
(498/532) train vimp2_3187_06092017_SRI_Aug0_Rot_-7_sd2
(499/532) train vimp2_3187_06092017_SRI_Aug1_Rot_-4_sd2
(500/532) train vimp2_3187_06092017_SRI_Aug1_Rot_-6_sd0
(501/532) train vimp2_3187_06092017_SRI_Aug1_Rot_-6_sd1
(502/532) train vimp2_3349_08012017_SRI_Aug0_Rot_4_sd0
(503/532) train vimp2_3349_08012017_SRI_Aug0_Rot_-4_sd1
(504/532) train vimp2_3349_08012017_SRI_Aug0_Rot_5_sd2
(505/532) train vimp2_3349_08012017_SRI_Aug1_Rot_-2_sd1
(506/532) train vimp2_3349_08012017_SRI_Aug1_Rot_-4_sd2
(507/532) train vimp2_3349_08012017_SRI_Aug1_Rot_-7_sd0
(508/532) train vimp2_676_04252014_SRI_Aug0_Rot_6_sd1
(509/532) train vimp2_676_04252014_SRI_Aug0_Rot_-6_sd2
(510/532) train vimp2_676_04252014_SRI_Aug0_Rot_7_sd0
(511/532) train vimp2_676_04252014_SRI_Aug1_Rot_2_sd0
(512/532) train vimp2_676_04252014_SRI_Aug1_Rot_-3_sd1
(513/532) train vimp2_676_04252014_SRI_Aug1_Rot_5_sd2
(514/532) train vimp2_702_04302014_SRI_Aug0_Rot_2_sd1
(515/532) train vimp2_702_04302014_SRI_Aug0_Rot_-3_sd0
(516/532) train vimp2_702_04302014_SRI_Aug0_Rot_-3_sd2
(517/532) train vimp2_702_04302014_SRI_Aug1_Rot_3_sd2
(518/532) train vimp2_702_04302014_SRI_Aug1_Rot_-4_sd1
(519/532) train vimp2_702_04302014_SRI_Aug1_Rot_-7_sd0
(520/532) train vimp2_804_06042014_SRI_Aug0_Rot_-2_sd2
(521/532) train vimp2_804_06042014_SRI_Aug0_Rot_3_sd1
(522/532) train vimp2_804_06042014_SRI_Aug0_Rot_-6_sd0
(523/532) train vimp2_804_06042014_SRI_Aug1_Rot_-3_sd1
(524/532) train vimp2_804_06042014_SRI_Aug1_Rot_5_sd0
(525/532) train vimp2_804_06042014_SRI_Aug1_Rot_7_sd2
(526/532) train vimp2_969_07142014_SRI_Aug0_Rot_1_sd2
(527/532) train vimp2_969_07142014_SRI_Aug0_Rot_-6_sd0
(528/532) train vimp2_969_07142014_SRI_Aug0_Rot_-6_sd1
(529/532) train vimp2_969_07142014_SRI_Aug1_Rot_-2_sd2
(530/532) train vimp2_969_07142014_SRI_Aug1_Rot_4_sd1
(531/532) train vimp2_969_07142014_SRI_Aug1_Rot_-6_sd0
(0/15) test vimp2_0699_04302014_SRI
(1/15) test vimp2_0781_05292014_SRI
(2/15) test vimp2_0837_06122014_SRI
(3/15) test vimp2_0892_06262014_SRI
(4/15) test vimp2_2456_08182016_SRI
(5/15) test vimp2_2520_09092016_SRI
(6/15) test vimp2_2530_09142016_SRI
(7/15) test vimp2_2551_09232016_Test_NewCases_SRI
(8/15) test vimp2_2553_09232016_Test_NewCases_SRI
(9/15) test vimp2_2554_09282016_SRI
(10/15) test vimp2_2594_10172016_SRI
(11/15) test vimp2_2597_10182016_Test_NewCases_SRI
(12/15) test vimp2_2598_10192016_Test_NewCases_SRI
(13/15) test vimp2_1876_01262016_SRI
(14/15) test vimp2_2475_08242016_SRI
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 10)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 11)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 30)   3000        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 30)   8130        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 30)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 40, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 60)   16260       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 60)   32460       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 90)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 90)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 120)  97320       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 120)  129720      activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 120)  480         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 120)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 210)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 210)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 60)   50460       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 60)   81060       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 60)   32460       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 60)   240         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 60)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 210)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 40, 210)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 30)   25230       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 60)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 30)   16230       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 30)   8130        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 30)   120         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 30)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 90)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 80, 90)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 13)   1183        dropout_6[0][0]                  
==================================================================================================
Total params: 504,183
Trainable params: 111,943
Non-trainable params: 392,240
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 30s - loss: 13807.0219 - acc: 0.6887 - mDice: 0.1079 - val_loss: 5831.4658 - val_acc: 0.9058 - val_mDice: 0.2961

Epoch 00001: val_mDice improved from -inf to 0.29609, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 19s - loss: 5239.5501 - acc: 0.8723 - mDice: 0.3538 - val_loss: 9046.9697 - val_acc: 0.9055 - val_mDice: 0.2584

Epoch 00002: val_mDice did not improve from 0.29609
Epoch 3/300
 - 19s - loss: 3873.2724 - acc: 0.8745 - mDice: 0.4578 - val_loss: 9406.4674 - val_acc: 0.9057 - val_mDice: 0.3007

Epoch 00003: val_mDice improved from 0.29609 to 0.30067, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 19s - loss: 3307.2421 - acc: 0.8772 - mDice: 0.5119 - val_loss: 6941.5340 - val_acc: 0.9059 - val_mDice: 0.3383

Epoch 00004: val_mDice improved from 0.30067 to 0.33825, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 19s - loss: 2960.2783 - acc: 0.8800 - mDice: 0.5487 - val_loss: 4594.8552 - val_acc: 0.9091 - val_mDice: 0.4176

Epoch 00005: val_mDice improved from 0.33825 to 0.41760, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 19s - loss: 2715.0955 - acc: 0.8837 - mDice: 0.5767 - val_loss: 3549.5848 - val_acc: 0.9145 - val_mDice: 0.4704

Epoch 00006: val_mDice improved from 0.41760 to 0.47041, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 19s - loss: 2559.6631 - acc: 0.8872 - mDice: 0.5955 - val_loss: 3179.3060 - val_acc: 0.9164 - val_mDice: 0.5041

Epoch 00007: val_mDice improved from 0.47041 to 0.50413, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 19s - loss: 2417.8773 - acc: 0.8907 - mDice: 0.6126 - val_loss: 3021.0322 - val_acc: 0.9205 - val_mDice: 0.5201

Epoch 00008: val_mDice improved from 0.50413 to 0.52009, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 19s - loss: 2315.8958 - acc: 0.8944 - mDice: 0.6254 - val_loss: 3232.2033 - val_acc: 0.9180 - val_mDice: 0.5001

Epoch 00009: val_mDice did not improve from 0.52009
Epoch 10/300
 - 19s - loss: 2241.3344 - acc: 0.8985 - mDice: 0.6350 - val_loss: 3214.6496 - val_acc: 0.9210 - val_mDice: 0.5008

Epoch 00010: val_mDice did not improve from 0.52009
Epoch 11/300
 - 18s - loss: 2160.1478 - acc: 0.9046 - mDice: 0.6455 - val_loss: 3080.3270 - val_acc: 0.9305 - val_mDice: 0.5166

Epoch 00011: val_mDice did not improve from 0.52009
Epoch 12/300
 - 19s - loss: 2106.3188 - acc: 0.9115 - mDice: 0.6523 - val_loss: 3651.6960 - val_acc: 0.9219 - val_mDice: 0.4589

Epoch 00012: val_mDice did not improve from 0.52009
Epoch 13/300
 - 19s - loss: 2042.7542 - acc: 0.9173 - mDice: 0.6606 - val_loss: 3221.9069 - val_acc: 0.9307 - val_mDice: 0.5012

Epoch 00013: val_mDice did not improve from 0.52009
Epoch 14/300
 - 18s - loss: 2009.3106 - acc: 0.9214 - mDice: 0.6650 - val_loss: 3406.3176 - val_acc: 0.9300 - val_mDice: 0.4839

Epoch 00014: val_mDice did not improve from 0.52009
Epoch 15/300
 - 19s - loss: 1967.3507 - acc: 0.9245 - mDice: 0.6703 - val_loss: 3101.1887 - val_acc: 0.9367 - val_mDice: 0.5115

Epoch 00015: val_mDice did not improve from 0.52009
Epoch 16/300
 - 19s - loss: 1914.4578 - acc: 0.9279 - mDice: 0.6775 - val_loss: 3073.6875 - val_acc: 0.9338 - val_mDice: 0.5139

Epoch 00016: val_mDice did not improve from 0.52009
Epoch 17/300
 - 19s - loss: 1873.6295 - acc: 0.9314 - mDice: 0.6827 - val_loss: 3042.7086 - val_acc: 0.9363 - val_mDice: 0.5182

Epoch 00017: val_mDice did not improve from 0.52009
Epoch 18/300
 - 19s - loss: 1849.2125 - acc: 0.9332 - mDice: 0.6858 - val_loss: 3030.6309 - val_acc: 0.9369 - val_mDice: 0.5182

Epoch 00018: val_mDice did not improve from 0.52009
Epoch 19/300
 - 19s - loss: 1812.4484 - acc: 0.9345 - mDice: 0.6908 - val_loss: 3308.8062 - val_acc: 0.9310 - val_mDice: 0.4928

Epoch 00019: val_mDice did not improve from 0.52009
Epoch 20/300
 - 19s - loss: 1782.2646 - acc: 0.9353 - mDice: 0.6949 - val_loss: 3239.5061 - val_acc: 0.9352 - val_mDice: 0.4982

Epoch 00020: val_mDice did not improve from 0.52009
Epoch 21/300
 - 19s - loss: 1754.4515 - acc: 0.9361 - mDice: 0.6988 - val_loss: 3099.0421 - val_acc: 0.9368 - val_mDice: 0.5117

Epoch 00021: val_mDice did not improve from 0.52009
Epoch 22/300
 - 19s - loss: 1731.7559 - acc: 0.9366 - mDice: 0.7021 - val_loss: 3013.8361 - val_acc: 0.9400 - val_mDice: 0.5174

Epoch 00022: val_mDice did not improve from 0.52009
Epoch 23/300
 - 19s - loss: 1708.8038 - acc: 0.9372 - mDice: 0.7053 - val_loss: 2993.6235 - val_acc: 0.9381 - val_mDice: 0.5168

Epoch 00023: val_mDice did not improve from 0.52009
Epoch 24/300
 - 19s - loss: 1685.1494 - acc: 0.9379 - mDice: 0.7086 - val_loss: 2998.7311 - val_acc: 0.9380 - val_mDice: 0.5189

Epoch 00024: val_mDice did not improve from 0.52009
Epoch 25/300
 - 19s - loss: 1663.9559 - acc: 0.9383 - mDice: 0.7117 - val_loss: 2971.8132 - val_acc: 0.9395 - val_mDice: 0.5203

Epoch 00025: val_mDice improved from 0.52009 to 0.52026, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 26/300
 - 19s - loss: 1654.2163 - acc: 0.9385 - mDice: 0.7131 - val_loss: 2861.9298 - val_acc: 0.9396 - val_mDice: 0.5309

Epoch 00026: val_mDice improved from 0.52026 to 0.53095, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 27/300
 - 19s - loss: 1633.5369 - acc: 0.9391 - mDice: 0.7161 - val_loss: 2798.3713 - val_acc: 0.9405 - val_mDice: 0.5373

Epoch 00027: val_mDice improved from 0.53095 to 0.53726, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 28/300
 - 19s - loss: 1596.8057 - acc: 0.9398 - mDice: 0.7214 - val_loss: 2848.6336 - val_acc: 0.9394 - val_mDice: 0.5336

Epoch 00028: val_mDice did not improve from 0.53726
Epoch 29/300
 - 19s - loss: 1590.9595 - acc: 0.9400 - mDice: 0.7222 - val_loss: 2926.8886 - val_acc: 0.9418 - val_mDice: 0.5241

Epoch 00029: val_mDice did not improve from 0.53726
Epoch 30/300
 - 19s - loss: 1575.8102 - acc: 0.9404 - mDice: 0.7245 - val_loss: 2978.0358 - val_acc: 0.9386 - val_mDice: 0.5184

Epoch 00030: val_mDice did not improve from 0.53726
Epoch 31/300
 - 19s - loss: 1571.1716 - acc: 0.9407 - mDice: 0.7251 - val_loss: 3735.3208 - val_acc: 0.9366 - val_mDice: 0.4463

Epoch 00031: val_mDice did not improve from 0.53726
Epoch 32/300
 - 19s - loss: 1550.9601 - acc: 0.9409 - mDice: 0.7281 - val_loss: 3002.8715 - val_acc: 0.9391 - val_mDice: 0.5116

Epoch 00032: val_mDice did not improve from 0.53726
Epoch 33/300
 - 19s - loss: 1539.0149 - acc: 0.9413 - mDice: 0.7299 - val_loss: 2851.3758 - val_acc: 0.9401 - val_mDice: 0.5292

Epoch 00033: val_mDice did not improve from 0.53726
Epoch 34/300
 - 19s - loss: 1524.5315 - acc: 0.9414 - mDice: 0.7321 - val_loss: 2952.8416 - val_acc: 0.9412 - val_mDice: 0.5206

Epoch 00034: val_mDice did not improve from 0.53726
Epoch 35/300
 - 19s - loss: 1506.1520 - acc: 0.9418 - mDice: 0.7348 - val_loss: 2865.1566 - val_acc: 0.9415 - val_mDice: 0.5266

Epoch 00035: val_mDice did not improve from 0.53726
Epoch 36/300
 - 19s - loss: 1499.5835 - acc: 0.9420 - mDice: 0.7357 - val_loss: 2913.8684 - val_acc: 0.9406 - val_mDice: 0.5219

Epoch 00036: val_mDice did not improve from 0.53726
Epoch 37/300
 - 19s - loss: 1491.5537 - acc: 0.9423 - mDice: 0.7370 - val_loss: 3198.2477 - val_acc: 0.9396 - val_mDice: 0.4953

Epoch 00037: val_mDice did not improve from 0.53726
Epoch 38/300
 - 19s - loss: 1479.8047 - acc: 0.9426 - mDice: 0.7387 - val_loss: 2955.8716 - val_acc: 0.9387 - val_mDice: 0.5181

Epoch 00038: val_mDice did not improve from 0.53726
Epoch 39/300
 - 19s - loss: 1468.2115 - acc: 0.9428 - mDice: 0.7405 - val_loss: 2869.3686 - val_acc: 0.9413 - val_mDice: 0.5254

Epoch 00039: val_mDice did not improve from 0.53726
Epoch 40/300
 - 18s - loss: 1456.9266 - acc: 0.9431 - mDice: 0.7421 - val_loss: 2924.4151 - val_acc: 0.9400 - val_mDice: 0.5217

Epoch 00040: val_mDice did not improve from 0.53726
Epoch 41/300
 - 19s - loss: 1446.9802 - acc: 0.9432 - mDice: 0.7436 - val_loss: 2796.7076 - val_acc: 0.9417 - val_mDice: 0.5328

Epoch 00041: val_mDice did not improve from 0.53726
Epoch 42/300
 - 19s - loss: 1433.6854 - acc: 0.9435 - mDice: 0.7457 - val_loss: 2934.2813 - val_acc: 0.9399 - val_mDice: 0.5188

Epoch 00042: val_mDice did not improve from 0.53726
Epoch 43/300
 - 19s - loss: 1429.9211 - acc: 0.9437 - mDice: 0.7462 - val_loss: 2843.4667 - val_acc: 0.9416 - val_mDice: 0.5270

Epoch 00043: val_mDice did not improve from 0.53726
Epoch 44/300
 - 19s - loss: 1418.7902 - acc: 0.9438 - mDice: 0.7479 - val_loss: 2815.8361 - val_acc: 0.9416 - val_mDice: 0.5310

Epoch 00044: val_mDice did not improve from 0.53726
Epoch 45/300
 - 19s - loss: 1411.2603 - acc: 0.9441 - mDice: 0.7490 - val_loss: 2842.3560 - val_acc: 0.9413 - val_mDice: 0.5281

Epoch 00045: val_mDice did not improve from 0.53726
Epoch 46/300
 - 19s - loss: 1403.8320 - acc: 0.9440 - mDice: 0.7501 - val_loss: 2993.6781 - val_acc: 0.9407 - val_mDice: 0.5120

Epoch 00046: val_mDice did not improve from 0.53726
Epoch 47/300
 - 19s - loss: 1399.7277 - acc: 0.9443 - mDice: 0.7509 - val_loss: 3071.1304 - val_acc: 0.9413 - val_mDice: 0.5047

Epoch 00047: val_mDice did not improve from 0.53726
Epoch 48/300
 - 19s - loss: 1395.3900 - acc: 0.9444 - mDice: 0.7515 - val_loss: 2948.0669 - val_acc: 0.9416 - val_mDice: 0.5192

Epoch 00048: val_mDice did not improve from 0.53726
Epoch 49/300
 - 19s - loss: 1376.3877 - acc: 0.9449 - mDice: 0.7544 - val_loss: 2808.4733 - val_acc: 0.9422 - val_mDice: 0.5316

Epoch 00049: val_mDice did not improve from 0.53726
Epoch 50/300
 - 19s - loss: 1380.6990 - acc: 0.9448 - mDice: 0.7537 - val_loss: 2927.0088 - val_acc: 0.9414 - val_mDice: 0.5175

Epoch 00050: val_mDice did not improve from 0.53726
Epoch 51/300
 - 19s - loss: 1361.4785 - acc: 0.9451 - mDice: 0.7567 - val_loss: 2864.8693 - val_acc: 0.9419 - val_mDice: 0.5256

Epoch 00051: val_mDice did not improve from 0.53726
Epoch 52/300
 - 19s - loss: 1363.1177 - acc: 0.9451 - mDice: 0.7564 - val_loss: 3159.6090 - val_acc: 0.9412 - val_mDice: 0.4948

Epoch 00052: val_mDice did not improve from 0.53726
Epoch 53/300
 - 19s - loss: 1356.1635 - acc: 0.9451 - mDice: 0.7575 - val_loss: 2973.2937 - val_acc: 0.9405 - val_mDice: 0.5148

Epoch 00053: val_mDice did not improve from 0.53726
Epoch 54/300
 - 18s - loss: 1338.6376 - acc: 0.9454 - mDice: 0.7602 - val_loss: 2791.6681 - val_acc: 0.9431 - val_mDice: 0.5343

Epoch 00054: val_mDice did not improve from 0.53726
Epoch 55/300
 - 19s - loss: 1341.5277 - acc: 0.9455 - mDice: 0.7598 - val_loss: 3055.6783 - val_acc: 0.9396 - val_mDice: 0.5064

Epoch 00055: val_mDice did not improve from 0.53726
Epoch 56/300
 - 18s - loss: 1333.4471 - acc: 0.9456 - mDice: 0.7610 - val_loss: 2899.7513 - val_acc: 0.9412 - val_mDice: 0.5224

Epoch 00056: val_mDice did not improve from 0.53726
Epoch 57/300
 - 19s - loss: 1334.7879 - acc: 0.9456 - mDice: 0.7607 - val_loss: 2952.0116 - val_acc: 0.9405 - val_mDice: 0.5158

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.44s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.17s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.95s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:55,  1.88s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:12,  1.74s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:13,  1.75s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:53,  1.68s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:16,  1.77s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<08:01,  1.73s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:14,  1.78s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<08:02,  1.74s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:28,  1.84s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:35,  1.87s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:05,  1.77s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:19,  1.83s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<08:04,  1.78s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<08:10,  1.81s/it]predicting train subjects:   5%|▌         | 15/285 [00:26<08:39,  1.92s/it]predicting train subjects:   6%|▌         | 16/285 [00:28<08:43,  1.95s/it]predicting train subjects:   6%|▌         | 17/285 [00:30<08:21,  1.87s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:27,  1.90s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<08:05,  1.82s/it]predicting train subjects:   7%|▋         | 20/285 [00:36<08:13,  1.86s/it]predicting train subjects:   7%|▋         | 21/285 [00:38<08:40,  1.97s/it]predicting train subjects:   8%|▊         | 22/285 [00:40<08:19,  1.90s/it]predicting train subjects:   8%|▊         | 23/285 [00:42<08:21,  1.91s/it]predicting train subjects:   8%|▊         | 24/285 [00:43<07:59,  1.84s/it]predicting train subjects:   9%|▉         | 25/285 [00:46<08:30,  1.96s/it]predicting train subjects:   9%|▉         | 26/285 [00:48<08:46,  2.03s/it]predicting train subjects:   9%|▉         | 27/285 [00:50<08:22,  1.95s/it]predicting train subjects:  10%|▉         | 28/285 [00:52<08:29,  1.98s/it]predicting train subjects:  10%|█         | 29/285 [00:54<08:27,  1.98s/it]predicting train subjects:  11%|█         | 30/285 [00:56<08:24,  1.98s/it]predicting train subjects:  11%|█         | 31/285 [00:58<08:21,  1.97s/it]predicting train subjects:  11%|█         | 32/285 [00:59<07:49,  1.86s/it]predicting train subjects:  12%|█▏        | 33/285 [01:01<07:49,  1.86s/it]predicting train subjects:  12%|█▏        | 34/285 [01:03<08:02,  1.92s/it]predicting train subjects:  12%|█▏        | 35/285 [01:05<08:16,  1.98s/it]predicting train subjects:  13%|█▎        | 36/285 [01:07<07:47,  1.88s/it]predicting train subjects:  13%|█▎        | 37/285 [01:09<07:54,  1.91s/it]predicting train subjects:  13%|█▎        | 38/285 [01:11<08:01,  1.95s/it]predicting train subjects:  14%|█▎        | 39/285 [01:13<07:43,  1.88s/it]predicting train subjects:  14%|█▍        | 40/285 [01:14<07:42,  1.89s/it]predicting train subjects:  14%|█▍        | 41/285 [01:16<07:27,  1.83s/it]predicting train subjects:  15%|█▍        | 42/285 [01:18<07:18,  1.81s/it]predicting train subjects:  15%|█▌        | 43/285 [01:20<07:32,  1.87s/it]predicting train subjects:  15%|█▌        | 44/285 [01:22<07:41,  1.92s/it]predicting train subjects:  16%|█▌        | 45/285 [01:24<07:27,  1.86s/it]predicting train subjects:  16%|█▌        | 46/285 [01:26<07:45,  1.95s/it]predicting train subjects:  16%|█▋        | 47/285 [01:27<07:19,  1.85s/it]predicting train subjects:  17%|█▋        | 48/285 [01:29<07:30,  1.90s/it]predicting train subjects:  17%|█▋        | 49/285 [01:32<07:39,  1.95s/it]predicting train subjects:  18%|█▊        | 50/285 [01:33<07:36,  1.94s/it]predicting train subjects:  18%|█▊        | 51/285 [01:36<07:46,  2.00s/it]predicting train subjects:  18%|█▊        | 52/285 [01:37<07:30,  1.93s/it]predicting train subjects:  19%|█▊        | 53/285 [01:39<07:30,  1.94s/it]predicting train subjects:  19%|█▉        | 54/285 [01:41<07:33,  1.96s/it]predicting train subjects:  19%|█▉        | 55/285 [01:43<07:05,  1.85s/it]predicting train subjects:  20%|█▉        | 56/285 [01:45<07:09,  1.88s/it]predicting train subjects:  20%|██        | 57/285 [01:47<06:54,  1.82s/it]predicting train subjects:  20%|██        | 58/285 [01:49<07:07,  1.89s/it]predicting train subjects:  21%|██        | 59/285 [01:51<07:14,  1.92s/it]predicting train subjects:  21%|██        | 60/285 [01:53<07:18,  1.95s/it]predicting train subjects:  21%|██▏       | 61/285 [01:54<06:58,  1.87s/it]predicting train subjects:  22%|██▏       | 62/285 [01:56<07:03,  1.90s/it]predicting train subjects:  22%|██▏       | 63/285 [01:58<07:00,  1.90s/it]predicting train subjects:  22%|██▏       | 64/285 [02:00<06:59,  1.90s/it]predicting train subjects:  23%|██▎       | 65/285 [02:02<07:03,  1.92s/it]predicting train subjects:  23%|██▎       | 66/285 [02:04<06:54,  1.89s/it]predicting train subjects:  24%|██▎       | 67/285 [02:06<06:53,  1.90s/it]predicting train subjects:  24%|██▍       | 68/285 [02:08<06:43,  1.86s/it]predicting train subjects:  24%|██▍       | 69/285 [02:09<06:43,  1.87s/it]predicting train subjects:  25%|██▍       | 70/285 [02:11<06:46,  1.89s/it]predicting train subjects:  25%|██▍       | 71/285 [02:13<07:00,  1.97s/it]predicting train subjects:  25%|██▌       | 72/285 [02:15<06:43,  1.90s/it]predicting train subjects:  26%|██▌       | 73/285 [02:17<06:43,  1.90s/it]predicting train subjects:  26%|██▌       | 74/285 [02:19<06:48,  1.93s/it]predicting train subjects:  26%|██▋       | 75/285 [02:21<06:44,  1.93s/it]predicting train subjects:  27%|██▋       | 76/285 [02:23<06:48,  1.95s/it]predicting train subjects:  27%|██▋       | 77/285 [02:25<06:28,  1.87s/it]predicting train subjects:  27%|██▋       | 78/285 [02:26<06:17,  1.82s/it]predicting train subjects:  28%|██▊       | 79/285 [02:28<06:19,  1.84s/it]predicting train subjects:  28%|██▊       | 80/285 [02:30<06:19,  1.85s/it]predicting train subjects:  28%|██▊       | 81/285 [02:32<06:10,  1.81s/it]predicting train subjects:  29%|██▉       | 82/285 [02:34<06:07,  1.81s/it]predicting train subjects:  29%|██▉       | 83/285 [02:36<06:05,  1.81s/it]predicting train subjects:  29%|██▉       | 84/285 [02:37<06:05,  1.82s/it]predicting train subjects:  30%|██▉       | 85/285 [02:39<06:06,  1.83s/it]predicting train subjects:  30%|███       | 86/285 [02:41<06:13,  1.88s/it]predicting train subjects:  31%|███       | 87/285 [02:43<06:19,  1.92s/it]predicting train subjects:  31%|███       | 88/285 [02:45<06:02,  1.84s/it]predicting train subjects:  31%|███       | 89/285 [02:47<05:58,  1.83s/it]predicting train subjects:  32%|███▏      | 90/285 [02:49<06:02,  1.86s/it]predicting train subjects:  32%|███▏      | 91/285 [02:50<05:50,  1.81s/it]predicting train subjects:  32%|███▏      | 92/285 [02:52<05:59,  1.86s/it]predicting train subjects:  33%|███▎      | 93/285 [02:54<05:49,  1.82s/it]predicting train subjects:  33%|███▎      | 94/285 [02:56<05:51,  1.84s/it]predicting train subjects:  33%|███▎      | 95/285 [02:58<05:52,  1.86s/it]predicting train subjects:  34%|███▎      | 96/285 [03:00<05:53,  1.87s/it]predicting train subjects:  34%|███▍      | 97/285 [03:02<05:54,  1.88s/it]predicting train subjects:  34%|███▍      | 98/285 [03:04<05:51,  1.88s/it]predicting train subjects:  35%|███▍      | 99/285 [03:05<05:46,  1.87s/it]predicting train subjects:  35%|███▌      | 100/285 [03:07<05:51,  1.90s/it]predicting train subjects:  35%|███▌      | 101/285 [03:09<05:37,  1.83s/it]predicting train subjects:  36%|███▌      | 102/285 [03:11<05:47,  1.90s/it]predicting train subjects:  36%|███▌      | 103/285 [03:13<05:34,  1.84s/it]predicting train subjects:  36%|███▋      | 104/285 [03:15<05:35,  1.85s/it]predicting train subjects:  37%|███▋      | 105/285 [03:17<05:36,  1.87s/it]predicting train subjects:  37%|███▋      | 106/285 [03:18<05:30,  1.85s/it]predicting train subjects:  38%|███▊      | 107/285 [03:20<05:25,  1.83s/it]predicting train subjects:  38%|███▊      | 108/285 [03:22<05:13,  1.77s/it]predicting train subjects:  38%|███▊      | 109/285 [03:24<05:18,  1.81s/it]predicting train subjects:  39%|███▊      | 110/285 [03:26<05:21,  1.84s/it]predicting train subjects:  39%|███▉      | 111/285 [03:27<05:10,  1.79s/it]predicting train subjects:  39%|███▉      | 112/285 [03:29<05:09,  1.79s/it]predicting train subjects:  40%|███▉      | 113/285 [03:31<05:17,  1.85s/it]predicting train subjects:  40%|████      | 114/285 [03:33<05:13,  1.83s/it]predicting train subjects:  40%|████      | 115/285 [03:35<05:17,  1.87s/it]predicting train subjects:  41%|████      | 116/285 [03:37<05:18,  1.88s/it]predicting train subjects:  41%|████      | 117/285 [03:38<05:06,  1.83s/it]predicting train subjects:  41%|████▏     | 118/285 [03:40<05:00,  1.80s/it]predicting train subjects:  42%|████▏     | 119/285 [03:42<05:04,  1.84s/it]predicting train subjects:  42%|████▏     | 120/285 [03:44<04:54,  1.78s/it]predicting train subjects:  42%|████▏     | 121/285 [03:46<04:56,  1.81s/it]predicting train subjects:  43%|████▎     | 122/285 [03:47<04:45,  1.75s/it]predicting train subjects:  43%|████▎     | 123/285 [03:49<04:30,  1.67s/it]predicting train subjects:  44%|████▎     | 124/285 [03:50<04:26,  1.66s/it]predicting train subjects:  44%|████▍     | 125/285 [03:52<04:21,  1.63s/it]predicting train subjects:  44%|████▍     | 126/285 [03:53<04:15,  1.61s/it]predicting train subjects:  45%|████▍     | 127/285 [03:55<04:03,  1.54s/it]predicting train subjects:  45%|████▍     | 128/285 [03:56<04:07,  1.58s/it]predicting train subjects:  45%|████▌     | 129/285 [03:58<04:02,  1.55s/it]predicting train subjects:  46%|████▌     | 130/285 [03:59<03:54,  1.52s/it]predicting train subjects:  46%|████▌     | 131/285 [04:01<03:49,  1.49s/it]predicting train subjects:  46%|████▋     | 132/285 [04:02<03:54,  1.53s/it]predicting train subjects:  47%|████▋     | 133/285 [04:04<03:51,  1.52s/it]predicting train subjects:  47%|████▋     | 134/285 [04:05<03:46,  1.50s/it]predicting train subjects:  47%|████▋     | 135/285 [04:07<03:45,  1.51s/it]predicting train subjects:  48%|████▊     | 136/285 [04:08<03:45,  1.51s/it]predicting train subjects:  48%|████▊     | 137/285 [04:10<03:51,  1.56s/it]predicting train subjects:  48%|████▊     | 138/285 [04:12<03:45,  1.54s/it]predicting train subjects:  49%|████▉     | 139/285 [04:13<03:46,  1.55s/it]predicting train subjects:  49%|████▉     | 140/285 [04:15<03:47,  1.57s/it]predicting train subjects:  49%|████▉     | 141/285 [04:16<03:37,  1.51s/it]predicting train subjects:  50%|████▉     | 142/285 [04:18<03:35,  1.51s/it]predicting train subjects:  50%|█████     | 143/285 [04:19<03:34,  1.51s/it]predicting train subjects:  51%|█████     | 144/285 [04:21<03:38,  1.55s/it]predicting train subjects:  51%|█████     | 145/285 [04:22<03:30,  1.50s/it]predicting train subjects:  51%|█████     | 146/285 [04:24<03:31,  1.52s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:25<03:24,  1.48s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:27<03:26,  1.51s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:28<03:23,  1.50s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:30<03:19,  1.48s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:31<03:30,  1.57s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:33<03:23,  1.53s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:34<03:19,  1.51s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:36<03:22,  1.55s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:37<03:13,  1.49s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:39<03:18,  1.54s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:40<03:12,  1.50s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:42<03:06,  1.47s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:43<03:03,  1.45s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:45<03:02,  1.46s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:46<03:07,  1.52s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:48<03:04,  1.50s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:49<03:07,  1.54s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:51<03:01,  1.50s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:52<02:58,  1.49s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:54<03:01,  1.53s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:55<03:00,  1.53s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:57<02:56,  1.51s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:58<02:52,  1.49s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:00<02:50,  1.48s/it]predicting train subjects:  60%|██████    | 171/285 [05:01<02:48,  1.48s/it]predicting train subjects:  60%|██████    | 172/285 [05:03<02:43,  1.45s/it]predicting train subjects:  61%|██████    | 173/285 [05:04<02:41,  1.44s/it]predicting train subjects:  61%|██████    | 174/285 [05:05<02:37,  1.42s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:07<02:40,  1.46s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:09<02:44,  1.51s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:10<02:40,  1.49s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:12<02:37,  1.47s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:13<02:35,  1.47s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:15<02:45,  1.58s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:16<02:44,  1.58s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:18<02:49,  1.64s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:20<02:40,  1.58s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:21<02:35,  1.54s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:23<02:31,  1.52s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:24<02:40,  1.62s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:26<02:44,  1.68s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:28<02:45,  1.70s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:29<02:34,  1.61s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:31<02:27,  1.55s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:32<02:28,  1.58s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:34<02:28,  1.60s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:35<02:20,  1.53s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:37<02:15,  1.49s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:38<02:11,  1.46s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:40<02:21,  1.59s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:42<02:27,  1.67s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:44<02:28,  1.71s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:45<02:19,  1.62s/it]predicting train subjects:  70%|███████   | 200/285 [05:47<02:16,  1.61s/it]predicting train subjects:  71%|███████   | 201/285 [05:48<02:18,  1.65s/it]predicting train subjects:  71%|███████   | 202/285 [05:50<02:15,  1.64s/it]predicting train subjects:  71%|███████   | 203/285 [05:52<02:15,  1.65s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:53<02:07,  1.57s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:55<02:03,  1.54s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:56<01:58,  1.49s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:58<02:04,  1.59s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:00<02:07,  1.65s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:02<02:10,  1.72s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:03<02:01,  1.62s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:04<01:55,  1.56s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:06<01:56,  1.59s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:08<01:56,  1.62s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:09<01:50,  1.55s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:11<01:54,  1.64s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:12<01:46,  1.54s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:14<01:51,  1.64s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:16<01:53,  1.69s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:18<01:55,  1.75s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:19<01:46,  1.64s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:21<01:40,  1.58s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:22<01:40,  1.59s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:24<01:34,  1.52s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:25<01:31,  1.51s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:26<01:27,  1.46s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:28<01:34,  1.60s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:30<01:37,  1.68s/it]predicting train subjects:  80%|████████  | 228/285 [06:32<01:37,  1.71s/it]predicting train subjects:  80%|████████  | 229/285 [06:34<01:34,  1.69s/it]predicting train subjects:  81%|████████  | 230/285 [06:35<01:27,  1.59s/it]predicting train subjects:  81%|████████  | 231/285 [06:36<01:22,  1.54s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:38<01:23,  1.57s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:39<01:18,  1.51s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:41<01:21,  1.61s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:43<01:16,  1.54s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:45<01:20,  1.65s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:46<01:22,  1.71s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:48<01:22,  1.76s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:50<01:19,  1.73s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:51<01:14,  1.64s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:53<01:10,  1.60s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:54<01:07,  1.57s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:56<01:03,  1.52s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:58<01:06,  1.62s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:59<01:01,  1.55s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:01<01:04,  1.65s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:03<01:04,  1.69s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:04<01:02,  1.69s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:06<00:57,  1.59s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:07<00:54,  1.57s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:09<00:51,  1.51s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:10<00:49,  1.49s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:12<00:51,  1.62s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:14<00:52,  1.68s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:15<00:50,  1.68s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:17<00:45,  1.58s/it]predicting train subjects:  90%|█████████ | 257/285 [07:18<00:43,  1.56s/it]predicting train subjects:  91%|█████████ | 258/285 [07:20<00:44,  1.67s/it]predicting train subjects:  91%|█████████ | 259/285 [07:22<00:43,  1.66s/it]predicting train subjects:  91%|█████████ | 260/285 [07:23<00:38,  1.55s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:25<00:36,  1.51s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:26<00:33,  1.46s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:27<00:31,  1.43s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:29<00:33,  1.58s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:31<00:32,  1.64s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:32<00:29,  1.56s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:34<00:27,  1.53s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:36<00:28,  1.65s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:37<00:26,  1.65s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:39<00:23,  1.57s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:40<00:21,  1.54s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:42<00:20,  1.60s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:43<00:18,  1.55s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:45<00:16,  1.51s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:47<00:16,  1.62s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:49<00:15,  1.68s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:50<00:12,  1.59s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:51<00:10,  1.55s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:53<00:09,  1.58s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:54<00:07,  1.53s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:56<00:06,  1.51s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:57<00:04,  1.46s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:59<00:03,  1.56s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:01<00:01,  1.63s/it]predicting train subjects: 100%|██████████| 285/285 [08:03<00:00,  1.68s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:52,  1.66s/it]Loading train:   1%|          | 2/285 [00:02<07:14,  1.53s/it]Loading train:   1%|          | 3/285 [00:04<07:05,  1.51s/it]Loading train:   1%|▏         | 4/285 [00:05<06:40,  1.43s/it]Loading train:   2%|▏         | 5/285 [00:07<06:57,  1.49s/it]Loading train:   2%|▏         | 6/285 [00:08<06:35,  1.42s/it]Loading train:   2%|▏         | 7/285 [00:10<06:48,  1.47s/it]Loading train:   3%|▎         | 8/285 [00:11<06:44,  1.46s/it]Loading train:   3%|▎         | 9/285 [00:13<07:12,  1.57s/it]Loading train:   4%|▎         | 10/285 [00:14<06:44,  1.47s/it]Loading train:   4%|▍         | 11/285 [00:15<06:09,  1.35s/it]Loading train:   4%|▍         | 12/285 [00:16<06:00,  1.32s/it]Loading train:   5%|▍         | 13/285 [00:17<05:34,  1.23s/it]Loading train:   5%|▍         | 14/285 [00:19<05:29,  1.22s/it]Loading train:   5%|▌         | 15/285 [00:20<05:31,  1.23s/it]Loading train:   6%|▌         | 16/285 [00:21<05:31,  1.23s/it]Loading train:   6%|▌         | 17/285 [00:22<05:22,  1.20s/it]Loading train:   6%|▋         | 18/285 [00:23<05:13,  1.17s/it]Loading train:   7%|▋         | 19/285 [00:24<05:02,  1.14s/it]Loading train:   7%|▋         | 20/285 [00:26<05:01,  1.14s/it]Loading train:   7%|▋         | 21/285 [00:27<05:14,  1.19s/it]Loading train:   8%|▊         | 22/285 [00:28<05:01,  1.15s/it]Loading train:   8%|▊         | 23/285 [00:29<05:04,  1.16s/it]Loading train:   8%|▊         | 24/285 [00:30<04:58,  1.14s/it]Loading train:   9%|▉         | 25/285 [00:31<05:01,  1.16s/it]Loading train:   9%|▉         | 26/285 [00:33<05:04,  1.17s/it]Loading train:   9%|▉         | 27/285 [00:34<05:00,  1.17s/it]Loading train:  10%|▉         | 28/285 [00:35<05:01,  1.17s/it]Loading train:  10%|█         | 29/285 [00:36<04:54,  1.15s/it]Loading train:  11%|█         | 30/285 [00:37<04:59,  1.17s/it]Loading train:  11%|█         | 31/285 [00:38<05:01,  1.19s/it]Loading train:  11%|█         | 32/285 [00:39<04:36,  1.09s/it]Loading train:  12%|█▏        | 33/285 [00:40<04:27,  1.06s/it]Loading train:  12%|█▏        | 34/285 [00:41<04:28,  1.07s/it]Loading train:  12%|█▏        | 35/285 [00:43<04:46,  1.14s/it]Loading train:  13%|█▎        | 36/285 [00:44<04:48,  1.16s/it]Loading train:  13%|█▎        | 37/285 [00:45<04:43,  1.14s/it]Loading train:  13%|█▎        | 38/285 [00:46<04:53,  1.19s/it]Loading train:  14%|█▎        | 39/285 [00:47<04:31,  1.10s/it]Loading train:  14%|█▍        | 40/285 [00:48<04:36,  1.13s/it]Loading train:  14%|█▍        | 41/285 [00:49<04:21,  1.07s/it]Loading train:  15%|█▍        | 42/285 [00:50<04:04,  1.01s/it]Loading train:  15%|█▌        | 43/285 [00:51<04:02,  1.00s/it]Loading train:  15%|█▌        | 44/285 [00:52<04:07,  1.03s/it]Loading train:  16%|█▌        | 45/285 [00:53<04:00,  1.00s/it]Loading train:  16%|█▌        | 46/285 [00:54<04:09,  1.05s/it]Loading train:  16%|█▋        | 47/285 [00:56<04:16,  1.08s/it]Loading train:  17%|█▋        | 48/285 [00:57<04:28,  1.13s/it]Loading train:  17%|█▋        | 49/285 [00:58<04:30,  1.15s/it]Loading train:  18%|█▊        | 50/285 [00:59<04:24,  1.12s/it]Loading train:  18%|█▊        | 51/285 [01:00<04:30,  1.16s/it]Loading train:  18%|█▊        | 52/285 [01:01<04:22,  1.13s/it]Loading train:  19%|█▊        | 53/285 [01:02<04:18,  1.11s/it]Loading train:  19%|█▉        | 54/285 [01:04<04:30,  1.17s/it]Loading train:  19%|█▉        | 55/285 [01:05<04:26,  1.16s/it]Loading train:  20%|█▉        | 56/285 [01:06<04:31,  1.18s/it]Loading train:  20%|██        | 57/285 [01:07<04:14,  1.11s/it]Loading train:  20%|██        | 58/285 [01:08<04:12,  1.11s/it]Loading train:  21%|██        | 59/285 [01:10<04:32,  1.21s/it]Loading train:  21%|██        | 60/285 [01:11<04:48,  1.28s/it]Loading train:  21%|██▏       | 61/285 [01:13<05:01,  1.35s/it]Loading train:  22%|██▏       | 62/285 [01:14<05:10,  1.39s/it]Loading train:  22%|██▏       | 63/285 [01:16<05:36,  1.51s/it]Loading train:  22%|██▏       | 64/285 [01:17<05:38,  1.53s/it]Loading train:  23%|██▎       | 65/285 [01:19<05:55,  1.62s/it]
Epoch 00057: val_mDice did not improve from 0.53726
Restoring model weights from the end of the best epoch
Epoch 00057: early stopping
{'val_loss': [5831.465808686756, 9046.969656808036, 9406.46742466518, 6941.533993675595, 4594.855178106399, 3549.5847749255954, 3179.3059895833335, 3021.032156808036, 3232.203322637649, 3214.6496000744046, 3080.3269973028273, 3651.6960100446427, 3221.9069242931546, 3406.317603701637, 3101.188743954613, 3073.687453497024, 3042.7085890997023, 3030.630882626488, 3308.8061872209823, 3239.5060686383927, 3099.0421142578125, 3013.8361235119046, 2993.6234537760415, 2998.731131417411, 2971.813209170387, 2861.9297805059523, 2798.3712565104165, 2848.633608863467, 2926.888602120536, 2978.035842168899, 3735.32080078125, 3002.871518089658, 2851.375796363467, 2952.8416283017114, 2865.1565987723216, 2913.868405296689, 3198.2476922898068, 2955.87156749907, 2869.368597121466, 2924.4151291620165, 2796.7076096307665, 2934.281283424014, 2843.4666573660716, 2815.836119152251, 2842.3560427711122, 2993.6781499953495, 3071.130408877418, 2948.066949753534, 2808.473318917411, 2927.008780343192, 2864.8692641485304, 3159.6090349469864, 2973.293724423363, 2791.6681111653647, 3055.6783418201267, 2899.751259940011, 2952.0115654355004], 'val_acc': [0.9057829890932355, 0.9055219604855492, 0.9057417370024181, 0.9058562545549302, 0.9091277718544006, 0.9145489704041254, 0.9164056749570937, 0.9205311139424642, 0.9180265665054321, 0.9210256480035328, 0.9304670237359547, 0.9219413967359633, 0.9306799400420416, 0.9300366413025629, 0.9367147655714125, 0.9338095301673526, 0.93626830691383, 0.936868116969154, 0.9309615208989098, 0.9351785864148822, 0.9368475278218588, 0.9400343128613063, 0.9381203992026192, 0.9380288379532951, 0.9395054692313785, 0.9396405447097051, 0.9404990786597842, 0.9394093411309379, 0.9418017466862997, 0.9386057938848223, 0.936618563674745, 0.9391025531859625, 0.9401259166853768, 0.9411790229025341, 0.9414514643805367, 0.9406227185612633, 0.9396291318393889, 0.9387179244132269, 0.9413003694443476, 0.9399656852086385, 0.9416689390227908, 0.9399015562874931, 0.9415590933391026, 0.9416460650307792, 0.9412774613925389, 0.9407005253292265, 0.9413003694443476, 0.9415773550669352, 0.9421634730838594, 0.9413713131632123, 0.941918480963934, 0.9411653195108686, 0.9405311374437242, 0.9430723360606602, 0.9395673246610732, 0.9412111072313218, 0.9405242488497779], 'val_mDice': [0.29608753075202304, 0.2583965810010254, 0.3006707681453831, 0.3382548862192336, 0.41759559849188443, 0.470406979677223, 0.5041259807490167, 0.5200930010704767, 0.5001338134918895, 0.5007640002738862, 0.5166006570770627, 0.45894587643089746, 0.5012339046668439, 0.48388343464050976, 0.5114744140633515, 0.5138980354226771, 0.5182206410737265, 0.5181675567513421, 0.492788984307221, 0.49816199196946054, 0.5116625690744037, 0.5173816629463718, 0.5167952137334006, 0.5189405564396155, 0.5202553582688173, 0.5309481063768977, 0.537259833088943, 0.5335710754706746, 0.5241174286320096, 0.5184014482157571, 0.44627165900809423, 0.5115527615305924, 0.5292412950879052, 0.520647308301358, 0.5266227770064559, 0.5218504355067298, 0.4953374653345063, 0.5181048633087249, 0.5253908722883179, 0.5216724918711753, 0.5327885491507394, 0.5187543586251282, 0.5270130786867369, 0.5310269365353244, 0.528142190937485, 0.5119562727354822, 0.504666001846393, 0.519221149739765, 0.5316298039896148, 0.5175279682236058, 0.525596401343743, 0.494776270928837, 0.5148088488550413, 0.5342521710055215, 0.5063852635877473, 0.5224213138932273, 0.5158303390656199], 'loss': [13807.021923705748, 5239.55005042843, 3873.2723591769386, 3307.2421436798877, 2960.2783072276543, 2715.095473740127, 2559.6630688989603, 2417.877299355661, 2315.8957585661497, 2241.3344273064345, 2160.147844469384, 2106.318779431489, 2042.7541752894858, 2009.3105666905394, 1967.3507283175638, 1914.4578167408079, 1873.6294637444348, 1849.2125103407934, 1812.4483522319922, 1782.2646129719205, 1754.4514904062667, 1731.755904560078, 1708.8038463750647, 1685.1494047430776, 1663.9559465257194, 1654.216267644773, 1633.536859186164, 1596.8056563669163, 1590.9594884239596, 1575.810219518523, 1571.1716426498563, 1550.960076182983, 1539.0149225132393, 1524.5315365016356, 1506.1520365385368, 1499.5834623461449, 1491.5537160678891, 1479.8047499824909, 1468.21147859131, 1456.9265739304128, 1446.980174505713, 1433.6854449261675, 1429.9211334469737, 1418.790231075548, 1411.260297961701, 1403.8319693558567, 1399.7276956570363, 1395.390039594366, 1376.387729507249, 1380.6990468584322, 1361.47847846498, 1363.1177397110753, 1356.1634616796648, 1338.6376402902538, 1341.5277419670344, 1333.4470753063924, 1334.7878661309223], 'acc': [0.6886802364233396, 0.8723179986878169, 0.8745312316008149, 0.8771995659023437, 0.8800332958192202, 0.8837063774819868, 0.8872005516838793, 0.890705916540044, 0.8944439518329884, 0.8985064853839569, 0.9045941171582687, 0.9114503591120852, 0.917305861189114, 0.9213730264358123, 0.9245040072902034, 0.9279291738957276, 0.9313887984324725, 0.9332039892064461, 0.9345213758570853, 0.9352961028842584, 0.9361132374268542, 0.9366452138111819, 0.9372199923633173, 0.9378537412482189, 0.9382722936017632, 0.9385032708736336, 0.9390789514703054, 0.9398454529875525, 0.9400397950752131, 0.9403629294819792, 0.9406521807798007, 0.9408994218920246, 0.9412874363510738, 0.9414196560579112, 0.9418006036031997, 0.9420411466563945, 0.942329542517823, 0.9425670541341719, 0.9427914758603744, 0.9430788012398491, 0.9432279111126932, 0.9435481023002457, 0.9436508493086081, 0.9437593392997619, 0.9441099517580308, 0.9440378872489157, 0.9442536633713801, 0.9444390157065641, 0.9448742741377385, 0.9447999384354047, 0.945147399086931, 0.9450562414990608, 0.9451210332417823, 0.9454215703291863, 0.9455322837333172, 0.9456223998544119, 0.9456382486110987], 'mDice': [0.10793729048888072, 0.35375081633289635, 0.45777172755707846, 0.5118977823927611, 0.5487068606314688, 0.5766528099861498, 0.5954996474519593, 0.6125762470889602, 0.6254327890843998, 0.6350447938050152, 0.645495703058572, 0.6523196234371199, 0.6606122760017047, 0.6649638952399026, 0.6703378584703453, 0.6775113255365841, 0.6827408374332614, 0.6857629789422651, 0.6908343665995579, 0.6949027438878048, 0.6988095795577355, 0.7020619648349108, 0.7053458558954622, 0.7086071778359568, 0.7116830712663706, 0.7130679670776594, 0.7160821267927407, 0.7213833480987196, 0.7222422815504528, 0.7244763820070693, 0.7251421462623099, 0.728106661180276, 0.729930796902695, 0.7320764434689245, 0.7347936675064546, 0.7356751314219836, 0.7369626005398692, 0.7386576337278383, 0.7404622622760753, 0.7421345715006124, 0.7435898866316981, 0.7456917884332817, 0.7461954251474697, 0.7478766541203392, 0.7490040133264636, 0.7501480350242499, 0.7508710381473124, 0.7514960459024662, 0.7543539986551577, 0.7537094081714476, 0.7566866003435104, 0.7564389811721361, 0.7575196751813703, 0.7601715248628965, 0.7597615475458793, 0.761011823078146, 0.760747303800912]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 maxLoading train:  23%|██▎       | 66/285 [01:21<06:12,  1.70s/it]Loading train:  24%|██▎       | 67/285 [01:23<05:52,  1.62s/it]Loading train:  24%|██▍       | 68/285 [01:24<05:47,  1.60s/it]Loading train:  24%|██▍       | 69/285 [01:26<05:44,  1.59s/it]Loading train:  25%|██▍       | 70/285 [01:27<05:49,  1.62s/it]Loading train:  25%|██▍       | 71/285 [01:29<05:46,  1.62s/it]Loading train:  25%|██▌       | 72/285 [01:31<05:55,  1.67s/it]Loading train:  26%|██▌       | 73/285 [01:32<05:57,  1.68s/it]Loading train:  26%|██▌       | 74/285 [01:34<05:43,  1.63s/it]Loading train:  26%|██▋       | 75/285 [01:36<06:05,  1.74s/it]Loading train:  27%|██▋       | 76/285 [01:38<05:51,  1.68s/it]Loading train:  27%|██▋       | 77/285 [01:39<05:34,  1.61s/it]Loading train:  27%|██▋       | 78/285 [01:40<05:20,  1.55s/it]Loading train:  28%|██▊       | 79/285 [01:42<05:16,  1.54s/it]Loading train:  28%|██▊       | 80/285 [01:43<05:15,  1.54s/it]Loading train:  28%|██▊       | 81/285 [01:45<05:06,  1.50s/it]Loading train:  29%|██▉       | 82/285 [01:46<05:08,  1.52s/it]Loading train:  29%|██▉       | 83/285 [01:48<05:03,  1.50s/it]Loading train:  29%|██▉       | 84/285 [01:49<04:50,  1.45s/it]Loading train:  30%|██▉       | 85/285 [01:51<04:43,  1.42s/it]Loading train:  30%|███       | 86/285 [01:52<04:40,  1.41s/it]Loading train:  31%|███       | 87/285 [01:53<04:37,  1.40s/it]Loading train:  31%|███       | 88/285 [01:55<04:24,  1.34s/it]Loading train:  31%|███       | 89/285 [01:56<04:33,  1.40s/it]Loading train:  32%|███▏      | 90/285 [01:57<04:32,  1.40s/it]Loading train:  32%|███▏      | 91/285 [01:59<04:26,  1.37s/it]Loading train:  32%|███▏      | 92/285 [02:00<04:24,  1.37s/it]Loading train:  33%|███▎      | 93/285 [02:01<04:23,  1.37s/it]Loading train:  33%|███▎      | 94/285 [02:03<04:33,  1.43s/it]Loading train:  33%|███▎      | 95/285 [02:05<04:39,  1.47s/it]Loading train:  34%|███▎      | 96/285 [02:06<04:36,  1.46s/it]Loading train:  34%|███▍      | 97/285 [02:08<04:45,  1.52s/it]Loading train:  34%|███▍      | 98/285 [02:09<04:47,  1.53s/it]Loading train:  35%|███▍      | 99/285 [02:11<04:50,  1.56s/it]Loading train:  35%|███▌      | 100/285 [02:12<04:37,  1.50s/it]Loading train:  35%|███▌      | 101/285 [02:14<04:30,  1.47s/it]Loading train:  36%|███▌      | 102/285 [02:15<04:22,  1.44s/it]Loading train:  36%|███▌      | 103/285 [02:16<04:07,  1.36s/it]Loading train:  36%|███▋      | 104/285 [02:18<04:10,  1.38s/it]Loading train:  37%|███▋      | 105/285 [02:19<03:59,  1.33s/it]Loading train:  37%|███▋      | 106/285 [02:20<04:00,  1.35s/it]Loading train:  38%|███▊      | 107/285 [02:22<04:16,  1.44s/it]Loading train:  38%|███▊      | 108/285 [02:23<04:10,  1.41s/it]Loading train:  38%|███▊      | 109/285 [02:25<04:10,  1.42s/it]Loading train:  39%|███▊      | 110/285 [02:26<04:10,  1.43s/it]Loading train:  39%|███▉      | 111/285 [02:28<04:08,  1.43s/it]Loading train:  39%|███▉      | 112/285 [02:29<04:02,  1.40s/it]Loading train:  40%|███▉      | 113/285 [02:30<04:08,  1.44s/it]Loading train:  40%|████      | 114/285 [02:32<03:59,  1.40s/it]Loading train:  40%|████      | 115/285 [02:34<04:17,  1.52s/it]Loading train:  41%|████      | 116/285 [02:35<04:15,  1.51s/it]Loading train:  41%|████      | 117/285 [02:36<04:05,  1.46s/it]Loading train:  41%|████▏     | 118/285 [02:38<04:03,  1.46s/it]Loading train:  42%|████▏     | 119/285 [02:39<03:58,  1.44s/it]Loading train:  42%|████▏     | 120/285 [02:40<03:42,  1.35s/it]Loading train:  42%|████▏     | 121/285 [02:42<03:50,  1.41s/it]Loading train:  43%|████▎     | 122/285 [02:43<03:56,  1.45s/it]Loading train:  43%|████▎     | 123/285 [02:45<03:54,  1.45s/it]Loading train:  44%|████▎     | 124/285 [02:46<03:38,  1.35s/it]Loading train:  44%|████▍     | 125/285 [02:47<03:38,  1.36s/it]Loading train:  44%|████▍     | 126/285 [02:49<03:28,  1.31s/it]Loading train:  45%|████▍     | 127/285 [02:50<03:19,  1.26s/it]Loading train:  45%|████▍     | 128/285 [02:51<03:09,  1.20s/it]Loading train:  45%|████▌     | 129/285 [02:52<03:04,  1.19s/it]Loading train:  46%|████▌     | 130/285 [02:53<03:11,  1.24s/it]Loading train:  46%|████▌     | 131/285 [02:55<03:13,  1.26s/it]Loading train:  46%|████▋     | 132/285 [02:56<03:05,  1.21s/it]Loading train:  47%|████▋     | 133/285 [02:57<03:08,  1.24s/it]Loading train:  47%|████▋     | 134/285 [02:58<03:11,  1.27s/it]Loading train:  47%|████▋     | 135/285 [03:00<03:13,  1.29s/it]Loading train:  48%|████▊     | 136/285 [03:01<03:05,  1.24s/it]Loading train:  48%|████▊     | 137/285 [03:02<02:59,  1.21s/it]Loading train:  48%|████▊     | 138/285 [03:03<02:49,  1.15s/it]Loading train:  49%|████▉     | 139/285 [03:04<02:51,  1.17s/it]Loading train:  49%|████▉     | 140/285 [03:05<02:44,  1.13s/it]Loading train:  49%|████▉     | 141/285 [03:06<02:38,  1.10s/it]Loading train:  50%|████▉     | 142/285 [03:07<02:40,  1.12s/it]Loading train:  50%|█████     | 143/285 [03:09<02:40,  1.13s/it]Loading train:  51%|█████     | 144/285 [03:10<02:53,  1.23s/it]Loading train:  51%|█████     | 145/285 [03:11<02:53,  1.24s/it]Loading train:  51%|█████     | 146/285 [03:13<02:54,  1.26s/it]Loading train:  52%|█████▏    | 147/285 [03:14<02:51,  1.25s/it]Loading train:  52%|█████▏    | 148/285 [03:15<02:55,  1.28s/it]Loading train:  52%|█████▏    | 149/285 [03:16<02:50,  1.26s/it]Loading train:  53%|█████▎    | 150/285 [03:18<02:46,  1.23s/it]Loading train:  53%|█████▎    | 151/285 [03:19<02:44,  1.23s/it]Loading train:  53%|█████▎    | 152/285 [03:20<02:42,  1.22s/it]Loading train:  54%|█████▎    | 153/285 [03:21<02:37,  1.20s/it]Loading train:  54%|█████▍    | 154/285 [03:22<02:39,  1.22s/it]Loading train:  54%|█████▍    | 155/285 [03:24<02:35,  1.20s/it]Loading train:  55%|█████▍    | 156/285 [03:25<02:35,  1.20s/it]Loading train:  55%|█████▌    | 157/285 [03:26<02:35,  1.21s/it]Loading train:  55%|█████▌    | 158/285 [03:27<02:29,  1.18s/it]Loading train:  56%|█████▌    | 159/285 [03:28<02:26,  1.17s/it]Loading train:  56%|█████▌    | 160/285 [03:30<02:30,  1.20s/it]Loading train:  56%|█████▋    | 161/285 [03:31<02:30,  1.21s/it]Loading train:  57%|█████▋    | 162/285 [03:32<02:29,  1.22s/it]Loading train:  57%|█████▋    | 163/285 [03:33<02:34,  1.26s/it]Loading train:  58%|█████▊    | 164/285 [03:35<02:39,  1.32s/it]Loading train:  58%|█████▊    | 165/285 [03:36<02:41,  1.35s/it]Loading train:  58%|█████▊    | 166/285 [03:37<02:37,  1.33s/it]Loading train:  59%|█████▊    | 167/285 [03:39<02:37,  1.33s/it]Loading train:  59%|█████▉    | 168/285 [03:40<02:36,  1.33s/it]Loading train:  59%|█████▉    | 169/285 [03:41<02:33,  1.32s/it]Loading train:  60%|█████▉    | 170/285 [03:43<02:39,  1.38s/it]Loading train:  60%|██████    | 171/285 [03:44<02:31,  1.33s/it]Loading train:  60%|██████    | 172/285 [03:46<02:31,  1.34s/it]Loading train:  61%|██████    | 173/285 [03:47<02:23,  1.28s/it]Loading train:  61%|██████    | 174/285 [03:48<02:18,  1.24s/it]Loading train:  61%|██████▏   | 175/285 [03:49<02:15,  1.23s/it]Loading train:  62%|██████▏   | 176/285 [03:51<02:20,  1.29s/it]Loading train:  62%|██████▏   | 177/285 [03:52<02:19,  1.29s/it]Loading train:  62%|██████▏   | 178/285 [03:53<02:15,  1.26s/it]Loading train:  63%|██████▎   | 179/285 [03:54<02:16,  1.28s/it]Loading train:  63%|██████▎   | 180/285 [03:56<02:20,  1.34s/it]Loading train:  64%|██████▎   | 181/285 [03:57<02:20,  1.35s/it]Loading train:  64%|██████▍   | 182/285 [03:59<02:22,  1.39s/it]Loading train:  64%|██████▍   | 183/285 [04:00<02:17,  1.34s/it]Loading train:  65%|██████▍   | 184/285 [04:01<02:11,  1.30s/it]Loading train:  65%|██████▍   | 185/285 [04:02<02:10,  1.30s/it]Loading train:  65%|██████▌   | 186/285 [04:04<02:15,  1.37s/it]Loading train:  66%|██████▌   | 187/285 [04:05<02:12,  1.35s/it]Loading train:  66%|██████▌   | 188/285 [04:06<02:07,  1.32s/it]Loading train:  66%|██████▋   | 189/285 [04:08<02:03,  1.29s/it]Loading train:  67%|██████▋   | 190/285 [04:09<02:00,  1.27s/it]Loading train:  67%|██████▋   | 191/285 [04:10<01:55,  1.22s/it]Loading train:  67%|██████▋   | 192/285 [04:11<01:50,  1.19s/it]Loading train:  68%|██████▊   | 193/285 [04:12<01:47,  1.17s/it]Loading train:  68%|██████▊   | 194/285 [04:13<01:47,  1.18s/it]Loading train:  68%|██████▊   | 195/285 [04:15<01:42,  1.14s/it]Loading train:  69%|██████▉   | 196/285 [04:16<01:55,  1.30s/it]Loading train:  69%|██████▉   | 197/285 [04:18<01:55,  1.31s/it]Loading train:  69%|██████▉   | 198/285 [04:19<01:53,  1.31s/it]Loading train:  70%|██████▉   | 199/285 [04:20<01:53,  1.32s/it]Loading train:  70%|███████   | 200/285 [04:21<01:50,  1.30s/it]Loading train:  71%|███████   | 201/285 [04:23<02:00,  1.43s/it]Loading train:  71%|███████   | 202/285 [04:25<01:57,  1.42s/it]Loading train:  71%|███████   | 203/285 [04:26<01:54,  1.39s/it]Loading train:  72%|███████▏  | 204/285 [04:27<01:47,  1.32s/it]Loading train:  72%|███████▏  | 205/285 [04:28<01:41,  1.27s/it]Loading train:  72%|███████▏  | 206/285 [04:29<01:38,  1.24s/it]Loading train:  73%|███████▎  | 207/285 [04:31<01:37,  1.25s/it]Loading train:  73%|███████▎  | 208/285 [04:32<01:37,  1.27s/it]Loading train:  73%|███████▎  | 209/285 [04:33<01:35,  1.26s/it]Loading train:  74%|███████▎  | 210/285 [04:35<01:41,  1.36s/it]Loading train:  74%|███████▍  | 211/285 [04:36<01:35,  1.29s/it]Loading train:  74%|███████▍  | 212/285 [04:37<01:32,  1.27s/it]Loading train:  75%|███████▍  | 213/285 [04:38<01:30,  1.26s/it]Loading train:  75%|███████▌  | 214/285 [04:40<01:27,  1.24s/it]Loading train:  75%|███████▌  | 215/285 [04:41<01:30,  1.30s/it]Loading train:  76%|███████▌  | 216/285 [04:42<01:27,  1.27s/it]Loading train:  76%|███████▌  | 217/285 [04:44<01:29,  1.31s/it]Loading train:  76%|███████▋  | 218/285 [04:45<01:35,  1.42s/it]Loading train:  77%|███████▋  | 219/285 [04:47<01:41,  1.54s/it]Loading train:  77%|███████▋  | 220/285 [04:49<01:39,  1.54s/it]Loading train:  78%|███████▊  | 221/285 [04:50<01:32,  1.44s/it]Loading train:  78%|███████▊  | 222/285 [04:51<01:32,  1.46s/it]Loading train:  78%|███████▊  | 223/285 [04:53<01:27,  1.42s/it]Loading train:  79%|███████▊  | 224/285 [04:54<01:22,  1.35s/it]Loading train:  79%|███████▉  | 225/285 [04:55<01:15,  1.26s/it]Loading train:  79%|███████▉  | 226/285 [04:57<01:28,  1.50s/it]Loading train:  80%|███████▉  | 227/285 [04:59<01:29,  1.54s/it]Loading train:  80%|████████  | 228/285 [05:00<01:24,  1.48s/it]Loading train:  80%|████████  | 229/285 [05:01<01:21,  1.45s/it]Loading train:  81%|████████  | 230/285 [05:03<01:15,  1.37s/it]Loading train:  81%|████████  | 231/285 [05:04<01:09,  1.29s/it]Loading train:  81%|████████▏ | 232/285 [05:05<01:09,  1.30s/it]Loading train:  82%|████████▏ | 233/285 [05:06<01:05,  1.26s/it]Loading train:  82%|████████▏ | 234/285 [05:07<01:05,  1.29s/it]Loading train:  82%|████████▏ | 235/285 [05:09<01:09,  1.38s/it]Loading train:  83%|████████▎ | 236/285 [05:10<01:06,  1.36s/it]Loading train:  83%|████████▎ | 237/285 [05:12<01:07,  1.41s/it]Loading train:  84%|████████▎ | 238/285 [05:14<01:10,  1.49s/it]Loading train:  84%|████████▍ | 239/285 [05:15<01:05,  1.43s/it]Loading train:  84%|████████▍ | 240/285 [05:16<01:04,  1.43s/it]Loading train:  85%|████████▍ | 241/285 [05:17<00:58,  1.34s/it]Loading train:  85%|████████▍ | 242/285 [05:19<00:55,  1.30s/it]Loading train:  85%|████████▌ | 243/285 [05:20<00:54,  1.31s/it]Loading train:  86%|████████▌ | 244/285 [05:21<00:53,  1.31s/it]Loading train:  86%|████████▌ | 245/285 [05:23<00:52,  1.31s/it]Loading train:  86%|████████▋ | 246/285 [05:24<00:56,  1.45s/it]Loading train:  87%|████████▋ | 247/285 [05:26<00:55,  1.45s/it]Loading train:  87%|████████▋ | 248/285 [05:27<00:53,  1.46s/it]Loading train:  87%|████████▋ | 249/285 [05:29<00:53,  1.49s/it]Loading train:  88%|████████▊ | 250/285 [05:30<00:51,  1.48s/it]Loading train:  88%|████████▊ | 251/285 [05:32<00:48,  1.42s/it]Loading train:  88%|████████▊ | 252/285 [05:33<00:46,  1.41s/it]Loading train:  89%|████████▉ | 253/285 [05:34<00:45,  1.41s/it]Loading train:  89%|████████▉ | 254/285 [05:36<00:43,  1.41s/it]Loading train:  89%|████████▉ | 255/285 [05:37<00:40,  1.35s/it]Loading train:  90%|████████▉ | 256/285 [05:38<00:39,  1.36s/it]Loading train:  90%|█████████ | 257/285 [05:40<00:36,  1.31s/it]Loading train:  91%|█████████ | 258/285 [05:41<00:36,  1.36s/it]Loading train:  91%|█████████ | 259/285 [05:42<00:34,  1.33s/it]Loading train:  91%|█████████ | 260/285 [05:44<00:33,  1.34s/it]Loading train:  92%|█████████▏| 261/285 [05:45<00:30,  1.27s/it]Loading train:  92%|█████████▏| 262/285 [05:46<00:28,  1.25s/it]Loading train:  92%|█████████▏| 263/285 [05:47<00:27,  1.25s/it]Loading train:  93%|█████████▎| 264/285 [05:49<00:30,  1.47s/it]Loading train:  93%|█████████▎| 265/285 [05:51<00:28,  1.42s/it]Loading train:  93%|█████████▎| 266/285 [05:52<00:25,  1.34s/it]Loading train:  94%|█████████▎| 267/285 [05:53<00:23,  1.30s/it]Loading train:  94%|█████████▍| 268/285 [05:54<00:21,  1.29s/it]Loading train:  94%|█████████▍| 269/285 [05:55<00:20,  1.25s/it]Loading train:  95%|█████████▍| 270/285 [05:56<00:18,  1.23s/it]Loading train:  95%|█████████▌| 271/285 [05:58<00:16,  1.18s/it]Loading train:  95%|█████████▌| 272/285 [05:59<00:15,  1.18s/it]Loading train:  96%|█████████▌| 273/285 [06:00<00:14,  1.22s/it]Loading train:  96%|█████████▌| 274/285 [06:01<00:13,  1.25s/it]Loading train:  96%|█████████▋| 275/285 [06:03<00:13,  1.31s/it]Loading train:  97%|█████████▋| 276/285 [06:04<00:12,  1.34s/it]Loading train:  97%|█████████▋| 277/285 [06:05<00:10,  1.31s/it]Loading train:  98%|█████████▊| 278/285 [06:06<00:08,  1.21s/it]Loading train:  98%|█████████▊| 279/285 [06:08<00:08,  1.35s/it]Loading train:  98%|█████████▊| 280/285 [06:09<00:06,  1.33s/it]Loading train:  99%|█████████▊| 281/285 [06:10<00:05,  1.25s/it]Loading train:  99%|█████████▉| 282/285 [06:12<00:03,  1.25s/it]Loading train:  99%|█████████▉| 283/285 [06:13<00:02,  1.25s/it]Loading train: 100%|█████████▉| 284/285 [06:14<00:01,  1.27s/it]Loading train: 100%|██████████| 285/285 [06:16<00:00,  1.30s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:04, 60.47it/s]concatenating: train:   5%|▍         | 14/285 [00:00<00:04, 61.07it/s]concatenating: train:   7%|▋         | 20/285 [00:00<00:04, 60.02it/s]concatenating: train:   9%|▉         | 25/285 [00:00<00:04, 56.61it/s]concatenating: train:  11%|█         | 31/285 [00:00<00:04, 57.59it/s]concatenating: train:  13%|█▎        | 36/285 [00:00<00:04, 52.90it/s]concatenating: train:  15%|█▌        | 44/285 [00:00<00:04, 57.85it/s]concatenating: train:  18%|█▊        | 50/285 [00:00<00:04, 47.86it/s]concatenating: train:  22%|██▏       | 62/285 [00:01<00:03, 58.29it/s]concatenating: train:  32%|███▏      | 90/285 [00:01<00:02, 76.02it/s]concatenating: train:  41%|████▏     | 118/285 [00:01<00:01, 97.23it/s]concatenating: train:  48%|████▊     | 136/285 [00:01<00:01, 91.62it/s]concatenating: train:  53%|█████▎    | 151/285 [00:01<00:01, 73.28it/s]concatenating: train:  57%|█████▋    | 163/285 [00:02<00:01, 62.71it/s]concatenating: train:  61%|██████    | 173/285 [00:02<00:01, 57.07it/s]concatenating: train:  64%|██████▍   | 182/285 [00:02<00:01, 56.82it/s]concatenating: train:  67%|██████▋   | 190/285 [00:02<00:01, 56.44it/s]concatenating: train:  69%|██████▉   | 197/285 [00:02<00:01, 55.90it/s]concatenating: train:  72%|███████▏  | 204/285 [00:02<00:01, 57.16it/s]concatenating: train:  74%|███████▍  | 211/285 [00:02<00:01, 47.65it/s]concatenating: train:  81%|████████  | 230/285 [00:03<00:00, 61.45it/s]concatenating: train:  88%|████████▊ | 252/285 [00:03<00:00, 77.75it/s]concatenating: train:  93%|█████████▎| 265/285 [00:03<00:00, 64.28it/s]concatenating: train:  97%|█████████▋| 276/285 [00:03<00:00, 62.43it/s]concatenating: train: 100%|██████████| 285/285 [00:03<00:00, 59.01it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.71s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.62s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.55s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 63.46it/s]2019-07-08 23:36:03.839230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-08 23:36:03.839348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-08 23:36:03.839366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-08 23:36:03.839375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-08 23:36:03.839805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12743 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.75it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.68it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.52it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  7.09it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.15it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  6.95it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.12it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.88it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  7.23it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.23it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.70it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:02,  8.19it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  8.66it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  6.67it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.14it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.52it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  7.44it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:04<00:00,  6.26it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  5.36it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.29it/s] 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 10)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 11)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   2000        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 13)   793         dropout_6[0][0]                  
==================================================================================================
Total params: 225,773
Trainable params: 51,073
Non-trainable params: 174,700
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 29s - loss: 11982.3880 - acc: 0.7454 - mDice: 0.1696 - val_loss: 4261.4644 - val_acc: 0.9183 - val_mDice: 0.4110

Epoch 00001: val_mDice improved from -inf to 0.41103, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 20s - loss: 3689.5996 - acc: 0.9053 - mDice: 0.4850 - val_loss: 2480.9298 - val_acc: 0.9307 - val_mDice: 0.5769

Epoch 00002: val_mDice improved from 0.41103 to 0.57691, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 21s - loss: 2610.5596 - acc: 0.9226 - mDice: 0.5913 - val_loss: 2100.4077 - val_acc: 0.9501 - val_mDice: 0.6254

Epoch 00003: val_mDice improved from 0.57691 to 0.62541, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 20s - loss: 2293.8148 - acc: 0.9336 - mDice: 0.6295 - val_loss: 2117.6546 - val_acc: 0.9532 - val_mDice: 0.6222

Epoch 00004: val_mDice did not improve from 0.62541
Epoch 5/300
 - 20s - loss: 2125.0847 - acc: 0.9416 - mDice: 0.6503 - val_loss: 2139.3694 - val_acc: 0.9513 - val_mDice: 0.6199

Epoch 00005: val_mDice did not improve from 0.62541
Epoch 6/300
 - 19s - loss: 2016.2382 - acc: 0.9441 - mDice: 0.6647 - val_loss: 2253.4492 - val_acc: 0.9523 - val_mDice: 0.6047

Epoch 00006: val_mDice did not improve from 0.62541
Epoch 7/300
 - 21s - loss: 1935.2018 - acc: 0.9457 - mDice: 0.6754 - val_loss: 2185.9825 - val_acc: 0.9536 - val_mDice: 0.6145

Epoch 00007: val_mDice did not improve from 0.62541
Epoch 8/300
 - 21s - loss: 1863.5632 - acc: 0.9468 - mDice: 0.6849 - val_loss: 2198.4923 - val_acc: 0.9519 - val_mDice: 0.6119

Epoch 00008: val_mDice did not improve from 0.62541
Epoch 9/300
 - 20s - loss: 1818.3505 - acc: 0.9476 - mDice: 0.6912 - val_loss: 2146.1070 - val_acc: 0.9527 - val_mDice: 0.6205

Epoch 00009: val_mDice did not improve from 0.62541
Epoch 10/300
 - 21s - loss: 1770.0290 - acc: 0.9482 - mDice: 0.6978 - val_loss: 2096.6825 - val_acc: 0.9550 - val_mDice: 0.6261

Epoch 00010: val_mDice improved from 0.62541 to 0.62612, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 21s - loss: 1740.1222 - acc: 0.9489 - mDice: 0.7023 - val_loss: 2054.7466 - val_acc: 0.9551 - val_mDice: 0.6315

Epoch 00011: val_mDice improved from 0.62612 to 0.63153, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 20s - loss: 1702.2698 - acc: 0.9494 - mDice: 0.7074 - val_loss: 2058.5022 - val_acc: 0.9539 - val_mDice: 0.6307

Epoch 00012: val_mDice did not improve from 0.63153
Epoch 13/300
 - 20s - loss: 1677.8207 - acc: 0.9497 - mDice: 0.7109 - val_loss: 2151.5500 - val_acc: 0.9555 - val_mDice: 0.6202

Epoch 00013: val_mDice did not improve from 0.63153
Epoch 14/300
 - 21s - loss: 1645.4390 - acc: 0.9502 - mDice: 0.7154 - val_loss: 2135.4140 - val_acc: 0.9557 - val_mDice: 0.6226

Epoch 00014: val_mDice did not improve from 0.63153
Epoch 15/300
 - 20s - loss: 1620.9259 - acc: 0.9506 - mDice: 0.7190 - val_loss: 2095.8397 - val_acc: 0.9541 - val_mDice: 0.6254

Epoch 00015: val_mDice did not improve from 0.63153
Epoch 16/300
 - 20s - loss: 1598.9113 - acc: 0.9509 - mDice: 0.7219 - val_loss: 2197.5935 - val_acc: 0.9544 - val_mDice: 0.6139

Epoch 00016: val_mDice did not improve from 0.63153
Epoch 17/300
 - 20s - loss: 1569.1908 - acc: 0.9514 - mDice: 0.7264 - val_loss: 2174.2002 - val_acc: 0.9528 - val_mDice: 0.6147

Epoch 00017: val_mDice did not improve from 0.63153
Epoch 18/300
 - 20s - loss: 1559.9319 - acc: 0.9515 - mDice: 0.7278 - val_loss: 2152.9483 - val_acc: 0.9555 - val_mDice: 0.6198

Epoch 00018: val_mDice did not improve from 0.63153
Epoch 19/300
 - 21s - loss: 1536.1472 - acc: 0.9517 - mDice: 0.7313 - val_loss: 2090.6241 - val_acc: 0.9549 - val_mDice: 0.6287

Epoch 00019: val_mDice did not improve from 0.63153
Epoch 20/300
 - 20s - loss: 1528.1379 - acc: 0.9520 - mDice: 0.7326 - val_loss: 2170.1526 - val_acc: 0.9544 - val_mDice: 0.6165

Epoch 00020: val_mDice did not improve from 0.63153
Epoch 21/300
 - 20s - loss: 1500.2913 - acc: 0.9523 - mDice: 0.7365 - val_loss: 2217.9771 - val_acc: 0.9538 - val_mDice: 0.6109

Epoch 00021: val_mDice did not improve from 0.63153
Epoch 22/300
 - 20s - loss: 1489.7584 - acc: 0.9525 - mDice: 0.7380 - val_loss: 2241.6024 - val_acc: 0.9540 - val_mDice: 0.6078

Epoch 00022: val_mDice did not improve from 0.63153
Epoch 23/300
 - 21s - loss: 1476.3265 - acc: 0.9526 - mDice: 0.7401 - val_loss: 2301.5535 - val_acc: 0.9555 - val_mDice: 0.6026

Epoch 00023: val_mDice did not improve from 0.63153
Epoch 24/300
 - 20s - loss: 1466.4995 - acc: 0.9528 - mDice: 0.7416 - val_loss: 2160.1582 - val_acc: 0.9555 - val_mDice: 0.6196

Epoch 00024: val_mDice did not improve from 0.63153
Epoch 25/300
 - 20s - loss: 1462.5800 - acc: 0.9528 - mDice: 0.7422 - val_loss: 2262.1720 - val_acc: 0.9548 - val_mDice: 0.6059

Epoch 00025: val_mDice did not improve from 0.63153
Epoch 26/300
 - 21s - loss: 1444.0910 - acc: 0.9531 - mDice: 0.7449 - val_loss: 2204.4266 - val_acc: 0.9548 - val_mDice: 0.6131

Epoch 00026: val_mDice did not improve from 0.63153
Epoch 27/300
 - 21s - loss: 1426.0847 - acc: 0.9533 - mDice: 0.7475 - val_loss: 2226.8975 - val_acc: 0.9555 - val_mDice: 0.6099

Epoch 00027: val_mDice did not improve from 0.63153
Epoch 28/300
 - 21s - loss: 1426.3055 - acc: 0.9533 - mDice: 0.7476 - val_loss: 2155.5260 - val_acc: 0.9557 - val_mDice: 0.6185

Epoch 00028: val_mDice did not improve from 0.63153
Epoch 29/300
 - 21s - loss: 1405.1801 - acc: 0.9536 - mDice: 0.7507 - val_loss: 2203.4951 - val_acc: 0.9540 - val_mDice: 0.6126

Epoch 00029: val_mDice did not improve from 0.63153
Epoch 30/300
 - 20s - loss: 1403.3384 - acc: 0.9535 - mDice: 0.7510 - val_loss: 2093.2014 - val_acc: 0.9559 - val_mDice: 0.6264

Epoch 00030: val_mDice did not improve from 0.63153
Epoch 31/300
 - 21s - loss: 1397.4826 - acc: 0.9537 - mDice: 0.7519 - val_loss: 2232.3666 - val_acc: 0.9546 - val_mDice: 0.6085

Epoch 00031: val_mDice did not improve from 0.63153
Epoch 32/300
 - 21s - loss: 1392.4238 - acc: 0.9538 - mDice: 0.7527 - val_loss: 2290.9753 - val_acc: 0.9560 - val_mDice: 0.6048

Epoch 00032: val_mDice did not improve from 0.63153
Epoch 33/300
 - 21s - loss: 1374.4758 - acc: 0.9540 - mDice: 0.7554 - val_loss: 2253.1158 - val_acc: 0.9549 - val_mDice: 0.6057

Epoch 00033: val_mDice did not improve from 0.63153
Epoch 34/300
 - 21s - loss: 1375.6387 - acc: 0.9540 - mDice: 0.7553 - val_loss: 2210.4943 - val_acc: 0.9532 - val_mDice: 0.6124

Epoch 00034: val_mDice did not improve from 0.63153
Epoch 35/300
 - 21s - loss: 1369.6673 - acc: 0.9541 - mDice: 0.7562 - val_loss: 2175.1100 - val_acc: 0.9558 - val_mDice: 0.6173

Epoch 00035: val_mDice did not improve from 0.63153
Epoch 36/300
 - 21s - loss: 1358.5119 - acc: 0.9542 - mDice: 0.7578 - val_loss: 2235.3958 - val_acc: 0.9549 - val_mDice: 0.6100

Epoch 00036: val_mDice did not improve from 0.63153
Epoch 37/300
 - 21s - loss: 1358.3606 - acc: 0.9543 - mDice: 0.7579 - val_loss: 2216.1482 - val_acc: 0.9552 - val_mDice: 0.6110

Epoch 00037: val_mDice did not improve from 0.63153
Epoch 38/300
 - 21s - loss: 1354.8504 - acc: 0.9545 - mDice: 0.7585 - val_loss: 2235.6630 - val_acc: 0.9553 - val_mDice: 0.6111

Epoch 00038: val_mDice did not improve from 0.63153
Epoch 39/300
 - 21s - loss: 1348.6724 - acc: 0.9545 - mDice: 0.7594 - val_loss: 2268.0444 - val_acc: 0.9554 - val_mDice: 0.6065

Epoch 00039: val_mDice did not improve from 0.63153
Epoch 40/300
 - 21s - loss: 1346.8524 - acc: 0.9546 - mDice: 0.7598 - val_loss: 2162.7994 - val_acc: 0.9557 - val_mDice: 0.6186

Epoch 00040: val_mDice did not improve from 0.63153
Epoch 41/300
 - 21s - loss: 1333.8670 - acc: 0.9546 - mDice: 0.7616 - val_loss: 2297.6340 - val_acc: 0.9555 - val_mDice: 0.6066

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.58s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.32s/it]predicting test subjects: 100%|██████████| 3/3 [00:06<00:00,  2.16s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:02<09:40,  2.05s/it]predicting train subjects:   1%|          | 2/285 [00:03<09:04,  1.93s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:52,  1.89s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<08:33,  1.83s/it]predicting train subjects:   2%|▏         | 5/285 [00:09<09:08,  1.96s/it]predicting train subjects:   2%|▏         | 6/285 [00:11<08:49,  1.90s/it]predicting train subjects:   2%|▏         | 7/285 [00:13<09:01,  1.95s/it]predicting train subjects:   3%|▎         | 8/285 [00:15<08:51,  1.92s/it]predicting train subjects:   3%|▎         | 9/285 [00:17<09:39,  2.10s/it]predicting train subjects:   4%|▎         | 10/285 [00:19<09:50,  2.15s/it]predicting train subjects:   4%|▍         | 11/285 [00:21<09:31,  2.08s/it]predicting train subjects:   4%|▍         | 12/285 [00:24<09:55,  2.18s/it]predicting train subjects:   5%|▍         | 13/285 [00:26<09:25,  2.08s/it]predicting train subjects:   5%|▍         | 14/285 [00:28<09:22,  2.08s/it]predicting train subjects:   5%|▌         | 15/285 [00:30<09:29,  2.11s/it]predicting train subjects:   6%|▌         | 16/285 [00:32<09:48,  2.19s/it]predicting train subjects:   6%|▌         | 17/285 [00:34<09:15,  2.07s/it]predicting train subjects:   6%|▋         | 18/285 [00:36<09:24,  2.12s/it]predicting train subjects:   7%|▋         | 19/285 [00:38<09:10,  2.07s/it]predicting train subjects:   7%|▋         | 20/285 [00:40<09:17,  2.10s/it]predicting train subjects:   7%|▋         | 21/285 [00:43<09:36,  2.18s/it]predicting train subjects:   8%|▊         | 22/285 [00:45<09:07,  2.08s/it]predicting train subjects:   8%|▊         | 23/285 [00:47<09:15,  2.12s/it]predicting train subjects:   8%|▊         | 24/285 [00:49<08:53,  2.04s/it]predicting train subjects:   9%|▉         | 25/285 [00:51<09:18,  2.15s/it]predicting train subjects:   9%|▉         | 26/285 [00:53<09:38,  2.23s/it]predicting train subjects:   9%|▉         | 27/285 [00:55<08:55,  2.07s/it]predicting train subjects:  10%|▉         | 28/285 [00:57<08:39,  2.02s/it]predicting train subjects:  10%|█         | 29/285 [00:59<08:44,  2.05s/it]predicting train subjects:  11%|█         | 30/285 [01:01<08:44,  2.06s/it]predicting train subjects:  11%|█         | 31/285 [01:04<09:08,  2.16s/it]predicting train subjects:  11%|█         | 32/285 [01:06<08:45,  2.08s/it]predicting train subjects:  12%|█▏        | 33/285 [01:08<08:41,  2.07s/it]predicting train subjects:  12%|█▏        | 34/285 [01:10<08:27,  2.02s/it]predicting train subjects:  12%|█▏        | 35/285 [01:12<08:36,  2.07s/it]predicting train subjects:  13%|█▎        | 36/285 [01:13<08:07,  1.96s/it]predicting train subjects:  13%|█▎        | 37/285 [01:15<08:12,  1.99s/it]predicting train subjects:  13%|█▎        | 38/285 [01:18<08:23,  2.04s/it]predicting train subjects:  14%|█▎        | 39/285 [01:19<07:54,  1.93s/it]predicting train subjects:  14%|█▍        | 40/285 [01:21<07:52,  1.93s/it]predicting train subjects:  14%|█▍        | 41/285 [01:23<07:39,  1.88s/it]predicting train subjects:  15%|█▍        | 42/285 [01:25<07:31,  1.86s/it]predicting train subjects:  15%|█▌        | 43/285 [01:27<07:34,  1.88s/it]predicting train subjects:  15%|█▌        | 44/285 [01:29<07:48,  1.94s/it]predicting train subjects:  16%|█▌        | 45/285 [01:30<07:26,  1.86s/it]predicting train subjects:  16%|█▌        | 46/285 [01:33<07:48,  1.96s/it]predicting train subjects:  16%|█▋        | 47/285 [01:34<07:28,  1.89s/it]predicting train subjects:  17%|█▋        | 48/285 [01:36<07:22,  1.87s/it]predicting train subjects:  17%|█▋        | 49/285 [01:38<07:33,  1.92s/it]predicting train subjects:  18%|█▊        | 50/285 [01:40<07:37,  1.95s/it]predicting train subjects:  18%|█▊        | 51/285 [01:42<07:49,  2.01s/it]predicting train subjects:  18%|█▊        | 52/285 [01:44<07:26,  1.91s/it]predicting train subjects:  19%|█▊        | 53/285 [01:46<07:22,  1.91s/it]predicting train subjects:  19%|█▉        | 54/285 [01:48<07:41,  2.00s/it]predicting train subjects:  19%|█▉        | 55/285 [01:50<07:19,  1.91s/it]predicting train subjects:  20%|█▉        | 56/285 [01:52<07:14,  1.90s/it]predicting train subjects:  20%|██        | 57/285 [01:54<07:00,  1.84s/it]predicting train subjects:  20%|██        | 58/285 [01:55<07:05,  1.88s/it]predicting train subjects:  21%|██        | 59/285 [01:58<07:27,  1.98s/it]predicting train subjects:  21%|██        | 60/285 [02:00<07:44,  2.06s/it]predicting train subjects:  21%|██▏       | 61/285 [02:02<07:20,  1.97s/it]predicting train subjects:  22%|██▏       | 62/285 [02:04<07:22,  1.99s/it]predicting train subjects:  22%|██▏       | 63/285 [02:06<07:17,  1.97s/it]predicting train subjects:  22%|██▏       | 64/285 [02:07<07:04,  1.92s/it]predicting train subjects:  23%|██▎       | 65/285 [02:09<07:05,  1.93s/it]predicting train subjects:  23%|██▎       | 66/285 [02:12<07:14,  1.98s/it]predicting train subjects:  24%|██▎       | 67/285 [02:13<07:11,  1.98s/it]predicting train subjects:  24%|██▍       | 68/285 [02:15<06:57,  1.92s/it]predicting train subjects:  24%|██▍       | 69/285 [02:17<06:49,  1.90s/it]predicting train subjects:  25%|██▍       | 70/285 [02:19<06:46,  1.89s/it]predicting train subjects:  25%|██▍       | 71/285 [02:21<06:42,  1.88s/it]predicting train subjects:  25%|██▌       | 72/285 [02:23<06:36,  1.86s/it]predicting train subjects:  26%|██▌       | 73/285 [02:25<06:37,  1.88s/it]predicting train subjects:  26%|██▌       | 74/285 [02:27<06:41,  1.90s/it]predicting train subjects:  26%|██▋       | 75/285 [02:29<06:44,  1.93s/it]predicting train subjects:  27%|██▋       | 76/285 [02:30<06:40,  1.91s/it]predicting train subjects:  27%|██▋       | 77/285 [02:32<06:29,  1.87s/it]predicting train subjects:  27%|██▋       | 78/285 [02:34<06:20,  1.84s/it]predicting train subjects:  28%|██▊       | 79/285 [02:36<06:19,  1.84s/it]predicting train subjects:  28%|██▊       | 80/285 [02:38<06:19,  1.85s/it]predicting train subjects:  28%|██▊       | 81/285 [02:39<06:13,  1.83s/it]predicting train subjects:  29%|██▉       | 82/285 [02:41<06:17,  1.86s/it]predicting train subjects:  29%|██▉       | 83/285 [02:43<06:11,  1.84s/it]predicting train subjects:  29%|██▉       | 84/285 [02:45<06:04,  1.81s/it]predicting train subjects:  30%|██▉       | 85/285 [02:47<06:07,  1.84s/it]predicting train subjects:  30%|███       | 86/285 [02:49<06:12,  1.87s/it]predicting train subjects:  31%|███       | 87/285 [02:51<06:13,  1.89s/it]predicting train subjects:  31%|███       | 88/285 [02:53<06:07,  1.86s/it]predicting train subjects:  31%|███       | 89/285 [02:54<06:04,  1.86s/it]predicting train subjects:  32%|███▏      | 90/285 [02:56<06:02,  1.86s/it]predicting train subjects:  32%|███▏      | 91/285 [02:58<05:55,  1.83s/it]predicting train subjects:  32%|███▏      | 92/285 [03:00<06:19,  1.97s/it]predicting train subjects:  33%|███▎      | 93/285 [03:02<06:05,  1.90s/it]predicting train subjects:  33%|███▎      | 94/285 [03:04<06:00,  1.89s/it]predicting train subjects:  33%|███▎      | 95/285 [03:06<06:08,  1.94s/it]predicting train subjects:  34%|███▎      | 96/285 [03:08<06:04,  1.93s/it]predicting train subjects:  34%|███▍      | 97/285 [03:10<06:01,  1.92s/it]predicting train subjects:  34%|███▍      | 98/285 [03:12<06:00,  1.93s/it]predicting train subjects:  35%|███▍      | 99/285 [03:14<05:56,  1.92s/it]predicting train subjects:  35%|███▌      | 100/285 [03:16<05:57,  1.93s/it]predicting train subjects:  35%|███▌      | 101/285 [03:17<05:45,  1.88s/it]predicting train subjects:  36%|███▌      | 102/285 [03:19<05:47,  1.90s/it]predicting train subjects:  36%|███▌      | 103/285 [03:21<05:38,  1.86s/it]predicting train subjects:  36%|███▋      | 104/285 [03:23<05:40,  1.88s/it]predicting train subjects:  37%|███▋      | 105/285 [03:25<05:41,  1.90s/it]predicting train subjects:  37%|███▋      | 106/285 [03:27<05:34,  1.87s/it]predicting train subjects:  38%|███▊      | 107/285 [03:29<05:38,  1.90s/it]predicting train subjects:  38%|███▊      | 108/285 [03:31<05:33,  1.89s/it]predicting train subjects:  38%|███▊      | 109/285 [03:33<05:37,  1.92s/it]predicting train subjects:  39%|███▊      | 110/285 [03:35<05:41,  1.95s/it]predicting train subjects:  39%|███▉      | 111/285 [03:36<05:28,  1.89s/it]predicting train subjects:  39%|███▉      | 112/285 [03:38<05:31,  1.91s/it]predicting train subjects:  40%|███▉      | 113/285 [03:40<05:31,  1.93s/it]predicting train subjects:  40%|████      | 114/285 [03:42<05:33,  1.95s/it]predicting train subjects:  40%|████      | 115/285 [03:44<05:31,  1.95s/it]predicting train subjects:  41%|████      | 116/285 [03:46<05:35,  1.99s/it]predicting train subjects:  41%|████      | 117/285 [03:48<05:25,  1.94s/it]predicting train subjects:  41%|████▏     | 118/285 [03:50<05:15,  1.89s/it]predicting train subjects:  42%|████▏     | 119/285 [03:52<05:19,  1.92s/it]predicting train subjects:  42%|████▏     | 120/285 [03:54<05:10,  1.88s/it]predicting train subjects:  42%|████▏     | 121/285 [03:55<04:57,  1.81s/it]predicting train subjects:  43%|████▎     | 122/285 [03:57<04:47,  1.76s/it]predicting train subjects:  43%|████▎     | 123/285 [03:59<04:38,  1.72s/it]predicting train subjects:  44%|████▎     | 124/285 [04:00<04:39,  1.74s/it]predicting train subjects:  44%|████▍     | 125/285 [04:02<04:30,  1.69s/it]predicting train subjects:  44%|████▍     | 126/285 [04:04<04:24,  1.67s/it]predicting train subjects:  45%|████▍     | 127/285 [04:05<04:17,  1.63s/it]predicting train subjects:  45%|████▍     | 128/285 [04:07<04:24,  1.68s/it]predicting train subjects:  45%|████▌     | 129/285 [04:08<04:19,  1.66s/it]predicting train subjects:  46%|████▌     | 130/285 [04:10<04:18,  1.67s/it]predicting train subjects:  46%|████▌     | 131/285 [04:12<04:16,  1.67s/it]predicting train subjects:  46%|████▋     | 132/285 [04:14<04:18,  1.69s/it]predicting train subjects:  47%|████▋     | 133/285 [04:15<04:13,  1.67s/it]predicting train subjects:  47%|████▋     | 134/285 [04:17<04:05,  1.62s/it]predicting train subjects:  47%|████▋     | 135/285 [04:18<03:59,  1.59s/it]predicting train subjects:  48%|████▊     | 136/285 [04:20<03:55,  1.58s/it]predicting train subjects:  48%|████▊     | 137/285 [04:22<04:00,  1.63s/it]predicting train subjects:  48%|████▊     | 138/285 [04:23<03:54,  1.60s/it]predicting train subjects:  49%|████▉     | 139/285 [04:25<03:59,  1.64s/it]predicting train subjects:  49%|████▉     | 140/285 [04:27<04:01,  1.67s/it]predicting train subjects:  49%|████▉     | 141/285 [04:28<03:52,  1.61s/it]predicting train subjects:  50%|████▉     | 142/285 [04:30<03:51,  1.62s/it]predicting train subjects:  50%|█████     | 143/285 [04:31<03:46,  1.60s/it]predicting train subjects:  51%|█████     | 144/285 [04:33<03:51,  1.64s/it]predicting train subjects:  51%|█████     | 145/285 [04:35<03:50,  1.65s/it]predicting train subjects:  51%|█████     | 146/285 [04:36<03:53,  1.68s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:38<03:47,  1.65s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:40<03:49,  1.68s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:41<03:44,  1.65s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:43<03:39,  1.62s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:44<03:39,  1.64s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:46<03:37,  1.63s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:48<03:34,  1.62s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:49<03:36,  1.65s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:51<03:31,  1.62s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:53<03:31,  1.64s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:54<03:25,  1.60s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:56<03:23,  1.60s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:57<03:19,  1.58s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:59<03:18,  1.59s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:01<03:21,  1.62s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:02<03:16,  1.59s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:04<03:19,  1.63s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:06<03:18,  1.64s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:07<03:17,  1.65s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:09<03:16,  1.66s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:11<03:16,  1.67s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:12<03:10,  1.63s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:14<03:08,  1.62s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:15<03:03,  1.60s/it]predicting train subjects:  60%|██████    | 171/285 [05:17<03:02,  1.60s/it]predicting train subjects:  60%|██████    | 172/285 [05:18<02:59,  1.58s/it]predicting train subjects:  61%|██████    | 173/285 [05:20<02:55,  1.57s/it]predicting train subjects:  61%|██████    | 174/285 [05:21<02:52,  1.55s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:23<02:57,  1.62s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:25<02:59,  1.64s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:26<02:53,  1.61s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:28<02:50,  1.60s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:30<02:47,  1.58s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:31<02:56,  1.68s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:33<03:02,  1.75s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:35<03:04,  1.79s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:37<02:55,  1.72s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:38<02:49,  1.68s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:40<02:41,  1.62s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:42<02:50,  1.72s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:44<02:59,  1.83s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:46<03:00,  1.86s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:47<02:50,  1.77s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:49<02:42,  1.71s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:51<02:44,  1.75s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:53<02:43,  1.76s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:54<02:34,  1.68s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:56<02:29,  1.64s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:57<02:24,  1.60s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:59<02:33,  1.73s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:01<02:37,  1.79s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:03<02:39,  1.83s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:05<02:30,  1.75s/it]predicting train subjects:  70%|███████   | 200/285 [06:06<02:25,  1.71s/it]predicting train subjects:  71%|███████   | 201/285 [06:08<02:30,  1.79s/it]predicting train subjects:  71%|███████   | 202/285 [06:10<02:29,  1.80s/it]predicting train subjects:  71%|███████   | 203/285 [06:12<02:26,  1.79s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:13<02:18,  1.71s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:15<02:12,  1.66s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:16<02:08,  1.62s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:18<02:13,  1.71s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:20<02:18,  1.80s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:22<02:18,  1.83s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:24<02:09,  1.73s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:25<02:03,  1.67s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:27<02:04,  1.70s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:29<02:05,  1.75s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:30<01:59,  1.69s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:32<02:03,  1.77s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:34<01:57,  1.70s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:36<02:02,  1.80s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:38<02:06,  1.88s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:40<02:04,  1.89s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:41<01:55,  1.77s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:43<01:49,  1.71s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:45<01:49,  1.74s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:46<01:43,  1.68s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:48<01:40,  1.64s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:49<01:36,  1.61s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:51<01:41,  1.71s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:53<01:43,  1.79s/it]predicting train subjects:  80%|████████  | 228/285 [06:55<01:44,  1.83s/it]predicting train subjects:  80%|████████  | 229/285 [06:57<01:41,  1.81s/it]predicting train subjects:  81%|████████  | 230/285 [06:59<01:34,  1.72s/it]predicting train subjects:  81%|████████  | 231/285 [07:00<01:30,  1.67s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:02<01:30,  1.72s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:04<01:27,  1.68s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:05<01:29,  1.75s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:07<01:23,  1.68s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:09<01:27,  1.79s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:11<01:28,  1.85s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:13<01:29,  1.90s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:15<01:26,  1.87s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:16<01:18,  1.75s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:18<01:15,  1.71s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:19<01:10,  1.65s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:21<01:08,  1.62s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:23<01:09,  1.71s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:24<01:05,  1.64s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:26<01:07,  1.72s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:28<01:07,  1.77s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:30<01:06,  1.79s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:32<01:02,  1.73s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:33<00:59,  1.69s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:35<00:55,  1.64s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:36<00:52,  1.60s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:38<00:55,  1.72s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:40<00:55,  1.78s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:42<00:53,  1.78s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:43<00:49,  1.70s/it]predicting train subjects:  90%|█████████ | 257/285 [07:45<00:45,  1.64s/it]predicting train subjects:  91%|█████████ | 258/285 [07:47<00:45,  1.70s/it]predicting train subjects:  91%|█████████ | 259/285 [07:48<00:44,  1.71s/it]predicting train subjects:  91%|█████████ | 260/285 [07:50<00:41,  1.67s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:52<00:39,  1.63s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:53<00:37,  1.61s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:55<00:35,  1.59s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:57<00:35,  1.69s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:59<00:35,  1.76s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:00<00:31,  1.68s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:02<00:29,  1.65s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:04<00:29,  1.74s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:05<00:28,  1.76s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:07<00:25,  1.67s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:08<00:23,  1.65s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:10<00:21,  1.69s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:12<00:19,  1.62s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:13<00:17,  1.59s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:15<00:17,  1.75s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:17<00:16,  1.82s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:19<00:13,  1.71s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:20<00:11,  1.65s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:22<00:10,  1.69s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:24<00:08,  1.64s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:25<00:06,  1.62s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:27<00:04,  1.61s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:29<00:03,  1.74s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:31<00:01,  1.80s/it]predicting train subjects: 100%|██████████| 285/285 [08:33<00:00,  1.82s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:04,  1.71s/it]Loading train:   1%|          | 2/285 [00:02<07:21,  1.56s/it]Loading train:   1%|          | 3/285 [00:04<06:59,  1.49s/it]Loading train:   1%|▏         | 4/285 [00:05<06:27,  1.38s/it]Loading train:   2%|▏         | 5/285 [00:06<06:39,  1.43s/it]Loading train:   2%|▏         | 6/285 [00:08<06:11,  1.33s/it]Loading train:   2%|▏         | 7/285 [00:09<06:23,  1.38s/it]Loading train:   3%|▎         | 8/285 [00:10<06:14,  1.35s/it]Loading train:   3%|▎         | 9/285 [00:12<06:39,  1.45s/it]Loading train:   4%|▎         | 10/285 [00:13<06:14,  1.36s/it]Loading train:   4%|▍         | 11/285 [00:14<05:24,  1.18s/it]Loading train:   4%|▍         | 12/285 [00:15<05:18,  1.17s/it]Loading train:   5%|▍         | 13/285 [00:16<04:52,  1.08s/it]Loading train:   5%|▍         | 14/285 [00:17<04:51,  1.08s/it]Loading train:   5%|▌         | 15/285 [00:18<04:52,  1.08s/it]Loading train:   6%|▌         | 16/285 [00:19<04:40,  1.04s/it]Loading train:   6%|▌         | 17/285 [00:20<04:35,  1.03s/it]Loading train:   6%|▋         | 18/285 [00:21<04:18,  1.03it/s]Loading train:   7%|▋         | 19/285 [00:22<04:08,  1.07it/s]Loading train:   7%|▋         | 20/285 [00:23<04:11,  1.05it/s]Loading train:   7%|▋         | 21/285 [00:24<04:19,  1.02it/s]Loading train:   8%|▊         | 22/285 [00:25<04:10,  1.05it/s]Loading train:   8%|▊         | 23/285 [00:26<04:21,  1.00it/s]Loading train:   8%|▊         | 24/285 [00:27<04:15,  1.02it/s]Loading train:   9%|▉         | 25/285 [00:28<04:14,  1.02it/s]Loading train:   9%|▉         | 26/285 [00:29<04:24,  1.02s/it]Loading train:   9%|▉         | 27/285 [00:30<04:13,  1.02it/s]Loading train:  10%|▉         | 28/285 [00:31<04:21,  1.02s/it]Loading train:  10%|█         | 29/285 [00:32<04:08,  1.03it/s]Loading train:  11%|█         | 30/285 [00:33<04:14,  1.00it/s]Loading train:  11%|█         | 31/285 [00:34<04:08,  1.02it/s]Loading train:  11%|█         | 32/285 [00:34<03:58,  1.06it/s]Loading train:  12%|█▏        | 33/285 [00:35<04:05,  1.03it/s]Loading train:  12%|█▏        | 34/285 [00:36<04:00,  1.04it/s]Loading train:  12%|█▏        | 35/285 [00:38<04:11,  1.00s/it]Loading train:  13%|█▎        | 36/285 [00:38<03:50,  1.08it/s]Loading train:  13%|█▎        | 37/285 [00:39<03:51,  1.07it/s]Loading train:  13%|█▎        | 38/285 [00:40<03:51,  1.07it/s]Loading train:  14%|█▎        | 39/285 [00:41<03:56,  1.04it/s]Loading train:  14%|█▍        | 40/285 [00:42<03:55,  1.04it/s]Loading train:  14%|█▍        | 41/285 [00:43<04:03,  1.00it/s]Loading train:  15%|█▍        | 42/285 [00:44<03:55,  1.03it/s]Loading train:  15%|█▌        | 43/285 [00:45<03:54,  1.03it/s]Loading train:  15%|█▌        | 44/285 [00:46<04:10,  1.04s/it]Loading train:  16%|█▌        | 45/285 [00:47<03:53,  1.03it/s]Loading train:  16%|█▌        | 46/285 [00:48<04:11,  1.05s/it]Loading train:  16%|█▋        | 47/285 [00:49<04:02,  1.02s/it]Loading train:  17%|█▋        | 48/285 [00:50<04:04,  1.03s/it]Loading train:  17%|█▋        | 49/285 [00:52<04:11,  1.06s/it]Loading train:  18%|█▊        | 50/285 [00:53<04:08,  1.06s/it]Loading train:  18%|█▊        | 51/285 [00:54<04:16,  1.09s/it]Loading train:  18%|█▊        | 52/285 [00:55<04:09,  1.07s/it]Loading train:  19%|█▊        | 53/285 [00:56<03:56,  1.02s/it]Loading train:  19%|█▉        | 54/285 [00:57<03:55,  1.02s/it]Loading train:  19%|█▉        | 55/285 [00:58<03:45,  1.02it/s]Loading train:  20%|█▉        | 56/285 [00:59<03:45,  1.02it/s]Loading train:  20%|██        | 57/285 [00:59<03:31,  1.08it/s]Loading train:  20%|██        | 58/285 [01:00<03:27,  1.09it/s]Loading train:  21%|██        | 59/285 [01:01<03:29,  1.08it/s]Loading train:  21%|██        | 60/285 [01:02<03:47,  1.01s/it]Loading train:  21%|██▏       | 61/285 [01:03<03:32,  1.05it/s]Loading train:  22%|██▏       | 62/285 [01:04<03:32,  1.05it/s]Loading train:  22%|██▏       | 63/285 [01:05<03:29,  1.06it/s]Loading train:  22%|██▏       | 64/285 [01:06<03:50,  1.04s/it]Loading train:  23%|██▎       | 65/285 [01:08<04:19,  1.18s/it]Loading train:  23%|██▎       | 66/285 [01:09<04:37,  1.27s/it]Loading train:  24%|██▎       | 67/285 [01:10<04:20,  1.19s/it]Loading train:  24%|██▍       | 68/285 [01:11<03:55,  1.08s/it]Loading train:  24%|██▍       | 69/285 [01:12<03:45,  1.04s/it]Loading train:  25%|██▍       | 70/285 [01:13<03:34,  1.00it/s]Loading train:  25%|██▍       | 71/285 [01:14<03:28,  1.03it/s]Loading train:  25%|██▌       | 72/285 [01:15<03:15,  1.09it/s]Loading train:  26%|██▌       | 73/285 [01:16<03:12,  1.10it/s]Loading train:  26%|██▌       | 74/285 [01:17<03:13,  1.09it/s]Loading train:  26%|██▋       | 75/285 [01:17<03:15,  1.08it/s]Loading train:  27%|██▋       | 76/285 [01:18<03:12,  1.08it/s]Loading train:  27%|██▋       | 77/285 [01:19<03:02,  1.14it/s]Loading train:  27%|██▋       | 78/285 [01:20<02:57,  1.16it/s]Loading train:  28%|██▊       | 79/285 [01:21<03:11,  1.08it/s]Loading train:  28%|██▊       | 80/285 [01:22<03:14,  1.05it/s]Loading train:  28%|██▊       | 81/285 [01:23<03:12,  1.06it/s]Loading train:  29%|██▉       | 82/285 [01:24<03:08,  1.08it/s]Loading train:  29%|██▉       | 83/285 [01:25<03:05,  1.09it/s]Loading train:  29%|██▉       | 84/285 [01:26<02:53,  1.16it/s]Loading train:  30%|██▉       | 85/285 [01:27<03:09,  1.05it/s]Loading train:  30%|███       | 86/285 [01:28<03:13,  1.03it/s]Loading train:  31%|███       | 87/285 [01:29<03:05,  1.07it/s]Loading train:  31%|███       | 88/285 [01:29<02:59,  1.10it/s]Loading train:  31%|███       | 89/285 [01:30<03:05,  1.05it/s]Loading train:  32%|███▏      | 90/285 [01:32<03:15,  1.00s/it]Loading train:  32%|███▏      | 91/285 [01:32<02:58,  1.08it/s]Loading train:  32%|███▏      | 92/285 [01:33<03:06,  1.04it/s]Loading train:  33%|███▎      | 93/285 [01:34<02:57,  1.08it/s]Loading train:  33%|███▎      | 94/285 [01:35<03:07,  1.02it/s]Loading train:  33%|███▎      | 95/285 [01:36<03:03,  1.04it/s]Loading train:  34%|███▎      | 96/285 [01:37<03:09,  1.00s/it]Loading train:  34%|███▍      | 97/285 [01:38<03:04,  1.02it/s]Loading train:  34%|███▍      | 98/285 [01:39<02:58,  1.04it/s]Loading train:  35%|███▍      | 99/285 [01:40<03:13,  1.04s/it]Loading train:  35%|███▌      | 100/285 [01:41<03:07,  1.01s/it]Loading train:  35%|███▌      | 101/285 [01:42<02:58,  1.03it/s]Loading train:  36%|███▌      | 102/285 [01:43<02:56,  1.04it/s]Loading train:  36%|███▌      | 103/285 [01:44<02:52,  1.05it/s]Loading train:  36%|███▋      | 104/285 [01:45<02:52,  1.05it/s]Loading train:  37%|███▋      | 105/285 [01:46<02:52,  1.04it/s]Loading train:  37%|███▋      | 106/285 [01:47<02:39,  1.12it/s]Loading train:  38%|███▊      | 107/285 [01:48<02:39,  1.11it/s]Loading train:  38%|███▊      | 108/285 [01:49<02:37,  1.12it/s]Loading train:  38%|███▊      | 109/285 [01:50<02:48,  1.05it/s]Loading train:  39%|███▊      | 110/285 [01:51<02:44,  1.06it/s]Loading train:  39%|███▉      | 111/285 [01:52<02:48,  1.03it/s]Loading train:  39%|███▉      | 112/285 [01:53<02:50,  1.01it/s]Loading train:  40%|███▉      | 113/285 [01:54<02:50,  1.01it/s]Loading train:  40%|████      | 114/285 [01:55<02:49,  1.01it/s]Loading train:  40%|████      | 115/285 [01:56<02:51,  1.01s/it]Loading train:  41%|████      | 116/285 [01:57<02:46,  1.02it/s]Loading train:  41%|████      | 117/285 [01:58<02:42,  1.03it/s]Loading train:  41%|████▏     | 118/285 [01:58<02:35,  1.08it/s]Loading train:  42%|████▏     | 119/285 [01:59<02:36,  1.06it/s]Loading train:  42%|████▏     | 120/285 [02:00<02:27,  1.12it/s]Loading train:  42%|████▏     | 121/285 [02:01<02:48,  1.03s/it]Loading train:  43%|████▎     | 122/285 [02:03<02:56,  1.08s/it]Loading train:  43%|████▎     | 123/285 [02:04<02:58,  1.10s/it]Loading train:  44%|████▎     | 124/285 [02:05<02:59,  1.11s/it]Loading train:  44%|████▍     | 125/285 [02:06<02:49,  1.06s/it]Loading train:  44%|████▍     | 126/285 [02:07<02:40,  1.01s/it]Loading train:  45%|████▍     | 127/285 [02:08<02:30,  1.05it/s]Loading train:  45%|████▍     | 128/285 [02:09<02:29,  1.05it/s]Loading train:  45%|████▌     | 129/285 [02:09<02:20,  1.11it/s]Loading train:  46%|████▌     | 130/285 [02:10<02:19,  1.11it/s]Loading train:  46%|████▌     | 131/285 [02:11<02:15,  1.14it/s]Loading train:  46%|████▋     | 132/285 [02:12<02:17,  1.11it/s]Loading train:  47%|████▋     | 133/285 [02:13<02:14,  1.13it/s]Loading train:  47%|████▋     | 134/285 [02:14<02:11,  1.15it/s]Loading train:  47%|████▋     | 135/285 [02:15<02:13,  1.12it/s]Loading train:  48%|████▊     | 136/285 [02:15<02:04,  1.19it/s]Loading train:  48%|████▊     | 137/285 [02:16<02:12,  1.12it/s]Loading train:  48%|████▊     | 138/285 [02:17<02:10,  1.12it/s]Loading train:  49%|████▉     | 139/285 [02:18<02:05,  1.16it/s]Loading train:  49%|████▉     | 140/285 [02:19<02:00,  1.20it/s]Loading train:  49%|████▉     | 141/285 [02:20<01:56,  1.24it/s]Loading train:  50%|████▉     | 142/285 [02:21<02:03,  1.16it/s]Loading train:  50%|█████     | 143/285 [02:21<02:01,  1.17it/s]Loading train:  51%|█████     | 144/285 [02:22<01:57,  1.20it/s]Loading train:  51%|█████     | 145/285 [02:23<01:55,  1.22it/s]Loading train:  51%|█████     | 146/285 [02:24<01:58,  1.17it/s]Loading train:  52%|█████▏    | 147/285 [02:25<01:53,  1.21it/s]Loading train:  52%|█████▏    | 148/285 [02:25<01:53,  1.21it/s]Loading train:  52%|█████▏    | 149/285 [02:26<01:50,  1.23it/s]Loading train:  53%|█████▎    | 150/285 [02:27<01:47,  1.25it/s]Loading train:  53%|█████▎    | 151/285 [02:28<01:46,  1.25it/s]Loading train:  53%|█████▎    | 152/285 [02:29<01:48,  1.23it/s]Loading train:  54%|█████▎    | 153/285 [02:29<01:43,  1.27it/s]Loading train:  54%|█████▍    | 154/285 [02:30<01:50,  1.19it/s]Loading train:  54%|█████▍    | 155/285 [02:31<01:50,  1.18it/s]Loading train:  55%|█████▍    | 156/285 [02:32<01:48,  1.19it/s]Loading train:  55%|█████▌    | 157/285 [02:33<01:46,  1.21it/s]Loading train:  55%|█████▌    | 158/285 [02:34<01:43,  1.23it/s]Loading train:  56%|█████▌    | 159/285 [02:34<01:40,  1.26it/s]Loading train:  56%|█████▌    | 160/285 [02:35<01:39,  1.26it/s]Loading train:  56%|█████▋    | 161/285 [02:36<01:42,  1.22it/s]Loading train:  57%|█████▋    | 162/285 [02:37<01:48,  1.14it/s]Loading train:  57%|█████▋    | 163/285 [02:38<01:53,  1.07it/s]Loading train:  58%|█████▊    | 164/285 [02:39<01:49,  1.11it/s]Loading train:  58%|█████▊    | 165/285 [02:40<01:44,  1.14it/s]Loading train:  58%|█████▊    | 166/285 [02:41<01:43,  1.15it/s]Loading train:  59%|█████▊    | 167/285 [02:42<01:45,  1.11it/s]Loading train:  59%|█████▉    | 168/285 [02:42<01:40,  1.17it/s]Loading train:  59%|█████▉    | 169/285 [02:43<01:42,  1.13it/s]Loading train:  60%|█████▉    | 170/285 [02:44<01:35,  1.20it/s]Loading train:  60%|██████    | 171/285 [02:45<01:38,  1.16it/s]Loading train:  60%|██████    | 172/285 [02:46<01:32,  1.22it/s]Loading train:  61%|██████    | 173/285 [02:47<01:35,  1.17it/s]Loading train:  61%|██████    | 174/285 [02:47<01:30,  1.22it/s]Loading train:  61%|██████▏   | 175/285 [02:48<01:35,  1.16it/s]Loading train:  62%|██████▏   | 176/285 [02:49<01:33,  1.16it/s]Loading train:  62%|██████▏   | 177/285 [02:50<01:31,  1.18it/s]Loading train:  62%|██████▏   | 178/285 [02:51<01:28,  1.21it/s]Loading train:  63%|██████▎   | 179/285 [02:52<01:27,  1.22it/s]Loading train:  63%|██████▎   | 180/285 [02:53<01:32,  1.13it/s]Loading train:  64%|██████▎   | 181/285 [02:54<01:33,  1.11it/s]Loading train:  64%|██████▍   | 182/285 [02:54<01:28,  1.16it/s]Loading train:  64%|██████▍   | 183/285 [02:55<01:27,  1.17it/s]Loading train:  65%|██████▍   | 184/285 [02:57<01:42,  1.02s/it]Loading train:  65%|██████▍   | 185/285 [02:58<01:45,  1.05s/it]Loading train:  65%|██████▌   | 186/285 [02:59<01:51,  1.12s/it]Loading train:  66%|██████▌   | 187/285 [03:00<01:53,  1.16s/it]Loading train:  66%|██████▌   | 188/285 [03:02<01:56,  1.20s/it]Loading train:  66%|██████▋   | 189/285 [03:03<01:51,  1.17s/it]Loading train:  67%|██████▋   | 190/285 [03:04<01:44,  1.10s/it]Loading train:  67%|██████▋   | 191/285 [03:05<01:49,  1.16s/it]Loading train:  67%|██████▋   | 192/285 [03:06<01:48,  1.17s/it]Loading train:  68%|██████▊   | 193/285 [03:07<01:38,  1.07s/it]Loading train:  68%|██████▊   | 194/285 [03:08<01:45,  1.16s/it]Loading train:  68%|██████▊   | 195/285 [03:09<01:40,  1.12s/it]Loading train:  69%|██████▉   | 196/285 [03:11<01:44,  1.18s/it]Loading train:  69%|██████▉   | 197/285 [03:12<01:53,  1.29s/it]Loading train:  69%|██████▉   | 198/285 [03:13<01:53,  1.30s/it]Loading train:  70%|██████▉   | 199/285 [03:14<01:45,  1.22s/it]Loading train:  70%|███████   | 200/285 [03:16<01:44,  1.23s/it]Loading train:  71%|███████   | 201/285 [03:17<01:48,  1.29s/it]Loading train:  71%|███████   | 202/285 [03:19<01:50,  1.33s/it]Loading train:  71%|███████   | 203/285 [03:20<01:47,  1.32s/it]Loading train:  72%|███████▏  | 204/285 [03:21<01:38,  1.22s/it]Loading train:  72%|███████▏  | 205/285 [03:22<01:39,  1.24s/it]Loading train:  72%|███████▏  | 206/285 [03:23<01:33,  1.18s/it]Loading train:  73%|███████▎  | 207/285 [03:24<01:31,  1.18s/it]Loading train:  73%|███████▎  | 208/285 [03:26<01:30,  1.17s/it]Loading train:  73%|███████▎  | 209/285 [03:27<01:37,  1.28s/it]Loading train:  74%|███████▎  | 210/285 [03:28<01:27,  1.16s/it]Loading train:  74%|███████▍  | 211/285 [03:29<01:22,  1.12s/it]Loading train:  74%|███████▍  | 212/285 [03:30<01:23,  1.15s/it]Loading train:  75%|███████▍  | 213/285 [03:31<01:22,  1.15s/it]Loading train:  75%|███████▌  | 214/285 [03:32<01:18,  1.11s/it]Loading train:  75%|███████▌  | 215/285 [03:34<01:20,  1.15s/it]Loading train:  76%|███████▌  | 216/285 [03:35<01:19,  1.16s/it]Loading train:  76%|███████▌  | 217/285 [03:36<01:22,  1.21s/it]Loading train:  76%|███████▋  | 218/285 [03:38<01:25,  1.28s/it]Loading train:  77%|███████▋  | 219/285 [03:39<01:26,  1.31s/it]Loading train:  77%|███████▋  | 220/285 [03:40<01:22,  1.26s/it]Loading train:  78%|███████▊  | 221/285 [03:41<01:15,  1.17s/it]Loading train:  78%|███████▊  | 222/285 [03:43<01:21,  1.29s/it]Loading train:  78%|███████▊  | 223/285 [03:44<01:16,  1.24s/it]Loading train:  79%|███████▊  | 224/285 [03:45<01:14,  1.22s/it]Loading train:  79%|███████▉  | 225/285 [03:46<01:15,  1.25s/it]Loading train:  79%|███████▉  | 226/285 [03:48<01:15,  1.28s/it]Loading train:  80%|███████▉  | 227/285 [03:49<01:14,  1.29s/it]Loading train:  80%|████████  | 228/285 [03:50<01:15,  1.32s/it]Loading train:  80%|████████  | 229/285 [03:52<01:12,  1.30s/it]Loading train:  81%|████████  | 230/285 [03:53<01:10,  1.28s/it]Loading train:  81%|████████  | 231/285 [03:54<01:05,  1.21s/it]Loading train:  81%|████████▏ | 232/285 [03:55<01:05,  1.23s/it]Loading train:  82%|████████▏ | 233/285 [03:56<01:01,  1.18s/it]Loading train:  82%|████████▏ | 234/285 [03:57<01:01,  1.21s/it]Loading train:  82%|████████▏ | 235/285 [03:59<01:01,  1.23s/it]Loading train:  83%|████████▎ | 236/285 [04:00<01:01,  1.26s/it]Loading train:  83%|████████▎ | 237/285 [04:01<01:01,  1.28s/it]Loading train:  84%|████████▎ | 238/285 [04:03<01:00,  1.28s/it]Loading train:  84%|████████▍ | 239/285 [04:04<00:58,  1.26s/it]Loading train:  84%|████████▍ | 240/285 [04:05<00:56,  1.24s/it]Loading train:  85%|████████▍ | 241/285 [04:06<00:55,  1.25s/it]Loading train:  85%|████████▍ | 242/285 [04:07<00:52,  1.22s/it]Loading train:  85%|████████▌ | 243/285 [04:09<00:50,  1.21s/it]Loading train:  86%|████████▌ | 244/285 [04:10<00:51,  1.26s/it]Loading train:  86%|████████▌ | 245/285 [04:11<00:47,  1.19s/it]Loading train:  86%|████████▋ | 246/285 [04:13<00:48,  1.26s/it]Loading train:  87%|████████▋ | 247/285 [04:14<00:50,  1.32s/it]Loading train:  87%|████████▋ | 248/285 [04:15<00:48,  1.30s/it]Loading train:  87%|████████▋ | 249/285 [04:16<00:42,  1.18s/it]Loading train:  88%|████████▊ | 250/285 [04:17<00:40,  1.15s/it]Loading train:  88%|████████▊ | 251/285 [04:18<00:37,  1.11s/it]Loading train:  88%|████████▊ | 252/285 [04:19<00:36,  1.10s/it]Loading train:  89%|████████▉ | 253/285 [04:21<00:37,  1.17s/it]Loading train:  89%|████████▉ | 254/285 [04:22<00:37,  1.20s/it]Loading train:  89%|████████▉ | 255/285 [04:23<00:36,  1.21s/it]Loading train:  90%|████████▉ | 256/285 [04:24<00:34,  1.19s/it]Loading train:  90%|█████████ | 257/285 [04:26<00:34,  1.22s/it]Loading train:  91%|█████████ | 258/285 [04:27<00:33,  1.24s/it]Loading train:  91%|█████████ | 259/285 [04:28<00:31,  1.19s/it]Loading train:  91%|█████████ | 260/285 [04:29<00:29,  1.19s/it]Loading train:  92%|█████████▏| 261/285 [04:31<00:30,  1.25s/it]Loading train:  92%|█████████▏| 262/285 [04:31<00:26,  1.16s/it]Loading train:  92%|█████████▏| 263/285 [04:33<00:25,  1.15s/it]Loading train:  93%|█████████▎| 264/285 [04:34<00:24,  1.18s/it]Loading train:  93%|█████████▎| 265/285 [04:35<00:24,  1.24s/it]Loading train:  93%|█████████▎| 266/285 [04:37<00:24,  1.29s/it]Loading train:  94%|█████████▎| 267/285 [04:38<00:21,  1.20s/it]Loading train:  94%|█████████▍| 268/285 [04:39<00:20,  1.23s/it]Loading train:  94%|█████████▍| 269/285 [04:40<00:18,  1.18s/it]Loading train:  95%|█████████▍| 270/285 [04:41<00:17,  1.14s/it]Loading train:  95%|█████████▌| 271/285 [04:42<00:16,  1.17s/it]Loading train:  95%|█████████▌| 272/285 [04:44<00:15,  1.19s/it]Loading train:  96%|█████████▌| 273/285 [04:45<00:13,  1.16s/it]Loading train:  96%|█████████▌| 274/285 [04:46<00:12,  1.11s/it]Loading train:  96%|█████████▋| 275/285 [04:47<00:10,  1.09s/it]Loading train:  97%|█████████▋| 276/285 [04:48<00:10,  1.12s/it]Loading train:  97%|█████████▋| 277/285 [04:49<00:09,  1.14s/it]Loading train:  98%|█████████▊| 278/285 [04:50<00:07,  1.11s/it]Loading train:  98%|█████████▊| 279/285 [04:51<00:06,  1.14s/it]Loading train:  98%|█████████▊| 280/285 [04:52<00:05,  1.13s/it]Loading train:  99%|█████████▊| 281/285 [04:54<00:04,  1.18s/it]Loading train:  99%|█████████▉| 282/285 [04:55<00:03,  1.20s/it]Loading train:  99%|█████████▉| 283/285 [04:56<00:02,  1.26s/it]Loading train: 100%|█████████▉| 284/285 [04:58<00:01,  1.29s/it]Loading train: 100%|██████████| 285/285 [04:59<00:00,  1.31s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/285 [00:00<00:04, 58.57it/s]concatenating: train:   4%|▍         | 11/285 [00:00<00:04, 55.27it/s]concatenating: train:   5%|▍         | 14/285 [00:00<00:06, 43.80it/s]concatenating: train:   7%|▋         | 21/285 [00:00<00:05, 49.30it/s]concatenating: train:  12%|█▏        | 33/285 [00:00<00:04, 59.52it/s]concatenating: train:  15%|█▌        | 43/285 [00:00<00:03, 66.67it/s]concatenating: train:  18%|█▊        | 51/285 [00:00<00:03, 59.58it/s]concatenating: train:  22%|██▏       | 62/285 [00:00<00:03, 68.51it/s]concatenating: train:  25%|██▌       | 72/285 [00:00<00:02, 74.98it/s]concatenating: train:  30%|██▉       | 85/285 [00:01<00:02, 85.20it/s]concatenating: train:  33%|███▎      | 95/285 [00:01<00:02, 89.16it/s]concatenating: train:  42%|████▏     | 120/285 [00:01<00:01, 109.90it/s]concatenating: train:  52%|█████▏    | 148/285 [00:01<00:01, 132.87it/s]concatenating: train:  58%|█████▊    | 166/285 [00:01<00:00, 125.99it/s]concatenating: train:  64%|██████▍   | 182/285 [00:01<00:00, 133.43it/s]concatenating: train:  69%|██████▉   | 198/285 [00:01<00:00, 121.13it/s]concatenating: train:  74%|███████▍  | 212/285 [00:01<00:00, 115.04it/s]concatenating: train:  79%|███████▉  | 225/285 [00:02<00:00, 96.79it/s] concatenating: train:  83%|████████▎ | 237/285 [00:02<00:00, 100.80it/s]concatenating: train:  87%|████████▋ | 249/285 [00:02<00:00, 103.57it/s]concatenating: train:  92%|█████████▏| 262/285 [00:02<00:00, 109.20it/s]concatenating: train:  96%|█████████▌| 274/285 [00:02<00:00, 108.56it/s]concatenating: train: 100%|██████████| 285/285 [00:02<00:00, 106.08it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.50s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.56s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.54s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 49.53it/s]2019-07-09 00:04:39.682136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-09 00:04:39.682260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-09 00:04:39.682278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-09 00:04:39.682287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-09 00:04:39.682692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12743 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.63it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.50it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.30it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.75it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.68it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.49it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.73it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.44it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  7.98it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.67it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.35it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  8.71it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  8.27it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  6.77it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.14it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.55it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  8.63it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:04<00:00,  6.28it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  5.39it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.50it/s]
Epoch 00041: val_mDice did not improve from 0.63153
Restoring model weights from the end of the best epoch
Epoch 00041: early stopping
{'val_loss': [4261.464395022259, 2480.9297611513616, 2100.407650739787, 2117.6546392174405, 2139.369358851257, 2253.449157373865, 2185.9825268963864, 2198.4922870657297, 2146.10703997905, 2096.6825108022, 2054.7465861229925, 2058.5021795347416, 2151.549984724162, 2135.4140284021473, 2095.839741456442, 2197.5935222263442, 2174.2002130433834, 2152.9482612822976, 2090.6241189114876, 2170.1526451750174, 2217.9770671482192, 2241.6023917597763, 2301.5534627051325, 2160.15823313111, 2262.17195137919, 2204.42660505412, 2226.8974691209846, 2155.5259893832927, 2203.495077633991, 2093.2014432939072, 2232.366643298272, 2290.975276328998, 2253.1157540262743, 2210.4942661050977, 2175.1099710304643, 2235.395753317039, 2216.148223365485, 2235.6629659130585, 2268.0444499607192, 2162.799366871072, 2297.634023655726], 'val_acc': [0.9182588880954508, 0.9307192364218515, 0.9501090775654969, 0.9532040057901564, 0.9512826004507822, 0.9523445540966269, 0.9535841881895865, 0.9519499600266611, 0.9526689312311524, 0.9549704746827067, 0.9550655241119129, 0.9539127000217331, 0.9555138632571897, 0.9557266541699457, 0.9540820954232242, 0.9544271174089869, 0.952788746889743, 0.9554890707218447, 0.9549415521115564, 0.954369270601752, 0.9538424328052798, 0.9539850057836351, 0.9554560044624286, 0.9555014628271817, 0.9547928218734997, 0.9548423912938081, 0.9554828575203539, 0.9557411327708367, 0.954009769016138, 0.9558692098329853, 0.954617204279873, 0.9559911053273931, 0.9549002337722139, 0.9531647636237757, 0.9557597210953356, 0.9549271197958366, 0.9552060305739248, 0.9552866060640559, 0.9553527289262697, 0.9556522988740292, 0.9555262720118688], 'val_mDice': [0.4110308552587498, 0.5769128296628344, 0.6254100296750414, 0.6221662486731673, 0.6199180507127133, 0.604674302665881, 0.6145228920036188, 0.6118673931952961, 0.6204602138956166, 0.6261241762331744, 0.6315341665092127, 0.6307194505989885, 0.6202114743893373, 0.6226125988880349, 0.6254176953651386, 0.6138717006038688, 0.6147120791440569, 0.6198307502203148, 0.628696935136891, 0.6165032729756232, 0.6109467002266612, 0.6078490125400394, 0.6025749834556153, 0.6196209648467975, 0.6059034406805838, 0.6131464432737681, 0.6098869462918969, 0.6184820203141793, 0.6125914943950802, 0.626385171986159, 0.6085441974954232, 0.6047898500991267, 0.605672473015066, 0.6124192386366135, 0.6173409663099151, 0.6100314672432798, 0.6109506344662032, 0.6111160869704945, 0.6064845729806569, 0.6185651674616937, 0.6066224601681672], 'loss': [11982.387987906282, 3689.5995742052405, 2610.559567240963, 2293.8148446063074, 2125.0846603789964, 2016.2381720841304, 1935.201771928272, 1863.5632059082643, 1818.3505186163309, 1770.0289912238618, 1740.1221678337886, 1702.269798812754, 1677.8206861737078, 1645.4390043016938, 1620.9259229395866, 1598.9112521303966, 1569.190809943072, 1559.9318836420543, 1536.1472298076915, 1528.1378885533748, 1500.2912792785255, 1489.7583973485007, 1476.3265282530313, 1466.4994548919979, 1462.5799986705963, 1444.0909718250205, 1426.0847031943556, 1426.3055174797294, 1405.1800964199233, 1403.338364319775, 1397.482592405119, 1392.423750000266, 1374.4757802820006, 1375.6386789621388, 1369.6673241328533, 1358.5118815281455, 1358.3605575682025, 1354.850448679037, 1348.6723931522763, 1346.8524480366473, 1333.8669719672152], 'acc': [0.7453810555516398, 0.9053181123775073, 0.9226473786298385, 0.9335600558296475, 0.9415650236912396, 0.9441472371220166, 0.9457203858779488, 0.9467770638474192, 0.9476264009067458, 0.948228739703976, 0.9488515834534105, 0.9494277982240175, 0.9497006976664842, 0.950189618199916, 0.9506150739111546, 0.950865877907583, 0.9513566718921638, 0.9514955887834229, 0.9517163223777745, 0.9520192757345455, 0.9523268211615721, 0.952455725261351, 0.9526335972858199, 0.952760610703283, 0.9528182789810757, 0.9530594928300586, 0.9533047614147717, 0.9533360596835682, 0.9535587637566396, 0.9535388083643893, 0.9536852167229346, 0.9537786762118762, 0.9540247869487681, 0.9540146559348625, 0.9540986273291454, 0.9542113193323731, 0.9543223607014886, 0.954472738357354, 0.9544851078160493, 0.9545501244690779, 0.9546236800937103], 'mDice': [0.16964305040083819, 0.4850134454542993, 0.5913049724001905, 0.6294568043720955, 0.6502930045835554, 0.6646559805491152, 0.6753770949942998, 0.6848545115171035, 0.6912384828083215, 0.6977670449822578, 0.7022718430656174, 0.7074155320295886, 0.7108893119381843, 0.7153638250739102, 0.7189749575772776, 0.7219308659594197, 0.7264477311769515, 0.7278382458410766, 0.7312627065208351, 0.7326395849173679, 0.7365042590658673, 0.7380244538360844, 0.7401152920809961, 0.7415677445671487, 0.7421733854798787, 0.7449446923137653, 0.747519226373784, 0.7475655903049326, 0.7506753201123956, 0.7509727544088807, 0.7519000130316238, 0.7526765248950911, 0.7553787370320466, 0.7552573717170912, 0.7561746360390711, 0.7578107680502323, 0.757877097398093, 0.7584681659279536, 0.7593638076903507, 0.7597771561500923, 0.7615766524879003]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 10)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 11)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 15)   1500        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 15)   2040        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 15)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 40, 26, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 30)   4080        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 30)   8130        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 45)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 60)   24360       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 60)   32460       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 105)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 30)   12630       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 30)   8130        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 105)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 40, 26, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 15)   6315        dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 15)   2040        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 45)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 80, 52, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 13)   598         dropout_6[0][0]                  
==================================================================================================
Total params: 127,968
Trainable params: 29,488
Non-trainable params: 98,480
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 23s - loss: 24283.4480 - acc: 0.5528 - mDice: 0.0810 - val_loss: 16794.4158 - val_acc: 0.9053 - val_mDice: 0.1637

Epoch 00001: val_mDice improved from -inf to 0.16368, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 13s - loss: 10359.3144 - acc: 0.8821 - mDice: 0.2775 - val_loss: 8238.6620 - val_acc: 0.9016 - val_mDice: 0.3369

Epoch 00002: val_mDice improved from 0.16368 to 0.33690, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 14s - loss: 7348.7832 - acc: 0.8892 - mDice: 0.3897 - val_loss: 6144.6538 - val_acc: 0.9043 - val_mDice: 0.4340

Epoch 00003: val_mDice improved from 0.33690 to 0.43401, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 13s - loss: 6099.3668 - acc: 0.8902 - mDice: 0.4547 - val_loss: 5884.0365 - val_acc: 0.9101 - val_mDice: 0.4488

Epoch 00004: val_mDice improved from 0.43401 to 0.44879, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 14s - loss: 5300.6129 - acc: 0.8920 - mDice: 0.5018 - val_loss: 4695.5125 - val_acc: 0.9139 - val_mDice: 0.5198

Epoch 00005: val_mDice improved from 0.44879 to 0.51982, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 13s - loss: 4819.6516 - acc: 0.8936 - mDice: 0.5329 - val_loss: 4883.6227 - val_acc: 0.9145 - val_mDice: 0.5052

Epoch 00006: val_mDice did not improve from 0.51982
Epoch 7/300
 - 14s - loss: 4492.6090 - acc: 0.8952 - mDice: 0.5553 - val_loss: 4247.5527 - val_acc: 0.9179 - val_mDice: 0.5503

Epoch 00007: val_mDice improved from 0.51982 to 0.55028, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 14s - loss: 4307.7046 - acc: 0.8965 - mDice: 0.5685 - val_loss: 4250.3138 - val_acc: 0.9178 - val_mDice: 0.5499

Epoch 00008: val_mDice did not improve from 0.55028
Epoch 9/300
 - 14s - loss: 4120.8117 - acc: 0.8981 - mDice: 0.5820 - val_loss: 4210.8162 - val_acc: 0.9195 - val_mDice: 0.5533

Epoch 00009: val_mDice improved from 0.55028 to 0.55331, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 14s - loss: 3976.0820 - acc: 0.8997 - mDice: 0.5930 - val_loss: 4319.7682 - val_acc: 0.9188 - val_mDice: 0.5463

Epoch 00010: val_mDice did not improve from 0.55331
Epoch 11/300
 - 13s - loss: 3924.6056 - acc: 0.9012 - mDice: 0.5973 - val_loss: 4285.1624 - val_acc: 0.9187 - val_mDice: 0.5487

Epoch 00011: val_mDice did not improve from 0.55331
Epoch 12/300
 - 14s - loss: 3804.6163 - acc: 0.9034 - mDice: 0.6063 - val_loss: 4121.7326 - val_acc: 0.9206 - val_mDice: 0.5608

Epoch 00012: val_mDice improved from 0.55331 to 0.56081, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 14s - loss: 3740.8148 - acc: 0.9057 - mDice: 0.6114 - val_loss: 4104.5686 - val_acc: 0.9227 - val_mDice: 0.5634

Epoch 00013: val_mDice improved from 0.56081 to 0.56340, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 13s - loss: 3660.2240 - acc: 0.9074 - mDice: 0.6177 - val_loss: 4072.8815 - val_acc: 0.9254 - val_mDice: 0.5650

Epoch 00014: val_mDice improved from 0.56340 to 0.56496, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 14s - loss: 3610.3077 - acc: 0.9101 - mDice: 0.6217 - val_loss: 4073.8622 - val_acc: 0.9301 - val_mDice: 0.5663

Epoch 00015: val_mDice improved from 0.56496 to 0.56631, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 14s - loss: 3539.9096 - acc: 0.9131 - mDice: 0.6275 - val_loss: 4113.0310 - val_acc: 0.9364 - val_mDice: 0.5600

Epoch 00016: val_mDice did not improve from 0.56631
Epoch 17/300
 - 13s - loss: 3521.1674 - acc: 0.9158 - mDice: 0.6290 - val_loss: 4206.2920 - val_acc: 0.9371 - val_mDice: 0.5540

Epoch 00017: val_mDice did not improve from 0.56631
Epoch 18/300
 - 14s - loss: 3462.6894 - acc: 0.9199 - mDice: 0.6336 - val_loss: 4085.8715 - val_acc: 0.9411 - val_mDice: 0.5630

Epoch 00018: val_mDice did not improve from 0.56631
Epoch 19/300
 - 14s - loss: 3412.4156 - acc: 0.9245 - mDice: 0.6377 - val_loss: 4000.5719 - val_acc: 0.9428 - val_mDice: 0.5705

Epoch 00019: val_mDice improved from 0.56631 to 0.57054, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 20/300
 - 13s - loss: 3371.4959 - acc: 0.9275 - mDice: 0.6408 - val_loss: 4110.8556 - val_acc: 0.9422 - val_mDice: 0.5629

Epoch 00020: val_mDice did not improve from 0.57054
Epoch 21/300
 - 13s - loss: 3363.1702 - acc: 0.9292 - mDice: 0.6414 - val_loss: 4057.6087 - val_acc: 0.9424 - val_mDice: 0.5672

Epoch 00021: val_mDice did not improve from 0.57054
Epoch 22/300
 - 13s - loss: 3336.3019 - acc: 0.9301 - mDice: 0.6435 - val_loss: 4439.9831 - val_acc: 0.9330 - val_mDice: 0.5382

Epoch 00022: val_mDice did not improve from 0.57054
Epoch 23/300
 - 14s - loss: 3289.0533 - acc: 0.9310 - mDice: 0.6475 - val_loss: 4096.2362 - val_acc: 0.9398 - val_mDice: 0.5617

Epoch 00023: val_mDice did not improve from 0.57054
Epoch 24/300
 - 14s - loss: 3264.5115 - acc: 0.9316 - mDice: 0.6496 - val_loss: 4862.3825 - val_acc: 0.9297 - val_mDice: 0.5107

Epoch 00024: val_mDice did not improve from 0.57054
Epoch 25/300
 - 13s - loss: 3227.5256 - acc: 0.9325 - mDice: 0.6526 - val_loss: 4008.0162 - val_acc: 0.9407 - val_mDice: 0.5674

Epoch 00025: val_mDice did not improve from 0.57054
Epoch 26/300
 - 13s - loss: 3200.9792 - acc: 0.9333 - mDice: 0.6547 - val_loss: 4229.4242 - val_acc: 0.9391 - val_mDice: 0.5524

Epoch 00026: val_mDice did not improve from 0.57054
Epoch 27/300
 - 14s - loss: 3185.9448 - acc: 0.9336 - mDice: 0.6559 - val_loss: 4057.5576 - val_acc: 0.9426 - val_mDice: 0.5671

Epoch 00027: val_mDice did not improve from 0.57054
Epoch 28/300
 - 14s - loss: 3145.6736 - acc: 0.9341 - mDice: 0.6594 - val_loss: 4170.0276 - val_acc: 0.9408 - val_mDice: 0.5565

Epoch 00028: val_mDice did not improve from 0.57054
Epoch 29/300
 - 13s - loss: 3138.7910 - acc: 0.9345 - mDice: 0.6600 - val_loss: 3943.4972 - val_acc: 0.9432 - val_mDice: 0.5740

Epoch 00029: val_mDice improved from 0.57054 to 0.57398, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 30/300
 - 14s - loss: 3108.9025 - acc: 0.9350 - mDice: 0.6626 - val_loss: 4069.3231 - val_acc: 0.9431 - val_mDice: 0.5643

Epoch 00030: val_mDice did not improve from 0.57398
Epoch 31/300
 - 13s - loss: 3100.5637 - acc: 0.9352 - mDice: 0.6633 - val_loss: 3936.2317 - val_acc: 0.9424 - val_mDice: 0.5758

Epoch 00031: val_mDice improved from 0.57398 to 0.57578, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 32/300
 - 13s - loss: 3088.9134 - acc: 0.9355 - mDice: 0.6643 - val_loss: 4013.1885 - val_acc: 0.9408 - val_mDice: 0.5693

Epoch 00032: val_mDice did not improve from 0.57578
Epoch 33/300
 - 14s - loss: 3059.3348 - acc: 0.9357 - mDice: 0.6668 - val_loss: 4064.4004 - val_acc: 0.9427 - val_mDice: 0.5665

Epoch 00033: val_mDice did not improve from 0.57578
Epoch 34/300
 - 14s - loss: 3058.4840 - acc: 0.9359 - mDice: 0.6669 - val_loss: 3987.4456 - val_acc: 0.9423 - val_mDice: 0.5712

Epoch 00034: val_mDice did not improve from 0.57578
Epoch 35/300
 - 14s - loss: 3034.2488 - acc: 0.9363 - mDice: 0.6690 - val_loss: 4023.9951 - val_acc: 0.9411 - val_mDice: 0.5690

Epoch 00035: val_mDice did not improve from 0.57578
Epoch 36/300
 - 13s - loss: 3018.9671 - acc: 0.9364 - mDice: 0.6703 - val_loss: 4182.3891 - val_acc: 0.9393 - val_mDice: 0.5573

Epoch 00036: val_mDice did not improve from 0.57578
Epoch 37/300
 - 14s - loss: 3016.6161 - acc: 0.9363 - mDice: 0.6705 - val_loss: 4071.3279 - val_acc: 0.9409 - val_mDice: 0.5650

Epoch 00037: val_mDice did not improve from 0.57578
Epoch 38/300
 - 14s - loss: 2993.7207 - acc: 0.9366 - mDice: 0.6725 - val_loss: 4246.7551 - val_acc: 0.9411 - val_mDice: 0.5525

Epoch 00038: val_mDice did not improve from 0.57578
Epoch 39/300
 - 13s - loss: 2986.6081 - acc: 0.9367 - mDice: 0.6731 - val_loss: 4356.7089 - val_acc: 0.9429 - val_mDice: 0.5459

Epoch 00039: val_mDice did not improve from 0.57578
Epoch 40/300
 - 14s - loss: 2962.1676 - acc: 0.9370 - mDice: 0.6753 - val_loss: 4256.3457 - val_acc: 0.9382 - val_mDice: 0.5493

Epoch 00040: val_mDice did not improve from 0.57578
Epoch 41/300
 - 13s - loss: 2956.0278 - acc: 0.9372 - mDice: 0.6759 - val_loss: 4476.5206 - val_acc: 0.9380 - val_mDice: 0.5349

Epoch 00041: val_mDice did not improve from 0.57578
Epoch 42/300
 - 14s - loss: 2934.1056 - acc: 0.9373 - mDice: 0.6778 - val_loss: 4098.4064 - val_acc: 0.9425 - val_mDice: 0.5616

Epoch 00042: val_mDice did not improve from 0.57578
Epoch 43/300
 - 13s - loss: 2876.3727 - acc: 0.9374 - mDice: 0.6831 - val_loss: 4084.2082 - val_acc: 0.9410 - val_mDice: 0.5631

Epoch 00043: val_mDice did not improve from 0.57578
Epoch 44/300
 - 13s - loss: 2852.8354 - acc: 0.9378 - mDice: 0.6856 - val_loss: 4228.9937 - val_acc: 0.9408 - val_mDice: 0.5513

Epoch 00044: val_mDice did not improve from 0.57578
Epoch 45/300
 - 14s - loss: 2850.3557 - acc: 0.9379 - mDice: 0.6858 - val_loss: 4394.8327 - val_acc: 0.9431 - val_mDice: 0.5434

Epoch 00045: val_mDice did not improve from 0.57578
Epoch 46/300
 - 14s - loss: 2825.9628 - acc: 0.9384 - mDice: 0.6878 - val_loss: 4261.9569 - val_acc: 0.9434 - val_mDice: 0.5541

Epoch 00046: val_mDice did not improve from 0.57578
Epoch 47/300
 - 14s - loss: 2807.8450 - acc: 0.9386 - mDice: 0.6894 - val_loss: 4233.6172 - val_acc: 0.9396 - val_mDice: 0.5521

Epoch 00047: val_mDice did not improve from 0.57578
Epoch 48/300
 - 14s - loss: 2811.7224 - acc: 0.9386 - mDice: 0.6892 - val_loss: 4131.8464 - val_acc: 0.9408 - val_mDice: 0.5606

Epoch 00048: val_mDice did not improve from 0.57578
Epoch 49/300
 - 14s - loss: 2805.0717 - acc: 0.9388 - mDice: 0.6899 - val_loss: 4083.0910 - val_acc: 0.9406 - val_mDice: 0.5631

Epoch 00049: val_mDice did not improve from 0.57578
Epoch 50/300
 - 14s - loss: 2791.3499 - acc: 0.9390 - mDice: 0.6909 - val_loss: 4152.0521 - val_acc: 0.9408 - val_mDice: 0.5579

Epoch 00050: val_mDice did not improve from 0.57578
Epoch 51/300
 - 14s - loss: 2788.5324 - acc: 0.9392 - mDice: 0.6913 - val_loss: 4145.7584 - val_acc: 0.9409 - val_mDice: 0.5586

Epoch 00051: val_mDice did not improve from 0.57578
Epoch 52/300
 - 13s - loss: 2761.8456 - acc: 0.9393 - mDice: 0.6935 - val_loss: 4103.4341 - val_acc: 0.9433 - val_mDice: 0.5617

Epoch 00052: val_mDice did not improve from 0.57578
Epoch 53/300
 - 13s - loss: 2763.5110 - acc: 0.9395 - mDice: 0.6936 - val_loss: 4103.4387 - val_acc: 0.9428 - val_mDice: 0.5630

Epoch 00053: val_mDice did not improve from 0.57578
Epoch 54/300
 - 13s - loss: 2758.8192 - acc: 0.9395 - mDice: 0.6940 - val_loss: 3943.1618 - val_acc: 0.9427 - val_mDice: 0.5746

Epoch 00054: val_mDice did not improve from 0.57578
Epoch 55/300
 - 14s - loss: 2737.7515 - acc: 0.9397 - mDice: 0.6958 - val_loss: 4091.7276 - val_acc: 0.9420 - val_mDice: 0.5611

Epoch 00055: val_mDice did not improve from 0.57578
Epoch 56/300
 - 14s - loss: 2733.5693 - acc: 0.9397 - mDice: 0.6962 - val_loss: 4140.3216 - val_acc: 0.9417 - val_mDice: 0.5597

Epoch 00056: val_mDice did not improve from 0.57578
Epoch 57/300
 - 13s - loss: 2729.6998 - acc: 0.9399 - mDice: 0.6965 - val_loss: 4088.7758 - val_acc: 0.9397 - val_mDice: 0.5623

Epoch 00057: val_mDice did not improve from 0.57578
Epoch 58/300
 - 13s - loss: 2720.0149 - acc: 0.9399 - mDice: 0.6973 - val_loss: 4210.1868 - val_acc: 0.9389 - val_mDice: 0.5531

Epoch 00058: val_mDice did not improve from 0.57578
Epoch 59/300
 - 14s - loss: 2713.7613 - acc: 0.9403 - mDice: 0.6980 - val_loss: 4385.0180 - val_acc: 0.9418 - val_mDice: 0.5428

Epoch 00059: val_mDice did not improve from 0.57578
Epoch 60/300
 - 14s - loss: 2715.8908 - acc: 0.9403 - mDice: 0.6978 - val_loss: 4109.6208 - val_acc: 0.9428 - val_mDice: 0.5635

Epoch 00060: val_mDice did not improve from 0.57578
Epoch 61/300
 - 13s - loss: 2718.4049 - acc: 0.9402 - mDice: 0.6977 - val_loss: 4010.7048 - val_acc: 0.9406 - val_mDice: 0.5690

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.29s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.06s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.85s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:37,  1.82s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:56,  1.69s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:53,  1.68s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:27,  1.59s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:42,  1.65s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:23,  1.59s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:52,  1.70s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:44,  1.68s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<08:01,  1.74s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:16,  1.80s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<07:52,  1.73s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:09,  1.79s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<07:59,  1.76s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<07:58,  1.76s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<08:08,  1.81s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<08:08,  1.81s/it]predicting train subjects:   6%|▌         | 17/285 [00:29<07:43,  1.73s/it]predicting train subjects:   6%|▋         | 18/285 [00:30<07:44,  1.74s/it]predicting train subjects:   7%|▋         | 19/285 [00:32<07:37,  1.72s/it]predicting train subjects:   7%|▋         | 20/285 [00:34<07:41,  1.74s/it]predicting train subjects:   7%|▋         | 21/285 [00:36<07:48,  1.77s/it]predicting train subjects:   8%|▊         | 22/285 [00:37<07:35,  1.73s/it]predicting train subjects:   8%|▊         | 23/285 [00:39<07:44,  1.77s/it]predicting train subjects:   8%|▊         | 24/285 [00:41<07:29,  1.72s/it]predicting train subjects:   9%|▉         | 25/285 [00:43<07:42,  1.78s/it]predicting train subjects:   9%|▉         | 26/285 [00:45<07:53,  1.83s/it]predicting train subjects:   9%|▉         | 27/285 [00:46<07:32,  1.75s/it]predicting train subjects:  10%|▉         | 28/285 [00:48<07:34,  1.77s/it]predicting train subjects:  10%|█         | 29/285 [00:50<07:30,  1.76s/it]predicting train subjects:  11%|█         | 30/285 [00:52<07:42,  1.82s/it]predicting train subjects:  11%|█         | 31/285 [00:54<07:44,  1.83s/it]predicting train subjects:  11%|█         | 32/285 [00:55<07:23,  1.75s/it]predicting train subjects:  12%|█▏        | 33/285 [00:57<07:20,  1.75s/it]predicting train subjects:  12%|█▏        | 34/285 [00:59<07:21,  1.76s/it]predicting train subjects:  12%|█▏        | 35/285 [01:01<07:29,  1.80s/it]predicting train subjects:  13%|█▎        | 36/285 [01:02<07:13,  1.74s/it]predicting train subjects:  13%|█▎        | 37/285 [01:04<07:16,  1.76s/it]predicting train subjects:  13%|█▎        | 38/285 [01:06<07:24,  1.80s/it]predicting train subjects:  14%|█▎        | 39/285 [01:07<07:02,  1.72s/it]predicting train subjects:  14%|█▍        | 40/285 [01:09<07:05,  1.74s/it]predicting train subjects:  14%|█▍        | 41/285 [01:11<06:59,  1.72s/it]predicting train subjects:  15%|█▍        | 42/285 [01:12<06:50,  1.69s/it]predicting train subjects:  15%|█▌        | 43/285 [01:14<06:53,  1.71s/it]predicting train subjects:  15%|█▌        | 44/285 [01:16<07:06,  1.77s/it]predicting train subjects:  16%|█▌        | 45/285 [01:18<06:58,  1.74s/it]predicting train subjects:  16%|█▌        | 46/285 [01:20<07:18,  1.83s/it]predicting train subjects:  16%|█▋        | 47/285 [01:22<07:07,  1.80s/it]predicting train subjects:  17%|█▋        | 48/285 [01:24<07:14,  1.83s/it]predicting train subjects:  17%|█▋        | 49/285 [01:26<07:30,  1.91s/it]predicting train subjects:  18%|█▊        | 50/285 [01:27<07:24,  1.89s/it]predicting train subjects:  18%|█▊        | 51/285 [01:29<07:31,  1.93s/it]predicting train subjects:  18%|█▊        | 52/285 [01:31<07:06,  1.83s/it]predicting train subjects:  19%|█▊        | 53/285 [01:33<06:57,  1.80s/it]predicting train subjects:  19%|█▉        | 54/285 [01:35<06:59,  1.81s/it]predicting train subjects:  19%|█▉        | 55/285 [01:36<06:38,  1.73s/it]predicting train subjects:  20%|█▉        | 56/285 [01:38<06:34,  1.72s/it]predicting train subjects:  20%|██        | 57/285 [01:40<06:27,  1.70s/it]predicting train subjects:  20%|██        | 58/285 [01:41<06:30,  1.72s/it]predicting train subjects:  21%|██        | 59/285 [01:43<06:41,  1.78s/it]predicting train subjects:  21%|██        | 60/285 [01:45<06:49,  1.82s/it]predicting train subjects:  21%|██▏       | 61/285 [01:47<06:36,  1.77s/it]predicting train subjects:  22%|██▏       | 62/285 [01:49<06:36,  1.78s/it]predicting train subjects:  22%|██▏       | 63/285 [01:50<06:35,  1.78s/it]predicting train subjects:  22%|██▏       | 64/285 [01:52<06:18,  1.71s/it]predicting train subjects:  23%|██▎       | 65/285 [01:54<06:19,  1.73s/it]predicting train subjects:  23%|██▎       | 66/285 [01:56<06:28,  1.77s/it]predicting train subjects:  24%|██▎       | 67/285 [01:57<06:19,  1.74s/it]predicting train subjects:  24%|██▍       | 68/285 [01:59<06:12,  1.71s/it]predicting train subjects:  24%|██▍       | 69/285 [02:01<06:12,  1.72s/it]predicting train subjects:  25%|██▍       | 70/285 [02:02<06:11,  1.73s/it]predicting train subjects:  25%|██▍       | 71/285 [02:04<06:12,  1.74s/it]predicting train subjects:  25%|██▌       | 72/285 [02:06<05:58,  1.68s/it]predicting train subjects:  26%|██▌       | 73/285 [02:07<06:00,  1.70s/it]predicting train subjects:  26%|██▌       | 74/285 [02:09<05:57,  1.69s/it]predicting train subjects:  26%|██▋       | 75/285 [02:11<06:00,  1.72s/it]predicting train subjects:  27%|██▋       | 76/285 [02:13<06:06,  1.75s/it]predicting train subjects:  27%|██▋       | 77/285 [02:14<05:54,  1.70s/it]predicting train subjects:  27%|██▋       | 78/285 [02:16<05:44,  1.66s/it]predicting train subjects:  28%|██▊       | 79/285 [02:18<05:46,  1.68s/it]predicting train subjects:  28%|██▊       | 80/285 [02:19<05:50,  1.71s/it]predicting train subjects:  28%|██▊       | 81/285 [02:21<05:45,  1.70s/it]predicting train subjects:  29%|██▉       | 82/285 [02:23<05:48,  1.72s/it]predicting train subjects:  29%|██▉       | 83/285 [02:24<05:41,  1.69s/it]predicting train subjects:  29%|██▉       | 84/285 [02:26<05:32,  1.65s/it]predicting train subjects:  30%|██▉       | 85/285 [02:28<05:36,  1.68s/it]predicting train subjects:  30%|███       | 86/285 [02:30<05:43,  1.72s/it]predicting train subjects:  31%|███       | 87/285 [02:31<05:42,  1.73s/it]predicting train subjects:  31%|███       | 88/285 [02:33<05:32,  1.69s/it]predicting train subjects:  31%|███       | 89/285 [02:35<05:37,  1.72s/it]predicting train subjects:  32%|███▏      | 90/285 [02:37<05:45,  1.77s/it]predicting train subjects:  32%|███▏      | 91/285 [02:38<05:30,  1.70s/it]predicting train subjects:  32%|███▏      | 92/285 [02:40<05:34,  1.73s/it]predicting train subjects:  33%|███▎      | 93/285 [02:42<05:31,  1.72s/it]predicting train subjects:  33%|███▎      | 94/285 [02:43<05:30,  1.73s/it]predicting train subjects:  33%|███▎      | 95/285 [02:45<05:32,  1.75s/it]predicting train subjects:  34%|███▎      | 96/285 [02:47<05:28,  1.74s/it]predicting train subjects:  34%|███▍      | 97/285 [02:49<05:30,  1.76s/it]predicting train subjects:  34%|███▍      | 98/285 [02:50<05:25,  1.74s/it]predicting train subjects:  35%|███▍      | 99/285 [02:52<05:22,  1.74s/it]predicting train subjects:  35%|███▌      | 100/285 [02:54<05:21,  1.74s/it]predicting train subjects:  35%|███▌      | 101/285 [02:55<05:08,  1.68s/it]predicting train subjects:  36%|███▌      | 102/285 [02:57<05:13,  1.71s/it]predicting train subjects:  36%|███▌      | 103/285 [02:59<05:00,  1.65s/it]predicting train subjects:  36%|███▋      | 104/285 [03:01<05:07,  1.70s/it]predicting train subjects:  37%|███▋      | 105/285 [03:02<05:12,  1.74s/it]predicting train subjects:  37%|███▋      | 106/285 [03:04<05:01,  1.69s/it]predicting train subjects:  38%|███▊      | 107/285 [03:06<05:00,  1.69s/it]predicting train subjects:  38%|███▊      | 108/285 [03:07<04:49,  1.64s/it]predicting train subjects:  38%|███▊      | 109/285 [03:09<04:53,  1.67s/it]predicting train subjects:  39%|███▊      | 110/285 [03:11<04:54,  1.68s/it]predicting train subjects:  39%|███▉      | 111/285 [03:12<04:46,  1.65s/it]predicting train subjects:  39%|███▉      | 112/285 [03:14<04:51,  1.69s/it]predicting train subjects:  40%|███▉      | 113/285 [03:16<04:55,  1.72s/it]predicting train subjects:  40%|████      | 114/285 [03:17<04:53,  1.72s/it]predicting train subjects:  40%|████      | 115/285 [03:19<04:55,  1.74s/it]predicting train subjects:  41%|████      | 116/285 [03:21<04:54,  1.74s/it]predicting train subjects:  41%|████      | 117/285 [03:23<04:43,  1.69s/it]predicting train subjects:  41%|████▏     | 118/285 [03:24<04:39,  1.67s/it]predicting train subjects:  42%|████▏     | 119/285 [03:26<04:44,  1.71s/it]predicting train subjects:  42%|████▏     | 120/285 [03:28<04:39,  1.69s/it]predicting train subjects:  42%|████▏     | 121/285 [03:29<04:30,  1.65s/it]predicting train subjects:  43%|████▎     | 122/285 [03:31<04:20,  1.60s/it]predicting train subjects:  43%|████▎     | 123/285 [03:32<04:13,  1.57s/it]predicting train subjects:  44%|████▎     | 124/285 [03:34<04:13,  1.58s/it]predicting train subjects:  44%|████▍     | 125/285 [03:35<04:06,  1.54s/it]predicting train subjects:  44%|████▍     | 126/285 [03:37<04:02,  1.52s/it]predicting train subjects:  45%|████▍     | 127/285 [03:38<03:57,  1.50s/it]predicting train subjects:  45%|████▍     | 128/285 [03:40<04:00,  1.53s/it]predicting train subjects:  45%|████▌     | 129/285 [03:41<03:58,  1.53s/it]predicting train subjects:  46%|████▌     | 130/285 [03:43<03:50,  1.48s/it]predicting train subjects:  46%|████▌     | 131/285 [03:44<03:43,  1.45s/it]predicting train subjects:  46%|████▋     | 132/285 [03:46<03:47,  1.49s/it]predicting train subjects:  47%|████▋     | 133/285 [03:47<03:46,  1.49s/it]predicting train subjects:  47%|████▋     | 134/285 [03:48<03:41,  1.47s/it]predicting train subjects:  47%|████▋     | 135/285 [03:50<03:36,  1.45s/it]predicting train subjects:  48%|████▊     | 136/285 [03:51<03:32,  1.43s/it]predicting train subjects:  48%|████▊     | 137/285 [03:53<03:36,  1.46s/it]predicting train subjects:  48%|████▊     | 138/285 [03:54<03:32,  1.45s/it]predicting train subjects:  49%|████▉     | 139/285 [03:56<03:35,  1.47s/it]predicting train subjects:  49%|████▉     | 140/285 [03:57<03:36,  1.49s/it]predicting train subjects:  49%|████▉     | 141/285 [03:59<03:29,  1.46s/it]predicting train subjects:  50%|████▉     | 142/285 [04:00<03:27,  1.45s/it]predicting train subjects:  50%|█████     | 143/285 [04:02<03:24,  1.44s/it]predicting train subjects:  51%|█████     | 144/285 [04:03<03:32,  1.50s/it]predicting train subjects:  51%|█████     | 145/285 [04:05<03:28,  1.49s/it]predicting train subjects:  51%|█████     | 146/285 [04:06<03:37,  1.56s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:08<03:29,  1.52s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:09<03:29,  1.53s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:11<03:26,  1.52s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:12<03:26,  1.53s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:14<03:26,  1.54s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:16<03:26,  1.55s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:17<03:20,  1.52s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:19<03:26,  1.58s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:20<03:23,  1.56s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:22<03:26,  1.60s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:23<03:18,  1.55s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:25<03:16,  1.55s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:26<03:10,  1.51s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:28<03:10,  1.52s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:29<03:13,  1.56s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:31<03:09,  1.54s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:33<03:12,  1.58s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:34<03:13,  1.60s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:36<03:12,  1.61s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:38<03:10,  1.60s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:39<03:12,  1.63s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:41<03:06,  1.59s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:42<03:01,  1.56s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:44<02:55,  1.52s/it]predicting train subjects:  60%|██████    | 171/285 [04:45<02:56,  1.55s/it]predicting train subjects:  60%|██████    | 172/285 [04:47<02:51,  1.52s/it]predicting train subjects:  61%|██████    | 173/285 [04:48<02:48,  1.50s/it]predicting train subjects:  61%|██████    | 174/285 [04:50<02:44,  1.48s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:51<02:47,  1.52s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:53<02:52,  1.59s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:54<02:46,  1.55s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:56<02:43,  1.52s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:57<02:39,  1.51s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:59<02:47,  1.60s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:01<02:48,  1.62s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:03<02:48,  1.64s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:04<02:40,  1.57s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:05<02:38,  1.57s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:07<02:31,  1.52s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:09<02:41,  1.63s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:11<02:46,  1.69s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:12<02:49,  1.75s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:14<02:36,  1.63s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:15<02:31,  1.59s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:17<02:31,  1.61s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:19<02:33,  1.65s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:20<02:25,  1.59s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:22<02:24,  1.59s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:23<02:18,  1.54s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:25<02:26,  1.64s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:27<02:30,  1.71s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:29<02:33,  1.76s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:30<02:22,  1.66s/it]predicting train subjects:  70%|███████   | 200/285 [05:32<02:18,  1.62s/it]predicting train subjects:  71%|███████   | 201/285 [05:34<02:21,  1.68s/it]predicting train subjects:  71%|███████   | 202/285 [05:35<02:18,  1.67s/it]predicting train subjects:  71%|███████   | 203/285 [05:37<02:16,  1.67s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:38<02:10,  1.61s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:40<02:05,  1.56s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:41<02:00,  1.52s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:43<02:07,  1.63s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:45<02:09,  1.68s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:47<02:10,  1.72s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:48<02:01,  1.62s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:50<01:58,  1.60s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:51<01:57,  1.61s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:53<01:58,  1.65s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:54<01:51,  1.58s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:56<01:55,  1.65s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:58<01:50,  1.60s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:00<01:54,  1.69s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:02<01:57,  1.75s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:03<01:57,  1.78s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:05<01:48,  1.66s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:06<01:42,  1.60s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:08<01:43,  1.64s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:09<01:37,  1.57s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:11<01:35,  1.57s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:12<01:30,  1.51s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:14<01:34,  1.61s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:16<01:38,  1.70s/it]predicting train subjects:  80%|████████  | 228/285 [06:18<01:38,  1.74s/it]predicting train subjects:  80%|████████  | 229/285 [06:20<01:36,  1.72s/it]predicting train subjects:  81%|████████  | 230/285 [06:21<01:30,  1.64s/it]predicting train subjects:  81%|████████  | 231/285 [06:23<01:26,  1.60s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:24<01:26,  1.62s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:26<01:21,  1.57s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:28<01:25,  1.67s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:29<01:20,  1.60s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:31<01:21,  1.67s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:33<01:22,  1.72s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:34<01:21,  1.74s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:36<01:18,  1.72s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:38<01:13,  1.63s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:39<01:09,  1.59s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:40<01:06,  1.54s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:42<01:02,  1.48s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:44<01:03,  1.55s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:45<00:59,  1.49s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:47<01:03,  1.63s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:49<01:04,  1.69s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:50<01:03,  1.70s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:52<00:57,  1.60s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:53<00:55,  1.57s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:55<00:52,  1.53s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:56<00:50,  1.52s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:58<00:51,  1.62s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:00<00:52,  1.68s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:02<00:51,  1.72s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:03<00:48,  1.66s/it]predicting train subjects:  90%|█████████ | 257/285 [07:05<00:45,  1.61s/it]predicting train subjects:  91%|█████████ | 258/285 [07:07<00:44,  1.66s/it]predicting train subjects:  91%|█████████ | 259/285 [07:08<00:44,  1.69s/it]predicting train subjects:  91%|█████████ | 260/285 [07:10<00:39,  1.59s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:11<00:37,  1.55s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:12<00:34,  1.50s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:14<00:32,  1.47s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:16<00:33,  1.58s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:18<00:33,  1.70s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:19<00:30,  1.63s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:21<00:28,  1.58s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:22<00:27,  1.64s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:24<00:26,  1.65s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:25<00:23,  1.57s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:27<00:21,  1.55s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:29<00:20,  1.60s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:30<00:18,  1.54s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:31<00:16,  1.50s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:33<00:16,  1.61s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:35<00:15,  1.68s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:37<00:13,  1.63s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:38<00:11,  1.62s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:40<00:09,  1.63s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:41<00:07,  1.59s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:43<00:06,  1.55s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:44<00:04,  1.54s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:46<00:03,  1.66s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:48<00:01,  1.71s/it]predicting train subjects: 100%|██████████| 285/285 [07:50<00:00,  1.75s/it]
Epoch 00061: val_mDice did not improve from 0.57578
Restoring model weights from the end of the best epoch
Epoch 00061: early stopping
{'val_loss': [16794.41582782452, 8238.661977914664, 6144.653799203726, 5884.036517803485, 4695.512488731971, 4883.622708834135, 4247.552706204928, 4250.313833383413, 4210.816180889423, 4319.768244816707, 4285.162419245793, 4121.732572115385, 4104.568622295673, 4072.8814791165864, 4073.8621732271636, 4113.031019944411, 4206.292001577524, 4085.871549166166, 4000.5718712439902, 4110.8556236853965, 4057.6087458683896, 4439.983149601863, 4096.23623422476, 4862.382540189303, 4008.016169621394, 4229.424189640926, 4057.557584322416, 4170.027555025541, 3943.4972299429087, 4069.3230637770434, 3936.2317176231973, 4013.1885047325723, 4064.400353064904, 3987.4456082857573, 4023.995098407452, 4182.389094426082, 4071.327899639423, 4246.755098783053, 4356.708899864783, 4256.345721905048, 4476.520568847656, 4098.406433105469, 4084.2081862229566, 4228.993680513822, 4394.832726111779, 4261.956852839543, 4233.617173414964, 4131.846397986779, 4083.091008112981, 4152.052053598257, 4145.758371206431, 4103.434147761418, 4103.438739483173, 3943.1617995042066, 4091.7276000976562, 4140.321551983173, 4088.7757803109976, 4210.186772273137, 4385.018005371094, 4109.620807354267, 4010.7047823392427], 'val_acc': [0.9053369989761939, 0.9016272242252643, 0.9042552503255697, 0.910149315228829, 0.9139400124549866, 0.9145386196099795, 0.9179294521992023, 0.9177907659457281, 0.9194665230237521, 0.918810099363327, 0.9187176388043624, 0.9206129656388209, 0.9227163401933817, 0.925379081414296, 0.9300850629806519, 0.936367406294896, 0.9371255544515756, 0.9411196158482478, 0.9428162070421072, 0.9421782493591309, 0.9424301798527057, 0.9330459695595962, 0.9397651828252352, 0.9297244869745694, 0.9407405784496894, 0.9390763777952927, 0.9425734785886911, 0.940807615335171, 0.9431860309380752, 0.9431097484551944, 0.9423839426957644, 0.9407891378952906, 0.9427376251954299, 0.9423307982774881, 0.9410803501422589, 0.9392982400380648, 0.9408676945246183, 0.9411335083154532, 0.9429225119260641, 0.9381656738427969, 0.9379761654597062, 0.9425411178515508, 0.9409786600332993, 0.9407706306530879, 0.9430935451617608, 0.9434056075719687, 0.939638043825443, 0.9408422456337855, 0.9406227171421051, 0.9407821618593656, 0.9408769653393672, 0.9433247057291178, 0.9428138801684747, 0.9426867618010595, 0.9419887363910675, 0.9417390846289121, 0.9396819380613474, 0.9389307659405929, 0.9418454422400548, 0.9428161887022165, 0.9405833666141217], 'val_mDice': [0.1636810295212154, 0.33690426197762674, 0.434009570055283, 0.44878534141641396, 0.5198174457137401, 0.5052169870871764, 0.5502761143904465, 0.5499097659037664, 0.5533140960794228, 0.546322250022338, 0.5486924393245807, 0.560805698713431, 0.5634024269305743, 0.5649604539458568, 0.5663140141046964, 0.5599721211653489, 0.5539642526553228, 0.5630284645236455, 0.5705386486191016, 0.5629166075243399, 0.5672072378488687, 0.5382458195090294, 0.5617479383945465, 0.5107004421834762, 0.5673945368482516, 0.5523787616537168, 0.5671389429615095, 0.5565342542070609, 0.5739773695285504, 0.5643358136025759, 0.575780386535021, 0.5693392065855173, 0.5665386236057832, 0.5711934279937011, 0.5690220153102508, 0.5573041244195058, 0.5650075983542663, 0.552507316836944, 0.5459422016373048, 0.5493250414729118, 0.5348527015974889, 0.5616004094481468, 0.5630643754624404, 0.5512704353492993, 0.5434137594241363, 0.5541347973048687, 0.5521289176092699, 0.5606425920358071, 0.5630840871196526, 0.5578813584378133, 0.5585537931093802, 0.5617336235367335, 0.5630235826739898, 0.57463500304864, 0.5611278013541148, 0.5597287665766019, 0.562264230961983, 0.553129506798891, 0.5427862027516732, 0.563487168114919, 0.5690497079720864], 'loss': [24283.44799063912, 10359.314400009835, 7348.7831524865915, 6099.3667526716545, 5300.612868239626, 4819.6515512780425, 4492.609032858631, 4307.704565954309, 4120.811693174113, 3976.082002294467, 3924.6055962128867, 3804.616285476607, 3740.81479325119, 3660.224028834577, 3610.307747577462, 3539.909578017464, 3521.167372223241, 3462.689411459204, 3412.4155706306956, 3371.495891331461, 3363.170243403002, 3336.301851287535, 3289.0532651326207, 3264.5114619891756, 3227.525578351871, 3200.9791522864693, 3185.944753057038, 3145.6735547924245, 3138.7910180904983, 3108.902494606976, 3100.5637499963973, 3088.9133628388563, 3059.3347965596863, 3058.484010286374, 3034.2487877065887, 3018.967080756306, 3016.6161150757725, 2993.720670949684, 2986.608056048455, 2962.1675971127147, 2956.0277766757463, 2934.105579855037, 2876.3727352990554, 2852.8354200380572, 2850.3556702116102, 2825.9628179659762, 2807.844953894956, 2811.722428287097, 2805.0717111130343, 2791.3498712694645, 2788.5324440554787, 2761.8455769455236, 2763.51099913971, 2758.8192145426665, 2737.75154411121, 2733.5693377950674, 2729.6998016320836, 2720.014859659782, 2713.7612592554133, 2715.8908306946123, 2718.404862723755], 'acc': [0.5527983984939069, 0.8821305293092689, 0.8892314202185433, 0.8902004970447016, 0.8919889366320003, 0.8936416793823858, 0.8952169126550903, 0.8965167187186588, 0.8981385547044168, 0.8997101795681066, 0.9011821690976021, 0.903365276104562, 0.9056871145026419, 0.9073834867041171, 0.910109767996934, 0.9130867158455195, 0.9158078981074725, 0.9198606061031708, 0.9244699925885125, 0.9275254497039497, 0.929175328254084, 0.9301171577208752, 0.9309861177801372, 0.9316278576004343, 0.9325286278225098, 0.9333006167427196, 0.9335999735208892, 0.9340630934311654, 0.9345344434659177, 0.934965973348731, 0.9351793798223519, 0.9355334719696421, 0.9357037781778543, 0.935871801445166, 0.9362663726497485, 0.9363512603172152, 0.9362761536218864, 0.936604260920071, 0.9367290284375714, 0.9370368982465199, 0.9372168283538164, 0.9372812108690972, 0.9374284558736848, 0.9378045892996903, 0.9379350311705781, 0.9383605128448079, 0.9386172583487314, 0.9385801672957474, 0.9388032164848963, 0.9390064202077955, 0.9392332862875377, 0.9393060007603705, 0.9395457437521504, 0.939522906289949, 0.9397430289861385, 0.9397227424136345, 0.9399063064692964, 0.9399413989718898, 0.9403485451513778, 0.9403262886187033, 0.9401703045166563], 'mDice': [0.08102247199138284, 0.27750303001957033, 0.3897290330860851, 0.45472097179166926, 0.501843611670521, 0.5329331638495728, 0.5553346340159127, 0.5684742144055003, 0.581978704077747, 0.5930114143681704, 0.5973403684593573, 0.60626317924166, 0.6114204580533398, 0.6176569499972121, 0.6217003551607344, 0.627548219312615, 0.6289527084976283, 0.6335904450420083, 0.6376642245247192, 0.6408232133359715, 0.6414445268264569, 0.6435433904326271, 0.6474914231401939, 0.6495589612650166, 0.6526025113480718, 0.6547498739668334, 0.6558871716686933, 0.6594468976566737, 0.6599942404307156, 0.662596720748971, 0.6632523322021853, 0.6643078133572426, 0.6668339234859336, 0.66688767245123, 0.6689517400718358, 0.670322583504052, 0.6704692755261767, 0.6725453749514809, 0.6731398882081365, 0.6752709840030717, 0.6758911450234856, 0.6778025899020924, 0.6831329765876567, 0.6856033063502173, 0.6857931348798812, 0.687845275035525, 0.6894438480974662, 0.6892173655477494, 0.6899014466156063, 0.6909325803039721, 0.6912632817317449, 0.6935318338907283, 0.6936469619084821, 0.6939691636303545, 0.6958294619298405, 0.6962254039533, 0.6965324945646844, 0.6973249630262676, 0.6980411731140272, 0.6977917823164399, 0.6976619557482087]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_amkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:32,  1.81s/it]Loading train:   1%|          | 2/285 [00:03<07:46,  1.65s/it]Loading train:   1%|          | 3/285 [00:04<07:31,  1.60s/it]Loading train:   1%|▏         | 4/285 [00:06<07:27,  1.59s/it]Loading train:   2%|▏         | 5/285 [00:07<07:39,  1.64s/it]Loading train:   2%|▏         | 6/285 [00:09<07:11,  1.55s/it]Loading train:   2%|▏         | 7/285 [00:11<07:43,  1.67s/it]Loading train:   3%|▎         | 8/285 [00:12<07:26,  1.61s/it]Loading train:   3%|▎         | 9/285 [00:14<07:46,  1.69s/it]Loading train:   4%|▎         | 10/285 [00:15<07:21,  1.60s/it]Loading train:   4%|▍         | 11/285 [00:17<06:45,  1.48s/it]Loading train:   4%|▍         | 12/285 [00:18<06:32,  1.44s/it]Loading train:   5%|▍         | 13/285 [00:19<06:22,  1.41s/it]Loading train:   5%|▍         | 14/285 [00:21<06:18,  1.40s/it]Loading train:   5%|▌         | 15/285 [00:22<06:21,  1.41s/it]Loading train:   6%|▌         | 16/285 [00:23<06:06,  1.36s/it]Loading train:   6%|▌         | 17/285 [00:25<05:59,  1.34s/it]Loading train:   6%|▋         | 18/285 [00:26<05:51,  1.32s/it]Loading train:   7%|▋         | 19/285 [00:27<05:50,  1.32s/it]Loading train:   7%|▋         | 20/285 [00:29<06:07,  1.39s/it]Loading train:   7%|▋         | 21/285 [00:30<06:07,  1.39s/it]Loading train:   8%|▊         | 22/285 [00:31<05:29,  1.25s/it]Loading train:   8%|▊         | 23/285 [00:32<05:29,  1.26s/it]Loading train:   8%|▊         | 24/285 [00:33<05:12,  1.20s/it]Loading train:   9%|▉         | 25/285 [00:35<05:19,  1.23s/it]Loading train:   9%|▉         | 26/285 [00:36<05:26,  1.26s/it]Loading train:   9%|▉         | 27/285 [00:37<05:07,  1.19s/it]Loading train:  10%|▉         | 28/285 [00:38<04:52,  1.14s/it]Loading train:  10%|█         | 29/285 [00:39<04:43,  1.11s/it]Loading train:  11%|█         | 30/285 [00:40<04:34,  1.08s/it]Loading train:  11%|█         | 31/285 [00:41<04:28,  1.06s/it]Loading train:  11%|█         | 32/285 [00:42<04:19,  1.03s/it]Loading train:  12%|█▏        | 33/285 [00:43<04:13,  1.01s/it]Loading train:  12%|█▏        | 34/285 [00:44<04:09,  1.00it/s]Loading train:  12%|█▏        | 35/285 [00:45<04:08,  1.00it/s]Loading train:  13%|█▎        | 36/285 [00:46<03:49,  1.08it/s]Loading train:  13%|█▎        | 37/285 [00:47<03:48,  1.08it/s]Loading train:  13%|█▎        | 38/285 [00:48<03:48,  1.08it/s]Loading train:  14%|█▎        | 39/285 [00:49<03:45,  1.09it/s]Loading train:  14%|█▍        | 40/285 [00:50<03:50,  1.06it/s]Loading train:  14%|█▍        | 41/285 [00:50<03:38,  1.12it/s]Loading train:  15%|█▍        | 42/285 [00:51<03:31,  1.15it/s]Loading train:  15%|█▌        | 43/285 [00:52<03:38,  1.11it/s]Loading train:  15%|█▌        | 44/285 [00:53<03:45,  1.07it/s]Loading train:  16%|█▌        | 45/285 [00:54<03:36,  1.11it/s]Loading train:  16%|█▌        | 46/285 [00:55<03:42,  1.07it/s]Loading train:  16%|█▋        | 47/285 [00:56<03:25,  1.16it/s]Loading train:  17%|█▋        | 48/285 [00:57<03:27,  1.14it/s]Loading train:  17%|█▋        | 49/285 [00:57<03:28,  1.13it/s]Loading train:  18%|█▊        | 50/285 [00:58<03:33,  1.10it/s]Loading train:  18%|█▊        | 51/285 [00:59<03:40,  1.06it/s]Loading train:  18%|█▊        | 52/285 [01:00<03:32,  1.10it/s]Loading train:  19%|█▊        | 53/285 [01:01<03:29,  1.11it/s]Loading train:  19%|█▉        | 54/285 [01:02<03:31,  1.09it/s]Loading train:  19%|█▉        | 55/285 [01:03<03:17,  1.16it/s]Loading train:  20%|█▉        | 56/285 [01:04<03:17,  1.16it/s]Loading train:  20%|██        | 57/285 [01:04<03:04,  1.24it/s]Loading train:  20%|██        | 58/285 [01:05<03:10,  1.19it/s]Loading train:  21%|██        | 59/285 [01:06<03:17,  1.14it/s]Loading train:  21%|██        | 60/285 [01:07<03:20,  1.12it/s]Loading train:  21%|██▏       | 61/285 [01:08<03:10,  1.17it/s]Loading train:  22%|██▏       | 62/285 [01:09<03:16,  1.14it/s]Loading train:  22%|██▏       | 63/285 [01:10<03:25,  1.08it/s]Loading train:  22%|██▏       | 64/285 [01:11<03:49,  1.04s/it]Loading train:  23%|██▎       | 65/285 [01:13<04:29,  1.23s/it]Loading train:  23%|██▎       | 66/285 [01:14<04:35,  1.26s/it]Loading train:  24%|██▎       | 67/285 [01:15<04:26,  1.22s/it]Loading train:  24%|██▍       | 68/285 [01:16<04:02,  1.12s/it]Loading train:  24%|██▍       | 69/285 [01:17<03:48,  1.06s/it]Loading train:  25%|██▍       | 70/285 [01:18<03:40,  1.03s/it]Loading train:  25%|██▍       | 71/285 [01:19<03:41,  1.04s/it]Loading train:  25%|██▌       | 72/285 [01:20<03:28,  1.02it/s]Loading train:  26%|██▌       | 73/285 [01:21<03:22,  1.05it/s]Loading train:  26%|██▌       | 74/285 [01:22<03:10,  1.11it/s]Loading train:  26%|██▋       | 75/285 [01:23<03:13,  1.09it/s]Loading train:  27%|██▋       | 76/285 [01:24<03:15,  1.07it/s]Loading train:  27%|██▋       | 77/285 [01:25<03:11,  1.09it/s]Loading train:  27%|██▋       | 78/285 [01:26<03:15,  1.06it/s]Loading train:  28%|██▊       | 79/285 [01:26<03:11,  1.08it/s]Loading train:  28%|██▊       | 80/285 [01:27<03:05,  1.10it/s]Loading train:  28%|██▊       | 81/285 [01:28<02:56,  1.16it/s]Loading train:  29%|██▉       | 82/285 [01:29<02:57,  1.14it/s]Loading train:  29%|██▉       | 83/285 [01:30<02:57,  1.14it/s]Loading train:  29%|██▉       | 84/285 [01:31<02:55,  1.15it/s]Loading train:  30%|██▉       | 85/285 [01:32<02:54,  1.15it/s]Loading train:  30%|███       | 86/285 [01:33<03:04,  1.08it/s]Loading train:  31%|███       | 87/285 [01:34<03:01,  1.09it/s]Loading train:  31%|███       | 88/285 [01:34<02:54,  1.13it/s]Loading train:  31%|███       | 89/285 [01:35<02:55,  1.12it/s]Loading train:  32%|███▏      | 90/285 [01:36<02:54,  1.12it/s]Loading train:  32%|███▏      | 91/285 [01:37<02:48,  1.15it/s]Loading train:  32%|███▏      | 92/285 [01:38<02:54,  1.10it/s]Loading train:  33%|███▎      | 93/285 [01:39<02:47,  1.15it/s]Loading train:  33%|███▎      | 94/285 [01:40<02:48,  1.13it/s]Loading train:  33%|███▎      | 95/285 [01:41<02:49,  1.12it/s]Loading train:  34%|███▎      | 96/285 [01:42<02:54,  1.08it/s]Loading train:  34%|███▍      | 97/285 [01:43<02:56,  1.07it/s]Loading train:  34%|███▍      | 98/285 [01:43<02:54,  1.07it/s]Loading train:  35%|███▍      | 99/285 [01:44<02:47,  1.11it/s]Loading train:  35%|███▌      | 100/285 [01:45<02:49,  1.09it/s]Loading train:  35%|███▌      | 101/285 [01:46<02:47,  1.10it/s]Loading train:  36%|███▌      | 102/285 [01:47<02:48,  1.08it/s]Loading train:  36%|███▌      | 103/285 [01:48<02:40,  1.14it/s]Loading train:  36%|███▋      | 104/285 [01:49<02:39,  1.13it/s]Loading train:  37%|███▋      | 105/285 [01:50<02:42,  1.11it/s]Loading train:  37%|███▋      | 106/285 [01:51<02:36,  1.14it/s]Loading train:  38%|███▊      | 107/285 [01:51<02:40,  1.11it/s]Loading train:  38%|███▊      | 108/285 [01:52<02:37,  1.12it/s]Loading train:  38%|███▊      | 109/285 [01:53<02:37,  1.11it/s]Loading train:  39%|███▊      | 110/285 [01:54<02:41,  1.09it/s]Loading train:  39%|███▉      | 111/285 [01:55<02:34,  1.12it/s]Loading train:  39%|███▉      | 112/285 [01:56<02:28,  1.17it/s]Loading train:  40%|███▉      | 113/285 [01:57<02:35,  1.11it/s]Loading train:  40%|████      | 114/285 [01:58<02:33,  1.11it/s]Loading train:  40%|████      | 115/285 [01:59<02:27,  1.15it/s]Loading train:  41%|████      | 116/285 [01:59<02:28,  1.13it/s]Loading train:  41%|████      | 117/285 [02:00<02:27,  1.14it/s]Loading train:  41%|████▏     | 118/285 [02:01<02:22,  1.17it/s]Loading train:  42%|████▏     | 119/285 [02:02<02:24,  1.15it/s]Loading train:  42%|████▏     | 120/285 [02:03<02:21,  1.17it/s]Loading train:  42%|████▏     | 121/285 [02:04<02:38,  1.04it/s]Loading train:  43%|████▎     | 122/285 [02:05<02:40,  1.01it/s]Loading train:  43%|████▎     | 123/285 [02:06<02:44,  1.02s/it]Loading train:  44%|████▎     | 124/285 [02:07<02:33,  1.05it/s]Loading train:  44%|████▍     | 125/285 [02:08<02:23,  1.11it/s]Loading train:  44%|████▍     | 126/285 [02:08<02:10,  1.22it/s]Loading train:  45%|████▍     | 127/285 [02:09<02:06,  1.25it/s]Loading train:  45%|████▍     | 128/285 [02:10<02:02,  1.28it/s]Loading train:  45%|████▌     | 129/285 [02:11<01:57,  1.32it/s]Loading train:  46%|████▌     | 130/285 [02:11<01:55,  1.35it/s]Loading train:  46%|████▌     | 131/285 [02:12<01:52,  1.37it/s]Loading train:  46%|████▋     | 132/285 [02:13<01:53,  1.35it/s]Loading train:  47%|████▋     | 133/285 [02:13<01:48,  1.40it/s]Loading train:  47%|████▋     | 134/285 [02:14<01:49,  1.38it/s]Loading train:  47%|████▋     | 135/285 [02:15<01:49,  1.37it/s]Loading train:  48%|████▊     | 136/285 [02:16<01:45,  1.42it/s]Loading train:  48%|████▊     | 137/285 [02:16<01:49,  1.35it/s]Loading train:  48%|████▊     | 138/285 [02:17<01:48,  1.36it/s]Loading train:  49%|████▉     | 139/285 [02:18<01:49,  1.33it/s]Loading train:  49%|████▉     | 140/285 [02:19<01:50,  1.31it/s]Loading train:  49%|████▉     | 141/285 [02:19<01:46,  1.35it/s]Loading train:  50%|████▉     | 142/285 [02:20<01:46,  1.34it/s]Loading train:  50%|█████     | 143/285 [02:21<01:44,  1.36it/s]Loading train:  51%|█████     | 144/285 [02:22<01:46,  1.33it/s]Loading train:  51%|█████     | 145/285 [02:22<01:44,  1.34it/s]Loading train:  51%|█████     | 146/285 [02:23<01:42,  1.35it/s]Loading train:  52%|█████▏    | 147/285 [02:24<01:40,  1.38it/s]Loading train:  52%|█████▏    | 148/285 [02:25<01:42,  1.34it/s]Loading train:  52%|█████▏    | 149/285 [02:25<01:42,  1.33it/s]Loading train:  53%|█████▎    | 150/285 [02:26<01:39,  1.36it/s]Loading train:  53%|█████▎    | 151/285 [02:27<01:43,  1.29it/s]Loading train:  53%|█████▎    | 152/285 [02:28<01:41,  1.31it/s]Loading train:  54%|█████▎    | 153/285 [02:28<01:40,  1.31it/s]Loading train:  54%|█████▍    | 154/285 [02:29<01:41,  1.29it/s]Loading train:  54%|█████▍    | 155/285 [02:30<01:39,  1.31it/s]Loading train:  55%|█████▍    | 156/285 [02:31<01:39,  1.30it/s]Loading train:  55%|█████▌    | 157/285 [02:31<01:38,  1.30it/s]Loading train:  55%|█████▌    | 158/285 [02:32<01:39,  1.27it/s]Loading train:  56%|█████▌    | 159/285 [02:33<01:37,  1.29it/s]Loading train:  56%|█████▌    | 160/285 [02:34<01:33,  1.34it/s]Loading train:  56%|█████▋    | 161/285 [02:35<01:37,  1.27it/s]Loading train:  57%|█████▋    | 162/285 [02:35<01:33,  1.32it/s]Loading train:  57%|█████▋    | 163/285 [02:36<01:33,  1.31it/s]Loading train:  58%|█████▊    | 164/285 [02:37<01:29,  1.36it/s]Loading train:  58%|█████▊    | 165/285 [02:37<01:25,  1.40it/s]Loading train:  58%|█████▊    | 166/285 [02:38<01:25,  1.39it/s]Loading train:  59%|█████▊    | 167/285 [02:39<01:26,  1.37it/s]Loading train:  59%|█████▉    | 168/285 [02:40<01:24,  1.38it/s]Loading train:  59%|█████▉    | 169/285 [02:40<01:20,  1.43it/s]Loading train:  60%|█████▉    | 170/285 [02:41<01:21,  1.41it/s]Loading train:  60%|██████    | 171/285 [02:42<01:23,  1.37it/s]Loading train:  60%|██████    | 172/285 [02:42<01:21,  1.39it/s]Loading train:  61%|██████    | 173/285 [02:43<01:20,  1.40it/s]Loading train:  61%|██████    | 174/285 [02:44<01:24,  1.31it/s]Loading train:  61%|██████▏   | 175/285 [02:45<01:25,  1.29it/s]Loading train:  62%|██████▏   | 176/285 [02:46<01:26,  1.26it/s]Loading train:  62%|██████▏   | 177/285 [02:46<01:24,  1.28it/s]Loading train:  62%|██████▏   | 178/285 [02:47<01:22,  1.30it/s]Loading train:  63%|██████▎   | 179/285 [02:48<01:21,  1.31it/s]Loading train:  63%|██████▎   | 180/285 [02:49<01:26,  1.21it/s]Loading train:  64%|██████▎   | 181/285 [02:50<01:24,  1.23it/s]Loading train:  64%|██████▍   | 182/285 [02:50<01:23,  1.24it/s]Loading train:  64%|██████▍   | 183/285 [02:51<01:21,  1.26it/s]Loading train:  65%|██████▍   | 184/285 [02:52<01:18,  1.28it/s]Loading train:  65%|██████▍   | 185/285 [02:53<01:16,  1.31it/s]Loading train:  65%|██████▌   | 186/285 [02:54<01:20,  1.23it/s]Loading train:  66%|██████▌   | 187/285 [02:55<01:23,  1.18it/s]Loading train:  66%|██████▌   | 188/285 [02:56<01:27,  1.11it/s]Loading train:  66%|██████▋   | 189/285 [02:56<01:21,  1.17it/s]Loading train:  67%|██████▋   | 190/285 [02:57<01:18,  1.21it/s]Loading train:  67%|██████▋   | 191/285 [02:58<01:17,  1.21it/s]Loading train:  67%|██████▋   | 192/285 [02:59<01:17,  1.20it/s]Loading train:  68%|██████▊   | 193/285 [02:59<01:12,  1.26it/s]Loading train:  68%|██████▊   | 194/285 [03:00<01:11,  1.27it/s]Loading train:  68%|██████▊   | 195/285 [03:01<01:08,  1.31it/s]Loading train:  69%|██████▉   | 196/285 [03:02<01:12,  1.23it/s]Loading train:  69%|██████▉   | 197/285 [03:03<01:16,  1.16it/s]Loading train:  69%|██████▉   | 198/285 [03:04<01:19,  1.10it/s]Loading train:  70%|██████▉   | 199/285 [03:05<01:15,  1.14it/s]Loading train:  70%|███████   | 200/285 [03:05<01:11,  1.19it/s]Loading train:  71%|███████   | 201/285 [03:06<01:13,  1.14it/s]Loading train:  71%|███████   | 202/285 [03:07<01:10,  1.18it/s]Loading train:  71%|███████   | 203/285 [03:08<01:07,  1.22it/s]Loading train:  72%|███████▏  | 204/285 [03:09<01:04,  1.25it/s]Loading train:  72%|███████▏  | 205/285 [03:09<01:01,  1.31it/s]Loading train:  72%|███████▏  | 206/285 [03:10<00:59,  1.32it/s]Loading train:  73%|███████▎  | 207/285 [03:11<01:02,  1.24it/s]Loading train:  73%|███████▎  | 208/285 [03:12<01:03,  1.21it/s]Loading train:  73%|███████▎  | 209/285 [03:13<01:06,  1.15it/s]Loading train:  74%|███████▎  | 210/285 [03:14<01:01,  1.22it/s]Loading train:  74%|███████▍  | 211/285 [03:14<00:58,  1.26it/s]Loading train:  74%|███████▍  | 212/285 [03:15<00:58,  1.24it/s]Loading train:  75%|███████▍  | 213/285 [03:16<00:58,  1.22it/s]Loading train:  75%|███████▌  | 214/285 [03:17<00:55,  1.28it/s]Loading train:  75%|███████▌  | 215/285 [03:18<00:57,  1.22it/s]Loading train:  76%|███████▌  | 216/285 [03:18<00:55,  1.24it/s]Loading train:  76%|███████▌  | 217/285 [03:19<00:57,  1.19it/s]Loading train:  76%|███████▋  | 218/285 [03:20<00:57,  1.16it/s]Loading train:  77%|███████▋  | 219/285 [03:21<00:58,  1.13it/s]Loading train:  77%|███████▋  | 220/285 [03:22<00:56,  1.16it/s]Loading train:  78%|███████▊  | 221/285 [03:23<00:54,  1.18it/s]Loading train:  78%|███████▊  | 222/285 [03:24<00:52,  1.20it/s]Loading train:  78%|███████▊  | 223/285 [03:24<00:48,  1.29it/s]Loading train:  79%|███████▊  | 224/285 [03:25<00:46,  1.32it/s]Loading train:  79%|███████▉  | 225/285 [03:26<00:43,  1.37it/s]Loading train:  79%|███████▉  | 226/285 [03:26<00:46,  1.27it/s]Loading train:  80%|███████▉  | 227/285 [03:27<00:46,  1.24it/s]Loading train:  80%|████████  | 228/285 [03:28<00:47,  1.19it/s]Loading train:  80%|████████  | 229/285 [03:29<00:47,  1.19it/s]Loading train:  81%|████████  | 230/285 [03:30<00:43,  1.25it/s]Loading train:  81%|████████  | 231/285 [03:31<00:41,  1.29it/s]Loading train:  81%|████████▏ | 232/285 [03:31<00:40,  1.30it/s]Loading train:  82%|████████▏ | 233/285 [03:32<00:40,  1.29it/s]Loading train:  82%|████████▏ | 234/285 [03:33<00:42,  1.21it/s]Loading train:  82%|████████▏ | 235/285 [03:34<00:39,  1.26it/s]Loading train:  83%|████████▎ | 236/285 [03:35<00:41,  1.19it/s]Loading train:  83%|████████▎ | 237/285 [03:36<00:40,  1.18it/s]Loading train:  84%|████████▎ | 238/285 [03:36<00:40,  1.15it/s]Loading train:  84%|████████▍ | 239/285 [03:37<00:37,  1.22it/s]Loading train:  84%|████████▍ | 240/285 [03:38<00:36,  1.24it/s]Loading train:  85%|████████▍ | 241/285 [03:39<00:33,  1.30it/s]Loading train:  85%|████████▍ | 242/285 [03:39<00:31,  1.36it/s]Loading train:  85%|████████▌ | 243/285 [03:40<00:31,  1.35it/s]Loading train:  86%|████████▌ | 244/285 [03:41<00:32,  1.25it/s]Loading train:  86%|████████▌ | 245/285 [03:42<00:31,  1.28it/s]Loading train:  86%|████████▋ | 246/285 [03:43<00:32,  1.22it/s]Loading train:  87%|████████▋ | 247/285 [03:44<00:32,  1.16it/s]Loading train:  87%|████████▋ | 248/285 [03:44<00:31,  1.18it/s]Loading train:  87%|████████▋ | 249/285 [03:45<00:29,  1.23it/s]Loading train:  88%|████████▊ | 250/285 [03:46<00:28,  1.23it/s]Loading train:  88%|████████▊ | 251/285 [03:47<00:27,  1.22it/s]Loading train:  88%|████████▊ | 252/285 [03:48<00:26,  1.25it/s]Loading train:  89%|████████▉ | 253/285 [03:48<00:27,  1.18it/s]Loading train:  89%|████████▉ | 254/285 [03:49<00:27,  1.14it/s]Loading train:  89%|████████▉ | 255/285 [03:50<00:25,  1.17it/s]Loading train:  90%|████████▉ | 256/285 [03:51<00:23,  1.24it/s]Loading train:  90%|█████████ | 257/285 [03:52<00:22,  1.26it/s]Loading train:  91%|█████████ | 258/285 [03:53<00:22,  1.18it/s]Loading train:  91%|█████████ | 259/285 [03:53<00:21,  1.22it/s]Loading train:  91%|█████████ | 260/285 [03:54<00:19,  1.30it/s]Loading train:  92%|█████████▏| 261/285 [03:55<00:18,  1.32it/s]Loading train:  92%|█████████▏| 262/285 [03:56<00:18,  1.27it/s]Loading train:  92%|█████████▏| 263/285 [03:56<00:16,  1.33it/s]Loading train:  93%|█████████▎| 264/285 [03:57<00:17,  1.23it/s]Loading train:  93%|█████████▎| 265/285 [03:58<00:16,  1.19it/s]Loading train:  93%|█████████▎| 266/285 [03:59<00:15,  1.26it/s]Loading train:  94%|█████████▎| 267/285 [04:00<00:14,  1.27it/s]Loading train:  94%|█████████▍| 268/285 [04:01<00:14,  1.19it/s]Loading train:  94%|█████████▍| 269/285 [04:01<00:13,  1.21it/s]Loading train:  95%|█████████▍| 270/285 [04:02<00:12,  1.24it/s]Loading train:  95%|█████████▌| 271/285 [04:03<00:10,  1.29it/s]Loading train:  95%|█████████▌| 272/285 [04:04<00:09,  1.34it/s]Loading train:  96%|█████████▌| 273/285 [04:04<00:08,  1.34it/s]Loading train:  96%|█████████▌| 274/285 [04:05<00:07,  1.38it/s]Loading train:  96%|█████████▋| 275/285 [04:06<00:07,  1.29it/s]Loading train:  97%|█████████▋| 276/285 [04:07<00:07,  1.22it/s]Loading train:  97%|█████████▋| 277/285 [04:08<00:06,  1.24it/s]Loading train:  98%|█████████▊| 278/285 [04:08<00:05,  1.28it/s]Loading train:  98%|█████████▊| 279/285 [04:09<00:04,  1.28it/s]Loading train:  98%|█████████▊| 280/285 [04:10<00:03,  1.32it/s]Loading train:  99%|█████████▊| 281/285 [04:10<00:02,  1.37it/s]Loading train:  99%|█████████▉| 282/285 [04:11<00:02,  1.37it/s]Loading train:  99%|█████████▉| 283/285 [04:12<00:01,  1.26it/s]Loading train: 100%|█████████▉| 284/285 [04:13<00:00,  1.21it/s]Loading train: 100%|██████████| 285/285 [04:14<00:00,  1.15it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:  10%|▉         | 28/285 [00:00<00:00, 263.65it/s]concatenating: train:  21%|██▏       | 61/285 [00:00<00:00, 276.86it/s]concatenating: train:  32%|███▏      | 92/285 [00:00<00:00, 284.52it/s]concatenating: train:  44%|████▍     | 125/285 [00:00<00:00, 295.85it/s]concatenating: train:  56%|█████▌    | 160/285 [00:00<00:00, 308.92it/s]concatenating: train:  68%|██████▊   | 194/285 [00:00<00:00, 317.37it/s]concatenating: train:  80%|████████  | 229/285 [00:00<00:00, 324.34it/s]concatenating: train:  93%|█████████▎| 265/285 [00:00<00:00, 332.87it/s]concatenating: train: 100%|██████████| 285/285 [00:00<00:00, 329.28it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.18s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.18s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.16s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 132.75it/s]2019-07-09 00:31:41.996837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-09 00:31:41.996945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-09 00:31:41.996962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-09 00:31:41.996971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-09 00:31:41.997375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12743 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.36it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.29it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.70it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.32it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.35it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.07it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.38it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.88it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  8.33it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.92it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.67it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.00it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.39it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.75it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.59it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.92it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 10.20it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  6.92it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.27it/s]
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 20)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 21)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 30)   5700        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 30)   8130        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 30)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 40, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 60)   16260       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 60)   32460       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 90)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 90)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 120)  97320       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 120)  129720      activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 120)  480         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 120)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 210)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 210)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 60)   50460       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 60)   81060       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 60)   32460       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 60)   240         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 60)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 210)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 40, 210)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 30)   25230       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 60)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 30)   16230       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 30)   8130        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 30)   120         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 30)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 90)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 80, 90)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 13)   1183        dropout_6[0][0]                  
==================================================================================================
Total params: 507,023
Trainable params: 114,763
Non-trainable params: 392,260
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 27s - loss: 12505.3617 - acc: 0.6947 - mDice: 0.1401 - val_loss: 5936.3873 - val_acc: 0.9056 - val_mDice: 0.2839

Epoch 00001: val_mDice improved from -inf to 0.28389, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 18s - loss: 4826.4669 - acc: 0.8783 - mDice: 0.3860 - val_loss: 5445.7916 - val_acc: 0.9102 - val_mDice: 0.3363

Epoch 00002: val_mDice improved from 0.28389 to 0.33627, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 19s - loss: 3605.2637 - acc: 0.8869 - mDice: 0.4849 - val_loss: 3856.4076 - val_acc: 0.9172 - val_mDice: 0.4371

Epoch 00003: val_mDice improved from 0.33627 to 0.43708, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 19s - loss: 3104.2948 - acc: 0.8943 - mDice: 0.5351 - val_loss: 3529.6391 - val_acc: 0.9228 - val_mDice: 0.4658

Epoch 00004: val_mDice improved from 0.43708 to 0.46580, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 19s - loss: 2824.5899 - acc: 0.9033 - mDice: 0.5656 - val_loss: 3190.9458 - val_acc: 0.9360 - val_mDice: 0.5020

Epoch 00005: val_mDice improved from 0.46580 to 0.50196, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 19s - loss: 2621.6438 - acc: 0.9160 - mDice: 0.5887 - val_loss: 3010.6448 - val_acc: 0.9314 - val_mDice: 0.5209

Epoch 00006: val_mDice improved from 0.50196 to 0.52091, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 19s - loss: 2482.2766 - acc: 0.9221 - mDice: 0.6049 - val_loss: 3107.5036 - val_acc: 0.9381 - val_mDice: 0.5090

Epoch 00007: val_mDice did not improve from 0.52091
Epoch 8/300
 - 19s - loss: 2350.9552 - acc: 0.9251 - mDice: 0.6207 - val_loss: 2823.5670 - val_acc: 0.9389 - val_mDice: 0.5401

Epoch 00008: val_mDice improved from 0.52091 to 0.54014, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 19s - loss: 2254.4515 - acc: 0.9274 - mDice: 0.6329 - val_loss: 2919.2438 - val_acc: 0.9322 - val_mDice: 0.5304

Epoch 00009: val_mDice did not improve from 0.54014
Epoch 10/300
 - 19s - loss: 2193.2507 - acc: 0.9286 - mDice: 0.6407 - val_loss: 2944.2394 - val_acc: 0.9413 - val_mDice: 0.5252

Epoch 00010: val_mDice did not improve from 0.54014
Epoch 11/300
 - 19s - loss: 2123.7449 - acc: 0.9304 - mDice: 0.6496 - val_loss: 2833.2781 - val_acc: 0.9413 - val_mDice: 0.5393

Epoch 00011: val_mDice did not improve from 0.54014
Epoch 12/300
 - 19s - loss: 2054.2854 - acc: 0.9321 - mDice: 0.6588 - val_loss: 2821.1427 - val_acc: 0.9317 - val_mDice: 0.5419

Epoch 00012: val_mDice improved from 0.54014 to 0.54191, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 19s - loss: 1994.9130 - acc: 0.9333 - mDice: 0.6665 - val_loss: 2867.9863 - val_acc: 0.9381 - val_mDice: 0.5371

Epoch 00013: val_mDice did not improve from 0.54191
Epoch 14/300
 - 19s - loss: 1959.8360 - acc: 0.9342 - mDice: 0.6713 - val_loss: 2819.3154 - val_acc: 0.9388 - val_mDice: 0.5410

Epoch 00014: val_mDice did not improve from 0.54191
Epoch 15/300
 - 19s - loss: 1903.7565 - acc: 0.9354 - mDice: 0.6788 - val_loss: 2745.2326 - val_acc: 0.9405 - val_mDice: 0.5500

Epoch 00015: val_mDice improved from 0.54191 to 0.55003, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 18s - loss: 1870.4121 - acc: 0.9362 - mDice: 0.6833 - val_loss: 2640.4595 - val_acc: 0.9433 - val_mDice: 0.5619

Epoch 00016: val_mDice improved from 0.55003 to 0.56190, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 19s - loss: 1831.6628 - acc: 0.9371 - mDice: 0.6888 - val_loss: 3016.6402 - val_acc: 0.9421 - val_mDice: 0.5147

Epoch 00017: val_mDice did not improve from 0.56190
Epoch 18/300
 - 20s - loss: 1800.6400 - acc: 0.9377 - mDice: 0.6930 - val_loss: 2809.9597 - val_acc: 0.9421 - val_mDice: 0.5411

Epoch 00018: val_mDice did not improve from 0.56190
Epoch 19/300
 - 19s - loss: 1767.2706 - acc: 0.9384 - mDice: 0.6976 - val_loss: 2787.7244 - val_acc: 0.9441 - val_mDice: 0.5429

Epoch 00019: val_mDice did not improve from 0.56190
Epoch 20/300
 - 19s - loss: 1735.0820 - acc: 0.9393 - mDice: 0.7022 - val_loss: 2860.5928 - val_acc: 0.9425 - val_mDice: 0.5360

Epoch 00020: val_mDice did not improve from 0.56190
Epoch 21/300
 - 19s - loss: 1716.7150 - acc: 0.9396 - mDice: 0.7049 - val_loss: 2833.4918 - val_acc: 0.9412 - val_mDice: 0.5372

Epoch 00021: val_mDice did not improve from 0.56190
Epoch 22/300
 - 19s - loss: 1687.5410 - acc: 0.9402 - mDice: 0.7089 - val_loss: 2788.7583 - val_acc: 0.9401 - val_mDice: 0.5432

Epoch 00022: val_mDice did not improve from 0.56190
Epoch 23/300
 - 19s - loss: 1664.5337 - acc: 0.9406 - mDice: 0.7122 - val_loss: 2819.1420 - val_acc: 0.9440 - val_mDice: 0.5412

Epoch 00023: val_mDice did not improve from 0.56190
Epoch 24/300
 - 19s - loss: 1643.0021 - acc: 0.9411 - mDice: 0.7153 - val_loss: 2810.8429 - val_acc: 0.9384 - val_mDice: 0.5398

Epoch 00024: val_mDice did not improve from 0.56190
Epoch 25/300
 - 19s - loss: 1621.8240 - acc: 0.9415 - mDice: 0.7183 - val_loss: 2793.0024 - val_acc: 0.9451 - val_mDice: 0.5404

Epoch 00025: val_mDice did not improve from 0.56190
Epoch 26/300
 - 19s - loss: 1605.0890 - acc: 0.9419 - mDice: 0.7207 - val_loss: 3120.6065 - val_acc: 0.9376 - val_mDice: 0.5037

Epoch 00026: val_mDice did not improve from 0.56190
Epoch 27/300
 - 19s - loss: 1581.6050 - acc: 0.9423 - mDice: 0.7241 - val_loss: 3088.2259 - val_acc: 0.9363 - val_mDice: 0.5093

Epoch 00027: val_mDice did not improve from 0.56190
Epoch 28/300
 - 19s - loss: 1567.9113 - acc: 0.9426 - mDice: 0.7262 - val_loss: 3121.3815 - val_acc: 0.9357 - val_mDice: 0.5083

Epoch 00028: val_mDice did not improve from 0.56190
Epoch 29/300
 - 19s - loss: 1552.4529 - acc: 0.9429 - mDice: 0.7284 - val_loss: 2989.8408 - val_acc: 0.9401 - val_mDice: 0.5199

Epoch 00029: val_mDice did not improve from 0.56190
Epoch 30/300
 - 19s - loss: 1534.5473 - acc: 0.9433 - mDice: 0.7311 - val_loss: 2786.3868 - val_acc: 0.9438 - val_mDice: 0.5410

Epoch 00030: val_mDice did not improve from 0.56190
Epoch 31/300
 - 19s - loss: 1515.9439 - acc: 0.9438 - mDice: 0.7337 - val_loss: 2996.8391 - val_acc: 0.9411 - val_mDice: 0.5184

Epoch 00031: val_mDice did not improve from 0.56190
Epoch 32/300
 - 19s - loss: 1499.6733 - acc: 0.9440 - mDice: 0.7362 - val_loss: 3163.8200 - val_acc: 0.9318 - val_mDice: 0.5033

Epoch 00032: val_mDice did not improve from 0.56190
Epoch 33/300
 - 19s - loss: 1492.3199 - acc: 0.9441 - mDice: 0.7373 - val_loss: 2869.5820 - val_acc: 0.9407 - val_mDice: 0.5316

Epoch 00033: val_mDice did not improve from 0.56190
Epoch 34/300
 - 20s - loss: 1481.4247 - acc: 0.9444 - mDice: 0.7389 - val_loss: 2791.1944 - val_acc: 0.9460 - val_mDice: 0.5387

Epoch 00034: val_mDice did not improve from 0.56190
Epoch 35/300
 - 19s - loss: 1456.3276 - acc: 0.9449 - mDice: 0.7427 - val_loss: 3007.2516 - val_acc: 0.9309 - val_mDice: 0.5155

Epoch 00035: val_mDice did not improve from 0.56190
Epoch 36/300
 - 19s - loss: 1449.7320 - acc: 0.9450 - mDice: 0.7436 - val_loss: 2772.4605 - val_acc: 0.9427 - val_mDice: 0.5408

Epoch 00036: val_mDice did not improve from 0.56190
Epoch 37/300
 - 19s - loss: 1446.2429 - acc: 0.9450 - mDice: 0.7441 - val_loss: 2810.2548 - val_acc: 0.9431 - val_mDice: 0.5343

Epoch 00037: val_mDice did not improve from 0.56190
Epoch 38/300
 - 19s - loss: 1432.2498 - acc: 0.9453 - mDice: 0.7463 - val_loss: 2786.7450 - val_acc: 0.9390 - val_mDice: 0.5361

Epoch 00038: val_mDice did not improve from 0.56190
Epoch 39/300
 - 19s - loss: 1419.5774 - acc: 0.9457 - mDice: 0.7481 - val_loss: 3100.6723 - val_acc: 0.9399 - val_mDice: 0.5044

Epoch 00039: val_mDice did not improve from 0.56190
Epoch 40/300
 - 19s - loss: 1412.5056 - acc: 0.9458 - mDice: 0.7492 - val_loss: 2813.1825 - val_acc: 0.9426 - val_mDice: 0.5331

Epoch 00040: val_mDice did not improve from 0.56190
Epoch 41/300
 - 19s - loss: 1398.1886 - acc: 0.9460 - mDice: 0.7514 - val_loss: 3220.6093 - val_acc: 0.9362 - val_mDice: 0.4943

Epoch 00041: val_mDice did not improve from 0.56190
Epoch 42/300
 - 19s - loss: 1393.1895 - acc: 0.9462 - mDice: 0.7521 - val_loss: 2781.3094 - val_acc: 0.9427 - val_mDice: 0.5352

Epoch 00042: val_mDice did not improve from 0.56190
Epoch 43/300
 - 18s - loss: 1379.8848 - acc: 0.9464 - mDice: 0.7541 - val_loss: 3007.2431 - val_acc: 0.9412 - val_mDice: 0.5161

Epoch 00043: val_mDice did not improve from 0.56190
Epoch 44/300
 - 18s - loss: 1375.3746 - acc: 0.9465 - mDice: 0.7549 - val_loss: 2989.4735 - val_acc: 0.9363 - val_mDice: 0.5151

Epoch 00044: val_mDice did not improve from 0.56190
Epoch 45/300
 - 19s - loss: 1355.4838 - acc: 0.9468 - mDice: 0.7578 - val_loss: 2889.4931 - val_acc: 0.9419 - val_mDice: 0.5247

Epoch 00045: val_mDice did not improve from 0.56190
Epoch 46/300
 - 19s - loss: 1354.5520 - acc: 0.9470 - mDice: 0.7580 - val_loss: 2914.4660 - val_acc: 0.9377 - val_mDice: 0.5220

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.58s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.28s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  2.06s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:56,  1.89s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:14,  1.75s/it]predicting train subjects:   1%|          | 3/285 [00:04<08:06,  1.72s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:37,  1.63s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:03,  1.73s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:54,  1.70s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<08:10,  1.76s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:56,  1.72s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:26,  1.83s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:41,  1.89s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:18,  1.82s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:44,  1.92s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:27,  1.87s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<08:34,  1.90s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:48,  1.96s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<08:53,  1.98s/it]predicting train subjects:   6%|▌         | 17/285 [00:31<08:32,  1.91s/it]predicting train subjects:   6%|▋         | 18/285 [00:33<08:40,  1.95s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<08:23,  1.89s/it]predicting train subjects:   7%|▋         | 20/285 [00:36<08:30,  1.93s/it]predicting train subjects:   7%|▋         | 21/285 [00:38<08:37,  1.96s/it]predicting train subjects:   8%|▊         | 22/285 [00:40<08:09,  1.86s/it]predicting train subjects:   8%|▊         | 23/285 [00:42<08:21,  1.91s/it]predicting train subjects:   8%|▊         | 24/285 [00:44<08:00,  1.84s/it]predicting train subjects:   9%|▉         | 25/285 [00:46<08:07,  1.88s/it]predicting train subjects:   9%|▉         | 26/285 [00:48<08:22,  1.94s/it]predicting train subjects:   9%|▉         | 27/285 [00:49<08:01,  1.87s/it]predicting train subjects:  10%|▉         | 28/285 [00:52<08:18,  1.94s/it]predicting train subjects:  10%|█         | 29/285 [00:54<08:15,  1.94s/it]predicting train subjects:  11%|█         | 30/285 [00:56<08:24,  1.98s/it]predicting train subjects:  11%|█         | 31/285 [00:58<08:30,  2.01s/it]predicting train subjects:  11%|█         | 32/285 [00:59<08:09,  1.93s/it]predicting train subjects:  12%|█▏        | 33/285 [01:01<08:11,  1.95s/it]predicting train subjects:  12%|█▏        | 34/285 [01:03<08:17,  1.98s/it]predicting train subjects:  12%|█▏        | 35/285 [01:05<08:18,  2.00s/it]predicting train subjects:  13%|█▎        | 36/285 [01:07<07:56,  1.91s/it]predicting train subjects:  13%|█▎        | 37/285 [01:09<07:59,  1.93s/it]predicting train subjects:  13%|█▎        | 38/285 [01:11<08:11,  1.99s/it]predicting train subjects:  14%|█▎        | 39/285 [01:13<07:45,  1.89s/it]predicting train subjects:  14%|█▍        | 40/285 [01:15<07:42,  1.89s/it]predicting train subjects:  14%|█▍        | 41/285 [01:17<07:23,  1.82s/it]predicting train subjects:  15%|█▍        | 42/285 [01:18<07:16,  1.80s/it]predicting train subjects:  15%|█▌        | 43/285 [01:20<07:25,  1.84s/it]predicting train subjects:  15%|█▌        | 44/285 [01:22<07:38,  1.90s/it]predicting train subjects:  16%|█▌        | 45/285 [01:24<07:19,  1.83s/it]predicting train subjects:  16%|█▌        | 46/285 [01:26<07:33,  1.90s/it]predicting train subjects:  16%|█▋        | 47/285 [01:28<07:15,  1.83s/it]predicting train subjects:  17%|█▋        | 48/285 [01:30<07:24,  1.87s/it]predicting train subjects:  17%|█▋        | 49/285 [01:32<07:36,  1.93s/it]predicting train subjects:  18%|█▊        | 50/285 [01:34<07:38,  1.95s/it]predicting train subjects:  18%|█▊        | 51/285 [01:36<07:54,  2.03s/it]predicting train subjects:  18%|█▊        | 52/285 [01:38<07:31,  1.94s/it]predicting train subjects:  19%|█▊        | 53/285 [01:40<07:26,  1.93s/it]predicting train subjects:  19%|█▉        | 54/285 [01:42<07:29,  1.95s/it]predicting train subjects:  19%|█▉        | 55/285 [01:43<07:10,  1.87s/it]predicting train subjects:  20%|█▉        | 56/285 [01:45<07:13,  1.89s/it]predicting train subjects:  20%|██        | 57/285 [01:47<06:54,  1.82s/it]predicting train subjects:  20%|██        | 58/285 [01:49<07:03,  1.86s/it]predicting train subjects:  21%|██        | 59/285 [01:51<07:16,  1.93s/it]predicting train subjects:  21%|██        | 60/285 [01:53<07:25,  1.98s/it]predicting train subjects:  21%|██▏       | 61/285 [01:55<07:00,  1.88s/it]predicting train subjects:  22%|██▏       | 62/285 [01:57<07:07,  1.92s/it]predicting train subjects:  22%|██▏       | 63/285 [01:59<07:07,  1.93s/it]predicting train subjects:  22%|██▏       | 64/285 [02:00<06:53,  1.87s/it]predicting train subjects:  23%|██▎       | 65/285 [02:02<07:03,  1.92s/it]predicting train subjects:  23%|██▎       | 66/285 [02:04<06:57,  1.91s/it]predicting train subjects:  24%|██▎       | 67/285 [02:06<06:55,  1.91s/it]predicting train subjects:  24%|██▍       | 68/285 [02:08<06:44,  1.86s/it]predicting train subjects:  24%|██▍       | 69/285 [02:10<06:48,  1.89s/it]predicting train subjects:  25%|██▍       | 70/285 [02:12<06:50,  1.91s/it]predicting train subjects:  25%|██▍       | 71/285 [02:14<07:02,  1.97s/it]predicting train subjects:  25%|██▌       | 72/285 [02:16<06:45,  1.90s/it]predicting train subjects:  26%|██▌       | 73/285 [02:18<06:48,  1.93s/it]predicting train subjects:  26%|██▌       | 74/285 [02:20<06:45,  1.92s/it]predicting train subjects:  26%|██▋       | 75/285 [02:21<06:46,  1.93s/it]predicting train subjects:  27%|██▋       | 76/285 [02:23<06:47,  1.95s/it]predicting train subjects:  27%|██▋       | 77/285 [02:25<06:34,  1.90s/it]predicting train subjects:  27%|██▋       | 78/285 [02:27<06:23,  1.85s/it]predicting train subjects:  28%|██▊       | 79/285 [02:29<06:19,  1.84s/it]predicting train subjects:  28%|██▊       | 80/285 [02:31<06:13,  1.82s/it]predicting train subjects:  28%|██▊       | 81/285 [02:32<06:02,  1.78s/it]predicting train subjects:  29%|██▉       | 82/285 [02:34<06:13,  1.84s/it]predicting train subjects:  29%|██▉       | 83/285 [02:36<06:09,  1.83s/it]predicting train subjects:  29%|██▉       | 84/285 [02:38<05:59,  1.79s/it]predicting train subjects:  30%|██▉       | 85/285 [02:40<06:06,  1.83s/it]predicting train subjects:  30%|███       | 86/285 [02:42<06:14,  1.88s/it]predicting train subjects:  31%|███       | 87/285 [02:44<06:17,  1.90s/it]predicting train subjects:  31%|███       | 88/285 [02:45<06:07,  1.87s/it]predicting train subjects:  31%|███       | 89/285 [02:47<06:10,  1.89s/it]predicting train subjects:  32%|███▏      | 90/285 [02:49<06:10,  1.90s/it]predicting train subjects:  32%|███▏      | 91/285 [02:51<05:58,  1.85s/it]predicting train subjects:  32%|███▏      | 92/285 [02:53<06:07,  1.90s/it]predicting train subjects:  33%|███▎      | 93/285 [02:55<05:58,  1.87s/it]predicting train subjects:  33%|███▎      | 94/285 [02:57<05:54,  1.86s/it]predicting train subjects:  33%|███▎      | 95/285 [02:59<05:55,  1.87s/it]predicting train subjects:  34%|███▎      | 96/285 [03:00<05:47,  1.84s/it]predicting train subjects:  34%|███▍      | 97/285 [03:02<05:48,  1.85s/it]predicting train subjects:  34%|███▍      | 98/285 [03:04<05:45,  1.85s/it]predicting train subjects:  35%|███▍      | 99/285 [03:06<05:41,  1.84s/it]predicting train subjects:  35%|███▌      | 100/285 [03:08<05:42,  1.85s/it]predicting train subjects:  35%|███▌      | 101/285 [03:09<05:27,  1.78s/it]predicting train subjects:  36%|███▌      | 102/285 [03:11<05:27,  1.79s/it]predicting train subjects:  36%|███▌      | 103/285 [03:13<05:13,  1.72s/it]predicting train subjects:  36%|███▋      | 104/285 [03:15<05:16,  1.75s/it]predicting train subjects:  37%|███▋      | 105/285 [03:16<05:19,  1.77s/it]predicting train subjects:  37%|███▋      | 106/285 [03:18<05:17,  1.78s/it]predicting train subjects:  38%|███▊      | 107/285 [03:20<05:17,  1.78s/it]predicting train subjects:  38%|███▊      | 108/285 [03:22<05:05,  1.73s/it]predicting train subjects:  38%|███▊      | 109/285 [03:23<05:07,  1.75s/it]predicting train subjects:  39%|███▊      | 110/285 [03:25<05:12,  1.78s/it]predicting train subjects:  39%|███▉      | 111/285 [03:27<05:04,  1.75s/it]predicting train subjects:  39%|███▉      | 112/285 [03:29<05:06,  1.77s/it]predicting train subjects:  40%|███▉      | 113/285 [03:31<05:09,  1.80s/it]predicting train subjects:  40%|████      | 114/285 [03:32<05:04,  1.78s/it]predicting train subjects:  40%|████      | 115/285 [03:34<05:08,  1.81s/it]predicting train subjects:  41%|████      | 116/285 [03:36<05:06,  1.82s/it]predicting train subjects:  41%|████      | 117/285 [03:38<04:57,  1.77s/it]predicting train subjects:  41%|████▏     | 118/285 [03:39<04:46,  1.71s/it]predicting train subjects:  42%|████▏     | 119/285 [03:41<04:49,  1.74s/it]predicting train subjects:  42%|████▏     | 120/285 [03:43<04:39,  1.70s/it]predicting train subjects:  42%|████▏     | 121/285 [03:44<04:34,  1.68s/it]predicting train subjects:  43%|████▎     | 122/285 [03:46<04:21,  1.60s/it]predicting train subjects:  43%|████▎     | 123/285 [03:47<04:11,  1.55s/it]predicting train subjects:  44%|████▎     | 124/285 [03:49<04:13,  1.58s/it]predicting train subjects:  44%|████▍     | 125/285 [03:50<04:03,  1.52s/it]predicting train subjects:  44%|████▍     | 126/285 [03:52<03:57,  1.49s/it]predicting train subjects:  45%|████▍     | 127/285 [03:53<03:52,  1.47s/it]predicting train subjects:  45%|████▍     | 128/285 [03:55<03:56,  1.51s/it]predicting train subjects:  45%|████▌     | 129/285 [03:56<03:52,  1.49s/it]predicting train subjects:  46%|████▌     | 130/285 [03:58<03:48,  1.47s/it]predicting train subjects:  46%|████▌     | 131/285 [03:59<03:43,  1.45s/it]predicting train subjects:  46%|████▋     | 132/285 [04:01<03:48,  1.50s/it]predicting train subjects:  47%|████▋     | 133/285 [04:02<03:47,  1.50s/it]predicting train subjects:  47%|████▋     | 134/285 [04:03<03:41,  1.46s/it]predicting train subjects:  47%|████▋     | 135/285 [04:05<03:36,  1.44s/it]predicting train subjects:  48%|████▊     | 136/285 [04:06<03:31,  1.42s/it]predicting train subjects:  48%|████▊     | 137/285 [04:08<03:38,  1.47s/it]predicting train subjects:  48%|████▊     | 138/285 [04:09<03:36,  1.47s/it]predicting train subjects:  49%|████▉     | 139/285 [04:11<03:40,  1.51s/it]predicting train subjects:  49%|████▉     | 140/285 [04:12<03:45,  1.55s/it]predicting train subjects:  49%|████▉     | 141/285 [04:14<03:37,  1.51s/it]predicting train subjects:  50%|████▉     | 142/285 [04:15<03:36,  1.51s/it]predicting train subjects:  50%|█████     | 143/285 [04:17<03:34,  1.51s/it]predicting train subjects:  51%|█████     | 144/285 [04:19<03:38,  1.55s/it]predicting train subjects:  51%|█████     | 145/285 [04:20<03:32,  1.52s/it]predicting train subjects:  51%|█████     | 146/285 [04:22<03:32,  1.53s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:23<03:25,  1.49s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:25<03:29,  1.53s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:26<03:23,  1.50s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:27<03:19,  1.48s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:29<03:21,  1.51s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:30<03:18,  1.49s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:32<03:16,  1.49s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:34<03:23,  1.56s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:35<03:18,  1.53s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:37<03:23,  1.58s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:38<03:21,  1.58s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:40<03:16,  1.54s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:41<03:11,  1.52s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:43<03:07,  1.50s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:44<03:12,  1.55s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:46<03:06,  1.52s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:47<03:06,  1.53s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:49<03:02,  1.51s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:50<03:00,  1.50s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:52<03:03,  1.54s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:54<03:02,  1.55s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:55<02:55,  1.50s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:56<02:51,  1.48s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:58<02:49,  1.47s/it]predicting train subjects:  60%|██████    | 171/285 [04:59<02:47,  1.47s/it]predicting train subjects:  60%|██████    | 172/285 [05:01<02:44,  1.46s/it]predicting train subjects:  61%|██████    | 173/285 [05:02<02:46,  1.48s/it]predicting train subjects:  61%|██████    | 174/285 [05:04<02:43,  1.47s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:05<02:49,  1.54s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:07<02:49,  1.55s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:08<02:43,  1.51s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:10<02:37,  1.47s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:11<02:32,  1.44s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:13<02:43,  1.56s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:15<02:42,  1.57s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:16<02:44,  1.59s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:18<02:34,  1.52s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:19<02:29,  1.48s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:20<02:24,  1.45s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:22<02:35,  1.57s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:24<02:42,  1.66s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:26<02:44,  1.69s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:27<02:31,  1.58s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:29<02:24,  1.52s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:30<02:25,  1.55s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:32<02:26,  1.58s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:33<02:18,  1.50s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:34<02:13,  1.47s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:36<02:09,  1.44s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:38<02:20,  1.58s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:40<02:27,  1.67s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:41<02:29,  1.72s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:43<02:18,  1.61s/it]predicting train subjects:  70%|███████   | 200/285 [05:44<02:13,  1.57s/it]predicting train subjects:  71%|███████   | 201/285 [05:46<02:16,  1.63s/it]predicting train subjects:  71%|███████   | 202/285 [05:48<02:15,  1.63s/it]predicting train subjects:  71%|███████   | 203/285 [05:49<02:14,  1.64s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:51<02:05,  1.55s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:52<02:01,  1.52s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:54<01:56,  1.48s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:55<02:03,  1.59s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:57<02:07,  1.66s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:59<02:10,  1.72s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:00<02:01,  1.62s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:02<01:55,  1.57s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:04<01:56,  1.59s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:05<01:57,  1.63s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:07<01:49,  1.55s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:08<01:52,  1.61s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:10<01:43,  1.51s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:11<01:47,  1.59s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:13<01:50,  1.65s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:15<01:55,  1.74s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:17<01:47,  1.65s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:18<01:43,  1.62s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:20<01:43,  1.65s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:21<01:37,  1.57s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:23<01:34,  1.54s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:24<01:29,  1.49s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:26<01:35,  1.61s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:28<01:40,  1.73s/it]predicting train subjects:  80%|████████  | 228/285 [06:30<01:40,  1.76s/it]predicting train subjects:  80%|████████  | 229/285 [06:32<01:38,  1.76s/it]predicting train subjects:  81%|████████  | 230/285 [06:33<01:31,  1.66s/it]predicting train subjects:  81%|████████  | 231/285 [06:34<01:26,  1.60s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:36<01:27,  1.65s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:38<01:22,  1.58s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:40<01:25,  1.67s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:41<01:21,  1.62s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:43<01:24,  1.73s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:45<01:26,  1.80s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:47<01:25,  1.83s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:49<01:22,  1.80s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:50<01:16,  1.69s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:51<01:10,  1.60s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:53<01:07,  1.58s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:54<01:04,  1.53s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:56<01:07,  1.64s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:58<01:03,  1.59s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:00<01:05,  1.68s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:02<01:06,  1.75s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:03<01:03,  1.72s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:05<00:58,  1.63s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:06<00:56,  1.61s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:08<00:52,  1.55s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:09<00:50,  1.53s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:11<00:52,  1.66s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:13<00:53,  1.72s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:15<00:51,  1.72s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:16<00:47,  1.63s/it]predicting train subjects:  90%|█████████ | 257/285 [07:18<00:44,  1.59s/it]predicting train subjects:  91%|█████████ | 258/285 [07:19<00:44,  1.65s/it]predicting train subjects:  91%|█████████ | 259/285 [07:21<00:43,  1.68s/it]predicting train subjects:  91%|█████████ | 260/285 [07:23<00:40,  1.62s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:24<00:38,  1.61s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:26<00:36,  1.58s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:27<00:34,  1.56s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:29<00:35,  1.69s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:31<00:35,  1.78s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:33<00:31,  1.68s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:34<00:29,  1.65s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:36<00:29,  1.72s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:38<00:27,  1.74s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:39<00:24,  1.65s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:41<00:22,  1.61s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:43<00:21,  1.67s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:44<00:19,  1.62s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:46<00:17,  1.57s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:48<00:16,  1.67s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:49<00:15,  1.74s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:51<00:13,  1.66s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:52<00:11,  1.63s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:54<00:09,  1.64s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:56<00:08,  1.61s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:57<00:06,  1.57s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:59<00:04,  1.54s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:01<00:03,  1.66s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:02<00:01,  1.72s/it]predicting train subjects: 100%|██████████| 285/285 [08:04<00:00,  1.78s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:58,  1.90s/it]Loading train:   1%|          | 2/285 [00:03<08:15,  1.75s/it]Loading train:   1%|          | 3/285 [00:04<08:06,  1.73s/it]Loading train:   1%|▏         | 4/285 [00:06<08:04,  1.72s/it]Loading train:   2%|▏         | 5/285 [00:08<08:12,  1.76s/it]Loading train:   2%|▏         | 6/285 [00:09<07:39,  1.65s/it]Loading train:   2%|▏         | 7/285 [00:11<07:48,  1.69s/it]Loading train:   3%|▎         | 8/285 [00:13<07:53,  1.71s/it]Loading train:   3%|▎         | 9/285 [00:15<08:10,  1.78s/it]Loading train:   4%|▎         | 10/285 [00:17<07:56,  1.73s/it]Loading train:   4%|▍         | 11/285 [00:18<07:27,  1.63s/it]Loading train:   4%|▍         | 12/285 [00:20<07:21,  1.62s/it]Loading train:   5%|▍         | 13/285 [00:21<06:51,  1.51s/it]Loading train:   5%|▍         | 14/285 [00:22<06:33,  1.45s/it]Loading train:   5%|▌         | 15/285 [00:23<06:27,  1.44s/it]Loading train:   6%|▌         | 16/285 [00:25<06:52,  1.53s/it]Loading train:   6%|▌         | 17/285 [00:27<06:38,  1.49s/it]Loading train:   6%|▋         | 18/285 [00:28<06:27,  1.45s/it]Loading train:   7%|▋         | 19/285 [00:29<06:30,  1.47s/it]Loading train:   7%|▋         | 20/285 [00:31<06:16,  1.42s/it]Loading train:   7%|▋         | 21/285 [00:32<06:30,  1.48s/it]Loading train:   8%|▊         | 22/285 [00:34<06:27,  1.47s/it]Loading train:   8%|▊         | 23/285 [00:35<06:12,  1.42s/it]Loading train:   8%|▊         | 24/285 [00:37<06:08,  1.41s/it]Loading train:   9%|▉         | 25/285 [00:38<06:17,  1.45s/it]Loading train:   9%|▉         | 26/285 [00:40<06:28,  1.50s/it]Loading train:   9%|▉         | 27/285 [00:41<06:08,  1.43s/it]Loading train:  10%|▉         | 28/285 [00:42<06:06,  1.42s/it]Loading train:  10%|█         | 29/285 [00:44<05:57,  1.40s/it]Loading train:  11%|█         | 30/285 [00:45<06:03,  1.43s/it]Loading train:  11%|█         | 31/285 [00:47<06:09,  1.46s/it]Loading train:  11%|█         | 32/285 [00:48<05:59,  1.42s/it]Loading train:  12%|█▏        | 33/285 [00:49<05:56,  1.41s/it]Loading train:  12%|█▏        | 34/285 [00:51<05:50,  1.39s/it]Loading train:  12%|█▏        | 35/285 [00:52<06:06,  1.47s/it]Loading train:  13%|█▎        | 36/285 [00:54<05:57,  1.43s/it]Loading train:  13%|█▎        | 37/285 [00:55<05:50,  1.41s/it]Loading train:  13%|█▎        | 38/285 [00:57<05:58,  1.45s/it]Loading train:  14%|█▎        | 39/285 [00:58<05:39,  1.38s/it]Loading train:  14%|█▍        | 40/285 [00:59<05:33,  1.36s/it]Loading train:  14%|█▍        | 41/285 [01:01<05:24,  1.33s/it]Loading train:  15%|█▍        | 42/285 [01:02<05:21,  1.32s/it]Loading train:  15%|█▌        | 43/285 [01:03<05:15,  1.30s/it]Loading train:  15%|█▌        | 44/285 [01:04<05:19,  1.33s/it]Loading train:  16%|█▌        | 45/285 [01:06<05:20,  1.34s/it]Loading train:  16%|█▌        | 46/285 [01:07<05:34,  1.40s/it]Loading train:  16%|█▋        | 47/285 [01:08<05:11,  1.31s/it]Loading train:  17%|█▋        | 48/285 [01:10<05:05,  1.29s/it]Loading train:  17%|█▋        | 49/285 [01:11<05:03,  1.29s/it]Loading train:  18%|█▊        | 50/285 [01:12<04:57,  1.27s/it]Loading train:  18%|█▊        | 51/285 [01:14<05:19,  1.37s/it]Loading train:  18%|█▊        | 52/285 [01:15<05:13,  1.35s/it]Loading train:  19%|█▊        | 53/285 [01:17<05:18,  1.37s/it]Loading train:  19%|█▉        | 54/285 [01:18<05:27,  1.42s/it]Loading train:  19%|█▉        | 55/285 [01:19<05:24,  1.41s/it]Loading train:  20%|█▉        | 56/285 [01:21<05:58,  1.57s/it]Loading train:  20%|██        | 57/285 [01:23<06:02,  1.59s/it]Loading train:  20%|██        | 58/285 [01:25<06:21,  1.68s/it]Loading train:  21%|██        | 59/285 [01:27<06:15,  1.66s/it]Loading train:  21%|██        | 60/285 [01:28<06:04,  1.62s/it]Loading train:  21%|██▏       | 61/285 [01:29<05:49,  1.56s/it]Loading train:  22%|██▏       | 62/285 [01:31<05:42,  1.54s/it]Loading train:  22%|██▏       | 63/285 [01:33<05:41,  1.54s/it]Loading train:  22%|██▏       | 64/285 [01:34<05:58,  1.62s/it]Loading train:  23%|██▎       | 65/285 [01:36<06:08,  1.67s/it]Loading train:  23%|██▎       | 66/285 [01:38<06:15,  1.72s/it]Loading train:  24%|██▎       | 67/285 [01:40<06:12,  1.71s/it]Loading train:  24%|██▍       | 68/285 [01:41<05:53,  1.63s/it]Loading train:  24%|██▍       | 69/285 [01:43<05:45,  1.60s/it]Loading train:  25%|██▍       | 70/285 [01:44<05:53,  1.65s/it]Loading train:  25%|██▍       | 71/285 [01:46<06:07,  1.72s/it]Loading train:  25%|██▌       | 72/285 [01:48<05:43,  1.61s/it]Loading train:  26%|██▌       | 73/285 [01:49<05:29,  1.55s/it]Loading train:  26%|██▌       | 74/285 [01:50<05:17,  1.51s/it]Loading train:  26%|██▋       | 75/285 [01:52<05:13,  1.49s/it]Loading train:  27%|██▋       | 76/285 [01:53<05:11,  1.49s/it]Loading train:  27%|██▋       | 77/285 [01:55<05:06,  1.47s/it]Loading train:  27%|██▋       | 78/285 [01:56<04:54,  1.42s/it]Loading train:  28%|██▊       | 79/285 [01:58<04:52,  1.42s/it]Loading train:  28%|██▊       | 80/285 [01:59<04:52,  1.43s/it]Loading train:  28%|██▊       | 81/285 [02:01<05:19,  1.57s/it]Loading train:  29%|██▉       | 82/285 [02:02<05:16,  1.56s/it]Loading train:  29%|██▉       | 83/285 [02:04<05:04,  1.51s/it]Loading train:  29%|██▉       | 84/285 [02:05<04:56,  1.47s/it]Loading train:  30%|██▉       | 85/285 [02:07<04:51,  1.46s/it]Loading train:  30%|███       | 86/285 [02:08<04:53,  1.47s/it]Loading train:  31%|███       | 87/285 [02:10<04:51,  1.47s/it]Loading train:  31%|███       | 88/285 [02:11<04:38,  1.42s/it]Loading train:  31%|███       | 89/285 [02:13<04:52,  1.49s/it]Loading train:  32%|███▏      | 90/285 [02:14<04:55,  1.51s/it]Loading train:  32%|███▏      | 91/285 [02:15<04:42,  1.46s/it]Loading train:  32%|███▏      | 92/285 [02:17<04:40,  1.45s/it]Loading train:  33%|███▎      | 93/285 [02:18<04:30,  1.41s/it]Loading train:  33%|███▎      | 94/285 [02:20<04:36,  1.45s/it]Loading train:  33%|███▎      | 95/285 [02:21<04:53,  1.55s/it]Loading train:  34%|███▎      | 96/285 [02:23<04:46,  1.52s/it]Loading train:  34%|███▍      | 97/285 [02:24<04:38,  1.48s/it]Loading train:  34%|███▍      | 98/285 [02:26<04:24,  1.41s/it]Loading train:  35%|███▍      | 99/285 [02:27<04:09,  1.34s/it]Loading train:  35%|███▌      | 100/285 [02:28<04:08,  1.34s/it]Loading train:  35%|███▌      | 101/285 [02:29<04:07,  1.35s/it]Loading train:  36%|███▌      | 102/285 [02:31<04:10,  1.37s/it]Loading train:  36%|███▌      | 103/285 [02:32<04:08,  1.37s/it]Loading train:  36%|███▋      | 104/285 [02:34<04:14,  1.41s/it]Loading train:  37%|███▋      | 105/285 [02:35<04:24,  1.47s/it]Loading train:  37%|███▋      | 106/285 [02:37<04:14,  1.42s/it]Loading train:  38%|███▊      | 107/285 [02:39<04:35,  1.55s/it]Loading train:  38%|███▊      | 108/285 [02:40<04:40,  1.59s/it]Loading train:  38%|███▊      | 109/285 [02:41<04:24,  1.50s/it]Loading train:  39%|███▊      | 110/285 [02:43<04:42,  1.61s/it]Loading train:  39%|███▉      | 111/285 [02:45<05:02,  1.74s/it]Loading train:  39%|███▉      | 112/285 [02:48<05:25,  1.88s/it]Loading train:  40%|███▉      | 113/285 [02:49<05:13,  1.82s/it]Loading train:  40%|████      | 114/285 [02:51<05:02,  1.77s/it]Loading train:  40%|████      | 115/285 [02:52<04:43,  1.67s/it]Loading train:  41%|████      | 116/285 [02:54<04:31,  1.61s/it]Loading train:  41%|████      | 117/285 [02:55<04:21,  1.56s/it]Loading train:  41%|████▏     | 118/285 [02:57<04:18,  1.55s/it]Loading train:  42%|████▏     | 119/285 [02:59<04:32,  1.64s/it]Loading train:  42%|████▏     | 120/285 [03:00<04:14,  1.54s/it]Loading train:  42%|████▏     | 121/285 [03:01<04:09,  1.52s/it]Loading train:  43%|████▎     | 122/285 [03:03<04:03,  1.50s/it]Loading train:  43%|████▎     | 123/285 [03:04<04:00,  1.48s/it]Loading train:  44%|████▎     | 124/285 [03:06<03:47,  1.41s/it]Loading train:  44%|████▍     | 125/285 [03:07<03:34,  1.34s/it]Loading train:  44%|████▍     | 126/285 [03:08<03:26,  1.30s/it]Loading train:  45%|████▍     | 127/285 [03:09<03:20,  1.27s/it]Loading train:  45%|████▍     | 128/285 [03:10<03:13,  1.23s/it]Loading train:  45%|████▌     | 129/285 [03:12<03:18,  1.27s/it]Loading train:  46%|████▌     | 130/285 [03:13<03:25,  1.33s/it]Loading train:  46%|████▌     | 131/285 [03:15<03:30,  1.37s/it]Loading train:  46%|████▋     | 132/285 [03:16<03:16,  1.28s/it]Loading train:  47%|████▋     | 133/285 [03:17<03:10,  1.25s/it]Loading train:  47%|████▋     | 134/285 [03:18<03:07,  1.24s/it]Loading train:  47%|████▋     | 135/285 [03:19<03:09,  1.27s/it]Loading train:  48%|████▊     | 136/285 [03:21<03:03,  1.23s/it]Loading train:  48%|████▊     | 137/285 [03:22<03:03,  1.24s/it]Loading train:  48%|████▊     | 138/285 [03:23<02:58,  1.22s/it]Loading train:  49%|████▉     | 139/285 [03:24<02:52,  1.18s/it]Loading train:  49%|████▉     | 140/285 [03:25<02:39,  1.10s/it]Loading train:  49%|████▉     | 141/285 [03:26<02:28,  1.03s/it]Loading train:  50%|████▉     | 142/285 [03:27<02:35,  1.08s/it]Loading train:  50%|█████     | 143/285 [03:28<02:43,  1.15s/it]Loading train:  51%|█████     | 144/285 [03:30<02:53,  1.23s/it]Loading train:  51%|█████     | 145/285 [03:31<02:55,  1.25s/it]Loading train:  51%|█████     | 146/285 [03:32<02:41,  1.16s/it]Loading train:  52%|█████▏    | 147/285 [03:33<02:30,  1.09s/it]Loading train:  52%|█████▏    | 148/285 [03:34<02:23,  1.05s/it]Loading train:  52%|█████▏    | 149/285 [03:35<02:14,  1.01it/s]Loading train:  53%|█████▎    | 150/285 [03:36<02:09,  1.04it/s]Loading train:  53%|█████▎    | 151/285 [03:37<02:07,  1.05it/s]Loading train:  53%|█████▎    | 152/285 [03:37<02:04,  1.07it/s]Loading train:  54%|█████▎    | 153/285 [03:38<02:03,  1.07it/s]Loading train:  54%|█████▍    | 154/285 [03:39<02:01,  1.08it/s]Loading train:  54%|█████▍    | 155/285 [03:40<02:00,  1.08it/s]Loading train:  55%|█████▍    | 156/285 [03:41<01:59,  1.08it/s]Loading train:  55%|█████▌    | 157/285 [03:42<02:00,  1.06it/s]Loading train:  55%|█████▌    | 158/285 [03:43<01:58,  1.07it/s]Loading train:  56%|█████▌    | 159/285 [03:44<01:52,  1.12it/s]Loading train:  56%|█████▌    | 160/285 [03:45<01:54,  1.09it/s]Loading train:  56%|█████▋    | 161/285 [03:46<01:55,  1.07it/s]Loading train:  57%|█████▋    | 162/285 [03:47<01:53,  1.08it/s]Loading train:  57%|█████▋    | 163/285 [03:48<01:50,  1.10it/s]Loading train:  58%|█████▊    | 164/285 [03:48<01:48,  1.12it/s]Loading train:  58%|█████▊    | 165/285 [03:49<01:46,  1.13it/s]Loading train:  58%|█████▊    | 166/285 [03:50<01:46,  1.12it/s]Loading train:  59%|█████▊    | 167/285 [03:51<01:45,  1.12it/s]Loading train:  59%|█████▉    | 168/285 [03:52<01:45,  1.11it/s]Loading train:  59%|█████▉    | 169/285 [03:53<01:43,  1.12it/s]Loading train:  60%|█████▉    | 170/285 [03:54<01:41,  1.14it/s]Loading train:  60%|██████    | 171/285 [03:55<01:41,  1.12it/s]Loading train:  60%|██████    | 172/285 [03:56<01:44,  1.08it/s]Loading train:  61%|██████    | 173/285 [03:57<01:41,  1.10it/s]Loading train:  61%|██████    | 174/285 [03:57<01:41,  1.09it/s]Loading train:  61%|██████▏   | 175/285 [03:58<01:39,  1.10it/s]Loading train:  62%|██████▏   | 176/285 [03:59<01:36,  1.13it/s]Loading train:  62%|██████▏   | 177/285 [04:00<01:33,  1.16it/s]Loading train:  62%|██████▏   | 178/285 [04:01<01:32,  1.16it/s]Loading train:  63%|██████▎   | 179/285 [04:02<01:35,  1.11it/s]Loading train:  63%|██████▎   | 180/285 [04:03<01:38,  1.07it/s]Loading train:  64%|██████▎   | 181/285 [04:04<01:40,  1.04it/s]Loading train:  64%|██████▍   | 182/285 [04:05<01:42,  1.01it/s]Loading train:  64%|██████▍   | 183/285 [04:06<01:43,  1.02s/it]Loading train:  65%|██████▍   | 184/285 [04:07<01:40,  1.00it/s]Loading train:  65%|██████▍   | 185/285 [04:08<01:36,  1.04it/s]Loading train:  65%|██████▌   | 186/285 [04:09<01:38,  1.00it/s]Loading train:  66%|██████▌   | 187/285 [04:10<01:41,  1.04s/it]Loading train:  66%|██████▌   | 188/285 [04:11<01:41,  1.05s/it]Loading train:  66%|██████▋   | 189/285 [04:12<01:36,  1.00s/it]Loading train:  67%|██████▋   | 190/285 [04:13<01:33,  1.02it/s]Loading train:  67%|██████▋   | 191/285 [04:14<01:32,  1.01it/s]Loading train:  67%|██████▋   | 192/285 [04:15<01:30,  1.03it/s]Loading train:  68%|██████▊   | 193/285 [04:16<01:28,  1.04it/s]Loading train:  68%|██████▊   | 194/285 [04:17<01:24,  1.07it/s]Loading train:  68%|██████▊   | 195/285 [04:18<01:22,  1.09it/s]Loading train:  69%|██████▉   | 196/285 [04:19<01:26,  1.02it/s]Loading train:  69%|██████▉   | 197/285 [04:20<01:29,  1.01s/it]Loading train:  69%|██████▉   | 198/285 [04:21<01:27,  1.01s/it]Loading train:  70%|██████▉   | 199/285 [04:22<01:23,  1.03it/s]Loading train:  70%|███████   | 200/285 [04:23<01:19,  1.07it/s]Loading train:  71%|███████   | 201/285 [04:24<01:22,  1.02it/s]Loading train:  71%|███████   | 202/285 [04:25<01:22,  1.01it/s]Loading train:  71%|███████   | 203/285 [04:26<01:18,  1.05it/s]Loading train:  72%|███████▏  | 204/285 [04:26<01:14,  1.09it/s]Loading train:  72%|███████▏  | 205/285 [04:27<01:12,  1.10it/s]Loading train:  72%|███████▏  | 206/285 [04:28<01:11,  1.11it/s]Loading train:  73%|███████▎  | 207/285 [04:29<01:12,  1.08it/s]Loading train:  73%|███████▎  | 208/285 [04:30<01:15,  1.03it/s]Loading train:  73%|███████▎  | 209/285 [04:31<01:15,  1.00it/s]Loading train:  74%|███████▎  | 210/285 [04:32<01:11,  1.05it/s]Loading train:  74%|███████▍  | 211/285 [04:33<01:09,  1.06it/s]Loading train:  74%|███████▍  | 212/285 [04:34<01:10,  1.03it/s]Loading train:  75%|███████▍  | 213/285 [04:35<01:09,  1.04it/s]Loading train:  75%|███████▌  | 214/285 [04:36<01:06,  1.07it/s]Loading train:  75%|███████▌  | 215/285 [04:37<01:07,  1.04it/s]Loading train:  76%|███████▌  | 216/285 [04:38<01:04,  1.07it/s]Loading train:  76%|███████▌  | 217/285 [04:39<01:06,  1.02it/s]Loading train:  76%|███████▋  | 218/285 [04:40<01:06,  1.01it/s]Loading train:  77%|███████▋  | 219/285 [04:41<01:06,  1.00s/it]Loading train:  77%|███████▋  | 220/285 [04:42<01:03,  1.02it/s]Loading train:  78%|███████▊  | 221/285 [04:43<00:59,  1.07it/s]Loading train:  78%|███████▊  | 222/285 [04:44<00:59,  1.07it/s]Loading train:  78%|███████▊  | 223/285 [04:44<00:56,  1.10it/s]Loading train:  79%|███████▊  | 224/285 [04:45<00:56,  1.08it/s]Loading train:  79%|███████▉  | 225/285 [04:46<00:52,  1.14it/s]Loading train:  79%|███████▉  | 226/285 [04:47<00:56,  1.05it/s]Loading train:  80%|███████▉  | 227/285 [04:48<00:57,  1.01it/s]Loading train:  80%|████████  | 228/285 [04:49<00:58,  1.02s/it]Loading train:  80%|████████  | 229/285 [04:50<00:56,  1.01s/it]Loading train:  81%|████████  | 230/285 [04:51<00:53,  1.02it/s]Loading train:  81%|████████  | 231/285 [04:52<00:49,  1.08it/s]Loading train:  81%|████████▏ | 232/285 [04:53<00:47,  1.11it/s]Loading train:  82%|████████▏ | 233/285 [04:54<00:46,  1.11it/s]Loading train:  82%|████████▏ | 234/285 [04:55<00:48,  1.05it/s]Loading train:  82%|████████▏ | 235/285 [04:56<00:45,  1.10it/s]Loading train:  83%|████████▎ | 236/285 [04:57<00:47,  1.04it/s]Loading train:  83%|████████▎ | 237/285 [04:58<00:48,  1.01s/it]Loading train:  84%|████████▎ | 238/285 [04:59<00:48,  1.02s/it]Loading train:  84%|████████▍ | 239/285 [05:00<00:45,  1.01it/s]Loading train:  84%|████████▍ | 240/285 [05:01<00:43,  1.03it/s]Loading train:  85%|████████▍ | 241/285 [05:02<00:42,  1.04it/s]Loading train:  85%|████████▍ | 242/285 [05:03<00:39,  1.08it/s]Loading train:  85%|████████▌ | 243/285 [05:03<00:37,  1.11it/s]Loading train:  86%|████████▌ | 244/285 [05:05<00:38,  1.05it/s]Loading train:  86%|████████▌ | 245/285 [05:05<00:36,  1.09it/s]Loading train:  86%|████████▋ | 246/285 [05:07<00:39,  1.03s/it]Loading train:  87%|████████▋ | 247/285 [05:08<00:38,  1.02s/it]Loading train:  87%|████████▋ | 248/285 [05:09<00:38,  1.05s/it]Loading train:  87%|████████▋ | 249/285 [05:10<00:37,  1.03s/it]Loading train:  88%|████████▊ | 250/285 [05:11<00:33,  1.03it/s]Loading train:  88%|████████▊ | 251/285 [05:11<00:32,  1.06it/s]Loading train:  88%|████████▊ | 252/285 [05:12<00:31,  1.05it/s]Loading train:  89%|████████▉ | 253/285 [05:14<00:31,  1.01it/s]Loading train:  89%|████████▉ | 254/285 [05:15<00:30,  1.01it/s]Loading train:  89%|████████▉ | 255/285 [05:16<00:29,  1.01it/s]Loading train:  90%|████████▉ | 256/285 [05:16<00:28,  1.03it/s]Loading train:  90%|█████████ | 257/285 [05:17<00:26,  1.05it/s]Loading train:  91%|█████████ | 258/285 [05:18<00:26,  1.02it/s]Loading train:  91%|█████████ | 259/285 [05:19<00:25,  1.03it/s]Loading train:  91%|█████████ | 260/285 [05:20<00:23,  1.07it/s]Loading train:  92%|█████████▏| 261/285 [05:21<00:21,  1.11it/s]Loading train:  92%|█████████▏| 262/285 [05:22<00:19,  1.15it/s]Loading train:  92%|█████████▏| 263/285 [05:23<00:19,  1.16it/s]Loading train:  93%|█████████▎| 264/285 [05:24<00:19,  1.09it/s]Loading train:  93%|█████████▎| 265/285 [05:25<00:18,  1.07it/s]Loading train:  93%|█████████▎| 266/285 [05:25<00:16,  1.13it/s]Loading train:  94%|█████████▎| 267/285 [05:26<00:15,  1.17it/s]Loading train:  94%|█████████▍| 268/285 [05:27<00:15,  1.13it/s]Loading train:  94%|█████████▍| 269/285 [05:28<00:14,  1.12it/s]Loading train:  95%|█████████▍| 270/285 [05:29<00:13,  1.14it/s]Loading train:  95%|█████████▌| 271/285 [05:30<00:11,  1.18it/s]Loading train:  95%|█████████▌| 272/285 [05:31<00:11,  1.17it/s]Loading train:  96%|█████████▌| 273/285 [05:31<00:10,  1.16it/s]Loading train:  96%|█████████▌| 274/285 [05:32<00:09,  1.16it/s]Loading train:  96%|█████████▋| 275/285 [05:33<00:09,  1.08it/s]Loading train:  97%|█████████▋| 276/285 [05:34<00:08,  1.03it/s]Loading train:  97%|█████████▋| 277/285 [05:35<00:07,  1.08it/s]Loading train:  98%|█████████▊| 278/285 [05:36<00:06,  1.07it/s]Loading train:  98%|█████████▊| 279/285 [05:37<00:05,  1.06it/s]Loading train:  98%|█████████▊| 280/285 [05:38<00:04,  1.07it/s]Loading train:  99%|█████████▊| 281/285 [05:39<00:03,  1.10it/s]Loading train:  99%|█████████▉| 282/285 [05:40<00:02,  1.13it/s]Loading train:  99%|█████████▉| 283/285 [05:41<00:01,  1.00it/s]Loading train: 100%|█████████▉| 284/285 [05:42<00:01,  1.02s/it]Loading train: 100%|██████████| 285/285 [05:43<00:00,  1.06s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   8%|▊         | 24/285 [00:00<00:01, 238.87it/s]concatenating: train:  19%|█▉        | 54/285 [00:00<00:00, 252.40it/s]concatenating: train:  28%|██▊       | 81/285 [00:00<00:00, 256.00it/s]concatenating: train:  39%|███▉      | 111/285 [00:00<00:00, 266.45it/s]concatenating: train:  48%|████▊     | 138/285 [00:00<00:00, 267.08it/s]concatenating: train:  59%|█████▉    | 169/285 [00:00<00:00, 278.45it/s]concatenating: train:  69%|██████▉   | 197/285 [00:00<00:00, 278.20it/s]concatenating: train:  81%|████████  | 230/285 [00:00<00:00, 289.94it/s]concatenating: train:  91%|█████████ | 259/285 [00:00<00:00, 288.90it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 283.24it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.42s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.39s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.33s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 105.90it/s]2019-07-09 01:01:00.788925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-09 01:01:00.789029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-09 01:01:00.789046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-09 01:01:00.789055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-09 01:01:00.789456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12743 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.46it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.56it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  6.03it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  7.18it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  6.36it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.22it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  6.41it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.31it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.74it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.11it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.75it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.07it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.19it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  6.71it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.52it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.03it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.44it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.50it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.27it/s]
Epoch 00046: val_mDice did not improve from 0.56190
Restoring model weights from the end of the best epoch
Epoch 00046: early stopping
{'val_loss': [5936.387253534226, 5445.791596912202, 3856.4076334635415, 3529.639136904762, 3190.9457891555057, 3010.644821893601, 3107.503615606399, 2823.566964285714, 2919.2438383556546, 2944.2394089471727, 2833.278122674851, 2821.1427176339284, 2867.9862932477677, 2819.3153948102677, 2745.2325846354165, 2640.459495907738, 3016.6402180989585, 2809.9596586681546, 2787.7243536086307, 2860.5927734375, 2833.4917805989585, 2788.75830078125, 2819.142020089286, 2810.8429013206846, 2793.002400716146, 3120.6065034412204, 3088.225876581101, 3121.3814987909227, 2989.8408319382443, 2786.3867943173364, 2996.839128766741, 3163.8199753534227, 2869.581990559896, 2791.1944289434523, 3007.2516159784227, 2772.4605480375744, 2810.254818870908, 2786.7450067429318, 3100.67234874907, 2813.1824544270835, 3220.609337216332, 2781.309390113467, 3007.243146623884, 2989.4735369001114, 2889.4930666968935, 2914.4660368419827], 'val_acc': [0.9056478880700611, 0.9102174668085008, 0.9172115666525704, 0.9227518467676072, 0.9359660943349203, 0.9313553287869408, 0.9380608938989186, 0.938878181434813, 0.9322115126110259, 0.9413232633045742, 0.9413346790132069, 0.9317079044523693, 0.9381021119299389, 0.9388209552991957, 0.940526564915975, 0.9433035481543768, 0.942145171619597, 0.9420925094967797, 0.9441460853531247, 0.942538925579616, 0.941195045198713, 0.9400755535988581, 0.9440155568576994, 0.9383562491053626, 0.9451121716272264, 0.9375961394537062, 0.9363209860665458, 0.9357143129621234, 0.940103014310201, 0.9438461774871463, 0.9410828664189294, 0.9318223396937052, 0.9407165589786711, 0.9460233591851734, 0.9308997250738598, 0.9426831234069097, 0.9430860877037048, 0.9389926592508951, 0.9399084448814392, 0.9425938498406183, 0.9362294021106902, 0.9426579787617638, 0.9411561262039911, 0.93627058892023, 0.9418795761607942, 0.937676265126183], 'val_mDice': [0.28388627124063315, 0.3362733083111899, 0.43708165056471315, 0.46580496341699645, 0.5019565458808627, 0.5209098376688504, 0.5090302894158023, 0.5401350477976459, 0.5303912749957471, 0.5252307608191457, 0.5392701448429198, 0.5419074337752092, 0.5370652063616684, 0.5410238999341216, 0.5500289712633405, 0.5618985556066036, 0.5146702506712505, 0.5410703257435844, 0.5429392041904586, 0.5360362698279676, 0.5372419357299805, 0.5432482473552227, 0.541156621561164, 0.5398185480208624, 0.5403668756286303, 0.5037311879651887, 0.5092856789983454, 0.5082757210447675, 0.519901457641806, 0.5409505271485874, 0.5183973748769078, 0.5032749055396943, 0.5315501274807113, 0.5387248822620937, 0.5154828470022905, 0.5407935572522027, 0.534298278568756, 0.5361452311986968, 0.504400500052032, 0.5330592031989779, 0.4942849303285281, 0.5352101829789934, 0.516094385158448, 0.5150849613405409, 0.5247491184799444, 0.5219722031837418], 'loss': [12505.361705043859, 4826.466887103953, 3605.263693620319, 3104.294791403087, 2824.5899461930444, 2621.6438253272904, 2482.276624083496, 2350.9551511977434, 2254.4515002434346, 2193.2506671388505, 2123.744943625026, 2054.285433926425, 1994.9130376459477, 1959.8359635755555, 1903.7564844823146, 1870.4121144112535, 1831.6628454916965, 1800.6399719108845, 1767.2705878042086, 1735.0819852647694, 1716.7149652790329, 1687.5409550016868, 1664.5337142576618, 1643.002095199123, 1621.8240089453275, 1605.088961158342, 1581.6049965424002, 1567.9112522705502, 1552.45288511901, 1534.5472902320405, 1515.9439132452148, 1499.673267806498, 1492.319872792709, 1481.4246949724823, 1456.3275542089148, 1449.7319573865177, 1446.2428620990954, 1432.24976640256, 1419.577356312393, 1412.5055546816636, 1398.1885854420646, 1393.189454066356, 1379.8847800512776, 1375.3745819674261, 1355.4838475112813, 1354.551951155213], 'acc': [0.694710703430572, 0.8782993004297691, 0.8869422096978131, 0.894302787775246, 0.9033419110422445, 0.9160278653257358, 0.9221093829068371, 0.9251194508383217, 0.9273705495353008, 0.9285898024874523, 0.9304331248151744, 0.9320637016528968, 0.9333327985094856, 0.9341603833883972, 0.9353740766877174, 0.9362239288024321, 0.9371271626738332, 0.9376986504796155, 0.9384189022168824, 0.9392964441421888, 0.9395836553225196, 0.9401568117825677, 0.9405810446989245, 0.9411410371393557, 0.9415355848742055, 0.9418720853266652, 0.9422756696519582, 0.942638818321831, 0.9428776494335618, 0.9433047756860085, 0.9437524813067736, 0.9440101756395943, 0.9441232732410074, 0.9444113257006227, 0.9448870176383704, 0.9450082094287376, 0.9450398340077214, 0.9453490888748367, 0.9456825956044363, 0.9457819841375511, 0.9459910125017212, 0.9461533594319925, 0.9463764589164261, 0.9465131507757336, 0.9468033280886504, 0.9470123148892963], 'mDice': [0.1400736349476643, 0.3860117721952913, 0.4849251393111703, 0.5350599151735984, 0.5656443715371308, 0.5886835390509773, 0.6048579353092952, 0.6206974126319562, 0.6329006683580536, 0.6407243435222426, 0.6496369574303017, 0.6587825372128535, 0.666508630909211, 0.6712539594872553, 0.6787934482315958, 0.6833303474911104, 0.6887527137150166, 0.693031395690529, 0.6975664418741575, 0.7022207942522857, 0.704855363838287, 0.7088705828499192, 0.7122137334527412, 0.7153139044743456, 0.718295228672046, 0.7207491005434566, 0.7240741954664286, 0.7262309889171035, 0.7283901401124112, 0.7310760155196637, 0.733712805393047, 0.7361569862984406, 0.7372695270337557, 0.7388759143830081, 0.742657089109294, 0.7435956637317421, 0.7440919379910362, 0.7462560254207852, 0.7480760623844736, 0.749211359798552, 0.751371126448876, 0.752094542196497, 0.754122300071709, 0.7549022739738404, 0.7578382957342481, 0.7580117326907071]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 20)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 21)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   3800        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 13)   793         dropout_6[0][0]                  
==================================================================================================
Total params: 227,713
Trainable params: 52,993
Non-trainable params: 174,720
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 29s - loss: 11476.4365 - acc: 0.8004 - mDice: 0.1759 - val_loss: 11198.3705 - val_acc: 0.9140 - val_mDice: 0.1928

Epoch 00001: val_mDice improved from -inf to 0.19282, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 21s - loss: 4461.2406 - acc: 0.8990 - mDice: 0.4107 - val_loss: 3473.4766 - val_acc: 0.9272 - val_mDice: 0.4683

Epoch 00002: val_mDice improved from 0.19282 to 0.46835, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 21s - loss: 3504.6871 - acc: 0.9143 - mDice: 0.4958 - val_loss: 2862.8008 - val_acc: 0.9366 - val_mDice: 0.5300

Epoch 00003: val_mDice improved from 0.46835 to 0.53002, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 21s - loss: 3050.7692 - acc: 0.9233 - mDice: 0.5431 - val_loss: 2851.7437 - val_acc: 0.9395 - val_mDice: 0.5311

Epoch 00004: val_mDice improved from 0.53002 to 0.53113, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 21s - loss: 2759.2202 - acc: 0.9285 - mDice: 0.5737 - val_loss: 2636.6882 - val_acc: 0.9379 - val_mDice: 0.5520

Epoch 00005: val_mDice improved from 0.53113 to 0.55196, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 21s - loss: 2557.1743 - acc: 0.9322 - mDice: 0.5965 - val_loss: 2616.0157 - val_acc: 0.9457 - val_mDice: 0.5576

Epoch 00006: val_mDice improved from 0.55196 to 0.55764, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 21s - loss: 2420.3755 - acc: 0.9349 - mDice: 0.6132 - val_loss: 2280.4443 - val_acc: 0.9490 - val_mDice: 0.5999

Epoch 00007: val_mDice improved from 0.55764 to 0.59991, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 20s - loss: 2302.3538 - acc: 0.9369 - mDice: 0.6274 - val_loss: 2747.8803 - val_acc: 0.9477 - val_mDice: 0.5510

Epoch 00008: val_mDice did not improve from 0.59991
Epoch 9/300
 - 20s - loss: 2220.4475 - acc: 0.9385 - mDice: 0.6380 - val_loss: 2342.7858 - val_acc: 0.9470 - val_mDice: 0.5912

Epoch 00009: val_mDice did not improve from 0.59991
Epoch 10/300
 - 20s - loss: 2151.6929 - acc: 0.9398 - mDice: 0.6467 - val_loss: 2430.4844 - val_acc: 0.9485 - val_mDice: 0.5818

Epoch 00010: val_mDice did not improve from 0.59991
Epoch 11/300
 - 21s - loss: 2089.7470 - acc: 0.9409 - mDice: 0.6547 - val_loss: 2418.7972 - val_acc: 0.9488 - val_mDice: 0.5834

Epoch 00011: val_mDice did not improve from 0.59991
Epoch 12/300
 - 21s - loss: 2044.4778 - acc: 0.9419 - mDice: 0.6607 - val_loss: 2400.4446 - val_acc: 0.9456 - val_mDice: 0.5820

Epoch 00012: val_mDice did not improve from 0.59991
Epoch 13/300
 - 20s - loss: 2000.0653 - acc: 0.9426 - mDice: 0.6664 - val_loss: 2285.0254 - val_acc: 0.9467 - val_mDice: 0.5977

Epoch 00013: val_mDice did not improve from 0.59991
Epoch 14/300
 - 20s - loss: 1963.5976 - acc: 0.9433 - mDice: 0.6713 - val_loss: 2464.5174 - val_acc: 0.9486 - val_mDice: 0.5793

Epoch 00014: val_mDice did not improve from 0.59991
Epoch 15/300
 - 20s - loss: 1910.9351 - acc: 0.9444 - mDice: 0.6783 - val_loss: 2298.2317 - val_acc: 0.9486 - val_mDice: 0.5976

Epoch 00015: val_mDice did not improve from 0.59991
Epoch 16/300
 - 21s - loss: 1885.8395 - acc: 0.9447 - mDice: 0.6817 - val_loss: 2510.4740 - val_acc: 0.9484 - val_mDice: 0.5715

Epoch 00016: val_mDice did not improve from 0.59991
Epoch 17/300
 - 21s - loss: 1862.6750 - acc: 0.9452 - mDice: 0.6850 - val_loss: 2203.1062 - val_acc: 0.9488 - val_mDice: 0.6116

Epoch 00017: val_mDice improved from 0.59991 to 0.61162, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 20s - loss: 1820.8765 - acc: 0.9458 - mDice: 0.6906 - val_loss: 2486.9126 - val_acc: 0.9475 - val_mDice: 0.5744

Epoch 00018: val_mDice did not improve from 0.61162
Epoch 19/300
 - 21s - loss: 1801.1489 - acc: 0.9461 - mDice: 0.6935 - val_loss: 2493.1481 - val_acc: 0.9496 - val_mDice: 0.5785

Epoch 00019: val_mDice did not improve from 0.61162
Epoch 20/300
 - 22s - loss: 1800.5874 - acc: 0.9464 - mDice: 0.6937 - val_loss: 2352.4131 - val_acc: 0.9504 - val_mDice: 0.5949

Epoch 00020: val_mDice did not improve from 0.61162
Epoch 21/300
 - 20s - loss: 1772.8502 - acc: 0.9468 - mDice: 0.6974 - val_loss: 2298.0803 - val_acc: 0.9469 - val_mDice: 0.5954

Epoch 00021: val_mDice did not improve from 0.61162
Epoch 22/300
 - 21s - loss: 1740.5451 - acc: 0.9472 - mDice: 0.7019 - val_loss: 2276.9674 - val_acc: 0.9508 - val_mDice: 0.6032

Epoch 00022: val_mDice did not improve from 0.61162
Epoch 23/300
 - 21s - loss: 1721.3896 - acc: 0.9475 - mDice: 0.7046 - val_loss: 2462.4709 - val_acc: 0.9483 - val_mDice: 0.5843

Epoch 00023: val_mDice did not improve from 0.61162
Epoch 24/300
 - 21s - loss: 1704.2699 - acc: 0.9478 - mDice: 0.7069 - val_loss: 2398.3993 - val_acc: 0.9483 - val_mDice: 0.5887

Epoch 00024: val_mDice did not improve from 0.61162
Epoch 25/300
 - 21s - loss: 1685.0491 - acc: 0.9481 - mDice: 0.7096 - val_loss: 2333.5620 - val_acc: 0.9500 - val_mDice: 0.5944

Epoch 00025: val_mDice did not improve from 0.61162
Epoch 26/300
 - 20s - loss: 1675.7311 - acc: 0.9483 - mDice: 0.7109 - val_loss: 2321.6773 - val_acc: 0.9502 - val_mDice: 0.5966

Epoch 00026: val_mDice did not improve from 0.61162
Epoch 27/300
 - 20s - loss: 1664.6033 - acc: 0.9485 - mDice: 0.7127 - val_loss: 2343.3160 - val_acc: 0.9496 - val_mDice: 0.5953

Epoch 00027: val_mDice did not improve from 0.61162
Epoch 28/300
 - 21s - loss: 1644.2896 - acc: 0.9488 - mDice: 0.7155 - val_loss: 2562.4995 - val_acc: 0.9468 - val_mDice: 0.5699

Epoch 00028: val_mDice did not improve from 0.61162
Epoch 29/300
 - 21s - loss: 1640.4423 - acc: 0.9489 - mDice: 0.7161 - val_loss: 2416.4306 - val_acc: 0.9477 - val_mDice: 0.5850

Epoch 00029: val_mDice did not improve from 0.61162
Epoch 30/300
 - 21s - loss: 1651.7727 - acc: 0.9492 - mDice: 0.7191 - val_loss: 2363.7515 - val_acc: 0.9483 - val_mDice: 0.5911

Epoch 00030: val_mDice did not improve from 0.61162
Epoch 31/300
 - 21s - loss: 1618.1101 - acc: 0.9493 - mDice: 0.7193 - val_loss: 2548.6522 - val_acc: 0.9478 - val_mDice: 0.5779

Epoch 00031: val_mDice did not improve from 0.61162
Epoch 32/300
 - 20s - loss: 1592.0928 - acc: 0.9496 - mDice: 0.7229 - val_loss: 2472.7659 - val_acc: 0.9495 - val_mDice: 0.5821

Epoch 00032: val_mDice did not improve from 0.61162
Epoch 33/300
 - 20s - loss: 1590.3527 - acc: 0.9497 - mDice: 0.7232 - val_loss: 2374.0032 - val_acc: 0.9481 - val_mDice: 0.5900

Epoch 00033: val_mDice did not improve from 0.61162
Epoch 34/300
 - 21s - loss: 1578.4645 - acc: 0.9498 - mDice: 0.7250 - val_loss: 2433.0961 - val_acc: 0.9517 - val_mDice: 0.5890

Epoch 00034: val_mDice did not improve from 0.61162
Epoch 35/300
 - 20s - loss: 1575.4045 - acc: 0.9501 - mDice: 0.7256 - val_loss: 2354.0453 - val_acc: 0.9485 - val_mDice: 0.5909

Epoch 00035: val_mDice did not improve from 0.61162
Epoch 36/300
 - 21s - loss: 1553.8594 - acc: 0.9502 - mDice: 0.7286 - val_loss: 2440.9607 - val_acc: 0.9469 - val_mDice: 0.5807

Epoch 00036: val_mDice did not improve from 0.61162
Epoch 37/300
 - 20s - loss: 1548.7943 - acc: 0.9503 - mDice: 0.7295 - val_loss: 2441.7151 - val_acc: 0.9497 - val_mDice: 0.5828

Epoch 00037: val_mDice did not improve from 0.61162
Epoch 38/300
 - 20s - loss: 1543.2312 - acc: 0.9504 - mDice: 0.7303 - val_loss: 2363.9929 - val_acc: 0.9514 - val_mDice: 0.5936

Epoch 00038: val_mDice did not improve from 0.61162
Epoch 39/300
 - 20s - loss: 1538.3433 - acc: 0.9505 - mDice: 0.7310 - val_loss: 2546.9200 - val_acc: 0.9457 - val_mDice: 0.5717

Epoch 00039: val_mDice did not improve from 0.61162
Epoch 40/300
 - 21s - loss: 1532.6782 - acc: 0.9507 - mDice: 0.7317 - val_loss: 2311.1632 - val_acc: 0.9511 - val_mDice: 0.5996

Epoch 00040: val_mDice did not improve from 0.61162
Epoch 41/300
 - 20s - loss: 1516.9462 - acc: 0.9508 - mDice: 0.7340 - val_loss: 2462.5316 - val_acc: 0.9464 - val_mDice: 0.5821

Epoch 00041: val_mDice did not improve from 0.61162
Epoch 42/300
 - 20s - loss: 1514.2916 - acc: 0.9507 - mDice: 0.7344 - val_loss: 2459.4869 - val_acc: 0.9467 - val_mDice: 0.5783

Epoch 00042: val_mDice did not improve from 0.61162
Epoch 43/300
 - 20s - loss: 1497.0149 - acc: 0.9511 - mDice: 0.7369 - val_loss: 2482.7814 - val_acc: 0.9483 - val_mDice: 0.5815

Epoch 00043: val_mDice did not improve from 0.61162
Epoch 44/300
 - 20s - loss: 1490.5030 - acc: 0.9512 - mDice: 0.7379 - val_loss: 2482.6931 - val_acc: 0.9500 - val_mDice: 0.5806

Epoch 00044: val_mDice did not improve from 0.61162
Epoch 45/300
 - 20s - loss: 1482.9164 - acc: 0.9513 - mDice: 0.7391 - val_loss: 2442.7473 - val_acc: 0.9448 - val_mDice: 0.5811

Epoch 00045: val_mDice did not improve from 0.61162
Epoch 46/300
 - 18s - loss: 1481.8007 - acc: 0.9513 - mDice: 0.7393 - val_loss: 2375.8859 - val_acc: 0.9486 - val_mDice: 0.5892

Epoch 00046: val_mDice did not improve from 0.61162
Epoch 47/300
 - 19s - loss: 1472.6926 - acc: 0.9515 - mDice: 0.7405 - val_loss: 2467.9325 - val_acc: 0.9506 - val_mDice: 0.5866

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.72s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.45s/it]predicting test subjects: 100%|██████████| 3/3 [00:06<00:00,  2.19s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:02<09:59,  2.11s/it]predicting train subjects:   1%|          | 2/285 [00:03<09:13,  1.96s/it]predicting train subjects:   1%|          | 3/285 [00:05<09:05,  1.93s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<08:37,  1.84s/it]predicting train subjects:   2%|▏         | 5/285 [00:09<08:53,  1.91s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<08:27,  1.82s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:48,  1.90s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:42,  1.89s/it]predicting train subjects:   3%|▎         | 9/285 [00:17<09:13,  2.00s/it]predicting train subjects:   4%|▎         | 10/285 [00:19<09:31,  2.08s/it]predicting train subjects:   4%|▍         | 11/285 [00:21<09:10,  2.01s/it]predicting train subjects:   4%|▍         | 12/285 [00:23<09:36,  2.11s/it]predicting train subjects:   5%|▍         | 13/285 [00:25<09:24,  2.08s/it]predicting train subjects:   5%|▍         | 14/285 [00:27<09:24,  2.08s/it]predicting train subjects:   5%|▌         | 15/285 [00:29<09:39,  2.15s/it]predicting train subjects:   6%|▌         | 16/285 [00:32<09:47,  2.19s/it]predicting train subjects:   6%|▌         | 17/285 [00:34<09:19,  2.09s/it]predicting train subjects:   6%|▋         | 18/285 [00:36<09:21,  2.10s/it]predicting train subjects:   7%|▋         | 19/285 [00:38<08:59,  2.03s/it]predicting train subjects:   7%|▋         | 20/285 [00:40<09:04,  2.05s/it]predicting train subjects:   7%|▋         | 21/285 [00:42<09:35,  2.18s/it]predicting train subjects:   8%|▊         | 22/285 [00:44<09:12,  2.10s/it]predicting train subjects:   8%|▊         | 23/285 [00:46<09:02,  2.07s/it]predicting train subjects:   8%|▊         | 24/285 [00:48<08:34,  1.97s/it]predicting train subjects:   9%|▉         | 25/285 [00:50<08:57,  2.07s/it]predicting train subjects:   9%|▉         | 26/285 [00:52<09:16,  2.15s/it]predicting train subjects:   9%|▉         | 27/285 [00:54<08:45,  2.04s/it]predicting train subjects:  10%|▉         | 28/285 [00:56<08:47,  2.05s/it]predicting train subjects:  10%|█         | 29/285 [00:58<08:45,  2.05s/it]predicting train subjects:  11%|█         | 30/285 [01:01<09:09,  2.15s/it]predicting train subjects:  11%|█         | 31/285 [01:03<09:14,  2.18s/it]predicting train subjects:  11%|█         | 32/285 [01:05<08:51,  2.10s/it]predicting train subjects:  12%|█▏        | 33/285 [01:07<08:56,  2.13s/it]predicting train subjects:  12%|█▏        | 34/285 [01:09<08:51,  2.12s/it]predicting train subjects:  12%|█▏        | 35/285 [01:11<09:01,  2.17s/it]predicting train subjects:  13%|█▎        | 36/285 [01:13<08:39,  2.09s/it]predicting train subjects:  13%|█▎        | 37/285 [01:16<08:40,  2.10s/it]predicting train subjects:  13%|█▎        | 38/285 [01:18<08:56,  2.17s/it]predicting train subjects:  14%|█▎        | 39/285 [01:20<08:27,  2.06s/it]predicting train subjects:  14%|█▍        | 40/285 [01:22<08:20,  2.04s/it]predicting train subjects:  14%|█▍        | 41/285 [01:23<08:01,  1.98s/it]predicting train subjects:  15%|█▍        | 42/285 [01:25<07:51,  1.94s/it]predicting train subjects:  15%|█▌        | 43/285 [01:27<08:00,  1.99s/it]predicting train subjects:  15%|█▌        | 44/285 [01:30<08:18,  2.07s/it]predicting train subjects:  16%|█▌        | 45/285 [01:32<07:58,  1.99s/it]predicting train subjects:  16%|█▌        | 46/285 [01:34<08:23,  2.10s/it]predicting train subjects:  16%|█▋        | 47/285 [01:36<08:06,  2.04s/it]predicting train subjects:  17%|█▋        | 48/285 [01:38<08:03,  2.04s/it]predicting train subjects:  17%|█▋        | 49/285 [01:40<08:15,  2.10s/it]predicting train subjects:  18%|█▊        | 50/285 [01:42<08:04,  2.06s/it]predicting train subjects:  18%|█▊        | 51/285 [01:44<08:19,  2.14s/it]predicting train subjects:  18%|█▊        | 52/285 [01:46<07:58,  2.05s/it]predicting train subjects:  19%|█▊        | 53/285 [01:48<07:54,  2.04s/it]predicting train subjects:  19%|█▉        | 54/285 [01:50<08:00,  2.08s/it]predicting train subjects:  19%|█▉        | 55/285 [01:52<07:42,  2.01s/it]predicting train subjects:  20%|█▉        | 56/285 [01:54<07:43,  2.03s/it]predicting train subjects:  20%|██        | 57/285 [01:56<07:39,  2.01s/it]predicting train subjects:  20%|██        | 58/285 [01:58<07:43,  2.04s/it]predicting train subjects:  21%|██        | 59/285 [02:01<07:59,  2.12s/it]predicting train subjects:  21%|██        | 60/285 [02:03<08:12,  2.19s/it]predicting train subjects:  21%|██▏       | 61/285 [02:05<07:44,  2.07s/it]predicting train subjects:  22%|██▏       | 62/285 [02:07<07:41,  2.07s/it]predicting train subjects:  22%|██▏       | 63/285 [02:09<07:42,  2.08s/it]predicting train subjects:  22%|██▏       | 64/285 [02:11<07:25,  2.01s/it]predicting train subjects:  23%|██▎       | 65/285 [02:13<07:30,  2.05s/it]predicting train subjects:  23%|██▎       | 66/285 [02:15<07:28,  2.05s/it]predicting train subjects:  24%|██▎       | 67/285 [02:17<07:29,  2.06s/it]predicting train subjects:  24%|██▍       | 68/285 [02:19<07:18,  2.02s/it]predicting train subjects:  24%|██▍       | 69/285 [02:21<07:21,  2.04s/it]predicting train subjects:  25%|██▍       | 70/285 [02:23<07:14,  2.02s/it]predicting train subjects:  25%|██▍       | 71/285 [02:25<07:19,  2.05s/it]predicting train subjects:  25%|██▌       | 72/285 [02:27<07:10,  2.02s/it]predicting train subjects:  26%|██▌       | 73/285 [02:29<07:04,  2.00s/it]predicting train subjects:  26%|██▌       | 74/285 [02:31<07:01,  2.00s/it]predicting train subjects:  26%|██▋       | 75/285 [02:33<06:58,  1.99s/it]predicting train subjects:  27%|██▋       | 76/285 [02:35<06:52,  1.97s/it]predicting train subjects:  27%|██▋       | 77/285 [02:37<06:36,  1.91s/it]predicting train subjects:  27%|██▋       | 78/285 [02:39<06:24,  1.86s/it]predicting train subjects:  28%|██▊       | 79/285 [02:40<06:28,  1.88s/it]predicting train subjects:  28%|██▊       | 80/285 [02:42<06:30,  1.91s/it]predicting train subjects:  28%|██▊       | 81/285 [02:44<06:25,  1.89s/it]predicting train subjects:  29%|██▉       | 82/285 [02:46<06:23,  1.89s/it]predicting train subjects:  29%|██▉       | 83/285 [02:48<06:14,  1.85s/it]predicting train subjects:  29%|██▉       | 84/285 [02:50<06:06,  1.82s/it]predicting train subjects:  30%|██▉       | 85/285 [02:52<06:14,  1.87s/it]predicting train subjects:  30%|███       | 86/285 [02:54<06:17,  1.90s/it]predicting train subjects:  31%|███       | 87/285 [02:56<06:24,  1.94s/it]predicting train subjects:  31%|███       | 88/285 [02:58<06:17,  1.92s/it]predicting train subjects:  31%|███       | 89/285 [03:00<06:22,  1.95s/it]predicting train subjects:  32%|███▏      | 90/285 [03:01<06:17,  1.94s/it]predicting train subjects:  32%|███▏      | 91/285 [03:03<06:07,  1.90s/it]predicting train subjects:  32%|███▏      | 92/285 [03:05<06:07,  1.91s/it]predicting train subjects:  33%|███▎      | 93/285 [03:07<06:00,  1.88s/it]predicting train subjects:  33%|███▎      | 94/285 [03:09<05:57,  1.87s/it]predicting train subjects:  33%|███▎      | 95/285 [03:11<05:58,  1.89s/it]predicting train subjects:  34%|███▎      | 96/285 [03:13<06:00,  1.91s/it]predicting train subjects:  34%|███▍      | 97/285 [03:15<05:58,  1.91s/it]predicting train subjects:  34%|███▍      | 98/285 [03:17<05:55,  1.90s/it]predicting train subjects:  35%|███▍      | 99/285 [03:18<05:52,  1.90s/it]predicting train subjects:  35%|███▌      | 100/285 [03:20<05:52,  1.91s/it]predicting train subjects:  35%|███▌      | 101/285 [03:22<05:53,  1.92s/it]predicting train subjects:  36%|███▌      | 102/285 [03:24<05:52,  1.92s/it]predicting train subjects:  36%|███▌      | 103/285 [03:26<05:43,  1.89s/it]predicting train subjects:  36%|███▋      | 104/285 [03:28<05:41,  1.89s/it]predicting train subjects:  37%|███▋      | 105/285 [03:30<05:40,  1.89s/it]predicting train subjects:  37%|███▋      | 106/285 [03:32<05:32,  1.86s/it]predicting train subjects:  38%|███▊      | 107/285 [03:33<05:28,  1.85s/it]predicting train subjects:  38%|███▊      | 108/285 [03:35<05:20,  1.81s/it]predicting train subjects:  38%|███▊      | 109/285 [03:37<05:26,  1.86s/it]predicting train subjects:  39%|███▊      | 110/285 [03:39<05:30,  1.89s/it]predicting train subjects:  39%|███▉      | 111/285 [03:41<05:22,  1.85s/it]predicting train subjects:  39%|███▉      | 112/285 [03:43<05:21,  1.86s/it]predicting train subjects:  40%|███▉      | 113/285 [03:45<05:19,  1.86s/it]predicting train subjects:  40%|████      | 114/285 [03:46<05:18,  1.86s/it]predicting train subjects:  40%|████      | 115/285 [03:48<05:18,  1.88s/it]predicting train subjects:  41%|████      | 116/285 [03:50<05:20,  1.89s/it]predicting train subjects:  41%|████      | 117/285 [03:52<05:13,  1.87s/it]predicting train subjects:  41%|████▏     | 118/285 [03:54<05:06,  1.84s/it]predicting train subjects:  42%|████▏     | 119/285 [03:56<05:09,  1.86s/it]predicting train subjects:  42%|████▏     | 120/285 [03:58<05:02,  1.83s/it]predicting train subjects:  42%|████▏     | 121/285 [03:59<04:55,  1.80s/it]predicting train subjects:  43%|████▎     | 122/285 [04:01<04:42,  1.73s/it]predicting train subjects:  43%|████▎     | 123/285 [04:02<04:31,  1.67s/it]predicting train subjects:  44%|████▎     | 124/285 [04:04<04:30,  1.68s/it]predicting train subjects:  44%|████▍     | 125/285 [04:06<04:22,  1.64s/it]predicting train subjects:  44%|████▍     | 126/285 [04:07<04:20,  1.64s/it]predicting train subjects:  45%|████▍     | 127/285 [04:09<04:13,  1.60s/it]predicting train subjects:  45%|████▍     | 128/285 [04:11<04:17,  1.64s/it]predicting train subjects:  45%|████▌     | 129/285 [04:12<04:21,  1.68s/it]predicting train subjects:  46%|████▌     | 130/285 [04:14<04:18,  1.66s/it]predicting train subjects:  46%|████▌     | 131/285 [04:16<04:16,  1.67s/it]predicting train subjects:  46%|████▋     | 132/285 [04:17<04:21,  1.71s/it]predicting train subjects:  47%|████▋     | 133/285 [04:19<04:18,  1.70s/it]predicting train subjects:  47%|████▋     | 134/285 [04:21<04:14,  1.68s/it]predicting train subjects:  47%|████▋     | 135/285 [04:22<04:06,  1.64s/it]predicting train subjects:  48%|████▊     | 136/285 [04:24<04:02,  1.63s/it]predicting train subjects:  48%|████▊     | 137/285 [04:26<04:08,  1.68s/it]predicting train subjects:  48%|████▊     | 138/285 [04:27<04:05,  1.67s/it]predicting train subjects:  49%|████▉     | 139/285 [04:29<04:07,  1.69s/it]predicting train subjects:  49%|████▉     | 140/285 [04:31<04:11,  1.74s/it]predicting train subjects:  49%|████▉     | 141/285 [04:33<04:04,  1.70s/it]predicting train subjects:  50%|████▉     | 142/285 [04:34<04:00,  1.68s/it]predicting train subjects:  50%|█████     | 143/285 [04:36<03:56,  1.66s/it]predicting train subjects:  51%|█████     | 144/285 [04:38<04:02,  1.72s/it]predicting train subjects:  51%|█████     | 145/285 [04:39<03:59,  1.71s/it]predicting train subjects:  51%|█████     | 146/285 [04:41<04:02,  1.74s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:43<03:53,  1.70s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:45<03:58,  1.74s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:46<03:56,  1.74s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:48<03:49,  1.70s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:50<03:53,  1.75s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:51<03:48,  1.72s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:53<03:40,  1.67s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:55<03:42,  1.70s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:56<03:37,  1.67s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:58<03:39,  1.70s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:00<03:34,  1.68s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:01<03:33,  1.68s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:03<03:25,  1.63s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:05<03:25,  1.64s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:06<03:28,  1.69s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:08<03:27,  1.69s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:10<03:27,  1.70s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:12<03:24,  1.69s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:13<03:21,  1.68s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:15<03:24,  1.72s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:17<03:26,  1.75s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:18<03:17,  1.69s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:20<03:18,  1.71s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:22<03:15,  1.70s/it]predicting train subjects:  60%|██████    | 171/285 [05:24<03:15,  1.71s/it]predicting train subjects:  60%|██████    | 172/285 [05:25<03:14,  1.72s/it]predicting train subjects:  61%|██████    | 173/285 [05:27<03:07,  1.67s/it]predicting train subjects:  61%|██████    | 174/285 [05:28<03:03,  1.65s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:30<03:07,  1.70s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:32<03:08,  1.73s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:34<03:01,  1.68s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:35<02:56,  1.65s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:37<02:54,  1.64s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:39<03:02,  1.74s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:41<03:07,  1.80s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:43<03:08,  1.83s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:44<03:00,  1.77s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:46<02:56,  1.75s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:47<02:47,  1.68s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:50<02:58,  1.80s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:52<03:02,  1.86s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:53<03:02,  1.88s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:55<02:50,  1.78s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:57<02:44,  1.73s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:58<02:44,  1.75s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:00<02:45,  1.78s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:02<02:36,  1.71s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:03<02:31,  1.67s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:05<02:26,  1.63s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:07<02:35,  1.75s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:09<02:40,  1.83s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:11<02:42,  1.87s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:13<02:33,  1.79s/it]predicting train subjects:  70%|███████   | 200/285 [06:14<02:29,  1.76s/it]predicting train subjects:  71%|███████   | 201/285 [06:16<02:34,  1.84s/it]predicting train subjects:  71%|███████   | 202/285 [06:18<02:31,  1.82s/it]predicting train subjects:  71%|███████   | 203/285 [06:20<02:29,  1.82s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:21<02:23,  1.77s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:23<02:20,  1.76s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:25<02:13,  1.69s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:27<02:20,  1.80s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:29<02:21,  1.84s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:31<02:22,  1.88s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:32<02:15,  1.80s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:34<02:12,  1.79s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:36<02:12,  1.82s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:38<02:11,  1.83s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:39<02:05,  1.76s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:41<02:06,  1.81s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:43<01:58,  1.72s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:45<02:02,  1.81s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:47<02:05,  1.87s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:49<02:05,  1.89s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:50<01:58,  1.82s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:52<01:52,  1.75s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:54<01:52,  1.78s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:55<01:45,  1.70s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:57<01:42,  1.67s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:59<01:37,  1.62s/it]predicting train subjects:  79%|███████▉  | 226/285 [07:01<01:42,  1.74s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:03<01:45,  1.82s/it]predicting train subjects:  80%|████████  | 228/285 [07:05<01:46,  1.87s/it]predicting train subjects:  80%|████████  | 229/285 [07:06<01:43,  1.84s/it]predicting train subjects:  81%|████████  | 230/285 [07:08<01:37,  1.78s/it]predicting train subjects:  81%|████████  | 231/285 [07:10<01:32,  1.71s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:11<01:31,  1.73s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:13<01:27,  1.69s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:15<01:30,  1.77s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:16<01:26,  1.72s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:18<01:29,  1.82s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:21<01:30,  1.89s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:22<01:28,  1.89s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:24<01:26,  1.87s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:26<01:20,  1.78s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:27<01:16,  1.74s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:29<01:12,  1.68s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:31<01:08,  1.63s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:32<01:10,  1.72s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:34<01:08,  1.71s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:36<01:11,  1.83s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:38<01:11,  1.87s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:40<01:09,  1.87s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:42<01:04,  1.79s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:43<01:00,  1.72s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:45<00:56,  1.67s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:46<00:53,  1.63s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:48<00:55,  1.74s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:50<00:55,  1.80s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:52<00:53,  1.79s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:54<00:50,  1.74s/it]predicting train subjects:  90%|█████████ | 257/285 [07:55<00:48,  1.72s/it]predicting train subjects:  91%|█████████ | 258/285 [07:57<00:48,  1.78s/it]predicting train subjects:  91%|█████████ | 259/285 [07:59<00:46,  1.77s/it]predicting train subjects:  91%|█████████ | 260/285 [08:01<00:42,  1.72s/it]predicting train subjects:  92%|█████████▏| 261/285 [08:02<00:40,  1.68s/it]predicting train subjects:  92%|█████████▏| 262/285 [08:04<00:38,  1.68s/it]predicting train subjects:  92%|█████████▏| 263/285 [08:06<00:36,  1.68s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:08<00:37,  1.78s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:10<00:36,  1.84s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:11<00:33,  1.78s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:13<00:31,  1.75s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:15<00:30,  1.81s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:17<00:29,  1.84s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:18<00:26,  1.74s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:20<00:23,  1.71s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:22<00:22,  1.75s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:23<00:20,  1.69s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:25<00:18,  1.66s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:27<00:17,  1.76s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:29<00:16,  1.80s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:30<00:13,  1.72s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:32<00:11,  1.70s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:34<00:10,  1.75s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:35<00:08,  1.70s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:37<00:06,  1.69s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:39<00:04,  1.64s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:41<00:03,  1.76s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:43<00:01,  1.86s/it]predicting train subjects: 100%|██████████| 285/285 [08:45<00:00,  1.90s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:10,  1.73s/it]Loading train:   1%|          | 2/285 [00:03<07:33,  1.60s/it]Loading train:   1%|          | 3/285 [00:04<07:30,  1.60s/it]Loading train:   1%|▏         | 4/285 [00:06<07:16,  1.55s/it]Loading train:   2%|▏         | 5/285 [00:07<07:22,  1.58s/it]Loading train:   2%|▏         | 6/285 [00:09<07:11,  1.55s/it]Loading train:   2%|▏         | 7/285 [00:10<07:18,  1.58s/it]Loading train:   3%|▎         | 8/285 [00:12<07:11,  1.56s/it]Loading train:   3%|▎         | 9/285 [00:14<07:44,  1.68s/it]Loading train:   4%|▎         | 10/285 [00:15<07:18,  1.59s/it]Loading train:   4%|▍         | 11/285 [00:16<06:46,  1.48s/it]Loading train:   4%|▍         | 12/285 [00:18<06:39,  1.46s/it]Loading train:   5%|▍         | 13/285 [00:19<06:16,  1.38s/it]Loading train:   5%|▍         | 14/285 [00:20<06:02,  1.34s/it]Loading train:   5%|▌         | 15/285 [00:22<05:57,  1.32s/it]Loading train:   6%|▌         | 16/285 [00:23<06:16,  1.40s/it]Loading train:   6%|▌         | 17/285 [00:24<06:07,  1.37s/it]Loading train:   6%|▋         | 18/285 [00:26<06:19,  1.42s/it]Loading train:   7%|▋         | 19/285 [00:27<05:50,  1.32s/it]Loading train:   7%|▋         | 20/285 [00:28<05:50,  1.32s/it]Loading train:   7%|▋         | 21/285 [00:30<05:58,  1.36s/it]Loading train:   8%|▊         | 22/285 [00:31<05:35,  1.28s/it]Loading train:   8%|▊         | 23/285 [00:32<05:36,  1.28s/it]Loading train:   8%|▊         | 24/285 [00:33<05:28,  1.26s/it]Loading train:   9%|▉         | 25/285 [00:35<05:49,  1.35s/it]Loading train:   9%|▉         | 26/285 [00:36<06:01,  1.40s/it]Loading train:   9%|▉         | 27/285 [00:38<05:40,  1.32s/it]Loading train:  10%|▉         | 28/285 [00:39<05:35,  1.31s/it]Loading train:  10%|█         | 29/285 [00:40<05:30,  1.29s/it]Loading train:  11%|█         | 30/285 [00:42<05:45,  1.36s/it]Loading train:  11%|█         | 31/285 [00:43<06:00,  1.42s/it]Loading train:  11%|█         | 32/285 [00:44<05:42,  1.36s/it]Loading train:  12%|█▏        | 33/285 [00:46<06:08,  1.46s/it]Loading train:  12%|█▏        | 34/285 [00:47<05:53,  1.41s/it]Loading train:  12%|█▏        | 35/285 [00:49<05:45,  1.38s/it]Loading train:  13%|█▎        | 36/285 [00:50<05:30,  1.33s/it]Loading train:  13%|█▎        | 37/285 [00:51<05:16,  1.28s/it]Loading train:  13%|█▎        | 38/285 [00:53<05:27,  1.33s/it]Loading train:  14%|█▎        | 39/285 [00:54<05:22,  1.31s/it]Loading train:  14%|█▍        | 40/285 [00:55<05:18,  1.30s/it]Loading train:  14%|█▍        | 41/285 [00:56<05:06,  1.26s/it]Loading train:  15%|█▍        | 42/285 [00:57<05:00,  1.24s/it]Loading train:  15%|█▌        | 43/285 [00:59<05:07,  1.27s/it]Loading train:  15%|█▌        | 44/285 [01:00<05:20,  1.33s/it]Loading train:  16%|█▌        | 45/285 [01:01<04:48,  1.20s/it]Loading train:  16%|█▌        | 46/285 [01:02<04:28,  1.12s/it]Loading train:  16%|█▋        | 47/285 [01:03<04:33,  1.15s/it]Loading train:  17%|█▋        | 48/285 [01:05<04:35,  1.16s/it]Loading train:  17%|█▋        | 49/285 [01:06<05:06,  1.30s/it]Loading train:  18%|█▊        | 50/285 [01:07<05:01,  1.28s/it]Loading train:  18%|█▊        | 51/285 [01:09<04:50,  1.24s/it]Loading train:  18%|█▊        | 52/285 [01:09<04:28,  1.15s/it]Loading train:  19%|█▊        | 53/285 [01:10<04:12,  1.09s/it]Loading train:  19%|█▉        | 54/285 [01:11<04:07,  1.07s/it]Loading train:  19%|█▉        | 55/285 [01:12<03:46,  1.01it/s]Loading train:  20%|█▉        | 56/285 [01:13<03:33,  1.07it/s]Loading train:  20%|██        | 57/285 [01:14<03:26,  1.11it/s]Loading train:  20%|██        | 58/285 [01:15<03:27,  1.09it/s]Loading train:  21%|██        | 59/285 [01:16<03:36,  1.04it/s]Loading train:  21%|██        | 60/285 [01:17<03:41,  1.02it/s]Loading train:  21%|██▏       | 61/285 [01:18<03:37,  1.03it/s]Loading train:  22%|██▏       | 62/285 [01:19<03:37,  1.03it/s]Loading train:  22%|██▏       | 63/285 [01:20<03:32,  1.04it/s]Loading train:  22%|██▏       | 64/285 [01:21<03:53,  1.06s/it]Loading train:  23%|██▎       | 65/285 [01:23<04:20,  1.19s/it]Loading train:  23%|██▎       | 66/285 [01:24<04:22,  1.20s/it]Loading train:  24%|██▎       | 67/285 [01:25<04:11,  1.15s/it]Loading train:  24%|██▍       | 68/285 [01:26<03:55,  1.08s/it]Loading train:  24%|██▍       | 69/285 [01:27<03:49,  1.06s/it]Loading train:  25%|██▍       | 70/285 [01:28<03:42,  1.03s/it]Loading train:  25%|██▍       | 71/285 [01:29<03:35,  1.01s/it]Loading train:  25%|██▌       | 72/285 [01:30<03:26,  1.03it/s]Loading train:  26%|██▌       | 73/285 [01:31<03:25,  1.03it/s]Loading train:  26%|██▌       | 74/285 [01:31<03:16,  1.07it/s]Loading train:  26%|██▋       | 75/285 [01:32<03:16,  1.07it/s]Loading train:  27%|██▋       | 76/285 [01:33<03:17,  1.06it/s]Loading train:  27%|██▋       | 77/285 [01:34<03:10,  1.09it/s]Loading train:  27%|██▋       | 78/285 [01:35<03:00,  1.15it/s]Loading train:  28%|██▊       | 79/285 [01:36<03:00,  1.14it/s]Loading train:  28%|██▊       | 80/285 [01:37<02:59,  1.14it/s]Loading train:  28%|██▊       | 81/285 [01:38<02:58,  1.15it/s]Loading train:  29%|██▉       | 82/285 [01:38<03:02,  1.11it/s]Loading train:  29%|██▉       | 83/285 [01:39<02:57,  1.14it/s]Loading train:  29%|██▉       | 84/285 [01:40<02:50,  1.18it/s]Loading train:  30%|██▉       | 85/285 [01:41<02:56,  1.14it/s]Loading train:  30%|███       | 86/285 [01:42<03:06,  1.07it/s]Loading train:  31%|███       | 87/285 [01:43<03:02,  1.08it/s]Loading train:  31%|███       | 88/285 [01:44<02:55,  1.12it/s]Loading train:  31%|███       | 89/285 [01:45<02:56,  1.11it/s]Loading train:  32%|███▏      | 90/285 [01:46<02:58,  1.09it/s]Loading train:  32%|███▏      | 91/285 [01:46<02:51,  1.13it/s]Loading train:  32%|███▏      | 92/285 [01:47<02:52,  1.12it/s]Loading train:  33%|███▎      | 93/285 [01:48<02:49,  1.13it/s]Loading train:  33%|███▎      | 94/285 [01:49<02:52,  1.11it/s]Loading train:  33%|███▎      | 95/285 [01:50<02:53,  1.10it/s]Loading train:  34%|███▎      | 96/285 [01:51<02:51,  1.10it/s]Loading train:  34%|███▍      | 97/285 [01:52<02:52,  1.09it/s]Loading train:  34%|███▍      | 98/285 [01:53<02:50,  1.10it/s]Loading train:  35%|███▍      | 99/285 [01:54<02:49,  1.10it/s]Loading train:  35%|███▌      | 100/285 [01:55<02:43,  1.13it/s]Loading train:  35%|███▌      | 101/285 [01:55<02:35,  1.18it/s]Loading train:  36%|███▌      | 102/285 [01:56<02:34,  1.18it/s]Loading train:  36%|███▌      | 103/285 [01:57<02:28,  1.22it/s]Loading train:  36%|███▋      | 104/285 [01:58<02:35,  1.16it/s]Loading train:  37%|███▋      | 105/285 [01:59<02:41,  1.12it/s]Loading train:  37%|███▋      | 106/285 [02:00<02:34,  1.16it/s]Loading train:  38%|███▊      | 107/285 [02:01<02:38,  1.12it/s]Loading train:  38%|███▊      | 108/285 [02:01<02:34,  1.15it/s]Loading train:  38%|███▊      | 109/285 [02:02<02:34,  1.14it/s]Loading train:  39%|███▊      | 110/285 [02:03<02:36,  1.12it/s]Loading train:  39%|███▉      | 111/285 [02:04<02:28,  1.17it/s]Loading train:  39%|███▉      | 112/285 [02:05<02:30,  1.15it/s]Loading train:  40%|███▉      | 113/285 [02:06<02:29,  1.15it/s]Loading train:  40%|████      | 114/285 [02:07<02:31,  1.13it/s]Loading train:  40%|████      | 115/285 [02:08<02:29,  1.14it/s]Loading train:  41%|████      | 116/285 [02:09<02:32,  1.11it/s]Loading train:  41%|████      | 117/285 [02:09<02:26,  1.14it/s]Loading train:  41%|████▏     | 118/285 [02:10<02:22,  1.18it/s]Loading train:  42%|████▏     | 119/285 [02:11<02:24,  1.15it/s]Loading train:  42%|████▏     | 120/285 [02:12<02:20,  1.17it/s]Loading train:  42%|████▏     | 121/285 [02:13<02:40,  1.02it/s]Loading train:  43%|████▎     | 122/285 [02:14<02:50,  1.05s/it]Loading train:  43%|████▎     | 123/285 [02:16<02:54,  1.08s/it]Loading train:  44%|████▎     | 124/285 [02:16<02:42,  1.01s/it]Loading train:  44%|████▍     | 125/285 [02:17<02:29,  1.07it/s]Loading train:  44%|████▍     | 126/285 [02:18<02:17,  1.15it/s]Loading train:  45%|████▍     | 127/285 [02:19<02:15,  1.17it/s]Loading train:  45%|████▍     | 128/285 [02:20<02:13,  1.18it/s]Loading train:  45%|████▌     | 129/285 [02:20<02:07,  1.22it/s]Loading train:  46%|████▌     | 130/285 [02:21<02:03,  1.26it/s]Loading train:  46%|████▌     | 131/285 [02:22<02:02,  1.26it/s]Loading train:  46%|████▋     | 132/285 [02:23<02:01,  1.26it/s]Loading train:  47%|████▋     | 133/285 [02:23<01:59,  1.27it/s]Loading train:  47%|████▋     | 134/285 [02:24<01:57,  1.28it/s]Loading train:  47%|████▋     | 135/285 [02:25<01:53,  1.32it/s]Loading train:  48%|████▊     | 136/285 [02:26<01:49,  1.36it/s]Loading train:  48%|████▊     | 137/285 [02:26<01:53,  1.31it/s]Loading train:  48%|████▊     | 138/285 [02:27<01:51,  1.32it/s]Loading train:  49%|████▉     | 139/285 [02:28<01:53,  1.29it/s]Loading train:  49%|████▉     | 140/285 [02:29<01:50,  1.31it/s]Loading train:  49%|████▉     | 141/285 [02:29<01:46,  1.35it/s]Loading train:  50%|████▉     | 142/285 [02:30<01:41,  1.40it/s]Loading train:  50%|█████     | 143/285 [02:31<01:39,  1.42it/s]Loading train:  51%|█████     | 144/285 [02:31<01:43,  1.37it/s]Loading train:  51%|█████     | 145/285 [02:32<01:46,  1.31it/s]Loading train:  51%|█████     | 146/285 [02:33<01:52,  1.23it/s]Loading train:  52%|█████▏    | 147/285 [02:34<01:48,  1.28it/s]Loading train:  52%|█████▏    | 148/285 [02:35<01:48,  1.26it/s]Loading train:  52%|█████▏    | 149/285 [02:35<01:45,  1.29it/s]Loading train:  53%|█████▎    | 150/285 [02:36<01:46,  1.27it/s]Loading train:  53%|█████▎    | 151/285 [02:37<01:47,  1.25it/s]Loading train:  53%|█████▎    | 152/285 [02:38<01:45,  1.26it/s]Loading train:  54%|█████▎    | 153/285 [02:39<01:45,  1.25it/s]Loading train:  54%|█████▍    | 154/285 [02:40<01:48,  1.21it/s]Loading train:  54%|█████▍    | 155/285 [02:40<01:49,  1.19it/s]Loading train:  55%|█████▍    | 156/285 [02:41<01:47,  1.20it/s]Loading train:  55%|█████▌    | 157/285 [02:42<01:42,  1.25it/s]Loading train:  55%|█████▌    | 158/285 [02:43<01:38,  1.29it/s]Loading train:  56%|█████▌    | 159/285 [02:44<01:38,  1.27it/s]Loading train:  56%|█████▌    | 160/285 [02:44<01:37,  1.28it/s]Loading train:  56%|█████▋    | 161/285 [02:45<01:40,  1.23it/s]Loading train:  57%|█████▋    | 162/285 [02:46<01:40,  1.22it/s]Loading train:  57%|█████▋    | 163/285 [02:47<01:38,  1.24it/s]Loading train:  58%|█████▊    | 164/285 [02:48<01:36,  1.25it/s]Loading train:  58%|█████▊    | 165/285 [02:48<01:33,  1.28it/s]Loading train:  58%|█████▊    | 166/285 [02:49<01:33,  1.27it/s]Loading train:  59%|█████▊    | 167/285 [02:50<01:32,  1.27it/s]Loading train:  59%|█████▉    | 168/285 [02:51<01:30,  1.29it/s]Loading train:  59%|█████▉    | 169/285 [02:51<01:30,  1.28it/s]Loading train:  60%|█████▉    | 170/285 [02:52<01:28,  1.30it/s]Loading train:  60%|██████    | 171/285 [02:53<01:27,  1.30it/s]Loading train:  60%|██████    | 172/285 [02:54<01:26,  1.31it/s]Loading train:  61%|██████    | 173/285 [02:54<01:24,  1.32it/s]Loading train:  61%|██████    | 174/285 [02:55<01:21,  1.37it/s]Loading train:  61%|██████▏   | 175/285 [02:56<01:21,  1.35it/s]Loading train:  62%|██████▏   | 176/285 [02:57<01:23,  1.31it/s]Loading train:  62%|██████▏   | 177/285 [02:57<01:21,  1.33it/s]Loading train:  62%|██████▏   | 178/285 [02:58<01:19,  1.34it/s]Loading train:  63%|██████▎   | 179/285 [02:59<01:20,  1.32it/s]Loading train:  63%|██████▎   | 180/285 [03:00<01:26,  1.21it/s]Loading train:  64%|██████▎   | 181/285 [03:01<01:26,  1.20it/s]Loading train:  64%|██████▍   | 182/285 [03:02<01:24,  1.21it/s]Loading train:  64%|██████▍   | 183/285 [03:02<01:22,  1.24it/s]Loading train:  65%|██████▍   | 184/285 [03:03<01:20,  1.25it/s]Loading train:  65%|██████▍   | 185/285 [03:04<01:14,  1.34it/s]Loading train:  65%|██████▌   | 186/285 [03:05<01:17,  1.28it/s]Loading train:  66%|██████▌   | 187/285 [03:05<01:19,  1.24it/s]Loading train:  66%|██████▌   | 188/285 [03:06<01:20,  1.21it/s]Loading train:  66%|██████▋   | 189/285 [03:07<01:15,  1.28it/s]Loading train:  67%|██████▋   | 190/285 [03:08<01:12,  1.31it/s]Loading train:  67%|██████▋   | 191/285 [03:09<01:13,  1.27it/s]Loading train:  67%|██████▋   | 192/285 [03:09<01:14,  1.25it/s]Loading train:  68%|██████▊   | 193/285 [03:10<01:09,  1.32it/s]Loading train:  68%|██████▊   | 194/285 [03:11<01:06,  1.37it/s]Loading train:  68%|██████▊   | 195/285 [03:11<01:03,  1.43it/s]Loading train:  69%|██████▉   | 196/285 [03:12<01:08,  1.30it/s]Loading train:  69%|██████▉   | 197/285 [03:13<01:10,  1.24it/s]Loading train:  69%|██████▉   | 198/285 [03:14<01:14,  1.16it/s]Loading train:  70%|██████▉   | 199/285 [03:15<01:09,  1.23it/s]Loading train:  70%|███████   | 200/285 [03:16<01:06,  1.28it/s]Loading train:  71%|███████   | 201/285 [03:17<01:08,  1.22it/s]Loading train:  71%|███████   | 202/285 [03:17<01:06,  1.25it/s]Loading train:  71%|███████   | 203/285 [03:18<01:04,  1.26it/s]Loading train:  72%|███████▏  | 204/285 [03:19<01:01,  1.33it/s]Loading train:  72%|███████▏  | 205/285 [03:19<00:58,  1.37it/s]Loading train:  72%|███████▏  | 206/285 [03:20<00:56,  1.41it/s]Loading train:  73%|███████▎  | 207/285 [03:21<00:58,  1.32it/s]Loading train:  73%|███████▎  | 208/285 [03:22<01:01,  1.25it/s]Loading train:  73%|███████▎  | 209/285 [03:23<01:04,  1.18it/s]Loading train:  74%|███████▎  | 210/285 [03:23<01:00,  1.25it/s]Loading train:  74%|███████▍  | 211/285 [03:24<00:57,  1.29it/s]Loading train:  74%|███████▍  | 212/285 [03:25<00:58,  1.26it/s]Loading train:  75%|███████▍  | 213/285 [03:26<00:56,  1.27it/s]Loading train:  75%|███████▌  | 214/285 [03:26<00:53,  1.32it/s]Loading train:  75%|███████▌  | 215/285 [03:27<00:57,  1.22it/s]Loading train:  76%|███████▌  | 216/285 [03:28<00:55,  1.25it/s]Loading train:  76%|███████▌  | 217/285 [03:29<00:55,  1.22it/s]Loading train:  76%|███████▋  | 218/285 [03:30<00:55,  1.20it/s]Loading train:  77%|███████▋  | 219/285 [03:31<00:57,  1.14it/s]Loading train:  77%|███████▋  | 220/285 [03:32<00:53,  1.22it/s]Loading train:  78%|███████▊  | 221/285 [03:32<00:50,  1.26it/s]Loading train:  78%|███████▊  | 222/285 [03:33<00:50,  1.25it/s]Loading train:  78%|███████▊  | 223/285 [03:34<00:46,  1.32it/s]Loading train:  79%|███████▊  | 224/285 [03:35<00:45,  1.34it/s]Loading train:  79%|███████▉  | 225/285 [03:35<00:44,  1.34it/s]Loading train:  79%|███████▉  | 226/285 [03:36<00:46,  1.26it/s]Loading train:  80%|███████▉  | 227/285 [03:37<00:47,  1.23it/s]Loading train:  80%|████████  | 228/285 [03:38<00:46,  1.21it/s]Loading train:  80%|████████  | 229/285 [03:39<00:45,  1.24it/s]Loading train:  81%|████████  | 230/285 [03:39<00:42,  1.30it/s]Loading train:  81%|████████  | 231/285 [03:40<00:41,  1.29it/s]Loading train:  81%|████████▏ | 232/285 [03:41<00:41,  1.27it/s]Loading train:  82%|████████▏ | 233/285 [03:42<00:39,  1.30it/s]Loading train:  82%|████████▏ | 234/285 [03:43<00:42,  1.20it/s]Loading train:  82%|████████▏ | 235/285 [03:43<00:40,  1.23it/s]Loading train:  83%|████████▎ | 236/285 [03:44<00:41,  1.19it/s]Loading train:  83%|████████▎ | 237/285 [03:45<00:41,  1.16it/s]Loading train:  84%|████████▎ | 238/285 [03:46<00:42,  1.12it/s]Loading train:  84%|████████▍ | 239/285 [03:47<00:40,  1.12it/s]Loading train:  84%|████████▍ | 240/285 [03:48<00:37,  1.19it/s]Loading train:  85%|████████▍ | 241/285 [03:49<00:36,  1.21it/s]Loading train:  85%|████████▍ | 242/285 [03:49<00:34,  1.25it/s]Loading train:  85%|████████▌ | 243/285 [03:50<00:32,  1.28it/s]Loading train:  86%|████████▌ | 244/285 [03:51<00:33,  1.22it/s]Loading train:  86%|████████▌ | 245/285 [03:52<00:31,  1.28it/s]Loading train:  86%|████████▋ | 246/285 [03:53<00:31,  1.23it/s]Loading train:  87%|████████▋ | 247/285 [03:53<00:32,  1.18it/s]Loading train:  87%|████████▋ | 248/285 [03:54<00:31,  1.18it/s]Loading train:  87%|████████▋ | 249/285 [03:55<00:29,  1.23it/s]Loading train:  88%|████████▊ | 250/285 [03:56<00:27,  1.27it/s]Loading train:  88%|████████▊ | 251/285 [03:56<00:25,  1.31it/s]Loading train:  88%|████████▊ | 252/285 [03:57<00:24,  1.35it/s]Loading train:  89%|████████▉ | 253/285 [03:58<00:25,  1.25it/s]Loading train:  89%|████████▉ | 254/285 [03:59<00:25,  1.20it/s]Loading train:  89%|████████▉ | 255/285 [04:00<00:24,  1.20it/s]Loading train:  90%|████████▉ | 256/285 [04:01<00:22,  1.26it/s]Loading train:  90%|█████████ | 257/285 [04:01<00:21,  1.32it/s]Loading train:  91%|█████████ | 258/285 [04:02<00:21,  1.26it/s]Loading train:  91%|█████████ | 259/285 [04:03<00:20,  1.24it/s]Loading train:  91%|█████████ | 260/285 [04:04<00:19,  1.26it/s]Loading train:  92%|█████████▏| 261/285 [04:04<00:18,  1.27it/s]Loading train:  92%|█████████▏| 262/285 [04:05<00:17,  1.29it/s]Loading train:  92%|█████████▏| 263/285 [04:06<00:16,  1.30it/s]Loading train:  93%|█████████▎| 264/285 [04:07<00:16,  1.24it/s]Loading train:  93%|█████████▎| 265/285 [04:08<00:16,  1.18it/s]Loading train:  93%|█████████▎| 266/285 [04:09<00:15,  1.23it/s]Loading train:  94%|█████████▎| 267/285 [04:09<00:14,  1.24it/s]Loading train:  94%|█████████▍| 268/285 [04:10<00:14,  1.19it/s]Loading train:  94%|█████████▍| 269/285 [04:11<00:13,  1.16it/s]Loading train:  95%|█████████▍| 270/285 [04:12<00:12,  1.18it/s]Loading train:  95%|█████████▌| 271/285 [04:13<00:11,  1.21it/s]Loading train:  95%|█████████▌| 272/285 [04:14<00:10,  1.19it/s]Loading train:  96%|█████████▌| 273/285 [04:14<00:09,  1.26it/s]Loading train:  96%|█████████▌| 274/285 [04:15<00:08,  1.28it/s]Loading train:  96%|█████████▋| 275/285 [04:16<00:08,  1.21it/s]Loading train:  97%|█████████▋| 276/285 [04:17<00:07,  1.17it/s]Loading train:  97%|█████████▋| 277/285 [04:18<00:06,  1.27it/s]Loading train:  98%|█████████▊| 278/285 [04:18<00:05,  1.31it/s]Loading train:  98%|█████████▊| 279/285 [04:19<00:04,  1.33it/s]Loading train:  98%|█████████▊| 280/285 [04:20<00:03,  1.38it/s]Loading train:  99%|█████████▊| 281/285 [04:20<00:02,  1.41it/s]Loading train:  99%|█████████▉| 282/285 [04:21<00:02,  1.35it/s]Loading train:  99%|█████████▉| 283/285 [04:22<00:01,  1.28it/s]Loading train: 100%|█████████▉| 284/285 [04:23<00:00,  1.23it/s]Loading train: 100%|██████████| 285/285 [04:24<00:00,  1.18it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   8%|▊         | 24/285 [00:00<00:01, 237.48it/s]concatenating: train:  19%|█▉        | 55/285 [00:00<00:00, 253.79it/s]concatenating: train:  31%|███       | 89/285 [00:00<00:00, 273.56it/s]concatenating: train:  44%|████▎     | 124/285 [00:00<00:00, 291.08it/s]concatenating: train:  55%|█████▍    | 156/285 [00:00<00:00, 296.83it/s]concatenating: train:  66%|██████▌   | 188/285 [00:00<00:00, 301.42it/s]concatenating: train:  77%|███████▋  | 220/285 [00:00<00:00, 306.01it/s]concatenating: train:  88%|████████▊ | 252/285 [00:00<00:00, 309.17it/s]concatenating: train: 100%|██████████| 285/285 [00:00<00:00, 314.29it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.28s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.25s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.19s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 162.77it/s]2019-07-09 01:31:07.092851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-09 01:31:07.092970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-09 01:31:07.092994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-09 01:31:07.093008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-09 01:31:07.093516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12743 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.22it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.00it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.44it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  7.02it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  6.21it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.02it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  6.50it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.49it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.78it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.13it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.85it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  8.89it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  8.97it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.20it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.95it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.24it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.36it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.50it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.44it/s]
Epoch 00047: val_mDice did not improve from 0.61162
Restoring model weights from the end of the best epoch
Epoch 00047: early stopping
{'val_loss': [11198.370537273046, 3473.476629331791, 2862.800846717877, 2851.7436591633204, 2636.688232421875, 2616.0156945596195, 2280.4443072953036, 2747.8802524332227, 2342.7857659196056, 2430.484385911313, 2418.797169605447, 2400.4446182677198, 2285.025379713687, 2464.517437641847, 2298.2316921809534, 2510.473979246683, 2203.1062052636175, 2486.9125635583973, 2493.1480856101607, 2352.413073662273, 2298.0803399965084, 2276.967413364176, 2462.47088588949, 2398.3992899463165, 2333.5620076270075, 2321.6773456594797, 2343.315998439682, 2562.4994680734985, 2416.4306040502793, 2363.7514580241796, 2548.652185535964, 2472.7659005106493, 2374.0032024703214, 2433.0961423053423, 2354.0452874039806, 2440.9606769924058, 2441.715124716306, 2363.9929131023046, 2546.9200268963864, 2311.163237331966, 2462.531584158956, 2459.486932338949, 2482.781363204871, 2482.693126145688, 2442.7472544409043, 2375.885869031512, 2467.9324617012917], 'val_acc': [0.9139925091626258, 0.9272255527906578, 0.9365992316320622, 0.9395288645222201, 0.9379049676090645, 0.9457084180256508, 0.9489603438856882, 0.9476504985180647, 0.9469645586093711, 0.9485388947598761, 0.9487558283619375, 0.9456092345647972, 0.9466897745372197, 0.948625658144498, 0.9485719673460422, 0.9484293943676869, 0.9488322505071842, 0.947460436288205, 0.9495719388210574, 0.9503570292249072, 0.9468530030223911, 0.950848736243541, 0.9483364044621004, 0.9482558253091141, 0.9500347092830935, 0.9502309793866547, 0.9495843176069206, 0.9467848339560312, 0.9476979804438586, 0.9482599903085378, 0.9478426325920574, 0.9495181957436674, 0.9480740118293123, 0.9517474470857802, 0.948458304618324, 0.9468819252605545, 0.9496524953309384, 0.9514437510980575, 0.9456649998712806, 0.9510904550552368, 0.9463881384061036, 0.9466608606237273, 0.9483426143337228, 0.9500491898819055, 0.9448014231367484, 0.9486050166231293, 0.9506441987426587], 'val_mDice': [0.1928156378715398, 0.4683471335379105, 0.530020864649192, 0.5311270389476968, 0.5519598978857755, 0.557644966261347, 0.5999144552140262, 0.5509999719078981, 0.5912279992796189, 0.5817533611585308, 0.583408012736443, 0.5820398330688477, 0.5977446626684519, 0.5793227276988535, 0.5976468894068755, 0.5715160406501599, 0.6116182311287139, 0.5743976438511683, 0.5784947585793181, 0.5948738479081479, 0.5953837706390039, 0.6032484450153799, 0.5843456500735362, 0.5886805330574846, 0.5943634826377784, 0.5965734940001418, 0.5952829572075572, 0.5699100447766607, 0.5850392213746822, 0.5911171802595341, 0.5779001046825387, 0.5821292933139055, 0.5900008575210358, 0.5889881346478808, 0.5908919459614674, 0.5807405144142705, 0.5828328259164395, 0.5935972296325854, 0.571668020173824, 0.5996150397721616, 0.582118162895714, 0.5782821854399569, 0.5814573808089315, 0.5806468775152495, 0.5810951860257367, 0.5892083927905759, 0.5866456148344711], 'loss': [11476.43651362454, 4461.240552870746, 3504.687133529777, 3050.7691747655954, 2759.220158292904, 2557.174277101218, 2420.3755114440933, 2302.3537672250714, 2220.4474827600366, 2151.6928793177563, 2089.7470383339473, 2044.4778321482609, 2000.0653251355836, 1963.597574914114, 1910.9351132631134, 1885.8394573812723, 1862.6750348001112, 1820.8765453618892, 1801.1488690774922, 1800.587412801601, 1772.8501832238094, 1740.5451252246876, 1721.3896487566208, 1704.269928389051, 1685.049086665946, 1675.7310745341476, 1664.6032859711247, 1644.2895824872203, 1640.4423445013963, 1651.7726886766511, 1618.1101008533074, 1592.092815115992, 1590.3527497951777, 1578.4644793939515, 1575.40447323572, 1553.8594471445454, 1548.7943368968565, 1543.2311745651875, 1538.3433098926776, 1532.6782161807594, 1516.9462233768245, 1514.2915863723551, 1497.0148626273185, 1490.5029855136759, 1482.9164358138726, 1481.800695499611, 1472.6926454654492], 'acc': [0.8004203755561708, 0.8989735664732348, 0.9142900880733144, 0.923315884513693, 0.92852294841082, 0.9322074769427655, 0.9349109623356976, 0.9369018911166191, 0.9384835395124261, 0.9397926129427917, 0.9409435504558371, 0.9419397820665987, 0.9426034546308765, 0.9433490598255639, 0.9443628540304477, 0.9447480645823028, 0.9451880631126887, 0.9458190616027286, 0.9461471307031613, 0.9464352608707423, 0.9468201862480845, 0.9472224591058958, 0.9475024077349659, 0.9477601418385584, 0.9480834954425496, 0.9483360348849714, 0.9484768673833578, 0.9488038661939491, 0.9488867291840104, 0.9491923363222665, 0.9492560286620858, 0.9495617570937326, 0.9496993276264067, 0.9497653147369343, 0.9500599052578683, 0.9502439186253726, 0.9503391725936101, 0.9504348837169101, 0.9505379903479461, 0.9506956197345356, 0.9508124592127503, 0.9507172111656975, 0.9510854826170364, 0.9512349927381885, 0.951325974065256, 0.951303113903409, 0.9514966761356254], 'mDice': [0.17594437003151914, 0.41071174116307607, 0.4958045672087438, 0.5431081508150106, 0.5737262024715065, 0.596507591714553, 0.6131942564577236, 0.6274314741768626, 0.6379832359098101, 0.6467359466403666, 0.6547301521774445, 0.6607006274889669, 0.6664355777232036, 0.6713122932955458, 0.6783150916174602, 0.6817206480158848, 0.6849752995100593, 0.6906425812348166, 0.6934547207790629, 0.6936851988677061, 0.6973569680906758, 0.7019054078729862, 0.704602168786825, 0.7068979066543138, 0.709586288387379, 0.710947977182464, 0.7126563773468931, 0.7155122901611511, 0.7161204723366257, 0.7190936375051261, 0.7193440924762842, 0.7228635992140858, 0.7232154594268371, 0.7249530378714294, 0.7255912758050859, 0.728574549740848, 0.7294924211400792, 0.7302583772777362, 0.7309532907298562, 0.7317280149636436, 0.7340115794564934, 0.7343915446567728, 0.736913845274977, 0.7378790297154267, 0.7390952615863611, 0.7393122847988794, 0.7405439144833584]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 20)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 21)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 15)   2850        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 15)   2040        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 15)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 40, 26, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 30)   4080        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 30)   8130        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 45)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 60)   24360       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 60)   32460       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 105)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 30)   12630       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 30)   8130        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 105)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 40, 26, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 15)   6315        dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 15)   2040        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 45)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 80, 52, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 13)   598         dropout_6[0][0]                  
==================================================================================================
Total params: 129,458
Trainable params: 30,958
Non-trainable params: 98,500
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 22s - loss: 25807.0459 - acc: 0.6638 - mDice: 0.0792 - val_loss: 13480.8399 - val_acc: 0.8970 - val_mDice: 0.1865

Epoch 00001: val_mDice improved from -inf to 0.18652, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 14s - loss: 11276.1377 - acc: 0.8781 - mDice: 0.2439 - val_loss: 7634.0238 - val_acc: 0.9002 - val_mDice: 0.3508

Epoch 00002: val_mDice improved from 0.18652 to 0.35075, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 14s - loss: 8126.3682 - acc: 0.8880 - mDice: 0.3455 - val_loss: 7050.3490 - val_acc: 0.9124 - val_mDice: 0.3826

Epoch 00003: val_mDice improved from 0.35075 to 0.38258, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 15s - loss: 6992.9926 - acc: 0.8962 - mDice: 0.3989 - val_loss: 6150.3884 - val_acc: 0.9115 - val_mDice: 0.4305

Epoch 00004: val_mDice improved from 0.38258 to 0.43046, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 14s - loss: 6443.1212 - acc: 0.9018 - mDice: 0.4297 - val_loss: 5492.4595 - val_acc: 0.9204 - val_mDice: 0.4690

Epoch 00005: val_mDice improved from 0.43046 to 0.46897, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 14s - loss: 6024.8108 - acc: 0.9060 - mDice: 0.4532 - val_loss: 6112.2490 - val_acc: 0.9264 - val_mDice: 0.4368

Epoch 00006: val_mDice did not improve from 0.46897
Epoch 7/300
 - 14s - loss: 5716.7467 - acc: 0.9099 - mDice: 0.4720 - val_loss: 5668.0462 - val_acc: 0.9297 - val_mDice: 0.4649

Epoch 00007: val_mDice did not improve from 0.46897
Epoch 8/300
 - 14s - loss: 5437.7572 - acc: 0.9127 - mDice: 0.4890 - val_loss: 5891.3176 - val_acc: 0.9292 - val_mDice: 0.4491

Epoch 00008: val_mDice did not improve from 0.46897
Epoch 9/300
 - 15s - loss: 5155.8291 - acc: 0.9150 - mDice: 0.5066 - val_loss: 5251.4975 - val_acc: 0.9324 - val_mDice: 0.4827

Epoch 00009: val_mDice improved from 0.46897 to 0.48271, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 14s - loss: 4976.4431 - acc: 0.9166 - mDice: 0.5184 - val_loss: 4870.7659 - val_acc: 0.9338 - val_mDice: 0.5082

Epoch 00010: val_mDice improved from 0.48271 to 0.50817, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 14s - loss: 4800.7221 - acc: 0.9183 - mDice: 0.5306 - val_loss: 4873.4729 - val_acc: 0.9330 - val_mDice: 0.5064

Epoch 00011: val_mDice did not improve from 0.50817
Epoch 12/300
 - 14s - loss: 4668.0568 - acc: 0.9197 - mDice: 0.5399 - val_loss: 4903.9307 - val_acc: 0.9288 - val_mDice: 0.5067

Epoch 00012: val_mDice did not improve from 0.50817
Epoch 13/300
 - 14s - loss: 4544.7251 - acc: 0.9212 - mDice: 0.5488 - val_loss: 4798.0400 - val_acc: 0.9286 - val_mDice: 0.5130

Epoch 00013: val_mDice improved from 0.50817 to 0.51298, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 15s - loss: 4455.3721 - acc: 0.9222 - mDice: 0.5557 - val_loss: 4625.3919 - val_acc: 0.9299 - val_mDice: 0.5253

Epoch 00014: val_mDice improved from 0.51298 to 0.52532, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 14s - loss: 4397.7610 - acc: 0.9229 - mDice: 0.5599 - val_loss: 4604.8258 - val_acc: 0.9350 - val_mDice: 0.5264

Epoch 00015: val_mDice improved from 0.52532 to 0.52645, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 14s - loss: 4294.1030 - acc: 0.9240 - mDice: 0.5675 - val_loss: 4765.9418 - val_acc: 0.9326 - val_mDice: 0.5152

Epoch 00016: val_mDice did not improve from 0.52645
Epoch 17/300
 - 14s - loss: 4219.2076 - acc: 0.9250 - mDice: 0.5734 - val_loss: 4689.4340 - val_acc: 0.9302 - val_mDice: 0.5199

Epoch 00017: val_mDice did not improve from 0.52645
Epoch 18/300
 - 14s - loss: 4148.6992 - acc: 0.9255 - mDice: 0.5786 - val_loss: 4732.2445 - val_acc: 0.9311 - val_mDice: 0.5178

Epoch 00018: val_mDice did not improve from 0.52645
Epoch 19/300
 - 14s - loss: 4107.0552 - acc: 0.9261 - mDice: 0.5819 - val_loss: 4565.6771 - val_acc: 0.9319 - val_mDice: 0.5289

Epoch 00019: val_mDice improved from 0.52645 to 0.52890, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 20/300
 - 15s - loss: 4043.4578 - acc: 0.9267 - mDice: 0.5867 - val_loss: 4502.5490 - val_acc: 0.9357 - val_mDice: 0.5321

Epoch 00020: val_mDice improved from 0.52890 to 0.53213, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 21/300
 - 14s - loss: 3984.0439 - acc: 0.9274 - mDice: 0.5910 - val_loss: 4461.9838 - val_acc: 0.9332 - val_mDice: 0.5347

Epoch 00021: val_mDice improved from 0.53213 to 0.53474, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 22/300
 - 13s - loss: 3948.0558 - acc: 0.9276 - mDice: 0.5941 - val_loss: 4497.1689 - val_acc: 0.9304 - val_mDice: 0.5312

Epoch 00022: val_mDice did not improve from 0.53474
Epoch 23/300
 - 14s - loss: 3890.7781 - acc: 0.9283 - mDice: 0.5986 - val_loss: 4374.6451 - val_acc: 0.9331 - val_mDice: 0.5410

Epoch 00023: val_mDice improved from 0.53474 to 0.54101, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 24/300
 - 14s - loss: 3872.6895 - acc: 0.9283 - mDice: 0.6001 - val_loss: 4683.7688 - val_acc: 0.9359 - val_mDice: 0.5198

Epoch 00024: val_mDice did not improve from 0.54101
Epoch 25/300
 - 15s - loss: 3834.7469 - acc: 0.9286 - mDice: 0.6031 - val_loss: 4477.7338 - val_acc: 0.9341 - val_mDice: 0.5306

Epoch 00025: val_mDice did not improve from 0.54101
Epoch 26/300
 - 14s - loss: 3788.7292 - acc: 0.9290 - mDice: 0.6067 - val_loss: 4427.6897 - val_acc: 0.9349 - val_mDice: 0.5351

Epoch 00026: val_mDice did not improve from 0.54101
Epoch 27/300
 - 14s - loss: 3744.6737 - acc: 0.9296 - mDice: 0.6102 - val_loss: 4600.4351 - val_acc: 0.9335 - val_mDice: 0.5243

Epoch 00027: val_mDice did not improve from 0.54101
Epoch 28/300
 - 14s - loss: 3731.6657 - acc: 0.9297 - mDice: 0.6114 - val_loss: 4519.1924 - val_acc: 0.9352 - val_mDice: 0.5294

Epoch 00028: val_mDice did not improve from 0.54101
Epoch 29/300
 - 14s - loss: 3717.8899 - acc: 0.9298 - mDice: 0.6126 - val_loss: 4587.5326 - val_acc: 0.9314 - val_mDice: 0.5244

Epoch 00029: val_mDice did not improve from 0.54101
Epoch 30/300
 - 14s - loss: 3665.8325 - acc: 0.9304 - mDice: 0.6167 - val_loss: 4468.3835 - val_acc: 0.9355 - val_mDice: 0.5333

Epoch 00030: val_mDice did not improve from 0.54101
Epoch 31/300
 - 15s - loss: 3650.5334 - acc: 0.9305 - mDice: 0.6180 - val_loss: 4436.9476 - val_acc: 0.9347 - val_mDice: 0.5358

Epoch 00031: val_mDice did not improve from 0.54101
Epoch 32/300
 - 14s - loss: 3628.9786 - acc: 0.9306 - mDice: 0.6198 - val_loss: 4531.5600 - val_acc: 0.9336 - val_mDice: 0.5293

Epoch 00032: val_mDice did not improve from 0.54101
Epoch 33/300
 - 14s - loss: 3594.3460 - acc: 0.9310 - mDice: 0.6224 - val_loss: 4852.6623 - val_acc: 0.9238 - val_mDice: 0.5069

Epoch 00033: val_mDice did not improve from 0.54101
Epoch 34/300
 - 14s - loss: 3580.0698 - acc: 0.9312 - mDice: 0.6239 - val_loss: 4368.4978 - val_acc: 0.9333 - val_mDice: 0.5392

Epoch 00034: val_mDice did not improve from 0.54101
Epoch 35/300
 - 13s - loss: 3555.3301 - acc: 0.9315 - mDice: 0.6259 - val_loss: 4306.8146 - val_acc: 0.9353 - val_mDice: 0.5425

Epoch 00035: val_mDice improved from 0.54101 to 0.54247, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 36/300
 - 13s - loss: 3526.9568 - acc: 0.9317 - mDice: 0.6281 - val_loss: 4485.7817 - val_acc: 0.9313 - val_mDice: 0.5308

Epoch 00036: val_mDice did not improve from 0.54247
Epoch 37/300
 - 14s - loss: 3531.0850 - acc: 0.9316 - mDice: 0.6278 - val_loss: 4387.2319 - val_acc: 0.9357 - val_mDice: 0.5400

Epoch 00037: val_mDice did not improve from 0.54247
Epoch 38/300
 - 14s - loss: 3494.7504 - acc: 0.9320 - mDice: 0.6308 - val_loss: 4256.7696 - val_acc: 0.9373 - val_mDice: 0.5471

Epoch 00038: val_mDice improved from 0.54247 to 0.54707, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 39/300
 - 14s - loss: 3470.5244 - acc: 0.9321 - mDice: 0.6327 - val_loss: 4433.2663 - val_acc: 0.9330 - val_mDice: 0.5346

Epoch 00039: val_mDice did not improve from 0.54707
Epoch 40/300
 - 13s - loss: 3446.6962 - acc: 0.9322 - mDice: 0.6348 - val_loss: 4449.8730 - val_acc: 0.9345 - val_mDice: 0.5322

Epoch 00040: val_mDice did not improve from 0.54707
Epoch 41/300
 - 14s - loss: 3409.3754 - acc: 0.9326 - mDice: 0.6379 - val_loss: 4556.2099 - val_acc: 0.9327 - val_mDice: 0.5260

Epoch 00041: val_mDice did not improve from 0.54707
Epoch 42/300
 - 14s - loss: 3410.1055 - acc: 0.9325 - mDice: 0.6378 - val_loss: 4410.8047 - val_acc: 0.9368 - val_mDice: 0.5360

Epoch 00042: val_mDice did not improve from 0.54707
Epoch 43/300
 - 14s - loss: 3399.4262 - acc: 0.9326 - mDice: 0.6388 - val_loss: 4426.8417 - val_acc: 0.9366 - val_mDice: 0.5350

Epoch 00043: val_mDice did not improve from 0.54707
Epoch 44/300
 - 14s - loss: 3391.0537 - acc: 0.9327 - mDice: 0.6395 - val_loss: 4329.0486 - val_acc: 0.9380 - val_mDice: 0.5430

Epoch 00044: val_mDice did not improve from 0.54707
Epoch 45/300
 - 14s - loss: 3368.2813 - acc: 0.9328 - mDice: 0.6413 - val_loss: 4162.7582 - val_acc: 0.9390 - val_mDice: 0.5527

Epoch 00045: val_mDice improved from 0.54707 to 0.55272, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 46/300
 - 14s - loss: 3366.8570 - acc: 0.9328 - mDice: 0.6416 - val_loss: 4421.1642 - val_acc: 0.9371 - val_mDice: 0.5376

Epoch 00046: val_mDice did not improve from 0.55272
Epoch 47/300
 - 14s - loss: 3340.3422 - acc: 0.9331 - mDice: 0.6437 - val_loss: 4103.4401 - val_acc: 0.9392 - val_mDice: 0.5580

Epoch 00047: val_mDice improved from 0.55272 to 0.55802, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 48/300
 - 14s - loss: 3334.0857 - acc: 0.9333 - mDice: 0.6444 - val_loss: 4146.4573 - val_acc: 0.9349 - val_mDice: 0.5554

Epoch 00048: val_mDice did not improve from 0.55802
Epoch 49/300
 - 14s - loss: 3320.3964 - acc: 0.9334 - mDice: 0.6455 - val_loss: 4242.4619 - val_acc: 0.9390 - val_mDice: 0.5483

Epoch 00049: val_mDice did not improve from 0.55802
Epoch 50/300
 - 14s - loss: 3305.7879 - acc: 0.9336 - mDice: 0.6468 - val_loss: 4538.1211 - val_acc: 0.9303 - val_mDice: 0.5260

Epoch 00050: val_mDice did not improve from 0.55802
Epoch 51/300
 - 14s - loss: 3290.2726 - acc: 0.9337 - mDice: 0.6480 - val_loss: 4243.3523 - val_acc: 0.9382 - val_mDice: 0.5482

Epoch 00051: val_mDice did not improve from 0.55802
Epoch 52/300
 - 14s - loss: 3283.1645 - acc: 0.9339 - mDice: 0.6486 - val_loss: 4201.4291 - val_acc: 0.9389 - val_mDice: 0.5510

Epoch 00052: val_mDice did not improve from 0.55802
Epoch 53/300
 - 15s - loss: 3278.0488 - acc: 0.9340 - mDice: 0.6490 - val_loss: 4247.4381 - val_acc: 0.9365 - val_mDice: 0.5471

Epoch 00053: val_mDice did not improve from 0.55802
Epoch 54/300
 - 14s - loss: 3273.8773 - acc: 0.9339 - mDice: 0.6494 - val_loss: 4214.3268 - val_acc: 0.9396 - val_mDice: 0.5497

Epoch 00054: val_mDice did not improve from 0.55802
Epoch 55/300
 - 15s - loss: 3242.9380 - acc: 0.9342 - mDice: 0.6520 - val_loss: 4410.5472 - val_acc: 0.9298 - val_mDice: 0.5378

Epoch 00055: val_mDice did not improve from 0.55802
Epoch 56/300
 - 14s - loss: 3255.4419 - acc: 0.9341 - mDice: 0.6511 - val_loss: 4126.0301 - val_acc: 0.9396 - val_mDice: 0.5574

Epoch 00056: val_mDice did not improve from 0.55802
Epoch 57/300
 - 14s - loss: 3226.3838 - acc: 0.9343 - mDice: 0.6535 - val_loss: 4335.4955 - val_acc: 0.9389 - val_mDice: 0.5406

Epoch 00057: val_mDice did not improve from 0.55802
Epoch 58/300
 - 14s - loss: 3227.7342 - acc: 0.9343 - mDice: 0.6534 - val_loss: 4107.6473 - val_acc: 0.9383 - val_mDice: 0.5592

Epoch 00058: val_mDice improved from 0.55802 to 0.55923, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 59/300
 - 14s - loss: 3234.6541 - acc: 0.9342 - mDice: 0.6529 - val_loss: 4523.2604 - val_acc: 0.9384 - val_mDice: 0.5293

Epoch 00059: val_mDice did not improve from 0.55923
Epoch 60/300
 - 14s - loss: 3205.7670 - acc: 0.9345 - mDice: 0.6553 - val_loss: 4097.1709 - val_acc: 0.9352 - val_mDice: 0.5575

Epoch 00060: val_mDice did not improve from 0.55923
Epoch 61/300
 - 14s - loss: 3191.4772 - acc: 0.9347 - mDice: 0.6564 - val_loss: 4247.8531 - val_acc: 0.9352 - val_mDice: 0.5489

Epoch 00061: val_mDice did not improve from 0.55923
Epoch 62/300
 - 15s - loss: 3184.3878 - acc: 0.9348 - mDice: 0.6572 - val_loss: 4004.8866 - val_acc: 0.9396 - val_mDice: 0.5673

Epoch 00062: val_mDice improved from 0.55923 to 0.56728, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 63/300
 - 14s - loss: 3187.2864 - acc: 0.9348 - mDice: 0.6571 - val_loss: 4118.5350 - val_acc: 0.9369 - val_mDice: 0.5573

Epoch 00063: val_mDice did not improve from 0.56728
Epoch 64/300
 - 14s - loss: 3151.3556 - acc: 0.9352 - mDice: 0.6600 - val_loss: 4315.8819 - val_acc: 0.9375 - val_mDice: 0.5437

Epoch 00064: val_mDice did not improve from 0.56728
Epoch 65/300
 - 14s - loss: 3157.0710 - acc: 0.9351 - mDice: 0.6596 - val_loss: 4235.3742 - val_acc: 0.9337 - val_mDice: 0.5488

Epoch 00065: val_mDice did not improve from 0.56728
Epoch 66/300
 - 14s - loss: 3145.0684 - acc: 0.9353 - mDice: 0.6606 - val_loss: 4196.6853 - val_acc: 0.9387 - val_mDice: 0.5512

Epoch 00066: val_mDice did not improve from 0.56728
Epoch 67/300
 - 14s - loss: 3135.8429 - acc: 0.9354 - mDice: 0.6613 - val_loss: 4222.6936 - val_acc: 0.9383 - val_mDice: 0.5497

Epoch 00067: val_mDice did not improve from 0.56728
Epoch 68/300
 - 15s - loss: 3134.8446 - acc: 0.9353 - mDice: 0.6615 - val_loss: 4030.0168 - val_acc: 0.9393 - val_mDice: 0.5637

Epoch 00068: val_mDice did not improve from 0.56728
Epoch 69/300
 - 14s - loss: 3121.0182 - acc: 0.9355 - mDice: 0.6627 - val_loss: 4047.8714 - val_acc: 0.9401 - val_mDice: 0.5629

Epoch 00069: val_mDice did not improve from 0.56728
Epoch 70/300
 - 14s - loss: 3114.7930 - acc: 0.9354 - mDice: 0.6632 - val_loss: 4380.4372 - val_acc: 0.9320 - val_mDice: 0.5395

Epoch 00070: val_mDice did not improve from 0.56728
Epoch 71/300
 - 14s - loss: 3100.1112 - acc: 0.9356 - mDice: 0.6645 - val_loss: 4293.1828 - val_acc: 0.9343 - val_mDice: 0.5432

Epoch 00071: val_mDice did not improve from 0.56728
Epoch 72/300
 - 14s - loss: 3103.9393 - acc: 0.9356 - mDice: 0.6640 - val_loss: 4131.4721 - val_acc: 0.9404 - val_mDice: 0.5558

Epoch 00072: val_mDice did not improve from 0.56728
Epoch 73/300
 - 14s - loss: 3098.9120 - acc: 0.9356 - mDice: 0.6645 - val_loss: 4299.4675 - val_acc: 0.9343 - val_mDice: 0.5441

Epoch 00073: val_mDice did not improve from 0.56728
Epoch 74/300
 - 15s - loss: 3112.9584 - acc: 0.9355 - mDice: 0.6634 - val_loss: 4468.6312 - val_acc: 0.9370 - val_mDice: 0.5325

Epoch 00074: val_mDice did not improve from 0.56728
Epoch 75/300
 - 14s - loss: 3083.7829 - acc: 0.9357 - mDice: 0.6658 - val_loss: 4222.1271 - val_acc: 0.9366 - val_mDice: 0.5489

Epoch 00075: val_mDice did not improve from 0.56728
Epoch 76/300
 - 13s - loss: 3063.5786 - acc: 0.9360 - mDice: 0.6676 - val_loss: 4226.9766 - val_acc: 0.9379 - val_mDice: 0.5477

Epoch 00076: val_mDice did not improve from 0.56728
Epoch 77/300
 - 14s - loss: 3053.4095 - acc: 0.9360 - mDice: 0.6685 - val_loss: 4415.0341 - val_acc: 0.9392 - val_mDice: 0.5390

Epoch 00077: val_mDice did not improve from 0.56728
Epoch 78/300
 - 14s - loss: 3056.8105 - acc: 0.9361 - mDice: 0.6682 - val_loss: 4416.7535 - val_acc: 0.9387 - val_mDice: 0.5361

Epoch 00078: val_mDice did not improve from 0.56728
Epoch 79/300
 - 14s - loss: 3059.8283 - acc: 0.9360 - mDice: 0.6679 - val_loss: 4246.4810 - val_acc: 0.9376 - val_mDice: 0.5490

Epoch 00079: val_mDice did not improve from 0.56728
Epoch 80/300
 - 15s - loss: 3041.1954 - acc: 0.9362 - mDice: 0.6697 - val_loss: 4242.0567 - val_acc: 0.9320 - val_mDice: 0.5471

Epoch 00080: val_mDice did not improve from 0.56728
Epoch 81/300
 - 14s - loss: 3038.9318 - acc: 0.9363 - mDice: 0.6699 - val_loss: 4148.5302 - val_acc: 0.9403 - val_mDice: 0.5553

Epoch 00081: val_mDice did not improve from 0.56728
Epoch 82/300
 - 14s - loss: 3044.2873 - acc: 0.9363 - mDice: 0.6694 - val_loss: 4149.1907 - val_acc: 0.9365 - val_mDice: 0.5550

Epoch 00082: val_mDice did not improve from 0.56728
Epoch 83/300
 - 14s - loss: 3022.2575 - acc: 0.9366 - mDice: 0.6713 - val_loss: 4038.6217 - val_acc: 0.9418 - val_mDice: 0.5648

Epoch 00083: val_mDice did not improve from 0.56728
Epoch 84/300
 - 14s - loss: 3019.4113 - acc: 0.9365 - mDice: 0.6714 - val_loss: 4129.3285 - val_acc: 0.9377 - val_mDice: 0.5555

Epoch 00084: val_mDice did not improve from 0.56728
Epoch 85/300
 - 14s - loss: 3025.5156 - acc: 0.9364 - mDice: 0.6709 - val_loss: 4433.9821 - val_acc: 0.9295 - val_mDice: 0.5351

Epoch 00085: val_mDice did not improve from 0.56728
Epoch 86/300
 - 14s - loss: 3002.4135 - acc: 0.9366 - mDice: 0.6731 - val_loss: 4245.5578 - val_acc: 0.9389 - val_mDice: 0.5481

Epoch 00086: val_mDice did not improve from 0.56728
Epoch 87/300
 - 14s - loss: 3000.3260 - acc: 0.9367 - mDice: 0.6733 - val_loss: 4274.7452 - val_acc: 0.9351 - val_mDice: 0.5461

Epoch 00087: val_mDice did not improve from 0.56728
Epoch 88/300
 - 14s - loss: 3009.8589 - acc: 0.9367 - mDice: 0.6723 - val_loss: 4285.5010 - val_acc: 0.9387 - val_mDice: 0.5459

Epoch 00088: val_mDice did not improve from 0.56728
Epoch 89/300
 - 14s - loss: 2986.1683 - acc: 0.9369 - mDice: 0.6744 - val_loss: 4336.6765 - val_acc: 0.9345 - val_mDice: 0.5398

Epoch 00089: val_mDice did not improve from 0.56728
Epoch 90/300
 - 14s - loss: 2982.8546 - acc: 0.9370 - mDice: 0.6748 - val_loss: 4219.6146 - val_acc: 0.9356 - val_mDice: 0.5487

Epoch 00090: val_mDice did not improve from 0.56728
Epoch 91/300
 - 14s - loss: 2995.3249 - acc: 0.9369 - mDice: 0.6737 - val_loss: 4163.7563 - val_acc: 0.9395 - val_mDice: 0.5551

Epoch 00091: val_mDice did not improve from 0.56728
Epoch 92/300
 - 14s - loss: 2982.4023 - acc: 0.9371 - mDice: 0.6747 - val_loss: 4144.6339 - val_acc: 0.9378 - val_mDice: 0.5552

Epoch 00092: val_mDice did not improve from 0.56728
Restoring model weights from the end of the best epoch
Epoch 00092: early stopping
{'val_loss': [13480.839909480168, 7634.023766150842, 7050.349008413462, 6150.388427734375, 5492.459482046274, 6112.249042217548, 5668.046151968149, 5891.317551832933, 5251.497530423678, 4870.765916090745, 4873.472891000601, 4903.930734487681, 4798.039973332332, 4625.391850398137, 4604.825843224158, 4765.94175368089, 4689.434044471154, 4732.24448805589, 4565.677081768329, 4502.549025315505, 4461.983759953426, 4497.1689218374395, 4374.645080566406, 4683.768761268029, 4477.733811598558, 4427.689739520733, 4600.435133713942, 4519.192364032452, 4587.532611553485, 4468.383451021635, 4436.947636530949, 4531.559959998498, 4852.662273700421, 4368.497774564303, 4306.814603365385, 4485.781719501202, 4387.23188664363, 4256.76962515024, 4433.266305776743, 4449.872950627254, 4556.209899902344, 4410.804659329928, 4426.841670109676, 4329.048555814303, 4162.758230356069, 4421.164189265324, 4103.4400634765625, 4146.457266000601, 4242.46186711238, 4538.121063232422, 4243.352257361779, 4201.4291100135215, 4247.438054011418, 4214.3267822265625, 4410.5472412109375, 4126.030137282151, 4335.495544433594, 4107.647327129657, 4523.260432316707, 4097.170928955078, 4247.853064903846, 4004.886638934796, 4118.5349684495195, 4315.88192983774, 4235.3741783728965, 4196.685316819411, 4222.693589430589, 4030.0167940579927, 4047.8714482234072, 4380.437171349158, 4293.182769775391, 4131.472102238582, 4299.467515211839, 4468.631234975962, 4222.127112755408, 4226.97664466271, 4415.034081092248, 4416.753450833834, 4246.48100398137, 4242.056720440204, 4148.530198317308, 4149.190704345703, 4038.621661846454, 4129.328538161058, 4433.982149564303, 4245.5578378530645, 4274.745171180139, 4285.501028207632, 4336.676480806791, 4219.614642803485, 4163.756277231069, 4144.633906437801], 'val_acc': [0.8969697470848377, 0.9001710208562704, 0.9124098764016078, 0.9115060957578512, 0.9204465334232037, 0.9264377103402064, 0.9297383702718295, 0.9291651386481065, 0.9323871961006751, 0.9338087279063004, 0.9330136179924011, 0.9287953078746796, 0.9286496845575479, 0.9299117005788363, 0.9350476287878476, 0.9326206468618833, 0.9301936970307276, 0.9311159276045285, 0.9318925600785476, 0.9356878858346206, 0.9331707839782422, 0.930357806957685, 0.9331060418715844, 0.9359397956958184, 0.9340583613285651, 0.9349158406257629, 0.9335313416444339, 0.935225608257147, 0.9313909778228173, 0.9355029670091776, 0.9347032056404994, 0.9336399986193731, 0.9237518562720373, 0.9332516858210931, 0.9352556467056274, 0.931284677523833, 0.9356948114358462, 0.9372665584087372, 0.9329858376429632, 0.9344905867026403, 0.9327107828397018, 0.9367649784454932, 0.9366147288909326, 0.9379668763050666, 0.9390278435670413, 0.9371024347268618, 0.9392427847935603, 0.9349066362931178, 0.9390417085244105, 0.9302861782220694, 0.9381749309026278, 0.9388521795089428, 0.9365130479519184, 0.9395941174947299, 0.929773021202821, 0.9395640721687903, 0.9388567713590769, 0.938315918812385, 0.9383598566055298, 0.9351631723917447, 0.9351862989939176, 0.939603369969588, 0.9368666708469391, 0.9375462050621326, 0.9337116434023931, 0.9386811279333555, 0.9382812243241531, 0.9393491309422713, 0.9401419185675107, 0.9319572838453146, 0.9342687038274912, 0.9403938696934626, 0.9343172151308793, 0.9369637370109558, 0.9366448086041671, 0.9379484286675086, 0.9391757524930514, 0.9387204280266395, 0.937641020004566, 0.9319896331200233, 0.9402667238162115, 0.9365453857641953, 0.9417575918711149, 0.9377427124060117, 0.9294725473110492, 0.9388914796022269, 0.9351100463133591, 0.9387435431663806, 0.9344928516791418, 0.9356092696006482, 0.9395086238017449, 0.9377681062771723], 'val_mDice': [0.1865167967402018, 0.3507503689481662, 0.38257696393590707, 0.4304584665940358, 0.46896991764123624, 0.43682377212322676, 0.4648996591567993, 0.44910787561765086, 0.4827064745701276, 0.5081705814943864, 0.5064453846560075, 0.5066630003544, 0.5129818635491225, 0.5253161094509639, 0.526448209125262, 0.5152009891775938, 0.5198605679548703, 0.5178207583152331, 0.5289027129228299, 0.5321320507388848, 0.5347386105702474, 0.5312251311082107, 0.5410089469872988, 0.5197703557518812, 0.5305906104353758, 0.5350500477048067, 0.5243098305968138, 0.5293917432427406, 0.5244360675032322, 0.5333486847006358, 0.5357821383155309, 0.52930775227455, 0.5069451412329307, 0.5392465998346989, 0.5424710578070238, 0.530798114836216, 0.5400079540335215, 0.5470665544271469, 0.5346484694343346, 0.5321522183143176, 0.526009508050405, 0.535999793272752, 0.5349551255886371, 0.5430173226273977, 0.552717828979859, 0.5376060324219557, 0.558020932170061, 0.5553697829063122, 0.5483339434632888, 0.5259937002108648, 0.5481876464417348, 0.5509914853251897, 0.5470548856716889, 0.549742131279065, 0.5377807330626708, 0.5574429115423789, 0.5406043546704146, 0.559229470216311, 0.5292657613754272, 0.5574989634064528, 0.5488628389743658, 0.5672829810243386, 0.557296691605678, 0.5437304486448948, 0.5487979765121753, 0.5511830735665101, 0.549659037246154, 0.5636853845073626, 0.5629077364618962, 0.5394843071699142, 0.5432144013734964, 0.555837862766706, 0.5440807090355799, 0.5325456227247531, 0.5489363492681429, 0.5477019236064874, 0.5389962007219975, 0.5360644044211278, 0.5490026880915349, 0.5470854061154219, 0.5553334120374459, 0.5550203300439395, 0.5648384504020214, 0.5555216051065005, 0.5350799743945782, 0.5481115814584953, 0.5460731507493899, 0.5458531617545165, 0.5397839167943368, 0.5486743988899084, 0.5550702328865345, 0.5552463176158758], 'loss': [25807.045915099316, 11276.137729018901, 8126.368182322949, 6992.992578602339, 6443.121235938329, 6024.810787570682, 5716.746725795696, 5437.757245435383, 5155.829100887021, 4976.443100306289, 4800.722054792244, 4668.05678704633, 4544.7250952020095, 4455.372083045279, 4397.760955886538, 4294.1029824806865, 4219.207563324805, 4148.699159195268, 4107.055150732237, 4043.4577854222985, 3984.0438667880667, 3948.055775617856, 3890.778136019314, 3872.6895052269465, 3834.7468521665583, 3788.729240909314, 3744.673734796319, 3731.6656581052257, 3717.8899387583724, 3665.8324914200657, 3650.533426337034, 3628.978601253221, 3594.3459536489013, 3580.069760442275, 3555.3300616996025, 3526.9568215475456, 3531.0849560290194, 3494.7503843475483, 3470.524364955177, 3446.696186322145, 3409.375440682497, 3410.105478116642, 3399.4262065878656, 3391.053667504201, 3368.2813430247156, 3366.857048132472, 3340.3421952162216, 3334.0857360834216, 3320.39636329539, 3305.78790434623, 3290.2725816005645, 3283.1645376882157, 3278.0487688517183, 3273.877264306915, 3242.9379854329804, 3255.441898640414, 3226.383831302453, 3227.734249147005, 3234.654090628747, 3205.7669906271435, 3191.4772091135264, 3184.3877527394725, 3187.286377065705, 3151.3555655348823, 3157.0710467681843, 3145.068376836132, 3135.8429177085554, 3134.8446325358236, 3121.018173458413, 3114.793004854352, 3100.1112108618463, 3103.939277680589, 3098.912016642992, 3112.958369734146, 3083.782938157106, 3063.578569093666, 3053.4095294280078, 3056.8105431486074, 3059.8283306946123, 3041.195423514973, 3038.9317547246605, 3044.2873235806474, 3022.2575164488144, 3019.411251708061, 3025.515575937709, 3002.413533127111, 3000.3259537290583, 3009.8588656663214, 2986.168270047406, 2982.8546338579613, 2995.324927834076, 2982.402333550267], 'acc': [0.6638262493302767, 0.8780795957927147, 0.8879525703905825, 0.896208606049505, 0.9017917423750502, 0.9060040078270449, 0.9099160033618899, 0.9127461491866403, 0.9149949640175804, 0.9166105715186023, 0.9183315700142517, 0.9196901449987416, 0.921183531848111, 0.9221979851301862, 0.9229024497002437, 0.9240010386516849, 0.9250217264707619, 0.9255109177923814, 0.9260554919875681, 0.9267002929568587, 0.9273624346780236, 0.9276282454475886, 0.9282542920679907, 0.9283476935028425, 0.92864999778924, 0.929044437317196, 0.9295890783786466, 0.9296740970191157, 0.9297794700713327, 0.9303515572164438, 0.9305404374369239, 0.9305685286722885, 0.9310417407049109, 0.9311616771568355, 0.931515211913019, 0.9316756568919862, 0.9316095648013741, 0.9319505974297196, 0.9320553767992256, 0.9322409590957548, 0.9325991073273033, 0.9324956868645407, 0.9326426012923025, 0.932736202534369, 0.9328251684722365, 0.9328195392112499, 0.9331319102620459, 0.9332666991162232, 0.9334153444754025, 0.9335513551835698, 0.9336690334973383, 0.9338668999961741, 0.9339816710127243, 0.9339144054807487, 0.934159845930068, 0.9341479813130175, 0.9342503632653038, 0.9343272483371934, 0.9342428473301351, 0.9345035165160782, 0.9347081837877954, 0.9348459053850917, 0.9348183925835879, 0.9351886891960317, 0.9351450611082135, 0.935301177244196, 0.9353559154992744, 0.9352611835280171, 0.9354584047542137, 0.9354304951472794, 0.9355683430615666, 0.9356440085937294, 0.9356333655283304, 0.9355316065086228, 0.9357043298245312, 0.9359693470931764, 0.9360000939812485, 0.9360565637339419, 0.9360213751976729, 0.9361583410038957, 0.9363247034768056, 0.9363286928597119, 0.9366117278599249, 0.9364959854355358, 0.9363554284096116, 0.9366010018878347, 0.9367134244275095, 0.9366851815996625, 0.936932701933904, 0.9370169686862136, 0.9369432799030931, 0.9370996381296923], 'mDice': [0.0791539924569173, 0.24393193580002007, 0.34553427455126884, 0.3989449018159168, 0.42972292464333334, 0.4531975418211052, 0.47195960355510813, 0.4889736461879076, 0.5065777879144766, 0.5184365688825483, 0.5305595450281251, 0.5398801337042209, 0.5487898945599522, 0.5556927199987295, 0.5599029667316124, 0.5674889818951179, 0.5733917386430903, 0.5786397498295798, 0.5819193975386514, 0.5866879596708446, 0.5910004501983511, 0.5940707894936266, 0.598603386204148, 0.6001263992995076, 0.603129169591995, 0.6066521405624, 0.6101630206017062, 0.6114020192907886, 0.6126120501554926, 0.6166544093820076, 0.61796834529749, 0.6198291589300604, 0.6224429875428107, 0.6238667797384849, 0.6259315911555745, 0.6281478038564617, 0.6278178303551544, 0.6308297977053481, 0.6327268072108243, 0.6347979911521694, 0.6378753504321704, 0.6378012751176284, 0.6387919846423644, 0.6394767627212093, 0.6413004951240457, 0.6415600508745555, 0.6437388409396704, 0.6444000690216224, 0.6454854815151159, 0.6468334082119978, 0.6479506441217215, 0.6486447208384839, 0.6490151221754585, 0.6493729508243056, 0.6519964237907084, 0.6510517556190403, 0.6534535661786396, 0.6533756832250598, 0.6528650919339825, 0.6552504547449493, 0.656437710885422, 0.6571763795888546, 0.6570728348485111, 0.6599897014955132, 0.6596043552792096, 0.6605778031163162, 0.6612620310876617, 0.6615170355785556, 0.6627381142243615, 0.6632122981925408, 0.6645435921811402, 0.6640136885783731, 0.6644988609703772, 0.6633847401743059, 0.665765410198295, 0.6676072974624113, 0.6685039126476129, 0.6682125887593297, 0.6678635804490235, 0.669678381840967, 0.6698730736105114, 0.6694465811969631, 0.671298122297164, 0.6714492050976724, 0.6709483494169761, 0.6730649194340969, 0.6732808274557853, 0.6723198810209046, 0.6743934023350595, 0.6747962638074749, 0.6736643473006786, 0.6747084512137118]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.27s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.01s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.84s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:59,  1.90s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:08,  1.73s/it]predicting train subjects:   1%|          | 3/285 [00:04<08:04,  1.72s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:28,  1.60s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:40,  1.64s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:21,  1.58s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:39,  1.65s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:35,  1.65s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<08:02,  1.75s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:15,  1.80s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<07:51,  1.72s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:05,  1.78s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:57,  1.76s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<07:57,  1.76s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<08:11,  1.82s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<08:14,  1.84s/it]predicting train subjects:   6%|▌         | 17/285 [00:29<07:47,  1.74s/it]predicting train subjects:   6%|▋         | 18/285 [00:30<07:40,  1.73s/it]predicting train subjects:   7%|▋         | 19/285 [00:32<07:28,  1.69s/it]predicting train subjects:   7%|▋         | 20/285 [00:34<07:25,  1.68s/it]predicting train subjects:   7%|▋         | 21/285 [00:35<07:37,  1.73s/it]predicting train subjects:   8%|▊         | 22/285 [00:37<07:25,  1.69s/it]predicting train subjects:   8%|▊         | 23/285 [00:39<07:38,  1.75s/it]predicting train subjects:   8%|▊         | 24/285 [00:40<07:24,  1.70s/it]predicting train subjects:   9%|▉         | 25/285 [00:42<07:42,  1.78s/it]predicting train subjects:   9%|▉         | 26/285 [00:44<08:02,  1.86s/it]predicting train subjects:   9%|▉         | 27/285 [00:46<07:41,  1.79s/it]predicting train subjects:  10%|▉         | 28/285 [00:48<07:44,  1.81s/it]predicting train subjects:  10%|█         | 29/285 [00:50<07:36,  1.78s/it]predicting train subjects:  11%|█         | 30/285 [00:52<07:46,  1.83s/it]predicting train subjects:  11%|█         | 31/285 [00:53<07:50,  1.85s/it]predicting train subjects:  11%|█         | 32/285 [00:55<07:31,  1.78s/it]predicting train subjects:  12%|█▏        | 33/285 [00:57<07:26,  1.77s/it]predicting train subjects:  12%|█▏        | 34/285 [00:59<07:26,  1.78s/it]predicting train subjects:  12%|█▏        | 35/285 [01:01<07:29,  1.80s/it]predicting train subjects:  13%|█▎        | 36/285 [01:02<07:12,  1.74s/it]predicting train subjects:  13%|█▎        | 37/285 [01:04<07:19,  1.77s/it]predicting train subjects:  13%|█▎        | 38/285 [01:06<07:26,  1.81s/it]predicting train subjects:  14%|█▎        | 39/285 [01:07<07:05,  1.73s/it]predicting train subjects:  14%|█▍        | 40/285 [01:09<07:08,  1.75s/it]predicting train subjects:  14%|█▍        | 41/285 [01:11<06:56,  1.71s/it]predicting train subjects:  15%|█▍        | 42/285 [01:12<06:48,  1.68s/it]predicting train subjects:  15%|█▌        | 43/285 [01:14<07:03,  1.75s/it]predicting train subjects:  15%|█▌        | 44/285 [01:16<07:17,  1.81s/it]predicting train subjects:  16%|█▌        | 45/285 [01:18<06:58,  1.74s/it]predicting train subjects:  16%|█▌        | 46/285 [01:20<07:04,  1.78s/it]predicting train subjects:  16%|█▋        | 47/285 [01:21<06:46,  1.71s/it]predicting train subjects:  17%|█▋        | 48/285 [01:23<06:55,  1.75s/it]predicting train subjects:  17%|█▋        | 49/285 [01:25<07:10,  1.82s/it]predicting train subjects:  18%|█▊        | 50/285 [01:27<07:12,  1.84s/it]predicting train subjects:  18%|█▊        | 51/285 [01:29<07:14,  1.86s/it]predicting train subjects:  18%|█▊        | 52/285 [01:30<06:55,  1.78s/it]predicting train subjects:  19%|█▊        | 53/285 [01:32<06:59,  1.81s/it]predicting train subjects:  19%|█▉        | 54/285 [01:34<07:03,  1.83s/it]predicting train subjects:  19%|█▉        | 55/285 [01:36<06:44,  1.76s/it]predicting train subjects:  20%|█▉        | 56/285 [01:38<06:45,  1.77s/it]predicting train subjects:  20%|██        | 57/285 [01:39<06:32,  1.72s/it]predicting train subjects:  20%|██        | 58/285 [01:41<06:34,  1.74s/it]predicting train subjects:  21%|██        | 59/285 [01:43<06:43,  1.79s/it]predicting train subjects:  21%|██        | 60/285 [01:45<06:51,  1.83s/it]predicting train subjects:  21%|██▏       | 61/285 [01:46<06:33,  1.76s/it]predicting train subjects:  22%|██▏       | 62/285 [01:48<06:36,  1.78s/it]predicting train subjects:  22%|██▏       | 63/285 [01:50<06:36,  1.79s/it]predicting train subjects:  22%|██▏       | 64/285 [01:52<06:24,  1.74s/it]predicting train subjects:  23%|██▎       | 65/285 [01:53<06:25,  1.75s/it]predicting train subjects:  23%|██▎       | 66/285 [01:55<06:27,  1.77s/it]predicting train subjects:  24%|██▎       | 67/285 [01:57<06:22,  1.75s/it]predicting train subjects:  24%|██▍       | 68/285 [01:59<06:10,  1.71s/it]predicting train subjects:  24%|██▍       | 69/285 [02:00<06:14,  1.73s/it]predicting train subjects:  25%|██▍       | 70/285 [02:02<06:15,  1.75s/it]predicting train subjects:  25%|██▍       | 71/285 [02:04<06:17,  1.76s/it]predicting train subjects:  25%|██▌       | 72/285 [02:06<06:04,  1.71s/it]predicting train subjects:  26%|██▌       | 73/285 [02:07<06:07,  1.73s/it]predicting train subjects:  26%|██▌       | 74/285 [02:09<06:08,  1.75s/it]predicting train subjects:  26%|██▋       | 75/285 [02:11<06:11,  1.77s/it]predicting train subjects:  27%|██▋       | 76/285 [02:13<06:10,  1.77s/it]predicting train subjects:  27%|██▋       | 77/285 [02:14<06:01,  1.74s/it]predicting train subjects:  27%|██▋       | 78/285 [02:16<05:50,  1.69s/it]predicting train subjects:  28%|██▊       | 79/285 [02:18<05:51,  1.71s/it]predicting train subjects:  28%|██▊       | 80/285 [02:20<05:57,  1.74s/it]predicting train subjects:  28%|██▊       | 81/285 [02:21<05:48,  1.71s/it]predicting train subjects:  29%|██▉       | 82/285 [02:23<05:47,  1.71s/it]predicting train subjects:  29%|██▉       | 83/285 [02:25<05:40,  1.69s/it]predicting train subjects:  29%|██▉       | 84/285 [02:26<05:32,  1.66s/it]predicting train subjects:  30%|██▉       | 85/285 [02:28<05:41,  1.71s/it]predicting train subjects:  30%|███       | 86/285 [02:30<05:41,  1.72s/it]predicting train subjects:  31%|███       | 87/285 [02:31<05:42,  1.73s/it]predicting train subjects:  31%|███       | 88/285 [02:33<05:31,  1.68s/it]predicting train subjects:  31%|███       | 89/285 [02:35<05:31,  1.69s/it]predicting train subjects:  32%|███▏      | 90/285 [02:36<05:33,  1.71s/it]predicting train subjects:  32%|███▏      | 91/285 [02:38<05:24,  1.67s/it]predicting train subjects:  32%|███▏      | 92/285 [02:40<05:30,  1.71s/it]predicting train subjects:  33%|███▎      | 93/285 [02:42<05:24,  1.69s/it]predicting train subjects:  33%|███▎      | 94/285 [02:43<05:33,  1.75s/it]predicting train subjects:  33%|███▎      | 95/285 [02:45<05:43,  1.81s/it]predicting train subjects:  34%|███▎      | 96/285 [02:47<05:38,  1.79s/it]predicting train subjects:  34%|███▍      | 97/285 [02:49<05:36,  1.79s/it]predicting train subjects:  34%|███▍      | 98/285 [02:51<05:33,  1.78s/it]predicting train subjects:  35%|███▍      | 99/285 [02:52<05:33,  1.79s/it]predicting train subjects:  35%|███▌      | 100/285 [02:54<05:28,  1.77s/it]predicting train subjects:  35%|███▌      | 101/285 [02:56<05:17,  1.72s/it]predicting train subjects:  36%|███▌      | 102/285 [02:58<05:21,  1.76s/it]predicting train subjects:  36%|███▌      | 103/285 [02:59<05:15,  1.73s/it]predicting train subjects:  36%|███▋      | 104/285 [03:01<05:14,  1.74s/it]predicting train subjects:  37%|███▋      | 105/285 [03:03<05:17,  1.76s/it]predicting train subjects:  37%|███▋      | 106/285 [03:04<05:02,  1.69s/it]predicting train subjects:  38%|███▊      | 107/285 [03:06<05:00,  1.69s/it]predicting train subjects:  38%|███▊      | 108/285 [03:08<04:50,  1.64s/it]predicting train subjects:  38%|███▊      | 109/285 [03:09<04:54,  1.67s/it]predicting train subjects:  39%|███▊      | 110/285 [03:11<05:01,  1.72s/it]predicting train subjects:  39%|███▉      | 111/285 [03:13<04:51,  1.68s/it]predicting train subjects:  39%|███▉      | 112/285 [03:14<04:52,  1.69s/it]predicting train subjects:  40%|███▉      | 113/285 [03:16<04:56,  1.72s/it]predicting train subjects:  40%|████      | 114/285 [03:18<04:55,  1.73s/it]predicting train subjects:  40%|████      | 115/285 [03:20<04:58,  1.76s/it]predicting train subjects:  41%|████      | 116/285 [03:22<04:57,  1.76s/it]predicting train subjects:  41%|████      | 117/285 [03:23<04:46,  1.71s/it]predicting train subjects:  41%|████▏     | 118/285 [03:25<04:37,  1.66s/it]predicting train subjects:  42%|████▏     | 119/285 [03:27<04:43,  1.71s/it]predicting train subjects:  42%|████▏     | 120/285 [03:28<04:37,  1.68s/it]predicting train subjects:  42%|████▏     | 121/285 [03:30<04:31,  1.65s/it]predicting train subjects:  43%|████▎     | 122/285 [03:31<04:17,  1.58s/it]predicting train subjects:  43%|████▎     | 123/285 [03:33<04:08,  1.53s/it]predicting train subjects:  44%|████▎     | 124/285 [03:34<04:11,  1.56s/it]predicting train subjects:  44%|████▍     | 125/285 [03:36<04:05,  1.54s/it]predicting train subjects:  44%|████▍     | 126/285 [03:37<04:01,  1.52s/it]predicting train subjects:  45%|████▍     | 127/285 [03:39<03:55,  1.49s/it]predicting train subjects:  45%|████▍     | 128/285 [03:40<03:58,  1.52s/it]predicting train subjects:  45%|████▌     | 129/285 [03:42<04:03,  1.56s/it]predicting train subjects:  46%|████▌     | 130/285 [03:43<03:55,  1.52s/it]predicting train subjects:  46%|████▌     | 131/285 [03:45<03:50,  1.50s/it]predicting train subjects:  46%|████▋     | 132/285 [03:46<03:57,  1.55s/it]predicting train subjects:  47%|████▋     | 133/285 [03:48<03:56,  1.55s/it]predicting train subjects:  47%|████▋     | 134/285 [03:49<03:48,  1.51s/it]predicting train subjects:  47%|████▋     | 135/285 [03:51<03:41,  1.48s/it]predicting train subjects:  48%|████▊     | 136/285 [03:52<03:38,  1.47s/it]predicting train subjects:  48%|████▊     | 137/285 [03:54<03:46,  1.53s/it]predicting train subjects:  48%|████▊     | 138/285 [03:55<03:44,  1.53s/it]predicting train subjects:  49%|████▉     | 139/285 [03:57<03:48,  1.57s/it]predicting train subjects:  49%|████▉     | 140/285 [03:59<03:50,  1.59s/it]predicting train subjects:  49%|████▉     | 141/285 [04:00<03:39,  1.53s/it]predicting train subjects:  50%|████▉     | 142/285 [04:02<03:35,  1.51s/it]predicting train subjects:  50%|█████     | 143/285 [04:03<03:32,  1.49s/it]predicting train subjects:  51%|█████     | 144/285 [04:05<03:35,  1.53s/it]predicting train subjects:  51%|█████     | 145/285 [04:06<03:34,  1.53s/it]predicting train subjects:  51%|█████     | 146/285 [04:08<03:33,  1.54s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:09<03:27,  1.50s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:11<03:28,  1.53s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:12<03:24,  1.50s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:14<03:19,  1.48s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:15<03:22,  1.51s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:17<03:15,  1.47s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:18<03:11,  1.45s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:20<03:16,  1.50s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:21<03:14,  1.50s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:23<03:13,  1.50s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:24<03:08,  1.48s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:25<03:07,  1.48s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:27<03:05,  1.47s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:28<03:00,  1.44s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:30<03:03,  1.48s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:31<03:00,  1.47s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:33<03:02,  1.50s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:34<03:03,  1.52s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:36<02:57,  1.48s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:37<03:01,  1.52s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:39<03:01,  1.54s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:40<02:55,  1.50s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:42<02:53,  1.50s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:43<02:52,  1.50s/it]predicting train subjects:  60%|██████    | 171/285 [04:45<02:50,  1.49s/it]predicting train subjects:  60%|██████    | 172/285 [04:46<02:49,  1.50s/it]predicting train subjects:  61%|██████    | 173/285 [04:48<02:47,  1.49s/it]predicting train subjects:  61%|██████    | 174/285 [04:49<02:45,  1.49s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:51<02:48,  1.53s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:53<02:50,  1.57s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:54<02:44,  1.53s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:55<02:38,  1.48s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:57<02:37,  1.48s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:59<02:45,  1.57s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:00<02:46,  1.60s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:02<02:44,  1.60s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:03<02:37,  1.54s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:05<02:32,  1.51s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:06<02:27,  1.47s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:08<02:33,  1.55s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:10<02:40,  1.64s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:12<02:44,  1.69s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:13<02:33,  1.60s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:14<02:27,  1.56s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:16<02:31,  1.61s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:18<02:31,  1.62s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:19<02:21,  1.54s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:21<02:17,  1.51s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:22<02:11,  1.46s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:24<02:20,  1.58s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:26<02:24,  1.64s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:28<02:28,  1.71s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:29<02:18,  1.61s/it]predicting train subjects:  70%|███████   | 200/285 [05:30<02:12,  1.56s/it]predicting train subjects:  71%|███████   | 201/285 [05:32<02:17,  1.64s/it]predicting train subjects:  71%|███████   | 202/285 [05:34<02:18,  1.67s/it]predicting train subjects:  71%|███████   | 203/285 [05:36<02:16,  1.66s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:37<02:07,  1.57s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:38<02:03,  1.54s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:40<01:56,  1.48s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:42<02:04,  1.60s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:43<02:07,  1.66s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:45<02:10,  1.72s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:47<01:59,  1.60s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:48<01:56,  1.58s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:50<01:56,  1.60s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:51<01:55,  1.60s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:53<01:49,  1.54s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:54<01:52,  1.60s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:56<01:45,  1.53s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:58<01:48,  1.60s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:59<01:50,  1.64s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:01<01:50,  1.68s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:02<01:43,  1.59s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:04<01:37,  1.52s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:05<01:37,  1.55s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:07<01:31,  1.47s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:08<01:28,  1.45s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:09<01:24,  1.42s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:11<01:29,  1.52s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:13<01:32,  1.60s/it]predicting train subjects:  80%|████████  | 228/285 [06:15<01:34,  1.66s/it]predicting train subjects:  80%|████████  | 229/285 [06:16<01:31,  1.63s/it]predicting train subjects:  81%|████████  | 230/285 [06:18<01:24,  1.54s/it]predicting train subjects:  81%|████████  | 231/285 [06:19<01:21,  1.51s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:21<01:23,  1.57s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:22<01:18,  1.51s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:24<01:20,  1.57s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:25<01:15,  1.52s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:27<01:18,  1.60s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:29<01:19,  1.66s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:31<01:18,  1.68s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:32<01:16,  1.66s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:34<01:10,  1.56s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:35<01:06,  1.50s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:36<01:03,  1.47s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:38<01:00,  1.43s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:39<01:01,  1.51s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:41<00:58,  1.46s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:42<01:00,  1.55s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:44<01:00,  1.60s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:46<00:59,  1.60s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:47<00:54,  1.51s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:48<00:51,  1.47s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:50<00:49,  1.45s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:51<00:46,  1.42s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:53<00:49,  1.55s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:55<00:50,  1.62s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:56<00:48,  1.61s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:58<00:44,  1.55s/it]predicting train subjects:  90%|█████████ | 257/285 [06:59<00:41,  1.50s/it]predicting train subjects:  91%|█████████ | 258/285 [07:01<00:42,  1.59s/it]predicting train subjects:  91%|█████████ | 259/285 [07:03<00:42,  1.62s/it]predicting train subjects:  91%|█████████ | 260/285 [07:04<00:39,  1.58s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:06<00:37,  1.57s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:07<00:35,  1.54s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:09<00:33,  1.52s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:11<00:34,  1.64s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:12<00:33,  1.70s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:14<00:31,  1.64s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:16<00:29,  1.63s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:17<00:28,  1.70s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:19<00:27,  1.72s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:21<00:24,  1.62s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:22<00:22,  1.58s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:24<00:21,  1.64s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:25<00:19,  1.61s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:27<00:17,  1.58s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:29<00:16,  1.68s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:31<00:15,  1.75s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:32<00:13,  1.66s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:34<00:11,  1.62s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:35<00:09,  1.65s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:37<00:07,  1.58s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:38<00:06,  1.56s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:40<00:04,  1.51s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:42<00:03,  1.59s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:43<00:01,  1.66s/it]predicting train subjects: 100%|██████████| 285/285 [07:45<00:00,  1.74s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:02<10:18,  2.18s/it]Loading train:   1%|          | 2/285 [00:03<09:07,  1.93s/it]Loading train:   1%|          | 3/285 [00:05<08:35,  1.83s/it]Loading train:   1%|▏         | 4/285 [00:06<08:21,  1.78s/it]Loading train:   2%|▏         | 5/285 [00:08<08:28,  1.82s/it]Loading train:   2%|▏         | 6/285 [00:10<08:00,  1.72s/it]Loading train:   2%|▏         | 7/285 [00:11<08:02,  1.74s/it]Loading train:   3%|▎         | 8/285 [00:13<07:53,  1.71s/it]Loading train:   3%|▎         | 9/285 [00:15<08:02,  1.75s/it]Loading train:   4%|▎         | 10/285 [00:17<07:58,  1.74s/it]Loading train:   4%|▍         | 11/285 [00:18<07:03,  1.55s/it]Loading train:   4%|▍         | 12/285 [00:19<06:47,  1.49s/it]Loading train:   5%|▍         | 13/285 [00:20<06:17,  1.39s/it]Loading train:   5%|▍         | 14/285 [00:21<05:57,  1.32s/it]Loading train:   5%|▌         | 15/285 [00:23<05:47,  1.29s/it]Loading train:   6%|▌         | 16/285 [00:24<05:57,  1.33s/it]Loading train:   6%|▌         | 17/285 [00:25<05:44,  1.29s/it]Loading train:   6%|▋         | 18/285 [00:26<05:39,  1.27s/it]Loading train:   7%|▋         | 19/285 [00:28<05:31,  1.25s/it]Loading train:   7%|▋         | 20/285 [00:29<05:43,  1.30s/it]Loading train:   7%|▋         | 21/285 [00:30<05:50,  1.33s/it]Loading train:   8%|▊         | 22/285 [00:32<05:30,  1.26s/it]Loading train:   8%|▊         | 23/285 [00:33<05:58,  1.37s/it]Loading train:   8%|▊         | 24/285 [00:34<05:37,  1.29s/it]Loading train:   9%|▉         | 25/285 [00:36<05:27,  1.26s/it]Loading train:   9%|▉         | 26/285 [00:37<06:13,  1.44s/it]Loading train:   9%|▉         | 27/285 [00:38<05:41,  1.32s/it]Loading train:  10%|▉         | 28/285 [00:40<05:51,  1.37s/it]Loading train:  10%|█         | 29/285 [00:41<05:47,  1.36s/it]Loading train:  11%|█         | 30/285 [00:43<05:47,  1.36s/it]Loading train:  11%|█         | 31/285 [00:44<05:50,  1.38s/it]Loading train:  11%|█         | 32/285 [00:45<05:26,  1.29s/it]Loading train:  12%|█▏        | 33/285 [00:46<05:22,  1.28s/it]Loading train:  12%|█▏        | 34/285 [00:48<05:20,  1.28s/it]Loading train:  12%|█▏        | 35/285 [00:49<05:29,  1.32s/it]Loading train:  13%|█▎        | 36/285 [00:50<05:32,  1.34s/it]Loading train:  13%|█▎        | 37/285 [00:52<05:38,  1.37s/it]Loading train:  13%|█▎        | 38/285 [00:53<05:38,  1.37s/it]Loading train:  14%|█▎        | 39/285 [00:54<05:20,  1.30s/it]Loading train:  14%|█▍        | 40/285 [00:56<05:19,  1.31s/it]Loading train:  14%|█▍        | 41/285 [00:57<05:18,  1.30s/it]Loading train:  15%|█▍        | 42/285 [00:59<05:43,  1.42s/it]Loading train:  15%|█▌        | 43/285 [01:00<05:53,  1.46s/it]Loading train:  15%|█▌        | 44/285 [01:02<06:21,  1.58s/it]Loading train:  16%|█▌        | 45/285 [01:04<06:25,  1.61s/it]Loading train:  16%|█▌        | 46/285 [01:06<06:50,  1.72s/it]Loading train:  16%|█▋        | 47/285 [01:07<06:43,  1.70s/it]Loading train:  17%|█▋        | 48/285 [01:09<06:44,  1.71s/it]Loading train:  17%|█▋        | 49/285 [01:11<06:26,  1.64s/it]Loading train:  18%|█▊        | 50/285 [01:12<06:20,  1.62s/it]Loading train:  18%|█▊        | 51/285 [01:14<06:07,  1.57s/it]Loading train:  18%|█▊        | 52/285 [01:15<05:51,  1.51s/it]Loading train:  19%|█▊        | 53/285 [01:16<05:45,  1.49s/it]Loading train:  19%|█▉        | 54/285 [01:18<05:57,  1.55s/it]Loading train:  19%|█▉        | 55/285 [01:19<05:27,  1.42s/it]Loading train:  20%|█▉        | 56/285 [01:21<05:59,  1.57s/it]Loading train:  20%|██        | 57/285 [01:23<05:55,  1.56s/it]Loading train:  20%|██        | 58/285 [01:25<06:24,  1.69s/it]Loading train:  21%|██        | 59/285 [01:27<06:45,  1.80s/it]Loading train:  21%|██        | 60/285 [01:29<07:14,  1.93s/it]Loading train:  21%|██▏       | 61/285 [01:30<06:43,  1.80s/it]Loading train:  22%|██▏       | 62/285 [01:32<06:25,  1.73s/it]Loading train:  22%|██▏       | 63/285 [01:34<06:19,  1.71s/it]Loading train:  22%|██▏       | 64/285 [01:35<06:06,  1.66s/it]Loading train:  23%|██▎       | 65/285 [01:37<06:09,  1.68s/it]Loading train:  23%|██▎       | 66/285 [01:39<06:49,  1.87s/it]Loading train:  24%|██▎       | 67/285 [01:42<07:29,  2.06s/it]Loading train:  24%|██▍       | 68/285 [01:43<06:31,  1.80s/it]Loading train:  24%|██▍       | 69/285 [01:45<06:12,  1.73s/it]Loading train:  25%|██▍       | 70/285 [01:47<06:34,  1.84s/it]Loading train:  25%|██▍       | 71/285 [01:48<06:18,  1.77s/it]Loading train:  25%|██▌       | 72/285 [01:50<05:51,  1.65s/it]Loading train:  26%|██▌       | 73/285 [01:52<06:15,  1.77s/it]Loading train:  26%|██▌       | 74/285 [01:53<06:09,  1.75s/it]Loading train:  26%|██▋       | 75/285 [01:55<06:08,  1.75s/it]Loading train:  27%|██▋       | 76/285 [01:57<06:14,  1.79s/it]Loading train:  27%|██▋       | 77/285 [01:59<06:08,  1.77s/it]Loading train:  27%|██▋       | 78/285 [02:00<05:35,  1.62s/it]Loading train:  28%|██▊       | 79/285 [02:02<05:28,  1.60s/it]Loading train:  28%|██▊       | 80/285 [02:04<05:55,  1.73s/it]Loading train:  28%|██▊       | 81/285 [02:05<05:44,  1.69s/it]Loading train:  29%|██▉       | 82/285 [02:07<05:20,  1.58s/it]Loading train:  29%|██▉       | 83/285 [02:08<05:13,  1.55s/it]Loading train:  29%|██▉       | 84/285 [02:09<05:05,  1.52s/it]Loading train:  30%|██▉       | 85/285 [02:11<05:20,  1.60s/it]Loading train:  30%|███       | 86/285 [02:13<05:31,  1.67s/it]Loading train:  31%|███       | 87/285 [02:15<05:48,  1.76s/it]Loading train:  31%|███       | 88/285 [02:16<05:15,  1.60s/it]Loading train:  31%|███       | 89/285 [02:18<05:42,  1.75s/it]Loading train:  32%|███▏      | 90/285 [02:20<05:31,  1.70s/it]Loading train:  32%|███▏      | 91/285 [02:21<05:14,  1.62s/it]Loading train:  32%|███▏      | 92/285 [02:24<05:43,  1.78s/it]Loading train:  33%|███▎      | 93/285 [02:25<05:41,  1.78s/it]Loading train:  33%|███▎      | 94/285 [02:27<05:21,  1.68s/it]Loading train:  33%|███▎      | 95/285 [02:28<05:18,  1.68s/it]Loading train:  34%|███▎      | 96/285 [02:31<05:43,  1.81s/it]Loading train:  34%|███▍      | 97/285 [02:32<05:38,  1.80s/it]Loading train:  34%|███▍      | 98/285 [02:34<05:29,  1.76s/it]Loading train:  35%|███▍      | 99/285 [02:35<04:59,  1.61s/it]Loading train:  35%|███▌      | 100/285 [02:37<04:55,  1.60s/it]Loading train:  35%|███▌      | 101/285 [02:38<04:28,  1.46s/it]Loading train:  36%|███▌      | 102/285 [02:40<05:16,  1.73s/it]Loading train:  36%|███▌      | 103/285 [02:42<05:09,  1.70s/it]Loading train:  36%|███▋      | 104/285 [02:44<04:58,  1.65s/it]Loading train:  37%|███▋      | 105/285 [02:45<04:53,  1.63s/it]Loading train:  37%|███▋      | 106/285 [02:47<05:07,  1.72s/it]Loading train:  38%|███▊      | 107/285 [02:49<05:38,  1.90s/it]Loading train:  38%|███▊      | 108/285 [02:51<05:09,  1.75s/it]Loading train:  38%|███▊      | 109/285 [02:52<04:55,  1.68s/it]Loading train:  39%|███▊      | 110/285 [02:54<04:38,  1.59s/it]Loading train:  39%|███▉      | 111/285 [02:55<04:48,  1.66s/it]Loading train:  39%|███▉      | 112/285 [02:57<04:31,  1.57s/it]Loading train:  40%|███▉      | 113/285 [02:58<04:22,  1.53s/it]Loading train:  40%|████      | 114/285 [02:59<04:06,  1.44s/it]Loading train:  40%|████      | 115/285 [03:01<03:58,  1.40s/it]Loading train:  41%|████      | 116/285 [03:02<03:48,  1.35s/it]Loading train:  41%|████      | 117/285 [03:04<04:01,  1.44s/it]Loading train:  41%|████▏     | 118/285 [03:05<03:42,  1.33s/it]Loading train:  42%|████▏     | 119/285 [03:07<04:18,  1.55s/it]Loading train:  42%|████▏     | 120/285 [03:08<04:17,  1.56s/it]Loading train:  42%|████▏     | 121/285 [03:10<04:11,  1.53s/it]Loading train:  43%|████▎     | 122/285 [03:12<04:23,  1.61s/it]Loading train:  43%|████▎     | 123/285 [03:14<04:32,  1.68s/it]Loading train:  44%|████▎     | 124/285 [03:15<04:21,  1.63s/it]Loading train:  44%|████▍     | 125/285 [03:16<04:05,  1.54s/it]Loading train:  44%|████▍     | 126/285 [03:18<03:59,  1.51s/it]Loading train:  45%|████▍     | 127/285 [03:19<03:55,  1.49s/it]Loading train:  45%|████▍     | 128/285 [03:21<03:59,  1.52s/it]Loading train:  45%|████▌     | 129/285 [03:22<03:41,  1.42s/it]Loading train:  46%|████▌     | 130/285 [03:23<03:32,  1.37s/it]Loading train:  46%|████▌     | 131/285 [03:24<03:19,  1.29s/it]Loading train:  46%|████▋     | 132/285 [03:26<03:25,  1.34s/it]Loading train:  47%|████▋     | 133/285 [03:27<03:28,  1.37s/it]Loading train:  47%|████▋     | 134/285 [03:29<03:28,  1.38s/it]Loading train:  47%|████▋     | 135/285 [03:30<03:15,  1.30s/it]Loading train:  48%|████▊     | 136/285 [03:32<03:40,  1.48s/it]Loading train:  48%|████▊     | 137/285 [03:33<03:37,  1.47s/it]Loading train:  48%|████▊     | 138/285 [03:35<03:47,  1.55s/it]Loading train:  49%|████▉     | 139/285 [03:36<03:38,  1.50s/it]Loading train:  49%|████▉     | 140/285 [03:38<03:55,  1.63s/it]Loading train:  49%|████▉     | 141/285 [03:40<04:03,  1.69s/it]Loading train:  50%|████▉     | 142/285 [03:42<03:57,  1.66s/it]Loading train:  50%|█████     | 143/285 [03:43<03:32,  1.49s/it]Loading train:  51%|█████     | 144/285 [03:44<03:21,  1.43s/it]Loading train:  51%|█████     | 145/285 [03:45<03:10,  1.36s/it]Loading train:  51%|█████     | 146/285 [03:47<03:25,  1.48s/it]Loading train:  52%|█████▏    | 147/285 [03:48<03:07,  1.36s/it]Loading train:  52%|█████▏    | 148/285 [03:49<03:08,  1.37s/it]Loading train:  52%|█████▏    | 149/285 [03:51<02:58,  1.31s/it]Loading train:  53%|█████▎    | 150/285 [03:52<03:12,  1.43s/it]Loading train:  53%|█████▎    | 151/285 [03:54<03:27,  1.55s/it]Loading train:  53%|█████▎    | 152/285 [03:56<03:39,  1.65s/it]Loading train:  54%|█████▎    | 153/285 [03:58<03:33,  1.61s/it]Loading train:  54%|█████▍    | 154/285 [03:59<03:14,  1.49s/it]Loading train:  54%|█████▍    | 155/285 [04:00<03:22,  1.55s/it]Loading train:  55%|█████▍    | 156/285 [04:02<03:31,  1.64s/it]Loading train:  55%|█████▌    | 157/285 [04:04<03:14,  1.52s/it]Loading train:  55%|█████▌    | 158/285 [04:05<02:59,  1.42s/it]Loading train:  56%|█████▌    | 159/285 [04:06<02:49,  1.35s/it]Loading train:  56%|█████▌    | 160/285 [04:07<02:45,  1.33s/it]Loading train:  56%|█████▋    | 161/285 [04:08<02:44,  1.32s/it]Loading train:  57%|█████▋    | 162/285 [04:10<02:44,  1.34s/it]Loading train:  57%|█████▋    | 163/285 [04:11<02:34,  1.27s/it]Loading train:  58%|█████▊    | 164/285 [04:12<02:34,  1.28s/it]Loading train:  58%|█████▊    | 165/285 [04:13<02:27,  1.23s/it]Loading train:  58%|█████▊    | 166/285 [04:15<02:22,  1.20s/it]Loading train:  59%|█████▊    | 167/285 [04:16<02:30,  1.28s/it]Loading train:  59%|█████▉    | 168/285 [04:18<02:50,  1.46s/it]Loading train:  59%|█████▉    | 169/285 [04:19<02:37,  1.36s/it]Loading train:  60%|█████▉    | 170/285 [04:20<02:24,  1.26s/it]Loading train:  60%|██████    | 171/285 [04:21<02:19,  1.22s/it]Loading train:  60%|██████    | 172/285 [04:22<02:14,  1.19s/it]Loading train:  61%|██████    | 173/285 [04:24<02:34,  1.38s/it]Loading train:  61%|██████    | 174/285 [04:25<02:28,  1.34s/it]Loading train:  61%|██████▏   | 175/285 [04:27<02:22,  1.30s/it]Loading train:  62%|██████▏   | 176/285 [04:28<02:20,  1.29s/it]Loading train:  62%|██████▏   | 177/285 [04:29<02:23,  1.33s/it]Loading train:  62%|██████▏   | 178/285 [04:30<02:17,  1.29s/it]Loading train:  63%|██████▎   | 179/285 [04:32<02:15,  1.28s/it]Loading train:  63%|██████▎   | 180/285 [04:34<02:50,  1.62s/it]Loading train:  64%|██████▎   | 181/285 [04:36<02:44,  1.58s/it]Loading train:  64%|██████▍   | 182/285 [04:37<02:29,  1.45s/it]Loading train:  64%|██████▍   | 183/285 [04:38<02:21,  1.38s/it]Loading train:  65%|██████▍   | 184/285 [04:39<02:21,  1.40s/it]Loading train:  65%|██████▍   | 185/285 [04:41<02:31,  1.51s/it]Loading train:  65%|██████▌   | 186/285 [04:43<02:32,  1.54s/it]Loading train:  66%|██████▌   | 187/285 [04:44<02:24,  1.48s/it]Loading train:  66%|██████▌   | 188/285 [04:45<02:19,  1.44s/it]Loading train:  66%|██████▋   | 189/285 [04:46<02:05,  1.30s/it]Loading train:  67%|██████▋   | 190/285 [04:48<02:12,  1.39s/it]Loading train:  67%|██████▋   | 191/285 [04:49<02:07,  1.35s/it]Loading train:  67%|██████▋   | 192/285 [04:51<02:16,  1.46s/it]Loading train:  68%|██████▊   | 193/285 [04:52<02:02,  1.33s/it]Loading train:  68%|██████▊   | 194/285 [04:53<01:59,  1.31s/it]Loading train:  68%|██████▊   | 195/285 [04:54<01:52,  1.25s/it]Loading train:  69%|██████▉   | 196/285 [04:56<01:54,  1.29s/it]Loading train:  69%|██████▉   | 197/285 [04:58<02:07,  1.45s/it]Loading train:  69%|██████▉   | 198/285 [04:59<02:16,  1.57s/it]Loading train:  70%|██████▉   | 199/285 [05:01<02:10,  1.52s/it]Loading train:  70%|███████   | 200/285 [05:02<01:59,  1.40s/it]Loading train:  71%|███████   | 201/285 [05:03<01:58,  1.41s/it]Loading train:  71%|███████   | 202/285 [05:05<01:57,  1.42s/it]Loading train:  71%|███████   | 203/285 [05:06<01:52,  1.37s/it]Loading train:  72%|███████▏  | 204/285 [05:07<01:45,  1.30s/it]Loading train:  72%|███████▏  | 205/285 [05:08<01:42,  1.29s/it]Loading train:  72%|███████▏  | 206/285 [05:10<01:42,  1.29s/it]Loading train:  73%|███████▎  | 207/285 [05:11<01:41,  1.30s/it]Loading train:  73%|███████▎  | 208/285 [05:13<01:49,  1.42s/it]Loading train:  73%|███████▎  | 209/285 [05:15<01:59,  1.57s/it]Loading train:  74%|███████▎  | 210/285 [05:16<01:58,  1.58s/it]Loading train:  74%|███████▍  | 211/285 [05:18<01:58,  1.61s/it]Loading train:  74%|███████▍  | 212/285 [05:19<01:49,  1.51s/it]Loading train:  75%|███████▍  | 213/285 [05:20<01:38,  1.37s/it]Loading train:  75%|███████▌  | 214/285 [05:21<01:32,  1.31s/it]Loading train:  75%|███████▌  | 215/285 [05:23<01:30,  1.30s/it]Loading train:  76%|███████▌  | 216/285 [05:24<01:31,  1.32s/it]Loading train:  76%|███████▌  | 217/285 [05:25<01:29,  1.31s/it]Loading train:  76%|███████▋  | 218/285 [05:27<01:32,  1.38s/it]Loading train:  77%|███████▋  | 219/285 [05:29<01:36,  1.47s/it]Loading train:  77%|███████▋  | 220/285 [05:30<01:32,  1.42s/it]Loading train:  78%|███████▊  | 221/285 [05:31<01:24,  1.32s/it]Loading train:  78%|███████▊  | 222/285 [05:33<01:31,  1.45s/it]Loading train:  78%|███████▊  | 223/285 [05:34<01:22,  1.34s/it]Loading train:  79%|███████▊  | 224/285 [05:35<01:15,  1.24s/it]Loading train:  79%|███████▉  | 225/285 [05:36<01:18,  1.30s/it]Loading train:  79%|███████▉  | 226/285 [05:38<01:20,  1.37s/it]Loading train:  80%|███████▉  | 227/285 [05:39<01:21,  1.41s/it]Loading train:  80%|████████  | 228/285 [05:41<01:31,  1.60s/it]Loading train:  80%|████████  | 229/285 [05:43<01:27,  1.55s/it]Loading train:  81%|████████  | 230/285 [05:44<01:18,  1.43s/it]Loading train:  81%|████████  | 231/285 [05:45<01:14,  1.37s/it]Loading train:  81%|████████▏ | 232/285 [05:46<01:09,  1.30s/it]Loading train:  82%|████████▏ | 233/285 [05:48<01:07,  1.30s/it]Loading train:  82%|████████▏ | 234/285 [05:50<01:15,  1.48s/it]Loading train:  82%|████████▏ | 235/285 [05:51<01:14,  1.49s/it]Loading train:  83%|████████▎ | 236/285 [05:52<01:11,  1.46s/it]Loading train:  83%|████████▎ | 237/285 [05:54<01:09,  1.44s/it]Loading train:  84%|████████▎ | 238/285 [05:56<01:10,  1.51s/it]Loading train:  84%|████████▍ | 239/285 [05:57<01:05,  1.42s/it]Loading train:  84%|████████▍ | 240/285 [05:58<01:00,  1.35s/it]Loading train:  85%|████████▍ | 241/285 [06:00<01:03,  1.45s/it]Loading train:  85%|████████▍ | 242/285 [06:01<00:58,  1.36s/it]Loading train:  85%|████████▌ | 243/285 [06:02<00:53,  1.27s/it]Loading train:  86%|████████▌ | 244/285 [06:03<00:52,  1.29s/it]Loading train:  86%|████████▌ | 245/285 [06:04<00:48,  1.21s/it]Loading train:  86%|████████▋ | 246/285 [06:05<00:48,  1.24s/it]Loading train:  87%|████████▋ | 247/285 [06:07<00:51,  1.35s/it]Loading train:  87%|████████▋ | 248/285 [06:09<00:53,  1.44s/it]Loading train:  87%|████████▋ | 249/285 [06:10<00:51,  1.43s/it]Loading train:  88%|████████▊ | 250/285 [06:11<00:49,  1.40s/it]Loading train:  88%|████████▊ | 251/285 [06:13<00:47,  1.39s/it]Loading train:  88%|████████▊ | 252/285 [06:14<00:45,  1.39s/it]Loading train:  89%|████████▉ | 253/285 [06:16<00:45,  1.43s/it]Loading train:  89%|████████▉ | 254/285 [06:17<00:45,  1.47s/it]Loading train:  89%|████████▉ | 255/285 [06:19<00:42,  1.42s/it]Loading train:  90%|████████▉ | 256/285 [06:20<00:40,  1.41s/it]Loading train:  90%|█████████ | 257/285 [06:21<00:39,  1.43s/it]Loading train:  91%|█████████ | 258/285 [06:23<00:37,  1.38s/it]Loading train:  91%|█████████ | 259/285 [06:24<00:34,  1.33s/it]Loading train:  91%|█████████ | 260/285 [06:25<00:30,  1.23s/it]Loading train:  92%|█████████▏| 261/285 [06:26<00:28,  1.18s/it]Loading train:  92%|█████████▏| 262/285 [06:27<00:27,  1.18s/it]Loading train:  92%|█████████▏| 263/285 [06:28<00:25,  1.16s/it]Loading train:  93%|█████████▎| 264/285 [06:30<00:26,  1.27s/it]Loading train:  93%|█████████▎| 265/285 [06:31<00:26,  1.33s/it]Loading train:  93%|█████████▎| 266/285 [06:33<00:24,  1.31s/it]Loading train:  94%|█████████▎| 267/285 [06:34<00:22,  1.23s/it]Loading train:  94%|█████████▍| 268/285 [06:35<00:21,  1.24s/it]Loading train:  94%|█████████▍| 269/285 [06:36<00:21,  1.33s/it]Loading train:  95%|█████████▍| 270/285 [06:38<00:19,  1.30s/it]Loading train:  95%|█████████▌| 271/285 [06:39<00:17,  1.22s/it]Loading train:  95%|█████████▌| 272/285 [06:41<00:18,  1.41s/it]Loading train:  96%|█████████▌| 273/285 [06:42<00:16,  1.38s/it]Loading train:  96%|█████████▌| 274/285 [06:43<00:13,  1.25s/it]Loading train:  96%|█████████▋| 275/285 [06:44<00:12,  1.29s/it]Loading train:  97%|█████████▋| 276/285 [06:46<00:12,  1.36s/it]Loading train:  97%|█████████▋| 277/285 [06:48<00:12,  1.51s/it]Loading train:  98%|█████████▊| 278/285 [06:49<00:10,  1.56s/it]Loading train:  98%|█████████▊| 279/285 [06:51<00:09,  1.53s/it]Loading train:  98%|█████████▊| 280/285 [06:52<00:07,  1.43s/it]Loading train:  99%|█████████▊| 281/285 [06:53<00:05,  1.36s/it]Loading train:  99%|█████████▉| 282/285 [06:54<00:03,  1.26s/it]Loading train:  99%|█████████▉| 283/285 [06:55<00:02,  1.29s/it]Loading train: 100%|█████████▉| 284/285 [06:57<00:01,  1.51s/it]Loading train: 100%|██████████| 285/285 [06:59<00:00,  1.55s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|          | 3/285 [00:00<00:13, 20.67it/s]concatenating: train:   2%|▏         | 6/285 [00:00<00:12, 21.99it/s]concatenating: train:   4%|▎         | 10/285 [00:00<00:11, 24.67it/s]concatenating: train:   5%|▍         | 13/285 [00:00<00:10, 25.53it/s]concatenating: train:   6%|▌         | 16/285 [00:00<00:10, 25.63it/s]concatenating: train:   7%|▋         | 19/285 [00:00<00:10, 26.49it/s]concatenating: train:   9%|▉         | 25/285 [00:00<00:08, 30.84it/s]concatenating: train:  11%|█         | 30/285 [00:00<00:07, 34.02it/s]concatenating: train:  12%|█▏        | 35/285 [00:01<00:06, 36.93it/s]concatenating: train:  14%|█▎        | 39/285 [00:01<00:07, 34.69it/s]concatenating: train:  15%|█▌        | 44/285 [00:01<00:06, 35.89it/s]concatenating: train:  18%|█▊        | 50/285 [00:01<00:05, 39.53it/s]concatenating: train:  20%|█▉        | 56/285 [00:01<00:05, 43.27it/s]concatenating: train:  22%|██▏       | 63/285 [00:01<00:04, 46.90it/s]concatenating: train:  25%|██▍       | 70/285 [00:01<00:04, 51.14it/s]concatenating: train:  29%|██▉       | 82/285 [00:01<00:03, 61.36it/s]concatenating: train:  32%|███▏      | 90/285 [00:01<00:03, 63.52it/s]concatenating: train:  34%|███▍      | 98/285 [00:02<00:02, 63.21it/s]concatenating: train:  37%|███▋      | 105/285 [00:02<00:03, 56.25it/s]concatenating: train:  40%|████      | 115/285 [00:02<00:02, 62.37it/s]concatenating: train:  44%|████▎     | 124/285 [00:02<00:02, 68.68it/s]concatenating: train:  46%|████▋     | 132/285 [00:02<00:02, 63.48it/s]concatenating: train:  49%|████▉     | 139/285 [00:02<00:02, 63.95it/s]concatenating: train:  53%|█████▎    | 150/285 [00:02<00:01, 73.08it/s]concatenating: train:  56%|█████▌    | 159/285 [00:02<00:01, 72.30it/s]concatenating: train:  59%|█████▊    | 167/285 [00:03<00:01, 69.77it/s]concatenating: train:  64%|██████▍   | 183/285 [00:03<00:01, 83.92it/s]concatenating: train:  68%|██████▊   | 193/285 [00:03<00:01, 57.71it/s]concatenating: train:  71%|███████   | 201/285 [00:03<00:01, 58.05it/s]concatenating: train:  73%|███████▎  | 209/285 [00:03<00:01, 55.32it/s]concatenating: train:  76%|███████▌  | 216/285 [00:03<00:01, 49.98it/s]concatenating: train:  78%|███████▊  | 223/285 [00:04<00:01, 53.18it/s]concatenating: train:  82%|████████▏ | 234/285 [00:04<00:00, 62.46it/s]concatenating: train:  86%|████████▋ | 246/285 [00:04<00:00, 71.90it/s]concatenating: train:  91%|█████████ | 259/285 [00:04<00:00, 82.41it/s]concatenating: train:  95%|█████████▌| 272/285 [00:04<00:00, 91.80it/s]concatenating: train:  99%|█████████▉| 283/285 [00:04<00:00, 88.31it/s]concatenating: train: 100%|██████████| 285/285 [00:04<00:00, 61.14it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.81s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.73s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.66s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 38.86it/s]2019-07-09 02:08:36.517770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-09 02:08:36.517880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-09 02:08:36.517898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-09 02:08:36.517907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-09 02:08:36.518327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12743 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:10,  4.08it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:08,  4.90it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:08,  4.82it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.27it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.70it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.56it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.76it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.27it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  7.21it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:02<00:03,  6.20it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:04,  5.38it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  6.65it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  7.14it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:03<00:02,  5.45it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:03<00:02,  6.18it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:02,  5.43it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:04<00:01,  6.66it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:01,  6.91it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:04<00:00,  6.07it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:04<00:00,  6.90it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  5.78it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  8.89it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 30)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 31)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 30)   8400        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 30)   8130        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 30)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 40, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 60)   16260       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 60)   32460       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 90)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 90)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 120)  97320       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 120)  129720      activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 120)  480         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 120)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 210)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 210)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 60)   50460       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 60)   81060       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 60)   32460       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 60)   240         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 60)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 210)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 40, 210)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 30)   25230       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 60)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 30)   16230       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 30)   8130        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 30)   120         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 30)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 90)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 80, 90)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 13)   1183        dropout_6[0][0]                  
==================================================================================================
Total params: 509,863
Trainable params: 117,583
Non-trainable params: 392,280
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 28s - loss: 12603.7961 - acc: 0.6227 - mDice: 0.1410 - val_loss: 8534.8191 - val_acc: 0.9037 - val_mDice: 0.1882

Epoch 00001: val_mDice improved from -inf to 0.18815, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 19s - loss: 4387.6819 - acc: 0.8898 - mDice: 0.4158 - val_loss: 5866.2181 - val_acc: 0.9139 - val_mDice: 0.3126

Epoch 00002: val_mDice improved from 0.18815 to 0.31256, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 19s - loss: 3331.2723 - acc: 0.9048 - mDice: 0.5096 - val_loss: 3917.9932 - val_acc: 0.9230 - val_mDice: 0.4327

Epoch 00003: val_mDice improved from 0.31256 to 0.43268, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 19s - loss: 2860.1661 - acc: 0.9149 - mDice: 0.5601 - val_loss: 3811.5287 - val_acc: 0.9260 - val_mDice: 0.4445

Epoch 00004: val_mDice improved from 0.43268 to 0.44453, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 20s - loss: 2564.3900 - acc: 0.9217 - mDice: 0.5944 - val_loss: 3096.3959 - val_acc: 0.9303 - val_mDice: 0.5129

Epoch 00005: val_mDice improved from 0.44453 to 0.51290, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 20s - loss: 2366.7531 - acc: 0.9263 - mDice: 0.6187 - val_loss: 3360.0659 - val_acc: 0.9159 - val_mDice: 0.4908

Epoch 00006: val_mDice did not improve from 0.51290
Epoch 7/300
 - 20s - loss: 2248.6629 - acc: 0.9288 - mDice: 0.6335 - val_loss: 3090.0682 - val_acc: 0.9168 - val_mDice: 0.5149

Epoch 00007: val_mDice improved from 0.51290 to 0.51487, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 20s - loss: 2129.3257 - acc: 0.9314 - mDice: 0.6489 - val_loss: 2816.2380 - val_acc: 0.9340 - val_mDice: 0.5413

Epoch 00008: val_mDice improved from 0.51487 to 0.54127, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 19s - loss: 2054.0677 - acc: 0.9330 - mDice: 0.6586 - val_loss: 2837.4186 - val_acc: 0.9357 - val_mDice: 0.5380

Epoch 00009: val_mDice did not improve from 0.54127
Epoch 10/300
 - 19s - loss: 1970.1433 - acc: 0.9347 - mDice: 0.6696 - val_loss: 3038.6809 - val_acc: 0.9298 - val_mDice: 0.5174

Epoch 00010: val_mDice did not improve from 0.54127
Epoch 11/300
 - 20s - loss: 1906.9283 - acc: 0.9362 - mDice: 0.6784 - val_loss: 2604.0723 - val_acc: 0.9402 - val_mDice: 0.5657

Epoch 00011: val_mDice improved from 0.54127 to 0.56569, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 20s - loss: 1863.4696 - acc: 0.9370 - mDice: 0.6842 - val_loss: 2878.4458 - val_acc: 0.9334 - val_mDice: 0.5358

Epoch 00012: val_mDice did not improve from 0.56569
Epoch 13/300
 - 20s - loss: 1818.5417 - acc: 0.9381 - mDice: 0.6904 - val_loss: 2589.1897 - val_acc: 0.9388 - val_mDice: 0.5677

Epoch 00013: val_mDice improved from 0.56569 to 0.56774, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 20s - loss: 1764.6334 - acc: 0.9393 - mDice: 0.6979 - val_loss: 2714.3286 - val_acc: 0.9377 - val_mDice: 0.5539

Epoch 00014: val_mDice did not improve from 0.56774
Epoch 15/300
 - 19s - loss: 1738.1896 - acc: 0.9397 - mDice: 0.7016 - val_loss: 3162.4466 - val_acc: 0.9392 - val_mDice: 0.5059

Epoch 00015: val_mDice did not improve from 0.56774
Epoch 16/300
 - 19s - loss: 1703.4783 - acc: 0.9402 - mDice: 0.7065 - val_loss: 2703.2689 - val_acc: 0.9354 - val_mDice: 0.5544

Epoch 00016: val_mDice did not improve from 0.56774
Epoch 17/300
 - 20s - loss: 1667.1410 - acc: 0.9412 - mDice: 0.7117 - val_loss: 2793.4673 - val_acc: 0.9376 - val_mDice: 0.5439

Epoch 00017: val_mDice did not improve from 0.56774
Epoch 18/300
 - 20s - loss: 1656.6944 - acc: 0.9413 - mDice: 0.7131 - val_loss: 2712.4217 - val_acc: 0.9432 - val_mDice: 0.5525

Epoch 00018: val_mDice did not improve from 0.56774
Epoch 19/300
 - 19s - loss: 1624.0122 - acc: 0.9420 - mDice: 0.7179 - val_loss: 2661.3671 - val_acc: 0.9408 - val_mDice: 0.5575

Epoch 00019: val_mDice did not improve from 0.56774
Epoch 20/300
 - 19s - loss: 1595.7591 - acc: 0.9427 - mDice: 0.7219 - val_loss: 2728.6556 - val_acc: 0.9424 - val_mDice: 0.5499

Epoch 00020: val_mDice did not improve from 0.56774
Epoch 21/300
 - 20s - loss: 1576.1471 - acc: 0.9430 - mDice: 0.7248 - val_loss: 2666.0663 - val_acc: 0.9453 - val_mDice: 0.5572

Epoch 00021: val_mDice did not improve from 0.56774
Epoch 22/300
 - 19s - loss: 1559.7916 - acc: 0.9432 - mDice: 0.7272 - val_loss: 2887.3644 - val_acc: 0.9420 - val_mDice: 0.5332

Epoch 00022: val_mDice did not improve from 0.56774
Epoch 23/300
 - 20s - loss: 1537.2688 - acc: 0.9438 - mDice: 0.7305 - val_loss: 2833.5314 - val_acc: 0.9352 - val_mDice: 0.5402

Epoch 00023: val_mDice did not improve from 0.56774
Epoch 24/300
 - 20s - loss: 1528.7689 - acc: 0.9441 - mDice: 0.7318 - val_loss: 2721.0010 - val_acc: 0.9408 - val_mDice: 0.5514

Epoch 00024: val_mDice did not improve from 0.56774
Epoch 25/300
 - 20s - loss: 1504.2613 - acc: 0.9444 - mDice: 0.7354 - val_loss: 2702.9536 - val_acc: 0.9387 - val_mDice: 0.5544

Epoch 00025: val_mDice did not improve from 0.56774
Epoch 26/300
 - 20s - loss: 1486.4352 - acc: 0.9448 - mDice: 0.7380 - val_loss: 2607.6982 - val_acc: 0.9396 - val_mDice: 0.5641

Epoch 00026: val_mDice did not improve from 0.56774
Epoch 27/300
 - 20s - loss: 1471.4643 - acc: 0.9452 - mDice: 0.7403 - val_loss: 2693.0700 - val_acc: 0.9402 - val_mDice: 0.5532

Epoch 00027: val_mDice did not improve from 0.56774
Epoch 28/300
 - 20s - loss: 1457.6509 - acc: 0.9454 - mDice: 0.7423 - val_loss: 2743.6746 - val_acc: 0.9436 - val_mDice: 0.5468

Epoch 00028: val_mDice did not improve from 0.56774
Epoch 29/300
 - 20s - loss: 1454.7609 - acc: 0.9454 - mDice: 0.7428 - val_loss: 2745.2241 - val_acc: 0.9413 - val_mDice: 0.5463

Epoch 00029: val_mDice did not improve from 0.56774
Epoch 30/300
 - 20s - loss: 1435.6108 - acc: 0.9457 - mDice: 0.7457 - val_loss: 2652.2308 - val_acc: 0.9424 - val_mDice: 0.5561

Epoch 00030: val_mDice did not improve from 0.56774
Epoch 31/300
 - 20s - loss: 1412.0847 - acc: 0.9463 - mDice: 0.7492 - val_loss: 2673.1255 - val_acc: 0.9424 - val_mDice: 0.5543

Epoch 00031: val_mDice did not improve from 0.56774
Epoch 32/300
 - 20s - loss: 1408.5702 - acc: 0.9464 - mDice: 0.7497 - val_loss: 2905.1742 - val_acc: 0.9441 - val_mDice: 0.5320

Epoch 00032: val_mDice did not improve from 0.56774
Epoch 33/300
 - 20s - loss: 1397.9803 - acc: 0.9466 - mDice: 0.7513 - val_loss: 2772.1075 - val_acc: 0.9450 - val_mDice: 0.5424

Epoch 00033: val_mDice did not improve from 0.56774
Epoch 34/300
 - 20s - loss: 1379.1920 - acc: 0.9468 - mDice: 0.7542 - val_loss: 2810.5483 - val_acc: 0.9382 - val_mDice: 0.5402

Epoch 00034: val_mDice did not improve from 0.56774
Epoch 35/300
 - 20s - loss: 1375.2625 - acc: 0.9470 - mDice: 0.7548 - val_loss: 2640.4021 - val_acc: 0.9445 - val_mDice: 0.5583

Epoch 00035: val_mDice did not improve from 0.56774
Epoch 36/300
 - 19s - loss: 1358.3276 - acc: 0.9473 - mDice: 0.7573 - val_loss: 2665.6853 - val_acc: 0.9441 - val_mDice: 0.5539

Epoch 00036: val_mDice did not improve from 0.56774
Epoch 37/300
 - 20s - loss: 1352.0114 - acc: 0.9476 - mDice: 0.7583 - val_loss: 2654.5536 - val_acc: 0.9427 - val_mDice: 0.5550

Epoch 00037: val_mDice did not improve from 0.56774
Epoch 38/300
 - 20s - loss: 1346.9070 - acc: 0.9475 - mDice: 0.7591 - val_loss: 2738.1568 - val_acc: 0.9435 - val_mDice: 0.5463

Epoch 00038: val_mDice did not improve from 0.56774
Epoch 39/300
 - 20s - loss: 1339.7339 - acc: 0.9477 - mDice: 0.7602 - val_loss: 2684.2364 - val_acc: 0.9455 - val_mDice: 0.5515

Epoch 00039: val_mDice did not improve from 0.56774
Epoch 40/300
 - 20s - loss: 1330.0520 - acc: 0.9479 - mDice: 0.7618 - val_loss: 2838.0947 - val_acc: 0.9437 - val_mDice: 0.5376

Epoch 00040: val_mDice did not improve from 0.56774
Epoch 41/300
 - 20s - loss: 1312.7435 - acc: 0.9482 - mDice: 0.7644 - val_loss: 2640.5191 - val_acc: 0.9469 - val_mDice: 0.5570

Epoch 00041: val_mDice did not improve from 0.56774
Epoch 42/300
 - 20s - loss: 1305.8720 - acc: 0.9484 - mDice: 0.7654 - val_loss: 2670.7297 - val_acc: 0.9448 - val_mDice: 0.5543

Epoch 00042: val_mDice did not improve from 0.56774
Epoch 43/300
 - 19s - loss: 1301.0258 - acc: 0.9484 - mDice: 0.7662 - val_loss: 2809.3166 - val_acc: 0.9409 - val_mDice: 0.5389

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.18s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.98s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.79s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:53,  1.88s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:09,  1.73s/it]predicting train subjects:   1%|          | 3/285 [00:04<08:07,  1.73s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:48,  1.67s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:03,  1.73s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:43,  1.66s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:59,  1.72s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:50,  1.70s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:09,  1.77s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:17,  1.81s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<07:48,  1.71s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:07,  1.78s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<07:47,  1.72s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<07:56,  1.76s/it]predicting train subjects:   5%|▌         | 15/285 [00:26<08:16,  1.84s/it]predicting train subjects:   6%|▌         | 16/285 [00:28<08:26,  1.88s/it]predicting train subjects:   6%|▌         | 17/285 [00:29<07:56,  1.78s/it]predicting train subjects:   6%|▋         | 18/285 [00:31<07:55,  1.78s/it]predicting train subjects:   7%|▋         | 19/285 [00:32<07:36,  1.72s/it]predicting train subjects:   7%|▋         | 20/285 [00:34<07:39,  1.73s/it]predicting train subjects:   7%|▋         | 21/285 [00:36<07:55,  1.80s/it]predicting train subjects:   8%|▊         | 22/285 [00:38<07:35,  1.73s/it]predicting train subjects:   8%|▊         | 23/285 [00:40<07:53,  1.81s/it]predicting train subjects:   8%|▊         | 24/285 [00:41<07:38,  1.76s/it]predicting train subjects:   9%|▉         | 25/285 [00:43<07:50,  1.81s/it]predicting train subjects:   9%|▉         | 26/285 [00:45<08:15,  1.91s/it]predicting train subjects:   9%|▉         | 27/285 [00:47<07:46,  1.81s/it]predicting train subjects:  10%|▉         | 28/285 [00:49<07:58,  1.86s/it]predicting train subjects:  10%|█         | 29/285 [00:51<07:57,  1.86s/it]predicting train subjects:  11%|█         | 30/285 [00:53<08:01,  1.89s/it]predicting train subjects:  11%|█         | 31/285 [00:55<08:03,  1.90s/it]predicting train subjects:  11%|█         | 32/285 [00:56<07:38,  1.81s/it]predicting train subjects:  12%|█▏        | 33/285 [00:58<07:41,  1.83s/it]predicting train subjects:  12%|█▏        | 34/285 [01:00<07:45,  1.86s/it]predicting train subjects:  12%|█▏        | 35/285 [01:02<07:51,  1.89s/it]predicting train subjects:  13%|█▎        | 36/285 [01:04<07:28,  1.80s/it]predicting train subjects:  13%|█▎        | 37/285 [01:06<07:30,  1.82s/it]predicting train subjects:  13%|█▎        | 38/285 [01:08<07:41,  1.87s/it]predicting train subjects:  14%|█▎        | 39/285 [01:09<07:20,  1.79s/it]predicting train subjects:  14%|█▍        | 40/285 [01:11<07:23,  1.81s/it]predicting train subjects:  14%|█▍        | 41/285 [01:13<07:06,  1.75s/it]predicting train subjects:  15%|█▍        | 42/285 [01:14<06:53,  1.70s/it]predicting train subjects:  15%|█▌        | 43/285 [01:16<07:02,  1.75s/it]predicting train subjects:  15%|█▌        | 44/285 [01:18<07:12,  1.80s/it]predicting train subjects:  16%|█▌        | 45/285 [01:20<06:51,  1.72s/it]predicting train subjects:  16%|█▌        | 46/285 [01:21<07:02,  1.77s/it]predicting train subjects:  16%|█▋        | 47/285 [01:23<06:47,  1.71s/it]predicting train subjects:  17%|█▋        | 48/285 [01:25<06:54,  1.75s/it]predicting train subjects:  17%|█▋        | 49/285 [01:27<07:12,  1.83s/it]predicting train subjects:  18%|█▊        | 50/285 [01:29<07:06,  1.81s/it]predicting train subjects:  18%|█▊        | 51/285 [01:31<07:17,  1.87s/it]predicting train subjects:  18%|█▊        | 52/285 [01:32<06:52,  1.77s/it]predicting train subjects:  19%|█▊        | 53/285 [01:34<06:52,  1.78s/it]predicting train subjects:  19%|█▉        | 54/285 [01:36<07:06,  1.85s/it]predicting train subjects:  19%|█▉        | 55/285 [01:38<06:44,  1.76s/it]predicting train subjects:  20%|█▉        | 56/285 [01:39<06:51,  1.80s/it]predicting train subjects:  20%|██        | 57/285 [01:41<06:37,  1.74s/it]predicting train subjects:  20%|██        | 58/285 [01:43<06:44,  1.78s/it]predicting train subjects:  21%|██        | 59/285 [01:45<06:51,  1.82s/it]predicting train subjects:  21%|██        | 60/285 [01:47<07:00,  1.87s/it]predicting train subjects:  21%|██▏       | 61/285 [01:48<06:45,  1.81s/it]predicting train subjects:  22%|██▏       | 62/285 [01:50<06:46,  1.82s/it]predicting train subjects:  22%|██▏       | 63/285 [01:52<06:44,  1.82s/it]predicting train subjects:  22%|██▏       | 64/285 [01:54<06:34,  1.78s/it]predicting train subjects:  23%|██▎       | 65/285 [01:56<06:35,  1.80s/it]predicting train subjects:  23%|██▎       | 66/285 [01:57<06:31,  1.79s/it]predicting train subjects:  24%|██▎       | 67/285 [01:59<06:36,  1.82s/it]predicting train subjects:  24%|██▍       | 68/285 [02:01<06:23,  1.77s/it]predicting train subjects:  24%|██▍       | 69/285 [02:03<06:21,  1.76s/it]predicting train subjects:  25%|██▍       | 70/285 [02:05<06:24,  1.79s/it]predicting train subjects:  25%|██▍       | 71/285 [02:07<06:41,  1.87s/it]predicting train subjects:  25%|██▌       | 72/285 [02:08<06:26,  1.82s/it]predicting train subjects:  26%|██▌       | 73/285 [02:10<06:23,  1.81s/it]predicting train subjects:  26%|██▌       | 74/285 [02:12<06:18,  1.80s/it]predicting train subjects:  26%|██▋       | 75/285 [02:14<06:20,  1.81s/it]predicting train subjects:  27%|██▋       | 76/285 [02:16<06:19,  1.82s/it]predicting train subjects:  27%|██▋       | 77/285 [02:17<06:11,  1.78s/it]predicting train subjects:  27%|██▋       | 78/285 [02:19<05:59,  1.74s/it]predicting train subjects:  28%|██▊       | 79/285 [02:21<05:58,  1.74s/it]predicting train subjects:  28%|██▊       | 80/285 [02:22<05:55,  1.74s/it]predicting train subjects:  28%|██▊       | 81/285 [02:24<05:46,  1.70s/it]predicting train subjects:  29%|██▉       | 82/285 [02:26<05:48,  1.72s/it]predicting train subjects:  29%|██▉       | 83/285 [02:27<05:40,  1.69s/it]predicting train subjects:  29%|██▉       | 84/285 [02:29<05:45,  1.72s/it]predicting train subjects:  30%|██▉       | 85/285 [02:31<05:51,  1.76s/it]predicting train subjects:  30%|███       | 86/285 [02:33<06:03,  1.83s/it]predicting train subjects:  31%|███       | 87/285 [02:35<06:01,  1.83s/it]predicting train subjects:  31%|███       | 88/285 [02:36<05:49,  1.78s/it]predicting train subjects:  31%|███       | 89/285 [02:38<05:51,  1.80s/it]predicting train subjects:  32%|███▏      | 90/285 [02:40<05:55,  1.82s/it]predicting train subjects:  32%|███▏      | 91/285 [02:42<05:44,  1.78s/it]predicting train subjects:  32%|███▏      | 92/285 [02:44<05:52,  1.82s/it]predicting train subjects:  33%|███▎      | 93/285 [02:46<05:44,  1.79s/it]predicting train subjects:  33%|███▎      | 94/285 [02:47<05:43,  1.80s/it]predicting train subjects:  33%|███▎      | 95/285 [02:49<05:44,  1.81s/it]predicting train subjects:  34%|███▎      | 96/285 [02:51<05:44,  1.82s/it]predicting train subjects:  34%|███▍      | 97/285 [02:53<05:46,  1.84s/it]predicting train subjects:  34%|███▍      | 98/285 [02:55<05:42,  1.83s/it]predicting train subjects:  35%|███▍      | 99/285 [02:57<05:38,  1.82s/it]predicting train subjects:  35%|███▌      | 100/285 [02:58<05:40,  1.84s/it]predicting train subjects:  35%|███▌      | 101/285 [03:00<05:27,  1.78s/it]predicting train subjects:  36%|███▌      | 102/285 [03:02<05:31,  1.81s/it]predicting train subjects:  36%|███▌      | 103/285 [03:04<05:19,  1.76s/it]predicting train subjects:  36%|███▋      | 104/285 [03:05<05:18,  1.76s/it]predicting train subjects:  37%|███▋      | 105/285 [03:07<05:22,  1.79s/it]predicting train subjects:  37%|███▋      | 106/285 [03:09<05:10,  1.74s/it]predicting train subjects:  38%|███▊      | 107/285 [03:11<05:09,  1.74s/it]predicting train subjects:  38%|███▊      | 108/285 [03:12<05:02,  1.71s/it]predicting train subjects:  38%|███▊      | 109/285 [03:14<05:03,  1.72s/it]predicting train subjects:  39%|███▊      | 110/285 [03:16<05:08,  1.76s/it]predicting train subjects:  39%|███▉      | 111/285 [03:17<05:00,  1.73s/it]predicting train subjects:  39%|███▉      | 112/285 [03:19<05:00,  1.74s/it]predicting train subjects:  40%|███▉      | 113/285 [03:21<05:06,  1.78s/it]predicting train subjects:  40%|████      | 114/285 [03:23<05:00,  1.76s/it]predicting train subjects:  40%|████      | 115/285 [03:25<04:58,  1.75s/it]predicting train subjects:  41%|████      | 116/285 [03:26<04:59,  1.77s/it]predicting train subjects:  41%|████      | 117/285 [03:28<04:51,  1.73s/it]predicting train subjects:  41%|████▏     | 118/285 [03:30<04:48,  1.73s/it]predicting train subjects:  42%|████▏     | 119/285 [03:32<04:53,  1.77s/it]predicting train subjects:  42%|████▏     | 120/285 [03:33<04:47,  1.74s/it]predicting train subjects:  42%|████▏     | 121/285 [03:35<04:40,  1.71s/it]predicting train subjects:  43%|████▎     | 122/285 [03:36<04:30,  1.66s/it]predicting train subjects:  43%|████▎     | 123/285 [03:38<04:20,  1.61s/it]predicting train subjects:  44%|████▎     | 124/285 [03:40<04:19,  1.61s/it]predicting train subjects:  44%|████▍     | 125/285 [03:41<04:14,  1.59s/it]predicting train subjects:  44%|████▍     | 126/285 [03:43<04:06,  1.55s/it]predicting train subjects:  45%|████▍     | 127/285 [03:44<04:01,  1.53s/it]predicting train subjects:  45%|████▍     | 128/285 [03:46<04:01,  1.54s/it]predicting train subjects:  45%|████▌     | 129/285 [03:47<03:55,  1.51s/it]predicting train subjects:  46%|████▌     | 130/285 [03:48<03:49,  1.48s/it]predicting train subjects:  46%|████▌     | 131/285 [03:50<03:46,  1.47s/it]predicting train subjects:  46%|████▋     | 132/285 [03:51<03:50,  1.51s/it]predicting train subjects:  47%|████▋     | 133/285 [03:53<03:48,  1.50s/it]predicting train subjects:  47%|████▋     | 134/285 [03:54<03:45,  1.50s/it]predicting train subjects:  47%|████▋     | 135/285 [03:56<03:42,  1.48s/it]predicting train subjects:  48%|████▊     | 136/285 [03:57<03:42,  1.49s/it]predicting train subjects:  48%|████▊     | 137/285 [03:59<03:51,  1.56s/it]predicting train subjects:  48%|████▊     | 138/285 [04:01<03:43,  1.52s/it]predicting train subjects:  49%|████▉     | 139/285 [04:02<03:45,  1.54s/it]predicting train subjects:  49%|████▉     | 140/285 [04:04<03:55,  1.62s/it]predicting train subjects:  49%|████▉     | 141/285 [04:05<03:44,  1.56s/it]predicting train subjects:  50%|████▉     | 142/285 [04:07<03:40,  1.54s/it]predicting train subjects:  50%|█████     | 143/285 [04:08<03:36,  1.52s/it]predicting train subjects:  51%|█████     | 144/285 [04:10<03:40,  1.56s/it]predicting train subjects:  51%|█████     | 145/285 [04:12<03:37,  1.56s/it]predicting train subjects:  51%|█████     | 146/285 [04:13<03:38,  1.57s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:15<03:32,  1.54s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:16<03:38,  1.60s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:18<03:33,  1.57s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:19<03:27,  1.54s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:21<03:32,  1.59s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:22<03:26,  1.55s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:24<03:20,  1.52s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:26<03:24,  1.56s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:27<03:20,  1.54s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:29<03:25,  1.59s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:30<03:19,  1.56s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:32<03:15,  1.54s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:33<03:09,  1.51s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:35<03:08,  1.51s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:36<03:12,  1.55s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:38<03:06,  1.52s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:40<03:12,  1.58s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:41<03:09,  1.56s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:43<03:04,  1.54s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:44<03:07,  1.58s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:46<03:10,  1.61s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:47<03:03,  1.57s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:49<03:01,  1.56s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:50<02:55,  1.53s/it]predicting train subjects:  60%|██████    | 171/285 [04:52<02:54,  1.53s/it]predicting train subjects:  60%|██████    | 172/285 [04:53<02:50,  1.51s/it]predicting train subjects:  61%|██████    | 173/285 [04:55<02:50,  1.52s/it]predicting train subjects:  61%|██████    | 174/285 [04:56<02:48,  1.52s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:58<02:52,  1.57s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:00<02:53,  1.59s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:01<02:47,  1.55s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:03<02:43,  1.53s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:04<02:41,  1.52s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:06<02:49,  1.61s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:08<02:53,  1.67s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:09<02:51,  1.67s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:11<02:42,  1.60s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:12<02:36,  1.55s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:14<02:31,  1.51s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:16<02:39,  1.62s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:17<02:45,  1.68s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:19<02:46,  1.72s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:21<02:36,  1.63s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:22<02:28,  1.57s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:24<02:32,  1.62s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:26<02:35,  1.67s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:27<02:26,  1.59s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:29<02:20,  1.55s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:30<02:15,  1.50s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:32<02:24,  1.62s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:34<02:27,  1.68s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:35<02:30,  1.73s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:37<02:19,  1.63s/it]predicting train subjects:  70%|███████   | 200/285 [05:38<02:12,  1.55s/it]predicting train subjects:  71%|███████   | 201/285 [05:40<02:16,  1.62s/it]predicting train subjects:  71%|███████   | 202/285 [05:42<02:14,  1.62s/it]predicting train subjects:  71%|███████   | 203/285 [05:43<02:14,  1.64s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:45<02:08,  1.59s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:46<02:03,  1.54s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:48<01:57,  1.49s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:50<02:06,  1.62s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:51<02:09,  1.68s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:53<02:10,  1.71s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:54<02:00,  1.61s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:56<01:54,  1.55s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:57<01:54,  1.56s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:59<01:54,  1.58s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:01<01:48,  1.53s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:02<01:53,  1.62s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:04<01:45,  1.53s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:05<01:49,  1.62s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:07<01:52,  1.68s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:09<01:52,  1.71s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:10<01:44,  1.61s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:12<01:42,  1.60s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:14<01:42,  1.63s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:15<01:35,  1.55s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:17<01:33,  1.52s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:18<01:26,  1.45s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:20<01:31,  1.55s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:21<01:35,  1.64s/it]predicting train subjects:  80%|████████  | 228/285 [06:23<01:37,  1.71s/it]predicting train subjects:  80%|████████  | 229/285 [06:25<01:36,  1.71s/it]predicting train subjects:  81%|████████  | 230/285 [06:26<01:28,  1.61s/it]predicting train subjects:  81%|████████  | 231/285 [06:28<01:24,  1.57s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:30<01:24,  1.59s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:31<01:20,  1.54s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:33<01:24,  1.65s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:34<01:18,  1.57s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:36<01:22,  1.68s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:38<01:22,  1.71s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:40<01:23,  1.77s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:42<01:19,  1.72s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:43<01:13,  1.64s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:44<01:10,  1.60s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:46<01:05,  1.53s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:47<01:03,  1.52s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:49<01:07,  1.66s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:51<01:03,  1.59s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:53<01:05,  1.69s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:55<01:05,  1.73s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:56<01:03,  1.72s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:58<00:59,  1.65s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:59<00:56,  1.63s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:01<00:52,  1.56s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:02<00:49,  1.51s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:04<00:51,  1.62s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:06<00:52,  1.68s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:07<00:50,  1.68s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:09<00:45,  1.56s/it]predicting train subjects:  90%|█████████ | 257/285 [07:10<00:43,  1.55s/it]predicting train subjects:  91%|█████████ | 258/285 [07:12<00:44,  1.63s/it]predicting train subjects:  91%|█████████ | 259/285 [07:14<00:43,  1.67s/it]predicting train subjects:  91%|█████████ | 260/285 [07:15<00:39,  1.56s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:17<00:36,  1.52s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:18<00:34,  1.49s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:19<00:32,  1.46s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:21<00:33,  1.59s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:23<00:33,  1.66s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:24<00:29,  1.58s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:26<00:27,  1.55s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:28<00:27,  1.65s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:30<00:26,  1.67s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:31<00:23,  1.59s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:32<00:21,  1.55s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:34<00:20,  1.58s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:36<00:18,  1.55s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:37<00:16,  1.51s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:39<00:16,  1.61s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:41<00:15,  1.68s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:42<00:12,  1.59s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:43<00:10,  1.55s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:45<00:09,  1.58s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:47<00:07,  1.53s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:48<00:06,  1.50s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:49<00:04,  1.47s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:51<00:03,  1.57s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:53<00:01,  1.66s/it]predicting train subjects: 100%|██████████| 285/285 [07:55<00:00,  1.71s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:00,  1.69s/it]Loading train:   1%|          | 2/285 [00:03<07:28,  1.59s/it]Loading train:   1%|          | 3/285 [00:04<07:34,  1.61s/it]Loading train:   1%|▏         | 4/285 [00:05<07:04,  1.51s/it]Loading train:   2%|▏         | 5/285 [00:07<07:22,  1.58s/it]Loading train:   2%|▏         | 6/285 [00:09<07:09,  1.54s/it]Loading train:   2%|▏         | 7/285 [00:10<07:12,  1.55s/it]Loading train:   3%|▎         | 8/285 [00:12<07:05,  1.54s/it]Loading train:   3%|▎         | 9/285 [00:14<07:31,  1.64s/it]Loading train:   4%|▎         | 10/285 [00:15<07:14,  1.58s/it]Loading train:   4%|▍         | 11/285 [00:16<06:31,  1.43s/it]Loading train:   4%|▍         | 12/285 [00:17<06:12,  1.36s/it]Loading train:   5%|▍         | 13/285 [00:19<06:05,  1.35s/it]Loading train:   5%|▍         | 14/285 [00:20<06:06,  1.35s/it]Loading train:   5%|▌         | 15/285 [00:21<06:11,  1.37s/it]Loading train:   6%|▌         | 16/285 [00:23<06:13,  1.39s/it]Loading train:   6%|▌         | 17/285 [00:24<05:56,  1.33s/it]Loading train:   6%|▋         | 18/285 [00:25<05:55,  1.33s/it]Loading train:   7%|▋         | 19/285 [00:26<05:30,  1.24s/it]Loading train:   7%|▋         | 20/285 [00:28<05:27,  1.24s/it]Loading train:   7%|▋         | 21/285 [00:29<05:34,  1.27s/it]Loading train:   8%|▊         | 22/285 [00:30<05:07,  1.17s/it]Loading train:   8%|▊         | 23/285 [00:31<05:03,  1.16s/it]Loading train:   8%|▊         | 24/285 [00:32<04:44,  1.09s/it]Loading train:   9%|▉         | 25/285 [00:33<04:57,  1.14s/it]Loading train:   9%|▉         | 26/285 [00:34<04:58,  1.15s/it]Loading train:   9%|▉         | 27/285 [00:35<04:36,  1.07s/it]Loading train:  10%|▉         | 28/285 [00:37<04:53,  1.14s/it]Loading train:  10%|█         | 29/285 [00:38<04:48,  1.13s/it]Loading train:  11%|█         | 30/285 [00:39<05:27,  1.28s/it]Loading train:  11%|█         | 31/285 [00:41<05:31,  1.30s/it]Loading train:  11%|█         | 32/285 [00:42<05:00,  1.19s/it]Loading train:  12%|█▏        | 33/285 [00:43<05:16,  1.25s/it]Loading train:  12%|█▏        | 34/285 [00:44<04:55,  1.18s/it]Loading train:  12%|█▏        | 35/285 [00:46<05:44,  1.38s/it]Loading train:  13%|█▎        | 36/285 [00:47<05:37,  1.35s/it]Loading train:  13%|█▎        | 37/285 [00:49<05:36,  1.36s/it]Loading train:  13%|█▎        | 38/285 [00:50<05:47,  1.41s/it]Loading train:  14%|█▎        | 39/285 [00:51<05:45,  1.41s/it]Loading train:  14%|█▍        | 40/285 [00:53<05:50,  1.43s/it]Loading train:  14%|█▍        | 41/285 [00:54<05:49,  1.43s/it]Loading train:  15%|█▍        | 42/285 [00:56<05:42,  1.41s/it]Loading train:  15%|█▌        | 43/285 [00:57<05:30,  1.36s/it]Loading train:  15%|█▌        | 44/285 [00:58<05:35,  1.39s/it]Loading train:  16%|█▌        | 45/285 [01:00<05:37,  1.41s/it]Loading train:  16%|█▌        | 46/285 [01:01<05:42,  1.43s/it]Loading train:  16%|█▋        | 47/285 [01:03<06:01,  1.52s/it]Loading train:  17%|█▋        | 48/285 [01:05<05:59,  1.52s/it]Loading train:  17%|█▋        | 49/285 [01:06<06:16,  1.59s/it]Loading train:  18%|█▊        | 50/285 [01:08<06:10,  1.58s/it]Loading train:  18%|█▊        | 51/285 [01:10<06:16,  1.61s/it]Loading train:  18%|█▊        | 52/285 [01:11<06:02,  1.56s/it]Loading train:  19%|█▊        | 53/285 [01:13<06:02,  1.56s/it]Loading train:  19%|█▉        | 54/285 [01:15<06:23,  1.66s/it]Loading train:  19%|█▉        | 55/285 [01:16<06:14,  1.63s/it]Loading train:  20%|█▉        | 56/285 [01:18<06:14,  1.64s/it]Loading train:  20%|██        | 57/285 [01:19<06:04,  1.60s/it]Loading train:  20%|██        | 58/285 [01:21<05:50,  1.54s/it]Loading train:  21%|██        | 59/285 [01:22<06:05,  1.62s/it]Loading train:  21%|██        | 60/285 [01:24<06:09,  1.64s/it]Loading train:  21%|██▏       | 61/285 [01:26<05:54,  1.58s/it]Loading train:  22%|██▏       | 62/285 [01:27<05:46,  1.55s/it]Loading train:  22%|██▏       | 63/285 [01:29<05:37,  1.52s/it]Loading train:  22%|██▏       | 64/285 [01:30<05:51,  1.59s/it]Loading train:  23%|██▎       | 65/285 [01:32<06:04,  1.66s/it]Loading train:  23%|██▎       | 66/285 [01:34<06:34,  1.80s/it]Loading train:  24%|██▎       | 67/285 [01:36<06:29,  1.79s/it]Loading train:  24%|██▍       | 68/285 [01:38<06:14,  1.72s/it]Loading train:  24%|██▍       | 69/285 [01:39<05:59,  1.66s/it]Loading train:  25%|██▍       | 70/285 [01:41<05:50,  1.63s/it]Loading train:  25%|██▍       | 71/285 [01:42<05:52,  1.65s/it]Loading train:  25%|██▌       | 72/285 [01:44<05:36,  1.58s/it]Loading train:  26%|██▌       | 73/285 [01:45<05:26,  1.54s/it]Loading train:  26%|██▌       | 74/285 [01:47<05:13,  1.49s/it]Loading train:  26%|██▋       | 75/285 [01:48<05:14,  1.50s/it]Loading train:  27%|██▋       | 76/285 [01:50<05:16,  1.52s/it]Loading train:  27%|██▋       | 77/285 [01:51<05:21,  1.55s/it]Loading train:  27%|██▋       | 78/285 [01:53<05:07,  1.49s/it]Loading train:  28%|██▊       | 79/285 [01:54<05:07,  1.49s/it]Loading train:  28%|██▊       | 80/285 [01:56<05:18,  1.56s/it]Loading train:  28%|██▊       | 81/285 [01:58<05:41,  1.68s/it]Loading train:  29%|██▉       | 82/285 [02:00<05:54,  1.75s/it]Loading train:  29%|██▉       | 83/285 [02:01<05:56,  1.76s/it]Loading train:  29%|██▉       | 84/285 [02:03<05:41,  1.70s/it]Loading train:  30%|██▉       | 85/285 [02:04<05:13,  1.57s/it]Loading train:  30%|███       | 86/285 [02:06<05:21,  1.62s/it]Loading train:  31%|███       | 87/285 [02:07<05:05,  1.54s/it]Loading train:  31%|███       | 88/285 [02:09<04:59,  1.52s/it]Loading train:  31%|███       | 89/285 [02:11<05:09,  1.58s/it]Loading train:  32%|███▏      | 90/285 [02:12<05:15,  1.62s/it]Loading train:  32%|███▏      | 91/285 [02:14<05:43,  1.77s/it]Loading train:  32%|███▏      | 92/285 [02:16<05:26,  1.69s/it]Loading train:  33%|███▎      | 93/285 [02:17<05:10,  1.62s/it]Loading train:  33%|███▎      | 94/285 [02:19<04:56,  1.55s/it]Loading train:  33%|███▎      | 95/285 [02:20<04:50,  1.53s/it]Loading train:  34%|███▎      | 96/285 [02:22<04:43,  1.50s/it]Loading train:  34%|███▍      | 97/285 [02:23<04:47,  1.53s/it]Loading train:  34%|███▍      | 98/285 [02:25<04:38,  1.49s/it]Loading train:  35%|███▍      | 99/285 [02:26<04:33,  1.47s/it]Loading train:  35%|███▌      | 100/285 [02:28<04:36,  1.50s/it]Loading train:  35%|███▌      | 101/285 [02:29<04:44,  1.55s/it]Loading train:  36%|███▌      | 102/285 [02:31<04:39,  1.52s/it]Loading train:  36%|███▌      | 103/285 [02:32<04:35,  1.51s/it]Loading train:  36%|███▋      | 104/285 [02:34<04:34,  1.52s/it]Loading train:  37%|███▋      | 105/285 [02:35<04:40,  1.56s/it]Loading train:  37%|███▋      | 106/285 [02:37<04:38,  1.55s/it]Loading train:  38%|███▊      | 107/285 [02:38<04:21,  1.47s/it]Loading train:  38%|███▊      | 108/285 [02:40<04:17,  1.46s/it]Loading train:  38%|███▊      | 109/285 [02:41<04:23,  1.50s/it]Loading train:  39%|███▊      | 110/285 [02:43<04:24,  1.51s/it]Loading train:  39%|███▉      | 111/285 [02:44<04:17,  1.48s/it]Loading train:  39%|███▉      | 112/285 [02:46<04:21,  1.51s/it]Loading train:  40%|███▉      | 113/285 [02:47<04:12,  1.47s/it]Loading train:  40%|████      | 114/285 [02:49<04:08,  1.45s/it]Loading train:  40%|████      | 115/285 [02:50<04:06,  1.45s/it]Loading train:  41%|████      | 116/285 [02:52<04:05,  1.45s/it]Loading train:  41%|████      | 117/285 [02:53<03:58,  1.42s/it]Loading train:  41%|████▏     | 118/285 [02:54<04:00,  1.44s/it]Loading train:  42%|████▏     | 119/285 [02:56<04:08,  1.50s/it]Loading train:  42%|████▏     | 120/285 [02:58<04:12,  1.53s/it]Loading train:  42%|████▏     | 121/285 [02:59<04:15,  1.56s/it]Loading train:  43%|████▎     | 122/285 [03:01<04:20,  1.60s/it]Loading train:  43%|████▎     | 123/285 [03:03<04:23,  1.63s/it]Loading train:  44%|████▎     | 124/285 [03:04<04:02,  1.50s/it]Loading train:  44%|████▍     | 125/285 [03:05<03:50,  1.44s/it]Loading train:  44%|████▍     | 126/285 [03:06<03:39,  1.38s/it]Loading train:  45%|████▍     | 127/285 [03:08<03:39,  1.39s/it]Loading train:  45%|████▍     | 128/285 [03:09<03:29,  1.33s/it]Loading train:  45%|████▌     | 129/285 [03:10<03:27,  1.33s/it]Loading train:  46%|████▌     | 130/285 [03:12<03:35,  1.39s/it]Loading train:  46%|████▌     | 131/285 [03:13<03:34,  1.40s/it]Loading train:  46%|████▋     | 132/285 [03:15<03:28,  1.36s/it]Loading train:  47%|████▋     | 133/285 [03:16<03:21,  1.32s/it]Loading train:  47%|████▋     | 134/285 [03:17<03:18,  1.31s/it]Loading train:  47%|████▋     | 135/285 [03:18<03:15,  1.31s/it]Loading train:  48%|████▊     | 136/285 [03:20<03:09,  1.27s/it]Loading train:  48%|████▊     | 137/285 [03:21<03:17,  1.33s/it]Loading train:  48%|████▊     | 138/285 [03:22<03:18,  1.35s/it]Loading train:  49%|████▉     | 139/285 [03:24<03:22,  1.39s/it]Loading train:  49%|████▉     | 140/285 [03:25<03:15,  1.35s/it]Loading train:  49%|████▉     | 141/285 [03:26<03:03,  1.28s/it]Loading train:  50%|████▉     | 142/285 [03:28<03:04,  1.29s/it]Loading train:  50%|█████     | 143/285 [03:29<03:03,  1.29s/it]Loading train:  51%|█████     | 144/285 [03:30<03:04,  1.31s/it]Loading train:  51%|█████     | 145/285 [03:31<02:54,  1.24s/it]Loading train:  51%|█████     | 146/285 [03:33<02:51,  1.23s/it]Loading train:  52%|█████▏    | 147/285 [03:34<02:55,  1.28s/it]Loading train:  52%|█████▏    | 148/285 [03:35<03:00,  1.32s/it]Loading train:  52%|█████▏    | 149/285 [03:37<02:55,  1.29s/it]Loading train:  53%|█████▎    | 150/285 [03:38<02:53,  1.29s/it]Loading train:  53%|█████▎    | 151/285 [03:39<02:45,  1.24s/it]Loading train:  53%|█████▎    | 152/285 [03:40<02:39,  1.20s/it]Loading train:  54%|█████▎    | 153/285 [03:41<02:42,  1.23s/it]Loading train:  54%|█████▍    | 154/285 [03:43<02:50,  1.30s/it]Loading train:  54%|█████▍    | 155/285 [03:44<02:55,  1.35s/it]Loading train:  55%|█████▍    | 156/285 [03:46<02:50,  1.32s/it]Loading train:  55%|█████▌    | 157/285 [03:47<02:45,  1.29s/it]Loading train:  55%|█████▌    | 158/285 [03:48<02:38,  1.25s/it]Loading train:  56%|█████▌    | 159/285 [03:49<02:28,  1.18s/it]Loading train:  56%|█████▌    | 160/285 [03:50<02:36,  1.25s/it]Loading train:  56%|█████▋    | 161/285 [03:52<02:34,  1.25s/it]Loading train:  57%|█████▋    | 162/285 [03:53<02:38,  1.29s/it]Loading train:  57%|█████▋    | 163/285 [03:54<02:36,  1.28s/it]Loading train:  58%|█████▊    | 164/285 [03:55<02:29,  1.24s/it]Loading train:  58%|█████▊    | 165/285 [03:57<02:34,  1.28s/it]Loading train:  58%|█████▊    | 166/285 [03:58<02:29,  1.25s/it]Loading train:  59%|█████▊    | 167/285 [03:59<02:38,  1.35s/it]Loading train:  59%|█████▉    | 168/285 [04:01<02:47,  1.43s/it]Loading train:  59%|█████▉    | 169/285 [04:03<02:44,  1.42s/it]Loading train:  60%|█████▉    | 170/285 [04:04<02:50,  1.48s/it]Loading train:  60%|██████    | 171/285 [04:05<02:41,  1.42s/it]Loading train:  60%|██████    | 172/285 [04:07<02:36,  1.39s/it]Loading train:  61%|██████    | 173/285 [04:08<02:29,  1.33s/it]Loading train:  61%|██████    | 174/285 [04:09<02:19,  1.26s/it]Loading train:  61%|██████▏   | 175/285 [04:10<02:24,  1.32s/it]Loading train:  62%|██████▏   | 176/285 [04:12<02:18,  1.27s/it]Loading train:  62%|██████▏   | 177/285 [04:13<02:13,  1.23s/it]Loading train:  62%|██████▏   | 178/285 [04:14<02:10,  1.22s/it]Loading train:  63%|██████▎   | 179/285 [04:15<02:12,  1.25s/it]Loading train:  63%|██████▎   | 180/285 [04:17<02:17,  1.31s/it]Loading train:  64%|██████▎   | 181/285 [04:18<02:21,  1.36s/it]Loading train:  64%|██████▍   | 182/285 [04:20<02:19,  1.36s/it]Loading train:  64%|██████▍   | 183/285 [04:21<02:20,  1.38s/it]Loading train:  65%|██████▍   | 184/285 [04:22<02:20,  1.39s/it]Loading train:  65%|██████▍   | 185/285 [04:24<02:28,  1.49s/it]Loading train:  65%|██████▌   | 186/285 [04:26<02:35,  1.57s/it]Loading train:  66%|██████▌   | 187/285 [04:27<02:34,  1.57s/it]Loading train:  66%|██████▌   | 188/285 [04:29<02:30,  1.56s/it]Loading train:  66%|██████▋   | 189/285 [04:31<02:36,  1.63s/it]Loading train:  67%|██████▋   | 190/285 [04:32<02:31,  1.60s/it]Loading train:  67%|██████▋   | 191/285 [04:34<02:29,  1.59s/it]Loading train:  67%|██████▋   | 192/285 [04:35<02:27,  1.58s/it]Loading train:  68%|██████▊   | 193/285 [04:37<02:20,  1.53s/it]Loading train:  68%|██████▊   | 194/285 [04:38<02:12,  1.45s/it]Loading train:  68%|██████▊   | 195/285 [04:40<02:19,  1.55s/it]Loading train:  69%|██████▉   | 196/285 [04:42<02:30,  1.69s/it]Loading train:  69%|██████▉   | 197/285 [04:43<02:21,  1.61s/it]Loading train:  69%|██████▉   | 198/285 [04:45<02:19,  1.60s/it]Loading train:  70%|██████▉   | 199/285 [04:47<02:22,  1.66s/it]Loading train:  70%|███████   | 200/285 [04:48<02:12,  1.56s/it]Loading train:  71%|███████   | 201/285 [04:50<02:18,  1.64s/it]Loading train:  71%|███████   | 202/285 [04:52<02:27,  1.77s/it]Loading train:  71%|███████   | 203/285 [04:53<02:12,  1.61s/it]Loading train:  72%|███████▏  | 204/285 [04:55<02:14,  1.66s/it]Loading train:  72%|███████▏  | 205/285 [04:56<02:01,  1.52s/it]Loading train:  72%|███████▏  | 206/285 [04:58<01:58,  1.50s/it]Loading train:  73%|███████▎  | 207/285 [04:59<01:59,  1.53s/it]Loading train:  73%|███████▎  | 208/285 [05:01<02:04,  1.62s/it]Loading train:  73%|███████▎  | 209/285 [05:03<02:02,  1.61s/it]Loading train:  74%|███████▎  | 210/285 [05:04<01:59,  1.60s/it]Loading train:  74%|███████▍  | 211/285 [05:06<01:56,  1.58s/it]Loading train:  74%|███████▍  | 212/285 [05:07<01:51,  1.53s/it]Loading train:  75%|███████▍  | 213/285 [05:08<01:45,  1.47s/it]Loading train:  75%|███████▌  | 214/285 [05:10<01:43,  1.46s/it]Loading train:  75%|███████▌  | 215/285 [05:12<01:46,  1.52s/it]Loading train:  76%|███████▌  | 216/285 [05:13<01:36,  1.41s/it]Loading train:  76%|███████▌  | 217/285 [05:14<01:38,  1.45s/it]Loading train:  76%|███████▋  | 218/285 [05:17<01:53,  1.69s/it]Loading train:  77%|███████▋  | 219/285 [05:18<01:48,  1.64s/it]Loading train:  77%|███████▋  | 220/285 [05:19<01:42,  1.57s/it]Loading train:  78%|███████▊  | 221/285 [05:21<01:38,  1.54s/it]Loading train:  78%|███████▊  | 222/285 [05:23<01:38,  1.56s/it]Loading train:  78%|███████▊  | 223/285 [05:24<01:37,  1.57s/it]Loading train:  79%|███████▊  | 224/285 [05:25<01:29,  1.47s/it]Loading train:  79%|███████▉  | 225/285 [05:27<01:29,  1.48s/it]Loading train:  79%|███████▉  | 226/285 [05:28<01:27,  1.48s/it]Loading train:  80%|███████▉  | 227/285 [05:30<01:31,  1.59s/it]Loading train:  80%|████████  | 228/285 [05:32<01:31,  1.61s/it]Loading train:  80%|████████  | 229/285 [05:34<01:36,  1.73s/it]Loading train:  81%|████████  | 230/285 [05:36<01:37,  1.77s/it]Loading train:  81%|████████  | 231/285 [05:37<01:25,  1.58s/it]Loading train:  81%|████████▏ | 232/285 [05:38<01:22,  1.56s/it]Loading train:  82%|████████▏ | 233/285 [05:40<01:19,  1.53s/it]Loading train:  82%|████████▏ | 234/285 [05:41<01:17,  1.53s/it]Loading train:  82%|████████▏ | 235/285 [05:43<01:16,  1.53s/it]Loading train:  83%|████████▎ | 236/285 [05:45<01:18,  1.60s/it]Loading train:  83%|████████▎ | 237/285 [05:47<01:21,  1.70s/it]Loading train:  84%|████████▎ | 238/285 [05:48<01:19,  1.70s/it]Loading train:  84%|████████▍ | 239/285 [05:50<01:15,  1.64s/it]Loading train:  84%|████████▍ | 240/285 [05:51<01:11,  1.58s/it]Loading train:  85%|████████▍ | 241/285 [05:53<01:11,  1.62s/it]Loading train:  85%|████████▍ | 242/285 [05:55<01:10,  1.63s/it]Loading train:  85%|████████▌ | 243/285 [05:56<01:04,  1.52s/it]Loading train:  86%|████████▌ | 244/285 [05:58<01:11,  1.73s/it]Loading train:  86%|████████▌ | 245/285 [05:59<01:05,  1.64s/it]Loading train:  86%|████████▋ | 246/285 [06:01<01:05,  1.68s/it]Loading train:  87%|████████▋ | 247/285 [06:03<01:04,  1.70s/it]Loading train:  87%|████████▋ | 248/285 [06:05<01:00,  1.65s/it]Loading train:  87%|████████▋ | 249/285 [06:06<00:59,  1.65s/it]Loading train:  88%|████████▊ | 250/285 [06:08<01:00,  1.72s/it]Loading train:  88%|████████▊ | 251/285 [06:10<00:58,  1.73s/it]Loading train:  88%|████████▊ | 252/285 [06:12<00:57,  1.74s/it]Loading train:  89%|████████▉ | 253/285 [06:15<01:07,  2.11s/it]Loading train:  89%|████████▉ | 254/285 [06:17<01:10,  2.27s/it]Loading train:  89%|████████▉ | 255/285 [06:20<01:08,  2.30s/it]Loading train:  90%|████████▉ | 256/285 [06:21<01:02,  2.16s/it]Loading train:  90%|█████████ | 257/285 [06:23<00:59,  2.13s/it]Loading train:  91%|█████████ | 258/285 [06:26<01:01,  2.28s/it]Loading train:  91%|█████████ | 259/285 [06:28<00:59,  2.28s/it]Loading train:  91%|█████████ | 260/285 [06:30<00:55,  2.22s/it]Loading train:  92%|█████████▏| 261/285 [06:32<00:50,  2.12s/it]Loading train:  92%|█████████▏| 262/285 [06:34<00:47,  2.06s/it]Loading train:  92%|█████████▏| 263/285 [06:36<00:46,  2.09s/it]Loading train:  93%|█████████▎| 264/285 [06:39<00:46,  2.20s/it]Loading train:  93%|█████████▎| 265/285 [06:41<00:46,  2.31s/it]Loading train:  93%|█████████▎| 266/285 [06:43<00:42,  2.21s/it]Loading train:  94%|█████████▎| 267/285 [06:45<00:39,  2.17s/it]Loading train:  94%|█████████▍| 268/285 [06:48<00:40,  2.37s/it]Loading train:  94%|█████████▍| 269/285 [06:50<00:35,  2.22s/it]Loading train:  95%|█████████▍| 270/285 [06:52<00:33,  2.21s/it]Loading train:  95%|█████████▌| 271/285 [06:54<00:30,  2.16s/it]Loading train:  95%|█████████▌| 272/285 [06:56<00:27,  2.08s/it]Loading train:  96%|█████████▌| 273/285 [06:58<00:24,  2.03s/it]Loading train:  96%|█████████▌| 274/285 [07:00<00:21,  1.96s/it]Loading train:  96%|█████████▋| 275/285 [07:02<00:19,  1.98s/it]Loading train:  97%|█████████▋| 276/285 [07:04<00:19,  2.11s/it]Loading train:  97%|█████████▋| 277/285 [07:07<00:16,  2.08s/it]Loading train:  98%|█████████▊| 278/285 [07:08<00:13,  1.96s/it]Loading train:  98%|█████████▊| 279/285 [07:10<00:11,  1.94s/it]Loading train:  98%|█████████▊| 280/285 [07:12<00:09,  1.95s/it]Loading train:  99%|█████████▊| 281/285 [07:14<00:07,  1.92s/it]Loading train:  99%|█████████▉| 282/285 [07:16<00:06,  2.03s/it]Loading train:  99%|█████████▉| 283/285 [07:18<00:04,  2.11s/it]Loading train: 100%|█████████▉| 284/285 [07:21<00:02,  2.12s/it]Loading train: 100%|██████████| 285/285 [07:23<00:00,  2.16s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|          | 2/285 [00:00<00:19, 14.77it/s]concatenating: train:   1%|▏         | 4/285 [00:00<00:18, 15.02it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:15, 17.42it/s]concatenating: train:   5%|▍         | 13/285 [00:00<00:12, 22.03it/s]concatenating: train:   7%|▋         | 21/285 [00:00<00:09, 28.15it/s]concatenating: train:   9%|▉         | 26/285 [00:00<00:09, 25.95it/s]concatenating: train:  11%|█         | 30/285 [00:01<00:10, 23.32it/s]concatenating: train:  12%|█▏        | 34/285 [00:01<00:10, 24.86it/s]concatenating: train:  14%|█▍        | 41/285 [00:01<00:07, 30.51it/s]concatenating: train:  17%|█▋        | 48/285 [00:01<00:06, 36.04it/s]concatenating: train:  19%|█▉        | 55/285 [00:01<00:05, 41.28it/s]concatenating: train:  21%|██▏       | 61/285 [00:01<00:05, 42.45it/s]concatenating: train:  23%|██▎       | 66/285 [00:01<00:06, 35.10it/s]concatenating: train:  25%|██▍       | 71/285 [00:02<00:07, 30.17it/s]concatenating: train:  27%|██▋       | 77/285 [00:02<00:05, 34.97it/s]concatenating: train:  29%|██▉       | 82/285 [00:02<00:05, 36.74it/s]concatenating: train:  31%|███       | 88/285 [00:02<00:04, 40.52it/s]concatenating: train:  33%|███▎      | 93/285 [00:02<00:04, 40.12it/s]concatenating: train:  34%|███▍      | 98/285 [00:02<00:05, 36.01it/s]concatenating: train:  36%|███▌      | 102/285 [00:02<00:05, 34.08it/s]concatenating: train:  37%|███▋      | 106/285 [00:02<00:05, 35.29it/s]concatenating: train:  39%|███▉      | 111/285 [00:03<00:04, 36.99it/s]concatenating: train:  40%|████      | 115/285 [00:03<00:05, 31.13it/s]concatenating: train:  42%|████▏     | 119/285 [00:03<00:05, 30.88it/s]concatenating: train:  43%|████▎     | 123/285 [00:03<00:05, 31.58it/s]concatenating: train:  45%|████▌     | 129/285 [00:03<00:04, 36.01it/s]concatenating: train:  48%|████▊     | 136/285 [00:03<00:03, 41.55it/s]concatenating: train:  49%|████▉     | 141/285 [00:03<00:03, 42.01it/s]concatenating: train:  51%|█████     | 146/285 [00:03<00:03, 38.42it/s]concatenating: train:  53%|█████▎    | 151/285 [00:04<00:03, 33.90it/s]concatenating: train:  54%|█████▍    | 155/285 [00:04<00:04, 31.80it/s]concatenating: train:  56%|█████▋    | 161/285 [00:04<00:03, 35.70it/s]concatenating: train:  59%|█████▉    | 168/285 [00:04<00:02, 40.97it/s]concatenating: train:  61%|██████▏   | 175/285 [00:04<00:02, 45.69it/s]concatenating: train:  64%|██████▎   | 181/285 [00:04<00:02, 45.62it/s]concatenating: train:  66%|██████▌   | 188/285 [00:04<00:01, 49.64it/s]concatenating: train:  68%|██████▊   | 194/285 [00:05<00:02, 42.19it/s]concatenating: train:  70%|██████▉   | 199/285 [00:05<00:02, 33.57it/s]concatenating: train:  71%|███████   | 203/285 [00:05<00:02, 33.84it/s]concatenating: train:  73%|███████▎  | 209/285 [00:05<00:01, 38.93it/s]concatenating: train:  75%|███████▌  | 214/285 [00:05<00:01, 37.23it/s]concatenating: train:  77%|███████▋  | 219/285 [00:05<00:01, 35.51it/s]concatenating: train:  78%|███████▊  | 223/285 [00:05<00:01, 36.72it/s]concatenating: train:  81%|████████  | 230/285 [00:06<00:01, 41.33it/s]concatenating: train:  82%|████████▏ | 235/285 [00:06<00:01, 35.44it/s]concatenating: train:  84%|████████▍ | 239/285 [00:06<00:01, 28.78it/s]concatenating: train:  85%|████████▌ | 243/285 [00:06<00:01, 31.42it/s]concatenating: train:  88%|████████▊ | 250/285 [00:06<00:00, 37.62it/s]concatenating: train:  91%|█████████ | 259/285 [00:06<00:00, 44.26it/s]concatenating: train:  93%|█████████▎| 266/285 [00:06<00:00, 49.27it/s]concatenating: train:  95%|█████████▌| 272/285 [00:07<00:00, 41.23it/s]concatenating: train:  97%|█████████▋| 277/285 [00:07<00:00, 36.75it/s]concatenating: train:  99%|█████████▉| 282/285 [00:07<00:00, 37.08it/s]concatenating: train: 100%|██████████| 285/285 [00:07<00:00, 38.58it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:02<00:04,  2.29s/it]Loading test:  67%|██████▋   | 2/3 [00:05<00:02,  2.56s/it]Loading test: 100%|██████████| 3/3 [00:07<00:00,  2.39s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation:  33%|███▎      | 1/3 [00:00<00:00,  8.10it/s]concatenating: validation:  67%|██████▋   | 2/3 [00:00<00:00,  8.25it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00,  8.71it/s]2019-07-09 02:39:03.918393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-09 02:39:03.918522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-09 02:39:03.918543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-09 02:39:03.918557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-09 02:39:03.919030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12743 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:11,  3.88it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:10,  4.01it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:01<00:10,  3.83it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:01<00:07,  4.95it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:09,  3.74it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:07,  4.51it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:02<00:08,  3.56it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:02<00:05,  4.72it/s]loading the weights for Res Unet:  41%|████      | 18/44 [00:02<00:06,  3.89it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:03<00:05,  4.30it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:03<00:07,  3.19it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:04<00:04,  4.03it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:04<00:03,  4.43it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:05<00:05,  2.84it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:05<00:03,  3.57it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:05<00:03,  3.32it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:06<00:02,  4.35it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:06<00:01,  4.73it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:06<00:01,  3.63it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:07<00:01,  3.80it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:07<00:00,  3.80it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:07<00:00,  5.86it/s]
Epoch 00043: val_mDice did not improve from 0.56774
Restoring model weights from the end of the best epoch
Epoch 00043: early stopping
{'val_loss': [8534.819103422618, 5866.218064081101, 3917.993210565476, 3811.5286807105654, 3096.3959030877977, 3360.0658598400296, 3090.0682431175596, 2816.2379789806546, 2837.4186430431546, 3038.6808733258927, 2604.0723237537204, 2878.4457891555057, 2589.1896623883927, 2714.3285551525296, 3162.4466378348216, 2703.2689383370534, 2793.4672967819943, 2712.4216889880954, 2661.3671061197915, 2728.6555757068454, 2666.0663248697915, 2887.3643740699404, 2833.5314360119046, 2721.0010346912204, 2702.953636532738, 2607.6981666201636, 2693.070021856399, 2743.674560546875, 2745.2241094680057, 2652.230776832217, 2673.1255231584823, 2905.1742234002977, 2772.1074974423364, 2810.54825265067, 2640.4021112351193, 2665.685262044271, 2654.5535598028273, 2738.156778971354, 2684.2364211309523, 2838.0947149367557, 2640.519083658854, 2670.729695638021, 2809.316621326265], 'val_acc': [0.9037431506883531, 0.913905660311381, 0.9229899304253715, 0.9259867384320214, 0.9303365633601234, 0.9159455185844785, 0.916753663903191, 0.9339537535394941, 0.9356822570164999, 0.9297985377765837, 0.9401922878764924, 0.9333882956277757, 0.9387935031028021, 0.9376854584330604, 0.9392444831984383, 0.9353892008463541, 0.9375618071783156, 0.9432142689114525, 0.9407555091948736, 0.9423671960830688, 0.9452747078168959, 0.9419505425861904, 0.9351900446982611, 0.9408218974158877, 0.9387339977991014, 0.9396154057411921, 0.9401923077447074, 0.9435828697113764, 0.9413164144470578, 0.9424221402122861, 0.9423626519384838, 0.9440888478642419, 0.9449702614829654, 0.9381959693772453, 0.9445489957219079, 0.9441117218562535, 0.9426900318690709, 0.9435416630336216, 0.9455105378514245, 0.9436835930460975, 0.9469024538993835, 0.9447642167409261, 0.9409272273381551], 'val_mDice': [0.18815278758605322, 0.31256390079791646, 0.4326839291801055, 0.44452708170172717, 0.5128953212073871, 0.490822935210807, 0.5148679163484347, 0.5412669605797246, 0.5380439197733289, 0.5174471743050075, 0.5656863795149893, 0.5357643582281613, 0.5677438355272725, 0.5539063986923013, 0.5059093114520822, 0.5543584756198383, 0.5438940024801663, 0.5524713052880197, 0.5574539857251304, 0.5499149376437777, 0.5572017150975409, 0.5331527927801722, 0.5401665504489627, 0.5513985543733552, 0.5544406954376471, 0.5640823498723053, 0.5531524295608202, 0.5467965984273524, 0.5462559447402046, 0.556133541145495, 0.5543272933434873, 0.5320437511517888, 0.5424149439093613, 0.5401701302755446, 0.5583070945881662, 0.5538892015105202, 0.5550277697898093, 0.5463120798979487, 0.5515187714426291, 0.5375740510367212, 0.557027395992052, 0.5543208920529911, 0.5389306167406696], 'loss': [12603.79607409449, 4387.6819383758375, 3331.27231187381, 2860.1660790017786, 2564.390004293524, 2366.75310334411, 2248.662910280509, 2129.3256889124104, 2054.067721206374, 1970.1433201016364, 1906.9282733482594, 1863.4696280966841, 1818.5416927657561, 1764.6333780430268, 1738.1896346654648, 1703.4783085973272, 1667.141034325033, 1656.694353611455, 1624.0122400963724, 1595.7591197843242, 1576.1471016925955, 1559.7915515153193, 1537.2688087123609, 1528.7688604163277, 1504.2613428195639, 1486.435187512426, 1471.4642598976031, 1457.6508981099082, 1454.7608678114307, 1435.6107808913434, 1412.0846850731848, 1408.5701904296875, 1397.9803036714948, 1379.1919869723888, 1375.2624835192134, 1358.327565999396, 1352.011373272424, 1346.9070047555413, 1339.7339027924002, 1330.0520468087286, 1312.743508904661, 1305.8719952864433, 1301.0258253901732], 'acc': [0.6227368068338555, 0.8897707237658621, 0.9047562028715003, 0.9148851220194536, 0.9217139556616148, 0.9263179686479953, 0.9287907972210792, 0.9314029325127993, 0.9330311960536941, 0.9347298543577781, 0.9362283995874544, 0.9370263669792802, 0.9380699118621919, 0.9392520715580387, 0.9397423620832571, 0.9402460249513244, 0.9412261241774397, 0.9412892414054039, 0.9419974466613062, 0.9426505640680582, 0.9430294941908963, 0.9431799261561243, 0.9437847800605992, 0.9441071663124382, 0.9444060201632947, 0.9448489016343892, 0.9452462761944973, 0.945421870570204, 0.9453788868880396, 0.9457051923492407, 0.9462845127936937, 0.946388393152144, 0.9465684119805173, 0.9468400541794239, 0.9469784153479934, 0.9473011528271251, 0.947563873462096, 0.9475110182303419, 0.9476516498911696, 0.947868328678693, 0.9481835359779653, 0.9483522717631435, 0.9484024633900702], 'mDice': [0.14095207477638044, 0.41576690841713965, 0.5096405982189792, 0.5601161467171781, 0.5944476558313173, 0.6186617037821119, 0.6335183001217273, 0.6488783273343891, 0.6585806501217377, 0.6696413186719382, 0.678363746178272, 0.6842232076147744, 0.690400758586179, 0.6978743472999291, 0.7016260200597566, 0.7065109887954149, 0.7116585990494102, 0.713142188419973, 0.7179282298546801, 0.7219494897803981, 0.7248187763212457, 0.7271879010285994, 0.7304592622206669, 0.7317997926987272, 0.7354152399105031, 0.738034698977874, 0.7402669752473796, 0.7423431221542961, 0.7428246140020395, 0.7456560436415723, 0.7492337720298068, 0.7497161251859259, 0.7513475958290232, 0.7541867336809509, 0.754812124528383, 0.7573192656235541, 0.7582689653547002, 0.7591051089871659, 0.7602176627879292, 0.7617559151105254, 0.7643723149669177, 0.7654212710713522, 0.7661652302659268]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 30)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 31)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   5600        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 13)   793         dropout_6[0][0]                  
==================================================================================================
Total params: 229,653
Trainable params: 54,913
Non-trainable params: 174,740
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 35s - loss: 8806.3989 - acc: 0.8209 - mDice: 0.3040 - val_loss: 3394.0954 - val_acc: 0.9230 - val_mDice: 0.4884

Epoch 00001: val_mDice improved from -inf to 0.48837, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 24s - loss: 2623.7177 - acc: 0.9208 - mDice: 0.5901 - val_loss: 2305.7688 - val_acc: 0.9482 - val_mDice: 0.6006

Epoch 00002: val_mDice improved from 0.48837 to 0.60061, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 24s - loss: 2229.4478 - acc: 0.9368 - mDice: 0.6377 - val_loss: 2097.7121 - val_acc: 0.9533 - val_mDice: 0.6261

Epoch 00003: val_mDice improved from 0.60061 to 0.62609, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 24s - loss: 2057.5439 - acc: 0.9426 - mDice: 0.6595 - val_loss: 2168.7730 - val_acc: 0.9550 - val_mDice: 0.6238

Epoch 00004: val_mDice did not improve from 0.62609
Epoch 5/300
 - 24s - loss: 1938.9242 - acc: 0.9451 - mDice: 0.6749 - val_loss: 2051.4099 - val_acc: 0.9545 - val_mDice: 0.6348

Epoch 00005: val_mDice improved from 0.62609 to 0.63477, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 24s - loss: 1872.6644 - acc: 0.9465 - mDice: 0.6838 - val_loss: 2092.4036 - val_acc: 0.9542 - val_mDice: 0.6275

Epoch 00006: val_mDice did not improve from 0.63477
Epoch 7/300
 - 22s - loss: 1811.7244 - acc: 0.9475 - mDice: 0.6922 - val_loss: 2095.7689 - val_acc: 0.9536 - val_mDice: 0.6291

Epoch 00007: val_mDice did not improve from 0.63477
Epoch 8/300
 - 24s - loss: 1756.5138 - acc: 0.9484 - mDice: 0.6997 - val_loss: 2193.0601 - val_acc: 0.9547 - val_mDice: 0.6183

Epoch 00008: val_mDice did not improve from 0.63477
Epoch 9/300
 - 22s - loss: 1709.8635 - acc: 0.9492 - mDice: 0.7062 - val_loss: 2108.0618 - val_acc: 0.9508 - val_mDice: 0.6233

Epoch 00009: val_mDice did not improve from 0.63477
Epoch 10/300
 - 22s - loss: 1673.9560 - acc: 0.9497 - mDice: 0.7113 - val_loss: 2046.9114 - val_acc: 0.9535 - val_mDice: 0.6317

Epoch 00010: val_mDice did not improve from 0.63477
Epoch 11/300
 - 22s - loss: 1654.8595 - acc: 0.9501 - mDice: 0.7142 - val_loss: 2211.3172 - val_acc: 0.9548 - val_mDice: 0.6137

Epoch 00011: val_mDice did not improve from 0.63477
Epoch 12/300
 - 22s - loss: 1626.9532 - acc: 0.9505 - mDice: 0.7181 - val_loss: 2102.4658 - val_acc: 0.9529 - val_mDice: 0.6264

Epoch 00012: val_mDice did not improve from 0.63477
Epoch 13/300
 - 21s - loss: 1597.4724 - acc: 0.9510 - mDice: 0.7224 - val_loss: 2120.5711 - val_acc: 0.9507 - val_mDice: 0.6243

Epoch 00013: val_mDice did not improve from 0.63477
Epoch 14/300
 - 22s - loss: 1590.5183 - acc: 0.9510 - mDice: 0.7234 - val_loss: 2107.6226 - val_acc: 0.9543 - val_mDice: 0.6325

Epoch 00014: val_mDice did not improve from 0.63477
Epoch 15/300
 - 22s - loss: 1554.4864 - acc: 0.9515 - mDice: 0.7285 - val_loss: 2045.2951 - val_acc: 0.9541 - val_mDice: 0.6333

Epoch 00015: val_mDice did not improve from 0.63477
Epoch 16/300
 - 22s - loss: 1535.1158 - acc: 0.9517 - mDice: 0.7314 - val_loss: 2064.3726 - val_acc: 0.9533 - val_mDice: 0.6329

Epoch 00016: val_mDice did not improve from 0.63477
Epoch 17/300
 - 22s - loss: 1543.9052 - acc: 0.9516 - mDice: 0.7302 - val_loss: 2047.0058 - val_acc: 0.9561 - val_mDice: 0.6337

Epoch 00017: val_mDice did not improve from 0.63477
Epoch 18/300
 - 21s - loss: 1533.8512 - acc: 0.9516 - mDice: 0.7316 - val_loss: 2037.3322 - val_acc: 0.9539 - val_mDice: 0.6346

Epoch 00018: val_mDice did not improve from 0.63477
Epoch 19/300
 - 22s - loss: 1494.1642 - acc: 0.9523 - mDice: 0.7373 - val_loss: 2150.4652 - val_acc: 0.9566 - val_mDice: 0.6219

Epoch 00019: val_mDice did not improve from 0.63477
Epoch 20/300
 - 23s - loss: 1482.1494 - acc: 0.9525 - mDice: 0.7391 - val_loss: 2303.5351 - val_acc: 0.9539 - val_mDice: 0.6005

Epoch 00020: val_mDice did not improve from 0.63477
Epoch 21/300
 - 22s - loss: 1476.3665 - acc: 0.9527 - mDice: 0.7402 - val_loss: 2079.6477 - val_acc: 0.9553 - val_mDice: 0.6287

Epoch 00021: val_mDice did not improve from 0.63477
Epoch 22/300
 - 23s - loss: 1455.6763 - acc: 0.9529 - mDice: 0.7431 - val_loss: 2196.8640 - val_acc: 0.9545 - val_mDice: 0.6148

Epoch 00022: val_mDice did not improve from 0.63477
Epoch 23/300
 - 22s - loss: 1445.6205 - acc: 0.9530 - mDice: 0.7446 - val_loss: 2089.3804 - val_acc: 0.9552 - val_mDice: 0.6265

Epoch 00023: val_mDice did not improve from 0.63477
Epoch 24/300
 - 22s - loss: 1423.0518 - acc: 0.9533 - mDice: 0.7479 - val_loss: 2027.6467 - val_acc: 0.9542 - val_mDice: 0.6355

Epoch 00024: val_mDice improved from 0.63477 to 0.63548, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 25/300
 - 22s - loss: 1423.1541 - acc: 0.9533 - mDice: 0.7479 - val_loss: 2102.3344 - val_acc: 0.9542 - val_mDice: 0.6276

Epoch 00025: val_mDice did not improve from 0.63548
Epoch 26/300
 - 22s - loss: 1412.6303 - acc: 0.9535 - mDice: 0.7496 - val_loss: 2137.3456 - val_acc: 0.9555 - val_mDice: 0.6227

Epoch 00026: val_mDice did not improve from 0.63548
Epoch 27/300
 - 22s - loss: 1403.5291 - acc: 0.9536 - mDice: 0.7509 - val_loss: 2007.7654 - val_acc: 0.9558 - val_mDice: 0.6368

Epoch 00027: val_mDice improved from 0.63548 to 0.63680, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 28/300
 - 21s - loss: 1396.9456 - acc: 0.9538 - mDice: 0.7520 - val_loss: 2147.1009 - val_acc: 0.9532 - val_mDice: 0.6218

Epoch 00028: val_mDice did not improve from 0.63680
Epoch 29/300
 - 20s - loss: 1397.9887 - acc: 0.9537 - mDice: 0.7518 - val_loss: 2109.3362 - val_acc: 0.9559 - val_mDice: 0.6252

Epoch 00029: val_mDice did not improve from 0.63680
Epoch 30/300
 - 22s - loss: 1382.9436 - acc: 0.9539 - mDice: 0.7540 - val_loss: 2038.6384 - val_acc: 0.9558 - val_mDice: 0.6347

Epoch 00030: val_mDice did not improve from 0.63680
Epoch 31/300
 - 22s - loss: 1374.6624 - acc: 0.9540 - mDice: 0.7553 - val_loss: 2036.5868 - val_acc: 0.9549 - val_mDice: 0.6334

Epoch 00031: val_mDice did not improve from 0.63680
Epoch 32/300
 - 20s - loss: 1367.6845 - acc: 0.9541 - mDice: 0.7564 - val_loss: 1967.2881 - val_acc: 0.9547 - val_mDice: 0.6427

Epoch 00032: val_mDice improved from 0.63680 to 0.64274, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 33/300
 - 21s - loss: 1356.9139 - acc: 0.9543 - mDice: 0.7580 - val_loss: 2126.7352 - val_acc: 0.9536 - val_mDice: 0.6226

Epoch 00033: val_mDice did not improve from 0.64274
Epoch 34/300
 - 21s - loss: 1357.5066 - acc: 0.9543 - mDice: 0.7579 - val_loss: 2037.3079 - val_acc: 0.9544 - val_mDice: 0.6328

Epoch 00034: val_mDice did not improve from 0.64274
Epoch 35/300
 - 21s - loss: 1349.5485 - acc: 0.9544 - mDice: 0.7591 - val_loss: 2068.1885 - val_acc: 0.9566 - val_mDice: 0.6304

Epoch 00035: val_mDice did not improve from 0.64274
Epoch 36/300
 - 21s - loss: 1336.0969 - acc: 0.9546 - mDice: 0.7611 - val_loss: 2005.3453 - val_acc: 0.9549 - val_mDice: 0.6380

Epoch 00036: val_mDice did not improve from 0.64274
Epoch 37/300
 - 22s - loss: 1334.8871 - acc: 0.9546 - mDice: 0.7614 - val_loss: 2098.6526 - val_acc: 0.9549 - val_mDice: 0.6257

Epoch 00037: val_mDice did not improve from 0.64274
Epoch 38/300
 - 21s - loss: 1328.3397 - acc: 0.9548 - mDice: 0.7624 - val_loss: 2033.3599 - val_acc: 0.9527 - val_mDice: 0.6331

Epoch 00038: val_mDice did not improve from 0.64274
Epoch 39/300
 - 21s - loss: 1332.0966 - acc: 0.9547 - mDice: 0.7619 - val_loss: 2124.0529 - val_acc: 0.9555 - val_mDice: 0.6243

Epoch 00039: val_mDice did not improve from 0.64274
Epoch 40/300
 - 22s - loss: 1316.7333 - acc: 0.9550 - mDice: 0.7641 - val_loss: 2082.0118 - val_acc: 0.9551 - val_mDice: 0.6271

Epoch 00040: val_mDice did not improve from 0.64274
Epoch 41/300
 - 20s - loss: 1313.4782 - acc: 0.9550 - mDice: 0.7646 - val_loss: 2219.7758 - val_acc: 0.9545 - val_mDice: 0.6103

Epoch 00041: val_mDice did not improve from 0.64274
Epoch 42/300
 - 21s - loss: 1309.8986 - acc: 0.9550 - mDice: 0.7652 - val_loss: 2107.4129 - val_acc: 0.9550 - val_mDice: 0.6241

Epoch 00042: val_mDice did not improve from 0.64274
Epoch 43/300
 - 22s - loss: 1307.0157 - acc: 0.9551 - mDice: 0.7657 - val_loss: 2101.3848 - val_acc: 0.9552 - val_mDice: 0.6240

Epoch 00043: val_mDice did not improve from 0.64274
Epoch 44/300
 - 21s - loss: 1303.5137 - acc: 0.9551 - mDice: 0.7663 - val_loss: 2046.3454 - val_acc: 0.9545 - val_mDice: 0.6333

Epoch 00044: val_mDice did not improve from 0.64274
Epoch 45/300
 - 21s - loss: 1301.4974 - acc: 0.9552 - mDice: 0.7665 - val_loss: 2091.3214 - val_acc: 0.9544 - val_mDice: 0.6272

Epoch 00045: val_mDice did not improve from 0.64274
Epoch 46/300
 - 21s - loss: 1293.8091 - acc: 0.9553 - mDice: 0.7677 - val_loss: 2028.5508 - val_acc: 0.9537 - val_mDice: 0.6353

Epoch 00046: val_mDice did not improve from 0.64274
Epoch 47/300
 - 21s - loss: 1293.2873 - acc: 0.9553 - mDice: 0.7678 - val_loss: 1953.5697 - val_acc: 0.9539 - val_mDice: 0.6436

Epoch 00047: val_mDice improved from 0.64274 to 0.64358, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 48/300
 - 21s - loss: 1282.8387 - acc: 0.9554 - mDice: 0.7694 - val_loss: 2016.7163 - val_acc: 0.9550 - val_mDice: 0.6358

Epoch 00048: val_mDice did not improve from 0.64358
Epoch 49/300
 - 22s - loss: 1281.4946 - acc: 0.9555 - mDice: 0.7697 - val_loss: 2169.9796 - val_acc: 0.9551 - val_mDice: 0.6176

Epoch 00049: val_mDice did not improve from 0.64358
Epoch 50/300
 - 21s - loss: 1273.5535 - acc: 0.9556 - mDice: 0.7709 - val_loss: 2057.2771 - val_acc: 0.9554 - val_mDice: 0.6314

Epoch 00050: val_mDice did not improve from 0.64358
Epoch 51/300
 - 21s - loss: 1276.9155 - acc: 0.9556 - mDice: 0.7704 - val_loss: 2070.1377 - val_acc: 0.9549 - val_mDice: 0.6275

Epoch 00051: val_mDice did not improve from 0.64358
Epoch 52/300
 - 21s - loss: 1268.2435 - acc: 0.9557 - mDice: 0.7717 - val_loss: 2048.4466 - val_acc: 0.9552 - val_mDice: 0.6308

Epoch 00052: val_mDice did not improve from 0.64358
Epoch 53/300
 - 21s - loss: 1266.7454 - acc: 0.9557 - mDice: 0.7719 - val_loss: 2035.9016 - val_acc: 0.9554 - val_mDice: 0.6333

Epoch 00053: val_mDice did not improve from 0.64358
Epoch 54/300
 - 21s - loss: 1262.1422 - acc: 0.9558 - mDice: 0.7726 - val_loss: 2216.3114 - val_acc: 0.9552 - val_mDice: 0.6119

Epoch 00054: val_mDice did not improve from 0.64358
Epoch 55/300
 - 21s - loss: 1253.3261 - acc: 0.9559 - mDice: 0.7740 - val_loss: 2065.5468 - val_acc: 0.9534 - val_mDice: 0.6290

Epoch 00055: val_mDice did not improve from 0.64358
Epoch 56/300
 - 20s - loss: 1252.5691 - acc: 0.9560 - mDice: 0.7741 - val_loss: 2108.8468 - val_acc: 0.9544 - val_mDice: 0.6237

Epoch 00056: val_mDice did not improve from 0.64358
Epoch 57/300
 - 21s - loss: 1248.0148 - acc: 0.9560 - mDice: 0.7748 - val_loss: 2120.3187 - val_acc: 0.9542 - val_mDice: 0.6223

Epoch 00057: val_mDice did not improve from 0.64358
Epoch 58/300
 - 21s - loss: 1254.0389 - acc: 0.9560 - mDice: 0.7740 - val_loss: 2111.6339 - val_acc: 0.9542 - val_mDice: 0.6240

Epoch 00058: val_mDice did not improve from 0.64358
Epoch 59/300
 - 20s - loss: 1246.9607 - acc: 0.9560 - mDice: 0.7750 - val_loss: 2091.7035 - val_acc: 0.9544 - val_mDice: 0.6258

Epoch 00059: val_mDice did not improve from 0.64358
Epoch 60/300
 - 20s - loss: 1243.4607 - acc: 0.9561 - mDice: 0.7756 - val_loss: 2204.0654 - val_acc: 0.9542 - val_mDice: 0.6130

Epoch 00060: val_mDice did not improve from 0.64358
Epoch 61/300
 - 20s - loss: 1245.6749 - acc: 0.9561 - mDice: 0.7752 - val_loss: 2108.3134 - val_acc: 0.9556 - val_mDice: 0.6242

Epoch 00061: val_mDice did not improve from 0.64358
Epoch 62/300
 - 20s - loss: 1241.4471 - acc: 0.9562 - mDice: 0.7759 - val_loss: 2051.9755 - val_acc: 0.9547 - val_mDice: 0.6314

Epoch 00062: val_mDice did not improve from 0.64358
Epoch 63/300
 - 21s - loss: 1234.9451 - acc: 0.9563 - mDice: 0.7770 - val_loss: 2069.8740 - val_acc: 0.9530 - val_mDice: 0.6283

Epoch 00063: val_mDice did not improve from 0.64358
Epoch 64/300
 - 21s - loss: 1234.2052 - acc: 0.9562 - mDice: 0.7770 - val_loss: 2302.0211 - val_acc: 0.9532 - val_mDice: 0.5984

Epoch 00064: val_mDice did not improve from 0.64358
Epoch 65/300
 - 19s - loss: 1229.7495 - acc: 0.9563 - mDice: 0.7777 - val_loss: 2097.9506 - val_acc: 0.9541 - val_mDice: 0.6252

Epoch 00065: val_mDice did not improve from 0.64358
Epoch 66/300
 - 20s - loss: 1230.5744 - acc: 0.9563 - mDice: 0.7775 - val_loss: 2107.0727 - val_acc: 0.9546 - val_mDice: 0.6254

Epoch 00066: val_mDice did not improve from 0.64358
Epoch 67/300
 - 20s - loss: 1219.5186 - acc: 0.9565 - mDice: 0.7794 - val_loss: 2020.0353 - val_acc: 0.9541 - val_mDice: 0.6347

Epoch 00067: val_mDice did not improve from 0.64358
Epoch 68/300
 - 21s - loss: 1231.3031 - acc: 0.9564 - mDice: 0.7776 - val_loss: 2195.2222 - val_acc: 0.9548 - val_mDice: 0.6173

Epoch 00068: val_mDice did not improve from 0.64358
Epoch 69/300
 - 22s - loss: 1229.4321 - acc: 0.9563 - mDice: 0.7778 - val_loss: 2065.7727 - val_acc: 0.9554 - val_mDice: 0.6303

Epoch 00069: val_mDice did not improve from 0.64358
Epoch 70/300
 - 21s - loss: 1231.5446 - acc: 0.9564 - mDice: 0.7775 - val_loss: 2021.0144 - val_acc: 0.9548 - val_mDice: 0.6352

Epoch 00070: val_mDice did not improve from 0.64358
Epoch 71/300
 - 21s - loss: 1222.9429 - acc: 0.9565 - mDice: 0.7788 - val_loss: 2045.8896 - val_acc: 0.9551 - val_mDice: 0.6312

Epoch 00071: val_mDice did not improve from 0.64358
Epoch 72/300
 - 20s - loss: 1218.5727 - acc: 0.9565 - mDice: 0.7795 - val_loss: 2186.3476 - val_acc: 0.9556 - val_mDice: 0.6171

Epoch 00072: val_mDice did not improve from 0.64358
Epoch 73/300
 - 20s - loss: 1218.7098 - acc: 0.9565 - mDice: 0.7794 - val_loss: 2154.1414 - val_acc: 0.9552 - val_mDice: 0.6193

Epoch 00073: val_mDice did not improve from 0.64358
Epoch 74/300
 - 21s - loss: 1217.6863 - acc: 0.9565 - mDice: 0.7797 - val_loss: 2034.2687 - val_acc: 0.9556 - val_mDice: 0.6333

Epoch 00074: val_mDice did not improve from 0.64358
Epoch 75/300
 - 21s - loss: 1207.5361 - acc: 0.9567 - mDice: 0.7812 - val_loss: 2157.0189 - val_acc: 0.9551 - val_mDice: 0.6184

Epoch 00075: val_mDice did not improve from 0.64358
Epoch 76/300
 - 20s - loss: 1213.0043 - acc: 0.9566 - mDice: 0.7803 - val_loss: 2121.5321 - val_acc: 0.9561 - val_mDice: 0.6237

Epoch 00076: val_mDice did not improve from 0.64358
Epoch 77/300
 - 20s - loss: 1212.4717 - acc: 0.9567 - mDice: 0.7805 - val_loss: 2096.6205 - val_acc: 0.9557 - val_mDice: 0.6260

Epoch 00077: val_mDice did not improve from 0.64358
Restoring model weights from the end of the best epoch
Epoch 00077: early stopping
{'val_loss': [3394.0953635103874, 2305.7687906446404, 2097.7121391083274, 2168.7729833166027, 2051.4099407515714, 2092.4035876396647, 2095.7688520207753, 2193.060139064682, 2108.061843957315, 2046.9114124148919, 2211.3172464210893, 2102.465832587727, 2120.571085839298, 2107.6225817802897, 2045.2951182786312, 2064.3725640494063, 2047.0058020906076, 2037.3321553661838, 2150.4651983676677, 2303.5351016934355, 2079.6476818915853, 2196.8639904853353, 2089.380361546351, 2027.6466971456005, 2102.334370362692, 2137.3455817366444, 2007.7654476911662, 2147.100941919082, 2109.336170729312, 2038.6383827252096, 2036.5867681236907, 1967.288100940555, 2126.7351783454087, 2037.3078531446404, 2068.1884942933834, 2005.3452816755412, 2098.6526479028457, 2033.3598905595322, 2124.0528530355273, 2082.0117514839385, 2219.775762973551, 2107.4128581638442, 2101.384827001135, 2046.34536760213, 2091.3213968117143, 2028.5507512438896, 1953.5697382921612, 2016.7162881350384, 2169.9795712945183, 2057.2770832424058, 2070.1376980403284, 2048.446595943174, 2035.9015895054993, 2216.3113993213165, 2065.5467686147, 2108.846817442825, 2120.3187262678944, 2111.6338708973462, 2091.7034796176677, 2204.0653983174757, 2108.3134192781076, 2051.975455001746, 2069.8739961592178, 2302.0211038429643, 2097.9506153980446, 2107.0726843466305, 2020.0353444701466, 2195.2222170696577, 2065.7726832554995, 2021.0144479421265, 2045.8896484375, 2186.347615332577, 2154.141368333188, 2034.2687429076466, 2157.018910669082, 2121.5321024463165, 2096.6204977195357], 'val_acc': [0.9229921974949331, 0.9481731936252317, 0.9532618868950359, 0.9549684497897185, 0.954484959221419, 0.9542246644057375, 0.9536316954223804, 0.9547060341808383, 0.95079914917493, 0.9535242745330214, 0.9548382695826738, 0.9528693396951899, 0.9507392215329176, 0.9543011135229186, 0.9541048111196336, 0.9532536035143463, 0.9561378033467511, 0.9539292108413228, 0.9566233431160783, 0.953861050099634, 0.9552638630627254, 0.9545139047686614, 0.9551791788479469, 0.9542081319420032, 0.9541936586689017, 0.9555283421910675, 0.955759726423125, 0.9532453587601305, 0.9558651124298906, 0.9558051811250229, 0.9549498358252329, 0.954722565978599, 0.953555251300002, 0.9543837485366693, 0.956584070647895, 0.954869276651457, 0.9549229601242023, 0.9526875105650066, 0.9554808372891815, 0.9551171970101042, 0.9545097677401324, 0.9550345170431297, 0.955156432516748, 0.9544766888272163, 0.9543651249155652, 0.9536853975423888, 0.953889941370021, 0.9549952935240122, 0.9551047812627015, 0.9553506574151236, 0.9549374400570406, 0.9551833271980286, 0.9554167726186401, 0.9551667854106626, 0.9533631242187329, 0.9544250429009592, 0.9541936466813753, 0.9541564703653644, 0.9543568728356387, 0.9541730081568883, 0.9555985684501392, 0.9546771192683854, 0.9529788201081686, 0.953179251881285, 0.9541048374255943, 0.9546337440693179, 0.9540511229850727, 0.9547948677446589, 0.9553857831981595, 0.9548444747924805, 0.9551068527738475, 0.9555737759147942, 0.955181242034422, 0.9555965265748221, 0.9551151148433792, 0.9560696309505228, 0.9556564042688082], 'val_mDice': [0.48836572176917303, 0.600607976234159, 0.626092848498062, 0.6237995751077237, 0.6347656303277894, 0.6274795498927879, 0.6291097645653027, 0.6182546342551375, 0.6233495746910905, 0.6316562145115943, 0.6137103088741196, 0.6264396150018916, 0.6242725343011611, 0.6325179351774673, 0.6333232248961592, 0.6329403070098195, 0.6337202993851134, 0.6346400276908661, 0.6219051147306431, 0.6004816889762878, 0.6286685127119779, 0.6147565864983884, 0.6265312772889376, 0.6354757517409724, 0.6275666855566995, 0.6227340225400871, 0.636795395579418, 0.6217601419161152, 0.6252119701001897, 0.6346574142658511, 0.6333675630931748, 0.6427369830328659, 0.6226160319823792, 0.6327752847245286, 0.6304028906635732, 0.6379904407362699, 0.6257008993425849, 0.6330895443868371, 0.6242757775930053, 0.6270962713816979, 0.6103091726089989, 0.624095379973257, 0.6240135744297305, 0.6332830417089622, 0.6271540802284326, 0.6352605000554516, 0.6435820893202414, 0.6358445393306583, 0.6175519557638541, 0.6313740710972408, 0.6274593039597879, 0.6308145116827342, 0.6333455656493843, 0.6118511054768908, 0.6289884714440926, 0.6236775500814342, 0.6223280060224693, 0.6239792661293925, 0.6257908570699852, 0.6129809424863847, 0.6242054527698282, 0.6313528012297007, 0.6283490917536133, 0.5984193396301909, 0.6251635404938426, 0.6253854842159335, 0.6347384086534298, 0.6172699675213691, 0.6302993230979536, 0.6352123281809204, 0.6311941786185323, 0.61711916643814, 0.6192786926663788, 0.6332537828211012, 0.6183967713537163, 0.6237448244121487, 0.6259746208537225], 'loss': [8806.39891946532, 2623.717728873625, 2229.447765820089, 2057.543919483669, 1938.9242349905837, 1872.6643534516413, 1811.7244287659857, 1756.5137774241684, 1709.8634586944006, 1673.9560294038336, 1654.8595036654735, 1626.9531859587003, 1597.4724421732035, 1590.5182611729206, 1554.4864453420187, 1535.1158487986754, 1543.9052118039924, 1533.8511501628261, 1494.1641804350402, 1482.1493877283947, 1476.3665347186823, 1455.676263584303, 1445.6205465710375, 1423.0518234848787, 1423.1541157573872, 1412.6302869389644, 1403.529132118971, 1396.9455533829346, 1397.9886620740058, 1382.9435753199823, 1374.6624156643795, 1367.6845398830126, 1356.9139224957696, 1357.5066422844277, 1349.5485021033244, 1336.0969284420783, 1334.8871468371096, 1328.3396675488405, 1332.0965726557502, 1316.7333268813334, 1313.4781781349247, 1309.8986201234636, 1307.0157338999356, 1303.513704036382, 1301.497439132914, 1293.8090842218805, 1293.287306192686, 1282.83874661639, 1281.4945843855894, 1273.553529168349, 1276.9154754500719, 1268.2435475990317, 1266.745431155721, 1262.1422068679665, 1253.3260549903987, 1252.5690593396414, 1248.0147718673995, 1254.0388766454394, 1246.9607060444225, 1243.4607418590717, 1245.6749053767262, 1241.4470938449915, 1234.945134646726, 1234.205180968291, 1229.7495179283067, 1230.5743762460334, 1219.5185585801075, 1231.3031482047281, 1229.4321335434724, 1231.5445679269399, 1222.9428634946885, 1218.5726893740627, 1218.7097594692948, 1217.6862984474405, 1207.5361283880245, 1213.0042574223748, 1212.4716554675692], 'acc': [0.8209302633307701, 0.9207555663286358, 0.9368264186772495, 0.9426303641948427, 0.9451297306331451, 0.946512541845729, 0.9475386441257108, 0.9483718656421026, 0.9491981402811327, 0.9496844233487999, 0.950109877268101, 0.9504654022689141, 0.9509585300020893, 0.9510425802448672, 0.951515085754568, 0.951703832408038, 0.9515754098979472, 0.9516146648625495, 0.9523226682490938, 0.9524873457964674, 0.9526533748087985, 0.9528664591707025, 0.9529726444671801, 0.9532544837655809, 0.9532690303439013, 0.9534722779105025, 0.9535717407795256, 0.9537667087477333, 0.9536621776724893, 0.9538730984809034, 0.9540058510812901, 0.9540502642937251, 0.9542941830593363, 0.9543131551194065, 0.9543862291381195, 0.954577418961989, 0.9546359876851152, 0.9547552662856387, 0.9547186677612113, 0.9549539249860464, 0.9549593030968156, 0.9550275435427437, 0.9551197128594295, 0.9551085942704773, 0.955210673491567, 0.9553333727481493, 0.9553428810053509, 0.9554492118675317, 0.955508548666349, 0.9555948971013969, 0.9555670188101903, 0.9556726017202676, 0.9557417283734169, 0.9558318042721365, 0.955928644332275, 0.9559504785482403, 0.9560413769202895, 0.9559858284785554, 0.9560043362190596, 0.9561154801149162, 0.9560511658072348, 0.9562388677027261, 0.9562766144695213, 0.9561685936674691, 0.9563058805903295, 0.9563107322188323, 0.9564731764699904, 0.9563959347585611, 0.9563069080554623, 0.9563503907881339, 0.9565070161541058, 0.9564949306850372, 0.9565360353965722, 0.9565004888985076, 0.9566589439754737, 0.9566120937572936, 0.9566690135700732], 'mDice': [0.304036715556435, 0.5900786657308962, 0.6376830788974337, 0.6594724297283275, 0.6749030951548295, 0.6838180155582947, 0.6921659830991534, 0.6997391985013435, 0.7061701131849973, 0.7113306670853479, 0.7141733332518093, 0.7181080913116493, 0.7223834828849738, 0.7234046860533558, 0.7285330829702946, 0.731420445984975, 0.7302350740625957, 0.7316152473451992, 0.7373279983535986, 0.7391025211535652, 0.7402039675091641, 0.7431322264779102, 0.7446089519614794, 0.7479008631270979, 0.7479064648502384, 0.7495653394013797, 0.7509349242033739, 0.7519548058503334, 0.7517539690044813, 0.7539879274805883, 0.7552961217481244, 0.7563535208847779, 0.7579600575682995, 0.7579031894749906, 0.7591073257160514, 0.7611493499838289, 0.7614314233767857, 0.762366234762763, 0.7618677244292359, 0.764124020941409, 0.7646061533559974, 0.7652368825944471, 0.7657079376313988, 0.7662712481668407, 0.7664990751521662, 0.767736099558545, 0.7677520178520149, 0.7694472257630393, 0.7696541802087554, 0.7709275745506685, 0.7704226160113066, 0.7716738729784415, 0.7719435846842579, 0.7726266035670828, 0.7739936886357817, 0.7741360586392426, 0.7748488115755329, 0.7739750334694653, 0.7750194126351663, 0.7755604799741312, 0.7752355296045248, 0.7758643622979068, 0.7769536106332339, 0.7770335017761552, 0.7776533195697289, 0.7775217802798162, 0.7793567492664396, 0.7775516731762028, 0.7778149894701682, 0.7774964322659985, 0.778826507729426, 0.7795006465784612, 0.7794187217553153, 0.7797073508573704, 0.7811697785270402, 0.780314754773625, 0.7804955752721364]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.36s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.12s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.92s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:52,  1.88s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:18,  1.76s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:15,  1.76s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:54,  1.69s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:15,  1.77s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<07:52,  1.69s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:13,  1.78s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<08:07,  1.76s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:36,  1.87s/it]predicting train subjects:   4%|▎         | 10/285 [00:18<08:53,  1.94s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:26,  1.85s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:47,  1.93s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:22,  1.85s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<08:29,  1.88s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:42,  1.94s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<08:57,  2.00s/it]predicting train subjects:   6%|▌         | 17/285 [00:31<08:37,  1.93s/it]predicting train subjects:   6%|▋         | 18/285 [00:33<08:35,  1.93s/it]predicting train subjects:   7%|▋         | 19/285 [00:35<08:21,  1.89s/it]predicting train subjects:   7%|▋         | 20/285 [00:36<08:17,  1.88s/it]predicting train subjects:   7%|▋         | 21/285 [00:39<08:35,  1.95s/it]predicting train subjects:   8%|▊         | 22/285 [00:40<08:11,  1.87s/it]predicting train subjects:   8%|▊         | 23/285 [00:42<08:09,  1.87s/it]predicting train subjects:   8%|▊         | 24/285 [00:44<07:49,  1.80s/it]predicting train subjects:   9%|▉         | 25/285 [00:46<08:13,  1.90s/it]predicting train subjects:   9%|▉         | 26/285 [00:48<08:30,  1.97s/it]predicting train subjects:   9%|▉         | 27/285 [00:50<08:05,  1.88s/it]predicting train subjects:  10%|▉         | 28/285 [00:52<08:07,  1.90s/it]predicting train subjects:  10%|█         | 29/285 [00:54<08:09,  1.91s/it]predicting train subjects:  11%|█         | 30/285 [00:56<08:23,  1.97s/it]predicting train subjects:  11%|█         | 31/285 [00:58<08:28,  2.00s/it]predicting train subjects:  11%|█         | 32/285 [01:00<08:06,  1.92s/it]predicting train subjects:  12%|█▏        | 33/285 [01:01<07:59,  1.90s/it]predicting train subjects:  12%|█▏        | 34/285 [01:03<07:57,  1.90s/it]predicting train subjects:  12%|█▏        | 35/285 [01:05<08:13,  1.97s/it]predicting train subjects:  13%|█▎        | 36/285 [01:07<07:50,  1.89s/it]predicting train subjects:  13%|█▎        | 37/285 [01:09<07:52,  1.90s/it]predicting train subjects:  13%|█▎        | 38/285 [01:11<08:07,  1.97s/it]predicting train subjects:  14%|█▎        | 39/285 [01:13<07:50,  1.91s/it]predicting train subjects:  14%|█▍        | 40/285 [01:15<07:49,  1.92s/it]predicting train subjects:  14%|█▍        | 41/285 [01:17<07:37,  1.87s/it]predicting train subjects:  15%|█▍        | 42/285 [01:18<07:24,  1.83s/it]predicting train subjects:  15%|█▌        | 43/285 [01:20<07:36,  1.89s/it]predicting train subjects:  15%|█▌        | 44/285 [01:23<08:01,  2.00s/it]predicting train subjects:  16%|█▌        | 45/285 [01:24<07:41,  1.92s/it]predicting train subjects:  16%|█▌        | 46/285 [01:27<07:56,  1.99s/it]predicting train subjects:  16%|█▋        | 47/285 [01:28<07:35,  1.91s/it]predicting train subjects:  17%|█▋        | 48/285 [01:30<07:35,  1.92s/it]predicting train subjects:  17%|█▋        | 49/285 [01:32<07:47,  1.98s/it]predicting train subjects:  18%|█▊        | 50/285 [01:34<07:38,  1.95s/it]predicting train subjects:  18%|█▊        | 51/285 [01:36<07:56,  2.04s/it]predicting train subjects:  18%|█▊        | 52/285 [01:38<07:29,  1.93s/it]predicting train subjects:  19%|█▊        | 53/285 [01:40<07:27,  1.93s/it]predicting train subjects:  19%|█▉        | 54/285 [01:42<07:39,  1.99s/it]predicting train subjects:  19%|█▉        | 55/285 [01:44<07:23,  1.93s/it]predicting train subjects:  20%|█▉        | 56/285 [01:46<07:19,  1.92s/it]predicting train subjects:  20%|██        | 57/285 [01:48<07:09,  1.88s/it]predicting train subjects:  20%|██        | 58/285 [01:50<07:09,  1.89s/it]predicting train subjects:  21%|██        | 59/285 [01:52<07:25,  1.97s/it]predicting train subjects:  21%|██        | 60/285 [01:54<07:39,  2.04s/it]predicting train subjects:  21%|██▏       | 61/285 [01:56<07:15,  1.94s/it]predicting train subjects:  22%|██▏       | 62/285 [01:58<07:09,  1.93s/it]predicting train subjects:  22%|██▏       | 63/285 [01:59<07:06,  1.92s/it]predicting train subjects:  22%|██▏       | 64/285 [02:01<06:58,  1.89s/it]predicting train subjects:  23%|██▎       | 65/285 [02:03<07:04,  1.93s/it]predicting train subjects:  23%|██▎       | 66/285 [02:05<07:00,  1.92s/it]predicting train subjects:  24%|██▎       | 67/285 [02:07<06:58,  1.92s/it]predicting train subjects:  24%|██▍       | 68/285 [02:09<06:46,  1.87s/it]predicting train subjects:  24%|██▍       | 69/285 [02:11<06:46,  1.88s/it]predicting train subjects:  25%|██▍       | 70/285 [02:13<06:49,  1.91s/it]predicting train subjects:  25%|██▍       | 71/285 [02:15<06:49,  1.92s/it]predicting train subjects:  25%|██▌       | 72/285 [02:16<06:37,  1.87s/it]predicting train subjects:  26%|██▌       | 73/285 [02:18<06:43,  1.90s/it]predicting train subjects:  26%|██▌       | 74/285 [02:20<06:40,  1.90s/it]predicting train subjects:  26%|██▋       | 75/285 [02:22<06:43,  1.92s/it]predicting train subjects:  27%|██▋       | 76/285 [02:24<06:41,  1.92s/it]predicting train subjects:  27%|██▋       | 77/285 [02:26<06:28,  1.87s/it]predicting train subjects:  27%|██▋       | 78/285 [02:28<06:19,  1.83s/it]predicting train subjects:  28%|██▊       | 79/285 [02:30<06:22,  1.86s/it]predicting train subjects:  28%|██▊       | 80/285 [02:31<06:21,  1.86s/it]predicting train subjects:  28%|██▊       | 81/285 [02:33<06:10,  1.81s/it]predicting train subjects:  29%|██▉       | 82/285 [02:35<06:11,  1.83s/it]predicting train subjects:  29%|██▉       | 83/285 [02:37<06:00,  1.79s/it]predicting train subjects:  29%|██▉       | 84/285 [02:38<05:53,  1.76s/it]predicting train subjects:  30%|██▉       | 85/285 [02:40<05:54,  1.77s/it]predicting train subjects:  30%|███       | 86/285 [02:42<06:01,  1.82s/it]predicting train subjects:  31%|███       | 87/285 [02:44<06:04,  1.84s/it]predicting train subjects:  31%|███       | 88/285 [02:46<05:56,  1.81s/it]predicting train subjects:  31%|███       | 89/285 [02:48<06:00,  1.84s/it]predicting train subjects:  32%|███▏      | 90/285 [02:50<06:04,  1.87s/it]predicting train subjects:  32%|███▏      | 91/285 [02:51<05:57,  1.84s/it]predicting train subjects:  32%|███▏      | 92/285 [02:53<05:58,  1.86s/it]predicting train subjects:  33%|███▎      | 93/285 [02:55<05:54,  1.85s/it]predicting train subjects:  33%|███▎      | 94/285 [02:57<05:55,  1.86s/it]predicting train subjects:  33%|███▎      | 95/285 [02:59<05:59,  1.89s/it]predicting train subjects:  34%|███▎      | 96/285 [03:01<05:59,  1.90s/it]predicting train subjects:  34%|███▍      | 97/285 [03:03<05:59,  1.91s/it]predicting train subjects:  34%|███▍      | 98/285 [03:05<05:54,  1.90s/it]predicting train subjects:  35%|███▍      | 99/285 [03:07<05:50,  1.88s/it]predicting train subjects:  35%|███▌      | 100/285 [03:09<05:51,  1.90s/it]predicting train subjects:  35%|███▌      | 101/285 [03:10<05:44,  1.87s/it]predicting train subjects:  36%|███▌      | 102/285 [03:12<05:48,  1.90s/it]predicting train subjects:  36%|███▌      | 103/285 [03:14<05:41,  1.87s/it]predicting train subjects:  36%|███▋      | 104/285 [03:16<05:41,  1.89s/it]predicting train subjects:  37%|███▋      | 105/285 [03:18<05:46,  1.93s/it]predicting train subjects:  37%|███▋      | 106/285 [03:20<05:33,  1.87s/it]predicting train subjects:  38%|███▊      | 107/285 [03:22<05:31,  1.86s/it]predicting train subjects:  38%|███▊      | 108/285 [03:23<05:27,  1.85s/it]predicting train subjects:  38%|███▊      | 109/285 [03:25<05:27,  1.86s/it]predicting train subjects:  39%|███▊      | 110/285 [03:27<05:22,  1.84s/it]predicting train subjects:  39%|███▉      | 111/285 [03:29<05:16,  1.82s/it]predicting train subjects:  39%|███▉      | 112/285 [03:31<05:18,  1.84s/it]predicting train subjects:  40%|███▉      | 113/285 [03:33<05:16,  1.84s/it]predicting train subjects:  40%|████      | 114/285 [03:34<05:13,  1.84s/it]predicting train subjects:  40%|████      | 115/285 [03:36<05:20,  1.88s/it]predicting train subjects:  41%|████      | 116/285 [03:38<05:22,  1.91s/it]predicting train subjects:  41%|████      | 117/285 [03:40<05:13,  1.87s/it]predicting train subjects:  41%|████▏     | 118/285 [03:42<05:07,  1.84s/it]predicting train subjects:  42%|████▏     | 119/285 [03:44<05:12,  1.88s/it]predicting train subjects:  42%|████▏     | 120/285 [03:46<05:05,  1.85s/it]predicting train subjects:  42%|████▏     | 121/285 [03:47<04:59,  1.83s/it]predicting train subjects:  43%|████▎     | 122/285 [03:49<04:43,  1.74s/it]predicting train subjects:  43%|████▎     | 123/285 [03:51<04:31,  1.68s/it]predicting train subjects:  44%|████▎     | 124/285 [03:52<04:33,  1.70s/it]predicting train subjects:  44%|████▍     | 125/285 [03:54<04:28,  1.68s/it]predicting train subjects:  44%|████▍     | 126/285 [03:56<04:22,  1.65s/it]predicting train subjects:  45%|████▍     | 127/285 [03:57<04:14,  1.61s/it]predicting train subjects:  45%|████▍     | 128/285 [03:59<04:13,  1.62s/it]predicting train subjects:  45%|████▌     | 129/285 [04:00<04:12,  1.62s/it]predicting train subjects:  46%|████▌     | 130/285 [04:02<04:09,  1.61s/it]predicting train subjects:  46%|████▌     | 131/285 [04:03<04:04,  1.59s/it]predicting train subjects:  46%|████▋     | 132/285 [04:05<04:08,  1.62s/it]predicting train subjects:  47%|████▋     | 133/285 [04:07<04:02,  1.60s/it]predicting train subjects:  47%|████▋     | 134/285 [04:08<04:01,  1.60s/it]predicting train subjects:  47%|████▋     | 135/285 [04:10<03:58,  1.59s/it]predicting train subjects:  48%|████▊     | 136/285 [04:11<03:53,  1.57s/it]predicting train subjects:  48%|████▊     | 137/285 [04:13<03:57,  1.61s/it]predicting train subjects:  48%|████▊     | 138/285 [04:15<03:53,  1.59s/it]predicting train subjects:  49%|████▉     | 139/285 [04:16<03:55,  1.62s/it]predicting train subjects:  49%|████▉     | 140/285 [04:18<04:00,  1.66s/it]predicting train subjects:  49%|████▉     | 141/285 [04:19<03:50,  1.60s/it]predicting train subjects:  50%|████▉     | 142/285 [04:21<03:48,  1.60s/it]predicting train subjects:  50%|█████     | 143/285 [04:23<03:40,  1.55s/it]predicting train subjects:  51%|█████     | 144/285 [04:24<03:44,  1.59s/it]predicting train subjects:  51%|█████     | 145/285 [04:26<03:38,  1.56s/it]predicting train subjects:  51%|█████     | 146/285 [04:27<03:45,  1.63s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:29<03:40,  1.60s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:31<03:49,  1.67s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:32<03:43,  1.65s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:34<03:40,  1.63s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:36<03:41,  1.65s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:37<03:31,  1.59s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:39<03:25,  1.56s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:40<03:29,  1.60s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:42<03:27,  1.59s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:44<03:30,  1.63s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:45<03:24,  1.60s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:47<03:20,  1.58s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:48<03:15,  1.55s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:50<03:13,  1.55s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:51<03:18,  1.60s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:53<03:15,  1.59s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:55<03:16,  1.61s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:56<03:14,  1.61s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:58<03:15,  1.63s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:00<03:15,  1.64s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:01<03:16,  1.67s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:03<03:10,  1.63s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:04<03:06,  1.61s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:06<03:02,  1.59s/it]predicting train subjects:  60%|██████    | 171/285 [05:08<03:03,  1.61s/it]predicting train subjects:  60%|██████    | 172/285 [05:09<03:01,  1.61s/it]predicting train subjects:  61%|██████    | 173/285 [05:11<02:57,  1.59s/it]predicting train subjects:  61%|██████    | 174/285 [05:12<02:54,  1.57s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:14<02:57,  1.62s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:16<03:02,  1.67s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:17<02:55,  1.63s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:19<02:50,  1.59s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:20<02:45,  1.57s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:22<02:52,  1.64s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:24<02:52,  1.66s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:26<02:53,  1.69s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:27<02:46,  1.63s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:29<02:42,  1.61s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:30<02:37,  1.58s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:32<02:47,  1.69s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:34<02:51,  1.75s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:36<02:54,  1.80s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:37<02:41,  1.68s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:39<02:33,  1.62s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:41<02:35,  1.65s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:42<02:35,  1.67s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:44<02:29,  1.62s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:45<02:25,  1.60s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:47<02:23,  1.60s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:49<02:30,  1.70s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:51<02:35,  1.76s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:53<02:35,  1.79s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:54<02:25,  1.69s/it]predicting train subjects:  70%|███████   | 200/285 [05:56<02:22,  1.67s/it]predicting train subjects:  71%|███████   | 201/285 [05:58<02:30,  1.79s/it]predicting train subjects:  71%|███████   | 202/285 [06:00<02:28,  1.79s/it]predicting train subjects:  71%|███████   | 203/285 [06:01<02:27,  1.80s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:03<02:19,  1.72s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:05<02:14,  1.69s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:06<02:11,  1.67s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:08<02:17,  1.76s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:10<02:21,  1.84s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:12<02:21,  1.86s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:14<02:11,  1.76s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:15<02:07,  1.72s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:17<02:08,  1.76s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:19<02:08,  1.79s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:21<02:03,  1.74s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:23<02:05,  1.80s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:24<01:57,  1.70s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:26<02:02,  1.81s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:28<02:05,  1.87s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:30<02:04,  1.88s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:32<01:55,  1.77s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:33<01:50,  1.73s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:35<01:51,  1.77s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:37<01:45,  1.70s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:38<01:41,  1.66s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:40<01:37,  1.63s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:42<01:43,  1.75s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:44<01:45,  1.82s/it]predicting train subjects:  80%|████████  | 228/285 [06:46<01:44,  1.84s/it]predicting train subjects:  80%|████████  | 229/285 [06:47<01:41,  1.82s/it]predicting train subjects:  81%|████████  | 230/285 [06:49<01:36,  1.75s/it]predicting train subjects:  81%|████████  | 231/285 [06:51<01:32,  1.71s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:52<01:31,  1.73s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:54<01:27,  1.68s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:56<01:30,  1.77s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:57<01:24,  1.70s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:59<01:26,  1.77s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:01<01:28,  1.84s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:03<01:28,  1.87s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:05<01:27,  1.89s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:07<01:20,  1.80s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:08<01:16,  1.74s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:10<01:13,  1.70s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:12<01:10,  1.68s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:14<01:12,  1.76s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:15<01:08,  1.71s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:17<01:10,  1.81s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:19<01:11,  1.87s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:21<01:08,  1.86s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:23<01:03,  1.76s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:24<00:59,  1.70s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:26<00:56,  1.65s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:27<00:54,  1.65s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:29<00:57,  1.79s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:31<00:57,  1.85s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:33<00:55,  1.84s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:35<00:50,  1.75s/it]predicting train subjects:  90%|█████████ | 257/285 [07:36<00:48,  1.72s/it]predicting train subjects:  91%|█████████ | 258/285 [07:38<00:48,  1.79s/it]predicting train subjects:  91%|█████████ | 259/285 [07:40<00:46,  1.81s/it]predicting train subjects:  91%|█████████ | 260/285 [07:42<00:43,  1.75s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:44<00:41,  1.73s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:45<00:38,  1.69s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:47<00:36,  1.64s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:49<00:37,  1.76s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:51<00:36,  1.84s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:52<00:33,  1.76s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:54<00:30,  1.69s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:56<00:29,  1.76s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:58<00:28,  1.79s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:59<00:25,  1.73s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:01<00:23,  1.69s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:03<00:22,  1.74s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:04<00:20,  1.69s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:06<00:18,  1.67s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:08<00:17,  1.77s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:10<00:16,  1.81s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:11<00:13,  1.75s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:13<00:11,  1.70s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:15<00:10,  1.75s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:16<00:08,  1.70s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:18<00:06,  1.67s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:20<00:04,  1.62s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:22<00:03,  1.73s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:23<00:01,  1.81s/it]predicting train subjects: 100%|██████████| 285/285 [08:25<00:00,  1.87s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:37,  1.82s/it]Loading train:   1%|          | 2/285 [00:03<07:47,  1.65s/it]Loading train:   1%|          | 3/285 [00:04<07:35,  1.61s/it]Loading train:   1%|▏         | 4/285 [00:05<07:08,  1.53s/it]Loading train:   2%|▏         | 5/285 [00:07<07:30,  1.61s/it]Loading train:   2%|▏         | 6/285 [00:09<07:24,  1.59s/it]Loading train:   2%|▏         | 7/285 [00:10<07:29,  1.62s/it]Loading train:   3%|▎         | 8/285 [00:12<07:22,  1.60s/it]Loading train:   3%|▎         | 9/285 [00:14<07:33,  1.64s/it]Loading train:   4%|▎         | 10/285 [00:15<07:22,  1.61s/it]Loading train:   4%|▍         | 11/285 [00:16<06:33,  1.43s/it]Loading train:   4%|▍         | 12/285 [00:18<06:43,  1.48s/it]Loading train:   5%|▍         | 13/285 [00:19<06:18,  1.39s/it]Loading train:   5%|▍         | 14/285 [00:20<06:13,  1.38s/it]Loading train:   5%|▌         | 15/285 [00:22<06:10,  1.37s/it]Loading train:   6%|▌         | 16/285 [00:23<06:09,  1.37s/it]Loading train:   6%|▌         | 17/285 [00:25<06:15,  1.40s/it]Loading train:   6%|▋         | 18/285 [00:26<06:06,  1.37s/it]Loading train:   7%|▋         | 19/285 [00:27<05:49,  1.32s/it]Loading train:   7%|▋         | 20/285 [00:28<05:32,  1.26s/it]Loading train:   7%|▋         | 21/285 [00:30<05:36,  1.28s/it]Loading train:   8%|▊         | 22/285 [00:31<05:32,  1.26s/it]Loading train:   8%|▊         | 23/285 [00:32<05:21,  1.23s/it]Loading train:   8%|▊         | 24/285 [00:33<05:08,  1.18s/it]Loading train:   9%|▉         | 25/285 [00:34<05:12,  1.20s/it]Loading train:   9%|▉         | 26/285 [00:36<05:18,  1.23s/it]Loading train:   9%|▉         | 27/285 [00:37<05:05,  1.18s/it]Loading train:  10%|▉         | 28/285 [00:38<05:52,  1.37s/it]Loading train:  10%|█         | 29/285 [00:40<05:37,  1.32s/it]Loading train:  11%|█         | 30/285 [00:41<05:32,  1.30s/it]Loading train:  11%|█         | 31/285 [00:42<05:37,  1.33s/it]Loading train:  11%|█         | 32/285 [00:43<05:21,  1.27s/it]Loading train:  12%|█▏        | 33/285 [00:45<05:22,  1.28s/it]Loading train:  12%|█▏        | 34/285 [00:46<05:31,  1.32s/it]Loading train:  12%|█▏        | 35/285 [00:48<05:39,  1.36s/it]Loading train:  13%|█▎        | 36/285 [00:49<05:48,  1.40s/it]Loading train:  13%|█▎        | 37/285 [00:51<05:59,  1.45s/it]Loading train:  13%|█▎        | 38/285 [00:52<05:54,  1.43s/it]Loading train:  14%|█▎        | 39/285 [00:53<05:30,  1.34s/it]Loading train:  14%|█▍        | 40/285 [00:54<05:23,  1.32s/it]Loading train:  14%|█▍        | 41/285 [00:56<05:06,  1.26s/it]Loading train:  15%|█▍        | 42/285 [00:57<05:07,  1.27s/it]Loading train:  15%|█▌        | 43/285 [00:58<04:51,  1.20s/it]Loading train:  15%|█▌        | 44/285 [00:59<04:56,  1.23s/it]Loading train:  16%|█▌        | 45/285 [01:00<04:48,  1.20s/it]Loading train:  16%|█▌        | 46/285 [01:02<04:55,  1.24s/it]Loading train:  16%|█▋        | 47/285 [01:03<04:57,  1.25s/it]Loading train:  17%|█▋        | 48/285 [01:04<04:59,  1.26s/it]Loading train:  17%|█▋        | 49/285 [01:05<04:57,  1.26s/it]Loading train:  18%|█▊        | 50/285 [01:07<04:58,  1.27s/it]Loading train:  18%|█▊        | 51/285 [01:09<05:32,  1.42s/it]Loading train:  18%|█▊        | 52/285 [01:10<05:14,  1.35s/it]Loading train:  19%|█▊        | 53/285 [01:11<05:04,  1.31s/it]Loading train:  19%|█▉        | 54/285 [01:12<04:57,  1.29s/it]Loading train:  19%|█▉        | 55/285 [01:13<04:52,  1.27s/it]Loading train:  20%|█▉        | 56/285 [01:15<04:51,  1.27s/it]Loading train:  20%|██        | 57/285 [01:16<04:45,  1.25s/it]Loading train:  20%|██        | 58/285 [01:17<04:42,  1.25s/it]Loading train:  21%|██        | 59/285 [01:18<04:36,  1.23s/it]Loading train:  21%|██        | 60/285 [01:20<04:48,  1.28s/it]Loading train:  21%|██▏       | 61/285 [01:21<04:51,  1.30s/it]Loading train:  22%|██▏       | 62/285 [01:22<04:47,  1.29s/it]Loading train:  22%|██▏       | 63/285 [01:24<04:41,  1.27s/it]Loading train:  22%|██▏       | 64/285 [01:25<05:02,  1.37s/it]Loading train:  23%|██▎       | 65/285 [01:27<05:19,  1.45s/it]Loading train:  23%|██▎       | 66/285 [01:29<05:52,  1.61s/it]Loading train:  24%|██▎       | 67/285 [01:30<05:19,  1.46s/it]Loading train:  24%|██▍       | 68/285 [01:31<05:06,  1.41s/it]Loading train:  24%|██▍       | 69/285 [01:33<05:10,  1.44s/it]Loading train:  25%|██▍       | 70/285 [01:34<04:55,  1.37s/it]Loading train:  25%|██▍       | 71/285 [01:35<04:48,  1.35s/it]Loading train:  25%|██▌       | 72/285 [01:36<04:34,  1.29s/it]Loading train:  26%|██▌       | 73/285 [01:38<04:53,  1.38s/it]Loading train:  26%|██▌       | 74/285 [01:40<05:15,  1.50s/it]Loading train:  26%|██▋       | 75/285 [01:41<04:46,  1.36s/it]Loading train:  27%|██▋       | 76/285 [01:42<04:57,  1.43s/it]Loading train:  27%|██▋       | 77/285 [01:43<04:34,  1.32s/it]Loading train:  27%|██▋       | 78/285 [01:45<04:31,  1.31s/it]Loading train:  28%|██▊       | 79/285 [01:46<04:36,  1.34s/it]Loading train:  28%|██▊       | 80/285 [01:47<04:30,  1.32s/it]Loading train:  28%|██▊       | 81/285 [01:49<04:58,  1.46s/it]Loading train:  29%|██▉       | 82/285 [01:51<05:09,  1.52s/it]Loading train:  29%|██▉       | 83/285 [01:52<04:40,  1.39s/it]Loading train:  29%|██▉       | 84/285 [01:53<04:22,  1.31s/it]Loading train:  30%|██▉       | 85/285 [01:54<04:19,  1.30s/it]Loading train:  30%|███       | 86/285 [01:56<04:19,  1.30s/it]Loading train:  31%|███       | 87/285 [01:57<04:07,  1.25s/it]Loading train:  31%|███       | 88/285 [01:58<03:47,  1.15s/it]Loading train:  31%|███       | 89/285 [01:59<03:47,  1.16s/it]Loading train:  32%|███▏      | 90/285 [02:00<03:50,  1.18s/it]Loading train:  32%|███▏      | 91/285 [02:01<03:49,  1.18s/it]Loading train:  32%|███▏      | 92/285 [02:02<03:49,  1.19s/it]Loading train:  33%|███▎      | 93/285 [02:04<03:40,  1.15s/it]Loading train:  33%|███▎      | 94/285 [02:05<03:57,  1.24s/it]Loading train:  33%|███▎      | 95/285 [02:06<03:57,  1.25s/it]Loading train:  34%|███▎      | 96/285 [02:07<03:53,  1.23s/it]Loading train:  34%|███▍      | 97/285 [02:09<03:55,  1.25s/it]Loading train:  34%|███▍      | 98/285 [02:10<03:54,  1.26s/it]Loading train:  35%|███▍      | 99/285 [02:11<03:54,  1.26s/it]Loading train:  35%|███▌      | 100/285 [02:13<03:57,  1.28s/it]Loading train:  35%|███▌      | 101/285 [02:14<03:57,  1.29s/it]Loading train:  36%|███▌      | 102/285 [02:15<04:00,  1.31s/it]Loading train:  36%|███▌      | 103/285 [02:17<04:21,  1.44s/it]Loading train:  36%|███▋      | 104/285 [02:18<04:18,  1.43s/it]Loading train:  37%|███▋      | 105/285 [02:20<04:14,  1.41s/it]Loading train:  37%|███▋      | 106/285 [02:21<03:59,  1.34s/it]Loading train:  38%|███▊      | 107/285 [02:22<03:57,  1.33s/it]Loading train:  38%|███▊      | 108/285 [02:23<03:40,  1.24s/it]Loading train:  38%|███▊      | 109/285 [02:25<03:39,  1.24s/it]Loading train:  39%|███▊      | 110/285 [02:26<03:45,  1.29s/it]Loading train:  39%|███▉      | 111/285 [02:27<03:35,  1.24s/it]Loading train:  39%|███▉      | 112/285 [02:29<03:58,  1.38s/it]Loading train:  40%|███▉      | 113/285 [02:31<04:23,  1.53s/it]Loading train:  40%|████      | 114/285 [02:32<04:09,  1.46s/it]Loading train:  40%|████      | 115/285 [02:33<03:57,  1.40s/it]Loading train:  41%|████      | 116/285 [02:35<04:00,  1.42s/it]Loading train:  41%|████      | 117/285 [02:36<03:47,  1.35s/it]Loading train:  41%|████▏     | 118/285 [02:37<03:30,  1.26s/it]Loading train:  42%|████▏     | 119/285 [02:38<03:35,  1.30s/it]Loading train:  42%|████▏     | 120/285 [02:39<03:25,  1.25s/it]Loading train:  42%|████▏     | 121/285 [02:41<03:44,  1.37s/it]Loading train:  43%|████▎     | 122/285 [02:43<03:49,  1.41s/it]Loading train:  43%|████▎     | 123/285 [02:44<03:43,  1.38s/it]Loading train:  44%|████▎     | 124/285 [02:45<03:34,  1.33s/it]Loading train:  44%|████▍     | 125/285 [02:46<03:33,  1.34s/it]Loading train:  44%|████▍     | 126/285 [02:48<03:37,  1.37s/it]Loading train:  45%|████▍     | 127/285 [02:49<03:39,  1.39s/it]Loading train:  45%|████▍     | 128/285 [02:50<03:24,  1.30s/it]Loading train:  45%|████▌     | 129/285 [02:52<03:17,  1.26s/it]Loading train:  46%|████▌     | 130/285 [02:53<03:10,  1.23s/it]Loading train:  46%|████▌     | 131/285 [02:54<03:03,  1.19s/it]Loading train:  46%|████▋     | 132/285 [02:55<03:04,  1.21s/it]Loading train:  47%|████▋     | 133/285 [02:56<02:58,  1.18s/it]Loading train:  47%|████▋     | 134/285 [02:58<03:02,  1.21s/it]Loading train:  47%|████▋     | 135/285 [02:59<02:58,  1.19s/it]Loading train:  48%|████▊     | 136/285 [03:00<02:47,  1.13s/it]Loading train:  48%|████▊     | 137/285 [03:01<02:56,  1.19s/it]Loading train:  48%|████▊     | 138/285 [03:02<02:50,  1.16s/it]Loading train:  49%|████▉     | 139/285 [03:03<02:50,  1.17s/it]Loading train:  49%|████▉     | 140/285 [03:05<02:56,  1.22s/it]Loading train:  49%|████▉     | 141/285 [03:06<02:55,  1.22s/it]Loading train:  50%|████▉     | 142/285 [03:07<02:46,  1.16s/it]Loading train:  50%|█████     | 143/285 [03:08<02:43,  1.15s/it]Loading train:  51%|█████     | 144/285 [03:09<02:43,  1.16s/it]Loading train:  51%|█████     | 145/285 [03:11<03:10,  1.36s/it]Loading train:  51%|█████     | 146/285 [03:12<03:03,  1.32s/it]Loading train:  52%|█████▏    | 147/285 [03:13<03:00,  1.31s/it]Loading train:  52%|█████▏    | 148/285 [03:15<02:58,  1.30s/it]Loading train:  52%|█████▏    | 149/285 [03:16<02:53,  1.28s/it]Loading train:  53%|█████▎    | 150/285 [03:17<02:42,  1.20s/it]Loading train:  53%|█████▎    | 151/285 [03:18<02:41,  1.21s/it]Loading train:  53%|█████▎    | 152/285 [03:19<02:42,  1.22s/it]Loading train:  54%|█████▎    | 153/285 [03:21<02:44,  1.25s/it]Loading train:  54%|█████▍    | 154/285 [03:22<02:42,  1.24s/it]Loading train:  54%|█████▍    | 155/285 [03:23<02:25,  1.12s/it]Loading train:  55%|█████▍    | 156/285 [03:24<02:26,  1.14s/it]Loading train:  55%|█████▌    | 157/285 [03:25<02:24,  1.13s/it]Loading train:  55%|█████▌    | 158/285 [03:26<02:24,  1.14s/it]Loading train:  56%|█████▌    | 159/285 [03:27<02:17,  1.09s/it]Loading train:  56%|█████▌    | 160/285 [03:28<02:06,  1.01s/it]Loading train:  56%|█████▋    | 161/285 [03:29<02:01,  1.02it/s]Loading train:  57%|█████▋    | 162/285 [03:30<01:56,  1.05it/s]Loading train:  57%|█████▋    | 163/285 [03:31<01:53,  1.08it/s]Loading train:  58%|█████▊    | 164/285 [03:32<01:51,  1.09it/s]Loading train:  58%|█████▊    | 165/285 [03:33<01:47,  1.12it/s]Loading train:  58%|█████▊    | 166/285 [03:33<01:47,  1.11it/s]Loading train:  59%|█████▊    | 167/285 [03:34<01:47,  1.10it/s]Loading train:  59%|█████▉    | 168/285 [03:35<01:42,  1.15it/s]Loading train:  59%|█████▉    | 169/285 [03:36<01:39,  1.17it/s]Loading train:  60%|█████▉    | 170/285 [03:37<01:39,  1.16it/s]Loading train:  60%|██████    | 171/285 [03:38<01:35,  1.20it/s]Loading train:  60%|██████    | 172/285 [03:38<01:34,  1.20it/s]Loading train:  61%|██████    | 173/285 [03:39<01:30,  1.24it/s]Loading train:  61%|██████    | 174/285 [03:40<01:29,  1.24it/s]Loading train:  61%|██████▏   | 175/285 [03:41<01:30,  1.21it/s]Loading train:  62%|██████▏   | 176/285 [03:42<01:30,  1.20it/s]Loading train:  62%|██████▏   | 177/285 [03:43<01:28,  1.22it/s]Loading train:  62%|██████▏   | 178/285 [03:43<01:27,  1.22it/s]Loading train:  63%|██████▎   | 179/285 [03:44<01:29,  1.19it/s]Loading train:  63%|██████▎   | 180/285 [03:45<01:31,  1.15it/s]Loading train:  64%|██████▎   | 181/285 [03:46<01:38,  1.05it/s]Loading train:  64%|██████▍   | 182/285 [03:47<01:34,  1.09it/s]Loading train:  64%|██████▍   | 183/285 [03:48<01:34,  1.08it/s]Loading train:  65%|██████▍   | 184/285 [03:49<01:31,  1.11it/s]Loading train:  65%|██████▍   | 185/285 [03:50<01:29,  1.11it/s]Loading train:  65%|██████▌   | 186/285 [03:51<01:28,  1.12it/s]Loading train:  66%|██████▌   | 187/285 [03:52<01:30,  1.08it/s]Loading train:  66%|██████▌   | 188/285 [03:53<01:31,  1.06it/s]Loading train:  66%|██████▋   | 189/285 [03:53<01:25,  1.13it/s]Loading train:  67%|██████▋   | 190/285 [03:54<01:22,  1.15it/s]Loading train:  67%|██████▋   | 191/285 [03:55<01:22,  1.14it/s]Loading train:  67%|██████▋   | 192/285 [03:56<01:21,  1.14it/s]Loading train:  68%|██████▊   | 193/285 [03:57<01:15,  1.22it/s]Loading train:  68%|██████▊   | 194/285 [03:58<01:15,  1.21it/s]Loading train:  68%|██████▊   | 195/285 [03:58<01:11,  1.25it/s]Loading train:  69%|██████▉   | 196/285 [03:59<01:17,  1.15it/s]Loading train:  69%|██████▉   | 197/285 [04:00<01:18,  1.13it/s]Loading train:  69%|██████▉   | 198/285 [04:01<01:21,  1.06it/s]Loading train:  70%|██████▉   | 199/285 [04:02<01:15,  1.14it/s]Loading train:  70%|███████   | 200/285 [04:03<01:11,  1.18it/s]Loading train:  71%|███████   | 201/285 [04:04<01:14,  1.13it/s]Loading train:  71%|███████   | 202/285 [04:05<01:15,  1.09it/s]Loading train:  71%|███████   | 203/285 [04:06<01:13,  1.12it/s]Loading train:  72%|███████▏  | 204/285 [04:06<01:11,  1.14it/s]Loading train:  72%|███████▏  | 205/285 [04:07<01:09,  1.15it/s]Loading train:  72%|███████▏  | 206/285 [04:08<01:05,  1.20it/s]Loading train:  73%|███████▎  | 207/285 [04:09<01:09,  1.12it/s]Loading train:  73%|███████▎  | 208/285 [04:10<01:08,  1.12it/s]Loading train:  73%|███████▎  | 209/285 [04:11<01:09,  1.09it/s]Loading train:  74%|███████▎  | 210/285 [04:12<01:03,  1.17it/s]Loading train:  74%|███████▍  | 211/285 [04:13<01:04,  1.15it/s]Loading train:  74%|███████▍  | 212/285 [04:13<01:01,  1.18it/s]Loading train:  75%|███████▍  | 213/285 [04:14<01:02,  1.15it/s]Loading train:  75%|███████▌  | 214/285 [04:15<00:58,  1.21it/s]Loading train:  75%|███████▌  | 215/285 [04:16<01:02,  1.11it/s]Loading train:  76%|███████▌  | 216/285 [04:17<00:59,  1.15it/s]Loading train:  76%|███████▌  | 217/285 [04:18<01:00,  1.12it/s]Loading train:  76%|███████▋  | 218/285 [04:19<01:00,  1.11it/s]Loading train:  77%|███████▋  | 219/285 [04:20<01:03,  1.03it/s]Loading train:  77%|███████▋  | 220/285 [04:21<00:58,  1.12it/s]Loading train:  78%|███████▊  | 221/285 [04:21<00:54,  1.17it/s]Loading train:  78%|███████▊  | 222/285 [04:22<00:53,  1.18it/s]Loading train:  78%|███████▊  | 223/285 [04:23<00:49,  1.25it/s]Loading train:  79%|███████▊  | 224/285 [04:24<00:49,  1.24it/s]Loading train:  79%|███████▉  | 225/285 [04:24<00:47,  1.27it/s]Loading train:  79%|███████▉  | 226/285 [04:25<00:49,  1.20it/s]Loading train:  80%|███████▉  | 227/285 [04:26<00:49,  1.18it/s]Loading train:  80%|████████  | 228/285 [04:27<00:51,  1.11it/s]Loading train:  80%|████████  | 229/285 [04:28<00:49,  1.14it/s]Loading train:  81%|████████  | 230/285 [04:29<00:44,  1.23it/s]Loading train:  81%|████████  | 231/285 [04:30<00:44,  1.21it/s]Loading train:  81%|████████▏ | 232/285 [04:31<00:44,  1.18it/s]Loading train:  82%|████████▏ | 233/285 [04:31<00:42,  1.24it/s]Loading train:  82%|████████▏ | 234/285 [04:32<00:43,  1.17it/s]Loading train:  82%|████████▏ | 235/285 [04:33<00:42,  1.19it/s]Loading train:  83%|████████▎ | 236/285 [04:34<00:43,  1.12it/s]Loading train:  83%|████████▎ | 237/285 [04:35<00:42,  1.13it/s]Loading train:  84%|████████▎ | 238/285 [04:36<00:42,  1.10it/s]Loading train:  84%|████████▍ | 239/285 [04:37<00:41,  1.11it/s]Loading train:  84%|████████▍ | 240/285 [04:38<00:39,  1.15it/s]Loading train:  85%|████████▍ | 241/285 [04:38<00:36,  1.21it/s]Loading train:  85%|████████▍ | 242/285 [04:39<00:35,  1.22it/s]Loading train:  85%|████████▌ | 243/285 [04:40<00:33,  1.24it/s]Loading train:  86%|████████▌ | 244/285 [04:41<00:36,  1.12it/s]Loading train:  86%|████████▌ | 245/285 [04:42<00:34,  1.16it/s]Loading train:  86%|████████▋ | 246/285 [04:43<00:35,  1.10it/s]Loading train:  87%|████████▋ | 247/285 [04:44<00:35,  1.08it/s]Loading train:  87%|████████▋ | 248/285 [04:45<00:34,  1.07it/s]Loading train:  87%|████████▋ | 249/285 [04:45<00:31,  1.13it/s]Loading train:  88%|████████▊ | 250/285 [04:46<00:31,  1.13it/s]Loading train:  88%|████████▊ | 251/285 [04:47<00:28,  1.19it/s]Loading train:  88%|████████▊ | 252/285 [04:48<00:26,  1.25it/s]Loading train:  89%|████████▉ | 253/285 [04:49<00:27,  1.18it/s]Loading train:  89%|████████▉ | 254/285 [04:50<00:26,  1.19it/s]Loading train:  89%|████████▉ | 255/285 [04:51<00:26,  1.14it/s]Loading train:  90%|████████▉ | 256/285 [04:51<00:24,  1.19it/s]Loading train:  90%|█████████ | 257/285 [04:52<00:23,  1.20it/s]Loading train:  91%|█████████ | 258/285 [04:53<00:24,  1.12it/s]Loading train:  91%|█████████ | 259/285 [04:54<00:24,  1.08it/s]Loading train:  91%|█████████ | 260/285 [04:55<00:21,  1.15it/s]Loading train:  92%|█████████▏| 261/285 [04:56<00:20,  1.19it/s]Loading train:  92%|█████████▏| 262/285 [04:56<00:18,  1.25it/s]Loading train:  92%|█████████▏| 263/285 [04:57<00:17,  1.24it/s]Loading train:  93%|█████████▎| 264/285 [04:58<00:17,  1.17it/s]Loading train:  93%|█████████▎| 265/285 [04:59<00:17,  1.13it/s]Loading train:  93%|█████████▎| 266/285 [05:00<00:15,  1.20it/s]Loading train:  94%|█████████▎| 267/285 [05:01<00:14,  1.24it/s]Loading train:  94%|█████████▍| 268/285 [05:02<00:14,  1.16it/s]Loading train:  94%|█████████▍| 269/285 [05:02<00:13,  1.18it/s]Loading train:  95%|█████████▍| 270/285 [05:03<00:12,  1.18it/s]Loading train:  95%|█████████▌| 271/285 [05:04<00:11,  1.22it/s]Loading train:  95%|█████████▌| 272/285 [05:05<00:10,  1.20it/s]Loading train:  96%|█████████▌| 273/285 [05:06<00:09,  1.26it/s]Loading train:  96%|█████████▌| 274/285 [05:06<00:08,  1.29it/s]Loading train:  96%|█████████▋| 275/285 [05:07<00:08,  1.19it/s]Loading train:  97%|█████████▋| 276/285 [05:08<00:08,  1.11it/s]Loading train:  97%|█████████▋| 277/285 [05:09<00:06,  1.15it/s]Loading train:  98%|█████████▊| 278/285 [05:10<00:05,  1.21it/s]Loading train:  98%|█████████▊| 279/285 [05:11<00:05,  1.18it/s]Loading train:  98%|█████████▊| 280/285 [05:11<00:04,  1.23it/s]Loading train:  99%|█████████▊| 281/285 [05:12<00:03,  1.28it/s]Loading train:  99%|█████████▉| 282/285 [05:13<00:02,  1.31it/s]Loading train:  99%|█████████▉| 283/285 [05:14<00:01,  1.25it/s]Loading train: 100%|█████████▉| 284/285 [05:15<00:00,  1.19it/s]Loading train: 100%|██████████| 285/285 [05:16<00:00,  1.12it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   5%|▌         | 15/285 [00:00<00:01, 147.55it/s]concatenating: train:  11%|█         | 31/285 [00:00<00:01, 148.83it/s]concatenating: train:  16%|█▌        | 45/285 [00:00<00:01, 144.23it/s]concatenating: train:  21%|██        | 60/285 [00:00<00:01, 144.69it/s]concatenating: train:  33%|███▎      | 93/285 [00:00<00:01, 173.71it/s]concatenating: train:  45%|████▍     | 128/285 [00:00<00:00, 203.53it/s]concatenating: train:  55%|█████▌    | 157/285 [00:00<00:00, 222.55it/s]concatenating: train:  67%|██████▋   | 192/285 [00:00<00:00, 248.39it/s]concatenating: train:  78%|███████▊  | 223/285 [00:00<00:00, 262.89it/s]concatenating: train:  90%|████████▉ | 256/285 [00:01<00:00, 279.70it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 255.67it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.27s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.24s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.19s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 826.08it/s]2019-07-09 03:21:17.018111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-09 03:21:17.018220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-09 03:21:17.018239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-09 03:21:17.018248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-09 03:21:17.018646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12743 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  4.97it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.00it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  5.87it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.46it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.39it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.27it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.12it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.32it/s]loading the weights for Res Unet:  41%|████      | 18/44 [00:01<00:04,  5.95it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:02<00:03,  6.64it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  5.81it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.32it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:02,  7.86it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  8.39it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  6.54it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.22it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.41it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  8.46it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  6.84it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.58it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 30)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 31)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 15)   4200        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 15)   2040        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 15)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 40, 26, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 30)   4080        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 30)   8130        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 45)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 60)   24360       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 60)   32460       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 105)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 30)   12630       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 30)   8130        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 105)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 40, 26, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 15)   6315        dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 15)   2040        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 45)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 80, 52, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 13)   598         dropout_6[0][0]                  
==================================================================================================
Total params: 130,948
Trainable params: 32,428
Non-trainable params: 98,520
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 24s - loss: 27152.3068 - acc: 0.3869 - mDice: 0.0523 - val_loss: 24323.9767 - val_acc: 0.7043 - val_mDice: 0.0783

Epoch 00001: val_mDice improved from -inf to 0.07834, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 15s - loss: 13319.8978 - acc: 0.8552 - mDice: 0.2042 - val_loss: 12573.5905 - val_acc: 0.8689 - val_mDice: 0.2080

Epoch 00002: val_mDice improved from 0.07834 to 0.20801, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 14s - loss: 9369.8184 - acc: 0.8795 - mDice: 0.2999 - val_loss: 8858.6489 - val_acc: 0.9021 - val_mDice: 0.3272

Epoch 00003: val_mDice improved from 0.20801 to 0.32719, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 15s - loss: 8039.8917 - acc: 0.8882 - mDice: 0.3529 - val_loss: 7330.8011 - val_acc: 0.9090 - val_mDice: 0.3667

Epoch 00004: val_mDice improved from 0.32719 to 0.36674, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 15s - loss: 7182.3967 - acc: 0.8946 - mDice: 0.3933 - val_loss: 7266.6802 - val_acc: 0.9071 - val_mDice: 0.3717

Epoch 00005: val_mDice improved from 0.36674 to 0.37172, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 15s - loss: 6593.1330 - acc: 0.8994 - mDice: 0.4242 - val_loss: 6134.1553 - val_acc: 0.9215 - val_mDice: 0.4309

Epoch 00006: val_mDice improved from 0.37172 to 0.43088, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 14s - loss: 6111.2084 - acc: 0.9027 - mDice: 0.4518 - val_loss: 5815.5278 - val_acc: 0.9192 - val_mDice: 0.4483

Epoch 00007: val_mDice improved from 0.43088 to 0.44825, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 15s - loss: 5799.5881 - acc: 0.9053 - mDice: 0.4699 - val_loss: 6963.4980 - val_acc: 0.9108 - val_mDice: 0.3993

Epoch 00008: val_mDice did not improve from 0.44825
Epoch 9/300
 - 15s - loss: 5535.8319 - acc: 0.9076 - mDice: 0.4867 - val_loss: 5522.9569 - val_acc: 0.9256 - val_mDice: 0.4681

Epoch 00009: val_mDice improved from 0.44825 to 0.46813, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 14s - loss: 5301.3221 - acc: 0.9093 - mDice: 0.5020 - val_loss: 6155.5856 - val_acc: 0.9182 - val_mDice: 0.4348

Epoch 00010: val_mDice did not improve from 0.46813
Epoch 11/300
 - 14s - loss: 5110.4476 - acc: 0.9109 - mDice: 0.5142 - val_loss: 5315.5608 - val_acc: 0.9244 - val_mDice: 0.4826

Epoch 00011: val_mDice improved from 0.46813 to 0.48263, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 14s - loss: 4971.0554 - acc: 0.9120 - mDice: 0.5237 - val_loss: 5250.1591 - val_acc: 0.9301 - val_mDice: 0.4864

Epoch 00012: val_mDice improved from 0.48263 to 0.48639, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 16s - loss: 4841.8595 - acc: 0.9132 - mDice: 0.5325 - val_loss: 5315.8977 - val_acc: 0.9267 - val_mDice: 0.4769

Epoch 00013: val_mDice did not improve from 0.48639
Epoch 14/300
 - 14s - loss: 4718.7959 - acc: 0.9143 - mDice: 0.5406 - val_loss: 5162.8216 - val_acc: 0.9269 - val_mDice: 0.4893

Epoch 00014: val_mDice improved from 0.48639 to 0.48930, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 14s - loss: 4613.1313 - acc: 0.9149 - mDice: 0.5481 - val_loss: 5842.0383 - val_acc: 0.9188 - val_mDice: 0.4515

Epoch 00015: val_mDice did not improve from 0.48930
Epoch 16/300
 - 14s - loss: 4511.8398 - acc: 0.9157 - mDice: 0.5549 - val_loss: 5200.6967 - val_acc: 0.9271 - val_mDice: 0.4882

Epoch 00016: val_mDice did not improve from 0.48930
Epoch 17/300
 - 14s - loss: 4432.9768 - acc: 0.9164 - mDice: 0.5606 - val_loss: 4817.8024 - val_acc: 0.9312 - val_mDice: 0.5118

Epoch 00017: val_mDice improved from 0.48930 to 0.51183, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 14s - loss: 4387.6988 - acc: 0.9170 - mDice: 0.5643 - val_loss: 4939.8159 - val_acc: 0.9298 - val_mDice: 0.5051

Epoch 00018: val_mDice did not improve from 0.51183
Epoch 19/300
 - 15s - loss: 4306.2408 - acc: 0.9178 - mDice: 0.5697 - val_loss: 4957.0597 - val_acc: 0.9280 - val_mDice: 0.5071

Epoch 00019: val_mDice did not improve from 0.51183
Epoch 20/300
 - 14s - loss: 4226.1105 - acc: 0.9189 - mDice: 0.5754 - val_loss: 4640.5231 - val_acc: 0.9322 - val_mDice: 0.5252

Epoch 00020: val_mDice improved from 0.51183 to 0.52516, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 21/300
 - 14s - loss: 4164.8638 - acc: 0.9198 - mDice: 0.5800 - val_loss: 4683.7520 - val_acc: 0.9312 - val_mDice: 0.5231

Epoch 00021: val_mDice did not improve from 0.52516
Epoch 22/300
 - 14s - loss: 4127.6411 - acc: 0.9201 - mDice: 0.5827 - val_loss: 4913.2828 - val_acc: 0.9283 - val_mDice: 0.5060

Epoch 00022: val_mDice did not improve from 0.52516
Epoch 23/300
 - 14s - loss: 4064.6557 - acc: 0.9208 - mDice: 0.5873 - val_loss: 4700.1843 - val_acc: 0.9316 - val_mDice: 0.5182

Epoch 00023: val_mDice did not improve from 0.52516
Epoch 24/300
 - 14s - loss: 4031.6208 - acc: 0.9210 - mDice: 0.5898 - val_loss: 4749.9139 - val_acc: 0.9328 - val_mDice: 0.5166

Epoch 00024: val_mDice did not improve from 0.52516
Epoch 25/300
 - 14s - loss: 3971.2043 - acc: 0.9216 - mDice: 0.5943 - val_loss: 4655.6865 - val_acc: 0.9324 - val_mDice: 0.5229

Epoch 00025: val_mDice did not improve from 0.52516
Epoch 26/300
 - 14s - loss: 3950.5167 - acc: 0.9218 - mDice: 0.5961 - val_loss: 4770.2221 - val_acc: 0.9315 - val_mDice: 0.5167

Epoch 00026: val_mDice did not improve from 0.52516
Epoch 27/300
 - 14s - loss: 3911.5654 - acc: 0.9221 - mDice: 0.5990 - val_loss: 4673.5151 - val_acc: 0.9328 - val_mDice: 0.5212

Epoch 00027: val_mDice did not improve from 0.52516
Epoch 28/300
 - 14s - loss: 3870.2808 - acc: 0.9225 - mDice: 0.6022 - val_loss: 4648.2040 - val_acc: 0.9294 - val_mDice: 0.5246

Epoch 00028: val_mDice did not improve from 0.52516
Epoch 29/300
 - 14s - loss: 3866.0546 - acc: 0.9225 - mDice: 0.6025 - val_loss: 4656.9378 - val_acc: 0.9308 - val_mDice: 0.5239

Epoch 00029: val_mDice did not improve from 0.52516
Epoch 30/300
 - 14s - loss: 3821.4082 - acc: 0.9228 - mDice: 0.6060 - val_loss: 4732.1069 - val_acc: 0.9311 - val_mDice: 0.5202

Epoch 00030: val_mDice did not improve from 0.52516
Epoch 31/300
 - 14s - loss: 3808.2674 - acc: 0.9229 - mDice: 0.6069 - val_loss: 4506.8091 - val_acc: 0.9342 - val_mDice: 0.5327

Epoch 00031: val_mDice improved from 0.52516 to 0.53268, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 32/300
 - 14s - loss: 3777.7214 - acc: 0.9232 - mDice: 0.6093 - val_loss: 4733.9629 - val_acc: 0.9336 - val_mDice: 0.5166

Epoch 00032: val_mDice did not improve from 0.53268
Epoch 33/300
 - 14s - loss: 3754.7984 - acc: 0.9233 - mDice: 0.6110 - val_loss: 4546.1207 - val_acc: 0.9331 - val_mDice: 0.5296

Epoch 00033: val_mDice did not improve from 0.53268
Epoch 34/300
 - 14s - loss: 3697.2429 - acc: 0.9237 - mDice: 0.6155 - val_loss: 4700.8942 - val_acc: 0.9329 - val_mDice: 0.5190

Epoch 00034: val_mDice did not improve from 0.53268
Epoch 35/300
 - 14s - loss: 3693.2063 - acc: 0.9237 - mDice: 0.6161 - val_loss: 4826.5614 - val_acc: 0.9293 - val_mDice: 0.5130

Epoch 00035: val_mDice did not improve from 0.53268
Epoch 36/300
 - 14s - loss: 3665.2807 - acc: 0.9239 - mDice: 0.6182 - val_loss: 4647.3103 - val_acc: 0.9310 - val_mDice: 0.5233

Epoch 00036: val_mDice did not improve from 0.53268
Epoch 37/300
 - 14s - loss: 3647.7022 - acc: 0.9240 - mDice: 0.6199 - val_loss: 4707.5467 - val_acc: 0.9335 - val_mDice: 0.5205

Epoch 00037: val_mDice did not improve from 0.53268
Epoch 38/300
 - 14s - loss: 3612.9445 - acc: 0.9243 - mDice: 0.6225 - val_loss: 4992.4666 - val_acc: 0.9278 - val_mDice: 0.5036

Epoch 00038: val_mDice did not improve from 0.53268
Epoch 39/300
 - 14s - loss: 3603.6298 - acc: 0.9244 - mDice: 0.6231 - val_loss: 4821.3751 - val_acc: 0.9324 - val_mDice: 0.5147

Epoch 00039: val_mDice did not improve from 0.53268
Epoch 40/300
 - 15s - loss: 3576.9683 - acc: 0.9245 - mDice: 0.6254 - val_loss: 4552.7899 - val_acc: 0.9355 - val_mDice: 0.5293

Epoch 00040: val_mDice did not improve from 0.53268
Epoch 41/300
 - 15s - loss: 3580.9829 - acc: 0.9246 - mDice: 0.6251 - val_loss: 4729.9617 - val_acc: 0.9314 - val_mDice: 0.5170

Epoch 00041: val_mDice did not improve from 0.53268
Epoch 42/300
 - 14s - loss: 3549.7572 - acc: 0.9247 - mDice: 0.6276 - val_loss: 4388.2683 - val_acc: 0.9364 - val_mDice: 0.5419

Epoch 00042: val_mDice improved from 0.53268 to 0.54185, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 43/300
 - 14s - loss: 3552.0221 - acc: 0.9248 - mDice: 0.6275 - val_loss: 4452.1592 - val_acc: 0.9368 - val_mDice: 0.5364

Epoch 00043: val_mDice did not improve from 0.54185
Epoch 44/300
 - 14s - loss: 3504.7607 - acc: 0.9251 - mDice: 0.6311 - val_loss: 4634.0604 - val_acc: 0.9325 - val_mDice: 0.5255

Epoch 00044: val_mDice did not improve from 0.54185
Epoch 45/300
 - 14s - loss: 3503.5139 - acc: 0.9251 - mDice: 0.6312 - val_loss: 4682.2307 - val_acc: 0.9310 - val_mDice: 0.5231

Epoch 00045: val_mDice did not improve from 0.54185
Epoch 46/300
 - 14s - loss: 3472.7853 - acc: 0.9254 - mDice: 0.6340 - val_loss: 4897.9126 - val_acc: 0.9318 - val_mDice: 0.5079

Epoch 00046: val_mDice did not improve from 0.54185
Epoch 47/300
 - 14s - loss: 3474.4376 - acc: 0.9256 - mDice: 0.6336 - val_loss: 4535.0082 - val_acc: 0.9346 - val_mDice: 0.5310

Epoch 00047: val_mDice did not improve from 0.54185
Epoch 48/300
 - 15s - loss: 3455.8574 - acc: 0.9257 - mDice: 0.6353 - val_loss: 4495.4522 - val_acc: 0.9352 - val_mDice: 0.5327

Epoch 00048: val_mDice did not improve from 0.54185
Epoch 49/300
 - 15s - loss: 3451.1151 - acc: 0.9258 - mDice: 0.6356 - val_loss: 4584.8640 - val_acc: 0.9348 - val_mDice: 0.5307

Epoch 00049: val_mDice did not improve from 0.54185
Epoch 50/300
 - 14s - loss: 3433.5025 - acc: 0.9260 - mDice: 0.6373 - val_loss: 4470.3349 - val_acc: 0.9351 - val_mDice: 0.5373

Epoch 00050: val_mDice did not improve from 0.54185
Epoch 51/300
 - 13s - loss: 3435.9880 - acc: 0.9261 - mDice: 0.6370 - val_loss: 4461.4207 - val_acc: 0.9354 - val_mDice: 0.5369

Epoch 00051: val_mDice did not improve from 0.54185
Epoch 52/300
 - 15s - loss: 3403.3540 - acc: 0.9262 - mDice: 0.6396 - val_loss: 4603.1572 - val_acc: 0.9358 - val_mDice: 0.5263

Epoch 00052: val_mDice did not improve from 0.54185
Epoch 53/300
 - 15s - loss: 3387.2969 - acc: 0.9265 - mDice: 0.6410 - val_loss: 4610.1371 - val_acc: 0.9359 - val_mDice: 0.5249

Epoch 00053: val_mDice did not improve from 0.54185
Epoch 54/300
 - 14s - loss: 3376.4898 - acc: 0.9265 - mDice: 0.6419 - val_loss: 4371.6449 - val_acc: 0.9352 - val_mDice: 0.5428

Epoch 00054: val_mDice improved from 0.54185 to 0.54284, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 55/300
 - 15s - loss: 3364.2173 - acc: 0.9266 - mDice: 0.6427 - val_loss: 4427.1606 - val_acc: 0.9355 - val_mDice: 0.5381

Epoch 00055: val_mDice did not improve from 0.54284
Epoch 56/300
 - 15s - loss: 3353.9476 - acc: 0.9268 - mDice: 0.6437 - val_loss: 4466.0540 - val_acc: 0.9355 - val_mDice: 0.5336

Epoch 00056: val_mDice did not improve from 0.54284
Epoch 57/300
 - 14s - loss: 3344.9297 - acc: 0.9270 - mDice: 0.6443 - val_loss: 4382.5091 - val_acc: 0.9367 - val_mDice: 0.5415

Epoch 00057: val_mDice did not improve from 0.54284
Epoch 58/300
 - 15s - loss: 3326.5887 - acc: 0.9272 - mDice: 0.6459 - val_loss: 4713.1876 - val_acc: 0.9313 - val_mDice: 0.5181

Epoch 00058: val_mDice did not improve from 0.54284
Epoch 59/300
 - 14s - loss: 3328.6946 - acc: 0.9273 - mDice: 0.6457 - val_loss: 4481.0319 - val_acc: 0.9343 - val_mDice: 0.5343

Epoch 00059: val_mDice did not improve from 0.54284
Epoch 60/300
 - 15s - loss: 3310.8221 - acc: 0.9275 - mDice: 0.6472 - val_loss: 4540.2571 - val_acc: 0.9352 - val_mDice: 0.5320

Epoch 00060: val_mDice did not improve from 0.54284
Epoch 61/300
 - 14s - loss: 3289.6044 - acc: 0.9277 - mDice: 0.6488 - val_loss: 4338.2902 - val_acc: 0.9366 - val_mDice: 0.5442

Epoch 00061: val_mDice improved from 0.54284 to 0.54421, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 62/300
 - 15s - loss: 3294.7924 - acc: 0.9277 - mDice: 0.6485 - val_loss: 4487.8100 - val_acc: 0.9327 - val_mDice: 0.5327

Epoch 00062: val_mDice did not improve from 0.54421
Epoch 63/300
 - 14s - loss: 3264.4415 - acc: 0.9278 - mDice: 0.6511 - val_loss: 5238.1305 - val_acc: 0.9318 - val_mDice: 0.4833

Epoch 00063: val_mDice did not improve from 0.54421
Epoch 64/300
 - 14s - loss: 3267.3251 - acc: 0.9278 - mDice: 0.6508 - val_loss: 4437.2895 - val_acc: 0.9357 - val_mDice: 0.5361

Epoch 00064: val_mDice did not improve from 0.54421
Epoch 65/300
 - 14s - loss: 3280.3719 - acc: 0.9279 - mDice: 0.6498 - val_loss: 4448.7396 - val_acc: 0.9364 - val_mDice: 0.5355

Epoch 00065: val_mDice did not improve from 0.54421
Epoch 66/300
 - 14s - loss: 3242.4198 - acc: 0.9282 - mDice: 0.6529 - val_loss: 4364.6445 - val_acc: 0.9368 - val_mDice: 0.5418

Epoch 00066: val_mDice did not improve from 0.54421
Epoch 67/300
 - 14s - loss: 3249.0318 - acc: 0.9281 - mDice: 0.6524 - val_loss: 4673.7246 - val_acc: 0.9347 - val_mDice: 0.5221

Epoch 00067: val_mDice did not improve from 0.54421
Epoch 68/300
 - 14s - loss: 3233.2156 - acc: 0.9285 - mDice: 0.6538 - val_loss: 4395.4484 - val_acc: 0.9347 - val_mDice: 0.5411

Epoch 00068: val_mDice did not improve from 0.54421
Epoch 69/300
 - 14s - loss: 3229.4403 - acc: 0.9284 - mDice: 0.6540 - val_loss: 4451.3516 - val_acc: 0.9329 - val_mDice: 0.5346

Epoch 00069: val_mDice did not improve from 0.54421
Epoch 70/300
 - 14s - loss: 3218.5197 - acc: 0.9285 - mDice: 0.6551 - val_loss: 4461.2903 - val_acc: 0.9357 - val_mDice: 0.5365

Epoch 00070: val_mDice did not improve from 0.54421
Epoch 71/300
 - 14s - loss: 3206.5699 - acc: 0.9284 - mDice: 0.6559 - val_loss: 4472.2044 - val_acc: 0.9352 - val_mDice: 0.5351

Epoch 00071: val_mDice did not improve from 0.54421
Epoch 72/300
 - 14s - loss: 3211.0589 - acc: 0.9284 - mDice: 0.6557 - val_loss: 4530.6251 - val_acc: 0.9358 - val_mDice: 0.5320

Epoch 00072: val_mDice did not improve from 0.54421
Epoch 73/300
 - 14s - loss: 3197.2057 - acc: 0.9287 - mDice: 0.6565 - val_loss: 4624.9850 - val_acc: 0.9358 - val_mDice: 0.5245

Epoch 00073: val_mDice did not improve from 0.54421
Epoch 74/300
 - 14s - loss: 3190.4155 - acc: 0.9287 - mDice: 0.6575 - val_loss: 4434.2555 - val_acc: 0.9375 - val_mDice: 0.5386

Epoch 00074: val_mDice did not improve from 0.54421
Epoch 75/300
 - 14s - loss: 3181.0697 - acc: 0.9289 - mDice: 0.6580 - val_loss: 4384.1067 - val_acc: 0.9337 - val_mDice: 0.5416

Epoch 00075: val_mDice did not improve from 0.54421
Epoch 76/300
 - 14s - loss: 3163.7132 - acc: 0.9290 - mDice: 0.6597 - val_loss: 4393.9721 - val_acc: 0.9357 - val_mDice: 0.5404

Epoch 00076: val_mDice did not improve from 0.54421
Epoch 77/300
 - 15s - loss: 3169.3168 - acc: 0.9289 - mDice: 0.6593 - val_loss: 4604.2808 - val_acc: 0.9339 - val_mDice: 0.5249

Epoch 00077: val_mDice did not improve from 0.54421
Epoch 78/300
 - 14s - loss: 3152.8278 - acc: 0.9290 - mDice: 0.6605 - val_loss: 4304.1404 - val_acc: 0.9368 - val_mDice: 0.5464

Epoch 00078: val_mDice improved from 0.54421 to 0.54637, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 79/300
 - 15s - loss: 3174.2974 - acc: 0.9288 - mDice: 0.6590 - val_loss: 4331.0825 - val_acc: 0.9365 - val_mDice: 0.5455

Epoch 00079: val_mDice did not improve from 0.54637
Epoch 80/300
 - 14s - loss: 3148.7297 - acc: 0.9288 - mDice: 0.6607 - val_loss: 4425.0501 - val_acc: 0.9366 - val_mDice: 0.5382

Epoch 00080: val_mDice did not improve from 0.54637
Epoch 81/300
 - 15s - loss: 3147.7576 - acc: 0.9289 - mDice: 0.6611 - val_loss: 4378.3310 - val_acc: 0.9368 - val_mDice: 0.5407

Epoch 00081: val_mDice did not improve from 0.54637
Epoch 82/300
 - 14s - loss: 3134.4257 - acc: 0.9289 - mDice: 0.6623 - val_loss: 4762.3041 - val_acc: 0.9343 - val_mDice: 0.5141

Epoch 00082: val_mDice did not improve from 0.54637
Epoch 83/300
 - 14s - loss: 3115.7314 - acc: 0.9291 - mDice: 0.6637 - val_loss: 4341.7015 - val_acc: 0.9366 - val_mDice: 0.5439

Epoch 00083: val_mDice did not improve from 0.54637
Epoch 84/300
 - 15s - loss: 3135.7487 - acc: 0.9289 - mDice: 0.6622 - val_loss: 4328.4799 - val_acc: 0.9358 - val_mDice: 0.5457

Epoch 00084: val_mDice did not improve from 0.54637
Epoch 85/300
 - 14s - loss: 3119.2524 - acc: 0.9291 - mDice: 0.6636 - val_loss: 4366.0816 - val_acc: 0.9359 - val_mDice: 0.5435

Epoch 00085: val_mDice did not improve from 0.54637
Epoch 86/300
 - 14s - loss: 3124.7082 - acc: 0.9291 - mDice: 0.6630 - val_loss: 4476.4372 - val_acc: 0.9373 - val_mDice: 0.5353

Epoch 00086: val_mDice did not improve from 0.54637
Epoch 87/300
 - 13s - loss: 3101.3395 - acc: 0.9292 - mDice: 0.6649 - val_loss: 4635.2808 - val_acc: 0.9358 - val_mDice: 0.5218

Epoch 00087: val_mDice did not improve from 0.54637
Epoch 88/300
 - 14s - loss: 3091.6452 - acc: 0.9293 - mDice: 0.6657 - val_loss: 4271.8063 - val_acc: 0.9382 - val_mDice: 0.5496

Epoch 00088: val_mDice improved from 0.54637 to 0.54957, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 89/300
 - 14s - loss: 3092.7203 - acc: 0.9293 - mDice: 0.6658 - val_loss: 4349.0031 - val_acc: 0.9366 - val_mDice: 0.5422

Epoch 00089: val_mDice did not improve from 0.54957
Epoch 90/300
 - 14s - loss: 3097.0726 - acc: 0.9295 - mDice: 0.6653 - val_loss: 4366.0334 - val_acc: 0.9345 - val_mDice: 0.5415

Epoch 00090: val_mDice did not improve from 0.54957
Epoch 91/300
 - 14s - loss: 3072.0082 - acc: 0.9295 - mDice: 0.6674 - val_loss: 4349.7248 - val_acc: 0.9343 - val_mDice: 0.5435

Epoch 00091: val_mDice did not improve from 0.54957
Epoch 92/300
 - 15s - loss: 3085.7650 - acc: 0.9295 - mDice: 0.6664 - val_loss: 4314.1780 - val_acc: 0.9366 - val_mDice: 0.5465

Epoch 00092: val_mDice did not improve from 0.54957
Epoch 93/300
 - 14s - loss: 3071.4775 - acc: 0.9295 - mDice: 0.6673 - val_loss: 4373.4242 - val_acc: 0.9345 - val_mDice: 0.5414

Epoch 00093: val_mDice did not improve from 0.54957
Epoch 94/300
 - 14s - loss: 3054.7147 - acc: 0.9298 - mDice: 0.6688 - val_loss: 4340.5129 - val_acc: 0.9351 - val_mDice: 0.5431

Epoch 00094: val_mDice did not improve from 0.54957
Epoch 95/300
 - 14s - loss: 3045.7841 - acc: 0.9300 - mDice: 0.6697 - val_loss: 4409.1190 - val_acc: 0.9349 - val_mDice: 0.5383

Epoch 00095: val_mDice did not improve from 0.54957
Epoch 96/300
 - 14s - loss: 3051.8456 - acc: 0.9299 - mDice: 0.6690 - val_loss: 4701.7196 - val_acc: 0.9347 - val_mDice: 0.5215

Epoch 00096: val_mDice did not improve from 0.54957
Epoch 97/300
 - 14s - loss: 3051.7375 - acc: 0.9300 - mDice: 0.6691 - val_loss: 4375.8337 - val_acc: 0.9369 - val_mDice: 0.5418

Epoch 00097: val_mDice did not improve from 0.54957
Epoch 98/300
 - 14s - loss: 3033.7569 - acc: 0.9302 - mDice: 0.6708 - val_loss: 4362.8682 - val_acc: 0.9372 - val_mDice: 0.5436

Epoch 00098: val_mDice did not improve from 0.54957
Epoch 99/300
 - 15s - loss: 3030.1682 - acc: 0.9303 - mDice: 0.6710 - val_loss: 4283.0130 - val_acc: 0.9381 - val_mDice: 0.5484

Epoch 00099: val_mDice did not improve from 0.54957
Epoch 100/300
 - 14s - loss: 3068.1434 - acc: 0.9301 - mDice: 0.6688 - val_loss: 4234.2636 - val_acc: 0.9376 - val_mDice: 0.5523

Epoch 00100: val_mDice improved from 0.54957 to 0.55234, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 101/300
 - 14s - loss: 3019.1997 - acc: 0.9304 - mDice: 0.6719 - val_loss: 4271.4146 - val_acc: 0.9370 - val_mDice: 0.5504

Epoch 00101: val_mDice did not improve from 0.55234
Epoch 102/300
 - 14s - loss: 3016.7816 - acc: 0.9305 - mDice: 0.6723 - val_loss: 4233.0232 - val_acc: 0.9389 - val_mDice: 0.5523

Epoch 00102: val_mDice did not improve from 0.55234
Epoch 103/300
 - 14s - loss: 3016.8334 - acc: 0.9306 - mDice: 0.6722 - val_loss: 4208.0183 - val_acc: 0.9386 - val_mDice: 0.5537

Epoch 00103: val_mDice improved from 0.55234 to 0.55367, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 104/300
 - 14s - loss: 3001.2524 - acc: 0.9307 - mDice: 0.6736 - val_loss: 4477.7457 - val_acc: 0.9356 - val_mDice: 0.5339

Epoch 00104: val_mDice did not improve from 0.55367
Epoch 105/300
 - 14s - loss: 2998.9287 - acc: 0.9308 - mDice: 0.6737 - val_loss: 4385.2698 - val_acc: 0.9378 - val_mDice: 0.5410

Epoch 00105: val_mDice did not improve from 0.55367
Epoch 106/300
 - 14s - loss: 3006.7676 - acc: 0.9308 - mDice: 0.6733 - val_loss: 4666.8350 - val_acc: 0.9366 - val_mDice: 0.5221

Epoch 00106: val_mDice did not improve from 0.55367
Epoch 107/300
 - 15s - loss: 3012.6629 - acc: 0.9309 - mDice: 0.6727 - val_loss: 4449.4475 - val_acc: 0.9372 - val_mDice: 0.5375

Epoch 00107: val_mDice did not improve from 0.55367
Epoch 108/300
 - 14s - loss: 3007.3682 - acc: 0.9310 - mDice: 0.6730 - val_loss: 4627.7303 - val_acc: 0.9350 - val_mDice: 0.5250

Epoch 00108: val_mDice did not improve from 0.55367
Epoch 109/300
 - 14s - loss: 2984.7065 - acc: 0.9309 - mDice: 0.6749 - val_loss: 4280.4367 - val_acc: 0.9384 - val_mDice: 0.5488

Epoch 00109: val_mDice did not improve from 0.55367
Epoch 110/300
 - 14s - loss: 2984.9442 - acc: 0.9313 - mDice: 0.6750 - val_loss: 4329.3139 - val_acc: 0.9361 - val_mDice: 0.5440

Epoch 00110: val_mDice did not improve from 0.55367
Epoch 111/300
 - 14s - loss: 2988.2723 - acc: 0.9311 - mDice: 0.6745 - val_loss: 4379.6127 - val_acc: 0.9396 - val_mDice: 0.5429

Epoch 00111: val_mDice did not improve from 0.55367
Epoch 112/300
 - 14s - loss: 2979.9526 - acc: 0.9311 - mDice: 0.6753 - val_loss: 4200.1733 - val_acc: 0.9381 - val_mDice: 0.5545

Epoch 00112: val_mDice improved from 0.55367 to 0.55446, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 113/300
 - 15s - loss: 2965.3949 - acc: 0.9313 - mDice: 0.6765 - val_loss: 4435.6609 - val_acc: 0.9375 - val_mDice: 0.5385

Epoch 00113: val_mDice did not improve from 0.55446
Epoch 114/300
 - 15s - loss: 2983.4962 - acc: 0.9311 - mDice: 0.6751 - val_loss: 4408.8334 - val_acc: 0.9361 - val_mDice: 0.5385

Epoch 00114: val_mDice did not improve from 0.55446
Epoch 115/300
 - 14s - loss: 2964.3313 - acc: 0.9314 - mDice: 0.6766 - val_loss: 4594.8950 - val_acc: 0.9344 - val_mDice: 0.5270

Epoch 00115: val_mDice did not improve from 0.55446
Epoch 116/300
 - 15s - loss: 2948.5474 - acc: 0.9317 - mDice: 0.6780 - val_loss: 4223.6284 - val_acc: 0.9400 - val_mDice: 0.5541

Epoch 00116: val_mDice did not improve from 0.55446
Epoch 117/300
 - 14s - loss: 2956.9499 - acc: 0.9317 - mDice: 0.6772 - val_loss: 4217.9372 - val_acc: 0.9384 - val_mDice: 0.5528

Epoch 00117: val_mDice did not improve from 0.55446
Epoch 118/300
 - 15s - loss: 2962.5937 - acc: 0.9318 - mDice: 0.6770 - val_loss: 4357.8879 - val_acc: 0.9388 - val_mDice: 0.5439

Epoch 00118: val_mDice did not improve from 0.55446
Epoch 119/300
 - 14s - loss: 2942.4255 - acc: 0.9319 - mDice: 0.6786 - val_loss: 4429.2892 - val_acc: 0.9358 - val_mDice: 0.5370

Epoch 00119: val_mDice did not improve from 0.55446
Epoch 120/300
 - 14s - loss: 2948.7827 - acc: 0.9319 - mDice: 0.6782 - val_loss: 4425.6304 - val_acc: 0.9358 - val_mDice: 0.5389

Epoch 00120: val_mDice did not improve from 0.55446
Epoch 121/300
 - 15s - loss: 2947.2262 - acc: 0.9319 - mDice: 0.6782 - val_loss: 4220.5608 - val_acc: 0.9397 - val_mDice: 0.5534

Epoch 00121: val_mDice did not improve from 0.55446
Epoch 122/300
 - 15s - loss: 2931.2256 - acc: 0.9321 - mDice: 0.6796 - val_loss: 4175.1812 - val_acc: 0.9382 - val_mDice: 0.5562

Epoch 00122: val_mDice improved from 0.55446 to 0.55625, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 123/300
 - 13s - loss: 2927.9864 - acc: 0.9322 - mDice: 0.6798 - val_loss: 4322.8928 - val_acc: 0.9398 - val_mDice: 0.5469

Epoch 00123: val_mDice did not improve from 0.55625
Epoch 124/300
 - 14s - loss: 2928.9610 - acc: 0.9322 - mDice: 0.6796 - val_loss: 4305.5886 - val_acc: 0.9383 - val_mDice: 0.5471

Epoch 00124: val_mDice did not improve from 0.55625
Epoch 125/300
 - 15s - loss: 2917.1378 - acc: 0.9323 - mDice: 0.6808 - val_loss: 4380.1466 - val_acc: 0.9376 - val_mDice: 0.5419

Epoch 00125: val_mDice did not improve from 0.55625
Epoch 126/300
 - 14s - loss: 2934.9490 - acc: 0.9322 - mDice: 0.6793 - val_loss: 4324.7942 - val_acc: 0.9362 - val_mDice: 0.5456

Epoch 00126: val_mDice did not improve from 0.55625
Epoch 127/300
 - 15s - loss: 2925.5062 - acc: 0.9324 - mDice: 0.6800 - val_loss: 4294.6936 - val_acc: 0.9369 - val_mDice: 0.5475

Epoch 00127: val_mDice did not improve from 0.55625
Epoch 128/300
 - 13s - loss: 2933.4063 - acc: 0.9324 - mDice: 0.6796 - val_loss: 4408.0357 - val_acc: 0.9358 - val_mDice: 0.5387

Epoch 00128: val_mDice did not improve from 0.55625
Epoch 129/300
 - 15s - loss: 2903.7789 - acc: 0.9327 - mDice: 0.6820 - val_loss: 4389.9658 - val_acc: 0.9380 - val_mDice: 0.5416

Epoch 00129: val_mDice did not improve from 0.55625
Epoch 130/300
 - 14s - loss: 2907.0749 - acc: 0.9325 - mDice: 0.6818 - val_loss: 4428.6548 - val_acc: 0.9354 - val_mDice: 0.5389

Epoch 00130: val_mDice did not improve from 0.55625
Epoch 131/300
 - 14s - loss: 2904.7528 - acc: 0.9328 - mDice: 0.6820 - val_loss: 4435.9038 - val_acc: 0.9370 - val_mDice: 0.5384

Epoch 00131: val_mDice did not improve from 0.55625
Epoch 132/300
 - 14s - loss: 2918.1195 - acc: 0.9327 - mDice: 0.6808 - val_loss: 4251.0851 - val_acc: 0.9370 - val_mDice: 0.5517

Epoch 00132: val_mDice did not improve from 0.55625
Epoch 133/300
 - 15s - loss: 2889.6823 - acc: 0.9330 - mDice: 0.6832 - val_loss: 4335.8110 - val_acc: 0.9391 - val_mDice: 0.5444

Epoch 00133: val_mDice did not improve from 0.55625
Epoch 134/300
 - 14s - loss: 2887.8202 - acc: 0.9329 - mDice: 0.6833 - val_loss: 4244.7591 - val_acc: 0.9388 - val_mDice: 0.5531

Epoch 00134: val_mDice did not improve from 0.55625
Epoch 135/300
 - 14s - loss: 2884.8959 - acc: 0.9332 - mDice: 0.6837 - val_loss: 4217.1452 - val_acc: 0.9398 - val_mDice: 0.5534

Epoch 00135: val_mDice did not improve from 0.55625
Epoch 136/300
 - 14s - loss: 2902.6912 - acc: 0.9329 - mDice: 0.6821 - val_loss: 4324.4506 - val_acc: 0.9376 - val_mDice: 0.5454

Epoch 00136: val_mDice did not improve from 0.55625
Epoch 137/300
 - 15s - loss: 2903.6660 - acc: 0.9329 - mDice: 0.6820 - val_loss: 4657.4172 - val_acc: 0.9353 - val_mDice: 0.5229

Epoch 00137: val_mDice did not improve from 0.55625
Epoch 138/300
 - 14s - loss: 2904.6916 - acc: 0.9330 - mDice: 0.6818 - val_loss: 4305.3678 - val_acc: 0.9372 - val_mDice: 0.5497

Epoch 00138: val_mDice did not improve from 0.55625
Epoch 139/300
 - 15s - loss: 2880.7816 - acc: 0.9334 - mDice: 0.6840 - val_loss: 4375.6707 - val_acc: 0.9387 - val_mDice: 0.5406

Epoch 00139: val_mDice did not improve from 0.55625
Epoch 140/300
 - 14s - loss: 2889.6169 - acc: 0.9335 - mDice: 0.6833 - val_loss: 4314.5445 - val_acc: 0.9391 - val_mDice: 0.5472

Epoch 00140: val_mDice did not improve from 0.55625
Epoch 141/300
 - 14s - loss: 2892.9349 - acc: 0.9335 - mDice: 0.6828 - val_loss: 4380.3783 - val_acc: 0.9385 - val_mDice: 0.5421

Epoch 00141: val_mDice did not improve from 0.55625
Epoch 142/300
 - 13s - loss: 2879.4226 - acc: 0.9337 - mDice: 0.6843 - val_loss: 4391.8089 - val_acc: 0.9365 - val_mDice: 0.5399

Epoch 00142: val_mDice did not improve from 0.55625
Epoch 143/300
 - 14s - loss: 2860.9580 - acc: 0.9337 - mDice: 0.6857 - val_loss: 4217.3124 - val_acc: 0.9366 - val_mDice: 0.5535

Epoch 00143: val_mDice did not improve from 0.55625
Epoch 144/300
 - 15s - loss: 2868.9585 - acc: 0.9337 - mDice: 0.6849 - val_loss: 4344.1503 - val_acc: 0.9390 - val_mDice: 0.5440

Epoch 00144: val_mDice did not improve from 0.55625
Epoch 145/300
 - 14s - loss: 2862.3435 - acc: 0.9337 - mDice: 0.6856 - val_loss: 4665.7341 - val_acc: 0.9363 - val_mDice: 0.5212

Epoch 00145: val_mDice did not improve from 0.55625
Epoch 146/300
 - 14s - loss: 2854.1549 - acc: 0.9339 - mDice: 0.6863 - val_loss: 4183.2437 - val_acc: 0.9396 - val_mDice: 0.5569

Epoch 00146: val_mDice improved from 0.55625 to 0.55687, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 147/300
 - 14s - loss: 2847.2495 - acc: 0.9339 - mDice: 0.6869 - val_loss: 4581.6213 - val_acc: 0.9360 - val_mDice: 0.5313

Epoch 00147: val_mDice did not improve from 0.55687
Epoch 148/300
 - 14s - loss: 2851.7402 - acc: 0.9341 - mDice: 0.6863 - val_loss: 4280.7005 - val_acc: 0.9398 - val_mDice: 0.5482

Epoch 00148: val_mDice did not improve from 0.55687
Epoch 149/300
 - 14s - loss: 2857.0788 - acc: 0.9341 - mDice: 0.6860 - val_loss: 4402.8576 - val_acc: 0.9375 - val_mDice: 0.5406

Epoch 00149: val_mDice did not improve from 0.55687
Epoch 150/300
 - 14s - loss: 2854.8740 - acc: 0.9343 - mDice: 0.6862 - val_loss: 4388.9567 - val_acc: 0.9382 - val_mDice: 0.5415

Epoch 00150: val_mDice did not improve from 0.55687
Epoch 151/300
 - 14s - loss: 2849.0269 - acc: 0.9344 - mDice: 0.6867 - val_loss: 4818.2894 - val_acc: 0.9348 - val_mDice: 0.5172

Epoch 00151: val_mDice did not improve from 0.55687
Epoch 152/300
 - 15s - loss: 2843.7075 - acc: 0.9344 - mDice: 0.6873 - val_loss: 4196.5559 - val_acc: 0.9395 - val_mDice: 0.5553

Epoch 00152: val_mDice did not improve from 0.55687
Epoch 153/300
 - 15s - loss: 2842.1390 - acc: 0.9344 - mDice: 0.6874 - val_loss: 4254.0789 - val_acc: 0.9385 - val_mDice: 0.5525

Epoch 00153: val_mDice did not improve from 0.55687
Epoch 154/300
 - 14s - loss: 2853.4924 - acc: 0.9342 - mDice: 0.6863 - val_loss: 4115.7393 - val_acc: 0.9394 - val_mDice: 0.5611

Epoch 00154: val_mDice improved from 0.55687 to 0.56105, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 155/300
 - 15s - loss: 2845.7760 - acc: 0.9346 - mDice: 0.6870 - val_loss: 4398.9841 - val_acc: 0.9387 - val_mDice: 0.5422

Epoch 00155: val_mDice did not improve from 0.56105
Epoch 156/300
 - 15s - loss: 2840.4209 - acc: 0.9345 - mDice: 0.6874 - val_loss: 4279.7530 - val_acc: 0.9385 - val_mDice: 0.5504

Epoch 00156: val_mDice did not improve from 0.56105
Epoch 157/300
 - 15s - loss: 2846.8096 - acc: 0.9346 - mDice: 0.6869 - val_loss: 4526.0015 - val_acc: 0.9394 - val_mDice: 0.5332

Epoch 00157: val_mDice did not improve from 0.56105
Epoch 158/300
 - 14s - loss: 2825.5633 - acc: 0.9347 - mDice: 0.6888 - val_loss: 4724.8073 - val_acc: 0.9322 - val_mDice: 0.5183

Epoch 00158: val_mDice did not improve from 0.56105
Epoch 159/300
 - 14s - loss: 2833.0860 - acc: 0.9347 - mDice: 0.6881 - val_loss: 4670.3847 - val_acc: 0.9350 - val_mDice: 0.5227

Epoch 00159: val_mDice did not improve from 0.56105
Epoch 160/300
 - 14s - loss: 2820.4617 - acc: 0.9348 - mDice: 0.6893 - val_loss: 4215.4959 - val_acc: 0.9392 - val_mDice: 0.5550

Epoch 00160: val_mDice did not improve from 0.56105
Epoch 161/300
 - 14s - loss: 2813.9067 - acc: 0.9349 - mDice: 0.6897 - val_loss: 4847.4445 - val_acc: 0.9336 - val_mDice: 0.5120

Epoch 00161: val_mDice did not improve from 0.56105
Epoch 162/300
 - 14s - loss: 2813.2668 - acc: 0.9348 - mDice: 0.6896 - val_loss: 4303.5035 - val_acc: 0.9359 - val_mDice: 0.5474

Epoch 00162: val_mDice did not improve from 0.56105
Epoch 163/300
 - 15s - loss: 2810.3618 - acc: 0.9350 - mDice: 0.6900 - val_loss: 4257.7476 - val_acc: 0.9387 - val_mDice: 0.5524

Epoch 00163: val_mDice did not improve from 0.56105
Epoch 164/300
 - 15s - loss: 2817.7522 - acc: 0.9349 - mDice: 0.6895 - val_loss: 4326.7505 - val_acc: 0.9405 - val_mDice: 0.5486

Epoch 00164: val_mDice did not improve from 0.56105
Epoch 165/300
 - 15s - loss: 2809.5026 - acc: 0.9349 - mDice: 0.6901 - val_loss: 4569.1119 - val_acc: 0.9357 - val_mDice: 0.5277

Epoch 00165: val_mDice did not improve from 0.56105
Epoch 166/300
 - 15s - loss: 2814.5871 - acc: 0.9349 - mDice: 0.6897 - val_loss: 4277.1094 - val_acc: 0.9394 - val_mDice: 0.5503

Epoch 00166: val_mDice did not improve from 0.56105
Epoch 167/300
 - 15s - loss: 2815.1779 - acc: 0.9351 - mDice: 0.6898 - val_loss: 4341.8480 - val_acc: 0.9376 - val_mDice: 0.5456

Epoch 00167: val_mDice did not improve from 0.56105
Epoch 168/300
 - 15s - loss: 2795.6286 - acc: 0.9351 - mDice: 0.6913 - val_loss: 4294.8562 - val_acc: 0.9397 - val_mDice: 0.5487

Epoch 00168: val_mDice did not improve from 0.56105
Epoch 169/300
 - 14s - loss: 2811.9095 - acc: 0.9350 - mDice: 0.6899 - val_loss: 4272.8529 - val_acc: 0.9396 - val_mDice: 0.5506

Epoch 00169: val_mDice did not improve from 0.56105
Epoch 170/300
 - 14s - loss: 2801.4778 - acc: 0.9350 - mDice: 0.6910 - val_loss: 4577.7432 - val_acc: 0.9362 - val_mDice: 0.5292

Epoch 00170: val_mDice did not improve from 0.56105
Epoch 171/300
 - 15s - loss: 2811.1157 - acc: 0.9351 - mDice: 0.6901 - val_loss: 4252.5391 - val_acc: 0.9394 - val_mDice: 0.5506

Epoch 00171: val_mDice did not improve from 0.56105
Epoch 172/300
 - 14s - loss: 2795.5575 - acc: 0.9351 - mDice: 0.6915 - val_loss: 4340.3942 - val_acc: 0.9390 - val_mDice: 0.5448

Epoch 00172: val_mDice did not improve from 0.56105
Epoch 173/300
 - 14s - loss: 2788.3211 - acc: 0.9352 - mDice: 0.6920 - val_loss: 4295.6011 - val_acc: 0.9394 - val_mDice: 0.5498

Epoch 00173: val_mDice did not improve from 0.56105
Epoch 174/300
 - 14s - loss: 2799.5199 - acc: 0.9351 - mDice: 0.6911 - val_loss: 4365.5973 - val_acc: 0.9380 - val_mDice: 0.5440

Epoch 00174: val_mDice did not improve from 0.56105
Epoch 175/300
 - 15s - loss: 2789.8549 - acc: 0.9353 - mDice: 0.6920 - val_loss: 4300.4312 - val_acc: 0.9386 - val_mDice: 0.5485

Epoch 00175: val_mDice did not improve from 0.56105
Epoch 176/300
 - 15s - loss: 2799.4849 - acc: 0.9353 - mDice: 0.6911 - val_loss: 4139.8493 - val_acc: 0.9402 - val_mDice: 0.5608

Epoch 00176: val_mDice did not improve from 0.56105
Epoch 177/300
 - 14s - loss: 2771.0232 - acc: 0.9355 - mDice: 0.6936 - val_loss: 4238.5215 - val_acc: 0.9382 - val_mDice: 0.5528

Epoch 00177: val_mDice did not improve from 0.56105
Epoch 178/300
 - 14s - loss: 2784.5840 - acc: 0.9353 - mDice: 0.6925 - val_loss: 4252.0596 - val_acc: 0.9376 - val_mDice: 0.5518

Epoch 00178: val_mDice did not improve from 0.56105
Epoch 179/300
 - 15s - loss: 2779.8855 - acc: 0.9352 - mDice: 0.6928 - val_loss: 4374.7968 - val_acc: 0.9372 - val_mDice: 0.5417

Epoch 00179: val_mDice did not improve from 0.56105
Epoch 180/300
 - 15s - loss: 2772.1719 - acc: 0.9355 - mDice: 0.6935 - val_loss: 4214.6997 - val_acc: 0.9397 - val_mDice: 0.5533

Epoch 00180: val_mDice did not improve from 0.56105
Epoch 181/300
 - 14s - loss: 2777.1595 - acc: 0.9356 - mDice: 0.6930 - val_loss: 4364.2691 - val_acc: 0.9398 - val_mDice: 0.5459

Epoch 00181: val_mDice did not improve from 0.56105
Epoch 182/300
 - 14s - loss: 2767.0545 - acc: 0.9356 - mDice: 0.6940 - val_loss: 4434.4202 - val_acc: 0.9380 - val_mDice: 0.5378

Epoch 00182: val_mDice did not improve from 0.56105
Epoch 183/300
 - 15s - loss: 2771.1738 - acc: 0.9354 - mDice: 0.6936 - val_loss: 4547.0139 - val_acc: 0.9370 - val_mDice: 0.5302

Epoch 00183: val_mDice did not improve from 0.56105
Epoch 184/300
 - 15s - loss: 2768.1955 - acc: 0.9357 - mDice: 0.6939 - val_loss: 4488.3676 - val_acc: 0.9385 - val_mDice: 0.5353

Epoch 00184: val_mDice did not improve from 0.56105
Restoring model weights from the end of the best epoch
Epoch 00184: early stopping
{'val_loss': [24323.97670335036, 12573.590529221754, 8858.648888221154, 7330.801100510817, 7266.680203951322, 6134.155301607572, 5815.527756911058, 6963.498046875, 5522.956918569712, 6155.585599459135, 5315.560781625601, 5250.159067007212, 5315.897723858173, 5162.821617713342, 5842.038264347957, 5200.6967210036055, 4817.802443284255, 4939.815908578726, 4957.059654822717, 4640.523127629207, 4683.752028245192, 4913.28280874399, 4700.184344951923, 4749.913893479567, 4655.686495267428, 4770.222083458533, 4673.515108548678, 4648.2039794921875, 4656.937819260817, 4732.106867863582, 4506.809072641226, 4733.962890625, 4546.12065241887, 4700.894211989183, 4826.561410757212, 4647.310349684495, 4707.546705979567, 4992.466590294471, 4821.375070425181, 4552.7898841271035, 4729.961679311899, 4388.268291766827, 4452.1591796875, 4634.0603590745195, 4682.230665940505, 4897.912592961238, 4535.008235051082, 4495.452157827524, 4584.864018366887, 4470.334928072416, 4461.420663686899, 4603.157198392428, 4610.13706618089, 4371.644873985877, 4427.16059758113, 4466.053959773137, 4382.509103628306, 4713.187617375301, 4481.031940166767, 4540.257094163161, 4338.290212777944, 4487.809974083533, 5238.130488469051, 4437.2894615760215, 4448.7395911583535, 4364.644540640024, 4673.724590594952, 4395.448420597957, 4451.351595365084, 4461.290273813101, 4472.204420823317, 4530.6251220703125, 4624.985036996694, 4434.255507249099, 4384.106698843149, 4393.972102238582, 4604.280841533954, 4304.140409029447, 4331.082528921274, 4425.050133338342, 4378.331035907452, 4762.304072453426, 4341.701477050781, 4328.479872483474, 4366.081552358774, 4476.437185434194, 4635.280766413762, 4271.806302584135, 4349.003136268029, 4366.033405010517, 4349.724825345553, 4314.177964430589, 4373.424217810998, 4340.512939453125, 4409.118962214543, 4701.719627967248, 4375.833749624399, 4362.8681640625, 4283.012986403245, 4234.263568584735, 4271.414578951322, 4233.023160494291, 4208.018296461839, 4477.745685283954, 4385.269780085637, 4666.835026667668, 4449.447514460637, 4627.730332594651, 4280.436734713041, 4329.313936673678, 4379.612713153546, 4200.173349233774, 4435.660855806791, 4408.833397498498, 4594.894958496094, 4223.628380408654, 4217.937161959135, 4357.887873722957, 4429.289170485276, 4425.63041804387, 4220.560795710637, 4175.181203988882, 4322.892831655649, 4305.588580791767, 4380.146597055288, 4324.794161283053, 4294.693594125601, 4408.035696176382, 4389.9658437875605, 4428.6548086313105, 4435.903794508714, 4251.0851487379805, 4335.810983511118, 4244.759051983173, 4217.145165076623, 4324.450617863582, 4657.417175292969, 4305.367793156551, 4375.670687161959, 4314.544513408954, 4380.378305288462, 4391.808908315806, 4217.3124107947715, 4344.150282639724, 4665.734144944411, 4183.243694598858, 4581.621309720553, 4280.700453538161, 4402.857567420373, 4388.9567307692305, 4818.289372370793, 4196.555856557993, 4254.078927847056, 4115.739271897536, 4398.9840745192305, 4279.752990722656, 4526.001497708834, 4724.807312011719, 4670.384690504808, 4215.495854304387, 4847.444537823017, 4303.50354708158, 4257.747553898738, 4326.750507061298, 4569.111915001502, 4277.10942195012, 4341.847980205829, 4294.856205866887, 4272.852928748498, 4577.743196927584, 4252.539053109976, 4340.394150954026, 4295.6011305588945, 4365.597285344051, 4300.431194598858, 4139.8493088942305, 4238.521484375, 4252.0595703125, 4374.796846829928, 4214.699669471154, 4364.269057053786, 4434.420212965745, 4547.013934795673, 4488.367642916166], 'val_acc': [0.704296873166011, 0.8688678535131308, 0.9021265048247117, 0.9090051765625293, 0.9071005995456989, 0.9215305860225971, 0.9192238174951993, 0.9108381317212031, 0.9256356404377863, 0.918192962041268, 0.9244082936873803, 0.9301451605099899, 0.9266873323000394, 0.926920792231193, 0.9187892950498141, 0.9270548316148611, 0.9311968156924615, 0.929849271590893, 0.9279840198846964, 0.9321699119531192, 0.931176061813648, 0.9282683065304389, 0.9316475322613349, 0.9327616576965039, 0.9324334263801575, 0.9314511097394503, 0.932770882661526, 0.929440207206286, 0.9308454921612372, 0.9311159459444193, 0.9341669770387503, 0.9335983991622925, 0.933059790959725, 0.9329142157848065, 0.9292714274846591, 0.9310280932829931, 0.9334850976100335, 0.9278430250974802, 0.9324380434476413, 0.9355353254538316, 0.9314371989323542, 0.9363858997821808, 0.9367534311918112, 0.9325027970167307, 0.9309842013395749, 0.9317746827235589, 0.9345992069977981, 0.9351908977215106, 0.9347794904158666, 0.9350637954014999, 0.9353665686570681, 0.9357687808000125, 0.935902829353626, 0.9352441086218908, 0.9354590613108414, 0.9355468864624317, 0.9366517273279337, 0.9313470881718856, 0.9343010324698228, 0.9352348446846008, 0.9366355309119592, 0.9327108218119695, 0.9318440556526184, 0.9356601329950186, 0.9363604829861567, 0.9367950031390557, 0.9346778117693387, 0.9347055027118096, 0.9328818298303164, 0.9357456564903259, 0.93523714863337, 0.9358357718357673, 0.9358265652106359, 0.9375138603723966, 0.933743967459752, 0.9356855337436383, 0.9339080911416274, 0.9367580551367539, 0.936466824549895, 0.9365684848565322, 0.9367950375263507, 0.9342524936565986, 0.9366147288909326, 0.9357595214476953, 0.9358958831200233, 0.9372642475825089, 0.9358311478908246, 0.9381680167638339, 0.9365869760513306, 0.9345252147087684, 0.9343311007206256, 0.9366077918272752, 0.9345044287351462, 0.9351470195330106, 0.9348765519949106, 0.9347332738913022, 0.9368920922279358, 0.9372226527104011, 0.9381263989668626, 0.9375624152330252, 0.9369822580080766, 0.9389399863206424, 0.9386302553690397, 0.93556075829726, 0.937849012704996, 0.936612436404595, 0.9372411507826585, 0.9350059972359583, 0.9384499765359439, 0.9361293545136085, 0.9396264896943018, 0.9380940313522632, 0.9375092249650222, 0.9360877298391782, 0.9343611437540787, 0.9399847686290741, 0.9383759911243732, 0.9387504458427429, 0.9358265697956085, 0.9358450655753796, 0.9396796524524689, 0.9382281051232264, 0.9398067754048568, 0.9382604566904215, 0.9376433193683624, 0.9361802087380335, 0.9369314152460831, 0.9357803257612082, 0.9379599552888137, 0.9353596407633561, 0.9370492971860446, 0.9370215558088743, 0.9391410717597375, 0.9387920705171732, 0.9398136826661917, 0.9376155734062195, 0.9353296229472527, 0.9371810486683478, 0.9386510734374707, 0.9390717515578637, 0.938477697280737, 0.9365408007915204, 0.9365546519939716, 0.9389769916351025, 0.936335034095324, 0.9395848581424127, 0.935967525610557, 0.9397836533876566, 0.9374953645926255, 0.9382465619307297, 0.9347818287519308, 0.9394507981263674, 0.9384892972616049, 0.9394161701202393, 0.9387458677475269, 0.9385424302174494, 0.9394253950852615, 0.9322462104834043, 0.9349944591522217, 0.9391849866280189, 0.933633063848202, 0.9358750810989966, 0.9386649429798126, 0.940458609507634, 0.9357387377665594, 0.9394484895926255, 0.9376017244962546, 0.9396981230148902, 0.939598750609618, 0.9362472456235152, 0.9394138570015247, 0.9390486455880679, 0.9393514440609858, 0.9380339521628159, 0.9385979038018447, 0.9401627458058871, 0.9382165097273313, 0.9375993701127859, 0.9371648476674006, 0.9396796180651739, 0.9397790065178504, 0.9379576536325308, 0.9370099718754108, 0.938512378014051], 'val_mDice': [0.07834414134805019, 0.20801381967388666, 0.3271920984754196, 0.36674245217671764, 0.3717170701577113, 0.43087904126598287, 0.4482526039847961, 0.399327101615759, 0.46813204855873036, 0.434813595448549, 0.4826331983965177, 0.4863922822360809, 0.47688709371365035, 0.48929936438798904, 0.45148403799304593, 0.488204217587526, 0.5118278786540031, 0.5051135380680745, 0.5071106985784494, 0.5251606012193056, 0.5230685185927612, 0.5059534941728299, 0.51817469814649, 0.5166330492267242, 0.5229026898741722, 0.5166737718077806, 0.52123221840996, 0.5246289097345792, 0.5239133559740506, 0.5201676393357607, 0.5326820173515723, 0.516594088707979, 0.5296291855092232, 0.5189853138648547, 0.5129783379916961, 0.5232528728934435, 0.5205147813719052, 0.5036081542762426, 0.5147282810738454, 0.5293142597835797, 0.5169973912147375, 0.541852705180645, 0.5363718855839509, 0.5254965226810712, 0.5230995012590518, 0.5078627174863448, 0.5310230252261345, 0.5327037435311538, 0.5307283779749503, 0.5372969789000658, 0.5369489359167906, 0.5263226152612612, 0.5248781144618988, 0.5428365875895207, 0.5380579872200122, 0.5335743355636413, 0.5414959857097039, 0.5181024647676028, 0.5342809704060738, 0.5319946924081216, 0.5442125206956496, 0.5326665903513248, 0.4832730167187177, 0.5361311361193657, 0.5355058977237115, 0.5418026762513014, 0.522053464100911, 0.5410781835134213, 0.5346276037968122, 0.5365106380329683, 0.5351328557500472, 0.5320224200303738, 0.5244937808467791, 0.5386385780114394, 0.5416069145386035, 0.5404413961447202, 0.5249326532849898, 0.546368016073337, 0.545539642469241, 0.5381537939493473, 0.5407268496660086, 0.5140607672242018, 0.5438616619660304, 0.5456894186253731, 0.5434912087825629, 0.5352620585606649, 0.5217848660854193, 0.5495745963775195, 0.542181080350509, 0.5414542423991057, 0.5434648130948727, 0.5465104316289608, 0.541434842806596, 0.5431491904533826, 0.5383272549280753, 0.5214614449785306, 0.5418026538995596, 0.5435832412197039, 0.5484420634233035, 0.5523436906246039, 0.5503847828278174, 0.5523315140834222, 0.5536696933783017, 0.5338764207867476, 0.5410461271038423, 0.5221019822817582, 0.5374602761406165, 0.5249589475301596, 0.5487770260526583, 0.5440360817771691, 0.54286212932605, 0.5544648628968459, 0.538528612599923, 0.5384812555634059, 0.5269725574896886, 0.5541136849385041, 0.5528087862409078, 0.5438892589165614, 0.5370122704368371, 0.5389397465265714, 0.5534260450647428, 0.5562470022302407, 0.5468853282240721, 0.547102167056157, 0.5418986643736179, 0.5456299930810928, 0.5474876767167678, 0.538745713348572, 0.5416352829107871, 0.5388678105977865, 0.5384186047774094, 0.5517045798209997, 0.5443671196699142, 0.5530843935333766, 0.5533986441217936, 0.5453804931961573, 0.5228934385455571, 0.5497088535473897, 0.5405590408123456, 0.5472429383259553, 0.5421343331153576, 0.5398793764985524, 0.5534656775685457, 0.5440445060913379, 0.5211511896206782, 0.5568743061560851, 0.5312507817378411, 0.5482008566076939, 0.5406343673284237, 0.5414637378775157, 0.5171746216141261, 0.5552786284914384, 0.5524832864220326, 0.5610505537344859, 0.5422133608506277, 0.5503810518063031, 0.5332479654596403, 0.518317271883671, 0.522698788688733, 0.5550323816446158, 0.5120084663996329, 0.5474018059097804, 0.5523874358488963, 0.5485728812905458, 0.5277011446081675, 0.5503092746321971, 0.5456395303973784, 0.5486550995936761, 0.5505935062582676, 0.5291612847493246, 0.5506147020138227, 0.5447951016517786, 0.5497837427716988, 0.5440086481662897, 0.5484780164865347, 0.5608251289679453, 0.5527941063046455, 0.5518390381565461, 0.5416986936560044, 0.5533490570691916, 0.5458744105238181, 0.5377689657303003, 0.5302458141858761, 0.5352505663266549], 'loss': [27152.30681237679, 13319.89775071799, 9369.818353836072, 8039.891704618079, 7182.396711043235, 6593.133003953263, 6111.208427397536, 5799.588083496769, 5535.831852833481, 5301.3220999074865, 5110.4475970375115, 4971.055400940915, 4841.859466685016, 4718.795934159081, 4613.131349322432, 4511.839836860114, 4432.976803420842, 4387.698779283365, 4306.240815174357, 4226.110492107163, 4164.863826429098, 4127.641148777671, 4064.655716123918, 4031.620754805898, 3971.204277220813, 3950.5167306127623, 3911.565423608189, 3870.2807989939324, 3866.0546303657347, 3821.408203800479, 3808.2674370174377, 3777.7214286344733, 3754.798388174272, 3697.2429491138255, 3693.206278169726, 3665.280722101907, 3647.7022425429823, 3612.9444926261112, 3603.629826533842, 3576.9682769508013, 3580.982852335248, 3549.7571666632743, 3552.0220627313743, 3504.7607322241847, 3503.5139212280715, 3472.785253620297, 3474.43760623033, 3455.85741500763, 3451.1150989076873, 3433.5025142003697, 3435.9880076134586, 3403.3540271539855, 3387.296942986961, 3376.4898297518234, 3364.2172755081583, 3353.9476088246197, 3344.9297315750046, 3326.588668743029, 3328.694632382715, 3310.822063972004, 3289.604393849016, 3294.79244563655, 3264.4414592976173, 3267.3251390901314, 3280.3719246904866, 3242.419845849839, 3249.0318005378977, 3233.215556650532, 3229.440271647931, 3218.519685889658, 3206.569857249673, 3211.058928145877, 3197.2057195485963, 3190.415521804822, 3181.069686860096, 3163.7131765890326, 3169.316756080572, 3152.8278468490075, 3174.2973674804775, 3148.729719418634, 3147.7576283982, 3134.425690443107, 3115.731379351976, 3135.7487090920913, 3119.252357421695, 3124.7082372839727, 3101.339503409908, 3091.645179597256, 3092.7202735991646, 3097.0725721235945, 3072.0082027242156, 3085.7649983693937, 3071.4774506648155, 3054.7146591303326, 3045.7841410726173, 3051.845590342524, 3051.7375114291044, 3033.7569037218173, 3030.168200810809, 3068.1434434135936, 3019.199657315996, 3016.7815563072086, 3016.833439679996, 3001.2524473166914, 2998.9286992967454, 3006.7676225490018, 3012.66291913922, 3007.368193547158, 2984.7064815902254, 2984.9441775039018, 2988.2722625718347, 2979.952576860053, 2965.3949416485216, 2983.496240092524, 2964.331286658245, 2948.5474020424863, 2956.949852326782, 2962.593679221059, 2942.425492617825, 2948.7826541407044, 2947.2261568298313, 2931.2256258132766, 2927.9863780428977, 2928.961023589798, 2917.1377506905196, 2934.9489979021423, 2925.5061532083632, 2933.406294300164, 2903.778873743699, 2907.074883342526, 2904.7527764663478, 2918.119519838908, 2889.6823080770537, 2887.820173193715, 2884.8958551100254, 2902.6911731647147, 2903.666014487944, 2904.6916485443157, 2880.7815502278977, 2889.6169256843414, 2892.934850129674, 2879.42263374304, 2860.957960044877, 2868.9585015426137, 2862.3434684378385, 2854.1548580516915, 2847.2494771679994, 2851.7401951972183, 2857.078766761336, 2854.8740292691355, 2849.0268524290946, 2843.707527693288, 2842.1390453698527, 2853.492369778007, 2845.775951497726, 2840.4208859861706, 2846.809564311995, 2825.5632736598677, 2833.085967682653, 2820.461698877408, 2813.9067203923146, 2813.266803294302, 2810.36181233086, 2817.7522476113263, 2809.5025715485367, 2814.5871470802376, 2815.1779384259466, 2795.6285913754664, 2811.9095149164677, 2801.477756183965, 2811.115735231417, 2795.557498291939, 2788.3211240092073, 2799.519942143873, 2789.85489427763, 2799.484934082707, 2771.023163210496, 2784.5839537645434, 2779.8855238163987, 2772.1718940485075, 2777.1595070021053, 2767.0544631846833, 2771.1737719138896, 2768.1954768890714], 'acc': [0.3869473115214395, 0.8552048607669852, 0.879455974667558, 0.8881960155382749, 0.8946070311078943, 0.899362848307015, 0.9027447244299301, 0.9052784203834379, 0.9075668279858387, 0.909304986121656, 0.9108594106449298, 0.911967175847697, 0.9132135288803096, 0.9142891496219264, 0.9149127573827575, 0.9157411902359598, 0.9164262560145459, 0.9169778969359774, 0.9178276128801024, 0.918923828738824, 0.9197721974849481, 0.9201279479529622, 0.9207784477210755, 0.9209709688821842, 0.9215678413569746, 0.9217668105170019, 0.9221028821457139, 0.9225046593281194, 0.9225266705818813, 0.922827382275927, 0.9229363925362671, 0.9231910082419442, 0.9232990837653471, 0.9237229220213886, 0.9236565006347662, 0.9238704150314317, 0.9240446234446417, 0.9243159127182641, 0.9243739776304373, 0.9245064830874579, 0.9246430247898395, 0.9246666330720824, 0.9248362561383943, 0.9251314451814764, 0.9251449669373824, 0.9253956153913253, 0.925561643620869, 0.925712378204479, 0.9257818331723282, 0.9259691432559555, 0.9261262808945042, 0.9262116341136604, 0.9265279915019902, 0.9265089714251178, 0.9266125057265403, 0.926810365139663, 0.9270122231322769, 0.9272139403451295, 0.9273231502862519, 0.9274717506299893, 0.9277036654699622, 0.9276978135669648, 0.9278461965238829, 0.9278333138399301, 0.927868588630601, 0.9282113959304875, 0.9280858048706228, 0.9284942997982831, 0.9284372384902418, 0.9285245628349458, 0.9284152223111123, 0.928417327993747, 0.9286849372426291, 0.9287369923761802, 0.9289204211711312, 0.9289697259101086, 0.9289484660057941, 0.9290367494614089, 0.9287963148402649, 0.9287846558023443, 0.9288768630169375, 0.9289213770167871, 0.9290675605441727, 0.9288994967250337, 0.9290586520932229, 0.9290935011419282, 0.9292035046994087, 0.9293462308165794, 0.9293219567191763, 0.929453287294603, 0.9294790519259023, 0.9294863876783682, 0.9295362687073521, 0.9298286435074838, 0.9299632981343978, 0.9299276536827893, 0.9299657844391123, 0.9302261867701738, 0.930273276176618, 0.9300866508620214, 0.9303900234309838, 0.9304884078152382, 0.9306182784863991, 0.9307295050687437, 0.9308011325964857, 0.930775882710085, 0.9309328428045208, 0.9310418260742859, 0.9309368798414588, 0.9312652551653992, 0.9310850824232769, 0.9311463368793239, 0.9313093025856085, 0.9311473330679189, 0.9313750114265452, 0.9316628659430063, 0.9317074661367902, 0.9318082083319316, 0.931870789872229, 0.931853230441726, 0.9318642777665717, 0.9320567492232446, 0.9321701049771706, 0.9322175918047162, 0.932296228207621, 0.9321771114830996, 0.93236288867247, 0.9323833728258784, 0.9326980083969195, 0.9325197833078896, 0.9327673078253954, 0.9326686954285005, 0.9330376423087978, 0.9329165071839942, 0.9331721677272663, 0.9328819673285431, 0.9329110359745383, 0.93304478188211, 0.9334355876870803, 0.9335106541713994, 0.933539714885134, 0.9336637770526031, 0.9336704057509484, 0.9336695862544218, 0.93365102863989, 0.9338625277373928, 0.9339316292386494, 0.9340968811071129, 0.9341030467824172, 0.9343354731130279, 0.9343996741922758, 0.9343790319488573, 0.9344106478290035, 0.9341849866173292, 0.9345777634763854, 0.934486773773103, 0.9346033690282035, 0.9346629834742407, 0.9346783700590038, 0.934781368677218, 0.9348584080956183, 0.9348243992453757, 0.9349883420434614, 0.934889687676497, 0.9348708211380673, 0.9348786033894054, 0.9350896584507197, 0.9351286736403643, 0.934975351028905, 0.9350221747348507, 0.935126236787221, 0.9350895024660845, 0.9351976897557547, 0.9350504414089533, 0.935263001439449, 0.9352817588227158, 0.9355222094018312, 0.9352605843152616, 0.9352294143952754, 0.9355301899981655, 0.9355502748065007, 0.9355946373567913, 0.9354433522204197, 0.9357289848628436], 'mDice': [0.052275819255067094, 0.20415344396486698, 0.29991199075213704, 0.35292406619436173, 0.3933097978013364, 0.42423772556825967, 0.4517972419224113, 0.46993774664332744, 0.4867067560794047, 0.502033047682463, 0.5141926910850182, 0.5236960472759808, 0.5325166850273408, 0.5405825631079568, 0.5480613500817086, 0.5549192772595016, 0.5605744361481653, 0.5643081171073059, 0.5697041242245564, 0.5754000124627457, 0.5799649331079993, 0.5826652041442894, 0.5872713883710525, 0.5897835837038946, 0.594314855935773, 0.5961279849070283, 0.599048960036285, 0.6022409564244025, 0.60254449062898, 0.6059937605468217, 0.6068640341895495, 0.6093247914230715, 0.6110380049573312, 0.6155113998477907, 0.6160778164654698, 0.6181753594574316, 0.6198796867323815, 0.622496516136383, 0.623099582887692, 0.6254149924935883, 0.6251065913551047, 0.6275848168228689, 0.6274582780694913, 0.6310674829763602, 0.6312132777460143, 0.6339598328141745, 0.6335955546822021, 0.6353298670953351, 0.6356325224296178, 0.6373260893263655, 0.6369785684880918, 0.6396356939192046, 0.6409518530170251, 0.6418809742436333, 0.6426858953869805, 0.6436927941719962, 0.6442879277116466, 0.645870386515224, 0.6456943900451266, 0.6472275989649097, 0.6488383146083455, 0.6485347175778449, 0.6511384962691951, 0.6507963845785458, 0.6498045776093302, 0.652882284457576, 0.6524262049865934, 0.6537640540019113, 0.6539554880035438, 0.6550711728512202, 0.6558679139648187, 0.6556608951708537, 0.6564663413056234, 0.6574624446961511, 0.6579791063324811, 0.6596926830136599, 0.6592571062431734, 0.6604952026609674, 0.6589836908103597, 0.660673448787254, 0.6610549747817446, 0.6622972128950427, 0.6636660171370878, 0.6622259340019757, 0.663555350859293, 0.6629598993145979, 0.6648595692937053, 0.665657239388817, 0.665753432033929, 0.6653374655378884, 0.6674056227803286, 0.6664231992686992, 0.6673458867172886, 0.6687946791997599, 0.6696914801581764, 0.669022197165107, 0.6691254102402064, 0.6708346770597562, 0.6709952578381464, 0.6688364371210735, 0.6719082043771868, 0.6722559456861317, 0.67218711947225, 0.6735591505942151, 0.6737117810650834, 0.6732883542916283, 0.672675452207734, 0.6730354197744535, 0.6748981983483767, 0.6749968094094855, 0.6745074897094768, 0.6752527519850277, 0.6765198485939021, 0.6751041164545954, 0.6766488770326873, 0.6780102966258988, 0.6772124317643784, 0.6769848059301808, 0.678596349260766, 0.6781879396310188, 0.6782164342682883, 0.6796093842018621, 0.6798402000801662, 0.679591892533644, 0.6807570574710832, 0.6792832103963379, 0.6799573960377261, 0.6795619041192117, 0.681988392590399, 0.6818192829167086, 0.682049069915389, 0.6807507379000273, 0.6832013308347772, 0.6833315901867107, 0.6836756423842717, 0.6820887242209633, 0.6819556449641054, 0.681823886607303, 0.683964216746517, 0.6832895078892572, 0.6828420155824335, 0.6842536959691669, 0.685657346929163, 0.6849264433647141, 0.6855689575891373, 0.6863251038168471, 0.6869398259560274, 0.6863237425793496, 0.685978879817988, 0.6862176570858912, 0.6866719306400316, 0.6873179886774923, 0.687442480039082, 0.6863312968345384, 0.6870282907927047, 0.6874496804208957, 0.6869024587691209, 0.6888061676761558, 0.688100221587384, 0.6892741561034921, 0.6896804734854244, 0.6895844790863614, 0.6900147269113602, 0.6895200465203299, 0.6901241925703163, 0.6897190872356151, 0.6897923871895423, 0.6912800997514891, 0.6898721312229829, 0.6910042816297733, 0.6900868201996803, 0.6914595829201483, 0.6920393213490922, 0.6910886434702639, 0.6919556895294477, 0.6911475365643218, 0.6936397475091599, 0.6924754106326703, 0.6928185439578152, 0.693518205068543, 0.6929845941096426, 0.6939928129151839, 0.6936143000308608, 0.6939276467936951]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.20s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.97s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.78s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:23,  1.77s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:42,  1.64s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:40,  1.63s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:11,  1.54s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:27,  1.60s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:09,  1.54s/it]predicting train subjects:   2%|▏         | 7/285 [00:10<07:22,  1.59s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:18,  1.58s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:37,  1.66s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<07:53,  1.72s/it]predicting train subjects:   4%|▍         | 11/285 [00:17<07:31,  1.65s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<07:46,  1.71s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:39,  1.69s/it]predicting train subjects:   5%|▍         | 14/285 [00:22<07:49,  1.73s/it]predicting train subjects:   5%|▌         | 15/285 [00:24<08:03,  1.79s/it]predicting train subjects:   6%|▌         | 16/285 [00:26<08:04,  1.80s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<07:37,  1.71s/it]predicting train subjects:   6%|▋         | 18/285 [00:29<07:35,  1.71s/it]predicting train subjects:   7%|▋         | 19/285 [00:31<07:20,  1.66s/it]predicting train subjects:   7%|▋         | 20/285 [00:33<07:35,  1.72s/it]predicting train subjects:   7%|▋         | 21/285 [00:35<07:51,  1.78s/it]predicting train subjects:   8%|▊         | 22/285 [00:36<07:31,  1.72s/it]predicting train subjects:   8%|▊         | 23/285 [00:38<07:32,  1.73s/it]predicting train subjects:   8%|▊         | 24/285 [00:40<07:20,  1.69s/it]predicting train subjects:   9%|▉         | 25/285 [00:41<07:29,  1.73s/it]predicting train subjects:   9%|▉         | 26/285 [00:43<07:35,  1.76s/it]predicting train subjects:   9%|▉         | 27/285 [00:45<07:16,  1.69s/it]predicting train subjects:  10%|▉         | 28/285 [00:47<07:16,  1.70s/it]predicting train subjects:  10%|█         | 29/285 [00:48<07:13,  1.69s/it]predicting train subjects:  11%|█         | 30/285 [00:50<07:24,  1.74s/it]predicting train subjects:  11%|█         | 31/285 [00:52<07:25,  1.75s/it]predicting train subjects:  11%|█         | 32/285 [00:53<07:01,  1.67s/it]predicting train subjects:  12%|█▏        | 33/285 [00:55<07:05,  1.69s/it]predicting train subjects:  12%|█▏        | 34/285 [00:57<07:06,  1.70s/it]predicting train subjects:  12%|█▏        | 35/285 [00:59<07:20,  1.76s/it]predicting train subjects:  13%|█▎        | 36/285 [01:00<06:57,  1.68s/it]predicting train subjects:  13%|█▎        | 37/285 [01:02<06:56,  1.68s/it]predicting train subjects:  13%|█▎        | 38/285 [01:04<07:04,  1.72s/it]predicting train subjects:  14%|█▎        | 39/285 [01:05<06:40,  1.63s/it]predicting train subjects:  14%|█▍        | 40/285 [01:07<06:43,  1.65s/it]predicting train subjects:  14%|█▍        | 41/285 [01:08<06:31,  1.60s/it]predicting train subjects:  15%|█▍        | 42/285 [01:10<06:28,  1.60s/it]predicting train subjects:  15%|█▌        | 43/285 [01:12<06:34,  1.63s/it]predicting train subjects:  15%|█▌        | 44/285 [01:13<06:48,  1.70s/it]predicting train subjects:  16%|█▌        | 45/285 [01:15<06:38,  1.66s/it]predicting train subjects:  16%|█▌        | 46/285 [01:17<06:55,  1.74s/it]predicting train subjects:  16%|█▋        | 47/285 [01:19<06:46,  1.71s/it]predicting train subjects:  17%|█▋        | 48/285 [01:20<06:50,  1.73s/it]predicting train subjects:  17%|█▋        | 49/285 [01:22<07:08,  1.81s/it]predicting train subjects:  18%|█▊        | 50/285 [01:24<06:58,  1.78s/it]predicting train subjects:  18%|█▊        | 51/285 [01:26<07:02,  1.81s/it]predicting train subjects:  18%|█▊        | 52/285 [01:27<06:43,  1.73s/it]predicting train subjects:  19%|█▊        | 53/285 [01:29<06:40,  1.73s/it]predicting train subjects:  19%|█▉        | 54/285 [01:31<06:52,  1.79s/it]predicting train subjects:  19%|█▉        | 55/285 [01:33<06:32,  1.71s/it]predicting train subjects:  20%|█▉        | 56/285 [01:34<06:36,  1.73s/it]predicting train subjects:  20%|██        | 57/285 [01:36<06:21,  1.67s/it]predicting train subjects:  20%|██        | 58/285 [01:38<06:23,  1.69s/it]predicting train subjects:  21%|██        | 59/285 [01:40<06:33,  1.74s/it]predicting train subjects:  21%|██        | 60/285 [01:41<06:38,  1.77s/it]predicting train subjects:  21%|██▏       | 61/285 [01:43<06:25,  1.72s/it]predicting train subjects:  22%|██▏       | 62/285 [01:45<06:25,  1.73s/it]predicting train subjects:  22%|██▏       | 63/285 [01:47<06:26,  1.74s/it]predicting train subjects:  22%|██▏       | 64/285 [01:48<06:16,  1.70s/it]predicting train subjects:  23%|██▎       | 65/285 [01:50<06:17,  1.72s/it]predicting train subjects:  23%|██▎       | 66/285 [01:52<06:19,  1.73s/it]predicting train subjects:  24%|██▎       | 67/285 [01:53<06:16,  1.73s/it]predicting train subjects:  24%|██▍       | 68/285 [01:55<06:04,  1.68s/it]predicting train subjects:  24%|██▍       | 69/285 [01:57<06:08,  1.70s/it]predicting train subjects:  25%|██▍       | 70/285 [01:58<06:08,  1.71s/it]predicting train subjects:  25%|██▍       | 71/285 [02:00<06:09,  1.73s/it]predicting train subjects:  25%|██▌       | 72/285 [02:02<05:55,  1.67s/it]predicting train subjects:  26%|██▌       | 73/285 [02:04<06:03,  1.72s/it]predicting train subjects:  26%|██▌       | 74/285 [02:05<06:04,  1.73s/it]predicting train subjects:  26%|██▋       | 75/285 [02:07<06:04,  1.73s/it]predicting train subjects:  27%|██▋       | 76/285 [02:09<06:06,  1.75s/it]predicting train subjects:  27%|██▋       | 77/285 [02:10<05:52,  1.69s/it]predicting train subjects:  27%|██▋       | 78/285 [02:12<05:40,  1.65s/it]predicting train subjects:  28%|██▊       | 79/285 [02:14<05:41,  1.66s/it]predicting train subjects:  28%|██▊       | 80/285 [02:15<05:42,  1.67s/it]predicting train subjects:  28%|██▊       | 81/285 [02:17<05:30,  1.62s/it]predicting train subjects:  29%|██▉       | 82/285 [02:18<05:31,  1.63s/it]predicting train subjects:  29%|██▉       | 83/285 [02:20<05:25,  1.61s/it]predicting train subjects:  29%|██▉       | 84/285 [02:22<05:20,  1.60s/it]predicting train subjects:  30%|██▉       | 85/285 [02:23<05:29,  1.65s/it]predicting train subjects:  30%|███       | 86/285 [02:25<05:42,  1.72s/it]predicting train subjects:  31%|███       | 87/285 [02:27<05:40,  1.72s/it]predicting train subjects:  31%|███       | 88/285 [02:29<05:26,  1.66s/it]predicting train subjects:  31%|███       | 89/285 [02:30<05:26,  1.66s/it]predicting train subjects:  32%|███▏      | 90/285 [02:32<05:28,  1.69s/it]predicting train subjects:  32%|███▏      | 91/285 [02:34<05:23,  1.67s/it]predicting train subjects:  32%|███▏      | 92/285 [02:35<05:27,  1.70s/it]predicting train subjects:  33%|███▎      | 93/285 [02:37<05:20,  1.67s/it]predicting train subjects:  33%|███▎      | 94/285 [02:39<05:22,  1.69s/it]predicting train subjects:  33%|███▎      | 95/285 [02:40<05:22,  1.70s/it]predicting train subjects:  34%|███▎      | 96/285 [02:42<05:20,  1.69s/it]predicting train subjects:  34%|███▍      | 97/285 [02:44<05:19,  1.70s/it]predicting train subjects:  34%|███▍      | 98/285 [02:46<05:19,  1.71s/it]predicting train subjects:  35%|███▍      | 99/285 [02:47<05:19,  1.72s/it]predicting train subjects:  35%|███▌      | 100/285 [02:49<05:18,  1.72s/it]predicting train subjects:  35%|███▌      | 101/285 [02:51<05:06,  1.67s/it]predicting train subjects:  36%|███▌      | 102/285 [02:52<05:10,  1.70s/it]predicting train subjects:  36%|███▌      | 103/285 [02:54<05:02,  1.66s/it]predicting train subjects:  36%|███▋      | 104/285 [02:56<05:03,  1.68s/it]predicting train subjects:  37%|███▋      | 105/285 [02:57<05:08,  1.71s/it]predicting train subjects:  37%|███▋      | 106/285 [02:59<05:00,  1.68s/it]predicting train subjects:  38%|███▊      | 107/285 [03:01<05:01,  1.69s/it]predicting train subjects:  38%|███▊      | 108/285 [03:02<04:49,  1.64s/it]predicting train subjects:  38%|███▊      | 109/285 [03:04<04:53,  1.66s/it]predicting train subjects:  39%|███▊      | 110/285 [03:06<04:51,  1.67s/it]predicting train subjects:  39%|███▉      | 111/285 [03:07<04:43,  1.63s/it]predicting train subjects:  39%|███▉      | 112/285 [03:09<04:43,  1.64s/it]predicting train subjects:  40%|███▉      | 113/285 [03:11<04:46,  1.66s/it]predicting train subjects:  40%|████      | 114/285 [03:12<04:48,  1.69s/it]predicting train subjects:  40%|████      | 115/285 [03:14<04:45,  1.68s/it]predicting train subjects:  41%|████      | 116/285 [03:16<04:42,  1.67s/it]predicting train subjects:  41%|████      | 117/285 [03:17<04:31,  1.62s/it]predicting train subjects:  41%|████▏     | 118/285 [03:19<04:36,  1.65s/it]predicting train subjects:  42%|████▏     | 119/285 [03:21<04:37,  1.67s/it]predicting train subjects:  42%|████▏     | 120/285 [03:22<04:27,  1.62s/it]predicting train subjects:  42%|████▏     | 121/285 [03:24<04:24,  1.61s/it]predicting train subjects:  43%|████▎     | 122/285 [03:25<04:11,  1.54s/it]predicting train subjects:  43%|████▎     | 123/285 [03:26<04:00,  1.48s/it]predicting train subjects:  44%|████▎     | 124/285 [03:28<04:00,  1.49s/it]predicting train subjects:  44%|████▍     | 125/285 [03:29<03:54,  1.47s/it]predicting train subjects:  44%|████▍     | 126/285 [03:31<03:54,  1.47s/it]predicting train subjects:  45%|████▍     | 127/285 [03:32<03:49,  1.45s/it]predicting train subjects:  45%|████▍     | 128/285 [03:34<03:54,  1.49s/it]predicting train subjects:  45%|████▌     | 129/285 [03:35<03:52,  1.49s/it]predicting train subjects:  46%|████▌     | 130/285 [03:37<03:49,  1.48s/it]predicting train subjects:  46%|████▌     | 131/285 [03:38<03:45,  1.47s/it]predicting train subjects:  46%|████▋     | 132/285 [03:40<03:47,  1.49s/it]predicting train subjects:  47%|████▋     | 133/285 [03:41<03:41,  1.46s/it]predicting train subjects:  47%|████▋     | 134/285 [03:42<03:38,  1.45s/it]predicting train subjects:  47%|████▋     | 135/285 [03:44<03:31,  1.41s/it]predicting train subjects:  48%|████▊     | 136/285 [03:45<03:33,  1.43s/it]predicting train subjects:  48%|████▊     | 137/285 [03:47<03:41,  1.50s/it]predicting train subjects:  48%|████▊     | 138/285 [03:48<03:33,  1.45s/it]predicting train subjects:  49%|████▉     | 139/285 [03:50<03:36,  1.48s/it]predicting train subjects:  49%|████▉     | 140/285 [03:51<03:39,  1.51s/it]predicting train subjects:  49%|████▉     | 141/285 [03:53<03:32,  1.48s/it]predicting train subjects:  50%|████▉     | 142/285 [03:54<03:29,  1.46s/it]predicting train subjects:  50%|█████     | 143/285 [03:56<03:27,  1.46s/it]predicting train subjects:  51%|█████     | 144/285 [03:57<03:30,  1.49s/it]predicting train subjects:  51%|█████     | 145/285 [03:59<03:25,  1.47s/it]predicting train subjects:  51%|█████     | 146/285 [04:00<03:28,  1.50s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:02<03:23,  1.48s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:03<03:26,  1.50s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:05<03:21,  1.48s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:06<03:17,  1.46s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:08<03:17,  1.47s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:09<03:12,  1.44s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:10<03:10,  1.44s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:12<03:17,  1.51s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:13<03:12,  1.48s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:15<03:15,  1.52s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:16<03:09,  1.48s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:18<03:06,  1.47s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:19<03:00,  1.43s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:21<02:57,  1.42s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:22<02:58,  1.44s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:24<02:54,  1.42s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:25<02:55,  1.44s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:26<02:53,  1.43s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:28<02:49,  1.42s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:29<02:51,  1.44s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:31<02:54,  1.48s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:32<02:47,  1.43s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:34<02:45,  1.43s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:35<02:44,  1.43s/it]predicting train subjects:  60%|██████    | 171/285 [04:36<02:40,  1.40s/it]predicting train subjects:  60%|██████    | 172/285 [04:38<02:38,  1.40s/it]predicting train subjects:  61%|██████    | 173/285 [04:39<02:35,  1.39s/it]predicting train subjects:  61%|██████    | 174/285 [04:40<02:32,  1.38s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:42<02:38,  1.44s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:44<02:46,  1.52s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:45<02:38,  1.47s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:46<02:32,  1.43s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:48<02:31,  1.43s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:50<02:39,  1.52s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:51<02:39,  1.53s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:53<02:39,  1.55s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:54<02:31,  1.49s/it]predicting train subjects:  65%|██████▍   | 184/285 [04:55<02:26,  1.45s/it]predicting train subjects:  65%|██████▍   | 185/285 [04:57<02:22,  1.43s/it]predicting train subjects:  65%|██████▌   | 186/285 [04:59<02:33,  1.55s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:01<02:41,  1.65s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:02<02:43,  1.68s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:04<02:32,  1.59s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:05<02:24,  1.53s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:07<02:27,  1.56s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:08<02:27,  1.58s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:10<02:18,  1.51s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:11<02:12,  1.45s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:12<02:06,  1.41s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:14<02:16,  1.53s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:16<02:21,  1.61s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:18<02:24,  1.66s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:19<02:13,  1.56s/it]predicting train subjects:  70%|███████   | 200/285 [05:20<02:07,  1.50s/it]predicting train subjects:  71%|███████   | 201/285 [05:22<02:13,  1.58s/it]predicting train subjects:  71%|███████   | 202/285 [05:24<02:15,  1.64s/it]predicting train subjects:  71%|███████   | 203/285 [05:26<02:13,  1.63s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:27<02:04,  1.54s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:28<01:59,  1.49s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:30<01:52,  1.42s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:31<01:59,  1.53s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:33<02:02,  1.59s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:35<02:03,  1.62s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:36<01:53,  1.51s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:37<01:48,  1.47s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:39<01:50,  1.52s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:41<01:50,  1.54s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:42<01:44,  1.47s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:44<01:48,  1.56s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:45<01:42,  1.49s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:47<01:47,  1.57s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:48<01:48,  1.62s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:50<01:49,  1.66s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:52<01:41,  1.56s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:53<01:37,  1.53s/it]predicting train subjects:  78%|███████▊  | 222/285 [05:55<01:37,  1.54s/it]predicting train subjects:  78%|███████▊  | 223/285 [05:56<01:32,  1.48s/it]predicting train subjects:  79%|███████▊  | 224/285 [05:57<01:28,  1.45s/it]predicting train subjects:  79%|███████▉  | 225/285 [05:59<01:25,  1.42s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:00<01:30,  1.53s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:02<01:33,  1.61s/it]predicting train subjects:  80%|████████  | 228/285 [06:04<01:33,  1.64s/it]predicting train subjects:  80%|████████  | 229/285 [06:06<01:31,  1.63s/it]predicting train subjects:  81%|████████  | 230/285 [06:07<01:24,  1.53s/it]predicting train subjects:  81%|████████  | 231/285 [06:08<01:21,  1.51s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:10<01:20,  1.53s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:11<01:16,  1.47s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:13<01:18,  1.55s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:14<01:15,  1.50s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:16<01:18,  1.60s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:18<01:18,  1.64s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:20<01:18,  1.67s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:21<01:17,  1.69s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:23<01:11,  1.60s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:24<01:07,  1.54s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:26<01:04,  1.50s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:27<01:01,  1.47s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:29<01:04,  1.56s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:30<01:00,  1.50s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:32<01:02,  1.61s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:34<01:02,  1.65s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:35<01:01,  1.66s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:37<00:56,  1.57s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:38<00:53,  1.52s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:40<00:50,  1.47s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:41<00:47,  1.43s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:43<00:49,  1.54s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:44<00:49,  1.60s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:46<00:47,  1.60s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:47<00:44,  1.54s/it]predicting train subjects:  90%|█████████ | 257/285 [06:49<00:42,  1.50s/it]predicting train subjects:  91%|█████████ | 258/285 [06:51<00:42,  1.57s/it]predicting train subjects:  91%|█████████ | 259/285 [06:52<00:41,  1.59s/it]predicting train subjects:  91%|█████████ | 260/285 [06:54<00:38,  1.53s/it]predicting train subjects:  92%|█████████▏| 261/285 [06:55<00:36,  1.51s/it]predicting train subjects:  92%|█████████▏| 262/285 [06:56<00:33,  1.47s/it]predicting train subjects:  92%|█████████▏| 263/285 [06:58<00:31,  1.44s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:00<00:32,  1.57s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:01<00:32,  1.63s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:03<00:29,  1.55s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:04<00:27,  1.51s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:06<00:27,  1.61s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:08<00:25,  1.61s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:09<00:22,  1.52s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:10<00:20,  1.48s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:12<00:19,  1.51s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:13<00:17,  1.46s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:15<00:15,  1.42s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:16<00:15,  1.55s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:18<00:14,  1.61s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:20<00:12,  1.53s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:21<00:10,  1.50s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:23<00:09,  1.54s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:24<00:07,  1.49s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:25<00:06,  1.50s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:27<00:04,  1.46s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:29<00:03,  1.57s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:30<00:01,  1.63s/it]predicting train subjects: 100%|██████████| 285/285 [07:32<00:00,  1.67s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:41,  1.84s/it]Loading train:   1%|          | 2/285 [00:03<07:51,  1.67s/it]Loading train:   1%|          | 3/285 [00:04<07:26,  1.58s/it]Loading train:   1%|▏         | 4/285 [00:05<06:47,  1.45s/it]Loading train:   2%|▏         | 5/285 [00:07<07:01,  1.50s/it]Loading train:   2%|▏         | 6/285 [00:08<06:43,  1.45s/it]Loading train:   2%|▏         | 7/285 [00:10<06:51,  1.48s/it]Loading train:   3%|▎         | 8/285 [00:11<06:30,  1.41s/it]Loading train:   3%|▎         | 9/285 [00:13<06:47,  1.48s/it]Loading train:   4%|▎         | 10/285 [00:14<06:30,  1.42s/it]Loading train:   4%|▍         | 11/285 [00:15<05:39,  1.24s/it]Loading train:   4%|▍         | 12/285 [00:16<05:35,  1.23s/it]Loading train:   5%|▍         | 13/285 [00:17<05:08,  1.13s/it]Loading train:   5%|▍         | 14/285 [00:18<04:58,  1.10s/it]Loading train:   5%|▌         | 15/285 [00:19<05:05,  1.13s/it]Loading train:   6%|▌         | 16/285 [00:20<04:51,  1.08s/it]Loading train:   6%|▌         | 17/285 [00:21<04:40,  1.05s/it]Loading train:   6%|▋         | 18/285 [00:22<04:43,  1.06s/it]Loading train:   7%|▋         | 19/285 [00:23<04:41,  1.06s/it]Loading train:   7%|▋         | 20/285 [00:24<04:42,  1.07s/it]Loading train:   7%|▋         | 21/285 [00:25<04:56,  1.12s/it]Loading train:   8%|▊         | 22/285 [00:26<04:34,  1.04s/it]Loading train:   8%|▊         | 23/285 [00:27<04:27,  1.02s/it]Loading train:   8%|▊         | 24/285 [00:28<03:57,  1.10it/s]Loading train:   9%|▉         | 25/285 [00:29<04:20,  1.00s/it]Loading train:   9%|▉         | 26/285 [00:30<04:17,  1.01it/s]Loading train:   9%|▉         | 27/285 [00:31<04:10,  1.03it/s]Loading train:  10%|▉         | 28/285 [00:32<04:17,  1.00s/it]Loading train:  10%|█         | 29/285 [00:33<04:16,  1.00s/it]Loading train:  11%|█         | 30/285 [00:34<04:27,  1.05s/it]Loading train:  11%|█         | 31/285 [00:35<04:26,  1.05s/it]Loading train:  11%|█         | 32/285 [00:36<04:12,  1.00it/s]Loading train:  12%|█▏        | 33/285 [00:37<04:10,  1.01it/s]Loading train:  12%|█▏        | 34/285 [00:38<04:19,  1.03s/it]Loading train:  12%|█▏        | 35/285 [00:39<04:33,  1.09s/it]Loading train:  13%|█▎        | 36/285 [00:40<04:12,  1.01s/it]Loading train:  13%|█▎        | 37/285 [00:41<04:22,  1.06s/it]Loading train:  13%|█▎        | 38/285 [00:42<04:18,  1.05s/it]Loading train:  14%|█▎        | 39/285 [00:43<04:03,  1.01it/s]Loading train:  14%|█▍        | 40/285 [00:44<04:06,  1.01s/it]Loading train:  14%|█▍        | 41/285 [00:45<04:05,  1.01s/it]Loading train:  15%|█▍        | 42/285 [00:46<03:49,  1.06it/s]Loading train:  15%|█▌        | 43/285 [00:47<04:04,  1.01s/it]Loading train:  15%|█▌        | 44/285 [00:48<04:09,  1.03s/it]Loading train:  16%|█▌        | 45/285 [00:49<04:05,  1.02s/it]Loading train:  16%|█▌        | 46/285 [00:50<04:00,  1.01s/it]Loading train:  16%|█▋        | 47/285 [00:51<03:49,  1.04it/s]Loading train:  17%|█▋        | 48/285 [00:52<03:51,  1.02it/s]Loading train:  17%|█▋        | 49/285 [00:53<03:58,  1.01s/it]Loading train:  18%|█▊        | 50/285 [00:55<04:11,  1.07s/it]Loading train:  18%|█▊        | 51/285 [00:56<04:08,  1.06s/it]Loading train:  18%|█▊        | 52/285 [00:57<04:09,  1.07s/it]Loading train:  19%|█▊        | 53/285 [00:58<04:17,  1.11s/it]Loading train:  19%|█▉        | 54/285 [00:59<04:12,  1.09s/it]Loading train:  19%|█▉        | 55/285 [01:00<03:58,  1.04s/it]Loading train:  20%|█▉        | 56/285 [01:01<03:54,  1.02s/it]Loading train:  20%|██        | 57/285 [01:02<03:47,  1.00it/s]Loading train:  20%|██        | 58/285 [01:03<03:55,  1.04s/it]Loading train:  21%|██        | 59/285 [01:04<04:14,  1.13s/it]Loading train:  21%|██        | 60/285 [01:05<04:14,  1.13s/it]Loading train:  21%|██▏       | 61/285 [01:06<03:57,  1.06s/it]Loading train:  22%|██▏       | 62/285 [01:08<04:23,  1.18s/it]Loading train:  22%|██▏       | 63/285 [01:09<04:11,  1.13s/it]Loading train:  22%|██▏       | 64/285 [01:10<04:26,  1.20s/it]Loading train:  23%|██▎       | 65/285 [01:12<04:54,  1.34s/it]Loading train:  23%|██▎       | 66/285 [01:13<04:50,  1.33s/it]Loading train:  24%|██▎       | 67/285 [01:14<04:28,  1.23s/it]Loading train:  24%|██▍       | 68/285 [01:15<04:06,  1.14s/it]Loading train:  24%|██▍       | 69/285 [01:16<04:03,  1.13s/it]Loading train:  25%|██▍       | 70/285 [01:17<04:07,  1.15s/it]Loading train:  25%|██▍       | 71/285 [01:18<03:59,  1.12s/it]Loading train:  25%|██▌       | 72/285 [01:19<03:43,  1.05s/it]Loading train:  26%|██▌       | 73/285 [01:20<03:32,  1.00s/it]Loading train:  26%|██▌       | 74/285 [01:21<03:35,  1.02s/it]Loading train:  26%|██▋       | 75/285 [01:23<04:00,  1.14s/it]Loading train:  27%|██▋       | 76/285 [01:24<03:49,  1.10s/it]Loading train:  27%|██▋       | 77/285 [01:25<03:46,  1.09s/it]Loading train:  27%|██▋       | 78/285 [01:26<03:35,  1.04s/it]Loading train:  28%|██▊       | 79/285 [01:27<03:35,  1.04s/it]Loading train:  28%|██▊       | 80/285 [01:28<03:25,  1.00s/it]Loading train:  28%|██▊       | 81/285 [01:29<03:28,  1.02s/it]Loading train:  29%|██▉       | 82/285 [01:30<03:28,  1.02s/it]Loading train:  29%|██▉       | 83/285 [01:31<03:19,  1.01it/s]Loading train:  29%|██▉       | 84/285 [01:31<03:09,  1.06it/s]Loading train:  30%|██▉       | 85/285 [01:32<03:07,  1.07it/s]Loading train:  30%|███       | 86/285 [01:33<03:07,  1.06it/s]Loading train:  31%|███       | 87/285 [01:34<03:08,  1.05it/s]Loading train:  31%|███       | 88/285 [01:35<03:07,  1.05it/s]Loading train:  31%|███       | 89/285 [01:36<03:05,  1.06it/s]Loading train:  32%|███▏      | 90/285 [01:37<03:19,  1.02s/it]Loading train:  32%|███▏      | 91/285 [01:38<03:11,  1.02it/s]Loading train:  32%|███▏      | 92/285 [01:40<03:23,  1.05s/it]Loading train:  33%|███▎      | 93/285 [01:40<03:15,  1.02s/it]Loading train:  33%|███▎      | 94/285 [01:41<03:14,  1.02s/it]Loading train:  33%|███▎      | 95/285 [01:43<03:26,  1.08s/it]Loading train:  34%|███▎      | 96/285 [01:44<03:18,  1.05s/it]Loading train:  34%|███▍      | 97/285 [01:45<03:20,  1.07s/it]Loading train:  34%|███▍      | 98/285 [01:46<03:13,  1.03s/it]Loading train:  35%|███▍      | 99/285 [01:47<03:15,  1.05s/it]Loading train:  35%|███▌      | 100/285 [01:48<03:12,  1.04s/it]Loading train:  35%|███▌      | 101/285 [01:49<03:11,  1.04s/it]Loading train:  36%|███▌      | 102/285 [01:50<03:14,  1.06s/it]Loading train:  36%|███▌      | 103/285 [01:51<03:08,  1.04s/it]Loading train:  36%|███▋      | 104/285 [01:52<03:14,  1.07s/it]Loading train:  37%|███▋      | 105/285 [01:53<03:09,  1.05s/it]Loading train:  37%|███▋      | 106/285 [01:54<03:01,  1.02s/it]Loading train:  38%|███▊      | 107/285 [01:55<02:59,  1.01s/it]Loading train:  38%|███▊      | 108/285 [01:56<02:59,  1.01s/it]Loading train:  38%|███▊      | 109/285 [01:57<03:06,  1.06s/it]Loading train:  39%|███▊      | 110/285 [01:58<03:02,  1.04s/it]Loading train:  39%|███▉      | 111/285 [01:59<02:51,  1.01it/s]Loading train:  39%|███▉      | 112/285 [02:00<02:49,  1.02it/s]Loading train:  40%|███▉      | 113/285 [02:01<02:56,  1.03s/it]Loading train:  40%|████      | 114/285 [02:02<03:06,  1.09s/it]Loading train:  40%|████      | 115/285 [02:03<02:57,  1.04s/it]Loading train:  41%|████      | 116/285 [02:05<03:01,  1.08s/it]Loading train:  41%|████      | 117/285 [02:05<02:53,  1.03s/it]Loading train:  41%|████▏     | 118/285 [02:06<02:46,  1.00it/s]Loading train:  42%|████▏     | 119/285 [02:07<02:51,  1.03s/it]Loading train:  42%|████▏     | 120/285 [02:08<02:46,  1.01s/it]Loading train:  42%|████▏     | 121/285 [02:10<02:59,  1.10s/it]Loading train:  43%|████▎     | 122/285 [02:11<03:05,  1.14s/it]Loading train:  43%|████▎     | 123/285 [02:12<03:12,  1.19s/it]Loading train:  44%|████▎     | 124/285 [02:13<03:07,  1.16s/it]Loading train:  44%|████▍     | 125/285 [02:15<03:06,  1.17s/it]Loading train:  44%|████▍     | 126/285 [02:15<02:42,  1.02s/it]Loading train:  45%|████▍     | 127/285 [02:16<02:30,  1.05it/s]Loading train:  45%|████▍     | 128/285 [02:17<02:24,  1.08it/s]Loading train:  45%|████▌     | 129/285 [02:18<02:13,  1.16it/s]Loading train:  46%|████▌     | 130/285 [02:18<02:07,  1.21it/s]Loading train:  46%|████▌     | 131/285 [02:19<02:04,  1.24it/s]Loading train:  46%|████▋     | 132/285 [02:20<02:06,  1.21it/s]Loading train:  47%|████▋     | 133/285 [02:21<02:06,  1.20it/s]Loading train:  47%|████▋     | 134/285 [02:22<02:06,  1.19it/s]Loading train:  47%|████▋     | 135/285 [02:23<02:11,  1.14it/s]Loading train:  48%|████▊     | 136/285 [02:23<02:02,  1.21it/s]Loading train:  48%|████▊     | 137/285 [02:24<02:07,  1.16it/s]Loading train:  48%|████▊     | 138/285 [02:25<01:58,  1.24it/s]Loading train:  49%|████▉     | 139/285 [02:26<01:59,  1.22it/s]Loading train:  49%|████▉     | 140/285 [02:27<01:54,  1.26it/s]Loading train:  49%|████▉     | 141/285 [02:27<02:00,  1.19it/s]Loading train:  50%|████▉     | 142/285 [02:28<01:56,  1.23it/s]Loading train:  50%|█████     | 143/285 [02:30<02:15,  1.05it/s]Loading train:  51%|█████     | 144/285 [02:31<02:25,  1.03s/it]Loading train:  51%|█████     | 145/285 [02:32<02:23,  1.03s/it]Loading train:  51%|█████     | 146/285 [02:33<02:31,  1.09s/it]Loading train:  52%|█████▏    | 147/285 [02:34<02:42,  1.17s/it]Loading train:  52%|█████▏    | 148/285 [02:36<02:42,  1.18s/it]Loading train:  52%|█████▏    | 149/285 [02:37<02:42,  1.19s/it]Loading train:  53%|█████▎    | 150/285 [02:38<02:44,  1.22s/it]Loading train:  53%|█████▎    | 151/285 [02:39<02:45,  1.24s/it]Loading train:  53%|█████▎    | 152/285 [02:40<02:35,  1.17s/it]Loading train:  54%|█████▎    | 153/285 [02:41<02:33,  1.16s/it]Loading train:  54%|█████▍    | 154/285 [02:43<02:41,  1.23s/it]Loading train:  54%|█████▍    | 155/285 [02:44<02:44,  1.27s/it]Loading train:  55%|█████▍    | 156/285 [02:45<02:37,  1.22s/it]Loading train:  55%|█████▌    | 157/285 [02:47<02:35,  1.22s/it]Loading train:  55%|█████▌    | 158/285 [02:48<02:29,  1.18s/it]Loading train:  56%|█████▌    | 159/285 [02:49<02:28,  1.18s/it]Loading train:  56%|█████▌    | 160/285 [02:50<02:31,  1.21s/it]Loading train:  56%|█████▋    | 161/285 [02:51<02:34,  1.25s/it]Loading train:  57%|█████▋    | 162/285 [02:53<02:29,  1.21s/it]Loading train:  57%|█████▋    | 163/285 [02:54<02:25,  1.20s/it]Loading train:  58%|█████▊    | 164/285 [02:55<02:17,  1.13s/it]Loading train:  58%|█████▊    | 165/285 [02:56<02:09,  1.08s/it]Loading train:  58%|█████▊    | 166/285 [02:57<02:17,  1.16s/it]Loading train:  59%|█████▊    | 167/285 [02:58<02:13,  1.13s/it]Loading train:  59%|█████▉    | 168/285 [02:59<02:09,  1.10s/it]Loading train:  59%|█████▉    | 169/285 [03:00<02:11,  1.14s/it]Loading train:  60%|█████▉    | 170/285 [03:01<02:02,  1.07s/it]Loading train:  60%|██████    | 171/285 [03:02<01:59,  1.05s/it]Loading train:  60%|██████    | 172/285 [03:03<01:56,  1.03s/it]Loading train:  61%|██████    | 173/285 [03:04<01:55,  1.04s/it]Loading train:  61%|██████    | 174/285 [03:05<01:55,  1.04s/it]Loading train:  61%|██████▏   | 175/285 [03:07<02:01,  1.11s/it]Loading train:  62%|██████▏   | 176/285 [03:08<02:02,  1.13s/it]Loading train:  62%|██████▏   | 177/285 [03:09<02:03,  1.14s/it]Loading train:  62%|██████▏   | 178/285 [03:10<01:58,  1.11s/it]Loading train:  63%|██████▎   | 179/285 [03:11<01:55,  1.09s/it]Loading train:  63%|██████▎   | 180/285 [03:12<02:00,  1.14s/it]Loading train:  64%|██████▎   | 181/285 [03:14<02:18,  1.33s/it]Loading train:  64%|██████▍   | 182/285 [03:15<02:13,  1.30s/it]Loading train:  64%|██████▍   | 183/285 [03:16<02:09,  1.27s/it]Loading train:  65%|██████▍   | 184/285 [03:17<01:59,  1.18s/it]Loading train:  65%|██████▍   | 185/285 [03:18<01:49,  1.10s/it]Loading train:  65%|██████▌   | 186/285 [03:20<02:03,  1.25s/it]Loading train:  66%|██████▌   | 187/285 [03:21<02:01,  1.24s/it]Loading train:  66%|██████▌   | 188/285 [03:22<02:01,  1.25s/it]Loading train:  66%|██████▋   | 189/285 [03:24<01:55,  1.21s/it]Loading train:  67%|██████▋   | 190/285 [03:25<01:53,  1.20s/it]Loading train:  67%|██████▋   | 191/285 [03:26<02:05,  1.33s/it]Loading train:  67%|██████▋   | 192/285 [03:28<01:58,  1.27s/it]Loading train:  68%|██████▊   | 193/285 [03:28<01:48,  1.18s/it]Loading train:  68%|██████▊   | 194/285 [03:30<01:49,  1.20s/it]Loading train:  68%|██████▊   | 195/285 [03:31<01:54,  1.27s/it]Loading train:  69%|██████▉   | 196/285 [03:32<01:53,  1.28s/it]Loading train:  69%|██████▉   | 197/285 [03:34<01:56,  1.32s/it]Loading train:  69%|██████▉   | 198/285 [03:35<01:55,  1.33s/it]Loading train:  70%|██████▉   | 199/285 [03:36<01:51,  1.29s/it]Loading train:  70%|███████   | 200/285 [03:38<01:47,  1.27s/it]Loading train:  71%|███████   | 201/285 [03:39<01:43,  1.23s/it]Loading train:  71%|███████   | 202/285 [03:40<01:37,  1.18s/it]Loading train:  71%|███████   | 203/285 [03:41<01:43,  1.26s/it]Loading train:  72%|███████▏  | 204/285 [03:43<01:41,  1.25s/it]Loading train:  72%|███████▏  | 205/285 [03:44<01:38,  1.23s/it]Loading train:  72%|███████▏  | 206/285 [03:45<01:31,  1.16s/it]Loading train:  73%|███████▎  | 207/285 [03:46<01:37,  1.25s/it]Loading train:  73%|███████▎  | 208/285 [03:47<01:36,  1.26s/it]Loading train:  73%|███████▎  | 209/285 [03:49<01:36,  1.27s/it]Loading train:  74%|███████▎  | 210/285 [03:50<01:29,  1.19s/it]Loading train:  74%|███████▍  | 211/285 [03:51<01:26,  1.17s/it]Loading train:  74%|███████▍  | 212/285 [03:52<01:22,  1.13s/it]Loading train:  75%|███████▍  | 213/285 [03:53<01:24,  1.18s/it]Loading train:  75%|███████▌  | 214/285 [03:54<01:24,  1.19s/it]Loading train:  75%|███████▌  | 215/285 [03:56<01:29,  1.28s/it]Loading train:  76%|███████▌  | 216/285 [03:57<01:23,  1.20s/it]Loading train:  76%|███████▌  | 217/285 [03:59<01:33,  1.38s/it]Loading train:  76%|███████▋  | 218/285 [04:00<01:31,  1.37s/it]Loading train:  77%|███████▋  | 219/285 [04:01<01:26,  1.31s/it]Loading train:  77%|███████▋  | 220/285 [04:02<01:22,  1.27s/it]Loading train:  78%|███████▊  | 221/285 [04:03<01:16,  1.19s/it]Loading train:  78%|███████▊  | 222/285 [04:05<01:22,  1.31s/it]Loading train:  78%|███████▊  | 223/285 [04:06<01:17,  1.25s/it]Loading train:  79%|███████▊  | 224/285 [04:07<01:14,  1.22s/it]Loading train:  79%|███████▉  | 225/285 [04:08<01:11,  1.19s/it]Loading train:  79%|███████▉  | 226/285 [04:10<01:13,  1.25s/it]Loading train:  80%|███████▉  | 227/285 [04:11<01:13,  1.27s/it]Loading train:  80%|████████  | 228/285 [04:12<01:14,  1.31s/it]Loading train:  80%|████████  | 229/285 [04:14<01:14,  1.32s/it]Loading train:  81%|████████  | 230/285 [04:15<01:09,  1.26s/it]Loading train:  81%|████████  | 231/285 [04:16<01:10,  1.30s/it]Loading train:  81%|████████▏ | 232/285 [04:18<01:09,  1.31s/it]Loading train:  82%|████████▏ | 233/285 [04:19<01:04,  1.24s/it]Loading train:  82%|████████▏ | 234/285 [04:20<01:07,  1.33s/it]Loading train:  82%|████████▏ | 235/285 [04:21<01:03,  1.27s/it]Loading train:  83%|████████▎ | 236/285 [04:23<01:03,  1.29s/it]Loading train:  83%|████████▎ | 237/285 [04:24<01:00,  1.27s/it]Loading train:  84%|████████▎ | 238/285 [04:25<01:00,  1.29s/it]Loading train:  84%|████████▍ | 239/285 [04:27<00:59,  1.28s/it]Loading train:  84%|████████▍ | 240/285 [04:28<00:56,  1.25s/it]Loading train:  85%|████████▍ | 241/285 [04:29<00:55,  1.25s/it]Loading train:  85%|████████▍ | 242/285 [04:30<00:55,  1.30s/it]Loading train:  85%|████████▌ | 243/285 [04:31<00:50,  1.20s/it]Loading train:  86%|████████▌ | 244/285 [04:33<00:50,  1.24s/it]Loading train:  86%|████████▌ | 245/285 [04:34<00:45,  1.14s/it]Loading train:  86%|████████▋ | 246/285 [04:35<00:44,  1.15s/it]Loading train:  87%|████████▋ | 247/285 [04:36<00:45,  1.20s/it]Loading train:  87%|████████▋ | 248/285 [04:37<00:43,  1.17s/it]Loading train:  87%|████████▋ | 249/285 [04:38<00:38,  1.08s/it]Loading train:  88%|████████▊ | 250/285 [04:39<00:37,  1.06s/it]Loading train:  88%|████████▊ | 251/285 [04:40<00:39,  1.16s/it]Loading train:  88%|████████▊ | 252/285 [04:41<00:35,  1.08s/it]Loading train:  89%|████████▉ | 253/285 [04:43<00:35,  1.12s/it]Loading train:  89%|████████▉ | 254/285 [04:44<00:35,  1.14s/it]Loading train:  89%|████████▉ | 255/285 [04:45<00:33,  1.12s/it]Loading train:  90%|████████▉ | 256/285 [04:46<00:30,  1.07s/it]Loading train:  90%|█████████ | 257/285 [04:47<00:28,  1.03s/it]Loading train:  91%|█████████ | 258/285 [04:48<00:30,  1.13s/it]Loading train:  91%|█████████ | 259/285 [04:49<00:28,  1.11s/it]Loading train:  91%|█████████ | 260/285 [04:50<00:25,  1.04s/it]Loading train:  92%|█████████▏| 261/285 [04:51<00:25,  1.07s/it]Loading train:  92%|█████████▏| 262/285 [04:52<00:24,  1.06s/it]Loading train:  92%|█████████▏| 263/285 [04:53<00:22,  1.04s/it]Loading train:  93%|█████████▎| 264/285 [04:55<00:26,  1.27s/it]Loading train:  93%|█████████▎| 265/285 [04:56<00:25,  1.27s/it]Loading train:  93%|█████████▎| 266/285 [04:57<00:23,  1.22s/it]Loading train:  94%|█████████▎| 267/285 [04:58<00:20,  1.16s/it]Loading train:  94%|█████████▍| 268/285 [05:00<00:21,  1.26s/it]Loading train:  94%|█████████▍| 269/285 [05:01<00:19,  1.19s/it]Loading train:  95%|█████████▍| 270/285 [05:02<00:16,  1.13s/it]Loading train:  95%|█████████▌| 271/285 [05:03<00:16,  1.20s/it]Loading train:  95%|█████████▌| 272/285 [05:04<00:15,  1.20s/it]Loading train:  96%|█████████▌| 273/285 [05:06<00:13,  1.15s/it]Loading train:  96%|█████████▌| 274/285 [05:07<00:12,  1.18s/it]Loading train:  96%|█████████▋| 275/285 [05:08<00:12,  1.26s/it]Loading train:  97%|█████████▋| 276/285 [05:09<00:11,  1.27s/it]Loading train:  97%|█████████▋| 277/285 [05:10<00:09,  1.14s/it]Loading train:  98%|█████████▊| 278/285 [05:11<00:07,  1.14s/it]Loading train:  98%|█████████▊| 279/285 [05:13<00:06,  1.13s/it]Loading train:  98%|█████████▊| 280/285 [05:14<00:05,  1.13s/it]Loading train:  99%|█████████▊| 281/285 [05:15<00:04,  1.16s/it]Loading train:  99%|█████████▉| 282/285 [05:16<00:03,  1.11s/it]Loading train:  99%|█████████▉| 283/285 [05:17<00:02,  1.19s/it]Loading train: 100%|█████████▉| 284/285 [05:19<00:01,  1.29s/it]Loading train: 100%|██████████| 285/285 [05:20<00:00,  1.31s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:05, 52.46it/s]concatenating: train:   4%|▍         | 12/285 [00:00<00:05, 51.16it/s]concatenating: train:   7%|▋         | 20/285 [00:00<00:04, 56.80it/s]concatenating: train:  11%|█         | 31/285 [00:00<00:04, 62.91it/s]concatenating: train:  13%|█▎        | 37/285 [00:00<00:04, 51.61it/s]concatenating: train:  17%|█▋        | 48/285 [00:00<00:04, 58.65it/s]concatenating: train:  20%|█▉        | 56/285 [00:00<00:03, 63.15it/s]concatenating: train:  24%|██▍       | 68/285 [00:00<00:02, 73.08it/s]concatenating: train:  27%|██▋       | 78/285 [00:01<00:02, 74.86it/s]concatenating: train:  31%|███       | 87/285 [00:01<00:02, 77.60it/s]concatenating: train:  35%|███▌      | 100/285 [00:01<00:02, 86.85it/s]concatenating: train:  39%|███▉      | 111/285 [00:01<00:01, 91.95it/s]concatenating: train:  44%|████▎     | 124/285 [00:01<00:01, 99.72it/s]concatenating: train:  48%|████▊     | 137/285 [00:01<00:01, 106.15it/s]concatenating: train:  52%|█████▏    | 149/285 [00:01<00:01, 105.33it/s]concatenating: train:  56%|█████▌    | 160/285 [00:01<00:01, 84.13it/s] concatenating: train:  60%|█████▉    | 170/285 [00:02<00:01, 69.06it/s]concatenating: train:  62%|██████▏   | 178/285 [00:02<00:01, 69.30it/s]concatenating: train:  65%|██████▌   | 186/285 [00:02<00:01, 65.78it/s]concatenating: train:  70%|██████▉   | 199/285 [00:02<00:01, 76.69it/s]concatenating: train:  74%|███████▍  | 212/285 [00:02<00:00, 85.83it/s]concatenating: train:  84%|████████▍ | 239/285 [00:02<00:00, 107.91it/s]concatenating: train:  89%|████████▉ | 254/285 [00:02<00:00, 117.08it/s]concatenating: train:  94%|█████████▍| 269/285 [00:03<00:00, 97.10it/s] concatenating: train:  99%|█████████▉| 282/285 [00:03<00:00, 96.73it/s]concatenating: train: 100%|██████████| 285/285 [00:03<00:00, 88.68it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.45s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.42s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.35s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 54.26it/s]2019-07-09 04:19:28.917278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-09 04:19:28.917371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-09 04:19:28.917389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-09 04:19:28.917399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-09 04:19:28.917784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12743 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.35it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.20it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:08,  4.93it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.04it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.57it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.37it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.59it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.21it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  7.43it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  5.81it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.04it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  7.64it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:03<00:02,  6.08it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:03<00:02,  6.79it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:02,  5.74it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:04<00:01,  7.12it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:00,  7.52it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:04<00:00,  6.18it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:04<00:00,  6.79it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:05<00:00,  5.36it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:05<00:00,  8.75it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 40)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 41)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 30)   11100       concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 30)   8130        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 30)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 40, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 60)   16260       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 60)   32460       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 90)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 90)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 120)  97320       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 120)  129720      activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 120)  480         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 120)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 210)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 210)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 60)   50460       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 60)   81060       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 60)   32460       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 60)   240         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 60)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 210)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 40, 210)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 30)   25230       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 60)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 30)   16230       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 30)   8130        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 30)   120         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 30)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 90)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 80, 90)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 13)   1183        dropout_6[0][0]                  
==================================================================================================
Total params: 512,703
Trainable params: 120,403
Non-trainable params: 392,300
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 28s - loss: 13249.9197 - acc: 0.6055 - mDice: 0.1392 - val_loss: 22289.3862 - val_acc: 0.9050 - val_mDice: 0.1068

Epoch 00001: val_mDice improved from -inf to 0.10685, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 20s - loss: 4288.8466 - acc: 0.8888 - mDice: 0.4239 - val_loss: 13152.7279 - val_acc: 0.9118 - val_mDice: 0.2609

Epoch 00002: val_mDice improved from 0.10685 to 0.26094, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 19s - loss: 3233.2815 - acc: 0.9033 - mDice: 0.5198 - val_loss: 3572.0011 - val_acc: 0.9256 - val_mDice: 0.4669

Epoch 00003: val_mDice improved from 0.26094 to 0.46691, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 19s - loss: 2785.0840 - acc: 0.9127 - mDice: 0.5686 - val_loss: 3190.3808 - val_acc: 0.9358 - val_mDice: 0.5064

Epoch 00004: val_mDice improved from 0.46691 to 0.50644, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 20s - loss: 2518.9354 - acc: 0.9197 - mDice: 0.5999 - val_loss: 3278.1962 - val_acc: 0.9328 - val_mDice: 0.4953

Epoch 00005: val_mDice did not improve from 0.50644
Epoch 6/300
 - 19s - loss: 2349.3585 - acc: 0.9243 - mDice: 0.6207 - val_loss: 2754.0321 - val_acc: 0.9314 - val_mDice: 0.5513

Epoch 00006: val_mDice improved from 0.50644 to 0.55128, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 19s - loss: 2235.7177 - acc: 0.9275 - mDice: 0.6350 - val_loss: 2817.1579 - val_acc: 0.9266 - val_mDice: 0.5407

Epoch 00007: val_mDice did not improve from 0.55128
Epoch 8/300
 - 20s - loss: 2139.5933 - acc: 0.9299 - mDice: 0.6475 - val_loss: 3071.2257 - val_acc: 0.9352 - val_mDice: 0.5166

Epoch 00008: val_mDice did not improve from 0.55128
Epoch 9/300
 - 20s - loss: 2044.3525 - acc: 0.9321 - mDice: 0.6599 - val_loss: 3926.0831 - val_acc: 0.9308 - val_mDice: 0.4435

Epoch 00009: val_mDice did not improve from 0.55128
Epoch 10/300
 - 19s - loss: 1980.8612 - acc: 0.9335 - mDice: 0.6683 - val_loss: 2778.7510 - val_acc: 0.9411 - val_mDice: 0.5469

Epoch 00010: val_mDice did not improve from 0.55128
Epoch 11/300
 - 19s - loss: 1924.3238 - acc: 0.9350 - mDice: 0.6759 - val_loss: 2778.0341 - val_acc: 0.9377 - val_mDice: 0.5498

Epoch 00011: val_mDice did not improve from 0.55128
Epoch 12/300
 - 19s - loss: 1885.7400 - acc: 0.9360 - mDice: 0.6811 - val_loss: 2984.6232 - val_acc: 0.9422 - val_mDice: 0.5252

Epoch 00012: val_mDice did not improve from 0.55128
Epoch 13/300
 - 19s - loss: 1844.4457 - acc: 0.9369 - mDice: 0.6869 - val_loss: 2742.9634 - val_acc: 0.9336 - val_mDice: 0.5535

Epoch 00013: val_mDice improved from 0.55128 to 0.55348, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 20s - loss: 1802.8278 - acc: 0.9379 - mDice: 0.6926 - val_loss: 2831.2256 - val_acc: 0.9245 - val_mDice: 0.5391

Epoch 00014: val_mDice did not improve from 0.55348
Epoch 15/300
 - 19s - loss: 1773.3792 - acc: 0.9385 - mDice: 0.6967 - val_loss: 2824.1259 - val_acc: 0.9387 - val_mDice: 0.5473

Epoch 00015: val_mDice did not improve from 0.55348
Epoch 16/300
 - 19s - loss: 1728.2192 - acc: 0.9395 - mDice: 0.7031 - val_loss: 2657.9859 - val_acc: 0.9359 - val_mDice: 0.5591

Epoch 00016: val_mDice improved from 0.55348 to 0.55914, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 20s - loss: 1703.4104 - acc: 0.9400 - mDice: 0.7066 - val_loss: 2825.0041 - val_acc: 0.9217 - val_mDice: 0.5408

Epoch 00017: val_mDice did not improve from 0.55914
Epoch 18/300
 - 20s - loss: 1664.8385 - acc: 0.9409 - mDice: 0.7121 - val_loss: 2829.1903 - val_acc: 0.9387 - val_mDice: 0.5424

Epoch 00018: val_mDice did not improve from 0.55914
Epoch 19/300
 - 20s - loss: 1651.8133 - acc: 0.9412 - mDice: 0.7139 - val_loss: 2861.8146 - val_acc: 0.9358 - val_mDice: 0.5346

Epoch 00019: val_mDice did not improve from 0.55914
Epoch 20/300
 - 19s - loss: 1626.1516 - acc: 0.9416 - mDice: 0.7177 - val_loss: 2947.1000 - val_acc: 0.9352 - val_mDice: 0.5288

Epoch 00020: val_mDice did not improve from 0.55914
Epoch 21/300
 - 20s - loss: 1601.3892 - acc: 0.9422 - mDice: 0.7212 - val_loss: 2697.6099 - val_acc: 0.9324 - val_mDice: 0.5553

Epoch 00021: val_mDice did not improve from 0.55914
Epoch 22/300
 - 20s - loss: 1582.2221 - acc: 0.9426 - mDice: 0.7240 - val_loss: 2731.1295 - val_acc: 0.9408 - val_mDice: 0.5543

Epoch 00022: val_mDice did not improve from 0.55914
Epoch 23/300
 - 20s - loss: 1573.1061 - acc: 0.9427 - mDice: 0.7254 - val_loss: 2846.7136 - val_acc: 0.9435 - val_mDice: 0.5423

Epoch 00023: val_mDice did not improve from 0.55914
Epoch 24/300
 - 20s - loss: 1542.2051 - acc: 0.9434 - mDice: 0.7299 - val_loss: 2709.7275 - val_acc: 0.9413 - val_mDice: 0.5562

Epoch 00024: val_mDice did not improve from 0.55914
Epoch 25/300
 - 20s - loss: 1533.1374 - acc: 0.9437 - mDice: 0.7313 - val_loss: 2877.4778 - val_acc: 0.9428 - val_mDice: 0.5345

Epoch 00025: val_mDice did not improve from 0.55914
Epoch 26/300
 - 20s - loss: 1515.8831 - acc: 0.9437 - mDice: 0.7338 - val_loss: 2731.7537 - val_acc: 0.9340 - val_mDice: 0.5496

Epoch 00026: val_mDice did not improve from 0.55914
Epoch 27/300
 - 20s - loss: 1506.3297 - acc: 0.9441 - mDice: 0.7352 - val_loss: 2958.4252 - val_acc: 0.9222 - val_mDice: 0.5282

Epoch 00027: val_mDice did not improve from 0.55914
Epoch 28/300
 - 20s - loss: 1493.4849 - acc: 0.9446 - mDice: 0.7371 - val_loss: 2746.2630 - val_acc: 0.9423 - val_mDice: 0.5471

Epoch 00028: val_mDice did not improve from 0.55914
Epoch 29/300
 - 20s - loss: 1466.2548 - acc: 0.9449 - mDice: 0.7411 - val_loss: 2860.1441 - val_acc: 0.9434 - val_mDice: 0.5350

Epoch 00029: val_mDice did not improve from 0.55914
Epoch 30/300
 - 20s - loss: 1451.0855 - acc: 0.9451 - mDice: 0.7434 - val_loss: 2656.7407 - val_acc: 0.9403 - val_mDice: 0.5590

Epoch 00030: val_mDice did not improve from 0.55914
Epoch 31/300
 - 20s - loss: 1433.9710 - acc: 0.9455 - mDice: 0.7460 - val_loss: 2735.5176 - val_acc: 0.9457 - val_mDice: 0.5491

Epoch 00031: val_mDice did not improve from 0.55914
Epoch 32/300
 - 20s - loss: 1419.9694 - acc: 0.9458 - mDice: 0.7480 - val_loss: 2655.0282 - val_acc: 0.9461 - val_mDice: 0.5578

Epoch 00032: val_mDice did not improve from 0.55914
Epoch 33/300
 - 20s - loss: 1412.5334 - acc: 0.9459 - mDice: 0.7493 - val_loss: 2589.6601 - val_acc: 0.9422 - val_mDice: 0.5659

Epoch 00033: val_mDice improved from 0.55914 to 0.56594, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 34/300
 - 20s - loss: 1399.9811 - acc: 0.9463 - mDice: 0.7512 - val_loss: 2693.8063 - val_acc: 0.9455 - val_mDice: 0.5521

Epoch 00034: val_mDice did not improve from 0.56594
Epoch 35/300
 - 20s - loss: 1396.2017 - acc: 0.9463 - mDice: 0.7517 - val_loss: 2884.1304 - val_acc: 0.9456 - val_mDice: 0.5311

Epoch 00035: val_mDice did not improve from 0.56594
Epoch 36/300
 - 20s - loss: 1389.2506 - acc: 0.9465 - mDice: 0.7528 - val_loss: 2750.2594 - val_acc: 0.9413 - val_mDice: 0.5467

Epoch 00036: val_mDice did not improve from 0.56594
Epoch 37/300
 - 19s - loss: 1372.9131 - acc: 0.9468 - mDice: 0.7553 - val_loss: 2688.3991 - val_acc: 0.9413 - val_mDice: 0.5525

Epoch 00037: val_mDice did not improve from 0.56594
Epoch 38/300
 - 19s - loss: 1363.3912 - acc: 0.9471 - mDice: 0.7567 - val_loss: 2616.9956 - val_acc: 0.9394 - val_mDice: 0.5590

Epoch 00038: val_mDice did not improve from 0.56594
Epoch 39/300
 - 20s - loss: 1354.7364 - acc: 0.9470 - mDice: 0.7580 - val_loss: 2707.9947 - val_acc: 0.9391 - val_mDice: 0.5489

Epoch 00039: val_mDice did not improve from 0.56594
Epoch 40/300
 - 20s - loss: 1341.2139 - acc: 0.9473 - mDice: 0.7601 - val_loss: 2834.1949 - val_acc: 0.9372 - val_mDice: 0.5363

Epoch 00040: val_mDice did not improve from 0.56594
Epoch 41/300
 - 20s - loss: 1337.6788 - acc: 0.9474 - mDice: 0.7606 - val_loss: 2505.6963 - val_acc: 0.9463 - val_mDice: 0.5696

Epoch 00041: val_mDice improved from 0.56594 to 0.56957, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 42/300
 - 20s - loss: 1329.0707 - acc: 0.9475 - mDice: 0.7619 - val_loss: 2678.1325 - val_acc: 0.9458 - val_mDice: 0.5526

Epoch 00042: val_mDice did not improve from 0.56957
Epoch 43/300
 - 20s - loss: 1324.1264 - acc: 0.9477 - mDice: 0.7627 - val_loss: 2711.6914 - val_acc: 0.9452 - val_mDice: 0.5477

Epoch 00043: val_mDice did not improve from 0.56957
Epoch 44/300
 - 20s - loss: 1324.1291 - acc: 0.9477 - mDice: 0.7628 - val_loss: 2700.0038 - val_acc: 0.9379 - val_mDice: 0.5492

Epoch 00044: val_mDice did not improve from 0.56957
Epoch 45/300
 - 20s - loss: 1309.0085 - acc: 0.9478 - mDice: 0.7651 - val_loss: 2672.4192 - val_acc: 0.9480 - val_mDice: 0.5516

Epoch 00045: val_mDice did not improve from 0.56957
Epoch 46/300
 - 19s - loss: 1296.4133 - acc: 0.9484 - mDice: 0.7670 - val_loss: 2702.6191 - val_acc: 0.9479 - val_mDice: 0.5476

Epoch 00046: val_mDice did not improve from 0.56957
Epoch 47/300
 - 20s - loss: 1287.1700 - acc: 0.9483 - mDice: 0.7684 - val_loss: 2656.4224 - val_acc: 0.9375 - val_mDice: 0.5503

Epoch 00047: val_mDice did not improve from 0.56957
Epoch 48/300
 - 20s - loss: 1279.6779 - acc: 0.9484 - mDice: 0.7696 - val_loss: 2595.6826 - val_acc: 0.9444 - val_mDice: 0.5592

Epoch 00048: val_mDice did not improve from 0.56957
Epoch 49/300
 - 19s - loss: 1272.1636 - acc: 0.9487 - mDice: 0.7708 - val_loss: 2613.4547 - val_acc: 0.9483 - val_mDice: 0.5557

Epoch 00049: val_mDice did not improve from 0.56957
Epoch 50/300
 - 20s - loss: 1269.2779 - acc: 0.9486 - mDice: 0.7711 - val_loss: 2539.2796 - val_acc: 0.9472 - val_mDice: 0.5647

Epoch 00050: val_mDice did not improve from 0.56957
Epoch 51/300
 - 19s - loss: 1265.5420 - acc: 0.9489 - mDice: 0.7718 - val_loss: 2597.2169 - val_acc: 0.9433 - val_mDice: 0.5578

Epoch 00051: val_mDice did not improve from 0.56957
Epoch 52/300
 - 20s - loss: 1252.4905 - acc: 0.9491 - mDice: 0.7739 - val_loss: 2649.8579 - val_acc: 0.9374 - val_mDice: 0.5560

Epoch 00052: val_mDice did not improve from 0.56957
Epoch 53/300
 - 20s - loss: 1251.8121 - acc: 0.9492 - mDice: 0.7739 - val_loss: 2536.7783 - val_acc: 0.9474 - val_mDice: 0.5667

Epoch 00053: val_mDice did not improve from 0.56957
Epoch 54/300
 - 20s - loss: 1241.0943 - acc: 0.9492 - mDice: 0.7756 - val_loss: 2754.4820 - val_acc: 0.9445 - val_mDice: 0.5419

Epoch 00054: val_mDice did not improve from 0.56957
Epoch 55/300
 - 19s - loss: 1237.5236 - acc: 0.9493 - mDice: 0.7762 - val_loss: 2778.2197 - val_acc: 0.9477 - val_mDice: 0.5386

Epoch 00055: val_mDice did not improve from 0.56957
Epoch 56/300
 - 19s - loss: 1240.4485 - acc: 0.9493 - mDice: 0.7757 - val_loss: 2983.7083 - val_acc: 0.9409 - val_mDice: 0.5166

Epoch 00056: val_mDice did not improve from 0.56957
Epoch 57/300
 - 20s - loss: 1237.1062 - acc: 0.9493 - mDice: 0.7763 - val_loss: 2625.4248 - val_acc: 0.9461 - val_mDice: 0.5556

Epoch 00057: val_mDice did not improve from 0.56957
Epoch 58/300
 - 20s - loss: 1226.6074 - acc: 0.9496 - mDice: 0.7779 - val_loss: 2732.3071 - val_acc: 0.9439 - val_mDice: 0.5442

Epoch 00058: val_mDice did not improve from 0.56957
Epoch 59/300
 - 20s - loss: 1218.3530 - acc: 0.9497 - mDice: 0.7792 - val_loss: 2853.6570 - val_acc: 0.9479 - val_mDice: 0.5315

Epoch 00059: val_mDice did not improve from 0.56957
Epoch 60/300
 - 20s - loss: 1214.1936 - acc: 0.9497 - mDice: 0.7798 - val_loss: 2869.0600 - val_acc: 0.9456 - val_mDice: 0.5276

Epoch 00060: val_mDice did not improve from 0.56957
Epoch 61/300
 - 20s - loss: 1205.8887 - acc: 0.9499 - mDice: 0.7812 - val_loss: 2743.1004 - val_acc: 0.9450 - val_mDice: 0.5447

Epoch 00061: val_mDice did not improve from 0.56957
Epoch 62/300
 - 19s - loss: 1199.4403 - acc: 0.9500 - mDice: 0.7822 - val_loss: 2774.7823 - val_acc: 0.9465 - val_mDice: 0.5391

Epoch 00062: val_mDice did not improve from 0.56957
Epoch 63/300
 - 20s - loss: 1201.1193 - acc: 0.9501 - mDice: 0.7819 - val_loss: 2829.3422 - val_acc: 0.9436 - val_mDice: 0.5330

Epoch 00063: val_mDice did not improve from 0.56957
Epoch 64/300
 - 19s - loss: 1194.5948 - acc: 0.9501 - mDice: 0.7830 - val_loss: 2727.1036 - val_acc: 0.9414 - val_mDice: 0.5436

Epoch 00064: val_mDice did not improve from 0.56957
Epoch 65/300
 - 20s - loss: 1193.5351 - acc: 0.9502 - mDice: 0.7831 - val_loss: 2734.5258 - val_acc: 0.9449 - val_mDice: 0.5418

Epoch 00065: val_mDice did not improve from 0.56957
Epoch 66/300
 - 19s - loss: 1193.1040 - acc: 0.9503 - mDice: 0.7831 - val_loss: 2882.3192 - val_acc: 0.9463 - val_mDice: 0.5298

Epoch 00066: val_mDice did not improve from 0.56957
Epoch 67/300
 - 19s - loss: 1183.5428 - acc: 0.9503 - mDice: 0.7847 - val_loss: 2713.2483 - val_acc: 0.9430 - val_mDice: 0.5476

Epoch 00067: val_mDice did not improve from 0.56957
Epoch 68/300
 - 20s - loss: 1174.9712 - acc: 0.9506 - mDice: 0.7861 - val_loss: 2718.2512 - val_acc: 0.9432 - val_mDice: 0.5461

Epoch 00068: val_mDice did not improve from 0.56957
Epoch 69/300
 - 19s - loss: 1179.3036 - acc: 0.9504 - mDice: 0.7854 - val_loss: 2539.6353 - val_acc: 0.9458 - val_mDice: 0.5643

Epoch 00069: val_mDice did not improve from 0.56957
Epoch 70/300
 - 19s - loss: 1173.6491 - acc: 0.9505 - mDice: 0.7863 - val_loss: 2756.2095 - val_acc: 0.9388 - val_mDice: 0.5438

Epoch 00070: val_mDice did not improve from 0.56957
Epoch 71/300
 - 20s - loss: 1166.2341 - acc: 0.9506 - mDice: 0.7875 - val_loss: 2686.2935 - val_acc: 0.9458 - val_mDice: 0.5489

Epoch 00071: val_mDice did not improve from 0.56957
Restoring model weights from the end of the best epoch
Epoch 00071: early stopping
{'val_loss': [22289.386183965773, 13152.72791108631, 3572.0011044456846, 3190.380836123512, 3278.196219308036, 2754.0321335565477, 2817.1579241071427, 3071.2257254464284, 3926.083054315476, 2778.7509649367557, 2778.0340750558034, 2984.6232328869046, 2742.963355654762, 2831.225632440476, 2824.125906808036, 2657.985863095238, 2825.0041387648807, 2829.1903134300596, 2861.8145693824404, 2947.0999930245534, 2697.609933035714, 2731.1295107886904, 2846.7136346726193, 2709.7275390625, 2877.477806454613, 2731.753685360863, 2958.4251999627977, 2746.262985956101, 2860.1441010974704, 2656.7406645275296, 2735.5176362537204, 2655.028163364955, 2589.660092308408, 2693.8062918526784, 2884.1303594680057, 2750.2593703497023, 2688.3991117931546, 2616.995599655878, 2707.9947277250744, 2834.1949491954983, 2505.69630359468, 2678.1324695405506, 2711.691388811384, 2700.003842308408, 2672.4191778273807, 2702.61912609282, 2656.4224301292784, 2595.68260265532, 2613.45466977074, 2539.2796427408853, 2597.2169276646205, 2649.857878185454, 2536.77830578032, 2754.48195539202, 2778.2196669805617, 2983.708282470703, 2625.42481921968, 2732.3071012951077, 2853.657039097377, 2869.0599684942335, 2743.100350516183, 2774.7823152087985, 2829.3421659923733, 2727.1036086309523, 2734.525816417876, 2882.3191644577755, 2713.2483491443454, 2718.2511683872767, 2539.6353352864585, 2756.20948718843, 2686.2934846423923], 'val_acc': [0.9049817125002543, 0.9118475516637167, 0.9255838138716561, 0.935828759556725, 0.9328319487117586, 0.9314079398200625, 0.9266231854756674, 0.9352014802751087, 0.9308218672162011, 0.9411195062455677, 0.9376579892067682, 0.942236704485757, 0.933626393477122, 0.9244620033672878, 0.9386904864084153, 0.9359409496897743, 0.9216895727884202, 0.9386881930487496, 0.935815033458528, 0.935187714440482, 0.9323763506753104, 0.9407944225129627, 0.9434935876301357, 0.9413415704454694, 0.9427747272309803, 0.9339514459882464, 0.9222366951760792, 0.9422733386357626, 0.9434226183664232, 0.9403480121067592, 0.9456708005496434, 0.946133227575393, 0.9421566213880267, 0.945521993296487, 0.9456410322870527, 0.9413095003082639, 0.9413209954897562, 0.9394070591245379, 0.9390750867979867, 0.937152019568852, 0.9462568447703407, 0.9458333310626802, 0.945203769774664, 0.9379464302744184, 0.9479761918385824, 0.9478754685038612, 0.9374747900735765, 0.9443818642979577, 0.9483058480989366, 0.9471726133709862, 0.9432715149152846, 0.9374336174556187, 0.9474267193249294, 0.9445307027725947, 0.9476877536092486, 0.9409455202874684, 0.9460622980481103, 0.9438552828062148, 0.9479464406058902, 0.9455540265355792, 0.9450091748010545, 0.9465247108822777, 0.943610355967567, 0.9414148500987461, 0.9449107391493661, 0.94630723907834, 0.9429853246325538, 0.9432188613074166, 0.9457852840423584, 0.938750025771913, 0.9457921300615583], 'val_mDice': [0.10684667188754593, 0.260938354766668, 0.4669085611544904, 0.5064415378229958, 0.4953010503557466, 0.5512821949308827, 0.5406885571068242, 0.5165549089156446, 0.44352788895013784, 0.5468938088133222, 0.5497654348257042, 0.5251620883299482, 0.5534801862779117, 0.5391005538403988, 0.5472539810552484, 0.5591375898747217, 0.5408048017748764, 0.5424171537160873, 0.5345822994907697, 0.5288029880750746, 0.5553065706931409, 0.5542806072958878, 0.5422500428699312, 0.5561842251391638, 0.5345081239938736, 0.5496101120398158, 0.5281777346418017, 0.5470816030033997, 0.5350105893753824, 0.5590069081102099, 0.5491207391023636, 0.5577728391758033, 0.5659359423887163, 0.5520823168612662, 0.5310820145975976, 0.5466715597680637, 0.5525049260329633, 0.5590485800944623, 0.54893802869178, 0.5363246202468872, 0.5695727492372195, 0.5526481668154398, 0.5477200283535889, 0.5492395758628845, 0.5516335442662239, 0.5476462418834368, 0.5503465937716621, 0.5592399647548085, 0.5556992654289518, 0.5646659785083362, 0.5577650728325049, 0.5560039542615414, 0.566703801708562, 0.541944891746555, 0.5386456588194484, 0.516601345368794, 0.5556445418014413, 0.5442100692363012, 0.5315355218592144, 0.527630036785489, 0.5446582589121092, 0.539099319172757, 0.5329843486348788, 0.5435995800154549, 0.5418285981175446, 0.5297546131270272, 0.5476317952076594, 0.5461207968848092, 0.5643381398348581, 0.5437673626556283, 0.5488517589512325], 'loss': [13249.919732662485, 4288.846609038747, 3233.2815185688078, 2785.084045445457, 2518.935372112297, 2349.3584660974475, 2235.717727311066, 2139.593305821269, 2044.352497454574, 1980.8612336364122, 1924.3237518375265, 1885.7399916934764, 1844.4456715095657, 1802.8277966786331, 1773.3792167797424, 1728.2191524531356, 1703.410412910657, 1664.838493304513, 1651.8132540730583, 1626.1515975843304, 1601.3892422424751, 1582.2221489533629, 1573.1061122608203, 1542.2050856323124, 1533.1373941492477, 1515.8830618180818, 1506.3297120081982, 1493.4848975701348, 1466.2548491472635, 1451.085491768032, 1433.970976353519, 1419.969417115317, 1412.5333556246385, 1399.9811010586864, 1396.2016546257846, 1389.2506058448216, 1372.913090903152, 1363.391210852778, 1354.736444041199, 1341.2138620806447, 1337.678780115384, 1329.0706612958554, 1324.1263911708922, 1324.1291218087097, 1309.0084991484496, 1296.41331170992, 1287.1699753910768, 1279.6778610932568, 1272.163622098459, 1269.2779003854475, 1265.5419850567298, 1252.490507391714, 1251.8120867918744, 1241.0943290985501, 1237.5235936709262, 1240.4485423623287, 1237.1061885459403, 1226.6073626872544, 1218.3529858299596, 1214.1936053748027, 1205.8887192840311, 1199.4402848128434, 1201.1193386156572, 1194.5948097312844, 1193.5350955090175, 1193.1040427371765, 1183.5427990235505, 1174.9712201764364, 1179.3035861254887, 1173.6490803518714, 1166.2341360838996], 'acc': [0.6055012257550294, 0.8888455893415602, 0.9032962623992958, 0.9126719343701332, 0.9196744184859897, 0.9243253996796477, 0.9275403774632685, 0.9299367146844093, 0.9320986677346855, 0.9334831611830213, 0.9349940131918093, 0.9359668808818117, 0.9369490886782552, 0.937922887864636, 0.938452756655384, 0.939475863430802, 0.9399670845445972, 0.9408877204901822, 0.9411583251522896, 0.9415759727264016, 0.9421968876292808, 0.9425720584882071, 0.9427265240228174, 0.9433634220485124, 0.9437114893068623, 0.9437466382934382, 0.9441429030603358, 0.94457345913664, 0.9448528409302982, 0.9451493254419419, 0.9454907167617448, 0.945778207648391, 0.9458604191042266, 0.9462739689193389, 0.9462705391069725, 0.9465283042253362, 0.9468042574591643, 0.9470703169080088, 0.9470387992657562, 0.9472696395859866, 0.9473823716536133, 0.9475483474116438, 0.947747744207601, 0.9476959769358542, 0.9478462454048636, 0.9483930110494733, 0.9483272493494621, 0.948436391084714, 0.9486856692462889, 0.9486377751733013, 0.9489076118697223, 0.9491021613268488, 0.9491685001818413, 0.9492317641289312, 0.9493279937192932, 0.9492526606532542, 0.9493051693920733, 0.9496161567353549, 0.949699322669888, 0.9497335461469797, 0.9498783953276723, 0.9500102402388486, 0.9500515106465744, 0.9501491346431877, 0.9501740427657959, 0.9502566978723207, 0.9502545441072617, 0.9505875208990546, 0.9503576351034864, 0.95052467856261, 0.9506461002336248], 'mDice': [0.1392291341596758, 0.42394805222847387, 0.5198435103684141, 0.5686436508670348, 0.5998534610649743, 0.6207302805773895, 0.6350302128794567, 0.6474769881678519, 0.6599432392710547, 0.6682899066747809, 0.6759438939997289, 0.6811178652266213, 0.686858917434068, 0.6925721641034549, 0.696723992916024, 0.7030579536917675, 0.7065578427231103, 0.7120703167370204, 0.7139320734242656, 0.7176721756550671, 0.7212001186288665, 0.72395993897008, 0.725394377249708, 0.7298668988274545, 0.7313118945180233, 0.7338171239094121, 0.7352381664042255, 0.7371257475880912, 0.7411462476723728, 0.7434183240097705, 0.7460089641567, 0.7480357720807312, 0.7492587302079062, 0.7511925603099151, 0.7516971238665621, 0.7528040008965958, 0.7552991843025924, 0.7566969432145018, 0.75802728342417, 0.7600541642021531, 0.7606117943819258, 0.7619399760577038, 0.7627281761937043, 0.7627761808001561, 0.7650723314386401, 0.7670049605995606, 0.768422430159615, 0.7695637799444652, 0.770754729090386, 0.7711430268639747, 0.771783943911244, 0.7738574047366249, 0.7739351110029065, 0.7756280281398024, 0.7762059750459501, 0.7756901675620151, 0.7762547567765423, 0.7778619225829099, 0.7791853104571697, 0.7798223817350779, 0.7811692252263918, 0.7821669780222097, 0.7819386276638942, 0.7829595302855185, 0.7831034760657178, 0.7831453373603607, 0.7846762418333266, 0.7860551764906683, 0.7854327672314317, 0.786299679719209, 0.787487908367571]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.48s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.22s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.99s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:03,  1.91s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:16,  1.75s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:15,  1.76s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:46,  1.66s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:06,  1.74s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:48,  1.68s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<08:04,  1.74s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:51,  1.70s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:12,  1.78s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:31,  1.86s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:04,  1.77s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:25,  1.85s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<08:10,  1.80s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<08:21,  1.85s/it]predicting train subjects:   5%|▌         | 15/285 [00:26<08:36,  1.91s/it]predicting train subjects:   6%|▌         | 16/285 [00:28<08:39,  1.93s/it]predicting train subjects:   6%|▌         | 17/285 [00:30<08:16,  1.85s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:17,  1.86s/it]predicting train subjects:   7%|▋         | 19/285 [00:33<08:01,  1.81s/it]predicting train subjects:   7%|▋         | 20/285 [00:35<08:07,  1.84s/it]predicting train subjects:   7%|▋         | 21/285 [00:37<08:13,  1.87s/it]predicting train subjects:   8%|▊         | 22/285 [00:39<07:55,  1.81s/it]predicting train subjects:   8%|▊         | 23/285 [00:41<08:07,  1.86s/it]predicting train subjects:   8%|▊         | 24/285 [00:43<07:54,  1.82s/it]predicting train subjects:   9%|▉         | 25/285 [00:45<08:06,  1.87s/it]predicting train subjects:   9%|▉         | 26/285 [00:47<08:18,  1.93s/it]predicting train subjects:   9%|▉         | 27/285 [00:48<07:52,  1.83s/it]predicting train subjects:  10%|▉         | 28/285 [00:50<08:04,  1.89s/it]predicting train subjects:  10%|█         | 29/285 [00:52<08:05,  1.90s/it]predicting train subjects:  11%|█         | 30/285 [00:54<08:08,  1.92s/it]predicting train subjects:  11%|█         | 31/285 [00:56<08:16,  1.95s/it]predicting train subjects:  11%|█         | 32/285 [00:58<07:56,  1.88s/it]predicting train subjects:  12%|█▏        | 33/285 [01:00<07:56,  1.89s/it]predicting train subjects:  12%|█▏        | 34/285 [01:02<08:01,  1.92s/it]predicting train subjects:  12%|█▏        | 35/285 [01:04<08:16,  1.99s/it]predicting train subjects:  13%|█▎        | 36/285 [01:06<07:47,  1.88s/it]predicting train subjects:  13%|█▎        | 37/285 [01:08<07:53,  1.91s/it]predicting train subjects:  13%|█▎        | 38/285 [01:10<08:00,  1.95s/it]predicting train subjects:  14%|█▎        | 39/285 [01:11<07:37,  1.86s/it]predicting train subjects:  14%|█▍        | 40/285 [01:13<07:44,  1.90s/it]predicting train subjects:  14%|█▍        | 41/285 [01:15<07:31,  1.85s/it]predicting train subjects:  15%|█▍        | 42/285 [01:17<07:19,  1.81s/it]predicting train subjects:  15%|█▌        | 43/285 [01:19<07:25,  1.84s/it]predicting train subjects:  15%|█▌        | 44/285 [01:21<07:41,  1.91s/it]predicting train subjects:  16%|█▌        | 45/285 [01:22<07:19,  1.83s/it]predicting train subjects:  16%|█▌        | 46/285 [01:24<07:33,  1.90s/it]predicting train subjects:  16%|█▋        | 47/285 [01:26<07:15,  1.83s/it]predicting train subjects:  17%|█▋        | 48/285 [01:28<07:18,  1.85s/it]predicting train subjects:  17%|█▋        | 49/285 [01:30<07:29,  1.90s/it]predicting train subjects:  18%|█▊        | 50/285 [01:32<07:16,  1.86s/it]predicting train subjects:  18%|█▊        | 51/285 [01:34<07:20,  1.88s/it]predicting train subjects:  18%|█▊        | 52/285 [01:35<06:58,  1.79s/it]predicting train subjects:  19%|█▊        | 53/285 [01:37<06:57,  1.80s/it]predicting train subjects:  19%|█▉        | 54/285 [01:39<07:06,  1.85s/it]predicting train subjects:  19%|█▉        | 55/285 [01:41<06:46,  1.77s/it]predicting train subjects:  20%|█▉        | 56/285 [01:43<06:52,  1.80s/it]predicting train subjects:  20%|██        | 57/285 [01:44<06:37,  1.74s/it]predicting train subjects:  20%|██        | 58/285 [01:46<06:43,  1.78s/it]predicting train subjects:  21%|██        | 59/285 [01:48<06:52,  1.82s/it]predicting train subjects:  21%|██        | 60/285 [01:50<07:03,  1.88s/it]predicting train subjects:  21%|██▏       | 61/285 [01:52<06:38,  1.78s/it]predicting train subjects:  22%|██▏       | 62/285 [01:53<06:39,  1.79s/it]predicting train subjects:  22%|██▏       | 63/285 [01:55<06:46,  1.83s/it]predicting train subjects:  22%|██▏       | 64/285 [01:57<06:34,  1.78s/it]predicting train subjects:  23%|██▎       | 65/285 [01:59<06:36,  1.80s/it]predicting train subjects:  23%|██▎       | 66/285 [02:01<06:31,  1.79s/it]predicting train subjects:  24%|██▎       | 67/285 [02:02<06:34,  1.81s/it]predicting train subjects:  24%|██▍       | 68/285 [02:04<06:20,  1.75s/it]predicting train subjects:  24%|██▍       | 69/285 [02:06<06:22,  1.77s/it]predicting train subjects:  25%|██▍       | 70/285 [02:08<06:25,  1.79s/it]predicting train subjects:  25%|██▍       | 71/285 [02:10<06:31,  1.83s/it]predicting train subjects:  25%|██▌       | 72/285 [02:11<06:14,  1.76s/it]predicting train subjects:  26%|██▌       | 73/285 [02:13<06:19,  1.79s/it]predicting train subjects:  26%|██▌       | 74/285 [02:15<06:21,  1.81s/it]predicting train subjects:  26%|██▋       | 75/285 [02:17<06:21,  1.82s/it]predicting train subjects:  27%|██▋       | 76/285 [02:19<06:26,  1.85s/it]predicting train subjects:  27%|██▋       | 77/285 [02:20<06:11,  1.79s/it]predicting train subjects:  27%|██▋       | 78/285 [02:22<06:01,  1.75s/it]predicting train subjects:  28%|██▊       | 79/285 [02:24<06:03,  1.76s/it]predicting train subjects:  28%|██▊       | 80/285 [02:26<06:01,  1.76s/it]predicting train subjects:  28%|██▊       | 81/285 [02:27<05:50,  1.72s/it]predicting train subjects:  29%|██▉       | 82/285 [02:29<05:56,  1.75s/it]predicting train subjects:  29%|██▉       | 83/285 [02:31<05:50,  1.73s/it]predicting train subjects:  29%|██▉       | 84/285 [02:32<05:42,  1.70s/it]predicting train subjects:  30%|██▉       | 85/285 [02:34<05:45,  1.73s/it]predicting train subjects:  30%|███       | 86/285 [02:36<05:54,  1.78s/it]predicting train subjects:  31%|███       | 87/285 [02:38<05:54,  1.79s/it]predicting train subjects:  31%|███       | 88/285 [02:39<05:42,  1.74s/it]predicting train subjects:  31%|███       | 89/285 [02:41<05:37,  1.72s/it]predicting train subjects:  32%|███▏      | 90/285 [02:43<05:42,  1.76s/it]predicting train subjects:  32%|███▏      | 91/285 [02:45<05:37,  1.74s/it]predicting train subjects:  32%|███▏      | 92/285 [02:47<05:42,  1.78s/it]predicting train subjects:  33%|███▎      | 93/285 [02:48<05:33,  1.74s/it]predicting train subjects:  33%|███▎      | 94/285 [02:50<05:36,  1.76s/it]predicting train subjects:  33%|███▎      | 95/285 [02:52<05:40,  1.79s/it]predicting train subjects:  34%|███▎      | 96/285 [02:54<05:37,  1.79s/it]predicting train subjects:  34%|███▍      | 97/285 [02:56<05:41,  1.81s/it]predicting train subjects:  34%|███▍      | 98/285 [02:57<05:34,  1.79s/it]predicting train subjects:  35%|███▍      | 99/285 [02:59<05:30,  1.77s/it]predicting train subjects:  35%|███▌      | 100/285 [03:01<05:33,  1.80s/it]predicting train subjects:  35%|███▌      | 101/285 [03:02<05:20,  1.74s/it]predicting train subjects:  36%|███▌      | 102/285 [03:04<05:21,  1.76s/it]predicting train subjects:  36%|███▌      | 103/285 [03:06<05:09,  1.70s/it]predicting train subjects:  36%|███▋      | 104/285 [03:08<05:13,  1.73s/it]predicting train subjects:  37%|███▋      | 105/285 [03:09<05:17,  1.77s/it]predicting train subjects:  37%|███▋      | 106/285 [03:11<05:10,  1.73s/it]predicting train subjects:  38%|███▊      | 107/285 [03:13<05:16,  1.78s/it]predicting train subjects:  38%|███▊      | 108/285 [03:15<05:10,  1.75s/it]predicting train subjects:  38%|███▊      | 109/285 [03:16<05:08,  1.75s/it]predicting train subjects:  39%|███▊      | 110/285 [03:18<05:14,  1.79s/it]predicting train subjects:  39%|███▉      | 111/285 [03:20<05:03,  1.74s/it]predicting train subjects:  39%|███▉      | 112/285 [03:22<05:00,  1.74s/it]predicting train subjects:  40%|███▉      | 113/285 [03:23<05:01,  1.76s/it]predicting train subjects:  40%|████      | 114/285 [03:25<05:01,  1.77s/it]predicting train subjects:  40%|████      | 115/285 [03:27<04:59,  1.76s/it]predicting train subjects:  41%|████      | 116/285 [03:29<05:01,  1.78s/it]predicting train subjects:  41%|████      | 117/285 [03:30<04:51,  1.74s/it]predicting train subjects:  41%|████▏     | 118/285 [03:32<04:44,  1.70s/it]predicting train subjects:  42%|████▏     | 119/285 [03:34<04:47,  1.73s/it]predicting train subjects:  42%|████▏     | 120/285 [03:35<04:37,  1.68s/it]predicting train subjects:  42%|████▏     | 121/285 [03:37<04:31,  1.66s/it]predicting train subjects:  43%|████▎     | 122/285 [03:39<04:21,  1.60s/it]predicting train subjects:  43%|████▎     | 123/285 [03:40<04:14,  1.57s/it]predicting train subjects:  44%|████▎     | 124/285 [03:42<04:13,  1.57s/it]predicting train subjects:  44%|████▍     | 125/285 [03:43<04:07,  1.55s/it]predicting train subjects:  44%|████▍     | 126/285 [03:45<04:03,  1.53s/it]predicting train subjects:  45%|████▍     | 127/285 [03:46<03:56,  1.50s/it]predicting train subjects:  45%|████▍     | 128/285 [03:48<04:02,  1.54s/it]predicting train subjects:  45%|████▌     | 129/285 [03:49<03:57,  1.52s/it]predicting train subjects:  46%|████▌     | 130/285 [03:51<03:49,  1.48s/it]predicting train subjects:  46%|████▌     | 131/285 [03:52<03:45,  1.46s/it]predicting train subjects:  46%|████▋     | 132/285 [03:54<03:50,  1.50s/it]predicting train subjects:  47%|████▋     | 133/285 [03:55<03:47,  1.50s/it]predicting train subjects:  47%|████▋     | 134/285 [03:56<03:43,  1.48s/it]predicting train subjects:  47%|████▋     | 135/285 [03:58<03:42,  1.48s/it]predicting train subjects:  48%|████▊     | 136/285 [03:59<03:38,  1.46s/it]predicting train subjects:  48%|████▊     | 137/285 [04:01<03:41,  1.50s/it]predicting train subjects:  48%|████▊     | 138/285 [04:02<03:36,  1.47s/it]predicting train subjects:  49%|████▉     | 139/285 [04:04<03:42,  1.52s/it]predicting train subjects:  49%|████▉     | 140/285 [04:06<03:43,  1.54s/it]predicting train subjects:  49%|████▉     | 141/285 [04:07<03:34,  1.49s/it]predicting train subjects:  50%|████▉     | 142/285 [04:08<03:31,  1.48s/it]predicting train subjects:  50%|█████     | 143/285 [04:10<03:28,  1.47s/it]predicting train subjects:  51%|█████     | 144/285 [04:11<03:32,  1.51s/it]predicting train subjects:  51%|█████     | 145/285 [04:13<03:30,  1.50s/it]predicting train subjects:  51%|█████     | 146/285 [04:15<03:33,  1.54s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:16<03:26,  1.50s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:18<03:28,  1.52s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:19<03:24,  1.50s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:21<03:24,  1.51s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:22<03:23,  1.52s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:23<03:17,  1.49s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:25<03:14,  1.47s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:27<03:17,  1.51s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:28<03:14,  1.50s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:30<03:20,  1.55s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:31<03:15,  1.53s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:33<03:14,  1.53s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:34<03:10,  1.51s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:36<03:06,  1.49s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:37<03:09,  1.53s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:39<03:01,  1.48s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:40<03:04,  1.52s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:42<03:02,  1.50s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:43<02:58,  1.49s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:45<03:00,  1.52s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:46<02:59,  1.52s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:48<02:53,  1.49s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:49<02:51,  1.48s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:51<02:48,  1.47s/it]predicting train subjects:  60%|██████    | 171/285 [04:52<02:44,  1.44s/it]predicting train subjects:  60%|██████    | 172/285 [04:53<02:42,  1.44s/it]predicting train subjects:  61%|██████    | 173/285 [04:55<02:46,  1.48s/it]predicting train subjects:  61%|██████    | 174/285 [04:56<02:43,  1.47s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:58<02:45,  1.50s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:00<02:47,  1.53s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:01<02:40,  1.49s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:02<02:35,  1.45s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:04<02:33,  1.45s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:06<02:44,  1.57s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:07<02:43,  1.57s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:09<02:42,  1.57s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:10<02:32,  1.50s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:11<02:28,  1.47s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:13<02:23,  1.43s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:15<02:32,  1.54s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:17<02:41,  1.65s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:18<02:46,  1.72s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:20<02:34,  1.61s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:21<02:27,  1.55s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:23<02:27,  1.57s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:24<02:29,  1.61s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:26<02:21,  1.53s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:27<02:16,  1.50s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:29<02:11,  1.46s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:30<02:21,  1.59s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:32<02:26,  1.67s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:34<02:27,  1.69s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:35<02:16,  1.59s/it]predicting train subjects:  70%|███████   | 200/285 [05:37<02:08,  1.52s/it]predicting train subjects:  71%|███████   | 201/285 [05:39<02:14,  1.60s/it]predicting train subjects:  71%|███████   | 202/285 [05:40<02:14,  1.62s/it]predicting train subjects:  71%|███████   | 203/285 [05:42<02:12,  1.61s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:43<02:04,  1.54s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:45<01:59,  1.49s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:46<01:55,  1.46s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:48<02:05,  1.61s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:50<02:08,  1.67s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:52<02:09,  1.71s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:53<01:59,  1.59s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:54<01:53,  1.54s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:56<01:54,  1.57s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:58<01:54,  1.59s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:59<01:48,  1.53s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:01<01:52,  1.61s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:02<01:45,  1.54s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:04<01:50,  1.62s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:06<01:51,  1.67s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:08<01:53,  1.72s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:09<01:45,  1.62s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:10<01:41,  1.59s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:12<01:42,  1.63s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:14<01:36,  1.56s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:15<01:32,  1.52s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:16<01:28,  1.47s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:18<01:32,  1.57s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:20<01:36,  1.67s/it]predicting train subjects:  80%|████████  | 228/285 [06:22<01:36,  1.70s/it]predicting train subjects:  80%|████████  | 229/285 [06:24<01:34,  1.68s/it]predicting train subjects:  81%|████████  | 230/285 [06:25<01:26,  1.58s/it]predicting train subjects:  81%|████████  | 231/285 [06:26<01:22,  1.54s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:28<01:23,  1.58s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:29<01:19,  1.53s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:31<01:22,  1.62s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:33<01:17,  1.55s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:34<01:19,  1.63s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:36<01:20,  1.67s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:38<01:20,  1.72s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:40<01:18,  1.72s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:41<01:13,  1.62s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:43<01:08,  1.56s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:44<01:04,  1.50s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:45<01:01,  1.47s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:47<01:04,  1.56s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:48<00:59,  1.49s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:50<01:01,  1.58s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:52<01:03,  1.66s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:54<01:01,  1.65s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:55<00:56,  1.57s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:57<00:54,  1.55s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:58<00:51,  1.50s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:59<00:49,  1.49s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:01<00:52,  1.63s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:03<00:51,  1.67s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:05<00:49,  1.66s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:06<00:45,  1.56s/it]predicting train subjects:  90%|█████████ | 257/285 [07:07<00:42,  1.51s/it]predicting train subjects:  91%|█████████ | 258/285 [07:09<00:43,  1.62s/it]predicting train subjects:  91%|█████████ | 259/285 [07:11<00:42,  1.62s/it]predicting train subjects:  91%|█████████ | 260/285 [07:12<00:38,  1.53s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:14<00:35,  1.49s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:15<00:33,  1.46s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:16<00:31,  1.42s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:18<00:32,  1.56s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:20<00:32,  1.63s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:21<00:29,  1.56s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:23<00:27,  1.52s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:25<00:27,  1.61s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:26<00:25,  1.62s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:28<00:23,  1.55s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:29<00:21,  1.51s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:31<00:20,  1.55s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:32<00:18,  1.50s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:34<00:16,  1.47s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:35<00:15,  1.59s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:37<00:14,  1.65s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:39<00:12,  1.55s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:40<00:10,  1.53s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:42<00:09,  1.56s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:43<00:07,  1.52s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:45<00:05,  1.49s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:46<00:04,  1.45s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:48<00:03,  1.56s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:49<00:01,  1.63s/it]predicting train subjects: 100%|██████████| 285/285 [07:51<00:00,  1.67s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:34,  1.60s/it]Loading train:   1%|          | 2/285 [00:02<07:07,  1.51s/it]Loading train:   1%|          | 3/285 [00:04<07:00,  1.49s/it]Loading train:   1%|▏         | 4/285 [00:05<06:40,  1.42s/it]Loading train:   2%|▏         | 5/285 [00:07<06:55,  1.48s/it]Loading train:   2%|▏         | 6/285 [00:08<06:47,  1.46s/it]Loading train:   2%|▏         | 7/285 [00:10<07:00,  1.51s/it]Loading train:   3%|▎         | 8/285 [00:11<06:49,  1.48s/it]Loading train:   3%|▎         | 9/285 [00:13<07:14,  1.57s/it]Loading train:   4%|▎         | 10/285 [00:14<06:43,  1.47s/it]Loading train:   4%|▍         | 11/285 [00:15<06:19,  1.38s/it]Loading train:   4%|▍         | 12/285 [00:17<06:03,  1.33s/it]Loading train:   5%|▍         | 13/285 [00:18<05:32,  1.22s/it]Loading train:   5%|▍         | 14/285 [00:19<05:35,  1.24s/it]Loading train:   5%|▌         | 15/285 [00:20<05:50,  1.30s/it]Loading train:   6%|▌         | 16/285 [00:22<05:50,  1.30s/it]Loading train:   6%|▌         | 17/285 [00:23<05:23,  1.21s/it]Loading train:   6%|▋         | 18/285 [00:24<05:20,  1.20s/it]Loading train:   7%|▋         | 19/285 [00:25<04:58,  1.12s/it]Loading train:   7%|▋         | 20/285 [00:26<04:48,  1.09s/it]Loading train:   7%|▋         | 21/285 [00:27<05:01,  1.14s/it]Loading train:   8%|▊         | 22/285 [00:28<04:51,  1.11s/it]Loading train:   8%|▊         | 23/285 [00:29<04:47,  1.10s/it]Loading train:   8%|▊         | 24/285 [00:30<04:40,  1.07s/it]Loading train:   9%|▉         | 25/285 [00:31<04:52,  1.12s/it]Loading train:   9%|▉         | 26/285 [00:33<05:07,  1.19s/it]Loading train:   9%|▉         | 27/285 [00:34<05:04,  1.18s/it]Loading train:  10%|▉         | 28/285 [00:35<05:02,  1.18s/it]Loading train:  10%|█         | 29/285 [00:36<04:51,  1.14s/it]Loading train:  11%|█         | 30/285 [00:38<05:16,  1.24s/it]Loading train:  11%|█         | 31/285 [00:39<05:31,  1.30s/it]Loading train:  11%|█         | 32/285 [00:40<05:29,  1.30s/it]Loading train:  12%|█▏        | 33/285 [00:41<05:15,  1.25s/it]Loading train:  12%|█▏        | 34/285 [00:42<04:57,  1.19s/it]Loading train:  12%|█▏        | 35/285 [00:44<05:04,  1.22s/it]Loading train:  13%|█▎        | 36/285 [00:45<04:56,  1.19s/it]Loading train:  13%|█▎        | 37/285 [00:46<04:55,  1.19s/it]Loading train:  13%|█▎        | 38/285 [00:47<04:55,  1.20s/it]Loading train:  14%|█▎        | 39/285 [00:48<04:46,  1.17s/it]Loading train:  14%|█▍        | 40/285 [00:49<04:34,  1.12s/it]Loading train:  14%|█▍        | 41/285 [00:51<04:39,  1.15s/it]Loading train:  15%|█▍        | 42/285 [00:52<04:24,  1.09s/it]Loading train:  15%|█▌        | 43/285 [00:53<04:23,  1.09s/it]Loading train:  15%|█▌        | 44/285 [00:54<04:42,  1.17s/it]Loading train:  16%|█▌        | 45/285 [00:55<04:30,  1.13s/it]Loading train:  16%|█▌        | 46/285 [00:56<04:30,  1.13s/it]Loading train:  16%|█▋        | 47/285 [00:57<04:09,  1.05s/it]Loading train:  17%|█▋        | 48/285 [00:58<04:08,  1.05s/it]Loading train:  17%|█▋        | 49/285 [00:59<04:22,  1.11s/it]Loading train:  18%|█▊        | 50/285 [01:00<04:19,  1.10s/it]Loading train:  18%|█▊        | 51/285 [01:02<04:30,  1.15s/it]Loading train:  18%|█▊        | 52/285 [01:03<04:15,  1.10s/it]Loading train:  19%|█▊        | 53/285 [01:04<04:15,  1.10s/it]Loading train:  19%|█▉        | 54/285 [01:05<04:26,  1.15s/it]Loading train:  19%|█▉        | 55/285 [01:06<04:27,  1.16s/it]Loading train:  20%|█▉        | 56/285 [01:07<04:21,  1.14s/it]Loading train:  20%|██        | 57/285 [01:08<04:17,  1.13s/it]Loading train:  20%|██        | 58/285 [01:10<04:17,  1.13s/it]Loading train:  21%|██        | 59/285 [01:11<04:31,  1.20s/it]Loading train:  21%|██        | 60/285 [01:12<04:32,  1.21s/it]Loading train:  21%|██▏       | 61/285 [01:13<04:16,  1.14s/it]Loading train:  22%|██▏       | 62/285 [01:14<04:13,  1.14s/it]Loading train:  22%|██▏       | 63/285 [01:15<04:12,  1.14s/it]Loading train:  22%|██▏       | 64/285 [01:17<04:37,  1.25s/it]Loading train:  23%|██▎       | 65/285 [01:18<04:56,  1.35s/it]Loading train:  23%|██▎       | 66/285 [01:20<05:09,  1.41s/it]Loading train:  24%|██▎       | 67/285 [01:21<05:08,  1.41s/it]Loading train:  24%|██▍       | 68/285 [01:23<05:09,  1.43s/it]Loading train:  24%|██▍       | 69/285 [01:25<05:22,  1.49s/it]Loading train:  25%|██▍       | 70/285 [01:26<05:25,  1.52s/it]Loading train:  25%|██▍       | 71/285 [01:28<05:26,  1.53s/it]Loading train:  25%|██▌       | 72/285 [01:29<05:32,  1.56s/it]Loading train:  26%|██▌       | 73/285 [01:31<05:31,  1.56s/it]Loading train:  26%|██▌       | 74/285 [01:32<05:21,  1.52s/it]Loading train:  26%|██▋       | 75/285 [01:34<05:09,  1.47s/it]Loading train:  27%|██▋       | 76/285 [01:35<05:02,  1.45s/it]Loading train:  27%|██▋       | 77/285 [01:36<04:47,  1.38s/it]Loading train:  27%|██▋       | 78/285 [01:38<04:47,  1.39s/it]Loading train:  28%|██▊       | 79/285 [01:39<04:48,  1.40s/it]Loading train:  28%|██▊       | 80/285 [01:41<04:45,  1.39s/it]Loading train:  28%|██▊       | 81/285 [01:42<04:37,  1.36s/it]Loading train:  29%|██▉       | 82/285 [01:43<04:41,  1.39s/it]Loading train:  29%|██▉       | 83/285 [01:45<04:54,  1.46s/it]Loading train:  29%|██▉       | 84/285 [01:46<04:40,  1.39s/it]Loading train:  30%|██▉       | 85/285 [01:47<04:33,  1.37s/it]Loading train:  30%|███       | 86/285 [01:49<04:35,  1.38s/it]Loading train:  31%|███       | 87/285 [01:50<04:35,  1.39s/it]Loading train:  31%|███       | 88/285 [01:51<04:18,  1.31s/it]Loading train:  31%|███       | 89/285 [01:53<04:17,  1.31s/it]Loading train:  32%|███▏      | 90/285 [01:54<04:10,  1.28s/it]Loading train:  32%|███▏      | 91/285 [01:55<04:21,  1.35s/it]Loading train:  32%|███▏      | 92/285 [01:57<04:30,  1.40s/it]Loading train:  33%|███▎      | 93/285 [01:58<04:15,  1.33s/it]Loading train:  33%|███▎      | 94/285 [01:59<04:16,  1.35s/it]Loading train:  33%|███▎      | 95/285 [02:01<04:26,  1.40s/it]Loading train:  34%|███▎      | 96/285 [02:02<04:25,  1.40s/it]Loading train:  34%|███▍      | 97/285 [02:04<04:24,  1.40s/it]Loading train:  34%|███▍      | 98/285 [02:05<04:12,  1.35s/it]Loading train:  35%|███▍      | 99/285 [02:06<04:14,  1.37s/it]Loading train:  35%|███▌      | 100/285 [02:08<04:17,  1.39s/it]Loading train:  35%|███▌      | 101/285 [02:10<04:29,  1.46s/it]Loading train:  36%|███▌      | 102/285 [02:11<04:33,  1.50s/it]Loading train:  36%|███▌      | 103/285 [02:13<04:31,  1.49s/it]Loading train:  36%|███▋      | 104/285 [02:14<04:20,  1.44s/it]Loading train:  37%|███▋      | 105/285 [02:16<04:30,  1.50s/it]Loading train:  37%|███▋      | 106/285 [02:17<04:09,  1.39s/it]Loading train:  38%|███▊      | 107/285 [02:18<04:08,  1.40s/it]Loading train:  38%|███▊      | 108/285 [02:20<04:14,  1.44s/it]Loading train:  38%|███▊      | 109/285 [02:21<04:10,  1.42s/it]Loading train:  39%|███▊      | 110/285 [02:22<04:03,  1.39s/it]Loading train:  39%|███▉      | 111/285 [02:24<03:53,  1.34s/it]Loading train:  39%|███▉      | 112/285 [02:25<03:59,  1.38s/it]Loading train:  40%|███▉      | 113/285 [02:27<04:16,  1.49s/it]Loading train:  40%|████      | 114/285 [02:28<04:04,  1.43s/it]Loading train:  40%|████      | 115/285 [02:29<03:53,  1.37s/it]Loading train:  41%|████      | 116/285 [02:31<03:51,  1.37s/it]Loading train:  41%|████      | 117/285 [02:32<03:47,  1.35s/it]Loading train:  41%|████▏     | 118/285 [02:33<03:46,  1.35s/it]Loading train:  42%|████▏     | 119/285 [02:35<03:46,  1.36s/it]Loading train:  42%|████▏     | 120/285 [02:36<03:49,  1.39s/it]Loading train:  42%|████▏     | 121/285 [02:38<03:55,  1.43s/it]Loading train:  43%|████▎     | 122/285 [02:39<03:47,  1.40s/it]Loading train:  43%|████▎     | 123/285 [02:40<03:46,  1.40s/it]Loading train:  44%|████▎     | 124/285 [02:42<03:37,  1.35s/it]Loading train:  44%|████▍     | 125/285 [02:43<03:34,  1.34s/it]Loading train:  44%|████▍     | 126/285 [02:44<03:29,  1.32s/it]Loading train:  45%|████▍     | 127/285 [02:46<03:29,  1.32s/it]Loading train:  45%|████▍     | 128/285 [02:47<03:28,  1.33s/it]Loading train:  45%|████▌     | 129/285 [02:48<03:23,  1.30s/it]Loading train:  46%|████▌     | 130/285 [02:49<03:15,  1.26s/it]Loading train:  46%|████▌     | 131/285 [02:51<03:13,  1.26s/it]Loading train:  46%|████▋     | 132/285 [02:52<03:10,  1.24s/it]Loading train:  47%|████▋     | 133/285 [02:53<03:06,  1.22s/it]Loading train:  47%|████▋     | 134/285 [02:54<03:08,  1.25s/it]Loading train:  47%|████▋     | 135/285 [02:56<03:06,  1.25s/it]Loading train:  48%|████▊     | 136/285 [02:57<03:02,  1.23s/it]Loading train:  48%|████▊     | 137/285 [02:58<03:04,  1.25s/it]Loading train:  48%|████▊     | 138/285 [02:59<03:01,  1.24s/it]Loading train:  49%|████▉     | 139/285 [03:00<03:02,  1.25s/it]Loading train:  49%|████▉     | 140/285 [03:02<02:59,  1.24s/it]Loading train:  49%|████▉     | 141/285 [03:03<02:58,  1.24s/it]Loading train:  50%|████▉     | 142/285 [03:04<02:55,  1.23s/it]Loading train:  50%|█████     | 143/285 [03:05<02:47,  1.18s/it]Loading train:  51%|█████     | 144/285 [03:06<02:46,  1.18s/it]Loading train:  51%|█████     | 145/285 [03:08<02:44,  1.18s/it]Loading train:  51%|█████     | 146/285 [03:09<02:48,  1.21s/it]Loading train:  52%|█████▏    | 147/285 [03:10<02:37,  1.14s/it]Loading train:  52%|█████▏    | 148/285 [03:11<02:39,  1.16s/it]Loading train:  52%|█████▏    | 149/285 [03:12<02:39,  1.17s/it]Loading train:  53%|█████▎    | 150/285 [03:14<02:50,  1.26s/it]Loading train:  53%|█████▎    | 151/285 [03:15<02:53,  1.30s/it]Loading train:  53%|█████▎    | 152/285 [03:16<02:51,  1.29s/it]Loading train:  54%|█████▎    | 153/285 [03:18<02:48,  1.28s/it]Loading train:  54%|█████▍    | 154/285 [03:19<02:46,  1.27s/it]Loading train:  54%|█████▍    | 155/285 [03:20<02:42,  1.25s/it]Loading train:  55%|█████▍    | 156/285 [03:21<02:40,  1.24s/it]Loading train:  55%|█████▌    | 157/285 [03:22<02:34,  1.20s/it]Loading train:  55%|█████▌    | 158/285 [03:24<02:29,  1.17s/it]Loading train:  56%|█████▌    | 159/285 [03:25<02:29,  1.19s/it]Loading train:  56%|█████▌    | 160/285 [03:26<02:29,  1.20s/it]Loading train:  56%|█████▋    | 161/285 [03:27<02:32,  1.23s/it]Loading train:  57%|█████▋    | 162/285 [03:29<02:34,  1.26s/it]Loading train:  57%|█████▋    | 163/285 [03:30<02:36,  1.28s/it]Loading train:  58%|█████▊    | 164/285 [03:31<02:43,  1.35s/it]Loading train:  58%|█████▊    | 165/285 [03:33<02:34,  1.29s/it]Loading train:  58%|█████▊    | 166/285 [03:34<02:24,  1.22s/it]Loading train:  59%|█████▊    | 167/285 [03:35<02:24,  1.22s/it]Loading train:  59%|█████▉    | 168/285 [03:36<02:16,  1.17s/it]Loading train:  59%|█████▉    | 169/285 [03:37<02:14,  1.16s/it]Loading train:  60%|█████▉    | 170/285 [03:38<02:17,  1.20s/it]Loading train:  60%|██████    | 171/285 [03:40<02:18,  1.22s/it]Loading train:  60%|██████    | 172/285 [03:41<02:16,  1.21s/it]Loading train:  61%|██████    | 173/285 [03:42<02:08,  1.14s/it]Loading train:  61%|██████    | 174/285 [03:43<02:06,  1.14s/it]Loading train:  61%|██████▏   | 175/285 [03:44<02:13,  1.22s/it]Loading train:  62%|██████▏   | 176/285 [03:46<02:14,  1.23s/it]Loading train:  62%|██████▏   | 177/285 [03:47<02:09,  1.20s/it]Loading train:  62%|██████▏   | 178/285 [03:48<02:10,  1.22s/it]Loading train:  63%|██████▎   | 179/285 [03:49<02:08,  1.21s/it]Loading train:  63%|██████▎   | 180/285 [03:51<02:14,  1.28s/it]Loading train:  64%|██████▎   | 181/285 [03:52<02:15,  1.30s/it]Loading train:  64%|██████▍   | 182/285 [03:53<02:18,  1.35s/it]Loading train:  64%|██████▍   | 183/285 [03:55<02:14,  1.32s/it]Loading train:  65%|██████▍   | 184/285 [03:56<02:15,  1.34s/it]Loading train:  65%|██████▍   | 185/285 [03:57<02:07,  1.28s/it]Loading train:  65%|██████▌   | 186/285 [03:59<02:13,  1.35s/it]Loading train:  66%|██████▌   | 187/285 [04:00<02:13,  1.36s/it]Loading train:  66%|██████▌   | 188/285 [04:02<02:15,  1.40s/it]Loading train:  66%|██████▋   | 189/285 [04:03<02:07,  1.33s/it]Loading train:  67%|██████▋   | 190/285 [04:04<01:58,  1.25s/it]Loading train:  67%|██████▋   | 191/285 [04:05<02:03,  1.31s/it]Loading train:  67%|██████▋   | 192/285 [04:07<01:59,  1.29s/it]Loading train:  68%|██████▊   | 193/285 [04:08<01:58,  1.29s/it]Loading train:  68%|██████▊   | 194/285 [04:09<01:52,  1.24s/it]Loading train:  68%|██████▊   | 195/285 [04:10<01:50,  1.23s/it]Loading train:  69%|██████▉   | 196/285 [04:11<01:52,  1.27s/it]Loading train:  69%|██████▉   | 197/285 [04:13<01:59,  1.35s/it]Loading train:  69%|██████▉   | 198/285 [04:14<01:58,  1.36s/it]Loading train:  70%|██████▉   | 199/285 [04:15<01:49,  1.27s/it]Loading train:  70%|███████   | 200/285 [04:17<01:46,  1.26s/it]Loading train:  71%|███████   | 201/285 [04:18<01:47,  1.28s/it]Loading train:  71%|███████   | 202/285 [04:19<01:48,  1.31s/it]Loading train:  71%|███████   | 203/285 [04:21<01:53,  1.38s/it]Loading train:  72%|███████▏  | 204/285 [04:22<01:48,  1.34s/it]Loading train:  72%|███████▏  | 205/285 [04:23<01:40,  1.25s/it]Loading train:  72%|███████▏  | 206/285 [04:24<01:36,  1.22s/it]Loading train:  73%|███████▎  | 207/285 [04:26<01:38,  1.26s/it]Loading train:  73%|███████▎  | 208/285 [04:27<01:37,  1.26s/it]Loading train:  73%|███████▎  | 209/285 [04:28<01:36,  1.27s/it]Loading train:  74%|███████▎  | 210/285 [04:30<01:38,  1.32s/it]Loading train:  74%|███████▍  | 211/285 [04:31<01:35,  1.29s/it]Loading train:  74%|███████▍  | 212/285 [04:32<01:32,  1.27s/it]Loading train:  75%|███████▍  | 213/285 [04:33<01:30,  1.26s/it]Loading train:  75%|███████▌  | 214/285 [04:35<01:28,  1.24s/it]Loading train:  75%|███████▌  | 215/285 [04:36<01:28,  1.26s/it]Loading train:  76%|███████▌  | 216/285 [04:37<01:24,  1.23s/it]Loading train:  76%|███████▌  | 217/285 [04:39<01:30,  1.33s/it]Loading train:  76%|███████▋  | 218/285 [04:40<01:28,  1.33s/it]Loading train:  77%|███████▋  | 219/285 [04:41<01:27,  1.33s/it]Loading train:  77%|███████▋  | 220/285 [04:43<01:25,  1.32s/it]Loading train:  78%|███████▊  | 221/285 [04:44<01:21,  1.28s/it]Loading train:  78%|███████▊  | 222/285 [04:45<01:19,  1.25s/it]Loading train:  78%|███████▊  | 223/285 [04:46<01:19,  1.28s/it]Loading train:  79%|███████▊  | 224/285 [04:47<01:16,  1.26s/it]Loading train:  79%|███████▉  | 225/285 [04:49<01:16,  1.28s/it]Loading train:  79%|███████▉  | 226/285 [04:50<01:16,  1.30s/it]Loading train:  80%|███████▉  | 227/285 [04:52<01:19,  1.37s/it]Loading train:  80%|████████  | 228/285 [04:53<01:22,  1.44s/it]Loading train:  80%|████████  | 229/285 [04:55<01:18,  1.40s/it]Loading train:  81%|████████  | 230/285 [04:56<01:12,  1.33s/it]Loading train:  81%|████████  | 231/285 [04:57<01:07,  1.25s/it]Loading train:  81%|████████▏ | 232/285 [04:58<01:03,  1.20s/it]Loading train:  82%|████████▏ | 233/285 [04:59<01:02,  1.20s/it]Loading train:  82%|████████▏ | 234/285 [05:01<01:07,  1.32s/it]Loading train:  82%|████████▏ | 235/285 [05:02<01:05,  1.30s/it]Loading train:  83%|████████▎ | 236/285 [05:04<01:10,  1.44s/it]Loading train:  83%|████████▎ | 237/285 [05:05<01:07,  1.40s/it]Loading train:  84%|████████▎ | 238/285 [05:06<01:06,  1.40s/it]Loading train:  84%|████████▍ | 239/285 [05:08<01:10,  1.53s/it]Loading train:  84%|████████▍ | 240/285 [05:10<01:04,  1.44s/it]Loading train:  85%|████████▍ | 241/285 [05:11<00:59,  1.36s/it]Loading train:  85%|████████▍ | 242/285 [05:12<00:57,  1.33s/it]Loading train:  85%|████████▌ | 243/285 [05:13<00:53,  1.28s/it]Loading train:  86%|████████▌ | 244/285 [05:14<00:53,  1.31s/it]Loading train:  86%|████████▌ | 245/285 [05:16<00:50,  1.25s/it]Loading train:  86%|████████▋ | 246/285 [05:17<00:51,  1.33s/it]Loading train:  87%|████████▋ | 247/285 [05:18<00:50,  1.33s/it]Loading train:  87%|████████▋ | 248/285 [05:20<00:48,  1.30s/it]Loading train:  87%|████████▋ | 249/285 [05:21<00:51,  1.42s/it]Loading train:  88%|████████▊ | 250/285 [05:23<00:50,  1.45s/it]Loading train:  88%|████████▊ | 251/285 [05:24<00:45,  1.35s/it]Loading train:  88%|████████▊ | 252/285 [05:25<00:45,  1.37s/it]Loading train:  89%|████████▉ | 253/285 [05:27<00:44,  1.40s/it]Loading train:  89%|████████▉ | 254/285 [05:28<00:43,  1.40s/it]Loading train:  89%|████████▉ | 255/285 [05:30<00:40,  1.36s/it]Loading train:  90%|████████▉ | 256/285 [05:31<00:38,  1.33s/it]Loading train:  90%|█████████ | 257/285 [05:32<00:35,  1.28s/it]Loading train:  91%|█████████ | 258/285 [05:33<00:35,  1.32s/it]Loading train:  91%|█████████ | 259/285 [05:35<00:32,  1.27s/it]Loading train:  91%|█████████ | 260/285 [05:36<00:31,  1.25s/it]Loading train:  92%|█████████▏| 261/285 [05:37<00:29,  1.22s/it]Loading train:  92%|█████████▏| 262/285 [05:38<00:27,  1.18s/it]Loading train:  92%|█████████▏| 263/285 [05:39<00:27,  1.24s/it]Loading train:  93%|█████████▎| 264/285 [05:41<00:29,  1.39s/it]Loading train:  93%|█████████▎| 265/285 [05:43<00:27,  1.39s/it]Loading train:  93%|█████████▎| 266/285 [05:44<00:24,  1.31s/it]Loading train:  94%|█████████▎| 267/285 [05:45<00:23,  1.29s/it]Loading train:  94%|█████████▍| 268/285 [05:46<00:21,  1.28s/it]Loading train:  94%|█████████▍| 269/285 [05:47<00:20,  1.29s/it]Loading train:  95%|█████████▍| 270/285 [05:49<00:19,  1.28s/it]Loading train:  95%|█████████▌| 271/285 [05:50<00:17,  1.28s/it]Loading train:  95%|█████████▌| 272/285 [05:51<00:16,  1.24s/it]Loading train:  96%|█████████▌| 273/285 [05:52<00:14,  1.20s/it]Loading train:  96%|█████████▌| 274/285 [05:54<00:13,  1.25s/it]Loading train:  96%|█████████▋| 275/285 [05:55<00:12,  1.28s/it]Loading train:  97%|█████████▋| 276/285 [05:56<00:11,  1.25s/it]Loading train:  97%|█████████▋| 277/285 [05:57<00:09,  1.24s/it]Loading train:  98%|█████████▊| 278/285 [05:58<00:08,  1.18s/it]Loading train:  98%|█████████▊| 279/285 [06:00<00:07,  1.25s/it]Loading train:  98%|█████████▊| 280/285 [06:01<00:06,  1.24s/it]Loading train:  99%|█████████▊| 281/285 [06:02<00:04,  1.24s/it]Loading train:  99%|█████████▉| 282/285 [06:04<00:03,  1.25s/it]Loading train:  99%|█████████▉| 283/285 [06:05<00:02,  1.32s/it]Loading train: 100%|█████████▉| 284/285 [06:06<00:01,  1.37s/it]Loading train: 100%|██████████| 285/285 [06:08<00:00,  1.51s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/285 [00:00<00:06, 46.58it/s]concatenating: train:   4%|▍         | 12/285 [00:00<00:05, 50.43it/s]concatenating: train:   6%|▌         | 16/285 [00:00<00:05, 44.88it/s]concatenating: train:   7%|▋         | 20/285 [00:00<00:06, 39.69it/s]concatenating: train:   9%|▉         | 27/285 [00:00<00:05, 44.57it/s]concatenating: train:  12%|█▏        | 33/285 [00:00<00:05, 48.24it/s]concatenating: train:  14%|█▍        | 40/285 [00:00<00:04, 52.78it/s]concatenating: train:  17%|█▋        | 48/285 [00:00<00:04, 57.76it/s]concatenating: train:  20%|██        | 58/285 [00:00<00:03, 64.11it/s]concatenating: train:  26%|██▌       | 74/285 [00:01<00:02, 78.16it/s]concatenating: train:  29%|██▉       | 84/285 [00:01<00:02, 67.40it/s]concatenating: train:  35%|███▌      | 100/285 [00:01<00:02, 81.50it/s]concatenating: train:  39%|███▉      | 111/285 [00:01<00:01, 88.36it/s]concatenating: train:  44%|████▎     | 124/285 [00:01<00:01, 95.22it/s]concatenating: train:  47%|████▋     | 135/285 [00:01<00:02, 71.95it/s]concatenating: train:  51%|█████     | 145/285 [00:01<00:01, 70.90it/s]concatenating: train:  54%|█████▍    | 154/285 [00:02<00:01, 73.83it/s]concatenating: train:  58%|█████▊    | 166/285 [00:02<00:01, 83.45it/s]concatenating: train:  65%|██████▌   | 186/285 [00:02<00:00, 100.90it/s]concatenating: train:  76%|███████▌  | 216/285 [00:02<00:00, 124.35it/s]concatenating: train:  82%|████████▏ | 233/285 [00:02<00:00, 102.84it/s]concatenating: train:  87%|████████▋ | 248/285 [00:02<00:00, 96.93it/s] concatenating: train:  92%|█████████▏| 261/285 [00:03<00:00, 75.57it/s]concatenating: train:  95%|█████████▌| 272/285 [00:03<00:00, 64.65it/s]concatenating: train: 100%|█████████▉| 284/285 [00:03<00:00, 74.98it/s]concatenating: train: 100%|██████████| 285/285 [00:03<00:00, 83.15it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.60s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.61s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.58s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 40.67it/s]2019-07-09 04:57:42.014947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-09 04:57:42.015051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-09 04:57:42.015065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-09 04:57:42.015074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-09 04:57:42.015490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12743 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:10,  4.29it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:08,  4.89it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:08,  4.63it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:06,  5.98it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.54it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.34it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:06,  5.06it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:04,  6.54it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  7.13it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.00it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.50it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  7.90it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  8.19it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:02,  6.23it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  7.84it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:00,  8.14it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  7.63it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:04<00:00,  6.19it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  5.48it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  8.87it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 40)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 41)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   7400        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 13)   793         dropout_6[0][0]                  
==================================================================================================
Total params: 231,593
Trainable params: 56,833
Non-trainable params: 174,760
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 30s - loss: 10963.6824 - acc: 0.6238 - mDice: 0.1882 - val_loss: 5703.2649 - val_acc: 0.9198 - val_mDice: 0.3339

Epoch 00001: val_mDice improved from -inf to 0.33392, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 22s - loss: 3832.4053 - acc: 0.9019 - mDice: 0.4645 - val_loss: 2700.4549 - val_acc: 0.9311 - val_mDice: 0.5467

Epoch 00002: val_mDice improved from 0.33392 to 0.54666, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 22s - loss: 3103.8395 - acc: 0.9081 - mDice: 0.5370 - val_loss: 2607.1911 - val_acc: 0.9359 - val_mDice: 0.5604

Epoch 00003: val_mDice improved from 0.54666 to 0.56036, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 22s - loss: 2728.6474 - acc: 0.9134 - mDice: 0.5777 - val_loss: 2688.0904 - val_acc: 0.9353 - val_mDice: 0.5498

Epoch 00004: val_mDice did not improve from 0.56036
Epoch 5/300
 - 21s - loss: 2499.7973 - acc: 0.9202 - mDice: 0.6045 - val_loss: 2612.1370 - val_acc: 0.9407 - val_mDice: 0.5587

Epoch 00005: val_mDice did not improve from 0.56036
Epoch 6/300
 - 22s - loss: 2338.7221 - acc: 0.9278 - mDice: 0.6241 - val_loss: 2461.8222 - val_acc: 0.9458 - val_mDice: 0.5756

Epoch 00006: val_mDice improved from 0.56036 to 0.57559, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 23s - loss: 2217.1929 - acc: 0.9341 - mDice: 0.6391 - val_loss: 2466.2491 - val_acc: 0.9467 - val_mDice: 0.5747

Epoch 00007: val_mDice did not improve from 0.57559
Epoch 8/300
 - 22s - loss: 2125.8354 - acc: 0.9388 - mDice: 0.6506 - val_loss: 2661.6077 - val_acc: 0.9447 - val_mDice: 0.5584

Epoch 00008: val_mDice did not improve from 0.57559
Epoch 9/300
 - 22s - loss: 2058.5628 - acc: 0.9414 - mDice: 0.6593 - val_loss: 2426.0017 - val_acc: 0.9487 - val_mDice: 0.5814

Epoch 00009: val_mDice improved from 0.57559 to 0.58141, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 22s - loss: 1993.1767 - acc: 0.9431 - mDice: 0.6678 - val_loss: 2593.8889 - val_acc: 0.9484 - val_mDice: 0.5679

Epoch 00010: val_mDice did not improve from 0.58141
Epoch 11/300
 - 22s - loss: 1944.2689 - acc: 0.9442 - mDice: 0.6742 - val_loss: 2381.7695 - val_acc: 0.9504 - val_mDice: 0.5881

Epoch 00011: val_mDice improved from 0.58141 to 0.58806, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 22s - loss: 1894.6197 - acc: 0.9453 - mDice: 0.6810 - val_loss: 2582.6613 - val_acc: 0.9489 - val_mDice: 0.5688

Epoch 00012: val_mDice did not improve from 0.58806
Epoch 13/300
 - 22s - loss: 1856.5981 - acc: 0.9459 - mDice: 0.6860 - val_loss: 2453.9446 - val_acc: 0.9510 - val_mDice: 0.5840

Epoch 00013: val_mDice did not improve from 0.58806
Epoch 14/300
 - 22s - loss: 1875.3684 - acc: 0.9459 - mDice: 0.6839 - val_loss: 2532.5253 - val_acc: 0.9517 - val_mDice: 0.5758

Epoch 00014: val_mDice did not improve from 0.58806
Epoch 15/300
 - 21s - loss: 1797.0524 - acc: 0.9469 - mDice: 0.6943 - val_loss: 2321.6034 - val_acc: 0.9506 - val_mDice: 0.5971

Epoch 00015: val_mDice improved from 0.58806 to 0.59707, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 21s - loss: 1771.8772 - acc: 0.9475 - mDice: 0.6977 - val_loss: 2384.0901 - val_acc: 0.9485 - val_mDice: 0.5898

Epoch 00016: val_mDice did not improve from 0.59707
Epoch 17/300
 - 22s - loss: 1743.4757 - acc: 0.9480 - mDice: 0.7017 - val_loss: 2433.8569 - val_acc: 0.9519 - val_mDice: 0.5881

Epoch 00017: val_mDice did not improve from 0.59707
Epoch 18/300
 - 22s - loss: 1717.9946 - acc: 0.9483 - mDice: 0.7052 - val_loss: 2447.8360 - val_acc: 0.9514 - val_mDice: 0.5900

Epoch 00018: val_mDice did not improve from 0.59707
Epoch 19/300
 - 21s - loss: 1697.4484 - acc: 0.9487 - mDice: 0.7081 - val_loss: 2486.5198 - val_acc: 0.9515 - val_mDice: 0.5876

Epoch 00019: val_mDice did not improve from 0.59707
Epoch 20/300
 - 22s - loss: 1678.1494 - acc: 0.9491 - mDice: 0.7110 - val_loss: 2307.4431 - val_acc: 0.9522 - val_mDice: 0.5990

Epoch 00020: val_mDice improved from 0.59707 to 0.59896, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 21/300
 - 22s - loss: 1656.8158 - acc: 0.9494 - mDice: 0.7138 - val_loss: 2401.2173 - val_acc: 0.9511 - val_mDice: 0.5876

Epoch 00021: val_mDice did not improve from 0.59896
Epoch 22/300
 - 22s - loss: 1645.7547 - acc: 0.9494 - mDice: 0.7154 - val_loss: 2280.3768 - val_acc: 0.9536 - val_mDice: 0.6044

Epoch 00022: val_mDice improved from 0.59896 to 0.60442, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 23/300
 - 21s - loss: 1616.1475 - acc: 0.9499 - mDice: 0.7196 - val_loss: 2332.2494 - val_acc: 0.9523 - val_mDice: 0.5970

Epoch 00023: val_mDice did not improve from 0.60442
Epoch 24/300
 - 22s - loss: 1595.5685 - acc: 0.9501 - mDice: 0.7226 - val_loss: 2572.4674 - val_acc: 0.9523 - val_mDice: 0.5760

Epoch 00024: val_mDice did not improve from 0.60442
Epoch 25/300
 - 22s - loss: 1578.8702 - acc: 0.9504 - mDice: 0.7250 - val_loss: 2408.5043 - val_acc: 0.9526 - val_mDice: 0.5905

Epoch 00025: val_mDice did not improve from 0.60442
Epoch 26/300
 - 22s - loss: 1567.9177 - acc: 0.9505 - mDice: 0.7265 - val_loss: 2302.5630 - val_acc: 0.9529 - val_mDice: 0.6007

Epoch 00026: val_mDice did not improve from 0.60442
Epoch 27/300
 - 22s - loss: 1551.1848 - acc: 0.9507 - mDice: 0.7290 - val_loss: 2493.7139 - val_acc: 0.9537 - val_mDice: 0.5850

Epoch 00027: val_mDice did not improve from 0.60442
Epoch 28/300
 - 20s - loss: 1543.0455 - acc: 0.9509 - mDice: 0.7303 - val_loss: 2220.7450 - val_acc: 0.9541 - val_mDice: 0.6107

Epoch 00028: val_mDice improved from 0.60442 to 0.61075, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 29/300
 - 22s - loss: 1530.2228 - acc: 0.9511 - mDice: 0.7321 - val_loss: 2377.4132 - val_acc: 0.9508 - val_mDice: 0.5911

Epoch 00029: val_mDice did not improve from 0.61075
Epoch 30/300
 - 22s - loss: 1510.0926 - acc: 0.9514 - mDice: 0.7350 - val_loss: 2601.3739 - val_acc: 0.9526 - val_mDice: 0.5705

Epoch 00030: val_mDice did not improve from 0.61075
Epoch 31/300
 - 22s - loss: 1506.3985 - acc: 0.9514 - mDice: 0.7355 - val_loss: 2353.9968 - val_acc: 0.9536 - val_mDice: 0.5975

Epoch 00031: val_mDice did not improve from 0.61075
Epoch 32/300
 - 21s - loss: 1495.4250 - acc: 0.9516 - mDice: 0.7372 - val_loss: 2345.6829 - val_acc: 0.9523 - val_mDice: 0.5976

Epoch 00032: val_mDice did not improve from 0.61075
Epoch 33/300
 - 22s - loss: 1481.4730 - acc: 0.9518 - mDice: 0.7393 - val_loss: 2327.3785 - val_acc: 0.9524 - val_mDice: 0.5975

Epoch 00033: val_mDice did not improve from 0.61075
Epoch 34/300
 - 21s - loss: 1479.9606 - acc: 0.9519 - mDice: 0.7396 - val_loss: 2340.9684 - val_acc: 0.9540 - val_mDice: 0.6001

Epoch 00034: val_mDice did not improve from 0.61075
Epoch 35/300
 - 22s - loss: 1459.8517 - acc: 0.9522 - mDice: 0.7426 - val_loss: 2769.4475 - val_acc: 0.9532 - val_mDice: 0.5633

Epoch 00035: val_mDice did not improve from 0.61075
Epoch 36/300
 - 21s - loss: 1459.7108 - acc: 0.9521 - mDice: 0.7425 - val_loss: 2439.7662 - val_acc: 0.9542 - val_mDice: 0.5921

Epoch 00036: val_mDice did not improve from 0.61075
Epoch 37/300
 - 21s - loss: 1447.9391 - acc: 0.9522 - mDice: 0.7443 - val_loss: 2436.8004 - val_acc: 0.9532 - val_mDice: 0.5894

Epoch 00037: val_mDice did not improve from 0.61075
Epoch 38/300
 - 22s - loss: 1442.9865 - acc: 0.9524 - mDice: 0.7451 - val_loss: 2411.0958 - val_acc: 0.9518 - val_mDice: 0.5921

Epoch 00038: val_mDice did not improve from 0.61075
Epoch 39/300
 - 23s - loss: 1426.1978 - acc: 0.9526 - mDice: 0.7475 - val_loss: 2305.5595 - val_acc: 0.9529 - val_mDice: 0.5990

Epoch 00039: val_mDice did not improve from 0.61075
Epoch 40/300
 - 24s - loss: 1427.5270 - acc: 0.9526 - mDice: 0.7474 - val_loss: 2506.3586 - val_acc: 0.9533 - val_mDice: 0.5813

Epoch 00040: val_mDice did not improve from 0.61075
Epoch 41/300
 - 24s - loss: 1418.9649 - acc: 0.9527 - mDice: 0.7487 - val_loss: 2458.5809 - val_acc: 0.9537 - val_mDice: 0.5885

Epoch 00041: val_mDice did not improve from 0.61075
Epoch 42/300
 - 24s - loss: 1416.7413 - acc: 0.9529 - mDice: 0.7492 - val_loss: 2411.4407 - val_acc: 0.9519 - val_mDice: 0.5902

Epoch 00042: val_mDice did not improve from 0.61075
Epoch 43/300
 - 24s - loss: 1409.3935 - acc: 0.9529 - mDice: 0.7501 - val_loss: 2351.0562 - val_acc: 0.9526 - val_mDice: 0.5966

Epoch 00043: val_mDice did not improve from 0.61075
Epoch 44/300
 - 24s - loss: 1407.9708 - acc: 0.9529 - mDice: 0.7504 - val_loss: 2395.2818 - val_acc: 0.9544 - val_mDice: 0.5944

Epoch 00044: val_mDice did not improve from 0.61075
Epoch 45/300
 - 24s - loss: 1398.4086 - acc: 0.9530 - mDice: 0.7518 - val_loss: 2526.4494 - val_acc: 0.9530 - val_mDice: 0.5777

Epoch 00045: val_mDice did not improve from 0.61075
Epoch 46/300
 - 24s - loss: 1385.1421 - acc: 0.9532 - mDice: 0.7538 - val_loss: 2346.2194 - val_acc: 0.9542 - val_mDice: 0.5982

Epoch 00046: val_mDice did not improve from 0.61075
Epoch 47/300
 - 24s - loss: 1375.1782 - acc: 0.9533 - mDice: 0.7553 - val_loss: 2456.8796 - val_acc: 0.9531 - val_mDice: 0.5835

Epoch 00047: val_mDice did not improve from 0.61075
Epoch 48/300
 - 24s - loss: 1385.8434 - acc: 0.9533 - mDice: 0.7538 - val_loss: 2452.7198 - val_acc: 0.9536 - val_mDice: 0.5862

Epoch 00048: val_mDice did not improve from 0.61075
Epoch 49/300
 - 23s - loss: 1374.1671 - acc: 0.9534 - mDice: 0.7554 - val_loss: 2353.3530 - val_acc: 0.9541 - val_mDice: 0.5995

Epoch 00049: val_mDice did not improve from 0.61075
Epoch 50/300
 - 21s - loss: 1369.0556 - acc: 0.9535 - mDice: 0.7563 - val_loss: 2470.4928 - val_acc: 0.9521 - val_mDice: 0.5819

Epoch 00050: val_mDice did not improve from 0.61075
Epoch 51/300
 - 22s - loss: 1366.9151 - acc: 0.9535 - mDice: 0.7566 - val_loss: 2288.2872 - val_acc: 0.9523 - val_mDice: 0.6017

Epoch 00051: val_mDice did not improve from 0.61075
Epoch 52/300
 - 22s - loss: 1358.6978 - acc: 0.9537 - mDice: 0.7577 - val_loss: 2390.8203 - val_acc: 0.9522 - val_mDice: 0.5896

Epoch 00052: val_mDice did not improve from 0.61075
Epoch 53/300
 - 22s - loss: 1347.6717 - acc: 0.9537 - mDice: 0.7595 - val_loss: 2390.9943 - val_acc: 0.9528 - val_mDice: 0.5916

Epoch 00053: val_mDice did not improve from 0.61075
Epoch 54/300
 - 22s - loss: 1346.3753 - acc: 0.9538 - mDice: 0.7596 - val_loss: 2417.7884 - val_acc: 0.9526 - val_mDice: 0.5918

Epoch 00054: val_mDice did not improve from 0.61075
Epoch 55/300
 - 23s - loss: 1338.0502 - acc: 0.9539 - mDice: 0.7609 - val_loss: 2498.7190 - val_acc: 0.9524 - val_mDice: 0.5844

Epoch 00055: val_mDice did not improve from 0.61075
Epoch 56/300
 - 23s - loss: 1344.0769 - acc: 0.9539 - mDice: 0.7601 - val_loss: 2312.0010 - val_acc: 0.9538 - val_mDice: 0.6039

Epoch 00056: val_mDice did not improve from 0.61075
Epoch 57/300
 - 23s - loss: 1334.8798 - acc: 0.9540 - mDice: 0.7616 - val_loss: 2328.7518 - val_acc: 0.9530 - val_mDice: 0.5988

Epoch 00057: val_mDice did not improve from 0.61075
Epoch 58/300
 - 22s - loss: 1332.3946 - acc: 0.9541 - mDice: 0.7618 - val_loss: 2301.7304 - val_acc: 0.9536 - val_mDice: 0.6045

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.63s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.35s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  2.14s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:19,  1.97s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:45,  1.86s/it]predicting train subjects:   1%|          | 3/285 [00:05<09:02,  1.92s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<08:58,  1.92s/it]predicting train subjects:   2%|▏         | 5/285 [00:09<09:04,  1.94s/it]predicting train subjects:   2%|▏         | 6/285 [00:11<08:40,  1.87s/it]predicting train subjects:   2%|▏         | 7/285 [00:13<08:52,  1.92s/it]predicting train subjects:   3%|▎         | 8/285 [00:15<08:46,  1.90s/it]predicting train subjects:   3%|▎         | 9/285 [00:17<09:17,  2.02s/it]predicting train subjects:   4%|▎         | 10/285 [00:19<09:29,  2.07s/it]predicting train subjects:   4%|▍         | 11/285 [00:21<08:55,  1.95s/it]predicting train subjects:   4%|▍         | 12/285 [00:23<09:06,  2.00s/it]predicting train subjects:   5%|▍         | 13/285 [00:25<08:36,  1.90s/it]predicting train subjects:   5%|▍         | 14/285 [00:26<08:36,  1.91s/it]predicting train subjects:   5%|▌         | 15/285 [00:29<08:52,  1.97s/it]predicting train subjects:   6%|▌         | 16/285 [00:31<09:06,  2.03s/it]predicting train subjects:   6%|▌         | 17/285 [00:33<08:43,  1.95s/it]predicting train subjects:   6%|▋         | 18/285 [00:34<08:38,  1.94s/it]predicting train subjects:   7%|▋         | 19/285 [00:36<08:18,  1.87s/it]predicting train subjects:   7%|▋         | 20/285 [00:38<08:15,  1.87s/it]predicting train subjects:   7%|▋         | 21/285 [00:40<08:32,  1.94s/it]predicting train subjects:   8%|▊         | 22/285 [00:42<08:11,  1.87s/it]predicting train subjects:   8%|▊         | 23/285 [00:44<08:11,  1.88s/it]predicting train subjects:   8%|▊         | 24/285 [00:45<07:57,  1.83s/it]predicting train subjects:   9%|▉         | 25/285 [00:48<08:25,  1.94s/it]predicting train subjects:   9%|▉         | 26/285 [00:50<08:41,  2.01s/it]predicting train subjects:   9%|▉         | 27/285 [00:52<08:10,  1.90s/it]predicting train subjects:  10%|▉         | 28/285 [00:53<08:11,  1.91s/it]predicting train subjects:  10%|█         | 29/285 [00:55<08:12,  1.92s/it]predicting train subjects:  11%|█         | 30/285 [00:58<08:27,  1.99s/it]predicting train subjects:  11%|█         | 31/285 [01:00<08:29,  2.01s/it]predicting train subjects:  11%|█         | 32/285 [01:01<08:07,  1.93s/it]predicting train subjects:  12%|█▏        | 33/285 [01:03<08:02,  1.92s/it]predicting train subjects:  12%|█▏        | 34/285 [01:05<08:03,  1.93s/it]predicting train subjects:  12%|█▏        | 35/285 [01:07<08:24,  2.02s/it]predicting train subjects:  13%|█▎        | 36/285 [01:09<08:10,  1.97s/it]predicting train subjects:  13%|█▎        | 37/285 [01:11<08:08,  1.97s/it]predicting train subjects:  13%|█▎        | 38/285 [01:13<08:24,  2.04s/it]predicting train subjects:  14%|█▎        | 39/285 [01:15<07:55,  1.93s/it]predicting train subjects:  14%|█▍        | 40/285 [01:17<07:53,  1.93s/it]predicting train subjects:  14%|█▍        | 41/285 [01:19<07:37,  1.88s/it]predicting train subjects:  15%|█▍        | 42/285 [01:20<07:23,  1.82s/it]predicting train subjects:  15%|█▌        | 43/285 [01:22<07:27,  1.85s/it]predicting train subjects:  15%|█▌        | 44/285 [01:25<07:48,  1.94s/it]predicting train subjects:  16%|█▌        | 45/285 [01:26<07:31,  1.88s/it]predicting train subjects:  16%|█▌        | 46/285 [01:28<07:44,  1.95s/it]predicting train subjects:  16%|█▋        | 47/285 [01:30<07:24,  1.87s/it]predicting train subjects:  17%|█▋        | 48/285 [01:32<07:27,  1.89s/it]predicting train subjects:  17%|█▋        | 49/285 [01:34<07:45,  1.97s/it]predicting train subjects:  18%|█▊        | 50/285 [01:36<07:37,  1.95s/it]predicting train subjects:  18%|█▊        | 51/285 [01:38<07:52,  2.02s/it]predicting train subjects:  18%|█▊        | 52/285 [01:40<07:30,  1.93s/it]predicting train subjects:  19%|█▊        | 53/285 [01:42<07:29,  1.94s/it]predicting train subjects:  19%|█▉        | 54/285 [01:44<07:41,  2.00s/it]predicting train subjects:  19%|█▉        | 55/285 [01:46<07:16,  1.90s/it]predicting train subjects:  20%|█▉        | 56/285 [01:48<07:14,  1.90s/it]predicting train subjects:  20%|██        | 57/285 [01:49<06:59,  1.84s/it]predicting train subjects:  20%|██        | 58/285 [01:51<06:57,  1.84s/it]predicting train subjects:  21%|██        | 59/285 [01:53<07:09,  1.90s/it]predicting train subjects:  21%|██        | 60/285 [01:55<07:21,  1.96s/it]predicting train subjects:  21%|██▏       | 61/285 [01:57<07:00,  1.88s/it]predicting train subjects:  22%|██▏       | 62/285 [01:59<06:52,  1.85s/it]predicting train subjects:  22%|██▏       | 63/285 [02:01<06:49,  1.84s/it]predicting train subjects:  22%|██▏       | 64/285 [02:02<06:42,  1.82s/it]predicting train subjects:  23%|██▎       | 65/285 [02:04<06:47,  1.85s/it]predicting train subjects:  23%|██▎       | 66/285 [02:06<06:54,  1.89s/it]predicting train subjects:  24%|██▎       | 67/285 [02:08<06:50,  1.88s/it]predicting train subjects:  24%|██▍       | 68/285 [02:10<06:39,  1.84s/it]predicting train subjects:  24%|██▍       | 69/285 [02:12<06:36,  1.84s/it]predicting train subjects:  25%|██▍       | 70/285 [02:14<06:44,  1.88s/it]predicting train subjects:  25%|██▍       | 71/285 [02:16<06:49,  1.91s/it]predicting train subjects:  25%|██▌       | 72/285 [02:18<06:41,  1.88s/it]predicting train subjects:  26%|██▌       | 73/285 [02:19<06:39,  1.88s/it]predicting train subjects:  26%|██▌       | 74/285 [02:21<06:40,  1.90s/it]predicting train subjects:  26%|██▋       | 75/285 [02:23<06:39,  1.90s/it]predicting train subjects:  27%|██▋       | 76/285 [02:25<06:38,  1.91s/it]predicting train subjects:  27%|██▋       | 77/285 [02:27<06:25,  1.85s/it]predicting train subjects:  27%|██▋       | 78/285 [02:29<06:13,  1.80s/it]predicting train subjects:  28%|██▊       | 79/285 [02:30<06:17,  1.83s/it]predicting train subjects:  28%|██▊       | 80/285 [02:32<06:21,  1.86s/it]predicting train subjects:  28%|██▊       | 81/285 [02:34<06:09,  1.81s/it]predicting train subjects:  29%|██▉       | 82/285 [02:36<06:07,  1.81s/it]predicting train subjects:  29%|██▉       | 83/285 [02:38<05:56,  1.76s/it]predicting train subjects:  29%|██▉       | 84/285 [02:39<05:49,  1.74s/it]predicting train subjects:  30%|██▉       | 85/285 [02:41<05:55,  1.78s/it]predicting train subjects:  30%|███       | 86/285 [02:43<05:55,  1.79s/it]predicting train subjects:  31%|███       | 87/285 [02:45<05:55,  1.80s/it]predicting train subjects:  31%|███       | 88/285 [02:46<05:46,  1.76s/it]predicting train subjects:  31%|███       | 89/285 [02:48<05:49,  1.78s/it]predicting train subjects:  32%|███▏      | 90/285 [02:50<05:52,  1.81s/it]predicting train subjects:  32%|███▏      | 91/285 [02:52<05:44,  1.77s/it]predicting train subjects:  32%|███▏      | 92/285 [02:54<05:45,  1.79s/it]predicting train subjects:  33%|███▎      | 93/285 [02:55<05:38,  1.76s/it]predicting train subjects:  33%|███▎      | 94/285 [02:57<05:39,  1.78s/it]predicting train subjects:  33%|███▎      | 95/285 [02:59<05:45,  1.82s/it]predicting train subjects:  34%|███▎      | 96/285 [03:01<05:49,  1.85s/it]predicting train subjects:  34%|███▍      | 97/285 [03:03<05:45,  1.84s/it]predicting train subjects:  34%|███▍      | 98/285 [03:05<05:44,  1.84s/it]predicting train subjects:  35%|███▍      | 99/285 [03:06<05:42,  1.84s/it]predicting train subjects:  35%|███▌      | 100/285 [03:08<05:41,  1.85s/it]predicting train subjects:  35%|███▌      | 101/285 [03:10<05:32,  1.81s/it]predicting train subjects:  36%|███▌      | 102/285 [03:12<05:36,  1.84s/it]predicting train subjects:  36%|███▌      | 103/285 [03:14<05:30,  1.82s/it]predicting train subjects:  36%|███▋      | 104/285 [03:16<05:31,  1.83s/it]predicting train subjects:  37%|███▋      | 105/285 [03:18<05:33,  1.85s/it]predicting train subjects:  37%|███▋      | 106/285 [03:19<05:21,  1.80s/it]predicting train subjects:  38%|███▊      | 107/285 [03:21<05:23,  1.82s/it]predicting train subjects:  38%|███▊      | 108/285 [03:23<05:19,  1.81s/it]predicting train subjects:  38%|███▊      | 109/285 [03:25<05:20,  1.82s/it]predicting train subjects:  39%|███▊      | 110/285 [03:27<05:23,  1.85s/it]predicting train subjects:  39%|███▉      | 111/285 [03:28<05:13,  1.80s/it]predicting train subjects:  39%|███▉      | 112/285 [03:30<05:12,  1.80s/it]predicting train subjects:  40%|███▉      | 113/285 [03:32<05:14,  1.83s/it]predicting train subjects:  40%|████      | 114/285 [03:34<05:11,  1.82s/it]predicting train subjects:  40%|████      | 115/285 [03:36<05:11,  1.83s/it]predicting train subjects:  41%|████      | 116/285 [03:38<05:16,  1.87s/it]predicting train subjects:  41%|████      | 117/285 [03:39<05:09,  1.84s/it]predicting train subjects:  41%|████▏     | 118/285 [03:41<05:03,  1.82s/it]predicting train subjects:  42%|████▏     | 119/285 [03:43<05:07,  1.85s/it]predicting train subjects:  42%|████▏     | 120/285 [03:45<04:59,  1.81s/it]predicting train subjects:  42%|████▏     | 121/285 [03:47<04:52,  1.78s/it]predicting train subjects:  43%|████▎     | 122/285 [03:48<04:39,  1.71s/it]predicting train subjects:  43%|████▎     | 123/285 [03:50<04:29,  1.66s/it]predicting train subjects:  44%|████▎     | 124/285 [03:51<04:29,  1.68s/it]predicting train subjects:  44%|████▍     | 125/285 [03:53<04:20,  1.63s/it]predicting train subjects:  44%|████▍     | 126/285 [03:54<04:14,  1.60s/it]predicting train subjects:  45%|████▍     | 127/285 [03:56<04:05,  1.55s/it]predicting train subjects:  45%|████▍     | 128/285 [03:57<04:09,  1.59s/it]predicting train subjects:  45%|████▌     | 129/285 [03:59<04:05,  1.58s/it]predicting train subjects:  46%|████▌     | 130/285 [04:01<04:03,  1.57s/it]predicting train subjects:  46%|████▌     | 131/285 [04:02<03:57,  1.54s/it]predicting train subjects:  46%|████▋     | 132/285 [04:04<04:00,  1.57s/it]predicting train subjects:  47%|████▋     | 133/285 [04:05<03:58,  1.57s/it]predicting train subjects:  47%|████▋     | 134/285 [04:07<03:53,  1.54s/it]predicting train subjects:  47%|████▋     | 135/285 [04:08<03:49,  1.53s/it]predicting train subjects:  48%|████▊     | 136/285 [04:10<03:48,  1.53s/it]predicting train subjects:  48%|████▊     | 137/285 [04:11<03:52,  1.57s/it]predicting train subjects:  48%|████▊     | 138/285 [04:13<03:46,  1.54s/it]predicting train subjects:  49%|████▉     | 139/285 [04:15<03:50,  1.58s/it]predicting train subjects:  49%|████▉     | 140/285 [04:16<03:50,  1.59s/it]predicting train subjects:  49%|████▉     | 141/285 [04:18<03:47,  1.58s/it]predicting train subjects:  50%|████▉     | 142/285 [04:19<03:46,  1.58s/it]predicting train subjects:  50%|█████     | 143/285 [04:21<03:41,  1.56s/it]predicting train subjects:  51%|█████     | 144/285 [04:23<03:46,  1.61s/it]predicting train subjects:  51%|█████     | 145/285 [04:24<03:44,  1.60s/it]predicting train subjects:  51%|█████     | 146/285 [04:26<03:47,  1.63s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:27<03:38,  1.58s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:29<03:39,  1.60s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:31<03:35,  1.58s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:32<03:28,  1.55s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:34<03:33,  1.59s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:35<03:29,  1.58s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:37<03:25,  1.55s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:38<03:29,  1.60s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:40<03:24,  1.57s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:42<03:31,  1.64s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:43<03:26,  1.61s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:45<03:25,  1.62s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:46<03:20,  1.59s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:48<03:19,  1.60s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:50<03:22,  1.64s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:51<03:16,  1.59s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:53<03:19,  1.63s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:54<03:12,  1.59s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:56<03:11,  1.60s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:58<03:14,  1.64s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:00<03:15,  1.66s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:01<03:09,  1.62s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:03<03:07,  1.62s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:04<03:03,  1.59s/it]predicting train subjects:  60%|██████    | 171/285 [05:06<03:01,  1.59s/it]predicting train subjects:  60%|██████    | 172/285 [05:07<02:59,  1.59s/it]predicting train subjects:  61%|██████    | 173/285 [05:09<02:57,  1.58s/it]predicting train subjects:  61%|██████    | 174/285 [05:11<02:55,  1.58s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:12<03:00,  1.64s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:14<02:59,  1.64s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:16<02:55,  1.62s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:17<02:50,  1.60s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:19<02:46,  1.57s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:21<02:56,  1.68s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:22<02:57,  1.70s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:24<02:58,  1.74s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:26<02:50,  1.67s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:27<02:44,  1.63s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:29<02:38,  1.59s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:31<02:48,  1.71s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:33<02:55,  1.79s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:35<02:58,  1.84s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:36<02:45,  1.72s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:37<02:34,  1.63s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:39<02:35,  1.66s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:41<02:34,  1.66s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:42<02:25,  1.58s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:44<02:19,  1.53s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:45<02:15,  1.51s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:47<02:23,  1.61s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:49<02:26,  1.67s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:51<02:29,  1.72s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:52<02:19,  1.63s/it]predicting train subjects:  70%|███████   | 200/285 [05:53<02:14,  1.58s/it]predicting train subjects:  71%|███████   | 201/285 [05:55<02:17,  1.64s/it]predicting train subjects:  71%|███████   | 202/285 [05:57<02:16,  1.65s/it]predicting train subjects:  71%|███████   | 203/285 [05:59<02:15,  1.65s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:00<02:10,  1.61s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:02<02:05,  1.56s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:03<01:59,  1.51s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:05<02:06,  1.62s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:07<02:09,  1.68s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:08<02:10,  1.72s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:10<02:01,  1.62s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:11<01:56,  1.58s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:13<01:57,  1.61s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:15<01:59,  1.66s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:16<01:54,  1.61s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:18<01:58,  1.69s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:20<01:52,  1.63s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:22<01:57,  1.73s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:24<02:00,  1.80s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:25<02:01,  1.83s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:27<01:54,  1.76s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:29<01:47,  1.69s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:30<01:48,  1.72s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:32<01:42,  1.65s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:33<01:36,  1.58s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:35<01:31,  1.52s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:36<01:35,  1.62s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:38<01:38,  1.70s/it]predicting train subjects:  80%|████████  | 228/285 [06:40<01:39,  1.74s/it]predicting train subjects:  80%|████████  | 229/285 [06:42<01:36,  1.73s/it]predicting train subjects:  81%|████████  | 230/285 [06:43<01:30,  1.64s/it]predicting train subjects:  81%|████████  | 231/285 [06:45<01:25,  1.59s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:46<01:25,  1.61s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:48<01:22,  1.59s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:50<01:25,  1.67s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:51<01:20,  1.60s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:53<01:24,  1.72s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:55<01:24,  1.77s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:57<01:23,  1.79s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:59<01:21,  1.77s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:00<01:16,  1.70s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:02<01:11,  1.63s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:03<01:09,  1.61s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:05<01:06,  1.59s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:07<01:08,  1.66s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:08<01:04,  1.60s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:10<01:05,  1.69s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:12<01:05,  1.73s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:14<01:04,  1.74s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:15<00:59,  1.65s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:16<00:55,  1.57s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:18<00:52,  1.54s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:19<00:50,  1.53s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:21<00:52,  1.64s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:23<00:52,  1.69s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:25<00:50,  1.68s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:26<00:46,  1.62s/it]predicting train subjects:  90%|█████████ | 257/285 [07:28<00:44,  1.58s/it]predicting train subjects:  91%|█████████ | 258/285 [07:30<00:44,  1.65s/it]predicting train subjects:  91%|█████████ | 259/285 [07:31<00:43,  1.68s/it]predicting train subjects:  91%|█████████ | 260/285 [07:33<00:40,  1.62s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:34<00:37,  1.56s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:36<00:35,  1.56s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:37<00:33,  1.54s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:39<00:35,  1.69s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:41<00:35,  1.76s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:43<00:31,  1.68s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:44<00:29,  1.64s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:46<00:29,  1.73s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:48<00:28,  1.77s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:50<00:25,  1.70s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:51<00:23,  1.64s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:53<00:21,  1.68s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:54<00:19,  1.60s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:56<00:17,  1.57s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:58<00:16,  1.68s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:00<00:15,  1.73s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:01<00:13,  1.65s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:03<00:11,  1.60s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:04<00:09,  1.64s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:06<00:08,  1.61s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:07<00:06,  1.59s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:09<00:04,  1.56s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:11<00:03,  1.68s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:13<00:01,  1.74s/it]predicting train subjects: 100%|██████████| 285/285 [08:15<00:00,  1.80s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:26,  1.57s/it]Loading train:   1%|          | 2/285 [00:02<06:42,  1.42s/it]Loading train:   1%|          | 3/285 [00:04<06:36,  1.41s/it]Loading train:   1%|▏         | 4/285 [00:05<06:01,  1.29s/it]Loading train:   2%|▏         | 5/285 [00:06<06:18,  1.35s/it]Loading train:   2%|▏         | 6/285 [00:07<05:58,  1.29s/it]Loading train:   2%|▏         | 7/285 [00:09<06:18,  1.36s/it]Loading train:   3%|▎         | 8/285 [00:10<06:15,  1.36s/it]Loading train:   3%|▎         | 9/285 [00:12<06:33,  1.43s/it]Loading train:   4%|▎         | 10/285 [00:13<05:58,  1.30s/it]Loading train:   4%|▍         | 11/285 [00:13<05:10,  1.13s/it]Loading train:   4%|▍         | 12/285 [00:14<05:05,  1.12s/it]Loading train:   5%|▍         | 13/285 [00:15<04:40,  1.03s/it]Loading train:   5%|▍         | 14/285 [00:16<04:41,  1.04s/it]Loading train:   5%|▌         | 15/285 [00:17<04:34,  1.02s/it]Loading train:   6%|▌         | 16/285 [00:18<04:27,  1.00it/s]Loading train:   6%|▌         | 17/285 [00:19<04:00,  1.12it/s]Loading train:   6%|▋         | 18/285 [00:20<03:59,  1.12it/s]Loading train:   7%|▋         | 19/285 [00:21<03:58,  1.11it/s]Loading train:   7%|▋         | 20/285 [00:22<03:58,  1.11it/s]Loading train:   7%|▋         | 21/285 [00:23<04:08,  1.06it/s]Loading train:   8%|▊         | 22/285 [00:23<03:55,  1.12it/s]Loading train:   8%|▊         | 23/285 [00:24<03:59,  1.09it/s]Loading train:   8%|▊         | 24/285 [00:25<03:55,  1.11it/s]Loading train:   9%|▉         | 25/285 [00:26<04:12,  1.03it/s]Loading train:   9%|▉         | 26/285 [00:27<04:10,  1.04it/s]Loading train:   9%|▉         | 27/285 [00:28<04:07,  1.04it/s]Loading train:  10%|▉         | 28/285 [00:29<04:13,  1.01it/s]Loading train:  10%|█         | 29/285 [00:30<04:11,  1.02it/s]Loading train:  11%|█         | 30/285 [00:31<04:04,  1.04it/s]Loading train:  11%|█         | 31/285 [00:32<04:06,  1.03it/s]Loading train:  11%|█         | 32/285 [00:33<03:52,  1.09it/s]Loading train:  12%|█▏        | 33/285 [00:34<03:47,  1.11it/s]Loading train:  12%|█▏        | 34/285 [00:35<03:52,  1.08it/s]Loading train:  12%|█▏        | 35/285 [00:36<03:59,  1.04it/s]Loading train:  13%|█▎        | 36/285 [00:37<03:49,  1.08it/s]Loading train:  13%|█▎        | 37/285 [00:38<03:54,  1.06it/s]Loading train:  13%|█▎        | 38/285 [00:39<04:10,  1.01s/it]Loading train:  14%|█▎        | 39/285 [00:40<03:58,  1.03it/s]Loading train:  14%|█▍        | 40/285 [00:41<04:06,  1.00s/it]Loading train:  14%|█▍        | 41/285 [00:42<03:50,  1.06it/s]Loading train:  15%|█▍        | 42/285 [00:43<03:43,  1.09it/s]Loading train:  15%|█▌        | 43/285 [00:43<03:38,  1.11it/s]Loading train:  15%|█▌        | 44/285 [00:44<03:47,  1.06it/s]Loading train:  16%|█▌        | 45/285 [00:45<03:38,  1.10it/s]Loading train:  16%|█▌        | 46/285 [00:46<03:51,  1.03it/s]Loading train:  16%|█▋        | 47/285 [00:47<03:40,  1.08it/s]Loading train:  17%|█▋        | 48/285 [00:48<03:53,  1.01it/s]Loading train:  17%|█▋        | 49/285 [00:49<03:50,  1.02it/s]Loading train:  18%|█▊        | 50/285 [00:50<03:50,  1.02it/s]Loading train:  18%|█▊        | 51/285 [00:51<03:45,  1.04it/s]Loading train:  18%|█▊        | 52/285 [00:52<03:43,  1.04it/s]Loading train:  19%|█▊        | 53/285 [00:53<03:42,  1.05it/s]Loading train:  19%|█▉        | 54/285 [00:54<03:49,  1.01it/s]Loading train:  19%|█▉        | 55/285 [00:55<03:38,  1.05it/s]Loading train:  20%|█▉        | 56/285 [00:56<03:45,  1.02it/s]Loading train:  20%|██        | 57/285 [00:57<03:30,  1.08it/s]Loading train:  20%|██        | 58/285 [00:58<03:28,  1.09it/s]Loading train:  21%|██        | 59/285 [00:59<03:29,  1.08it/s]Loading train:  21%|██        | 60/285 [01:00<03:34,  1.05it/s]Loading train:  21%|██▏       | 61/285 [01:01<03:38,  1.02it/s]Loading train:  22%|██▏       | 62/285 [01:02<03:40,  1.01it/s]Loading train:  22%|██▏       | 63/285 [01:03<03:41,  1.00it/s]Loading train:  22%|██▏       | 64/285 [01:04<04:04,  1.11s/it]Loading train:  23%|██▎       | 65/285 [01:06<04:31,  1.23s/it]
Epoch 00058: val_mDice did not improve from 0.61075
Restoring model weights from the end of the best epoch
Epoch 00058: early stopping
{'val_loss': [5703.264891214211, 2700.454924002706, 2607.191132103265, 2688.0903852239003, 2612.1369601627966, 2461.822224707577, 2466.2491284588864, 2661.6077042052198, 2426.001668066952, 2593.8888560034043, 2381.7695026078036, 2582.6613442191865, 2453.9446482738304, 2532.5253483436627, 2321.6033505913933, 2384.0900715236558, 2433.8568735815293, 2447.8360343379013, 2486.5197931215084, 2307.4431370570005, 2401.2172878840784, 2280.376796274878, 2332.249447614787, 2572.4674460981146, 2408.5043154242317, 2302.5630414739003, 2493.7138671875, 2220.744999890887, 2377.4131950506285, 2601.3738515843224, 2353.996751156599, 2345.6829349794866, 2327.378492984026, 2340.9684458471543, 2769.4474511173185, 2439.766241489176, 2436.8003720757683, 2411.0957740485337, 2305.559484385911, 2506.3585948411314, 2458.5808651034395, 2411.4406820116096, 2351.056230086854, 2395.2818351191513, 2526.4493687805516, 2346.21942104574, 2456.8796045740223, 2452.7197579325243, 2353.353017796351, 2470.4927698913234, 2288.2871912098462, 2390.8202524877793, 2390.994256557699, 2417.788395546002, 2498.718969590171, 2312.000950648132, 2328.7518317366444, 2301.730351453387], 'val_acc': [0.9197505938940208, 0.9311386496661096, 0.9358967585936605, 0.9353471741330024, 0.940725098442099, 0.945766270160675, 0.9467124912325896, 0.9447332167758622, 0.9487083064777225, 0.9484459161758423, 0.9503590647734743, 0.9488508704654331, 0.9510181642777427, 0.9516772218256689, 0.9506421435478679, 0.948481025309536, 0.9519416716511689, 0.951445819279335, 0.9514706258001274, 0.9521916745095279, 0.9510656501993787, 0.9536358564259619, 0.9522846287855223, 0.9522536390320548, 0.9526090042551136, 0.9528713988858228, 0.9536750772811847, 0.9541068859606482, 0.9507826290317087, 0.9525594271761079, 0.9535800524930048, 0.9523053145941409, 0.9524127148383157, 0.9540015342515274, 0.9531936815331102, 0.9541750570249291, 0.9532143516913473, 0.951846646862989, 0.9528858425230954, 0.9533259372471431, 0.9537246586890195, 0.9519189186602331, 0.952600731530003, 0.9543796234956666, 0.9529643604875276, 0.9542143071829939, 0.9530945133896513, 0.9535552579597388, 0.9540511159923489, 0.9521421000944169, 0.9522722286885011, 0.9522226526084558, 0.9528321450649027, 0.9526461745773613, 0.9524354515128961, 0.9537866335341384, 0.9529602397753539, 0.9536358214623435], 'val_mDice': [0.33392037875825464, 0.5466633698793762, 0.5603645733614874, 0.5497599836834316, 0.5586923047816953, 0.5755925071972042, 0.574711168278529, 0.5584386530535181, 0.5814075416692809, 0.5678513812619215, 0.588063728875954, 0.5688456320229855, 0.5840047950851185, 0.5757977179974817, 0.5970653315496178, 0.5898437919563422, 0.5881276463663112, 0.5900039732789194, 0.5876171422404284, 0.5989590969831584, 0.5876140774295316, 0.6044246744177195, 0.5969733262861241, 0.5760414107551788, 0.5904523040995252, 0.6006609677602459, 0.5850441309326854, 0.6107499672713892, 0.5911199740191412, 0.5704789757728577, 0.5975473692963243, 0.5976255449502827, 0.5975438459625457, 0.6001012481790681, 0.5632609874842553, 0.5920689791940444, 0.5893770159955797, 0.5920643453491466, 0.5990485645539267, 0.5813361026721293, 0.5885271799630959, 0.5901897419764343, 0.5965869693116769, 0.5944159860051544, 0.5776771729884866, 0.5982465937150924, 0.5835153517110387, 0.5862261473133578, 0.5995365854082161, 0.5819128059142129, 0.6017039731228152, 0.5896183984905647, 0.5915713363519594, 0.5917708247733515, 0.5844348252818571, 0.6039428198137763, 0.5987805204684508, 0.6044909674362098], 'loss': [10963.682382128518, 3832.4053217045043, 3103.8395344422706, 2728.6473747749137, 2499.7972838800333, 2338.722064660075, 2217.1928924216495, 2125.835410219542, 2058.5627855332377, 1993.176679687766, 1944.2689008403725, 1894.6197116515857, 1856.5981090490181, 1875.3683958438467, 1797.0524348004517, 1771.8772219309951, 1743.4757340626873, 1717.9946292652608, 1697.4484394838669, 1678.1493846701546, 1656.8158216541365, 1645.7547035032378, 1616.147491872262, 1595.5684532962082, 1578.870196708387, 1567.9177451527694, 1551.1848017481325, 1543.0455422855125, 1530.2228239944614, 1510.0925634161954, 1506.3984573519663, 1495.424970570424, 1481.473001475428, 1479.9606197654898, 1459.8516746642745, 1459.7107875897314, 1447.9390975447704, 1442.986544980806, 1426.1978353152679, 1427.5270425632273, 1418.9648711145992, 1416.7413487577483, 1409.3935008757735, 1407.97081788213, 1398.408585311917, 1385.1420569676704, 1375.1782303317675, 1385.8434342666426, 1374.167085051621, 1369.0555707529397, 1366.9151445219156, 1358.6978392045512, 1347.6717264892086, 1346.3752924840855, 1338.0502452735034, 1344.0768602748406, 1334.879775587948, 1332.3946442054278], 'acc': [0.6238268240135884, 0.9019226585687048, 0.9081354569612288, 0.9134485063440666, 0.9201566108814038, 0.9278345641295938, 0.9341498029581973, 0.9387569463945774, 0.9414470946858258, 0.9431479249954431, 0.9442492944405662, 0.9452696162776149, 0.9459449273913678, 0.9458908479228387, 0.9469486107773514, 0.9474948138870203, 0.947956159765259, 0.9483282389311507, 0.9486892815931101, 0.949076524942206, 0.9493705355408834, 0.9494374245283462, 0.9498739975495092, 0.9501120121992853, 0.9503908152674013, 0.9505379070228536, 0.9507465590566379, 0.950929949949863, 0.9511011506170951, 0.9513611015908099, 0.9514230570692648, 0.9515694677326572, 0.9517862719165286, 0.951868956491946, 0.9521613727532131, 0.9521383315959427, 0.9522135797542111, 0.952431212511141, 0.9525784082671382, 0.9526240281514382, 0.9527223783603882, 0.9529401356245099, 0.9528745736284236, 0.9529278850861868, 0.9530440241668123, 0.953150632542324, 0.9533354357192539, 0.9532893305477718, 0.9534278852047143, 0.9535091388953367, 0.9535127029615799, 0.953673274576401, 0.9537248364409541, 0.9538113443000041, 0.9538757790570477, 0.9539249847315864, 0.9539513280400653, 0.9540536885920917], 'mDice': [0.18820628715924242, 0.4645475341057532, 0.5369820783070882, 0.5776933015714082, 0.6045402193288906, 0.62412210696923, 0.6390963990011413, 0.6506381945687697, 0.6593385721160646, 0.6678019103924178, 0.6742285088927689, 0.680973709330801, 0.68599942501357, 0.6839068331728054, 0.6942660946074956, 0.6977369526614097, 0.7017460366582489, 0.7051745633934585, 0.7081270629359411, 0.7109650522332508, 0.7138182468698939, 0.7154022340946977, 0.7196405369318308, 0.7226126690126701, 0.724975877088384, 0.7265069309802014, 0.7290414473108137, 0.7302724659803237, 0.732134595866375, 0.7350022588820961, 0.735544857632899, 0.7372431948770463, 0.7393320158451031, 0.7395752618031189, 0.7425561572665139, 0.7425195443578928, 0.7443481803907755, 0.7450675594119113, 0.7474880902136497, 0.747429269440884, 0.7486895323124308, 0.7492200458116647, 0.7501096072185793, 0.7503568111217319, 0.7518199073561305, 0.7537610123771824, 0.7552712927274432, 0.7537607881317899, 0.7554134216114338, 0.7563295319938536, 0.7566254798846984, 0.7577470468543764, 0.7594616282227109, 0.7596312615484605, 0.76091750586749, 0.7601341441996794, 0.761571581025677, 0.76179501725778]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label valuesLoading train:  23%|██▎       | 66/285 [01:07<04:33,  1.25s/it]Loading train:  24%|██▎       | 67/285 [01:08<04:14,  1.17s/it]Loading train:  24%|██▍       | 68/285 [01:09<03:52,  1.07s/it]Loading train:  24%|██▍       | 69/285 [01:10<03:39,  1.02s/it]Loading train:  25%|██▍       | 70/285 [01:11<03:37,  1.01s/it]Loading train:  25%|██▍       | 71/285 [01:12<03:45,  1.05s/it]Loading train:  25%|██▌       | 72/285 [01:13<03:32,  1.00it/s]Loading train:  26%|██▌       | 73/285 [01:14<03:35,  1.01s/it]Loading train:  26%|██▌       | 74/285 [01:15<03:37,  1.03s/it]Loading train:  26%|██▋       | 75/285 [01:16<03:34,  1.02s/it]Loading train:  27%|██▋       | 76/285 [01:17<03:35,  1.03s/it]Loading train:  27%|██▋       | 77/285 [01:18<03:21,  1.03it/s]Loading train:  27%|██▋       | 78/285 [01:19<03:12,  1.08it/s]Loading train:  28%|██▊       | 79/285 [01:20<03:19,  1.03it/s]Loading train:  28%|██▊       | 80/285 [01:20<03:10,  1.07it/s]Loading train:  28%|██▊       | 81/285 [01:21<03:11,  1.06it/s]Loading train:  29%|██▉       | 82/285 [01:22<03:09,  1.07it/s]Loading train:  29%|██▉       | 83/285 [01:23<02:59,  1.13it/s]Loading train:  29%|██▉       | 84/285 [01:24<02:50,  1.18it/s]Loading train:  30%|██▉       | 85/285 [01:25<02:57,  1.13it/s]Loading train:  30%|███       | 86/285 [01:26<03:00,  1.10it/s]Loading train:  31%|███       | 87/285 [01:27<03:02,  1.09it/s]Loading train:  31%|███       | 88/285 [01:28<02:55,  1.12it/s]Loading train:  31%|███       | 89/285 [01:29<03:08,  1.04it/s]Loading train:  32%|███▏      | 90/285 [01:30<02:59,  1.08it/s]Loading train:  32%|███▏      | 91/285 [01:30<02:51,  1.13it/s]Loading train:  32%|███▏      | 92/285 [01:31<02:56,  1.09it/s]Loading train:  33%|███▎      | 93/285 [01:32<02:48,  1.14it/s]Loading train:  33%|███▎      | 94/285 [01:33<02:50,  1.12it/s]Loading train:  33%|███▎      | 95/285 [01:34<02:52,  1.10it/s]Loading train:  34%|███▎      | 96/285 [01:35<02:51,  1.10it/s]Loading train:  34%|███▍      | 97/285 [01:36<02:55,  1.07it/s]Loading train:  34%|███▍      | 98/285 [01:37<02:59,  1.04it/s]Loading train:  35%|███▍      | 99/285 [01:38<02:52,  1.08it/s]Loading train:  35%|███▌      | 100/285 [01:39<02:53,  1.07it/s]Loading train:  35%|███▌      | 101/285 [01:39<02:39,  1.15it/s]Loading train:  36%|███▌      | 102/285 [01:40<02:41,  1.13it/s]Loading train:  36%|███▌      | 103/285 [01:41<02:33,  1.18it/s]Loading train:  36%|███▋      | 104/285 [01:42<02:38,  1.14it/s]Loading train:  37%|███▋      | 105/285 [01:43<02:40,  1.12it/s]Loading train:  37%|███▋      | 106/285 [01:44<02:31,  1.18it/s]Loading train:  38%|███▊      | 107/285 [01:45<02:41,  1.10it/s]Loading train:  38%|███▊      | 108/285 [01:45<02:31,  1.17it/s]Loading train:  38%|███▊      | 109/285 [01:47<02:38,  1.11it/s]Loading train:  39%|███▊      | 110/285 [01:47<02:38,  1.10it/s]Loading train:  39%|███▉      | 111/285 [01:48<02:36,  1.11it/s]Loading train:  39%|███▉      | 112/285 [01:49<02:37,  1.10it/s]Loading train:  40%|███▉      | 113/285 [01:50<02:40,  1.07it/s]Loading train:  40%|████      | 114/285 [01:51<02:42,  1.05it/s]Loading train:  40%|████      | 115/285 [01:52<02:42,  1.05it/s]Loading train:  41%|████      | 116/285 [01:53<02:35,  1.08it/s]Loading train:  41%|████      | 117/285 [01:54<02:22,  1.18it/s]Loading train:  41%|████▏     | 118/285 [01:55<02:23,  1.16it/s]Loading train:  42%|████▏     | 119/285 [01:56<02:26,  1.13it/s]Loading train:  42%|████▏     | 120/285 [01:56<02:21,  1.16it/s]Loading train:  42%|████▏     | 121/285 [01:58<02:44,  1.00s/it]Loading train:  43%|████▎     | 122/285 [01:59<02:54,  1.07s/it]Loading train:  43%|████▎     | 123/285 [02:00<03:00,  1.12s/it]Loading train:  44%|████▎     | 124/285 [02:01<02:49,  1.05s/it]Loading train:  44%|████▍     | 125/285 [02:02<02:36,  1.02it/s]Loading train:  44%|████▍     | 126/285 [02:03<02:31,  1.05it/s]Loading train:  45%|████▍     | 127/285 [02:04<02:24,  1.09it/s]Loading train:  45%|████▍     | 128/285 [02:05<02:30,  1.04it/s]Loading train:  45%|████▌     | 129/285 [02:05<02:25,  1.07it/s]Loading train:  46%|████▌     | 130/285 [02:06<02:15,  1.14it/s]Loading train:  46%|████▌     | 131/285 [02:07<02:12,  1.16it/s]Loading train:  46%|████▋     | 132/285 [02:08<02:08,  1.19it/s]Loading train:  47%|████▋     | 133/285 [02:09<02:18,  1.10it/s]Loading train:  47%|████▋     | 134/285 [02:10<02:12,  1.14it/s]Loading train:  47%|████▋     | 135/285 [02:11<02:07,  1.17it/s]Loading train:  48%|████▊     | 136/285 [02:11<02:00,  1.24it/s]Loading train:  48%|████▊     | 137/285 [02:12<02:01,  1.22it/s]Loading train:  48%|████▊     | 138/285 [02:13<01:59,  1.23it/s]Loading train:  49%|████▉     | 139/285 [02:14<02:00,  1.21it/s]Loading train:  49%|████▉     | 140/285 [02:14<01:57,  1.23it/s]Loading train:  49%|████▉     | 141/285 [02:15<01:54,  1.26it/s]Loading train:  50%|████▉     | 142/285 [02:16<01:58,  1.21it/s]Loading train:  50%|█████     | 143/285 [02:17<02:01,  1.17it/s]Loading train:  51%|█████     | 144/285 [02:18<02:05,  1.12it/s]Loading train:  51%|█████     | 145/285 [02:19<01:59,  1.17it/s]Loading train:  51%|█████     | 146/285 [02:20<01:58,  1.17it/s]Loading train:  52%|█████▏    | 147/285 [02:20<01:54,  1.21it/s]Loading train:  52%|█████▏    | 148/285 [02:21<01:52,  1.21it/s]Loading train:  52%|█████▏    | 149/285 [02:22<01:53,  1.20it/s]Loading train:  53%|█████▎    | 150/285 [02:23<01:48,  1.25it/s]Loading train:  53%|█████▎    | 151/285 [02:24<01:50,  1.22it/s]Loading train:  53%|█████▎    | 152/285 [02:24<01:46,  1.25it/s]Loading train:  54%|█████▎    | 153/285 [02:25<01:41,  1.31it/s]Loading train:  54%|█████▍    | 154/285 [02:26<01:50,  1.19it/s]Loading train:  54%|█████▍    | 155/285 [02:27<01:46,  1.22it/s]Loading train:  55%|█████▍    | 156/285 [02:28<01:49,  1.18it/s]Loading train:  55%|█████▌    | 157/285 [02:29<01:44,  1.22it/s]Loading train:  55%|█████▌    | 158/285 [02:29<01:41,  1.25it/s]Loading train:  56%|█████▌    | 159/285 [02:30<01:39,  1.26it/s]Loading train:  56%|█████▌    | 160/285 [02:31<01:33,  1.34it/s]Loading train:  56%|█████▋    | 161/285 [02:32<01:37,  1.27it/s]Loading train:  57%|█████▋    | 162/285 [02:32<01:36,  1.27it/s]Loading train:  57%|█████▋    | 163/285 [02:33<01:37,  1.26it/s]Loading train:  58%|█████▊    | 164/285 [02:34<01:39,  1.22it/s]Loading train:  58%|█████▊    | 165/285 [02:35<01:37,  1.22it/s]Loading train:  58%|█████▊    | 166/285 [02:36<01:39,  1.20it/s]Loading train:  59%|█████▊    | 167/285 [02:37<01:35,  1.24it/s]Loading train:  59%|█████▉    | 168/285 [02:37<01:34,  1.24it/s]Loading train:  59%|█████▉    | 169/285 [02:38<01:32,  1.26it/s]Loading train:  60%|█████▉    | 170/285 [02:39<01:32,  1.24it/s]Loading train:  60%|██████    | 171/285 [02:40<01:31,  1.24it/s]Loading train:  60%|██████    | 172/285 [02:41<01:29,  1.26it/s]Loading train:  61%|██████    | 173/285 [02:41<01:30,  1.24it/s]Loading train:  61%|██████    | 174/285 [02:42<01:28,  1.25it/s]Loading train:  61%|██████▏   | 175/285 [02:43<01:30,  1.22it/s]Loading train:  62%|██████▏   | 176/285 [02:44<01:31,  1.20it/s]Loading train:  62%|██████▏   | 177/285 [02:45<01:27,  1.23it/s]Loading train:  62%|██████▏   | 178/285 [02:45<01:25,  1.25it/s]Loading train:  63%|██████▎   | 179/285 [02:46<01:24,  1.26it/s]Loading train:  63%|██████▎   | 180/285 [02:47<01:30,  1.16it/s]Loading train:  64%|██████▎   | 181/285 [02:48<01:30,  1.15it/s]Loading train:  64%|██████▍   | 182/285 [02:49<01:30,  1.14it/s]Loading train:  64%|██████▍   | 183/285 [02:50<01:24,  1.21it/s]Loading train:  65%|██████▍   | 184/285 [02:50<01:20,  1.25it/s]Loading train:  65%|██████▍   | 185/285 [02:51<01:18,  1.28it/s]Loading train:  65%|██████▌   | 186/285 [02:52<01:22,  1.20it/s]Loading train:  66%|██████▌   | 187/285 [02:53<01:23,  1.17it/s]Loading train:  66%|██████▌   | 188/285 [02:54<01:26,  1.12it/s]Loading train:  66%|██████▋   | 189/285 [02:55<01:19,  1.21it/s]Loading train:  67%|██████▋   | 190/285 [02:55<01:15,  1.25it/s]Loading train:  67%|██████▋   | 191/285 [02:56<01:22,  1.14it/s]Loading train:  67%|██████▋   | 192/285 [02:57<01:22,  1.13it/s]Loading train:  68%|██████▊   | 193/285 [02:58<01:19,  1.16it/s]Loading train:  68%|██████▊   | 194/285 [02:59<01:18,  1.16it/s]Loading train:  68%|██████▊   | 195/285 [03:00<01:14,  1.20it/s]Loading train:  69%|██████▉   | 196/285 [03:01<01:16,  1.16it/s]Loading train:  69%|██████▉   | 197/285 [03:02<01:19,  1.11it/s]Loading train:  69%|██████▉   | 198/285 [03:03<01:19,  1.10it/s]Loading train:  70%|██████▉   | 199/285 [03:03<01:12,  1.19it/s]Loading train:  70%|███████   | 200/285 [03:04<01:11,  1.18it/s]Loading train:  71%|███████   | 201/285 [03:05<01:13,  1.14it/s]Loading train:  71%|███████   | 202/285 [03:06<01:14,  1.11it/s]Loading train:  71%|███████   | 203/285 [03:07<01:11,  1.14it/s]Loading train:  72%|███████▏  | 204/285 [03:08<01:13,  1.10it/s]Loading train:  72%|███████▏  | 205/285 [03:09<01:09,  1.16it/s]Loading train:  72%|███████▏  | 206/285 [03:09<01:07,  1.17it/s]Loading train:  73%|███████▎  | 207/285 [03:10<01:07,  1.16it/s]Loading train:  73%|███████▎  | 208/285 [03:11<01:07,  1.14it/s]Loading train:  73%|███████▎  | 209/285 [03:12<01:07,  1.13it/s]Loading train:  74%|███████▎  | 210/285 [03:13<01:04,  1.16it/s]Loading train:  74%|███████▍  | 211/285 [03:14<01:01,  1.20it/s]Loading train:  74%|███████▍  | 212/285 [03:15<00:59,  1.22it/s]Loading train:  75%|███████▍  | 213/285 [03:16<01:02,  1.15it/s]Loading train:  75%|███████▌  | 214/285 [03:16<00:59,  1.19it/s]Loading train:  75%|███████▌  | 215/285 [03:17<01:01,  1.14it/s]Loading train:  76%|███████▌  | 216/285 [03:18<00:56,  1.21it/s]Loading train:  76%|███████▌  | 217/285 [03:19<00:55,  1.22it/s]Loading train:  76%|███████▋  | 218/285 [03:20<00:58,  1.14it/s]Loading train:  77%|███████▋  | 219/285 [03:21<00:58,  1.13it/s]Loading train:  77%|███████▋  | 220/285 [03:22<00:58,  1.12it/s]Loading train:  78%|███████▊  | 221/285 [03:22<00:54,  1.17it/s]Loading train:  78%|███████▊  | 222/285 [03:23<00:54,  1.15it/s]Loading train:  78%|███████▊  | 223/285 [03:24<00:50,  1.24it/s]Loading train:  79%|███████▊  | 224/285 [03:25<00:50,  1.21it/s]Loading train:  79%|███████▉  | 225/285 [03:26<00:51,  1.17it/s]Loading train:  79%|███████▉  | 226/285 [03:27<00:53,  1.11it/s]Loading train:  80%|███████▉  | 227/285 [03:28<00:51,  1.12it/s]Loading train:  80%|████████  | 228/285 [03:29<00:53,  1.07it/s]Loading train:  80%|████████  | 229/285 [03:30<00:56,  1.01s/it]Loading train:  81%|████████  | 230/285 [03:31<00:50,  1.08it/s]Loading train:  81%|████████  | 231/285 [03:31<00:49,  1.08it/s]Loading train:  81%|████████▏ | 232/285 [03:32<00:47,  1.11it/s]Loading train:  82%|████████▏ | 233/285 [03:33<00:43,  1.18it/s]Loading train:  82%|████████▏ | 234/285 [03:34<00:44,  1.14it/s]Loading train:  82%|████████▏ | 235/285 [03:35<00:42,  1.17it/s]Loading train:  83%|████████▎ | 236/285 [03:36<00:44,  1.10it/s]Loading train:  83%|████████▎ | 237/285 [03:37<00:43,  1.11it/s]Loading train:  84%|████████▎ | 238/285 [03:38<00:43,  1.09it/s]Loading train:  84%|████████▍ | 239/285 [03:39<00:41,  1.12it/s]Loading train:  84%|████████▍ | 240/285 [03:39<00:38,  1.18it/s]Loading train:  85%|████████▍ | 241/285 [03:40<00:37,  1.18it/s]Loading train:  85%|████████▍ | 242/285 [03:41<00:36,  1.18it/s]Loading train:  85%|████████▌ | 243/285 [03:42<00:33,  1.25it/s]Loading train:  86%|████████▌ | 244/285 [03:43<00:34,  1.18it/s]Loading train:  86%|████████▌ | 245/285 [03:43<00:32,  1.21it/s]Loading train:  86%|████████▋ | 246/285 [03:44<00:33,  1.17it/s]Loading train:  87%|████████▋ | 247/285 [03:45<00:33,  1.13it/s]Loading train:  87%|████████▋ | 248/285 [03:46<00:32,  1.15it/s]Loading train:  87%|████████▋ | 249/285 [03:47<00:30,  1.20it/s]Loading train:  88%|████████▊ | 250/285 [03:48<00:27,  1.27it/s]Loading train:  88%|████████▊ | 251/285 [03:48<00:26,  1.30it/s]Loading train:  88%|████████▊ | 252/285 [03:49<00:25,  1.30it/s]Loading train:  89%|████████▉ | 253/285 [03:50<00:27,  1.18it/s]Loading train:  89%|████████▉ | 254/285 [03:51<00:29,  1.05it/s]Loading train:  89%|████████▉ | 255/285 [03:52<00:28,  1.05it/s]Loading train:  90%|████████▉ | 256/285 [03:53<00:28,  1.03it/s]Loading train:  90%|█████████ | 257/285 [03:54<00:25,  1.08it/s]Loading train:  91%|█████████ | 258/285 [03:55<00:25,  1.07it/s]Loading train:  91%|█████████ | 259/285 [03:56<00:23,  1.11it/s]Loading train:  91%|█████████ | 260/285 [03:57<00:21,  1.18it/s]Loading train:  92%|█████████▏| 261/285 [03:57<00:20,  1.17it/s]Loading train:  92%|█████████▏| 262/285 [03:58<00:19,  1.20it/s]Loading train:  92%|█████████▏| 263/285 [03:59<00:18,  1.22it/s]Loading train:  93%|█████████▎| 264/285 [04:00<00:17,  1.21it/s]Loading train:  93%|█████████▎| 265/285 [04:01<00:17,  1.12it/s]Loading train:  93%|█████████▎| 266/285 [04:02<00:15,  1.19it/s]Loading train:  94%|█████████▎| 267/285 [04:02<00:14,  1.20it/s]Loading train:  94%|█████████▍| 268/285 [04:03<00:15,  1.11it/s]Loading train:  94%|█████████▍| 269/285 [04:04<00:14,  1.11it/s]Loading train:  95%|█████████▍| 270/285 [04:05<00:13,  1.10it/s]Loading train:  95%|█████████▌| 271/285 [04:06<00:11,  1.19it/s]Loading train:  95%|█████████▌| 272/285 [04:07<00:11,  1.10it/s]Loading train:  96%|█████████▌| 273/285 [04:08<00:10,  1.13it/s]Loading train:  96%|█████████▌| 274/285 [04:09<00:09,  1.14it/s]Loading train:  96%|█████████▋| 275/285 [04:10<00:08,  1.15it/s]Loading train:  97%|█████████▋| 276/285 [04:11<00:08,  1.06it/s]Loading train:  97%|█████████▋| 277/285 [04:11<00:06,  1.17it/s]Loading train:  98%|█████████▊| 278/285 [04:12<00:06,  1.10it/s]Loading train:  98%|█████████▊| 279/285 [04:13<00:05,  1.05it/s]Loading train:  98%|█████████▊| 280/285 [04:14<00:04,  1.10it/s]Loading train:  99%|█████████▊| 281/285 [04:15<00:03,  1.18it/s]Loading train:  99%|█████████▉| 282/285 [04:16<00:02,  1.17it/s]Loading train:  99%|█████████▉| 283/285 [04:17<00:01,  1.13it/s]Loading train: 100%|█████████▉| 284/285 [04:18<00:00,  1.10it/s]Loading train: 100%|██████████| 285/285 [04:19<00:00,  1.06it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   9%|▉         | 25/285 [00:00<00:01, 243.38it/s]concatenating: train:  19%|█▉        | 54/285 [00:00<00:00, 254.97it/s]concatenating: train:  26%|██▌       | 74/285 [00:00<00:00, 235.10it/s]concatenating: train:  38%|███▊      | 107/285 [00:00<00:00, 256.81it/s]concatenating: train:  48%|████▊     | 136/285 [00:00<00:00, 261.46it/s]concatenating: train:  59%|█████▉    | 168/285 [00:00<00:00, 276.58it/s]concatenating: train:  71%|███████   | 203/285 [00:00<00:00, 294.22it/s]concatenating: train:  84%|████████▎ | 238/285 [00:00<00:00, 308.56it/s]concatenating: train:  96%|█████████▌| 273/285 [00:00<00:00, 318.86it/s]concatenating: train: 100%|██████████| 285/285 [00:00<00:00, 302.87it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.20s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.20s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.23s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 387.78it/s]2019-07-09 05:32:44.394522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-09 05:32:44.394638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-09 05:32:44.394653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-09 05:32:44.394662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-09 05:32:44.395101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12743 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  4.82it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.63it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.48it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  7.05it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.35it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.33it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.95it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.84it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.55it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.12it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.83it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.47it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.93it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.39it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.81it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.88it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.01it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.26it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.41it/s] min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 40)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 41)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 15)   5550        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 15)   2040        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 15)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 40, 26, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 30)   4080        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 30)   8130        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 45)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 60)   24360       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 60)   32460       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 105)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 30)   12630       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 30)   8130        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 105)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 40, 26, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 15)   6315        dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 15)   2040        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 45)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 80, 52, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 13)   598         dropout_6[0][0]                  
==================================================================================================
Total params: 132,438
Trainable params: 33,898
Non-trainable params: 98,540
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 23s - loss: 24317.7313 - acc: 0.7161 - mDice: 0.0714 - val_loss: 13447.4486 - val_acc: 0.9024 - val_mDice: 0.1859

Epoch 00001: val_mDice improved from -inf to 0.18585, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 15s - loss: 11841.9290 - acc: 0.8763 - mDice: 0.2340 - val_loss: 11164.7693 - val_acc: 0.9040 - val_mDice: 0.2323

Epoch 00002: val_mDice improved from 0.18585 to 0.23228, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 14s - loss: 8551.4366 - acc: 0.8801 - mDice: 0.3315 - val_loss: 7488.1087 - val_acc: 0.9054 - val_mDice: 0.3616

Epoch 00003: val_mDice improved from 0.23228 to 0.36159, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 16s - loss: 7384.1751 - acc: 0.8817 - mDice: 0.3824 - val_loss: 6443.3231 - val_acc: 0.9081 - val_mDice: 0.4118

Epoch 00004: val_mDice improved from 0.36159 to 0.41179, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 15s - loss: 6714.3460 - acc: 0.8836 - mDice: 0.4164 - val_loss: 6113.2173 - val_acc: 0.9097 - val_mDice: 0.4309

Epoch 00005: val_mDice improved from 0.41179 to 0.43092, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 15s - loss: 6273.1224 - acc: 0.8873 - mDice: 0.4405 - val_loss: 5728.4520 - val_acc: 0.9144 - val_mDice: 0.4530

Epoch 00006: val_mDice improved from 0.43092 to 0.45303, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 15s - loss: 5880.9338 - acc: 0.8949 - mDice: 0.4628 - val_loss: 6218.2600 - val_acc: 0.9137 - val_mDice: 0.4264

Epoch 00007: val_mDice did not improve from 0.45303
Epoch 8/300
 - 14s - loss: 5643.5765 - acc: 0.9020 - mDice: 0.4773 - val_loss: 5623.3317 - val_acc: 0.9171 - val_mDice: 0.4590

Epoch 00008: val_mDice improved from 0.45303 to 0.45900, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 15s - loss: 5388.8146 - acc: 0.9056 - mDice: 0.4928 - val_loss: 5514.5906 - val_acc: 0.9158 - val_mDice: 0.4648

Epoch 00009: val_mDice improved from 0.45900 to 0.46475, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 15s - loss: 5225.5096 - acc: 0.9086 - mDice: 0.5031 - val_loss: 5579.2347 - val_acc: 0.9172 - val_mDice: 0.4621

Epoch 00010: val_mDice did not improve from 0.46475
Epoch 11/300
 - 15s - loss: 5043.6363 - acc: 0.9113 - mDice: 0.5147 - val_loss: 5228.7169 - val_acc: 0.9208 - val_mDice: 0.4836

Epoch 00011: val_mDice improved from 0.46475 to 0.48362, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 15s - loss: 4871.1663 - acc: 0.9136 - mDice: 0.5261 - val_loss: 5296.8514 - val_acc: 0.9203 - val_mDice: 0.4774

Epoch 00012: val_mDice did not improve from 0.48362
Epoch 13/300
 - 15s - loss: 4720.8403 - acc: 0.9157 - mDice: 0.5362 - val_loss: 5256.6103 - val_acc: 0.9254 - val_mDice: 0.4790

Epoch 00013: val_mDice did not improve from 0.48362
Epoch 14/300
 - 15s - loss: 4600.9758 - acc: 0.9175 - mDice: 0.5447 - val_loss: 5068.8397 - val_acc: 0.9264 - val_mDice: 0.4913

Epoch 00014: val_mDice improved from 0.48362 to 0.49126, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 14s - loss: 4464.7541 - acc: 0.9192 - mDice: 0.5543 - val_loss: 6122.4090 - val_acc: 0.9241 - val_mDice: 0.4340

Epoch 00015: val_mDice did not improve from 0.49126
Epoch 16/300
 - 15s - loss: 4392.6345 - acc: 0.9204 - mDice: 0.5594 - val_loss: 4734.5656 - val_acc: 0.9234 - val_mDice: 0.5146

Epoch 00016: val_mDice improved from 0.49126 to 0.51461, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 15s - loss: 4317.9293 - acc: 0.9216 - mDice: 0.5651 - val_loss: 4767.0120 - val_acc: 0.9256 - val_mDice: 0.5117

Epoch 00017: val_mDice did not improve from 0.51461
Epoch 18/300
 - 15s - loss: 4212.2231 - acc: 0.9227 - mDice: 0.5729 - val_loss: 4879.3530 - val_acc: 0.9264 - val_mDice: 0.5033

Epoch 00018: val_mDice did not improve from 0.51461
Epoch 19/300
 - 15s - loss: 4165.7829 - acc: 0.9235 - mDice: 0.5764 - val_loss: 5220.4022 - val_acc: 0.9215 - val_mDice: 0.4821

Epoch 00019: val_mDice did not improve from 0.51461
Epoch 20/300
 - 15s - loss: 4118.5830 - acc: 0.9240 - mDice: 0.5798 - val_loss: 4693.9855 - val_acc: 0.9231 - val_mDice: 0.5160

Epoch 00020: val_mDice improved from 0.51461 to 0.51604, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 21/300
 - 15s - loss: 4090.5564 - acc: 0.9244 - mDice: 0.5823 - val_loss: 4797.4919 - val_acc: 0.9269 - val_mDice: 0.5095

Epoch 00021: val_mDice did not improve from 0.51604
Epoch 22/300
 - 15s - loss: 4015.0398 - acc: 0.9253 - mDice: 0.5881 - val_loss: 4707.4798 - val_acc: 0.9245 - val_mDice: 0.5155

Epoch 00022: val_mDice did not improve from 0.51604
Epoch 23/300
 - 14s - loss: 3956.4421 - acc: 0.9259 - mDice: 0.5924 - val_loss: 4809.3681 - val_acc: 0.9301 - val_mDice: 0.5074

Epoch 00023: val_mDice did not improve from 0.51604
Epoch 24/300
 - 15s - loss: 3922.3272 - acc: 0.9265 - mDice: 0.5951 - val_loss: 4736.7556 - val_acc: 0.9305 - val_mDice: 0.5116

Epoch 00024: val_mDice did not improve from 0.51604
Epoch 25/300
 - 15s - loss: 3909.3281 - acc: 0.9267 - mDice: 0.5963 - val_loss: 4706.4897 - val_acc: 0.9258 - val_mDice: 0.5171

Epoch 00025: val_mDice improved from 0.51604 to 0.51710, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 26/300
 - 14s - loss: 3872.6093 - acc: 0.9269 - mDice: 0.5991 - val_loss: 4606.5802 - val_acc: 0.9257 - val_mDice: 0.5222

Epoch 00026: val_mDice improved from 0.51710 to 0.52221, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 27/300
 - 15s - loss: 3825.1615 - acc: 0.9275 - mDice: 0.6030 - val_loss: 4619.1392 - val_acc: 0.9303 - val_mDice: 0.5226

Epoch 00027: val_mDice improved from 0.52221 to 0.52256, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 28/300
 - 15s - loss: 3791.4082 - acc: 0.9277 - mDice: 0.6054 - val_loss: 4836.3665 - val_acc: 0.9276 - val_mDice: 0.5052

Epoch 00028: val_mDice did not improve from 0.52256
Epoch 29/300
 - 14s - loss: 3774.2564 - acc: 0.9279 - mDice: 0.6070 - val_loss: 4568.9065 - val_acc: 0.9296 - val_mDice: 0.5255

Epoch 00029: val_mDice improved from 0.52256 to 0.52552, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 30/300
 - 15s - loss: 3740.2450 - acc: 0.9283 - mDice: 0.6096 - val_loss: 4615.0326 - val_acc: 0.9301 - val_mDice: 0.5210

Epoch 00030: val_mDice did not improve from 0.52552
Epoch 31/300
 - 15s - loss: 3704.1399 - acc: 0.9285 - mDice: 0.6126 - val_loss: 4692.2089 - val_acc: 0.9266 - val_mDice: 0.5158

Epoch 00031: val_mDice did not improve from 0.52552
Epoch 32/300
 - 15s - loss: 3671.2973 - acc: 0.9289 - mDice: 0.6151 - val_loss: 4585.6170 - val_acc: 0.9324 - val_mDice: 0.5247

Epoch 00032: val_mDice did not improve from 0.52552
Epoch 33/300
 - 15s - loss: 3632.2981 - acc: 0.9294 - mDice: 0.6181 - val_loss: 4414.1479 - val_acc: 0.9319 - val_mDice: 0.5367

Epoch 00033: val_mDice improved from 0.52552 to 0.53668, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 34/300
 - 16s - loss: 3606.5973 - acc: 0.9297 - mDice: 0.6204 - val_loss: 4514.9746 - val_acc: 0.9339 - val_mDice: 0.5295

Epoch 00034: val_mDice did not improve from 0.53668
Epoch 35/300
 - 14s - loss: 3584.9586 - acc: 0.9299 - mDice: 0.6221 - val_loss: 4990.0561 - val_acc: 0.9298 - val_mDice: 0.4974

Epoch 00035: val_mDice did not improve from 0.53668
Epoch 36/300
 - 15s - loss: 3579.8574 - acc: 0.9299 - mDice: 0.6228 - val_loss: 4612.8225 - val_acc: 0.9324 - val_mDice: 0.5235

Epoch 00036: val_mDice did not improve from 0.53668
Epoch 37/300
 - 15s - loss: 3550.6513 - acc: 0.9302 - mDice: 0.6250 - val_loss: 5030.5769 - val_acc: 0.9306 - val_mDice: 0.4938

Epoch 00037: val_mDice did not improve from 0.53668
Epoch 38/300
 - 14s - loss: 3538.4957 - acc: 0.9303 - mDice: 0.6261 - val_loss: 4555.3658 - val_acc: 0.9317 - val_mDice: 0.5246

Epoch 00038: val_mDice did not improve from 0.53668
Epoch 39/300
 - 14s - loss: 3510.4075 - acc: 0.9307 - mDice: 0.6284 - val_loss: 4541.3014 - val_acc: 0.9334 - val_mDice: 0.5272

Epoch 00039: val_mDice did not improve from 0.53668
Epoch 40/300
 - 16s - loss: 3524.1251 - acc: 0.9307 - mDice: 0.6273 - val_loss: 4723.4929 - val_acc: 0.9320 - val_mDice: 0.5153

Epoch 00040: val_mDice did not improve from 0.53668
Epoch 41/300
 - 15s - loss: 3488.9484 - acc: 0.9309 - mDice: 0.6301 - val_loss: 4459.3739 - val_acc: 0.9343 - val_mDice: 0.5355

Epoch 00041: val_mDice did not improve from 0.53668
Epoch 42/300
 - 15s - loss: 3463.5818 - acc: 0.9312 - mDice: 0.6322 - val_loss: 4511.4330 - val_acc: 0.9312 - val_mDice: 0.5319

Epoch 00042: val_mDice did not improve from 0.53668
Epoch 43/300
 - 15s - loss: 3440.7522 - acc: 0.9314 - mDice: 0.6342 - val_loss: 4510.1261 - val_acc: 0.9296 - val_mDice: 0.5321

Epoch 00043: val_mDice did not improve from 0.53668
Epoch 44/300
 - 13s - loss: 3446.3037 - acc: 0.9313 - mDice: 0.6337 - val_loss: 4364.4372 - val_acc: 0.9334 - val_mDice: 0.5424

Epoch 00044: val_mDice improved from 0.53668 to 0.54241, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 45/300
 - 14s - loss: 3410.1666 - acc: 0.9317 - mDice: 0.6367 - val_loss: 4526.5249 - val_acc: 0.9316 - val_mDice: 0.5299

Epoch 00045: val_mDice did not improve from 0.54241
Epoch 46/300
 - 15s - loss: 3406.1784 - acc: 0.9317 - mDice: 0.6369 - val_loss: 4332.5079 - val_acc: 0.9328 - val_mDice: 0.5417

Epoch 00046: val_mDice did not improve from 0.54241
Epoch 47/300
 - 16s - loss: 3394.4158 - acc: 0.9319 - mDice: 0.6380 - val_loss: 4540.8575 - val_acc: 0.9357 - val_mDice: 0.5286

Epoch 00047: val_mDice did not improve from 0.54241
Epoch 48/300
 - 15s - loss: 3371.1955 - acc: 0.9323 - mDice: 0.6401 - val_loss: 4473.8362 - val_acc: 0.9319 - val_mDice: 0.5347

Epoch 00048: val_mDice did not improve from 0.54241
Epoch 49/300
 - 15s - loss: 3379.0542 - acc: 0.9320 - mDice: 0.6395 - val_loss: 4738.5725 - val_acc: 0.9294 - val_mDice: 0.5170

Epoch 00049: val_mDice did not improve from 0.54241
Epoch 50/300
 - 15s - loss: 3334.0866 - acc: 0.9324 - mDice: 0.6432 - val_loss: 4543.8492 - val_acc: 0.9343 - val_mDice: 0.5299

Epoch 00050: val_mDice did not improve from 0.54241
Epoch 51/300
 - 15s - loss: 3336.5198 - acc: 0.9324 - mDice: 0.6429 - val_loss: 4562.2727 - val_acc: 0.9321 - val_mDice: 0.5278

Epoch 00051: val_mDice did not improve from 0.54241
Epoch 52/300
 - 15s - loss: 3337.6314 - acc: 0.9325 - mDice: 0.6430 - val_loss: 4634.6240 - val_acc: 0.9348 - val_mDice: 0.5238

Epoch 00052: val_mDice did not improve from 0.54241
Epoch 53/300
 - 15s - loss: 3327.7365 - acc: 0.9325 - mDice: 0.6436 - val_loss: 4595.8054 - val_acc: 0.9319 - val_mDice: 0.5263

Epoch 00053: val_mDice did not improve from 0.54241
Epoch 54/300
 - 16s - loss: 3293.5990 - acc: 0.9331 - mDice: 0.6466 - val_loss: 4542.4437 - val_acc: 0.9293 - val_mDice: 0.5286

Epoch 00054: val_mDice did not improve from 0.54241
Epoch 55/300
 - 16s - loss: 3289.1907 - acc: 0.9331 - mDice: 0.6469 - val_loss: 4559.9106 - val_acc: 0.9297 - val_mDice: 0.5270

Epoch 00055: val_mDice did not improve from 0.54241
Epoch 56/300
 - 15s - loss: 3288.0146 - acc: 0.9332 - mDice: 0.6471 - val_loss: 4483.2282 - val_acc: 0.9337 - val_mDice: 0.5340

Epoch 00056: val_mDice did not improve from 0.54241
Epoch 57/300
 - 15s - loss: 3269.6558 - acc: 0.9333 - mDice: 0.6487 - val_loss: 4583.1808 - val_acc: 0.9328 - val_mDice: 0.5257

Epoch 00057: val_mDice did not improve from 0.54241
Epoch 58/300
 - 15s - loss: 3252.7412 - acc: 0.9336 - mDice: 0.6501 - val_loss: 4447.0581 - val_acc: 0.9359 - val_mDice: 0.5369

Epoch 00058: val_mDice did not improve from 0.54241
Epoch 59/300
 - 15s - loss: 3241.0319 - acc: 0.9337 - mDice: 0.6511 - val_loss: 4653.6379 - val_acc: 0.9347 - val_mDice: 0.5187

Epoch 00059: val_mDice did not improve from 0.54241
Epoch 60/300
 - 15s - loss: 3244.0688 - acc: 0.9337 - mDice: 0.6510 - val_loss: 4516.1762 - val_acc: 0.9315 - val_mDice: 0.5310

Epoch 00060: val_mDice did not improve from 0.54241
Epoch 61/300
 - 14s - loss: 3243.0622 - acc: 0.9338 - mDice: 0.6510 - val_loss: 4433.6989 - val_acc: 0.9332 - val_mDice: 0.5366

Epoch 00061: val_mDice did not improve from 0.54241
Epoch 62/300
 - 15s - loss: 3212.7385 - acc: 0.9340 - mDice: 0.6537 - val_loss: 4465.7468 - val_acc: 0.9340 - val_mDice: 0.5354

Epoch 00062: val_mDice did not improve from 0.54241
Epoch 63/300
 - 15s - loss: 3198.5630 - acc: 0.9343 - mDice: 0.6547 - val_loss: 4632.7051 - val_acc: 0.9348 - val_mDice: 0.5219

Epoch 00063: val_mDice did not improve from 0.54241
Epoch 64/300
 - 15s - loss: 3181.0331 - acc: 0.9344 - mDice: 0.6564 - val_loss: 4418.1808 - val_acc: 0.9335 - val_mDice: 0.5375

Epoch 00064: val_mDice did not improve from 0.54241
Epoch 65/300
 - 15s - loss: 3187.2926 - acc: 0.9343 - mDice: 0.6558 - val_loss: 4472.0059 - val_acc: 0.9245 - val_mDice: 0.5339

Epoch 00065: val_mDice did not improve from 0.54241
Epoch 66/300
 - 14s - loss: 3181.1526 - acc: 0.9344 - mDice: 0.6563 - val_loss: 4305.7948 - val_acc: 0.9308 - val_mDice: 0.5483

Epoch 00066: val_mDice improved from 0.54241 to 0.54831, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 67/300
 - 14s - loss: 3162.3076 - acc: 0.9346 - mDice: 0.6578 - val_loss: 4688.2012 - val_acc: 0.9232 - val_mDice: 0.5194

Epoch 00067: val_mDice did not improve from 0.54831
Epoch 68/300
 - 15s - loss: 3163.1486 - acc: 0.9348 - mDice: 0.6578 - val_loss: 4416.4281 - val_acc: 0.9345 - val_mDice: 0.5378

Epoch 00068: val_mDice did not improve from 0.54831
Epoch 69/300
 - 15s - loss: 3158.8018 - acc: 0.9349 - mDice: 0.6582 - val_loss: 4374.7841 - val_acc: 0.9352 - val_mDice: 0.5409

Epoch 00069: val_mDice did not improve from 0.54831
Epoch 70/300
 - 16s - loss: 3167.2744 - acc: 0.9346 - mDice: 0.6575 - val_loss: 4719.4013 - val_acc: 0.9365 - val_mDice: 0.5177

Epoch 00070: val_mDice did not improve from 0.54831
Epoch 71/300
 - 15s - loss: 3143.9323 - acc: 0.9350 - mDice: 0.6596 - val_loss: 4338.3505 - val_acc: 0.9343 - val_mDice: 0.5438

Epoch 00071: val_mDice did not improve from 0.54831
Epoch 72/300
 - 15s - loss: 3114.3375 - acc: 0.9353 - mDice: 0.6621 - val_loss: 4415.0699 - val_acc: 0.9352 - val_mDice: 0.5385

Epoch 00072: val_mDice did not improve from 0.54831
Epoch 73/300
 - 15s - loss: 3119.6644 - acc: 0.9353 - mDice: 0.6616 - val_loss: 4512.1925 - val_acc: 0.9276 - val_mDice: 0.5327

Epoch 00073: val_mDice did not improve from 0.54831
Epoch 74/300
 - 15s - loss: 3129.2823 - acc: 0.9352 - mDice: 0.6607 - val_loss: 4380.4622 - val_acc: 0.9308 - val_mDice: 0.5416

Epoch 00074: val_mDice did not improve from 0.54831
Epoch 75/300
 - 15s - loss: 3122.8175 - acc: 0.9354 - mDice: 0.6615 - val_loss: 4363.3842 - val_acc: 0.9306 - val_mDice: 0.5401

Epoch 00075: val_mDice did not improve from 0.54831
Epoch 76/300
 - 15s - loss: 3113.2582 - acc: 0.9355 - mDice: 0.6622 - val_loss: 4429.2954 - val_acc: 0.9287 - val_mDice: 0.5367

Epoch 00076: val_mDice did not improve from 0.54831
Epoch 77/300
 - 15s - loss: 3096.8280 - acc: 0.9357 - mDice: 0.6637 - val_loss: 4765.1777 - val_acc: 0.9303 - val_mDice: 0.5131

Epoch 00077: val_mDice did not improve from 0.54831
Epoch 78/300
 - 15s - loss: 3087.0197 - acc: 0.9356 - mDice: 0.6644 - val_loss: 4464.9117 - val_acc: 0.9343 - val_mDice: 0.5361

Epoch 00078: val_mDice did not improve from 0.54831
Epoch 79/300
 - 15s - loss: 3084.3706 - acc: 0.9358 - mDice: 0.6647 - val_loss: 4671.5791 - val_acc: 0.9260 - val_mDice: 0.5208

Epoch 00079: val_mDice did not improve from 0.54831
Epoch 80/300
 - 15s - loss: 3080.7580 - acc: 0.9358 - mDice: 0.6651 - val_loss: 4479.7724 - val_acc: 0.9344 - val_mDice: 0.5329

Epoch 00080: val_mDice did not improve from 0.54831
Epoch 81/300
 - 15s - loss: 3072.7120 - acc: 0.9360 - mDice: 0.6657 - val_loss: 4408.4259 - val_acc: 0.9269 - val_mDice: 0.5381

Epoch 00081: val_mDice did not improve from 0.54831
Epoch 82/300
 - 15s - loss: 3062.2104 - acc: 0.9361 - mDice: 0.6666 - val_loss: 4279.6278 - val_acc: 0.9339 - val_mDice: 0.5494

Epoch 00082: val_mDice improved from 0.54831 to 0.54944, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 83/300
 - 15s - loss: 3058.1385 - acc: 0.9360 - mDice: 0.6671 - val_loss: 4521.2220 - val_acc: 0.9270 - val_mDice: 0.5306

Epoch 00083: val_mDice did not improve from 0.54944
Epoch 84/300
 - 15s - loss: 3080.5876 - acc: 0.9359 - mDice: 0.6652 - val_loss: 4254.6494 - val_acc: 0.9313 - val_mDice: 0.5509

Epoch 00084: val_mDice improved from 0.54944 to 0.55088, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 85/300
 - 16s - loss: 3049.1985 - acc: 0.9363 - mDice: 0.6677 - val_loss: 4382.6093 - val_acc: 0.9280 - val_mDice: 0.5404

Epoch 00085: val_mDice did not improve from 0.55088
Epoch 86/300
 - 15s - loss: 3055.3873 - acc: 0.9362 - mDice: 0.6672 - val_loss: 4394.6245 - val_acc: 0.9284 - val_mDice: 0.5380

Epoch 00086: val_mDice did not improve from 0.55088
Epoch 87/300
 - 15s - loss: 3035.4455 - acc: 0.9365 - mDice: 0.6691 - val_loss: 4434.4446 - val_acc: 0.9273 - val_mDice: 0.5366

Epoch 00087: val_mDice did not improve from 0.55088
Epoch 88/300
 - 15s - loss: 3033.5434 - acc: 0.9365 - mDice: 0.6690 - val_loss: 4361.4231 - val_acc: 0.9364 - val_mDice: 0.5413

Epoch 00088: val_mDice did not improve from 0.55088
Epoch 89/300
 - 15s - loss: 3035.8668 - acc: 0.9368 - mDice: 0.6690 - val_loss: 4363.9422 - val_acc: 0.9273 - val_mDice: 0.5420

Epoch 00089: val_mDice did not improve from 0.55088
Epoch 90/300
 - 15s - loss: 3013.7017 - acc: 0.9369 - mDice: 0.6709 - val_loss: 4517.9952 - val_acc: 0.9342 - val_mDice: 0.5296

Epoch 00090: val_mDice did not improve from 0.55088
Epoch 91/300
 - 15s - loss: 3015.0356 - acc: 0.9369 - mDice: 0.6707 - val_loss: 4317.9467 - val_acc: 0.9296 - val_mDice: 0.5460

Epoch 00091: val_mDice did not improve from 0.55088
Epoch 92/300
 - 15s - loss: 3016.2358 - acc: 0.9368 - mDice: 0.6707 - val_loss: 4460.4774 - val_acc: 0.9294 - val_mDice: 0.5348

Epoch 00092: val_mDice did not improve from 0.55088
Epoch 93/300
 - 16s - loss: 3011.5118 - acc: 0.9369 - mDice: 0.6710 - val_loss: 4393.1615 - val_acc: 0.9346 - val_mDice: 0.5391

Epoch 00093: val_mDice did not improve from 0.55088
Epoch 94/300
 - 15s - loss: 3004.4899 - acc: 0.9370 - mDice: 0.6717 - val_loss: 4636.0535 - val_acc: 0.9321 - val_mDice: 0.5240

Epoch 00094: val_mDice did not improve from 0.55088
Epoch 95/300
 - 14s - loss: 3001.1693 - acc: 0.9369 - mDice: 0.6720 - val_loss: 4466.9173 - val_acc: 0.9370 - val_mDice: 0.5328

Epoch 00095: val_mDice did not improve from 0.55088
Epoch 96/300
 - 15s - loss: 3002.4437 - acc: 0.9371 - mDice: 0.6718 - val_loss: 4287.2008 - val_acc: 0.9344 - val_mDice: 0.5479

Epoch 00096: val_mDice did not improve from 0.55088
Epoch 97/300
 - 14s - loss: 2981.8933 - acc: 0.9374 - mDice: 0.6738 - val_loss: 4425.6337 - val_acc: 0.9337 - val_mDice: 0.5374

Epoch 00097: val_mDice did not improve from 0.55088
Epoch 98/300
 - 15s - loss: 2985.5494 - acc: 0.9373 - mDice: 0.6734 - val_loss: 4288.8461 - val_acc: 0.9339 - val_mDice: 0.5460

Epoch 00098: val_mDice did not improve from 0.55088
Epoch 99/300
 - 15s - loss: 3010.0061 - acc: 0.9370 - mDice: 0.6714 - val_loss: 4505.0137 - val_acc: 0.9322 - val_mDice: 0.5329

Epoch 00099: val_mDice did not improve from 0.55088
Epoch 100/300
 - 16s - loss: 2984.3488 - acc: 0.9373 - mDice: 0.6735 - val_loss: 4342.8282 - val_acc: 0.9328 - val_mDice: 0.5438

Epoch 00100: val_mDice did not improve from 0.55088
Epoch 101/300
 - 15s - loss: 2976.4374 - acc: 0.9374 - mDice: 0.6742 - val_loss: 4342.5014 - val_acc: 0.9349 - val_mDice: 0.5438

Epoch 00101: val_mDice did not improve from 0.55088
Epoch 102/300
 - 15s - loss: 2983.6051 - acc: 0.9375 - mDice: 0.6736 - val_loss: 4539.0851 - val_acc: 0.9338 - val_mDice: 0.5288

Epoch 00102: val_mDice did not improve from 0.55088
Epoch 103/300
 - 15s - loss: 2962.5727 - acc: 0.9376 - mDice: 0.6754 - val_loss: 4355.0311 - val_acc: 0.9368 - val_mDice: 0.5424

Epoch 00103: val_mDice did not improve from 0.55088
Epoch 104/300
 - 15s - loss: 2937.3042 - acc: 0.9378 - mDice: 0.6775 - val_loss: 4375.0262 - val_acc: 0.9347 - val_mDice: 0.5412

Epoch 00104: val_mDice did not improve from 0.55088
Epoch 105/300
 - 15s - loss: 2960.6873 - acc: 0.9376 - mDice: 0.6755 - val_loss: 4320.8759 - val_acc: 0.9344 - val_mDice: 0.5448

Epoch 00105: val_mDice did not improve from 0.55088
Epoch 106/300
 - 15s - loss: 2944.4457 - acc: 0.9377 - mDice: 0.6770 - val_loss: 4287.3248 - val_acc: 0.9349 - val_mDice: 0.5478

Epoch 00106: val_mDice did not improve from 0.55088
Epoch 107/300
 - 15s - loss: 2954.3435 - acc: 0.9377 - mDice: 0.6761 - val_loss: 4381.9174 - val_acc: 0.9361 - val_mDice: 0.5401

Epoch 00107: val_mDice did not improve from 0.55088
Epoch 108/300
 - 16s - loss: 2948.1240 - acc: 0.9378 - mDice: 0.6767 - val_loss: 4340.9322 - val_acc: 0.9352 - val_mDice: 0.5441

Epoch 00108: val_mDice did not improve from 0.55088
Epoch 109/300
 - 15s - loss: 2948.6636 - acc: 0.9378 - mDice: 0.6767 - val_loss: 4434.7587 - val_acc: 0.9373 - val_mDice: 0.5364

Epoch 00109: val_mDice did not improve from 0.55088
Epoch 110/300
 - 15s - loss: 2928.7676 - acc: 0.9380 - mDice: 0.6784 - val_loss: 4277.4587 - val_acc: 0.9371 - val_mDice: 0.5474

Epoch 00110: val_mDice did not improve from 0.55088
Epoch 111/300
 - 15s - loss: 2920.2325 - acc: 0.9381 - mDice: 0.6791 - val_loss: 4436.5659 - val_acc: 0.9321 - val_mDice: 0.5359

Epoch 00111: val_mDice did not improve from 0.55088
Epoch 112/300
 - 14s - loss: 2921.2150 - acc: 0.9379 - mDice: 0.6790 - val_loss: 4209.0003 - val_acc: 0.9340 - val_mDice: 0.5520

Epoch 00112: val_mDice improved from 0.55088 to 0.55204, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 113/300
 - 15s - loss: 2929.7746 - acc: 0.9381 - mDice: 0.6784 - val_loss: 4430.8439 - val_acc: 0.9351 - val_mDice: 0.5363

Epoch 00113: val_mDice did not improve from 0.55204
Epoch 114/300
 - 15s - loss: 2910.7413 - acc: 0.9382 - mDice: 0.6800 - val_loss: 4405.6488 - val_acc: 0.9355 - val_mDice: 0.5380

Epoch 00114: val_mDice did not improve from 0.55204
Epoch 115/300
 - 15s - loss: 2919.7755 - acc: 0.9383 - mDice: 0.6793 - val_loss: 4233.1552 - val_acc: 0.9365 - val_mDice: 0.5503

Epoch 00115: val_mDice did not improve from 0.55204
Epoch 116/300
 - 16s - loss: 2909.0132 - acc: 0.9383 - mDice: 0.6801 - val_loss: 4314.3254 - val_acc: 0.9331 - val_mDice: 0.5479

Epoch 00116: val_mDice did not improve from 0.55204
Epoch 117/300
 - 15s - loss: 2926.1820 - acc: 0.9381 - mDice: 0.6786 - val_loss: 4557.6459 - val_acc: 0.9357 - val_mDice: 0.5292

Epoch 00117: val_mDice did not improve from 0.55204
Epoch 118/300
 - 15s - loss: 2922.8509 - acc: 0.9382 - mDice: 0.6790 - val_loss: 4569.4382 - val_acc: 0.9362 - val_mDice: 0.5268

Epoch 00118: val_mDice did not improve from 0.55204
Epoch 119/300
 - 15s - loss: 2903.4723 - acc: 0.9383 - mDice: 0.6805 - val_loss: 4408.0711 - val_acc: 0.9291 - val_mDice: 0.5383

Epoch 00119: val_mDice did not improve from 0.55204
Epoch 120/300
 - 16s - loss: 2891.9565 - acc: 0.9384 - mDice: 0.6816 - val_loss: 4448.5801 - val_acc: 0.9320 - val_mDice: 0.5352

Epoch 00120: val_mDice did not improve from 0.55204
Epoch 121/300
 - 15s - loss: 2903.6797 - acc: 0.9383 - mDice: 0.6805 - val_loss: 4511.6490 - val_acc: 0.9253 - val_mDice: 0.5301

Epoch 00121: val_mDice did not improve from 0.55204
Epoch 122/300
 - 14s - loss: 2886.5654 - acc: 0.9387 - mDice: 0.6822 - val_loss: 4509.0401 - val_acc: 0.9345 - val_mDice: 0.5328

Epoch 00122: val_mDice did not improve from 0.55204
Epoch 123/300
 - 15s - loss: 2905.3524 - acc: 0.9384 - mDice: 0.6806 - val_loss: 4269.8933 - val_acc: 0.9353 - val_mDice: 0.5487

Epoch 00123: val_mDice did not improve from 0.55204
Epoch 124/300
 - 15s - loss: 2882.8016 - acc: 0.9386 - mDice: 0.6824 - val_loss: 4346.5968 - val_acc: 0.9332 - val_mDice: 0.5436

Epoch 00124: val_mDice did not improve from 0.55204
Epoch 125/300
 - 14s - loss: 2881.1256 - acc: 0.9386 - mDice: 0.6826 - val_loss: 4457.2862 - val_acc: 0.9323 - val_mDice: 0.5369

Epoch 00125: val_mDice did not improve from 0.55204
Epoch 126/300
 - 15s - loss: 2883.3745 - acc: 0.9387 - mDice: 0.6826 - val_loss: 4297.9380 - val_acc: 0.9316 - val_mDice: 0.5461

Epoch 00126: val_mDice did not improve from 0.55204
Epoch 127/300
 - 15s - loss: 2868.0126 - acc: 0.9388 - mDice: 0.6838 - val_loss: 4451.5503 - val_acc: 0.9332 - val_mDice: 0.5341

Epoch 00127: val_mDice did not improve from 0.55204
Epoch 128/300
 - 16s - loss: 2873.8014 - acc: 0.9387 - mDice: 0.6833 - val_loss: 4410.9953 - val_acc: 0.9340 - val_mDice: 0.5381

Epoch 00128: val_mDice did not improve from 0.55204
Epoch 129/300
 - 14s - loss: 2877.7367 - acc: 0.9386 - mDice: 0.6829 - val_loss: 4472.9469 - val_acc: 0.9378 - val_mDice: 0.5319

Epoch 00129: val_mDice did not improve from 0.55204
Epoch 130/300
 - 15s - loss: 2870.1692 - acc: 0.9387 - mDice: 0.6836 - val_loss: 4341.4424 - val_acc: 0.9305 - val_mDice: 0.5448

Epoch 00130: val_mDice did not improve from 0.55204
Epoch 131/300
 - 15s - loss: 2861.6271 - acc: 0.9387 - mDice: 0.6843 - val_loss: 4328.7372 - val_acc: 0.9331 - val_mDice: 0.5445

Epoch 00131: val_mDice did not improve from 0.55204
Epoch 132/300
 - 15s - loss: 2875.9980 - acc: 0.9388 - mDice: 0.6831 - val_loss: 4276.6430 - val_acc: 0.9293 - val_mDice: 0.5477

Epoch 00132: val_mDice did not improve from 0.55204
Epoch 133/300
 - 15s - loss: 2849.8451 - acc: 0.9389 - mDice: 0.6854 - val_loss: 4346.9855 - val_acc: 0.9373 - val_mDice: 0.5422

Epoch 00133: val_mDice did not improve from 0.55204
Epoch 134/300
 - 15s - loss: 2850.5050 - acc: 0.9391 - mDice: 0.6854 - val_loss: 4339.4467 - val_acc: 0.9360 - val_mDice: 0.5426

Epoch 00134: val_mDice did not improve from 0.55204
Epoch 135/300
 - 15s - loss: 2865.4561 - acc: 0.9388 - mDice: 0.6840 - val_loss: 4341.5653 - val_acc: 0.9346 - val_mDice: 0.5436

Epoch 00135: val_mDice did not improve from 0.55204
Epoch 136/300
 - 14s - loss: 2850.4768 - acc: 0.9389 - mDice: 0.6855 - val_loss: 4285.8262 - val_acc: 0.9335 - val_mDice: 0.5472

Epoch 00136: val_mDice did not improve from 0.55204
Epoch 137/300
 - 15s - loss: 2846.1976 - acc: 0.9391 - mDice: 0.6858 - val_loss: 4461.0465 - val_acc: 0.9353 - val_mDice: 0.5350

Epoch 00137: val_mDice did not improve from 0.55204
Epoch 138/300
 - 15s - loss: 2837.0506 - acc: 0.9392 - mDice: 0.6865 - val_loss: 4364.2181 - val_acc: 0.9355 - val_mDice: 0.5412

Epoch 00138: val_mDice did not improve from 0.55204
Epoch 139/300
 - 15s - loss: 2827.5452 - acc: 0.9393 - mDice: 0.6875 - val_loss: 4325.6669 - val_acc: 0.9369 - val_mDice: 0.5459

Epoch 00139: val_mDice did not improve from 0.55204
Epoch 140/300
 - 15s - loss: 2842.4863 - acc: 0.9392 - mDice: 0.6862 - val_loss: 4295.7011 - val_acc: 0.9350 - val_mDice: 0.5449

Epoch 00140: val_mDice did not improve from 0.55204
Epoch 141/300
 - 15s - loss: 2846.9388 - acc: 0.9390 - mDice: 0.6857 - val_loss: 4420.6115 - val_acc: 0.9314 - val_mDice: 0.5376

Epoch 00141: val_mDice did not improve from 0.55204
Epoch 142/300
 - 15s - loss: 2816.0836 - acc: 0.9392 - mDice: 0.6884 - val_loss: 4240.3929 - val_acc: 0.9344 - val_mDice: 0.5497

Epoch 00142: val_mDice did not improve from 0.55204
Restoring model weights from the end of the best epoch
Epoch 00142: early stopping
{'val_loss': [13447.448580228365, 11164.769334059496, 7488.108670748197, 6443.32314828726, 6113.217303936298, 5728.451979417067, 6218.260009765625, 5623.331740159255, 5514.590594951923, 5579.234703650842, 5228.716881385217, 5296.851393479567, 5256.61025766226, 5068.8397216796875, 6122.408963716947, 4734.565622182993, 4767.012033315806, 4879.353046123798, 5220.402226374699, 4693.985464242788, 4797.491896409255, 4707.479773888221, 4809.368051382212, 4736.755648099459, 4706.489661583533, 4606.580204890324, 4619.139188326322, 4836.366502028245, 4568.906461275541, 4615.032630333533, 4692.208881084735, 4585.616995004507, 4414.147930438702, 4514.974609375, 4990.056133563702, 4612.8224534254805, 5030.576904296875, 4555.365755521334, 4541.301447941707, 4723.492905836839, 4459.37388258714, 4511.433002178485, 4510.126108022837, 4364.437222994291, 4526.524864783654, 4332.507911095252, 4540.857487605168, 4473.836167555589, 4738.572462815505, 4543.849163348858, 4562.272695688101, 4634.623971792368, 4595.805419921875, 4542.443744365985, 4559.91064453125, 4483.228243314303, 4583.180776742788, 4447.05810546875, 4653.6379159780645, 4516.1761803260215, 4433.698922964243, 4465.7468026968145, 4632.705139160156, 4418.180837777944, 4472.005901630108, 4305.794842059796, 4688.2012282151445, 4416.42812875601, 4374.784137432392, 4719.40132023738, 4338.350534292368, 4415.069889948918, 4512.192514272837, 4380.4621816781855, 4363.384206918569, 4429.29541015625, 4765.177673339844, 4464.91171499399, 4671.5791015625, 4479.772399902344, 4408.4259033203125, 4279.62778883714, 4521.221989558293, 4254.649442232572, 4382.609267014724, 4394.624478853666, 4434.444575383113, 4361.423105093149, 4363.942246657151, 4517.995197002704, 4317.946692833533, 4460.477412297176, 4393.161461463342, 4636.053532527043, 4466.917269193209, 4287.200843224158, 4425.633737417368, 4288.846078725962, 4505.013657789964, 4342.8281813401445, 4342.501431978666, 4539.0851158728965, 4355.031071589543, 4375.026240422176, 4320.875924917368, 4287.324833796574, 4381.917353703426, 4340.932204026442, 4434.7586669921875, 4277.458735539363, 4436.565856933594, 4209.000328650842, 4430.843886155349, 4405.648799015926, 4233.155193622296, 4314.325378417969, 4557.6459068885215, 4569.438213641827, 4408.0711341271035, 4448.580106295072, 4511.64897273137, 4509.04008601262, 4269.893319936899, 4346.596754807692, 4457.286165677584, 4297.937950721154, 4451.550283578726, 4410.995253342849, 4472.946875939002, 4341.442425067608, 4328.73716383714, 4276.643047626202, 4346.985520582933, 4339.446650578426, 4341.56534752479, 4285.826171875, 4461.0464759239785, 4364.218078613281, 4325.666856032151, 4295.701056847205, 4420.611485407902, 4240.392920860877], 'val_acc': [0.9024292459854713, 0.9039524564376245, 0.9053809207219344, 0.9081014325985541, 0.9097448381093832, 0.9144207812272586, 0.9137227351848896, 0.9171042648645548, 0.9158376203133509, 0.9171921289884127, 0.9208394747513992, 0.920291719528345, 0.9253698105995471, 0.9263891371396872, 0.9241101329143231, 0.9233981806498307, 0.9256263902554145, 0.9264469284277695, 0.9214519972984607, 0.9230792086858016, 0.926911493906608, 0.9245423193161304, 0.9300758380156297, 0.9305473268032074, 0.9258390573354868, 0.9257049812720373, 0.9303462344866532, 0.9275956795765803, 0.9296019558723156, 0.9300804161108457, 0.9265671395338498, 0.9323710524118863, 0.9318671203576602, 0.9338988615916326, 0.929837724337211, 0.9323640786684476, 0.9305751002751864, 0.9317399882353269, 0.9333649208912482, 0.9319988855948815, 0.9343403531954839, 0.931155229990299, 0.9296366457755749, 0.933448117512923, 0.9316498499650222, 0.932798656133505, 0.9357271836354182, 0.9318763682475457, 0.9294286026404455, 0.9343426135870126, 0.9321260223021874, 0.9347655979486612, 0.9319087427396041, 0.9292714504095224, 0.9297452706557053, 0.9337208477350382, 0.9328125165059016, 0.9358543134652652, 0.9346731580220736, 0.9314996325052701, 0.9331730810495523, 0.9339704994971936, 0.9348419079413781, 0.9334782041036166, 0.9245076775550842, 0.9307692463581378, 0.9231994174993955, 0.9345437196584848, 0.9351678055066329, 0.9365176718968612, 0.934250180537884, 0.9352486958870521, 0.9275771860892956, 0.9307576876420242, 0.9305866314814641, 0.928732904104086, 0.9302722949248093, 0.9343033616359417, 0.9259615517579592, 0.934416589828638, 0.9269276811526372, 0.933889606824288, 0.9269715983134049, 0.9313170130436237, 0.9279932288023142, 0.9283561225120838, 0.9273460599092337, 0.9363928322608654, 0.9272790023913751, 0.9341901105183822, 0.9296112014697149, 0.9294263399564303, 0.9346084457177383, 0.9321491351494422, 0.9370238689275888, 0.9343935182461371, 0.9337000938562247, 0.9339404587562268, 0.9321653338579031, 0.932756999364266, 0.9348788696985978, 0.9338294863700867, 0.9368250828522903, 0.934719408933933, 0.9343888920087081, 0.9348996740121108, 0.9360900269104884, 0.9352071078924032, 0.937340511725499, 0.9370724169107584, 0.932082073046611, 0.9340352278489333, 0.9350614868677579, 0.9354682702284592, 0.9365384349456201, 0.9331245628687052, 0.9357017622544215, 0.9362448935325329, 0.9290842001254742, 0.9319988741324499, 0.9253374544473795, 0.934490598165072, 0.9353180435987619, 0.933152281321012, 0.9322600571008829, 0.9316290708688589, 0.9332054509566381, 0.9340098248078272, 0.9378281900515923, 0.9304849482499636, 0.9331476298662332, 0.9292552837958703, 0.937271196108598, 0.9360022292687342, 0.9346362077272855, 0.9335036163146679, 0.9352533244169675, 0.9355237644452316, 0.9368990109517024, 0.9349829073135669, 0.9313632754179147, 0.9343750110039344], 'val_mDice': [0.18585191724392083, 0.2322799637913704, 0.361591270336738, 0.4117930689110206, 0.4309204902786475, 0.4530293391301082, 0.4263631308881136, 0.45900077602038014, 0.4647516459226608, 0.4620586880124532, 0.48362402274058414, 0.47739556718331116, 0.47903838180578673, 0.4912573523246325, 0.4339600004828893, 0.5146145270420954, 0.5117195563820692, 0.5032850498190293, 0.482066317819632, 0.5160445811656805, 0.5095162087908158, 0.5154627808011495, 0.5073862408216183, 0.5116092774730462, 0.517098011305699, 0.5222061167542751, 0.5225555094388815, 0.5052416058113942, 0.5255205743014812, 0.5210097185694255, 0.5157761602447584, 0.5247416817224942, 0.5366790053936151, 0.5295093942147034, 0.49735801552350706, 0.5234881862998009, 0.4937664127120605, 0.5245960521010252, 0.527164847518389, 0.515308796786345, 0.5354653273064357, 0.5318766110218488, 0.5321340810220975, 0.5424097145979221, 0.5298579203394743, 0.5416892921695342, 0.528623582651982, 0.5346936067709556, 0.5169994504405901, 0.5299293914666543, 0.527751425997569, 0.5238388455831088, 0.5263200820638583, 0.5286406977818563, 0.526983900138965, 0.5339625517909343, 0.5257386215604268, 0.5368985533714294, 0.51868597475382, 0.5310071190962424, 0.5366445178022752, 0.5354032516479492, 0.5219447125609105, 0.5374973129767638, 0.5338703921208015, 0.5483127442690042, 0.5194109747043023, 0.5377637411539371, 0.5408847544055718, 0.5177248355287772, 0.5437710382617437, 0.5384625058907729, 0.5327423810958862, 0.5416029095649719, 0.5400969689855208, 0.5366765461288966, 0.5131188682638682, 0.5360779126103108, 0.520773609670309, 0.5329439960993253, 0.538127104823406, 0.5494379091721314, 0.530595057285749, 0.5508836037837542, 0.540384557384711, 0.538013396354822, 0.5365743046769729, 0.541289131801862, 0.5419541969895363, 0.5296123194006773, 0.5460455280083877, 0.5347771707635659, 0.5390699356794357, 0.5240474377687161, 0.5327941826902903, 0.547924888248627, 0.537441971210333, 0.5460309566786656, 0.5329277681616637, 0.543806598163568, 0.5437610023296796, 0.5287828327944646, 0.5423653922401942, 0.5411599490504998, 0.5448033809661865, 0.5477863412636977, 0.5400605499744415, 0.5441434131218836, 0.5364057805675727, 0.5474478682646384, 0.5359303062924972, 0.5520357363499128, 0.5362566743905728, 0.5380159335640761, 0.5502807185626947, 0.5479459808422968, 0.5291996770180188, 0.5267612722057563, 0.5382919042156293, 0.535176855726884, 0.5300754079451928, 0.5328489049122884, 0.548720257786604, 0.5436350451065943, 0.5368645208386275, 0.5461375323625711, 0.5340673447801516, 0.5380568647613893, 0.5319154615012499, 0.5448027316194314, 0.5445292798372415, 0.5476582096173213, 0.542200640990184, 0.5425515541663537, 0.543622666826615, 0.5472382484720304, 0.5350030597585899, 0.541234034471787, 0.5459062829613686, 0.5448638750956609, 0.5375800619904811, 0.5497183123460183], 'loss': [24317.73125613335, 11841.929018032768, 8551.436625074573, 7384.175086699981, 6714.346023054369, 6273.122408457285, 5880.933755121932, 5643.576486558148, 5388.814586059267, 5225.509553772271, 5043.63625062054, 4871.166307589538, 4720.840315155533, 4600.975775859678, 4464.754094551028, 4392.634504755012, 4317.929295249347, 4212.22311628497, 4165.782870789334, 4118.582974556418, 4090.556430202035, 4015.0398196218903, 3956.442068703509, 3922.3272451098023, 3909.3280751383923, 3872.6092914657643, 3825.16147986235, 3791.408249913178, 3774.2564395326513, 3740.2449999581204, 3704.1398922854173, 3671.297342408949, 3632.29814747859, 3606.597286402734, 3584.958623230155, 3579.857420501526, 3550.651291792786, 3538.4956944068176, 3510.407540153624, 3524.1251450365985, 3488.948438616792, 3463.5817807373564, 3440.752218036604, 3446.303702741688, 3410.1666403079753, 3406.178410225509, 3394.415849671069, 3371.195525647397, 3379.054160356192, 3334.086647169491, 3336.519832569922, 3337.6313828824796, 3327.736499696665, 3293.599012285342, 3289.1906821928064, 3288.0145555478803, 3269.6558315632783, 3252.7412482914883, 3241.031919793714, 3244.0687901504716, 3243.062227162776, 3212.7385487959723, 3198.562965292448, 3181.033080660658, 3187.292618131369, 3181.1525578880996, 3162.3075839089015, 3163.148582716726, 3158.8017945360416, 3167.2743892724206, 3143.932331471143, 3114.337458239637, 3119.6643806506067, 3129.282273001681, 3122.817459468108, 3113.2581853193738, 3096.8279853447175, 3087.0196847188276, 3084.3706227610123, 3080.7580441667797, 3072.7120436306295, 3062.210354854334, 3058.138470717355, 3080.587614736862, 3049.198542696847, 3055.3873210971365, 3035.445500823544, 3033.543383764295, 3035.8667688606342, 3013.7016537391996, 3015.0355701384965, 3016.235849244166, 3011.5117989743885, 3004.48994225285, 3001.169320484792, 3002.443666019948, 2981.8932792609394, 2985.5494378798894, 3010.00612296942, 2984.3488450817745, 2976.4373618532873, 2983.6050871944312, 2962.572712240454, 2937.3042122442366, 2960.6872734556027, 2944.445746123741, 2954.3434571911134, 2948.1240056161123, 2948.6635891355777, 2928.7676456391255, 2920.2325465909385, 2921.2149885389226, 2929.7746308237097, 2910.7413422281006, 2919.775465839586, 2909.0132282992017, 2926.181965597945, 2922.850937659413, 2903.4723323353055, 2891.9564665833336, 2903.679718470712, 2886.5653894852417, 2905.35243277588, 2882.8016289311076, 2881.1256323384036, 2883.3745329287904, 2868.012622180641, 2873.8013718888337, 2877.7367468656876, 2870.1691668245785, 2861.627147392759, 2875.998046661098, 2849.845069525702, 2850.5050077761143, 2865.4561451904274, 2850.4767808711013, 2846.197557285572, 2837.0505617418426, 2827.5451695506317, 2842.4862895889232, 2846.9387865735853, 2816.0835582828495], 'acc': [0.716110714140671, 0.8763161860883956, 0.8801183091542009, 0.8816732184139112, 0.8836261561399983, 0.8872607676105329, 0.8949211278459105, 0.9020281609910161, 0.9055595080109086, 0.9086489022674128, 0.911275597732577, 0.9136173042173173, 0.9156847472924385, 0.9175235134181222, 0.9192162243453359, 0.9204043608018309, 0.9216253483997965, 0.9227269551558962, 0.9234795895799613, 0.9239975187343765, 0.9244428141403163, 0.9253261581202071, 0.9259260891108982, 0.9265034100638427, 0.9266723861369349, 0.9268723748645626, 0.9274636370597219, 0.9277122023085173, 0.9279382447744333, 0.9282861534524292, 0.928470003861052, 0.9289364493015254, 0.9294000386883937, 0.929675962122826, 0.929852495188644, 0.9299339243464834, 0.9301702548005666, 0.9303210308430193, 0.9306834141156841, 0.930664057811006, 0.930898635427879, 0.9312353694855612, 0.9314386643552477, 0.9313436423260095, 0.9316704232325734, 0.9317061825672837, 0.931900498447719, 0.9322946272872201, 0.9320414964754533, 0.9323959247680934, 0.9323890272359242, 0.9324790590211582, 0.9325361914556867, 0.9331357431106106, 0.9330679075827647, 0.9332325822102301, 0.9333238301380066, 0.9336391282424621, 0.933661380036669, 0.9337160949127421, 0.9337578434890501, 0.9340382000347417, 0.9342910204548946, 0.9344422195952261, 0.934303328168136, 0.9344451640855669, 0.9346262031756764, 0.9347822115252645, 0.9349269331254654, 0.9345526665182535, 0.9349587468283869, 0.9353401518600251, 0.9352796246433108, 0.9351955184052156, 0.9354253276175243, 0.9354989080700412, 0.9356738074309797, 0.9356474661523649, 0.9357527066374314, 0.9357828342594652, 0.9359652901898557, 0.9360604860471929, 0.9359925154675244, 0.9358664785629377, 0.9363246373196628, 0.9362107278356734, 0.9365005949145367, 0.9364682508000894, 0.9367527971130933, 0.9369243673487562, 0.9368544025064054, 0.936825957864916, 0.9368984260143944, 0.9370251953530375, 0.9369108647391177, 0.9370922560974603, 0.937381504674377, 0.9372562656738568, 0.9370123359821252, 0.9373047741358982, 0.9374263071765387, 0.9374800041836038, 0.9376224186668248, 0.9377551488547399, 0.9375964392708048, 0.9377386327611337, 0.9377184582792238, 0.9377748575540835, 0.9378373784507914, 0.9380169470932699, 0.9380572750473181, 0.9379375819503343, 0.938120858300758, 0.9381649338494343, 0.9382509919403774, 0.9382995899275727, 0.9381149394215555, 0.9381916672060061, 0.9383138422100546, 0.938400549910819, 0.9383355950909018, 0.9386848046376588, 0.9383918389143412, 0.9386125547600267, 0.938622822590467, 0.9386591585175221, 0.9387924855544559, 0.9386737006820789, 0.9386151308097777, 0.9387078858450925, 0.9386684007885645, 0.9388045891562831, 0.9389093176834612, 0.9391481544240796, 0.9387602926641881, 0.9389455014573332, 0.9390892254616913, 0.9392252335972334, 0.9393043334574472, 0.9391776819043545, 0.9390256422302395, 0.9391907625759944], 'mDice': [0.07139031129339399, 0.23403176090588246, 0.3314635688986141, 0.3824062960884244, 0.41644860791575145, 0.4405147901520698, 0.46282608861370433, 0.4773027499031231, 0.4927752461642739, 0.5031356990068016, 0.5146654378133189, 0.526094982305884, 0.5361569482418462, 0.5447288987261226, 0.5542708366358949, 0.5593694479804323, 0.56511382902503, 0.5728584479595213, 0.5764315570180271, 0.5798341432071135, 0.5823234697554941, 0.5880602079377583, 0.5923841186503385, 0.5951227956533673, 0.5962749106147617, 0.5991339246681187, 0.6029813264575731, 0.6053795633770757, 0.6069794353673151, 0.6096362147693604, 0.6125937194981654, 0.6151319313102088, 0.6181194949147887, 0.6203677264634593, 0.6221319966504003, 0.6227753322073688, 0.625028862687568, 0.6260802254381737, 0.6283869767149447, 0.6273064293083445, 0.6300940222046664, 0.6322252671403945, 0.6341647316386402, 0.6337354908864195, 0.6366920264996605, 0.6368956713947788, 0.6380477607068811, 0.6400557692987853, 0.6394647936160017, 0.6431512240168245, 0.6428940515835698, 0.6429597929781086, 0.64360911821644, 0.646619786341494, 0.6469236984910818, 0.6471033962485557, 0.6486939206770246, 0.6500903116450653, 0.6510979341402997, 0.6509847956852401, 0.650967531012706, 0.6537075877123671, 0.6547254162235783, 0.6563934855253112, 0.655786517591458, 0.6563162423528055, 0.6577615079421966, 0.6578288076768928, 0.6582333907467143, 0.6574806907756802, 0.6596387839235965, 0.6621488139471708, 0.6616372796130953, 0.6607427223135732, 0.6614715477081833, 0.662240757082899, 0.6636770588934097, 0.6644222174119127, 0.664734752786387, 0.6650696419530564, 0.6656752205704187, 0.6666230856135444, 0.6670769791832646, 0.665172043562837, 0.6677104599260596, 0.6672312555899756, 0.6690533146266292, 0.6689845578736247, 0.6690031990984715, 0.6709365445584881, 0.6706922902927225, 0.670730988158958, 0.6710386478756887, 0.6717464644497945, 0.6719976526822572, 0.6718234646961301, 0.6737777056876973, 0.673357598056853, 0.6713562828692126, 0.6734512868616224, 0.674244703170636, 0.6736384529167245, 0.6754468140716011, 0.6775126616629158, 0.6755211306906798, 0.6770266879146899, 0.6761218178737298, 0.6766529839757645, 0.676706496666336, 0.6783885088154259, 0.679101487174857, 0.6790485258835945, 0.6783746695711991, 0.6799678354039905, 0.6792952199599229, 0.6801283049163459, 0.6785937280636437, 0.6789680834923857, 0.6805272723908773, 0.6816419623472655, 0.6805440321802423, 0.6821571558337364, 0.6806183882462388, 0.6824381857200664, 0.6825767540243469, 0.6825913050886473, 0.6837730416730026, 0.6832730950909458, 0.682934988735677, 0.6835927731610637, 0.6843153634414807, 0.6831347445197995, 0.6854210401564235, 0.6854276369992937, 0.6840288599049991, 0.6854695899563721, 0.6858290085259986, 0.686537316746348, 0.6874866435957232, 0.6861607787695514, 0.685711195468243, 0.6884423962468801]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.12s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.92s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.74s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:31,  1.80s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:51,  1.67s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:44,  1.65s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:27,  1.59s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:38,  1.64s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:16,  1.56s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:35,  1.64s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:29,  1.62s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:51,  1.71s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:00,  1.75s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<07:39,  1.68s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:05,  1.78s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:49,  1.73s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<07:54,  1.75s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<08:02,  1.79s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<08:07,  1.81s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<07:45,  1.74s/it]predicting train subjects:   6%|▋         | 18/285 [00:30<07:43,  1.73s/it]predicting train subjects:   7%|▋         | 19/285 [00:32<07:30,  1.69s/it]predicting train subjects:   7%|▋         | 20/285 [00:33<07:39,  1.73s/it]predicting train subjects:   7%|▋         | 21/285 [00:35<07:51,  1.79s/it]predicting train subjects:   8%|▊         | 22/285 [00:37<07:34,  1.73s/it]predicting train subjects:   8%|▊         | 23/285 [00:39<07:38,  1.75s/it]predicting train subjects:   8%|▊         | 24/285 [00:40<07:19,  1.68s/it]predicting train subjects:   9%|▉         | 25/285 [00:42<07:29,  1.73s/it]predicting train subjects:   9%|▉         | 26/285 [00:44<07:35,  1.76s/it]predicting train subjects:   9%|▉         | 27/285 [00:45<07:15,  1.69s/it]predicting train subjects:  10%|▉         | 28/285 [00:47<07:15,  1.69s/it]predicting train subjects:  10%|█         | 29/285 [00:49<07:20,  1.72s/it]predicting train subjects:  11%|█         | 30/285 [00:51<07:31,  1.77s/it]predicting train subjects:  11%|█         | 31/285 [00:53<07:38,  1.81s/it]predicting train subjects:  11%|█         | 32/285 [00:54<07:14,  1.72s/it]predicting train subjects:  12%|█▏        | 33/285 [00:56<07:12,  1.72s/it]predicting train subjects:  12%|█▏        | 34/285 [00:58<07:10,  1.71s/it]predicting train subjects:  12%|█▏        | 35/285 [00:59<07:15,  1.74s/it]predicting train subjects:  13%|█▎        | 36/285 [01:01<06:59,  1.68s/it]predicting train subjects:  13%|█▎        | 37/285 [01:03<07:01,  1.70s/it]predicting train subjects:  13%|█▎        | 38/285 [01:05<07:12,  1.75s/it]predicting train subjects:  14%|█▎        | 39/285 [01:06<06:54,  1.68s/it]predicting train subjects:  14%|█▍        | 40/285 [01:08<06:57,  1.70s/it]predicting train subjects:  14%|█▍        | 41/285 [01:09<06:47,  1.67s/it]predicting train subjects:  15%|█▍        | 42/285 [01:11<06:36,  1.63s/it]predicting train subjects:  15%|█▌        | 43/285 [01:13<06:43,  1.67s/it]predicting train subjects:  15%|█▌        | 44/285 [01:15<06:53,  1.71s/it]predicting train subjects:  16%|█▌        | 45/285 [01:16<06:38,  1.66s/it]predicting train subjects:  16%|█▌        | 46/285 [01:18<06:47,  1.70s/it]predicting train subjects:  16%|█▋        | 47/285 [01:20<06:41,  1.69s/it]predicting train subjects:  17%|█▋        | 48/285 [01:21<06:45,  1.71s/it]predicting train subjects:  17%|█▋        | 49/285 [01:23<07:12,  1.83s/it]predicting train subjects:  18%|█▊        | 50/285 [01:25<07:01,  1.79s/it]predicting train subjects:  18%|█▊        | 51/285 [01:27<07:05,  1.82s/it]predicting train subjects:  18%|█▊        | 52/285 [01:29<06:43,  1.73s/it]predicting train subjects:  19%|█▊        | 53/285 [01:30<06:41,  1.73s/it]predicting train subjects:  19%|█▉        | 54/285 [01:32<06:51,  1.78s/it]predicting train subjects:  19%|█▉        | 55/285 [01:34<06:34,  1.71s/it]predicting train subjects:  20%|█▉        | 56/285 [01:35<06:34,  1.72s/it]predicting train subjects:  20%|██        | 57/285 [01:37<06:23,  1.68s/it]predicting train subjects:  20%|██        | 58/285 [01:39<06:25,  1.70s/it]predicting train subjects:  21%|██        | 59/285 [01:41<06:33,  1.74s/it]predicting train subjects:  21%|██        | 60/285 [01:43<06:47,  1.81s/it]predicting train subjects:  21%|██▏       | 61/285 [01:44<06:28,  1.73s/it]predicting train subjects:  22%|██▏       | 62/285 [01:46<06:32,  1.76s/it]predicting train subjects:  22%|██▏       | 63/285 [01:48<06:32,  1.77s/it]predicting train subjects:  22%|██▏       | 64/285 [01:49<06:17,  1.71s/it]predicting train subjects:  23%|██▎       | 65/285 [01:51<06:15,  1.71s/it]predicting train subjects:  23%|██▎       | 66/285 [01:53<06:18,  1.73s/it]predicting train subjects:  24%|██▎       | 67/285 [01:55<06:18,  1.73s/it]predicting train subjects:  24%|██▍       | 68/285 [01:56<06:01,  1.66s/it]predicting train subjects:  24%|██▍       | 69/285 [01:58<06:10,  1.72s/it]predicting train subjects:  25%|██▍       | 70/285 [02:00<06:07,  1.71s/it]predicting train subjects:  25%|██▍       | 71/285 [02:01<06:11,  1.73s/it]predicting train subjects:  25%|██▌       | 72/285 [02:03<06:00,  1.69s/it]predicting train subjects:  26%|██▌       | 73/285 [02:05<05:58,  1.69s/it]predicting train subjects:  26%|██▌       | 74/285 [02:06<05:57,  1.70s/it]predicting train subjects:  26%|██▋       | 75/285 [02:08<05:53,  1.68s/it]predicting train subjects:  27%|██▋       | 76/285 [02:10<05:54,  1.70s/it]predicting train subjects:  27%|██▋       | 77/285 [02:11<05:48,  1.67s/it]predicting train subjects:  27%|██▋       | 78/285 [02:13<05:39,  1.64s/it]predicting train subjects:  28%|██▊       | 79/285 [02:15<05:43,  1.67s/it]predicting train subjects:  28%|██▊       | 80/285 [02:16<05:44,  1.68s/it]predicting train subjects:  28%|██▊       | 81/285 [02:18<05:39,  1.66s/it]predicting train subjects:  29%|██▉       | 82/285 [02:20<05:42,  1.69s/it]predicting train subjects:  29%|██▉       | 83/285 [02:21<05:36,  1.67s/it]predicting train subjects:  29%|██▉       | 84/285 [02:23<05:28,  1.64s/it]predicting train subjects:  30%|██▉       | 85/285 [02:25<05:35,  1.68s/it]predicting train subjects:  30%|███       | 86/285 [02:27<05:39,  1.71s/it]predicting train subjects:  31%|███       | 87/285 [02:28<05:47,  1.76s/it]predicting train subjects:  31%|███       | 88/285 [02:30<05:34,  1.70s/it]predicting train subjects:  31%|███       | 89/285 [02:32<05:36,  1.72s/it]predicting train subjects:  32%|███▏      | 90/285 [02:33<05:35,  1.72s/it]predicting train subjects:  32%|███▏      | 91/285 [02:35<05:22,  1.66s/it]predicting train subjects:  32%|███▏      | 92/285 [02:37<05:21,  1.66s/it]predicting train subjects:  33%|███▎      | 93/285 [02:38<05:11,  1.62s/it]predicting train subjects:  33%|███▎      | 94/285 [02:40<05:22,  1.69s/it]predicting train subjects:  33%|███▎      | 95/285 [02:42<05:20,  1.69s/it]predicting train subjects:  34%|███▎      | 96/285 [02:43<05:18,  1.68s/it]predicting train subjects:  34%|███▍      | 97/285 [02:45<05:18,  1.69s/it]predicting train subjects:  34%|███▍      | 98/285 [02:47<05:13,  1.68s/it]predicting train subjects:  35%|███▍      | 99/285 [02:48<05:13,  1.68s/it]predicting train subjects:  35%|███▌      | 100/285 [02:50<05:13,  1.70s/it]predicting train subjects:  35%|███▌      | 101/285 [02:52<05:01,  1.64s/it]predicting train subjects:  36%|███▌      | 102/285 [02:53<05:04,  1.66s/it]predicting train subjects:  36%|███▌      | 103/285 [02:55<04:55,  1.62s/it]predicting train subjects:  36%|███▋      | 104/285 [02:57<05:02,  1.67s/it]predicting train subjects:  37%|███▋      | 105/285 [02:58<05:02,  1.68s/it]predicting train subjects:  37%|███▋      | 106/285 [03:00<04:52,  1.63s/it]predicting train subjects:  38%|███▊      | 107/285 [03:02<04:51,  1.64s/it]predicting train subjects:  38%|███▊      | 108/285 [03:03<04:46,  1.62s/it]predicting train subjects:  38%|███▊      | 109/285 [03:05<04:47,  1.63s/it]predicting train subjects:  39%|███▊      | 110/285 [03:07<04:52,  1.67s/it]predicting train subjects:  39%|███▉      | 111/285 [03:08<04:45,  1.64s/it]predicting train subjects:  39%|███▉      | 112/285 [03:10<04:52,  1.69s/it]predicting train subjects:  40%|███▉      | 113/285 [03:12<04:55,  1.72s/it]predicting train subjects:  40%|████      | 114/285 [03:13<04:54,  1.72s/it]predicting train subjects:  40%|████      | 115/285 [03:15<04:48,  1.70s/it]predicting train subjects:  41%|████      | 116/285 [03:17<04:48,  1.71s/it]predicting train subjects:  41%|████      | 117/285 [03:18<04:38,  1.66s/it]predicting train subjects:  41%|████▏     | 118/285 [03:20<04:32,  1.63s/it]predicting train subjects:  42%|████▏     | 119/285 [03:22<04:35,  1.66s/it]predicting train subjects:  42%|████▏     | 120/285 [03:23<04:26,  1.61s/it]predicting train subjects:  42%|████▏     | 121/285 [03:25<04:19,  1.58s/it]predicting train subjects:  43%|████▎     | 122/285 [03:26<04:13,  1.56s/it]predicting train subjects:  43%|████▎     | 123/285 [03:28<04:04,  1.51s/it]predicting train subjects:  44%|████▎     | 124/285 [03:29<04:06,  1.53s/it]predicting train subjects:  44%|████▍     | 125/285 [03:31<03:58,  1.49s/it]predicting train subjects:  44%|████▍     | 126/285 [03:32<03:54,  1.48s/it]predicting train subjects:  45%|████▍     | 127/285 [03:33<03:47,  1.44s/it]predicting train subjects:  45%|████▍     | 128/285 [03:35<03:52,  1.48s/it]predicting train subjects:  45%|████▌     | 129/285 [03:36<03:46,  1.45s/it]predicting train subjects:  46%|████▌     | 130/285 [03:38<03:40,  1.42s/it]predicting train subjects:  46%|████▌     | 131/285 [03:39<03:34,  1.40s/it]predicting train subjects:  46%|████▋     | 132/285 [03:41<03:40,  1.44s/it]predicting train subjects:  47%|████▋     | 133/285 [03:42<03:40,  1.45s/it]predicting train subjects:  47%|████▋     | 134/285 [03:43<03:39,  1.45s/it]predicting train subjects:  47%|████▋     | 135/285 [03:45<03:33,  1.43s/it]predicting train subjects:  48%|████▊     | 136/285 [03:46<03:32,  1.42s/it]predicting train subjects:  48%|████▊     | 137/285 [03:48<03:37,  1.47s/it]predicting train subjects:  48%|████▊     | 138/285 [03:49<03:29,  1.43s/it]predicting train subjects:  49%|████▉     | 139/285 [03:51<03:32,  1.45s/it]predicting train subjects:  49%|████▉     | 140/285 [03:52<03:35,  1.49s/it]predicting train subjects:  49%|████▉     | 141/285 [03:54<03:28,  1.44s/it]predicting train subjects:  50%|████▉     | 142/285 [03:55<03:26,  1.44s/it]predicting train subjects:  50%|█████     | 143/285 [03:56<03:22,  1.43s/it]predicting train subjects:  51%|█████     | 144/285 [03:58<03:25,  1.46s/it]predicting train subjects:  51%|█████     | 145/285 [03:59<03:23,  1.45s/it]predicting train subjects:  51%|█████     | 146/285 [04:01<03:25,  1.48s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:02<03:18,  1.44s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:04<03:19,  1.46s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:05<03:16,  1.45s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:07<03:11,  1.42s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:08<03:17,  1.47s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:09<03:12,  1.45s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:11<03:11,  1.45s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:13<03:14,  1.48s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:14<03:08,  1.45s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:15<03:13,  1.50s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:17<03:05,  1.45s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:18<03:01,  1.43s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:20<02:56,  1.40s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:21<02:54,  1.40s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:22<02:57,  1.43s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:24<02:54,  1.42s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:25<02:59,  1.47s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:27<02:56,  1.46s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:28<02:53,  1.45s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:30<02:54,  1.47s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:31<02:53,  1.47s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:33<02:46,  1.42s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:34<02:45,  1.42s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:35<02:43,  1.42s/it]predicting train subjects:  60%|██████    | 171/285 [04:37<02:41,  1.42s/it]predicting train subjects:  60%|██████    | 172/285 [04:38<02:39,  1.41s/it]predicting train subjects:  61%|██████    | 173/285 [04:40<02:37,  1.40s/it]predicting train subjects:  61%|██████    | 174/285 [04:41<02:34,  1.39s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:43<02:39,  1.45s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:44<02:41,  1.49s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:46<02:37,  1.46s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:47<02:33,  1.43s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:48<02:28,  1.40s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:50<02:36,  1.49s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:51<02:37,  1.51s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:53<02:38,  1.54s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:54<02:30,  1.47s/it]predicting train subjects:  65%|██████▍   | 184/285 [04:56<02:25,  1.44s/it]predicting train subjects:  65%|██████▍   | 185/285 [04:57<02:18,  1.39s/it]predicting train subjects:  65%|██████▌   | 186/285 [04:59<02:26,  1.48s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:00<02:31,  1.55s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:02<02:34,  1.60s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:03<02:25,  1.52s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:05<02:20,  1.48s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:06<02:23,  1.52s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:08<02:24,  1.55s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:09<02:17,  1.50s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:11<02:15,  1.49s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:12<02:09,  1.44s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:14<02:18,  1.55s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:16<02:20,  1.60s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:18<02:22,  1.63s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:19<02:14,  1.56s/it]predicting train subjects:  70%|███████   | 200/285 [05:20<02:12,  1.56s/it]predicting train subjects:  71%|███████   | 201/285 [05:22<02:17,  1.63s/it]predicting train subjects:  71%|███████   | 202/285 [05:24<02:16,  1.64s/it]predicting train subjects:  71%|███████   | 203/285 [05:26<02:15,  1.66s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:27<02:08,  1.58s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:29<02:05,  1.56s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:30<02:00,  1.52s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:32<02:06,  1.62s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:34<02:07,  1.65s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:35<02:07,  1.68s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:37<01:59,  1.59s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:38<01:55,  1.57s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:40<01:56,  1.60s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:41<01:54,  1.60s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:43<01:50,  1.55s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:45<01:54,  1.63s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:46<01:46,  1.54s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:48<01:50,  1.62s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:50<01:52,  1.67s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:52<01:54,  1.73s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:53<01:45,  1.63s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:54<01:41,  1.59s/it]predicting train subjects:  78%|███████▊  | 222/285 [05:56<01:42,  1.63s/it]predicting train subjects:  78%|███████▊  | 223/285 [05:58<01:36,  1.56s/it]predicting train subjects:  79%|███████▊  | 224/285 [05:59<01:34,  1.54s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:00<01:30,  1.50s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:02<01:34,  1.61s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:04<01:36,  1.67s/it]predicting train subjects:  80%|████████  | 228/285 [06:06<01:38,  1.72s/it]predicting train subjects:  80%|████████  | 229/285 [06:08<01:35,  1.70s/it]predicting train subjects:  81%|████████  | 230/285 [06:09<01:27,  1.59s/it]predicting train subjects:  81%|████████  | 231/285 [06:10<01:23,  1.54s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:12<01:24,  1.58s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:13<01:19,  1.53s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:15<01:23,  1.64s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:17<01:18,  1.57s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:19<01:20,  1.63s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:20<01:20,  1.67s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:22<01:19,  1.70s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:24<01:17,  1.69s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:25<01:11,  1.59s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:27<01:07,  1.54s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:28<01:04,  1.51s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:29<01:02,  1.48s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:31<01:03,  1.56s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:32<00:59,  1.49s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:34<01:02,  1.61s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:36<01:02,  1.64s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:38<01:00,  1.64s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:39<00:55,  1.55s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:41<00:53,  1.53s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:42<00:50,  1.49s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:43<00:47,  1.44s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:45<00:49,  1.56s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:47<00:50,  1.62s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:49<00:48,  1.63s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:50<00:44,  1.54s/it]predicting train subjects:  90%|█████████ | 257/285 [06:51<00:42,  1.51s/it]predicting train subjects:  91%|█████████ | 258/285 [06:53<00:42,  1.58s/it]predicting train subjects:  91%|█████████ | 259/285 [06:55<00:41,  1.60s/it]predicting train subjects:  91%|█████████ | 260/285 [06:56<00:38,  1.53s/it]predicting train subjects:  92%|█████████▏| 261/285 [06:57<00:36,  1.50s/it]predicting train subjects:  92%|█████████▏| 262/285 [06:59<00:33,  1.47s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:00<00:31,  1.44s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:02<00:32,  1.57s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:04<00:32,  1.65s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:05<00:29,  1.57s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:07<00:27,  1.55s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:09<00:27,  1.65s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:10<00:26,  1.64s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:12<00:23,  1.56s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:13<00:21,  1.54s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:15<00:20,  1.59s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:16<00:18,  1.52s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:18<00:16,  1.48s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:19<00:15,  1.58s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:21<00:14,  1.66s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:23<00:12,  1.58s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:24<00:10,  1.52s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:26<00:09,  1.57s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:27<00:07,  1.50s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:29<00:05,  1.49s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:30<00:04,  1.48s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:32<00:03,  1.59s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:34<00:01,  1.67s/it]predicting train subjects: 100%|██████████| 285/285 [07:36<00:00,  1.71s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:57,  1.89s/it]Loading train:   1%|          | 2/285 [00:03<08:17,  1.76s/it]Loading train:   1%|          | 3/285 [00:04<08:03,  1.72s/it]Loading train:   1%|▏         | 4/285 [00:06<07:57,  1.70s/it]Loading train:   2%|▏         | 5/285 [00:08<07:56,  1.70s/it]Loading train:   2%|▏         | 6/285 [00:09<07:43,  1.66s/it]Loading train:   2%|▏         | 7/285 [00:11<07:46,  1.68s/it]Loading train:   3%|▎         | 8/285 [00:13<07:37,  1.65s/it]Loading train:   3%|▎         | 9/285 [00:15<07:53,  1.71s/it]Loading train:   4%|▎         | 10/285 [00:16<07:24,  1.62s/it]Loading train:   4%|▍         | 11/285 [00:17<06:42,  1.47s/it]Loading train:   4%|▍         | 12/285 [00:19<06:56,  1.53s/it]Loading train:   5%|▍         | 13/285 [00:20<06:22,  1.41s/it]Loading train:   5%|▍         | 14/285 [00:22<06:45,  1.50s/it]Loading train:   5%|▌         | 15/285 [00:23<06:25,  1.43s/it]Loading train:   6%|▌         | 16/285 [00:24<06:16,  1.40s/it]Loading train:   6%|▌         | 17/285 [00:25<05:52,  1.32s/it]Loading train:   6%|▋         | 18/285 [00:27<05:46,  1.30s/it]Loading train:   7%|▋         | 19/285 [00:28<05:29,  1.24s/it]Loading train:   7%|▋         | 20/285 [00:29<05:37,  1.27s/it]Loading train:   7%|▋         | 21/285 [00:30<05:43,  1.30s/it]Loading train:   8%|▊         | 22/285 [00:32<05:37,  1.28s/it]Loading train:   8%|▊         | 23/285 [00:33<05:48,  1.33s/it]Loading train:   8%|▊         | 24/285 [00:34<05:24,  1.24s/it]Loading train:   9%|▉         | 25/285 [00:36<05:39,  1.31s/it]Loading train:   9%|▉         | 26/285 [00:37<05:52,  1.36s/it]Loading train:   9%|▉         | 27/285 [00:38<05:49,  1.36s/it]Loading train:  10%|▉         | 28/285 [00:40<05:43,  1.34s/it]Loading train:  10%|█         | 29/285 [00:41<06:15,  1.47s/it]Loading train:  11%|█         | 30/285 [00:43<06:03,  1.43s/it]Loading train:  11%|█         | 31/285 [00:44<05:48,  1.37s/it]Loading train:  11%|█         | 32/285 [00:45<05:18,  1.26s/it]Loading train:  12%|█▏        | 33/285 [00:46<05:10,  1.23s/it]Loading train:  12%|█▏        | 34/285 [00:47<05:00,  1.20s/it]Loading train:  12%|█▏        | 35/285 [00:49<05:16,  1.27s/it]Loading train:  13%|█▎        | 36/285 [00:50<05:12,  1.26s/it]Loading train:  13%|█▎        | 37/285 [00:51<05:28,  1.32s/it]Loading train:  13%|█▎        | 38/285 [00:53<05:18,  1.29s/it]Loading train:  14%|█▎        | 39/285 [00:54<05:21,  1.31s/it]Loading train:  14%|█▍        | 40/285 [00:55<05:19,  1.30s/it]Loading train:  14%|█▍        | 41/285 [00:56<04:54,  1.21s/it]Loading train:  15%|█▍        | 42/285 [00:57<04:51,  1.20s/it]Loading train:  15%|█▌        | 43/285 [00:59<04:53,  1.21s/it]Loading train:  15%|█▌        | 44/285 [01:00<05:06,  1.27s/it]Loading train:  16%|█▌        | 45/285 [01:01<04:55,  1.23s/it]Loading train:  16%|█▌        | 46/285 [01:03<05:01,  1.26s/it]Loading train:  16%|█▋        | 47/285 [01:04<04:45,  1.20s/it]Loading train:  17%|█▋        | 48/285 [01:05<04:56,  1.25s/it]Loading train:  17%|█▋        | 49/285 [01:06<05:03,  1.29s/it]Loading train:  18%|█▊        | 50/285 [01:08<05:06,  1.30s/it]Loading train:  18%|█▊        | 51/285 [01:09<05:09,  1.32s/it]Loading train:  18%|█▊        | 52/285 [01:10<05:02,  1.30s/it]Loading train:  19%|█▊        | 53/285 [01:11<04:50,  1.25s/it]Loading train:  19%|█▉        | 54/285 [01:13<04:47,  1.24s/it]Loading train:  19%|█▉        | 55/285 [01:14<04:37,  1.21s/it]Loading train:  20%|█▉        | 56/285 [01:15<04:46,  1.25s/it]Loading train:  20%|██        | 57/285 [01:16<04:37,  1.22s/it]Loading train:  20%|██        | 58/285 [01:18<05:35,  1.48s/it]Loading train:  21%|██        | 59/285 [01:20<05:47,  1.54s/it]Loading train:  21%|██        | 60/285 [01:21<05:33,  1.48s/it]Loading train:  21%|██▏       | 61/285 [01:23<05:11,  1.39s/it]Loading train:  22%|██▏       | 62/285 [01:24<04:54,  1.32s/it]Loading train:  22%|██▏       | 63/285 [01:25<04:41,  1.27s/it]Loading train:  22%|██▏       | 64/285 [01:26<04:56,  1.34s/it]Loading train:  23%|██▎       | 65/285 [01:28<05:19,  1.45s/it]Loading train:  23%|██▎       | 66/285 [01:30<05:40,  1.55s/it]Loading train:  24%|██▎       | 67/285 [01:31<05:24,  1.49s/it]Loading train:  24%|██▍       | 68/285 [01:32<05:05,  1.41s/it]Loading train:  24%|██▍       | 69/285 [01:34<04:51,  1.35s/it]Loading train:  25%|██▍       | 70/285 [01:35<05:10,  1.44s/it]Loading train:  25%|██▍       | 71/285 [01:37<05:17,  1.48s/it]Loading train:  25%|██▌       | 72/285 [01:38<04:59,  1.40s/it]Loading train:  26%|██▌       | 73/285 [01:40<05:07,  1.45s/it]Loading train:  26%|██▌       | 74/285 [01:41<04:52,  1.38s/it]Loading train:  26%|██▋       | 75/285 [01:42<04:50,  1.38s/it]Loading train:  27%|██▋       | 76/285 [01:44<04:43,  1.36s/it]Loading train:  27%|██▋       | 77/285 [01:45<04:32,  1.31s/it]Loading train:  27%|██▋       | 78/285 [01:46<04:16,  1.24s/it]Loading train:  28%|██▊       | 79/285 [01:47<04:19,  1.26s/it]Loading train:  28%|██▊       | 80/285 [01:48<04:16,  1.25s/it]Loading train:  28%|██▊       | 81/285 [01:50<04:19,  1.27s/it]Loading train:  29%|██▉       | 82/285 [01:51<04:18,  1.27s/it]Loading train:  29%|██▉       | 83/285 [01:53<04:31,  1.34s/it]Loading train:  29%|██▉       | 84/285 [01:54<04:18,  1.28s/it]Loading train:  30%|██▉       | 85/285 [01:55<04:24,  1.32s/it]Loading train:  30%|███       | 86/285 [01:56<04:22,  1.32s/it]Loading train:  31%|███       | 87/285 [01:58<04:20,  1.32s/it]Loading train:  31%|███       | 88/285 [01:59<04:18,  1.31s/it]Loading train:  31%|███       | 89/285 [02:00<04:14,  1.30s/it]Loading train:  32%|███▏      | 90/285 [02:02<04:23,  1.35s/it]Loading train:  32%|███▏      | 91/285 [02:03<04:18,  1.33s/it]Loading train:  32%|███▏      | 92/285 [02:05<04:26,  1.38s/it]Loading train:  33%|███▎      | 93/285 [02:06<04:45,  1.49s/it]Loading train:  33%|███▎      | 94/285 [02:08<05:06,  1.61s/it]Loading train:  33%|███▎      | 95/285 [02:09<04:44,  1.50s/it]Loading train:  34%|███▎      | 96/285 [02:10<04:20,  1.38s/it]Loading train:  34%|███▍      | 97/285 [02:12<04:00,  1.28s/it]Loading train:  34%|███▍      | 98/285 [02:13<04:03,  1.30s/it]Loading train:  35%|███▍      | 99/285 [02:14<04:00,  1.29s/it]Loading train:  35%|███▌      | 100/285 [02:16<04:05,  1.33s/it]Loading train:  35%|███▌      | 101/285 [02:17<03:59,  1.30s/it]Loading train:  36%|███▌      | 102/285 [02:18<03:48,  1.25s/it]Loading train:  36%|███▌      | 103/285 [02:19<03:23,  1.12s/it]Loading train:  36%|███▋      | 104/285 [02:20<03:12,  1.07s/it]Loading train:  37%|███▋      | 105/285 [02:21<03:12,  1.07s/it]Loading train:  37%|███▋      | 106/285 [02:22<03:06,  1.04s/it]Loading train:  38%|███▊      | 107/285 [02:23<02:56,  1.01it/s]Loading train:  38%|███▊      | 108/285 [02:24<02:52,  1.03it/s]Loading train:  38%|███▊      | 109/285 [02:24<02:45,  1.06it/s]Loading train:  39%|███▊      | 110/285 [02:26<02:52,  1.01it/s]Loading train:  39%|███▉      | 111/285 [02:26<02:45,  1.05it/s]Loading train:  39%|███▉      | 112/285 [02:27<02:46,  1.04it/s]Loading train:  40%|███▉      | 113/285 [02:28<02:43,  1.05it/s]Loading train:  40%|████      | 114/285 [02:29<02:43,  1.05it/s]Loading train:  40%|████      | 115/285 [02:30<02:42,  1.05it/s]Loading train:  41%|████      | 116/285 [02:31<02:54,  1.03s/it]Loading train:  41%|████      | 117/285 [02:32<02:44,  1.02it/s]Loading train:  41%|████▏     | 118/285 [02:33<02:36,  1.07it/s]Loading train:  42%|████▏     | 119/285 [02:34<02:37,  1.06it/s]Loading train:  42%|████▏     | 120/285 [02:35<02:37,  1.05it/s]Loading train:  42%|████▏     | 121/285 [02:36<02:51,  1.04s/it]Loading train:  43%|████▎     | 122/285 [02:38<02:58,  1.10s/it]Loading train:  43%|████▎     | 123/285 [02:39<03:00,  1.11s/it]Loading train:  44%|████▎     | 124/285 [02:40<02:45,  1.03s/it]Loading train:  44%|████▍     | 125/285 [02:40<02:31,  1.06it/s]Loading train:  44%|████▍     | 126/285 [02:41<02:22,  1.11it/s]Loading train:  45%|████▍     | 127/285 [02:42<02:15,  1.17it/s]Loading train:  45%|████▍     | 128/285 [02:43<02:12,  1.18it/s]Loading train:  45%|████▌     | 129/285 [02:44<02:14,  1.16it/s]Loading train:  46%|████▌     | 130/285 [02:44<02:05,  1.24it/s]Loading train:  46%|████▌     | 131/285 [02:45<02:05,  1.22it/s]Loading train:  46%|████▋     | 132/285 [02:46<02:04,  1.23it/s]Loading train:  47%|████▋     | 133/285 [02:47<02:07,  1.20it/s]Loading train:  47%|████▋     | 134/285 [02:48<02:05,  1.20it/s]Loading train:  47%|████▋     | 135/285 [02:48<02:01,  1.23it/s]Loading train:  48%|████▊     | 136/285 [02:49<01:59,  1.25it/s]Loading train:  48%|████▊     | 137/285 [02:50<01:59,  1.24it/s]Loading train:  48%|████▊     | 138/285 [02:51<01:56,  1.26it/s]Loading train:  49%|████▉     | 139/285 [02:51<01:55,  1.26it/s]Loading train:  49%|████▉     | 140/285 [02:52<01:51,  1.30it/s]Loading train:  49%|████▉     | 141/285 [02:53<01:56,  1.23it/s]Loading train:  50%|████▉     | 142/285 [02:54<01:55,  1.23it/s]Loading train:  50%|█████     | 143/285 [02:55<01:53,  1.25it/s]Loading train:  51%|█████     | 144/285 [02:56<01:58,  1.19it/s]Loading train:  51%|█████     | 145/285 [02:57<01:59,  1.17it/s]Loading train:  51%|█████     | 146/285 [02:57<01:57,  1.18it/s]Loading train:  52%|█████▏    | 147/285 [02:58<01:57,  1.17it/s]Loading train:  52%|█████▏    | 148/285 [02:59<01:56,  1.18it/s]Loading train:  52%|█████▏    | 149/285 [03:00<01:51,  1.22it/s]Loading train:  53%|█████▎    | 150/285 [03:01<01:49,  1.23it/s]Loading train:  53%|█████▎    | 151/285 [03:01<01:50,  1.21it/s]Loading train:  53%|█████▎    | 152/285 [03:02<01:49,  1.21it/s]Loading train:  54%|█████▎    | 153/285 [03:03<01:47,  1.23it/s]Loading train:  54%|█████▍    | 154/285 [03:04<01:48,  1.21it/s]Loading train:  54%|█████▍    | 155/285 [03:05<01:44,  1.24it/s]Loading train:  55%|█████▍    | 156/285 [03:05<01:43,  1.24it/s]Loading train:  55%|█████▌    | 157/285 [03:06<01:41,  1.26it/s]Loading train:  55%|█████▌    | 158/285 [03:07<01:38,  1.29it/s]Loading train:  56%|█████▌    | 159/285 [03:08<01:35,  1.31it/s]Loading train:  56%|█████▌    | 160/285 [03:08<01:33,  1.34it/s]Loading train:  56%|█████▋    | 161/285 [03:09<01:31,  1.35it/s]Loading train:  57%|█████▋    | 162/285 [03:10<01:36,  1.27it/s]Loading train:  57%|█████▋    | 163/285 [03:11<01:36,  1.27it/s]Loading train:  58%|█████▊    | 164/285 [03:12<01:33,  1.29it/s]Loading train:  58%|█████▊    | 165/285 [03:12<01:33,  1.28it/s]Loading train:  58%|█████▊    | 166/285 [03:13<01:35,  1.25it/s]Loading train:  59%|█████▊    | 167/285 [03:14<01:34,  1.25it/s]Loading train:  59%|█████▉    | 168/285 [03:15<01:32,  1.27it/s]Loading train:  59%|█████▉    | 169/285 [03:16<01:29,  1.30it/s]Loading train:  60%|█████▉    | 170/285 [03:16<01:27,  1.32it/s]Loading train:  60%|██████    | 171/285 [03:17<01:26,  1.32it/s]Loading train:  60%|██████    | 172/285 [03:18<01:30,  1.26it/s]Loading train:  61%|██████    | 173/285 [03:19<01:30,  1.24it/s]Loading train:  61%|██████    | 174/285 [03:19<01:26,  1.29it/s]Loading train:  61%|██████▏   | 175/285 [03:20<01:26,  1.28it/s]Loading train:  62%|██████▏   | 176/285 [03:21<01:26,  1.26it/s]Loading train:  62%|██████▏   | 177/285 [03:22<01:26,  1.24it/s]Loading train:  62%|██████▏   | 178/285 [03:23<01:26,  1.24it/s]Loading train:  63%|██████▎   | 179/285 [03:23<01:24,  1.26it/s]Loading train:  63%|██████▎   | 180/285 [03:24<01:29,  1.18it/s]Loading train:  64%|██████▎   | 181/285 [03:25<01:27,  1.19it/s]Loading train:  64%|██████▍   | 182/285 [03:26<01:26,  1.19it/s]Loading train:  64%|██████▍   | 183/285 [03:27<01:21,  1.24it/s]Loading train:  65%|██████▍   | 184/285 [03:28<01:23,  1.21it/s]Loading train:  65%|██████▍   | 185/285 [03:28<01:20,  1.24it/s]Loading train:  65%|██████▌   | 186/285 [03:30<01:28,  1.12it/s]Loading train:  66%|██████▌   | 187/285 [03:30<01:27,  1.12it/s]Loading train:  66%|██████▌   | 188/285 [03:31<01:30,  1.08it/s]Loading train:  66%|██████▋   | 189/285 [03:32<01:23,  1.15it/s]Loading train:  67%|██████▋   | 190/285 [03:33<01:19,  1.20it/s]Loading train:  67%|██████▋   | 191/285 [03:34<01:16,  1.23it/s]Loading train:  67%|██████▋   | 192/285 [03:34<01:14,  1.25it/s]Loading train:  68%|██████▊   | 193/285 [03:35<01:10,  1.30it/s]Loading train:  68%|██████▊   | 194/285 [03:36<01:09,  1.31it/s]Loading train:  68%|██████▊   | 195/285 [03:37<01:06,  1.35it/s]Loading train:  69%|██████▉   | 196/285 [03:38<01:14,  1.20it/s]Loading train:  69%|██████▉   | 197/285 [03:39<01:16,  1.14it/s]Loading train:  69%|██████▉   | 198/285 [03:40<01:18,  1.10it/s]Loading train:  70%|██████▉   | 199/285 [03:40<01:14,  1.15it/s]Loading train:  70%|███████   | 200/285 [03:41<01:11,  1.19it/s]Loading train:  71%|███████   | 201/285 [03:42<01:13,  1.15it/s]Loading train:  71%|███████   | 202/285 [03:43<01:10,  1.19it/s]Loading train:  71%|███████   | 203/285 [03:44<01:08,  1.19it/s]Loading train:  72%|███████▏  | 204/285 [03:44<01:06,  1.22it/s]Loading train:  72%|███████▏  | 205/285 [03:45<01:07,  1.18it/s]Loading train:  72%|███████▏  | 206/285 [03:46<01:03,  1.24it/s]Loading train:  73%|███████▎  | 207/285 [03:47<01:04,  1.20it/s]Loading train:  73%|███████▎  | 208/285 [03:48<01:08,  1.13it/s]Loading train:  73%|███████▎  | 209/285 [03:49<01:11,  1.06it/s]Loading train:  74%|███████▎  | 210/285 [03:50<01:04,  1.15it/s]Loading train:  74%|███████▍  | 211/285 [03:51<01:03,  1.17it/s]Loading train:  74%|███████▍  | 212/285 [03:51<01:01,  1.18it/s]Loading train:  75%|███████▍  | 213/285 [03:52<01:01,  1.18it/s]Loading train:  75%|███████▌  | 214/285 [03:53<00:57,  1.24it/s]Loading train:  75%|███████▌  | 215/285 [03:54<00:58,  1.19it/s]Loading train:  76%|███████▌  | 216/285 [03:55<00:55,  1.24it/s]Loading train:  76%|███████▌  | 217/285 [03:56<00:57,  1.19it/s]Loading train:  76%|███████▋  | 218/285 [03:57<00:59,  1.13it/s]Loading train:  77%|███████▋  | 219/285 [03:57<00:59,  1.11it/s]Loading train:  77%|███████▋  | 220/285 [03:58<00:58,  1.12it/s]Loading train:  78%|███████▊  | 221/285 [03:59<00:55,  1.15it/s]Loading train:  78%|███████▊  | 222/285 [04:00<00:54,  1.16it/s]Loading train:  78%|███████▊  | 223/285 [04:01<00:49,  1.25it/s]Loading train:  79%|███████▊  | 224/285 [04:01<00:48,  1.25it/s]Loading train:  79%|███████▉  | 225/285 [04:02<00:49,  1.20it/s]Loading train:  79%|███████▉  | 226/285 [04:03<00:52,  1.12it/s]Loading train:  80%|███████▉  | 227/285 [04:04<00:53,  1.08it/s]Loading train:  80%|████████  | 228/285 [04:05<00:53,  1.06it/s]Loading train:  80%|████████  | 229/285 [04:06<00:51,  1.10it/s]Loading train:  81%|████████  | 230/285 [04:07<00:46,  1.18it/s]Loading train:  81%|████████  | 231/285 [04:08<00:44,  1.21it/s]Loading train:  81%|████████▏ | 232/285 [04:09<00:43,  1.21it/s]Loading train:  82%|████████▏ | 233/285 [04:09<00:41,  1.27it/s]Loading train:  82%|████████▏ | 234/285 [04:10<00:43,  1.18it/s]Loading train:  82%|████████▏ | 235/285 [04:11<00:39,  1.25it/s]Loading train:  83%|████████▎ | 236/285 [04:12<00:41,  1.19it/s]Loading train:  83%|████████▎ | 237/285 [04:13<00:41,  1.16it/s]Loading train:  84%|████████▎ | 238/285 [04:14<00:41,  1.14it/s]Loading train:  84%|████████▍ | 239/285 [04:14<00:39,  1.17it/s]Loading train:  84%|████████▍ | 240/285 [04:15<00:36,  1.23it/s]Loading train:  85%|████████▍ | 241/285 [04:16<00:35,  1.24it/s]Loading train:  85%|████████▍ | 242/285 [04:17<00:32,  1.31it/s]Loading train:  85%|████████▌ | 243/285 [04:17<00:31,  1.33it/s]Loading train:  86%|████████▌ | 244/285 [04:18<00:33,  1.22it/s]Loading train:  86%|████████▌ | 245/285 [04:19<00:31,  1.29it/s]Loading train:  86%|████████▋ | 246/285 [04:20<00:32,  1.20it/s]Loading train:  87%|████████▋ | 247/285 [04:21<00:33,  1.15it/s]Loading train:  87%|████████▋ | 248/285 [04:22<00:32,  1.14it/s]Loading train:  87%|████████▋ | 249/285 [04:23<00:29,  1.21it/s]Loading train:  88%|████████▊ | 250/285 [04:23<00:28,  1.24it/s]Loading train:  88%|████████▊ | 251/285 [04:24<00:26,  1.27it/s]Loading train:  88%|████████▊ | 252/285 [04:25<00:25,  1.30it/s]Loading train:  89%|████████▉ | 253/285 [04:26<00:25,  1.23it/s]Loading train:  89%|████████▉ | 254/285 [04:27<00:25,  1.21it/s]Loading train:  89%|████████▉ | 255/285 [04:27<00:24,  1.21it/s]Loading train:  90%|████████▉ | 256/285 [04:28<00:22,  1.31it/s]Loading train:  90%|█████████ | 257/285 [04:29<00:22,  1.25it/s]Loading train:  91%|█████████ | 258/285 [04:30<00:22,  1.18it/s]Loading train:  91%|█████████ | 259/285 [04:31<00:21,  1.21it/s]Loading train:  91%|█████████ | 260/285 [04:31<00:19,  1.26it/s]Loading train:  92%|█████████▏| 261/285 [04:32<00:18,  1.29it/s]Loading train:  92%|█████████▏| 262/285 [04:33<00:18,  1.25it/s]Loading train:  92%|█████████▏| 263/285 [04:34<00:16,  1.31it/s]Loading train:  93%|█████████▎| 264/285 [04:35<00:17,  1.23it/s]Loading train:  93%|█████████▎| 265/285 [04:35<00:16,  1.20it/s]Loading train:  93%|█████████▎| 266/285 [04:36<00:15,  1.19it/s]Loading train:  94%|█████████▎| 267/285 [04:37<00:14,  1.24it/s]Loading train:  94%|█████████▍| 268/285 [04:38<00:14,  1.16it/s]Loading train:  94%|█████████▍| 269/285 [04:39<00:13,  1.18it/s]Loading train:  95%|█████████▍| 270/285 [04:40<00:12,  1.23it/s]Loading train:  95%|█████████▌| 271/285 [04:40<00:11,  1.22it/s]Loading train:  95%|█████████▌| 272/285 [04:41<00:10,  1.24it/s]Loading train:  96%|█████████▌| 273/285 [04:42<00:09,  1.26it/s]Loading train:  96%|█████████▌| 274/285 [04:43<00:08,  1.31it/s]Loading train:  96%|█████████▋| 275/285 [04:44<00:08,  1.21it/s]Loading train:  97%|█████████▋| 276/285 [04:45<00:07,  1.14it/s]Loading train:  97%|█████████▋| 277/285 [04:45<00:06,  1.18it/s]Loading train:  98%|█████████▊| 278/285 [04:46<00:05,  1.21it/s]Loading train:  98%|█████████▊| 279/285 [04:47<00:04,  1.24it/s]Loading train:  98%|█████████▊| 280/285 [04:48<00:04,  1.23it/s]Loading train:  99%|█████████▊| 281/285 [04:48<00:03,  1.28it/s]Loading train:  99%|█████████▉| 282/285 [04:49<00:02,  1.26it/s]Loading train:  99%|█████████▉| 283/285 [04:50<00:01,  1.21it/s]Loading train: 100%|█████████▉| 284/285 [04:51<00:00,  1.17it/s]Loading train: 100%|██████████| 285/285 [04:52<00:00,  1.15it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   6%|▌         | 16/285 [00:00<00:01, 156.72it/s]concatenating: train:  17%|█▋        | 49/285 [00:00<00:01, 185.74it/s]concatenating: train:  28%|██▊       | 81/285 [00:00<00:00, 212.19it/s]concatenating: train:  40%|████      | 114/285 [00:00<00:00, 237.52it/s]concatenating: train:  52%|█████▏    | 148/285 [00:00<00:00, 260.09it/s]concatenating: train:  64%|██████▍   | 183/285 [00:00<00:00, 281.34it/s]concatenating: train:  76%|███████▋  | 218/285 [00:00<00:00, 297.45it/s]concatenating: train:  87%|████████▋ | 249/285 [00:01<00:00, 192.08it/s]concatenating: train:  96%|█████████▌| 274/285 [00:01<00:00, 206.35it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 251.95it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.27s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.26s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.20s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 120.24it/s]2019-07-09 06:21:34.486823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-09 06:21:34.486923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-09 06:21:34.486938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-09 06:21:34.486947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-09 06:21:34.487363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12743 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.44it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.27it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.01it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.44it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.64it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.43it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.68it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.37it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  7.77it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.42it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.00it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:02,  8.18it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  8.38it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  6.64it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.12it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.33it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  8.36it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:04<00:00,  6.83it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  5.92it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.47it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 10)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 11)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 30)   3000        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 30)   8130        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 30)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 40, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 60)   16260       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 60)   32460       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 90)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 90)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 120)  97320       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 120)  129720      activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 120)  480         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 120)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 210)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 210)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 60)   50460       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 60)   81060       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 60)   32460       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 60)   240         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 60)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 210)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 40, 210)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 30)   25230       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 60)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 30)   16230       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 30)   8130        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 30)   120         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 30)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 90)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 80, 90)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 10)   8110        dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 80, 10)   40          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 80, 10)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 80, 10)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 80, 100)  0           dropout_6[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 80, 13)   1313        concatenate_8[0][0]              
==================================================================================================
Total params: 512,463
Trainable params: 120,203
Non-trainable params: 392,260
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 30s - loss: 12757.5014 - acc: 0.6868 - mDice: 0.1413 - val_loss: 12062.5567 - val_acc: 0.9058 - val_mDice: 0.1859

Epoch 00001: val_mDice improved from -inf to 0.18593, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 22s - loss: 4268.0570 - acc: 0.8811 - mDice: 0.4276 - val_loss: 8240.2539 - val_acc: 0.9082 - val_mDice: 0.3203

Epoch 00002: val_mDice improved from 0.18593 to 0.32032, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 21s - loss: 3054.5455 - acc: 0.8952 - mDice: 0.5392 - val_loss: 3261.4829 - val_acc: 0.9238 - val_mDice: 0.4950

Epoch 00003: val_mDice improved from 0.32032 to 0.49497, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 21s - loss: 2537.6697 - acc: 0.9110 - mDice: 0.5979 - val_loss: 2824.9269 - val_acc: 0.9328 - val_mDice: 0.5390

Epoch 00004: val_mDice improved from 0.49497 to 0.53895, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 22s - loss: 2264.8798 - acc: 0.9235 - mDice: 0.6314 - val_loss: 2673.8864 - val_acc: 0.9377 - val_mDice: 0.5567

Epoch 00005: val_mDice improved from 0.53895 to 0.55669, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 20s - loss: 2088.6492 - acc: 0.9314 - mDice: 0.6542 - val_loss: 2708.1310 - val_acc: 0.9417 - val_mDice: 0.5526

Epoch 00006: val_mDice did not improve from 0.55669
Epoch 7/300
 - 21s - loss: 1973.5263 - acc: 0.9351 - mDice: 0.6695 - val_loss: 2660.9335 - val_acc: 0.9415 - val_mDice: 0.5597

Epoch 00007: val_mDice improved from 0.55669 to 0.55974, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 21s - loss: 1885.6123 - acc: 0.9373 - mDice: 0.6813 - val_loss: 2749.1493 - val_acc: 0.9425 - val_mDice: 0.5501

Epoch 00008: val_mDice did not improve from 0.55974
Epoch 9/300
 - 22s - loss: 1817.7315 - acc: 0.9387 - mDice: 0.6906 - val_loss: 2689.3763 - val_acc: 0.9421 - val_mDice: 0.5564

Epoch 00009: val_mDice did not improve from 0.55974
Epoch 10/300
 - 21s - loss: 1763.4941 - acc: 0.9400 - mDice: 0.6982 - val_loss: 2506.1704 - val_acc: 0.9412 - val_mDice: 0.5768

Epoch 00010: val_mDice improved from 0.55974 to 0.57681, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 21s - loss: 1713.7988 - acc: 0.9412 - mDice: 0.7051 - val_loss: 2601.2947 - val_acc: 0.9395 - val_mDice: 0.5681

Epoch 00011: val_mDice did not improve from 0.57681
Epoch 12/300
 - 21s - loss: 1665.3241 - acc: 0.9419 - mDice: 0.7119 - val_loss: 2737.7802 - val_acc: 0.9368 - val_mDice: 0.5531

Epoch 00012: val_mDice did not improve from 0.57681
Epoch 13/300
 - 21s - loss: 1624.4203 - acc: 0.9428 - mDice: 0.7177 - val_loss: 2706.5085 - val_acc: 0.9419 - val_mDice: 0.5566

Epoch 00013: val_mDice did not improve from 0.57681
Epoch 14/300
 - 21s - loss: 1604.1811 - acc: 0.9432 - mDice: 0.7206 - val_loss: 2638.8864 - val_acc: 0.9384 - val_mDice: 0.5613

Epoch 00014: val_mDice did not improve from 0.57681
Epoch 15/300
 - 20s - loss: 1562.9394 - acc: 0.9439 - mDice: 0.7267 - val_loss: 2564.2519 - val_acc: 0.9399 - val_mDice: 0.5717

Epoch 00015: val_mDice did not improve from 0.57681
Epoch 16/300
 - 20s - loss: 1542.8796 - acc: 0.9443 - mDice: 0.7296 - val_loss: 2523.9668 - val_acc: 0.9437 - val_mDice: 0.5738

Epoch 00016: val_mDice did not improve from 0.57681
Epoch 17/300
 - 20s - loss: 1511.2155 - acc: 0.9450 - mDice: 0.7342 - val_loss: 2621.0498 - val_acc: 0.9420 - val_mDice: 0.5632

Epoch 00017: val_mDice did not improve from 0.57681
Epoch 18/300
 - 21s - loss: 1479.1330 - acc: 0.9456 - mDice: 0.7390 - val_loss: 2599.9568 - val_acc: 0.9428 - val_mDice: 0.5669

Epoch 00018: val_mDice did not improve from 0.57681
Epoch 19/300
 - 21s - loss: 1472.6498 - acc: 0.9457 - mDice: 0.7400 - val_loss: 2537.7010 - val_acc: 0.9417 - val_mDice: 0.5731

Epoch 00019: val_mDice did not improve from 0.57681
Epoch 20/300
 - 20s - loss: 1447.4981 - acc: 0.9461 - mDice: 0.7436 - val_loss: 2531.6403 - val_acc: 0.9411 - val_mDice: 0.5737

Epoch 00020: val_mDice did not improve from 0.57681
Epoch 21/300
 - 20s - loss: 1432.4641 - acc: 0.9464 - mDice: 0.7459 - val_loss: 2654.0474 - val_acc: 0.9419 - val_mDice: 0.5611

Epoch 00021: val_mDice did not improve from 0.57681
Epoch 22/300
 - 20s - loss: 1411.5073 - acc: 0.9467 - mDice: 0.7491 - val_loss: 2537.6044 - val_acc: 0.9413 - val_mDice: 0.5723

Epoch 00022: val_mDice did not improve from 0.57681
Epoch 23/300
 - 21s - loss: 1400.7906 - acc: 0.9469 - mDice: 0.7507 - val_loss: 2658.8400 - val_acc: 0.9370 - val_mDice: 0.5593

Epoch 00023: val_mDice did not improve from 0.57681
Epoch 24/300
 - 21s - loss: 1386.7436 - acc: 0.9472 - mDice: 0.7529 - val_loss: 2542.6589 - val_acc: 0.9447 - val_mDice: 0.5728

Epoch 00024: val_mDice did not improve from 0.57681
Epoch 25/300
 - 21s - loss: 1368.8130 - acc: 0.9476 - mDice: 0.7556 - val_loss: 2676.4787 - val_acc: 0.9444 - val_mDice: 0.5583

Epoch 00025: val_mDice did not improve from 0.57681
Epoch 26/300
 - 21s - loss: 1353.9316 - acc: 0.9478 - mDice: 0.7578 - val_loss: 2823.1420 - val_acc: 0.9452 - val_mDice: 0.5398

Epoch 00026: val_mDice did not improve from 0.57681
Epoch 27/300
 - 21s - loss: 1344.6096 - acc: 0.9479 - mDice: 0.7592 - val_loss: 2661.6318 - val_acc: 0.9429 - val_mDice: 0.5610

Epoch 00027: val_mDice did not improve from 0.57681
Epoch 28/300
 - 22s - loss: 1320.3681 - acc: 0.9483 - mDice: 0.7631 - val_loss: 2632.5944 - val_acc: 0.9435 - val_mDice: 0.5620

Epoch 00028: val_mDice did not improve from 0.57681
Epoch 29/300
 - 21s - loss: 1313.2413 - acc: 0.9486 - mDice: 0.7641 - val_loss: 2811.2189 - val_acc: 0.9440 - val_mDice: 0.5432

Epoch 00029: val_mDice did not improve from 0.57681
Epoch 30/300
 - 21s - loss: 1314.3581 - acc: 0.9484 - mDice: 0.7640 - val_loss: 2720.9555 - val_acc: 0.9453 - val_mDice: 0.5511

Epoch 00030: val_mDice did not improve from 0.57681
Epoch 31/300
 - 21s - loss: 1293.3480 - acc: 0.9488 - mDice: 0.7672 - val_loss: 2679.9011 - val_acc: 0.9418 - val_mDice: 0.5572

Epoch 00031: val_mDice did not improve from 0.57681
Epoch 32/300
 - 21s - loss: 1282.3163 - acc: 0.9490 - mDice: 0.7689 - val_loss: 2682.9657 - val_acc: 0.9401 - val_mDice: 0.5560

Epoch 00032: val_mDice did not improve from 0.57681
Epoch 33/300
 - 21s - loss: 1262.8823 - acc: 0.9493 - mDice: 0.7720 - val_loss: 2675.5541 - val_acc: 0.9423 - val_mDice: 0.5567

Epoch 00033: val_mDice did not improve from 0.57681
Epoch 34/300
 - 21s - loss: 1262.6471 - acc: 0.9493 - mDice: 0.7720 - val_loss: 2736.1593 - val_acc: 0.9426 - val_mDice: 0.5518

Epoch 00034: val_mDice did not improve from 0.57681
Epoch 35/300
 - 21s - loss: 1255.5679 - acc: 0.9495 - mDice: 0.7732 - val_loss: 2678.5566 - val_acc: 0.9417 - val_mDice: 0.5561

Epoch 00035: val_mDice did not improve from 0.57681
Epoch 36/300
 - 21s - loss: 1245.5911 - acc: 0.9496 - mDice: 0.7746 - val_loss: 2768.5077 - val_acc: 0.9392 - val_mDice: 0.5465

Epoch 00036: val_mDice did not improve from 0.57681
Epoch 37/300
 - 21s - loss: 1243.8539 - acc: 0.9497 - mDice: 0.7749 - val_loss: 2704.0586 - val_acc: 0.9426 - val_mDice: 0.5536

Epoch 00037: val_mDice did not improve from 0.57681
Epoch 38/300
 - 20s - loss: 1225.7481 - acc: 0.9500 - mDice: 0.7778 - val_loss: 2734.9028 - val_acc: 0.9424 - val_mDice: 0.5514

Epoch 00038: val_mDice did not improve from 0.57681
Epoch 39/300
 - 21s - loss: 1218.2189 - acc: 0.9501 - mDice: 0.7790 - val_loss: 2723.1468 - val_acc: 0.9437 - val_mDice: 0.5529

Epoch 00039: val_mDice did not improve from 0.57681
Epoch 40/300
 - 21s - loss: 1216.6400 - acc: 0.9502 - mDice: 0.7792 - val_loss: 2609.1975 - val_acc: 0.9428 - val_mDice: 0.5643

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.34s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.08s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.87s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:45,  1.85s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:59,  1.69s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:53,  1.68s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:30,  1.60s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:49,  1.68s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:27,  1.60s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:44,  1.67s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:36,  1.65s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:59,  1.74s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:18,  1.81s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<07:52,  1.72s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:05,  1.78s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:45,  1.71s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<07:52,  1.75s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<08:08,  1.81s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<08:20,  1.86s/it]predicting train subjects:   6%|▌         | 17/285 [00:29<08:06,  1.81s/it]predicting train subjects:   6%|▋         | 18/285 [00:31<08:06,  1.82s/it]predicting train subjects:   7%|▋         | 19/285 [00:32<07:46,  1.75s/it]predicting train subjects:   7%|▋         | 20/285 [00:34<07:48,  1.77s/it]predicting train subjects:   7%|▋         | 21/285 [00:36<07:59,  1.82s/it]predicting train subjects:   8%|▊         | 22/285 [00:38<07:38,  1.74s/it]predicting train subjects:   8%|▊         | 23/285 [00:39<07:45,  1.77s/it]predicting train subjects:   8%|▊         | 24/285 [00:41<07:29,  1.72s/it]predicting train subjects:   9%|▉         | 25/285 [00:43<07:40,  1.77s/it]predicting train subjects:   9%|▉         | 26/285 [00:45<07:47,  1.81s/it]predicting train subjects:   9%|▉         | 27/285 [00:46<07:28,  1.74s/it]predicting train subjects:  10%|▉         | 28/285 [00:48<07:34,  1.77s/it]predicting train subjects:  10%|█         | 29/285 [00:50<07:36,  1.78s/it]predicting train subjects:  11%|█         | 30/285 [00:52<07:44,  1.82s/it]predicting train subjects:  11%|█         | 31/285 [00:54<07:48,  1.84s/it]predicting train subjects:  11%|█         | 32/285 [00:55<07:22,  1.75s/it]predicting train subjects:  12%|█▏        | 33/285 [00:57<07:20,  1.75s/it]predicting train subjects:  12%|█▏        | 34/285 [00:59<07:24,  1.77s/it]predicting train subjects:  12%|█▏        | 35/285 [01:01<07:35,  1.82s/it]predicting train subjects:  13%|█▎        | 36/285 [01:02<07:16,  1.75s/it]predicting train subjects:  13%|█▎        | 37/285 [01:04<07:22,  1.78s/it]predicting train subjects:  13%|█▎        | 38/285 [01:06<07:29,  1.82s/it]predicting train subjects:  14%|█▎        | 39/285 [01:08<07:08,  1.74s/it]predicting train subjects:  14%|█▍        | 40/285 [01:10<07:14,  1.77s/it]predicting train subjects:  14%|█▍        | 41/285 [01:11<07:00,  1.73s/it]predicting train subjects:  15%|█▍        | 42/285 [01:13<06:51,  1.69s/it]predicting train subjects:  15%|█▌        | 43/285 [01:15<06:59,  1.73s/it]predicting train subjects:  15%|█▌        | 44/285 [01:17<07:18,  1.82s/it]predicting train subjects:  16%|█▌        | 45/285 [01:18<06:54,  1.73s/it]predicting train subjects:  16%|█▌        | 46/285 [01:20<07:04,  1.77s/it]predicting train subjects:  16%|█▋        | 47/285 [01:22<06:50,  1.72s/it]predicting train subjects:  17%|█▋        | 48/285 [01:23<06:51,  1.74s/it]predicting train subjects:  17%|█▋        | 49/285 [01:25<07:06,  1.81s/it]predicting train subjects:  18%|█▊        | 50/285 [01:27<07:06,  1.82s/it]predicting train subjects:  18%|█▊        | 51/285 [01:29<07:16,  1.87s/it]predicting train subjects:  18%|█▊        | 52/285 [01:31<06:58,  1.80s/it]predicting train subjects:  19%|█▊        | 53/285 [01:33<07:02,  1.82s/it]predicting train subjects:  19%|█▉        | 54/285 [01:35<07:08,  1.85s/it]predicting train subjects:  19%|█▉        | 55/285 [01:36<06:44,  1.76s/it]predicting train subjects:  20%|█▉        | 56/285 [01:38<06:49,  1.79s/it]predicting train subjects:  20%|██        | 57/285 [01:40<06:33,  1.72s/it]predicting train subjects:  20%|██        | 58/285 [01:41<06:37,  1.75s/it]predicting train subjects:  21%|██        | 59/285 [01:43<06:48,  1.81s/it]predicting train subjects:  21%|██        | 60/285 [01:45<06:55,  1.85s/it]predicting train subjects:  21%|██▏       | 61/285 [01:47<06:34,  1.76s/it]predicting train subjects:  22%|██▏       | 62/285 [01:49<06:35,  1.77s/it]predicting train subjects:  22%|██▏       | 63/285 [01:51<06:38,  1.80s/it]predicting train subjects:  22%|██▏       | 64/285 [01:52<06:25,  1.75s/it]predicting train subjects:  23%|██▎       | 65/285 [01:54<06:26,  1.76s/it]predicting train subjects:  23%|██▎       | 66/285 [01:56<06:24,  1.76s/it]predicting train subjects:  24%|██▎       | 67/285 [01:58<06:28,  1.78s/it]predicting train subjects:  24%|██▍       | 68/285 [01:59<06:16,  1.73s/it]predicting train subjects:  24%|██▍       | 69/285 [02:01<06:20,  1.76s/it]predicting train subjects:  25%|██▍       | 70/285 [02:03<06:24,  1.79s/it]predicting train subjects:  25%|██▍       | 71/285 [02:05<06:25,  1.80s/it]predicting train subjects:  25%|██▌       | 72/285 [02:06<06:11,  1.74s/it]predicting train subjects:  26%|██▌       | 73/285 [02:08<06:10,  1.75s/it]predicting train subjects:  26%|██▌       | 74/285 [02:10<06:08,  1.75s/it]predicting train subjects:  26%|██▋       | 75/285 [02:12<06:12,  1.77s/it]predicting train subjects:  27%|██▋       | 76/285 [02:13<06:13,  1.79s/it]predicting train subjects:  27%|██▋       | 77/285 [02:15<06:01,  1.74s/it]predicting train subjects:  27%|██▋       | 78/285 [02:17<05:52,  1.71s/it]predicting train subjects:  28%|██▊       | 79/285 [02:18<05:53,  1.71s/it]predicting train subjects:  28%|██▊       | 80/285 [02:20<05:53,  1.73s/it]predicting train subjects:  28%|██▊       | 81/285 [02:22<05:44,  1.69s/it]predicting train subjects:  29%|██▉       | 82/285 [02:24<05:44,  1.70s/it]predicting train subjects:  29%|██▉       | 83/285 [02:25<05:40,  1.69s/it]predicting train subjects:  29%|██▉       | 84/285 [02:27<05:34,  1.66s/it]predicting train subjects:  30%|██▉       | 85/285 [02:29<05:39,  1.70s/it]predicting train subjects:  30%|███       | 86/285 [02:30<05:47,  1.75s/it]predicting train subjects:  31%|███       | 87/285 [02:32<05:50,  1.77s/it]predicting train subjects:  31%|███       | 88/285 [02:34<05:42,  1.74s/it]predicting train subjects:  31%|███       | 89/285 [02:36<05:44,  1.76s/it]predicting train subjects:  32%|███▏      | 90/285 [02:38<05:47,  1.78s/it]predicting train subjects:  32%|███▏      | 91/285 [02:39<05:36,  1.74s/it]predicting train subjects:  32%|███▏      | 92/285 [02:41<05:41,  1.77s/it]predicting train subjects:  33%|███▎      | 93/285 [02:43<05:32,  1.73s/it]predicting train subjects:  33%|███▎      | 94/285 [02:44<05:33,  1.74s/it]predicting train subjects:  33%|███▎      | 95/285 [02:46<05:34,  1.76s/it]predicting train subjects:  34%|███▎      | 96/285 [02:48<05:29,  1.74s/it]predicting train subjects:  34%|███▍      | 97/285 [02:50<05:31,  1.76s/it]predicting train subjects:  34%|███▍      | 98/285 [02:52<05:29,  1.76s/it]predicting train subjects:  35%|███▍      | 99/285 [02:53<05:25,  1.75s/it]predicting train subjects:  35%|███▌      | 100/285 [02:55<05:26,  1.76s/it]predicting train subjects:  35%|███▌      | 101/285 [02:57<05:17,  1.73s/it]predicting train subjects:  36%|███▌      | 102/285 [02:59<05:24,  1.77s/it]predicting train subjects:  36%|███▌      | 103/285 [03:00<05:13,  1.72s/it]predicting train subjects:  36%|███▋      | 104/285 [03:02<05:13,  1.73s/it]predicting train subjects:  37%|███▋      | 105/285 [03:04<05:13,  1.74s/it]predicting train subjects:  37%|███▋      | 106/285 [03:05<05:07,  1.72s/it]predicting train subjects:  38%|███▊      | 107/285 [03:07<05:07,  1.73s/it]predicting train subjects:  38%|███▊      | 108/285 [03:09<04:58,  1.69s/it]predicting train subjects:  38%|███▊      | 109/285 [03:11<05:04,  1.73s/it]predicting train subjects:  39%|███▊      | 110/285 [03:12<05:04,  1.74s/it]predicting train subjects:  39%|███▉      | 111/285 [03:14<04:57,  1.71s/it]predicting train subjects:  39%|███▉      | 112/285 [03:16<04:56,  1.71s/it]predicting train subjects:  40%|███▉      | 113/285 [03:18<05:04,  1.77s/it]predicting train subjects:  40%|████      | 114/285 [03:19<04:58,  1.75s/it]predicting train subjects:  40%|████      | 115/285 [03:21<05:00,  1.77s/it]predicting train subjects:  41%|████      | 116/285 [03:23<05:02,  1.79s/it]predicting train subjects:  41%|████      | 117/285 [03:25<05:00,  1.79s/it]predicting train subjects:  41%|████▏     | 118/285 [03:26<04:50,  1.74s/it]predicting train subjects:  42%|████▏     | 119/285 [03:28<04:55,  1.78s/it]predicting train subjects:  42%|████▏     | 120/285 [03:30<04:45,  1.73s/it]predicting train subjects:  42%|████▏     | 121/285 [03:31<04:40,  1.71s/it]predicting train subjects:  43%|████▎     | 122/285 [03:33<04:28,  1.65s/it]predicting train subjects:  43%|████▎     | 123/285 [03:34<04:18,  1.60s/it]predicting train subjects:  44%|████▎     | 124/285 [03:36<04:17,  1.60s/it]predicting train subjects:  44%|████▍     | 125/285 [03:37<04:06,  1.54s/it]predicting train subjects:  44%|████▍     | 126/285 [03:39<03:59,  1.51s/it]predicting train subjects:  45%|████▍     | 127/285 [03:40<03:53,  1.48s/it]predicting train subjects:  45%|████▍     | 128/285 [03:42<03:59,  1.52s/it]predicting train subjects:  45%|████▌     | 129/285 [03:43<03:55,  1.51s/it]predicting train subjects:  46%|████▌     | 130/285 [03:45<03:50,  1.48s/it]predicting train subjects:  46%|████▌     | 131/285 [03:46<03:45,  1.46s/it]predicting train subjects:  46%|████▋     | 132/285 [03:48<03:51,  1.51s/it]predicting train subjects:  47%|████▋     | 133/285 [03:49<03:45,  1.48s/it]predicting train subjects:  47%|████▋     | 134/285 [03:51<03:42,  1.47s/it]predicting train subjects:  47%|████▋     | 135/285 [03:52<03:37,  1.45s/it]predicting train subjects:  48%|████▊     | 136/285 [03:54<03:34,  1.44s/it]predicting train subjects:  48%|████▊     | 137/285 [03:55<03:41,  1.50s/it]predicting train subjects:  48%|████▊     | 138/285 [03:57<03:36,  1.47s/it]predicting train subjects:  49%|████▉     | 139/285 [03:58<03:42,  1.52s/it]predicting train subjects:  49%|████▉     | 140/285 [04:00<03:45,  1.55s/it]predicting train subjects:  49%|████▉     | 141/285 [04:01<03:37,  1.51s/it]predicting train subjects:  50%|████▉     | 142/285 [04:03<03:35,  1.51s/it]predicting train subjects:  50%|█████     | 143/285 [04:04<03:32,  1.49s/it]predicting train subjects:  51%|█████     | 144/285 [04:06<03:34,  1.52s/it]predicting train subjects:  51%|█████     | 145/285 [04:07<03:30,  1.50s/it]predicting train subjects:  51%|█████     | 146/285 [04:09<03:31,  1.52s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:10<03:29,  1.52s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:12<03:29,  1.53s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:13<03:25,  1.51s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:15<03:22,  1.50s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:16<03:26,  1.54s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:18<03:21,  1.51s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:19<03:16,  1.49s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:21<03:23,  1.55s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:23<03:17,  1.52s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:24<03:22,  1.57s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:26<03:20,  1.57s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:27<03:15,  1.54s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:29<03:09,  1.50s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:30<03:06,  1.49s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:32<03:10,  1.54s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:33<03:07,  1.53s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:35<03:07,  1.54s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:36<03:01,  1.50s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:38<02:58,  1.49s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:39<03:01,  1.53s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:41<03:00,  1.53s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:42<02:53,  1.48s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:44<02:50,  1.47s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:45<02:46,  1.45s/it]predicting train subjects:  60%|██████    | 171/285 [04:46<02:43,  1.43s/it]predicting train subjects:  60%|██████    | 172/285 [04:48<02:42,  1.43s/it]predicting train subjects:  61%|██████    | 173/285 [04:49<02:40,  1.44s/it]predicting train subjects:  61%|██████    | 174/285 [04:51<02:39,  1.44s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:52<02:44,  1.50s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:54<02:46,  1.52s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:55<02:40,  1.49s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:57<02:35,  1.46s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:58<02:34,  1.46s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:00<02:42,  1.54s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:02<02:42,  1.56s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:03<02:43,  1.59s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:05<02:35,  1.52s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:06<02:30,  1.49s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:07<02:24,  1.44s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:09<02:34,  1.56s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:11<02:39,  1.62s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:13<02:46,  1.71s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:14<02:34,  1.61s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:16<02:27,  1.55s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:17<02:29,  1.59s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:19<02:31,  1.63s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:20<02:21,  1.54s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:22<02:17,  1.51s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:23<02:11,  1.46s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:25<02:20,  1.58s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:27<02:25,  1.66s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:29<02:24,  1.66s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:30<02:15,  1.58s/it]predicting train subjects:  70%|███████   | 200/285 [05:31<02:07,  1.50s/it]predicting train subjects:  71%|███████   | 201/285 [05:33<02:13,  1.59s/it]predicting train subjects:  71%|███████   | 202/285 [05:35<02:13,  1.61s/it]predicting train subjects:  71%|███████   | 203/285 [05:36<02:13,  1.62s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:38<02:04,  1.54s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:39<02:01,  1.51s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:41<01:55,  1.46s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:42<02:02,  1.56s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:44<02:06,  1.64s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:46<02:08,  1.70s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:47<01:59,  1.60s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:49<01:54,  1.55s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:50<01:55,  1.58s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:52<01:54,  1.59s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:53<01:48,  1.53s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:55<01:51,  1.59s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:57<01:44,  1.51s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:58<01:51,  1.64s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:00<01:53,  1.69s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:02<01:53,  1.72s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:03<01:45,  1.62s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:05<01:40,  1.57s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:07<01:40,  1.59s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:08<01:39,  1.60s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:10<01:35,  1.57s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:11<01:30,  1.50s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:13<01:34,  1.60s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:15<01:36,  1.67s/it]predicting train subjects:  80%|████████  | 228/285 [06:16<01:36,  1.70s/it]predicting train subjects:  80%|████████  | 229/285 [06:18<01:34,  1.69s/it]predicting train subjects:  81%|████████  | 230/285 [06:19<01:27,  1.59s/it]predicting train subjects:  81%|████████  | 231/285 [06:21<01:23,  1.54s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:22<01:22,  1.56s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:24<01:18,  1.50s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:26<01:21,  1.60s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:27<01:16,  1.53s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:29<01:19,  1.62s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:31<01:20,  1.67s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:33<01:21,  1.73s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:34<01:18,  1.70s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:36<01:11,  1.60s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:37<01:09,  1.57s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:38<01:04,  1.51s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:40<01:01,  1.47s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:42<01:05,  1.59s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:43<01:00,  1.51s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:45<01:02,  1.60s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:47<01:04,  1.69s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:48<01:01,  1.66s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:50<00:57,  1.60s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:51<00:54,  1.57s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:53<00:52,  1.54s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:54<00:49,  1.49s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:56<00:51,  1.62s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:58<00:52,  1.71s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:00<00:51,  1.70s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:01<00:47,  1.62s/it]predicting train subjects:  90%|█████████ | 257/285 [07:03<00:44,  1.60s/it]predicting train subjects:  91%|█████████ | 258/285 [07:04<00:45,  1.70s/it]predicting train subjects:  91%|█████████ | 259/285 [07:06<00:44,  1.73s/it]predicting train subjects:  91%|█████████ | 260/285 [07:08<00:40,  1.63s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:09<00:38,  1.61s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:11<00:35,  1.54s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:12<00:32,  1.49s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:14<00:34,  1.63s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:16<00:33,  1.70s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:17<00:30,  1.61s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:19<00:28,  1.58s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:21<00:28,  1.68s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:22<00:27,  1.70s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:24<00:24,  1.62s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:25<00:21,  1.57s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:27<00:21,  1.62s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:28<00:18,  1.56s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:30<00:16,  1.53s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:32<00:16,  1.65s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:34<00:15,  1.72s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:35<00:12,  1.62s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:37<00:11,  1.58s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:38<00:09,  1.61s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:40<00:07,  1.57s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:41<00:06,  1.55s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:43<00:04,  1.53s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:45<00:03,  1.64s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:47<00:01,  1.72s/it]predicting train subjects: 100%|██████████| 285/285 [07:48<00:00,  1.79s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<09:03,  1.91s/it]Loading train:   1%|          | 2/285 [00:03<08:39,  1.84s/it]Loading train:   1%|          | 3/285 [00:05<08:21,  1.78s/it]Loading train:   1%|▏         | 4/285 [00:06<07:56,  1.69s/it]Loading train:   2%|▏         | 5/285 [00:08<08:02,  1.72s/it]Loading train:   2%|▏         | 6/285 [00:10<07:54,  1.70s/it]Loading train:   2%|▏         | 7/285 [00:11<07:58,  1.72s/it]Loading train:   3%|▎         | 8/285 [00:13<07:38,  1.66s/it]Loading train:   3%|▎         | 9/285 [00:15<07:54,  1.72s/it]Loading train:   4%|▎         | 10/285 [00:17<08:17,  1.81s/it]Loading train:   4%|▍         | 11/285 [00:18<07:25,  1.63s/it]Loading train:   4%|▍         | 12/285 [00:19<07:11,  1.58s/it]Loading train:   5%|▍         | 13/285 [00:21<06:41,  1.48s/it]Loading train:   5%|▍         | 14/285 [00:22<06:30,  1.44s/it]Loading train:   5%|▌         | 15/285 [00:24<06:38,  1.48s/it]Loading train:   6%|▌         | 16/285 [00:25<07:06,  1.59s/it]Loading train:   6%|▌         | 17/285 [00:27<06:47,  1.52s/it]Loading train:   6%|▋         | 18/285 [00:28<06:19,  1.42s/it]Loading train:   7%|▋         | 19/285 [00:29<06:02,  1.36s/it]Loading train:   7%|▋         | 20/285 [00:31<05:56,  1.34s/it]Loading train:   7%|▋         | 21/285 [00:32<06:04,  1.38s/it]Loading train:   8%|▊         | 22/285 [00:33<05:54,  1.35s/it]Loading train:   8%|▊         | 23/285 [00:35<05:58,  1.37s/it]Loading train:   8%|▊         | 24/285 [00:36<05:56,  1.37s/it]Loading train:   9%|▉         | 25/285 [00:38<05:59,  1.38s/it]Loading train:   9%|▉         | 26/285 [00:39<06:00,  1.39s/it]Loading train:   9%|▉         | 27/285 [00:40<05:35,  1.30s/it]Loading train:  10%|▉         | 28/285 [00:41<05:29,  1.28s/it]Loading train:  10%|█         | 29/285 [00:43<05:38,  1.32s/it]Loading train:  11%|█         | 30/285 [00:44<06:15,  1.47s/it]Loading train:  11%|█         | 31/285 [00:46<06:26,  1.52s/it]Loading train:  11%|█         | 32/285 [00:47<06:02,  1.43s/it]Loading train:  12%|█▏        | 33/285 [00:49<06:08,  1.46s/it]Loading train:  12%|█▏        | 34/285 [00:50<06:08,  1.47s/it]Loading train:  12%|█▏        | 35/285 [00:52<06:16,  1.51s/it]Loading train:  13%|█▎        | 36/285 [00:54<06:23,  1.54s/it]Loading train:  13%|█▎        | 37/285 [00:55<06:07,  1.48s/it]Loading train:  13%|█▎        | 38/285 [00:57<06:21,  1.54s/it]Loading train:  14%|█▎        | 39/285 [00:58<06:05,  1.49s/it]Loading train:  14%|█▍        | 40/285 [00:59<05:47,  1.42s/it]Loading train:  14%|█▍        | 41/285 [01:01<05:38,  1.39s/it]Loading train:  15%|█▍        | 42/285 [01:02<05:21,  1.32s/it]Loading train:  15%|█▌        | 43/285 [01:03<05:53,  1.46s/it]Loading train:  15%|█▌        | 44/285 [01:05<06:07,  1.52s/it]Loading train:  16%|█▌        | 45/285 [01:07<05:52,  1.47s/it]Loading train:  16%|█▌        | 46/285 [01:08<06:01,  1.51s/it]Loading train:  16%|█▋        | 47/285 [01:09<05:41,  1.43s/it]Loading train:  17%|█▋        | 48/285 [01:11<06:07,  1.55s/it]Loading train:  17%|█▋        | 49/285 [01:13<06:30,  1.65s/it]Loading train:  18%|█▊        | 50/285 [01:14<06:07,  1.57s/it]Loading train:  18%|█▊        | 51/285 [01:16<06:05,  1.56s/it]Loading train:  18%|█▊        | 52/285 [01:17<05:46,  1.49s/it]Loading train:  19%|█▊        | 53/285 [01:19<05:47,  1.50s/it]Loading train:  19%|█▉        | 54/285 [01:21<05:58,  1.55s/it]Loading train:  19%|█▉        | 55/285 [01:22<05:45,  1.50s/it]Loading train:  20%|█▉        | 56/285 [01:23<05:27,  1.43s/it]Loading train:  20%|██        | 57/285 [01:24<05:11,  1.37s/it]Loading train:  20%|██        | 58/285 [01:26<05:06,  1.35s/it]Loading train:  21%|██        | 59/285 [01:27<05:12,  1.38s/it]Loading train:  21%|██        | 60/285 [01:29<05:19,  1.42s/it]Loading train:  21%|██▏       | 61/285 [01:30<05:06,  1.37s/it]Loading train:  22%|██▏       | 62/285 [01:31<05:14,  1.41s/it]Loading train:  22%|██▏       | 63/285 [01:33<05:15,  1.42s/it]Loading train:  22%|██▏       | 64/285 [01:34<05:25,  1.47s/it]Loading train:  23%|██▎       | 65/285 [01:36<05:44,  1.57s/it]Loading train:  23%|██▎       | 66/285 [01:38<06:01,  1.65s/it]Loading train:  24%|██▎       | 67/285 [01:39<05:42,  1.57s/it]Loading train:  24%|██▍       | 68/285 [01:41<05:26,  1.51s/it]Loading train:  24%|██▍       | 69/285 [01:42<05:07,  1.42s/it]Loading train:  25%|██▍       | 70/285 [01:43<04:54,  1.37s/it]Loading train:  25%|██▍       | 71/285 [01:45<05:00,  1.40s/it]Loading train:  25%|██▌       | 72/285 [01:46<04:47,  1.35s/it]Loading train:  26%|██▌       | 73/285 [01:47<04:50,  1.37s/it]Loading train:  26%|██▌       | 74/285 [01:49<04:40,  1.33s/it]Loading train:  26%|██▋       | 75/285 [01:50<04:34,  1.31s/it]Loading train:  27%|██▋       | 76/285 [01:51<04:27,  1.28s/it]Loading train:  27%|██▋       | 77/285 [01:52<04:27,  1.29s/it]Loading train:  27%|██▋       | 78/285 [01:54<04:23,  1.27s/it]Loading train:  28%|██▊       | 79/285 [01:55<04:30,  1.31s/it]Loading train:  28%|██▊       | 80/285 [01:57<04:40,  1.37s/it]Loading train:  28%|██▊       | 81/285 [01:58<04:34,  1.35s/it]Loading train:  29%|██▉       | 82/285 [02:00<04:59,  1.48s/it]Loading train:  29%|██▉       | 83/285 [02:01<04:52,  1.45s/it]Loading train:  29%|██▉       | 84/285 [02:03<05:02,  1.50s/it]Loading train:  30%|██▉       | 85/285 [02:04<04:56,  1.48s/it]Loading train:  30%|███       | 86/285 [02:06<04:52,  1.47s/it]Loading train:  31%|███       | 87/285 [02:07<04:46,  1.45s/it]Loading train:  31%|███       | 88/285 [02:08<04:35,  1.40s/it]Loading train:  31%|███       | 89/285 [02:10<04:30,  1.38s/it]Loading train:  32%|███▏      | 90/285 [02:11<04:47,  1.48s/it]Loading train:  32%|███▏      | 91/285 [02:13<04:43,  1.46s/it]Loading train:  32%|███▏      | 92/285 [02:14<04:40,  1.45s/it]Loading train:  33%|███▎      | 93/285 [02:15<04:27,  1.40s/it]Loading train:  33%|███▎      | 94/285 [02:17<04:38,  1.46s/it]Loading train:  33%|███▎      | 95/285 [02:19<04:40,  1.48s/it]Loading train:  34%|███▎      | 96/285 [02:20<04:35,  1.46s/it]Loading train:  34%|███▍      | 97/285 [02:21<04:31,  1.45s/it]Loading train:  34%|███▍      | 98/285 [02:23<04:28,  1.44s/it]Loading train:  35%|███▍      | 99/285 [02:24<04:22,  1.41s/it]Loading train:  35%|███▌      | 100/285 [02:26<04:30,  1.46s/it]Loading train:  35%|███▌      | 101/285 [02:27<04:26,  1.45s/it]Loading train:  36%|███▌      | 102/285 [02:28<04:22,  1.43s/it]Loading train:  36%|███▌      | 103/285 [02:30<04:21,  1.44s/it]Loading train:  36%|███▋      | 104/285 [02:31<04:17,  1.42s/it]Loading train:  37%|███▋      | 105/285 [02:33<04:04,  1.36s/it]Loading train:  37%|███▋      | 106/285 [02:34<03:58,  1.33s/it]Loading train:  38%|███▊      | 107/285 [02:35<04:05,  1.38s/it]Loading train:  38%|███▊      | 108/285 [02:38<04:52,  1.65s/it]Loading train:  38%|███▊      | 109/285 [02:39<05:04,  1.73s/it]Loading train:  39%|███▊      | 110/285 [02:41<04:57,  1.70s/it]Loading train:  39%|███▉      | 111/285 [02:43<05:03,  1.74s/it]Loading train:  39%|███▉      | 112/285 [02:44<04:49,  1.67s/it]Loading train:  40%|███▉      | 113/285 [02:46<04:41,  1.63s/it]Loading train:  40%|████      | 114/285 [02:48<04:44,  1.66s/it]Loading train:  40%|████      | 115/285 [02:49<04:32,  1.60s/it]Loading train:  41%|████      | 116/285 [02:51<04:25,  1.57s/it]Loading train:  41%|████      | 117/285 [02:52<04:19,  1.54s/it]Loading train:  41%|████▏     | 118/285 [02:54<04:08,  1.49s/it]Loading train:  42%|████▏     | 119/285 [02:56<04:35,  1.66s/it]Loading train:  42%|████▏     | 120/285 [02:57<04:08,  1.51s/it]Loading train:  42%|████▏     | 121/285 [02:58<04:15,  1.56s/it]Loading train:  43%|████▎     | 122/285 [03:00<04:12,  1.55s/it]Loading train:  43%|████▎     | 123/285 [03:01<04:07,  1.53s/it]Loading train:  44%|████▎     | 124/285 [03:03<04:17,  1.60s/it]Loading train:  44%|████▍     | 125/285 [03:04<03:55,  1.47s/it]Loading train:  44%|████▍     | 126/285 [03:05<03:33,  1.34s/it]Loading train:  45%|████▍     | 127/285 [03:07<03:20,  1.27s/it]Loading train:  45%|████▍     | 128/285 [03:08<03:17,  1.26s/it]Loading train:  45%|████▌     | 129/285 [03:09<03:14,  1.25s/it]Loading train:  46%|████▌     | 130/285 [03:10<03:12,  1.24s/it]Loading train:  46%|████▌     | 131/285 [03:11<03:11,  1.24s/it]Loading train:  46%|████▋     | 132/285 [03:13<03:10,  1.25s/it]Loading train:  47%|████▋     | 133/285 [03:14<03:11,  1.26s/it]Loading train:  47%|████▋     | 134/285 [03:15<03:03,  1.21s/it]Loading train:  47%|████▋     | 135/285 [03:16<03:03,  1.22s/it]Loading train:  48%|████▊     | 136/285 [03:17<02:58,  1.20s/it]Loading train:  48%|████▊     | 137/285 [03:19<03:03,  1.24s/it]Loading train:  48%|████▊     | 138/285 [03:20<03:04,  1.25s/it]Loading train:  49%|████▉     | 139/285 [03:22<03:10,  1.31s/it]Loading train:  49%|████▉     | 140/285 [03:23<03:01,  1.25s/it]Loading train:  49%|████▉     | 141/285 [03:24<02:59,  1.24s/it]Loading train:  50%|████▉     | 142/285 [03:25<02:59,  1.25s/it]Loading train:  50%|█████     | 143/285 [03:26<02:52,  1.21s/it]Loading train:  51%|█████     | 144/285 [03:28<02:51,  1.21s/it]Loading train:  51%|█████     | 145/285 [03:28<02:39,  1.14s/it]Loading train:  51%|█████     | 146/285 [03:30<02:39,  1.15s/it]Loading train:  52%|█████▏    | 147/285 [03:31<02:39,  1.16s/it]Loading train:  52%|█████▏    | 148/285 [03:32<02:45,  1.21s/it]Loading train:  52%|█████▏    | 149/285 [03:33<02:44,  1.21s/it]Loading train:  53%|█████▎    | 150/285 [03:35<02:45,  1.23s/it]Loading train:  53%|█████▎    | 151/285 [03:36<02:43,  1.22s/it]Loading train:  53%|█████▎    | 152/285 [03:37<02:37,  1.19s/it]Loading train:  54%|█████▎    | 153/285 [03:38<02:34,  1.17s/it]Loading train:  54%|█████▍    | 154/285 [03:39<02:34,  1.18s/it]Loading train:  54%|█████▍    | 155/285 [03:40<02:27,  1.14s/it]Loading train:  55%|█████▍    | 156/285 [03:42<02:34,  1.20s/it]Loading train:  55%|█████▌    | 157/285 [03:43<02:25,  1.14s/it]Loading train:  55%|█████▌    | 158/285 [03:44<02:30,  1.19s/it]Loading train:  56%|█████▌    | 159/285 [03:45<02:31,  1.20s/it]Loading train:  56%|█████▌    | 160/285 [03:46<02:32,  1.22s/it]Loading train:  56%|█████▋    | 161/285 [03:48<02:27,  1.19s/it]Loading train:  57%|█████▋    | 162/285 [03:49<02:26,  1.19s/it]Loading train:  57%|█████▋    | 163/285 [03:50<02:26,  1.20s/it]Loading train:  58%|█████▊    | 164/285 [03:51<02:32,  1.26s/it]Loading train:  58%|█████▊    | 165/285 [03:53<02:28,  1.24s/it]Loading train:  58%|█████▊    | 166/285 [03:54<02:23,  1.20s/it]Loading train:  59%|█████▊    | 167/285 [03:55<02:37,  1.34s/it]Loading train:  59%|█████▉    | 168/285 [03:57<02:33,  1.31s/it]Loading train:  59%|█████▉    | 169/285 [03:58<02:32,  1.31s/it]Loading train:  60%|█████▉    | 170/285 [03:59<02:28,  1.29s/it]Loading train:  60%|██████    | 171/285 [04:00<02:20,  1.23s/it]Loading train:  60%|██████    | 172/285 [04:02<02:25,  1.29s/it]Loading train:  61%|██████    | 173/285 [04:03<02:23,  1.28s/it]Loading train:  61%|██████    | 174/285 [04:04<02:17,  1.24s/it]Loading train:  61%|██████▏   | 175/285 [04:05<02:17,  1.25s/it]Loading train:  62%|██████▏   | 176/285 [04:07<02:20,  1.28s/it]Loading train:  62%|██████▏   | 177/285 [04:08<02:17,  1.28s/it]Loading train:  62%|██████▏   | 178/285 [04:09<02:13,  1.25s/it]Loading train:  63%|██████▎   | 179/285 [04:10<02:10,  1.23s/it]Loading train:  63%|██████▎   | 180/285 [04:12<02:15,  1.29s/it]Loading train:  64%|██████▎   | 181/285 [04:13<02:12,  1.28s/it]Loading train:  64%|██████▍   | 182/285 [04:14<02:13,  1.29s/it]Loading train:  64%|██████▍   | 183/285 [04:16<02:08,  1.26s/it]Loading train:  65%|██████▍   | 184/285 [04:17<02:04,  1.24s/it]Loading train:  65%|██████▍   | 185/285 [04:18<02:01,  1.21s/it]Loading train:  65%|██████▌   | 186/285 [04:19<02:08,  1.29s/it]Loading train:  66%|██████▌   | 187/285 [04:21<02:11,  1.34s/it]Loading train:  66%|██████▌   | 188/285 [04:22<02:09,  1.34s/it]Loading train:  66%|██████▋   | 189/285 [04:23<02:05,  1.31s/it]Loading train:  67%|██████▋   | 190/285 [04:24<01:59,  1.25s/it]Loading train:  67%|██████▋   | 191/285 [04:26<01:55,  1.23s/it]Loading train:  67%|██████▋   | 192/285 [04:27<01:55,  1.24s/it]Loading train:  68%|██████▊   | 193/285 [04:28<01:51,  1.22s/it]Loading train:  68%|██████▊   | 194/285 [04:29<01:49,  1.21s/it]Loading train:  68%|██████▊   | 195/285 [04:31<01:52,  1.25s/it]Loading train:  69%|██████▉   | 196/285 [04:32<01:57,  1.32s/it]Loading train:  69%|██████▉   | 197/285 [04:33<01:54,  1.30s/it]Loading train:  69%|██████▉   | 198/285 [04:35<01:54,  1.32s/it]Loading train:  70%|██████▉   | 199/285 [04:36<01:52,  1.30s/it]Loading train:  70%|███████   | 200/285 [04:37<01:43,  1.22s/it]Loading train:  71%|███████   | 201/285 [04:39<01:51,  1.33s/it]Loading train:  71%|███████   | 202/285 [04:40<01:46,  1.29s/it]Loading train:  71%|███████   | 203/285 [04:41<01:44,  1.28s/it]Loading train:  72%|███████▏  | 204/285 [04:42<01:43,  1.28s/it]Loading train:  72%|███████▏  | 205/285 [04:43<01:39,  1.24s/it]Loading train:  72%|███████▏  | 206/285 [04:45<01:38,  1.24s/it]Loading train:  73%|███████▎  | 207/285 [04:46<01:43,  1.32s/it]Loading train:  73%|███████▎  | 208/285 [04:48<01:42,  1.34s/it]Loading train:  73%|███████▎  | 209/285 [04:49<01:42,  1.35s/it]Loading train:  74%|███████▎  | 210/285 [04:50<01:37,  1.30s/it]Loading train:  74%|███████▍  | 211/285 [04:51<01:30,  1.23s/it]Loading train:  74%|███████▍  | 212/285 [04:53<01:32,  1.27s/it]Loading train:  75%|███████▍  | 213/285 [04:54<01:29,  1.24s/it]Loading train:  75%|███████▌  | 214/285 [04:55<01:25,  1.21s/it]Loading train:  75%|███████▌  | 215/285 [04:56<01:27,  1.26s/it]Loading train:  76%|███████▌  | 216/285 [04:57<01:23,  1.21s/it]Loading train:  76%|███████▌  | 217/285 [04:59<01:26,  1.27s/it]Loading train:  76%|███████▋  | 218/285 [05:00<01:26,  1.29s/it]Loading train:  77%|███████▋  | 219/285 [05:02<01:27,  1.32s/it]Loading train:  77%|███████▋  | 220/285 [05:03<01:22,  1.27s/it]Loading train:  78%|███████▊  | 221/285 [05:04<01:19,  1.24s/it]Loading train:  78%|███████▊  | 222/285 [05:05<01:19,  1.27s/it]Loading train:  78%|███████▊  | 223/285 [05:06<01:15,  1.22s/it]Loading train:  79%|███████▊  | 224/285 [05:08<01:23,  1.37s/it]Loading train:  79%|███████▉  | 225/285 [05:09<01:19,  1.33s/it]Loading train:  79%|███████▉  | 226/285 [05:10<01:16,  1.30s/it]Loading train:  80%|███████▉  | 227/285 [05:12<01:12,  1.25s/it]Loading train:  80%|████████  | 228/285 [05:13<01:16,  1.34s/it]Loading train:  80%|████████  | 229/285 [05:15<01:15,  1.35s/it]Loading train:  81%|████████  | 230/285 [05:16<01:16,  1.40s/it]Loading train:  81%|████████  | 231/285 [05:17<01:10,  1.30s/it]Loading train:  81%|████████▏ | 232/285 [05:18<01:04,  1.22s/it]Loading train:  82%|████████▏ | 233/285 [05:19<00:59,  1.14s/it]Loading train:  82%|████████▏ | 234/285 [05:20<00:58,  1.16s/it]Loading train:  82%|████████▏ | 235/285 [05:21<00:56,  1.13s/it]Loading train:  83%|████████▎ | 236/285 [05:23<00:56,  1.16s/it]Loading train:  83%|████████▎ | 237/285 [05:24<00:56,  1.17s/it]Loading train:  84%|████████▎ | 238/285 [05:25<00:52,  1.12s/it]Loading train:  84%|████████▍ | 239/285 [05:26<00:50,  1.10s/it]Loading train:  84%|████████▍ | 240/285 [05:27<00:47,  1.06s/it]Loading train:  85%|████████▍ | 241/285 [05:28<00:43,  1.00it/s]Loading train:  85%|████████▍ | 242/285 [05:28<00:40,  1.06it/s]Loading train:  85%|████████▌ | 243/285 [05:29<00:40,  1.03it/s]Loading train:  86%|████████▌ | 244/285 [05:31<00:41,  1.00s/it]Loading train:  86%|████████▌ | 245/285 [05:32<00:39,  1.02it/s]Loading train:  86%|████████▋ | 246/285 [05:33<00:39,  1.02s/it]Loading train:  87%|████████▋ | 247/285 [05:34<00:41,  1.08s/it]Loading train:  87%|████████▋ | 248/285 [05:35<00:39,  1.06s/it]Loading train:  87%|████████▋ | 249/285 [05:36<00:36,  1.02s/it]Loading train:  88%|████████▊ | 250/285 [05:37<00:35,  1.00s/it]Loading train:  88%|████████▊ | 251/285 [05:38<00:33,  1.01it/s]Loading train:  88%|████████▊ | 252/285 [05:39<00:31,  1.04it/s]Loading train:  89%|████████▉ | 253/285 [05:40<00:33,  1.05s/it]Loading train:  89%|████████▉ | 254/285 [05:41<00:32,  1.04s/it]Loading train:  89%|████████▉ | 255/285 [05:42<00:29,  1.02it/s]Loading train:  90%|████████▉ | 256/285 [05:42<00:26,  1.09it/s]Loading train:  90%|█████████ | 257/285 [05:43<00:25,  1.11it/s]Loading train:  91%|█████████ | 258/285 [05:44<00:25,  1.05it/s]Loading train:  91%|█████████ | 259/285 [05:45<00:25,  1.04it/s]Loading train:  91%|█████████ | 260/285 [05:46<00:23,  1.06it/s]Loading train:  92%|█████████▏| 261/285 [05:47<00:22,  1.08it/s]Loading train:  92%|█████████▏| 262/285 [05:48<00:20,  1.10it/s]Loading train:  92%|█████████▏| 263/285 [05:49<00:21,  1.04it/s]Loading train:  93%|█████████▎| 264/285 [05:50<00:20,  1.01it/s]Loading train:  93%|█████████▎| 265/285 [05:51<00:20,  1.02s/it]Loading train:  93%|█████████▎| 266/285 [05:52<00:18,  1.00it/s]Loading train:  94%|█████████▎| 267/285 [05:53<00:17,  1.01it/s]Loading train:  94%|█████████▍| 268/285 [05:54<00:17,  1.05s/it]Loading train:  94%|█████████▍| 269/285 [05:56<00:17,  1.07s/it]Loading train:  95%|█████████▍| 270/285 [05:57<00:15,  1.05s/it]Loading train:  95%|█████████▌| 271/285 [05:57<00:14,  1.00s/it]Loading train:  95%|█████████▌| 272/285 [05:59<00:13,  1.03s/it]Loading train:  96%|█████████▌| 273/285 [05:59<00:12,  1.00s/it]Loading train:  96%|█████████▌| 274/285 [06:00<00:10,  1.03it/s]Loading train:  96%|█████████▋| 275/285 [06:01<00:09,  1.01it/s]Loading train:  97%|█████████▋| 276/285 [06:02<00:08,  1.00it/s]Loading train:  97%|█████████▋| 277/285 [06:03<00:07,  1.04it/s]Loading train:  98%|█████████▊| 278/285 [06:04<00:06,  1.08it/s]Loading train:  98%|█████████▊| 279/285 [06:05<00:05,  1.06it/s]Loading train:  98%|█████████▊| 280/285 [06:06<00:04,  1.04it/s]Loading train:  99%|█████████▊| 281/285 [06:07<00:03,  1.09it/s]Loading train:  99%|█████████▉| 282/285 [06:08<00:02,  1.13it/s]Loading train:  99%|█████████▉| 283/285 [06:09<00:01,  1.04it/s]Loading train: 100%|█████████▉| 284/285 [06:10<00:01,  1.01s/it]Loading train: 100%|██████████| 285/285 [06:11<00:00,  1.06s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:04, 66.07it/s]concatenating: train:   7%|▋         | 19/285 [00:00<00:03, 75.94it/s]concatenating: train:  16%|█▌        | 45/285 [00:00<00:02, 96.14it/s]concatenating: train:  25%|██▌       | 72/285 [00:00<00:01, 118.71it/s]concatenating: train:  35%|███▍      | 99/285 [00:00<00:01, 142.08it/s]concatenating: train:  44%|████▍     | 126/285 [00:00<00:00, 165.17it/s]concatenating: train:  52%|█████▏    | 148/285 [00:00<00:00, 164.41it/s]concatenating: train:  59%|█████▉    | 168/285 [00:00<00:00, 127.26it/s]concatenating: train:  65%|██████▍   | 185/285 [00:01<00:00, 135.01it/s]concatenating: train:  75%|███████▍  | 213/285 [00:01<00:00, 159.13it/s]concatenating: train:  86%|████████▌ | 244/285 [00:01<00:00, 185.49it/s]concatenating: train:  97%|█████████▋| 276/285 [00:01<00:00, 211.93it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 198.70it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.53s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.48s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.41s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 58.36it/s]2019-07-09 06:50:25.522766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-09 06:50:25.522867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-09 06:50:25.522881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-09 06:50:25.522890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-09 06:50:25.523298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12743 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.29it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.25it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  5.80it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.44it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.42it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.14it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.18it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.96it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.43it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.71it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.39it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  8.68it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  8.92it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.29it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.11it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.19it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.24it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.46it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.37it/s]
Epoch 00040: val_mDice did not improve from 0.57681
Restoring model weights from the end of the best epoch
Epoch 00040: early stopping
{'val_loss': [12062.556663876489, 8240.253871372768, 3261.4828752790177, 2824.9268624441966, 2673.8864397321427, 2708.1309872581846, 2660.9334774925596, 2749.1492745535716, 2689.3763020833335, 2506.1703752790177, 2601.294654482887, 2737.7801688058034, 2706.508475167411, 2638.8863699776784, 2564.2518949962796, 2523.9668317522323, 2621.0498046875, 2599.9567987351193, 2537.700950985863, 2531.6402878534227, 2654.047409784226, 2537.6043526785716, 2658.840041387649, 2542.658889043899, 2676.4786551339284, 2823.1419735863096, 2661.6317545572915, 2632.5943777901784, 2811.218947637649, 2720.955543154762, 2679.9010649181546, 2682.9656691778273, 2675.5540945870534, 2736.1593191964284, 2678.556617373512, 2768.507742745536, 2704.0585821242557, 2734.90283203125, 2723.1468098958335, 2609.1975213913693], 'val_acc': [0.9057623829160418, 0.9081707880610511, 0.9238278496833074, 0.9327678793952578, 0.9377335281599135, 0.9417193134625753, 0.9414995199158078, 0.9425366549264818, 0.9420810512134007, 0.941204221475692, 0.9395077625910441, 0.9367765386899313, 0.9418978833016896, 0.9383584913753328, 0.9399153192838033, 0.9436744565055484, 0.9419986265046256, 0.9428273808388483, 0.9416804285276503, 0.941089718114762, 0.941925341174716, 0.941275193577721, 0.9369894720259166, 0.9446542830694289, 0.944425364335378, 0.9452335380372547, 0.9429418728465125, 0.9434775795255389, 0.9440018250828698, 0.9452769869849795, 0.9417513495399839, 0.9401236346789769, 0.9423145878882635, 0.9425938555172512, 0.9416849897021339, 0.9392422040303549, 0.9425617938949948, 0.942403861454555, 0.943731685479482, 0.9428113585426694], 'val_mDice': [0.18592603959439744, 0.3203197698827959, 0.49496755429676603, 0.5389539869058699, 0.5566883974132084, 0.5526215437622297, 0.5597374077354159, 0.550062660305273, 0.5563678711297966, 0.5768097708267825, 0.5681129672697612, 0.5531295961922124, 0.556559104295004, 0.5613279640674591, 0.5717121951636814, 0.5737898518287, 0.5631992022196451, 0.5669295791359175, 0.5730652970572313, 0.573745946621611, 0.5611183712525027, 0.5723486846046788, 0.5593059857686361, 0.5727500592668852, 0.5583013414981819, 0.5397954859903881, 0.5609678508979934, 0.5620243533381394, 0.543180297882784, 0.5510952932139238, 0.5571665380682264, 0.5560449095708984, 0.5566630806951296, 0.5517529935709068, 0.5561266193787257, 0.5465006478840396, 0.553637716741789, 0.5513656373534884, 0.5528890838225683, 0.5642546532409531], 'loss': [12757.501433873145, 4268.056966192901, 3054.545497278729, 2537.6696557066493, 2264.879765143026, 2088.6492323337643, 1973.526324638218, 1885.6123177958793, 1817.731455855685, 1763.4941113488348, 1713.7988389741256, 1665.3240623908027, 1624.4203411548704, 1604.181051877553, 1562.939414647082, 1542.879585861815, 1511.2155497197773, 1479.1330222105369, 1472.649768765363, 1447.498084011486, 1432.464136838867, 1411.5072648191995, 1400.7905670807315, 1386.7436388823621, 1368.8130273828162, 1353.931572353171, 1344.6096069265336, 1320.3680513586776, 1313.2413037551812, 1314.3581477191515, 1293.3480103527486, 1282.3163044659048, 1262.8822600653527, 1262.6470777233235, 1255.5678906268827, 1245.5910849040797, 1243.8539084998404, 1225.7481054390973, 1218.2189412011285, 1216.6400241090632], 'acc': [0.6868263237596317, 0.8810502834372468, 0.8951923788133926, 0.9110442294834528, 0.9234766585072594, 0.9313904227883181, 0.935089686587065, 0.937337239204125, 0.9387011126169286, 0.9400221879527775, 0.9412181987016904, 0.9419396085869676, 0.9428076478978539, 0.9431932975681894, 0.9439322927771723, 0.9443128907039304, 0.9449588967376255, 0.9455699635213892, 0.9456620495489896, 0.9460548824351119, 0.946351500542977, 0.9467405804738342, 0.9468607266720995, 0.9472215360176685, 0.9476328572832552, 0.9478321577947861, 0.9478562824271515, 0.9483067889721012, 0.9486144397193029, 0.9484444523170226, 0.9488104517942039, 0.9490251848870949, 0.9493252614892607, 0.9493424749935159, 0.9495125332847597, 0.9496133551906477, 0.9496875511030253, 0.9500030115410522, 0.9501313610827966, 0.9501876222942522], 'mDice': [0.14130126373924592, 0.42760049189035665, 0.5391986541190036, 0.5979451359938582, 0.63135514441818, 0.6541796374785227, 0.6695069464066136, 0.6812675258132886, 0.6905851987646061, 0.6981864251427644, 0.705096166924932, 0.7118994008605366, 0.7177165338407943, 0.7206354403463613, 0.7266538852737063, 0.7295576545781705, 0.7342189025828345, 0.7389592134770985, 0.7399506772761862, 0.7436070386122848, 0.7459284454176186, 0.7490593330442319, 0.750713488948536, 0.7528633616989647, 0.7555950219538806, 0.7578238585056403, 0.7592322875912396, 0.7630594355167855, 0.7641316002128165, 0.7639656380373365, 0.7672289623928272, 0.7689444811927438, 0.7719510878490671, 0.771996190489568, 0.7731557861789242, 0.7746290763449021, 0.7749156523284044, 0.7777916481206705, 0.7789851444659721, 0.7792216331048212]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 10)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 11)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   2000        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 10)   5410        dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 52, 10)   40          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 52, 10)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 52, 10)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 52, 70)   0           dropout_6[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 52, 13)   923         concatenate_8[0][0]              
==================================================================================================
Total params: 231,353
Trainable params: 56,633
Non-trainable params: 174,720
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 30s - loss: 10474.2794 - acc: 0.7456 - mDice: 0.2164 - val_loss: 5163.3764 - val_acc: 0.9177 - val_mDice: 0.3536

Epoch 00001: val_mDice improved from -inf to 0.35360, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 21s - loss: 3369.8337 - acc: 0.9082 - mDice: 0.5118 - val_loss: 2935.4759 - val_acc: 0.9366 - val_mDice: 0.5380

Epoch 00002: val_mDice improved from 0.35360 to 0.53797, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 23s - loss: 2570.1056 - acc: 0.9249 - mDice: 0.5971 - val_loss: 2670.4139 - val_acc: 0.9461 - val_mDice: 0.5565

Epoch 00003: val_mDice improved from 0.53797 to 0.55645, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 23s - loss: 2280.3570 - acc: 0.9384 - mDice: 0.6317 - val_loss: 2263.3369 - val_acc: 0.9525 - val_mDice: 0.6086

Epoch 00004: val_mDice improved from 0.55645 to 0.60865, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 22s - loss: 2118.7051 - acc: 0.9433 - mDice: 0.6516 - val_loss: 2444.3221 - val_acc: 0.9519 - val_mDice: 0.5974

Epoch 00005: val_mDice did not improve from 0.60865
Epoch 6/300
 - 22s - loss: 2002.5524 - acc: 0.9454 - mDice: 0.6664 - val_loss: 2374.6473 - val_acc: 0.9525 - val_mDice: 0.6042

Epoch 00006: val_mDice did not improve from 0.60865
Epoch 7/300
 - 23s - loss: 1923.2329 - acc: 0.9468 - mDice: 0.6770 - val_loss: 2281.3154 - val_acc: 0.9532 - val_mDice: 0.6170

Epoch 00007: val_mDice improved from 0.60865 to 0.61702, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 21s - loss: 1854.6896 - acc: 0.9477 - mDice: 0.6861 - val_loss: 2118.8838 - val_acc: 0.9531 - val_mDice: 0.6258

Epoch 00008: val_mDice improved from 0.61702 to 0.62581, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 22s - loss: 1815.7455 - acc: 0.9486 - mDice: 0.6918 - val_loss: 2139.6302 - val_acc: 0.9553 - val_mDice: 0.6249

Epoch 00009: val_mDice did not improve from 0.62581
Epoch 10/300
 - 21s - loss: 1762.3628 - acc: 0.9493 - mDice: 0.6989 - val_loss: 2160.1374 - val_acc: 0.9513 - val_mDice: 0.6218

Epoch 00010: val_mDice did not improve from 0.62581
Epoch 11/300
 - 23s - loss: 1719.1950 - acc: 0.9500 - mDice: 0.7050 - val_loss: 2162.8625 - val_acc: 0.9534 - val_mDice: 0.6181

Epoch 00011: val_mDice did not improve from 0.62581
Epoch 12/300
 - 22s - loss: 1698.4440 - acc: 0.9503 - mDice: 0.7080 - val_loss: 2136.1852 - val_acc: 0.9528 - val_mDice: 0.6221

Epoch 00012: val_mDice did not improve from 0.62581
Epoch 13/300
 - 22s - loss: 1661.2134 - acc: 0.9508 - mDice: 0.7132 - val_loss: 2225.8997 - val_acc: 0.9544 - val_mDice: 0.6169

Epoch 00013: val_mDice did not improve from 0.62581
Epoch 14/300
 - 21s - loss: 1639.3144 - acc: 0.9511 - mDice: 0.7164 - val_loss: 2272.9527 - val_acc: 0.9545 - val_mDice: 0.6155

Epoch 00014: val_mDice did not improve from 0.62581
Epoch 15/300
 - 22s - loss: 1610.3276 - acc: 0.9515 - mDice: 0.7205 - val_loss: 2157.9272 - val_acc: 0.9545 - val_mDice: 0.6289

Epoch 00015: val_mDice improved from 0.62581 to 0.62890, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 22s - loss: 1584.2711 - acc: 0.9518 - mDice: 0.7241 - val_loss: 2227.0698 - val_acc: 0.9524 - val_mDice: 0.6113

Epoch 00016: val_mDice did not improve from 0.62890
Epoch 17/300
 - 22s - loss: 1583.4163 - acc: 0.9519 - mDice: 0.7245 - val_loss: 2191.5179 - val_acc: 0.9541 - val_mDice: 0.6197

Epoch 00017: val_mDice did not improve from 0.62890
Epoch 18/300
 - 22s - loss: 1543.6695 - acc: 0.9524 - mDice: 0.7301 - val_loss: 2179.9063 - val_acc: 0.9545 - val_mDice: 0.6174

Epoch 00018: val_mDice did not improve from 0.62890
Epoch 19/300
 - 23s - loss: 1536.3775 - acc: 0.9526 - mDice: 0.7312 - val_loss: 2245.1107 - val_acc: 0.9533 - val_mDice: 0.6095

Epoch 00019: val_mDice did not improve from 0.62890
Epoch 20/300
 - 23s - loss: 1519.8196 - acc: 0.9528 - mDice: 0.7337 - val_loss: 2192.3592 - val_acc: 0.9528 - val_mDice: 0.6172

Epoch 00020: val_mDice did not improve from 0.62890
Epoch 21/300
 - 22s - loss: 1501.7078 - acc: 0.9531 - mDice: 0.7363 - val_loss: 2209.3240 - val_acc: 0.9538 - val_mDice: 0.6177

Epoch 00021: val_mDice did not improve from 0.62890
Epoch 22/300
 - 22s - loss: 1482.7871 - acc: 0.9534 - mDice: 0.7392 - val_loss: 2099.4189 - val_acc: 0.9537 - val_mDice: 0.6284

Epoch 00022: val_mDice did not improve from 0.62890
Epoch 23/300
 - 22s - loss: 1475.6724 - acc: 0.9534 - mDice: 0.7401 - val_loss: 2185.6241 - val_acc: 0.9538 - val_mDice: 0.6198

Epoch 00023: val_mDice did not improve from 0.62890
Epoch 24/300
 - 23s - loss: 1461.3022 - acc: 0.9536 - mDice: 0.7423 - val_loss: 2145.7892 - val_acc: 0.9540 - val_mDice: 0.6227

Epoch 00024: val_mDice did not improve from 0.62890
Epoch 25/300
 - 21s - loss: 1448.9752 - acc: 0.9538 - mDice: 0.7441 - val_loss: 2176.9974 - val_acc: 0.9547 - val_mDice: 0.6190

Epoch 00025: val_mDice did not improve from 0.62890
Epoch 26/300
 - 23s - loss: 1441.6487 - acc: 0.9538 - mDice: 0.7453 - val_loss: 2162.3537 - val_acc: 0.9542 - val_mDice: 0.6207

Epoch 00026: val_mDice did not improve from 0.62890
Epoch 27/300
 - 22s - loss: 1422.6477 - acc: 0.9541 - mDice: 0.7481 - val_loss: 2092.5487 - val_acc: 0.9520 - val_mDice: 0.6279

Epoch 00027: val_mDice did not improve from 0.62890
Epoch 28/300
 - 23s - loss: 1413.4815 - acc: 0.9542 - mDice: 0.7494 - val_loss: 2245.9285 - val_acc: 0.9547 - val_mDice: 0.6141

Epoch 00028: val_mDice did not improve from 0.62890
Epoch 29/300
 - 23s - loss: 1413.1079 - acc: 0.9542 - mDice: 0.7495 - val_loss: 2250.6064 - val_acc: 0.9532 - val_mDice: 0.6108

Epoch 00029: val_mDice did not improve from 0.62890
Epoch 30/300
 - 22s - loss: 1400.6872 - acc: 0.9544 - mDice: 0.7514 - val_loss: 2144.2626 - val_acc: 0.9539 - val_mDice: 0.6235

Epoch 00030: val_mDice did not improve from 0.62890
Epoch 31/300
 - 22s - loss: 1394.5386 - acc: 0.9545 - mDice: 0.7524 - val_loss: 2252.9272 - val_acc: 0.9524 - val_mDice: 0.6105

Epoch 00031: val_mDice did not improve from 0.62890
Epoch 32/300
 - 23s - loss: 1380.0633 - acc: 0.9547 - mDice: 0.7545 - val_loss: 2218.0772 - val_acc: 0.9539 - val_mDice: 0.6164

Epoch 00032: val_mDice did not improve from 0.62890
Epoch 33/300
 - 22s - loss: 1371.2155 - acc: 0.9548 - mDice: 0.7559 - val_loss: 2157.3980 - val_acc: 0.9525 - val_mDice: 0.6193

Epoch 00033: val_mDice did not improve from 0.62890
Epoch 34/300
 - 23s - loss: 1359.5793 - acc: 0.9548 - mDice: 0.7576 - val_loss: 2179.0651 - val_acc: 0.9527 - val_mDice: 0.6181

Epoch 00034: val_mDice did not improve from 0.62890
Epoch 35/300
 - 21s - loss: 1357.6960 - acc: 0.9549 - mDice: 0.7578 - val_loss: 2375.1125 - val_acc: 0.9529 - val_mDice: 0.6025

Epoch 00035: val_mDice did not improve from 0.62890
Epoch 36/300
 - 22s - loss: 1345.7447 - acc: 0.9550 - mDice: 0.7597 - val_loss: 2177.0245 - val_acc: 0.9538 - val_mDice: 0.6185

Epoch 00036: val_mDice did not improve from 0.62890
Epoch 37/300
 - 22s - loss: 1341.6871 - acc: 0.9551 - mDice: 0.7603 - val_loss: 2247.8902 - val_acc: 0.9540 - val_mDice: 0.6111

Epoch 00037: val_mDice did not improve from 0.62890
Epoch 38/300
 - 22s - loss: 1332.8901 - acc: 0.9553 - mDice: 0.7617 - val_loss: 2291.6668 - val_acc: 0.9546 - val_mDice: 0.6073

Epoch 00038: val_mDice did not improve from 0.62890
Epoch 39/300
 - 23s - loss: 1334.9182 - acc: 0.9552 - mDice: 0.7614 - val_loss: 2132.8109 - val_acc: 0.9529 - val_mDice: 0.6238

Epoch 00039: val_mDice did not improve from 0.62890
Epoch 40/300
 - 22s - loss: 1326.4020 - acc: 0.9553 - mDice: 0.7627 - val_loss: 2406.2709 - val_acc: 0.9551 - val_mDice: 0.6008

Epoch 00040: val_mDice did not improve from 0.62890
Epoch 41/300
 - 22s - loss: 1325.2484 - acc: 0.9553 - mDice: 0.7628 - val_loss: 2211.2080 - val_acc: 0.9525 - val_mDice: 0.6136

Epoch 00041: val_mDice did not improve from 0.62890
Epoch 42/300
 - 22s - loss: 1310.6634 - acc: 0.9555 - mDice: 0.7651 - val_loss: 2045.7247 - val_acc: 0.9535 - val_mDice: 0.6326

Epoch 00042: val_mDice improved from 0.62890 to 0.63263, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 43/300
 - 22s - loss: 1315.4792 - acc: 0.9555 - mDice: 0.7644 - val_loss: 2244.3992 - val_acc: 0.9535 - val_mDice: 0.6169

Epoch 00043: val_mDice did not improve from 0.63263
Epoch 44/300
 - 22s - loss: 1305.2335 - acc: 0.9556 - mDice: 0.7659 - val_loss: 2184.7182 - val_acc: 0.9538 - val_mDice: 0.6210

Epoch 00044: val_mDice did not improve from 0.63263
Epoch 45/300
 - 22s - loss: 1303.4852 - acc: 0.9557 - mDice: 0.7662 - val_loss: 2186.5838 - val_acc: 0.9547 - val_mDice: 0.6198

Epoch 00045: val_mDice did not improve from 0.63263
Epoch 46/300
 - 21s - loss: 1295.2078 - acc: 0.9557 - mDice: 0.7674 - val_loss: 2266.4387 - val_acc: 0.9556 - val_mDice: 0.6100

Epoch 00046: val_mDice did not improve from 0.63263
Epoch 47/300
 - 22s - loss: 1289.5698 - acc: 0.9558 - mDice: 0.7683 - val_loss: 2296.6467 - val_acc: 0.9541 - val_mDice: 0.6087

Epoch 00047: val_mDice did not improve from 0.63263
Epoch 48/300
 - 22s - loss: 1282.9035 - acc: 0.9559 - mDice: 0.7694 - val_loss: 2195.2136 - val_acc: 0.9548 - val_mDice: 0.6161

Epoch 00048: val_mDice did not improve from 0.63263
Epoch 49/300
 - 22s - loss: 1285.3054 - acc: 0.9558 - mDice: 0.7690 - val_loss: 2308.0589 - val_acc: 0.9523 - val_mDice: 0.6045

Epoch 00049: val_mDice did not improve from 0.63263
Epoch 50/300
 - 23s - loss: 1285.4449 - acc: 0.9559 - mDice: 0.7689 - val_loss: 2104.1661 - val_acc: 0.9536 - val_mDice: 0.6270

Epoch 00050: val_mDice did not improve from 0.63263
Epoch 51/300
 - 22s - loss: 1277.2977 - acc: 0.9560 - mDice: 0.7703 - val_loss: 2214.9483 - val_acc: 0.9530 - val_mDice: 0.6132

Epoch 00051: val_mDice did not improve from 0.63263
Epoch 52/300
 - 22s - loss: 1266.0143 - acc: 0.9562 - mDice: 0.7720 - val_loss: 2188.3824 - val_acc: 0.9532 - val_mDice: 0.6151

Epoch 00052: val_mDice did not improve from 0.63263
Epoch 53/300
 - 22s - loss: 1269.1470 - acc: 0.9561 - mDice: 0.7716 - val_loss: 2149.5290 - val_acc: 0.9538 - val_mDice: 0.6207

Epoch 00053: val_mDice did not improve from 0.63263
Epoch 54/300
 - 22s - loss: 1262.9469 - acc: 0.9562 - mDice: 0.7725 - val_loss: 2107.5126 - val_acc: 0.9531 - val_mDice: 0.6242

Epoch 00054: val_mDice did not improve from 0.63263
Epoch 55/300
 - 23s - loss: 1259.5613 - acc: 0.9562 - mDice: 0.7730 - val_loss: 2229.2714 - val_acc: 0.9533 - val_mDice: 0.6123

Epoch 00055: val_mDice did not improve from 0.63263
Epoch 56/300
 - 22s - loss: 1258.3935 - acc: 0.9563 - mDice: 0.7734 - val_loss: 2176.0240 - val_acc: 0.9530 - val_mDice: 0.6163

Epoch 00056: val_mDice did not improve from 0.63263
Epoch 57/300
 - 21s - loss: 1249.7953 - acc: 0.9563 - mDice: 0.7745 - val_loss: 2208.6903 - val_acc: 0.9545 - val_mDice: 0.6153

Epoch 00057: val_mDice did not improve from 0.63263
Epoch 58/300
 - 22s - loss: 1246.8097 - acc: 0.9564 - mDice: 0.7750 - val_loss: 2110.0891 - val_acc: 0.9540 - val_mDice: 0.6253

Epoch 00058: val_mDice did not improve from 0.63263
Epoch 59/300
 - 22s - loss: 1244.5441 - acc: 0.9564 - mDice: 0.7753 - val_loss: 2147.4966 - val_acc: 0.9544 - val_mDice: 0.6229

Epoch 00059: val_mDice did not improve from 0.63263
Epoch 60/300
 - 23s - loss: 1244.5748 - acc: 0.9564 - mDice: 0.7753 - val_loss: 2250.2172 - val_acc: 0.9544 - val_mDice: 0.6115

Epoch 00060: val_mDice did not improve from 0.63263
Epoch 61/300
 - 22s - loss: 1242.3790 - acc: 0.9565 - mDice: 0.7757 - val_loss: 2282.5155 - val_acc: 0.9524 - val_mDice: 0.6054

Epoch 00061: val_mDice did not improve from 0.63263
Epoch 62/300
 - 22s - loss: 1236.1057 - acc: 0.9566 - mDice: 0.7767 - val_loss: 2245.6574 - val_acc: 0.9543 - val_mDice: 0.6105

Epoch 00062: val_mDice did not improve from 0.63263
Epoch 63/300
 - 22s - loss: 1231.3327 - acc: 0.9566 - mDice: 0.7774 - val_loss: 2144.5232 - val_acc: 0.9542 - val_mDice: 0.6219

Epoch 00063: val_mDice did not improve from 0.63263
Epoch 64/300
 - 22s - loss: 1234.2149 - acc: 0.9566 - mDice: 0.7770 - val_loss: 2241.2915 - val_acc: 0.9538 - val_mDice: 0.6110

Epoch 00064: val_mDice did not improve from 0.63263
Epoch 65/300
 - 22s - loss: 1231.6756 - acc: 0.9566 - mDice: 0.7773 - val_loss: 2239.6607 - val_acc: 0.9547 - val_mDice: 0.6138

Epoch 00065: val_mDice did not improve from 0.63263
Epoch 66/300
 - 22s - loss: 1220.5054 - acc: 0.9568 - mDice: 0.7791 - val_loss: 2140.4165 - val_acc: 0.9520 - val_mDice: 0.6216

Epoch 00066: val_mDice did not improve from 0.63263
Epoch 67/300
 - 21s - loss: 1218.4186 - acc: 0.9568 - mDice: 0.7795 - val_loss: 2246.7396 - val_acc: 0.9532 - val_mDice: 0.6132

Epoch 00067: val_mDice did not improve from 0.63263
Epoch 68/300
 - 21s - loss: 1223.5506 - acc: 0.9568 - mDice: 0.7787 - val_loss: 2214.8476 - val_acc: 0.9536 - val_mDice: 0.6134

Epoch 00068: val_mDice did not improve from 0.63263
Epoch 69/300
 - 21s - loss: 1221.8730 - acc: 0.9568 - mDice: 0.7789 - val_loss: 2185.0976 - val_acc: 0.9529 - val_mDice: 0.6175

Epoch 00069: val_mDice did not improve from 0.63263
Epoch 70/300
 - 22s - loss: 1219.5389 - acc: 0.9568 - mDice: 0.7793 - val_loss: 2130.1789 - val_acc: 0.9536 - val_mDice: 0.6218

Epoch 00070: val_mDice did not improve from 0.63263
Epoch 71/300
 - 22s - loss: 1214.4079 - acc: 0.9568 - mDice: 0.7801 - val_loss: 2218.4001 - val_acc: 0.9527 - val_mDice: 0.6123

Epoch 00071: val_mDice did not improve from 0.63263
Epoch 72/300
 - 22s - loss: 1208.7300 - acc: 0.9570 - mDice: 0.7810 - val_loss: 2194.8668 - val_acc: 0.9537 - val_mDice: 0.6165

Epoch 00072: val_mDice did not improve from 0.63263
Restoring model weights from the end of the best epoch
Epoch 00072: early stopping
{'val_loss': [5163.376391192388, 2935.4758873625174, 2670.4139015581354, 2263.3368922398745, 2444.322138780988, 2374.647257714298, 2281.3153587639663, 2118.8838490747207, 2139.6301583231493, 2160.1374047987956, 2162.8625461002966, 2136.185212716044, 2225.8996800257505, 2272.9527062783695, 2157.9272392741796, 2227.0697655704435, 2191.517909556128, 2179.906325015276, 2245.1106693544866, 2192.3592413364177, 2209.3239718815466, 2099.418909850733, 2185.6240807218924, 2145.7892357170913, 2176.997446752793, 2162.353679294693, 2092.548687641847, 2245.9284708886175, 2250.60641530639, 2144.2626162054817, 2252.9272283628666, 2218.0772166332054, 2157.397999683572, 2179.0650764337465, 2375.1124642654504, 2177.024506808659, 2247.890228100995, 2291.666761686016, 2132.810891945269, 2406.270918350646, 2211.2080309990397, 2045.724699393331, 2244.3991890166726, 2184.7182180734985, 2186.5838097939945, 2266.4386893331007, 2296.646698509515, 2195.21363804993, 2308.0588719884777, 2104.166056542423, 2214.9482967440645, 2188.3824469710194, 2149.5290090891235, 2107.5126134776538, 2229.2714120875526, 2176.0239844295565, 2208.6903342135124, 2110.089111328125, 2147.4965861229925, 2250.2172428749127, 2282.515458602479, 2245.657420238303, 2144.523157897608, 2241.291479355796, 2239.660734549581, 2140.416514817563, 2246.739613794082, 2214.847589418209, 2185.0975880542946, 2130.1788664237083, 2218.4000769247555, 2194.866791964909], 'val_acc': [0.917692795146111, 0.9366033476824202, 0.9460637772549464, 0.9525180861936601, 0.9519251441822372, 0.9524995241751218, 0.9531875179466589, 0.9531337825279662, 0.9552865980723717, 0.9512660809735346, 0.9534023460729162, 0.9528238929849763, 0.9543548109811112, 0.9544622415270885, 0.9544911714239493, 0.9524499101345766, 0.9541275388035695, 0.9544519102773187, 0.9532949175248598, 0.9527887279094931, 0.9538197247675677, 0.9536833699855058, 0.9537887246915082, 0.9539664177921231, 0.9546998456203738, 0.9541833174295266, 0.9520119148925696, 0.9547246584679161, 0.9532019732384708, 0.9538775689109078, 0.9523631520777441, 0.9539044066514383, 0.9524643870705333, 0.9526523884448259, 0.9529023646642376, 0.9537515460445894, 0.9540304365104804, 0.9546316362626059, 0.9528899975329138, 0.9550903529428237, 0.9525160399895141, 0.9535263293948253, 0.9535366776269242, 0.9537597974585421, 0.9546853723472724, 0.9556399041047975, 0.954071752518915, 0.9548217214685578, 0.95226398027143, 0.9536378746592132, 0.9530201517669848, 0.9531626847869191, 0.9537783924427778, 0.9531027854487882, 0.9533486542754999, 0.9529602484330119, 0.9545263048656826, 0.9539622751028178, 0.954441595676891, 0.9543899271075286, 0.9524003343875181, 0.9543176250084818, 0.9541626535980395, 0.953774255081262, 0.9547122547080397, 0.9520387749432185, 0.9532246749494329, 0.9535614285389138, 0.9528734674000873, 0.9535841818628364, 0.9527370866450517, 0.9537060663686784], 'val_mDice': [0.3535982749981587, 0.5379731456993678, 0.556452575675602, 0.6086470421466081, 0.5974237892214812, 0.6041558984271641, 0.6170219602531561, 0.6258112651675773, 0.6248930792568782, 0.6218066781592768, 0.6180703679942552, 0.6220650619634703, 0.6169480947808846, 0.6155331024910484, 0.6289027399856951, 0.6113388561669675, 0.6196962884684515, 0.6174439871111396, 0.6095327185518915, 0.617169877004357, 0.6177329177963001, 0.6284397420936456, 0.6198215624473614, 0.622681443251711, 0.618985952611742, 0.6207083983128298, 0.6279307816947639, 0.6141252314578222, 0.6108252249616485, 0.6235028591901897, 0.6105271304785872, 0.6164424772369129, 0.6193431988774731, 0.6180723935532171, 0.6024766557709464, 0.6185077159098407, 0.6110601947960241, 0.6073421596148827, 0.6238192513002364, 0.600847734752314, 0.6135925261002013, 0.6326303815042507, 0.6169233162309871, 0.6210296520307743, 0.6198489109897081, 0.6099709558753328, 0.6087111427797286, 0.6160870757182884, 0.6044821912349936, 0.6269589585964906, 0.6131735820344041, 0.6151188358914252, 0.620654135109992, 0.6242112377502399, 0.6122833483711967, 0.6163021992038749, 0.6153246866924137, 0.6253393831865748, 0.6228542494374281, 0.6114874338970504, 0.605417557934809, 0.6105311659461293, 0.6219423020352198, 0.6110137604468362, 0.6138454788889964, 0.6216364133291404, 0.6131592056604737, 0.6134085615253981, 0.6175086718031814, 0.6218381487457446, 0.6123039888936048, 0.6165418884607666], 'loss': [10474.279365579025, 3369.8336858907805, 2570.1056284832025, 2280.3569985680524, 2118.70514049315, 2002.5524361966047, 1923.2329118981172, 1854.6895984512328, 1815.7454864034908, 1762.3628477511352, 1719.1949774232748, 1698.4440113252742, 1661.2134303711098, 1639.3144262955927, 1610.3275521085527, 1584.2711050634932, 1583.416254965518, 1543.6695240245756, 1536.3774698079915, 1519.8196058969834, 1501.7078421655924, 1482.7870524219293, 1475.672382494975, 1461.3021999143268, 1448.9752112532433, 1441.6486748593104, 1422.6477472519189, 1413.4815104197692, 1413.1078650139689, 1400.6871858456252, 1394.5386213056727, 1380.0632989319456, 1371.2155017668915, 1359.5793394603265, 1357.6960295808126, 1345.744657567277, 1341.687064297208, 1332.8900565928632, 1334.9182016050547, 1326.4019548681968, 1325.2484137407998, 1310.6634023456647, 1315.4792487050615, 1305.2334747139935, 1303.4851786688932, 1295.2078285531004, 1289.5698346832494, 1282.9035423939072, 1285.3054233324774, 1285.44486590389, 1277.297714835905, 1266.014331028759, 1269.1469707947126, 1262.9469157191352, 1259.5612765145415, 1258.39351770939, 1249.7952864803615, 1246.8096548329445, 1244.544148958039, 1244.5747705163224, 1242.37902647872, 1236.1056677283989, 1231.3327211457188, 1234.2149192220434, 1231.6755835148422, 1220.5053978101353, 1218.4185998909459, 1223.5506379348924, 1221.8729961447827, 1219.5389495179788, 1214.4078759996987, 1208.7299841419622], 'acc': [0.745595222285978, 0.9081954383056711, 0.9248778159228437, 0.9384029966301599, 0.9432655124549778, 0.9453796081329754, 0.946774745992531, 0.9477449954935723, 0.9485613788552588, 0.94932730870792, 0.9499598619017386, 0.950279430284537, 0.9507925226228584, 0.9510509606981763, 0.951474821779841, 0.9517629893249003, 0.9519114955942405, 0.9524178581620593, 0.9525994156695199, 0.9528098170108431, 0.9530704517353075, 0.9533754385645422, 0.9534121153823535, 0.9536156291165946, 0.9537538231233971, 0.953821256363173, 0.9541034593696941, 0.954178708790759, 0.9542274529440108, 0.9544047594563867, 0.9545285111061597, 0.9546728870570157, 0.9547778478856116, 0.9548449972883353, 0.9549486678570264, 0.9550479872574325, 0.9551466190050801, 0.9552724273186235, 0.955237178035463, 0.9553047940528612, 0.9553040674741566, 0.9555425072156501, 0.9554644786878502, 0.9555822889774066, 0.9556931694032683, 0.9557060982418647, 0.9558448721611852, 0.9558879999928495, 0.9558379257902406, 0.9558792765523203, 0.9559530166069229, 0.9561666395531637, 0.9560750751711952, 0.9562182634635518, 0.9561668803415152, 0.9562794130278675, 0.9563489819941623, 0.9564313206996775, 0.9564417525902728, 0.9563522451350219, 0.9564585746370183, 0.9565888508966848, 0.9566065539696151, 0.9565501994709065, 0.9565877810548278, 0.9568253946709455, 0.9568284162313654, 0.9567563902720809, 0.956758987068656, 0.9568421332887183, 0.9568483578302419, 0.9570122711812091], 'mDice': [0.2164020555318181, 0.5117963462034073, 0.5970666119199349, 0.6316755053738767, 0.6515968620020751, 0.6664348202433165, 0.6770257026818991, 0.6860764009598962, 0.6918332678781772, 0.6989387251973561, 0.7050376045769462, 0.708032084640403, 0.7132401567198574, 0.7163865563396951, 0.7205353960006119, 0.7241248097283915, 0.7245019315167013, 0.7301396071719328, 0.7312244099798327, 0.7337013665260258, 0.7363371757190801, 0.7391661613648847, 0.7401456488781808, 0.7422677510821295, 0.7441180614524986, 0.74526711022774, 0.7480576362857099, 0.7494047851280984, 0.749507735240538, 0.751444362242311, 0.7523793367822473, 0.7544632662447, 0.7558577673204466, 0.757579340504169, 0.75783107388637, 0.7597095887876921, 0.7603381991282533, 0.7617110918013724, 0.7614010904006829, 0.7626834391060818, 0.7628385150369609, 0.7650584599420036, 0.7643542591863633, 0.7659301910971213, 0.7662107084748091, 0.7674152901584135, 0.7683256399585403, 0.769397846173178, 0.7690372651785874, 0.7689472919461982, 0.7702506909630903, 0.7720031320292358, 0.7715548824480978, 0.772528352300999, 0.7729968305221279, 0.7733846521865801, 0.7745219897577221, 0.7750294704263516, 0.7753370835801744, 0.7753379709138492, 0.7757207755818878, 0.7767089365010531, 0.7774459724592219, 0.7769942679739448, 0.7773411364786753, 0.7790913084228407, 0.7795179938966169, 0.7786781250778012, 0.7789306703537587, 0.7793270150701385, 0.7801060955169044, 0.7810217377329358]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.59s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.30s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  2.08s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:02<09:53,  2.09s/it]predicting train subjects:   1%|          | 2/285 [00:03<09:12,  1.95s/it]predicting train subjects:   1%|          | 3/285 [00:05<09:11,  1.96s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<08:43,  1.86s/it]predicting train subjects:   2%|▏         | 5/285 [00:09<08:53,  1.91s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<08:25,  1.81s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:44,  1.89s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:26,  1.83s/it]predicting train subjects:   3%|▎         | 9/285 [00:16<08:53,  1.93s/it]predicting train subjects:   4%|▎         | 10/285 [00:19<09:14,  2.02s/it]predicting train subjects:   4%|▍         | 11/285 [00:20<08:53,  1.95s/it]predicting train subjects:   4%|▍         | 12/285 [00:23<09:13,  2.03s/it]predicting train subjects:   5%|▍         | 13/285 [00:24<08:59,  1.98s/it]predicting train subjects:   5%|▍         | 14/285 [00:27<09:08,  2.02s/it]predicting train subjects:   5%|▌         | 15/285 [00:29<09:21,  2.08s/it]predicting train subjects:   6%|▌         | 16/285 [00:31<09:37,  2.15s/it]predicting train subjects:   6%|▌         | 17/285 [00:33<09:13,  2.06s/it]predicting train subjects:   6%|▋         | 18/285 [00:35<09:03,  2.03s/it]predicting train subjects:   7%|▋         | 19/285 [00:37<08:47,  1.98s/it]predicting train subjects:   7%|▋         | 20/285 [00:39<08:54,  2.02s/it]predicting train subjects:   7%|▋         | 21/285 [00:41<09:25,  2.14s/it]predicting train subjects:   8%|▊         | 22/285 [00:43<09:06,  2.08s/it]predicting train subjects:   8%|▊         | 23/285 [00:45<09:12,  2.11s/it]predicting train subjects:   8%|▊         | 24/285 [00:47<08:48,  2.03s/it]predicting train subjects:   9%|▉         | 25/285 [00:50<09:11,  2.12s/it]predicting train subjects:   9%|▉         | 26/285 [00:52<09:22,  2.17s/it]predicting train subjects:   9%|▉         | 27/285 [00:54<08:46,  2.04s/it]predicting train subjects:  10%|▉         | 28/285 [00:56<08:46,  2.05s/it]predicting train subjects:  10%|█         | 29/285 [00:58<08:43,  2.05s/it]predicting train subjects:  11%|█         | 30/285 [01:00<08:57,  2.11s/it]predicting train subjects:  11%|█         | 31/285 [01:02<08:58,  2.12s/it]predicting train subjects:  11%|█         | 32/285 [01:04<08:30,  2.02s/it]predicting train subjects:  12%|█▏        | 33/285 [01:06<08:24,  2.00s/it]predicting train subjects:  12%|█▏        | 34/285 [01:08<08:21,  2.00s/it]predicting train subjects:  12%|█▏        | 35/285 [01:10<08:41,  2.08s/it]predicting train subjects:  13%|█▎        | 36/285 [01:12<08:23,  2.02s/it]predicting train subjects:  13%|█▎        | 37/285 [01:14<08:17,  2.01s/it]predicting train subjects:  13%|█▎        | 38/285 [01:16<08:36,  2.09s/it]predicting train subjects:  14%|█▎        | 39/285 [01:18<08:14,  2.01s/it]predicting train subjects:  14%|█▍        | 40/285 [01:20<08:09,  2.00s/it]predicting train subjects:  14%|█▍        | 41/285 [01:22<07:50,  1.93s/it]predicting train subjects:  15%|█▍        | 42/285 [01:23<07:27,  1.84s/it]predicting train subjects:  15%|█▌        | 43/285 [01:25<07:28,  1.85s/it]predicting train subjects:  15%|█▌        | 44/285 [01:28<07:47,  1.94s/it]predicting train subjects:  16%|█▌        | 45/285 [01:29<07:31,  1.88s/it]predicting train subjects:  16%|█▌        | 46/285 [01:31<07:48,  1.96s/it]predicting train subjects:  16%|█▋        | 47/285 [01:33<07:22,  1.86s/it]predicting train subjects:  17%|█▋        | 48/285 [01:35<07:29,  1.90s/it]predicting train subjects:  17%|█▋        | 49/285 [01:37<07:44,  1.97s/it]predicting train subjects:  18%|█▊        | 50/285 [01:39<07:33,  1.93s/it]predicting train subjects:  18%|█▊        | 51/285 [01:41<07:50,  2.01s/it]predicting train subjects:  18%|█▊        | 52/285 [01:43<07:27,  1.92s/it]predicting train subjects:  19%|█▊        | 53/285 [01:45<07:25,  1.92s/it]predicting train subjects:  19%|█▉        | 54/285 [01:47<07:34,  1.97s/it]predicting train subjects:  19%|█▉        | 55/285 [01:49<07:12,  1.88s/it]predicting train subjects:  20%|█▉        | 56/285 [01:50<07:11,  1.88s/it]predicting train subjects:  20%|██        | 57/285 [01:52<07:03,  1.86s/it]predicting train subjects:  20%|██        | 58/285 [01:54<07:26,  1.97s/it]predicting train subjects:  21%|██        | 59/285 [01:57<08:03,  2.14s/it]predicting train subjects:  21%|██        | 60/285 [01:59<08:21,  2.23s/it]predicting train subjects:  21%|██▏       | 61/285 [02:02<08:08,  2.18s/it]predicting train subjects:  22%|██▏       | 62/285 [02:04<08:07,  2.19s/it]predicting train subjects:  22%|██▏       | 63/285 [02:06<08:08,  2.20s/it]predicting train subjects:  22%|██▏       | 64/285 [02:08<08:05,  2.19s/it]predicting train subjects:  23%|██▎       | 65/285 [02:10<08:01,  2.19s/it]predicting train subjects:  23%|██▎       | 66/285 [02:13<08:06,  2.22s/it]predicting train subjects:  24%|██▎       | 67/285 [02:15<08:10,  2.25s/it]predicting train subjects:  24%|██▍       | 68/285 [02:17<08:10,  2.26s/it]predicting train subjects:  24%|██▍       | 69/285 [02:19<07:57,  2.21s/it]predicting train subjects:  25%|██▍       | 70/285 [02:22<08:04,  2.26s/it]predicting train subjects:  25%|██▍       | 71/285 [02:24<08:06,  2.27s/it]predicting train subjects:  25%|██▌       | 72/285 [02:26<07:53,  2.22s/it]predicting train subjects:  26%|██▌       | 73/285 [02:28<07:54,  2.24s/it]predicting train subjects:  26%|██▌       | 74/285 [02:31<07:53,  2.24s/it]predicting train subjects:  26%|██▋       | 75/285 [02:33<08:01,  2.29s/it]predicting train subjects:  27%|██▋       | 76/285 [02:35<07:48,  2.24s/it]predicting train subjects:  27%|██▋       | 77/285 [02:37<07:37,  2.20s/it]predicting train subjects:  27%|██▋       | 78/285 [02:39<07:31,  2.18s/it]predicting train subjects:  28%|██▊       | 79/285 [02:42<07:26,  2.17s/it]predicting train subjects:  28%|██▊       | 80/285 [02:44<07:23,  2.16s/it]predicting train subjects:  28%|██▊       | 81/285 [02:46<07:11,  2.11s/it]predicting train subjects:  29%|██▉       | 82/285 [02:48<07:09,  2.12s/it]predicting train subjects:  29%|██▉       | 83/285 [02:50<06:57,  2.07s/it]predicting train subjects:  29%|██▉       | 84/285 [02:52<06:48,  2.03s/it]predicting train subjects:  30%|██▉       | 85/285 [02:54<06:52,  2.06s/it]predicting train subjects:  30%|███       | 86/285 [02:56<06:56,  2.09s/it]predicting train subjects:  31%|███       | 87/285 [02:58<07:03,  2.14s/it]predicting train subjects:  31%|███       | 88/285 [03:01<07:10,  2.18s/it]predicting train subjects:  31%|███       | 89/285 [03:03<07:10,  2.20s/it]predicting train subjects:  32%|███▏      | 90/285 [03:05<07:11,  2.21s/it]predicting train subjects:  32%|███▏      | 91/285 [03:07<07:03,  2.18s/it]predicting train subjects:  32%|███▏      | 92/285 [03:09<07:00,  2.18s/it]predicting train subjects:  33%|███▎      | 93/285 [03:11<06:36,  2.06s/it]predicting train subjects:  33%|███▎      | 94/285 [03:13<06:39,  2.09s/it]predicting train subjects:  33%|███▎      | 95/285 [03:16<06:59,  2.21s/it]predicting train subjects:  34%|███▎      | 96/285 [03:18<06:59,  2.22s/it]predicting train subjects:  34%|███▍      | 97/285 [03:20<06:59,  2.23s/it]predicting train subjects:  34%|███▍      | 98/285 [03:22<06:52,  2.21s/it]predicting train subjects:  35%|███▍      | 99/285 [03:25<06:53,  2.22s/it]predicting train subjects:  35%|███▌      | 100/285 [03:27<06:48,  2.21s/it]predicting train subjects:  35%|███▌      | 101/285 [03:29<06:30,  2.12s/it]predicting train subjects:  36%|███▌      | 102/285 [03:31<06:44,  2.21s/it]predicting train subjects:  36%|███▌      | 103/285 [03:33<06:26,  2.12s/it]predicting train subjects:  36%|███▋      | 104/285 [03:35<06:30,  2.16s/it]predicting train subjects:  37%|███▋      | 105/285 [03:38<06:37,  2.21s/it]predicting train subjects:  37%|███▋      | 106/285 [03:40<06:29,  2.18s/it]predicting train subjects:  38%|███▊      | 107/285 [03:42<06:33,  2.21s/it]predicting train subjects:  38%|███▊      | 108/285 [03:44<06:37,  2.25s/it]predicting train subjects:  38%|███▊      | 109/285 [03:46<06:28,  2.21s/it]predicting train subjects:  39%|███▊      | 110/285 [03:49<06:31,  2.24s/it]predicting train subjects:  39%|███▉      | 111/285 [03:51<06:17,  2.17s/it]predicting train subjects:  39%|███▉      | 112/285 [03:53<06:11,  2.15s/it]predicting train subjects:  40%|███▉      | 113/285 [03:55<06:16,  2.19s/it]predicting train subjects:  40%|████      | 114/285 [03:57<06:07,  2.15s/it]predicting train subjects:  40%|████      | 115/285 [04:00<06:11,  2.19s/it]predicting train subjects:  41%|████      | 116/285 [04:02<06:15,  2.22s/it]predicting train subjects:  41%|████      | 117/285 [04:04<06:03,  2.16s/it]predicting train subjects:  41%|████▏     | 118/285 [04:06<05:58,  2.14s/it]predicting train subjects:  42%|████▏     | 119/285 [04:08<06:11,  2.24s/it]predicting train subjects:  42%|████▏     | 120/285 [04:11<06:16,  2.28s/it]predicting train subjects:  42%|████▏     | 121/285 [04:13<06:22,  2.33s/it]predicting train subjects:  43%|████▎     | 122/285 [04:15<06:05,  2.24s/it]predicting train subjects:  43%|████▎     | 123/285 [04:17<05:45,  2.13s/it]predicting train subjects:  44%|████▎     | 124/285 [04:19<05:45,  2.15s/it]predicting train subjects:  44%|████▍     | 125/285 [04:21<05:35,  2.10s/it]predicting train subjects:  44%|████▍     | 126/285 [04:23<05:26,  2.05s/it]predicting train subjects:  45%|████▍     | 127/285 [04:25<05:12,  1.98s/it]predicting train subjects:  45%|████▍     | 128/285 [04:27<05:22,  2.06s/it]predicting train subjects:  45%|████▌     | 129/285 [04:29<05:16,  2.03s/it]predicting train subjects:  46%|████▌     | 130/285 [04:31<05:07,  1.99s/it]predicting train subjects:  46%|████▌     | 131/285 [04:33<05:07,  2.00s/it]predicting train subjects:  46%|████▋     | 132/285 [04:35<05:13,  2.05s/it]predicting train subjects:  47%|████▋     | 133/285 [04:37<05:10,  2.04s/it]predicting train subjects:  47%|████▋     | 134/285 [04:39<05:02,  2.01s/it]predicting train subjects:  47%|████▋     | 135/285 [04:41<05:01,  2.01s/it]predicting train subjects:  48%|████▊     | 136/285 [04:43<04:44,  1.91s/it]predicting train subjects:  48%|████▊     | 137/285 [04:45<04:54,  1.99s/it]predicting train subjects:  48%|████▊     | 138/285 [04:47<04:53,  2.00s/it]predicting train subjects:  49%|████▉     | 139/285 [04:49<05:03,  2.08s/it]predicting train subjects:  49%|████▉     | 140/285 [04:52<05:03,  2.09s/it]predicting train subjects:  49%|████▉     | 141/285 [04:54<05:04,  2.11s/it]predicting train subjects:  50%|████▉     | 142/285 [04:56<04:55,  2.06s/it]predicting train subjects:  50%|█████     | 143/285 [04:58<04:47,  2.02s/it]predicting train subjects:  51%|█████     | 144/285 [05:00<04:56,  2.10s/it]predicting train subjects:  51%|█████     | 145/285 [05:02<04:54,  2.10s/it]predicting train subjects:  51%|█████     | 146/285 [05:04<04:58,  2.15s/it]predicting train subjects:  52%|█████▏    | 147/285 [05:06<04:45,  2.07s/it]predicting train subjects:  52%|█████▏    | 148/285 [05:08<04:52,  2.14s/it]predicting train subjects:  52%|█████▏    | 149/285 [05:10<04:47,  2.11s/it]predicting train subjects:  53%|█████▎    | 150/285 [05:12<04:37,  2.06s/it]predicting train subjects:  53%|█████▎    | 151/285 [05:15<04:48,  2.15s/it]predicting train subjects:  53%|█████▎    | 152/285 [05:17<04:34,  2.07s/it]predicting train subjects:  54%|█████▎    | 153/285 [05:19<04:26,  2.02s/it]predicting train subjects:  54%|█████▍    | 154/285 [05:21<04:25,  2.03s/it]predicting train subjects:  54%|█████▍    | 155/285 [05:23<04:22,  2.02s/it]predicting train subjects:  55%|█████▍    | 156/285 [05:25<04:35,  2.14s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:27<04:19,  2.03s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:29<04:13,  2.00s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:31<04:03,  1.94s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:33<04:09,  2.00s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:35<04:16,  2.06s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:37<04:07,  2.01s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:39<04:04,  2.00s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:41<04:01,  2.00s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:43<04:07,  2.06s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:45<04:14,  2.14s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:47<04:07,  2.10s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:49<03:56,  2.02s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:51<03:44,  1.94s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:53<03:38,  1.90s/it]predicting train subjects:  60%|██████    | 171/285 [05:55<03:39,  1.93s/it]predicting train subjects:  60%|██████    | 172/285 [05:57<03:35,  1.91s/it]predicting train subjects:  61%|██████    | 173/285 [05:58<03:35,  1.92s/it]predicting train subjects:  61%|██████    | 174/285 [06:00<03:36,  1.95s/it]predicting train subjects:  61%|██████▏   | 175/285 [06:03<03:40,  2.01s/it]predicting train subjects:  62%|██████▏   | 176/285 [06:05<03:40,  2.02s/it]predicting train subjects:  62%|██████▏   | 177/285 [06:06<03:31,  1.96s/it]predicting train subjects:  62%|██████▏   | 178/285 [06:08<03:30,  1.96s/it]predicting train subjects:  63%|██████▎   | 179/285 [06:10<03:22,  1.91s/it]predicting train subjects:  63%|██████▎   | 180/285 [06:13<03:33,  2.03s/it]predicting train subjects:  64%|██████▎   | 181/285 [06:15<03:32,  2.04s/it]predicting train subjects:  64%|██████▍   | 182/285 [06:17<03:33,  2.07s/it]predicting train subjects:  64%|██████▍   | 183/285 [06:19<03:24,  2.01s/it]predicting train subjects:  65%|██████▍   | 184/285 [06:21<03:30,  2.09s/it]predicting train subjects:  65%|██████▍   | 185/285 [06:23<03:23,  2.03s/it]predicting train subjects:  65%|██████▌   | 186/285 [06:26<03:42,  2.24s/it]predicting train subjects:  66%|██████▌   | 187/285 [06:28<03:42,  2.27s/it]predicting train subjects:  66%|██████▌   | 188/285 [06:30<03:42,  2.29s/it]predicting train subjects:  66%|██████▋   | 189/285 [06:32<03:24,  2.13s/it]predicting train subjects:  67%|██████▋   | 190/285 [06:34<03:15,  2.06s/it]predicting train subjects:  67%|██████▋   | 191/285 [06:36<03:19,  2.12s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:38<03:21,  2.17s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:41<03:18,  2.15s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:42<03:07,  2.07s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:44<02:57,  1.97s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:47<03:05,  2.09s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:49<03:15,  2.22s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:51<03:11,  2.21s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:53<02:56,  2.06s/it]predicting train subjects:  70%|███████   | 200/285 [06:55<02:50,  2.01s/it]predicting train subjects:  71%|███████   | 201/285 [06:57<02:56,  2.10s/it]predicting train subjects:  71%|███████   | 202/285 [06:59<02:54,  2.10s/it]predicting train subjects:  71%|███████   | 203/285 [07:01<02:56,  2.15s/it]predicting train subjects:  72%|███████▏  | 204/285 [07:03<02:49,  2.09s/it]predicting train subjects:  72%|███████▏  | 205/285 [07:05<02:40,  2.01s/it]predicting train subjects:  72%|███████▏  | 206/285 [07:07<02:35,  1.96s/it]predicting train subjects:  73%|███████▎  | 207/285 [07:10<02:48,  2.16s/it]predicting train subjects:  73%|███████▎  | 208/285 [07:12<02:54,  2.27s/it]predicting train subjects:  73%|███████▎  | 209/285 [07:15<02:55,  2.30s/it]predicting train subjects:  74%|███████▎  | 210/285 [07:17<02:47,  2.23s/it]predicting train subjects:  74%|███████▍  | 211/285 [07:19<02:36,  2.12s/it]predicting train subjects:  74%|███████▍  | 212/285 [07:21<02:43,  2.24s/it]predicting train subjects:  75%|███████▍  | 213/285 [07:23<02:34,  2.15s/it]predicting train subjects:  75%|███████▌  | 214/285 [07:25<02:30,  2.12s/it]predicting train subjects:  75%|███████▌  | 215/285 [07:27<02:32,  2.18s/it]predicting train subjects:  76%|███████▌  | 216/285 [07:29<02:21,  2.06s/it]predicting train subjects:  76%|███████▌  | 217/285 [07:32<02:25,  2.14s/it]predicting train subjects:  76%|███████▋  | 218/285 [07:34<02:27,  2.19s/it]predicting train subjects:  77%|███████▋  | 219/285 [07:36<02:26,  2.22s/it]predicting train subjects:  77%|███████▋  | 220/285 [07:38<02:17,  2.12s/it]predicting train subjects:  78%|███████▊  | 221/285 [07:40<02:15,  2.12s/it]predicting train subjects:  78%|███████▊  | 222/285 [07:42<02:15,  2.15s/it]predicting train subjects:  78%|███████▊  | 223/285 [07:44<02:06,  2.05s/it]predicting train subjects:  79%|███████▊  | 224/285 [07:46<02:01,  1.99s/it]predicting train subjects:  79%|███████▉  | 225/285 [07:48<01:55,  1.93s/it]predicting train subjects:  79%|███████▉  | 226/285 [07:50<02:01,  2.06s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:53<02:07,  2.19s/it]predicting train subjects:  80%|████████  | 228/285 [07:55<02:07,  2.23s/it]predicting train subjects:  80%|████████  | 229/285 [07:57<02:07,  2.27s/it]predicting train subjects:  81%|████████  | 230/285 [08:00<02:03,  2.25s/it]predicting train subjects:  81%|████████  | 231/285 [08:02<01:58,  2.19s/it]predicting train subjects:  81%|████████▏ | 232/285 [08:04<02:00,  2.27s/it]predicting train subjects:  82%|████████▏ | 233/285 [08:06<01:50,  2.12s/it]predicting train subjects:  82%|████████▏ | 234/285 [08:08<01:54,  2.25s/it]predicting train subjects:  82%|████████▏ | 235/285 [08:10<01:49,  2.20s/it]predicting train subjects:  83%|████████▎ | 236/285 [08:13<01:50,  2.25s/it]predicting train subjects:  83%|████████▎ | 237/285 [08:15<01:50,  2.30s/it]predicting train subjects:  84%|████████▎ | 238/285 [08:18<01:48,  2.31s/it]predicting train subjects:  84%|████████▍ | 239/285 [08:20<01:44,  2.27s/it]predicting train subjects:  84%|████████▍ | 240/285 [08:22<01:35,  2.12s/it]predicting train subjects:  85%|████████▍ | 241/285 [08:23<01:30,  2.06s/it]predicting train subjects:  85%|████████▍ | 242/285 [08:25<01:26,  2.00s/it]predicting train subjects:  85%|████████▌ | 243/285 [08:27<01:24,  2.00s/it]predicting train subjects:  86%|████████▌ | 244/285 [08:30<01:28,  2.15s/it]predicting train subjects:  86%|████████▌ | 245/285 [08:32<01:22,  2.07s/it]predicting train subjects:  86%|████████▋ | 246/285 [08:34<01:25,  2.20s/it]predicting train subjects:  87%|████████▋ | 247/285 [08:36<01:24,  2.21s/it]predicting train subjects:  87%|████████▋ | 248/285 [08:39<01:24,  2.28s/it]predicting train subjects:  87%|████████▋ | 249/285 [08:41<01:16,  2.14s/it]predicting train subjects:  88%|████████▊ | 250/285 [08:43<01:13,  2.11s/it]predicting train subjects:  88%|████████▊ | 251/285 [08:44<01:07,  1.99s/it]predicting train subjects:  88%|████████▊ | 252/285 [08:46<01:05,  1.99s/it]predicting train subjects:  89%|████████▉ | 253/285 [08:49<01:08,  2.15s/it]predicting train subjects:  89%|████████▉ | 254/285 [08:51<01:07,  2.18s/it]predicting train subjects:  89%|████████▉ | 255/285 [08:53<01:06,  2.20s/it]predicting train subjects:  90%|████████▉ | 256/285 [08:56<01:03,  2.18s/it]predicting train subjects:  90%|█████████ | 257/285 [08:57<00:58,  2.08s/it]predicting train subjects:  91%|█████████ | 258/285 [09:00<00:58,  2.18s/it]predicting train subjects:  91%|█████████ | 259/285 [09:02<00:57,  2.22s/it]predicting train subjects:  91%|█████████ | 260/285 [09:04<00:53,  2.14s/it]predicting train subjects:  92%|█████████▏| 261/285 [09:06<00:48,  2.03s/it]predicting train subjects:  92%|█████████▏| 262/285 [09:08<00:44,  1.94s/it]predicting train subjects:  92%|█████████▏| 263/285 [09:09<00:42,  1.92s/it]predicting train subjects:  93%|█████████▎| 264/285 [09:12<00:43,  2.09s/it]predicting train subjects:  93%|█████████▎| 265/285 [09:14<00:43,  2.15s/it]predicting train subjects:  93%|█████████▎| 266/285 [09:16<00:38,  2.05s/it]predicting train subjects:  94%|█████████▎| 267/285 [09:18<00:36,  2.02s/it]predicting train subjects:  94%|█████████▍| 268/285 [09:21<00:37,  2.18s/it]predicting train subjects:  94%|█████████▍| 269/285 [09:23<00:35,  2.22s/it]predicting train subjects:  95%|█████████▍| 270/285 [09:25<00:31,  2.13s/it]predicting train subjects:  95%|█████████▌| 271/285 [09:27<00:29,  2.11s/it]predicting train subjects:  95%|█████████▌| 272/285 [09:29<00:26,  2.07s/it]predicting train subjects:  96%|█████████▌| 273/285 [09:31<00:23,  1.96s/it]predicting train subjects:  96%|█████████▌| 274/285 [09:32<00:20,  1.90s/it]predicting train subjects:  96%|█████████▋| 275/285 [09:34<00:19,  1.94s/it]predicting train subjects:  97%|█████████▋| 276/285 [09:36<00:17,  1.96s/it]predicting train subjects:  97%|█████████▋| 277/285 [09:38<00:14,  1.82s/it]predicting train subjects:  98%|█████████▊| 278/285 [09:40<00:12,  1.80s/it]predicting train subjects:  98%|█████████▊| 279/285 [09:42<00:11,  1.84s/it]predicting train subjects:  98%|█████████▊| 280/285 [09:43<00:08,  1.75s/it]predicting train subjects:  99%|█████████▊| 281/285 [09:45<00:06,  1.70s/it]predicting train subjects:  99%|█████████▉| 282/285 [09:46<00:04,  1.62s/it]predicting train subjects:  99%|█████████▉| 283/285 [09:48<00:03,  1.76s/it]predicting train subjects: 100%|█████████▉| 284/285 [09:50<00:01,  1.86s/it]predicting train subjects: 100%|██████████| 285/285 [09:52<00:00,  1.92s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:23,  1.77s/it]Loading train:   1%|          | 2/285 [00:03<07:46,  1.65s/it]Loading train:   1%|          | 3/285 [00:04<07:31,  1.60s/it]Loading train:   1%|▏         | 4/285 [00:06<07:25,  1.59s/it]Loading train:   2%|▏         | 5/285 [00:07<07:39,  1.64s/it]Loading train:   2%|▏         | 6/285 [00:09<07:10,  1.54s/it]Loading train:   2%|▏         | 7/285 [00:10<07:18,  1.58s/it]Loading train:   3%|▎         | 8/285 [00:12<07:25,  1.61s/it]Loading train:   3%|▎         | 9/285 [00:14<07:37,  1.66s/it]Loading train:   4%|▎         | 10/285 [00:15<07:22,  1.61s/it]Loading train:   4%|▍         | 11/285 [00:16<06:37,  1.45s/it]Loading train:   4%|▍         | 12/285 [00:18<06:23,  1.41s/it]Loading train:   5%|▍         | 13/285 [00:19<06:04,  1.34s/it]Loading train:   5%|▍         | 14/285 [00:20<06:11,  1.37s/it]Loading train:   5%|▌         | 15/285 [00:22<06:20,  1.41s/it]Loading train:   6%|▌         | 16/285 [00:23<06:16,  1.40s/it]Loading train:   6%|▌         | 17/285 [00:24<05:34,  1.25s/it]Loading train:   6%|▋         | 18/285 [00:25<05:22,  1.21s/it]Loading train:   7%|▋         | 19/285 [00:26<05:08,  1.16s/it]Loading train:   7%|▋         | 20/285 [00:27<05:04,  1.15s/it]Loading train:   7%|▋         | 21/285 [00:29<05:10,  1.17s/it]Loading train:   8%|▊         | 22/285 [00:30<04:53,  1.12s/it]Loading train:   8%|▊         | 23/285 [00:31<04:59,  1.14s/it]Loading train:   8%|▊         | 24/285 [00:32<05:01,  1.15s/it]Loading train:   9%|▉         | 25/285 [00:33<04:57,  1.15s/it]Loading train:   9%|▉         | 26/285 [00:34<05:04,  1.17s/it]Loading train:   9%|▉         | 27/285 [00:35<04:56,  1.15s/it]Loading train:  10%|▉         | 28/285 [00:37<05:13,  1.22s/it]Loading train:  10%|█         | 29/285 [00:38<04:59,  1.17s/it]Loading train:  11%|█         | 30/285 [00:39<05:03,  1.19s/it]Loading train:  11%|█         | 31/285 [00:40<04:53,  1.16s/it]Loading train:  11%|█         | 32/285 [00:41<04:34,  1.08s/it]Loading train:  12%|█▏        | 33/285 [00:42<04:35,  1.09s/it]Loading train:  12%|█▏        | 34/285 [00:43<04:35,  1.10s/it]Loading train:  12%|█▏        | 35/285 [00:45<04:45,  1.14s/it]Loading train:  13%|█▎        | 36/285 [00:46<04:46,  1.15s/it]Loading train:  13%|█▎        | 37/285 [00:47<04:41,  1.13s/it]Loading train:  13%|█▎        | 38/285 [00:48<05:02,  1.22s/it]Loading train:  14%|█▎        | 39/285 [00:50<05:00,  1.22s/it]Loading train:  14%|█▍        | 40/285 [00:51<05:03,  1.24s/it]Loading train:  14%|█▍        | 41/285 [00:52<04:58,  1.23s/it]Loading train:  15%|█▍        | 42/285 [00:53<04:40,  1.16s/it]Loading train:  15%|█▌        | 43/285 [00:54<04:38,  1.15s/it]Loading train:  15%|█▌        | 44/285 [00:56<04:53,  1.22s/it]Loading train:  16%|█▌        | 45/285 [00:57<04:40,  1.17s/it]Loading train:  16%|█▌        | 46/285 [00:58<04:36,  1.16s/it]Loading train:  16%|█▋        | 47/285 [00:59<04:28,  1.13s/it]Loading train:  17%|█▋        | 48/285 [01:00<04:41,  1.19s/it]Loading train:  17%|█▋        | 49/285 [01:01<04:44,  1.21s/it]Loading train:  18%|█▊        | 50/285 [01:02<04:34,  1.17s/it]Loading train:  18%|█▊        | 51/285 [01:04<04:35,  1.18s/it]Loading train:  18%|█▊        | 52/285 [01:05<04:23,  1.13s/it]Loading train:  19%|█▊        | 53/285 [01:06<04:35,  1.19s/it]Loading train:  19%|█▉        | 54/285 [01:07<04:36,  1.20s/it]Loading train:  19%|█▉        | 55/285 [01:08<04:21,  1.14s/it]Loading train:  20%|█▉        | 56/285 [01:09<04:20,  1.14s/it]Loading train:  20%|██        | 57/285 [01:11<04:28,  1.18s/it]Loading train:  20%|██        | 58/285 [01:12<04:20,  1.15s/it]Loading train:  21%|██        | 59/285 [01:13<04:32,  1.21s/it]Loading train:  21%|██        | 60/285 [01:14<04:46,  1.27s/it]Loading train:  21%|██▏       | 61/285 [01:16<04:37,  1.24s/it]Loading train:  22%|██▏       | 62/285 [01:17<04:45,  1.28s/it]Loading train:  22%|██▏       | 63/285 [01:18<04:42,  1.27s/it]Loading train:  22%|██▏       | 64/285 [01:20<04:55,  1.34s/it]Loading train:  23%|██▎       | 65/285 [01:22<05:24,  1.48s/it]Loading train:  23%|██▎       | 66/285 [01:23<05:53,  1.62s/it]Loading train:  24%|██▎       | 67/285 [01:25<05:26,  1.50s/it]Loading train:  24%|██▍       | 68/285 [01:26<04:58,  1.37s/it]Loading train:  24%|██▍       | 69/285 [01:27<04:50,  1.34s/it]Loading train:  25%|██▍       | 70/285 [01:28<04:40,  1.30s/it]Loading train:  25%|██▍       | 71/285 [01:30<04:40,  1.31s/it]Loading train:  25%|██▌       | 72/285 [01:31<04:22,  1.23s/it]Loading train:  26%|██▌       | 73/285 [01:32<04:17,  1.21s/it]Loading train:  26%|██▌       | 74/285 [01:33<04:23,  1.25s/it]Loading train:  26%|██▋       | 75/285 [01:34<04:10,  1.19s/it]Loading train:  27%|██▋       | 76/285 [01:35<04:07,  1.18s/it]Loading train:  27%|██▋       | 77/285 [01:36<04:00,  1.16s/it]Loading train:  27%|██▋       | 78/285 [01:37<03:49,  1.11s/it]Loading train:  28%|██▊       | 79/285 [01:39<03:49,  1.11s/it]Loading train:  28%|██▊       | 80/285 [01:40<03:45,  1.10s/it]Loading train:  28%|██▊       | 81/285 [01:41<03:54,  1.15s/it]Loading train:  29%|██▉       | 82/285 [01:42<03:56,  1.17s/it]Loading train:  29%|██▉       | 83/285 [01:43<03:48,  1.13s/it]Loading train:  29%|██▉       | 84/285 [01:44<03:47,  1.13s/it]Loading train:  30%|██▉       | 85/285 [01:46<04:11,  1.26s/it]Loading train:  30%|███       | 86/285 [01:47<04:05,  1.23s/it]Loading train:  31%|███       | 87/285 [01:48<04:03,  1.23s/it]Loading train:  31%|███       | 88/285 [01:49<03:42,  1.13s/it]Loading train:  31%|███       | 89/285 [01:50<03:42,  1.14s/it]Loading train:  32%|███▏      | 90/285 [01:52<03:55,  1.21s/it]Loading train:  32%|███▏      | 91/285 [01:53<03:54,  1.21s/it]Loading train:  32%|███▏      | 92/285 [01:54<03:52,  1.21s/it]Loading train:  33%|███▎      | 93/285 [01:55<04:00,  1.25s/it]Loading train:  33%|███▎      | 94/285 [01:57<04:15,  1.34s/it]Loading train:  33%|███▎      | 95/285 [01:58<04:02,  1.28s/it]Loading train:  34%|███▎      | 96/285 [01:59<03:52,  1.23s/it]Loading train:  34%|███▍      | 97/285 [02:00<03:48,  1.22s/it]Loading train:  34%|███▍      | 98/285 [02:02<03:53,  1.25s/it]Loading train:  35%|███▍      | 99/285 [02:03<03:41,  1.19s/it]Loading train:  35%|███▌      | 100/285 [02:04<03:41,  1.20s/it]Loading train:  35%|███▌      | 101/285 [02:05<03:32,  1.16s/it]Loading train:  36%|███▌      | 102/285 [02:06<03:29,  1.15s/it]Loading train:  36%|███▌      | 103/285 [02:07<03:31,  1.16s/it]Loading train:  36%|███▋      | 104/285 [02:09<03:32,  1.17s/it]Loading train:  37%|███▋      | 105/285 [02:10<03:34,  1.19s/it]Loading train:  37%|███▋      | 106/285 [02:11<03:19,  1.12s/it]Loading train:  38%|███▊      | 107/285 [02:12<03:31,  1.19s/it]Loading train:  38%|███▊      | 108/285 [02:13<03:19,  1.13s/it]Loading train:  38%|███▊      | 109/285 [02:14<03:15,  1.11s/it]Loading train:  39%|███▊      | 110/285 [02:16<03:34,  1.23s/it]Loading train:  39%|███▉      | 111/285 [02:17<03:24,  1.18s/it]Loading train:  39%|███▉      | 112/285 [02:18<03:31,  1.22s/it]Loading train:  40%|███▉      | 113/285 [02:19<03:31,  1.23s/it]Loading train:  40%|████      | 114/285 [02:21<03:31,  1.24s/it]Loading train:  40%|████      | 115/285 [02:22<03:32,  1.25s/it]Loading train:  41%|████      | 116/285 [02:24<03:57,  1.41s/it]Loading train:  41%|████      | 117/285 [02:25<04:15,  1.52s/it]Loading train:  41%|████▏     | 118/285 [02:27<04:08,  1.49s/it]Loading train:  42%|████▏     | 119/285 [02:29<04:31,  1.64s/it]Loading train:  42%|████▏     | 120/285 [02:31<04:53,  1.78s/it]Loading train:  42%|████▏     | 121/285 [02:32<04:33,  1.67s/it]Loading train:  43%|████▎     | 122/285 [02:33<04:08,  1.52s/it]Loading train:  43%|████▎     | 123/285 [02:35<03:50,  1.42s/it]Loading train:  44%|████▎     | 124/285 [02:36<03:21,  1.25s/it]Loading train:  44%|████▍     | 125/285 [02:36<02:54,  1.09s/it]Loading train:  44%|████▍     | 126/285 [02:37<02:42,  1.02s/it]Loading train:  45%|████▍     | 127/285 [02:38<02:45,  1.05s/it]Loading train:  45%|████▍     | 128/285 [02:39<02:46,  1.06s/it]Loading train:  45%|████▌     | 129/285 [02:40<02:46,  1.07s/it]Loading train:  46%|████▌     | 130/285 [02:42<02:59,  1.16s/it]Loading train:  46%|████▌     | 131/285 [02:43<02:57,  1.15s/it]Loading train:  46%|████▋     | 132/285 [02:44<02:59,  1.18s/it]Loading train:  47%|████▋     | 133/285 [02:45<03:03,  1.21s/it]Loading train:  47%|████▋     | 134/285 [02:46<02:47,  1.11s/it]Loading train:  47%|████▋     | 135/285 [02:47<02:32,  1.02s/it]Loading train:  48%|████▊     | 136/285 [02:48<02:22,  1.04it/s]Loading train:  48%|████▊     | 137/285 [02:49<02:29,  1.01s/it]Loading train:  48%|████▊     | 138/285 [02:51<02:58,  1.21s/it]Loading train:  49%|████▉     | 139/285 [02:52<02:44,  1.13s/it]Loading train:  49%|████▉     | 140/285 [02:52<02:30,  1.03s/it]Loading train:  49%|████▉     | 141/285 [02:53<02:17,  1.05it/s]Loading train:  50%|████▉     | 142/285 [02:54<02:09,  1.10it/s]Loading train:  50%|█████     | 143/285 [02:55<02:05,  1.14it/s]Loading train:  51%|█████     | 144/285 [02:56<02:01,  1.16it/s]Loading train:  51%|█████     | 145/285 [02:57<01:59,  1.17it/s]Loading train:  51%|█████     | 146/285 [02:57<01:57,  1.18it/s]Loading train:  52%|█████▏    | 147/285 [02:58<01:53,  1.21it/s]Loading train:  52%|█████▏    | 148/285 [02:59<01:51,  1.23it/s]Loading train:  52%|█████▏    | 149/285 [03:00<01:49,  1.24it/s]Loading train:  53%|█████▎    | 150/285 [03:00<01:47,  1.26it/s]Loading train:  53%|█████▎    | 151/285 [03:01<01:52,  1.19it/s]Loading train:  53%|█████▎    | 152/285 [03:02<01:50,  1.20it/s]Loading train:  54%|█████▎    | 153/285 [03:03<01:49,  1.21it/s]Loading train:  54%|█████▍    | 154/285 [03:04<01:50,  1.19it/s]Loading train:  54%|█████▍    | 155/285 [03:05<01:51,  1.16it/s]Loading train:  55%|█████▍    | 156/285 [03:06<01:51,  1.16it/s]Loading train:  55%|█████▌    | 157/285 [03:06<01:48,  1.18it/s]Loading train:  55%|█████▌    | 158/285 [03:07<01:47,  1.18it/s]Loading train:  56%|█████▌    | 159/285 [03:08<01:43,  1.22it/s]Loading train:  56%|█████▌    | 160/285 [03:09<01:37,  1.28it/s]Loading train:  56%|█████▋    | 161/285 [03:10<01:39,  1.25it/s]Loading train:  57%|█████▋    | 162/285 [03:10<01:40,  1.23it/s]Loading train:  57%|█████▋    | 163/285 [03:11<01:38,  1.23it/s]Loading train:  58%|█████▊    | 164/285 [03:12<01:36,  1.26it/s]Loading train:  58%|█████▊    | 165/285 [03:13<01:33,  1.29it/s]Loading train:  58%|█████▊    | 166/285 [03:14<01:32,  1.29it/s]Loading train:  59%|█████▊    | 167/285 [03:15<01:37,  1.21it/s]Loading train:  59%|█████▉    | 168/285 [03:15<01:36,  1.21it/s]Loading train:  59%|█████▉    | 169/285 [03:16<01:35,  1.21it/s]Loading train:  60%|█████▉    | 170/285 [03:17<01:33,  1.24it/s]Loading train:  60%|██████    | 171/285 [03:18<01:30,  1.27it/s]Loading train:  60%|██████    | 172/285 [03:18<01:24,  1.33it/s]Loading train:  61%|██████    | 173/285 [03:19<01:26,  1.30it/s]Loading train:  61%|██████    | 174/285 [03:20<01:22,  1.35it/s]Loading train:  61%|██████▏   | 175/285 [03:21<01:24,  1.30it/s]Loading train:  62%|██████▏   | 176/285 [03:21<01:25,  1.27it/s]Loading train:  62%|██████▏   | 177/285 [03:22<01:23,  1.29it/s]Loading train:  62%|██████▏   | 178/285 [03:23<01:25,  1.25it/s]Loading train:  63%|██████▎   | 179/285 [03:24<01:24,  1.25it/s]Loading train:  63%|██████▎   | 180/285 [03:25<01:30,  1.17it/s]Loading train:  64%|██████▎   | 181/285 [03:26<01:32,  1.12it/s]Loading train:  64%|██████▍   | 182/285 [03:27<01:30,  1.14it/s]Loading train:  64%|██████▍   | 183/285 [03:27<01:25,  1.19it/s]Loading train:  65%|██████▍   | 184/285 [03:28<01:25,  1.18it/s]Loading train:  65%|██████▍   | 185/285 [03:29<01:21,  1.23it/s]Loading train:  65%|██████▌   | 186/285 [03:30<01:23,  1.18it/s]Loading train:  66%|██████▌   | 187/285 [03:31<01:23,  1.17it/s]Loading train:  66%|██████▌   | 188/285 [03:32<01:25,  1.13it/s]Loading train:  66%|██████▋   | 189/285 [03:33<01:20,  1.19it/s]Loading train:  67%|██████▋   | 190/285 [03:33<01:13,  1.30it/s]Loading train:  67%|██████▋   | 191/285 [03:34<01:14,  1.27it/s]Loading train:  67%|██████▋   | 192/285 [03:35<01:14,  1.26it/s]Loading train:  68%|██████▊   | 193/285 [03:36<01:12,  1.26it/s]Loading train:  68%|██████▊   | 194/285 [03:36<01:10,  1.28it/s]Loading train:  68%|██████▊   | 195/285 [03:37<01:07,  1.33it/s]Loading train:  69%|██████▉   | 196/285 [03:38<01:11,  1.25it/s]Loading train:  69%|██████▉   | 197/285 [03:39<01:12,  1.21it/s]Loading train:  69%|██████▉   | 198/285 [03:40<01:14,  1.16it/s]Loading train:  70%|██████▉   | 199/285 [03:40<01:10,  1.22it/s]Loading train:  70%|███████   | 200/285 [03:41<01:07,  1.25it/s]Loading train:  71%|███████   | 201/285 [03:42<01:11,  1.18it/s]Loading train:  71%|███████   | 202/285 [03:43<01:07,  1.23it/s]Loading train:  71%|███████   | 203/285 [03:44<01:09,  1.19it/s]Loading train:  72%|███████▏  | 204/285 [03:45<01:06,  1.21it/s]Loading train:  72%|███████▏  | 205/285 [03:45<01:03,  1.25it/s]Loading train:  72%|███████▏  | 206/285 [03:46<01:03,  1.24it/s]Loading train:  73%|███████▎  | 207/285 [03:47<01:04,  1.20it/s]Loading train:  73%|███████▎  | 208/285 [03:48<01:07,  1.14it/s]Loading train:  73%|███████▎  | 209/285 [03:49<01:07,  1.12it/s]Loading train:  74%|███████▎  | 210/285 [03:50<01:01,  1.23it/s]Loading train:  74%|███████▍  | 211/285 [03:50<00:58,  1.26it/s]Loading train:  74%|███████▍  | 212/285 [03:51<00:58,  1.24it/s]Loading train:  75%|███████▍  | 213/285 [03:52<00:58,  1.23it/s]Loading train:  75%|███████▌  | 214/285 [03:53<00:55,  1.29it/s]Loading train:  75%|███████▌  | 215/285 [03:54<00:58,  1.20it/s]Loading train:  76%|███████▌  | 216/285 [03:54<00:54,  1.26it/s]Loading train:  76%|███████▌  | 217/285 [03:55<00:55,  1.22it/s]Loading train:  76%|███████▋  | 218/285 [03:56<00:55,  1.21it/s]Loading train:  77%|███████▋  | 219/285 [03:57<01:00,  1.10it/s]Loading train:  77%|███████▋  | 220/285 [03:58<00:57,  1.12it/s]Loading train:  78%|███████▊  | 221/285 [03:59<00:54,  1.18it/s]Loading train:  78%|███████▊  | 222/285 [04:00<00:52,  1.21it/s]Loading train:  78%|███████▊  | 223/285 [04:00<00:50,  1.23it/s]Loading train:  79%|███████▊  | 224/285 [04:01<00:50,  1.21it/s]Loading train:  79%|███████▉  | 225/285 [04:02<00:48,  1.23it/s]Loading train:  79%|███████▉  | 226/285 [04:03<00:51,  1.14it/s]Loading train:  80%|███████▉  | 227/285 [04:04<00:51,  1.12it/s]Loading train:  80%|████████  | 228/285 [04:05<00:53,  1.07it/s]Loading train:  80%|████████  | 229/285 [04:06<00:53,  1.04it/s]Loading train:  81%|████████  | 230/285 [04:07<00:50,  1.09it/s]Loading train:  81%|████████  | 231/285 [04:08<00:47,  1.13it/s]Loading train:  81%|████████▏ | 232/285 [04:09<00:46,  1.13it/s]Loading train:  82%|████████▏ | 233/285 [04:09<00:44,  1.18it/s]Loading train:  82%|████████▏ | 234/285 [04:10<00:43,  1.16it/s]Loading train:  82%|████████▏ | 235/285 [04:11<00:42,  1.18it/s]Loading train:  83%|████████▎ | 236/285 [04:12<00:41,  1.17it/s]Loading train:  83%|████████▎ | 237/285 [04:13<00:41,  1.15it/s]Loading train:  84%|████████▎ | 238/285 [04:14<00:41,  1.13it/s]Loading train:  84%|████████▍ | 239/285 [04:14<00:39,  1.15it/s]Loading train:  84%|████████▍ | 240/285 [04:15<00:37,  1.20it/s]Loading train:  85%|████████▍ | 241/285 [04:16<00:34,  1.26it/s]Loading train:  85%|████████▍ | 242/285 [04:17<00:33,  1.29it/s]Loading train:  85%|████████▌ | 243/285 [04:17<00:32,  1.31it/s]Loading train:  86%|████████▌ | 244/285 [04:18<00:33,  1.23it/s]Loading train:  86%|████████▌ | 245/285 [04:19<00:30,  1.29it/s]Loading train:  86%|████████▋ | 246/285 [04:20<00:31,  1.23it/s]Loading train:  87%|████████▋ | 247/285 [04:21<00:31,  1.19it/s]Loading train:  87%|████████▋ | 248/285 [04:22<00:30,  1.21it/s]Loading train:  87%|████████▋ | 249/285 [04:22<00:28,  1.26it/s]Loading train:  88%|████████▊ | 250/285 [04:23<00:28,  1.25it/s]Loading train:  88%|████████▊ | 251/285 [04:24<00:26,  1.29it/s]Loading train:  88%|████████▊ | 252/285 [04:25<00:24,  1.33it/s]Loading train:  89%|████████▉ | 253/285 [04:25<00:25,  1.25it/s]Loading train:  89%|████████▉ | 254/285 [04:26<00:25,  1.20it/s]Loading train:  89%|████████▉ | 255/285 [04:27<00:25,  1.20it/s]Loading train:  90%|████████▉ | 256/285 [04:28<00:23,  1.24it/s]Loading train:  90%|█████████ | 257/285 [04:29<00:21,  1.28it/s]Loading train:  91%|█████████ | 258/285 [04:30<00:22,  1.22it/s]Loading train:  91%|█████████ | 259/285 [04:30<00:21,  1.21it/s]Loading train:  91%|█████████ | 260/285 [04:31<00:19,  1.27it/s]Loading train:  92%|█████████▏| 261/285 [04:32<00:18,  1.29it/s]Loading train:  92%|█████████▏| 262/285 [04:33<00:18,  1.28it/s]Loading train:  92%|█████████▏| 263/285 [04:33<00:16,  1.30it/s]Loading train:  93%|█████████▎| 264/285 [04:34<00:17,  1.18it/s]Loading train:  93%|█████████▎| 265/285 [04:35<00:17,  1.13it/s]Loading train:  93%|█████████▎| 266/285 [04:36<00:15,  1.19it/s]Loading train:  94%|█████████▎| 267/285 [04:37<00:14,  1.26it/s]Loading train:  94%|█████████▍| 268/285 [04:38<00:13,  1.22it/s]Loading train:  94%|█████████▍| 269/285 [04:39<00:13,  1.22it/s]Loading train:  95%|█████████▍| 270/285 [04:39<00:11,  1.29it/s]Loading train:  95%|█████████▌| 271/285 [04:40<00:10,  1.33it/s]Loading train:  95%|█████████▌| 272/285 [04:41<00:10,  1.29it/s]Loading train:  96%|█████████▌| 273/285 [04:41<00:09,  1.33it/s]Loading train:  96%|█████████▌| 274/285 [04:42<00:08,  1.34it/s]Loading train:  96%|█████████▋| 275/285 [04:43<00:08,  1.21it/s]Loading train:  97%|█████████▋| 276/285 [04:44<00:07,  1.15it/s]Loading train:  97%|█████████▋| 277/285 [04:45<00:06,  1.26it/s]Loading train:  98%|█████████▊| 278/285 [04:46<00:05,  1.29it/s]Loading train:  98%|█████████▊| 279/285 [04:46<00:04,  1.27it/s]Loading train:  98%|█████████▊| 280/285 [04:47<00:03,  1.28it/s]Loading train:  99%|█████████▊| 281/285 [04:48<00:03,  1.31it/s]Loading train:  99%|█████████▉| 282/285 [04:49<00:02,  1.33it/s]Loading train:  99%|█████████▉| 283/285 [04:50<00:01,  1.19it/s]Loading train: 100%|█████████▉| 284/285 [04:50<00:00,  1.20it/s]Loading train: 100%|██████████| 285/285 [04:51<00:00,  1.18it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   4%|▍         | 11/285 [00:00<00:02, 106.97it/s]concatenating: train:  12%|█▏        | 35/285 [00:00<00:01, 128.27it/s]concatenating: train:  24%|██▎       | 67/285 [00:00<00:01, 155.90it/s]concatenating: train:  35%|███▌      | 101/285 [00:00<00:00, 185.96it/s]concatenating: train:  47%|████▋     | 134/285 [00:00<00:00, 212.78it/s]concatenating: train:  58%|█████▊    | 164/285 [00:00<00:00, 231.54it/s]concatenating: train:  69%|██████▉   | 196/285 [00:00<00:00, 252.10it/s]concatenating: train:  81%|████████  | 231/285 [00:00<00:00, 274.87it/s]concatenating: train:  93%|█████████▎| 266/285 [00:00<00:00, 293.14it/s]concatenating: train: 100%|██████████| 285/285 [00:00<00:00, 296.39it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.22s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.20s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.15s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 483.81it/s]2019-07-09 07:32:35.361895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-09 07:32:35.361985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-09 07:32:35.362001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-09 07:32:35.362009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-09 07:32:35.362382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12743 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.33it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.37it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  6.13it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.85it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:03,  8.61it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  7.50it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02,  9.64it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02, 10.08it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:01<00:02,  8.15it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:01, 10.00it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01, 10.25it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01, 10.30it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:02<00:01,  8.17it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00, 10.07it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00, 10.42it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 10.43it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  8.12it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 11.60it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 10)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 11)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 15)   1500        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 15)   2040        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 15)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 40, 26, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 30)   4080        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 30)   8130        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 45)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 60)   24360       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 60)   32460       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 105)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 30)   12630       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 30)   8130        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 105)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 40, 26, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 15)   6315        dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 15)   2040        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 45)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 80, 52, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 10)   4060        dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 80, 52, 10)   40          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 52, 10)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 80, 52, 10)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 80, 52, 55)   0           dropout_6[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 52, 13)   728         concatenate_8[0][0]              
==================================================================================================
Total params: 132,198
Trainable params: 33,698
Non-trainable params: 98,500
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 25s - loss: 26744.0517 - acc: 0.5106 - mDice: 0.0674 - val_loss: 14704.2136 - val_acc: 0.9020 - val_mDice: 0.1519

Epoch 00001: val_mDice improved from -inf to 0.15194, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 15s - loss: 10609.1736 - acc: 0.8782 - mDice: 0.2662 - val_loss: 8944.3064 - val_acc: 0.9047 - val_mDice: 0.3064

Epoch 00002: val_mDice improved from 0.15194 to 0.30643, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 16s - loss: 7205.4592 - acc: 0.8850 - mDice: 0.3923 - val_loss: 6550.1158 - val_acc: 0.9050 - val_mDice: 0.4097

Epoch 00003: val_mDice improved from 0.30643 to 0.40970, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 16s - loss: 6204.8210 - acc: 0.8883 - mDice: 0.4470 - val_loss: 5658.2627 - val_acc: 0.9107 - val_mDice: 0.4597

Epoch 00004: val_mDice improved from 0.40970 to 0.45972, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 17s - loss: 5653.6093 - acc: 0.8926 - mDice: 0.4794 - val_loss: 5523.4647 - val_acc: 0.9153 - val_mDice: 0.4679

Epoch 00005: val_mDice improved from 0.45972 to 0.46794, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 15s - loss: 5274.7840 - acc: 0.8989 - mDice: 0.5037 - val_loss: 5499.1815 - val_acc: 0.9182 - val_mDice: 0.4694

Epoch 00006: val_mDice improved from 0.46794 to 0.46945, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 15s - loss: 5000.2782 - acc: 0.9060 - mDice: 0.5212 - val_loss: 5412.9430 - val_acc: 0.9232 - val_mDice: 0.4746

Epoch 00007: val_mDice improved from 0.46945 to 0.47459, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 16s - loss: 4792.1676 - acc: 0.9131 - mDice: 0.5351 - val_loss: 5291.9885 - val_acc: 0.9270 - val_mDice: 0.4830

Epoch 00008: val_mDice improved from 0.47459 to 0.48300, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 16s - loss: 4625.8990 - acc: 0.9175 - mDice: 0.5469 - val_loss: 5377.3976 - val_acc: 0.9253 - val_mDice: 0.4793

Epoch 00009: val_mDice did not improve from 0.48300
Epoch 10/300
 - 15s - loss: 4470.5923 - acc: 0.9207 - mDice: 0.5571 - val_loss: 5082.9152 - val_acc: 0.9269 - val_mDice: 0.4932

Epoch 00010: val_mDice improved from 0.48300 to 0.49324, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 15s - loss: 4342.1723 - acc: 0.9225 - mDice: 0.5661 - val_loss: 5431.7846 - val_acc: 0.9275 - val_mDice: 0.4746

Epoch 00011: val_mDice did not improve from 0.49324
Epoch 12/300
 - 15s - loss: 4216.0820 - acc: 0.9240 - mDice: 0.5753 - val_loss: 4688.4463 - val_acc: 0.9325 - val_mDice: 0.5194

Epoch 00012: val_mDice improved from 0.49324 to 0.51943, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 16s - loss: 4118.0285 - acc: 0.9251 - mDice: 0.5823 - val_loss: 4764.2541 - val_acc: 0.9316 - val_mDice: 0.5160

Epoch 00013: val_mDice did not improve from 0.51943
Epoch 14/300
 - 16s - loss: 4031.5638 - acc: 0.9262 - mDice: 0.5887 - val_loss: 4881.7503 - val_acc: 0.9310 - val_mDice: 0.5097

Epoch 00014: val_mDice did not improve from 0.51943
Epoch 15/300
 - 16s - loss: 3936.6960 - acc: 0.9272 - mDice: 0.5959 - val_loss: 4539.2819 - val_acc: 0.9336 - val_mDice: 0.5306

Epoch 00015: val_mDice improved from 0.51943 to 0.53064, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 16s - loss: 3902.0627 - acc: 0.9276 - mDice: 0.5986 - val_loss: 4435.9326 - val_acc: 0.9341 - val_mDice: 0.5381

Epoch 00016: val_mDice improved from 0.53064 to 0.53812, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 16s - loss: 3816.3533 - acc: 0.9287 - mDice: 0.6053 - val_loss: 4626.0355 - val_acc: 0.9336 - val_mDice: 0.5261

Epoch 00017: val_mDice did not improve from 0.53812
Epoch 18/300
 - 16s - loss: 3771.9438 - acc: 0.9289 - mDice: 0.6087 - val_loss: 4619.8519 - val_acc: 0.9307 - val_mDice: 0.5262

Epoch 00018: val_mDice did not improve from 0.53812
Epoch 19/300
 - 16s - loss: 3710.3405 - acc: 0.9296 - mDice: 0.6135 - val_loss: 4568.5677 - val_acc: 0.9309 - val_mDice: 0.5275

Epoch 00019: val_mDice did not improve from 0.53812
Epoch 20/300
 - 16s - loss: 3678.2255 - acc: 0.9302 - mDice: 0.6161 - val_loss: 4684.6380 - val_acc: 0.9315 - val_mDice: 0.5206

Epoch 00020: val_mDice did not improve from 0.53812
Epoch 21/300
 - 16s - loss: 3625.1726 - acc: 0.9308 - mDice: 0.6203 - val_loss: 4403.6482 - val_acc: 0.9317 - val_mDice: 0.5405

Epoch 00021: val_mDice improved from 0.53812 to 0.54046, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 22/300
 - 16s - loss: 3562.4675 - acc: 0.9314 - mDice: 0.6251 - val_loss: 4404.9063 - val_acc: 0.9306 - val_mDice: 0.5405

Epoch 00022: val_mDice improved from 0.54046 to 0.54048, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 23/300
 - 15s - loss: 3557.8834 - acc: 0.9315 - mDice: 0.6256 - val_loss: 5020.0267 - val_acc: 0.9205 - val_mDice: 0.4984

Epoch 00023: val_mDice did not improve from 0.54048
Epoch 24/300
 - 16s - loss: 3506.8360 - acc: 0.9320 - mDice: 0.6296 - val_loss: 4357.0046 - val_acc: 0.9304 - val_mDice: 0.5452

Epoch 00024: val_mDice improved from 0.54048 to 0.54523, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 25/300
 - 16s - loss: 3483.7614 - acc: 0.9326 - mDice: 0.6317 - val_loss: 4419.8684 - val_acc: 0.9338 - val_mDice: 0.5403

Epoch 00025: val_mDice did not improve from 0.54523
Epoch 26/300
 - 16s - loss: 3442.7097 - acc: 0.9329 - mDice: 0.6350 - val_loss: 4410.6103 - val_acc: 0.9312 - val_mDice: 0.5387

Epoch 00026: val_mDice did not improve from 0.54523
Epoch 27/300
 - 16s - loss: 3444.3801 - acc: 0.9331 - mDice: 0.6349 - val_loss: 4499.7222 - val_acc: 0.9312 - val_mDice: 0.5352

Epoch 00027: val_mDice did not improve from 0.54523
Epoch 28/300
 - 15s - loss: 3377.5544 - acc: 0.9337 - mDice: 0.6403 - val_loss: 4577.1688 - val_acc: 0.9317 - val_mDice: 0.5283

Epoch 00028: val_mDice did not improve from 0.54523
Epoch 29/300
 - 15s - loss: 3362.9526 - acc: 0.9341 - mDice: 0.6415 - val_loss: 4412.5750 - val_acc: 0.9335 - val_mDice: 0.5400

Epoch 00029: val_mDice did not improve from 0.54523
Epoch 30/300
 - 16s - loss: 3346.1632 - acc: 0.9342 - mDice: 0.6431 - val_loss: 4254.8848 - val_acc: 0.9323 - val_mDice: 0.5521

Epoch 00030: val_mDice improved from 0.54523 to 0.55213, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 31/300
 - 16s - loss: 3326.1288 - acc: 0.9343 - mDice: 0.6446 - val_loss: 4655.2407 - val_acc: 0.9295 - val_mDice: 0.5220

Epoch 00031: val_mDice did not improve from 0.55213
Epoch 32/300
 - 16s - loss: 3287.9964 - acc: 0.9347 - mDice: 0.6477 - val_loss: 4308.0092 - val_acc: 0.9321 - val_mDice: 0.5484

Epoch 00032: val_mDice did not improve from 0.55213
Epoch 33/300
 - 16s - loss: 3290.2162 - acc: 0.9348 - mDice: 0.6477 - val_loss: 4387.0514 - val_acc: 0.9321 - val_mDice: 0.5436

Epoch 00033: val_mDice did not improve from 0.55213
Epoch 34/300
 - 16s - loss: 3266.6664 - acc: 0.9350 - mDice: 0.6497 - val_loss: 4353.1147 - val_acc: 0.9321 - val_mDice: 0.5445

Epoch 00034: val_mDice did not improve from 0.55213
Epoch 35/300
 - 15s - loss: 3227.3214 - acc: 0.9353 - mDice: 0.6528 - val_loss: 4120.4020 - val_acc: 0.9343 - val_mDice: 0.5602

Epoch 00035: val_mDice improved from 0.55213 to 0.56023, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 36/300
 - 16s - loss: 3219.5329 - acc: 0.9355 - mDice: 0.6536 - val_loss: 4181.3525 - val_acc: 0.9340 - val_mDice: 0.5558

Epoch 00036: val_mDice did not improve from 0.56023
Epoch 37/300
 - 16s - loss: 3204.7108 - acc: 0.9357 - mDice: 0.6549 - val_loss: 4176.0955 - val_acc: 0.9339 - val_mDice: 0.5564

Epoch 00037: val_mDice did not improve from 0.56023
Epoch 38/300
 - 14s - loss: 3180.7801 - acc: 0.9358 - mDice: 0.6568 - val_loss: 4254.7242 - val_acc: 0.9325 - val_mDice: 0.5503

Epoch 00038: val_mDice did not improve from 0.56023
Epoch 39/300
 - 15s - loss: 3178.0349 - acc: 0.9360 - mDice: 0.6573 - val_loss: 4205.7002 - val_acc: 0.9368 - val_mDice: 0.5551

Epoch 00039: val_mDice did not improve from 0.56023
Epoch 40/300
 - 15s - loss: 3152.3192 - acc: 0.9361 - mDice: 0.6592 - val_loss: 4118.1515 - val_acc: 0.9371 - val_mDice: 0.5614

Epoch 00040: val_mDice improved from 0.56023 to 0.56143, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 41/300
 - 17s - loss: 3155.6089 - acc: 0.9361 - mDice: 0.6591 - val_loss: 4277.8792 - val_acc: 0.9359 - val_mDice: 0.5491

Epoch 00041: val_mDice did not improve from 0.56143
Epoch 42/300
 - 15s - loss: 3130.5024 - acc: 0.9364 - mDice: 0.6613 - val_loss: 4533.4216 - val_acc: 0.9307 - val_mDice: 0.5288

Epoch 00042: val_mDice did not improve from 0.56143
Epoch 43/300
 - 15s - loss: 3125.4311 - acc: 0.9365 - mDice: 0.6617 - val_loss: 4291.7773 - val_acc: 0.9326 - val_mDice: 0.5485

Epoch 00043: val_mDice did not improve from 0.56143
Epoch 44/300
 - 14s - loss: 3094.5554 - acc: 0.9366 - mDice: 0.6642 - val_loss: 4355.6675 - val_acc: 0.9326 - val_mDice: 0.5436

Epoch 00044: val_mDice did not improve from 0.56143
Epoch 45/300
 - 14s - loss: 3083.7358 - acc: 0.9367 - mDice: 0.6651 - val_loss: 4553.8989 - val_acc: 0.9299 - val_mDice: 0.5283

Epoch 00045: val_mDice did not improve from 0.56143
Epoch 46/300
 - 15s - loss: 3076.0136 - acc: 0.9368 - mDice: 0.6658 - val_loss: 4144.3493 - val_acc: 0.9356 - val_mDice: 0.5578

Epoch 00046: val_mDice did not improve from 0.56143
Epoch 47/300
 - 15s - loss: 3059.7847 - acc: 0.9371 - mDice: 0.6672 - val_loss: 4254.8807 - val_acc: 0.9349 - val_mDice: 0.5485

Epoch 00047: val_mDice did not improve from 0.56143
Epoch 48/300
 - 16s - loss: 3049.7195 - acc: 0.9371 - mDice: 0.6681 - val_loss: 4339.5768 - val_acc: 0.9339 - val_mDice: 0.5441

Epoch 00048: val_mDice did not improve from 0.56143
Epoch 49/300
 - 15s - loss: 3034.3658 - acc: 0.9373 - mDice: 0.6693 - val_loss: 4251.1587 - val_acc: 0.9323 - val_mDice: 0.5505

Epoch 00049: val_mDice did not improve from 0.56143
Epoch 50/300
 - 15s - loss: 3029.3959 - acc: 0.9373 - mDice: 0.6698 - val_loss: 4097.7575 - val_acc: 0.9338 - val_mDice: 0.5614

Epoch 00050: val_mDice did not improve from 0.56143
Epoch 51/300
 - 15s - loss: 3028.1296 - acc: 0.9373 - mDice: 0.6700 - val_loss: 4202.4922 - val_acc: 0.9352 - val_mDice: 0.5556

Epoch 00051: val_mDice did not improve from 0.56143
Epoch 52/300
 - 15s - loss: 3026.8967 - acc: 0.9375 - mDice: 0.6702 - val_loss: 4462.7549 - val_acc: 0.9305 - val_mDice: 0.5325

Epoch 00052: val_mDice did not improve from 0.56143
Epoch 53/300
 - 15s - loss: 2995.7193 - acc: 0.9379 - mDice: 0.6729 - val_loss: 4153.0665 - val_acc: 0.9343 - val_mDice: 0.5573

Epoch 00053: val_mDice did not improve from 0.56143
Epoch 54/300
 - 16s - loss: 2986.8362 - acc: 0.9379 - mDice: 0.6736 - val_loss: 4128.7771 - val_acc: 0.9371 - val_mDice: 0.5593

Epoch 00054: val_mDice did not improve from 0.56143
Epoch 55/300
 - 15s - loss: 2966.3852 - acc: 0.9381 - mDice: 0.6754 - val_loss: 4439.6216 - val_acc: 0.9359 - val_mDice: 0.5368

Epoch 00055: val_mDice did not improve from 0.56143
Epoch 56/300
 - 15s - loss: 2965.0333 - acc: 0.9381 - mDice: 0.6755 - val_loss: 4291.6987 - val_acc: 0.9321 - val_mDice: 0.5476

Epoch 00056: val_mDice did not improve from 0.56143
Epoch 57/300
 - 15s - loss: 2966.7940 - acc: 0.9381 - mDice: 0.6754 - val_loss: 4232.6319 - val_acc: 0.9326 - val_mDice: 0.5514

Epoch 00057: val_mDice did not improve from 0.56143
Epoch 58/300
 - 15s - loss: 2961.2202 - acc: 0.9382 - mDice: 0.6759 - val_loss: 4298.9809 - val_acc: 0.9356 - val_mDice: 0.5485

Epoch 00058: val_mDice did not improve from 0.56143
Epoch 59/300
 - 15s - loss: 2929.4917 - acc: 0.9385 - mDice: 0.6787 - val_loss: 4276.6910 - val_acc: 0.9356 - val_mDice: 0.5495

Epoch 00059: val_mDice did not improve from 0.56143
Epoch 60/300
 - 16s - loss: 2926.0458 - acc: 0.9385 - mDice: 0.6789 - val_loss: 4334.4458 - val_acc: 0.9333 - val_mDice: 0.5452

Epoch 00060: val_mDice did not improve from 0.56143
Epoch 61/300
 - 16s - loss: 2918.8552 - acc: 0.9386 - mDice: 0.6796 - val_loss: 4263.7857 - val_acc: 0.9337 - val_mDice: 0.5497

Epoch 00061: val_mDice did not improve from 0.56143
Epoch 62/300
 - 16s - loss: 2922.0407 - acc: 0.9386 - mDice: 0.6793 - val_loss: 4328.7955 - val_acc: 0.9345 - val_mDice: 0.5445

Epoch 00062: val_mDice did not improve from 0.56143
Epoch 63/300
 - 15s - loss: 2918.5198 - acc: 0.9387 - mDice: 0.6797 - val_loss: 4416.8616 - val_acc: 0.9300 - val_mDice: 0.5383

Epoch 00063: val_mDice did not improve from 0.56143
Epoch 64/300
 - 15s - loss: 2888.2953 - acc: 0.9387 - mDice: 0.6821 - val_loss: 4459.6859 - val_acc: 0.9367 - val_mDice: 0.5376

Epoch 00064: val_mDice did not improve from 0.56143
Epoch 65/300
 - 15s - loss: 2887.2354 - acc: 0.9389 - mDice: 0.6825 - val_loss: 4297.2534 - val_acc: 0.9349 - val_mDice: 0.5467

Epoch 00065: val_mDice did not improve from 0.56143
Epoch 66/300
 - 15s - loss: 2890.9559 - acc: 0.9390 - mDice: 0.6820 - val_loss: 4354.6551 - val_acc: 0.9335 - val_mDice: 0.5437

Epoch 00066: val_mDice did not improve from 0.56143
Epoch 67/300
 - 15s - loss: 2877.0062 - acc: 0.9391 - mDice: 0.6833 - val_loss: 4246.0251 - val_acc: 0.9343 - val_mDice: 0.5520

Epoch 00067: val_mDice did not improve from 0.56143
Epoch 68/300
 - 16s - loss: 2874.5546 - acc: 0.9392 - mDice: 0.6836 - val_loss: 4182.2240 - val_acc: 0.9359 - val_mDice: 0.5571

Epoch 00068: val_mDice did not improve from 0.56143
Epoch 69/300
 - 15s - loss: 2855.0262 - acc: 0.9393 - mDice: 0.6852 - val_loss: 4109.1037 - val_acc: 0.9386 - val_mDice: 0.5622

Epoch 00069: val_mDice improved from 0.56143 to 0.56217, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 70/300
 - 15s - loss: 2852.8803 - acc: 0.9393 - mDice: 0.6854 - val_loss: 4311.2960 - val_acc: 0.9344 - val_mDice: 0.5467

Epoch 00070: val_mDice did not improve from 0.56217
Epoch 71/300
 - 15s - loss: 2853.1081 - acc: 0.9394 - mDice: 0.6855 - val_loss: 4199.7031 - val_acc: 0.9378 - val_mDice: 0.5545

Epoch 00071: val_mDice did not improve from 0.56217
Epoch 72/300
 - 14s - loss: 2838.4862 - acc: 0.9394 - mDice: 0.6867 - val_loss: 4366.3300 - val_acc: 0.9311 - val_mDice: 0.5422

Epoch 00072: val_mDice did not improve from 0.56217
Epoch 73/300
 - 15s - loss: 2819.1987 - acc: 0.9396 - mDice: 0.6884 - val_loss: 4369.9638 - val_acc: 0.9338 - val_mDice: 0.5416

Epoch 00073: val_mDice did not improve from 0.56217
Epoch 74/300
 - 15s - loss: 2829.1817 - acc: 0.9395 - mDice: 0.6876 - val_loss: 4193.5401 - val_acc: 0.9344 - val_mDice: 0.5552

Epoch 00074: val_mDice did not improve from 0.56217
Epoch 75/300
 - 16s - loss: 2836.0833 - acc: 0.9394 - mDice: 0.6870 - val_loss: 4211.5303 - val_acc: 0.9364 - val_mDice: 0.5537

Epoch 00075: val_mDice did not improve from 0.56217
Epoch 76/300
 - 16s - loss: 2822.6810 - acc: 0.9397 - mDice: 0.6881 - val_loss: 4168.6595 - val_acc: 0.9354 - val_mDice: 0.5582

Epoch 00076: val_mDice did not improve from 0.56217
Epoch 77/300
 - 15s - loss: 2821.4219 - acc: 0.9397 - mDice: 0.6883 - val_loss: 4232.6793 - val_acc: 0.9369 - val_mDice: 0.5525

Epoch 00077: val_mDice did not improve from 0.56217
Epoch 78/300
 - 15s - loss: 2799.1702 - acc: 0.9400 - mDice: 0.6902 - val_loss: 4125.0720 - val_acc: 0.9361 - val_mDice: 0.5605

Epoch 00078: val_mDice did not improve from 0.56217
Epoch 79/300
 - 15s - loss: 2815.4100 - acc: 0.9399 - mDice: 0.6889 - val_loss: 4392.8447 - val_acc: 0.9346 - val_mDice: 0.5390

Epoch 00079: val_mDice did not improve from 0.56217
Epoch 80/300
 - 15s - loss: 2794.7977 - acc: 0.9399 - mDice: 0.6907 - val_loss: 4241.3360 - val_acc: 0.9368 - val_mDice: 0.5533

Epoch 00080: val_mDice did not improve from 0.56217
Epoch 81/300
 - 15s - loss: 2790.3765 - acc: 0.9399 - mDice: 0.6910 - val_loss: 4393.9515 - val_acc: 0.9357 - val_mDice: 0.5410

Epoch 00081: val_mDice did not improve from 0.56217
Epoch 82/300
 - 16s - loss: 2773.2464 - acc: 0.9402 - mDice: 0.6925 - val_loss: 4560.8399 - val_acc: 0.9305 - val_mDice: 0.5290

Epoch 00082: val_mDice did not improve from 0.56217
Epoch 83/300
 - 16s - loss: 2772.3846 - acc: 0.9402 - mDice: 0.6927 - val_loss: 4357.3725 - val_acc: 0.9372 - val_mDice: 0.5430

Epoch 00083: val_mDice did not improve from 0.56217
Epoch 84/300
 - 16s - loss: 2765.0366 - acc: 0.9402 - mDice: 0.6933 - val_loss: 4192.5344 - val_acc: 0.9367 - val_mDice: 0.5555

Epoch 00084: val_mDice did not improve from 0.56217
Epoch 85/300
 - 15s - loss: 2769.9739 - acc: 0.9403 - mDice: 0.6930 - val_loss: 4090.1338 - val_acc: 0.9381 - val_mDice: 0.5620

Epoch 00085: val_mDice did not improve from 0.56217
Epoch 86/300
 - 16s - loss: 2756.2347 - acc: 0.9404 - mDice: 0.6942 - val_loss: 4070.2853 - val_acc: 0.9385 - val_mDice: 0.5642

Epoch 00086: val_mDice improved from 0.56217 to 0.56417, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 87/300
 - 15s - loss: 2755.0670 - acc: 0.9405 - mDice: 0.6943 - val_loss: 4150.9759 - val_acc: 0.9379 - val_mDice: 0.5584

Epoch 00087: val_mDice did not improve from 0.56417
Epoch 88/300
 - 15s - loss: 2754.2841 - acc: 0.9405 - mDice: 0.6943 - val_loss: 4431.6980 - val_acc: 0.9355 - val_mDice: 0.5391

Epoch 00088: val_mDice did not improve from 0.56417
Epoch 89/300
 - 15s - loss: 2746.4295 - acc: 0.9406 - mDice: 0.6951 - val_loss: 4492.1888 - val_acc: 0.9338 - val_mDice: 0.5371

Epoch 00089: val_mDice did not improve from 0.56417
Epoch 90/300
 - 16s - loss: 2739.7678 - acc: 0.9407 - mDice: 0.6957 - val_loss: 4394.9010 - val_acc: 0.9362 - val_mDice: 0.5416

Epoch 00090: val_mDice did not improve from 0.56417
Epoch 91/300
 - 15s - loss: 2734.4907 - acc: 0.9406 - mDice: 0.6960 - val_loss: 4171.8365 - val_acc: 0.9388 - val_mDice: 0.5574

Epoch 00091: val_mDice did not improve from 0.56417
Epoch 92/300
 - 16s - loss: 2732.3196 - acc: 0.9407 - mDice: 0.6963 - val_loss: 4433.4814 - val_acc: 0.9366 - val_mDice: 0.5388

Epoch 00092: val_mDice did not improve from 0.56417
Epoch 93/300
 - 15s - loss: 2719.6664 - acc: 0.9408 - mDice: 0.6973 - val_loss: 4276.8138 - val_acc: 0.9349 - val_mDice: 0.5484

Epoch 00093: val_mDice did not improve from 0.56417
Epoch 94/300
 - 15s - loss: 2731.4958 - acc: 0.9409 - mDice: 0.6964 - val_loss: 4298.7811 - val_acc: 0.9371 - val_mDice: 0.5480

Epoch 00094: val_mDice did not improve from 0.56417
Epoch 95/300
 - 16s - loss: 2722.6331 - acc: 0.9407 - mDice: 0.6971 - val_loss: 4261.3454 - val_acc: 0.9356 - val_mDice: 0.5496

Epoch 00095: val_mDice did not improve from 0.56417
Epoch 96/300
 - 16s - loss: 2719.8929 - acc: 0.9408 - mDice: 0.6974 - val_loss: 4143.9837 - val_acc: 0.9392 - val_mDice: 0.5587

Epoch 00096: val_mDice did not improve from 0.56417
Epoch 97/300
 - 16s - loss: 2700.7616 - acc: 0.9409 - mDice: 0.6991 - val_loss: 4185.9847 - val_acc: 0.9363 - val_mDice: 0.5560

Epoch 00097: val_mDice did not improve from 0.56417
Epoch 98/300
 - 15s - loss: 2700.0539 - acc: 0.9411 - mDice: 0.6991 - val_loss: 4267.5323 - val_acc: 0.9387 - val_mDice: 0.5499

Epoch 00098: val_mDice did not improve from 0.56417
Epoch 99/300
 - 16s - loss: 2707.5042 - acc: 0.9411 - mDice: 0.6986 - val_loss: 4172.0865 - val_acc: 0.9362 - val_mDice: 0.5567

Epoch 00099: val_mDice did not improve from 0.56417
Epoch 100/300
 - 15s - loss: 2689.3357 - acc: 0.9412 - mDice: 0.7001 - val_loss: 4202.0273 - val_acc: 0.9385 - val_mDice: 0.5543

Epoch 00100: val_mDice did not improve from 0.56417
Epoch 101/300
 - 15s - loss: 2682.9307 - acc: 0.9412 - mDice: 0.7007 - val_loss: 4351.0093 - val_acc: 0.9347 - val_mDice: 0.5437

Epoch 00101: val_mDice did not improve from 0.56417
Epoch 102/300
 - 15s - loss: 2695.4943 - acc: 0.9411 - mDice: 0.6996 - val_loss: 4163.5019 - val_acc: 0.9379 - val_mDice: 0.5571

Epoch 00102: val_mDice did not improve from 0.56417
Epoch 103/300
 - 16s - loss: 2705.0713 - acc: 0.9411 - mDice: 0.6987 - val_loss: 4281.7417 - val_acc: 0.9346 - val_mDice: 0.5500

Epoch 00103: val_mDice did not improve from 0.56417
Epoch 104/300
 - 16s - loss: 2679.6854 - acc: 0.9412 - mDice: 0.7010 - val_loss: 4367.5373 - val_acc: 0.9386 - val_mDice: 0.5450

Epoch 00104: val_mDice did not improve from 0.56417
Epoch 105/300
 - 14s - loss: 2685.4801 - acc: 0.9413 - mDice: 0.7005 - val_loss: 4422.3847 - val_acc: 0.9355 - val_mDice: 0.5399

Epoch 00105: val_mDice did not improve from 0.56417
Epoch 106/300
 - 15s - loss: 2671.2195 - acc: 0.9415 - mDice: 0.7018 - val_loss: 4263.7041 - val_acc: 0.9364 - val_mDice: 0.5528

Epoch 00106: val_mDice did not improve from 0.56417
Epoch 107/300
 - 15s - loss: 2668.1002 - acc: 0.9415 - mDice: 0.7020 - val_loss: 4298.3982 - val_acc: 0.9363 - val_mDice: 0.5495

Epoch 00107: val_mDice did not improve from 0.56417
Epoch 108/300
 - 15s - loss: 2652.3841 - acc: 0.9417 - mDice: 0.7035 - val_loss: 4261.7552 - val_acc: 0.9357 - val_mDice: 0.5510

Epoch 00108: val_mDice did not improve from 0.56417
Epoch 109/300
 - 15s - loss: 2662.0830 - acc: 0.9415 - mDice: 0.7027 - val_loss: 4207.1854 - val_acc: 0.9367 - val_mDice: 0.5555

Epoch 00109: val_mDice did not improve from 0.56417
Epoch 110/300
 - 15s - loss: 2671.0540 - acc: 0.9415 - mDice: 0.7019 - val_loss: 4304.8850 - val_acc: 0.9356 - val_mDice: 0.5473

Epoch 00110: val_mDice did not improve from 0.56417
Epoch 111/300
 - 16s - loss: 2648.8966 - acc: 0.9416 - mDice: 0.7039 - val_loss: 4352.4299 - val_acc: 0.9361 - val_mDice: 0.5449

Epoch 00111: val_mDice did not improve from 0.56417
Epoch 112/300
 - 15s - loss: 2666.6148 - acc: 0.9416 - mDice: 0.7023 - val_loss: 4302.4972 - val_acc: 0.9372 - val_mDice: 0.5489

Epoch 00112: val_mDice did not improve from 0.56417
Epoch 113/300
 - 16s - loss: 2671.7221 - acc: 0.9416 - mDice: 0.7018 - val_loss: 4423.2668 - val_acc: 0.9383 - val_mDice: 0.5402

Epoch 00113: val_mDice did not improve from 0.56417
Epoch 114/300
 - 15s - loss: 2645.7254 - acc: 0.9417 - mDice: 0.7042 - val_loss: 4278.2641 - val_acc: 0.9350 - val_mDice: 0.5491

Epoch 00114: val_mDice did not improve from 0.56417
Epoch 115/300
 - 15s - loss: 2643.2812 - acc: 0.9417 - mDice: 0.7044 - val_loss: 4318.6281 - val_acc: 0.9388 - val_mDice: 0.5482

Epoch 00115: val_mDice did not improve from 0.56417
Epoch 116/300
 - 15s - loss: 2657.5827 - acc: 0.9417 - mDice: 0.7032 - val_loss: 4287.4089 - val_acc: 0.9393 - val_mDice: 0.5502

Epoch 00116: val_mDice did not improve from 0.56417
Restoring model weights from the end of the best epoch
Epoch 00116: early stopping
{'val_loss': [14704.213613656852, 8944.306443434496, 6550.115760216346, 5658.262676532452, 5523.464693509615, 5499.181462214543, 5412.942983774038, 5291.988506610577, 5377.397611177885, 5082.9152268629805, 5431.784639798678, 4688.446307842548, 4764.254103440505, 4881.7503004807695, 4539.281897911658, 4435.932551457332, 4626.0354567307695, 4619.851900540865, 4568.5676832932695, 4684.637986403245, 4403.648155799279, 4404.906287560096, 5020.026705228365, 4357.004591721755, 4419.8683518629805, 4410.610342172476, 4499.72216796875, 4577.168766902043, 4412.574960561899, 4254.8848219651445, 4655.240694486178, 4308.0092210036055, 4387.051372821515, 4353.114736703726, 4120.401991624099, 4181.352459247296, 4176.0954824594355, 4254.724200908954, 4205.700214092548, 4118.1514892578125, 4277.879234900842, 4533.421630859375, 4291.777324969952, 4355.667466383714, 4553.898864746094, 4144.3492760291465, 4254.880676269531, 4339.576805701623, 4251.158696101262, 4097.757497934194, 4202.492168719952, 4462.754901592548, 4153.066467285156, 4128.777057354267, 4439.621614896334, 4291.698702298678, 4232.631887582632, 4298.9809335561895, 4276.691044734074, 4334.445782001202, 4263.785729041467, 4328.795452411358, 4416.861586350661, 4459.685936560998, 4297.2534414438105, 4354.655109112079, 4246.025104229267, 4182.223989633413, 4109.1037034254805, 4311.2959547776445, 4199.7030686598555, 4366.329960749699, 4369.9638437124395, 4193.54008601262, 4211.530310997596, 4168.659503643329, 4232.679260253906, 4125.0719651442305, 4392.844656137319, 4241.3359938401445, 4393.951524000901, 4560.8399329552285, 4357.372544508714, 4192.534372182993, 4090.13376558744, 4070.2852877103364, 4150.975909893329, 4431.697965181791, 4492.188800518329, 4394.901015061599, 4171.8365478515625, 4433.481431227464, 4276.81382399339, 4298.781085674579, 4261.345440204327, 4143.9837317833535, 4185.984703650842, 4267.532278207632, 4172.086491511418, 4202.027315579928, 4351.009286733774, 4163.50185922476, 4281.741732083834, 4367.537311260517, 4422.384652944712, 4263.70414851262, 4298.398202749399, 4261.755197378306, 4207.185373159556, 4304.885042630709, 4352.4299081655645, 4302.497248722957, 4423.266845703125, 4278.264082688552, 4318.628112792969, 4287.408921461839], 'val_acc': [0.9019577480279483, 0.9046644018246577, 0.904994921042369, 0.9107156097888947, 0.9152991015177506, 0.9181767747952387, 0.9232156070379111, 0.9270201348341428, 0.9253212603238913, 0.9268976610440475, 0.9275055734010843, 0.932502764921922, 0.9315805228856894, 0.9310350303466504, 0.9336099487084609, 0.9341484720890338, 0.9336260855197906, 0.9307253360748291, 0.9308547652684726, 0.9315181443324456, 0.9316845238208771, 0.9305612169779264, 0.920525135902258, 0.9303600994440225, 0.9337994387516608, 0.9311806490788093, 0.9311922284273001, 0.9317376819940714, 0.933487403851289, 0.9322762649792892, 0.9294956555733314, 0.9320774880739359, 0.9320797943151914, 0.9321375878957602, 0.9342940931136792, 0.9340121264641101, 0.933924294435061, 0.9325189819702735, 0.9367533968045161, 0.9371463839824383, 0.9358727542253641, 0.9306605802132533, 0.9325698040998899, 0.9325813467685993, 0.929890914605214, 0.9355769226184258, 0.9349158520881946, 0.9339126967466794, 0.9323363693860861, 0.9338387342599722, 0.9352117203749143, 0.9304525645879599, 0.9343495896229377, 0.9371116757392883, 0.9358843473287729, 0.9320520254281851, 0.9326483790691082, 0.9356416349227612, 0.9356162295891688, 0.9333417942890754, 0.9337462805784665, 0.9344928723115188, 0.9300249516963959, 0.9366933428324186, 0.934915875013058, 0.9334735549413241, 0.9343241430245913, 0.9359074303737054, 0.938625665811392, 0.934402720286296, 0.9378212873752301, 0.931069708787478, 0.9337671124018155, 0.9343865582576165, 0.9363997739094955, 0.9353758417643033, 0.9369498743460729, 0.9361409155222086, 0.9345830197517688, 0.936788063782912, 0.9356509126149691, 0.9305242345883296, 0.937238837663944, 0.9366563375179584, 0.9380893890674298, 0.938507786163917, 0.9378559405987079, 0.9354567160973182, 0.9337532336895282, 0.9362310469150543, 0.9387989915334262, 0.9365962170637571, 0.934895056944627, 0.9371348183888656, 0.9355561183049128, 0.9391711216706496, 0.9363119395879599, 0.9387273307030017, 0.9362241121438833, 0.9385054615827707, 0.9346870367343609, 0.9378814078294314, 0.9345668325057397, 0.9385771178282224, 0.9354567458996406, 0.9363743662834167, 0.936270317206016, 0.9356971222620744, 0.9367464964206402, 0.9356347070290492, 0.9360784819492927, 0.9372272812403165, 0.9383251919196203, 0.9349898031124702, 0.9388313362231622, 0.9393352201351752], 'val_mDice': [0.15193709301260802, 0.3064263543257347, 0.409698647661851, 0.45972028804513126, 0.46794401854276657, 0.4694492725225595, 0.4745890268912682, 0.4830043356005962, 0.47932008653879166, 0.4932426603940817, 0.47460674207944137, 0.5194321761910732, 0.5159720784196486, 0.5096647183482463, 0.5306400330020831, 0.5381234626357372, 0.526137273472089, 0.5262402296066284, 0.5275181692380172, 0.520581203011366, 0.5404629449431713, 0.540477855847432, 0.49842943766942394, 0.5452257429177945, 0.5403360724449158, 0.5387462778733327, 0.5352309724459281, 0.5282823431950349, 0.5400366668517773, 0.5521289052871557, 0.5219536509651405, 0.5484038058381814, 0.5436437118511933, 0.5444613345540487, 0.5602302012535242, 0.5557921677827835, 0.5563718722416804, 0.5502719489427713, 0.5551445415386786, 0.561432811503227, 0.5491217578259798, 0.5288134137025247, 0.548480443083323, 0.5436057173288785, 0.5282706601115373, 0.5577788135180106, 0.5484909180265206, 0.5440870787088687, 0.5505396081851079, 0.5614121785530677, 0.5555924950883939, 0.5325168646298922, 0.5572960858161633, 0.559325679563559, 0.5368059099866793, 0.5475674242927477, 0.5513563901185989, 0.5484906681455098, 0.549500224682001, 0.5451708275538224, 0.549690234546478, 0.5445303131754582, 0.5383477463172033, 0.5376280935911032, 0.546723468372455, 0.5437089491349, 0.5520259394095495, 0.5571013540029526, 0.5621689122456771, 0.5466802509931418, 0.5545120159020791, 0.5422108070208476, 0.5415934135134404, 0.5552055125053112, 0.5536688434389921, 0.5582228600978851, 0.5525217870107064, 0.5605138448568491, 0.5389896785983672, 0.553347820845934, 0.5410340451277219, 0.5290439507135978, 0.5429803631626643, 0.5555056092830805, 0.5619722060286082, 0.5641695834123172, 0.5583544975289931, 0.539126781316904, 0.5370979635761335, 0.5416386964229437, 0.5573991078596848, 0.5388176693366125, 0.5484116146197686, 0.548030830346621, 0.5495650252470603, 0.5586991848853918, 0.5559536258761699, 0.54994697868824, 0.5567380522306149, 0.5543390225905639, 0.5436968717437524, 0.5570601081618896, 0.5500412554695056, 0.5449529479329402, 0.5398781878443865, 0.5527557157553159, 0.5494672948351274, 0.5510057640763429, 0.5554636682455356, 0.5472517896157044, 0.5448608484405738, 0.5488755863446456, 0.5401801306467789, 0.5491317000526649, 0.548221903351637, 0.5501964166760445], 'loss': [26744.05174479827, 10609.17356905629, 7205.459195957537, 6204.820964855098, 5653.60932771647, 5274.784001124627, 5000.278206584353, 4792.167618412819, 4625.899000174003, 4470.5923484036, 4342.172255913863, 4216.082039873615, 4118.028498807825, 4031.563843831688, 3936.696046137737, 3902.062746414738, 3816.3533492882975, 3771.943849874073, 3710.3404966679973, 3678.2254846606825, 3625.1725762034876, 3562.4674806849034, 3557.8834442417306, 3506.8360031453003, 3483.7614014887736, 3442.70969332398, 3444.3800894302667, 3377.5543925408388, 3362.9525643974657, 3346.1632021086293, 3326.128768182093, 3287.9964068908043, 3290.216203083931, 3266.666404520774, 3227.3214078905135, 3219.532869325796, 3204.7107729983486, 3180.7800647370063, 3178.0348709839623, 3152.3192299661036, 3155.608853079896, 3130.502403658232, 3125.4310847958504, 3094.555366829226, 3083.735838413986, 3076.013613491099, 3059.7846810167525, 3049.719524740634, 3034.365781209021, 3029.395940726988, 3028.129571382909, 3026.8966899120005, 2995.7193301689094, 2986.8362136245555, 2966.3852234871792, 2965.0332962285215, 2966.7940126690137, 2961.2202211594786, 2929.4916989147846, 2926.0458356292115, 2918.855224744471, 2922.0406826251133, 2918.519841486245, 2888.295264128949, 2887.2354333179746, 2890.955924815405, 2877.0062361797, 2874.5545621310985, 2855.026199634935, 2852.8803364641935, 2853.1080813226276, 2838.4862290772635, 2819.1987032131724, 2829.1816576245546, 2836.0832830364166, 2822.681014579809, 2821.4218597566905, 2799.17019624331, 2815.4100450999313, 2794.797694997727, 2790.376502952023, 2773.2463654952, 2772.3845937718856, 2765.036622467224, 2769.973861585978, 2756.2347108594145, 2755.066973066941, 2754.2841443937223, 2746.429451498897, 2739.76780303699, 2734.490726630318, 2732.319636717039, 2719.66639075226, 2731.4958263278654, 2722.633059894182, 2719.8929086368726, 2700.761644886372, 2700.053872073014, 2707.5041871141666, 2689.3357352728467, 2682.9307101751992, 2695.4942598808166, 2705.0713015588613, 2679.6853688187366, 2685.4801138645935, 2671.2195424494416, 2668.1001982012986, 2652.384145355154, 2662.083048048532, 2671.0539508676393, 2648.8965521030273, 2666.6148128761065, 2671.7220795035178, 2645.7254290237292, 2643.281242693569, 2657.582673517945], 'acc': [0.5106166968178641, 0.8782352934648419, 0.8850303343836918, 0.888347854245295, 0.8925850330535462, 0.8989264854786306, 0.9060163327460907, 0.9130996860207133, 0.9175365688362586, 0.9206635657078466, 0.9224543795917215, 0.9240254947458214, 0.9250551136637442, 0.9261749419494935, 0.9271847004491575, 0.9275897619118058, 0.9286692411567764, 0.9289483978862001, 0.9295878363284503, 0.930174111319481, 0.9308003807907822, 0.9314066281202567, 0.931470612510812, 0.9320212778741227, 0.9325839009637225, 0.9329101922194764, 0.9330922471941545, 0.9337432095345498, 0.9340901441001522, 0.9342225372357023, 0.9342989811353728, 0.9347165013870212, 0.9348445083452285, 0.9350056137192527, 0.9352643770847463, 0.9354862478521931, 0.9357243721570673, 0.9357670726211464, 0.9360152138320654, 0.9360968443143085, 0.9360534360155258, 0.9364191878164078, 0.9364668977367233, 0.936553934552095, 0.9367081506450403, 0.9367883141208132, 0.9370571174085508, 0.9371312958644697, 0.9372963036193978, 0.9373004961792178, 0.9373441896820754, 0.9375425017068035, 0.9379055919456358, 0.9378907386198768, 0.9380875611441564, 0.9380653676737787, 0.9381484850013893, 0.9382319500016889, 0.9385092240258094, 0.9385358514594908, 0.9385768222619739, 0.9386011177044694, 0.938724802800961, 0.9386805304299748, 0.9388505726802572, 0.9389660092096295, 0.9391057401425524, 0.9391747581104527, 0.9392957787479431, 0.939290412796233, 0.9393934138166633, 0.939401377196199, 0.9395847581282298, 0.939479654283637, 0.939448817694505, 0.9396627073708819, 0.9397237194669562, 0.9399898011042581, 0.9398546770777109, 0.939910787113652, 0.9399020059636672, 0.9401641173808214, 0.9401663097301378, 0.9402398052640389, 0.9402975104374716, 0.9403725551149452, 0.9405217569802043, 0.9405128657680414, 0.9405919452286575, 0.9406729542405405, 0.9406209843059555, 0.9406662336533045, 0.9407843990287669, 0.9409246883422677, 0.9407311024441992, 0.9408020008471161, 0.9409441760212339, 0.9410518089376846, 0.9411247688763302, 0.9411876639800462, 0.9412042894541948, 0.9411344346685251, 0.9411033943087965, 0.941221890024711, 0.9412843895598354, 0.9414505735101553, 0.9414687274974023, 0.9416586112065761, 0.9415150858550497, 0.9414932287663955, 0.9415959822266323, 0.9416176002535511, 0.9416156469384848, 0.9417219706581251, 0.9417361594440422, 0.9416744177503954], 'mDice': [0.06741809272348612, 0.2661835687863896, 0.39232149212538264, 0.4470076970010515, 0.4794364399678217, 0.5036725933004501, 0.521216739304752, 0.5351030494381138, 0.5468882080990374, 0.5570924479308564, 0.566145535083997, 0.575255117039943, 0.5822712612649034, 0.5887302932050585, 0.5959200252139193, 0.5985726013313765, 0.6052820371007124, 0.6087455847414396, 0.6134865270333351, 0.6161466842151531, 0.6202617808042676, 0.6251058774846271, 0.6256352774080817, 0.6296212645482062, 0.6317204470829276, 0.6349554768427045, 0.6348699192757603, 0.6402516576523251, 0.6415179119903444, 0.6431112422622527, 0.6445684099366698, 0.6476961266925213, 0.6476917319012823, 0.6496832169235759, 0.6528370405303303, 0.6536162174529698, 0.654907622263021, 0.6568417730536351, 0.6573168042510196, 0.6592001836919745, 0.6591069426833841, 0.6613403041347591, 0.6617392460479514, 0.6642045856269756, 0.665141726984789, 0.6658094257025616, 0.6671909866413924, 0.6681421331557622, 0.6693392534444201, 0.6698260579196705, 0.6700029379105772, 0.6701560644473271, 0.6729323243969516, 0.6735802991775243, 0.6754088238091923, 0.6755339938710561, 0.6753616314482713, 0.675898155536773, 0.678722677691049, 0.678897426877747, 0.6796221460658862, 0.6793313099704061, 0.6797262118617557, 0.6821264160258803, 0.6824567554556201, 0.6820302355457669, 0.6832878466495935, 0.6835525570172595, 0.6851831591130403, 0.6854346607000331, 0.6855366646578355, 0.6866928613692712, 0.6883738054996551, 0.6875580238106396, 0.6870034851843632, 0.6880945159831984, 0.6882771292724897, 0.6902026764352438, 0.6889190398975018, 0.6906572025683955, 0.6909571918385348, 0.6924983481578938, 0.6926502513014764, 0.6932712256177308, 0.6929533263529445, 0.6941597451915669, 0.6942929984139503, 0.6942994349185121, 0.6950580662470797, 0.6957043924312315, 0.6960319125717178, 0.6962857542855487, 0.6973496222533413, 0.6964189072470158, 0.6971114852447566, 0.6973598493835336, 0.6991248809795455, 0.6990835004150565, 0.6985853209405832, 0.7001432375880193, 0.7006651121928201, 0.6996271107003971, 0.6987335618149363, 0.7009852565182516, 0.700537960962276, 0.7018025106778172, 0.7019597979409002, 0.7035113543720029, 0.702660031845503, 0.7018912209583189, 0.7038999756884555, 0.7022651931428826, 0.7017968409859385, 0.7042301961837588, 0.704385934891455, 0.7031523176997744]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.46s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.19s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.96s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:41,  1.84s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:05,  1.71s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:08,  1.73s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:40,  1.64s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:54,  1.70s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:37,  1.64s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:56,  1.72s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<08:01,  1.74s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:19,  1.81s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:26,  1.84s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<07:58,  1.75s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:15,  1.81s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<08:09,  1.80s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<08:12,  1.82s/it]predicting train subjects:   5%|▌         | 15/285 [00:26<08:21,  1.86s/it]predicting train subjects:   6%|▌         | 16/285 [00:28<08:26,  1.88s/it]predicting train subjects:   6%|▌         | 17/285 [00:29<08:02,  1.80s/it]predicting train subjects:   6%|▋         | 18/285 [00:31<08:02,  1.81s/it]predicting train subjects:   7%|▋         | 19/285 [00:33<07:47,  1.76s/it]predicting train subjects:   7%|▋         | 20/285 [00:35<07:55,  1.79s/it]predicting train subjects:   7%|▋         | 21/285 [00:37<08:02,  1.83s/it]predicting train subjects:   8%|▊         | 22/285 [00:38<07:53,  1.80s/it]predicting train subjects:   8%|▊         | 23/285 [00:40<07:59,  1.83s/it]predicting train subjects:   8%|▊         | 24/285 [00:42<07:44,  1.78s/it]predicting train subjects:   9%|▉         | 25/285 [00:44<07:56,  1.83s/it]predicting train subjects:   9%|▉         | 26/285 [00:46<08:07,  1.88s/it]predicting train subjects:   9%|▉         | 27/285 [00:48<07:45,  1.80s/it]predicting train subjects:  10%|▉         | 28/285 [00:49<07:46,  1.82s/it]predicting train subjects:  10%|█         | 29/285 [00:51<07:52,  1.84s/it]predicting train subjects:  11%|█         | 30/285 [00:53<07:59,  1.88s/it]predicting train subjects:  11%|█         | 31/285 [00:55<08:04,  1.91s/it]predicting train subjects:  11%|█         | 32/285 [00:57<07:41,  1.83s/it]predicting train subjects:  12%|█▏        | 33/285 [00:59<07:39,  1.83s/it]predicting train subjects:  12%|█▏        | 34/285 [01:01<07:32,  1.80s/it]predicting train subjects:  12%|█▏        | 35/285 [01:02<07:38,  1.83s/it]predicting train subjects:  13%|█▎        | 36/285 [01:04<07:15,  1.75s/it]predicting train subjects:  13%|█▎        | 37/285 [01:06<07:14,  1.75s/it]predicting train subjects:  13%|█▎        | 38/285 [01:08<07:18,  1.78s/it]predicting train subjects:  14%|█▎        | 39/285 [01:09<07:01,  1.71s/it]predicting train subjects:  14%|█▍        | 40/285 [01:11<07:04,  1.73s/it]predicting train subjects:  14%|█▍        | 41/285 [01:12<06:51,  1.69s/it]predicting train subjects:  15%|█▍        | 42/285 [01:14<06:50,  1.69s/it]predicting train subjects:  15%|█▌        | 43/285 [01:16<06:51,  1.70s/it]predicting train subjects:  15%|█▌        | 44/285 [01:18<07:03,  1.76s/it]predicting train subjects:  16%|█▌        | 45/285 [01:19<06:48,  1.70s/it]predicting train subjects:  16%|█▌        | 46/285 [01:21<06:57,  1.75s/it]predicting train subjects:  16%|█▋        | 47/285 [01:23<06:43,  1.69s/it]predicting train subjects:  17%|█▋        | 48/285 [01:25<06:44,  1.71s/it]predicting train subjects:  17%|█▋        | 49/285 [01:26<06:57,  1.77s/it]predicting train subjects:  18%|█▊        | 50/285 [01:28<06:54,  1.77s/it]predicting train subjects:  18%|█▊        | 51/285 [01:30<07:04,  1.81s/it]predicting train subjects:  18%|█▊        | 52/285 [01:32<06:50,  1.76s/it]predicting train subjects:  19%|█▊        | 53/285 [01:34<06:53,  1.78s/it]predicting train subjects:  19%|█▉        | 54/285 [01:35<06:54,  1.80s/it]predicting train subjects:  19%|█▉        | 55/285 [01:37<06:39,  1.74s/it]predicting train subjects:  20%|█▉        | 56/285 [01:39<06:37,  1.74s/it]predicting train subjects:  20%|██        | 57/285 [01:40<06:21,  1.67s/it]predicting train subjects:  20%|██        | 58/285 [01:42<06:23,  1.69s/it]predicting train subjects:  21%|██        | 59/285 [01:44<06:30,  1.73s/it]predicting train subjects:  21%|██        | 60/285 [01:46<06:37,  1.77s/it]predicting train subjects:  21%|██▏       | 61/285 [01:47<06:16,  1.68s/it]predicting train subjects:  22%|██▏       | 62/285 [01:49<06:18,  1.70s/it]predicting train subjects:  22%|██▏       | 63/285 [01:51<06:16,  1.70s/it]predicting train subjects:  22%|██▏       | 64/285 [01:52<06:01,  1.64s/it]predicting train subjects:  23%|██▎       | 65/285 [01:54<06:07,  1.67s/it]predicting train subjects:  23%|██▎       | 66/285 [01:56<06:12,  1.70s/it]predicting train subjects:  24%|██▎       | 67/285 [01:57<06:13,  1.71s/it]predicting train subjects:  24%|██▍       | 68/285 [01:59<06:03,  1.67s/it]predicting train subjects:  24%|██▍       | 69/285 [02:01<06:08,  1.71s/it]predicting train subjects:  25%|██▍       | 70/285 [02:02<06:07,  1.71s/it]predicting train subjects:  25%|██▍       | 71/285 [02:04<06:09,  1.73s/it]predicting train subjects:  25%|██▌       | 72/285 [02:06<06:00,  1.69s/it]predicting train subjects:  26%|██▌       | 73/285 [02:08<06:04,  1.72s/it]predicting train subjects:  26%|██▌       | 74/285 [02:09<06:05,  1.73s/it]predicting train subjects:  26%|██▋       | 75/285 [02:11<06:09,  1.76s/it]predicting train subjects:  27%|██▋       | 76/285 [02:13<06:07,  1.76s/it]predicting train subjects:  27%|██▋       | 77/285 [02:15<05:53,  1.70s/it]predicting train subjects:  27%|██▋       | 78/285 [02:16<05:43,  1.66s/it]predicting train subjects:  28%|██▊       | 79/285 [02:18<05:42,  1.66s/it]predicting train subjects:  28%|██▊       | 80/285 [02:19<05:44,  1.68s/it]predicting train subjects:  28%|██▊       | 81/285 [02:21<05:33,  1.63s/it]predicting train subjects:  29%|██▉       | 82/285 [02:23<05:36,  1.66s/it]predicting train subjects:  29%|██▉       | 83/285 [02:24<05:31,  1.64s/it]predicting train subjects:  29%|██▉       | 84/285 [02:26<05:24,  1.62s/it]predicting train subjects:  30%|██▉       | 85/285 [02:28<05:36,  1.68s/it]predicting train subjects:  30%|███       | 86/285 [02:29<05:38,  1.70s/it]predicting train subjects:  31%|███       | 87/285 [02:31<05:35,  1.70s/it]predicting train subjects:  31%|███       | 88/285 [02:33<05:26,  1.66s/it]predicting train subjects:  31%|███       | 89/285 [02:34<05:27,  1.67s/it]predicting train subjects:  32%|███▏      | 90/285 [02:36<05:29,  1.69s/it]predicting train subjects:  32%|███▏      | 91/285 [02:38<05:18,  1.64s/it]predicting train subjects:  32%|███▏      | 92/285 [02:39<05:19,  1.66s/it]predicting train subjects:  33%|███▎      | 93/285 [02:41<05:11,  1.62s/it]predicting train subjects:  33%|███▎      | 94/285 [02:43<05:13,  1.64s/it]predicting train subjects:  33%|███▎      | 95/285 [02:44<05:16,  1.67s/it]predicting train subjects:  34%|███▎      | 96/285 [02:46<05:13,  1.66s/it]predicting train subjects:  34%|███▍      | 97/285 [02:48<05:19,  1.70s/it]predicting train subjects:  34%|███▍      | 98/285 [02:49<05:18,  1.70s/it]predicting train subjects:  35%|███▍      | 99/285 [02:51<05:15,  1.69s/it]predicting train subjects:  35%|███▌      | 100/285 [02:53<05:14,  1.70s/it]predicting train subjects:  35%|███▌      | 101/285 [02:54<05:01,  1.64s/it]predicting train subjects:  36%|███▌      | 102/285 [02:56<05:05,  1.67s/it]predicting train subjects:  36%|███▌      | 103/285 [02:58<04:56,  1.63s/it]predicting train subjects:  36%|███▋      | 104/285 [02:59<04:59,  1.66s/it]predicting train subjects:  37%|███▋      | 105/285 [03:01<04:59,  1.66s/it]predicting train subjects:  37%|███▋      | 106/285 [03:03<04:51,  1.63s/it]predicting train subjects:  38%|███▊      | 107/285 [03:04<04:52,  1.65s/it]predicting train subjects:  38%|███▊      | 108/285 [03:06<04:45,  1.62s/it]predicting train subjects:  38%|███▊      | 109/285 [03:07<04:47,  1.63s/it]predicting train subjects:  39%|███▊      | 110/285 [03:09<04:53,  1.68s/it]predicting train subjects:  39%|███▉      | 111/285 [03:11<04:44,  1.63s/it]predicting train subjects:  39%|███▉      | 112/285 [03:12<04:45,  1.65s/it]predicting train subjects:  40%|███▉      | 113/285 [03:14<04:48,  1.68s/it]predicting train subjects:  40%|████      | 114/285 [03:16<04:48,  1.69s/it]predicting train subjects:  40%|████      | 115/285 [03:18<04:51,  1.71s/it]predicting train subjects:  41%|████      | 116/285 [03:19<04:54,  1.74s/it]predicting train subjects:  41%|████      | 117/285 [03:21<04:40,  1.67s/it]predicting train subjects:  41%|████▏     | 118/285 [03:23<04:33,  1.64s/it]predicting train subjects:  42%|████▏     | 119/285 [03:24<04:39,  1.68s/it]predicting train subjects:  42%|████▏     | 120/285 [03:26<04:28,  1.63s/it]predicting train subjects:  42%|████▏     | 121/285 [03:27<04:22,  1.60s/it]predicting train subjects:  43%|████▎     | 122/285 [03:29<04:15,  1.57s/it]predicting train subjects:  43%|████▎     | 123/285 [03:30<04:03,  1.50s/it]predicting train subjects:  44%|████▎     | 124/285 [03:32<04:02,  1.51s/it]predicting train subjects:  44%|████▍     | 125/285 [03:33<03:58,  1.49s/it]predicting train subjects:  44%|████▍     | 126/285 [03:35<03:53,  1.47s/it]predicting train subjects:  45%|████▍     | 127/285 [03:36<03:48,  1.45s/it]predicting train subjects:  45%|████▍     | 128/285 [03:38<03:52,  1.48s/it]predicting train subjects:  45%|████▌     | 129/285 [03:39<03:49,  1.47s/it]predicting train subjects:  46%|████▌     | 130/285 [03:40<03:44,  1.45s/it]predicting train subjects:  46%|████▌     | 131/285 [03:42<03:39,  1.42s/it]predicting train subjects:  46%|████▋     | 132/285 [03:43<03:43,  1.46s/it]predicting train subjects:  47%|████▋     | 133/285 [03:45<03:42,  1.46s/it]predicting train subjects:  47%|████▋     | 134/285 [03:46<03:37,  1.44s/it]predicting train subjects:  47%|████▋     | 135/285 [03:48<03:32,  1.41s/it]predicting train subjects:  48%|████▊     | 136/285 [03:49<03:29,  1.41s/it]predicting train subjects:  48%|████▊     | 137/285 [03:51<03:41,  1.50s/it]predicting train subjects:  48%|████▊     | 138/285 [03:52<03:34,  1.46s/it]predicting train subjects:  49%|████▉     | 139/285 [03:54<03:36,  1.48s/it]predicting train subjects:  49%|████▉     | 140/285 [03:55<03:43,  1.54s/it]predicting train subjects:  49%|████▉     | 141/285 [03:57<03:34,  1.49s/it]predicting train subjects:  50%|████▉     | 142/285 [03:58<03:29,  1.46s/it]predicting train subjects:  50%|█████     | 143/285 [03:59<03:28,  1.47s/it]predicting train subjects:  51%|█████     | 144/285 [04:01<03:28,  1.48s/it]predicting train subjects:  51%|█████     | 145/285 [04:02<03:25,  1.47s/it]predicting train subjects:  51%|█████     | 146/285 [04:04<03:28,  1.50s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:05<03:21,  1.46s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:07<03:23,  1.48s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:08<03:20,  1.47s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:10<03:16,  1.46s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:11<03:19,  1.49s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:13<03:19,  1.50s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:14<03:13,  1.47s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:16<03:17,  1.51s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:17<03:13,  1.49s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:19<03:14,  1.50s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:20<03:07,  1.46s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:22<03:06,  1.47s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:23<03:02,  1.45s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:25<03:00,  1.44s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:26<03:04,  1.49s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:28<03:03,  1.50s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:29<03:03,  1.51s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:31<03:00,  1.49s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:32<02:56,  1.47s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:34<02:58,  1.50s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:35<02:57,  1.50s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:36<02:49,  1.45s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:38<02:48,  1.45s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:39<02:46,  1.45s/it]predicting train subjects:  60%|██████    | 171/285 [04:41<02:43,  1.43s/it]predicting train subjects:  60%|██████    | 172/285 [04:42<02:40,  1.42s/it]predicting train subjects:  61%|██████    | 173/285 [04:43<02:37,  1.41s/it]predicting train subjects:  61%|██████    | 174/285 [04:45<02:36,  1.41s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:47<02:41,  1.47s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:48<02:45,  1.52s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:50<02:41,  1.49s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:51<02:35,  1.45s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:52<02:30,  1.42s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:54<02:38,  1.51s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:56<02:39,  1.53s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:57<02:39,  1.54s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:59<02:35,  1.52s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:00<02:29,  1.48s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:01<02:24,  1.45s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:03<02:31,  1.53s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:05<02:38,  1.62s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:07<02:42,  1.67s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:08<02:30,  1.57s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:09<02:23,  1.52s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:11<02:24,  1.54s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:13<02:26,  1.57s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:14<02:17,  1.49s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:15<02:11,  1.45s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:17<02:06,  1.40s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:18<02:14,  1.51s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:20<02:18,  1.57s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:22<02:21,  1.62s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:23<02:13,  1.55s/it]predicting train subjects:  70%|███████   | 200/285 [05:25<02:08,  1.51s/it]predicting train subjects:  71%|███████   | 201/285 [05:26<02:12,  1.58s/it]predicting train subjects:  71%|███████   | 202/285 [05:28<02:11,  1.59s/it]predicting train subjects:  71%|███████   | 203/285 [05:30<02:11,  1.60s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:31<02:02,  1.51s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:32<01:59,  1.49s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:34<01:53,  1.44s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:35<01:59,  1.53s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:37<02:01,  1.58s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:39<02:03,  1.62s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:40<01:54,  1.53s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:42<01:49,  1.48s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:43<01:51,  1.52s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:45<01:50,  1.53s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:46<01:44,  1.47s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:48<01:49,  1.57s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:49<01:42,  1.49s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:51<01:46,  1.56s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:53<01:48,  1.63s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:54<01:48,  1.64s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:56<01:40,  1.54s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:57<01:35,  1.50s/it]predicting train subjects:  78%|███████▊  | 222/285 [05:59<01:36,  1.54s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:00<01:30,  1.46s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:01<01:28,  1.46s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:03<01:24,  1.40s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:04<01:28,  1.50s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:06<01:30,  1.57s/it]predicting train subjects:  80%|████████  | 228/285 [06:08<01:32,  1.62s/it]predicting train subjects:  80%|████████  | 229/285 [06:09<01:30,  1.61s/it]predicting train subjects:  81%|████████  | 230/285 [06:11<01:23,  1.52s/it]predicting train subjects:  81%|████████  | 231/285 [06:12<01:20,  1.49s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:14<01:20,  1.53s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:15<01:16,  1.47s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:17<01:19,  1.55s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:18<01:15,  1.51s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:20<01:16,  1.57s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:22<01:16,  1.59s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:23<01:16,  1.63s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:25<01:14,  1.62s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:26<01:09,  1.55s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:28<01:06,  1.50s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:29<01:02,  1.45s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:30<01:01,  1.45s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:32<01:03,  1.55s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:34<00:59,  1.48s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:35<01:01,  1.57s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:37<01:01,  1.61s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:39<00:59,  1.62s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:40<00:55,  1.53s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:41<00:52,  1.49s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:43<00:49,  1.44s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:44<00:46,  1.40s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:46<00:47,  1.50s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:47<00:48,  1.56s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:49<00:47,  1.58s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:50<00:43,  1.51s/it]predicting train subjects:  90%|█████████ | 257/285 [06:52<00:41,  1.47s/it]predicting train subjects:  91%|█████████ | 258/285 [06:54<00:42,  1.57s/it]predicting train subjects:  91%|█████████ | 259/285 [06:55<00:40,  1.57s/it]predicting train subjects:  91%|█████████ | 260/285 [06:57<00:37,  1.49s/it]predicting train subjects:  92%|█████████▏| 261/285 [06:58<00:34,  1.43s/it]predicting train subjects:  92%|█████████▏| 262/285 [06:59<00:32,  1.40s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:00<00:30,  1.37s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:02<00:32,  1.55s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:04<00:32,  1.62s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:05<00:28,  1.52s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:07<00:26,  1.48s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:09<00:26,  1.53s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:10<00:24,  1.55s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:11<00:22,  1.48s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:13<00:19,  1.43s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:14<00:19,  1.49s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:16<00:17,  1.45s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:17<00:15,  1.41s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:19<00:15,  1.50s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:20<00:14,  1.56s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:22<00:11,  1.48s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:23<00:10,  1.46s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:25<00:09,  1.52s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:26<00:07,  1.47s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:28<00:05,  1.44s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:29<00:04,  1.43s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:31<00:03,  1.54s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:32<00:01,  1.59s/it]predicting train subjects: 100%|██████████| 285/285 [07:34<00:00,  1.63s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:05,  1.71s/it]Loading train:   1%|          | 2/285 [00:03<07:32,  1.60s/it]Loading train:   1%|          | 3/285 [00:04<07:32,  1.60s/it]Loading train:   1%|▏         | 4/285 [00:06<07:11,  1.54s/it]Loading train:   2%|▏         | 5/285 [00:07<07:31,  1.61s/it]Loading train:   2%|▏         | 6/285 [00:09<07:01,  1.51s/it]Loading train:   2%|▏         | 7/285 [00:10<07:12,  1.56s/it]Loading train:   3%|▎         | 8/285 [00:12<07:09,  1.55s/it]Loading train:   3%|▎         | 9/285 [00:14<07:44,  1.68s/it]Loading train:   4%|▎         | 10/285 [00:15<07:08,  1.56s/it]Loading train:   4%|▍         | 11/285 [00:16<06:17,  1.38s/it]Loading train:   4%|▍         | 12/285 [00:17<06:08,  1.35s/it]Loading train:   5%|▍         | 13/285 [00:18<05:46,  1.27s/it]Loading train:   5%|▍         | 14/285 [00:20<05:45,  1.28s/it]Loading train:   5%|▌         | 15/285 [00:21<05:46,  1.28s/it]Loading train:   6%|▌         | 16/285 [00:22<05:33,  1.24s/it]Loading train:   6%|▌         | 17/285 [00:23<05:16,  1.18s/it]Loading train:   6%|▋         | 18/285 [00:25<05:28,  1.23s/it]Loading train:   7%|▋         | 19/285 [00:26<05:27,  1.23s/it]Loading train:   7%|▋         | 20/285 [00:27<05:27,  1.23s/it]Loading train:   7%|▋         | 21/285 [00:28<05:44,  1.30s/it]Loading train:   8%|▊         | 22/285 [00:30<05:27,  1.24s/it]Loading train:   8%|▊         | 23/285 [00:31<05:30,  1.26s/it]Loading train:   8%|▊         | 24/285 [00:32<05:27,  1.25s/it]Loading train:   9%|▉         | 25/285 [00:33<05:35,  1.29s/it]Loading train:   9%|▉         | 26/285 [00:35<05:42,  1.32s/it]Loading train:   9%|▉         | 27/285 [00:36<05:25,  1.26s/it]Loading train:  10%|▉         | 28/285 [00:37<05:40,  1.33s/it]Loading train:  10%|█         | 29/285 [00:39<05:35,  1.31s/it]Loading train:  11%|█         | 30/285 [00:40<06:01,  1.42s/it]Loading train:  11%|█         | 31/285 [00:42<05:44,  1.36s/it]Loading train:  11%|█         | 32/285 [00:43<05:27,  1.29s/it]Loading train:  12%|█▏        | 33/285 [00:44<05:25,  1.29s/it]Loading train:  12%|█▏        | 34/285 [00:45<05:28,  1.31s/it]Loading train:  12%|█▏        | 35/285 [00:47<05:41,  1.37s/it]Loading train:  13%|█▎        | 36/285 [00:48<05:52,  1.41s/it]Loading train:  13%|█▎        | 37/285 [00:50<05:43,  1.38s/it]Loading train:  13%|█▎        | 38/285 [00:51<05:37,  1.37s/it]Loading train:  14%|█▎        | 39/285 [00:52<05:14,  1.28s/it]Loading train:  14%|█▍        | 40/285 [00:54<05:33,  1.36s/it]Loading train:  14%|█▍        | 41/285 [00:55<05:42,  1.40s/it]Loading train:  15%|█▍        | 42/285 [00:57<05:46,  1.43s/it]Loading train:  15%|█▌        | 43/285 [00:58<05:29,  1.36s/it]Loading train:  15%|█▌        | 44/285 [00:59<05:22,  1.34s/it]Loading train:  16%|█▌        | 45/285 [01:00<05:07,  1.28s/it]Loading train:  16%|█▌        | 46/285 [01:02<05:06,  1.28s/it]Loading train:  16%|█▋        | 47/285 [01:03<04:47,  1.21s/it]Loading train:  17%|█▋        | 48/285 [01:04<05:01,  1.27s/it]Loading train:  17%|█▋        | 49/285 [01:05<04:57,  1.26s/it]Loading train:  18%|█▊        | 50/285 [01:07<04:55,  1.26s/it]Loading train:  18%|█▊        | 51/285 [01:08<04:54,  1.26s/it]Loading train:  18%|█▊        | 52/285 [01:09<04:54,  1.27s/it]Loading train:  19%|█▊        | 53/285 [01:11<05:23,  1.40s/it]Loading train:  19%|█▉        | 54/285 [01:12<05:17,  1.37s/it]Loading train:  19%|█▉        | 55/285 [01:13<05:00,  1.31s/it]Loading train:  20%|█▉        | 56/285 [01:15<05:02,  1.32s/it]Loading train:  20%|██        | 57/285 [01:16<04:50,  1.27s/it]Loading train:  20%|██        | 58/285 [01:18<05:51,  1.55s/it]Loading train:  21%|██        | 59/285 [01:20<06:06,  1.62s/it]Loading train:  21%|██        | 60/285 [01:21<05:45,  1.53s/it]Loading train:  21%|██▏       | 61/285 [01:22<05:17,  1.42s/it]Loading train:  22%|██▏       | 62/285 [01:23<04:59,  1.34s/it]Loading train:  22%|██▏       | 63/285 [01:25<05:19,  1.44s/it]Loading train:  22%|██▏       | 64/285 [01:27<05:28,  1.49s/it]Loading train:  23%|██▎       | 65/285 [01:28<05:40,  1.55s/it]Loading train:  23%|██▎       | 66/285 [01:30<05:41,  1.56s/it]Loading train:  24%|██▎       | 67/285 [01:31<05:23,  1.48s/it]Loading train:  24%|██▍       | 68/285 [01:33<05:07,  1.42s/it]Loading train:  24%|██▍       | 69/285 [01:34<05:04,  1.41s/it]Loading train:  25%|██▍       | 70/285 [01:35<04:55,  1.38s/it]Loading train:  25%|██▍       | 71/285 [01:37<04:55,  1.38s/it]Loading train:  25%|██▌       | 72/285 [01:38<04:31,  1.27s/it]Loading train:  26%|██▌       | 73/285 [01:39<04:29,  1.27s/it]Loading train:  26%|██▌       | 74/285 [01:41<05:06,  1.45s/it]Loading train:  26%|██▋       | 75/285 [01:42<04:49,  1.38s/it]Loading train:  27%|██▋       | 76/285 [01:43<04:56,  1.42s/it]Loading train:  27%|██▋       | 77/285 [01:45<05:04,  1.46s/it]Loading train:  27%|██▋       | 78/285 [01:46<04:47,  1.39s/it]Loading train:  28%|██▊       | 79/285 [01:47<04:28,  1.30s/it]Loading train:  28%|██▊       | 80/285 [01:49<04:25,  1.29s/it]Loading train:  28%|██▊       | 81/285 [01:50<04:14,  1.25s/it]Loading train:  29%|██▉       | 82/285 [01:51<04:09,  1.23s/it]Loading train:  29%|██▉       | 83/285 [01:52<03:56,  1.17s/it]Loading train:  29%|██▉       | 84/285 [01:53<03:52,  1.16s/it]Loading train:  30%|██▉       | 85/285 [01:55<04:09,  1.25s/it]Loading train:  30%|███       | 86/285 [01:56<04:16,  1.29s/it]Loading train:  31%|███       | 87/285 [01:57<04:14,  1.29s/it]Loading train:  31%|███       | 88/285 [01:58<04:11,  1.28s/it]Loading train:  31%|███       | 89/285 [02:00<04:07,  1.26s/it]Loading train:  32%|███▏      | 90/285 [02:01<04:08,  1.27s/it]Loading train:  32%|███▏      | 91/285 [02:02<03:53,  1.20s/it]Loading train:  32%|███▏      | 92/285 [02:03<03:49,  1.19s/it]Loading train:  33%|███▎      | 93/285 [02:04<03:45,  1.17s/it]Loading train:  33%|███▎      | 94/285 [02:06<03:42,  1.16s/it]Loading train:  33%|███▎      | 95/285 [02:07<03:45,  1.19s/it]Loading train:  34%|███▎      | 96/285 [02:08<03:45,  1.19s/it]Loading train:  34%|███▍      | 97/285 [02:09<03:48,  1.21s/it]Loading train:  34%|███▍      | 98/285 [02:10<03:41,  1.18s/it]Loading train:  35%|███▍      | 99/285 [02:11<03:36,  1.16s/it]Loading train:  35%|███▌      | 100/285 [02:13<03:42,  1.21s/it]Loading train:  35%|███▌      | 101/285 [02:14<03:48,  1.24s/it]Loading train:  36%|███▌      | 102/285 [02:15<03:50,  1.26s/it]Loading train:  36%|███▌      | 103/285 [02:16<03:39,  1.20s/it]Loading train:  36%|███▋      | 104/285 [02:18<03:33,  1.18s/it]Loading train:  37%|███▋      | 105/285 [02:19<03:34,  1.19s/it]Loading train:  37%|███▋      | 106/285 [02:20<03:26,  1.15s/it]Loading train:  38%|███▊      | 107/285 [02:21<03:17,  1.11s/it]Loading train:  38%|███▊      | 108/285 [02:22<03:14,  1.10s/it]Loading train:  38%|███▊      | 109/285 [02:23<03:12,  1.09s/it]Loading train:  39%|███▊      | 110/285 [02:24<03:23,  1.17s/it]Loading train:  39%|███▉      | 111/285 [02:25<03:22,  1.16s/it]Loading train:  39%|███▉      | 112/285 [02:27<03:21,  1.17s/it]Loading train:  40%|███▉      | 113/285 [02:28<03:27,  1.21s/it]Loading train:  40%|████      | 114/285 [02:29<03:32,  1.24s/it]Loading train:  40%|████      | 115/285 [02:31<03:34,  1.26s/it]Loading train:  41%|████      | 116/285 [02:32<03:35,  1.27s/it]Loading train:  41%|████      | 117/285 [02:33<03:30,  1.25s/it]Loading train:  41%|████▏     | 118/285 [02:34<03:28,  1.25s/it]Loading train:  42%|████▏     | 119/285 [02:36<03:23,  1.23s/it]Loading train:  42%|████▏     | 120/285 [02:37<03:22,  1.23s/it]Loading train:  42%|████▏     | 121/285 [02:38<03:31,  1.29s/it]Loading train:  43%|████▎     | 122/285 [02:40<03:31,  1.30s/it]Loading train:  43%|████▎     | 123/285 [02:41<03:32,  1.31s/it]Loading train:  44%|████▎     | 124/285 [02:42<03:18,  1.23s/it]Loading train:  44%|████▍     | 125/285 [02:43<03:08,  1.18s/it]Loading train:  44%|████▍     | 126/285 [02:44<02:56,  1.11s/it]Loading train:  45%|████▍     | 127/285 [02:45<02:45,  1.04s/it]Loading train:  45%|████▍     | 128/285 [02:46<02:45,  1.06s/it]Loading train:  45%|████▌     | 129/285 [02:47<02:46,  1.07s/it]Loading train:  46%|████▌     | 130/285 [02:48<02:39,  1.03s/it]Loading train:  46%|████▌     | 131/285 [02:49<02:41,  1.05s/it]Loading train:  46%|████▋     | 132/285 [02:50<02:46,  1.09s/it]Loading train:  47%|████▋     | 133/285 [02:51<02:44,  1.08s/it]Loading train:  47%|████▋     | 134/285 [02:52<02:45,  1.10s/it]Loading train:  47%|████▋     | 135/285 [02:54<02:55,  1.17s/it]Loading train:  48%|████▊     | 136/285 [02:55<02:49,  1.14s/it]Loading train:  48%|████▊     | 137/285 [02:56<02:50,  1.15s/it]Loading train:  48%|████▊     | 138/285 [02:57<02:42,  1.11s/it]Loading train:  49%|████▉     | 139/285 [02:58<02:35,  1.07s/it]Loading train:  49%|████▉     | 140/285 [02:59<02:36,  1.08s/it]Loading train:  49%|████▉     | 141/285 [03:00<02:37,  1.09s/it]Loading train:  50%|████▉     | 142/285 [03:01<02:38,  1.11s/it]Loading train:  50%|█████     | 143/285 [03:02<02:35,  1.09s/it]Loading train:  51%|█████     | 144/285 [03:04<02:37,  1.12s/it]Loading train:  51%|█████     | 145/285 [03:05<02:31,  1.08s/it]Loading train:  51%|█████     | 146/285 [03:06<02:28,  1.07s/it]Loading train:  52%|█████▏    | 147/285 [03:07<02:34,  1.12s/it]Loading train:  52%|█████▏    | 148/285 [03:08<02:34,  1.13s/it]Loading train:  52%|█████▏    | 149/285 [03:09<02:32,  1.12s/it]Loading train:  53%|█████▎    | 150/285 [03:10<02:31,  1.13s/it]Loading train:  53%|█████▎    | 151/285 [03:11<02:36,  1.17s/it]Loading train:  53%|█████▎    | 152/285 [03:13<02:36,  1.18s/it]Loading train:  54%|█████▎    | 153/285 [03:14<02:26,  1.11s/it]Loading train:  54%|█████▍    | 154/285 [03:15<02:23,  1.09s/it]Loading train:  54%|█████▍    | 155/285 [03:16<02:22,  1.10s/it]Loading train:  55%|█████▍    | 156/285 [03:17<02:27,  1.14s/it]Loading train:  55%|█████▌    | 157/285 [03:18<02:24,  1.13s/it]Loading train:  55%|█████▌    | 158/285 [03:19<02:15,  1.07s/it]Loading train:  56%|█████▌    | 159/285 [03:20<02:15,  1.07s/it]Loading train:  56%|█████▌    | 160/285 [03:21<02:22,  1.14s/it]Loading train:  56%|█████▋    | 161/285 [03:23<02:19,  1.12s/it]Loading train:  57%|█████▋    | 162/285 [03:24<02:21,  1.15s/it]Loading train:  57%|█████▋    | 163/285 [03:25<02:32,  1.25s/it]Loading train:  58%|█████▊    | 164/285 [03:27<02:39,  1.32s/it]Loading train:  58%|█████▊    | 165/285 [03:28<02:39,  1.33s/it]Loading train:  58%|█████▊    | 166/285 [03:29<02:28,  1.25s/it]Loading train:  59%|█████▊    | 167/285 [03:30<02:20,  1.19s/it]Loading train:  59%|█████▉    | 168/285 [03:31<02:15,  1.16s/it]Loading train:  59%|█████▉    | 169/285 [03:32<02:07,  1.10s/it]Loading train:  60%|█████▉    | 170/285 [03:33<02:04,  1.09s/it]Loading train:  60%|██████    | 171/285 [03:34<02:02,  1.08s/it]Loading train:  60%|██████    | 172/285 [03:35<01:57,  1.04s/it]Loading train:  61%|██████    | 173/285 [03:36<01:55,  1.03s/it]Loading train:  61%|██████    | 174/285 [03:37<01:53,  1.02s/it]Loading train:  61%|██████▏   | 175/285 [03:38<01:54,  1.04s/it]Loading train:  62%|██████▏   | 176/285 [03:39<01:52,  1.04s/it]Loading train:  62%|██████▏   | 177/285 [03:40<01:46,  1.01it/s]Loading train:  62%|██████▏   | 178/285 [03:41<01:49,  1.02s/it]Loading train:  63%|██████▎   | 179/285 [03:42<01:48,  1.02s/it]Loading train:  63%|██████▎   | 180/285 [03:44<01:57,  1.11s/it]Loading train:  64%|██████▎   | 181/285 [03:45<01:57,  1.13s/it]Loading train:  64%|██████▍   | 182/285 [03:46<01:56,  1.13s/it]Loading train:  64%|██████▍   | 183/285 [03:47<01:53,  1.11s/it]Loading train:  65%|██████▍   | 184/285 [03:48<01:49,  1.08s/it]Loading train:  65%|██████▍   | 185/285 [03:49<01:43,  1.03s/it]Loading train:  65%|██████▌   | 186/285 [03:50<01:46,  1.07s/it]Loading train:  66%|██████▌   | 187/285 [03:52<02:04,  1.27s/it]Loading train:  66%|██████▌   | 188/285 [03:53<01:59,  1.23s/it]Loading train:  66%|██████▋   | 189/285 [03:54<01:53,  1.18s/it]Loading train:  67%|██████▋   | 190/285 [03:55<01:47,  1.13s/it]Loading train:  67%|██████▋   | 191/285 [03:56<01:44,  1.11s/it]Loading train:  67%|██████▋   | 192/285 [03:57<01:45,  1.14s/it]Loading train:  68%|██████▊   | 193/285 [03:59<01:45,  1.15s/it]Loading train:  68%|██████▊   | 194/285 [04:00<01:40,  1.11s/it]Loading train:  68%|██████▊   | 195/285 [04:01<01:38,  1.09s/it]Loading train:  69%|██████▉   | 196/285 [04:02<01:39,  1.12s/it]Loading train:  69%|██████▉   | 197/285 [04:03<01:40,  1.14s/it]Loading train:  69%|██████▉   | 198/285 [04:04<01:46,  1.22s/it]Loading train:  70%|██████▉   | 199/285 [04:05<01:35,  1.11s/it]Loading train:  70%|███████   | 200/285 [04:06<01:34,  1.11s/it]Loading train:  71%|███████   | 201/285 [04:08<01:37,  1.16s/it]Loading train:  71%|███████   | 202/285 [04:09<01:35,  1.15s/it]Loading train:  71%|███████   | 203/285 [04:10<01:35,  1.16s/it]Loading train:  72%|███████▏  | 204/285 [04:11<01:31,  1.12s/it]Loading train:  72%|███████▏  | 205/285 [04:12<01:28,  1.11s/it]Loading train:  72%|███████▏  | 206/285 [04:13<01:26,  1.09s/it]Loading train:  73%|███████▎  | 207/285 [04:14<01:26,  1.11s/it]Loading train:  73%|███████▎  | 208/285 [04:15<01:26,  1.12s/it]Loading train:  73%|███████▎  | 209/285 [04:17<01:27,  1.15s/it]Loading train:  74%|███████▎  | 210/285 [04:18<01:26,  1.15s/it]Loading train:  74%|███████▍  | 211/285 [04:19<01:23,  1.13s/it]Loading train:  74%|███████▍  | 212/285 [04:20<01:23,  1.15s/it]Loading train:  75%|███████▍  | 213/285 [04:21<01:22,  1.14s/it]Loading train:  75%|███████▌  | 214/285 [04:22<01:17,  1.10s/it]Loading train:  75%|███████▌  | 215/285 [04:23<01:18,  1.12s/it]Loading train:  76%|███████▌  | 216/285 [04:24<01:16,  1.11s/it]Loading train:  76%|███████▌  | 217/285 [04:26<01:15,  1.11s/it]Loading train:  76%|███████▋  | 218/285 [04:27<01:16,  1.15s/it]Loading train:  77%|███████▋  | 219/285 [04:28<01:14,  1.13s/it]Loading train:  77%|███████▋  | 220/285 [04:29<01:13,  1.12s/it]Loading train:  78%|███████▊  | 221/285 [04:30<01:11,  1.11s/it]Loading train:  78%|███████▊  | 222/285 [04:31<01:09,  1.10s/it]Loading train:  78%|███████▊  | 223/285 [04:32<01:05,  1.06s/it]Loading train:  79%|███████▊  | 224/285 [04:33<01:01,  1.01s/it]Loading train:  79%|███████▉  | 225/285 [04:34<01:00,  1.02s/it]Loading train:  79%|███████▉  | 226/285 [04:35<01:03,  1.08s/it]Loading train:  80%|███████▉  | 227/285 [04:36<01:04,  1.11s/it]Loading train:  80%|████████  | 228/285 [04:38<01:04,  1.14s/it]Loading train:  80%|████████  | 229/285 [04:39<01:02,  1.11s/it]Loading train:  81%|████████  | 230/285 [04:40<00:59,  1.09s/it]Loading train:  81%|████████  | 231/285 [04:41<00:57,  1.07s/it]Loading train:  81%|████████▏ | 232/285 [04:42<00:57,  1.09s/it]Loading train:  82%|████████▏ | 233/285 [04:43<00:55,  1.08s/it]Loading train:  82%|████████▏ | 234/285 [04:44<00:56,  1.10s/it]Loading train:  82%|████████▏ | 235/285 [04:45<00:52,  1.05s/it]Loading train:  83%|████████▎ | 236/285 [04:46<00:52,  1.08s/it]Loading train:  83%|████████▎ | 237/285 [04:47<00:54,  1.13s/it]Loading train:  84%|████████▎ | 238/285 [04:49<00:54,  1.16s/it]Loading train:  84%|████████▍ | 239/285 [04:50<00:52,  1.14s/it]Loading train:  84%|████████▍ | 240/285 [04:51<00:49,  1.10s/it]Loading train:  85%|████████▍ | 241/285 [04:52<00:50,  1.14s/it]Loading train:  85%|████████▍ | 242/285 [04:53<00:48,  1.13s/it]Loading train:  85%|████████▌ | 243/285 [04:54<00:47,  1.12s/it]Loading train:  86%|████████▌ | 244/285 [04:56<00:51,  1.26s/it]Loading train:  86%|████████▌ | 245/285 [04:57<00:48,  1.21s/it]Loading train:  86%|████████▋ | 246/285 [04:58<00:46,  1.20s/it]Loading train:  87%|████████▋ | 247/285 [04:59<00:46,  1.21s/it]Loading train:  87%|████████▋ | 248/285 [05:00<00:43,  1.17s/it]Loading train:  87%|████████▋ | 249/285 [05:01<00:40,  1.13s/it]Loading train:  88%|████████▊ | 250/285 [05:02<00:38,  1.11s/it]Loading train:  88%|████████▊ | 251/285 [05:03<00:36,  1.07s/it]Loading train:  88%|████████▊ | 252/285 [05:05<00:35,  1.09s/it]Loading train:  89%|████████▉ | 253/285 [05:06<00:35,  1.10s/it]Loading train:  89%|████████▉ | 254/285 [05:07<00:35,  1.14s/it]Loading train:  89%|████████▉ | 255/285 [05:08<00:33,  1.11s/it]Loading train:  90%|████████▉ | 256/285 [05:09<00:31,  1.08s/it]Loading train:  90%|█████████ | 257/285 [05:10<00:30,  1.09s/it]Loading train:  91%|█████████ | 258/285 [05:11<00:29,  1.11s/it]Loading train:  91%|█████████ | 259/285 [05:12<00:28,  1.09s/it]Loading train:  91%|█████████ | 260/285 [05:13<00:27,  1.10s/it]Loading train:  92%|█████████▏| 261/285 [05:14<00:25,  1.08s/it]Loading train:  92%|█████████▏| 262/285 [05:16<00:24,  1.07s/it]Loading train:  92%|█████████▏| 263/285 [05:16<00:21,  1.00it/s]Loading train:  93%|█████████▎| 264/285 [05:18<00:22,  1.05s/it]Loading train:  93%|█████████▎| 265/285 [05:19<00:22,  1.15s/it]Loading train:  93%|█████████▎| 266/285 [05:20<00:20,  1.07s/it]Loading train:  94%|█████████▎| 267/285 [05:21<00:18,  1.05s/it]Loading train:  94%|█████████▍| 268/285 [05:22<00:18,  1.07s/it]Loading train:  94%|█████████▍| 269/285 [05:23<00:18,  1.14s/it]Loading train:  95%|█████████▍| 270/285 [05:24<00:16,  1.11s/it]Loading train:  95%|█████████▌| 271/285 [05:26<00:16,  1.16s/it]Loading train:  95%|█████████▌| 272/285 [05:27<00:15,  1.18s/it]Loading train:  96%|█████████▌| 273/285 [05:28<00:13,  1.15s/it]Loading train:  96%|█████████▌| 274/285 [05:29<00:12,  1.10s/it]Loading train:  96%|█████████▋| 275/285 [05:30<00:11,  1.15s/it]Loading train:  97%|█████████▋| 276/285 [05:31<00:10,  1.17s/it]Loading train:  97%|█████████▋| 277/285 [05:32<00:08,  1.08s/it]Loading train:  98%|█████████▊| 278/285 [05:33<00:07,  1.05s/it]Loading train:  98%|█████████▊| 279/285 [05:35<00:07,  1.23s/it]Loading train:  98%|█████████▊| 280/285 [05:36<00:05,  1.13s/it]Loading train:  99%|█████████▊| 281/285 [05:36<00:04,  1.01s/it]Loading train:  99%|█████████▉| 282/285 [05:37<00:02,  1.12it/s]Loading train:  99%|█████████▉| 283/285 [05:38<00:02,  1.01s/it]Loading train: 100%|█████████▉| 284/285 [05:40<00:01,  1.06s/it]Loading train: 100%|██████████| 285/285 [05:41<00:00,  1.12s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|          | 3/285 [00:00<00:09, 29.64it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:08, 31.83it/s]concatenating: train:   5%|▍         | 14/285 [00:00<00:07, 37.57it/s]concatenating: train:   7%|▋         | 21/285 [00:00<00:06, 42.67it/s]concatenating: train:  10%|▉         | 28/285 [00:00<00:05, 47.16it/s]concatenating: train:  19%|█▊        | 53/285 [00:00<00:03, 62.30it/s]concatenating: train:  31%|███       | 87/285 [00:00<00:02, 82.34it/s]concatenating: train:  42%|████▏     | 121/285 [00:00<00:01, 106.39it/s]concatenating: train:  55%|█████▍    | 156/285 [00:00<00:00, 134.25it/s]concatenating: train:  68%|██████▊   | 193/285 [00:01<00:00, 165.45it/s]concatenating: train:  80%|███████▉  | 227/285 [00:01<00:00, 194.76it/s]concatenating: train:  93%|█████████▎| 264/285 [00:01<00:00, 225.99it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 218.31it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.32s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.27s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.24s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 775.24it/s]2019-07-09 08:16:56.299563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-09 08:16:56.299659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-09 08:16:56.299673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-09 08:16:56.299682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-09 08:16:56.300041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12743 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.19it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.15it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.61it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.21it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.51it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.15it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.36it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.25it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.80it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.23it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  9.01it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.49it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.72it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.52it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.33it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.65it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.68it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.09it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.56it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 20)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 21)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 30)   5700        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 30)   8130        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 30)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 40, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 60)   16260       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 60)   32460       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 90)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 90)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 120)  97320       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 120)  129720      activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 120)  480         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 120)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 210)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 210)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 60)   50460       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 60)   81060       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 60)   32460       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 60)   240         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 60)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 210)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 40, 210)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 30)   25230       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 60)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 30)   16230       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 30)   8130        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 30)   120         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 30)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 90)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 80, 90)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 20)   16220       dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 80, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 80, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 80, 20)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 80, 110)  0           dropout_6[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 80, 13)   1443        concatenate_8[0][0]              
==================================================================================================
Total params: 523,583
Trainable params: 131,283
Non-trainable params: 392,300
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 31s - loss: 11752.8007 - acc: 0.6533 - mDice: 0.1817 - val_loss: 7180.1582 - val_acc: 0.9063 - val_mDice: 0.2432

Epoch 00001: val_mDice improved from -inf to 0.24319, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 22s - loss: 3797.1720 - acc: 0.8868 - mDice: 0.4717 - val_loss: 4132.5573 - val_acc: 0.9134 - val_mDice: 0.4231

Epoch 00002: val_mDice improved from 0.24319 to 0.42314, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 21s - loss: 2721.0245 - acc: 0.8977 - mDice: 0.5791 - val_loss: 2838.3546 - val_acc: 0.9346 - val_mDice: 0.5446

Epoch 00003: val_mDice improved from 0.42314 to 0.54462, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 23s - loss: 2340.5461 - acc: 0.9065 - mDice: 0.6242 - val_loss: 2870.3566 - val_acc: 0.9389 - val_mDice: 0.5411

Epoch 00004: val_mDice did not improve from 0.54462
Epoch 5/300
 - 22s - loss: 2144.2282 - acc: 0.9154 - mDice: 0.6490 - val_loss: 2602.4513 - val_acc: 0.9457 - val_mDice: 0.5706

Epoch 00005: val_mDice improved from 0.54462 to 0.57057, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 22s - loss: 2013.4600 - acc: 0.9242 - mDice: 0.6658 - val_loss: 2555.0342 - val_acc: 0.9465 - val_mDice: 0.5752

Epoch 00006: val_mDice improved from 0.57057 to 0.57520, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 22s - loss: 1927.4804 - acc: 0.9304 - mDice: 0.6769 - val_loss: 2492.8310 - val_acc: 0.9477 - val_mDice: 0.5820

Epoch 00007: val_mDice improved from 0.57520 to 0.58198, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 22s - loss: 1848.5588 - acc: 0.9357 - mDice: 0.6873 - val_loss: 2506.6256 - val_acc: 0.9429 - val_mDice: 0.5795

Epoch 00008: val_mDice did not improve from 0.58198
Epoch 9/300
 - 22s - loss: 1789.5813 - acc: 0.9389 - mDice: 0.6950 - val_loss: 2611.5135 - val_acc: 0.9446 - val_mDice: 0.5673

Epoch 00009: val_mDice did not improve from 0.58198
Epoch 10/300
 - 22s - loss: 1743.9218 - acc: 0.9401 - mDice: 0.7012 - val_loss: 2803.1002 - val_acc: 0.9463 - val_mDice: 0.5482

Epoch 00010: val_mDice did not improve from 0.58198
Epoch 11/300
 - 22s - loss: 1692.8654 - acc: 0.9411 - mDice: 0.7083 - val_loss: 2612.3858 - val_acc: 0.9389 - val_mDice: 0.5662

Epoch 00011: val_mDice did not improve from 0.58198
Epoch 12/300
 - 22s - loss: 1657.2522 - acc: 0.9419 - mDice: 0.7133 - val_loss: 2575.2460 - val_acc: 0.9416 - val_mDice: 0.5704

Epoch 00012: val_mDice did not improve from 0.58198
Epoch 13/300
 - 22s - loss: 1610.5910 - acc: 0.9428 - mDice: 0.7199 - val_loss: 2609.5283 - val_acc: 0.9404 - val_mDice: 0.5663

Epoch 00013: val_mDice did not improve from 0.58198
Epoch 14/300
 - 22s - loss: 1599.3049 - acc: 0.9430 - mDice: 0.7216 - val_loss: 2777.3543 - val_acc: 0.9325 - val_mDice: 0.5478

Epoch 00014: val_mDice did not improve from 0.58198
Epoch 15/300
 - 21s - loss: 1558.6805 - acc: 0.9438 - mDice: 0.7274 - val_loss: 2605.8443 - val_acc: 0.9399 - val_mDice: 0.5659

Epoch 00015: val_mDice did not improve from 0.58198
Epoch 16/300
 - 22s - loss: 1529.9351 - acc: 0.9444 - mDice: 0.7317 - val_loss: 2743.1262 - val_acc: 0.9385 - val_mDice: 0.5518

Epoch 00016: val_mDice did not improve from 0.58198
Epoch 17/300
 - 22s - loss: 1502.7707 - acc: 0.9451 - mDice: 0.7356 - val_loss: 2603.9301 - val_acc: 0.9408 - val_mDice: 0.5668

Epoch 00017: val_mDice did not improve from 0.58198
Epoch 18/300
 - 21s - loss: 1478.7138 - acc: 0.9454 - mDice: 0.7391 - val_loss: 2738.8781 - val_acc: 0.9453 - val_mDice: 0.5521

Epoch 00018: val_mDice did not improve from 0.58198
Epoch 19/300
 - 21s - loss: 1456.9221 - acc: 0.9459 - mDice: 0.7424 - val_loss: 2697.9922 - val_acc: 0.9450 - val_mDice: 0.5577

Epoch 00019: val_mDice did not improve from 0.58198
Epoch 20/300
 - 22s - loss: 1448.1604 - acc: 0.9461 - mDice: 0.7436 - val_loss: 2771.6138 - val_acc: 0.9448 - val_mDice: 0.5495

Epoch 00020: val_mDice did not improve from 0.58198
Epoch 21/300
 - 22s - loss: 1422.3589 - acc: 0.9466 - mDice: 0.7476 - val_loss: 2690.1787 - val_acc: 0.9403 - val_mDice: 0.5599

Epoch 00021: val_mDice did not improve from 0.58198
Epoch 22/300
 - 22s - loss: 1396.8610 - acc: 0.9469 - mDice: 0.7514 - val_loss: 2673.3155 - val_acc: 0.9411 - val_mDice: 0.5601

Epoch 00022: val_mDice did not improve from 0.58198
Epoch 23/300
 - 22s - loss: 1388.7144 - acc: 0.9471 - mDice: 0.7526 - val_loss: 2686.7727 - val_acc: 0.9434 - val_mDice: 0.5586

Epoch 00023: val_mDice did not improve from 0.58198
Epoch 24/300
 - 22s - loss: 1372.5464 - acc: 0.9474 - mDice: 0.7551 - val_loss: 2658.4744 - val_acc: 0.9425 - val_mDice: 0.5618

Epoch 00024: val_mDice did not improve from 0.58198
Epoch 25/300
 - 22s - loss: 1362.4656 - acc: 0.9478 - mDice: 0.7566 - val_loss: 2663.7403 - val_acc: 0.9457 - val_mDice: 0.5605

Epoch 00025: val_mDice did not improve from 0.58198
Epoch 26/300
 - 22s - loss: 1342.8259 - acc: 0.9479 - mDice: 0.7596 - val_loss: 2713.0715 - val_acc: 0.9443 - val_mDice: 0.5575

Epoch 00026: val_mDice did not improve from 0.58198
Epoch 27/300
 - 22s - loss: 1329.4424 - acc: 0.9482 - mDice: 0.7617 - val_loss: 2690.3940 - val_acc: 0.9450 - val_mDice: 0.5587

Epoch 00027: val_mDice did not improve from 0.58198
Epoch 28/300
 - 21s - loss: 1318.8000 - acc: 0.9483 - mDice: 0.7633 - val_loss: 2796.5784 - val_acc: 0.9439 - val_mDice: 0.5474

Epoch 00028: val_mDice did not improve from 0.58198
Epoch 29/300
 - 21s - loss: 1301.1357 - acc: 0.9488 - mDice: 0.7660 - val_loss: 2818.7651 - val_acc: 0.9426 - val_mDice: 0.5452

Epoch 00029: val_mDice did not improve from 0.58198
Epoch 30/300
 - 22s - loss: 1299.4178 - acc: 0.9487 - mDice: 0.7663 - val_loss: 2843.1209 - val_acc: 0.9448 - val_mDice: 0.5417

Epoch 00030: val_mDice did not improve from 0.58198
Epoch 31/300
 - 22s - loss: 1285.1864 - acc: 0.9490 - mDice: 0.7686 - val_loss: 2646.3030 - val_acc: 0.9439 - val_mDice: 0.5625

Epoch 00031: val_mDice did not improve from 0.58198
Epoch 32/300
 - 21s - loss: 1267.7073 - acc: 0.9493 - mDice: 0.7712 - val_loss: 2653.8572 - val_acc: 0.9457 - val_mDice: 0.5629

Epoch 00032: val_mDice did not improve from 0.58198
Epoch 33/300
 - 21s - loss: 1268.9394 - acc: 0.9495 - mDice: 0.7710 - val_loss: 2864.9219 - val_acc: 0.9441 - val_mDice: 0.5399

Epoch 00033: val_mDice did not improve from 0.58198
Epoch 34/300
 - 21s - loss: 1256.0186 - acc: 0.9496 - mDice: 0.7730 - val_loss: 2812.4779 - val_acc: 0.9431 - val_mDice: 0.5455

Epoch 00034: val_mDice did not improve from 0.58198
Epoch 35/300
 - 22s - loss: 1249.2982 - acc: 0.9497 - mDice: 0.7741 - val_loss: 2841.5203 - val_acc: 0.9458 - val_mDice: 0.5436

Epoch 00035: val_mDice did not improve from 0.58198
Epoch 36/300
 - 22s - loss: 1242.6396 - acc: 0.9499 - mDice: 0.7752 - val_loss: 2748.1980 - val_acc: 0.9446 - val_mDice: 0.5536

Epoch 00036: val_mDice did not improve from 0.58198
Epoch 37/300
 - 21s - loss: 1229.3445 - acc: 0.9501 - mDice: 0.7773 - val_loss: 2686.4871 - val_acc: 0.9442 - val_mDice: 0.5590

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.59s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.27s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  2.01s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:26,  1.99s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:52,  1.88s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:46,  1.87s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<08:14,  1.76s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:33,  1.83s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<08:13,  1.77s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:30,  1.83s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:23,  1.82s/it]predicting train subjects:   3%|▎         | 9/285 [00:16<08:36,  1.87s/it]predicting train subjects:   4%|▎         | 10/285 [00:18<08:44,  1.91s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:19,  1.82s/it]predicting train subjects:   4%|▍         | 12/285 [00:22<08:44,  1.92s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:23,  1.85s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<08:29,  1.88s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:43,  1.94s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<08:50,  1.97s/it]predicting train subjects:   6%|▌         | 17/285 [00:31<08:27,  1.89s/it]predicting train subjects:   6%|▋         | 18/285 [00:33<08:30,  1.91s/it]predicting train subjects:   7%|▋         | 19/285 [00:35<08:10,  1.84s/it]predicting train subjects:   7%|▋         | 20/285 [00:37<08:20,  1.89s/it]predicting train subjects:   7%|▋         | 21/285 [00:39<08:33,  1.94s/it]predicting train subjects:   8%|▊         | 22/285 [00:41<08:12,  1.87s/it]predicting train subjects:   8%|▊         | 23/285 [00:42<08:14,  1.89s/it]predicting train subjects:   8%|▊         | 24/285 [00:44<07:53,  1.82s/it]predicting train subjects:   9%|▉         | 25/285 [00:46<08:09,  1.88s/it]predicting train subjects:   9%|▉         | 26/285 [00:48<08:20,  1.93s/it]predicting train subjects:   9%|▉         | 27/285 [00:50<07:58,  1.86s/it]predicting train subjects:  10%|▉         | 28/285 [00:52<08:03,  1.88s/it]predicting train subjects:  10%|█         | 29/285 [00:54<08:04,  1.89s/it]predicting train subjects:  11%|█         | 30/285 [00:56<08:18,  1.95s/it]predicting train subjects:  11%|█         | 31/285 [00:58<08:19,  1.97s/it]predicting train subjects:  11%|█         | 32/285 [00:59<07:55,  1.88s/it]predicting train subjects:  12%|█▏        | 33/285 [01:01<07:59,  1.90s/it]predicting train subjects:  12%|█▏        | 34/285 [01:03<07:58,  1.91s/it]predicting train subjects:  12%|█▏        | 35/285 [01:05<08:06,  1.95s/it]predicting train subjects:  13%|█▎        | 36/285 [01:07<07:44,  1.86s/it]predicting train subjects:  13%|█▎        | 37/285 [01:09<07:48,  1.89s/it]predicting train subjects:  13%|█▎        | 38/285 [01:11<08:00,  1.95s/it]predicting train subjects:  14%|█▎        | 39/285 [01:13<07:42,  1.88s/it]predicting train subjects:  14%|█▍        | 40/285 [01:15<07:43,  1.89s/it]predicting train subjects:  14%|█▍        | 41/285 [01:16<07:28,  1.84s/it]predicting train subjects:  15%|█▍        | 42/285 [01:18<07:10,  1.77s/it]predicting train subjects:  15%|█▌        | 43/285 [01:20<07:16,  1.80s/it]predicting train subjects:  15%|█▌        | 44/285 [01:22<07:34,  1.89s/it]predicting train subjects:  16%|█▌        | 45/285 [01:24<07:13,  1.81s/it]predicting train subjects:  16%|█▌        | 46/285 [01:26<07:31,  1.89s/it]predicting train subjects:  16%|█▋        | 47/285 [01:27<07:12,  1.82s/it]predicting train subjects:  17%|█▋        | 48/285 [01:29<07:10,  1.81s/it]predicting train subjects:  17%|█▋        | 49/285 [01:31<07:17,  1.85s/it]predicting train subjects:  18%|█▊        | 50/285 [01:33<07:08,  1.82s/it]predicting train subjects:  18%|█▊        | 51/285 [01:35<07:21,  1.89s/it]predicting train subjects:  18%|█▊        | 52/285 [01:37<07:04,  1.82s/it]predicting train subjects:  19%|█▊        | 53/285 [01:38<07:07,  1.84s/it]predicting train subjects:  19%|█▉        | 54/285 [01:40<07:10,  1.87s/it]predicting train subjects:  19%|█▉        | 55/285 [01:42<06:49,  1.78s/it]predicting train subjects:  20%|█▉        | 56/285 [01:44<06:56,  1.82s/it]predicting train subjects:  20%|██        | 57/285 [01:45<06:33,  1.73s/it]predicting train subjects:  20%|██        | 58/285 [01:47<06:40,  1.76s/it]predicting train subjects:  21%|██        | 59/285 [01:49<06:52,  1.82s/it]predicting train subjects:  21%|██        | 60/285 [01:51<06:58,  1.86s/it]predicting train subjects:  21%|██▏       | 61/285 [01:53<06:38,  1.78s/it]predicting train subjects:  22%|██▏       | 62/285 [01:55<06:38,  1.79s/it]predicting train subjects:  22%|██▏       | 63/285 [01:56<06:43,  1.82s/it]predicting train subjects:  22%|██▏       | 64/285 [01:58<06:31,  1.77s/it]predicting train subjects:  23%|██▎       | 65/285 [02:00<06:32,  1.78s/it]predicting train subjects:  23%|██▎       | 66/285 [02:02<06:32,  1.79s/it]predicting train subjects:  24%|██▎       | 67/285 [02:04<06:34,  1.81s/it]predicting train subjects:  24%|██▍       | 68/285 [02:05<06:25,  1.78s/it]predicting train subjects:  24%|██▍       | 69/285 [02:07<06:26,  1.79s/it]predicting train subjects:  25%|██▍       | 70/285 [02:09<06:25,  1.79s/it]predicting train subjects:  25%|██▍       | 71/285 [02:11<06:33,  1.84s/it]predicting train subjects:  25%|██▌       | 72/285 [02:12<06:17,  1.77s/it]predicting train subjects:  26%|██▌       | 73/285 [02:14<06:21,  1.80s/it]predicting train subjects:  26%|██▌       | 74/285 [02:16<06:20,  1.80s/it]predicting train subjects:  26%|██▋       | 75/285 [02:18<06:21,  1.82s/it]predicting train subjects:  27%|██▋       | 76/285 [02:20<06:27,  1.85s/it]predicting train subjects:  27%|██▋       | 77/285 [02:22<06:17,  1.82s/it]predicting train subjects:  27%|██▋       | 78/285 [02:23<06:01,  1.75s/it]predicting train subjects:  28%|██▊       | 79/285 [02:25<06:01,  1.76s/it]predicting train subjects:  28%|██▊       | 80/285 [02:27<05:59,  1.76s/it]predicting train subjects:  28%|██▊       | 81/285 [02:28<05:51,  1.72s/it]predicting train subjects:  29%|██▉       | 82/285 [02:30<05:48,  1.72s/it]predicting train subjects:  29%|██▉       | 83/285 [02:32<05:44,  1.70s/it]predicting train subjects:  29%|██▉       | 84/285 [02:33<05:41,  1.70s/it]predicting train subjects:  30%|██▉       | 85/285 [02:35<05:40,  1.70s/it]predicting train subjects:  30%|███       | 86/285 [02:37<05:47,  1.74s/it]predicting train subjects:  31%|███       | 87/285 [02:39<05:51,  1.78s/it]predicting train subjects:  31%|███       | 88/285 [02:40<05:39,  1.72s/it]predicting train subjects:  31%|███       | 89/285 [02:42<05:40,  1.74s/it]predicting train subjects:  32%|███▏      | 90/285 [02:44<05:45,  1.77s/it]predicting train subjects:  32%|███▏      | 91/285 [02:46<05:31,  1.71s/it]predicting train subjects:  32%|███▏      | 92/285 [02:47<05:36,  1.75s/it]predicting train subjects:  33%|███▎      | 93/285 [02:49<05:29,  1.71s/it]predicting train subjects:  33%|███▎      | 94/285 [02:51<05:30,  1.73s/it]predicting train subjects:  33%|███▎      | 95/285 [02:53<05:30,  1.74s/it]predicting train subjects:  34%|███▎      | 96/285 [02:54<05:28,  1.74s/it]predicting train subjects:  34%|███▍      | 97/285 [02:56<05:32,  1.77s/it]predicting train subjects:  34%|███▍      | 98/285 [02:58<05:32,  1.78s/it]predicting train subjects:  35%|███▍      | 99/285 [03:00<05:24,  1.75s/it]predicting train subjects:  35%|███▌      | 100/285 [03:02<05:26,  1.77s/it]predicting train subjects:  35%|███▌      | 101/285 [03:03<05:21,  1.75s/it]predicting train subjects:  36%|███▌      | 102/285 [03:05<05:24,  1.77s/it]predicting train subjects:  36%|███▌      | 103/285 [03:07<05:14,  1.73s/it]predicting train subjects:  36%|███▋      | 104/285 [03:08<05:15,  1.75s/it]predicting train subjects:  37%|███▋      | 105/285 [03:10<05:19,  1.78s/it]predicting train subjects:  37%|███▋      | 106/285 [03:12<05:08,  1.73s/it]predicting train subjects:  38%|███▊      | 107/285 [03:14<05:08,  1.73s/it]predicting train subjects:  38%|███▊      | 108/285 [03:15<04:59,  1.69s/it]predicting train subjects:  38%|███▊      | 109/285 [03:17<05:00,  1.71s/it]predicting train subjects:  39%|███▊      | 110/285 [03:19<05:03,  1.74s/it]predicting train subjects:  39%|███▉      | 111/285 [03:20<04:56,  1.70s/it]predicting train subjects:  39%|███▉      | 112/285 [03:22<04:55,  1.71s/it]predicting train subjects:  40%|███▉      | 113/285 [03:24<04:58,  1.74s/it]predicting train subjects:  40%|████      | 114/285 [03:26<05:00,  1.76s/it]predicting train subjects:  40%|████      | 115/285 [03:28<05:05,  1.80s/it]predicting train subjects:  41%|████      | 116/285 [03:29<05:05,  1.81s/it]predicting train subjects:  41%|████      | 117/285 [03:31<04:58,  1.77s/it]predicting train subjects:  41%|████▏     | 118/285 [03:33<04:53,  1.75s/it]predicting train subjects:  42%|████▏     | 119/285 [03:35<04:55,  1.78s/it]predicting train subjects:  42%|████▏     | 120/285 [03:36<04:48,  1.75s/it]predicting train subjects:  42%|████▏     | 121/285 [03:38<04:41,  1.72s/it]predicting train subjects:  43%|████▎     | 122/285 [03:39<04:25,  1.63s/it]predicting train subjects:  43%|████▎     | 123/285 [03:41<04:12,  1.56s/it]predicting train subjects:  44%|████▎     | 124/285 [03:42<04:11,  1.56s/it]predicting train subjects:  44%|████▍     | 125/285 [03:44<04:11,  1.57s/it]predicting train subjects:  44%|████▍     | 126/285 [03:45<04:02,  1.53s/it]predicting train subjects:  45%|████▍     | 127/285 [03:47<03:57,  1.50s/it]predicting train subjects:  45%|████▍     | 128/285 [03:49<04:01,  1.54s/it]predicting train subjects:  45%|████▌     | 129/285 [03:50<03:55,  1.51s/it]predicting train subjects:  46%|████▌     | 130/285 [03:51<03:50,  1.49s/it]predicting train subjects:  46%|████▌     | 131/285 [03:53<03:47,  1.48s/it]predicting train subjects:  46%|████▋     | 132/285 [03:55<03:57,  1.55s/it]predicting train subjects:  47%|████▋     | 133/285 [03:56<03:52,  1.53s/it]predicting train subjects:  47%|████▋     | 134/285 [03:58<03:51,  1.53s/it]predicting train subjects:  47%|████▋     | 135/285 [03:59<03:44,  1.50s/it]predicting train subjects:  48%|████▊     | 136/285 [04:00<03:40,  1.48s/it]predicting train subjects:  48%|████▊     | 137/285 [04:02<03:47,  1.54s/it]predicting train subjects:  48%|████▊     | 138/285 [04:04<03:40,  1.50s/it]predicting train subjects:  49%|████▉     | 139/285 [04:05<03:43,  1.53s/it]predicting train subjects:  49%|████▉     | 140/285 [04:07<03:47,  1.57s/it]predicting train subjects:  49%|████▉     | 141/285 [04:08<03:38,  1.52s/it]predicting train subjects:  50%|████▉     | 142/285 [04:10<03:35,  1.51s/it]predicting train subjects:  50%|█████     | 143/285 [04:11<03:30,  1.48s/it]predicting train subjects:  51%|█████     | 144/285 [04:13<03:37,  1.54s/it]predicting train subjects:  51%|█████     | 145/285 [04:14<03:32,  1.51s/it]predicting train subjects:  51%|█████     | 146/285 [04:16<03:34,  1.54s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:17<03:26,  1.50s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:19<03:26,  1.51s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:20<03:20,  1.48s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:22<03:16,  1.46s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:23<03:22,  1.51s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:25<03:22,  1.52s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:26<03:17,  1.49s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:28<03:21,  1.53s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:29<03:16,  1.51s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:31<03:17,  1.53s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:32<03:11,  1.49s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:34<03:08,  1.49s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:35<03:05,  1.48s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:37<03:00,  1.45s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:38<03:07,  1.51s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:40<03:02,  1.48s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:41<03:07,  1.53s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:43<03:04,  1.52s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:44<03:01,  1.51s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:46<03:03,  1.54s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:47<03:04,  1.56s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:49<02:56,  1.51s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:50<02:53,  1.50s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:52<02:49,  1.47s/it]predicting train subjects:  60%|██████    | 171/285 [04:53<02:48,  1.48s/it]predicting train subjects:  60%|██████    | 172/285 [04:55<02:46,  1.47s/it]predicting train subjects:  61%|██████    | 173/285 [04:56<02:41,  1.45s/it]predicting train subjects:  61%|██████    | 174/285 [04:58<02:39,  1.44s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:59<02:46,  1.51s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:01<02:47,  1.54s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:02<02:41,  1.50s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:04<02:36,  1.46s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:05<02:32,  1.44s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:07<02:43,  1.56s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:08<02:45,  1.59s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:10<02:44,  1.60s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:11<02:37,  1.54s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:13<02:30,  1.49s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:14<02:26,  1.46s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:16<02:38,  1.60s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:18<02:47,  1.71s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:20<02:52,  1.78s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:21<02:39,  1.66s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:23<02:34,  1.63s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:25<02:38,  1.68s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:27<02:41,  1.73s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:28<02:31,  1.65s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:30<02:25,  1.60s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:31<02:20,  1.56s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:33<02:28,  1.67s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:35<02:34,  1.76s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:37<02:35,  1.78s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:38<02:23,  1.67s/it]predicting train subjects:  70%|███████   | 200/285 [05:40<02:16,  1.61s/it]predicting train subjects:  71%|███████   | 201/285 [05:41<02:19,  1.66s/it]predicting train subjects:  71%|███████   | 202/285 [05:43<02:19,  1.68s/it]predicting train subjects:  71%|███████   | 203/285 [05:45<02:18,  1.68s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:46<02:12,  1.64s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:48<02:06,  1.58s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:49<02:01,  1.54s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:51<02:09,  1.66s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:53<02:13,  1.73s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:55<02:15,  1.79s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:57<02:06,  1.68s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:58<01:59,  1.61s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:00<01:59,  1.63s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:01<01:58,  1.65s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:03<01:51,  1.58s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:05<01:57,  1.67s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:06<01:50,  1.59s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:08<01:56,  1.71s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:10<01:58,  1.77s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:12<01:58,  1.80s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:13<01:50,  1.70s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:15<01:43,  1.62s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:16<01:44,  1.66s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:18<01:36,  1.56s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:19<01:35,  1.56s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:21<01:31,  1.53s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:23<01:38,  1.66s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:25<01:40,  1.73s/it]predicting train subjects:  80%|████████  | 228/285 [06:27<01:40,  1.77s/it]predicting train subjects:  80%|████████  | 229/285 [06:28<01:37,  1.74s/it]predicting train subjects:  81%|████████  | 230/285 [06:30<01:29,  1.63s/it]predicting train subjects:  81%|████████  | 231/285 [06:31<01:24,  1.57s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:33<01:24,  1.60s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:34<01:20,  1.55s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:36<01:24,  1.66s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:37<01:19,  1.58s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:39<01:21,  1.67s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:41<01:23,  1.73s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:43<01:23,  1.77s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:45<01:20,  1.74s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:46<01:13,  1.64s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:48<01:10,  1.60s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:49<01:07,  1.56s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:50<01:03,  1.51s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:52<01:06,  1.63s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:54<01:02,  1.55s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:56<01:03,  1.63s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:57<01:05,  1.71s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:59<01:02,  1.69s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:01<00:58,  1.61s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:02<00:55,  1.57s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:04<00:52,  1.54s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:05<00:49,  1.49s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:07<00:51,  1.60s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:09<00:51,  1.67s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:10<00:50,  1.67s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:12<00:45,  1.58s/it]predicting train subjects:  90%|█████████ | 257/285 [07:13<00:43,  1.56s/it]predicting train subjects:  91%|█████████ | 258/285 [07:15<00:47,  1.75s/it]predicting train subjects:  91%|█████████ | 259/285 [07:17<00:44,  1.73s/it]predicting train subjects:  91%|█████████ | 260/285 [07:18<00:40,  1.64s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:20<00:37,  1.58s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:21<00:35,  1.52s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:23<00:32,  1.48s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:25<00:34,  1.62s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:26<00:33,  1.70s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:28<00:30,  1.63s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:29<00:28,  1.60s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:31<00:28,  1.69s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:33<00:27,  1.72s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:35<00:24,  1.65s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:36<00:22,  1.59s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:38<00:21,  1.62s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:39<00:18,  1.56s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:41<00:16,  1.54s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:43<00:16,  1.66s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:44<00:15,  1.71s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:46<00:13,  1.63s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:47<00:11,  1.59s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:49<00:09,  1.62s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:50<00:07,  1.56s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:52<00:06,  1.53s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:53<00:04,  1.48s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:55<00:03,  1.59s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:57<00:01,  1.68s/it]predicting train subjects: 100%|██████████| 285/285 [07:59<00:00,  1.74s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:45,  1.85s/it]Loading train:   1%|          | 2/285 [00:03<08:20,  1.77s/it]Loading train:   1%|          | 3/285 [00:05<08:27,  1.80s/it]Loading train:   1%|▏         | 4/285 [00:07<08:38,  1.84s/it]Loading train:   2%|▏         | 5/285 [00:09<08:37,  1.85s/it]Loading train:   2%|▏         | 6/285 [00:10<08:03,  1.73s/it]Loading train:   2%|▏         | 7/285 [00:12<08:20,  1.80s/it]Loading train:   3%|▎         | 8/285 [00:14<08:00,  1.73s/it]Loading train:   3%|▎         | 9/285 [00:16<08:17,  1.80s/it]Loading train:   4%|▎         | 10/285 [00:17<08:01,  1.75s/it]Loading train:   4%|▍         | 11/285 [00:19<07:29,  1.64s/it]Loading train:   4%|▍         | 12/285 [00:20<07:20,  1.61s/it]Loading train:   5%|▍         | 13/285 [00:22<07:17,  1.61s/it]Loading train:   5%|▍         | 14/285 [00:23<07:19,  1.62s/it]Loading train:   5%|▌         | 15/285 [00:25<07:16,  1.62s/it]Loading train:   6%|▌         | 16/285 [00:27<07:16,  1.62s/it]Loading train:   6%|▌         | 17/285 [00:28<06:57,  1.56s/it]Loading train:   6%|▋         | 18/285 [00:29<06:44,  1.52s/it]Loading train:   7%|▋         | 19/285 [00:31<06:25,  1.45s/it]Loading train:   7%|▋         | 20/285 [00:32<06:20,  1.44s/it]Loading train:   7%|▋         | 21/285 [00:34<06:28,  1.47s/it]Loading train:   8%|▊         | 22/285 [00:35<06:15,  1.43s/it]Loading train:   8%|▊         | 23/285 [00:37<06:41,  1.53s/it]Loading train:   8%|▊         | 24/285 [00:38<06:24,  1.47s/it]Loading train:   9%|▉         | 25/285 [00:40<06:23,  1.47s/it]Loading train:   9%|▉         | 26/285 [00:41<06:18,  1.46s/it]Loading train:   9%|▉         | 27/285 [00:42<05:52,  1.37s/it]Loading train:  10%|▉         | 28/285 [00:44<06:11,  1.44s/it]Loading train:  10%|█         | 29/285 [00:46<06:30,  1.52s/it]Loading train:  11%|█         | 30/285 [00:47<06:55,  1.63s/it]Loading train:  11%|█         | 31/285 [00:49<06:54,  1.63s/it]Loading train:  11%|█         | 32/285 [00:50<06:30,  1.54s/it]Loading train:  12%|█▏        | 33/285 [00:52<06:04,  1.45s/it]Loading train:  12%|█▏        | 34/285 [00:53<05:48,  1.39s/it]Loading train:  12%|█▏        | 35/285 [00:54<05:41,  1.37s/it]Loading train:  13%|█▎        | 36/285 [00:55<05:21,  1.29s/it]Loading train:  13%|█▎        | 37/285 [00:57<05:25,  1.31s/it]Loading train:  13%|█▎        | 38/285 [00:58<05:34,  1.35s/it]Loading train:  14%|█▎        | 39/285 [00:59<05:23,  1.31s/it]Loading train:  14%|█▍        | 40/285 [01:01<05:21,  1.31s/it]Loading train:  14%|█▍        | 41/285 [01:02<05:13,  1.28s/it]Loading train:  15%|█▍        | 42/285 [01:03<05:18,  1.31s/it]Loading train:  15%|█▌        | 43/285 [01:04<05:09,  1.28s/it]Loading train:  15%|█▌        | 44/285 [01:06<05:26,  1.36s/it]Loading train:  16%|█▌        | 45/285 [01:07<05:09,  1.29s/it]Loading train:  16%|█▌        | 46/285 [01:09<05:23,  1.35s/it]Loading train:  16%|█▋        | 47/285 [01:10<05:02,  1.27s/it]Loading train:  17%|█▋        | 48/285 [01:11<04:59,  1.26s/it]Loading train:  17%|█▋        | 49/285 [01:12<05:06,  1.30s/it]Loading train:  18%|█▊        | 50/285 [01:14<05:06,  1.31s/it]Loading train:  18%|█▊        | 51/285 [01:15<05:21,  1.37s/it]Loading train:  18%|█▊        | 52/285 [01:16<05:11,  1.34s/it]Loading train:  19%|█▊        | 53/285 [01:18<05:12,  1.34s/it]Loading train:  19%|█▉        | 54/285 [01:19<05:23,  1.40s/it]Loading train:  19%|█▉        | 55/285 [01:21<05:18,  1.38s/it]Loading train:  20%|█▉        | 56/285 [01:22<05:22,  1.41s/it]Loading train:  20%|██        | 57/285 [01:23<05:08,  1.35s/it]Loading train:  20%|██        | 58/285 [01:25<05:09,  1.36s/it]Loading train:  21%|██        | 59/285 [01:27<05:40,  1.51s/it]Loading train:  21%|██        | 60/285 [01:28<05:26,  1.45s/it]Loading train:  21%|██▏       | 61/285 [01:29<05:09,  1.38s/it]Loading train:  22%|██▏       | 62/285 [01:31<05:10,  1.39s/it]Loading train:  22%|██▏       | 63/285 [01:32<05:03,  1.37s/it]Loading train:  22%|██▏       | 64/285 [01:33<05:15,  1.43s/it]Loading train:  23%|██▎       | 65/285 [01:35<05:40,  1.55s/it]Loading train:  23%|██▎       | 66/285 [01:37<06:03,  1.66s/it]Loading train:  24%|██▎       | 67/285 [01:38<05:40,  1.56s/it]Loading train:  24%|██▍       | 68/285 [01:40<05:20,  1.48s/it]Loading train:  24%|██▍       | 69/285 [01:41<05:04,  1.41s/it]Loading train:  25%|██▍       | 70/285 [01:42<05:00,  1.40s/it]Loading train:  25%|██▍       | 71/285 [01:44<04:58,  1.39s/it]Loading train:  25%|██▌       | 72/285 [01:45<04:49,  1.36s/it]Loading train:  26%|██▌       | 73/285 [01:46<04:49,  1.37s/it]Loading train:  26%|██▌       | 74/285 [01:48<04:49,  1.37s/it]Loading train:  26%|██▋       | 75/285 [01:49<04:43,  1.35s/it]Loading train:  27%|██▋       | 76/285 [01:51<04:59,  1.43s/it]Loading train:  27%|██▋       | 77/285 [01:52<04:55,  1.42s/it]Loading train:  27%|██▋       | 78/285 [01:53<04:38,  1.35s/it]Loading train:  28%|██▊       | 79/285 [01:55<04:38,  1.35s/it]Loading train:  28%|██▊       | 80/285 [01:56<04:50,  1.42s/it]Loading train:  28%|██▊       | 81/285 [01:57<04:37,  1.36s/it]Loading train:  29%|██▉       | 82/285 [01:59<04:46,  1.41s/it]Loading train:  29%|██▉       | 83/285 [02:01<05:11,  1.54s/it]Loading train:  29%|██▉       | 84/285 [02:02<05:16,  1.58s/it]Loading train:  30%|██▉       | 85/285 [02:04<05:05,  1.53s/it]Loading train:  30%|███       | 86/285 [02:05<04:51,  1.47s/it]Loading train:  31%|███       | 87/285 [02:07<04:45,  1.44s/it]Loading train:  31%|███       | 88/285 [02:08<04:34,  1.39s/it]Loading train:  31%|███       | 89/285 [02:09<04:31,  1.38s/it]Loading train:  32%|███▏      | 90/285 [02:11<04:41,  1.44s/it]Loading train:  32%|███▏      | 91/285 [02:12<04:28,  1.39s/it]Loading train:  32%|███▏      | 92/285 [02:13<04:24,  1.37s/it]Loading train:  33%|███▎      | 93/285 [02:15<04:27,  1.39s/it]Loading train:  33%|███▎      | 94/285 [02:16<04:29,  1.41s/it]Loading train:  33%|███▎      | 95/285 [02:18<04:30,  1.42s/it]Loading train:  34%|███▎      | 96/285 [02:19<04:26,  1.41s/it]Loading train:  34%|███▍      | 97/285 [02:21<04:26,  1.42s/it]Loading train:  34%|███▍      | 98/285 [02:22<04:22,  1.40s/it]Loading train:  35%|███▍      | 99/285 [02:23<04:17,  1.38s/it]Loading train:  35%|███▌      | 100/285 [02:25<04:14,  1.37s/it]Loading train:  35%|███▌      | 101/285 [02:26<04:06,  1.34s/it]Loading train:  36%|███▌      | 102/285 [02:27<04:09,  1.36s/it]Loading train:  36%|███▌      | 103/285 [02:29<04:06,  1.36s/it]Loading train:  36%|███▋      | 104/285 [02:30<04:06,  1.36s/it]Loading train:  37%|███▋      | 105/285 [02:32<04:37,  1.54s/it]Loading train:  37%|███▋      | 106/285 [02:33<04:33,  1.53s/it]Loading train:  38%|███▊      | 107/285 [02:35<04:27,  1.50s/it]Loading train:  38%|███▊      | 108/285 [02:36<04:07,  1.40s/it]Loading train:  38%|███▊      | 109/285 [02:37<04:05,  1.39s/it]Loading train:  39%|███▊      | 110/285 [02:39<04:06,  1.41s/it]Loading train:  39%|███▉      | 111/285 [02:40<04:01,  1.39s/it]Loading train:  39%|███▉      | 112/285 [02:42<04:03,  1.41s/it]Loading train:  40%|███▉      | 113/285 [02:43<04:02,  1.41s/it]Loading train:  40%|████      | 114/285 [02:44<03:43,  1.30s/it]Loading train:  40%|████      | 115/285 [02:45<03:30,  1.24s/it]Loading train:  41%|████      | 116/285 [02:47<03:32,  1.25s/it]Loading train:  41%|████      | 117/285 [02:48<03:30,  1.25s/it]Loading train:  41%|████▏     | 118/285 [02:49<03:39,  1.31s/it]Loading train:  42%|████▏     | 119/285 [02:50<03:32,  1.28s/it]Loading train:  42%|████▏     | 120/285 [02:52<03:21,  1.22s/it]Loading train:  42%|████▏     | 121/285 [02:53<03:31,  1.29s/it]Loading train:  43%|████▎     | 122/285 [02:54<03:32,  1.30s/it]Loading train:  43%|████▎     | 123/285 [02:56<03:32,  1.31s/it]Loading train:  44%|████▎     | 124/285 [02:57<03:13,  1.20s/it]Loading train:  44%|████▍     | 125/285 [02:58<03:03,  1.15s/it]Loading train:  44%|████▍     | 126/285 [02:59<02:55,  1.10s/it]Loading train:  45%|████▍     | 127/285 [02:59<02:42,  1.03s/it]Loading train:  45%|████▍     | 128/285 [03:00<02:37,  1.00s/it]Loading train:  45%|████▌     | 129/285 [03:01<02:30,  1.03it/s]Loading train:  46%|████▌     | 130/285 [03:02<02:26,  1.06it/s]Loading train:  46%|████▌     | 131/285 [03:03<02:26,  1.05it/s]Loading train:  46%|████▋     | 132/285 [03:04<02:22,  1.07it/s]Loading train:  47%|████▋     | 133/285 [03:05<02:18,  1.09it/s]Loading train:  47%|████▋     | 134/285 [03:06<02:15,  1.11it/s]Loading train:  47%|████▋     | 135/285 [03:07<02:17,  1.09it/s]Loading train:  48%|████▊     | 136/285 [03:08<02:13,  1.12it/s]Loading train:  48%|████▊     | 137/285 [03:09<02:14,  1.10it/s]Loading train:  48%|████▊     | 138/285 [03:09<02:08,  1.15it/s]Loading train:  49%|████▉     | 139/285 [03:10<02:05,  1.17it/s]Loading train:  49%|████▉     | 140/285 [03:11<02:04,  1.16it/s]Loading train:  49%|████▉     | 141/285 [03:12<02:00,  1.20it/s]Loading train:  50%|████▉     | 142/285 [03:13<02:04,  1.15it/s]Loading train:  50%|█████     | 143/285 [03:13<01:58,  1.20it/s]Loading train:  51%|█████     | 144/285 [03:14<02:04,  1.14it/s]Loading train:  51%|█████     | 145/285 [03:15<02:03,  1.14it/s]Loading train:  51%|█████     | 146/285 [03:16<02:02,  1.13it/s]Loading train:  52%|█████▏    | 147/285 [03:17<02:02,  1.13it/s]Loading train:  52%|█████▏    | 148/285 [03:18<02:04,  1.10it/s]Loading train:  52%|█████▏    | 149/285 [03:19<02:02,  1.11it/s]Loading train:  53%|█████▎    | 150/285 [03:20<01:57,  1.15it/s]Loading train:  53%|█████▎    | 151/285 [03:21<01:55,  1.16it/s]Loading train:  53%|█████▎    | 152/285 [03:21<01:53,  1.17it/s]Loading train:  54%|█████▎    | 153/285 [03:22<01:55,  1.14it/s]Loading train:  54%|█████▍    | 154/285 [03:23<01:55,  1.14it/s]Loading train:  54%|█████▍    | 155/285 [03:24<01:56,  1.12it/s]Loading train:  55%|█████▍    | 156/285 [03:25<02:01,  1.06it/s]Loading train:  55%|█████▌    | 157/285 [03:26<01:54,  1.11it/s]Loading train:  55%|█████▌    | 158/285 [03:27<01:54,  1.11it/s]Loading train:  56%|█████▌    | 159/285 [03:28<01:50,  1.14it/s]Loading train:  56%|█████▌    | 160/285 [03:29<01:53,  1.10it/s]Loading train:  56%|█████▋    | 161/285 [03:30<01:56,  1.07it/s]Loading train:  57%|█████▋    | 162/285 [03:31<01:54,  1.07it/s]Loading train:  57%|█████▋    | 163/285 [03:32<01:55,  1.05it/s]Loading train:  58%|█████▊    | 164/285 [03:33<01:54,  1.06it/s]Loading train:  58%|█████▊    | 165/285 [03:34<01:53,  1.06it/s]Loading train:  58%|█████▊    | 166/285 [03:34<01:48,  1.09it/s]Loading train:  59%|█████▊    | 167/285 [03:35<01:49,  1.07it/s]Loading train:  59%|█████▉    | 168/285 [03:36<01:47,  1.09it/s]Loading train:  59%|█████▉    | 169/285 [03:37<01:46,  1.09it/s]Loading train:  60%|█████▉    | 170/285 [03:38<01:41,  1.13it/s]Loading train:  60%|██████    | 171/285 [03:39<01:39,  1.14it/s]Loading train:  60%|██████    | 172/285 [03:40<01:38,  1.15it/s]Loading train:  61%|██████    | 173/285 [03:41<01:37,  1.15it/s]Loading train:  61%|██████    | 174/285 [03:41<01:37,  1.14it/s]Loading train:  61%|██████▏   | 175/285 [03:42<01:35,  1.16it/s]Loading train:  62%|██████▏   | 176/285 [03:43<01:37,  1.11it/s]Loading train:  62%|██████▏   | 177/285 [03:44<01:38,  1.09it/s]Loading train:  62%|██████▏   | 178/285 [03:45<01:39,  1.08it/s]Loading train:  63%|██████▎   | 179/285 [03:46<01:37,  1.09it/s]Loading train:  63%|██████▎   | 180/285 [03:47<01:40,  1.04it/s]Loading train:  64%|██████▎   | 181/285 [03:48<01:41,  1.03it/s]Loading train:  64%|██████▍   | 182/285 [03:49<01:41,  1.02it/s]Loading train:  64%|██████▍   | 183/285 [03:50<01:42,  1.00s/it]Loading train:  65%|██████▍   | 184/285 [03:51<01:34,  1.06it/s]Loading train:  65%|██████▍   | 185/285 [03:52<01:32,  1.08it/s]Loading train:  65%|██████▌   | 186/285 [03:53<01:34,  1.05it/s]Loading train:  66%|██████▌   | 187/285 [03:54<01:35,  1.03it/s]Loading train:  66%|██████▌   | 188/285 [03:55<01:37,  1.00s/it]Loading train:  66%|██████▋   | 189/285 [03:56<01:30,  1.06it/s]Loading train:  67%|██████▋   | 190/285 [03:57<01:24,  1.12it/s]Loading train:  67%|██████▋   | 191/285 [03:58<01:25,  1.09it/s]Loading train:  67%|██████▋   | 192/285 [03:58<01:23,  1.12it/s]Loading train:  68%|██████▊   | 193/285 [03:59<01:18,  1.18it/s]Loading train:  68%|██████▊   | 194/285 [04:00<01:17,  1.18it/s]Loading train:  68%|██████▊   | 195/285 [04:01<01:16,  1.17it/s]Loading train:  69%|██████▉   | 196/285 [04:02<01:18,  1.13it/s]Loading train:  69%|██████▉   | 197/285 [04:03<01:19,  1.11it/s]Loading train:  69%|██████▉   | 198/285 [04:04<01:18,  1.11it/s]Loading train:  70%|██████▉   | 199/285 [04:04<01:14,  1.15it/s]Loading train:  70%|███████   | 200/285 [04:05<01:12,  1.17it/s]Loading train:  71%|███████   | 201/285 [04:06<01:15,  1.11it/s]Loading train:  71%|███████   | 202/285 [04:07<01:16,  1.09it/s]Loading train:  71%|███████   | 203/285 [04:08<01:16,  1.07it/s]Loading train:  72%|███████▏  | 204/285 [04:09<01:16,  1.07it/s]Loading train:  72%|███████▏  | 205/285 [04:10<01:13,  1.09it/s]Loading train:  72%|███████▏  | 206/285 [04:11<01:12,  1.09it/s]Loading train:  73%|███████▎  | 207/285 [04:12<01:13,  1.07it/s]Loading train:  73%|███████▎  | 208/285 [04:13<01:15,  1.03it/s]Loading train:  73%|███████▎  | 209/285 [04:14<01:13,  1.03it/s]Loading train:  74%|███████▎  | 210/285 [04:15<01:10,  1.06it/s]Loading train:  74%|███████▍  | 211/285 [04:16<01:06,  1.11it/s]Loading train:  74%|███████▍  | 212/285 [04:16<01:05,  1.12it/s]Loading train:  75%|███████▍  | 213/285 [04:17<01:06,  1.08it/s]Loading train:  75%|███████▌  | 214/285 [04:18<01:05,  1.09it/s]Loading train:  75%|███████▌  | 215/285 [04:19<01:08,  1.03it/s]Loading train:  76%|███████▌  | 216/285 [04:20<01:05,  1.05it/s]Loading train:  76%|███████▌  | 217/285 [04:21<01:07,  1.00it/s]Loading train:  76%|███████▋  | 218/285 [04:23<01:08,  1.03s/it]Loading train:  77%|███████▋  | 219/285 [04:24<01:09,  1.05s/it]Loading train:  77%|███████▋  | 220/285 [04:25<01:05,  1.00s/it]Loading train:  78%|███████▊  | 221/285 [04:26<01:03,  1.01it/s]Loading train:  78%|███████▊  | 222/285 [04:26<01:01,  1.03it/s]Loading train:  78%|███████▊  | 223/285 [04:27<00:57,  1.08it/s]Loading train:  79%|███████▊  | 224/285 [04:28<00:53,  1.14it/s]Loading train:  79%|███████▉  | 225/285 [04:29<00:51,  1.17it/s]Loading train:  79%|███████▉  | 226/285 [04:30<00:52,  1.13it/s]Loading train:  80%|███████▉  | 227/285 [04:31<00:53,  1.08it/s]Loading train:  80%|████████  | 228/285 [04:32<00:54,  1.05it/s]Loading train:  80%|████████  | 229/285 [04:33<00:55,  1.01it/s]Loading train:  81%|████████  | 230/285 [04:34<00:53,  1.03it/s]Loading train:  81%|████████  | 231/285 [04:35<00:51,  1.06it/s]Loading train:  81%|████████▏ | 232/285 [04:36<00:50,  1.06it/s]Loading train:  82%|████████▏ | 233/285 [04:37<00:48,  1.07it/s]Loading train:  82%|████████▏ | 234/285 [04:38<00:49,  1.03it/s]Loading train:  82%|████████▏ | 235/285 [04:38<00:46,  1.08it/s]Loading train:  83%|████████▎ | 236/285 [04:40<00:47,  1.02it/s]Loading train:  83%|████████▎ | 237/285 [04:41<00:48,  1.01s/it]Loading train:  84%|████████▎ | 238/285 [04:42<00:47,  1.02s/it]Loading train:  84%|████████▍ | 239/285 [04:43<00:46,  1.00s/it]Loading train:  84%|████████▍ | 240/285 [04:43<00:42,  1.06it/s]Loading train:  85%|████████▍ | 241/285 [04:44<00:40,  1.09it/s]Loading train:  85%|████████▍ | 242/285 [04:45<00:38,  1.10it/s]Loading train:  85%|████████▌ | 243/285 [04:46<00:37,  1.11it/s]Loading train:  86%|████████▌ | 244/285 [04:47<00:39,  1.04it/s]Loading train:  86%|████████▌ | 245/285 [04:48<00:37,  1.07it/s]Loading train:  86%|████████▋ | 246/285 [04:49<00:37,  1.04it/s]Loading train:  87%|████████▋ | 247/285 [04:50<00:37,  1.01it/s]Loading train:  87%|████████▋ | 248/285 [04:51<00:36,  1.02it/s]Loading train:  87%|████████▋ | 249/285 [04:52<00:34,  1.05it/s]Loading train:  88%|████████▊ | 250/285 [04:53<00:32,  1.06it/s]Loading train:  88%|████████▊ | 251/285 [04:54<00:31,  1.09it/s]Loading train:  88%|████████▊ | 252/285 [04:55<00:30,  1.09it/s]Loading train:  89%|████████▉ | 253/285 [04:56<00:30,  1.06it/s]Loading train:  89%|████████▉ | 254/285 [04:57<00:30,  1.02it/s]Loading train:  89%|████████▉ | 255/285 [04:58<00:28,  1.06it/s]Loading train:  90%|████████▉ | 256/285 [04:58<00:26,  1.10it/s]Loading train:  90%|█████████ | 257/285 [04:59<00:25,  1.11it/s]Loading train:  91%|█████████ | 258/285 [05:00<00:25,  1.05it/s]Loading train:  91%|█████████ | 259/285 [05:01<00:24,  1.05it/s]Loading train:  91%|█████████ | 260/285 [05:02<00:23,  1.07it/s]Loading train:  92%|█████████▏| 261/285 [05:03<00:22,  1.07it/s]Loading train:  92%|█████████▏| 262/285 [05:04<00:20,  1.13it/s]Loading train:  92%|█████████▏| 263/285 [05:05<00:19,  1.13it/s]Loading train:  93%|█████████▎| 264/285 [05:06<00:19,  1.05it/s]Loading train:  93%|█████████▎| 265/285 [05:07<00:19,  1.00it/s]Loading train:  93%|█████████▎| 266/285 [05:08<00:18,  1.01it/s]Loading train:  94%|█████████▎| 267/285 [05:09<00:17,  1.05it/s]Loading train:  94%|█████████▍| 268/285 [05:10<00:17,  1.01s/it]Loading train:  94%|█████████▍| 269/285 [05:11<00:16,  1.00s/it]Loading train:  95%|█████████▍| 270/285 [05:12<00:14,  1.04it/s]Loading train:  95%|█████████▌| 271/285 [05:13<00:13,  1.06it/s]Loading train:  95%|█████████▌| 272/285 [05:14<00:12,  1.05it/s]Loading train:  96%|█████████▌| 273/285 [05:15<00:11,  1.08it/s]Loading train:  96%|█████████▌| 274/285 [05:16<00:10,  1.09it/s]Loading train:  96%|█████████▋| 275/285 [05:17<00:09,  1.04it/s]Loading train:  97%|█████████▋| 276/285 [05:18<00:08,  1.02it/s]Loading train:  97%|█████████▋| 277/285 [05:18<00:07,  1.06it/s]Loading train:  98%|█████████▊| 278/285 [05:19<00:06,  1.07it/s]Loading train:  98%|█████████▊| 279/285 [05:20<00:05,  1.07it/s]Loading train:  98%|█████████▊| 280/285 [05:21<00:04,  1.11it/s]Loading train:  99%|█████████▊| 281/285 [05:22<00:03,  1.15it/s]Loading train:  99%|█████████▉| 282/285 [05:23<00:02,  1.17it/s]Loading train:  99%|█████████▉| 283/285 [05:24<00:01,  1.09it/s]Loading train: 100%|█████████▉| 284/285 [05:25<00:00,  1.05it/s]Loading train: 100%|██████████| 285/285 [05:26<00:00,  1.02it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:04, 64.65it/s]concatenating: train:  11%|█         | 30/285 [00:00<00:03, 82.19it/s]concatenating: train:  21%|██        | 59/285 [00:00<00:02, 104.64it/s]concatenating: train:  31%|███       | 88/285 [00:00<00:01, 129.37it/s]concatenating: train:  41%|████      | 117/285 [00:00<00:01, 154.95it/s]concatenating: train:  52%|█████▏    | 148/285 [00:00<00:00, 181.68it/s]concatenating: train:  62%|██████▏   | 177/285 [00:00<00:00, 203.34it/s]concatenating: train:  74%|███████▎  | 210/285 [00:00<00:00, 228.40it/s]concatenating: train:  84%|████████▎ | 238/285 [00:00<00:00, 238.37it/s]concatenating: train:  95%|█████████▌| 271/285 [00:01<00:00, 259.74it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 268.47it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.36s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.33s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.27s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 71.01it/s]2019-07-09 08:44:42.065964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-09 08:44:42.066063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-09 08:44:42.066078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-09 08:44:42.066087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-09 08:44:42.066441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12743 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.41it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.26it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.03it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.42it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.65it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.35it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.55it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.15it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  7.55it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.24it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.76it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:02,  8.14it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  8.22it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  6.51it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.15it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:00,  8.49it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  8.53it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  6.62it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.34it/s]
Epoch 00037: val_mDice did not improve from 0.58198
Restoring model weights from the end of the best epoch
Epoch 00037: early stopping
{'val_loss': [7180.158203125, 4132.557256789434, 2838.3545968191966, 2870.3566313244046, 2602.4513346354165, 2555.0342145647323, 2492.831031436012, 2506.6256161644346, 2611.5135207403273, 2803.1001906622023, 2612.3858351934523, 2575.2459891183034, 2609.5283086867557, 2777.3543410528273, 2605.8443196614585, 2743.126150948661, 2603.9300711495534, 2738.8780924479165, 2697.9921991257443, 2771.6137579055057, 2690.178734188988, 2673.3155226934523, 2686.772728329613, 2658.4743768601193, 2663.7402925037204, 2713.071486700149, 2690.39404296875, 2796.578438895089, 2818.765066964286, 2843.120872860863, 2646.3030366443454, 2653.8571661086307, 2864.9218866257443, 2812.4778878348216, 2841.520286923363, 2748.1980096726193, 2686.487083798363], 'val_acc': [0.9063003943079994, 0.9133859702519008, 0.9346291280928112, 0.938944623583839, 0.945737191608974, 0.9465315881229582, 0.9476854432196844, 0.9429052273432413, 0.9446039398511251, 0.9462911912373134, 0.9388781785964966, 0.9415979725973946, 0.9404098050934928, 0.9325068791707357, 0.9399381847608657, 0.9384752852576119, 0.9407669589633033, 0.9453296945208595, 0.944972554842631, 0.9448443310601371, 0.9402861765452794, 0.9411469953400748, 0.9433791069757371, 0.9425205928938729, 0.9456707920346942, 0.9443452273096357, 0.9449862695875622, 0.9439125344866798, 0.9426465006101699, 0.9447779144559588, 0.9438713448388236, 0.9457417726516724, 0.944056803271884, 0.9431455873307728, 0.9458333140327817, 0.9446382749648321, 0.9442261854807535], 'val_mDice': [0.24319453506558647, 0.423144025184835, 0.5446182787418365, 0.541110900186357, 0.570573954355149, 0.5751987594578948, 0.5819821368370738, 0.5794563305874666, 0.5673440522736027, 0.5482133768853688, 0.5662349540562857, 0.5704050837528138, 0.5662622785284406, 0.5477961926233201, 0.5659248763251872, 0.5517630339378402, 0.5667630306312016, 0.5520752714503379, 0.5577120651446638, 0.5494822544001398, 0.5598577592699301, 0.5600812928307624, 0.5585947780027276, 0.5618274281067508, 0.5605010337063244, 0.5575105810449237, 0.558674670933258, 0.5474110809820039, 0.54520950413176, 0.5417359446485838, 0.5625381368611541, 0.5629072987607547, 0.5399339864296573, 0.5455381868495828, 0.5435777702147052, 0.553608642802352, 0.5590143813973382], 'loss': [11752.800693280302, 3797.1720468445, 2721.0244793455245, 2340.5460612685183, 2144.228199494191, 2013.459957336814, 1927.4804352612678, 1848.5587653356272, 1789.581320761715, 1743.9217809585562, 1692.8654263174462, 1657.2521621059861, 1610.5910245631733, 1599.3048567793055, 1558.6804827338403, 1529.9350848811105, 1502.7707168640877, 1478.7137710280058, 1456.9220792271394, 1448.1603806456872, 1422.358891425529, 1396.861017077512, 1388.714404454552, 1372.5463854126187, 1362.465639289781, 1342.8259400543689, 1329.4424244792608, 1318.799989758049, 1301.1356950608756, 1299.4178192156323, 1285.1863895414053, 1267.7073312130235, 1268.9393717565586, 1256.0186330789036, 1249.2982229626614, 1242.6395697872235, 1229.3444526985659], 'acc': [0.6532744579254167, 0.8867755805409573, 0.8977254528242751, 0.9065161039196321, 0.915374487920007, 0.9241821509646799, 0.9304403526741162, 0.9356591393659403, 0.9388974231402263, 0.9401148958819345, 0.9411079460241121, 0.9418964174778814, 0.9427539342075316, 0.9430267625469129, 0.9437710844829221, 0.9444050461496258, 0.9450770966667005, 0.9453954094748335, 0.9459448845969797, 0.9460747389290542, 0.9466165174793503, 0.9469474351357835, 0.9471123274843058, 0.947438003402329, 0.9477676251432398, 0.9479179629958708, 0.9481719725274939, 0.9483228469942953, 0.948759453395945, 0.9487181550187368, 0.9490298158588818, 0.9493426866606754, 0.9494642442835993, 0.9496286699186751, 0.9497010620062766, 0.9498919949311844, 0.9500672431701821], 'mDice': [0.18166273352708895, 0.4717061173738899, 0.5790940600368175, 0.6241918399840943, 0.6490270767065747, 0.6658307784482053, 0.6769327688290706, 0.6872859235809147, 0.6949968898321637, 0.7012399433549484, 0.7082836982807214, 0.713330142755878, 0.7199000221974637, 0.7215664172783877, 0.7273917516141538, 0.7316864775466808, 0.7355859710665964, 0.7390987074097066, 0.7424184572542705, 0.7436326754927428, 0.7475526368822554, 0.7513672602482331, 0.7525986435327406, 0.7550785619789221, 0.7566014868297948, 0.7595754783117222, 0.7616548940283682, 0.7632875262093677, 0.7660409982939412, 0.7663217846175621, 0.7685917138547733, 0.7711939548329165, 0.7710497166486703, 0.7730345490214588, 0.7740940341421789, 0.7752014752962191, 0.7772500015348512]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 20)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 21)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   3800        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 20)   10820       dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 52, 20)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 52, 80)   0           dropout_6[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 52, 13)   1053        concatenate_8[0][0]              
==================================================================================================
Total params: 238,873
Trainable params: 64,113
Non-trainable params: 174,760
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 32s - loss: 10938.6380 - acc: 0.7609 - mDice: 0.1876 - val_loss: 8513.1747 - val_acc: 0.9149 - val_mDice: 0.2714

Epoch 00001: val_mDice improved from -inf to 0.27139, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 23s - loss: 4116.0699 - acc: 0.8983 - mDice: 0.4412 - val_loss: 4513.7430 - val_acc: 0.9177 - val_mDice: 0.4150

Epoch 00002: val_mDice improved from 0.27139 to 0.41503, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 23s - loss: 3153.4535 - acc: 0.9097 - mDice: 0.5312 - val_loss: 3024.1282 - val_acc: 0.9325 - val_mDice: 0.5193

Epoch 00003: val_mDice improved from 0.41503 to 0.51927, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 23s - loss: 2740.9083 - acc: 0.9247 - mDice: 0.5766 - val_loss: 2810.6100 - val_acc: 0.9382 - val_mDice: 0.5362

Epoch 00004: val_mDice improved from 0.51927 to 0.53616, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 24s - loss: 2505.1890 - acc: 0.9347 - mDice: 0.6038 - val_loss: 2329.4088 - val_acc: 0.9458 - val_mDice: 0.5938

Epoch 00005: val_mDice improved from 0.53616 to 0.59377, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 23s - loss: 2341.8244 - acc: 0.9380 - mDice: 0.6230 - val_loss: 2341.2696 - val_acc: 0.9451 - val_mDice: 0.5918

Epoch 00006: val_mDice did not improve from 0.59377
Epoch 7/300
 - 23s - loss: 2223.3629 - acc: 0.9399 - mDice: 0.6380 - val_loss: 2296.7995 - val_acc: 0.9488 - val_mDice: 0.6011

Epoch 00007: val_mDice improved from 0.59377 to 0.60109, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 24s - loss: 2130.5920 - acc: 0.9415 - mDice: 0.6496 - val_loss: 2333.0484 - val_acc: 0.9468 - val_mDice: 0.5939

Epoch 00008: val_mDice did not improve from 0.60109
Epoch 9/300
 - 23s - loss: 2056.5967 - acc: 0.9426 - mDice: 0.6592 - val_loss: 2338.4312 - val_acc: 0.9484 - val_mDice: 0.5985

Epoch 00009: val_mDice did not improve from 0.60109
Epoch 10/300
 - 23s - loss: 1977.4971 - acc: 0.9438 - mDice: 0.6695 - val_loss: 2341.8010 - val_acc: 0.9494 - val_mDice: 0.5957

Epoch 00010: val_mDice did not improve from 0.60109
Epoch 11/300
 - 23s - loss: 1936.8142 - acc: 0.9445 - mDice: 0.6751 - val_loss: 2879.1332 - val_acc: 0.9387 - val_mDice: 0.5343

Epoch 00011: val_mDice did not improve from 0.60109
Epoch 12/300
 - 23s - loss: 1889.0226 - acc: 0.9453 - mDice: 0.6814 - val_loss: 2257.6777 - val_acc: 0.9472 - val_mDice: 0.6037

Epoch 00012: val_mDice improved from 0.60109 to 0.60370, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 23s - loss: 1841.7910 - acc: 0.9459 - mDice: 0.6878 - val_loss: 2234.3264 - val_acc: 0.9486 - val_mDice: 0.6072

Epoch 00013: val_mDice improved from 0.60370 to 0.60717, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 23s - loss: 1802.3530 - acc: 0.9466 - mDice: 0.6932 - val_loss: 2317.7055 - val_acc: 0.9510 - val_mDice: 0.6001

Epoch 00014: val_mDice did not improve from 0.60717
Epoch 15/300
 - 23s - loss: 1767.0095 - acc: 0.9471 - mDice: 0.6982 - val_loss: 2262.7120 - val_acc: 0.9467 - val_mDice: 0.6043

Epoch 00015: val_mDice did not improve from 0.60717
Epoch 16/300
 - 24s - loss: 1744.2381 - acc: 0.9475 - mDice: 0.7014 - val_loss: 2208.5565 - val_acc: 0.9492 - val_mDice: 0.6096

Epoch 00016: val_mDice improved from 0.60717 to 0.60961, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 23s - loss: 1711.5029 - acc: 0.9481 - mDice: 0.7059 - val_loss: 2242.3107 - val_acc: 0.9480 - val_mDice: 0.6068

Epoch 00017: val_mDice did not improve from 0.60961
Epoch 18/300
 - 23s - loss: 1688.3774 - acc: 0.9484 - mDice: 0.7091 - val_loss: 2235.7045 - val_acc: 0.9514 - val_mDice: 0.6101

Epoch 00018: val_mDice improved from 0.60961 to 0.61015, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 19/300
 - 23s - loss: 1653.5228 - acc: 0.9489 - mDice: 0.7140 - val_loss: 2296.9131 - val_acc: 0.9509 - val_mDice: 0.6013

Epoch 00019: val_mDice did not improve from 0.61015
Epoch 20/300
 - 23s - loss: 1648.0846 - acc: 0.9491 - mDice: 0.7150 - val_loss: 2320.6559 - val_acc: 0.9489 - val_mDice: 0.5978

Epoch 00020: val_mDice did not improve from 0.61015
Epoch 21/300
 - 23s - loss: 1620.6261 - acc: 0.9494 - mDice: 0.7188 - val_loss: 2258.6439 - val_acc: 0.9484 - val_mDice: 0.6049

Epoch 00021: val_mDice did not improve from 0.61015
Epoch 22/300
 - 23s - loss: 1594.3268 - acc: 0.9499 - mDice: 0.7225 - val_loss: 2336.9550 - val_acc: 0.9502 - val_mDice: 0.5970

Epoch 00022: val_mDice did not improve from 0.61015
Epoch 23/300
 - 22s - loss: 1582.8597 - acc: 0.9501 - mDice: 0.7242 - val_loss: 2319.9504 - val_acc: 0.9504 - val_mDice: 0.5996

Epoch 00023: val_mDice did not improve from 0.61015
Epoch 24/300
 - 24s - loss: 1568.5501 - acc: 0.9503 - mDice: 0.7263 - val_loss: 2165.2512 - val_acc: 0.9524 - val_mDice: 0.6180

Epoch 00024: val_mDice improved from 0.61015 to 0.61798, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 25/300
 - 23s - loss: 1559.0630 - acc: 0.9504 - mDice: 0.7276 - val_loss: 2154.9623 - val_acc: 0.9499 - val_mDice: 0.6180

Epoch 00025: val_mDice did not improve from 0.61798
Epoch 26/300
 - 23s - loss: 1541.3686 - acc: 0.9507 - mDice: 0.7303 - val_loss: 2357.8674 - val_acc: 0.9525 - val_mDice: 0.5968

Epoch 00026: val_mDice did not improve from 0.61798
Epoch 27/300
 - 23s - loss: 1523.4933 - acc: 0.9510 - mDice: 0.7329 - val_loss: 2327.4721 - val_acc: 0.9507 - val_mDice: 0.5996

Epoch 00027: val_mDice did not improve from 0.61798
Epoch 28/300
 - 23s - loss: 1521.0269 - acc: 0.9511 - mDice: 0.7334 - val_loss: 2192.0936 - val_acc: 0.9497 - val_mDice: 0.6120

Epoch 00028: val_mDice did not improve from 0.61798
Epoch 29/300
 - 24s - loss: 1507.1397 - acc: 0.9513 - mDice: 0.7353 - val_loss: 2436.9612 - val_acc: 0.9479 - val_mDice: 0.5857

Epoch 00029: val_mDice did not improve from 0.61798
Epoch 30/300
 - 23s - loss: 1496.4193 - acc: 0.9515 - mDice: 0.7369 - val_loss: 2368.3295 - val_acc: 0.9502 - val_mDice: 0.5942

Epoch 00030: val_mDice did not improve from 0.61798
Epoch 31/300
 - 23s - loss: 1480.5794 - acc: 0.9517 - mDice: 0.7393 - val_loss: 2220.5717 - val_acc: 0.9505 - val_mDice: 0.6107

Epoch 00031: val_mDice did not improve from 0.61798
Epoch 32/300
 - 23s - loss: 1468.2885 - acc: 0.9520 - mDice: 0.7412 - val_loss: 2323.6088 - val_acc: 0.9504 - val_mDice: 0.5983

Epoch 00032: val_mDice did not improve from 0.61798
Epoch 33/300
 - 23s - loss: 1458.7865 - acc: 0.9522 - mDice: 0.7425 - val_loss: 2334.4009 - val_acc: 0.9513 - val_mDice: 0.6002

Epoch 00033: val_mDice did not improve from 0.61798
Epoch 34/300
 - 23s - loss: 1454.9480 - acc: 0.9522 - mDice: 0.7430 - val_loss: 2287.0361 - val_acc: 0.9512 - val_mDice: 0.6018

Epoch 00034: val_mDice did not improve from 0.61798
Epoch 35/300
 - 22s - loss: 1431.7356 - acc: 0.9525 - mDice: 0.7465 - val_loss: 2259.3051 - val_acc: 0.9509 - val_mDice: 0.6067

Epoch 00035: val_mDice did not improve from 0.61798
Epoch 36/300
 - 23s - loss: 1432.1063 - acc: 0.9525 - mDice: 0.7465 - val_loss: 2202.2540 - val_acc: 0.9488 - val_mDice: 0.6103

Epoch 00036: val_mDice did not improve from 0.61798
Epoch 37/300
 - 22s - loss: 1439.7696 - acc: 0.9525 - mDice: 0.7454 - val_loss: 2268.8729 - val_acc: 0.9465 - val_mDice: 0.6028

Epoch 00037: val_mDice did not improve from 0.61798
Epoch 38/300
 - 23s - loss: 1418.8190 - acc: 0.9528 - mDice: 0.7484 - val_loss: 2337.8127 - val_acc: 0.9481 - val_mDice: 0.5958

Epoch 00038: val_mDice did not improve from 0.61798
Epoch 39/300
 - 23s - loss: 1413.1187 - acc: 0.9529 - mDice: 0.7493 - val_loss: 2331.2610 - val_acc: 0.9488 - val_mDice: 0.5961

Epoch 00039: val_mDice did not improve from 0.61798
Epoch 40/300
 - 22s - loss: 1400.9436 - acc: 0.9531 - mDice: 0.7511 - val_loss: 2433.7183 - val_acc: 0.9502 - val_mDice: 0.5878

Epoch 00040: val_mDice did not improve from 0.61798
Epoch 41/300
 - 23s - loss: 1393.9137 - acc: 0.9533 - mDice: 0.7523 - val_loss: 2250.3641 - val_acc: 0.9465 - val_mDice: 0.6047

Epoch 00041: val_mDice did not improve from 0.61798
Epoch 42/300
 - 23s - loss: 1391.6599 - acc: 0.9533 - mDice: 0.7527 - val_loss: 2365.0209 - val_acc: 0.9487 - val_mDice: 0.5936

Epoch 00042: val_mDice did not improve from 0.61798
Epoch 43/300
 - 23s - loss: 1385.7530 - acc: 0.9535 - mDice: 0.7535 - val_loss: 2242.4911 - val_acc: 0.9493 - val_mDice: 0.6078

Epoch 00043: val_mDice did not improve from 0.61798
Epoch 44/300
 - 23s - loss: 1382.6865 - acc: 0.9536 - mDice: 0.7539 - val_loss: 2187.0665 - val_acc: 0.9510 - val_mDice: 0.6133

Epoch 00044: val_mDice did not improve from 0.61798
Epoch 45/300
 - 23s - loss: 1379.3799 - acc: 0.9536 - mDice: 0.7546 - val_loss: 2221.4873 - val_acc: 0.9503 - val_mDice: 0.6103

Epoch 00045: val_mDice did not improve from 0.61798
Epoch 46/300
 - 21s - loss: 1367.6337 - acc: 0.9537 - mDice: 0.7561 - val_loss: 2272.9542 - val_acc: 0.9497 - val_mDice: 0.6031

Epoch 00046: val_mDice did not improve from 0.61798
Epoch 47/300
 - 22s - loss: 1361.2926 - acc: 0.9537 - mDice: 0.7572 - val_loss: 2351.0055 - val_acc: 0.9490 - val_mDice: 0.5948

Epoch 00047: val_mDice did not improve from 0.61798
Epoch 48/300
 - 23s - loss: 1348.2484 - acc: 0.9540 - mDice: 0.7591 - val_loss: 2204.6665 - val_acc: 0.9491 - val_mDice: 0.6110

Epoch 00048: val_mDice did not improve from 0.61798
Epoch 49/300
 - 24s - loss: 1345.8399 - acc: 0.9540 - mDice: 0.7595 - val_loss: 2385.2207 - val_acc: 0.9482 - val_mDice: 0.5915

Epoch 00049: val_mDice did not improve from 0.61798
Epoch 50/300
 - 23s - loss: 1349.5640 - acc: 0.9539 - mDice: 0.7590 - val_loss: 2283.3846 - val_acc: 0.9489 - val_mDice: 0.6024

Epoch 00050: val_mDice did not improve from 0.61798
Epoch 51/300
 - 22s - loss: 1344.4538 - acc: 0.9541 - mDice: 0.7598 - val_loss: 2293.6485 - val_acc: 0.9501 - val_mDice: 0.6042

Epoch 00051: val_mDice did not improve from 0.61798
Epoch 52/300
 - 23s - loss: 1339.0615 - acc: 0.9541 - mDice: 0.7606 - val_loss: 2392.8897 - val_acc: 0.9500 - val_mDice: 0.5919

Epoch 00052: val_mDice did not improve from 0.61798
Epoch 53/300
 - 22s - loss: 1331.1916 - acc: 0.9543 - mDice: 0.7618 - val_loss: 2295.4482 - val_acc: 0.9491 - val_mDice: 0.6007

Epoch 00053: val_mDice did not improve from 0.61798
Epoch 54/300
 - 24s - loss: 1321.6805 - acc: 0.9544 - mDice: 0.7631 - val_loss: 2317.0946 - val_acc: 0.9475 - val_mDice: 0.5978

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.52s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.24s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  2.02s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:15,  1.96s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:50,  1.88s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:45,  1.86s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<08:25,  1.80s/it]predicting train subjects:   2%|▏         | 5/285 [00:09<08:43,  1.87s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<08:24,  1.81s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:34,  1.85s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:26,  1.83s/it]predicting train subjects:   3%|▎         | 9/285 [00:16<08:56,  1.94s/it]predicting train subjects:   4%|▎         | 10/285 [00:19<09:36,  2.10s/it]predicting train subjects:   4%|▍         | 11/285 [00:20<09:07,  2.00s/it]predicting train subjects:   4%|▍         | 12/285 [00:23<09:36,  2.11s/it]predicting train subjects:   5%|▍         | 13/285 [00:25<09:05,  2.00s/it]predicting train subjects:   5%|▍         | 14/285 [00:27<08:59,  1.99s/it]predicting train subjects:   5%|▌         | 15/285 [00:29<09:26,  2.10s/it]predicting train subjects:   6%|▌         | 16/285 [00:31<09:26,  2.10s/it]predicting train subjects:   6%|▌         | 17/285 [00:33<08:53,  1.99s/it]predicting train subjects:   6%|▋         | 18/285 [00:35<08:40,  1.95s/it]predicting train subjects:   7%|▋         | 19/285 [00:36<08:21,  1.89s/it]predicting train subjects:   7%|▋         | 20/285 [00:38<08:20,  1.89s/it]predicting train subjects:   7%|▋         | 21/285 [00:40<08:40,  1.97s/it]predicting train subjects:   8%|▊         | 22/285 [00:42<08:18,  1.89s/it]predicting train subjects:   8%|▊         | 23/285 [00:44<08:15,  1.89s/it]predicting train subjects:   8%|▊         | 24/285 [00:46<07:52,  1.81s/it]predicting train subjects:   9%|▉         | 25/285 [00:48<08:17,  1.91s/it]predicting train subjects:   9%|▉         | 26/285 [00:50<08:27,  1.96s/it]predicting train subjects:   9%|▉         | 27/285 [00:51<07:58,  1.85s/it]predicting train subjects:  10%|▉         | 28/285 [00:53<08:00,  1.87s/it]predicting train subjects:  10%|█         | 29/285 [00:55<07:55,  1.86s/it]predicting train subjects:  11%|█         | 30/285 [00:57<08:11,  1.93s/it]predicting train subjects:  11%|█         | 31/285 [00:59<08:23,  1.98s/it]predicting train subjects:  11%|█         | 32/285 [01:01<07:53,  1.87s/it]predicting train subjects:  12%|█▏        | 33/285 [01:03<07:57,  1.90s/it]predicting train subjects:  12%|█▏        | 34/285 [01:05<08:02,  1.92s/it]predicting train subjects:  12%|█▏        | 35/285 [01:07<08:21,  2.00s/it]predicting train subjects:  13%|█▎        | 36/285 [01:09<07:58,  1.92s/it]predicting train subjects:  13%|█▎        | 37/285 [01:11<08:02,  1.95s/it]predicting train subjects:  13%|█▎        | 38/285 [01:13<08:09,  1.98s/it]predicting train subjects:  14%|█▎        | 39/285 [01:15<07:54,  1.93s/it]predicting train subjects:  14%|█▍        | 40/285 [01:17<07:54,  1.94s/it]predicting train subjects:  14%|█▍        | 41/285 [01:18<07:41,  1.89s/it]predicting train subjects:  15%|█▍        | 42/285 [01:20<07:22,  1.82s/it]predicting train subjects:  15%|█▌        | 43/285 [01:22<07:27,  1.85s/it]predicting train subjects:  15%|█▌        | 44/285 [01:24<07:49,  1.95s/it]predicting train subjects:  16%|█▌        | 45/285 [01:26<07:32,  1.89s/it]predicting train subjects:  16%|█▌        | 46/285 [01:28<07:49,  1.96s/it]predicting train subjects:  16%|█▋        | 47/285 [01:30<07:31,  1.90s/it]predicting train subjects:  17%|█▋        | 48/285 [01:32<07:31,  1.91s/it]predicting train subjects:  17%|█▋        | 49/285 [01:34<07:49,  1.99s/it]predicting train subjects:  18%|█▊        | 50/285 [01:36<07:35,  1.94s/it]predicting train subjects:  18%|█▊        | 51/285 [01:38<07:45,  1.99s/it]predicting train subjects:  18%|█▊        | 52/285 [01:40<07:24,  1.91s/it]predicting train subjects:  19%|█▊        | 53/285 [01:42<07:23,  1.91s/it]predicting train subjects:  19%|█▉        | 54/285 [01:44<07:37,  1.98s/it]predicting train subjects:  19%|█▉        | 55/285 [01:45<07:14,  1.89s/it]predicting train subjects:  20%|█▉        | 56/285 [01:47<07:17,  1.91s/it]predicting train subjects:  20%|██        | 57/285 [01:49<07:00,  1.85s/it]predicting train subjects:  20%|██        | 58/285 [01:51<07:01,  1.85s/it]predicting train subjects:  21%|██        | 59/285 [01:53<07:21,  1.95s/it]predicting train subjects:  21%|██        | 60/285 [01:55<07:36,  2.03s/it]predicting train subjects:  21%|██▏       | 61/285 [01:57<07:12,  1.93s/it]predicting train subjects:  22%|██▏       | 62/285 [01:59<07:06,  1.91s/it]predicting train subjects:  22%|██▏       | 63/285 [02:01<07:04,  1.91s/it]predicting train subjects:  22%|██▏       | 64/285 [02:03<07:02,  1.91s/it]predicting train subjects:  23%|██▎       | 65/285 [02:05<07:00,  1.91s/it]predicting train subjects:  23%|██▎       | 66/285 [02:06<06:53,  1.89s/it]predicting train subjects:  24%|██▎       | 67/285 [02:08<06:48,  1.87s/it]predicting train subjects:  24%|██▍       | 68/285 [02:10<06:35,  1.82s/it]predicting train subjects:  24%|██▍       | 69/285 [02:12<06:32,  1.82s/it]predicting train subjects:  25%|██▍       | 70/285 [02:14<06:47,  1.89s/it]predicting train subjects:  25%|██▍       | 71/285 [02:16<06:43,  1.88s/it]predicting train subjects:  25%|██▌       | 72/285 [02:18<06:35,  1.86s/it]predicting train subjects:  26%|██▌       | 73/285 [02:19<06:32,  1.85s/it]predicting train subjects:  26%|██▌       | 74/285 [02:21<06:26,  1.83s/it]predicting train subjects:  26%|██▋       | 75/285 [02:23<06:28,  1.85s/it]predicting train subjects:  27%|██▋       | 76/285 [02:25<06:25,  1.84s/it]predicting train subjects:  27%|██▋       | 77/285 [02:27<06:19,  1.82s/it]predicting train subjects:  27%|██▋       | 78/285 [02:28<06:10,  1.79s/it]predicting train subjects:  28%|██▊       | 79/285 [02:30<06:09,  1.79s/it]predicting train subjects:  28%|██▊       | 80/285 [02:32<06:08,  1.80s/it]predicting train subjects:  28%|██▊       | 81/285 [02:34<06:03,  1.78s/it]predicting train subjects:  29%|██▉       | 82/285 [02:36<06:07,  1.81s/it]predicting train subjects:  29%|██▉       | 83/285 [02:37<06:07,  1.82s/it]predicting train subjects:  29%|██▉       | 84/285 [02:39<05:59,  1.79s/it]predicting train subjects:  30%|██▉       | 85/285 [02:41<06:00,  1.80s/it]predicting train subjects:  30%|███       | 86/285 [02:43<06:05,  1.84s/it]predicting train subjects:  31%|███       | 87/285 [02:45<06:03,  1.84s/it]predicting train subjects:  31%|███       | 88/285 [02:46<05:55,  1.80s/it]predicting train subjects:  31%|███       | 89/285 [02:48<05:58,  1.83s/it]predicting train subjects:  32%|███▏      | 90/285 [02:50<05:59,  1.85s/it]predicting train subjects:  32%|███▏      | 91/285 [02:52<05:51,  1.81s/it]predicting train subjects:  32%|███▏      | 92/285 [02:54<05:59,  1.86s/it]predicting train subjects:  33%|███▎      | 93/285 [02:56<05:51,  1.83s/it]predicting train subjects:  33%|███▎      | 94/285 [02:58<05:58,  1.88s/it]predicting train subjects:  33%|███▎      | 95/285 [03:00<05:56,  1.88s/it]predicting train subjects:  34%|███▎      | 96/285 [03:01<05:54,  1.88s/it]predicting train subjects:  34%|███▍      | 97/285 [03:03<05:53,  1.88s/it]predicting train subjects:  34%|███▍      | 98/285 [03:05<05:51,  1.88s/it]predicting train subjects:  35%|███▍      | 99/285 [03:07<05:50,  1.89s/it]predicting train subjects:  35%|███▌      | 100/285 [03:09<05:51,  1.90s/it]predicting train subjects:  35%|███▌      | 101/285 [03:11<05:44,  1.87s/it]predicting train subjects:  36%|███▌      | 102/285 [03:13<05:45,  1.89s/it]predicting train subjects:  36%|███▌      | 103/285 [03:15<05:36,  1.85s/it]predicting train subjects:  36%|███▋      | 104/285 [03:16<05:36,  1.86s/it]predicting train subjects:  37%|███▋      | 105/285 [03:18<05:37,  1.88s/it]predicting train subjects:  37%|███▋      | 106/285 [03:20<05:30,  1.85s/it]predicting train subjects:  38%|███▊      | 107/285 [03:22<05:34,  1.88s/it]predicting train subjects:  38%|███▊      | 108/285 [03:24<05:28,  1.86s/it]predicting train subjects:  38%|███▊      | 109/285 [03:26<05:28,  1.87s/it]predicting train subjects:  39%|███▊      | 110/285 [03:28<05:27,  1.87s/it]predicting train subjects:  39%|███▉      | 111/285 [03:29<05:21,  1.85s/it]predicting train subjects:  39%|███▉      | 112/285 [03:31<05:23,  1.87s/it]predicting train subjects:  40%|███▉      | 113/285 [03:33<05:21,  1.87s/it]predicting train subjects:  40%|████      | 114/285 [03:35<05:19,  1.87s/it]predicting train subjects:  40%|████      | 115/285 [03:37<05:15,  1.86s/it]predicting train subjects:  41%|████      | 116/285 [03:39<05:14,  1.86s/it]predicting train subjects:  41%|████      | 117/285 [03:41<05:09,  1.84s/it]predicting train subjects:  41%|████▏     | 118/285 [03:42<05:01,  1.81s/it]predicting train subjects:  42%|████▏     | 119/285 [03:44<05:03,  1.83s/it]predicting train subjects:  42%|████▏     | 120/285 [03:46<04:59,  1.81s/it]predicting train subjects:  42%|████▏     | 121/285 [03:48<04:52,  1.78s/it]predicting train subjects:  43%|████▎     | 122/285 [03:49<04:41,  1.72s/it]predicting train subjects:  43%|████▎     | 123/285 [03:51<04:32,  1.68s/it]predicting train subjects:  44%|████▎     | 124/285 [03:52<04:30,  1.68s/it]predicting train subjects:  44%|████▍     | 125/285 [03:54<04:25,  1.66s/it]predicting train subjects:  44%|████▍     | 126/285 [03:56<04:23,  1.66s/it]predicting train subjects:  45%|████▍     | 127/285 [03:57<04:13,  1.61s/it]predicting train subjects:  45%|████▍     | 128/285 [03:59<04:16,  1.64s/it]predicting train subjects:  45%|████▌     | 129/285 [04:00<04:10,  1.61s/it]predicting train subjects:  46%|████▌     | 130/285 [04:02<04:09,  1.61s/it]predicting train subjects:  46%|████▌     | 131/285 [04:04<04:02,  1.58s/it]predicting train subjects:  46%|████▋     | 132/285 [04:05<04:06,  1.61s/it]predicting train subjects:  47%|████▋     | 133/285 [04:07<04:03,  1.60s/it]predicting train subjects:  47%|████▋     | 134/285 [04:08<03:58,  1.58s/it]predicting train subjects:  47%|████▋     | 135/285 [04:10<03:52,  1.55s/it]predicting train subjects:  48%|████▊     | 136/285 [04:11<03:51,  1.55s/it]predicting train subjects:  48%|████▊     | 137/285 [04:13<03:59,  1.62s/it]predicting train subjects:  48%|████▊     | 138/285 [04:15<03:55,  1.60s/it]predicting train subjects:  49%|████▉     | 139/285 [04:16<03:58,  1.63s/it]predicting train subjects:  49%|████▉     | 140/285 [04:18<03:57,  1.64s/it]predicting train subjects:  49%|████▉     | 141/285 [04:20<03:50,  1.60s/it]predicting train subjects:  50%|████▉     | 142/285 [04:21<03:49,  1.60s/it]predicting train subjects:  50%|█████     | 143/285 [04:23<03:43,  1.57s/it]predicting train subjects:  51%|█████     | 144/285 [04:25<03:51,  1.64s/it]predicting train subjects:  51%|█████     | 145/285 [04:26<03:49,  1.64s/it]predicting train subjects:  51%|█████     | 146/285 [04:28<03:52,  1.67s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:30<03:48,  1.65s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:31<03:50,  1.68s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:33<03:45,  1.66s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:34<03:37,  1.61s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:36<03:38,  1.63s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:38<03:34,  1.61s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:39<03:29,  1.59s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:41<03:31,  1.61s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:42<03:28,  1.60s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:44<03:30,  1.63s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:46<03:23,  1.59s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:47<03:21,  1.59s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:49<03:16,  1.56s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:50<03:16,  1.57s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:52<03:17,  1.60s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:54<03:17,  1.60s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:55<03:19,  1.63s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:57<03:14,  1.61s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:58<03:12,  1.61s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:00<03:11,  1.61s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:02<03:12,  1.63s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:03<03:09,  1.62s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:05<03:09,  1.63s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:07<03:08,  1.64s/it]predicting train subjects:  60%|██████    | 171/285 [05:08<03:03,  1.61s/it]predicting train subjects:  60%|██████    | 172/285 [05:10<03:01,  1.61s/it]predicting train subjects:  61%|██████    | 173/285 [05:11<02:56,  1.58s/it]predicting train subjects:  61%|██████    | 174/285 [05:13<02:53,  1.56s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:14<02:55,  1.60s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:16<02:58,  1.64s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:18<02:56,  1.63s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:19<02:49,  1.58s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:21<02:45,  1.57s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:23<02:55,  1.67s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:24<02:55,  1.68s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:26<02:55,  1.71s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:28<02:48,  1.66s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:29<02:44,  1.63s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:31<02:40,  1.61s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:33<02:50,  1.73s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:35<02:55,  1.79s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:37<02:55,  1.81s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:38<02:45,  1.72s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:40<02:38,  1.67s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:41<02:38,  1.69s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:43<02:38,  1.70s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:45<02:30,  1.64s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:46<02:28,  1.63s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:48<02:23,  1.59s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:50<02:32,  1.72s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:52<02:36,  1.78s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:54<02:37,  1.82s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:55<02:27,  1.71s/it]predicting train subjects:  70%|███████   | 200/285 [05:57<02:20,  1.65s/it]predicting train subjects:  71%|███████   | 201/285 [05:59<02:24,  1.73s/it]predicting train subjects:  71%|███████   | 202/285 [06:00<02:22,  1.72s/it]predicting train subjects:  71%|███████   | 203/285 [06:02<02:24,  1.76s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:04<02:18,  1.71s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:05<02:11,  1.64s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:07<02:05,  1.59s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:09<02:11,  1.68s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:10<02:15,  1.76s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:12<02:18,  1.82s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:14<02:07,  1.70s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:15<02:01,  1.65s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:17<02:02,  1.68s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:19<02:03,  1.71s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:20<01:57,  1.65s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:22<02:01,  1.74s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:24<01:54,  1.66s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:26<01:59,  1.75s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:28<02:00,  1.81s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:30<02:01,  1.85s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:31<01:53,  1.75s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:33<01:48,  1.69s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:35<01:48,  1.72s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:36<01:44,  1.69s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:38<01:41,  1.67s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:39<01:36,  1.61s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:41<01:41,  1.71s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:43<01:42,  1.77s/it]predicting train subjects:  80%|████████  | 228/285 [06:45<01:41,  1.78s/it]predicting train subjects:  80%|████████  | 229/285 [06:47<01:38,  1.77s/it]predicting train subjects:  81%|████████  | 230/285 [06:48<01:31,  1.67s/it]predicting train subjects:  81%|████████  | 231/285 [06:50<01:27,  1.62s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:51<01:27,  1.65s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:53<01:23,  1.60s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:55<01:25,  1.68s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:56<01:20,  1.60s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:58<01:22,  1.68s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:00<01:22,  1.73s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:02<01:23,  1.77s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:03<01:20,  1.76s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:05<01:14,  1.66s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:06<01:10,  1.61s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:08<01:06,  1.55s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:09<01:04,  1.53s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:11<01:06,  1.62s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:12<01:02,  1.57s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:14<01:04,  1.67s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:16<01:05,  1.72s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:18<01:03,  1.72s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:19<00:58,  1.64s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:21<00:55,  1.59s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:22<00:52,  1.55s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:24<00:50,  1.53s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:26<00:52,  1.65s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:28<00:52,  1.71s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:29<00:51,  1.72s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:31<00:48,  1.67s/it]predicting train subjects:  90%|█████████ | 257/285 [07:32<00:45,  1.63s/it]predicting train subjects:  91%|█████████ | 258/285 [07:34<00:45,  1.70s/it]predicting train subjects:  91%|█████████ | 259/285 [07:36<00:43,  1.69s/it]predicting train subjects:  91%|█████████ | 260/285 [07:37<00:40,  1.61s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:39<00:37,  1.56s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:40<00:35,  1.54s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:42<00:33,  1.51s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:44<00:34,  1.64s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:46<00:34,  1.72s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:47<00:31,  1.65s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:49<00:28,  1.60s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:50<00:28,  1.67s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:52<00:26,  1.68s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:54<00:24,  1.61s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:55<00:21,  1.57s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:57<00:21,  1.64s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:58<00:18,  1.57s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:00<00:17,  1.56s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:02<00:16,  1.67s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:03<00:15,  1.71s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:05<00:12,  1.61s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:06<00:11,  1.58s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:08<00:09,  1.64s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:10<00:08,  1.60s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:11<00:06,  1.56s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:13<00:04,  1.52s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:15<00:03,  1.66s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:16<00:01,  1.74s/it]predicting train subjects: 100%|██████████| 285/285 [08:18<00:00,  1.78s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:22,  1.56s/it]Loading train:   1%|          | 2/285 [00:02<06:46,  1.44s/it]Loading train:   1%|          | 3/285 [00:04<06:36,  1.41s/it]Loading train:   1%|▏         | 4/285 [00:05<06:00,  1.28s/it]Loading train:   2%|▏         | 5/285 [00:06<06:20,  1.36s/it]Loading train:   2%|▏         | 6/285 [00:07<06:04,  1.31s/it]Loading train:   2%|▏         | 7/285 [00:09<06:20,  1.37s/it]Loading train:   3%|▎         | 8/285 [00:10<06:05,  1.32s/it]Loading train:   3%|▎         | 9/285 [00:12<06:29,  1.41s/it]Loading train:   4%|▎         | 10/285 [00:13<05:50,  1.27s/it]Loading train:   4%|▍         | 11/285 [00:13<05:06,  1.12s/it]Loading train:   4%|▍         | 12/285 [00:14<04:57,  1.09s/it]Loading train:   5%|▍         | 13/285 [00:15<04:39,  1.03s/it]Loading train:   5%|▍         | 14/285 [00:16<04:31,  1.00s/it]Loading train:   5%|▌         | 15/285 [00:17<04:35,  1.02s/it]Loading train:   6%|▌         | 16/285 [00:18<04:32,  1.01s/it]Loading train:   6%|▌         | 17/285 [00:19<04:26,  1.00it/s]Loading train:   6%|▋         | 18/285 [00:20<04:25,  1.01it/s]Loading train:   7%|▋         | 19/285 [00:21<04:13,  1.05it/s]Loading train:   7%|▋         | 20/285 [00:22<04:09,  1.06it/s]Loading train:   7%|▋         | 21/285 [00:23<04:09,  1.06it/s]Loading train:   8%|▊         | 22/285 [00:24<04:01,  1.09it/s]Loading train:   8%|▊         | 23/285 [00:25<04:20,  1.01it/s]Loading train:   8%|▊         | 24/285 [00:26<04:05,  1.06it/s]Loading train:   9%|▉         | 25/285 [00:27<04:10,  1.04it/s]Loading train:   9%|▉         | 26/285 [00:28<04:33,  1.05s/it]Loading train:   9%|▉         | 27/285 [00:29<04:22,  1.02s/it]Loading train:  10%|▉         | 28/285 [00:30<04:39,  1.09s/it]Loading train:  10%|█         | 29/285 [00:31<04:46,  1.12s/it]Loading train:  11%|█         | 30/285 [00:33<04:50,  1.14s/it]Loading train:  11%|█         | 31/285 [00:34<04:57,  1.17s/it]Loading train:  11%|█         | 32/285 [00:35<04:46,  1.13s/it]Loading train:  12%|█▏        | 33/285 [00:36<04:57,  1.18s/it]Loading train:  12%|█▏        | 34/285 [00:37<04:48,  1.15s/it]Loading train:  12%|█▏        | 35/285 [00:39<05:05,  1.22s/it]Loading train:  13%|█▎        | 36/285 [00:40<04:51,  1.17s/it]Loading train:  13%|█▎        | 37/285 [00:41<04:57,  1.20s/it]Loading train:  13%|█▎        | 38/285 [00:42<05:09,  1.25s/it]Loading train:  14%|█▎        | 39/285 [00:44<05:12,  1.27s/it]Loading train:  14%|█▍        | 40/285 [00:45<05:18,  1.30s/it]Loading train:  14%|█▍        | 41/285 [00:46<05:03,  1.24s/it]Loading train:  15%|█▍        | 42/285 [00:47<04:30,  1.11s/it]Loading train:  15%|█▌        | 43/285 [00:48<04:34,  1.13s/it]Loading train:  15%|█▌        | 44/285 [00:50<04:52,  1.21s/it]Loading train:  16%|█▌        | 45/285 [00:51<04:54,  1.23s/it]Loading train:  16%|█▌        | 46/285 [00:52<05:02,  1.26s/it]Loading train:  16%|█▋        | 47/285 [00:53<04:50,  1.22s/it]Loading train:  17%|█▋        | 48/285 [00:55<04:58,  1.26s/it]Loading train:  17%|█▋        | 49/285 [00:56<04:48,  1.22s/it]Loading train:  18%|█▊        | 50/285 [00:57<04:43,  1.21s/it]Loading train:  18%|█▊        | 51/285 [00:58<04:39,  1.20s/it]Loading train:  18%|█▊        | 52/285 [00:59<04:28,  1.15s/it]Loading train:  19%|█▊        | 53/285 [01:00<04:29,  1.16s/it]Loading train:  19%|█▉        | 54/285 [01:02<04:44,  1.23s/it]Loading train:  19%|█▉        | 55/285 [01:03<04:34,  1.19s/it]Loading train:  20%|█▉        | 56/285 [01:04<04:39,  1.22s/it]Loading train:  20%|██        | 57/285 [01:05<04:26,  1.17s/it]Loading train:  20%|██        | 58/285 [01:06<04:30,  1.19s/it]Loading train:  21%|██        | 59/285 [01:08<04:39,  1.24s/it]Loading train:  21%|██        | 60/285 [01:09<04:35,  1.23s/it]Loading train:  21%|██▏       | 61/285 [01:10<04:37,  1.24s/it]Loading train:  22%|██▏       | 62/285 [01:11<04:38,  1.25s/it]Loading train:  22%|██▏       | 63/285 [01:13<04:46,  1.29s/it]Loading train:  22%|██▏       | 64/285 [01:14<05:04,  1.38s/it]Loading train:  23%|██▎       | 65/285 [01:16<05:25,  1.48s/it]Loading train:  23%|██▎       | 66/285 [01:18<05:32,  1.52s/it]Loading train:  24%|██▎       | 67/285 [01:19<05:17,  1.45s/it]Loading train:  24%|██▍       | 68/285 [01:20<05:02,  1.40s/it]Loading train:  24%|██▍       | 69/285 [01:22<04:55,  1.37s/it]Loading train:  25%|██▍       | 70/285 [01:23<04:39,  1.30s/it]Loading train:  25%|██▍       | 71/285 [01:24<04:33,  1.28s/it]Loading train:  25%|██▌       | 72/285 [01:25<04:20,  1.22s/it]Loading train:  26%|██▌       | 73/285 [01:26<04:30,  1.28s/it]Loading train:  26%|██▌       | 74/285 [01:28<04:18,  1.23s/it]Loading train:  26%|██▋       | 75/285 [01:29<04:11,  1.20s/it]Loading train:  27%|██▋       | 76/285 [01:30<04:15,  1.22s/it]Loading train:  27%|██▋       | 77/285 [01:31<04:11,  1.21s/it]Loading train:  27%|██▋       | 78/285 [01:32<04:08,  1.20s/it]Loading train:  28%|██▊       | 79/285 [01:34<04:03,  1.18s/it]Loading train:  28%|██▊       | 80/285 [01:35<04:06,  1.20s/it]Loading train:  28%|██▊       | 81/285 [01:36<03:50,  1.13s/it]Loading train:  29%|██▉       | 82/285 [01:37<03:45,  1.11s/it]Loading train:  29%|██▉       | 83/285 [01:38<03:29,  1.04s/it]Loading train:  29%|██▉       | 84/285 [01:39<03:31,  1.05s/it]Loading train:  30%|██▉       | 85/285 [01:40<03:39,  1.10s/it]Loading train:  30%|███       | 86/285 [01:41<03:39,  1.10s/it]Loading train:  31%|███       | 87/285 [01:42<03:35,  1.09s/it]Loading train:  31%|███       | 88/285 [01:43<03:30,  1.07s/it]Loading train:  31%|███       | 89/285 [01:44<03:37,  1.11s/it]Loading train:  32%|███▏      | 90/285 [01:46<03:53,  1.20s/it]Loading train:  32%|███▏      | 91/285 [01:47<03:45,  1.16s/it]Loading train:  32%|███▏      | 92/285 [01:48<03:46,  1.17s/it]Loading train:  33%|███▎      | 93/285 [01:49<03:44,  1.17s/it]Loading train:  33%|███▎      | 94/285 [01:50<03:49,  1.20s/it]Loading train:  33%|███▎      | 95/285 [01:52<03:44,  1.18s/it]Loading train:  34%|███▎      | 96/285 [01:53<03:37,  1.15s/it]Loading train:  34%|███▍      | 97/285 [01:54<03:29,  1.12s/it]Loading train:  34%|███▍      | 98/285 [01:55<03:25,  1.10s/it]Loading train:  35%|███▍      | 99/285 [01:56<03:24,  1.10s/it]Loading train:  35%|███▌      | 100/285 [01:57<03:24,  1.11s/it]Loading train:  35%|███▌      | 101/285 [01:58<03:28,  1.13s/it]Loading train:  36%|███▌      | 102/285 [01:59<03:23,  1.11s/it]Loading train:  36%|███▌      | 103/285 [02:01<03:33,  1.17s/it]Loading train:  36%|███▋      | 104/285 [02:02<03:28,  1.15s/it]Loading train:  37%|███▋      | 105/285 [02:03<03:27,  1.15s/it]Loading train:  37%|███▋      | 106/285 [02:04<03:24,  1.15s/it]Loading train:  38%|███▊      | 107/285 [02:05<03:29,  1.18s/it]Loading train:  38%|███▊      | 108/285 [02:06<03:18,  1.12s/it]Loading train:  38%|███▊      | 109/285 [02:07<03:19,  1.13s/it]Loading train:  39%|███▊      | 110/285 [02:08<03:17,  1.13s/it]Loading train:  39%|███▉      | 111/285 [02:09<03:07,  1.08s/it]Loading train:  39%|███▉      | 112/285 [02:11<03:15,  1.13s/it]Loading train:  40%|███▉      | 113/285 [02:12<03:06,  1.09s/it]Loading train:  40%|████      | 114/285 [02:13<03:10,  1.11s/it]Loading train:  40%|████      | 115/285 [02:14<03:13,  1.14s/it]Loading train:  41%|████      | 116/285 [02:15<03:12,  1.14s/it]Loading train:  41%|████      | 117/285 [02:16<03:17,  1.17s/it]Loading train:  41%|████▏     | 118/285 [02:17<03:04,  1.11s/it]Loading train:  42%|████▏     | 119/285 [02:19<03:09,  1.14s/it]Loading train:  42%|████▏     | 120/285 [02:20<03:03,  1.11s/it]Loading train:  42%|████▏     | 121/285 [02:21<03:23,  1.24s/it]Loading train:  43%|████▎     | 122/285 [02:23<03:34,  1.32s/it]Loading train:  43%|████▎     | 123/285 [02:24<03:33,  1.32s/it]Loading train:  44%|████▎     | 124/285 [02:25<03:27,  1.29s/it]Loading train:  44%|████▍     | 125/285 [02:26<03:18,  1.24s/it]Loading train:  44%|████▍     | 126/285 [02:28<03:15,  1.23s/it]Loading train:  45%|████▍     | 127/285 [02:29<03:09,  1.20s/it]Loading train:  45%|████▍     | 128/285 [02:30<03:05,  1.18s/it]Loading train:  45%|████▌     | 129/285 [02:31<03:00,  1.16s/it]Loading train:  46%|████▌     | 130/285 [02:32<02:57,  1.14s/it]Loading train:  46%|████▌     | 131/285 [02:33<03:00,  1.17s/it]Loading train:  46%|████▋     | 132/285 [02:35<03:08,  1.24s/it]Loading train:  47%|████▋     | 133/285 [02:36<02:58,  1.17s/it]Loading train:  47%|████▋     | 134/285 [02:37<02:49,  1.13s/it]Loading train:  47%|████▋     | 135/285 [02:38<02:49,  1.13s/it]Loading train:  48%|████▊     | 136/285 [02:39<02:47,  1.12s/it]Loading train:  48%|████▊     | 137/285 [02:40<02:45,  1.12s/it]Loading train:  48%|████▊     | 138/285 [02:41<02:37,  1.07s/it]Loading train:  49%|████▉     | 139/285 [02:42<02:47,  1.15s/it]Loading train:  49%|████▉     | 140/285 [02:43<02:46,  1.15s/it]Loading train:  49%|████▉     | 141/285 [02:45<02:41,  1.12s/it]Loading train:  50%|████▉     | 142/285 [02:46<02:40,  1.12s/it]Loading train:  50%|█████     | 143/285 [02:47<02:35,  1.10s/it]Loading train:  51%|█████     | 144/285 [02:48<02:35,  1.10s/it]Loading train:  51%|█████     | 145/285 [02:49<02:33,  1.10s/it]Loading train:  51%|█████     | 146/285 [02:50<02:31,  1.09s/it]Loading train:  52%|█████▏    | 147/285 [02:51<02:28,  1.07s/it]Loading train:  52%|█████▏    | 148/285 [02:52<02:27,  1.08s/it]Loading train:  52%|█████▏    | 149/285 [02:53<02:24,  1.06s/it]Loading train:  53%|█████▎    | 150/285 [02:54<02:22,  1.06s/it]Loading train:  53%|█████▎    | 151/285 [02:55<02:24,  1.08s/it]Loading train:  53%|█████▎    | 152/285 [02:56<02:25,  1.10s/it]Loading train:  54%|█████▎    | 153/285 [02:57<02:20,  1.06s/it]Loading train:  54%|█████▍    | 154/285 [02:59<02:24,  1.11s/it]Loading train:  54%|█████▍    | 155/285 [03:00<02:32,  1.17s/it]Loading train:  55%|█████▍    | 156/285 [03:01<02:31,  1.18s/it]Loading train:  55%|█████▌    | 157/285 [03:02<02:19,  1.09s/it]Loading train:  55%|█████▌    | 158/285 [03:03<02:14,  1.06s/it]Loading train:  56%|█████▌    | 159/285 [03:04<02:09,  1.03s/it]Loading train:  56%|█████▌    | 160/285 [03:05<02:07,  1.02s/it]Loading train:  56%|█████▋    | 161/285 [03:06<02:00,  1.03it/s]Loading train:  57%|█████▋    | 162/285 [03:07<01:51,  1.10it/s]Loading train:  57%|█████▋    | 163/285 [03:08<01:54,  1.06it/s]Loading train:  58%|█████▊    | 164/285 [03:09<01:57,  1.03it/s]Loading train:  58%|█████▊    | 165/285 [03:10<02:02,  1.02s/it]Loading train:  58%|█████▊    | 166/285 [03:11<02:07,  1.07s/it]Loading train:  59%|█████▊    | 167/285 [03:12<02:01,  1.03s/it]Loading train:  59%|█████▉    | 168/285 [03:13<01:56,  1.01it/s]Loading train:  59%|█████▉    | 169/285 [03:14<01:58,  1.02s/it]Loading train:  60%|█████▉    | 170/285 [03:15<01:54,  1.00it/s]Loading train:  60%|██████    | 171/285 [03:16<02:01,  1.06s/it]Loading train:  60%|██████    | 172/285 [03:17<01:58,  1.05s/it]Loading train:  61%|██████    | 173/285 [03:18<01:56,  1.04s/it]Loading train:  61%|██████    | 174/285 [03:19<01:52,  1.01s/it]Loading train:  61%|██████▏   | 175/285 [03:20<01:54,  1.04s/it]Loading train:  62%|██████▏   | 176/285 [03:21<01:51,  1.02s/it]Loading train:  62%|██████▏   | 177/285 [03:22<01:50,  1.03s/it]Loading train:  62%|██████▏   | 178/285 [03:23<01:48,  1.01s/it]Loading train:  63%|██████▎   | 179/285 [03:24<01:49,  1.03s/it]Loading train:  63%|██████▎   | 180/285 [03:26<01:56,  1.11s/it]Loading train:  64%|██████▎   | 181/285 [03:27<02:08,  1.23s/it]Loading train:  64%|██████▍   | 182/285 [03:28<02:03,  1.20s/it]Loading train:  64%|██████▍   | 183/285 [03:29<02:01,  1.19s/it]Loading train:  65%|██████▍   | 184/285 [03:31<01:59,  1.19s/it]Loading train:  65%|██████▍   | 185/285 [03:32<01:58,  1.19s/it]Loading train:  65%|██████▌   | 186/285 [03:33<02:10,  1.31s/it]Loading train:  66%|██████▌   | 187/285 [03:35<02:09,  1.32s/it]Loading train:  66%|██████▌   | 188/285 [03:36<02:10,  1.35s/it]Loading train:  66%|██████▋   | 189/285 [03:37<02:00,  1.26s/it]Loading train:  67%|██████▋   | 190/285 [03:38<01:56,  1.23s/it]Loading train:  67%|██████▋   | 191/285 [03:39<01:54,  1.21s/it]Loading train:  67%|██████▋   | 192/285 [03:41<01:50,  1.18s/it]Loading train:  68%|██████▊   | 193/285 [03:42<01:44,  1.13s/it]Loading train:  68%|██████▊   | 194/285 [03:42<01:35,  1.05s/it]Loading train:  68%|██████▊   | 195/285 [03:43<01:31,  1.01s/it]Loading train:  69%|██████▉   | 196/285 [03:45<01:39,  1.12s/it]Loading train:  69%|██████▉   | 197/285 [03:46<01:40,  1.14s/it]Loading train:  69%|██████▉   | 198/285 [03:47<01:44,  1.20s/it]Loading train:  70%|██████▉   | 199/285 [03:48<01:37,  1.14s/it]Loading train:  70%|███████   | 200/285 [03:49<01:34,  1.11s/it]Loading train:  71%|███████   | 201/285 [03:50<01:35,  1.13s/it]Loading train:  71%|███████   | 202/285 [03:52<01:38,  1.19s/it]Loading train:  71%|███████   | 203/285 [03:53<01:35,  1.16s/it]Loading train:  72%|███████▏  | 204/285 [03:54<01:32,  1.14s/it]Loading train:  72%|███████▏  | 205/285 [03:55<01:28,  1.10s/it]Loading train:  72%|███████▏  | 206/285 [03:56<01:27,  1.11s/it]Loading train:  73%|███████▎  | 207/285 [03:57<01:31,  1.17s/it]Loading train:  73%|███████▎  | 208/285 [03:59<01:31,  1.18s/it]Loading train:  73%|███████▎  | 209/285 [04:00<01:31,  1.21s/it]Loading train:  74%|███████▎  | 210/285 [04:01<01:24,  1.12s/it]Loading train:  74%|███████▍  | 211/285 [04:02<01:18,  1.06s/it]Loading train:  74%|███████▍  | 212/285 [04:03<01:18,  1.08s/it]Loading train:  75%|███████▍  | 213/285 [04:04<01:16,  1.07s/it]Loading train:  75%|███████▌  | 214/285 [04:05<01:14,  1.04s/it]Loading train:  75%|███████▌  | 215/285 [04:06<01:16,  1.09s/it]Loading train:  76%|███████▌  | 216/285 [04:07<01:17,  1.12s/it]Loading train:  76%|███████▌  | 217/285 [04:09<01:19,  1.17s/it]Loading train:  76%|███████▋  | 218/285 [04:10<01:21,  1.22s/it]Loading train:  77%|███████▋  | 219/285 [04:11<01:25,  1.29s/it]Loading train:  77%|███████▋  | 220/285 [04:12<01:19,  1.23s/it]Loading train:  78%|███████▊  | 221/285 [04:13<01:14,  1.16s/it]Loading train:  78%|███████▊  | 222/285 [04:15<01:13,  1.16s/it]Loading train:  78%|███████▊  | 223/285 [04:16<01:12,  1.17s/it]Loading train:  79%|███████▊  | 224/285 [04:17<01:06,  1.09s/it]Loading train:  79%|███████▉  | 225/285 [04:18<01:01,  1.02s/it]Loading train:  79%|███████▉  | 226/285 [04:19<01:04,  1.09s/it]Loading train:  80%|███████▉  | 227/285 [04:20<01:04,  1.11s/it]Loading train:  80%|████████  | 228/285 [04:21<01:04,  1.13s/it]Loading train:  80%|████████  | 229/285 [04:23<01:06,  1.19s/it]Loading train:  81%|████████  | 230/285 [04:24<01:03,  1.16s/it]Loading train:  81%|████████  | 231/285 [04:25<01:03,  1.17s/it]Loading train:  81%|████████▏ | 232/285 [04:26<00:59,  1.13s/it]Loading train:  82%|████████▏ | 233/285 [04:27<00:59,  1.15s/it]Loading train:  82%|████████▏ | 234/285 [04:28<00:57,  1.13s/it]Loading train:  82%|████████▏ | 235/285 [04:30<01:01,  1.22s/it]Loading train:  83%|████████▎ | 236/285 [04:31<00:59,  1.21s/it]Loading train:  83%|████████▎ | 237/285 [04:32<00:56,  1.19s/it]Loading train:  84%|████████▎ | 238/285 [04:33<00:55,  1.18s/it]Loading train:  84%|████████▍ | 239/285 [04:34<00:54,  1.18s/it]Loading train:  84%|████████▍ | 240/285 [04:35<00:50,  1.12s/it]Loading train:  85%|████████▍ | 241/285 [04:36<00:48,  1.10s/it]Loading train:  85%|████████▍ | 242/285 [04:37<00:48,  1.12s/it]Loading train:  85%|████████▌ | 243/285 [04:38<00:46,  1.10s/it]Loading train:  86%|████████▌ | 244/285 [04:40<00:47,  1.15s/it]Loading train:  86%|████████▌ | 245/285 [04:41<00:45,  1.13s/it]Loading train:  86%|████████▋ | 246/285 [04:42<00:43,  1.13s/it]Loading train:  87%|████████▋ | 247/285 [04:43<00:44,  1.18s/it]Loading train:  87%|████████▋ | 248/285 [04:44<00:42,  1.14s/it]Loading train:  87%|████████▋ | 249/285 [04:45<00:38,  1.07s/it]Loading train:  88%|████████▊ | 250/285 [04:46<00:36,  1.03s/it]Loading train:  88%|████████▊ | 251/285 [04:47<00:35,  1.03s/it]Loading train:  88%|████████▊ | 252/285 [04:48<00:33,  1.00s/it]Loading train:  89%|████████▉ | 253/285 [04:49<00:34,  1.07s/it]Loading train:  89%|████████▉ | 254/285 [04:51<00:34,  1.11s/it]Loading train:  89%|████████▉ | 255/285 [04:52<00:32,  1.08s/it]Loading train:  90%|████████▉ | 256/285 [04:53<00:30,  1.07s/it]Loading train:  90%|█████████ | 257/285 [04:53<00:28,  1.02s/it]Loading train:  91%|█████████ | 258/285 [04:55<00:28,  1.05s/it]Loading train:  91%|█████████ | 259/285 [04:55<00:25,  1.01it/s]Loading train:  91%|█████████ | 260/285 [04:56<00:23,  1.07it/s]Loading train:  92%|█████████▏| 261/285 [04:57<00:21,  1.11it/s]Loading train:  92%|█████████▏| 262/285 [04:58<00:19,  1.17it/s]Loading train:  92%|█████████▏| 263/285 [04:59<00:18,  1.17it/s]Loading train:  93%|█████████▎| 264/285 [05:00<00:19,  1.09it/s]Loading train:  93%|█████████▎| 265/285 [05:01<00:21,  1.07s/it]Loading train:  93%|█████████▎| 266/285 [05:02<00:19,  1.04s/it]Loading train:  94%|█████████▎| 267/285 [05:03<00:19,  1.06s/it]Loading train:  94%|█████████▍| 268/285 [05:05<00:19,  1.13s/it]Loading train:  94%|█████████▍| 269/285 [05:06<00:17,  1.09s/it]Loading train:  95%|█████████▍| 270/285 [05:07<00:16,  1.12s/it]Loading train:  95%|█████████▌| 271/285 [05:08<00:14,  1.03s/it]Loading train:  95%|█████████▌| 272/285 [05:09<00:14,  1.10s/it]Loading train:  96%|█████████▌| 273/285 [05:10<00:11,  1.01it/s]Loading train:  96%|█████████▌| 274/285 [05:10<00:10,  1.05it/s]Loading train:  96%|█████████▋| 275/285 [05:12<00:10,  1.02s/it]Loading train:  97%|█████████▋| 276/285 [05:13<00:09,  1.09s/it]Loading train:  97%|█████████▋| 277/285 [05:14<00:07,  1.00it/s]Loading train:  98%|█████████▊| 278/285 [05:15<00:06,  1.03it/s]Loading train:  98%|█████████▊| 279/285 [05:15<00:05,  1.04it/s]Loading train:  98%|█████████▊| 280/285 [05:16<00:04,  1.07it/s]Loading train:  99%|█████████▊| 281/285 [05:17<00:03,  1.09it/s]Loading train:  99%|█████████▉| 282/285 [05:18<00:02,  1.07it/s]Loading train:  99%|█████████▉| 283/285 [05:19<00:02,  1.01s/it]Loading train: 100%|█████████▉| 284/285 [05:20<00:01,  1.03s/it]Loading train: 100%|██████████| 285/285 [05:22<00:00,  1.06s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|▏         | 4/285 [00:00<00:08, 31.56it/s]concatenating: train:   8%|▊         | 22/285 [00:00<00:06, 41.83it/s]concatenating: train:  15%|█▌        | 43/285 [00:00<00:04, 53.68it/s]concatenating: train:  18%|█▊        | 52/285 [00:00<00:05, 43.66it/s]concatenating: train:  21%|██        | 60/285 [00:00<00:04, 46.62it/s]concatenating: train:  31%|███       | 87/285 [00:00<00:03, 61.89it/s]concatenating: train:  41%|████      | 116/285 [00:01<00:02, 80.91it/s]concatenating: train:  47%|████▋     | 134/285 [00:01<00:02, 75.48it/s]concatenating: train:  52%|█████▏    | 149/285 [00:01<00:02, 61.63it/s]concatenating: train:  56%|█████▋    | 161/285 [00:01<00:01, 66.81it/s]concatenating: train:  67%|██████▋   | 190/285 [00:01<00:01, 86.80it/s]concatenating: train:  78%|███████▊  | 222/285 [00:01<00:00, 110.95it/s]concatenating: train:  89%|████████▉ | 253/285 [00:02<00:00, 134.91it/s]concatenating: train:  97%|█████████▋| 276/285 [00:02<00:00, 86.16it/s] concatenating: train: 100%|██████████| 285/285 [00:02<00:00, 106.20it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.38s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.41s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.38s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 36.67it/s]2019-07-09 09:20:06.726305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-09 09:20:06.726426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-09 09:20:06.726444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-09 09:20:06.726458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-09 09:20:06.726903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12743 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:10,  3.99it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:08,  4.89it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:08,  4.89it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.27it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.46it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.35it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.45it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.07it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  7.63it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.37it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.05it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:02,  8.33it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  8.76it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  6.68it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.41it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.16it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  8.50it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  6.95it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.65it/s]
Epoch 00054: val_mDice did not improve from 0.61798
Restoring model weights from the end of the best epoch
Epoch 00054: early stopping
{'val_loss': [8513.17466829609, 4513.7430440380585, 3024.1281574611558, 2810.610014675716, 2329.40876778544, 2341.269593990049, 2296.799549635562, 2333.0484366816513, 2338.4312123559707, 2341.800973561889, 2879.133184848551, 2257.6776552679817, 2234.3263696425456, 2317.7054954827163, 2262.711989077776, 2208.556498777933, 2242.310684630325, 2235.7045434706706, 2296.913106396212, 2320.6558503731667, 2258.64389021037, 2336.9550399354052, 2319.950418994413, 2165.2512016083274, 2154.9623477871855, 2357.8674029984286, 2327.472082042161, 2192.093646342528, 2436.9612402889315, 2368.329503917161, 2220.571710511959, 2323.6088485291552, 2334.400867994937, 2287.0360646167946, 2259.3051416833973, 2202.2539949044167, 2268.8728736579087, 2337.812663669693, 2331.2610149703214, 2433.7182999083448, 2250.364125512832, 2365.020892436278, 2242.491135922224, 2187.0664744457054, 2221.487267861819, 2272.954218859113, 2351.005451564682, 2204.6665202732192, 2385.2206744828036, 2283.3845542183135, 2293.648498876135, 2392.889715269291, 2295.4481849031076, 2317.094614721543], 'val_acc': [0.9148540546774199, 0.917694887968415, 0.9325414959278853, 0.9381714633057238, 0.9458488865271627, 0.9450885793350262, 0.9488343336728698, 0.9468344190267212, 0.9483674012082915, 0.9493942220783766, 0.9387148189145094, 0.9472496815899897, 0.9485905187090016, 0.9510326052511204, 0.9467186964423963, 0.9491648790556625, 0.9479872511085852, 0.9513528466890644, 0.9509334497611616, 0.9488694721094056, 0.9484294030253447, 0.9502227129882941, 0.9503818164324628, 0.9524292669482737, 0.9499210738602963, 0.952503650215085, 0.9506792985527209, 0.9497351090335313, 0.9478963343790789, 0.950204120667953, 0.950507822649439, 0.9504355262111686, 0.951346653466784, 0.9511772107811614, 0.9509169346127431, 0.9487723724802113, 0.9464914598944467, 0.9481298300807036, 0.9488301923155119, 0.9501793457809107, 0.9464625000287701, 0.9486938411963053, 0.9492723289148768, 0.9509850753752213, 0.9503280873405201, 0.9497268669432102, 0.9490326889400376, 0.949082245706846, 0.9481897350796108, 0.9488611907266372, 0.9501235644910588, 0.9499603226864138, 0.9490987958188829, 0.947540988469257], 'val_mDice': [0.2713935909657505, 0.4150316781837847, 0.5192651322434069, 0.5361620594003347, 0.5937718499306194, 0.5917563035501449, 0.6010890373304569, 0.5938560353311081, 0.5985094065772755, 0.5956589070112346, 0.5342630995385473, 0.6036979163159205, 0.6071678992756252, 0.6001365198103409, 0.604333089050634, 0.6096075403623741, 0.6067697509041046, 0.6101482800265264, 0.6012576129183423, 0.5977623835622266, 0.6049081773065322, 0.5969526997491634, 0.5996476574983011, 0.6179811481656975, 0.6179661810731089, 0.5967981322517608, 0.5996436020515484, 0.6120398763837761, 0.585746912316903, 0.5941771821602763, 0.610738938081198, 0.5983162785375584, 0.6002209732652376, 0.6017587994064033, 0.6066795457674804, 0.6103331263504881, 0.6028274277735023, 0.5958417777242607, 0.5960839440702727, 0.5878087841598681, 0.6047120473904317, 0.5936036865804448, 0.6078291964930529, 0.6133350083947847, 0.6102930667014096, 0.603056775791019, 0.5947877884577106, 0.6109668495934769, 0.5914651491788513, 0.6023861382926643, 0.6042255016678538, 0.5918946013104316, 0.6006836391694053, 0.5978479725022555], 'loss': [10938.638023581318, 4116.06985363104, 3153.4535185024047, 2740.9082597423294, 2505.188967383419, 2341.8244157937297, 2223.362947170527, 2130.592003658559, 2056.596664735366, 1977.4971395550415, 1936.8142452444636, 1889.022557378432, 1841.7909797505156, 1802.3530201302926, 1767.0095386304638, 1744.2381072860094, 1711.5029276730506, 1688.3774391724053, 1653.5227927831281, 1648.0845670328702, 1620.6261197014264, 1594.3267785367295, 1582.85967621669, 1568.5501106843521, 1559.0629740138959, 1541.3685553210876, 1523.4932501918447, 1521.026870956076, 1507.1396707593274, 1496.4192958200401, 1480.579394747986, 1468.288472429222, 1458.7864585316756, 1454.9480037877233, 1431.7356427268885, 1432.1062906918771, 1439.7696303236778, 1418.8189699725513, 1413.118677660658, 1400.9435589318052, 1393.9137045629313, 1391.6599117536884, 1385.752953604931, 1382.686524029203, 1379.3799009093025, 1367.633650883241, 1361.2926192363877, 1348.2483706229407, 1345.8398909998073, 1349.5639755941284, 1344.4538483900947, 1339.0614624389098, 1331.1915594744698, 1321.680468508], 'acc': [0.7609400462861752, 0.898345281593317, 0.9096976512268304, 0.9247305812019453, 0.9347367146443544, 0.9380369770501565, 0.9399448645757009, 0.9415473627515637, 0.9426399904309999, 0.9437838391822432, 0.9445340822032708, 0.9452580359628612, 0.9459328010291175, 0.9465517786799494, 0.9471482348581017, 0.9475284503193295, 0.9480523190157624, 0.948401113090403, 0.9488926297808958, 0.9491361074669417, 0.9494294486698466, 0.9498535135162272, 0.9501293123427393, 0.9503282503224453, 0.9503542963446021, 0.9507068568121069, 0.9510106540156062, 0.9511461509227831, 0.9512938916030698, 0.9515316615787169, 0.9516511417559748, 0.9519769353522733, 0.9521531558499072, 0.9521790379065391, 0.9524502271492038, 0.9525468861847024, 0.9524766540002747, 0.9528062123241043, 0.9528989661565099, 0.9531471109209767, 0.9533068365497817, 0.9532786174301202, 0.9535373192805817, 0.9535860781751163, 0.953619856936604, 0.9536770977399219, 0.9537188550867707, 0.9539501412450718, 0.9540306892109868, 0.9539477453629933, 0.9540892602909001, 0.9541376207130783, 0.9542964802355257, 0.9544062715497101], 'mDice': [0.18764888753041314, 0.4412490796577982, 0.5311802838286389, 0.576629330237884, 0.603808537631193, 0.622989178239491, 0.6380267540267542, 0.6496004289930458, 0.6592064840030998, 0.6694567570706597, 0.6750577136125123, 0.6813505509470901, 0.6878380805674373, 0.6931640860282688, 0.6981754852213843, 0.7013861991975973, 0.7059475590243759, 0.7091330643553573, 0.7140223049960374, 0.715042175300552, 0.7187813866288436, 0.7224907941090035, 0.7242186105846677, 0.7262757735654657, 0.7276271918254846, 0.7302524304962594, 0.73292112561471, 0.7333880071773501, 0.7353172635312732, 0.73692427992165, 0.7393002255920829, 0.7411776652302879, 0.7425211916483537, 0.7429884870446694, 0.7464987122800237, 0.7465032469466013, 0.7454267145534154, 0.74840936914105, 0.7493254758032518, 0.7511177943050326, 0.7523025730961087, 0.7526524689428544, 0.7534576034073243, 0.7539355711417289, 0.7546168019761058, 0.7561152260077947, 0.7572052991277908, 0.7591364904982508, 0.7595058073470824, 0.7589874913422255, 0.7598186302701864, 0.7605556171870519, 0.7617668730521422, 0.7631303696556813]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 20)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 21)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 15)   2850        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 15)   2040        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 15)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 40, 26, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 30)   4080        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 30)   8130        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 45)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 60)   24360       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 60)   32460       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 105)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 30)   12630       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 30)   8130        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 105)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 40, 26, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 15)   6315        dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 15)   2040        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 45)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 80, 52, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 20)   8120        dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 80, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 80, 52, 20)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 80, 52, 65)   0           dropout_6[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 52, 13)   858         concatenate_8[0][0]              
==================================================================================================
Total params: 137,918
Trainable params: 39,378
Non-trainable params: 98,540
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 26s - loss: 24271.4893 - acc: 0.7683 - mDice: 0.0734 - val_loss: 14159.7374 - val_acc: 0.8965 - val_mDice: 0.1520

Epoch 00001: val_mDice improved from -inf to 0.15203, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 18s - loss: 11288.2686 - acc: 0.8748 - mDice: 0.2427 - val_loss: 8589.4857 - val_acc: 0.9037 - val_mDice: 0.3164

Epoch 00002: val_mDice improved from 0.15203 to 0.31636, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 18s - loss: 8451.2996 - acc: 0.8760 - mDice: 0.3397 - val_loss: 7184.6633 - val_acc: 0.9042 - val_mDice: 0.3797

Epoch 00003: val_mDice improved from 0.31636 to 0.37969, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 17s - loss: 7229.6966 - acc: 0.8771 - mDice: 0.3946 - val_loss: 6220.5120 - val_acc: 0.9051 - val_mDice: 0.4281

Epoch 00004: val_mDice improved from 0.37969 to 0.42813, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 18s - loss: 6397.1075 - acc: 0.8786 - mDice: 0.4371 - val_loss: 20904.7529 - val_acc: 0.9048 - val_mDice: 0.2671

Epoch 00005: val_mDice did not improve from 0.42813
Epoch 6/300
 - 17s - loss: 5867.0569 - acc: 0.8810 - mDice: 0.4674 - val_loss: 5973.0275 - val_acc: 0.9085 - val_mDice: 0.4424

Epoch 00006: val_mDice improved from 0.42813 to 0.44240, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 18s - loss: 5482.4421 - acc: 0.8844 - mDice: 0.4907 - val_loss: 5460.1279 - val_acc: 0.9108 - val_mDice: 0.4747

Epoch 00007: val_mDice improved from 0.44240 to 0.47468, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 18s - loss: 5181.9854 - acc: 0.8896 - mDice: 0.5097 - val_loss: 5418.9844 - val_acc: 0.9122 - val_mDice: 0.4756

Epoch 00008: val_mDice improved from 0.47468 to 0.47556, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 17s - loss: 4973.9114 - acc: 0.8978 - mDice: 0.5231 - val_loss: 5305.2245 - val_acc: 0.9069 - val_mDice: 0.4815

Epoch 00009: val_mDice improved from 0.47556 to 0.48149, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 18s - loss: 4771.3309 - acc: 0.9046 - mDice: 0.5361 - val_loss: 5058.2401 - val_acc: 0.9268 - val_mDice: 0.5017

Epoch 00010: val_mDice improved from 0.48149 to 0.50170, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 18s - loss: 4624.4358 - acc: 0.9112 - mDice: 0.5462 - val_loss: 5653.3424 - val_acc: 0.9300 - val_mDice: 0.4620

Epoch 00011: val_mDice did not improve from 0.50170
Epoch 12/300
 - 18s - loss: 4469.8751 - acc: 0.9199 - mDice: 0.5564 - val_loss: 4952.1033 - val_acc: 0.9140 - val_mDice: 0.5071

Epoch 00012: val_mDice improved from 0.50170 to 0.50709, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 18s - loss: 4342.2862 - acc: 0.9228 - mDice: 0.5653 - val_loss: 4860.5142 - val_acc: 0.9200 - val_mDice: 0.5117

Epoch 00013: val_mDice improved from 0.50709 to 0.51172, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 16s - loss: 4236.6601 - acc: 0.9242 - mDice: 0.5735 - val_loss: 5183.1975 - val_acc: 0.9192 - val_mDice: 0.4905

Epoch 00014: val_mDice did not improve from 0.51172
Epoch 15/300
 - 17s - loss: 4157.3808 - acc: 0.9249 - mDice: 0.5792 - val_loss: 4879.3355 - val_acc: 0.9196 - val_mDice: 0.5073

Epoch 00015: val_mDice did not improve from 0.51172
Epoch 16/300
 - 17s - loss: 4073.0629 - acc: 0.9262 - mDice: 0.5855 - val_loss: 4816.5107 - val_acc: 0.9311 - val_mDice: 0.5166

Epoch 00016: val_mDice improved from 0.51172 to 0.51660, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 17s - loss: 3988.7175 - acc: 0.9270 - mDice: 0.5917 - val_loss: 4595.0081 - val_acc: 0.9247 - val_mDice: 0.5290

Epoch 00017: val_mDice improved from 0.51660 to 0.52904, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 16s - loss: 3935.1853 - acc: 0.9276 - mDice: 0.5958 - val_loss: 4639.7980 - val_acc: 0.9247 - val_mDice: 0.5266

Epoch 00018: val_mDice did not improve from 0.52904
Epoch 19/300
 - 17s - loss: 3882.4156 - acc: 0.9281 - mDice: 0.5999 - val_loss: 4598.9464 - val_acc: 0.9234 - val_mDice: 0.5283

Epoch 00019: val_mDice did not improve from 0.52904
Epoch 20/300
 - 16s - loss: 3824.5892 - acc: 0.9290 - mDice: 0.6046 - val_loss: 4921.0616 - val_acc: 0.9153 - val_mDice: 0.5092

Epoch 00020: val_mDice did not improve from 0.52904
Epoch 21/300
 - 16s - loss: 3795.4209 - acc: 0.9289 - mDice: 0.6065 - val_loss: 4753.3699 - val_acc: 0.9280 - val_mDice: 0.5197

Epoch 00021: val_mDice did not improve from 0.52904
Epoch 22/300
 - 17s - loss: 3720.6134 - acc: 0.9299 - mDice: 0.6125 - val_loss: 4544.6918 - val_acc: 0.9265 - val_mDice: 0.5312

Epoch 00022: val_mDice improved from 0.52904 to 0.53119, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 23/300
 - 16s - loss: 3682.8636 - acc: 0.9304 - mDice: 0.6156 - val_loss: 4507.4766 - val_acc: 0.9283 - val_mDice: 0.5345

Epoch 00023: val_mDice improved from 0.53119 to 0.53447, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 24/300
 - 16s - loss: 3649.4797 - acc: 0.9307 - mDice: 0.6182 - val_loss: 4760.3864 - val_acc: 0.9223 - val_mDice: 0.5181

Epoch 00024: val_mDice did not improve from 0.53447
Epoch 25/300
 - 17s - loss: 3632.6262 - acc: 0.9312 - mDice: 0.6207 - val_loss: 4323.8874 - val_acc: 0.9348 - val_mDice: 0.5465

Epoch 00025: val_mDice improved from 0.53447 to 0.54651, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 26/300
 - 17s - loss: 3605.8310 - acc: 0.9314 - mDice: 0.6218 - val_loss: 4664.7202 - val_acc: 0.9347 - val_mDice: 0.5245

Epoch 00026: val_mDice did not improve from 0.54651
Epoch 27/300
 - 16s - loss: 3538.2069 - acc: 0.9321 - mDice: 0.6272 - val_loss: 4564.8050 - val_acc: 0.9254 - val_mDice: 0.5307

Epoch 00027: val_mDice did not improve from 0.54651
Epoch 28/300
 - 16s - loss: 3523.5620 - acc: 0.9322 - mDice: 0.6285 - val_loss: 4545.1290 - val_acc: 0.9308 - val_mDice: 0.5307

Epoch 00028: val_mDice did not improve from 0.54651
Epoch 29/300
 - 17s - loss: 3495.3982 - acc: 0.9325 - mDice: 0.6308 - val_loss: 4532.0133 - val_acc: 0.9297 - val_mDice: 0.5346

Epoch 00029: val_mDice did not improve from 0.54651
Epoch 30/300
 - 16s - loss: 3444.4710 - acc: 0.9330 - mDice: 0.6348 - val_loss: 4537.5089 - val_acc: 0.9313 - val_mDice: 0.5333

Epoch 00030: val_mDice did not improve from 0.54651
Epoch 31/300
 - 16s - loss: 3423.7256 - acc: 0.9334 - mDice: 0.6366 - val_loss: 4530.5352 - val_acc: 0.9257 - val_mDice: 0.5326

Epoch 00031: val_mDice did not improve from 0.54651
Epoch 32/300
 - 16s - loss: 3407.0132 - acc: 0.9335 - mDice: 0.6380 - val_loss: 4475.0051 - val_acc: 0.9288 - val_mDice: 0.5371

Epoch 00032: val_mDice did not improve from 0.54651
Epoch 33/300
 - 17s - loss: 3359.1632 - acc: 0.9339 - mDice: 0.6419 - val_loss: 4467.9204 - val_acc: 0.9274 - val_mDice: 0.5381

Epoch 00033: val_mDice did not improve from 0.54651
Epoch 34/300
 - 16s - loss: 3359.7381 - acc: 0.9340 - mDice: 0.6419 - val_loss: 4929.1369 - val_acc: 0.9303 - val_mDice: 0.5103

Epoch 00034: val_mDice did not improve from 0.54651
Epoch 35/300
 - 16s - loss: 3336.2920 - acc: 0.9342 - mDice: 0.6438 - val_loss: 4546.0635 - val_acc: 0.9256 - val_mDice: 0.5321

Epoch 00035: val_mDice did not improve from 0.54651
Epoch 36/300
 - 16s - loss: 3315.3481 - acc: 0.9345 - mDice: 0.6455 - val_loss: 4558.1760 - val_acc: 0.9340 - val_mDice: 0.5319

Epoch 00036: val_mDice did not improve from 0.54651
Epoch 37/300
 - 16s - loss: 3286.2879 - acc: 0.9347 - mDice: 0.6481 - val_loss: 4443.5356 - val_acc: 0.9253 - val_mDice: 0.5403

Epoch 00037: val_mDice did not improve from 0.54651
Epoch 38/300
 - 17s - loss: 3269.7693 - acc: 0.9348 - mDice: 0.6495 - val_loss: 4400.4106 - val_acc: 0.9270 - val_mDice: 0.5426

Epoch 00038: val_mDice did not improve from 0.54651
Epoch 39/300
 - 16s - loss: 3240.4161 - acc: 0.9351 - mDice: 0.6519 - val_loss: 4304.1421 - val_acc: 0.9322 - val_mDice: 0.5484

Epoch 00039: val_mDice improved from 0.54651 to 0.54843, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 40/300
 - 16s - loss: 3247.5379 - acc: 0.9349 - mDice: 0.6512 - val_loss: 4414.4753 - val_acc: 0.9274 - val_mDice: 0.5396

Epoch 00040: val_mDice did not improve from 0.54843
Epoch 41/300
 - 15s - loss: 3239.5840 - acc: 0.9352 - mDice: 0.6521 - val_loss: 4438.0120 - val_acc: 0.9352 - val_mDice: 0.5433

Epoch 00041: val_mDice did not improve from 0.54843
Epoch 42/300
 - 16s - loss: 3181.9270 - acc: 0.9357 - mDice: 0.6568 - val_loss: 4612.9538 - val_acc: 0.9182 - val_mDice: 0.5279

Epoch 00042: val_mDice did not improve from 0.54843
Epoch 43/300
 - 16s - loss: 3179.8710 - acc: 0.9358 - mDice: 0.6569 - val_loss: 4315.1179 - val_acc: 0.9310 - val_mDice: 0.5468

Epoch 00043: val_mDice did not improve from 0.54843
Epoch 44/300
 - 16s - loss: 3157.2838 - acc: 0.9359 - mDice: 0.6588 - val_loss: 4409.0593 - val_acc: 0.9303 - val_mDice: 0.5410

Epoch 00044: val_mDice did not improve from 0.54843
Epoch 45/300
 - 16s - loss: 3135.2986 - acc: 0.9362 - mDice: 0.6607 - val_loss: 4315.7280 - val_acc: 0.9359 - val_mDice: 0.5481

Epoch 00045: val_mDice did not improve from 0.54843
Epoch 46/300
 - 15s - loss: 3136.7526 - acc: 0.9362 - mDice: 0.6606 - val_loss: 4372.5649 - val_acc: 0.9354 - val_mDice: 0.5457

Epoch 00046: val_mDice did not improve from 0.54843
Epoch 47/300
 - 16s - loss: 3124.7629 - acc: 0.9363 - mDice: 0.6616 - val_loss: 4337.5506 - val_acc: 0.9316 - val_mDice: 0.5455

Epoch 00047: val_mDice did not improve from 0.54843
Epoch 48/300
 - 16s - loss: 3118.5730 - acc: 0.9365 - mDice: 0.6623 - val_loss: 4299.8805 - val_acc: 0.9291 - val_mDice: 0.5482

Epoch 00048: val_mDice did not improve from 0.54843
Epoch 49/300
 - 16s - loss: 3095.0732 - acc: 0.9367 - mDice: 0.6642 - val_loss: 4566.1217 - val_acc: 0.9243 - val_mDice: 0.5312

Epoch 00049: val_mDice did not improve from 0.54843
Epoch 50/300
 - 17s - loss: 3071.6356 - acc: 0.9370 - mDice: 0.6662 - val_loss: 4560.6741 - val_acc: 0.9205 - val_mDice: 0.5291

Epoch 00050: val_mDice did not improve from 0.54843
Epoch 51/300
 - 16s - loss: 3082.7940 - acc: 0.9370 - mDice: 0.6654 - val_loss: 4335.6935 - val_acc: 0.9270 - val_mDice: 0.5452

Epoch 00051: val_mDice did not improve from 0.54843
Epoch 52/300
 - 16s - loss: 3058.1059 - acc: 0.9370 - mDice: 0.6672 - val_loss: 4408.2922 - val_acc: 0.9264 - val_mDice: 0.5414

Epoch 00052: val_mDice did not improve from 0.54843
Epoch 53/300
 - 16s - loss: 3047.6001 - acc: 0.9372 - mDice: 0.6683 - val_loss: 4418.2450 - val_acc: 0.9364 - val_mDice: 0.5405

Epoch 00053: val_mDice did not improve from 0.54843
Epoch 54/300
 - 16s - loss: 3027.2918 - acc: 0.9375 - mDice: 0.6701 - val_loss: 4312.2793 - val_acc: 0.9281 - val_mDice: 0.5469

Epoch 00054: val_mDice did not improve from 0.54843
Epoch 55/300
 - 16s - loss: 3031.8805 - acc: 0.9375 - mDice: 0.6696 - val_loss: 4347.7485 - val_acc: 0.9265 - val_mDice: 0.5436

Epoch 00055: val_mDice did not improve from 0.54843
Epoch 56/300
 - 17s - loss: 3000.4085 - acc: 0.9379 - mDice: 0.6725 - val_loss: 4742.4092 - val_acc: 0.9315 - val_mDice: 0.5214

Epoch 00056: val_mDice did not improve from 0.54843
Epoch 57/300
 - 16s - loss: 2991.3288 - acc: 0.9380 - mDice: 0.6732 - val_loss: 4314.9547 - val_acc: 0.9313 - val_mDice: 0.5477

Epoch 00057: val_mDice did not improve from 0.54843
Epoch 58/300
 - 16s - loss: 2983.2232 - acc: 0.9379 - mDice: 0.6738 - val_loss: 4533.7616 - val_acc: 0.9363 - val_mDice: 0.5328

Epoch 00058: val_mDice did not improve from 0.54843
Epoch 59/300
 - 16s - loss: 2990.0675 - acc: 0.9379 - mDice: 0.6733 - val_loss: 4319.5377 - val_acc: 0.9295 - val_mDice: 0.5472

Epoch 00059: val_mDice did not improve from 0.54843
Epoch 60/300
 - 16s - loss: 2956.3700 - acc: 0.9383 - mDice: 0.6762 - val_loss: 4385.6443 - val_acc: 0.9350 - val_mDice: 0.5428

Epoch 00060: val_mDice did not improve from 0.54843
Epoch 61/300
 - 16s - loss: 2946.1049 - acc: 0.9384 - mDice: 0.6770 - val_loss: 4588.6111 - val_acc: 0.9381 - val_mDice: 0.5318

Epoch 00061: val_mDice did not improve from 0.54843
Epoch 62/300
 - 16s - loss: 2943.6208 - acc: 0.9385 - mDice: 0.6773 - val_loss: 4472.7908 - val_acc: 0.9361 - val_mDice: 0.5363

Epoch 00062: val_mDice did not improve from 0.54843
Epoch 63/300
 - 16s - loss: 2944.1912 - acc: 0.9386 - mDice: 0.6774 - val_loss: 4338.1280 - val_acc: 0.9307 - val_mDice: 0.5447

Epoch 00063: val_mDice did not improve from 0.54843
Epoch 64/300
 - 16s - loss: 2932.9415 - acc: 0.9386 - mDice: 0.6782 - val_loss: 4399.4437 - val_acc: 0.9309 - val_mDice: 0.5424

Epoch 00064: val_mDice did not improve from 0.54843
Epoch 65/300
 - 16s - loss: 2935.3690 - acc: 0.9386 - mDice: 0.6780 - val_loss: 4378.7421 - val_acc: 0.9320 - val_mDice: 0.5422

Epoch 00065: val_mDice did not improve from 0.54843
Epoch 66/300
 - 16s - loss: 2919.2296 - acc: 0.9388 - mDice: 0.6795 - val_loss: 4261.6597 - val_acc: 0.9328 - val_mDice: 0.5506

Epoch 00066: val_mDice improved from 0.54843 to 0.55063, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 67/300
 - 16s - loss: 2909.3804 - acc: 0.9389 - mDice: 0.6805 - val_loss: 4600.2376 - val_acc: 0.9286 - val_mDice: 0.5259

Epoch 00067: val_mDice did not improve from 0.55063
Epoch 68/300
 - 15s - loss: 2903.7226 - acc: 0.9391 - mDice: 0.6809 - val_loss: 4234.8097 - val_acc: 0.9327 - val_mDice: 0.5531

Epoch 00068: val_mDice improved from 0.55063 to 0.55306, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 69/300
 - 16s - loss: 2888.8712 - acc: 0.9392 - mDice: 0.6822 - val_loss: 4293.2890 - val_acc: 0.9299 - val_mDice: 0.5486

Epoch 00069: val_mDice did not improve from 0.55306
Epoch 70/300
 - 16s - loss: 2886.2907 - acc: 0.9393 - mDice: 0.6824 - val_loss: 4305.8915 - val_acc: 0.9320 - val_mDice: 0.5478

Epoch 00070: val_mDice did not improve from 0.55306
Epoch 71/300
 - 16s - loss: 2853.7836 - acc: 0.9394 - mDice: 0.6852 - val_loss: 4408.2804 - val_acc: 0.9335 - val_mDice: 0.5414

Epoch 00071: val_mDice did not improve from 0.55306
Epoch 72/300
 - 16s - loss: 2883.7293 - acc: 0.9393 - mDice: 0.6827 - val_loss: 4315.6690 - val_acc: 0.9320 - val_mDice: 0.5462

Epoch 00072: val_mDice did not improve from 0.55306
Epoch 73/300
 - 17s - loss: 2856.4739 - acc: 0.9396 - mDice: 0.6850 - val_loss: 4406.6627 - val_acc: 0.9265 - val_mDice: 0.5395

Epoch 00073: val_mDice did not improve from 0.55306
Epoch 74/300
 - 16s - loss: 2860.2000 - acc: 0.9396 - mDice: 0.6848 - val_loss: 4429.1500 - val_acc: 0.9330 - val_mDice: 0.5387

Epoch 00074: val_mDice did not improve from 0.55306
Epoch 75/300
 - 16s - loss: 2842.8692 - acc: 0.9396 - mDice: 0.6863 - val_loss: 4356.1719 - val_acc: 0.9335 - val_mDice: 0.5463

Epoch 00075: val_mDice did not improve from 0.55306
Epoch 76/300
 - 16s - loss: 2849.6190 - acc: 0.9395 - mDice: 0.6858 - val_loss: 4329.4691 - val_acc: 0.9368 - val_mDice: 0.5468

Epoch 00076: val_mDice did not improve from 0.55306
Epoch 77/300
 - 16s - loss: 2838.8349 - acc: 0.9397 - mDice: 0.6867 - val_loss: 4304.7871 - val_acc: 0.9282 - val_mDice: 0.5481

Epoch 00077: val_mDice did not improve from 0.55306
Epoch 78/300
 - 15s - loss: 2831.4028 - acc: 0.9399 - mDice: 0.6873 - val_loss: 4300.9858 - val_acc: 0.9344 - val_mDice: 0.5477

Epoch 00078: val_mDice did not improve from 0.55306
Epoch 79/300
 - 16s - loss: 2799.9043 - acc: 0.9401 - mDice: 0.6901 - val_loss: 4307.1940 - val_acc: 0.9341 - val_mDice: 0.5487

Epoch 00079: val_mDice did not improve from 0.55306
Epoch 80/300
 - 16s - loss: 2823.2146 - acc: 0.9400 - mDice: 0.6881 - val_loss: 4406.5245 - val_acc: 0.9284 - val_mDice: 0.5395

Epoch 00080: val_mDice did not improve from 0.55306
Epoch 81/300
 - 16s - loss: 2802.5647 - acc: 0.9403 - mDice: 0.6899 - val_loss: 4353.6507 - val_acc: 0.9231 - val_mDice: 0.5431

Epoch 00081: val_mDice did not improve from 0.55306
Epoch 82/300
 - 16s - loss: 2801.5870 - acc: 0.9400 - mDice: 0.6899 - val_loss: 4248.3954 - val_acc: 0.9305 - val_mDice: 0.5513

Epoch 00082: val_mDice did not improve from 0.55306
Epoch 83/300
 - 16s - loss: 2804.5147 - acc: 0.9401 - mDice: 0.6896 - val_loss: 4280.7710 - val_acc: 0.9332 - val_mDice: 0.5495

Epoch 00083: val_mDice did not improve from 0.55306
Epoch 84/300
 - 16s - loss: 2782.9193 - acc: 0.9403 - mDice: 0.6916 - val_loss: 4427.6127 - val_acc: 0.9277 - val_mDice: 0.5381

Epoch 00084: val_mDice did not improve from 0.55306
Epoch 85/300
 - 17s - loss: 2778.3876 - acc: 0.9403 - mDice: 0.6920 - val_loss: 4394.9090 - val_acc: 0.9360 - val_mDice: 0.5412

Epoch 00085: val_mDice did not improve from 0.55306
Epoch 86/300
 - 16s - loss: 2776.8253 - acc: 0.9403 - mDice: 0.6921 - val_loss: 4349.9527 - val_acc: 0.9362 - val_mDice: 0.5446

Epoch 00086: val_mDice did not improve from 0.55306
Epoch 87/300
 - 16s - loss: 2772.9393 - acc: 0.9406 - mDice: 0.6926 - val_loss: 4628.6223 - val_acc: 0.9219 - val_mDice: 0.5243

Epoch 00087: val_mDice did not improve from 0.55306
Epoch 88/300
 - 16s - loss: 2764.7514 - acc: 0.9405 - mDice: 0.6931 - val_loss: 4329.8381 - val_acc: 0.9346 - val_mDice: 0.5446

Epoch 00088: val_mDice did not improve from 0.55306
Epoch 89/300
 - 16s - loss: 2760.6343 - acc: 0.9406 - mDice: 0.6936 - val_loss: 4424.3537 - val_acc: 0.9276 - val_mDice: 0.5390

Epoch 00089: val_mDice did not improve from 0.55306
Epoch 90/300
 - 16s - loss: 2764.2468 - acc: 0.9407 - mDice: 0.6933 - val_loss: 4427.3622 - val_acc: 0.9310 - val_mDice: 0.5417

Epoch 00090: val_mDice did not improve from 0.55306
Epoch 91/300
 - 18s - loss: 2740.9771 - acc: 0.9408 - mDice: 0.6954 - val_loss: 4236.7703 - val_acc: 0.9363 - val_mDice: 0.5529

Epoch 00091: val_mDice did not improve from 0.55306
Epoch 92/300
 - 17s - loss: 2751.1458 - acc: 0.9408 - mDice: 0.6945 - val_loss: 4296.5068 - val_acc: 0.9286 - val_mDice: 0.5474

Epoch 00092: val_mDice did not improve from 0.55306
Epoch 93/300
 - 16s - loss: 2741.0175 - acc: 0.9408 - mDice: 0.6952 - val_loss: 4425.2104 - val_acc: 0.9302 - val_mDice: 0.5395

Epoch 00093: val_mDice did not improve from 0.55306
Epoch 94/300
 - 15s - loss: 2749.1946 - acc: 0.9408 - mDice: 0.6947 - val_loss: 4435.5097 - val_acc: 0.9372 - val_mDice: 0.5385

Epoch 00094: val_mDice did not improve from 0.55306
Epoch 95/300
 - 17s - loss: 2736.2993 - acc: 0.9409 - mDice: 0.6958 - val_loss: 4535.6871 - val_acc: 0.9275 - val_mDice: 0.5318

Epoch 00095: val_mDice did not improve from 0.55306
Epoch 96/300
 - 17s - loss: 2745.8442 - acc: 0.9409 - mDice: 0.6950 - val_loss: 4306.4685 - val_acc: 0.9283 - val_mDice: 0.5466

Epoch 00096: val_mDice did not improve from 0.55306
Epoch 97/300
 - 18s - loss: 2725.1797 - acc: 0.9411 - mDice: 0.6967 - val_loss: 4296.9330 - val_acc: 0.9315 - val_mDice: 0.5486

Epoch 00097: val_mDice did not improve from 0.55306
Epoch 98/300
 - 17s - loss: 2713.3444 - acc: 0.9410 - mDice: 0.6979 - val_loss: 4335.2985 - val_acc: 0.9281 - val_mDice: 0.5466

Epoch 00098: val_mDice did not improve from 0.55306
Restoring model weights from the end of the best epoch
Epoch 00098: early stopping
{'val_loss': [14159.737445537861, 8589.485661433293, 7184.663292518029, 6220.512009840745, 20904.752948467547, 5973.027512770433, 5460.127910907452, 5418.9844313401445, 5305.224459134615, 5058.240102914663, 5653.342360276442, 4952.103290264423, 4860.514235276442, 5183.197547325721, 4879.335467998798, 4816.5106858473555, 4595.008103590745, 4639.79799241286, 4598.946364182692, 4921.061556302584, 4753.369938777043, 4544.691814716046, 4507.476647010217, 4760.386422964243, 4323.887352576623, 4664.720196063702, 4564.8049879807695, 4545.1290283203125, 4532.0133385291465, 4537.508873572717, 4530.535198505108, 4475.005145733173, 4467.920358511118, 4929.13685960036, 4546.0635329026445, 4558.1760488656855, 4443.535574106069, 4400.410635141226, 4304.142085148738, 4414.475257286658, 4438.012028620793, 4612.9538010817305, 4315.117854191707, 4409.059255746694, 4315.728022648738, 4372.564927321214, 4337.550612229567, 4299.880540114183, 4566.121694711538, 4560.674067570613, 4335.693504920373, 4408.292170597957, 4418.2450279822715, 4312.27934382512, 4347.748539851262, 4742.409207857572, 4314.954697829026, 4533.761620154748, 4319.537715031551, 4385.644273024339, 4588.611051119291, 4472.790776179387, 4338.127995417668, 4399.443716195913, 4378.742145244892, 4261.659677358774, 4600.2376051682695, 4234.809697077824, 4293.289020244892, 4305.891498272235, 4408.280353252704, 4315.669011042668, 4406.662663386418, 4429.150005634015, 4356.171912560096, 4329.469106820913, 4304.7870530348555, 4300.9857506385215, 4307.194044846755, 4406.524475097656, 4353.650700495793, 4248.395362267127, 4280.7710195688105, 4427.612717848558, 4394.9090247521035, 4349.952740009015, 4628.622333233173, 4329.838106595553, 4424.353661170373, 4427.362238957332, 4236.770258976863, 4296.506770207332, 4425.21035531851, 4435.509728064904, 4535.687110314002, 4306.468454214243, 4296.933044433594, 4335.298466609074], 'val_acc': [0.8964843727075137, 0.9037352204322815, 0.9041674297589523, 0.9051382220708407, 0.9047591777948233, 0.9084666096247159, 0.9107572298783523, 0.9122180228049939, 0.9068671189821683, 0.9268167798335736, 0.9300365310448867, 0.9140116205582252, 0.9200189801362845, 0.9192446286861713, 0.9196283014921042, 0.9311113242919629, 0.9246903016017034, 0.9246971905231476, 0.9234490715540372, 0.915345318042315, 0.9280233039305761, 0.9265000659685868, 0.9283284017672906, 0.9223442100561582, 0.9347795156332163, 0.9346985954504746, 0.9253536187685453, 0.9308385528050936, 0.9297129007486197, 0.9313146976324228, 0.9257396597128648, 0.9287791320910821, 0.927431604036918, 0.9302977208907788, 0.9255824914345374, 0.9339890159093417, 0.9253305013363178, 0.9270039957303268, 0.9321930500177237, 0.9273760960652278, 0.9352255990872016, 0.9181767862576705, 0.93096341078098, 0.9302954123570368, 0.9359120680735662, 0.9354243530676916, 0.9316382935413947, 0.9290796151527991, 0.9242996688072498, 0.920527478823295, 0.9270270741902865, 0.9264214955843412, 0.9364436681453998, 0.9281481023018177, 0.9265070053247305, 0.931455699297098, 0.9313147320197179, 0.9362795650959015, 0.9294725243861859, 0.9350198667783004, 0.9380755401574649, 0.9360808019454663, 0.9306790782855108, 0.9309241083952097, 0.9319919554086832, 0.932840264760531, 0.9286219706902137, 0.9326761479561145, 0.9299302238684434, 0.9319873062463907, 0.9334990084171295, 0.9320428050481356, 0.9265093161509588, 0.9329512004668896, 0.9335267108220321, 0.9367534059744614, 0.9281758620188787, 0.9343727139326242, 0.9340930305994474, 0.9283769268255967, 0.9230537987672366, 0.9305427326605871, 0.9331522881984711, 0.9276581131494962, 0.9360391795635223, 0.9362287269188807, 0.9219304483670455, 0.9345969007565424, 0.9276141570164607, 0.9310304018167349, 0.9363442888626685, 0.9286289077538711, 0.9301682916971353, 0.9372480488740481, 0.9274986134125636, 0.9282682813130892, 0.9314927229514489, 0.9281064890898191], 'val_mDice': [0.15202670816618663, 0.3163556086902435, 0.3796862936936892, 0.42813072410913616, 0.2670508757806741, 0.4424036168135129, 0.4746805326296733, 0.47555964210858714, 0.48149147171240586, 0.5017009291511315, 0.462048386151974, 0.5070888537627, 0.5117178444678967, 0.4904517221909303, 0.5072978459871732, 0.5165963631409866, 0.5290440229269174, 0.5265831786852616, 0.5283146953353515, 0.5091647436985602, 0.5196901330581079, 0.5311855880113748, 0.534472677570123, 0.5180527567863464, 0.546507481772166, 0.5245030705745404, 0.5307088184815186, 0.5307144264762218, 0.5345918071957735, 0.5333468661858485, 0.53261337773158, 0.5371041871034182, 0.5380832289273922, 0.510276486667303, 0.532091674896387, 0.5318846244078416, 0.5403030652266282, 0.5425916193769529, 0.5484322882615603, 0.5396026653739122, 0.5433123060143911, 0.5278587438739263, 0.5467624698693936, 0.5410330329950039, 0.548086051757519, 0.5456732981480085, 0.5454553170846059, 0.5481566356924864, 0.5312006421960317, 0.529066243996987, 0.5452018867318447, 0.5413534159843738, 0.5404699989236318, 0.5469301635256181, 0.5435552889337907, 0.5214187646141419, 0.5477359203191904, 0.5327755281558404, 0.5472494249160473, 0.5428262324287341, 0.5317529325301831, 0.5363384353426787, 0.5446628922453294, 0.5423704729630396, 0.5421572576921719, 0.5506295194992652, 0.5259374122206981, 0.5530636035479032, 0.54855909714332, 0.5478266116518241, 0.5413872920549833, 0.5461929589509964, 0.5394993189435738, 0.5386984365490767, 0.5463405022254357, 0.5467763703603011, 0.5481132652897102, 0.547711312197722, 0.5486847781218015, 0.539519146657907, 0.543110827413889, 0.5513256788253784, 0.54951323224948, 0.5381246042939333, 0.5412452496015109, 0.5446291393958606, 0.5243435335847048, 0.5446056299484693, 0.5390133800414892, 0.5417031307633107, 0.5528933531962908, 0.5474076225207403, 0.5395080430003313, 0.5385258541657374, 0.5318371647825608, 0.5466109468386724, 0.548573109966058, 0.5466008656300031], 'loss': [24271.48925574103, 11288.268567814308, 8451.299553409313, 7229.696647246496, 6397.107457697903, 5867.056905052511, 5482.442111427556, 5181.985435276863, 4973.911383662883, 4771.330908423782, 4624.4357671487005, 4469.875069833271, 4342.286229563608, 4236.660072445573, 4157.380790982752, 4073.062902765609, 3988.7174806736452, 3935.185343713434, 3882.415594092333, 3824.5892374400537, 3795.4209357464565, 3720.613441710035, 3682.8636051084045, 3649.479746584148, 3632.6262087921787, 3605.831049767761, 3538.206904226175, 3523.561996914502, 3495.3981932130214, 3444.4710201610665, 3423.7255501371133, 3407.0131556739516, 3359.163188227536, 3359.7380672244803, 3336.291998919774, 3315.3480790210456, 3286.2879051005148, 3269.7693109988154, 3240.416081506718, 3247.537942814759, 3239.5840397530196, 3181.926975091577, 3179.871016857974, 3157.283817360567, 3135.298553666626, 3136.7526232564537, 3124.7629035063846, 3118.5729749905254, 3095.0732229813807, 3071.635550024984, 3082.793961569028, 3058.1059474957383, 3047.6000559116483, 3027.2918371538126, 3031.8805013373585, 3000.4084616082955, 2991.328827047836, 2983.223157894476, 2990.0674636110457, 2956.37004573308, 2946.1048981728923, 2943.6207872514055, 2944.1911688866808, 2932.94152476279, 2935.369020783768, 2919.229578705101, 2909.380410046372, 2903.722613728597, 2888.871174571062, 2886.29071825663, 2853.783585828883, 2883.729335431341, 2856.4739243604927, 2860.2000392205623, 2842.86922257186, 2849.6190408117204, 2838.8349490603277, 2831.4027880350513, 2799.9043061178045, 2823.214598235901, 2802.564716922064, 2801.5870457133565, 2804.5146723044245, 2782.919339904813, 2778.3875517506976, 2776.8252924463795, 2772.9392680887872, 2764.7513862630267, 2760.6342841435717, 2764.246774520248, 2740.9770934940384, 2751.145764854774, 2741.017492609359, 2749.1946053860715, 2736.299253800605, 2745.844160792551, 2725.179692667414, 2713.3443658342003], 'acc': [0.7682832214078769, 0.874795262778167, 0.8759988497502578, 0.8771174614097231, 0.8786362319110032, 0.8809514431774006, 0.8843608124608165, 0.889627258506943, 0.8978056572168106, 0.9046416888539998, 0.9111672568110141, 0.9198705602382631, 0.9228456501128279, 0.9242302912204873, 0.9249336261112928, 0.9262095492978735, 0.9270046410619537, 0.9276193778672958, 0.9281314521283117, 0.9289636966938749, 0.9289433035443303, 0.9299162122185881, 0.9303984861086735, 0.930741477323768, 0.9311897037687374, 0.9313992673341698, 0.9321451157669536, 0.9322130689704087, 0.9324747599887417, 0.9329877604387634, 0.9333583480436886, 0.9335267016569495, 0.9339233396854346, 0.9339567283626238, 0.9342220780166282, 0.9344627469500459, 0.9346843737413839, 0.9348493206548282, 0.9351401586632859, 0.9349182002781656, 0.935206160184302, 0.9356704129236469, 0.9357766259819293, 0.9358601603826385, 0.936205299404355, 0.9361700255921612, 0.936320773517141, 0.9364699593089905, 0.9366620098226329, 0.9369929810901921, 0.9370055325926422, 0.9370081010069737, 0.9372022861123008, 0.9374775621852103, 0.937521658116993, 0.9379377848194126, 0.9380416914533449, 0.9378530968822018, 0.9378624466482942, 0.9382508397542121, 0.9383898868855873, 0.938517514018789, 0.9385699908539652, 0.9385800572830428, 0.9385652700594559, 0.9387543089196524, 0.9388751758043148, 0.9390504096834728, 0.9391591702452623, 0.9392613259164827, 0.9393677855509844, 0.9392529492073478, 0.9395975689985628, 0.9395560294920191, 0.9396224031531479, 0.9395194021437118, 0.9397408557116276, 0.9399138250045755, 0.9401245436401898, 0.9399993328066162, 0.940251021936878, 0.9400247567794776, 0.9401103346030958, 0.9403482378711012, 0.940344929046476, 0.940324754372169, 0.9405532818784752, 0.9405362105541076, 0.9405545902342349, 0.940671487904712, 0.9407759293313287, 0.940758015631662, 0.9407624310588723, 0.9407519216820245, 0.9408522619814558, 0.9408563414392223, 0.9410669938847114, 0.9410389487422129], 'mDice': [0.07338978473915117, 0.24274954551877784, 0.3397325747217363, 0.3946426552753436, 0.43706994015253814, 0.4674173373088926, 0.4907065954670567, 0.5096898734635514, 0.5231097939516207, 0.5361463603724481, 0.5462402845895632, 0.5564055412521246, 0.5653367516608143, 0.5734618178793044, 0.5791875477603668, 0.5855400325692822, 0.5916774486479566, 0.5957575963946997, 0.5999443354910506, 0.6045793601477771, 0.6065230132204728, 0.6124905904786433, 0.6156491166956254, 0.6181966031674011, 0.6206996222214319, 0.62175370314833, 0.6271906195394471, 0.6285301981723849, 0.6307856734691923, 0.634782270148134, 0.636566216425846, 0.6380348802107589, 0.6419139987129705, 0.6418806346406315, 0.6438411650078923, 0.6454993298679746, 0.6480585286057239, 0.6494731306864813, 0.6519164218900829, 0.6512071184925979, 0.6521283104269529, 0.6567697317565289, 0.6569374535649528, 0.6588369166731207, 0.6606816591387974, 0.6605584007847367, 0.6615525223139543, 0.6623453139258324, 0.664154252486619, 0.6662409597686392, 0.6653865571722579, 0.6672137242164777, 0.6683129102313231, 0.6700936030563168, 0.6696486298386861, 0.6725015763392981, 0.6731971600206754, 0.6738486738538297, 0.6733074872286835, 0.6761929170293561, 0.6770144852283179, 0.6772564343780343, 0.6773609757357436, 0.6782386364734977, 0.677961256806837, 0.6794545803850212, 0.680470337410821, 0.6808988344819962, 0.6822156543651652, 0.6823579936375821, 0.6851879956756781, 0.6826949611005226, 0.6850424152364769, 0.684783508172282, 0.6863020140614818, 0.6857661757534702, 0.6867281942473977, 0.6873230417199343, 0.6901182063521026, 0.6881050287847159, 0.6899441501415492, 0.6899498247478013, 0.6895525218771358, 0.6916141093442397, 0.6920069804944027, 0.6921441840045865, 0.6925581632961726, 0.693092920216623, 0.6936357388755421, 0.6932675700329287, 0.6954046433662165, 0.6944620082060218, 0.6952364863004125, 0.6947238415213053, 0.6957509469790266, 0.6950190855240147, 0.696745587859681, 0.6979488158516258]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.25s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.01s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.81s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:09,  1.72s/it]predicting train subjects:   1%|          | 2/285 [00:02<07:29,  1.59s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:29,  1.59s/it]predicting train subjects:   1%|▏         | 4/285 [00:05<07:02,  1.50s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:16,  1.56s/it]predicting train subjects:   2%|▏         | 6/285 [00:08<07:02,  1.51s/it]predicting train subjects:   2%|▏         | 7/285 [00:10<07:26,  1.61s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:27,  1.62s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:49,  1.70s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:04,  1.76s/it]predicting train subjects:   4%|▍         | 11/285 [00:17<07:42,  1.69s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<08:02,  1.77s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:45,  1.71s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<07:50,  1.74s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<08:04,  1.80s/it]predicting train subjects:   6%|▌         | 16/285 [00:26<08:03,  1.80s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<07:43,  1.73s/it]predicting train subjects:   6%|▋         | 18/285 [00:30<07:42,  1.73s/it]predicting train subjects:   7%|▋         | 19/285 [00:31<07:30,  1.69s/it]predicting train subjects:   7%|▋         | 20/285 [00:33<07:32,  1.71s/it]predicting train subjects:   7%|▋         | 21/285 [00:35<07:51,  1.79s/it]predicting train subjects:   8%|▊         | 22/285 [00:37<07:34,  1.73s/it]predicting train subjects:   8%|▊         | 23/285 [00:38<07:37,  1.75s/it]predicting train subjects:   8%|▊         | 24/285 [00:40<07:15,  1.67s/it]predicting train subjects:   9%|▉         | 25/285 [00:42<07:28,  1.73s/it]predicting train subjects:   9%|▉         | 26/285 [00:44<07:39,  1.77s/it]predicting train subjects:   9%|▉         | 27/285 [00:45<07:20,  1.71s/it]predicting train subjects:  10%|▉         | 28/285 [00:47<07:24,  1.73s/it]predicting train subjects:  10%|█         | 29/285 [00:49<07:19,  1.72s/it]predicting train subjects:  11%|█         | 30/285 [00:50<07:26,  1.75s/it]predicting train subjects:  11%|█         | 31/285 [00:52<07:36,  1.80s/it]predicting train subjects:  11%|█         | 32/285 [00:54<07:15,  1.72s/it]predicting train subjects:  12%|█▏        | 33/285 [00:56<07:14,  1.73s/it]predicting train subjects:  12%|█▏        | 34/285 [00:57<07:17,  1.74s/it]predicting train subjects:  12%|█▏        | 35/285 [00:59<07:30,  1.80s/it]predicting train subjects:  13%|█▎        | 36/285 [01:01<07:09,  1.72s/it]predicting train subjects:  13%|█▎        | 37/285 [01:03<07:13,  1.75s/it]predicting train subjects:  13%|█▎        | 38/285 [01:04<07:17,  1.77s/it]predicting train subjects:  14%|█▎        | 39/285 [01:06<06:59,  1.70s/it]predicting train subjects:  14%|█▍        | 40/285 [01:08<07:00,  1.72s/it]predicting train subjects:  14%|█▍        | 41/285 [01:09<06:53,  1.70s/it]predicting train subjects:  15%|█▍        | 42/285 [01:11<06:50,  1.69s/it]predicting train subjects:  15%|█▌        | 43/285 [01:13<06:52,  1.70s/it]predicting train subjects:  15%|█▌        | 44/285 [01:15<07:03,  1.76s/it]predicting train subjects:  16%|█▌        | 45/285 [01:16<06:55,  1.73s/it]predicting train subjects:  16%|█▌        | 46/285 [01:18<07:07,  1.79s/it]predicting train subjects:  16%|█▋        | 47/285 [01:20<06:58,  1.76s/it]predicting train subjects:  17%|█▋        | 48/285 [01:22<07:00,  1.78s/it]predicting train subjects:  17%|█▋        | 49/285 [01:24<07:03,  1.79s/it]predicting train subjects:  18%|█▊        | 50/285 [01:25<06:55,  1.77s/it]predicting train subjects:  18%|█▊        | 51/285 [01:27<07:04,  1.82s/it]predicting train subjects:  18%|█▊        | 52/285 [01:29<06:48,  1.75s/it]predicting train subjects:  19%|█▊        | 53/285 [01:31<06:44,  1.74s/it]predicting train subjects:  19%|█▉        | 54/285 [01:32<06:51,  1.78s/it]predicting train subjects:  19%|█▉        | 55/285 [01:34<06:33,  1.71s/it]predicting train subjects:  20%|█▉        | 56/285 [01:36<06:30,  1.71s/it]predicting train subjects:  20%|██        | 57/285 [01:37<06:19,  1.67s/it]predicting train subjects:  20%|██        | 58/285 [01:39<06:23,  1.69s/it]predicting train subjects:  21%|██        | 59/285 [01:41<06:36,  1.76s/it]predicting train subjects:  21%|██        | 60/285 [01:43<06:46,  1.81s/it]predicting train subjects:  21%|██▏       | 61/285 [01:44<06:31,  1.75s/it]predicting train subjects:  22%|██▏       | 62/285 [01:46<06:35,  1.77s/it]predicting train subjects:  22%|██▏       | 63/285 [01:48<06:33,  1.77s/it]predicting train subjects:  22%|██▏       | 64/285 [01:50<06:19,  1.72s/it]predicting train subjects:  23%|██▎       | 65/285 [01:51<06:22,  1.74s/it]predicting train subjects:  23%|██▎       | 66/285 [01:53<06:23,  1.75s/it]predicting train subjects:  24%|██▎       | 67/285 [01:55<06:21,  1.75s/it]predicting train subjects:  24%|██▍       | 68/285 [01:57<06:08,  1.70s/it]predicting train subjects:  24%|██▍       | 69/285 [01:58<06:15,  1.74s/it]predicting train subjects:  25%|██▍       | 70/285 [02:00<06:12,  1.73s/it]predicting train subjects:  25%|██▍       | 71/285 [02:02<06:10,  1.73s/it]predicting train subjects:  25%|██▌       | 72/285 [02:03<05:56,  1.67s/it]predicting train subjects:  26%|██▌       | 73/285 [02:05<05:56,  1.68s/it]predicting train subjects:  26%|██▌       | 74/285 [02:07<06:03,  1.72s/it]predicting train subjects:  26%|██▋       | 75/285 [02:09<06:04,  1.73s/it]predicting train subjects:  27%|██▋       | 76/285 [02:10<06:03,  1.74s/it]predicting train subjects:  27%|██▋       | 77/285 [02:12<05:51,  1.69s/it]predicting train subjects:  27%|██▋       | 78/285 [02:14<05:38,  1.63s/it]predicting train subjects:  28%|██▊       | 79/285 [02:15<05:37,  1.64s/it]predicting train subjects:  28%|██▊       | 80/285 [02:17<05:39,  1.66s/it]predicting train subjects:  28%|██▊       | 81/285 [02:18<05:28,  1.61s/it]predicting train subjects:  29%|██▉       | 82/285 [02:20<05:38,  1.67s/it]predicting train subjects:  29%|██▉       | 83/285 [02:22<05:34,  1.66s/it]predicting train subjects:  29%|██▉       | 84/285 [02:23<05:25,  1.62s/it]predicting train subjects:  30%|██▉       | 85/285 [02:25<05:35,  1.68s/it]predicting train subjects:  30%|███       | 86/285 [02:27<05:33,  1.68s/it]predicting train subjects:  31%|███       | 87/285 [02:29<05:37,  1.71s/it]predicting train subjects:  31%|███       | 88/285 [02:30<05:24,  1.65s/it]predicting train subjects:  31%|███       | 89/285 [02:32<05:25,  1.66s/it]predicting train subjects:  32%|███▏      | 90/285 [02:34<05:27,  1.68s/it]predicting train subjects:  32%|███▏      | 91/285 [02:35<05:19,  1.64s/it]predicting train subjects:  32%|███▏      | 92/285 [02:37<05:24,  1.68s/it]predicting train subjects:  33%|███▎      | 93/285 [02:38<05:18,  1.66s/it]predicting train subjects:  33%|███▎      | 94/285 [02:40<05:21,  1.68s/it]predicting train subjects:  33%|███▎      | 95/285 [02:42<05:20,  1.69s/it]predicting train subjects:  34%|███▎      | 96/285 [02:44<05:20,  1.69s/it]predicting train subjects:  34%|███▍      | 97/285 [02:45<05:22,  1.72s/it]predicting train subjects:  34%|███▍      | 98/285 [02:47<05:16,  1.69s/it]predicting train subjects:  35%|███▍      | 99/285 [02:49<05:11,  1.67s/it]predicting train subjects:  35%|███▌      | 100/285 [02:50<05:14,  1.70s/it]predicting train subjects:  35%|███▌      | 101/285 [02:52<05:01,  1.64s/it]predicting train subjects:  36%|███▌      | 102/285 [02:54<05:06,  1.68s/it]predicting train subjects:  36%|███▌      | 103/285 [02:55<04:59,  1.65s/it]predicting train subjects:  36%|███▋      | 104/285 [02:57<05:03,  1.68s/it]predicting train subjects:  37%|███▋      | 105/285 [02:59<05:05,  1.70s/it]predicting train subjects:  37%|███▋      | 106/285 [03:00<04:55,  1.65s/it]predicting train subjects:  38%|███▊      | 107/285 [03:02<04:55,  1.66s/it]predicting train subjects:  38%|███▊      | 108/285 [03:04<04:48,  1.63s/it]predicting train subjects:  38%|███▊      | 109/285 [03:05<04:49,  1.65s/it]predicting train subjects:  39%|███▊      | 110/285 [03:07<04:51,  1.67s/it]predicting train subjects:  39%|███▉      | 111/285 [03:08<04:41,  1.62s/it]predicting train subjects:  39%|███▉      | 112/285 [03:10<04:46,  1.66s/it]predicting train subjects:  40%|███▉      | 113/285 [03:12<04:50,  1.69s/it]predicting train subjects:  40%|████      | 114/285 [03:14<04:49,  1.69s/it]predicting train subjects:  40%|████      | 115/285 [03:15<04:48,  1.70s/it]predicting train subjects:  41%|████      | 116/285 [03:17<04:54,  1.74s/it]predicting train subjects:  41%|████      | 117/285 [03:19<04:45,  1.70s/it]predicting train subjects:  41%|████▏     | 118/285 [03:20<04:36,  1.66s/it]predicting train subjects:  42%|████▏     | 119/285 [03:22<04:36,  1.66s/it]predicting train subjects:  42%|████▏     | 120/285 [03:24<04:30,  1.64s/it]predicting train subjects:  42%|████▏     | 121/285 [03:25<04:25,  1.62s/it]predicting train subjects:  43%|████▎     | 122/285 [03:27<04:23,  1.61s/it]predicting train subjects:  43%|████▎     | 123/285 [03:28<04:09,  1.54s/it]predicting train subjects:  44%|████▎     | 124/285 [03:30<04:09,  1.55s/it]predicting train subjects:  44%|████▍     | 125/285 [03:31<04:03,  1.52s/it]predicting train subjects:  44%|████▍     | 126/285 [03:33<03:56,  1.49s/it]predicting train subjects:  45%|████▍     | 127/285 [03:34<03:51,  1.47s/it]predicting train subjects:  45%|████▍     | 128/285 [03:36<03:58,  1.52s/it]predicting train subjects:  45%|████▌     | 129/285 [03:37<03:55,  1.51s/it]predicting train subjects:  46%|████▌     | 130/285 [03:39<03:48,  1.47s/it]predicting train subjects:  46%|████▌     | 131/285 [03:40<03:43,  1.45s/it]predicting train subjects:  46%|████▋     | 132/285 [03:41<03:46,  1.48s/it]predicting train subjects:  47%|████▋     | 133/285 [03:43<03:41,  1.46s/it]predicting train subjects:  47%|████▋     | 134/285 [03:44<03:36,  1.43s/it]predicting train subjects:  47%|████▋     | 135/285 [03:46<03:32,  1.42s/it]predicting train subjects:  48%|████▊     | 136/285 [03:47<03:28,  1.40s/it]predicting train subjects:  48%|████▊     | 137/285 [03:48<03:32,  1.44s/it]predicting train subjects:  48%|████▊     | 138/285 [03:50<03:26,  1.40s/it]predicting train subjects:  49%|████▉     | 139/285 [03:51<03:30,  1.44s/it]predicting train subjects:  49%|████▉     | 140/285 [03:53<03:33,  1.47s/it]predicting train subjects:  49%|████▉     | 141/285 [03:54<03:26,  1.43s/it]predicting train subjects:  50%|████▉     | 142/285 [03:56<03:22,  1.41s/it]predicting train subjects:  50%|█████     | 143/285 [03:57<03:20,  1.41s/it]predicting train subjects:  51%|█████     | 144/285 [03:59<03:24,  1.45s/it]predicting train subjects:  51%|█████     | 145/285 [04:00<03:24,  1.46s/it]predicting train subjects:  51%|█████     | 146/285 [04:02<03:26,  1.48s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:03<03:20,  1.45s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:04<03:22,  1.48s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:06<03:17,  1.45s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:07<03:14,  1.44s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:09<03:16,  1.47s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:10<03:10,  1.43s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:12<03:05,  1.41s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:13<03:11,  1.46s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:15<03:10,  1.47s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:16<03:16,  1.53s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:18<03:14,  1.52s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:19<03:10,  1.50s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:21<03:05,  1.47s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:22<03:00,  1.45s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:24<03:06,  1.50s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:25<03:02,  1.49s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:27<03:04,  1.51s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:28<02:59,  1.48s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:29<02:54,  1.46s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:31<02:55,  1.47s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:32<02:54,  1.48s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:34<02:47,  1.43s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:35<02:48,  1.45s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:37<02:42,  1.42s/it]predicting train subjects:  60%|██████    | 171/285 [04:38<02:40,  1.41s/it]predicting train subjects:  60%|██████    | 172/285 [04:39<02:36,  1.38s/it]predicting train subjects:  61%|██████    | 173/285 [04:41<02:34,  1.38s/it]predicting train subjects:  61%|██████    | 174/285 [04:42<02:32,  1.38s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:44<02:35,  1.42s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:45<02:39,  1.46s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:47<02:35,  1.44s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:48<02:28,  1.38s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:49<02:25,  1.38s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:51<02:33,  1.46s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:52<02:34,  1.49s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:54<02:36,  1.52s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:55<02:31,  1.48s/it]predicting train subjects:  65%|██████▍   | 184/285 [04:57<02:24,  1.43s/it]predicting train subjects:  65%|██████▍   | 185/285 [04:58<02:20,  1.41s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:00<02:28,  1.50s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:01<02:34,  1.57s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:03<02:37,  1.62s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:05<02:26,  1.52s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:06<02:21,  1.49s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:07<02:22,  1.52s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:09<02:22,  1.53s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:10<02:15,  1.48s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:12<02:12,  1.45s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:13<02:06,  1.40s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:15<02:16,  1.53s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:17<02:20,  1.60s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:18<02:22,  1.64s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:20<02:11,  1.53s/it]predicting train subjects:  70%|███████   | 200/285 [05:21<02:05,  1.48s/it]predicting train subjects:  71%|███████   | 201/285 [05:23<02:10,  1.56s/it]predicting train subjects:  71%|███████   | 202/285 [05:24<02:10,  1.58s/it]predicting train subjects:  71%|███████   | 203/285 [05:26<02:09,  1.58s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:27<01:59,  1.48s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:29<01:55,  1.44s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:30<01:51,  1.41s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:32<01:57,  1.51s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:33<02:02,  1.59s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:35<02:02,  1.61s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:36<01:53,  1.51s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:38<01:48,  1.47s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:39<01:50,  1.51s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:41<01:50,  1.53s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:42<01:46,  1.50s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:44<01:50,  1.57s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:46<01:44,  1.52s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:47<01:48,  1.59s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:49<01:48,  1.61s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:51<01:47,  1.64s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:52<01:40,  1.55s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:53<01:35,  1.50s/it]predicting train subjects:  78%|███████▊  | 222/285 [05:55<01:36,  1.52s/it]predicting train subjects:  78%|███████▊  | 223/285 [05:56<01:31,  1.47s/it]predicting train subjects:  79%|███████▊  | 224/285 [05:58<01:28,  1.45s/it]predicting train subjects:  79%|███████▉  | 225/285 [05:59<01:24,  1.41s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:01<01:30,  1.53s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:03<01:32,  1.59s/it]predicting train subjects:  80%|████████  | 228/285 [06:04<01:33,  1.64s/it]predicting train subjects:  80%|████████  | 229/285 [06:06<01:30,  1.61s/it]predicting train subjects:  81%|████████  | 230/285 [06:07<01:23,  1.53s/it]predicting train subjects:  81%|████████  | 231/285 [06:09<01:20,  1.48s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:10<01:20,  1.52s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:11<01:16,  1.46s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:13<01:20,  1.57s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:15<01:14,  1.49s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:16<01:16,  1.55s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:18<01:18,  1.64s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:20<01:17,  1.66s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:21<01:15,  1.64s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:23<01:10,  1.57s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:24<01:07,  1.52s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:26<01:03,  1.48s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:27<00:59,  1.43s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:29<01:02,  1.53s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:30<00:58,  1.47s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:32<01:00,  1.56s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:33<00:59,  1.57s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:35<00:58,  1.58s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:36<00:54,  1.52s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:38<00:52,  1.50s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:39<00:50,  1.47s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:41<00:47,  1.43s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:42<00:48,  1.53s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:44<00:50,  1.62s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:46<00:48,  1.60s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:47<00:44,  1.52s/it]predicting train subjects:  90%|█████████ | 257/285 [06:49<00:42,  1.50s/it]predicting train subjects:  91%|█████████ | 258/285 [06:50<00:42,  1.56s/it]predicting train subjects:  91%|█████████ | 259/285 [06:52<00:40,  1.57s/it]predicting train subjects:  91%|█████████ | 260/285 [06:53<00:37,  1.48s/it]predicting train subjects:  92%|█████████▏| 261/285 [06:54<00:34,  1.45s/it]predicting train subjects:  92%|█████████▏| 262/285 [06:56<00:32,  1.43s/it]predicting train subjects:  92%|█████████▏| 263/285 [06:57<00:30,  1.39s/it]predicting train subjects:  93%|█████████▎| 264/285 [06:59<00:31,  1.49s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:01<00:31,  1.57s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:02<00:28,  1.50s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:03<00:26,  1.48s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:05<00:26,  1.57s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:07<00:25,  1.59s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:08<00:22,  1.51s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:09<00:20,  1.45s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:11<00:19,  1.51s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:12<00:17,  1.45s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:14<00:15,  1.41s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:16<00:15,  1.52s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:17<00:14,  1.58s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:19<00:11,  1.50s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:20<00:10,  1.44s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:21<00:08,  1.47s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:23<00:07,  1.41s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:24<00:05,  1.39s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:25<00:04,  1.35s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:27<00:02,  1.47s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:29<00:01,  1.54s/it]predicting train subjects: 100%|██████████| 285/285 [07:30<00:00,  1.59s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:52,  1.66s/it]Loading train:   1%|          | 2/285 [00:02<07:05,  1.50s/it]Loading train:   1%|          | 3/285 [00:04<06:51,  1.46s/it]Loading train:   1%|▏         | 4/285 [00:05<06:18,  1.35s/it]Loading train:   2%|▏         | 5/285 [00:06<06:36,  1.42s/it]Loading train:   2%|▏         | 6/285 [00:08<06:17,  1.35s/it]Loading train:   2%|▏         | 7/285 [00:09<06:32,  1.41s/it]Loading train:   3%|▎         | 8/285 [00:10<06:21,  1.38s/it]Loading train:   3%|▎         | 9/285 [00:12<06:47,  1.48s/it]Loading train:   4%|▎         | 10/285 [00:13<05:57,  1.30s/it]Loading train:   4%|▍         | 11/285 [00:14<05:46,  1.26s/it]Loading train:   4%|▍         | 12/285 [00:15<05:44,  1.26s/it]Loading train:   5%|▍         | 13/285 [00:16<05:14,  1.16s/it]Loading train:   5%|▍         | 14/285 [00:17<04:58,  1.10s/it]Loading train:   5%|▌         | 15/285 [00:18<04:48,  1.07s/it]Loading train:   6%|▌         | 16/285 [00:19<04:33,  1.02s/it]Loading train:   6%|▌         | 17/285 [00:20<04:09,  1.07it/s]Loading train:   6%|▋         | 18/285 [00:21<04:04,  1.09it/s]Loading train:   7%|▋         | 19/285 [00:22<03:48,  1.16it/s]Loading train:   7%|▋         | 20/285 [00:22<03:53,  1.13it/s]Loading train:   7%|▋         | 21/285 [00:23<03:56,  1.12it/s]Loading train:   8%|▊         | 22/285 [00:24<03:49,  1.15it/s]Loading train:   8%|▊         | 23/285 [00:25<03:46,  1.16it/s]Loading train:   8%|▊         | 24/285 [00:26<03:56,  1.10it/s]Loading train:   9%|▉         | 25/285 [00:27<04:11,  1.03it/s]Loading train:   9%|▉         | 26/285 [00:28<04:15,  1.01it/s]Loading train:   9%|▉         | 27/285 [00:29<04:12,  1.02it/s]Loading train:  10%|▉         | 28/285 [00:30<04:22,  1.02s/it]Loading train:  10%|█         | 29/285 [00:31<04:24,  1.03s/it]Loading train:  11%|█         | 30/285 [00:32<04:12,  1.01it/s]Loading train:  11%|█         | 31/285 [00:33<04:28,  1.06s/it]Loading train:  11%|█         | 32/285 [00:34<04:15,  1.01s/it]Loading train:  12%|█▏        | 33/285 [00:35<04:11,  1.00it/s]Loading train:  12%|█▏        | 34/285 [00:37<04:28,  1.07s/it]Loading train:  12%|█▏        | 35/285 [00:38<04:38,  1.11s/it]Loading train:  13%|█▎        | 36/285 [00:39<04:22,  1.05s/it]Loading train:  13%|█▎        | 37/285 [00:40<04:19,  1.05s/it]Loading train:  13%|█▎        | 38/285 [00:41<04:31,  1.10s/it]Loading train:  14%|█▎        | 39/285 [00:42<04:15,  1.04s/it]Loading train:  14%|█▍        | 40/285 [00:43<04:08,  1.02s/it]Loading train:  14%|█▍        | 41/285 [00:44<04:04,  1.00s/it]Loading train:  15%|█▍        | 42/285 [00:45<03:46,  1.07it/s]Loading train:  15%|█▌        | 43/285 [00:45<03:44,  1.08it/s]Loading train:  15%|█▌        | 44/285 [00:46<03:53,  1.03it/s]Loading train:  16%|█▌        | 45/285 [00:47<03:42,  1.08it/s]Loading train:  16%|█▌        | 46/285 [00:48<03:41,  1.08it/s]Loading train:  16%|█▋        | 47/285 [00:49<03:35,  1.11it/s]Loading train:  17%|█▋        | 48/285 [00:50<03:36,  1.09it/s]Loading train:  17%|█▋        | 49/285 [00:51<03:38,  1.08it/s]Loading train:  18%|█▊        | 50/285 [00:52<03:37,  1.08it/s]Loading train:  18%|█▊        | 51/285 [00:53<03:43,  1.05it/s]Loading train:  18%|█▊        | 52/285 [00:54<03:41,  1.05it/s]Loading train:  19%|█▊        | 53/285 [00:55<03:50,  1.00it/s]Loading train:  19%|█▉        | 54/285 [00:56<03:55,  1.02s/it]Loading train:  19%|█▉        | 55/285 [00:57<03:42,  1.03it/s]Loading train:  20%|█▉        | 56/285 [00:58<03:40,  1.04it/s]Loading train:  20%|██        | 57/285 [00:59<03:24,  1.12it/s]Loading train:  20%|██        | 58/285 [00:59<03:22,  1.12it/s]Loading train:  21%|██        | 59/285 [01:00<03:25,  1.10it/s]Loading train:  21%|██        | 60/285 [01:01<03:30,  1.07it/s]Loading train:  21%|██▏       | 61/285 [01:02<03:15,  1.15it/s]Loading train:  22%|██▏       | 62/285 [01:03<03:23,  1.09it/s]Loading train:  22%|██▏       | 63/285 [01:04<03:18,  1.12it/s]Loading train:  22%|██▏       | 64/285 [01:05<03:39,  1.01it/s]Loading train:  23%|██▎       | 65/285 [01:07<04:15,  1.16s/it]Loading train:  23%|██▎       | 66/285 [01:08<04:23,  1.20s/it]Loading train:  24%|██▎       | 67/285 [01:09<04:06,  1.13s/it]Loading train:  24%|██▍       | 68/285 [01:10<03:48,  1.05s/it]Loading train:  24%|██▍       | 69/285 [01:11<03:46,  1.05s/it]Loading train:  25%|██▍       | 70/285 [01:12<03:42,  1.04s/it]Loading train:  25%|██▍       | 71/285 [01:13<03:42,  1.04s/it]Loading train:  25%|██▌       | 72/285 [01:14<03:25,  1.04it/s]Loading train:  26%|██▌       | 73/285 [01:15<03:18,  1.07it/s]Loading train:  26%|██▌       | 74/285 [01:16<03:15,  1.08it/s]Loading train:  26%|██▋       | 75/285 [01:17<03:18,  1.06it/s]Loading train:  27%|██▋       | 76/285 [01:18<03:19,  1.05it/s]Loading train:  27%|██▋       | 77/285 [01:18<03:14,  1.07it/s]Loading train:  27%|██▋       | 78/285 [01:19<03:04,  1.12it/s]Loading train:  28%|██▊       | 79/285 [01:20<03:02,  1.13it/s]Loading train:  28%|██▊       | 80/285 [01:21<02:55,  1.16it/s]Loading train:  28%|██▊       | 81/285 [01:22<02:55,  1.17it/s]Loading train:  29%|██▉       | 82/285 [01:23<02:54,  1.16it/s]Loading train:  29%|██▉       | 83/285 [01:24<02:59,  1.13it/s]Loading train:  29%|██▉       | 84/285 [01:24<02:54,  1.15it/s]Loading train:  30%|██▉       | 85/285 [01:25<02:54,  1.15it/s]Loading train:  30%|███       | 86/285 [01:26<02:56,  1.13it/s]Loading train:  31%|███       | 87/285 [01:27<02:58,  1.11it/s]Loading train:  31%|███       | 88/285 [01:28<02:53,  1.14it/s]Loading train:  31%|███       | 89/285 [01:29<02:48,  1.16it/s]Loading train:  32%|███▏      | 90/285 [01:30<02:59,  1.09it/s]Loading train:  32%|███▏      | 91/285 [01:31<02:49,  1.14it/s]Loading train:  32%|███▏      | 92/285 [01:32<02:53,  1.11it/s]Loading train:  33%|███▎      | 93/285 [01:32<02:50,  1.12it/s]Loading train:  33%|███▎      | 94/285 [01:33<02:49,  1.13it/s]Loading train:  33%|███▎      | 95/285 [01:34<02:55,  1.09it/s]Loading train:  34%|███▎      | 96/285 [01:35<02:52,  1.10it/s]Loading train:  34%|███▍      | 97/285 [01:36<02:57,  1.06it/s]Loading train:  34%|███▍      | 98/285 [01:37<02:55,  1.07it/s]Loading train:  35%|███▍      | 99/285 [01:38<02:47,  1.11it/s]Loading train:  35%|███▌      | 100/285 [01:39<02:53,  1.06it/s]Loading train:  35%|███▌      | 101/285 [01:40<02:47,  1.10it/s]Loading train:  36%|███▌      | 102/285 [01:41<02:51,  1.07it/s]Loading train:  36%|███▌      | 103/285 [01:42<02:43,  1.11it/s]Loading train:  36%|███▋      | 104/285 [01:43<02:42,  1.11it/s]Loading train:  37%|███▋      | 105/285 [01:43<02:41,  1.11it/s]Loading train:  37%|███▋      | 106/285 [01:44<02:38,  1.13it/s]Loading train:  38%|███▊      | 107/285 [01:45<02:36,  1.14it/s]Loading train:  38%|███▊      | 108/285 [01:46<02:27,  1.20it/s]Loading train:  38%|███▊      | 109/285 [01:47<02:28,  1.19it/s]Loading train:  39%|███▊      | 110/285 [01:48<02:33,  1.14it/s]Loading train:  39%|███▉      | 111/285 [01:49<02:37,  1.10it/s]Loading train:  39%|███▉      | 112/285 [01:50<02:42,  1.06it/s]Loading train:  40%|███▉      | 113/285 [01:51<02:48,  1.02it/s]Loading train:  40%|████      | 114/285 [01:52<02:42,  1.05it/s]Loading train:  40%|████      | 115/285 [01:52<02:36,  1.08it/s]Loading train:  41%|████      | 116/285 [01:54<02:41,  1.05it/s]Loading train:  41%|████      | 117/285 [01:54<02:35,  1.08it/s]Loading train:  41%|████▏     | 118/285 [01:55<02:24,  1.15it/s]Loading train:  42%|████▏     | 119/285 [01:56<02:31,  1.09it/s]Loading train:  42%|████▏     | 120/285 [01:57<02:25,  1.13it/s]Loading train:  42%|████▏     | 121/285 [01:58<02:46,  1.02s/it]Loading train:  43%|████▎     | 122/285 [01:59<02:53,  1.06s/it]Loading train:  43%|████▎     | 123/285 [02:01<02:55,  1.08s/it]Loading train:  44%|████▎     | 124/285 [02:01<02:43,  1.02s/it]Loading train:  44%|████▍     | 125/285 [02:02<02:30,  1.07it/s]Loading train:  44%|████▍     | 126/285 [02:03<02:19,  1.14it/s]Loading train:  45%|████▍     | 127/285 [02:04<02:10,  1.21it/s]Loading train:  45%|████▍     | 128/285 [02:04<02:11,  1.19it/s]Loading train:  45%|████▌     | 129/285 [02:05<02:06,  1.23it/s]Loading train:  46%|████▌     | 130/285 [02:06<02:05,  1.24it/s]Loading train:  46%|████▌     | 131/285 [02:07<02:02,  1.26it/s]Loading train:  46%|████▋     | 132/285 [02:08<02:02,  1.25it/s]Loading train:  47%|████▋     | 133/285 [02:08<02:01,  1.25it/s]Loading train:  47%|████▋     | 134/285 [02:09<02:03,  1.23it/s]Loading train:  47%|████▋     | 135/285 [02:10<01:59,  1.25it/s]Loading train:  48%|████▊     | 136/285 [02:11<01:54,  1.30it/s]Loading train:  48%|████▊     | 137/285 [02:12<01:59,  1.24it/s]Loading train:  48%|████▊     | 138/285 [02:12<01:55,  1.27it/s]Loading train:  49%|████▉     | 139/285 [02:13<01:56,  1.25it/s]Loading train:  49%|████▉     | 140/285 [02:14<01:54,  1.27it/s]Loading train:  49%|████▉     | 141/285 [02:15<01:47,  1.33it/s]Loading train:  50%|████▉     | 142/285 [02:16<01:53,  1.26it/s]Loading train:  50%|█████     | 143/285 [02:16<01:49,  1.29it/s]Loading train:  51%|█████     | 144/285 [02:17<01:52,  1.26it/s]Loading train:  51%|█████     | 145/285 [02:18<01:50,  1.26it/s]Loading train:  51%|█████     | 146/285 [02:19<01:52,  1.24it/s]Loading train:  52%|█████▏    | 147/285 [02:20<01:52,  1.23it/s]Loading train:  52%|█████▏    | 148/285 [02:20<01:55,  1.19it/s]Loading train:  52%|█████▏    | 149/285 [02:21<01:54,  1.19it/s]Loading train:  53%|█████▎    | 150/285 [02:22<01:47,  1.26it/s]Loading train:  53%|█████▎    | 151/285 [02:23<01:50,  1.21it/s]Loading train:  53%|█████▎    | 152/285 [02:24<01:49,  1.22it/s]Loading train:  54%|█████▎    | 153/285 [02:25<01:49,  1.21it/s]Loading train:  54%|█████▍    | 154/285 [02:25<01:51,  1.18it/s]Loading train:  54%|█████▍    | 155/285 [02:26<01:45,  1.23it/s]Loading train:  55%|█████▍    | 156/285 [02:27<01:43,  1.25it/s]Loading train:  55%|█████▌    | 157/285 [02:28<01:46,  1.20it/s]Loading train:  55%|█████▌    | 158/285 [02:29<01:39,  1.28it/s]Loading train:  56%|█████▌    | 159/285 [02:29<01:37,  1.30it/s]Loading train:  56%|█████▌    | 160/285 [02:30<01:34,  1.33it/s]Loading train:  56%|█████▋    | 161/285 [02:31<01:38,  1.26it/s]Loading train:  57%|█████▋    | 162/285 [02:32<01:37,  1.26it/s]Loading train:  57%|█████▋    | 163/285 [02:32<01:37,  1.25it/s]Loading train:  58%|█████▊    | 164/285 [02:33<01:36,  1.25it/s]Loading train:  58%|█████▊    | 165/285 [02:34<01:33,  1.28it/s]Loading train:  58%|█████▊    | 166/285 [02:35<01:35,  1.24it/s]Loading train:  59%|█████▊    | 167/285 [02:36<01:33,  1.26it/s]Loading train:  59%|█████▉    | 168/285 [02:37<01:36,  1.22it/s]Loading train:  59%|█████▉    | 169/285 [02:37<01:31,  1.26it/s]Loading train:  60%|█████▉    | 170/285 [02:38<01:29,  1.28it/s]Loading train:  60%|██████    | 171/285 [02:39<01:24,  1.35it/s]Loading train:  60%|██████    | 172/285 [02:39<01:23,  1.35it/s]Loading train:  61%|██████    | 173/285 [02:40<01:20,  1.38it/s]Loading train:  61%|██████    | 174/285 [02:41<01:16,  1.44it/s]Loading train:  61%|██████▏   | 175/285 [02:42<01:22,  1.33it/s]Loading train:  62%|██████▏   | 176/285 [02:42<01:21,  1.34it/s]Loading train:  62%|██████▏   | 177/285 [02:43<01:18,  1.38it/s]Loading train:  62%|██████▏   | 178/285 [02:44<01:15,  1.41it/s]Loading train:  63%|██████▎   | 179/285 [02:44<01:14,  1.43it/s]Loading train:  63%|██████▎   | 180/285 [02:45<01:22,  1.28it/s]Loading train:  64%|██████▎   | 181/285 [02:46<01:29,  1.16it/s]Loading train:  64%|██████▍   | 182/285 [02:47<01:28,  1.16it/s]Loading train:  64%|██████▍   | 183/285 [02:48<01:29,  1.14it/s]Loading train:  65%|██████▍   | 184/285 [02:49<01:24,  1.19it/s]Loading train:  65%|██████▍   | 185/285 [02:50<01:21,  1.22it/s]Loading train:  65%|██████▌   | 186/285 [02:51<01:29,  1.11it/s]Loading train:  66%|██████▌   | 187/285 [02:52<01:28,  1.11it/s]Loading train:  66%|██████▌   | 188/285 [02:53<01:28,  1.10it/s]Loading train:  66%|██████▋   | 189/285 [02:53<01:21,  1.18it/s]Loading train:  67%|██████▋   | 190/285 [02:54<01:19,  1.19it/s]Loading train:  67%|██████▋   | 191/285 [02:55<01:17,  1.21it/s]Loading train:  67%|██████▋   | 192/285 [02:56<01:15,  1.23it/s]Loading train:  68%|██████▊   | 193/285 [02:57<01:16,  1.20it/s]Loading train:  68%|██████▊   | 194/285 [02:57<01:11,  1.28it/s]Loading train:  68%|██████▊   | 195/285 [02:58<01:08,  1.31it/s]Loading train:  69%|██████▉   | 196/285 [02:59<01:12,  1.23it/s]Loading train:  69%|██████▉   | 197/285 [03:00<01:15,  1.16it/s]Loading train:  69%|██████▉   | 198/285 [03:01<01:16,  1.14it/s]Loading train:  70%|██████▉   | 199/285 [03:01<01:11,  1.20it/s]Loading train:  70%|███████   | 200/285 [03:02<01:08,  1.24it/s]Loading train:  71%|███████   | 201/285 [03:03<01:13,  1.15it/s]Loading train:  71%|███████   | 202/285 [03:04<01:12,  1.15it/s]Loading train:  71%|███████   | 203/285 [03:05<01:09,  1.18it/s]Loading train:  72%|███████▏  | 204/285 [03:06<01:06,  1.22it/s]Loading train:  72%|███████▏  | 205/285 [03:06<01:04,  1.25it/s]Loading train:  72%|███████▏  | 206/285 [03:07<01:01,  1.28it/s]Loading train:  73%|███████▎  | 207/285 [03:08<01:05,  1.20it/s]Loading train:  73%|███████▎  | 208/285 [03:09<01:07,  1.14it/s]Loading train:  73%|███████▎  | 209/285 [03:10<01:09,  1.09it/s]Loading train:  74%|███████▎  | 210/285 [03:11<01:04,  1.16it/s]Loading train:  74%|███████▍  | 211/285 [03:12<01:02,  1.19it/s]Loading train:  74%|███████▍  | 212/285 [03:12<01:00,  1.21it/s]Loading train:  75%|███████▍  | 213/285 [03:13<01:00,  1.20it/s]Loading train:  75%|███████▌  | 214/285 [03:14<00:56,  1.25it/s]Loading train:  75%|███████▌  | 215/285 [03:15<00:59,  1.17it/s]Loading train:  76%|███████▌  | 216/285 [03:16<00:55,  1.25it/s]Loading train:  76%|███████▌  | 217/285 [03:17<00:57,  1.18it/s]Loading train:  76%|███████▋  | 218/285 [03:18<00:58,  1.14it/s]Loading train:  77%|███████▋  | 219/285 [03:19<01:00,  1.09it/s]Loading train:  77%|███████▋  | 220/285 [03:19<00:58,  1.12it/s]Loading train:  78%|███████▊  | 221/285 [03:20<00:53,  1.19it/s]Loading train:  78%|███████▊  | 222/285 [03:21<00:52,  1.20it/s]Loading train:  78%|███████▊  | 223/285 [03:22<00:50,  1.23it/s]Loading train:  79%|███████▊  | 224/285 [03:22<00:48,  1.25it/s]Loading train:  79%|███████▉  | 225/285 [03:23<00:46,  1.30it/s]Loading train:  79%|███████▉  | 226/285 [03:24<00:48,  1.20it/s]Loading train:  80%|███████▉  | 227/285 [03:25<00:50,  1.14it/s]Loading train:  80%|████████  | 228/285 [03:26<00:53,  1.07it/s]Loading train:  80%|████████  | 229/285 [03:27<00:50,  1.11it/s]Loading train:  81%|████████  | 230/285 [03:28<00:46,  1.17it/s]Loading train:  81%|████████  | 231/285 [03:29<00:44,  1.21it/s]Loading train:  81%|████████▏ | 232/285 [03:29<00:46,  1.15it/s]Loading train:  82%|████████▏ | 233/285 [03:30<00:43,  1.19it/s]Loading train:  82%|████████▏ | 234/285 [03:31<00:44,  1.15it/s]Loading train:  82%|████████▏ | 235/285 [03:32<00:41,  1.20it/s]Loading train:  83%|████████▎ | 236/285 [03:33<00:41,  1.18it/s]Loading train:  83%|████████▎ | 237/285 [03:34<00:42,  1.12it/s]Loading train:  84%|████████▎ | 238/285 [03:35<00:42,  1.11it/s]Loading train:  84%|████████▍ | 239/285 [03:36<00:39,  1.15it/s]Loading train:  84%|████████▍ | 240/285 [03:36<00:37,  1.19it/s]Loading train:  85%|████████▍ | 241/285 [03:37<00:37,  1.19it/s]Loading train:  85%|████████▍ | 242/285 [03:38<00:37,  1.16it/s]Loading train:  85%|████████▌ | 243/285 [03:39<00:34,  1.23it/s]Loading train:  86%|████████▌ | 244/285 [03:40<00:34,  1.17it/s]Loading train:  86%|████████▌ | 245/285 [03:41<00:33,  1.20it/s]Loading train:  86%|████████▋ | 246/285 [03:41<00:34,  1.14it/s]Loading train:  87%|████████▋ | 247/285 [03:42<00:34,  1.11it/s]Loading train:  87%|████████▋ | 248/285 [03:43<00:33,  1.10it/s]Loading train:  87%|████████▋ | 249/285 [03:44<00:32,  1.09it/s]Loading train:  88%|████████▊ | 250/285 [03:45<00:30,  1.13it/s]Loading train:  88%|████████▊ | 251/285 [03:46<00:29,  1.17it/s]Loading train:  88%|████████▊ | 252/285 [03:47<00:28,  1.16it/s]Loading train:  89%|████████▉ | 253/285 [03:48<00:31,  1.02it/s]Loading train:  89%|████████▉ | 254/285 [03:49<00:32,  1.04s/it]Loading train:  89%|████████▉ | 255/285 [03:50<00:31,  1.03s/it]Loading train:  90%|████████▉ | 256/285 [03:51<00:29,  1.00s/it]Loading train:  90%|█████████ | 257/285 [03:52<00:27,  1.01it/s]Loading train:  91%|█████████ | 258/285 [03:53<00:27,  1.02s/it]Loading train:  91%|█████████ | 259/285 [03:55<00:29,  1.12s/it]Loading train:  91%|█████████ | 260/285 [03:56<00:27,  1.10s/it]Loading train:  92%|█████████▏| 261/285 [03:57<00:26,  1.12s/it]Loading train:  92%|█████████▏| 262/285 [03:58<00:25,  1.10s/it]Loading train:  92%|█████████▏| 263/285 [03:59<00:22,  1.02s/it]Loading train:  93%|█████████▎| 264/285 [04:00<00:21,  1.01s/it]Loading train:  93%|█████████▎| 265/285 [04:01<00:20,  1.04s/it]Loading train:  93%|█████████▎| 266/285 [04:02<00:19,  1.02s/it]Loading train:  94%|█████████▎| 267/285 [04:03<00:18,  1.01s/it]Loading train:  94%|█████████▍| 268/285 [04:04<00:17,  1.03s/it]Loading train:  94%|█████████▍| 269/285 [04:05<00:15,  1.01it/s]Loading train:  95%|█████████▍| 270/285 [04:06<00:16,  1.07s/it]Loading train:  95%|█████████▌| 271/285 [04:07<00:15,  1.10s/it]Loading train:  95%|█████████▌| 272/285 [04:08<00:14,  1.10s/it]Loading train:  96%|█████████▌| 273/285 [04:09<00:12,  1.06s/it]Loading train:  96%|█████████▌| 274/285 [04:10<00:11,  1.06s/it]Loading train:  96%|█████████▋| 275/285 [04:11<00:10,  1.08s/it]Loading train:  97%|█████████▋| 276/285 [04:13<00:10,  1.14s/it]Loading train:  97%|█████████▋| 277/285 [04:14<00:08,  1.10s/it]Loading train:  98%|█████████▊| 278/285 [04:15<00:07,  1.04s/it]Loading train:  98%|█████████▊| 279/285 [04:16<00:06,  1.03s/it]Loading train:  98%|█████████▊| 280/285 [04:16<00:04,  1.03it/s]Loading train:  99%|█████████▊| 281/285 [04:17<00:03,  1.01it/s]Loading train:  99%|█████████▉| 282/285 [04:18<00:02,  1.02it/s]Loading train:  99%|█████████▉| 283/285 [04:20<00:02,  1.07s/it]Loading train: 100%|█████████▉| 284/285 [04:21<00:01,  1.08s/it]Loading train: 100%|██████████| 285/285 [04:22<00:00,  1.15s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   3%|▎         | 9/285 [00:00<00:03, 81.11it/s]concatenating: train:   6%|▌         | 16/285 [00:00<00:03, 77.31it/s]concatenating: train:   9%|▉         | 26/285 [00:00<00:03, 82.23it/s]concatenating: train:  11%|█         | 32/285 [00:00<00:03, 70.86it/s]concatenating: train:  14%|█▎        | 39/285 [00:00<00:03, 68.13it/s]concatenating: train:  18%|█▊        | 50/285 [00:00<00:03, 76.19it/s]concatenating: train:  21%|██        | 60/285 [00:00<00:02, 81.35it/s]concatenating: train:  24%|██▍       | 68/285 [00:00<00:02, 74.60it/s]concatenating: train:  31%|███       | 89/285 [00:00<00:02, 92.43it/s]concatenating: train:  39%|███▉      | 112/285 [00:01<00:01, 112.42it/s]concatenating: train:  46%|████▋     | 132/285 [00:01<00:01, 128.34it/s]concatenating: train:  56%|█████▌    | 159/285 [00:01<00:00, 152.13it/s]concatenating: train:  63%|██████▎   | 179/285 [00:01<00:00, 157.16it/s]concatenating: train:  69%|██████▉   | 198/285 [00:01<00:00, 120.37it/s]concatenating: train:  75%|███████▌  | 214/285 [00:01<00:00, 122.85it/s]concatenating: train:  80%|████████  | 229/285 [00:01<00:00, 123.50it/s]concatenating: train:  85%|████████▌ | 243/285 [00:02<00:00, 122.64it/s]concatenating: train:  91%|█████████ | 258/285 [00:02<00:00, 128.87it/s]concatenating: train: 100%|██████████| 285/285 [00:02<00:00, 129.37it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.39s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.42s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.35s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 98.83it/s]2019-07-09 09:59:56.702071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-09 09:59:56.702202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-09 09:59:56.702249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-09 09:59:56.702260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-09 09:59:56.702896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12743 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.36it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.29it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  5.84it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.50it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.49it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.39it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  6.57it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.50it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.87it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.11it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.84it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.38it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.60it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.69it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.50it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.83it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.70it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.15it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.66it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 30)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 31)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 30)   8400        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 30)   8130        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 30)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 40, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 60)   16260       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 60)   32460       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 90)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 90)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 120)  97320       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 120)  129720      activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 120)  480         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 120)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 210)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 210)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 60)   50460       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 60)   81060       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 60)   32460       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 60)   240         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 60)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 210)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 40, 210)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 30)   25230       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 60)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 30)   16230       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 30)   8130        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 30)   120         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 30)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 90)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 80, 90)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 30)   24330       dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 80, 30)   120         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 80, 30)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 80, 30)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 80, 120)  0           dropout_6[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 80, 13)   1573        concatenate_8[0][0]              
==================================================================================================
Total params: 534,703
Trainable params: 142,363
Non-trainable params: 392,340
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 31s - loss: 13458.0101 - acc: 0.6511 - mDice: 0.1364 - val_loss: 9013.3125 - val_acc: 0.9035 - val_mDice: 0.2000

Epoch 00001: val_mDice improved from -inf to 0.20000, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 23s - loss: 4303.0393 - acc: 0.8714 - mDice: 0.4234 - val_loss: 4517.4390 - val_acc: 0.9065 - val_mDice: 0.3918

Epoch 00002: val_mDice improved from 0.20000 to 0.39179, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 23s - loss: 3223.2153 - acc: 0.8739 - mDice: 0.5213 - val_loss: 3583.2748 - val_acc: 0.9081 - val_mDice: 0.4659

Epoch 00003: val_mDice improved from 0.39179 to 0.46588, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 22s - loss: 2793.4235 - acc: 0.8771 - mDice: 0.5684 - val_loss: 3712.3448 - val_acc: 0.9090 - val_mDice: 0.4609

Epoch 00004: val_mDice did not improve from 0.46588
Epoch 5/300
 - 22s - loss: 2565.0994 - acc: 0.8807 - mDice: 0.5954 - val_loss: 3212.5494 - val_acc: 0.9119 - val_mDice: 0.5027

Epoch 00005: val_mDice improved from 0.46588 to 0.50271, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 23s - loss: 2392.8801 - acc: 0.8844 - mDice: 0.6163 - val_loss: 3548.8146 - val_acc: 0.9139 - val_mDice: 0.4738

Epoch 00006: val_mDice did not improve from 0.50271
Epoch 7/300
 - 22s - loss: 2292.1640 - acc: 0.8875 - mDice: 0.6292 - val_loss: 3067.4093 - val_acc: 0.9193 - val_mDice: 0.5195

Epoch 00007: val_mDice improved from 0.50271 to 0.51953, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 22s - loss: 2183.4759 - acc: 0.8900 - mDice: 0.6432 - val_loss: 3200.5423 - val_acc: 0.9183 - val_mDice: 0.5067

Epoch 00008: val_mDice did not improve from 0.51953
Epoch 9/300
 - 23s - loss: 2128.5326 - acc: 0.8928 - mDice: 0.6505 - val_loss: 3367.9509 - val_acc: 0.9225 - val_mDice: 0.4918

Epoch 00009: val_mDice did not improve from 0.51953
Epoch 10/300
 - 22s - loss: 2060.8727 - acc: 0.8955 - mDice: 0.6593 - val_loss: 3006.7389 - val_acc: 0.9248 - val_mDice: 0.5242

Epoch 00010: val_mDice improved from 0.51953 to 0.52424, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 22s - loss: 1999.0042 - acc: 0.8975 - mDice: 0.6675 - val_loss: 3238.5527 - val_acc: 0.9212 - val_mDice: 0.5015

Epoch 00011: val_mDice did not improve from 0.52424
Epoch 12/300
 - 22s - loss: 1949.5613 - acc: 0.8992 - mDice: 0.6744 - val_loss: 3054.6150 - val_acc: 0.9235 - val_mDice: 0.5193

Epoch 00012: val_mDice did not improve from 0.52424
Epoch 13/300
 - 23s - loss: 1903.9241 - acc: 0.9015 - mDice: 0.6806 - val_loss: 3268.0115 - val_acc: 0.9223 - val_mDice: 0.4992

Epoch 00013: val_mDice did not improve from 0.52424
Epoch 14/300
 - 23s - loss: 1870.0853 - acc: 0.9035 - mDice: 0.6852 - val_loss: 3094.2612 - val_acc: 0.9270 - val_mDice: 0.5159

Epoch 00014: val_mDice did not improve from 0.52424
Epoch 15/300
 - 22s - loss: 1818.6118 - acc: 0.9054 - mDice: 0.6925 - val_loss: 2989.5716 - val_acc: 0.9336 - val_mDice: 0.5282

Epoch 00015: val_mDice improved from 0.52424 to 0.52821, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 23s - loss: 1783.8588 - acc: 0.9077 - mDice: 0.6973 - val_loss: 2985.5692 - val_acc: 0.9313 - val_mDice: 0.5288

Epoch 00016: val_mDice improved from 0.52821 to 0.52884, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 23s - loss: 1756.7353 - acc: 0.9099 - mDice: 0.7013 - val_loss: 3056.8578 - val_acc: 0.9345 - val_mDice: 0.5218

Epoch 00017: val_mDice did not improve from 0.52884
Epoch 18/300
 - 23s - loss: 1721.1658 - acc: 0.9116 - mDice: 0.7062 - val_loss: 3045.3634 - val_acc: 0.9330 - val_mDice: 0.5205

Epoch 00018: val_mDice did not improve from 0.52884
Epoch 19/300
 - 22s - loss: 1700.9048 - acc: 0.9142 - mDice: 0.7091 - val_loss: 3221.3255 - val_acc: 0.9351 - val_mDice: 0.5057

Epoch 00019: val_mDice did not improve from 0.52884
Epoch 20/300
 - 23s - loss: 1681.8398 - acc: 0.9197 - mDice: 0.7118 - val_loss: 3489.6548 - val_acc: 0.9331 - val_mDice: 0.4818

Epoch 00020: val_mDice did not improve from 0.52884
Epoch 21/300
 - 22s - loss: 1647.8577 - acc: 0.9290 - mDice: 0.7162 - val_loss: 2976.2049 - val_acc: 0.9398 - val_mDice: 0.5270

Epoch 00021: val_mDice did not improve from 0.52884
Epoch 22/300
 - 22s - loss: 1623.7772 - acc: 0.9333 - mDice: 0.7193 - val_loss: 2903.0632 - val_acc: 0.9430 - val_mDice: 0.5371

Epoch 00022: val_mDice improved from 0.52884 to 0.53705, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 23/300
 - 22s - loss: 1606.4167 - acc: 0.9389 - mDice: 0.7210 - val_loss: 3200.1219 - val_acc: 0.9386 - val_mDice: 0.5044

Epoch 00023: val_mDice did not improve from 0.53705
Epoch 24/300
 - 22s - loss: 1575.5202 - acc: 0.9411 - mDice: 0.7249 - val_loss: 3309.2776 - val_acc: 0.9406 - val_mDice: 0.4952

Epoch 00024: val_mDice did not improve from 0.53705
Epoch 25/300
 - 22s - loss: 1554.4559 - acc: 0.9417 - mDice: 0.7278 - val_loss: 3133.5911 - val_acc: 0.9362 - val_mDice: 0.5112

Epoch 00025: val_mDice did not improve from 0.53705
Epoch 26/300
 - 22s - loss: 1539.3663 - acc: 0.9421 - mDice: 0.7300 - val_loss: 3302.9254 - val_acc: 0.9364 - val_mDice: 0.4957

Epoch 00026: val_mDice did not improve from 0.53705
Epoch 27/300
 - 22s - loss: 1535.5828 - acc: 0.9422 - mDice: 0.7307 - val_loss: 3065.7703 - val_acc: 0.9400 - val_mDice: 0.5176

Epoch 00027: val_mDice did not improve from 0.53705
Epoch 28/300
 - 22s - loss: 1508.1852 - acc: 0.9428 - mDice: 0.7346 - val_loss: 3074.9452 - val_acc: 0.9423 - val_mDice: 0.5150

Epoch 00028: val_mDice did not improve from 0.53705
Epoch 29/300
 - 23s - loss: 1489.4485 - acc: 0.9432 - mDice: 0.7373 - val_loss: 2992.5107 - val_acc: 0.9414 - val_mDice: 0.5253

Epoch 00029: val_mDice did not improve from 0.53705
Epoch 30/300
 - 23s - loss: 1479.4154 - acc: 0.9435 - mDice: 0.7389 - val_loss: 2952.8323 - val_acc: 0.9413 - val_mDice: 0.5294

Epoch 00030: val_mDice did not improve from 0.53705
Epoch 31/300
 - 22s - loss: 1462.7013 - acc: 0.9438 - mDice: 0.7413 - val_loss: 2937.4326 - val_acc: 0.9399 - val_mDice: 0.5286

Epoch 00031: val_mDice did not improve from 0.53705
Epoch 32/300
 - 22s - loss: 1450.1507 - acc: 0.9440 - mDice: 0.7433 - val_loss: 2947.6873 - val_acc: 0.9421 - val_mDice: 0.5297

Epoch 00032: val_mDice did not improve from 0.53705
Epoch 33/300
 - 22s - loss: 1437.9624 - acc: 0.9443 - mDice: 0.7451 - val_loss: 3174.3413 - val_acc: 0.9415 - val_mDice: 0.5085

Epoch 00033: val_mDice did not improve from 0.53705
Epoch 34/300
 - 23s - loss: 1428.0463 - acc: 0.9445 - mDice: 0.7466 - val_loss: 3030.1706 - val_acc: 0.9412 - val_mDice: 0.5212

Epoch 00034: val_mDice did not improve from 0.53705
Epoch 35/300
 - 23s - loss: 1415.3970 - acc: 0.9446 - mDice: 0.7485 - val_loss: 3173.3715 - val_acc: 0.9403 - val_mDice: 0.5066

Epoch 00035: val_mDice did not improve from 0.53705
Epoch 36/300
 - 24s - loss: 1399.7459 - acc: 0.9449 - mDice: 0.7508 - val_loss: 3173.0352 - val_acc: 0.9422 - val_mDice: 0.5068

Epoch 00036: val_mDice did not improve from 0.53705
Epoch 37/300
 - 22s - loss: 1387.3700 - acc: 0.9453 - mDice: 0.7527 - val_loss: 2997.2783 - val_acc: 0.9412 - val_mDice: 0.5257

Epoch 00037: val_mDice did not improve from 0.53705
Epoch 38/300
 - 23s - loss: 1379.9236 - acc: 0.9453 - mDice: 0.7539 - val_loss: 3324.8992 - val_acc: 0.9407 - val_mDice: 0.4955

Epoch 00038: val_mDice did not improve from 0.53705
Epoch 39/300
 - 23s - loss: 1365.8676 - acc: 0.9457 - mDice: 0.7560 - val_loss: 3143.4654 - val_acc: 0.9421 - val_mDice: 0.5090

Epoch 00039: val_mDice did not improve from 0.53705
Epoch 40/300
 - 23s - loss: 1361.4767 - acc: 0.9457 - mDice: 0.7566 - val_loss: 3093.3740 - val_acc: 0.9420 - val_mDice: 0.5141

Epoch 00040: val_mDice did not improve from 0.53705
Epoch 41/300
 - 23s - loss: 1353.3568 - acc: 0.9460 - mDice: 0.7579 - val_loss: 2922.3222 - val_acc: 0.9424 - val_mDice: 0.5307

Epoch 00041: val_mDice did not improve from 0.53705
Epoch 42/300
 - 24s - loss: 1343.1414 - acc: 0.9462 - mDice: 0.7595 - val_loss: 2950.2081 - val_acc: 0.9434 - val_mDice: 0.5285

Epoch 00042: val_mDice did not improve from 0.53705
Epoch 43/300
 - 23s - loss: 1336.4401 - acc: 0.9463 - mDice: 0.7605 - val_loss: 2952.4438 - val_acc: 0.9424 - val_mDice: 0.5293

Epoch 00043: val_mDice did not improve from 0.53705
Epoch 44/300
 - 23s - loss: 1322.1734 - acc: 0.9466 - mDice: 0.7627 - val_loss: 2943.2861 - val_acc: 0.9440 - val_mDice: 0.5314

Epoch 00044: val_mDice did not improve from 0.53705
Epoch 45/300
 - 24s - loss: 1319.8412 - acc: 0.9467 - mDice: 0.7631 - val_loss: 3095.5042 - val_acc: 0.9431 - val_mDice: 0.5136

Epoch 00045: val_mDice did not improve from 0.53705
Epoch 46/300
 - 23s - loss: 1319.2604 - acc: 0.9467 - mDice: 0.7632 - val_loss: 3129.7583 - val_acc: 0.9432 - val_mDice: 0.5085

Epoch 00046: val_mDice did not improve from 0.53705
Epoch 47/300
 - 23s - loss: 1303.5240 - acc: 0.9471 - mDice: 0.7657 - val_loss: 3033.6593 - val_acc: 0.9424 - val_mDice: 0.5207

Epoch 00047: val_mDice did not improve from 0.53705
Epoch 48/300
 - 24s - loss: 1296.5035 - acc: 0.9472 - mDice: 0.7667 - val_loss: 2965.0749 - val_acc: 0.9416 - val_mDice: 0.5281

Epoch 00048: val_mDice did not improve from 0.53705
Epoch 49/300
 - 23s - loss: 1284.3416 - acc: 0.9474 - mDice: 0.7686 - val_loss: 3152.4801 - val_acc: 0.9400 - val_mDice: 0.5094

Epoch 00049: val_mDice did not improve from 0.53705
Epoch 50/300
 - 23s - loss: 1282.7514 - acc: 0.9474 - mDice: 0.7688 - val_loss: 3196.9159 - val_acc: 0.9431 - val_mDice: 0.5050

Epoch 00050: val_mDice did not improve from 0.53705
Epoch 51/300
 - 23s - loss: 1282.9149 - acc: 0.9475 - mDice: 0.7689 - val_loss: 3029.8006 - val_acc: 0.9406 - val_mDice: 0.5212

Epoch 00051: val_mDice did not improve from 0.53705
Epoch 52/300
 - 23s - loss: 1280.4209 - acc: 0.9476 - mDice: 0.7693 - val_loss: 2911.8238 - val_acc: 0.9437 - val_mDice: 0.5324

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.39s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.12s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.90s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:32,  1.80s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:53,  1.67s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:51,  1.67s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:23,  1.58s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:48,  1.67s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:29,  1.61s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:52,  1.70s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:35,  1.65s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:58,  1.73s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:18,  1.81s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<07:48,  1.71s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:09,  1.79s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:49,  1.72s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<07:55,  1.76s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<08:06,  1.80s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<08:10,  1.82s/it]predicting train subjects:   6%|▌         | 17/285 [00:29<07:50,  1.75s/it]predicting train subjects:   6%|▋         | 18/285 [00:30<07:46,  1.75s/it]predicting train subjects:   7%|▋         | 19/285 [00:32<07:27,  1.68s/it]predicting train subjects:   7%|▋         | 20/285 [00:34<07:37,  1.73s/it]predicting train subjects:   7%|▋         | 21/285 [00:36<08:00,  1.82s/it]predicting train subjects:   8%|▊         | 22/285 [00:37<07:34,  1.73s/it]predicting train subjects:   8%|▊         | 23/285 [00:39<07:46,  1.78s/it]predicting train subjects:   8%|▊         | 24/285 [00:41<07:23,  1.70s/it]predicting train subjects:   9%|▉         | 25/285 [00:43<07:38,  1.77s/it]predicting train subjects:   9%|▉         | 26/285 [00:45<07:53,  1.83s/it]predicting train subjects:   9%|▉         | 27/285 [00:46<07:34,  1.76s/it]predicting train subjects:  10%|▉         | 28/285 [00:48<07:48,  1.82s/it]predicting train subjects:  10%|█         | 29/285 [00:50<07:45,  1.82s/it]predicting train subjects:  11%|█         | 30/285 [00:52<07:54,  1.86s/it]predicting train subjects:  11%|█         | 31/285 [00:54<07:58,  1.88s/it]predicting train subjects:  11%|█         | 32/285 [00:56<07:37,  1.81s/it]predicting train subjects:  12%|█▏        | 33/285 [00:57<07:35,  1.81s/it]predicting train subjects:  12%|█▏        | 34/285 [00:59<07:32,  1.80s/it]predicting train subjects:  12%|█▏        | 35/285 [01:01<07:36,  1.83s/it]predicting train subjects:  13%|█▎        | 36/285 [01:03<07:16,  1.75s/it]predicting train subjects:  13%|█▎        | 37/285 [01:04<07:21,  1.78s/it]predicting train subjects:  13%|█▎        | 38/285 [01:06<07:28,  1.81s/it]predicting train subjects:  14%|█▎        | 39/285 [01:08<07:12,  1.76s/it]predicting train subjects:  14%|█▍        | 40/285 [01:10<07:16,  1.78s/it]predicting train subjects:  14%|█▍        | 41/285 [01:11<06:56,  1.71s/it]predicting train subjects:  15%|█▍        | 42/285 [01:13<06:44,  1.67s/it]predicting train subjects:  15%|█▌        | 43/285 [01:15<06:52,  1.71s/it]predicting train subjects:  15%|█▌        | 44/285 [01:17<07:11,  1.79s/it]predicting train subjects:  16%|█▌        | 45/285 [01:18<06:52,  1.72s/it]predicting train subjects:  16%|█▌        | 46/285 [01:20<07:07,  1.79s/it]predicting train subjects:  16%|█▋        | 47/285 [01:22<06:52,  1.73s/it]predicting train subjects:  17%|█▋        | 48/285 [01:24<06:56,  1.76s/it]predicting train subjects:  17%|█▋        | 49/285 [01:26<07:16,  1.85s/it]predicting train subjects:  18%|█▊        | 50/285 [01:28<07:16,  1.86s/it]predicting train subjects:  18%|█▊        | 51/285 [01:29<07:20,  1.88s/it]predicting train subjects:  18%|█▊        | 52/285 [01:31<06:57,  1.79s/it]predicting train subjects:  19%|█▊        | 53/285 [01:33<06:58,  1.80s/it]predicting train subjects:  19%|█▉        | 54/285 [01:35<07:06,  1.84s/it]predicting train subjects:  19%|█▉        | 55/285 [01:36<06:51,  1.79s/it]predicting train subjects:  20%|█▉        | 56/285 [01:38<06:53,  1.81s/it]predicting train subjects:  20%|██        | 57/285 [01:40<06:34,  1.73s/it]predicting train subjects:  20%|██        | 58/285 [01:42<06:40,  1.76s/it]predicting train subjects:  21%|██        | 59/285 [01:44<06:52,  1.83s/it]predicting train subjects:  21%|██        | 60/285 [01:46<07:02,  1.88s/it]predicting train subjects:  21%|██▏       | 61/285 [01:47<06:37,  1.78s/it]predicting train subjects:  22%|██▏       | 62/285 [01:49<06:38,  1.79s/it]predicting train subjects:  22%|██▏       | 63/285 [01:51<06:41,  1.81s/it]predicting train subjects:  22%|██▏       | 64/285 [01:53<06:28,  1.76s/it]predicting train subjects:  23%|██▎       | 65/285 [01:54<06:34,  1.79s/it]predicting train subjects:  23%|██▎       | 66/285 [01:56<06:26,  1.77s/it]predicting train subjects:  24%|██▎       | 67/285 [01:58<06:32,  1.80s/it]predicting train subjects:  24%|██▍       | 68/285 [02:00<06:17,  1.74s/it]predicting train subjects:  24%|██▍       | 69/285 [02:01<06:16,  1.74s/it]predicting train subjects:  25%|██▍       | 70/285 [02:03<06:23,  1.78s/it]predicting train subjects:  25%|██▍       | 71/285 [02:05<06:30,  1.82s/it]predicting train subjects:  25%|██▌       | 72/285 [02:07<06:15,  1.76s/it]predicting train subjects:  26%|██▌       | 73/285 [02:08<06:11,  1.75s/it]predicting train subjects:  26%|██▌       | 74/285 [02:10<06:08,  1.75s/it]predicting train subjects:  26%|██▋       | 75/285 [02:12<06:14,  1.78s/it]predicting train subjects:  27%|██▋       | 76/285 [02:14<06:14,  1.79s/it]predicting train subjects:  27%|██▋       | 77/285 [02:16<06:05,  1.76s/it]predicting train subjects:  27%|██▋       | 78/285 [02:17<05:57,  1.73s/it]predicting train subjects:  28%|██▊       | 79/285 [02:19<05:57,  1.74s/it]predicting train subjects:  28%|██▊       | 80/285 [02:21<05:56,  1.74s/it]predicting train subjects:  28%|██▊       | 81/285 [02:22<05:44,  1.69s/it]predicting train subjects:  29%|██▉       | 82/285 [02:24<05:45,  1.70s/it]predicting train subjects:  29%|██▉       | 83/285 [02:26<05:39,  1.68s/it]predicting train subjects:  29%|██▉       | 84/285 [02:27<05:38,  1.68s/it]predicting train subjects:  30%|██▉       | 85/285 [02:29<05:38,  1.69s/it]predicting train subjects:  30%|███       | 86/285 [02:31<05:46,  1.74s/it]predicting train subjects:  31%|███       | 87/285 [02:33<05:55,  1.80s/it]predicting train subjects:  31%|███       | 88/285 [02:34<05:43,  1.74s/it]predicting train subjects:  31%|███       | 89/285 [02:36<05:44,  1.76s/it]predicting train subjects:  32%|███▏      | 90/285 [02:38<05:48,  1.79s/it]predicting train subjects:  32%|███▏      | 91/285 [02:40<05:37,  1.74s/it]predicting train subjects:  32%|███▏      | 92/285 [02:42<05:39,  1.76s/it]predicting train subjects:  33%|███▎      | 93/285 [02:43<05:28,  1.71s/it]predicting train subjects:  33%|███▎      | 94/285 [02:45<05:29,  1.73s/it]predicting train subjects:  33%|███▎      | 95/285 [02:47<05:33,  1.75s/it]predicting train subjects:  34%|███▎      | 96/285 [02:49<05:30,  1.75s/it]predicting train subjects:  34%|███▍      | 97/285 [02:50<05:30,  1.76s/it]predicting train subjects:  34%|███▍      | 98/285 [02:52<05:23,  1.73s/it]predicting train subjects:  35%|███▍      | 99/285 [02:54<05:19,  1.72s/it]predicting train subjects:  35%|███▌      | 100/285 [02:55<05:23,  1.75s/it]predicting train subjects:  35%|███▌      | 101/285 [02:57<05:13,  1.70s/it]predicting train subjects:  36%|███▌      | 102/285 [02:59<05:25,  1.78s/it]predicting train subjects:  36%|███▌      | 103/285 [03:01<05:12,  1.72s/it]predicting train subjects:  36%|███▋      | 104/285 [03:02<05:14,  1.74s/it]predicting train subjects:  37%|███▋      | 105/285 [03:04<05:16,  1.76s/it]predicting train subjects:  37%|███▋      | 106/285 [03:06<05:08,  1.72s/it]predicting train subjects:  38%|███▊      | 107/285 [03:08<05:07,  1.73s/it]predicting train subjects:  38%|███▊      | 108/285 [03:09<04:58,  1.68s/it]predicting train subjects:  38%|███▊      | 109/285 [03:11<04:58,  1.69s/it]predicting train subjects:  39%|███▊      | 110/285 [03:13<05:03,  1.73s/it]predicting train subjects:  39%|███▉      | 111/285 [03:14<05:02,  1.74s/it]predicting train subjects:  39%|███▉      | 112/285 [03:16<05:01,  1.74s/it]predicting train subjects:  40%|███▉      | 113/285 [03:18<05:04,  1.77s/it]predicting train subjects:  40%|████      | 114/285 [03:20<05:01,  1.76s/it]predicting train subjects:  40%|████      | 115/285 [03:22<05:05,  1.80s/it]predicting train subjects:  41%|████      | 116/285 [03:23<05:05,  1.81s/it]predicting train subjects:  41%|████      | 117/285 [03:25<04:54,  1.75s/it]predicting train subjects:  41%|████▏     | 118/285 [03:27<04:44,  1.71s/it]predicting train subjects:  42%|████▏     | 119/285 [03:29<04:48,  1.74s/it]predicting train subjects:  42%|████▏     | 120/285 [03:30<04:43,  1.72s/it]predicting train subjects:  42%|████▏     | 121/285 [03:32<04:33,  1.67s/it]predicting train subjects:  43%|████▎     | 122/285 [03:33<04:20,  1.60s/it]predicting train subjects:  43%|████▎     | 123/285 [03:35<04:11,  1.55s/it]predicting train subjects:  44%|████▎     | 124/285 [03:36<04:12,  1.57s/it]predicting train subjects:  44%|████▍     | 125/285 [03:38<04:04,  1.53s/it]predicting train subjects:  44%|████▍     | 126/285 [03:39<04:01,  1.52s/it]predicting train subjects:  45%|████▍     | 127/285 [03:41<03:55,  1.49s/it]predicting train subjects:  45%|████▍     | 128/285 [03:42<03:57,  1.52s/it]predicting train subjects:  45%|████▌     | 129/285 [03:44<03:57,  1.52s/it]predicting train subjects:  46%|████▌     | 130/285 [03:45<03:51,  1.49s/it]predicting train subjects:  46%|████▌     | 131/285 [03:47<03:47,  1.48s/it]predicting train subjects:  46%|████▋     | 132/285 [03:48<03:56,  1.55s/it]predicting train subjects:  47%|████▋     | 133/285 [03:50<03:51,  1.52s/it]predicting train subjects:  47%|████▋     | 134/285 [03:51<03:44,  1.49s/it]predicting train subjects:  47%|████▋     | 135/285 [03:53<03:38,  1.46s/it]predicting train subjects:  48%|████▊     | 136/285 [03:54<03:33,  1.43s/it]predicting train subjects:  48%|████▊     | 137/285 [03:56<03:41,  1.50s/it]predicting train subjects:  48%|████▊     | 138/285 [03:57<03:35,  1.47s/it]predicting train subjects:  49%|████▉     | 139/285 [03:59<03:39,  1.51s/it]predicting train subjects:  49%|████▉     | 140/285 [04:00<03:44,  1.55s/it]predicting train subjects:  49%|████▉     | 141/285 [04:02<03:36,  1.51s/it]predicting train subjects:  50%|████▉     | 142/285 [04:03<03:31,  1.48s/it]predicting train subjects:  50%|█████     | 143/285 [04:05<03:30,  1.49s/it]predicting train subjects:  51%|█████     | 144/285 [04:06<03:34,  1.52s/it]predicting train subjects:  51%|█████     | 145/285 [04:08<03:30,  1.50s/it]predicting train subjects:  51%|█████     | 146/285 [04:09<03:34,  1.54s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:11<03:28,  1.51s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:12<03:32,  1.55s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:14<03:27,  1.53s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:15<03:21,  1.49s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:17<03:30,  1.57s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:18<03:19,  1.50s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:20<03:14,  1.47s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:21<03:16,  1.50s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:23<03:12,  1.48s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:24<03:15,  1.51s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:26<03:12,  1.50s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:27<03:09,  1.49s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:29<03:03,  1.46s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:30<03:04,  1.47s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:32<03:06,  1.51s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:33<03:02,  1.48s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:35<03:02,  1.50s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:36<02:56,  1.46s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:37<02:55,  1.46s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:39<02:58,  1.50s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:41<02:59,  1.52s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:42<02:53,  1.48s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:43<02:50,  1.47s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:45<02:45,  1.44s/it]predicting train subjects:  60%|██████    | 171/285 [04:46<02:42,  1.43s/it]predicting train subjects:  60%|██████    | 172/285 [04:48<02:41,  1.43s/it]predicting train subjects:  61%|██████    | 173/285 [04:49<02:40,  1.43s/it]predicting train subjects:  61%|██████    | 174/285 [04:51<02:38,  1.43s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:52<02:44,  1.50s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:54<02:46,  1.53s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:55<02:42,  1.51s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:57<02:36,  1.46s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:58<02:31,  1.43s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:00<02:41,  1.53s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:01<02:42,  1.56s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:03<02:42,  1.58s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:05<02:40,  1.57s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:06<02:36,  1.55s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:07<02:30,  1.51s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:09<02:39,  1.61s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:11<02:42,  1.66s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:13<02:45,  1.71s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:14<02:34,  1.61s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:16<02:27,  1.55s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:17<02:30,  1.60s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:19<02:29,  1.61s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:20<02:21,  1.54s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:22<02:18,  1.53s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:23<02:13,  1.48s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:25<02:21,  1.60s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:27<02:26,  1.67s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:29<02:29,  1.71s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:30<02:17,  1.60s/it]predicting train subjects:  70%|███████   | 200/285 [05:32<02:10,  1.54s/it]predicting train subjects:  71%|███████   | 201/285 [05:33<02:16,  1.62s/it]predicting train subjects:  71%|███████   | 202/285 [05:35<02:14,  1.62s/it]predicting train subjects:  71%|███████   | 203/285 [05:37<02:12,  1.62s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:38<02:04,  1.54s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:39<02:00,  1.50s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:41<01:54,  1.44s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:42<02:00,  1.55s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:44<02:06,  1.64s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:46<02:07,  1.68s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:47<01:59,  1.59s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:49<01:53,  1.53s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:51<01:55,  1.58s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:52<01:54,  1.59s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:54<01:48,  1.53s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:55<01:53,  1.62s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:57<01:47,  1.55s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:59<01:52,  1.65s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:01<01:55,  1.72s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:02<01:55,  1.75s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:04<01:46,  1.63s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:05<01:38,  1.55s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:07<01:38,  1.57s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:08<01:32,  1.49s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:09<01:29,  1.47s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:11<01:25,  1.43s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:13<01:33,  1.58s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:14<01:35,  1.64s/it]predicting train subjects:  80%|████████  | 228/285 [06:16<01:36,  1.69s/it]predicting train subjects:  80%|████████  | 229/285 [06:18<01:36,  1.72s/it]predicting train subjects:  81%|████████  | 230/285 [06:20<01:30,  1.64s/it]predicting train subjects:  81%|████████  | 231/285 [06:21<01:23,  1.55s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:23<01:23,  1.58s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:24<01:19,  1.52s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:26<01:22,  1.61s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:27<01:16,  1.54s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:29<01:19,  1.63s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:31<01:20,  1.67s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:32<01:19,  1.70s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:34<01:18,  1.70s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:36<01:11,  1.60s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:37<01:07,  1.54s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:38<01:03,  1.47s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:40<01:01,  1.46s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:42<01:04,  1.58s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:43<01:00,  1.50s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:45<01:03,  1.62s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:47<01:03,  1.67s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:48<01:01,  1.67s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:50<00:56,  1.56s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:51<00:53,  1.52s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:52<00:49,  1.47s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:54<00:47,  1.44s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:55<00:49,  1.54s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:57<00:49,  1.60s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:59<00:47,  1.60s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:00<00:43,  1.51s/it]predicting train subjects:  90%|█████████ | 257/285 [07:01<00:41,  1.48s/it]predicting train subjects:  91%|█████████ | 258/285 [07:03<00:42,  1.58s/it]predicting train subjects:  91%|█████████ | 259/285 [07:05<00:41,  1.59s/it]predicting train subjects:  91%|█████████ | 260/285 [07:06<00:37,  1.51s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:08<00:35,  1.48s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:09<00:33,  1.45s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:10<00:31,  1.43s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:12<00:32,  1.56s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:14<00:32,  1.64s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:15<00:29,  1.56s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:17<00:27,  1.51s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:19<00:27,  1.60s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:20<00:25,  1.62s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:22<00:22,  1.53s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:23<00:20,  1.48s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:25<00:19,  1.54s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:26<00:17,  1.48s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:27<00:15,  1.45s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:29<00:15,  1.53s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:31<00:14,  1.62s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:32<00:12,  1.52s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:34<00:10,  1.49s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:35<00:09,  1.51s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:37<00:07,  1.47s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:38<00:05,  1.44s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:39<00:04,  1.41s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:41<00:03,  1.54s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:43<00:01,  1.63s/it]predicting train subjects: 100%|██████████| 285/285 [07:45<00:00,  1.70s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:48,  1.65s/it]Loading train:   1%|          | 2/285 [00:03<07:22,  1.57s/it]Loading train:   1%|          | 3/285 [00:04<07:25,  1.58s/it]Loading train:   1%|▏         | 4/285 [00:06<07:07,  1.52s/it]Loading train:   2%|▏         | 5/285 [00:07<07:17,  1.56s/it]Loading train:   2%|▏         | 6/285 [00:08<06:55,  1.49s/it]Loading train:   2%|▏         | 7/285 [00:10<07:08,  1.54s/it]Loading train:   3%|▎         | 8/285 [00:12<06:56,  1.50s/it]Loading train:   3%|▎         | 9/285 [00:13<07:23,  1.61s/it]Loading train:   4%|▎         | 10/285 [00:15<07:01,  1.53s/it]Loading train:   4%|▍         | 11/285 [00:16<06:22,  1.40s/it]Loading train:   4%|▍         | 12/285 [00:17<06:08,  1.35s/it]Loading train:   5%|▍         | 13/285 [00:18<05:27,  1.21s/it]Loading train:   5%|▍         | 14/285 [00:19<05:30,  1.22s/it]Loading train:   5%|▌         | 15/285 [00:20<05:29,  1.22s/it]Loading train:   6%|▌         | 16/285 [00:22<05:27,  1.22s/it]Loading train:   6%|▌         | 17/285 [00:23<05:24,  1.21s/it]Loading train:   6%|▋         | 18/285 [00:24<05:22,  1.21s/it]Loading train:   7%|▋         | 19/285 [00:25<04:57,  1.12s/it]Loading train:   7%|▋         | 20/285 [00:26<05:04,  1.15s/it]Loading train:   7%|▋         | 21/285 [00:27<05:10,  1.18s/it]Loading train:   8%|▊         | 22/285 [00:29<05:02,  1.15s/it]Loading train:   8%|▊         | 23/285 [00:30<05:13,  1.20s/it]Loading train:   8%|▊         | 24/285 [00:31<05:01,  1.16s/it]Loading train:   9%|▉         | 25/285 [00:32<05:01,  1.16s/it]Loading train:   9%|▉         | 26/285 [00:33<05:07,  1.19s/it]Loading train:   9%|▉         | 27/285 [00:34<04:59,  1.16s/it]Loading train:  10%|▉         | 28/285 [00:36<04:59,  1.17s/it]Loading train:  10%|█         | 29/285 [00:37<04:50,  1.14s/it]Loading train:  11%|█         | 30/285 [00:38<05:02,  1.19s/it]Loading train:  11%|█         | 31/285 [00:39<05:05,  1.20s/it]Loading train:  11%|█         | 32/285 [00:40<05:07,  1.22s/it]Loading train:  12%|█▏        | 33/285 [00:42<04:59,  1.19s/it]Loading train:  12%|█▏        | 34/285 [00:43<04:46,  1.14s/it]Loading train:  12%|█▏        | 35/285 [00:44<04:49,  1.16s/it]Loading train:  13%|█▎        | 36/285 [00:45<04:36,  1.11s/it]Loading train:  13%|█▎        | 37/285 [00:46<04:32,  1.10s/it]Loading train:  13%|█▎        | 38/285 [00:47<04:31,  1.10s/it]Loading train:  14%|█▎        | 39/285 [00:48<04:13,  1.03s/it]Loading train:  14%|█▍        | 40/285 [00:49<04:36,  1.13s/it]Loading train:  14%|█▍        | 41/285 [00:50<04:40,  1.15s/it]Loading train:  15%|█▍        | 42/285 [00:51<04:25,  1.09s/it]Loading train:  15%|█▌        | 43/285 [00:52<04:21,  1.08s/it]Loading train:  15%|█▌        | 44/285 [00:54<04:38,  1.16s/it]Loading train:  16%|█▌        | 45/285 [00:55<04:28,  1.12s/it]Loading train:  16%|█▌        | 46/285 [00:56<04:40,  1.17s/it]Loading train:  16%|█▋        | 47/285 [00:57<04:20,  1.10s/it]Loading train:  17%|█▋        | 48/285 [00:58<04:22,  1.11s/it]Loading train:  17%|█▋        | 49/285 [00:59<04:29,  1.14s/it]Loading train:  18%|█▊        | 50/285 [01:00<04:22,  1.12s/it]Loading train:  18%|█▊        | 51/285 [01:02<04:44,  1.22s/it]Loading train:  18%|█▊        | 52/285 [01:03<04:35,  1.18s/it]Loading train:  19%|█▊        | 53/285 [01:04<04:44,  1.23s/it]Loading train:  19%|█▉        | 54/285 [01:05<04:39,  1.21s/it]Loading train:  19%|█▉        | 55/285 [01:07<04:32,  1.19s/it]Loading train:  20%|█▉        | 56/285 [01:08<04:27,  1.17s/it]Loading train:  20%|██        | 57/285 [01:09<04:09,  1.10s/it]Loading train:  20%|██        | 58/285 [01:10<04:01,  1.06s/it]Loading train:  21%|██        | 59/285 [01:11<04:22,  1.16s/it]Loading train:  21%|██        | 60/285 [01:12<04:24,  1.18s/it]Loading train:  21%|██▏       | 61/285 [01:13<04:14,  1.14s/it]Loading train:  22%|██▏       | 62/285 [01:14<04:16,  1.15s/it]Loading train:  22%|██▏       | 63/285 [01:16<04:13,  1.14s/it]Loading train:  22%|██▏       | 64/285 [01:17<04:33,  1.24s/it]Loading train:  23%|██▎       | 65/285 [01:19<05:02,  1.38s/it]Loading train:  23%|██▎       | 66/285 [01:20<05:03,  1.39s/it]Loading train:  24%|██▎       | 67/285 [01:21<04:48,  1.32s/it]Loading train:  24%|██▍       | 68/285 [01:22<04:32,  1.25s/it]Loading train:  24%|██▍       | 69/285 [01:23<04:14,  1.18s/it]Loading train:  25%|██▍       | 70/285 [01:24<04:07,  1.15s/it]Loading train:  25%|██▍       | 71/285 [01:26<03:59,  1.12s/it]Loading train:  25%|██▌       | 72/285 [01:27<03:51,  1.09s/it]Loading train:  26%|██▌       | 73/285 [01:28<03:54,  1.11s/it]Loading train:  26%|██▌       | 74/285 [01:29<03:52,  1.10s/it]Loading train:  26%|██▋       | 75/285 [01:30<03:48,  1.09s/it]Loading train:  27%|██▋       | 76/285 [01:31<03:54,  1.12s/it]Loading train:  27%|██▋       | 77/285 [01:32<03:53,  1.12s/it]Loading train:  27%|██▋       | 78/285 [01:33<03:46,  1.09s/it]Loading train:  28%|██▊       | 79/285 [01:34<03:52,  1.13s/it]Loading train:  28%|██▊       | 80/285 [01:36<03:52,  1.13s/it]Loading train:  28%|██▊       | 81/285 [01:36<03:36,  1.06s/it]Loading train:  29%|██▉       | 82/285 [01:38<03:40,  1.09s/it]Loading train:  29%|██▉       | 83/285 [01:39<03:37,  1.08s/it]Loading train:  29%|██▉       | 84/285 [01:40<03:26,  1.03s/it]Loading train:  30%|██▉       | 85/285 [01:41<03:32,  1.06s/it]Loading train:  30%|███       | 86/285 [01:42<03:40,  1.11s/it]Loading train:  31%|███       | 87/285 [01:43<03:32,  1.07s/it]Loading train:  31%|███       | 88/285 [01:44<03:25,  1.04s/it]Loading train:  31%|███       | 89/285 [01:45<03:32,  1.08s/it]Loading train:  32%|███▏      | 90/285 [01:46<03:39,  1.13s/it]Loading train:  32%|███▏      | 91/285 [01:47<03:34,  1.11s/it]Loading train:  32%|███▏      | 92/285 [01:48<03:31,  1.09s/it]Loading train:  33%|███▎      | 93/285 [01:50<03:35,  1.12s/it]Loading train:  33%|███▎      | 94/285 [01:51<03:38,  1.14s/it]Loading train:  33%|███▎      | 95/285 [01:52<03:38,  1.15s/it]Loading train:  34%|███▎      | 96/285 [01:53<03:31,  1.12s/it]Loading train:  34%|███▍      | 97/285 [01:54<03:36,  1.15s/it]Loading train:  34%|███▍      | 98/285 [01:55<03:35,  1.15s/it]Loading train:  35%|███▍      | 99/285 [01:57<03:39,  1.18s/it]Loading train:  35%|███▌      | 100/285 [01:58<03:33,  1.15s/it]Loading train:  35%|███▌      | 101/285 [01:59<03:20,  1.09s/it]Loading train:  36%|███▌      | 102/285 [02:00<03:21,  1.10s/it]Loading train:  36%|███▌      | 103/285 [02:01<03:17,  1.08s/it]Loading train:  36%|███▋      | 104/285 [02:02<03:15,  1.08s/it]Loading train:  37%|███▋      | 105/285 [02:03<03:10,  1.06s/it]Loading train:  37%|███▋      | 106/285 [02:04<03:05,  1.04s/it]Loading train:  38%|███▊      | 107/285 [02:05<03:10,  1.07s/it]Loading train:  38%|███▊      | 108/285 [02:06<03:08,  1.07s/it]Loading train:  38%|███▊      | 109/285 [02:07<03:13,  1.10s/it]Loading train:  39%|███▊      | 110/285 [02:08<03:16,  1.12s/it]Loading train:  39%|███▉      | 111/285 [02:09<03:05,  1.07s/it]Loading train:  39%|███▉      | 112/285 [02:10<03:01,  1.05s/it]Loading train:  40%|███▉      | 113/285 [02:12<03:12,  1.12s/it]Loading train:  40%|████      | 114/285 [02:13<03:18,  1.16s/it]Loading train:  40%|████      | 115/285 [02:14<03:15,  1.15s/it]Loading train:  41%|████      | 116/285 [02:15<03:13,  1.15s/it]Loading train:  41%|████      | 117/285 [02:16<03:10,  1.13s/it]Loading train:  41%|████▏     | 118/285 [02:17<02:58,  1.07s/it]Loading train:  42%|████▏     | 119/285 [02:19<03:16,  1.18s/it]Loading train:  42%|████▏     | 120/285 [02:20<03:09,  1.15s/it]Loading train:  42%|████▏     | 121/285 [02:21<03:25,  1.25s/it]Loading train:  43%|████▎     | 122/285 [02:23<03:41,  1.36s/it]Loading train:  43%|████▎     | 123/285 [02:24<03:38,  1.35s/it]Loading train:  44%|████▎     | 124/285 [02:25<03:26,  1.28s/it]Loading train:  44%|████▍     | 125/285 [02:27<03:28,  1.30s/it]Loading train:  44%|████▍     | 126/285 [02:28<03:14,  1.22s/it]Loading train:  45%|████▍     | 127/285 [02:29<03:05,  1.18s/it]Loading train:  45%|████▍     | 128/285 [02:30<03:03,  1.17s/it]Loading train:  45%|████▌     | 129/285 [02:31<03:18,  1.27s/it]Loading train:  46%|████▌     | 130/285 [02:33<03:15,  1.26s/it]Loading train:  46%|████▌     | 131/285 [02:34<03:07,  1.22s/it]Loading train:  46%|████▋     | 132/285 [02:35<03:05,  1.21s/it]Loading train:  47%|████▋     | 133/285 [02:36<03:06,  1.22s/it]Loading train:  47%|████▋     | 134/285 [02:37<02:56,  1.17s/it]Loading train:  47%|████▋     | 135/285 [02:38<02:47,  1.12s/it]Loading train:  48%|████▊     | 136/285 [02:39<02:40,  1.07s/it]Loading train:  48%|████▊     | 137/285 [02:41<02:47,  1.13s/it]Loading train:  48%|████▊     | 138/285 [02:42<02:55,  1.19s/it]Loading train:  49%|████▉     | 139/285 [02:43<02:49,  1.16s/it]Loading train:  49%|████▉     | 140/285 [02:44<02:47,  1.16s/it]Loading train:  49%|████▉     | 141/285 [02:45<02:37,  1.10s/it]Loading train:  50%|████▉     | 142/285 [02:46<02:51,  1.20s/it]Loading train:  50%|█████     | 143/285 [02:48<02:43,  1.15s/it]Loading train:  51%|█████     | 144/285 [02:49<02:54,  1.24s/it]Loading train:  51%|█████     | 145/285 [02:50<02:45,  1.18s/it]Loading train:  51%|█████     | 146/285 [02:51<02:42,  1.17s/it]Loading train:  52%|█████▏    | 147/285 [02:52<02:39,  1.16s/it]Loading train:  52%|█████▏    | 148/285 [02:53<02:35,  1.13s/it]Loading train:  52%|█████▏    | 149/285 [02:55<02:34,  1.14s/it]Loading train:  53%|█████▎    | 150/285 [02:56<02:30,  1.12s/it]Loading train:  53%|█████▎    | 151/285 [02:57<02:28,  1.11s/it]Loading train:  53%|█████▎    | 152/285 [02:58<02:23,  1.08s/it]Loading train:  54%|█████▎    | 153/285 [02:59<02:24,  1.10s/it]Loading train:  54%|█████▍    | 154/285 [03:00<02:20,  1.07s/it]Loading train:  54%|█████▍    | 155/285 [03:01<02:15,  1.04s/it]Loading train:  55%|█████▍    | 156/285 [03:02<02:16,  1.06s/it]Loading train:  55%|█████▌    | 157/285 [03:03<02:12,  1.04s/it]Loading train:  55%|█████▌    | 158/285 [03:04<02:16,  1.07s/it]Loading train:  56%|█████▌    | 159/285 [03:05<02:16,  1.09s/it]Loading train:  56%|█████▌    | 160/285 [03:06<02:21,  1.13s/it]Loading train:  56%|█████▋    | 161/285 [03:08<02:26,  1.18s/it]Loading train:  57%|█████▋    | 162/285 [03:09<02:24,  1.17s/it]Loading train:  57%|█████▋    | 163/285 [03:10<02:15,  1.11s/it]Loading train:  58%|█████▊    | 164/285 [03:11<02:10,  1.08s/it]Loading train:  58%|█████▊    | 165/285 [03:12<02:09,  1.08s/it]Loading train:  58%|█████▊    | 166/285 [03:13<02:11,  1.10s/it]Loading train:  59%|█████▊    | 167/285 [03:14<02:12,  1.12s/it]Loading train:  59%|█████▉    | 168/285 [03:15<02:07,  1.09s/it]Loading train:  59%|█████▉    | 169/285 [03:16<02:09,  1.12s/it]Loading train:  60%|█████▉    | 170/285 [03:18<02:08,  1.12s/it]Loading train:  60%|██████    | 171/285 [03:19<02:05,  1.10s/it]Loading train:  60%|██████    | 172/285 [03:20<02:04,  1.10s/it]Loading train:  61%|██████    | 173/285 [03:21<02:02,  1.09s/it]Loading train:  61%|██████    | 174/285 [03:22<01:59,  1.08s/it]Loading train:  61%|██████▏   | 175/285 [03:23<01:58,  1.08s/it]Loading train:  62%|██████▏   | 176/285 [03:24<01:58,  1.09s/it]Loading train:  62%|██████▏   | 177/285 [03:25<01:56,  1.08s/it]Loading train:  62%|██████▏   | 178/285 [03:26<01:58,  1.11s/it]Loading train:  63%|██████▎   | 179/285 [03:27<01:59,  1.12s/it]Loading train:  63%|██████▎   | 180/285 [03:29<02:01,  1.16s/it]Loading train:  64%|██████▎   | 181/285 [03:30<02:00,  1.16s/it]Loading train:  64%|██████▍   | 182/285 [03:31<01:59,  1.16s/it]Loading train:  64%|██████▍   | 183/285 [03:32<01:58,  1.16s/it]Loading train:  65%|██████▍   | 184/285 [03:33<01:54,  1.13s/it]Loading train:  65%|██████▍   | 185/285 [03:34<01:49,  1.09s/it]Loading train:  65%|██████▌   | 186/285 [03:35<01:52,  1.14s/it]Loading train:  66%|██████▌   | 187/285 [03:37<01:54,  1.17s/it]Loading train:  66%|██████▌   | 188/285 [03:38<01:59,  1.23s/it]Loading train:  66%|██████▋   | 189/285 [03:39<01:58,  1.24s/it]Loading train:  67%|██████▋   | 190/285 [03:40<01:52,  1.19s/it]Loading train:  67%|██████▋   | 191/285 [03:41<01:49,  1.17s/it]Loading train:  67%|██████▋   | 192/285 [03:43<01:45,  1.13s/it]Loading train:  68%|██████▊   | 193/285 [03:44<01:43,  1.13s/it]Loading train:  68%|██████▊   | 194/285 [03:45<01:39,  1.10s/it]Loading train:  68%|██████▊   | 195/285 [03:46<01:37,  1.08s/it]Loading train:  69%|██████▉   | 196/285 [03:47<01:45,  1.18s/it]Loading train:  69%|██████▉   | 197/285 [03:49<01:50,  1.25s/it]Loading train:  69%|██████▉   | 198/285 [03:50<01:57,  1.35s/it]Loading train:  70%|██████▉   | 199/285 [03:51<01:49,  1.28s/it]Loading train:  70%|███████   | 200/285 [03:52<01:41,  1.20s/it]Loading train:  71%|███████   | 201/285 [03:53<01:40,  1.20s/it]Loading train:  71%|███████   | 202/285 [03:55<01:43,  1.25s/it]Loading train:  71%|███████   | 203/285 [03:56<01:40,  1.22s/it]Loading train:  72%|███████▏  | 204/285 [03:57<01:36,  1.19s/it]Loading train:  72%|███████▏  | 205/285 [03:58<01:31,  1.14s/it]Loading train:  72%|███████▏  | 206/285 [03:59<01:29,  1.13s/it]Loading train:  73%|███████▎  | 207/285 [04:01<01:33,  1.20s/it]Loading train:  73%|███████▎  | 208/285 [04:02<01:36,  1.25s/it]Loading train:  73%|███████▎  | 209/285 [04:03<01:37,  1.29s/it]Loading train:  74%|███████▎  | 210/285 [04:04<01:30,  1.20s/it]Loading train:  74%|███████▍  | 211/285 [04:05<01:27,  1.18s/it]Loading train:  74%|███████▍  | 212/285 [04:07<01:27,  1.20s/it]Loading train:  75%|███████▍  | 213/285 [04:08<01:26,  1.20s/it]Loading train:  75%|███████▌  | 214/285 [04:09<01:23,  1.17s/it]Loading train:  75%|███████▌  | 215/285 [04:10<01:24,  1.21s/it]Loading train:  76%|███████▌  | 216/285 [04:12<01:27,  1.26s/it]Loading train:  76%|███████▌  | 217/285 [04:13<01:29,  1.31s/it]Loading train:  76%|███████▋  | 218/285 [04:14<01:26,  1.29s/it]Loading train:  77%|███████▋  | 219/285 [04:16<01:25,  1.30s/it]Loading train:  77%|███████▋  | 220/285 [04:17<01:24,  1.30s/it]Loading train:  78%|███████▊  | 221/285 [04:18<01:23,  1.31s/it]Loading train:  78%|███████▊  | 222/285 [04:19<01:18,  1.25s/it]Loading train:  78%|███████▊  | 223/285 [04:20<01:12,  1.16s/it]Loading train:  79%|███████▊  | 224/285 [04:22<01:12,  1.19s/it]Loading train:  79%|███████▉  | 225/285 [04:23<01:12,  1.20s/it]Loading train:  79%|███████▉  | 226/285 [04:24<01:11,  1.21s/it]Loading train:  80%|███████▉  | 227/285 [04:25<01:09,  1.20s/it]Loading train:  80%|████████  | 228/285 [04:26<01:08,  1.20s/it]Loading train:  80%|████████  | 229/285 [04:28<01:04,  1.16s/it]Loading train:  81%|████████  | 230/285 [04:29<01:01,  1.12s/it]Loading train:  81%|████████  | 231/285 [04:30<00:59,  1.10s/it]Loading train:  81%|████████▏ | 232/285 [04:31<01:00,  1.13s/it]Loading train:  82%|████████▏ | 233/285 [04:32<00:58,  1.13s/it]Loading train:  82%|████████▏ | 234/285 [04:33<01:00,  1.18s/it]Loading train:  82%|████████▏ | 235/285 [04:34<00:57,  1.15s/it]Loading train:  83%|████████▎ | 236/285 [04:36<01:00,  1.24s/it]Loading train:  83%|████████▎ | 237/285 [04:37<00:59,  1.25s/it]Loading train:  84%|████████▎ | 238/285 [04:38<00:57,  1.21s/it]Loading train:  84%|████████▍ | 239/285 [04:39<00:56,  1.22s/it]Loading train:  84%|████████▍ | 240/285 [04:41<00:53,  1.20s/it]Loading train:  85%|████████▍ | 241/285 [04:42<00:53,  1.21s/it]Loading train:  85%|████████▍ | 242/285 [04:43<00:52,  1.21s/it]Loading train:  85%|████████▌ | 243/285 [04:44<00:49,  1.18s/it]Loading train:  86%|████████▌ | 244/285 [04:45<00:49,  1.21s/it]Loading train:  86%|████████▌ | 245/285 [04:47<00:47,  1.20s/it]Loading train:  86%|████████▋ | 246/285 [04:48<00:47,  1.21s/it]Loading train:  87%|████████▋ | 247/285 [04:49<00:47,  1.24s/it]Loading train:  87%|████████▋ | 248/285 [04:50<00:43,  1.19s/it]Loading train:  87%|████████▋ | 249/285 [04:51<00:42,  1.19s/it]Loading train:  88%|████████▊ | 250/285 [04:53<00:41,  1.17s/it]Loading train:  88%|████████▊ | 251/285 [04:54<00:39,  1.16s/it]Loading train:  88%|████████▊ | 252/285 [04:55<00:38,  1.18s/it]Loading train:  89%|████████▉ | 253/285 [04:56<00:38,  1.20s/it]Loading train:  89%|████████▉ | 254/285 [04:58<00:40,  1.29s/it]Loading train:  89%|████████▉ | 255/285 [04:59<00:38,  1.27s/it]Loading train:  90%|████████▉ | 256/285 [05:00<00:35,  1.21s/it]Loading train:  90%|█████████ | 257/285 [05:01<00:33,  1.18s/it]Loading train:  91%|█████████ | 258/285 [05:02<00:32,  1.22s/it]Loading train:  91%|█████████ | 259/285 [05:04<00:33,  1.30s/it]Loading train:  91%|█████████ | 260/285 [05:05<00:33,  1.35s/it]Loading train:  92%|█████████▏| 261/285 [05:06<00:29,  1.23s/it]Loading train:  92%|█████████▏| 262/285 [05:07<00:26,  1.17s/it]Loading train:  92%|█████████▏| 263/285 [05:08<00:25,  1.14s/it]Loading train:  93%|█████████▎| 264/285 [05:10<00:25,  1.19s/it]Loading train:  93%|█████████▎| 265/285 [05:11<00:26,  1.35s/it]Loading train:  93%|█████████▎| 266/285 [05:12<00:24,  1.27s/it]Loading train:  94%|█████████▎| 267/285 [05:13<00:21,  1.18s/it]Loading train:  94%|█████████▍| 268/285 [05:15<00:20,  1.22s/it]Loading train:  94%|█████████▍| 269/285 [05:16<00:19,  1.23s/it]Loading train:  95%|█████████▍| 270/285 [05:17<00:17,  1.16s/it]Loading train:  95%|█████████▌| 271/285 [05:18<00:16,  1.15s/it]Loading train:  95%|█████████▌| 272/285 [05:19<00:14,  1.13s/it]Loading train:  96%|█████████▌| 273/285 [05:20<00:13,  1.11s/it]Loading train:  96%|█████████▌| 274/285 [05:21<00:12,  1.09s/it]Loading train:  96%|█████████▋| 275/285 [05:23<00:11,  1.19s/it]Loading train:  97%|█████████▋| 276/285 [05:24<00:10,  1.21s/it]Loading train:  97%|█████████▋| 277/285 [05:25<00:09,  1.19s/it]Loading train:  98%|█████████▊| 278/285 [05:26<00:07,  1.14s/it]Loading train:  98%|█████████▊| 279/285 [05:27<00:07,  1.19s/it]Loading train:  98%|█████████▊| 280/285 [05:29<00:05,  1.19s/it]Loading train:  99%|█████████▊| 281/285 [05:30<00:04,  1.16s/it]Loading train:  99%|█████████▉| 282/285 [05:31<00:03,  1.14s/it]Loading train:  99%|█████████▉| 283/285 [05:32<00:02,  1.24s/it]Loading train: 100%|█████████▉| 284/285 [05:34<00:01,  1.28s/it]Loading train: 100%|██████████| 285/285 [05:35<00:00,  1.33s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|▏         | 4/285 [00:00<00:07, 36.54it/s]concatenating: train:   4%|▍         | 11/285 [00:00<00:06, 41.74it/s]concatenating: train:   6%|▋         | 18/285 [00:00<00:05, 46.74it/s]concatenating: train:   9%|▉         | 27/285 [00:00<00:04, 54.17it/s]concatenating: train:  14%|█▍        | 40/285 [00:00<00:03, 65.27it/s]concatenating: train:  17%|█▋        | 49/285 [00:00<00:03, 69.24it/s]concatenating: train:  20%|██        | 57/285 [00:00<00:03, 65.74it/s]concatenating: train:  23%|██▎       | 65/285 [00:00<00:03, 62.32it/s]concatenating: train:  25%|██▌       | 72/285 [00:01<00:03, 61.07it/s]concatenating: train:  29%|██▉       | 82/285 [00:01<00:03, 66.39it/s]concatenating: train:  31%|███       | 89/285 [00:01<00:03, 62.38it/s]concatenating: train:  35%|███▍      | 99/285 [00:01<00:02, 69.66it/s]concatenating: train:  39%|███▉      | 112/285 [00:01<00:02, 80.32it/s]concatenating: train:  44%|████▍     | 125/285 [00:01<00:01, 89.98it/s]concatenating: train:  48%|████▊     | 137/285 [00:01<00:01, 96.35it/s]concatenating: train:  53%|█████▎    | 150/285 [00:01<00:01, 103.46it/s]concatenating: train:  57%|█████▋    | 162/285 [00:01<00:01, 98.37it/s] concatenating: train:  61%|██████▏   | 175/285 [00:02<00:01, 103.07it/s]concatenating: train:  66%|██████▌   | 188/285 [00:02<00:00, 108.82it/s]concatenating: train:  71%|███████   | 201/285 [00:02<00:00, 113.22it/s]concatenating: train:  75%|███████▍  | 213/285 [00:02<00:00, 96.42it/s] concatenating: train:  79%|███████▊  | 224/285 [00:02<00:00, 93.01it/s]concatenating: train:  82%|████████▏ | 234/285 [00:02<00:00, 81.13it/s]concatenating: train:  86%|████████▌ | 244/285 [00:02<00:00, 84.26it/s]concatenating: train:  89%|████████▉ | 253/285 [00:03<00:00, 63.69it/s]concatenating: train:  93%|█████████▎| 264/285 [00:03<00:00, 72.51it/s]concatenating: train:  97%|█████████▋| 277/285 [00:03<00:00, 82.97it/s]concatenating: train: 100%|██████████| 285/285 [00:03<00:00, 85.49it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.51s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.48s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.42s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 54.46it/s]2019-07-09 10:33:58.470133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-09 10:33:58.470226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-09 10:33:58.470243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-09 10:33:58.470251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-09 10:33:58.470579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12743 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.57it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.61it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  6.20it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.93it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:03,  8.60it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  7.16it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02,  9.25it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.63it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:02,  7.79it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:01,  9.69it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01, 10.06it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.97it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:02<00:01,  7.93it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.82it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00, 10.11it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 10.14it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  7.73it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 11.23it/s]
Epoch 00052: val_mDice did not improve from 0.53705
Restoring model weights from the end of the best epoch
Epoch 00052: early stopping
{'val_loss': [9013.312523251489, 4517.43902297247, 3583.2748442150296, 3712.3448428199404, 3212.5494326636904, 3548.8145810081846, 3067.4092610677085, 3200.5423177083335, 3367.9508696056546, 3006.7389206659227, 3238.5527460007443, 3054.6149553571427, 3268.011521112351, 3094.2611955915177, 2989.5716494605654, 2985.5692080543154, 3056.8577938988096, 3045.3633975074404, 3221.3255208333335, 3489.654831659226, 2976.2048921130954, 2903.0632440476193, 3200.1219075520835, 3309.2775995163693, 3133.591110956101, 3302.9254441034227, 3065.770263671875, 3074.9451613653273, 2992.5106840587796, 2952.8322637648807, 2937.4326288132443, 2947.687279110863, 3174.3413434709823, 3030.170607793899, 3173.3714773995534, 3173.035202752976, 2997.278273809524, 3324.899216424851, 3143.4654250372023, 3093.374000186012, 2922.322242373512, 2950.2081124441966, 2952.4437662760415, 2943.2861211867557, 3095.504196893601, 3129.758324032738, 3033.6593075706846, 2965.074881417411, 3152.4800734747023, 3196.9158644903273, 3029.8005952380954, 2911.82381766183], 'val_acc': [0.9034913210641771, 0.9065453268232799, 0.9081364302408128, 0.9090293248494467, 0.9119322243190947, 0.9139171100798107, 0.9192879796028137, 0.9183356080736432, 0.9224519360633123, 0.9247847880635943, 0.9211996595064799, 0.9234936180568877, 0.9222848245075771, 0.9269505228315081, 0.9336286811601548, 0.931332426411765, 0.93453296877089, 0.93303116162618, 0.9351098963192531, 0.933092937583015, 0.9397825002670288, 0.9430471431641352, 0.9385645389556885, 0.940579184464046, 0.9362042035375323, 0.9363873657726106, 0.9400137322289603, 0.9422550371715, 0.9413736150378272, 0.9412751793861389, 0.9398603212265741, 0.9420627525874546, 0.9414560369082859, 0.9412431234405154, 0.9402678410212199, 0.9421611683709281, 0.9411676100322178, 0.9407463102113633, 0.9421199560165405, 0.9420398161524818, 0.9423694979576838, 0.9433653666859582, 0.9423580425126212, 0.9440384791010902, 0.9431364224070594, 0.9431684982208979, 0.9423717686108181, 0.9415888445717948, 0.9399931061835516, 0.9430952554657346, 0.9406249750228155, 0.9436653199649992], 'val_mDice': [0.20000096691295594, 0.3917882956032242, 0.46588337971341043, 0.4609338790178299, 0.5027095654181072, 0.4737693160062745, 0.5195307282819634, 0.5067088930379777, 0.49180722839775537, 0.5242352680790991, 0.5015337415749118, 0.5192651400963465, 0.4992029063758396, 0.5159432022344499, 0.5282129600998902, 0.5288359762302467, 0.5217958050114768, 0.520530379599049, 0.5056670066856203, 0.4818081933827627, 0.5270055897888684, 0.537052826157638, 0.5044401082254591, 0.49522930862648146, 0.5111904687115124, 0.4956925344609079, 0.5176005595851512, 0.5150465275205317, 0.525269095031988, 0.5294467334945997, 0.5285821603167624, 0.5297268627300149, 0.5084562718513466, 0.5211717596366292, 0.5065838834714322, 0.5067782882778418, 0.5257165416010788, 0.4954807579162575, 0.5089950148193609, 0.5140934515567053, 0.5306914395519665, 0.5285288233842168, 0.5293031164578029, 0.5314004155141967, 0.5136018257055964, 0.5085430533758232, 0.5206981890258335, 0.5281143521978742, 0.5093692370823452, 0.5050107402106127, 0.5212015451065132, 0.5323865873118242], 'loss': [13458.010142637995, 4303.039252136125, 3223.2152947535606, 2793.4234599136817, 2565.099387638643, 2392.88014239136, 2292.1639813786646, 2183.4758998090556, 2128.5326286626273, 2060.8727370748084, 1999.0042323591806, 1949.5612764963414, 1903.9241375015815, 1870.0852865760028, 1818.6117690560536, 1783.858767425437, 1756.735328052139, 1721.1657876521608, 1700.9047834853434, 1681.8398154622585, 1647.8577417947663, 1623.7771853904217, 1606.416684058215, 1575.5201792087264, 1554.4559270396544, 1539.36626108823, 1535.5828378271776, 1508.1852260609455, 1489.4485036255378, 1479.4153956480745, 1462.701271941121, 1450.1506972951836, 1437.962408133088, 1428.0462726028939, 1415.3969636427682, 1399.7459314837952, 1387.3700326537498, 1379.923592221238, 1365.8675557583863, 1361.4766642840952, 1353.356799980062, 1343.141357163002, 1336.4401409266104, 1322.1733750386898, 1319.8412307553929, 1319.2603862726414, 1303.5240473573508, 1296.5034785214614, 1284.3415839167856, 1282.7514152578335, 1282.914941973417, 1280.4209118518202], 'acc': [0.651069402533826, 0.8713815346351588, 0.8738774424553469, 0.8770545079617549, 0.8807042553656037, 0.8843559083829203, 0.8874590560515216, 0.890039190968866, 0.892768763142191, 0.8954851538867925, 0.8975108811821761, 0.8992193648643707, 0.9014843411245211, 0.903538826391236, 0.905410440310086, 0.9076944191905835, 0.9098651744346296, 0.9116477632030762, 0.9141902444517541, 0.9197019685296073, 0.9290315513553844, 0.9333364382308642, 0.9389106553024195, 0.9411120971825303, 0.9416715526066006, 0.9421132811466715, 0.9422139624697132, 0.9427800487410202, 0.9432210835023309, 0.9434536079209458, 0.9437620512823712, 0.9439584279487835, 0.9443374775681901, 0.9444588029777611, 0.9445658789357629, 0.9449207372740788, 0.9452604771418817, 0.9453306685345284, 0.9457197243914063, 0.9457270941087131, 0.9459796409306325, 0.9461758347497135, 0.9463119473971221, 0.9466487992032774, 0.9467316099115941, 0.9467130967227163, 0.947127041086793, 0.9471943306973474, 0.947415460252293, 0.9474474122488868, 0.9474542025819275, 0.9475733088302501], 'mDice': [0.13636190031482945, 0.4234059822566251, 0.5213073759104719, 0.5684056911644091, 0.5953587744308156, 0.6163135214947726, 0.6292352351881255, 0.643172722194198, 0.6504559276052033, 0.659315569680712, 0.667536946006747, 0.6743682693350355, 0.6805757422288167, 0.6851967036643652, 0.6925031994840233, 0.6973412638343045, 0.7012849050333947, 0.7061693433486177, 0.7090574051572198, 0.7117527644138288, 0.7161926137980456, 0.7193137240681042, 0.7210062417263283, 0.72487361993729, 0.7278440155595949, 0.7300147820534861, 0.7307454858737252, 0.7345606737314264, 0.7373456424524129, 0.7388530882057115, 0.7413261207583692, 0.743309367868237, 0.745052609941002, 0.7465620619933087, 0.7484692063133037, 0.7507834458066155, 0.7527002514914003, 0.75387048240983, 0.7559797817258355, 0.7565813533414506, 0.7579260427689355, 0.7594531755445549, 0.7605197061135495, 0.76270810325228, 0.7630554373286835, 0.7631927494692945, 0.7656648872168463, 0.7666972207269251, 0.7685741582816796, 0.7688497652409048, 0.7688528902617543, 0.769305566475528]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 30)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 31)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   5600        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 30)   16230       dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 52, 30)   120         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 52, 30)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 52, 30)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 52, 90)   0           dropout_6[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 52, 13)   1183        concatenate_8[0][0]              
==================================================================================================
Total params: 246,393
Trainable params: 71,593
Non-trainable params: 174,800
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 32s - loss: 10906.9914 - acc: 0.7891 - mDice: 0.1883 - val_loss: 5608.9927 - val_acc: 0.9200 - val_mDice: 0.3379

Epoch 00001: val_mDice improved from -inf to 0.33786, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 24s - loss: 4135.4053 - acc: 0.9060 - mDice: 0.4421 - val_loss: 3243.7110 - val_acc: 0.9355 - val_mDice: 0.4974

Epoch 00002: val_mDice improved from 0.33786 to 0.49738, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 25s - loss: 3085.7884 - acc: 0.9234 - mDice: 0.5392 - val_loss: 2669.2829 - val_acc: 0.9464 - val_mDice: 0.5526

Epoch 00003: val_mDice improved from 0.49738 to 0.55260, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 24s - loss: 2636.4575 - acc: 0.9337 - mDice: 0.5886 - val_loss: 2582.4712 - val_acc: 0.9407 - val_mDice: 0.5618

Epoch 00004: val_mDice improved from 0.55260 to 0.56182, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 25s - loss: 2380.7861 - acc: 0.9381 - mDice: 0.6186 - val_loss: 2679.0042 - val_acc: 0.9434 - val_mDice: 0.5527

Epoch 00005: val_mDice did not improve from 0.56182
Epoch 6/300
 - 24s - loss: 2236.9734 - acc: 0.9405 - mDice: 0.6364 - val_loss: 2449.0959 - val_acc: 0.9433 - val_mDice: 0.5780

Epoch 00006: val_mDice improved from 0.56182 to 0.57798, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 24s - loss: 2138.5973 - acc: 0.9422 - mDice: 0.6489 - val_loss: 2490.9387 - val_acc: 0.9435 - val_mDice: 0.5729

Epoch 00007: val_mDice did not improve from 0.57798
Epoch 8/300
 - 25s - loss: 2041.9157 - acc: 0.9437 - mDice: 0.6613 - val_loss: 2287.3145 - val_acc: 0.9492 - val_mDice: 0.5989

Epoch 00008: val_mDice improved from 0.57798 to 0.59890, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 25s - loss: 1975.5739 - acc: 0.9447 - mDice: 0.6702 - val_loss: 2455.6776 - val_acc: 0.9474 - val_mDice: 0.5785

Epoch 00009: val_mDice did not improve from 0.59890
Epoch 10/300
 - 24s - loss: 1916.2418 - acc: 0.9458 - mDice: 0.6781 - val_loss: 2279.3098 - val_acc: 0.9483 - val_mDice: 0.6003

Epoch 00010: val_mDice improved from 0.59890 to 0.60035, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 25s - loss: 1872.1665 - acc: 0.9463 - mDice: 0.6839 - val_loss: 2456.1574 - val_acc: 0.9488 - val_mDice: 0.5801

Epoch 00011: val_mDice did not improve from 0.60035
Epoch 12/300
 - 24s - loss: 1833.6033 - acc: 0.9470 - mDice: 0.6893 - val_loss: 2479.1268 - val_acc: 0.9461 - val_mDice: 0.5757

Epoch 00012: val_mDice did not improve from 0.60035
Epoch 13/300
 - 25s - loss: 1783.6278 - acc: 0.9476 - mDice: 0.6960 - val_loss: 2443.0285 - val_acc: 0.9468 - val_mDice: 0.5802

Epoch 00013: val_mDice did not improve from 0.60035
Epoch 14/300
 - 25s - loss: 1763.4623 - acc: 0.9481 - mDice: 0.6990 - val_loss: 2320.0919 - val_acc: 0.9470 - val_mDice: 0.5943

Epoch 00014: val_mDice did not improve from 0.60035
Epoch 15/300
 - 23s - loss: 1730.7396 - acc: 0.9485 - mDice: 0.7032 - val_loss: 2420.4848 - val_acc: 0.9483 - val_mDice: 0.5855

Epoch 00015: val_mDice did not improve from 0.60035
Epoch 16/300
 - 25s - loss: 1691.2914 - acc: 0.9490 - mDice: 0.7089 - val_loss: 2337.9976 - val_acc: 0.9471 - val_mDice: 0.5938

Epoch 00016: val_mDice did not improve from 0.60035
Epoch 17/300
 - 24s - loss: 1663.7110 - acc: 0.9495 - mDice: 0.7129 - val_loss: 2310.9348 - val_acc: 0.9479 - val_mDice: 0.5956

Epoch 00017: val_mDice did not improve from 0.60035
Epoch 18/300
 - 26s - loss: 1635.9875 - acc: 0.9499 - mDice: 0.7167 - val_loss: 2280.8232 - val_acc: 0.9475 - val_mDice: 0.6005

Epoch 00018: val_mDice improved from 0.60035 to 0.60051, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 19/300
 - 25s - loss: 1617.2438 - acc: 0.9502 - mDice: 0.7194 - val_loss: 2242.8872 - val_acc: 0.9484 - val_mDice: 0.6057

Epoch 00019: val_mDice improved from 0.60051 to 0.60572, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 20/300
 - 25s - loss: 1593.2316 - acc: 0.9505 - mDice: 0.7229 - val_loss: 2273.7516 - val_acc: 0.9488 - val_mDice: 0.6015

Epoch 00020: val_mDice did not improve from 0.60572
Epoch 21/300
 - 25s - loss: 1570.4463 - acc: 0.9508 - mDice: 0.7260 - val_loss: 2285.5750 - val_acc: 0.9488 - val_mDice: 0.6015

Epoch 00021: val_mDice did not improve from 0.60572
Epoch 22/300
 - 25s - loss: 1560.2576 - acc: 0.9511 - mDice: 0.7276 - val_loss: 2387.7692 - val_acc: 0.9500 - val_mDice: 0.5938

Epoch 00022: val_mDice did not improve from 0.60572
Epoch 23/300
 - 24s - loss: 1541.3561 - acc: 0.9513 - mDice: 0.7304 - val_loss: 2257.3228 - val_acc: 0.9505 - val_mDice: 0.6052

Epoch 00023: val_mDice did not improve from 0.60572
Epoch 24/300
 - 25s - loss: 1531.4277 - acc: 0.9516 - mDice: 0.7318 - val_loss: 2269.8369 - val_acc: 0.9498 - val_mDice: 0.6038

Epoch 00024: val_mDice did not improve from 0.60572
Epoch 25/300
 - 23s - loss: 1514.9585 - acc: 0.9518 - mDice: 0.7343 - val_loss: 2301.6274 - val_acc: 0.9505 - val_mDice: 0.6006

Epoch 00025: val_mDice did not improve from 0.60572
Epoch 26/300
 - 24s - loss: 1492.4343 - acc: 0.9521 - mDice: 0.7375 - val_loss: 2285.3923 - val_acc: 0.9490 - val_mDice: 0.6020

Epoch 00026: val_mDice did not improve from 0.60572
Epoch 27/300
 - 24s - loss: 1488.1779 - acc: 0.9522 - mDice: 0.7382 - val_loss: 2274.0578 - val_acc: 0.9484 - val_mDice: 0.6017

Epoch 00027: val_mDice did not improve from 0.60572
Epoch 28/300
 - 25s - loss: 1461.9216 - acc: 0.9526 - mDice: 0.7420 - val_loss: 2423.6779 - val_acc: 0.9477 - val_mDice: 0.5874

Epoch 00028: val_mDice did not improve from 0.60572
Epoch 29/300
 - 24s - loss: 1468.4141 - acc: 0.9525 - mDice: 0.7412 - val_loss: 2282.6094 - val_acc: 0.9484 - val_mDice: 0.6019

Epoch 00029: val_mDice did not improve from 0.60572
Epoch 30/300
 - 25s - loss: 1453.5571 - acc: 0.9527 - mDice: 0.7433 - val_loss: 2273.2964 - val_acc: 0.9498 - val_mDice: 0.6039

Epoch 00030: val_mDice did not improve from 0.60572
Epoch 31/300
 - 23s - loss: 1439.5590 - acc: 0.9529 - mDice: 0.7454 - val_loss: 2542.6072 - val_acc: 0.9477 - val_mDice: 0.5707

Epoch 00031: val_mDice did not improve from 0.60572
Epoch 32/300
 - 24s - loss: 1424.8286 - acc: 0.9531 - mDice: 0.7475 - val_loss: 2320.8674 - val_acc: 0.9480 - val_mDice: 0.5960

Epoch 00032: val_mDice did not improve from 0.60572
Epoch 33/300
 - 24s - loss: 1420.4815 - acc: 0.9531 - mDice: 0.7482 - val_loss: 2284.0372 - val_acc: 0.9496 - val_mDice: 0.6027

Epoch 00033: val_mDice did not improve from 0.60572
Epoch 34/300
 - 24s - loss: 1410.1373 - acc: 0.9533 - mDice: 0.7498 - val_loss: 2284.4171 - val_acc: 0.9495 - val_mDice: 0.6020

Epoch 00034: val_mDice did not improve from 0.60572
Epoch 35/300
 - 25s - loss: 1413.4942 - acc: 0.9534 - mDice: 0.7494 - val_loss: 2375.7745 - val_acc: 0.9496 - val_mDice: 0.5904

Epoch 00035: val_mDice did not improve from 0.60572
Epoch 36/300
 - 23s - loss: 1396.9343 - acc: 0.9535 - mDice: 0.7518 - val_loss: 2401.2478 - val_acc: 0.9484 - val_mDice: 0.5885

Epoch 00036: val_mDice did not improve from 0.60572
Epoch 37/300
 - 24s - loss: 1393.3706 - acc: 0.9536 - mDice: 0.7523 - val_loss: 2270.8503 - val_acc: 0.9477 - val_mDice: 0.6029

Epoch 00037: val_mDice did not improve from 0.60572
Epoch 38/300
 - 23s - loss: 1385.1707 - acc: 0.9538 - mDice: 0.7536 - val_loss: 2266.5080 - val_acc: 0.9511 - val_mDice: 0.6061

Epoch 00038: val_mDice improved from 0.60572 to 0.60609, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 39/300
 - 25s - loss: 1381.2015 - acc: 0.9538 - mDice: 0.7543 - val_loss: 2318.4068 - val_acc: 0.9462 - val_mDice: 0.5967

Epoch 00039: val_mDice did not improve from 0.60609
Epoch 40/300
 - 24s - loss: 1362.3917 - acc: 0.9541 - mDice: 0.7571 - val_loss: 2296.4842 - val_acc: 0.9497 - val_mDice: 0.5991

Epoch 00040: val_mDice did not improve from 0.60609
Epoch 41/300
 - 23s - loss: 1357.9458 - acc: 0.9542 - mDice: 0.7577 - val_loss: 2242.0082 - val_acc: 0.9473 - val_mDice: 0.6054

Epoch 00041: val_mDice did not improve from 0.60609
Epoch 42/300
 - 24s - loss: 1351.7721 - acc: 0.9543 - mDice: 0.7587 - val_loss: 2408.3985 - val_acc: 0.9485 - val_mDice: 0.5881

Epoch 00042: val_mDice did not improve from 0.60609
Epoch 43/300
 - 24s - loss: 1348.7175 - acc: 0.9542 - mDice: 0.7591 - val_loss: 2301.6057 - val_acc: 0.9504 - val_mDice: 0.6011

Epoch 00043: val_mDice did not improve from 0.60609
Epoch 44/300
 - 23s - loss: 1341.2946 - acc: 0.9545 - mDice: 0.7603 - val_loss: 2264.2572 - val_acc: 0.9480 - val_mDice: 0.6022

Epoch 00044: val_mDice did not improve from 0.60609
Epoch 45/300
 - 24s - loss: 1404.8153 - acc: 0.9534 - mDice: 0.7507 - val_loss: 2244.4899 - val_acc: 0.9488 - val_mDice: 0.6068

Epoch 00045: val_mDice improved from 0.60609 to 0.60680, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 46/300
 - 23s - loss: 1336.0641 - acc: 0.9545 - mDice: 0.7610 - val_loss: 2268.5623 - val_acc: 0.9484 - val_mDice: 0.6045

Epoch 00046: val_mDice did not improve from 0.60680
Epoch 47/300
 - 25s - loss: 1329.7741 - acc: 0.9547 - mDice: 0.7621 - val_loss: 2303.6300 - val_acc: 0.9495 - val_mDice: 0.6012

Epoch 00047: val_mDice did not improve from 0.60680
Epoch 48/300
 - 24s - loss: 1321.5803 - acc: 0.9548 - mDice: 0.7633 - val_loss: 2354.5707 - val_acc: 0.9497 - val_mDice: 0.5951

Epoch 00048: val_mDice did not improve from 0.60680
Epoch 49/300
 - 23s - loss: 1315.7208 - acc: 0.9549 - mDice: 0.7642 - val_loss: 2342.1528 - val_acc: 0.9483 - val_mDice: 0.5950

Epoch 00049: val_mDice did not improve from 0.60680
Epoch 50/300
 - 23s - loss: 1308.9822 - acc: 0.9549 - mDice: 0.7652 - val_loss: 2330.4758 - val_acc: 0.9482 - val_mDice: 0.5956

Epoch 00050: val_mDice did not improve from 0.60680
Epoch 51/300
 - 25s - loss: 1299.1262 - acc: 0.9550 - mDice: 0.7667 - val_loss: 2384.4724 - val_acc: 0.9502 - val_mDice: 0.5938

Epoch 00051: val_mDice did not improve from 0.60680
Epoch 52/300
 - 25s - loss: 1296.1195 - acc: 0.9552 - mDice: 0.7672 - val_loss: 2270.4913 - val_acc: 0.9496 - val_mDice: 0.6039

Epoch 00052: val_mDice did not improve from 0.60680
Epoch 53/300
 - 25s - loss: 1290.4754 - acc: 0.9552 - mDice: 0.7680 - val_loss: 2323.4260 - val_acc: 0.9487 - val_mDice: 0.5985

Epoch 00053: val_mDice did not improve from 0.60680
Epoch 54/300
 - 25s - loss: 1302.1516 - acc: 0.9551 - mDice: 0.7662 - val_loss: 2348.0026 - val_acc: 0.9483 - val_mDice: 0.5938

Epoch 00054: val_mDice did not improve from 0.60680
Epoch 55/300
 - 25s - loss: 1286.6762 - acc: 0.9553 - mDice: 0.7687 - val_loss: 2329.6726 - val_acc: 0.9506 - val_mDice: 0.6004

Epoch 00055: val_mDice did not improve from 0.60680
Epoch 56/300
 - 24s - loss: 1280.1953 - acc: 0.9552 - mDice: 0.7696 - val_loss: 2325.9827 - val_acc: 0.9503 - val_mDice: 0.5991

Epoch 00056: val_mDice did not improve from 0.60680
Epoch 57/300
 - 24s - loss: 1277.7785 - acc: 0.9554 - mDice: 0.7700 - val_loss: 2303.9015 - val_acc: 0.9490 - val_mDice: 0.5980

Epoch 00057: val_mDice did not improve from 0.60680
Epoch 58/300
 - 25s - loss: 1271.2934 - acc: 0.9555 - mDice: 0.7711 - val_loss: 2265.8530 - val_acc: 0.9483 - val_mDice: 0.6053

Epoch 00058: val_mDice did not improve from 0.60680
Epoch 59/300
 - 26s - loss: 1266.1572 - acc: 0.9555 - mDice: 0.7718 - val_loss: 2285.3957 - val_acc: 0.9470 - val_mDice: 0.6014

Epoch 00059: val_mDice did not improve from 0.60680
Epoch 60/300
 - 26s - loss: 1261.8919 - acc: 0.9556 - mDice: 0.7724 - val_loss: 2415.6038 - val_acc: 0.9470 - val_mDice: 0.5845

Epoch 00060: val_mDice did not improve from 0.60680
Epoch 61/300
 - 24s - loss: 1258.0235 - acc: 0.9557 - mDice: 0.7731 - val_loss: 2333.7809 - val_acc: 0.9504 - val_mDice: 0.5979

Epoch 00061: val_mDice did not improve from 0.60680
Epoch 62/300
 - 25s - loss: 1260.5518 - acc: 0.9556 - mDice: 0.7728 - val_loss: 2335.9828 - val_acc: 0.9500 - val_mDice: 0.5969

Epoch 00062: val_mDice did not improve from 0.60680
Epoch 63/300
 - 25s - loss: 1250.8236 - acc: 0.9558 - mDice: 0.7742 - val_loss: 2335.9705 - val_acc: 0.9513 - val_mDice: 0.5995

Epoch 00063: val_mDice did not improve from 0.60680
Epoch 64/300
 - 25s - loss: 1248.4591 - acc: 0.9559 - mDice: 0.7746 - val_loss: 2321.8364 - val_acc: 0.9467 - val_mDice: 0.5964

Epoch 00064: val_mDice did not improve from 0.60680
Epoch 65/300
 - 26s - loss: 1243.0788 - acc: 0.9559 - mDice: 0.7754 - val_loss: 2344.7398 - val_acc: 0.9512 - val_mDice: 0.5981

Epoch 00065: val_mDice did not improve from 0.60680
Epoch 66/300
 - 25s - loss: 1248.1766 - acc: 0.9559 - mDice: 0.7746 - val_loss: 2300.4409 - val_acc: 0.9510 - val_mDice: 0.6007

Epoch 00066: val_mDice did not improve from 0.60680
Epoch 67/300
 - 25s - loss: 1237.1885 - acc: 0.9561 - mDice: 0.7763 - val_loss: 2455.7612 - val_acc: 0.9471 - val_mDice: 0.5823

Epoch 00067: val_mDice did not improve from 0.60680
Epoch 68/300
 - 25s - loss: 1238.2056 - acc: 0.9560 - mDice: 0.7762 - val_loss: 2310.8708 - val_acc: 0.9495 - val_mDice: 0.6006

Epoch 00068: val_mDice did not improve from 0.60680
Epoch 69/300
 - 25s - loss: 1235.6590 - acc: 0.9560 - mDice: 0.7766 - val_loss: 2254.8881 - val_acc: 0.9504 - val_mDice: 0.6076

Epoch 00069: val_mDice improved from 0.60680 to 0.60755, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 70/300
 - 25s - loss: 1224.5823 - acc: 0.9562 - mDice: 0.7782 - val_loss: 2290.3434 - val_acc: 0.9496 - val_mDice: 0.6017

Epoch 00070: val_mDice did not improve from 0.60755
Epoch 71/300
 - 26s - loss: 1230.7826 - acc: 0.9561 - mDice: 0.7773 - val_loss: 2209.6848 - val_acc: 0.9494 - val_mDice: 0.6106

Epoch 00071: val_mDice improved from 0.60755 to 0.61056, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 72/300
 - 26s - loss: 1228.1844 - acc: 0.9561 - mDice: 0.7777 - val_loss: 2402.8869 - val_acc: 0.9509 - val_mDice: 0.5911

Epoch 00072: val_mDice did not improve from 0.61056
Epoch 73/300
 - 26s - loss: 1218.9073 - acc: 0.9562 - mDice: 0.7792 - val_loss: 2306.0974 - val_acc: 0.9498 - val_mDice: 0.6019

Epoch 00073: val_mDice did not improve from 0.61056
Epoch 74/300
 - 25s - loss: 1219.9483 - acc: 0.9563 - mDice: 0.7790 - val_loss: 2284.6660 - val_acc: 0.9484 - val_mDice: 0.6011

Epoch 00074: val_mDice did not improve from 0.61056
Epoch 75/300
 - 24s - loss: 1218.3511 - acc: 0.9562 - mDice: 0.7793 - val_loss: 2381.9412 - val_acc: 0.9468 - val_mDice: 0.5877

Epoch 00075: val_mDice did not improve from 0.61056
Epoch 76/300
 - 25s - loss: 1211.2653 - acc: 0.9563 - mDice: 0.7804 - val_loss: 2220.0126 - val_acc: 0.9482 - val_mDice: 0.6091

Epoch 00076: val_mDice did not improve from 0.61056
Epoch 77/300
 - 26s - loss: 1209.5231 - acc: 0.9565 - mDice: 0.7807 - val_loss: 2256.9900 - val_acc: 0.9510 - val_mDice: 0.6064

Epoch 00077: val_mDice did not improve from 0.61056
Epoch 78/300
 - 26s - loss: 1203.8365 - acc: 0.9565 - mDice: 0.7815 - val_loss: 2254.8332 - val_acc: 0.9477 - val_mDice: 0.6058

Epoch 00078: val_mDice did not improve from 0.61056
Epoch 79/300
 - 25s - loss: 1209.2569 - acc: 0.9565 - mDice: 0.7807 - val_loss: 2274.0125 - val_acc: 0.9487 - val_mDice: 0.6032

Epoch 00079: val_mDice did not improve from 0.61056
Epoch 80/300
 - 26s - loss: 1201.7676 - acc: 0.9566 - mDice: 0.7819 - val_loss: 2351.6357 - val_acc: 0.9511 - val_mDice: 0.5966

Epoch 00080: val_mDice did not improve from 0.61056
Epoch 81/300
 - 26s - loss: 1205.5167 - acc: 0.9566 - mDice: 0.7814 - val_loss: 2300.4093 - val_acc: 0.9474 - val_mDice: 0.5997

Epoch 00081: val_mDice did not improve from 0.61056
Epoch 82/300
 - 25s - loss: 1207.7177 - acc: 0.9565 - mDice: 0.7810 - val_loss: 2314.1654 - val_acc: 0.9487 - val_mDice: 0.5990

Epoch 00082: val_mDice did not improve from 0.61056
Epoch 83/300
 - 26s - loss: 1195.8049 - acc: 0.9567 - mDice: 0.7829 - val_loss: 2361.5859 - val_acc: 0.9487 - val_mDice: 0.5933

Epoch 00083: val_mDice did not improve from 0.61056
Epoch 84/300
 - 24s - loss: 1190.6610 - acc: 0.9568 - mDice: 0.7836 - val_loss: 2280.3770 - val_acc: 0.9502 - val_mDice: 0.6050

Epoch 00084: val_mDice did not improve from 0.61056
Epoch 85/300
 - 26s - loss: 1199.9039 - acc: 0.9567 - mDice: 0.7823 - val_loss: 2316.7263 - val_acc: 0.9494 - val_mDice: 0.6025

Epoch 00085: val_mDice did not improve from 0.61056
Epoch 86/300
 - 25s - loss: 1191.2478 - acc: 0.9567 - mDice: 0.7836 - val_loss: 2309.2403 - val_acc: 0.9439 - val_mDice: 0.5963

Epoch 00086: val_mDice did not improve from 0.61056
Epoch 87/300
 - 25s - loss: 1189.2054 - acc: 0.9568 - mDice: 0.7839 - val_loss: 2226.3592 - val_acc: 0.9482 - val_mDice: 0.6092

Epoch 00087: val_mDice did not improve from 0.61056
Epoch 88/300
 - 26s - loss: 1186.7886 - acc: 0.9569 - mDice: 0.7845 - val_loss: 2324.6502 - val_acc: 0.9517 - val_mDice: 0.6007

Epoch 00088: val_mDice did not improve from 0.61056
Epoch 89/300
 - 25s - loss: 1188.8252 - acc: 0.9568 - mDice: 0.7840 - val_loss: 2215.9018 - val_acc: 0.9495 - val_mDice: 0.6107

Epoch 00089: val_mDice improved from 0.61056 to 0.61074, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 90/300
 - 25s - loss: 1184.5850 - acc: 0.9568 - mDice: 0.7846 - val_loss: 2265.7174 - val_acc: 0.9482 - val_mDice: 0.6058

Epoch 00090: val_mDice did not improve from 0.61074
Epoch 91/300
 - 25s - loss: 1175.3274 - acc: 0.9570 - mDice: 0.7861 - val_loss: 2321.9061 - val_acc: 0.9475 - val_mDice: 0.5959

Epoch 00091: val_mDice did not improve from 0.61074
Epoch 92/300
 - 25s - loss: 1172.9050 - acc: 0.9569 - mDice: 0.7864 - val_loss: 2207.1586 - val_acc: 0.9467 - val_mDice: 0.6110

Epoch 00092: val_mDice improved from 0.61074 to 0.61097, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 93/300
 - 26s - loss: 1174.8736 - acc: 0.9570 - mDice: 0.7862 - val_loss: 2283.1974 - val_acc: 0.9477 - val_mDice: 0.6020

Epoch 00093: val_mDice did not improve from 0.61097
Epoch 94/300
 - 24s - loss: 1168.4275 - acc: 0.9571 - mDice: 0.7872 - val_loss: 2389.8863 - val_acc: 0.9487 - val_mDice: 0.5903

Epoch 00094: val_mDice did not improve from 0.61097
Epoch 95/300
 - 25s - loss: 1169.2251 - acc: 0.9570 - mDice: 0.7870 - val_loss: 2213.2994 - val_acc: 0.9495 - val_mDice: 0.6119

Epoch 00095: val_mDice improved from 0.61097 to 0.61192, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 96/300
 - 26s - loss: 1168.3385 - acc: 0.9571 - mDice: 0.7872 - val_loss: 2252.6789 - val_acc: 0.9493 - val_mDice: 0.6063

Epoch 00096: val_mDice did not improve from 0.61192
Epoch 97/300
 - 26s - loss: 1173.5527 - acc: 0.9570 - mDice: 0.7864 - val_loss: 2271.4110 - val_acc: 0.9486 - val_mDice: 0.6031

Epoch 00097: val_mDice did not improve from 0.61192
Epoch 98/300
 - 25s - loss: 1165.8681 - acc: 0.9571 - mDice: 0.7875 - val_loss: 2253.9088 - val_acc: 0.9494 - val_mDice: 0.6063

Epoch 00098: val_mDice did not improve from 0.61192
Epoch 99/300
 - 26s - loss: 1166.2894 - acc: 0.9571 - mDice: 0.7875 - val_loss: 2221.6824 - val_acc: 0.9482 - val_mDice: 0.6098

Epoch 00099: val_mDice did not improve from 0.61192
Epoch 100/300
 - 25s - loss: 1164.8776 - acc: 0.9572 - mDice: 0.7877 - val_loss: 2316.6887 - val_acc: 0.9477 - val_mDice: 0.5978

Epoch 00100: val_mDice did not improve from 0.61192
Epoch 101/300
 - 25s - loss: 1168.0788 - acc: 0.9571 - mDice: 0.7872 - val_loss: 2258.9424 - val_acc: 0.9492 - val_mDice: 0.6083

Epoch 00101: val_mDice did not improve from 0.61192
Epoch 102/300
 - 25s - loss: 1162.7422 - acc: 0.9572 - mDice: 0.7881 - val_loss: 2253.3416 - val_acc: 0.9477 - val_mDice: 0.6063

Epoch 00102: val_mDice did not improve from 0.61192
Epoch 103/300
 - 24s - loss: 1154.2903 - acc: 0.9573 - mDice: 0.7894 - val_loss: 2261.0071 - val_acc: 0.9486 - val_mDice: 0.6042

Epoch 00103: val_mDice did not improve from 0.61192
Epoch 104/300
 - 25s - loss: 1153.3412 - acc: 0.9574 - mDice: 0.7896 - val_loss: 2281.8674 - val_acc: 0.9480 - val_mDice: 0.6041

Epoch 00104: val_mDice did not improve from 0.61192
Epoch 105/300
 - 24s - loss: 1154.2137 - acc: 0.9573 - mDice: 0.7895 - val_loss: 2394.2971 - val_acc: 0.9464 - val_mDice: 0.5883

Epoch 00105: val_mDice did not improve from 0.61192
Epoch 106/300
 - 25s - loss: 1153.8834 - acc: 0.9574 - mDice: 0.7896 - val_loss: 2264.6772 - val_acc: 0.9494 - val_mDice: 0.6052

Epoch 00106: val_mDice did not improve from 0.61192
Epoch 107/300
 - 25s - loss: 1150.3888 - acc: 0.9574 - mDice: 0.7901 - val_loss: 2366.6642 - val_acc: 0.9485 - val_mDice: 0.5929

Epoch 00107: val_mDice did not improve from 0.61192
Epoch 108/300
 - 25s - loss: 1152.7703 - acc: 0.9573 - mDice: 0.7897 - val_loss: 2312.9729 - val_acc: 0.9489 - val_mDice: 0.5983

Epoch 00108: val_mDice did not improve from 0.61192
Epoch 109/300
 - 25s - loss: 1149.0401 - acc: 0.9574 - mDice: 0.7903 - val_loss: 2282.6448 - val_acc: 0.9466 - val_mDice: 0.6009

Epoch 00109: val_mDice did not improve from 0.61192
Epoch 110/300
 - 25s - loss: 1143.8203 - acc: 0.9575 - mDice: 0.7911 - val_loss: 2301.3326 - val_acc: 0.9479 - val_mDice: 0.6025

Epoch 00110: val_mDice did not improve from 0.61192
Epoch 111/300
 - 25s - loss: 1141.8507 - acc: 0.9575 - mDice: 0.7915 - val_loss: 2170.9017 - val_acc: 0.9485 - val_mDice: 0.6150

Epoch 00111: val_mDice improved from 0.61192 to 0.61496, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 112/300
 - 24s - loss: 1146.9188 - acc: 0.9575 - mDice: 0.7906 - val_loss: 2275.1505 - val_acc: 0.9500 - val_mDice: 0.6036

Epoch 00112: val_mDice did not improve from 0.61496
Epoch 113/300
 - 25s - loss: 1143.3319 - acc: 0.9576 - mDice: 0.7912 - val_loss: 2408.5060 - val_acc: 0.9451 - val_mDice: 0.5857

Epoch 00113: val_mDice did not improve from 0.61496
Epoch 114/300
 - 24s - loss: 1141.7420 - acc: 0.9576 - mDice: 0.7915 - val_loss: 2209.1732 - val_acc: 0.9489 - val_mDice: 0.6117

Epoch 00114: val_mDice did not improve from 0.61496
Epoch 115/300
 - 25s - loss: 1142.3658 - acc: 0.9575 - mDice: 0.7914 - val_loss: 2322.5189 - val_acc: 0.9466 - val_mDice: 0.5971

Epoch 00115: val_mDice did not improve from 0.61496
Epoch 116/300
 - 25s - loss: 1138.0597 - acc: 0.9577 - mDice: 0.7920 - val_loss: 2446.6611 - val_acc: 0.9493 - val_mDice: 0.5858

Epoch 00116: val_mDice did not improve from 0.61496
Epoch 117/300
 - 24s - loss: 1131.2367 - acc: 0.9577 - mDice: 0.7932 - val_loss: 2354.4758 - val_acc: 0.9462 - val_mDice: 0.5934

Epoch 00117: val_mDice did not improve from 0.61496
Epoch 118/300
 - 24s - loss: 1137.9040 - acc: 0.9576 - mDice: 0.7921 - val_loss: 2322.1914 - val_acc: 0.9499 - val_mDice: 0.6018

Epoch 00118: val_mDice did not improve from 0.61496
Epoch 119/300
 - 25s - loss: 1140.4163 - acc: 0.9576 - mDice: 0.7917 - val_loss: 2298.7740 - val_acc: 0.9480 - val_mDice: 0.6009

Epoch 00119: val_mDice did not improve from 0.61496
Epoch 120/300
 - 24s - loss: 1131.1063 - acc: 0.9576 - mDice: 0.7932 - val_loss: 2344.2538 - val_acc: 0.9485 - val_mDice: 0.5960

Epoch 00120: val_mDice did not improve from 0.61496
Epoch 121/300
 - 26s - loss: 1130.0240 - acc: 0.9577 - mDice: 0.7933 - val_loss: 2272.1671 - val_acc: 0.9461 - val_mDice: 0.6019

Epoch 00121: val_mDice did not improve from 0.61496
Epoch 122/300
 - 23s - loss: 1128.7061 - acc: 0.9578 - mDice: 0.7935 - val_loss: 2202.1925 - val_acc: 0.9486 - val_mDice: 0.6120

Epoch 00122: val_mDice did not improve from 0.61496
Epoch 123/300
 - 25s - loss: 1126.5773 - acc: 0.9578 - mDice: 0.7938 - val_loss: 2236.1807 - val_acc: 0.9500 - val_mDice: 0.6074

Epoch 00123: val_mDice did not improve from 0.61496
Epoch 124/300
 - 25s - loss: 1125.3743 - acc: 0.9578 - mDice: 0.7941 - val_loss: 2286.6245 - val_acc: 0.9520 - val_mDice: 0.6057

Epoch 00124: val_mDice did not improve from 0.61496
Epoch 125/300
 - 25s - loss: 1128.1391 - acc: 0.9578 - mDice: 0.7937 - val_loss: 2305.8542 - val_acc: 0.9498 - val_mDice: 0.6025

Epoch 00125: val_mDice did not improve from 0.61496
Epoch 126/300
 - 25s - loss: 1128.5914 - acc: 0.9578 - mDice: 0.7936 - val_loss: 2270.2481 - val_acc: 0.9505 - val_mDice: 0.6042

Epoch 00126: val_mDice did not improve from 0.61496
Epoch 127/300
 - 25s - loss: 1135.1711 - acc: 0.9576 - mDice: 0.7926 - val_loss: 2235.3198 - val_acc: 0.9503 - val_mDice: 0.6101

Epoch 00127: val_mDice did not improve from 0.61496
Epoch 128/300
 - 24s - loss: 1126.4235 - acc: 0.9579 - mDice: 0.7940 - val_loss: 2214.3143 - val_acc: 0.9499 - val_mDice: 0.6120

Epoch 00128: val_mDice did not improve from 0.61496
Epoch 129/300
 - 25s - loss: 1118.3499 - acc: 0.9578 - mDice: 0.7952 - val_loss: 2200.7105 - val_acc: 0.9487 - val_mDice: 0.6130

Epoch 00129: val_mDice did not improve from 0.61496
Epoch 130/300
 - 25s - loss: 1117.4863 - acc: 0.9579 - mDice: 0.7953 - val_loss: 2172.8732 - val_acc: 0.9503 - val_mDice: 0.6162

Epoch 00130: val_mDice improved from 0.61496 to 0.61616, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 131/300
 - 24s - loss: 1120.4171 - acc: 0.9579 - mDice: 0.7949 - val_loss: 2185.4952 - val_acc: 0.9492 - val_mDice: 0.6132

Epoch 00131: val_mDice did not improve from 0.61616
Epoch 132/300
 - 23s - loss: 1115.4051 - acc: 0.9580 - mDice: 0.7957 - val_loss: 2337.3103 - val_acc: 0.9506 - val_mDice: 0.5997

Epoch 00132: val_mDice did not improve from 0.61616
Epoch 133/300
 - 24s - loss: 1114.3808 - acc: 0.9580 - mDice: 0.7959 - val_loss: 2452.3888 - val_acc: 0.9486 - val_mDice: 0.5831

Epoch 00133: val_mDice did not improve from 0.61616
Epoch 134/300
 - 24s - loss: 1123.1722 - acc: 0.9579 - mDice: 0.7946 - val_loss: 2386.8286 - val_acc: 0.9505 - val_mDice: 0.5973

Epoch 00134: val_mDice did not improve from 0.61616
Epoch 135/300
 - 23s - loss: 1113.8522 - acc: 0.9579 - mDice: 0.7959 - val_loss: 2210.6149 - val_acc: 0.9494 - val_mDice: 0.6133

Epoch 00135: val_mDice did not improve from 0.61616
Epoch 136/300
 - 24s - loss: 1116.3394 - acc: 0.9580 - mDice: 0.7956 - val_loss: 2247.8265 - val_acc: 0.9505 - val_mDice: 0.6082

Epoch 00136: val_mDice did not improve from 0.61616
Epoch 137/300
 - 24s - loss: 1107.3566 - acc: 0.9581 - mDice: 0.7970 - val_loss: 2318.2086 - val_acc: 0.9469 - val_mDice: 0.5985

Epoch 00137: val_mDice did not improve from 0.61616
Epoch 138/300
 - 24s - loss: 1109.4598 - acc: 0.9580 - mDice: 0.7967 - val_loss: 2295.1708 - val_acc: 0.9443 - val_mDice: 0.5996

Epoch 00138: val_mDice did not improve from 0.61616
Epoch 139/300
 - 24s - loss: 1109.1039 - acc: 0.9581 - mDice: 0.7967 - val_loss: 2271.0646 - val_acc: 0.9500 - val_mDice: 0.6062

Epoch 00139: val_mDice did not improve from 0.61616
Epoch 140/300
 - 25s - loss: 1103.7052 - acc: 0.9581 - mDice: 0.7976 - val_loss: 2358.8978 - val_acc: 0.9498 - val_mDice: 0.5934

Epoch 00140: val_mDice did not improve from 0.61616
Epoch 141/300
 - 24s - loss: 1111.2731 - acc: 0.9581 - mDice: 0.7964 - val_loss: 2296.1566 - val_acc: 0.9455 - val_mDice: 0.5991

Epoch 00141: val_mDice did not improve from 0.61616
Epoch 142/300
 - 24s - loss: 1111.0342 - acc: 0.9580 - mDice: 0.7964 - val_loss: 2284.7442 - val_acc: 0.9497 - val_mDice: 0.6052

Epoch 00142: val_mDice did not improve from 0.61616
Epoch 143/300
 - 24s - loss: 1105.2590 - acc: 0.9581 - mDice: 0.7973 - val_loss: 2287.0751 - val_acc: 0.9473 - val_mDice: 0.6018

Epoch 00143: val_mDice did not improve from 0.61616
Epoch 144/300
 - 25s - loss: 1110.6322 - acc: 0.9581 - mDice: 0.7965 - val_loss: 2246.6444 - val_acc: 0.9504 - val_mDice: 0.6083

Epoch 00144: val_mDice did not improve from 0.61616
Epoch 145/300
 - 25s - loss: 1100.7325 - acc: 0.9582 - mDice: 0.7980 - val_loss: 2283.3813 - val_acc: 0.9468 - val_mDice: 0.6015

Epoch 00145: val_mDice did not improve from 0.61616
Epoch 146/300
 - 26s - loss: 1106.9981 - acc: 0.9581 - mDice: 0.7971 - val_loss: 2276.5034 - val_acc: 0.9486 - val_mDice: 0.6044

Epoch 00146: val_mDice did not improve from 0.61616
Epoch 147/300
 - 26s - loss: 1099.7464 - acc: 0.9582 - mDice: 0.7982 - val_loss: 2239.5188 - val_acc: 0.9483 - val_mDice: 0.6083

Epoch 00147: val_mDice did not improve from 0.61616
Epoch 148/300
 - 26s - loss: 1101.2120 - acc: 0.9582 - mDice: 0.7980 - val_loss: 2256.8317 - val_acc: 0.9503 - val_mDice: 0.6073

Epoch 00148: val_mDice did not improve from 0.61616
Epoch 149/300
 - 26s - loss: 1096.8014 - acc: 0.9583 - mDice: 0.7987 - val_loss: 2402.3534 - val_acc: 0.9495 - val_mDice: 0.5911

Epoch 00149: val_mDice did not improve from 0.61616
Epoch 150/300
 - 25s - loss: 1103.2474 - acc: 0.9582 - mDice: 0.7977 - val_loss: 2216.2925 - val_acc: 0.9499 - val_mDice: 0.6122

Epoch 00150: val_mDice did not improve from 0.61616
Epoch 151/300
 - 25s - loss: 1094.9574 - acc: 0.9583 - mDice: 0.7990 - val_loss: 2224.0651 - val_acc: 0.9490 - val_mDice: 0.6085

Epoch 00151: val_mDice did not improve from 0.61616
Epoch 152/300
 - 24s - loss: 1095.1942 - acc: 0.9582 - mDice: 0.7989 - val_loss: 2269.7293 - val_acc: 0.9477 - val_mDice: 0.6037

Epoch 00152: val_mDice did not improve from 0.61616
Epoch 153/300
 - 25s - loss: 1095.0046 - acc: 0.9583 - mDice: 0.7990 - val_loss: 2267.7171 - val_acc: 0.9515 - val_mDice: 0.6080

Epoch 00153: val_mDice did not improve from 0.61616
Epoch 154/300
 - 25s - loss: 1096.1048 - acc: 0.9582 - mDice: 0.7988 - val_loss: 2265.3693 - val_acc: 0.9490 - val_mDice: 0.6056

Epoch 00154: val_mDice did not improve from 0.61616
Epoch 155/300
 - 26s - loss: 1095.8156 - acc: 0.9583 - mDice: 0.7989 - val_loss: 2292.6646 - val_acc: 0.9482 - val_mDice: 0.6012

Epoch 00155: val_mDice did not improve from 0.61616
Epoch 156/300
 - 23s - loss: 1094.2935 - acc: 0.9584 - mDice: 0.7992 - val_loss: 2250.0786 - val_acc: 0.9489 - val_mDice: 0.6075

Epoch 00156: val_mDice did not improve from 0.61616
Epoch 157/300
 - 25s - loss: 1091.9258 - acc: 0.9583 - mDice: 0.7995 - val_loss: 2320.5064 - val_acc: 0.9505 - val_mDice: 0.6024

Epoch 00157: val_mDice did not improve from 0.61616
Epoch 158/300
 - 25s - loss: 1084.9433 - acc: 0.9584 - mDice: 0.8006 - val_loss: 2387.3352 - val_acc: 0.9486 - val_mDice: 0.5913

Epoch 00158: val_mDice did not improve from 0.61616
Epoch 159/300
 - 25s - loss: 1088.6255 - acc: 0.9584 - mDice: 0.8000 - val_loss: 2295.3451 - val_acc: 0.9510 - val_mDice: 0.6070

Epoch 00159: val_mDice did not improve from 0.61616
Epoch 160/300
 - 26s - loss: 1096.6909 - acc: 0.9583 - mDice: 0.7988 - val_loss: 2286.0911 - val_acc: 0.9480 - val_mDice: 0.6017

Epoch 00160: val_mDice did not improve from 0.61616
Restoring model weights from the end of the best epoch
Epoch 00160: early stopping
{'val_loss': [5608.99270578736, 3243.710993420478, 2669.282852599075, 2582.4712486906424, 2679.0041735771647, 2449.0959390821404, 2490.9387234309534, 2287.3144817671964, 2455.677576160964, 2279.3098362757505, 2456.157435241358, 2479.1267580852827, 2443.0285194439593, 2320.091899168558, 2420.4848087246855, 2337.997639064682, 2310.9348471870635, 2280.823178083537, 2242.8872397651885, 2273.7515944155903, 2285.574960719274, 2387.769194363216, 2257.3227770927897, 2269.836874508991, 2301.6274250392808, 2285.39231898132, 2274.057809499389, 2423.6778939529504, 2282.6094241009077, 2273.296398993977, 2542.607228199197, 2320.8673607170913, 2284.037222579871, 2284.417067202776, 2375.7745109004013, 2401.2477536334673, 2270.8503486164454, 2266.507981625349, 2318.4068078408695, 2296.484218149878, 2242.008239405115, 2408.3984852369936, 2301.605673337116, 2264.257243747818, 2244.489862026449, 2268.562280409829, 2303.630020567825, 2354.5706930320357, 2342.152791113827, 2330.475839625524, 2384.472356188897, 2270.4913336897694, 2323.4259667423185, 2348.0025805254886, 2329.6726360640714, 2325.9827082969623, 2303.9014749367143, 2265.853039618977, 2285.3956551152237, 2415.603769313024, 2333.7808694679643, 2335.982756033956, 2335.970536727479, 2321.8364298729925, 2344.739757005063, 2300.4409125130937, 2455.7611595452163, 2310.870759591044, 2254.888148131983, 2290.343418568872, 2209.6847571687326, 2402.8868537774965, 2306.0973739197802, 2284.6660183528284, 2381.9412453081354, 2220.012608021997, 2256.990040699197, 2254.8331578430516, 2274.012481177985, 2351.6356821752793, 2300.4093242623953, 2314.165399135824, 2361.585936136086, 2280.3770008619936, 2316.726348365485, 2309.2402561976255, 2226.3592045107366, 2324.650209224424, 2215.9018281904678, 2265.7173642632683, 2321.9061313394727, 2207.15858502095, 2283.1974402060055, 2389.886282297486, 2213.299420063722, 2252.678878698935, 2271.411040066341, 2253.9087909719797, 2221.6824330590957, 2316.688709791812, 2258.9424291855794, 2253.341618202252, 2261.007080078125, 2281.8673784479747, 2394.297106865398, 2264.6771506197624, 2366.6642493562326, 2312.9728512897173, 2282.6447972132505, 2301.3325877269554, 2170.9016849794866, 2275.150502465957, 2408.5059930385823, 2209.173248461505, 2322.518914760824, 2446.6611014424757, 2354.4758137111558, 2322.191350329522, 2298.7739571512743, 2344.253816231669, 2272.1671258510823, 2202.1924510082054, 2236.1806695181563, 2286.624455798272, 2305.8542044016235, 2270.2480932480794, 2235.3197969404678, 2214.314264904853, 2200.7104874083448, 2172.8731682633556, 2185.495233120199, 2337.3102700004365, 2452.3887537098462, 2386.828611917336, 2210.6149356778105, 2247.826516945269, 2318.2085547420565, 2295.170835697451, 2271.0646140668646, 2358.897780093401, 2296.1566387155203, 2284.744241554644, 2287.075079379801, 2246.6443948585893, 2283.3812794605446, 2276.503443883118, 2239.5187770054995, 2256.8317339167247, 2402.3533969644727, 2216.292455918296, 2224.0650764337465, 2269.729348976519, 2267.7170628382505, 2265.369253829871, 2292.6645794234464, 2250.0785791833973, 2320.5063762984464, 2387.3351668885302, 2295.345082544082, 2286.091054905726], 'val_acc': [0.9199695737002282, 0.9355351864958609, 0.9464273938919578, 0.9406590078796089, 0.9434212779199611, 0.9433138670202074, 0.9434502168074667, 0.9492268645563605, 0.9474211794704033, 0.9483219568289858, 0.9487702999701048, 0.9460575633874818, 0.9468054801392156, 0.9470368577115362, 0.9483323040621241, 0.9471298566077675, 0.9478922333131289, 0.9475306642122109, 0.9483818654907482, 0.9487909438223813, 0.9488364145076474, 0.9499541274662124, 0.9504561960364187, 0.9497805880434687, 0.9504913091659546, 0.9490161667988953, 0.9483798106289443, 0.947714529556935, 0.9484149547262565, 0.9497867925873016, 0.9477455259701393, 0.9479790000276193, 0.9496214869302079, 0.9494995921017737, 0.9496214726117737, 0.9483839356699469, 0.9477496526760762, 0.9511483205097347, 0.9462042507512609, 0.9496607370882727, 0.9473240558661562, 0.948549217351988, 0.9503652739791231, 0.9479996465437905, 0.9488260895846277, 0.9483591581190098, 0.949483062634921, 0.9497186072045865, 0.9483116322389528, 0.9482269377015823, 0.9501937927480516, 0.9496153103572696, 0.9486752565346617, 0.9482847552059749, 0.950640061048156, 0.9502785229150144, 0.949005817567836, 0.9482641183464221, 0.9469810957349213, 0.9470141613283637, 0.9503983235891971, 0.949960316026677, 0.9512557364042911, 0.9467063123287436, 0.951195808096305, 0.9510139922855952, 0.9470699153132944, 0.9494727473685195, 0.9504148563859183, 0.9496297753057, 0.949437618921589, 0.9508983266420205, 0.949848764435539, 0.9483798096299837, 0.9467910241814299, 0.9482310447612954, 0.9509603011541526, 0.9477496590028262, 0.9486546120164114, 0.9511235229795871, 0.9473509012653841, 0.9487372130655044, 0.948716568880241, 0.950185545329941, 0.9493611751321974, 0.9438675735249865, 0.9482392968412218, 0.9516751549763387, 0.9495016602830514, 0.9482021345106583, 0.9475347989098319, 0.9467352392287228, 0.9477207307708996, 0.9487144893774108, 0.9495099206876488, 0.9492620322957385, 0.9485615974697987, 0.9494149065550479, 0.9482186426663531, 0.9476918355046704, 0.9492041718360432, 0.9477434454683485, 0.9486236079445098, 0.947974859336235, 0.9464108491077103, 0.949394253046153, 0.9484645061652753, 0.9489335091420392, 0.9465720333866567, 0.9478901431547196, 0.948522353305497, 0.9499582811440835, 0.9450823854467723, 0.948923193542651, 0.9465740739300265, 0.9492805879875268, 0.9462373200075587, 0.9499086717653541, 0.948016187332196, 0.9485492176849749, 0.9461195758601141, 0.9486380815505981, 0.9499789150067548, 0.9520305098768053, 0.9498301631245534, 0.9504954435305888, 0.9502516418861944, 0.9499252278711543, 0.9486669814786431, 0.9502743745649327, 0.9492186324556446, 0.9506007979036043, 0.9486008902501794, 0.9505202267423022, 0.9494169587529572, 0.9504768448834978, 0.9469087836462692, 0.944282823767742, 0.9499933926086852, 0.949799173038099, 0.9455245153864003, 0.949710334146489, 0.9472806603548913, 0.9504065939833998, 0.9467951572141168, 0.9485574760916513, 0.9483012886686698, 0.9503487341896781, 0.9495285259944767, 0.9498839042040222, 0.9490306067733125, 0.9476814766169926, 0.9515181400256449, 0.948991347291616, 0.9481711097935724, 0.9488694787691425, 0.950514024862364, 0.9485926068694898, 0.9510449960245101, 0.9480058500886629], 'val_mDice': [0.3378605792642306, 0.49737923305127874, 0.5526049996221531, 0.5618160909780577, 0.5527130844872757, 0.5779814027541177, 0.5728527517292087, 0.598903023330859, 0.5785048244385745, 0.6003462472441476, 0.5800765659556043, 0.575726646950791, 0.5801781878791041, 0.5942666390754657, 0.5855169802404648, 0.5937871679913398, 0.5955997582254463, 0.6005145780867038, 0.6057207347960446, 0.6014975455886159, 0.6015058985635555, 0.5937836003703112, 0.6051891982222403, 0.6037654616979248, 0.6005568590910075, 0.6020452083822069, 0.6017292971051605, 0.5873657954471737, 0.6018602914650347, 0.6039143501047316, 0.5706924259995615, 0.5959901916248173, 0.6027168754758782, 0.6019780782347951, 0.5903504400945908, 0.5884760971175892, 0.6029354653544932, 0.6060860942861888, 0.5966545703024838, 0.5991389351850115, 0.6053882281207505, 0.5880749079102244, 0.6011328877017484, 0.6021752697129489, 0.6068028008471654, 0.6044726764689611, 0.6011845799131766, 0.5951202242068072, 0.5949964263585693, 0.5955614560809215, 0.5938100375276704, 0.6039153783681006, 0.5984539056623448, 0.5938086456426696, 0.6004483649850557, 0.599091705996231, 0.5979608826797101, 0.6053015559745234, 0.6013916044927842, 0.5844924739619207, 0.5979231216388041, 0.5968912000762684, 0.5995159938348739, 0.5964178233173306, 0.5980982274316543, 0.6006805783543507, 0.5822902018797464, 0.6006390262582448, 0.6075528353952163, 0.6017179549073374, 0.6105624913503338, 0.591115119403967, 0.601905825417801, 0.6011062427605997, 0.5876718929360033, 0.609051003802422, 0.6064078195135021, 0.6057678081469828, 0.6032298556919204, 0.596556295229736, 0.5997219308794544, 0.5990219122870675, 0.5932697883531368, 0.6050144860198378, 0.6025059003403733, 0.5963404751356753, 0.6092302379661432, 0.6007272994052099, 0.6107404298622515, 0.6058319397478796, 0.5959029757110766, 0.6109650867611336, 0.6020001539304936, 0.5903142274425016, 0.611916013270117, 0.6062651083456071, 0.6030839172155498, 0.6063079840644112, 0.6097554694340882, 0.597779093174961, 0.6083367070672232, 0.6062995621611952, 0.6041534329925835, 0.6040695276340293, 0.588271504340891, 0.6051935483623483, 0.5928663931079416, 0.5983170277579537, 0.6009247629336139, 0.6024977734634996, 0.6149603857674413, 0.6036489339514152, 0.5857034548700855, 0.6116625716566374, 0.5970569922271387, 0.585822780705031, 0.593391780080742, 0.6017597840484961, 0.600928287266353, 0.5960106293582383, 0.6019303092743431, 0.6119625601688576, 0.6074076011860171, 0.6057105180937484, 0.6025033143645558, 0.6041598929373245, 0.6101314418808708, 0.6119610350891198, 0.613015794887223, 0.6161645108095094, 0.6132356214789705, 0.5997433945453366, 0.583098820467901, 0.5972686576443678, 0.6132982916006163, 0.6082181387773439, 0.5984988891878608, 0.5995740457620035, 0.6062064530463193, 0.5934384315373511, 0.5991047194550158, 0.6051551922739551, 0.6017809060698781, 0.6083340714763663, 0.6015044963559625, 0.6044105784187104, 0.6082921860604312, 0.6073103766867568, 0.5911476502205406, 0.6122470541373312, 0.6085134554841665, 0.6036749608689846, 0.6080471933221018, 0.6055776699961231, 0.6012287432921, 0.6075153151037973, 0.6023717872257339, 0.5913154586067413, 0.6069720021173275, 0.6017404511654177], 'loss': [10906.991397091237, 4135.4053390899335, 3085.7883956507785, 2636.457537827503, 2380.786073123634, 2236.9734226249866, 2138.597292572083, 2041.9156514285119, 1975.5739435482944, 1916.2418121076944, 1872.1665047705353, 1833.6032728406378, 1783.6277965809302, 1763.4622644370731, 1730.7395686892394, 1691.2913965553794, 1663.711035719365, 1635.9875350294792, 1617.2438470472614, 1593.2315624397659, 1570.4462792861048, 1560.2576448619122, 1541.3561065193485, 1531.4277136554244, 1514.958468140772, 1492.4343205639937, 1488.1778936527905, 1461.9216115326283, 1468.4141234852937, 1453.557083704134, 1439.559024669306, 1424.8285809835768, 1420.481452309886, 1410.1372688143454, 1413.4941760407482, 1396.9342701362762, 1393.370635811809, 1385.1707257333712, 1381.201481634817, 1362.3916867344826, 1357.9457591891867, 1351.7721334199462, 1348.7174709675962, 1341.294574871139, 1404.815324201491, 1336.0640665601459, 1329.7740580567763, 1321.5803457974519, 1315.7207514817571, 1308.982219469378, 1299.126226689962, 1296.1195389939953, 1290.4754423132442, 1302.1516298836634, 1286.6762347770123, 1280.1952576777246, 1277.7784547520635, 1271.293407663944, 1266.1572280251364, 1261.8918521054838, 1258.0235416762846, 1260.5518213507592, 1250.8235687377191, 1248.4591104841838, 1243.0787543990787, 1248.1766219967285, 1237.1885414669946, 1238.2055969520836, 1235.6590199243801, 1224.5823299502906, 1230.7825746633382, 1228.1843618735022, 1218.9073140580801, 1219.9483191687182, 1218.3510819474543, 1211.2653394135752, 1209.5231303064452, 1203.8365489784574, 1209.2569441559801, 1201.7675947126277, 1205.5166705224867, 1207.7177143469855, 1195.8049390801261, 1190.6610176498207, 1199.9038577483088, 1191.247793001194, 1189.2053943170934, 1186.7886110771897, 1188.8251792002293, 1184.5849673731007, 1175.3273734641252, 1172.9050033949122, 1174.87355591904, 1168.4275076065076, 1169.2250696633819, 1168.3385287699803, 1173.5527230262705, 1165.8681366114722, 1166.2894342822528, 1164.8776432766801, 1168.0788228870329, 1162.7422085087787, 1154.2902789581549, 1153.3412146625692, 1154.2136900555718, 1153.8834216448874, 1150.3887598592337, 1152.7703478798471, 1149.0401449706792, 1143.8203382756442, 1141.8507031113045, 1146.9188381876731, 1143.331879996765, 1141.7419619215618, 1142.3657566592244, 1138.0597443197048, 1131.236695263382, 1137.9040323073266, 1140.4163368100026, 1131.10629629311, 1130.024032623522, 1128.7061463748635, 1126.5772948241442, 1125.374274326198, 1128.1390849335198, 1128.5914366475754, 1135.1711066404814, 1126.4235014950007, 1118.3499093750424, 1117.4862841229105, 1120.4171464191945, 1115.4051069562247, 1114.3807529881399, 1123.1721921694004, 1113.8522105410457, 1116.3393598566595, 1107.3565920116166, 1109.459763468276, 1109.1039266757186, 1103.705159075282, 1111.2730700724148, 1111.0341914816688, 1105.2589706920355, 1110.632228465922, 1100.7324823749643, 1106.9981206816321, 1099.746400105863, 1101.212041763963, 1096.8013613947946, 1103.2473760733358, 1094.9573697107342, 1095.1941588720551, 1095.0045581504116, 1096.1048100682738, 1095.815614671127, 1094.2934559675143, 1091.9257730426148, 1084.943340447154, 1088.625538968253, 1096.6909317840166], 'acc': [0.7890694551829269, 0.9059927393574515, 0.9234219290391986, 0.9337084178480212, 0.9381083615380275, 0.9405271028207607, 0.9421666385749476, 0.9436799685333453, 0.944671910382143, 0.9457523712703627, 0.9463222816803183, 0.9469756624529964, 0.9476276276145493, 0.9480657363520956, 0.948499583586402, 0.9490332413840337, 0.9494600641033396, 0.9498764724845974, 0.9501811603426992, 0.9505095294141138, 0.9508225722196322, 0.9511260275591187, 0.9512988050014752, 0.9515538177915625, 0.9518006960944824, 0.9520715402301169, 0.9521665097088032, 0.9525500498762786, 0.9525143783094187, 0.9527086241138403, 0.9529097382912325, 0.9531226572949645, 0.9531128267097639, 0.9533464940315848, 0.9533696148554086, 0.9534998133183694, 0.9535801991009581, 0.9538458694846054, 0.9538121912274367, 0.9540929258807891, 0.9541547217274808, 0.9542535959969847, 0.9542189726226503, 0.9545066990004951, 0.953358539769634, 0.9545428114521446, 0.9546754458755535, 0.9548102133667915, 0.9548613147780783, 0.9549043784895452, 0.9550459722951635, 0.9551808218422049, 0.9551869446847844, 0.9551139112963057, 0.9553238858221456, 0.9552490633723848, 0.955401213270641, 0.9555163835688397, 0.9555016201076525, 0.9556004361911288, 0.9557182445588971, 0.9556363078154716, 0.9557936336017565, 0.9558726496234464, 0.9558997798197137, 0.9558692452993394, 0.9560600690063611, 0.9559783516259477, 0.9560235113848542, 0.9561797324903819, 0.9560957202581037, 0.956110485530706, 0.9562163070216755, 0.9562647296292779, 0.9562497226269078, 0.9563247500847033, 0.9564720066172463, 0.9565096911726471, 0.9564639712482436, 0.9565514871824944, 0.9565793241779825, 0.9565041337155561, 0.9566710278246567, 0.95675195763232, 0.9567201976507073, 0.956742311873134, 0.9567667427136224, 0.9569367990047868, 0.9568432405275312, 0.9568361500581946, 0.9569799840096445, 0.956944555165909, 0.9569982509488121, 0.9570682442407061, 0.9570219168819625, 0.9570549098269286, 0.9569773828793076, 0.9570907014535992, 0.9571151956903682, 0.9571813607448314, 0.9570501396114689, 0.9571698001154199, 0.9573228153409304, 0.9573753458710448, 0.9572954230283601, 0.9574139577346095, 0.9573695241778409, 0.9573170135343368, 0.9574095459910469, 0.957509206986026, 0.957479538520069, 0.9574771434235863, 0.957596079202449, 0.9575702570426257, 0.9575279584884592, 0.9576504620992309, 0.957707561888107, 0.9575956353473284, 0.9576226235130736, 0.9575984955684506, 0.9577415621518945, 0.9577506644605948, 0.9577637984273377, 0.9578394503688495, 0.9578206593658818, 0.9577771510201909, 0.9576411165999442, 0.9579181232247748, 0.9578457757458111, 0.9578719586466699, 0.9578612444739827, 0.9579800412413485, 0.9580040077070844, 0.9579118012726213, 0.957890348242659, 0.9580022777732463, 0.9580974652352828, 0.9580358920400682, 0.9580639508170348, 0.958121174635902, 0.9580898730526705, 0.9580282800000618, 0.9581272577247383, 0.9580784116907516, 0.9581779130020275, 0.9580663090067474, 0.9582151534101437, 0.9582440573680532, 0.9582655062168279, 0.9581734400826286, 0.9583072220082571, 0.9582283466244425, 0.9582725185745714, 0.9582020628556831, 0.9583132250377422, 0.9583693978073718, 0.9583322181628164, 0.958427508580101, 0.9583815849656457, 0.9582723987809545], 'mDice': [0.18830414110336433, 0.4421477918271425, 0.5391506821584237, 0.5885962889699737, 0.6186490518115365, 0.6363786349115558, 0.6489362330986234, 0.6612518823787632, 0.670173487936085, 0.6780676234587171, 0.6838862863892492, 0.6893422645354127, 0.6960028660569431, 0.6990079343542931, 0.7032282681975721, 0.7089273389255382, 0.7129058304561989, 0.7167229989496791, 0.7194057815533682, 0.7228880588164692, 0.7260222036810874, 0.727599739483009, 0.7303663489768061, 0.7318309597132558, 0.73430473157104, 0.7374587358813434, 0.7382114488998923, 0.7419971725362999, 0.7411911374836613, 0.7433153764886421, 0.7453874525184511, 0.7475402021802827, 0.7481866301219517, 0.7498096916438071, 0.7493909895923245, 0.7518230743816193, 0.7523394161810458, 0.7536482486607469, 0.7543031167382801, 0.7570520195233316, 0.757680026734098, 0.7586900231515028, 0.7591484802285153, 0.7603109805167523, 0.7507449859536868, 0.7609754215884745, 0.7620823454327083, 0.7632779445135803, 0.7641792660035843, 0.7652237257869939, 0.7666683889319647, 0.7672077533070489, 0.7680146900840487, 0.7662210684833908, 0.7687211443828501, 0.769566391137137, 0.7700424788142464, 0.7710605775808095, 0.7717882157164159, 0.7724371856415001, 0.7730857074263958, 0.7727686744630677, 0.7741605331452218, 0.774567911976284, 0.7753538085117, 0.7745931447055447, 0.7763125819679725, 0.7761589666706474, 0.7765620241341239, 0.7782109656382488, 0.7773256756064614, 0.7777216329234896, 0.7791530019635371, 0.7790347013745678, 0.7793176150920571, 0.7804167787011078, 0.7806577906162675, 0.7815363953351312, 0.7807061313660886, 0.7819104387436705, 0.7813504735022795, 0.7810069927429881, 0.7829078936731365, 0.7836177839081594, 0.7822888412933179, 0.7836144158967563, 0.7839255236273049, 0.7844910796811447, 0.7840308758156939, 0.7846111456401649, 0.7860946145058197, 0.7864325814832498, 0.7861701772497485, 0.7871743609693457, 0.7870467481877534, 0.7872009972531087, 0.7864099027842882, 0.7875360581234814, 0.787508686577259, 0.7877471591352306, 0.7872039062525866, 0.788137406979139, 0.7894155673423394, 0.7896034730252705, 0.7894551277056764, 0.7895769664037656, 0.7900667812341076, 0.7896677297831919, 0.7902821470732705, 0.7911393674758322, 0.7914812111606538, 0.7906225914854116, 0.7912000901662318, 0.7914725775669605, 0.7914401065335217, 0.7920462339702602, 0.7931900765698341, 0.7920786503203898, 0.7916905604496441, 0.7931750958199971, 0.7933101509853708, 0.7935479114819285, 0.7938322096918606, 0.7941381237318713, 0.7936658505345279, 0.7936248323781175, 0.7925758625802557, 0.7939715774339383, 0.795219626375276, 0.7953159633879243, 0.7948799969505805, 0.7956776451320471, 0.7958593558988555, 0.7945775634601909, 0.7959091700887402, 0.7955785809691114, 0.7969556368453643, 0.7966965656577616, 0.7966706533167371, 0.7975983624819037, 0.7963887003926201, 0.7963501600377486, 0.7973152898598144, 0.7965177621114787, 0.7980441023604711, 0.7970595416384619, 0.7982162329296317, 0.7979548349144685, 0.7987202549349488, 0.7976802297195807, 0.7990225941505991, 0.7989230574193418, 0.7989636144894646, 0.7988381255757906, 0.7988789427982268, 0.7991743412459833, 0.7994959962717959, 0.8006324120079742, 0.8000162485397548, 0.7987674057376546]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.36s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.12s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.92s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:15,  1.96s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:38,  1.83s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:24,  1.79s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:54,  1.69s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:08,  1.74s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:43,  1.66s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<08:05,  1.74s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<08:12,  1.78s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:39,  1.88s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:49,  1.92s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:25,  1.84s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:39,  1.90s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:18,  1.83s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<08:21,  1.85s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:36,  1.91s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<08:47,  1.96s/it]predicting train subjects:   6%|▌         | 17/285 [00:31<08:23,  1.88s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:20,  1.87s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<08:02,  1.82s/it]predicting train subjects:   7%|▋         | 20/285 [00:36<08:11,  1.85s/it]predicting train subjects:   7%|▋         | 21/285 [00:38<08:25,  1.92s/it]predicting train subjects:   8%|▊         | 22/285 [00:40<08:02,  1.83s/it]predicting train subjects:   8%|▊         | 23/285 [00:42<08:07,  1.86s/it]predicting train subjects:   8%|▊         | 24/285 [00:43<07:52,  1.81s/it]predicting train subjects:   9%|▉         | 25/285 [00:45<08:11,  1.89s/it]predicting train subjects:   9%|▉         | 26/285 [00:47<08:18,  1.93s/it]predicting train subjects:   9%|▉         | 27/285 [00:49<07:55,  1.84s/it]predicting train subjects:  10%|▉         | 28/285 [00:51<07:54,  1.85s/it]predicting train subjects:  10%|█         | 29/285 [00:53<07:53,  1.85s/it]predicting train subjects:  11%|█         | 30/285 [00:55<08:06,  1.91s/it]predicting train subjects:  11%|█         | 31/285 [00:57<08:17,  1.96s/it]predicting train subjects:  11%|█         | 32/285 [00:58<07:48,  1.85s/it]predicting train subjects:  12%|█▏        | 33/285 [01:00<07:49,  1.86s/it]predicting train subjects:  12%|█▏        | 34/285 [01:02<07:45,  1.85s/it]predicting train subjects:  12%|█▏        | 35/285 [01:04<07:53,  1.89s/it]predicting train subjects:  13%|█▎        | 36/285 [01:06<07:32,  1.82s/it]predicting train subjects:  13%|█▎        | 37/285 [01:08<07:32,  1.82s/it]predicting train subjects:  13%|█▎        | 38/285 [01:10<07:52,  1.91s/it]predicting train subjects:  14%|█▎        | 39/285 [01:11<07:30,  1.83s/it]predicting train subjects:  14%|█▍        | 40/285 [01:13<07:35,  1.86s/it]predicting train subjects:  14%|█▍        | 41/285 [01:15<07:16,  1.79s/it]predicting train subjects:  15%|█▍        | 42/285 [01:17<07:03,  1.74s/it]predicting train subjects:  15%|█▌        | 43/285 [01:19<07:13,  1.79s/it]predicting train subjects:  15%|█▌        | 44/285 [01:21<07:32,  1.88s/it]predicting train subjects:  16%|█▌        | 45/285 [01:22<07:13,  1.81s/it]predicting train subjects:  16%|█▌        | 46/285 [01:24<07:31,  1.89s/it]predicting train subjects:  16%|█▋        | 47/285 [01:26<07:11,  1.81s/it]predicting train subjects:  17%|█▋        | 48/285 [01:28<07:16,  1.84s/it]predicting train subjects:  17%|█▋        | 49/285 [01:30<07:34,  1.93s/it]predicting train subjects:  18%|█▊        | 50/285 [01:32<07:25,  1.90s/it]predicting train subjects:  18%|█▊        | 51/285 [01:34<07:36,  1.95s/it]predicting train subjects:  18%|█▊        | 52/285 [01:36<07:12,  1.85s/it]predicting train subjects:  19%|█▊        | 53/285 [01:37<07:11,  1.86s/it]predicting train subjects:  19%|█▉        | 54/285 [01:39<07:20,  1.91s/it]predicting train subjects:  19%|█▉        | 55/285 [01:41<07:14,  1.89s/it]predicting train subjects:  20%|█▉        | 56/285 [01:43<07:09,  1.88s/it]predicting train subjects:  20%|██        | 57/285 [01:45<06:52,  1.81s/it]predicting train subjects:  20%|██        | 58/285 [01:47<06:50,  1.81s/it]predicting train subjects:  21%|██        | 59/285 [01:49<07:12,  1.91s/it]predicting train subjects:  21%|██        | 60/285 [01:51<07:24,  1.98s/it]predicting train subjects:  21%|██▏       | 61/285 [01:53<07:02,  1.89s/it]predicting train subjects:  22%|██▏       | 62/285 [01:54<07:00,  1.88s/it]predicting train subjects:  22%|██▏       | 63/285 [01:56<06:55,  1.87s/it]predicting train subjects:  22%|██▏       | 64/285 [01:58<06:43,  1.83s/it]predicting train subjects:  23%|██▎       | 65/285 [02:00<06:42,  1.83s/it]predicting train subjects:  23%|██▎       | 66/285 [02:02<06:39,  1.83s/it]predicting train subjects:  24%|██▎       | 67/285 [02:03<06:41,  1.84s/it]predicting train subjects:  24%|██▍       | 68/285 [02:05<06:26,  1.78s/it]predicting train subjects:  24%|██▍       | 69/285 [02:07<06:24,  1.78s/it]predicting train subjects:  25%|██▍       | 70/285 [02:09<06:29,  1.81s/it]predicting train subjects:  25%|██▍       | 71/285 [02:11<06:33,  1.84s/it]predicting train subjects:  25%|██▌       | 72/285 [02:12<06:26,  1.81s/it]predicting train subjects:  26%|██▌       | 73/285 [02:14<06:30,  1.84s/it]predicting train subjects:  26%|██▌       | 74/285 [02:16<06:28,  1.84s/it]predicting train subjects:  26%|██▋       | 75/285 [02:18<06:26,  1.84s/it]predicting train subjects:  27%|██▋       | 76/285 [02:20<06:32,  1.88s/it]predicting train subjects:  27%|██▋       | 77/285 [02:22<06:21,  1.83s/it]predicting train subjects:  27%|██▋       | 78/285 [02:23<06:14,  1.81s/it]predicting train subjects:  28%|██▊       | 79/285 [02:25<06:15,  1.82s/it]predicting train subjects:  28%|██▊       | 80/285 [02:27<06:18,  1.85s/it]predicting train subjects:  28%|██▊       | 81/285 [02:29<06:12,  1.82s/it]predicting train subjects:  29%|██▉       | 82/285 [02:31<06:16,  1.86s/it]predicting train subjects:  29%|██▉       | 83/285 [02:33<06:03,  1.80s/it]predicting train subjects:  29%|██▉       | 84/285 [02:34<05:58,  1.78s/it]predicting train subjects:  30%|██▉       | 85/285 [02:36<06:00,  1.80s/it]predicting train subjects:  30%|███       | 86/285 [02:38<06:02,  1.82s/it]predicting train subjects:  31%|███       | 87/285 [02:40<06:04,  1.84s/it]predicting train subjects:  31%|███       | 88/285 [02:42<05:53,  1.79s/it]predicting train subjects:  31%|███       | 89/285 [02:43<05:54,  1.81s/it]predicting train subjects:  32%|███▏      | 90/285 [02:45<05:59,  1.85s/it]predicting train subjects:  32%|███▏      | 91/285 [02:47<05:48,  1.80s/it]predicting train subjects:  32%|███▏      | 92/285 [02:49<05:51,  1.82s/it]predicting train subjects:  33%|███▎      | 93/285 [02:51<05:45,  1.80s/it]predicting train subjects:  33%|███▎      | 94/285 [02:53<05:48,  1.82s/it]predicting train subjects:  33%|███▎      | 95/285 [02:55<05:53,  1.86s/it]predicting train subjects:  34%|███▎      | 96/285 [02:56<05:52,  1.87s/it]predicting train subjects:  34%|███▍      | 97/285 [02:58<05:46,  1.84s/it]predicting train subjects:  34%|███▍      | 98/285 [03:00<05:41,  1.82s/it]predicting train subjects:  35%|███▍      | 99/285 [03:02<05:34,  1.80s/it]predicting train subjects:  35%|███▌      | 100/285 [03:04<05:41,  1.85s/it]predicting train subjects:  35%|███▌      | 101/285 [03:06<05:38,  1.84s/it]predicting train subjects:  36%|███▌      | 102/285 [03:07<05:40,  1.86s/it]predicting train subjects:  36%|███▌      | 103/285 [03:09<05:33,  1.83s/it]predicting train subjects:  36%|███▋      | 104/285 [03:11<05:32,  1.84s/it]predicting train subjects:  37%|███▋      | 105/285 [03:13<05:32,  1.85s/it]predicting train subjects:  37%|███▋      | 106/285 [03:15<05:24,  1.81s/it]predicting train subjects:  38%|███▊      | 107/285 [03:17<05:25,  1.83s/it]predicting train subjects:  38%|███▊      | 108/285 [03:18<05:18,  1.80s/it]predicting train subjects:  38%|███▊      | 109/285 [03:20<05:19,  1.82s/it]predicting train subjects:  39%|███▊      | 110/285 [03:22<05:20,  1.83s/it]predicting train subjects:  39%|███▉      | 111/285 [03:24<05:15,  1.81s/it]predicting train subjects:  39%|███▉      | 112/285 [03:26<05:15,  1.82s/it]predicting train subjects:  40%|███▉      | 113/285 [03:27<05:16,  1.84s/it]predicting train subjects:  40%|████      | 114/285 [03:29<05:16,  1.85s/it]predicting train subjects:  40%|████      | 115/285 [03:31<05:13,  1.85s/it]predicting train subjects:  41%|████      | 116/285 [03:33<05:12,  1.85s/it]predicting train subjects:  41%|████      | 117/285 [03:35<05:04,  1.81s/it]predicting train subjects:  41%|████▏     | 118/285 [03:36<04:58,  1.79s/it]predicting train subjects:  42%|████▏     | 119/285 [03:38<05:01,  1.81s/it]predicting train subjects:  42%|████▏     | 120/285 [03:40<04:54,  1.79s/it]predicting train subjects:  42%|████▏     | 121/285 [03:42<04:48,  1.76s/it]predicting train subjects:  43%|████▎     | 122/285 [03:43<04:36,  1.70s/it]predicting train subjects:  43%|████▎     | 123/285 [03:45<04:24,  1.63s/it]predicting train subjects:  44%|████▎     | 124/285 [03:46<04:23,  1.63s/it]predicting train subjects:  44%|████▍     | 125/285 [03:48<04:15,  1.60s/it]predicting train subjects:  44%|████▍     | 126/285 [03:49<04:06,  1.55s/it]predicting train subjects:  45%|████▍     | 127/285 [03:51<04:02,  1.53s/it]predicting train subjects:  45%|████▍     | 128/285 [03:53<04:06,  1.57s/it]predicting train subjects:  45%|████▌     | 129/285 [03:54<04:03,  1.56s/it]predicting train subjects:  46%|████▌     | 130/285 [03:56<03:59,  1.55s/it]predicting train subjects:  46%|████▌     | 131/285 [03:57<03:54,  1.52s/it]predicting train subjects:  46%|████▋     | 132/285 [03:59<04:00,  1.57s/it]predicting train subjects:  47%|████▋     | 133/285 [04:00<03:55,  1.55s/it]predicting train subjects:  47%|████▋     | 134/285 [04:02<03:53,  1.54s/it]predicting train subjects:  47%|████▋     | 135/285 [04:03<03:48,  1.52s/it]predicting train subjects:  48%|████▊     | 136/285 [04:05<03:45,  1.51s/it]predicting train subjects:  48%|████▊     | 137/285 [04:06<03:51,  1.57s/it]predicting train subjects:  48%|████▊     | 138/285 [04:08<03:43,  1.52s/it]predicting train subjects:  49%|████▉     | 139/285 [04:10<03:48,  1.56s/it]predicting train subjects:  49%|████▉     | 140/285 [04:11<03:50,  1.59s/it]predicting train subjects:  49%|████▉     | 141/285 [04:13<03:47,  1.58s/it]predicting train subjects:  50%|████▉     | 142/285 [04:14<03:46,  1.59s/it]predicting train subjects:  50%|█████     | 143/285 [04:16<03:40,  1.55s/it]predicting train subjects:  51%|█████     | 144/285 [04:17<03:39,  1.56s/it]predicting train subjects:  51%|█████     | 145/285 [04:19<03:39,  1.57s/it]predicting train subjects:  51%|█████     | 146/285 [04:21<03:40,  1.58s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:22<03:34,  1.55s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:24<03:33,  1.56s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:25<03:30,  1.55s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:27<03:26,  1.53s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:28<03:29,  1.56s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:30<03:25,  1.54s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:31<03:20,  1.52s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:33<03:26,  1.57s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:34<03:21,  1.55s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:36<03:24,  1.59s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:38<03:19,  1.56s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:39<03:16,  1.55s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:41<03:16,  1.56s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:42<03:16,  1.57s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:44<03:20,  1.62s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:46<03:16,  1.60s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:47<03:17,  1.62s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:49<03:14,  1.61s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:50<03:10,  1.59s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:52<03:08,  1.58s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:54<03:07,  1.59s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:55<03:03,  1.57s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:57<03:02,  1.57s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:58<02:58,  1.55s/it]predicting train subjects:  60%|██████    | 171/285 [05:00<02:59,  1.57s/it]predicting train subjects:  60%|██████    | 172/285 [05:01<02:54,  1.54s/it]predicting train subjects:  61%|██████    | 173/285 [05:03<02:52,  1.54s/it]predicting train subjects:  61%|██████    | 174/285 [05:04<02:52,  1.56s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:06<02:54,  1.59s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:08<02:56,  1.62s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:09<02:50,  1.58s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:11<02:42,  1.52s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:12<02:40,  1.51s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:14<02:48,  1.61s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:16<02:47,  1.61s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:17<02:49,  1.64s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:19<02:43,  1.60s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:20<02:39,  1.58s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:22<02:34,  1.54s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:24<02:42,  1.64s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:25<02:44,  1.68s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:27<02:44,  1.69s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:28<02:33,  1.59s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:30<02:24,  1.52s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:32<02:29,  1.59s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:33<02:30,  1.61s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:35<02:24,  1.57s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:36<02:20,  1.54s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:38<02:16,  1.52s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:40<02:25,  1.63s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:41<02:30,  1.71s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:43<02:31,  1.74s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:45<02:21,  1.65s/it]predicting train subjects:  70%|███████   | 200/285 [05:46<02:15,  1.60s/it]predicting train subjects:  71%|███████   | 201/285 [05:48<02:19,  1.66s/it]predicting train subjects:  71%|███████   | 202/285 [05:50<02:19,  1.68s/it]predicting train subjects:  71%|███████   | 203/285 [05:51<02:19,  1.70s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:53<02:13,  1.64s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:54<02:06,  1.58s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:56<02:00,  1.53s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:58<02:06,  1.62s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:59<02:09,  1.69s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:01<02:09,  1.70s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:03<02:02,  1.64s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:04<01:56,  1.58s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:06<01:58,  1.62s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:08<01:57,  1.63s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:09<01:52,  1.59s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:11<01:55,  1.65s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:12<01:49,  1.59s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:14<01:51,  1.64s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:16<01:53,  1.70s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:18<01:53,  1.71s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:19<01:45,  1.63s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:20<01:40,  1.57s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:22<01:39,  1.59s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:23<01:34,  1.53s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:25<01:33,  1.54s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:26<01:29,  1.49s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:28<01:34,  1.60s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:30<01:37,  1.68s/it]predicting train subjects:  80%|████████  | 228/285 [06:32<01:36,  1.70s/it]predicting train subjects:  80%|████████  | 229/285 [06:33<01:33,  1.67s/it]predicting train subjects:  81%|████████  | 230/285 [06:35<01:27,  1.59s/it]predicting train subjects:  81%|████████  | 231/285 [06:36<01:23,  1.55s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:38<01:23,  1.57s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:39<01:19,  1.52s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:41<01:20,  1.58s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:42<01:16,  1.53s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:44<01:18,  1.59s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:46<01:19,  1.65s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:48<01:18,  1.67s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:49<01:14,  1.63s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:51<01:10,  1.56s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:52<01:07,  1.53s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:54<01:04,  1.49s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:55<01:02,  1.50s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:57<01:04,  1.58s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:58<01:01,  1.53s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:00<01:03,  1.63s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:02<01:03,  1.66s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:03<01:01,  1.65s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:05<00:57,  1.59s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:06<00:53,  1.52s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:08<00:50,  1.50s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:09<00:49,  1.49s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:11<00:50,  1.58s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:13<00:50,  1.64s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:14<00:49,  1.63s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:16<00:45,  1.57s/it]predicting train subjects:  90%|█████████ | 257/285 [07:17<00:43,  1.55s/it]predicting train subjects:  91%|█████████ | 258/285 [07:19<00:43,  1.63s/it]predicting train subjects:  91%|█████████ | 259/285 [07:21<00:42,  1.64s/it]predicting train subjects:  91%|█████████ | 260/285 [07:22<00:39,  1.56s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:24<00:36,  1.53s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:25<00:34,  1.49s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:27<00:33,  1.51s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:28<00:34,  1.63s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:30<00:33,  1.69s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:32<00:30,  1.61s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:33<00:28,  1.56s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:35<00:27,  1.62s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:37<00:25,  1.61s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:38<00:23,  1.55s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:39<00:21,  1.51s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:41<00:20,  1.54s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:42<00:17,  1.48s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:44<00:16,  1.47s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:45<00:15,  1.56s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:47<00:14,  1.61s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:49<00:12,  1.56s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:50<00:10,  1.54s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:52<00:09,  1.55s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:53<00:07,  1.51s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:55<00:05,  1.49s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:56<00:04,  1.47s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:58<00:03,  1.57s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:00<00:01,  1.65s/it]predicting train subjects: 100%|██████████| 285/285 [08:01<00:00,  1.70s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:16,  1.54s/it]Loading train:   1%|          | 2/285 [00:02<06:38,  1.41s/it]Loading train:   1%|          | 3/285 [00:04<06:34,  1.40s/it]Loading train:   1%|▏         | 4/285 [00:05<06:01,  1.29s/it]Loading train:   2%|▏         | 5/285 [00:06<06:11,  1.33s/it]Loading train:   2%|▏         | 6/285 [00:07<06:01,  1.29s/it]Loading train:   2%|▏         | 7/285 [00:09<06:06,  1.32s/it]Loading train:   3%|▎         | 8/285 [00:10<06:05,  1.32s/it]Loading train:   3%|▎         | 9/285 [00:11<06:19,  1.37s/it]Loading train:   4%|▎         | 10/285 [00:12<05:41,  1.24s/it]Loading train:   4%|▍         | 11/285 [00:13<04:52,  1.07s/it]Loading train:   4%|▍         | 12/285 [00:14<04:39,  1.02s/it]Loading train:   5%|▍         | 13/285 [00:15<04:18,  1.05it/s]Loading train:   5%|▍         | 14/285 [00:16<04:24,  1.03it/s]Loading train:   5%|▌         | 15/285 [00:17<04:20,  1.04it/s]Loading train:   6%|▌         | 16/285 [00:18<04:14,  1.06it/s]Loading train:   6%|▌         | 17/285 [00:18<04:02,  1.11it/s]Loading train:   6%|▋         | 18/285 [00:19<04:01,  1.11it/s]Loading train:   7%|▋         | 19/285 [00:20<03:49,  1.16it/s]Loading train:   7%|▋         | 20/285 [00:21<03:49,  1.15it/s]Loading train:   7%|▋         | 21/285 [00:22<03:50,  1.15it/s]Loading train:   8%|▊         | 22/285 [00:23<03:46,  1.16it/s]Loading train:   8%|▊         | 23/285 [00:24<03:51,  1.13it/s]Loading train:   8%|▊         | 24/285 [00:24<03:38,  1.19it/s]Loading train:   9%|▉         | 25/285 [00:25<03:43,  1.16it/s]Loading train:   9%|▉         | 26/285 [00:26<03:45,  1.15it/s]Loading train:   9%|▉         | 27/285 [00:27<03:37,  1.19it/s]Loading train:  10%|▉         | 28/285 [00:28<03:42,  1.15it/s]Loading train:  10%|█         | 29/285 [00:29<03:40,  1.16it/s]Loading train:  11%|█         | 30/285 [00:30<03:46,  1.13it/s]Loading train:  11%|█         | 31/285 [00:31<03:49,  1.11it/s]Loading train:  11%|█         | 32/285 [00:31<03:37,  1.16it/s]Loading train:  12%|█▏        | 33/285 [00:32<03:39,  1.15it/s]Loading train:  12%|█▏        | 34/285 [00:33<03:40,  1.14it/s]Loading train:  12%|█▏        | 35/285 [00:34<03:47,  1.10it/s]Loading train:  13%|█▎        | 36/285 [00:35<03:37,  1.14it/s]Loading train:  13%|█▎        | 37/285 [00:36<03:33,  1.16it/s]Loading train:  13%|█▎        | 38/285 [00:37<03:38,  1.13it/s]Loading train:  14%|█▎        | 39/285 [00:37<03:31,  1.16it/s]Loading train:  14%|█▍        | 40/285 [00:38<03:35,  1.14it/s]Loading train:  14%|█▍        | 41/285 [00:39<03:27,  1.18it/s]Loading train:  15%|█▍        | 42/285 [00:40<03:31,  1.15it/s]Loading train:  15%|█▌        | 43/285 [00:41<03:32,  1.14it/s]Loading train:  15%|█▌        | 44/285 [00:42<03:43,  1.08it/s]Loading train:  16%|█▌        | 45/285 [00:43<03:37,  1.10it/s]Loading train:  16%|█▌        | 46/285 [00:44<03:41,  1.08it/s]Loading train:  16%|█▋        | 47/285 [00:45<03:31,  1.13it/s]Loading train:  17%|█▋        | 48/285 [00:46<03:32,  1.12it/s]Loading train:  17%|█▋        | 49/285 [00:47<03:40,  1.07it/s]Loading train:  18%|█▊        | 50/285 [00:47<03:39,  1.07it/s]Loading train:  18%|█▊        | 51/285 [00:48<03:39,  1.07it/s]Loading train:  18%|█▊        | 52/285 [00:49<03:33,  1.09it/s]Loading train:  19%|█▊        | 53/285 [00:50<03:27,  1.12it/s]Loading train:  19%|█▉        | 54/285 [00:51<03:26,  1.12it/s]Loading train:  19%|█▉        | 55/285 [00:52<03:22,  1.14it/s]Loading train:  20%|█▉        | 56/285 [00:53<03:29,  1.10it/s]Loading train:  20%|██        | 57/285 [00:54<03:31,  1.08it/s]Loading train:  20%|██        | 58/285 [00:55<03:31,  1.08it/s]Loading train:  21%|██        | 59/285 [00:56<03:28,  1.09it/s]Loading train:  21%|██        | 60/285 [00:57<03:31,  1.06it/s]Loading train:  21%|██▏       | 61/285 [00:58<03:26,  1.08it/s]Loading train:  22%|██▏       | 62/285 [00:59<03:43,  1.00s/it]Loading train:  22%|██▏       | 63/285 [01:00<03:36,  1.02it/s]Loading train:  22%|██▏       | 64/285 [01:01<03:51,  1.05s/it]Loading train:  23%|██▎       | 65/285 [01:02<04:19,  1.18s/it]Loading train:  23%|██▎       | 66/285 [01:04<04:24,  1.21s/it]Loading train:  24%|██▎       | 67/285 [01:04<03:59,  1.10s/it]Loading train:  24%|██▍       | 68/285 [01:05<03:35,  1.01it/s]Loading train:  24%|██▍       | 69/285 [01:06<03:35,  1.00it/s]Loading train:  25%|██▍       | 70/285 [01:07<03:32,  1.01it/s]Loading train:  25%|██▍       | 71/285 [01:08<03:29,  1.02it/s]Loading train:  25%|██▌       | 72/285 [01:09<03:18,  1.07it/s]Loading train:  26%|██▌       | 73/285 [01:10<03:16,  1.08it/s]Loading train:  26%|██▌       | 74/285 [01:11<03:16,  1.07it/s]Loading train:  26%|██▋       | 75/285 [01:12<03:10,  1.10it/s]Loading train:  27%|██▋       | 76/285 [01:13<03:09,  1.10it/s]Loading train:  27%|██▋       | 77/285 [01:14<03:08,  1.10it/s]Loading train:  27%|██▋       | 78/285 [01:14<02:57,  1.17it/s]Loading train:  28%|██▊       | 79/285 [01:15<03:00,  1.14it/s]Loading train:  28%|██▊       | 80/285 [01:16<03:03,  1.12it/s]Loading train:  28%|██▊       | 81/285 [01:17<02:51,  1.19it/s]Loading train:  29%|██▉       | 82/285 [01:18<02:53,  1.17it/s]Loading train:  29%|██▉       | 83/285 [01:18<02:44,  1.23it/s]Loading train:  29%|██▉       | 84/285 [01:19<02:35,  1.30it/s]Loading train:  30%|██▉       | 85/285 [01:20<02:51,  1.17it/s]Loading train:  30%|███       | 86/285 [01:21<02:50,  1.17it/s]Loading train:  31%|███       | 87/285 [01:22<02:47,  1.18it/s]Loading train:  31%|███       | 88/285 [01:23<02:42,  1.22it/s]Loading train:  31%|███       | 89/285 [01:24<02:50,  1.15it/s]Loading train:  32%|███▏      | 90/285 [01:25<02:53,  1.12it/s]Loading train:  32%|███▏      | 91/285 [01:25<02:48,  1.15it/s]Loading train:  32%|███▏      | 92/285 [01:26<02:49,  1.14it/s]Loading train:  33%|███▎      | 93/285 [01:27<02:42,  1.19it/s]Loading train:  33%|███▎      | 94/285 [01:28<02:56,  1.08it/s]Loading train:  33%|███▎      | 95/285 [01:29<02:51,  1.11it/s]Loading train:  34%|███▎      | 96/285 [01:30<02:45,  1.14it/s]Loading train:  34%|███▍      | 97/285 [01:31<02:44,  1.14it/s]Loading train:  34%|███▍      | 98/285 [01:31<02:42,  1.15it/s]Loading train:  35%|███▍      | 99/285 [01:32<02:38,  1.17it/s]Loading train:  35%|███▌      | 100/285 [01:33<02:35,  1.19it/s]Loading train:  35%|███▌      | 101/285 [01:34<02:35,  1.18it/s]Loading train:  36%|███▌      | 102/285 [01:35<02:37,  1.17it/s]Loading train:  36%|███▌      | 103/285 [01:36<02:35,  1.17it/s]Loading train:  36%|███▋      | 104/285 [01:37<02:39,  1.13it/s]Loading train:  37%|███▋      | 105/285 [01:38<02:42,  1.11it/s]Loading train:  37%|███▋      | 106/285 [01:38<02:30,  1.19it/s]Loading train:  38%|███▊      | 107/285 [01:39<02:32,  1.16it/s]Loading train:  38%|███▊      | 108/285 [01:40<02:25,  1.22it/s]Loading train:  38%|███▊      | 109/285 [01:41<02:24,  1.21it/s]Loading train:  39%|███▊      | 110/285 [01:42<02:25,  1.20it/s]Loading train:  39%|███▉      | 111/285 [01:42<02:15,  1.28it/s]Loading train:  39%|███▉      | 112/285 [01:43<02:16,  1.27it/s]Loading train:  40%|███▉      | 113/285 [01:44<02:16,  1.26it/s]Loading train:  40%|████      | 114/285 [01:45<02:21,  1.21it/s]Loading train:  40%|████      | 115/285 [01:46<02:25,  1.16it/s]Loading train:  41%|████      | 116/285 [01:47<02:24,  1.17it/s]Loading train:  41%|████      | 117/285 [01:47<02:16,  1.23it/s]Loading train:  41%|████▏     | 118/285 [01:48<02:09,  1.29it/s]Loading train:  42%|████▏     | 119/285 [01:49<02:10,  1.27it/s]Loading train:  42%|████▏     | 120/285 [01:50<02:05,  1.31it/s]Loading train:  42%|████▏     | 121/285 [01:51<02:26,  1.12it/s]Loading train:  43%|████▎     | 122/285 [01:52<02:33,  1.06it/s]Loading train:  43%|████▎     | 123/285 [01:53<02:41,  1.00it/s]Loading train:  44%|████▎     | 124/285 [01:54<02:39,  1.01it/s]Loading train:  44%|████▍     | 125/285 [01:55<02:28,  1.08it/s]Loading train:  44%|████▍     | 126/285 [01:55<02:21,  1.13it/s]Loading train:  45%|████▍     | 127/285 [01:56<02:10,  1.21it/s]Loading train:  45%|████▍     | 128/285 [01:57<02:08,  1.22it/s]Loading train:  45%|████▌     | 129/285 [01:58<02:06,  1.23it/s]Loading train:  46%|████▌     | 130/285 [01:59<02:05,  1.23it/s]Loading train:  46%|████▌     | 131/285 [01:59<02:12,  1.16it/s]Loading train:  46%|████▋     | 132/285 [02:00<02:10,  1.18it/s]Loading train:  47%|████▋     | 133/285 [02:01<02:04,  1.22it/s]Loading train:  47%|████▋     | 134/285 [02:02<01:56,  1.29it/s]Loading train:  47%|████▋     | 135/285 [02:03<01:56,  1.29it/s]Loading train:  48%|████▊     | 136/285 [02:03<01:56,  1.28it/s]Loading train:  48%|████▊     | 137/285 [02:04<01:59,  1.24it/s]Loading train:  48%|████▊     | 138/285 [02:05<02:06,  1.16it/s]Loading train:  49%|████▉     | 139/285 [02:06<02:08,  1.14it/s]Loading train:  49%|████▉     | 140/285 [02:07<02:07,  1.14it/s]Loading train:  49%|████▉     | 141/285 [02:08<02:02,  1.17it/s]Loading train:  50%|████▉     | 142/285 [02:09<02:03,  1.16it/s]Loading train:  50%|█████     | 143/285 [02:10<02:10,  1.09it/s]Loading train:  51%|█████     | 144/285 [02:11<02:09,  1.09it/s]Loading train:  51%|█████     | 145/285 [02:11<02:06,  1.10it/s]Loading train:  51%|█████     | 146/285 [02:12<02:09,  1.07it/s]Loading train:  52%|█████▏    | 147/285 [02:13<02:01,  1.14it/s]Loading train:  52%|█████▏    | 148/285 [02:14<02:00,  1.13it/s]Loading train:  52%|█████▏    | 149/285 [02:15<01:55,  1.17it/s]Loading train:  53%|█████▎    | 150/285 [02:16<01:47,  1.26it/s]Loading train:  53%|█████▎    | 151/285 [02:16<01:43,  1.30it/s]Loading train:  53%|█████▎    | 152/285 [02:17<01:39,  1.34it/s]Loading train:  54%|█████▎    | 153/285 [02:18<01:37,  1.36it/s]Loading train:  54%|█████▍    | 154/285 [02:18<01:38,  1.34it/s]Loading train:  54%|█████▍    | 155/285 [02:19<01:36,  1.34it/s]Loading train:  55%|█████▍    | 156/285 [02:20<01:34,  1.36it/s]Loading train:  55%|█████▌    | 157/285 [02:21<01:33,  1.38it/s]Loading train:  55%|█████▌    | 158/285 [02:21<01:30,  1.40it/s]Loading train:  56%|█████▌    | 159/285 [02:22<01:28,  1.43it/s]Loading train:  56%|█████▌    | 160/285 [02:23<01:26,  1.44it/s]Loading train:  56%|█████▋    | 161/285 [02:23<01:28,  1.40it/s]Loading train:  57%|█████▋    | 162/285 [02:24<01:27,  1.40it/s]Loading train:  57%|█████▋    | 163/285 [02:25<01:26,  1.40it/s]Loading train:  58%|█████▊    | 164/285 [02:26<01:27,  1.38it/s]Loading train:  58%|█████▊    | 165/285 [02:26<01:26,  1.39it/s]Loading train:  58%|█████▊    | 166/285 [02:27<01:27,  1.37it/s]Loading train:  59%|█████▊    | 167/285 [02:28<01:25,  1.39it/s]Loading train:  59%|█████▉    | 168/285 [02:28<01:22,  1.42it/s]Loading train:  59%|█████▉    | 169/285 [02:29<01:22,  1.41it/s]Loading train:  60%|█████▉    | 170/285 [02:30<01:21,  1.42it/s]Loading train:  60%|██████    | 171/285 [02:31<01:20,  1.42it/s]Loading train:  60%|██████    | 172/285 [02:31<01:17,  1.47it/s]Loading train:  61%|██████    | 173/285 [02:32<01:16,  1.47it/s]Loading train:  61%|██████    | 174/285 [02:33<01:16,  1.45it/s]Loading train:  61%|██████▏   | 175/285 [02:33<01:17,  1.42it/s]Loading train:  62%|██████▏   | 176/285 [02:34<01:19,  1.37it/s]Loading train:  62%|██████▏   | 177/285 [02:35<01:20,  1.35it/s]Loading train:  62%|██████▏   | 178/285 [02:36<01:17,  1.38it/s]Loading train:  63%|██████▎   | 179/285 [02:36<01:17,  1.37it/s]Loading train:  63%|██████▎   | 180/285 [02:37<01:20,  1.30it/s]Loading train:  64%|██████▎   | 181/285 [02:38<01:20,  1.29it/s]Loading train:  64%|██████▍   | 182/285 [02:39<01:17,  1.33it/s]Loading train:  64%|██████▍   | 183/285 [02:39<01:14,  1.37it/s]Loading train:  65%|██████▍   | 184/285 [02:40<01:13,  1.38it/s]Loading train:  65%|██████▍   | 185/285 [02:41<01:09,  1.44it/s]Loading train:  65%|██████▌   | 186/285 [02:42<01:14,  1.34it/s]Loading train:  66%|██████▌   | 187/285 [02:42<01:15,  1.30it/s]Loading train:  66%|██████▌   | 188/285 [02:43<01:18,  1.23it/s]Loading train:  66%|██████▋   | 189/285 [02:44<01:15,  1.27it/s]Loading train:  67%|██████▋   | 190/285 [02:45<01:12,  1.30it/s]Loading train:  67%|██████▋   | 191/285 [02:45<01:12,  1.29it/s]Loading train:  67%|██████▋   | 192/285 [02:46<01:12,  1.29it/s]Loading train:  68%|██████▊   | 193/285 [02:47<01:07,  1.35it/s]Loading train:  68%|██████▊   | 194/285 [02:48<01:06,  1.37it/s]Loading train:  68%|██████▊   | 195/285 [02:48<01:05,  1.38it/s]Loading train:  69%|██████▉   | 196/285 [02:49<01:08,  1.30it/s]Loading train:  69%|██████▉   | 197/285 [02:50<01:15,  1.17it/s]Loading train:  69%|██████▉   | 198/285 [02:51<01:19,  1.09it/s]Loading train:  70%|██████▉   | 199/285 [02:52<01:17,  1.11it/s]Loading train:  70%|███████   | 200/285 [02:53<01:16,  1.11it/s]Loading train:  71%|███████   | 201/285 [02:54<01:18,  1.08it/s]Loading train:  71%|███████   | 202/285 [02:55<01:19,  1.05it/s]Loading train:  71%|███████   | 203/285 [02:56<01:16,  1.08it/s]Loading train:  72%|███████▏  | 204/285 [02:57<01:16,  1.06it/s]Loading train:  72%|███████▏  | 205/285 [02:58<01:11,  1.13it/s]Loading train:  72%|███████▏  | 206/285 [02:59<01:08,  1.16it/s]Loading train:  73%|███████▎  | 207/285 [02:59<01:08,  1.14it/s]Loading train:  73%|███████▎  | 208/285 [03:00<01:12,  1.07it/s]Loading train:  73%|███████▎  | 209/285 [03:01<01:11,  1.07it/s]Loading train:  74%|███████▎  | 210/285 [03:02<01:04,  1.17it/s]Loading train:  74%|███████▍  | 211/285 [03:03<00:58,  1.26it/s]Loading train:  74%|███████▍  | 212/285 [03:04<00:57,  1.26it/s]Loading train:  75%|███████▍  | 213/285 [03:05<01:00,  1.18it/s]Loading train:  75%|███████▌  | 214/285 [03:05<01:02,  1.14it/s]Loading train:  75%|███████▌  | 215/285 [03:07<01:08,  1.02it/s]Loading train:  76%|███████▌  | 216/285 [03:07<01:01,  1.12it/s]Loading train:  76%|███████▌  | 217/285 [03:08<01:01,  1.11it/s]Loading train:  76%|███████▋  | 218/285 [03:09<00:59,  1.13it/s]Loading train:  77%|███████▋  | 219/285 [03:10<01:00,  1.10it/s]Loading train:  77%|███████▋  | 220/285 [03:11<00:58,  1.12it/s]Loading train:  78%|███████▊  | 221/285 [03:12<00:58,  1.09it/s]Loading train:  78%|███████▊  | 222/285 [03:13<00:57,  1.10it/s]Loading train:  78%|███████▊  | 223/285 [03:14<00:56,  1.10it/s]Loading train:  79%|███████▊  | 224/285 [03:15<00:53,  1.14it/s]Loading train:  79%|███████▉  | 225/285 [03:16<00:54,  1.10it/s]Loading train:  79%|███████▉  | 226/285 [03:17<00:55,  1.06it/s]Loading train:  80%|███████▉  | 227/285 [03:18<00:55,  1.05it/s]Loading train:  80%|████████  | 228/285 [03:19<00:57,  1.00s/it]Loading train:  80%|████████  | 229/285 [03:20<00:55,  1.02it/s]Loading train:  81%|████████  | 230/285 [03:20<00:50,  1.09it/s]Loading train:  81%|████████  | 231/285 [03:21<00:47,  1.15it/s]Loading train:  81%|████████▏ | 232/285 [03:22<00:44,  1.19it/s]Loading train:  82%|████████▏ | 233/285 [03:23<00:44,  1.16it/s]Loading train:  82%|████████▏ | 234/285 [03:24<00:46,  1.10it/s]Loading train:  82%|████████▏ | 235/285 [03:25<00:43,  1.14it/s]Loading train:  83%|████████▎ | 236/285 [03:26<00:44,  1.10it/s]Loading train:  83%|████████▎ | 237/285 [03:27<00:44,  1.09it/s]Loading train:  84%|████████▎ | 238/285 [03:28<00:44,  1.06it/s]Loading train:  84%|████████▍ | 239/285 [03:28<00:42,  1.09it/s]Loading train:  84%|████████▍ | 240/285 [03:29<00:39,  1.14it/s]Loading train:  85%|████████▍ | 241/285 [03:30<00:37,  1.17it/s]Loading train:  85%|████████▍ | 242/285 [03:31<00:34,  1.24it/s]Loading train:  85%|████████▌ | 243/285 [03:31<00:32,  1.31it/s]Loading train:  86%|████████▌ | 244/285 [03:32<00:32,  1.24it/s]Loading train:  86%|████████▌ | 245/285 [03:33<00:30,  1.29it/s]Loading train:  86%|████████▋ | 246/285 [03:34<00:32,  1.19it/s]Loading train:  87%|████████▋ | 247/285 [03:35<00:34,  1.11it/s]Loading train:  87%|████████▋ | 248/285 [03:36<00:35,  1.04it/s]Loading train:  87%|████████▋ | 249/285 [03:37<00:34,  1.04it/s]Loading train:  88%|████████▊ | 250/285 [03:38<00:32,  1.07it/s]Loading train:  88%|████████▊ | 251/285 [03:39<00:28,  1.17it/s]Loading train:  88%|████████▊ | 252/285 [03:39<00:27,  1.21it/s]Loading train:  89%|████████▉ | 253/285 [03:40<00:28,  1.13it/s]Loading train:  89%|████████▉ | 254/285 [03:41<00:28,  1.10it/s]Loading train:  89%|████████▉ | 255/285 [03:42<00:26,  1.13it/s]Loading train:  90%|████████▉ | 256/285 [03:43<00:27,  1.05it/s]Loading train:  90%|█████████ | 257/285 [03:44<00:26,  1.07it/s]Loading train:  91%|█████████ | 258/285 [03:45<00:28,  1.04s/it]Loading train:  91%|█████████ | 259/285 [03:46<00:27,  1.04s/it]Loading train:  91%|█████████ | 260/285 [03:47<00:25,  1.00s/it]Loading train:  92%|█████████▏| 261/285 [03:48<00:22,  1.08it/s]Loading train:  92%|█████████▏| 262/285 [03:49<00:21,  1.07it/s]Loading train:  92%|█████████▏| 263/285 [03:50<00:19,  1.14it/s]Loading train:  93%|█████████▎| 264/285 [03:51<00:19,  1.08it/s]Loading train:  93%|█████████▎| 265/285 [03:52<00:19,  1.02it/s]Loading train:  93%|█████████▎| 266/285 [03:53<00:16,  1.14it/s]Loading train:  94%|█████████▎| 267/285 [03:53<00:15,  1.17it/s]Loading train:  94%|█████████▍| 268/285 [03:55<00:15,  1.07it/s]Loading train:  94%|█████████▍| 269/285 [03:55<00:14,  1.10it/s]Loading train:  95%|█████████▍| 270/285 [03:56<00:13,  1.12it/s]Loading train:  95%|█████████▌| 271/285 [03:57<00:12,  1.08it/s]Loading train:  95%|█████████▌| 272/285 [03:58<00:12,  1.05it/s]Loading train:  96%|█████████▌| 273/285 [03:59<00:11,  1.09it/s]Loading train:  96%|█████████▌| 274/285 [04:00<00:10,  1.09it/s]Loading train:  96%|█████████▋| 275/285 [04:01<00:09,  1.06it/s]Loading train:  97%|█████████▋| 276/285 [04:02<00:09,  1.02s/it]Loading train:  97%|█████████▋| 277/285 [04:03<00:07,  1.07it/s]Loading train:  98%|█████████▊| 278/285 [04:04<00:06,  1.07it/s]Loading train:  98%|█████████▊| 279/285 [04:05<00:05,  1.10it/s]Loading train:  98%|█████████▊| 280/285 [04:06<00:04,  1.14it/s]Loading train:  99%|█████████▊| 281/285 [04:06<00:03,  1.16it/s]Loading train:  99%|█████████▉| 282/285 [04:07<00:02,  1.10it/s]Loading train:  99%|█████████▉| 283/285 [04:08<00:01,  1.04it/s]Loading train: 100%|█████████▉| 284/285 [04:10<00:01,  1.03s/it]Loading train: 100%|██████████| 285/285 [04:11<00:00,  1.01s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   5%|▍         | 13/285 [00:00<00:02, 126.45it/s]concatenating: train:  16%|█▌        | 46/285 [00:00<00:01, 154.91it/s]concatenating: train:  24%|██▍       | 69/285 [00:00<00:01, 169.08it/s]concatenating: train:  30%|██▉       | 85/285 [00:00<00:01, 152.67it/s]concatenating: train:  36%|███▋      | 104/285 [00:00<00:01, 161.00it/s]concatenating: train:  48%|████▊     | 137/285 [00:00<00:00, 189.65it/s]concatenating: train:  58%|█████▊    | 164/285 [00:00<00:00, 206.83it/s]concatenating: train:  69%|██████▉   | 198/285 [00:00<00:00, 234.06it/s]concatenating: train:  81%|████████  | 231/285 [00:00<00:00, 256.38it/s]concatenating: train:  92%|█████████▏| 263/285 [00:01<00:00, 271.29it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 255.57it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.22s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.21s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.18s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 54.81it/s]2019-07-09 11:53:00.580165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-09 11:53:00.580259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-09 11:53:00.580274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-09 11:53:00.580282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-09 11:53:00.580612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12743 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.38it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.38it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  6.03it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.73it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:04,  8.45it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  7.29it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02,  9.32it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.69it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:02,  7.74it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:01,  9.62it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.74it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.97it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:02<00:01,  7.99it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.85it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00, 10.19it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 10.35it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  8.23it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 11.35it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 30)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 31)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 15)   4200        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 15)   2040        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 15)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 40, 26, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 30)   4080        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 30)   8130        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 45)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 60)   24360       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 60)   32460       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 105)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 30)   12630       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 30)   8130        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 105)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 40, 26, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 15)   6315        dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 15)   2040        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 45)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 80, 52, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 30)   12180       dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 80, 52, 30)   120         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 52, 30)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 80, 52, 30)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 80, 52, 75)   0           dropout_6[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 52, 13)   988         concatenate_8[0][0]              
==================================================================================================
Total params: 143,638
Trainable params: 45,058
Non-trainable params: 98,580
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 27s - loss: 24438.7745 - acc: 0.5555 - mDice: 0.0806 - val_loss: 15850.7074 - val_acc: 0.8741 - val_mDice: 0.1431

Epoch 00001: val_mDice improved from -inf to 0.14306, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 17s - loss: 11369.1752 - acc: 0.8750 - mDice: 0.2480 - val_loss: 9552.0355 - val_acc: 0.8955 - val_mDice: 0.2714

Epoch 00002: val_mDice improved from 0.14306 to 0.27143, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 17s - loss: 8651.5353 - acc: 0.8846 - mDice: 0.3337 - val_loss: 9900.6325 - val_acc: 0.9061 - val_mDice: 0.3121

Epoch 00003: val_mDice improved from 0.27143 to 0.31214, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 18s - loss: 7371.0651 - acc: 0.8900 - mDice: 0.3900 - val_loss: 8019.8815 - val_acc: 0.9133 - val_mDice: 0.3481

Epoch 00004: val_mDice improved from 0.31214 to 0.34813, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 17s - loss: 6517.1470 - acc: 0.8934 - mDice: 0.4334 - val_loss: 5984.1943 - val_acc: 0.9183 - val_mDice: 0.4380

Epoch 00005: val_mDice improved from 0.34813 to 0.43799, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 17s - loss: 5971.6044 - acc: 0.8966 - mDice: 0.4646 - val_loss: 7186.8262 - val_acc: 0.9106 - val_mDice: 0.3758

Epoch 00006: val_mDice did not improve from 0.43799
Epoch 7/300
 - 18s - loss: 5551.6138 - acc: 0.8997 - mDice: 0.4892 - val_loss: 5670.0665 - val_acc: 0.9215 - val_mDice: 0.4625

Epoch 00007: val_mDice improved from 0.43799 to 0.46248, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 19s - loss: 5240.4873 - acc: 0.9031 - mDice: 0.5084 - val_loss: 5124.6309 - val_acc: 0.9298 - val_mDice: 0.4990

Epoch 00008: val_mDice improved from 0.46248 to 0.49902, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 18s - loss: 4985.4447 - acc: 0.9067 - mDice: 0.5249 - val_loss: 5143.8449 - val_acc: 0.9293 - val_mDice: 0.4955

Epoch 00009: val_mDice did not improve from 0.49902
Epoch 10/300
 - 19s - loss: 4766.1210 - acc: 0.9101 - mDice: 0.5393 - val_loss: 5022.9859 - val_acc: 0.9293 - val_mDice: 0.5011

Epoch 00010: val_mDice improved from 0.49902 to 0.50113, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 18s - loss: 4609.8504 - acc: 0.9132 - mDice: 0.5497 - val_loss: 5272.6380 - val_acc: 0.9323 - val_mDice: 0.4883

Epoch 00011: val_mDice did not improve from 0.50113
Epoch 12/300
 - 18s - loss: 4452.8884 - acc: 0.9156 - mDice: 0.5605 - val_loss: 4869.8225 - val_acc: 0.9315 - val_mDice: 0.5102

Epoch 00012: val_mDice improved from 0.50113 to 0.51021, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 19s - loss: 4324.7001 - acc: 0.9187 - mDice: 0.5692 - val_loss: 5006.0122 - val_acc: 0.9327 - val_mDice: 0.5039

Epoch 00013: val_mDice did not improve from 0.51021
Epoch 14/300
 - 18s - loss: 4176.6462 - acc: 0.9213 - mDice: 0.5794 - val_loss: 5209.6706 - val_acc: 0.9293 - val_mDice: 0.4889

Epoch 00014: val_mDice did not improve from 0.51021
Epoch 15/300
 - 18s - loss: 4090.0387 - acc: 0.9238 - mDice: 0.5858 - val_loss: 4617.6826 - val_acc: 0.9338 - val_mDice: 0.5263

Epoch 00015: val_mDice improved from 0.51021 to 0.52631, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 18s - loss: 4029.1434 - acc: 0.9255 - mDice: 0.5903 - val_loss: 4745.4938 - val_acc: 0.9326 - val_mDice: 0.5199

Epoch 00016: val_mDice did not improve from 0.52631
Epoch 17/300
 - 18s - loss: 3926.3197 - acc: 0.9274 - mDice: 0.5976 - val_loss: 4964.1142 - val_acc: 0.9331 - val_mDice: 0.5046

Epoch 00017: val_mDice did not improve from 0.52631
Epoch 18/300
 - 18s - loss: 3849.6925 - acc: 0.9285 - mDice: 0.6035 - val_loss: 4537.2234 - val_acc: 0.9328 - val_mDice: 0.5339

Epoch 00018: val_mDice improved from 0.52631 to 0.53392, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 19/300
 - 19s - loss: 3800.9202 - acc: 0.9293 - mDice: 0.6074 - val_loss: 4532.4520 - val_acc: 0.9316 - val_mDice: 0.5337

Epoch 00019: val_mDice did not improve from 0.53392
Epoch 20/300
 - 18s - loss: 3739.5201 - acc: 0.9301 - mDice: 0.6120 - val_loss: 4603.4767 - val_acc: 0.9340 - val_mDice: 0.5289

Epoch 00020: val_mDice did not improve from 0.53392
Epoch 21/300
 - 19s - loss: 3699.0391 - acc: 0.9306 - mDice: 0.6149 - val_loss: 4560.6038 - val_acc: 0.9254 - val_mDice: 0.5324

Epoch 00021: val_mDice did not improve from 0.53392
Epoch 22/300
 - 19s - loss: 3649.3368 - acc: 0.9314 - mDice: 0.6190 - val_loss: 4531.2724 - val_acc: 0.9257 - val_mDice: 0.5335

Epoch 00022: val_mDice did not improve from 0.53392
Epoch 23/300
 - 18s - loss: 3608.3532 - acc: 0.9316 - mDice: 0.6223 - val_loss: 4579.8182 - val_acc: 0.9330 - val_mDice: 0.5304

Epoch 00023: val_mDice did not improve from 0.53392
Epoch 24/300
 - 19s - loss: 3551.1754 - acc: 0.9324 - mDice: 0.6267 - val_loss: 4539.0482 - val_acc: 0.9305 - val_mDice: 0.5331

Epoch 00024: val_mDice did not improve from 0.53392
Epoch 25/300
 - 19s - loss: 3496.4937 - acc: 0.9329 - mDice: 0.6311 - val_loss: 4305.6318 - val_acc: 0.9327 - val_mDice: 0.5500

Epoch 00025: val_mDice improved from 0.53392 to 0.55000, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 26/300
 - 19s - loss: 3517.5589 - acc: 0.9331 - mDice: 0.6295 - val_loss: 4413.4350 - val_acc: 0.9338 - val_mDice: 0.5405

Epoch 00026: val_mDice did not improve from 0.55000
Epoch 27/300
 - 19s - loss: 3453.6176 - acc: 0.9335 - mDice: 0.6346 - val_loss: 4454.7289 - val_acc: 0.9323 - val_mDice: 0.5376

Epoch 00027: val_mDice did not improve from 0.55000
Epoch 28/300
 - 19s - loss: 3431.0002 - acc: 0.9337 - mDice: 0.6364 - val_loss: 4281.4729 - val_acc: 0.9329 - val_mDice: 0.5514

Epoch 00028: val_mDice improved from 0.55000 to 0.55141, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 29/300
 - 18s - loss: 3392.9539 - acc: 0.9342 - mDice: 0.6394 - val_loss: 4339.3193 - val_acc: 0.9343 - val_mDice: 0.5464

Epoch 00029: val_mDice did not improve from 0.55141
Epoch 30/300
 - 18s - loss: 3348.9459 - acc: 0.9346 - mDice: 0.6430 - val_loss: 4416.4028 - val_acc: 0.9324 - val_mDice: 0.5419

Epoch 00030: val_mDice did not improve from 0.55141
Epoch 31/300
 - 18s - loss: 3350.7084 - acc: 0.9349 - mDice: 0.6431 - val_loss: 4601.9199 - val_acc: 0.9216 - val_mDice: 0.5292

Epoch 00031: val_mDice did not improve from 0.55141
Epoch 32/300
 - 19s - loss: 3312.2929 - acc: 0.9352 - mDice: 0.6462 - val_loss: 4383.9790 - val_acc: 0.9304 - val_mDice: 0.5435

Epoch 00032: val_mDice did not improve from 0.55141
Epoch 33/300
 - 19s - loss: 3293.6243 - acc: 0.9352 - mDice: 0.6477 - val_loss: 4371.2390 - val_acc: 0.9242 - val_mDice: 0.5454

Epoch 00033: val_mDice did not improve from 0.55141
Epoch 34/300
 - 18s - loss: 3271.3777 - acc: 0.9357 - mDice: 0.6495 - val_loss: 4404.6292 - val_acc: 0.9253 - val_mDice: 0.5411

Epoch 00034: val_mDice did not improve from 0.55141
Epoch 35/300
 - 18s - loss: 3250.8636 - acc: 0.9357 - mDice: 0.6513 - val_loss: 4421.1246 - val_acc: 0.9345 - val_mDice: 0.5398

Epoch 00035: val_mDice did not improve from 0.55141
Epoch 36/300
 - 18s - loss: 3223.4212 - acc: 0.9362 - mDice: 0.6536 - val_loss: 4503.0435 - val_acc: 0.9260 - val_mDice: 0.5351

Epoch 00036: val_mDice did not improve from 0.55141
Epoch 37/300
 - 18s - loss: 3196.1842 - acc: 0.9364 - mDice: 0.6558 - val_loss: 4285.5480 - val_acc: 0.9349 - val_mDice: 0.5497

Epoch 00037: val_mDice did not improve from 0.55141
Epoch 38/300
 - 18s - loss: 3199.1924 - acc: 0.9363 - mDice: 0.6556 - val_loss: 4447.0783 - val_acc: 0.9270 - val_mDice: 0.5399

Epoch 00038: val_mDice did not improve from 0.55141
Epoch 39/300
 - 17s - loss: 3190.3982 - acc: 0.9366 - mDice: 0.6563 - val_loss: 4227.9831 - val_acc: 0.9330 - val_mDice: 0.5518

Epoch 00039: val_mDice improved from 0.55141 to 0.55180, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 40/300
 - 18s - loss: 3162.8524 - acc: 0.9368 - mDice: 0.6586 - val_loss: 4457.7674 - val_acc: 0.9322 - val_mDice: 0.5366

Epoch 00040: val_mDice did not improve from 0.55180
Epoch 41/300
 - 18s - loss: 3143.6854 - acc: 0.9370 - mDice: 0.6602 - val_loss: 4398.5596 - val_acc: 0.9301 - val_mDice: 0.5414

Epoch 00041: val_mDice did not improve from 0.55180
Epoch 42/300
 - 18s - loss: 3137.0313 - acc: 0.9372 - mDice: 0.6609 - val_loss: 4264.2185 - val_acc: 0.9316 - val_mDice: 0.5529

Epoch 00042: val_mDice improved from 0.55180 to 0.55287, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 43/300
 - 17s - loss: 3097.8359 - acc: 0.9375 - mDice: 0.6641 - val_loss: 4390.0961 - val_acc: 0.9273 - val_mDice: 0.5424

Epoch 00043: val_mDice did not improve from 0.55287
Epoch 44/300
 - 19s - loss: 3102.1392 - acc: 0.9376 - mDice: 0.6637 - val_loss: 4269.9964 - val_acc: 0.9291 - val_mDice: 0.5524

Epoch 00044: val_mDice did not improve from 0.55287
Epoch 45/300
 - 19s - loss: 3079.3500 - acc: 0.9378 - mDice: 0.6658 - val_loss: 4101.6716 - val_acc: 0.9337 - val_mDice: 0.5648

Epoch 00045: val_mDice improved from 0.55287 to 0.56478, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 46/300
 - 19s - loss: 3075.0971 - acc: 0.9378 - mDice: 0.6661 - val_loss: 4250.1718 - val_acc: 0.9299 - val_mDice: 0.5524

Epoch 00046: val_mDice did not improve from 0.56478
Epoch 47/300
 - 19s - loss: 3043.1257 - acc: 0.9381 - mDice: 0.6687 - val_loss: 4200.6499 - val_acc: 0.9342 - val_mDice: 0.5552

Epoch 00047: val_mDice did not improve from 0.56478
Epoch 48/300
 - 19s - loss: 3023.6206 - acc: 0.9383 - mDice: 0.6705 - val_loss: 4119.2981 - val_acc: 0.9312 - val_mDice: 0.5613

Epoch 00048: val_mDice did not improve from 0.56478
Epoch 49/300
 - 19s - loss: 3026.1406 - acc: 0.9384 - mDice: 0.6703 - val_loss: 4254.1379 - val_acc: 0.9363 - val_mDice: 0.5513

Epoch 00049: val_mDice did not improve from 0.56478
Epoch 50/300
 - 19s - loss: 3005.6347 - acc: 0.9387 - mDice: 0.6720 - val_loss: 4211.5222 - val_acc: 0.9351 - val_mDice: 0.5555

Epoch 00050: val_mDice did not improve from 0.56478
Epoch 51/300
 - 18s - loss: 3019.1908 - acc: 0.9383 - mDice: 0.6708 - val_loss: 4707.0888 - val_acc: 0.9373 - val_mDice: 0.5245

Epoch 00051: val_mDice did not improve from 0.56478
Epoch 52/300
 - 19s - loss: 2996.4912 - acc: 0.9387 - mDice: 0.6728 - val_loss: 4475.5097 - val_acc: 0.9359 - val_mDice: 0.5381

Epoch 00052: val_mDice did not improve from 0.56478
Epoch 53/300
 - 18s - loss: 2971.9035 - acc: 0.9388 - mDice: 0.6749 - val_loss: 4261.2442 - val_acc: 0.9360 - val_mDice: 0.5508

Epoch 00053: val_mDice did not improve from 0.56478
Epoch 54/300
 - 19s - loss: 2980.2090 - acc: 0.9388 - mDice: 0.6743 - val_loss: 4310.5230 - val_acc: 0.9329 - val_mDice: 0.5491

Epoch 00054: val_mDice did not improve from 0.56478
Epoch 55/300
 - 17s - loss: 2950.9150 - acc: 0.9392 - mDice: 0.6769 - val_loss: 4351.9112 - val_acc: 0.9337 - val_mDice: 0.5455

Epoch 00055: val_mDice did not improve from 0.56478
Epoch 56/300
 - 18s - loss: 2968.0420 - acc: 0.9390 - mDice: 0.6754 - val_loss: 4093.7582 - val_acc: 0.9339 - val_mDice: 0.5620

Epoch 00056: val_mDice did not improve from 0.56478
Epoch 57/300
 - 19s - loss: 2927.3936 - acc: 0.9394 - mDice: 0.6790 - val_loss: 4193.4135 - val_acc: 0.9310 - val_mDice: 0.5557

Epoch 00057: val_mDice did not improve from 0.56478
Epoch 58/300
 - 18s - loss: 2923.9040 - acc: 0.9393 - mDice: 0.6791 - val_loss: 4360.7426 - val_acc: 0.9321 - val_mDice: 0.5430

Epoch 00058: val_mDice did not improve from 0.56478
Epoch 59/300
 - 18s - loss: 2925.3618 - acc: 0.9394 - mDice: 0.6791 - val_loss: 4160.3570 - val_acc: 0.9386 - val_mDice: 0.5599

Epoch 00059: val_mDice did not improve from 0.56478
Epoch 60/300
 - 18s - loss: 2923.3344 - acc: 0.9393 - mDice: 0.6792 - val_loss: 4239.7455 - val_acc: 0.9334 - val_mDice: 0.5519

Epoch 00060: val_mDice did not improve from 0.56478
Epoch 61/300
 - 18s - loss: 2924.7790 - acc: 0.9395 - mDice: 0.6794 - val_loss: 4191.1295 - val_acc: 0.9327 - val_mDice: 0.5560

Epoch 00061: val_mDice did not improve from 0.56478
Epoch 62/300
 - 19s - loss: 2902.0524 - acc: 0.9396 - mDice: 0.6813 - val_loss: 4159.4534 - val_acc: 0.9380 - val_mDice: 0.5581

Epoch 00062: val_mDice did not improve from 0.56478
Epoch 63/300
 - 17s - loss: 2882.8060 - acc: 0.9399 - mDice: 0.6827 - val_loss: 4186.9727 - val_acc: 0.9390 - val_mDice: 0.5544

Epoch 00063: val_mDice did not improve from 0.56478
Epoch 64/300
 - 17s - loss: 2867.4229 - acc: 0.9399 - mDice: 0.6841 - val_loss: 4170.5790 - val_acc: 0.9347 - val_mDice: 0.5571

Epoch 00064: val_mDice did not improve from 0.56478
Epoch 65/300
 - 18s - loss: 2852.1353 - acc: 0.9402 - mDice: 0.6856 - val_loss: 4448.6954 - val_acc: 0.9367 - val_mDice: 0.5377

Epoch 00065: val_mDice did not improve from 0.56478
Epoch 66/300
 - 18s - loss: 2865.2896 - acc: 0.9401 - mDice: 0.6844 - val_loss: 4079.3931 - val_acc: 0.9356 - val_mDice: 0.5643

Epoch 00066: val_mDice did not improve from 0.56478
Epoch 67/300
 - 17s - loss: 2851.0082 - acc: 0.9402 - mDice: 0.6857 - val_loss: 4186.9891 - val_acc: 0.9362 - val_mDice: 0.5550

Epoch 00067: val_mDice did not improve from 0.56478
Epoch 68/300
 - 16s - loss: 2833.8587 - acc: 0.9403 - mDice: 0.6871 - val_loss: 4141.8064 - val_acc: 0.9377 - val_mDice: 0.5597

Epoch 00068: val_mDice did not improve from 0.56478
Epoch 69/300
 - 18s - loss: 2828.7022 - acc: 0.9405 - mDice: 0.6877 - val_loss: 4037.5397 - val_acc: 0.9373 - val_mDice: 0.5659

Epoch 00069: val_mDice improved from 0.56478 to 0.56591, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 70/300
 - 18s - loss: 2834.9986 - acc: 0.9405 - mDice: 0.6871 - val_loss: 4126.0793 - val_acc: 0.9368 - val_mDice: 0.5604

Epoch 00070: val_mDice did not improve from 0.56591
Epoch 71/300
 - 18s - loss: 2815.4367 - acc: 0.9407 - mDice: 0.6888 - val_loss: 4247.7620 - val_acc: 0.9362 - val_mDice: 0.5526

Epoch 00071: val_mDice did not improve from 0.56591
Epoch 72/300
 - 18s - loss: 2813.5843 - acc: 0.9405 - mDice: 0.6889 - val_loss: 4165.4491 - val_acc: 0.9359 - val_mDice: 0.5572

Epoch 00072: val_mDice did not improve from 0.56591
Epoch 73/300
 - 18s - loss: 2804.4960 - acc: 0.9407 - mDice: 0.6898 - val_loss: 4103.9414 - val_acc: 0.9366 - val_mDice: 0.5620

Epoch 00073: val_mDice did not improve from 0.56591
Epoch 74/300
 - 18s - loss: 2788.0999 - acc: 0.9410 - mDice: 0.6913 - val_loss: 4256.0693 - val_acc: 0.9369 - val_mDice: 0.5526

Epoch 00074: val_mDice did not improve from 0.56591
Epoch 75/300
 - 17s - loss: 2784.5781 - acc: 0.9409 - mDice: 0.6915 - val_loss: 4112.9275 - val_acc: 0.9337 - val_mDice: 0.5614

Epoch 00075: val_mDice did not improve from 0.56591
Epoch 76/300
 - 18s - loss: 2771.8385 - acc: 0.9410 - mDice: 0.6927 - val_loss: 4417.4028 - val_acc: 0.9250 - val_mDice: 0.5427

Epoch 00076: val_mDice did not improve from 0.56591
Epoch 77/300
 - 18s - loss: 2787.0086 - acc: 0.9408 - mDice: 0.6914 - val_loss: 4079.0596 - val_acc: 0.9397 - val_mDice: 0.5635

Epoch 00077: val_mDice did not improve from 0.56591
Epoch 78/300
 - 18s - loss: 2775.7529 - acc: 0.9409 - mDice: 0.6924 - val_loss: 4047.5971 - val_acc: 0.9372 - val_mDice: 0.5672

Epoch 00078: val_mDice improved from 0.56591 to 0.56720, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 79/300
 - 17s - loss: 2762.5752 - acc: 0.9413 - mDice: 0.6934 - val_loss: 4224.2928 - val_acc: 0.9313 - val_mDice: 0.5535

Epoch 00079: val_mDice did not improve from 0.56720
Epoch 80/300
 - 18s - loss: 2765.1512 - acc: 0.9411 - mDice: 0.6934 - val_loss: 4175.1162 - val_acc: 0.9384 - val_mDice: 0.5561

Epoch 00080: val_mDice did not improve from 0.56720
Epoch 81/300
 - 18s - loss: 2761.5786 - acc: 0.9410 - mDice: 0.6935 - val_loss: 4185.4974 - val_acc: 0.9395 - val_mDice: 0.5554

Epoch 00081: val_mDice did not improve from 0.56720
Epoch 82/300
 - 16s - loss: 2739.8122 - acc: 0.9413 - mDice: 0.6955 - val_loss: 4172.8824 - val_acc: 0.9376 - val_mDice: 0.5563

Epoch 00082: val_mDice did not improve from 0.56720
Epoch 83/300
 - 17s - loss: 2728.5146 - acc: 0.9415 - mDice: 0.6965 - val_loss: 4296.4020 - val_acc: 0.9332 - val_mDice: 0.5502

Epoch 00083: val_mDice did not improve from 0.56720
Epoch 84/300
 - 18s - loss: 2727.1196 - acc: 0.9415 - mDice: 0.6967 - val_loss: 4065.7385 - val_acc: 0.9373 - val_mDice: 0.5644

Epoch 00084: val_mDice did not improve from 0.56720
Epoch 85/300
 - 18s - loss: 2724.1638 - acc: 0.9415 - mDice: 0.6970 - val_loss: 4127.9678 - val_acc: 0.9339 - val_mDice: 0.5608

Epoch 00085: val_mDice did not improve from 0.56720
Epoch 86/300
 - 17s - loss: 2719.2477 - acc: 0.9414 - mDice: 0.6974 - val_loss: 4191.7105 - val_acc: 0.9393 - val_mDice: 0.5548

Epoch 00086: val_mDice did not improve from 0.56720
Epoch 87/300
 - 17s - loss: 2708.9708 - acc: 0.9417 - mDice: 0.6983 - val_loss: 4091.0522 - val_acc: 0.9371 - val_mDice: 0.5622

Epoch 00087: val_mDice did not improve from 0.56720
Epoch 88/300
 - 17s - loss: 2713.0175 - acc: 0.9416 - mDice: 0.6980 - val_loss: 4159.9969 - val_acc: 0.9405 - val_mDice: 0.5583

Epoch 00088: val_mDice did not improve from 0.56720
Epoch 89/300
 - 18s - loss: 2691.1296 - acc: 0.9418 - mDice: 0.6999 - val_loss: 4146.2781 - val_acc: 0.9379 - val_mDice: 0.5592

Epoch 00089: val_mDice did not improve from 0.56720
Epoch 90/300
 - 23s - loss: 2705.7856 - acc: 0.9417 - mDice: 0.6987 - val_loss: 4199.2930 - val_acc: 0.9357 - val_mDice: 0.5552

Epoch 00090: val_mDice did not improve from 0.56720
Epoch 91/300
 - 19s - loss: 2704.1998 - acc: 0.9417 - mDice: 0.6988 - val_loss: 4151.4713 - val_acc: 0.9390 - val_mDice: 0.5578

Epoch 00091: val_mDice did not improve from 0.56720
Epoch 92/300
 - 18s - loss: 2695.5469 - acc: 0.9417 - mDice: 0.6996 - val_loss: 4255.8093 - val_acc: 0.9347 - val_mDice: 0.5525

Epoch 00092: val_mDice did not improve from 0.56720
Epoch 93/300
 - 19s - loss: 2697.4174 - acc: 0.9419 - mDice: 0.6995 - val_loss: 4136.8326 - val_acc: 0.9370 - val_mDice: 0.5592

Epoch 00093: val_mDice did not improve from 0.56720
Epoch 94/300
 - 18s - loss: 2688.1637 - acc: 0.9419 - mDice: 0.7002 - val_loss: 4028.1009 - val_acc: 0.9388 - val_mDice: 0.5668

Epoch 00094: val_mDice did not improve from 0.56720
Epoch 95/300
 - 22s - loss: 2669.0547 - acc: 0.9420 - mDice: 0.7020 - val_loss: 4206.4896 - val_acc: 0.9336 - val_mDice: 0.5552

Epoch 00095: val_mDice did not improve from 0.56720
Epoch 96/300
 - 17s - loss: 2683.4437 - acc: 0.9419 - mDice: 0.7007 - val_loss: 4150.6785 - val_acc: 0.9350 - val_mDice: 0.5599

Epoch 00096: val_mDice did not improve from 0.56720
Epoch 97/300
 - 20s - loss: 2656.7246 - acc: 0.9422 - mDice: 0.7030 - val_loss: 4190.9243 - val_acc: 0.9319 - val_mDice: 0.5576

Epoch 00097: val_mDice did not improve from 0.56720
Epoch 98/300
 - 20s - loss: 2668.3972 - acc: 0.9421 - mDice: 0.7021 - val_loss: 4190.5277 - val_acc: 0.9361 - val_mDice: 0.5570

Epoch 00098: val_mDice did not improve from 0.56720
Epoch 99/300
 - 19s - loss: 2652.3012 - acc: 0.9422 - mDice: 0.7035 - val_loss: 4120.9718 - val_acc: 0.9383 - val_mDice: 0.5614

Epoch 00099: val_mDice did not improve from 0.56720
Epoch 100/300
 - 18s - loss: 2651.2751 - acc: 0.9422 - mDice: 0.7036 - val_loss: 4380.6522 - val_acc: 0.9363 - val_mDice: 0.5457

Epoch 00100: val_mDice did not improve from 0.56720
Epoch 101/300
 - 18s - loss: 2643.6318 - acc: 0.9422 - mDice: 0.7043 - val_loss: 4065.0024 - val_acc: 0.9409 - val_mDice: 0.5656

Epoch 00101: val_mDice did not improve from 0.56720
Epoch 102/300
 - 19s - loss: 2642.1829 - acc: 0.9423 - mDice: 0.7044 - val_loss: 4294.3918 - val_acc: 0.9389 - val_mDice: 0.5491

Epoch 00102: val_mDice did not improve from 0.56720
Epoch 103/300
 - 18s - loss: 2634.9097 - acc: 0.9424 - mDice: 0.7051 - val_loss: 4120.0795 - val_acc: 0.9373 - val_mDice: 0.5620

Epoch 00103: val_mDice did not improve from 0.56720
Epoch 104/300
 - 18s - loss: 2618.4771 - acc: 0.9424 - mDice: 0.7066 - val_loss: 4127.1338 - val_acc: 0.9374 - val_mDice: 0.5604

Epoch 00104: val_mDice did not improve from 0.56720
Epoch 105/300
 - 18s - loss: 2626.9384 - acc: 0.9425 - mDice: 0.7058 - val_loss: 4110.5896 - val_acc: 0.9359 - val_mDice: 0.5605

Epoch 00105: val_mDice did not improve from 0.56720
Epoch 106/300
 - 18s - loss: 2636.0172 - acc: 0.9423 - mDice: 0.7050 - val_loss: 4303.3218 - val_acc: 0.9281 - val_mDice: 0.5483

Epoch 00106: val_mDice did not improve from 0.56720
Epoch 107/300
 - 18s - loss: 2618.5989 - acc: 0.9426 - mDice: 0.7065 - val_loss: 4136.4014 - val_acc: 0.9355 - val_mDice: 0.5608

Epoch 00107: val_mDice did not improve from 0.56720
Epoch 108/300
 - 17s - loss: 2615.3408 - acc: 0.9426 - mDice: 0.7068 - val_loss: 4284.2796 - val_acc: 0.9308 - val_mDice: 0.5505

Epoch 00108: val_mDice did not improve from 0.56720
Restoring model weights from the end of the best epoch
Epoch 00108: early stopping
{'val_loss': [15850.707388070914, 9552.03545673077, 9900.63251201923, 8019.881544846755, 5984.19428898738, 7186.826181265024, 5670.066509540265, 5124.630934495192, 5143.84486741286, 5022.985943134015, 5272.6379957932695, 4869.822490985577, 5006.0121506911055, 5209.670635516827, 4617.6825608473555, 4745.493811974158, 4964.11416391226, 4537.223416841947, 4532.451988807092, 4603.47670335036, 4560.603750375601, 4531.272385817308, 4579.818162184495, 4539.04824594351, 4305.631817157452, 4413.434983473558, 4454.728891225962, 4281.472919170673, 4339.319340632512, 4416.402841421274, 4601.919940655048, 4383.978975736178, 4371.239041841947, 4404.629197340745, 4421.12455866887, 4503.043475811298, 4285.547954852765, 4447.078270545373, 4227.9830979567305, 4457.767441969651, 4398.55961726262, 4264.218534029447, 4390.09605055589, 4269.9963613656855, 4101.671593299279, 4250.171842134916, 4200.649911733774, 4119.298062838041, 4254.137911283053, 4211.522179236779, 4707.088759202224, 4475.5096764197715, 4261.24423452524, 4310.522967998798, 4351.911212627704, 4093.7581881009614, 4193.413499098558, 4360.7425865760215, 4160.356971153846, 4239.745497483474, 4191.129493126502, 4159.453359750601, 4186.972721980168, 4170.578974797176, 4448.695429875301, 4079.39306640625, 4186.989107572115, 4141.806415264423, 4037.5396681565503, 4126.079294057993, 4247.762038010817, 4165.449054424579, 4103.941420335036, 4256.069284292368, 4112.927509014423, 4417.402803861178, 4079.05961726262, 4047.5970928485576, 4224.292785644531, 4175.116243802584, 4185.497422438401, 4172.882436899038, 4296.4020432692305, 4065.738478440505, 4127.967848557692, 4191.710547814002, 4091.0521803635816, 4159.996859036959, 4146.278109036959, 4199.293001615084, 4151.471343994141, 4255.809283916767, 4136.8326087364785, 4028.100877028245, 4206.489609938401, 4150.6785231370195, 4190.924311711238, 4190.527667705829, 4120.971750112681, 4380.652212289663, 4065.00244140625, 4294.391803448017, 4120.079472468449, 4127.13383601262, 4110.589585524339, 4303.321758563702, 4136.401353102464, 4284.279583270733], 'val_acc': [0.8741031862222232, 0.8954904927657201, 0.906072043455564, 0.913267392378587, 0.9182553703968341, 0.910556130684339, 0.9214913111466628, 0.9297568247868464, 0.929331531891456, 0.9292922638929807, 0.9323270802314465, 0.9314672924005069, 0.9326622852912316, 0.9293361856387212, 0.9338479798573714, 0.9326414718077733, 0.9330552174494817, 0.9327708987089304, 0.9315689687545483, 0.9339843782094809, 0.9253629148006439, 0.925721173103039, 0.9329558198268597, 0.9304964748712686, 0.932703857238476, 0.9338318224136646, 0.9323017047001765, 0.9329049426775712, 0.9343356856933007, 0.9324334401350755, 0.9216276682340182, 0.9304433006506699, 0.9242303325579717, 0.9253305311386402, 0.9344882391966306, 0.9260447231622843, 0.9349158635506263, 0.9270201760988969, 0.9330043288377615, 0.9322300484547248, 0.930075833430657, 0.9316290731613452, 0.9272697728413802, 0.9291489605720227, 0.9337416864358462, 0.9299301848961756, 0.9341531350062444, 0.9312107104521531, 0.9363188674816718, 0.9351030954947839, 0.9372734977648809, 0.9359120772435114, 0.93599989093267, 0.9328910662577703, 0.933737073953335, 0.9338618608621451, 0.9310026719019964, 0.9320821051414196, 0.938577094903359, 0.9333926439285278, 0.932724668429448, 0.937973834001101, 0.938960822728964, 0.9346731648995326, 0.936672527056474, 0.9356439617963938, 0.9362010153440329, 0.9377010831466088, 0.9373127611783835, 0.9368019837599534, 0.9362033078303704, 0.9359097664172833, 0.936598580617171, 0.9369221581862524, 0.9337069942401006, 0.9250485507341532, 0.9397119971422049, 0.9371579358210931, 0.931280058163863, 0.9383898812990922, 0.9395247766604791, 0.9376294383635888, 0.9332239375664637, 0.9372734885949355, 0.9339034786591163, 0.9392890288279607, 0.9370885605995471, 0.9404909152251023, 0.9378605920534867, 0.9357040593257318, 0.9390417039394379, 0.9346824334217951, 0.936968383880762, 0.938836008310318, 0.9335960470713102, 0.934969037771225, 0.9319411195241488, 0.9360877206692328, 0.938281251833989, 0.936291135274447, 0.9409138950017782, 0.9388683186127589, 0.9373104480596689, 0.9374352854031783, 0.9358519934690915, 0.9281180500984192, 0.9354544213184943, 0.9307669080220736], 'val_mDice': [0.14305820029515487, 0.27142972499132156, 0.3121415568658939, 0.34812750495397127, 0.43798518639344436, 0.3758071643801836, 0.4624808459327771, 0.49901987612247467, 0.49547794117377353, 0.5011322549902476, 0.4883166207717015, 0.510212548650228, 0.5038593740990529, 0.4889097362756729, 0.5263085915492132, 0.5198692965966004, 0.5045975034053509, 0.5339207013065999, 0.5336843998386309, 0.5289204114904771, 0.532432737831886, 0.5335465503426698, 0.5304108617397455, 0.533140568779065, 0.5499951919684043, 0.5404924429379977, 0.5376343257152117, 0.5514123863898791, 0.5463578746869013, 0.5419397485943941, 0.52921934483143, 0.5435051551231971, 0.5453791457873124, 0.541053447012718, 0.5398303717374802, 0.5351045836622899, 0.5496921321520438, 0.5399414312381011, 0.5518007072118613, 0.5366291363651936, 0.5413797715535531, 0.5528665998807321, 0.5423788737792236, 0.552436565550474, 0.5647781582979056, 0.5524358382591834, 0.5552118185621041, 0.5612534823325964, 0.5512614771723747, 0.5554816315953548, 0.5245078802108765, 0.5380764901638031, 0.550815720970814, 0.5490924647221198, 0.545509112569002, 0.5619551149698404, 0.5557070735555428, 0.5429519552450913, 0.5599063445742314, 0.5519175042326634, 0.5560217671669446, 0.5581494283217651, 0.5544398593214842, 0.5571494343189093, 0.5377275777550844, 0.5642776231353099, 0.5550307201651427, 0.5597351267933846, 0.565911658681356, 0.5604407632580171, 0.5526349647687032, 0.5571756317065313, 0.5620440989732742, 0.5526444648320858, 0.5614373311400414, 0.5427233897722684, 0.5634578440624934, 0.5672007524050199, 0.5534838443765273, 0.5561230406165123, 0.5554395358149822, 0.5563055236752217, 0.5502251191781118, 0.564380407333374, 0.5608333693100855, 0.5547735719726636, 0.5621595686444869, 0.5582848644027343, 0.559237913443492, 0.555246346271955, 0.5578417984338907, 0.5524510013369414, 0.5592428182180111, 0.5667604586252799, 0.5552166092854279, 0.5598765199001019, 0.5575775446800085, 0.5570313443358128, 0.5614096379050841, 0.5457173402492816, 0.565567577114472, 0.5491487853802167, 0.561988597879043, 0.560380196915223, 0.5604545130179479, 0.5483349985801257, 0.5608214632822917, 0.5504846784930962], 'loss': [24438.774507638856, 11369.175169356095, 8651.53528961207, 7371.065067225471, 6517.146982788435, 5971.604381228817, 5551.613763204264, 5240.487303314026, 4985.444690834164, 4766.12099416188, 4609.850368185588, 4452.888408978575, 4324.700103120875, 4176.646248700378, 4090.0386984731113, 4029.1434063072807, 3926.319717279167, 3849.6925126958527, 3800.9201759226503, 3739.5200703610444, 3699.0390548670875, 3649.3368023495323, 3608.353153939772, 3551.1754245520583, 3496.4936921970107, 3517.5589377827105, 3453.617560296858, 3431.000197239867, 3392.9539163123854, 3348.9459161080304, 3350.708391822309, 3312.2929185168787, 3293.624313961016, 3271.377725760391, 3250.8635740363707, 3223.4211644636443, 3196.184237245065, 3199.1924472194223, 3190.398199607556, 3162.852446049042, 3143.685355658154, 3137.0313013701775, 3097.835881378953, 3102.1391617323675, 3079.349989421999, 3075.097064496626, 3043.125661991932, 3023.6206399406947, 3026.140601380751, 3005.6346982121963, 3019.1907984765157, 2996.4911721875214, 2971.903494439727, 2980.20898007445, 2950.9150232900656, 2968.0420229780843, 2927.393571675797, 2923.9040497059773, 2925.3618268311425, 2923.334445963572, 2924.778989363187, 2902.0524190388887, 2882.805993617444, 2867.4228551763126, 2852.13534556875, 2865.2895919629527, 2851.0081538420523, 2833.858743449655, 2828.7021917469615, 2834.998621110952, 2815.4366688793857, 2813.5842571897083, 2804.4959960419633, 2788.0999388061064, 2784.5781024615176, 2771.8385021361346, 2787.0086214423873, 2775.752920467212, 2762.5752160947372, 2765.151164611349, 2761.5786182910524, 2739.8122369121893, 2728.5145984520545, 2727.119578504259, 2724.163830563029, 2719.247748482154, 2708.970805493842, 2713.0175409173653, 2691.129592986979, 2705.7855701835288, 2704.19979165751, 2695.5468976172883, 2697.417393061768, 2688.163699824069, 2669.0546859351402, 2683.4437280964676, 2656.724647832271, 2668.3971500595503, 2652.301188282385, 2651.275106923822, 2643.631839810246, 2642.1829028250513, 2634.9097463355715, 2618.4770759541007, 2626.9383710977127, 2636.017157538003, 2618.5989196433975, 2615.3407561082213], 'acc': [0.555538559318919, 0.8749870310121716, 0.884624074099744, 0.8900389265092792, 0.8933703466984637, 0.8966013847006035, 0.8997206842339721, 0.9030957602711387, 0.9067085760057297, 0.9101001226977867, 0.9131975638506916, 0.915611322137424, 0.9186974561193558, 0.9212919390752374, 0.9238300652760351, 0.9254802584065444, 0.927371500828692, 0.9285077123880321, 0.9293262588849183, 0.9301422737648068, 0.9306300074194648, 0.9313807783339677, 0.93161539852009, 0.932424390309413, 0.9328729684674123, 0.9330606543027221, 0.9334708829378164, 0.9337038186152109, 0.9342102567439127, 0.9346201035530708, 0.934871551917508, 0.9351911725268355, 0.9352077745834994, 0.9356884349539174, 0.9357384723028573, 0.9361831945850985, 0.936421583260182, 0.9363324829576245, 0.9366002505438844, 0.9368484587859791, 0.9369851984760478, 0.9372005568190077, 0.9375059869163406, 0.9376311555764535, 0.9378486605056876, 0.9378363577617904, 0.9381180184854745, 0.9383351268621429, 0.9383502004936614, 0.938708793965255, 0.9383170373444406, 0.9386815726399741, 0.9388298623612212, 0.938823701820173, 0.9391541794240668, 0.9389667383069692, 0.9394497699670704, 0.9393022971257483, 0.939393412024621, 0.9393330454210684, 0.9394626937855393, 0.9395875533458481, 0.9399062656646042, 0.9399366116684257, 0.9402006951731136, 0.940082488558691, 0.9402377413755676, 0.9403316510083172, 0.9404847783146557, 0.9404707201829116, 0.9406680737453821, 0.9405284958891484, 0.9406833047138131, 0.9409566559134556, 0.9408664905056351, 0.9409839908135373, 0.9408360323947282, 0.9409161761690306, 0.9412573871990307, 0.9410753514805612, 0.9410252033053514, 0.9412799749626815, 0.9414518360753874, 0.9415001916036629, 0.9414914981538075, 0.9414337929309013, 0.9416640442774149, 0.941646195316649, 0.9418126286027133, 0.9417295793891998, 0.9416862102404936, 0.941738933206627, 0.9418698856391492, 0.9418815066099145, 0.9419741515225836, 0.9418968901438081, 0.9421634555610576, 0.9421264987518281, 0.9421894191640182, 0.942213030370698, 0.942245842158701, 0.9423417007308554, 0.9423922229866408, 0.9423531856933094, 0.942486421858309, 0.9423486628644989, 0.942568470853881, 0.9425611789404856], 'mDice': [0.08057875840767585, 0.24798835113810885, 0.3337159376709287, 0.38995689629441993, 0.43338288936152797, 0.4646368534277146, 0.48916160699725975, 0.5083878340233431, 0.5249416594255524, 0.5392981437088588, 0.5496782572586291, 0.5604905735123787, 0.5691556174476066, 0.579449640152189, 0.5858244096057547, 0.5902903995412331, 0.5975832180553374, 0.6034847627175994, 0.6074145347619314, 0.611950060609499, 0.6149056016722696, 0.619039304728307, 0.6223418786166658, 0.6266992428607742, 0.6311253350917609, 0.6295099098018578, 0.6346282501848688, 0.636387850930855, 0.6394360886171583, 0.6430073884935669, 0.6431213929448018, 0.6461696807588146, 0.6477170889034357, 0.6494680484106627, 0.6512959194141572, 0.6535534416629876, 0.6557711414236276, 0.6555812174649649, 0.6562944451271581, 0.6585939268250972, 0.6602056510969797, 0.6609162984711872, 0.664092670977363, 0.6637443879714237, 0.6657743164339288, 0.6661013747167512, 0.6686814223159935, 0.6705468692133526, 0.6702745459038625, 0.671982108364793, 0.6707791274273119, 0.6727551749455558, 0.6748517293128802, 0.6742562006334092, 0.6769119845010099, 0.6753842789814787, 0.6789689211621998, 0.6791317641520691, 0.6790802348070145, 0.6791856567116227, 0.6793640934815214, 0.6813136645703807, 0.6826514605940196, 0.6841066205544434, 0.6855612419017245, 0.6844218456744048, 0.6857068591327626, 0.6871004128856302, 0.687683925701883, 0.6870678303031302, 0.6888165434249199, 0.6889389953599648, 0.6897692472350055, 0.6912746635308337, 0.6915123906179975, 0.6927171653897782, 0.6913853711740212, 0.6924173204450054, 0.6933541828873829, 0.6934061703740875, 0.6935399314205684, 0.6954671932049566, 0.6965135268418318, 0.6967293954166024, 0.6969627003096726, 0.6974145562064106, 0.6982718737134412, 0.6979722375580826, 0.6998776944539187, 0.6986768138284427, 0.6987894122411237, 0.6995642421255029, 0.6995492648519868, 0.7002154524713537, 0.7019882008102144, 0.7006547984454197, 0.7030185598470865, 0.7020990650097316, 0.7034854893203724, 0.7036018168080791, 0.7043016889510225, 0.7043537637420678, 0.7050784562639586, 0.706566118186969, 0.7058411768570516, 0.7049746521282468, 0.7064935942478069, 0.7067743314980339]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.20s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.98s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.78s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:48,  1.86s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:59,  1.69s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:54,  1.68s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:23,  1.58s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:36,  1.63s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:10,  1.54s/it]predicting train subjects:   2%|▏         | 7/285 [00:10<07:24,  1.60s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:23,  1.60s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:44,  1.68s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<07:54,  1.73s/it]predicting train subjects:   4%|▍         | 11/285 [00:17<07:32,  1.65s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<07:49,  1.72s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:37,  1.68s/it]predicting train subjects:   5%|▍         | 14/285 [00:22<07:36,  1.68s/it]predicting train subjects:   5%|▌         | 15/285 [00:24<07:51,  1.75s/it]predicting train subjects:   6%|▌         | 16/285 [00:26<07:57,  1.78s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<07:38,  1.71s/it]predicting train subjects:   6%|▋         | 18/285 [00:29<07:38,  1.72s/it]predicting train subjects:   7%|▋         | 19/285 [00:31<07:20,  1.65s/it]predicting train subjects:   7%|▋         | 20/285 [00:33<07:20,  1.66s/it]predicting train subjects:   7%|▋         | 21/285 [00:35<07:39,  1.74s/it]predicting train subjects:   8%|▊         | 22/285 [00:36<07:21,  1.68s/it]predicting train subjects:   8%|▊         | 23/285 [00:38<07:22,  1.69s/it]predicting train subjects:   8%|▊         | 24/285 [00:39<07:14,  1.66s/it]predicting train subjects:   9%|▉         | 25/285 [00:41<07:27,  1.72s/it]predicting train subjects:   9%|▉         | 26/285 [00:43<07:38,  1.77s/it]predicting train subjects:   9%|▉         | 27/285 [00:45<07:21,  1.71s/it]predicting train subjects:  10%|▉         | 28/285 [00:47<07:25,  1.73s/it]predicting train subjects:  10%|█         | 29/285 [00:48<07:21,  1.72s/it]predicting train subjects:  11%|█         | 30/285 [00:50<07:31,  1.77s/it]predicting train subjects:  11%|█         | 31/285 [00:52<07:35,  1.80s/it]predicting train subjects:  11%|█         | 32/285 [00:54<07:16,  1.72s/it]predicting train subjects:  12%|█▏        | 33/285 [00:55<07:13,  1.72s/it]predicting train subjects:  12%|█▏        | 34/285 [00:57<07:09,  1.71s/it]predicting train subjects:  12%|█▏        | 35/285 [00:59<07:20,  1.76s/it]predicting train subjects:  13%|█▎        | 36/285 [01:00<07:05,  1.71s/it]predicting train subjects:  13%|█▎        | 37/285 [01:02<07:04,  1.71s/it]predicting train subjects:  13%|█▎        | 38/285 [01:04<07:13,  1.76s/it]predicting train subjects:  14%|█▎        | 39/285 [01:05<06:55,  1.69s/it]predicting train subjects:  14%|█▍        | 40/285 [01:07<06:53,  1.69s/it]predicting train subjects:  14%|█▍        | 41/285 [01:09<06:41,  1.64s/it]predicting train subjects:  15%|█▍        | 42/285 [01:10<06:31,  1.61s/it]predicting train subjects:  15%|█▌        | 43/285 [01:12<06:39,  1.65s/it]predicting train subjects:  15%|█▌        | 44/285 [01:14<06:55,  1.73s/it]predicting train subjects:  16%|█▌        | 45/285 [01:16<06:46,  1.69s/it]predicting train subjects:  16%|█▌        | 46/285 [01:17<06:56,  1.74s/it]predicting train subjects:  16%|█▋        | 47/285 [01:19<06:40,  1.68s/it]predicting train subjects:  17%|█▋        | 48/285 [01:21<06:44,  1.70s/it]predicting train subjects:  17%|█▋        | 49/285 [01:23<07:01,  1.79s/it]predicting train subjects:  18%|█▊        | 50/285 [01:24<06:52,  1.76s/it]predicting train subjects:  18%|█▊        | 51/285 [01:26<07:01,  1.80s/it]predicting train subjects:  18%|█▊        | 52/285 [01:28<06:44,  1.73s/it]predicting train subjects:  19%|█▊        | 53/285 [01:30<06:42,  1.74s/it]predicting train subjects:  19%|█▉        | 54/285 [01:31<06:48,  1.77s/it]predicting train subjects:  19%|█▉        | 55/285 [01:33<06:33,  1.71s/it]predicting train subjects:  20%|█▉        | 56/285 [01:35<06:32,  1.71s/it]predicting train subjects:  20%|██        | 57/285 [01:36<06:21,  1.67s/it]predicting train subjects:  20%|██        | 58/285 [01:38<06:19,  1.67s/it]predicting train subjects:  21%|██        | 59/285 [01:40<06:30,  1.73s/it]predicting train subjects:  21%|██        | 60/285 [01:42<06:38,  1.77s/it]predicting train subjects:  21%|██▏       | 61/285 [01:43<06:22,  1.71s/it]predicting train subjects:  22%|██▏       | 62/285 [01:45<06:32,  1.76s/it]predicting train subjects:  22%|██▏       | 63/285 [01:47<06:30,  1.76s/it]predicting train subjects:  22%|██▏       | 64/285 [01:48<06:15,  1.70s/it]predicting train subjects:  23%|██▎       | 65/285 [01:50<06:16,  1.71s/it]predicting train subjects:  23%|██▎       | 66/285 [01:52<06:14,  1.71s/it]predicting train subjects:  24%|██▎       | 67/285 [01:54<06:15,  1.72s/it]predicting train subjects:  24%|██▍       | 68/285 [01:55<06:02,  1.67s/it]predicting train subjects:  24%|██▍       | 69/285 [01:57<06:04,  1.69s/it]predicting train subjects:  25%|██▍       | 70/285 [01:59<06:02,  1.68s/it]predicting train subjects:  25%|██▍       | 71/285 [02:00<06:03,  1.70s/it]predicting train subjects:  25%|██▌       | 72/285 [02:02<05:50,  1.64s/it]predicting train subjects:  26%|██▌       | 73/285 [02:03<05:49,  1.65s/it]predicting train subjects:  26%|██▌       | 74/285 [02:05<05:49,  1.66s/it]predicting train subjects:  26%|██▋       | 75/285 [02:07<05:49,  1.66s/it]predicting train subjects:  27%|██▋       | 76/285 [02:09<05:52,  1.69s/it]predicting train subjects:  27%|██▋       | 77/285 [02:10<05:41,  1.64s/it]predicting train subjects:  27%|██▋       | 78/285 [02:12<05:32,  1.61s/it]predicting train subjects:  28%|██▊       | 79/285 [02:13<05:37,  1.64s/it]predicting train subjects:  28%|██▊       | 80/285 [02:15<05:39,  1.66s/it]predicting train subjects:  28%|██▊       | 81/285 [02:17<05:29,  1.62s/it]predicting train subjects:  29%|██▉       | 82/285 [02:18<05:32,  1.64s/it]predicting train subjects:  29%|██▉       | 83/285 [02:20<05:27,  1.62s/it]predicting train subjects:  29%|██▉       | 84/285 [02:21<05:23,  1.61s/it]predicting train subjects:  30%|██▉       | 85/285 [02:23<05:41,  1.71s/it]predicting train subjects:  30%|███       | 86/285 [02:25<05:40,  1.71s/it]predicting train subjects:  31%|███       | 87/285 [02:27<05:39,  1.71s/it]predicting train subjects:  31%|███       | 88/285 [02:28<05:29,  1.67s/it]predicting train subjects:  31%|███       | 89/285 [02:30<05:27,  1.67s/it]predicting train subjects:  32%|███▏      | 90/285 [02:32<05:27,  1.68s/it]predicting train subjects:  32%|███▏      | 91/285 [02:33<05:16,  1.63s/it]predicting train subjects:  32%|███▏      | 92/285 [02:35<05:20,  1.66s/it]predicting train subjects:  33%|███▎      | 93/285 [02:37<05:11,  1.62s/it]predicting train subjects:  33%|███▎      | 94/285 [02:38<05:16,  1.66s/it]predicting train subjects:  33%|███▎      | 95/285 [02:40<05:18,  1.68s/it]predicting train subjects:  34%|███▎      | 96/285 [02:42<05:18,  1.69s/it]predicting train subjects:  34%|███▍      | 97/285 [02:43<05:19,  1.70s/it]predicting train subjects:  34%|███▍      | 98/285 [02:45<05:23,  1.73s/it]predicting train subjects:  35%|███▍      | 99/285 [02:47<05:21,  1.73s/it]predicting train subjects:  35%|███▌      | 100/285 [02:49<05:21,  1.74s/it]predicting train subjects:  35%|███▌      | 101/285 [02:50<05:12,  1.70s/it]predicting train subjects:  36%|███▌      | 102/285 [02:52<05:10,  1.70s/it]predicting train subjects:  36%|███▌      | 103/285 [02:54<05:00,  1.65s/it]predicting train subjects:  36%|███▋      | 104/285 [02:55<05:01,  1.67s/it]predicting train subjects:  37%|███▋      | 105/285 [02:57<05:00,  1.67s/it]predicting train subjects:  37%|███▋      | 106/285 [02:58<04:47,  1.61s/it]predicting train subjects:  38%|███▊      | 107/285 [03:00<04:46,  1.61s/it]predicting train subjects:  38%|███▊      | 108/285 [03:02<04:39,  1.58s/it]predicting train subjects:  38%|███▊      | 109/285 [03:03<04:42,  1.61s/it]predicting train subjects:  39%|███▊      | 110/285 [03:05<04:46,  1.64s/it]predicting train subjects:  39%|███▉      | 111/285 [03:06<04:42,  1.62s/it]predicting train subjects:  39%|███▉      | 112/285 [03:08<04:45,  1.65s/it]predicting train subjects:  40%|███▉      | 113/285 [03:10<04:45,  1.66s/it]predicting train subjects:  40%|████      | 114/285 [03:12<04:46,  1.67s/it]predicting train subjects:  40%|████      | 115/285 [03:13<04:48,  1.70s/it]predicting train subjects:  41%|████      | 116/285 [03:15<04:47,  1.70s/it]predicting train subjects:  41%|████      | 117/285 [03:17<04:38,  1.66s/it]predicting train subjects:  41%|████▏     | 118/285 [03:18<04:32,  1.63s/it]predicting train subjects:  42%|████▏     | 119/285 [03:20<04:35,  1.66s/it]predicting train subjects:  42%|████▏     | 120/285 [03:21<04:31,  1.65s/it]predicting train subjects:  42%|████▏     | 121/285 [03:23<04:23,  1.61s/it]predicting train subjects:  43%|████▎     | 122/285 [03:24<04:15,  1.56s/it]predicting train subjects:  43%|████▎     | 123/285 [03:26<04:02,  1.50s/it]predicting train subjects:  44%|████▎     | 124/285 [03:27<04:06,  1.53s/it]predicting train subjects:  44%|████▍     | 125/285 [03:29<04:02,  1.52s/it]predicting train subjects:  44%|████▍     | 126/285 [03:30<03:58,  1.50s/it]predicting train subjects:  45%|████▍     | 127/285 [03:32<03:51,  1.46s/it]predicting train subjects:  45%|████▍     | 128/285 [03:33<03:54,  1.49s/it]predicting train subjects:  45%|████▌     | 129/285 [03:35<03:53,  1.50s/it]predicting train subjects:  46%|████▌     | 130/285 [03:36<03:47,  1.47s/it]predicting train subjects:  46%|████▌     | 131/285 [03:38<03:40,  1.43s/it]predicting train subjects:  46%|████▋     | 132/285 [03:39<03:44,  1.47s/it]predicting train subjects:  47%|████▋     | 133/285 [03:41<03:41,  1.46s/it]predicting train subjects:  47%|████▋     | 134/285 [03:42<03:38,  1.45s/it]predicting train subjects:  47%|████▋     | 135/285 [03:43<03:34,  1.43s/it]predicting train subjects:  48%|████▊     | 136/285 [03:45<03:30,  1.41s/it]predicting train subjects:  48%|████▊     | 137/285 [03:46<03:40,  1.49s/it]predicting train subjects:  48%|████▊     | 138/285 [03:48<03:33,  1.45s/it]predicting train subjects:  49%|████▉     | 139/285 [03:49<03:37,  1.49s/it]predicting train subjects:  49%|████▉     | 140/285 [03:51<03:38,  1.51s/it]predicting train subjects:  49%|████▉     | 141/285 [03:52<03:31,  1.47s/it]predicting train subjects:  50%|████▉     | 142/285 [03:54<03:28,  1.45s/it]predicting train subjects:  50%|█████     | 143/285 [03:55<03:24,  1.44s/it]predicting train subjects:  51%|█████     | 144/285 [03:57<03:29,  1.48s/it]predicting train subjects:  51%|█████     | 145/285 [03:58<03:23,  1.45s/it]predicting train subjects:  51%|█████     | 146/285 [04:00<03:25,  1.48s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:01<03:21,  1.46s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:03<03:22,  1.48s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:04<03:18,  1.46s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:05<03:14,  1.44s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:07<03:15,  1.46s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:08<03:11,  1.44s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:10<03:07,  1.42s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:11<03:12,  1.47s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:13<03:15,  1.51s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:14<03:15,  1.52s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:16<03:09,  1.48s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:17<03:07,  1.47s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:19<03:02,  1.45s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:20<02:59,  1.44s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:22<03:00,  1.45s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:23<02:56,  1.43s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:24<02:57,  1.45s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:26<02:52,  1.43s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:27<02:52,  1.43s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:29<02:51,  1.44s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:30<02:52,  1.46s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:32<02:48,  1.44s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:33<02:47,  1.45s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:34<02:45,  1.44s/it]predicting train subjects:  60%|██████    | 171/285 [04:36<02:43,  1.43s/it]predicting train subjects:  60%|██████    | 172/285 [04:37<02:42,  1.44s/it]predicting train subjects:  61%|██████    | 173/285 [04:39<02:39,  1.43s/it]predicting train subjects:  61%|██████    | 174/285 [04:40<02:38,  1.42s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:42<02:39,  1.45s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:43<02:42,  1.49s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:45<02:38,  1.46s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:46<02:33,  1.44s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:47<02:29,  1.41s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:49<02:37,  1.50s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:51<02:39,  1.53s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:52<02:39,  1.55s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:54<02:32,  1.49s/it]predicting train subjects:  65%|██████▍   | 184/285 [04:55<02:27,  1.46s/it]predicting train subjects:  65%|██████▍   | 185/285 [04:56<02:21,  1.41s/it]predicting train subjects:  65%|██████▌   | 186/285 [04:58<02:29,  1.51s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:00<02:35,  1.58s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:01<02:35,  1.60s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:03<02:25,  1.51s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:04<02:19,  1.47s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:06<02:21,  1.51s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:07<02:22,  1.53s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:09<02:14,  1.46s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:10<02:10,  1.43s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:11<02:04,  1.39s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:13<02:12,  1.48s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:15<02:16,  1.55s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:16<02:17,  1.58s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:18<02:08,  1.50s/it]predicting train subjects:  70%|███████   | 200/285 [05:19<02:04,  1.46s/it]predicting train subjects:  71%|███████   | 201/285 [05:21<02:07,  1.52s/it]predicting train subjects:  71%|███████   | 202/285 [05:22<02:07,  1.54s/it]predicting train subjects:  71%|███████   | 203/285 [05:24<02:07,  1.55s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:25<01:58,  1.47s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:26<01:53,  1.42s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:28<01:49,  1.39s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:29<01:57,  1.50s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:31<02:00,  1.56s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:33<02:02,  1.62s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:34<01:55,  1.54s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:36<01:50,  1.49s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:37<01:50,  1.52s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:39<01:52,  1.57s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:40<01:47,  1.51s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:42<01:51,  1.59s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:43<01:43,  1.50s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:45<01:46,  1.57s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:47<01:49,  1.63s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:49<01:48,  1.65s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:50<01:41,  1.56s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:51<01:36,  1.50s/it]predicting train subjects:  78%|███████▊  | 222/285 [05:53<01:36,  1.53s/it]predicting train subjects:  78%|███████▊  | 223/285 [05:54<01:31,  1.47s/it]predicting train subjects:  79%|███████▊  | 224/285 [05:56<01:28,  1.45s/it]predicting train subjects:  79%|███████▉  | 225/285 [05:57<01:26,  1.43s/it]predicting train subjects:  79%|███████▉  | 226/285 [05:59<01:30,  1.54s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:00<01:31,  1.57s/it]predicting train subjects:  80%|████████  | 228/285 [06:02<01:32,  1.63s/it]predicting train subjects:  80%|████████  | 229/285 [06:04<01:30,  1.61s/it]predicting train subjects:  81%|████████  | 230/285 [06:05<01:23,  1.51s/it]predicting train subjects:  81%|████████  | 231/285 [06:06<01:20,  1.48s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:08<01:20,  1.52s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:09<01:15,  1.45s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:11<01:19,  1.56s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:13<01:14,  1.49s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:14<01:17,  1.58s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:16<01:17,  1.61s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:18<01:17,  1.64s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:19<01:15,  1.64s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:21<01:09,  1.54s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:22<01:05,  1.49s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:23<01:02,  1.46s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:25<00:59,  1.42s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:26<01:01,  1.50s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:28<00:57,  1.44s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:29<00:59,  1.52s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:31<00:59,  1.57s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:33<00:59,  1.61s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:34<00:54,  1.52s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:36<00:51,  1.48s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:37<00:48,  1.42s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:38<00:45,  1.37s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:40<00:47,  1.49s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:42<00:48,  1.55s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:43<00:46,  1.55s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:44<00:42,  1.48s/it]predicting train subjects:  90%|█████████ | 257/285 [06:46<00:40,  1.44s/it]predicting train subjects:  91%|█████████ | 258/285 [06:47<00:41,  1.53s/it]predicting train subjects:  91%|█████████ | 259/285 [06:49<00:40,  1.54s/it]predicting train subjects:  91%|█████████ | 260/285 [06:50<00:36,  1.48s/it]predicting train subjects:  92%|█████████▏| 261/285 [06:52<00:35,  1.47s/it]predicting train subjects:  92%|█████████▏| 262/285 [06:53<00:32,  1.42s/it]predicting train subjects:  92%|█████████▏| 263/285 [06:54<00:30,  1.39s/it]predicting train subjects:  93%|█████████▎| 264/285 [06:56<00:31,  1.51s/it]predicting train subjects:  93%|█████████▎| 265/285 [06:58<00:31,  1.58s/it]predicting train subjects:  93%|█████████▎| 266/285 [06:59<00:28,  1.50s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:01<00:26,  1.47s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:02<00:26,  1.55s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:04<00:25,  1.58s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:05<00:22,  1.51s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:07<00:20,  1.47s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:08<00:19,  1.50s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:10<00:17,  1.45s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:11<00:15,  1.40s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:13<00:15,  1.51s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:14<00:14,  1.56s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:16<00:11,  1.49s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:17<00:10,  1.45s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:19<00:08,  1.48s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:20<00:07,  1.42s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:21<00:05,  1.41s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:23<00:04,  1.39s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:24<00:02,  1.49s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:26<00:01,  1.58s/it]predicting train subjects: 100%|██████████| 285/285 [07:28<00:00,  1.63s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:20,  1.76s/it]Loading train:   1%|          | 2/285 [00:03<07:43,  1.64s/it]Loading train:   1%|          | 3/285 [00:04<07:23,  1.57s/it]Loading train:   1%|▏         | 4/285 [00:06<07:32,  1.61s/it]Loading train:   2%|▏         | 5/285 [00:07<07:37,  1.63s/it]Loading train:   2%|▏         | 6/285 [00:09<07:09,  1.54s/it]Loading train:   2%|▏         | 7/285 [00:10<07:17,  1.57s/it]Loading train:   3%|▎         | 8/285 [00:12<06:59,  1.51s/it]Loading train:   3%|▎         | 9/285 [00:13<07:16,  1.58s/it]Loading train:   4%|▎         | 10/285 [00:15<06:56,  1.52s/it]Loading train:   4%|▍         | 11/285 [00:16<06:14,  1.37s/it]Loading train:   4%|▍         | 12/285 [00:17<06:00,  1.32s/it]Loading train:   5%|▍         | 13/285 [00:18<05:35,  1.23s/it]Loading train:   5%|▍         | 14/285 [00:20<05:53,  1.30s/it]Loading train:   5%|▌         | 15/285 [00:21<05:33,  1.24s/it]Loading train:   6%|▌         | 16/285 [00:22<05:26,  1.21s/it]Loading train:   6%|▌         | 17/285 [00:23<05:07,  1.15s/it]Loading train:   6%|▋         | 18/285 [00:24<05:23,  1.21s/it]Loading train:   7%|▋         | 19/285 [00:25<05:12,  1.18s/it]Loading train:   7%|▋         | 20/285 [00:26<05:07,  1.16s/it]Loading train:   7%|▋         | 21/285 [00:28<05:20,  1.21s/it]Loading train:   8%|▊         | 22/285 [00:29<05:08,  1.17s/it]Loading train:   8%|▊         | 23/285 [00:30<05:11,  1.19s/it]Loading train:   8%|▊         | 24/285 [00:31<05:00,  1.15s/it]Loading train:   9%|▉         | 25/285 [00:32<05:08,  1.19s/it]Loading train:   9%|▉         | 26/285 [00:34<05:05,  1.18s/it]Loading train:   9%|▉         | 27/285 [00:35<04:52,  1.13s/it]Loading train:  10%|▉         | 28/285 [00:36<05:01,  1.17s/it]Loading train:  10%|█         | 29/285 [00:37<04:56,  1.16s/it]Loading train:  11%|█         | 30/285 [00:38<05:08,  1.21s/it]Loading train:  11%|█         | 31/285 [00:40<05:09,  1.22s/it]Loading train:  11%|█         | 32/285 [00:41<04:54,  1.16s/it]Loading train:  12%|█▏        | 33/285 [00:42<04:50,  1.15s/it]Loading train:  12%|█▏        | 34/285 [00:43<05:03,  1.21s/it]Loading train:  12%|█▏        | 35/285 [00:44<05:08,  1.23s/it]Loading train:  13%|█▎        | 36/285 [00:45<04:59,  1.20s/it]Loading train:  13%|█▎        | 37/285 [00:47<04:51,  1.18s/it]Loading train:  13%|█▎        | 38/285 [00:48<05:11,  1.26s/it]Loading train:  14%|█▎        | 39/285 [00:49<04:56,  1.21s/it]Loading train:  14%|█▍        | 40/285 [00:50<04:49,  1.18s/it]Loading train:  14%|█▍        | 41/285 [00:51<04:48,  1.18s/it]Loading train:  15%|█▍        | 42/285 [00:52<04:29,  1.11s/it]Loading train:  15%|█▌        | 43/285 [00:53<04:25,  1.10s/it]Loading train:  15%|█▌        | 44/285 [00:54<04:22,  1.09s/it]Loading train:  16%|█▌        | 45/285 [00:55<04:13,  1.06s/it]Loading train:  16%|█▌        | 46/285 [00:57<04:34,  1.15s/it]Loading train:  16%|█▋        | 47/285 [00:58<04:25,  1.11s/it]Loading train:  17%|█▋        | 48/285 [00:59<04:28,  1.13s/it]Loading train:  17%|█▋        | 49/285 [01:00<04:25,  1.13s/it]Loading train:  18%|█▊        | 50/285 [01:01<04:33,  1.17s/it]Loading train:  18%|█▊        | 51/285 [01:03<04:35,  1.18s/it]Loading train:  18%|█▊        | 52/285 [01:04<04:32,  1.17s/it]Loading train:  19%|█▊        | 53/285 [01:05<04:35,  1.19s/it]Loading train:  19%|█▉        | 54/285 [01:06<04:29,  1.17s/it]Loading train:  19%|█▉        | 55/285 [01:07<04:13,  1.10s/it]Loading train:  20%|█▉        | 56/285 [01:08<04:15,  1.11s/it]Loading train:  20%|██        | 57/285 [01:09<04:10,  1.10s/it]Loading train:  20%|██        | 58/285 [01:10<04:15,  1.12s/it]Loading train:  21%|██        | 59/285 [01:12<04:21,  1.16s/it]Loading train:  21%|██        | 60/285 [01:13<04:25,  1.18s/it]Loading train:  21%|██▏       | 61/285 [01:14<04:05,  1.10s/it]Loading train:  22%|██▏       | 62/285 [01:15<04:09,  1.12s/it]Loading train:  22%|██▏       | 63/285 [01:16<04:13,  1.14s/it]Loading train:  22%|██▏       | 64/285 [01:18<04:30,  1.22s/it]Loading train:  23%|██▎       | 65/285 [01:19<04:54,  1.34s/it]Loading train:  23%|██▎       | 66/285 [01:21<05:07,  1.40s/it]Loading train:  24%|██▎       | 67/285 [01:22<04:57,  1.37s/it]Loading train:  24%|██▍       | 68/285 [01:23<04:37,  1.28s/it]Loading train:  24%|██▍       | 69/285 [01:24<04:21,  1.21s/it]Loading train:  25%|██▍       | 70/285 [01:25<04:23,  1.23s/it]Loading train:  25%|██▍       | 71/285 [01:27<04:33,  1.28s/it]Loading train:  25%|██▌       | 72/285 [01:28<04:14,  1.20s/it]Loading train:  26%|██▌       | 73/285 [01:29<04:28,  1.27s/it]Loading train:  26%|██▌       | 74/285 [01:31<04:40,  1.33s/it]Loading train:  26%|██▋       | 75/285 [01:32<04:54,  1.40s/it]Loading train:  27%|██▋       | 76/285 [01:34<04:54,  1.41s/it]Loading train:  27%|██▋       | 77/285 [01:35<04:43,  1.36s/it]Loading train:  27%|██▋       | 78/285 [01:36<04:25,  1.28s/it]Loading train:  28%|██▊       | 79/285 [01:37<04:18,  1.26s/it]Loading train:  28%|██▊       | 80/285 [01:38<04:09,  1.22s/it]Loading train:  28%|██▊       | 81/285 [01:39<03:52,  1.14s/it]Loading train:  29%|██▉       | 82/285 [01:40<03:48,  1.13s/it]Loading train:  29%|██▉       | 83/285 [01:42<03:47,  1.13s/it]Loading train:  29%|██▉       | 84/285 [01:43<03:43,  1.11s/it]Loading train:  30%|██▉       | 85/285 [01:44<03:40,  1.10s/it]Loading train:  30%|███       | 86/285 [01:45<03:46,  1.14s/it]Loading train:  31%|███       | 87/285 [01:46<03:46,  1.15s/it]Loading train:  31%|███       | 88/285 [01:47<03:46,  1.15s/it]Loading train:  31%|███       | 89/285 [01:48<03:43,  1.14s/it]Loading train:  32%|███▏      | 90/285 [01:50<03:43,  1.15s/it]Loading train:  32%|███▏      | 91/285 [01:50<03:28,  1.08s/it]Loading train:  32%|███▏      | 92/285 [01:52<03:37,  1.13s/it]Loading train:  33%|███▎      | 93/285 [01:53<03:25,  1.07s/it]Loading train:  33%|███▎      | 94/285 [01:54<03:31,  1.11s/it]Loading train:  33%|███▎      | 95/285 [01:55<03:36,  1.14s/it]Loading train:  34%|███▎      | 96/285 [01:56<03:38,  1.15s/it]Loading train:  34%|███▍      | 97/285 [01:58<03:48,  1.21s/it]Loading train:  34%|███▍      | 98/285 [01:59<03:41,  1.19s/it]Loading train:  35%|███▍      | 99/285 [02:00<03:31,  1.14s/it]Loading train:  35%|███▌      | 100/285 [02:01<03:31,  1.14s/it]Loading train:  35%|███▌      | 101/285 [02:02<03:25,  1.12s/it]Loading train:  36%|███▌      | 102/285 [02:03<03:32,  1.16s/it]Loading train:  36%|███▌      | 103/285 [02:04<03:26,  1.13s/it]Loading train:  36%|███▋      | 104/285 [02:06<03:32,  1.18s/it]Loading train:  37%|███▋      | 105/285 [02:07<03:34,  1.19s/it]Loading train:  37%|███▋      | 106/285 [02:08<03:22,  1.13s/it]Loading train:  38%|███▊      | 107/285 [02:09<03:31,  1.19s/it]Loading train:  38%|███▊      | 108/285 [02:10<03:23,  1.15s/it]Loading train:  38%|███▊      | 109/285 [02:11<03:22,  1.15s/it]Loading train:  39%|███▊      | 110/285 [02:13<03:27,  1.19s/it]Loading train:  39%|███▉      | 111/285 [02:14<03:22,  1.16s/it]Loading train:  39%|███▉      | 112/285 [02:15<03:12,  1.12s/it]Loading train:  40%|███▉      | 113/285 [02:16<03:16,  1.14s/it]Loading train:  40%|████      | 114/285 [02:17<03:21,  1.18s/it]Loading train:  40%|████      | 115/285 [02:18<03:22,  1.19s/it]Loading train:  41%|████      | 116/285 [02:20<03:20,  1.18s/it]Loading train:  41%|████      | 117/285 [02:21<03:11,  1.14s/it]Loading train:  41%|████▏     | 118/285 [02:22<03:05,  1.11s/it]Loading train:  42%|████▏     | 119/285 [02:23<03:21,  1.22s/it]Loading train:  42%|████▏     | 120/285 [02:24<03:13,  1.17s/it]Loading train:  42%|████▏     | 121/285 [02:26<03:28,  1.27s/it]Loading train:  43%|████▎     | 122/285 [02:27<03:24,  1.25s/it]Loading train:  43%|████▎     | 123/285 [02:28<03:23,  1.25s/it]Loading train:  44%|████▎     | 124/285 [02:29<03:14,  1.21s/it]Loading train:  44%|████▍     | 125/285 [02:30<02:59,  1.12s/it]Loading train:  44%|████▍     | 126/285 [02:31<02:53,  1.09s/it]Loading train:  45%|████▍     | 127/285 [02:32<02:43,  1.03s/it]Loading train:  45%|████▍     | 128/285 [02:33<02:35,  1.01it/s]Loading train:  45%|████▌     | 129/285 [02:34<02:32,  1.02it/s]Loading train:  46%|████▌     | 130/285 [02:35<02:28,  1.04it/s]Loading train:  46%|████▌     | 131/285 [02:36<02:29,  1.03it/s]Loading train:  46%|████▋     | 132/285 [02:37<02:32,  1.00it/s]Loading train:  47%|████▋     | 133/285 [02:38<02:34,  1.02s/it]Loading train:  47%|████▋     | 134/285 [02:39<02:34,  1.02s/it]Loading train:  47%|████▋     | 135/285 [02:40<02:25,  1.03it/s]Loading train:  48%|████▊     | 136/285 [02:41<02:27,  1.01it/s]Loading train:  48%|████▊     | 137/285 [02:42<02:38,  1.07s/it]Loading train:  48%|████▊     | 138/285 [02:43<02:36,  1.07s/it]Loading train:  49%|████▉     | 139/285 [02:44<02:37,  1.08s/it]Loading train:  49%|████▉     | 140/285 [02:45<02:35,  1.08s/it]Loading train:  49%|████▉     | 141/285 [02:47<02:36,  1.09s/it]Loading train:  50%|████▉     | 142/285 [02:47<02:29,  1.04s/it]Loading train:  50%|█████     | 143/285 [02:49<02:31,  1.06s/it]Loading train:  51%|█████     | 144/285 [02:50<02:32,  1.08s/it]Loading train:  51%|█████     | 145/285 [02:51<02:20,  1.01s/it]Loading train:  51%|█████     | 146/285 [02:51<02:18,  1.00it/s]Loading train:  52%|█████▏    | 147/285 [02:53<02:20,  1.01s/it]Loading train:  52%|█████▏    | 148/285 [02:54<02:24,  1.06s/it]Loading train:  52%|█████▏    | 149/285 [02:55<02:16,  1.01s/it]Loading train:  53%|█████▎    | 150/285 [02:56<02:20,  1.04s/it]Loading train:  53%|█████▎    | 151/285 [02:57<02:19,  1.04s/it]Loading train:  53%|█████▎    | 152/285 [02:58<02:17,  1.03s/it]Loading train:  54%|█████▎    | 153/285 [02:59<02:17,  1.04s/it]Loading train:  54%|█████▍    | 154/285 [03:00<02:14,  1.02s/it]Loading train:  54%|█████▍    | 155/285 [03:01<02:09,  1.01it/s]Loading train:  55%|█████▍    | 156/285 [03:02<02:11,  1.02s/it]Loading train:  55%|█████▌    | 157/285 [03:03<02:12,  1.03s/it]Loading train:  55%|█████▌    | 158/285 [03:04<02:12,  1.04s/it]Loading train:  56%|█████▌    | 159/285 [03:05<02:10,  1.03s/it]Loading train:  56%|█████▌    | 160/285 [03:06<02:08,  1.03s/it]Loading train:  56%|█████▋    | 161/285 [03:07<02:06,  1.02s/it]Loading train:  57%|█████▋    | 162/285 [03:08<02:14,  1.09s/it]Loading train:  57%|█████▋    | 163/285 [03:09<02:14,  1.11s/it]Loading train:  58%|█████▊    | 164/285 [03:10<02:12,  1.10s/it]Loading train:  58%|█████▊    | 165/285 [03:11<02:09,  1.08s/it]Loading train:  58%|█████▊    | 166/285 [03:13<02:06,  1.07s/it]Loading train:  59%|█████▊    | 167/285 [03:14<02:03,  1.05s/it]Loading train:  59%|█████▉    | 168/285 [03:15<02:00,  1.03s/it]Loading train:  59%|█████▉    | 169/285 [03:15<01:57,  1.01s/it]Loading train:  60%|█████▉    | 170/285 [03:17<01:56,  1.02s/it]Loading train:  60%|██████    | 171/285 [03:17<01:52,  1.01it/s]Loading train:  60%|██████    | 172/285 [03:18<01:51,  1.01it/s]Loading train:  61%|██████    | 173/285 [03:20<01:53,  1.02s/it]Loading train:  61%|██████    | 174/285 [03:21<01:53,  1.03s/it]Loading train:  61%|██████▏   | 175/285 [03:22<01:57,  1.07s/it]Loading train:  62%|██████▏   | 176/285 [03:23<02:03,  1.13s/it]Loading train:  62%|██████▏   | 177/285 [03:24<01:55,  1.07s/it]Loading train:  62%|██████▏   | 178/285 [03:25<01:57,  1.10s/it]Loading train:  63%|██████▎   | 179/285 [03:26<01:48,  1.03s/it]Loading train:  63%|██████▎   | 180/285 [03:27<01:55,  1.10s/it]Loading train:  64%|██████▎   | 181/285 [03:28<01:53,  1.09s/it]Loading train:  64%|██████▍   | 182/285 [03:29<01:54,  1.11s/it]Loading train:  64%|██████▍   | 183/285 [03:30<01:49,  1.08s/it]Loading train:  65%|██████▍   | 184/285 [03:31<01:46,  1.06s/it]Loading train:  65%|██████▍   | 185/285 [03:33<01:51,  1.12s/it]Loading train:  65%|██████▌   | 186/285 [03:34<01:56,  1.17s/it]Loading train:  66%|██████▌   | 187/285 [03:35<01:51,  1.14s/it]Loading train:  66%|██████▌   | 188/285 [03:36<01:53,  1.17s/it]Loading train:  66%|██████▋   | 189/285 [03:37<01:48,  1.13s/it]Loading train:  67%|██████▋   | 190/285 [03:38<01:43,  1.09s/it]Loading train:  67%|██████▋   | 191/285 [03:39<01:39,  1.06s/it]Loading train:  67%|██████▋   | 192/285 [03:41<01:41,  1.10s/it]Loading train:  68%|██████▊   | 193/285 [03:42<01:38,  1.07s/it]Loading train:  68%|██████▊   | 194/285 [03:43<01:35,  1.05s/it]Loading train:  68%|██████▊   | 195/285 [03:43<01:31,  1.01s/it]Loading train:  69%|██████▉   | 196/285 [03:45<01:38,  1.11s/it]Loading train:  69%|██████▉   | 197/285 [03:46<01:43,  1.18s/it]Loading train:  69%|██████▉   | 198/285 [03:47<01:47,  1.23s/it]Loading train:  70%|██████▉   | 199/285 [03:48<01:39,  1.16s/it]Loading train:  70%|███████   | 200/285 [03:49<01:32,  1.09s/it]Loading train:  71%|███████   | 201/285 [03:51<01:38,  1.17s/it]Loading train:  71%|███████   | 202/285 [03:52<01:32,  1.12s/it]Loading train:  71%|███████   | 203/285 [03:53<01:25,  1.05s/it]Loading train:  72%|███████▏  | 204/285 [03:54<01:24,  1.05s/it]Loading train:  72%|███████▏  | 205/285 [03:55<01:25,  1.07s/it]Loading train:  72%|███████▏  | 206/285 [03:56<01:22,  1.04s/it]Loading train:  73%|███████▎  | 207/285 [03:57<01:22,  1.06s/it]Loading train:  73%|███████▎  | 208/285 [03:58<01:23,  1.09s/it]Loading train:  73%|███████▎  | 209/285 [03:59<01:30,  1.18s/it]Loading train:  74%|███████▎  | 210/285 [04:00<01:25,  1.13s/it]Loading train:  74%|███████▍  | 211/285 [04:02<01:24,  1.14s/it]Loading train:  74%|███████▍  | 212/285 [04:03<01:19,  1.09s/it]Loading train:  75%|███████▍  | 213/285 [04:04<01:17,  1.08s/it]Loading train:  75%|███████▌  | 214/285 [04:05<01:13,  1.04s/it]Loading train:  75%|███████▌  | 215/285 [04:06<01:20,  1.14s/it]Loading train:  76%|███████▌  | 216/285 [04:07<01:16,  1.11s/it]Loading train:  76%|███████▌  | 217/285 [04:08<01:16,  1.13s/it]Loading train:  76%|███████▋  | 218/285 [04:10<01:19,  1.19s/it]Loading train:  77%|███████▋  | 219/285 [04:11<01:17,  1.18s/it]Loading train:  77%|███████▋  | 220/285 [04:12<01:12,  1.11s/it]Loading train:  78%|███████▊  | 221/285 [04:13<01:08,  1.07s/it]Loading train:  78%|███████▊  | 222/285 [04:14<01:12,  1.15s/it]Loading train:  78%|███████▊  | 223/285 [04:15<01:14,  1.20s/it]Loading train:  79%|███████▊  | 224/285 [04:16<01:10,  1.16s/it]Loading train:  79%|███████▉  | 225/285 [04:17<01:03,  1.07s/it]Loading train:  79%|███████▉  | 226/285 [04:18<01:05,  1.10s/it]Loading train:  80%|███████▉  | 227/285 [04:20<01:05,  1.13s/it]Loading train:  80%|████████  | 228/285 [04:21<01:14,  1.31s/it]Loading train:  80%|████████  | 229/285 [04:22<01:06,  1.19s/it]Loading train:  81%|████████  | 230/285 [04:23<01:02,  1.14s/it]Loading train:  81%|████████  | 231/285 [04:24<00:59,  1.09s/it]Loading train:  81%|████████▏ | 232/285 [04:25<00:56,  1.07s/it]Loading train:  82%|████████▏ | 233/285 [04:26<00:53,  1.03s/it]Loading train:  82%|████████▏ | 234/285 [04:27<00:57,  1.12s/it]Loading train:  82%|████████▏ | 235/285 [04:29<00:55,  1.11s/it]Loading train:  83%|████████▎ | 236/285 [04:30<00:57,  1.17s/it]Loading train:  83%|████████▎ | 237/285 [04:31<00:58,  1.21s/it]Loading train:  84%|████████▎ | 238/285 [04:33<01:01,  1.30s/it]Loading train:  84%|████████▍ | 239/285 [04:34<00:55,  1.21s/it]Loading train:  84%|████████▍ | 240/285 [04:35<00:52,  1.16s/it]Loading train:  85%|████████▍ | 241/285 [04:36<00:51,  1.16s/it]Loading train:  85%|████████▍ | 242/285 [04:37<00:45,  1.06s/it]Loading train:  85%|████████▌ | 243/285 [04:38<00:43,  1.03s/it]Loading train:  86%|████████▌ | 244/285 [04:39<00:45,  1.10s/it]Loading train:  86%|████████▌ | 245/285 [04:40<00:42,  1.06s/it]Loading train:  86%|████████▋ | 246/285 [04:41<00:43,  1.11s/it]Loading train:  87%|████████▋ | 247/285 [04:42<00:42,  1.12s/it]Loading train:  87%|████████▋ | 248/285 [04:44<00:43,  1.17s/it]Loading train:  87%|████████▋ | 249/285 [04:45<00:40,  1.14s/it]Loading train:  88%|████████▊ | 250/285 [04:46<00:39,  1.14s/it]Loading train:  88%|████████▊ | 251/285 [04:47<00:38,  1.13s/it]Loading train:  88%|████████▊ | 252/285 [04:48<00:36,  1.12s/it]Loading train:  89%|████████▉ | 253/285 [04:49<00:37,  1.18s/it]Loading train:  89%|████████▉ | 254/285 [04:51<00:37,  1.20s/it]Loading train:  89%|████████▉ | 255/285 [04:52<00:35,  1.18s/it]Loading train:  90%|████████▉ | 256/285 [04:53<00:32,  1.13s/it]Loading train:  90%|█████████ | 257/285 [04:54<00:30,  1.09s/it]Loading train:  91%|█████████ | 258/285 [04:55<00:30,  1.13s/it]Loading train:  91%|█████████ | 259/285 [04:56<00:28,  1.08s/it]Loading train:  91%|█████████ | 260/285 [04:57<00:24,  1.03it/s]Loading train:  92%|█████████▏| 261/285 [04:58<00:23,  1.03it/s]Loading train:  92%|█████████▏| 262/285 [04:58<00:21,  1.08it/s]Loading train:  92%|█████████▏| 263/285 [04:59<00:20,  1.06it/s]Loading train:  93%|█████████▎| 264/285 [05:01<00:22,  1.06s/it]Loading train:  93%|█████████▎| 265/285 [05:02<00:21,  1.07s/it]Loading train:  93%|█████████▎| 266/285 [05:03<00:18,  1.01it/s]Loading train:  94%|█████████▎| 267/285 [05:03<00:16,  1.10it/s]Loading train:  94%|█████████▍| 268/285 [05:04<00:15,  1.10it/s]Loading train:  94%|█████████▍| 269/285 [05:05<00:14,  1.13it/s]Loading train:  95%|█████████▍| 270/285 [05:06<00:12,  1.17it/s]Loading train:  95%|█████████▌| 271/285 [05:07<00:11,  1.18it/s]Loading train:  95%|█████████▌| 272/285 [05:07<00:10,  1.21it/s]Loading train:  96%|█████████▌| 273/285 [05:08<00:09,  1.23it/s]Loading train:  96%|█████████▌| 274/285 [05:09<00:08,  1.26it/s]Loading train:  96%|█████████▋| 275/285 [05:10<00:08,  1.20it/s]Loading train:  97%|█████████▋| 276/285 [05:11<00:07,  1.15it/s]Loading train:  97%|█████████▋| 277/285 [05:12<00:06,  1.15it/s]Loading train:  98%|█████████▊| 278/285 [05:13<00:06,  1.08it/s]Loading train:  98%|█████████▊| 279/285 [05:14<00:05,  1.14it/s]Loading train:  98%|█████████▊| 280/285 [05:14<00:04,  1.25it/s]Loading train:  99%|█████████▊| 281/285 [05:15<00:03,  1.25it/s]Loading train:  99%|█████████▉| 282/285 [05:16<00:02,  1.27it/s]Loading train:  99%|█████████▉| 283/285 [05:17<00:01,  1.22it/s]Loading train: 100%|█████████▉| 284/285 [05:17<00:00,  1.25it/s]Loading train: 100%|██████████| 285/285 [05:18<00:00,  1.21it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:04, 68.25it/s]concatenating: train:  10%|█         | 29/285 [00:00<00:02, 85.79it/s]concatenating: train:  20%|██        | 58/285 [00:00<00:02, 108.60it/s]concatenating: train:  31%|███       | 89/285 [00:00<00:01, 134.81it/s]concatenating: train:  42%|████▏     | 119/285 [00:00<00:01, 161.11it/s]concatenating: train:  51%|█████     | 146/285 [00:00<00:00, 182.76it/s]concatenating: train:  62%|██████▏   | 178/285 [00:00<00:00, 208.72it/s]concatenating: train:  74%|███████▍  | 212/285 [00:00<00:00, 235.33it/s]concatenating: train:  86%|████████▌ | 244/285 [00:00<00:00, 254.59it/s]concatenating: train:  97%|█████████▋| 276/285 [00:01<00:00, 270.71it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 273.81it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.14s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.14s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.12s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 793.57it/s]2019-07-09 12:39:37.372906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-09 12:39:37.373019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-09 12:39:37.373036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-09 12:39:37.373045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-09 12:39:37.487197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12743 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  4.95it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  5.93it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.66it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:01<00:07,  4.99it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:08,  4.34it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:02<00:07,  4.62it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:02<00:06,  4.82it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:02<00:04,  6.41it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  7.26it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:03<00:03,  6.58it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:03<00:02,  8.32it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:01,  8.91it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  9.07it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:05<00:03,  3.63it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:05<00:01,  4.65it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:05<00:01,  4.83it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:05<00:01,  4.86it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:06<00:00,  5.82it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:06<00:00,  5.31it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:06<00:00,  6.88it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 40)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 41)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 30)   11100       concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 30)   8130        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 30)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 40, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 60)   16260       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 60)   32460       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 90)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 90)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 120)  97320       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 120)  129720      activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 120)  480         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 120)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 210)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 210)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 60)   50460       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 60)   81060       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 60)   32460       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 60)   240         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 60)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 210)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 40, 210)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 30)   25230       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 60)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 30)   16230       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 30)   8130        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 30)   120         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 30)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 90)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 80, 90)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 40)   32440       dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 80, 40)   160         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 80, 40)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 80, 40)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 80, 130)  0           dropout_6[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 80, 13)   1703        concatenate_8[0][0]              
==================================================================================================
Total params: 545,823
Trainable params: 153,443
Non-trainable params: 392,380
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 34s - loss: 12705.3400 - acc: 0.6482 - mDice: 0.1455 - val_loss: 6325.1663 - val_acc: 0.9067 - val_mDice: 0.2752

Epoch 00001: val_mDice improved from -inf to 0.27522, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 24s - loss: 3966.5011 - acc: 0.8830 - mDice: 0.4497 - val_loss: 5273.8407 - val_acc: 0.9168 - val_mDice: 0.3545

Epoch 00002: val_mDice improved from 0.27522 to 0.35449, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 25s - loss: 3071.9747 - acc: 0.8969 - mDice: 0.5365 - val_loss: 3449.4930 - val_acc: 0.9291 - val_mDice: 0.4751

Epoch 00003: val_mDice improved from 0.35449 to 0.47507, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 24s - loss: 2714.7445 - acc: 0.9111 - mDice: 0.5766 - val_loss: 3477.3352 - val_acc: 0.9327 - val_mDice: 0.4745

Epoch 00004: val_mDice did not improve from 0.47507
Epoch 5/300
 - 25s - loss: 2474.2557 - acc: 0.9208 - mDice: 0.6047 - val_loss: 3480.1109 - val_acc: 0.9306 - val_mDice: 0.4777

Epoch 00005: val_mDice improved from 0.47507 to 0.47766, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 27s - loss: 2308.5524 - acc: 0.9249 - mDice: 0.6251 - val_loss: 3100.8744 - val_acc: 0.9336 - val_mDice: 0.5120

Epoch 00006: val_mDice improved from 0.47766 to 0.51204, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 25s - loss: 2199.2350 - acc: 0.9280 - mDice: 0.6389 - val_loss: 3196.2214 - val_acc: 0.9356 - val_mDice: 0.5016

Epoch 00007: val_mDice did not improve from 0.51204
Epoch 8/300
 - 25s - loss: 2104.1055 - acc: 0.9304 - mDice: 0.6513 - val_loss: 2958.1645 - val_acc: 0.9328 - val_mDice: 0.5266

Epoch 00008: val_mDice improved from 0.51204 to 0.52655, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 25s - loss: 2023.5144 - acc: 0.9324 - mDice: 0.6618 - val_loss: 3075.9215 - val_acc: 0.9320 - val_mDice: 0.5154

Epoch 00009: val_mDice did not improve from 0.52655
Epoch 10/300
 - 24s - loss: 1953.0700 - acc: 0.9339 - mDice: 0.6714 - val_loss: 2953.1168 - val_acc: 0.9362 - val_mDice: 0.5273

Epoch 00010: val_mDice improved from 0.52655 to 0.52731, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 25s - loss: 1903.0834 - acc: 0.9353 - mDice: 0.6782 - val_loss: 2952.4563 - val_acc: 0.9406 - val_mDice: 0.5283

Epoch 00011: val_mDice improved from 0.52731 to 0.52830, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 26s - loss: 1833.9987 - acc: 0.9367 - mDice: 0.6876 - val_loss: 3068.7825 - val_acc: 0.9348 - val_mDice: 0.5180

Epoch 00012: val_mDice did not improve from 0.52830
Epoch 13/300
 - 24s - loss: 1808.5158 - acc: 0.9374 - mDice: 0.6913 - val_loss: 3216.2444 - val_acc: 0.9259 - val_mDice: 0.5012

Epoch 00013: val_mDice did not improve from 0.52830
Epoch 14/300
 - 25s - loss: 1755.8798 - acc: 0.9383 - mDice: 0.6984 - val_loss: 2984.3065 - val_acc: 0.9401 - val_mDice: 0.5250

Epoch 00014: val_mDice did not improve from 0.52830
Epoch 15/300
 - 25s - loss: 1730.4126 - acc: 0.9391 - mDice: 0.7022 - val_loss: 3397.7657 - val_acc: 0.9182 - val_mDice: 0.4830

Epoch 00015: val_mDice did not improve from 0.52830
Epoch 16/300
 - 25s - loss: 1698.8653 - acc: 0.9398 - mDice: 0.7067 - val_loss: 3247.2269 - val_acc: 0.9288 - val_mDice: 0.5021

Epoch 00016: val_mDice did not improve from 0.52830
Epoch 17/300
 - 24s - loss: 1669.5815 - acc: 0.9404 - mDice: 0.7109 - val_loss: 3398.2673 - val_acc: 0.9275 - val_mDice: 0.4850

Epoch 00017: val_mDice did not improve from 0.52830
Epoch 18/300
 - 25s - loss: 1643.9167 - acc: 0.9410 - mDice: 0.7145 - val_loss: 3295.7209 - val_acc: 0.9369 - val_mDice: 0.4952

Epoch 00018: val_mDice did not improve from 0.52830
Epoch 19/300
 - 25s - loss: 1620.7479 - acc: 0.9414 - mDice: 0.7179 - val_loss: 3084.8772 - val_acc: 0.9316 - val_mDice: 0.5142

Epoch 00019: val_mDice did not improve from 0.52830
Epoch 20/300
 - 24s - loss: 1606.0983 - acc: 0.9418 - mDice: 0.7201 - val_loss: 2953.1575 - val_acc: 0.9400 - val_mDice: 0.5298

Epoch 00020: val_mDice improved from 0.52830 to 0.52981, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 21/300
 - 26s - loss: 1573.7649 - acc: 0.9425 - mDice: 0.7249 - val_loss: 2993.9044 - val_acc: 0.9372 - val_mDice: 0.5259

Epoch 00021: val_mDice did not improve from 0.52981
Epoch 22/300
 - 24s - loss: 1559.0804 - acc: 0.9427 - mDice: 0.7270 - val_loss: 3081.4361 - val_acc: 0.9404 - val_mDice: 0.5165

Epoch 00022: val_mDice did not improve from 0.52981
Epoch 23/300
 - 25s - loss: 1526.1389 - acc: 0.9435 - mDice: 0.7317 - val_loss: 2895.3506 - val_acc: 0.9458 - val_mDice: 0.5335

Epoch 00023: val_mDice improved from 0.52981 to 0.53349, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 24/300
 - 24s - loss: 1505.9163 - acc: 0.9438 - mDice: 0.7348 - val_loss: 3360.4266 - val_acc: 0.9252 - val_mDice: 0.4919

Epoch 00024: val_mDice did not improve from 0.53349
Epoch 25/300
 - 24s - loss: 1496.8476 - acc: 0.9439 - mDice: 0.7362 - val_loss: 3158.7386 - val_acc: 0.9400 - val_mDice: 0.5095

Epoch 00025: val_mDice did not improve from 0.53349
Epoch 26/300
 - 24s - loss: 1482.1106 - acc: 0.9444 - mDice: 0.7384 - val_loss: 3211.4347 - val_acc: 0.9287 - val_mDice: 0.5029

Epoch 00026: val_mDice did not improve from 0.53349
Epoch 27/300
 - 25s - loss: 1454.4835 - acc: 0.9451 - mDice: 0.7426 - val_loss: 2908.2831 - val_acc: 0.9437 - val_mDice: 0.5345

Epoch 00027: val_mDice improved from 0.53349 to 0.53451, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 28/300
 - 25s - loss: 1446.0848 - acc: 0.9449 - mDice: 0.7438 - val_loss: 3423.3943 - val_acc: 0.9377 - val_mDice: 0.4825

Epoch 00028: val_mDice did not improve from 0.53451
Epoch 29/300
 - 26s - loss: 1433.4863 - acc: 0.9454 - mDice: 0.7457 - val_loss: 3217.5441 - val_acc: 0.9376 - val_mDice: 0.5042

Epoch 00029: val_mDice did not improve from 0.53451
Epoch 30/300
 - 25s - loss: 1425.9969 - acc: 0.9455 - mDice: 0.7468 - val_loss: 3058.3356 - val_acc: 0.9436 - val_mDice: 0.5203

Epoch 00030: val_mDice did not improve from 0.53451
Epoch 31/300
 - 25s - loss: 1410.6403 - acc: 0.9457 - mDice: 0.7492 - val_loss: 3072.4710 - val_acc: 0.9334 - val_mDice: 0.5167

Epoch 00031: val_mDice did not improve from 0.53451
Epoch 32/300
 - 24s - loss: 1404.6174 - acc: 0.9459 - mDice: 0.7500 - val_loss: 3056.2712 - val_acc: 0.9417 - val_mDice: 0.5215

Epoch 00032: val_mDice did not improve from 0.53451
Epoch 33/300
 - 26s - loss: 1385.1833 - acc: 0.9463 - mDice: 0.7531 - val_loss: 3071.2397 - val_acc: 0.9375 - val_mDice: 0.5179

Epoch 00033: val_mDice did not improve from 0.53451
Epoch 34/300
 - 25s - loss: 1366.3039 - acc: 0.9466 - mDice: 0.7559 - val_loss: 3057.4728 - val_acc: 0.9384 - val_mDice: 0.5206

Epoch 00034: val_mDice did not improve from 0.53451
Epoch 35/300
 - 24s - loss: 1368.1257 - acc: 0.9467 - mDice: 0.7557 - val_loss: 3274.1475 - val_acc: 0.9413 - val_mDice: 0.4991

Epoch 00035: val_mDice did not improve from 0.53451
Epoch 36/300
 - 25s - loss: 1352.8409 - acc: 0.9471 - mDice: 0.7581 - val_loss: 3309.2381 - val_acc: 0.9348 - val_mDice: 0.4964

Epoch 00036: val_mDice did not improve from 0.53451
Epoch 37/300
 - 25s - loss: 1340.7753 - acc: 0.9473 - mDice: 0.7599 - val_loss: 3373.6249 - val_acc: 0.9263 - val_mDice: 0.4909

Epoch 00037: val_mDice did not improve from 0.53451
Epoch 38/300
 - 25s - loss: 1331.2733 - acc: 0.9474 - mDice: 0.7613 - val_loss: 3005.8710 - val_acc: 0.9427 - val_mDice: 0.5250

Epoch 00038: val_mDice did not improve from 0.53451
Epoch 39/300
 - 25s - loss: 1323.4932 - acc: 0.9476 - mDice: 0.7626 - val_loss: 3022.2536 - val_acc: 0.9425 - val_mDice: 0.5232

Epoch 00039: val_mDice did not improve from 0.53451
Epoch 40/300
 - 25s - loss: 1315.5270 - acc: 0.9476 - mDice: 0.7637 - val_loss: 3119.9598 - val_acc: 0.9431 - val_mDice: 0.5136

Epoch 00040: val_mDice did not improve from 0.53451
Epoch 41/300
 - 25s - loss: 1308.3507 - acc: 0.9478 - mDice: 0.7649 - val_loss: 3198.5101 - val_acc: 0.9433 - val_mDice: 0.5029

Epoch 00041: val_mDice did not improve from 0.53451
Epoch 42/300
 - 25s - loss: 1299.7850 - acc: 0.9480 - mDice: 0.7662 - val_loss: 2986.2353 - val_acc: 0.9413 - val_mDice: 0.5266

Epoch 00042: val_mDice did not improve from 0.53451
Epoch 43/300
 - 25s - loss: 1289.3438 - acc: 0.9483 - mDice: 0.7678 - val_loss: 2916.7083 - val_acc: 0.9354 - val_mDice: 0.5310

Epoch 00043: val_mDice did not improve from 0.53451
Epoch 44/300
 - 25s - loss: 1289.6351 - acc: 0.9481 - mDice: 0.7678 - val_loss: 3051.4785 - val_acc: 0.9434 - val_mDice: 0.5220

Epoch 00044: val_mDice did not improve from 0.53451
Epoch 45/300
 - 23s - loss: 1276.9131 - acc: 0.9486 - mDice: 0.7698 - val_loss: 3160.5462 - val_acc: 0.9305 - val_mDice: 0.5092

Epoch 00045: val_mDice did not improve from 0.53451
Epoch 46/300
 - 23s - loss: 1271.6106 - acc: 0.9486 - mDice: 0.7706 - val_loss: 2773.9395 - val_acc: 0.9431 - val_mDice: 0.5453

Epoch 00046: val_mDice improved from 0.53451 to 0.54526, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 47/300
 - 24s - loss: 1260.1278 - acc: 0.9487 - mDice: 0.7724 - val_loss: 2974.5116 - val_acc: 0.9400 - val_mDice: 0.5255

Epoch 00047: val_mDice did not improve from 0.54526
Epoch 48/300
 - 25s - loss: 1245.5835 - acc: 0.9491 - mDice: 0.7747 - val_loss: 2995.7891 - val_acc: 0.9337 - val_mDice: 0.5222

Epoch 00048: val_mDice did not improve from 0.54526
Epoch 49/300
 - 26s - loss: 1251.1002 - acc: 0.9488 - mDice: 0.7737 - val_loss: 3090.6608 - val_acc: 0.9409 - val_mDice: 0.5151

Epoch 00049: val_mDice did not improve from 0.54526
Epoch 50/300
 - 25s - loss: 1240.6324 - acc: 0.9492 - mDice: 0.7754 - val_loss: 3031.9380 - val_acc: 0.9396 - val_mDice: 0.5214

Epoch 00050: val_mDice did not improve from 0.54526
Epoch 51/300
 - 25s - loss: 1231.1613 - acc: 0.9493 - mDice: 0.7769 - val_loss: 3071.2494 - val_acc: 0.9446 - val_mDice: 0.5156

Epoch 00051: val_mDice did not improve from 0.54526
Epoch 52/300
 - 25s - loss: 1228.2931 - acc: 0.9494 - mDice: 0.7775 - val_loss: 3040.3023 - val_acc: 0.9447 - val_mDice: 0.5218

Epoch 00052: val_mDice did not improve from 0.54526
Epoch 53/300
 - 25s - loss: 1222.5297 - acc: 0.9495 - mDice: 0.7783 - val_loss: 3141.6869 - val_acc: 0.9425 - val_mDice: 0.5145

Epoch 00053: val_mDice did not improve from 0.54526
Epoch 54/300
 - 25s - loss: 1217.7363 - acc: 0.9497 - mDice: 0.7791 - val_loss: 3083.8798 - val_acc: 0.9436 - val_mDice: 0.5163

Epoch 00054: val_mDice did not improve from 0.54526
Epoch 55/300
 - 25s - loss: 1210.8100 - acc: 0.9498 - mDice: 0.7801 - val_loss: 3159.9203 - val_acc: 0.9300 - val_mDice: 0.5077

Epoch 00055: val_mDice did not improve from 0.54526
Epoch 56/300
 - 24s - loss: 1204.7963 - acc: 0.9497 - mDice: 0.7812 - val_loss: 3046.7365 - val_acc: 0.9392 - val_mDice: 0.5203

Epoch 00056: val_mDice did not improve from 0.54526
Epoch 57/300
 - 25s - loss: 1196.4203 - acc: 0.9500 - mDice: 0.7825 - val_loss: 3086.8063 - val_acc: 0.9415 - val_mDice: 0.5167

Epoch 00057: val_mDice did not improve from 0.54526
Epoch 58/300
 - 24s - loss: 1195.1921 - acc: 0.9500 - mDice: 0.7826 - val_loss: 2924.8040 - val_acc: 0.9391 - val_mDice: 0.5316

Epoch 00058: val_mDice did not improve from 0.54526
Epoch 59/300
 - 25s - loss: 1194.1897 - acc: 0.9499 - mDice: 0.7828 - val_loss: 3257.7359 - val_acc: 0.9323 - val_mDice: 0.5029

Epoch 00059: val_mDice did not improve from 0.54526
Epoch 60/300
 - 24s - loss: 1182.4381 - acc: 0.9503 - mDice: 0.7847 - val_loss: 2835.5482 - val_acc: 0.9369 - val_mDice: 0.5405

Epoch 00060: val_mDice did not improve from 0.54526
Epoch 61/300
 - 25s - loss: 1182.3580 - acc: 0.9503 - mDice: 0.7847 - val_loss: 2990.7716 - val_acc: 0.9440 - val_mDice: 0.5214

Epoch 00061: val_mDice did not improve from 0.54526
Epoch 62/300
 - 25s - loss: 1170.9933 - acc: 0.9505 - mDice: 0.7865 - val_loss: 2930.2524 - val_acc: 0.9307 - val_mDice: 0.5281

Epoch 00062: val_mDice did not improve from 0.54526
Epoch 63/300
 - 25s - loss: 1169.1883 - acc: 0.9506 - mDice: 0.7868 - val_loss: 3161.9040 - val_acc: 0.9390 - val_mDice: 0.5137

Epoch 00063: val_mDice did not improve from 0.54526
Epoch 64/300
 - 25s - loss: 1161.2461 - acc: 0.9508 - mDice: 0.7881 - val_loss: 2940.0889 - val_acc: 0.9433 - val_mDice: 0.5324

Epoch 00064: val_mDice did not improve from 0.54526
Epoch 65/300
 - 25s - loss: 1158.2160 - acc: 0.9508 - mDice: 0.7886 - val_loss: 3048.3612 - val_acc: 0.9376 - val_mDice: 0.5172

Epoch 00065: val_mDice did not improve from 0.54526
Epoch 66/300
 - 25s - loss: 1157.1596 - acc: 0.9507 - mDice: 0.7888 - val_loss: 2878.2676 - val_acc: 0.9433 - val_mDice: 0.5365

Epoch 00066: val_mDice did not improve from 0.54526
Epoch 67/300
 - 24s - loss: 1153.3659 - acc: 0.9509 - mDice: 0.7893 - val_loss: 3198.8009 - val_acc: 0.9402 - val_mDice: 0.5067

Epoch 00067: val_mDice did not improve from 0.54526
Epoch 68/300
 - 24s - loss: 1151.1197 - acc: 0.9509 - mDice: 0.7897 - val_loss: 2875.9427 - val_acc: 0.9404 - val_mDice: 0.5345

Epoch 00068: val_mDice did not improve from 0.54526
Epoch 69/300
 - 23s - loss: 1143.8479 - acc: 0.9511 - mDice: 0.7909 - val_loss: 3030.1067 - val_acc: 0.9392 - val_mDice: 0.5206

Epoch 00069: val_mDice did not improve from 0.54526
Epoch 70/300
 - 25s - loss: 1147.2585 - acc: 0.9509 - mDice: 0.7903 - val_loss: 3194.7221 - val_acc: 0.9369 - val_mDice: 0.5071

Epoch 00070: val_mDice did not improve from 0.54526
Epoch 71/300
 - 25s - loss: 1140.1254 - acc: 0.9512 - mDice: 0.7915 - val_loss: 3019.2893 - val_acc: 0.9462 - val_mDice: 0.5226

Epoch 00071: val_mDice did not improve from 0.54526
Epoch 72/300
 - 25s - loss: 1131.4311 - acc: 0.9513 - mDice: 0.7929 - val_loss: 2993.9543 - val_acc: 0.9409 - val_mDice: 0.5238

Epoch 00072: val_mDice did not improve from 0.54526
Epoch 73/300
 - 24s - loss: 1128.1377 - acc: 0.9514 - mDice: 0.7935 - val_loss: 2820.9158 - val_acc: 0.9402 - val_mDice: 0.5392

Epoch 00073: val_mDice did not improve from 0.54526
Epoch 74/300
 - 24s - loss: 1126.9164 - acc: 0.9515 - mDice: 0.7936 - val_loss: 2818.4033 - val_acc: 0.9401 - val_mDice: 0.5395

Epoch 00074: val_mDice did not improve from 0.54526
Epoch 75/300
 - 23s - loss: 1121.9993 - acc: 0.9514 - mDice: 0.7944 - val_loss: 2877.6991 - val_acc: 0.9405 - val_mDice: 0.5342

Epoch 00075: val_mDice did not improve from 0.54526
Epoch 76/300
 - 25s - loss: 1124.2266 - acc: 0.9514 - mDice: 0.7940 - val_loss: 3009.1481 - val_acc: 0.9430 - val_mDice: 0.5214

Epoch 00076: val_mDice did not improve from 0.54526
Restoring model weights from the end of the best epoch
Epoch 00076: early stopping
{'val_loss': [6325.166271391369, 5273.840704055059, 3449.4929780505954, 3477.3352167038693, 3480.110863095238, 3100.8744070870534, 3196.221365792411, 2958.1644577752977, 3075.9214797247023, 2953.1167573474704, 2952.4562639508927, 3068.7825055803573, 3216.244408017113, 2984.306466238839, 3397.7657180059523, 3247.226853143601, 3398.267333984375, 3295.7209356398807, 3084.8771856398807, 2953.157470703125, 2993.9043782552085, 3081.4361165364585, 2895.350632440476, 3360.4265950520835, 3158.7386416480654, 3211.4346633184523, 2908.2830984933034, 3423.3943452380954, 3217.5440848214284, 3058.3356352306546, 3072.470993768601, 3056.271193731399, 3071.239722842262, 3057.4727608816966, 3274.1475423177085, 3309.2381301153273, 3373.624930245536, 3005.871047247024, 3022.253615606399, 3119.9597981770835, 3198.5101492745534, 2986.2353399367557, 2916.7083449590773, 3051.4785272507443, 3160.546165829613, 2773.9395345052085, 2974.5115676153273, 2995.789132254464, 3090.660818917411, 3031.938034784226, 3071.2493838355654, 3040.3022809709823, 3141.6868605840773, 3083.8797781808034, 3159.9202938988096, 3046.7364501953125, 3086.806349981399, 2924.803955078125, 3257.7358979724704, 2835.5482352120534, 2990.7715890066966, 2930.2524297805057, 3161.9039713541665, 2940.0889485677085, 3048.3612176804318, 2878.26760718936, 3198.800938197545, 2875.9426850818454, 3030.106660388765, 3194.7220633370534, 3019.289324079241, 2993.9542875744046, 2820.9157831101193, 2818.403297061012, 2877.6991083054318, 3009.1480945405506], 'val_acc': [0.9067147374153137, 0.9167857028189159, 0.9290590740385509, 0.9326510997045607, 0.930570071651822, 0.9336217868895758, 0.9356478679747808, 0.9327655945505414, 0.9320009038561866, 0.9361858935583205, 0.9406204280399141, 0.9348214098385402, 0.9258859753608704, 0.9400847043309893, 0.9182028600147792, 0.9287614396640232, 0.9275068782624745, 0.9368932871591478, 0.9316346219607762, 0.9400183075950259, 0.93723444995426, 0.9404166851724897, 0.9458104116576058, 0.9251693912914821, 0.9400252103805542, 0.9287431523913429, 0.9436767555418468, 0.9377128907612392, 0.937577812444596, 0.9435989147140866, 0.9333745297931489, 0.9416987158003307, 0.9374587762923468, 0.9384409387906393, 0.9412797746204195, 0.9348122647830418, 0.9263438923018319, 0.942731207325345, 0.9424771325928825, 0.9430952639806838, 0.9432715035620189, 0.9412957685334342, 0.9353502818516323, 0.9434088809149606, 0.9304601521719069, 0.943097520442236, 0.9400412071318853, 0.9336973684174674, 0.9408882969901675, 0.9395535815329779, 0.9445993588084266, 0.9447344342867533, 0.9424885511398315, 0.9436194896697998, 0.9299588118280683, 0.9391849864096868, 0.9414858335540408, 0.939107114360446, 0.9323397392318362, 0.9368704103288197, 0.9439652051244464, 0.9307257277624947, 0.9390476289249602, 0.9432600481169564, 0.9375618270465306, 0.9432715347834996, 0.9401854191507611, 0.9404029108229137, 0.9392147631872267, 0.9368589662370228, 0.9461561441421509, 0.9408745510237557, 0.9401808522996449, 0.9401099142574129, 0.9404555644307818, 0.9429578610828945], 'val_mDice': [0.27521671780518125, 0.3544920322795709, 0.4750726059788749, 0.47454748143042835, 0.47765811284383136, 0.5120424944020453, 0.5015756700720105, 0.5265506085540567, 0.5154135056904384, 0.5273106302179041, 0.5283028020390442, 0.5179969196518263, 0.5011937664378256, 0.5249568967237359, 0.4829844371193931, 0.5021014673014482, 0.48495597676152274, 0.495189108841476, 0.5142468787020161, 0.5298107791514624, 0.5259384548380261, 0.5165373796508426, 0.5334861929572764, 0.4919440842100552, 0.509543102944181, 0.5029093261275973, 0.5345067896303677, 0.48245639070158913, 0.5041821563527698, 0.5202636660209724, 0.5167321388920149, 0.5215284891781353, 0.5178580071244921, 0.5206467867607162, 0.49905129752698396, 0.49639791001876193, 0.4908704835744131, 0.5249952047708488, 0.5231939298766, 0.5136260273201125, 0.502881761817705, 0.5265734224092393, 0.5309824283633914, 0.5220414767307895, 0.5092178751670179, 0.5452558047005108, 0.5255061563636575, 0.522162445244335, 0.5150970353611878, 0.5214038913448652, 0.515573555514926, 0.521762991767554, 0.5144997840481145, 0.5162927153564635, 0.5076730497890994, 0.5203362586242812, 0.5167463400534221, 0.5315727547165894, 0.5028539104830652, 0.5404588590775218, 0.5214073767974263, 0.5281109916312354, 0.5136568551617009, 0.5324277444964364, 0.5172448708187967, 0.5365310529513019, 0.5066883787512779, 0.5344942678653058, 0.5206424640048117, 0.5070914650956789, 0.522593073901676, 0.5238316908833527, 0.5391698023747831, 0.5395408093574501, 0.5341954217070625, 0.5214311008652052], 'loss': [12705.340038234106, 3966.5011093878024, 3071.9747003099696, 2714.7444521431657, 2474.255707440175, 2308.5523801898826, 2199.2349790680128, 2104.105506145359, 2023.5144178994663, 1953.0700087009516, 1903.083396968985, 1833.9987255454591, 1808.5158269678855, 1755.8798247543814, 1730.4126309096434, 1698.865267957868, 1669.5814942535876, 1643.9167206534214, 1620.7479487857263, 1606.0982855698817, 1573.7649340448477, 1559.080397691758, 1526.1388738664193, 1505.916258824269, 1496.8475977682713, 1482.110595467786, 1454.4835429826821, 1446.0848429385512, 1433.4863363265624, 1425.996942523451, 1410.6403082690763, 1404.6173895620211, 1385.1833374423513, 1366.3039220718374, 1368.125672881121, 1352.840852989313, 1340.7752506100926, 1331.2732751867272, 1323.493235899714, 1315.5269903768021, 1308.3507295177924, 1299.785022189168, 1289.3438003037002, 1289.6350721892811, 1276.913082783958, 1271.6106002922345, 1260.1277796000857, 1245.583488715874, 1251.1001803778904, 1240.6323851127029, 1231.1613387458467, 1228.293091126253, 1222.5297391357187, 1217.7363305019235, 1210.8099649406156, 1204.7962953954711, 1196.4202851088999, 1195.1921045594945, 1194.1897461455246, 1182.4381320262796, 1182.3579790517272, 1170.9932916044431, 1169.1883477850274, 1161.2460888784838, 1158.2159865088654, 1157.159630361586, 1153.365903926075, 1151.1197433633474, 1143.8478568411526, 1147.2585168577054, 1140.1254228099547, 1131.4310648917967, 1128.1377458162383, 1126.91643879973, 1121.9993175405837, 1124.2266179458563], 'acc': [0.6481948905174318, 0.8830084883686387, 0.8969246122288709, 0.9111475295957996, 0.9208068929128571, 0.9249317819543121, 0.9279731787053151, 0.9303625645677961, 0.9324451324589017, 0.9339457879940715, 0.9353258809832817, 0.9367494645182145, 0.9373943613447481, 0.9383469772104448, 0.939078836949409, 0.9397594387967485, 0.9403723349731185, 0.9409952394094039, 0.9414245001332526, 0.9418105422037057, 0.9424510528776074, 0.9426826108897011, 0.9434644072322871, 0.9438446585511987, 0.9438879633882912, 0.944354646119029, 0.9450923691532251, 0.944921499976814, 0.9453554602976546, 0.9455105951923107, 0.9457233178838499, 0.9458888301919232, 0.9462709781841803, 0.9466054616393623, 0.9466590817456809, 0.9471103337911, 0.9472536051206697, 0.9474322852978984, 0.9476352459965631, 0.947633552337534, 0.9478299128014113, 0.9479887296934222, 0.9482911011146309, 0.9480960415189658, 0.9485726146562862, 0.9485855909448289, 0.9487137764847438, 0.9490593168256093, 0.9488324877704203, 0.9492082168813705, 0.9493407157889124, 0.949398506404762, 0.9494571291184596, 0.9496619463748318, 0.9498406927641219, 0.9497270813584903, 0.9500266702528608, 0.9500196254940558, 0.9499185048065274, 0.9503384936009847, 0.9503168535181983, 0.9505478772258446, 0.9505761702303852, 0.950773567897818, 0.9508304304301636, 0.9507139455106922, 0.9509129477921584, 0.9508966796770936, 0.9510851379922757, 0.9509480532846952, 0.9512286158524567, 0.9512595041238988, 0.9514341742886223, 0.9514559557816186, 0.9514405447346915, 0.9514285438042834], 'mDice': [0.1455143823219973, 0.44967607357769956, 0.5364966010436033, 0.5765983769952021, 0.6047051317985517, 0.6250594861249554, 0.6389330765036735, 0.6513410240256627, 0.6618238236946892, 0.6714256539587481, 0.6782127412408446, 0.6875578916576158, 0.6913057073982368, 0.6984407478544509, 0.7021926236630681, 0.7066687293794542, 0.7109147194311157, 0.7145176796479241, 0.7179067549917862, 0.7201225308869095, 0.7248529234051084, 0.7269849028572632, 0.7317384258731381, 0.734810482405366, 0.7361633746592278, 0.738372441843017, 0.7425562706507537, 0.7437839224224999, 0.7457011322628585, 0.7468442629131481, 0.7491700552735734, 0.7500440849719168, 0.7530593674537279, 0.7558973739435385, 0.7556616782636478, 0.7581216036204729, 0.7598930882515879, 0.7612702054441469, 0.7625658165312282, 0.763735073355551, 0.7648898656137972, 0.766195031829898, 0.7677953562824763, 0.7678192974469876, 0.7697985333377786, 0.7705968057394533, 0.7723896170779416, 0.7746713945740148, 0.7737469721074873, 0.7754229431164295, 0.7769220430473613, 0.7774539855902242, 0.77832459339361, 0.7791066356125378, 0.7800965937939319, 0.7811604617808121, 0.7824799326290302, 0.7826136887153955, 0.7827851347710003, 0.7847018433439954, 0.7847031149097506, 0.7865165885482561, 0.7867890881945087, 0.7880700922251346, 0.7885579772829343, 0.7887501058055414, 0.7893223737691303, 0.7897076793826566, 0.7908809242713697, 0.7903322813849654, 0.7914962980566582, 0.7928789031282656, 0.7934815000770683, 0.793622179184894, 0.7944208777706955, 0.7940448777671492]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.50s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.19s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.94s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:35,  1.82s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:52,  1.67s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:50,  1.67s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:21,  1.57s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:42,  1.65s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:23,  1.59s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:41,  1.66s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:26,  1.61s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:48,  1.70s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:05,  1.77s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<07:37,  1.67s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<07:57,  1.75s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:39,  1.69s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<07:50,  1.74s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<08:04,  1.80s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<08:10,  1.82s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<07:51,  1.76s/it]predicting train subjects:   6%|▋         | 18/285 [00:30<07:51,  1.77s/it]predicting train subjects:   7%|▋         | 19/285 [00:32<07:33,  1.71s/it]predicting train subjects:   7%|▋         | 20/285 [00:33<07:38,  1.73s/it]predicting train subjects:   7%|▋         | 21/285 [00:35<08:00,  1.82s/it]predicting train subjects:   8%|▊         | 22/285 [00:37<07:33,  1.73s/it]predicting train subjects:   8%|▊         | 23/285 [00:39<07:42,  1.76s/it]predicting train subjects:   8%|▊         | 24/285 [00:40<07:18,  1.68s/it]predicting train subjects:   9%|▉         | 25/285 [00:42<07:33,  1.75s/it]predicting train subjects:   9%|▉         | 26/285 [00:44<07:42,  1.79s/it]predicting train subjects:   9%|▉         | 27/285 [00:46<07:24,  1.72s/it]predicting train subjects:  10%|▉         | 28/285 [00:48<07:37,  1.78s/it]predicting train subjects:  10%|█         | 29/285 [00:49<07:45,  1.82s/it]predicting train subjects:  11%|█         | 30/285 [00:51<07:53,  1.86s/it]predicting train subjects:  11%|█         | 31/285 [00:53<07:49,  1.85s/it]predicting train subjects:  11%|█         | 32/285 [00:55<07:24,  1.76s/it]predicting train subjects:  12%|█▏        | 33/285 [00:57<07:26,  1.77s/it]predicting train subjects:  12%|█▏        | 34/285 [00:58<07:21,  1.76s/it]predicting train subjects:  12%|█▏        | 35/285 [01:00<07:30,  1.80s/it]predicting train subjects:  13%|█▎        | 36/285 [01:02<07:05,  1.71s/it]predicting train subjects:  13%|█▎        | 37/285 [01:04<07:12,  1.74s/it]predicting train subjects:  13%|█▎        | 38/285 [01:05<07:23,  1.80s/it]predicting train subjects:  14%|█▎        | 39/285 [01:07<07:06,  1.73s/it]predicting train subjects:  14%|█▍        | 40/285 [01:09<07:09,  1.75s/it]predicting train subjects:  14%|█▍        | 41/285 [01:10<06:52,  1.69s/it]predicting train subjects:  15%|█▍        | 42/285 [01:12<06:40,  1.65s/it]predicting train subjects:  15%|█▌        | 43/285 [01:14<06:52,  1.70s/it]predicting train subjects:  15%|█▌        | 44/285 [01:16<07:17,  1.82s/it]predicting train subjects:  16%|█▌        | 45/285 [01:17<06:57,  1.74s/it]predicting train subjects:  16%|█▌        | 46/285 [01:19<07:09,  1.80s/it]predicting train subjects:  16%|█▋        | 47/285 [01:21<06:47,  1.71s/it]predicting train subjects:  17%|█▋        | 48/285 [01:23<06:51,  1.74s/it]predicting train subjects:  17%|█▋        | 49/285 [01:25<07:05,  1.80s/it]predicting train subjects:  18%|█▊        | 50/285 [01:26<07:03,  1.80s/it]predicting train subjects:  18%|█▊        | 51/285 [01:28<07:17,  1.87s/it]predicting train subjects:  18%|█▊        | 52/285 [01:30<06:55,  1.78s/it]predicting train subjects:  19%|█▊        | 53/285 [01:32<06:57,  1.80s/it]predicting train subjects:  19%|█▉        | 54/285 [01:34<07:04,  1.84s/it]predicting train subjects:  19%|█▉        | 55/285 [01:35<06:42,  1.75s/it]predicting train subjects:  20%|█▉        | 56/285 [01:37<06:47,  1.78s/it]predicting train subjects:  20%|██        | 57/285 [01:39<06:27,  1.70s/it]predicting train subjects:  20%|██        | 58/285 [01:41<06:36,  1.75s/it]predicting train subjects:  21%|██        | 59/285 [01:43<06:51,  1.82s/it]predicting train subjects:  21%|██        | 60/285 [01:45<07:00,  1.87s/it]predicting train subjects:  21%|██▏       | 61/285 [01:46<06:38,  1.78s/it]predicting train subjects:  22%|██▏       | 62/285 [01:48<06:41,  1.80s/it]predicting train subjects:  22%|██▏       | 63/285 [01:50<06:41,  1.81s/it]predicting train subjects:  22%|██▏       | 64/285 [01:51<06:29,  1.76s/it]predicting train subjects:  23%|██▎       | 65/285 [01:53<06:32,  1.79s/it]predicting train subjects:  23%|██▎       | 66/285 [01:55<06:31,  1.79s/it]predicting train subjects:  24%|██▎       | 67/285 [01:57<06:33,  1.81s/it]predicting train subjects:  24%|██▍       | 68/285 [01:59<06:23,  1.77s/it]predicting train subjects:  24%|██▍       | 69/285 [02:00<06:23,  1.77s/it]predicting train subjects:  25%|██▍       | 70/285 [02:02<06:24,  1.79s/it]predicting train subjects:  25%|██▍       | 71/285 [02:04<06:35,  1.85s/it]predicting train subjects:  25%|██▌       | 72/285 [02:06<06:17,  1.77s/it]predicting train subjects:  26%|██▌       | 73/285 [02:08<06:15,  1.77s/it]predicting train subjects:  26%|██▌       | 74/285 [02:09<06:12,  1.77s/it]predicting train subjects:  26%|██▋       | 75/285 [02:11<06:21,  1.82s/it]predicting train subjects:  27%|██▋       | 76/285 [02:13<06:18,  1.81s/it]predicting train subjects:  27%|██▋       | 77/285 [02:15<06:03,  1.75s/it]predicting train subjects:  27%|██▋       | 78/285 [02:16<05:54,  1.71s/it]predicting train subjects:  28%|██▊       | 79/285 [02:18<05:56,  1.73s/it]predicting train subjects:  28%|██▊       | 80/285 [02:20<05:56,  1.74s/it]predicting train subjects:  28%|██▊       | 81/285 [02:21<05:46,  1.70s/it]predicting train subjects:  29%|██▉       | 82/285 [02:23<05:47,  1.71s/it]predicting train subjects:  29%|██▉       | 83/285 [02:25<05:46,  1.71s/it]predicting train subjects:  29%|██▉       | 84/285 [02:27<05:46,  1.72s/it]predicting train subjects:  30%|██▉       | 85/285 [02:28<05:44,  1.72s/it]predicting train subjects:  30%|███       | 86/285 [02:30<05:49,  1.76s/it]predicting train subjects:  31%|███       | 87/285 [02:32<05:48,  1.76s/it]predicting train subjects:  31%|███       | 88/285 [02:34<05:35,  1.71s/it]predicting train subjects:  31%|███       | 89/285 [02:35<05:34,  1.70s/it]predicting train subjects:  32%|███▏      | 90/285 [02:37<05:37,  1.73s/it]predicting train subjects:  32%|███▏      | 91/285 [02:39<05:29,  1.70s/it]predicting train subjects:  32%|███▏      | 92/285 [02:40<05:36,  1.75s/it]predicting train subjects:  33%|███▎      | 93/285 [02:42<05:29,  1.72s/it]predicting train subjects:  33%|███▎      | 94/285 [02:44<05:29,  1.73s/it]predicting train subjects:  33%|███▎      | 95/285 [02:46<05:36,  1.77s/it]predicting train subjects:  34%|███▎      | 96/285 [02:47<05:32,  1.76s/it]predicting train subjects:  34%|███▍      | 97/285 [02:49<05:34,  1.78s/it]predicting train subjects:  34%|███▍      | 98/285 [02:51<05:30,  1.77s/it]predicting train subjects:  35%|███▍      | 99/285 [02:53<05:26,  1.75s/it]predicting train subjects:  35%|███▌      | 100/285 [02:55<05:28,  1.78s/it]predicting train subjects:  35%|███▌      | 101/285 [02:56<05:15,  1.71s/it]predicting train subjects:  36%|███▌      | 102/285 [02:58<05:18,  1.74s/it]predicting train subjects:  36%|███▌      | 103/285 [03:00<05:07,  1.69s/it]predicting train subjects:  36%|███▋      | 104/285 [03:01<05:09,  1.71s/it]predicting train subjects:  37%|███▋      | 105/285 [03:03<05:18,  1.77s/it]predicting train subjects:  37%|███▋      | 106/285 [03:05<05:06,  1.71s/it]predicting train subjects:  38%|███▊      | 107/285 [03:07<05:08,  1.74s/it]predicting train subjects:  38%|███▊      | 108/285 [03:08<05:00,  1.70s/it]predicting train subjects:  38%|███▊      | 109/285 [03:10<05:04,  1.73s/it]predicting train subjects:  39%|███▊      | 110/285 [03:12<05:07,  1.75s/it]predicting train subjects:  39%|███▉      | 111/285 [03:13<04:56,  1.71s/it]predicting train subjects:  39%|███▉      | 112/285 [03:15<04:56,  1.71s/it]predicting train subjects:  40%|███▉      | 113/285 [03:17<05:00,  1.74s/it]predicting train subjects:  40%|████      | 114/285 [03:19<04:57,  1.74s/it]predicting train subjects:  40%|████      | 115/285 [03:21<05:00,  1.77s/it]predicting train subjects:  41%|████      | 116/285 [03:22<05:02,  1.79s/it]predicting train subjects:  41%|████      | 117/285 [03:24<04:51,  1.73s/it]predicting train subjects:  41%|████▏     | 118/285 [03:26<04:44,  1.70s/it]predicting train subjects:  42%|████▏     | 119/285 [03:27<04:48,  1.74s/it]predicting train subjects:  42%|████▏     | 120/285 [03:29<04:39,  1.70s/it]predicting train subjects:  42%|████▏     | 121/285 [03:31<04:36,  1.68s/it]predicting train subjects:  43%|████▎     | 122/285 [03:32<04:25,  1.63s/it]predicting train subjects:  43%|████▎     | 123/285 [03:34<04:13,  1.57s/it]predicting train subjects:  44%|████▎     | 124/285 [03:35<04:10,  1.55s/it]predicting train subjects:  44%|████▍     | 125/285 [03:37<04:08,  1.55s/it]predicting train subjects:  44%|████▍     | 126/285 [03:38<04:00,  1.52s/it]predicting train subjects:  45%|████▍     | 127/285 [03:40<03:56,  1.50s/it]predicting train subjects:  45%|████▍     | 128/285 [03:41<04:00,  1.53s/it]predicting train subjects:  45%|████▌     | 129/285 [03:43<03:52,  1.49s/it]predicting train subjects:  46%|████▌     | 130/285 [03:44<03:50,  1.48s/it]predicting train subjects:  46%|████▌     | 131/285 [03:45<03:46,  1.47s/it]predicting train subjects:  46%|████▋     | 132/285 [03:47<03:48,  1.49s/it]predicting train subjects:  47%|████▋     | 133/285 [03:48<03:42,  1.47s/it]predicting train subjects:  47%|████▋     | 134/285 [03:50<03:39,  1.45s/it]predicting train subjects:  47%|████▋     | 135/285 [03:51<03:35,  1.43s/it]predicting train subjects:  48%|████▊     | 136/285 [03:53<03:31,  1.42s/it]predicting train subjects:  48%|████▊     | 137/285 [03:54<03:38,  1.48s/it]predicting train subjects:  48%|████▊     | 138/285 [03:56<03:34,  1.46s/it]predicting train subjects:  49%|████▉     | 139/285 [03:57<03:36,  1.49s/it]predicting train subjects:  49%|████▉     | 140/285 [03:59<03:46,  1.56s/it]predicting train subjects:  49%|████▉     | 141/285 [04:00<03:39,  1.53s/it]predicting train subjects:  50%|████▉     | 142/285 [04:02<03:36,  1.51s/it]predicting train subjects:  50%|█████     | 143/285 [04:03<03:29,  1.47s/it]predicting train subjects:  51%|█████     | 144/285 [04:05<03:34,  1.52s/it]predicting train subjects:  51%|█████     | 145/285 [04:06<03:28,  1.49s/it]predicting train subjects:  51%|█████     | 146/285 [04:08<03:30,  1.52s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:09<03:24,  1.48s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:11<03:26,  1.51s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:12<03:23,  1.50s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:14<03:18,  1.47s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:15<03:20,  1.50s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:17<03:15,  1.47s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:18<03:12,  1.46s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:20<03:17,  1.51s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:21<03:13,  1.49s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:23<03:18,  1.54s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:24<03:12,  1.51s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:26<03:09,  1.49s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:27<03:05,  1.47s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:29<03:03,  1.47s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:30<03:04,  1.49s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:32<03:00,  1.46s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:33<03:02,  1.50s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:35<02:58,  1.48s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:36<02:56,  1.47s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:38<03:00,  1.51s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:39<03:00,  1.53s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:41<02:56,  1.51s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:42<02:54,  1.51s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:44<02:48,  1.47s/it]predicting train subjects:  60%|██████    | 171/285 [04:45<02:45,  1.45s/it]predicting train subjects:  60%|██████    | 172/285 [04:46<02:42,  1.44s/it]predicting train subjects:  61%|██████    | 173/285 [04:48<02:40,  1.43s/it]predicting train subjects:  61%|██████    | 174/285 [04:49<02:37,  1.42s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:51<02:45,  1.50s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:52<02:47,  1.53s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:54<02:41,  1.49s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:55<02:35,  1.45s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:57<02:33,  1.44s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:59<02:45,  1.57s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:00<02:44,  1.58s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:02<02:46,  1.62s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:03<02:35,  1.52s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:05<02:32,  1.51s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:06<02:26,  1.47s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:08<02:35,  1.57s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:10<02:42,  1.66s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:11<02:45,  1.71s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:13<02:33,  1.60s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:14<02:28,  1.56s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:16<02:29,  1.59s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:18<02:30,  1.62s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:19<02:19,  1.52s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:20<02:16,  1.50s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:22<02:11,  1.46s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:24<02:18,  1.56s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:25<02:23,  1.63s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:27<02:27,  1.70s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:29<02:17,  1.60s/it]predicting train subjects:  70%|███████   | 200/285 [05:30<02:10,  1.54s/it]predicting train subjects:  71%|███████   | 201/285 [05:32<02:15,  1.61s/it]predicting train subjects:  71%|███████   | 202/285 [05:33<02:14,  1.62s/it]predicting train subjects:  71%|███████   | 203/285 [05:35<02:11,  1.60s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:36<02:04,  1.53s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:38<02:00,  1.51s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:39<01:57,  1.49s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:41<02:04,  1.60s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:43<02:08,  1.66s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:45<02:09,  1.70s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:46<02:01,  1.62s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:48<01:58,  1.61s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:49<01:56,  1.60s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:51<01:55,  1.60s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:52<01:50,  1.55s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:54<01:53,  1.63s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:55<01:47,  1.55s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:57<01:50,  1.63s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:59<01:53,  1.69s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:01<01:52,  1.71s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:02<01:44,  1.61s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:04<01:40,  1.56s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:05<01:40,  1.60s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:07<01:35,  1.53s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:08<01:32,  1.51s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:10<01:28,  1.48s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:12<01:35,  1.62s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:13<01:39,  1.71s/it]predicting train subjects:  80%|████████  | 228/285 [06:15<01:38,  1.73s/it]predicting train subjects:  80%|████████  | 229/285 [06:17<01:36,  1.73s/it]predicting train subjects:  81%|████████  | 230/285 [06:18<01:29,  1.63s/it]predicting train subjects:  81%|████████  | 231/285 [06:20<01:28,  1.63s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:22<01:27,  1.65s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:23<01:22,  1.58s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:25<01:23,  1.64s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:26<01:18,  1.58s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:28<01:21,  1.66s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:30<01:21,  1.70s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:32<01:20,  1.71s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:33<01:16,  1.67s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:35<01:11,  1.59s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:36<01:07,  1.54s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:38<01:05,  1.52s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:39<01:01,  1.45s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:41<01:04,  1.57s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:42<00:59,  1.49s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:44<01:01,  1.59s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:46<01:01,  1.63s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:47<01:00,  1.63s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:49<00:55,  1.54s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:50<00:52,  1.51s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:51<00:49,  1.44s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:53<00:46,  1.41s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:54<00:49,  1.54s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:56<00:49,  1.60s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:58<00:47,  1.59s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:59<00:43,  1.50s/it]predicting train subjects:  90%|█████████ | 257/285 [07:00<00:41,  1.47s/it]predicting train subjects:  91%|█████████ | 258/285 [07:02<00:42,  1.56s/it]predicting train subjects:  91%|█████████ | 259/285 [07:04<00:41,  1.58s/it]predicting train subjects:  91%|█████████ | 260/285 [07:05<00:37,  1.52s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:07<00:35,  1.49s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:08<00:33,  1.45s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:09<00:31,  1.41s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:11<00:31,  1.52s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:13<00:32,  1.62s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:14<00:29,  1.54s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:16<00:27,  1.51s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:17<00:26,  1.57s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:19<00:25,  1.59s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:20<00:22,  1.52s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:22<00:21,  1.51s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:24<00:20,  1.58s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:25<00:18,  1.54s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:27<00:16,  1.49s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:28<00:15,  1.59s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:30<00:14,  1.65s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:31<00:12,  1.55s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:33<00:10,  1.50s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:34<00:09,  1.53s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:36<00:07,  1.47s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:37<00:05,  1.44s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:38<00:04,  1.41s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:40<00:03,  1.52s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:42<00:01,  1.60s/it]predicting train subjects: 100%|██████████| 285/285 [07:44<00:00,  1.66s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:23,  1.77s/it]Loading train:   1%|          | 2/285 [00:03<07:46,  1.65s/it]Loading train:   1%|          | 3/285 [00:04<07:34,  1.61s/it]Loading train:   1%|▏         | 4/285 [00:05<07:01,  1.50s/it]Loading train:   2%|▏         | 5/285 [00:07<07:14,  1.55s/it]Loading train:   2%|▏         | 6/285 [00:08<06:59,  1.50s/it]Loading train:   2%|▏         | 7/285 [00:10<07:10,  1.55s/it]Loading train:   3%|▎         | 8/285 [00:12<07:04,  1.53s/it]Loading train:   3%|▎         | 9/285 [00:13<07:27,  1.62s/it]Loading train:   4%|▎         | 10/285 [00:15<07:01,  1.53s/it]Loading train:   4%|▍         | 11/285 [00:16<06:18,  1.38s/it]Loading train:   4%|▍         | 12/285 [00:17<05:59,  1.32s/it]Loading train:   5%|▍         | 13/285 [00:18<05:38,  1.25s/it]Loading train:   5%|▍         | 14/285 [00:19<05:25,  1.20s/it]Loading train:   5%|▌         | 15/285 [00:20<05:22,  1.20s/it]Loading train:   6%|▌         | 16/285 [00:22<05:29,  1.22s/it]Loading train:   6%|▌         | 17/285 [00:23<05:13,  1.17s/it]Loading train:   6%|▋         | 18/285 [00:24<05:17,  1.19s/it]Loading train:   7%|▋         | 19/285 [00:25<05:13,  1.18s/it]Loading train:   7%|▋         | 20/285 [00:26<05:04,  1.15s/it]Loading train:   7%|▋         | 21/285 [00:27<05:17,  1.20s/it]Loading train:   8%|▊         | 22/285 [00:28<05:02,  1.15s/it]Loading train:   8%|▊         | 23/285 [00:30<05:03,  1.16s/it]Loading train:   8%|▊         | 24/285 [00:31<04:49,  1.11s/it]Loading train:   9%|▉         | 25/285 [00:32<05:00,  1.16s/it]Loading train:   9%|▉         | 26/285 [00:33<05:12,  1.21s/it]Loading train:   9%|▉         | 27/285 [00:34<04:51,  1.13s/it]Loading train:  10%|▉         | 28/285 [00:35<04:52,  1.14s/it]Loading train:  10%|█         | 29/285 [00:36<04:44,  1.11s/it]Loading train:  11%|█         | 30/285 [00:38<04:56,  1.16s/it]Loading train:  11%|█         | 31/285 [00:39<05:03,  1.19s/it]Loading train:  11%|█         | 32/285 [00:40<04:48,  1.14s/it]Loading train:  12%|█▏        | 33/285 [00:41<04:56,  1.18s/it]Loading train:  12%|█▏        | 34/285 [00:42<04:47,  1.15s/it]Loading train:  12%|█▏        | 35/285 [00:44<05:11,  1.25s/it]Loading train:  13%|█▎        | 36/285 [00:45<04:55,  1.19s/it]Loading train:  13%|█▎        | 37/285 [00:46<04:51,  1.17s/it]Loading train:  13%|█▎        | 38/285 [00:47<04:57,  1.21s/it]Loading train:  14%|█▎        | 39/285 [00:48<04:27,  1.09s/it]Loading train:  14%|█▍        | 40/285 [00:49<04:27,  1.09s/it]Loading train:  14%|█▍        | 41/285 [00:50<04:19,  1.06s/it]Loading train:  15%|█▍        | 42/285 [00:51<04:08,  1.02s/it]Loading train:  15%|█▌        | 43/285 [00:52<04:17,  1.06s/it]Loading train:  15%|█▌        | 44/285 [00:53<04:25,  1.10s/it]Loading train:  16%|█▌        | 45/285 [00:55<04:21,  1.09s/it]Loading train:  16%|█▌        | 46/285 [00:56<04:27,  1.12s/it]Loading train:  16%|█▋        | 47/285 [00:57<04:28,  1.13s/it]Loading train:  17%|█▋        | 48/285 [00:58<04:29,  1.14s/it]Loading train:  17%|█▋        | 49/285 [00:59<04:36,  1.17s/it]Loading train:  18%|█▊        | 50/285 [01:00<04:23,  1.12s/it]Loading train:  18%|█▊        | 51/285 [01:02<04:56,  1.27s/it]Loading train:  18%|█▊        | 52/285 [01:03<04:43,  1.21s/it]Loading train:  19%|█▊        | 53/285 [01:04<04:38,  1.20s/it]Loading train:  19%|█▉        | 54/285 [01:05<04:38,  1.21s/it]Loading train:  19%|█▉        | 55/285 [01:06<04:20,  1.13s/it]Loading train:  20%|█▉        | 56/285 [01:07<04:10,  1.09s/it]Loading train:  20%|██        | 57/285 [01:08<04:10,  1.10s/it]Loading train:  20%|██        | 58/285 [01:09<04:03,  1.07s/it]Loading train:  21%|██        | 59/285 [01:11<04:26,  1.18s/it]Loading train:  21%|██        | 60/285 [01:12<04:34,  1.22s/it]Loading train:  21%|██▏       | 61/285 [01:13<04:20,  1.16s/it]Loading train:  22%|██▏       | 62/285 [01:15<04:30,  1.21s/it]Loading train:  22%|██▏       | 63/285 [01:16<04:18,  1.17s/it]Loading train:  22%|██▏       | 64/285 [01:17<04:37,  1.26s/it]Loading train:  23%|██▎       | 65/285 [01:19<05:05,  1.39s/it]Loading train:  23%|██▎       | 66/285 [01:20<05:03,  1.39s/it]Loading train:  24%|██▎       | 67/285 [01:21<04:48,  1.32s/it]Loading train:  24%|██▍       | 68/285 [01:22<04:23,  1.21s/it]Loading train:  24%|██▍       | 69/285 [01:23<04:11,  1.16s/it]Loading train:  25%|██▍       | 70/285 [01:24<04:06,  1.15s/it]Loading train:  25%|██▍       | 71/285 [01:25<03:58,  1.11s/it]Loading train:  25%|██▌       | 72/285 [01:26<03:43,  1.05s/it]Loading train:  26%|██▌       | 73/285 [01:27<03:39,  1.04s/it]Loading train:  26%|██▌       | 74/285 [01:28<03:36,  1.03s/it]Loading train:  26%|██▋       | 75/285 [01:29<03:35,  1.02s/it]Loading train:  27%|██▋       | 76/285 [01:30<03:29,  1.00s/it]Loading train:  27%|██▋       | 77/285 [01:31<03:30,  1.01s/it]Loading train:  27%|██▋       | 78/285 [01:32<03:21,  1.03it/s]Loading train:  28%|██▊       | 79/285 [01:33<03:18,  1.04it/s]Loading train:  28%|██▊       | 80/285 [01:34<03:19,  1.03it/s]Loading train:  28%|██▊       | 81/285 [01:35<03:14,  1.05it/s]Loading train:  29%|██▉       | 82/285 [01:36<03:18,  1.02it/s]Loading train:  29%|██▉       | 83/285 [01:37<03:34,  1.06s/it]Loading train:  29%|██▉       | 84/285 [01:39<03:40,  1.10s/it]Loading train:  30%|██▉       | 85/285 [01:40<03:51,  1.16s/it]Loading train:  30%|███       | 86/285 [01:41<04:12,  1.27s/it]Loading train:  31%|███       | 87/285 [01:43<04:08,  1.26s/it]Loading train:  31%|███       | 88/285 [01:44<04:07,  1.26s/it]Loading train:  31%|███       | 89/285 [01:45<04:06,  1.26s/it]Loading train:  32%|███▏      | 90/285 [01:47<04:15,  1.31s/it]Loading train:  32%|███▏      | 91/285 [01:48<04:17,  1.33s/it]Loading train:  32%|███▏      | 92/285 [01:49<04:14,  1.32s/it]Loading train:  33%|███▎      | 93/285 [01:50<04:01,  1.26s/it]Loading train:  33%|███▎      | 94/285 [01:52<03:59,  1.25s/it]Loading train:  33%|███▎      | 95/285 [01:53<04:01,  1.27s/it]Loading train:  34%|███▎      | 96/285 [01:54<04:03,  1.29s/it]Loading train:  34%|███▍      | 97/285 [01:56<04:22,  1.40s/it]Loading train:  34%|███▍      | 98/285 [01:57<04:11,  1.35s/it]Loading train:  35%|███▍      | 99/285 [01:59<04:31,  1.46s/it]Loading train:  35%|███▌      | 100/285 [02:00<04:27,  1.45s/it]Loading train:  35%|███▌      | 101/285 [02:01<04:12,  1.37s/it]Loading train:  36%|███▌      | 102/285 [02:03<04:11,  1.38s/it]Loading train:  36%|███▌      | 103/285 [02:04<04:13,  1.39s/it]Loading train:  36%|███▋      | 104/285 [02:06<04:07,  1.37s/it]Loading train:  37%|███▋      | 105/285 [02:07<04:02,  1.35s/it]Loading train:  37%|███▋      | 106/285 [02:08<04:04,  1.37s/it]Loading train:  38%|███▊      | 107/285 [02:10<04:19,  1.46s/it]Loading train:  38%|███▊      | 108/285 [02:11<04:10,  1.41s/it]Loading train:  38%|███▊      | 109/285 [02:13<04:06,  1.40s/it]Loading train:  39%|███▊      | 110/285 [02:14<04:03,  1.39s/it]Loading train:  39%|███▉      | 111/285 [02:15<04:05,  1.41s/it]Loading train:  39%|███▉      | 112/285 [02:17<03:56,  1.37s/it]Loading train:  40%|███▉      | 113/285 [02:18<04:03,  1.41s/it]Loading train:  40%|████      | 114/285 [02:20<04:06,  1.44s/it]Loading train:  40%|████      | 115/285 [02:21<04:04,  1.44s/it]Loading train:  41%|████      | 116/285 [02:23<04:02,  1.44s/it]Loading train:  41%|████      | 117/285 [02:24<03:51,  1.38s/it]Loading train:  41%|████▏     | 118/285 [02:25<03:43,  1.34s/it]Loading train:  42%|████▏     | 119/285 [02:27<03:55,  1.42s/it]Loading train:  42%|████▏     | 120/285 [02:28<03:44,  1.36s/it]Loading train:  42%|████▏     | 121/285 [02:30<03:54,  1.43s/it]Loading train:  43%|████▎     | 122/285 [02:31<03:56,  1.45s/it]Loading train:  43%|████▎     | 123/285 [02:33<04:01,  1.49s/it]Loading train:  44%|████▎     | 124/285 [02:34<04:00,  1.49s/it]Loading train:  44%|████▍     | 125/285 [02:36<03:54,  1.47s/it]Loading train:  44%|████▍     | 126/285 [02:37<03:48,  1.44s/it]Loading train:  45%|████▍     | 127/285 [02:38<03:44,  1.42s/it]Loading train:  45%|████▍     | 128/285 [02:40<03:36,  1.38s/it]Loading train:  45%|████▌     | 129/285 [02:41<03:22,  1.30s/it]Loading train:  46%|████▌     | 130/285 [02:42<03:11,  1.24s/it]Loading train:  46%|████▌     | 131/285 [02:43<03:10,  1.24s/it]Loading train:  46%|████▋     | 132/285 [02:44<03:06,  1.22s/it]Loading train:  47%|████▋     | 133/285 [02:45<02:58,  1.18s/it]Loading train:  47%|████▋     | 134/285 [02:46<02:59,  1.19s/it]Loading train:  47%|████▋     | 135/285 [02:48<02:56,  1.18s/it]Loading train:  48%|████▊     | 136/285 [02:49<02:49,  1.14s/it]Loading train:  48%|████▊     | 137/285 [02:50<02:51,  1.16s/it]Loading train:  48%|████▊     | 138/285 [02:51<02:48,  1.14s/it]Loading train:  49%|████▉     | 139/285 [02:52<02:58,  1.22s/it]Loading train:  49%|████▉     | 140/285 [02:53<02:48,  1.16s/it]Loading train:  49%|████▉     | 141/285 [02:55<02:44,  1.14s/it]Loading train:  50%|████▉     | 142/285 [02:56<02:38,  1.11s/it]Loading train:  50%|█████     | 143/285 [02:57<02:43,  1.15s/it]Loading train:  51%|█████     | 144/285 [02:58<02:35,  1.10s/it]Loading train:  51%|█████     | 145/285 [02:59<02:36,  1.12s/it]Loading train:  51%|█████     | 146/285 [03:00<02:34,  1.11s/it]Loading train:  52%|█████▏    | 147/285 [03:01<02:31,  1.10s/it]Loading train:  52%|█████▏    | 148/285 [03:02<02:32,  1.11s/it]Loading train:  52%|█████▏    | 149/285 [03:03<02:31,  1.11s/it]Loading train:  53%|█████▎    | 150/285 [03:05<02:32,  1.13s/it]Loading train:  53%|█████▎    | 151/285 [03:06<02:43,  1.22s/it]Loading train:  53%|█████▎    | 152/285 [03:07<02:33,  1.16s/it]Loading train:  54%|█████▎    | 153/285 [03:08<02:33,  1.16s/it]Loading train:  54%|█████▍    | 154/285 [03:09<02:34,  1.18s/it]Loading train:  54%|█████▍    | 155/285 [03:11<02:31,  1.17s/it]Loading train:  55%|█████▍    | 156/285 [03:12<02:27,  1.15s/it]Loading train:  55%|█████▌    | 157/285 [03:13<02:20,  1.09s/it]Loading train:  55%|█████▌    | 158/285 [03:14<02:26,  1.15s/it]Loading train:  56%|█████▌    | 159/285 [03:15<02:19,  1.11s/it]Loading train:  56%|█████▌    | 160/285 [03:16<02:25,  1.16s/it]Loading train:  56%|█████▋    | 161/285 [03:17<02:25,  1.17s/it]Loading train:  57%|█████▋    | 162/285 [03:18<02:20,  1.15s/it]Loading train:  57%|█████▋    | 163/285 [03:20<02:23,  1.17s/it]Loading train:  58%|█████▊    | 164/285 [03:21<02:25,  1.20s/it]Loading train:  58%|█████▊    | 165/285 [03:22<02:21,  1.18s/it]Loading train:  58%|█████▊    | 166/285 [03:24<02:32,  1.28s/it]Loading train:  59%|█████▊    | 167/285 [03:25<02:24,  1.22s/it]Loading train:  59%|█████▉    | 168/285 [03:26<02:16,  1.17s/it]Loading train:  59%|█████▉    | 169/285 [03:27<02:16,  1.18s/it]Loading train:  60%|█████▉    | 170/285 [03:28<02:15,  1.18s/it]Loading train:  60%|██████    | 171/285 [03:29<02:13,  1.17s/it]Loading train:  60%|██████    | 172/285 [03:30<02:12,  1.17s/it]Loading train:  61%|██████    | 173/285 [03:31<02:06,  1.13s/it]Loading train:  61%|██████    | 174/285 [03:32<01:59,  1.08s/it]Loading train:  61%|██████▏   | 175/285 [03:34<02:02,  1.11s/it]Loading train:  62%|██████▏   | 176/285 [03:35<02:01,  1.11s/it]Loading train:  62%|██████▏   | 177/285 [03:36<02:00,  1.11s/it]Loading train:  62%|██████▏   | 178/285 [03:37<01:58,  1.11s/it]Loading train:  63%|██████▎   | 179/285 [03:38<01:57,  1.11s/it]Loading train:  63%|██████▎   | 180/285 [03:39<02:05,  1.20s/it]Loading train:  64%|██████▎   | 181/285 [03:41<02:06,  1.22s/it]Loading train:  64%|██████▍   | 182/285 [03:42<02:05,  1.22s/it]Loading train:  64%|██████▍   | 183/285 [03:43<02:01,  1.19s/it]Loading train:  65%|██████▍   | 184/285 [03:44<01:58,  1.17s/it]Loading train:  65%|██████▍   | 185/285 [03:45<01:55,  1.15s/it]Loading train:  65%|██████▌   | 186/285 [03:47<02:01,  1.23s/it]Loading train:  66%|██████▌   | 187/285 [03:48<02:08,  1.31s/it]Loading train:  66%|██████▌   | 188/285 [03:49<02:04,  1.28s/it]Loading train:  66%|██████▋   | 189/285 [03:51<02:01,  1.26s/it]Loading train:  67%|██████▋   | 190/285 [03:52<01:56,  1.23s/it]Loading train:  67%|██████▋   | 191/285 [03:53<01:50,  1.18s/it]Loading train:  67%|██████▋   | 192/285 [03:54<01:48,  1.16s/it]Loading train:  68%|██████▊   | 193/285 [03:55<01:49,  1.19s/it]Loading train:  68%|██████▊   | 194/285 [03:56<01:43,  1.13s/it]Loading train:  68%|██████▊   | 195/285 [03:57<01:40,  1.12s/it]Loading train:  69%|██████▉   | 196/285 [03:59<01:44,  1.17s/it]Loading train:  69%|██████▉   | 197/285 [04:00<01:45,  1.20s/it]Loading train:  69%|██████▉   | 198/285 [04:01<01:47,  1.24s/it]Loading train:  70%|██████▉   | 199/285 [04:02<01:41,  1.18s/it]Loading train:  70%|███████   | 200/285 [04:03<01:37,  1.15s/it]Loading train:  71%|███████   | 201/285 [04:05<01:40,  1.19s/it]Loading train:  71%|███████   | 202/285 [04:06<01:36,  1.16s/it]Loading train:  71%|███████   | 203/285 [04:07<01:38,  1.20s/it]Loading train:  72%|███████▏  | 204/285 [04:08<01:35,  1.18s/it]Loading train:  72%|███████▏  | 205/285 [04:09<01:32,  1.16s/it]Loading train:  72%|███████▏  | 206/285 [04:10<01:28,  1.12s/it]Loading train:  73%|███████▎  | 207/285 [04:12<01:36,  1.24s/it]Loading train:  73%|███████▎  | 208/285 [04:13<01:36,  1.26s/it]Loading train:  73%|███████▎  | 209/285 [04:14<01:34,  1.25s/it]Loading train:  74%|███████▎  | 210/285 [04:15<01:31,  1.22s/it]Loading train:  74%|███████▍  | 211/285 [04:17<01:30,  1.23s/it]Loading train:  74%|███████▍  | 212/285 [04:18<01:33,  1.28s/it]Loading train:  75%|███████▍  | 213/285 [04:19<01:28,  1.23s/it]Loading train:  75%|███████▌  | 214/285 [04:20<01:27,  1.23s/it]Loading train:  75%|███████▌  | 215/285 [04:22<01:29,  1.28s/it]Loading train:  76%|███████▌  | 216/285 [04:23<01:25,  1.23s/it]Loading train:  76%|███████▌  | 217/285 [04:24<01:25,  1.26s/it]Loading train:  76%|███████▋  | 218/285 [04:26<01:32,  1.38s/it]Loading train:  77%|███████▋  | 219/285 [04:27<01:26,  1.31s/it]Loading train:  77%|███████▋  | 220/285 [04:28<01:18,  1.21s/it]Loading train:  78%|███████▊  | 221/285 [04:29<01:18,  1.22s/it]Loading train:  78%|███████▊  | 222/285 [04:31<01:17,  1.23s/it]Loading train:  78%|███████▊  | 223/285 [04:32<01:12,  1.17s/it]Loading train:  79%|███████▊  | 224/285 [04:33<01:07,  1.10s/it]Loading train:  79%|███████▉  | 225/285 [04:33<01:01,  1.03s/it]Loading train:  79%|███████▉  | 226/285 [04:35<01:05,  1.10s/it]Loading train:  80%|███████▉  | 227/285 [04:36<01:06,  1.15s/it]Loading train:  80%|████████  | 228/285 [04:37<01:06,  1.16s/it]Loading train:  80%|████████  | 229/285 [04:39<01:11,  1.27s/it]Loading train:  81%|████████  | 230/285 [04:40<01:09,  1.27s/it]Loading train:  81%|████████  | 231/285 [04:41<01:05,  1.22s/it]Loading train:  81%|████████▏ | 232/285 [04:42<01:01,  1.17s/it]Loading train:  82%|████████▏ | 233/285 [04:43<01:01,  1.18s/it]Loading train:  82%|████████▏ | 234/285 [04:45<01:01,  1.22s/it]Loading train:  82%|████████▏ | 235/285 [04:46<00:58,  1.17s/it]Loading train:  83%|████████▎ | 236/285 [04:47<00:59,  1.21s/it]Loading train:  83%|████████▎ | 237/285 [04:49<01:06,  1.38s/it]Loading train:  84%|████████▎ | 238/285 [04:50<01:09,  1.47s/it]Loading train:  84%|████████▍ | 239/285 [04:52<01:05,  1.43s/it]Loading train:  84%|████████▍ | 240/285 [04:53<00:59,  1.32s/it]Loading train:  85%|████████▍ | 241/285 [04:54<00:56,  1.27s/it]Loading train:  85%|████████▍ | 242/285 [04:55<00:54,  1.27s/it]Loading train:  85%|████████▌ | 243/285 [04:56<00:51,  1.21s/it]Loading train:  86%|████████▌ | 244/285 [04:58<00:51,  1.27s/it]Loading train:  86%|████████▌ | 245/285 [04:59<00:47,  1.20s/it]Loading train:  86%|████████▋ | 246/285 [05:00<00:47,  1.21s/it]Loading train:  87%|████████▋ | 247/285 [05:01<00:46,  1.23s/it]Loading train:  87%|████████▋ | 248/285 [05:02<00:44,  1.19s/it]Loading train:  87%|████████▋ | 249/285 [05:03<00:41,  1.15s/it]Loading train:  88%|████████▊ | 250/285 [05:04<00:37,  1.07s/it]Loading train:  88%|████████▊ | 251/285 [05:05<00:36,  1.06s/it]Loading train:  88%|████████▊ | 252/285 [05:06<00:35,  1.07s/it]Loading train:  89%|████████▉ | 253/285 [05:08<00:37,  1.16s/it]Loading train:  89%|████████▉ | 254/285 [05:09<00:37,  1.22s/it]Loading train:  89%|████████▉ | 255/285 [05:10<00:36,  1.23s/it]Loading train:  90%|████████▉ | 256/285 [05:12<00:34,  1.19s/it]Loading train:  90%|█████████ | 257/285 [05:13<00:35,  1.25s/it]Loading train:  91%|█████████ | 258/285 [05:14<00:34,  1.28s/it]Loading train:  91%|█████████ | 259/285 [05:15<00:31,  1.22s/it]Loading train:  91%|█████████ | 260/285 [05:17<00:30,  1.23s/it]Loading train:  92%|█████████▏| 261/285 [05:18<00:29,  1.23s/it]Loading train:  92%|█████████▏| 262/285 [05:19<00:28,  1.24s/it]Loading train:  92%|█████████▏| 263/285 [05:20<00:27,  1.24s/it]Loading train:  93%|█████████▎| 264/285 [05:22<00:26,  1.28s/it]Loading train:  93%|█████████▎| 265/285 [05:23<00:25,  1.28s/it]Loading train:  93%|█████████▎| 266/285 [05:24<00:23,  1.23s/it]Loading train:  94%|█████████▎| 267/285 [05:25<00:20,  1.15s/it]Loading train:  94%|█████████▍| 268/285 [05:26<00:20,  1.18s/it]Loading train:  94%|█████████▍| 269/285 [05:28<00:19,  1.21s/it]Loading train:  95%|█████████▍| 270/285 [05:29<00:18,  1.21s/it]Loading train:  95%|█████████▌| 271/285 [05:30<00:15,  1.14s/it]Loading train:  95%|█████████▌| 272/285 [05:31<00:15,  1.20s/it]Loading train:  96%|█████████▌| 273/285 [05:32<00:14,  1.18s/it]Loading train:  96%|█████████▌| 274/285 [05:33<00:12,  1.17s/it]Loading train:  96%|█████████▋| 275/285 [05:35<00:14,  1.42s/it]Loading train:  97%|█████████▋| 276/285 [05:37<00:13,  1.45s/it]Loading train:  97%|█████████▋| 277/285 [05:38<00:11,  1.40s/it]Loading train:  98%|█████████▊| 278/285 [05:39<00:08,  1.28s/it]Loading train:  98%|█████████▊| 279/285 [05:40<00:07,  1.22s/it]Loading train:  98%|█████████▊| 280/285 [05:41<00:05,  1.18s/it]Loading train:  99%|█████████▊| 281/285 [05:43<00:04,  1.17s/it]Loading train:  99%|█████████▉| 282/285 [05:44<00:03,  1.20s/it]Loading train:  99%|█████████▉| 283/285 [05:45<00:02,  1.23s/it]Loading train: 100%|█████████▉| 284/285 [05:47<00:01,  1.32s/it]Loading train: 100%|██████████| 285/285 [05:48<00:00,  1.31s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:04, 62.48it/s]concatenating: train:   5%|▍         | 14/285 [00:00<00:04, 63.16it/s]concatenating: train:   7%|▋         | 21/285 [00:00<00:04, 64.24it/s]concatenating: train:  10%|▉         | 28/285 [00:00<00:03, 65.16it/s]concatenating: train:  13%|█▎        | 36/285 [00:00<00:03, 68.29it/s]concatenating: train:  16%|█▌        | 45/285 [00:00<00:03, 71.60it/s]concatenating: train:  19%|█▊        | 53/285 [00:00<00:03, 73.11it/s]concatenating: train:  21%|██▏       | 61/285 [00:00<00:03, 74.09it/s]concatenating: train:  25%|██▍       | 70/285 [00:00<00:02, 77.56it/s]concatenating: train:  28%|██▊       | 80/285 [00:01<00:02, 82.22it/s]concatenating: train:  32%|███▏      | 92/285 [00:01<00:02, 89.87it/s]concatenating: train:  36%|███▌      | 102/285 [00:01<00:02, 91.11it/s]concatenating: train:  39%|███▉      | 112/285 [00:01<00:01, 87.54it/s]concatenating: train:  44%|████▎     | 124/285 [00:01<00:01, 95.16it/s]concatenating: train:  47%|████▋     | 134/285 [00:01<00:01, 95.17it/s]concatenating: train:  51%|█████     | 144/285 [00:01<00:01, 89.69it/s]concatenating: train:  54%|█████▍    | 154/285 [00:01<00:01, 79.34it/s]concatenating: train:  57%|█████▋    | 163/285 [00:02<00:01, 73.41it/s]concatenating: train:  60%|██████    | 171/285 [00:02<00:01, 69.76it/s]concatenating: train:  63%|██████▎   | 179/285 [00:02<00:01, 68.80it/s]concatenating: train:  66%|██████▌   | 187/285 [00:02<00:01, 66.78it/s]concatenating: train:  68%|██████▊   | 195/285 [00:02<00:01, 70.18it/s]concatenating: train:  72%|███████▏  | 204/285 [00:02<00:01, 73.75it/s]concatenating: train:  74%|███████▍  | 212/285 [00:02<00:01, 66.04it/s]concatenating: train:  78%|███████▊  | 222/285 [00:02<00:00, 72.05it/s]concatenating: train:  82%|████████▏ | 233/285 [00:02<00:00, 78.98it/s]concatenating: train:  86%|████████▌ | 244/285 [00:03<00:00, 85.40it/s]concatenating: train:  90%|█████████ | 257/285 [00:03<00:00, 92.83it/s]concatenating: train:  94%|█████████▎| 267/285 [00:03<00:00, 84.31it/s]concatenating: train:  97%|█████████▋| 276/285 [00:03<00:00, 76.33it/s]concatenating: train: 100%|██████████| 285/285 [00:03<00:00, 79.07it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.54s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.51s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.43s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 52.26it/s]2019-07-09 13:25:28.937546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-09 13:25:28.937662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-09 13:25:28.937681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-09 13:25:28.937690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-09 13:25:28.938030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12743 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:10,  3.97it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:08,  4.89it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.01it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.49it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.83it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.59it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.98it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:02<00:05,  5.25it/s]loading the weights for Res Unet:  41%|████      | 18/44 [00:03<00:06,  4.00it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:03<00:04,  4.95it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:03<00:04,  5.08it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:03<00:02,  6.59it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  7.52it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  8.10it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:04<00:01,  6.96it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:04<00:01,  8.69it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:00,  9.26it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  9.52it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:06<00:00,  3.18it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:06<00:00,  6.72it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 40)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 41)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   7400        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 40)   21640       dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 52, 40)   160         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 52, 40)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 52, 40)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 52, 100)  0           dropout_6[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 52, 13)   1313        concatenate_8[0][0]              
==================================================================================================
Total params: 253,913
Trainable params: 79,073
Non-trainable params: 174,840
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 35s - loss: 8655.3974 - acc: 0.7905 - mDice: 0.2779 - val_loss: 5531.1397 - val_acc: 0.9312 - val_mDice: 0.4325

Epoch 00001: val_mDice improved from -inf to 0.43249, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 27s - loss: 2759.0800 - acc: 0.9221 - mDice: 0.5755 - val_loss: 2256.7970 - val_acc: 0.9521 - val_mDice: 0.6038

Epoch 00002: val_mDice improved from 0.43249 to 0.60382, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 28s - loss: 2214.4717 - acc: 0.9399 - mDice: 0.6399 - val_loss: 2144.9399 - val_acc: 0.9526 - val_mDice: 0.6185

Epoch 00003: val_mDice improved from 0.60382 to 0.61846, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 26s - loss: 2000.5717 - acc: 0.9458 - mDice: 0.6668 - val_loss: 3001.8313 - val_acc: 0.9470 - val_mDice: 0.5269

Epoch 00004: val_mDice did not improve from 0.61846
Epoch 5/300
 - 26s - loss: 1900.1470 - acc: 0.9476 - mDice: 0.6801 - val_loss: 2270.0865 - val_acc: 0.9527 - val_mDice: 0.6089

Epoch 00005: val_mDice did not improve from 0.61846
Epoch 6/300
 - 27s - loss: 1812.2429 - acc: 0.9491 - mDice: 0.6921 - val_loss: 2316.5042 - val_acc: 0.9528 - val_mDice: 0.6056

Epoch 00006: val_mDice did not improve from 0.61846
Epoch 7/300
 - 26s - loss: 1751.2506 - acc: 0.9499 - mDice: 0.7003 - val_loss: 2150.4202 - val_acc: 0.9515 - val_mDice: 0.6188

Epoch 00007: val_mDice improved from 0.61846 to 0.61877, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 26s - loss: 1696.7290 - acc: 0.9507 - mDice: 0.7081 - val_loss: 2308.9140 - val_acc: 0.9532 - val_mDice: 0.6115

Epoch 00008: val_mDice did not improve from 0.61877
Epoch 9/300
 - 27s - loss: 1650.1710 - acc: 0.9513 - mDice: 0.7146 - val_loss: 2292.1947 - val_acc: 0.9489 - val_mDice: 0.6018

Epoch 00009: val_mDice did not improve from 0.61877
Epoch 10/300
 - 26s - loss: 1621.9098 - acc: 0.9517 - mDice: 0.7186 - val_loss: 2295.1346 - val_acc: 0.9523 - val_mDice: 0.6069

Epoch 00010: val_mDice did not improve from 0.61877
Epoch 11/300
 - 27s - loss: 1581.3029 - acc: 0.9524 - mDice: 0.7246 - val_loss: 2114.0287 - val_acc: 0.9512 - val_mDice: 0.6259

Epoch 00011: val_mDice improved from 0.61877 to 0.62589, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 26s - loss: 1552.5718 - acc: 0.9527 - mDice: 0.7288 - val_loss: 2156.0739 - val_acc: 0.9522 - val_mDice: 0.6197

Epoch 00012: val_mDice did not improve from 0.62589
Epoch 13/300
 - 27s - loss: 1532.8256 - acc: 0.9531 - mDice: 0.7316 - val_loss: 2075.0798 - val_acc: 0.9529 - val_mDice: 0.6293

Epoch 00013: val_mDice improved from 0.62589 to 0.62932, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 27s - loss: 1507.8067 - acc: 0.9535 - mDice: 0.7354 - val_loss: 2279.8260 - val_acc: 0.9473 - val_mDice: 0.6046

Epoch 00014: val_mDice did not improve from 0.62932
Epoch 15/300
 - 27s - loss: 1486.4794 - acc: 0.9537 - mDice: 0.7385 - val_loss: 2206.6508 - val_acc: 0.9523 - val_mDice: 0.6141

Epoch 00015: val_mDice did not improve from 0.62932
Epoch 16/300
 - 25s - loss: 1470.0385 - acc: 0.9540 - mDice: 0.7410 - val_loss: 2320.7305 - val_acc: 0.9500 - val_mDice: 0.6067

Epoch 00016: val_mDice did not improve from 0.62932
Epoch 17/300
 - 26s - loss: 1450.0705 - acc: 0.9543 - mDice: 0.7438 - val_loss: 2098.8887 - val_acc: 0.9540 - val_mDice: 0.6284

Epoch 00017: val_mDice did not improve from 0.62932
Epoch 18/300
 - 26s - loss: 1431.8863 - acc: 0.9544 - mDice: 0.7465 - val_loss: 2236.8080 - val_acc: 0.9524 - val_mDice: 0.6117

Epoch 00018: val_mDice did not improve from 0.62932
Epoch 19/300
 - 26s - loss: 1411.7795 - acc: 0.9547 - mDice: 0.7495 - val_loss: 2208.9723 - val_acc: 0.9547 - val_mDice: 0.6129

Epoch 00019: val_mDice did not improve from 0.62932
Epoch 20/300
 - 27s - loss: 1402.2969 - acc: 0.9549 - mDice: 0.7511 - val_loss: 2383.6426 - val_acc: 0.9526 - val_mDice: 0.5970

Epoch 00020: val_mDice did not improve from 0.62932
Epoch 21/300
 - 27s - loss: 1381.0684 - acc: 0.9551 - mDice: 0.7541 - val_loss: 2233.6644 - val_acc: 0.9548 - val_mDice: 0.6118

Epoch 00021: val_mDice did not improve from 0.62932
Epoch 22/300
 - 26s - loss: 1388.4271 - acc: 0.9551 - mDice: 0.7531 - val_loss: 2138.3439 - val_acc: 0.9523 - val_mDice: 0.6234

Epoch 00022: val_mDice did not improve from 0.62932
Epoch 23/300
 - 26s - loss: 1368.1299 - acc: 0.9553 - mDice: 0.7562 - val_loss: 2146.6340 - val_acc: 0.9535 - val_mDice: 0.6216

Epoch 00023: val_mDice did not improve from 0.62932
Epoch 24/300
 - 26s - loss: 1350.7166 - acc: 0.9555 - mDice: 0.7588 - val_loss: 2226.3788 - val_acc: 0.9521 - val_mDice: 0.6125

Epoch 00024: val_mDice did not improve from 0.62932
Epoch 25/300
 - 26s - loss: 1343.9501 - acc: 0.9556 - mDice: 0.7598 - val_loss: 2211.3455 - val_acc: 0.9526 - val_mDice: 0.6149

Epoch 00025: val_mDice did not improve from 0.62932
Epoch 26/300
 - 27s - loss: 1335.1717 - acc: 0.9558 - mDice: 0.7612 - val_loss: 2297.8924 - val_acc: 0.9528 - val_mDice: 0.6062

Epoch 00026: val_mDice did not improve from 0.62932
Epoch 27/300
 - 27s - loss: 1319.5386 - acc: 0.9560 - mDice: 0.7635 - val_loss: 2217.4972 - val_acc: 0.9536 - val_mDice: 0.6181

Epoch 00027: val_mDice did not improve from 0.62932
Epoch 28/300
 - 27s - loss: 1318.8806 - acc: 0.9560 - mDice: 0.7636 - val_loss: 2094.5475 - val_acc: 0.9543 - val_mDice: 0.6286

Epoch 00028: val_mDice did not improve from 0.62932
Epoch 29/300
 - 26s - loss: 1304.4246 - acc: 0.9562 - mDice: 0.7659 - val_loss: 2170.6655 - val_acc: 0.9542 - val_mDice: 0.6234

Epoch 00029: val_mDice did not improve from 0.62932
Epoch 30/300
 - 26s - loss: 1301.1742 - acc: 0.9563 - mDice: 0.7665 - val_loss: 2300.1788 - val_acc: 0.9546 - val_mDice: 0.6074

Epoch 00030: val_mDice did not improve from 0.62932
Epoch 31/300
 - 27s - loss: 1293.0476 - acc: 0.9564 - mDice: 0.7677 - val_loss: 2130.0182 - val_acc: 0.9531 - val_mDice: 0.6266

Epoch 00031: val_mDice did not improve from 0.62932
Epoch 32/300
 - 25s - loss: 1284.1749 - acc: 0.9565 - mDice: 0.7691 - val_loss: 2248.7481 - val_acc: 0.9532 - val_mDice: 0.6138

Epoch 00032: val_mDice did not improve from 0.62932
Epoch 33/300
 - 27s - loss: 1290.3496 - acc: 0.9564 - mDice: 0.7681 - val_loss: 2340.4785 - val_acc: 0.9519 - val_mDice: 0.6065

Epoch 00033: val_mDice did not improve from 0.62932
Epoch 34/300
 - 26s - loss: 1274.4281 - acc: 0.9566 - mDice: 0.7706 - val_loss: 2111.4962 - val_acc: 0.9548 - val_mDice: 0.6274

Epoch 00034: val_mDice did not improve from 0.62932
Epoch 35/300
 - 26s - loss: 1260.6812 - acc: 0.9567 - mDice: 0.7727 - val_loss: 2207.4770 - val_acc: 0.9544 - val_mDice: 0.6165

Epoch 00035: val_mDice did not improve from 0.62932
Epoch 36/300
 - 26s - loss: 1254.3911 - acc: 0.9569 - mDice: 0.7736 - val_loss: 2169.4254 - val_acc: 0.9524 - val_mDice: 0.6182

Epoch 00036: val_mDice did not improve from 0.62932
Epoch 37/300
 - 26s - loss: 1253.9280 - acc: 0.9568 - mDice: 0.7736 - val_loss: 2207.8330 - val_acc: 0.9540 - val_mDice: 0.6225

Epoch 00037: val_mDice did not improve from 0.62932
Epoch 38/300
 - 26s - loss: 1250.5685 - acc: 0.9569 - mDice: 0.7743 - val_loss: 2300.5257 - val_acc: 0.9540 - val_mDice: 0.6031

Epoch 00038: val_mDice did not improve from 0.62932
Epoch 39/300
 - 26s - loss: 1248.6817 - acc: 0.9569 - mDice: 0.7745 - val_loss: 2173.1340 - val_acc: 0.9534 - val_mDice: 0.6212

Epoch 00039: val_mDice did not improve from 0.62932
Epoch 40/300
 - 26s - loss: 1237.9326 - acc: 0.9571 - mDice: 0.7762 - val_loss: 2199.6351 - val_acc: 0.9548 - val_mDice: 0.6199

Epoch 00040: val_mDice did not improve from 0.62932
Epoch 41/300
 - 27s - loss: 1236.3512 - acc: 0.9571 - mDice: 0.7765 - val_loss: 2243.7406 - val_acc: 0.9547 - val_mDice: 0.6146

Epoch 00041: val_mDice did not improve from 0.62932
Epoch 42/300
 - 25s - loss: 1227.4883 - acc: 0.9572 - mDice: 0.7779 - val_loss: 2295.9055 - val_acc: 0.9519 - val_mDice: 0.6132

Epoch 00042: val_mDice did not improve from 0.62932
Epoch 43/300
 - 26s - loss: 1216.6080 - acc: 0.9573 - mDice: 0.7795 - val_loss: 2328.0782 - val_acc: 0.9549 - val_mDice: 0.6106

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:03<00:06,  3.41s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.85s/it]predicting test subjects: 100%|██████████| 3/3 [00:06<00:00,  2.43s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:43,  1.84s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:09,  1.73s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:10,  1.74s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:43,  1.65s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:07,  1.74s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:47,  1.67s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<08:05,  1.75s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<08:00,  1.74s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:38,  1.88s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:54,  1.94s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:29,  1.86s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:49,  1.94s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:19,  1.84s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<08:21,  1.85s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:32,  1.90s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<08:49,  1.97s/it]predicting train subjects:   6%|▌         | 17/285 [00:31<08:27,  1.89s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:24,  1.89s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<08:09,  1.84s/it]predicting train subjects:   7%|▋         | 20/285 [00:36<08:14,  1.86s/it]predicting train subjects:   7%|▋         | 21/285 [00:38<08:33,  1.95s/it]predicting train subjects:   8%|▊         | 22/285 [00:40<08:04,  1.84s/it]predicting train subjects:   8%|▊         | 23/285 [00:42<08:01,  1.84s/it]predicting train subjects:   8%|▊         | 24/285 [00:43<07:42,  1.77s/it]predicting train subjects:   9%|▉         | 25/285 [00:45<08:00,  1.85s/it]predicting train subjects:   9%|▉         | 26/285 [00:47<08:17,  1.92s/it]predicting train subjects:   9%|▉         | 27/285 [00:49<07:52,  1.83s/it]predicting train subjects:  10%|▉         | 28/285 [00:51<07:58,  1.86s/it]predicting train subjects:  10%|█         | 29/285 [00:53<08:02,  1.88s/it]predicting train subjects:  11%|█         | 30/285 [00:55<08:19,  1.96s/it]predicting train subjects:  11%|█         | 31/285 [00:57<08:25,  1.99s/it]predicting train subjects:  11%|█         | 32/285 [00:59<08:02,  1.91s/it]predicting train subjects:  12%|█▏        | 33/285 [01:01<08:00,  1.91s/it]predicting train subjects:  12%|█▏        | 34/285 [01:03<07:56,  1.90s/it]predicting train subjects:  12%|█▏        | 35/285 [01:05<08:18,  1.99s/it]predicting train subjects:  13%|█▎        | 36/285 [01:06<07:51,  1.89s/it]predicting train subjects:  13%|█▎        | 37/285 [01:08<07:46,  1.88s/it]predicting train subjects:  13%|█▎        | 38/285 [01:10<08:00,  1.95s/it]predicting train subjects:  14%|█▎        | 39/285 [01:12<07:34,  1.85s/it]predicting train subjects:  14%|█▍        | 40/285 [01:14<07:37,  1.87s/it]predicting train subjects:  14%|█▍        | 41/285 [01:16<07:24,  1.82s/it]predicting train subjects:  15%|█▍        | 42/285 [01:17<07:13,  1.78s/it]predicting train subjects:  15%|█▌        | 43/285 [01:19<07:19,  1.81s/it]predicting train subjects:  15%|█▌        | 44/285 [01:21<07:40,  1.91s/it]predicting train subjects:  16%|█▌        | 45/285 [01:23<07:16,  1.82s/it]predicting train subjects:  16%|█▌        | 46/285 [01:25<07:39,  1.92s/it]predicting train subjects:  16%|█▋        | 47/285 [01:27<07:27,  1.88s/it]predicting train subjects:  17%|█▋        | 48/285 [01:29<07:28,  1.89s/it]predicting train subjects:  17%|█▋        | 49/285 [01:31<07:42,  1.96s/it]predicting train subjects:  18%|█▊        | 50/285 [01:33<07:37,  1.95s/it]predicting train subjects:  18%|█▊        | 51/285 [01:35<07:49,  2.01s/it]predicting train subjects:  18%|█▊        | 52/285 [01:37<07:21,  1.89s/it]predicting train subjects:  19%|█▊        | 53/285 [01:39<07:18,  1.89s/it]predicting train subjects:  19%|█▉        | 54/285 [01:41<07:28,  1.94s/it]predicting train subjects:  19%|█▉        | 55/285 [01:42<07:11,  1.88s/it]predicting train subjects:  20%|█▉        | 56/285 [01:44<07:07,  1.86s/it]predicting train subjects:  20%|██        | 57/285 [01:46<06:58,  1.84s/it]predicting train subjects:  20%|██        | 58/285 [01:48<07:02,  1.86s/it]predicting train subjects:  21%|██        | 59/285 [01:50<07:23,  1.96s/it]predicting train subjects:  21%|██        | 60/285 [01:52<07:38,  2.04s/it]predicting train subjects:  21%|██▏       | 61/285 [01:54<07:16,  1.95s/it]predicting train subjects:  22%|██▏       | 62/285 [01:56<07:09,  1.93s/it]predicting train subjects:  22%|██▏       | 63/285 [01:58<07:04,  1.91s/it]predicting train subjects:  22%|██▏       | 64/285 [02:00<06:55,  1.88s/it]predicting train subjects:  23%|██▎       | 65/285 [02:02<07:00,  1.91s/it]predicting train subjects:  23%|██▎       | 66/285 [02:03<07:03,  1.93s/it]predicting train subjects:  24%|██▎       | 67/285 [02:05<07:01,  1.93s/it]predicting train subjects:  24%|██▍       | 68/285 [02:07<06:49,  1.89s/it]predicting train subjects:  24%|██▍       | 69/285 [02:09<06:49,  1.90s/it]predicting train subjects:  25%|██▍       | 70/285 [02:11<06:52,  1.92s/it]predicting train subjects:  25%|██▍       | 71/285 [02:13<06:53,  1.93s/it]predicting train subjects:  25%|██▌       | 72/285 [02:15<06:43,  1.89s/it]predicting train subjects:  26%|██▌       | 73/285 [02:17<06:42,  1.90s/it]predicting train subjects:  26%|██▌       | 74/285 [02:19<06:39,  1.89s/it]predicting train subjects:  26%|██▋       | 75/285 [02:21<06:46,  1.93s/it]predicting train subjects:  27%|██▋       | 76/285 [02:23<06:44,  1.94s/it]predicting train subjects:  27%|██▋       | 77/285 [02:25<06:38,  1.92s/it]predicting train subjects:  27%|██▋       | 78/285 [02:26<06:24,  1.86s/it]predicting train subjects:  28%|██▊       | 79/285 [02:28<06:24,  1.87s/it]predicting train subjects:  28%|██▊       | 80/285 [02:30<06:28,  1.90s/it]predicting train subjects:  28%|██▊       | 81/285 [02:32<06:15,  1.84s/it]predicting train subjects:  29%|██▉       | 82/285 [02:34<06:18,  1.87s/it]predicting train subjects:  29%|██▉       | 83/285 [02:36<06:13,  1.85s/it]predicting train subjects:  29%|██▉       | 84/285 [02:37<05:58,  1.78s/it]predicting train subjects:  30%|██▉       | 85/285 [02:39<06:07,  1.84s/it]predicting train subjects:  30%|███       | 86/285 [02:41<06:08,  1.85s/it]predicting train subjects:  31%|███       | 87/285 [02:43<06:04,  1.84s/it]predicting train subjects:  31%|███       | 88/285 [02:45<05:54,  1.80s/it]predicting train subjects:  31%|███       | 89/285 [02:46<05:54,  1.81s/it]predicting train subjects:  32%|███▏      | 90/285 [02:48<05:56,  1.83s/it]predicting train subjects:  32%|███▏      | 91/285 [02:50<05:44,  1.78s/it]predicting train subjects:  32%|███▏      | 92/285 [02:52<05:48,  1.81s/it]predicting train subjects:  33%|███▎      | 93/285 [02:53<05:40,  1.77s/it]predicting train subjects:  33%|███▎      | 94/285 [02:55<05:45,  1.81s/it]predicting train subjects:  33%|███▎      | 95/285 [02:57<05:50,  1.84s/it]predicting train subjects:  34%|███▎      | 96/285 [02:59<05:46,  1.83s/it]predicting train subjects:  34%|███▍      | 97/285 [03:01<05:45,  1.84s/it]predicting train subjects:  34%|███▍      | 98/285 [03:03<05:42,  1.83s/it]predicting train subjects:  35%|███▍      | 99/285 [03:05<05:46,  1.86s/it]predicting train subjects:  35%|███▌      | 100/285 [03:07<06:02,  1.96s/it]predicting train subjects:  35%|███▌      | 101/285 [03:09<05:46,  1.88s/it]predicting train subjects:  36%|███▌      | 102/285 [03:10<05:40,  1.86s/it]predicting train subjects:  36%|███▌      | 103/285 [03:12<05:32,  1.83s/it]predicting train subjects:  36%|███▋      | 104/285 [03:14<05:32,  1.83s/it]predicting train subjects:  37%|███▋      | 105/285 [03:16<05:33,  1.85s/it]predicting train subjects:  37%|███▋      | 106/285 [03:18<05:28,  1.83s/it]predicting train subjects:  38%|███▊      | 107/285 [03:20<05:30,  1.86s/it]predicting train subjects:  38%|███▊      | 108/285 [03:21<05:28,  1.85s/it]predicting train subjects:  38%|███▊      | 109/285 [03:23<05:25,  1.85s/it]predicting train subjects:  39%|███▊      | 110/285 [03:25<05:23,  1.85s/it]predicting train subjects:  39%|███▉      | 111/285 [03:27<05:15,  1.81s/it]predicting train subjects:  39%|███▉      | 112/285 [03:29<05:18,  1.84s/it]predicting train subjects:  40%|███▉      | 113/285 [03:31<05:21,  1.87s/it]predicting train subjects:  40%|████      | 114/285 [03:33<05:23,  1.89s/it]predicting train subjects:  40%|████      | 115/285 [03:35<05:22,  1.90s/it]predicting train subjects:  41%|████      | 116/285 [03:36<05:23,  1.91s/it]predicting train subjects:  41%|████      | 117/285 [03:38<05:12,  1.86s/it]predicting train subjects:  41%|████▏     | 118/285 [03:40<05:04,  1.82s/it]predicting train subjects:  42%|████▏     | 119/285 [03:42<05:03,  1.83s/it]predicting train subjects:  42%|████▏     | 120/285 [03:44<05:02,  1.83s/it]predicting train subjects:  42%|████▏     | 121/285 [03:45<04:53,  1.79s/it]predicting train subjects:  43%|████▎     | 122/285 [03:47<04:41,  1.73s/it]predicting train subjects:  43%|████▎     | 123/285 [03:48<04:27,  1.65s/it]predicting train subjects:  44%|████▎     | 124/285 [03:50<04:27,  1.66s/it]predicting train subjects:  44%|████▍     | 125/285 [03:52<04:21,  1.64s/it]predicting train subjects:  44%|████▍     | 126/285 [03:53<04:17,  1.62s/it]predicting train subjects:  45%|████▍     | 127/285 [03:55<04:09,  1.58s/it]predicting train subjects:  45%|████▍     | 128/285 [03:56<04:14,  1.62s/it]predicting train subjects:  45%|████▌     | 129/285 [03:58<04:08,  1.60s/it]predicting train subjects:  46%|████▌     | 130/285 [04:00<04:07,  1.60s/it]predicting train subjects:  46%|████▌     | 131/285 [04:01<04:02,  1.57s/it]predicting train subjects:  46%|████▋     | 132/285 [04:03<04:06,  1.61s/it]predicting train subjects:  47%|████▋     | 133/285 [04:04<04:08,  1.63s/it]predicting train subjects:  47%|████▋     | 134/285 [04:06<04:03,  1.62s/it]predicting train subjects:  47%|████▋     | 135/285 [04:08<03:55,  1.57s/it]predicting train subjects:  48%|████▊     | 136/285 [04:09<03:51,  1.55s/it]predicting train subjects:  48%|████▊     | 137/285 [04:11<03:57,  1.61s/it]predicting train subjects:  48%|████▊     | 138/285 [04:12<03:51,  1.57s/it]predicting train subjects:  49%|████▉     | 139/285 [04:14<03:58,  1.64s/it]predicting train subjects:  49%|████▉     | 140/285 [04:16<03:59,  1.65s/it]predicting train subjects:  49%|████▉     | 141/285 [04:17<03:53,  1.62s/it]predicting train subjects:  50%|████▉     | 142/285 [04:19<03:49,  1.60s/it]predicting train subjects:  50%|█████     | 143/285 [04:20<03:46,  1.60s/it]predicting train subjects:  51%|█████     | 144/285 [04:22<03:50,  1.63s/it]predicting train subjects:  51%|█████     | 145/285 [04:24<03:44,  1.60s/it]predicting train subjects:  51%|█████     | 146/285 [04:25<03:46,  1.63s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:27<03:37,  1.58s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:29<03:42,  1.62s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:30<03:40,  1.62s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:32<03:36,  1.60s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:33<03:34,  1.60s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:35<03:28,  1.57s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:36<03:21,  1.52s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:38<03:22,  1.54s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:39<03:17,  1.52s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:41<03:19,  1.55s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:42<03:17,  1.54s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:44<03:19,  1.57s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:46<03:14,  1.55s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:47<03:14,  1.55s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:49<03:17,  1.59s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:50<03:13,  1.57s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:52<03:14,  1.60s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:54<03:12,  1.59s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:55<03:09,  1.58s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:57<03:14,  1.64s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:59<03:15,  1.66s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:00<03:11,  1.64s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:02<03:08,  1.62s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:03<03:02,  1.58s/it]predicting train subjects:  60%|██████    | 171/285 [05:05<02:59,  1.58s/it]predicting train subjects:  60%|██████    | 172/285 [05:06<02:59,  1.59s/it]predicting train subjects:  61%|██████    | 173/285 [05:08<02:56,  1.58s/it]predicting train subjects:  61%|██████    | 174/285 [05:09<02:50,  1.54s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:11<02:53,  1.58s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:13<02:52,  1.58s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:14<02:48,  1.56s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:16<02:45,  1.54s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:17<02:43,  1.54s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:19<02:53,  1.66s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:21<03:00,  1.73s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:23<02:59,  1.74s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:24<02:53,  1.70s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:26<02:46,  1.65s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:28<02:44,  1.65s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:30<02:51,  1.73s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:31<02:55,  1.79s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:33<02:56,  1.82s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:35<02:46,  1.74s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:36<02:38,  1.67s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:38<02:41,  1.71s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:40<02:41,  1.73s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:42<02:33,  1.67s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:43<02:28,  1.63s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:45<02:24,  1.61s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:47<02:33,  1.73s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:49<02:37,  1.79s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:50<02:38,  1.82s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:52<02:29,  1.74s/it]predicting train subjects:  70%|███████   | 200/285 [05:54<02:22,  1.68s/it]predicting train subjects:  71%|███████   | 201/285 [05:55<02:25,  1.74s/it]predicting train subjects:  71%|███████   | 202/285 [05:57<02:23,  1.73s/it]predicting train subjects:  71%|███████   | 203/285 [05:59<02:23,  1.75s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:00<02:15,  1.67s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:02<02:11,  1.65s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:03<02:05,  1.59s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:06<02:15,  1.74s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:08<02:18,  1.80s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:09<02:19,  1.84s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:11<02:12,  1.76s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:12<02:03,  1.67s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:14<02:03,  1.69s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:16<02:02,  1.70s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:17<01:57,  1.65s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:19<02:00,  1.72s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:21<01:52,  1.63s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:23<01:56,  1.71s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:25<01:58,  1.77s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:27<01:59,  1.82s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:28<01:51,  1.72s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:30<01:46,  1.67s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:31<01:44,  1.66s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:33<01:39,  1.61s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:34<01:37,  1.59s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:36<01:36,  1.60s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:38<01:41,  1.71s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:40<01:43,  1.78s/it]predicting train subjects:  80%|████████  | 228/285 [06:42<01:42,  1.80s/it]predicting train subjects:  80%|████████  | 229/285 [06:43<01:39,  1.77s/it]predicting train subjects:  81%|████████  | 230/285 [06:45<01:33,  1.71s/it]predicting train subjects:  81%|████████  | 231/285 [06:46<01:29,  1.66s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:48<01:28,  1.67s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:50<01:25,  1.65s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:52<01:27,  1.72s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:53<01:22,  1.64s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:55<01:24,  1.72s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:57<01:25,  1.77s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:59<01:23,  1.77s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:00<01:20,  1.76s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:02<01:16,  1.70s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:03<01:12,  1.64s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:05<01:09,  1.61s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:07<01:07,  1.61s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:08<01:09,  1.69s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:10<01:04,  1.62s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:12<01:06,  1.70s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:14<01:07,  1.76s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:15<01:05,  1.76s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:17<01:01,  1.71s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:19<00:57,  1.65s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:20<00:54,  1.61s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:22<00:51,  1.57s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:23<00:53,  1.69s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:25<00:55,  1.78s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:27<00:53,  1.79s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:29<00:49,  1.69s/it]predicting train subjects:  90%|█████████ | 257/285 [07:30<00:46,  1.64s/it]predicting train subjects:  91%|█████████ | 258/285 [07:32<00:46,  1.73s/it]predicting train subjects:  91%|█████████ | 259/285 [07:34<00:44,  1.72s/it]predicting train subjects:  91%|█████████ | 260/285 [07:35<00:41,  1.66s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:37<00:39,  1.64s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:39<00:36,  1.59s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:40<00:34,  1.57s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:42<00:35,  1.69s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:44<00:34,  1.74s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:45<00:31,  1.66s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:47<00:29,  1.61s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:49<00:28,  1.69s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:50<00:27,  1.70s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:52<00:24,  1.64s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:53<00:22,  1.60s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:55<00:21,  1.64s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:57<00:19,  1.61s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:58<00:17,  1.59s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:00<00:17,  1.74s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:02<00:15,  1.77s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:04<00:13,  1.69s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:05<00:11,  1.64s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:07<00:10,  1.67s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:08<00:08,  1.61s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:10<00:06,  1.61s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:12<00:04,  1.58s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:14<00:03,  1.71s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:16<00:01,  1.79s/it]predicting train subjects: 100%|██████████| 285/285 [08:17<00:00,  1.81s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<09:04,  1.92s/it]Loading train:   1%|          | 2/285 [00:03<08:20,  1.77s/it]Loading train:   1%|          | 3/285 [00:04<07:59,  1.70s/it]Loading train:   1%|▏         | 4/285 [00:06<07:50,  1.68s/it]Loading train:   2%|▏         | 5/285 [00:08<07:41,  1.65s/it]Loading train:   2%|▏         | 6/285 [00:09<07:10,  1.54s/it]Loading train:   2%|▏         | 7/285 [00:11<07:25,  1.60s/it]Loading train:   3%|▎         | 8/285 [00:12<07:32,  1.63s/it]Loading train:   3%|▎         | 9/285 [00:14<07:40,  1.67s/it]Loading train:   4%|▎         | 10/285 [00:15<07:12,  1.57s/it]Loading train:   4%|▍         | 11/285 [00:17<06:36,  1.45s/it]Loading train:   4%|▍         | 12/285 [00:18<06:17,  1.38s/it]Loading train:   5%|▍         | 13/285 [00:19<05:49,  1.28s/it]Loading train:   5%|▍         | 14/285 [00:20<05:56,  1.31s/it]Loading train:   5%|▌         | 15/285 [00:22<05:58,  1.33s/it]Loading train:   6%|▌         | 16/285 [00:23<05:55,  1.32s/it]Loading train:   6%|▌         | 17/285 [00:24<05:27,  1.22s/it]Loading train:   6%|▋         | 18/285 [00:25<05:43,  1.29s/it]Loading train:   7%|▋         | 19/285 [00:26<05:26,  1.23s/it]Loading train:   7%|▋         | 20/285 [00:28<05:23,  1.22s/it]Loading train:   7%|▋         | 21/285 [00:29<05:28,  1.24s/it]Loading train:   8%|▊         | 22/285 [00:30<05:18,  1.21s/it]Loading train:   8%|▊         | 23/285 [00:31<05:11,  1.19s/it]Loading train:   8%|▊         | 24/285 [00:32<05:08,  1.18s/it]Loading train:   9%|▉         | 25/285 [00:34<05:16,  1.22s/it]Loading train:   9%|▉         | 26/285 [00:35<05:20,  1.24s/it]Loading train:   9%|▉         | 27/285 [00:36<05:21,  1.25s/it]Loading train:  10%|▉         | 28/285 [00:38<05:40,  1.32s/it]Loading train:  10%|█         | 29/285 [00:39<05:21,  1.26s/it]Loading train:  11%|█         | 30/285 [00:40<05:20,  1.26s/it]Loading train:  11%|█         | 31/285 [00:41<05:22,  1.27s/it]Loading train:  11%|█         | 32/285 [00:42<04:50,  1.15s/it]Loading train:  12%|█▏        | 33/285 [00:43<04:51,  1.16s/it]Loading train:  12%|█▏        | 34/285 [00:45<04:50,  1.16s/it]Loading train:  12%|█▏        | 35/285 [00:46<04:54,  1.18s/it]Loading train:  13%|█▎        | 36/285 [00:47<04:46,  1.15s/it]Loading train:  13%|█▎        | 37/285 [00:48<04:54,  1.19s/it]Loading train:  13%|█▎        | 38/285 [00:49<05:02,  1.23s/it]Loading train:  14%|█▎        | 39/285 [00:50<04:39,  1.14s/it]Loading train:  14%|█▍        | 40/285 [00:52<04:51,  1.19s/it]Loading train:  14%|█▍        | 41/285 [00:53<04:49,  1.19s/it]Loading train:  15%|█▍        | 42/285 [00:54<04:50,  1.19s/it]Loading train:  15%|█▌        | 43/285 [00:55<04:39,  1.15s/it]Loading train:  15%|█▌        | 44/285 [00:56<04:39,  1.16s/it]Loading train:  16%|█▌        | 45/285 [00:57<04:27,  1.11s/it]Loading train:  16%|█▌        | 46/285 [00:59<04:34,  1.15s/it]Loading train:  16%|█▋        | 47/285 [01:00<04:27,  1.13s/it]Loading train:  17%|█▋        | 48/285 [01:01<04:37,  1.17s/it]Loading train:  17%|█▋        | 49/285 [01:02<04:44,  1.21s/it]Loading train:  18%|█▊        | 50/285 [01:03<04:45,  1.22s/it]Loading train:  18%|█▊        | 51/285 [01:05<04:44,  1.22s/it]Loading train:  18%|█▊        | 52/285 [01:06<04:41,  1.21s/it]Loading train:  19%|█▊        | 53/285 [01:07<04:34,  1.18s/it]Loading train:  19%|█▉        | 54/285 [01:08<04:44,  1.23s/it]Loading train:  19%|█▉        | 55/285 [01:09<04:25,  1.15s/it]Loading train:  20%|█▉        | 56/285 [01:11<04:39,  1.22s/it]Loading train:  20%|██        | 57/285 [01:12<04:27,  1.17s/it]Loading train:  20%|██        | 58/285 [01:13<04:26,  1.17s/it]Loading train:  21%|██        | 59/285 [01:14<04:29,  1.19s/it]Loading train:  21%|██        | 60/285 [01:15<04:29,  1.20s/it]Loading train:  21%|██▏       | 61/285 [01:16<04:19,  1.16s/it]Loading train:  22%|██▏       | 62/285 [01:18<04:24,  1.19s/it]Loading train:  22%|██▏       | 63/285 [01:19<04:25,  1.19s/it]Loading train:  22%|██▏       | 64/285 [01:20<04:48,  1.30s/it]Loading train:  23%|██▎       | 65/285 [01:22<05:11,  1.42s/it]Loading train:  23%|██▎       | 66/285 [01:24<05:31,  1.51s/it]Loading train:  24%|██▎       | 67/285 [01:25<05:21,  1.47s/it]Loading train:  24%|██▍       | 68/285 [01:26<04:56,  1.36s/it]Loading train:  24%|██▍       | 69/285 [01:28<04:54,  1.36s/it]Loading train:  25%|██▍       | 70/285 [01:29<04:33,  1.27s/it]Loading train:  25%|██▍       | 71/285 [01:30<04:17,  1.21s/it]Loading train:  25%|██▌       | 72/285 [01:31<04:03,  1.15s/it]Loading train:  26%|██▌       | 73/285 [01:32<04:10,  1.18s/it]Loading train:  26%|██▌       | 74/285 [01:33<04:08,  1.18s/it]Loading train:  26%|██▋       | 75/285 [01:34<04:09,  1.19s/it]Loading train:  27%|██▋       | 76/285 [01:36<04:21,  1.25s/it]Loading train:  27%|██▋       | 77/285 [01:37<04:08,  1.19s/it]Loading train:  27%|██▋       | 78/285 [01:38<04:04,  1.18s/it]Loading train:  28%|██▊       | 79/285 [01:39<04:02,  1.18s/it]Loading train:  28%|██▊       | 80/285 [01:40<04:01,  1.18s/it]Loading train:  28%|██▊       | 81/285 [01:41<03:51,  1.13s/it]Loading train:  29%|██▉       | 82/285 [01:43<03:49,  1.13s/it]Loading train:  29%|██▉       | 83/285 [01:44<03:44,  1.11s/it]Loading train:  29%|██▉       | 84/285 [01:45<03:52,  1.16s/it]Loading train:  30%|██▉       | 85/285 [01:46<04:05,  1.23s/it]Loading train:  30%|███       | 86/285 [01:48<04:11,  1.26s/it]Loading train:  31%|███       | 87/285 [01:49<04:21,  1.32s/it]Loading train:  31%|███       | 88/285 [01:50<04:02,  1.23s/it]Loading train:  31%|███       | 89/285 [01:51<03:52,  1.18s/it]Loading train:  32%|███▏      | 90/285 [01:53<04:01,  1.24s/it]Loading train:  32%|███▏      | 91/285 [01:54<03:49,  1.18s/it]Loading train:  32%|███▏      | 92/285 [01:55<03:51,  1.20s/it]Loading train:  33%|███▎      | 93/285 [01:56<03:47,  1.18s/it]Loading train:  33%|███▎      | 94/285 [01:57<03:43,  1.17s/it]Loading train:  33%|███▎      | 95/285 [01:58<03:49,  1.21s/it]Loading train:  34%|███▎      | 96/285 [02:00<03:57,  1.26s/it]Loading train:  34%|███▍      | 97/285 [02:01<03:52,  1.24s/it]Loading train:  34%|███▍      | 98/285 [02:02<03:48,  1.22s/it]Loading train:  35%|███▍      | 99/285 [02:03<03:49,  1.23s/it]Loading train:  35%|███▌      | 100/285 [02:05<03:42,  1.20s/it]Loading train:  35%|███▌      | 101/285 [02:06<03:36,  1.18s/it]Loading train:  36%|███▌      | 102/285 [02:07<03:38,  1.19s/it]Loading train:  36%|███▌      | 103/285 [02:08<03:35,  1.18s/it]Loading train:  36%|███▋      | 104/285 [02:10<03:51,  1.28s/it]Loading train:  37%|███▋      | 105/285 [02:11<03:53,  1.30s/it]Loading train:  37%|███▋      | 106/285 [02:12<03:35,  1.20s/it]Loading train:  38%|███▊      | 107/285 [02:13<03:20,  1.13s/it]Loading train:  38%|███▊      | 108/285 [02:14<02:59,  1.01s/it]Loading train:  38%|███▊      | 109/285 [02:15<03:19,  1.13s/it]Loading train:  39%|███▊      | 110/285 [02:16<03:14,  1.11s/it]Loading train:  39%|███▉      | 111/285 [02:17<03:23,  1.17s/it]Loading train:  39%|███▉      | 112/285 [02:19<03:20,  1.16s/it]Loading train:  40%|███▉      | 113/285 [02:19<03:03,  1.06s/it]Loading train:  40%|████      | 114/285 [02:21<03:11,  1.12s/it]Loading train:  40%|████      | 115/285 [02:22<03:05,  1.09s/it]Loading train:  41%|████      | 116/285 [02:23<02:59,  1.06s/it]Loading train:  41%|████      | 117/285 [02:23<02:46,  1.01it/s]Loading train:  41%|████▏     | 118/285 [02:24<02:33,  1.09it/s]Loading train:  42%|████▏     | 119/285 [02:25<02:39,  1.04it/s]Loading train:  42%|████▏     | 120/285 [02:26<02:31,  1.09it/s]Loading train:  42%|████▏     | 121/285 [02:27<02:48,  1.03s/it]Loading train:  43%|████▎     | 122/285 [02:29<02:53,  1.06s/it]Loading train:  43%|████▎     | 123/285 [02:30<02:55,  1.08s/it]Loading train:  44%|████▎     | 124/285 [02:31<02:46,  1.04s/it]Loading train:  44%|████▍     | 125/285 [02:31<02:27,  1.09it/s]Loading train:  44%|████▍     | 126/285 [02:32<02:15,  1.17it/s]Loading train:  45%|████▍     | 127/285 [02:33<02:11,  1.20it/s]Loading train:  45%|████▍     | 128/285 [02:33<02:05,  1.25it/s]Loading train:  45%|████▌     | 129/285 [02:34<01:58,  1.32it/s]Loading train:  46%|████▌     | 130/285 [02:35<01:53,  1.37it/s]Loading train:  46%|████▌     | 131/285 [02:36<02:01,  1.27it/s]Loading train:  46%|████▋     | 132/285 [02:37<02:13,  1.14it/s]Loading train:  47%|████▋     | 133/285 [02:38<02:08,  1.18it/s]Loading train:  47%|████▋     | 134/285 [02:38<02:05,  1.21it/s]Loading train:  47%|████▋     | 135/285 [02:39<02:08,  1.17it/s]Loading train:  48%|████▊     | 136/285 [02:40<02:03,  1.21it/s]Loading train:  48%|████▊     | 137/285 [02:41<02:03,  1.19it/s]Loading train:  48%|████▊     | 138/285 [02:42<02:03,  1.19it/s]Loading train:  49%|████▉     | 139/285 [02:43<02:03,  1.18it/s]Loading train:  49%|████▉     | 140/285 [02:43<02:01,  1.19it/s]Loading train:  49%|████▉     | 141/285 [02:44<01:57,  1.23it/s]Loading train:  50%|████▉     | 142/285 [02:45<01:51,  1.29it/s]Loading train:  50%|█████     | 143/285 [02:46<01:54,  1.24it/s]Loading train:  51%|█████     | 144/285 [02:47<01:56,  1.21it/s]Loading train:  51%|█████     | 145/285 [02:47<01:54,  1.22it/s]Loading train:  51%|█████     | 146/285 [02:48<01:53,  1.23it/s]Loading train:  52%|█████▏    | 147/285 [02:49<01:48,  1.27it/s]Loading train:  52%|█████▏    | 148/285 [02:50<01:46,  1.28it/s]Loading train:  52%|█████▏    | 149/285 [02:51<01:53,  1.20it/s]Loading train:  53%|█████▎    | 150/285 [02:51<01:47,  1.26it/s]Loading train:  53%|█████▎    | 151/285 [02:52<01:48,  1.23it/s]Loading train:  53%|█████▎    | 152/285 [02:53<01:45,  1.26it/s]Loading train:  54%|█████▎    | 153/285 [02:54<01:45,  1.25it/s]Loading train:  54%|█████▍    | 154/285 [02:55<01:50,  1.18it/s]Loading train:  54%|█████▍    | 155/285 [02:56<01:50,  1.18it/s]Loading train:  55%|█████▍    | 156/285 [02:56<01:48,  1.19it/s]Loading train:  55%|█████▌    | 157/285 [02:57<01:44,  1.22it/s]Loading train:  55%|█████▌    | 158/285 [02:58<01:48,  1.17it/s]Loading train:  56%|█████▌    | 159/285 [02:59<01:43,  1.22it/s]Loading train:  56%|█████▌    | 160/285 [03:00<01:47,  1.17it/s]Loading train:  56%|█████▋    | 161/285 [03:01<01:44,  1.18it/s]Loading train:  57%|█████▋    | 162/285 [03:01<01:41,  1.22it/s]Loading train:  57%|█████▋    | 163/285 [03:02<01:39,  1.22it/s]Loading train:  58%|█████▊    | 164/285 [03:03<01:37,  1.24it/s]Loading train:  58%|█████▊    | 165/285 [03:04<01:36,  1.24it/s]Loading train:  58%|█████▊    | 166/285 [03:05<01:40,  1.19it/s]Loading train:  59%|█████▊    | 167/285 [03:06<01:38,  1.19it/s]Loading train:  59%|█████▉    | 168/285 [03:06<01:33,  1.26it/s]Loading train:  59%|█████▉    | 169/285 [03:07<01:29,  1.30it/s]Loading train:  60%|█████▉    | 170/285 [03:08<01:29,  1.29it/s]Loading train:  60%|██████    | 171/285 [03:09<01:28,  1.29it/s]Loading train:  60%|██████    | 172/285 [03:09<01:28,  1.28it/s]Loading train:  61%|██████    | 173/285 [03:10<01:27,  1.27it/s]Loading train:  61%|██████    | 174/285 [03:11<01:24,  1.32it/s]Loading train:  61%|██████▏   | 175/285 [03:12<01:25,  1.29it/s]Loading train:  62%|██████▏   | 176/285 [03:12<01:26,  1.26it/s]Loading train:  62%|██████▏   | 177/285 [03:13<01:21,  1.33it/s]Loading train:  62%|██████▏   | 178/285 [03:14<01:18,  1.36it/s]Loading train:  63%|██████▎   | 179/285 [03:15<01:17,  1.36it/s]Loading train:  63%|██████▎   | 180/285 [03:15<01:21,  1.29it/s]Loading train:  64%|██████▎   | 181/285 [03:16<01:23,  1.25it/s]Loading train:  64%|██████▍   | 182/285 [03:17<01:23,  1.23it/s]Loading train:  64%|██████▍   | 183/285 [03:18<01:25,  1.19it/s]Loading train:  65%|██████▍   | 184/285 [03:19<01:24,  1.20it/s]Loading train:  65%|██████▍   | 185/285 [03:20<01:22,  1.22it/s]Loading train:  65%|██████▌   | 186/285 [03:21<01:24,  1.17it/s]Loading train:  66%|██████▌   | 187/285 [03:21<01:24,  1.15it/s]Loading train:  66%|██████▌   | 188/285 [03:22<01:25,  1.14it/s]Loading train:  66%|██████▋   | 189/285 [03:23<01:19,  1.20it/s]Loading train:  67%|██████▋   | 190/285 [03:24<01:17,  1.23it/s]Loading train:  67%|██████▋   | 191/285 [03:25<01:14,  1.26it/s]Loading train:  67%|██████▋   | 192/285 [03:26<01:17,  1.19it/s]Loading train:  68%|██████▊   | 193/285 [03:26<01:18,  1.16it/s]Loading train:  68%|██████▊   | 194/285 [03:27<01:15,  1.20it/s]Loading train:  68%|██████▊   | 195/285 [03:28<01:10,  1.28it/s]Loading train:  69%|██████▉   | 196/285 [03:29<01:10,  1.26it/s]Loading train:  69%|██████▉   | 197/285 [03:29<01:09,  1.26it/s]Loading train:  69%|██████▉   | 198/285 [03:30<01:13,  1.19it/s]Loading train:  70%|██████▉   | 199/285 [03:31<01:09,  1.24it/s]Loading train:  70%|███████   | 200/285 [03:32<01:06,  1.27it/s]Loading train:  71%|███████   | 201/285 [03:33<01:09,  1.22it/s]Loading train:  71%|███████   | 202/285 [03:34<01:10,  1.18it/s]Loading train:  71%|███████   | 203/285 [03:35<01:10,  1.16it/s]Loading train:  72%|███████▏  | 204/285 [03:35<01:06,  1.22it/s]Loading train:  72%|███████▏  | 205/285 [03:36<01:03,  1.27it/s]Loading train:  72%|███████▏  | 206/285 [03:37<00:58,  1.34it/s]Loading train:  73%|███████▎  | 207/285 [03:38<01:02,  1.25it/s]Loading train:  73%|███████▎  | 208/285 [03:39<01:04,  1.20it/s]Loading train:  73%|███████▎  | 209/285 [03:40<01:16,  1.01s/it]Loading train:  74%|███████▎  | 210/285 [03:41<01:08,  1.09it/s]Loading train:  74%|███████▍  | 211/285 [03:41<01:03,  1.16it/s]Loading train:  74%|███████▍  | 212/285 [03:42<01:00,  1.20it/s]Loading train:  75%|███████▍  | 213/285 [03:43<00:59,  1.20it/s]Loading train:  75%|███████▌  | 214/285 [03:44<00:55,  1.28it/s]Loading train:  75%|███████▌  | 215/285 [03:45<00:58,  1.20it/s]Loading train:  76%|███████▌  | 216/285 [03:45<00:54,  1.26it/s]Loading train:  76%|███████▌  | 217/285 [03:46<00:54,  1.25it/s]Loading train:  76%|███████▋  | 218/285 [03:47<00:56,  1.18it/s]Loading train:  77%|███████▋  | 219/285 [03:48<00:58,  1.13it/s]Loading train:  77%|███████▋  | 220/285 [03:49<00:53,  1.21it/s]Loading train:  78%|███████▊  | 221/285 [03:50<00:52,  1.22it/s]Loading train:  78%|███████▊  | 222/285 [03:50<00:51,  1.23it/s]Loading train:  78%|███████▊  | 223/285 [03:51<00:49,  1.25it/s]Loading train:  79%|███████▊  | 224/285 [03:52<00:47,  1.28it/s]Loading train:  79%|███████▉  | 225/285 [03:53<00:45,  1.31it/s]Loading train:  79%|███████▉  | 226/285 [03:53<00:47,  1.24it/s]Loading train:  80%|███████▉  | 227/285 [03:54<00:47,  1.21it/s]Loading train:  80%|████████  | 228/285 [03:55<00:48,  1.16it/s]Loading train:  80%|████████  | 229/285 [03:56<00:47,  1.18it/s]Loading train:  81%|████████  | 230/285 [03:57<00:44,  1.24it/s]Loading train:  81%|████████  | 231/285 [03:58<00:42,  1.27it/s]Loading train:  81%|████████▏ | 232/285 [03:58<00:43,  1.22it/s]Loading train:  82%|████████▏ | 233/285 [03:59<00:41,  1.25it/s]Loading train:  82%|████████▏ | 234/285 [04:00<00:43,  1.18it/s]Loading train:  82%|████████▏ | 235/285 [04:01<00:40,  1.23it/s]Loading train:  83%|████████▎ | 236/285 [04:02<00:42,  1.16it/s]Loading train:  83%|████████▎ | 237/285 [04:03<00:42,  1.14it/s]Loading train:  84%|████████▎ | 238/285 [04:04<00:42,  1.11it/s]Loading train:  84%|████████▍ | 239/285 [04:05<00:40,  1.15it/s]Loading train:  84%|████████▍ | 240/285 [04:05<00:38,  1.16it/s]Loading train:  85%|████████▍ | 241/285 [04:06<00:37,  1.18it/s]Loading train:  85%|████████▍ | 242/285 [04:07<00:33,  1.29it/s]Loading train:  85%|████████▌ | 243/285 [04:07<00:31,  1.33it/s]Loading train:  86%|████████▌ | 244/285 [04:08<00:33,  1.22it/s]Loading train:  86%|████████▌ | 245/285 [04:09<00:31,  1.27it/s]Loading train:  86%|████████▋ | 246/285 [04:10<00:32,  1.22it/s]Loading train:  87%|████████▋ | 247/285 [04:11<00:33,  1.15it/s]Loading train:  87%|████████▋ | 248/285 [04:12<00:33,  1.12it/s]Loading train:  87%|████████▋ | 249/285 [04:13<00:30,  1.20it/s]Loading train:  88%|████████▊ | 250/285 [04:13<00:28,  1.23it/s]Loading train:  88%|████████▊ | 251/285 [04:14<00:26,  1.29it/s]Loading train:  88%|████████▊ | 252/285 [04:15<00:24,  1.34it/s]Loading train:  89%|████████▉ | 253/285 [04:16<00:25,  1.25it/s]Loading train:  89%|████████▉ | 254/285 [04:17<00:25,  1.24it/s]Loading train:  89%|████████▉ | 255/285 [04:17<00:23,  1.26it/s]Loading train:  90%|████████▉ | 256/285 [04:18<00:21,  1.35it/s]Loading train:  90%|█████████ | 257/285 [04:19<00:20,  1.39it/s]Loading train:  91%|█████████ | 258/285 [04:20<00:21,  1.28it/s]Loading train:  91%|█████████ | 259/285 [04:20<00:21,  1.23it/s]Loading train:  91%|█████████ | 260/285 [04:21<00:19,  1.26it/s]Loading train:  92%|█████████▏| 261/285 [04:22<00:18,  1.27it/s]Loading train:  92%|█████████▏| 262/285 [04:23<00:18,  1.26it/s]Loading train:  92%|█████████▏| 263/285 [04:24<00:17,  1.29it/s]Loading train:  93%|█████████▎| 264/285 [04:24<00:16,  1.25it/s]Loading train:  93%|█████████▎| 265/285 [04:25<00:16,  1.24it/s]Loading train:  93%|█████████▎| 266/285 [04:26<00:15,  1.26it/s]Loading train:  94%|█████████▎| 267/285 [04:27<00:14,  1.27it/s]Loading train:  94%|█████████▍| 268/285 [04:28<00:14,  1.18it/s]Loading train:  94%|█████████▍| 269/285 [04:29<00:13,  1.15it/s]Loading train:  95%|█████████▍| 270/285 [04:30<00:13,  1.15it/s]Loading train:  95%|█████████▌| 271/285 [04:30<00:11,  1.19it/s]Loading train:  95%|█████████▌| 272/285 [04:31<00:11,  1.17it/s]Loading train:  96%|█████████▌| 273/285 [04:32<00:10,  1.20it/s]Loading train:  96%|█████████▌| 274/285 [04:33<00:08,  1.23it/s]Loading train:  96%|█████████▋| 275/285 [04:34<00:08,  1.18it/s]Loading train:  97%|█████████▋| 276/285 [04:35<00:07,  1.15it/s]Loading train:  97%|█████████▋| 277/285 [04:35<00:06,  1.26it/s]Loading train:  98%|█████████▊| 278/285 [04:36<00:05,  1.31it/s]Loading train:  98%|█████████▊| 279/285 [04:37<00:04,  1.33it/s]Loading train:  98%|█████████▊| 280/285 [04:37<00:03,  1.35it/s]Loading train:  99%|█████████▊| 281/285 [04:38<00:02,  1.37it/s]Loading train:  99%|█████████▉| 282/285 [04:39<00:02,  1.41it/s]Loading train:  99%|█████████▉| 283/285 [04:40<00:01,  1.32it/s]Loading train: 100%|█████████▉| 284/285 [04:40<00:00,  1.26it/s]Loading train: 100%|██████████| 285/285 [04:41<00:00,  1.24it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   8%|▊         | 23/285 [00:00<00:01, 224.81it/s]concatenating: train:  20%|██        | 57/285 [00:00<00:00, 248.71it/s]concatenating: train:  33%|███▎      | 93/285 [00:00<00:00, 272.92it/s]concatenating: train:  45%|████▍     | 128/285 [00:00<00:00, 291.25it/s]concatenating: train:  56%|█████▌    | 159/285 [00:00<00:00, 295.37it/s]concatenating: train:  67%|██████▋   | 190/285 [00:00<00:00, 298.24it/s]concatenating: train:  79%|███████▉  | 225/285 [00:00<00:00, 311.74it/s]concatenating: train:  91%|█████████ | 260/285 [00:00<00:00, 320.73it/s]concatenating: train: 100%|██████████| 285/285 [00:00<00:00, 324.60it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.12s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.12s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.07s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 111.56it/s]2019-07-09 13:58:18.228927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-09 13:58:18.229031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-09 13:58:18.229048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-09 13:58:18.229057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-09 13:58:18.229356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12743 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:01<00:47,  1.09s/it]loading the weights for Res Unet:   7%|▋         | 3/44 [00:01<00:33,  1.24it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:01<00:27,  1.46it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:01<00:17,  2.03it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:02<00:13,  2.51it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:02<00:10,  3.27it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:02<00:08,  3.67it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:02<00:05,  4.94it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:04,  5.85it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:03<00:04,  5.65it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:03<00:02,  7.23it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:04<00:04,  3.81it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:04<00:04,  3.56it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:05<00:03,  3.98it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:05<00:03,  4.26it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:05<00:01,  5.62it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:05<00:01,  6.54it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:06<00:00,  7.27it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:06<00:00,  6.31it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:06<00:00,  6.83it/s]
Epoch 00043: val_mDice did not improve from 0.62932
Restoring model weights from the end of the best epoch
Epoch 00043: early stopping
{'val_loss': [5531.13970844972, 2256.7970223027237, 2144.939863663146, 3001.831308375524, 2270.086503524354, 2316.504215858502, 2150.420241030901, 2308.914048860859, 2292.1947273808487, 2295.1345664935407, 2114.0287253949896, 2156.0738518571056, 2075.0797630608413, 2279.826004113565, 2206.650761609637, 2320.7305137591657, 2098.8887441624474, 2236.808040000873, 2208.972281173621, 2383.6426244980794, 2233.6643952950417, 2138.3438604770427, 2146.633967735248, 2226.378816231669, 2211.345484898743, 2297.8923626265714, 2217.4972326182788, 2094.547531042685, 2170.6654673315293, 2300.178802319745, 2130.018246442912, 2248.7481437129013, 2340.4785115332575, 2111.496174220932, 2207.4769675824896, 2169.425425268418, 2207.8329614394206, 2300.5257329674405, 2173.134012744413, 2199.6351093313547, 2243.740568533956, 2295.9055107585546, 2328.0781631895948], 'val_acc': [0.9311613823448479, 0.9520966427286244, 0.9525945296500649, 0.9470162285106808, 0.9527309243905477, 0.9528383439479593, 0.9515305477813636, 0.953210246962542, 0.9488901132977875, 0.9523259634412201, 0.9512474746677463, 0.9521503495104486, 0.9528941252378113, 0.9472992586689954, 0.9523280449419714, 0.9500285210556159, 0.9539891048516641, 0.9524085871334182, 0.9546978037450566, 0.9526234618778335, 0.9547824826320457, 0.952257773729676, 0.9535387461411886, 0.9520862815100387, 0.9526276138907704, 0.9527536224386546, 0.9535924372726312, 0.9543155471705858, 0.9541626739102369, 0.9546151450892401, 0.9531131183634923, 0.9531937025112813, 0.9519396054678123, 0.9548444721285857, 0.954431275415687, 0.9524333983160264, 0.9540201219100526, 0.9539849981249378, 0.9533920241467779, 0.9548279286762855, 0.9546544112306733, 0.95186523285658, 0.9549147173679075], 'val_mDice': [0.4324874393433832, 0.6038213661929083, 0.6184624496784956, 0.5269143098559459, 0.6089200174342321, 0.6055662984954578, 0.618765508662389, 0.611469718997039, 0.6017788342257452, 0.6068604611817685, 0.625891209980629, 0.6197112648846717, 0.6293222438023743, 0.6046424930988077, 0.6141493856573904, 0.6066980961314793, 0.6283736711773793, 0.6117420236491624, 0.6128666993626003, 0.5970045341459732, 0.6118329736773528, 0.62344323390023, 0.6215651648004628, 0.6124657702179594, 0.6149247122210497, 0.6061802543075391, 0.6180688505732147, 0.6285924811602971, 0.6233910775051437, 0.607385220474371, 0.6265622210902209, 0.6138365621673328, 0.6064763681848622, 0.6273913296907307, 0.6165369649173161, 0.6182324057184784, 0.6225158915173408, 0.6031210342599027, 0.6212360139665657, 0.6198960965572122, 0.6146034062241709, 0.6131539358107071, 0.6105944564222624], 'loss': [8655.39740596896, 2759.080012166742, 2214.471699878532, 2000.571724629001, 1900.1469634881785, 1812.2428503336193, 1751.2505646707652, 1696.728961343528, 1650.170987305964, 1621.9097786637396, 1581.3028858010919, 1552.5718257603423, 1532.8256230871375, 1507.8067011050193, 1486.4794484347237, 1470.0385013561831, 1450.070470717379, 1431.8863421676401, 1411.7795104498464, 1402.2968886025194, 1381.068437250421, 1388.4270915396105, 1368.12990862471, 1350.716576309416, 1343.9501351150357, 1335.1717165665495, 1319.5385537817292, 1318.8806024695473, 1304.4246240319474, 1301.1741567827455, 1293.047601458307, 1284.1748782813852, 1290.3495982922043, 1274.4280536087126, 1260.681203413033, 1254.3911199694878, 1253.9279733465346, 1250.5685423441776, 1248.6817380931018, 1237.9326075640167, 1236.3511724281425, 1227.4883067530618, 1216.6080144123148], 'acc': [0.7904705946468579, 0.922093119926945, 0.9398887102383556, 0.9457898770183216, 0.9475931069747171, 0.949073104211483, 0.9499211479983722, 0.9506588198508736, 0.9513247488377485, 0.9517003698394706, 0.9523964914145354, 0.9527452205833828, 0.9530511369379795, 0.9534749580970953, 0.9537324290650582, 0.9539771319299175, 0.9542607655842562, 0.9544314082317716, 0.9547119425549551, 0.9548916665695246, 0.9551296210627911, 0.9550542730949042, 0.9553238698375439, 0.9555251053667596, 0.9556056523133477, 0.955836660205185, 0.9559766217115871, 0.9559613744435139, 0.956196084435966, 0.9562604595883649, 0.9563993583330109, 0.9565144264128634, 0.9564143226210454, 0.9566028087131728, 0.9567116350690288, 0.9568703322328518, 0.9567777595711678, 0.956914039964049, 0.9569083792335762, 0.9571175311984375, 0.9570876397401457, 0.9572347957066907, 0.9573210457572295], 'mDice': [0.2779158540853218, 0.5755477257267295, 0.6398702982262675, 0.666795863746058, 0.6801316979715595, 0.6921086314651521, 0.7003356261870407, 0.7081422577314105, 0.7146058914370672, 0.7186222860388659, 0.7245686563568485, 0.7287850232693334, 0.7316366695551355, 0.7353616816293349, 0.7385144149560462, 0.7409591521288885, 0.7438428425709671, 0.7465289099875713, 0.7495034108474347, 0.7510656007825208, 0.7541098635438598, 0.7530699721621984, 0.7562072117482777, 0.7587988885112151, 0.7598152003395525, 0.7612374928397398, 0.763545251328937, 0.7636425861715783, 0.7659047789436287, 0.7664648534932055, 0.7676544920641524, 0.7690518845283975, 0.7681161716063424, 0.7705513786908608, 0.7726727587667324, 0.773636082724856, 0.7736454757429482, 0.7743323623280296, 0.7745180815583279, 0.7762168888874053, 0.7765157810905831, 0.777859552481434, 0.7795216146523601]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 40)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 41)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 15)   5550        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 15)   2040        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 15)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 40, 26, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 30)   4080        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 30)   8130        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 45)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 60)   24360       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 60)   32460       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 105)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 30)   12630       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 30)   8130        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 105)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 40, 26, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 15)   6315        dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 15)   2040        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 45)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 80, 52, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 40)   16240       dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 80, 52, 40)   160         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 52, 40)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 80, 52, 40)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 80, 52, 85)   0           dropout_6[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 52, 13)   1118        concatenate_8[0][0]              
==================================================================================================
Total params: 149,358
Trainable params: 50,738
Non-trainable params: 98,620
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 26s - loss: 24701.6801 - acc: 0.5664 - mDice: 0.0770 - val_loss: 14634.7892 - val_acc: 0.8391 - val_mDice: 0.1693

Epoch 00001: val_mDice improved from -inf to 0.16925, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 19s - loss: 10251.3532 - acc: 0.8806 - mDice: 0.2816 - val_loss: 7924.9514 - val_acc: 0.9050 - val_mDice: 0.3502

Epoch 00002: val_mDice improved from 0.16925 to 0.35022, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 19s - loss: 7484.3435 - acc: 0.8907 - mDice: 0.3819 - val_loss: 6433.9691 - val_acc: 0.9145 - val_mDice: 0.4130

Epoch 00003: val_mDice improved from 0.35022 to 0.41305, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 19s - loss: 6410.0955 - acc: 0.8978 - mDice: 0.4363 - val_loss: 6525.7542 - val_acc: 0.9157 - val_mDice: 0.4144

Epoch 00004: val_mDice improved from 0.41305 to 0.41441, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 19s - loss: 5864.3724 - acc: 0.9031 - mDice: 0.4671 - val_loss: 5587.7207 - val_acc: 0.9131 - val_mDice: 0.4631

Epoch 00005: val_mDice improved from 0.41441 to 0.46311, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 19s - loss: 5441.6143 - acc: 0.9076 - mDice: 0.4927 - val_loss: 5567.5701 - val_acc: 0.9159 - val_mDice: 0.4671

Epoch 00006: val_mDice improved from 0.46311 to 0.46705, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 19s - loss: 5095.1557 - acc: 0.9118 - mDice: 0.5145 - val_loss: 5308.9063 - val_acc: 0.9216 - val_mDice: 0.4836

Epoch 00007: val_mDice improved from 0.46705 to 0.48364, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 19s - loss: 4839.7895 - acc: 0.9153 - mDice: 0.5307 - val_loss: 5076.2984 - val_acc: 0.9224 - val_mDice: 0.4977

Epoch 00008: val_mDice improved from 0.48364 to 0.49775, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 19s - loss: 4674.3294 - acc: 0.9180 - mDice: 0.5419 - val_loss: 5671.8425 - val_acc: 0.9049 - val_mDice: 0.4595

Epoch 00009: val_mDice did not improve from 0.49775
Epoch 10/300
 - 19s - loss: 4451.0343 - acc: 0.9206 - mDice: 0.5573 - val_loss: 4812.1664 - val_acc: 0.9247 - val_mDice: 0.5142

Epoch 00010: val_mDice improved from 0.49775 to 0.51423, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 18s - loss: 4335.9197 - acc: 0.9223 - mDice: 0.5656 - val_loss: 4961.3733 - val_acc: 0.9196 - val_mDice: 0.5037

Epoch 00011: val_mDice did not improve from 0.51423
Epoch 12/300
 - 19s - loss: 4202.8221 - acc: 0.9240 - mDice: 0.5752 - val_loss: 4737.6749 - val_acc: 0.9301 - val_mDice: 0.5203

Epoch 00012: val_mDice improved from 0.51423 to 0.52033, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 19s - loss: 4092.5129 - acc: 0.9255 - mDice: 0.5837 - val_loss: 4856.0514 - val_acc: 0.9220 - val_mDice: 0.5111

Epoch 00013: val_mDice did not improve from 0.52033
Epoch 14/300
 - 19s - loss: 3994.2284 - acc: 0.9268 - mDice: 0.5908 - val_loss: 4919.2301 - val_acc: 0.9116 - val_mDice: 0.5044

Epoch 00014: val_mDice did not improve from 0.52033
Epoch 15/300
 - 19s - loss: 3923.9812 - acc: 0.9275 - mDice: 0.5963 - val_loss: 4872.9474 - val_acc: 0.9181 - val_mDice: 0.5092

Epoch 00015: val_mDice did not improve from 0.52033
Epoch 16/300
 - 19s - loss: 3850.2964 - acc: 0.9283 - mDice: 0.6021 - val_loss: 4741.0932 - val_acc: 0.9185 - val_mDice: 0.5197

Epoch 00016: val_mDice did not improve from 0.52033
Epoch 17/300
 - 19s - loss: 3790.8011 - acc: 0.9293 - mDice: 0.6068 - val_loss: 4607.0824 - val_acc: 0.9274 - val_mDice: 0.5297

Epoch 00017: val_mDice improved from 0.52033 to 0.52966, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 19s - loss: 3748.5630 - acc: 0.9296 - mDice: 0.6100 - val_loss: 5167.4134 - val_acc: 0.9289 - val_mDice: 0.4988

Epoch 00018: val_mDice did not improve from 0.52966
Epoch 19/300
 - 19s - loss: 3703.6515 - acc: 0.9303 - mDice: 0.6149 - val_loss: 4543.5734 - val_acc: 0.9292 - val_mDice: 0.5332

Epoch 00019: val_mDice improved from 0.52966 to 0.53319, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 20/300
 - 18s - loss: 3607.6842 - acc: 0.9313 - mDice: 0.6212 - val_loss: 4757.0539 - val_acc: 0.9173 - val_mDice: 0.5125

Epoch 00020: val_mDice did not improve from 0.53319
Epoch 21/300
 - 19s - loss: 3578.0592 - acc: 0.9319 - mDice: 0.6237 - val_loss: 4532.8418 - val_acc: 0.9295 - val_mDice: 0.5340

Epoch 00021: val_mDice improved from 0.53319 to 0.53403, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 22/300
 - 19s - loss: 3545.0780 - acc: 0.9323 - mDice: 0.6265 - val_loss: 4336.6324 - val_acc: 0.9261 - val_mDice: 0.5469

Epoch 00022: val_mDice improved from 0.53403 to 0.54689, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 23/300
 - 19s - loss: 3497.5340 - acc: 0.9330 - mDice: 0.6304 - val_loss: 4290.1025 - val_acc: 0.9326 - val_mDice: 0.5502

Epoch 00023: val_mDice improved from 0.54689 to 0.55025, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 24/300
 - 18s - loss: 3436.6869 - acc: 0.9334 - mDice: 0.6351 - val_loss: 4557.4686 - val_acc: 0.9351 - val_mDice: 0.5346

Epoch 00024: val_mDice did not improve from 0.55025
Epoch 25/300
 - 19s - loss: 3424.8687 - acc: 0.9337 - mDice: 0.6364 - val_loss: 4533.3074 - val_acc: 0.9240 - val_mDice: 0.5333

Epoch 00025: val_mDice did not improve from 0.55025
Epoch 26/300
 - 19s - loss: 3379.1198 - acc: 0.9343 - mDice: 0.6400 - val_loss: 4355.6853 - val_acc: 0.9269 - val_mDice: 0.5466

Epoch 00026: val_mDice did not improve from 0.55025
Epoch 27/300
 - 19s - loss: 3351.0874 - acc: 0.9345 - mDice: 0.6425 - val_loss: 4513.5391 - val_acc: 0.9208 - val_mDice: 0.5303

Epoch 00027: val_mDice did not improve from 0.55025
Epoch 28/300
 - 19s - loss: 3350.7702 - acc: 0.9348 - mDice: 0.6426 - val_loss: 4374.4982 - val_acc: 0.9347 - val_mDice: 0.5478

Epoch 00028: val_mDice did not improve from 0.55025
Epoch 29/300
 - 19s - loss: 3284.7572 - acc: 0.9354 - mDice: 0.6481 - val_loss: 4366.2535 - val_acc: 0.9317 - val_mDice: 0.5465

Epoch 00029: val_mDice did not improve from 0.55025
Epoch 30/300
 - 19s - loss: 3287.4726 - acc: 0.9354 - mDice: 0.6480 - val_loss: 4271.4931 - val_acc: 0.9376 - val_mDice: 0.5539

Epoch 00030: val_mDice improved from 0.55025 to 0.55391, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 31/300
 - 19s - loss: 3261.7140 - acc: 0.9357 - mDice: 0.6500 - val_loss: 4254.5558 - val_acc: 0.9295 - val_mDice: 0.5533

Epoch 00031: val_mDice did not improve from 0.55391
Epoch 32/300
 - 19s - loss: 3212.8524 - acc: 0.9362 - mDice: 0.6541 - val_loss: 4261.3630 - val_acc: 0.9315 - val_mDice: 0.5522

Epoch 00032: val_mDice did not improve from 0.55391
Epoch 33/300
 - 19s - loss: 3215.5057 - acc: 0.9363 - mDice: 0.6539 - val_loss: 4214.2293 - val_acc: 0.9328 - val_mDice: 0.5571

Epoch 00033: val_mDice improved from 0.55391 to 0.55705, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 34/300
 - 19s - loss: 3171.3428 - acc: 0.9365 - mDice: 0.6576 - val_loss: 4367.7007 - val_acc: 0.9313 - val_mDice: 0.5457

Epoch 00034: val_mDice did not improve from 0.55705
Epoch 35/300
 - 19s - loss: 3170.1670 - acc: 0.9367 - mDice: 0.6578 - val_loss: 4403.5428 - val_acc: 0.9309 - val_mDice: 0.5434

Epoch 00035: val_mDice did not improve from 0.55705
Epoch 36/300
 - 19s - loss: 3134.7270 - acc: 0.9371 - mDice: 0.6607 - val_loss: 4658.2924 - val_acc: 0.9356 - val_mDice: 0.5268

Epoch 00036: val_mDice did not improve from 0.55705
Epoch 37/300
 - 18s - loss: 3128.9066 - acc: 0.9372 - mDice: 0.6613 - val_loss: 4241.0145 - val_acc: 0.9349 - val_mDice: 0.5547

Epoch 00037: val_mDice did not improve from 0.55705
Epoch 38/300
 - 19s - loss: 3105.6988 - acc: 0.9374 - mDice: 0.6632 - val_loss: 4199.3834 - val_acc: 0.9341 - val_mDice: 0.5575

Epoch 00038: val_mDice improved from 0.55705 to 0.55749, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 39/300
 - 19s - loss: 3092.6558 - acc: 0.9375 - mDice: 0.6644 - val_loss: 4237.0629 - val_acc: 0.9301 - val_mDice: 0.5523

Epoch 00039: val_mDice did not improve from 0.55749
Epoch 40/300
 - 19s - loss: 3075.7203 - acc: 0.9378 - mDice: 0.6660 - val_loss: 4429.7782 - val_acc: 0.9259 - val_mDice: 0.5383

Epoch 00040: val_mDice did not improve from 0.55749
Epoch 41/300
 - 19s - loss: 3038.5328 - acc: 0.9381 - mDice: 0.6689 - val_loss: 4276.5701 - val_acc: 0.9261 - val_mDice: 0.5492

Epoch 00041: val_mDice did not improve from 0.55749
Epoch 42/300
 - 19s - loss: 3029.5664 - acc: 0.9383 - mDice: 0.6699 - val_loss: 4481.5922 - val_acc: 0.9282 - val_mDice: 0.5352

Epoch 00042: val_mDice did not improve from 0.55749
Epoch 43/300
 - 19s - loss: 3019.4998 - acc: 0.9384 - mDice: 0.6708 - val_loss: 4233.4699 - val_acc: 0.9301 - val_mDice: 0.5521

Epoch 00043: val_mDice did not improve from 0.55749
Epoch 44/300
 - 19s - loss: 3003.6970 - acc: 0.9385 - mDice: 0.6720 - val_loss: 4290.7913 - val_acc: 0.9329 - val_mDice: 0.5490

Epoch 00044: val_mDice did not improve from 0.55749
Epoch 45/300
 - 19s - loss: 2987.3296 - acc: 0.9388 - mDice: 0.6736 - val_loss: 4390.9810 - val_acc: 0.9281 - val_mDice: 0.5410

Epoch 00045: val_mDice did not improve from 0.55749
Epoch 46/300
 - 19s - loss: 2990.5491 - acc: 0.9387 - mDice: 0.6734 - val_loss: 4263.2804 - val_acc: 0.9330 - val_mDice: 0.5522

Epoch 00046: val_mDice did not improve from 0.55749
Epoch 47/300
 - 19s - loss: 2961.3092 - acc: 0.9391 - mDice: 0.6757 - val_loss: 4242.7897 - val_acc: 0.9311 - val_mDice: 0.5521

Epoch 00047: val_mDice did not improve from 0.55749
Epoch 48/300
 - 19s - loss: 2951.5784 - acc: 0.9392 - mDice: 0.6766 - val_loss: 4212.8931 - val_acc: 0.9346 - val_mDice: 0.5573

Epoch 00048: val_mDice did not improve from 0.55749
Epoch 49/300
 - 19s - loss: 2943.8458 - acc: 0.9392 - mDice: 0.6773 - val_loss: 4464.8954 - val_acc: 0.9357 - val_mDice: 0.5394

Epoch 00049: val_mDice did not improve from 0.55749
Epoch 50/300
 - 19s - loss: 2911.9725 - acc: 0.9395 - mDice: 0.6802 - val_loss: 4263.4943 - val_acc: 0.9391 - val_mDice: 0.5516

Epoch 00050: val_mDice did not improve from 0.55749
Epoch 51/300
 - 17s - loss: 2925.2059 - acc: 0.9395 - mDice: 0.6790 - val_loss: 4264.8743 - val_acc: 0.9346 - val_mDice: 0.5510

Epoch 00051: val_mDice did not improve from 0.55749
Epoch 52/300
 - 19s - loss: 2911.7494 - acc: 0.9396 - mDice: 0.6803 - val_loss: 4511.9235 - val_acc: 0.9287 - val_mDice: 0.5346

Epoch 00052: val_mDice did not improve from 0.55749
Epoch 53/300
 - 19s - loss: 2907.7094 - acc: 0.9396 - mDice: 0.6805 - val_loss: 4181.0295 - val_acc: 0.9362 - val_mDice: 0.5574

Epoch 00053: val_mDice did not improve from 0.55749
Epoch 54/300
 - 19s - loss: 2870.3492 - acc: 0.9400 - mDice: 0.6837 - val_loss: 4316.5684 - val_acc: 0.9283 - val_mDice: 0.5457

Epoch 00054: val_mDice did not improve from 0.55749
Epoch 55/300
 - 19s - loss: 2866.3800 - acc: 0.9400 - mDice: 0.6842 - val_loss: 4673.4361 - val_acc: 0.9340 - val_mDice: 0.5261

Epoch 00055: val_mDice did not improve from 0.55749
Epoch 56/300
 - 19s - loss: 2872.7060 - acc: 0.9400 - mDice: 0.6837 - val_loss: 4146.3850 - val_acc: 0.9343 - val_mDice: 0.5601

Epoch 00056: val_mDice improved from 0.55749 to 0.56014, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet_TL_NL3_LS_MyJoint_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 57/300
 - 19s - loss: 2864.0925 - acc: 0.9401 - mDice: 0.6843 - val_loss: 4246.8607 - val_acc: 0.9301 - val_mDice: 0.5512

Epoch 00057: val_mDice did not improve from 0.56014
Epoch 58/300
 - 19s - loss: 2843.2536 - acc: 0.9403 - mDice: 0.6862 - val_loss: 4278.9333 - val_acc: 0.9317 - val_mDice: 0.5501

Epoch 00058: val_mDice did not improve from 0.56014
Epoch 59/300
 - 19s - loss: 2834.0664 - acc: 0.9403 - mDice: 0.6869 - val_loss: 4357.7319 - val_acc: 0.9346 - val_mDice: 0.5456

Epoch 00059: val_mDice did not improve from 0.56014
Epoch 60/300
 - 19s - loss: 2841.9300 - acc: 0.9403 - mDice: 0.6862 - val_loss: 4379.0389 - val_acc: 0.9360 - val_mDice: 0.5444

Epoch 00060: val_mDice did not improve from 0.56014
Epoch 61/300
 - 19s - loss: 2806.7385 - acc: 0.9407 - mDice: 0.6895 - val_loss: 4168.8570 - val_acc: 0.9377 - val_mDice: 0.5574

Epoch 00061: val_mDice did not improve from 0.56014
Epoch 62/300
 - 19s - loss: 2796.4512 - acc: 0.9409 - mDice: 0.6904 - val_loss: 4223.8235 - val_acc: 0.9324 - val_mDice: 0.5535

Epoch 00062: val_mDice did not improve from 0.56014
Epoch 63/300
 - 19s - loss: 2787.8731 - acc: 0.9409 - mDice: 0.6910 - val_loss: 4445.2977 - val_acc: 0.9290 - val_mDice: 0.5364

Epoch 00063: val_mDice did not improve from 0.56014
Epoch 64/300
 - 18s - loss: 2814.3478 - acc: 0.9406 - mDice: 0.6889 - val_loss: 4333.5749 - val_acc: 0.9355 - val_mDice: 0.5477

Epoch 00064: val_mDice did not improve from 0.56014
Epoch 65/300
 - 19s - loss: 2786.2766 - acc: 0.9410 - mDice: 0.6913 - val_loss: 4253.2125 - val_acc: 0.9333 - val_mDice: 0.5518

Epoch 00065: val_mDice did not improve from 0.56014
Epoch 66/300
 - 19s - loss: 2784.9506 - acc: 0.9410 - mDice: 0.6914 - val_loss: 4213.1047 - val_acc: 0.9372 - val_mDice: 0.5543

Epoch 00066: val_mDice did not improve from 0.56014
Epoch 67/300
 - 19s - loss: 2763.8599 - acc: 0.9412 - mDice: 0.6933 - val_loss: 4300.6747 - val_acc: 0.9334 - val_mDice: 0.5492

Epoch 00067: val_mDice did not improve from 0.56014
Epoch 68/300
 - 19s - loss: 2756.6101 - acc: 0.9413 - mDice: 0.6939 - val_loss: 4236.6528 - val_acc: 0.9325 - val_mDice: 0.5515

Epoch 00068: val_mDice did not improve from 0.56014
Epoch 69/300
 - 19s - loss: 2752.0218 - acc: 0.9413 - mDice: 0.6944 - val_loss: 4215.4663 - val_acc: 0.9381 - val_mDice: 0.5555
