2019-07-10 20:16:12.417158: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-10 20:16:17.722105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:05:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2019-07-10 20:16:17.722184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-10 20:16:18.082461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-10 20:16:18.082530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-10 20:16:18.082543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-10 20:16:18.082994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)
mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a’: File exists
mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a’: File exists
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using TensorFlow backend.
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:27,  1.57s/it]Loading train:   1%|          | 2/285 [00:02<06:31,  1.38s/it]Loading train:   1%|          | 3/285 [00:03<06:11,  1.32s/it]Loading train:   1%|▏         | 4/285 [00:04<05:27,  1.17s/it]Loading train:   2%|▏         | 5/285 [00:05<05:41,  1.22s/it]Loading train:   2%|▏         | 6/285 [00:06<05:15,  1.13s/it]Loading train:   2%|▏         | 7/285 [00:08<05:34,  1.20s/it]Loading train:   3%|▎         | 8/285 [00:09<05:25,  1.17s/it]Loading train:   3%|▎         | 9/285 [00:10<05:55,  1.29s/it]Loading train:   4%|▎         | 10/285 [00:11<05:21,  1.17s/it]Loading train:   4%|▍         | 11/285 [00:12<04:44,  1.04s/it]Loading train:   4%|▍         | 12/285 [00:13<04:27,  1.02it/s]Loading train:   5%|▍         | 13/285 [00:14<04:07,  1.10it/s]Loading train:   5%|▍         | 14/285 [00:14<04:12,  1.07it/s]Loading train:   5%|▌         | 15/285 [00:15<04:12,  1.07it/s]Loading train:   6%|▌         | 16/285 [00:16<04:15,  1.05it/s]Loading train:   6%|▌         | 17/285 [00:17<03:52,  1.15it/s]Loading train:   6%|▋         | 18/285 [00:18<03:54,  1.14it/s]Loading train:   7%|▋         | 19/285 [00:19<03:47,  1.17it/s]Loading train:   7%|▋         | 20/285 [00:20<03:51,  1.14it/s]Loading train:   7%|▋         | 21/285 [00:21<03:59,  1.10it/s]Loading train:   8%|▊         | 22/285 [00:21<03:41,  1.19it/s]Loading train:   8%|▊         | 23/285 [00:22<03:37,  1.20it/s]Loading train:   8%|▊         | 24/285 [00:23<03:30,  1.24it/s]Loading train:   9%|▉         | 25/285 [00:24<03:30,  1.23it/s]Loading train:   9%|▉         | 26/285 [00:25<03:31,  1.22it/s]Loading train:   9%|▉         | 27/285 [00:25<03:31,  1.22it/s]Loading train:  10%|▉         | 28/285 [00:26<03:42,  1.16it/s]Loading train:  10%|█         | 29/285 [00:27<03:44,  1.14it/s]Loading train:  11%|█         | 30/285 [00:28<03:46,  1.13it/s]Loading train:  11%|█         | 31/285 [00:29<03:55,  1.08it/s]Loading train:  11%|█         | 32/285 [00:30<03:37,  1.16it/s]Loading train:  12%|█▏        | 33/285 [00:31<03:40,  1.14it/s]Loading train:  12%|█▏        | 34/285 [00:32<03:40,  1.14it/s]Loading train:  12%|█▏        | 35/285 [00:33<03:41,  1.13it/s]Loading train:  13%|█▎        | 36/285 [00:33<03:30,  1.18it/s]Loading train:  13%|█▎        | 37/285 [00:34<03:34,  1.16it/s]Loading train:  13%|█▎        | 38/285 [00:35<03:36,  1.14it/s]Loading train:  14%|█▎        | 39/285 [00:36<03:27,  1.19it/s]Loading train:  14%|█▍        | 40/285 [00:37<03:42,  1.10it/s]Loading train:  14%|█▍        | 41/285 [00:38<03:30,  1.16it/s]Loading train:  15%|█▍        | 42/285 [00:39<03:45,  1.08it/s]Loading train:  15%|█▌        | 43/285 [00:40<03:48,  1.06it/s]Loading train:  15%|█▌        | 44/285 [00:41<04:08,  1.03s/it]Loading train:  16%|█▌        | 45/285 [00:42<04:14,  1.06s/it]Loading train:  16%|█▌        | 46/285 [00:43<04:29,  1.13s/it]Loading train:  16%|█▋        | 47/285 [00:44<04:13,  1.06s/it]Loading train:  17%|█▋        | 48/285 [00:45<04:06,  1.04s/it]Loading train:  17%|█▋        | 49/285 [00:47<04:28,  1.14s/it]Loading train:  18%|█▊        | 50/285 [00:48<04:30,  1.15s/it]Loading train:  18%|█▊        | 51/285 [00:49<04:28,  1.15s/it]Loading train:  18%|█▊        | 52/285 [00:50<04:17,  1.10s/it]Loading train:  19%|█▊        | 53/285 [00:51<04:17,  1.11s/it]Loading train:  19%|█▉        | 54/285 [00:52<04:21,  1.13s/it]Loading train:  19%|█▉        | 55/285 [00:53<04:16,  1.12s/it]Loading train:  20%|█▉        | 56/285 [00:55<04:28,  1.17s/it]Loading train:  20%|██        | 57/285 [00:56<04:17,  1.13s/it]Loading train:  20%|██        | 58/285 [00:57<04:10,  1.11s/it]Loading train:  21%|██        | 59/285 [00:58<04:18,  1.14s/it]Loading train:  21%|██        | 60/285 [00:59<04:20,  1.16s/it]Loading train:  21%|██▏       | 61/285 [01:00<04:12,  1.13s/it]Loading train:  22%|██▏       | 62/285 [01:01<04:12,  1.13s/it]Loading train:  22%|██▏       | 63/285 [01:03<04:31,  1.22s/it]Loading train:  22%|██▏       | 64/285 [01:04<04:35,  1.25s/it]Loading train:  23%|██▎       | 65/285 [01:06<04:54,  1.34s/it]Loading train:  23%|██▎       | 66/285 [01:07<05:00,  1.37s/it]Loading train:  24%|██▎       | 67/285 [01:08<04:44,  1.30s/it]Loading train:  24%|██▍       | 68/285 [01:09<04:26,  1.23s/it]Loading train:  24%|██▍       | 69/285 [01:11<04:29,  1.25s/it]Loading train:  25%|██▍       | 70/285 [01:12<04:23,  1.22s/it]Loading train:  25%|██▍       | 71/285 [01:13<04:19,  1.21s/it]Loading train:  25%|██▌       | 72/285 [01:14<03:56,  1.11s/it]Loading train:  26%|██▌       | 73/285 [01:15<03:57,  1.12s/it]Loading train:  26%|██▌       | 74/285 [01:16<03:49,  1.09s/it]Loading train:  26%|██▋       | 75/285 [01:17<03:41,  1.06s/it]Loading train:  27%|██▋       | 76/285 [01:18<03:54,  1.12s/it]Loading train:  27%|██▋       | 77/285 [01:19<03:44,  1.08s/it]Loading train:  27%|██▋       | 78/285 [01:20<03:42,  1.07s/it]Loading train:  28%|██▊       | 79/285 [01:21<03:36,  1.05s/it]Loading train:  28%|██▊       | 80/285 [01:23<03:53,  1.14s/it]Loading train:  28%|██▊       | 81/285 [01:24<03:38,  1.07s/it]Loading train:  29%|██▉       | 82/285 [01:25<03:34,  1.06s/it]Loading train:  29%|██▉       | 83/285 [01:26<03:35,  1.07s/it]Loading train:  29%|██▉       | 84/285 [01:27<03:32,  1.06s/it]Loading train:  30%|██▉       | 85/285 [01:28<03:39,  1.10s/it]Loading train:  30%|███       | 86/285 [01:29<03:52,  1.17s/it]Loading train:  31%|███       | 87/285 [01:31<04:08,  1.26s/it]Loading train:  31%|███       | 88/285 [01:32<03:54,  1.19s/it]Loading train:  31%|███       | 89/285 [01:33<03:41,  1.13s/it]Loading train:  32%|███▏      | 90/285 [01:34<03:49,  1.17s/it]Loading train:  32%|███▏      | 91/285 [01:35<03:43,  1.15s/it]Loading train:  32%|███▏      | 92/285 [01:36<03:43,  1.16s/it]Loading train:  33%|███▎      | 93/285 [01:38<03:43,  1.16s/it]Loading train:  33%|███▎      | 94/285 [01:39<03:41,  1.16s/it]Loading train:  33%|███▎      | 95/285 [01:40<04:03,  1.28s/it]Loading train:  34%|███▎      | 96/285 [01:42<04:04,  1.29s/it]Loading train:  34%|███▍      | 97/285 [01:43<04:03,  1.29s/it]Loading train:  34%|███▍      | 98/285 [01:44<04:09,  1.34s/it]Loading train:  35%|███▍      | 99/285 [01:46<04:07,  1.33s/it]Loading train:  35%|███▌      | 100/285 [01:47<03:56,  1.28s/it]Loading train:  35%|███▌      | 101/285 [01:48<03:48,  1.24s/it]Loading train:  36%|███▌      | 102/285 [01:49<03:55,  1.29s/it]Loading train:  36%|███▌      | 103/285 [01:51<03:51,  1.27s/it]Loading train:  36%|███▋      | 104/285 [01:52<04:10,  1.38s/it]Loading train:  37%|███▋      | 105/285 [01:54<04:13,  1.41s/it]Loading train:  37%|███▋      | 106/285 [01:55<04:17,  1.44s/it]Loading train:  38%|███▊      | 107/285 [01:57<04:42,  1.59s/it]Loading train:  38%|███▊      | 108/285 [01:59<04:46,  1.62s/it]Loading train:  38%|███▊      | 109/285 [02:00<04:33,  1.56s/it]Loading train:  39%|███▊      | 110/285 [02:02<04:53,  1.68s/it]Loading train:  39%|███▉      | 111/285 [02:04<04:37,  1.59s/it]Loading train:  39%|███▉      | 112/285 [02:06<04:59,  1.73s/it]Loading train:  40%|███▉      | 113/285 [02:07<04:29,  1.56s/it]Loading train:  40%|████      | 114/285 [02:08<04:34,  1.61s/it]Loading train:  40%|████      | 115/285 [02:11<04:56,  1.74s/it]Loading train:  41%|████      | 116/285 [02:12<04:53,  1.74s/it]Loading train:  41%|████      | 117/285 [02:14<04:39,  1.66s/it]Loading train:  41%|████▏     | 118/285 [02:15<04:36,  1.66s/it]Loading train:  42%|████▏     | 119/285 [02:18<05:13,  1.89s/it]Loading train:  42%|████▏     | 120/285 [02:20<05:22,  1.96s/it]Loading train:  42%|████▏     | 121/285 [02:22<05:40,  2.08s/it]Loading train:  43%|████▎     | 122/285 [02:25<06:04,  2.24s/it]Loading train:  43%|████▎     | 123/285 [02:27<06:05,  2.26s/it]Loading train:  44%|████▎     | 124/285 [02:29<05:38,  2.10s/it]Loading train:  44%|████▍     | 125/285 [02:31<05:22,  2.02s/it]Loading train:  44%|████▍     | 126/285 [02:32<04:38,  1.75s/it]Loading train:  45%|████▍     | 127/285 [02:33<04:26,  1.69s/it]Loading train:  45%|████▍     | 128/285 [02:35<04:27,  1.71s/it]Loading train:  45%|████▌     | 129/285 [02:37<04:20,  1.67s/it]Loading train:  46%|████▌     | 130/285 [02:38<04:05,  1.58s/it]Loading train:  46%|████▌     | 131/285 [02:40<04:19,  1.69s/it]Loading train:  46%|████▋     | 132/285 [02:42<04:20,  1.70s/it]Loading train:  47%|████▋     | 133/285 [02:44<04:17,  1.69s/it]Loading train:  47%|████▋     | 134/285 [02:45<04:22,  1.74s/it]Loading train:  47%|████▋     | 135/285 [02:47<04:23,  1.76s/it]Loading train:  48%|████▊     | 136/285 [02:50<04:53,  1.97s/it]Loading train:  48%|████▊     | 137/285 [02:52<05:03,  2.05s/it]Loading train:  48%|████▊     | 138/285 [02:54<04:47,  1.96s/it]Loading train:  49%|████▉     | 139/285 [02:55<04:20,  1.78s/it]Loading train:  49%|████▉     | 140/285 [02:56<04:04,  1.69s/it]Loading train:  49%|████▉     | 141/285 [02:59<04:24,  1.83s/it]Loading train:  50%|████▉     | 142/285 [03:00<04:20,  1.82s/it]Loading train:  50%|█████     | 143/285 [03:02<04:04,  1.72s/it]Loading train:  51%|█████     | 144/285 [03:04<04:20,  1.84s/it]Loading train:  51%|█████     | 145/285 [03:06<04:26,  1.90s/it]Loading train:  51%|█████     | 146/285 [03:07<03:59,  1.72s/it]Loading train:  52%|█████▏    | 147/285 [03:09<03:32,  1.54s/it]Loading train:  52%|█████▏    | 148/285 [03:10<03:24,  1.49s/it]Loading train:  52%|█████▏    | 149/285 [03:11<03:23,  1.50s/it]Loading train:  53%|█████▎    | 150/285 [03:13<03:28,  1.55s/it]Loading train:  53%|█████▎    | 151/285 [03:15<03:49,  1.71s/it]Loading train:  53%|█████▎    | 152/285 [03:17<03:50,  1.73s/it]Loading train:  54%|█████▎    | 153/285 [03:19<03:52,  1.76s/it]Loading train:  54%|█████▍    | 154/285 [03:21<03:58,  1.82s/it]Loading train:  54%|█████▍    | 155/285 [03:22<03:24,  1.57s/it]Loading train:  55%|█████▍    | 156/285 [03:24<03:44,  1.74s/it]Loading train:  55%|█████▌    | 157/285 [03:25<03:38,  1.70s/it]Loading train:  55%|█████▌    | 158/285 [03:27<03:30,  1.66s/it]Loading train:  56%|█████▌    | 159/285 [03:29<03:40,  1.75s/it]Loading train:  56%|█████▌    | 160/285 [03:31<03:58,  1.91s/it]Loading train:  56%|█████▋    | 161/285 [03:33<04:00,  1.94s/it]Loading train:  57%|█████▋    | 162/285 [03:35<03:57,  1.93s/it]Loading train:  57%|█████▋    | 163/285 [03:37<03:58,  1.96s/it]Loading train:  58%|█████▊    | 164/285 [03:39<03:37,  1.80s/it]Loading train:  58%|█████▊    | 165/285 [03:40<03:29,  1.75s/it]Loading train:  58%|█████▊    | 166/285 [03:42<03:40,  1.85s/it]Loading train:  59%|█████▊    | 167/285 [03:44<03:21,  1.71s/it]Loading train:  59%|█████▉    | 168/285 [03:45<03:11,  1.64s/it]Loading train:  59%|█████▉    | 169/285 [03:47<03:08,  1.62s/it]Loading train:  60%|█████▉    | 170/285 [03:49<03:20,  1.74s/it]Loading train:  60%|██████    | 171/285 [03:51<03:28,  1.83s/it]Loading train:  60%|██████    | 172/285 [03:52<03:04,  1.64s/it]Loading train:  61%|██████    | 173/285 [03:54<03:01,  1.62s/it]Loading train:  61%|██████    | 174/285 [03:56<03:10,  1.71s/it]Loading train:  61%|██████▏   | 175/285 [03:57<03:11,  1.74s/it]Loading train:  62%|██████▏   | 176/285 [03:59<03:15,  1.80s/it]Loading train:  62%|██████▏   | 177/285 [04:01<03:08,  1.74s/it]Loading train:  62%|██████▏   | 178/285 [04:02<02:54,  1.63s/it]Loading train:  63%|██████▎   | 179/285 [04:04<03:02,  1.72s/it]Loading train:  63%|██████▎   | 180/285 [04:06<03:01,  1.72s/it]Loading train:  64%|██████▎   | 181/285 [04:08<03:04,  1.78s/it]Loading train:  64%|██████▍   | 182/285 [04:10<03:01,  1.76s/it]Loading train:  64%|██████▍   | 183/285 [04:11<03:02,  1.79s/it]Loading train:  65%|██████▍   | 184/285 [04:13<02:59,  1.78s/it]Loading train:  65%|██████▍   | 185/285 [04:15<03:13,  1.94s/it]Loading train:  65%|██████▌   | 186/285 [04:17<03:06,  1.89s/it]Loading train:  66%|██████▌   | 187/285 [04:19<02:55,  1.79s/it]Loading train:  66%|██████▌   | 188/285 [04:20<02:48,  1.74s/it]Loading train:  66%|██████▋   | 189/285 [04:22<02:38,  1.65s/it]Loading train:  67%|██████▋   | 190/285 [04:23<02:25,  1.53s/it]Loading train:  67%|██████▋   | 191/285 [04:25<02:32,  1.62s/it]Loading train:  67%|██████▋   | 192/285 [04:27<02:30,  1.62s/it]Loading train:  68%|██████▊   | 193/285 [04:28<02:19,  1.51s/it]Loading train:  68%|██████▊   | 194/285 [04:29<02:10,  1.44s/it]Loading train:  68%|██████▊   | 195/285 [04:31<02:18,  1.53s/it]Loading train:  69%|██████▉   | 196/285 [04:33<02:24,  1.62s/it]Loading train:  69%|██████▉   | 197/285 [04:35<02:40,  1.82s/it]Loading train:  69%|██████▉   | 198/285 [04:37<02:42,  1.87s/it]Loading train:  70%|██████▉   | 199/285 [04:38<02:31,  1.76s/it]Loading train:  70%|███████   | 200/285 [04:40<02:25,  1.71s/it]Loading train:  71%|███████   | 201/285 [04:42<02:25,  1.74s/it]Loading train:  71%|███████   | 202/285 [04:44<02:28,  1.79s/it]Loading train:  71%|███████   | 203/285 [04:46<02:28,  1.81s/it]Loading train:  72%|███████▏  | 204/285 [04:48<02:28,  1.83s/it]Loading train:  72%|███████▏  | 205/285 [04:49<02:19,  1.75s/it]Loading train:  72%|███████▏  | 206/285 [04:50<02:03,  1.56s/it]Loading train:  73%|███████▎  | 207/285 [04:52<02:07,  1.63s/it]Loading train:  73%|███████▎  | 208/285 [04:54<02:12,  1.72s/it]Loading train:  73%|███████▎  | 209/285 [04:56<02:09,  1.70s/it]Loading train:  74%|███████▎  | 210/285 [04:57<02:12,  1.76s/it]Loading train:  74%|███████▍  | 211/285 [05:00<02:16,  1.85s/it]Loading train:  74%|███████▍  | 212/285 [05:01<02:09,  1.77s/it]Loading train:  75%|███████▍  | 213/285 [05:03<02:15,  1.88s/it]Loading train:  75%|███████▌  | 214/285 [05:05<02:04,  1.75s/it]Loading train:  75%|███████▌  | 215/285 [05:07<02:07,  1.82s/it]Loading train:  76%|███████▌  | 216/285 [05:08<02:03,  1.79s/it]Loading train:  76%|███████▌  | 217/285 [05:10<02:02,  1.80s/it]Loading train:  76%|███████▋  | 218/285 [05:12<01:53,  1.70s/it]Loading train:  77%|███████▋  | 219/285 [05:13<01:53,  1.72s/it]Loading train:  77%|███████▋  | 220/285 [05:15<01:51,  1.72s/it]Loading train:  78%|███████▊  | 221/285 [05:17<01:49,  1.72s/it]Loading train:  78%|███████▊  | 222/285 [05:19<01:58,  1.87s/it]Loading train:  78%|███████▊  | 223/285 [05:21<01:53,  1.82s/it]Loading train:  79%|███████▊  | 224/285 [05:22<01:47,  1.76s/it]Loading train:  79%|███████▉  | 225/285 [05:24<01:47,  1.79s/it]Loading train:  79%|███████▉  | 226/285 [05:26<01:39,  1.69s/it]Loading train:  80%|███████▉  | 227/285 [05:27<01:33,  1.61s/it]Loading train:  80%|████████  | 228/285 [05:29<01:33,  1.64s/it]Loading train:  80%|████████  | 229/285 [05:31<01:35,  1.70s/it]Loading train:  81%|████████  | 230/285 [05:32<01:26,  1.58s/it]Loading train:  81%|████████  | 231/285 [05:34<01:38,  1.82s/it]Loading train:  81%|████████▏ | 232/285 [05:36<01:37,  1.83s/it]Loading train:  82%|████████▏ | 233/285 [05:38<01:26,  1.67s/it]Loading train:  82%|████████▏ | 234/285 [05:39<01:26,  1.70s/it]Loading train:  82%|████████▏ | 235/285 [05:41<01:22,  1.64s/it]Loading train:  83%|████████▎ | 236/285 [05:43<01:23,  1.70s/it]Loading train:  83%|████████▎ | 237/285 [05:45<01:29,  1.86s/it]Loading train:  84%|████████▎ | 238/285 [05:46<01:23,  1.77s/it]Loading train:  84%|████████▍ | 239/285 [05:48<01:17,  1.68s/it]Loading train:  84%|████████▍ | 240/285 [05:50<01:14,  1.66s/it]Loading train:  85%|████████▍ | 241/285 [05:52<01:18,  1.77s/it]Loading train:  85%|████████▍ | 242/285 [05:53<01:17,  1.81s/it]Loading train:  85%|████████▌ | 243/285 [05:55<01:16,  1.81s/it]Loading train:  86%|████████▌ | 244/285 [05:58<01:22,  2.02s/it]Loading train:  86%|████████▌ | 245/285 [05:59<01:13,  1.85s/it]Loading train:  86%|████████▋ | 246/285 [06:01<01:13,  1.88s/it]Loading train:  87%|████████▋ | 247/285 [06:03<01:11,  1.87s/it]Loading train:  87%|████████▋ | 248/285 [06:04<01:03,  1.72s/it]Loading train:  87%|████████▋ | 249/285 [06:06<00:58,  1.62s/it]Loading train:  88%|████████▊ | 250/285 [06:07<00:53,  1.53s/it]Loading train:  88%|████████▊ | 251/285 [06:09<00:58,  1.73s/it]Loading train:  88%|████████▊ | 252/285 [06:11<00:56,  1.71s/it]Loading train:  89%|████████▉ | 253/285 [06:13<00:59,  1.85s/it]Loading train:  89%|████████▉ | 254/285 [06:15<00:58,  1.89s/it]Loading train:  89%|████████▉ | 255/285 [06:17<00:53,  1.78s/it]Loading train:  90%|████████▉ | 256/285 [06:18<00:48,  1.67s/it]Loading train:  90%|█████████ | 257/285 [06:20<00:46,  1.67s/it]Loading train:  91%|█████████ | 258/285 [06:21<00:42,  1.59s/it]Loading train:  91%|█████████ | 259/285 [06:23<00:40,  1.54s/it]Loading train:  91%|█████████ | 260/285 [06:24<00:39,  1.59s/it]Loading train:  92%|█████████▏| 261/285 [06:26<00:35,  1.49s/it]Loading train:  92%|█████████▏| 262/285 [06:27<00:31,  1.38s/it]Loading train:  92%|█████████▏| 263/285 [06:28<00:28,  1.32s/it]Loading train:  93%|█████████▎| 264/285 [06:29<00:29,  1.39s/it]Loading train:  93%|█████████▎| 265/285 [06:31<00:31,  1.56s/it]Loading train:  93%|█████████▎| 266/285 [06:32<00:26,  1.38s/it]Loading train:  94%|█████████▎| 267/285 [06:33<00:22,  1.24s/it]Loading train:  94%|█████████▍| 268/285 [06:35<00:21,  1.29s/it]Loading train:  94%|█████████▍| 269/285 [06:36<00:19,  1.21s/it]Loading train:  95%|█████████▍| 270/285 [06:37<00:18,  1.22s/it]Loading train:  95%|█████████▌| 271/285 [06:38<00:15,  1.13s/it]Loading train:  95%|█████████▌| 272/285 [06:39<00:14,  1.09s/it]Loading train:  96%|█████████▌| 273/285 [06:40<00:12,  1.06s/it]Loading train:  96%|█████████▌| 274/285 [06:41<00:12,  1.13s/it]Loading train:  96%|█████████▋| 275/285 [06:42<00:12,  1.20s/it]Loading train:  97%|█████████▋| 276/285 [06:44<00:10,  1.20s/it]Loading train:  97%|█████████▋| 277/285 [06:44<00:08,  1.08s/it]Loading train:  98%|█████████▊| 278/285 [06:46<00:07,  1.08s/it]Loading train:  98%|█████████▊| 279/285 [06:47<00:06,  1.08s/it]Loading train:  98%|█████████▊| 280/285 [06:48<00:05,  1.10s/it]Loading train:  99%|█████████▊| 281/285 [06:49<00:04,  1.11s/it]Loading train:  99%|█████████▉| 282/285 [06:50<00:03,  1.05s/it]Loading train:  99%|█████████▉| 283/285 [06:51<00:02,  1.21s/it]Loading train: 100%|█████████▉| 284/285 [06:53<00:01,  1.21s/it]Loading train: 100%|██████████| 285/285 [06:54<00:00,  1.28s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|          | 2/285 [00:00<00:20, 13.52it/s]concatenating: train:   2%|▏         | 6/285 [00:00<00:17, 15.54it/s]concatenating: train:   3%|▎         | 8/285 [00:00<00:17, 16.15it/s]concatenating: train:   8%|▊         | 24/285 [00:00<00:11, 22.11it/s]concatenating: train:  15%|█▌        | 44/285 [00:00<00:07, 30.13it/s]concatenating: train:  20%|██        | 58/285 [00:00<00:05, 38.70it/s]concatenating: train:  24%|██▍       | 69/285 [00:00<00:05, 40.81it/s]concatenating: train:  27%|██▋       | 78/285 [00:01<00:04, 43.67it/s]concatenating: train:  30%|███       | 86/285 [00:01<00:05, 36.28it/s]concatenating: train:  33%|███▎      | 93/285 [00:01<00:05, 34.59it/s]concatenating: train:  38%|███▊      | 109/285 [00:01<00:03, 45.07it/s]concatenating: train:  49%|████▉     | 139/285 [00:01<00:02, 60.46it/s]concatenating: train:  54%|█████▍    | 154/285 [00:02<00:02, 59.11it/s]concatenating: train:  58%|█████▊    | 166/285 [00:02<00:01, 61.91it/s]concatenating: train:  62%|██████▏   | 177/285 [00:02<00:01, 58.16it/s]concatenating: train:  65%|██████▌   | 186/285 [00:02<00:02, 48.61it/s]concatenating: train:  68%|██████▊   | 194/285 [00:02<00:01, 49.06it/s]concatenating: train:  71%|███████   | 201/285 [00:03<00:01, 53.34it/s]concatenating: train:  73%|███████▎  | 208/285 [00:03<00:01, 53.80it/s]concatenating: train:  76%|███████▋  | 218/285 [00:03<00:01, 61.53it/s]concatenating: train:  84%|████████▍ | 240/285 [00:03<00:00, 78.13it/s]concatenating: train:  88%|████████▊ | 252/285 [00:03<00:00, 58.62it/s]concatenating: train:  92%|█████████▏| 262/285 [00:04<00:00, 50.07it/s]concatenating: train:  95%|█████████▍| 270/285 [00:04<00:00, 47.21it/s]concatenating: train:  97%|█████████▋| 277/285 [00:04<00:00, 46.12it/s]concatenating: train:  99%|█████████▉| 283/285 [00:04<00:00, 48.13it/s]concatenating: train: 100%|██████████| 285/285 [00:04<00:00, 63.44it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.71s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.68s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.53s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 37.70it/s]
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.91it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:05,  7.03it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  6.66it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  8.49it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:01<00:08,  4.02it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:02<00:11,  2.87it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:02<00:09,  3.34it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:02<00:05,  4.55it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:04,  5.52it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:03<00:04,  5.35it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:03<00:02,  6.90it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  7.73it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  8.55it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:04<00:01,  7.56it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:05<00:01,  5.75it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:05<00:01,  5.92it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:06<00:01,  4.00it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:06<00:00,  4.98it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:06<00:00,  5.19it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:06<00:00,  6.91it/s]---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 30)   4080        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 40, 45)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 60)   24360       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 20, 105)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 105)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 105)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 105)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 15)   4065        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 45)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 45)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 13)   598         dropout_5[0][0]                  
==================================================================================================
Total params: 126,478
Trainable params: 28,018
Non-trainable params: 98,460
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 16s - loss: 3.0767 - acc: 0.6100 - mDice: 0.0862 - val_loss: 2.7069 - val_acc: 0.9015 - val_mDice: 0.1757

Epoch 00001: val_mDice improved from -inf to 0.17570, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 7s - loss: 1.3256 - acc: 0.8747 - mDice: 0.2856 - val_loss: 2.5644 - val_acc: 0.9071 - val_mDice: 0.2090

Epoch 00002: val_mDice improved from 0.17570 to 0.20897, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 7s - loss: 0.7733 - acc: 0.8941 - mDice: 0.4479 - val_loss: 1.3337 - val_acc: 0.9242 - val_mDice: 0.4366

Epoch 00003: val_mDice improved from 0.20897 to 0.43657, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 8s - loss: 0.6488 - acc: 0.9086 - mDice: 0.5081 - val_loss: 1.1367 - val_acc: 0.9212 - val_mDice: 0.4961

Epoch 00004: val_mDice improved from 0.43657 to 0.49612, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 8s - loss: 0.5951 - acc: 0.9155 - mDice: 0.5367 - val_loss: 1.0384 - val_acc: 0.9351 - val_mDice: 0.5510

Epoch 00005: val_mDice improved from 0.49612 to 0.55101, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 7s - loss: 0.5583 - acc: 0.9187 - mDice: 0.5574 - val_loss: 1.0222 - val_acc: 0.9399 - val_mDice: 0.5545

Epoch 00006: val_mDice improved from 0.55101 to 0.55448, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 8s - loss: 0.5300 - acc: 0.9206 - mDice: 0.5732 - val_loss: 1.0226 - val_acc: 0.9343 - val_mDice: 0.5453

Epoch 00007: val_mDice did not improve from 0.55448
Epoch 8/300
 - 7s - loss: 0.5083 - acc: 0.9223 - mDice: 0.5859 - val_loss: 1.0140 - val_acc: 0.9367 - val_mDice: 0.5328

Epoch 00008: val_mDice did not improve from 0.55448
Epoch 9/300
 - 7s - loss: 0.4949 - acc: 0.9233 - mDice: 0.5940 - val_loss: 1.0044 - val_acc: 0.9440 - val_mDice: 0.5445

Epoch 00009: val_mDice did not improve from 0.55448
Epoch 10/300
 - 8s - loss: 0.4826 - acc: 0.9243 - mDice: 0.6015 - val_loss: 0.9562 - val_acc: 0.9445 - val_mDice: 0.5548

Epoch 00010: val_mDice improved from 0.55448 to 0.55478, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 7s - loss: 0.4714 - acc: 0.9256 - mDice: 0.6086 - val_loss: 0.9191 - val_acc: 0.9442 - val_mDice: 0.5559

Epoch 00011: val_mDice improved from 0.55478 to 0.55592, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 7s - loss: 0.4623 - acc: 0.9262 - mDice: 0.6144 - val_loss: 0.9829 - val_acc: 0.9435 - val_mDice: 0.5305

Epoch 00012: val_mDice did not improve from 0.55592
Epoch 13/300
 - 7s - loss: 0.4545 - acc: 0.9271 - mDice: 0.6195 - val_loss: 0.9179 - val_acc: 0.9452 - val_mDice: 0.5628

Epoch 00013: val_mDice improved from 0.55592 to 0.56279, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 7s - loss: 0.4464 - acc: 0.9278 - mDice: 0.6247 - val_loss: 0.9429 - val_acc: 0.9449 - val_mDice: 0.5449

Epoch 00014: val_mDice did not improve from 0.56279
Epoch 15/300
 - 7s - loss: 0.4402 - acc: 0.9283 - mDice: 0.6285 - val_loss: 0.9093 - val_acc: 0.9446 - val_mDice: 0.5505

Epoch 00015: val_mDice did not improve from 0.56279
Epoch 16/300
 - 7s - loss: 0.4354 - acc: 0.9288 - mDice: 0.6317 - val_loss: 0.8707 - val_acc: 0.9415 - val_mDice: 0.5621

Epoch 00016: val_mDice did not improve from 0.56279
Epoch 17/300
 - 7s - loss: 0.4292 - acc: 0.9293 - mDice: 0.6358 - val_loss: 0.8744 - val_acc: 0.9364 - val_mDice: 0.5413

Epoch 00017: val_mDice did not improve from 0.56279
Epoch 18/300
 - 7s - loss: 0.4252 - acc: 0.9297 - mDice: 0.6383 - val_loss: 0.8709 - val_acc: 0.9436 - val_mDice: 0.5555

Epoch 00018: val_mDice did not improve from 0.56279
Epoch 19/300
 - 7s - loss: 0.4227 - acc: 0.9300 - mDice: 0.6401 - val_loss: 0.8380 - val_acc: 0.9453 - val_mDice: 0.5710

Epoch 00019: val_mDice improved from 0.56279 to 0.57104, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 20/300
 - 7s - loss: 0.4168 - acc: 0.9305 - mDice: 0.6441 - val_loss: 0.8544 - val_acc: 0.9368 - val_mDice: 0.5486

Epoch 00020: val_mDice did not improve from 0.57104
Epoch 21/300
 - 7s - loss: 0.4133 - acc: 0.9309 - mDice: 0.6463 - val_loss: 0.8461 - val_acc: 0.9451 - val_mDice: 0.5607

Epoch 00021: val_mDice did not improve from 0.57104
Epoch 22/300
 - 7s - loss: 0.4104 - acc: 0.9309 - mDice: 0.6483 - val_loss: 0.8411 - val_acc: 0.9403 - val_mDice: 0.5298

Epoch 00022: val_mDice did not improve from 0.57104
Epoch 23/300
 - 7s - loss: 0.4077 - acc: 0.9314 - mDice: 0.6501 - val_loss: 0.8697 - val_acc: 0.9434 - val_mDice: 0.5345

Epoch 00023: val_mDice did not improve from 0.57104
Epoch 24/300
 - 7s - loss: 0.4047 - acc: 0.9316 - mDice: 0.6522 - val_loss: 0.8294 - val_acc: 0.9420 - val_mDice: 0.5380

Epoch 00024: val_mDice did not improve from 0.57104
Epoch 25/300
 - 7s - loss: 0.4000 - acc: 0.9321 - mDice: 0.6554 - val_loss: 0.9187 - val_acc: 0.9340 - val_mDice: 0.5297

Epoch 00025: val_mDice did not improve from 0.57104
Epoch 26/300
 - 7s - loss: 0.3978 - acc: 0.9324 - mDice: 0.6570 - val_loss: 0.8383 - val_acc: 0.9445 - val_mDice: 0.5349

Epoch 00026: val_mDice did not improve from 0.57104
Epoch 27/300
 - 7s - loss: 0.3948 - acc: 0.9326 - mDice: 0.6588 - val_loss: 0.8168 - val_acc: 0.9424 - val_mDice: 0.5503

Epoch 00027: val_mDice did not improve from 0.57104
Epoch 28/300
 - 7s - loss: 0.3938 - acc: 0.9325 - mDice: 0.6595 - val_loss: 0.8380 - val_acc: 0.9336 - val_mDice: 0.5322

Epoch 00028: val_mDice did not improve from 0.57104
Epoch 29/300
 - 7s - loss: 0.3901 - acc: 0.9329 - mDice: 0.6622 - val_loss: 0.8417 - val_acc: 0.9415 - val_mDice: 0.5513

Epoch 00029: val_mDice did not improve from 0.57104
Epoch 30/300
 - 7s - loss: 0.3903 - acc: 0.9329 - mDice: 0.6620 - val_loss: 0.8167 - val_acc: 0.9425 - val_mDice: 0.5340

Epoch 00030: val_mDice did not improve from 0.57104
Epoch 31/300
 - 7s - loss: 0.3873 - acc: 0.9332 - mDice: 0.6641 - val_loss: 0.8343 - val_acc: 0.9434 - val_mDice: 0.5329

Epoch 00031: val_mDice did not improve from 0.57104
Epoch 32/300
 - 7s - loss: 0.3833 - acc: 0.9337 - mDice: 0.6668 - val_loss: 0.7816 - val_acc: 0.9423 - val_mDice: 0.5628

Epoch 00032: val_mDice did not improve from 0.57104
Epoch 33/300
 - 7s - loss: 0.3809 - acc: 0.9338 - mDice: 0.6685 - val_loss: 0.7836 - val_acc: 0.9412 - val_mDice: 0.5443

Epoch 00033: val_mDice did not improve from 0.57104
Epoch 34/300
 - 7s - loss: 0.3811 - acc: 0.9339 - mDice: 0.6684 - val_loss: 0.8205 - val_acc: 0.9327 - val_mDice: 0.5398

Epoch 00034: val_mDice did not improve from 0.57104
Epoch 35/300
 - 7s - loss: 0.3784 - acc: 0.9341 - mDice: 0.6702 - val_loss: 0.7959 - val_acc: 0.9391 - val_mDice: 0.5321

Epoch 00035: val_mDice did not improve from 0.57104
Epoch 36/300
 - 7s - loss: 0.3767 - acc: 0.9343 - mDice: 0.6714 - val_loss: 0.7507 - val_acc: 0.9437 - val_mDice: 0.5525

Epoch 00036: val_mDice did not improve from 0.57104
Epoch 37/300
 - 7s - loss: 0.3733 - acc: 0.9346 - mDice: 0.6738 - val_loss: 0.7834 - val_acc: 0.9376 - val_mDice: 0.5520

Epoch 00037: val_mDice did not improve from 0.57104
Epoch 38/300
 - 7s - loss: 0.3732 - acc: 0.9346 - mDice: 0.6737 - val_loss: 0.8563 - val_acc: 0.9306 - val_mDice: 0.5080

Epoch 00038: val_mDice did not improve from 0.57104
Epoch 39/300
 - 7s - loss: 0.3722 - acc: 0.9348 - mDice: 0.6745 - val_loss: 0.7267 - val_acc: 0.9446 - val_mDice: 0.5645

Epoch 00039: val_mDice did not improve from 0.57104
Epoch 40/300
 - 7s - loss: 0.3701 - acc: 0.9349 - mDice: 0.6760 - val_loss: 0.7670 - val_acc: 0.9417 - val_mDice: 0.5392

Epoch 00040: val_mDice did not improve from 0.57104
Epoch 41/300
 - 7s - loss: 0.3676 - acc: 0.9353 - mDice: 0.6777 - val_loss: 0.7204 - val_acc: 0.9445 - val_mDice: 0.5587

Epoch 00041: val_mDice did not improve from 0.57104
Epoch 42/300
 - 7s - loss: 0.3704 - acc: 0.9349 - mDice: 0.6759 - val_loss: 0.7497 - val_acc: 0.9431 - val_mDice: 0.5513

Epoch 00042: val_mDice did not improve from 0.57104
Epoch 43/300
 - 7s - loss: 0.3665 - acc: 0.9354 - mDice: 0.6786 - val_loss: 0.7383 - val_acc: 0.9449 - val_mDice: 0.5504

Epoch 00043: val_mDice did not improve from 0.57104
Epoch 44/300
 - 7s - loss: 0.3666 - acc: 0.9355 - mDice: 0.6784 - val_loss: 0.7769 - val_acc: 0.9396 - val_mDice: 0.5366

Epoch 00044: val_mDice did not improve from 0.57104
Epoch 45/300
 - 7s - loss: 0.3624 - acc: 0.9358 - mDice: 0.6814 - val_loss: 0.7325 - val_acc: 0.9416 - val_mDice: 0.5521

Epoch 00045: val_mDice did not improve from 0.57104
Epoch 46/300
 - 7s - loss: 0.3628 - acc: 0.9359 - mDice: 0.6812 - val_loss: 0.7225 - val_acc: 0.9443 - val_mDice: 0.5442

Epoch 00046: val_mDice did not improve from 0.57104
Epoch 47/300
 - 7s - loss: 0.3609 - acc: 0.9361 - mDice: 0.6825 - val_loss: 0.7723 - val_acc: 0.9380 - val_mDice: 0.5193

Epoch 00047: val_mDice did not improve from 0.57104
Epoch 48/300
 - 7s - loss: 0.3600 - acc: 0.9361 - mDice: 0.6832 - val_loss: 0.7239 - val_acc: 0.9395 - val_mDice: 0.5481

Epoch 00048: val_mDice did not improve from 0.57104
Epoch 49/300
 - 7s - loss: 0.3584 - acc: 0.9364 - mDice: 0.6843 - val_loss: 0.7361 - val_acc: 0.9388 - val_mDice: 0.5530

Epoch 00049: val_mDice did not improve from 0.57104
Epoch 50/300
 - 7s - loss: 0.3595 - acc: 0.9362 - mDice: 0.6835 - val_loss: 0.6848 - val_acc: 0.9402 - val_mDice: 0.5629

Epoch 00050: val_mDice did not improve from 0.57104
Epoch 51/300
 - 7s - loss: 0.3579 - acc: 0.9364 - mDice: 0.6847 - val_loss: 0.7166 - val_acc: 0.9379 - val_mDice: 0.5418

Epoch 00051: val_mDice did not improve from 0.57104
Epoch 52/300
 - 7s - loss: 0.3550 - acc: 0.9367 - mDice: 0.6867 - val_loss: 0.7116 - val_acc: 0.9379 - val_mDice: 0.5531

Epoch 00052: val_mDice did not improve from 0.57104
Epoch 53/300
 - 7s - loss: 0.3567 - acc: 0.9367 - mDice: 0.6856 - val_loss: 0.7240 - val_acc: 0.9414 - val_mDice: 0.5431

Epoch 00053: val_mDice did not improve from 0.57104
Epoch 54/300
 - 7s - loss: 0.3537 - acc: 0.9370 - mDice: 0.6878 - val_loss: 0.7209 - val_acc: 0.9422 - val_mDice: 0.5425

Epoch 00054: val_mDice did not improve from 0.57104
Epoch 55/300
 - 7s - loss: 0.3536 - acc: 0.9370 - mDice: 0.6878 - val_loss: 0.7208 - val_acc: 0.9388 - val_mDice: 0.5461

Epoch 00055: val_mDice did not improve from 0.57104
Epoch 56/300
 - 7s - loss: 0.3532 - acc: 0.9371 - mDice: 0.6881 - val_loss: 0.7111 - val_acc: 0.9404 - val_mDice: 0.5406

Epoch 00056: val_mDice did not improve from 0.57104
Epoch 57/300
 - 7s - loss: 0.3511 - acc: 0.9374 - mDice: 0.6895 - val_loss: 0.6971 - val_acc: 0.9419 - val_mDice: 0.5550

Epoch 00057: val_mDice did not improve from 0.57104
Epoch 58/300
 - 7s - loss: 0.3519 - acc: 0.9373 - mDice: 0.6890 - val_loss: 0.6830 - val_acc: 0.9422 - val_mDice: 0.5449

Epoch 00058: val_mDice did not improve from 0.57104
Epoch 59/300
 - 7s - loss: 0.3507 - acc: 0.9375 - mDice: 0.6899 - val_loss: 0.6975 - val_acc: 0.9415 - val_mDice: 0.5408

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.11s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.91s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.74s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:14,  1.74s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:35,  1.61s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:31,  1.60s/it]predicting train subjects:   1%|▏         | 4/285 [00:05<07:04,  1.51s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:25,  1.59s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:10,  1.54s/it]predicting train subjects:   2%|▏         | 7/285 [00:10<07:27,  1.61s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:25,  1.61s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:51,  1.71s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:05,  1.77s/it]predicting train subjects:   4%|▍         | 11/285 [00:17<07:40,  1.68s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<08:01,  1.76s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:45,  1.71s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<07:55,  1.76s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<08:07,  1.81s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<08:13,  1.84s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<07:52,  1.76s/it]predicting train subjects:   6%|▋         | 18/285 [00:30<07:57,  1.79s/it]predicting train subjects:   7%|▋         | 19/285 [00:32<07:40,  1.73s/it]predicting train subjects:   7%|▋         | 20/285 [00:33<07:43,  1.75s/it]predicting train subjects:   7%|▋         | 21/285 [00:35<07:59,  1.82s/it]predicting train subjects:   8%|▊         | 22/285 [00:37<07:33,  1.73s/it]predicting train subjects:   8%|▊         | 23/285 [00:39<07:37,  1.75s/it]predicting train subjects:   8%|▊         | 24/285 [00:40<07:16,  1.67s/it]predicting train subjects:   9%|▉         | 25/285 [00:42<07:34,  1.75s/it]predicting train subjects:   9%|▉         | 26/285 [00:44<07:41,  1.78s/it]predicting train subjects:   9%|▉         | 27/285 [00:46<07:21,  1.71s/it]predicting train subjects:  10%|▉         | 28/285 [00:47<07:32,  1.76s/it]predicting train subjects:  10%|█         | 29/285 [00:49<07:36,  1.78s/it]predicting train subjects:  11%|█         | 30/285 [00:51<07:44,  1.82s/it]predicting train subjects:  11%|█         | 31/285 [00:53<07:47,  1.84s/it]predicting train subjects:  11%|█         | 32/285 [00:55<07:20,  1.74s/it]predicting train subjects:  12%|█▏        | 33/285 [00:56<07:21,  1.75s/it]predicting train subjects:  12%|█▏        | 34/285 [00:58<07:19,  1.75s/it]predicting train subjects:  12%|█▏        | 35/285 [01:00<07:32,  1.81s/it]predicting train subjects:  13%|█▎        | 36/285 [01:02<07:08,  1.72s/it]predicting train subjects:  13%|█▎        | 37/285 [01:03<07:10,  1.74s/it]predicting train subjects:  13%|█▎        | 38/285 [01:05<07:22,  1.79s/it]predicting train subjects:  14%|█▎        | 39/285 [01:07<07:02,  1.72s/it]predicting train subjects:  14%|█▍        | 40/285 [01:09<07:12,  1.77s/it]predicting train subjects:  14%|█▍        | 41/285 [01:10<06:57,  1.71s/it]predicting train subjects:  15%|█▍        | 42/285 [01:12<06:40,  1.65s/it]predicting train subjects:  15%|█▌        | 43/285 [01:14<06:49,  1.69s/it]predicting train subjects:  15%|█▌        | 44/285 [01:15<07:05,  1.77s/it]predicting train subjects:  16%|█▌        | 45/285 [01:17<06:44,  1.68s/it]predicting train subjects:  16%|█▌        | 46/285 [01:19<06:55,  1.74s/it]predicting train subjects:  16%|█▋        | 47/285 [01:20<06:40,  1.68s/it]predicting train subjects:  17%|█▋        | 48/285 [01:22<06:50,  1.73s/it]predicting train subjects:  17%|█▋        | 49/285 [01:24<07:09,  1.82s/it]predicting train subjects:  18%|█▊        | 50/285 [01:26<07:07,  1.82s/it]predicting train subjects:  18%|█▊        | 51/285 [01:28<07:10,  1.84s/it]predicting train subjects:  18%|█▊        | 52/285 [01:29<06:45,  1.74s/it]predicting train subjects:  19%|█▊        | 53/285 [01:31<06:50,  1.77s/it]predicting train subjects:  19%|█▉        | 54/285 [01:33<06:57,  1.81s/it]predicting train subjects:  19%|█▉        | 55/285 [01:35<06:34,  1.71s/it]predicting train subjects:  20%|█▉        | 56/285 [01:36<06:38,  1.74s/it]predicting train subjects:  20%|██        | 57/285 [01:38<06:22,  1.68s/it]predicting train subjects:  20%|██        | 58/285 [01:40<06:28,  1.71s/it]predicting train subjects:  21%|██        | 59/285 [01:42<06:37,  1.76s/it]predicting train subjects:  21%|██        | 60/285 [01:44<06:44,  1.80s/it]predicting train subjects:  21%|██▏       | 61/285 [01:45<06:27,  1.73s/it]predicting train subjects:  22%|██▏       | 62/285 [01:47<06:28,  1.74s/it]predicting train subjects:  22%|██▏       | 63/285 [01:49<06:26,  1.74s/it]predicting train subjects:  22%|██▏       | 64/285 [01:50<06:13,  1.69s/it]predicting train subjects:  23%|██▎       | 65/285 [01:52<06:24,  1.75s/it]predicting train subjects:  23%|██▎       | 66/285 [01:54<06:21,  1.74s/it]predicting train subjects:  24%|██▎       | 67/285 [01:56<06:24,  1.76s/it]predicting train subjects:  24%|██▍       | 68/285 [01:57<06:11,  1.71s/it]predicting train subjects:  24%|██▍       | 69/285 [01:59<06:10,  1.71s/it]predicting train subjects:  25%|██▍       | 70/285 [02:01<06:12,  1.73s/it]predicting train subjects:  25%|██▍       | 71/285 [02:03<06:19,  1.77s/it]predicting train subjects:  25%|██▌       | 72/285 [02:04<06:07,  1.72s/it]predicting train subjects:  26%|██▌       | 73/285 [02:06<06:03,  1.72s/it]predicting train subjects:  26%|██▌       | 74/285 [02:08<06:03,  1.72s/it]predicting train subjects:  26%|██▋       | 75/285 [02:09<06:02,  1.73s/it]predicting train subjects:  27%|██▋       | 76/285 [02:11<06:06,  1.75s/it]predicting train subjects:  27%|██▋       | 77/285 [02:13<05:54,  1.70s/it]predicting train subjects:  27%|██▋       | 78/285 [02:14<05:47,  1.68s/it]predicting train subjects:  28%|██▊       | 79/285 [02:16<05:48,  1.69s/it]predicting train subjects:  28%|██▊       | 80/285 [02:18<05:45,  1.68s/it]predicting train subjects:  28%|██▊       | 81/285 [02:19<05:37,  1.65s/it]predicting train subjects:  29%|██▉       | 82/285 [02:21<05:39,  1.67s/it]predicting train subjects:  29%|██▉       | 83/285 [02:23<05:29,  1.63s/it]predicting train subjects:  29%|██▉       | 84/285 [02:24<05:24,  1.62s/it]predicting train subjects:  30%|██▉       | 85/285 [02:26<05:31,  1.66s/it]predicting train subjects:  30%|███       | 86/285 [02:28<05:35,  1.68s/it]predicting train subjects:  31%|███       | 87/285 [02:29<05:39,  1.71s/it]predicting train subjects:  31%|███       | 88/285 [02:31<05:29,  1.67s/it]predicting train subjects:  31%|███       | 89/285 [02:33<05:31,  1.69s/it]predicting train subjects:  32%|███▏      | 90/285 [02:35<05:34,  1.71s/it]predicting train subjects:  32%|███▏      | 91/285 [02:36<05:22,  1.66s/it]predicting train subjects:  32%|███▏      | 92/285 [02:38<05:25,  1.69s/it]predicting train subjects:  33%|███▎      | 93/285 [02:39<05:16,  1.65s/it]predicting train subjects:  33%|███▎      | 94/285 [02:41<05:17,  1.66s/it]predicting train subjects:  33%|███▎      | 95/285 [02:43<05:18,  1.68s/it]predicting train subjects:  34%|███▎      | 96/285 [02:44<05:17,  1.68s/it]predicting train subjects:  34%|███▍      | 97/285 [02:46<05:21,  1.71s/it]predicting train subjects:  34%|███▍      | 98/285 [02:48<05:17,  1.70s/it]predicting train subjects:  35%|███▍      | 99/285 [02:50<05:14,  1.69s/it]predicting train subjects:  35%|███▌      | 100/285 [02:51<05:16,  1.71s/it]predicting train subjects:  35%|███▌      | 101/285 [02:53<05:08,  1.68s/it]predicting train subjects:  36%|███▌      | 102/285 [02:55<05:15,  1.72s/it]predicting train subjects:  36%|███▌      | 103/285 [02:56<05:06,  1.68s/it]predicting train subjects:  36%|███▋      | 104/285 [02:58<05:09,  1.71s/it]predicting train subjects:  37%|███▋      | 105/285 [03:00<05:14,  1.75s/it]predicting train subjects:  37%|███▋      | 106/285 [03:02<05:09,  1.73s/it]predicting train subjects:  38%|███▊      | 107/285 [03:04<05:14,  1.77s/it]predicting train subjects:  38%|███▊      | 108/285 [03:05<05:04,  1.72s/it]predicting train subjects:  38%|███▊      | 109/285 [03:07<05:05,  1.74s/it]predicting train subjects:  39%|███▊      | 110/285 [03:09<05:10,  1.77s/it]predicting train subjects:  39%|███▉      | 111/285 [03:10<05:01,  1.73s/it]predicting train subjects:  39%|███▉      | 112/285 [03:12<05:00,  1.74s/it]predicting train subjects:  40%|███▉      | 113/285 [03:14<05:05,  1.77s/it]predicting train subjects:  40%|████      | 114/285 [03:16<05:01,  1.76s/it]predicting train subjects:  40%|████      | 115/285 [03:18<05:00,  1.77s/it]predicting train subjects:  41%|████      | 116/285 [03:19<05:03,  1.80s/it]predicting train subjects:  41%|████      | 117/285 [03:21<04:54,  1.75s/it]predicting train subjects:  41%|████▏     | 118/285 [03:23<04:46,  1.71s/it]predicting train subjects:  42%|████▏     | 119/285 [03:24<04:48,  1.74s/it]predicting train subjects:  42%|████▏     | 120/285 [03:26<04:44,  1.72s/it]predicting train subjects:  42%|████▏     | 121/285 [03:28<04:35,  1.68s/it]predicting train subjects:  43%|████▎     | 122/285 [03:29<04:26,  1.64s/it]predicting train subjects:  43%|████▎     | 123/285 [03:31<04:14,  1.57s/it]predicting train subjects:  44%|████▎     | 124/285 [03:32<04:13,  1.58s/it]predicting train subjects:  44%|████▍     | 125/285 [03:34<04:03,  1.52s/it]predicting train subjects:  44%|████▍     | 126/285 [03:35<03:56,  1.49s/it]predicting train subjects:  45%|████▍     | 127/285 [03:36<03:50,  1.46s/it]predicting train subjects:  45%|████▍     | 128/285 [03:38<03:59,  1.52s/it]predicting train subjects:  45%|████▌     | 129/285 [03:40<03:54,  1.51s/it]predicting train subjects:  46%|████▌     | 130/285 [03:41<03:48,  1.48s/it]predicting train subjects:  46%|████▌     | 131/285 [03:42<03:47,  1.48s/it]predicting train subjects:  46%|████▋     | 132/285 [03:44<03:53,  1.53s/it]predicting train subjects:  47%|████▋     | 133/285 [03:46<03:50,  1.51s/it]predicting train subjects:  47%|████▋     | 134/285 [03:47<03:41,  1.47s/it]predicting train subjects:  47%|████▋     | 135/285 [03:48<03:36,  1.44s/it]predicting train subjects:  48%|████▊     | 136/285 [03:50<03:33,  1.44s/it]predicting train subjects:  48%|████▊     | 137/285 [03:51<03:38,  1.48s/it]predicting train subjects:  48%|████▊     | 138/285 [03:53<03:33,  1.45s/it]predicting train subjects:  49%|████▉     | 139/285 [03:54<03:36,  1.49s/it]predicting train subjects:  49%|████▉     | 140/285 [03:56<03:39,  1.52s/it]predicting train subjects:  49%|████▉     | 141/285 [03:57<03:33,  1.48s/it]predicting train subjects:  50%|████▉     | 142/285 [03:59<03:28,  1.46s/it]predicting train subjects:  50%|█████     | 143/285 [04:00<03:25,  1.45s/it]predicting train subjects:  51%|█████     | 144/285 [04:02<03:30,  1.49s/it]predicting train subjects:  51%|█████     | 145/285 [04:03<03:23,  1.45s/it]predicting train subjects:  51%|█████     | 146/285 [04:05<03:29,  1.50s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:06<03:25,  1.49s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:08<03:26,  1.51s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:09<03:21,  1.48s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:11<03:17,  1.46s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:12<03:21,  1.50s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:14<03:14,  1.46s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:15<03:12,  1.46s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:17<03:16,  1.50s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:18<03:12,  1.48s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:20<03:18,  1.54s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:21<03:11,  1.50s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:23<03:08,  1.48s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:24<03:03,  1.46s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:25<03:02,  1.46s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:27<03:05,  1.49s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:28<03:02,  1.48s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:30<03:07,  1.54s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:32<03:05,  1.53s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:33<03:02,  1.52s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:35<03:03,  1.54s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:36<03:04,  1.56s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:38<02:59,  1.53s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:39<02:56,  1.52s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:41<02:53,  1.50s/it]predicting train subjects:  60%|██████    | 171/285 [04:42<02:49,  1.48s/it]predicting train subjects:  60%|██████    | 172/285 [04:44<02:45,  1.47s/it]predicting train subjects:  61%|██████    | 173/285 [04:45<02:39,  1.43s/it]predicting train subjects:  61%|██████    | 174/285 [04:46<02:36,  1.41s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:48<02:40,  1.46s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:50<02:45,  1.52s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:51<02:40,  1.48s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:52<02:34,  1.44s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:54<02:33,  1.44s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:56<02:43,  1.56s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:57<02:43,  1.57s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:59<02:44,  1.60s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:00<02:36,  1.53s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:02<02:30,  1.49s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:03<02:24,  1.45s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:05<02:34,  1.56s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:07<02:41,  1.65s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:08<02:44,  1.70s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:10<02:35,  1.62s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:11<02:30,  1.58s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:13<02:29,  1.59s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:15<02:27,  1.59s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:16<02:20,  1.52s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:17<02:15,  1.49s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:19<02:10,  1.44s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:21<02:20,  1.58s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:22<02:26,  1.67s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:24<02:27,  1.70s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:26<02:16,  1.59s/it]predicting train subjects:  70%|███████   | 200/285 [05:27<02:09,  1.52s/it]predicting train subjects:  71%|███████   | 201/285 [05:29<02:14,  1.60s/it]predicting train subjects:  71%|███████   | 202/285 [05:30<02:14,  1.62s/it]predicting train subjects:  71%|███████   | 203/285 [05:32<02:13,  1.63s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:33<02:05,  1.54s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:35<02:02,  1.53s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:36<01:57,  1.48s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:38<02:06,  1.62s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:40<02:08,  1.67s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:42<02:12,  1.74s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:43<02:03,  1.64s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:45<01:58,  1.60s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:46<01:57,  1.60s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:48<01:55,  1.60s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:49<01:50,  1.56s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:51<01:56,  1.67s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:53<01:48,  1.58s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:55<01:52,  1.66s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:56<01:54,  1.71s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:58<01:54,  1.74s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:00<01:46,  1.64s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:01<01:40,  1.58s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:03<01:40,  1.60s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:04<01:33,  1.52s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:05<01:32,  1.51s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:07<01:27,  1.46s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:09<01:32,  1.56s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:10<01:34,  1.62s/it]predicting train subjects:  80%|████████  | 228/285 [06:12<01:36,  1.69s/it]predicting train subjects:  80%|████████  | 229/285 [06:14<01:34,  1.69s/it]predicting train subjects:  81%|████████  | 230/285 [06:15<01:26,  1.58s/it]predicting train subjects:  81%|████████  | 231/285 [06:17<01:21,  1.52s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:18<01:22,  1.56s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:20<01:17,  1.49s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:21<01:20,  1.58s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:23<01:16,  1.53s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:25<01:19,  1.61s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:26<01:20,  1.67s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:28<01:20,  1.71s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:30<01:17,  1.69s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:31<01:10,  1.58s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:33<01:07,  1.53s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:34<01:04,  1.49s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:35<01:01,  1.46s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:37<01:04,  1.58s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:39<01:01,  1.53s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:40<01:03,  1.62s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:42<01:03,  1.67s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:44<01:01,  1.65s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:45<00:57,  1.59s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:47<00:55,  1.58s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:48<00:51,  1.52s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:50<00:48,  1.47s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:52<00:51,  1.60s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:53<00:51,  1.67s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:55<00:50,  1.67s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:56<00:45,  1.58s/it]predicting train subjects:  90%|█████████ | 257/285 [06:58<00:43,  1.54s/it]predicting train subjects:  91%|█████████ | 258/285 [07:00<00:44,  1.64s/it]predicting train subjects:  91%|█████████ | 259/285 [07:01<00:42,  1.65s/it]predicting train subjects:  91%|█████████ | 260/285 [07:03<00:39,  1.59s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:04<00:37,  1.56s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:06<00:34,  1.51s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:07<00:32,  1.47s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:09<00:34,  1.62s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:11<00:33,  1.67s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:12<00:30,  1.59s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:14<00:27,  1.54s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:15<00:27,  1.61s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:17<00:25,  1.62s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:19<00:23,  1.56s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:20<00:21,  1.53s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:22<00:20,  1.58s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:23<00:18,  1.54s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:25<00:16,  1.51s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:26<00:16,  1.61s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:28<00:15,  1.68s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:30<00:12,  1.58s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:31<00:10,  1.56s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:33<00:09,  1.58s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:34<00:07,  1.55s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:36<00:06,  1.52s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:37<00:04,  1.48s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:39<00:03,  1.58s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:41<00:01,  1.67s/it]predicting train subjects: 100%|██████████| 285/285 [07:43<00:00,  1.73s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:34,  1.81s/it]Loading train:   1%|          | 2/285 [00:03<07:57,  1.69s/it]Loading train:   1%|          | 3/285 [00:04<07:48,  1.66s/it]Loading train:   1%|▏         | 4/285 [00:06<07:22,  1.58s/it]Loading train:   2%|▏         | 5/285 [00:08<07:45,  1.66s/it]Loading train:   2%|▏         | 6/285 [00:09<07:21,  1.58s/it]Loading train:   2%|▏         | 7/285 [00:11<07:32,  1.63s/it]Loading train:   3%|▎         | 8/285 [00:12<07:17,  1.58s/it]Loading train:   3%|▎         | 9/285 [00:14<07:47,  1.69s/it]Loading train:   4%|▎         | 10/285 [00:15<07:16,  1.59s/it]Loading train:   4%|▍         | 11/285 [00:17<06:52,  1.51s/it]Loading train:   4%|▍         | 12/285 [00:18<06:57,  1.53s/it]Loading train:   5%|▍         | 13/285 [00:20<06:28,  1.43s/it]Loading train:   5%|▍         | 14/285 [00:21<06:09,  1.36s/it]Loading train:   5%|▌         | 15/285 [00:22<06:18,  1.40s/it]Loading train:   6%|▌         | 16/285 [00:24<06:16,  1.40s/it]Loading train:   6%|▌         | 17/285 [00:25<05:42,  1.28s/it]Loading train:   6%|▋         | 18/285 [00:26<05:43,  1.29s/it]Loading train:   7%|▋         | 19/285 [00:27<05:33,  1.26s/it]Loading train:   7%|▋         | 20/285 [00:28<05:33,  1.26s/it]Loading train:   7%|▋         | 21/285 [00:30<05:51,  1.33s/it]Loading train:   8%|▊         | 22/285 [00:31<05:45,  1.31s/it]Loading train:   8%|▊         | 23/285 [00:32<05:27,  1.25s/it]Loading train:   8%|▊         | 24/285 [00:33<05:19,  1.23s/it]Loading train:   9%|▉         | 25/285 [00:35<05:25,  1.25s/it]Loading train:   9%|▉         | 26/285 [00:36<05:46,  1.34s/it]Loading train:   9%|▉         | 27/285 [00:38<05:39,  1.32s/it]Loading train:  10%|▉         | 28/285 [00:39<05:27,  1.27s/it]Loading train:  10%|█         | 29/285 [00:40<05:41,  1.33s/it]Loading train:  11%|█         | 30/285 [00:42<06:08,  1.44s/it]Loading train:  11%|█         | 31/285 [00:43<06:00,  1.42s/it]Loading train:  11%|█         | 32/285 [00:44<05:35,  1.32s/it]Loading train:  12%|█▏        | 33/285 [00:46<05:33,  1.33s/it]Loading train:  12%|█▏        | 34/285 [00:47<05:31,  1.32s/it]Loading train:  12%|█▏        | 35/285 [00:49<06:28,  1.55s/it]Loading train:  13%|█▎        | 36/285 [00:50<06:07,  1.48s/it]Loading train:  13%|█▎        | 37/285 [00:52<06:13,  1.51s/it]Loading train:  13%|█▎        | 38/285 [00:54<06:16,  1.53s/it]Loading train:  14%|█▎        | 39/285 [00:55<05:43,  1.40s/it]Loading train:  14%|█▍        | 40/285 [00:56<05:39,  1.39s/it]Loading train:  14%|█▍        | 41/285 [00:57<05:09,  1.27s/it]Loading train:  15%|█▍        | 42/285 [00:58<05:00,  1.24s/it]Loading train:  15%|█▌        | 43/285 [00:59<05:02,  1.25s/it]Loading train:  15%|█▌        | 44/285 [01:01<05:11,  1.29s/it]Loading train:  16%|█▌        | 45/285 [01:02<04:59,  1.25s/it]Loading train:  16%|█▌        | 46/285 [01:04<05:32,  1.39s/it]Loading train:  16%|█▋        | 47/285 [01:05<05:17,  1.33s/it]Loading train:  17%|█▋        | 48/285 [01:06<05:06,  1.30s/it]Loading train:  17%|█▋        | 49/285 [01:08<05:23,  1.37s/it]Loading train:  18%|█▊        | 50/285 [01:09<05:06,  1.30s/it]Loading train:  18%|█▊        | 51/285 [01:10<05:14,  1.35s/it]Loading train:  18%|█▊        | 52/285 [01:11<04:57,  1.28s/it]Loading train:  19%|█▊        | 53/285 [01:13<04:58,  1.29s/it]Loading train:  19%|█▉        | 54/285 [01:14<05:10,  1.35s/it]Loading train:  19%|█▉        | 55/285 [01:16<05:25,  1.41s/it]Loading train:  20%|█▉        | 56/285 [01:17<05:19,  1.39s/it]Loading train:  20%|██        | 57/285 [01:18<04:50,  1.27s/it]Loading train:  20%|██        | 58/285 [01:19<04:53,  1.29s/it]Loading train:  21%|██        | 59/285 [01:21<05:00,  1.33s/it]Loading train:  21%|██        | 60/285 [01:23<05:26,  1.45s/it]Loading train:  21%|██▏       | 61/285 [01:24<05:27,  1.46s/it]Loading train:  22%|██▏       | 62/285 [01:25<05:05,  1.37s/it]Loading train:  22%|██▏       | 63/285 [01:26<04:55,  1.33s/it]Loading train:  22%|██▏       | 64/285 [01:28<05:10,  1.40s/it]Loading train:  23%|██▎       | 65/285 [01:30<05:35,  1.53s/it]
Epoch 00059: val_mDice did not improve from 0.57104
Restoring model weights from the end of the best epoch
Epoch 00059: early stopping
{'val_loss': [2.7069345655895414, 2.5643790108816966, 1.3336535408383323, 1.1366690681094216, 1.0384295894986106, 1.022172632671538, 1.0226473694755918, 1.0139916510809035, 1.0043713478814988, 0.9562278248014904, 0.9190666334969657, 0.9828765051705497, 0.9179026058741978, 0.9428754761105492, 0.9092741353171212, 0.8706994737897601, 0.874370154880342, 0.8708911623273577, 0.8380324443181356, 0.8544225352151054, 0.8460672469366164, 0.8410749094826835, 0.8697246142796108, 0.8294444765363421, 0.918682166508266, 0.8383424622671944, 0.8167656262715658, 0.8379946322668166, 0.8417180606297084, 0.8166783991314116, 0.8343261310032436, 0.7816120556422642, 0.7835965043022519, 0.8205482619149345, 0.795871689206078, 0.7507486116318476, 0.7833578813643682, 0.8563284760429746, 0.7266524519239154, 0.7670048645564488, 0.7203901608784994, 0.7496502853575207, 0.7382772990635463, 0.7769283680688768, 0.7325317973182315, 0.7225322950453985, 0.7723297732216972, 0.7239405541192918, 0.7360909439268566, 0.6848388285863967, 0.7165543351854596, 0.7116192181905111, 0.7239653042384556, 0.7209102766854423, 0.7208160105205718, 0.7111416203635079, 0.6970589501517159, 0.6829864524659657, 0.6974777834756034], 'val_acc': [0.9014903704325358, 0.9071062491053626, 0.9242467823482695, 0.9212293993859064, 0.9351373485156468, 0.9399221624646869, 0.9342628291675023, 0.9366849632490248, 0.9440384535562425, 0.944450577100118, 0.9442101773761568, 0.9435096014113653, 0.9451602668989272, 0.9448717889331636, 0.9445947664124625, 0.9414972804841542, 0.9364102624711537, 0.9435576654615856, 0.9453159258479163, 0.9367513543083554, 0.9450915540967669, 0.9403365140869504, 0.9433974481764293, 0.9420398587272281, 0.9339583061990284, 0.9444826160158429, 0.9424290344828651, 0.9336126333191281, 0.9414789563133603, 0.9425274502663386, 0.9433631187393552, 0.9423076851027352, 0.941190466994331, 0.9326716916901725, 0.9390590815317064, 0.9436675962947664, 0.9375892593747094, 0.9306066717420306, 0.9446313806942531, 0.9416643636567252, 0.9444619786171686, 0.9430700739224752, 0.9448511969475519, 0.9395627351034255, 0.941636880238851, 0.9443498225439162, 0.9380174108913967, 0.9395329753557841, 0.9387912324496678, 0.9401854503722418, 0.9379280890737262, 0.9378548463185629, 0.9414079842113313, 0.9421955205145336, 0.938839282308306, 0.9404166425977435, 0.9419139254660833, 0.9421955233528501, 0.9414720847493127], 'val_mDice': [0.17570360519346737, 0.20896789956549627, 0.43656960697401137, 0.4961217143351123, 0.5510087776042166, 0.5544760411693936, 0.5453309700602577, 0.5328212215432099, 0.5444777795956248, 0.5547775661661511, 0.5559245479248819, 0.5304912094558988, 0.5627878187667756, 0.5448946459662347, 0.5505434230324768, 0.5621294490993023, 0.5412794163539296, 0.5554555462939399, 0.5710434713179157, 0.5486026439993155, 0.5607045716827824, 0.5297700741461345, 0.5345167815685272, 0.5379697215699014, 0.5297412004853997, 0.5348666618977275, 0.5503430684052762, 0.5322420685773804, 0.5512753551205, 0.5340086870959827, 0.5329490616208031, 0.5628029466384933, 0.544309830913941, 0.5398319283766406, 0.5321359739062332, 0.5525165993188109, 0.5519910018358912, 0.5079666237745967, 0.5644604914954731, 0.5391959782157626, 0.5587267568778425, 0.5513072968238876, 0.5503883163134257, 0.5365747239972863, 0.5521044360385055, 0.5441754619990077, 0.5192798892302173, 0.5480872069795927, 0.552993341393414, 0.5629150189814114, 0.5417540506238029, 0.5530992013712724, 0.5431022890621707, 0.5425472775740283, 0.5461263087178979, 0.5405904359760738, 0.5549942331299895, 0.5449381332312312, 0.5408210715367681], 'loss': [3.0766935944672102, 1.325635044830301, 0.7733270145000372, 0.6487810234010438, 0.5950591414103923, 0.5582742153368682, 0.5299962844167437, 0.5082788525782317, 0.49490534755934035, 0.4825758731144574, 0.47138339832657816, 0.462301980237959, 0.45449318010406686, 0.4463772163791925, 0.4402397722264395, 0.4354280144671427, 0.429237079914535, 0.42520681628032714, 0.4226592765944712, 0.41676044658886485, 0.41328272925582443, 0.4104065739605177, 0.40769436831922, 0.40474204676836606, 0.39997180599409743, 0.3977592498586889, 0.39480381351986304, 0.393841915003523, 0.3900544331876763, 0.39030244554631255, 0.38725549392854636, 0.3833144647159948, 0.3808500531242835, 0.38109824502654266, 0.3784151928707977, 0.3767345120262406, 0.37333151902655126, 0.37319742338216577, 0.37220734275672074, 0.37011237292821086, 0.3676141490073523, 0.37037999624918255, 0.3664636658305305, 0.3666123719212635, 0.3624415322664227, 0.36279343743418047, 0.3609481748586356, 0.3599665252165411, 0.35837098538404444, 0.35948086838076887, 0.35788711830786896, 0.3549981964032085, 0.3567382355795353, 0.3536545674144038, 0.3535853545112327, 0.35323636337514325, 0.35114479588938285, 0.351929636067776, 0.3507437707602415], 'acc': [0.61000483191057, 0.8746613867829387, 0.8940895817310612, 0.9086358639599617, 0.9154950068685069, 0.9187411926880678, 0.9205933421568671, 0.9222833124318517, 0.9233404566884523, 0.9243036186462977, 0.9256014718999287, 0.9261952042234917, 0.9271111882718882, 0.9277888228375258, 0.9283483810155452, 0.9287949908738057, 0.9293144566947976, 0.9297496450069164, 0.9300385070302157, 0.9305076216695303, 0.9308693762893779, 0.9309022348005693, 0.931397302430651, 0.9316441271836895, 0.9320893994939564, 0.9323727436118073, 0.9325598578520172, 0.9324619323618499, 0.9329088907125072, 0.932867696468187, 0.9332255169056918, 0.9336747703281975, 0.9338404024890652, 0.9338585479723274, 0.9340826869125837, 0.9343111599390277, 0.9346315811336304, 0.9346017823390288, 0.9347776104219392, 0.9349251187833628, 0.9352746008792456, 0.9349472517564574, 0.935368237707779, 0.93546055622452, 0.9358385104951037, 0.9358846008467357, 0.9360569979107078, 0.9360568125008479, 0.9364191735436606, 0.936208656649151, 0.9364455866979132, 0.9367422337979739, 0.936732202096093, 0.936992605814521, 0.9369758980017258, 0.937123109948688, 0.9374116442441159, 0.9372935609847841, 0.9374612779062976], 'mDice': [0.08622891026909398, 0.28564787638401146, 0.44792760357315287, 0.508053740589564, 0.5366953725366205, 0.5574094373090018, 0.5732234765827392, 0.5859309893502926, 0.5939810985840421, 0.6014690693228696, 0.6086346490869914, 0.6143556243885637, 0.6194732749372497, 0.6246539350876993, 0.6284727257227011, 0.6316680879245403, 0.6357504792679521, 0.6383154569895759, 0.6400954056066517, 0.6440544856727664, 0.6463425814910089, 0.6482707595052989, 0.650124081566496, 0.652158477942057, 0.6553637633347571, 0.656989535684183, 0.6588181711148728, 0.6595286691903562, 0.6621562577590148, 0.6620400782056183, 0.664090864456571, 0.6668143814782634, 0.6685319650212257, 0.6683889871528894, 0.6702173962307179, 0.6714330589998796, 0.6737675034565481, 0.6737311353613605, 0.6745304788425291, 0.6760174343299609, 0.677738722209092, 0.6758917732828955, 0.6785719471444784, 0.6784395847519124, 0.6813700493415794, 0.6811794900747078, 0.6824623250722287, 0.6831988294344774, 0.6843080188765194, 0.6835211657457368, 0.6846846217522622, 0.6866766732736936, 0.6856330384954405, 0.6877579809453231, 0.6877877820266656, 0.6880514810074725, 0.6895153724735864, 0.6890073147770617, 0.6899410423939228]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0Loading train:  23%|██▎       | 66/285 [01:31<05:37,  1.54s/it]Loading train:  24%|██▎       | 67/285 [01:33<05:31,  1.52s/it]Loading train:  24%|██▍       | 68/285 [01:34<05:19,  1.47s/it]Loading train:  24%|██▍       | 69/285 [01:35<05:04,  1.41s/it]Loading train:  25%|██▍       | 70/285 [01:37<04:57,  1.38s/it]Loading train:  25%|██▍       | 71/285 [01:38<04:48,  1.35s/it]Loading train:  25%|██▌       | 72/285 [01:39<04:47,  1.35s/it]Loading train:  26%|██▌       | 73/285 [01:41<04:48,  1.36s/it]Loading train:  26%|██▌       | 74/285 [01:42<04:45,  1.35s/it]Loading train:  26%|██▋       | 75/285 [01:43<04:42,  1.35s/it]Loading train:  27%|██▋       | 76/285 [01:45<04:46,  1.37s/it]Loading train:  27%|██▋       | 77/285 [01:46<04:34,  1.32s/it]Loading train:  27%|██▋       | 78/285 [01:47<04:25,  1.28s/it]Loading train:  28%|██▊       | 79/285 [01:49<04:36,  1.34s/it]Loading train:  28%|██▊       | 80/285 [01:50<04:26,  1.30s/it]Loading train:  28%|██▊       | 81/285 [01:51<04:24,  1.29s/it]Loading train:  29%|██▉       | 82/285 [01:52<04:13,  1.25s/it]Loading train:  29%|██▉       | 83/285 [01:54<04:12,  1.25s/it]Loading train:  29%|██▉       | 84/285 [01:55<04:10,  1.25s/it]Loading train:  30%|██▉       | 85/285 [01:56<04:08,  1.24s/it]Loading train:  30%|███       | 86/285 [01:57<04:08,  1.25s/it]Loading train:  31%|███       | 87/285 [01:59<04:08,  1.26s/it]Loading train:  31%|███       | 88/285 [02:00<03:54,  1.19s/it]Loading train:  31%|███       | 89/285 [02:01<04:02,  1.24s/it]Loading train:  32%|███▏      | 90/285 [02:02<04:09,  1.28s/it]Loading train:  32%|███▏      | 91/285 [02:04<04:10,  1.29s/it]Loading train:  32%|███▏      | 92/285 [02:05<04:12,  1.31s/it]Loading train:  33%|███▎      | 93/285 [02:07<04:19,  1.35s/it]Loading train:  33%|███▎      | 94/285 [02:08<04:39,  1.46s/it]Loading train:  33%|███▎      | 95/285 [02:10<04:33,  1.44s/it]Loading train:  34%|███▎      | 96/285 [02:11<04:29,  1.43s/it]Loading train:  34%|███▍      | 97/285 [02:12<04:16,  1.37s/it]Loading train:  34%|███▍      | 98/285 [02:14<04:13,  1.36s/it]Loading train:  35%|███▍      | 99/285 [02:15<03:59,  1.29s/it]Loading train:  35%|███▌      | 100/285 [02:16<04:03,  1.31s/it]Loading train:  35%|███▌      | 101/285 [02:17<03:57,  1.29s/it]Loading train:  36%|███▌      | 102/285 [02:19<04:01,  1.32s/it]Loading train:  36%|███▌      | 103/285 [02:20<03:57,  1.30s/it]Loading train:  36%|███▋      | 104/285 [02:21<03:58,  1.32s/it]Loading train:  37%|███▋      | 105/285 [02:23<03:53,  1.30s/it]Loading train:  37%|███▋      | 106/285 [02:24<03:47,  1.27s/it]Loading train:  38%|███▊      | 107/285 [02:25<03:42,  1.25s/it]Loading train:  38%|███▊      | 108/285 [02:26<03:38,  1.23s/it]Loading train:  38%|███▊      | 109/285 [02:27<03:35,  1.22s/it]Loading train:  39%|███▊      | 110/285 [02:29<03:39,  1.25s/it]Loading train:  39%|███▉      | 111/285 [02:30<03:33,  1.23s/it]Loading train:  39%|███▉      | 112/285 [02:31<03:35,  1.25s/it]Loading train:  40%|███▉      | 113/285 [02:32<03:33,  1.24s/it]Loading train:  40%|████      | 114/285 [02:34<03:58,  1.40s/it]Loading train:  40%|████      | 115/285 [02:36<03:53,  1.38s/it]Loading train:  41%|████      | 116/285 [02:37<03:45,  1.33s/it]Loading train:  41%|████      | 117/285 [02:38<03:30,  1.26s/it]Loading train:  41%|████▏     | 118/285 [02:39<03:30,  1.26s/it]Loading train:  42%|████▏     | 119/285 [02:40<03:29,  1.26s/it]Loading train:  42%|████▏     | 120/285 [02:42<03:30,  1.27s/it]Loading train:  42%|████▏     | 121/285 [02:43<03:43,  1.37s/it]Loading train:  43%|████▎     | 122/285 [02:45<03:51,  1.42s/it]Loading train:  43%|████▎     | 123/285 [02:46<03:45,  1.39s/it]Loading train:  44%|████▎     | 124/285 [02:47<03:28,  1.30s/it]Loading train:  44%|████▍     | 125/285 [02:48<03:17,  1.23s/it]Loading train:  44%|████▍     | 126/285 [02:50<03:18,  1.25s/it]Loading train:  45%|████▍     | 127/285 [02:51<03:08,  1.19s/it]Loading train:  45%|████▍     | 128/285 [02:52<02:58,  1.14s/it]Loading train:  45%|████▌     | 129/285 [02:53<02:56,  1.13s/it]Loading train:  46%|████▌     | 130/285 [02:54<03:04,  1.19s/it]Loading train:  46%|████▌     | 131/285 [02:55<02:59,  1.17s/it]Loading train:  46%|████▋     | 132/285 [02:56<03:02,  1.19s/it]Loading train:  47%|████▋     | 133/285 [02:58<02:59,  1.18s/it]Loading train:  47%|████▋     | 134/285 [02:59<03:05,  1.23s/it]Loading train:  47%|████▋     | 135/285 [03:00<03:00,  1.20s/it]Loading train:  48%|████▊     | 136/285 [03:01<03:01,  1.22s/it]Loading train:  48%|████▊     | 137/285 [03:03<03:12,  1.30s/it]Loading train:  48%|████▊     | 138/285 [03:04<03:04,  1.26s/it]Loading train:  49%|████▉     | 139/285 [03:05<02:59,  1.23s/it]Loading train:  49%|████▉     | 140/285 [03:06<02:51,  1.19s/it]Loading train:  49%|████▉     | 141/285 [03:07<02:42,  1.13s/it]Loading train:  50%|████▉     | 142/285 [03:08<02:41,  1.13s/it]Loading train:  50%|█████     | 143/285 [03:10<02:41,  1.14s/it]Loading train:  51%|█████     | 144/285 [03:11<02:39,  1.13s/it]Loading train:  51%|█████     | 145/285 [03:12<02:41,  1.15s/it]Loading train:  51%|█████     | 146/285 [03:13<02:37,  1.13s/it]Loading train:  52%|█████▏    | 147/285 [03:14<02:32,  1.11s/it]Loading train:  52%|█████▏    | 148/285 [03:15<02:32,  1.11s/it]Loading train:  52%|█████▏    | 149/285 [03:16<02:35,  1.15s/it]Loading train:  53%|█████▎    | 150/285 [03:18<02:46,  1.23s/it]Loading train:  53%|█████▎    | 151/285 [03:19<02:42,  1.21s/it]Loading train:  53%|█████▎    | 152/285 [03:20<02:38,  1.19s/it]Loading train:  54%|█████▎    | 153/285 [03:21<02:32,  1.15s/it]Loading train:  54%|█████▍    | 154/285 [03:22<02:28,  1.13s/it]Loading train:  54%|█████▍    | 155/285 [03:23<02:33,  1.18s/it]Loading train:  55%|█████▍    | 156/285 [03:25<02:33,  1.19s/it]Loading train:  55%|█████▌    | 157/285 [03:26<02:26,  1.14s/it]Loading train:  55%|█████▌    | 158/285 [03:27<02:29,  1.18s/it]Loading train:  56%|█████▌    | 159/285 [03:28<02:24,  1.15s/it]Loading train:  56%|█████▌    | 160/285 [03:29<02:22,  1.14s/it]Loading train:  56%|█████▋    | 161/285 [03:30<02:22,  1.15s/it]Loading train:  57%|█████▋    | 162/285 [03:31<02:13,  1.08s/it]Loading train:  57%|█████▋    | 163/285 [03:32<02:16,  1.12s/it]Loading train:  58%|█████▊    | 164/285 [03:34<02:17,  1.13s/it]Loading train:  58%|█████▊    | 165/285 [03:35<02:16,  1.14s/it]Loading train:  58%|█████▊    | 166/285 [03:36<02:16,  1.15s/it]Loading train:  59%|█████▊    | 167/285 [03:37<02:16,  1.15s/it]Loading train:  59%|█████▉    | 168/285 [03:38<02:14,  1.15s/it]Loading train:  59%|█████▉    | 169/285 [03:39<02:09,  1.12s/it]Loading train:  60%|█████▉    | 170/285 [03:40<02:08,  1.12s/it]Loading train:  60%|██████    | 171/285 [03:42<02:09,  1.14s/it]Loading train:  60%|██████    | 172/285 [03:43<02:21,  1.26s/it]Loading train:  61%|██████    | 173/285 [03:45<02:42,  1.45s/it]Loading train:  61%|██████    | 174/285 [03:47<03:03,  1.65s/it]Loading train:  61%|██████▏   | 175/285 [03:49<03:07,  1.70s/it]Loading train:  62%|██████▏   | 176/285 [03:50<02:49,  1.55s/it]Loading train:  62%|██████▏   | 177/285 [03:52<02:46,  1.54s/it]Loading train:  62%|██████▏   | 178/285 [03:53<02:51,  1.60s/it]Loading train:  63%|██████▎   | 179/285 [03:55<02:37,  1.49s/it]Loading train:  63%|██████▎   | 180/285 [03:57<02:52,  1.64s/it]Loading train:  64%|██████▎   | 181/285 [03:59<02:57,  1.71s/it]Loading train:  64%|██████▍   | 182/285 [04:01<03:08,  1.83s/it]Loading train:  64%|██████▍   | 183/285 [04:02<03:06,  1.83s/it]Loading train:  65%|██████▍   | 184/285 [04:04<02:46,  1.65s/it]Loading train:  65%|██████▍   | 185/285 [04:05<02:39,  1.59s/it]Loading train:  65%|██████▌   | 186/285 [04:07<02:48,  1.70s/it]Loading train:  66%|██████▌   | 187/285 [04:09<02:53,  1.77s/it]Loading train:  66%|██████▌   | 188/285 [04:11<02:49,  1.75s/it]Loading train:  66%|██████▋   | 189/285 [04:12<02:41,  1.68s/it]Loading train:  67%|██████▋   | 190/285 [04:14<02:47,  1.76s/it]Loading train:  67%|██████▋   | 191/285 [04:16<02:44,  1.75s/it]Loading train:  67%|██████▋   | 192/285 [04:17<02:26,  1.58s/it]Loading train:  68%|██████▊   | 193/285 [04:19<02:24,  1.57s/it]Loading train:  68%|██████▊   | 194/285 [04:21<02:41,  1.77s/it]Loading train:  68%|██████▊   | 195/285 [04:23<02:41,  1.79s/it]Loading train:  69%|██████▉   | 196/285 [04:24<02:36,  1.76s/it]Loading train:  69%|██████▉   | 197/285 [04:27<02:49,  1.92s/it]Loading train:  69%|██████▉   | 198/285 [04:28<02:40,  1.85s/it]Loading train:  70%|██████▉   | 199/285 [04:30<02:20,  1.63s/it]Loading train:  70%|███████   | 200/285 [04:31<02:24,  1.70s/it]Loading train:  71%|███████   | 201/285 [04:34<02:33,  1.83s/it]Loading train:  71%|███████   | 202/285 [04:35<02:19,  1.68s/it]Loading train:  71%|███████   | 203/285 [04:37<02:24,  1.76s/it]Loading train:  72%|███████▏  | 204/285 [04:38<02:18,  1.71s/it]Loading train:  72%|███████▏  | 205/285 [04:40<02:10,  1.63s/it]Loading train:  72%|███████▏  | 206/285 [04:41<02:05,  1.58s/it]Loading train:  73%|███████▎  | 207/285 [04:43<02:09,  1.66s/it]Loading train:  73%|███████▎  | 208/285 [04:45<02:11,  1.71s/it]Loading train:  73%|███████▎  | 209/285 [04:47<02:12,  1.75s/it]Loading train:  74%|███████▎  | 210/285 [04:48<02:05,  1.67s/it]Loading train:  74%|███████▍  | 211/285 [04:50<01:55,  1.56s/it]Loading train:  74%|███████▍  | 212/285 [04:51<01:50,  1.52s/it]Loading train:  75%|███████▍  | 213/285 [04:54<02:09,  1.80s/it]Loading train:  75%|███████▌  | 214/285 [04:55<02:00,  1.70s/it]Loading train:  75%|███████▌  | 215/285 [04:57<01:57,  1.68s/it]Loading train:  76%|███████▌  | 216/285 [04:58<01:47,  1.56s/it]Loading train:  76%|███████▌  | 217/285 [04:59<01:44,  1.53s/it]Loading train:  76%|███████▋  | 218/285 [05:01<01:44,  1.57s/it]Loading train:  77%|███████▋  | 219/285 [05:03<01:48,  1.64s/it]Loading train:  77%|███████▋  | 220/285 [05:04<01:37,  1.51s/it]Loading train:  78%|███████▊  | 221/285 [05:05<01:32,  1.44s/it]Loading train:  78%|███████▊  | 222/285 [05:08<01:45,  1.67s/it]Loading train:  78%|███████▊  | 223/285 [05:09<01:46,  1.71s/it]Loading train:  79%|███████▊  | 224/285 [05:11<01:37,  1.60s/it]Loading train:  79%|███████▉  | 225/285 [05:12<01:35,  1.59s/it]Loading train:  79%|███████▉  | 226/285 [05:14<01:32,  1.56s/it]Loading train:  80%|███████▉  | 227/285 [05:15<01:28,  1.52s/it]Loading train:  80%|████████  | 228/285 [05:17<01:29,  1.58s/it]Loading train:  80%|████████  | 229/285 [05:19<01:32,  1.66s/it]Loading train:  81%|████████  | 230/285 [05:20<01:27,  1.59s/it]Loading train:  81%|████████  | 231/285 [05:22<01:26,  1.60s/it]Loading train:  81%|████████▏ | 232/285 [05:23<01:26,  1.64s/it]Loading train:  82%|████████▏ | 233/285 [05:25<01:25,  1.65s/it]Loading train:  82%|████████▏ | 234/285 [05:27<01:20,  1.57s/it]Loading train:  82%|████████▏ | 235/285 [05:28<01:19,  1.58s/it]Loading train:  83%|████████▎ | 236/285 [05:30<01:22,  1.68s/it]Loading train:  83%|████████▎ | 237/285 [05:32<01:23,  1.74s/it]Loading train:  84%|████████▎ | 238/285 [05:33<01:15,  1.60s/it]Loading train:  84%|████████▍ | 239/285 [05:34<01:05,  1.43s/it]Loading train:  84%|████████▍ | 240/285 [05:35<01:01,  1.37s/it]Loading train:  85%|████████▍ | 241/285 [05:37<00:57,  1.31s/it]Loading train:  85%|████████▍ | 242/285 [05:39<01:05,  1.52s/it]Loading train:  85%|████████▌ | 243/285 [05:40<01:00,  1.45s/it]Loading train:  86%|████████▌ | 244/285 [05:42<01:04,  1.57s/it]Loading train:  86%|████████▌ | 245/285 [05:43<01:03,  1.58s/it]Loading train:  86%|████████▋ | 246/285 [05:45<01:00,  1.54s/it]Loading train:  87%|████████▋ | 247/285 [05:46<00:54,  1.44s/it]Loading train:  87%|████████▋ | 248/285 [05:47<00:52,  1.43s/it]Loading train:  87%|████████▋ | 249/285 [05:49<00:47,  1.32s/it]Loading train:  88%|████████▊ | 250/285 [05:50<00:42,  1.22s/it]Loading train:  88%|████████▊ | 251/285 [05:51<00:42,  1.25s/it]Loading train:  88%|████████▊ | 252/285 [05:52<00:42,  1.30s/it]Loading train:  89%|████████▉ | 253/285 [05:54<00:41,  1.29s/it]Loading train:  89%|████████▉ | 254/285 [05:55<00:40,  1.31s/it]Loading train:  89%|████████▉ | 255/285 [05:56<00:37,  1.24s/it]Loading train:  90%|████████▉ | 256/285 [05:57<00:35,  1.22s/it]Loading train:  90%|█████████ | 257/285 [05:58<00:35,  1.27s/it]Loading train:  91%|█████████ | 258/285 [06:01<00:40,  1.51s/it]Loading train:  91%|█████████ | 259/285 [06:02<00:39,  1.53s/it]Loading train:  91%|█████████ | 260/285 [06:04<00:37,  1.48s/it]Loading train:  92%|█████████▏| 261/285 [06:04<00:31,  1.32s/it]Loading train:  92%|█████████▏| 262/285 [06:06<00:29,  1.27s/it]Loading train:  92%|█████████▏| 263/285 [06:06<00:25,  1.15s/it]Loading train:  93%|█████████▎| 264/285 [06:08<00:26,  1.28s/it]Loading train:  93%|█████████▎| 265/285 [06:10<00:27,  1.39s/it]Loading train:  93%|█████████▎| 266/285 [06:11<00:27,  1.45s/it]Loading train:  94%|█████████▎| 267/285 [06:12<00:24,  1.35s/it]Loading train:  94%|█████████▍| 268/285 [06:14<00:22,  1.31s/it]Loading train:  94%|█████████▍| 269/285 [06:15<00:20,  1.26s/it]Loading train:  95%|█████████▍| 270/285 [06:16<00:20,  1.33s/it]Loading train:  95%|█████████▌| 271/285 [06:17<00:17,  1.25s/it]Loading train:  95%|█████████▌| 272/285 [06:18<00:15,  1.22s/it]Loading train:  96%|█████████▌| 273/285 [06:20<00:14,  1.22s/it]Loading train:  96%|█████████▌| 274/285 [06:21<00:13,  1.23s/it]Loading train:  96%|█████████▋| 275/285 [06:22<00:13,  1.32s/it]Loading train:  97%|█████████▋| 276/285 [06:24<00:12,  1.35s/it]Loading train:  97%|█████████▋| 277/285 [06:25<00:09,  1.24s/it]Loading train:  98%|█████████▊| 278/285 [06:26<00:08,  1.25s/it]Loading train:  98%|█████████▊| 279/285 [06:28<00:08,  1.37s/it]Loading train:  98%|█████████▊| 280/285 [06:29<00:06,  1.25s/it]Loading train:  99%|█████████▊| 281/285 [06:30<00:04,  1.14s/it]Loading train:  99%|█████████▉| 282/285 [06:31<00:03,  1.28s/it]Loading train:  99%|█████████▉| 283/285 [06:33<00:02,  1.42s/it]Loading train: 100%|█████████▉| 284/285 [06:35<00:01,  1.49s/it]Loading train: 100%|██████████| 285/285 [06:37<00:00,  1.60s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:03, 69.75it/s]concatenating: train:  11%|█         | 32/285 [00:00<00:02, 88.65it/s]concatenating: train:  17%|█▋        | 49/285 [00:00<00:02, 99.18it/s]concatenating: train:  21%|██        | 60/285 [00:00<00:02, 91.03it/s]concatenating: train:  25%|██▍       | 70/285 [00:00<00:02, 84.98it/s]concatenating: train:  28%|██▊       | 79/285 [00:00<00:03, 67.62it/s]concatenating: train:  31%|███       | 87/285 [00:00<00:02, 66.08it/s]concatenating: train:  33%|███▎      | 95/285 [00:01<00:03, 50.22it/s]concatenating: train:  35%|███▌      | 101/285 [00:01<00:04, 39.47it/s]concatenating: train:  37%|███▋      | 106/285 [00:01<00:04, 39.72it/s]concatenating: train:  39%|███▉      | 111/285 [00:01<00:04, 39.19it/s]concatenating: train:  41%|████      | 117/285 [00:01<00:04, 41.91it/s]concatenating: train:  49%|████▉     | 140/285 [00:01<00:02, 55.53it/s]concatenating: train:  60%|█████▉    | 170/285 [00:01<00:01, 73.41it/s]concatenating: train:  69%|██████▉   | 198/285 [00:02<00:00, 94.12it/s]concatenating: train:  78%|███████▊  | 223/285 [00:02<00:00, 114.66it/s]concatenating: train:  87%|████████▋ | 248/285 [00:02<00:00, 136.67it/s]concatenating: train:  95%|█████████▍| 270/285 [00:02<00:00, 72.06it/s] concatenating: train: 100%|██████████| 285/285 [00:03<00:00, 80.46it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.78s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.68s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.63s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 35.72it/s]2019-07-10 20:45:48.208296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-10 20:45:48.208391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-10 20:45:48.208406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-10 20:45:48.208415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-10 20:45:48.208890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.40it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.44it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  6.23it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.97it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:03,  8.71it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  7.02it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.98it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.52it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.51it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  9.44it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.88it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01, 10.20it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:02<00:01,  8.10it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.97it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.40it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.74it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  7.43it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 11.00it/s] max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 26, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 13, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 26, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 13)   793         dropout_5[0][0]                  
==================================================================================================
Total params: 223,833
Trainable params: 49,153
Non-trainable params: 174,680
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 16s - loss: 2.1731 - acc: 0.7748 - mDice: 0.1882 - val_loss: 0.9693 - val_acc: 0.9296 - val_mDice: 0.3802

Epoch 00001: val_mDice improved from -inf to 0.38022, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 12s - loss: 0.7708 - acc: 0.9175 - mDice: 0.4502 - val_loss: 0.5989 - val_acc: 0.9433 - val_mDice: 0.5375

Epoch 00002: val_mDice improved from 0.38022 to 0.53745, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 11s - loss: 0.6088 - acc: 0.9287 - mDice: 0.5299 - val_loss: 0.5337 - val_acc: 0.9440 - val_mDice: 0.5712

Epoch 00003: val_mDice improved from 0.53745 to 0.57121, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 11s - loss: 0.5276 - acc: 0.9343 - mDice: 0.5754 - val_loss: 0.5264 - val_acc: 0.9466 - val_mDice: 0.5780

Epoch 00004: val_mDice improved from 0.57121 to 0.57797, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 11s - loss: 0.4809 - acc: 0.9376 - mDice: 0.6035 - val_loss: 0.5138 - val_acc: 0.9505 - val_mDice: 0.5890

Epoch 00005: val_mDice improved from 0.57797 to 0.58903, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 11s - loss: 0.4526 - acc: 0.9398 - mDice: 0.6215 - val_loss: 0.5268 - val_acc: 0.9492 - val_mDice: 0.5822

Epoch 00006: val_mDice did not improve from 0.58903
Epoch 7/300
 - 11s - loss: 0.4274 - acc: 0.9417 - mDice: 0.6373 - val_loss: 0.5101 - val_acc: 0.9493 - val_mDice: 0.5940

Epoch 00007: val_mDice improved from 0.58903 to 0.59403, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 11s - loss: 0.4092 - acc: 0.9430 - mDice: 0.6498 - val_loss: 0.5229 - val_acc: 0.9486 - val_mDice: 0.5848

Epoch 00008: val_mDice did not improve from 0.59403
Epoch 9/300
 - 10s - loss: 0.3946 - acc: 0.9442 - mDice: 0.6597 - val_loss: 0.4930 - val_acc: 0.9511 - val_mDice: 0.6084

Epoch 00009: val_mDice improved from 0.59403 to 0.60836, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 11s - loss: 0.3804 - acc: 0.9450 - mDice: 0.6690 - val_loss: 0.5093 - val_acc: 0.9517 - val_mDice: 0.5977

Epoch 00010: val_mDice did not improve from 0.60836
Epoch 11/300
 - 12s - loss: 0.3705 - acc: 0.9458 - mDice: 0.6761 - val_loss: 0.4773 - val_acc: 0.9528 - val_mDice: 0.6169

Epoch 00011: val_mDice improved from 0.60836 to 0.61687, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 11s - loss: 0.3619 - acc: 0.9465 - mDice: 0.6821 - val_loss: 0.4790 - val_acc: 0.9534 - val_mDice: 0.6157

Epoch 00012: val_mDice did not improve from 0.61687
Epoch 13/300
 - 10s - loss: 0.3530 - acc: 0.9471 - mDice: 0.6883 - val_loss: 0.4928 - val_acc: 0.9508 - val_mDice: 0.6053

Epoch 00013: val_mDice did not improve from 0.61687
Epoch 14/300
 - 12s - loss: 0.3465 - acc: 0.9476 - mDice: 0.6930 - val_loss: 0.4769 - val_acc: 0.9529 - val_mDice: 0.6185

Epoch 00014: val_mDice improved from 0.61687 to 0.61849, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 11s - loss: 0.3388 - acc: 0.9481 - mDice: 0.6984 - val_loss: 0.4809 - val_acc: 0.9505 - val_mDice: 0.6165

Epoch 00015: val_mDice did not improve from 0.61849
Epoch 16/300
 - 11s - loss: 0.3355 - acc: 0.9484 - mDice: 0.7011 - val_loss: 0.5521 - val_acc: 0.9535 - val_mDice: 0.6090

Epoch 00016: val_mDice did not improve from 0.61849
Epoch 17/300
 - 11s - loss: 0.3305 - acc: 0.9487 - mDice: 0.7047 - val_loss: 0.5038 - val_acc: 0.9535 - val_mDice: 0.6116

Epoch 00017: val_mDice did not improve from 0.61849
Epoch 18/300
 - 10s - loss: 0.3222 - acc: 0.9492 - mDice: 0.7105 - val_loss: 0.4577 - val_acc: 0.9527 - val_mDice: 0.6257

Epoch 00018: val_mDice improved from 0.61849 to 0.62572, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 19/300
 - 10s - loss: 0.3202 - acc: 0.9495 - mDice: 0.7121 - val_loss: 0.5053 - val_acc: 0.9532 - val_mDice: 0.6104

Epoch 00019: val_mDice did not improve from 0.62572
Epoch 20/300
 - 11s - loss: 0.3155 - acc: 0.9497 - mDice: 0.7156 - val_loss: 0.5084 - val_acc: 0.9517 - val_mDice: 0.6106

Epoch 00020: val_mDice did not improve from 0.62572
Epoch 21/300
 - 10s - loss: 0.3118 - acc: 0.9500 - mDice: 0.7184 - val_loss: 0.4956 - val_acc: 0.9528 - val_mDice: 0.6151

Epoch 00021: val_mDice did not improve from 0.62572
Epoch 22/300
 - 11s - loss: 0.3089 - acc: 0.9504 - mDice: 0.7205 - val_loss: 0.5202 - val_acc: 0.9537 - val_mDice: 0.6145

Epoch 00022: val_mDice did not improve from 0.62572
Epoch 23/300
 - 11s - loss: 0.3041 - acc: 0.9506 - mDice: 0.7240 - val_loss: 0.5286 - val_acc: 0.9538 - val_mDice: 0.6122

Epoch 00023: val_mDice did not improve from 0.62572
Epoch 24/300
 - 10s - loss: 0.3041 - acc: 0.9506 - mDice: 0.7242 - val_loss: 0.4982 - val_acc: 0.9542 - val_mDice: 0.6205

Epoch 00024: val_mDice did not improve from 0.62572
Epoch 25/300
 - 11s - loss: 0.3007 - acc: 0.9509 - mDice: 0.7268 - val_loss: 0.5300 - val_acc: 0.9533 - val_mDice: 0.6108

Epoch 00025: val_mDice did not improve from 0.62572
Epoch 26/300
 - 11s - loss: 0.2985 - acc: 0.9512 - mDice: 0.7284 - val_loss: 0.5294 - val_acc: 0.9518 - val_mDice: 0.5981

Epoch 00026: val_mDice did not improve from 0.62572
Epoch 27/300
 - 10s - loss: 0.2934 - acc: 0.9516 - mDice: 0.7322 - val_loss: 0.5415 - val_acc: 0.9531 - val_mDice: 0.6080

Epoch 00027: val_mDice did not improve from 0.62572
Epoch 28/300
 - 11s - loss: 0.2933 - acc: 0.9516 - mDice: 0.7323 - val_loss: 0.5023 - val_acc: 0.9537 - val_mDice: 0.6109

Epoch 00028: val_mDice did not improve from 0.62572
Epoch 29/300
 - 10s - loss: 0.2922 - acc: 0.9517 - mDice: 0.7332 - val_loss: 0.5471 - val_acc: 0.9517 - val_mDice: 0.6037

Epoch 00029: val_mDice did not improve from 0.62572
Epoch 30/300
 - 11s - loss: 0.2880 - acc: 0.9520 - mDice: 0.7364 - val_loss: 0.5217 - val_acc: 0.9551 - val_mDice: 0.6100

Epoch 00030: val_mDice did not improve from 0.62572
Epoch 31/300
 - 11s - loss: 0.2850 - acc: 0.9521 - mDice: 0.7387 - val_loss: 0.4868 - val_acc: 0.9527 - val_mDice: 0.6132

Epoch 00031: val_mDice did not improve from 0.62572
Epoch 32/300
 - 11s - loss: 0.2854 - acc: 0.9522 - mDice: 0.7384 - val_loss: 0.5106 - val_acc: 0.9518 - val_mDice: 0.6033

Epoch 00032: val_mDice did not improve from 0.62572
Epoch 33/300
 - 11s - loss: 0.2834 - acc: 0.9524 - mDice: 0.7399 - val_loss: 0.4814 - val_acc: 0.9539 - val_mDice: 0.6214

Epoch 00033: val_mDice did not improve from 0.62572
Epoch 34/300
 - 11s - loss: 0.2828 - acc: 0.9525 - mDice: 0.7404 - val_loss: 0.5704 - val_acc: 0.9518 - val_mDice: 0.5803

Epoch 00034: val_mDice did not improve from 0.62572
Epoch 35/300
 - 11s - loss: 0.2790 - acc: 0.9528 - mDice: 0.7435 - val_loss: 0.4950 - val_acc: 0.9541 - val_mDice: 0.6103

Epoch 00035: val_mDice did not improve from 0.62572
Epoch 36/300
 - 11s - loss: 0.2785 - acc: 0.9527 - mDice: 0.7437 - val_loss: 0.4993 - val_acc: 0.9524 - val_mDice: 0.6088

Epoch 00036: val_mDice did not improve from 0.62572
Epoch 37/300
 - 11s - loss: 0.2774 - acc: 0.9529 - mDice: 0.7446 - val_loss: 0.5043 - val_acc: 0.9521 - val_mDice: 0.6038

Epoch 00037: val_mDice did not improve from 0.62572
Epoch 38/300
 - 11s - loss: 0.2739 - acc: 0.9531 - mDice: 0.7472 - val_loss: 0.4979 - val_acc: 0.9531 - val_mDice: 0.6148

Epoch 00038: val_mDice did not improve from 0.62572
Epoch 39/300
 - 11s - loss: 0.2735 - acc: 0.9532 - mDice: 0.7475 - val_loss: 0.4946 - val_acc: 0.9536 - val_mDice: 0.6115

Epoch 00039: val_mDice did not improve from 0.62572
Epoch 40/300
 - 11s - loss: 0.2719 - acc: 0.9532 - mDice: 0.7489 - val_loss: 0.5033 - val_acc: 0.9532 - val_mDice: 0.6052

Epoch 00040: val_mDice did not improve from 0.62572
Epoch 41/300
 - 11s - loss: 0.2702 - acc: 0.9535 - mDice: 0.7501 - val_loss: 0.5413 - val_acc: 0.9533 - val_mDice: 0.6014

Epoch 00041: val_mDice did not improve from 0.62572
Epoch 42/300
 - 11s - loss: 0.2704 - acc: 0.9535 - mDice: 0.7501 - val_loss: 0.5256 - val_acc: 0.9529 - val_mDice: 0.5939

Epoch 00042: val_mDice did not improve from 0.62572
Epoch 43/300
 - 11s - loss: 0.2693 - acc: 0.9536 - mDice: 0.7509 - val_loss: 0.4737 - val_acc: 0.9529 - val_mDice: 0.6210

Epoch 00043: val_mDice did not improve from 0.62572
Epoch 44/300
 - 11s - loss: 0.2683 - acc: 0.9536 - mDice: 0.7518 - val_loss: 0.4886 - val_acc: 0.9510 - val_mDice: 0.6065

Epoch 00044: val_mDice did not improve from 0.62572
Epoch 45/300
 - 10s - loss: 0.2660 - acc: 0.9537 - mDice: 0.7534 - val_loss: 0.5606 - val_acc: 0.9529 - val_mDice: 0.5976

Epoch 00045: val_mDice did not improve from 0.62572
Epoch 46/300
 - 11s - loss: 0.2659 - acc: 0.9538 - mDice: 0.7536 - val_loss: 0.4986 - val_acc: 0.9529 - val_mDice: 0.6106

Epoch 00046: val_mDice did not improve from 0.62572
Epoch 47/300
 - 11s - loss: 0.2654 - acc: 0.9539 - mDice: 0.7540 - val_loss: 0.5704 - val_acc: 0.9498 - val_mDice: 0.5841

Epoch 00047: val_mDice did not improve from 0.62572
Epoch 48/300
 - 11s - loss: 0.2633 - acc: 0.9539 - mDice: 0.7556 - val_loss: 0.5119 - val_acc: 0.9522 - val_mDice: 0.5979

Epoch 00048: val_mDice did not improve from 0.62572
Epoch 49/300
 - 11s - loss: 0.2618 - acc: 0.9541 - mDice: 0.7568 - val_loss: 0.5188 - val_acc: 0.9526 - val_mDice: 0.6038

Epoch 00049: val_mDice did not improve from 0.62572
Epoch 50/300
 - 11s - loss: 0.2617 - acc: 0.9542 - mDice: 0.7569 - val_loss: 0.4997 - val_acc: 0.9545 - val_mDice: 0.6126

Epoch 00050: val_mDice did not improve from 0.62572
Epoch 51/300
 - 11s - loss: 0.2610 - acc: 0.9542 - mDice: 0.7575 - val_loss: 0.5194 - val_acc: 0.9513 - val_mDice: 0.6056

Epoch 00051: val_mDice did not improve from 0.62572
Epoch 52/300
 - 11s - loss: 0.2602 - acc: 0.9542 - mDice: 0.7581 - val_loss: 0.5078 - val_acc: 0.9533 - val_mDice: 0.6098

Epoch 00052: val_mDice did not improve from 0.62572
Epoch 53/300
 - 11s - loss: 0.2597 - acc: 0.9543 - mDice: 0.7584 - val_loss: 0.5473 - val_acc: 0.9531 - val_mDice: 0.5950

Epoch 00053: val_mDice did not improve from 0.62572
Epoch 54/300
 - 11s - loss: 0.2604 - acc: 0.9544 - mDice: 0.7581 - val_loss: 0.5285 - val_acc: 0.9546 - val_mDice: 0.6144

Epoch 00054: val_mDice did not improve from 0.62572
Epoch 55/300
 - 11s - loss: 0.2574 - acc: 0.9545 - mDice: 0.7603 - val_loss: 1.1251 - val_acc: 0.9532 - val_mDice: 0.5898

Epoch 00055: val_mDice did not improve from 0.62572
Epoch 56/300
 - 11s - loss: 0.2579 - acc: 0.9545 - mDice: 0.7600 - val_loss: 0.5030 - val_acc: 0.9532 - val_mDice: 0.6141

Epoch 00056: val_mDice did not improve from 0.62572
Epoch 57/300
 - 11s - loss: 0.2561 - acc: 0.9546 - mDice: 0.7614 - val_loss: 0.4708 - val_acc: 0.9526 - val_mDice: 0.6205

Epoch 00057: val_mDice did not improve from 0.62572
Epoch 58/300
 - 11s - loss: 0.2558 - acc: 0.9546 - mDice: 0.7616 - val_loss: 0.5021 - val_acc: 0.9499 - val_mDice: 0.6073

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.27s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.04s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.87s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:45,  1.85s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:09,  1.73s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:06,  1.73s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:40,  1.64s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:56,  1.70s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:37,  1.64s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:52,  1.70s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:44,  1.68s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:19,  1.81s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:37,  1.88s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:11,  1.79s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:37,  1.90s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<08:12,  1.81s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<08:15,  1.83s/it]predicting train subjects:   5%|▌         | 15/285 [00:26<08:27,  1.88s/it]predicting train subjects:   6%|▌         | 16/285 [00:28<08:45,  1.95s/it]predicting train subjects:   6%|▌         | 17/285 [00:30<08:16,  1.85s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:16,  1.86s/it]predicting train subjects:   7%|▋         | 19/285 [00:33<07:58,  1.80s/it]predicting train subjects:   7%|▋         | 20/285 [00:35<08:04,  1.83s/it]predicting train subjects:   7%|▋         | 21/285 [00:37<08:20,  1.90s/it]predicting train subjects:   8%|▊         | 22/285 [00:39<07:56,  1.81s/it]predicting train subjects:   8%|▊         | 23/285 [00:41<08:01,  1.84s/it]predicting train subjects:   8%|▊         | 24/285 [00:43<07:45,  1.78s/it]predicting train subjects:   9%|▉         | 25/285 [00:45<08:02,  1.86s/it]predicting train subjects:   9%|▉         | 26/285 [00:47<08:15,  1.91s/it]predicting train subjects:   9%|▉         | 27/285 [00:48<07:53,  1.84s/it]predicting train subjects:  10%|▉         | 28/285 [00:50<07:52,  1.84s/it]predicting train subjects:  10%|█         | 29/285 [00:52<07:52,  1.84s/it]predicting train subjects:  11%|█         | 30/285 [00:54<08:06,  1.91s/it]predicting train subjects:  11%|█         | 31/285 [00:56<08:19,  1.97s/it]predicting train subjects:  11%|█         | 32/285 [00:58<07:51,  1.87s/it]predicting train subjects:  12%|█▏        | 33/285 [01:00<07:50,  1.87s/it]predicting train subjects:  12%|█▏        | 34/285 [01:01<07:42,  1.84s/it]predicting train subjects:  12%|█▏        | 35/285 [01:03<07:56,  1.91s/it]predicting train subjects:  13%|█▎        | 36/285 [01:05<07:31,  1.81s/it]predicting train subjects:  13%|█▎        | 37/285 [01:07<07:30,  1.82s/it]predicting train subjects:  13%|█▎        | 38/285 [01:09<07:46,  1.89s/it]predicting train subjects:  14%|█▎        | 39/285 [01:11<07:25,  1.81s/it]predicting train subjects:  14%|█▍        | 40/285 [01:12<07:26,  1.82s/it]predicting train subjects:  14%|█▍        | 41/285 [01:14<07:14,  1.78s/it]predicting train subjects:  15%|█▍        | 42/285 [01:16<07:02,  1.74s/it]predicting train subjects:  15%|█▌        | 43/285 [01:18<07:10,  1.78s/it]predicting train subjects:  15%|█▌        | 44/285 [01:20<07:26,  1.85s/it]predicting train subjects:  16%|█▌        | 45/285 [01:21<07:10,  1.79s/it]predicting train subjects:  16%|█▌        | 46/285 [01:23<07:31,  1.89s/it]predicting train subjects:  16%|█▋        | 47/285 [01:25<07:17,  1.84s/it]predicting train subjects:  17%|█▋        | 48/285 [01:27<07:17,  1.85s/it]predicting train subjects:  17%|█▋        | 49/285 [01:29<07:28,  1.90s/it]predicting train subjects:  18%|█▊        | 50/285 [01:31<07:22,  1.88s/it]predicting train subjects:  18%|█▊        | 51/285 [01:33<07:35,  1.95s/it]predicting train subjects:  18%|█▊        | 52/285 [01:35<07:11,  1.85s/it]predicting train subjects:  19%|█▊        | 53/285 [01:36<07:11,  1.86s/it]predicting train subjects:  19%|█▉        | 54/285 [01:39<07:23,  1.92s/it]predicting train subjects:  19%|█▉        | 55/285 [01:40<07:02,  1.84s/it]predicting train subjects:  20%|█▉        | 56/285 [01:42<07:00,  1.84s/it]predicting train subjects:  20%|██        | 57/285 [01:44<06:50,  1.80s/it]predicting train subjects:  20%|██        | 58/285 [01:46<06:48,  1.80s/it]predicting train subjects:  21%|██        | 59/285 [01:48<07:03,  1.87s/it]predicting train subjects:  21%|██        | 60/285 [01:50<07:17,  1.94s/it]predicting train subjects:  21%|██▏       | 61/285 [01:51<06:55,  1.85s/it]predicting train subjects:  22%|██▏       | 62/285 [01:53<06:54,  1.86s/it]predicting train subjects:  22%|██▏       | 63/285 [01:55<06:56,  1.88s/it]predicting train subjects:  22%|██▏       | 64/285 [01:57<06:47,  1.85s/it]predicting train subjects:  23%|██▎       | 65/285 [01:59<06:47,  1.85s/it]predicting train subjects:  23%|██▎       | 66/285 [02:01<06:45,  1.85s/it]predicting train subjects:  24%|██▎       | 67/285 [02:02<06:45,  1.86s/it]predicting train subjects:  24%|██▍       | 68/285 [02:04<06:33,  1.81s/it]predicting train subjects:  24%|██▍       | 69/285 [02:06<06:32,  1.82s/it]predicting train subjects:  25%|██▍       | 70/285 [02:08<06:35,  1.84s/it]predicting train subjects:  25%|██▍       | 71/285 [02:10<06:31,  1.83s/it]predicting train subjects:  25%|██▌       | 72/285 [02:11<06:21,  1.79s/it]predicting train subjects:  26%|██▌       | 73/285 [02:13<06:20,  1.79s/it]predicting train subjects:  26%|██▌       | 74/285 [02:15<06:19,  1.80s/it]predicting train subjects:  26%|██▋       | 75/285 [02:17<06:28,  1.85s/it]predicting train subjects:  27%|██▋       | 76/285 [02:19<06:28,  1.86s/it]predicting train subjects:  27%|██▋       | 77/285 [02:21<06:18,  1.82s/it]predicting train subjects:  27%|██▋       | 78/285 [02:22<06:09,  1.78s/it]predicting train subjects:  28%|██▊       | 79/285 [02:24<06:11,  1.80s/it]predicting train subjects:  28%|██▊       | 80/285 [02:26<06:12,  1.82s/it]predicting train subjects:  28%|██▊       | 81/285 [02:28<06:09,  1.81s/it]predicting train subjects:  29%|██▉       | 82/285 [02:30<06:10,  1.83s/it]predicting train subjects:  29%|██▉       | 83/285 [02:31<06:00,  1.79s/it]predicting train subjects:  29%|██▉       | 84/285 [02:33<05:52,  1.75s/it]predicting train subjects:  30%|██▉       | 85/285 [02:35<05:57,  1.79s/it]predicting train subjects:  30%|███       | 86/285 [02:37<06:03,  1.83s/it]predicting train subjects:  31%|███       | 87/285 [02:39<05:59,  1.82s/it]predicting train subjects:  31%|███       | 88/285 [02:40<05:50,  1.78s/it]predicting train subjects:  31%|███       | 89/285 [02:42<05:52,  1.80s/it]predicting train subjects:  32%|███▏      | 90/285 [02:44<05:55,  1.82s/it]predicting train subjects:  32%|███▏      | 91/285 [02:46<05:45,  1.78s/it]predicting train subjects:  32%|███▏      | 92/285 [02:48<05:48,  1.81s/it]predicting train subjects:  33%|███▎      | 93/285 [02:49<05:41,  1.78s/it]predicting train subjects:  33%|███▎      | 94/285 [02:51<05:44,  1.80s/it]predicting train subjects:  33%|███▎      | 95/285 [02:53<05:42,  1.80s/it]predicting train subjects:  34%|███▎      | 96/285 [02:55<05:41,  1.81s/it]predicting train subjects:  34%|███▍      | 97/285 [02:57<05:44,  1.83s/it]predicting train subjects:  34%|███▍      | 98/285 [02:58<05:40,  1.82s/it]predicting train subjects:  35%|███▍      | 99/285 [03:00<05:36,  1.81s/it]predicting train subjects:  35%|███▌      | 100/285 [03:02<05:37,  1.82s/it]predicting train subjects:  35%|███▌      | 101/285 [03:04<05:35,  1.82s/it]predicting train subjects:  36%|███▌      | 102/285 [03:06<05:35,  1.84s/it]predicting train subjects:  36%|███▌      | 103/285 [03:07<05:25,  1.79s/it]predicting train subjects:  36%|███▋      | 104/285 [03:09<05:25,  1.80s/it]predicting train subjects:  37%|███▋      | 105/285 [03:11<05:26,  1.82s/it]predicting train subjects:  37%|███▋      | 106/285 [03:13<05:18,  1.78s/it]predicting train subjects:  38%|███▊      | 107/285 [03:15<05:16,  1.78s/it]predicting train subjects:  38%|███▊      | 108/285 [03:16<05:16,  1.79s/it]predicting train subjects:  38%|███▊      | 109/285 [03:18<05:16,  1.80s/it]predicting train subjects:  39%|███▊      | 110/285 [03:20<05:21,  1.84s/it]predicting train subjects:  39%|███▉      | 111/285 [03:22<05:09,  1.78s/it]predicting train subjects:  39%|███▉      | 112/285 [03:24<05:07,  1.78s/it]predicting train subjects:  40%|███▉      | 113/285 [03:25<05:11,  1.81s/it]predicting train subjects:  40%|████      | 114/285 [03:27<05:08,  1.80s/it]predicting train subjects:  40%|████      | 115/285 [03:29<05:09,  1.82s/it]predicting train subjects:  41%|████      | 116/285 [03:31<05:10,  1.84s/it]predicting train subjects:  41%|████      | 117/285 [03:33<05:00,  1.79s/it]predicting train subjects:  41%|████▏     | 118/285 [03:34<04:52,  1.75s/it]predicting train subjects:  42%|████▏     | 119/285 [03:36<04:55,  1.78s/it]predicting train subjects:  42%|████▏     | 120/285 [03:38<04:51,  1.77s/it]predicting train subjects:  42%|████▏     | 121/285 [03:40<04:43,  1.73s/it]predicting train subjects:  43%|████▎     | 122/285 [03:41<04:32,  1.67s/it]predicting train subjects:  43%|████▎     | 123/285 [03:43<04:25,  1.64s/it]predicting train subjects:  44%|████▎     | 124/285 [03:44<04:24,  1.64s/it]predicting train subjects:  44%|████▍     | 125/285 [03:46<04:19,  1.62s/it]predicting train subjects:  44%|████▍     | 126/285 [03:47<04:13,  1.60s/it]predicting train subjects:  45%|████▍     | 127/285 [03:49<04:08,  1.57s/it]predicting train subjects:  45%|████▍     | 128/285 [03:51<04:10,  1.60s/it]predicting train subjects:  45%|████▌     | 129/285 [03:52<04:06,  1.58s/it]predicting train subjects:  46%|████▌     | 130/285 [03:54<04:01,  1.56s/it]predicting train subjects:  46%|████▌     | 131/285 [03:55<03:56,  1.54s/it]predicting train subjects:  46%|████▋     | 132/285 [03:57<04:01,  1.58s/it]predicting train subjects:  47%|████▋     | 133/285 [03:58<03:57,  1.56s/it]predicting train subjects:  47%|████▋     | 134/285 [04:00<03:52,  1.54s/it]predicting train subjects:  47%|████▋     | 135/285 [04:01<03:51,  1.54s/it]predicting train subjects:  48%|████▊     | 136/285 [04:03<03:48,  1.53s/it]predicting train subjects:  48%|████▊     | 137/285 [04:05<03:57,  1.61s/it]predicting train subjects:  48%|████▊     | 138/285 [04:06<03:53,  1.59s/it]predicting train subjects:  49%|████▉     | 139/285 [04:08<03:56,  1.62s/it]predicting train subjects:  49%|████▉     | 140/285 [04:10<03:55,  1.62s/it]predicting train subjects:  49%|████▉     | 141/285 [04:11<03:49,  1.59s/it]predicting train subjects:  50%|████▉     | 142/285 [04:13<03:45,  1.58s/it]predicting train subjects:  50%|█████     | 143/285 [04:14<03:41,  1.56s/it]predicting train subjects:  51%|█████     | 144/285 [04:16<03:45,  1.60s/it]predicting train subjects:  51%|█████     | 145/285 [04:17<03:40,  1.58s/it]predicting train subjects:  51%|█████     | 146/285 [04:19<03:43,  1.61s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:20<03:34,  1.56s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:22<03:36,  1.58s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:24<03:32,  1.56s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:25<03:29,  1.55s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:27<03:30,  1.57s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:28<03:25,  1.54s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:30<03:21,  1.53s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:31<03:26,  1.58s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:33<03:25,  1.58s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:35<03:26,  1.60s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:36<03:24,  1.60s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:38<03:20,  1.58s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:39<03:16,  1.56s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:41<03:13,  1.55s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:42<03:16,  1.59s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:44<03:10,  1.55s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:46<03:16,  1.61s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:47<03:11,  1.58s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:49<03:07,  1.56s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:50<03:12,  1.61s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:52<03:12,  1.63s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:54<03:04,  1.58s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:55<03:02,  1.57s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:57<02:57,  1.54s/it]predicting train subjects:  60%|██████    | 171/285 [04:58<02:55,  1.54s/it]predicting train subjects:  60%|██████    | 172/285 [05:00<02:58,  1.58s/it]predicting train subjects:  61%|██████    | 173/285 [05:01<02:55,  1.57s/it]predicting train subjects:  61%|██████    | 174/285 [05:03<02:50,  1.53s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:04<02:51,  1.56s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:06<02:52,  1.58s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:08<02:46,  1.55s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:09<02:41,  1.51s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:10<02:36,  1.48s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:12<02:44,  1.57s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:14<02:46,  1.61s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:16<02:49,  1.65s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:17<02:42,  1.59s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:19<02:39,  1.58s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:20<02:35,  1.56s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:22<02:42,  1.64s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:24<02:47,  1.71s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:26<02:50,  1.75s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:27<02:40,  1.67s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:29<02:30,  1.59s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:30<02:32,  1.62s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:32<02:32,  1.64s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:33<02:24,  1.57s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:35<02:20,  1.54s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:36<02:15,  1.51s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:38<02:24,  1.63s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:40<02:28,  1.69s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:42<02:29,  1.72s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:43<02:21,  1.64s/it]predicting train subjects:  70%|███████   | 200/285 [05:45<02:15,  1.59s/it]predicting train subjects:  71%|███████   | 201/285 [05:46<02:18,  1.65s/it]predicting train subjects:  71%|███████   | 202/285 [05:48<02:18,  1.67s/it]predicting train subjects:  71%|███████   | 203/285 [05:50<02:16,  1.66s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:51<02:09,  1.60s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:53<02:05,  1.57s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:54<02:01,  1.54s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:56<02:07,  1.63s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:58<02:11,  1.71s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:00<02:13,  1.76s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:01<02:04,  1.66s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:03<01:59,  1.61s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:04<01:59,  1.63s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:06<01:57,  1.64s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:08<01:52,  1.58s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:09<01:55,  1.65s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:11<01:48,  1.57s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:13<01:53,  1.67s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:15<01:55,  1.72s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:16<01:54,  1.74s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:18<01:46,  1.64s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:19<01:42,  1.60s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:21<01:42,  1.63s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:22<01:37,  1.57s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:24<01:33,  1.53s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:25<01:30,  1.51s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:27<01:35,  1.62s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:29<01:40,  1.73s/it]predicting train subjects:  80%|████████  | 228/285 [06:31<01:39,  1.75s/it]predicting train subjects:  80%|████████  | 229/285 [06:33<01:38,  1.76s/it]predicting train subjects:  81%|████████  | 230/285 [06:34<01:30,  1.64s/it]predicting train subjects:  81%|████████  | 231/285 [06:36<01:25,  1.58s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:37<01:26,  1.63s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:39<01:20,  1.55s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:40<01:23,  1.64s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:42<01:20,  1.61s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:44<01:23,  1.70s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:46<01:22,  1.73s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:48<01:22,  1.76s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:49<01:19,  1.74s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:51<01:13,  1.64s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:52<01:10,  1.61s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:54<01:07,  1.56s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:55<01:04,  1.54s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:57<01:06,  1.61s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:58<01:02,  1.57s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:00<01:06,  1.70s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:02<01:05,  1.73s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:04<01:03,  1.70s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:05<00:59,  1.64s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:07<00:55,  1.60s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:08<00:53,  1.58s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:10<00:50,  1.54s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:12<00:52,  1.64s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:13<00:52,  1.70s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:15<00:51,  1.72s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:17<00:48,  1.66s/it]predicting train subjects:  90%|█████████ | 257/285 [07:18<00:44,  1.60s/it]predicting train subjects:  91%|█████████ | 258/285 [07:20<00:44,  1.65s/it]predicting train subjects:  91%|█████████ | 259/285 [07:22<00:43,  1.66s/it]predicting train subjects:  91%|█████████ | 260/285 [07:23<00:40,  1.61s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:25<00:37,  1.58s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:26<00:35,  1.54s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:28<00:33,  1.53s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:30<00:34,  1.66s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:31<00:34,  1.73s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:33<00:31,  1.64s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:34<00:28,  1.59s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:36<00:28,  1.67s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:38<00:26,  1.68s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:39<00:24,  1.61s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:41<00:22,  1.58s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:43<00:21,  1.65s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:44<00:19,  1.59s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:46<00:17,  1.55s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:48<00:16,  1.66s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:49<00:15,  1.71s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:51<00:13,  1.63s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:52<00:11,  1.59s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:54<00:09,  1.66s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:56<00:08,  1.62s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:57<00:06,  1.58s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:59<00:04,  1.54s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:00<00:03,  1.63s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:02<00:01,  1.71s/it]predicting train subjects: 100%|██████████| 285/285 [08:04<00:00,  1.76s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<06:47,  1.44s/it]Loading train:   1%|          | 2/285 [00:02<06:28,  1.37s/it]Loading train:   1%|          | 3/285 [00:03<06:18,  1.34s/it]Loading train:   1%|▏         | 4/285 [00:05<06:06,  1.30s/it]Loading train:   2%|▏         | 5/285 [00:06<06:15,  1.34s/it]Loading train:   2%|▏         | 6/285 [00:07<06:04,  1.31s/it]Loading train:   2%|▏         | 7/285 [00:09<06:20,  1.37s/it]Loading train:   3%|▎         | 8/285 [00:10<06:13,  1.35s/it]Loading train:   3%|▎         | 9/285 [00:12<06:19,  1.38s/it]Loading train:   4%|▎         | 10/285 [00:13<05:50,  1.28s/it]Loading train:   4%|▍         | 11/285 [00:13<05:10,  1.13s/it]Loading train:   4%|▍         | 12/285 [00:14<05:03,  1.11s/it]Loading train:   5%|▍         | 13/285 [00:15<04:43,  1.04s/it]Loading train:   5%|▍         | 14/285 [00:17<05:05,  1.13s/it]Loading train:   5%|▌         | 15/285 [00:18<04:58,  1.11s/it]Loading train:   6%|▌         | 16/285 [00:19<05:03,  1.13s/it]Loading train:   6%|▌         | 17/285 [00:20<04:35,  1.03s/it]Loading train:   6%|▋         | 18/285 [00:21<04:22,  1.02it/s]Loading train:   7%|▋         | 19/285 [00:21<04:16,  1.04it/s]Loading train:   7%|▋         | 20/285 [00:22<04:02,  1.09it/s]Loading train:   7%|▋         | 21/285 [00:23<04:15,  1.03it/s]Loading train:   8%|▊         | 22/285 [00:24<04:03,  1.08it/s]Loading train:   8%|▊         | 23/285 [00:25<04:13,  1.03it/s]Loading train:   8%|▊         | 24/285 [00:26<04:06,  1.06it/s]Loading train:   9%|▉         | 25/285 [00:27<04:12,  1.03it/s]Loading train:   9%|▉         | 26/285 [00:28<04:09,  1.04it/s]Loading train:   9%|▉         | 27/285 [00:29<03:55,  1.09it/s]Loading train:  10%|▉         | 28/285 [00:30<04:00,  1.07it/s]Loading train:  10%|█         | 29/285 [00:31<03:51,  1.11it/s]Loading train:  11%|█         | 30/285 [00:32<03:59,  1.07it/s]Loading train:  11%|█         | 31/285 [00:33<04:05,  1.04it/s]Loading train:  11%|█         | 32/285 [00:34<03:55,  1.08it/s]Loading train:  12%|█▏        | 33/285 [00:35<04:00,  1.05it/s]Loading train:  12%|█▏        | 34/285 [00:36<03:54,  1.07it/s]Loading train:  12%|█▏        | 35/285 [00:37<03:58,  1.05it/s]Loading train:  13%|█▎        | 36/285 [00:37<03:47,  1.09it/s]Loading train:  13%|█▎        | 37/285 [00:38<03:46,  1.10it/s]Loading train:  13%|█▎        | 38/285 [00:39<03:54,  1.05it/s]Loading train:  14%|█▎        | 39/285 [00:40<03:46,  1.09it/s]Loading train:  14%|█▍        | 40/285 [00:41<04:08,  1.02s/it]Loading train:  14%|█▍        | 41/285 [00:42<03:55,  1.04it/s]Loading train:  15%|█▍        | 42/285 [00:43<03:49,  1.06it/s]Loading train:  15%|█▌        | 43/285 [00:44<03:47,  1.07it/s]Loading train:  15%|█▌        | 44/285 [00:45<03:50,  1.05it/s]Loading train:  16%|█▌        | 45/285 [00:46<03:42,  1.08it/s]Loading train:  16%|█▌        | 46/285 [00:47<03:42,  1.08it/s]Loading train:  16%|█▋        | 47/285 [00:48<03:40,  1.08it/s]Loading train:  17%|█▋        | 48/285 [00:49<03:39,  1.08it/s]Loading train:  17%|█▋        | 49/285 [00:50<03:59,  1.01s/it]Loading train:  18%|█▊        | 50/285 [00:51<03:47,  1.03it/s]Loading train:  18%|█▊        | 51/285 [00:52<03:55,  1.01s/it]Loading train:  18%|█▊        | 52/285 [00:53<03:45,  1.03it/s]Loading train:  19%|█▊        | 53/285 [00:54<03:43,  1.04it/s]Loading train:  19%|█▉        | 54/285 [00:55<03:51,  1.00s/it]Loading train:  19%|█▉        | 55/285 [00:56<03:43,  1.03it/s]Loading train:  20%|█▉        | 56/285 [00:57<03:45,  1.02it/s]Loading train:  20%|██        | 57/285 [00:58<03:29,  1.09it/s]Loading train:  20%|██        | 58/285 [00:58<03:28,  1.09it/s]Loading train:  21%|██        | 59/285 [00:59<03:28,  1.08it/s]Loading train:  21%|██        | 60/285 [01:00<03:37,  1.03it/s]Loading train:  21%|██▏       | 61/285 [01:01<03:30,  1.06it/s]Loading train:  22%|██▏       | 62/285 [01:02<03:31,  1.05it/s]Loading train:  22%|██▏       | 63/285 [01:03<03:37,  1.02it/s]Loading train:  22%|██▏       | 64/285 [01:05<03:58,  1.08s/it]Loading train:  23%|██▎       | 65/285 [01:06<04:16,  1.17s/it]
Epoch 00058: val_mDice did not improve from 0.62572
Restoring model weights from the end of the best epoch
Epoch 00058: early stopping
{'val_loss': [0.9693080090277688, 0.598945447186518, 0.5336884366733402, 0.5263686832768957, 0.5138120721172355, 0.5267506078634848, 0.5101222815460333, 0.5228583875981123, 0.4930162972578123, 0.5092605435648444, 0.47727549409067166, 0.47904466850131583, 0.49277708716898655, 0.4769456769501031, 0.4809023997637147, 0.5520764009912587, 0.5038378005587189, 0.45774116929016967, 0.5053499617390127, 0.5083530511935996, 0.49558686077927744, 0.520201403335486, 0.5286164080630468, 0.49815059707151443, 0.5299693252787244, 0.5293907106921659, 0.5415326510061765, 0.5023375563115381, 0.5471314574753106, 0.5217265979537751, 0.4868320602944443, 0.5105879077032291, 0.48135985575574736, 0.5704115422744325, 0.4949677043786928, 0.4993003230521133, 0.5043167778233576, 0.4979024339654592, 0.49460954706096116, 0.5032917137918526, 0.5412681702129002, 0.5255626749725981, 0.47374624446783653, 0.48856043682418054, 0.5606378589928483, 0.498577060646185, 0.570370208950682, 0.5118840057090674, 0.5188489206676377, 0.499747101821047, 0.5193752802950043, 0.507753004241922, 0.5473013237201968, 0.5284991011273261, 1.1251483363146222, 0.5029855520365625, 0.47080342030392014, 0.5021244530571239], 'val_acc': [0.9296428081709579, 0.9432539550285766, 0.9440183875947025, 0.9466112429203268, 0.9504892276652033, 0.9491814195110811, 0.9492826634945151, 0.9485657581403935, 0.9510822013103762, 0.9517247360511865, 0.9528280176929922, 0.9533548328463591, 0.9508115599275301, 0.9529168439311022, 0.9504850896377137, 0.9535056648973647, 0.9535159928172661, 0.9526833861899775, 0.9532370883659278, 0.9517392203128537, 0.9528156089383131, 0.9537184621368706, 0.9537597838060816, 0.9542390950565232, 0.9532866547893546, 0.95178466569112, 0.9531275759862122, 0.9537040048471376, 0.9516627422258175, 0.9550552065146036, 0.9526854417177552, 0.9517908269466635, 0.9538878745206908, 0.9517557228077723, 0.9541482266101091, 0.9523569422061217, 0.9521255662987352, 0.9530573374066273, 0.9535862630306009, 0.9531668154886981, 0.9533321158180024, 0.9529044638132916, 0.9529044531577127, 0.9510057598518926, 0.9529168595814838, 0.9528528068984687, 0.9498405236771653, 0.952224719790773, 0.9526028170265965, 0.9544663788886044, 0.9512660922950873, 0.9533486476157631, 0.9530841771450789, 0.9546048228301149, 0.9532350198516633, 0.9531606249303125, 0.9526089989273242, 0.9499190103408345], 'val_mDice': [0.3802168257742621, 0.5374537213554595, 0.5712113873252656, 0.5779701008477025, 0.5890254414947339, 0.5822067880097714, 0.594029973672089, 0.5848186542201974, 0.6083564678383939, 0.5977044781493075, 0.6168709354027689, 0.6157487237919642, 0.6052785951997981, 0.6184852023364446, 0.6165176876430405, 0.6090391501368091, 0.6115587410314123, 0.6257217736217563, 0.6103561993417793, 0.6105744618943284, 0.6151239082799943, 0.6144525125705996, 0.6122313458160316, 0.6205194948771813, 0.6107845173201747, 0.5980527554144407, 0.6079857366045094, 0.6109088745863078, 0.6036809263282648, 0.6099872122929749, 0.6131595143392765, 0.6032928231708165, 0.6214066813777945, 0.5802711714579406, 0.6103434506075343, 0.6087621666865641, 0.6038260376653192, 0.6148038909421952, 0.6115159805260557, 0.6052234539106571, 0.601426295395004, 0.59389976649311, 0.6209911384396047, 0.6064839356438407, 0.5976139157178015, 0.6106070633041126, 0.5840527465223601, 0.5978684368746241, 0.603849468284479, 0.6125672419643935, 0.6055509184991847, 0.6098036889257378, 0.5950390779772284, 0.6143640289759503, 0.5898251340375932, 0.6140518544772484, 0.6204994570609578, 0.6073392016927623], 'loss': [2.1731203970426853, 0.7708293819056118, 0.608781430652592, 0.5275708294130347, 0.4808945519609536, 0.45259304280134594, 0.42738880142654756, 0.409178391682492, 0.3945957011393125, 0.3803864397742794, 0.3704860623408348, 0.36191882369117173, 0.3530480199117662, 0.346499887649468, 0.3387729910443106, 0.3355342808466294, 0.33045438458233783, 0.3221602072370876, 0.32021573992130264, 0.3154794983283788, 0.31178913347718895, 0.3089412415925535, 0.3041177608012296, 0.3041275878544954, 0.30072217020137426, 0.29852027095556843, 0.293405884111845, 0.293272872052222, 0.2921942865531706, 0.28796794100801354, 0.28499792835745025, 0.28538090917424086, 0.28340487346969384, 0.28277882408371197, 0.27895574475300805, 0.2784839383294059, 0.27737215535130794, 0.27385842312389286, 0.27350112070452187, 0.27189509537730183, 0.2701974339841219, 0.270352174702582, 0.2692599569710438, 0.26827019672658436, 0.2660425418044323, 0.26592863952923324, 0.26535080937406647, 0.2633149204258825, 0.26175111932313283, 0.2617225592613973, 0.261043535176916, 0.26019669313406374, 0.2597118078522884, 0.2603609140652547, 0.2573743094890753, 0.25788334849567546, 0.25610947202677875, 0.25578714433296024], 'acc': [0.7748243126608981, 0.9175146025683156, 0.928676547522275, 0.934276797352556, 0.937590538965228, 0.939798916894414, 0.9416544980443412, 0.9430336829825338, 0.944236221604212, 0.9450171804461862, 0.9457863928718405, 0.9465494605783452, 0.9471359099284035, 0.9475891997232319, 0.948073003337012, 0.9483982305284951, 0.948688797786224, 0.949225190064206, 0.9494601238735438, 0.9496807756133604, 0.9499755902790529, 0.9503605603639366, 0.9505659872835923, 0.9506243977676023, 0.950932988929733, 0.9511857477059507, 0.9515542419645874, 0.9516235899317531, 0.9517295346898416, 0.9519723243498087, 0.952112512942084, 0.9521821186950371, 0.9524036579860282, 0.9524939747510097, 0.9527716465644552, 0.9526789958528571, 0.9528903245607769, 0.9530792959563178, 0.9531504157373676, 0.9532240524666481, 0.9534932890460873, 0.953492786599156, 0.9535573375367253, 0.9536229194518846, 0.9537274366461057, 0.9538295125657453, 0.9538775104939058, 0.9539004521109973, 0.9540831153217884, 0.9542123859669218, 0.9542023975646196, 0.9542395796308876, 0.954312370250794, 0.9543823422017514, 0.954487100934211, 0.9545343137275653, 0.9546419716168317, 0.9546066411608516], 'mDice': [0.1881526021482534, 0.45022348159474035, 0.5299125967264162, 0.5754265665365236, 0.6035058121296596, 0.6214744964200917, 0.6373342086946671, 0.6497761133507792, 0.6596680848818317, 0.6689603396454354, 0.676056437636245, 0.6820749845758489, 0.688290564142978, 0.6930251020205112, 0.6983697370898262, 0.7011026149254195, 0.7046920116622557, 0.7105304061616599, 0.7121487238147304, 0.7156049879922644, 0.7184007824989752, 0.7205192596199115, 0.7240203783069455, 0.7242355475880976, 0.7267552190379869, 0.7283815866585073, 0.7322147133777451, 0.7323319270430187, 0.7331503748237993, 0.7363864891825532, 0.7386618287927814, 0.7384089773876801, 0.7399080722824524, 0.7404435310908623, 0.7434933391455426, 0.7436914235267443, 0.7446226610297777, 0.7472035680861977, 0.7475363769456456, 0.7488656174051664, 0.7501402684373732, 0.7500787314055344, 0.7508625210282668, 0.7517873737931634, 0.7534457553764631, 0.7535934062164065, 0.753971472456398, 0.7556157676711737, 0.7568370485466801, 0.7568731624883644, 0.7574563970766285, 0.7580655431651347, 0.7584101563185351, 0.7581007383103582, 0.7603382751330214, 0.7599866533063867, 0.7613830731154124, 0.761587450787507]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0     Loading train:  23%|██▎       | 66/285 [01:07<04:26,  1.22s/it]Loading train:  24%|██▎       | 67/285 [01:08<04:03,  1.12s/it]Loading train:  24%|██▍       | 68/285 [01:09<03:43,  1.03s/it]Loading train:  24%|██▍       | 69/285 [01:10<03:40,  1.02s/it]Loading train:  25%|██▍       | 70/285 [01:11<03:33,  1.01it/s]Loading train:  25%|██▍       | 71/285 [01:12<03:27,  1.03it/s]Loading train:  25%|██▌       | 72/285 [01:13<03:12,  1.11it/s]Loading train:  26%|██▌       | 73/285 [01:14<03:16,  1.08it/s]Loading train:  26%|██▌       | 74/285 [01:15<03:18,  1.06it/s]Loading train:  26%|██▋       | 75/285 [01:16<03:26,  1.02it/s]Loading train:  27%|██▋       | 76/285 [01:17<03:23,  1.03it/s]Loading train:  27%|██▋       | 77/285 [01:17<03:08,  1.10it/s]Loading train:  27%|██▋       | 78/285 [01:18<03:00,  1.15it/s]Loading train:  28%|██▊       | 79/285 [01:19<02:58,  1.15it/s]Loading train:  28%|██▊       | 80/285 [01:20<03:03,  1.12it/s]Loading train:  28%|██▊       | 81/285 [01:21<02:56,  1.16it/s]Loading train:  29%|██▉       | 82/285 [01:22<02:59,  1.13it/s]Loading train:  29%|██▉       | 83/285 [01:23<02:55,  1.15it/s]Loading train:  29%|██▉       | 84/285 [01:23<02:46,  1.21it/s]Loading train:  30%|██▉       | 85/285 [01:24<03:00,  1.11it/s]Loading train:  30%|███       | 86/285 [01:25<03:04,  1.08it/s]Loading train:  31%|███       | 87/285 [01:26<03:01,  1.09it/s]Loading train:  31%|███       | 88/285 [01:27<02:50,  1.16it/s]Loading train:  31%|███       | 89/285 [01:28<02:49,  1.15it/s]Loading train:  32%|███▏      | 90/285 [01:29<02:59,  1.08it/s]Loading train:  32%|███▏      | 91/285 [01:30<02:50,  1.14it/s]Loading train:  32%|███▏      | 92/285 [01:31<02:52,  1.12it/s]Loading train:  33%|███▎      | 93/285 [01:31<02:47,  1.15it/s]Loading train:  33%|███▎      | 94/285 [01:32<02:45,  1.16it/s]Loading train:  33%|███▎      | 95/285 [01:33<02:55,  1.08it/s]Loading train:  34%|███▎      | 96/285 [01:34<02:55,  1.08it/s]Loading train:  34%|███▍      | 97/285 [01:35<03:03,  1.02it/s]Loading train:  34%|███▍      | 98/285 [01:36<03:01,  1.03it/s]Loading train:  35%|███▍      | 99/285 [01:37<02:58,  1.04it/s]Loading train:  35%|███▌      | 100/285 [01:38<02:55,  1.05it/s]Loading train:  35%|███▌      | 101/285 [01:39<02:50,  1.08it/s]Loading train:  36%|███▌      | 102/285 [01:40<02:45,  1.10it/s]Loading train:  36%|███▌      | 103/285 [01:41<02:38,  1.15it/s]Loading train:  36%|███▋      | 104/285 [01:42<02:47,  1.08it/s]Loading train:  37%|███▋      | 105/285 [01:43<02:44,  1.10it/s]Loading train:  37%|███▋      | 106/285 [01:43<02:36,  1.15it/s]Loading train:  38%|███▊      | 107/285 [01:44<02:39,  1.12it/s]Loading train:  38%|███▊      | 108/285 [01:45<02:35,  1.14it/s]Loading train:  38%|███▊      | 109/285 [01:46<02:40,  1.10it/s]Loading train:  39%|███▊      | 110/285 [01:47<02:34,  1.14it/s]Loading train:  39%|███▉      | 111/285 [01:48<02:34,  1.13it/s]Loading train:  39%|███▉      | 112/285 [01:49<02:41,  1.07it/s]Loading train:  40%|███▉      | 113/285 [01:50<02:43,  1.05it/s]Loading train:  40%|████      | 114/285 [01:51<02:38,  1.08it/s]Loading train:  40%|████      | 115/285 [01:52<02:30,  1.13it/s]Loading train:  41%|████      | 116/285 [01:53<02:34,  1.09it/s]Loading train:  41%|████      | 117/285 [01:53<02:23,  1.17it/s]Loading train:  41%|████▏     | 118/285 [01:54<02:25,  1.15it/s]Loading train:  42%|████▏     | 119/285 [01:55<02:30,  1.10it/s]Loading train:  42%|████▏     | 120/285 [01:56<02:27,  1.12it/s]Loading train:  42%|████▏     | 121/285 [01:57<02:48,  1.03s/it]Loading train:  43%|████▎     | 122/285 [01:59<02:55,  1.07s/it]Loading train:  43%|████▎     | 123/285 [02:00<02:58,  1.10s/it]Loading train:  44%|████▎     | 124/285 [02:01<02:49,  1.05s/it]Loading train:  44%|████▍     | 125/285 [02:02<02:39,  1.00it/s]Loading train:  44%|████▍     | 126/285 [02:02<02:34,  1.03it/s]Loading train:  45%|████▍     | 127/285 [02:03<02:21,  1.11it/s]Loading train:  45%|████▍     | 128/285 [02:04<02:17,  1.14it/s]Loading train:  45%|████▌     | 129/285 [02:05<02:15,  1.15it/s]Loading train:  46%|████▌     | 130/285 [02:06<02:10,  1.19it/s]Loading train:  46%|████▌     | 131/285 [02:06<02:08,  1.20it/s]Loading train:  46%|████▋     | 132/285 [02:07<02:10,  1.17it/s]Loading train:  47%|████▋     | 133/285 [02:08<02:11,  1.16it/s]Loading train:  47%|████▋     | 134/285 [02:09<02:12,  1.14it/s]Loading train:  47%|████▋     | 135/285 [02:10<02:01,  1.23it/s]Loading train:  48%|████▊     | 136/285 [02:11<01:58,  1.26it/s]Loading train:  48%|████▊     | 137/285 [02:11<02:02,  1.20it/s]Loading train:  48%|████▊     | 138/285 [02:12<02:01,  1.21it/s]Loading train:  49%|████▉     | 139/285 [02:13<02:05,  1.17it/s]Loading train:  49%|████▉     | 140/285 [02:14<02:06,  1.15it/s]Loading train:  49%|████▉     | 141/285 [02:15<02:02,  1.18it/s]Loading train:  50%|████▉     | 142/285 [02:16<02:01,  1.18it/s]Loading train:  50%|█████     | 143/285 [02:17<01:57,  1.21it/s]Loading train:  51%|█████     | 144/285 [02:17<01:57,  1.20it/s]Loading train:  51%|█████     | 145/285 [02:18<01:56,  1.21it/s]Loading train:  51%|█████     | 146/285 [02:19<01:57,  1.18it/s]Loading train:  52%|█████▏    | 147/285 [02:20<01:53,  1.21it/s]Loading train:  52%|█████▏    | 148/285 [02:21<01:51,  1.23it/s]Loading train:  52%|█████▏    | 149/285 [02:21<01:46,  1.28it/s]Loading train:  53%|█████▎    | 150/285 [02:22<01:45,  1.28it/s]Loading train:  53%|█████▎    | 151/285 [02:23<01:50,  1.22it/s]Loading train:  53%|█████▎    | 152/285 [02:24<01:51,  1.19it/s]Loading train:  54%|█████▎    | 153/285 [02:25<01:45,  1.26it/s]Loading train:  54%|█████▍    | 154/285 [02:25<01:44,  1.26it/s]Loading train:  54%|█████▍    | 155/285 [02:26<01:47,  1.21it/s]Loading train:  55%|█████▍    | 156/285 [02:27<01:43,  1.25it/s]Loading train:  55%|█████▌    | 157/285 [02:28<01:41,  1.26it/s]Loading train:  55%|█████▌    | 158/285 [02:29<01:38,  1.28it/s]Loading train:  56%|█████▌    | 159/285 [02:29<01:33,  1.34it/s]Loading train:  56%|█████▌    | 160/285 [02:30<01:36,  1.30it/s]Loading train:  56%|█████▋    | 161/285 [02:31<01:35,  1.30it/s]Loading train:  57%|█████▋    | 162/285 [02:32<01:32,  1.33it/s]Loading train:  57%|█████▋    | 163/285 [02:32<01:33,  1.30it/s]Loading train:  58%|█████▊    | 164/285 [02:33<01:28,  1.37it/s]Loading train:  58%|█████▊    | 165/285 [02:34<01:29,  1.35it/s]Loading train:  58%|█████▊    | 166/285 [02:35<01:29,  1.33it/s]Loading train:  59%|█████▊    | 167/285 [02:35<01:29,  1.32it/s]Loading train:  59%|█████▉    | 168/285 [02:36<01:34,  1.23it/s]Loading train:  59%|█████▉    | 169/285 [02:37<01:33,  1.24it/s]Loading train:  60%|█████▉    | 170/285 [02:38<01:33,  1.23it/s]Loading train:  60%|██████    | 171/285 [02:39<01:34,  1.21it/s]Loading train:  60%|██████    | 172/285 [02:40<01:32,  1.23it/s]Loading train:  61%|██████    | 173/285 [02:40<01:26,  1.29it/s]Loading train:  61%|██████    | 174/285 [02:41<01:28,  1.25it/s]Loading train:  61%|██████▏   | 175/285 [02:42<01:29,  1.23it/s]Loading train:  62%|██████▏   | 176/285 [02:43<01:31,  1.19it/s]Loading train:  62%|██████▏   | 177/285 [02:44<01:34,  1.15it/s]Loading train:  62%|██████▏   | 178/285 [02:45<01:31,  1.17it/s]Loading train:  63%|██████▎   | 179/285 [02:45<01:29,  1.19it/s]Loading train:  63%|██████▎   | 180/285 [02:46<01:31,  1.15it/s]Loading train:  64%|██████▎   | 181/285 [02:47<01:34,  1.10it/s]Loading train:  64%|██████▍   | 182/285 [02:48<01:31,  1.13it/s]Loading train:  64%|██████▍   | 183/285 [02:49<01:26,  1.18it/s]Loading train:  65%|██████▍   | 184/285 [02:50<01:23,  1.21it/s]Loading train:  65%|██████▍   | 185/285 [02:50<01:17,  1.29it/s]Loading train:  65%|██████▌   | 186/285 [02:51<01:25,  1.16it/s]Loading train:  66%|██████▌   | 187/285 [02:52<01:24,  1.16it/s]Loading train:  66%|██████▌   | 188/285 [02:53<01:24,  1.15it/s]Loading train:  66%|██████▋   | 189/285 [02:54<01:19,  1.22it/s]Loading train:  67%|██████▋   | 190/285 [02:55<01:17,  1.22it/s]Loading train:  67%|██████▋   | 191/285 [02:56<01:18,  1.20it/s]Loading train:  67%|██████▋   | 192/285 [02:56<01:17,  1.20it/s]Loading train:  68%|██████▊   | 193/285 [02:57<01:12,  1.28it/s]Loading train:  68%|██████▊   | 194/285 [02:58<01:14,  1.22it/s]Loading train:  68%|██████▊   | 195/285 [02:59<01:10,  1.28it/s]Loading train:  69%|██████▉   | 196/285 [03:00<01:12,  1.22it/s]Loading train:  69%|██████▉   | 197/285 [03:00<01:12,  1.21it/s]Loading train:  69%|██████▉   | 198/285 [03:01<01:14,  1.17it/s]Loading train:  70%|██████▉   | 199/285 [03:02<01:10,  1.22it/s]Loading train:  70%|███████   | 200/285 [03:03<01:09,  1.22it/s]Loading train:  71%|███████   | 201/285 [03:04<01:13,  1.14it/s]Loading train:  71%|███████   | 202/285 [03:05<01:13,  1.13it/s]Loading train:  71%|███████   | 203/285 [03:06<01:11,  1.15it/s]Loading train:  72%|███████▏  | 204/285 [03:06<01:07,  1.20it/s]Loading train:  72%|███████▏  | 205/285 [03:07<01:04,  1.23it/s]Loading train:  72%|███████▏  | 206/285 [03:08<01:03,  1.25it/s]Loading train:  73%|███████▎  | 207/285 [03:09<01:05,  1.18it/s]Loading train:  73%|███████▎  | 208/285 [03:10<01:07,  1.14it/s]Loading train:  73%|███████▎  | 209/285 [03:11<01:07,  1.12it/s]Loading train:  74%|███████▎  | 210/285 [03:12<01:05,  1.15it/s]Loading train:  74%|███████▍  | 211/285 [03:12<01:00,  1.22it/s]Loading train:  74%|███████▍  | 212/285 [03:13<01:02,  1.17it/s]Loading train:  75%|███████▍  | 213/285 [03:14<00:59,  1.21it/s]Loading train:  75%|███████▌  | 214/285 [03:15<00:58,  1.21it/s]Loading train:  75%|███████▌  | 215/285 [03:16<00:59,  1.18it/s]Loading train:  76%|███████▌  | 216/285 [03:17<00:58,  1.18it/s]Loading train:  76%|███████▌  | 217/285 [03:17<00:59,  1.14it/s]Loading train:  76%|███████▋  | 218/285 [03:18<00:59,  1.12it/s]Loading train:  77%|███████▋  | 219/285 [03:19<01:00,  1.10it/s]Loading train:  77%|███████▋  | 220/285 [03:20<00:55,  1.16it/s]Loading train:  78%|███████▊  | 221/285 [03:21<00:54,  1.17it/s]Loading train:  78%|███████▊  | 222/285 [03:22<00:52,  1.20it/s]Loading train:  78%|███████▊  | 223/285 [03:22<00:48,  1.27it/s]Loading train:  79%|███████▊  | 224/285 [03:23<00:46,  1.32it/s]Loading train:  79%|███████▉  | 225/285 [03:24<00:45,  1.31it/s]Loading train:  79%|███████▉  | 226/285 [03:25<00:47,  1.25it/s]Loading train:  80%|███████▉  | 227/285 [03:26<00:46,  1.24it/s]Loading train:  80%|████████  | 228/285 [03:27<00:49,  1.15it/s]Loading train:  80%|████████  | 229/285 [03:27<00:48,  1.16it/s]Loading train:  81%|████████  | 230/285 [03:28<00:45,  1.20it/s]Loading train:  81%|████████  | 231/285 [03:29<00:43,  1.23it/s]Loading train:  81%|████████▏ | 232/285 [03:30<00:44,  1.20it/s]Loading train:  82%|████████▏ | 233/285 [03:31<00:42,  1.22it/s]Loading train:  82%|████████▏ | 234/285 [03:32<00:45,  1.11it/s]Loading train:  82%|████████▏ | 235/285 [03:32<00:40,  1.22it/s]Loading train:  83%|████████▎ | 236/285 [03:33<00:42,  1.14it/s]Loading train:  83%|████████▎ | 237/285 [03:34<00:41,  1.15it/s]Loading train:  84%|████████▎ | 238/285 [03:35<00:43,  1.09it/s]Loading train:  84%|████████▍ | 239/285 [03:36<00:41,  1.11it/s]Loading train:  84%|████████▍ | 240/285 [03:37<00:40,  1.11it/s]Loading train:  85%|████████▍ | 241/285 [03:38<00:36,  1.19it/s]Loading train:  85%|████████▍ | 242/285 [03:38<00:34,  1.23it/s]Loading train:  85%|████████▌ | 243/285 [03:39<00:33,  1.24it/s]Loading train:  86%|████████▌ | 244/285 [03:40<00:34,  1.19it/s]Loading train:  86%|████████▌ | 245/285 [03:41<00:33,  1.21it/s]Loading train:  86%|████████▋ | 246/285 [03:42<00:33,  1.15it/s]Loading train:  87%|████████▋ | 247/285 [03:43<00:34,  1.11it/s]Loading train:  87%|████████▋ | 248/285 [03:44<00:32,  1.14it/s]Loading train:  87%|████████▋ | 249/285 [03:45<00:31,  1.15it/s]Loading train:  88%|████████▊ | 250/285 [03:45<00:29,  1.17it/s]Loading train:  88%|████████▊ | 251/285 [03:46<00:28,  1.18it/s]Loading train:  88%|████████▊ | 252/285 [03:47<00:25,  1.28it/s]Loading train:  89%|████████▉ | 253/285 [03:48<00:25,  1.23it/s]Loading train:  89%|████████▉ | 254/285 [03:49<00:25,  1.23it/s]Loading train:  89%|████████▉ | 255/285 [03:49<00:24,  1.22it/s]Loading train:  90%|████████▉ | 256/285 [03:50<00:22,  1.28it/s]Loading train:  90%|█████████ | 257/285 [03:51<00:21,  1.30it/s]Loading train:  91%|█████████ | 258/285 [03:52<00:22,  1.20it/s]Loading train:  91%|█████████ | 259/285 [03:53<00:21,  1.22it/s]Loading train:  91%|█████████ | 260/285 [03:53<00:20,  1.21it/s]Loading train:  92%|█████████▏| 261/285 [03:54<00:19,  1.23it/s]Loading train:  92%|█████████▏| 262/285 [03:55<00:17,  1.30it/s]Loading train:  92%|█████████▏| 263/285 [03:56<00:16,  1.35it/s]Loading train:  93%|█████████▎| 264/285 [03:56<00:16,  1.28it/s]Loading train:  93%|█████████▎| 265/285 [03:57<00:16,  1.18it/s]Loading train:  93%|█████████▎| 266/285 [03:58<00:15,  1.20it/s]Loading train:  94%|█████████▎| 267/285 [03:59<00:15,  1.18it/s]Loading train:  94%|█████████▍| 268/285 [04:00<00:14,  1.18it/s]Loading train:  94%|█████████▍| 269/285 [04:01<00:13,  1.16it/s]Loading train:  95%|█████████▍| 270/285 [04:02<00:12,  1.22it/s]Loading train:  95%|█████████▌| 271/285 [04:02<00:11,  1.24it/s]Loading train:  95%|█████████▌| 272/285 [04:03<00:10,  1.24it/s]Loading train:  96%|█████████▌| 273/285 [04:04<00:09,  1.29it/s]Loading train:  96%|█████████▌| 274/285 [04:05<00:08,  1.29it/s]Loading train:  96%|█████████▋| 275/285 [04:05<00:07,  1.27it/s]Loading train:  97%|█████████▋| 276/285 [04:07<00:07,  1.15it/s]Loading train:  97%|█████████▋| 277/285 [04:07<00:06,  1.21it/s]Loading train:  98%|█████████▊| 278/285 [04:08<00:05,  1.24it/s]Loading train:  98%|█████████▊| 279/285 [04:09<00:05,  1.19it/s]Loading train:  98%|█████████▊| 280/285 [04:10<00:04,  1.20it/s]Loading train:  99%|█████████▊| 281/285 [04:11<00:03,  1.22it/s]Loading train:  99%|█████████▉| 282/285 [04:11<00:02,  1.26it/s]Loading train:  99%|█████████▉| 283/285 [04:12<00:01,  1.17it/s]Loading train: 100%|█████████▉| 284/285 [04:13<00:00,  1.18it/s]Loading train: 100%|██████████| 285/285 [04:14<00:00,  1.13it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:  11%|█         | 30/285 [00:00<00:00, 298.68it/s]concatenating: train:  21%|██        | 60/285 [00:00<00:00, 296.67it/s]concatenating: train:  33%|███▎      | 93/285 [00:00<00:00, 305.38it/s]concatenating: train:  44%|████▍     | 126/285 [00:00<00:00, 312.25it/s]concatenating: train:  54%|█████▍    | 155/285 [00:00<00:00, 302.50it/s]concatenating: train:  66%|██████▌   | 188/285 [00:00<00:00, 308.36it/s]concatenating: train:  78%|███████▊  | 221/285 [00:00<00:00, 312.52it/s]concatenating: train:  89%|████████▉ | 253/285 [00:00<00:00, 313.68it/s]concatenating: train:  99%|█████████▉| 283/285 [00:01<00:00, 197.10it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 258.81it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.29s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.27s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.23s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 126.60it/s]2019-07-10 21:09:27.002042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-10 21:09:27.002153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-10 21:09:27.002170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-10 21:09:27.002180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-10 21:09:27.002661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.40it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.36it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  5.92it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.45it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.72it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.75it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  6.94it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.92it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.57it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:02,  7.75it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:01,  9.69it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01, 10.09it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01, 10.17it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:02<00:01,  7.81it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.58it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.72it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.79it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  7.73it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 11.11it/s] 6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 26, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 26, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 26, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 26, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 13, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 13, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 13, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 20, 13, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 40, 26, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 40, 26, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 40, 26, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 80, 52, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 80, 52, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 52, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 80, 52, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 13)   793         dropout_5[0][0]                  
==================================================================================================
Total params: 223,833
Trainable params: 49,153
Non-trainable params: 174,680
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 15s - loss: 2.8234 - acc: 0.0979 - mDice: 0.0939 - val_loss: 2.0309 - val_acc: 0.0259 - val_mDice: 0.2068

Epoch 00001: val_mDice improved from -inf to 0.20684, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 9s - loss: 1.2324 - acc: 0.2338 - mDice: 0.3063 - val_loss: 1.5838 - val_acc: 0.3661 - val_mDice: 0.3195

Epoch 00002: val_mDice improved from 0.20684 to 0.31951, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 9s - loss: 0.9337 - acc: 0.7552 - mDice: 0.3998 - val_loss: 1.0915 - val_acc: 0.9056 - val_mDice: 0.4257

Epoch 00003: val_mDice improved from 0.31951 to 0.42574, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 9s - loss: 0.7419 - acc: 0.8896 - mDice: 0.4612 - val_loss: 1.0101 - val_acc: 0.9117 - val_mDice: 0.4583

Epoch 00004: val_mDice improved from 0.42574 to 0.45826, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 9s - loss: 0.6737 - acc: 0.8946 - mDice: 0.4942 - val_loss: 0.9579 - val_acc: 0.9159 - val_mDice: 0.4853

Epoch 00005: val_mDice improved from 0.45826 to 0.48529, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 9s - loss: 0.6252 - acc: 0.9000 - mDice: 0.5191 - val_loss: 0.8866 - val_acc: 0.9276 - val_mDice: 0.5128

Epoch 00006: val_mDice improved from 0.48529 to 0.51278, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 9s - loss: 0.5865 - acc: 0.9080 - mDice: 0.5401 - val_loss: 0.8780 - val_acc: 0.9256 - val_mDice: 0.5116

Epoch 00007: val_mDice did not improve from 0.51278
Epoch 8/300
 - 8s - loss: 0.5556 - acc: 0.9166 - mDice: 0.5574 - val_loss: 0.8502 - val_acc: 0.9288 - val_mDice: 0.5292

Epoch 00008: val_mDice improved from 0.51278 to 0.52924, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 9s - loss: 0.5291 - acc: 0.9216 - mDice: 0.5727 - val_loss: 0.8379 - val_acc: 0.9246 - val_mDice: 0.5278

Epoch 00009: val_mDice did not improve from 0.52924
Epoch 10/300
 - 9s - loss: 0.5099 - acc: 0.9241 - mDice: 0.5841 - val_loss: 0.8511 - val_acc: 0.9262 - val_mDice: 0.5328

Epoch 00010: val_mDice improved from 0.52924 to 0.53284, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 9s - loss: 0.4936 - acc: 0.9257 - mDice: 0.5939 - val_loss: 0.8469 - val_acc: 0.9287 - val_mDice: 0.5341

Epoch 00011: val_mDice improved from 0.53284 to 0.53406, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 9s - loss: 0.4777 - acc: 0.9271 - mDice: 0.6038 - val_loss: 0.8009 - val_acc: 0.9299 - val_mDice: 0.5419

Epoch 00012: val_mDice improved from 0.53406 to 0.54194, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 9s - loss: 0.4655 - acc: 0.9283 - mDice: 0.6115 - val_loss: 0.7742 - val_acc: 0.9331 - val_mDice: 0.5514

Epoch 00013: val_mDice improved from 0.54194 to 0.55136, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 9s - loss: 0.4549 - acc: 0.9293 - mDice: 0.6182 - val_loss: 0.8347 - val_acc: 0.9158 - val_mDice: 0.5181

Epoch 00014: val_mDice did not improve from 0.55136
Epoch 15/300
 - 9s - loss: 0.4463 - acc: 0.9300 - mDice: 0.6237 - val_loss: 0.7635 - val_acc: 0.9333 - val_mDice: 0.5538

Epoch 00015: val_mDice improved from 0.55136 to 0.55376, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 9s - loss: 0.4356 - acc: 0.9310 - mDice: 0.6307 - val_loss: 0.8400 - val_acc: 0.9334 - val_mDice: 0.5307

Epoch 00016: val_mDice did not improve from 0.55376
Epoch 17/300
 - 9s - loss: 0.4271 - acc: 0.9317 - mDice: 0.6364 - val_loss: 0.7651 - val_acc: 0.9312 - val_mDice: 0.5454

Epoch 00017: val_mDice did not improve from 0.55376
Epoch 18/300
 - 9s - loss: 0.4218 - acc: 0.9322 - mDice: 0.6398 - val_loss: 0.7789 - val_acc: 0.9283 - val_mDice: 0.5417

Epoch 00018: val_mDice did not improve from 0.55376
Epoch 19/300
 - 9s - loss: 0.4157 - acc: 0.9328 - mDice: 0.6440 - val_loss: 0.7661 - val_acc: 0.9357 - val_mDice: 0.5594

Epoch 00019: val_mDice improved from 0.55376 to 0.55938, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 20/300
 - 9s - loss: 0.4121 - acc: 0.9330 - mDice: 0.6464 - val_loss: 0.7833 - val_acc: 0.9283 - val_mDice: 0.5473

Epoch 00020: val_mDice did not improve from 0.55938
Epoch 21/300
 - 10s - loss: 0.4013 - acc: 0.9336 - mDice: 0.6535 - val_loss: 0.7697 - val_acc: 0.9329 - val_mDice: 0.5541

Epoch 00021: val_mDice did not improve from 0.55938
Epoch 22/300
 - 9s - loss: 0.4001 - acc: 0.9339 - mDice: 0.6546 - val_loss: 0.7632 - val_acc: 0.9368 - val_mDice: 0.5584

Epoch 00022: val_mDice did not improve from 0.55938
Epoch 23/300
 - 10s - loss: 0.3949 - acc: 0.9343 - mDice: 0.6580 - val_loss: 0.7679 - val_acc: 0.9332 - val_mDice: 0.5483

Epoch 00023: val_mDice did not improve from 0.55938
Epoch 24/300
 - 9s - loss: 0.3914 - acc: 0.9346 - mDice: 0.6605 - val_loss: 0.7624 - val_acc: 0.9319 - val_mDice: 0.5506

Epoch 00024: val_mDice did not improve from 0.55938
Epoch 25/300
 - 9s - loss: 0.3868 - acc: 0.9349 - mDice: 0.6636 - val_loss: 0.7694 - val_acc: 0.9271 - val_mDice: 0.5449

Epoch 00025: val_mDice did not improve from 0.55938
Epoch 26/300
 - 10s - loss: 0.3847 - acc: 0.9351 - mDice: 0.6651 - val_loss: 0.7479 - val_acc: 0.9370 - val_mDice: 0.5538

Epoch 00026: val_mDice did not improve from 0.55938
Epoch 27/300
 - 9s - loss: 0.3801 - acc: 0.9356 - mDice: 0.6684 - val_loss: 0.8182 - val_acc: 0.9244 - val_mDice: 0.5275

Epoch 00027: val_mDice did not improve from 0.55938
Epoch 28/300
 - 10s - loss: 0.3759 - acc: 0.9358 - mDice: 0.6713 - val_loss: 0.7815 - val_acc: 0.9372 - val_mDice: 0.5510

Epoch 00028: val_mDice did not improve from 0.55938
Epoch 29/300
 - 9s - loss: 0.3733 - acc: 0.9362 - mDice: 0.6731 - val_loss: 0.7112 - val_acc: 0.9346 - val_mDice: 0.5497

Epoch 00029: val_mDice did not improve from 0.55938
Epoch 30/300
 - 10s - loss: 0.3712 - acc: 0.9362 - mDice: 0.6745 - val_loss: 0.7076 - val_acc: 0.9330 - val_mDice: 0.5668

Epoch 00030: val_mDice improved from 0.55938 to 0.56684, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 31/300
 - 9s - loss: 0.3705 - acc: 0.9363 - mDice: 0.6751 - val_loss: 0.7973 - val_acc: 0.9398 - val_mDice: 0.5582

Epoch 00031: val_mDice did not improve from 0.56684
Epoch 32/300
 - 10s - loss: 0.3636 - acc: 0.9367 - mDice: 0.6799 - val_loss: 0.7466 - val_acc: 0.9341 - val_mDice: 0.5462

Epoch 00032: val_mDice did not improve from 0.56684
Epoch 33/300
 - 9s - loss: 0.3631 - acc: 0.9370 - mDice: 0.6804 - val_loss: 0.7159 - val_acc: 0.9342 - val_mDice: 0.5571

Epoch 00033: val_mDice did not improve from 0.56684
Epoch 34/300
 - 9s - loss: 0.3611 - acc: 0.9372 - mDice: 0.6819 - val_loss: 0.7991 - val_acc: 0.9312 - val_mDice: 0.5396

Epoch 00034: val_mDice did not improve from 0.56684
Epoch 35/300
 - 10s - loss: 0.3592 - acc: 0.9374 - mDice: 0.6831 - val_loss: 0.8083 - val_acc: 0.9389 - val_mDice: 0.5461

Epoch 00035: val_mDice did not improve from 0.56684
Epoch 36/300
 - 9s - loss: 0.3559 - acc: 0.9373 - mDice: 0.6854 - val_loss: 0.7632 - val_acc: 0.9392 - val_mDice: 0.5523

Epoch 00036: val_mDice did not improve from 0.56684
Epoch 37/300
 - 10s - loss: 0.3552 - acc: 0.9374 - mDice: 0.6859 - val_loss: 0.7902 - val_acc: 0.9318 - val_mDice: 0.5429

Epoch 00037: val_mDice did not improve from 0.56684
Epoch 38/300
 - 9s - loss: 0.3509 - acc: 0.9378 - mDice: 0.6890 - val_loss: 0.7073 - val_acc: 0.9359 - val_mDice: 0.5575

Epoch 00038: val_mDice did not improve from 0.56684
Epoch 39/300
 - 9s - loss: 0.3498 - acc: 0.9380 - mDice: 0.6899 - val_loss: 0.6853 - val_acc: 0.9360 - val_mDice: 0.5550

Epoch 00039: val_mDice did not improve from 0.56684
Epoch 40/300
 - 10s - loss: 0.3482 - acc: 0.9382 - mDice: 0.6910 - val_loss: 0.7851 - val_acc: 0.9365 - val_mDice: 0.5531

Epoch 00040: val_mDice did not improve from 0.56684
Epoch 41/300
 - 9s - loss: 0.3459 - acc: 0.9383 - mDice: 0.6927 - val_loss: 0.7337 - val_acc: 0.9369 - val_mDice: 0.5528

Epoch 00041: val_mDice did not improve from 0.56684
Epoch 42/300
 - 9s - loss: 0.3455 - acc: 0.9383 - mDice: 0.6930 - val_loss: 0.6943 - val_acc: 0.9341 - val_mDice: 0.5528

Epoch 00042: val_mDice did not improve from 0.56684
Epoch 43/300
 - 9s - loss: 0.3432 - acc: 0.9385 - mDice: 0.6945 - val_loss: 0.7559 - val_acc: 0.9387 - val_mDice: 0.5590

Epoch 00043: val_mDice did not improve from 0.56684
Epoch 44/300
 - 9s - loss: 0.3408 - acc: 0.9386 - mDice: 0.6963 - val_loss: 0.7131 - val_acc: 0.9355 - val_mDice: 0.5565

Epoch 00044: val_mDice did not improve from 0.56684
Epoch 45/300
 - 10s - loss: 0.3384 - acc: 0.9388 - mDice: 0.6981 - val_loss: 0.7321 - val_acc: 0.9312 - val_mDice: 0.5547

Epoch 00045: val_mDice did not improve from 0.56684
Epoch 46/300
 - 9s - loss: 0.3378 - acc: 0.9388 - mDice: 0.6985 - val_loss: 0.6803 - val_acc: 0.9354 - val_mDice: 0.5553

Epoch 00046: val_mDice did not improve from 0.56684
Epoch 47/300
 - 10s - loss: 0.3413 - acc: 0.9388 - mDice: 0.6975 - val_loss: 0.8031 - val_acc: 0.9216 - val_mDice: 0.5171

Epoch 00047: val_mDice did not improve from 0.56684
Epoch 48/300
 - 9s - loss: 0.3768 - acc: 0.9358 - mDice: 0.6705 - val_loss: 0.6549 - val_acc: 0.9354 - val_mDice: 0.5656

Epoch 00048: val_mDice did not improve from 0.56684
Epoch 49/300
 - 9s - loss: 0.3421 - acc: 0.9388 - mDice: 0.6952 - val_loss: 0.7058 - val_acc: 0.9383 - val_mDice: 0.5596

Epoch 00049: val_mDice did not improve from 0.56684
Epoch 50/300
 - 9s - loss: 0.3373 - acc: 0.9391 - mDice: 0.6988 - val_loss: 0.7775 - val_acc: 0.9389 - val_mDice: 0.5484

Epoch 00050: val_mDice did not improve from 0.56684
Epoch 51/300
 - 9s - loss: 0.3353 - acc: 0.9394 - mDice: 0.7003 - val_loss: 0.7142 - val_acc: 0.9379 - val_mDice: 0.5650

Epoch 00051: val_mDice did not improve from 0.56684
Epoch 52/300
 - 9s - loss: 0.3337 - acc: 0.9395 - mDice: 0.7015 - val_loss: 0.6731 - val_acc: 0.9375 - val_mDice: 0.5501

Epoch 00052: val_mDice did not improve from 0.56684
Epoch 53/300
 - 9s - loss: 0.3333 - acc: 0.9396 - mDice: 0.7019 - val_loss: 0.7084 - val_acc: 0.9382 - val_mDice: 0.5519

Epoch 00053: val_mDice did not improve from 0.56684
Epoch 54/300
 - 9s - loss: 0.3300 - acc: 0.9397 - mDice: 0.7042 - val_loss: 0.6739 - val_acc: 0.9381 - val_mDice: 0.5488

Epoch 00054: val_mDice did not improve from 0.56684
Epoch 55/300
 - 8s - loss: 0.3287 - acc: 0.9398 - mDice: 0.7051 - val_loss: 0.7845 - val_acc: 0.9399 - val_mDice: 0.5361

Epoch 00055: val_mDice did not improve from 0.56684
Epoch 56/300
 - 9s - loss: 0.3265 - acc: 0.9399 - mDice: 0.7068 - val_loss: 0.6811 - val_acc: 0.9350 - val_mDice: 0.5588

Epoch 00056: val_mDice did not improve from 0.56684
Epoch 57/300
 - 8s - loss: 0.3268 - acc: 0.9399 - mDice: 0.7066 - val_loss: 0.7114 - val_acc: 0.9392 - val_mDice: 0.5437

Epoch 00057: val_mDice did not improve from 0.56684
Epoch 58/300
 - 9s - loss: 0.3258 - acc: 0.9400 - mDice: 0.7073 - val_loss: 0.7115 - val_acc: 0.9299 - val_mDice: 0.5463

Epoch 00058: val_mDice did not improve from 0.56684
Epoch 59/300
 - 9s - loss: 0.3250 - acc: 0.9401 - mDice: 0.7080 - val_loss: 0.6799 - val_acc: 0.9383 - val_mDice: 0.5598

Epoch 00059: val_mDice did not improve from 0.56684
Epoch 60/300
 - 8s - loss: 0.3240 - acc: 0.9402 - mDice: 0.7087 - val_loss: 0.6176 - val_acc: 0.9358 - val_mDice: 0.5656

Epoch 00060: val_mDice did not improve from 0.56684
Epoch 61/300
 - 9s - loss: 0.3230 - acc: 0.9402 - mDice: 0.7095 - val_loss: 0.6859 - val_acc: 0.9388 - val_mDice: 0.5519

Epoch 00061: val_mDice did not improve from 0.56684
Epoch 62/300
 - 9s - loss: 0.3209 - acc: 0.9403 - mDice: 0.7110 - val_loss: 0.6899 - val_acc: 0.9355 - val_mDice: 0.5531

Epoch 00062: val_mDice did not improve from 0.56684
Epoch 63/300
 - 8s - loss: 0.3210 - acc: 0.9403 - mDice: 0.7109 - val_loss: 0.6622 - val_acc: 0.9385 - val_mDice: 0.5645

Epoch 00063: val_mDice did not improve from 0.56684
Epoch 64/300
 - 8s - loss: 0.3199 - acc: 0.9404 - mDice: 0.7118 - val_loss: 0.6782 - val_acc: 0.9323 - val_mDice: 0.5544

Epoch 00064: val_mDice did not improve from 0.56684
Epoch 65/300
 - 9s - loss: 0.3176 - acc: 0.9406 - mDice: 0.7134 - val_loss: 0.6400 - val_acc: 0.9389 - val_mDice: 0.5533

Epoch 00065: val_mDice did not improve from 0.56684
Epoch 66/300
 - 9s - loss: 0.3186 - acc: 0.9407 - mDice: 0.7128 - val_loss: 0.6383 - val_acc: 0.9323 - val_mDice: 0.5521

Epoch 00066: val_mDice did not improve from 0.56684
Epoch 67/300
 - 8s - loss: 0.3169 - acc: 0.9409 - mDice: 0.7140 - val_loss: 0.6590 - val_acc: 0.9351 - val_mDice: 0.5459

Epoch 00067: val_mDice did not improve from 0.56684
Epoch 68/300
 - 8s - loss: 0.3155 - acc: 0.9407 - mDice: 0.7150 - val_loss: 0.6358 - val_acc: 0.9389 - val_mDice: 0.5582

Epoch 00068: val_mDice did not improve from 0.56684
Epoch 69/300
 - 8s - loss: 0.3153 - acc: 0.9408 - mDice: 0.7151 - val_loss: 0.6473 - val_acc: 0.9370 - val_mDice: 0.5541

Epoch 00069: val_mDice did not improve from 0.56684
Epoch 70/300
 - 8s - loss: 0.3140 - acc: 0.9410 - mDice: 0.7161 - val_loss: 0.6796 - val_acc: 0.9308 - val_mDice: 0.5521

Epoch 00070: val_mDice did not improve from 0.56684
Restoring model weights from the end of the best epoch
Epoch 00070: early stopping
{'val_loss': [2.030916383633247, 1.5837703484755297, 1.0915081615631397, 1.0101366707911859, 0.9578940432805282, 0.8865737777489883, 0.8780369919080001, 0.8502176060126378, 0.8378547750986539, 0.8510683224751399, 0.8468550168550931, 0.8008678188690772, 0.7741694519153008, 0.8347388368386489, 0.7635262379279504, 0.8399887818556565, 0.7650787624029013, 0.7789433185870831, 0.7660607420481168, 0.7833255919126364, 0.7697473260072561, 0.76320903805586, 0.7679019478651193, 0.7624339919823867, 0.769444268483382, 0.747876877968128, 0.8182145013259008, 0.7815151902345511, 0.7112424052678622, 0.7075654841386355, 0.7973289077098553, 0.7465738631211795, 0.7158548694390517, 0.799147720520313, 0.8083013066878686, 0.7631724866536947, 0.7902285915154678, 0.7073167103987473, 0.6853463787298936, 0.7851080642296717, 0.7337192870103396, 0.6943114858407241, 0.7559121617904077, 0.713136402460245, 0.7320879468551049, 0.6803195889179523, 0.8031302782205435, 0.6548900604248047, 0.705752588235415, 0.7775390033538525, 0.7142451497224661, 0.6731150631721203, 0.708361932864556, 0.6738950335062467, 0.7845471226252042, 0.6811337929505569, 0.7114361111934369, 0.7115280330181122, 0.6799100270638099, 0.6175572940936456, 0.6858818095463973, 0.6899193296065698, 0.6622272867422837, 0.6782125761875739, 0.6399502066465524, 0.638267803650636, 0.6589861053686875, 0.6358262919462644, 0.6472536715177389, 0.679615875849357], 'val_acc': [0.025938425412347827, 0.36605260463861317, 0.9055750576349405, 0.9116794696220984, 0.9159278067258688, 0.9275540847044724, 0.9256286735718067, 0.9287975934835581, 0.9245608632381146, 0.9261811146369348, 0.9286936269356654, 0.9298770404778994, 0.9331337878337274, 0.9158122218572177, 0.9332886475783128, 0.9333741871210245, 0.9311899107236129, 0.9283492152507489, 0.9356532096862793, 0.9282983449789194, 0.9329026639461517, 0.9367649784454932, 0.9332169661155114, 0.9318671455750098, 0.9271495777827042, 0.9370007354479569, 0.9243967441412119, 0.9371925661197076, 0.9345622337781466, 0.9330089413202726, 0.9398414217508756, 0.9341092109680176, 0.9341623301689441, 0.9312199606345251, 0.9388729815299695, 0.9392404579199277, 0.9317677754622239, 0.9359166736786182, 0.9360484182834625, 0.9364506075015435, 0.9368643554357382, 0.9340860820733584, 0.9386972922545213, 0.935463682963298, 0.9311806857585907, 0.935429009107443, 0.9215745054758512, 0.9354128218614138, 0.9383066961398492, 0.9388567690665905, 0.9379391440978417, 0.9374514818191528, 0.9382234720083383, 0.9381425885053781, 0.9398830326703879, 0.9350383854829348, 0.9391595652470222, 0.9298770060906043, 0.9382581504491659, 0.9357803120062902, 0.9387897780308356, 0.9355029647166913, 0.9385077632390536, 0.9322878030630258, 0.9389053330971644, 0.9323455760112176, 0.9351470172405243, 0.9389446377754211, 0.9370423463674692, 0.9308200959975903], 'val_mDice': [0.20684213019334352, 0.3195086737664846, 0.4257438606940783, 0.45826158271386075, 0.4852857475097363, 0.5127821186414132, 0.511644265972651, 0.5292382950966175, 0.5278303250670433, 0.5328435794665263, 0.5340646849228785, 0.5419361264659808, 0.551357069840798, 0.5181028235417146, 0.5537555240667783, 0.5306746323521321, 0.5454171059223322, 0.5416689228553039, 0.5593844675100766, 0.5472711026668549, 0.5540549812408594, 0.5584494947240903, 0.54832041148956, 0.5506132543087006, 0.5449120069925601, 0.5538132803944441, 0.5274668370301907, 0.5509876179007384, 0.5496518376928109, 0.5668401431578857, 0.5581835634433306, 0.546206113237601, 0.5570692718029022, 0.539638856282601, 0.5460563130103625, 0.552273646570169, 0.5428852129441041, 0.5574915300195034, 0.5549799381540372, 0.5530537524475501, 0.5528206590276498, 0.5527769779929748, 0.5590104919213515, 0.5564752931778247, 0.5546787816744584, 0.5553050304834659, 0.517063109920575, 0.5655655425328475, 0.5595835670828819, 0.5483799553834475, 0.5649900482251093, 0.5500618763841115, 0.5519207223103597, 0.5487597504487405, 0.5360641513879483, 0.5588151193582095, 0.543661157385661, 0.5462968498468399, 0.559825351031927, 0.5655937939882278, 0.5518568307161331, 0.5531005842181352, 0.5645227552606509, 0.5543617869798954, 0.5532932109557666, 0.5520683079957962, 0.5458778802018899, 0.5581700457976415, 0.5541285161788647, 0.5520814622824008], 'loss': [2.8233867936234165, 1.2323510922112941, 0.9337088274777645, 0.7419440326276855, 0.6737490823037354, 0.6252440192993415, 0.5864837536246291, 0.5556005041922281, 0.5290618969771207, 0.5099379869362948, 0.49363379629953624, 0.47768758175657383, 0.4654809992427504, 0.45491159830235867, 0.4463246963395301, 0.4355636841667256, 0.42709118386184797, 0.4218040227197385, 0.4156965167058698, 0.41205338653433665, 0.4013237644361084, 0.40007259218134056, 0.3949138819676621, 0.39144544179046176, 0.3868146857454099, 0.3847320198622465, 0.3800674169598762, 0.3759156990912109, 0.37326822616864225, 0.37124781758156605, 0.3705436163235335, 0.3635734600394368, 0.3630611587964795, 0.36105660016627084, 0.3592468014829198, 0.3559122223849887, 0.3551860902045119, 0.3509254898079908, 0.3498487031477399, 0.3481527751858446, 0.34587539022648056, 0.34553359833841535, 0.34322855435844324, 0.34081166896621734, 0.33835179863419795, 0.33781721320834357, 0.34125321731898967, 0.3768464901301514, 0.342074696932795, 0.3373125181843035, 0.33532592230679575, 0.3336924881768229, 0.33330348644717905, 0.32999549181239474, 0.32869599291091584, 0.3265478696141924, 0.32678814707707843, 0.32584189417110887, 0.32497120758082765, 0.324048560183833, 0.3229774643571617, 0.32085824975841637, 0.3210307024567041, 0.31992919567567357, 0.31764654915380947, 0.31863550136122964, 0.3168791865473533, 0.3155022711812334, 0.3153213353479391, 0.31398570732987696], 'acc': [0.09793911688631007, 0.2337889470820342, 0.7551677002960011, 0.8895942955607254, 0.8945641734938027, 0.899989023992939, 0.9080072502242038, 0.9165997959685086, 0.9216249037479372, 0.9241170306646834, 0.9256599204935821, 0.9270669774882503, 0.9283437699307642, 0.9293205419622818, 0.9299925639215325, 0.9309717750544919, 0.931679535388155, 0.9322313129775454, 0.9328241267349847, 0.933039926904314, 0.9336485013710686, 0.9338822579082611, 0.934251136372123, 0.9345784306603143, 0.9349416318298607, 0.9350887288975119, 0.9355609811155996, 0.9358254905161708, 0.9361968743155762, 0.9361774529476706, 0.9363249234857236, 0.9367171946480454, 0.9369882155880764, 0.937195524231134, 0.9373590654193569, 0.937338697732204, 0.9374308503224908, 0.9378196178113228, 0.9379544556992945, 0.9381904494638187, 0.9382629435759217, 0.9382714327274626, 0.9384878520748772, 0.938586396868902, 0.938814074584372, 0.9387568586549668, 0.938798009051967, 0.9358263959812522, 0.9387755045852988, 0.9391345198684586, 0.9393713779470572, 0.9394541781216675, 0.9395851569620762, 0.9397023283752537, 0.9398295336034392, 0.9398853566157778, 0.9399196056491563, 0.9399659409301369, 0.940097452183002, 0.9402190515951708, 0.9401758657295106, 0.9402750311473479, 0.9403167543492171, 0.9403937468941687, 0.9406406517223624, 0.9407104205174892, 0.9408617955253297, 0.9407354930961505, 0.9408293377536255, 0.9410015500186609], 'mDice': [0.09387722850171587, 0.3062779658517747, 0.39983490313109815, 0.4611834478721313, 0.49422810610442497, 0.5190599249054186, 0.5401128811292253, 0.5573905088261002, 0.5726572184295305, 0.5840709808292088, 0.5939029731137456, 0.603780575116534, 0.611536428017622, 0.6182250303007476, 0.6237203183126199, 0.6307408673389695, 0.6363821880718247, 0.6398288980682958, 0.6440408086189647, 0.646447022886038, 0.6535468666049746, 0.6546051448026751, 0.6580284078611743, 0.6604535398828052, 0.6636432714813213, 0.6650797530182787, 0.6683846875375172, 0.6712621684599042, 0.6730902988422756, 0.6744959209772929, 0.6750550037005132, 0.6799471084783297, 0.6804196076849164, 0.6818689568603675, 0.6830961893188177, 0.6853671722401995, 0.6858862286551592, 0.6889770628066232, 0.6898821530049218, 0.6910432753478932, 0.6926958662144518, 0.6929983523766471, 0.6944861493679713, 0.6962991762367945, 0.6980662845129414, 0.6984805087041428, 0.6975283465140928, 0.6704597599796843, 0.6951758449811793, 0.6987692097186998, 0.7003151680461641, 0.7014658365601006, 0.7019210245670191, 0.7042084538847563, 0.7051408812699146, 0.706754488390024, 0.7065641668618391, 0.7072895948356734, 0.7079516206842655, 0.7086663439211608, 0.7095370779318485, 0.7110154880519108, 0.7109143898285459, 0.71178925856996, 0.7134057065607887, 0.7127800105924834, 0.7140190616190945, 0.7150293653173815, 0.7151417165491663, 0.7161221235844852]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.25s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.03s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.83s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:25,  1.78s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:46,  1.65s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:51,  1.67s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:25,  1.58s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:34,  1.62s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:17,  1.57s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:29,  1.62s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:29,  1.62s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:49,  1.70s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:04,  1.76s/it]predicting train subjects:   4%|▍         | 11/285 [00:17<07:35,  1.66s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<07:48,  1.72s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:43,  1.70s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<07:48,  1.73s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<07:57,  1.77s/it]predicting train subjects:   6%|▌         | 16/285 [00:26<08:01,  1.79s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<07:38,  1.71s/it]predicting train subjects:   6%|▋         | 18/285 [00:30<07:37,  1.71s/it]predicting train subjects:   7%|▋         | 19/285 [00:31<07:25,  1.68s/it]predicting train subjects:   7%|▋         | 20/285 [00:33<07:27,  1.69s/it]predicting train subjects:   7%|▋         | 21/285 [00:35<07:38,  1.74s/it]predicting train subjects:   8%|▊         | 22/285 [00:36<07:24,  1.69s/it]predicting train subjects:   8%|▊         | 23/285 [00:38<07:27,  1.71s/it]predicting train subjects:   8%|▊         | 24/285 [00:40<07:11,  1.65s/it]predicting train subjects:   9%|▉         | 25/285 [00:42<07:23,  1.71s/it]predicting train subjects:   9%|▉         | 26/285 [00:43<07:31,  1.74s/it]predicting train subjects:   9%|▉         | 27/285 [00:45<07:12,  1.68s/it]predicting train subjects:  10%|▉         | 28/285 [00:47<07:12,  1.68s/it]predicting train subjects:  10%|█         | 29/285 [00:48<07:10,  1.68s/it]predicting train subjects:  11%|█         | 30/285 [00:50<07:23,  1.74s/it]predicting train subjects:  11%|█         | 31/285 [00:52<07:26,  1.76s/it]predicting train subjects:  11%|█         | 32/285 [00:53<07:07,  1.69s/it]predicting train subjects:  12%|█▏        | 33/285 [00:55<07:12,  1.72s/it]predicting train subjects:  12%|█▏        | 34/285 [00:57<07:16,  1.74s/it]predicting train subjects:  12%|█▏        | 35/285 [00:59<07:28,  1.79s/it]predicting train subjects:  13%|█▎        | 36/285 [01:01<07:07,  1.72s/it]predicting train subjects:  13%|█▎        | 37/285 [01:02<07:04,  1.71s/it]predicting train subjects:  13%|█▎        | 38/285 [01:04<07:09,  1.74s/it]predicting train subjects:  14%|█▎        | 39/285 [01:06<06:50,  1.67s/it]predicting train subjects:  14%|█▍        | 40/285 [01:07<06:51,  1.68s/it]predicting train subjects:  14%|█▍        | 41/285 [01:09<06:40,  1.64s/it]predicting train subjects:  15%|█▍        | 42/285 [01:10<06:31,  1.61s/it]predicting train subjects:  15%|█▌        | 43/285 [01:12<06:39,  1.65s/it]predicting train subjects:  15%|█▌        | 44/285 [01:14<06:56,  1.73s/it]predicting train subjects:  16%|█▌        | 45/285 [01:16<06:48,  1.70s/it]predicting train subjects:  16%|█▌        | 46/285 [01:17<06:58,  1.75s/it]predicting train subjects:  16%|█▋        | 47/285 [01:19<06:54,  1.74s/it]predicting train subjects:  17%|█▋        | 48/285 [01:21<06:59,  1.77s/it]predicting train subjects:  17%|█▋        | 49/285 [01:23<07:07,  1.81s/it]predicting train subjects:  18%|█▊        | 50/285 [01:25<06:58,  1.78s/it]predicting train subjects:  18%|█▊        | 51/285 [01:27<07:03,  1.81s/it]predicting train subjects:  18%|█▊        | 52/285 [01:28<06:47,  1.75s/it]predicting train subjects:  19%|█▊        | 53/285 [01:30<06:48,  1.76s/it]predicting train subjects:  19%|█▉        | 54/285 [01:32<06:51,  1.78s/it]predicting train subjects:  19%|█▉        | 55/285 [01:33<06:33,  1.71s/it]predicting train subjects:  20%|█▉        | 56/285 [01:35<06:32,  1.71s/it]predicting train subjects:  20%|██        | 57/285 [01:37<06:19,  1.66s/it]predicting train subjects:  20%|██        | 58/285 [01:38<06:23,  1.69s/it]predicting train subjects:  21%|██        | 59/285 [01:40<06:38,  1.77s/it]predicting train subjects:  21%|██        | 60/285 [01:42<06:42,  1.79s/it]predicting train subjects:  21%|██▏       | 61/285 [01:44<06:23,  1.71s/it]predicting train subjects:  22%|██▏       | 62/285 [01:45<06:31,  1.75s/it]predicting train subjects:  22%|██▏       | 63/285 [01:47<06:29,  1.76s/it]predicting train subjects:  22%|██▏       | 64/285 [01:49<06:13,  1.69s/it]predicting train subjects:  23%|██▎       | 65/285 [01:50<06:12,  1.69s/it]predicting train subjects:  23%|██▎       | 66/285 [01:52<06:11,  1.70s/it]predicting train subjects:  24%|██▎       | 67/285 [01:54<06:09,  1.69s/it]predicting train subjects:  24%|██▍       | 68/285 [01:56<06:04,  1.68s/it]predicting train subjects:  24%|██▍       | 69/285 [01:57<06:12,  1.72s/it]predicting train subjects:  25%|██▍       | 70/285 [01:59<06:10,  1.72s/it]predicting train subjects:  25%|██▍       | 71/285 [02:01<06:10,  1.73s/it]predicting train subjects:  25%|██▌       | 72/285 [02:02<05:54,  1.66s/it]predicting train subjects:  26%|██▌       | 73/285 [02:04<05:52,  1.66s/it]predicting train subjects:  26%|██▌       | 74/285 [02:06<05:54,  1.68s/it]predicting train subjects:  26%|██▋       | 75/285 [02:07<05:55,  1.69s/it]predicting train subjects:  27%|██▋       | 76/285 [02:09<05:55,  1.70s/it]predicting train subjects:  27%|██▋       | 77/285 [02:11<05:42,  1.64s/it]predicting train subjects:  27%|██▋       | 78/285 [02:12<05:33,  1.61s/it]predicting train subjects:  28%|██▊       | 79/285 [02:14<05:41,  1.66s/it]predicting train subjects:  28%|██▊       | 80/285 [02:16<05:42,  1.67s/it]predicting train subjects:  28%|██▊       | 81/285 [02:17<05:31,  1.63s/it]predicting train subjects:  29%|██▉       | 82/285 [02:19<05:31,  1.63s/it]predicting train subjects:  29%|██▉       | 83/285 [02:20<05:23,  1.60s/it]predicting train subjects:  29%|██▉       | 84/285 [02:22<05:15,  1.57s/it]predicting train subjects:  30%|██▉       | 85/285 [02:24<05:22,  1.61s/it]predicting train subjects:  30%|███       | 86/285 [02:25<05:25,  1.63s/it]predicting train subjects:  31%|███       | 87/285 [02:27<05:26,  1.65s/it]predicting train subjects:  31%|███       | 88/285 [02:29<05:20,  1.63s/it]predicting train subjects:  31%|███       | 89/285 [02:30<05:21,  1.64s/it]predicting train subjects:  32%|███▏      | 90/285 [02:32<05:25,  1.67s/it]predicting train subjects:  32%|███▏      | 91/285 [02:33<05:15,  1.63s/it]predicting train subjects:  32%|███▏      | 92/285 [02:35<05:18,  1.65s/it]predicting train subjects:  33%|███▎      | 93/285 [02:37<05:08,  1.61s/it]predicting train subjects:  33%|███▎      | 94/285 [02:38<05:15,  1.65s/it]predicting train subjects:  33%|███▎      | 95/285 [02:40<05:18,  1.68s/it]predicting train subjects:  34%|███▎      | 96/285 [02:42<05:15,  1.67s/it]predicting train subjects:  34%|███▍      | 97/285 [02:44<05:15,  1.68s/it]predicting train subjects:  34%|███▍      | 98/285 [02:45<05:11,  1.67s/it]predicting train subjects:  35%|███▍      | 99/285 [02:47<05:12,  1.68s/it]predicting train subjects:  35%|███▌      | 100/285 [02:49<05:16,  1.71s/it]predicting train subjects:  35%|███▌      | 101/285 [02:50<05:06,  1.66s/it]predicting train subjects:  36%|███▌      | 102/285 [02:52<05:09,  1.69s/it]predicting train subjects:  36%|███▌      | 103/285 [02:54<05:00,  1.65s/it]predicting train subjects:  36%|███▋      | 104/285 [02:55<05:00,  1.66s/it]predicting train subjects:  37%|███▋      | 105/285 [02:57<05:02,  1.68s/it]predicting train subjects:  37%|███▋      | 106/285 [02:58<04:52,  1.63s/it]predicting train subjects:  38%|███▊      | 107/285 [03:00<04:53,  1.65s/it]predicting train subjects:  38%|███▊      | 108/285 [03:02<04:47,  1.62s/it]predicting train subjects:  38%|███▊      | 109/285 [03:03<04:53,  1.67s/it]predicting train subjects:  39%|███▊      | 110/285 [03:05<04:57,  1.70s/it]predicting train subjects:  39%|███▉      | 111/285 [03:07<04:49,  1.66s/it]predicting train subjects:  39%|███▉      | 112/285 [03:09<04:49,  1.67s/it]predicting train subjects:  40%|███▉      | 113/285 [03:10<04:48,  1.68s/it]predicting train subjects:  40%|████      | 114/285 [03:12<04:49,  1.69s/it]predicting train subjects:  40%|████      | 115/285 [03:14<04:49,  1.70s/it]predicting train subjects:  41%|████      | 116/285 [03:15<04:50,  1.72s/it]predicting train subjects:  41%|████      | 117/285 [03:17<04:39,  1.67s/it]predicting train subjects:  41%|████▏     | 118/285 [03:18<04:30,  1.62s/it]predicting train subjects:  42%|████▏     | 119/285 [03:20<04:34,  1.65s/it]predicting train subjects:  42%|████▏     | 120/285 [03:22<04:25,  1.61s/it]predicting train subjects:  42%|████▏     | 121/285 [03:23<04:19,  1.58s/it]predicting train subjects:  43%|████▎     | 122/285 [03:25<04:09,  1.53s/it]predicting train subjects:  43%|████▎     | 123/285 [03:26<04:00,  1.49s/it]predicting train subjects:  44%|████▎     | 124/285 [03:28<04:03,  1.51s/it]predicting train subjects:  44%|████▍     | 125/285 [03:29<04:00,  1.51s/it]predicting train subjects:  44%|████▍     | 126/285 [03:31<03:55,  1.48s/it]predicting train subjects:  45%|████▍     | 127/285 [03:32<03:50,  1.46s/it]predicting train subjects:  45%|████▍     | 128/285 [03:34<03:55,  1.50s/it]predicting train subjects:  45%|████▌     | 129/285 [03:35<03:50,  1.48s/it]predicting train subjects:  46%|████▌     | 130/285 [03:36<03:43,  1.44s/it]predicting train subjects:  46%|████▌     | 131/285 [03:38<03:44,  1.46s/it]predicting train subjects:  46%|████▋     | 132/285 [03:39<03:50,  1.51s/it]predicting train subjects:  47%|████▋     | 133/285 [03:41<03:42,  1.46s/it]predicting train subjects:  47%|████▋     | 134/285 [03:42<03:40,  1.46s/it]predicting train subjects:  47%|████▋     | 135/285 [03:44<03:36,  1.44s/it]predicting train subjects:  48%|████▊     | 136/285 [03:45<03:32,  1.43s/it]predicting train subjects:  48%|████▊     | 137/285 [03:47<03:35,  1.46s/it]predicting train subjects:  48%|████▊     | 138/285 [03:48<03:31,  1.44s/it]predicting train subjects:  49%|████▉     | 139/285 [03:50<03:36,  1.48s/it]predicting train subjects:  49%|████▉     | 140/285 [03:51<03:41,  1.53s/it]predicting train subjects:  49%|████▉     | 141/285 [03:53<03:33,  1.48s/it]predicting train subjects:  50%|████▉     | 142/285 [03:54<03:27,  1.45s/it]predicting train subjects:  50%|█████     | 143/285 [03:55<03:20,  1.41s/it]predicting train subjects:  51%|█████     | 144/285 [03:57<03:24,  1.45s/it]predicting train subjects:  51%|█████     | 145/285 [03:58<03:19,  1.42s/it]predicting train subjects:  51%|█████     | 146/285 [04:00<03:22,  1.46s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:01<03:17,  1.43s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:03<03:22,  1.48s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:04<03:17,  1.45s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:05<03:13,  1.44s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:07<03:19,  1.49s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:08<03:15,  1.47s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:10<03:10,  1.44s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:11<03:13,  1.48s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:13<03:07,  1.44s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:14<03:12,  1.49s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:16<03:06,  1.46s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:17<03:04,  1.46s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:19<03:06,  1.48s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:20<03:01,  1.45s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:22<03:02,  1.47s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:23<02:57,  1.44s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:24<02:57,  1.45s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:26<02:53,  1.43s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:27<02:48,  1.41s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:29<02:53,  1.46s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:30<02:55,  1.49s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:32<02:48,  1.44s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:33<02:45,  1.42s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:34<02:41,  1.41s/it]predicting train subjects:  60%|██████    | 171/285 [04:36<02:39,  1.40s/it]predicting train subjects:  60%|██████    | 172/285 [04:37<02:38,  1.40s/it]predicting train subjects:  61%|██████    | 173/285 [04:39<02:35,  1.39s/it]predicting train subjects:  61%|██████    | 174/285 [04:40<02:31,  1.36s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:41<02:35,  1.42s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:43<02:38,  1.46s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:44<02:34,  1.43s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:46<02:29,  1.39s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:47<02:26,  1.38s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:49<02:34,  1.47s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:50<02:35,  1.50s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:52<02:35,  1.51s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:53<02:28,  1.46s/it]predicting train subjects:  65%|██████▍   | 184/285 [04:54<02:24,  1.43s/it]predicting train subjects:  65%|██████▍   | 185/285 [04:56<02:19,  1.40s/it]predicting train subjects:  65%|██████▌   | 186/285 [04:58<02:27,  1.49s/it]predicting train subjects:  66%|██████▌   | 187/285 [04:59<02:36,  1.60s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:01<02:37,  1.63s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:02<02:29,  1.56s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:04<02:22,  1.50s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:05<02:23,  1.53s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:07<02:24,  1.55s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:08<02:15,  1.48s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:10<02:14,  1.47s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:11<02:07,  1.42s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:13<02:16,  1.53s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:15<02:21,  1.60s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:16<02:21,  1.63s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:18<02:12,  1.54s/it]predicting train subjects:  70%|███████   | 200/285 [05:19<02:06,  1.49s/it]predicting train subjects:  71%|███████   | 201/285 [05:21<02:09,  1.54s/it]predicting train subjects:  71%|███████   | 202/285 [05:22<02:07,  1.54s/it]predicting train subjects:  71%|███████   | 203/285 [05:24<02:06,  1.54s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:25<01:57,  1.45s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:26<01:54,  1.43s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:28<01:50,  1.40s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:29<01:56,  1.50s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:31<01:59,  1.56s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:33<02:01,  1.60s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:34<01:52,  1.50s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:35<01:48,  1.46s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:37<01:48,  1.49s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:39<01:48,  1.50s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:40<01:42,  1.45s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:42<01:48,  1.54s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:43<01:41,  1.47s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:45<01:47,  1.58s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:47<01:50,  1.65s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:48<01:50,  1.68s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:50<01:42,  1.58s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:51<01:37,  1.53s/it]predicting train subjects:  78%|███████▊  | 222/285 [05:53<01:37,  1.55s/it]predicting train subjects:  78%|███████▊  | 223/285 [05:54<01:32,  1.49s/it]predicting train subjects:  79%|███████▊  | 224/285 [05:55<01:28,  1.45s/it]predicting train subjects:  79%|███████▉  | 225/285 [05:57<01:24,  1.40s/it]predicting train subjects:  79%|███████▉  | 226/285 [05:58<01:29,  1.51s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:00<01:31,  1.58s/it]predicting train subjects:  80%|████████  | 228/285 [06:02<01:33,  1.65s/it]predicting train subjects:  80%|████████  | 229/285 [06:04<01:32,  1.65s/it]predicting train subjects:  81%|████████  | 230/285 [06:05<01:24,  1.54s/it]predicting train subjects:  81%|████████  | 231/285 [06:06<01:20,  1.49s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:08<01:20,  1.52s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:09<01:16,  1.46s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:11<01:19,  1.55s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:12<01:13,  1.48s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:14<01:16,  1.57s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:16<01:18,  1.63s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:18<01:17,  1.64s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:19<01:15,  1.63s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:20<01:08,  1.53s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:22<01:05,  1.48s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:23<01:01,  1.42s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:24<00:57,  1.37s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:26<01:00,  1.48s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:27<00:56,  1.41s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:29<00:58,  1.51s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:31<00:59,  1.57s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:32<00:58,  1.58s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:34<00:53,  1.50s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:35<00:51,  1.48s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:36<00:48,  1.42s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:38<00:45,  1.37s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:39<00:47,  1.50s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:41<00:48,  1.57s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:43<00:48,  1.60s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:44<00:44,  1.53s/it]predicting train subjects:  90%|█████████ | 257/285 [06:46<00:41,  1.49s/it]predicting train subjects:  91%|█████████ | 258/285 [06:47<00:41,  1.52s/it]predicting train subjects:  91%|█████████ | 259/285 [06:49<00:39,  1.53s/it]predicting train subjects:  91%|█████████ | 260/285 [06:50<00:36,  1.47s/it]predicting train subjects:  92%|█████████▏| 261/285 [06:51<00:34,  1.44s/it]predicting train subjects:  92%|█████████▏| 262/285 [06:53<00:32,  1.40s/it]predicting train subjects:  92%|█████████▏| 263/285 [06:54<00:30,  1.38s/it]predicting train subjects:  93%|█████████▎| 264/285 [06:56<00:31,  1.50s/it]predicting train subjects:  93%|█████████▎| 265/285 [06:58<00:31,  1.58s/it]predicting train subjects:  93%|█████████▎| 266/285 [06:59<00:28,  1.50s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:00<00:26,  1.47s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:02<00:26,  1.55s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:04<00:25,  1.57s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:05<00:22,  1.48s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:06<00:20,  1.47s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:08<00:19,  1.51s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:09<00:17,  1.43s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:11<00:15,  1.38s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:12<00:14,  1.46s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:14<00:13,  1.54s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:15<00:11,  1.47s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:17<00:10,  1.46s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:18<00:09,  1.51s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:20<00:07,  1.45s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:21<00:05,  1.43s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:22<00:04,  1.39s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:24<00:02,  1.48s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:26<00:01,  1.55s/it]predicting train subjects: 100%|██████████| 285/285 [07:27<00:00,  1.61s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM10_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:42,  1.63s/it]Loading train:   1%|          | 2/285 [00:02<07:03,  1.50s/it]Loading train:   1%|          | 3/285 [00:04<06:52,  1.46s/it]Loading train:   1%|▏         | 4/285 [00:05<06:10,  1.32s/it]Loading train:   2%|▏         | 5/285 [00:06<06:29,  1.39s/it]Loading train:   2%|▏         | 6/285 [00:07<06:11,  1.33s/it]Loading train:   2%|▏         | 7/285 [00:09<06:32,  1.41s/it]Loading train:   3%|▎         | 8/285 [00:10<06:19,  1.37s/it]Loading train:   3%|▎         | 9/285 [00:12<06:36,  1.44s/it]Loading train:   4%|▎         | 10/285 [00:13<05:54,  1.29s/it]Loading train:   4%|▍         | 11/285 [00:14<05:05,  1.12s/it]Loading train:   4%|▍         | 12/285 [00:15<04:51,  1.07s/it]Loading train:   5%|▍         | 13/285 [00:15<04:25,  1.03it/s]Loading train:   5%|▍         | 14/285 [00:16<04:22,  1.03it/s]Loading train:   5%|▌         | 15/285 [00:17<04:21,  1.03it/s]Loading train:   6%|▌         | 16/285 [00:18<04:12,  1.07it/s]Loading train:   6%|▌         | 17/285 [00:19<04:17,  1.04it/s]Loading train:   6%|▋         | 18/285 [00:20<04:13,  1.05it/s]Loading train:   7%|▋         | 19/285 [00:21<03:59,  1.11it/s]Loading train:   7%|▋         | 20/285 [00:22<04:00,  1.10it/s]Loading train:   7%|▋         | 21/285 [00:23<04:00,  1.10it/s]Loading train:   8%|▊         | 22/285 [00:23<03:50,  1.14it/s]Loading train:   8%|▊         | 23/285 [00:24<03:58,  1.10it/s]Loading train:   8%|▊         | 24/285 [00:25<03:44,  1.16it/s]Loading train:   9%|▉         | 25/285 [00:26<03:51,  1.12it/s]Loading train:   9%|▉         | 26/285 [00:27<03:50,  1.12it/s]Loading train:   9%|▉         | 27/285 [00:28<03:44,  1.15it/s]Loading train:  10%|▉         | 28/285 [00:29<03:46,  1.14it/s]Loading train:  10%|█         | 29/285 [00:30<03:55,  1.09it/s]Loading train:  11%|█         | 30/285 [00:31<04:01,  1.06it/s]Loading train:  11%|█         | 31/285 [00:32<04:04,  1.04it/s]Loading train:  11%|█         | 32/285 [00:33<03:57,  1.06it/s]Loading train:  12%|█▏        | 33/285 [00:34<03:51,  1.09it/s]Loading train:  12%|█▏        | 34/285 [00:34<03:52,  1.08it/s]Loading train:  12%|█▏        | 35/285 [00:35<03:51,  1.08it/s]Loading train:  13%|█▎        | 36/285 [00:36<03:38,  1.14it/s]Loading train:  13%|█▎        | 37/285 [00:37<03:35,  1.15it/s]Loading train:  13%|█▎        | 38/285 [00:38<03:43,  1.10it/s]Loading train:  14%|█▎        | 39/285 [00:39<03:27,  1.19it/s]Loading train:  14%|█▍        | 40/285 [00:39<03:20,  1.22it/s]Loading train:  14%|█▍        | 41/285 [00:40<03:08,  1.29it/s]Loading train:  15%|█▍        | 42/285 [00:41<02:59,  1.35it/s]Loading train:  15%|█▌        | 43/285 [00:42<03:08,  1.29it/s]Loading train:  15%|█▌        | 44/285 [00:43<03:19,  1.21it/s]Loading train:  16%|█▌        | 45/285 [00:43<03:07,  1.28it/s]Loading train:  16%|█▌        | 46/285 [00:44<03:18,  1.20it/s]Loading train:  16%|█▋        | 47/285 [00:45<03:06,  1.28it/s]Loading train:  17%|█▋        | 48/285 [00:46<03:12,  1.23it/s]Loading train:  17%|█▋        | 49/285 [00:47<03:21,  1.17it/s]Loading train:  18%|█▊        | 50/285 [00:48<03:21,  1.17it/s]Loading train:  18%|█▊        | 51/285 [00:49<03:27,  1.13it/s]Loading train:  18%|█▊        | 52/285 [00:49<03:18,  1.17it/s]Loading train:  19%|█▊        | 53/285 [00:50<03:16,  1.18it/s]Loading train:  19%|█▉        | 54/285 [00:51<03:28,  1.11it/s]Loading train:  19%|█▉        | 55/285 [00:52<03:28,  1.10it/s]Loading train:  20%|█▉        | 56/285 [00:53<03:29,  1.09it/s]Loading train:  20%|██        | 57/285 [00:54<03:21,  1.13it/s]Loading train:  20%|██        | 58/285 [00:55<03:19,  1.14it/s]Loading train:  21%|██        | 59/285 [00:56<03:21,  1.12it/s]Loading train:  21%|██        | 60/285 [00:57<03:25,  1.09it/s]Loading train:  21%|██▏       | 61/285 [00:57<03:20,  1.12it/s]Loading train:  22%|██▏       | 62/285 [00:58<03:23,  1.10it/s]Loading train:  22%|██▏       | 63/285 [00:59<03:24,  1.08it/s]Loading train:  22%|██▏       | 64/285 [01:01<03:48,  1.03s/it]Loading train:  23%|██▎       | 65/285 [01:02<04:19,  1.18s/it]Loading train:  23%|██▎       | 66/285 [01:03<04:22,  1.20s/it]Loading train:  24%|██▎       | 67/285 [01:04<04:02,  1.11s/it]Loading train:  24%|██▍       | 68/285 [01:05<03:39,  1.01s/it]Loading train:  24%|██▍       | 69/285 [01:06<03:22,  1.06it/s]Loading train:  25%|██▍       | 70/285 [01:07<03:21,  1.07it/s]Loading train:  25%|██▍       | 71/285 [01:08<03:18,  1.08it/s]Loading train:  25%|██▌       | 72/285 [01:08<03:05,  1.15it/s]Loading train:  26%|██▌       | 73/285 [01:09<02:57,  1.19it/s]Loading train:  26%|██▌       | 74/285 [01:10<02:58,  1.18it/s]Loading train:  26%|██▋       | 75/285 [01:11<03:01,  1.16it/s]Loading train:  27%|██▋       | 76/285 [01:12<02:59,  1.17it/s]Loading train:  27%|██▋       | 77/285 [01:13<02:56,  1.18it/s]Loading train:  27%|██▋       | 78/285 [01:13<02:48,  1.23it/s]Loading train:  28%|██▊       | 79/285 [01:14<02:47,  1.23it/s]Loading train:  28%|██▊       | 80/285 [01:15<02:50,  1.20it/s]Loading train:  28%|██▊       | 81/285 [01:16<02:52,  1.18it/s]Loading train:  29%|██▉       | 82/285 [01:17<02:49,  1.20it/s]Loading train:  29%|██▉       | 83/285 [01:17<02:43,  1.24it/s]Loading train:  29%|██▉       | 84/285 [01:18<02:44,  1.22it/s]Loading train:  30%|██▉       | 85/285 [01:19<02:49,  1.18it/s]Loading train:  30%|███       | 86/285 [01:20<02:54,  1.14it/s]Loading train:  31%|███       | 87/285 [01:21<02:56,  1.12it/s]Loading train:  31%|███       | 88/285 [01:22<02:52,  1.15it/s]Loading train:  31%|███       | 89/285 [01:23<02:50,  1.15it/s]Loading train:  32%|███▏      | 90/285 [01:24<02:56,  1.11it/s]Loading train:  32%|███▏      | 91/285 [01:25<02:53,  1.12it/s]Loading train:  32%|███▏      | 92/285 [01:26<02:54,  1.10it/s]Loading train:  33%|███▎      | 93/285 [01:26<02:42,  1.18it/s]Loading train:  33%|███▎      | 94/285 [01:27<02:42,  1.17it/s]Loading train:  33%|███▎      | 95/285 [01:28<02:46,  1.14it/s]Loading train:  34%|███▎      | 96/285 [01:29<02:42,  1.16it/s]Loading train:  34%|███▍      | 97/285 [01:30<02:40,  1.17it/s]Loading train:  34%|███▍      | 98/285 [01:31<02:36,  1.19it/s]Loading train:  35%|███▍      | 99/285 [01:31<02:32,  1.22it/s]Loading train:  35%|███▌      | 100/285 [01:32<02:39,  1.16it/s]Loading train:  35%|███▌      | 101/285 [01:33<02:39,  1.15it/s]Loading train:  36%|███▌      | 102/285 [01:34<02:47,  1.10it/s]Loading train:  36%|███▌      | 103/285 [01:35<02:38,  1.15it/s]Loading train:  36%|███▋      | 104/285 [01:36<02:41,  1.12it/s]Loading train:  37%|███▋      | 105/285 [01:37<02:41,  1.12it/s]Loading train:  37%|███▋      | 106/285 [01:38<02:34,  1.16it/s]Loading train:  38%|███▊      | 107/285 [01:39<02:38,  1.13it/s]Loading train:  38%|███▊      | 108/285 [01:39<02:33,  1.15it/s]Loading train:  38%|███▊      | 109/285 [01:40<02:27,  1.19it/s]Loading train:  39%|███▊      | 110/285 [01:41<02:25,  1.21it/s]Loading train:  39%|███▉      | 111/285 [01:42<02:18,  1.25it/s]Loading train:  39%|███▉      | 112/285 [01:42<02:18,  1.25it/s]Loading train:  40%|███▉      | 113/285 [01:43<02:24,  1.19it/s]Loading train:  40%|████      | 114/285 [01:44<02:19,  1.23it/s]Loading train:  40%|████      | 115/285 [01:45<02:22,  1.19it/s]Loading train:  41%|████      | 116/285 [01:46<02:22,  1.18it/s]Loading train:  41%|████      | 117/285 [01:47<02:18,  1.21it/s]Loading train:  41%|████▏     | 118/285 [01:47<02:14,  1.24it/s]Loading train:  42%|████▏     | 119/285 [01:48<02:18,  1.19it/s]Loading train:  42%|████▏     | 120/285 [01:49<02:13,  1.24it/s]Loading train:  42%|████▏     | 121/285 [01:50<02:31,  1.08it/s]Loading train:  43%|████▎     | 122/285 [01:51<02:41,  1.01it/s]Loading train:  43%|████▎     | 123/285 [01:52<02:44,  1.02s/it]Loading train:  44%|████▎     | 124/285 [01:53<02:32,  1.05it/s]Loading train:  44%|████▍     | 125/285 [01:54<02:20,  1.14it/s]Loading train:  44%|████▍     | 126/285 [01:55<02:07,  1.24it/s]Loading train:  45%|████▍     | 127/285 [01:55<02:05,  1.26it/s]Loading train:  45%|████▍     | 128/285 [01:56<02:02,  1.28it/s]Loading train:  45%|████▌     | 129/285 [01:57<02:00,  1.30it/s]Loading train:  46%|████▌     | 130/285 [01:57<01:51,  1.39it/s]Loading train:  46%|████▌     | 131/285 [01:58<01:49,  1.40it/s]Loading train:  46%|████▋     | 132/285 [01:59<01:54,  1.34it/s]Loading train:  47%|████▋     | 133/285 [02:00<01:48,  1.40it/s]Loading train:  47%|████▋     | 134/285 [02:00<01:43,  1.46it/s]Loading train:  47%|████▋     | 135/285 [02:01<01:43,  1.45it/s]Loading train:  48%|████▊     | 136/285 [02:02<01:43,  1.44it/s]Loading train:  48%|████▊     | 137/285 [02:02<01:44,  1.41it/s]Loading train:  48%|████▊     | 138/285 [02:03<01:46,  1.38it/s]Loading train:  49%|████▉     | 139/285 [02:04<01:46,  1.38it/s]Loading train:  49%|████▉     | 140/285 [02:05<01:50,  1.31it/s]Loading train:  49%|████▉     | 141/285 [02:05<01:45,  1.36it/s]Loading train:  50%|████▉     | 142/285 [02:06<01:42,  1.40it/s]Loading train:  50%|█████     | 143/285 [02:07<01:42,  1.39it/s]Loading train:  51%|█████     | 144/285 [02:08<01:41,  1.38it/s]Loading train:  51%|█████     | 145/285 [02:08<01:39,  1.40it/s]Loading train:  51%|█████     | 146/285 [02:09<01:39,  1.39it/s]Loading train:  52%|█████▏    | 147/285 [02:10<01:39,  1.39it/s]Loading train:  52%|█████▏    | 148/285 [02:10<01:38,  1.39it/s]Loading train:  52%|█████▏    | 149/285 [02:11<01:36,  1.42it/s]Loading train:  53%|█████▎    | 150/285 [02:12<01:35,  1.41it/s]Loading train:  53%|█████▎    | 151/285 [02:13<01:37,  1.38it/s]Loading train:  53%|█████▎    | 152/285 [02:13<01:35,  1.40it/s]Loading train:  54%|█████▎    | 153/285 [02:14<01:31,  1.44it/s]Loading train:  54%|█████▍    | 154/285 [02:15<01:31,  1.42it/s]Loading train:  54%|█████▍    | 155/285 [02:15<01:29,  1.46it/s]Loading train:  55%|█████▍    | 156/285 [02:16<01:28,  1.45it/s]Loading train:  55%|█████▌    | 157/285 [02:17<01:27,  1.46it/s]Loading train:  55%|█████▌    | 158/285 [02:17<01:24,  1.50it/s]Loading train:  56%|█████▌    | 159/285 [02:18<01:23,  1.51it/s]Loading train:  56%|█████▌    | 160/285 [02:19<01:21,  1.54it/s]Loading train:  56%|█████▋    | 161/285 [02:19<01:21,  1.51it/s]Loading train:  57%|█████▋    | 162/285 [02:20<01:19,  1.54it/s]Loading train:  57%|█████▋    | 163/285 [02:21<01:19,  1.53it/s]Loading train:  58%|█████▊    | 164/285 [02:21<01:25,  1.41it/s]Loading train:  58%|█████▊    | 165/285 [02:22<01:28,  1.36it/s]Loading train:  58%|█████▊    | 166/285 [02:23<01:27,  1.36it/s]Loading train:  59%|█████▊    | 167/285 [02:24<01:26,  1.37it/s]Loading train:  59%|█████▉    | 168/285 [02:24<01:24,  1.38it/s]Loading train:  59%|█████▉    | 169/285 [02:25<01:25,  1.36it/s]Loading train:  60%|█████▉    | 170/285 [02:26<01:20,  1.42it/s]Loading train:  60%|██████    | 171/285 [02:26<01:20,  1.42it/s]Loading train:  60%|██████    | 172/285 [02:27<01:18,  1.45it/s]Loading train:  61%|██████    | 173/285 [02:28<01:18,  1.43it/s]Loading train:  61%|██████    | 174/285 [02:28<01:17,  1.44it/s]Loading train:  61%|██████▏   | 175/285 [02:29<01:17,  1.41it/s]Loading train:  62%|██████▏   | 176/285 [02:30<01:21,  1.34it/s]Loading train:  62%|██████▏   | 177/285 [02:31<01:18,  1.38it/s]Loading train:  62%|██████▏   | 178/285 [02:31<01:17,  1.38it/s]Loading train:  63%|██████▎   | 179/285 [02:32<01:13,  1.44it/s]Loading train:  63%|██████▎   | 180/285 [02:33<01:16,  1.37it/s]Loading train:  64%|██████▎   | 181/285 [02:34<01:15,  1.37it/s]Loading train:  64%|██████▍   | 182/285 [02:34<01:18,  1.32it/s]Loading train:  64%|██████▍   | 183/285 [02:35<01:14,  1.38it/s]Loading train:  65%|██████▍   | 184/285 [02:36<01:16,  1.32it/s]Loading train:  65%|██████▍   | 185/285 [02:37<01:14,  1.35it/s]Loading train:  65%|██████▌   | 186/285 [02:37<01:16,  1.30it/s]Loading train:  66%|██████▌   | 187/285 [02:38<01:17,  1.26it/s]Loading train:  66%|██████▌   | 188/285 [02:39<01:18,  1.23it/s]Loading train:  66%|██████▋   | 189/285 [02:40<01:17,  1.25it/s]Loading train:  67%|██████▋   | 190/285 [02:41<01:14,  1.28it/s]Loading train:  67%|██████▋   | 191/285 [02:41<01:13,  1.28it/s]Loading train:  67%|██████▋   | 192/285 [02:42<01:12,  1.28it/s]Loading train:  68%|██████▊   | 193/285 [02:43<01:12,  1.27it/s]Loading train:  68%|██████▊   | 194/285 [02:44<01:08,  1.33it/s]Loading train:  68%|██████▊   | 195/285 [02:44<01:07,  1.34it/s]Loading train:  69%|██████▉   | 196/285 [02:45<01:09,  1.28it/s]Loading train:  69%|██████▉   | 197/285 [02:46<01:09,  1.26it/s]Loading train:  69%|██████▉   | 198/285 [02:47<01:12,  1.20it/s]Loading train:  70%|██████▉   | 199/285 [02:48<01:06,  1.29it/s]Loading train:  70%|███████   | 200/285 [02:48<01:03,  1.34it/s]Loading train:  71%|███████   | 201/285 [02:49<01:06,  1.26it/s]Loading train:  71%|███████   | 202/285 [02:50<01:04,  1.29it/s]Loading train:  71%|███████   | 203/285 [02:51<01:03,  1.29it/s]Loading train:  72%|███████▏  | 204/285 [02:51<00:58,  1.38it/s]Loading train:  72%|███████▏  | 205/285 [02:52<00:58,  1.37it/s]Loading train:  72%|███████▏  | 206/285 [02:53<00:55,  1.43it/s]Loading train:  73%|███████▎  | 207/285 [02:54<00:58,  1.32it/s]Loading train:  73%|███████▎  | 208/285 [02:55<01:00,  1.28it/s]Loading train:  73%|███████▎  | 209/285 [02:55<01:00,  1.26it/s]Loading train:  74%|███████▎  | 210/285 [02:56<00:56,  1.34it/s]Loading train:  74%|███████▍  | 211/285 [02:57<00:53,  1.37it/s]Loading train:  74%|███████▍  | 212/285 [02:57<00:53,  1.37it/s]Loading train:  75%|███████▍  | 213/285 [02:58<00:53,  1.35it/s]Loading train:  75%|███████▌  | 214/285 [02:59<00:51,  1.37it/s]Loading train:  75%|███████▌  | 215/285 [03:00<00:54,  1.28it/s]Loading train:  76%|███████▌  | 216/285 [03:00<00:50,  1.37it/s]Loading train:  76%|███████▌  | 217/285 [03:01<00:51,  1.33it/s]Loading train:  76%|███████▋  | 218/285 [03:02<00:51,  1.31it/s]Loading train:  77%|███████▋  | 219/285 [03:03<00:51,  1.27it/s]Loading train:  77%|███████▋  | 220/285 [03:04<00:49,  1.31it/s]Loading train:  78%|███████▊  | 221/285 [03:04<00:46,  1.39it/s]Loading train:  78%|███████▊  | 222/285 [03:05<00:45,  1.39it/s]Loading train:  78%|███████▊  | 223/285 [03:06<00:43,  1.42it/s]Loading train:  79%|███████▊  | 224/285 [03:06<00:44,  1.38it/s]Loading train:  79%|███████▉  | 225/285 [03:07<00:42,  1.42it/s]Loading train:  79%|███████▉  | 226/285 [03:08<00:44,  1.33it/s]Loading train:  80%|███████▉  | 227/285 [03:09<00:47,  1.22it/s]Loading train:  80%|████████  | 228/285 [03:10<00:46,  1.22it/s]Loading train:  80%|████████  | 229/285 [03:10<00:46,  1.20it/s]Loading train:  81%|████████  | 230/285 [03:11<00:44,  1.23it/s]Loading train:  81%|████████  | 231/285 [03:12<00:42,  1.28it/s]Loading train:  81%|████████▏ | 232/285 [03:13<00:40,  1.32it/s]Loading train:  82%|████████▏ | 233/285 [03:13<00:38,  1.36it/s]Loading train:  82%|████████▏ | 234/285 [03:14<00:41,  1.23it/s]Loading train:  82%|████████▏ | 235/285 [03:15<00:38,  1.31it/s]Loading train:  83%|████████▎ | 236/285 [03:16<00:38,  1.27it/s]Loading train:  83%|████████▎ | 237/285 [03:17<00:39,  1.21it/s]Loading train:  84%|████████▎ | 238/285 [03:18<00:40,  1.15it/s]Loading train:  84%|████████▍ | 239/285 [03:19<00:39,  1.17it/s]Loading train:  84%|████████▍ | 240/285 [03:19<00:37,  1.21it/s]Loading train:  85%|████████▍ | 241/285 [03:20<00:35,  1.23it/s]Loading train:  85%|████████▍ | 242/285 [03:21<00:32,  1.32it/s]Loading train:  85%|████████▌ | 243/285 [03:21<00:32,  1.30it/s]Loading train:  86%|████████▌ | 244/285 [03:22<00:33,  1.21it/s]Loading train:  86%|████████▌ | 245/285 [03:23<00:31,  1.26it/s]Loading train:  86%|████████▋ | 246/285 [03:24<00:31,  1.22it/s]Loading train:  87%|████████▋ | 247/285 [03:25<00:33,  1.12it/s]Loading train:  87%|████████▋ | 248/285 [03:26<00:31,  1.18it/s]Loading train:  87%|████████▋ | 249/285 [03:27<00:29,  1.22it/s]Loading train:  88%|████████▊ | 250/285 [03:27<00:27,  1.28it/s]Loading train:  88%|████████▊ | 251/285 [03:28<00:26,  1.29it/s]Loading train:  88%|████████▊ | 252/285 [03:29<00:25,  1.32it/s]Loading train:  89%|████████▉ | 253/285 [03:30<00:26,  1.19it/s]Loading train:  89%|████████▉ | 254/285 [03:31<00:26,  1.17it/s]Loading train:  89%|████████▉ | 255/285 [03:31<00:24,  1.23it/s]Loading train:  90%|████████▉ | 256/285 [03:32<00:22,  1.32it/s]Loading train:  90%|█████████ | 257/285 [03:33<00:20,  1.37it/s]Loading train:  91%|█████████ | 258/285 [03:34<00:22,  1.22it/s]Loading train:  91%|█████████ | 259/285 [03:34<00:20,  1.29it/s]Loading train:  91%|█████████ | 260/285 [03:35<00:18,  1.35it/s]Loading train:  92%|█████████▏| 261/285 [03:36<00:17,  1.35it/s]Loading train:  92%|█████████▏| 262/285 [03:36<00:16,  1.43it/s]Loading train:  92%|█████████▏| 263/285 [03:37<00:15,  1.42it/s]Loading train:  93%|█████████▎| 264/285 [03:38<00:15,  1.34it/s]Loading train:  93%|█████████▎| 265/285 [03:39<00:15,  1.27it/s]Loading train:  93%|█████████▎| 266/285 [03:40<00:14,  1.28it/s]Loading train:  94%|█████████▎| 267/285 [03:40<00:13,  1.35it/s]Loading train:  94%|█████████▍| 268/285 [03:41<00:13,  1.25it/s]Loading train:  94%|█████████▍| 269/285 [03:42<00:12,  1.30it/s]Loading train:  95%|█████████▍| 270/285 [03:43<00:11,  1.36it/s]Loading train:  95%|█████████▌| 271/285 [03:43<00:09,  1.41it/s]Loading train:  95%|█████████▌| 272/285 [03:44<00:09,  1.41it/s]Loading train:  96%|█████████▌| 273/285 [03:45<00:08,  1.34it/s]Loading train:  96%|█████████▌| 274/285 [03:45<00:07,  1.38it/s]Loading train:  96%|█████████▋| 275/285 [03:46<00:07,  1.30it/s]Loading train:  97%|█████████▋| 276/285 [03:47<00:07,  1.26it/s]Loading train:  97%|█████████▋| 277/285 [03:48<00:06,  1.33it/s]Loading train:  98%|█████████▊| 278/285 [03:49<00:05,  1.33it/s]Loading train:  98%|█████████▊| 279/285 [03:49<00:04,  1.28it/s]Loading train:  98%|█████████▊| 280/285 [03:50<00:03,  1.31it/s]Loading train:  99%|█████████▊| 281/285 [03:51<00:03,  1.29it/s]Loading train:  99%|█████████▉| 282/285 [03:52<00:02,  1.35it/s]Loading train:  99%|█████████▉| 283/285 [03:52<00:01,  1.28it/s]Loading train: 100%|█████████▉| 284/285 [03:53<00:00,  1.25it/s]Loading train: 100%|██████████| 285/285 [03:54<00:00,  1.18it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   3%|▎         | 8/285 [00:00<00:03, 79.02it/s]concatenating: train:  10%|▉         | 28/285 [00:00<00:02, 96.52it/s]concatenating: train:  21%|██        | 60/285 [00:00<00:01, 121.70it/s]concatenating: train:  29%|██▉       | 82/285 [00:00<00:01, 140.19it/s]concatenating: train:  38%|███▊      | 109/285 [00:00<00:01, 162.81it/s]concatenating: train:  48%|████▊     | 138/285 [00:00<00:00, 186.73it/s]concatenating: train:  61%|██████    | 173/285 [00:00<00:00, 216.20it/s]concatenating: train:  73%|███████▎  | 208/285 [00:00<00:00, 242.94it/s]concatenating: train:  85%|████████▍ | 242/285 [00:00<00:00, 264.52it/s]concatenating: train:  96%|█████████▋| 275/285 [00:01<00:00, 279.78it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 273.81it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.38s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.33s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.25s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 66.32it/s]2019-07-10 21:32:18.464160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-10 21:32:18.464288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-10 21:32:18.464307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-10 21:32:18.464317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-10 21:32:18.464770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:11,  3.75it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:09,  4.54it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:08,  4.74it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.20it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.69it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.47it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.78it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.49it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  7.93it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.30it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.91it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:02,  8.46it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  8.69it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.16it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.82it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.04it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  8.94it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.10it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.85it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 30)   4080        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 40, 45)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 60)   24360       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 20, 105)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 105)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 105)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 105)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 15)   4065        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 45)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 45)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 10)   4060        dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 10)   40          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 10)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 80, 10)   0           activation_11[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 55)   0           dropout_5[0][0]                  
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 13)   728         concatenate_7[0][0]              
==================================================================================================
Total params: 130,708
Trainable params: 32,228
Non-trainable params: 98,480
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 14s - loss: 3.2158 - acc: 0.4709 - mDice: 0.0716 - val_loss: 2.6557 - val_acc: 0.9014 - val_mDice: 0.1594

Epoch 00001: val_mDice improved from -inf to 0.15936, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 9s - loss: 1.3811 - acc: 0.8772 - mDice: 0.2683 - val_loss: 2.6932 - val_acc: 0.9058 - val_mDice: 0.1610

Epoch 00002: val_mDice improved from 0.15936 to 0.16101, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 8s - loss: 0.7794 - acc: 0.8995 - mDice: 0.4441 - val_loss: 1.3260 - val_acc: 0.9280 - val_mDice: 0.4299

Epoch 00003: val_mDice improved from 0.16101 to 0.42988, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 9s - loss: 0.6035 - acc: 0.9110 - mDice: 0.5294 - val_loss: 1.1549 - val_acc: 0.9381 - val_mDice: 0.5152

Epoch 00004: val_mDice improved from 0.42988 to 0.51516, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 8s - loss: 0.5369 - acc: 0.9171 - mDice: 0.5677 - val_loss: 1.0272 - val_acc: 0.9304 - val_mDice: 0.5533

Epoch 00005: val_mDice improved from 0.51516 to 0.55326, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 8s - loss: 0.4988 - acc: 0.9210 - mDice: 0.5907 - val_loss: 0.9853 - val_acc: 0.9413 - val_mDice: 0.5792

Epoch 00006: val_mDice improved from 0.55326 to 0.57919, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 8s - loss: 0.4734 - acc: 0.9237 - mDice: 0.6066 - val_loss: 0.9848 - val_acc: 0.9363 - val_mDice: 0.5730

Epoch 00007: val_mDice did not improve from 0.57919
Epoch 8/300
 - 8s - loss: 0.4560 - acc: 0.9255 - mDice: 0.6176 - val_loss: 0.9980 - val_acc: 0.9442 - val_mDice: 0.5681

Epoch 00008: val_mDice did not improve from 0.57919
Epoch 9/300
 - 8s - loss: 0.4404 - acc: 0.9270 - mDice: 0.6277 - val_loss: 1.0159 - val_acc: 0.9426 - val_mDice: 0.5529

Epoch 00009: val_mDice did not improve from 0.57919
Epoch 10/300
 - 8s - loss: 0.4272 - acc: 0.9282 - mDice: 0.6364 - val_loss: 0.9749 - val_acc: 0.9437 - val_mDice: 0.5697

Epoch 00010: val_mDice did not improve from 0.57919
Epoch 11/300
 - 8s - loss: 0.4222 - acc: 0.9290 - mDice: 0.6397 - val_loss: 0.9463 - val_acc: 0.9419 - val_mDice: 0.5727

Epoch 00011: val_mDice did not improve from 0.57919
Epoch 12/300
 - 9s - loss: 0.4131 - acc: 0.9298 - mDice: 0.6459 - val_loss: 0.9153 - val_acc: 0.9433 - val_mDice: 0.5877

Epoch 00012: val_mDice improved from 0.57919 to 0.58770, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 8s - loss: 0.4067 - acc: 0.9309 - mDice: 0.6502 - val_loss: 0.9710 - val_acc: 0.9412 - val_mDice: 0.5736

Epoch 00013: val_mDice did not improve from 0.58770
Epoch 14/300
 - 8s - loss: 0.4008 - acc: 0.9312 - mDice: 0.6543 - val_loss: 0.9659 - val_acc: 0.9398 - val_mDice: 0.5737

Epoch 00014: val_mDice did not improve from 0.58770
Epoch 15/300
 - 8s - loss: 0.3954 - acc: 0.9320 - mDice: 0.6579 - val_loss: 0.9258 - val_acc: 0.9433 - val_mDice: 0.5793

Epoch 00015: val_mDice did not improve from 0.58770
Epoch 16/300
 - 8s - loss: 0.3893 - acc: 0.9323 - mDice: 0.6621 - val_loss: 0.9930 - val_acc: 0.9314 - val_mDice: 0.5544

Epoch 00016: val_mDice did not improve from 0.58770
Epoch 17/300
 - 9s - loss: 0.3874 - acc: 0.9330 - mDice: 0.6634 - val_loss: 0.9236 - val_acc: 0.9444 - val_mDice: 0.5682

Epoch 00017: val_mDice did not improve from 0.58770
Epoch 18/300
 - 8s - loss: 0.3834 - acc: 0.9332 - mDice: 0.6662 - val_loss: 0.9338 - val_acc: 0.9360 - val_mDice: 0.5774

Epoch 00018: val_mDice did not improve from 0.58770
Epoch 19/300
 - 9s - loss: 0.3794 - acc: 0.9337 - mDice: 0.6689 - val_loss: 0.9120 - val_acc: 0.9421 - val_mDice: 0.5734

Epoch 00019: val_mDice did not improve from 0.58770
Epoch 20/300
 - 8s - loss: 0.3744 - acc: 0.9342 - mDice: 0.6725 - val_loss: 0.8930 - val_acc: 0.9436 - val_mDice: 0.5809

Epoch 00020: val_mDice did not improve from 0.58770
Epoch 21/300
 - 9s - loss: 0.3710 - acc: 0.9345 - mDice: 0.6749 - val_loss: 0.9734 - val_acc: 0.9318 - val_mDice: 0.5603

Epoch 00021: val_mDice did not improve from 0.58770
Epoch 22/300
 - 8s - loss: 0.3664 - acc: 0.9351 - mDice: 0.6781 - val_loss: 0.9092 - val_acc: 0.9448 - val_mDice: 0.5608

Epoch 00022: val_mDice did not improve from 0.58770
Epoch 23/300
 - 8s - loss: 0.3650 - acc: 0.9353 - mDice: 0.6791 - val_loss: 0.8874 - val_acc: 0.9416 - val_mDice: 0.5778

Epoch 00023: val_mDice did not improve from 0.58770
Epoch 24/300
 - 8s - loss: 0.3615 - acc: 0.9356 - mDice: 0.6816 - val_loss: 0.9007 - val_acc: 0.9429 - val_mDice: 0.5647

Epoch 00024: val_mDice did not improve from 0.58770
Epoch 25/300
 - 8s - loss: 0.3607 - acc: 0.9357 - mDice: 0.6821 - val_loss: 0.8904 - val_acc: 0.9456 - val_mDice: 0.5696

Epoch 00025: val_mDice did not improve from 0.58770
Epoch 26/300
 - 9s - loss: 0.3586 - acc: 0.9360 - mDice: 0.6837 - val_loss: 0.9262 - val_acc: 0.9427 - val_mDice: 0.5338

Epoch 00026: val_mDice did not improve from 0.58770
Epoch 27/300
 - 8s - loss: 0.3548 - acc: 0.9363 - mDice: 0.6863 - val_loss: 0.8838 - val_acc: 0.9435 - val_mDice: 0.5621

Epoch 00027: val_mDice did not improve from 0.58770
Epoch 28/300
 - 9s - loss: 0.3522 - acc: 0.9367 - mDice: 0.6883 - val_loss: 0.8667 - val_acc: 0.9399 - val_mDice: 0.5663

Epoch 00028: val_mDice did not improve from 0.58770
Epoch 29/300
 - 8s - loss: 0.3493 - acc: 0.9371 - mDice: 0.6903 - val_loss: 0.9081 - val_acc: 0.9440 - val_mDice: 0.5546

Epoch 00029: val_mDice did not improve from 0.58770
Epoch 30/300
 - 8s - loss: 0.3506 - acc: 0.9369 - mDice: 0.6895 - val_loss: 0.8597 - val_acc: 0.9403 - val_mDice: 0.5724

Epoch 00030: val_mDice did not improve from 0.58770
Epoch 31/300
 - 9s - loss: 0.3469 - acc: 0.9371 - mDice: 0.6919 - val_loss: 0.8487 - val_acc: 0.9446 - val_mDice: 0.5712

Epoch 00031: val_mDice did not improve from 0.58770
Epoch 32/300
 - 8s - loss: 0.3443 - acc: 0.9375 - mDice: 0.6938 - val_loss: 0.8462 - val_acc: 0.9386 - val_mDice: 0.5736

Epoch 00032: val_mDice did not improve from 0.58770
Epoch 33/300
 - 8s - loss: 0.3433 - acc: 0.9377 - mDice: 0.6947 - val_loss: 0.9166 - val_acc: 0.9413 - val_mDice: 0.5277

Epoch 00033: val_mDice did not improve from 0.58770
Epoch 34/300
 - 8s - loss: 0.3426 - acc: 0.9378 - mDice: 0.6951 - val_loss: 0.8358 - val_acc: 0.9432 - val_mDice: 0.5790

Epoch 00034: val_mDice did not improve from 0.58770
Epoch 35/300
 - 8s - loss: 0.3398 - acc: 0.9381 - mDice: 0.6971 - val_loss: 0.8848 - val_acc: 0.9360 - val_mDice: 0.5587

Epoch 00035: val_mDice did not improve from 0.58770
Epoch 36/300
 - 8s - loss: 0.3409 - acc: 0.9379 - mDice: 0.6964 - val_loss: 0.8924 - val_acc: 0.9410 - val_mDice: 0.5220

Epoch 00036: val_mDice did not improve from 0.58770
Epoch 37/300
 - 8s - loss: 0.3364 - acc: 0.9385 - mDice: 0.6997 - val_loss: 0.9159 - val_acc: 0.9394 - val_mDice: 0.5035

Epoch 00037: val_mDice did not improve from 0.58770
Epoch 38/300
 - 8s - loss: 0.3360 - acc: 0.9384 - mDice: 0.7001 - val_loss: 0.8700 - val_acc: 0.9316 - val_mDice: 0.5615

Epoch 00038: val_mDice did not improve from 0.58770
Epoch 39/300
 - 8s - loss: 0.3351 - acc: 0.9386 - mDice: 0.7006 - val_loss: 0.8364 - val_acc: 0.9431 - val_mDice: 0.5719

Epoch 00039: val_mDice did not improve from 0.58770
Epoch 40/300
 - 8s - loss: 0.3325 - acc: 0.9387 - mDice: 0.7026 - val_loss: 0.8286 - val_acc: 0.9393 - val_mDice: 0.5653

Epoch 00040: val_mDice did not improve from 0.58770
Epoch 41/300
 - 8s - loss: 0.3335 - acc: 0.9385 - mDice: 0.7017 - val_loss: 0.8432 - val_acc: 0.9426 - val_mDice: 0.5409

Epoch 00041: val_mDice did not improve from 0.58770
Epoch 42/300
 - 8s - loss: 0.3304 - acc: 0.9391 - mDice: 0.7041 - val_loss: 0.8327 - val_acc: 0.9395 - val_mDice: 0.5460

Epoch 00042: val_mDice did not improve from 0.58770
Epoch 43/300
 - 8s - loss: 0.3286 - acc: 0.9391 - mDice: 0.7054 - val_loss: 0.9181 - val_acc: 0.9395 - val_mDice: 0.4917

Epoch 00043: val_mDice did not improve from 0.58770
Epoch 44/300
 - 8s - loss: 0.3292 - acc: 0.9392 - mDice: 0.7049 - val_loss: 0.8053 - val_acc: 0.9449 - val_mDice: 0.5531

Epoch 00044: val_mDice did not improve from 0.58770
Epoch 45/300
 - 9s - loss: 0.3262 - acc: 0.9395 - mDice: 0.7071 - val_loss: 0.8692 - val_acc: 0.9398 - val_mDice: 0.5139

Epoch 00045: val_mDice did not improve from 0.58770
Epoch 46/300
 - 8s - loss: 0.3264 - acc: 0.9396 - mDice: 0.7070 - val_loss: 0.8483 - val_acc: 0.9416 - val_mDice: 0.5172

Epoch 00046: val_mDice did not improve from 0.58770
Epoch 47/300
 - 8s - loss: 0.3240 - acc: 0.9397 - mDice: 0.7087 - val_loss: 0.7957 - val_acc: 0.9423 - val_mDice: 0.5661

Epoch 00047: val_mDice did not improve from 0.58770
Epoch 48/300
 - 8s - loss: 0.3239 - acc: 0.9398 - mDice: 0.7089 - val_loss: 0.7690 - val_acc: 0.9419 - val_mDice: 0.5727

Epoch 00048: val_mDice did not improve from 0.58770
Epoch 49/300
 - 8s - loss: 0.3239 - acc: 0.9397 - mDice: 0.7089 - val_loss: 0.7904 - val_acc: 0.9432 - val_mDice: 0.5528

Epoch 00049: val_mDice did not improve from 0.58770
Epoch 50/300
 - 8s - loss: 0.3229 - acc: 0.9399 - mDice: 0.7096 - val_loss: 0.8368 - val_acc: 0.9404 - val_mDice: 0.5056

Epoch 00050: val_mDice did not improve from 0.58770
Epoch 51/300
 - 8s - loss: 0.3234 - acc: 0.9399 - mDice: 0.7092 - val_loss: 0.8050 - val_acc: 0.9405 - val_mDice: 0.5488

Epoch 00051: val_mDice did not improve from 0.58770
Epoch 52/300
 - 10s - loss: 0.3209 - acc: 0.9401 - mDice: 0.7110 - val_loss: 0.8012 - val_acc: 0.9423 - val_mDice: 0.5441

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.31s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.07s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.92s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:02<10:17,  2.17s/it]predicting train subjects:   1%|          | 2/285 [00:03<09:22,  1.99s/it]predicting train subjects:   1%|          | 3/285 [00:05<09:08,  1.94s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<08:32,  1.82s/it]predicting train subjects:   2%|▏         | 5/285 [00:09<08:58,  1.92s/it]predicting train subjects:   2%|▏         | 6/285 [00:11<08:42,  1.87s/it]predicting train subjects:   2%|▏         | 7/285 [00:13<09:10,  1.98s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:43,  1.89s/it]predicting train subjects:   3%|▎         | 9/285 [00:17<09:14,  2.01s/it]predicting train subjects:   4%|▎         | 10/285 [00:19<09:56,  2.17s/it]predicting train subjects:   4%|▍         | 11/285 [00:21<09:13,  2.02s/it]predicting train subjects:   4%|▍         | 12/285 [00:23<09:32,  2.10s/it]predicting train subjects:   5%|▍         | 13/285 [00:25<09:09,  2.02s/it]predicting train subjects:   5%|▍         | 14/285 [00:27<09:16,  2.05s/it]predicting train subjects:   5%|▌         | 15/285 [00:30<09:39,  2.15s/it]predicting train subjects:   6%|▌         | 16/285 [00:32<09:39,  2.15s/it]predicting train subjects:   6%|▌         | 17/285 [00:34<09:14,  2.07s/it]predicting train subjects:   6%|▋         | 18/285 [00:36<09:16,  2.08s/it]predicting train subjects:   7%|▋         | 19/285 [00:38<08:51,  2.00s/it]predicting train subjects:   7%|▋         | 20/285 [00:40<09:08,  2.07s/it]predicting train subjects:   7%|▋         | 21/285 [00:42<09:35,  2.18s/it]predicting train subjects:   8%|▊         | 22/285 [00:44<09:10,  2.09s/it]predicting train subjects:   8%|▊         | 23/285 [00:46<09:16,  2.12s/it]predicting train subjects:   8%|▊         | 24/285 [00:48<08:49,  2.03s/it]predicting train subjects:   9%|▉         | 25/285 [00:50<09:13,  2.13s/it]predicting train subjects:   9%|▉         | 26/285 [00:53<09:36,  2.23s/it]predicting train subjects:   9%|▉         | 27/285 [00:55<09:02,  2.10s/it]predicting train subjects:  10%|▉         | 28/285 [00:57<09:08,  2.13s/it]predicting train subjects:  10%|█         | 29/285 [00:59<09:09,  2.15s/it]predicting train subjects:  11%|█         | 30/285 [01:01<09:16,  2.18s/it]predicting train subjects:  11%|█         | 31/285 [01:04<09:25,  2.23s/it]predicting train subjects:  11%|█         | 32/285 [01:05<08:47,  2.09s/it]predicting train subjects:  12%|█▏        | 33/285 [01:08<08:52,  2.11s/it]predicting train subjects:  12%|█▏        | 34/285 [01:10<08:59,  2.15s/it]predicting train subjects:  12%|█▏        | 35/285 [01:12<08:57,  2.15s/it]predicting train subjects:  13%|█▎        | 36/285 [01:14<08:32,  2.06s/it]predicting train subjects:  13%|█▎        | 37/285 [01:16<08:44,  2.11s/it]predicting train subjects:  13%|█▎        | 38/285 [01:18<08:53,  2.16s/it]predicting train subjects:  14%|█▎        | 39/285 [01:20<08:25,  2.06s/it]predicting train subjects:  14%|█▍        | 40/285 [01:22<08:23,  2.06s/it]predicting train subjects:  14%|█▍        | 41/285 [01:24<08:07,  2.00s/it]predicting train subjects:  15%|█▍        | 42/285 [01:26<08:05,  2.00s/it]predicting train subjects:  15%|█▌        | 43/285 [01:28<08:15,  2.05s/it]predicting train subjects:  15%|█▌        | 44/285 [01:31<08:37,  2.15s/it]predicting train subjects:  16%|█▌        | 45/285 [01:32<08:09,  2.04s/it]predicting train subjects:  16%|█▌        | 46/285 [01:35<08:26,  2.12s/it]predicting train subjects:  16%|█▋        | 47/285 [01:37<08:03,  2.03s/it]predicting train subjects:  17%|█▋        | 48/285 [01:39<08:04,  2.04s/it]predicting train subjects:  17%|█▋        | 49/285 [01:41<08:09,  2.08s/it]predicting train subjects:  18%|█▊        | 50/285 [01:43<07:58,  2.03s/it]predicting train subjects:  18%|█▊        | 51/285 [01:45<08:13,  2.11s/it]predicting train subjects:  18%|█▊        | 52/285 [01:47<07:48,  2.01s/it]predicting train subjects:  19%|█▊        | 53/285 [01:49<07:55,  2.05s/it]predicting train subjects:  19%|█▉        | 54/285 [01:51<08:07,  2.11s/it]predicting train subjects:  19%|█▉        | 55/285 [01:53<07:47,  2.03s/it]predicting train subjects:  20%|█▉        | 56/285 [01:55<07:55,  2.07s/it]predicting train subjects:  20%|██        | 57/285 [01:57<07:34,  1.99s/it]predicting train subjects:  20%|██        | 58/285 [01:59<07:47,  2.06s/it]predicting train subjects:  21%|██        | 59/285 [02:02<08:04,  2.15s/it]predicting train subjects:  21%|██        | 60/285 [02:04<08:16,  2.21s/it]predicting train subjects:  21%|██▏       | 61/285 [02:06<07:51,  2.11s/it]predicting train subjects:  22%|██▏       | 62/285 [02:08<08:08,  2.19s/it]predicting train subjects:  22%|██▏       | 63/285 [02:10<08:13,  2.22s/it]predicting train subjects:  22%|██▏       | 64/285 [02:12<07:46,  2.11s/it]predicting train subjects:  23%|██▎       | 65/285 [02:15<07:59,  2.18s/it]predicting train subjects:  23%|██▎       | 66/285 [02:17<08:02,  2.20s/it]predicting train subjects:  24%|██▎       | 67/285 [02:19<07:58,  2.19s/it]predicting train subjects:  24%|██▍       | 68/285 [02:21<07:37,  2.11s/it]predicting train subjects:  24%|██▍       | 69/285 [02:23<07:27,  2.07s/it]predicting train subjects:  25%|██▍       | 70/285 [02:25<07:36,  2.12s/it]predicting train subjects:  25%|██▍       | 71/285 [02:27<07:43,  2.17s/it]predicting train subjects:  25%|██▌       | 72/285 [02:29<07:17,  2.05s/it]predicting train subjects:  26%|██▌       | 73/285 [02:31<07:15,  2.05s/it]predicting train subjects:  26%|██▌       | 74/285 [02:34<07:24,  2.10s/it]predicting train subjects:  26%|██▋       | 75/285 [02:36<07:23,  2.11s/it]predicting train subjects:  27%|██▋       | 76/285 [02:38<07:16,  2.09s/it]predicting train subjects:  27%|██▋       | 77/285 [02:40<07:14,  2.09s/it]predicting train subjects:  27%|██▋       | 78/285 [02:42<07:02,  2.04s/it]predicting train subjects:  28%|██▊       | 79/285 [02:44<07:01,  2.05s/it]predicting train subjects:  28%|██▊       | 80/285 [02:46<07:01,  2.06s/it]predicting train subjects:  28%|██▊       | 81/285 [02:48<06:51,  2.02s/it]predicting train subjects:  29%|██▉       | 82/285 [02:50<06:55,  2.05s/it]predicting train subjects:  29%|██▉       | 83/285 [02:52<06:46,  2.01s/it]predicting train subjects:  29%|██▉       | 84/285 [02:54<06:42,  2.00s/it]predicting train subjects:  30%|██▉       | 85/285 [02:56<06:44,  2.02s/it]predicting train subjects:  30%|███       | 86/285 [02:58<06:47,  2.05s/it]predicting train subjects:  31%|███       | 87/285 [03:00<06:53,  2.09s/it]predicting train subjects:  31%|███       | 88/285 [03:02<06:43,  2.05s/it]predicting train subjects:  31%|███       | 89/285 [03:04<06:32,  2.00s/it]predicting train subjects:  32%|███▏      | 90/285 [03:06<06:31,  2.01s/it]predicting train subjects:  32%|███▏      | 91/285 [03:08<06:23,  1.98s/it]predicting train subjects:  32%|███▏      | 92/285 [03:10<06:32,  2.03s/it]predicting train subjects:  33%|███▎      | 93/285 [03:12<06:20,  1.98s/it]predicting train subjects:  33%|███▎      | 94/285 [03:14<06:23,  2.01s/it]predicting train subjects:  33%|███▎      | 95/285 [03:16<06:33,  2.07s/it]predicting train subjects:  34%|███▎      | 96/285 [03:18<06:33,  2.08s/it]predicting train subjects:  34%|███▍      | 97/285 [03:21<06:48,  2.17s/it]predicting train subjects:  34%|███▍      | 98/285 [03:23<06:44,  2.16s/it]predicting train subjects:  35%|███▍      | 99/285 [03:25<06:42,  2.16s/it]predicting train subjects:  35%|███▌      | 100/285 [03:27<06:54,  2.24s/it]predicting train subjects:  35%|███▌      | 101/285 [03:29<06:32,  2.13s/it]predicting train subjects:  36%|███▌      | 102/285 [03:32<06:30,  2.13s/it]predicting train subjects:  36%|███▌      | 103/285 [03:33<06:15,  2.07s/it]predicting train subjects:  36%|███▋      | 104/285 [03:36<06:28,  2.15s/it]predicting train subjects:  37%|███▋      | 105/285 [03:38<06:11,  2.06s/it]predicting train subjects:  37%|███▋      | 106/285 [03:40<06:17,  2.11s/it]predicting train subjects:  38%|███▊      | 107/285 [03:42<06:06,  2.06s/it]predicting train subjects:  38%|███▊      | 108/285 [03:43<05:40,  1.92s/it]predicting train subjects:  38%|███▊      | 109/285 [03:45<05:23,  1.84s/it]predicting train subjects:  39%|███▊      | 110/285 [03:47<05:17,  1.81s/it]predicting train subjects:  39%|███▉      | 111/285 [03:48<05:04,  1.75s/it]predicting train subjects:  39%|███▉      | 112/285 [03:50<05:01,  1.74s/it]predicting train subjects:  40%|███▉      | 113/285 [03:52<05:04,  1.77s/it]predicting train subjects:  40%|████      | 114/285 [03:54<05:00,  1.76s/it]predicting train subjects:  40%|████      | 115/285 [03:55<04:56,  1.75s/it]predicting train subjects:  41%|████      | 116/285 [03:57<05:01,  1.78s/it]predicting train subjects:  41%|████      | 117/285 [03:59<04:50,  1.73s/it]predicting train subjects:  41%|████▏     | 118/285 [04:00<04:41,  1.68s/it]predicting train subjects:  42%|████▏     | 119/285 [04:02<04:41,  1.69s/it]predicting train subjects:  42%|████▏     | 120/285 [04:04<04:34,  1.66s/it]predicting train subjects:  42%|████▏     | 121/285 [04:05<04:25,  1.62s/it]predicting train subjects:  43%|████▎     | 122/285 [04:07<04:13,  1.56s/it]predicting train subjects:  43%|████▎     | 123/285 [04:08<04:04,  1.51s/it]predicting train subjects:  44%|████▎     | 124/285 [04:10<04:01,  1.50s/it]predicting train subjects:  44%|████▍     | 125/285 [04:11<03:56,  1.48s/it]predicting train subjects:  44%|████▍     | 126/285 [04:12<03:52,  1.46s/it]predicting train subjects:  45%|████▍     | 127/285 [04:14<03:46,  1.43s/it]predicting train subjects:  45%|████▍     | 128/285 [04:15<03:52,  1.48s/it]predicting train subjects:  45%|████▌     | 129/285 [04:17<03:48,  1.46s/it]predicting train subjects:  46%|████▌     | 130/285 [04:18<03:41,  1.43s/it]predicting train subjects:  46%|████▌     | 131/285 [04:20<03:38,  1.42s/it]predicting train subjects:  46%|████▋     | 132/285 [04:21<03:45,  1.47s/it]predicting train subjects:  47%|████▋     | 133/285 [04:23<03:41,  1.46s/it]predicting train subjects:  47%|████▋     | 134/285 [04:24<03:34,  1.42s/it]predicting train subjects:  47%|████▋     | 135/285 [04:25<03:30,  1.41s/it]predicting train subjects:  48%|████▊     | 136/285 [04:27<03:28,  1.40s/it]predicting train subjects:  48%|████▊     | 137/285 [04:28<03:34,  1.45s/it]predicting train subjects:  48%|████▊     | 138/285 [04:30<03:30,  1.43s/it]predicting train subjects:  49%|████▉     | 139/285 [04:31<03:33,  1.46s/it]predicting train subjects:  49%|████▉     | 140/285 [04:33<03:35,  1.49s/it]predicting train subjects:  49%|████▉     | 141/285 [04:34<03:28,  1.45s/it]predicting train subjects:  50%|████▉     | 142/285 [04:35<03:24,  1.43s/it]predicting train subjects:  50%|█████     | 143/285 [04:37<03:20,  1.41s/it]predicting train subjects:  51%|█████     | 144/285 [04:38<03:25,  1.46s/it]predicting train subjects:  51%|█████     | 145/285 [04:40<03:21,  1.44s/it]predicting train subjects:  51%|█████     | 146/285 [04:41<03:26,  1.49s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:43<03:21,  1.46s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:44<03:22,  1.48s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:46<03:17,  1.45s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:47<03:12,  1.42s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:49<03:17,  1.47s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:50<03:13,  1.46s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:51<03:08,  1.43s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:53<03:14,  1.48s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:54<03:11,  1.47s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:56<03:14,  1.51s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:58<03:11,  1.50s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:59<03:08,  1.48s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:00<03:04,  1.46s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:02<03:02,  1.46s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:03<03:06,  1.50s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:05<03:01,  1.48s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:06<03:05,  1.52s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:08<02:59,  1.48s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:09<02:58,  1.49s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:11<03:03,  1.54s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:13<03:02,  1.55s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:14<02:52,  1.48s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:15<02:48,  1.45s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:17<02:44,  1.43s/it]predicting train subjects:  60%|██████    | 171/285 [05:18<02:44,  1.44s/it]predicting train subjects:  60%|██████    | 172/285 [05:20<02:40,  1.42s/it]predicting train subjects:  61%|██████    | 173/285 [05:21<02:39,  1.42s/it]predicting train subjects:  61%|██████    | 174/285 [05:22<02:38,  1.43s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:24<02:42,  1.48s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:26<02:43,  1.50s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:27<02:39,  1.48s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:28<02:35,  1.46s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:30<02:33,  1.45s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:32<02:41,  1.54s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:33<02:43,  1.57s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:35<02:44,  1.60s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:36<02:37,  1.54s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:38<02:31,  1.50s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:39<02:26,  1.47s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:41<02:36,  1.58s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:43<02:42,  1.66s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:45<02:43,  1.69s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:46<02:35,  1.62s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:47<02:28,  1.56s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:49<02:28,  1.58s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:51<02:28,  1.59s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:52<02:17,  1.50s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:53<02:12,  1.45s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:55<02:07,  1.42s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:56<02:16,  1.53s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:58<02:23,  1.63s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:00<02:26,  1.68s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:01<02:14,  1.57s/it]predicting train subjects:  70%|███████   | 200/285 [06:03<02:09,  1.52s/it]predicting train subjects:  71%|███████   | 201/285 [06:05<02:13,  1.59s/it]predicting train subjects:  71%|███████   | 202/285 [06:06<02:11,  1.59s/it]predicting train subjects:  71%|███████   | 203/285 [06:08<02:11,  1.60s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:09<02:05,  1.55s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:11<02:01,  1.51s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:12<01:56,  1.47s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:14<02:03,  1.58s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:16<02:07,  1.65s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:17<02:09,  1.70s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:19<01:58,  1.58s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:20<01:52,  1.52s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:22<01:52,  1.54s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:23<01:51,  1.55s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:25<01:45,  1.49s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:26<01:50,  1.58s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:28<01:42,  1.49s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:29<01:46,  1.57s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:31<01:49,  1.63s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:33<01:51,  1.69s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:35<01:45,  1.62s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:36<01:38,  1.55s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:38<01:38,  1.56s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:39<01:34,  1.52s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:40<01:31,  1.50s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:42<01:27,  1.46s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:44<01:32,  1.57s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:45<01:35,  1.65s/it]predicting train subjects:  80%|████████  | 228/285 [06:47<01:35,  1.67s/it]predicting train subjects:  80%|████████  | 229/285 [06:49<01:32,  1.65s/it]predicting train subjects:  81%|████████  | 230/285 [06:50<01:25,  1.56s/it]predicting train subjects:  81%|████████  | 231/285 [06:51<01:20,  1.50s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:53<01:20,  1.53s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:54<01:16,  1.48s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:56<01:19,  1.56s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:57<01:14,  1.49s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:59<01:17,  1.59s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:01<01:19,  1.66s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:03<01:20,  1.70s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:05<01:16,  1.66s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:06<01:10,  1.57s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:07<01:06,  1.51s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:09<01:03,  1.47s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:10<01:00,  1.44s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:12<01:02,  1.53s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:13<00:59,  1.48s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:15<01:02,  1.59s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:17<01:01,  1.63s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:18<00:59,  1.61s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:20<00:55,  1.54s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:21<00:52,  1.49s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:22<00:49,  1.47s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:24<00:46,  1.42s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:25<00:48,  1.53s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:27<00:49,  1.60s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:29<00:48,  1.61s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:30<00:43,  1.52s/it]predicting train subjects:  90%|█████████ | 257/285 [07:32<00:41,  1.47s/it]predicting train subjects:  91%|█████████ | 258/285 [07:33<00:42,  1.57s/it]predicting train subjects:  91%|█████████ | 259/285 [07:35<00:40,  1.58s/it]predicting train subjects:  91%|█████████ | 260/285 [07:36<00:37,  1.51s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:38<00:35,  1.47s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:39<00:32,  1.43s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:40<00:31,  1.42s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:42<00:32,  1.56s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:44<00:32,  1.63s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:45<00:29,  1.54s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:47<00:26,  1.49s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:48<00:26,  1.56s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:50<00:25,  1.58s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:51<00:22,  1.50s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:53<00:20,  1.47s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:54<00:19,  1.51s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:56<00:17,  1.49s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:57<00:16,  1.48s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:59<00:16,  1.60s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:01<00:15,  1.67s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:02<00:12,  1.58s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:04<00:10,  1.54s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:05<00:09,  1.55s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:07<00:07,  1.51s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:08<00:05,  1.48s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:10<00:04,  1.45s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:11<00:03,  1.56s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:13<00:01,  1.63s/it]predicting train subjects: 100%|██████████| 285/285 [08:15<00:00,  1.69s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<09:18,  1.97s/it]Loading train:   1%|          | 2/285 [00:03<08:32,  1.81s/it]Loading train:   1%|          | 3/285 [00:05<08:12,  1.75s/it]Loading train:   1%|▏         | 4/285 [00:06<08:10,  1.74s/it]Loading train:   2%|▏         | 5/285 [00:08<08:20,  1.79s/it]Loading train:   2%|▏         | 6/285 [00:10<07:57,  1.71s/it]Loading train:   2%|▏         | 7/285 [00:11<07:52,  1.70s/it]Loading train:   3%|▎         | 8/285 [00:13<07:56,  1.72s/it]Loading train:   3%|▎         | 9/285 [00:15<08:28,  1.84s/it]Loading train:   4%|▎         | 10/285 [00:17<07:58,  1.74s/it]Loading train:   4%|▍         | 11/285 [00:18<07:22,  1.61s/it]Loading train:   4%|▍         | 12/285 [00:20<07:07,  1.57s/it]Loading train:   5%|▍         | 13/285 [00:21<06:44,  1.49s/it]Loading train:   5%|▍         | 14/285 [00:22<06:30,  1.44s/it]Loading train:   5%|▌         | 15/285 [00:24<06:28,  1.44s/it]Loading train:   6%|▌         | 16/285 [00:25<06:30,  1.45s/it]Loading train:   6%|▌         | 17/285 [00:26<06:09,  1.38s/it]Loading train:   6%|▋         | 18/285 [00:28<06:02,  1.36s/it]Loading train:   7%|▋         | 19/285 [00:29<05:38,  1.27s/it]Loading train:   7%|▋         | 20/285 [00:30<05:52,  1.33s/it]Loading train:   7%|▋         | 21/285 [00:32<06:19,  1.44s/it]Loading train:   8%|▊         | 22/285 [00:33<06:06,  1.39s/it]Loading train:   8%|▊         | 23/285 [00:35<06:24,  1.47s/it]Loading train:   8%|▊         | 24/285 [00:36<06:19,  1.45s/it]Loading train:   9%|▉         | 25/285 [00:38<06:22,  1.47s/it]Loading train:   9%|▉         | 26/285 [00:39<06:35,  1.53s/it]Loading train:   9%|▉         | 27/285 [00:41<06:17,  1.46s/it]Loading train:  10%|▉         | 28/285 [00:42<05:57,  1.39s/it]Loading train:  10%|█         | 29/285 [00:43<05:52,  1.38s/it]Loading train:  11%|█         | 30/285 [00:45<06:06,  1.44s/it]Loading train:  11%|█         | 31/285 [00:46<06:13,  1.47s/it]Loading train:  11%|█         | 32/285 [00:48<05:59,  1.42s/it]Loading train:  12%|█▏        | 33/285 [00:49<05:46,  1.37s/it]Loading train:  12%|█▏        | 34/285 [00:50<05:40,  1.36s/it]Loading train:  12%|█▏        | 35/285 [00:52<05:47,  1.39s/it]Loading train:  13%|█▎        | 36/285 [00:53<05:32,  1.34s/it]Loading train:  13%|█▎        | 37/285 [00:54<05:30,  1.33s/it]Loading train:  13%|█▎        | 38/285 [00:56<05:40,  1.38s/it]Loading train:  14%|█▎        | 39/285 [00:57<05:30,  1.34s/it]Loading train:  14%|█▍        | 40/285 [00:58<05:32,  1.36s/it]Loading train:  14%|█▍        | 41/285 [01:00<05:35,  1.37s/it]Loading train:  15%|█▍        | 42/285 [01:01<05:23,  1.33s/it]Loading train:  15%|█▌        | 43/285 [01:02<05:06,  1.27s/it]Loading train:  15%|█▌        | 44/285 [01:04<05:20,  1.33s/it]Loading train:  16%|█▌        | 45/285 [01:05<05:09,  1.29s/it]Loading train:  16%|█▌        | 46/285 [01:06<05:22,  1.35s/it]Loading train:  16%|█▋        | 47/285 [01:07<05:08,  1.29s/it]Loading train:  17%|█▋        | 48/285 [01:09<05:04,  1.29s/it]Loading train:  17%|█▋        | 49/285 [01:10<05:25,  1.38s/it]Loading train:  18%|█▊        | 50/285 [01:12<05:24,  1.38s/it]Loading train:  18%|█▊        | 51/285 [01:13<05:42,  1.46s/it]Loading train:  18%|█▊        | 52/285 [01:15<05:44,  1.48s/it]Loading train:  19%|█▊        | 53/285 [01:16<05:34,  1.44s/it]Loading train:  19%|█▉        | 54/285 [01:18<05:35,  1.45s/it]Loading train:  19%|█▉        | 55/285 [01:19<05:09,  1.34s/it]Loading train:  20%|█▉        | 56/285 [01:20<04:56,  1.30s/it]Loading train:  20%|██        | 57/285 [01:21<04:50,  1.28s/it]Loading train:  20%|██        | 58/285 [01:22<04:45,  1.26s/it]Loading train:  21%|██        | 59/285 [01:24<05:20,  1.42s/it]Loading train:  21%|██        | 60/285 [01:26<05:39,  1.51s/it]Loading train:  21%|██▏       | 61/285 [01:27<05:11,  1.39s/it]Loading train:  22%|██▏       | 62/285 [01:28<05:11,  1.40s/it]Loading train:  22%|██▏       | 63/285 [01:30<04:57,  1.34s/it]Loading train:  22%|██▏       | 64/285 [01:31<05:15,  1.43s/it]Loading train:  23%|██▎       | 65/285 [01:33<05:28,  1.49s/it]Loading train:  23%|██▎       | 66/285 [01:35<05:41,  1.56s/it]Loading train:  24%|██▎       | 67/285 [01:36<05:25,  1.49s/it]Loading train:  24%|██▍       | 68/285 [01:37<05:02,  1.39s/it]Loading train:  24%|██▍       | 69/285 [01:38<04:55,  1.37s/it]Loading train:  25%|██▍       | 70/285 [01:40<04:51,  1.35s/it]Loading train:  25%|██▍       | 71/285 [01:41<04:48,  1.35s/it]Loading train:  25%|██▌       | 72/285 [01:42<04:40,  1.32s/it]Loading train:  26%|██▌       | 73/285 [01:44<04:55,  1.39s/it]Loading train:  26%|██▌       | 74/285 [01:45<04:57,  1.41s/it]Loading train:  26%|██▋       | 75/285 [01:47<04:45,  1.36s/it]Loading train:  27%|██▋       | 76/285 [01:48<04:39,  1.34s/it]Loading train:  27%|██▋       | 77/285 [01:49<04:32,  1.31s/it]Loading train:  27%|██▋       | 78/285 [01:50<04:30,  1.31s/it]Loading train:  28%|██▊       | 79/285 [01:52<04:28,  1.30s/it]Loading train:  28%|██▊       | 80/285 [01:53<04:24,  1.29s/it]Loading train:  28%|██▊       | 81/285 [01:54<04:19,  1.27s/it]Loading train:  29%|██▉       | 82/285 [01:56<04:17,  1.27s/it]Loading train:  29%|██▉       | 83/285 [01:57<04:13,  1.25s/it]Loading train:  29%|██▉       | 84/285 [01:58<04:11,  1.25s/it]Loading train:  30%|██▉       | 85/285 [01:59<04:11,  1.26s/it]Loading train:  30%|███       | 86/285 [02:01<04:26,  1.34s/it]Loading train:  31%|███       | 87/285 [02:02<04:25,  1.34s/it]Loading train:  31%|███       | 88/285 [02:04<04:39,  1.42s/it]Loading train:  31%|███       | 89/285 [02:05<04:33,  1.40s/it]Loading train:  32%|███▏      | 90/285 [02:06<04:24,  1.36s/it]Loading train:  32%|███▏      | 91/285 [02:08<04:21,  1.35s/it]Loading train:  32%|███▏      | 92/285 [02:09<04:11,  1.30s/it]Loading train:  33%|███▎      | 93/285 [02:10<04:09,  1.30s/it]Loading train:  33%|███▎      | 94/285 [02:11<04:08,  1.30s/it]Loading train:  33%|███▎      | 95/285 [02:13<04:20,  1.37s/it]Loading train:  34%|███▎      | 96/285 [02:14<04:12,  1.33s/it]Loading train:  34%|███▍      | 97/285 [02:15<04:00,  1.28s/it]Loading train:  34%|███▍      | 98/285 [02:17<04:14,  1.36s/it]Loading train:  35%|███▍      | 99/285 [02:18<04:18,  1.39s/it]Loading train:  35%|███▌      | 100/285 [02:20<04:24,  1.43s/it]Loading train:  35%|███▌      | 101/285 [02:21<04:17,  1.40s/it]Loading train:  36%|███▌      | 102/285 [02:23<04:34,  1.50s/it]Loading train:  36%|███▌      | 103/285 [02:24<04:15,  1.40s/it]Loading train:  36%|███▋      | 104/285 [02:25<04:05,  1.36s/it]Loading train:  37%|███▋      | 105/285 [02:27<04:10,  1.39s/it]Loading train:  37%|███▋      | 106/285 [02:28<04:02,  1.36s/it]Loading train:  38%|███▊      | 107/285 [02:29<03:53,  1.31s/it]Loading train:  38%|███▊      | 108/285 [02:31<03:57,  1.34s/it]Loading train:  38%|███▊      | 109/285 [02:32<04:00,  1.36s/it]Loading train:  39%|███▊      | 110/285 [02:34<04:01,  1.38s/it]Loading train:  39%|███▉      | 111/285 [02:35<03:57,  1.37s/it]Loading train:  39%|███▉      | 112/285 [02:36<04:00,  1.39s/it]Loading train:  40%|███▉      | 113/285 [02:38<03:56,  1.37s/it]Loading train:  40%|████      | 114/285 [02:39<03:49,  1.34s/it]Loading train:  40%|████      | 115/285 [02:40<03:48,  1.34s/it]Loading train:  41%|████      | 116/285 [02:42<03:45,  1.34s/it]Loading train:  41%|████      | 117/285 [02:43<03:42,  1.32s/it]Loading train:  41%|████▏     | 118/285 [02:44<03:37,  1.30s/it]Loading train:  42%|████▏     | 119/285 [02:46<03:38,  1.32s/it]Loading train:  42%|████▏     | 120/285 [02:47<03:41,  1.34s/it]Loading train:  42%|████▏     | 121/285 [02:48<03:48,  1.39s/it]Loading train:  43%|████▎     | 122/285 [02:50<04:01,  1.48s/it]Loading train:  43%|████▎     | 123/285 [02:52<03:59,  1.48s/it]Loading train:  44%|████▎     | 124/285 [02:53<03:43,  1.39s/it]Loading train:  44%|████▍     | 125/285 [02:54<03:39,  1.37s/it]Loading train:  44%|████▍     | 126/285 [02:55<03:24,  1.29s/it]Loading train:  45%|████▍     | 127/285 [02:57<03:24,  1.29s/it]Loading train:  45%|████▍     | 128/285 [02:58<03:45,  1.43s/it]Loading train:  45%|████▌     | 129/285 [03:00<03:34,  1.37s/it]Loading train:  46%|████▌     | 130/285 [03:01<03:23,  1.32s/it]Loading train:  46%|████▌     | 131/285 [03:02<03:08,  1.22s/it]Loading train:  46%|████▋     | 132/285 [03:03<03:04,  1.21s/it]Loading train:  47%|████▋     | 133/285 [03:04<03:05,  1.22s/it]Loading train:  47%|████▋     | 134/285 [03:05<03:01,  1.20s/it]Loading train:  47%|████▋     | 135/285 [03:06<02:56,  1.17s/it]Loading train:  48%|████▊     | 136/285 [03:08<02:52,  1.16s/it]Loading train:  48%|████▊     | 137/285 [03:09<02:54,  1.18s/it]Loading train:  48%|████▊     | 138/285 [03:10<03:01,  1.23s/it]Loading train:  49%|████▉     | 139/285 [03:11<02:54,  1.20s/it]Loading train:  49%|████▉     | 140/285 [03:12<02:52,  1.19s/it]Loading train:  49%|████▉     | 141/285 [03:14<02:50,  1.19s/it]Loading train:  50%|████▉     | 142/285 [03:15<02:46,  1.16s/it]Loading train:  50%|█████     | 143/285 [03:16<02:40,  1.13s/it]Loading train:  51%|█████     | 144/285 [03:17<02:49,  1.20s/it]Loading train:  51%|█████     | 145/285 [03:18<02:50,  1.22s/it]Loading train:  51%|█████     | 146/285 [03:20<02:46,  1.20s/it]Loading train:  52%|█████▏    | 147/285 [03:21<02:46,  1.21s/it]Loading train:  52%|█████▏    | 148/285 [03:22<02:44,  1.20s/it]Loading train:  52%|█████▏    | 149/285 [03:23<02:44,  1.21s/it]Loading train:  53%|█████▎    | 150/285 [03:24<02:43,  1.21s/it]Loading train:  53%|█████▎    | 151/285 [03:26<02:46,  1.24s/it]Loading train:  53%|█████▎    | 152/285 [03:27<02:43,  1.23s/it]Loading train:  54%|█████▎    | 153/285 [03:28<02:37,  1.20s/it]Loading train:  54%|█████▍    | 154/285 [03:29<02:37,  1.20s/it]Loading train:  54%|█████▍    | 155/285 [03:30<02:38,  1.22s/it]Loading train:  55%|█████▍    | 156/285 [03:32<02:40,  1.24s/it]Loading train:  55%|█████▌    | 157/285 [03:33<02:32,  1.19s/it]Loading train:  55%|█████▌    | 158/285 [03:34<02:32,  1.20s/it]Loading train:  56%|█████▌    | 159/285 [03:35<02:31,  1.20s/it]Loading train:  56%|█████▌    | 160/285 [03:36<02:28,  1.19s/it]Loading train:  56%|█████▋    | 161/285 [03:38<02:26,  1.18s/it]Loading train:  57%|█████▋    | 162/285 [03:39<02:33,  1.25s/it]Loading train:  57%|█████▋    | 163/285 [03:40<02:27,  1.21s/it]Loading train:  58%|█████▊    | 164/285 [03:41<02:24,  1.19s/it]Loading train:  58%|█████▊    | 165/285 [03:42<02:17,  1.15s/it]Loading train:  58%|█████▊    | 166/285 [03:43<02:17,  1.16s/it]Loading train:  59%|█████▊    | 167/285 [03:45<02:17,  1.16s/it]Loading train:  59%|█████▉    | 168/285 [03:46<02:20,  1.20s/it]Loading train:  59%|█████▉    | 169/285 [03:47<02:21,  1.22s/it]Loading train:  60%|█████▉    | 170/285 [03:48<02:12,  1.15s/it]Loading train:  60%|██████    | 171/285 [03:49<02:13,  1.18s/it]Loading train:  60%|██████    | 172/285 [03:51<02:10,  1.16s/it]Loading train:  61%|██████    | 173/285 [03:52<02:07,  1.14s/it]Loading train:  61%|██████    | 174/285 [03:53<02:07,  1.15s/it]Loading train:  61%|██████▏   | 175/285 [03:54<02:18,  1.26s/it]Loading train:  62%|██████▏   | 176/285 [03:56<02:25,  1.33s/it]Loading train:  62%|██████▏   | 177/285 [03:57<02:17,  1.28s/it]Loading train:  62%|██████▏   | 178/285 [03:58<02:09,  1.21s/it]Loading train:  63%|██████▎   | 179/285 [03:59<02:02,  1.15s/it]Loading train:  63%|██████▎   | 180/285 [04:00<02:05,  1.20s/it]Loading train:  64%|██████▎   | 181/285 [04:02<02:05,  1.21s/it]Loading train:  64%|██████▍   | 182/285 [04:03<02:02,  1.19s/it]Loading train:  64%|██████▍   | 183/285 [04:04<01:55,  1.13s/it]Loading train:  65%|██████▍   | 184/285 [04:05<01:51,  1.10s/it]Loading train:  65%|██████▍   | 185/285 [04:06<01:48,  1.09s/it]Loading train:  65%|██████▌   | 186/285 [04:07<01:51,  1.12s/it]Loading train:  66%|██████▌   | 187/285 [04:08<01:54,  1.17s/it]Loading train:  66%|██████▌   | 188/285 [04:09<01:54,  1.18s/it]Loading train:  66%|██████▋   | 189/285 [04:11<01:48,  1.13s/it]Loading train:  67%|██████▋   | 190/285 [04:12<01:43,  1.09s/it]Loading train:  67%|██████▋   | 191/285 [04:13<01:44,  1.11s/it]Loading train:  67%|██████▋   | 192/285 [04:14<01:42,  1.10s/it]Loading train:  68%|██████▊   | 193/285 [04:15<01:38,  1.07s/it]Loading train:  68%|██████▊   | 194/285 [04:16<01:37,  1.07s/it]Loading train:  68%|██████▊   | 195/285 [04:17<01:36,  1.07s/it]Loading train:  69%|██████▉   | 196/285 [04:18<01:42,  1.15s/it]Loading train:  69%|██████▉   | 197/285 [04:20<01:45,  1.20s/it]Loading train:  69%|██████▉   | 198/285 [04:21<01:47,  1.24s/it]Loading train:  70%|██████▉   | 199/285 [04:22<01:43,  1.20s/it]Loading train:  70%|███████   | 200/285 [04:23<01:39,  1.17s/it]Loading train:  71%|███████   | 201/285 [04:24<01:40,  1.20s/it]Loading train:  71%|███████   | 202/285 [04:26<01:43,  1.24s/it]Loading train:  71%|███████   | 203/285 [04:27<01:41,  1.24s/it]Loading train:  72%|███████▏  | 204/285 [04:28<01:37,  1.21s/it]Loading train:  72%|███████▏  | 205/285 [04:29<01:34,  1.18s/it]Loading train:  72%|███████▏  | 206/285 [04:30<01:33,  1.18s/it]Loading train:  73%|███████▎  | 207/285 [04:32<01:35,  1.23s/it]Loading train:  73%|███████▎  | 208/285 [04:33<01:38,  1.28s/it]Loading train:  73%|███████▎  | 209/285 [04:34<01:38,  1.29s/it]Loading train:  74%|███████▎  | 210/285 [04:35<01:28,  1.18s/it]Loading train:  74%|███████▍  | 211/285 [04:37<01:27,  1.18s/it]Loading train:  74%|███████▍  | 212/285 [04:38<01:33,  1.28s/it]Loading train:  75%|███████▍  | 213/285 [04:39<01:29,  1.24s/it]Loading train:  75%|███████▌  | 214/285 [04:40<01:20,  1.14s/it]Loading train:  75%|███████▌  | 215/285 [04:41<01:18,  1.12s/it]Loading train:  76%|███████▌  | 216/285 [04:42<01:11,  1.04s/it]Loading train:  76%|███████▌  | 217/285 [04:43<01:09,  1.03s/it]Loading train:  76%|███████▋  | 218/285 [04:44<01:09,  1.03s/it]Loading train:  77%|███████▋  | 219/285 [04:45<01:06,  1.01s/it]Loading train:  77%|███████▋  | 220/285 [04:46<01:00,  1.08it/s]Loading train:  78%|███████▊  | 221/285 [04:47<00:56,  1.12it/s]Loading train:  78%|███████▊  | 222/285 [04:47<00:56,  1.12it/s]Loading train:  78%|███████▊  | 223/285 [04:48<00:53,  1.16it/s]Loading train:  79%|███████▊  | 224/285 [04:49<00:52,  1.17it/s]Loading train:  79%|███████▉  | 225/285 [04:50<00:51,  1.16it/s]Loading train:  79%|███████▉  | 226/285 [04:51<00:54,  1.07it/s]Loading train:  80%|███████▉  | 227/285 [04:52<00:55,  1.05it/s]Loading train:  80%|████████  | 228/285 [04:53<00:56,  1.01it/s]Loading train:  80%|████████  | 229/285 [04:54<00:54,  1.03it/s]Loading train:  81%|████████  | 230/285 [04:55<00:51,  1.08it/s]Loading train:  81%|████████  | 231/285 [04:56<00:47,  1.13it/s]Loading train:  81%|████████▏ | 232/285 [04:57<00:46,  1.13it/s]Loading train:  82%|████████▏ | 233/285 [04:58<00:47,  1.09it/s]Loading train:  82%|████████▏ | 234/285 [04:59<00:49,  1.04it/s]Loading train:  82%|████████▏ | 235/285 [05:00<00:49,  1.00it/s]Loading train:  83%|████████▎ | 236/285 [05:01<00:52,  1.06s/it]Loading train:  83%|████████▎ | 237/285 [05:02<00:51,  1.08s/it]Loading train:  84%|████████▎ | 238/285 [05:03<00:50,  1.08s/it]Loading train:  84%|████████▍ | 239/285 [05:04<00:47,  1.04s/it]Loading train:  84%|████████▍ | 240/285 [05:05<00:43,  1.04it/s]Loading train:  85%|████████▍ | 241/285 [05:06<00:40,  1.09it/s]Loading train:  85%|████████▍ | 242/285 [05:06<00:38,  1.12it/s]Loading train:  85%|████████▌ | 243/285 [05:07<00:36,  1.14it/s]Loading train:  86%|████████▌ | 244/285 [05:08<00:38,  1.06it/s]Loading train:  86%|████████▌ | 245/285 [05:09<00:35,  1.11it/s]Loading train:  86%|████████▋ | 246/285 [05:10<00:36,  1.06it/s]Loading train:  87%|████████▋ | 247/285 [05:11<00:36,  1.04it/s]Loading train:  87%|████████▋ | 248/285 [05:12<00:35,  1.05it/s]Loading train:  87%|████████▋ | 249/285 [05:13<00:32,  1.09it/s]Loading train:  88%|████████▊ | 250/285 [05:14<00:31,  1.11it/s]Loading train:  88%|████████▊ | 251/285 [05:15<00:29,  1.14it/s]Loading train:  88%|████████▊ | 252/285 [05:16<00:28,  1.14it/s]Loading train:  89%|████████▉ | 253/285 [05:16<00:28,  1.13it/s]Loading train:  89%|████████▉ | 254/285 [05:17<00:27,  1.12it/s]Loading train:  89%|████████▉ | 255/285 [05:18<00:26,  1.14it/s]Loading train:  90%|████████▉ | 256/285 [05:19<00:24,  1.18it/s]Loading train:  90%|█████████ | 257/285 [05:20<00:22,  1.22it/s]Loading train:  91%|█████████ | 258/285 [05:21<00:23,  1.16it/s]Loading train:  91%|█████████ | 259/285 [05:22<00:22,  1.15it/s]Loading train:  91%|█████████ | 260/285 [05:22<00:20,  1.22it/s]Loading train:  92%|█████████▏| 261/285 [05:23<00:19,  1.24it/s]Loading train:  92%|█████████▏| 262/285 [05:24<00:19,  1.21it/s]Loading train:  92%|█████████▏| 263/285 [05:25<00:17,  1.23it/s]Loading train:  93%|█████████▎| 264/285 [05:26<00:19,  1.10it/s]Loading train:  93%|█████████▎| 265/285 [05:27<00:19,  1.04it/s]Loading train:  93%|█████████▎| 266/285 [05:28<00:17,  1.07it/s]Loading train:  94%|█████████▎| 267/285 [05:29<00:16,  1.09it/s]Loading train:  94%|█████████▍| 268/285 [05:30<00:16,  1.04it/s]Loading train:  94%|█████████▍| 269/285 [05:31<00:15,  1.04it/s]Loading train:  95%|█████████▍| 270/285 [05:32<00:14,  1.07it/s]Loading train:  95%|█████████▌| 271/285 [05:32<00:12,  1.10it/s]Loading train:  95%|█████████▌| 272/285 [05:33<00:12,  1.08it/s]Loading train:  96%|█████████▌| 273/285 [05:34<00:10,  1.12it/s]Loading train:  96%|█████████▌| 274/285 [05:35<00:09,  1.12it/s]Loading train:  96%|█████████▋| 275/285 [05:36<00:09,  1.07it/s]Loading train:  97%|█████████▋| 276/285 [05:37<00:08,  1.04it/s]Loading train:  97%|█████████▋| 277/285 [05:38<00:07,  1.07it/s]Loading train:  98%|█████████▊| 278/285 [05:39<00:06,  1.11it/s]Loading train:  98%|█████████▊| 279/285 [05:40<00:05,  1.10it/s]Loading train:  98%|█████████▊| 280/285 [05:41<00:04,  1.12it/s]Loading train:  99%|█████████▊| 281/285 [05:42<00:03,  1.10it/s]Loading train:  99%|█████████▉| 282/285 [05:43<00:02,  1.09it/s]Loading train:  99%|█████████▉| 283/285 [05:44<00:01,  1.02it/s]Loading train: 100%|█████████▉| 284/285 [05:45<00:01,  1.02s/it]Loading train: 100%|██████████| 285/285 [05:46<00:00,  1.03s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:04, 63.23it/s]concatenating: train:   9%|▉         | 27/285 [00:00<00:03, 79.35it/s]concatenating: train:  19%|█▉        | 55/285 [00:00<00:02, 101.07it/s]concatenating: train:  30%|███       | 86/285 [00:00<00:01, 126.65it/s]concatenating: train:  41%|████      | 117/285 [00:00<00:01, 153.32it/s]concatenating: train:  53%|█████▎    | 150/285 [00:00<00:00, 181.81it/s]concatenating: train:  64%|██████▍   | 183/285 [00:00<00:00, 208.90it/s]concatenating: train:  76%|███████▌  | 216/285 [00:00<00:00, 234.47it/s]concatenating: train:  87%|████████▋ | 249/285 [00:00<00:00, 255.67it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 278.28it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.42s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.38s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.32s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 60.41it/s]2019-07-10 21:54:17.278018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-10 21:54:17.278130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-10 21:54:17.278147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-10 21:54:17.278156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-10 21:54:17.278604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.07it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.09it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  5.82it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.45it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.73it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.71it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  6.87it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.92it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.36it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:02,  7.70it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:01,  9.54it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.85it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.98it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:02<00:01,  8.16it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00, 10.15it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00, 10.40it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 10.25it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  7.92it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 11.38it/s]
Epoch 00052: val_mDice did not improve from 0.58770
Restoring model weights from the end of the best epoch
Epoch 00052: early stopping
{'val_loss': [2.6556929633730935, 2.693166051592146, 1.3260360558827717, 1.154867138181414, 1.0271994726998466, 0.9852595045453026, 0.9847547383535475, 0.9979980105445498, 1.015866722379412, 0.9748685359954834, 0.9463173945744833, 0.9153428815660023, 0.9709861505599249, 0.965904712677002, 0.9258245627085367, 0.992964335850307, 0.9235757873171851, 0.933829665184021, 0.9119565203076317, 0.8930099861962455, 0.9734187693822951, 0.9091753959655762, 0.8874233904339018, 0.9007394086746943, 0.8904272204353696, 0.9262206895010812, 0.8838244392758324, 0.8667336361748832, 0.9081167493547712, 0.8597105911799839, 0.8487055244899931, 0.846245941661653, 0.9165828795660109, 0.835795833950951, 0.8848381837209066, 0.8923882529849098, 0.9159431798117501, 0.8700181075504848, 0.8364289204279581, 0.828616840498788, 0.8431684176127116, 0.832718088513329, 0.918103195372082, 0.8053404830750965, 0.8691666693914504, 0.8483009678976876, 0.7957336789085752, 0.7690041121982393, 0.7904469058627174, 0.8368463629768008, 0.8050171193622407, 0.8011656715756371], 'val_acc': [0.9013621721948896, 0.9057532236689613, 0.9280356963475546, 0.9380837877591451, 0.930377775714511, 0.9413003410611834, 0.9363301424753099, 0.9442330598831177, 0.9426327659970238, 0.943667607648032, 0.9419070255188715, 0.9433356126149496, 0.9412248248145694, 0.9398008443060375, 0.943340213525863, 0.9313644880340213, 0.9444345008759272, 0.9359546445664906, 0.9421382716723851, 0.943559970174517, 0.9318429288410005, 0.9448054149037316, 0.9415979584058126, 0.942925805137271, 0.945576894850958, 0.9426923223904201, 0.943511908962613, 0.9398626316161383, 0.9440178615706307, 0.9402701570874169, 0.9445604454903376, 0.9385943043799627, 0.941272911571321, 0.9432371570950463, 0.9360416673478626, 0.940986746833438, 0.9393566931997027, 0.9316460575376239, 0.9430586099624634, 0.9392536651520502, 0.9425984422365824, 0.9394894554501488, 0.9394757123220534, 0.9449313112667629, 0.9398030979292733, 0.941588838895162, 0.9422848253023057, 0.9419024785359701, 0.9432188754989987, 0.940357125940777, 0.9405265280178615, 0.9423191405477978], 'val_mDice': [0.15936155014094852, 0.16100948655401312, 0.4298832613442625, 0.5151601453267393, 0.553257092833519, 0.5791932867751235, 0.5730116890654677, 0.5680533243077142, 0.5528607558281649, 0.5697058451672395, 0.5727022297325588, 0.5877020919606799, 0.5735973146344934, 0.5736629785526366, 0.5793469340673515, 0.5543680934324151, 0.5682078936979884, 0.5773856104129836, 0.5734062319000562, 0.5809240649853434, 0.5603445021524316, 0.5607770409967218, 0.5777722423275312, 0.5647238477000168, 0.5696269788202786, 0.5337977955738703, 0.562133544257709, 0.5663440181385904, 0.5546179186730158, 0.572433563215392, 0.5712217048165344, 0.5735616520756767, 0.5277299545705318, 0.5789606548136189, 0.5587215796113014, 0.5220327588419119, 0.5034708996259031, 0.5615047709572882, 0.5719426387832278, 0.5652685333930311, 0.5408718286170846, 0.5460476630500385, 0.4917468935960815, 0.5531232396051997, 0.5138566259826932, 0.5171647050551006, 0.5660777446769533, 0.5727198432598796, 0.5528342432919002, 0.5055622603921663, 0.5488008299753779, 0.5440913949693952], 'loss': [3.2157793746923975, 1.3810978536778662, 0.7794249371133697, 0.603524251873148, 0.5368672188982606, 0.49880528538494134, 0.47341075527523213, 0.4559802361851095, 0.4404015157846488, 0.427175300904315, 0.4222497367229171, 0.4131375517612113, 0.4067261425118605, 0.4007955216616823, 0.3953501640520782, 0.3892924805148985, 0.3874053647517239, 0.38337589257113247, 0.37936840185269655, 0.37438742465680563, 0.37102798831148004, 0.3663789803854919, 0.3649811553132311, 0.3614822311428486, 0.36067978014761204, 0.3585882651936877, 0.35480693625029464, 0.35217398680862905, 0.34931356590424334, 0.3506337848441872, 0.3469413170436225, 0.3442795080717575, 0.3432962162567743, 0.34259667465722193, 0.33983121071451083, 0.34086230121436595, 0.3363788158810389, 0.33596590650846947, 0.33513575672804563, 0.33245262243923757, 0.33347438739769625, 0.33035944740345236, 0.32860727629749814, 0.3292172363332087, 0.32619729453092, 0.3263825229626757, 0.324019063713005, 0.3238580300671438, 0.3238984485547713, 0.32285567027584355, 0.32344187392488893, 0.3208616882223648], 'acc': [0.47088192287255787, 0.8771749093442012, 0.8994679759411492, 0.9110260111922034, 0.9171137449390653, 0.9209711341722774, 0.9236789974537525, 0.925497431067435, 0.9269982198311089, 0.9282374972664645, 0.9289857618538014, 0.9297925851375859, 0.9308649992607269, 0.931247914839462, 0.9320266029153091, 0.9323449393607574, 0.9329923350548547, 0.9331777108320042, 0.9336776889908031, 0.9342402077741606, 0.9344857650752791, 0.9350965254587638, 0.9352735077826899, 0.9355942808365992, 0.9357395699448454, 0.9360158654428617, 0.9362515487008088, 0.936659002283393, 0.9371463757432769, 0.9368559614596671, 0.9371428279396838, 0.937530913540502, 0.9376594249007558, 0.9378374720529851, 0.9381352334852643, 0.9378969091336714, 0.9385171286835017, 0.938416048157576, 0.9385974388005809, 0.9387359618451155, 0.9385423161676906, 0.9391064335896786, 0.9391258299316265, 0.9392033603027282, 0.9395033465154327, 0.9395606475044634, 0.9397461365040084, 0.9398159123763243, 0.9397432865930104, 0.9398608854884745, 0.9398983283288359, 0.940091259359555], 'mDice': [0.07159511620296963, 0.268270955555513, 0.44414379939376586, 0.5293922171510895, 0.5677308857912086, 0.5907310751423525, 0.6066115794899791, 0.6175790151948526, 0.6277254889276599, 0.6364088641992763, 0.6397352845585597, 0.6458503736428312, 0.6501760419356885, 0.6542645079427218, 0.6578843745740365, 0.6621358927927519, 0.6634009705358372, 0.6661834389069003, 0.6689327344146105, 0.6725185107743554, 0.6748619772966413, 0.6781226941126721, 0.6791279125884707, 0.6816011361816565, 0.6821496599392094, 0.6836628903882086, 0.6862951412420639, 0.6883105836623387, 0.6903157304173057, 0.689451530934851, 0.6919213324377297, 0.6938491251074741, 0.6946669610474687, 0.6950908961014778, 0.697126057489497, 0.69641966219465, 0.6996846171916508, 0.7000520781374906, 0.7005954013754229, 0.7025729282664867, 0.7017369288021092, 0.7040538314865669, 0.7053568903733844, 0.7048846881514182, 0.7071402567486003, 0.7069981840389047, 0.7086880957549401, 0.7089098853046365, 0.7088611761636994, 0.709646033015765, 0.7092186620705662, 0.7110450647000014]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 26, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 13, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 26, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 10)   5410        dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 10)   40          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 10)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 52, 10)   0           activation_11[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 70)   0           dropout_5[0][0]                  
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 13)   923         concatenate_7[0][0]              
==================================================================================================
Total params: 229,413
Trainable params: 54,713
Non-trainable params: 174,700
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 17s - loss: 1.8217 - acc: 0.5854 - mDice: 0.2756 - val_loss: 0.6461 - val_acc: 0.9266 - val_mDice: 0.5203

Epoch 00001: val_mDice improved from -inf to 0.52032, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 12s - loss: 0.5188 - acc: 0.9066 - mDice: 0.5819 - val_loss: 0.4676 - val_acc: 0.9315 - val_mDice: 0.6192

Epoch 00002: val_mDice improved from 0.52032 to 0.61920, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 12s - loss: 0.4317 - acc: 0.9139 - mDice: 0.6364 - val_loss: 0.5040 - val_acc: 0.9374 - val_mDice: 0.6099

Epoch 00003: val_mDice did not improve from 0.61920
Epoch 4/300
 - 11s - loss: 0.3961 - acc: 0.9208 - mDice: 0.6599 - val_loss: 0.4374 - val_acc: 0.9440 - val_mDice: 0.6379

Epoch 00004: val_mDice improved from 0.61920 to 0.63787, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 11s - loss: 0.3743 - acc: 0.9266 - mDice: 0.6748 - val_loss: 0.4424 - val_acc: 0.9455 - val_mDice: 0.6365

Epoch 00005: val_mDice did not improve from 0.63787
Epoch 6/300
 - 11s - loss: 0.3605 - acc: 0.9321 - mDice: 0.6845 - val_loss: 0.4989 - val_acc: 0.9460 - val_mDice: 0.6081

Epoch 00006: val_mDice did not improve from 0.63787
Epoch 7/300
 - 11s - loss: 0.3465 - acc: 0.9389 - mDice: 0.6941 - val_loss: 0.4913 - val_acc: 0.9531 - val_mDice: 0.6151

Epoch 00007: val_mDice did not improve from 0.63787
Epoch 8/300
 - 12s - loss: 0.3386 - acc: 0.9452 - mDice: 0.6994 - val_loss: 0.4738 - val_acc: 0.9550 - val_mDice: 0.6229

Epoch 00008: val_mDice did not improve from 0.63787
Epoch 9/300
 - 12s - loss: 0.3284 - acc: 0.9480 - mDice: 0.7066 - val_loss: 0.4716 - val_acc: 0.9519 - val_mDice: 0.6186

Epoch 00009: val_mDice did not improve from 0.63787
Epoch 10/300
 - 11s - loss: 0.3204 - acc: 0.9493 - mDice: 0.7123 - val_loss: 0.4790 - val_acc: 0.9543 - val_mDice: 0.6233

Epoch 00010: val_mDice did not improve from 0.63787
Epoch 11/300
 - 11s - loss: 0.3158 - acc: 0.9498 - mDice: 0.7157 - val_loss: 0.4561 - val_acc: 0.9554 - val_mDice: 0.6328

Epoch 00011: val_mDice did not improve from 0.63787
Epoch 12/300
 - 11s - loss: 0.3103 - acc: 0.9505 - mDice: 0.7198 - val_loss: 0.4897 - val_acc: 0.9536 - val_mDice: 0.6077

Epoch 00012: val_mDice did not improve from 0.63787
Epoch 13/300
 - 11s - loss: 0.3050 - acc: 0.9510 - mDice: 0.7237 - val_loss: 0.4952 - val_acc: 0.9552 - val_mDice: 0.6129

Epoch 00013: val_mDice did not improve from 0.63787
Epoch 14/300
 - 11s - loss: 0.3008 - acc: 0.9514 - mDice: 0.7269 - val_loss: 0.5253 - val_acc: 0.9543 - val_mDice: 0.5947

Epoch 00014: val_mDice did not improve from 0.63787
Epoch 15/300
 - 12s - loss: 0.2974 - acc: 0.9517 - mDice: 0.7294 - val_loss: 0.4703 - val_acc: 0.9517 - val_mDice: 0.6205

Epoch 00015: val_mDice did not improve from 0.63787
Epoch 16/300
 - 12s - loss: 0.2947 - acc: 0.9519 - mDice: 0.7315 - val_loss: 0.5405 - val_acc: 0.9544 - val_mDice: 0.6137

Epoch 00016: val_mDice did not improve from 0.63787
Epoch 17/300
 - 11s - loss: 0.2898 - acc: 0.9524 - mDice: 0.7351 - val_loss: 0.5223 - val_acc: 0.9538 - val_mDice: 0.6110

Epoch 00017: val_mDice did not improve from 0.63787
Epoch 18/300
 - 12s - loss: 0.2874 - acc: 0.9527 - mDice: 0.7370 - val_loss: 0.4940 - val_acc: 0.9531 - val_mDice: 0.6092

Epoch 00018: val_mDice did not improve from 0.63787
Epoch 19/300
 - 12s - loss: 0.2832 - acc: 0.9529 - mDice: 0.7401 - val_loss: 0.4868 - val_acc: 0.9537 - val_mDice: 0.6170

Epoch 00019: val_mDice did not improve from 0.63787
Epoch 20/300
 - 12s - loss: 0.2820 - acc: 0.9532 - mDice: 0.7411 - val_loss: 0.4810 - val_acc: 0.9550 - val_mDice: 0.6197

Epoch 00020: val_mDice did not improve from 0.63787
Epoch 21/300
 - 12s - loss: 0.2802 - acc: 0.9534 - mDice: 0.7426 - val_loss: 0.5663 - val_acc: 0.9551 - val_mDice: 0.5951

Epoch 00021: val_mDice did not improve from 0.63787
Epoch 22/300
 - 12s - loss: 0.2769 - acc: 0.9536 - mDice: 0.7450 - val_loss: 0.4994 - val_acc: 0.9542 - val_mDice: 0.6127

Epoch 00022: val_mDice did not improve from 0.63787
Epoch 23/300
 - 12s - loss: 0.2748 - acc: 0.9538 - mDice: 0.7467 - val_loss: 0.4843 - val_acc: 0.9539 - val_mDice: 0.6198

Epoch 00023: val_mDice did not improve from 0.63787
Epoch 24/300
 - 13s - loss: 0.2739 - acc: 0.9539 - mDice: 0.7474 - val_loss: 0.4550 - val_acc: 0.9536 - val_mDice: 0.6312

Epoch 00024: val_mDice did not improve from 0.63787
Epoch 25/300
 - 12s - loss: 0.2715 - acc: 0.9540 - mDice: 0.7492 - val_loss: 0.4896 - val_acc: 0.9488 - val_mDice: 0.6082

Epoch 00025: val_mDice did not improve from 0.63787
Epoch 26/300
 - 13s - loss: 0.2708 - acc: 0.9541 - mDice: 0.7498 - val_loss: 0.4636 - val_acc: 0.9546 - val_mDice: 0.6261

Epoch 00026: val_mDice did not improve from 0.63787
Epoch 27/300
 - 12s - loss: 0.2679 - acc: 0.9543 - mDice: 0.7521 - val_loss: 0.5269 - val_acc: 0.9544 - val_mDice: 0.6034

Epoch 00027: val_mDice did not improve from 0.63787
Epoch 28/300
 - 12s - loss: 0.2670 - acc: 0.9544 - mDice: 0.7527 - val_loss: 0.4939 - val_acc: 0.9535 - val_mDice: 0.6129

Epoch 00028: val_mDice did not improve from 0.63787
Epoch 29/300
 - 13s - loss: 0.2661 - acc: 0.9544 - mDice: 0.7534 - val_loss: 0.4753 - val_acc: 0.9529 - val_mDice: 0.6213

Epoch 00029: val_mDice did not improve from 0.63787
Epoch 30/300
 - 12s - loss: 0.2635 - acc: 0.9547 - mDice: 0.7555 - val_loss: 0.5442 - val_acc: 0.9537 - val_mDice: 0.5896

Epoch 00030: val_mDice did not improve from 0.63787
Epoch 31/300
 - 12s - loss: 0.2639 - acc: 0.9547 - mDice: 0.7552 - val_loss: 0.4666 - val_acc: 0.9530 - val_mDice: 0.6210

Epoch 00031: val_mDice did not improve from 0.63787
Epoch 32/300
 - 13s - loss: 0.2602 - acc: 0.9549 - mDice: 0.7581 - val_loss: 0.5106 - val_acc: 0.9551 - val_mDice: 0.6137

Epoch 00032: val_mDice did not improve from 0.63787
Epoch 33/300
 - 12s - loss: 0.2587 - acc: 0.9551 - mDice: 0.7592 - val_loss: 0.4657 - val_acc: 0.9544 - val_mDice: 0.6244

Epoch 00033: val_mDice did not improve from 0.63787
Epoch 34/300
 - 12s - loss: 0.2582 - acc: 0.9552 - mDice: 0.7597 - val_loss: 0.4731 - val_acc: 0.9523 - val_mDice: 0.6172

Epoch 00034: val_mDice did not improve from 0.63787
Epoch 35/300
 - 13s - loss: 0.2571 - acc: 0.9552 - mDice: 0.7605 - val_loss: 0.4576 - val_acc: 0.9521 - val_mDice: 0.6264

Epoch 00035: val_mDice did not improve from 0.63787
Epoch 36/300
 - 12s - loss: 0.2552 - acc: 0.9553 - mDice: 0.7620 - val_loss: 0.5017 - val_acc: 0.9545 - val_mDice: 0.6121

Epoch 00036: val_mDice did not improve from 0.63787
Epoch 37/300
 - 12s - loss: 0.2556 - acc: 0.9553 - mDice: 0.7617 - val_loss: 0.5397 - val_acc: 0.9526 - val_mDice: 0.5837

Epoch 00037: val_mDice did not improve from 0.63787
Epoch 38/300
 - 12s - loss: 0.2529 - acc: 0.9555 - mDice: 0.7639 - val_loss: 0.5202 - val_acc: 0.9523 - val_mDice: 0.5951

Epoch 00038: val_mDice did not improve from 0.63787
Epoch 39/300
 - 12s - loss: 0.2568 - acc: 0.9553 - mDice: 0.7608 - val_loss: 0.4642 - val_acc: 0.9531 - val_mDice: 0.6236

Epoch 00039: val_mDice did not improve from 0.63787
Epoch 40/300
 - 13s - loss: 0.2514 - acc: 0.9556 - mDice: 0.7651 - val_loss: 0.4967 - val_acc: 0.9520 - val_mDice: 0.6051

Epoch 00040: val_mDice did not improve from 0.63787
Epoch 41/300
 - 12s - loss: 0.2509 - acc: 0.9557 - mDice: 0.7655 - val_loss: 0.5367 - val_acc: 0.9524 - val_mDice: 0.5962

Epoch 00041: val_mDice did not improve from 0.63787
Epoch 42/300
 - 12s - loss: 0.2486 - acc: 0.9557 - mDice: 0.7673 - val_loss: 0.5373 - val_acc: 0.9520 - val_mDice: 0.5860

Epoch 00042: val_mDice did not improve from 0.63787
Epoch 43/300
 - 13s - loss: 0.2488 - acc: 0.9558 - mDice: 0.7671 - val_loss: 0.5154 - val_acc: 0.9548 - val_mDice: 0.6029

Epoch 00043: val_mDice did not improve from 0.63787
Epoch 44/300
 - 13s - loss: 0.2494 - acc: 0.9559 - mDice: 0.7666 - val_loss: 0.4830 - val_acc: 0.9537 - val_mDice: 0.6163

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.34s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.09s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.89s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:06,  1.92s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:21,  1.77s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:20,  1.77s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:54,  1.69s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:09,  1.75s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:43,  1.66s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<08:06,  1.75s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<08:02,  1.74s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:40,  1.89s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:56,  1.95s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:32,  1.87s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:51,  1.95s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:31,  1.88s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<08:21,  1.85s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:38,  1.92s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<08:46,  1.96s/it]predicting train subjects:   6%|▌         | 17/285 [00:31<08:21,  1.87s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:22,  1.88s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<08:06,  1.83s/it]predicting train subjects:   7%|▋         | 20/285 [00:36<08:08,  1.84s/it]predicting train subjects:   7%|▋         | 21/285 [00:38<08:28,  1.93s/it]predicting train subjects:   8%|▊         | 22/285 [00:40<08:03,  1.84s/it]predicting train subjects:   8%|▊         | 23/285 [00:42<08:06,  1.86s/it]predicting train subjects:   8%|▊         | 24/285 [00:43<07:50,  1.80s/it]predicting train subjects:   9%|▉         | 25/285 [00:46<08:14,  1.90s/it]predicting train subjects:   9%|▉         | 26/285 [00:48<08:23,  1.94s/it]predicting train subjects:   9%|▉         | 27/285 [00:49<08:00,  1.86s/it]predicting train subjects:  10%|▉         | 28/285 [00:51<07:56,  1.85s/it]predicting train subjects:  10%|█         | 29/285 [00:53<08:02,  1.88s/it]predicting train subjects:  11%|█         | 30/285 [00:55<08:16,  1.95s/it]predicting train subjects:  11%|█         | 31/285 [00:57<08:32,  2.02s/it]predicting train subjects:  11%|█         | 32/285 [00:59<08:01,  1.90s/it]predicting train subjects:  12%|█▏        | 33/285 [01:01<07:55,  1.89s/it]predicting train subjects:  12%|█▏        | 34/285 [01:03<07:57,  1.90s/it]predicting train subjects:  12%|█▏        | 35/285 [01:05<08:13,  1.97s/it]predicting train subjects:  13%|█▎        | 36/285 [01:07<07:48,  1.88s/it]predicting train subjects:  13%|█▎        | 37/285 [01:08<07:47,  1.88s/it]predicting train subjects:  13%|█▎        | 38/285 [01:11<08:09,  1.98s/it]predicting train subjects:  14%|█▎        | 39/285 [01:12<07:46,  1.90s/it]predicting train subjects:  14%|█▍        | 40/285 [01:14<07:42,  1.89s/it]predicting train subjects:  14%|█▍        | 41/285 [01:16<07:27,  1.84s/it]predicting train subjects:  15%|█▍        | 42/285 [01:18<07:18,  1.80s/it]predicting train subjects:  15%|█▌        | 43/285 [01:19<07:17,  1.81s/it]predicting train subjects:  15%|█▌        | 44/285 [01:22<07:33,  1.88s/it]predicting train subjects:  16%|█▌        | 45/285 [01:23<07:25,  1.86s/it]predicting train subjects:  16%|█▌        | 46/285 [01:25<07:35,  1.91s/it]predicting train subjects:  16%|█▋        | 47/285 [01:27<07:17,  1.84s/it]predicting train subjects:  17%|█▋        | 48/285 [01:29<07:12,  1.83s/it]predicting train subjects:  17%|█▋        | 49/285 [01:31<07:38,  1.94s/it]predicting train subjects:  18%|█▊        | 50/285 [01:33<07:33,  1.93s/it]predicting train subjects:  18%|█▊        | 51/285 [01:35<07:52,  2.02s/it]predicting train subjects:  18%|█▊        | 52/285 [01:37<07:22,  1.90s/it]predicting train subjects:  19%|█▊        | 53/285 [01:39<07:23,  1.91s/it]predicting train subjects:  19%|█▉        | 54/285 [01:41<07:37,  1.98s/it]predicting train subjects:  19%|█▉        | 55/285 [01:43<07:21,  1.92s/it]predicting train subjects:  20%|█▉        | 56/285 [01:45<07:36,  2.00s/it]predicting train subjects:  20%|██        | 57/285 [01:47<07:40,  2.02s/it]predicting train subjects:  20%|██        | 58/285 [01:49<07:41,  2.03s/it]predicting train subjects:  21%|██        | 59/285 [01:51<08:09,  2.16s/it]predicting train subjects:  21%|██        | 60/285 [01:54<08:14,  2.20s/it]predicting train subjects:  21%|██▏       | 61/285 [01:56<07:50,  2.10s/it]predicting train subjects:  22%|██▏       | 62/285 [01:58<07:46,  2.09s/it]predicting train subjects:  22%|██▏       | 63/285 [02:00<07:39,  2.07s/it]predicting train subjects:  22%|██▏       | 64/285 [02:02<07:24,  2.01s/it]predicting train subjects:  23%|██▎       | 65/285 [02:04<07:43,  2.11s/it]predicting train subjects:  23%|██▎       | 66/285 [02:06<07:50,  2.15s/it]predicting train subjects:  24%|██▎       | 67/285 [02:08<07:41,  2.12s/it]predicting train subjects:  24%|██▍       | 68/285 [02:10<07:32,  2.09s/it]predicting train subjects:  24%|██▍       | 69/285 [02:12<07:34,  2.10s/it]predicting train subjects:  25%|██▍       | 70/285 [02:14<07:32,  2.10s/it]predicting train subjects:  25%|██▍       | 71/285 [02:16<07:26,  2.09s/it]predicting train subjects:  25%|██▌       | 72/285 [02:18<07:19,  2.06s/it]predicting train subjects:  26%|██▌       | 73/285 [02:21<07:24,  2.09s/it]predicting train subjects:  26%|██▌       | 74/285 [02:23<07:20,  2.09s/it]predicting train subjects:  26%|██▋       | 75/285 [02:25<07:13,  2.07s/it]predicting train subjects:  27%|██▋       | 76/285 [02:27<07:17,  2.09s/it]predicting train subjects:  27%|██▋       | 77/285 [02:29<07:01,  2.03s/it]predicting train subjects:  27%|██▋       | 78/285 [02:31<06:52,  1.99s/it]predicting train subjects:  28%|██▊       | 79/285 [02:33<06:56,  2.02s/it]predicting train subjects:  28%|██▊       | 80/285 [02:35<06:47,  1.99s/it]predicting train subjects:  28%|██▊       | 81/285 [02:36<06:34,  1.93s/it]predicting train subjects:  29%|██▉       | 82/285 [02:39<06:52,  2.03s/it]predicting train subjects:  29%|██▉       | 83/285 [02:41<06:56,  2.06s/it]predicting train subjects:  29%|██▉       | 84/285 [02:43<06:56,  2.07s/it]predicting train subjects:  30%|██▉       | 85/285 [02:45<07:01,  2.11s/it]predicting train subjects:  30%|███       | 86/285 [02:47<07:12,  2.17s/it]predicting train subjects:  31%|███       | 87/285 [02:50<07:16,  2.21s/it]predicting train subjects:  31%|███       | 88/285 [02:52<07:01,  2.14s/it]predicting train subjects:  31%|███       | 89/285 [02:54<06:59,  2.14s/it]predicting train subjects:  32%|███▏      | 90/285 [02:56<06:56,  2.13s/it]predicting train subjects:  32%|███▏      | 91/285 [02:58<06:45,  2.09s/it]predicting train subjects:  32%|███▏      | 92/285 [03:00<06:43,  2.09s/it]predicting train subjects:  33%|███▎      | 93/285 [03:02<06:30,  2.03s/it]predicting train subjects:  33%|███▎      | 94/285 [03:04<06:25,  2.02s/it]predicting train subjects:  33%|███▎      | 95/285 [03:06<06:32,  2.07s/it]predicting train subjects:  34%|███▎      | 96/285 [03:08<06:34,  2.09s/it]predicting train subjects:  34%|███▍      | 97/285 [03:10<06:39,  2.12s/it]predicting train subjects:  34%|███▍      | 98/285 [03:13<06:36,  2.12s/it]predicting train subjects:  35%|███▍      | 99/285 [03:15<06:44,  2.18s/it]predicting train subjects:  35%|███▌      | 100/285 [03:17<06:49,  2.21s/it]predicting train subjects:  35%|███▌      | 101/285 [03:19<06:32,  2.13s/it]predicting train subjects:  36%|███▌      | 102/285 [03:21<06:31,  2.14s/it]predicting train subjects:  36%|███▌      | 103/285 [03:23<06:31,  2.15s/it]predicting train subjects:  36%|███▋      | 104/285 [03:26<06:29,  2.15s/it]predicting train subjects:  37%|███▋      | 105/285 [03:28<06:27,  2.15s/it]predicting train subjects:  37%|███▋      | 106/285 [03:30<06:09,  2.07s/it]predicting train subjects:  38%|███▊      | 107/285 [03:32<06:01,  2.03s/it]predicting train subjects:  38%|███▊      | 108/285 [03:33<05:49,  1.98s/it]predicting train subjects:  38%|███▊      | 109/285 [03:36<06:03,  2.07s/it]predicting train subjects:  39%|███▊      | 110/285 [03:38<06:07,  2.10s/it]predicting train subjects:  39%|███▉      | 111/285 [03:40<05:57,  2.05s/it]predicting train subjects:  39%|███▉      | 112/285 [03:42<06:06,  2.12s/it]predicting train subjects:  40%|███▉      | 113/285 [03:44<06:02,  2.11s/it]predicting train subjects:  40%|████      | 114/285 [03:46<05:58,  2.10s/it]predicting train subjects:  40%|████      | 115/285 [03:48<05:55,  2.09s/it]predicting train subjects:  41%|████      | 116/285 [03:50<05:52,  2.09s/it]predicting train subjects:  41%|████      | 117/285 [03:52<05:44,  2.05s/it]predicting train subjects:  41%|████▏     | 118/285 [03:54<05:30,  1.98s/it]predicting train subjects:  42%|████▏     | 119/285 [03:56<05:38,  2.04s/it]predicting train subjects:  42%|████▏     | 120/285 [03:58<05:32,  2.01s/it]predicting train subjects:  42%|████▏     | 121/285 [04:00<05:24,  1.98s/it]predicting train subjects:  43%|████▎     | 122/285 [04:02<05:19,  1.96s/it]predicting train subjects:  43%|████▎     | 123/285 [04:04<05:02,  1.87s/it]predicting train subjects:  44%|████▎     | 124/285 [04:06<05:10,  1.93s/it]predicting train subjects:  44%|████▍     | 125/285 [04:08<04:57,  1.86s/it]predicting train subjects:  44%|████▍     | 126/285 [04:09<04:46,  1.80s/it]predicting train subjects:  45%|████▍     | 127/285 [04:11<04:38,  1.76s/it]predicting train subjects:  45%|████▍     | 128/285 [04:13<04:40,  1.79s/it]predicting train subjects:  45%|████▌     | 129/285 [04:14<04:29,  1.73s/it]predicting train subjects:  46%|████▌     | 130/285 [04:16<04:19,  1.68s/it]predicting train subjects:  46%|████▌     | 131/285 [04:18<04:15,  1.66s/it]predicting train subjects:  46%|████▋     | 132/285 [04:19<04:17,  1.68s/it]predicting train subjects:  47%|████▋     | 133/285 [04:21<04:10,  1.65s/it]predicting train subjects:  47%|████▋     | 134/285 [04:22<04:06,  1.63s/it]predicting train subjects:  47%|████▋     | 135/285 [04:24<04:01,  1.61s/it]predicting train subjects:  48%|████▊     | 136/285 [04:26<03:57,  1.59s/it]predicting train subjects:  48%|████▊     | 137/285 [04:28<04:12,  1.71s/it]predicting train subjects:  48%|████▊     | 138/285 [04:29<04:07,  1.68s/it]predicting train subjects:  49%|████▉     | 139/285 [04:31<04:11,  1.72s/it]predicting train subjects:  49%|████▉     | 140/285 [04:33<04:15,  1.76s/it]predicting train subjects:  49%|████▉     | 141/285 [04:35<04:11,  1.75s/it]predicting train subjects:  50%|████▉     | 142/285 [04:36<04:07,  1.73s/it]predicting train subjects:  50%|█████     | 143/285 [04:38<04:06,  1.73s/it]predicting train subjects:  51%|█████     | 144/285 [04:40<04:05,  1.74s/it]predicting train subjects:  51%|█████     | 145/285 [04:41<04:01,  1.72s/it]predicting train subjects:  51%|█████     | 146/285 [04:43<04:07,  1.78s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:45<03:59,  1.73s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:47<04:00,  1.76s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:49<04:09,  1.83s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:50<04:03,  1.80s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:52<03:57,  1.77s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:54<03:53,  1.76s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:56<03:49,  1.74s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:57<03:52,  1.78s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:59<03:49,  1.77s/it]predicting train subjects:  55%|█████▍    | 156/285 [05:01<03:53,  1.81s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:03<03:49,  1.80s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:05<03:50,  1.82s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:07<03:51,  1.84s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:09<03:53,  1.87s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:11<03:56,  1.91s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:12<03:55,  1.91s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:15<03:57,  1.95s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:16<03:48,  1.88s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:18<03:44,  1.87s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:20<03:48,  1.92s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:22<03:48,  1.94s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:24<03:36,  1.85s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:25<03:29,  1.81s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:27<03:22,  1.76s/it]predicting train subjects:  60%|██████    | 171/285 [05:29<03:21,  1.77s/it]predicting train subjects:  60%|██████    | 172/285 [05:31<03:25,  1.81s/it]predicting train subjects:  61%|██████    | 173/285 [05:32<03:17,  1.77s/it]predicting train subjects:  61%|██████    | 174/285 [05:34<03:08,  1.70s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:36<03:15,  1.77s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:38<03:17,  1.81s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:39<03:04,  1.71s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:41<03:03,  1.71s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:43<03:06,  1.76s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:45<03:13,  1.84s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:47<03:18,  1.91s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:49<03:19,  1.94s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:51<03:11,  1.88s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:53<03:05,  1.84s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:54<02:56,  1.77s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:56<03:06,  1.88s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:58<03:08,  1.92s/it]predicting train subjects:  66%|██████▌   | 188/285 [06:00<03:09,  1.95s/it]predicting train subjects:  66%|██████▋   | 189/285 [06:02<02:55,  1.83s/it]predicting train subjects:  67%|██████▋   | 190/285 [06:03<02:44,  1.73s/it]predicting train subjects:  67%|██████▋   | 191/285 [06:05<02:46,  1.77s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:07<02:48,  1.82s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:09<02:40,  1.75s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:11<02:41,  1.77s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:12<02:40,  1.79s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:15<02:48,  1.90s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:17<03:00,  2.05s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:19<03:03,  2.10s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:21<02:46,  1.93s/it]predicting train subjects:  70%|███████   | 200/285 [06:22<02:40,  1.89s/it]predicting train subjects:  71%|███████   | 201/285 [06:25<02:50,  2.03s/it]predicting train subjects:  71%|███████   | 202/285 [06:27<02:46,  2.00s/it]predicting train subjects:  71%|███████   | 203/285 [06:29<02:46,  2.03s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:31<02:35,  1.92s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:32<02:23,  1.80s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:34<02:19,  1.77s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:36<02:24,  1.86s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:38<02:25,  1.89s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:40<02:20,  1.84s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:41<02:08,  1.72s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:42<02:00,  1.63s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:44<01:58,  1.63s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:46<01:56,  1.62s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:47<01:51,  1.56s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:49<01:55,  1.64s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:50<01:49,  1.59s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:52<01:55,  1.70s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:54<01:57,  1.75s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:56<01:56,  1.77s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:57<01:48,  1.67s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:59<01:42,  1.60s/it]predicting train subjects:  78%|███████▊  | 222/285 [07:01<01:44,  1.65s/it]predicting train subjects:  78%|███████▊  | 223/285 [07:02<01:39,  1.60s/it]predicting train subjects:  79%|███████▊  | 224/285 [07:04<01:36,  1.58s/it]predicting train subjects:  79%|███████▉  | 225/285 [07:05<01:31,  1.53s/it]predicting train subjects:  79%|███████▉  | 226/285 [07:07<01:36,  1.63s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:09<01:38,  1.70s/it]predicting train subjects:  80%|████████  | 228/285 [07:11<01:39,  1.75s/it]predicting train subjects:  80%|████████  | 229/285 [07:12<01:37,  1.74s/it]predicting train subjects:  81%|████████  | 230/285 [07:14<01:30,  1.65s/it]predicting train subjects:  81%|████████  | 231/285 [07:15<01:26,  1.60s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:17<01:26,  1.63s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:18<01:21,  1.57s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:20<01:24,  1.65s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:22<01:19,  1.59s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:24<01:22,  1.68s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:25<01:22,  1.72s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:27<01:21,  1.74s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:29<01:19,  1.72s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:30<01:14,  1.65s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:32<01:10,  1.60s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:33<01:06,  1.55s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:35<01:03,  1.51s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:37<01:06,  1.61s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:38<01:02,  1.55s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:40<01:04,  1.66s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:42<01:05,  1.73s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:43<01:03,  1.73s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:45<00:59,  1.64s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:46<00:56,  1.60s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:48<00:52,  1.54s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:49<00:49,  1.52s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:51<00:51,  1.62s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:53<00:51,  1.68s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:55<00:50,  1.69s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:56<00:46,  1.62s/it]predicting train subjects:  90%|█████████ | 257/285 [07:58<00:44,  1.59s/it]predicting train subjects:  91%|█████████ | 258/285 [08:00<00:45,  1.68s/it]predicting train subjects:  91%|█████████ | 259/285 [08:01<00:44,  1.70s/it]predicting train subjects:  91%|█████████ | 260/285 [08:03<00:40,  1.63s/it]predicting train subjects:  92%|█████████▏| 261/285 [08:04<00:38,  1.59s/it]predicting train subjects:  92%|█████████▏| 262/285 [08:06<00:35,  1.54s/it]predicting train subjects:  92%|█████████▏| 263/285 [08:07<00:33,  1.53s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:09<00:34,  1.63s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:11<00:34,  1.72s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:12<00:31,  1.65s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:14<00:28,  1.59s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:16<00:28,  1.67s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:17<00:26,  1.68s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:19<00:24,  1.62s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:20<00:22,  1.59s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:22<00:20,  1.60s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:23<00:18,  1.53s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:25<00:16,  1.52s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:27<00:16,  1.62s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:29<00:15,  1.70s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:30<00:13,  1.63s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:32<00:11,  1.59s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:33<00:09,  1.62s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:35<00:07,  1.59s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:36<00:06,  1.56s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:38<00:04,  1.53s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:40<00:03,  1.64s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:42<00:01,  1.73s/it]predicting train subjects: 100%|██████████| 285/285 [08:43<00:00,  1.74s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:20,  1.55s/it]Loading train:   1%|          | 2/285 [00:02<06:45,  1.43s/it]Loading train:   1%|          | 3/285 [00:04<06:39,  1.42s/it]Loading train:   1%|▏         | 4/285 [00:05<05:56,  1.27s/it]Loading train:   2%|▏         | 5/285 [00:06<06:06,  1.31s/it]Loading train:   2%|▏         | 6/285 [00:07<05:51,  1.26s/it]Loading train:   2%|▏         | 7/285 [00:09<06:09,  1.33s/it]Loading train:   3%|▎         | 8/285 [00:10<05:51,  1.27s/it]Loading train:   3%|▎         | 9/285 [00:11<06:16,  1.36s/it]Loading train:   4%|▎         | 10/285 [00:12<05:48,  1.27s/it]Loading train:   4%|▍         | 11/285 [00:13<05:13,  1.14s/it]Loading train:   4%|▍         | 12/285 [00:14<04:58,  1.09s/it]Loading train:   5%|▍         | 13/285 [00:15<04:44,  1.05s/it]Loading train:   5%|▍         | 14/285 [00:16<04:40,  1.03s/it]Loading train:   5%|▌         | 15/285 [00:17<04:33,  1.01s/it]Loading train:   6%|▌         | 16/285 [00:18<04:34,  1.02s/it]Loading train:   6%|▌         | 17/285 [00:19<04:33,  1.02s/it]Loading train:   6%|▋         | 18/285 [00:20<04:27,  1.00s/it]Loading train:   7%|▋         | 19/285 [00:21<04:13,  1.05it/s]Loading train:   7%|▋         | 20/285 [00:22<04:04,  1.08it/s]Loading train:   7%|▋         | 21/285 [00:23<04:15,  1.03it/s]Loading train:   8%|▊         | 22/285 [00:24<03:59,  1.10it/s]Loading train:   8%|▊         | 23/285 [00:24<03:54,  1.12it/s]Loading train:   8%|▊         | 24/285 [00:25<03:50,  1.13it/s]Loading train:   9%|▉         | 25/285 [00:26<03:52,  1.12it/s]Loading train:   9%|▉         | 26/285 [00:27<03:58,  1.09it/s]Loading train:   9%|▉         | 27/285 [00:28<03:42,  1.16it/s]Loading train:  10%|▉         | 28/285 [00:29<03:46,  1.13it/s]Loading train:  10%|█         | 29/285 [00:30<03:42,  1.15it/s]Loading train:  11%|█         | 30/285 [00:31<03:51,  1.10it/s]Loading train:  11%|█         | 31/285 [00:32<03:49,  1.11it/s]Loading train:  11%|█         | 32/285 [00:32<03:39,  1.15it/s]Loading train:  12%|█▏        | 33/285 [00:33<03:53,  1.08it/s]Loading train:  12%|█▏        | 34/285 [00:34<03:58,  1.05it/s]Loading train:  12%|█▏        | 35/285 [00:36<04:17,  1.03s/it]Loading train:  13%|█▎        | 36/285 [00:37<04:07,  1.01it/s]Loading train:  13%|█▎        | 37/285 [00:37<03:55,  1.05it/s]Loading train:  13%|█▎        | 38/285 [00:38<03:51,  1.07it/s]Loading train:  14%|█▎        | 39/285 [00:39<03:41,  1.11it/s]Loading train:  14%|█▍        | 40/285 [00:40<03:47,  1.08it/s]Loading train:  14%|█▍        | 41/285 [00:41<03:43,  1.09it/s]Loading train:  15%|█▍        | 42/285 [00:42<03:34,  1.13it/s]Loading train:  15%|█▌        | 43/285 [00:43<03:41,  1.09it/s]Loading train:  15%|█▌        | 44/285 [00:44<04:22,  1.09s/it]Loading train:  16%|█▌        | 45/285 [00:45<04:05,  1.02s/it]Loading train:  16%|█▌        | 46/285 [00:46<04:05,  1.03s/it]Loading train:  16%|█▋        | 47/285 [00:47<03:51,  1.03it/s]Loading train:  17%|█▋        | 48/285 [00:48<03:48,  1.04it/s]Loading train:  17%|█▋        | 49/285 [00:49<03:51,  1.02it/s]Loading train:  18%|█▊        | 50/285 [00:50<03:46,  1.04it/s]Loading train:  18%|█▊        | 51/285 [00:51<03:45,  1.04it/s]Loading train:  18%|█▊        | 52/285 [00:52<03:34,  1.09it/s]Loading train:  19%|█▊        | 53/285 [00:53<03:30,  1.10it/s]Loading train:  19%|█▉        | 54/285 [00:54<03:31,  1.09it/s]Loading train:  19%|█▉        | 55/285 [00:54<03:26,  1.12it/s]Loading train:  20%|█▉        | 56/285 [00:55<03:27,  1.11it/s]Loading train:  20%|██        | 57/285 [00:56<03:24,  1.12it/s]Loading train:  20%|██        | 58/285 [00:57<03:21,  1.13it/s]Loading train:  21%|██        | 59/285 [00:58<03:32,  1.07it/s]Loading train:  21%|██        | 60/285 [00:59<03:31,  1.06it/s]Loading train:  21%|██▏       | 61/285 [01:00<03:22,  1.11it/s]Loading train:  22%|██▏       | 62/285 [01:01<03:28,  1.07it/s]Loading train:  22%|██▏       | 63/285 [01:02<03:22,  1.10it/s]Loading train:  22%|██▏       | 64/285 [01:03<03:41,  1.00s/it]Loading train:  23%|██▎       | 65/285 [01:04<04:12,  1.15s/it]Loading train:  23%|██▎       | 66/285 [01:06<04:13,  1.16s/it]Loading train:  24%|██▎       | 67/285 [01:06<03:48,  1.05s/it]Loading train:  24%|██▍       | 68/285 [01:07<03:30,  1.03it/s]Loading train:  24%|██▍       | 69/285 [01:08<03:20,  1.08it/s]Loading train:  25%|██▍       | 70/285 [01:09<03:15,  1.10it/s]Loading train:  25%|██▍       | 71/285 [01:10<03:09,  1.13it/s]Loading train:  25%|██▌       | 72/285 [01:10<02:55,  1.22it/s]Loading train:  26%|██▌       | 73/285 [01:11<02:53,  1.22it/s]Loading train:  26%|██▌       | 74/285 [01:12<02:47,  1.26it/s]Loading train:  26%|██▋       | 75/285 [01:13<02:44,  1.27it/s]Loading train:  27%|██▋       | 76/285 [01:14<02:47,  1.25it/s]Loading train:  27%|██▋       | 77/285 [01:14<02:39,  1.31it/s]Loading train:  27%|██▋       | 78/285 [01:15<02:35,  1.33it/s]Loading train:  28%|██▊       | 79/285 [01:16<02:39,  1.30it/s]Loading train:  28%|██▊       | 80/285 [01:17<02:43,  1.25it/s]Loading train:  28%|██▊       | 81/285 [01:17<02:40,  1.27it/s]Loading train:  29%|██▉       | 82/285 [01:18<02:47,  1.21it/s]Loading train:  29%|██▉       | 83/285 [01:19<02:48,  1.20it/s]Loading train:  29%|██▉       | 84/285 [01:20<02:42,  1.24it/s]Loading train:  30%|██▉       | 85/285 [01:21<02:49,  1.18it/s]Loading train:  30%|███       | 86/285 [01:22<02:57,  1.12it/s]Loading train:  31%|███       | 87/285 [01:23<02:55,  1.13it/s]Loading train:  31%|███       | 88/285 [01:23<02:45,  1.19it/s]Loading train:  31%|███       | 89/285 [01:24<02:51,  1.14it/s]Loading train:  32%|███▏      | 90/285 [01:25<02:57,  1.10it/s]Loading train:  32%|███▏      | 91/285 [01:26<02:44,  1.18it/s]Loading train:  32%|███▏      | 92/285 [01:27<02:47,  1.15it/s]Loading train:  33%|███▎      | 93/285 [01:28<02:47,  1.14it/s]Loading train:  33%|███▎      | 94/285 [01:29<02:45,  1.15it/s]Loading train:  33%|███▎      | 95/285 [01:30<02:44,  1.16it/s]Loading train:  34%|███▎      | 96/285 [01:30<02:39,  1.19it/s]Loading train:  34%|███▍      | 97/285 [01:31<02:43,  1.15it/s]Loading train:  34%|███▍      | 98/285 [01:32<02:48,  1.11it/s]Loading train:  35%|███▍      | 99/285 [01:33<02:50,  1.09it/s]Loading train:  35%|███▌      | 100/285 [01:34<02:48,  1.09it/s]Loading train:  35%|███▌      | 101/285 [01:35<02:41,  1.14it/s]Loading train:  36%|███▌      | 102/285 [01:36<02:37,  1.16it/s]Loading train:  36%|███▌      | 103/285 [01:37<02:28,  1.23it/s]Loading train:  36%|███▋      | 104/285 [01:37<02:26,  1.24it/s]Loading train:  37%|███▋      | 105/285 [01:38<02:25,  1.23it/s]Loading train:  37%|███▋      | 106/285 [01:39<02:21,  1.27it/s]Loading train:  38%|███▊      | 107/285 [01:40<02:23,  1.24it/s]Loading train:  38%|███▊      | 108/285 [01:40<02:18,  1.28it/s]Loading train:  38%|███▊      | 109/285 [01:41<02:26,  1.20it/s]Loading train:  39%|███▊      | 110/285 [01:42<02:29,  1.17it/s]Loading train:  39%|███▉      | 111/285 [01:43<02:30,  1.15it/s]Loading train:  39%|███▉      | 112/285 [01:44<02:33,  1.13it/s]Loading train:  40%|███▉      | 113/285 [01:45<02:32,  1.13it/s]Loading train:  40%|████      | 114/285 [01:46<02:28,  1.15it/s]Loading train:  40%|████      | 115/285 [01:47<02:28,  1.15it/s]Loading train:  41%|████      | 116/285 [01:48<02:26,  1.16it/s]Loading train:  41%|████      | 117/285 [01:48<02:16,  1.23it/s]Loading train:  41%|████▏     | 118/285 [01:49<02:18,  1.21it/s]Loading train:  42%|████▏     | 119/285 [01:50<02:22,  1.17it/s]Loading train:  42%|████▏     | 120/285 [01:51<02:24,  1.14it/s]Loading train:  42%|████▏     | 121/285 [01:52<02:40,  1.02it/s]Loading train:  43%|████▎     | 122/285 [01:53<02:47,  1.03s/it]Loading train:  43%|████▎     | 123/285 [01:55<02:54,  1.08s/it]Loading train:  44%|████▎     | 124/285 [01:55<02:43,  1.02s/it]Loading train:  44%|████▍     | 125/285 [01:56<02:32,  1.05it/s]Loading train:  44%|████▍     | 126/285 [01:57<02:26,  1.08it/s]Loading train:  45%|████▍     | 127/285 [01:58<02:16,  1.16it/s]Loading train:  45%|████▍     | 128/285 [01:59<02:12,  1.19it/s]Loading train:  45%|████▌     | 129/285 [01:59<02:07,  1.22it/s]Loading train:  46%|████▌     | 130/285 [02:00<02:00,  1.28it/s]Loading train:  46%|████▌     | 131/285 [02:01<01:57,  1.31it/s]Loading train:  46%|████▋     | 132/285 [02:01<01:53,  1.35it/s]Loading train:  47%|████▋     | 133/285 [02:02<01:51,  1.36it/s]Loading train:  47%|████▋     | 134/285 [02:03<01:47,  1.40it/s]Loading train:  47%|████▋     | 135/285 [02:04<01:48,  1.38it/s]Loading train:  48%|████▊     | 136/285 [02:04<01:45,  1.41it/s]Loading train:  48%|████▊     | 137/285 [02:05<01:46,  1.38it/s]Loading train:  48%|████▊     | 138/285 [02:06<01:47,  1.37it/s]Loading train:  49%|████▉     | 139/285 [02:07<01:50,  1.32it/s]Loading train:  49%|████▉     | 140/285 [02:07<01:50,  1.32it/s]Loading train:  49%|████▉     | 141/285 [02:08<01:51,  1.29it/s]Loading train:  50%|████▉     | 142/285 [02:09<01:51,  1.29it/s]Loading train:  50%|█████     | 143/285 [02:10<01:48,  1.31it/s]Loading train:  51%|█████     | 144/285 [02:10<01:49,  1.29it/s]Loading train:  51%|█████     | 145/285 [02:11<01:47,  1.30it/s]Loading train:  51%|█████     | 146/285 [02:12<01:46,  1.30it/s]Loading train:  52%|█████▏    | 147/285 [02:13<01:49,  1.26it/s]Loading train:  52%|█████▏    | 148/285 [02:14<01:52,  1.22it/s]Loading train:  52%|█████▏    | 149/285 [02:14<01:46,  1.28it/s]Loading train:  53%|█████▎    | 150/285 [02:15<01:44,  1.30it/s]Loading train:  53%|█████▎    | 151/285 [02:16<01:42,  1.31it/s]Loading train:  53%|█████▎    | 152/285 [02:17<01:42,  1.30it/s]Loading train:  54%|█████▎    | 153/285 [02:17<01:38,  1.33it/s]Loading train:  54%|█████▍    | 154/285 [02:18<01:42,  1.28it/s]Loading train:  54%|█████▍    | 155/285 [02:19<01:38,  1.32it/s]Loading train:  55%|█████▍    | 156/285 [02:20<01:39,  1.29it/s]Loading train:  55%|█████▌    | 157/285 [02:20<01:36,  1.32it/s]Loading train:  55%|█████▌    | 158/285 [02:21<01:37,  1.30it/s]Loading train:  56%|█████▌    | 159/285 [02:22<01:35,  1.32it/s]Loading train:  56%|█████▌    | 160/285 [02:23<01:35,  1.31it/s]Loading train:  56%|█████▋    | 161/285 [02:24<01:36,  1.29it/s]Loading train:  57%|█████▋    | 162/285 [02:24<01:37,  1.26it/s]Loading train:  57%|█████▋    | 163/285 [02:25<01:38,  1.24it/s]Loading train:  58%|█████▊    | 164/285 [02:26<01:39,  1.21it/s]Loading train:  58%|█████▊    | 165/285 [02:27<01:37,  1.24it/s]Loading train:  58%|█████▊    | 166/285 [02:28<01:38,  1.21it/s]Loading train:  59%|█████▊    | 167/285 [02:29<01:37,  1.21it/s]Loading train:  59%|█████▉    | 168/285 [02:29<01:33,  1.25it/s]Loading train:  59%|█████▉    | 169/285 [02:30<01:32,  1.25it/s]Loading train:  60%|█████▉    | 170/285 [02:31<01:31,  1.26it/s]Loading train:  60%|██████    | 171/285 [02:32<01:30,  1.26it/s]Loading train:  60%|██████    | 172/285 [02:32<01:26,  1.31it/s]Loading train:  61%|██████    | 173/285 [02:33<01:22,  1.36it/s]Loading train:  61%|██████    | 174/285 [02:34<01:20,  1.38it/s]Loading train:  61%|██████▏   | 175/285 [02:35<01:22,  1.33it/s]Loading train:  62%|██████▏   | 176/285 [02:35<01:24,  1.28it/s]Loading train:  62%|██████▏   | 177/285 [02:36<01:23,  1.29it/s]Loading train:  62%|██████▏   | 178/285 [02:37<01:23,  1.27it/s]Loading train:  63%|██████▎   | 179/285 [02:38<01:22,  1.29it/s]Loading train:  63%|██████▎   | 180/285 [02:39<01:27,  1.20it/s]Loading train:  64%|██████▎   | 181/285 [02:40<01:27,  1.19it/s]Loading train:  64%|██████▍   | 182/285 [02:40<01:29,  1.16it/s]Loading train:  64%|██████▍   | 183/285 [02:41<01:23,  1.22it/s]Loading train:  65%|██████▍   | 184/285 [02:42<01:20,  1.25it/s]Loading train:  65%|██████▍   | 185/285 [02:43<01:16,  1.31it/s]Loading train:  65%|██████▌   | 186/285 [02:44<01:19,  1.25it/s]Loading train:  66%|██████▌   | 187/285 [02:44<01:22,  1.19it/s]Loading train:  66%|██████▌   | 188/285 [02:45<01:23,  1.16it/s]Loading train:  66%|██████▋   | 189/285 [02:46<01:19,  1.21it/s]Loading train:  67%|██████▋   | 190/285 [02:47<01:15,  1.26it/s]Loading train:  67%|██████▋   | 191/285 [02:48<01:16,  1.24it/s]Loading train:  67%|██████▋   | 192/285 [02:48<01:15,  1.24it/s]Loading train:  68%|██████▊   | 193/285 [02:49<01:12,  1.27it/s]Loading train:  68%|██████▊   | 194/285 [02:50<01:11,  1.28it/s]Loading train:  68%|██████▊   | 195/285 [02:51<01:07,  1.33it/s]Loading train:  69%|██████▉   | 196/285 [02:52<01:12,  1.23it/s]Loading train:  69%|██████▉   | 197/285 [02:53<01:13,  1.20it/s]Loading train:  69%|██████▉   | 198/285 [02:53<01:14,  1.17it/s]Loading train:  70%|██████▉   | 199/285 [02:54<01:09,  1.24it/s]Loading train:  70%|███████   | 200/285 [02:55<01:07,  1.26it/s]Loading train:  71%|███████   | 201/285 [02:56<01:09,  1.21it/s]Loading train:  71%|███████   | 202/285 [02:57<01:10,  1.18it/s]Loading train:  71%|███████   | 203/285 [02:58<01:09,  1.17it/s]Loading train:  72%|███████▏  | 204/285 [02:58<01:04,  1.25it/s]Loading train:  72%|███████▏  | 205/285 [02:59<01:03,  1.27it/s]Loading train:  72%|███████▏  | 206/285 [03:00<00:59,  1.32it/s]Loading train:  73%|███████▎  | 207/285 [03:01<01:02,  1.25it/s]Loading train:  73%|███████▎  | 208/285 [03:02<01:05,  1.18it/s]Loading train:  73%|███████▎  | 209/285 [03:02<01:06,  1.14it/s]Loading train:  74%|███████▎  | 210/285 [03:03<01:00,  1.24it/s]Loading train:  74%|███████▍  | 211/285 [03:04<00:57,  1.29it/s]Loading train:  74%|███████▍  | 212/285 [03:05<00:58,  1.24it/s]Loading train:  75%|███████▍  | 213/285 [03:06<00:59,  1.20it/s]Loading train:  75%|███████▌  | 214/285 [03:06<00:56,  1.26it/s]Loading train:  75%|███████▌  | 215/285 [03:07<00:58,  1.20it/s]Loading train:  76%|███████▌  | 216/285 [03:08<00:54,  1.27it/s]Loading train:  76%|███████▌  | 217/285 [03:09<00:55,  1.23it/s]Loading train:  76%|███████▋  | 218/285 [03:10<00:55,  1.20it/s]Loading train:  77%|███████▋  | 219/285 [03:11<00:56,  1.18it/s]Loading train:  77%|███████▋  | 220/285 [03:11<00:52,  1.25it/s]Loading train:  78%|███████▊  | 221/285 [03:12<00:51,  1.24it/s]Loading train:  78%|███████▊  | 222/285 [03:13<00:51,  1.21it/s]Loading train:  78%|███████▊  | 223/285 [03:14<00:49,  1.26it/s]Loading train:  79%|███████▊  | 224/285 [03:14<00:45,  1.34it/s]Loading train:  79%|███████▉  | 225/285 [03:15<00:42,  1.42it/s]Loading train:  79%|███████▉  | 226/285 [03:16<00:43,  1.35it/s]Loading train:  80%|███████▉  | 227/285 [03:17<00:46,  1.26it/s]Loading train:  80%|████████  | 228/285 [03:18<00:47,  1.20it/s]Loading train:  80%|████████  | 229/285 [03:18<00:46,  1.22it/s]Loading train:  81%|████████  | 230/285 [03:19<00:43,  1.27it/s]Loading train:  81%|████████  | 231/285 [03:20<00:41,  1.30it/s]Loading train:  81%|████████▏ | 232/285 [03:21<00:41,  1.27it/s]Loading train:  82%|████████▏ | 233/285 [03:21<00:40,  1.29it/s]Loading train:  82%|████████▏ | 234/285 [03:22<00:42,  1.19it/s]Loading train:  82%|████████▏ | 235/285 [03:23<00:40,  1.23it/s]Loading train:  83%|████████▎ | 236/285 [03:24<00:41,  1.19it/s]Loading train:  83%|████████▎ | 237/285 [03:25<00:40,  1.18it/s]Loading train:  84%|████████▎ | 238/285 [03:26<00:40,  1.16it/s]Loading train:  84%|████████▍ | 239/285 [03:27<00:38,  1.18it/s]Loading train:  84%|████████▍ | 240/285 [03:27<00:36,  1.23it/s]Loading train:  85%|████████▍ | 241/285 [03:28<00:34,  1.26it/s]Loading train:  85%|████████▍ | 242/285 [03:29<00:33,  1.30it/s]Loading train:  85%|████████▌ | 243/285 [03:29<00:31,  1.34it/s]Loading train:  86%|████████▌ | 244/285 [03:30<00:32,  1.24it/s]Loading train:  86%|████████▌ | 245/285 [03:31<00:31,  1.28it/s]Loading train:  86%|████████▋ | 246/285 [03:32<00:31,  1.22it/s]Loading train:  87%|████████▋ | 247/285 [03:33<00:31,  1.22it/s]Loading train:  87%|████████▋ | 248/285 [03:34<00:31,  1.17it/s]Loading train:  87%|████████▋ | 249/285 [03:35<00:30,  1.19it/s]Loading train:  88%|████████▊ | 250/285 [03:35<00:28,  1.21it/s]Loading train:  88%|████████▊ | 251/285 [03:36<00:27,  1.22it/s]Loading train:  88%|████████▊ | 252/285 [03:37<00:25,  1.28it/s]Loading train:  89%|████████▉ | 253/285 [03:38<00:27,  1.16it/s]Loading train:  89%|████████▉ | 254/285 [03:39<00:26,  1.15it/s]Loading train:  89%|████████▉ | 255/285 [03:40<00:25,  1.18it/s]Loading train:  90%|████████▉ | 256/285 [03:40<00:23,  1.25it/s]Loading train:  90%|█████████ | 257/285 [03:41<00:21,  1.31it/s]Loading train:  91%|█████████ | 258/285 [03:42<00:21,  1.27it/s]Loading train:  91%|█████████ | 259/285 [03:43<00:20,  1.29it/s]Loading train:  91%|█████████ | 260/285 [03:43<00:19,  1.30it/s]Loading train:  92%|█████████▏| 261/285 [03:44<00:17,  1.34it/s]Loading train:  92%|█████████▏| 262/285 [03:45<00:16,  1.41it/s]Loading train:  92%|█████████▏| 263/285 [03:45<00:15,  1.43it/s]Loading train:  93%|█████████▎| 264/285 [03:46<00:15,  1.34it/s]Loading train:  93%|█████████▎| 265/285 [03:47<00:16,  1.23it/s]Loading train:  93%|█████████▎| 266/285 [03:48<00:15,  1.23it/s]Loading train:  94%|█████████▎| 267/285 [03:49<00:14,  1.22it/s]Loading train:  94%|█████████▍| 268/285 [03:50<00:14,  1.17it/s]Loading train:  94%|█████████▍| 269/285 [03:51<00:13,  1.19it/s]Loading train:  95%|█████████▍| 270/285 [03:51<00:12,  1.24it/s]Loading train:  95%|█████████▌| 271/285 [03:52<00:10,  1.31it/s]Loading train:  95%|█████████▌| 272/285 [03:53<00:10,  1.27it/s]Loading train:  96%|█████████▌| 273/285 [03:53<00:09,  1.31it/s]Loading train:  96%|█████████▌| 274/285 [03:54<00:08,  1.33it/s]Loading train:  96%|█████████▋| 275/285 [03:55<00:07,  1.27it/s]Loading train:  97%|█████████▋| 276/285 [03:56<00:07,  1.23it/s]Loading train:  97%|█████████▋| 277/285 [03:57<00:06,  1.25it/s]Loading train:  98%|█████████▊| 278/285 [03:57<00:05,  1.27it/s]Loading train:  98%|█████████▊| 279/285 [03:58<00:04,  1.23it/s]Loading train:  98%|█████████▊| 280/285 [03:59<00:04,  1.23it/s]Loading train:  99%|█████████▊| 281/285 [04:00<00:03,  1.25it/s]Loading train:  99%|█████████▉| 282/285 [04:01<00:02,  1.29it/s]Loading train:  99%|█████████▉| 283/285 [04:01<00:01,  1.26it/s]Loading train: 100%|█████████▉| 284/285 [04:02<00:00,  1.26it/s]Loading train: 100%|██████████| 285/285 [04:03<00:00,  1.24it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:  11%|█         | 30/285 [00:00<00:00, 293.15it/s]concatenating: train:  22%|██▏       | 62/285 [00:00<00:00, 299.26it/s]concatenating: train:  33%|███▎      | 95/285 [00:00<00:00, 306.96it/s]concatenating: train:  45%|████▌     | 129/285 [00:00<00:00, 315.57it/s]concatenating: train:  57%|█████▋    | 162/285 [00:00<00:00, 318.96it/s]concatenating: train:  67%|██████▋   | 190/285 [00:00<00:00, 290.68it/s]concatenating: train:  79%|███████▉  | 225/285 [00:00<00:00, 305.64it/s]concatenating: train:  93%|█████████▎| 265/285 [00:00<00:00, 328.05it/s]concatenating: train: 100%|██████████| 285/285 [00:00<00:00, 330.36it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.21s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.18s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.14s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 412.19it/s]2019-07-10 22:16:39.268339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-10 22:16:39.268447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-10 22:16:39.268465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-10 22:16:39.268474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-10 22:16:39.268886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.63it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.65it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  6.39it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  8.19it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:03,  9.04it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  7.92it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02, 10.20it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02, 10.69it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:01<00:02,  8.82it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:01<00:01, 10.95it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01, 11.40it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01, 11.44it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:02<00:01,  8.65it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:02<00:00, 10.68it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00, 10.72it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 10.97it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  8.72it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 12.40it/s]
Epoch 00044: val_mDice did not improve from 0.63787
Restoring model weights from the end of the best epoch
Epoch 00044: early stopping
{'val_loss': [0.6461195785906062, 0.46760754079126116, 0.5039704758361732, 0.43742790501876916, 0.44243196468779494, 0.4988789358618539, 0.49127081153113084, 0.47378707131859976, 0.4715718184103513, 0.4789578701530755, 0.45607516119600006, 0.4896765804157577, 0.49517986594631686, 0.525337585190821, 0.47034154657545035, 0.5404548794863611, 0.5223365709102353, 0.49399343615803637, 0.4867569304711326, 0.48100573490451837, 0.5662774147268114, 0.49940925237186795, 0.48426573369756093, 0.4550365312805389, 0.48961777094356174, 0.46360349555255315, 0.5268538570936832, 0.49387148971664174, 0.4753059058882005, 0.5441811950513105, 0.4665735330661582, 0.5106318100204681, 0.4657155874721165, 0.47309950909801035, 0.4576356137931014, 0.5016694914695271, 0.539673343717053, 0.5201959223720615, 0.4642206400466365, 0.4966657221650278, 0.5367112256295188, 0.5373495400950895, 0.5153619104257509, 0.4830062116324569], 'val_acc': [0.926636736819198, 0.931467130197493, 0.9374318266048112, 0.9440411086189014, 0.9454625375443997, 0.9460348650063882, 0.9531441081169597, 0.9550159670121177, 0.9519230849916043, 0.9543217686967477, 0.9553712959396107, 0.9535903947313404, 0.9552039750461472, 0.9542845660747763, 0.9517164959587865, 0.9544106002626472, 0.9537825188157278, 0.9530780058999301, 0.9537102023982469, 0.9550118143332071, 0.9550924058067066, 0.9542081422645953, 0.9539436514817137, 0.9535717631185521, 0.948770307961789, 0.9546192861136111, 0.9543837198998009, 0.9534643512198379, 0.9528796716109335, 0.953701957644031, 0.9529519870294539, 0.955100664213383, 0.9543589466776927, 0.952342482252494, 0.9521048811560903, 0.9544829230068782, 0.952619359812923, 0.9522701738266971, 0.9530883381486605, 0.951980936127668, 0.9523982575485826, 0.9520098410505157, 0.9547886721914707, 0.9536854198525072], 'val_mDice': [0.5203238607451902, 0.619196619401431, 0.6098584729199968, 0.6378726166719831, 0.6365123487717612, 0.6081117987632751, 0.6150899422901303, 0.6229134038839926, 0.6186111246407365, 0.6232648551797068, 0.6327880627616158, 0.6076891109264096, 0.6129053028602174, 0.5946705347998849, 0.6205303495822672, 0.6137490908526841, 0.6110065333004104, 0.6091521798565401, 0.6169906794691885, 0.6197300583290655, 0.5950693358256164, 0.6126594603394663, 0.6198046290674689, 0.631247930686567, 0.6082289365416799, 0.6260633109002139, 0.6034378302829891, 0.6128735905253021, 0.6213343762818662, 0.5896270255136756, 0.6209593075613736, 0.6137455468737213, 0.6243559098776492, 0.6172218615782328, 0.6264112914740706, 0.6120688152712817, 0.5837442402067131, 0.5950845080380999, 0.6236062366203223, 0.6051462299330941, 0.5962010428892167, 0.585994138397984, 0.6029410122493126, 0.6162966856077396], 'loss': [1.821710175385851, 0.5188491771660185, 0.43167786891570403, 0.3961125798529513, 0.3742603647505027, 0.36045215628932853, 0.34645481398147043, 0.33863840937568995, 0.32837199918728144, 0.32037975002553143, 0.3157831483690134, 0.3103480830859219, 0.30500601707872926, 0.3008444119360665, 0.29739499426629507, 0.29471496490635946, 0.28984338135366366, 0.2874183117820705, 0.2832446242672745, 0.282019964234319, 0.2802099243734054, 0.2768869826339973, 0.27479982268322684, 0.27391815667292385, 0.27154229753002235, 0.2707860278061328, 0.26789184301372554, 0.2670427704356048, 0.266135714922613, 0.2635095379063782, 0.2638839980897077, 0.2601777119114147, 0.2586931739667747, 0.25819853308686347, 0.25710796991417034, 0.2552211487959052, 0.2555958165607449, 0.2528856325306006, 0.25683980414722096, 0.251360070599261, 0.25088559852096487, 0.24856511163209027, 0.24878191424477017, 0.24943675160291154], 'acc': [0.5854179157940048, 0.9065766496327466, 0.9138598613642664, 0.920809629341855, 0.9265805375477982, 0.9321031619225911, 0.9388826311261141, 0.945181052452741, 0.9480225690718369, 0.9492539136662059, 0.9498421141189867, 0.950530637301337, 0.9509924865062445, 0.9513929460304611, 0.9516687657304478, 0.9519299464926703, 0.9524333884913276, 0.9526500535922843, 0.9529039608900483, 0.9531716857527305, 0.953368870389792, 0.9535501862875965, 0.9537762567943869, 0.9538551935423213, 0.9540074436559792, 0.954091879885984, 0.9543000843963698, 0.9544102801300655, 0.9544349741321537, 0.9546604184412008, 0.9547012056973783, 0.9549160196782327, 0.955106740180044, 0.95516414417303, 0.9551929285710533, 0.9553294263434796, 0.9553301715427517, 0.9554684018525194, 0.955276193198578, 0.9556208407331556, 0.9557325038364021, 0.9557420311946182, 0.955849848274156, 0.9558525908247174], 'mDice': [0.27560077800500316, 0.5818515123121685, 0.6363604155626116, 0.6599169605392873, 0.6748133042975258, 0.6845060520575694, 0.6940711123816984, 0.6994244922876657, 0.7065951066737561, 0.7123199741822573, 0.7157004881668673, 0.7197668742856963, 0.723674961037836, 0.7268801069189524, 0.7293695170637452, 0.7314569186582576, 0.7350985086221956, 0.7369782776297856, 0.7400542893971203, 0.7411292950043938, 0.7426064850380137, 0.7449836401720984, 0.74667025627858, 0.7473692890053955, 0.7492366975464402, 0.7497687868858746, 0.7520734704623107, 0.7526958829910821, 0.7534166991590551, 0.7554702688994397, 0.7552267157604905, 0.7580899993946503, 0.759249991535277, 0.7597065239026392, 0.7604588054051151, 0.7619753671389742, 0.7617265612047668, 0.7638535977649985, 0.7607611097461563, 0.7650938090120588, 0.7655081876021157, 0.7672508514029392, 0.7671252742168672, 0.7666492132175515]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 26, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 26, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 26, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 26, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 13, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 13, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 13, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 20, 13, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 40, 26, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 40, 26, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 40, 26, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 80, 52, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 80, 52, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 52, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 80, 52, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 10)   5410        dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 10)   40          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 10)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 80, 52, 10)   0           activation_11[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 70)   0           dropout_5[0][0]                  
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 13)   923         concatenate_7[0][0]              
==================================================================================================
Total params: 229,413
Trainable params: 54,713
Non-trainable params: 174,700
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 15s - loss: 2.7660 - acc: 0.5631 - mDice: 0.1088 - val_loss: 2.5763 - val_acc: 0.9037 - val_mDice: 0.1748

Epoch 00001: val_mDice improved from -inf to 0.17484, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 9s - loss: 0.9318 - acc: 0.8835 - mDice: 0.3827 - val_loss: 1.1707 - val_acc: 0.9101 - val_mDice: 0.4036

Epoch 00002: val_mDice improved from 0.17484 to 0.40364, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 9s - loss: 0.7213 - acc: 0.8876 - mDice: 0.4718 - val_loss: 1.0170 - val_acc: 0.9144 - val_mDice: 0.4731

Epoch 00003: val_mDice improved from 0.40364 to 0.47312, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 10s - loss: 0.6350 - acc: 0.8902 - mDice: 0.5153 - val_loss: 0.9012 - val_acc: 0.9146 - val_mDice: 0.5083

Epoch 00004: val_mDice improved from 0.47312 to 0.50829, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 9s - loss: 0.5764 - acc: 0.8923 - mDice: 0.5467 - val_loss: 0.8655 - val_acc: 0.9175 - val_mDice: 0.5262

Epoch 00005: val_mDice improved from 0.50829 to 0.52617, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 9s - loss: 0.5371 - acc: 0.8954 - mDice: 0.5694 - val_loss: 0.8714 - val_acc: 0.9163 - val_mDice: 0.5337

Epoch 00006: val_mDice improved from 0.52617 to 0.53371, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 9s - loss: 0.5070 - acc: 0.8993 - mDice: 0.5873 - val_loss: 0.8457 - val_acc: 0.9237 - val_mDice: 0.5289

Epoch 00007: val_mDice did not improve from 0.53371
Epoch 8/300
 - 9s - loss: 0.4889 - acc: 0.9044 - mDice: 0.5986 - val_loss: 0.8404 - val_acc: 0.9305 - val_mDice: 0.5429

Epoch 00008: val_mDice improved from 0.53371 to 0.54285, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 9s - loss: 0.4709 - acc: 0.9127 - mDice: 0.6096 - val_loss: 0.8302 - val_acc: 0.9352 - val_mDice: 0.5349

Epoch 00009: val_mDice did not improve from 0.54285
Epoch 10/300
 - 9s - loss: 0.4597 - acc: 0.9215 - mDice: 0.6164 - val_loss: 0.8511 - val_acc: 0.9287 - val_mDice: 0.5253

Epoch 00010: val_mDice did not improve from 0.54285
Epoch 11/300
 - 10s - loss: 0.4510 - acc: 0.9266 - mDice: 0.6219 - val_loss: 0.8286 - val_acc: 0.9372 - val_mDice: 0.5349

Epoch 00011: val_mDice did not improve from 0.54285
Epoch 12/300
 - 9s - loss: 0.4410 - acc: 0.9303 - mDice: 0.6281 - val_loss: 0.8377 - val_acc: 0.9349 - val_mDice: 0.5275

Epoch 00012: val_mDice did not improve from 0.54285
Epoch 13/300
 - 9s - loss: 0.4298 - acc: 0.9325 - mDice: 0.6352 - val_loss: 0.7896 - val_acc: 0.9245 - val_mDice: 0.5344

Epoch 00013: val_mDice did not improve from 0.54285
Epoch 14/300
 - 9s - loss: 0.4211 - acc: 0.9340 - mDice: 0.6407 - val_loss: 0.7704 - val_acc: 0.9341 - val_mDice: 0.5468

Epoch 00014: val_mDice improved from 0.54285 to 0.54682, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 9s - loss: 0.4141 - acc: 0.9350 - mDice: 0.6454 - val_loss: 0.7723 - val_acc: 0.9299 - val_mDice: 0.5411

Epoch 00015: val_mDice did not improve from 0.54682
Epoch 16/300
 - 9s - loss: 0.4073 - acc: 0.9356 - mDice: 0.6498 - val_loss: 0.7896 - val_acc: 0.9315 - val_mDice: 0.5430

Epoch 00016: val_mDice did not improve from 0.54682
Epoch 17/300
 - 9s - loss: 0.4011 - acc: 0.9364 - mDice: 0.6540 - val_loss: 0.7708 - val_acc: 0.9337 - val_mDice: 0.5548

Epoch 00017: val_mDice improved from 0.54682 to 0.55480, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 9s - loss: 0.3967 - acc: 0.9367 - mDice: 0.6570 - val_loss: 0.7831 - val_acc: 0.9264 - val_mDice: 0.5416

Epoch 00018: val_mDice did not improve from 0.55480
Epoch 19/300
 - 9s - loss: 0.3917 - acc: 0.9372 - mDice: 0.6605 - val_loss: 0.8009 - val_acc: 0.9299 - val_mDice: 0.5456

Epoch 00019: val_mDice did not improve from 0.55480
Epoch 20/300
 - 9s - loss: 0.3880 - acc: 0.9375 - mDice: 0.6629 - val_loss: 0.8043 - val_acc: 0.9224 - val_mDice: 0.5258

Epoch 00020: val_mDice did not improve from 0.55480
Epoch 21/300
 - 10s - loss: 0.3819 - acc: 0.9382 - mDice: 0.6671 - val_loss: 0.8144 - val_acc: 0.9341 - val_mDice: 0.5434

Epoch 00021: val_mDice did not improve from 0.55480
Epoch 22/300
 - 9s - loss: 0.3811 - acc: 0.9382 - mDice: 0.6676 - val_loss: 0.8024 - val_acc: 0.9362 - val_mDice: 0.5495

Epoch 00022: val_mDice did not improve from 0.55480
Epoch 23/300
 - 9s - loss: 0.3772 - acc: 0.9387 - mDice: 0.6705 - val_loss: 0.7953 - val_acc: 0.9342 - val_mDice: 0.5506

Epoch 00023: val_mDice did not improve from 0.55480
Epoch 24/300
 - 9s - loss: 0.3720 - acc: 0.9390 - mDice: 0.6739 - val_loss: 0.8063 - val_acc: 0.9327 - val_mDice: 0.5486

Epoch 00024: val_mDice did not improve from 0.55480
Epoch 25/300
 - 9s - loss: 0.3676 - acc: 0.9394 - mDice: 0.6770 - val_loss: 0.8613 - val_acc: 0.9214 - val_mDice: 0.5114

Epoch 00025: val_mDice did not improve from 0.55480
Epoch 26/300
 - 9s - loss: 0.3664 - acc: 0.9395 - mDice: 0.6779 - val_loss: 0.7974 - val_acc: 0.9279 - val_mDice: 0.5504

Epoch 00026: val_mDice did not improve from 0.55480
Epoch 27/300
 - 9s - loss: 0.3644 - acc: 0.9396 - mDice: 0.6794 - val_loss: 0.7964 - val_acc: 0.9291 - val_mDice: 0.5364

Epoch 00027: val_mDice did not improve from 0.55480
Epoch 28/300
 - 9s - loss: 0.3610 - acc: 0.9400 - mDice: 0.6817 - val_loss: 0.7978 - val_acc: 0.9351 - val_mDice: 0.5407

Epoch 00028: val_mDice did not improve from 0.55480
Epoch 29/300
 - 9s - loss: 0.3595 - acc: 0.9402 - mDice: 0.6828 - val_loss: 0.7913 - val_acc: 0.9295 - val_mDice: 0.5374

Epoch 00029: val_mDice did not improve from 0.55480
Epoch 30/300
 - 9s - loss: 0.3567 - acc: 0.9404 - mDice: 0.6848 - val_loss: 0.8087 - val_acc: 0.9341 - val_mDice: 0.5414

Epoch 00030: val_mDice did not improve from 0.55480
Epoch 31/300
 - 9s - loss: 0.3522 - acc: 0.9406 - mDice: 0.6880 - val_loss: 0.7890 - val_acc: 0.9355 - val_mDice: 0.5497

Epoch 00031: val_mDice did not improve from 0.55480
Epoch 32/300
 - 10s - loss: 0.3508 - acc: 0.9409 - mDice: 0.6890 - val_loss: 0.8143 - val_acc: 0.9260 - val_mDice: 0.5339

Epoch 00032: val_mDice did not improve from 0.55480
Epoch 33/300
 - 9s - loss: 0.3511 - acc: 0.9410 - mDice: 0.6888 - val_loss: 0.8093 - val_acc: 0.9386 - val_mDice: 0.5585

Epoch 00033: val_mDice improved from 0.55480 to 0.55853, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 34/300
 - 9s - loss: 0.3463 - acc: 0.9412 - mDice: 0.6922 - val_loss: 0.8274 - val_acc: 0.9259 - val_mDice: 0.5295

Epoch 00034: val_mDice did not improve from 0.55853
Epoch 35/300
 - 9s - loss: 0.3446 - acc: 0.9413 - mDice: 0.6935 - val_loss: 0.7739 - val_acc: 0.9332 - val_mDice: 0.5477

Epoch 00035: val_mDice did not improve from 0.55853
Epoch 36/300
 - 9s - loss: 0.3431 - acc: 0.9415 - mDice: 0.6944 - val_loss: 0.7953 - val_acc: 0.9357 - val_mDice: 0.5471

Epoch 00036: val_mDice did not improve from 0.55853
Epoch 37/300
 - 9s - loss: 0.3412 - acc: 0.9415 - mDice: 0.6959 - val_loss: 0.7798 - val_acc: 0.9368 - val_mDice: 0.5505

Epoch 00037: val_mDice did not improve from 0.55853
Epoch 38/300
 - 9s - loss: 0.3398 - acc: 0.9419 - mDice: 0.6969 - val_loss: 0.7771 - val_acc: 0.9358 - val_mDice: 0.5542

Epoch 00038: val_mDice did not improve from 0.55853
Epoch 39/300
 - 9s - loss: 0.3362 - acc: 0.9420 - mDice: 0.6995 - val_loss: 0.7923 - val_acc: 0.9336 - val_mDice: 0.5441

Epoch 00039: val_mDice did not improve from 0.55853
Epoch 40/300
 - 9s - loss: 0.3373 - acc: 0.9420 - mDice: 0.6988 - val_loss: 0.7834 - val_acc: 0.9345 - val_mDice: 0.5502

Epoch 00040: val_mDice did not improve from 0.55853
Epoch 41/300
 - 9s - loss: 0.3338 - acc: 0.9421 - mDice: 0.7013 - val_loss: 0.7664 - val_acc: 0.9365 - val_mDice: 0.5578

Epoch 00041: val_mDice did not improve from 0.55853
Epoch 42/300
 - 9s - loss: 0.3312 - acc: 0.9423 - mDice: 0.7032 - val_loss: 0.7821 - val_acc: 0.9310 - val_mDice: 0.5511

Epoch 00042: val_mDice did not improve from 0.55853
Epoch 43/300
 - 10s - loss: 0.3305 - acc: 0.9424 - mDice: 0.7038 - val_loss: 0.7694 - val_acc: 0.9369 - val_mDice: 0.5509

Epoch 00043: val_mDice did not improve from 0.55853
Epoch 44/300
 - 9s - loss: 0.3288 - acc: 0.9425 - mDice: 0.7050 - val_loss: 0.7908 - val_acc: 0.9377 - val_mDice: 0.5463

Epoch 00044: val_mDice did not improve from 0.55853
Epoch 45/300
 - 9s - loss: 0.3286 - acc: 0.9426 - mDice: 0.7052 - val_loss: 0.7893 - val_acc: 0.9312 - val_mDice: 0.5431

Epoch 00045: val_mDice did not improve from 0.55853
Epoch 46/300
 - 9s - loss: 0.3268 - acc: 0.9427 - mDice: 0.7065 - val_loss: 0.7762 - val_acc: 0.9366 - val_mDice: 0.5508

Epoch 00046: val_mDice did not improve from 0.55853
Epoch 47/300
 - 9s - loss: 0.3252 - acc: 0.9428 - mDice: 0.7076 - val_loss: 0.8039 - val_acc: 0.9285 - val_mDice: 0.5359

Epoch 00047: val_mDice did not improve from 0.55853
Epoch 48/300
 - 9s - loss: 0.3242 - acc: 0.9430 - mDice: 0.7084 - val_loss: 0.7478 - val_acc: 0.9374 - val_mDice: 0.5541

Epoch 00048: val_mDice did not improve from 0.55853
Epoch 49/300
 - 9s - loss: 0.3220 - acc: 0.9432 - mDice: 0.7100 - val_loss: 0.7775 - val_acc: 0.9384 - val_mDice: 0.5565

Epoch 00049: val_mDice did not improve from 0.55853
Epoch 50/300
 - 9s - loss: 0.3243 - acc: 0.9430 - mDice: 0.7083 - val_loss: 0.7900 - val_acc: 0.9321 - val_mDice: 0.5306

Epoch 00050: val_mDice did not improve from 0.55853
Epoch 51/300
 - 9s - loss: 0.3204 - acc: 0.9432 - mDice: 0.7111 - val_loss: 0.7686 - val_acc: 0.9345 - val_mDice: 0.5446

Epoch 00051: val_mDice did not improve from 0.55853
Epoch 52/300
 - 9s - loss: 0.3191 - acc: 0.9434 - mDice: 0.7122 - val_loss: 0.7624 - val_acc: 0.9333 - val_mDice: 0.5480

Epoch 00052: val_mDice did not improve from 0.55853
Epoch 53/300
 - 9s - loss: 0.3183 - acc: 0.9434 - mDice: 0.7128 - val_loss: 0.7528 - val_acc: 0.9364 - val_mDice: 0.5492

Epoch 00053: val_mDice did not improve from 0.55853
Epoch 54/300
 - 9s - loss: 0.3173 - acc: 0.9435 - mDice: 0.7134 - val_loss: 0.7417 - val_acc: 0.9361 - val_mDice: 0.5585

Epoch 00054: val_mDice improved from 0.55853 to 0.55855, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 55/300
 - 10s - loss: 0.3164 - acc: 0.9434 - mDice: 0.7140 - val_loss: 0.7854 - val_acc: 0.9353 - val_mDice: 0.5403

Epoch 00055: val_mDice did not improve from 0.55855
Epoch 56/300
 - 10s - loss: 0.3144 - acc: 0.9436 - mDice: 0.7156 - val_loss: 0.7937 - val_acc: 0.9343 - val_mDice: 0.5405

Epoch 00056: val_mDice did not improve from 0.55855
Epoch 57/300
 - 9s - loss: 0.3133 - acc: 0.9438 - mDice: 0.7165 - val_loss: 0.7693 - val_acc: 0.9347 - val_mDice: 0.5431

Epoch 00057: val_mDice did not improve from 0.55855
Epoch 58/300
 - 9s - loss: 0.3123 - acc: 0.9439 - mDice: 0.7173 - val_loss: 0.7650 - val_acc: 0.9339 - val_mDice: 0.5506

Epoch 00058: val_mDice did not improve from 0.55855
Epoch 59/300
 - 9s - loss: 0.3124 - acc: 0.9439 - mDice: 0.7172 - val_loss: 0.7417 - val_acc: 0.9380 - val_mDice: 0.5448

Epoch 00059: val_mDice did not improve from 0.55855
Epoch 60/300
 - 9s - loss: 0.3121 - acc: 0.9439 - mDice: 0.7174 - val_loss: 0.7647 - val_acc: 0.9322 - val_mDice: 0.5391

Epoch 00060: val_mDice did not improve from 0.55855
Epoch 61/300
 - 9s - loss: 0.3098 - acc: 0.9441 - mDice: 0.7191 - val_loss: 0.7556 - val_acc: 0.9383 - val_mDice: 0.5332

Epoch 00061: val_mDice did not improve from 0.55855
Epoch 62/300
 - 9s - loss: 0.3083 - acc: 0.9442 - mDice: 0.7202 - val_loss: 0.7613 - val_acc: 0.9384 - val_mDice: 0.5505

Epoch 00062: val_mDice did not improve from 0.55855
Epoch 63/300
 - 9s - loss: 0.3086 - acc: 0.9442 - mDice: 0.7200 - val_loss: 0.7312 - val_acc: 0.9345 - val_mDice: 0.5528

Epoch 00063: val_mDice did not improve from 0.55855
Epoch 64/300
 - 9s - loss: 0.3076 - acc: 0.9442 - mDice: 0.7208 - val_loss: 0.7655 - val_acc: 0.9396 - val_mDice: 0.5519

Epoch 00064: val_mDice did not improve from 0.55855
Epoch 65/300
 - 10s - loss: 0.3075 - acc: 0.9444 - mDice: 0.7209 - val_loss: 0.7788 - val_acc: 0.9395 - val_mDice: 0.5510

Epoch 00065: val_mDice did not improve from 0.55855
Epoch 66/300
 - 9s - loss: 0.3054 - acc: 0.9443 - mDice: 0.7225 - val_loss: 0.7663 - val_acc: 0.9391 - val_mDice: 0.5440

Epoch 00066: val_mDice did not improve from 0.55855
Epoch 67/300
 - 10s - loss: 0.3051 - acc: 0.9445 - mDice: 0.7227 - val_loss: 0.7195 - val_acc: 0.9358 - val_mDice: 0.5581

Epoch 00067: val_mDice did not improve from 0.55855
Epoch 68/300
 - 10s - loss: 0.3026 - acc: 0.9446 - mDice: 0.7245 - val_loss: 0.7292 - val_acc: 0.9340 - val_mDice: 0.5506

Epoch 00068: val_mDice did not improve from 0.55855
Epoch 69/300
 - 10s - loss: 0.3025 - acc: 0.9447 - mDice: 0.7247 - val_loss: 0.7386 - val_acc: 0.9381 - val_mDice: 0.5494

Epoch 00069: val_mDice did not improve from 0.55855
Epoch 70/300
 - 9s - loss: 0.3030 - acc: 0.9447 - mDice: 0.7243 - val_loss: 0.7192 - val_acc: 0.9357 - val_mDice: 0.5511

Epoch 00070: val_mDice did not improve from 0.55855
Epoch 71/300
 - 10s - loss: 0.3012 - acc: 0.9447 - mDice: 0.7256 - val_loss: 0.7485 - val_acc: 0.9319 - val_mDice: 0.5346

Epoch 00071: val_mDice did not improve from 0.55855
Epoch 72/300
 - 10s - loss: 0.3019 - acc: 0.9447 - mDice: 0.7251 - val_loss: 0.7400 - val_acc: 0.9363 - val_mDice: 0.5437

Epoch 00072: val_mDice did not improve from 0.55855
Epoch 73/300
 - 10s - loss: 0.3009 - acc: 0.9448 - mDice: 0.7259 - val_loss: 0.7061 - val_acc: 0.9354 - val_mDice: 0.5498

Epoch 00073: val_mDice did not improve from 0.55855
Epoch 74/300
 - 10s - loss: 0.2985 - acc: 0.9449 - mDice: 0.7276 - val_loss: 0.7507 - val_acc: 0.9322 - val_mDice: 0.5461

Epoch 00074: val_mDice did not improve from 0.55855
Epoch 75/300
 - 10s - loss: 0.2999 - acc: 0.9448 - mDice: 0.7266 - val_loss: 0.7365 - val_acc: 0.9325 - val_mDice: 0.5490

Epoch 00075: val_mDice did not improve from 0.55855
Epoch 76/300
 - 10s - loss: 0.2974 - acc: 0.9451 - mDice: 0.7286 - val_loss: 0.7486 - val_acc: 0.9309 - val_mDice: 0.5482

Epoch 00076: val_mDice did not improve from 0.55855
Epoch 77/300
 - 10s - loss: 0.2974 - acc: 0.9451 - mDice: 0.7285 - val_loss: 0.7347 - val_acc: 0.9363 - val_mDice: 0.5365

Epoch 00077: val_mDice did not improve from 0.55855
Epoch 78/300
 - 10s - loss: 0.2992 - acc: 0.9449 - mDice: 0.7272 - val_loss: 0.7376 - val_acc: 0.9314 - val_mDice: 0.5455

Epoch 00078: val_mDice did not improve from 0.55855
Epoch 79/300
 - 10s - loss: 0.2967 - acc: 0.9451 - mDice: 0.7291 - val_loss: 0.7348 - val_acc: 0.9363 - val_mDice: 0.5422

Epoch 00079: val_mDice did not improve from 0.55855
Epoch 80/300
 - 10s - loss: 0.2973 - acc: 0.9450 - mDice: 0.7286 - val_loss: 0.7663 - val_acc: 0.9344 - val_mDice: 0.5416

Epoch 00080: val_mDice did not improve from 0.55855
Epoch 81/300
 - 10s - loss: 0.2960 - acc: 0.9450 - mDice: 0.7295 - val_loss: 0.7128 - val_acc: 0.9284 - val_mDice: 0.5455

Epoch 00081: val_mDice did not improve from 0.55855
Epoch 82/300
 - 10s - loss: 0.2940 - acc: 0.9454 - mDice: 0.7311 - val_loss: 0.7060 - val_acc: 0.9365 - val_mDice: 0.5471

Epoch 00082: val_mDice did not improve from 0.55855
Epoch 83/300
 - 10s - loss: 0.2939 - acc: 0.9453 - mDice: 0.7312 - val_loss: 0.7443 - val_acc: 0.9389 - val_mDice: 0.5463

Epoch 00083: val_mDice did not improve from 0.55855
Epoch 84/300
 - 10s - loss: 0.2940 - acc: 0.9453 - mDice: 0.7312 - val_loss: 0.7266 - val_acc: 0.9310 - val_mDice: 0.5446

Epoch 00084: val_mDice did not improve from 0.55855
Epoch 85/300
 - 10s - loss: 0.2932 - acc: 0.9453 - mDice: 0.7317 - val_loss: 0.8222 - val_acc: 0.9275 - val_mDice: 0.5232

Epoch 00085: val_mDice did not improve from 0.55855
Epoch 86/300
 - 10s - loss: 0.2914 - acc: 0.9456 - mDice: 0.7331 - val_loss: 0.7453 - val_acc: 0.9306 - val_mDice: 0.5233

Epoch 00086: val_mDice did not improve from 0.55855
Epoch 87/300
 - 10s - loss: 0.2925 - acc: 0.9454 - mDice: 0.7322 - val_loss: 0.6899 - val_acc: 0.9370 - val_mDice: 0.5547

Epoch 00087: val_mDice did not improve from 0.55855
Epoch 88/300
 - 10s - loss: 0.2921 - acc: 0.9455 - mDice: 0.7326 - val_loss: 0.7121 - val_acc: 0.9365 - val_mDice: 0.5491

Epoch 00088: val_mDice did not improve from 0.55855
Epoch 89/300
 - 10s - loss: 0.2891 - acc: 0.9457 - mDice: 0.7349 - val_loss: 0.7055 - val_acc: 0.9309 - val_mDice: 0.5415

Epoch 00089: val_mDice did not improve from 0.55855
Epoch 90/300
 - 10s - loss: 0.2903 - acc: 0.9457 - mDice: 0.7340 - val_loss: 0.7638 - val_acc: 0.9397 - val_mDice: 0.5410

Epoch 00090: val_mDice did not improve from 0.55855
Epoch 91/300
 - 10s - loss: 0.2888 - acc: 0.9457 - mDice: 0.7350 - val_loss: 0.7013 - val_acc: 0.9401 - val_mDice: 0.5470

Epoch 00091: val_mDice did not improve from 0.55855
Epoch 92/300
 - 10s - loss: 0.2888 - acc: 0.9459 - mDice: 0.7351 - val_loss: 0.6888 - val_acc: 0.9367 - val_mDice: 0.5508

Epoch 00092: val_mDice did not improve from 0.55855
Epoch 93/300
 - 10s - loss: 0.2872 - acc: 0.9459 - mDice: 0.7364 - val_loss: 0.7238 - val_acc: 0.9363 - val_mDice: 0.5174

Epoch 00093: val_mDice did not improve from 0.55855
Epoch 94/300
 - 10s - loss: 0.2888 - acc: 0.9458 - mDice: 0.7351 - val_loss: 0.6718 - val_acc: 0.9328 - val_mDice: 0.5446

Epoch 00094: val_mDice did not improve from 0.55855
Restoring model weights from the end of the best epoch
Epoch 00094: early stopping
{'val_loss': [2.576285930780264, 1.170745645578091, 1.0170071950325599, 0.9012106817502242, 0.8655231984762045, 0.8714141043332907, 0.8457472874568059, 0.8404400784235734, 0.8302078315844903, 0.8511063548234793, 0.8286050282991849, 0.8376804567300357, 0.7896424623636099, 0.7704460689654717, 0.7723327164466565, 0.7895818169300373, 0.7707613958762243, 0.7831275394329658, 0.8008685524647052, 0.8042722160999591, 0.8144151797661414, 0.8024135621694418, 0.7953016070219187, 0.8062749963540298, 0.8612840702900519, 0.7973947043602283, 0.7964252416904156, 0.7977581253418555, 0.7913001821591303, 0.8087103160528036, 0.7889615618265592, 0.8142808263118451, 0.8092613288989434, 0.8273871816121615, 0.7739479358379657, 0.7953084202913138, 0.7798347587768848, 0.7770566504735213, 0.7923194949443524, 0.7833564556561984, 0.7664446395177108, 0.7820977110129136, 0.7693543021495526, 0.7908387596790607, 0.7892913084763747, 0.776161267207219, 0.8039095883186047, 0.7478058200616103, 0.7774778398183676, 0.7899849781623254, 0.7686225313406724, 0.7623950793192937, 0.7527961616332715, 0.7417199840912452, 0.7854119126613324, 0.7936525849195627, 0.7692986956009498, 0.7649522446669065, 0.7416985814387982, 0.764695046039728, 0.7556437116402847, 0.7612657455297617, 0.7311727954791143, 0.7655056164814875, 0.7788181465405685, 0.7662777533897986, 0.7195110871241643, 0.7292217979064355, 0.7385540719215686, 0.7191779315471649, 0.7485162707475516, 0.7400101514963003, 0.7060647492225354, 0.7507289923154391, 0.7364753484725952, 0.7486215371351975, 0.7347109203155224, 0.7375788596960214, 0.7347564720190488, 0.766264959023549, 0.7128369395549481, 0.7059920132160187, 0.7442606022724738, 0.7265571149495932, 0.8222329112199637, 0.7453168905698336, 0.6899202122138097, 0.7120872323329632, 0.705481611765348, 0.763792654642692, 0.7013303981377528, 0.6888483258394095, 0.7237626314163208, 0.6717660702191867], 'val_acc': [0.9037190308937659, 0.9100753527421218, 0.9143860775690812, 0.9145941046568064, 0.9175203511348138, 0.9162583007262304, 0.9237495271059183, 0.930450283564054, 0.9352024885324332, 0.9286843629983755, 0.9372018163020794, 0.934929751432859, 0.9245007152740772, 0.9340537098737863, 0.9299440452685723, 0.9314534091032468, 0.9337278237709632, 0.9264330772253183, 0.9299070858038389, 0.9224251302388998, 0.9340721918986394, 0.9362287292113671, 0.9342201283344855, 0.9327339117343609, 0.9213595482019278, 0.9279100573979892, 0.9290980834227341, 0.9351215798121232, 0.9295395727340992, 0.9341137959406927, 0.9355353300388043, 0.9259731013041276, 0.9386141162652236, 0.9259222516646752, 0.9331869391294626, 0.9356624621611375, 0.9367534036819751, 0.93584271806937, 0.9336330455083114, 0.9345090343401983, 0.9364852974048028, 0.9310257985041692, 0.9368713268866906, 0.937724232673645, 0.9311552345752716, 0.9366147495233096, 0.9284809438081888, 0.9374375962294065, 0.9384107062449822, 0.9321329754132491, 0.934513678917518, 0.9333418217989115, 0.9363627983973577, 0.9360946508554312, 0.9352625539669623, 0.9343010347623092, 0.9347355938874758, 0.9338803612268888, 0.9379645746487838, 0.9321768398468311, 0.9382812426640437, 0.938412987268888, 0.9344836611014146, 0.9396496162964747, 0.9394785601359147, 0.939117981837346, 0.9357641545625833, 0.9339658595048465, 0.9380639745638921, 0.9357410027430608, 0.9319157004356384, 0.9362703493008246, 0.935361963052016, 0.9321745679928706, 0.9325212927965018, 0.9308963601405804, 0.9362611151658572, 0.9314233568998483, 0.93631423665927, 0.9344189029473525, 0.9283746297542865, 0.9365222866718586, 0.9388799163011404, 0.9310234647530776, 0.9274708536955026, 0.9305912645963522, 0.9370446273913751, 0.9365176398020524, 0.9308501550784478, 0.9396681074912732, 0.940084131864401, 0.9366817841163049, 0.9362911673692557, 0.9327524029291593], 'val_mDice': [0.1748419263615058, 0.40363680829222387, 0.4731173710181163, 0.5082928899389046, 0.5261674082049956, 0.5337112471461296, 0.5288582381147605, 0.5428539227980834, 0.5348619850209126, 0.5252691679275953, 0.5348704500267139, 0.5274835142951745, 0.5344004252782235, 0.5468157495443637, 0.5410560891032219, 0.5430070456977074, 0.5548049222964507, 0.5416060485518895, 0.5455929442093923, 0.5258011502715257, 0.5434267870508708, 0.5495178837042588, 0.5506237097657644, 0.5486055506536593, 0.5114183746851407, 0.5503784991227664, 0.5363932779202094, 0.5407237032285104, 0.5373970212844702, 0.5413861733216506, 0.5497116916454755, 0.5338820720521303, 0.5585312705773574, 0.5294536842176547, 0.5477298005269124, 0.547094912483142, 0.5504758403851435, 0.554198658810212, 0.5440955316791167, 0.5502438900562433, 0.5578151534383113, 0.5510552840737196, 0.5509455490570802, 0.5462687777785155, 0.5430590808391571, 0.5507824976856892, 0.5358842920798522, 0.5540698970166537, 0.5565104547601479, 0.5306177431574235, 0.5446421985442822, 0.5479611510840746, 0.5491932183504105, 0.5585491307652913, 0.5403302939465413, 0.5405480342988784, 0.5431428975783862, 0.5505985717933911, 0.5448421417520597, 0.5391243065779026, 0.5332120129695306, 0.5505482494257964, 0.5528354031535295, 0.5519458453815717, 0.5509523159036269, 0.5439871022334466, 0.5580625591369776, 0.5506006166912042, 0.5494258833619264, 0.5510792525914999, 0.5345725061801764, 0.543721406505658, 0.549777032664189, 0.5461024991594828, 0.5489744458060998, 0.5481939338720762, 0.5365231504233984, 0.545507461978839, 0.5421587561185544, 0.5416306669895465, 0.5455009702306527, 0.5471276279825431, 0.5462640979542182, 0.5446294838419328, 0.5232497725922328, 0.5233064379829627, 0.5546561869291159, 0.5490689661640388, 0.5415131346537516, 0.5410244221297594, 0.5469683248263139, 0.5508200314182502, 0.5173637465788767, 0.5446270452095912], 'loss': [2.7659556230121813, 0.9318102119561107, 0.7212549379849735, 0.6349550717037278, 0.5764140232588042, 0.5370681311309552, 0.5069839163513891, 0.4889151333256378, 0.4709489928349065, 0.4597418869068336, 0.45104977339272523, 0.44103503173912384, 0.4297846538311637, 0.4210698580863917, 0.41405337811736703, 0.4072978672677385, 0.40107165895011454, 0.39672442654462625, 0.39167497735352, 0.3879840993511823, 0.381891084557847, 0.381149182652873, 0.37717399798195533, 0.371965226633549, 0.3676309941478577, 0.36640139277445527, 0.3643570710105847, 0.36103434449388655, 0.3595154044274792, 0.3566535764280131, 0.3521582438454773, 0.3507830805607215, 0.3510605854422121, 0.3462825801460921, 0.3445803974344976, 0.3430701337880472, 0.3412298210281997, 0.33978754984522225, 0.33618861459381827, 0.3373142160151614, 0.3338165605963129, 0.3311735346898221, 0.33045590266325614, 0.32878898864883915, 0.3285585189700116, 0.3268409450478762, 0.32520211340755945, 0.32418800724297003, 0.3219543454376169, 0.3243252570604053, 0.3204189898078758, 0.319076491110793, 0.31834036137393, 0.3173330927520707, 0.3164377146532183, 0.3144280038850285, 0.3132644675484467, 0.3123367142959856, 0.3124268907556496, 0.3121334770190191, 0.3098371876602099, 0.30831617058109534, 0.30864872686055755, 0.3075696058453839, 0.3074925952288406, 0.3054187663842928, 0.30511696085733736, 0.3026463697946765, 0.3024522243891323, 0.30303844591848506, 0.3011533988585257, 0.30192626400219497, 0.30092759395364704, 0.29847077969133573, 0.29992226153724827, 0.29741058129287123, 0.2974374329242321, 0.29917982761285783, 0.29665271864323933, 0.2973321915431446, 0.2960479808812386, 0.29400170719305835, 0.2938504358927922, 0.29398759406870456, 0.29317641158468066, 0.2914349384510373, 0.29252210605477624, 0.2920700754449122, 0.28910420467402126, 0.29028173327929724, 0.2888365610025361, 0.28882956880545974, 0.2871966776038232, 0.28882940328342166], 'acc': [0.5631445345981506, 0.8834851360855359, 0.8875712535922887, 0.8902290966153903, 0.892254971808133, 0.8953921671977048, 0.8993417850161218, 0.9044467270797572, 0.9126559438426634, 0.9214798288460555, 0.926641656603088, 0.9302754025007212, 0.932485176074948, 0.9339812686552611, 0.9349970339321512, 0.9356291110825848, 0.9363711704234186, 0.9367340392900615, 0.9372222163432486, 0.9375027951736419, 0.9381676573798653, 0.9382233711930644, 0.9386575378022004, 0.9390018781997352, 0.9393585865748035, 0.939497033861261, 0.9396376115616359, 0.9400025909428313, 0.9402153531607695, 0.940355235054013, 0.9406464369789784, 0.9409027399639026, 0.9409629090635097, 0.9411625230838966, 0.9413280220947768, 0.9414558706661328, 0.9415158840394664, 0.9418551477407009, 0.9420215476815863, 0.9420064515890719, 0.9421390271501261, 0.9422852575399664, 0.9424255690890837, 0.9425010990801854, 0.9426087530998576, 0.9427108887068011, 0.9428337549884018, 0.9429899128745713, 0.9431758073217742, 0.9430458509184322, 0.9432361969855024, 0.9433867289144197, 0.9434066581833817, 0.9434552310270148, 0.9434315572417795, 0.9435510259816691, 0.9437955360422272, 0.9438654836567854, 0.9438876703712736, 0.9438626829530989, 0.9440785955538403, 0.944207225334685, 0.9441792934481579, 0.9442104398077357, 0.9443653377452745, 0.9443483143497918, 0.9444881575821973, 0.9446026175145039, 0.9446828071288074, 0.9447036659015036, 0.9446506400362522, 0.9446874624917859, 0.9448175092283501, 0.9449322356032587, 0.9447500690547103, 0.9450587613121078, 0.945086893038832, 0.9449439646902421, 0.9450964698335907, 0.9450177231871048, 0.9450028192334033, 0.9453882614174177, 0.9452825826845694, 0.945279675019048, 0.945320647509129, 0.9456140394306685, 0.9453654059413438, 0.9454865627685486, 0.9456820787675903, 0.9456809460264746, 0.9456778422862437, 0.9458829542263115, 0.9459263405038633, 0.9457902221082487], 'mDice': [0.1088475598788323, 0.38268054955660674, 0.47177396437497987, 0.51531573808755, 0.5467128100061421, 0.5693772572999641, 0.5873020332721308, 0.5985940564913381, 0.6096266326204631, 0.61636732339881, 0.6218554587213797, 0.6280727709921745, 0.6351830932329493, 0.6406804385972861, 0.6453684293607015, 0.6497773772553413, 0.6540174935946526, 0.6569580218508972, 0.6604914586834062, 0.6629360474960111, 0.6670940344727019, 0.6676179783860773, 0.6704536488352365, 0.6739436365367851, 0.6769663194641244, 0.6779098074990072, 0.6793757608804736, 0.6817408942718914, 0.6827852674200341, 0.6848030042617532, 0.6879674477582927, 0.6890304326835203, 0.688825284078048, 0.6922369521998681, 0.6934928020504825, 0.694445596798467, 0.6959457715081188, 0.696901412189617, 0.6995225391693136, 0.6987646322326005, 0.7012585999615395, 0.7031700833305754, 0.7037811017636717, 0.7049661964428202, 0.7052370699406506, 0.7064766329581322, 0.7075914009618086, 0.7083907752836102, 0.7100194459206436, 0.7083247991700152, 0.7111387800369977, 0.7121920858341577, 0.7127569602235683, 0.7134416099899888, 0.7140451851205984, 0.7156022605910948, 0.7164968659294428, 0.717254580468981, 0.7172027583009234, 0.7173591035104794, 0.7190740371084648, 0.7201566133487711, 0.7200162068488996, 0.7207607764341531, 0.720885303455185, 0.7224857923697141, 0.7226775753083599, 0.7245162383421402, 0.7246818196055613, 0.7242964575192392, 0.725638337453265, 0.7250922736586828, 0.7259387570554168, 0.7276485580409858, 0.7266414515164948, 0.7285522466038774, 0.7284809886051435, 0.7272451901132414, 0.7291360543265198, 0.72861136693549, 0.7295409445281971, 0.7311156821363055, 0.7312287916328418, 0.7311549446497699, 0.7316833048863769, 0.733090459987113, 0.7322039747550392, 0.7325803207359465, 0.7349031008962092, 0.7340271516082846, 0.7350366263001274, 0.7351280712700963, 0.7363595971594566, 0.7351157173375565]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.25s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  2.00s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.82s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:37,  1.82s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:59,  1.69s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:58,  1.70s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:26,  1.59s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:34,  1.62s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:09,  1.54s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:36,  1.64s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:34,  1.64s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:52,  1.71s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:04,  1.76s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<07:42,  1.69s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<07:55,  1.74s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:41,  1.70s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<07:45,  1.72s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<07:55,  1.76s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<08:01,  1.79s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<07:42,  1.73s/it]predicting train subjects:   6%|▋         | 18/285 [00:30<07:42,  1.73s/it]predicting train subjects:   7%|▋         | 19/285 [00:31<07:26,  1.68s/it]predicting train subjects:   7%|▋         | 20/285 [00:33<07:37,  1.73s/it]predicting train subjects:   7%|▋         | 21/285 [00:35<07:56,  1.81s/it]predicting train subjects:   8%|▊         | 22/285 [00:37<07:40,  1.75s/it]predicting train subjects:   8%|▊         | 23/285 [00:39<07:39,  1.75s/it]predicting train subjects:   8%|▊         | 24/285 [00:40<07:21,  1.69s/it]predicting train subjects:   9%|▉         | 25/285 [00:42<07:33,  1.74s/it]predicting train subjects:   9%|▉         | 26/285 [00:44<07:43,  1.79s/it]predicting train subjects:   9%|▉         | 27/285 [00:45<07:20,  1.71s/it]predicting train subjects:  10%|▉         | 28/285 [00:47<07:20,  1.72s/it]predicting train subjects:  10%|█         | 29/285 [00:49<07:19,  1.72s/it]predicting train subjects:  11%|█         | 30/285 [00:51<07:35,  1.78s/it]predicting train subjects:  11%|█         | 31/285 [00:53<07:45,  1.83s/it]predicting train subjects:  11%|█         | 32/285 [00:54<07:24,  1.76s/it]predicting train subjects:  12%|█▏        | 33/285 [00:56<07:20,  1.75s/it]predicting train subjects:  12%|█▏        | 34/285 [00:58<07:17,  1.74s/it]predicting train subjects:  12%|█▏        | 35/285 [01:00<07:26,  1.79s/it]predicting train subjects:  13%|█▎        | 36/285 [01:01<07:07,  1.72s/it]predicting train subjects:  13%|█▎        | 37/285 [01:03<07:05,  1.71s/it]predicting train subjects:  13%|█▎        | 38/285 [01:05<07:14,  1.76s/it]predicting train subjects:  14%|█▎        | 39/285 [01:06<06:52,  1.67s/it]predicting train subjects:  14%|█▍        | 40/285 [01:08<07:04,  1.73s/it]predicting train subjects:  14%|█▍        | 41/285 [01:10<06:57,  1.71s/it]predicting train subjects:  15%|█▍        | 42/285 [01:11<06:44,  1.66s/it]predicting train subjects:  15%|█▌        | 43/285 [01:13<06:49,  1.69s/it]predicting train subjects:  15%|█▌        | 44/285 [01:15<07:07,  1.77s/it]predicting train subjects:  16%|█▌        | 45/285 [01:17<06:46,  1.69s/it]predicting train subjects:  16%|█▌        | 46/285 [01:19<06:58,  1.75s/it]predicting train subjects:  16%|█▋        | 47/285 [01:20<06:38,  1.67s/it]predicting train subjects:  17%|█▋        | 48/285 [01:22<06:46,  1.71s/it]predicting train subjects:  17%|█▋        | 49/285 [01:24<07:05,  1.80s/it]predicting train subjects:  18%|█▊        | 50/285 [01:26<07:04,  1.81s/it]predicting train subjects:  18%|█▊        | 51/285 [01:28<07:10,  1.84s/it]predicting train subjects:  18%|█▊        | 52/285 [01:29<06:47,  1.75s/it]predicting train subjects:  19%|█▊        | 53/285 [01:31<06:41,  1.73s/it]predicting train subjects:  19%|█▉        | 54/285 [01:33<06:47,  1.76s/it]predicting train subjects:  19%|█▉        | 55/285 [01:34<06:25,  1.68s/it]predicting train subjects:  20%|█▉        | 56/285 [01:36<06:26,  1.69s/it]predicting train subjects:  20%|██        | 57/285 [01:37<06:17,  1.66s/it]predicting train subjects:  20%|██        | 58/285 [01:39<06:23,  1.69s/it]predicting train subjects:  21%|██        | 59/285 [01:41<06:32,  1.74s/it]predicting train subjects:  21%|██        | 60/285 [01:43<06:41,  1.78s/it]predicting train subjects:  21%|██▏       | 61/285 [01:44<06:25,  1.72s/it]predicting train subjects:  22%|██▏       | 62/285 [01:46<06:27,  1.74s/it]predicting train subjects:  22%|██▏       | 63/285 [01:48<06:30,  1.76s/it]predicting train subjects:  22%|██▏       | 64/285 [01:50<06:16,  1.70s/it]predicting train subjects:  23%|██▎       | 65/285 [01:51<06:18,  1.72s/it]predicting train subjects:  23%|██▎       | 66/285 [01:53<06:20,  1.74s/it]predicting train subjects:  24%|██▎       | 67/285 [01:55<06:19,  1.74s/it]predicting train subjects:  24%|██▍       | 68/285 [01:57<06:06,  1.69s/it]predicting train subjects:  24%|██▍       | 69/285 [01:58<06:10,  1.72s/it]predicting train subjects:  25%|██▍       | 70/285 [02:00<06:09,  1.72s/it]predicting train subjects:  25%|██▍       | 71/285 [02:02<06:17,  1.76s/it]predicting train subjects:  25%|██▌       | 72/285 [02:03<06:01,  1.70s/it]predicting train subjects:  26%|██▌       | 73/285 [02:05<06:03,  1.72s/it]predicting train subjects:  26%|██▌       | 74/285 [02:07<06:08,  1.75s/it]predicting train subjects:  26%|██▋       | 75/285 [02:09<06:07,  1.75s/it]predicting train subjects:  27%|██▋       | 76/285 [02:10<06:04,  1.75s/it]predicting train subjects:  27%|██▋       | 77/285 [02:12<05:50,  1.68s/it]predicting train subjects:  27%|██▋       | 78/285 [02:14<05:40,  1.64s/it]predicting train subjects:  28%|██▊       | 79/285 [02:15<05:52,  1.71s/it]predicting train subjects:  28%|██▊       | 80/285 [02:17<05:57,  1.75s/it]predicting train subjects:  28%|██▊       | 81/285 [02:19<05:44,  1.69s/it]predicting train subjects:  29%|██▉       | 82/285 [02:21<05:49,  1.72s/it]predicting train subjects:  29%|██▉       | 83/285 [02:22<05:38,  1.68s/it]predicting train subjects:  29%|██▉       | 84/285 [02:24<05:33,  1.66s/it]predicting train subjects:  30%|██▉       | 85/285 [02:26<05:40,  1.70s/it]predicting train subjects:  30%|███       | 86/285 [02:27<05:41,  1.72s/it]predicting train subjects:  31%|███       | 87/285 [02:29<05:39,  1.71s/it]predicting train subjects:  31%|███       | 88/285 [02:31<05:29,  1.67s/it]predicting train subjects:  31%|███       | 89/285 [02:32<05:31,  1.69s/it]predicting train subjects:  32%|███▏      | 90/285 [02:34<05:31,  1.70s/it]predicting train subjects:  32%|███▏      | 91/285 [02:36<05:14,  1.62s/it]predicting train subjects:  32%|███▏      | 92/285 [02:37<05:14,  1.63s/it]predicting train subjects:  33%|███▎      | 93/285 [02:39<05:05,  1.59s/it]predicting train subjects:  33%|███▎      | 94/285 [02:40<05:13,  1.64s/it]predicting train subjects:  33%|███▎      | 95/285 [02:42<05:17,  1.67s/it]predicting train subjects:  34%|███▎      | 96/285 [02:44<05:14,  1.66s/it]predicting train subjects:  34%|███▍      | 97/285 [02:46<05:15,  1.68s/it]predicting train subjects:  34%|███▍      | 98/285 [02:47<05:17,  1.70s/it]predicting train subjects:  35%|███▍      | 99/285 [02:49<05:15,  1.69s/it]predicting train subjects:  35%|███▌      | 100/285 [02:51<05:20,  1.73s/it]predicting train subjects:  35%|███▌      | 101/285 [02:52<05:11,  1.69s/it]predicting train subjects:  36%|███▌      | 102/285 [02:54<05:11,  1.70s/it]predicting train subjects:  36%|███▌      | 103/285 [02:56<04:55,  1.63s/it]predicting train subjects:  36%|███▋      | 104/285 [02:57<05:00,  1.66s/it]predicting train subjects:  37%|███▋      | 105/285 [02:59<05:00,  1.67s/it]predicting train subjects:  37%|███▋      | 106/285 [03:01<04:49,  1.62s/it]predicting train subjects:  38%|███▊      | 107/285 [03:02<05:00,  1.69s/it]predicting train subjects:  38%|███▊      | 108/285 [03:04<04:55,  1.67s/it]predicting train subjects:  38%|███▊      | 109/285 [03:06<04:58,  1.70s/it]predicting train subjects:  39%|███▊      | 110/285 [03:07<04:56,  1.69s/it]predicting train subjects:  39%|███▉      | 111/285 [03:09<04:46,  1.65s/it]predicting train subjects:  39%|███▉      | 112/285 [03:11<04:51,  1.68s/it]predicting train subjects:  40%|███▉      | 113/285 [03:12<04:50,  1.69s/it]predicting train subjects:  40%|████      | 114/285 [03:14<04:51,  1.70s/it]predicting train subjects:  40%|████      | 115/285 [03:16<04:52,  1.72s/it]predicting train subjects:  41%|████      | 116/285 [03:18<04:59,  1.77s/it]predicting train subjects:  41%|████      | 117/285 [03:20<04:58,  1.78s/it]predicting train subjects:  41%|████▏     | 118/285 [03:21<04:57,  1.78s/it]predicting train subjects:  42%|████▏     | 119/285 [03:23<05:04,  1.83s/it]predicting train subjects:  42%|████▏     | 120/285 [03:25<05:08,  1.87s/it]predicting train subjects:  42%|████▏     | 121/285 [03:27<04:59,  1.83s/it]predicting train subjects:  43%|████▎     | 122/285 [03:29<04:44,  1.74s/it]predicting train subjects:  43%|████▎     | 123/285 [03:30<04:42,  1.74s/it]predicting train subjects:  44%|████▎     | 124/285 [03:32<04:43,  1.76s/it]predicting train subjects:  44%|████▍     | 125/285 [03:34<04:32,  1.70s/it]predicting train subjects:  44%|████▍     | 126/285 [03:35<04:18,  1.63s/it]predicting train subjects:  45%|████▍     | 127/285 [03:37<04:14,  1.61s/it]predicting train subjects:  45%|████▍     | 128/285 [03:39<04:22,  1.67s/it]predicting train subjects:  45%|████▌     | 129/285 [03:40<04:23,  1.69s/it]predicting train subjects:  46%|████▌     | 130/285 [03:42<04:13,  1.64s/it]predicting train subjects:  46%|████▌     | 131/285 [03:43<04:04,  1.59s/it]predicting train subjects:  46%|████▋     | 132/285 [03:45<04:12,  1.65s/it]predicting train subjects:  47%|████▋     | 133/285 [03:47<04:20,  1.71s/it]predicting train subjects:  47%|████▋     | 134/285 [03:49<04:13,  1.68s/it]predicting train subjects:  47%|████▋     | 135/285 [03:50<04:08,  1.66s/it]predicting train subjects:  48%|████▊     | 136/285 [03:52<04:08,  1.66s/it]predicting train subjects:  48%|████▊     | 137/285 [03:54<04:15,  1.73s/it]predicting train subjects:  48%|████▊     | 138/285 [03:55<03:59,  1.63s/it]predicting train subjects:  49%|████▉     | 139/285 [03:57<03:59,  1.64s/it]predicting train subjects:  49%|████▉     | 140/285 [03:59<04:03,  1.68s/it]predicting train subjects:  49%|████▉     | 141/285 [04:00<03:51,  1.60s/it]predicting train subjects:  50%|████▉     | 142/285 [04:02<03:47,  1.59s/it]predicting train subjects:  50%|█████     | 143/285 [04:03<03:49,  1.62s/it]predicting train subjects:  51%|█████     | 144/285 [04:05<03:51,  1.64s/it]predicting train subjects:  51%|█████     | 145/285 [04:07<03:49,  1.64s/it]predicting train subjects:  51%|█████     | 146/285 [04:08<03:54,  1.69s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:10<03:46,  1.64s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:12<03:50,  1.68s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:13<03:44,  1.65s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:15<03:41,  1.64s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:17<03:40,  1.65s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:18<03:45,  1.70s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:20<03:38,  1.65s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:22<03:50,  1.76s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:23<03:42,  1.72s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:25<03:39,  1.70s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:27<03:31,  1.66s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:28<03:33,  1.68s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:30<03:26,  1.64s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:31<03:19,  1.60s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:33<03:23,  1.64s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:35<03:24,  1.66s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:37<03:25,  1.69s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:38<03:25,  1.70s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:40<03:17,  1.65s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:42<03:21,  1.69s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:44<03:25,  1.74s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:45<03:23,  1.74s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:47<03:21,  1.74s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:49<03:16,  1.71s/it]predicting train subjects:  60%|██████    | 171/285 [04:50<03:16,  1.72s/it]predicting train subjects:  60%|██████    | 172/285 [04:52<03:17,  1.75s/it]predicting train subjects:  61%|██████    | 173/285 [04:54<03:17,  1.76s/it]predicting train subjects:  61%|██████    | 174/285 [04:56<03:12,  1.73s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:57<03:11,  1.74s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:59<03:15,  1.79s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:01<03:07,  1.74s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:03<03:02,  1.71s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:04<02:59,  1.69s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:06<03:05,  1.76s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:08<03:09,  1.82s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:10<03:14,  1.89s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:12<02:59,  1.76s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:13<02:52,  1.71s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:15<02:45,  1.66s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:17<02:55,  1.78s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:19<03:06,  1.90s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:21<03:07,  1.93s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:23<02:57,  1.84s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:24<02:50,  1.80s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:26<02:52,  1.83s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:28<02:46,  1.79s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:30<02:37,  1.71s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:31<02:34,  1.70s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:33<02:30,  1.67s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:35<02:36,  1.76s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:37<02:37,  1.79s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:39<02:41,  1.86s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:40<02:27,  1.71s/it]predicting train subjects:  70%|███████   | 200/285 [05:42<02:20,  1.66s/it]predicting train subjects:  71%|███████   | 201/285 [05:44<02:30,  1.80s/it]predicting train subjects:  71%|███████   | 202/285 [05:46<02:34,  1.86s/it]predicting train subjects:  71%|███████   | 203/285 [05:48<02:35,  1.89s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:49<02:24,  1.78s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:51<02:17,  1.72s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:52<02:08,  1.63s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:54<02:15,  1.74s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:56<02:23,  1.87s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:58<02:26,  1.93s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:00<02:17,  1.83s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:02<02:11,  1.78s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:03<02:10,  1.79s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:05<02:11,  1.82s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:07<02:06,  1.78s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:09<02:11,  1.88s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:11<02:05,  1.82s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:13<02:11,  1.94s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:15<02:13,  1.99s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:17<02:11,  1.99s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:19<02:02,  1.88s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:20<01:55,  1.80s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:23<02:03,  1.97s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:24<01:56,  1.88s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:26<01:48,  1.78s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:28<01:43,  1.73s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:30<01:51,  1.88s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:32<01:54,  1.97s/it]predicting train subjects:  80%|████████  | 228/285 [06:34<01:56,  2.05s/it]predicting train subjects:  80%|████████  | 229/285 [06:36<01:54,  2.05s/it]predicting train subjects:  81%|████████  | 230/285 [06:38<01:44,  1.89s/it]predicting train subjects:  81%|████████  | 231/285 [06:40<01:39,  1.85s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:42<01:44,  1.98s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:44<01:38,  1.89s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:46<01:39,  1.95s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:47<01:29,  1.79s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:49<01:33,  1.92s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:51<01:33,  1.95s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:53<01:33,  1.98s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:55<01:28,  1.93s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:57<01:27,  1.94s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:59<01:23,  1.90s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:01<01:17,  1.81s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:02<01:15,  1.79s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:04<01:16,  1.86s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:06<01:12,  1.80s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:08<01:14,  1.92s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:11<01:19,  2.10s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:13<01:18,  2.11s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:15<01:13,  2.03s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:17<01:10,  2.00s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:18<01:03,  1.87s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:20<00:59,  1.81s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:22<01:01,  1.91s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:24<01:00,  1.95s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:26<00:58,  1.96s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:28<00:54,  1.88s/it]predicting train subjects:  90%|█████████ | 257/285 [07:29<00:51,  1.85s/it]predicting train subjects:  91%|█████████ | 258/285 [07:32<00:53,  1.97s/it]predicting train subjects:  91%|█████████ | 259/285 [07:34<00:51,  1.97s/it]predicting train subjects:  91%|█████████ | 260/285 [07:35<00:46,  1.87s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:37<00:42,  1.78s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:39<00:40,  1.75s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:40<00:36,  1.64s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:42<00:36,  1.76s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:44<00:36,  1.83s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:46<00:33,  1.74s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:47<00:29,  1.63s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:49<00:28,  1.67s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:50<00:26,  1.65s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:52<00:23,  1.57s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:53<00:21,  1.52s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:55<00:20,  1.56s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:56<00:17,  1.49s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:57<00:15,  1.45s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:59<00:15,  1.57s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:01<00:14,  1.61s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:02<00:12,  1.54s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:04<00:10,  1.50s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:05<00:09,  1.56s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:07<00:07,  1.49s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:08<00:05,  1.45s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:09<00:04,  1.42s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:11<00:03,  1.50s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:13<00:01,  1.57s/it]predicting train subjects: 100%|██████████| 285/285 [08:15<00:00,  1.62s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:23,  1.77s/it]Loading train:   1%|          | 2/285 [00:03<07:45,  1.65s/it]Loading train:   1%|          | 3/285 [00:04<07:13,  1.54s/it]Loading train:   1%|▏         | 4/285 [00:05<06:44,  1.44s/it]Loading train:   2%|▏         | 5/285 [00:07<07:08,  1.53s/it]Loading train:   2%|▏         | 6/285 [00:08<06:37,  1.43s/it]Loading train:   2%|▏         | 7/285 [00:10<06:48,  1.47s/it]Loading train:   3%|▎         | 8/285 [00:11<06:40,  1.44s/it]Loading train:   3%|▎         | 9/285 [00:13<07:01,  1.53s/it]Loading train:   4%|▎         | 10/285 [00:14<06:32,  1.43s/it]Loading train:   4%|▍         | 11/285 [00:15<05:40,  1.24s/it]Loading train:   4%|▍         | 12/285 [00:16<05:25,  1.19s/it]Loading train:   5%|▍         | 13/285 [00:17<05:12,  1.15s/it]Loading train:   5%|▍         | 14/285 [00:18<05:14,  1.16s/it]Loading train:   5%|▌         | 15/285 [00:19<05:13,  1.16s/it]Loading train:   6%|▌         | 16/285 [00:20<05:04,  1.13s/it]Loading train:   6%|▌         | 17/285 [00:21<04:36,  1.03s/it]Loading train:   6%|▋         | 18/285 [00:22<04:32,  1.02s/it]Loading train:   7%|▋         | 19/285 [00:23<04:45,  1.07s/it]Loading train:   7%|▋         | 20/285 [00:24<04:28,  1.01s/it]Loading train:   7%|▋         | 21/285 [00:25<04:24,  1.00s/it]Loading train:   8%|▊         | 22/285 [00:26<04:07,  1.06it/s]Loading train:   8%|▊         | 23/285 [00:27<04:02,  1.08it/s]Loading train:   8%|▊         | 24/285 [00:27<03:42,  1.17it/s]Loading train:   9%|▉         | 25/285 [00:28<03:47,  1.15it/s]Loading train:   9%|▉         | 26/285 [00:29<03:58,  1.09it/s]Loading train:   9%|▉         | 27/285 [00:30<03:48,  1.13it/s]Loading train:  10%|▉         | 28/285 [00:31<03:52,  1.11it/s]Loading train:  10%|█         | 29/285 [00:32<04:07,  1.04it/s]Loading train:  11%|█         | 30/285 [00:33<04:08,  1.03it/s]Loading train:  11%|█         | 31/285 [00:34<04:08,  1.02it/s]Loading train:  11%|█         | 32/285 [00:35<04:02,  1.04it/s]Loading train:  12%|█▏        | 33/285 [00:36<04:13,  1.00s/it]Loading train:  12%|█▏        | 34/285 [00:37<04:17,  1.03s/it]Loading train:  12%|█▏        | 35/285 [00:39<04:28,  1.07s/it]Loading train:  13%|█▎        | 36/285 [00:39<04:14,  1.02s/it]Loading train:  13%|█▎        | 37/285 [00:40<04:05,  1.01it/s]Loading train:  13%|█▎        | 38/285 [00:41<04:11,  1.02s/it]Loading train:  14%|█▎        | 39/285 [00:42<03:55,  1.04it/s]Loading train:  14%|█▍        | 40/285 [00:43<04:03,  1.01it/s]Loading train:  14%|█▍        | 41/285 [00:44<04:01,  1.01it/s]Loading train:  15%|█▍        | 42/285 [00:46<04:18,  1.06s/it]Loading train:  15%|█▌        | 43/285 [00:47<04:22,  1.09s/it]Loading train:  15%|█▌        | 44/285 [00:48<04:26,  1.11s/it]Loading train:  16%|█▌        | 45/285 [00:49<04:03,  1.01s/it]Loading train:  16%|█▌        | 46/285 [00:50<04:07,  1.04s/it]Loading train:  16%|█▋        | 47/285 [00:51<03:56,  1.01it/s]Loading train:  17%|█▋        | 48/285 [00:52<03:53,  1.02it/s]Loading train:  17%|█▋        | 49/285 [00:53<03:49,  1.03it/s]Loading train:  18%|█▊        | 50/285 [00:54<03:53,  1.01it/s]Loading train:  18%|█▊        | 51/285 [00:55<03:58,  1.02s/it]Loading train:  18%|█▊        | 52/285 [00:56<03:59,  1.03s/it]Loading train:  19%|█▊        | 53/285 [00:57<03:59,  1.03s/it]Loading train:  19%|█▉        | 54/285 [00:58<03:56,  1.02s/it]Loading train:  19%|█▉        | 55/285 [00:59<03:49,  1.00it/s]Loading train:  20%|█▉        | 56/285 [01:00<03:59,  1.05s/it]Loading train:  20%|██        | 57/285 [01:01<03:53,  1.02s/it]Loading train:  20%|██        | 58/285 [01:02<03:54,  1.03s/it]Loading train:  21%|██        | 59/285 [01:03<03:57,  1.05s/it]Loading train:  21%|██        | 60/285 [01:04<04:02,  1.08s/it]Loading train:  21%|██▏       | 61/285 [01:05<03:49,  1.03s/it]Loading train:  22%|██▏       | 62/285 [01:06<04:03,  1.09s/it]Loading train:  22%|██▏       | 63/285 [01:07<03:55,  1.06s/it]Loading train:  22%|██▏       | 64/285 [01:09<04:09,  1.13s/it]Loading train:  23%|██▎       | 65/285 [01:10<04:43,  1.29s/it]Loading train:  23%|██▎       | 66/285 [01:12<04:54,  1.35s/it]Loading train:  24%|██▎       | 67/285 [01:13<04:30,  1.24s/it]Loading train:  24%|██▍       | 68/285 [01:14<04:07,  1.14s/it]Loading train:  24%|██▍       | 69/285 [01:15<03:52,  1.08s/it]Loading train:  25%|██▍       | 70/285 [01:15<03:42,  1.03s/it]Loading train:  25%|██▍       | 71/285 [01:17<03:51,  1.08s/it]Loading train:  25%|██▌       | 72/285 [01:18<03:43,  1.05s/it]Loading train:  26%|██▌       | 73/285 [01:19<03:40,  1.04s/it]Loading train:  26%|██▌       | 74/285 [01:19<03:28,  1.01it/s]Loading train:  26%|██▋       | 75/285 [01:21<03:46,  1.08s/it]Loading train:  27%|██▋       | 76/285 [01:22<03:41,  1.06s/it]Loading train:  27%|██▋       | 77/285 [01:23<03:25,  1.01it/s]Loading train:  27%|██▋       | 78/285 [01:24<03:24,  1.01it/s]Loading train:  28%|██▊       | 79/285 [01:25<03:29,  1.02s/it]Loading train:  28%|██▊       | 80/285 [01:26<03:32,  1.03s/it]Loading train:  28%|██▊       | 81/285 [01:27<03:22,  1.01it/s]Loading train:  29%|██▉       | 82/285 [01:28<03:16,  1.03it/s]Loading train:  29%|██▉       | 83/285 [01:28<03:11,  1.05it/s]Loading train:  29%|██▉       | 84/285 [01:30<03:15,  1.03it/s]Loading train:  30%|██▉       | 85/285 [01:30<03:11,  1.04it/s]Loading train:  30%|███       | 86/285 [01:31<03:13,  1.03it/s]Loading train:  31%|███       | 87/285 [01:33<03:18,  1.00s/it]Loading train:  31%|███       | 88/285 [01:33<03:11,  1.03it/s]Loading train:  31%|███       | 89/285 [01:34<03:10,  1.03it/s]Loading train:  32%|███▏      | 90/285 [01:35<03:15,  1.00s/it]Loading train:  32%|███▏      | 91/285 [01:36<03:06,  1.04it/s]Loading train:  32%|███▏      | 92/285 [01:37<03:11,  1.01it/s]Loading train:  33%|███▎      | 93/285 [01:38<03:03,  1.04it/s]Loading train:  33%|███▎      | 94/285 [01:39<03:01,  1.05it/s]Loading train:  33%|███▎      | 95/285 [01:40<03:06,  1.02it/s]Loading train:  34%|███▎      | 96/285 [01:41<03:01,  1.04it/s]Loading train:  34%|███▍      | 97/285 [01:42<03:00,  1.04it/s]Loading train:  34%|███▍      | 98/285 [01:43<02:52,  1.08it/s]Loading train:  35%|███▍      | 99/285 [01:44<02:48,  1.10it/s]Loading train:  35%|███▌      | 100/285 [01:45<02:58,  1.04it/s]Loading train:  35%|███▌      | 101/285 [01:46<02:53,  1.06it/s]Loading train:  36%|███▌      | 102/285 [01:47<03:00,  1.01it/s]Loading train:  36%|███▌      | 103/285 [01:48<02:57,  1.02it/s]Loading train:  36%|███▋      | 104/285 [01:49<03:00,  1.00it/s]Loading train:  37%|███▋      | 105/285 [01:50<03:03,  1.02s/it]Loading train:  37%|███▋      | 106/285 [01:51<02:58,  1.00it/s]Loading train:  38%|███▊      | 107/285 [01:52<02:53,  1.02it/s]Loading train:  38%|███▊      | 108/285 [01:53<02:46,  1.06it/s]Loading train:  38%|███▊      | 109/285 [01:54<02:45,  1.06it/s]Loading train:  39%|███▊      | 110/285 [01:55<02:50,  1.02it/s]Loading train:  39%|███▉      | 111/285 [01:56<02:47,  1.04it/s]Loading train:  39%|███▉      | 112/285 [01:56<02:40,  1.08it/s]Loading train:  40%|███▉      | 113/285 [01:58<02:50,  1.01it/s]Loading train:  40%|████      | 114/285 [01:59<02:45,  1.03it/s]Loading train:  40%|████      | 115/285 [02:00<02:50,  1.00s/it]Loading train:  41%|████      | 116/285 [02:01<02:55,  1.04s/it]Loading train:  41%|████      | 117/285 [02:02<02:51,  1.02s/it]Loading train:  41%|████▏     | 118/285 [02:03<02:43,  1.02it/s]Loading train:  42%|████▏     | 119/285 [02:04<02:45,  1.00it/s]Loading train:  42%|████▏     | 120/285 [02:05<02:44,  1.01it/s]Loading train:  42%|████▏     | 121/285 [02:06<03:02,  1.12s/it]Loading train:  43%|████▎     | 122/285 [02:07<03:06,  1.14s/it]Loading train:  43%|████▎     | 123/285 [02:08<03:07,  1.16s/it]Loading train:  44%|████▎     | 124/285 [02:09<02:51,  1.06s/it]Loading train:  44%|████▍     | 125/285 [02:10<02:39,  1.00it/s]Loading train:  44%|████▍     | 126/285 [02:11<02:26,  1.09it/s]Loading train:  45%|████▍     | 127/285 [02:12<02:25,  1.09it/s]Loading train:  45%|████▍     | 128/285 [02:13<02:24,  1.09it/s]Loading train:  45%|████▌     | 129/285 [02:14<02:24,  1.08it/s]Loading train:  46%|████▌     | 130/285 [02:14<02:18,  1.12it/s]Loading train:  46%|████▌     | 131/285 [02:15<02:10,  1.18it/s]Loading train:  46%|████▋     | 132/285 [02:16<02:08,  1.19it/s]Loading train:  47%|████▋     | 133/285 [02:17<02:03,  1.23it/s]Loading train:  47%|████▋     | 134/285 [02:18<02:11,  1.15it/s]Loading train:  47%|████▋     | 135/285 [02:18<02:04,  1.21it/s]Loading train:  48%|████▊     | 136/285 [02:19<01:58,  1.25it/s]Loading train:  48%|████▊     | 137/285 [02:20<02:00,  1.23it/s]Loading train:  48%|████▊     | 138/285 [02:21<01:59,  1.23it/s]Loading train:  49%|████▉     | 139/285 [02:22<02:03,  1.18it/s]Loading train:  49%|████▉     | 140/285 [02:23<02:05,  1.15it/s]Loading train:  49%|████▉     | 141/285 [02:23<02:00,  1.20it/s]Loading train:  50%|████▉     | 142/285 [02:24<02:00,  1.19it/s]Loading train:  50%|█████     | 143/285 [02:25<01:59,  1.19it/s]Loading train:  51%|█████     | 144/285 [02:26<01:58,  1.19it/s]Loading train:  51%|█████     | 145/285 [02:27<02:03,  1.13it/s]Loading train:  51%|█████     | 146/285 [02:28<02:02,  1.13it/s]Loading train:  52%|█████▏    | 147/285 [02:29<01:59,  1.16it/s]Loading train:  52%|█████▏    | 148/285 [02:29<01:49,  1.26it/s]Loading train:  52%|█████▏    | 149/285 [02:30<01:54,  1.18it/s]Loading train:  53%|█████▎    | 150/285 [02:31<01:54,  1.18it/s]Loading train:  53%|█████▎    | 151/285 [02:32<01:58,  1.13it/s]Loading train:  53%|█████▎    | 152/285 [02:33<01:51,  1.19it/s]Loading train:  54%|█████▎    | 153/285 [02:34<01:49,  1.21it/s]Loading train:  54%|█████▍    | 154/285 [02:35<01:49,  1.19it/s]Loading train:  54%|█████▍    | 155/285 [02:35<01:54,  1.14it/s]Loading train:  55%|█████▍    | 156/285 [02:36<01:52,  1.15it/s]Loading train:  55%|█████▌    | 157/285 [02:37<01:46,  1.20it/s]Loading train:  55%|█████▌    | 158/285 [02:38<01:49,  1.15it/s]Loading train:  56%|█████▌    | 159/285 [02:39<01:43,  1.22it/s]Loading train:  56%|█████▌    | 160/285 [02:40<01:41,  1.23it/s]Loading train:  56%|█████▋    | 161/285 [02:40<01:45,  1.18it/s]Loading train:  57%|█████▋    | 162/285 [02:41<01:47,  1.14it/s]Loading train:  57%|█████▋    | 163/285 [02:42<01:52,  1.09it/s]Loading train:  58%|█████▊    | 164/285 [02:43<01:50,  1.10it/s]Loading train:  58%|█████▊    | 165/285 [02:44<01:45,  1.14it/s]Loading train:  58%|█████▊    | 166/285 [02:45<01:43,  1.15it/s]Loading train:  59%|█████▊    | 167/285 [02:46<01:50,  1.07it/s]Loading train:  59%|█████▉    | 168/285 [02:47<01:45,  1.11it/s]Loading train:  59%|█████▉    | 169/285 [02:48<01:49,  1.06it/s]Loading train:  60%|█████▉    | 170/285 [02:49<01:44,  1.10it/s]Loading train:  60%|██████    | 171/285 [02:50<01:44,  1.09it/s]Loading train:  60%|██████    | 172/285 [02:51<01:49,  1.03it/s]Loading train:  61%|██████    | 173/285 [02:52<01:45,  1.06it/s]Loading train:  61%|██████    | 174/285 [02:53<01:44,  1.07it/s]Loading train:  61%|██████▏   | 175/285 [02:54<01:44,  1.05it/s]Loading train:  62%|██████▏   | 176/285 [02:54<01:42,  1.07it/s]Loading train:  62%|██████▏   | 177/285 [02:55<01:41,  1.07it/s]Loading train:  62%|██████▏   | 178/285 [02:56<01:34,  1.13it/s]Loading train:  63%|██████▎   | 179/285 [02:57<01:25,  1.24it/s]Loading train:  63%|██████▎   | 180/285 [02:58<01:24,  1.24it/s]Loading train:  64%|██████▎   | 181/285 [02:58<01:20,  1.29it/s]Loading train:  64%|██████▍   | 182/285 [02:59<01:16,  1.34it/s]Loading train:  64%|██████▍   | 183/285 [03:00<01:12,  1.41it/s]Loading train:  65%|██████▍   | 184/285 [03:00<01:11,  1.41it/s]Loading train:  65%|██████▍   | 185/285 [03:01<01:11,  1.41it/s]Loading train:  65%|██████▌   | 186/285 [03:02<01:24,  1.18it/s]Loading train:  66%|██████▌   | 187/285 [03:03<01:25,  1.15it/s]Loading train:  66%|██████▌   | 188/285 [03:04<01:30,  1.08it/s]Loading train:  66%|██████▋   | 189/285 [03:05<01:27,  1.10it/s]Loading train:  67%|██████▋   | 190/285 [03:06<01:24,  1.13it/s]Loading train:  67%|██████▋   | 191/285 [03:07<01:27,  1.08it/s]Loading train:  67%|██████▋   | 192/285 [03:08<01:32,  1.01it/s]Loading train:  68%|██████▊   | 193/285 [03:09<01:28,  1.04it/s]Loading train:  68%|██████▊   | 194/285 [03:10<01:25,  1.07it/s]Loading train:  68%|██████▊   | 195/285 [03:11<01:20,  1.12it/s]Loading train:  69%|██████▉   | 196/285 [03:12<01:20,  1.10it/s]Loading train:  69%|██████▉   | 197/285 [03:12<01:20,  1.09it/s]Loading train:  69%|██████▉   | 198/285 [03:13<01:19,  1.10it/s]Loading train:  70%|██████▉   | 199/285 [03:14<01:14,  1.15it/s]Loading train:  70%|███████   | 200/285 [03:15<01:12,  1.18it/s]Loading train:  71%|███████   | 201/285 [03:16<01:17,  1.09it/s]Loading train:  71%|███████   | 202/285 [03:17<01:17,  1.07it/s]Loading train:  71%|███████   | 203/285 [03:18<01:15,  1.09it/s]Loading train:  72%|███████▏  | 204/285 [03:19<01:14,  1.09it/s]Loading train:  72%|███████▏  | 205/285 [03:20<01:14,  1.08it/s]Loading train:  72%|███████▏  | 206/285 [03:20<01:08,  1.15it/s]Loading train:  73%|███████▎  | 207/285 [03:22<01:12,  1.07it/s]Loading train:  73%|███████▎  | 208/285 [03:23<01:13,  1.05it/s]Loading train:  73%|███████▎  | 209/285 [03:24<01:15,  1.01it/s]Loading train:  74%|███████▎  | 210/285 [03:24<01:10,  1.06it/s]Loading train:  74%|███████▍  | 211/285 [03:25<01:04,  1.15it/s]Loading train:  74%|███████▍  | 212/285 [03:26<01:07,  1.08it/s]Loading train:  75%|███████▍  | 213/285 [03:27<01:07,  1.06it/s]Loading train:  75%|███████▌  | 214/285 [03:28<01:05,  1.09it/s]Loading train:  75%|███████▌  | 215/285 [03:29<01:03,  1.10it/s]Loading train:  76%|███████▌  | 216/285 [03:30<00:57,  1.19it/s]Loading train:  76%|███████▌  | 217/285 [03:31<01:03,  1.07it/s]Loading train:  76%|███████▋  | 218/285 [03:32<01:03,  1.05it/s]Loading train:  77%|███████▋  | 219/285 [03:33<01:05,  1.00it/s]Loading train:  77%|███████▋  | 220/285 [03:34<01:03,  1.02it/s]Loading train:  78%|███████▊  | 221/285 [03:35<01:01,  1.05it/s]Loading train:  78%|███████▊  | 222/285 [03:36<01:00,  1.04it/s]Loading train:  78%|███████▊  | 223/285 [03:37<00:56,  1.10it/s]Loading train:  79%|███████▊  | 224/285 [03:38<00:59,  1.02it/s]Loading train:  79%|███████▉  | 225/285 [03:39<00:57,  1.05it/s]Loading train:  79%|███████▉  | 226/285 [03:40<00:57,  1.02it/s]Loading train:  80%|███████▉  | 227/285 [03:41<00:57,  1.01it/s]Loading train:  80%|████████  | 228/285 [03:42<01:00,  1.06s/it]Loading train:  80%|████████  | 229/285 [03:43<01:00,  1.08s/it]Loading train:  81%|████████  | 230/285 [03:44<00:56,  1.02s/it]Loading train:  81%|████████  | 231/285 [03:45<00:53,  1.02it/s]Loading train:  81%|████████▏ | 232/285 [03:46<00:50,  1.05it/s]Loading train:  82%|████████▏ | 233/285 [03:47<00:49,  1.05it/s]Loading train:  82%|████████▏ | 234/285 [03:48<00:50,  1.02it/s]Loading train:  82%|████████▏ | 235/285 [03:48<00:47,  1.06it/s]Loading train:  83%|████████▎ | 236/285 [03:50<00:48,  1.01it/s]Loading train:  83%|████████▎ | 237/285 [03:51<00:47,  1.00it/s]Loading train:  84%|████████▎ | 238/285 [03:52<00:46,  1.01it/s]Loading train:  84%|████████▍ | 239/285 [03:52<00:44,  1.04it/s]Loading train:  84%|████████▍ | 240/285 [03:53<00:44,  1.01it/s]Loading train:  85%|████████▍ | 241/285 [03:54<00:43,  1.02it/s]Loading train:  85%|████████▍ | 242/285 [03:55<00:41,  1.04it/s]Loading train:  85%|████████▌ | 243/285 [03:56<00:40,  1.04it/s]Loading train:  86%|████████▌ | 244/285 [03:57<00:40,  1.00it/s]Loading train:  86%|████████▌ | 245/285 [03:58<00:35,  1.13it/s]Loading train:  86%|████████▋ | 246/285 [03:59<00:33,  1.17it/s]Loading train:  87%|████████▋ | 247/285 [04:00<00:35,  1.07it/s]Loading train:  87%|████████▋ | 248/285 [04:01<00:34,  1.06it/s]Loading train:  87%|████████▋ | 249/285 [04:02<00:31,  1.13it/s]Loading train:  88%|████████▊ | 250/285 [04:02<00:30,  1.15it/s]Loading train:  88%|████████▊ | 251/285 [04:03<00:28,  1.20it/s]Loading train:  88%|████████▊ | 252/285 [04:04<00:28,  1.18it/s]Loading train:  89%|████████▉ | 253/285 [04:05<00:29,  1.09it/s]Loading train:  89%|████████▉ | 254/285 [04:06<00:29,  1.05it/s]Loading train:  89%|████████▉ | 255/285 [04:07<00:28,  1.05it/s]Loading train:  90%|████████▉ | 256/285 [04:08<00:26,  1.08it/s]Loading train:  90%|█████████ | 257/285 [04:09<00:24,  1.12it/s]Loading train:  91%|█████████ | 258/285 [04:10<00:25,  1.05it/s]Loading train:  91%|█████████ | 259/285 [04:11<00:25,  1.04it/s]Loading train:  91%|█████████ | 260/285 [04:12<00:23,  1.06it/s]Loading train:  92%|█████████▏| 261/285 [04:13<00:20,  1.15it/s]Loading train:  92%|█████████▏| 262/285 [04:13<00:18,  1.23it/s]Loading train:  92%|█████████▏| 263/285 [04:14<00:16,  1.31it/s]Loading train:  93%|█████████▎| 264/285 [04:15<00:16,  1.27it/s]Loading train:  93%|█████████▎| 265/285 [04:16<00:16,  1.18it/s]Loading train:  93%|█████████▎| 266/285 [04:16<00:14,  1.27it/s]Loading train:  94%|█████████▎| 267/285 [04:17<00:14,  1.26it/s]Loading train:  94%|█████████▍| 268/285 [04:18<00:14,  1.20it/s]Loading train:  94%|█████████▍| 269/285 [04:19<00:13,  1.18it/s]Loading train:  95%|█████████▍| 270/285 [04:20<00:12,  1.24it/s]Loading train:  95%|█████████▌| 271/285 [04:20<00:10,  1.32it/s]Loading train:  95%|█████████▌| 272/285 [04:21<00:10,  1.24it/s]Loading train:  96%|█████████▌| 273/285 [04:22<00:09,  1.23it/s]Loading train:  96%|█████████▌| 274/285 [04:23<00:08,  1.27it/s]Loading train:  96%|█████████▋| 275/285 [04:24<00:08,  1.14it/s]Loading train:  97%|█████████▋| 276/285 [04:25<00:07,  1.13it/s]Loading train:  97%|█████████▋| 277/285 [04:26<00:06,  1.16it/s]Loading train:  98%|█████████▊| 278/285 [04:26<00:05,  1.18it/s]Loading train:  98%|█████████▊| 279/285 [04:27<00:05,  1.19it/s]Loading train:  98%|█████████▊| 280/285 [04:28<00:04,  1.14it/s]Loading train:  99%|█████████▊| 281/285 [04:29<00:03,  1.16it/s]Loading train:  99%|█████████▉| 282/285 [04:30<00:02,  1.24it/s]Loading train:  99%|█████████▉| 283/285 [04:31<00:01,  1.13it/s]Loading train: 100%|█████████▉| 284/285 [04:32<00:00,  1.07it/s]Loading train: 100%|██████████| 285/285 [04:33<00:00,  1.04it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|          | 3/285 [00:00<00:11, 25.48it/s]concatenating: train:   4%|▍         | 12/285 [00:00<00:08, 32.23it/s]concatenating: train:   8%|▊         | 24/285 [00:00<00:06, 41.12it/s]concatenating: train:  13%|█▎        | 38/285 [00:00<00:04, 52.16it/s]concatenating: train:  21%|██        | 60/285 [00:00<00:03, 67.39it/s]concatenating: train:  33%|███▎      | 95/285 [00:00<00:02, 88.78it/s]concatenating: train:  45%|████▌     | 129/285 [00:00<00:01, 113.96it/s]concatenating: train:  59%|█████▊    | 167/285 [00:00<00:00, 143.93it/s]concatenating: train:  71%|███████   | 202/285 [00:00<00:00, 174.14it/s]concatenating: train:  84%|████████▎ | 238/285 [00:01<00:00, 206.01it/s]concatenating: train:  97%|█████████▋| 276/285 [00:01<00:00, 238.60it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 245.75it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.28s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.25s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.25s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 821.29it/s]2019-07-10 22:45:17.019635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-10 22:45:17.019766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-10 22:45:17.019785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-10 22:45:17.019795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-10 22:45:17.020251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.22it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.13it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  5.98it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.57it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.64it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.47it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.98it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.82it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.47it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.17it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.72it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  8.89it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.20it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.55it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.31it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.66it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.73it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.70it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.65it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 30)   4080        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 40, 45)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 60)   24360       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 20, 105)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 105)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 105)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 105)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 15)   4065        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 45)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 45)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 20)   8120        dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 80, 20)   0           activation_11[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 65)   0           dropout_5[0][0]                  
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 13)   858         concatenate_7[0][0]              
==================================================================================================
Total params: 134,938
Trainable params: 36,438
Non-trainable params: 98,500
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 13s - loss: 3.0742 - acc: 0.4848 - mDice: 0.0872 - val_loss: 2.4191 - val_acc: 0.8722 - val_mDice: 0.1941

Epoch 00001: val_mDice improved from -inf to 0.19409, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 8s - loss: 1.2139 - acc: 0.8811 - mDice: 0.3193 - val_loss: 2.2595 - val_acc: 0.9135 - val_mDice: 0.2516

Epoch 00002: val_mDice improved from 0.19409 to 0.25156, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 8s - loss: 0.8157 - acc: 0.8906 - mDice: 0.4373 - val_loss: 1.4069 - val_acc: 0.9183 - val_mDice: 0.4182

Epoch 00003: val_mDice improved from 0.25156 to 0.41818, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 8s - loss: 0.6765 - acc: 0.8968 - mDice: 0.4963 - val_loss: 1.3499 - val_acc: 0.9106 - val_mDice: 0.4502

Epoch 00004: val_mDice improved from 0.41818 to 0.45017, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 8s - loss: 0.5952 - acc: 0.9029 - mDice: 0.5370 - val_loss: 1.1973 - val_acc: 0.9256 - val_mDice: 0.5095

Epoch 00005: val_mDice improved from 0.45017 to 0.50949, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 8s - loss: 0.5501 - acc: 0.9094 - mDice: 0.5622 - val_loss: 1.1074 - val_acc: 0.9348 - val_mDice: 0.5218

Epoch 00006: val_mDice improved from 0.50949 to 0.52181, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 8s - loss: 0.5152 - acc: 0.9151 - mDice: 0.5824 - val_loss: 1.0820 - val_acc: 0.9337 - val_mDice: 0.5447

Epoch 00007: val_mDice improved from 0.52181 to 0.54465, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 8s - loss: 0.4915 - acc: 0.9192 - mDice: 0.5966 - val_loss: 1.1532 - val_acc: 0.9328 - val_mDice: 0.4852

Epoch 00008: val_mDice did not improve from 0.54465
Epoch 9/300
 - 8s - loss: 0.4718 - acc: 0.9221 - mDice: 0.6090 - val_loss: 1.0391 - val_acc: 0.9393 - val_mDice: 0.5507

Epoch 00009: val_mDice improved from 0.54465 to 0.55071, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 8s - loss: 0.4571 - acc: 0.9242 - mDice: 0.6182 - val_loss: 1.0507 - val_acc: 0.9393 - val_mDice: 0.5347

Epoch 00010: val_mDice did not improve from 0.55071
Epoch 11/300
 - 8s - loss: 0.4445 - acc: 0.9257 - mDice: 0.6261 - val_loss: 1.0429 - val_acc: 0.9385 - val_mDice: 0.5359

Epoch 00011: val_mDice did not improve from 0.55071
Epoch 12/300
 - 8s - loss: 0.4377 - acc: 0.9267 - mDice: 0.6306 - val_loss: 1.0363 - val_acc: 0.9411 - val_mDice: 0.5435

Epoch 00012: val_mDice did not improve from 0.55071
Epoch 13/300
 - 8s - loss: 0.4247 - acc: 0.9280 - mDice: 0.6390 - val_loss: 1.0332 - val_acc: 0.9333 - val_mDice: 0.5557

Epoch 00013: val_mDice improved from 0.55071 to 0.55566, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 8s - loss: 0.4207 - acc: 0.9290 - mDice: 0.6417 - val_loss: 1.0419 - val_acc: 0.9388 - val_mDice: 0.5146

Epoch 00014: val_mDice did not improve from 0.55566
Epoch 15/300
 - 8s - loss: 0.4150 - acc: 0.9294 - mDice: 0.6454 - val_loss: 0.9967 - val_acc: 0.9421 - val_mDice: 0.5585

Epoch 00015: val_mDice improved from 0.55566 to 0.55847, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 8s - loss: 0.4081 - acc: 0.9302 - mDice: 0.6500 - val_loss: 1.0039 - val_acc: 0.9435 - val_mDice: 0.5592

Epoch 00016: val_mDice improved from 0.55847 to 0.55919, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 8s - loss: 0.4034 - acc: 0.9309 - mDice: 0.6531 - val_loss: 1.0148 - val_acc: 0.9422 - val_mDice: 0.5423

Epoch 00017: val_mDice did not improve from 0.55919
Epoch 18/300
 - 8s - loss: 0.3978 - acc: 0.9316 - mDice: 0.6568 - val_loss: 0.9990 - val_acc: 0.9399 - val_mDice: 0.5533

Epoch 00018: val_mDice did not improve from 0.55919
Epoch 19/300
 - 8s - loss: 0.3947 - acc: 0.9319 - mDice: 0.6590 - val_loss: 1.0402 - val_acc: 0.9410 - val_mDice: 0.5316

Epoch 00019: val_mDice did not improve from 0.55919
Epoch 20/300
 - 8s - loss: 0.3918 - acc: 0.9322 - mDice: 0.6611 - val_loss: 0.9930 - val_acc: 0.9418 - val_mDice: 0.5429

Epoch 00020: val_mDice did not improve from 0.55919
Epoch 21/300
 - 8s - loss: 0.3864 - acc: 0.9327 - mDice: 0.6646 - val_loss: 1.0013 - val_acc: 0.9430 - val_mDice: 0.5476

Epoch 00021: val_mDice did not improve from 0.55919
Epoch 22/300
 - 8s - loss: 0.3832 - acc: 0.9331 - mDice: 0.6668 - val_loss: 0.9681 - val_acc: 0.9437 - val_mDice: 0.5555

Epoch 00022: val_mDice did not improve from 0.55919
Epoch 23/300
 - 8s - loss: 0.3797 - acc: 0.9337 - mDice: 0.6692 - val_loss: 1.0258 - val_acc: 0.9426 - val_mDice: 0.5375

Epoch 00023: val_mDice did not improve from 0.55919
Epoch 24/300
 - 8s - loss: 0.3764 - acc: 0.9340 - mDice: 0.6715 - val_loss: 0.9407 - val_acc: 0.9416 - val_mDice: 0.5697

Epoch 00024: val_mDice improved from 0.55919 to 0.56966, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 25/300
 - 8s - loss: 0.3751 - acc: 0.9343 - mDice: 0.6724 - val_loss: 0.9744 - val_acc: 0.9438 - val_mDice: 0.5618

Epoch 00025: val_mDice did not improve from 0.56966
Epoch 26/300
 - 8s - loss: 0.3715 - acc: 0.9348 - mDice: 0.6749 - val_loss: 0.9358 - val_acc: 0.9430 - val_mDice: 0.5766

Epoch 00026: val_mDice improved from 0.56966 to 0.57657, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 27/300
 - 8s - loss: 0.3699 - acc: 0.9352 - mDice: 0.6760 - val_loss: 0.9663 - val_acc: 0.9423 - val_mDice: 0.5302

Epoch 00027: val_mDice did not improve from 0.57657
Epoch 28/300
 - 8s - loss: 0.3657 - acc: 0.9356 - mDice: 0.6790 - val_loss: 0.9314 - val_acc: 0.9442 - val_mDice: 0.5568

Epoch 00028: val_mDice did not improve from 0.57657
Epoch 29/300
 - 8s - loss: 0.3654 - acc: 0.9358 - mDice: 0.6791 - val_loss: 0.9517 - val_acc: 0.9431 - val_mDice: 0.5422

Epoch 00029: val_mDice did not improve from 0.57657
Epoch 30/300
 - 8s - loss: 0.3613 - acc: 0.9362 - mDice: 0.6820 - val_loss: 1.0910 - val_acc: 0.9367 - val_mDice: 0.4703

Epoch 00030: val_mDice did not improve from 0.57657
Epoch 31/300
 - 8s - loss: 0.3595 - acc: 0.9366 - mDice: 0.6832 - val_loss: 0.9939 - val_acc: 0.9401 - val_mDice: 0.5127

Epoch 00031: val_mDice did not improve from 0.57657
Epoch 32/300
 - 8s - loss: 0.3579 - acc: 0.9368 - mDice: 0.6844 - val_loss: 0.9444 - val_acc: 0.9415 - val_mDice: 0.5587

Epoch 00032: val_mDice did not improve from 0.57657
Epoch 33/300
 - 8s - loss: 0.3565 - acc: 0.9370 - mDice: 0.6855 - val_loss: 0.8878 - val_acc: 0.9409 - val_mDice: 0.5742

Epoch 00033: val_mDice did not improve from 0.57657
Epoch 34/300
 - 8s - loss: 0.3533 - acc: 0.9371 - mDice: 0.6876 - val_loss: 0.9165 - val_acc: 0.9442 - val_mDice: 0.5500

Epoch 00034: val_mDice did not improve from 0.57657
Epoch 35/300
 - 8s - loss: 0.3514 - acc: 0.9374 - mDice: 0.6889 - val_loss: 0.9267 - val_acc: 0.9390 - val_mDice: 0.5673

Epoch 00035: val_mDice did not improve from 0.57657
Epoch 36/300
 - 8s - loss: 0.3519 - acc: 0.9374 - mDice: 0.6886 - val_loss: 0.8948 - val_acc: 0.9443 - val_mDice: 0.5458

Epoch 00036: val_mDice did not improve from 0.57657
Epoch 37/300
 - 8s - loss: 0.3495 - acc: 0.9376 - mDice: 0.6903 - val_loss: 0.9424 - val_acc: 0.9440 - val_mDice: 0.5456

Epoch 00037: val_mDice did not improve from 0.57657
Epoch 38/300
 - 8s - loss: 0.3475 - acc: 0.9379 - mDice: 0.6918 - val_loss: 0.9122 - val_acc: 0.9441 - val_mDice: 0.5581

Epoch 00038: val_mDice did not improve from 0.57657
Epoch 39/300
 - 8s - loss: 0.3443 - acc: 0.9382 - mDice: 0.6940 - val_loss: 0.9448 - val_acc: 0.9423 - val_mDice: 0.5483

Epoch 00039: val_mDice did not improve from 0.57657
Epoch 40/300
 - 8s - loss: 0.3442 - acc: 0.9382 - mDice: 0.6942 - val_loss: 0.8792 - val_acc: 0.9438 - val_mDice: 0.5590

Epoch 00040: val_mDice did not improve from 0.57657
Epoch 41/300
 - 8s - loss: 0.3415 - acc: 0.9384 - mDice: 0.6960 - val_loss: 0.8918 - val_acc: 0.9436 - val_mDice: 0.5800

Epoch 00041: val_mDice improved from 0.57657 to 0.58000, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 42/300
 - 8s - loss: 0.3407 - acc: 0.9386 - mDice: 0.6967 - val_loss: 0.8460 - val_acc: 0.9448 - val_mDice: 0.5881

Epoch 00042: val_mDice improved from 0.58000 to 0.58811, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 43/300
 - 8s - loss: 0.3374 - acc: 0.9389 - mDice: 0.6990 - val_loss: 0.8966 - val_acc: 0.9447 - val_mDice: 0.5545

Epoch 00043: val_mDice did not improve from 0.58811
Epoch 44/300
 - 8s - loss: 0.3388 - acc: 0.9388 - mDice: 0.6980 - val_loss: 0.9997 - val_acc: 0.9361 - val_mDice: 0.5659

Epoch 00044: val_mDice did not improve from 0.58811
Epoch 45/300
 - 8s - loss: 0.3371 - acc: 0.9389 - mDice: 0.6993 - val_loss: 0.8681 - val_acc: 0.9411 - val_mDice: 0.5700

Epoch 00045: val_mDice did not improve from 0.58811
Epoch 46/300
 - 8s - loss: 0.3353 - acc: 0.9389 - mDice: 0.7004 - val_loss: 0.8703 - val_acc: 0.9439 - val_mDice: 0.5649

Epoch 00046: val_mDice did not improve from 0.58811
Epoch 47/300
 - 8s - loss: 0.3326 - acc: 0.9394 - mDice: 0.7025 - val_loss: 0.9132 - val_acc: 0.9420 - val_mDice: 0.5288

Epoch 00047: val_mDice did not improve from 0.58811
Epoch 48/300
 - 8s - loss: 0.3338 - acc: 0.9392 - mDice: 0.7017 - val_loss: 0.8988 - val_acc: 0.9416 - val_mDice: 0.5651

Epoch 00048: val_mDice did not improve from 0.58811
Epoch 49/300
 - 8s - loss: 0.3311 - acc: 0.9394 - mDice: 0.7036 - val_loss: 0.8066 - val_acc: 0.9427 - val_mDice: 0.5539

Epoch 00049: val_mDice did not improve from 0.58811
Epoch 50/300
 - 8s - loss: 0.3301 - acc: 0.9397 - mDice: 0.7043 - val_loss: 0.8379 - val_acc: 0.9448 - val_mDice: 0.5712

Epoch 00050: val_mDice did not improve from 0.58811
Epoch 51/300
 - 8s - loss: 0.3292 - acc: 0.9396 - mDice: 0.7051 - val_loss: 0.7946 - val_acc: 0.9453 - val_mDice: 0.5707

Epoch 00051: val_mDice did not improve from 0.58811
Epoch 52/300
 - 8s - loss: 0.3281 - acc: 0.9399 - mDice: 0.7058 - val_loss: 0.8873 - val_acc: 0.9421 - val_mDice: 0.5274

Epoch 00052: val_mDice did not improve from 0.58811
Epoch 53/300
 - 8s - loss: 0.3273 - acc: 0.9397 - mDice: 0.7063 - val_loss: 0.9344 - val_acc: 0.9342 - val_mDice: 0.5505

Epoch 00053: val_mDice did not improve from 0.58811
Epoch 54/300
 - 8s - loss: 0.3262 - acc: 0.9400 - mDice: 0.7072 - val_loss: 0.8806 - val_acc: 0.9323 - val_mDice: 0.5495

Epoch 00054: val_mDice did not improve from 0.58811
Epoch 55/300
 - 8s - loss: 0.3263 - acc: 0.9398 - mDice: 0.7070 - val_loss: 0.8835 - val_acc: 0.9397 - val_mDice: 0.5712

Epoch 00055: val_mDice did not improve from 0.58811
Epoch 56/300
 - 8s - loss: 0.3252 - acc: 0.9400 - mDice: 0.7079 - val_loss: 0.8562 - val_acc: 0.9421 - val_mDice: 0.5591

Epoch 00056: val_mDice did not improve from 0.58811
Epoch 57/300
 - 8s - loss: 0.3240 - acc: 0.9403 - mDice: 0.7088 - val_loss: 0.8536 - val_acc: 0.9448 - val_mDice: 0.5727

Epoch 00057: val_mDice did not improve from 0.58811
Epoch 58/300
 - 8s - loss: 0.3211 - acc: 0.9404 - mDice: 0.7109 - val_loss: 0.8006 - val_acc: 0.9377 - val_mDice: 0.5794

Epoch 00058: val_mDice did not improve from 0.58811
Epoch 59/300
 - 8s - loss: 0.3224 - acc: 0.9405 - mDice: 0.7100 - val_loss: 0.8307 - val_acc: 0.9424 - val_mDice: 0.5781

Epoch 00059: val_mDice did not improve from 0.58811
Epoch 60/300
 - 8s - loss: 0.3213 - acc: 0.9404 - mDice: 0.7107 - val_loss: 0.9107 - val_acc: 0.9317 - val_mDice: 0.5481

Epoch 00060: val_mDice did not improve from 0.58811
Epoch 61/300
 - 8s - loss: 0.3201 - acc: 0.9404 - mDice: 0.7117 - val_loss: 0.7971 - val_acc: 0.9447 - val_mDice: 0.5774

Epoch 00061: val_mDice did not improve from 0.58811
Epoch 62/300
 - 8s - loss: 0.3188 - acc: 0.9407 - mDice: 0.7126 - val_loss: 0.8392 - val_acc: 0.9434 - val_mDice: 0.5609

Epoch 00062: val_mDice did not improve from 0.58811
Epoch 63/300
 - 8s - loss: 0.3190 - acc: 0.9407 - mDice: 0.7125 - val_loss: 0.7716 - val_acc: 0.9389 - val_mDice: 0.5475

Epoch 00063: val_mDice did not improve from 0.58811
Epoch 64/300
 - 8s - loss: 0.3185 - acc: 0.9407 - mDice: 0.7128 - val_loss: 0.7802 - val_acc: 0.9415 - val_mDice: 0.5626

Epoch 00064: val_mDice did not improve from 0.58811
Epoch 65/300
 - 8s - loss: 0.3179 - acc: 0.9408 - mDice: 0.7133 - val_loss: 0.7561 - val_acc: 0.9421 - val_mDice: 0.5685

Epoch 00065: val_mDice did not improve from 0.58811
Epoch 66/300
 - 8s - loss: 0.3180 - acc: 0.9406 - mDice: 0.7133 - val_loss: 0.7618 - val_acc: 0.9404 - val_mDice: 0.5653

Epoch 00066: val_mDice did not improve from 0.58811
Epoch 67/300
 - 8s - loss: 0.3154 - acc: 0.9410 - mDice: 0.7152 - val_loss: 0.7865 - val_acc: 0.9421 - val_mDice: 0.5726

Epoch 00067: val_mDice did not improve from 0.58811
Epoch 68/300
 - 8s - loss: 0.3157 - acc: 0.9409 - mDice: 0.7149 - val_loss: 0.7659 - val_acc: 0.9355 - val_mDice: 0.5493

Epoch 00068: val_mDice did not improve from 0.58811
Epoch 69/300
 - 8s - loss: 0.3134 - acc: 0.9411 - mDice: 0.7166 - val_loss: 0.7797 - val_acc: 0.9445 - val_mDice: 0.5386

Epoch 00069: val_mDice did not improve from 0.58811
Epoch 70/300
 - 8s - loss: 0.3133 - acc: 0.9413 - mDice: 0.7168 - val_loss: 0.7908 - val_acc: 0.9450 - val_mDice: 0.5693

Epoch 00070: val_mDice did not improve from 0.58811
Epoch 71/300
 - 8s - loss: 0.3135 - acc: 0.9411 - mDice: 0.7167 - val_loss: 0.8628 - val_acc: 0.9410 - val_mDice: 0.5506

Epoch 00071: val_mDice did not improve from 0.58811
Epoch 72/300
 - 9s - loss: 0.3119 - acc: 0.9414 - mDice: 0.7178 - val_loss: 0.7943 - val_acc: 0.9432 - val_mDice: 0.5672

Epoch 00072: val_mDice did not improve from 0.58811
Epoch 73/300
 - 9s - loss: 0.3108 - acc: 0.9414 - mDice: 0.7185 - val_loss: 0.7753 - val_acc: 0.9422 - val_mDice: 0.5207

Epoch 00073: val_mDice did not improve from 0.58811
Epoch 74/300
 - 8s - loss: 0.3117 - acc: 0.9414 - mDice: 0.7179 - val_loss: 0.7644 - val_acc: 0.9462 - val_mDice: 0.5730

Epoch 00074: val_mDice did not improve from 0.58811
Epoch 75/300
 - 8s - loss: 0.3105 - acc: 0.9416 - mDice: 0.7188 - val_loss: 0.7917 - val_acc: 0.9444 - val_mDice: 0.5483

Epoch 00075: val_mDice did not improve from 0.58811
Epoch 76/300
 - 8s - loss: 0.3109 - acc: 0.9416 - mDice: 0.7186 - val_loss: 0.8833 - val_acc: 0.9287 - val_mDice: 0.5231

Epoch 00076: val_mDice did not improve from 0.58811
Epoch 77/300
 - 8s - loss: 0.3100 - acc: 0.9414 - mDice: 0.7191 - val_loss: 0.7297 - val_acc: 0.9415 - val_mDice: 0.5702

Epoch 00077: val_mDice did not improve from 0.58811
Epoch 78/300
 - 8s - loss: 0.3104 - acc: 0.9415 - mDice: 0.7189 - val_loss: 0.8423 - val_acc: 0.9268 - val_mDice: 0.5351

Epoch 00078: val_mDice did not improve from 0.58811
Epoch 79/300
 - 9s - loss: 0.3078 - acc: 0.9417 - mDice: 0.7207 - val_loss: 0.8225 - val_acc: 0.9331 - val_mDice: 0.5545

Epoch 00079: val_mDice did not improve from 0.58811
Epoch 80/300
 - 8s - loss: 0.3064 - acc: 0.9419 - mDice: 0.7219 - val_loss: 0.7127 - val_acc: 0.9408 - val_mDice: 0.5525

Epoch 00080: val_mDice did not improve from 0.58811
Epoch 81/300
 - 8s - loss: 0.3067 - acc: 0.9417 - mDice: 0.7216 - val_loss: 0.8121 - val_acc: 0.9433 - val_mDice: 0.5548

Epoch 00081: val_mDice did not improve from 0.58811
Epoch 82/300
 - 8s - loss: 0.3077 - acc: 0.9419 - mDice: 0.7209 - val_loss: 0.6764 - val_acc: 0.9420 - val_mDice: 0.5482

Epoch 00082: val_mDice did not improve from 0.58811
Restoring model weights from the end of the best epoch
Epoch 00082: early stopping
{'val_loss': [2.4190887950715565, 2.259509881337484, 1.4068937301635742, 1.3499094191051664, 1.1973382064274378, 1.107424531664167, 1.0820348603384835, 1.1532391480037145, 1.039072763352167, 1.050729206630162, 1.0428974060785203, 1.0362985474722726, 1.0331652732122512, 1.041886908667428, 0.9967109475816999, 1.0039377893720354, 1.0148325193495977, 0.99901625088283, 1.0401854174477714, 0.9930298668997628, 1.0013250850495838, 0.9681420212700254, 1.0257827667962938, 0.9406737429755074, 0.9743689809526715, 0.935803044409979, 0.9663379078819638, 0.9314351990109399, 0.9516525495620001, 1.0909860247657412, 0.9939166364215669, 0.9444202468508766, 0.8877702951431274, 0.9164894421895345, 0.9267012164706275, 0.8947821117582775, 0.9424005803607759, 0.912215721039545, 0.94475785891215, 0.8792275247119722, 0.8918037244251796, 0.8459683429627192, 0.8966003145490374, 0.9997421219235375, 0.8680576199576968, 0.870270570119222, 0.9132270585922968, 0.8987629754202706, 0.8065574963887533, 0.8378766037168957, 0.794632803826105, 0.8872531936282203, 0.9343687579745338, 0.8805829456874302, 0.8835312128067017, 0.8562342893509638, 0.8535840057191395, 0.8005700735818773, 0.8306997673852103, 0.9107026599702381, 0.7970802783966064, 0.8391768478211903, 0.7715633483160109, 0.7802195776076544, 0.7561168840953282, 0.7618278435298375, 0.7864908150264195, 0.7658822990599132, 0.779733555657523, 0.7907883893875849, 0.8628121784755162, 0.7942875794001988, 0.7752966426667713, 0.7644078845069522, 0.7916908264160156, 0.8833005995977492, 0.7297312759217762, 0.8423430351983934, 0.8224746953873407, 0.7127002193814233, 0.8120720727103097, 0.676449559983753], 'val_acc': [0.8721566115106855, 0.9134752835546222, 0.9183310298692613, 0.9106158585775466, 0.9256158215659005, 0.9347939689954122, 0.9336790357317243, 0.9328181999070304, 0.9393383491606939, 0.9393131903239659, 0.9385439299401783, 0.9411195317904154, 0.9332944381804693, 0.9388072178477332, 0.9421405934152149, 0.9434867444492522, 0.9421794925417218, 0.9399221482731047, 0.9410119085084825, 0.9418063419205802, 0.9429807804879689, 0.9436675792648679, 0.9425572554270426, 0.9415522104217893, 0.9437591632207235, 0.9430448810259501, 0.9423306045078096, 0.9441575124150231, 0.9430860593205407, 0.9366827096257891, 0.9401327655428932, 0.9414972407477242, 0.9408813998812721, 0.9441712243216378, 0.9390064250855219, 0.9442880040123349, 0.9440270350092933, 0.944118565037137, 0.9422687547547477, 0.9437980822154454, 0.9436492863155547, 0.9448076997484479, 0.9447412831442696, 0.9361080470539275, 0.9411355427333287, 0.9439377472514198, 0.941950573807671, 0.9416369086220151, 0.9426968892415365, 0.9447871020862034, 0.9453457026254564, 0.9420512971423921, 0.9341712565649123, 0.9322985126858666, 0.9396657376062303, 0.9420650402704874, 0.9447847775050572, 0.9377083239101228, 0.94240384158634, 0.9316895405451456, 0.9446611631484259, 0.9433974283082145, 0.9389331596238273, 0.9414537690934681, 0.9420924896285647, 0.9403915093058631, 0.9420535848254249, 0.9354601530801683, 0.9444597108023507, 0.945027490456899, 0.9410142132214138, 0.9432165622711182, 0.9422092749958947, 0.9462065072286696, 0.9443933339346022, 0.9287477164041429, 0.9415224109377179, 0.9268200738089425, 0.9330563233012245, 0.9407646400587899, 0.9432967220033918, 0.9420283976055327], 'val_mDice': [0.19409335067584402, 0.25156451016664505, 0.4181834544454302, 0.4501690962130115, 0.5094928101059937, 0.5218137876973266, 0.5446531623601913, 0.48521832057407926, 0.5507121332699344, 0.5347275545909291, 0.5358948161204656, 0.5434578476207597, 0.5556573866023904, 0.5146487830650239, 0.5584732570818493, 0.5591887460932845, 0.5423251857005414, 0.553319836301463, 0.5315889203477473, 0.5429093906922, 0.5476402108158384, 0.5554963980047476, 0.537491749972105, 0.5696642957627773, 0.5617587112245106, 0.576571500372319, 0.5302299266414983, 0.5567695305106186, 0.5421893550526529, 0.4703224485828763, 0.5126840960057009, 0.5587399869802452, 0.5741581581532955, 0.5499886073881671, 0.5673441351169631, 0.5457512466680436, 0.5455971583724022, 0.5581461877695152, 0.5483229335929666, 0.55897779691787, 0.5799956889379592, 0.5881128988805271, 0.5544561048348745, 0.5658599982659022, 0.5699741333013489, 0.5649379804020837, 0.5287698007055691, 0.565058151171321, 0.5539458532418523, 0.5712419624129931, 0.5706701101291747, 0.5274433399594965, 0.5505420260486149, 0.549529285303184, 0.571181201509067, 0.5591117874497459, 0.5726919021634829, 0.5793556347489357, 0.5781065633609181, 0.5480639877773467, 0.5773835086396762, 0.560928400605917, 0.5475418239477134, 0.5626092758916673, 0.5685046457108998, 0.5653048665041015, 0.572612305127439, 0.5493097074684643, 0.5386176100444227, 0.5692696046261561, 0.5506200779761586, 0.5672080860961051, 0.520667382649013, 0.5730227286971751, 0.5482862235179969, 0.5230861091542811, 0.5702202909049534, 0.5350987453545842, 0.5544805448679697, 0.552457277086519, 0.5547886501465525, 0.5482405200600624], 'loss': [3.0742208169378573, 1.2138574428587767, 0.8157114989959323, 0.6764621848496533, 0.5951750650326825, 0.5501154684505642, 0.5152063182330163, 0.491524428008539, 0.4717717616227589, 0.4571276165879667, 0.4444895896156422, 0.43770558923247327, 0.42466927934685766, 0.4206756477827554, 0.4150057344542824, 0.4080614190708816, 0.40344859588139315, 0.39777851083477683, 0.3947081286794123, 0.3917803079355239, 0.3864283292468674, 0.3832204648300198, 0.37968703755666827, 0.3763647268095158, 0.37509096550739224, 0.37151525190438706, 0.3699433553223438, 0.36569994418566365, 0.365446089032024, 0.3612810902531629, 0.35953891750749006, 0.3579411715849392, 0.35645882492008435, 0.35334187463940003, 0.351402998435973, 0.3519499084497661, 0.3494861137035014, 0.3474796893671572, 0.34425977832530535, 0.3442239136693104, 0.3414791266663538, 0.34065531426618756, 0.3374420137954213, 0.33875744385206336, 0.3371132592750878, 0.33534507291703547, 0.3325896196186554, 0.33376832569819875, 0.3310652555287723, 0.330092893174004, 0.3291531340658079, 0.3281003072447048, 0.3273373349153722, 0.32618818926930726, 0.3263465912902381, 0.3251870206056451, 0.3240396560605882, 0.3210948281017415, 0.32244245951314043, 0.3213104001756852, 0.3201104331469292, 0.31880680864225447, 0.3190362969930861, 0.31854726445107234, 0.31792225955721726, 0.31798552064875407, 0.3154049939633059, 0.3156555775091187, 0.3134420894693956, 0.31329452285353837, 0.31348072166201096, 0.31185414864305866, 0.31083433330346333, 0.31170688543977915, 0.31050511834960187, 0.31087069952559193, 0.3100470589412438, 0.3103897415686141, 0.30782041498891693, 0.3064211432428656, 0.30674545172438905, 0.30769314933356373], 'acc': [0.4847517754384863, 0.8811009125670923, 0.890594088045278, 0.8968405199345078, 0.9029462066532353, 0.9093932597444585, 0.9151036107565411, 0.9191955732936135, 0.9220822473378546, 0.9241657908054268, 0.9256774285222515, 0.9267389091517807, 0.9280408614744036, 0.9289908389238947, 0.9294394469454221, 0.9302138239748565, 0.9308625195833996, 0.9315516069970977, 0.9318743884069326, 0.932221040712838, 0.9327048681502584, 0.933109193758765, 0.9337002584441034, 0.9339974825267781, 0.9343213339244467, 0.9347738580297408, 0.9351937550557976, 0.9356203487044886, 0.9357952251010532, 0.9362126432886375, 0.9365904340055469, 0.9367613272789197, 0.9370365830453256, 0.937121395927324, 0.9374136855222137, 0.9373691929818486, 0.9376347672739355, 0.9378982050032291, 0.9381507329796467, 0.938179770209138, 0.9383740658954961, 0.9385963511163613, 0.9388538400561957, 0.9387641373410582, 0.9389117657276438, 0.9389204530672736, 0.93936885723563, 0.9391655687401468, 0.9393971223396351, 0.9397239384220035, 0.9395802755656444, 0.9398983064381768, 0.9397114979777236, 0.9399651136498518, 0.939832290358366, 0.9400143298382058, 0.9403487463918568, 0.9404192799682536, 0.940477417709052, 0.9404053515681923, 0.9404488033542335, 0.9406670373208219, 0.9406696040896476, 0.9407261215769442, 0.9407929261226702, 0.9405962420562478, 0.9409849739428635, 0.9408748830837943, 0.9411332964069792, 0.9412657468792834, 0.9411238188317959, 0.9413675176102186, 0.9414106863115435, 0.9414439824405654, 0.9415861702572065, 0.9415949492158516, 0.9414310335124736, 0.9415347720125588, 0.9417461049632574, 0.9418800793701637, 0.9417334229288382, 0.9418688644005978], 'mDice': [0.08722972583563623, 0.3192812094275653, 0.43733640754868675, 0.4962780356797865, 0.5369897723335831, 0.5621570506283422, 0.5824076272008597, 0.5965627915647326, 0.6089825118601564, 0.6181915536858982, 0.6260957852456986, 0.6305618400354939, 0.6389712905847017, 0.6416850579205519, 0.6453769708245114, 0.6500152441746058, 0.6531275685338678, 0.6567999024898624, 0.6589962034090328, 0.6610620604192036, 0.664563051475733, 0.6668190528070028, 0.6692395323224212, 0.6715402933864987, 0.6723606418570457, 0.6748651265638376, 0.6760114054701014, 0.6789546125491782, 0.6790963254017202, 0.6820341111930184, 0.6832385353897724, 0.684425745553678, 0.6854919994730055, 0.6875755629466865, 0.6888975233891026, 0.688588196219611, 0.690264929184363, 0.6918338367147024, 0.6940194796752857, 0.6941766148016175, 0.6960165617735785, 0.6967485895477693, 0.6989700763078929, 0.6979856656791389, 0.6992793783002537, 0.7004341864507737, 0.7024605239037491, 0.7016694741785032, 0.7035777607542346, 0.7043487853642624, 0.7050794311196721, 0.7058026921388293, 0.7063129370052138, 0.7071788076470071, 0.7070014307856077, 0.7079347402621539, 0.7088048738713483, 0.7108764950425174, 0.7099678620497846, 0.7107455003622388, 0.7117221211683826, 0.712577522961602, 0.7125399254732149, 0.7127882738161206, 0.713333797990322, 0.713250826118492, 0.7151734639344841, 0.7149242873777423, 0.7166077145864583, 0.7168033531871816, 0.7166513238588418, 0.7177512650777546, 0.7184951427080785, 0.7178874922920243, 0.7188199959854779, 0.7186285433613866, 0.7191296873902548, 0.7188752893195438, 0.7207485649634906, 0.7218648485533414, 0.7216184023420821, 0.7209371148632145]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.57s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.34s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  2.12s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:14,  1.95s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:39,  1.83s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:38,  1.84s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<08:04,  1.72s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:19,  1.79s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<08:12,  1.76s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:25,  1.82s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:05,  1.75s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:21,  1.82s/it]predicting train subjects:   4%|▎         | 10/285 [00:18<08:38,  1.89s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:08,  1.78s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:20,  1.83s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:17,  1.83s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<08:26,  1.87s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:38,  1.92s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<08:45,  1.95s/it]predicting train subjects:   6%|▌         | 17/285 [00:31<08:20,  1.87s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:15,  1.86s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<07:58,  1.80s/it]predicting train subjects:   7%|▋         | 20/285 [00:36<08:08,  1.84s/it]predicting train subjects:   7%|▋         | 21/285 [00:38<08:26,  1.92s/it]predicting train subjects:   8%|▊         | 22/285 [00:40<08:03,  1.84s/it]predicting train subjects:   8%|▊         | 23/285 [00:42<08:21,  1.91s/it]predicting train subjects:   8%|▊         | 24/285 [00:44<08:10,  1.88s/it]predicting train subjects:   9%|▉         | 25/285 [00:46<08:40,  2.00s/it]predicting train subjects:   9%|▉         | 26/285 [00:48<08:46,  2.03s/it]predicting train subjects:   9%|▉         | 27/285 [00:50<08:20,  1.94s/it]predicting train subjects:  10%|▉         | 28/285 [00:52<08:22,  1.95s/it]predicting train subjects:  10%|█         | 29/285 [00:54<08:17,  1.94s/it]predicting train subjects:  11%|█         | 30/285 [00:56<08:36,  2.03s/it]predicting train subjects:  11%|█         | 31/285 [00:58<08:29,  2.01s/it]predicting train subjects:  11%|█         | 32/285 [00:59<07:58,  1.89s/it]predicting train subjects:  12%|█▏        | 33/285 [01:01<08:07,  1.93s/it]predicting train subjects:  12%|█▏        | 34/285 [01:03<08:11,  1.96s/it]predicting train subjects:  12%|█▏        | 35/285 [01:06<08:23,  2.02s/it]predicting train subjects:  13%|█▎        | 36/285 [01:07<08:01,  1.93s/it]predicting train subjects:  13%|█▎        | 37/285 [01:09<08:00,  1.94s/it]predicting train subjects:  13%|█▎        | 38/285 [01:12<08:17,  2.01s/it]predicting train subjects:  14%|█▎        | 39/285 [01:13<07:57,  1.94s/it]predicting train subjects:  14%|█▍        | 40/285 [01:15<07:54,  1.94s/it]predicting train subjects:  14%|█▍        | 41/285 [01:17<07:45,  1.91s/it]predicting train subjects:  15%|█▍        | 42/285 [01:19<07:37,  1.88s/it]predicting train subjects:  15%|█▌        | 43/285 [01:21<07:45,  1.93s/it]predicting train subjects:  15%|█▌        | 44/285 [01:23<08:10,  2.03s/it]predicting train subjects:  16%|█▌        | 45/285 [01:25<07:44,  1.93s/it]predicting train subjects:  16%|█▌        | 46/285 [01:27<08:03,  2.02s/it]predicting train subjects:  16%|█▋        | 47/285 [01:29<07:36,  1.92s/it]predicting train subjects:  17%|█▋        | 48/285 [01:31<07:44,  1.96s/it]predicting train subjects:  17%|█▋        | 49/285 [01:33<07:52,  2.00s/it]predicting train subjects:  18%|█▊        | 50/285 [01:35<07:44,  1.98s/it]predicting train subjects:  18%|█▊        | 51/285 [01:37<07:58,  2.04s/it]predicting train subjects:  18%|█▊        | 52/285 [01:39<07:37,  1.97s/it]predicting train subjects:  19%|█▊        | 53/285 [01:41<07:35,  1.96s/it]predicting train subjects:  19%|█▉        | 54/285 [01:43<07:46,  2.02s/it]predicting train subjects:  19%|█▉        | 55/285 [01:45<07:14,  1.89s/it]predicting train subjects:  20%|█▉        | 56/285 [01:47<07:20,  1.92s/it]predicting train subjects:  20%|██        | 57/285 [01:48<06:58,  1.83s/it]predicting train subjects:  20%|██        | 58/285 [01:50<07:04,  1.87s/it]predicting train subjects:  21%|██        | 59/285 [01:53<07:50,  2.08s/it]predicting train subjects:  21%|██        | 60/285 [01:55<08:05,  2.16s/it]predicting train subjects:  21%|██▏       | 61/285 [01:57<07:40,  2.06s/it]predicting train subjects:  22%|██▏       | 62/285 [01:59<07:34,  2.04s/it]predicting train subjects:  22%|██▏       | 63/285 [02:01<07:41,  2.08s/it]predicting train subjects:  22%|██▏       | 64/285 [02:03<07:24,  2.01s/it]predicting train subjects:  23%|██▎       | 65/285 [02:05<07:23,  2.02s/it]predicting train subjects:  23%|██▎       | 66/285 [02:07<07:18,  2.00s/it]predicting train subjects:  24%|██▎       | 67/285 [02:09<07:12,  1.98s/it]predicting train subjects:  24%|██▍       | 68/285 [02:11<06:52,  1.90s/it]predicting train subjects:  24%|██▍       | 69/285 [02:13<07:05,  1.97s/it]predicting train subjects:  25%|██▍       | 70/285 [02:15<07:11,  2.01s/it]predicting train subjects:  25%|██▍       | 71/285 [02:17<07:10,  2.01s/it]predicting train subjects:  25%|██▌       | 72/285 [02:19<06:52,  1.94s/it]predicting train subjects:  26%|██▌       | 73/285 [02:21<06:55,  1.96s/it]predicting train subjects:  26%|██▌       | 74/285 [02:22<06:46,  1.93s/it]predicting train subjects:  26%|██▋       | 75/285 [02:24<06:44,  1.93s/it]predicting train subjects:  27%|██▋       | 76/285 [02:26<06:56,  1.99s/it]predicting train subjects:  27%|██▋       | 77/285 [02:28<06:52,  1.98s/it]predicting train subjects:  27%|██▋       | 78/285 [02:30<06:44,  1.95s/it]predicting train subjects:  28%|██▊       | 79/285 [02:32<06:36,  1.93s/it]predicting train subjects:  28%|██▊       | 80/285 [02:34<06:44,  1.97s/it]predicting train subjects:  28%|██▊       | 81/285 [02:36<06:23,  1.88s/it]predicting train subjects:  29%|██▉       | 82/285 [02:38<06:23,  1.89s/it]predicting train subjects:  29%|██▉       | 83/285 [02:40<06:20,  1.88s/it]predicting train subjects:  29%|██▉       | 84/285 [02:41<06:09,  1.84s/it]predicting train subjects:  30%|██▉       | 85/285 [02:43<06:01,  1.81s/it]predicting train subjects:  30%|███       | 86/285 [02:45<06:11,  1.86s/it]predicting train subjects:  31%|███       | 87/285 [02:47<06:10,  1.87s/it]predicting train subjects:  31%|███       | 88/285 [02:49<05:58,  1.82s/it]predicting train subjects:  31%|███       | 89/285 [02:51<05:56,  1.82s/it]predicting train subjects:  32%|███▏      | 90/285 [02:52<05:57,  1.84s/it]predicting train subjects:  32%|███▏      | 91/285 [02:54<05:50,  1.81s/it]predicting train subjects:  32%|███▏      | 92/285 [02:56<05:54,  1.83s/it]predicting train subjects:  33%|███▎      | 93/285 [02:58<05:43,  1.79s/it]predicting train subjects:  33%|███▎      | 94/285 [03:00<05:49,  1.83s/it]predicting train subjects:  33%|███▎      | 95/285 [03:02<05:49,  1.84s/it]predicting train subjects:  34%|███▎      | 96/285 [03:03<05:45,  1.83s/it]predicting train subjects:  34%|███▍      | 97/285 [03:05<05:43,  1.83s/it]predicting train subjects:  34%|███▍      | 98/285 [03:07<05:37,  1.81s/it]predicting train subjects:  35%|███▍      | 99/285 [03:09<05:32,  1.79s/it]predicting train subjects:  35%|███▌      | 100/285 [03:11<05:37,  1.82s/it]predicting train subjects:  35%|███▌      | 101/285 [03:12<05:31,  1.80s/it]predicting train subjects:  36%|███▌      | 102/285 [03:14<05:27,  1.79s/it]predicting train subjects:  36%|███▌      | 103/285 [03:16<05:15,  1.73s/it]predicting train subjects:  36%|███▋      | 104/285 [03:18<05:21,  1.77s/it]predicting train subjects:  37%|███▋      | 105/285 [03:19<05:27,  1.82s/it]predicting train subjects:  37%|███▋      | 106/285 [03:21<05:17,  1.78s/it]predicting train subjects:  38%|███▊      | 107/285 [03:23<05:18,  1.79s/it]predicting train subjects:  38%|███▊      | 108/285 [03:25<05:12,  1.77s/it]predicting train subjects:  38%|███▊      | 109/285 [03:27<05:17,  1.81s/it]predicting train subjects:  39%|███▊      | 110/285 [03:28<05:19,  1.83s/it]predicting train subjects:  39%|███▉      | 111/285 [03:30<05:16,  1.82s/it]predicting train subjects:  39%|███▉      | 112/285 [03:32<05:14,  1.82s/it]predicting train subjects:  40%|███▉      | 113/285 [03:34<05:16,  1.84s/it]predicting train subjects:  40%|████      | 114/285 [03:36<05:08,  1.81s/it]predicting train subjects:  40%|████      | 115/285 [03:37<05:02,  1.78s/it]predicting train subjects:  41%|████      | 116/285 [03:39<05:05,  1.81s/it]predicting train subjects:  41%|████      | 117/285 [03:41<04:59,  1.78s/it]predicting train subjects:  41%|████▏     | 118/285 [03:43<04:52,  1.75s/it]predicting train subjects:  42%|████▏     | 119/285 [03:45<05:00,  1.81s/it]predicting train subjects:  42%|████▏     | 120/285 [03:46<04:52,  1.77s/it]predicting train subjects:  42%|████▏     | 121/285 [03:48<04:44,  1.73s/it]predicting train subjects:  43%|████▎     | 122/285 [03:49<04:30,  1.66s/it]predicting train subjects:  43%|████▎     | 123/285 [03:51<04:19,  1.60s/it]predicting train subjects:  44%|████▎     | 124/285 [03:53<04:21,  1.63s/it]predicting train subjects:  44%|████▍     | 125/285 [03:54<04:14,  1.59s/it]predicting train subjects:  44%|████▍     | 126/285 [03:56<04:09,  1.57s/it]predicting train subjects:  45%|████▍     | 127/285 [03:57<04:04,  1.55s/it]predicting train subjects:  45%|████▍     | 128/285 [03:59<04:07,  1.57s/it]predicting train subjects:  45%|████▌     | 129/285 [04:00<04:01,  1.55s/it]predicting train subjects:  46%|████▌     | 130/285 [04:02<03:56,  1.52s/it]predicting train subjects:  46%|████▌     | 131/285 [04:03<03:54,  1.52s/it]predicting train subjects:  46%|████▋     | 132/285 [04:05<03:59,  1.56s/it]predicting train subjects:  47%|████▋     | 133/285 [04:06<03:49,  1.51s/it]predicting train subjects:  47%|████▋     | 134/285 [04:08<03:49,  1.52s/it]predicting train subjects:  47%|████▋     | 135/285 [04:09<03:40,  1.47s/it]predicting train subjects:  48%|████▊     | 136/285 [04:11<03:37,  1.46s/it]predicting train subjects:  48%|████▊     | 137/285 [04:12<03:45,  1.52s/it]predicting train subjects:  48%|████▊     | 138/285 [04:14<03:44,  1.53s/it]predicting train subjects:  49%|████▉     | 139/285 [04:16<03:55,  1.61s/it]predicting train subjects:  49%|████▉     | 140/285 [04:17<03:55,  1.63s/it]predicting train subjects:  49%|████▉     | 141/285 [04:19<03:46,  1.57s/it]predicting train subjects:  50%|████▉     | 142/285 [04:20<03:40,  1.54s/it]predicting train subjects:  50%|█████     | 143/285 [04:22<03:33,  1.51s/it]predicting train subjects:  51%|█████     | 144/285 [04:23<03:41,  1.57s/it]predicting train subjects:  51%|█████     | 145/285 [04:25<03:36,  1.55s/it]predicting train subjects:  51%|█████     | 146/285 [04:26<03:35,  1.55s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:28<03:27,  1.50s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:29<03:30,  1.54s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:31<03:31,  1.55s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:32<03:23,  1.51s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:34<03:23,  1.52s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:35<03:20,  1.51s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:37<03:15,  1.48s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:39<03:26,  1.57s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:40<03:21,  1.55s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:42<03:23,  1.58s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:43<03:19,  1.55s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:45<03:14,  1.53s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:46<03:09,  1.51s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:48<03:10,  1.53s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:49<03:09,  1.53s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:51<03:07,  1.52s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:52<03:09,  1.55s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:54<03:02,  1.51s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:55<02:59,  1.49s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:57<03:01,  1.53s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:58<02:58,  1.51s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:00<02:50,  1.46s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:01<02:48,  1.45s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:03<02:46,  1.45s/it]predicting train subjects:  60%|██████    | 171/285 [05:04<02:43,  1.43s/it]predicting train subjects:  60%|██████    | 172/285 [05:05<02:41,  1.43s/it]predicting train subjects:  61%|██████    | 173/285 [05:07<02:54,  1.55s/it]predicting train subjects:  61%|██████    | 174/285 [05:09<02:57,  1.60s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:11<03:14,  1.76s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:13<03:15,  1.80s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:15<03:07,  1.74s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:16<03:01,  1.69s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:18<02:55,  1.66s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:20<03:26,  1.97s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:23<03:30,  2.02s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:25<03:33,  2.07s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:27<03:22,  1.98s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:28<03:12,  1.91s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:30<03:14,  1.95s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:33<03:26,  2.09s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:35<03:29,  2.14s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:37<03:29,  2.16s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:39<03:16,  2.04s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:41<03:15,  2.05s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:43<03:14,  2.06s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:45<03:14,  2.09s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:47<03:04,  2.00s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:49<02:57,  1.96s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:51<02:56,  1.96s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:53<02:59,  2.02s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:55<02:57,  2.02s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:58<03:08,  2.17s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:59<02:51,  1.99s/it]predicting train subjects:  70%|███████   | 200/285 [06:01<02:43,  1.92s/it]predicting train subjects:  71%|███████   | 201/285 [06:03<02:47,  2.00s/it]predicting train subjects:  71%|███████   | 202/285 [06:05<02:39,  1.92s/it]predicting train subjects:  71%|███████   | 203/285 [06:07<02:42,  1.98s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:09<02:30,  1.86s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:10<02:24,  1.80s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:12<02:17,  1.74s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:14<02:33,  1.97s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:17<02:43,  2.12s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:19<02:39,  2.10s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:21<02:33,  2.05s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:23<02:26,  1.98s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:25<02:23,  1.97s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:26<02:19,  1.93s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:28<02:11,  1.85s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:31<02:22,  2.03s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:32<02:10,  1.89s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:34<02:18,  2.04s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:37<02:25,  2.17s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:39<02:24,  2.19s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:41<02:12,  2.04s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:43<02:03,  1.94s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:45<02:03,  1.95s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:46<01:55,  1.86s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:48<01:49,  1.79s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:49<01:43,  1.72s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:52<01:49,  1.86s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:54<01:53,  1.96s/it]predicting train subjects:  80%|████████  | 228/285 [06:56<01:53,  1.99s/it]predicting train subjects:  80%|████████  | 229/285 [06:58<01:49,  1.95s/it]predicting train subjects:  81%|████████  | 230/285 [06:59<01:40,  1.83s/it]predicting train subjects:  81%|████████  | 231/285 [07:01<01:38,  1.82s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:03<01:41,  1.91s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:05<01:35,  1.85s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:07<01:39,  1.95s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:09<01:33,  1.88s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:11<01:35,  1.96s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:13<01:38,  2.05s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:15<01:35,  2.04s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:17<01:31,  2.00s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:19<01:25,  1.90s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:21<01:23,  1.89s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:22<01:17,  1.81s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:24<01:16,  1.81s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:26<01:18,  1.92s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:28<01:14,  1.86s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:30<01:18,  2.01s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:33<01:19,  2.09s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:35<01:17,  2.10s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:37<01:12,  2.02s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:38<01:08,  1.97s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:40<01:04,  1.89s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:42<01:01,  1.86s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:44<01:05,  2.05s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:47<01:05,  2.12s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:49<01:01,  2.06s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:50<00:55,  1.92s/it]predicting train subjects:  90%|█████████ | 257/285 [07:52<00:51,  1.84s/it]predicting train subjects:  91%|█████████ | 258/285 [07:54<00:52,  1.95s/it]predicting train subjects:  91%|█████████ | 259/285 [07:56<00:51,  1.96s/it]predicting train subjects:  91%|█████████ | 260/285 [07:58<00:48,  1.96s/it]predicting train subjects:  92%|█████████▏| 261/285 [08:00<00:44,  1.87s/it]predicting train subjects:  92%|█████████▏| 262/285 [08:01<00:42,  1.84s/it]predicting train subjects:  92%|█████████▏| 263/285 [08:03<00:39,  1.81s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:05<00:38,  1.85s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:07<00:39,  1.98s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:09<00:35,  1.87s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:11<00:32,  1.81s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:13<00:34,  2.00s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:15<00:32,  2.01s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:17<00:29,  1.93s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:19<00:26,  1.87s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:21<00:25,  1.98s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:23<00:22,  1.91s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:24<00:20,  1.83s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:26<00:19,  1.95s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:29<00:19,  2.13s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:31<00:15,  1.99s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:33<00:13,  2.00s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:35<00:11,  1.98s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:37<00:09,  1.96s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:38<00:07,  1.90s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:40<00:05,  1.79s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:42<00:03,  1.92s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:44<00:02,  2.07s/it]predicting train subjects: 100%|██████████| 285/285 [08:47<00:00,  2.12s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:02<11:13,  2.37s/it]Loading train:   1%|          | 2/285 [00:04<10:41,  2.27s/it]Loading train:   1%|          | 3/285 [00:06<10:15,  2.18s/it]Loading train:   1%|▏         | 4/285 [00:08<09:41,  2.07s/it]Loading train:   2%|▏         | 5/285 [00:10<09:29,  2.04s/it]Loading train:   2%|▏         | 6/285 [00:12<09:24,  2.02s/it]Loading train:   2%|▏         | 7/285 [00:14<09:49,  2.12s/it]Loading train:   3%|▎         | 8/285 [00:16<09:50,  2.13s/it]Loading train:   3%|▎         | 9/285 [00:19<10:36,  2.31s/it]Loading train:   4%|▎         | 10/285 [00:21<10:13,  2.23s/it]Loading train:   4%|▍         | 11/285 [00:23<09:26,  2.07s/it]Loading train:   4%|▍         | 12/285 [00:25<09:19,  2.05s/it]Loading train:   5%|▍         | 13/285 [00:26<08:26,  1.86s/it]Loading train:   5%|▍         | 14/285 [00:27<07:51,  1.74s/it]Loading train:   5%|▌         | 15/285 [00:29<08:07,  1.80s/it]Loading train:   6%|▌         | 16/285 [00:31<07:39,  1.71s/it]Loading train:   6%|▌         | 17/285 [00:33<08:02,  1.80s/it]Loading train:   6%|▋         | 18/285 [00:35<08:01,  1.80s/it]Loading train:   7%|▋         | 19/285 [00:37<08:20,  1.88s/it]Loading train:   7%|▋         | 20/285 [00:38<07:28,  1.69s/it]Loading train:   7%|▋         | 21/285 [00:40<07:36,  1.73s/it]Loading train:   8%|▊         | 22/285 [00:41<07:04,  1.61s/it]Loading train:   8%|▊         | 23/285 [00:43<07:08,  1.63s/it]Loading train:   8%|▊         | 24/285 [00:45<07:28,  1.72s/it]Loading train:   9%|▉         | 25/285 [00:47<07:49,  1.81s/it]Loading train:   9%|▉         | 26/285 [00:49<08:05,  1.87s/it]Loading train:   9%|▉         | 27/285 [00:51<07:49,  1.82s/it]Loading train:  10%|▉         | 28/285 [00:52<07:36,  1.78s/it]Loading train:  10%|█         | 29/285 [00:54<07:23,  1.73s/it]Loading train:  11%|█         | 30/285 [00:56<07:41,  1.81s/it]Loading train:  11%|█         | 31/285 [00:57<07:19,  1.73s/it]Loading train:  11%|█         | 32/285 [00:59<06:59,  1.66s/it]Loading train:  12%|█▏        | 33/285 [01:01<07:17,  1.74s/it]Loading train:  12%|█▏        | 34/285 [01:03<07:15,  1.73s/it]Loading train:  12%|█▏        | 35/285 [01:05<07:45,  1.86s/it]Loading train:  13%|█▎        | 36/285 [01:06<07:21,  1.77s/it]Loading train:  13%|█▎        | 37/285 [01:08<07:17,  1.76s/it]Loading train:  13%|█▎        | 38/285 [01:10<07:40,  1.87s/it]Loading train:  14%|█▎        | 39/285 [01:12<07:10,  1.75s/it]Loading train:  14%|█▍        | 40/285 [01:14<07:24,  1.81s/it]Loading train:  14%|█▍        | 41/285 [01:15<07:24,  1.82s/it]Loading train:  15%|█▍        | 42/285 [01:17<07:09,  1.77s/it]Loading train:  15%|█▌        | 43/285 [01:19<07:31,  1.87s/it]Loading train:  15%|█▌        | 44/285 [01:21<08:02,  2.00s/it]Loading train:  16%|█▌        | 45/285 [01:23<07:40,  1.92s/it]Loading train:  16%|█▌        | 46/285 [01:25<07:24,  1.86s/it]Loading train:  16%|█▋        | 47/285 [01:27<07:19,  1.85s/it]Loading train:  17%|█▋        | 48/285 [01:29<07:47,  1.97s/it]Loading train:  17%|█▋        | 49/285 [01:31<07:33,  1.92s/it]Loading train:  18%|█▊        | 50/285 [01:33<07:44,  1.98s/it]Loading train:  18%|█▊        | 51/285 [01:36<08:40,  2.23s/it]Loading train:  18%|█▊        | 52/285 [01:37<07:15,  1.87s/it]Loading train:  19%|█▊        | 53/285 [01:38<06:28,  1.67s/it]Loading train:  19%|█▉        | 54/285 [01:39<06:04,  1.58s/it]Loading train:  19%|█▉        | 55/285 [01:41<06:02,  1.57s/it]Loading train:  20%|█▉        | 56/285 [01:42<05:49,  1.53s/it]Loading train:  20%|██        | 57/285 [01:43<05:21,  1.41s/it]Loading train:  20%|██        | 58/285 [01:45<05:15,  1.39s/it]Loading train:  21%|██        | 59/285 [01:46<05:18,  1.41s/it]Loading train:  21%|██        | 60/285 [01:47<05:04,  1.35s/it]Loading train:  21%|██▏       | 61/285 [01:49<04:44,  1.27s/it]Loading train:  22%|██▏       | 62/285 [01:50<04:43,  1.27s/it]Loading train:  22%|██▏       | 63/285 [01:51<04:35,  1.24s/it]Loading train:  22%|██▏       | 64/285 [01:53<04:55,  1.34s/it]Loading train:  23%|██▎       | 65/285 [01:54<05:23,  1.47s/it]Loading train:  23%|██▎       | 66/285 [01:56<05:24,  1.48s/it]Loading train:  24%|██▎       | 67/285 [01:57<05:05,  1.40s/it]Loading train:  24%|██▍       | 68/285 [01:58<04:51,  1.34s/it]Loading train:  24%|██▍       | 69/285 [01:59<04:35,  1.28s/it]Loading train:  25%|██▍       | 70/285 [02:01<04:29,  1.25s/it]Loading train:  25%|██▍       | 71/285 [02:02<04:23,  1.23s/it]Loading train:  25%|██▌       | 72/285 [02:03<04:16,  1.20s/it]Loading train:  26%|██▌       | 73/285 [02:04<04:09,  1.18s/it]Loading train:  26%|██▌       | 74/285 [02:05<04:08,  1.18s/it]Loading train:  26%|██▋       | 75/285 [02:06<04:02,  1.15s/it]Loading train:  27%|██▋       | 76/285 [02:07<04:05,  1.18s/it]Loading train:  27%|██▋       | 77/285 [02:09<04:01,  1.16s/it]Loading train:  27%|██▋       | 78/285 [02:10<03:58,  1.15s/it]Loading train:  28%|██▊       | 79/285 [02:11<04:00,  1.17s/it]Loading train:  28%|██▊       | 80/285 [02:12<03:55,  1.15s/it]Loading train:  28%|██▊       | 81/285 [02:13<03:50,  1.13s/it]Loading train:  29%|██▉       | 82/285 [02:14<03:53,  1.15s/it]Loading train:  29%|██▉       | 83/285 [02:16<03:55,  1.17s/it]Loading train:  29%|██▉       | 84/285 [02:16<03:41,  1.10s/it]Loading train:  30%|██▉       | 85/285 [02:18<03:37,  1.09s/it]Loading train:  30%|███       | 86/285 [02:19<03:44,  1.13s/it]Loading train:  31%|███       | 87/285 [02:20<03:38,  1.10s/it]Loading train:  31%|███       | 88/285 [02:21<03:34,  1.09s/it]Loading train:  31%|███       | 89/285 [02:22<03:35,  1.10s/it]Loading train:  32%|███▏      | 90/285 [02:23<03:30,  1.08s/it]Loading train:  32%|███▏      | 91/285 [02:24<03:26,  1.07s/it]Loading train:  32%|███▏      | 92/285 [02:25<03:33,  1.11s/it]Loading train:  33%|███▎      | 93/285 [02:26<03:31,  1.10s/it]Loading train:  33%|███▎      | 94/285 [02:27<03:24,  1.07s/it]Loading train:  33%|███▎      | 95/285 [02:28<03:27,  1.09s/it]Loading train:  34%|███▎      | 96/285 [02:30<03:29,  1.11s/it]Loading train:  34%|███▍      | 97/285 [02:31<03:30,  1.12s/it]Loading train:  34%|███▍      | 98/285 [02:32<03:30,  1.13s/it]Loading train:  35%|███▍      | 99/285 [02:33<03:32,  1.14s/it]Loading train:  35%|███▌      | 100/285 [02:34<03:28,  1.13s/it]Loading train:  35%|███▌      | 101/285 [02:35<03:21,  1.10s/it]Loading train:  36%|███▌      | 102/285 [02:36<03:21,  1.10s/it]Loading train:  36%|███▌      | 103/285 [02:37<03:11,  1.05s/it]Loading train:  36%|███▋      | 104/285 [02:38<03:03,  1.02s/it]Loading train:  37%|███▋      | 105/285 [02:39<02:59,  1.00it/s]Loading train:  37%|███▋      | 106/285 [02:40<02:56,  1.02it/s]Loading train:  38%|███▊      | 107/285 [02:41<03:02,  1.03s/it]Loading train:  38%|███▊      | 108/285 [02:42<03:02,  1.03s/it]Loading train:  38%|███▊      | 109/285 [02:43<03:05,  1.06s/it]Loading train:  39%|███▊      | 110/285 [02:44<03:05,  1.06s/it]Loading train:  39%|███▉      | 111/285 [02:45<03:03,  1.05s/it]Loading train:  39%|███▉      | 112/285 [02:47<03:03,  1.06s/it]Loading train:  40%|███▉      | 113/285 [02:48<03:05,  1.08s/it]Loading train:  40%|████      | 114/285 [02:49<03:13,  1.13s/it]Loading train:  40%|████      | 115/285 [02:50<03:16,  1.15s/it]Loading train:  41%|████      | 116/285 [02:51<03:14,  1.15s/it]Loading train:  41%|████      | 117/285 [02:52<03:13,  1.15s/it]Loading train:  41%|████▏     | 118/285 [02:54<03:14,  1.16s/it]Loading train:  42%|████▏     | 119/285 [02:55<03:11,  1.15s/it]Loading train:  42%|████▏     | 120/285 [02:56<03:04,  1.12s/it]Loading train:  42%|████▏     | 121/285 [02:57<03:15,  1.19s/it]Loading train:  43%|████▎     | 122/285 [02:58<03:13,  1.19s/it]Loading train:  43%|████▎     | 123/285 [03:00<03:14,  1.20s/it]Loading train:  44%|████▎     | 124/285 [03:01<03:07,  1.16s/it]Loading train:  44%|████▍     | 125/285 [03:02<02:54,  1.09s/it]Loading train:  44%|████▍     | 126/285 [03:03<02:47,  1.06s/it]Loading train:  45%|████▍     | 127/285 [03:03<02:39,  1.01s/it]Loading train:  45%|████▍     | 128/285 [03:04<02:36,  1.00it/s]Loading train:  45%|████▌     | 129/285 [03:05<02:31,  1.03it/s]Loading train:  46%|████▌     | 130/285 [03:06<02:30,  1.03it/s]Loading train:  46%|████▌     | 131/285 [03:07<02:31,  1.01it/s]Loading train:  46%|████▋     | 132/285 [03:08<02:29,  1.03it/s]Loading train:  47%|████▋     | 133/285 [03:09<02:29,  1.01it/s]Loading train:  47%|████▋     | 134/285 [03:10<02:29,  1.01it/s]Loading train:  47%|████▋     | 135/285 [03:11<02:27,  1.02it/s]Loading train:  48%|████▊     | 136/285 [03:12<02:26,  1.02it/s]Loading train:  48%|████▊     | 137/285 [03:13<02:27,  1.01it/s]Loading train:  48%|████▊     | 138/285 [03:14<02:21,  1.04it/s]Loading train:  49%|████▉     | 139/285 [03:15<02:24,  1.01it/s]Loading train:  49%|████▉     | 140/285 [03:16<02:24,  1.00it/s]Loading train:  49%|████▉     | 141/285 [03:17<02:20,  1.03it/s]Loading train:  50%|████▉     | 142/285 [03:18<02:18,  1.03it/s]Loading train:  50%|█████     | 143/285 [03:19<02:20,  1.01it/s]Loading train:  51%|█████     | 144/285 [03:20<02:23,  1.02s/it]Loading train:  51%|█████     | 145/285 [03:21<02:23,  1.02s/it]Loading train:  51%|█████     | 146/285 [03:22<02:27,  1.06s/it]Loading train:  52%|█████▏    | 147/285 [03:23<02:27,  1.07s/it]Loading train:  52%|█████▏    | 148/285 [03:24<02:22,  1.04s/it]Loading train:  52%|█████▏    | 149/285 [03:26<02:21,  1.04s/it]Loading train:  53%|█████▎    | 150/285 [03:26<02:16,  1.01s/it]Loading train:  53%|█████▎    | 151/285 [03:27<02:15,  1.01s/it]Loading train:  53%|█████▎    | 152/285 [03:29<02:15,  1.02s/it]Loading train:  54%|█████▎    | 153/285 [03:30<02:15,  1.03s/it]Loading train:  54%|█████▍    | 154/285 [03:31<02:13,  1.02s/it]Loading train:  54%|█████▍    | 155/285 [03:31<02:09,  1.00it/s]Loading train:  55%|█████▍    | 156/285 [03:32<02:08,  1.01it/s]Loading train:  55%|█████▌    | 157/285 [03:33<02:05,  1.02it/s]Loading train:  55%|█████▌    | 158/285 [03:34<02:00,  1.05it/s]Loading train:  56%|█████▌    | 159/285 [03:35<01:57,  1.08it/s]Loading train:  56%|█████▌    | 160/285 [03:36<01:56,  1.08it/s]Loading train:  56%|█████▋    | 161/285 [03:37<01:54,  1.08it/s]Loading train:  57%|█████▋    | 162/285 [03:38<01:51,  1.10it/s]Loading train:  57%|█████▋    | 163/285 [03:39<01:54,  1.07it/s]Loading train:  58%|█████▊    | 164/285 [03:40<01:56,  1.04it/s]Loading train:  58%|█████▊    | 165/285 [03:41<01:59,  1.00it/s]Loading train:  58%|█████▊    | 166/285 [03:42<02:03,  1.04s/it]Loading train:  59%|█████▊    | 167/285 [03:43<02:06,  1.07s/it]Loading train:  59%|█████▉    | 168/285 [03:44<02:02,  1.04s/it]Loading train:  59%|█████▉    | 169/285 [03:46<02:08,  1.11s/it]Loading train:  60%|█████▉    | 170/285 [03:47<02:03,  1.07s/it]Loading train:  60%|██████    | 171/285 [03:47<01:57,  1.03s/it]Loading train:  60%|██████    | 172/285 [03:48<01:53,  1.01s/it]Loading train:  61%|██████    | 173/285 [03:49<01:51,  1.01it/s]Loading train:  61%|██████    | 174/285 [03:50<01:45,  1.05it/s]Loading train:  61%|██████▏   | 175/285 [03:51<01:40,  1.09it/s]Loading train:  62%|██████▏   | 176/285 [03:52<01:40,  1.08it/s]Loading train:  62%|██████▏   | 177/285 [03:53<01:39,  1.09it/s]Loading train:  62%|██████▏   | 178/285 [03:54<01:42,  1.05it/s]Loading train:  63%|██████▎   | 179/285 [03:55<01:40,  1.05it/s]Loading train:  63%|██████▎   | 180/285 [03:56<01:46,  1.01s/it]Loading train:  64%|██████▎   | 181/285 [03:57<01:46,  1.02s/it]Loading train:  64%|██████▍   | 182/285 [03:58<01:51,  1.08s/it]Loading train:  64%|██████▍   | 183/285 [03:59<01:47,  1.05s/it]Loading train:  65%|██████▍   | 184/285 [04:00<01:42,  1.02s/it]Loading train:  65%|██████▍   | 185/285 [04:01<01:39,  1.01it/s]Loading train:  65%|██████▌   | 186/285 [04:02<01:45,  1.07s/it]Loading train:  66%|██████▌   | 187/285 [04:03<01:45,  1.07s/it]Loading train:  66%|██████▌   | 188/285 [04:04<01:42,  1.06s/it]Loading train:  66%|██████▋   | 189/285 [04:05<01:36,  1.01s/it]Loading train:  67%|██████▋   | 190/285 [04:06<01:33,  1.01it/s]Loading train:  67%|██████▋   | 191/285 [04:07<01:31,  1.02it/s]Loading train:  67%|██████▋   | 192/285 [04:08<01:31,  1.01it/s]Loading train:  68%|██████▊   | 193/285 [04:09<01:30,  1.02it/s]Loading train:  68%|██████▊   | 194/285 [04:10<01:28,  1.03it/s]Loading train:  68%|██████▊   | 195/285 [04:11<01:24,  1.07it/s]Loading train:  69%|██████▉   | 196/285 [04:12<01:26,  1.02it/s]Loading train:  69%|██████▉   | 197/285 [04:13<01:28,  1.01s/it]Loading train:  69%|██████▉   | 198/285 [04:14<01:29,  1.03s/it]Loading train:  70%|██████▉   | 199/285 [04:15<01:23,  1.02it/s]Loading train:  70%|███████   | 200/285 [04:16<01:21,  1.05it/s]Loading train:  71%|███████   | 201/285 [04:17<01:23,  1.01it/s]Loading train:  71%|███████   | 202/285 [04:18<01:25,  1.03s/it]Loading train:  71%|███████   | 203/285 [04:19<01:26,  1.05s/it]Loading train:  72%|███████▏  | 204/285 [04:20<01:23,  1.04s/it]Loading train:  72%|███████▏  | 205/285 [04:21<01:22,  1.03s/it]Loading train:  72%|███████▏  | 206/285 [04:22<01:21,  1.03s/it]Loading train:  73%|███████▎  | 207/285 [04:24<01:23,  1.08s/it]Loading train:  73%|███████▎  | 208/285 [04:25<01:26,  1.12s/it]Loading train:  73%|███████▎  | 209/285 [04:26<01:24,  1.11s/it]Loading train:  74%|███████▎  | 210/285 [04:27<01:16,  1.03s/it]Loading train:  74%|███████▍  | 211/285 [04:28<01:12,  1.03it/s]Loading train:  74%|███████▍  | 212/285 [04:29<01:11,  1.03it/s]Loading train:  75%|███████▍  | 213/285 [04:30<01:09,  1.03it/s]Loading train:  75%|███████▌  | 214/285 [04:30<01:07,  1.05it/s]Loading train:  75%|███████▌  | 215/285 [04:32<01:10,  1.01s/it]Loading train:  76%|███████▌  | 216/285 [04:32<01:07,  1.02it/s]Loading train:  76%|███████▌  | 217/285 [04:34<01:11,  1.05s/it]Loading train:  76%|███████▋  | 218/285 [04:35<01:13,  1.09s/it]Loading train:  77%|███████▋  | 219/285 [04:36<01:11,  1.08s/it]Loading train:  77%|███████▋  | 220/285 [04:37<01:06,  1.02s/it]Loading train:  78%|███████▊  | 221/285 [04:38<01:04,  1.00s/it]Loading train:  78%|███████▊  | 222/285 [04:39<01:02,  1.00it/s]Loading train:  78%|███████▊  | 223/285 [04:40<01:02,  1.01s/it]Loading train:  79%|███████▊  | 224/285 [04:41<00:59,  1.02it/s]Loading train:  79%|███████▉  | 225/285 [04:42<00:58,  1.03it/s]Loading train:  79%|███████▉  | 226/285 [04:43<00:59,  1.01s/it]Loading train:  80%|███████▉  | 227/285 [04:44<01:00,  1.04s/it]Loading train:  80%|████████  | 228/285 [04:45<01:03,  1.11s/it]Loading train:  80%|████████  | 229/285 [04:46<01:00,  1.09s/it]Loading train:  81%|████████  | 230/285 [04:47<00:56,  1.04s/it]Loading train:  81%|████████  | 231/285 [04:48<00:56,  1.04s/it]Loading train:  81%|████████▏ | 232/285 [04:49<00:53,  1.01s/it]Loading train:  82%|████████▏ | 233/285 [04:50<00:50,  1.02it/s]Loading train:  82%|████████▏ | 234/285 [04:51<00:52,  1.04s/it]Loading train:  82%|████████▏ | 235/285 [04:52<00:50,  1.01s/it]Loading train:  83%|████████▎ | 236/285 [04:53<00:53,  1.09s/it]Loading train:  83%|████████▎ | 237/285 [04:55<00:55,  1.16s/it]Loading train:  84%|████████▎ | 238/285 [04:56<00:53,  1.13s/it]Loading train:  84%|████████▍ | 239/285 [04:57<00:49,  1.09s/it]Loading train:  84%|████████▍ | 240/285 [04:58<00:47,  1.05s/it]Loading train:  85%|████████▍ | 241/285 [04:59<00:43,  1.00it/s]Loading train:  85%|████████▍ | 242/285 [04:59<00:41,  1.03it/s]Loading train:  85%|████████▌ | 243/285 [05:00<00:38,  1.08it/s]Loading train:  86%|████████▌ | 244/285 [05:01<00:40,  1.01it/s]Loading train:  86%|████████▌ | 245/285 [05:02<00:38,  1.03it/s]Loading train:  86%|████████▋ | 246/285 [05:04<00:39,  1.02s/it]Loading train:  87%|████████▋ | 247/285 [05:05<00:38,  1.02s/it]Loading train:  87%|████████▋ | 248/285 [05:06<00:37,  1.01s/it]Loading train:  87%|████████▋ | 249/285 [05:07<00:36,  1.00s/it]Loading train:  88%|████████▊ | 250/285 [05:07<00:33,  1.03it/s]Loading train:  88%|████████▊ | 251/285 [05:08<00:33,  1.01it/s]Loading train:  88%|████████▊ | 252/285 [05:09<00:31,  1.04it/s]Loading train:  89%|████████▉ | 253/285 [05:11<00:32,  1.03s/it]Loading train:  89%|████████▉ | 254/285 [05:12<00:31,  1.03s/it]Loading train:  89%|████████▉ | 255/285 [05:13<00:30,  1.01s/it]Loading train:  90%|████████▉ | 256/285 [05:13<00:28,  1.03it/s]Loading train:  90%|█████████ | 257/285 [05:14<00:27,  1.02it/s]Loading train:  91%|█████████ | 258/285 [05:16<00:27,  1.03s/it]Loading train:  91%|█████████ | 259/285 [05:17<00:26,  1.02s/it]Loading train:  91%|█████████ | 260/285 [05:18<00:25,  1.03s/it]Loading train:  92%|█████████▏| 261/285 [05:19<00:24,  1.03s/it]Loading train:  92%|█████████▏| 262/285 [05:20<00:22,  1.00it/s]Loading train:  92%|█████████▏| 263/285 [05:21<00:22,  1.00s/it]Loading train:  93%|█████████▎| 264/285 [05:22<00:22,  1.05s/it]Loading train:  93%|█████████▎| 265/285 [05:23<00:20,  1.04s/it]Loading train:  93%|█████████▎| 266/285 [05:24<00:18,  1.00it/s]Loading train:  94%|█████████▎| 267/285 [05:25<00:17,  1.03it/s]Loading train:  94%|█████████▍| 268/285 [05:26<00:16,  1.03it/s]Loading train:  94%|█████████▍| 269/285 [05:27<00:15,  1.02it/s]Loading train:  95%|█████████▍| 270/285 [05:27<00:14,  1.03it/s]Loading train:  95%|█████████▌| 271/285 [05:28<00:12,  1.08it/s]Loading train:  95%|█████████▌| 272/285 [05:29<00:11,  1.09it/s]Loading train:  96%|█████████▌| 273/285 [05:30<00:11,  1.05it/s]Loading train:  96%|█████████▌| 274/285 [05:31<00:10,  1.08it/s]Loading train:  96%|█████████▋| 275/285 [05:32<00:09,  1.05it/s]Loading train:  97%|█████████▋| 276/285 [05:33<00:08,  1.05it/s]Loading train:  97%|█████████▋| 277/285 [05:34<00:07,  1.03it/s]Loading train:  98%|█████████▊| 278/285 [05:35<00:06,  1.02it/s]Loading train:  98%|█████████▊| 279/285 [05:36<00:06,  1.01s/it]Loading train:  98%|█████████▊| 280/285 [05:37<00:05,  1.00s/it]Loading train:  99%|█████████▊| 281/285 [05:38<00:03,  1.04it/s]Loading train:  99%|█████████▉| 282/285 [05:39<00:02,  1.02it/s]Loading train:  99%|█████████▉| 283/285 [05:40<00:02,  1.05s/it]Loading train: 100%|█████████▉| 284/285 [05:41<00:01,  1.05s/it]Loading train: 100%|██████████| 285/285 [05:42<00:00,  1.09s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   4%|▍         | 12/285 [00:00<00:02, 116.20it/s]concatenating: train:   8%|▊         | 24/285 [00:00<00:02, 116.14it/s]concatenating: train:  13%|█▎        | 37/285 [00:00<00:02, 118.67it/s]concatenating: train:  17%|█▋        | 49/285 [00:00<00:01, 118.88it/s]concatenating: train:  22%|██▏       | 62/285 [00:00<00:01, 120.69it/s]concatenating: train:  26%|██▌       | 73/285 [00:00<00:01, 114.49it/s]concatenating: train:  29%|██▉       | 84/285 [00:00<00:01, 110.22it/s]concatenating: train:  36%|███▋      | 104/285 [00:00<00:01, 126.84it/s]concatenating: train:  46%|████▋     | 132/285 [00:00<00:01, 151.15it/s]concatenating: train:  57%|█████▋    | 163/285 [00:01<00:00, 177.91it/s]concatenating: train:  68%|██████▊   | 195/285 [00:01<00:00, 204.35it/s]concatenating: train:  79%|███████▊  | 224/285 [00:01<00:00, 222.80it/s]concatenating: train:  88%|████████▊ | 250/285 [00:01<00:00, 186.66it/s]concatenating: train:  95%|█████████▌| 272/285 [00:01<00:00, 170.13it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 174.33it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.44s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.41s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.36s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 55.18it/s]2019-07-10 23:11:35.050341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-10 23:11:35.050452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-10 23:11:35.050467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-10 23:11:35.050476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-10 23:11:35.050902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.06it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  5.99it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.63it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  7.02it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  6.51it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.55it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  6.55it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.46it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.05it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.65it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:01,  9.55it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.87it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01, 10.13it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.57it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.49it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.95it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.98it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  8.02it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 11.02it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 26, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 13, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 26, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   10820       dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 52, 20)   0           activation_11[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 80)   0           dropout_5[0][0]                  
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 13)   1053        concatenate_7[0][0]              
==================================================================================================
Total params: 234,993
Trainable params: 60,273
Non-trainable params: 174,720
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 17s - loss: 2.0387 - acc: 0.4035 - mDice: 0.2392 - val_loss: 3.4070 - val_acc: 0.9139 - val_mDice: 0.1464

Epoch 00001: val_mDice improved from -inf to 0.14642, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 12s - loss: 0.6054 - acc: 0.9169 - mDice: 0.5331 - val_loss: 0.6282 - val_acc: 0.9391 - val_mDice: 0.5215

Epoch 00002: val_mDice improved from 0.14642 to 0.52149, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 12s - loss: 0.4917 - acc: 0.9283 - mDice: 0.5980 - val_loss: 0.7263 - val_acc: 0.9385 - val_mDice: 0.4959

Epoch 00003: val_mDice did not improve from 0.52149
Epoch 4/300
 - 12s - loss: 0.4403 - acc: 0.9368 - mDice: 0.6298 - val_loss: 0.4893 - val_acc: 0.9507 - val_mDice: 0.6026

Epoch 00004: val_mDice improved from 0.52149 to 0.60256, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 12s - loss: 0.4132 - acc: 0.9415 - mDice: 0.6476 - val_loss: 0.4783 - val_acc: 0.9518 - val_mDice: 0.6081

Epoch 00005: val_mDice improved from 0.60256 to 0.60809, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 12s - loss: 0.3935 - acc: 0.9439 - mDice: 0.6606 - val_loss: 0.4893 - val_acc: 0.9516 - val_mDice: 0.6033

Epoch 00006: val_mDice did not improve from 0.60809
Epoch 7/300
 - 12s - loss: 0.3783 - acc: 0.9453 - mDice: 0.6711 - val_loss: 0.4728 - val_acc: 0.9534 - val_mDice: 0.6130

Epoch 00007: val_mDice improved from 0.60809 to 0.61304, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 12s - loss: 0.3631 - acc: 0.9466 - mDice: 0.6814 - val_loss: 0.4493 - val_acc: 0.9534 - val_mDice: 0.6274

Epoch 00008: val_mDice improved from 0.61304 to 0.62738, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 12s - loss: 0.3570 - acc: 0.9474 - mDice: 0.6861 - val_loss: 0.4544 - val_acc: 0.9541 - val_mDice: 0.6252

Epoch 00009: val_mDice did not improve from 0.62738
Epoch 10/300
 - 12s - loss: 0.3467 - acc: 0.9483 - mDice: 0.6932 - val_loss: 0.4942 - val_acc: 0.9526 - val_mDice: 0.6034

Epoch 00010: val_mDice did not improve from 0.62738
Epoch 11/300
 - 12s - loss: 0.3370 - acc: 0.9489 - mDice: 0.7000 - val_loss: 0.4422 - val_acc: 0.9509 - val_mDice: 0.6299

Epoch 00011: val_mDice improved from 0.62738 to 0.62986, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 12s - loss: 0.3298 - acc: 0.9495 - mDice: 0.7052 - val_loss: 0.4948 - val_acc: 0.9507 - val_mDice: 0.6026

Epoch 00012: val_mDice did not improve from 0.62986
Epoch 13/300
 - 12s - loss: 0.3236 - acc: 0.9500 - mDice: 0.7097 - val_loss: 0.4577 - val_acc: 0.9529 - val_mDice: 0.6225

Epoch 00013: val_mDice did not improve from 0.62986
Epoch 14/300
 - 12s - loss: 0.3183 - acc: 0.9505 - mDice: 0.7137 - val_loss: 0.4425 - val_acc: 0.9540 - val_mDice: 0.6311

Epoch 00014: val_mDice improved from 0.62986 to 0.63111, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 12s - loss: 0.3137 - acc: 0.9508 - mDice: 0.7169 - val_loss: 0.4702 - val_acc: 0.9503 - val_mDice: 0.6137

Epoch 00015: val_mDice did not improve from 0.63111
Epoch 16/300
 - 12s - loss: 0.3107 - acc: 0.9511 - mDice: 0.7194 - val_loss: 0.4664 - val_acc: 0.9517 - val_mDice: 0.6219

Epoch 00016: val_mDice did not improve from 0.63111
Epoch 17/300
 - 12s - loss: 0.3055 - acc: 0.9515 - mDice: 0.7231 - val_loss: 0.4580 - val_acc: 0.9509 - val_mDice: 0.6222

Epoch 00017: val_mDice did not improve from 0.63111
Epoch 18/300
 - 12s - loss: 0.3018 - acc: 0.9518 - mDice: 0.7259 - val_loss: 0.4515 - val_acc: 0.9543 - val_mDice: 0.6260

Epoch 00018: val_mDice did not improve from 0.63111
Epoch 19/300
 - 12s - loss: 0.2984 - acc: 0.9519 - mDice: 0.7285 - val_loss: 0.5628 - val_acc: 0.9511 - val_mDice: 0.5746

Epoch 00019: val_mDice did not improve from 0.63111
Epoch 20/300
 - 12s - loss: 0.2951 - acc: 0.9522 - mDice: 0.7309 - val_loss: 0.4941 - val_acc: 0.9535 - val_mDice: 0.6023

Epoch 00020: val_mDice did not improve from 0.63111
Epoch 21/300
 - 12s - loss: 0.2931 - acc: 0.9524 - mDice: 0.7325 - val_loss: 0.4602 - val_acc: 0.9532 - val_mDice: 0.6220

Epoch 00021: val_mDice did not improve from 0.63111
Epoch 22/300
 - 12s - loss: 0.2908 - acc: 0.9527 - mDice: 0.7346 - val_loss: 0.4655 - val_acc: 0.9540 - val_mDice: 0.6201

Epoch 00022: val_mDice did not improve from 0.63111
Epoch 23/300
 - 12s - loss: 0.2887 - acc: 0.9528 - mDice: 0.7360 - val_loss: 0.4624 - val_acc: 0.9534 - val_mDice: 0.6194

Epoch 00023: val_mDice did not improve from 0.63111
Epoch 24/300
 - 12s - loss: 0.2855 - acc: 0.9530 - mDice: 0.7384 - val_loss: 0.4854 - val_acc: 0.9536 - val_mDice: 0.6115

Epoch 00024: val_mDice did not improve from 0.63111
Epoch 25/300
 - 12s - loss: 0.2824 - acc: 0.9532 - mDice: 0.7408 - val_loss: 0.4966 - val_acc: 0.9500 - val_mDice: 0.6004

Epoch 00025: val_mDice did not improve from 0.63111
Epoch 26/300
 - 12s - loss: 0.2807 - acc: 0.9533 - mDice: 0.7420 - val_loss: 0.4958 - val_acc: 0.9530 - val_mDice: 0.6055

Epoch 00026: val_mDice did not improve from 0.63111
Epoch 27/300
 - 12s - loss: 0.2791 - acc: 0.9534 - mDice: 0.7434 - val_loss: 0.4694 - val_acc: 0.9528 - val_mDice: 0.6170

Epoch 00027: val_mDice did not improve from 0.63111
Epoch 28/300
 - 12s - loss: 0.2760 - acc: 0.9536 - mDice: 0.7456 - val_loss: 0.4772 - val_acc: 0.9531 - val_mDice: 0.6149

Epoch 00028: val_mDice did not improve from 0.63111
Epoch 29/300
 - 12s - loss: 0.2752 - acc: 0.9537 - mDice: 0.7463 - val_loss: 0.4573 - val_acc: 0.9530 - val_mDice: 0.6237

Epoch 00029: val_mDice did not improve from 0.63111
Epoch 30/300
 - 12s - loss: 0.2727 - acc: 0.9538 - mDice: 0.7483 - val_loss: 0.4724 - val_acc: 0.9513 - val_mDice: 0.6143

Epoch 00030: val_mDice did not improve from 0.63111
Epoch 31/300
 - 12s - loss: 0.2713 - acc: 0.9539 - mDice: 0.7493 - val_loss: 0.5663 - val_acc: 0.9509 - val_mDice: 0.5684

Epoch 00031: val_mDice did not improve from 0.63111
Epoch 32/300
 - 12s - loss: 0.2702 - acc: 0.9540 - mDice: 0.7502 - val_loss: 0.4806 - val_acc: 0.9526 - val_mDice: 0.6101

Epoch 00032: val_mDice did not improve from 0.63111
Epoch 33/300
 - 12s - loss: 0.2687 - acc: 0.9542 - mDice: 0.7514 - val_loss: 0.4610 - val_acc: 0.9531 - val_mDice: 0.6204

Epoch 00033: val_mDice did not improve from 0.63111
Epoch 34/300
 - 12s - loss: 0.2671 - acc: 0.9542 - mDice: 0.7525 - val_loss: 0.5116 - val_acc: 0.9502 - val_mDice: 0.5948

Epoch 00034: val_mDice did not improve from 0.63111
Epoch 35/300
 - 12s - loss: 0.2660 - acc: 0.9544 - mDice: 0.7536 - val_loss: 0.4830 - val_acc: 0.9527 - val_mDice: 0.6115

Epoch 00035: val_mDice did not improve from 0.63111
Epoch 36/300
 - 12s - loss: 0.2635 - acc: 0.9544 - mDice: 0.7554 - val_loss: 0.4910 - val_acc: 0.9507 - val_mDice: 0.6040

Epoch 00036: val_mDice did not improve from 0.63111
Epoch 37/300
 - 12s - loss: 0.2638 - acc: 0.9545 - mDice: 0.7553 - val_loss: 0.4848 - val_acc: 0.9532 - val_mDice: 0.6135

Epoch 00037: val_mDice did not improve from 0.63111
Epoch 38/300
 - 12s - loss: 0.2614 - acc: 0.9547 - mDice: 0.7571 - val_loss: 0.4834 - val_acc: 0.9505 - val_mDice: 0.6086

Epoch 00038: val_mDice did not improve from 0.63111
Epoch 39/300
 - 12s - loss: 0.2604 - acc: 0.9547 - mDice: 0.7579 - val_loss: 0.4866 - val_acc: 0.9526 - val_mDice: 0.6073

Epoch 00039: val_mDice did not improve from 0.63111
Epoch 40/300
 - 12s - loss: 0.2597 - acc: 0.9547 - mDice: 0.7584 - val_loss: 0.4706 - val_acc: 0.9522 - val_mDice: 0.6149

Epoch 00040: val_mDice did not improve from 0.63111
Epoch 41/300
 - 12s - loss: 0.2578 - acc: 0.9549 - mDice: 0.7599 - val_loss: 0.4692 - val_acc: 0.9538 - val_mDice: 0.6173

Epoch 00041: val_mDice did not improve from 0.63111
Epoch 42/300
 - 12s - loss: 0.2584 - acc: 0.9548 - mDice: 0.7595 - val_loss: 0.4936 - val_acc: 0.9512 - val_mDice: 0.6055

Epoch 00042: val_mDice did not improve from 0.63111
Epoch 43/300
 - 12s - loss: 0.2561 - acc: 0.9551 - mDice: 0.7613 - val_loss: 0.4676 - val_acc: 0.9520 - val_mDice: 0.6170

Epoch 00043: val_mDice did not improve from 0.63111
Epoch 44/300
 - 12s - loss: 0.2543 - acc: 0.9551 - mDice: 0.7626 - val_loss: 0.4733 - val_acc: 0.9533 - val_mDice: 0.6125

Epoch 00044: val_mDice did not improve from 0.63111
Epoch 45/300
 - 12s - loss: 0.2536 - acc: 0.9552 - mDice: 0.7632 - val_loss: 0.4696 - val_acc: 0.9528 - val_mDice: 0.6188

Epoch 00045: val_mDice did not improve from 0.63111
Epoch 46/300
 - 12s - loss: 0.2544 - acc: 0.9552 - mDice: 0.7627 - val_loss: 0.4706 - val_acc: 0.9523 - val_mDice: 0.6160

Epoch 00046: val_mDice did not improve from 0.63111
Epoch 47/300
 - 12s - loss: 0.2515 - acc: 0.9553 - mDice: 0.7649 - val_loss: 0.5131 - val_acc: 0.9513 - val_mDice: 0.5927

Epoch 00047: val_mDice did not improve from 0.63111
Epoch 48/300
 - 12s - loss: 0.2503 - acc: 0.9554 - mDice: 0.7659 - val_loss: 0.4782 - val_acc: 0.9528 - val_mDice: 0.6104

Epoch 00048: val_mDice did not improve from 0.63111
Epoch 49/300
 - 12s - loss: 0.2505 - acc: 0.9555 - mDice: 0.7658 - val_loss: 0.4728 - val_acc: 0.9522 - val_mDice: 0.6184

Epoch 00049: val_mDice did not improve from 0.63111
Epoch 50/300
 - 12s - loss: 0.2503 - acc: 0.9555 - mDice: 0.7659 - val_loss: 0.4902 - val_acc: 0.9531 - val_mDice: 0.6056

Epoch 00050: val_mDice did not improve from 0.63111
Epoch 51/300
 - 12s - loss: 0.2489 - acc: 0.9555 - mDice: 0.7671 - val_loss: 0.4664 - val_acc: 0.9530 - val_mDice: 0.6181

Epoch 00051: val_mDice did not improve from 0.63111
Epoch 52/300
 - 12s - loss: 0.2488 - acc: 0.9556 - mDice: 0.7672 - val_loss: 0.4891 - val_acc: 0.9516 - val_mDice: 0.6102

Epoch 00052: val_mDice did not improve from 0.63111
Epoch 53/300
 - 12s - loss: 0.2485 - acc: 0.9556 - mDice: 0.7674 - val_loss: 0.5249 - val_acc: 0.9525 - val_mDice: 0.5943

Epoch 00053: val_mDice did not improve from 0.63111
Epoch 54/300
 - 12s - loss: 0.2463 - acc: 0.9558 - mDice: 0.7692 - val_loss: 0.4880 - val_acc: 0.9516 - val_mDice: 0.6046

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.42s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.17s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.96s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:17,  1.96s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:37,  1.83s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:40,  1.85s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<08:14,  1.76s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:32,  1.83s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<08:10,  1.76s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:32,  1.84s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:18,  1.80s/it]predicting train subjects:   3%|▎         | 9/285 [00:16<08:51,  1.93s/it]predicting train subjects:   4%|▎         | 10/285 [00:18<09:09,  2.00s/it]predicting train subjects:   4%|▍         | 11/285 [00:20<08:46,  1.92s/it]predicting train subjects:   4%|▍         | 12/285 [00:22<08:55,  1.96s/it]predicting train subjects:   5%|▍         | 13/285 [00:24<08:32,  1.88s/it]predicting train subjects:   5%|▍         | 14/285 [00:26<08:32,  1.89s/it]predicting train subjects:   5%|▌         | 15/285 [00:28<08:55,  1.98s/it]predicting train subjects:   6%|▌         | 16/285 [00:30<09:06,  2.03s/it]predicting train subjects:   6%|▌         | 17/285 [00:32<08:37,  1.93s/it]predicting train subjects:   6%|▋         | 18/285 [00:34<08:41,  1.95s/it]predicting train subjects:   7%|▋         | 19/285 [00:35<08:21,  1.88s/it]predicting train subjects:   7%|▋         | 20/285 [00:37<08:21,  1.89s/it]predicting train subjects:   7%|▋         | 21/285 [00:39<08:48,  2.00s/it]predicting train subjects:   8%|▊         | 22/285 [00:41<08:26,  1.93s/it]predicting train subjects:   8%|▊         | 23/285 [00:43<08:27,  1.94s/it]predicting train subjects:   8%|▊         | 24/285 [00:45<08:04,  1.86s/it]predicting train subjects:   9%|▉         | 25/285 [00:47<08:18,  1.92s/it]predicting train subjects:   9%|▉         | 26/285 [00:49<08:30,  1.97s/it]predicting train subjects:   9%|▉         | 27/285 [00:51<08:01,  1.87s/it]predicting train subjects:  10%|▉         | 28/285 [00:53<08:00,  1.87s/it]predicting train subjects:  10%|█         | 29/285 [00:54<08:03,  1.89s/it]predicting train subjects:  11%|█         | 30/285 [00:57<08:30,  2.00s/it]predicting train subjects:  11%|█         | 31/285 [00:59<08:40,  2.05s/it]predicting train subjects:  11%|█         | 32/285 [01:01<08:09,  1.93s/it]predicting train subjects:  12%|█▏        | 33/285 [01:02<08:04,  1.92s/it]predicting train subjects:  12%|█▏        | 34/285 [01:04<08:02,  1.92s/it]predicting train subjects:  12%|█▏        | 35/285 [01:07<08:21,  2.01s/it]predicting train subjects:  13%|█▎        | 36/285 [01:08<08:01,  1.93s/it]predicting train subjects:  13%|█▎        | 37/285 [01:10<07:51,  1.90s/it]predicting train subjects:  13%|█▎        | 38/285 [01:12<07:57,  1.93s/it]predicting train subjects:  14%|█▎        | 39/285 [01:14<07:36,  1.86s/it]predicting train subjects:  14%|█▍        | 40/285 [01:16<07:35,  1.86s/it]predicting train subjects:  14%|█▍        | 41/285 [01:17<07:25,  1.83s/it]predicting train subjects:  15%|█▍        | 42/285 [01:19<07:16,  1.80s/it]predicting train subjects:  15%|█▌        | 43/285 [01:21<07:25,  1.84s/it]predicting train subjects:  15%|█▌        | 44/285 [01:23<07:39,  1.91s/it]predicting train subjects:  16%|█▌        | 45/285 [01:25<07:17,  1.82s/it]predicting train subjects:  16%|█▌        | 46/285 [01:27<07:43,  1.94s/it]predicting train subjects:  16%|█▋        | 47/285 [01:29<07:32,  1.90s/it]predicting train subjects:  17%|█▋        | 48/285 [01:31<07:34,  1.92s/it]predicting train subjects:  17%|█▋        | 49/285 [01:33<07:50,  1.99s/it]predicting train subjects:  18%|█▊        | 50/285 [01:35<07:40,  1.96s/it]predicting train subjects:  18%|█▊        | 51/285 [01:37<07:47,  2.00s/it]predicting train subjects:  18%|█▊        | 52/285 [01:39<07:21,  1.89s/it]predicting train subjects:  19%|█▊        | 53/285 [01:41<07:22,  1.91s/it]predicting train subjects:  19%|█▉        | 54/285 [01:43<07:41,  2.00s/it]predicting train subjects:  19%|█▉        | 55/285 [01:44<07:19,  1.91s/it]predicting train subjects:  20%|█▉        | 56/285 [01:46<07:22,  1.93s/it]predicting train subjects:  20%|██        | 57/285 [01:48<07:05,  1.86s/it]predicting train subjects:  20%|██        | 58/285 [01:50<07:09,  1.89s/it]predicting train subjects:  21%|██        | 59/285 [01:52<07:28,  1.98s/it]predicting train subjects:  21%|██        | 60/285 [01:54<07:42,  2.05s/it]predicting train subjects:  21%|██▏       | 61/285 [01:56<07:10,  1.92s/it]predicting train subjects:  22%|██▏       | 62/285 [01:58<07:07,  1.92s/it]predicting train subjects:  22%|██▏       | 63/285 [02:00<07:03,  1.91s/it]predicting train subjects:  22%|██▏       | 64/285 [02:02<06:52,  1.86s/it]predicting train subjects:  23%|██▎       | 65/285 [02:04<06:59,  1.91s/it]predicting train subjects:  23%|██▎       | 66/285 [02:06<07:00,  1.92s/it]predicting train subjects:  24%|██▎       | 67/285 [02:08<07:05,  1.95s/it]predicting train subjects:  24%|██▍       | 68/285 [02:09<06:52,  1.90s/it]predicting train subjects:  24%|██▍       | 69/285 [02:11<06:52,  1.91s/it]predicting train subjects:  25%|██▍       | 70/285 [02:13<06:52,  1.92s/it]predicting train subjects:  25%|██▍       | 71/285 [02:15<06:50,  1.92s/it]predicting train subjects:  25%|██▌       | 72/285 [02:17<06:36,  1.86s/it]predicting train subjects:  26%|██▌       | 73/285 [02:19<06:43,  1.90s/it]predicting train subjects:  26%|██▌       | 74/285 [02:21<06:44,  1.92s/it]predicting train subjects:  26%|██▋       | 75/285 [02:23<06:42,  1.92s/it]predicting train subjects:  27%|██▋       | 76/285 [02:25<06:43,  1.93s/it]predicting train subjects:  27%|██▋       | 77/285 [02:26<06:27,  1.86s/it]predicting train subjects:  27%|██▋       | 78/285 [02:28<06:20,  1.84s/it]predicting train subjects:  28%|██▊       | 79/285 [02:30<06:19,  1.84s/it]predicting train subjects:  28%|██▊       | 80/285 [02:32<06:23,  1.87s/it]predicting train subjects:  28%|██▊       | 81/285 [02:34<06:17,  1.85s/it]predicting train subjects:  29%|██▉       | 82/285 [02:36<06:22,  1.88s/it]predicting train subjects:  29%|██▉       | 83/285 [02:38<06:15,  1.86s/it]predicting train subjects:  29%|██▉       | 84/285 [02:39<06:11,  1.85s/it]predicting train subjects:  30%|██▉       | 85/285 [02:41<06:15,  1.88s/it]predicting train subjects:  30%|███       | 86/285 [02:43<06:20,  1.91s/it]predicting train subjects:  31%|███       | 87/285 [02:45<06:27,  1.96s/it]predicting train subjects:  31%|███       | 88/285 [02:47<06:20,  1.93s/it]predicting train subjects:  31%|███       | 89/285 [02:49<06:27,  1.97s/it]predicting train subjects:  32%|███▏      | 90/285 [02:51<06:24,  1.97s/it]predicting train subjects:  32%|███▏      | 91/285 [02:53<06:12,  1.92s/it]predicting train subjects:  32%|███▏      | 92/285 [02:55<06:08,  1.91s/it]predicting train subjects:  33%|███▎      | 93/285 [02:57<06:03,  1.90s/it]predicting train subjects:  33%|███▎      | 94/285 [02:59<06:03,  1.90s/it]predicting train subjects:  33%|███▎      | 95/285 [03:01<06:08,  1.94s/it]predicting train subjects:  34%|███▎      | 96/285 [03:03<06:02,  1.92s/it]predicting train subjects:  34%|███▍      | 97/285 [03:05<06:01,  1.92s/it]predicting train subjects:  34%|███▍      | 98/285 [03:07<06:00,  1.93s/it]predicting train subjects:  35%|███▍      | 99/285 [03:08<05:57,  1.92s/it]predicting train subjects:  35%|███▌      | 100/285 [03:10<05:59,  1.94s/it]predicting train subjects:  35%|███▌      | 101/285 [03:12<05:48,  1.90s/it]predicting train subjects:  36%|███▌      | 102/285 [03:14<05:50,  1.91s/it]predicting train subjects:  36%|███▌      | 103/285 [03:16<05:43,  1.89s/it]predicting train subjects:  36%|███▋      | 104/285 [03:18<05:47,  1.92s/it]predicting train subjects:  37%|███▋      | 105/285 [03:20<05:46,  1.92s/it]predicting train subjects:  37%|███▋      | 106/285 [03:22<05:36,  1.88s/it]predicting train subjects:  38%|███▊      | 107/285 [03:24<05:38,  1.90s/it]predicting train subjects:  38%|███▊      | 108/285 [03:26<05:32,  1.88s/it]predicting train subjects:  38%|███▊      | 109/285 [03:27<05:35,  1.91s/it]predicting train subjects:  39%|███▊      | 110/285 [03:30<05:39,  1.94s/it]predicting train subjects:  39%|███▉      | 111/285 [03:31<05:32,  1.91s/it]predicting train subjects:  39%|███▉      | 112/285 [03:33<05:29,  1.90s/it]predicting train subjects:  40%|███▉      | 113/285 [03:35<05:32,  1.93s/it]predicting train subjects:  40%|████      | 114/285 [03:37<05:31,  1.94s/it]predicting train subjects:  40%|████      | 115/285 [03:39<05:30,  1.95s/it]predicting train subjects:  41%|████      | 116/285 [03:41<05:33,  1.98s/it]predicting train subjects:  41%|████      | 117/285 [03:43<05:21,  1.92s/it]predicting train subjects:  41%|████▏     | 118/285 [03:45<05:14,  1.88s/it]predicting train subjects:  42%|████▏     | 119/285 [03:47<05:16,  1.91s/it]predicting train subjects:  42%|████▏     | 120/285 [03:49<05:08,  1.87s/it]predicting train subjects:  42%|████▏     | 121/285 [03:50<05:04,  1.86s/it]predicting train subjects:  43%|████▎     | 122/285 [03:52<04:48,  1.77s/it]predicting train subjects:  43%|████▎     | 123/285 [03:53<04:35,  1.70s/it]predicting train subjects:  44%|████▎     | 124/285 [03:55<04:34,  1.71s/it]predicting train subjects:  44%|████▍     | 125/285 [03:57<04:37,  1.73s/it]predicting train subjects:  44%|████▍     | 126/285 [03:59<04:34,  1.73s/it]predicting train subjects:  45%|████▍     | 127/285 [04:00<04:34,  1.74s/it]predicting train subjects:  45%|████▍     | 128/285 [04:02<04:43,  1.80s/it]predicting train subjects:  45%|████▌     | 129/285 [04:04<04:39,  1.79s/it]predicting train subjects:  46%|████▌     | 130/285 [04:06<04:32,  1.76s/it]predicting train subjects:  46%|████▌     | 131/285 [04:07<04:24,  1.72s/it]predicting train subjects:  46%|████▋     | 132/285 [04:09<04:23,  1.72s/it]predicting train subjects:  47%|████▋     | 133/285 [04:11<04:21,  1.72s/it]predicting train subjects:  47%|████▋     | 134/285 [04:13<04:17,  1.71s/it]predicting train subjects:  47%|████▋     | 135/285 [04:14<04:13,  1.69s/it]predicting train subjects:  48%|████▊     | 136/285 [04:16<04:13,  1.70s/it]predicting train subjects:  48%|████▊     | 137/285 [04:18<04:16,  1.73s/it]predicting train subjects:  48%|████▊     | 138/285 [04:19<04:07,  1.68s/it]predicting train subjects:  49%|████▉     | 139/285 [04:21<04:20,  1.78s/it]predicting train subjects:  49%|████▉     | 140/285 [04:23<04:18,  1.78s/it]predicting train subjects:  49%|████▉     | 141/285 [04:25<04:08,  1.73s/it]predicting train subjects:  50%|████▉     | 142/285 [04:26<04:00,  1.68s/it]predicting train subjects:  50%|█████     | 143/285 [04:28<03:59,  1.68s/it]predicting train subjects:  51%|█████     | 144/285 [04:30<04:09,  1.77s/it]predicting train subjects:  51%|█████     | 145/285 [04:32<04:09,  1.78s/it]predicting train subjects:  51%|█████     | 146/285 [04:34<04:10,  1.80s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:36<04:12,  1.83s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:37<04:09,  1.82s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:39<04:03,  1.79s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:41<04:02,  1.79s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:43<04:01,  1.80s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:44<03:54,  1.76s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:46<03:50,  1.75s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:48<03:52,  1.78s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:50<03:50,  1.77s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:51<03:50,  1.79s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:53<03:47,  1.78s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:55<03:45,  1.77s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:57<03:38,  1.74s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:58<03:32,  1.70s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:00<03:39,  1.77s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:02<03:34,  1.74s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:04<03:33,  1.75s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:05<03:32,  1.76s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:07<03:28,  1.74s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:09<03:24,  1.72s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:11<03:24,  1.73s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:12<03:21,  1.72s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:14<03:22,  1.74s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:16<03:19,  1.74s/it]predicting train subjects:  60%|██████    | 171/285 [05:17<03:17,  1.73s/it]predicting train subjects:  60%|██████    | 172/285 [05:19<03:22,  1.80s/it]predicting train subjects:  61%|██████    | 173/285 [05:21<03:15,  1.74s/it]predicting train subjects:  61%|██████    | 174/285 [05:23<03:09,  1.71s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:25<03:13,  1.76s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:26<03:13,  1.77s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:28<03:08,  1.74s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:30<03:02,  1.70s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:31<02:59,  1.69s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:33<03:06,  1.78s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:35<03:06,  1.80s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:37<03:04,  1.79s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:38<02:54,  1.71s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:40<02:47,  1.66s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:42<02:46,  1.66s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:44<02:57,  1.79s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:46<03:10,  1.94s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:48<03:08,  1.95s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:50<02:56,  1.84s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:51<02:46,  1.75s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:53<02:46,  1.77s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:55<02:48,  1.82s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:57<02:47,  1.83s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:58<02:43,  1.79s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:00<02:36,  1.74s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:02<02:43,  1.84s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:04<02:50,  1.94s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:06<02:54,  2.01s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:08<02:43,  1.91s/it]predicting train subjects:  70%|███████   | 200/285 [06:10<02:36,  1.84s/it]predicting train subjects:  71%|███████   | 201/285 [06:12<02:42,  1.93s/it]predicting train subjects:  71%|███████   | 202/285 [06:14<02:41,  1.94s/it]predicting train subjects:  71%|███████   | 203/285 [06:16<02:43,  2.00s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:18<02:32,  1.88s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:20<02:30,  1.89s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:21<02:24,  1.83s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:24<02:33,  1.97s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:26<02:35,  2.01s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:28<02:34,  2.04s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:29<02:22,  1.90s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:31<02:15,  1.84s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:33<02:16,  1.86s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:35<02:15,  1.88s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:37<02:09,  1.82s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:39<02:16,  1.95s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:40<02:09,  1.88s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:43<02:13,  1.97s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:45<02:15,  2.02s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:47<02:16,  2.06s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:49<02:06,  1.94s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:50<02:00,  1.88s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:52<01:57,  1.87s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:54<01:49,  1.76s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:55<01:43,  1.69s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:57<01:40,  1.67s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:59<01:45,  1.79s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:01<01:52,  1.93s/it]predicting train subjects:  80%|████████  | 228/285 [07:03<01:51,  1.96s/it]predicting train subjects:  80%|████████  | 229/285 [07:05<01:47,  1.92s/it]predicting train subjects:  81%|████████  | 230/285 [07:07<01:40,  1.84s/it]predicting train subjects:  81%|████████  | 231/285 [07:08<01:37,  1.81s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:10<01:37,  1.83s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:12<01:36,  1.86s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:14<01:37,  1.91s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:16<01:30,  1.81s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:18<01:31,  1.87s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:20<01:31,  1.91s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:22<01:32,  1.97s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:24<01:30,  1.97s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:26<01:26,  1.91s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:27<01:20,  1.84s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:29<01:17,  1.79s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:31<01:13,  1.76s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:33<01:14,  1.81s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:34<01:09,  1.74s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:36<01:10,  1.82s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:38<01:12,  1.92s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:40<01:10,  1.90s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:42<01:06,  1.85s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:44<01:02,  1.79s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:45<00:59,  1.75s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:47<00:56,  1.71s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:49<00:58,  1.83s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:51<00:57,  1.86s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:53<00:56,  1.88s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:54<00:51,  1.79s/it]predicting train subjects:  90%|█████████ | 257/285 [07:56<00:49,  1.77s/it]predicting train subjects:  91%|█████████ | 258/285 [07:58<00:50,  1.85s/it]predicting train subjects:  91%|█████████ | 259/285 [08:00<00:49,  1.91s/it]predicting train subjects:  91%|█████████ | 260/285 [08:02<00:45,  1.83s/it]predicting train subjects:  92%|█████████▏| 261/285 [08:04<00:42,  1.79s/it]predicting train subjects:  92%|█████████▏| 262/285 [08:05<00:40,  1.75s/it]predicting train subjects:  92%|█████████▏| 263/285 [08:07<00:37,  1.70s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:09<00:38,  1.83s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:11<00:38,  1.92s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:13<00:35,  1.84s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:15<00:32,  1.81s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:17<00:32,  1.92s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:19<00:30,  1.90s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:20<00:26,  1.79s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:22<00:24,  1.75s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:23<00:22,  1.75s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:25<00:21,  1.76s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:27<00:18,  1.72s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:29<00:18,  1.85s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:31<00:17,  1.92s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:33<00:14,  1.84s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:35<00:12,  1.82s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:37<00:11,  1.88s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:38<00:09,  1.82s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:40<00:07,  1.78s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:42<00:05,  1.75s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:44<00:03,  1.91s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:46<00:01,  1.98s/it]predicting train subjects: 100%|██████████| 285/285 [08:48<00:00,  1.99s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<09:12,  1.95s/it]Loading train:   1%|          | 2/285 [00:03<08:27,  1.79s/it]Loading train:   1%|          | 3/285 [00:05<08:42,  1.85s/it]Loading train:   1%|▏         | 4/285 [00:06<08:20,  1.78s/it]Loading train:   2%|▏         | 5/285 [00:08<08:15,  1.77s/it]Loading train:   2%|▏         | 6/285 [00:10<08:09,  1.76s/it]Loading train:   2%|▏         | 7/285 [00:12<08:22,  1.81s/it]Loading train:   3%|▎         | 8/285 [00:14<08:14,  1.78s/it]Loading train:   3%|▎         | 9/285 [00:16<08:30,  1.85s/it]Loading train:   4%|▎         | 10/285 [00:17<07:57,  1.74s/it]Loading train:   4%|▍         | 11/285 [00:18<07:21,  1.61s/it]Loading train:   4%|▍         | 12/285 [00:20<07:07,  1.57s/it]Loading train:   5%|▍         | 13/285 [00:21<06:50,  1.51s/it]Loading train:   5%|▍         | 14/285 [00:23<06:46,  1.50s/it]Loading train:   5%|▌         | 15/285 [00:24<07:01,  1.56s/it]Loading train:   6%|▌         | 16/285 [00:26<06:28,  1.45s/it]Loading train:   6%|▌         | 17/285 [00:27<06:12,  1.39s/it]Loading train:   6%|▋         | 18/285 [00:28<05:54,  1.33s/it]Loading train:   7%|▋         | 19/285 [00:29<05:33,  1.25s/it]Loading train:   7%|▋         | 20/285 [00:30<05:32,  1.25s/it]Loading train:   7%|▋         | 21/285 [00:32<05:49,  1.32s/it]Loading train:   8%|▊         | 22/285 [00:33<05:21,  1.22s/it]Loading train:   8%|▊         | 23/285 [00:34<05:04,  1.16s/it]Loading train:   8%|▊         | 24/285 [00:35<04:39,  1.07s/it]Loading train:   9%|▉         | 25/285 [00:36<04:43,  1.09s/it]Loading train:   9%|▉         | 26/285 [00:37<04:48,  1.11s/it]Loading train:   9%|▉         | 27/285 [00:38<04:43,  1.10s/it]Loading train:  10%|▉         | 28/285 [00:39<04:42,  1.10s/it]Loading train:  10%|█         | 29/285 [00:40<04:47,  1.12s/it]Loading train:  11%|█         | 30/285 [00:42<04:48,  1.13s/it]Loading train:  11%|█         | 31/285 [00:43<04:57,  1.17s/it]Loading train:  11%|█         | 32/285 [00:44<04:55,  1.17s/it]Loading train:  12%|█▏        | 33/285 [00:45<04:49,  1.15s/it]Loading train:  12%|█▏        | 34/285 [00:46<04:41,  1.12s/it]Loading train:  12%|█▏        | 35/285 [00:47<04:43,  1.13s/it]Loading train:  13%|█▎        | 36/285 [00:49<05:06,  1.23s/it]Loading train:  13%|█▎        | 37/285 [00:50<05:07,  1.24s/it]Loading train:  13%|█▎        | 38/285 [00:51<05:05,  1.24s/it]Loading train:  14%|█▎        | 39/285 [00:52<04:32,  1.11s/it]Loading train:  14%|█▍        | 40/285 [00:53<04:33,  1.12s/it]Loading train:  14%|█▍        | 41/285 [00:54<04:22,  1.07s/it]Loading train:  15%|█▍        | 42/285 [00:55<04:13,  1.04s/it]Loading train:  15%|█▌        | 43/285 [00:56<04:21,  1.08s/it]Loading train:  15%|█▌        | 44/285 [00:57<04:24,  1.10s/it]Loading train:  16%|█▌        | 45/285 [00:58<04:21,  1.09s/it]Loading train:  16%|█▌        | 46/285 [01:00<04:26,  1.12s/it]Loading train:  16%|█▋        | 47/285 [01:01<04:23,  1.11s/it]Loading train:  17%|█▋        | 48/285 [01:02<04:29,  1.14s/it]Loading train:  17%|█▋        | 49/285 [01:03<04:21,  1.11s/it]Loading train:  18%|█▊        | 50/285 [01:04<04:25,  1.13s/it]Loading train:  18%|█▊        | 51/285 [01:05<04:30,  1.15s/it]Loading train:  18%|█▊        | 52/285 [01:06<04:20,  1.12s/it]Loading train:  19%|█▊        | 53/285 [01:08<04:25,  1.15s/it]Loading train:  19%|█▉        | 54/285 [01:09<04:23,  1.14s/it]Loading train:  19%|█▉        | 55/285 [01:10<04:15,  1.11s/it]Loading train:  20%|█▉        | 56/285 [01:11<04:16,  1.12s/it]Loading train:  20%|██        | 57/285 [01:12<04:06,  1.08s/it]Loading train:  20%|██        | 58/285 [01:13<04:04,  1.08s/it]Loading train:  21%|██        | 59/285 [01:14<04:11,  1.11s/it]Loading train:  21%|██        | 60/285 [01:15<04:15,  1.14s/it]Loading train:  21%|██▏       | 61/285 [01:16<04:06,  1.10s/it]Loading train:  22%|██▏       | 62/285 [01:18<04:15,  1.14s/it]Loading train:  22%|██▏       | 63/285 [01:19<04:03,  1.10s/it]Loading train:  22%|██▏       | 64/285 [01:20<04:25,  1.20s/it]Loading train:  23%|██▎       | 65/285 [01:22<04:54,  1.34s/it]Loading train:  23%|██▎       | 66/285 [01:23<04:56,  1.36s/it]Loading train:  24%|██▎       | 67/285 [01:24<04:29,  1.23s/it]Loading train:  24%|██▍       | 68/285 [01:25<04:20,  1.20s/it]Loading train:  24%|██▍       | 69/285 [01:26<04:06,  1.14s/it]Loading train:  25%|██▍       | 70/285 [01:27<03:57,  1.10s/it]Loading train:  25%|██▍       | 71/285 [01:28<03:59,  1.12s/it]Loading train:  25%|██▌       | 72/285 [01:29<03:44,  1.05s/it]Loading train:  26%|██▌       | 73/285 [01:30<03:37,  1.02s/it]Loading train:  26%|██▌       | 74/285 [01:31<03:38,  1.04s/it]Loading train:  26%|██▋       | 75/285 [01:32<03:33,  1.02s/it]Loading train:  27%|██▋       | 76/285 [01:33<03:41,  1.06s/it]Loading train:  27%|██▋       | 77/285 [01:34<03:40,  1.06s/it]Loading train:  27%|██▋       | 78/285 [01:35<03:33,  1.03s/it]Loading train:  28%|██▊       | 79/285 [01:37<03:40,  1.07s/it]Loading train:  28%|██▊       | 80/285 [01:38<03:49,  1.12s/it]Loading train:  28%|██▊       | 81/285 [01:39<03:43,  1.10s/it]Loading train:  29%|██▉       | 82/285 [01:40<03:49,  1.13s/it]Loading train:  29%|██▉       | 83/285 [01:41<03:54,  1.16s/it]Loading train:  29%|██▉       | 84/285 [01:42<03:36,  1.08s/it]Loading train:  30%|██▉       | 85/285 [01:43<03:35,  1.08s/it]Loading train:  30%|███       | 86/285 [01:44<03:37,  1.09s/it]Loading train:  31%|███       | 87/285 [01:45<03:34,  1.08s/it]Loading train:  31%|███       | 88/285 [01:46<03:16,  1.00it/s]Loading train:  31%|███       | 89/285 [01:47<03:14,  1.01it/s]Loading train:  32%|███▏      | 90/285 [01:48<03:12,  1.02it/s]Loading train:  32%|███▏      | 91/285 [01:49<02:57,  1.09it/s]Loading train:  32%|███▏      | 92/285 [01:50<03:20,  1.04s/it]Loading train:  33%|███▎      | 93/285 [01:51<03:23,  1.06s/it]Loading train:  33%|███▎      | 94/285 [01:53<03:27,  1.09s/it]Loading train:  33%|███▎      | 95/285 [01:54<03:28,  1.10s/it]Loading train:  34%|███▎      | 96/285 [01:55<03:17,  1.05s/it]Loading train:  34%|███▍      | 97/285 [01:56<03:15,  1.04s/it]Loading train:  34%|███▍      | 98/285 [01:57<03:11,  1.02s/it]Loading train:  35%|███▍      | 99/285 [01:58<03:09,  1.02s/it]Loading train:  35%|███▌      | 100/285 [01:59<03:14,  1.05s/it]Loading train:  35%|███▌      | 101/285 [02:00<03:15,  1.06s/it]Loading train:  36%|███▌      | 102/285 [02:01<03:20,  1.10s/it]Loading train:  36%|███▌      | 103/285 [02:02<03:13,  1.06s/it]Loading train:  36%|███▋      | 104/285 [02:03<03:12,  1.07s/it]Loading train:  37%|███▋      | 105/285 [02:04<03:11,  1.06s/it]Loading train:  37%|███▋      | 106/285 [02:05<03:25,  1.15s/it]Loading train:  38%|███▊      | 107/285 [02:07<03:21,  1.13s/it]Loading train:  38%|███▊      | 108/285 [02:07<03:07,  1.06s/it]Loading train:  38%|███▊      | 109/285 [02:09<03:10,  1.08s/it]Loading train:  39%|███▊      | 110/285 [02:10<03:10,  1.09s/it]Loading train:  39%|███▉      | 111/285 [02:11<02:55,  1.01s/it]Loading train:  39%|███▉      | 112/285 [02:12<03:09,  1.10s/it]Loading train:  40%|███▉      | 113/285 [02:13<02:59,  1.04s/it]Loading train:  40%|████      | 114/285 [02:14<02:49,  1.01it/s]Loading train:  40%|████      | 115/285 [02:15<02:50,  1.00s/it]Loading train:  41%|████      | 116/285 [02:16<02:49,  1.00s/it]Loading train:  41%|████      | 117/285 [02:17<02:50,  1.02s/it]Loading train:  41%|████▏     | 118/285 [02:18<02:44,  1.02it/s]Loading train:  42%|████▏     | 119/285 [02:19<02:54,  1.05s/it]Loading train:  42%|████▏     | 120/285 [02:20<02:50,  1.03s/it]Loading train:  42%|████▏     | 121/285 [02:21<03:07,  1.14s/it]Loading train:  43%|████▎     | 122/285 [02:23<03:13,  1.19s/it]Loading train:  43%|████▎     | 123/285 [02:24<03:23,  1.25s/it]Loading train:  44%|████▎     | 124/285 [02:25<03:02,  1.13s/it]Loading train:  44%|████▍     | 125/285 [02:26<02:48,  1.06s/it]Loading train:  44%|████▍     | 126/285 [02:27<02:49,  1.07s/it]Loading train:  45%|████▍     | 127/285 [02:28<02:51,  1.09s/it]Loading train:  45%|████▍     | 128/285 [02:29<02:51,  1.09s/it]Loading train:  45%|████▌     | 129/285 [02:30<02:49,  1.08s/it]Loading train:  46%|████▌     | 130/285 [02:31<02:57,  1.15s/it]Loading train:  46%|████▌     | 131/285 [02:33<03:15,  1.27s/it]Loading train:  46%|████▋     | 132/285 [02:34<03:20,  1.31s/it]Loading train:  47%|████▋     | 133/285 [02:35<03:12,  1.27s/it]Loading train:  47%|████▋     | 134/285 [02:37<03:30,  1.39s/it]Loading train:  47%|████▋     | 135/285 [02:38<03:08,  1.25s/it]Loading train:  48%|████▊     | 136/285 [02:39<03:04,  1.24s/it]Loading train:  48%|████▊     | 137/285 [02:40<03:01,  1.22s/it]Loading train:  48%|████▊     | 138/285 [02:42<02:53,  1.18s/it]Loading train:  49%|████▉     | 139/285 [02:43<03:19,  1.37s/it]Loading train:  49%|████▉     | 140/285 [02:44<03:05,  1.28s/it]Loading train:  49%|████▉     | 141/285 [02:46<03:12,  1.33s/it]Loading train:  50%|████▉     | 142/285 [02:47<02:52,  1.21s/it]Loading train:  50%|█████     | 143/285 [02:48<03:02,  1.29s/it]Loading train:  51%|█████     | 144/285 [02:49<02:54,  1.24s/it]Loading train:  51%|█████     | 145/285 [02:51<03:12,  1.38s/it]Loading train:  51%|█████     | 146/285 [02:53<03:14,  1.40s/it]Loading train:  52%|█████▏    | 147/285 [02:54<03:29,  1.52s/it]Loading train:  52%|█████▏    | 148/285 [02:56<03:18,  1.45s/it]Loading train:  52%|█████▏    | 149/285 [02:57<03:05,  1.36s/it]Loading train:  53%|█████▎    | 150/285 [02:58<02:50,  1.26s/it]Loading train:  53%|█████▎    | 151/285 [02:59<03:05,  1.38s/it]Loading train:  53%|█████▎    | 152/285 [03:00<02:45,  1.25s/it]Loading train:  54%|█████▎    | 153/285 [03:01<02:33,  1.16s/it]Loading train:  54%|█████▍    | 154/285 [03:03<02:55,  1.34s/it]Loading train:  54%|█████▍    | 155/285 [03:05<02:55,  1.35s/it]Loading train:  55%|█████▍    | 156/285 [03:06<02:44,  1.27s/it]Loading train:  55%|█████▌    | 157/285 [03:07<02:45,  1.29s/it]Loading train:  55%|█████▌    | 158/285 [03:08<02:43,  1.29s/it]Loading train:  56%|█████▌    | 159/285 [03:09<02:36,  1.25s/it]Loading train:  56%|█████▌    | 160/285 [03:11<02:49,  1.36s/it]Loading train:  56%|█████▋    | 161/285 [03:13<03:02,  1.47s/it]Loading train:  57%|█████▋    | 162/285 [03:14<03:11,  1.56s/it]Loading train:  57%|█████▋    | 163/285 [03:16<03:25,  1.68s/it]Loading train:  58%|█████▊    | 164/285 [03:18<03:16,  1.62s/it]Loading train:  58%|█████▊    | 165/285 [03:19<02:46,  1.39s/it]Loading train:  58%|█████▊    | 166/285 [03:20<02:41,  1.36s/it]Loading train:  59%|█████▊    | 167/285 [03:21<02:23,  1.22s/it]Loading train:  59%|█████▉    | 168/285 [03:23<02:36,  1.34s/it]Loading train:  59%|█████▉    | 169/285 [03:24<02:48,  1.45s/it]Loading train:  60%|█████▉    | 170/285 [03:26<02:48,  1.47s/it]Loading train:  60%|██████    | 171/285 [03:27<02:54,  1.53s/it]Loading train:  60%|██████    | 172/285 [03:28<02:34,  1.36s/it]Loading train:  61%|██████    | 173/285 [03:30<02:29,  1.33s/it]Loading train:  61%|██████    | 174/285 [03:31<02:33,  1.38s/it]Loading train:  61%|██████▏   | 175/285 [03:33<02:38,  1.44s/it]Loading train:  62%|██████▏   | 176/285 [03:34<02:29,  1.37s/it]Loading train:  62%|██████▏   | 177/285 [03:35<02:19,  1.29s/it]Loading train:  62%|██████▏   | 178/285 [03:37<02:32,  1.42s/it]Loading train:  63%|██████▎   | 179/285 [03:38<02:16,  1.29s/it]Loading train:  63%|██████▎   | 180/285 [03:40<02:28,  1.42s/it]Loading train:  64%|██████▎   | 181/285 [03:41<02:25,  1.40s/it]Loading train:  64%|██████▍   | 182/285 [03:42<02:23,  1.39s/it]Loading train:  64%|██████▍   | 183/285 [03:44<02:27,  1.45s/it]Loading train:  65%|██████▍   | 184/285 [03:45<02:30,  1.49s/it]Loading train:  65%|██████▍   | 185/285 [03:46<02:13,  1.33s/it]Loading train:  65%|██████▌   | 186/285 [03:48<02:14,  1.36s/it]Loading train:  66%|██████▌   | 187/285 [03:49<02:21,  1.45s/it]Loading train:  66%|██████▌   | 188/285 [03:51<02:28,  1.53s/it]Loading train:  66%|██████▋   | 189/285 [03:53<02:26,  1.52s/it]Loading train:  67%|██████▋   | 190/285 [03:54<02:09,  1.37s/it]Loading train:  67%|██████▋   | 191/285 [03:55<02:13,  1.42s/it]Loading train:  67%|██████▋   | 192/285 [03:57<02:23,  1.54s/it]Loading train:  68%|██████▊   | 193/285 [03:58<02:13,  1.46s/it]Loading train:  68%|██████▊   | 194/285 [04:00<02:05,  1.38s/it]Loading train:  68%|██████▊   | 195/285 [04:01<02:01,  1.35s/it]Loading train:  69%|██████▉   | 196/285 [04:03<02:17,  1.55s/it]Loading train:  69%|██████▉   | 197/285 [04:04<02:18,  1.57s/it]Loading train:  69%|██████▉   | 198/285 [04:06<02:14,  1.55s/it]Loading train:  70%|██████▉   | 199/285 [04:07<02:08,  1.50s/it]Loading train:  70%|███████   | 200/285 [04:09<02:16,  1.60s/it]Loading train:  71%|███████   | 201/285 [04:11<02:11,  1.57s/it]Loading train:  71%|███████   | 202/285 [04:12<02:03,  1.49s/it]Loading train:  71%|███████   | 203/285 [04:13<01:53,  1.38s/it]Loading train:  72%|███████▏  | 204/285 [04:14<01:47,  1.33s/it]Loading train:  72%|███████▏  | 205/285 [04:15<01:40,  1.25s/it]Loading train:  72%|███████▏  | 206/285 [04:16<01:31,  1.16s/it]Loading train:  73%|███████▎  | 207/285 [04:17<01:29,  1.15s/it]Loading train:  73%|███████▎  | 208/285 [04:19<01:39,  1.30s/it]Loading train:  73%|███████▎  | 209/285 [04:21<01:47,  1.42s/it]Loading train:  74%|███████▎  | 210/285 [04:22<01:36,  1.29s/it]Loading train:  74%|███████▍  | 211/285 [04:23<01:41,  1.38s/it]Loading train:  74%|███████▍  | 212/285 [04:25<01:54,  1.57s/it]Loading train:  75%|███████▍  | 213/285 [04:26<01:42,  1.42s/it]Loading train:  75%|███████▌  | 214/285 [04:28<01:37,  1.37s/it]Loading train:  75%|███████▌  | 215/285 [04:30<01:47,  1.54s/it]Loading train:  76%|███████▌  | 216/285 [04:31<01:47,  1.56s/it]Loading train:  76%|███████▌  | 217/285 [04:32<01:37,  1.43s/it]Loading train:  76%|███████▋  | 218/285 [04:34<01:37,  1.45s/it]Loading train:  77%|███████▋  | 219/285 [04:35<01:38,  1.49s/it]Loading train:  77%|███████▋  | 220/285 [04:37<01:31,  1.40s/it]Loading train:  78%|███████▊  | 221/285 [04:38<01:30,  1.41s/it]Loading train:  78%|███████▊  | 222/285 [04:40<01:36,  1.53s/it]Loading train:  78%|███████▊  | 223/285 [04:42<01:41,  1.63s/it]Loading train:  79%|███████▊  | 224/285 [04:43<01:33,  1.53s/it]Loading train:  79%|███████▉  | 225/285 [04:44<01:25,  1.43s/it]Loading train:  79%|███████▉  | 226/285 [04:46<01:26,  1.47s/it]Loading train:  80%|███████▉  | 227/285 [04:47<01:24,  1.45s/it]Loading train:  80%|████████  | 228/285 [04:50<01:38,  1.73s/it]Loading train:  80%|████████  | 229/285 [04:51<01:29,  1.59s/it]Loading train:  81%|████████  | 230/285 [04:52<01:19,  1.44s/it]Loading train:  81%|████████  | 231/285 [04:53<01:16,  1.41s/it]Loading train:  81%|████████▏ | 232/285 [04:55<01:19,  1.49s/it]Loading train:  82%|████████▏ | 233/285 [04:56<01:10,  1.35s/it]Loading train:  82%|████████▏ | 234/285 [04:58<01:14,  1.46s/it]Loading train:  82%|████████▏ | 235/285 [04:59<01:06,  1.33s/it]Loading train:  83%|████████▎ | 236/285 [05:00<01:07,  1.37s/it]Loading train:  83%|████████▎ | 237/285 [05:02<01:14,  1.55s/it]Loading train:  84%|████████▎ | 238/285 [05:04<01:14,  1.59s/it]Loading train:  84%|████████▍ | 239/285 [05:05<01:07,  1.46s/it]Loading train:  84%|████████▍ | 240/285 [05:06<01:00,  1.33s/it]Loading train:  85%|████████▍ | 241/285 [05:07<00:58,  1.32s/it]Loading train:  85%|████████▍ | 242/285 [05:09<01:02,  1.46s/it]Loading train:  85%|████████▌ | 243/285 [05:10<00:54,  1.30s/it]Loading train:  86%|████████▌ | 244/285 [05:12<00:56,  1.39s/it]Loading train:  86%|████████▌ | 245/285 [05:13<00:54,  1.37s/it]Loading train:  86%|████████▋ | 246/285 [05:14<00:53,  1.38s/it]Loading train:  87%|████████▋ | 247/285 [05:16<00:54,  1.44s/it]Loading train:  87%|████████▋ | 248/285 [05:17<00:54,  1.48s/it]Loading train:  87%|████████▋ | 249/285 [05:19<00:49,  1.37s/it]Loading train:  88%|████████▊ | 250/285 [05:20<00:48,  1.38s/it]Loading train:  88%|████████▊ | 251/285 [05:21<00:47,  1.39s/it]Loading train:  88%|████████▊ | 252/285 [05:23<00:47,  1.43s/it]Loading train:  89%|████████▉ | 253/285 [05:25<00:47,  1.47s/it]Loading train:  89%|████████▉ | 254/285 [05:26<00:43,  1.39s/it]Loading train:  89%|████████▉ | 255/285 [05:27<00:40,  1.35s/it]Loading train:  90%|████████▉ | 256/285 [05:28<00:36,  1.27s/it]Loading train:  90%|█████████ | 257/285 [05:29<00:35,  1.27s/it]Loading train:  91%|█████████ | 258/285 [05:31<00:38,  1.42s/it]Loading train:  91%|█████████ | 259/285 [05:33<00:37,  1.46s/it]Loading train:  91%|█████████ | 260/285 [05:34<00:33,  1.35s/it]Loading train:  92%|█████████▏| 261/285 [05:35<00:33,  1.39s/it]Loading train:  92%|█████████▏| 262/285 [05:37<00:32,  1.42s/it]Loading train:  92%|█████████▏| 263/285 [05:38<00:32,  1.48s/it]Loading train:  93%|█████████▎| 264/285 [05:40<00:32,  1.53s/it]Loading train:  93%|█████████▎| 265/285 [05:41<00:29,  1.48s/it]Loading train:  93%|█████████▎| 266/285 [05:42<00:26,  1.37s/it]Loading train:  94%|█████████▎| 267/285 [05:44<00:23,  1.29s/it]Loading train:  94%|█████████▍| 268/285 [05:45<00:24,  1.46s/it]Loading train:  94%|█████████▍| 269/285 [05:47<00:22,  1.38s/it]Loading train:  95%|█████████▍| 270/285 [05:48<00:19,  1.29s/it]Loading train:  95%|█████████▌| 271/285 [05:49<00:17,  1.27s/it]Loading train:  95%|█████████▌| 272/285 [05:51<00:18,  1.40s/it]Loading train:  96%|█████████▌| 273/285 [05:52<00:15,  1.29s/it]Loading train:  96%|█████████▌| 274/285 [05:53<00:14,  1.29s/it]Loading train:  96%|█████████▋| 275/285 [05:55<00:14,  1.45s/it]Loading train:  97%|█████████▋| 276/285 [05:57<00:13,  1.53s/it]Loading train:  97%|█████████▋| 277/285 [05:58<00:12,  1.56s/it]Loading train:  98%|█████████▊| 278/285 [06:00<00:10,  1.52s/it]Loading train:  98%|█████████▊| 279/285 [06:01<00:09,  1.57s/it]Loading train:  98%|█████████▊| 280/285 [06:02<00:06,  1.36s/it]Loading train:  99%|█████████▊| 281/285 [06:04<00:05,  1.37s/it]Loading train:  99%|█████████▉| 282/285 [06:05<00:04,  1.45s/it]Loading train:  99%|█████████▉| 283/285 [06:06<00:02,  1.39s/it]Loading train: 100%|█████████▉| 284/285 [06:07<00:01,  1.27s/it]Loading train: 100%|██████████| 285/285 [06:09<00:00,  1.33s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|          | 2/285 [00:00<00:14, 19.37it/s]concatenating: train:   2%|▏         | 5/285 [00:00<00:13, 20.43it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:15, 18.50it/s]concatenating: train:   5%|▍         | 13/285 [00:00<00:11, 22.81it/s]concatenating: train:   6%|▋         | 18/285 [00:00<00:10, 26.39it/s]concatenating: train:   9%|▉         | 27/285 [00:00<00:07, 33.35it/s]concatenating: train:  11%|█         | 32/285 [00:00<00:07, 36.05it/s]concatenating: train:  13%|█▎        | 37/285 [00:01<00:08, 28.98it/s]concatenating: train:  14%|█▍        | 41/285 [00:01<00:14, 17.22it/s]concatenating: train:  16%|█▌        | 46/285 [00:01<00:11, 21.22it/s]concatenating: train:  26%|██▌       | 74/285 [00:01<00:07, 29.34it/s]concatenating: train:  38%|███▊      | 107/285 [00:01<00:04, 40.34it/s]concatenating: train:  49%|████▉     | 139/285 [00:01<00:02, 54.61it/s]concatenating: train:  58%|█████▊    | 165/285 [00:02<00:01, 70.60it/s]concatenating: train:  66%|██████▌   | 187/285 [00:02<00:01, 59.57it/s]concatenating: train:  72%|███████▏  | 204/285 [00:02<00:01, 54.79it/s]concatenating: train:  76%|███████▌  | 217/285 [00:03<00:01, 42.10it/s]concatenating: train:  80%|███████▉  | 227/285 [00:03<00:01, 43.05it/s]concatenating: train:  83%|████████▎ | 236/285 [00:03<00:01, 43.12it/s]concatenating: train:  86%|████████▌ | 244/285 [00:04<00:01, 38.03it/s]concatenating: train:  89%|████████▉ | 254/285 [00:04<00:00, 45.94it/s]concatenating: train:  92%|█████████▏| 263/285 [00:04<00:00, 53.50it/s]concatenating: train:  96%|█████████▋| 275/285 [00:04<00:00, 63.72it/s]concatenating: train: 100%|██████████| 285/285 [00:04<00:00, 63.29it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.83s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.77s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.68s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 32.58it/s]2019-07-10 23:38:07.135696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-10 23:38:07.135809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-10 23:38:07.135827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-10 23:38:07.135840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-10 23:38:07.136383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

Epoch 00054: val_mDice did not improve from 0.63111
Restoring model weights from the end of the best epoch
Epoch 00054: early stopping
{'val_loss': [3.407027215265029, 0.6281502150290506, 0.7263185202076449, 0.48933268259357476, 0.4782572288752934, 0.4892906786343239, 0.4727990114489081, 0.4492894560931115, 0.4543922183899906, 0.4942272538579376, 0.4421976858011171, 0.4947799830463345, 0.4577174792742596, 0.44254839353721237, 0.4702381951182914, 0.46643152516647424, 0.45795536807129505, 0.4515277906503091, 0.5628344506524795, 0.4940978182094723, 0.4601751099751648, 0.46554662961533616, 0.4623737042176657, 0.4853700419378014, 0.4966482373589244, 0.4957526106408188, 0.46936518386755577, 0.4771906447144194, 0.45727593239459247, 0.472441233070203, 0.5663150865272437, 0.4805967261671354, 0.460957067971789, 0.5115667258560991, 0.4830033016604418, 0.49095069429727906, 0.48477920640114297, 0.48342966733698073, 0.48656639373502253, 0.47061399041607394, 0.46916014622043634, 0.4935891721501697, 0.4676260205620494, 0.4732841762750508, 0.46959187931188656, 0.4705546291846803, 0.5131409671053541, 0.47816261033106117, 0.4728028794240685, 0.49020151152957087, 0.4664155934110034, 0.489115574506408, 0.5248787829329847, 0.4879770898286191], 'val_acc': [0.913920213390329, 0.9390991183632579, 0.9385144330935771, 0.950716499842745, 0.951751611752217, 0.9516131438356538, 0.9534478187561035, 0.9533879144231701, 0.9541027382765402, 0.952588331099995, 0.9508941799568731, 0.9507061735877778, 0.9528527939119819, 0.9540180630524066, 0.9503156939032358, 0.9517185258465772, 0.9508549274679002, 0.954311426458412, 0.9510553199485694, 0.9535490430933137, 0.953187492306672, 0.9540159955371026, 0.953381682574416, 0.9536234406785592, 0.9500409248154923, 0.9530283965212006, 0.9527598319772902, 0.9531296594848846, 0.9530181038979045, 0.9513115333445246, 0.950869381094778, 0.9525573456753565, 0.9530635342917628, 0.9502165161031585, 0.9526874952476118, 0.9506793052124578, 0.9531668344689481, 0.9505326288372444, 0.9526379551301455, 0.9521668743154856, 0.9538176579182375, 0.951228901993629, 0.9520015826438393, 0.9532907838261994, 0.9527556842931822, 0.9522825762546262, 0.951330143646155, 0.9528445115302528, 0.9522474304923798, 0.9531379079019557, 0.9530469915054364, 0.9516482846030976, 0.95253257545013, 0.9515925106389562], 'val_mDice': [0.14641947952728698, 0.5214926061017553, 0.49593001570781514, 0.6025572332589986, 0.6080904985939324, 0.6032548523481998, 0.6130384719571588, 0.627378776752749, 0.6251532312212044, 0.6033669949909828, 0.629861842320618, 0.602619251725394, 0.6225296225627708, 0.6311148205282968, 0.6137328674007394, 0.6219398685673762, 0.6222139876648034, 0.6259789346982647, 0.5745935426744003, 0.6023283021410084, 0.6219782389742036, 0.6201085494883234, 0.6193521285856236, 0.6115386449424914, 0.6003785106722869, 0.6054764426620313, 0.6170248016298816, 0.6148520481653054, 0.6236577746588424, 0.6143366284876562, 0.568387284625176, 0.6101175506687697, 0.6203672256549644, 0.5948269946615123, 0.6114781685381628, 0.6039689093328721, 0.6134682001348314, 0.608616148959325, 0.6072678213012951, 0.6148899154290141, 0.6172675100784728, 0.6054604186692052, 0.6169958167901918, 0.6124674488046316, 0.6188031288498607, 0.6160137416930173, 0.5927083732029579, 0.6104235509254413, 0.6183925157818715, 0.605614516988147, 0.618112420569585, 0.6102007114687445, 0.594294638940076, 0.6046095873390496], 'loss': [2.0386893603057814, 0.6053785413128704, 0.4917286523049657, 0.44032727456464205, 0.4132412345095415, 0.3935397331682557, 0.37829801442511335, 0.3630985921390513, 0.3570048820153735, 0.3467447405274115, 0.337040423166907, 0.32982266171780633, 0.3236164378692016, 0.31830499996404543, 0.3137185206847489, 0.3107056765279494, 0.3055082224798413, 0.30183112366800313, 0.2984113831154811, 0.29512385584048395, 0.29314824292118413, 0.2908414423702706, 0.2886513001674284, 0.2854643003313794, 0.2823696618674595, 0.28070918195946637, 0.27913129380647733, 0.27601913448239934, 0.27521351957417256, 0.272693250272913, 0.2713274013700065, 0.2702050957812326, 0.2686582332449888, 0.2671141079662737, 0.2659690731358381, 0.2635496313970831, 0.26375860073689666, 0.2613728218063421, 0.2603851961830487, 0.25969664590089037, 0.25782141182607154, 0.2584120695721213, 0.2561287926576423, 0.25434137011533936, 0.253641521548934, 0.25437452010317346, 0.25154331911785993, 0.2502639725602249, 0.2504986466279016, 0.2503062053970324, 0.24894378495663705, 0.24881269564510958, 0.24854797120642527, 0.24628874268282355], 'acc': [0.4035245093702296, 0.916912846166995, 0.928339860027155, 0.9368068825172109, 0.9415459303929651, 0.9439286391632885, 0.9453462140050227, 0.9466410861621203, 0.9474418830861194, 0.9482801599275584, 0.948915471617585, 0.9494683610465193, 0.949976076588808, 0.9505283011407688, 0.9507815640714523, 0.951065683331107, 0.951511681579789, 0.9517917938108025, 0.9519362681981077, 0.9522068549862005, 0.9524452520166047, 0.9526720663430053, 0.9527586161827354, 0.9529665014945203, 0.9532045738953248, 0.9533198453730652, 0.9534167488554544, 0.9535708114521857, 0.9536807263094215, 0.9538316075484105, 0.9538900393636182, 0.9539995303627167, 0.9541619737276448, 0.9541800777141217, 0.9543666103314576, 0.954445849033841, 0.9544783194797062, 0.9546583457571197, 0.95468279800347, 0.9547292056066019, 0.9548678409364396, 0.9548456831588951, 0.955094414292698, 0.9550940289969252, 0.9552044686321391, 0.9552377628206227, 0.9553457432261714, 0.9554190784717111, 0.9554671569851175, 0.9554738635091271, 0.9555276427112642, 0.9555667986128885, 0.9555898195069819, 0.9558160534923577], 'mDice': [0.23917739000338809, 0.5331206340317398, 0.5980495601806445, 0.6298367570645214, 0.6476308222099052, 0.6605764559187743, 0.6710736616771534, 0.6814422264811222, 0.6860521320722492, 0.6931702151945698, 0.6999727107556477, 0.7052136822357383, 0.7097296351558288, 0.713651517524899, 0.7169157053564545, 0.7193565502658102, 0.7230607467690789, 0.7259414920775201, 0.7285011308845446, 0.7309089527690562, 0.7325135639346079, 0.7346450392570535, 0.7359810497147748, 0.738406374481637, 0.7407681032383041, 0.7419611648642986, 0.7433549432990585, 0.7455835563218072, 0.7462979980130827, 0.7482502260639753, 0.7493360811417077, 0.7501671224447852, 0.7514127174186509, 0.7525182938038163, 0.753593845228102, 0.7553676335122498, 0.7552835379256628, 0.7571411636340437, 0.7579063055179106, 0.7584172789193883, 0.759894077038104, 0.7595019882348983, 0.7613253573934781, 0.7626422235833411, 0.7632449045919345, 0.7627272200048129, 0.7649384685983508, 0.765909496283948, 0.7657716884786258, 0.7659286144972951, 0.7670682436967622, 0.7671935851976092, 0.7673513429219814, 0.7691773789412419]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:18,  2.29it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:13,  3.01it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:11,  3.48it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:07,  4.65it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:09,  3.76it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:07,  4.52it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:06,  4.61it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:04,  6.15it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:04,  5.22it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:04,  5.24it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:03<00:02,  6.67it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  5.96it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:03<00:02,  5.75it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:03<00:02,  6.63it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:04<00:02,  5.55it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:04<00:01,  6.72it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:00,  7.70it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:04<00:00,  6.11it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:05<00:00,  6.94it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:05<00:00,  5.69it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:05<00:00,  8.28it/s]
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 26, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 26, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 26, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 26, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 13, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 13, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 13, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 20, 13, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 40, 26, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 40, 26, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 40, 26, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 80, 52, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 80, 52, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 52, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 80, 52, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 20)   10820       dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 80, 52, 20)   0           activation_11[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 80)   0           dropout_5[0][0]                  
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 13)   1053        concatenate_7[0][0]              
==================================================================================================
Total params: 234,993
Trainable params: 60,273
Non-trainable params: 174,720
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 19s - loss: 2.5308 - acc: 0.5637 - mDice: 0.1376 - val_loss: 1.5882 - val_acc: 0.8906 - val_mDice: 0.2694

Epoch 00001: val_mDice improved from -inf to 0.26938, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 11s - loss: 0.8844 - acc: 0.8893 - mDice: 0.4036 - val_loss: 1.1500 - val_acc: 0.9108 - val_mDice: 0.4074

Epoch 00002: val_mDice improved from 0.26938 to 0.40737, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 12s - loss: 0.6856 - acc: 0.9005 - mDice: 0.4901 - val_loss: 0.9949 - val_acc: 0.9234 - val_mDice: 0.4673

Epoch 00003: val_mDice improved from 0.40737 to 0.46731, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 10s - loss: 0.6005 - acc: 0.9063 - mDice: 0.5340 - val_loss: 0.9918 - val_acc: 0.9243 - val_mDice: 0.4961

Epoch 00004: val_mDice improved from 0.46731 to 0.49606, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 12s - loss: 0.5519 - acc: 0.9114 - mDice: 0.5612 - val_loss: 0.9649 - val_acc: 0.9295 - val_mDice: 0.5062

Epoch 00005: val_mDice improved from 0.49606 to 0.50624, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 10s - loss: 0.5106 - acc: 0.9175 - mDice: 0.5853 - val_loss: 0.9660 - val_acc: 0.9309 - val_mDice: 0.5095

Epoch 00006: val_mDice improved from 0.50624 to 0.50949, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 12s - loss: 0.4837 - acc: 0.9242 - mDice: 0.6018 - val_loss: 0.8960 - val_acc: 0.9382 - val_mDice: 0.5390

Epoch 00007: val_mDice improved from 0.50949 to 0.53899, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 11s - loss: 0.4660 - acc: 0.9292 - mDice: 0.6129 - val_loss: 0.8767 - val_acc: 0.9421 - val_mDice: 0.5520

Epoch 00008: val_mDice improved from 0.53899 to 0.55200, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 12s - loss: 0.4496 - acc: 0.9324 - mDice: 0.6232 - val_loss: 0.8996 - val_acc: 0.9418 - val_mDice: 0.5402

Epoch 00009: val_mDice did not improve from 0.55200
Epoch 10/300
 - 11s - loss: 0.4344 - acc: 0.9346 - mDice: 0.6327 - val_loss: 0.9200 - val_acc: 0.9388 - val_mDice: 0.5268

Epoch 00010: val_mDice did not improve from 0.55200
Epoch 11/300
 - 12s - loss: 0.4197 - acc: 0.9360 - mDice: 0.6424 - val_loss: 0.8349 - val_acc: 0.9377 - val_mDice: 0.5603

Epoch 00011: val_mDice improved from 0.55200 to 0.56030, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 11s - loss: 0.4102 - acc: 0.9369 - mDice: 0.6485 - val_loss: 0.8567 - val_acc: 0.9362 - val_mDice: 0.5479

Epoch 00012: val_mDice did not improve from 0.56030
Epoch 13/300
 - 10s - loss: 0.4025 - acc: 0.9378 - mDice: 0.6538 - val_loss: 0.8727 - val_acc: 0.9442 - val_mDice: 0.5499

Epoch 00013: val_mDice did not improve from 0.56030
Epoch 14/300
 - 10s - loss: 0.3958 - acc: 0.9383 - mDice: 0.6582 - val_loss: 0.8033 - val_acc: 0.9416 - val_mDice: 0.5749

Epoch 00014: val_mDice improved from 0.56030 to 0.57491, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 10s - loss: 0.3887 - acc: 0.9390 - mDice: 0.6631 - val_loss: 0.8154 - val_acc: 0.9417 - val_mDice: 0.5705

Epoch 00015: val_mDice did not improve from 0.57491
Epoch 16/300
 - 10s - loss: 0.3822 - acc: 0.9396 - mDice: 0.6675 - val_loss: 0.7816 - val_acc: 0.9398 - val_mDice: 0.5803

Epoch 00016: val_mDice improved from 0.57491 to 0.58026, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 10s - loss: 0.3773 - acc: 0.9399 - mDice: 0.6709 - val_loss: 0.8007 - val_acc: 0.9437 - val_mDice: 0.5703

Epoch 00017: val_mDice did not improve from 0.58026
Epoch 18/300
 - 10s - loss: 0.3722 - acc: 0.9404 - mDice: 0.6744 - val_loss: 0.8024 - val_acc: 0.9442 - val_mDice: 0.5689

Epoch 00018: val_mDice did not improve from 0.58026
Epoch 19/300
 - 10s - loss: 0.3678 - acc: 0.9408 - mDice: 0.6774 - val_loss: 0.8298 - val_acc: 0.9382 - val_mDice: 0.5518

Epoch 00019: val_mDice did not improve from 0.58026
Epoch 20/300
 - 10s - loss: 0.3634 - acc: 0.9412 - mDice: 0.6806 - val_loss: 0.8174 - val_acc: 0.9416 - val_mDice: 0.5624

Epoch 00020: val_mDice did not improve from 0.58026
Epoch 21/300
 - 10s - loss: 0.3600 - acc: 0.9415 - mDice: 0.6830 - val_loss: 0.8156 - val_acc: 0.9397 - val_mDice: 0.5610

Epoch 00021: val_mDice did not improve from 0.58026
Epoch 22/300
 - 10s - loss: 0.3539 - acc: 0.9421 - mDice: 0.6873 - val_loss: 0.8215 - val_acc: 0.9429 - val_mDice: 0.5610

Epoch 00022: val_mDice did not improve from 0.58026
Epoch 23/300
 - 10s - loss: 0.3518 - acc: 0.9421 - mDice: 0.6886 - val_loss: 0.8581 - val_acc: 0.9387 - val_mDice: 0.5376

Epoch 00023: val_mDice did not improve from 0.58026
Epoch 24/300
 - 10s - loss: 0.3486 - acc: 0.9424 - mDice: 0.6910 - val_loss: 0.8373 - val_acc: 0.9382 - val_mDice: 0.5491

Epoch 00024: val_mDice did not improve from 0.58026
Epoch 25/300
 - 10s - loss: 0.3434 - acc: 0.9427 - mDice: 0.6948 - val_loss: 0.7930 - val_acc: 0.9384 - val_mDice: 0.5650

Epoch 00025: val_mDice did not improve from 0.58026
Epoch 26/300
 - 10s - loss: 0.3412 - acc: 0.9430 - mDice: 0.6962 - val_loss: 0.7699 - val_acc: 0.9405 - val_mDice: 0.5799

Epoch 00026: val_mDice did not improve from 0.58026
Epoch 27/300
 - 10s - loss: 0.3379 - acc: 0.9432 - mDice: 0.6987 - val_loss: 0.7641 - val_acc: 0.9419 - val_mDice: 0.5829

Epoch 00027: val_mDice improved from 0.58026 to 0.58290, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 28/300
 - 10s - loss: 0.3364 - acc: 0.9432 - mDice: 0.6997 - val_loss: 0.7970 - val_acc: 0.9441 - val_mDice: 0.5757

Epoch 00028: val_mDice did not improve from 0.58290
Epoch 29/300
 - 10s - loss: 0.3328 - acc: 0.9436 - mDice: 0.7023 - val_loss: 0.7513 - val_acc: 0.9395 - val_mDice: 0.5794

Epoch 00029: val_mDice did not improve from 0.58290
Epoch 30/300
 - 10s - loss: 0.3305 - acc: 0.9438 - mDice: 0.7040 - val_loss: 0.7494 - val_acc: 0.9399 - val_mDice: 0.5779

Epoch 00030: val_mDice did not improve from 0.58290
Epoch 31/300
 - 10s - loss: 0.3288 - acc: 0.9440 - mDice: 0.7053 - val_loss: 0.7822 - val_acc: 0.9429 - val_mDice: 0.5759

Epoch 00031: val_mDice did not improve from 0.58290
Epoch 32/300
 - 10s - loss: 0.3256 - acc: 0.9442 - mDice: 0.7075 - val_loss: 0.7953 - val_acc: 0.9397 - val_mDice: 0.5659

Epoch 00032: val_mDice did not improve from 0.58290
Epoch 33/300
 - 10s - loss: 0.3239 - acc: 0.9445 - mDice: 0.7090 - val_loss: 0.7850 - val_acc: 0.9408 - val_mDice: 0.5688

Epoch 00033: val_mDice did not improve from 0.58290
Epoch 34/300
 - 10s - loss: 0.3215 - acc: 0.9444 - mDice: 0.7106 - val_loss: 0.8253 - val_acc: 0.9429 - val_mDice: 0.5480

Epoch 00034: val_mDice did not improve from 0.58290
Epoch 35/300
 - 10s - loss: 0.3195 - acc: 0.9446 - mDice: 0.7121 - val_loss: 0.7805 - val_acc: 0.9418 - val_mDice: 0.5728

Epoch 00035: val_mDice did not improve from 0.58290
Epoch 36/300
 - 10s - loss: 0.3173 - acc: 0.9449 - mDice: 0.7137 - val_loss: 0.7796 - val_acc: 0.9381 - val_mDice: 0.5640

Epoch 00036: val_mDice did not improve from 0.58290
Epoch 37/300
 - 10s - loss: 0.3143 - acc: 0.9451 - mDice: 0.7160 - val_loss: 0.7658 - val_acc: 0.9403 - val_mDice: 0.5773

Epoch 00037: val_mDice did not improve from 0.58290
Epoch 38/300
 - 10s - loss: 0.3160 - acc: 0.9450 - mDice: 0.7149 - val_loss: 0.7649 - val_acc: 0.9408 - val_mDice: 0.5597

Epoch 00038: val_mDice did not improve from 0.58290
Epoch 39/300
 - 10s - loss: 0.3116 - acc: 0.9453 - mDice: 0.7180 - val_loss: 0.7420 - val_acc: 0.9402 - val_mDice: 0.5742

Epoch 00039: val_mDice did not improve from 0.58290
Epoch 40/300
 - 10s - loss: 0.3089 - acc: 0.9457 - mDice: 0.7201 - val_loss: 0.7856 - val_acc: 0.9403 - val_mDice: 0.5575

Epoch 00040: val_mDice did not improve from 0.58290
Epoch 41/300
 - 10s - loss: 0.3097 - acc: 0.9456 - mDice: 0.7194 - val_loss: 0.8794 - val_acc: 0.9447 - val_mDice: 0.5264

Epoch 00041: val_mDice did not improve from 0.58290
Epoch 42/300
 - 10s - loss: 0.3058 - acc: 0.9459 - mDice: 0.7225 - val_loss: 0.7823 - val_acc: 0.9407 - val_mDice: 0.5684

Epoch 00042: val_mDice did not improve from 0.58290
Epoch 43/300
 - 10s - loss: 0.3046 - acc: 0.9460 - mDice: 0.7232 - val_loss: 0.7570 - val_acc: 0.9386 - val_mDice: 0.5695

Epoch 00043: val_mDice did not improve from 0.58290
Epoch 44/300
 - 10s - loss: 0.3063 - acc: 0.9458 - mDice: 0.7220 - val_loss: 0.7556 - val_acc: 0.9406 - val_mDice: 0.5774

Epoch 00044: val_mDice did not improve from 0.58290
Epoch 45/300
 - 10s - loss: 0.3025 - acc: 0.9462 - mDice: 0.7249 - val_loss: 0.7392 - val_acc: 0.9398 - val_mDice: 0.5707

Epoch 00045: val_mDice did not improve from 0.58290
Epoch 46/300
 - 10s - loss: 0.3021 - acc: 0.9462 - mDice: 0.7251 - val_loss: 0.7705 - val_acc: 0.9448 - val_mDice: 0.5604

Epoch 00046: val_mDice did not improve from 0.58290
Epoch 47/300
 - 10s - loss: 0.2982 - acc: 0.9465 - mDice: 0.7281 - val_loss: 0.7277 - val_acc: 0.9413 - val_mDice: 0.5761

Epoch 00047: val_mDice did not improve from 0.58290
Epoch 48/300
 - 10s - loss: 0.2991 - acc: 0.9464 - mDice: 0.7273 - val_loss: 0.7370 - val_acc: 0.9427 - val_mDice: 0.5801

Epoch 00048: val_mDice did not improve from 0.58290
Epoch 49/300
 - 10s - loss: 0.2987 - acc: 0.9464 - mDice: 0.7278 - val_loss: 0.7763 - val_acc: 0.9427 - val_mDice: 0.5583

Epoch 00049: val_mDice did not improve from 0.58290
Epoch 50/300
 - 10s - loss: 0.2962 - acc: 0.9467 - mDice: 0.7296 - val_loss: 0.7477 - val_acc: 0.9417 - val_mDice: 0.5751

Epoch 00050: val_mDice did not improve from 0.58290
Epoch 51/300
 - 10s - loss: 0.2949 - acc: 0.9468 - mDice: 0.7306 - val_loss: 0.7540 - val_acc: 0.9416 - val_mDice: 0.5753

Epoch 00051: val_mDice did not improve from 0.58290
Epoch 52/300
 - 10s - loss: 0.2931 - acc: 0.9469 - mDice: 0.7320 - val_loss: 0.7660 - val_acc: 0.9407 - val_mDice: 0.5609

Epoch 00052: val_mDice did not improve from 0.58290
Epoch 53/300
 - 10s - loss: 0.2923 - acc: 0.9469 - mDice: 0.7325 - val_loss: 0.7193 - val_acc: 0.9403 - val_mDice: 0.5761

Epoch 00053: val_mDice did not improve from 0.58290
Epoch 54/300
 - 10s - loss: 0.2923 - acc: 0.9471 - mDice: 0.7326 - val_loss: 0.7337 - val_acc: 0.9421 - val_mDice: 0.5779

Epoch 00054: val_mDice did not improve from 0.58290
Epoch 55/300
 - 10s - loss: 0.2888 - acc: 0.9473 - mDice: 0.7352 - val_loss: 0.7128 - val_acc: 0.9410 - val_mDice: 0.5785

Epoch 00055: val_mDice did not improve from 0.58290
Epoch 56/300
 - 10s - loss: 0.2890 - acc: 0.9473 - mDice: 0.7351 - val_loss: 0.7504 - val_acc: 0.9364 - val_mDice: 0.5564

Epoch 00056: val_mDice did not improve from 0.58290
Epoch 57/300
 - 10s - loss: 0.2895 - acc: 0.9472 - mDice: 0.7349 - val_loss: 0.7240 - val_acc: 0.9385 - val_mDice: 0.5687

Epoch 00057: val_mDice did not improve from 0.58290
Epoch 58/300
 - 10s - loss: 0.2874 - acc: 0.9474 - mDice: 0.7363 - val_loss: 0.7564 - val_acc: 0.9358 - val_mDice: 0.5556

Epoch 00058: val_mDice did not improve from 0.58290
Epoch 59/300
 - 10s - loss: 0.2862 - acc: 0.9474 - mDice: 0.7373 - val_loss: 0.7298 - val_acc: 0.9384 - val_mDice: 0.5730

Epoch 00059: val_mDice did not improve from 0.58290
Epoch 60/300
 - 10s - loss: 0.2855 - acc: 0.9475 - mDice: 0.7378 - val_loss: 0.7163 - val_acc: 0.9412 - val_mDice: 0.5677

Epoch 00060: val_mDice did not improve from 0.58290
Epoch 61/300
 - 10s - loss: 0.2832 - acc: 0.9477 - mDice: 0.7396 - val_loss: 0.7639 - val_acc: 0.9389 - val_mDice: 0.5570

Epoch 00061: val_mDice did not improve from 0.58290
Epoch 62/300
 - 10s - loss: 0.2839 - acc: 0.9477 - mDice: 0.7391 - val_loss: 0.7006 - val_acc: 0.9410 - val_mDice: 0.5794

Epoch 00062: val_mDice did not improve from 0.58290
Epoch 63/300
 - 10s - loss: 0.2842 - acc: 0.9478 - mDice: 0.7388 - val_loss: 0.7522 - val_acc: 0.9428 - val_mDice: 0.5561

Epoch 00063: val_mDice did not improve from 0.58290
Epoch 64/300
 - 10s - loss: 0.2831 - acc: 0.9478 - mDice: 0.7396 - val_loss: 0.7093 - val_acc: 0.9391 - val_mDice: 0.5782

Epoch 00064: val_mDice did not improve from 0.58290
Epoch 65/300
 - 10s - loss: 0.2817 - acc: 0.9479 - mDice: 0.7407 - val_loss: 0.7230 - val_acc: 0.9422 - val_mDice: 0.5732

Epoch 00065: val_mDice did not improve from 0.58290
Epoch 66/300
 - 10s - loss: 0.2822 - acc: 0.9479 - mDice: 0.7404 - val_loss: 0.7435 - val_acc: 0.9402 - val_mDice: 0.5574

Epoch 00066: val_mDice did not improve from 0.58290
Epoch 67/300
 - 10s - loss: 0.2801 - acc: 0.9480 - mDice: 0.7420 - val_loss: 0.7266 - val_acc: 0.9429 - val_mDice: 0.5714

Epoch 00067: val_mDice did not improve from 0.58290
Restoring model weights from the end of the best epoch
Epoch 00067: early stopping
{'val_loss': [1.5881979373785167, 1.1500461537104387, 0.9949301297848041, 0.9917821219334235, 0.9649144548636216, 0.966010529261369, 0.8959545355576736, 0.8766631438181951, 0.8995576959389907, 0.9200282142712519, 0.8349157801041236, 0.8567286431789398, 0.8727264656470373, 0.8032970061668983, 0.8154066205024719, 0.7815884901927068, 0.8006746035355788, 0.8023876479038825, 0.829759996670943, 0.8173664945822495, 0.8156461578149062, 0.8215130223677709, 0.8581450948348412, 0.8372504023405222, 0.793044049006242, 0.7699196315728701, 0.7641289291473535, 0.7970338899355668, 0.7513107943993348, 0.7493952868076471, 0.7822472418730075, 0.7953006487626296, 0.7849519367401416, 0.8253048910544469, 0.780500930089217, 0.7796480976618253, 0.765772833273961, 0.7648858244602497, 0.7419775013740246, 0.7856149627612188, 0.8793619343867669, 0.782258180471567, 0.7570123672485352, 0.7555675231493436, 0.7392270496258369, 0.7704770702582139, 0.7277177984897907, 0.7369905194410911, 0.7763265806895036, 0.7476527186540457, 0.7539500387815329, 0.7659734808481656, 0.7193320256013137, 0.7336837580570807, 0.7128184139728546, 0.7503670729123629, 0.7239641363804157, 0.756367183648623, 0.729824824975087, 0.7162541105197027, 0.7638665827421042, 0.7006384008205854, 0.7522155482035416, 0.7093458955104535, 0.7229958635110122, 0.7435259406383221, 0.726627895465264], 'val_acc': [0.8906296078975384, 0.9107942008055173, 0.9234120983343858, 0.9243389505606431, 0.9295303179667547, 0.9308616862847254, 0.9381934243899125, 0.9420950412750244, 0.9418431153664222, 0.9387643589423253, 0.9376895060906043, 0.9362472226986518, 0.944175293812385, 0.9416466286549201, 0.9417460262775421, 0.9398229374335363, 0.9437361565920023, 0.9441568094950455, 0.938223490348229, 0.9415518412223229, 0.9397166279646066, 0.9429410375081576, 0.938683454806988, 0.938244294661742, 0.9383806242392614, 0.9405463956869565, 0.9418847308709071, 0.9441082592193897, 0.9394531433398907, 0.939926979633478, 0.942890139726492, 0.9397166187946613, 0.9407590604745425, 0.9428901374340057, 0.9418037923482748, 0.9381264035518353, 0.9403222157404973, 0.9408075992877667, 0.9402297666439643, 0.9402713592235858, 0.9447161555290222, 0.9407197924760672, 0.9386094418855814, 0.9406088269673861, 0.9398159889074472, 0.9447693480895116, 0.9412606220978957, 0.9426798247374021, 0.9426890497024243, 0.9417367783876566, 0.9416004098378695, 0.9406827986240387, 0.9402875556395605, 0.9420835054837741, 0.9410433860925528, 0.9364090103369492, 0.9385447547985957, 0.9357549066726978, 0.9383505743283492, 0.9412444600692162, 0.9389145443072686, 0.9410179463716654, 0.9427699653001932, 0.9391226057822888, 0.9422383698133322, 0.9401534635287064, 0.9429201942223769], 'val_mDice': [0.26938297427617586, 0.4073726615080467, 0.467314330717692, 0.49605767600811446, 0.506241265970927, 0.5094856533866662, 0.5389905336957711, 0.5519991860939906, 0.540172834522449, 0.526759606714432, 0.5603035344527318, 0.5479443308252555, 0.549885101043261, 0.5749069864933307, 0.5704669046860474, 0.5802596119733957, 0.5703000219968649, 0.568932620378641, 0.5518439836226977, 0.5623886694128697, 0.5610099813112845, 0.5610050911513659, 0.5375884619469826, 0.5490662329472028, 0.5650067742054279, 0.5799114864606124, 0.5829008748898139, 0.5756939712625283, 0.5794176791722958, 0.577917951803941, 0.5759495642895882, 0.5658893671173316, 0.5688204223719927, 0.5479671427836785, 0.5727875977754593, 0.5640155925200536, 0.5772892116354063, 0.5596875926622977, 0.5741838021920278, 0.5574785768985748, 0.5263581293133589, 0.5683516384317324, 0.5695099274699504, 0.5773920605962093, 0.5706982073875574, 0.5604461898597387, 0.5761006451570071, 0.5801004692912102, 0.5583425387740135, 0.575138790676227, 0.5752871294434254, 0.5608594045042992, 0.5761122823907778, 0.5779152718874124, 0.5785113429793944, 0.5564103120794663, 0.5687114298343658, 0.5556082221177908, 0.5729749214190704, 0.5677435375176944, 0.5570263478618401, 0.5794209345028951, 0.5561277980987842, 0.5781895357828873, 0.5731953468460304, 0.5573780548114043, 0.5713727892591403], 'loss': [2.5307545011953643, 0.8843877235374075, 0.6856287592980933, 0.6004529995066449, 0.551854360689594, 0.51056182245965, 0.4837379967617744, 0.46597717511778136, 0.44959501542970726, 0.43443070733711026, 0.419716872825269, 0.41024261640466736, 0.40247511088897586, 0.39583430541272996, 0.38870646162995287, 0.3821991415664981, 0.37728276604998323, 0.37216407657604117, 0.3677809279469407, 0.36335813182587445, 0.3600349333204269, 0.35392634381362237, 0.35183951997739366, 0.34863010114556164, 0.343419450139973, 0.34118163102745935, 0.33793682037800055, 0.33640420644373226, 0.3328168515453015, 0.3305421882940924, 0.32879048020793733, 0.32561572379955095, 0.32389115297485405, 0.32147131427225123, 0.3194752596603882, 0.3173035745370941, 0.31426005991558675, 0.3159684794784461, 0.3116445835392204, 0.3088624309698594, 0.3097143897785534, 0.3057619647176945, 0.30459033999013846, 0.3063129697472234, 0.30251535027051096, 0.3020847050546445, 0.29819850856545643, 0.29911350198780645, 0.2987161726652779, 0.2962240248129705, 0.29485590124189615, 0.2931434609463852, 0.29232284376116174, 0.29232503177604474, 0.28877555423311496, 0.2890155027270658, 0.28947812730256983, 0.28740869360657006, 0.28620466034449543, 0.28547943859019864, 0.28321388458662516, 0.2838938289722987, 0.28417793101548905, 0.2831413273407636, 0.28173195358177155, 0.2822195831440608, 0.28012338726764385], 'acc': [0.563747967518732, 0.8892839210428986, 0.9004527670226941, 0.9062721916948265, 0.9114347523531658, 0.9175181490660571, 0.9241562715472083, 0.9291920605141618, 0.9323685650597702, 0.9346310609844595, 0.9360305567206816, 0.9369368261542474, 0.937803745770008, 0.9383377877205684, 0.9390496094486518, 0.9395825647124832, 0.9399277445608802, 0.9403863460399958, 0.9408229089559449, 0.9412469659345919, 0.9414726301916387, 0.9420540046122399, 0.9421476055354767, 0.9424259427243973, 0.9427298228041245, 0.9429955665809933, 0.9432368877958044, 0.943162309610018, 0.9436418550827841, 0.9437938520062468, 0.9439779476882852, 0.9441618894800691, 0.9445286833480265, 0.944371657272354, 0.9446092032917881, 0.9449268706245285, 0.9451390988083769, 0.9450407548770027, 0.9453480739078102, 0.9456966428544308, 0.9455808288637897, 0.9458565976273845, 0.9459973957544542, 0.9458042751002398, 0.9461743295945816, 0.9462143226126337, 0.9465331454168416, 0.946376094912225, 0.9464298125552613, 0.9466582249091097, 0.9467576550654596, 0.9469429522898434, 0.9468796772676717, 0.9471286183451084, 0.9472582679684065, 0.9473205431794193, 0.947158569808289, 0.9473949208763554, 0.947410747352522, 0.9475386007063219, 0.947733781741882, 0.947746466108324, 0.9477644213437925, 0.9478208411062027, 0.9478575113700741, 0.9478973470072372, 0.9479860276860592], 'mDice': [0.13756585959181908, 0.40362333012366003, 0.4900567002988198, 0.5339663931444586, 0.5612326774343863, 0.5853303553685814, 0.6018095921076038, 0.6128585661325048, 0.623168464242604, 0.6327378919156926, 0.6423666942694591, 0.6484839354979204, 0.6537633803094609, 0.6582225461919996, 0.6631436312230522, 0.6675439194857629, 0.6708698647824598, 0.6744453578178682, 0.6774368956224688, 0.6806185218028605, 0.6829668526542613, 0.687277988920042, 0.6886497715473131, 0.6909803917605224, 0.6948056402631234, 0.6961681974843388, 0.6986629178600317, 0.6996650218985612, 0.7023412607741468, 0.7040260279078573, 0.7052731378859264, 0.707526977416456, 0.7089905066869691, 0.7105996210636891, 0.7121031864272331, 0.7137236653862432, 0.7159565608461635, 0.7149013290213536, 0.7180147292835405, 0.7201407557647298, 0.719383411925074, 0.7224948734723916, 0.723212191009284, 0.7219825278104237, 0.7249008142056527, 0.7251066605037487, 0.7280906852316529, 0.7273474126507257, 0.7277784721664229, 0.7295711066003194, 0.7306489561752542, 0.7320092525262735, 0.7325290472956257, 0.73261694288953, 0.7352246694609675, 0.7350808928552219, 0.7348691198775923, 0.7363209957501704, 0.7372821137373665, 0.7378227707315699, 0.739589271719777, 0.7390824970169546, 0.7388314022895189, 0.7396272431547479, 0.7406990267600915, 0.740358407879122, 0.74197242535492]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.11s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.96s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.80s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:29,  1.79s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:59,  1.69s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:10,  1.74s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:45,  1.66s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:58,  1.71s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:30,  1.62s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:39,  1.65s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:36,  1.65s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<07:58,  1.73s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:23,  1.83s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<07:55,  1.73s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:13,  1.81s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<08:03,  1.78s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<07:58,  1.77s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<08:04,  1.80s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<08:05,  1.81s/it]predicting train subjects:   6%|▌         | 17/285 [00:29<07:43,  1.73s/it]predicting train subjects:   6%|▋         | 18/285 [00:31<07:47,  1.75s/it]predicting train subjects:   7%|▋         | 19/285 [00:32<07:28,  1.69s/it]predicting train subjects:   7%|▋         | 20/285 [00:34<07:30,  1.70s/it]predicting train subjects:   7%|▋         | 21/285 [00:36<07:41,  1.75s/it]predicting train subjects:   8%|▊         | 22/285 [00:37<07:22,  1.68s/it]predicting train subjects:   8%|▊         | 23/285 [00:39<07:23,  1.69s/it]predicting train subjects:   8%|▊         | 24/285 [00:41<07:09,  1.65s/it]predicting train subjects:   9%|▉         | 25/285 [00:42<07:28,  1.73s/it]predicting train subjects:   9%|▉         | 26/285 [00:44<07:41,  1.78s/it]predicting train subjects:   9%|▉         | 27/285 [00:46<07:25,  1.73s/it]predicting train subjects:  10%|▉         | 28/285 [00:48<07:26,  1.74s/it]predicting train subjects:  10%|█         | 29/285 [00:49<07:23,  1.73s/it]predicting train subjects:  11%|█         | 30/285 [00:51<07:33,  1.78s/it]predicting train subjects:  11%|█         | 31/285 [00:53<07:46,  1.84s/it]predicting train subjects:  11%|█         | 32/285 [00:55<07:32,  1.79s/it]predicting train subjects:  12%|█▏        | 33/285 [00:57<07:34,  1.80s/it]predicting train subjects:  12%|█▏        | 34/285 [00:59<07:33,  1.81s/it]predicting train subjects:  12%|█▏        | 35/285 [01:01<07:37,  1.83s/it]predicting train subjects:  13%|█▎        | 36/285 [01:02<07:19,  1.77s/it]predicting train subjects:  13%|█▎        | 37/285 [01:04<07:18,  1.77s/it]predicting train subjects:  13%|█▎        | 38/285 [01:06<07:34,  1.84s/it]predicting train subjects:  14%|█▎        | 39/285 [01:07<07:11,  1.75s/it]predicting train subjects:  14%|█▍        | 40/285 [01:09<07:17,  1.78s/it]predicting train subjects:  14%|█▍        | 41/285 [01:11<07:03,  1.74s/it]predicting train subjects:  15%|█▍        | 42/285 [01:13<06:57,  1.72s/it]predicting train subjects:  15%|█▌        | 43/285 [01:14<07:00,  1.74s/it]predicting train subjects:  15%|█▌        | 44/285 [01:16<07:12,  1.80s/it]predicting train subjects:  16%|█▌        | 45/285 [01:18<06:58,  1.74s/it]predicting train subjects:  16%|█▌        | 46/285 [01:20<07:10,  1.80s/it]predicting train subjects:  16%|█▋        | 47/285 [01:22<06:54,  1.74s/it]predicting train subjects:  17%|█▋        | 48/285 [01:23<07:00,  1.77s/it]predicting train subjects:  17%|█▋        | 49/285 [01:25<07:23,  1.88s/it]predicting train subjects:  18%|█▊        | 50/285 [01:27<07:18,  1.86s/it]predicting train subjects:  18%|█▊        | 51/285 [01:29<07:15,  1.86s/it]predicting train subjects:  18%|█▊        | 52/285 [01:31<07:00,  1.80s/it]predicting train subjects:  19%|█▊        | 53/285 [01:33<06:59,  1.81s/it]predicting train subjects:  19%|█▉        | 54/285 [01:35<07:03,  1.83s/it]predicting train subjects:  19%|█▉        | 55/285 [01:36<06:56,  1.81s/it]predicting train subjects:  20%|█▉        | 56/285 [01:38<07:19,  1.92s/it]predicting train subjects:  20%|██        | 57/285 [01:40<07:05,  1.87s/it]predicting train subjects:  20%|██        | 58/285 [01:42<07:05,  1.88s/it]predicting train subjects:  21%|██        | 59/285 [01:44<07:07,  1.89s/it]predicting train subjects:  21%|██        | 60/285 [01:46<07:19,  1.95s/it]predicting train subjects:  21%|██▏       | 61/285 [01:48<07:00,  1.88s/it]predicting train subjects:  22%|██▏       | 62/285 [01:50<06:58,  1.88s/it]predicting train subjects:  22%|██▏       | 63/285 [01:52<06:57,  1.88s/it]predicting train subjects:  22%|██▏       | 64/285 [01:53<06:37,  1.80s/it]predicting train subjects:  23%|██▎       | 65/285 [01:55<06:43,  1.83s/it]predicting train subjects:  23%|██▎       | 66/285 [01:57<06:40,  1.83s/it]predicting train subjects:  24%|██▎       | 67/285 [01:59<06:32,  1.80s/it]predicting train subjects:  24%|██▍       | 68/285 [02:00<06:14,  1.73s/it]predicting train subjects:  24%|██▍       | 69/285 [02:02<06:15,  1.74s/it]predicting train subjects:  25%|██▍       | 70/285 [02:04<06:20,  1.77s/it]predicting train subjects:  25%|██▍       | 71/285 [02:06<06:17,  1.76s/it]predicting train subjects:  25%|██▌       | 72/285 [02:07<06:17,  1.77s/it]predicting train subjects:  26%|██▌       | 73/285 [02:09<06:34,  1.86s/it]predicting train subjects:  26%|██▌       | 74/285 [02:11<06:31,  1.85s/it]predicting train subjects:  26%|██▋       | 75/285 [02:13<06:18,  1.80s/it]predicting train subjects:  27%|██▋       | 76/285 [02:15<06:13,  1.79s/it]predicting train subjects:  27%|██▋       | 77/285 [02:16<06:00,  1.73s/it]predicting train subjects:  27%|██▋       | 78/285 [02:18<06:07,  1.77s/it]predicting train subjects:  28%|██▊       | 79/285 [02:20<05:58,  1.74s/it]predicting train subjects:  28%|██▊       | 80/285 [02:22<05:54,  1.73s/it]predicting train subjects:  28%|██▊       | 81/285 [02:23<05:44,  1.69s/it]predicting train subjects:  29%|██▉       | 82/285 [02:25<05:46,  1.71s/it]predicting train subjects:  29%|██▉       | 83/285 [02:26<05:35,  1.66s/it]predicting train subjects:  29%|██▉       | 84/285 [02:28<05:24,  1.61s/it]predicting train subjects:  30%|██▉       | 85/285 [02:30<05:28,  1.64s/it]predicting train subjects:  30%|███       | 86/285 [02:32<05:40,  1.71s/it]predicting train subjects:  31%|███       | 87/285 [02:33<05:43,  1.73s/it]predicting train subjects:  31%|███       | 88/285 [02:35<05:34,  1.70s/it]predicting train subjects:  31%|███       | 89/285 [02:37<05:30,  1.68s/it]predicting train subjects:  32%|███▏      | 90/285 [02:38<05:29,  1.69s/it]predicting train subjects:  32%|███▏      | 91/285 [02:40<05:17,  1.63s/it]predicting train subjects:  32%|███▏      | 92/285 [02:42<05:18,  1.65s/it]predicting train subjects:  33%|███▎      | 93/285 [02:43<05:10,  1.62s/it]predicting train subjects:  33%|███▎      | 94/285 [02:45<05:13,  1.64s/it]predicting train subjects:  33%|███▎      | 95/285 [02:47<05:23,  1.70s/it]predicting train subjects:  34%|███▎      | 96/285 [02:48<05:28,  1.74s/it]predicting train subjects:  34%|███▍      | 97/285 [02:50<05:23,  1.72s/it]predicting train subjects:  34%|███▍      | 98/285 [02:52<05:26,  1.75s/it]predicting train subjects:  35%|███▍      | 99/285 [02:54<05:32,  1.79s/it]predicting train subjects:  35%|███▌      | 100/285 [02:56<05:35,  1.82s/it]predicting train subjects:  35%|███▌      | 101/285 [02:57<05:20,  1.74s/it]predicting train subjects:  36%|███▌      | 102/285 [02:59<05:15,  1.73s/it]predicting train subjects:  36%|███▌      | 103/285 [03:01<05:10,  1.71s/it]predicting train subjects:  36%|███▋      | 104/285 [03:03<05:21,  1.78s/it]predicting train subjects:  37%|███▋      | 105/285 [03:04<05:28,  1.82s/it]predicting train subjects:  37%|███▋      | 106/285 [03:06<05:19,  1.78s/it]predicting train subjects:  38%|███▊      | 107/285 [03:08<05:20,  1.80s/it]predicting train subjects:  38%|███▊      | 108/285 [03:10<05:06,  1.73s/it]predicting train subjects:  38%|███▊      | 109/285 [03:11<05:03,  1.73s/it]predicting train subjects:  39%|███▊      | 110/285 [03:13<05:00,  1.72s/it]predicting train subjects:  39%|███▉      | 111/285 [03:15<04:51,  1.68s/it]predicting train subjects:  39%|███▉      | 112/285 [03:16<04:51,  1.69s/it]predicting train subjects:  40%|███▉      | 113/285 [03:18<04:50,  1.69s/it]predicting train subjects:  40%|████      | 114/285 [03:20<04:46,  1.68s/it]predicting train subjects:  40%|████      | 115/285 [03:21<04:46,  1.68s/it]predicting train subjects:  41%|████      | 116/285 [03:23<04:45,  1.69s/it]predicting train subjects:  41%|████      | 117/285 [03:25<04:36,  1.65s/it]predicting train subjects:  41%|████▏     | 118/285 [03:26<04:29,  1.62s/it]predicting train subjects:  42%|████▏     | 119/285 [03:28<04:33,  1.65s/it]predicting train subjects:  42%|████▏     | 120/285 [03:29<04:25,  1.61s/it]predicting train subjects:  42%|████▏     | 121/285 [03:31<04:20,  1.59s/it]predicting train subjects:  43%|████▎     | 122/285 [03:32<04:14,  1.56s/it]predicting train subjects:  43%|████▎     | 123/285 [03:34<04:03,  1.51s/it]predicting train subjects:  44%|████▎     | 124/285 [03:35<04:02,  1.51s/it]predicting train subjects:  44%|████▍     | 125/285 [03:37<03:59,  1.50s/it]predicting train subjects:  44%|████▍     | 126/285 [03:38<03:55,  1.48s/it]predicting train subjects:  45%|████▍     | 127/285 [03:40<03:50,  1.46s/it]predicting train subjects:  45%|████▍     | 128/285 [03:41<03:52,  1.48s/it]predicting train subjects:  45%|████▌     | 129/285 [03:43<03:56,  1.51s/it]predicting train subjects:  46%|████▌     | 130/285 [03:44<03:50,  1.49s/it]predicting train subjects:  46%|████▌     | 131/285 [03:45<03:43,  1.45s/it]predicting train subjects:  46%|████▋     | 132/285 [03:47<03:44,  1.47s/it]predicting train subjects:  47%|████▋     | 133/285 [03:48<03:41,  1.45s/it]predicting train subjects:  47%|████▋     | 134/285 [03:50<03:37,  1.44s/it]predicting train subjects:  47%|████▋     | 135/285 [03:51<03:34,  1.43s/it]predicting train subjects:  48%|████▊     | 136/285 [03:53<03:29,  1.41s/it]predicting train subjects:  48%|████▊     | 137/285 [03:54<03:42,  1.51s/it]predicting train subjects:  48%|████▊     | 138/285 [03:56<03:35,  1.47s/it]predicting train subjects:  49%|████▉     | 139/285 [03:57<03:39,  1.50s/it]predicting train subjects:  49%|████▉     | 140/285 [03:59<03:43,  1.54s/it]predicting train subjects:  49%|████▉     | 141/285 [04:00<03:36,  1.50s/it]predicting train subjects:  50%|████▉     | 142/285 [04:02<03:30,  1.47s/it]predicting train subjects:  50%|█████     | 143/285 [04:03<03:27,  1.46s/it]predicting train subjects:  51%|█████     | 144/285 [04:05<03:29,  1.49s/it]predicting train subjects:  51%|█████     | 145/285 [04:06<03:28,  1.49s/it]predicting train subjects:  51%|█████     | 146/285 [04:08<03:28,  1.50s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:09<03:21,  1.46s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:11<03:24,  1.49s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:12<03:21,  1.48s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:14<03:18,  1.47s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:15<03:19,  1.49s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:16<03:13,  1.45s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:18<03:07,  1.42s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:19<03:10,  1.45s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:21<03:06,  1.44s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:22<03:07,  1.46s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:24<03:03,  1.43s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:25<03:00,  1.42s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:26<02:57,  1.41s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:28<02:57,  1.42s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:29<03:02,  1.47s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:31<02:58,  1.45s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:32<02:59,  1.47s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:34<02:55,  1.45s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:35<02:50,  1.42s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:37<02:54,  1.47s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:38<02:52,  1.47s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:39<02:46,  1.42s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:41<02:47,  1.45s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:42<02:44,  1.43s/it]predicting train subjects:  60%|██████    | 171/285 [04:44<02:42,  1.43s/it]predicting train subjects:  60%|██████    | 172/285 [04:45<02:41,  1.43s/it]predicting train subjects:  61%|██████    | 173/285 [04:47<02:37,  1.41s/it]predicting train subjects:  61%|██████    | 174/285 [04:48<02:35,  1.40s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:49<02:38,  1.44s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:51<02:45,  1.52s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:53<02:42,  1.50s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:54<02:37,  1.47s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:55<02:34,  1.45s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:57<02:41,  1.54s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:59<02:42,  1.56s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:00<02:41,  1.57s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:02<02:32,  1.50s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:03<02:31,  1.50s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:05<02:24,  1.45s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:06<02:32,  1.54s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:08<02:37,  1.61s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:10<02:41,  1.67s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:11<02:32,  1.59s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:13<02:25,  1.53s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:14<02:28,  1.58s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:16<02:26,  1.58s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:17<02:19,  1.51s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:19<02:13,  1.47s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:20<02:08,  1.43s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:22<02:17,  1.54s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:24<02:19,  1.59s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:25<02:21,  1.62s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:27<02:11,  1.53s/it]predicting train subjects:  70%|███████   | 200/285 [05:28<02:05,  1.48s/it]predicting train subjects:  71%|███████   | 201/285 [05:30<02:09,  1.54s/it]predicting train subjects:  71%|███████   | 202/285 [05:31<02:08,  1.55s/it]predicting train subjects:  71%|███████   | 203/285 [05:33<02:09,  1.57s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:34<01:59,  1.48s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:35<01:54,  1.44s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:37<01:51,  1.42s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:39<01:59,  1.53s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:40<02:02,  1.59s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:42<02:03,  1.62s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:43<01:54,  1.52s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:45<01:48,  1.47s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:46<01:48,  1.49s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:48<01:49,  1.52s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:49<01:45,  1.48s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:51<01:48,  1.55s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:52<01:44,  1.51s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:54<01:48,  1.59s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:56<01:52,  1.68s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:58<01:53,  1.72s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:59<01:44,  1.61s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:01<01:39,  1.56s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:02<01:40,  1.60s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:04<01:34,  1.53s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:05<01:30,  1.48s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:06<01:28,  1.47s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:08<01:33,  1.59s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:10<01:36,  1.67s/it]predicting train subjects:  80%|████████  | 228/285 [06:12<01:36,  1.69s/it]predicting train subjects:  80%|████████  | 229/285 [06:14<01:34,  1.69s/it]predicting train subjects:  81%|████████  | 230/285 [06:15<01:26,  1.57s/it]predicting train subjects:  81%|████████  | 231/285 [06:16<01:21,  1.50s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:18<01:21,  1.55s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:19<01:18,  1.50s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:21<01:22,  1.63s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:22<01:17,  1.54s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:24<01:20,  1.65s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:26<01:21,  1.71s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:28<01:21,  1.74s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:30<01:19,  1.73s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:31<01:13,  1.64s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:33<01:08,  1.57s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:34<01:05,  1.51s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:35<01:01,  1.47s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:37<01:03,  1.55s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:39<01:00,  1.52s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:40<01:02,  1.61s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:42<01:04,  1.70s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:44<01:02,  1.68s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:45<00:58,  1.61s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:47<00:54,  1.55s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:48<00:50,  1.50s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:49<00:47,  1.45s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:51<00:50,  1.57s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:53<00:50,  1.64s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:55<00:49,  1.64s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:56<00:45,  1.56s/it]predicting train subjects:  90%|█████████ | 257/285 [06:58<00:42,  1.52s/it]predicting train subjects:  91%|█████████ | 258/285 [06:59<00:43,  1.60s/it]predicting train subjects:  91%|█████████ | 259/285 [07:01<00:42,  1.62s/it]predicting train subjects:  91%|█████████ | 260/285 [07:02<00:38,  1.55s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:04<00:36,  1.51s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:05<00:33,  1.46s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:07<00:31,  1.44s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:08<00:32,  1.56s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:10<00:32,  1.63s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:12<00:29,  1.54s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:13<00:27,  1.51s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:15<00:27,  1.60s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:16<00:25,  1.61s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:18<00:22,  1.52s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:19<00:20,  1.49s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:21<00:20,  1.55s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:22<00:17,  1.48s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:23<00:15,  1.44s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:25<00:15,  1.55s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:27<00:14,  1.64s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:29<00:12,  1.56s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:30<00:10,  1.53s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:32<00:09,  1.58s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:33<00:07,  1.51s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:34<00:05,  1.50s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:36<00:04,  1.45s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:38<00:03,  1.56s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:39<00:01,  1.63s/it]predicting train subjects: 100%|██████████| 285/285 [07:41<00:00,  1.70s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:35,  1.81s/it]Loading train:   1%|          | 2/285 [00:03<08:14,  1.75s/it]Loading train:   1%|          | 3/285 [00:04<07:59,  1.70s/it]Loading train:   1%|▏         | 4/285 [00:06<07:33,  1.61s/it]Loading train:   2%|▏         | 5/285 [00:08<07:42,  1.65s/it]Loading train:   2%|▏         | 6/285 [00:09<07:09,  1.54s/it]Loading train:   2%|▏         | 7/285 [00:11<07:32,  1.63s/it]Loading train:   3%|▎         | 8/285 [00:12<07:11,  1.56s/it]Loading train:   3%|▎         | 9/285 [00:14<07:37,  1.66s/it]Loading train:   4%|▎         | 10/285 [00:15<06:50,  1.49s/it]Loading train:   4%|▍         | 11/285 [00:16<06:02,  1.32s/it]Loading train:   4%|▍         | 12/285 [00:17<05:39,  1.24s/it]Loading train:   5%|▍         | 13/285 [00:18<04:58,  1.10s/it]Loading train:   5%|▍         | 14/285 [00:19<04:47,  1.06s/it]Loading train:   5%|▌         | 15/285 [00:20<04:34,  1.02s/it]Loading train:   6%|▌         | 16/285 [00:21<04:27,  1.01it/s]Loading train:   6%|▌         | 17/285 [00:22<04:33,  1.02s/it]Loading train:   6%|▋         | 18/285 [00:23<04:39,  1.05s/it]Loading train:   7%|▋         | 19/285 [00:24<04:28,  1.01s/it]Loading train:   7%|▋         | 20/285 [00:25<04:33,  1.03s/it]Loading train:   7%|▋         | 21/285 [00:26<04:43,  1.07s/it]Loading train:   8%|▊         | 22/285 [00:27<04:37,  1.06s/it]Loading train:   8%|▊         | 23/285 [00:29<05:06,  1.17s/it]Loading train:   8%|▊         | 24/285 [00:29<04:33,  1.05s/it]Loading train:   9%|▉         | 25/285 [00:31<04:50,  1.12s/it]Loading train:   9%|▉         | 26/285 [00:32<04:50,  1.12s/it]Loading train:   9%|▉         | 27/285 [00:33<04:39,  1.08s/it]Loading train:  10%|▉         | 28/285 [00:34<04:54,  1.15s/it]Loading train:  10%|█         | 29/285 [00:35<05:07,  1.20s/it]Loading train:  11%|█         | 30/285 [00:37<05:10,  1.22s/it]Loading train:  11%|█         | 31/285 [00:38<05:08,  1.22s/it]Loading train:  11%|█         | 32/285 [00:39<04:50,  1.15s/it]Loading train:  12%|█▏        | 33/285 [00:40<04:55,  1.17s/it]Loading train:  12%|█▏        | 34/285 [00:41<04:55,  1.18s/it]Loading train:  12%|█▏        | 35/285 [00:42<04:38,  1.12s/it]Loading train:  13%|█▎        | 36/285 [00:43<04:20,  1.05s/it]Loading train:  13%|█▎        | 37/285 [00:44<04:23,  1.06s/it]Loading train:  13%|█▎        | 38/285 [00:45<04:27,  1.08s/it]Loading train:  14%|█▎        | 39/285 [00:46<04:04,  1.00it/s]Loading train:  14%|█▍        | 40/285 [00:47<04:18,  1.05s/it]Loading train:  14%|█▍        | 41/285 [00:48<04:08,  1.02s/it]Loading train:  15%|█▍        | 42/285 [00:49<03:55,  1.03it/s]Loading train:  15%|█▌        | 43/285 [00:50<03:56,  1.02it/s]Loading train:  15%|█▌        | 44/285 [00:51<04:16,  1.06s/it]Loading train:  16%|█▌        | 45/285 [00:52<04:01,  1.01s/it]Loading train:  16%|█▌        | 46/285 [00:53<04:04,  1.02s/it]Loading train:  16%|█▋        | 47/285 [00:54<03:49,  1.04it/s]Loading train:  17%|█▋        | 48/285 [00:55<03:45,  1.05it/s]Loading train:  17%|█▋        | 49/285 [00:56<04:00,  1.02s/it]Loading train:  18%|█▊        | 50/285 [00:57<04:03,  1.04s/it]Loading train:  18%|█▊        | 51/285 [00:59<04:17,  1.10s/it]Loading train:  18%|█▊        | 52/285 [01:00<04:11,  1.08s/it]Loading train:  19%|█▊        | 53/285 [01:01<04:15,  1.10s/it]Loading train:  19%|█▉        | 54/285 [01:02<04:19,  1.12s/it]Loading train:  19%|█▉        | 55/285 [01:03<04:10,  1.09s/it]Loading train:  20%|█▉        | 56/285 [01:04<04:11,  1.10s/it]Loading train:  20%|██        | 57/285 [01:05<04:09,  1.09s/it]Loading train:  20%|██        | 58/285 [01:06<04:16,  1.13s/it]Loading train:  21%|██        | 59/285 [01:07<04:15,  1.13s/it]Loading train:  21%|██        | 60/285 [01:09<04:11,  1.12s/it]Loading train:  21%|██▏       | 61/285 [01:10<04:02,  1.08s/it]Loading train:  22%|██▏       | 62/285 [01:11<04:12,  1.13s/it]Loading train:  22%|██▏       | 63/285 [01:12<04:27,  1.20s/it]Loading train:  22%|██▏       | 64/285 [01:14<04:41,  1.27s/it]Loading train:  23%|██▎       | 65/285 [01:15<05:15,  1.44s/it]Loading train:  23%|██▎       | 66/285 [01:17<05:34,  1.53s/it]Loading train:  24%|██▎       | 67/285 [01:18<05:15,  1.45s/it]Loading train:  24%|██▍       | 68/285 [01:19<04:34,  1.27s/it]Loading train:  24%|██▍       | 69/285 [01:20<04:18,  1.20s/it]Loading train:  25%|██▍       | 70/285 [01:21<04:18,  1.20s/it]Loading train:  25%|██▍       | 71/285 [01:23<04:16,  1.20s/it]Loading train:  25%|██▌       | 72/285 [01:24<04:16,  1.21s/it]Loading train:  26%|██▌       | 73/285 [01:25<04:12,  1.19s/it]Loading train:  26%|██▌       | 74/285 [01:26<04:07,  1.18s/it]Loading train:  26%|██▋       | 75/285 [01:27<04:01,  1.15s/it]Loading train:  27%|██▋       | 76/285 [01:28<03:59,  1.15s/it]Loading train:  27%|██▋       | 77/285 [01:29<03:39,  1.06s/it]Loading train:  27%|██▋       | 78/285 [01:30<03:27,  1.00s/it]Loading train:  28%|██▊       | 79/285 [01:31<03:32,  1.03s/it]Loading train:  28%|██▊       | 80/285 [01:32<03:29,  1.02s/it]Loading train:  28%|██▊       | 81/285 [01:33<03:23,  1.00it/s]Loading train:  29%|██▉       | 82/285 [01:34<03:15,  1.04it/s]Loading train:  29%|██▉       | 83/285 [01:35<03:15,  1.03it/s]Loading train:  29%|██▉       | 84/285 [01:36<03:11,  1.05it/s]Loading train:  30%|██▉       | 85/285 [01:37<03:32,  1.06s/it]Loading train:  30%|███       | 86/285 [01:38<03:39,  1.10s/it]Loading train:  31%|███       | 87/285 [01:40<03:34,  1.08s/it]Loading train:  31%|███       | 88/285 [01:40<03:23,  1.03s/it]Loading train:  31%|███       | 89/285 [01:41<03:21,  1.03s/it]Loading train:  32%|███▏      | 90/285 [01:43<03:29,  1.08s/it]Loading train:  32%|███▏      | 91/285 [01:44<03:22,  1.04s/it]Loading train:  32%|███▏      | 92/285 [01:45<03:36,  1.12s/it]Loading train:  33%|███▎      | 93/285 [01:46<03:35,  1.12s/it]Loading train:  33%|███▎      | 94/285 [01:47<03:33,  1.12s/it]Loading train:  33%|███▎      | 95/285 [01:48<03:33,  1.12s/it]Loading train:  34%|███▎      | 96/285 [01:49<03:33,  1.13s/it]Loading train:  34%|███▍      | 97/285 [01:50<03:24,  1.09s/it]Loading train:  34%|███▍      | 98/285 [01:51<03:19,  1.07s/it]Loading train:  35%|███▍      | 99/285 [01:52<03:14,  1.04s/it]Loading train:  35%|███▌      | 100/285 [01:54<03:17,  1.07s/it]Loading train:  35%|███▌      | 101/285 [01:55<03:09,  1.03s/it]Loading train:  36%|███▌      | 102/285 [01:56<03:18,  1.08s/it]Loading train:  36%|███▌      | 103/285 [01:57<03:09,  1.04s/it]Loading train:  36%|███▋      | 104/285 [01:58<03:09,  1.05s/it]Loading train:  37%|███▋      | 105/285 [01:59<03:17,  1.10s/it]Loading train:  37%|███▋      | 106/285 [02:00<03:05,  1.04s/it]Loading train:  38%|███▊      | 107/285 [02:01<03:05,  1.04s/it]Loading train:  38%|███▊      | 108/285 [02:02<03:03,  1.04s/it]Loading train:  38%|███▊      | 109/285 [02:03<03:05,  1.05s/it]Loading train:  39%|███▊      | 110/285 [02:04<03:04,  1.05s/it]Loading train:  39%|███▉      | 111/285 [02:05<02:56,  1.01s/it]Loading train:  39%|███▉      | 112/285 [02:06<03:00,  1.04s/it]Loading train:  40%|███▉      | 113/285 [02:07<03:07,  1.09s/it]Loading train:  40%|████      | 114/285 [02:08<03:03,  1.07s/it]Loading train:  40%|████      | 115/285 [02:09<02:57,  1.05s/it]Loading train:  41%|████      | 116/285 [02:10<03:04,  1.09s/it]Loading train:  41%|████      | 117/285 [02:11<02:56,  1.05s/it]Loading train:  41%|████▏     | 118/285 [02:12<02:47,  1.00s/it]Loading train:  42%|████▏     | 119/285 [02:14<02:59,  1.08s/it]Loading train:  42%|████▏     | 120/285 [02:14<02:48,  1.02s/it]Loading train:  42%|████▏     | 121/285 [02:16<03:05,  1.13s/it]Loading train:  43%|████▎     | 122/285 [02:17<03:11,  1.17s/it]Loading train:  43%|████▎     | 123/285 [02:18<03:10,  1.17s/it]Loading train:  44%|████▎     | 124/285 [02:19<03:00,  1.12s/it]Loading train:  44%|████▍     | 125/285 [02:20<02:50,  1.06s/it]Loading train:  44%|████▍     | 126/285 [02:21<02:44,  1.03s/it]Loading train:  45%|████▍     | 127/285 [02:22<02:37,  1.01it/s]Loading train:  45%|████▍     | 128/285 [02:23<02:33,  1.02it/s]Loading train:  45%|████▌     | 129/285 [02:24<02:34,  1.01it/s]Loading train:  46%|████▌     | 130/285 [02:25<02:34,  1.00it/s]Loading train:  46%|████▌     | 131/285 [02:26<02:37,  1.02s/it]Loading train:  46%|████▋     | 132/285 [02:27<02:36,  1.02s/it]Loading train:  47%|████▋     | 133/285 [02:28<02:25,  1.04it/s]Loading train:  47%|████▋     | 134/285 [02:29<02:21,  1.07it/s]Loading train:  47%|████▋     | 135/285 [02:30<02:27,  1.01it/s]Loading train:  48%|████▊     | 136/285 [02:31<02:25,  1.02it/s]Loading train:  48%|████▊     | 137/285 [02:32<02:28,  1.00s/it]Loading train:  48%|████▊     | 138/285 [02:33<02:35,  1.05s/it]Loading train:  49%|████▉     | 139/285 [02:34<02:31,  1.04s/it]Loading train:  49%|████▉     | 140/285 [02:35<02:22,  1.02it/s]Loading train:  49%|████▉     | 141/285 [02:36<02:17,  1.05it/s]Loading train:  50%|████▉     | 142/285 [02:37<02:10,  1.10it/s]Loading train:  50%|█████     | 143/285 [02:38<02:13,  1.06it/s]Loading train:  51%|█████     | 144/285 [02:39<02:09,  1.09it/s]Loading train:  51%|█████     | 145/285 [02:40<02:10,  1.08it/s]Loading train:  51%|█████     | 146/285 [02:41<02:12,  1.05it/s]Loading train:  52%|█████▏    | 147/285 [02:41<02:08,  1.07it/s]Loading train:  52%|█████▏    | 148/285 [02:42<02:04,  1.10it/s]Loading train:  52%|█████▏    | 149/285 [02:43<01:57,  1.16it/s]Loading train:  53%|█████▎    | 150/285 [02:44<01:55,  1.16it/s]Loading train:  53%|█████▎    | 151/285 [02:45<01:53,  1.18it/s]Loading train:  53%|█████▎    | 152/285 [02:46<01:51,  1.20it/s]Loading train:  54%|█████▎    | 153/285 [02:46<01:52,  1.17it/s]Loading train:  54%|█████▍    | 154/285 [02:47<01:59,  1.10it/s]Loading train:  54%|█████▍    | 155/285 [02:48<02:02,  1.06it/s]Loading train:  55%|█████▍    | 156/285 [02:49<02:02,  1.06it/s]Loading train:  55%|█████▌    | 157/285 [02:50<01:58,  1.08it/s]Loading train:  55%|█████▌    | 158/285 [02:51<02:02,  1.04it/s]Loading train:  56%|█████▌    | 159/285 [02:52<01:54,  1.10it/s]Loading train:  56%|█████▌    | 160/285 [02:53<01:51,  1.12it/s]Loading train:  56%|█████▋    | 161/285 [02:54<01:53,  1.09it/s]Loading train:  57%|█████▋    | 162/285 [02:55<01:47,  1.14it/s]Loading train:  57%|█████▋    | 163/285 [02:56<01:57,  1.04it/s]Loading train:  58%|█████▊    | 164/285 [02:57<01:52,  1.07it/s]Loading train:  58%|█████▊    | 165/285 [02:58<01:47,  1.12it/s]Loading train:  58%|█████▊    | 166/285 [02:58<01:41,  1.17it/s]Loading train:  59%|█████▊    | 167/285 [02:59<01:48,  1.09it/s]Loading train:  59%|█████▉    | 168/285 [03:00<01:46,  1.10it/s]Loading train:  59%|█████▉    | 169/285 [03:01<01:43,  1.12it/s]Loading train:  60%|█████▉    | 170/285 [03:02<01:46,  1.08it/s]Loading train:  60%|██████    | 171/285 [03:03<01:45,  1.08it/s]Loading train:  60%|██████    | 172/285 [03:04<01:41,  1.11it/s]Loading train:  61%|██████    | 173/285 [03:05<01:44,  1.08it/s]Loading train:  61%|██████    | 174/285 [03:06<01:42,  1.08it/s]Loading train:  61%|██████▏   | 175/285 [03:07<01:45,  1.04it/s]Loading train:  62%|██████▏   | 176/285 [03:08<01:48,  1.00it/s]Loading train:  62%|██████▏   | 177/285 [03:09<01:40,  1.07it/s]Loading train:  62%|██████▏   | 178/285 [03:10<01:40,  1.06it/s]Loading train:  63%|██████▎   | 179/285 [03:11<01:43,  1.02it/s]Loading train:  63%|██████▎   | 180/285 [03:12<01:45,  1.00s/it]Loading train:  64%|██████▎   | 181/285 [03:13<01:45,  1.02s/it]Loading train:  64%|██████▍   | 182/285 [03:14<01:42,  1.00it/s]Loading train:  64%|██████▍   | 183/285 [03:15<01:38,  1.03it/s]Loading train:  65%|██████▍   | 184/285 [03:16<01:35,  1.06it/s]Loading train:  65%|██████▍   | 185/285 [03:16<01:30,  1.11it/s]Loading train:  65%|██████▌   | 186/285 [03:18<01:38,  1.00it/s]Loading train:  66%|██████▌   | 187/285 [03:19<01:35,  1.03it/s]Loading train:  66%|██████▌   | 188/285 [03:20<01:38,  1.01s/it]Loading train:  66%|██████▋   | 189/285 [03:21<01:32,  1.03it/s]Loading train:  67%|██████▋   | 190/285 [03:22<01:33,  1.02it/s]Loading train:  67%|██████▋   | 191/285 [03:22<01:30,  1.03it/s]Loading train:  67%|██████▋   | 192/285 [03:24<01:32,  1.01it/s]Loading train:  68%|██████▊   | 193/285 [03:24<01:28,  1.04it/s]Loading train:  68%|██████▊   | 194/285 [03:25<01:24,  1.08it/s]Loading train:  68%|██████▊   | 195/285 [03:26<01:18,  1.14it/s]Loading train:  69%|██████▉   | 196/285 [03:27<01:22,  1.08it/s]Loading train:  69%|██████▉   | 197/285 [03:28<01:22,  1.06it/s]Loading train:  69%|██████▉   | 198/285 [03:29<01:23,  1.04it/s]Loading train:  70%|██████▉   | 199/285 [03:30<01:21,  1.06it/s]Loading train:  70%|███████   | 200/285 [03:31<01:21,  1.05it/s]Loading train:  71%|███████   | 201/285 [03:32<01:20,  1.05it/s]Loading train:  71%|███████   | 202/285 [03:33<01:21,  1.02it/s]Loading train:  71%|███████   | 203/285 [03:34<01:16,  1.07it/s]Loading train:  72%|███████▏  | 204/285 [03:35<01:20,  1.00it/s]Loading train:  72%|███████▏  | 205/285 [03:36<01:16,  1.05it/s]Loading train:  72%|███████▏  | 206/285 [03:37<01:12,  1.09it/s]Loading train:  73%|███████▎  | 207/285 [03:38<01:15,  1.03it/s]Loading train:  73%|███████▎  | 208/285 [03:39<01:20,  1.05s/it]Loading train:  73%|███████▎  | 209/285 [03:40<01:21,  1.08s/it]Loading train:  74%|███████▎  | 210/285 [03:41<01:13,  1.02it/s]Loading train:  74%|███████▍  | 211/285 [03:42<01:08,  1.09it/s]Loading train:  74%|███████▍  | 212/285 [03:43<01:09,  1.05it/s]Loading train:  75%|███████▍  | 213/285 [03:44<01:12,  1.01s/it]Loading train:  75%|███████▌  | 214/285 [03:45<01:09,  1.02it/s]Loading train:  75%|███████▌  | 215/285 [03:46<01:10,  1.00s/it]Loading train:  76%|███████▌  | 216/285 [03:47<01:08,  1.01it/s]Loading train:  76%|███████▌  | 217/285 [03:48<01:11,  1.05s/it]Loading train:  76%|███████▋  | 218/285 [03:49<01:13,  1.10s/it]Loading train:  77%|███████▋  | 219/285 [03:50<01:10,  1.07s/it]Loading train:  77%|███████▋  | 220/285 [03:51<01:03,  1.03it/s]Loading train:  78%|███████▊  | 221/285 [03:52<00:57,  1.12it/s]Loading train:  78%|███████▊  | 222/285 [03:52<00:54,  1.16it/s]Loading train:  78%|███████▊  | 223/285 [03:53<00:53,  1.15it/s]Loading train:  79%|███████▊  | 224/285 [03:54<00:54,  1.12it/s]Loading train:  79%|███████▉  | 225/285 [03:55<00:53,  1.12it/s]Loading train:  79%|███████▉  | 226/285 [03:56<00:55,  1.07it/s]Loading train:  80%|███████▉  | 227/285 [03:57<00:54,  1.06it/s]Loading train:  80%|████████  | 228/285 [03:58<00:53,  1.07it/s]Loading train:  80%|████████  | 229/285 [03:59<00:52,  1.08it/s]Loading train:  81%|████████  | 230/285 [04:00<00:48,  1.13it/s]Loading train:  81%|████████  | 231/285 [04:00<00:46,  1.15it/s]Loading train:  81%|████████▏ | 232/285 [04:01<00:47,  1.12it/s]Loading train:  82%|████████▏ | 233/285 [04:02<00:48,  1.07it/s]Loading train:  82%|████████▏ | 234/285 [04:04<00:49,  1.03it/s]Loading train:  82%|████████▏ | 235/285 [04:04<00:48,  1.03it/s]Loading train:  83%|████████▎ | 236/285 [04:05<00:47,  1.02it/s]Loading train:  83%|████████▎ | 237/285 [04:07<00:50,  1.04s/it]Loading train:  84%|████████▎ | 238/285 [04:08<00:50,  1.07s/it]Loading train:  84%|████████▍ | 239/285 [04:09<00:48,  1.05s/it]Loading train:  84%|████████▍ | 240/285 [04:10<00:43,  1.03it/s]Loading train:  85%|████████▍ | 241/285 [04:11<00:41,  1.05it/s]Loading train:  85%|████████▍ | 242/285 [04:11<00:38,  1.11it/s]Loading train:  85%|████████▌ | 243/285 [04:12<00:37,  1.11it/s]Loading train:  86%|████████▌ | 244/285 [04:13<00:39,  1.04it/s]Loading train:  86%|████████▌ | 245/285 [04:14<00:38,  1.03it/s]Loading train:  86%|████████▋ | 246/285 [04:15<00:39,  1.02s/it]Loading train:  87%|████████▋ | 247/285 [04:17<00:41,  1.08s/it]Loading train:  87%|████████▋ | 248/285 [04:18<00:38,  1.05s/it]Loading train:  87%|████████▋ | 249/285 [04:18<00:33,  1.06it/s]Loading train:  88%|████████▊ | 250/285 [04:19<00:33,  1.06it/s]Loading train:  88%|████████▊ | 251/285 [04:20<00:33,  1.01it/s]Loading train:  88%|████████▊ | 252/285 [04:21<00:33,  1.02s/it]Loading train:  89%|████████▉ | 253/285 [04:23<00:33,  1.04s/it]Loading train:  89%|████████▉ | 254/285 [04:24<00:32,  1.04s/it]Loading train:  89%|████████▉ | 255/285 [04:24<00:30,  1.00s/it]Loading train:  90%|████████▉ | 256/285 [04:25<00:27,  1.06it/s]Loading train:  90%|█████████ | 257/285 [04:26<00:25,  1.11it/s]Loading train:  91%|█████████ | 258/285 [04:27<00:26,  1.02it/s]Loading train:  91%|█████████ | 259/285 [04:28<00:24,  1.05it/s]Loading train:  91%|█████████ | 260/285 [04:29<00:24,  1.03it/s]Loading train:  92%|█████████▏| 261/285 [04:30<00:22,  1.07it/s]Loading train:  92%|█████████▏| 262/285 [04:31<00:20,  1.11it/s]Loading train:  92%|█████████▏| 263/285 [04:32<00:19,  1.14it/s]Loading train:  93%|█████████▎| 264/285 [04:33<00:20,  1.04it/s]Loading train:  93%|█████████▎| 265/285 [04:34<00:19,  1.03it/s]Loading train:  93%|█████████▎| 266/285 [04:35<00:17,  1.07it/s]Loading train:  94%|█████████▎| 267/285 [04:36<00:16,  1.07it/s]Loading train:  94%|█████████▍| 268/285 [04:37<00:16,  1.03it/s]Loading train:  94%|█████████▍| 269/285 [04:38<00:16,  1.01s/it]Loading train:  95%|█████████▍| 270/285 [04:39<00:14,  1.02it/s]Loading train:  95%|█████████▌| 271/285 [04:40<00:13,  1.03it/s]Loading train:  95%|█████████▌| 272/285 [04:41<00:12,  1.06it/s]Loading train:  96%|█████████▌| 273/285 [04:41<00:10,  1.10it/s]Loading train:  96%|█████████▌| 274/285 [04:42<00:09,  1.10it/s]Loading train:  96%|█████████▋| 275/285 [04:43<00:09,  1.04it/s]Loading train:  97%|█████████▋| 276/285 [04:44<00:08,  1.02it/s]Loading train:  97%|█████████▋| 277/285 [04:45<00:07,  1.11it/s]Loading train:  98%|█████████▊| 278/285 [04:46<00:05,  1.17it/s]Loading train:  98%|█████████▊| 279/285 [04:47<00:05,  1.10it/s]Loading train:  98%|█████████▊| 280/285 [04:48<00:04,  1.06it/s]Loading train:  99%|█████████▊| 281/285 [04:49<00:03,  1.10it/s]Loading train:  99%|█████████▉| 282/285 [04:50<00:02,  1.12it/s]Loading train:  99%|█████████▉| 283/285 [04:51<00:01,  1.00it/s]Loading train: 100%|█████████▉| 284/285 [04:52<00:00,  1.01it/s]Loading train: 100%|██████████| 285/285 [04:53<00:00,  1.04s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|          | 2/285 [00:00<00:15, 17.76it/s]concatenating: train:   2%|▏         | 6/285 [00:00<00:13, 20.82it/s]concatenating: train:   7%|▋         | 21/285 [00:00<00:09, 28.07it/s]concatenating: train:  19%|█▉        | 54/285 [00:00<00:05, 38.66it/s]concatenating: train:  31%|███       | 87/285 [00:00<00:03, 52.53it/s]concatenating: train:  43%|████▎     | 122/285 [00:00<00:02, 70.46it/s]concatenating: train:  55%|█████▌    | 157/285 [00:00<00:01, 92.57it/s]concatenating: train:  65%|██████▍   | 185/285 [00:01<00:01, 85.50it/s]concatenating: train:  73%|███████▎  | 207/285 [00:01<00:00, 89.94it/s]concatenating: train:  84%|████████▎ | 238/285 [00:01<00:00, 114.08it/s]concatenating: train:  97%|█████████▋| 276/285 [00:01<00:00, 144.30it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 183.35it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.54s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.46s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.37s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 372.77it/s]2019-07-11 00:03:03.503100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 00:03:03.503211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 00:03:03.503226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 00:03:03.503234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 00:03:03.503665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:10,  4.05it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:08,  5.02it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.10it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.49it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  5.94it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  6.95it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.33it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.21it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.68it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.83it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.10it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  8.72it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  8.86it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.00it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.65it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.90it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.16it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.34it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.09it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 30)   4080        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 40, 45)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 60)   24360       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 20, 105)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 105)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 105)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 105)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 15)   4065        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 45)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 45)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 30)   12180       dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 30)   120         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 30)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 80, 30)   0           activation_11[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 75)   0           dropout_5[0][0]                  
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 13)   988         concatenate_7[0][0]              
==================================================================================================
Total params: 139,168
Trainable params: 40,648
Non-trainable params: 98,520
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 15s - loss: 2.9751 - acc: 0.3791 - mDice: 0.1042 - val_loss: 2.1661 - val_acc: 0.9034 - val_mDice: 0.2130

Epoch 00001: val_mDice improved from -inf to 0.21300, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 8s - loss: 1.0459 - acc: 0.8790 - mDice: 0.3639 - val_loss: 1.4383 - val_acc: 0.9163 - val_mDice: 0.4089

Epoch 00002: val_mDice improved from 0.21300 to 0.40894, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 9s - loss: 0.6562 - acc: 0.8902 - mDice: 0.5080 - val_loss: 1.2658 - val_acc: 0.9209 - val_mDice: 0.4788

Epoch 00003: val_mDice improved from 0.40894 to 0.47882, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 8s - loss: 0.5455 - acc: 0.8956 - mDice: 0.5662 - val_loss: 1.1263 - val_acc: 0.9242 - val_mDice: 0.5359

Epoch 00004: val_mDice improved from 0.47882 to 0.53590, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 8s - loss: 0.4945 - acc: 0.8995 - mDice: 0.5960 - val_loss: 1.0010 - val_acc: 0.9267 - val_mDice: 0.5611

Epoch 00005: val_mDice improved from 0.53590 to 0.56106, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 8s - loss: 0.4678 - acc: 0.9022 - mDice: 0.6126 - val_loss: 0.9997 - val_acc: 0.9269 - val_mDice: 0.5542

Epoch 00006: val_mDice did not improve from 0.56106
Epoch 7/300
 - 8s - loss: 0.4488 - acc: 0.9049 - mDice: 0.6246 - val_loss: 1.0438 - val_acc: 0.9253 - val_mDice: 0.5531

Epoch 00007: val_mDice did not improve from 0.56106
Epoch 8/300
 - 9s - loss: 0.4359 - acc: 0.9072 - mDice: 0.6329 - val_loss: 0.9903 - val_acc: 0.9284 - val_mDice: 0.5752

Epoch 00008: val_mDice improved from 0.56106 to 0.57523, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 9s - loss: 0.4230 - acc: 0.9098 - mDice: 0.6412 - val_loss: 0.9418 - val_acc: 0.9318 - val_mDice: 0.5794

Epoch 00009: val_mDice improved from 0.57523 to 0.57942, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 8s - loss: 0.4112 - acc: 0.9124 - mDice: 0.6491 - val_loss: 0.9539 - val_acc: 0.9327 - val_mDice: 0.5754

Epoch 00010: val_mDice did not improve from 0.57942
Epoch 11/300
 - 8s - loss: 0.4052 - acc: 0.9142 - mDice: 0.6530 - val_loss: 0.9545 - val_acc: 0.9326 - val_mDice: 0.5840

Epoch 00011: val_mDice improved from 0.57942 to 0.58395, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 9s - loss: 0.3991 - acc: 0.9162 - mDice: 0.6571 - val_loss: 0.9675 - val_acc: 0.9368 - val_mDice: 0.5668

Epoch 00012: val_mDice did not improve from 0.58395
Epoch 13/300
 - 8s - loss: 0.3928 - acc: 0.9186 - mDice: 0.6614 - val_loss: 0.9582 - val_acc: 0.9368 - val_mDice: 0.5725

Epoch 00013: val_mDice did not improve from 0.58395
Epoch 14/300
 - 9s - loss: 0.3873 - acc: 0.9196 - mDice: 0.6651 - val_loss: 0.9446 - val_acc: 0.9405 - val_mDice: 0.5772

Epoch 00014: val_mDice did not improve from 0.58395
Epoch 15/300
 - 9s - loss: 0.3837 - acc: 0.9212 - mDice: 0.6676 - val_loss: 0.9896 - val_acc: 0.9394 - val_mDice: 0.5475

Epoch 00015: val_mDice did not improve from 0.58395
Epoch 16/300
 - 9s - loss: 0.3789 - acc: 0.9227 - mDice: 0.6710 - val_loss: 0.9706 - val_acc: 0.9411 - val_mDice: 0.5722

Epoch 00016: val_mDice did not improve from 0.58395
Epoch 17/300
 - 10s - loss: 0.3738 - acc: 0.9246 - mDice: 0.6744 - val_loss: 0.9502 - val_acc: 0.9429 - val_mDice: 0.5734

Epoch 00017: val_mDice did not improve from 0.58395
Epoch 18/300
 - 9s - loss: 0.3707 - acc: 0.9258 - mDice: 0.6766 - val_loss: 0.9542 - val_acc: 0.9449 - val_mDice: 0.5628

Epoch 00018: val_mDice did not improve from 0.58395
Epoch 19/300
 - 10s - loss: 0.3658 - acc: 0.9267 - mDice: 0.6800 - val_loss: 0.9588 - val_acc: 0.9438 - val_mDice: 0.5483

Epoch 00019: val_mDice did not improve from 0.58395
Epoch 20/300
 - 10s - loss: 0.3629 - acc: 0.9283 - mDice: 0.6819 - val_loss: 0.9509 - val_acc: 0.9448 - val_mDice: 0.5490

Epoch 00020: val_mDice did not improve from 0.58395
Epoch 21/300
 - 9s - loss: 0.3610 - acc: 0.9295 - mDice: 0.6834 - val_loss: 0.9797 - val_acc: 0.9412 - val_mDice: 0.5304

Epoch 00021: val_mDice did not improve from 0.58395
Epoch 22/300
 - 11s - loss: 0.3591 - acc: 0.9305 - mDice: 0.6845 - val_loss: 0.9131 - val_acc: 0.9455 - val_mDice: 0.5679

Epoch 00022: val_mDice did not improve from 0.58395
Epoch 23/300
 - 9s - loss: 0.3555 - acc: 0.9321 - mDice: 0.6871 - val_loss: 0.9500 - val_acc: 0.9386 - val_mDice: 0.5641

Epoch 00023: val_mDice did not improve from 0.58395
Epoch 24/300
 - 10s - loss: 0.3513 - acc: 0.9334 - mDice: 0.6902 - val_loss: 0.9443 - val_acc: 0.9454 - val_mDice: 0.5615

Epoch 00024: val_mDice did not improve from 0.58395
Epoch 25/300
 - 9s - loss: 0.3500 - acc: 0.9343 - mDice: 0.6911 - val_loss: 0.9228 - val_acc: 0.9457 - val_mDice: 0.5562

Epoch 00025: val_mDice did not improve from 0.58395
Epoch 26/300
 - 10s - loss: 0.3465 - acc: 0.9367 - mDice: 0.6935 - val_loss: 0.9499 - val_acc: 0.9446 - val_mDice: 0.5584

Epoch 00026: val_mDice did not improve from 0.58395
Epoch 27/300
 - 9s - loss: 0.3436 - acc: 0.9381 - mDice: 0.6950 - val_loss: 0.9345 - val_acc: 0.9405 - val_mDice: 0.5747

Epoch 00027: val_mDice did not improve from 0.58395
Epoch 28/300
 - 9s - loss: 0.3419 - acc: 0.9385 - mDice: 0.6961 - val_loss: 0.9326 - val_acc: 0.9448 - val_mDice: 0.5503

Epoch 00028: val_mDice did not improve from 0.58395
Epoch 29/300
 - 10s - loss: 0.3393 - acc: 0.9387 - mDice: 0.6980 - val_loss: 0.9635 - val_acc: 0.9428 - val_mDice: 0.5337

Epoch 00029: val_mDice did not improve from 0.58395
Epoch 30/300
 - 9s - loss: 0.3384 - acc: 0.9388 - mDice: 0.6985 - val_loss: 0.9115 - val_acc: 0.9447 - val_mDice: 0.5736

Epoch 00030: val_mDice did not improve from 0.58395
Epoch 31/300
 - 10s - loss: 0.3383 - acc: 0.9389 - mDice: 0.6985 - val_loss: 0.9332 - val_acc: 0.9320 - val_mDice: 0.5539

Epoch 00031: val_mDice did not improve from 0.58395
Epoch 32/300
 - 9s - loss: 0.3356 - acc: 0.9392 - mDice: 0.7006 - val_loss: 0.8945 - val_acc: 0.9445 - val_mDice: 0.5775

Epoch 00032: val_mDice did not improve from 0.58395
Epoch 33/300
 - 10s - loss: 0.3326 - acc: 0.9395 - mDice: 0.7027 - val_loss: 0.9333 - val_acc: 0.9379 - val_mDice: 0.5662

Epoch 00033: val_mDice did not improve from 0.58395
Epoch 34/300
 - 10s - loss: 0.3319 - acc: 0.9396 - mDice: 0.7032 - val_loss: 0.8838 - val_acc: 0.9448 - val_mDice: 0.5808

Epoch 00034: val_mDice did not improve from 0.58395
Epoch 35/300
 - 10s - loss: 0.3290 - acc: 0.9398 - mDice: 0.7053 - val_loss: 0.9528 - val_acc: 0.9440 - val_mDice: 0.5505

Epoch 00035: val_mDice did not improve from 0.58395
Epoch 36/300
 - 11s - loss: 0.3284 - acc: 0.9398 - mDice: 0.7057 - val_loss: 1.0106 - val_acc: 0.9390 - val_mDice: 0.4839

Epoch 00036: val_mDice did not improve from 0.58395
Epoch 37/300
 - 9s - loss: 0.3268 - acc: 0.9402 - mDice: 0.7069 - val_loss: 0.9178 - val_acc: 0.9371 - val_mDice: 0.5564

Epoch 00037: val_mDice did not improve from 0.58395
Epoch 38/300
 - 10s - loss: 0.3262 - acc: 0.9403 - mDice: 0.7074 - val_loss: 0.9624 - val_acc: 0.9375 - val_mDice: 0.5537

Epoch 00038: val_mDice did not improve from 0.58395
Epoch 39/300
 - 9s - loss: 0.3237 - acc: 0.9405 - mDice: 0.7092 - val_loss: 0.8902 - val_acc: 0.9456 - val_mDice: 0.5796

Epoch 00039: val_mDice did not improve from 0.58395
Epoch 40/300
 - 10s - loss: 0.3234 - acc: 0.9404 - mDice: 0.7094 - val_loss: 0.9357 - val_acc: 0.9427 - val_mDice: 0.5647

Epoch 00040: val_mDice did not improve from 0.58395
Epoch 41/300
 - 9s - loss: 0.3206 - acc: 0.9406 - mDice: 0.7114 - val_loss: 0.9329 - val_acc: 0.9411 - val_mDice: 0.5483

Epoch 00041: val_mDice did not improve from 0.58395
Epoch 42/300
 - 10s - loss: 0.3212 - acc: 0.9408 - mDice: 0.7111 - val_loss: 0.9107 - val_acc: 0.9373 - val_mDice: 0.5555

Epoch 00042: val_mDice did not improve from 0.58395
Epoch 43/300
 - 9s - loss: 0.3198 - acc: 0.9408 - mDice: 0.7119 - val_loss: 0.8727 - val_acc: 0.9446 - val_mDice: 0.5562

Epoch 00043: val_mDice did not improve from 0.58395
Epoch 44/300
 - 8s - loss: 0.3171 - acc: 0.9410 - mDice: 0.7140 - val_loss: 0.9948 - val_acc: 0.9414 - val_mDice: 0.5093

Epoch 00044: val_mDice did not improve from 0.58395
Epoch 45/300
 - 9s - loss: 0.3159 - acc: 0.9413 - mDice: 0.7149 - val_loss: 0.9350 - val_acc: 0.9450 - val_mDice: 0.5628

Epoch 00045: val_mDice did not improve from 0.58395
Epoch 46/300
 - 8s - loss: 0.3146 - acc: 0.9413 - mDice: 0.7158 - val_loss: 0.9074 - val_acc: 0.9450 - val_mDice: 0.5518

Epoch 00046: val_mDice did not improve from 0.58395
Epoch 47/300
 - 8s - loss: 0.3140 - acc: 0.9415 - mDice: 0.7163 - val_loss: 0.9047 - val_acc: 0.9438 - val_mDice: 0.5424

Epoch 00047: val_mDice did not improve from 0.58395
Epoch 48/300
 - 9s - loss: 0.3116 - acc: 0.9417 - mDice: 0.7180 - val_loss: 0.9396 - val_acc: 0.9318 - val_mDice: 0.5497

Epoch 00048: val_mDice did not improve from 0.58395
Epoch 49/300
 - 8s - loss: 0.3128 - acc: 0.9417 - mDice: 0.7171 - val_loss: 0.9822 - val_acc: 0.9369 - val_mDice: 0.5305

Epoch 00049: val_mDice did not improve from 0.58395
Epoch 50/300
 - 8s - loss: 0.3114 - acc: 0.9419 - mDice: 0.7182 - val_loss: 0.8839 - val_acc: 0.9446 - val_mDice: 0.5724

Epoch 00050: val_mDice did not improve from 0.58395
Epoch 51/300
 - 9s - loss: 0.3100 - acc: 0.9419 - mDice: 0.7192 - val_loss: 0.8490 - val_acc: 0.9443 - val_mDice: 0.5586

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.13s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.96s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.80s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:45,  1.85s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:58,  1.69s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:56,  1.69s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:27,  1.59s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:44,  1.66s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:26,  1.60s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:44,  1.67s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:31,  1.63s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:54,  1.72s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:08,  1.78s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<07:39,  1.68s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:05,  1.78s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:44,  1.71s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<07:47,  1.73s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<07:58,  1.77s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<08:16,  1.85s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<07:49,  1.75s/it]predicting train subjects:   6%|▋         | 18/285 [00:30<07:51,  1.77s/it]predicting train subjects:   7%|▋         | 19/285 [00:32<07:32,  1.70s/it]predicting train subjects:   7%|▋         | 20/285 [00:34<07:46,  1.76s/it]predicting train subjects:   7%|▋         | 21/285 [00:36<08:03,  1.83s/it]predicting train subjects:   8%|▊         | 22/285 [00:37<07:45,  1.77s/it]predicting train subjects:   8%|▊         | 23/285 [00:39<07:52,  1.80s/it]predicting train subjects:   8%|▊         | 24/285 [00:41<07:27,  1.72s/it]predicting train subjects:   9%|▉         | 25/285 [00:43<07:41,  1.78s/it]predicting train subjects:   9%|▉         | 26/285 [00:45<07:55,  1.83s/it]predicting train subjects:   9%|▉         | 27/285 [00:46<07:29,  1.74s/it]predicting train subjects:  10%|▉         | 28/285 [00:48<07:37,  1.78s/it]predicting train subjects:  10%|█         | 29/285 [00:50<07:36,  1.78s/it]predicting train subjects:  11%|█         | 30/285 [00:52<07:43,  1.82s/it]predicting train subjects:  11%|█         | 31/285 [00:54<07:56,  1.88s/it]predicting train subjects:  11%|█         | 32/285 [00:55<07:29,  1.78s/it]predicting train subjects:  12%|█▏        | 33/285 [00:57<07:32,  1.80s/it]predicting train subjects:  12%|█▏        | 34/285 [00:59<07:44,  1.85s/it]predicting train subjects:  12%|█▏        | 35/285 [01:01<07:52,  1.89s/it]predicting train subjects:  13%|█▎        | 36/285 [01:03<07:33,  1.82s/it]predicting train subjects:  13%|█▎        | 37/285 [01:04<07:32,  1.83s/it]predicting train subjects:  13%|█▎        | 38/285 [01:06<07:38,  1.85s/it]predicting train subjects:  14%|█▎        | 39/285 [01:08<07:14,  1.77s/it]predicting train subjects:  14%|█▍        | 40/285 [01:10<07:14,  1.77s/it]predicting train subjects:  14%|█▍        | 41/285 [01:11<06:55,  1.70s/it]predicting train subjects:  15%|█▍        | 42/285 [01:13<06:47,  1.68s/it]predicting train subjects:  15%|█▌        | 43/285 [01:15<07:01,  1.74s/it]predicting train subjects:  15%|█▌        | 44/285 [01:17<07:12,  1.80s/it]predicting train subjects:  16%|█▌        | 45/285 [01:18<06:54,  1.73s/it]predicting train subjects:  16%|█▌        | 46/285 [01:20<07:08,  1.79s/it]predicting train subjects:  16%|█▋        | 47/285 [01:22<06:49,  1.72s/it]predicting train subjects:  17%|█▋        | 48/285 [01:24<06:51,  1.74s/it]predicting train subjects:  17%|█▋        | 49/285 [01:26<07:06,  1.81s/it]predicting train subjects:  18%|█▊        | 50/285 [01:27<07:09,  1.83s/it]predicting train subjects:  18%|█▊        | 51/285 [01:30<07:26,  1.91s/it]predicting train subjects:  18%|█▊        | 52/285 [01:31<07:04,  1.82s/it]predicting train subjects:  19%|█▊        | 53/285 [01:33<07:05,  1.84s/it]predicting train subjects:  19%|█▉        | 54/285 [01:35<07:11,  1.87s/it]predicting train subjects:  19%|█▉        | 55/285 [01:36<06:46,  1.77s/it]predicting train subjects:  20%|█▉        | 56/285 [01:38<06:51,  1.80s/it]predicting train subjects:  20%|██        | 57/285 [01:40<06:31,  1.72s/it]predicting train subjects:  20%|██        | 58/285 [01:42<06:36,  1.75s/it]predicting train subjects:  21%|██        | 59/285 [01:44<06:48,  1.81s/it]predicting train subjects:  21%|██        | 60/285 [01:46<06:56,  1.85s/it]predicting train subjects:  21%|██▏       | 61/285 [01:47<06:37,  1.77s/it]predicting train subjects:  22%|██▏       | 62/285 [01:49<06:41,  1.80s/it]predicting train subjects:  22%|██▏       | 63/285 [01:51<06:40,  1.80s/it]predicting train subjects:  22%|██▏       | 64/285 [01:53<06:28,  1.76s/it]predicting train subjects:  23%|██▎       | 65/285 [01:54<06:33,  1.79s/it]predicting train subjects:  23%|██▎       | 66/285 [01:56<06:34,  1.80s/it]predicting train subjects:  24%|██▎       | 67/285 [01:58<06:37,  1.82s/it]predicting train subjects:  24%|██▍       | 68/285 [02:00<06:20,  1.75s/it]predicting train subjects:  24%|██▍       | 69/285 [02:01<06:18,  1.75s/it]predicting train subjects:  25%|██▍       | 70/285 [02:03<06:19,  1.76s/it]predicting train subjects:  25%|██▍       | 71/285 [02:05<06:22,  1.79s/it]predicting train subjects:  25%|██▌       | 72/285 [02:07<06:06,  1.72s/it]predicting train subjects:  26%|██▌       | 73/285 [02:08<06:04,  1.72s/it]predicting train subjects:  26%|██▌       | 74/285 [02:10<06:06,  1.74s/it]predicting train subjects:  26%|██▋       | 75/285 [02:12<06:11,  1.77s/it]predicting train subjects:  27%|██▋       | 76/285 [02:14<06:17,  1.80s/it]predicting train subjects:  27%|██▋       | 77/285 [02:15<06:02,  1.74s/it]predicting train subjects:  27%|██▋       | 78/285 [02:17<05:52,  1.70s/it]predicting train subjects:  28%|██▊       | 79/285 [02:19<05:54,  1.72s/it]predicting train subjects:  28%|██▊       | 80/285 [02:21<05:57,  1.74s/it]predicting train subjects:  28%|██▊       | 81/285 [02:22<05:47,  1.70s/it]predicting train subjects:  29%|██▉       | 82/285 [02:24<05:51,  1.73s/it]predicting train subjects:  29%|██▉       | 83/285 [02:26<05:45,  1.71s/it]predicting train subjects:  29%|██▉       | 84/285 [02:27<05:40,  1.70s/it]predicting train subjects:  30%|██▉       | 85/285 [02:29<05:45,  1.73s/it]predicting train subjects:  30%|███       | 86/285 [02:31<05:53,  1.78s/it]predicting train subjects:  31%|███       | 87/285 [02:33<05:55,  1.80s/it]predicting train subjects:  31%|███       | 88/285 [02:34<05:41,  1.73s/it]predicting train subjects:  31%|███       | 89/285 [02:36<05:40,  1.74s/it]predicting train subjects:  32%|███▏      | 90/285 [02:38<05:44,  1.77s/it]predicting train subjects:  32%|███▏      | 91/285 [02:40<05:35,  1.73s/it]predicting train subjects:  32%|███▏      | 92/285 [02:42<05:40,  1.76s/it]predicting train subjects:  33%|███▎      | 93/285 [02:43<05:29,  1.71s/it]predicting train subjects:  33%|███▎      | 94/285 [02:45<05:30,  1.73s/it]predicting train subjects:  33%|███▎      | 95/285 [02:47<05:42,  1.80s/it]predicting train subjects:  34%|███▎      | 96/285 [02:49<05:43,  1.82s/it]predicting train subjects:  34%|███▍      | 97/285 [02:51<05:44,  1.83s/it]predicting train subjects:  34%|███▍      | 98/285 [02:52<05:39,  1.82s/it]predicting train subjects:  35%|███▍      | 99/285 [02:54<05:34,  1.80s/it]predicting train subjects:  35%|███▌      | 100/285 [02:56<05:34,  1.81s/it]predicting train subjects:  35%|███▌      | 101/285 [02:58<05:23,  1.76s/it]predicting train subjects:  36%|███▌      | 102/285 [02:59<05:27,  1.79s/it]predicting train subjects:  36%|███▌      | 103/285 [03:01<05:15,  1.73s/it]predicting train subjects:  36%|███▋      | 104/285 [03:03<05:17,  1.76s/it]predicting train subjects:  37%|███▋      | 105/285 [03:05<05:22,  1.79s/it]predicting train subjects:  37%|███▋      | 106/285 [03:06<05:12,  1.75s/it]predicting train subjects:  38%|███▊      | 107/285 [03:08<05:13,  1.76s/it]predicting train subjects:  38%|███▊      | 108/285 [03:10<05:01,  1.70s/it]predicting train subjects:  38%|███▊      | 109/285 [03:12<05:04,  1.73s/it]predicting train subjects:  39%|███▊      | 110/285 [03:13<05:13,  1.79s/it]predicting train subjects:  39%|███▉      | 111/285 [03:15<05:02,  1.74s/it]predicting train subjects:  39%|███▉      | 112/285 [03:17<05:06,  1.77s/it]predicting train subjects:  40%|███▉      | 113/285 [03:19<05:05,  1.78s/it]predicting train subjects:  40%|████      | 114/285 [03:20<05:01,  1.76s/it]predicting train subjects:  40%|████      | 115/285 [03:22<05:00,  1.77s/it]predicting train subjects:  41%|████      | 116/285 [03:24<05:03,  1.80s/it]predicting train subjects:  41%|████      | 117/285 [03:26<04:53,  1.75s/it]predicting train subjects:  41%|████▏     | 118/285 [03:27<04:43,  1.70s/it]predicting train subjects:  42%|████▏     | 119/285 [03:29<04:48,  1.74s/it]predicting train subjects:  42%|████▏     | 120/285 [03:31<04:44,  1.72s/it]predicting train subjects:  42%|████▏     | 121/285 [03:32<04:34,  1.67s/it]predicting train subjects:  43%|████▎     | 122/285 [03:34<04:25,  1.63s/it]predicting train subjects:  43%|████▎     | 123/285 [03:35<04:14,  1.57s/it]predicting train subjects:  44%|████▎     | 124/285 [03:37<04:15,  1.59s/it]predicting train subjects:  44%|████▍     | 125/285 [03:38<04:10,  1.57s/it]predicting train subjects:  44%|████▍     | 126/285 [03:40<04:06,  1.55s/it]predicting train subjects:  45%|████▍     | 127/285 [03:41<03:58,  1.51s/it]predicting train subjects:  45%|████▍     | 128/285 [03:43<04:00,  1.53s/it]predicting train subjects:  45%|████▌     | 129/285 [03:45<03:57,  1.52s/it]predicting train subjects:  46%|████▌     | 130/285 [03:46<03:52,  1.50s/it]predicting train subjects:  46%|████▌     | 131/285 [03:47<03:49,  1.49s/it]predicting train subjects:  46%|████▋     | 132/285 [03:49<03:50,  1.51s/it]predicting train subjects:  47%|████▋     | 133/285 [03:50<03:47,  1.49s/it]predicting train subjects:  47%|████▋     | 134/285 [03:52<03:42,  1.47s/it]predicting train subjects:  47%|████▋     | 135/285 [03:53<03:39,  1.46s/it]predicting train subjects:  48%|████▊     | 136/285 [03:55<03:37,  1.46s/it]predicting train subjects:  48%|████▊     | 137/285 [03:56<03:41,  1.50s/it]predicting train subjects:  48%|████▊     | 138/285 [03:58<03:36,  1.47s/it]predicting train subjects:  49%|████▉     | 139/285 [03:59<03:39,  1.50s/it]predicting train subjects:  49%|████▉     | 140/285 [04:01<03:40,  1.52s/it]predicting train subjects:  49%|████▉     | 141/285 [04:02<03:32,  1.48s/it]predicting train subjects:  50%|████▉     | 142/285 [04:04<03:28,  1.46s/it]predicting train subjects:  50%|█████     | 143/285 [04:05<03:23,  1.44s/it]predicting train subjects:  51%|█████     | 144/285 [04:07<03:31,  1.50s/it]predicting train subjects:  51%|█████     | 145/285 [04:08<03:27,  1.48s/it]predicting train subjects:  51%|█████     | 146/285 [04:10<03:30,  1.51s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:11<03:23,  1.48s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:13<03:23,  1.49s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:14<03:22,  1.49s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:16<03:20,  1.48s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:17<03:24,  1.53s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:19<03:17,  1.49s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:20<03:14,  1.48s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:22<03:16,  1.50s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:23<03:13,  1.49s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:25<03:18,  1.54s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:26<03:11,  1.49s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:28<03:11,  1.51s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:29<03:05,  1.47s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:30<03:02,  1.46s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:32<03:04,  1.49s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:33<02:57,  1.45s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:35<02:59,  1.47s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:36<02:58,  1.47s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:38<02:55,  1.46s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:39<02:57,  1.49s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:41<02:57,  1.50s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:42<02:49,  1.45s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:44<02:47,  1.44s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:45<02:43,  1.42s/it]predicting train subjects:  60%|██████    | 171/285 [04:46<02:41,  1.42s/it]predicting train subjects:  60%|██████    | 172/285 [04:48<02:43,  1.45s/it]predicting train subjects:  61%|██████    | 173/285 [04:49<02:42,  1.45s/it]predicting train subjects:  61%|██████    | 174/285 [04:51<02:37,  1.42s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:52<02:42,  1.48s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:54<02:45,  1.52s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:55<02:39,  1.48s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:57<02:33,  1.44s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:58<02:30,  1.42s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:00<02:40,  1.53s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:02<02:41,  1.56s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:03<02:45,  1.61s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:05<02:39,  1.56s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:06<02:34,  1.53s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:08<02:29,  1.49s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:09<02:38,  1.61s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:11<02:46,  1.70s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:13<02:48,  1.74s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:14<02:34,  1.61s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:16<02:28,  1.56s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:18<02:27,  1.57s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:19<02:27,  1.58s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:20<02:18,  1.51s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:22<02:13,  1.47s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:23<02:08,  1.43s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:25<02:16,  1.54s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:27<02:22,  1.62s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:29<02:26,  1.68s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:30<02:18,  1.61s/it]predicting train subjects:  70%|███████   | 200/285 [05:31<02:12,  1.56s/it]predicting train subjects:  71%|███████   | 201/285 [05:33<02:15,  1.62s/it]predicting train subjects:  71%|███████   | 202/285 [05:35<02:14,  1.62s/it]predicting train subjects:  71%|███████   | 203/285 [05:37<02:13,  1.63s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:38<02:07,  1.57s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:39<02:02,  1.53s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:41<01:57,  1.49s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:43<02:05,  1.61s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:44<02:07,  1.66s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:46<02:09,  1.71s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:48<01:58,  1.58s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:49<01:53,  1.53s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:51<01:54,  1.56s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:52<01:52,  1.56s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:54<01:47,  1.51s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:55<01:51,  1.60s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:57<01:45,  1.52s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:59<01:49,  1.61s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:00<01:52,  1.67s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:02<01:53,  1.71s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:04<01:44,  1.60s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:05<01:40,  1.56s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:07<01:38,  1.57s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:08<01:33,  1.51s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:09<01:30,  1.49s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:11<01:26,  1.45s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:13<01:32,  1.58s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:14<01:36,  1.67s/it]predicting train subjects:  80%|████████  | 228/285 [06:16<01:35,  1.68s/it]predicting train subjects:  80%|████████  | 229/285 [06:18<01:32,  1.64s/it]predicting train subjects:  81%|████████  | 230/285 [06:19<01:24,  1.54s/it]predicting train subjects:  81%|████████  | 231/285 [06:20<01:21,  1.51s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:22<01:21,  1.53s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:24<01:18,  1.51s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:25<01:21,  1.59s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:27<01:17,  1.54s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:29<01:20,  1.64s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:30<01:22,  1.71s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:32<01:21,  1.73s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:34<01:18,  1.70s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:35<01:12,  1.61s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:37<01:08,  1.57s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:38<01:04,  1.51s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:40<01:01,  1.48s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:41<01:04,  1.57s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:43<00:59,  1.50s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:44<01:01,  1.59s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:46<01:03,  1.67s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:48<01:01,  1.65s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:49<00:56,  1.56s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:51<00:53,  1.52s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:52<00:50,  1.47s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:53<00:47,  1.43s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:55<00:49,  1.56s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:57<00:50,  1.61s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:59<00:48,  1.60s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:00<00:44,  1.52s/it]predicting train subjects:  90%|█████████ | 257/285 [07:01<00:41,  1.48s/it]predicting train subjects:  91%|█████████ | 258/285 [07:03<00:42,  1.58s/it]predicting train subjects:  91%|█████████ | 259/285 [07:05<00:41,  1.60s/it]predicting train subjects:  91%|█████████ | 260/285 [07:06<00:37,  1.52s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:07<00:35,  1.49s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:09<00:33,  1.46s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:10<00:31,  1.43s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:12<00:32,  1.54s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:14<00:32,  1.60s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:15<00:28,  1.53s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:17<00:26,  1.48s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:18<00:26,  1.57s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:20<00:25,  1.58s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:21<00:22,  1.52s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:23<00:20,  1.48s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:24<00:19,  1.53s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:26<00:17,  1.47s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:27<00:16,  1.47s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:29<00:16,  1.61s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:31<00:15,  1.69s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:32<00:12,  1.58s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:34<00:10,  1.54s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:36<00:10,  1.67s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:37<00:08,  1.63s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:39<00:06,  1.61s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:40<00:04,  1.58s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:42<00:03,  1.70s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:44<00:01,  1.73s/it]predicting train subjects: 100%|██████████| 285/285 [07:46<00:00,  1.77s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:02<10:37,  2.24s/it]Loading train:   1%|          | 2/285 [00:03<09:33,  2.03s/it]Loading train:   1%|          | 3/285 [00:05<09:31,  2.03s/it]Loading train:   1%|▏         | 4/285 [00:07<08:57,  1.91s/it]Loading train:   2%|▏         | 5/285 [00:09<08:52,  1.90s/it]Loading train:   2%|▏         | 6/285 [00:10<08:08,  1.75s/it]Loading train:   2%|▏         | 7/285 [00:12<08:13,  1.77s/it]Loading train:   3%|▎         | 8/285 [00:14<07:57,  1.72s/it]Loading train:   3%|▎         | 9/285 [00:16<08:17,  1.80s/it]Loading train:   4%|▎         | 10/285 [00:17<07:45,  1.69s/it]Loading train:   4%|▍         | 11/285 [00:18<06:55,  1.52s/it]Loading train:   4%|▍         | 12/285 [00:20<07:20,  1.61s/it]Loading train:   5%|▍         | 13/285 [00:21<06:38,  1.47s/it]Loading train:   5%|▍         | 14/285 [00:23<06:29,  1.44s/it]Loading train:   5%|▌         | 15/285 [00:24<06:39,  1.48s/it]Loading train:   6%|▌         | 16/285 [00:26<06:37,  1.48s/it]Loading train:   6%|▌         | 17/285 [00:27<06:17,  1.41s/it]Loading train:   6%|▋         | 18/285 [00:28<06:11,  1.39s/it]Loading train:   7%|▋         | 19/285 [00:29<06:02,  1.36s/it]Loading train:   7%|▋         | 20/285 [00:31<06:22,  1.44s/it]Loading train:   7%|▋         | 21/285 [00:33<06:28,  1.47s/it]Loading train:   8%|▊         | 22/285 [00:34<05:53,  1.34s/it]Loading train:   8%|▊         | 23/285 [00:35<06:21,  1.46s/it]Loading train:   8%|▊         | 24/285 [00:37<06:21,  1.46s/it]Loading train:   9%|▉         | 25/285 [00:38<06:17,  1.45s/it]Loading train:   9%|▉         | 26/285 [00:40<06:33,  1.52s/it]Loading train:   9%|▉         | 27/285 [00:41<06:07,  1.43s/it]Loading train:  10%|▉         | 28/285 [00:42<05:52,  1.37s/it]Loading train:  10%|█         | 29/285 [00:44<06:10,  1.45s/it]Loading train:  11%|█         | 30/285 [00:46<06:41,  1.57s/it]Loading train:  11%|█         | 31/285 [00:47<06:22,  1.51s/it]Loading train:  11%|█         | 32/285 [00:48<05:52,  1.39s/it]Loading train:  12%|█▏        | 33/285 [00:50<05:41,  1.36s/it]Loading train:  12%|█▏        | 34/285 [00:51<05:59,  1.43s/it]Loading train:  12%|█▏        | 35/285 [00:53<06:20,  1.52s/it]Loading train:  13%|█▎        | 36/285 [00:54<06:13,  1.50s/it]Loading train:  13%|█▎        | 37/285 [00:56<06:24,  1.55s/it]Loading train:  13%|█▎        | 38/285 [00:58<06:33,  1.59s/it]Loading train:  14%|█▎        | 39/285 [00:59<06:02,  1.47s/it]Loading train:  14%|█▍        | 40/285 [01:00<05:43,  1.40s/it]Loading train:  14%|█▍        | 41/285 [01:01<05:31,  1.36s/it]Loading train:  15%|█▍        | 42/285 [01:03<05:29,  1.36s/it]Loading train:  15%|█▌        | 43/285 [01:04<05:32,  1.38s/it]Loading train:  15%|█▌        | 44/285 [01:06<05:52,  1.46s/it]Loading train:  16%|█▌        | 45/285 [01:07<05:48,  1.45s/it]Loading train:  16%|█▌        | 46/285 [01:09<06:00,  1.51s/it]Loading train:  16%|█▋        | 47/285 [01:10<05:53,  1.48s/it]Loading train:  17%|█▋        | 48/285 [01:12<06:11,  1.57s/it]Loading train:  17%|█▋        | 49/285 [01:14<06:07,  1.56s/it]Loading train:  18%|█▊        | 50/285 [01:15<05:57,  1.52s/it]Loading train:  18%|█▊        | 51/285 [01:17<06:04,  1.56s/it]Loading train:  18%|█▊        | 52/285 [01:18<05:43,  1.47s/it]Loading train:  19%|█▊        | 53/285 [01:19<05:32,  1.43s/it]Loading train:  19%|█▉        | 54/285 [01:21<05:39,  1.47s/it]Loading train:  19%|█▉        | 55/285 [01:23<05:52,  1.53s/it]Loading train:  20%|█▉        | 56/285 [01:24<05:44,  1.50s/it]Loading train:  20%|██        | 57/285 [01:25<05:28,  1.44s/it]Loading train:  20%|██        | 58/285 [01:27<05:28,  1.45s/it]Loading train:  21%|██        | 59/285 [01:28<05:36,  1.49s/it]Loading train:  21%|██        | 60/285 [01:30<05:37,  1.50s/it]Loading train:  21%|██▏       | 61/285 [01:31<05:17,  1.42s/it]Loading train:  22%|██▏       | 62/285 [01:32<05:08,  1.38s/it]Loading train:  22%|██▏       | 63/285 [01:34<04:54,  1.33s/it]Loading train:  22%|██▏       | 64/285 [01:35<05:11,  1.41s/it]Loading train:  23%|██▎       | 65/285 [01:37<05:33,  1.51s/it]Loading train:  23%|██▎       | 66/285 [01:39<06:00,  1.65s/it]Loading train:  24%|██▎       | 67/285 [01:40<05:38,  1.55s/it]Loading train:  24%|██▍       | 68/285 [01:42<05:27,  1.51s/it]Loading train:  24%|██▍       | 69/285 [01:43<05:18,  1.47s/it]Loading train:  25%|██▍       | 70/285 [01:44<05:08,  1.43s/it]Loading train:  25%|██▍       | 71/285 [01:46<05:02,  1.41s/it]Loading train:  25%|██▌       | 72/285 [01:47<05:00,  1.41s/it]Loading train:  26%|██▌       | 73/285 [01:49<04:58,  1.41s/it]Loading train:  26%|██▌       | 74/285 [01:50<04:57,  1.41s/it]Loading train:  26%|██▋       | 75/285 [01:52<05:21,  1.53s/it]Loading train:  27%|██▋       | 76/285 [01:53<05:09,  1.48s/it]Loading train:  27%|██▋       | 77/285 [01:55<05:00,  1.45s/it]Loading train:  27%|██▋       | 78/285 [01:56<04:46,  1.39s/it]Loading train:  28%|██▊       | 79/285 [01:57<04:38,  1.35s/it]Loading train:  28%|██▊       | 80/285 [01:59<04:42,  1.38s/it]Loading train:  28%|██▊       | 81/285 [02:00<04:45,  1.40s/it]Loading train:  29%|██▉       | 82/285 [02:01<04:30,  1.33s/it]Loading train:  29%|██▉       | 83/285 [02:02<04:24,  1.31s/it]Loading train:  29%|██▉       | 84/285 [02:04<04:19,  1.29s/it]Loading train:  30%|██▉       | 85/285 [02:05<04:15,  1.28s/it]Loading train:  30%|███       | 86/285 [02:06<04:17,  1.29s/it]Loading train:  31%|███       | 87/285 [02:08<04:25,  1.34s/it]Loading train:  31%|███       | 88/285 [02:09<04:27,  1.36s/it]Loading train:  31%|███       | 89/285 [02:11<04:37,  1.41s/it]Loading train:  32%|███▏      | 90/285 [02:12<04:22,  1.35s/it]Loading train:  32%|███▏      | 91/285 [02:13<04:35,  1.42s/it]Loading train:  32%|███▏      | 92/285 [02:15<05:02,  1.57s/it]Loading train:  33%|███▎      | 93/285 [02:17<04:51,  1.52s/it]Loading train:  33%|███▎      | 94/285 [02:18<04:34,  1.44s/it]Loading train:  33%|███▎      | 95/285 [02:19<04:31,  1.43s/it]Loading train:  34%|███▎      | 96/285 [02:21<04:32,  1.44s/it]Loading train:  34%|███▍      | 97/285 [02:22<04:33,  1.45s/it]Loading train:  34%|███▍      | 98/285 [02:24<04:24,  1.41s/it]Loading train:  35%|███▍      | 99/285 [02:25<04:13,  1.36s/it]Loading train:  35%|███▌      | 100/285 [02:26<04:07,  1.34s/it]Loading train:  35%|███▌      | 101/285 [02:27<04:01,  1.31s/it]Loading train:  36%|███▌      | 102/285 [02:29<04:08,  1.36s/it]Loading train:  36%|███▌      | 103/285 [02:30<04:07,  1.36s/it]Loading train:  36%|███▋      | 104/285 [02:32<03:59,  1.33s/it]Loading train:  37%|███▋      | 105/285 [02:33<04:04,  1.36s/it]Loading train:  37%|███▋      | 106/285 [02:34<04:01,  1.35s/it]Loading train:  38%|███▊      | 107/285 [02:36<04:04,  1.38s/it]Loading train:  38%|███▊      | 108/285 [02:37<04:04,  1.38s/it]Loading train:  38%|███▊      | 109/285 [02:38<03:59,  1.36s/it]Loading train:  39%|███▊      | 110/285 [02:40<04:00,  1.37s/it]Loading train:  39%|███▉      | 111/285 [02:41<04:08,  1.43s/it]Loading train:  39%|███▉      | 112/285 [02:43<04:07,  1.43s/it]Loading train:  40%|███▉      | 113/285 [02:44<04:00,  1.40s/it]Loading train:  40%|████      | 114/285 [02:45<03:51,  1.35s/it]Loading train:  40%|████      | 115/285 [02:47<03:45,  1.33s/it]Loading train:  41%|████      | 116/285 [02:48<03:49,  1.36s/it]Loading train:  41%|████      | 117/285 [02:49<03:43,  1.33s/it]Loading train:  41%|████▏     | 118/285 [02:51<03:52,  1.39s/it]Loading train:  42%|████▏     | 119/285 [02:52<04:00,  1.45s/it]Loading train:  42%|████▏     | 120/285 [02:54<03:50,  1.40s/it]Loading train:  42%|████▏     | 121/285 [02:55<03:55,  1.44s/it]Loading train:  43%|████▎     | 122/285 [02:57<03:52,  1.43s/it]Loading train:  43%|████▎     | 123/285 [02:58<03:48,  1.41s/it]Loading train:  44%|████▎     | 124/285 [03:00<03:52,  1.44s/it]Loading train:  44%|████▍     | 125/285 [03:01<03:50,  1.44s/it]Loading train:  44%|████▍     | 126/285 [03:02<03:38,  1.37s/it]Loading train:  45%|████▍     | 127/285 [03:04<03:34,  1.36s/it]Loading train:  45%|████▍     | 128/285 [03:05<03:25,  1.31s/it]Loading train:  45%|████▌     | 129/285 [03:06<03:20,  1.28s/it]Loading train:  46%|████▌     | 130/285 [03:07<03:10,  1.23s/it]Loading train:  46%|████▌     | 131/285 [03:08<03:14,  1.27s/it]Loading train:  46%|████▋     | 132/285 [03:10<03:13,  1.27s/it]Loading train:  47%|████▋     | 133/285 [03:11<03:04,  1.21s/it]Loading train:  47%|████▋     | 134/285 [03:12<03:05,  1.23s/it]Loading train:  47%|████▋     | 135/285 [03:13<02:58,  1.19s/it]Loading train:  48%|████▊     | 136/285 [03:14<02:54,  1.17s/it]Loading train:  48%|████▊     | 137/285 [03:15<02:54,  1.18s/it]Loading train:  48%|████▊     | 138/285 [03:17<02:46,  1.13s/it]Loading train:  49%|████▉     | 139/285 [03:18<02:44,  1.13s/it]Loading train:  49%|████▉     | 140/285 [03:19<02:45,  1.14s/it]Loading train:  49%|████▉     | 141/285 [03:20<02:40,  1.11s/it]Loading train:  50%|████▉     | 142/285 [03:21<02:39,  1.12s/it]Loading train:  50%|█████     | 143/285 [03:22<02:32,  1.07s/it]Loading train:  51%|█████     | 144/285 [03:23<02:34,  1.10s/it]Loading train:  51%|█████     | 145/285 [03:24<02:35,  1.11s/it]Loading train:  51%|█████     | 146/285 [03:25<02:35,  1.12s/it]Loading train:  52%|█████▏    | 147/285 [03:27<02:37,  1.14s/it]Loading train:  52%|█████▏    | 148/285 [03:28<02:47,  1.22s/it]Loading train:  52%|█████▏    | 149/285 [03:29<02:45,  1.21s/it]Loading train:  53%|█████▎    | 150/285 [03:30<02:46,  1.23s/it]Loading train:  53%|█████▎    | 151/285 [03:32<02:51,  1.28s/it]Loading train:  53%|█████▎    | 152/285 [03:33<02:49,  1.28s/it]Loading train:  54%|█████▎    | 153/285 [03:34<02:42,  1.23s/it]Loading train:  54%|█████▍    | 154/285 [03:35<02:39,  1.21s/it]Loading train:  54%|█████▍    | 155/285 [03:37<02:36,  1.21s/it]Loading train:  55%|█████▍    | 156/285 [03:38<02:30,  1.16s/it]Loading train:  55%|█████▌    | 157/285 [03:39<02:25,  1.14s/it]Loading train:  55%|█████▌    | 158/285 [03:40<02:21,  1.11s/it]Loading train:  56%|█████▌    | 159/285 [03:41<02:22,  1.13s/it]Loading train:  56%|█████▌    | 160/285 [03:42<02:28,  1.19s/it]Loading train:  56%|█████▋    | 161/285 [03:44<02:30,  1.21s/it]Loading train:  57%|█████▋    | 162/285 [03:45<02:29,  1.21s/it]Loading train:  57%|█████▋    | 163/285 [03:46<02:28,  1.22s/it]Loading train:  58%|█████▊    | 164/285 [03:47<02:28,  1.23s/it]Loading train:  58%|█████▊    | 165/285 [03:48<02:25,  1.21s/it]Loading train:  58%|█████▊    | 166/285 [03:50<02:26,  1.23s/it]Loading train:  59%|█████▊    | 167/285 [03:51<02:24,  1.23s/it]Loading train:  59%|█████▉    | 168/285 [03:52<02:20,  1.20s/it]Loading train:  59%|█████▉    | 169/285 [03:53<02:21,  1.22s/it]Loading train:  60%|█████▉    | 170/285 [03:54<02:15,  1.18s/it]Loading train:  60%|██████    | 171/285 [03:55<02:09,  1.14s/it]Loading train:  60%|██████    | 172/285 [03:57<02:27,  1.31s/it]Loading train:  61%|██████    | 173/285 [03:58<02:26,  1.31s/it]Loading train:  61%|██████    | 174/285 [04:00<02:33,  1.38s/it]Loading train:  61%|██████▏   | 175/285 [04:02<02:37,  1.43s/it]Loading train:  62%|██████▏   | 176/285 [04:03<02:30,  1.38s/it]Loading train:  62%|██████▏   | 177/285 [04:04<02:20,  1.30s/it]Loading train:  62%|██████▏   | 178/285 [04:05<02:07,  1.19s/it]Loading train:  63%|██████▎   | 179/285 [04:06<02:06,  1.19s/it]Loading train:  63%|██████▎   | 180/285 [04:07<02:09,  1.23s/it]Loading train:  64%|██████▎   | 181/285 [04:09<02:14,  1.29s/it]Loading train:  64%|██████▍   | 182/285 [04:10<02:10,  1.27s/it]Loading train:  64%|██████▍   | 183/285 [04:11<02:04,  1.22s/it]Loading train:  65%|██████▍   | 184/285 [04:12<02:00,  1.19s/it]Loading train:  65%|██████▍   | 185/285 [04:14<02:02,  1.23s/it]Loading train:  65%|██████▌   | 186/285 [04:15<02:07,  1.28s/it]Loading train:  66%|██████▌   | 187/285 [04:16<02:11,  1.34s/it]Loading train:  66%|██████▌   | 188/285 [04:18<02:08,  1.32s/it]Loading train:  66%|██████▋   | 189/285 [04:19<02:02,  1.27s/it]Loading train:  67%|██████▋   | 190/285 [04:20<02:00,  1.27s/it]Loading train:  67%|██████▋   | 191/285 [04:21<01:55,  1.23s/it]Loading train:  67%|██████▋   | 192/285 [04:23<01:56,  1.26s/it]Loading train:  68%|██████▊   | 193/285 [04:24<01:53,  1.23s/it]Loading train:  68%|██████▊   | 194/285 [04:25<01:47,  1.18s/it]Loading train:  68%|██████▊   | 195/285 [04:26<01:42,  1.14s/it]Loading train:  69%|██████▉   | 196/285 [04:27<01:43,  1.16s/it]Loading train:  69%|██████▉   | 197/285 [04:29<01:48,  1.24s/it]Loading train:  69%|██████▉   | 198/285 [04:30<01:50,  1.27s/it]Loading train:  70%|██████▉   | 199/285 [04:31<01:46,  1.24s/it]Loading train:  70%|███████   | 200/285 [04:32<01:45,  1.24s/it]Loading train:  71%|███████   | 201/285 [04:34<01:47,  1.28s/it]Loading train:  71%|███████   | 202/285 [04:35<01:42,  1.24s/it]Loading train:  71%|███████   | 203/285 [04:36<01:37,  1.20s/it]Loading train:  72%|███████▏  | 204/285 [04:37<01:34,  1.17s/it]Loading train:  72%|███████▏  | 205/285 [04:38<01:31,  1.15s/it]Loading train:  72%|███████▏  | 206/285 [04:39<01:33,  1.19s/it]Loading train:  73%|███████▎  | 207/285 [04:41<01:35,  1.23s/it]Loading train:  73%|███████▎  | 208/285 [04:42<01:41,  1.32s/it]Loading train:  73%|███████▎  | 209/285 [04:44<01:40,  1.32s/it]Loading train:  74%|███████▎  | 210/285 [04:45<01:38,  1.32s/it]Loading train:  74%|███████▍  | 211/285 [04:46<01:34,  1.28s/it]Loading train:  74%|███████▍  | 212/285 [04:48<01:37,  1.34s/it]Loading train:  75%|███████▍  | 213/285 [04:49<01:39,  1.38s/it]Loading train:  75%|███████▌  | 214/285 [04:50<01:35,  1.35s/it]Loading train:  75%|███████▌  | 215/285 [04:52<01:32,  1.32s/it]Loading train:  76%|███████▌  | 216/285 [04:53<01:29,  1.30s/it]Loading train:  76%|███████▌  | 217/285 [04:54<01:30,  1.33s/it]Loading train:  76%|███████▋  | 218/285 [04:56<01:37,  1.46s/it]Loading train:  77%|███████▋  | 219/285 [04:58<01:38,  1.49s/it]Loading train:  77%|███████▋  | 220/285 [04:59<01:34,  1.45s/it]Loading train:  78%|███████▊  | 221/285 [05:00<01:25,  1.33s/it]Loading train:  78%|███████▊  | 222/285 [05:01<01:24,  1.35s/it]Loading train:  78%|███████▊  | 223/285 [05:03<01:24,  1.37s/it]Loading train:  79%|███████▊  | 224/285 [05:04<01:25,  1.40s/it]Loading train:  79%|███████▉  | 225/285 [05:05<01:18,  1.31s/it]Loading train:  79%|███████▉  | 226/285 [05:07<01:19,  1.35s/it]Loading train:  80%|███████▉  | 227/285 [05:08<01:16,  1.32s/it]Loading train:  80%|████████  | 228/285 [05:09<01:17,  1.36s/it]Loading train:  80%|████████  | 229/285 [05:11<01:14,  1.33s/it]Loading train:  81%|████████  | 230/285 [05:12<01:12,  1.33s/it]Loading train:  81%|████████  | 231/285 [05:13<01:09,  1.29s/it]Loading train:  81%|████████▏ | 232/285 [05:15<01:09,  1.31s/it]Loading train:  82%|████████▏ | 233/285 [05:16<01:05,  1.25s/it]Loading train:  82%|████████▏ | 234/285 [05:17<01:07,  1.33s/it]Loading train:  82%|████████▏ | 235/285 [05:18<01:04,  1.30s/it]Loading train:  83%|████████▎ | 236/285 [05:20<01:09,  1.43s/it]Loading train:  83%|████████▎ | 237/285 [05:22<01:07,  1.41s/it]Loading train:  84%|████████▎ | 238/285 [05:23<01:11,  1.52s/it]Loading train:  84%|████████▍ | 239/285 [05:25<01:07,  1.48s/it]Loading train:  84%|████████▍ | 240/285 [05:26<01:03,  1.40s/it]Loading train:  85%|████████▍ | 241/285 [05:27<00:58,  1.32s/it]Loading train:  85%|████████▍ | 242/285 [05:28<00:54,  1.26s/it]Loading train:  85%|████████▌ | 243/285 [05:30<00:56,  1.35s/it]Loading train:  86%|████████▌ | 244/285 [05:31<01:00,  1.47s/it]Loading train:  86%|████████▌ | 245/285 [05:33<00:55,  1.40s/it]Loading train:  86%|████████▋ | 246/285 [05:34<00:53,  1.36s/it]Loading train:  87%|████████▋ | 247/285 [05:35<00:50,  1.34s/it]Loading train:  87%|████████▋ | 248/285 [05:36<00:47,  1.28s/it]Loading train:  87%|████████▋ | 249/285 [05:38<00:45,  1.26s/it]Loading train:  88%|████████▊ | 250/285 [05:39<00:43,  1.23s/it]Loading train:  88%|████████▊ | 251/285 [05:40<00:43,  1.28s/it]Loading train:  88%|████████▊ | 252/285 [05:41<00:40,  1.24s/it]Loading train:  89%|████████▉ | 253/285 [05:43<00:42,  1.33s/it]Loading train:  89%|████████▉ | 254/285 [05:44<00:41,  1.33s/it]Loading train:  89%|████████▉ | 255/285 [05:45<00:39,  1.30s/it]Loading train:  90%|████████▉ | 256/285 [05:47<00:36,  1.24s/it]Loading train:  90%|█████████ | 257/285 [05:48<00:35,  1.25s/it]Loading train:  91%|█████████ | 258/285 [05:50<00:37,  1.40s/it]Loading train:  91%|█████████ | 259/285 [05:51<00:35,  1.36s/it]Loading train:  91%|█████████ | 260/285 [05:52<00:33,  1.35s/it]Loading train:  92%|█████████▏| 261/285 [05:53<00:31,  1.32s/it]Loading train:  92%|█████████▏| 262/285 [05:55<00:30,  1.32s/it]Loading train:  92%|█████████▏| 263/285 [05:56<00:28,  1.28s/it]Loading train:  93%|█████████▎| 264/285 [05:58<00:30,  1.46s/it]Loading train:  93%|█████████▎| 265/285 [05:59<00:28,  1.43s/it]Loading train:  93%|█████████▎| 266/285 [06:00<00:26,  1.38s/it]Loading train:  94%|█████████▎| 267/285 [06:02<00:24,  1.33s/it]Loading train:  94%|█████████▍| 268/285 [06:03<00:24,  1.41s/it]Loading train:  94%|█████████▍| 269/285 [06:05<00:22,  1.38s/it]Loading train:  95%|█████████▍| 270/285 [06:06<00:20,  1.36s/it]Loading train:  95%|█████████▌| 271/285 [06:07<00:18,  1.29s/it]Loading train:  95%|█████████▌| 272/285 [06:08<00:16,  1.27s/it]Loading train:  96%|█████████▌| 273/285 [06:09<00:15,  1.27s/it]Loading train:  96%|█████████▌| 274/285 [06:11<00:14,  1.34s/it]Loading train:  96%|█████████▋| 275/285 [06:12<00:12,  1.29s/it]Loading train:  97%|█████████▋| 276/285 [06:14<00:11,  1.33s/it]Loading train:  97%|█████████▋| 277/285 [06:14<00:09,  1.21s/it]Loading train:  98%|█████████▊| 278/285 [06:15<00:07,  1.11s/it]Loading train:  98%|█████████▊| 279/285 [06:16<00:06,  1.12s/it]Loading train:  98%|█████████▊| 280/285 [06:18<00:05,  1.10s/it]Loading train:  99%|█████████▊| 281/285 [06:19<00:04,  1.08s/it]Loading train:  99%|█████████▉| 282/285 [06:20<00:03,  1.07s/it]Loading train:  99%|█████████▉| 283/285 [06:21<00:02,  1.11s/it]Loading train: 100%|█████████▉| 284/285 [06:22<00:01,  1.14s/it]Loading train: 100%|██████████| 285/285 [06:23<00:00,  1.17s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/285 [00:00<00:06, 45.10it/s]concatenating: train:   4%|▍         | 12/285 [00:00<00:05, 49.99it/s]concatenating: train:   8%|▊         | 22/285 [00:00<00:04, 57.25it/s]concatenating: train:  10%|█         | 29/285 [00:00<00:04, 58.73it/s]concatenating: train:  19%|█▉        | 55/285 [00:00<00:03, 76.40it/s]concatenating: train:  29%|██▉       | 84/285 [00:00<00:02, 97.84it/s]concatenating: train:  36%|███▌      | 103/285 [00:00<00:01, 113.54it/s]concatenating: train:  42%|████▏     | 120/285 [00:00<00:01, 98.14it/s] concatenating: train:  47%|████▋     | 135/285 [00:01<00:01, 101.52it/s]concatenating: train:  59%|█████▊    | 167/285 [00:01<00:00, 127.31it/s]concatenating: train:  70%|███████   | 200/285 [00:01<00:00, 155.58it/s]concatenating: train:  82%|████████▏ | 233/285 [00:01<00:00, 184.80it/s]concatenating: train:  94%|█████████▎| 267/285 [00:01<00:00, 213.15it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 182.25it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.54s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.51s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.45s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 40.65it/s]2019-07-11 00:25:48.383064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 00:25:48.383177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 00:25:48.383194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 00:25:48.383204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 00:25:48.383645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  4.83it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.73it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.24it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.71it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  6.19it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.08it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.32it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.15it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.72it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.23it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.93it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.50it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.65it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.16it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.93it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.07it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  7.83it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  6.57it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.04it/s]
Epoch 00051: val_mDice did not improve from 0.58395
Restoring model weights from the end of the best epoch
Epoch 00051: early stopping
{'val_loss': [2.166114920661563, 1.438329367410569, 1.2657744316827684, 1.126252015431722, 1.0010368256341844, 0.9997040771302723, 1.0437875248136974, 0.9902959834961664, 0.9418434018180484, 0.9539230153674171, 0.9544989211218697, 0.9675044445764451, 0.9582263912473407, 0.9446251676196143, 0.9895685740879604, 0.97063828649975, 0.9501635290327526, 0.9542149135044643, 0.9588288693200975, 0.9509033816201347, 0.9797206946781704, 0.9130915346599761, 0.9499545778547015, 0.9443380492074149, 0.9228081021990094, 0.9499180543990362, 0.9345105545861381, 0.9326419149126325, 0.9634800070808047, 0.911457339922587, 0.9332343850816999, 0.8945073116393316, 0.9332924740655082, 0.8838039182481312, 0.9527779193151564, 1.010569379443214, 0.9178213959648496, 0.9624111992972237, 0.8902185190291632, 0.9356728962489537, 0.9329111803145635, 0.9107411588941302, 0.8727209227425712, 0.994848750886463, 0.9349590823763892, 0.9073535147167388, 0.9047314212435767, 0.9395891144162133, 0.9821601368132091, 0.8839288949966431, 0.8490496362958636], 'val_acc': [0.9033608237902323, 0.9163415942873273, 0.9209432431629726, 0.9242399221374875, 0.9266826652345204, 0.9269482521783738, 0.9253296880494981, 0.9284272193908691, 0.9317674125943866, 0.9326831726800828, 0.9325801304408482, 0.9368406704493931, 0.9368383912813096, 0.9405311090605599, 0.9393933074814933, 0.9411240787733168, 0.94290748664311, 0.9448718116396949, 0.9438164092245556, 0.944848929132734, 0.9412156740824381, 0.9454533145541236, 0.9385622455960229, 0.9453777528944469, 0.945670797711327, 0.9446336967604501, 0.9405357014565241, 0.9448259841828119, 0.9428274063836961, 0.9446657413528079, 0.9320031972158522, 0.9444505203337896, 0.9378525557972136, 0.9448351916812715, 0.944038484777723, 0.9390499080930438, 0.9370604384513128, 0.9374954189573016, 0.9456478697913033, 0.9427266234443301, 0.941149251801627, 0.93726875100817, 0.9446291015261695, 0.9414240036691938, 0.944965640703837, 0.9450000098773411, 0.9438118111519587, 0.9317834008307684, 0.9368635302498227, 0.9446085180555072, 0.944333811601003], 'val_mDice': [0.21300030783528373, 0.40893992001102086, 0.47881735187201274, 0.535896399723632, 0.5610565933443251, 0.5542054158591089, 0.553054656301226, 0.5752330988290764, 0.5794213674962521, 0.5753873875808149, 0.5839510941434474, 0.5667866745165416, 0.5724741679926714, 0.577154445151488, 0.5475345225561232, 0.5721564624635946, 0.5734266028517768, 0.562812864070847, 0.5482667067221233, 0.5490102757300649, 0.5303601899317333, 0.5678527333906719, 0.5641307873385293, 0.5614842133862632, 0.5562223632420812, 0.5584434348912466, 0.5746511753116336, 0.5503046285538447, 0.5336656866683847, 0.573569980228231, 0.5538964910166604, 0.5774634540790603, 0.5661547496205285, 0.5807708265880743, 0.5505139989157518, 0.4839073836448647, 0.5563618448518571, 0.5536803656390735, 0.5796360025803248, 0.5647464085902486, 0.5482919462734744, 0.555456951792751, 0.5562239736318588, 0.5092683523183777, 0.5628098749688694, 0.5518383844977334, 0.5423657589015507, 0.5496567265973205, 0.5304587533076605, 0.5724012578527132, 0.558606081420467], 'loss': [2.9750692035413233, 1.0459345592706908, 0.6561629030776662, 0.5454836730463372, 0.49445948384505417, 0.46780166552203317, 0.44878382382421383, 0.43589353008102033, 0.4230217688720719, 0.41124879610614323, 0.4052343555204161, 0.3990952244424535, 0.3928224387623015, 0.3873364503601509, 0.3837209575284716, 0.3788605991622398, 0.3738090141283333, 0.3706638019726597, 0.3657593235634921, 0.36287562839553283, 0.3609905368575752, 0.3591491759846108, 0.35548831304994555, 0.3512704497142543, 0.34997574393519876, 0.3465431895942295, 0.3436101810514341, 0.3419044297888763, 0.33925729448197317, 0.3384114232841475, 0.3383363558592446, 0.3355742771661831, 0.3326142181406964, 0.33188430441811706, 0.32904728179564474, 0.32842196745060764, 0.32677671789019835, 0.3261804254397, 0.32365894417600044, 0.3234121468868333, 0.3205801828566695, 0.32117154001500164, 0.31982928717874115, 0.3171206432338484, 0.315869424300362, 0.31464143548715956, 0.3139821844211727, 0.3116322439232152, 0.3128258515891253, 0.3114296817034914, 0.31002526545147685], 'acc': [0.37911872486852316, 0.8790406849725825, 0.890241392170829, 0.8956145435048822, 0.899460814432163, 0.9022364480453625, 0.9048597120540046, 0.9072190921546086, 0.9097696657536553, 0.9124320832226395, 0.9141626945460305, 0.9161994325441273, 0.9186294609143919, 0.9195923188965928, 0.9212143946319089, 0.9227106925240136, 0.9245994077129632, 0.9257514642593556, 0.9266890890225524, 0.9282637752157336, 0.9295028658278167, 0.9305062070043647, 0.9320524639882907, 0.933359721802277, 0.9343243687282023, 0.9366921132783428, 0.9380661609293708, 0.9384596606819575, 0.9386794003811512, 0.9388421356781429, 0.9388829172174664, 0.9392023613877165, 0.9394945616733138, 0.9395978866984946, 0.9397922041720914, 0.9398292107505791, 0.9401517872270739, 0.9402694086567018, 0.9404779743408224, 0.9403889288625575, 0.9405996259959052, 0.9408396849725111, 0.9408091692214805, 0.9410328699118925, 0.94128766433568, 0.9413324386392781, 0.9415299952869036, 0.9417238054832604, 0.9416775804092734, 0.9418584156385709, 0.941935295897319], 'mDice': [0.10415297071839978, 0.36391500676209143, 0.5080116078852228, 0.5661541313042134, 0.5960472399774305, 0.6125699654006076, 0.6246036105999856, 0.6329317676186769, 0.6412382701446676, 0.6490693864207381, 0.6529848227294994, 0.6570834459908234, 0.6614134929325853, 0.6651009104949145, 0.6675972363749795, 0.6709531564254717, 0.674425017806131, 0.6766316210554817, 0.6799667650549679, 0.6819376706709309, 0.6833855108371791, 0.6845166056124443, 0.6871089163671368, 0.6901906800104608, 0.6910712996130393, 0.6934963955179629, 0.6950084114203408, 0.6961455016161909, 0.6979735287393659, 0.6985314358216111, 0.6985130438989404, 0.7005760134909684, 0.7026520954843245, 0.7031630559281988, 0.70534101429072, 0.705691459334285, 0.7069245081704454, 0.7073621434330687, 0.7091919586381311, 0.7094207558646606, 0.7113664776965881, 0.711120453900355, 0.7118782724790865, 0.7139719393020286, 0.7148662405549986, 0.7158172496233415, 0.7162913338214602, 0.7180138808788765, 0.7171486031694267, 0.718216262779324, 0.7192052414427839]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 26, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 13, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 26, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 30)   16230       dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 30)   120         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 30)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 52, 30)   0           activation_11[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 90)   0           dropout_5[0][0]                  
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 13)   1183        concatenate_7[0][0]              
==================================================================================================
Total params: 240,573
Trainable params: 65,833
Non-trainable params: 174,740
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 18s - loss: 2.0082 - acc: 0.7840 - mDice: 0.2172 - val_loss: 0.8921 - val_acc: 0.9191 - val_mDice: 0.4096

Epoch 00001: val_mDice improved from -inf to 0.40959, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 13s - loss: 0.7087 - acc: 0.9014 - mDice: 0.4777 - val_loss: 0.6055 - val_acc: 0.9333 - val_mDice: 0.5331

Epoch 00002: val_mDice improved from 0.40959 to 0.53313, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 12s - loss: 0.5739 - acc: 0.9159 - mDice: 0.5486 - val_loss: 0.6138 - val_acc: 0.9403 - val_mDice: 0.5278

Epoch 00003: val_mDice did not improve from 0.53313
Epoch 4/300
 - 12s - loss: 0.5104 - acc: 0.9312 - mDice: 0.5860 - val_loss: 0.6211 - val_acc: 0.9436 - val_mDice: 0.5398

Epoch 00004: val_mDice improved from 0.53313 to 0.53984, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 13s - loss: 0.4678 - acc: 0.9358 - mDice: 0.6116 - val_loss: 0.5591 - val_acc: 0.9450 - val_mDice: 0.5592

Epoch 00005: val_mDice improved from 0.53984 to 0.55919, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 13s - loss: 0.4420 - acc: 0.9381 - mDice: 0.6283 - val_loss: 0.5257 - val_acc: 0.9488 - val_mDice: 0.5826

Epoch 00006: val_mDice improved from 0.55919 to 0.58259, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 13s - loss: 0.4195 - acc: 0.9401 - mDice: 0.6428 - val_loss: 0.5155 - val_acc: 0.9495 - val_mDice: 0.5861

Epoch 00007: val_mDice improved from 0.58259 to 0.58609, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 13s - loss: 0.4034 - acc: 0.9416 - mDice: 0.6537 - val_loss: 0.6334 - val_acc: 0.9434 - val_mDice: 0.5323

Epoch 00008: val_mDice did not improve from 0.58609
Epoch 9/300
 - 13s - loss: 0.3895 - acc: 0.9428 - mDice: 0.6629 - val_loss: 0.4996 - val_acc: 0.9488 - val_mDice: 0.5959

Epoch 00009: val_mDice improved from 0.58609 to 0.59586, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 12s - loss: 0.3750 - acc: 0.9439 - mDice: 0.6728 - val_loss: 0.5122 - val_acc: 0.9485 - val_mDice: 0.5866

Epoch 00010: val_mDice did not improve from 0.59586
Epoch 11/300
 - 13s - loss: 0.3666 - acc: 0.9448 - mDice: 0.6788 - val_loss: 0.4946 - val_acc: 0.9509 - val_mDice: 0.5967

Epoch 00011: val_mDice improved from 0.59586 to 0.59670, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 12s - loss: 0.3580 - acc: 0.9455 - mDice: 0.6848 - val_loss: 0.5133 - val_acc: 0.9496 - val_mDice: 0.5886

Epoch 00012: val_mDice did not improve from 0.59670
Epoch 13/300
 - 13s - loss: 0.3493 - acc: 0.9463 - mDice: 0.6910 - val_loss: 0.4886 - val_acc: 0.9510 - val_mDice: 0.6024

Epoch 00013: val_mDice improved from 0.59670 to 0.60245, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 13s - loss: 0.3429 - acc: 0.9468 - mDice: 0.6956 - val_loss: 0.5180 - val_acc: 0.9489 - val_mDice: 0.5849

Epoch 00014: val_mDice did not improve from 0.60245
Epoch 15/300
 - 13s - loss: 0.3361 - acc: 0.9474 - mDice: 0.7006 - val_loss: 0.5606 - val_acc: 0.9480 - val_mDice: 0.5688

Epoch 00015: val_mDice did not improve from 0.60245
Epoch 16/300
 - 13s - loss: 0.3292 - acc: 0.9479 - mDice: 0.7053 - val_loss: 0.5454 - val_acc: 0.9469 - val_mDice: 0.5754

Epoch 00016: val_mDice did not improve from 0.60245
Epoch 17/300
 - 13s - loss: 0.3263 - acc: 0.9481 - mDice: 0.7076 - val_loss: 0.5978 - val_acc: 0.9471 - val_mDice: 0.5419

Epoch 00017: val_mDice did not improve from 0.60245
Epoch 18/300
 - 13s - loss: 0.3217 - acc: 0.9486 - mDice: 0.7112 - val_loss: 0.5534 - val_acc: 0.9467 - val_mDice: 0.5625

Epoch 00018: val_mDice did not improve from 0.60245
Epoch 19/300
 - 12s - loss: 0.3180 - acc: 0.9490 - mDice: 0.7138 - val_loss: 0.5168 - val_acc: 0.9498 - val_mDice: 0.5878

Epoch 00019: val_mDice did not improve from 0.60245
Epoch 20/300
 - 13s - loss: 0.3123 - acc: 0.9494 - mDice: 0.7179 - val_loss: 0.5504 - val_acc: 0.9493 - val_mDice: 0.5690

Epoch 00020: val_mDice did not improve from 0.60245
Epoch 21/300
 - 12s - loss: 0.3097 - acc: 0.9496 - mDice: 0.7202 - val_loss: 0.5434 - val_acc: 0.9471 - val_mDice: 0.5754

Epoch 00021: val_mDice did not improve from 0.60245
Epoch 22/300
 - 13s - loss: 0.3051 - acc: 0.9500 - mDice: 0.7234 - val_loss: 0.5510 - val_acc: 0.9444 - val_mDice: 0.5641

Epoch 00022: val_mDice did not improve from 0.60245
Epoch 23/300
 - 12s - loss: 0.3026 - acc: 0.9503 - mDice: 0.7253 - val_loss: 0.5092 - val_acc: 0.9500 - val_mDice: 0.5909

Epoch 00023: val_mDice did not improve from 0.60245
Epoch 24/300
 - 12s - loss: 0.2992 - acc: 0.9506 - mDice: 0.7279 - val_loss: 0.5613 - val_acc: 0.9487 - val_mDice: 0.5621

Epoch 00024: val_mDice did not improve from 0.60245
Epoch 25/300
 - 13s - loss: 0.2949 - acc: 0.9509 - mDice: 0.7311 - val_loss: 0.5467 - val_acc: 0.9511 - val_mDice: 0.5770

Epoch 00025: val_mDice did not improve from 0.60245
Epoch 26/300
 - 12s - loss: 0.2949 - acc: 0.9510 - mDice: 0.7311 - val_loss: 0.5207 - val_acc: 0.9492 - val_mDice: 0.5869

Epoch 00026: val_mDice did not improve from 0.60245
Epoch 27/300
 - 13s - loss: 0.2911 - acc: 0.9513 - mDice: 0.7341 - val_loss: 0.5569 - val_acc: 0.9465 - val_mDice: 0.5667

Epoch 00027: val_mDice did not improve from 0.60245
Epoch 28/300
 - 12s - loss: 0.2889 - acc: 0.9514 - mDice: 0.7357 - val_loss: 0.5325 - val_acc: 0.9517 - val_mDice: 0.5814

Epoch 00028: val_mDice did not improve from 0.60245
Epoch 29/300
 - 14s - loss: 0.2840 - acc: 0.9518 - mDice: 0.7395 - val_loss: 0.5264 - val_acc: 0.9506 - val_mDice: 0.5834

Epoch 00029: val_mDice did not improve from 0.60245
Epoch 30/300
 - 13s - loss: 0.2822 - acc: 0.9519 - mDice: 0.7407 - val_loss: 0.5430 - val_acc: 0.9471 - val_mDice: 0.5726

Epoch 00030: val_mDice did not improve from 0.60245
Epoch 31/300
 - 14s - loss: 0.2832 - acc: 0.9519 - mDice: 0.7401 - val_loss: 0.5128 - val_acc: 0.9505 - val_mDice: 0.5909

Epoch 00031: val_mDice did not improve from 0.60245
Epoch 32/300
 - 14s - loss: 0.2798 - acc: 0.9521 - mDice: 0.7427 - val_loss: 0.5633 - val_acc: 0.9444 - val_mDice: 0.5578

Epoch 00032: val_mDice did not improve from 0.60245
Epoch 33/300
 - 14s - loss: 0.2793 - acc: 0.9522 - mDice: 0.7431 - val_loss: 0.5597 - val_acc: 0.9469 - val_mDice: 0.5604

Epoch 00033: val_mDice did not improve from 0.60245
Epoch 34/300
 - 13s - loss: 0.2758 - acc: 0.9524 - mDice: 0.7458 - val_loss: 0.5096 - val_acc: 0.9509 - val_mDice: 0.5936

Epoch 00034: val_mDice did not improve from 0.60245
Epoch 35/300
 - 15s - loss: 0.2739 - acc: 0.9526 - mDice: 0.7473 - val_loss: 0.5123 - val_acc: 0.9510 - val_mDice: 0.5908

Epoch 00035: val_mDice did not improve from 0.60245
Epoch 36/300
 - 14s - loss: 0.2725 - acc: 0.9527 - mDice: 0.7484 - val_loss: 0.5252 - val_acc: 0.9478 - val_mDice: 0.5779

Epoch 00036: val_mDice did not improve from 0.60245
Epoch 37/300
 - 15s - loss: 0.2711 - acc: 0.9529 - mDice: 0.7495 - val_loss: 0.4980 - val_acc: 0.9520 - val_mDice: 0.5993

Epoch 00037: val_mDice did not improve from 0.60245
Epoch 38/300
 - 14s - loss: 0.2693 - acc: 0.9530 - mDice: 0.7509 - val_loss: 0.5248 - val_acc: 0.9498 - val_mDice: 0.5837

Epoch 00038: val_mDice did not improve from 0.60245
Epoch 39/300
 - 15s - loss: 0.2704 - acc: 0.9530 - mDice: 0.7501 - val_loss: 0.5128 - val_acc: 0.9503 - val_mDice: 0.5911

Epoch 00039: val_mDice did not improve from 0.60245
Epoch 40/300
 - 14s - loss: 0.2682 - acc: 0.9532 - mDice: 0.7518 - val_loss: 0.5356 - val_acc: 0.9476 - val_mDice: 0.5741

Epoch 00040: val_mDice did not improve from 0.60245
Epoch 41/300
 - 14s - loss: 0.2665 - acc: 0.9533 - mDice: 0.7530 - val_loss: 0.5216 - val_acc: 0.9517 - val_mDice: 0.5884

Epoch 00041: val_mDice did not improve from 0.60245
Epoch 42/300
 - 14s - loss: 0.2629 - acc: 0.9536 - mDice: 0.7558 - val_loss: 0.5115 - val_acc: 0.9510 - val_mDice: 0.5932

Epoch 00042: val_mDice did not improve from 0.60245
Epoch 43/300
 - 14s - loss: 0.2617 - acc: 0.9536 - mDice: 0.7568 - val_loss: 0.5970 - val_acc: 0.9494 - val_mDice: 0.5502

Epoch 00043: val_mDice did not improve from 0.60245
Epoch 44/300
 - 15s - loss: 0.2633 - acc: 0.9535 - mDice: 0.7556 - val_loss: 0.4863 - val_acc: 0.9509 - val_mDice: 0.6049

Epoch 00044: val_mDice improved from 0.60245 to 0.60490, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 45/300
 - 14s - loss: 0.2608 - acc: 0.9538 - mDice: 0.7577 - val_loss: 0.5112 - val_acc: 0.9491 - val_mDice: 0.5927

Epoch 00045: val_mDice did not improve from 0.60490
Epoch 46/300
 - 14s - loss: 0.2596 - acc: 0.9538 - mDice: 0.7585 - val_loss: 0.5460 - val_acc: 0.9478 - val_mDice: 0.5710

Epoch 00046: val_mDice did not improve from 0.60490
Epoch 47/300
 - 15s - loss: 0.2575 - acc: 0.9540 - mDice: 0.7602 - val_loss: 0.5363 - val_acc: 0.9499 - val_mDice: 0.5765

Epoch 00047: val_mDice did not improve from 0.60490
Epoch 48/300
 - 14s - loss: 0.2588 - acc: 0.9539 - mDice: 0.7592 - val_loss: 0.5635 - val_acc: 0.9487 - val_mDice: 0.5704

Epoch 00048: val_mDice did not improve from 0.60490
Epoch 49/300
 - 13s - loss: 0.2566 - acc: 0.9541 - mDice: 0.7609 - val_loss: 0.5061 - val_acc: 0.9487 - val_mDice: 0.5898

Epoch 00049: val_mDice did not improve from 0.60490
Epoch 50/300
 - 13s - loss: 0.2551 - acc: 0.9542 - mDice: 0.7620 - val_loss: 0.4984 - val_acc: 0.9512 - val_mDice: 0.5976

Epoch 00050: val_mDice did not improve from 0.60490
Epoch 51/300
 - 12s - loss: 0.2566 - acc: 0.9541 - mDice: 0.7609 - val_loss: 0.5439 - val_acc: 0.9488 - val_mDice: 0.5701

Epoch 00051: val_mDice did not improve from 0.60490
Epoch 52/300
 - 12s - loss: 0.2532 - acc: 0.9544 - mDice: 0.7636 - val_loss: 0.5111 - val_acc: 0.9508 - val_mDice: 0.5901

Epoch 00052: val_mDice did not improve from 0.60490
Epoch 53/300
 - 12s - loss: 0.2527 - acc: 0.9544 - mDice: 0.7640 - val_loss: 0.5112 - val_acc: 0.9521 - val_mDice: 0.5906

Epoch 00053: val_mDice did not improve from 0.60490
Epoch 54/300
 - 13s - loss: 0.2515 - acc: 0.9545 - mDice: 0.7649 - val_loss: 0.4998 - val_acc: 0.9495 - val_mDice: 0.5965

Epoch 00054: val_mDice did not improve from 0.60490
Epoch 55/300
 - 12s - loss: 0.2513 - acc: 0.9546 - mDice: 0.7651 - val_loss: 0.5169 - val_acc: 0.9503 - val_mDice: 0.5886

Epoch 00055: val_mDice did not improve from 0.60490
Epoch 56/300
 - 12s - loss: 0.2508 - acc: 0.9547 - mDice: 0.7656 - val_loss: 0.4962 - val_acc: 0.9514 - val_mDice: 0.5984

Epoch 00056: val_mDice did not improve from 0.60490
Epoch 57/300
 - 12s - loss: 0.2501 - acc: 0.9546 - mDice: 0.7661 - val_loss: 0.5651 - val_acc: 0.9503 - val_mDice: 0.5698

Epoch 00057: val_mDice did not improve from 0.60490
Epoch 58/300
 - 12s - loss: 0.2488 - acc: 0.9548 - mDice: 0.7671 - val_loss: 0.5015 - val_acc: 0.9534 - val_mDice: 0.6012

Epoch 00058: val_mDice did not improve from 0.60490
Epoch 59/300
 - 13s - loss: 0.2480 - acc: 0.9549 - mDice: 0.7677 - val_loss: 0.5062 - val_acc: 0.9507 - val_mDice: 0.5919

Epoch 00059: val_mDice did not improve from 0.60490
Epoch 60/300
 - 12s - loss: 0.2465 - acc: 0.9550 - mDice: 0.7690 - val_loss: 0.5233 - val_acc: 0.9470 - val_mDice: 0.5811

Epoch 00060: val_mDice did not improve from 0.60490
Epoch 61/300
 - 12s - loss: 0.2477 - acc: 0.9549 - mDice: 0.7680 - val_loss: 0.4975 - val_acc: 0.9513 - val_mDice: 0.5991

Epoch 00061: val_mDice did not improve from 0.60490
Epoch 62/300
 - 12s - loss: 0.2466 - acc: 0.9550 - mDice: 0.7689 - val_loss: 0.5378 - val_acc: 0.9478 - val_mDice: 0.5723

Epoch 00062: val_mDice did not improve from 0.60490
Epoch 63/300
 - 12s - loss: 0.2449 - acc: 0.9551 - mDice: 0.7703 - val_loss: 0.5305 - val_acc: 0.9491 - val_mDice: 0.5761

Epoch 00063: val_mDice did not improve from 0.60490
Epoch 64/300
 - 12s - loss: 0.2442 - acc: 0.9551 - mDice: 0.7709 - val_loss: 0.5089 - val_acc: 0.9516 - val_mDice: 0.5923

Epoch 00064: val_mDice did not improve from 0.60490
Epoch 65/300
 - 12s - loss: 0.2449 - acc: 0.9551 - mDice: 0.7702 - val_loss: 0.5034 - val_acc: 0.9525 - val_mDice: 0.5964

Epoch 00065: val_mDice did not improve from 0.60490
Epoch 66/300
 - 12s - loss: 0.2428 - acc: 0.9553 - mDice: 0.7719 - val_loss: 0.5100 - val_acc: 0.9480 - val_mDice: 0.5868

Epoch 00066: val_mDice did not improve from 0.60490
Epoch 67/300
 - 12s - loss: 0.2428 - acc: 0.9553 - mDice: 0.7719 - val_loss: 0.4823 - val_acc: 0.9524 - val_mDice: 0.6063

Epoch 00067: val_mDice improved from 0.60490 to 0.60629, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 68/300
 - 12s - loss: 0.2424 - acc: 0.9553 - mDice: 0.7722 - val_loss: 0.5250 - val_acc: 0.9506 - val_mDice: 0.5827

Epoch 00068: val_mDice did not improve from 0.60629
Epoch 69/300
 - 12s - loss: 0.2418 - acc: 0.9553 - mDice: 0.7727 - val_loss: 0.4971 - val_acc: 0.9511 - val_mDice: 0.5973

Epoch 00069: val_mDice did not improve from 0.60629
Epoch 70/300
 - 13s - loss: 0.2398 - acc: 0.9556 - mDice: 0.7744 - val_loss: 0.5226 - val_acc: 0.9510 - val_mDice: 0.5847

Epoch 00070: val_mDice did not improve from 0.60629
Epoch 71/300
 - 12s - loss: 0.2396 - acc: 0.9555 - mDice: 0.7745 - val_loss: 0.4875 - val_acc: 0.9500 - val_mDice: 0.6029

Epoch 00071: val_mDice did not improve from 0.60629
Epoch 72/300
 - 12s - loss: 0.2400 - acc: 0.9555 - mDice: 0.7742 - val_loss: 0.5357 - val_acc: 0.9479 - val_mDice: 0.5726

Epoch 00072: val_mDice did not improve from 0.60629
Epoch 73/300
 - 12s - loss: 0.2383 - acc: 0.9556 - mDice: 0.7755 - val_loss: 0.5089 - val_acc: 0.9518 - val_mDice: 0.5948

Epoch 00073: val_mDice did not improve from 0.60629
Epoch 74/300
 - 12s - loss: 0.2384 - acc: 0.9556 - mDice: 0.7755 - val_loss: 0.5440 - val_acc: 0.9488 - val_mDice: 0.5748

Epoch 00074: val_mDice did not improve from 0.60629
Epoch 75/300
 - 12s - loss: 0.2385 - acc: 0.9556 - mDice: 0.7754 - val_loss: 0.4999 - val_acc: 0.9511 - val_mDice: 0.5955

Epoch 00075: val_mDice did not improve from 0.60629
Epoch 76/300
 - 12s - loss: 0.2375 - acc: 0.9557 - mDice: 0.7762 - val_loss: 0.5213 - val_acc: 0.9505 - val_mDice: 0.5828

Epoch 00076: val_mDice did not improve from 0.60629
Epoch 77/300
 - 12s - loss: 0.2374 - acc: 0.9558 - mDice: 0.7764 - val_loss: 0.5007 - val_acc: 0.9529 - val_mDice: 0.5978

Epoch 00077: val_mDice did not improve from 0.60629
Epoch 78/300
 - 12s - loss: 0.2367 - acc: 0.9558 - mDice: 0.7768 - val_loss: 0.5048 - val_acc: 0.9510 - val_mDice: 0.5930

Epoch 00078: val_mDice did not improve from 0.60629
Epoch 79/300
 - 12s - loss: 0.2349 - acc: 0.9559 - mDice: 0.7783 - val_loss: 0.5209 - val_acc: 0.9511 - val_mDice: 0.5864

Epoch 00079: val_mDice did not improve from 0.60629
Epoch 80/300
 - 12s - loss: 0.2351 - acc: 0.9559 - mDice: 0.7782 - val_loss: 0.5013 - val_acc: 0.9522 - val_mDice: 0.5963

Epoch 00080: val_mDice did not improve from 0.60629
Epoch 81/300
 - 12s - loss: 0.2357 - acc: 0.9558 - mDice: 0.7778 - val_loss: 0.5150 - val_acc: 0.9505 - val_mDice: 0.5886

Epoch 00081: val_mDice did not improve from 0.60629
Epoch 82/300
 - 12s - loss: 0.2338 - acc: 0.9560 - mDice: 0.7792 - val_loss: 0.5330 - val_acc: 0.9526 - val_mDice: 0.5815

Epoch 00082: val_mDice did not improve from 0.60629
Epoch 83/300
 - 12s - loss: 0.2352 - acc: 0.9559 - mDice: 0.7780 - val_loss: 0.4796 - val_acc: 0.9523 - val_mDice: 0.6076

Epoch 00083: val_mDice improved from 0.60629 to 0.60761, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 84/300
 - 12s - loss: 0.2334 - acc: 0.9560 - mDice: 0.7795 - val_loss: 0.5474 - val_acc: 0.9495 - val_mDice: 0.5689

Epoch 00084: val_mDice did not improve from 0.60761
Epoch 85/300
 - 12s - loss: 0.2326 - acc: 0.9561 - mDice: 0.7802 - val_loss: 0.4990 - val_acc: 0.9525 - val_mDice: 0.5980

Epoch 00085: val_mDice did not improve from 0.60761
Epoch 86/300
 - 12s - loss: 0.2326 - acc: 0.9562 - mDice: 0.7802 - val_loss: 0.5531 - val_acc: 0.9507 - val_mDice: 0.5747

Epoch 00086: val_mDice did not improve from 0.60761
Epoch 87/300
 - 12s - loss: 0.2330 - acc: 0.9561 - mDice: 0.7799 - val_loss: 0.5093 - val_acc: 0.9523 - val_mDice: 0.5918

Epoch 00087: val_mDice did not improve from 0.60761
Epoch 88/300
 - 12s - loss: 0.2334 - acc: 0.9561 - mDice: 0.7796 - val_loss: 0.5396 - val_acc: 0.9495 - val_mDice: 0.5753

Epoch 00088: val_mDice did not improve from 0.60761
Epoch 89/300
 - 12s - loss: 0.2319 - acc: 0.9562 - mDice: 0.7808 - val_loss: 0.5150 - val_acc: 0.9515 - val_mDice: 0.5874

Epoch 00089: val_mDice did not improve from 0.60761
Epoch 90/300
 - 12s - loss: 0.2310 - acc: 0.9563 - mDice: 0.7815 - val_loss: 0.4952 - val_acc: 0.9525 - val_mDice: 0.5997

Epoch 00090: val_mDice did not improve from 0.60761
Epoch 91/300
 - 12s - loss: 0.2312 - acc: 0.9563 - mDice: 0.7814 - val_loss: 0.5046 - val_acc: 0.9517 - val_mDice: 0.5951

Epoch 00091: val_mDice did not improve from 0.60761
Epoch 92/300
 - 12s - loss: 0.2316 - acc: 0.9563 - mDice: 0.7810 - val_loss: 0.5019 - val_acc: 0.9499 - val_mDice: 0.5917

Epoch 00092: val_mDice did not improve from 0.60761
Epoch 93/300
 - 12s - loss: 0.2296 - acc: 0.9564 - mDice: 0.7827 - val_loss: 0.5555 - val_acc: 0.9471 - val_mDice: 0.5617

Epoch 00093: val_mDice did not improve from 0.60761
Epoch 94/300
 - 12s - loss: 0.2308 - acc: 0.9564 - mDice: 0.7817 - val_loss: 0.5456 - val_acc: 0.9499 - val_mDice: 0.5737

Epoch 00094: val_mDice did not improve from 0.60761
Epoch 95/300
 - 13s - loss: 0.2296 - acc: 0.9565 - mDice: 0.7827 - val_loss: 0.5248 - val_acc: 0.9491 - val_mDice: 0.5807

Epoch 00095: val_mDice did not improve from 0.60761
Epoch 96/300
 - 12s - loss: 0.2308 - acc: 0.9563 - mDice: 0.7817 - val_loss: 0.4774 - val_acc: 0.9526 - val_mDice: 0.6089

Epoch 00096: val_mDice improved from 0.60761 to 0.60894, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 97/300
 - 12s - loss: 0.2281 - acc: 0.9566 - mDice: 0.7839 - val_loss: 0.5164 - val_acc: 0.9527 - val_mDice: 0.5891

Epoch 00097: val_mDice did not improve from 0.60894
Epoch 98/300
 - 12s - loss: 0.2282 - acc: 0.9565 - mDice: 0.7839 - val_loss: 0.5389 - val_acc: 0.9492 - val_mDice: 0.5746

Epoch 00098: val_mDice did not improve from 0.60894
Epoch 99/300
 - 12s - loss: 0.2285 - acc: 0.9565 - mDice: 0.7836 - val_loss: 0.5051 - val_acc: 0.9515 - val_mDice: 0.5962

Epoch 00099: val_mDice did not improve from 0.60894
Epoch 100/300
 - 12s - loss: 0.2281 - acc: 0.9566 - mDice: 0.7839 - val_loss: 0.5263 - val_acc: 0.9505 - val_mDice: 0.5803

Epoch 00100: val_mDice did not improve from 0.60894
Epoch 101/300
 - 13s - loss: 0.2277 - acc: 0.9566 - mDice: 0.7843 - val_loss: 0.4911 - val_acc: 0.9493 - val_mDice: 0.5995

Epoch 00101: val_mDice did not improve from 0.60894
Epoch 102/300
 - 12s - loss: 0.2272 - acc: 0.9567 - mDice: 0.7847 - val_loss: 0.5652 - val_acc: 0.9507 - val_mDice: 0.5689

Epoch 00102: val_mDice did not improve from 0.60894
Epoch 103/300
 - 12s - loss: 0.2269 - acc: 0.9567 - mDice: 0.7849 - val_loss: 0.4950 - val_acc: 0.9510 - val_mDice: 0.5964

Epoch 00103: val_mDice did not improve from 0.60894
Epoch 104/300
 - 12s - loss: 0.2264 - acc: 0.9567 - mDice: 0.7853 - val_loss: 0.5169 - val_acc: 0.9533 - val_mDice: 0.5892

Epoch 00104: val_mDice did not improve from 0.60894
Epoch 105/300
 - 12s - loss: 0.2265 - acc: 0.9568 - mDice: 0.7852 - val_loss: 0.5427 - val_acc: 0.9515 - val_mDice: 0.5800

Epoch 00105: val_mDice did not improve from 0.60894
Epoch 106/300
 - 12s - loss: 0.2256 - acc: 0.9567 - mDice: 0.7860 - val_loss: 0.5146 - val_acc: 0.9522 - val_mDice: 0.5906

Epoch 00106: val_mDice did not improve from 0.60894
Epoch 107/300
 - 12s - loss: 0.2268 - acc: 0.9567 - mDice: 0.7851 - val_loss: 0.4995 - val_acc: 0.9523 - val_mDice: 0.5965

Epoch 00107: val_mDice did not improve from 0.60894
Epoch 108/300
 - 13s - loss: 0.2254 - acc: 0.9567 - mDice: 0.7862 - val_loss: 0.5072 - val_acc: 0.9493 - val_mDice: 0.5905

Epoch 00108: val_mDice did not improve from 0.60894
Epoch 109/300
 - 13s - loss: 0.2250 - acc: 0.9568 - mDice: 0.7865 - val_loss: 0.5138 - val_acc: 0.9524 - val_mDice: 0.5905

Epoch 00109: val_mDice did not improve from 0.60894
Epoch 110/300
 - 12s - loss: 0.2246 - acc: 0.9568 - mDice: 0.7868 - val_loss: 0.5094 - val_acc: 0.9513 - val_mDice: 0.5922

Epoch 00110: val_mDice did not improve from 0.60894
Epoch 111/300
 - 12s - loss: 0.2242 - acc: 0.9569 - mDice: 0.7872 - val_loss: 0.4919 - val_acc: 0.9500 - val_mDice: 0.5988

Epoch 00111: val_mDice did not improve from 0.60894
Epoch 112/300
 - 12s - loss: 0.2244 - acc: 0.9569 - mDice: 0.7870 - val_loss: 0.5385 - val_acc: 0.9491 - val_mDice: 0.5753

Epoch 00112: val_mDice did not improve from 0.60894
Epoch 113/300
 - 12s - loss: 0.2244 - acc: 0.9569 - mDice: 0.7870 - val_loss: 0.5456 - val_acc: 0.9473 - val_mDice: 0.5683

Epoch 00113: val_mDice did not improve from 0.60894
Epoch 114/300
 - 12s - loss: 0.2233 - acc: 0.9570 - mDice: 0.7879 - val_loss: 0.5236 - val_acc: 0.9478 - val_mDice: 0.5815

Epoch 00114: val_mDice did not improve from 0.60894
Epoch 115/300
 - 12s - loss: 0.2230 - acc: 0.9570 - mDice: 0.7882 - val_loss: 0.5270 - val_acc: 0.9509 - val_mDice: 0.5833

Epoch 00115: val_mDice did not improve from 0.60894
Epoch 116/300
 - 12s - loss: 0.2224 - acc: 0.9570 - mDice: 0.7887 - val_loss: 0.5354 - val_acc: 0.9507 - val_mDice: 0.5790

Epoch 00116: val_mDice did not improve from 0.60894
Epoch 117/300
 - 13s - loss: 0.2239 - acc: 0.9569 - mDice: 0.7874 - val_loss: 0.5026 - val_acc: 0.9528 - val_mDice: 0.5949

Epoch 00117: val_mDice did not improve from 0.60894
Epoch 118/300
 - 13s - loss: 0.2234 - acc: 0.9570 - mDice: 0.7878 - val_loss: 0.5016 - val_acc: 0.9511 - val_mDice: 0.5970

Epoch 00118: val_mDice did not improve from 0.60894
Epoch 119/300
 - 12s - loss: 0.2220 - acc: 0.9571 - mDice: 0.7889 - val_loss: 0.5533 - val_acc: 0.9491 - val_mDice: 0.5660

Epoch 00119: val_mDice did not improve from 0.60894
Epoch 120/300
 - 12s - loss: 0.2228 - acc: 0.9570 - mDice: 0.7884 - val_loss: 0.5521 - val_acc: 0.9455 - val_mDice: 0.5640

Epoch 00120: val_mDice did not improve from 0.60894
Epoch 121/300
 - 12s - loss: 0.2223 - acc: 0.9571 - mDice: 0.7888 - val_loss: 0.4861 - val_acc: 0.9509 - val_mDice: 0.6035

Epoch 00121: val_mDice did not improve from 0.60894
Epoch 122/300
 - 13s - loss: 0.2218 - acc: 0.9571 - mDice: 0.7892 - val_loss: 0.5245 - val_acc: 0.9524 - val_mDice: 0.5870

Epoch 00122: val_mDice did not improve from 0.60894
Epoch 123/300
 - 13s - loss: 0.2201 - acc: 0.9572 - mDice: 0.7905 - val_loss: 0.5213 - val_acc: 0.9502 - val_mDice: 0.5840

Epoch 00123: val_mDice did not improve from 0.60894
Epoch 124/300
 - 12s - loss: 0.2216 - acc: 0.9571 - mDice: 0.7894 - val_loss: 0.4992 - val_acc: 0.9517 - val_mDice: 0.5955

Epoch 00124: val_mDice did not improve from 0.60894
Epoch 125/300
 - 13s - loss: 0.2209 - acc: 0.9571 - mDice: 0.7899 - val_loss: 0.4777 - val_acc: 0.9518 - val_mDice: 0.6091

Epoch 00125: val_mDice improved from 0.60894 to 0.60907, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 126/300
 - 12s - loss: 0.2208 - acc: 0.9572 - mDice: 0.7899 - val_loss: 0.5194 - val_acc: 0.9501 - val_mDice: 0.5858

Epoch 00126: val_mDice did not improve from 0.60907
Epoch 127/300
 - 13s - loss: 0.2201 - acc: 0.9572 - mDice: 0.7905 - val_loss: 0.5091 - val_acc: 0.9525 - val_mDice: 0.5919

Epoch 00127: val_mDice did not improve from 0.60907
Epoch 128/300
 - 13s - loss: 0.2211 - acc: 0.9571 - mDice: 0.7897 - val_loss: 0.5632 - val_acc: 0.9509 - val_mDice: 0.5677

Epoch 00128: val_mDice did not improve from 0.60907
Epoch 129/300
 - 12s - loss: 0.2202 - acc: 0.9572 - mDice: 0.7905 - val_loss: 0.4926 - val_acc: 0.9518 - val_mDice: 0.6022

Epoch 00129: val_mDice did not improve from 0.60907
Epoch 130/300
 - 13s - loss: 0.2191 - acc: 0.9573 - mDice: 0.7914 - val_loss: 0.5088 - val_acc: 0.9506 - val_mDice: 0.5884

Epoch 00130: val_mDice did not improve from 0.60907
Epoch 131/300
 - 13s - loss: 0.2203 - acc: 0.9573 - mDice: 0.7904 - val_loss: 0.5260 - val_acc: 0.9525 - val_mDice: 0.5872

Epoch 00131: val_mDice did not improve from 0.60907
Epoch 132/300
 - 12s - loss: 0.2194 - acc: 0.9573 - mDice: 0.7912 - val_loss: 0.4990 - val_acc: 0.9523 - val_mDice: 0.5981

Epoch 00132: val_mDice did not improve from 0.60907
Epoch 133/300
 - 13s - loss: 0.2197 - acc: 0.9573 - mDice: 0.7909 - val_loss: 0.4901 - val_acc: 0.9512 - val_mDice: 0.6010

Epoch 00133: val_mDice did not improve from 0.60907
Epoch 134/300
 - 13s - loss: 0.2187 - acc: 0.9574 - mDice: 0.7917 - val_loss: 0.4748 - val_acc: 0.9510 - val_mDice: 0.6105

Epoch 00134: val_mDice improved from 0.60907 to 0.61045, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 135/300
 - 12s - loss: 0.2189 - acc: 0.9574 - mDice: 0.7915 - val_loss: 0.5056 - val_acc: 0.9536 - val_mDice: 0.5951

Epoch 00135: val_mDice did not improve from 0.61045
Epoch 136/300
 - 13s - loss: 0.2188 - acc: 0.9574 - mDice: 0.7916 - val_loss: 0.5061 - val_acc: 0.9517 - val_mDice: 0.5949

Epoch 00136: val_mDice did not improve from 0.61045
Epoch 137/300
 - 13s - loss: 0.2182 - acc: 0.9574 - mDice: 0.7921 - val_loss: 0.5312 - val_acc: 0.9491 - val_mDice: 0.5766

Epoch 00137: val_mDice did not improve from 0.61045
Epoch 138/300
 - 12s - loss: 0.2182 - acc: 0.9574 - mDice: 0.7921 - val_loss: 0.5680 - val_acc: 0.9476 - val_mDice: 0.5582

Epoch 00138: val_mDice did not improve from 0.61045
Epoch 139/300
 - 13s - loss: 0.2186 - acc: 0.9574 - mDice: 0.7918 - val_loss: 0.4867 - val_acc: 0.9538 - val_mDice: 0.6066

Epoch 00139: val_mDice did not improve from 0.61045
Epoch 140/300
 - 13s - loss: 0.2189 - acc: 0.9574 - mDice: 0.7916 - val_loss: 0.5193 - val_acc: 0.9535 - val_mDice: 0.5931

Epoch 00140: val_mDice did not improve from 0.61045
Epoch 141/300
 - 12s - loss: 0.2169 - acc: 0.9575 - mDice: 0.7932 - val_loss: 0.4981 - val_acc: 0.9520 - val_mDice: 0.5972

Epoch 00141: val_mDice did not improve from 0.61045
Epoch 142/300
 - 13s - loss: 0.2175 - acc: 0.9575 - mDice: 0.7926 - val_loss: 0.5423 - val_acc: 0.9505 - val_mDice: 0.5756

Epoch 00142: val_mDice did not improve from 0.61045
Epoch 143/300
 - 13s - loss: 0.2172 - acc: 0.9575 - mDice: 0.7930 - val_loss: 0.5037 - val_acc: 0.9514 - val_mDice: 0.5919

Epoch 00143: val_mDice did not improve from 0.61045
Epoch 144/300
 - 12s - loss: 0.2168 - acc: 0.9575 - mDice: 0.7933 - val_loss: 0.5178 - val_acc: 0.9532 - val_mDice: 0.5902

Epoch 00144: val_mDice did not improve from 0.61045
Epoch 145/300
 - 13s - loss: 0.2188 - acc: 0.9574 - mDice: 0.7916 - val_loss: 0.5072 - val_acc: 0.9526 - val_mDice: 0.5927

Epoch 00145: val_mDice did not improve from 0.61045
Epoch 146/300
 - 12s - loss: 0.2163 - acc: 0.9576 - mDice: 0.7938 - val_loss: 0.4845 - val_acc: 0.9519 - val_mDice: 0.6045

Epoch 00146: val_mDice did not improve from 0.61045
Epoch 147/300
 - 13s - loss: 0.2164 - acc: 0.9576 - mDice: 0.7936 - val_loss: 0.4901 - val_acc: 0.9523 - val_mDice: 0.6029

Epoch 00147: val_mDice did not improve from 0.61045
Epoch 148/300
 - 13s - loss: 0.2153 - acc: 0.9577 - mDice: 0.7945 - val_loss: 0.4846 - val_acc: 0.9528 - val_mDice: 0.6038

Epoch 00148: val_mDice did not improve from 0.61045
Epoch 149/300
 - 12s - loss: 0.2155 - acc: 0.9576 - mDice: 0.7944 - val_loss: 0.5313 - val_acc: 0.9513 - val_mDice: 0.5818

Epoch 00149: val_mDice did not improve from 0.61045
Epoch 150/300
 - 13s - loss: 0.2163 - acc: 0.9576 - mDice: 0.7937 - val_loss: 0.5331 - val_acc: 0.9482 - val_mDice: 0.5731

Epoch 00150: val_mDice did not improve from 0.61045
Epoch 151/300
 - 13s - loss: 0.2178 - acc: 0.9576 - mDice: 0.7925 - val_loss: 0.4959 - val_acc: 0.9509 - val_mDice: 0.5971

Epoch 00151: val_mDice did not improve from 0.61045
Epoch 152/300
 - 14s - loss: 0.2156 - acc: 0.9576 - mDice: 0.7943 - val_loss: 0.5147 - val_acc: 0.9522 - val_mDice: 0.5892

Epoch 00152: val_mDice did not improve from 0.61045
Epoch 153/300
 - 14s - loss: 0.2160 - acc: 0.9577 - mDice: 0.7941 - val_loss: 0.5358 - val_acc: 0.9534 - val_mDice: 0.5863

Epoch 00153: val_mDice did not improve from 0.61045
Epoch 154/300
 - 13s - loss: 0.2162 - acc: 0.9577 - mDice: 0.7938 - val_loss: 0.5314 - val_acc: 0.9513 - val_mDice: 0.5827

Epoch 00154: val_mDice did not improve from 0.61045
Epoch 155/300
 - 14s - loss: 0.2155 - acc: 0.9577 - mDice: 0.7944 - val_loss: 0.5285 - val_acc: 0.9543 - val_mDice: 0.5877

Epoch 00155: val_mDice did not improve from 0.61045
Epoch 156/300
 - 14s - loss: 0.2151 - acc: 0.9577 - mDice: 0.7948 - val_loss: 0.5061 - val_acc: 0.9508 - val_mDice: 0.5919

Epoch 00156: val_mDice did not improve from 0.61045
Epoch 157/300
 - 14s - loss: 0.2157 - acc: 0.9576 - mDice: 0.7943 - val_loss: 0.5095 - val_acc: 0.9528 - val_mDice: 0.5935

Epoch 00157: val_mDice did not improve from 0.61045
Epoch 158/300
 - 14s - loss: 0.2148 - acc: 0.9577 - mDice: 0.7949 - val_loss: 0.5226 - val_acc: 0.9505 - val_mDice: 0.5830

Epoch 00158: val_mDice did not improve from 0.61045
Epoch 159/300
 - 13s - loss: 0.2137 - acc: 0.9578 - mDice: 0.7960 - val_loss: 0.5021 - val_acc: 0.9526 - val_mDice: 0.5950

Epoch 00159: val_mDice did not improve from 0.61045
Epoch 160/300
 - 14s - loss: 0.2147 - acc: 0.9577 - mDice: 0.7950 - val_loss: 0.5047 - val_acc: 0.9522 - val_mDice: 0.5949

Epoch 00160: val_mDice did not improve from 0.61045
Epoch 161/300
 - 14s - loss: 0.2136 - acc: 0.9578 - mDice: 0.7960 - val_loss: 0.5390 - val_acc: 0.9506 - val_mDice: 0.5749

Epoch 00161: val_mDice did not improve from 0.61045
Epoch 162/300
 - 14s - loss: 0.2141 - acc: 0.9579 - mDice: 0.7956 - val_loss: 0.5208 - val_acc: 0.9495 - val_mDice: 0.5834

Epoch 00162: val_mDice did not improve from 0.61045
Epoch 163/300
 - 14s - loss: 0.2138 - acc: 0.9578 - mDice: 0.7958 - val_loss: 0.5322 - val_acc: 0.9509 - val_mDice: 0.5772

Epoch 00163: val_mDice did not improve from 0.61045
Epoch 164/300
 - 14s - loss: 0.2140 - acc: 0.9578 - mDice: 0.7957 - val_loss: 0.5364 - val_acc: 0.9524 - val_mDice: 0.5769

Epoch 00164: val_mDice did not improve from 0.61045
Epoch 165/300
 - 15s - loss: 0.2126 - acc: 0.9579 - mDice: 0.7968 - val_loss: 0.5017 - val_acc: 0.9524 - val_mDice: 0.5969

Epoch 00165: val_mDice did not improve from 0.61045
Epoch 166/300
 - 14s - loss: 0.2134 - acc: 0.9578 - mDice: 0.7962 - val_loss: 0.5069 - val_acc: 0.9518 - val_mDice: 0.5917

Epoch 00166: val_mDice did not improve from 0.61045
Epoch 167/300
 - 14s - loss: 0.2134 - acc: 0.9579 - mDice: 0.7962 - val_loss: 0.4907 - val_acc: 0.9531 - val_mDice: 0.6025

Epoch 00167: val_mDice did not improve from 0.61045
Epoch 168/300
 - 14s - loss: 0.2135 - acc: 0.9579 - mDice: 0.7960 - val_loss: 0.5251 - val_acc: 0.9507 - val_mDice: 0.5829

Epoch 00168: val_mDice did not improve from 0.61045
Epoch 169/300
 - 14s - loss: 0.2122 - acc: 0.9579 - mDice: 0.7971 - val_loss: 0.5028 - val_acc: 0.9523 - val_mDice: 0.5944

Epoch 00169: val_mDice did not improve from 0.61045
Epoch 170/300
 - 14s - loss: 0.2136 - acc: 0.9580 - mDice: 0.7961 - val_loss: 0.5390 - val_acc: 0.9497 - val_mDice: 0.5762

Epoch 00170: val_mDice did not improve from 0.61045
Epoch 171/300
 - 14s - loss: 0.2118 - acc: 0.9580 - mDice: 0.7975 - val_loss: 0.5424 - val_acc: 0.9521 - val_mDice: 0.5798

Epoch 00171: val_mDice did not improve from 0.61045
Epoch 172/300
 - 14s - loss: 0.2118 - acc: 0.9580 - mDice: 0.7974 - val_loss: 0.5079 - val_acc: 0.9510 - val_mDice: 0.5896

Epoch 00172: val_mDice did not improve from 0.61045
Epoch 173/300
 - 14s - loss: 0.2124 - acc: 0.9580 - mDice: 0.7970 - val_loss: 0.5191 - val_acc: 0.9506 - val_mDice: 0.5849

Epoch 00173: val_mDice did not improve from 0.61045
Epoch 174/300
 - 14s - loss: 0.2115 - acc: 0.9580 - mDice: 0.7978 - val_loss: 0.5152 - val_acc: 0.9527 - val_mDice: 0.5902

Epoch 00174: val_mDice did not improve from 0.61045
Restoring model weights from the end of the best epoch
Epoch 00174: early stopping
{'val_loss': [0.8921169162462543, 0.6055469020118927, 0.6138265112924842, 0.6210724544924731, 0.559118421717063, 0.5256920014013792, 0.5155329121557694, 0.6333630091651192, 0.49964150403464974, 0.5122077874631189, 0.4946316230896465, 0.5132681580895152, 0.48860317102357664, 0.517957667731706, 0.5605610039647065, 0.5454413038392306, 0.5978409468128695, 0.5534249687328019, 0.5167988125838381, 0.5504311989139579, 0.5434290650170609, 0.5509701667551222, 0.5092111915849441, 0.5613068951574783, 0.546715569895739, 0.5207028092618761, 0.5568859224212902, 0.5325272279744707, 0.5264096503151195, 0.5429797095959413, 0.512843776015596, 0.5633210130243994, 0.5596559743641475, 0.5095523898827963, 0.5122801974499026, 0.5252467896685254, 0.49800968702944964, 0.5248372135215631, 0.5127548355629991, 0.5356081970577133, 0.5215954277768481, 0.5114648954828358, 0.5970470572317113, 0.4862597824474953, 0.5111855997719579, 0.5460354605866544, 0.5363287166510214, 0.5635016530585688, 0.5061298595460434, 0.4984024393491905, 0.5438712755395048, 0.5110857013883537, 0.511192927147423, 0.4997967894516844, 0.5168533854644392, 0.4961863682922704, 0.5651137952032036, 0.5015287562455545, 0.5062436754477091, 0.5233038966882162, 0.4974691078649553, 0.5378125969258101, 0.5305208856833048, 0.5088723421762775, 0.5034013796785024, 0.5100419967534155, 0.4822684113539797, 0.5250262338355933, 0.4971318507993687, 0.5225945571281391, 0.4874714276644105, 0.5357482110321855, 0.508859155231348, 0.5439524307597283, 0.4999276303046242, 0.5213422495559608, 0.500667834748103, 0.5048307569999269, 0.52086591620685, 0.5012508477578616, 0.5150034837216638, 0.5330481535895577, 0.47963818125218655, 0.5474147740023096, 0.4989530643937308, 0.553073664617272, 0.5092715541077726, 0.539598205902057, 0.5150206138967802, 0.4951593506269615, 0.5046044504842279, 0.5018984955116357, 0.555486124654056, 0.5456385329448977, 0.5248305641073089, 0.47741505220615665, 0.5164276717761376, 0.5389389545557886, 0.505135320085387, 0.5262574293759948, 0.4910914691466859, 0.5651863480413426, 0.4950266120820072, 0.5169339353145834, 0.5427423539108405, 0.5145968878069404, 0.4995172816281878, 0.5071535217029423, 0.5138469974421922, 0.509446937944636, 0.4919245809150142, 0.5385002696980311, 0.5456096440054184, 0.5235702681807832, 0.5269931764576022, 0.535389459998914, 0.5025505147166758, 0.5015502475493447, 0.553337096501995, 0.5520629323394605, 0.48609447212858575, 0.5245356859441576, 0.5212822736308561, 0.4991687599507124, 0.4776778763898924, 0.5193557333013865, 0.509069671843971, 0.5632318534664602, 0.49260000077039834, 0.5087827876959433, 0.5259793800348677, 0.4990485716798452, 0.4900616647144936, 0.4748437794227174, 0.5056471441711128, 0.5061214962485117, 0.5311508505038043, 0.5680186135808849, 0.4867163087402642, 0.5192527471307936, 0.4980655692143147, 0.5423072566533221, 0.5036977496227073, 0.5178260533503314, 0.5071871134155955, 0.48449031600739034, 0.490115081797765, 0.4845942375380234, 0.5313214819524541, 0.5330734769059293, 0.4958677112057222, 0.5147265262443926, 0.5358064950511442, 0.5313561405549502, 0.5284996512215897, 0.5061432556067099, 0.5095192570260118, 0.5226094732737409, 0.5020565826799617, 0.5047011658466062, 0.5390101028554266, 0.5208022021714536, 0.5322380005980337, 0.536367431033257, 0.5016959852346495, 0.5068663851508881, 0.49069268343834904, 0.5251331455880703, 0.5028272141291442, 0.5390150610295088, 0.5423996531763556, 0.5079397159581743, 0.519096367518995, 0.5152194300177377], 'val_acc': [0.9190687870180141, 0.9333307123716983, 0.9402850533330906, 0.9436361706456659, 0.9449790962581528, 0.9487620458922572, 0.9494872019943579, 0.9433944305228121, 0.9487723425113955, 0.9485058218407232, 0.950925181031893, 0.949571903857439, 0.9510470632068272, 0.9489211147057943, 0.9480347896421422, 0.9469459782765565, 0.947102978575829, 0.9466794779180815, 0.9498136306608189, 0.9492537209441542, 0.947148447596161, 0.9444026614034642, 0.9500388466446094, 0.9487331036748833, 0.9510635996664036, 0.9491855495468864, 0.9465286365434444, 0.9517433430229485, 0.9505904629909793, 0.9470699263018603, 0.9505202200825654, 0.9444274446151776, 0.9468571200717095, 0.9509107124206074, 0.9510264180226033, 0.9477517425014986, 0.9520201866187197, 0.9497557765278737, 0.9503260128324924, 0.9476236191541789, 0.951656561990024, 0.9509726756111869, 0.949367363692662, 0.9508631892044451, 0.9490739972897748, 0.9478446807941245, 0.9498983415145448, 0.948710387645487, 0.9486959183682276, 0.9511917130241181, 0.9488178095338065, 0.9507557719779414, 0.9521193437736127, 0.9494851507954092, 0.9502908767268644, 0.9513673106385343, 0.9502826276438197, 0.9534023777066662, 0.9506565685378773, 0.9470389538637086, 0.9512949942210533, 0.9478446957785324, 0.9490595396670549, 0.9515925056441537, 0.9524602460461622, 0.9480079252626643, 0.9523796805456364, 0.9505987423758268, 0.9511379879280175, 0.9510346947435561, 0.9499995738434392, 0.9479335409968925, 0.9518362936360876, 0.9487909278390128, 0.9511400424568347, 0.9504850976293979, 0.9528631384812254, 0.9510326115778704, 0.9511214244965068, 0.9521854906108792, 0.9504933527062059, 0.9526317249463258, 0.9523218224168489, 0.9495243906308819, 0.9524519959641569, 0.9507433725468939, 0.9522825929039683, 0.9495285333201872, 0.9514995563629619, 0.9524664512559688, 0.9517350802874432, 0.9498818193734025, 0.9470699529408076, 0.949929318947499, 0.9491008723248316, 0.9525842167145713, 0.952718497987566, 0.949175234280485, 0.9514788878696591, 0.9505408925717104, 0.949323980834897, 0.9506958366772316, 0.9510181556200848, 0.9532783970486518, 0.9514933458253658, 0.9521813462566397, 0.9522949447178973, 0.9493260370286484, 0.9524271941051803, 0.9513135822125653, 0.9500161359430025, 0.9491235683750174, 0.9472703537461478, 0.9478343631968152, 0.9509499592488039, 0.9507392371832991, 0.9528114862282183, 0.9511111275443818, 0.949098791490054, 0.9454687344295353, 0.9509086372466061, 0.9524395868764909, 0.9502454356774271, 0.951714416788943, 0.9517556984997328, 0.950127663226101, 0.9525366755171195, 0.9509045162014456, 0.9518362803166139, 0.9506173480156414, 0.9524602383874649, 0.9523487041116426, 0.9512247656310737, 0.950985082367945, 0.9536213774920842, 0.9516689467696504, 0.9491401111613439, 0.9476215742819802, 0.9537701213826014, 0.9534540336225286, 0.9520305038830421, 0.9505078363018995, 0.9513776235740278, 0.9532350005384264, 0.9525821511971884, 0.9519457916973689, 0.9523238952599424, 0.9527515672438638, 0.9512929426891178, 0.9481876582406753, 0.9508755909664005, 0.9522350523724902, 0.9533817128762186, 0.9513073936521008, 0.9542845640768552, 0.950759878371681, 0.9528011533135142, 0.950522300917343, 0.9525573423454882, 0.9521999365790597, 0.9506007872480254, 0.9494644809701589, 0.950945840867538, 0.952390010130472, 0.9524230707291118, 0.951836286643364, 0.953080054767971, 0.950720634540366, 0.9522825755886526, 0.9496876044646322, 0.9521358782352682, 0.9509665186844725, 0.950557430696221, 0.9527205631719621], 'val_mDice': [0.40959339118536625, 0.5331282392560437, 0.5277535908715019, 0.5398392624029235, 0.5591879290575422, 0.5825920045042837, 0.5860886207505978, 0.5323464147871433, 0.5958580744333107, 0.5865672407203546, 0.5967034028229101, 0.588647987256503, 0.6024455514700053, 0.5848875788337026, 0.5688426484608783, 0.5753870959388477, 0.5418932524473308, 0.5624659900558727, 0.5878231898366406, 0.5689782453648871, 0.5753923088478643, 0.5641198025069423, 0.5908857171095949, 0.5621354273577642, 0.5770303224052131, 0.5868707688827088, 0.5666555585807929, 0.5813925799044817, 0.5834124937403802, 0.5726445880016136, 0.5909386377094844, 0.5577535096493513, 0.5603820698221302, 0.5935569638646515, 0.5908339456472983, 0.5779048953642393, 0.5993029718292492, 0.583652601228746, 0.5910746178813486, 0.5741478617630857, 0.588402794726068, 0.5932429143170405, 0.550163255723495, 0.6049041588213191, 0.5926711825685128, 0.5710180358513773, 0.5765448239262544, 0.570421874190176, 0.5897596478462219, 0.5975759295777902, 0.5701088412513946, 0.5900979994395592, 0.5906012084897004, 0.5965460099321503, 0.5885899769527286, 0.5983651217135637, 0.5698087335298847, 0.6011503042455492, 0.5919285966031378, 0.5810788650086472, 0.5991019763094086, 0.572324894660012, 0.5761105481472761, 0.592325426013776, 0.5964462021209674, 0.5867978660753985, 0.6062882209623326, 0.5826660681037263, 0.5973448340453249, 0.584708862797508, 0.6028575930515481, 0.5726276299806946, 0.5947526686684379, 0.5747596588214683, 0.5954526479683775, 0.5828471546732513, 0.5977843120777407, 0.5929513537017993, 0.5864328828603862, 0.5962807293044788, 0.5885591753368271, 0.5814510840277433, 0.6076103895070166, 0.5689310035226065, 0.598002411466737, 0.5746558841380327, 0.5918004948999629, 0.5753363124485122, 0.5874246944928302, 0.599676536448175, 0.5951026887867038, 0.591703772211874, 0.5617412328720093, 0.5736688425421049, 0.5807249825759973, 0.6089442139231293, 0.5891145897311205, 0.5745834894686438, 0.596228400755195, 0.5803030113268165, 0.5994834307185765, 0.568858783338323, 0.5964015632368332, 0.5892183194613324, 0.5799826093892145, 0.5906467893936115, 0.5965416721125555, 0.5904603880210961, 0.5904643658819145, 0.5921938419342041, 0.5988203280464897, 0.5752840631500968, 0.5683431072608053, 0.5815319602049929, 0.5832870502711675, 0.5789893026458485, 0.5948928494693181, 0.597006722535501, 0.5660486108097951, 0.5639672825456331, 0.6035023618010835, 0.5869811513570434, 0.5839659102136197, 0.5955103502593226, 0.6090742835785423, 0.5857615024683862, 0.5918610595458047, 0.5677055606628929, 0.6022399584008329, 0.5884225848000809, 0.587222135599765, 0.598123079571644, 0.6010136174756056, 0.6104538487322504, 0.5950586609334253, 0.594900506834744, 0.5766337324121145, 0.5582289409371062, 0.6065681516791189, 0.5930528161246017, 0.5971606164005215, 0.5755607628955521, 0.5919369459152222, 0.5901739524063452, 0.592655854851174, 0.6044619229918752, 0.6028914884482016, 0.6037750473901546, 0.5818109142713707, 0.5730933756801669, 0.5971125477519115, 0.5892366347366205, 0.5863349457692834, 0.5826915872163613, 0.5876704943912655, 0.5918772733411309, 0.5935077440805275, 0.5829900732919491, 0.5950037447433898, 0.5948522936698445, 0.5749268421913658, 0.5833632010321378, 0.577235236514214, 0.5769015434068009, 0.5969275835506077, 0.5916614718943335, 0.6025308197437051, 0.5829206478662331, 0.5944286874552679, 0.5762218436715323, 0.5798487689907991, 0.589642352232054, 0.5849432625584097, 0.5902307353206186], 'loss': [2.0082401688351728, 0.7087419942815892, 0.5738710175541698, 0.5103937684499544, 0.46783523058736776, 0.4419704744235524, 0.4194709697691523, 0.40336640908349203, 0.38951086945721, 0.3750054652729453, 0.3665647904770702, 0.35802323202650294, 0.3493459693380226, 0.34292915376285393, 0.33606534419473455, 0.32922570220162345, 0.32626931033884476, 0.32174674997720043, 0.31804527694457924, 0.3123287857098229, 0.30970312809413064, 0.30513518825185554, 0.30263610757077014, 0.2992310271557364, 0.2949015571932655, 0.2949479705455302, 0.2911234845585192, 0.2888740358834537, 0.28396725245572846, 0.2822460351079373, 0.28316711239530123, 0.2798371741447851, 0.2792852417516732, 0.27581788802139123, 0.2739315230510352, 0.27249546167825955, 0.271105750926952, 0.2693016150633849, 0.2703931618896382, 0.26819795403538443, 0.26654351295504747, 0.26291767733366256, 0.26174825482505854, 0.26330144047724136, 0.260754697554369, 0.2596414129196848, 0.2575240607223936, 0.25877879956930616, 0.25662803367964354, 0.2551084305133625, 0.2565811503966463, 0.2532200951503127, 0.25266170306121605, 0.25148288721882056, 0.25127673880979, 0.2507724824761859, 0.25006285584587773, 0.24877522358768522, 0.24800919961610537, 0.24647542431664085, 0.24769411358228988, 0.24656145825854678, 0.24488186878606416, 0.24423050032670407, 0.24490551801718863, 0.24283156137984274, 0.24275783687646557, 0.24238948430830498, 0.2418482542138598, 0.23977949058695963, 0.23962495776895512, 0.24001094857404762, 0.2382615879320071, 0.2383910215395701, 0.23850008734875167, 0.23750279796168303, 0.2373584602047406, 0.23670752910797416, 0.2348836258075692, 0.23514390490061707, 0.23566207209350717, 0.23384151732692415, 0.2352473303342098, 0.23342583202814512, 0.23264727474839902, 0.23264746844888637, 0.23300491855295907, 0.23335057437617912, 0.23190261950375216, 0.231032418667293, 0.23119890394926812, 0.23162071958381453, 0.22961951517525092, 0.2307754893197349, 0.22960888541677757, 0.23083958371740873, 0.2281175264970493, 0.22819999272228877, 0.22854289833376543, 0.22814893954073925, 0.2276730501892312, 0.22719243101633216, 0.22688864957668847, 0.22642539071998438, 0.2264862297434841, 0.2255892265776937, 0.2267584531434539, 0.2253507529508898, 0.2249657941013242, 0.2245820812650914, 0.22423416563910237, 0.22438896593299087, 0.22440132472689886, 0.223281671921384, 0.22304185184996916, 0.22235754558018275, 0.22387526260810534, 0.22337007006264792, 0.2220385403810948, 0.22276265727029726, 0.22225655570774774, 0.22176548539147606, 0.22010387947315108, 0.22156709446723175, 0.2208501446997637, 0.22076422519270525, 0.22011702815926443, 0.22114141027260356, 0.22015645076010418, 0.2191061432395299, 0.22032095782264413, 0.2193754447799487, 0.21969588270365142, 0.2187315075477739, 0.21894659992250817, 0.2188211888655956, 0.2182187053053008, 0.2182016620532885, 0.21863176796724706, 0.21887821576205885, 0.21686713926725013, 0.21754216613573327, 0.2171946241944439, 0.21675303642490476, 0.21882861175394144, 0.21626273702642806, 0.21642821162726442, 0.21527684062279476, 0.2154717983182015, 0.2163103637662655, 0.21775750342806624, 0.21563128798260264, 0.21596087438742337, 0.21622565568279034, 0.2155425918432734, 0.21505017829781478, 0.21566911531191987, 0.21482503938831396, 0.2136561122457288, 0.21471622559306316, 0.21361841907474471, 0.21407283657526607, 0.2138133513421692, 0.2139504898515417, 0.21260820280576503, 0.21339164156908824, 0.21341399144752374, 0.2135203115020817, 0.21224723253710573, 0.21356423378938633, 0.21179172663015775, 0.21184842068884382, 0.21235908142644902, 0.2114776555552448], 'acc': [0.7840228620797913, 0.901396314239237, 0.9159461421700619, 0.9311820995599237, 0.9357949599195985, 0.9381371222188495, 0.940098303389909, 0.9416382026259439, 0.9428019300699688, 0.9439418099426599, 0.9448469005783596, 0.9455384277783216, 0.9462639927558926, 0.9467971036165512, 0.9474125552505951, 0.9478822209127237, 0.9481313340018942, 0.9486392692253289, 0.9490071802018262, 0.9493672516921086, 0.9496283878961177, 0.9499806058211405, 0.9502883731075559, 0.9505984746392442, 0.9509152437365332, 0.9509957736662079, 0.9512642607937697, 0.9513644476022851, 0.9517892570279015, 0.9519430955220759, 0.9518966493533332, 0.9520698092152731, 0.9522383539390086, 0.9524447281767967, 0.9525905930459009, 0.9527318867506865, 0.9528522740703192, 0.9530163294096072, 0.9529635623145302, 0.9531692663969203, 0.9532651217646941, 0.9535526241795714, 0.9536360297046724, 0.9535172979664578, 0.9537934402768684, 0.9537949499549718, 0.9540339092057577, 0.9539483500445021, 0.9540950806628749, 0.9542143810068715, 0.9540504261751488, 0.954383472420864, 0.9544368269500516, 0.9545167475528145, 0.9545673020173896, 0.954651094165985, 0.9546173992100367, 0.9547747433961434, 0.9548951922324701, 0.9550190637310465, 0.9549472790016055, 0.9549821457028694, 0.9550900004812656, 0.9551381410372607, 0.9551103664317114, 0.9553374230754537, 0.9552792329835214, 0.9553192744333755, 0.9553341430540238, 0.9555511656270282, 0.9555369282747872, 0.9554706812684011, 0.9555841826755012, 0.955597293285378, 0.955640678328241, 0.9557032586020534, 0.9557668456200986, 0.9557868268883155, 0.9558631438139276, 0.9558727104681638, 0.9558310954407548, 0.9559983967579071, 0.9559471949364429, 0.9560406523899773, 0.9561148334592199, 0.956150022417065, 0.9561247440485853, 0.9561207773774922, 0.9562244247646154, 0.9562646088358118, 0.9563408431245393, 0.9562674498293149, 0.956388622163642, 0.9563872714972653, 0.9565190599249194, 0.956348920659259, 0.9565509646866396, 0.9565274575379775, 0.9565351526790842, 0.9565504606522854, 0.9565666541380078, 0.9566768297870709, 0.9566573122118911, 0.9567087928029903, 0.956761407125659, 0.9567328638406135, 0.9567105476129458, 0.9566811594618451, 0.9568186261919964, 0.9568160074636649, 0.9568648517479156, 0.956910935390178, 0.9568848740586424, 0.9569653197997186, 0.9569748648955186, 0.9570299943063093, 0.9569297096197021, 0.9570129356394146, 0.9570514857850169, 0.9570202256241082, 0.9570595240918881, 0.9570783363870985, 0.9572235368661687, 0.9571339682383277, 0.9571214767298624, 0.9571671992545229, 0.9572406383123242, 0.9571374101996143, 0.9572180970439295, 0.9573350020966676, 0.9572979817397713, 0.9572964522951692, 0.957325152183214, 0.9574319666380274, 0.9573549607027187, 0.957395022675451, 0.9573761115120385, 0.9574330921922592, 0.9573987080870251, 0.9573863413876538, 0.9575022404330611, 0.9575229441247652, 0.9574859411873191, 0.9575320073387136, 0.9574149225565949, 0.9576449855844749, 0.9575811720518991, 0.9576697976856305, 0.9576367673729248, 0.9575563594735427, 0.9575689064476668, 0.9576256866970845, 0.9576810557210792, 0.9576562423344032, 0.9576699759087449, 0.9577206546857359, 0.9576469374945673, 0.957700433979613, 0.9577853311335922, 0.9577228932441446, 0.9578387475820105, 0.9578660001072267, 0.957813327559575, 0.9578002751584498, 0.957908517602391, 0.9578487352052095, 0.957887329587645, 0.9579183468696085, 0.9579381252982947, 0.9579663656972136, 0.9580402834944837, 0.9579968389703339, 0.9579629401814982, 0.9580077760996469], 'mDice': [0.21717297493596657, 0.4777419112306633, 0.5485975418914851, 0.5859572669012043, 0.6116490857766466, 0.6282569995977463, 0.6428036406424419, 0.6536862995816591, 0.6629455817998167, 0.6727586464388206, 0.6788349876015036, 0.6848066163169527, 0.6910340211586354, 0.6955932235154222, 0.7005600972338171, 0.7053345330049384, 0.7076400971790524, 0.7111561288826347, 0.7138254609504535, 0.717905811566581, 0.7201707188934161, 0.7233761827200756, 0.7253286192330275, 0.7278757183635283, 0.73113695442933, 0.7310903973649786, 0.7340653516207312, 0.7357013784497075, 0.7394958587521516, 0.740707291937895, 0.7401193575683512, 0.7426934901467271, 0.743125965357489, 0.7458162275666174, 0.7472922353954605, 0.7484455349580258, 0.7494678883295187, 0.7508961527664789, 0.7500522118639007, 0.751774824118148, 0.7530401844512429, 0.7558326528752903, 0.756774507942208, 0.7556359092496228, 0.757683320909237, 0.7584608878992487, 0.7602378037278282, 0.7591987321121125, 0.7608709749745152, 0.7620232172907259, 0.7608942605656909, 0.7635524902823677, 0.7639891986370113, 0.7649023923295547, 0.765110242416134, 0.7655692865019965, 0.7661257874348228, 0.7671446217040689, 0.7677385250757635, 0.7689731932499265, 0.7679807348621677, 0.7689349144854634, 0.7703026746016793, 0.7708653685288404, 0.7702079933392548, 0.7719035467371222, 0.7719279244914631, 0.7722184131214428, 0.7726871689954917, 0.7743747543226458, 0.7745009812581033, 0.7741612144839978, 0.7755362446820656, 0.7755154199371942, 0.7754097165290609, 0.7762412424700679, 0.7763690879503228, 0.7768158825626366, 0.7783481167699055, 0.7781829951466652, 0.7777537655209698, 0.7791974524852789, 0.7780053103049981, 0.7795427510872248, 0.780171999383496, 0.7802034084083117, 0.7798888121066248, 0.7796287529154687, 0.7807890958603181, 0.78152834025157, 0.7813763831034575, 0.7810278074374276, 0.7826763953098342, 0.7817410638919161, 0.7827420161963873, 0.7816903693283457, 0.7838716949228952, 0.783881211977471, 0.7835810765917022, 0.7839139098760369, 0.7843316375647655, 0.7847427362599967, 0.7849061553868182, 0.7853242546006697, 0.7852371125158665, 0.7859831165692157, 0.7850642764687142, 0.7862052958902791, 0.7865105037316278, 0.786809133526339, 0.7871578965115136, 0.7869818479717053, 0.7869935003372781, 0.7879331254159228, 0.7881660712167177, 0.7886503073496663, 0.7873676100799665, 0.787830696741056, 0.788947656201249, 0.7883727238735442, 0.7887624809051299, 0.789209352570755, 0.7905276459219487, 0.7893502705627379, 0.7898725015873886, 0.7899458565312555, 0.7905180652113913, 0.7897026703888915, 0.7905012821327931, 0.7914198002753697, 0.7904007738662775, 0.7911747022428502, 0.7909162676312955, 0.7916750886018133, 0.7915340704009214, 0.791623557677398, 0.7920849903931864, 0.7921296236957965, 0.7918494485457033, 0.7915931768091693, 0.7932092718137687, 0.7926491870482005, 0.7929635424057153, 0.7932962052255056, 0.7916240143390284, 0.7937696081615145, 0.7936320148627941, 0.7945490210873455, 0.7944011612594482, 0.7937444619289457, 0.7925439321600685, 0.7942943629872584, 0.7940652910338969, 0.7937838395211531, 0.7943665544702742, 0.7947594937003845, 0.7942515846158638, 0.7949302278503303, 0.7959742731378265, 0.7950459045072077, 0.7959939840312461, 0.7956186931388167, 0.7957599185130012, 0.7957023071519469, 0.7968231708153837, 0.7961648279243769, 0.7962117063590796, 0.7960485389994728, 0.7970964489020291, 0.7960659330962861, 0.7974870657000197, 0.7974414630793492, 0.7970307351690927, 0.7977592350350935]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.23s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.04s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.86s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:50,  1.87s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:21,  1.77s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:21,  1.78s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:55,  1.69s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:09,  1.75s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<07:40,  1.65s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:58,  1.72s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:56,  1.72s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:34,  1.86s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:55,  1.95s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:29,  1.86s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:43,  1.92s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:18,  1.83s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<08:16,  1.83s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:30,  1.89s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<08:43,  1.95s/it]predicting train subjects:   6%|▌         | 17/285 [00:30<08:20,  1.87s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:26,  1.90s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<08:07,  1.83s/it]predicting train subjects:   7%|▋         | 20/285 [00:36<08:19,  1.89s/it]predicting train subjects:   7%|▋         | 21/285 [00:38<08:32,  1.94s/it]predicting train subjects:   8%|▊         | 22/285 [00:40<08:06,  1.85s/it]predicting train subjects:   8%|▊         | 23/285 [00:42<08:04,  1.85s/it]predicting train subjects:   8%|▊         | 24/285 [00:43<07:53,  1.81s/it]predicting train subjects:   9%|▉         | 25/285 [00:45<08:15,  1.91s/it]predicting train subjects:   9%|▉         | 26/285 [00:48<08:24,  1.95s/it]predicting train subjects:   9%|▉         | 27/285 [00:49<08:00,  1.86s/it]predicting train subjects:  10%|▉         | 28/285 [00:51<08:01,  1.87s/it]predicting train subjects:  10%|█         | 29/285 [00:53<07:53,  1.85s/it]predicting train subjects:  11%|█         | 30/285 [00:55<08:10,  1.93s/it]predicting train subjects:  11%|█         | 31/285 [00:57<08:20,  1.97s/it]predicting train subjects:  11%|█         | 32/285 [00:59<07:49,  1.85s/it]predicting train subjects:  12%|█▏        | 33/285 [01:01<07:56,  1.89s/it]predicting train subjects:  12%|█▏        | 34/285 [01:02<07:49,  1.87s/it]predicting train subjects:  12%|█▏        | 35/285 [01:04<07:59,  1.92s/it]predicting train subjects:  13%|█▎        | 36/285 [01:06<07:36,  1.83s/it]predicting train subjects:  13%|█▎        | 37/285 [01:08<07:31,  1.82s/it]predicting train subjects:  13%|█▎        | 38/285 [01:10<07:45,  1.88s/it]predicting train subjects:  14%|█▎        | 39/285 [01:12<07:31,  1.83s/it]predicting train subjects:  14%|█▍        | 40/285 [01:13<07:29,  1.83s/it]predicting train subjects:  14%|█▍        | 41/285 [01:15<07:27,  1.84s/it]predicting train subjects:  15%|█▍        | 42/285 [01:17<07:13,  1.79s/it]predicting train subjects:  15%|█▌        | 43/285 [01:19<07:21,  1.82s/it]predicting train subjects:  15%|█▌        | 44/285 [01:21<07:38,  1.90s/it]predicting train subjects:  16%|█▌        | 45/285 [01:23<07:20,  1.83s/it]predicting train subjects:  16%|█▌        | 46/285 [01:25<07:33,  1.90s/it]predicting train subjects:  16%|█▋        | 47/285 [01:26<07:22,  1.86s/it]predicting train subjects:  17%|█▋        | 48/285 [01:28<07:16,  1.84s/it]predicting train subjects:  17%|█▋        | 49/285 [01:30<07:29,  1.90s/it]predicting train subjects:  18%|█▊        | 50/285 [01:32<07:26,  1.90s/it]predicting train subjects:  18%|█▊        | 51/285 [01:34<07:45,  1.99s/it]predicting train subjects:  18%|█▊        | 52/285 [01:36<07:20,  1.89s/it]predicting train subjects:  19%|█▊        | 53/285 [01:38<07:16,  1.88s/it]predicting train subjects:  19%|█▉        | 54/285 [01:40<07:29,  1.95s/it]predicting train subjects:  19%|█▉        | 55/285 [01:42<07:08,  1.86s/it]predicting train subjects:  20%|█▉        | 56/285 [01:44<07:07,  1.87s/it]predicting train subjects:  20%|██        | 57/285 [01:45<06:56,  1.83s/it]predicting train subjects:  20%|██        | 58/285 [01:47<07:05,  1.87s/it]predicting train subjects:  21%|██        | 59/285 [01:50<07:32,  2.00s/it]predicting train subjects:  21%|██        | 60/285 [01:52<07:42,  2.06s/it]predicting train subjects:  21%|██▏       | 61/285 [01:53<07:12,  1.93s/it]predicting train subjects:  22%|██▏       | 62/285 [01:55<07:14,  1.95s/it]predicting train subjects:  22%|██▏       | 63/285 [01:57<07:07,  1.92s/it]predicting train subjects:  22%|██▏       | 64/285 [01:59<06:50,  1.86s/it]predicting train subjects:  23%|██▎       | 65/285 [02:01<06:51,  1.87s/it]predicting train subjects:  23%|██▎       | 66/285 [02:03<06:49,  1.87s/it]predicting train subjects:  24%|██▎       | 67/285 [02:05<06:46,  1.86s/it]predicting train subjects:  24%|██▍       | 68/285 [02:06<06:30,  1.80s/it]predicting train subjects:  24%|██▍       | 69/285 [02:08<06:30,  1.81s/it]predicting train subjects:  25%|██▍       | 70/285 [02:10<06:35,  1.84s/it]predicting train subjects:  25%|██▍       | 71/285 [02:12<06:35,  1.85s/it]predicting train subjects:  25%|██▌       | 72/285 [02:14<06:26,  1.82s/it]predicting train subjects:  26%|██▌       | 73/285 [02:15<06:27,  1.83s/it]predicting train subjects:  26%|██▌       | 74/285 [02:17<06:26,  1.83s/it]predicting train subjects:  26%|██▋       | 75/285 [02:19<06:27,  1.84s/it]predicting train subjects:  27%|██▋       | 76/285 [02:21<06:28,  1.86s/it]predicting train subjects:  27%|██▋       | 77/285 [02:23<06:18,  1.82s/it]predicting train subjects:  27%|██▋       | 78/285 [02:24<06:08,  1.78s/it]predicting train subjects:  28%|██▊       | 79/285 [02:26<06:10,  1.80s/it]predicting train subjects:  28%|██▊       | 80/285 [02:28<06:11,  1.81s/it]predicting train subjects:  28%|██▊       | 81/285 [02:30<06:05,  1.79s/it]predicting train subjects:  29%|██▉       | 82/285 [02:32<06:04,  1.80s/it]predicting train subjects:  29%|██▉       | 83/285 [02:33<06:01,  1.79s/it]predicting train subjects:  29%|██▉       | 84/285 [02:35<05:58,  1.78s/it]predicting train subjects:  30%|██▉       | 85/285 [02:37<06:02,  1.81s/it]predicting train subjects:  30%|███       | 86/285 [02:39<06:05,  1.84s/it]predicting train subjects:  31%|███       | 87/285 [02:41<06:04,  1.84s/it]predicting train subjects:  31%|███       | 88/285 [02:43<05:53,  1.79s/it]predicting train subjects:  31%|███       | 89/285 [02:44<05:58,  1.83s/it]predicting train subjects:  32%|███▏      | 90/285 [02:46<05:56,  1.83s/it]predicting train subjects:  32%|███▏      | 91/285 [02:48<05:51,  1.81s/it]predicting train subjects:  32%|███▏      | 92/285 [02:50<05:58,  1.86s/it]predicting train subjects:  33%|███▎      | 93/285 [02:52<05:49,  1.82s/it]predicting train subjects:  33%|███▎      | 94/285 [02:54<05:46,  1.81s/it]predicting train subjects:  33%|███▎      | 95/285 [02:55<05:48,  1.83s/it]predicting train subjects:  34%|███▎      | 96/285 [02:57<05:47,  1.84s/it]predicting train subjects:  34%|███▍      | 97/285 [02:59<05:51,  1.87s/it]predicting train subjects:  34%|███▍      | 98/285 [03:01<05:49,  1.87s/it]predicting train subjects:  35%|███▍      | 99/285 [03:03<05:45,  1.86s/it]predicting train subjects:  35%|███▌      | 100/285 [03:05<05:45,  1.87s/it]predicting train subjects:  35%|███▌      | 101/285 [03:07<05:34,  1.82s/it]predicting train subjects:  36%|███▌      | 102/285 [03:08<05:35,  1.83s/it]predicting train subjects:  36%|███▌      | 103/285 [03:10<05:33,  1.83s/it]predicting train subjects:  36%|███▋      | 104/285 [03:12<05:30,  1.83s/it]predicting train subjects:  37%|███▋      | 105/285 [03:14<05:31,  1.84s/it]predicting train subjects:  37%|███▋      | 106/285 [03:16<05:22,  1.80s/it]predicting train subjects:  38%|███▊      | 107/285 [03:17<05:23,  1.82s/it]predicting train subjects:  38%|███▊      | 108/285 [03:19<05:14,  1.78s/it]predicting train subjects:  38%|███▊      | 109/285 [03:21<05:15,  1.79s/it]predicting train subjects:  39%|███▊      | 110/285 [03:23<05:17,  1.82s/it]predicting train subjects:  39%|███▉      | 111/285 [03:25<05:15,  1.81s/it]predicting train subjects:  39%|███▉      | 112/285 [03:26<05:13,  1.81s/it]predicting train subjects:  40%|███▉      | 113/285 [03:28<05:18,  1.85s/it]predicting train subjects:  40%|████      | 114/285 [03:30<05:10,  1.82s/it]predicting train subjects:  40%|████      | 115/285 [03:32<05:15,  1.86s/it]predicting train subjects:  41%|████      | 116/285 [03:34<05:15,  1.87s/it]predicting train subjects:  41%|████      | 117/285 [03:36<05:06,  1.82s/it]predicting train subjects:  41%|████▏     | 118/285 [03:37<04:59,  1.79s/it]predicting train subjects:  42%|████▏     | 119/285 [03:39<05:02,  1.82s/it]predicting train subjects:  42%|████▏     | 120/285 [03:41<04:57,  1.80s/it]predicting train subjects:  42%|████▏     | 121/285 [03:43<04:49,  1.77s/it]predicting train subjects:  43%|████▎     | 122/285 [03:44<04:36,  1.70s/it]predicting train subjects:  43%|████▎     | 123/285 [03:46<04:26,  1.64s/it]predicting train subjects:  44%|████▎     | 124/285 [03:48<04:30,  1.68s/it]predicting train subjects:  44%|████▍     | 125/285 [03:49<04:22,  1.64s/it]predicting train subjects:  44%|████▍     | 126/285 [03:51<04:18,  1.63s/it]predicting train subjects:  45%|████▍     | 127/285 [03:52<04:12,  1.60s/it]predicting train subjects:  45%|████▍     | 128/285 [03:54<04:17,  1.64s/it]predicting train subjects:  45%|████▌     | 129/285 [03:56<04:11,  1.61s/it]predicting train subjects:  46%|████▌     | 130/285 [03:57<04:07,  1.59s/it]predicting train subjects:  46%|████▌     | 131/285 [03:59<04:00,  1.56s/it]predicting train subjects:  46%|████▋     | 132/285 [04:00<04:07,  1.62s/it]predicting train subjects:  47%|████▋     | 133/285 [04:02<04:00,  1.58s/it]predicting train subjects:  47%|████▋     | 134/285 [04:03<03:59,  1.59s/it]predicting train subjects:  47%|████▋     | 135/285 [04:05<03:53,  1.56s/it]predicting train subjects:  48%|████▊     | 136/285 [04:06<03:47,  1.53s/it]predicting train subjects:  48%|████▊     | 137/285 [04:08<03:58,  1.61s/it]predicting train subjects:  48%|████▊     | 138/285 [04:10<03:50,  1.57s/it]predicting train subjects:  49%|████▉     | 139/285 [04:11<03:53,  1.60s/it]predicting train subjects:  49%|████▉     | 140/285 [04:13<03:53,  1.61s/it]predicting train subjects:  49%|████▉     | 141/285 [04:15<03:52,  1.61s/it]predicting train subjects:  50%|████▉     | 142/285 [04:16<03:49,  1.60s/it]predicting train subjects:  50%|█████     | 143/285 [04:18<03:48,  1.61s/it]predicting train subjects:  51%|█████     | 144/285 [04:19<03:49,  1.62s/it]predicting train subjects:  51%|█████     | 145/285 [04:21<03:50,  1.64s/it]predicting train subjects:  51%|█████     | 146/285 [04:23<03:50,  1.66s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:24<03:43,  1.62s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:26<03:49,  1.67s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:28<03:42,  1.64s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:29<03:39,  1.63s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:31<03:39,  1.64s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:32<03:33,  1.60s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:34<03:24,  1.55s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:36<03:30,  1.60s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:37<03:27,  1.60s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:39<03:30,  1.63s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:40<03:25,  1.61s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:42<03:22,  1.60s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:44<03:17,  1.57s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:45<03:18,  1.59s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:47<03:19,  1.61s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:48<03:17,  1.61s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:50<03:20,  1.65s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:52<03:13,  1.60s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:53<03:08,  1.57s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:55<03:12,  1.62s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:57<03:16,  1.67s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:58<03:11,  1.64s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:00<03:07,  1.61s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:01<03:00,  1.57s/it]predicting train subjects:  60%|██████    | 171/285 [05:03<03:05,  1.63s/it]predicting train subjects:  60%|██████    | 172/285 [05:05<03:03,  1.63s/it]predicting train subjects:  61%|██████    | 173/285 [05:06<02:58,  1.60s/it]predicting train subjects:  61%|██████    | 174/285 [05:08<02:56,  1.59s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:10<03:00,  1.64s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:11<03:03,  1.68s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:13<02:57,  1.64s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:14<02:50,  1.59s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:16<02:45,  1.56s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:18<02:53,  1.65s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:19<02:54,  1.68s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:21<02:52,  1.68s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:23<02:48,  1.65s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:24<02:42,  1.61s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:26<02:39,  1.59s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:28<02:51,  1.73s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:30<02:57,  1.81s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:32<02:58,  1.84s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:33<02:46,  1.74s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:35<02:42,  1.72s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:37<02:44,  1.75s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:39<02:46,  1.79s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:40<02:40,  1.74s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:42<02:35,  1.71s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:43<02:30,  1.68s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:45<02:34,  1.74s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:47<02:37,  1.79s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:49<02:41,  1.85s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:51<02:29,  1.74s/it]predicting train subjects:  70%|███████   | 200/285 [05:52<02:27,  1.73s/it]predicting train subjects:  71%|███████   | 201/285 [05:54<02:33,  1.82s/it]predicting train subjects:  71%|███████   | 202/285 [05:56<02:33,  1.85s/it]predicting train subjects:  71%|███████   | 203/285 [05:58<02:30,  1.84s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:00<02:22,  1.76s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:01<02:16,  1.71s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:03<02:09,  1.64s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:05<02:16,  1.74s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:07<02:18,  1.80s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:09<02:18,  1.82s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:10<02:09,  1.72s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:12<02:03,  1.67s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:14<02:06,  1.74s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:15<02:06,  1.76s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:17<02:00,  1.69s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:19<02:03,  1.76s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:20<01:56,  1.69s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:22<02:00,  1.77s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:24<02:02,  1.83s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:26<02:04,  1.89s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:28<01:55,  1.78s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:30<01:51,  1.74s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:31<01:51,  1.77s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:33<01:47,  1.73s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:35<01:42,  1.68s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:36<01:39,  1.65s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:38<01:43,  1.76s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:40<01:43,  1.79s/it]predicting train subjects:  80%|████████  | 228/285 [06:42<01:47,  1.89s/it]predicting train subjects:  80%|████████  | 229/285 [06:44<01:44,  1.86s/it]predicting train subjects:  81%|████████  | 230/285 [06:45<01:35,  1.73s/it]predicting train subjects:  81%|████████  | 231/285 [06:47<01:32,  1.71s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:49<01:30,  1.72s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:50<01:26,  1.66s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:52<01:32,  1.81s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:54<01:27,  1.75s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:56<01:29,  1.82s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:58<01:28,  1.84s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:00<01:27,  1.86s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:02<01:23,  1.82s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:03<01:18,  1.74s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:05<01:14,  1.68s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:06<01:09,  1.62s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:08<01:06,  1.58s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:09<01:07,  1.65s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:11<01:06,  1.65s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:13<01:08,  1.74s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:15<01:06,  1.75s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:16<01:04,  1.73s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:18<01:00,  1.67s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:20<00:57,  1.65s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:21<00:55,  1.63s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:23<00:52,  1.59s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:25<00:53,  1.67s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:26<00:53,  1.73s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:28<00:52,  1.74s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:30<00:47,  1.65s/it]predicting train subjects:  90%|█████████ | 257/285 [07:31<00:45,  1.62s/it]predicting train subjects:  91%|█████████ | 258/285 [07:33<00:45,  1.67s/it]predicting train subjects:  91%|█████████ | 259/285 [07:35<00:43,  1.69s/it]predicting train subjects:  91%|█████████ | 260/285 [07:36<00:40,  1.63s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:38<00:37,  1.58s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:39<00:35,  1.55s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:41<00:33,  1.52s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:43<00:35,  1.67s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:45<00:35,  1.77s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:46<00:32,  1.74s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:48<00:30,  1.71s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:50<00:29,  1.75s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:51<00:27,  1.73s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:53<00:24,  1.66s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:54<00:22,  1.61s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:56<00:21,  1.68s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:58<00:20,  1.67s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:59<00:18,  1.64s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:02<00:17,  1.75s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:03<00:16,  1.82s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:05<00:13,  1.71s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:07<00:11,  1.70s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:08<00:10,  1.75s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:10<00:08,  1.68s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:11<00:06,  1.61s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:13<00:04,  1.57s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:15<00:03,  1.69s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:17<00:01,  1.76s/it]predicting train subjects: 100%|██████████| 285/285 [08:19<00:00,  1.80s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:39,  1.83s/it]Loading train:   1%|          | 2/285 [00:03<07:54,  1.68s/it]Loading train:   1%|          | 3/285 [00:04<07:55,  1.69s/it]Loading train:   1%|▏         | 4/285 [00:06<07:31,  1.61s/it]Loading train:   2%|▏         | 5/285 [00:07<07:38,  1.64s/it]Loading train:   2%|▏         | 6/285 [00:09<07:17,  1.57s/it]Loading train:   2%|▏         | 7/285 [00:11<07:32,  1.63s/it]Loading train:   3%|▎         | 8/285 [00:12<07:23,  1.60s/it]Loading train:   3%|▎         | 9/285 [00:14<07:51,  1.71s/it]Loading train:   4%|▎         | 10/285 [00:15<07:07,  1.56s/it]Loading train:   4%|▍         | 11/285 [00:16<06:18,  1.38s/it]Loading train:   4%|▍         | 12/285 [00:18<06:09,  1.35s/it]Loading train:   5%|▍         | 13/285 [00:19<05:32,  1.22s/it]Loading train:   5%|▍         | 14/285 [00:20<05:24,  1.20s/it]Loading train:   5%|▌         | 15/285 [00:21<05:32,  1.23s/it]Loading train:   6%|▌         | 16/285 [00:22<05:25,  1.21s/it]Loading train:   6%|▌         | 17/285 [00:24<05:40,  1.27s/it]Loading train:   6%|▋         | 18/285 [00:25<05:30,  1.24s/it]Loading train:   7%|▋         | 19/285 [00:26<05:15,  1.18s/it]Loading train:   7%|▋         | 20/285 [00:27<05:16,  1.20s/it]Loading train:   7%|▋         | 21/285 [00:28<05:14,  1.19s/it]Loading train:   8%|▊         | 22/285 [00:29<05:14,  1.19s/it]Loading train:   8%|▊         | 23/285 [00:31<05:18,  1.22s/it]Loading train:   8%|▊         | 24/285 [00:32<05:11,  1.19s/it]Loading train:   9%|▉         | 25/285 [00:33<05:22,  1.24s/it]Loading train:   9%|▉         | 26/285 [00:35<05:36,  1.30s/it]Loading train:   9%|▉         | 27/285 [00:36<05:32,  1.29s/it]Loading train:  10%|▉         | 28/285 [00:37<05:29,  1.28s/it]Loading train:  10%|█         | 29/285 [00:38<05:25,  1.27s/it]Loading train:  11%|█         | 30/285 [00:40<05:31,  1.30s/it]Loading train:  11%|█         | 31/285 [00:41<05:32,  1.31s/it]Loading train:  11%|█         | 32/285 [00:42<05:18,  1.26s/it]Loading train:  12%|█▏        | 33/285 [00:44<05:24,  1.29s/it]Loading train:  12%|█▏        | 34/285 [00:45<05:15,  1.26s/it]Loading train:  12%|█▏        | 35/285 [00:46<05:11,  1.25s/it]Loading train:  13%|█▎        | 36/285 [00:47<05:21,  1.29s/it]Loading train:  13%|█▎        | 37/285 [00:49<05:24,  1.31s/it]Loading train:  13%|█▎        | 38/285 [00:50<05:29,  1.33s/it]Loading train:  14%|█▎        | 39/285 [00:51<05:23,  1.32s/it]Loading train:  14%|█▍        | 40/285 [00:53<05:10,  1.27s/it]Loading train:  14%|█▍        | 41/285 [00:54<05:11,  1.28s/it]Loading train:  15%|█▍        | 42/285 [00:55<05:08,  1.27s/it]Loading train:  15%|█▌        | 43/285 [00:56<05:10,  1.28s/it]Loading train:  15%|█▌        | 44/285 [00:58<05:32,  1.38s/it]Loading train:  16%|█▌        | 45/285 [00:59<05:07,  1.28s/it]Loading train:  16%|█▌        | 46/285 [01:00<05:00,  1.26s/it]Loading train:  16%|█▋        | 47/285 [01:01<04:53,  1.23s/it]Loading train:  17%|█▋        | 48/285 [01:03<04:59,  1.26s/it]Loading train:  17%|█▋        | 49/285 [01:04<05:04,  1.29s/it]Loading train:  18%|█▊        | 50/285 [01:05<05:02,  1.29s/it]Loading train:  18%|█▊        | 51/285 [01:07<05:04,  1.30s/it]Loading train:  18%|█▊        | 52/285 [01:08<04:55,  1.27s/it]Loading train:  19%|█▊        | 53/285 [01:09<04:49,  1.25s/it]Loading train:  19%|█▉        | 54/285 [01:10<04:55,  1.28s/it]Loading train:  19%|█▉        | 55/285 [01:12<04:44,  1.24s/it]Loading train:  20%|█▉        | 56/285 [01:13<04:41,  1.23s/it]Loading train:  20%|██        | 57/285 [01:14<04:28,  1.18s/it]Loading train:  20%|██        | 58/285 [01:15<04:20,  1.15s/it]Loading train:  21%|██        | 59/285 [01:16<04:22,  1.16s/it]Loading train:  21%|██        | 60/285 [01:17<04:20,  1.16s/it]Loading train:  21%|██▏       | 61/285 [01:18<04:20,  1.16s/it]Loading train:  22%|██▏       | 62/285 [01:20<04:19,  1.17s/it]Loading train:  22%|██▏       | 63/285 [01:21<04:11,  1.13s/it]Loading train:  22%|██▏       | 64/285 [01:22<04:25,  1.20s/it]Loading train:  23%|██▎       | 65/285 [01:24<04:52,  1.33s/it]Loading train:  23%|██▎       | 66/285 [01:25<05:14,  1.44s/it]Loading train:  24%|██▎       | 67/285 [01:27<04:59,  1.37s/it]Loading train:  24%|██▍       | 68/285 [01:28<04:45,  1.32s/it]Loading train:  24%|██▍       | 69/285 [01:29<04:35,  1.27s/it]Loading train:  25%|██▍       | 70/285 [01:30<04:32,  1.27s/it]Loading train:  25%|██▍       | 71/285 [01:31<04:23,  1.23s/it]Loading train:  25%|██▌       | 72/285 [01:32<04:11,  1.18s/it]Loading train:  26%|██▌       | 73/285 [01:34<04:06,  1.16s/it]Loading train:  26%|██▌       | 74/285 [01:35<04:11,  1.19s/it]Loading train:  26%|██▋       | 75/285 [01:36<04:31,  1.29s/it]Loading train:  27%|██▋       | 76/285 [01:37<04:18,  1.24s/it]Loading train:  27%|██▋       | 77/285 [01:39<04:14,  1.22s/it]Loading train:  27%|██▋       | 78/285 [01:40<04:02,  1.17s/it]Loading train:  28%|██▊       | 79/285 [01:41<04:06,  1.19s/it]Loading train:  28%|██▊       | 80/285 [01:42<04:02,  1.18s/it]Loading train:  28%|██▊       | 81/285 [01:43<04:03,  1.19s/it]Loading train:  29%|██▉       | 82/285 [01:44<03:55,  1.16s/it]Loading train:  29%|██▉       | 83/285 [01:46<04:16,  1.27s/it]Loading train:  29%|██▉       | 84/285 [01:47<04:06,  1.23s/it]Loading train:  30%|██▉       | 85/285 [01:48<04:06,  1.23s/it]Loading train:  30%|███       | 86/285 [01:50<04:32,  1.37s/it]Loading train:  31%|███       | 87/285 [01:51<04:28,  1.36s/it]Loading train:  31%|███       | 88/285 [01:52<04:07,  1.26s/it]Loading train:  31%|███       | 89/285 [01:53<04:01,  1.23s/it]Loading train:  32%|███▏      | 90/285 [01:55<04:00,  1.23s/it]Loading train:  32%|███▏      | 91/285 [01:56<03:40,  1.14s/it]Loading train:  32%|███▏      | 92/285 [01:57<03:43,  1.16s/it]Loading train:  33%|███▎      | 93/285 [01:58<03:48,  1.19s/it]Loading train:  33%|███▎      | 94/285 [01:59<03:43,  1.17s/it]Loading train:  33%|███▎      | 95/285 [02:00<03:42,  1.17s/it]Loading train:  34%|███▎      | 96/285 [02:01<03:33,  1.13s/it]Loading train:  34%|███▍      | 97/285 [02:03<03:29,  1.11s/it]Loading train:  34%|███▍      | 98/285 [02:04<03:31,  1.13s/it]Loading train:  35%|███▍      | 99/285 [02:05<03:31,  1.14s/it]Loading train:  35%|███▌      | 100/285 [02:06<03:40,  1.19s/it]Loading train:  35%|███▌      | 101/285 [02:07<03:31,  1.15s/it]Loading train:  36%|███▌      | 102/285 [02:08<03:24,  1.12s/it]Loading train:  36%|███▌      | 103/285 [02:09<03:10,  1.05s/it]Loading train:  36%|███▋      | 104/285 [02:10<03:11,  1.06s/it]Loading train:  37%|███▋      | 105/285 [02:11<03:11,  1.06s/it]Loading train:  37%|███▋      | 106/285 [02:12<02:57,  1.01it/s]Loading train:  38%|███▊      | 107/285 [02:13<03:00,  1.01s/it]Loading train:  38%|███▊      | 108/285 [02:14<03:02,  1.03s/it]Loading train:  38%|███▊      | 109/285 [02:16<03:14,  1.10s/it]Loading train:  39%|███▊      | 110/285 [02:17<03:10,  1.09s/it]Loading train:  39%|███▉      | 111/285 [02:18<03:03,  1.06s/it]Loading train:  39%|███▉      | 112/285 [02:19<03:04,  1.07s/it]Loading train:  40%|███▉      | 113/285 [02:20<03:03,  1.07s/it]Loading train:  40%|████      | 114/285 [02:21<03:02,  1.07s/it]Loading train:  40%|████      | 115/285 [02:22<03:01,  1.07s/it]Loading train:  41%|████      | 116/285 [02:23<02:59,  1.06s/it]Loading train:  41%|████      | 117/285 [02:24<02:49,  1.01s/it]Loading train:  41%|████▏     | 118/285 [02:25<02:42,  1.03it/s]Loading train:  42%|████▏     | 119/285 [02:26<02:42,  1.02it/s]Loading train:  42%|████▏     | 120/285 [02:27<02:37,  1.05it/s]Loading train:  42%|████▏     | 121/285 [02:28<02:54,  1.06s/it]Loading train:  43%|████▎     | 122/285 [02:29<02:59,  1.10s/it]Loading train:  43%|████▎     | 123/285 [02:30<03:03,  1.13s/it]Loading train:  44%|████▎     | 124/285 [02:31<02:53,  1.08s/it]Loading train:  44%|████▍     | 125/285 [02:32<02:44,  1.03s/it]Loading train:  44%|████▍     | 126/285 [02:33<02:41,  1.01s/it]Loading train:  45%|████▍     | 127/285 [02:34<02:35,  1.02it/s]Loading train:  45%|████▍     | 128/285 [02:35<02:36,  1.00it/s]Loading train:  45%|████▌     | 129/285 [02:36<02:27,  1.06it/s]Loading train:  46%|████▌     | 130/285 [02:37<02:24,  1.07it/s]Loading train:  46%|████▌     | 131/285 [02:38<02:18,  1.11it/s]Loading train:  46%|████▋     | 132/285 [02:38<02:16,  1.12it/s]Loading train:  47%|████▋     | 133/285 [02:39<02:11,  1.15it/s]Loading train:  47%|████▋     | 134/285 [02:40<02:12,  1.14it/s]Loading train:  47%|████▋     | 135/285 [02:41<02:05,  1.20it/s]Loading train:  48%|████▊     | 136/285 [02:42<02:00,  1.23it/s]Loading train:  48%|████▊     | 137/285 [02:43<02:03,  1.20it/s]Loading train:  48%|████▊     | 138/285 [02:44<02:07,  1.15it/s]Loading train:  49%|████▉     | 139/285 [02:44<02:07,  1.15it/s]Loading train:  49%|████▉     | 140/285 [02:45<02:04,  1.16it/s]Loading train:  49%|████▉     | 141/285 [02:46<02:02,  1.17it/s]Loading train:  50%|████▉     | 142/285 [02:47<02:03,  1.15it/s]Loading train:  50%|█████     | 143/285 [02:48<01:57,  1.21it/s]Loading train:  51%|█████     | 144/285 [02:49<02:00,  1.17it/s]Loading train:  51%|█████     | 145/285 [02:50<02:11,  1.07it/s]Loading train:  51%|█████     | 146/285 [02:51<02:12,  1.05it/s]Loading train:  52%|█████▏    | 147/285 [02:52<02:09,  1.06it/s]Loading train:  52%|█████▏    | 148/285 [02:53<02:13,  1.03it/s]Loading train:  52%|█████▏    | 149/285 [02:54<02:11,  1.03it/s]Loading train:  53%|█████▎    | 150/285 [02:55<02:12,  1.02it/s]Loading train:  53%|█████▎    | 151/285 [02:56<02:14,  1.00s/it]Loading train:  53%|█████▎    | 152/285 [02:57<02:09,  1.03it/s]Loading train:  54%|█████▎    | 153/285 [02:58<02:10,  1.01it/s]Loading train:  54%|█████▍    | 154/285 [02:59<02:12,  1.01s/it]Loading train:  54%|█████▍    | 155/285 [03:00<02:14,  1.04s/it]Loading train:  55%|█████▍    | 156/285 [03:01<02:07,  1.01it/s]Loading train:  55%|█████▌    | 157/285 [03:02<02:07,  1.01it/s]Loading train:  55%|█████▌    | 158/285 [03:03<02:04,  1.02it/s]Loading train:  56%|█████▌    | 159/285 [03:03<01:58,  1.07it/s]Loading train:  56%|█████▌    | 160/285 [03:04<01:51,  1.12it/s]Loading train:  56%|█████▋    | 161/285 [03:05<01:54,  1.09it/s]Loading train:  57%|█████▋    | 162/285 [03:06<01:49,  1.12it/s]Loading train:  57%|█████▋    | 163/285 [03:07<01:48,  1.12it/s]Loading train:  58%|█████▊    | 164/285 [03:08<01:46,  1.13it/s]Loading train:  58%|█████▊    | 165/285 [03:09<01:45,  1.14it/s]Loading train:  58%|█████▊    | 166/285 [03:10<01:46,  1.11it/s]Loading train:  59%|█████▊    | 167/285 [03:11<01:47,  1.09it/s]Loading train:  59%|█████▉    | 168/285 [03:12<01:47,  1.09it/s]Loading train:  59%|█████▉    | 169/285 [03:12<01:47,  1.08it/s]Loading train:  60%|█████▉    | 170/285 [03:13<01:45,  1.09it/s]Loading train:  60%|██████    | 171/285 [03:14<01:44,  1.09it/s]Loading train:  60%|██████    | 172/285 [03:15<01:46,  1.06it/s]Loading train:  61%|██████    | 173/285 [03:16<01:41,  1.11it/s]Loading train:  61%|██████    | 174/285 [03:17<01:36,  1.15it/s]Loading train:  61%|██████▏   | 175/285 [03:18<01:36,  1.14it/s]Loading train:  62%|██████▏   | 176/285 [03:19<01:38,  1.11it/s]Loading train:  62%|██████▏   | 177/285 [03:20<01:43,  1.04it/s]Loading train:  62%|██████▏   | 178/285 [03:21<01:39,  1.08it/s]Loading train:  63%|██████▎   | 179/285 [03:22<01:36,  1.10it/s]Loading train:  63%|██████▎   | 180/285 [03:23<01:40,  1.04it/s]Loading train:  64%|██████▎   | 181/285 [03:24<01:37,  1.06it/s]Loading train:  64%|██████▍   | 182/285 [03:25<01:40,  1.03it/s]Loading train:  64%|██████▍   | 183/285 [03:26<01:39,  1.03it/s]Loading train:  65%|██████▍   | 184/285 [03:26<01:34,  1.07it/s]Loading train:  65%|██████▍   | 185/285 [03:27<01:28,  1.13it/s]Loading train:  65%|██████▌   | 186/285 [03:28<01:28,  1.12it/s]Loading train:  66%|██████▌   | 187/285 [03:29<01:30,  1.09it/s]Loading train:  66%|██████▌   | 188/285 [03:30<01:31,  1.06it/s]Loading train:  66%|██████▋   | 189/285 [03:31<01:30,  1.06it/s]Loading train:  67%|██████▋   | 190/285 [03:32<01:28,  1.07it/s]Loading train:  67%|██████▋   | 191/285 [03:33<01:28,  1.07it/s]Loading train:  67%|██████▋   | 192/285 [03:34<01:26,  1.08it/s]Loading train:  68%|██████▊   | 193/285 [03:35<01:20,  1.15it/s]Loading train:  68%|██████▊   | 194/285 [03:35<01:17,  1.17it/s]Loading train:  68%|██████▊   | 195/285 [03:36<01:16,  1.18it/s]Loading train:  69%|██████▉   | 196/285 [03:37<01:18,  1.13it/s]Loading train:  69%|██████▉   | 197/285 [03:38<01:21,  1.09it/s]Loading train:  69%|██████▉   | 198/285 [03:39<01:24,  1.03it/s]Loading train:  70%|██████▉   | 199/285 [03:40<01:25,  1.01it/s]Loading train:  70%|███████   | 200/285 [03:41<01:23,  1.01it/s]Loading train:  71%|███████   | 201/285 [03:42<01:26,  1.03s/it]Loading train:  71%|███████   | 202/285 [03:43<01:27,  1.05s/it]Loading train:  71%|███████   | 203/285 [03:44<01:23,  1.02s/it]Loading train:  72%|███████▏  | 204/285 [03:45<01:19,  1.03it/s]Loading train:  72%|███████▏  | 205/285 [03:46<01:13,  1.08it/s]Loading train:  72%|███████▏  | 206/285 [03:47<01:11,  1.10it/s]Loading train:  73%|███████▎  | 207/285 [03:48<01:13,  1.06it/s]Loading train:  73%|███████▎  | 208/285 [03:49<01:15,  1.01it/s]Loading train:  73%|███████▎  | 209/285 [03:50<01:17,  1.02s/it]Loading train:  74%|███████▎  | 210/285 [03:51<01:13,  1.01it/s]Loading train:  74%|███████▍  | 211/285 [03:52<01:12,  1.02it/s]Loading train:  74%|███████▍  | 212/285 [03:53<01:11,  1.02it/s]Loading train:  75%|███████▍  | 213/285 [03:54<01:10,  1.02it/s]Loading train:  75%|███████▌  | 214/285 [03:55<01:06,  1.07it/s]Loading train:  75%|███████▌  | 215/285 [03:56<01:08,  1.02it/s]Loading train:  76%|███████▌  | 216/285 [03:57<01:02,  1.10it/s]Loading train:  76%|███████▌  | 217/285 [03:58<01:02,  1.08it/s]Loading train:  76%|███████▋  | 218/285 [03:59<01:01,  1.09it/s]Loading train:  77%|███████▋  | 219/285 [04:00<01:02,  1.06it/s]Loading train:  77%|███████▋  | 220/285 [04:00<01:00,  1.08it/s]Loading train:  78%|███████▊  | 221/285 [04:01<00:57,  1.10it/s]Loading train:  78%|███████▊  | 222/285 [04:02<00:55,  1.13it/s]Loading train:  78%|███████▊  | 223/285 [04:03<00:53,  1.16it/s]Loading train:  79%|███████▊  | 224/285 [04:04<00:52,  1.16it/s]Loading train:  79%|███████▉  | 225/285 [04:05<00:49,  1.21it/s]Loading train:  79%|███████▉  | 226/285 [04:06<00:53,  1.11it/s]Loading train:  80%|███████▉  | 227/285 [04:07<00:53,  1.08it/s]Loading train:  80%|████████  | 228/285 [04:08<00:54,  1.06it/s]Loading train:  80%|████████  | 229/285 [04:09<00:54,  1.02it/s]Loading train:  81%|████████  | 230/285 [04:09<00:50,  1.08it/s]Loading train:  81%|████████  | 231/285 [04:10<00:49,  1.10it/s]Loading train:  81%|████████▏ | 232/285 [04:11<00:49,  1.08it/s]Loading train:  82%|████████▏ | 233/285 [04:12<00:45,  1.13it/s]Loading train:  82%|████████▏ | 234/285 [04:13<00:47,  1.08it/s]Loading train:  82%|████████▏ | 235/285 [04:14<00:46,  1.07it/s]Loading train:  83%|████████▎ | 236/285 [04:15<00:47,  1.04it/s]Loading train:  83%|████████▎ | 237/285 [04:16<00:47,  1.00it/s]Loading train:  84%|████████▎ | 238/285 [04:18<00:51,  1.10s/it]Loading train:  84%|████████▍ | 239/285 [04:18<00:48,  1.05s/it]Loading train:  84%|████████▍ | 240/285 [04:19<00:46,  1.04s/it]Loading train:  85%|████████▍ | 241/285 [04:21<00:45,  1.04s/it]Loading train:  85%|████████▍ | 242/285 [04:21<00:43,  1.01s/it]Loading train:  85%|████████▌ | 243/285 [04:22<00:42,  1.00s/it]Loading train:  86%|████████▌ | 244/285 [04:24<00:42,  1.05s/it]Loading train:  86%|████████▌ | 245/285 [04:25<00:41,  1.04s/it]Loading train:  86%|████████▋ | 246/285 [04:26<00:39,  1.01s/it]Loading train:  87%|████████▋ | 247/285 [04:27<00:40,  1.08s/it]Loading train:  87%|████████▋ | 248/285 [04:28<00:38,  1.04s/it]Loading train:  87%|████████▋ | 249/285 [04:29<00:35,  1.01it/s]Loading train:  88%|████████▊ | 250/285 [04:29<00:32,  1.08it/s]Loading train:  88%|████████▊ | 251/285 [04:30<00:32,  1.06it/s]Loading train:  88%|████████▊ | 252/285 [04:31<00:31,  1.04it/s]Loading train:  89%|████████▉ | 253/285 [04:33<00:32,  1.02s/it]Loading train:  89%|████████▉ | 254/285 [04:34<00:31,  1.01s/it]Loading train:  89%|████████▉ | 255/285 [04:34<00:29,  1.01it/s]Loading train:  90%|████████▉ | 256/285 [04:35<00:27,  1.04it/s]Loading train:  90%|█████████ | 257/285 [04:36<00:25,  1.08it/s]Loading train:  91%|█████████ | 258/285 [04:37<00:25,  1.07it/s]Loading train:  91%|█████████ | 259/285 [04:38<00:25,  1.04it/s]Loading train:  91%|█████████ | 260/285 [04:39<00:23,  1.07it/s]Loading train:  92%|█████████▏| 261/285 [04:40<00:22,  1.07it/s]Loading train:  92%|█████████▏| 262/285 [04:41<00:20,  1.12it/s]Loading train:  92%|█████████▏| 263/285 [04:42<00:18,  1.17it/s]Loading train:  93%|█████████▎| 264/285 [04:43<00:19,  1.09it/s]Loading train:  93%|█████████▎| 265/285 [04:44<00:18,  1.07it/s]Loading train:  93%|█████████▎| 266/285 [04:44<00:16,  1.15it/s]Loading train:  94%|█████████▎| 267/285 [04:45<00:15,  1.13it/s]Loading train:  94%|█████████▍| 268/285 [04:46<00:16,  1.05it/s]Loading train:  94%|█████████▍| 269/285 [04:47<00:15,  1.06it/s]Loading train:  95%|█████████▍| 270/285 [04:48<00:13,  1.10it/s]Loading train:  95%|█████████▌| 271/285 [04:49<00:12,  1.09it/s]Loading train:  95%|█████████▌| 272/285 [04:50<00:11,  1.10it/s]Loading train:  96%|█████████▌| 273/285 [04:51<00:10,  1.13it/s]Loading train:  96%|█████████▌| 274/285 [04:52<00:09,  1.17it/s]Loading train:  96%|█████████▋| 275/285 [04:52<00:08,  1.12it/s]Loading train:  97%|█████████▋| 276/285 [04:54<00:08,  1.06it/s]Loading train:  97%|█████████▋| 277/285 [04:54<00:07,  1.13it/s]Loading train:  98%|█████████▊| 278/285 [04:55<00:06,  1.14it/s]Loading train:  98%|█████████▊| 279/285 [04:56<00:05,  1.16it/s]Loading train:  98%|█████████▊| 280/285 [04:57<00:04,  1.17it/s]Loading train:  99%|█████████▊| 281/285 [04:58<00:03,  1.17it/s]Loading train:  99%|█████████▉| 282/285 [04:59<00:02,  1.16it/s]Loading train:  99%|█████████▉| 283/285 [05:00<00:01,  1.11it/s]Loading train: 100%|█████████▉| 284/285 [05:01<00:00,  1.08it/s]Loading train: 100%|██████████| 285/285 [05:01<00:00,  1.07it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   5%|▍         | 13/285 [00:00<00:02, 126.33it/s]concatenating: train:   9%|▉         | 26/285 [00:00<00:02, 124.49it/s]concatenating: train:  20%|█▉        | 56/285 [00:00<00:01, 150.88it/s]concatenating: train:  25%|██▍       | 70/285 [00:00<00:01, 147.36it/s]concatenating: train:  31%|███       | 87/285 [00:00<00:01, 152.10it/s]concatenating: train:  38%|███▊      | 108/285 [00:00<00:01, 164.28it/s]concatenating: train:  47%|████▋     | 135/285 [00:00<00:00, 184.59it/s]concatenating: train:  58%|█████▊    | 165/285 [00:00<00:00, 208.27it/s]concatenating: train:  69%|██████▉   | 197/285 [00:00<00:00, 232.20it/s]concatenating: train:  81%|████████▏ | 232/285 [00:01<00:00, 257.60it/s]concatenating: train:  94%|█████████▎| 267/285 [00:01<00:00, 279.52it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 243.46it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.37s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.32s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.26s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 756.41it/s]2019-07-11 01:17:15.200306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 01:17:15.200432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 01:17:15.200463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 01:17:15.200475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 01:17:15.200885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.09it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.03it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.71it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.89it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  6.23it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.05it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.11it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.86it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.51it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.07it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.83it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.37it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.82it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.62it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.31it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.77it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 10.19it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.46it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.38it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 26, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 26, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 26, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 26, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 13, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 13, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 13, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 20, 13, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 40, 26, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 40, 26, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 40, 26, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 80, 52, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 80, 52, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 52, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 80, 52, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 30)   16230       dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 30)   120         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 30)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 80, 52, 30)   0           activation_11[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 90)   0           dropout_5[0][0]                  
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 13)   1183        concatenate_7[0][0]              
==================================================================================================
Total params: 240,573
Trainable params: 65,833
Non-trainable params: 174,740
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 15s - loss: 2.7589 - acc: 0.5809 - mDice: 0.0987 - val_loss: 5.2597 - val_acc: 0.9024 - val_mDice: 0.0778

Epoch 00001: val_mDice improved from -inf to 0.07777, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 10s - loss: 1.1379 - acc: 0.8772 - mDice: 0.3156 - val_loss: 1.6928 - val_acc: 0.9035 - val_mDice: 0.2759

Epoch 00002: val_mDice improved from 0.07777 to 0.27594, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 10s - loss: 0.8440 - acc: 0.8807 - mDice: 0.4155 - val_loss: 1.3647 - val_acc: 0.9095 - val_mDice: 0.3420

Epoch 00003: val_mDice improved from 0.27594 to 0.34205, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 10s - loss: 0.7130 - acc: 0.8844 - mDice: 0.4749 - val_loss: 1.1087 - val_acc: 0.9121 - val_mDice: 0.4255

Epoch 00004: val_mDice improved from 0.34205 to 0.42551, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 10s - loss: 0.6356 - acc: 0.8880 - mDice: 0.5149 - val_loss: 1.0357 - val_acc: 0.9170 - val_mDice: 0.4584

Epoch 00005: val_mDice improved from 0.42551 to 0.45835, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 10s - loss: 0.5751 - acc: 0.8915 - mDice: 0.5476 - val_loss: 0.9422 - val_acc: 0.9188 - val_mDice: 0.4943

Epoch 00006: val_mDice improved from 0.45835 to 0.49433, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 10s - loss: 0.5374 - acc: 0.8947 - mDice: 0.5693 - val_loss: 0.9441 - val_acc: 0.9218 - val_mDice: 0.5050

Epoch 00007: val_mDice improved from 0.49433 to 0.50496, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 10s - loss: 0.5138 - acc: 0.8976 - mDice: 0.5834 - val_loss: 0.8988 - val_acc: 0.9236 - val_mDice: 0.5271

Epoch 00008: val_mDice improved from 0.50496 to 0.52714, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 10s - loss: 0.4902 - acc: 0.9010 - mDice: 0.5979 - val_loss: 0.9794 - val_acc: 0.9240 - val_mDice: 0.4988

Epoch 00009: val_mDice did not improve from 0.52714
Epoch 10/300
 - 10s - loss: 0.4715 - acc: 0.9050 - mDice: 0.6094 - val_loss: 0.9616 - val_acc: 0.9265 - val_mDice: 0.4937

Epoch 00010: val_mDice did not improve from 0.52714
Epoch 11/300
 - 10s - loss: 0.4567 - acc: 0.9086 - mDice: 0.6187 - val_loss: 0.9296 - val_acc: 0.9256 - val_mDice: 0.5207

Epoch 00011: val_mDice did not improve from 0.52714
Epoch 12/300
 - 10s - loss: 0.4460 - acc: 0.9117 - mDice: 0.6256 - val_loss: 0.8894 - val_acc: 0.9273 - val_mDice: 0.5310

Epoch 00012: val_mDice improved from 0.52714 to 0.53101, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 10s - loss: 0.4362 - acc: 0.9145 - mDice: 0.6320 - val_loss: 0.9149 - val_acc: 0.9278 - val_mDice: 0.5319

Epoch 00013: val_mDice improved from 0.53101 to 0.53186, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 10s - loss: 0.4240 - acc: 0.9171 - mDice: 0.6400 - val_loss: 0.8612 - val_acc: 0.9301 - val_mDice: 0.5407

Epoch 00014: val_mDice improved from 0.53186 to 0.54072, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 10s - loss: 0.4163 - acc: 0.9202 - mDice: 0.6453 - val_loss: 0.9209 - val_acc: 0.9311 - val_mDice: 0.5177

Epoch 00015: val_mDice did not improve from 0.54072
Epoch 16/300
 - 11s - loss: 0.4110 - acc: 0.9230 - mDice: 0.6489 - val_loss: 0.9733 - val_acc: 0.9285 - val_mDice: 0.4979

Epoch 00016: val_mDice did not improve from 0.54072
Epoch 17/300
 - 10s - loss: 0.4037 - acc: 0.9263 - mDice: 0.6537 - val_loss: 0.8217 - val_acc: 0.9316 - val_mDice: 0.5402

Epoch 00017: val_mDice did not improve from 0.54072
Epoch 18/300
 - 10s - loss: 0.3970 - acc: 0.9298 - mDice: 0.6577 - val_loss: 0.8400 - val_acc: 0.9303 - val_mDice: 0.5411

Epoch 00018: val_mDice improved from 0.54072 to 0.54108, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 19/300
 - 11s - loss: 0.3915 - acc: 0.9318 - mDice: 0.6613 - val_loss: 0.8526 - val_acc: 0.9316 - val_mDice: 0.5418

Epoch 00019: val_mDice improved from 0.54108 to 0.54177, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 20/300
 - 10s - loss: 0.3848 - acc: 0.9332 - mDice: 0.6659 - val_loss: 0.8538 - val_acc: 0.9336 - val_mDice: 0.5302

Epoch 00020: val_mDice did not improve from 0.54177
Epoch 21/300
 - 10s - loss: 0.3811 - acc: 0.9341 - mDice: 0.6683 - val_loss: 0.8779 - val_acc: 0.9307 - val_mDice: 0.5342

Epoch 00021: val_mDice did not improve from 0.54177
Epoch 22/300
 - 11s - loss: 0.3773 - acc: 0.9353 - mDice: 0.6710 - val_loss: 0.8664 - val_acc: 0.9328 - val_mDice: 0.5359

Epoch 00022: val_mDice did not improve from 0.54177
Epoch 23/300
 - 10s - loss: 0.3699 - acc: 0.9366 - mDice: 0.6762 - val_loss: 0.8631 - val_acc: 0.9356 - val_mDice: 0.5384

Epoch 00023: val_mDice did not improve from 0.54177
Epoch 24/300
 - 10s - loss: 0.3690 - acc: 0.9378 - mDice: 0.6766 - val_loss: 0.8465 - val_acc: 0.9363 - val_mDice: 0.5483

Epoch 00024: val_mDice improved from 0.54177 to 0.54829, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 25/300
 - 10s - loss: 0.3657 - acc: 0.9387 - mDice: 0.6788 - val_loss: 0.9277 - val_acc: 0.9327 - val_mDice: 0.5147

Epoch 00025: val_mDice did not improve from 0.54829
Epoch 26/300
 - 11s - loss: 0.3648 - acc: 0.9389 - mDice: 0.6793 - val_loss: 0.8349 - val_acc: 0.9373 - val_mDice: 0.5540

Epoch 00026: val_mDice improved from 0.54829 to 0.55397, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 27/300
 - 10s - loss: 0.3573 - acc: 0.9396 - mDice: 0.6845 - val_loss: 0.8667 - val_acc: 0.9335 - val_mDice: 0.5295

Epoch 00027: val_mDice did not improve from 0.55397
Epoch 28/300
 - 10s - loss: 0.3551 - acc: 0.9400 - mDice: 0.6861 - val_loss: 0.8582 - val_acc: 0.9328 - val_mDice: 0.5374

Epoch 00028: val_mDice did not improve from 0.55397
Epoch 29/300
 - 11s - loss: 0.3532 - acc: 0.9403 - mDice: 0.6875 - val_loss: 0.8293 - val_acc: 0.9349 - val_mDice: 0.5428

Epoch 00029: val_mDice did not improve from 0.55397
Epoch 30/300
 - 10s - loss: 0.3493 - acc: 0.9406 - mDice: 0.6903 - val_loss: 0.8194 - val_acc: 0.9394 - val_mDice: 0.5551

Epoch 00030: val_mDice improved from 0.55397 to 0.55512, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 31/300
 - 10s - loss: 0.3458 - acc: 0.9410 - mDice: 0.6927 - val_loss: 0.8064 - val_acc: 0.9368 - val_mDice: 0.5475

Epoch 00031: val_mDice did not improve from 0.55512
Epoch 32/300
 - 10s - loss: 0.3416 - acc: 0.9414 - mDice: 0.6957 - val_loss: 0.8595 - val_acc: 0.9384 - val_mDice: 0.5493

Epoch 00032: val_mDice did not improve from 0.55512
Epoch 33/300
 - 11s - loss: 0.3412 - acc: 0.9414 - mDice: 0.6960 - val_loss: 0.8811 - val_acc: 0.9334 - val_mDice: 0.5371

Epoch 00033: val_mDice did not improve from 0.55512
Epoch 34/300
 - 10s - loss: 0.3385 - acc: 0.9416 - mDice: 0.6979 - val_loss: 0.8420 - val_acc: 0.9357 - val_mDice: 0.5496

Epoch 00034: val_mDice did not improve from 0.55512
Epoch 35/300
 - 10s - loss: 0.3367 - acc: 0.9419 - mDice: 0.6993 - val_loss: 0.8665 - val_acc: 0.9336 - val_mDice: 0.5378

Epoch 00035: val_mDice did not improve from 0.55512
Epoch 36/300
 - 11s - loss: 0.3340 - acc: 0.9421 - mDice: 0.7013 - val_loss: 0.8611 - val_acc: 0.9368 - val_mDice: 0.5498

Epoch 00036: val_mDice did not improve from 0.55512
Epoch 37/300
 - 10s - loss: 0.3334 - acc: 0.9422 - mDice: 0.7017 - val_loss: 0.8373 - val_acc: 0.9384 - val_mDice: 0.5435

Epoch 00037: val_mDice did not improve from 0.55512
Epoch 38/300
 - 10s - loss: 0.3293 - acc: 0.9424 - mDice: 0.7045 - val_loss: 0.8341 - val_acc: 0.9373 - val_mDice: 0.5517

Epoch 00038: val_mDice did not improve from 0.55512
Epoch 39/300
 - 11s - loss: 0.3284 - acc: 0.9425 - mDice: 0.7053 - val_loss: 0.8906 - val_acc: 0.9356 - val_mDice: 0.5385

Epoch 00039: val_mDice did not improve from 0.55512
Epoch 40/300
 - 10s - loss: 0.3272 - acc: 0.9428 - mDice: 0.7063 - val_loss: 0.8375 - val_acc: 0.9297 - val_mDice: 0.5299

Epoch 00040: val_mDice did not improve from 0.55512
Epoch 41/300
 - 10s - loss: 0.3247 - acc: 0.9428 - mDice: 0.7080 - val_loss: 0.8357 - val_acc: 0.9328 - val_mDice: 0.5484

Epoch 00041: val_mDice did not improve from 0.55512
Epoch 42/300
 - 11s - loss: 0.3247 - acc: 0.9430 - mDice: 0.7082 - val_loss: 0.8249 - val_acc: 0.9380 - val_mDice: 0.5498

Epoch 00042: val_mDice did not improve from 0.55512
Epoch 43/300
 - 10s - loss: 0.3213 - acc: 0.9433 - mDice: 0.7105 - val_loss: 0.8510 - val_acc: 0.9341 - val_mDice: 0.5302

Epoch 00043: val_mDice did not improve from 0.55512
Epoch 44/300
 - 11s - loss: 0.3213 - acc: 0.9434 - mDice: 0.7106 - val_loss: 0.8329 - val_acc: 0.9388 - val_mDice: 0.5434

Epoch 00044: val_mDice did not improve from 0.55512
Epoch 45/300
 - 10s - loss: 0.3194 - acc: 0.9435 - mDice: 0.7120 - val_loss: 0.8055 - val_acc: 0.9385 - val_mDice: 0.5532

Epoch 00045: val_mDice did not improve from 0.55512
Epoch 46/300
 - 10s - loss: 0.3166 - acc: 0.9436 - mDice: 0.7141 - val_loss: 0.8084 - val_acc: 0.9347 - val_mDice: 0.5506

Epoch 00046: val_mDice did not improve from 0.55512
Epoch 47/300
 - 10s - loss: 0.3154 - acc: 0.9438 - mDice: 0.7149 - val_loss: 0.8811 - val_acc: 0.9357 - val_mDice: 0.5274

Epoch 00047: val_mDice did not improve from 0.55512
Epoch 48/300
 - 11s - loss: 0.3131 - acc: 0.9440 - mDice: 0.7166 - val_loss: 0.7814 - val_acc: 0.9307 - val_mDice: 0.5391

Epoch 00048: val_mDice did not improve from 0.55512
Epoch 49/300
 - 10s - loss: 0.3121 - acc: 0.9439 - mDice: 0.7172 - val_loss: 0.8183 - val_acc: 0.9350 - val_mDice: 0.5439

Epoch 00049: val_mDice did not improve from 0.55512
Epoch 50/300
 - 10s - loss: 0.3113 - acc: 0.9441 - mDice: 0.7180 - val_loss: 0.8207 - val_acc: 0.9338 - val_mDice: 0.5482

Epoch 00050: val_mDice did not improve from 0.55512
Epoch 51/300
 - 10s - loss: 0.3085 - acc: 0.9443 - mDice: 0.7200 - val_loss: 0.8127 - val_acc: 0.9369 - val_mDice: 0.5445

Epoch 00051: val_mDice did not improve from 0.55512
Epoch 52/300
 - 10s - loss: 0.3092 - acc: 0.9442 - mDice: 0.7195 - val_loss: 0.7906 - val_acc: 0.9369 - val_mDice: 0.5527

Epoch 00052: val_mDice did not improve from 0.55512
Epoch 53/300
 - 11s - loss: 0.3088 - acc: 0.9443 - mDice: 0.7199 - val_loss: 0.7937 - val_acc: 0.9373 - val_mDice: 0.5496

Epoch 00053: val_mDice did not improve from 0.55512
Epoch 54/300
 - 10s - loss: 0.3066 - acc: 0.9445 - mDice: 0.7215 - val_loss: 0.7825 - val_acc: 0.9376 - val_mDice: 0.5352

Epoch 00054: val_mDice did not improve from 0.55512
Epoch 55/300
 - 10s - loss: 0.3058 - acc: 0.9446 - mDice: 0.7222 - val_loss: 0.8434 - val_acc: 0.9379 - val_mDice: 0.5465

Epoch 00055: val_mDice did not improve from 0.55512
Epoch 56/300
 - 10s - loss: 0.3046 - acc: 0.9447 - mDice: 0.7231 - val_loss: 0.7732 - val_acc: 0.9384 - val_mDice: 0.5525

Epoch 00056: val_mDice did not improve from 0.55512
Epoch 57/300
 - 11s - loss: 0.3041 - acc: 0.9448 - mDice: 0.7234 - val_loss: 0.8061 - val_acc: 0.9383 - val_mDice: 0.5527

Epoch 00057: val_mDice did not improve from 0.55512
Epoch 58/300
 - 10s - loss: 0.3015 - acc: 0.9450 - mDice: 0.7253 - val_loss: 0.7772 - val_acc: 0.9401 - val_mDice: 0.5530

Epoch 00058: val_mDice did not improve from 0.55512
Epoch 59/300
 - 10s - loss: 0.3021 - acc: 0.9451 - mDice: 0.7251 - val_loss: 0.7855 - val_acc: 0.9352 - val_mDice: 0.5427

Epoch 00059: val_mDice did not improve from 0.55512
Epoch 60/300
 - 11s - loss: 0.3001 - acc: 0.9451 - mDice: 0.7264 - val_loss: 0.8062 - val_acc: 0.9325 - val_mDice: 0.5419

Epoch 00060: val_mDice did not improve from 0.55512
Epoch 61/300
 - 10s - loss: 0.2989 - acc: 0.9452 - mDice: 0.7273 - val_loss: 0.8027 - val_acc: 0.9349 - val_mDice: 0.5411

Epoch 00061: val_mDice did not improve from 0.55512
Epoch 62/300
 - 10s - loss: 0.2966 - acc: 0.9454 - mDice: 0.7290 - val_loss: 0.7896 - val_acc: 0.9320 - val_mDice: 0.5417

Epoch 00062: val_mDice did not improve from 0.55512
Epoch 63/300
 - 10s - loss: 0.2963 - acc: 0.9455 - mDice: 0.7294 - val_loss: 0.8183 - val_acc: 0.9386 - val_mDice: 0.5389

Epoch 00063: val_mDice did not improve from 0.55512
Epoch 64/300
 - 12s - loss: 0.2968 - acc: 0.9454 - mDice: 0.7290 - val_loss: 0.7751 - val_acc: 0.9352 - val_mDice: 0.5515

Epoch 00064: val_mDice did not improve from 0.55512
Epoch 65/300
 - 11s - loss: 0.2955 - acc: 0.9455 - mDice: 0.7299 - val_loss: 0.8190 - val_acc: 0.9376 - val_mDice: 0.5229

Epoch 00065: val_mDice did not improve from 0.55512
Epoch 66/300
 - 12s - loss: 0.2941 - acc: 0.9456 - mDice: 0.7310 - val_loss: 0.7775 - val_acc: 0.9376 - val_mDice: 0.5434

Epoch 00066: val_mDice did not improve from 0.55512
Epoch 67/300
 - 11s - loss: 0.2930 - acc: 0.9457 - mDice: 0.7319 - val_loss: 0.7764 - val_acc: 0.9392 - val_mDice: 0.5431

Epoch 00067: val_mDice did not improve from 0.55512
Epoch 68/300
 - 12s - loss: 0.2912 - acc: 0.9458 - mDice: 0.7333 - val_loss: 0.7555 - val_acc: 0.9365 - val_mDice: 0.5391

Epoch 00068: val_mDice did not improve from 0.55512
Epoch 69/300
 - 11s - loss: 0.2912 - acc: 0.9460 - mDice: 0.7332 - val_loss: 0.7715 - val_acc: 0.9399 - val_mDice: 0.5432

Epoch 00069: val_mDice did not improve from 0.55512
Epoch 70/300
 - 13s - loss: 0.2904 - acc: 0.9459 - mDice: 0.7340 - val_loss: 0.7517 - val_acc: 0.9353 - val_mDice: 0.5506

Epoch 00070: val_mDice did not improve from 0.55512
Restoring model weights from the end of the best epoch
Epoch 00070: early stopping
{'val_loss': [5.259659583751972, 1.6928112552716181, 1.3646553938205426, 1.1086804224894597, 1.035665214061737, 0.9422372671274039, 0.9441207486849564, 0.8988142288648165, 0.9794376905147846, 0.9616470955885373, 0.9295631922208346, 0.8894173778020419, 0.9148576924434075, 0.8611741501551408, 0.9209131575547732, 0.973337308718608, 0.8216624443347638, 0.839960868542011, 0.8526158264050117, 0.8538082058613117, 0.8779407235292288, 0.8664264747729669, 0.8631430497536292, 0.8464990533315219, 0.9277269404668075, 0.8349472994987781, 0.8666855601164011, 0.8581662728236272, 0.8292824442570026, 0.8193600957210248, 0.8063844969639411, 0.85947919350404, 0.8810881284567026, 0.8419956931701074, 0.8664645850658417, 0.8611475573136256, 0.8373285509072818, 0.8341487187605637, 0.890627886240299, 0.8375266125568976, 0.8356719315052032, 0.8248845247121958, 0.8509718156777896, 0.8329120461757367, 0.8055458435645471, 0.8083650997051826, 0.8811226074512188, 0.7813803759905008, 0.8182531251357152, 0.8206976491671342, 0.8126722895182096, 0.790632786659094, 0.79373444043673, 0.7825246728383578, 0.8434127523348882, 0.7731991410255432, 0.8060680146400745, 0.7771776433174427, 0.7855423299165872, 0.8061543794778677, 0.8026961271579449, 0.7896426388850579, 0.818294855264517, 0.7751274911256937, 0.8189530968666077, 0.777512428852228, 0.7764488962980417, 0.7555253482781924, 0.7714872979200803, 0.7517152978823736], 'val_acc': [0.9024038200195019, 0.9034832945236793, 0.9094905807421758, 0.912123230787424, 0.916988709798226, 0.9188309128467853, 0.9218033254146576, 0.9235854286413926, 0.9240199671341822, 0.9265047174233657, 0.9255732252047613, 0.9272651786987598, 0.9278314365790441, 0.9300550130697397, 0.9310974409947028, 0.9285179651700534, 0.93164988893729, 0.9302815428146949, 0.9316082505079416, 0.933575261097688, 0.9306767651667962, 0.9327616485265585, 0.9356439801362845, 0.936302703160506, 0.9327408258731549, 0.9372619207088764, 0.9335059248484098, 0.932810189632269, 0.9348950890394357, 0.9393583352749164, 0.9368273936785184, 0.9383921852478614, 0.9333764612674713, 0.9357202419867883, 0.9336237792785351, 0.9368482025770041, 0.9383667799142691, 0.9373197372143085, 0.9356485972037683, 0.9296759435763726, 0.9328425572468684, 0.9379923412433038, 0.9340837850020483, 0.9388429270340846, 0.9384707785569705, 0.9346685386621035, 0.9356508873976194, 0.9307137704812564, 0.9350499327366169, 0.9338063987401816, 0.9368736079105964, 0.9369059869876275, 0.9372803935637841, 0.9375554460745591, 0.937902202972999, 0.9383667638668647, 0.9382766439364507, 0.9401280765350049, 0.9352348423921145, 0.9324519152824695, 0.934922816661688, 0.9320404942219074, 0.9386279697601612, 0.9352255967947153, 0.937631749189817, 0.9376479478982779, 0.9391850187228277, 0.9364644678739401, 0.9399408033260932, 0.9353249714924738], 'val_mDice': [0.07777360253609143, 0.2759426221824609, 0.34204520371097785, 0.425511933863163, 0.458350593654009, 0.4943312910886911, 0.5049627400361575, 0.5271412707292117, 0.4987749434434451, 0.49368372043737996, 0.5206708111442052, 0.5310052730716192, 0.5318597451998637, 0.5407215735087028, 0.517704692024451, 0.49787004463947737, 0.5401525583404762, 0.5410815729544713, 0.541774856356474, 0.5302176217620189, 0.5341635065583082, 0.5359244673297956, 0.5384180075847186, 0.5482863027315873, 0.5147187787179763, 0.5539713158057287, 0.5294798532357583, 0.5373956876305434, 0.5427712574601173, 0.5551235916522833, 0.5474601909518242, 0.5492551842561135, 0.5371078814451511, 0.5496246218681335, 0.5378470151470258, 0.5497728219399085, 0.5434778332710266, 0.5517282153551395, 0.5384632177077807, 0.5298793396124473, 0.5483832319195454, 0.5498293707003961, 0.5302427634596825, 0.5433580325200007, 0.553196538812839, 0.5506148750965412, 0.5274246343626425, 0.539083403463547, 0.5438661518005224, 0.5482407378462645, 0.5445239051030233, 0.5527126525457089, 0.5496377154038503, 0.5351631182890672, 0.5465431176126003, 0.5525451010236373, 0.552650388616782, 0.5529822380496905, 0.5426852703094482, 0.5418563892061894, 0.5410995125197448, 0.5417306193938622, 0.5388652246731979, 0.5515431323303626, 0.5228977638941544, 0.543408952653408, 0.5431137933180883, 0.5391467316792562, 0.5432381867789305, 0.5506142916587683], 'loss': [2.7588824618954417, 1.1378665653902655, 0.8439945296300994, 0.7130112015628225, 0.6355903132049996, 0.5751003143664909, 0.5374033103720965, 0.5138445596303336, 0.4902216792876217, 0.47150651963667645, 0.45670638279117565, 0.44602867406001445, 0.43618284972140814, 0.4240443309981874, 0.41625822961116027, 0.4109504067357985, 0.40367193070546864, 0.3969548158426627, 0.39148914852199945, 0.384751758361164, 0.38113932587624827, 0.3773245774906939, 0.36991508362929365, 0.3690484128407993, 0.3657499381721454, 0.36480810772687716, 0.35729360996846793, 0.3551366185060146, 0.3531849043160185, 0.3493203803846056, 0.3458454080732021, 0.34162766335580685, 0.3412197829392259, 0.33846755815994733, 0.3366975209089176, 0.33395523057150617, 0.33340989548672084, 0.32934736322127484, 0.3283747509898355, 0.3271691018855848, 0.324694084192701, 0.32470753777679084, 0.32128630427760985, 0.321319976663673, 0.3194286318230121, 0.3165562037424244, 0.3154363432411425, 0.313089407255517, 0.3121205411702298, 0.31129757351819454, 0.3084962125123784, 0.3092409261948704, 0.30878937806215034, 0.3066173302399478, 0.30578840354167697, 0.30458328976057714, 0.3041361363146519, 0.30152985790300707, 0.30209001299036087, 0.30014349505226956, 0.2989485990123798, 0.29662172638830153, 0.29629113929392414, 0.29682083208160975, 0.29552721053452596, 0.2940685013299673, 0.2930252159652175, 0.2911661166409488, 0.29122603881252457, 0.29037130516931864], 'acc': [0.5808961289437244, 0.8772319894836121, 0.8806529502790374, 0.8843729143640514, 0.8880459718474226, 0.8914862642986995, 0.8946689957678785, 0.8976326236742004, 0.9010055911427746, 0.9050019204446138, 0.9085729712931133, 0.9116906982214482, 0.9145384931612706, 0.9171165476577106, 0.9202165623756943, 0.9229576309085893, 0.9262644603915796, 0.9297988497605131, 0.9317907162129544, 0.9331591765862775, 0.9340973265890287, 0.9353478907615312, 0.9365844633717121, 0.9378309719107154, 0.9387485683486546, 0.9389477375357791, 0.9395743840285842, 0.9400169126367168, 0.9403375521759854, 0.9406326696748037, 0.9409672995395549, 0.9413518507377496, 0.941387633352518, 0.9416020099751505, 0.9419076876656591, 0.9420730915883585, 0.9422040276286413, 0.942442615264392, 0.9424777121481438, 0.9428191225950672, 0.942832889036203, 0.9430478457967855, 0.9432501221762959, 0.9433532062408438, 0.943453882949484, 0.9435540237440391, 0.9437647641535165, 0.9440141260310599, 0.9439487937058975, 0.9441368148839859, 0.9442751299056313, 0.9442232114950098, 0.9443177193235583, 0.9445400148654879, 0.9445703173270802, 0.9447184118421538, 0.944819633315149, 0.9449911824036137, 0.9450748977621114, 0.9451314317094964, 0.9452075172666803, 0.9453913881628537, 0.9454607612794477, 0.9454480772868058, 0.9455253389129491, 0.9455569749838046, 0.9457246440479173, 0.9458147846859759, 0.9460091044198518, 0.9459041505900848], 'mDice': [0.09867208570937307, 0.31555555530945817, 0.4154877381758816, 0.47491752283935734, 0.5149101105319457, 0.547598514732351, 0.5693002082177285, 0.583443940169563, 0.5979204476731714, 0.6093809251843327, 0.6187499061145764, 0.6256185226375345, 0.631983739324, 0.6399789049673111, 0.6452761449563617, 0.6488651774262278, 0.6536830303128724, 0.6577189861216427, 0.6613478351483691, 0.6659108606814502, 0.6683256267061052, 0.6709815710549379, 0.6761691940124324, 0.6765876028092048, 0.6787781540806372, 0.6793071218195694, 0.6845152200472198, 0.6860509831494405, 0.6874865849530643, 0.6902908828440357, 0.6927441579658123, 0.695679070896123, 0.6960032335849724, 0.6979374449532113, 0.6993418460862835, 0.7012654604380129, 0.7016570963268514, 0.7045316171802235, 0.7053034593178801, 0.7063119900267272, 0.707959535392813, 0.7081949967228925, 0.7105284644527694, 0.7106380780706499, 0.7119635010594582, 0.7140955371213753, 0.7148722593089284, 0.7166138451983104, 0.7172242845433956, 0.7179896413405905, 0.7199975970892364, 0.7194946120280704, 0.7198870772256916, 0.7215109862745176, 0.7221633469355917, 0.7230953620191013, 0.7233828535535552, 0.7253431802766521, 0.7250852449831021, 0.7263743157955396, 0.727346650384113, 0.7290072645701727, 0.7293628014443403, 0.7290211973798942, 0.7299266064132941, 0.7310144964271967, 0.731873432527683, 0.7333190882270828, 0.7332229247109032, 0.7339681652015968]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.74s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.47s/it]predicting test subjects: 100%|██████████| 3/3 [00:06<00:00,  2.26s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:02<10:23,  2.19s/it]predicting train subjects:   1%|          | 2/285 [00:03<09:31,  2.02s/it]predicting train subjects:   1%|          | 3/285 [00:05<09:20,  1.99s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<09:00,  1.92s/it]predicting train subjects:   2%|▏         | 5/285 [00:09<09:12,  1.97s/it]predicting train subjects:   2%|▏         | 6/285 [00:11<08:47,  1.89s/it]predicting train subjects:   2%|▏         | 7/285 [00:13<09:25,  2.03s/it]predicting train subjects:   3%|▎         | 8/285 [00:15<09:38,  2.09s/it]predicting train subjects:   3%|▎         | 9/285 [00:18<10:20,  2.25s/it]predicting train subjects:   4%|▎         | 10/285 [00:20<10:18,  2.25s/it]predicting train subjects:   4%|▍         | 11/285 [00:22<09:40,  2.12s/it]predicting train subjects:   4%|▍         | 12/285 [00:24<09:56,  2.18s/it]predicting train subjects:   5%|▍         | 13/285 [00:27<10:05,  2.23s/it]predicting train subjects:   5%|▍         | 14/285 [00:29<10:11,  2.26s/it]predicting train subjects:   5%|▌         | 15/285 [00:31<10:14,  2.28s/it]predicting train subjects:   6%|▌         | 16/285 [00:34<10:48,  2.41s/it]predicting train subjects:   6%|▌         | 17/285 [00:36<09:54,  2.22s/it]predicting train subjects:   6%|▋         | 18/285 [00:38<09:33,  2.15s/it]predicting train subjects:   7%|▋         | 19/285 [00:40<08:59,  2.03s/it]predicting train subjects:   7%|▋         | 20/285 [00:42<09:04,  2.05s/it]predicting train subjects:   7%|▋         | 21/285 [00:44<09:19,  2.12s/it]predicting train subjects:   8%|▊         | 22/285 [00:46<09:12,  2.10s/it]predicting train subjects:   8%|▊         | 23/285 [00:48<09:32,  2.19s/it]predicting train subjects:   8%|▊         | 24/285 [00:50<09:04,  2.09s/it]predicting train subjects:   9%|▉         | 25/285 [00:52<08:56,  2.06s/it]predicting train subjects:   9%|▉         | 26/285 [00:55<09:13,  2.14s/it]predicting train subjects:   9%|▉         | 27/285 [00:57<09:17,  2.16s/it]predicting train subjects:  10%|▉         | 28/285 [00:59<09:20,  2.18s/it]predicting train subjects:  10%|█         | 29/285 [01:01<09:17,  2.18s/it]predicting train subjects:  11%|█         | 30/285 [01:04<09:27,  2.23s/it]predicting train subjects:  11%|█         | 31/285 [01:06<09:40,  2.28s/it]predicting train subjects:  11%|█         | 32/285 [01:08<09:19,  2.21s/it]predicting train subjects:  12%|█▏        | 33/285 [01:10<09:15,  2.20s/it]predicting train subjects:  12%|█▏        | 34/285 [01:13<09:26,  2.26s/it]predicting train subjects:  12%|█▏        | 35/285 [01:15<09:29,  2.28s/it]predicting train subjects:  13%|█▎        | 36/285 [01:17<09:01,  2.17s/it]predicting train subjects:  13%|█▎        | 37/285 [01:19<09:03,  2.19s/it]predicting train subjects:  13%|█▎        | 38/285 [01:21<09:12,  2.24s/it]predicting train subjects:  14%|█▎        | 39/285 [01:23<08:39,  2.11s/it]predicting train subjects:  14%|█▍        | 40/285 [01:25<08:40,  2.12s/it]predicting train subjects:  14%|█▍        | 41/285 [01:27<08:30,  2.09s/it]predicting train subjects:  15%|█▍        | 42/285 [01:30<08:57,  2.21s/it]predicting train subjects:  15%|█▌        | 43/285 [01:32<08:45,  2.17s/it]predicting train subjects:  15%|█▌        | 44/285 [01:35<09:33,  2.38s/it]predicting train subjects:  16%|█▌        | 45/285 [01:37<09:09,  2.29s/it]predicting train subjects:  16%|█▌        | 46/285 [01:39<09:09,  2.30s/it]predicting train subjects:  16%|█▋        | 47/285 [01:41<08:44,  2.20s/it]predicting train subjects:  17%|█▋        | 48/285 [01:43<08:47,  2.23s/it]predicting train subjects:  17%|█▋        | 49/285 [01:46<09:02,  2.30s/it]predicting train subjects:  18%|█▊        | 50/285 [01:48<08:52,  2.27s/it]predicting train subjects:  18%|█▊        | 51/285 [01:51<09:12,  2.36s/it]predicting train subjects:  18%|█▊        | 52/285 [01:53<08:53,  2.29s/it]predicting train subjects:  19%|█▊        | 53/285 [01:55<08:45,  2.26s/it]predicting train subjects:  19%|█▉        | 54/285 [01:57<08:42,  2.26s/it]predicting train subjects:  19%|█▉        | 55/285 [01:59<08:22,  2.18s/it]predicting train subjects:  20%|█▉        | 56/285 [02:01<08:08,  2.13s/it]predicting train subjects:  20%|██        | 57/285 [02:03<08:06,  2.13s/it]predicting train subjects:  20%|██        | 58/285 [02:06<08:05,  2.14s/it]predicting train subjects:  21%|██        | 59/285 [02:08<08:40,  2.30s/it]predicting train subjects:  21%|██        | 60/285 [02:11<08:52,  2.37s/it]predicting train subjects:  21%|██▏       | 61/285 [02:13<08:35,  2.30s/it]predicting train subjects:  22%|██▏       | 62/285 [02:15<08:23,  2.26s/it]predicting train subjects:  22%|██▏       | 63/285 [02:17<08:19,  2.25s/it]predicting train subjects:  22%|██▏       | 64/285 [02:19<08:05,  2.20s/it]predicting train subjects:  23%|██▎       | 65/285 [02:22<08:03,  2.20s/it]predicting train subjects:  23%|██▎       | 66/285 [02:24<08:18,  2.28s/it]predicting train subjects:  24%|██▎       | 67/285 [02:26<08:04,  2.22s/it]predicting train subjects:  24%|██▍       | 68/285 [02:28<07:40,  2.12s/it]predicting train subjects:  24%|██▍       | 69/285 [02:30<07:41,  2.14s/it]predicting train subjects:  25%|██▍       | 70/285 [02:32<07:42,  2.15s/it]predicting train subjects:  25%|██▍       | 71/285 [02:35<07:41,  2.16s/it]predicting train subjects:  25%|██▌       | 72/285 [02:37<07:37,  2.15s/it]predicting train subjects:  26%|██▌       | 73/285 [02:39<07:58,  2.26s/it]predicting train subjects:  26%|██▌       | 74/285 [02:41<07:52,  2.24s/it]predicting train subjects:  26%|██▋       | 75/285 [02:44<07:51,  2.24s/it]predicting train subjects:  27%|██▋       | 76/285 [02:46<07:43,  2.22s/it]predicting train subjects:  27%|██▋       | 77/285 [02:48<07:31,  2.17s/it]predicting train subjects:  27%|██▋       | 78/285 [02:50<07:32,  2.19s/it]predicting train subjects:  28%|██▊       | 79/285 [02:52<07:31,  2.19s/it]predicting train subjects:  28%|██▊       | 80/285 [02:55<07:30,  2.20s/it]predicting train subjects:  28%|██▊       | 81/285 [02:56<07:11,  2.11s/it]predicting train subjects:  29%|██▉       | 82/285 [02:59<07:16,  2.15s/it]predicting train subjects:  29%|██▉       | 83/285 [03:01<07:27,  2.21s/it]predicting train subjects:  29%|██▉       | 84/285 [03:03<07:02,  2.10s/it]predicting train subjects:  30%|██▉       | 85/285 [03:05<07:12,  2.16s/it]predicting train subjects:  30%|███       | 86/285 [03:07<07:10,  2.16s/it]predicting train subjects:  31%|███       | 87/285 [03:09<06:57,  2.11s/it]predicting train subjects:  31%|███       | 88/285 [03:11<06:41,  2.04s/it]predicting train subjects:  31%|███       | 89/285 [03:13<06:47,  2.08s/it]predicting train subjects:  32%|███▏      | 90/285 [03:16<07:07,  2.19s/it]predicting train subjects:  32%|███▏      | 91/285 [03:18<06:52,  2.13s/it]predicting train subjects:  32%|███▏      | 92/285 [03:20<06:48,  2.12s/it]predicting train subjects:  33%|███▎      | 93/285 [03:22<06:39,  2.08s/it]predicting train subjects:  33%|███▎      | 94/285 [03:24<06:52,  2.16s/it]predicting train subjects:  33%|███▎      | 95/285 [03:27<06:55,  2.19s/it]predicting train subjects:  34%|███▎      | 96/285 [03:28<06:27,  2.05s/it]predicting train subjects:  34%|███▍      | 97/285 [03:31<06:52,  2.20s/it]predicting train subjects:  34%|███▍      | 98/285 [03:33<06:42,  2.15s/it]predicting train subjects:  35%|███▍      | 99/285 [03:35<06:14,  2.01s/it]predicting train subjects:  35%|███▌      | 100/285 [03:36<05:55,  1.92s/it]predicting train subjects:  35%|███▌      | 101/285 [03:38<05:32,  1.80s/it]predicting train subjects:  36%|███▌      | 102/285 [03:39<05:25,  1.78s/it]predicting train subjects:  36%|███▌      | 103/285 [03:41<05:12,  1.72s/it]predicting train subjects:  36%|███▋      | 104/285 [03:43<05:10,  1.72s/it]predicting train subjects:  37%|███▋      | 105/285 [03:45<05:11,  1.73s/it]predicting train subjects:  37%|███▋      | 106/285 [03:46<05:04,  1.70s/it]predicting train subjects:  38%|███▊      | 107/285 [03:48<05:05,  1.72s/it]predicting train subjects:  38%|███▊      | 108/285 [03:49<04:54,  1.67s/it]predicting train subjects:  38%|███▊      | 109/285 [03:51<04:56,  1.68s/it]predicting train subjects:  39%|███▊      | 110/285 [03:53<05:06,  1.75s/it]predicting train subjects:  39%|███▉      | 111/285 [03:55<04:59,  1.72s/it]predicting train subjects:  39%|███▉      | 112/285 [03:57<04:59,  1.73s/it]predicting train subjects:  40%|███▉      | 113/285 [03:58<05:09,  1.80s/it]predicting train subjects:  40%|████      | 114/285 [04:00<05:18,  1.86s/it]predicting train subjects:  40%|████      | 115/285 [04:02<05:17,  1.87s/it]predicting train subjects:  41%|████      | 116/285 [04:04<05:11,  1.85s/it]predicting train subjects:  41%|████      | 117/285 [04:06<04:56,  1.77s/it]predicting train subjects:  41%|████▏     | 118/285 [04:07<04:44,  1.71s/it]predicting train subjects:  42%|████▏     | 119/285 [04:09<04:48,  1.74s/it]predicting train subjects:  42%|████▏     | 120/285 [04:11<04:37,  1.68s/it]predicting train subjects:  42%|████▏     | 121/285 [04:12<04:33,  1.67s/it]predicting train subjects:  43%|████▎     | 122/285 [04:14<04:21,  1.60s/it]predicting train subjects:  43%|████▎     | 123/285 [04:15<04:13,  1.56s/it]predicting train subjects:  44%|████▎     | 124/285 [04:17<04:14,  1.58s/it]predicting train subjects:  44%|████▍     | 125/285 [04:18<04:10,  1.57s/it]predicting train subjects:  44%|████▍     | 126/285 [04:20<04:07,  1.56s/it]predicting train subjects:  45%|████▍     | 127/285 [04:21<03:57,  1.50s/it]predicting train subjects:  45%|████▍     | 128/285 [04:23<03:59,  1.52s/it]predicting train subjects:  45%|████▌     | 129/285 [04:24<03:54,  1.51s/it]predicting train subjects:  46%|████▌     | 130/285 [04:26<03:50,  1.49s/it]predicting train subjects:  46%|████▌     | 131/285 [04:27<03:46,  1.47s/it]predicting train subjects:  46%|████▋     | 132/285 [04:29<03:51,  1.51s/it]predicting train subjects:  47%|████▋     | 133/285 [04:30<03:49,  1.51s/it]predicting train subjects:  47%|████▋     | 134/285 [04:32<03:45,  1.49s/it]predicting train subjects:  47%|████▋     | 135/285 [04:33<03:42,  1.48s/it]predicting train subjects:  48%|████▊     | 136/285 [04:35<03:36,  1.45s/it]predicting train subjects:  48%|████▊     | 137/285 [04:36<03:48,  1.55s/it]predicting train subjects:  48%|████▊     | 138/285 [04:38<03:46,  1.54s/it]predicting train subjects:  49%|████▉     | 139/285 [04:40<03:57,  1.62s/it]predicting train subjects:  49%|████▉     | 140/285 [04:41<03:56,  1.63s/it]predicting train subjects:  49%|████▉     | 141/285 [04:43<03:46,  1.57s/it]predicting train subjects:  50%|████▉     | 142/285 [04:44<03:41,  1.55s/it]predicting train subjects:  50%|█████     | 143/285 [04:46<03:34,  1.51s/it]predicting train subjects:  51%|█████     | 144/285 [04:47<03:33,  1.52s/it]predicting train subjects:  51%|█████     | 145/285 [04:49<03:36,  1.55s/it]predicting train subjects:  51%|█████     | 146/285 [04:50<03:35,  1.55s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:52<03:33,  1.55s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:53<03:29,  1.53s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:55<03:30,  1.54s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:57<03:27,  1.54s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:58<03:33,  1.59s/it]predicting train subjects:  53%|█████▎    | 152/285 [05:00<03:25,  1.55s/it]predicting train subjects:  54%|█████▎    | 153/285 [05:01<03:20,  1.52s/it]predicting train subjects:  54%|█████▍    | 154/285 [05:03<03:31,  1.62s/it]predicting train subjects:  54%|█████▍    | 155/285 [05:05<03:29,  1.61s/it]predicting train subjects:  55%|█████▍    | 156/285 [05:06<03:27,  1.61s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:08<03:20,  1.57s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:09<03:20,  1.58s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:11<03:15,  1.55s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:12<03:18,  1.59s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:14<03:20,  1.62s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:16<03:14,  1.58s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:17<03:13,  1.59s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:19<03:06,  1.54s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:20<02:59,  1.50s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:22<03:03,  1.54s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:23<03:02,  1.54s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:25<03:01,  1.55s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:26<03:04,  1.59s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:28<02:59,  1.56s/it]predicting train subjects:  60%|██████    | 171/285 [05:29<02:54,  1.53s/it]predicting train subjects:  60%|██████    | 172/285 [05:31<02:53,  1.53s/it]predicting train subjects:  61%|██████    | 173/285 [05:32<02:47,  1.50s/it]predicting train subjects:  61%|██████    | 174/285 [05:34<02:49,  1.53s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:36<02:50,  1.55s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:37<02:50,  1.57s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:39<02:42,  1.50s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:40<02:35,  1.45s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:41<02:32,  1.44s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:43<02:41,  1.54s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:45<02:43,  1.58s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:46<02:45,  1.61s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:48<02:38,  1.55s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:49<02:36,  1.55s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:51<02:37,  1.58s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:53<02:46,  1.68s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:55<02:50,  1.74s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:57<02:51,  1.77s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:58<02:41,  1.69s/it]predicting train subjects:  67%|██████▋   | 190/285 [06:00<02:31,  1.60s/it]predicting train subjects:  67%|██████▋   | 191/285 [06:01<02:30,  1.61s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:03<02:31,  1.63s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:04<02:29,  1.62s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:06<02:23,  1.58s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:07<02:15,  1.50s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:09<02:20,  1.58s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:11<02:26,  1.66s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:13<02:26,  1.69s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:14<02:15,  1.58s/it]predicting train subjects:  70%|███████   | 200/285 [06:15<02:10,  1.54s/it]predicting train subjects:  71%|███████   | 201/285 [06:17<02:18,  1.64s/it]predicting train subjects:  71%|███████   | 202/285 [06:19<02:16,  1.64s/it]predicting train subjects:  71%|███████   | 203/285 [06:21<02:12,  1.62s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:22<02:05,  1.56s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:24<02:05,  1.57s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:25<01:59,  1.51s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:27<02:05,  1.61s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:28<02:07,  1.65s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:30<02:10,  1.72s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:32<01:59,  1.60s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:33<01:56,  1.57s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:35<02:00,  1.65s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:37<01:57,  1.64s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:38<01:52,  1.59s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:40<01:54,  1.64s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:41<01:50,  1.60s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:43<01:53,  1.67s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:45<01:56,  1.73s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:47<01:55,  1.76s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:48<01:47,  1.65s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:50<01:44,  1.63s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:51<01:41,  1.61s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:53<01:34,  1.53s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:54<01:32,  1.52s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:56<01:29,  1.50s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:58<01:34,  1.60s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:59<01:36,  1.66s/it]predicting train subjects:  80%|████████  | 228/285 [07:01<01:38,  1.73s/it]predicting train subjects:  80%|████████  | 229/285 [07:03<01:35,  1.70s/it]predicting train subjects:  81%|████████  | 230/285 [07:05<01:33,  1.69s/it]predicting train subjects:  81%|████████  | 231/285 [07:06<01:28,  1.65s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:08<01:27,  1.65s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:09<01:23,  1.60s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:11<01:27,  1.71s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:13<01:19,  1.59s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:14<01:22,  1.68s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:16<01:21,  1.69s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:18<01:21,  1.73s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:20<01:20,  1.75s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:21<01:13,  1.63s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:23<01:09,  1.58s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:24<01:05,  1.53s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:25<01:03,  1.52s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:27<01:06,  1.61s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:29<01:02,  1.57s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:31<01:03,  1.64s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:32<01:04,  1.70s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:34<01:03,  1.72s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:36<00:58,  1.62s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:37<00:54,  1.57s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:38<00:51,  1.52s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:40<00:49,  1.50s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:42<00:51,  1.62s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:44<00:51,  1.65s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:45<00:49,  1.66s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:47<00:47,  1.63s/it]predicting train subjects:  90%|█████████ | 257/285 [07:48<00:44,  1.58s/it]predicting train subjects:  91%|█████████ | 258/285 [07:50<00:43,  1.62s/it]predicting train subjects:  91%|█████████ | 259/285 [07:52<00:42,  1.64s/it]predicting train subjects:  91%|█████████ | 260/285 [07:53<00:39,  1.57s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:54<00:36,  1.52s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:56<00:34,  1.52s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:57<00:32,  1.48s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:59<00:33,  1.61s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:01<00:33,  1.70s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:03<00:31,  1.66s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:04<00:30,  1.68s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:06<00:30,  1.78s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:08<00:28,  1.76s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:09<00:24,  1.62s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:11<00:21,  1.55s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:12<00:20,  1.57s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:14<00:18,  1.54s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:16<00:17,  1.57s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:17<00:16,  1.67s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:19<00:15,  1.74s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:21<00:13,  1.66s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:22<00:11,  1.62s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:24<00:09,  1.62s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:25<00:07,  1.54s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:27<00:06,  1.52s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:28<00:04,  1.52s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:30<00:03,  1.60s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:32<00:01,  1.68s/it]predicting train subjects: 100%|██████████| 285/285 [08:34<00:00,  1.74s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:02<10:01,  2.12s/it]Loading train:   1%|          | 2/285 [00:03<08:46,  1.86s/it]Loading train:   1%|          | 3/285 [00:04<08:09,  1.73s/it]Loading train:   1%|▏         | 4/285 [00:06<07:39,  1.64s/it]Loading train:   2%|▏         | 5/285 [00:07<07:43,  1.66s/it]Loading train:   2%|▏         | 6/285 [00:09<07:11,  1.55s/it]Loading train:   2%|▏         | 7/285 [00:11<07:43,  1.67s/it]Loading train:   3%|▎         | 8/285 [00:12<07:21,  1.59s/it]Loading train:   3%|▎         | 9/285 [00:14<07:29,  1.63s/it]Loading train:   4%|▎         | 10/285 [00:15<07:01,  1.53s/it]Loading train:   4%|▍         | 11/285 [00:16<06:11,  1.36s/it]Loading train:   4%|▍         | 12/285 [00:17<06:00,  1.32s/it]Loading train:   5%|▍         | 13/285 [00:18<05:27,  1.21s/it]Loading train:   5%|▍         | 14/285 [00:19<05:10,  1.15s/it]Loading train:   5%|▌         | 15/285 [00:20<04:57,  1.10s/it]Loading train:   6%|▌         | 16/285 [00:21<05:03,  1.13s/it]Loading train:   6%|▌         | 17/285 [00:22<04:41,  1.05s/it]Loading train:   6%|▋         | 18/285 [00:23<04:42,  1.06s/it]Loading train:   7%|▋         | 19/285 [00:24<04:31,  1.02s/it]Loading train:   7%|▋         | 20/285 [00:26<04:47,  1.08s/it]Loading train:   7%|▋         | 21/285 [00:27<04:55,  1.12s/it]Loading train:   8%|▊         | 22/285 [00:28<04:34,  1.04s/it]Loading train:   8%|▊         | 23/285 [00:29<04:33,  1.04s/it]Loading train:   8%|▊         | 24/285 [00:30<04:21,  1.00s/it]Loading train:   9%|▉         | 25/285 [00:31<04:43,  1.09s/it]Loading train:   9%|▉         | 26/285 [00:32<04:25,  1.02s/it]Loading train:   9%|▉         | 27/285 [00:33<04:12,  1.02it/s]Loading train:  10%|▉         | 28/285 [00:34<04:25,  1.03s/it]Loading train:  10%|█         | 29/285 [00:35<04:26,  1.04s/it]Loading train:  11%|█         | 30/285 [00:36<04:15,  1.00s/it]Loading train:  11%|█         | 31/285 [00:37<04:08,  1.02it/s]Loading train:  11%|█         | 32/285 [00:37<03:50,  1.10it/s]Loading train:  12%|█▏        | 33/285 [00:38<03:44,  1.12it/s]Loading train:  12%|█▏        | 34/285 [00:39<03:46,  1.11it/s]Loading train:  12%|█▏        | 35/285 [00:40<04:12,  1.01s/it]Loading train:  13%|█▎        | 36/285 [00:41<03:55,  1.06it/s]Loading train:  13%|█▎        | 37/285 [00:42<04:02,  1.02it/s]Loading train:  13%|█▎        | 38/285 [00:44<04:22,  1.06s/it]Loading train:  14%|█▎        | 39/285 [00:44<04:11,  1.02s/it]Loading train:  14%|█▍        | 40/285 [00:46<04:15,  1.04s/it]Loading train:  14%|█▍        | 41/285 [00:46<04:02,  1.01it/s]Loading train:  15%|█▍        | 42/285 [00:47<04:04,  1.00s/it]Loading train:  15%|█▌        | 43/285 [00:48<04:04,  1.01s/it]Loading train:  15%|█▌        | 44/285 [00:49<04:02,  1.01s/it]Loading train:  16%|█▌        | 45/285 [00:50<03:55,  1.02it/s]Loading train:  16%|█▌        | 46/285 [00:52<04:04,  1.02s/it]Loading train:  16%|█▋        | 47/285 [00:52<03:56,  1.01it/s]Loading train:  17%|█▋        | 48/285 [00:53<03:54,  1.01it/s]Loading train:  17%|█▋        | 49/285 [00:55<04:08,  1.05s/it]Loading train:  18%|█▊        | 50/285 [00:56<04:07,  1.06s/it]Loading train:  18%|█▊        | 51/285 [00:57<04:15,  1.09s/it]Loading train:  18%|█▊        | 52/285 [00:58<03:57,  1.02s/it]Loading train:  19%|█▊        | 53/285 [00:59<04:08,  1.07s/it]Loading train:  19%|█▉        | 54/285 [01:00<04:14,  1.10s/it]Loading train:  19%|█▉        | 55/285 [01:01<04:08,  1.08s/it]Loading train:  20%|█▉        | 56/285 [01:02<04:03,  1.06s/it]Loading train:  20%|██        | 57/285 [01:03<03:52,  1.02s/it]Loading train:  20%|██        | 58/285 [01:04<03:54,  1.03s/it]Loading train:  21%|██        | 59/285 [01:05<03:57,  1.05s/it]Loading train:  21%|██        | 60/285 [01:06<04:09,  1.11s/it]Loading train:  21%|██▏       | 61/285 [01:07<03:55,  1.05s/it]Loading train:  22%|██▏       | 62/285 [01:08<03:53,  1.05s/it]Loading train:  22%|██▏       | 63/285 [01:10<03:55,  1.06s/it]Loading train:  22%|██▏       | 64/285 [01:11<04:18,  1.17s/it]Loading train:  23%|██▎       | 65/285 [01:12<04:40,  1.27s/it]Loading train:  23%|██▎       | 66/285 [01:14<04:28,  1.23s/it]Loading train:  24%|██▎       | 67/285 [01:14<04:07,  1.14s/it]Loading train:  24%|██▍       | 68/285 [01:15<03:51,  1.07s/it]Loading train:  24%|██▍       | 69/285 [01:16<03:44,  1.04s/it]Loading train:  25%|██▍       | 70/285 [01:17<03:47,  1.06s/it]Loading train:  25%|██▍       | 71/285 [01:19<03:46,  1.06s/it]Loading train:  25%|██▌       | 72/285 [01:19<03:34,  1.01s/it]Loading train:  26%|██▌       | 73/285 [01:21<03:38,  1.03s/it]Loading train:  26%|██▌       | 74/285 [01:21<03:30,  1.00it/s]Loading train:  26%|██▋       | 75/285 [01:22<03:30,  1.00s/it]Loading train:  27%|██▋       | 76/285 [01:24<03:41,  1.06s/it]Loading train:  27%|██▋       | 77/285 [01:25<03:39,  1.05s/it]Loading train:  27%|██▋       | 78/285 [01:26<03:34,  1.04s/it]Loading train:  28%|██▊       | 79/285 [01:27<03:26,  1.00s/it]Loading train:  28%|██▊       | 80/285 [01:28<03:26,  1.01s/it]Loading train:  28%|██▊       | 81/285 [01:29<03:20,  1.02it/s]Loading train:  29%|██▉       | 82/285 [01:29<03:17,  1.03it/s]Loading train:  29%|██▉       | 83/285 [01:30<03:12,  1.05it/s]Loading train:  29%|██▉       | 84/285 [01:31<03:10,  1.05it/s]Loading train:  30%|██▉       | 85/285 [01:32<03:11,  1.04it/s]Loading train:  30%|███       | 86/285 [01:33<03:16,  1.01it/s]Loading train:  31%|███       | 87/285 [01:35<03:28,  1.05s/it]Loading train:  31%|███       | 88/285 [01:36<03:30,  1.07s/it]Loading train:  31%|███       | 89/285 [01:37<03:23,  1.04s/it]Loading train:  32%|███▏      | 90/285 [01:38<03:17,  1.01s/it]Loading train:  32%|███▏      | 91/285 [01:39<03:15,  1.01s/it]Loading train:  32%|███▏      | 92/285 [01:40<03:17,  1.02s/it]Loading train:  33%|███▎      | 93/285 [01:41<03:07,  1.02it/s]Loading train:  33%|███▎      | 94/285 [01:42<03:06,  1.02it/s]Loading train:  33%|███▎      | 95/285 [01:43<03:11,  1.01s/it]Loading train:  34%|███▎      | 96/285 [01:44<03:10,  1.01s/it]Loading train:  34%|███▍      | 97/285 [01:45<03:11,  1.02s/it]Loading train:  34%|███▍      | 98/285 [01:46<03:08,  1.01s/it]Loading train:  35%|███▍      | 99/285 [01:47<03:02,  1.02it/s]Loading train:  35%|███▌      | 100/285 [01:48<03:01,  1.02it/s]Loading train:  35%|███▌      | 101/285 [01:49<03:03,  1.00it/s]Loading train:  36%|███▌      | 102/285 [01:50<03:07,  1.03s/it]Loading train:  36%|███▌      | 103/285 [01:50<02:52,  1.05it/s]Loading train:  36%|███▋      | 104/285 [01:51<02:47,  1.08it/s]Loading train:  37%|███▋      | 105/285 [01:52<02:48,  1.07it/s]Loading train:  37%|███▋      | 106/285 [01:53<02:37,  1.14it/s]Loading train:  38%|███▊      | 107/285 [01:54<02:32,  1.17it/s]Loading train:  38%|███▊      | 108/285 [01:55<02:33,  1.15it/s]Loading train:  38%|███▊      | 109/285 [01:56<02:35,  1.13it/s]Loading train:  39%|███▊      | 110/285 [01:57<02:40,  1.09it/s]Loading train:  39%|███▉      | 111/285 [01:58<02:38,  1.10it/s]Loading train:  39%|███▉      | 112/285 [01:59<02:46,  1.04it/s]Loading train:  40%|███▉      | 113/285 [02:00<02:52,  1.00s/it]Loading train:  40%|████      | 114/285 [02:01<02:51,  1.01s/it]Loading train:  40%|████      | 115/285 [02:02<02:47,  1.02it/s]Loading train:  41%|████      | 116/285 [02:03<02:48,  1.00it/s]Loading train:  41%|████      | 117/285 [02:04<02:43,  1.03it/s]Loading train:  41%|████▏     | 118/285 [02:05<02:40,  1.04it/s]Loading train:  42%|████▏     | 119/285 [02:06<02:40,  1.03it/s]Loading train:  42%|████▏     | 120/285 [02:06<02:33,  1.08it/s]Loading train:  42%|████▏     | 121/285 [02:08<02:50,  1.04s/it]Loading train:  43%|████▎     | 122/285 [02:09<02:53,  1.07s/it]Loading train:  43%|████▎     | 123/285 [02:10<02:59,  1.11s/it]Loading train:  44%|████▎     | 124/285 [02:11<02:43,  1.02s/it]Loading train:  44%|████▍     | 125/285 [02:12<02:32,  1.05it/s]Loading train:  44%|████▍     | 126/285 [02:12<02:24,  1.10it/s]Loading train:  45%|████▍     | 127/285 [02:13<02:17,  1.15it/s]Loading train:  45%|████▍     | 128/285 [02:14<02:13,  1.18it/s]Loading train:  45%|████▌     | 129/285 [02:15<02:14,  1.16it/s]Loading train:  46%|████▌     | 130/285 [02:16<02:11,  1.18it/s]Loading train:  46%|████▌     | 131/285 [02:16<02:06,  1.22it/s]Loading train:  46%|████▋     | 132/285 [02:17<02:09,  1.18it/s]Loading train:  47%|████▋     | 133/285 [02:18<02:10,  1.17it/s]Loading train:  47%|████▋     | 134/285 [02:19<02:11,  1.15it/s]Loading train:  47%|████▋     | 135/285 [02:20<02:13,  1.13it/s]Loading train:  48%|████▊     | 136/285 [02:21<02:24,  1.03it/s]Loading train:  48%|████▊     | 137/285 [02:22<02:20,  1.06it/s]Loading train:  48%|████▊     | 138/285 [02:23<02:15,  1.09it/s]Loading train:  49%|████▉     | 139/285 [02:24<02:11,  1.11it/s]Loading train:  49%|████▉     | 140/285 [02:25<02:04,  1.16it/s]Loading train:  49%|████▉     | 141/285 [02:26<02:07,  1.13it/s]Loading train:  50%|████▉     | 142/285 [02:26<01:59,  1.20it/s]Loading train:  50%|█████     | 143/285 [02:27<01:56,  1.21it/s]Loading train:  51%|█████     | 144/285 [02:28<02:00,  1.17it/s]Loading train:  51%|█████     | 145/285 [02:29<01:58,  1.18it/s]Loading train:  51%|█████     | 146/285 [02:30<02:00,  1.15it/s]Loading train:  52%|█████▏    | 147/285 [02:31<01:59,  1.15it/s]Loading train:  52%|█████▏    | 148/285 [02:31<01:57,  1.17it/s]Loading train:  52%|█████▏    | 149/285 [02:32<01:53,  1.20it/s]Loading train:  53%|█████▎    | 150/285 [02:33<01:49,  1.23it/s]Loading train:  53%|█████▎    | 151/285 [02:34<01:59,  1.12it/s]Loading train:  53%|█████▎    | 152/285 [02:35<01:55,  1.15it/s]Loading train:  54%|█████▎    | 153/285 [02:36<01:52,  1.18it/s]Loading train:  54%|█████▍    | 154/285 [02:37<01:52,  1.16it/s]Loading train:  54%|█████▍    | 155/285 [02:37<01:48,  1.19it/s]Loading train:  55%|█████▍    | 156/285 [02:38<01:43,  1.25it/s]Loading train:  55%|█████▌    | 157/285 [02:39<01:45,  1.21it/s]Loading train:  55%|█████▌    | 158/285 [02:40<01:48,  1.17it/s]Loading train:  56%|█████▌    | 159/285 [02:41<01:46,  1.19it/s]Loading train:  56%|█████▌    | 160/285 [02:41<01:42,  1.22it/s]Loading train:  56%|█████▋    | 161/285 [02:42<01:47,  1.15it/s]Loading train:  57%|█████▋    | 162/285 [02:43<01:43,  1.18it/s]Loading train:  57%|█████▋    | 163/285 [02:44<01:38,  1.24it/s]Loading train:  58%|█████▊    | 164/285 [02:45<01:35,  1.27it/s]Loading train:  58%|█████▊    | 165/285 [02:45<01:28,  1.35it/s]Loading train:  58%|█████▊    | 166/285 [02:46<01:28,  1.35it/s]Loading train:  59%|█████▊    | 167/285 [02:47<01:31,  1.28it/s]Loading train:  59%|█████▉    | 168/285 [02:48<01:30,  1.30it/s]Loading train:  59%|█████▉    | 169/285 [02:48<01:29,  1.29it/s]Loading train:  60%|█████▉    | 170/285 [02:49<01:29,  1.29it/s]Loading train:  60%|██████    | 171/285 [02:50<01:31,  1.24it/s]Loading train:  60%|██████    | 172/285 [02:51<01:29,  1.27it/s]Loading train:  61%|██████    | 173/285 [02:52<01:27,  1.28it/s]Loading train:  61%|██████    | 174/285 [02:52<01:26,  1.28it/s]Loading train:  61%|██████▏   | 175/285 [02:53<01:30,  1.21it/s]Loading train:  62%|██████▏   | 176/285 [02:54<01:32,  1.18it/s]Loading train:  62%|██████▏   | 177/285 [02:55<01:31,  1.18it/s]Loading train:  62%|██████▏   | 178/285 [02:56<01:28,  1.21it/s]Loading train:  63%|██████▎   | 179/285 [02:57<01:27,  1.21it/s]Loading train:  63%|██████▎   | 180/285 [02:58<01:31,  1.15it/s]Loading train:  64%|██████▎   | 181/285 [02:59<01:34,  1.10it/s]Loading train:  64%|██████▍   | 182/285 [03:00<01:33,  1.10it/s]Loading train:  64%|██████▍   | 183/285 [03:00<01:26,  1.18it/s]Loading train:  65%|██████▍   | 184/285 [03:01<01:26,  1.17it/s]Loading train:  65%|██████▍   | 185/285 [03:02<01:22,  1.20it/s]Loading train:  65%|██████▌   | 186/285 [03:03<01:24,  1.18it/s]Loading train:  66%|██████▌   | 187/285 [03:04<01:23,  1.18it/s]Loading train:  66%|██████▌   | 188/285 [03:05<01:24,  1.15it/s]Loading train:  66%|██████▋   | 189/285 [03:05<01:18,  1.22it/s]Loading train:  67%|██████▋   | 190/285 [03:06<01:15,  1.25it/s]Loading train:  67%|██████▋   | 191/285 [03:07<01:15,  1.24it/s]Loading train:  67%|██████▋   | 192/285 [03:08<01:17,  1.20it/s]Loading train:  68%|██████▊   | 193/285 [03:09<01:16,  1.20it/s]Loading train:  68%|██████▊   | 194/285 [03:09<01:12,  1.25it/s]Loading train:  68%|██████▊   | 195/285 [03:10<01:10,  1.27it/s]Loading train:  69%|██████▉   | 196/285 [03:11<01:14,  1.20it/s]Loading train:  69%|██████▉   | 197/285 [03:12<01:21,  1.08it/s]Loading train:  69%|██████▉   | 198/285 [03:13<01:22,  1.06it/s]Loading train:  70%|██████▉   | 199/285 [03:14<01:14,  1.16it/s]Loading train:  70%|███████   | 200/285 [03:15<01:10,  1.20it/s]Loading train:  71%|███████   | 201/285 [03:15<01:11,  1.17it/s]Loading train:  71%|███████   | 202/285 [03:16<01:10,  1.18it/s]Loading train:  71%|███████   | 203/285 [03:17<01:09,  1.18it/s]Loading train:  72%|███████▏  | 204/285 [03:18<01:06,  1.22it/s]Loading train:  72%|███████▏  | 205/285 [03:19<01:08,  1.17it/s]Loading train:  72%|███████▏  | 206/285 [03:20<01:05,  1.20it/s]Loading train:  73%|███████▎  | 207/285 [03:21<01:07,  1.16it/s]Loading train:  73%|███████▎  | 208/285 [03:22<01:10,  1.09it/s]Loading train:  73%|███████▎  | 209/285 [03:23<01:10,  1.08it/s]Loading train:  74%|███████▎  | 210/285 [03:23<01:05,  1.15it/s]Loading train:  74%|███████▍  | 211/285 [03:24<01:01,  1.19it/s]Loading train:  74%|███████▍  | 212/285 [03:25<01:04,  1.13it/s]Loading train:  75%|███████▍  | 213/285 [03:26<01:03,  1.13it/s]Loading train:  75%|███████▌  | 214/285 [03:27<01:00,  1.16it/s]Loading train:  75%|███████▌  | 215/285 [03:28<01:03,  1.10it/s]Loading train:  76%|███████▌  | 216/285 [03:28<00:59,  1.16it/s]Loading train:  76%|███████▌  | 217/285 [03:29<00:59,  1.13it/s]Loading train:  76%|███████▋  | 218/285 [03:30<00:59,  1.12it/s]Loading train:  77%|███████▋  | 219/285 [03:31<01:00,  1.10it/s]Loading train:  77%|███████▋  | 220/285 [03:32<00:54,  1.20it/s]Loading train:  78%|███████▊  | 221/285 [03:33<00:52,  1.22it/s]Loading train:  78%|███████▊  | 222/285 [03:34<00:52,  1.20it/s]Loading train:  78%|███████▊  | 223/285 [03:34<00:48,  1.28it/s]Loading train:  79%|███████▊  | 224/285 [03:35<00:48,  1.26it/s]Loading train:  79%|███████▉  | 225/285 [03:36<00:49,  1.20it/s]Loading train:  79%|███████▉  | 226/285 [03:37<00:52,  1.13it/s]Loading train:  80%|███████▉  | 227/285 [03:38<00:52,  1.10it/s]Loading train:  80%|████████  | 228/285 [03:39<00:51,  1.10it/s]Loading train:  80%|████████  | 229/285 [03:40<00:49,  1.12it/s]Loading train:  81%|████████  | 230/285 [03:40<00:46,  1.18it/s]Loading train:  81%|████████  | 231/285 [03:41<00:43,  1.24it/s]Loading train:  81%|████████▏ | 232/285 [03:42<00:45,  1.16it/s]Loading train:  82%|████████▏ | 233/285 [03:43<00:44,  1.17it/s]Loading train:  82%|████████▏ | 234/285 [03:44<00:46,  1.09it/s]Loading train:  82%|████████▏ | 235/285 [03:45<00:43,  1.16it/s]Loading train:  83%|████████▎ | 236/285 [03:46<00:43,  1.13it/s]Loading train:  83%|████████▎ | 237/285 [03:47<00:43,  1.10it/s]Loading train:  84%|████████▎ | 238/285 [03:48<00:43,  1.08it/s]Loading train:  84%|████████▍ | 239/285 [03:48<00:41,  1.11it/s]Loading train:  84%|████████▍ | 240/285 [03:49<00:37,  1.20it/s]Loading train:  85%|████████▍ | 241/285 [03:50<00:35,  1.23it/s]Loading train:  85%|████████▍ | 242/285 [03:51<00:33,  1.28it/s]Loading train:  85%|████████▌ | 243/285 [03:51<00:30,  1.36it/s]Loading train:  86%|████████▌ | 244/285 [03:52<00:33,  1.22it/s]Loading train:  86%|████████▌ | 245/285 [03:53<00:33,  1.19it/s]Loading train:  86%|████████▋ | 246/285 [03:54<00:34,  1.14it/s]Loading train:  87%|████████▋ | 247/285 [03:55<00:35,  1.07it/s]Loading train:  87%|████████▋ | 248/285 [03:56<00:33,  1.11it/s]Loading train:  87%|████████▋ | 249/285 [03:57<00:30,  1.17it/s]Loading train:  88%|████████▊ | 250/285 [03:58<00:29,  1.20it/s]Loading train:  88%|████████▊ | 251/285 [03:58<00:26,  1.26it/s]Loading train:  88%|████████▊ | 252/285 [03:59<00:26,  1.27it/s]Loading train:  89%|████████▉ | 253/285 [04:00<00:27,  1.16it/s]Loading train:  89%|████████▉ | 254/285 [04:01<00:28,  1.09it/s]Loading train:  89%|████████▉ | 255/285 [04:02<00:27,  1.10it/s]Loading train:  90%|████████▉ | 256/285 [04:03<00:24,  1.19it/s]Loading train:  90%|█████████ | 257/285 [04:03<00:22,  1.25it/s]Loading train:  91%|█████████ | 258/285 [04:04<00:22,  1.19it/s]Loading train:  91%|█████████ | 259/285 [04:05<00:21,  1.22it/s]Loading train:  91%|█████████ | 260/285 [04:06<00:19,  1.29it/s]Loading train:  92%|█████████▏| 261/285 [04:06<00:18,  1.32it/s]Loading train:  92%|█████████▏| 262/285 [04:07<00:16,  1.36it/s]Loading train:  92%|█████████▏| 263/285 [04:08<00:16,  1.36it/s]Loading train:  93%|█████████▎| 264/285 [04:09<00:16,  1.24it/s]Loading train:  93%|█████████▎| 265/285 [04:10<00:16,  1.20it/s]Loading train:  93%|█████████▎| 266/285 [04:11<00:15,  1.22it/s]Loading train:  94%|█████████▎| 267/285 [04:11<00:14,  1.24it/s]Loading train:  94%|█████████▍| 268/285 [04:12<00:14,  1.16it/s]Loading train:  94%|█████████▍| 269/285 [04:13<00:13,  1.17it/s]Loading train:  95%|█████████▍| 270/285 [04:14<00:12,  1.21it/s]Loading train:  95%|█████████▌| 271/285 [04:15<00:10,  1.30it/s]Loading train:  95%|█████████▌| 272/285 [04:15<00:10,  1.28it/s]Loading train:  96%|█████████▌| 273/285 [04:16<00:08,  1.34it/s]Loading train:  96%|█████████▌| 274/285 [04:17<00:07,  1.40it/s]Loading train:  96%|█████████▋| 275/285 [04:18<00:07,  1.28it/s]Loading train:  97%|█████████▋| 276/285 [04:19<00:07,  1.20it/s]Loading train:  97%|█████████▋| 277/285 [04:19<00:06,  1.24it/s]Loading train:  98%|█████████▊| 278/285 [04:20<00:05,  1.28it/s]Loading train:  98%|█████████▊| 279/285 [04:21<00:04,  1.26it/s]Loading train:  98%|█████████▊| 280/285 [04:22<00:03,  1.28it/s]Loading train:  99%|█████████▊| 281/285 [04:22<00:03,  1.30it/s]Loading train:  99%|█████████▉| 282/285 [04:23<00:02,  1.29it/s]Loading train:  99%|█████████▉| 283/285 [04:24<00:01,  1.20it/s]Loading train: 100%|█████████▉| 284/285 [04:25<00:00,  1.10it/s]Loading train: 100%|██████████| 285/285 [04:26<00:00,  1.01s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   8%|▊         | 22/285 [00:00<00:01, 216.78it/s]concatenating: train:  19%|█▉        | 54/285 [00:00<00:00, 239.64it/s]concatenating: train:  31%|███       | 89/285 [00:00<00:00, 263.41it/s]concatenating: train:  40%|████      | 114/285 [00:00<00:00, 255.76it/s]concatenating: train:  48%|████▊     | 136/285 [00:00<00:00, 201.88it/s]concatenating: train:  54%|█████▍    | 155/285 [00:00<00:00, 187.95it/s]concatenating: train:  67%|██████▋   | 190/285 [00:00<00:00, 216.98it/s]concatenating: train:  79%|███████▉  | 225/285 [00:00<00:00, 244.33it/s]concatenating: train:  91%|█████████ | 260/285 [00:00<00:00, 268.40it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 269.14it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.15s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.16s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.14s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 206.81it/s]2019-07-11 01:43:26.824920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 01:43:26.825034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 01:43:26.825052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 01:43:26.825062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 01:43:26.825501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.34it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.35it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  5.90it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.49it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.67it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.63it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  6.79it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.75it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.22it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.40it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  9.03it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.48it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  8.96it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.52it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.40it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.86it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.68it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.24it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.71it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 30)   4080        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 40, 45)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 60)   24360       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 20, 105)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 105)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 105)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 105)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 15)   4065        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 45)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 45)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 40)   16240       dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 40)   160         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 40)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 80, 40)   0           activation_11[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 85)   0           dropout_5[0][0]                  
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 13)   1118        concatenate_7[0][0]              
==================================================================================================
Total params: 143,398
Trainable params: 44,858
Non-trainable params: 98,540
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 14s - loss: 2.8107 - acc: 0.5646 - mDice: 0.0963 - val_loss: 2.0972 - val_acc: 0.9042 - val_mDice: 0.2315

Epoch 00001: val_mDice improved from -inf to 0.23147, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 9s - loss: 1.1286 - acc: 0.8759 - mDice: 0.3193 - val_loss: 1.5229 - val_acc: 0.9108 - val_mDice: 0.3706

Epoch 00002: val_mDice improved from 0.23147 to 0.37057, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 9s - loss: 0.8392 - acc: 0.8838 - mDice: 0.4209 - val_loss: 1.2866 - val_acc: 0.9163 - val_mDice: 0.4640

Epoch 00003: val_mDice improved from 0.37057 to 0.46399, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 9s - loss: 0.6742 - acc: 0.8922 - mDice: 0.4955 - val_loss: 1.3976 - val_acc: 0.9228 - val_mDice: 0.4184

Epoch 00004: val_mDice did not improve from 0.46399
Epoch 5/300
 - 9s - loss: 0.5738 - acc: 0.9023 - mDice: 0.5489 - val_loss: 1.1063 - val_acc: 0.9384 - val_mDice: 0.5287

Epoch 00005: val_mDice improved from 0.46399 to 0.52867, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 9s - loss: 0.5148 - acc: 0.9116 - mDice: 0.5829 - val_loss: 1.1951 - val_acc: 0.9256 - val_mDice: 0.5000

Epoch 00006: val_mDice did not improve from 0.52867
Epoch 7/300
 - 9s - loss: 0.4807 - acc: 0.9195 - mDice: 0.6034 - val_loss: 1.0350 - val_acc: 0.9373 - val_mDice: 0.5492

Epoch 00007: val_mDice improved from 0.52867 to 0.54921, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 9s - loss: 0.4602 - acc: 0.9245 - mDice: 0.6160 - val_loss: 1.0984 - val_acc: 0.9378 - val_mDice: 0.5121

Epoch 00008: val_mDice did not improve from 0.54921
Epoch 9/300
 - 9s - loss: 0.4454 - acc: 0.9273 - mDice: 0.6254 - val_loss: 1.0345 - val_acc: 0.9406 - val_mDice: 0.5471

Epoch 00009: val_mDice did not improve from 0.54921
Epoch 10/300
 - 9s - loss: 0.4314 - acc: 0.9291 - mDice: 0.6343 - val_loss: 1.0653 - val_acc: 0.9305 - val_mDice: 0.5399

Epoch 00010: val_mDice did not improve from 0.54921
Epoch 11/300
 - 9s - loss: 0.4249 - acc: 0.9301 - mDice: 0.6386 - val_loss: 1.0057 - val_acc: 0.9417 - val_mDice: 0.5407

Epoch 00011: val_mDice did not improve from 0.54921
Epoch 12/300
 - 9s - loss: 0.4161 - acc: 0.9312 - mDice: 0.6446 - val_loss: 0.9875 - val_acc: 0.9404 - val_mDice: 0.5620

Epoch 00012: val_mDice improved from 0.54921 to 0.56201, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 9s - loss: 0.4088 - acc: 0.9320 - mDice: 0.6493 - val_loss: 1.0919 - val_acc: 0.9381 - val_mDice: 0.4934

Epoch 00013: val_mDice did not improve from 0.56201
Epoch 14/300
 - 9s - loss: 0.4030 - acc: 0.9328 - mDice: 0.6533 - val_loss: 1.0769 - val_acc: 0.9381 - val_mDice: 0.5060

Epoch 00014: val_mDice did not improve from 0.56201
Epoch 15/300
 - 9s - loss: 0.3963 - acc: 0.9336 - mDice: 0.6576 - val_loss: 0.9814 - val_acc: 0.9424 - val_mDice: 0.5483

Epoch 00015: val_mDice did not improve from 0.56201
Epoch 16/300
 - 9s - loss: 0.3905 - acc: 0.9344 - mDice: 0.6615 - val_loss: 0.9942 - val_acc: 0.9421 - val_mDice: 0.5386

Epoch 00016: val_mDice did not improve from 0.56201
Epoch 17/300
 - 9s - loss: 0.3880 - acc: 0.9346 - mDice: 0.6633 - val_loss: 0.9827 - val_acc: 0.9364 - val_mDice: 0.5594

Epoch 00017: val_mDice did not improve from 0.56201
Epoch 18/300
 - 9s - loss: 0.3849 - acc: 0.9351 - mDice: 0.6655 - val_loss: 0.9807 - val_acc: 0.9424 - val_mDice: 0.5507

Epoch 00018: val_mDice did not improve from 0.56201
Epoch 19/300
 - 9s - loss: 0.3798 - acc: 0.9356 - mDice: 0.6690 - val_loss: 0.9240 - val_acc: 0.9441 - val_mDice: 0.5693

Epoch 00019: val_mDice improved from 0.56201 to 0.56929, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 20/300
 - 9s - loss: 0.3781 - acc: 0.9357 - mDice: 0.6701 - val_loss: 0.9221 - val_acc: 0.9452 - val_mDice: 0.5744

Epoch 00020: val_mDice improved from 0.56929 to 0.57440, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 21/300
 - 9s - loss: 0.3712 - acc: 0.9365 - mDice: 0.6749 - val_loss: 1.0114 - val_acc: 0.9416 - val_mDice: 0.5182

Epoch 00021: val_mDice did not improve from 0.57440
Epoch 22/300
 - 9s - loss: 0.3697 - acc: 0.9367 - mDice: 0.6759 - val_loss: 0.9764 - val_acc: 0.9397 - val_mDice: 0.5618

Epoch 00022: val_mDice did not improve from 0.57440
Epoch 23/300
 - 9s - loss: 0.3666 - acc: 0.9371 - mDice: 0.6781 - val_loss: 0.9856 - val_acc: 0.9339 - val_mDice: 0.5643

Epoch 00023: val_mDice did not improve from 0.57440
Epoch 24/300
 - 9s - loss: 0.3635 - acc: 0.9373 - mDice: 0.6803 - val_loss: 0.9439 - val_acc: 0.9440 - val_mDice: 0.5537

Epoch 00024: val_mDice did not improve from 0.57440
Epoch 25/300
 - 9s - loss: 0.3614 - acc: 0.9374 - mDice: 0.6818 - val_loss: 1.0079 - val_acc: 0.9395 - val_mDice: 0.5026

Epoch 00025: val_mDice did not improve from 0.57440
Epoch 26/300
 - 9s - loss: 0.3585 - acc: 0.9378 - mDice: 0.6839 - val_loss: 0.9411 - val_acc: 0.9432 - val_mDice: 0.5593

Epoch 00026: val_mDice did not improve from 0.57440
Epoch 27/300
 - 9s - loss: 0.3587 - acc: 0.9379 - mDice: 0.6837 - val_loss: 0.9181 - val_acc: 0.9418 - val_mDice: 0.5603

Epoch 00027: val_mDice did not improve from 0.57440
Epoch 28/300
 - 9s - loss: 0.3547 - acc: 0.9382 - mDice: 0.6865 - val_loss: 0.9987 - val_acc: 0.9351 - val_mDice: 0.5496

Epoch 00028: val_mDice did not improve from 0.57440
Epoch 29/300
 - 9s - loss: 0.3527 - acc: 0.9384 - mDice: 0.6880 - val_loss: 0.9696 - val_acc: 0.9426 - val_mDice: 0.5368

Epoch 00029: val_mDice did not improve from 0.57440
Epoch 30/300
 - 9s - loss: 0.3510 - acc: 0.9387 - mDice: 0.6892 - val_loss: 0.9100 - val_acc: 0.9402 - val_mDice: 0.5553

Epoch 00030: val_mDice did not improve from 0.57440
Epoch 31/300
 - 9s - loss: 0.3477 - acc: 0.9389 - mDice: 0.6915 - val_loss: 0.9440 - val_acc: 0.9419 - val_mDice: 0.5577

Epoch 00031: val_mDice did not improve from 0.57440
Epoch 32/300
 - 9s - loss: 0.3454 - acc: 0.9390 - mDice: 0.6931 - val_loss: 0.8811 - val_acc: 0.9453 - val_mDice: 0.5725

Epoch 00032: val_mDice did not improve from 0.57440
Epoch 33/300
 - 9s - loss: 0.3452 - acc: 0.9391 - mDice: 0.6933 - val_loss: 0.8640 - val_acc: 0.9451 - val_mDice: 0.5684

Epoch 00033: val_mDice did not improve from 0.57440
Epoch 34/300
 - 9s - loss: 0.3426 - acc: 0.9394 - mDice: 0.6952 - val_loss: 0.9017 - val_acc: 0.9348 - val_mDice: 0.5497

Epoch 00034: val_mDice did not improve from 0.57440
Epoch 35/300
 - 9s - loss: 0.3409 - acc: 0.9396 - mDice: 0.6965 - val_loss: 0.8525 - val_acc: 0.9445 - val_mDice: 0.5783

Epoch 00035: val_mDice improved from 0.57440 to 0.57834, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 36/300
 - 9s - loss: 0.3418 - acc: 0.9392 - mDice: 0.6957 - val_loss: 0.8738 - val_acc: 0.9446 - val_mDice: 0.5593

Epoch 00036: val_mDice did not improve from 0.57834
Epoch 37/300
 - 9s - loss: 0.3379 - acc: 0.9398 - mDice: 0.6985 - val_loss: 0.8852 - val_acc: 0.9447 - val_mDice: 0.5558

Epoch 00037: val_mDice did not improve from 0.57834
Epoch 38/300
 - 9s - loss: 0.3360 - acc: 0.9400 - mDice: 0.7000 - val_loss: 0.9017 - val_acc: 0.9435 - val_mDice: 0.5687

Epoch 00038: val_mDice did not improve from 0.57834
Epoch 39/300
 - 9s - loss: 0.3335 - acc: 0.9403 - mDice: 0.7017 - val_loss: 0.8629 - val_acc: 0.9448 - val_mDice: 0.5557

Epoch 00039: val_mDice did not improve from 0.57834
Epoch 40/300
 - 9s - loss: 0.3337 - acc: 0.9402 - mDice: 0.7016 - val_loss: 0.8466 - val_acc: 0.9447 - val_mDice: 0.5598

Epoch 00040: val_mDice did not improve from 0.57834
Epoch 41/300
 - 9s - loss: 0.3312 - acc: 0.9404 - mDice: 0.7033 - val_loss: 0.8430 - val_acc: 0.9452 - val_mDice: 0.5611

Epoch 00041: val_mDice did not improve from 0.57834
Epoch 42/300
 - 9s - loss: 0.3283 - acc: 0.9407 - mDice: 0.7055 - val_loss: 0.8401 - val_acc: 0.9439 - val_mDice: 0.5620

Epoch 00042: val_mDice did not improve from 0.57834
Epoch 43/300
 - 9s - loss: 0.3282 - acc: 0.9408 - mDice: 0.7055 - val_loss: 0.8308 - val_acc: 0.9432 - val_mDice: 0.5780

Epoch 00043: val_mDice did not improve from 0.57834
Epoch 44/300
 - 9s - loss: 0.3282 - acc: 0.9407 - mDice: 0.7056 - val_loss: 0.8552 - val_acc: 0.9422 - val_mDice: 0.5663

Epoch 00044: val_mDice did not improve from 0.57834
Epoch 45/300
 - 9s - loss: 0.3275 - acc: 0.9409 - mDice: 0.7061 - val_loss: 0.8498 - val_acc: 0.9425 - val_mDice: 0.5519

Epoch 00045: val_mDice did not improve from 0.57834
Epoch 46/300
 - 9s - loss: 0.3263 - acc: 0.9409 - mDice: 0.7070 - val_loss: 0.7918 - val_acc: 0.9429 - val_mDice: 0.5825

Epoch 00046: val_mDice improved from 0.57834 to 0.58250, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 47/300
 - 9s - loss: 0.3242 - acc: 0.9410 - mDice: 0.7084 - val_loss: 0.8285 - val_acc: 0.9414 - val_mDice: 0.5636

Epoch 00047: val_mDice did not improve from 0.58250
Epoch 48/300
 - 9s - loss: 0.3234 - acc: 0.9411 - mDice: 0.7091 - val_loss: 0.8250 - val_acc: 0.9446 - val_mDice: 0.5455

Epoch 00048: val_mDice did not improve from 0.58250
Epoch 49/300
 - 9s - loss: 0.3233 - acc: 0.9411 - mDice: 0.7091 - val_loss: 0.8308 - val_acc: 0.9437 - val_mDice: 0.5362

Epoch 00049: val_mDice did not improve from 0.58250
Epoch 50/300
 - 9s - loss: 0.3216 - acc: 0.9413 - mDice: 0.7103 - val_loss: 0.8279 - val_acc: 0.9398 - val_mDice: 0.5616

Epoch 00050: val_mDice did not improve from 0.58250
Epoch 51/300
 - 9s - loss: 0.3203 - acc: 0.9415 - mDice: 0.7114 - val_loss: 0.8435 - val_acc: 0.9435 - val_mDice: 0.5257

Epoch 00051: val_mDice did not improve from 0.58250
Epoch 52/300
 - 9s - loss: 0.3193 - acc: 0.9414 - mDice: 0.7120 - val_loss: 0.8120 - val_acc: 0.9422 - val_mDice: 0.5513

Epoch 00052: val_mDice did not improve from 0.58250
Epoch 53/300
 - 9s - loss: 0.3183 - acc: 0.9416 - mDice: 0.7129 - val_loss: 0.7676 - val_acc: 0.9430 - val_mDice: 0.5515

Epoch 00053: val_mDice did not improve from 0.58250
Epoch 54/300
 - 9s - loss: 0.3180 - acc: 0.9417 - mDice: 0.7131 - val_loss: 0.8415 - val_acc: 0.9360 - val_mDice: 0.5524

Epoch 00054: val_mDice did not improve from 0.58250
Epoch 55/300
 - 9s - loss: 0.3162 - acc: 0.9419 - mDice: 0.7145 - val_loss: 0.8122 - val_acc: 0.9367 - val_mDice: 0.5596

Epoch 00055: val_mDice did not improve from 0.58250
Epoch 56/300
 - 9s - loss: 0.3158 - acc: 0.9419 - mDice: 0.7147 - val_loss: 0.7596 - val_acc: 0.9429 - val_mDice: 0.5591

Epoch 00056: val_mDice did not improve from 0.58250
Epoch 57/300
 - 9s - loss: 0.3158 - acc: 0.9418 - mDice: 0.7148 - val_loss: 0.7775 - val_acc: 0.9457 - val_mDice: 0.5615

Epoch 00057: val_mDice did not improve from 0.58250
Epoch 58/300
 - 9s - loss: 0.3144 - acc: 0.9419 - mDice: 0.7157 - val_loss: 0.8320 - val_acc: 0.9430 - val_mDice: 0.5311

Epoch 00058: val_mDice did not improve from 0.58250
Epoch 59/300
 - 9s - loss: 0.3141 - acc: 0.9421 - mDice: 0.7161 - val_loss: 0.8579 - val_acc: 0.9420 - val_mDice: 0.5107

Epoch 00059: val_mDice did not improve from 0.58250
Epoch 60/300
 - 9s - loss: 0.3123 - acc: 0.9421 - mDice: 0.7174 - val_loss: 0.7645 - val_acc: 0.9425 - val_mDice: 0.5714

Epoch 00060: val_mDice did not improve from 0.58250
Epoch 61/300
 - 9s - loss: 0.3099 - acc: 0.9423 - mDice: 0.7191 - val_loss: 0.7522 - val_acc: 0.9393 - val_mDice: 0.5638

Epoch 00061: val_mDice did not improve from 0.58250
Epoch 62/300
 - 9s - loss: 0.3111 - acc: 0.9423 - mDice: 0.7182 - val_loss: 0.7388 - val_acc: 0.9409 - val_mDice: 0.5562

Epoch 00062: val_mDice did not improve from 0.58250
Epoch 63/300
 - 9s - loss: 0.3093 - acc: 0.9425 - mDice: 0.7196 - val_loss: 0.7651 - val_acc: 0.9381 - val_mDice: 0.5523

Epoch 00063: val_mDice did not improve from 0.58250
Epoch 64/300
 - 9s - loss: 0.3082 - acc: 0.9425 - mDice: 0.7205 - val_loss: 0.7022 - val_acc: 0.9451 - val_mDice: 0.5723

Epoch 00064: val_mDice did not improve from 0.58250
Epoch 65/300
 - 9s - loss: 0.3086 - acc: 0.9425 - mDice: 0.7202 - val_loss: 0.7636 - val_acc: 0.9443 - val_mDice: 0.5588

Epoch 00065: val_mDice did not improve from 0.58250
Epoch 66/300
 - 9s - loss: 0.3080 - acc: 0.9426 - mDice: 0.7206 - val_loss: 0.6952 - val_acc: 0.9453 - val_mDice: 0.5537

Epoch 00066: val_mDice did not improve from 0.58250
Epoch 67/300
 - 9s - loss: 0.3063 - acc: 0.9426 - mDice: 0.7218 - val_loss: 0.7107 - val_acc: 0.9426 - val_mDice: 0.5731

Epoch 00067: val_mDice did not improve from 0.58250
Epoch 68/300
 - 9s - loss: 0.3062 - acc: 0.9428 - mDice: 0.7220 - val_loss: 0.7249 - val_acc: 0.9456 - val_mDice: 0.5643

Epoch 00068: val_mDice did not improve from 0.58250
Epoch 69/300
 - 9s - loss: 0.3048 - acc: 0.9428 - mDice: 0.7230 - val_loss: 0.6675 - val_acc: 0.9440 - val_mDice: 0.5661

Epoch 00069: val_mDice did not improve from 0.58250
Epoch 70/300
 - 9s - loss: 0.3048 - acc: 0.9427 - mDice: 0.7230 - val_loss: 0.7207 - val_acc: 0.9403 - val_mDice: 0.5341

Epoch 00070: val_mDice did not improve from 0.58250
Epoch 71/300
 - 9s - loss: 0.3039 - acc: 0.9428 - mDice: 0.7236 - val_loss: 0.6554 - val_acc: 0.9438 - val_mDice: 0.5592

Epoch 00071: val_mDice did not improve from 0.58250
Epoch 72/300
 - 9s - loss: 0.3042 - acc: 0.9428 - mDice: 0.7235 - val_loss: 0.7536 - val_acc: 0.9382 - val_mDice: 0.5450

Epoch 00072: val_mDice did not improve from 0.58250
Epoch 73/300
 - 9s - loss: 0.3024 - acc: 0.9429 - mDice: 0.7247 - val_loss: 0.7213 - val_acc: 0.9418 - val_mDice: 0.5469

Epoch 00073: val_mDice did not improve from 0.58250
Epoch 74/300
 - 9s - loss: 0.3015 - acc: 0.9432 - mDice: 0.7256 - val_loss: 0.7425 - val_acc: 0.9439 - val_mDice: 0.5455

Epoch 00074: val_mDice did not improve from 0.58250
Epoch 75/300
 - 9s - loss: 0.3020 - acc: 0.9429 - mDice: 0.7251 - val_loss: 0.7076 - val_acc: 0.9438 - val_mDice: 0.5492

Epoch 00075: val_mDice did not improve from 0.58250
Epoch 76/300
 - 9s - loss: 0.2996 - acc: 0.9432 - mDice: 0.7269 - val_loss: 0.7553 - val_acc: 0.9433 - val_mDice: 0.5589

Epoch 00076: val_mDice did not improve from 0.58250
Epoch 77/300
 - 9s - loss: 0.3011 - acc: 0.9431 - mDice: 0.7259 - val_loss: 0.6830 - val_acc: 0.9410 - val_mDice: 0.5566

Epoch 00077: val_mDice did not improve from 0.58250
Epoch 78/300
 - 9s - loss: 0.3011 - acc: 0.9431 - mDice: 0.7258 - val_loss: 0.7382 - val_acc: 0.9405 - val_mDice: 0.5558

Epoch 00078: val_mDice did not improve from 0.58250
Epoch 79/300
 - 9s - loss: 0.3007 - acc: 0.9429 - mDice: 0.7261 - val_loss: 0.7774 - val_acc: 0.9442 - val_mDice: 0.5444

Epoch 00079: val_mDice did not improve from 0.58250
Epoch 80/300
 - 9s - loss: 0.2989 - acc: 0.9431 - mDice: 0.7274 - val_loss: 0.6796 - val_acc: 0.9360 - val_mDice: 0.5572

Epoch 00080: val_mDice did not improve from 0.58250
Epoch 81/300
 - 9s - loss: 0.2970 - acc: 0.9435 - mDice: 0.7289 - val_loss: 0.7173 - val_acc: 0.9398 - val_mDice: 0.5693

Epoch 00081: val_mDice did not improve from 0.58250
Epoch 82/300
 - 9s - loss: 0.2982 - acc: 0.9433 - mDice: 0.7280 - val_loss: 0.6985 - val_acc: 0.9376 - val_mDice: 0.5728

Epoch 00082: val_mDice did not improve from 0.58250
Epoch 83/300
 - 9s - loss: 0.2979 - acc: 0.9434 - mDice: 0.7283 - val_loss: 0.6403 - val_acc: 0.9451 - val_mDice: 0.5675

Epoch 00083: val_mDice did not improve from 0.58250
Epoch 84/300
 - 9s - loss: 0.2977 - acc: 0.9434 - mDice: 0.7284 - val_loss: 0.7007 - val_acc: 0.9349 - val_mDice: 0.5404

Epoch 00084: val_mDice did not improve from 0.58250
Epoch 85/300
 - 9s - loss: 0.2981 - acc: 0.9433 - mDice: 0.7281 - val_loss: 0.7529 - val_acc: 0.9432 - val_mDice: 0.5362

Epoch 00085: val_mDice did not improve from 0.58250
Epoch 86/300
 - 9s - loss: 0.2962 - acc: 0.9436 - mDice: 0.7296 - val_loss: 0.6789 - val_acc: 0.9344 - val_mDice: 0.5632

Epoch 00086: val_mDice did not improve from 0.58250
Restoring model weights from the end of the best epoch
Epoch 00086: early stopping
{'val_loss': [2.0971998941330683, 1.522862468447004, 1.2866477852775937, 1.3975725514548165, 1.10628266561599, 1.1951123646327428, 1.0350110190255302, 1.0983685084751673, 1.0345274153209867, 1.0652783598218645, 1.0057107380458288, 0.9874551636832101, 1.0919010298592704, 1.0769183749244327, 0.9814310414450509, 0.9942131269545782, 0.9826608725956508, 0.9807418414524623, 0.9239872921080816, 0.9221368801026117, 1.011445681254069, 0.9763751484098888, 0.9855987344469342, 0.9439329987480527, 1.0079323450724285, 0.9410725094023205, 0.918068318139939, 0.9986644245329357, 0.9696171851385207, 0.9100243591126942, 0.9440237908136278, 0.8811466353280204, 0.863951563835144, 0.9017172540937152, 0.8525243146078927, 0.8738406839824858, 0.8852273169017973, 0.9016771997724261, 0.8629201934451148, 0.8465720358349028, 0.8430146149226597, 0.8400770596095494, 0.8308357113883609, 0.8552281175340924, 0.8497968741825649, 0.7918052957171485, 0.828479528427124, 0.8250182242620558, 0.8308466275533041, 0.8278897943950835, 0.8434818245115734, 0.8119720731462751, 0.7675699392954508, 0.8414912450881231, 0.8122287364233107, 0.7595703034173875, 0.7774933406284877, 0.8319617680140904, 0.8579089755103702, 0.7645469733646938, 0.7522459938412621, 0.7387949852716356, 0.765086775734311, 0.7022375095458258, 0.7636384509858631, 0.6951987175714403, 0.7106536570049468, 0.724941821325393, 0.6674633537020002, 0.7206706887199765, 0.6553838366553897, 0.7536030951000395, 0.7213223207564581, 0.7425258954366049, 0.7076157047635033, 0.7552821636199951, 0.6829504285539899, 0.7381855533236549, 0.7774213495708647, 0.6795822779337565, 0.7173336687542143, 0.6984823147455851, 0.6402710846492222, 0.7007492042723156, 0.7529115222749256, 0.6789473919641404], 'val_acc': [0.904182663985661, 0.9107829758099147, 0.9163461781683422, 0.9228205340249198, 0.9383905671891712, 0.9255814750989279, 0.9373351619357154, 0.9377518551690238, 0.9406158469972157, 0.9305036550476438, 0.9417284670330229, 0.9404304027557373, 0.9380837792441958, 0.9381341366540819, 0.9423763751983643, 0.9420993498393467, 0.9364377118292309, 0.9423511766252064, 0.9440865317980448, 0.9452083423024132, 0.9416071204912095, 0.939748139608474, 0.9338690553392682, 0.9440338696752276, 0.939503224123092, 0.9431616465250651, 0.9417925987924848, 0.9351076143128532, 0.9426099033582778, 0.9401510783604213, 0.9418681065241495, 0.9452953537305196, 0.9450938474564325, 0.9347687562306722, 0.9445077833675203, 0.9446497304098946, 0.9446977859451657, 0.9435279397737413, 0.9447802106539408, 0.9447207223801386, 0.9452083451407296, 0.9439148335229783, 0.9432120096115839, 0.9422001129104978, 0.9425000009082612, 0.942944137823014, 0.9413759311040243, 0.9445948061488924, 0.9437317025093805, 0.9398214277767, 0.9435302104268756, 0.9422184285663423, 0.9430105118524461, 0.9360279384113493, 0.9366551978247506, 0.9429281240417844, 0.9456822247732253, 0.9429739004089719, 0.9419665733973185, 0.9425182966958909, 0.9392926011766706, 0.9408539533615112, 0.9380654635883513, 0.9450892720903669, 0.9442788248970395, 0.9452884594599406, 0.9425801152274722, 0.9456410351253691, 0.9440384592328753, 0.9402861595153809, 0.9438141300564721, 0.9381730868702843, 0.9417857016835894, 0.943857593195779, 0.9437660120782398, 0.9433150206293378, 0.9409890118099394, 0.9404967853001186, 0.9442216356595358, 0.9359684302693322, 0.9397619167963663, 0.93756407783145, 0.9451075934228443, 0.9349335886183239, 0.9432417296227955, 0.9343727287792024], 'val_mDice': [0.23147313261315935, 0.37057242081278846, 0.4639886977771918, 0.4183687111806302, 0.5286690837570599, 0.5000288014610609, 0.5492107568397409, 0.5120960161799476, 0.5470637336728119, 0.5399027486287412, 0.5407309532165527, 0.5620148045321306, 0.4934357502275989, 0.5060347354128247, 0.5482547407348951, 0.5385794623621872, 0.5594354438639823, 0.5507339755339282, 0.5692923455720856, 0.574403910764626, 0.5181732014531181, 0.5618337291691985, 0.5643287616826239, 0.5536823272705078, 0.5025920296708742, 0.5592767323056856, 0.5603351747351033, 0.549605212750889, 0.5367727279663086, 0.5553284546449071, 0.5576648981798262, 0.5725320662770953, 0.5683984532952309, 0.5497485683077857, 0.5783428634916034, 0.5592572706795874, 0.5557709740740913, 0.5687375139622461, 0.5557253550560701, 0.5598256438970566, 0.5611192619516736, 0.5619782894140198, 0.5779944237853799, 0.5663000849031267, 0.5518747147704873, 0.5824987157469704, 0.5635635545920759, 0.5455411147503626, 0.5361918869117895, 0.5616062049354825, 0.5257450189618837, 0.5512847068409125, 0.551481496720087, 0.5524125180783725, 0.5595948536481176, 0.5590630753764084, 0.5614791317355066, 0.5310916173316184, 0.51072687123503, 0.5714308385338102, 0.5638383055726687, 0.556225346667426, 0.5523340373876549, 0.5722865646793729, 0.5587643253661337, 0.5537471544174921, 0.5731455257960728, 0.564349561752308, 0.5661014898547104, 0.5341348781117371, 0.5591717830726078, 0.5450280564171928, 0.5469415916928223, 0.5454740394793806, 0.549169393345004, 0.5589362893785749, 0.5565562173724174, 0.5557559570741086, 0.544417146061148, 0.5571741346447241, 0.569261796062901, 0.5728430320464429, 0.5675400140739623, 0.5403518229722977, 0.5362052339173499, 0.5632029266229698], 'loss': [2.8106819151085376, 1.128570439924917, 0.8391980476316883, 0.6742350087704538, 0.5737614428374219, 0.5148132223372334, 0.48070703530463266, 0.46024239285616875, 0.4454198235752543, 0.43139114681755575, 0.42485935138856284, 0.41606862563514196, 0.40884825729763025, 0.40300252463676484, 0.3962991982267522, 0.3905334002955102, 0.3880232884712892, 0.3849306809596526, 0.37975404559359377, 0.3781198451680808, 0.3712332965276456, 0.36971965220155156, 0.36662256913606156, 0.363478668747965, 0.36138496026956946, 0.3585038557490655, 0.3586975220416308, 0.35471632945094006, 0.35267735620397167, 0.35095332451171907, 0.34772967913028063, 0.3453948373782605, 0.34516143985559467, 0.3425594978199682, 0.3408588537860519, 0.3417983390024592, 0.3378798031947138, 0.3359547559353619, 0.3335447528124637, 0.3337263402530677, 0.33123473371180673, 0.32830475430762535, 0.32824099880894736, 0.32818319466225737, 0.32753548893092893, 0.32629777718904923, 0.3242037052625127, 0.3234026559072123, 0.3233363789665876, 0.3215653996764522, 0.32027128480729605, 0.31934770614810826, 0.31831698772625494, 0.31796871871187066, 0.3161971902075084, 0.31577462622120545, 0.3157580796523615, 0.3143566599098134, 0.31405993357246176, 0.31226505420445616, 0.3098657645999018, 0.3111264317429132, 0.30925548637398226, 0.3081579544547897, 0.30860521167327104, 0.30795075862031235, 0.306333809033832, 0.30616984236141565, 0.3047682050509974, 0.30475395022156565, 0.3039359150018815, 0.30422852255141136, 0.30243917887716915, 0.3015008693845005, 0.3020317970970956, 0.299641405016971, 0.3010788620529502, 0.30108718998932715, 0.3007457848801327, 0.29885825460210386, 0.2970458640398629, 0.29815478527249456, 0.29788978428010515, 0.2976628892599146, 0.29814402526091904, 0.29616792062493175], 'acc': [0.5646332671716077, 0.8759373236258686, 0.8837946599817286, 0.8921685673056574, 0.9023413275371565, 0.9116303600142497, 0.9195074866864639, 0.9244780996895168, 0.9272948234601128, 0.9290868414144698, 0.9301062365683237, 0.9311774719168231, 0.9320479928815161, 0.9328374791425709, 0.9335544621045819, 0.934376272445978, 0.9345886453466193, 0.9351458547546014, 0.9356138111195031, 0.935659576133425, 0.9364677411824586, 0.9366826820125326, 0.9370535008245887, 0.9373054267561732, 0.9374493722950582, 0.9377724777211199, 0.9378877091849036, 0.9381549733439369, 0.938394755326141, 0.9386523093059386, 0.9389111648434179, 0.9390188896382546, 0.9390510037866014, 0.9394398055739409, 0.9396024491944616, 0.9392272517794654, 0.9397891245872868, 0.9400164619424289, 0.9403193179228551, 0.9402084858035545, 0.9403920295910958, 0.9407108959168948, 0.9408229369521486, 0.9407119843365486, 0.9409101977039446, 0.9409026668805802, 0.9410152378766229, 0.9411180743781362, 0.9411193959304357, 0.9413311821843977, 0.9414927627922185, 0.9414417812399996, 0.9416271162005502, 0.9417371771596221, 0.9419021894758507, 0.9418875848440299, 0.9418044931423878, 0.9418597318474811, 0.942080306264507, 0.9421134892860451, 0.9422751592031582, 0.94226371192831, 0.9425285208746949, 0.9425016152782892, 0.9424791442927355, 0.942632560362723, 0.942624937035524, 0.9428033371617023, 0.9428475967762625, 0.9427156788157847, 0.9427732417343071, 0.9428155959882051, 0.9428957003101072, 0.9431617380981159, 0.9428976484523565, 0.9432302066326969, 0.9431173842215735, 0.943062954907797, 0.9429341863753916, 0.9431296388538031, 0.9434655654837176, 0.9433268355063811, 0.9434263590950944, 0.9433888421597361, 0.9433417605462046, 0.9435857355606126], 'mDice': [0.09631526489288379, 0.31932813750771355, 0.42088617983985, 0.49545223471147143, 0.5489341913447207, 0.5829286421220933, 0.6034499287306515, 0.6160086945161807, 0.6253743024605052, 0.6342869823967673, 0.6385818020052273, 0.6445877799552048, 0.6493450527088201, 0.6532839091384436, 0.6575582566140864, 0.6614979442567386, 0.6633299160077205, 0.6654549761845332, 0.6689931843031204, 0.6700909336293068, 0.6748884368407053, 0.6759434461892398, 0.678092433867575, 0.6803385088479149, 0.6817718178453256, 0.6838728803785775, 0.6837257698410988, 0.686519803225431, 0.6879817607983335, 0.6891536470297929, 0.6914864027226663, 0.6931459505663273, 0.6932995741551659, 0.6952281592322931, 0.6964873428034005, 0.6957203425353539, 0.6985361646980777, 0.700005803984761, 0.7016803417818059, 0.7015559533806649, 0.7033442682398982, 0.7054646861835875, 0.7055294815690066, 0.7056356474616428, 0.706116612140949, 0.7069559245411086, 0.7084493181690307, 0.7090659104653905, 0.7090612979828794, 0.7103413650243526, 0.7114198341152675, 0.712049446757276, 0.7128603884956385, 0.7131312189245582, 0.7144731591495678, 0.7147229674328079, 0.7147886657475827, 0.7157456274779058, 0.7160613895243985, 0.7173955083031266, 0.7191491335233972, 0.7182152075691216, 0.7196328923815772, 0.7204878463068518, 0.7201874930435278, 0.7206337014926015, 0.7218101688471975, 0.7220151504960988, 0.7229743248147268, 0.7230291242472625, 0.7235587050235867, 0.7234867507261832, 0.7247411015637237, 0.7255678506216516, 0.7251384161055053, 0.7268616048407642, 0.7258693621823709, 0.7257910425409729, 0.7260677539155459, 0.7273580580978511, 0.7288747379516438, 0.7280251518113089, 0.728289447022422, 0.7283757301867985, 0.7280605417560102, 0.7295964746225172]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.26s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.03s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.84s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:10,  1.94s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:31,  1.81s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:16,  1.76s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:44,  1.65s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:07,  1.74s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:39,  1.65s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<08:04,  1.74s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:54,  1.71s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:22,  1.82s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:30,  1.86s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<07:56,  1.74s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:10,  1.80s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<07:52,  1.74s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<07:56,  1.76s/it]predicting train subjects:   5%|▌         | 15/285 [00:26<08:05,  1.80s/it]predicting train subjects:   6%|▌         | 16/285 [00:28<08:25,  1.88s/it]predicting train subjects:   6%|▌         | 17/285 [00:29<08:01,  1.80s/it]predicting train subjects:   6%|▋         | 18/285 [00:31<08:04,  1.81s/it]predicting train subjects:   7%|▋         | 19/285 [00:33<07:47,  1.76s/it]predicting train subjects:   7%|▋         | 20/285 [00:35<07:51,  1.78s/it]predicting train subjects:   7%|▋         | 21/285 [00:37<08:10,  1.86s/it]predicting train subjects:   8%|▊         | 22/285 [00:38<07:52,  1.80s/it]predicting train subjects:   8%|▊         | 23/285 [00:40<07:57,  1.82s/it]predicting train subjects:   8%|▊         | 24/285 [00:42<07:42,  1.77s/it]predicting train subjects:   9%|▉         | 25/285 [00:44<08:03,  1.86s/it]predicting train subjects:   9%|▉         | 26/285 [00:46<08:15,  1.91s/it]predicting train subjects:   9%|▉         | 27/285 [00:48<07:47,  1.81s/it]predicting train subjects:  10%|▉         | 28/285 [00:49<07:51,  1.83s/it]predicting train subjects:  10%|█         | 29/285 [00:51<07:50,  1.84s/it]predicting train subjects:  11%|█         | 30/285 [00:53<08:04,  1.90s/it]predicting train subjects:  11%|█         | 31/285 [00:55<08:14,  1.95s/it]predicting train subjects:  11%|█         | 32/285 [00:57<07:44,  1.84s/it]predicting train subjects:  12%|█▏        | 33/285 [00:59<07:46,  1.85s/it]predicting train subjects:  12%|█▏        | 34/285 [01:01<07:51,  1.88s/it]predicting train subjects:  12%|█▏        | 35/285 [01:03<08:03,  1.93s/it]predicting train subjects:  13%|█▎        | 36/285 [01:05<07:44,  1.87s/it]predicting train subjects:  13%|█▎        | 37/285 [01:06<07:46,  1.88s/it]predicting train subjects:  13%|█▎        | 38/285 [01:08<07:53,  1.92s/it]predicting train subjects:  14%|█▎        | 39/285 [01:10<07:27,  1.82s/it]predicting train subjects:  14%|█▍        | 40/285 [01:12<07:32,  1.85s/it]predicting train subjects:  14%|█▍        | 41/285 [01:14<07:12,  1.77s/it]predicting train subjects:  15%|█▍        | 42/285 [01:15<06:59,  1.73s/it]predicting train subjects:  15%|█▌        | 43/285 [01:17<07:17,  1.81s/it]predicting train subjects:  15%|█▌        | 44/285 [01:19<07:32,  1.88s/it]predicting train subjects:  16%|█▌        | 45/285 [01:21<07:09,  1.79s/it]predicting train subjects:  16%|█▌        | 46/285 [01:23<07:15,  1.82s/it]predicting train subjects:  16%|█▋        | 47/285 [01:24<07:00,  1.77s/it]predicting train subjects:  17%|█▋        | 48/285 [01:26<07:05,  1.79s/it]predicting train subjects:  17%|█▋        | 49/285 [01:28<07:20,  1.87s/it]predicting train subjects:  18%|█▊        | 50/285 [01:30<07:25,  1.90s/it]predicting train subjects:  18%|█▊        | 51/285 [01:32<07:33,  1.94s/it]predicting train subjects:  18%|█▊        | 52/285 [01:34<07:05,  1.83s/it]predicting train subjects:  19%|█▊        | 53/285 [01:36<07:00,  1.81s/it]predicting train subjects:  19%|█▉        | 54/285 [01:38<07:09,  1.86s/it]predicting train subjects:  19%|█▉        | 55/285 [01:39<06:50,  1.78s/it]predicting train subjects:  20%|█▉        | 56/285 [01:41<06:53,  1.81s/it]predicting train subjects:  20%|██        | 57/285 [01:43<06:39,  1.75s/it]predicting train subjects:  20%|██        | 58/285 [01:45<06:47,  1.80s/it]predicting train subjects:  21%|██        | 59/285 [01:47<07:03,  1.87s/it]predicting train subjects:  21%|██        | 60/285 [01:49<07:10,  1.91s/it]predicting train subjects:  21%|██▏       | 61/285 [01:50<06:48,  1.82s/it]predicting train subjects:  22%|██▏       | 62/285 [01:52<06:53,  1.85s/it]predicting train subjects:  22%|██▏       | 63/285 [01:54<06:58,  1.88s/it]predicting train subjects:  22%|██▏       | 64/285 [01:56<06:46,  1.84s/it]predicting train subjects:  23%|██▎       | 65/285 [01:58<06:51,  1.87s/it]predicting train subjects:  23%|██▎       | 66/285 [02:00<06:47,  1.86s/it]predicting train subjects:  24%|██▎       | 67/285 [02:01<06:45,  1.86s/it]predicting train subjects:  24%|██▍       | 68/285 [02:03<06:32,  1.81s/it]predicting train subjects:  24%|██▍       | 69/285 [02:05<06:33,  1.82s/it]predicting train subjects:  25%|██▍       | 70/285 [02:07<06:32,  1.83s/it]predicting train subjects:  25%|██▍       | 71/285 [02:09<06:41,  1.88s/it]predicting train subjects:  25%|██▌       | 72/285 [02:10<06:21,  1.79s/it]predicting train subjects:  26%|██▌       | 73/285 [02:12<06:24,  1.81s/it]predicting train subjects:  26%|██▌       | 74/285 [02:14<06:37,  1.88s/it]predicting train subjects:  26%|██▋       | 75/285 [02:16<06:34,  1.88s/it]predicting train subjects:  27%|██▋       | 76/285 [02:18<06:36,  1.90s/it]predicting train subjects:  27%|██▋       | 77/285 [02:20<06:23,  1.84s/it]predicting train subjects:  27%|██▋       | 78/285 [02:22<06:28,  1.88s/it]predicting train subjects:  28%|██▊       | 79/285 [02:24<06:28,  1.89s/it]predicting train subjects:  28%|██▊       | 80/285 [02:26<06:27,  1.89s/it]predicting train subjects:  28%|██▊       | 81/285 [02:28<06:28,  1.90s/it]predicting train subjects:  29%|██▉       | 82/285 [02:30<06:34,  1.95s/it]predicting train subjects:  29%|██▉       | 83/285 [02:31<06:23,  1.90s/it]predicting train subjects:  29%|██▉       | 84/285 [02:33<06:17,  1.88s/it]predicting train subjects:  30%|██▉       | 85/285 [02:35<06:18,  1.89s/it]predicting train subjects:  30%|███       | 86/285 [02:37<06:20,  1.91s/it]predicting train subjects:  31%|███       | 87/285 [02:39<06:21,  1.93s/it]predicting train subjects:  31%|███       | 88/285 [02:41<06:12,  1.89s/it]predicting train subjects:  31%|███       | 89/285 [02:43<06:13,  1.91s/it]predicting train subjects:  32%|███▏      | 90/285 [02:45<06:08,  1.89s/it]predicting train subjects:  32%|███▏      | 91/285 [02:46<05:50,  1.80s/it]predicting train subjects:  32%|███▏      | 92/285 [02:48<06:05,  1.89s/it]predicting train subjects:  33%|███▎      | 93/285 [02:50<05:53,  1.84s/it]predicting train subjects:  33%|███▎      | 94/285 [02:52<05:50,  1.84s/it]predicting train subjects:  33%|███▎      | 95/285 [02:54<05:53,  1.86s/it]predicting train subjects:  34%|███▎      | 96/285 [02:56<05:52,  1.86s/it]predicting train subjects:  34%|███▍      | 97/285 [02:58<05:52,  1.87s/it]predicting train subjects:  34%|███▍      | 98/285 [02:59<05:46,  1.85s/it]predicting train subjects:  35%|███▍      | 99/285 [03:01<05:44,  1.85s/it]predicting train subjects:  35%|███▌      | 100/285 [03:03<05:51,  1.90s/it]predicting train subjects:  35%|███▌      | 101/285 [03:05<05:36,  1.83s/it]predicting train subjects:  36%|███▌      | 102/285 [03:07<05:43,  1.88s/it]predicting train subjects:  36%|███▌      | 103/285 [03:09<05:33,  1.83s/it]predicting train subjects:  36%|███▋      | 104/285 [03:11<05:39,  1.87s/it]predicting train subjects:  37%|███▋      | 105/285 [03:13<05:43,  1.91s/it]predicting train subjects:  37%|███▋      | 106/285 [03:14<05:33,  1.87s/it]predicting train subjects:  38%|███▊      | 107/285 [03:16<05:30,  1.86s/it]predicting train subjects:  38%|███▊      | 108/285 [03:18<05:22,  1.82s/it]predicting train subjects:  38%|███▊      | 109/285 [03:20<05:28,  1.87s/it]predicting train subjects:  39%|███▊      | 110/285 [03:22<05:30,  1.89s/it]predicting train subjects:  39%|███▉      | 111/285 [03:24<05:34,  1.92s/it]predicting train subjects:  39%|███▉      | 112/285 [03:26<05:40,  1.97s/it]predicting train subjects:  40%|███▉      | 113/285 [03:28<05:46,  2.01s/it]predicting train subjects:  40%|████      | 114/285 [03:30<05:47,  2.03s/it]predicting train subjects:  40%|████      | 115/285 [03:32<05:44,  2.02s/it]predicting train subjects:  41%|████      | 116/285 [03:34<05:43,  2.03s/it]predicting train subjects:  41%|████      | 117/285 [03:36<05:25,  1.94s/it]predicting train subjects:  41%|████▏     | 118/285 [03:38<05:05,  1.83s/it]predicting train subjects:  42%|████▏     | 119/285 [03:39<05:06,  1.84s/it]predicting train subjects:  42%|████▏     | 120/285 [03:41<04:56,  1.80s/it]predicting train subjects:  42%|████▏     | 121/285 [03:43<04:51,  1.78s/it]predicting train subjects:  43%|████▎     | 122/285 [03:44<04:33,  1.68s/it]predicting train subjects:  43%|████▎     | 123/285 [03:46<04:19,  1.60s/it]predicting train subjects:  44%|████▎     | 124/285 [03:47<04:18,  1.60s/it]predicting train subjects:  44%|████▍     | 125/285 [03:49<04:21,  1.64s/it]predicting train subjects:  44%|████▍     | 126/285 [03:51<04:40,  1.76s/it]predicting train subjects:  45%|████▍     | 127/285 [03:53<04:48,  1.83s/it]predicting train subjects:  45%|████▍     | 128/285 [03:55<04:57,  1.89s/it]predicting train subjects:  45%|████▌     | 129/285 [03:57<04:53,  1.88s/it]predicting train subjects:  46%|████▌     | 130/285 [03:59<04:57,  1.92s/it]predicting train subjects:  46%|████▌     | 131/285 [04:01<04:56,  1.93s/it]predicting train subjects:  46%|████▋     | 132/285 [04:03<05:03,  1.98s/it]predicting train subjects:  47%|████▋     | 133/285 [04:05<04:56,  1.95s/it]predicting train subjects:  47%|████▋     | 134/285 [04:07<04:50,  1.92s/it]predicting train subjects:  47%|████▋     | 135/285 [04:09<04:51,  1.95s/it]predicting train subjects:  48%|████▊     | 136/285 [04:11<05:05,  2.05s/it]predicting train subjects:  48%|████▊     | 137/285 [04:14<05:21,  2.17s/it]predicting train subjects:  48%|████▊     | 138/285 [04:15<05:04,  2.07s/it]predicting train subjects:  49%|████▉     | 139/285 [04:18<05:10,  2.13s/it]predicting train subjects:  49%|████▉     | 140/285 [04:20<05:08,  2.13s/it]predicting train subjects:  49%|████▉     | 141/285 [04:22<05:03,  2.11s/it]predicting train subjects:  50%|████▉     | 142/285 [04:24<05:06,  2.14s/it]predicting train subjects:  50%|█████     | 143/285 [04:26<04:50,  2.04s/it]predicting train subjects:  51%|█████     | 144/285 [04:28<04:49,  2.05s/it]predicting train subjects:  51%|█████     | 145/285 [04:30<04:45,  2.04s/it]predicting train subjects:  51%|█████     | 146/285 [04:32<04:51,  2.09s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:34<04:48,  2.09s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:36<04:53,  2.14s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:39<04:48,  2.12s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:41<04:45,  2.11s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:43<05:02,  2.25s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:45<04:44,  2.14s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:47<04:28,  2.03s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:49<04:24,  2.02s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:51<04:27,  2.06s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:53<04:36,  2.14s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:55<04:24,  2.06s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:57<04:21,  2.06s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:59<04:12,  2.01s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:01<04:07,  1.98s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:03<04:02,  1.95s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:05<04:01,  1.97s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:07<04:14,  2.08s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:09<04:04,  2.02s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:11<03:52,  1.93s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:13<03:56,  1.99s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:15<03:55,  2.00s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:17<03:51,  1.98s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:19<03:55,  2.03s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:21<03:58,  2.08s/it]predicting train subjects:  60%|██████    | 171/285 [05:24<04:01,  2.11s/it]predicting train subjects:  60%|██████    | 172/285 [05:25<03:53,  2.07s/it]predicting train subjects:  61%|██████    | 173/285 [05:27<03:49,  2.05s/it]predicting train subjects:  61%|██████    | 174/285 [05:29<03:45,  2.04s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:32<04:03,  2.22s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:34<04:05,  2.25s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:36<03:55,  2.18s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:38<03:43,  2.09s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:40<03:35,  2.04s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:43<03:56,  2.25s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:46<04:08,  2.39s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:48<03:54,  2.27s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:50<03:46,  2.22s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:53<03:57,  2.36s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:54<03:37,  2.17s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:57<03:47,  2.30s/it]predicting train subjects:  66%|██████▌   | 187/285 [06:00<03:55,  2.41s/it]predicting train subjects:  66%|██████▌   | 188/285 [06:02<03:56,  2.44s/it]predicting train subjects:  66%|██████▋   | 189/285 [06:04<03:35,  2.25s/it]predicting train subjects:  67%|██████▋   | 190/285 [06:06<03:27,  2.18s/it]predicting train subjects:  67%|██████▋   | 191/285 [06:08<03:28,  2.22s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:10<03:25,  2.21s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:12<03:16,  2.14s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:14<03:08,  2.07s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:16<03:07,  2.08s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:19<03:16,  2.20s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:21<03:19,  2.27s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:24<03:18,  2.28s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:25<03:00,  2.10s/it]predicting train subjects:  70%|███████   | 200/285 [06:27<02:49,  1.99s/it]predicting train subjects:  71%|███████   | 201/285 [06:30<03:00,  2.15s/it]predicting train subjects:  71%|███████   | 202/285 [06:32<02:57,  2.13s/it]predicting train subjects:  71%|███████   | 203/285 [06:34<03:06,  2.27s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:36<02:50,  2.10s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:38<02:45,  2.07s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:40<02:39,  2.02s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:42<02:50,  2.18s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:45<02:50,  2.22s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:47<02:52,  2.27s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:49<02:40,  2.14s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:51<02:37,  2.12s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:54<02:47,  2.30s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:56<02:44,  2.28s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:58<02:37,  2.22s/it]predicting train subjects:  75%|███████▌  | 215/285 [07:01<02:43,  2.34s/it]predicting train subjects:  76%|███████▌  | 216/285 [07:03<02:37,  2.29s/it]predicting train subjects:  76%|███████▌  | 217/285 [07:05<02:43,  2.40s/it]predicting train subjects:  76%|███████▋  | 218/285 [07:08<02:42,  2.43s/it]predicting train subjects:  77%|███████▋  | 219/285 [07:10<02:39,  2.41s/it]predicting train subjects:  77%|███████▋  | 220/285 [07:12<02:27,  2.27s/it]predicting train subjects:  78%|███████▊  | 221/285 [07:14<02:19,  2.18s/it]predicting train subjects:  78%|███████▊  | 222/285 [07:16<02:16,  2.17s/it]predicting train subjects:  78%|███████▊  | 223/285 [07:18<02:07,  2.05s/it]predicting train subjects:  79%|███████▊  | 224/285 [07:20<02:01,  2.00s/it]predicting train subjects:  79%|███████▉  | 225/285 [07:22<01:55,  1.92s/it]predicting train subjects:  79%|███████▉  | 226/285 [07:24<02:08,  2.17s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:27<02:20,  2.42s/it]predicting train subjects:  80%|████████  | 228/285 [07:30<02:22,  2.51s/it]predicting train subjects:  80%|████████  | 229/285 [07:33<02:17,  2.45s/it]predicting train subjects:  81%|████████  | 230/285 [07:34<02:04,  2.26s/it]predicting train subjects:  81%|████████  | 231/285 [07:36<01:53,  2.10s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:38<01:53,  2.14s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:40<01:44,  2.01s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:42<01:46,  2.09s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:44<01:37,  1.95s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:47<01:53,  2.32s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:49<01:51,  2.33s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:52<01:50,  2.35s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:54<01:43,  2.26s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:56<01:35,  2.13s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:58<01:32,  2.10s/it]predicting train subjects:  85%|████████▍ | 242/285 [08:00<01:26,  2.02s/it]predicting train subjects:  85%|████████▌ | 243/285 [08:02<01:25,  2.04s/it]predicting train subjects:  86%|████████▌ | 244/285 [08:04<01:28,  2.16s/it]predicting train subjects:  86%|████████▌ | 245/285 [08:06<01:22,  2.06s/it]predicting train subjects:  86%|████████▋ | 246/285 [08:09<01:28,  2.28s/it]predicting train subjects:  87%|████████▋ | 247/285 [08:11<01:28,  2.34s/it]predicting train subjects:  87%|████████▋ | 248/285 [08:13<01:25,  2.30s/it]predicting train subjects:  87%|████████▋ | 249/285 [08:15<01:18,  2.17s/it]predicting train subjects:  88%|████████▊ | 250/285 [08:17<01:14,  2.12s/it]predicting train subjects:  88%|████████▊ | 251/285 [08:19<01:11,  2.09s/it]predicting train subjects:  88%|████████▊ | 252/285 [08:21<01:05,  1.99s/it]predicting train subjects:  89%|████████▉ | 253/285 [08:24<01:11,  2.24s/it]predicting train subjects:  89%|████████▉ | 254/285 [08:26<01:10,  2.28s/it]predicting train subjects:  89%|████████▉ | 255/285 [08:29<01:09,  2.33s/it]predicting train subjects:  90%|████████▉ | 256/285 [08:31<01:07,  2.32s/it]predicting train subjects:  90%|█████████ | 257/285 [08:33<01:01,  2.18s/it]predicting train subjects:  91%|█████████ | 258/285 [08:35<01:00,  2.25s/it]predicting train subjects:  91%|█████████ | 259/285 [08:38<01:00,  2.34s/it]predicting train subjects:  91%|█████████ | 260/285 [08:40<00:53,  2.15s/it]predicting train subjects:  92%|█████████▏| 261/285 [08:41<00:48,  2.02s/it]predicting train subjects:  92%|█████████▏| 262/285 [08:43<00:44,  1.95s/it]predicting train subjects:  92%|█████████▏| 263/285 [08:45<00:41,  1.87s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:47<00:41,  1.98s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:49<00:41,  2.06s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:51<00:37,  1.95s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:53<00:34,  1.90s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:55<00:33,  2.00s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:57<00:31,  1.97s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:58<00:28,  1.88s/it]predicting train subjects:  95%|█████████▌| 271/285 [09:00<00:25,  1.84s/it]predicting train subjects:  95%|█████████▌| 272/285 [09:02<00:24,  1.92s/it]predicting train subjects:  96%|█████████▌| 273/285 [09:04<00:22,  1.86s/it]predicting train subjects:  96%|█████████▌| 274/285 [09:06<00:19,  1.78s/it]predicting train subjects:  96%|█████████▋| 275/285 [09:08<00:19,  1.96s/it]predicting train subjects:  97%|█████████▋| 276/285 [09:10<00:18,  2.08s/it]predicting train subjects:  97%|█████████▋| 277/285 [09:12<00:15,  1.98s/it]predicting train subjects:  98%|█████████▊| 278/285 [09:14<00:13,  1.93s/it]predicting train subjects:  98%|█████████▊| 279/285 [09:16<00:12,  2.01s/it]predicting train subjects:  98%|█████████▊| 280/285 [09:18<00:09,  1.91s/it]predicting train subjects:  99%|█████████▊| 281/285 [09:20<00:07,  1.95s/it]predicting train subjects:  99%|█████████▉| 282/285 [09:22<00:05,  1.87s/it]predicting train subjects:  99%|█████████▉| 283/285 [09:24<00:03,  1.99s/it]predicting train subjects: 100%|█████████▉| 284/285 [09:26<00:02,  2.07s/it]predicting train subjects: 100%|██████████| 285/285 [09:28<00:00,  2.09s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:02<11:35,  2.45s/it]Loading train:   1%|          | 2/285 [00:04<10:34,  2.24s/it]Loading train:   1%|          | 3/285 [00:06<10:58,  2.33s/it]Loading train:   1%|▏         | 4/285 [00:08<10:20,  2.21s/it]Loading train:   2%|▏         | 5/285 [00:11<10:59,  2.36s/it]Loading train:   2%|▏         | 6/285 [00:12<09:32,  2.05s/it]Loading train:   2%|▏         | 7/285 [00:15<09:50,  2.12s/it]Loading train:   3%|▎         | 8/285 [00:16<09:30,  2.06s/it]Loading train:   3%|▎         | 9/285 [00:19<09:58,  2.17s/it]Loading train:   4%|▎         | 10/285 [00:20<08:53,  1.94s/it]Loading train:   4%|▍         | 11/285 [00:21<07:40,  1.68s/it]Loading train:   4%|▍         | 12/285 [00:23<07:04,  1.55s/it]Loading train:   5%|▍         | 13/285 [00:24<06:25,  1.42s/it]Loading train:   5%|▍         | 14/285 [00:25<06:02,  1.34s/it]Loading train:   5%|▌         | 15/285 [00:26<06:03,  1.35s/it]Loading train:   6%|▌         | 16/285 [00:28<06:13,  1.39s/it]Loading train:   6%|▌         | 17/285 [00:29<05:48,  1.30s/it]Loading train:   6%|▋         | 18/285 [00:30<05:28,  1.23s/it]Loading train:   7%|▋         | 19/285 [00:31<05:22,  1.21s/it]Loading train:   7%|▋         | 20/285 [00:32<05:13,  1.18s/it]Loading train:   7%|▋         | 21/285 [00:33<05:16,  1.20s/it]Loading train:   8%|▊         | 22/285 [00:34<04:59,  1.14s/it]Loading train:   8%|▊         | 23/285 [00:36<04:58,  1.14s/it]Loading train:   8%|▊         | 24/285 [00:36<04:40,  1.07s/it]Loading train:   9%|▉         | 25/285 [00:38<04:55,  1.14s/it]Loading train:   9%|▉         | 26/285 [00:39<05:03,  1.17s/it]Loading train:   9%|▉         | 27/285 [00:40<05:02,  1.17s/it]Loading train:  10%|▉         | 28/285 [00:41<04:59,  1.17s/it]Loading train:  10%|█         | 29/285 [00:42<04:53,  1.15s/it]Loading train:  11%|█         | 30/285 [00:44<04:58,  1.17s/it]Loading train:  11%|█         | 31/285 [00:45<05:01,  1.19s/it]Loading train:  11%|█         | 32/285 [00:46<04:46,  1.13s/it]Loading train:  12%|█▏        | 33/285 [00:47<04:39,  1.11s/it]Loading train:  12%|█▏        | 34/285 [00:48<04:47,  1.15s/it]Loading train:  12%|█▏        | 35/285 [00:49<05:00,  1.20s/it]Loading train:  13%|█▎        | 36/285 [00:51<04:53,  1.18s/it]Loading train:  13%|█▎        | 37/285 [00:52<04:47,  1.16s/it]Loading train:  13%|█▎        | 38/285 [00:53<04:56,  1.20s/it]Loading train:  14%|█▎        | 39/285 [00:54<04:44,  1.16s/it]Loading train:  14%|█▍        | 40/285 [00:55<04:51,  1.19s/it]Loading train:  14%|█▍        | 41/285 [00:56<04:37,  1.14s/it]Loading train:  15%|█▍        | 42/285 [00:57<04:36,  1.14s/it]Loading train:  15%|█▌        | 43/285 [00:59<04:33,  1.13s/it]Loading train:  15%|█▌        | 44/285 [01:00<04:47,  1.19s/it]Loading train:  16%|█▌        | 45/285 [01:01<04:47,  1.20s/it]Loading train:  16%|█▌        | 46/285 [01:03<05:13,  1.31s/it]Loading train:  16%|█▋        | 47/285 [01:04<04:58,  1.25s/it]Loading train:  17%|█▋        | 48/285 [01:05<05:00,  1.27s/it]Loading train:  17%|█▋        | 49/285 [01:06<05:05,  1.29s/it]Loading train:  18%|█▊        | 50/285 [01:08<04:49,  1.23s/it]Loading train:  18%|█▊        | 51/285 [01:09<04:55,  1.26s/it]Loading train:  18%|█▊        | 52/285 [01:10<04:48,  1.24s/it]Loading train:  19%|█▊        | 53/285 [01:11<04:48,  1.25s/it]Loading train:  19%|█▉        | 54/285 [01:13<04:48,  1.25s/it]Loading train:  19%|█▉        | 55/285 [01:14<04:56,  1.29s/it]Loading train:  20%|█▉        | 56/285 [01:15<04:49,  1.27s/it]Loading train:  20%|██        | 57/285 [01:16<04:45,  1.25s/it]Loading train:  20%|██        | 58/285 [01:18<04:34,  1.21s/it]Loading train:  21%|██        | 59/285 [01:19<04:39,  1.24s/it]Loading train:  21%|██        | 60/285 [01:20<04:45,  1.27s/it]Loading train:  21%|██▏       | 61/285 [01:21<04:39,  1.25s/it]Loading train:  22%|██▏       | 62/285 [01:23<04:36,  1.24s/it]Loading train:  22%|██▏       | 63/285 [01:24<04:37,  1.25s/it]Loading train:  22%|██▏       | 64/285 [01:25<04:55,  1.34s/it]Loading train:  23%|██▎       | 65/285 [01:27<05:20,  1.46s/it]Loading train:  23%|██▎       | 66/285 [01:29<05:32,  1.52s/it]Loading train:  24%|██▎       | 67/285 [01:30<05:16,  1.45s/it]Loading train:  24%|██▍       | 68/285 [01:31<04:49,  1.33s/it]Loading train:  24%|██▍       | 69/285 [01:32<04:34,  1.27s/it]Loading train:  25%|██▍       | 70/285 [01:33<04:15,  1.19s/it]Loading train:  25%|██▍       | 71/285 [01:34<04:10,  1.17s/it]Loading train:  25%|██▌       | 72/285 [01:35<03:56,  1.11s/it]Loading train:  26%|██▌       | 73/285 [01:36<03:52,  1.10s/it]Loading train:  26%|██▌       | 74/285 [01:37<03:44,  1.07s/it]Loading train:  26%|██▋       | 75/285 [01:39<04:21,  1.25s/it]Loading train:  27%|██▋       | 76/285 [01:40<04:15,  1.22s/it]Loading train:  27%|██▋       | 77/285 [01:41<04:10,  1.21s/it]Loading train:  27%|██▋       | 78/285 [01:43<04:08,  1.20s/it]Loading train:  28%|██▊       | 79/285 [01:44<04:08,  1.21s/it]Loading train:  28%|██▊       | 80/285 [01:45<04:05,  1.20s/it]Loading train:  28%|██▊       | 81/285 [01:46<04:19,  1.27s/it]Loading train:  29%|██▉       | 82/285 [01:48<04:04,  1.20s/it]Loading train:  29%|██▉       | 83/285 [01:49<03:52,  1.15s/it]Loading train:  29%|██▉       | 84/285 [01:50<03:49,  1.14s/it]Loading train:  30%|██▉       | 85/285 [01:51<03:42,  1.11s/it]Loading train:  30%|███       | 86/285 [01:52<03:47,  1.14s/it]Loading train:  31%|███       | 87/285 [01:53<03:52,  1.17s/it]Loading train:  31%|███       | 88/285 [01:54<03:45,  1.15s/it]Loading train:  31%|███       | 89/285 [01:55<03:47,  1.16s/it]Loading train:  32%|███▏      | 90/285 [01:57<03:50,  1.18s/it]Loading train:  32%|███▏      | 91/285 [01:58<03:48,  1.18s/it]Loading train:  32%|███▏      | 92/285 [01:59<03:50,  1.19s/it]Loading train:  33%|███▎      | 93/285 [02:01<04:02,  1.26s/it]Loading train:  33%|███▎      | 94/285 [02:02<03:59,  1.25s/it]Loading train:  33%|███▎      | 95/285 [02:03<04:01,  1.27s/it]Loading train:  34%|███▎      | 96/285 [02:04<04:01,  1.28s/it]Loading train:  34%|███▍      | 97/285 [02:06<03:56,  1.26s/it]Loading train:  34%|███▍      | 98/285 [02:07<03:49,  1.23s/it]Loading train:  35%|███▍      | 99/285 [02:08<03:48,  1.23s/it]Loading train:  35%|███▌      | 100/285 [02:09<03:50,  1.25s/it]Loading train:  35%|███▌      | 101/285 [02:10<03:43,  1.21s/it]Loading train:  36%|███▌      | 102/285 [02:12<03:48,  1.25s/it]Loading train:  36%|███▌      | 103/285 [02:13<03:45,  1.24s/it]Loading train:  36%|███▋      | 104/285 [02:14<03:46,  1.25s/it]Loading train:  37%|███▋      | 105/285 [02:15<03:41,  1.23s/it]Loading train:  37%|███▋      | 106/285 [02:17<03:42,  1.24s/it]Loading train:  38%|███▊      | 107/285 [02:18<03:34,  1.21s/it]Loading train:  38%|███▊      | 108/285 [02:19<03:34,  1.21s/it]Loading train:  38%|███▊      | 109/285 [02:20<03:33,  1.21s/it]Loading train:  39%|███▊      | 110/285 [02:21<03:28,  1.19s/it]Loading train:  39%|███▉      | 111/285 [02:22<03:16,  1.13s/it]Loading train:  39%|███▉      | 112/285 [02:23<03:11,  1.11s/it]Loading train:  40%|███▉      | 113/285 [02:24<03:08,  1.10s/it]Loading train:  40%|████      | 114/285 [02:26<03:09,  1.11s/it]Loading train:  40%|████      | 115/285 [02:27<03:10,  1.12s/it]Loading train:  41%|████      | 116/285 [02:28<03:17,  1.17s/it]Loading train:  41%|████      | 117/285 [02:29<03:21,  1.20s/it]Loading train:  41%|████▏     | 118/285 [02:30<03:18,  1.19s/it]Loading train:  42%|████▏     | 119/285 [02:32<03:15,  1.18s/it]Loading train:  42%|████▏     | 120/285 [02:33<03:21,  1.22s/it]Loading train:  42%|████▏     | 121/285 [02:34<03:31,  1.29s/it]Loading train:  43%|████▎     | 122/285 [02:36<03:35,  1.32s/it]Loading train:  43%|████▎     | 123/285 [02:37<03:33,  1.32s/it]Loading train:  44%|████▎     | 124/285 [02:38<03:27,  1.29s/it]Loading train:  44%|████▍     | 125/285 [02:39<03:11,  1.19s/it]Loading train:  44%|████▍     | 126/285 [02:40<02:57,  1.12s/it]Loading train:  45%|████▍     | 127/285 [02:41<03:00,  1.14s/it]Loading train:  45%|████▍     | 128/285 [02:43<02:59,  1.14s/it]Loading train:  45%|████▌     | 129/285 [02:44<02:52,  1.10s/it]Loading train:  46%|████▌     | 130/285 [02:45<02:51,  1.10s/it]Loading train:  46%|████▌     | 131/285 [02:46<02:47,  1.09s/it]Loading train:  46%|████▋     | 132/285 [02:47<02:50,  1.11s/it]Loading train:  47%|████▋     | 133/285 [02:48<02:41,  1.06s/it]Loading train:  47%|████▋     | 134/285 [02:49<02:43,  1.08s/it]Loading train:  47%|████▋     | 135/285 [02:50<02:46,  1.11s/it]Loading train:  48%|████▊     | 136/285 [02:51<02:35,  1.05s/it]Loading train:  48%|████▊     | 137/285 [02:52<02:37,  1.07s/it]Loading train:  48%|████▊     | 138/285 [02:53<02:38,  1.08s/it]Loading train:  49%|████▉     | 139/285 [02:54<02:40,  1.10s/it]Loading train:  49%|████▉     | 140/285 [02:55<02:36,  1.08s/it]Loading train:  49%|████▉     | 141/285 [02:56<02:28,  1.03s/it]Loading train:  50%|████▉     | 142/285 [02:57<02:20,  1.02it/s]Loading train:  50%|█████     | 143/285 [02:58<02:23,  1.01s/it]Loading train:  51%|█████     | 144/285 [02:59<02:23,  1.02s/it]Loading train:  51%|█████     | 145/285 [03:00<02:17,  1.02it/s]Loading train:  51%|█████     | 146/285 [03:01<02:17,  1.01it/s]Loading train:  52%|█████▏    | 147/285 [03:02<02:15,  1.02it/s]Loading train:  52%|█████▏    | 148/285 [03:03<02:09,  1.05it/s]Loading train:  52%|█████▏    | 149/285 [03:04<02:07,  1.07it/s]Loading train:  53%|█████▎    | 150/285 [03:05<02:02,  1.10it/s]Loading train:  53%|█████▎    | 151/285 [03:06<02:09,  1.04it/s]Loading train:  53%|█████▎    | 152/285 [03:07<02:11,  1.01it/s]Loading train:  54%|█████▎    | 153/285 [03:08<02:13,  1.01s/it]Loading train:  54%|█████▍    | 154/285 [03:09<02:14,  1.03s/it]Loading train:  54%|█████▍    | 155/285 [03:10<02:13,  1.03s/it]Loading train:  55%|█████▍    | 156/285 [03:11<02:13,  1.03s/it]Loading train:  55%|█████▌    | 157/285 [03:12<02:06,  1.01it/s]Loading train:  55%|█████▌    | 158/285 [03:13<02:00,  1.06it/s]Loading train:  56%|█████▌    | 159/285 [03:14<02:05,  1.01it/s]Loading train:  56%|█████▌    | 160/285 [03:15<02:03,  1.01it/s]Loading train:  56%|█████▋    | 161/285 [03:16<02:02,  1.01it/s]Loading train:  57%|█████▋    | 162/285 [03:17<01:59,  1.03it/s]Loading train:  57%|█████▋    | 163/285 [03:18<01:59,  1.02it/s]Loading train:  58%|█████▊    | 164/285 [03:19<02:07,  1.05s/it]Loading train:  58%|█████▊    | 165/285 [03:20<02:03,  1.03s/it]Loading train:  58%|█████▊    | 166/285 [03:21<02:05,  1.06s/it]Loading train:  59%|█████▊    | 167/285 [03:22<02:04,  1.05s/it]Loading train:  59%|█████▉    | 168/285 [03:23<02:06,  1.08s/it]Loading train:  59%|█████▉    | 169/285 [03:24<02:01,  1.05s/it]Loading train:  60%|█████▉    | 170/285 [03:25<01:56,  1.01s/it]Loading train:  60%|██████    | 171/285 [03:26<01:50,  1.03it/s]Loading train:  60%|██████    | 172/285 [03:27<01:51,  1.01it/s]Loading train:  61%|██████    | 173/285 [03:28<01:47,  1.04it/s]Loading train:  61%|██████    | 174/285 [03:29<01:48,  1.03it/s]Loading train:  61%|██████▏   | 175/285 [03:30<01:46,  1.04it/s]Loading train:  62%|██████▏   | 176/285 [03:31<01:53,  1.04s/it]Loading train:  62%|██████▏   | 177/285 [03:32<01:51,  1.04s/it]Loading train:  62%|██████▏   | 178/285 [03:33<01:48,  1.02s/it]Loading train:  63%|██████▎   | 179/285 [03:34<01:43,  1.02it/s]Loading train:  63%|██████▎   | 180/285 [03:35<01:48,  1.03s/it]Loading train:  64%|██████▎   | 181/285 [03:37<01:51,  1.08s/it]Loading train:  64%|██████▍   | 182/285 [03:38<01:54,  1.12s/it]Loading train:  64%|██████▍   | 183/285 [03:39<01:55,  1.13s/it]Loading train:  65%|██████▍   | 184/285 [03:40<01:53,  1.12s/it]Loading train:  65%|██████▍   | 185/285 [03:41<01:49,  1.10s/it]Loading train:  65%|██████▌   | 186/285 [03:42<01:50,  1.12s/it]Loading train:  66%|██████▌   | 187/285 [03:43<01:47,  1.09s/it]Loading train:  66%|██████▌   | 188/285 [03:44<01:47,  1.11s/it]Loading train:  66%|██████▋   | 189/285 [03:46<01:46,  1.11s/it]Loading train:  67%|██████▋   | 190/285 [03:46<01:40,  1.06s/it]Loading train:  67%|██████▋   | 191/285 [03:48<01:43,  1.10s/it]Loading train:  67%|██████▋   | 192/285 [03:49<01:42,  1.10s/it]Loading train:  68%|██████▊   | 193/285 [03:50<01:38,  1.07s/it]Loading train:  68%|██████▊   | 194/285 [03:51<01:34,  1.03s/it]Loading train:  68%|██████▊   | 195/285 [03:52<01:33,  1.04s/it]Loading train:  69%|██████▉   | 196/285 [03:53<01:37,  1.10s/it]Loading train:  69%|██████▉   | 197/285 [03:54<01:38,  1.12s/it]Loading train:  69%|██████▉   | 198/285 [03:56<01:45,  1.21s/it]Loading train:  70%|██████▉   | 199/285 [03:57<01:40,  1.17s/it]Loading train:  70%|███████   | 200/285 [03:58<01:39,  1.16s/it]Loading train:  71%|███████   | 201/285 [03:59<01:36,  1.15s/it]Loading train:  71%|███████   | 202/285 [04:00<01:34,  1.14s/it]Loading train:  71%|███████   | 203/285 [04:01<01:29,  1.09s/it]Loading train:  72%|███████▏  | 204/285 [04:02<01:28,  1.10s/it]Loading train:  72%|███████▏  | 205/285 [04:03<01:26,  1.08s/it]Loading train:  72%|███████▏  | 206/285 [04:04<01:22,  1.05s/it]Loading train:  73%|███████▎  | 207/285 [04:05<01:23,  1.07s/it]Loading train:  73%|███████▎  | 208/285 [04:06<01:26,  1.12s/it]Loading train:  73%|███████▎  | 209/285 [04:08<01:29,  1.18s/it]Loading train:  74%|███████▎  | 210/285 [04:09<01:26,  1.15s/it]Loading train:  74%|███████▍  | 211/285 [04:10<01:20,  1.09s/it]Loading train:  74%|███████▍  | 212/285 [04:11<01:25,  1.17s/it]Loading train:  75%|███████▍  | 213/285 [04:12<01:18,  1.09s/it]Loading train:  75%|███████▌  | 214/285 [04:13<01:14,  1.05s/it]Loading train:  75%|███████▌  | 215/285 [04:14<01:12,  1.04s/it]Loading train:  76%|███████▌  | 216/285 [04:15<01:08,  1.00it/s]Loading train:  76%|███████▌  | 217/285 [04:16<01:11,  1.06s/it]Loading train:  76%|███████▋  | 218/285 [04:17<01:13,  1.10s/it]Loading train:  77%|███████▋  | 219/285 [04:19<01:14,  1.13s/it]Loading train:  77%|███████▋  | 220/285 [04:19<01:08,  1.05s/it]Loading train:  78%|███████▊  | 221/285 [04:20<01:06,  1.03s/it]Loading train:  78%|███████▊  | 222/285 [04:22<01:05,  1.05s/it]Loading train:  78%|███████▊  | 223/285 [04:22<01:02,  1.01s/it]Loading train:  79%|███████▊  | 224/285 [04:24<01:03,  1.05s/it]Loading train:  79%|███████▉  | 225/285 [04:25<01:00,  1.02s/it]Loading train:  79%|███████▉  | 226/285 [04:26<01:02,  1.06s/it]Loading train:  80%|███████▉  | 227/285 [04:27<01:04,  1.12s/it]Loading train:  80%|████████  | 228/285 [04:28<01:03,  1.11s/it]Loading train:  80%|████████  | 229/285 [04:29<01:04,  1.15s/it]Loading train:  81%|████████  | 230/285 [04:30<01:00,  1.10s/it]Loading train:  81%|████████  | 231/285 [04:31<00:55,  1.03s/it]Loading train:  81%|████████▏ | 232/285 [04:32<00:56,  1.07s/it]Loading train:  82%|████████▏ | 233/285 [04:33<00:54,  1.04s/it]Loading train:  82%|████████▏ | 234/285 [04:34<00:54,  1.06s/it]Loading train:  82%|████████▏ | 235/285 [04:35<00:51,  1.03s/it]Loading train:  83%|████████▎ | 236/285 [04:37<00:53,  1.09s/it]Loading train:  83%|████████▎ | 237/285 [04:38<00:54,  1.13s/it]Loading train:  84%|████████▎ | 238/285 [04:39<00:50,  1.07s/it]Loading train:  84%|████████▍ | 239/285 [04:40<00:46,  1.01s/it]Loading train:  84%|████████▍ | 240/285 [04:41<00:45,  1.02s/it]Loading train:  85%|████████▍ | 241/285 [04:42<00:46,  1.07s/it]Loading train:  85%|████████▍ | 242/285 [04:43<00:46,  1.08s/it]Loading train:  85%|████████▌ | 243/285 [04:44<00:45,  1.09s/it]Loading train:  86%|████████▌ | 244/285 [04:45<00:45,  1.10s/it]Loading train:  86%|████████▌ | 245/285 [04:46<00:41,  1.04s/it]Loading train:  86%|████████▋ | 246/285 [04:47<00:43,  1.12s/it]Loading train:  87%|████████▋ | 247/285 [04:49<00:43,  1.15s/it]Loading train:  87%|████████▋ | 248/285 [04:50<00:41,  1.13s/it]Loading train:  87%|████████▋ | 249/285 [04:51<00:39,  1.09s/it]Loading train:  88%|████████▊ | 250/285 [04:52<00:38,  1.09s/it]Loading train:  88%|████████▊ | 251/285 [04:53<00:35,  1.04s/it]Loading train:  88%|████████▊ | 252/285 [04:54<00:34,  1.05s/it]Loading train:  89%|████████▉ | 253/285 [04:55<00:35,  1.11s/it]Loading train:  89%|████████▉ | 254/285 [04:56<00:36,  1.16s/it]Loading train:  89%|████████▉ | 255/285 [04:57<00:35,  1.18s/it]Loading train:  90%|████████▉ | 256/285 [04:59<00:33,  1.14s/it]Loading train:  90%|█████████ | 257/285 [05:00<00:30,  1.09s/it]Loading train:  91%|█████████ | 258/285 [05:01<00:30,  1.12s/it]Loading train:  91%|█████████ | 259/285 [05:02<00:28,  1.09s/it]Loading train:  91%|█████████ | 260/285 [05:03<00:26,  1.05s/it]Loading train:  92%|█████████▏| 261/285 [05:04<00:24,  1.04s/it]Loading train:  92%|█████████▏| 262/285 [05:05<00:23,  1.01s/it]Loading train:  92%|█████████▏| 263/285 [05:06<00:22,  1.02s/it]Loading train:  93%|█████████▎| 264/285 [05:07<00:23,  1.10s/it]Loading train:  93%|█████████▎| 265/285 [05:08<00:22,  1.13s/it]Loading train:  93%|█████████▎| 266/285 [05:09<00:21,  1.12s/it]Loading train:  94%|█████████▎| 267/285 [05:10<00:19,  1.11s/it]Loading train:  94%|█████████▍| 268/285 [05:12<00:19,  1.17s/it]Loading train:  94%|█████████▍| 269/285 [05:13<00:18,  1.17s/it]Loading train:  95%|█████████▍| 270/285 [05:14<00:16,  1.11s/it]Loading train:  95%|█████████▌| 271/285 [05:15<00:14,  1.04s/it]Loading train:  95%|█████████▌| 272/285 [05:16<00:13,  1.07s/it]Loading train:  96%|█████████▌| 273/285 [05:17<00:12,  1.05s/it]Loading train:  96%|█████████▌| 274/285 [05:18<00:11,  1.03s/it]Loading train:  96%|█████████▋| 275/285 [05:19<00:10,  1.05s/it]Loading train:  97%|█████████▋| 276/285 [05:20<00:09,  1.11s/it]Loading train:  97%|█████████▋| 277/285 [05:21<00:08,  1.09s/it]Loading train:  98%|█████████▊| 278/285 [05:22<00:07,  1.06s/it]Loading train:  98%|█████████▊| 279/285 [05:23<00:06,  1.11s/it]Loading train:  98%|█████████▊| 280/285 [05:24<00:05,  1.05s/it]Loading train:  99%|█████████▊| 281/285 [05:25<00:03,  1.01it/s]Loading train:  99%|█████████▉| 282/285 [05:26<00:02,  1.08it/s]Loading train:  99%|█████████▉| 283/285 [05:27<00:02,  1.02s/it]Loading train: 100%|█████████▉| 284/285 [05:28<00:01,  1.09s/it]Loading train: 100%|██████████| 285/285 [05:29<00:00,  1.08s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:04, 66.28it/s]concatenating: train:   6%|▌         | 17/285 [00:00<00:03, 73.33it/s]concatenating: train:   9%|▉         | 26/285 [00:00<00:03, 75.03it/s]concatenating: train:  12%|█▏        | 33/285 [00:00<00:03, 70.77it/s]concatenating: train:  16%|█▌        | 45/285 [00:00<00:02, 80.05it/s]concatenating: train:  22%|██▏       | 64/285 [00:00<00:02, 95.73it/s]concatenating: train:  31%|███       | 88/285 [00:00<00:01, 116.58it/s]concatenating: train:  36%|███▌      | 103/285 [00:00<00:01, 123.77it/s]concatenating: train:  42%|████▏     | 119/285 [00:00<00:01, 130.31it/s]concatenating: train:  47%|████▋     | 134/285 [00:01<00:01, 131.37it/s]concatenating: train:  52%|█████▏    | 149/285 [00:01<00:01, 129.40it/s]concatenating: train:  60%|█████▉    | 170/285 [00:01<00:00, 145.75it/s]concatenating: train:  71%|███████   | 203/285 [00:01<00:00, 173.13it/s]concatenating: train:  79%|███████▊  | 224/285 [00:01<00:00, 170.60it/s]concatenating: train:  87%|████████▋ | 248/285 [00:01<00:00, 185.60it/s]concatenating: train:  94%|█████████▍| 269/285 [00:01<00:00, 178.63it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 155.86it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.46s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.43s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.37s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 143.56it/s]2019-07-11 02:11:43.488176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 02:11:43.488311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 02:11:43.488326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 02:11:43.488335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 02:11:43.488772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.29it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.22it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  5.83it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.38it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  6.17it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.09it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.00it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.78it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  8.28it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.96it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.63it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.07it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.14it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.56it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.28it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.52it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.43it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.59it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.48it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 26, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 13, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 26, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 40)   21640       dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 40)   160         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 40)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 52, 40)   0           activation_11[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 100)  0           dropout_5[0][0]                  
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 13)   1313        concatenate_7[0][0]              
==================================================================================================
Total params: 246,153
Trainable params: 71,393
Non-trainable params: 174,760
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 18s - loss: 2.1622 - acc: 0.6661 - mDice: 0.1812 - val_loss: 1.6609 - val_acc: 0.9156 - val_mDice: 0.2692

Epoch 00001: val_mDice improved from -inf to 0.26923, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 13s - loss: 0.7946 - acc: 0.8957 - mDice: 0.4395 - val_loss: 0.6982 - val_acc: 0.9249 - val_mDice: 0.4897

Epoch 00002: val_mDice improved from 0.26923 to 0.48974, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 13s - loss: 0.6236 - acc: 0.9028 - mDice: 0.5228 - val_loss: 0.5979 - val_acc: 0.9364 - val_mDice: 0.5343

Epoch 00003: val_mDice improved from 0.48974 to 0.53434, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 13s - loss: 0.5518 - acc: 0.9091 - mDice: 0.5629 - val_loss: 0.5955 - val_acc: 0.9374 - val_mDice: 0.5480

Epoch 00004: val_mDice improved from 0.53434 to 0.54804, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 13s - loss: 0.4972 - acc: 0.9153 - mDice: 0.5948 - val_loss: 0.5430 - val_acc: 0.9398 - val_mDice: 0.5680

Epoch 00005: val_mDice improved from 0.54804 to 0.56803, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 13s - loss: 0.4629 - acc: 0.9218 - mDice: 0.6160 - val_loss: 0.5264 - val_acc: 0.9451 - val_mDice: 0.5790

Epoch 00006: val_mDice improved from 0.56803 to 0.57902, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 13s - loss: 0.4390 - acc: 0.9275 - mDice: 0.6311 - val_loss: 0.5313 - val_acc: 0.9459 - val_mDice: 0.5817

Epoch 00007: val_mDice improved from 0.57902 to 0.58166, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 13s - loss: 0.4179 - acc: 0.9313 - mDice: 0.6449 - val_loss: 0.5602 - val_acc: 0.9444 - val_mDice: 0.5607

Epoch 00008: val_mDice did not improve from 0.58166
Epoch 9/300
 - 13s - loss: 0.4044 - acc: 0.9342 - mDice: 0.6539 - val_loss: 0.5241 - val_acc: 0.9459 - val_mDice: 0.5794

Epoch 00009: val_mDice did not improve from 0.58166
Epoch 10/300
 - 13s - loss: 0.3920 - acc: 0.9372 - mDice: 0.6622 - val_loss: 0.5841 - val_acc: 0.9436 - val_mDice: 0.5499

Epoch 00010: val_mDice did not improve from 0.58166
Epoch 11/300
 - 13s - loss: 0.3808 - acc: 0.9407 - mDice: 0.6697 - val_loss: 0.5371 - val_acc: 0.9486 - val_mDice: 0.5759

Epoch 00011: val_mDice did not improve from 0.58166
Epoch 12/300
 - 13s - loss: 0.3726 - acc: 0.9429 - mDice: 0.6750 - val_loss: 0.5298 - val_acc: 0.9460 - val_mDice: 0.5790

Epoch 00012: val_mDice did not improve from 0.58166
Epoch 13/300
 - 13s - loss: 0.3632 - acc: 0.9444 - mDice: 0.6815 - val_loss: 0.5510 - val_acc: 0.9485 - val_mDice: 0.5717

Epoch 00013: val_mDice did not improve from 0.58166
Epoch 14/300
 - 13s - loss: 0.3552 - acc: 0.9452 - mDice: 0.6868 - val_loss: 0.5313 - val_acc: 0.9442 - val_mDice: 0.5761

Epoch 00014: val_mDice did not improve from 0.58166
Epoch 15/300
 - 13s - loss: 0.3496 - acc: 0.9460 - mDice: 0.6909 - val_loss: 0.5464 - val_acc: 0.9436 - val_mDice: 0.5682

Epoch 00015: val_mDice did not improve from 0.58166
Epoch 16/300
 - 13s - loss: 0.3436 - acc: 0.9466 - mDice: 0.6952 - val_loss: 0.5308 - val_acc: 0.9454 - val_mDice: 0.5765

Epoch 00016: val_mDice did not improve from 0.58166
Epoch 17/300
 - 13s - loss: 0.3374 - acc: 0.9472 - mDice: 0.6996 - val_loss: 0.5411 - val_acc: 0.9420 - val_mDice: 0.5702

Epoch 00017: val_mDice did not improve from 0.58166
Epoch 18/300
 - 13s - loss: 0.3311 - acc: 0.9477 - mDice: 0.7040 - val_loss: 0.5096 - val_acc: 0.9486 - val_mDice: 0.5901

Epoch 00018: val_mDice improved from 0.58166 to 0.59015, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 19/300
 - 13s - loss: 0.3281 - acc: 0.9481 - mDice: 0.7066 - val_loss: 0.4936 - val_acc: 0.9500 - val_mDice: 0.6010

Epoch 00019: val_mDice improved from 0.59015 to 0.60099, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 20/300
 - 13s - loss: 0.3222 - acc: 0.9485 - mDice: 0.7106 - val_loss: 0.5408 - val_acc: 0.9495 - val_mDice: 0.5776

Epoch 00020: val_mDice did not improve from 0.60099
Epoch 21/300
 - 13s - loss: 0.3217 - acc: 0.9486 - mDice: 0.7110 - val_loss: 0.4838 - val_acc: 0.9513 - val_mDice: 0.6056

Epoch 00021: val_mDice improved from 0.60099 to 0.60564, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 22/300
 - 13s - loss: 0.3156 - acc: 0.9492 - mDice: 0.7154 - val_loss: 0.5975 - val_acc: 0.9371 - val_mDice: 0.5409

Epoch 00022: val_mDice did not improve from 0.60564
Epoch 23/300
 - 14s - loss: 0.3123 - acc: 0.9495 - mDice: 0.7180 - val_loss: 0.5579 - val_acc: 0.9423 - val_mDice: 0.5587

Epoch 00023: val_mDice did not improve from 0.60564
Epoch 24/300
 - 13s - loss: 0.3096 - acc: 0.9498 - mDice: 0.7199 - val_loss: 0.5330 - val_acc: 0.9419 - val_mDice: 0.5746

Epoch 00024: val_mDice did not improve from 0.60564
Epoch 25/300
 - 13s - loss: 0.3064 - acc: 0.9499 - mDice: 0.7224 - val_loss: 0.5208 - val_acc: 0.9472 - val_mDice: 0.5835

Epoch 00025: val_mDice did not improve from 0.60564
Epoch 26/300
 - 13s - loss: 0.3023 - acc: 0.9503 - mDice: 0.7253 - val_loss: 0.5300 - val_acc: 0.9473 - val_mDice: 0.5814

Epoch 00026: val_mDice did not improve from 0.60564
Epoch 27/300
 - 13s - loss: 0.3008 - acc: 0.9505 - mDice: 0.7266 - val_loss: 0.5027 - val_acc: 0.9479 - val_mDice: 0.5943

Epoch 00027: val_mDice did not improve from 0.60564
Epoch 28/300
 - 13s - loss: 0.2977 - acc: 0.9507 - mDice: 0.7288 - val_loss: 0.4950 - val_acc: 0.9498 - val_mDice: 0.6008

Epoch 00028: val_mDice did not improve from 0.60564
Epoch 29/300
 - 13s - loss: 0.2946 - acc: 0.9510 - mDice: 0.7312 - val_loss: 0.5176 - val_acc: 0.9474 - val_mDice: 0.5855

Epoch 00029: val_mDice did not improve from 0.60564
Epoch 30/300
 - 13s - loss: 0.2928 - acc: 0.9511 - mDice: 0.7326 - val_loss: 0.5234 - val_acc: 0.9447 - val_mDice: 0.5813

Epoch 00030: val_mDice did not improve from 0.60564
Epoch 31/300
 - 14s - loss: 0.2915 - acc: 0.9511 - mDice: 0.7336 - val_loss: 0.5094 - val_acc: 0.9499 - val_mDice: 0.5955

Epoch 00031: val_mDice did not improve from 0.60564
Epoch 32/300
 - 13s - loss: 0.2888 - acc: 0.9515 - mDice: 0.7356 - val_loss: 0.5719 - val_acc: 0.9492 - val_mDice: 0.5669

Epoch 00032: val_mDice did not improve from 0.60564
Epoch 33/300
 - 13s - loss: 0.2890 - acc: 0.9514 - mDice: 0.7354 - val_loss: 0.5288 - val_acc: 0.9456 - val_mDice: 0.5774

Epoch 00033: val_mDice did not improve from 0.60564
Epoch 34/300
 - 13s - loss: 0.2832 - acc: 0.9519 - mDice: 0.7398 - val_loss: 0.4924 - val_acc: 0.9500 - val_mDice: 0.6020

Epoch 00034: val_mDice did not improve from 0.60564
Epoch 35/300
 - 14s - loss: 0.2850 - acc: 0.9517 - mDice: 0.7384 - val_loss: 0.5204 - val_acc: 0.9459 - val_mDice: 0.5824

Epoch 00035: val_mDice did not improve from 0.60564
Epoch 36/300
 - 13s - loss: 0.2822 - acc: 0.9520 - mDice: 0.7407 - val_loss: 0.6147 - val_acc: 0.9490 - val_mDice: 0.5430

Epoch 00036: val_mDice did not improve from 0.60564
Epoch 37/300
 - 13s - loss: 0.2817 - acc: 0.9520 - mDice: 0.7410 - val_loss: 0.5313 - val_acc: 0.9495 - val_mDice: 0.5863

Epoch 00037: val_mDice did not improve from 0.60564
Epoch 38/300
 - 14s - loss: 0.2798 - acc: 0.9523 - mDice: 0.7426 - val_loss: 0.5055 - val_acc: 0.9506 - val_mDice: 0.5988

Epoch 00038: val_mDice did not improve from 0.60564
Epoch 39/300
 - 13s - loss: 0.2781 - acc: 0.9524 - mDice: 0.7439 - val_loss: 0.5539 - val_acc: 0.9508 - val_mDice: 0.5747

Epoch 00039: val_mDice did not improve from 0.60564
Epoch 40/300
 - 13s - loss: 0.2750 - acc: 0.9526 - mDice: 0.7462 - val_loss: 0.6708 - val_acc: 0.9372 - val_mDice: 0.5135

Epoch 00040: val_mDice did not improve from 0.60564
Epoch 41/300
 - 14s - loss: 0.2743 - acc: 0.9527 - mDice: 0.7467 - val_loss: 0.5243 - val_acc: 0.9447 - val_mDice: 0.5857

Epoch 00041: val_mDice did not improve from 0.60564
Epoch 42/300
 - 13s - loss: 0.2734 - acc: 0.9527 - mDice: 0.7475 - val_loss: 0.5042 - val_acc: 0.9499 - val_mDice: 0.5945

Epoch 00042: val_mDice did not improve from 0.60564
Epoch 43/300
 - 14s - loss: 0.2723 - acc: 0.9528 - mDice: 0.7483 - val_loss: 0.5304 - val_acc: 0.9492 - val_mDice: 0.5826

Epoch 00043: val_mDice did not improve from 0.60564
Epoch 44/300
 - 14s - loss: 0.2720 - acc: 0.9529 - mDice: 0.7485 - val_loss: 0.5480 - val_acc: 0.9503 - val_mDice: 0.5762

Epoch 00044: val_mDice did not improve from 0.60564
Epoch 45/300
 - 13s - loss: 0.2690 - acc: 0.9529 - mDice: 0.7508 - val_loss: 0.4975 - val_acc: 0.9500 - val_mDice: 0.6008

Epoch 00045: val_mDice did not improve from 0.60564
Epoch 46/300
 - 13s - loss: 0.2684 - acc: 0.9531 - mDice: 0.7514 - val_loss: 0.5307 - val_acc: 0.9507 - val_mDice: 0.5863

Epoch 00046: val_mDice did not improve from 0.60564
Epoch 47/300
 - 13s - loss: 0.2664 - acc: 0.9533 - mDice: 0.7528 - val_loss: 0.5283 - val_acc: 0.9495 - val_mDice: 0.5842

Epoch 00047: val_mDice did not improve from 0.60564
Epoch 48/300
 - 14s - loss: 0.2654 - acc: 0.9534 - mDice: 0.7537 - val_loss: 0.5296 - val_acc: 0.9493 - val_mDice: 0.5895

Epoch 00048: val_mDice did not improve from 0.60564
Epoch 49/300
 - 13s - loss: 0.2661 - acc: 0.9533 - mDice: 0.7532 - val_loss: 0.5287 - val_acc: 0.9516 - val_mDice: 0.5881

Epoch 00049: val_mDice did not improve from 0.60564
Epoch 50/300
 - 13s - loss: 0.2655 - acc: 0.9534 - mDice: 0.7537 - val_loss: 0.5445 - val_acc: 0.9494 - val_mDice: 0.5768

Epoch 00050: val_mDice did not improve from 0.60564
Epoch 51/300
 - 13s - loss: 0.2631 - acc: 0.9535 - mDice: 0.7556 - val_loss: 0.5272 - val_acc: 0.9510 - val_mDice: 0.5847

Epoch 00051: val_mDice did not improve from 0.60564
Epoch 52/300
 - 13s - loss: 0.2637 - acc: 0.9535 - mDice: 0.7550 - val_loss: 0.5326 - val_acc: 0.9489 - val_mDice: 0.5856

Epoch 00052: val_mDice did not improve from 0.60564
Epoch 53/300
 - 13s - loss: 0.2615 - acc: 0.9537 - mDice: 0.7568 - val_loss: 0.5600 - val_acc: 0.9488 - val_mDice: 0.5726

Epoch 00053: val_mDice did not improve from 0.60564
Epoch 54/300
 - 13s - loss: 0.2598 - acc: 0.9538 - mDice: 0.7581 - val_loss: 0.5475 - val_acc: 0.9517 - val_mDice: 0.5847

Epoch 00054: val_mDice did not improve from 0.60564
Epoch 55/300
 - 14s - loss: 0.2589 - acc: 0.9538 - mDice: 0.7589 - val_loss: 0.5119 - val_acc: 0.9480 - val_mDice: 0.5920

Epoch 00055: val_mDice did not improve from 0.60564
Epoch 56/300
 - 14s - loss: 0.2584 - acc: 0.9539 - mDice: 0.7593 - val_loss: 0.5947 - val_acc: 0.9482 - val_mDice: 0.5638

Epoch 00056: val_mDice did not improve from 0.60564
Epoch 57/300
 - 13s - loss: 0.2575 - acc: 0.9540 - mDice: 0.7599 - val_loss: 0.5670 - val_acc: 0.9501 - val_mDice: 0.5626

Epoch 00057: val_mDice did not improve from 0.60564
Epoch 58/300
 - 13s - loss: 0.2575 - acc: 0.9540 - mDice: 0.7600 - val_loss: 0.5754 - val_acc: 0.9506 - val_mDice: 0.5655

Epoch 00058: val_mDice did not improve from 0.60564
Epoch 59/300
 - 13s - loss: 0.2557 - acc: 0.9541 - mDice: 0.7614 - val_loss: 0.5516 - val_acc: 0.9505 - val_mDice: 0.5832

Epoch 00059: val_mDice did not improve from 0.60564
Epoch 60/300
 - 13s - loss: 0.2550 - acc: 0.9541 - mDice: 0.7620 - val_loss: 0.5624 - val_acc: 0.9521 - val_mDice: 0.5816

Epoch 00060: val_mDice did not improve from 0.60564
Epoch 61/300
 - 13s - loss: 0.2554 - acc: 0.9541 - mDice: 0.7617 - val_loss: 0.5379 - val_acc: 0.9490 - val_mDice: 0.5849

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.55s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.32s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  2.10s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:02<10:12,  2.16s/it]predicting train subjects:   1%|          | 2/285 [00:03<09:23,  1.99s/it]predicting train subjects:   1%|          | 3/285 [00:05<09:16,  1.97s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<08:42,  1.86s/it]predicting train subjects:   2%|▏         | 5/285 [00:09<08:57,  1.92s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<08:23,  1.80s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:45,  1.89s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:40,  1.88s/it]predicting train subjects:   3%|▎         | 9/285 [00:17<09:09,  1.99s/it]predicting train subjects:   4%|▎         | 10/285 [00:19<09:18,  2.03s/it]predicting train subjects:   4%|▍         | 11/285 [00:21<09:02,  1.98s/it]predicting train subjects:   4%|▍         | 12/285 [00:23<09:09,  2.01s/it]predicting train subjects:   5%|▍         | 13/285 [00:25<09:24,  2.07s/it]predicting train subjects:   5%|▍         | 14/285 [00:28<10:43,  2.37s/it]predicting train subjects:   5%|▌         | 15/285 [00:31<12:04,  2.68s/it]predicting train subjects:   6%|▌         | 16/285 [00:35<12:50,  2.87s/it]predicting train subjects:   6%|▌         | 17/285 [00:37<12:13,  2.74s/it]predicting train subjects:   6%|▋         | 18/285 [00:40<12:02,  2.71s/it]predicting train subjects:   7%|▋         | 19/285 [00:42<11:22,  2.56s/it]predicting train subjects:   7%|▋         | 20/285 [00:44<11:07,  2.52s/it]predicting train subjects:   7%|▋         | 21/285 [00:47<11:24,  2.59s/it]predicting train subjects:   8%|▊         | 22/285 [00:49<10:40,  2.44s/it]predicting train subjects:   8%|▊         | 23/285 [00:52<10:53,  2.49s/it]predicting train subjects:   8%|▊         | 24/285 [00:54<10:16,  2.36s/it]predicting train subjects:   9%|▉         | 25/285 [00:57<11:10,  2.58s/it]predicting train subjects:   9%|▉         | 26/285 [01:00<11:30,  2.66s/it]predicting train subjects:   9%|▉         | 27/285 [01:02<10:47,  2.51s/it]predicting train subjects:  10%|▉         | 28/285 [01:05<10:54,  2.55s/it]predicting train subjects:  10%|█         | 29/285 [01:07<10:44,  2.52s/it]predicting train subjects:  11%|█         | 30/285 [01:10<10:48,  2.54s/it]predicting train subjects:  11%|█         | 31/285 [01:12<10:48,  2.55s/it]predicting train subjects:  11%|█         | 32/285 [01:14<10:03,  2.38s/it]predicting train subjects:  12%|█▏        | 33/285 [01:17<09:57,  2.37s/it]predicting train subjects:  12%|█▏        | 34/285 [01:19<09:57,  2.38s/it]predicting train subjects:  12%|█▏        | 35/285 [01:21<10:02,  2.41s/it]predicting train subjects:  13%|█▎        | 36/285 [01:23<09:18,  2.24s/it]predicting train subjects:  13%|█▎        | 37/285 [01:26<09:38,  2.33s/it]predicting train subjects:  13%|█▎        | 38/285 [01:28<09:55,  2.41s/it]predicting train subjects:  14%|█▎        | 39/285 [01:30<09:27,  2.31s/it]predicting train subjects:  14%|█▍        | 40/285 [01:33<09:27,  2.32s/it]predicting train subjects:  14%|█▍        | 41/285 [01:35<09:08,  2.25s/it]predicting train subjects:  15%|█▍        | 42/285 [01:37<09:06,  2.25s/it]predicting train subjects:  15%|█▌        | 43/285 [01:39<09:02,  2.24s/it]predicting train subjects:  15%|█▌        | 44/285 [01:42<09:34,  2.38s/it]predicting train subjects:  16%|█▌        | 45/285 [01:44<09:28,  2.37s/it]predicting train subjects:  16%|█▌        | 46/285 [01:47<09:40,  2.43s/it]predicting train subjects:  16%|█▋        | 47/285 [01:49<09:10,  2.31s/it]predicting train subjects:  17%|█▋        | 48/285 [01:51<08:55,  2.26s/it]predicting train subjects:  17%|█▋        | 49/285 [01:53<08:55,  2.27s/it]predicting train subjects:  18%|█▊        | 50/285 [01:56<08:55,  2.28s/it]predicting train subjects:  18%|█▊        | 51/285 [01:58<09:15,  2.37s/it]predicting train subjects:  18%|█▊        | 52/285 [02:01<09:20,  2.40s/it]predicting train subjects:  19%|█▊        | 53/285 [02:03<09:11,  2.38s/it]predicting train subjects:  19%|█▉        | 54/285 [02:06<09:42,  2.52s/it]predicting train subjects:  19%|█▉        | 55/285 [02:08<09:21,  2.44s/it]predicting train subjects:  20%|█▉        | 56/285 [02:11<09:18,  2.44s/it]predicting train subjects:  20%|██        | 57/285 [02:13<08:45,  2.30s/it]predicting train subjects:  20%|██        | 58/285 [02:15<08:26,  2.23s/it]predicting train subjects:  21%|██        | 59/285 [02:17<08:55,  2.37s/it]predicting train subjects:  21%|██        | 60/285 [02:20<09:06,  2.43s/it]predicting train subjects:  21%|██▏       | 61/285 [02:22<08:45,  2.35s/it]predicting train subjects:  22%|██▏       | 62/285 [02:25<08:42,  2.34s/it]predicting train subjects:  22%|██▏       | 63/285 [02:27<08:37,  2.33s/it]predicting train subjects:  22%|██▏       | 64/285 [02:29<08:24,  2.28s/it]predicting train subjects:  23%|██▎       | 65/285 [02:31<08:28,  2.31s/it]predicting train subjects:  23%|██▎       | 66/285 [02:34<08:26,  2.31s/it]predicting train subjects:  24%|██▎       | 67/285 [02:36<08:20,  2.29s/it]predicting train subjects:  24%|██▍       | 68/285 [02:38<07:58,  2.20s/it]predicting train subjects:  24%|██▍       | 69/285 [02:40<08:00,  2.22s/it]predicting train subjects:  25%|██▍       | 70/285 [02:42<08:02,  2.24s/it]predicting train subjects:  25%|██▍       | 71/285 [02:45<08:24,  2.36s/it]predicting train subjects:  25%|██▌       | 72/285 [02:47<08:01,  2.26s/it]predicting train subjects:  26%|██▌       | 73/285 [02:49<07:47,  2.20s/it]predicting train subjects:  26%|██▌       | 74/285 [02:52<07:51,  2.24s/it]predicting train subjects:  26%|██▋       | 75/285 [02:54<07:53,  2.25s/it]predicting train subjects:  27%|██▋       | 76/285 [02:56<07:58,  2.29s/it]predicting train subjects:  27%|██▋       | 77/285 [02:58<07:57,  2.29s/it]predicting train subjects:  27%|██▋       | 78/285 [03:01<07:46,  2.25s/it]predicting train subjects:  28%|██▊       | 79/285 [03:03<07:50,  2.28s/it]predicting train subjects:  28%|██▊       | 80/285 [03:05<07:41,  2.25s/it]predicting train subjects:  28%|██▊       | 81/285 [03:07<07:19,  2.15s/it]predicting train subjects:  29%|██▉       | 82/285 [03:09<07:09,  2.12s/it]predicting train subjects:  29%|██▉       | 83/285 [03:11<07:02,  2.09s/it]predicting train subjects:  29%|██▉       | 84/285 [03:13<07:04,  2.11s/it]predicting train subjects:  30%|██▉       | 85/285 [03:16<07:15,  2.18s/it]predicting train subjects:  30%|███       | 86/285 [03:18<07:44,  2.33s/it]predicting train subjects:  31%|███       | 87/285 [03:20<07:27,  2.26s/it]predicting train subjects:  31%|███       | 88/285 [03:22<07:12,  2.19s/it]predicting train subjects:  31%|███       | 89/285 [03:25<07:11,  2.20s/it]predicting train subjects:  32%|███▏      | 90/285 [03:27<07:09,  2.20s/it]predicting train subjects:  32%|███▏      | 91/285 [03:29<07:10,  2.22s/it]predicting train subjects:  32%|███▏      | 92/285 [03:32<07:31,  2.34s/it]predicting train subjects:  33%|███▎      | 93/285 [03:34<07:21,  2.30s/it]predicting train subjects:  33%|███▎      | 94/285 [03:36<07:22,  2.32s/it]predicting train subjects:  33%|███▎      | 95/285 [03:39<07:24,  2.34s/it]predicting train subjects:  34%|███▎      | 96/285 [03:41<07:17,  2.31s/it]predicting train subjects:  34%|███▍      | 97/285 [03:43<07:17,  2.33s/it]predicting train subjects:  34%|███▍      | 98/285 [03:46<07:18,  2.35s/it]predicting train subjects:  35%|███▍      | 99/285 [03:48<07:00,  2.26s/it]predicting train subjects:  35%|███▌      | 100/285 [03:50<07:16,  2.36s/it]predicting train subjects:  35%|███▌      | 101/285 [03:52<06:56,  2.26s/it]predicting train subjects:  36%|███▌      | 102/285 [03:55<06:49,  2.24s/it]predicting train subjects:  36%|███▌      | 103/285 [03:57<06:53,  2.27s/it]predicting train subjects:  36%|███▋      | 104/285 [03:59<06:42,  2.22s/it]predicting train subjects:  37%|███▋      | 105/285 [04:01<06:40,  2.23s/it]predicting train subjects:  37%|███▋      | 106/285 [04:03<06:33,  2.20s/it]predicting train subjects:  38%|███▊      | 107/285 [04:06<06:26,  2.17s/it]predicting train subjects:  38%|███▊      | 108/285 [04:08<06:19,  2.14s/it]predicting train subjects:  38%|███▊      | 109/285 [04:10<06:23,  2.18s/it]predicting train subjects:  39%|███▊      | 110/285 [04:12<06:34,  2.26s/it]predicting train subjects:  39%|███▉      | 111/285 [04:14<06:22,  2.20s/it]predicting train subjects:  39%|███▉      | 112/285 [04:17<06:33,  2.27s/it]predicting train subjects:  40%|███▉      | 113/285 [04:19<06:21,  2.22s/it]predicting train subjects:  40%|████      | 114/285 [04:21<06:25,  2.25s/it]predicting train subjects:  40%|████      | 115/285 [04:24<06:24,  2.26s/it]predicting train subjects:  41%|████      | 116/285 [04:26<06:17,  2.23s/it]predicting train subjects:  41%|████      | 117/285 [04:28<06:05,  2.18s/it]predicting train subjects:  41%|████▏     | 118/285 [04:30<06:04,  2.18s/it]predicting train subjects:  42%|████▏     | 119/285 [04:32<06:05,  2.20s/it]predicting train subjects:  42%|████▏     | 120/285 [04:34<06:04,  2.21s/it]predicting train subjects:  42%|████▏     | 121/285 [04:36<05:50,  2.14s/it]predicting train subjects:  43%|████▎     | 122/285 [04:38<05:42,  2.10s/it]predicting train subjects:  43%|████▎     | 123/285 [04:40<05:34,  2.07s/it]predicting train subjects:  44%|████▎     | 124/285 [04:42<05:32,  2.07s/it]predicting train subjects:  44%|████▍     | 125/285 [04:44<05:18,  1.99s/it]predicting train subjects:  44%|████▍     | 126/285 [04:46<05:15,  1.98s/it]predicting train subjects:  45%|████▍     | 127/285 [04:48<05:02,  1.92s/it]predicting train subjects:  45%|████▍     | 128/285 [04:50<05:02,  1.93s/it]predicting train subjects:  45%|████▌     | 129/285 [04:52<05:02,  1.94s/it]predicting train subjects:  46%|████▌     | 130/285 [04:54<05:11,  2.01s/it]predicting train subjects:  46%|████▌     | 131/285 [04:56<04:59,  1.94s/it]predicting train subjects:  46%|████▋     | 132/285 [04:58<04:58,  1.95s/it]predicting train subjects:  47%|████▋     | 133/285 [05:00<05:05,  2.01s/it]predicting train subjects:  47%|████▋     | 134/285 [05:02<04:57,  1.97s/it]predicting train subjects:  47%|████▋     | 135/285 [05:04<04:49,  1.93s/it]predicting train subjects:  48%|████▊     | 136/285 [05:05<04:34,  1.84s/it]predicting train subjects:  48%|████▊     | 137/285 [05:07<04:36,  1.87s/it]predicting train subjects:  48%|████▊     | 138/285 [05:09<04:30,  1.84s/it]predicting train subjects:  49%|████▉     | 139/285 [05:11<04:44,  1.95s/it]predicting train subjects:  49%|████▉     | 140/285 [05:13<04:46,  1.97s/it]predicting train subjects:  49%|████▉     | 141/285 [05:15<04:33,  1.90s/it]predicting train subjects:  50%|████▉     | 142/285 [05:17<04:32,  1.91s/it]predicting train subjects:  50%|█████     | 143/285 [05:19<04:20,  1.83s/it]predicting train subjects:  51%|█████     | 144/285 [05:21<04:26,  1.89s/it]predicting train subjects:  51%|█████     | 145/285 [05:22<04:23,  1.88s/it]predicting train subjects:  51%|█████     | 146/285 [05:25<04:29,  1.94s/it]predicting train subjects:  52%|█████▏    | 147/285 [05:26<04:21,  1.89s/it]predicting train subjects:  52%|█████▏    | 148/285 [05:28<04:28,  1.96s/it]predicting train subjects:  52%|█████▏    | 149/285 [05:30<04:22,  1.93s/it]predicting train subjects:  53%|█████▎    | 150/285 [05:32<04:07,  1.84s/it]predicting train subjects:  53%|█████▎    | 151/285 [05:34<04:10,  1.87s/it]predicting train subjects:  53%|█████▎    | 152/285 [05:36<04:11,  1.89s/it]predicting train subjects:  54%|█████▎    | 153/285 [05:38<04:05,  1.86s/it]predicting train subjects:  54%|█████▍    | 154/285 [05:40<04:21,  2.00s/it]predicting train subjects:  54%|█████▍    | 155/285 [05:42<04:16,  1.97s/it]predicting train subjects:  55%|█████▍    | 156/285 [05:44<04:23,  2.04s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:46<04:11,  1.96s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:48<04:13,  1.99s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:50<04:09,  1.98s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:52<04:02,  1.94s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:54<04:15,  2.06s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:56<03:59,  1.95s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:58<04:03,  2.00s/it]predicting train subjects:  58%|█████▊    | 164/285 [06:00<03:52,  1.93s/it]predicting train subjects:  58%|█████▊    | 165/285 [06:01<03:39,  1.83s/it]predicting train subjects:  58%|█████▊    | 166/285 [06:03<03:39,  1.84s/it]predicting train subjects:  59%|█████▊    | 167/285 [06:05<03:40,  1.87s/it]predicting train subjects:  59%|█████▉    | 168/285 [06:07<03:32,  1.81s/it]predicting train subjects:  59%|█████▉    | 169/285 [06:08<03:21,  1.74s/it]predicting train subjects:  60%|█████▉    | 170/285 [06:10<03:09,  1.65s/it]predicting train subjects:  60%|██████    | 171/285 [06:11<03:06,  1.63s/it]predicting train subjects:  60%|██████    | 172/285 [06:13<02:59,  1.59s/it]predicting train subjects:  61%|██████    | 173/285 [06:14<02:57,  1.58s/it]predicting train subjects:  61%|██████    | 174/285 [06:16<02:53,  1.57s/it]predicting train subjects:  61%|██████▏   | 175/285 [06:18<02:55,  1.60s/it]predicting train subjects:  62%|██████▏   | 176/285 [06:19<02:57,  1.63s/it]predicting train subjects:  62%|██████▏   | 177/285 [06:21<02:50,  1.58s/it]predicting train subjects:  62%|██████▏   | 178/285 [06:22<02:48,  1.58s/it]predicting train subjects:  63%|██████▎   | 179/285 [06:24<02:45,  1.56s/it]predicting train subjects:  63%|██████▎   | 180/285 [06:26<02:56,  1.68s/it]predicting train subjects:  64%|██████▎   | 181/285 [06:27<02:54,  1.68s/it]predicting train subjects:  64%|██████▍   | 182/285 [06:29<02:54,  1.70s/it]predicting train subjects:  64%|██████▍   | 183/285 [06:31<02:48,  1.65s/it]predicting train subjects:  65%|██████▍   | 184/285 [06:32<02:42,  1.61s/it]predicting train subjects:  65%|██████▍   | 185/285 [06:34<02:35,  1.56s/it]predicting train subjects:  65%|██████▌   | 186/285 [06:36<02:45,  1.67s/it]predicting train subjects:  66%|██████▌   | 187/285 [06:37<02:49,  1.73s/it]predicting train subjects:  66%|██████▌   | 188/285 [06:39<02:51,  1.77s/it]predicting train subjects:  66%|██████▋   | 189/285 [06:41<02:40,  1.67s/it]predicting train subjects:  67%|██████▋   | 190/285 [06:42<02:35,  1.63s/it]predicting train subjects:  67%|██████▋   | 191/285 [06:44<02:34,  1.64s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:46<02:33,  1.65s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:47<02:26,  1.59s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:49<02:22,  1.57s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:50<02:19,  1.55s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:52<02:26,  1.65s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:54<02:32,  1.73s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:56<02:34,  1.78s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:57<02:25,  1.69s/it]predicting train subjects:  70%|███████   | 200/285 [06:59<02:17,  1.62s/it]predicting train subjects:  71%|███████   | 201/285 [07:01<02:22,  1.69s/it]predicting train subjects:  71%|███████   | 202/285 [07:02<02:20,  1.69s/it]predicting train subjects:  71%|███████   | 203/285 [07:04<02:19,  1.70s/it]predicting train subjects:  72%|███████▏  | 204/285 [07:06<02:13,  1.65s/it]predicting train subjects:  72%|███████▏  | 205/285 [07:07<02:07,  1.59s/it]predicting train subjects:  72%|███████▏  | 206/285 [07:09<02:06,  1.60s/it]predicting train subjects:  73%|███████▎  | 207/285 [07:11<02:11,  1.69s/it]predicting train subjects:  73%|███████▎  | 208/285 [07:12<02:13,  1.74s/it]predicting train subjects:  73%|███████▎  | 209/285 [07:14<02:16,  1.79s/it]predicting train subjects:  74%|███████▎  | 210/285 [07:16<02:08,  1.71s/it]predicting train subjects:  74%|███████▍  | 211/285 [07:17<02:01,  1.64s/it]predicting train subjects:  74%|███████▍  | 212/285 [07:19<02:03,  1.69s/it]predicting train subjects:  75%|███████▍  | 213/285 [07:21<02:02,  1.71s/it]predicting train subjects:  75%|███████▌  | 214/285 [07:22<01:55,  1.62s/it]predicting train subjects:  75%|███████▌  | 215/285 [07:24<01:57,  1.68s/it]predicting train subjects:  76%|███████▌  | 216/285 [07:26<01:51,  1.62s/it]predicting train subjects:  76%|███████▌  | 217/285 [07:28<01:57,  1.72s/it]predicting train subjects:  76%|███████▋  | 218/285 [07:30<02:01,  1.81s/it]predicting train subjects:  77%|███████▋  | 219/285 [07:31<02:01,  1.84s/it]predicting train subjects:  77%|███████▋  | 220/285 [07:33<01:53,  1.75s/it]predicting train subjects:  78%|███████▊  | 221/285 [07:34<01:47,  1.68s/it]predicting train subjects:  78%|███████▊  | 222/285 [07:36<01:46,  1.69s/it]predicting train subjects:  78%|███████▊  | 223/285 [07:38<01:40,  1.61s/it]predicting train subjects:  79%|███████▊  | 224/285 [07:39<01:36,  1.58s/it]predicting train subjects:  79%|███████▉  | 225/285 [07:41<01:32,  1.55s/it]predicting train subjects:  79%|███████▉  | 226/285 [07:43<01:38,  1.67s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:44<01:40,  1.73s/it]predicting train subjects:  80%|████████  | 228/285 [07:46<01:40,  1.76s/it]predicting train subjects:  80%|████████  | 229/285 [07:48<01:36,  1.73s/it]predicting train subjects:  81%|████████  | 230/285 [07:49<01:32,  1.68s/it]predicting train subjects:  81%|████████  | 231/285 [07:51<01:27,  1.62s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:53<01:29,  1.69s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:54<01:24,  1.63s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:56<01:26,  1.70s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:58<01:22,  1.64s/it]predicting train subjects:  83%|████████▎ | 236/285 [08:00<01:24,  1.72s/it]predicting train subjects:  83%|████████▎ | 237/285 [08:02<01:25,  1.79s/it]predicting train subjects:  84%|████████▎ | 238/285 [08:03<01:24,  1.80s/it]predicting train subjects:  84%|████████▍ | 239/285 [08:05<01:21,  1.77s/it]predicting train subjects:  84%|████████▍ | 240/285 [08:07<01:16,  1.70s/it]predicting train subjects:  85%|████████▍ | 241/285 [08:08<01:11,  1.62s/it]predicting train subjects:  85%|████████▍ | 242/285 [08:10<01:08,  1.59s/it]predicting train subjects:  85%|████████▌ | 243/285 [08:11<01:04,  1.54s/it]predicting train subjects:  86%|████████▌ | 244/285 [08:13<01:06,  1.62s/it]predicting train subjects:  86%|████████▌ | 245/285 [08:14<01:03,  1.58s/it]predicting train subjects:  86%|████████▋ | 246/285 [08:16<01:05,  1.67s/it]predicting train subjects:  87%|████████▋ | 247/285 [08:18<01:05,  1.73s/it]predicting train subjects:  87%|████████▋ | 248/285 [08:20<01:04,  1.74s/it]predicting train subjects:  87%|████████▋ | 249/285 [08:21<00:59,  1.65s/it]predicting train subjects:  88%|████████▊ | 250/285 [08:23<00:57,  1.63s/it]predicting train subjects:  88%|████████▊ | 251/285 [08:24<00:53,  1.57s/it]predicting train subjects:  88%|████████▊ | 252/285 [08:26<00:51,  1.57s/it]predicting train subjects:  89%|████████▉ | 253/285 [08:28<00:52,  1.65s/it]predicting train subjects:  89%|████████▉ | 254/285 [08:29<00:52,  1.70s/it]predicting train subjects:  89%|████████▉ | 255/285 [08:31<00:50,  1.70s/it]predicting train subjects:  90%|████████▉ | 256/285 [08:33<00:47,  1.62s/it]predicting train subjects:  90%|█████████ | 257/285 [08:34<00:44,  1.59s/it]predicting train subjects:  91%|█████████ | 258/285 [08:36<00:45,  1.69s/it]predicting train subjects:  91%|█████████ | 259/285 [08:38<00:44,  1.70s/it]predicting train subjects:  91%|█████████ | 260/285 [08:39<00:40,  1.62s/it]predicting train subjects:  92%|█████████▏| 261/285 [08:41<00:38,  1.59s/it]predicting train subjects:  92%|█████████▏| 262/285 [08:42<00:35,  1.55s/it]predicting train subjects:  92%|█████████▏| 263/285 [08:44<00:33,  1.52s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:46<00:34,  1.66s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:47<00:34,  1.71s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:49<00:31,  1.65s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:50<00:29,  1.63s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:52<00:28,  1.69s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:54<00:27,  1.71s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:56<00:24,  1.64s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:57<00:22,  1.58s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:59<00:21,  1.65s/it]predicting train subjects:  96%|█████████▌| 273/285 [09:00<00:19,  1.60s/it]predicting train subjects:  96%|█████████▌| 274/285 [09:02<00:17,  1.56s/it]predicting train subjects:  96%|█████████▋| 275/285 [09:04<00:16,  1.68s/it]predicting train subjects:  97%|█████████▋| 276/285 [09:06<00:15,  1.72s/it]predicting train subjects:  97%|█████████▋| 277/285 [09:07<00:13,  1.64s/it]predicting train subjects:  98%|█████████▊| 278/285 [09:08<00:11,  1.60s/it]predicting train subjects:  98%|█████████▊| 279/285 [09:10<00:09,  1.63s/it]predicting train subjects:  98%|█████████▊| 280/285 [09:12<00:07,  1.57s/it]predicting train subjects:  99%|█████████▊| 281/285 [09:13<00:06,  1.55s/it]predicting train subjects:  99%|█████████▉| 282/285 [09:15<00:04,  1.52s/it]predicting train subjects:  99%|█████████▉| 283/285 [09:16<00:03,  1.64s/it]predicting train subjects: 100%|█████████▉| 284/285 [09:18<00:01,  1.73s/it]predicting train subjects: 100%|██████████| 285/285 [09:20<00:00,  1.77s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:08,  1.72s/it]Loading train:   1%|          | 2/285 [00:02<07:24,  1.57s/it]Loading train:   1%|          | 3/285 [00:04<07:13,  1.54s/it]
Epoch 00061: val_mDice did not improve from 0.60564
Restoring model weights from the end of the best epoch
Epoch 00061: early stopping
{'val_loss': [1.6608863755977354, 0.6982416317449601, 0.5979053884245163, 0.5954666640505445, 0.5429562939611893, 0.5263967454100454, 0.5313153713109107, 0.5601902970388615, 0.5241400606139412, 0.5841315838211741, 0.5370656195299586, 0.5298412865100626, 0.5509719988487286, 0.5313080399396033, 0.5463943434827154, 0.5307692798822286, 0.5411144638194718, 0.5095621617146711, 0.4936455378319298, 0.5407596390340581, 0.4837874463816595, 0.5974518979727889, 0.5578988430886295, 0.5329594518885267, 0.5208280183083518, 0.5299674159321706, 0.5027066399265268, 0.4949706043611026, 0.5175689009314809, 0.5233917555995493, 0.5094271838332022, 0.5718828586226735, 0.5287871743713677, 0.49240394011556105, 0.5204009267204966, 0.614743694579801, 0.5313133161161199, 0.5055329040442099, 0.5538571516894761, 0.6708439715081753, 0.5243084730382738, 0.5041578978133601, 0.5303839848028215, 0.5479506860232221, 0.49752020203201464, 0.5306996443418152, 0.5283269762326885, 0.5296245347188172, 0.5287015101763123, 0.5445000362795824, 0.5271664215199774, 0.5326488597432995, 0.5600471486592425, 0.5475364097669804, 0.5118618164648557, 0.5947191458840609, 0.5670028059176226, 0.5754420993714359, 0.5516059481897834, 0.562383034042806, 0.5378695063750837], 'val_acc': [0.9156102414903694, 0.924874406287124, 0.9363636730769493, 0.9373863885522554, 0.9397850263052147, 0.945080339575613, 0.9459377463969438, 0.9444253854245447, 0.9459088158341094, 0.9436320452716763, 0.9485657657990908, 0.9459501341734519, 0.9485388767785866, 0.944154741044817, 0.9435783125168784, 0.9453799098563593, 0.9420349554642619, 0.9485926058705293, 0.9500181931357145, 0.9494871930037131, 0.9512908462039585, 0.9370950307260012, 0.9422808389423946, 0.9419482014032715, 0.9472104464163328, 0.9473013355079309, 0.9479066809462435, 0.9497806010299554, 0.9473860400349068, 0.9447208296653279, 0.9499003927134935, 0.949243424325016, 0.94559890830983, 0.9499747829730284, 0.9458943432269815, 0.9489707084341422, 0.9494665331680682, 0.9505863486055556, 0.9508322264229119, 0.9372004317171747, 0.94467538129018, 0.9498673584208143, 0.9491959097665116, 0.9502681733509681, 0.9500223128489276, 0.9506813970358012, 0.9495078551702659, 0.9492909368855993, 0.9516007856949747, 0.9493529307109684, 0.9509995636327306, 0.9489334888298419, 0.9488343223513171, 0.9516875447507677, 0.9479769211907626, 0.9482351854526797, 0.9500760316182781, 0.9505553575201408, 0.950497515041735, 0.9521358792342287, 0.9489975578292122], 'val_mDice': [0.2692281418173007, 0.48974004903985136, 0.5343444294103697, 0.5480383314899893, 0.5680303280579977, 0.5790211921297638, 0.5816641656380126, 0.5607323573288305, 0.5793913273172006, 0.549879257239443, 0.57593024309787, 0.5789891831035721, 0.5717416355729769, 0.5761103536829603, 0.5682294242208896, 0.5764607280992263, 0.5701914819259217, 0.59014576640209, 0.6009918437989731, 0.577555689065816, 0.6056431125662181, 0.5409178633929631, 0.5587254066707036, 0.5745900856050034, 0.583544753783242, 0.5813560395933396, 0.5943499710306775, 0.6008461374144315, 0.5854986766197162, 0.5812753119282217, 0.5954728466172458, 0.5668625092373214, 0.5773933533183689, 0.6020114441823693, 0.5824474602438218, 0.5430054737868921, 0.5862697063211623, 0.5987523341312089, 0.5747002869344956, 0.5134514983139891, 0.5856613183820714, 0.5944978171886679, 0.5825730785311267, 0.5761629316393889, 0.6007866859436035, 0.5863043699184609, 0.5841631163431945, 0.5895341588132208, 0.5880990601118716, 0.5768036789068297, 0.584656429024382, 0.5855645337584299, 0.5726241292900214, 0.5847357757930649, 0.592006620748083, 0.56383041962565, 0.5625647629439497, 0.5655334565226592, 0.583177140638149, 0.5815728566500061, 0.584932415512021], 'loss': [2.16219240766901, 0.7945887676303887, 0.6236032717829534, 0.5517798583950718, 0.4971671330354863, 0.46286981030718366, 0.43902527241007994, 0.41787697982764715, 0.4044478002875389, 0.3919898808249188, 0.3808178292770712, 0.37256578287490866, 0.36316881569815673, 0.35521611256262076, 0.3495959494230268, 0.3436062054062492, 0.3373565900092693, 0.33111395254340814, 0.32805165591650776, 0.32215855982002234, 0.32171424691125616, 0.31558249457022325, 0.31233654939416094, 0.3096447701119408, 0.3064048502006456, 0.3023470353780895, 0.3008149138064265, 0.2976889058003712, 0.29455500664706324, 0.29277531881132685, 0.29145062699679436, 0.2887592217880139, 0.28900861239863096, 0.28324363298174876, 0.2850335509252083, 0.28221773743194456, 0.2817109545135763, 0.27975254141033284, 0.27806855564731364, 0.2750095417581543, 0.27432205517186453, 0.2733718354398405, 0.2722894354480381, 0.2720426399654166, 0.26903217185764855, 0.2684205180110836, 0.2664335368327031, 0.2653781098741883, 0.2661073349473471, 0.2654940835576867, 0.2631119418446778, 0.26367597463642434, 0.26152748182431385, 0.2598395254394989, 0.25885729379146477, 0.2583740934633, 0.2575429546489584, 0.25748146407277384, 0.25566669980280216, 0.2550035937861753, 0.2553854707175432], 'acc': [0.6661126733759128, 0.8957101596959322, 0.9028317940585086, 0.9090518076807694, 0.9152902672963558, 0.9218213480059458, 0.9274570458783646, 0.9312939471061256, 0.9341680711017287, 0.9372468579699094, 0.9407229602619308, 0.9429027591517247, 0.9443809628993051, 0.9452373302876901, 0.9459944569034181, 0.9465648092499526, 0.9472149652590984, 0.9476840857924229, 0.9481493409478153, 0.9484879842323127, 0.9486072026763267, 0.9491634169316202, 0.9495433695850909, 0.949817057366426, 0.949945722865835, 0.9502669621621541, 0.950476920096341, 0.950702788604383, 0.9510176250029673, 0.951134628115588, 0.9511416795193892, 0.9515370213610824, 0.9514048663101635, 0.9518741297959489, 0.9517264325474221, 0.9520149032837568, 0.9519881938129824, 0.9522765642560053, 0.9524143331321352, 0.9525652352283673, 0.9527048985752027, 0.9526931950615016, 0.9527752142178195, 0.9528823482250766, 0.9529172550014638, 0.9531343180358971, 0.9532517265970947, 0.9533679651594663, 0.9532702756398098, 0.953413283134765, 0.9535270030218936, 0.9535406195619425, 0.9536522261412482, 0.9538088082215422, 0.9538140663666427, 0.9539466765502018, 0.9540369532952465, 0.9539822079758649, 0.9540970542450226, 0.954128576778689, 0.9541324432181492], 'mDice': [0.18117059345739214, 0.4395325101737941, 0.5227774327619747, 0.5628585823740122, 0.5947627812278251, 0.6160382989035811, 0.6311316473747246, 0.6448833495987168, 0.6539339012884379, 0.6621916082376592, 0.6696822848411422, 0.6750333891033861, 0.6814508592470183, 0.6868371313923644, 0.6908835213101642, 0.6952169782215133, 0.6996352160251593, 0.7039912502676449, 0.7065728436328702, 0.7106167059254785, 0.7109630879419093, 0.7154392352077438, 0.7179669954925962, 0.7199194431921722, 0.7223516791242509, 0.7253227264596371, 0.7265555544990541, 0.7287671391328081, 0.7311594361255426, 0.7325879519563973, 0.7335510653456366, 0.7356009819260753, 0.7353695757241948, 0.7397766056341788, 0.7383860362185729, 0.7406586699382938, 0.7410306431201735, 0.7426286628872057, 0.7438984575026708, 0.746185672857112, 0.7467492228661686, 0.7474789120235394, 0.7483104355363414, 0.748536375092107, 0.7508263937769019, 0.7513690517168278, 0.7528339770519229, 0.7537406458229315, 0.7531517807820947, 0.7537026542132018, 0.7555831053971037, 0.7550426545041065, 0.7568020881972056, 0.7581324994865959, 0.758940279136445, 0.7592611767440494, 0.7599336048738804, 0.7599753814223779, 0.7614389695501049, 0.7619814174340562, 0.7617068329990238]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0Loading train:   1%|▏         | 4/285 [00:05<07:11,  1.54s/it]Loading train:   2%|▏         | 5/285 [00:07<07:19,  1.57s/it]Loading train:   2%|▏         | 6/285 [00:08<06:47,  1.46s/it]Loading train:   2%|▏         | 7/285 [00:10<06:39,  1.44s/it]Loading train:   3%|▎         | 8/285 [00:11<06:48,  1.48s/it]Loading train:   3%|▎         | 9/285 [00:13<07:03,  1.54s/it]Loading train:   4%|▎         | 10/285 [00:14<06:28,  1.41s/it]Loading train:   4%|▍         | 11/285 [00:15<05:44,  1.26s/it]Loading train:   4%|▍         | 12/285 [00:16<05:33,  1.22s/it]Loading train:   5%|▍         | 13/285 [00:17<05:16,  1.16s/it]Loading train:   5%|▍         | 14/285 [00:18<05:07,  1.13s/it]Loading train:   5%|▌         | 15/285 [00:19<05:11,  1.15s/it]Loading train:   6%|▌         | 16/285 [00:20<05:03,  1.13s/it]Loading train:   6%|▌         | 17/285 [00:21<04:36,  1.03s/it]Loading train:   6%|▋         | 18/285 [00:22<04:24,  1.01it/s]Loading train:   7%|▋         | 19/285 [00:23<04:16,  1.04it/s]Loading train:   7%|▋         | 20/285 [00:24<04:23,  1.00it/s]Loading train:   7%|▋         | 21/285 [00:25<04:37,  1.05s/it]Loading train:   8%|▊         | 22/285 [00:26<04:29,  1.03s/it]Loading train:   8%|▊         | 23/285 [00:27<04:27,  1.02s/it]Loading train:   8%|▊         | 24/285 [00:28<04:23,  1.01s/it]Loading train:   9%|▉         | 25/285 [00:29<04:36,  1.06s/it]Loading train:   9%|▉         | 26/285 [00:31<04:40,  1.08s/it]Loading train:   9%|▉         | 27/285 [00:32<04:31,  1.05s/it]Loading train:  10%|▉         | 28/285 [00:33<04:27,  1.04s/it]Loading train:  10%|█         | 29/285 [00:33<04:07,  1.04it/s]Loading train:  11%|█         | 30/285 [00:34<04:04,  1.04it/s]Loading train:  11%|█         | 31/285 [00:35<04:02,  1.05it/s]Loading train:  11%|█         | 32/285 [00:36<04:17,  1.02s/it]Loading train:  12%|█▏        | 33/285 [00:37<04:14,  1.01s/it]Loading train:  12%|█▏        | 34/285 [00:39<04:21,  1.04s/it]Loading train:  12%|█▏        | 35/285 [00:40<04:19,  1.04s/it]Loading train:  13%|█▎        | 36/285 [00:40<04:09,  1.00s/it]Loading train:  13%|█▎        | 37/285 [00:42<04:16,  1.03s/it]Loading train:  13%|█▎        | 38/285 [00:43<04:14,  1.03s/it]Loading train:  14%|█▎        | 39/285 [00:43<03:59,  1.03it/s]Loading train:  14%|█▍        | 40/285 [00:45<04:11,  1.03s/it]Loading train:  14%|█▍        | 41/285 [00:46<04:04,  1.00s/it]Loading train:  15%|█▍        | 42/285 [00:46<03:50,  1.05it/s]Loading train:  15%|█▌        | 43/285 [00:47<04:02,  1.00s/it]Loading train:  15%|█▌        | 44/285 [00:49<04:06,  1.02s/it]Loading train:  16%|█▌        | 45/285 [00:50<04:48,  1.20s/it]Loading train:  16%|█▌        | 46/285 [00:51<04:42,  1.18s/it]Loading train:  16%|█▋        | 47/285 [00:52<04:23,  1.11s/it]Loading train:  17%|█▋        | 48/285 [00:53<04:27,  1.13s/it]Loading train:  17%|█▋        | 49/285 [00:55<04:31,  1.15s/it]Loading train:  18%|█▊        | 50/285 [00:56<04:14,  1.08s/it]Loading train:  18%|█▊        | 51/285 [00:57<04:17,  1.10s/it]Loading train:  18%|█▊        | 52/285 [00:58<03:58,  1.02s/it]Loading train:  19%|█▊        | 53/285 [00:58<03:47,  1.02it/s]Loading train:  19%|█▉        | 54/285 [00:59<03:49,  1.01it/s]Loading train:  19%|█▉        | 55/285 [01:00<03:43,  1.03it/s]Loading train:  20%|█▉        | 56/285 [01:01<03:49,  1.00s/it]Loading train:  20%|██        | 57/285 [01:02<03:38,  1.04it/s]Loading train:  20%|██        | 58/285 [01:03<03:36,  1.05it/s]Loading train:  21%|██        | 59/285 [01:04<03:39,  1.03it/s]Loading train:  21%|██        | 60/285 [01:05<03:38,  1.03it/s]Loading train:  21%|██▏       | 61/285 [01:06<03:26,  1.08it/s]Loading train:  22%|██▏       | 62/285 [01:07<03:20,  1.11it/s]Loading train:  22%|██▏       | 63/285 [01:08<03:15,  1.13it/s]Loading train:  22%|██▏       | 64/285 [01:09<03:39,  1.01it/s]Loading train:  23%|██▎       | 65/285 [01:11<04:18,  1.18s/it]Loading train:  23%|██▎       | 66/285 [01:12<04:38,  1.27s/it]Loading train:  24%|██▎       | 67/285 [01:13<04:18,  1.19s/it]Loading train:  24%|██▍       | 68/285 [01:14<04:01,  1.11s/it]Loading train:  24%|██▍       | 69/285 [01:15<03:52,  1.08s/it]Loading train:  25%|██▍       | 70/285 [01:16<03:41,  1.03s/it]Loading train:  25%|██▍       | 71/285 [01:17<03:41,  1.04s/it]Loading train:  25%|██▌       | 72/285 [01:18<03:31,  1.01it/s]Loading train:  26%|██▌       | 73/285 [01:19<03:25,  1.03it/s]Loading train:  26%|██▌       | 74/285 [01:20<03:24,  1.03it/s]Loading train:  26%|██▋       | 75/285 [01:21<03:26,  1.01it/s]Loading train:  27%|██▋       | 76/285 [01:22<03:21,  1.04it/s]Loading train:  27%|██▋       | 77/285 [01:22<03:11,  1.08it/s]Loading train:  27%|██▋       | 78/285 [01:24<03:18,  1.04it/s]Loading train:  28%|██▊       | 79/285 [01:25<03:19,  1.03it/s]Loading train:  28%|██▊       | 80/285 [01:25<03:16,  1.04it/s]Loading train:  28%|██▊       | 81/285 [01:26<03:15,  1.04it/s]Loading train:  29%|██▉       | 82/285 [01:27<03:19,  1.02it/s]Loading train:  29%|██▉       | 83/285 [01:28<03:10,  1.06it/s]Loading train:  29%|██▉       | 84/285 [01:29<03:00,  1.11it/s]Loading train:  30%|██▉       | 85/285 [01:30<03:05,  1.08it/s]Loading train:  30%|███       | 86/285 [01:31<03:16,  1.01it/s]Loading train:  31%|███       | 87/285 [01:32<03:18,  1.00s/it]Loading train:  31%|███       | 88/285 [01:33<03:21,  1.02s/it]Loading train:  31%|███       | 89/285 [01:34<03:19,  1.02s/it]Loading train:  32%|███▏      | 90/285 [01:35<03:16,  1.01s/it]Loading train:  32%|███▏      | 91/285 [01:36<03:05,  1.05it/s]Loading train:  32%|███▏      | 92/285 [01:37<03:11,  1.01it/s]Loading train:  33%|███▎      | 93/285 [01:38<03:07,  1.02it/s]Loading train:  33%|███▎      | 94/285 [01:39<03:18,  1.04s/it]Loading train:  33%|███▎      | 95/285 [01:40<03:15,  1.03s/it]Loading train:  34%|███▎      | 96/285 [01:41<03:10,  1.01s/it]Loading train:  34%|███▍      | 97/285 [01:42<03:10,  1.02s/it]Loading train:  34%|███▍      | 98/285 [01:43<03:07,  1.00s/it]Loading train:  35%|███▍      | 99/285 [01:44<03:08,  1.01s/it]Loading train:  35%|███▌      | 100/285 [01:45<03:05,  1.00s/it]Loading train:  35%|███▌      | 101/285 [01:46<02:59,  1.02it/s]Loading train:  36%|███▌      | 102/285 [01:47<03:00,  1.02it/s]Loading train:  36%|███▌      | 103/285 [01:48<02:59,  1.01it/s]Loading train:  36%|███▋      | 104/285 [01:49<03:04,  1.02s/it]Loading train:  37%|███▋      | 105/285 [01:50<03:10,  1.06s/it]Loading train:  37%|███▋      | 106/285 [01:51<03:06,  1.04s/it]Loading train:  38%|███▊      | 107/285 [01:53<03:06,  1.05s/it]Loading train:  38%|███▊      | 108/285 [01:53<02:55,  1.01it/s]Loading train:  38%|███▊      | 109/285 [01:54<02:51,  1.02it/s]Loading train:  39%|███▊      | 110/285 [01:55<02:55,  1.00s/it]Loading train:  39%|███▉      | 111/285 [01:56<02:44,  1.06it/s]Loading train:  39%|███▉      | 112/285 [01:57<02:48,  1.03it/s]Loading train:  40%|███▉      | 113/285 [01:58<02:52,  1.00s/it]Loading train:  40%|████      | 114/285 [01:59<02:48,  1.01it/s]Loading train:  40%|████      | 115/285 [02:00<02:57,  1.04s/it]Loading train:  41%|████      | 116/285 [02:02<02:57,  1.05s/it]Loading train:  41%|████      | 117/285 [02:03<02:56,  1.05s/it]Loading train:  41%|████▏     | 118/285 [02:04<02:49,  1.02s/it]Loading train:  42%|████▏     | 119/285 [02:05<02:47,  1.01s/it]Loading train:  42%|████▏     | 120/285 [02:05<02:42,  1.02it/s]Loading train:  42%|████▏     | 121/285 [02:07<03:01,  1.11s/it]Loading train:  43%|████▎     | 122/285 [02:08<03:05,  1.14s/it]Loading train:  43%|████▎     | 123/285 [02:09<03:09,  1.17s/it]Loading train:  44%|████▎     | 124/285 [02:10<02:58,  1.11s/it]Loading train:  44%|████▍     | 125/285 [02:11<02:50,  1.06s/it]Loading train:  44%|████▍     | 126/285 [02:12<02:42,  1.02s/it]Loading train:  45%|████▍     | 127/285 [02:13<02:37,  1.00it/s]Loading train:  45%|████▍     | 128/285 [02:14<02:35,  1.01it/s]Loading train:  45%|████▌     | 129/285 [02:15<02:32,  1.02it/s]Loading train:  46%|████▌     | 130/285 [02:16<02:26,  1.06it/s]Loading train:  46%|████▌     | 131/285 [02:17<02:14,  1.14it/s]Loading train:  46%|████▋     | 132/285 [02:17<02:12,  1.15it/s]Loading train:  47%|████▋     | 133/285 [02:18<02:13,  1.14it/s]Loading train:  47%|████▋     | 134/285 [02:19<02:11,  1.15it/s]Loading train:  47%|████▋     | 135/285 [02:20<02:03,  1.21it/s]Loading train:  48%|████▊     | 136/285 [02:21<02:02,  1.22it/s]Loading train:  48%|████▊     | 137/285 [02:22<02:09,  1.15it/s]Loading train:  48%|████▊     | 138/285 [02:23<02:07,  1.15it/s]Loading train:  49%|████▉     | 139/285 [02:24<02:10,  1.12it/s]Loading train:  49%|████▉     | 140/285 [02:24<02:11,  1.10it/s]Loading train:  49%|████▉     | 141/285 [02:25<02:08,  1.12it/s]Loading train:  50%|████▉     | 142/285 [02:26<02:03,  1.16it/s]Loading train:  50%|█████     | 143/285 [02:27<02:02,  1.16it/s]Loading train:  51%|█████     | 144/285 [02:28<02:08,  1.09it/s]Loading train:  51%|█████     | 145/285 [02:29<02:08,  1.09it/s]Loading train:  51%|█████     | 146/285 [02:30<02:11,  1.06it/s]Loading train:  52%|█████▏    | 147/285 [02:31<02:05,  1.10it/s]Loading train:  52%|█████▏    | 148/285 [02:32<02:07,  1.08it/s]Loading train:  52%|█████▏    | 149/285 [02:33<02:07,  1.07it/s]Loading train:  53%|█████▎    | 150/285 [02:34<02:02,  1.10it/s]Loading train:  53%|█████▎    | 151/285 [02:34<02:01,  1.11it/s]Loading train:  53%|█████▎    | 152/285 [02:35<01:57,  1.13it/s]Loading train:  54%|█████▎    | 153/285 [02:36<01:55,  1.14it/s]Loading train:  54%|█████▍    | 154/285 [02:37<01:57,  1.11it/s]Loading train:  54%|█████▍    | 155/285 [02:38<01:58,  1.10it/s]Loading train:  55%|█████▍    | 156/285 [02:39<02:02,  1.05it/s]Loading train:  55%|█████▌    | 157/285 [02:40<01:56,  1.10it/s]Loading train:  55%|█████▌    | 158/285 [02:41<01:58,  1.07it/s]Loading train:  56%|█████▌    | 159/285 [02:42<01:56,  1.08it/s]Loading train:  56%|█████▌    | 160/285 [02:43<01:53,  1.10it/s]Loading train:  56%|█████▋    | 161/285 [02:44<01:50,  1.12it/s]Loading train:  57%|█████▋    | 162/285 [02:44<01:43,  1.18it/s]Loading train:  57%|█████▋    | 163/285 [02:45<01:46,  1.15it/s]Loading train:  58%|█████▊    | 164/285 [02:46<01:44,  1.16it/s]Loading train:  58%|█████▊    | 165/285 [02:47<01:46,  1.12it/s]Loading train:  58%|█████▊    | 166/285 [02:48<01:49,  1.09it/s]Loading train:  59%|█████▊    | 167/285 [02:49<01:49,  1.07it/s]Loading train:  59%|█████▉    | 168/285 [02:50<01:44,  1.12it/s]Loading train:  59%|█████▉    | 169/285 [02:51<01:41,  1.15it/s]Loading train:  60%|█████▉    | 170/285 [02:51<01:42,  1.12it/s]Loading train:  60%|██████    | 171/285 [02:52<01:40,  1.14it/s]Loading train:  60%|██████    | 172/285 [02:53<01:36,  1.17it/s]Loading train:  61%|██████    | 173/285 [02:54<01:35,  1.18it/s]Loading train:  61%|██████    | 174/285 [02:55<01:32,  1.20it/s]Loading train:  61%|██████▏   | 175/285 [02:56<01:36,  1.14it/s]Loading train:  62%|██████▏   | 176/285 [02:57<01:36,  1.13it/s]Loading train:  62%|██████▏   | 177/285 [02:57<01:33,  1.15it/s]Loading train:  62%|██████▏   | 178/285 [02:58<01:30,  1.18it/s]Loading train:  63%|██████▎   | 179/285 [02:59<01:30,  1.17it/s]Loading train:  63%|██████▎   | 180/285 [03:00<01:37,  1.07it/s]Loading train:  64%|██████▎   | 181/285 [03:01<01:39,  1.04it/s]Loading train:  64%|██████▍   | 182/285 [03:02<01:38,  1.04it/s]Loading train:  64%|██████▍   | 183/285 [03:03<01:39,  1.03it/s]Loading train:  65%|██████▍   | 184/285 [03:04<01:33,  1.08it/s]Loading train:  65%|██████▍   | 185/285 [03:05<01:27,  1.14it/s]Loading train:  65%|██████▌   | 186/285 [03:06<01:35,  1.03it/s]Loading train:  66%|██████▌   | 187/285 [03:07<01:35,  1.03it/s]Loading train:  66%|██████▌   | 188/285 [03:08<01:34,  1.03it/s]Loading train:  66%|██████▋   | 189/285 [03:09<01:29,  1.08it/s]Loading train:  67%|██████▋   | 190/285 [03:10<01:27,  1.09it/s]Loading train:  67%|██████▋   | 191/285 [03:11<01:25,  1.10it/s]Loading train:  67%|██████▋   | 192/285 [03:11<01:22,  1.13it/s]Loading train:  68%|██████▊   | 193/285 [03:12<01:18,  1.17it/s]Loading train:  68%|██████▊   | 194/285 [03:13<01:17,  1.18it/s]Loading train:  68%|██████▊   | 195/285 [03:14<01:16,  1.18it/s]Loading train:  69%|██████▉   | 196/285 [03:15<01:19,  1.12it/s]Loading train:  69%|██████▉   | 197/285 [03:16<01:25,  1.03it/s]Loading train:  69%|██████▉   | 198/285 [03:17<01:28,  1.02s/it]Loading train:  70%|██████▉   | 199/285 [03:18<01:26,  1.01s/it]Loading train:  70%|███████   | 200/285 [03:19<01:22,  1.03it/s]Loading train:  71%|███████   | 201/285 [03:20<01:22,  1.02it/s]Loading train:  71%|███████   | 202/285 [03:21<01:22,  1.01it/s]Loading train:  71%|███████   | 203/285 [03:22<01:21,  1.00it/s]Loading train:  72%|███████▏  | 204/285 [03:23<01:17,  1.04it/s]Loading train:  72%|███████▏  | 205/285 [03:24<01:14,  1.07it/s]Loading train:  72%|███████▏  | 206/285 [03:25<01:09,  1.14it/s]Loading train:  73%|███████▎  | 207/285 [03:26<01:10,  1.10it/s]Loading train:  73%|███████▎  | 208/285 [03:27<01:14,  1.04it/s]Loading train:  73%|███████▎  | 209/285 [03:28<01:15,  1.01it/s]Loading train:  74%|███████▎  | 210/285 [03:28<01:10,  1.06it/s]Loading train:  74%|███████▍  | 211/285 [03:29<01:07,  1.10it/s]Loading train:  74%|███████▍  | 212/285 [03:30<01:07,  1.08it/s]Loading train:  75%|███████▍  | 213/285 [03:31<01:08,  1.05it/s]Loading train:  75%|███████▌  | 214/285 [03:32<01:08,  1.04it/s]Loading train:  75%|███████▌  | 215/285 [03:33<01:07,  1.04it/s]Loading train:  76%|███████▌  | 216/285 [03:34<01:03,  1.09it/s]Loading train:  76%|███████▌  | 217/285 [03:35<01:05,  1.04it/s]Loading train:  76%|███████▋  | 218/285 [03:36<01:04,  1.04it/s]Loading train:  77%|███████▋  | 219/285 [03:37<01:05,  1.00it/s]Loading train:  77%|███████▋  | 220/285 [03:38<01:00,  1.07it/s]Loading train:  78%|███████▊  | 221/285 [03:39<00:58,  1.08it/s]Loading train:  78%|███████▊  | 222/285 [03:40<01:02,  1.01it/s]Loading train:  78%|███████▊  | 223/285 [03:41<01:00,  1.02it/s]Loading train:  79%|███████▊  | 224/285 [03:42<01:00,  1.01it/s]Loading train:  79%|███████▉  | 225/285 [03:43<00:56,  1.06it/s]Loading train:  79%|███████▉  | 226/285 [03:44<00:57,  1.03it/s]Loading train:  80%|███████▉  | 227/285 [03:45<01:00,  1.04s/it]Loading train:  80%|████████  | 228/285 [03:46<01:00,  1.07s/it]Loading train:  80%|████████  | 229/285 [03:47<00:58,  1.04s/it]Loading train:  81%|████████  | 230/285 [03:48<00:53,  1.03it/s]Loading train:  81%|████████  | 231/285 [03:49<00:50,  1.06it/s]Loading train:  81%|████████▏ | 232/285 [03:50<00:50,  1.05it/s]Loading train:  82%|████████▏ | 233/285 [03:51<00:46,  1.11it/s]Loading train:  82%|████████▏ | 234/285 [03:52<00:49,  1.03it/s]Loading train:  82%|████████▏ | 235/285 [03:52<00:45,  1.10it/s]Loading train:  83%|████████▎ | 236/285 [03:54<00:48,  1.02it/s]Loading train:  83%|████████▎ | 237/285 [03:55<00:47,  1.02it/s]Loading train:  84%|████████▎ | 238/285 [03:56<00:46,  1.02it/s]Loading train:  84%|████████▍ | 239/285 [03:57<00:44,  1.03it/s]Loading train:  84%|████████▍ | 240/285 [03:57<00:41,  1.07it/s]Loading train:  85%|████████▍ | 241/285 [03:58<00:39,  1.12it/s]Loading train:  85%|████████▍ | 242/285 [03:59<00:38,  1.13it/s]Loading train:  85%|████████▌ | 243/285 [04:00<00:37,  1.11it/s]Loading train:  86%|████████▌ | 244/285 [04:01<00:38,  1.07it/s]Loading train:  86%|████████▌ | 245/285 [04:02<00:35,  1.14it/s]Loading train:  86%|████████▋ | 246/285 [04:03<00:35,  1.09it/s]Loading train:  87%|████████▋ | 247/285 [04:04<00:36,  1.05it/s]Loading train:  87%|████████▋ | 248/285 [04:05<00:33,  1.10it/s]Loading train:  87%|████████▋ | 249/285 [04:05<00:30,  1.17it/s]Loading train:  88%|████████▊ | 250/285 [04:06<00:32,  1.09it/s]Loading train:  88%|████████▊ | 251/285 [04:07<00:29,  1.16it/s]Loading train:  88%|████████▊ | 252/285 [04:08<00:28,  1.17it/s]Loading train:  89%|████████▉ | 253/285 [04:09<00:28,  1.11it/s]Loading train:  89%|████████▉ | 254/285 [04:10<00:29,  1.06it/s]Loading train:  89%|████████▉ | 255/285 [04:11<00:27,  1.08it/s]Loading train:  90%|████████▉ | 256/285 [04:12<00:25,  1.12it/s]Loading train:  90%|█████████ | 257/285 [04:12<00:23,  1.18it/s]Loading train:  91%|█████████ | 258/285 [04:13<00:24,  1.11it/s]Loading train:  91%|█████████ | 259/285 [04:14<00:24,  1.07it/s]Loading train:  91%|█████████ | 260/285 [04:15<00:22,  1.10it/s]Loading train:  92%|█████████▏| 261/285 [04:16<00:21,  1.13it/s]Loading train:  92%|█████████▏| 262/285 [04:17<00:20,  1.14it/s]Loading train:  92%|█████████▏| 263/285 [04:18<00:18,  1.17it/s]Loading train:  93%|█████████▎| 264/285 [04:19<00:19,  1.10it/s]Loading train:  93%|█████████▎| 265/285 [04:20<00:18,  1.06it/s]Loading train:  93%|█████████▎| 266/285 [04:21<00:16,  1.13it/s]Loading train:  94%|█████████▎| 267/285 [04:22<00:16,  1.11it/s]Loading train:  94%|█████████▍| 268/285 [04:23<00:16,  1.05it/s]Loading train:  94%|█████████▍| 269/285 [04:24<00:15,  1.04it/s]Loading train:  95%|█████████▍| 270/285 [04:24<00:13,  1.08it/s]Loading train:  95%|█████████▌| 271/285 [04:25<00:12,  1.09it/s]Loading train:  95%|█████████▌| 272/285 [04:26<00:12,  1.07it/s]Loading train:  96%|█████████▌| 273/285 [04:27<00:11,  1.09it/s]Loading train:  96%|█████████▌| 274/285 [04:28<00:09,  1.15it/s]Loading train:  96%|█████████▋| 275/285 [04:29<00:09,  1.08it/s]Loading train:  97%|█████████▋| 276/285 [04:30<00:08,  1.03it/s]Loading train:  97%|█████████▋| 277/285 [04:31<00:07,  1.09it/s]Loading train:  98%|█████████▊| 278/285 [04:32<00:06,  1.10it/s]Loading train:  98%|█████████▊| 279/285 [04:33<00:05,  1.10it/s]Loading train:  98%|█████████▊| 280/285 [04:34<00:04,  1.08it/s]Loading train:  99%|█████████▊| 281/285 [04:35<00:03,  1.09it/s]Loading train:  99%|█████████▉| 282/285 [04:35<00:02,  1.12it/s]Loading train:  99%|█████████▉| 283/285 [04:36<00:01,  1.09it/s]Loading train: 100%|█████████▉| 284/285 [04:37<00:00,  1.11it/s]Loading train: 100%|██████████| 285/285 [04:38<00:00,  1.06it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:04, 65.67it/s]concatenating: train:   6%|▋         | 18/285 [00:00<00:03, 74.70it/s]concatenating: train:  11%|█         | 31/285 [00:00<00:03, 83.65it/s]concatenating: train:  13%|█▎        | 38/285 [00:00<00:03, 73.09it/s]concatenating: train:  18%|█▊        | 51/285 [00:00<00:02, 83.42it/s]concatenating: train:  28%|██▊       | 79/285 [00:00<00:01, 105.32it/s]concatenating: train:  34%|███▎      | 96/285 [00:00<00:01, 118.64it/s]concatenating: train:  42%|████▏     | 120/285 [00:00<00:01, 139.56it/s]concatenating: train:  52%|█████▏    | 149/285 [00:00<00:00, 164.48it/s]concatenating: train:  65%|██████▍   | 184/285 [00:01<00:00, 195.04it/s]concatenating: train:  77%|███████▋  | 220/285 [00:01<00:00, 225.94it/s]concatenating: train:  89%|████████▉ | 255/285 [00:01<00:00, 251.97it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 212.90it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.27s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.24s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.19s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 45.90it/s]2019-07-11 02:39:56.932173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 02:39:56.932302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 02:39:56.932320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 02:39:56.932328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 02:39:56.932766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  4.91it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.81it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.70it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.35it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.47it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.25it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  6.40it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.36it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.02it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.22it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  9.01it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.26it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.60it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.46it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.17it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.20it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.38it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.36it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.65it/s]      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 26, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 26, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 26, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 26, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 13, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 13, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 13, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 20, 13, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 40, 26, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 40, 26, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 40, 26, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 80, 52, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 80, 52, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 52, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 80, 52, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 40)   21640       dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 40)   160         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 40)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 80, 52, 40)   0           activation_11[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 100)  0           dropout_5[0][0]                  
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 13)   1313        concatenate_7[0][0]              
==================================================================================================
Total params: 246,153
Trainable params: 71,393
Non-trainable params: 174,760
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 16s - loss: 2.4183 - acc: 0.6292 - mDice: 0.1580 - val_loss: 3.1462 - val_acc: 0.9036 - val_mDice: 0.1426

Epoch 00001: val_mDice improved from -inf to 0.14265, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 11s - loss: 0.8070 - acc: 0.8877 - mDice: 0.4351 - val_loss: 1.1842 - val_acc: 0.9148 - val_mDice: 0.3957

Epoch 00002: val_mDice improved from 0.14265 to 0.39571, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 11s - loss: 0.6311 - acc: 0.8969 - mDice: 0.5165 - val_loss: 0.8888 - val_acc: 0.9316 - val_mDice: 0.5034

Epoch 00003: val_mDice improved from 0.39571 to 0.50343, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 11s - loss: 0.5471 - acc: 0.9140 - mDice: 0.5627 - val_loss: 0.8550 - val_acc: 0.9398 - val_mDice: 0.5244

Epoch 00004: val_mDice improved from 0.50343 to 0.52439, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 11s - loss: 0.5009 - acc: 0.9287 - mDice: 0.5895 - val_loss: 0.8231 - val_acc: 0.9352 - val_mDice: 0.5340

Epoch 00005: val_mDice improved from 0.52439 to 0.53404, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 11s - loss: 0.4735 - acc: 0.9320 - mDice: 0.6069 - val_loss: 0.8059 - val_acc: 0.9355 - val_mDice: 0.5499

Epoch 00006: val_mDice improved from 0.53404 to 0.54992, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 11s - loss: 0.4492 - acc: 0.9342 - mDice: 0.6223 - val_loss: 0.8224 - val_acc: 0.9359 - val_mDice: 0.5367

Epoch 00007: val_mDice did not improve from 0.54992
Epoch 8/300
 - 11s - loss: 0.4346 - acc: 0.9356 - mDice: 0.6317 - val_loss: 0.8135 - val_acc: 0.9397 - val_mDice: 0.5546

Epoch 00008: val_mDice improved from 0.54992 to 0.55457, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 10s - loss: 0.4173 - acc: 0.9370 - mDice: 0.6434 - val_loss: 0.8149 - val_acc: 0.9359 - val_mDice: 0.5443

Epoch 00009: val_mDice did not improve from 0.55457
Epoch 10/300
 - 11s - loss: 0.4075 - acc: 0.9378 - mDice: 0.6498 - val_loss: 0.8217 - val_acc: 0.9380 - val_mDice: 0.5466

Epoch 00010: val_mDice did not improve from 0.55457
Epoch 11/300
 - 11s - loss: 0.3979 - acc: 0.9387 - mDice: 0.6563 - val_loss: 0.8161 - val_acc: 0.9396 - val_mDice: 0.5532

Epoch 00011: val_mDice did not improve from 0.55457
Epoch 12/300
 - 10s - loss: 0.3883 - acc: 0.9394 - mDice: 0.6627 - val_loss: 0.7788 - val_acc: 0.9383 - val_mDice: 0.5620

Epoch 00012: val_mDice improved from 0.55457 to 0.56195, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 11s - loss: 0.3816 - acc: 0.9401 - mDice: 0.6676 - val_loss: 0.7974 - val_acc: 0.9377 - val_mDice: 0.5583

Epoch 00013: val_mDice did not improve from 0.56195
Epoch 14/300
 - 11s - loss: 0.3739 - acc: 0.9407 - mDice: 0.6727 - val_loss: 0.8408 - val_acc: 0.9417 - val_mDice: 0.5471

Epoch 00014: val_mDice did not improve from 0.56195
Epoch 15/300
 - 11s - loss: 0.3673 - acc: 0.9413 - mDice: 0.6775 - val_loss: 0.8002 - val_acc: 0.9383 - val_mDice: 0.5646

Epoch 00015: val_mDice improved from 0.56195 to 0.56458, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 11s - loss: 0.3647 - acc: 0.9414 - mDice: 0.6793 - val_loss: 0.9496 - val_acc: 0.9332 - val_mDice: 0.4925

Epoch 00016: val_mDice did not improve from 0.56458
Epoch 17/300
 - 11s - loss: 0.3600 - acc: 0.9420 - mDice: 0.6826 - val_loss: 0.8083 - val_acc: 0.9328 - val_mDice: 0.5480

Epoch 00017: val_mDice did not improve from 0.56458
Epoch 18/300
 - 11s - loss: 0.3547 - acc: 0.9422 - mDice: 0.6864 - val_loss: 0.8452 - val_acc: 0.9405 - val_mDice: 0.5502

Epoch 00018: val_mDice did not improve from 0.56458
Epoch 19/300
 - 11s - loss: 0.3508 - acc: 0.9426 - mDice: 0.6891 - val_loss: 0.8320 - val_acc: 0.9439 - val_mDice: 0.5564

Epoch 00019: val_mDice did not improve from 0.56458
Epoch 20/300
 - 11s - loss: 0.3479 - acc: 0.9428 - mDice: 0.6914 - val_loss: 0.8191 - val_acc: 0.9360 - val_mDice: 0.5549

Epoch 00020: val_mDice did not improve from 0.56458
Epoch 21/300
 - 11s - loss: 0.3429 - acc: 0.9432 - mDice: 0.6948 - val_loss: 0.8054 - val_acc: 0.9402 - val_mDice: 0.5671

Epoch 00021: val_mDice improved from 0.56458 to 0.56706, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 22/300
 - 11s - loss: 0.3412 - acc: 0.9434 - mDice: 0.6962 - val_loss: 0.8221 - val_acc: 0.9402 - val_mDice: 0.5545

Epoch 00022: val_mDice did not improve from 0.56706
Epoch 23/300
 - 11s - loss: 0.3367 - acc: 0.9438 - mDice: 0.6994 - val_loss: 0.8273 - val_acc: 0.9407 - val_mDice: 0.5606

Epoch 00023: val_mDice did not improve from 0.56706
Epoch 24/300
 - 11s - loss: 0.3319 - acc: 0.9440 - mDice: 0.7028 - val_loss: 0.8158 - val_acc: 0.9427 - val_mDice: 0.5676

Epoch 00024: val_mDice improved from 0.56706 to 0.56764, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 25/300
 - 11s - loss: 0.3296 - acc: 0.9443 - mDice: 0.7046 - val_loss: 0.8727 - val_acc: 0.9345 - val_mDice: 0.5322

Epoch 00025: val_mDice did not improve from 0.56764
Epoch 26/300
 - 11s - loss: 0.3281 - acc: 0.9443 - mDice: 0.7057 - val_loss: 0.8420 - val_acc: 0.9370 - val_mDice: 0.5487

Epoch 00026: val_mDice did not improve from 0.56764
Epoch 27/300
 - 11s - loss: 0.3253 - acc: 0.9445 - mDice: 0.7078 - val_loss: 0.8998 - val_acc: 0.9357 - val_mDice: 0.5220

Epoch 00027: val_mDice did not improve from 0.56764
Epoch 28/300
 - 11s - loss: 0.3254 - acc: 0.9447 - mDice: 0.7076 - val_loss: 0.8249 - val_acc: 0.9407 - val_mDice: 0.5603

Epoch 00028: val_mDice did not improve from 0.56764
Epoch 29/300
 - 11s - loss: 0.3205 - acc: 0.9450 - mDice: 0.7113 - val_loss: 0.8095 - val_acc: 0.9409 - val_mDice: 0.5724

Epoch 00029: val_mDice improved from 0.56764 to 0.57235, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 30/300
 - 11s - loss: 0.3196 - acc: 0.9451 - mDice: 0.7121 - val_loss: 0.8352 - val_acc: 0.9391 - val_mDice: 0.5587

Epoch 00030: val_mDice did not improve from 0.57235
Epoch 31/300
 - 10s - loss: 0.3185 - acc: 0.9452 - mDice: 0.7129 - val_loss: 0.8492 - val_acc: 0.9406 - val_mDice: 0.5557

Epoch 00031: val_mDice did not improve from 0.57235
Epoch 32/300
 - 11s - loss: 0.3150 - acc: 0.9455 - mDice: 0.7155 - val_loss: 0.8358 - val_acc: 0.9390 - val_mDice: 0.5611

Epoch 00032: val_mDice did not improve from 0.57235
Epoch 33/300
 - 11s - loss: 0.3134 - acc: 0.9455 - mDice: 0.7166 - val_loss: 0.8355 - val_acc: 0.9384 - val_mDice: 0.5530

Epoch 00033: val_mDice did not improve from 0.57235
Epoch 34/300
 - 11s - loss: 0.3117 - acc: 0.9457 - mDice: 0.7179 - val_loss: 0.8120 - val_acc: 0.9418 - val_mDice: 0.5613

Epoch 00034: val_mDice did not improve from 0.57235
Epoch 35/300
 - 11s - loss: 0.3098 - acc: 0.9458 - mDice: 0.7193 - val_loss: 0.7976 - val_acc: 0.9406 - val_mDice: 0.5653

Epoch 00035: val_mDice did not improve from 0.57235
Epoch 36/300
 - 11s - loss: 0.3088 - acc: 0.9459 - mDice: 0.7200 - val_loss: 0.8469 - val_acc: 0.9357 - val_mDice: 0.5423

Epoch 00036: val_mDice did not improve from 0.57235
Epoch 37/300
 - 11s - loss: 0.3062 - acc: 0.9462 - mDice: 0.7220 - val_loss: 0.8314 - val_acc: 0.9408 - val_mDice: 0.5621

Epoch 00037: val_mDice did not improve from 0.57235
Epoch 38/300
 - 11s - loss: 0.3050 - acc: 0.9462 - mDice: 0.7232 - val_loss: 0.8347 - val_acc: 0.9411 - val_mDice: 0.5640

Epoch 00038: val_mDice did not improve from 0.57235
Epoch 39/300
 - 10s - loss: 0.3037 - acc: 0.9464 - mDice: 0.7239 - val_loss: 0.7778 - val_acc: 0.9406 - val_mDice: 0.5693

Epoch 00039: val_mDice did not improve from 0.57235
Epoch 40/300
 - 10s - loss: 0.3011 - acc: 0.9465 - mDice: 0.7258 - val_loss: 0.7990 - val_acc: 0.9396 - val_mDice: 0.5535

Epoch 00040: val_mDice did not improve from 0.57235
Epoch 41/300
 - 10s - loss: 0.2991 - acc: 0.9466 - mDice: 0.7273 - val_loss: 0.7834 - val_acc: 0.9437 - val_mDice: 0.5726

Epoch 00041: val_mDice improved from 0.57235 to 0.57260, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 42/300
 - 11s - loss: 0.2988 - acc: 0.9466 - mDice: 0.7276 - val_loss: 0.7682 - val_acc: 0.9394 - val_mDice: 0.5716

Epoch 00042: val_mDice did not improve from 0.57260
Epoch 43/300
 - 11s - loss: 0.2971 - acc: 0.9468 - mDice: 0.7289 - val_loss: 0.8120 - val_acc: 0.9402 - val_mDice: 0.5619

Epoch 00043: val_mDice did not improve from 0.57260
Epoch 44/300
 - 11s - loss: 0.2970 - acc: 0.9469 - mDice: 0.7290 - val_loss: 0.8022 - val_acc: 0.9395 - val_mDice: 0.5628

Epoch 00044: val_mDice did not improve from 0.57260
Epoch 45/300
 - 11s - loss: 0.2950 - acc: 0.9470 - mDice: 0.7305 - val_loss: 0.8209 - val_acc: 0.9412 - val_mDice: 0.5617

Epoch 00045: val_mDice did not improve from 0.57260
Epoch 46/300
 - 11s - loss: 0.2942 - acc: 0.9470 - mDice: 0.7311 - val_loss: 0.7733 - val_acc: 0.9382 - val_mDice: 0.5705

Epoch 00046: val_mDice did not improve from 0.57260
Epoch 47/300
 - 11s - loss: 0.2921 - acc: 0.9471 - mDice: 0.7327 - val_loss: 0.7803 - val_acc: 0.9422 - val_mDice: 0.5659

Epoch 00047: val_mDice did not improve from 0.57260
Epoch 48/300
 - 10s - loss: 0.2914 - acc: 0.9472 - mDice: 0.7333 - val_loss: 0.7775 - val_acc: 0.9390 - val_mDice: 0.5676

Epoch 00048: val_mDice did not improve from 0.57260
Epoch 49/300
 - 10s - loss: 0.2893 - acc: 0.9475 - mDice: 0.7348 - val_loss: 0.7954 - val_acc: 0.9422 - val_mDice: 0.5709

Epoch 00049: val_mDice did not improve from 0.57260
Epoch 50/300
 - 11s - loss: 0.2903 - acc: 0.9474 - mDice: 0.7340 - val_loss: 0.7969 - val_acc: 0.9397 - val_mDice: 0.5644

Epoch 00050: val_mDice did not improve from 0.57260
Epoch 51/300
 - 11s - loss: 0.2889 - acc: 0.9476 - mDice: 0.7352 - val_loss: 0.7639 - val_acc: 0.9418 - val_mDice: 0.5663

Epoch 00051: val_mDice did not improve from 0.57260
Epoch 52/300
 - 11s - loss: 0.2866 - acc: 0.9476 - mDice: 0.7370 - val_loss: 0.7419 - val_acc: 0.9364 - val_mDice: 0.5729

Epoch 00052: val_mDice improved from 0.57260 to 0.57292, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 53/300
 - 11s - loss: 0.2855 - acc: 0.9477 - mDice: 0.7378 - val_loss: 0.8035 - val_acc: 0.9399 - val_mDice: 0.5678

Epoch 00053: val_mDice did not improve from 0.57292
Epoch 54/300
 - 11s - loss: 0.2852 - acc: 0.9478 - mDice: 0.7381 - val_loss: 0.8043 - val_acc: 0.9397 - val_mDice: 0.5664

Epoch 00054: val_mDice did not improve from 0.57292
Epoch 55/300
 - 11s - loss: 0.2844 - acc: 0.9477 - mDice: 0.7386 - val_loss: 0.7936 - val_acc: 0.9411 - val_mDice: 0.5518

Epoch 00055: val_mDice did not improve from 0.57292
Epoch 56/300
 - 11s - loss: 0.2847 - acc: 0.9478 - mDice: 0.7384 - val_loss: 0.7536 - val_acc: 0.9413 - val_mDice: 0.5777

Epoch 00056: val_mDice improved from 0.57292 to 0.57765, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 57/300
 - 11s - loss: 0.2832 - acc: 0.9479 - mDice: 0.7396 - val_loss: 0.7821 - val_acc: 0.9372 - val_mDice: 0.5645

Epoch 00057: val_mDice did not improve from 0.57765
Epoch 58/300
 - 11s - loss: 0.2808 - acc: 0.9480 - mDice: 0.7415 - val_loss: 0.8111 - val_acc: 0.9421 - val_mDice: 0.5577

Epoch 00058: val_mDice did not improve from 0.57765
Epoch 59/300
 - 11s - loss: 0.2812 - acc: 0.9480 - mDice: 0.7412 - val_loss: 0.7675 - val_acc: 0.9388 - val_mDice: 0.5712

Epoch 00059: val_mDice did not improve from 0.57765
Epoch 60/300
 - 11s - loss: 0.2823 - acc: 0.9480 - mDice: 0.7402 - val_loss: 0.7890 - val_acc: 0.9406 - val_mDice: 0.5589

Epoch 00060: val_mDice did not improve from 0.57765
Epoch 61/300
 - 11s - loss: 0.2783 - acc: 0.9482 - mDice: 0.7434 - val_loss: 0.7981 - val_acc: 0.9385 - val_mDice: 0.5634

Epoch 00061: val_mDice did not improve from 0.57765
Epoch 62/300
 - 11s - loss: 0.2777 - acc: 0.9484 - mDice: 0.7439 - val_loss: 0.7896 - val_acc: 0.9352 - val_mDice: 0.5661

Epoch 00062: val_mDice did not improve from 0.57765
Epoch 63/300
 - 11s - loss: 0.2773 - acc: 0.9485 - mDice: 0.7442 - val_loss: 0.7435 - val_acc: 0.9406 - val_mDice: 0.5573

Epoch 00063: val_mDice did not improve from 0.57765
Epoch 64/300
 - 11s - loss: 0.2760 - acc: 0.9484 - mDice: 0.7452 - val_loss: 0.8117 - val_acc: 0.9299 - val_mDice: 0.5414

Epoch 00064: val_mDice did not improve from 0.57765
Epoch 65/300
 - 11s - loss: 0.2763 - acc: 0.9483 - mDice: 0.7449 - val_loss: 0.8076 - val_acc: 0.9374 - val_mDice: 0.5602

Epoch 00065: val_mDice did not improve from 0.57765
Epoch 66/300
 - 11s - loss: 0.2750 - acc: 0.9485 - mDice: 0.7459 - val_loss: 0.7795 - val_acc: 0.9392 - val_mDice: 0.5641

Epoch 00066: val_mDice did not improve from 0.57765
Epoch 67/300
 - 11s - loss: 0.2747 - acc: 0.9486 - mDice: 0.7462 - val_loss: 0.7918 - val_acc: 0.9413 - val_mDice: 0.5534

Epoch 00067: val_mDice did not improve from 0.57765
Epoch 68/300
 - 11s - loss: 0.2740 - acc: 0.9486 - mDice: 0.7467 - val_loss: 0.7797 - val_acc: 0.9290 - val_mDice: 0.5520

Epoch 00068: val_mDice did not improve from 0.57765
Epoch 69/300
 - 11s - loss: 0.2745 - acc: 0.9485 - mDice: 0.7464 - val_loss: 0.7658 - val_acc: 0.9367 - val_mDice: 0.5649

Epoch 00069: val_mDice did not improve from 0.57765
Epoch 70/300
 - 11s - loss: 0.2731 - acc: 0.9487 - mDice: 0.7474 - val_loss: 0.7253 - val_acc: 0.9410 - val_mDice: 0.5748

Epoch 00070: val_mDice did not improve from 0.57765
Epoch 71/300
 - 11s - loss: 0.2721 - acc: 0.9488 - mDice: 0.7482 - val_loss: 0.7788 - val_acc: 0.9419 - val_mDice: 0.5536

Epoch 00071: val_mDice did not improve from 0.57765
Epoch 72/300
 - 11s - loss: 0.2703 - acc: 0.9490 - mDice: 0.7496 - val_loss: 0.7435 - val_acc: 0.9413 - val_mDice: 0.5646

Epoch 00072: val_mDice did not improve from 0.57765
Epoch 73/300
 - 12s - loss: 0.2710 - acc: 0.9488 - mDice: 0.7491 - val_loss: 0.7468 - val_acc: 0.9347 - val_mDice: 0.5649

Epoch 00073: val_mDice did not improve from 0.57765
Epoch 74/300
 - 11s - loss: 0.2693 - acc: 0.9489 - mDice: 0.7504 - val_loss: 0.7827 - val_acc: 0.9437 - val_mDice: 0.5449

Epoch 00074: val_mDice did not improve from 0.57765
Epoch 75/300
 - 11s - loss: 0.2700 - acc: 0.9489 - mDice: 0.7498 - val_loss: 0.7427 - val_acc: 0.9421 - val_mDice: 0.5548

Epoch 00075: val_mDice did not improve from 0.57765
Epoch 76/300
 - 12s - loss: 0.2684 - acc: 0.9490 - mDice: 0.7511 - val_loss: 0.7365 - val_acc: 0.9376 - val_mDice: 0.5679

Epoch 00076: val_mDice did not improve from 0.57765
Epoch 77/300
 - 11s - loss: 0.2688 - acc: 0.9490 - mDice: 0.7508 - val_loss: 0.7545 - val_acc: 0.9375 - val_mDice: 0.5595

Epoch 00077: val_mDice did not improve from 0.57765
Epoch 78/300
 - 11s - loss: 0.2686 - acc: 0.9491 - mDice: 0.7510 - val_loss: 0.8589 - val_acc: 0.9340 - val_mDice: 0.5304

Epoch 00078: val_mDice did not improve from 0.57765
Epoch 79/300
 - 11s - loss: 0.2669 - acc: 0.9492 - mDice: 0.7523 - val_loss: 0.7211 - val_acc: 0.9381 - val_mDice: 0.5695

Epoch 00079: val_mDice did not improve from 0.57765
Epoch 80/300
 - 11s - loss: 0.2662 - acc: 0.9492 - mDice: 0.7529 - val_loss: 0.7384 - val_acc: 0.9401 - val_mDice: 0.5636

Epoch 00080: val_mDice did not improve from 0.57765
Epoch 81/300
 - 11s - loss: 0.2675 - acc: 0.9491 - mDice: 0.7519 - val_loss: 0.7624 - val_acc: 0.9391 - val_mDice: 0.5620

Epoch 00081: val_mDice did not improve from 0.57765
Epoch 82/300
 - 11s - loss: 0.2654 - acc: 0.9493 - mDice: 0.7535 - val_loss: 0.6973 - val_acc: 0.9411 - val_mDice: 0.5701

Epoch 00082: val_mDice did not improve from 0.57765
Epoch 83/300
 - 11s - loss: 0.2649 - acc: 0.9493 - mDice: 0.7539 - val_loss: 0.7389 - val_acc: 0.9374 - val_mDice: 0.5599

Epoch 00083: val_mDice did not improve from 0.57765
Epoch 84/300
 - 11s - loss: 0.2643 - acc: 0.9494 - mDice: 0.7543 - val_loss: 0.7807 - val_acc: 0.9380 - val_mDice: 0.5552

Epoch 00084: val_mDice did not improve from 0.57765
Epoch 85/300
 - 11s - loss: 0.2644 - acc: 0.9493 - mDice: 0.7543 - val_loss: 0.7342 - val_acc: 0.9400 - val_mDice: 0.5683

Epoch 00085: val_mDice did not improve from 0.57765
Epoch 86/300
 - 11s - loss: 0.2636 - acc: 0.9495 - mDice: 0.7549 - val_loss: 0.7936 - val_acc: 0.9393 - val_mDice: 0.5580

Epoch 00086: val_mDice did not improve from 0.57765
Epoch 87/300
 - 11s - loss: 0.2646 - acc: 0.9495 - mDice: 0.7543 - val_loss: 0.7230 - val_acc: 0.9418 - val_mDice: 0.5700

Epoch 00087: val_mDice did not improve from 0.57765
Epoch 88/300
 - 11s - loss: 0.2631 - acc: 0.9494 - mDice: 0.7553 - val_loss: 0.7225 - val_acc: 0.9403 - val_mDice: 0.5658

Epoch 00088: val_mDice did not improve from 0.57765
Epoch 89/300
 - 11s - loss: 0.2625 - acc: 0.9495 - mDice: 0.7558 - val_loss: 0.7765 - val_acc: 0.9413 - val_mDice: 0.5574

Epoch 00089: val_mDice did not improve from 0.57765
Epoch 90/300
 - 11s - loss: 0.2623 - acc: 0.9495 - mDice: 0.7560 - val_loss: 0.7365 - val_acc: 0.9405 - val_mDice: 0.5634

Epoch 00090: val_mDice did not improve from 0.57765
Epoch 91/300
 - 11s - loss: 0.2605 - acc: 0.9497 - mDice: 0.7574 - val_loss: 0.7255 - val_acc: 0.9404 - val_mDice: 0.5594

Epoch 00091: val_mDice did not improve from 0.57765
Epoch 92/300
 - 11s - loss: 0.2605 - acc: 0.9496 - mDice: 0.7574 - val_loss: 0.7115 - val_acc: 0.9411 - val_mDice: 0.5713

Epoch 00092: val_mDice did not improve from 0.57765
Epoch 93/300
 - 11s - loss: 0.2609 - acc: 0.9497 - mDice: 0.7572 - val_loss: 0.6679 - val_acc: 0.9402 - val_mDice: 0.5772

Epoch 00093: val_mDice did not improve from 0.57765
Epoch 94/300
 - 11s - loss: 0.2608 - acc: 0.9497 - mDice: 0.7571 - val_loss: 0.6720 - val_acc: 0.9380 - val_mDice: 0.5727

Epoch 00094: val_mDice did not improve from 0.57765
Epoch 95/300
 - 11s - loss: 0.2596 - acc: 0.9497 - mDice: 0.7580 - val_loss: 0.7336 - val_acc: 0.9386 - val_mDice: 0.5546

Epoch 00095: val_mDice did not improve from 0.57765
Epoch 96/300
 - 11s - loss: 0.2594 - acc: 0.9498 - mDice: 0.7582 - val_loss: 0.7000 - val_acc: 0.9382 - val_mDice: 0.5593

Epoch 00096: val_mDice did not improve from 0.57765
Restoring model weights from the end of the best epoch
Epoch 00096: early stopping
{'val_loss': [3.1462038847116323, 1.1841655373573303, 0.8888253707152146, 0.8550351949838492, 0.8231480167462275, 0.8058649347378657, 0.822387172625615, 0.8135277835222391, 0.8149349024662604, 0.821716138949761, 0.8161418575506943, 0.7788211451126978, 0.7973904242882361, 0.8408075479360727, 0.8001940846443176, 0.9495711349523984, 0.8083444421107953, 0.8452452008540814, 0.8320231139659882, 0.819131498153393, 0.8053856377418225, 0.8220753096617185, 0.8273072907557855, 0.8157791151450231, 0.8727008608671335, 0.8420079098297999, 0.8997815457674173, 0.8249143981016599, 0.8095145087975723, 0.8351973088888022, 0.8492094484659342, 0.8357883233290452, 0.8355227823440845, 0.8119846353164086, 0.7976479094762069, 0.8468913435935974, 0.831359109053245, 0.8346736843769367, 0.7778457747055934, 0.7990324726471534, 0.7833823171945719, 0.768243704850857, 0.8119969482605274, 0.8021891254645127, 0.820933481821647, 0.7733014959555405, 0.7803454651282384, 0.7775345719777621, 0.7953920777027423, 0.7968978262864627, 0.7639416914719802, 0.7419187678740575, 0.8034545137332036, 0.8043025548641498, 0.79361659517655, 0.7536443620920181, 0.7820786123092358, 0.811087211737266, 0.7674601123883174, 0.7889788884382981, 0.7980743990494654, 0.7895549031404349, 0.7435342096365415, 0.811656470482166, 0.8075781464576721, 0.7794565673057849, 0.7917844286331763, 0.7797104120254517, 0.7658332059016595, 0.7253141953394964, 0.7787914276123047, 0.7434665216849401, 0.746762569134052, 0.7827348342308631, 0.7426777482032776, 0.7364641588467818, 0.7545438500551077, 0.8589412317826197, 0.7211360083176539, 0.7383826031134679, 0.7623561001740969, 0.6972728623793676, 0.7389246064883012, 0.7806643522702731, 0.7341735729804406, 0.7936234244933495, 0.7230016199442056, 0.72245615033003, 0.7764711953126467, 0.7365428988750164, 0.7255002902104304, 0.7115375995635986, 0.6678635947979413, 0.6719523049317874, 0.7336037319440109, 0.7000145407823416], 'val_acc': [0.903647379233287, 0.914760566674746, 0.9316128606979663, 0.9398414240433619, 0.9352209453399365, 0.9355168067491971, 0.9359167218208313, 0.9397397614442385, 0.9358912477126489, 0.9380339269454663, 0.939570997770016, 0.9382743399876815, 0.937728803891402, 0.9416974874643179, 0.9382812724663661, 0.93323088150758, 0.9327685718352978, 0.940465496136592, 0.9438586280896113, 0.9359628970806415, 0.9401581035210536, 0.9402228341652796, 0.9407498034147116, 0.9427375953931075, 0.9344767171602982, 0.9369521920497601, 0.9356739933674152, 0.9406573382707742, 0.9408838588457841, 0.9391341713758615, 0.940562578348013, 0.9390417085244105, 0.9383621628467853, 0.9417853240783398, 0.9405995928324186, 0.9356578084138724, 0.9407821503969339, 0.941071120592264, 0.9405949322076944, 0.9396449671341822, 0.9437361588844886, 0.9394230888440058, 0.9401627022486466, 0.9394508348061488, 0.9411542988740481, 0.9381980231175056, 0.9422314304571885, 0.9390209133808429, 0.9421805854027088, 0.9397489543144519, 0.9418338674765366, 0.9364390785877521, 0.9398529896369348, 0.939656518972837, 0.9411381414303412, 0.9412952844913189, 0.9371625597660358, 0.9420812015350049, 0.9387666193338541, 0.9405811062225928, 0.9384569273545191, 0.9351631999015808, 0.9406365293722886, 0.9299209347138038, 0.9373913613649515, 0.9391803535131308, 0.9413045713534722, 0.9290102766110346, 0.9367256921071273, 0.9410479825276595, 0.9418846873136667, 0.9413368999958038, 0.9346685363696172, 0.9436714190703172, 0.9421458840370178, 0.9376317446048443, 0.9375370053144602, 0.9339728080309354, 0.9381171258596274, 0.9401257404914269, 0.9390602111816406, 0.9410710839124826, 0.9373751741189223, 0.9380478194126716, 0.9400101418678577, 0.9392728209495544, 0.9417737699471987, 0.940347650876412, 0.9413230648407569, 0.9404747715363135, 0.9403614883239453, 0.9410572533424084, 0.9401557926948254, 0.9380362354792081, 0.9385909759081327, 0.9381564442928021], 'val_mDice': [0.1426497927078834, 0.395713026706989, 0.5034283777842155, 0.5243922689786324, 0.534036384179042, 0.549918131186412, 0.5367366327689245, 0.5545721839253719, 0.5442796005652502, 0.546587854050673, 0.553154435295325, 0.561951628098121, 0.5583195818158296, 0.5471234149657763, 0.5645807454219232, 0.4924696809970416, 0.5479953403656299, 0.5502153824155147, 0.5563810943410947, 0.5549334734678268, 0.5670579683322173, 0.5544756375826322, 0.5606366716898404, 0.5676360840980823, 0.5321814509538504, 0.548712283372879, 0.5220255129612409, 0.5603177364055927, 0.5723531303497461, 0.5586596079743825, 0.5557463736488268, 0.5611138636103044, 0.5530470970731515, 0.5612648897446119, 0.5653152603369492, 0.5422665247550378, 0.562091273184006, 0.5639842576705493, 0.569280546445113, 0.5535372083003705, 0.5726046161009715, 0.5716436470930393, 0.5618508526912103, 0.5628045797348022, 0.5617393295352275, 0.5705242678523064, 0.5658937090864549, 0.5675638088813195, 0.5708888304921297, 0.56439759181096, 0.5662891589678251, 0.5729182884097099, 0.5677860425068781, 0.5663688882039144, 0.5518377343049417, 0.5776547927122849, 0.5644642206338736, 0.5576790215877386, 0.5711646171716543, 0.5588877739814612, 0.5634489993636425, 0.5661491602659225, 0.5572576843775235, 0.5414189965679095, 0.5602012116175431, 0.5640649967468702, 0.5534343524621084, 0.5520019044096653, 0.5648756313782471, 0.5747721676643078, 0.5536426747074494, 0.5646353937112368, 0.5649092220343076, 0.5449202335797824, 0.5547658548905299, 0.567861930682109, 0.5595474346325948, 0.5303912265942647, 0.569471711722704, 0.5635891086780108, 0.5619639616746169, 0.5701155565105952, 0.5599218435012377, 0.555223808838771, 0.5683471766801981, 0.5579562588379934, 0.5700010657310486, 0.565822877562963, 0.5574019041198951, 0.5634292152065498, 0.5594077144677823, 0.5713116859014218, 0.5771888798246017, 0.5726799884667764, 0.5545924523702035, 0.5593212539186845], 'loss': [2.418271680220372, 0.8069737040500716, 0.6311429990379065, 0.547114874019753, 0.5009250041689367, 0.47351915337146017, 0.4491583412009984, 0.43457792080230384, 0.41725321178241465, 0.40750422626857463, 0.3978968121727751, 0.38834092152093397, 0.38160555773112076, 0.3739243747920202, 0.3673290831322799, 0.3647128190791311, 0.36002456111177067, 0.35468141584667695, 0.3507674367271929, 0.34786237580721463, 0.34293278433636065, 0.3411719744593348, 0.33670483319167666, 0.331949349447094, 0.3296189194404803, 0.32805269990395675, 0.325339579985149, 0.3254311328432079, 0.3205178906053874, 0.3195800800682115, 0.3184502649013708, 0.31500578442535027, 0.3133898328549636, 0.3117382007612466, 0.3098373151205897, 0.3088340429591042, 0.30623843398226547, 0.30497107525148, 0.303731576873952, 0.3010954207229755, 0.29913520723111314, 0.2987812403343837, 0.29714272731203417, 0.2969919909666157, 0.2950390201949396, 0.2941921041794152, 0.2921197589452137, 0.2913582848796741, 0.28934017861064243, 0.2903124143785297, 0.2889381220070713, 0.28664087121759096, 0.2855223967538025, 0.28517865000599635, 0.28442705026095527, 0.2847192962456814, 0.2831644468627204, 0.2807654774569392, 0.2811584721838077, 0.2823364698643901, 0.2783172000551712, 0.2777085996807627, 0.27733933563372265, 0.27599853918988426, 0.276324592420099, 0.27504137134206785, 0.2746720250617267, 0.27395933382484533, 0.27445711978113124, 0.27311123133442294, 0.2721398829380371, 0.2702891630109667, 0.2709619475089348, 0.26925062221826845, 0.26999000957462277, 0.26841587101985503, 0.26877774173270336, 0.268637764176836, 0.26688347233954607, 0.26615730451062125, 0.26749583164902174, 0.26536343703572957, 0.26489492983277363, 0.2642831548184011, 0.26437229334203166, 0.26364897132018805, 0.26456074456353695, 0.2630761255859988, 0.2625342321128717, 0.26230726915840336, 0.26050037922349506, 0.26050108286394, 0.26086163490854, 0.26078838869526655, 0.2596139082315607, 0.25939828876440657], 'acc': [0.6291892713262709, 0.8876936745898679, 0.896905749753141, 0.9140185909573358, 0.9286733167501082, 0.9320141399994026, 0.9341803719436046, 0.9355787611047269, 0.9369933118099416, 0.9378289752733022, 0.9386545030940758, 0.9393998613648229, 0.9400893398055971, 0.9406508023059644, 0.9412581613008182, 0.9414191136476266, 0.9419851012470911, 0.9422222048519701, 0.9425752576642247, 0.9427651596621242, 0.943210146160657, 0.9433789708996285, 0.9438352633872662, 0.9439983674546047, 0.9442748222240693, 0.944345788554183, 0.9445497660600402, 0.9446668671163193, 0.9449880595336065, 0.9451335584898557, 0.9452171591851343, 0.9454933709404757, 0.9455318810380627, 0.9457425338408609, 0.9458336487837101, 0.9459412834207411, 0.946185304968381, 0.9462494857524755, 0.9463556107533194, 0.9465448089348679, 0.94659787794656, 0.9466440150639475, 0.9467598081712495, 0.9468832465980718, 0.9470385455572878, 0.9469840321760276, 0.9471369131700058, 0.9471944433774476, 0.9474545121632697, 0.9473612459451524, 0.9475997908852213, 0.9475683103812244, 0.9476925029005279, 0.9477743339870597, 0.9477499659998351, 0.9477631769573448, 0.947937253754396, 0.9480416278474986, 0.9480469264931799, 0.948003830361562, 0.9481885482285787, 0.9483705585836034, 0.9484960808807179, 0.9484246069189038, 0.9483267565467509, 0.9485340357310523, 0.94860016848893, 0.9486026746380387, 0.9485392456541507, 0.9486725055499676, 0.9487705437732251, 0.9489515571975514, 0.9487819401395284, 0.948918104265203, 0.9488834075400896, 0.9489857181624975, 0.9489874497810479, 0.9490564848063321, 0.9491588647741789, 0.949209187788947, 0.9491014918376849, 0.949257876147844, 0.9492523543489251, 0.9494140784172931, 0.9493481901962247, 0.9494857767856749, 0.9494576224605282, 0.9494356734335098, 0.9494554051325614, 0.9495366351263423, 0.9497170950899614, 0.9496465751377846, 0.9496862757121308, 0.9496504075245962, 0.9497260505957631, 0.9497597034562616], 'mDice': [0.15798931431400098, 0.4350832096382359, 0.5164893989708991, 0.5627185959641392, 0.5894759147905791, 0.606892876494011, 0.6222950327410686, 0.6317352761006779, 0.6433730340582258, 0.6498362487459451, 0.6563126541619854, 0.6627294046186405, 0.6675505953434043, 0.6727365416749579, 0.6774737731145887, 0.6793241871411451, 0.6826427001349767, 0.6863869113103277, 0.6891325556911974, 0.6913828638485412, 0.6948063853184345, 0.6961630611778966, 0.6994346648490397, 0.7028288488226228, 0.7046114690275438, 0.7057284334538597, 0.7077972689733001, 0.7076416293336579, 0.7112623257774671, 0.7120770564007163, 0.7128837171168627, 0.7154577077946781, 0.7165606080424816, 0.7178649575433464, 0.7192878596052454, 0.7200470821483432, 0.7219927619933466, 0.7231558310439157, 0.7238797359467433, 0.7258227887622415, 0.7273001169285452, 0.727595674555141, 0.7288509309319325, 0.7289805815392048, 0.7304546617388582, 0.7311465294612001, 0.7326731377781224, 0.7332566453996514, 0.7347810577666816, 0.734029021593386, 0.7351805566257187, 0.736990957905267, 0.7377729136917651, 0.7380786694515502, 0.7385749428032355, 0.7383973441704013, 0.7396036263795441, 0.7414594189185977, 0.7411772357431338, 0.7402180753642097, 0.7433884577712461, 0.7439088732853462, 0.7441585683013464, 0.7451918564038029, 0.7449115374580164, 0.7458954310599678, 0.7462361725748965, 0.7466681123516452, 0.7463633960698195, 0.7474463483366613, 0.7482112681723868, 0.7496155786479101, 0.7490554281038782, 0.7504328728040998, 0.7498370957948466, 0.7511005187555728, 0.7508021054491724, 0.751011427451706, 0.7523333308420355, 0.7529337981920736, 0.7518724750177366, 0.753509335002039, 0.7538535526007026, 0.7543418343454382, 0.7543047553475114, 0.7548951348903973, 0.7542622127480627, 0.7552803703079164, 0.755773132207769, 0.7559777400782327, 0.7573978485221585, 0.757383068769079, 0.7571518140658015, 0.7571336268323227, 0.7580260730730831, 0.7582470405522851]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.23s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.02s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.83s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:45,  1.85s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:14,  1.75s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:07,  1.73s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:45,  1.66s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:54,  1.70s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:32,  1.62s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:50,  1.69s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:49,  1.70s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:15,  1.79s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:21,  1.82s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<07:53,  1.73s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:17,  1.82s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<08:04,  1.78s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<08:11,  1.81s/it]predicting train subjects:   5%|▌         | 15/285 [00:26<08:21,  1.86s/it]predicting train subjects:   6%|▌         | 16/285 [00:28<08:25,  1.88s/it]predicting train subjects:   6%|▌         | 17/285 [00:29<08:05,  1.81s/it]predicting train subjects:   6%|▋         | 18/285 [00:31<08:04,  1.81s/it]predicting train subjects:   7%|▋         | 19/285 [00:33<07:50,  1.77s/it]predicting train subjects:   7%|▋         | 20/285 [00:35<07:54,  1.79s/it]predicting train subjects:   7%|▋         | 21/285 [00:37<08:18,  1.89s/it]predicting train subjects:   8%|▊         | 22/285 [00:38<07:57,  1.82s/it]predicting train subjects:   8%|▊         | 23/285 [00:40<08:00,  1.83s/it]predicting train subjects:   8%|▊         | 24/285 [00:42<07:50,  1.80s/it]predicting train subjects:   9%|▉         | 25/285 [00:44<07:51,  1.81s/it]predicting train subjects:   9%|▉         | 26/285 [00:46<07:54,  1.83s/it]predicting train subjects:   9%|▉         | 27/285 [00:47<07:33,  1.76s/it]predicting train subjects:  10%|▉         | 28/285 [00:49<07:47,  1.82s/it]predicting train subjects:  10%|█         | 29/285 [00:51<07:47,  1.83s/it]predicting train subjects:  11%|█         | 30/285 [00:53<08:02,  1.89s/it]predicting train subjects:  11%|█         | 31/285 [00:55<08:12,  1.94s/it]predicting train subjects:  11%|█         | 32/285 [00:57<07:47,  1.85s/it]predicting train subjects:  12%|█▏        | 33/285 [00:59<07:43,  1.84s/it]predicting train subjects:  12%|█▏        | 34/285 [01:01<07:44,  1.85s/it]predicting train subjects:  12%|█▏        | 35/285 [01:03<07:48,  1.87s/it]predicting train subjects:  13%|█▎        | 36/285 [01:04<07:31,  1.81s/it]predicting train subjects:  13%|█▎        | 37/285 [01:06<07:35,  1.84s/it]predicting train subjects:  13%|█▎        | 38/285 [01:08<07:40,  1.86s/it]predicting train subjects:  14%|█▎        | 39/285 [01:10<07:18,  1.78s/it]predicting train subjects:  14%|█▍        | 40/285 [01:12<07:22,  1.81s/it]predicting train subjects:  14%|█▍        | 41/285 [01:13<07:17,  1.79s/it]predicting train subjects:  15%|█▍        | 42/285 [01:15<07:08,  1.76s/it]predicting train subjects:  15%|█▌        | 43/285 [01:17<07:07,  1.77s/it]predicting train subjects:  15%|█▌        | 44/285 [01:19<07:17,  1.82s/it]predicting train subjects:  16%|█▌        | 45/285 [01:20<07:02,  1.76s/it]predicting train subjects:  16%|█▌        | 46/285 [01:22<07:09,  1.80s/it]predicting train subjects:  16%|█▋        | 47/285 [01:24<06:53,  1.74s/it]predicting train subjects:  17%|█▋        | 48/285 [01:26<06:56,  1.76s/it]predicting train subjects:  17%|█▋        | 49/285 [01:28<07:09,  1.82s/it]predicting train subjects:  18%|█▊        | 50/285 [01:29<07:08,  1.83s/it]predicting train subjects:  18%|█▊        | 51/285 [01:31<07:19,  1.88s/it]predicting train subjects:  18%|█▊        | 52/285 [01:33<07:06,  1.83s/it]predicting train subjects:  19%|█▊        | 53/285 [01:35<06:59,  1.81s/it]predicting train subjects:  19%|█▉        | 54/285 [01:37<06:59,  1.82s/it]predicting train subjects:  19%|█▉        | 55/285 [01:38<06:43,  1.76s/it]predicting train subjects:  20%|█▉        | 56/285 [01:40<06:44,  1.77s/it]predicting train subjects:  20%|██        | 57/285 [01:42<06:35,  1.73s/it]predicting train subjects:  20%|██        | 58/285 [01:44<06:38,  1.75s/it]predicting train subjects:  21%|██        | 59/285 [01:46<06:50,  1.82s/it]predicting train subjects:  21%|██        | 60/285 [01:47<06:55,  1.85s/it]predicting train subjects:  21%|██▏       | 61/285 [01:49<06:39,  1.78s/it]predicting train subjects:  22%|██▏       | 62/285 [01:51<06:40,  1.80s/it]predicting train subjects:  22%|██▏       | 63/285 [01:53<06:41,  1.81s/it]predicting train subjects:  22%|██▏       | 64/285 [01:55<06:45,  1.83s/it]predicting train subjects:  23%|██▎       | 65/285 [01:57<07:00,  1.91s/it]predicting train subjects:  23%|██▎       | 66/285 [01:59<07:20,  2.01s/it]predicting train subjects:  24%|██▎       | 67/285 [02:01<07:22,  2.03s/it]predicting train subjects:  24%|██▍       | 68/285 [02:03<07:34,  2.09s/it]predicting train subjects:  24%|██▍       | 69/285 [02:06<07:46,  2.16s/it]predicting train subjects:  25%|██▍       | 70/285 [02:08<07:36,  2.12s/it]predicting train subjects:  25%|██▍       | 71/285 [02:10<07:37,  2.14s/it]predicting train subjects:  25%|██▌       | 72/285 [02:12<07:20,  2.07s/it]predicting train subjects:  26%|██▌       | 73/285 [02:14<07:17,  2.07s/it]predicting train subjects:  26%|██▌       | 74/285 [02:16<07:35,  2.16s/it]predicting train subjects:  26%|██▋       | 75/285 [02:18<07:33,  2.16s/it]predicting train subjects:  27%|██▋       | 76/285 [02:21<07:36,  2.19s/it]predicting train subjects:  27%|██▋       | 77/285 [02:23<07:25,  2.14s/it]predicting train subjects:  27%|██▋       | 78/285 [02:24<07:04,  2.05s/it]predicting train subjects:  28%|██▊       | 79/285 [02:27<07:26,  2.17s/it]predicting train subjects:  28%|██▊       | 80/285 [02:29<07:20,  2.15s/it]predicting train subjects:  28%|██▊       | 81/285 [02:31<06:56,  2.04s/it]predicting train subjects:  29%|██▉       | 82/285 [02:33<07:13,  2.13s/it]predicting train subjects:  29%|██▉       | 83/285 [02:35<06:56,  2.06s/it]predicting train subjects:  29%|██▉       | 84/285 [02:37<06:48,  2.03s/it]predicting train subjects:  30%|██▉       | 85/285 [02:39<06:59,  2.10s/it]predicting train subjects:  30%|███       | 86/285 [02:41<07:02,  2.12s/it]predicting train subjects:  31%|███       | 87/285 [02:43<06:55,  2.10s/it]predicting train subjects:  31%|███       | 88/285 [02:45<06:40,  2.03s/it]predicting train subjects:  31%|███       | 89/285 [02:47<06:39,  2.04s/it]predicting train subjects:  32%|███▏      | 90/285 [02:50<06:50,  2.11s/it]predicting train subjects:  32%|███▏      | 91/285 [02:52<06:51,  2.12s/it]predicting train subjects:  32%|███▏      | 92/285 [02:54<07:04,  2.20s/it]predicting train subjects:  33%|███▎      | 93/285 [02:56<06:51,  2.14s/it]predicting train subjects:  33%|███▎      | 94/285 [02:58<06:41,  2.10s/it]predicting train subjects:  33%|███▎      | 95/285 [03:01<06:54,  2.18s/it]predicting train subjects:  34%|███▎      | 96/285 [03:03<06:57,  2.21s/it]predicting train subjects:  34%|███▍      | 97/285 [03:05<07:17,  2.33s/it]predicting train subjects:  34%|███▍      | 98/285 [03:08<07:17,  2.34s/it]predicting train subjects:  35%|███▍      | 99/285 [03:10<06:54,  2.23s/it]predicting train subjects:  35%|███▌      | 100/285 [03:12<06:33,  2.13s/it]predicting train subjects:  35%|███▌      | 101/285 [03:13<06:12,  2.03s/it]predicting train subjects:  36%|███▌      | 102/285 [03:16<06:15,  2.05s/it]predicting train subjects:  36%|███▌      | 103/285 [03:18<06:13,  2.05s/it]predicting train subjects:  36%|███▋      | 104/285 [03:20<06:36,  2.19s/it]predicting train subjects:  37%|███▋      | 105/285 [03:23<06:56,  2.31s/it]predicting train subjects:  37%|███▋      | 106/285 [03:25<07:03,  2.37s/it]predicting train subjects:  38%|███▊      | 107/285 [03:28<07:10,  2.42s/it]predicting train subjects:  38%|███▊      | 108/285 [03:30<07:00,  2.38s/it]predicting train subjects:  38%|███▊      | 109/285 [03:32<07:01,  2.40s/it]predicting train subjects:  39%|███▊      | 110/285 [03:35<07:15,  2.49s/it]predicting train subjects:  39%|███▉      | 111/285 [03:37<06:43,  2.32s/it]predicting train subjects:  39%|███▉      | 112/285 [03:39<06:42,  2.33s/it]predicting train subjects:  40%|███▉      | 113/285 [03:42<06:59,  2.44s/it]predicting train subjects:  40%|████      | 114/285 [03:44<06:40,  2.34s/it]predicting train subjects:  40%|████      | 115/285 [03:47<06:33,  2.32s/it]predicting train subjects:  41%|████      | 116/285 [03:49<06:42,  2.38s/it]predicting train subjects:  41%|████      | 117/285 [03:51<06:16,  2.24s/it]predicting train subjects:  41%|████▏     | 118/285 [03:53<06:04,  2.18s/it]predicting train subjects:  42%|████▏     | 119/285 [03:55<06:04,  2.20s/it]predicting train subjects:  42%|████▏     | 120/285 [03:57<06:02,  2.20s/it]predicting train subjects:  42%|████▏     | 121/285 [04:00<06:03,  2.22s/it]predicting train subjects:  43%|████▎     | 122/285 [04:02<05:48,  2.14s/it]predicting train subjects:  43%|████▎     | 123/285 [04:04<05:50,  2.16s/it]predicting train subjects:  44%|████▎     | 124/285 [04:06<05:35,  2.08s/it]predicting train subjects:  44%|████▍     | 125/285 [04:08<05:38,  2.12s/it]predicting train subjects:  44%|████▍     | 126/285 [04:10<05:39,  2.14s/it]predicting train subjects:  45%|████▍     | 127/285 [04:12<05:27,  2.07s/it]predicting train subjects:  45%|████▍     | 128/285 [04:15<05:45,  2.20s/it]predicting train subjects:  45%|████▌     | 129/285 [04:17<05:42,  2.19s/it]predicting train subjects:  46%|████▌     | 130/285 [04:19<05:31,  2.14s/it]predicting train subjects:  46%|████▌     | 131/285 [04:21<05:40,  2.21s/it]predicting train subjects:  46%|████▋     | 132/285 [04:23<05:35,  2.19s/it]predicting train subjects:  47%|████▋     | 133/285 [04:25<05:22,  2.12s/it]predicting train subjects:  47%|████▋     | 134/285 [04:27<05:21,  2.13s/it]predicting train subjects:  47%|████▋     | 135/285 [04:29<05:05,  2.03s/it]predicting train subjects:  48%|████▊     | 136/285 [04:31<05:00,  2.02s/it]predicting train subjects:  48%|████▊     | 137/285 [04:33<05:10,  2.10s/it]predicting train subjects:  48%|████▊     | 138/285 [04:35<05:00,  2.04s/it]predicting train subjects:  49%|████▉     | 139/285 [04:38<05:03,  2.08s/it]predicting train subjects:  49%|████▉     | 140/285 [04:40<05:11,  2.15s/it]predicting train subjects:  49%|████▉     | 141/285 [04:42<05:01,  2.09s/it]predicting train subjects:  50%|████▉     | 142/285 [04:44<04:57,  2.08s/it]predicting train subjects:  50%|█████     | 143/285 [04:46<04:38,  1.96s/it]predicting train subjects:  51%|█████     | 144/285 [04:47<04:35,  1.95s/it]predicting train subjects:  51%|█████     | 145/285 [04:50<04:46,  2.05s/it]predicting train subjects:  51%|█████     | 146/285 [04:52<05:02,  2.17s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:54<04:49,  2.10s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:57<05:00,  2.19s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:58<04:42,  2.08s/it]predicting train subjects:  53%|█████▎    | 150/285 [05:01<04:47,  2.13s/it]predicting train subjects:  53%|█████▎    | 151/285 [05:03<04:38,  2.08s/it]predicting train subjects:  53%|█████▎    | 152/285 [05:05<04:34,  2.07s/it]predicting train subjects:  54%|█████▎    | 153/285 [05:06<04:17,  1.95s/it]predicting train subjects:  54%|█████▍    | 154/285 [05:09<04:37,  2.12s/it]predicting train subjects:  54%|█████▍    | 155/285 [05:11<04:34,  2.11s/it]predicting train subjects:  55%|█████▍    | 156/285 [05:13<04:36,  2.15s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:15<04:26,  2.08s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:17<04:14,  2.01s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:19<04:03,  1.93s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:21<03:59,  1.91s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:23<04:00,  1.94s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:25<04:00,  1.95s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:27<04:02,  1.99s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:29<04:05,  2.03s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:31<03:57,  1.98s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:33<04:15,  2.14s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:35<04:09,  2.12s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:37<03:56,  2.02s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:39<03:52,  2.01s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:41<03:50,  2.00s/it]predicting train subjects:  60%|██████    | 171/285 [05:43<03:44,  1.97s/it]predicting train subjects:  60%|██████    | 172/285 [05:45<03:38,  1.94s/it]predicting train subjects:  61%|██████    | 173/285 [05:46<03:32,  1.90s/it]predicting train subjects:  61%|██████    | 174/285 [05:49<03:42,  2.00s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:51<04:01,  2.20s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:54<03:59,  2.20s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:55<03:42,  2.06s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:58<03:46,  2.11s/it]predicting train subjects:  63%|██████▎   | 179/285 [06:00<03:40,  2.08s/it]predicting train subjects:  63%|██████▎   | 180/285 [06:02<03:43,  2.13s/it]predicting train subjects:  64%|██████▎   | 181/285 [06:04<03:42,  2.14s/it]predicting train subjects:  64%|██████▍   | 182/285 [06:06<03:36,  2.10s/it]predicting train subjects:  64%|██████▍   | 183/285 [06:08<03:20,  1.96s/it]predicting train subjects:  65%|██████▍   | 184/285 [06:10<03:31,  2.09s/it]predicting train subjects:  65%|██████▍   | 185/285 [06:12<03:19,  2.00s/it]predicting train subjects:  65%|██████▌   | 186/285 [06:14<03:27,  2.09s/it]predicting train subjects:  66%|██████▌   | 187/285 [06:16<03:28,  2.13s/it]predicting train subjects:  66%|██████▌   | 188/285 [06:19<03:33,  2.20s/it]predicting train subjects:  66%|██████▋   | 189/285 [06:20<03:17,  2.05s/it]predicting train subjects:  67%|██████▋   | 190/285 [06:22<03:14,  2.04s/it]predicting train subjects:  67%|██████▋   | 191/285 [06:25<03:13,  2.06s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:27<03:25,  2.20s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:29<03:07,  2.03s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:31<03:01,  2.00s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:32<02:56,  1.96s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:35<03:00,  2.02s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:37<03:03,  2.09s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:39<03:06,  2.14s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:41<02:55,  2.04s/it]predicting train subjects:  70%|███████   | 200/285 [06:43<02:49,  1.99s/it]predicting train subjects:  71%|███████   | 201/285 [06:45<02:52,  2.06s/it]predicting train subjects:  71%|███████   | 202/285 [06:48<03:03,  2.21s/it]predicting train subjects:  71%|███████   | 203/285 [06:50<03:00,  2.20s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:51<02:45,  2.04s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:54<02:49,  2.11s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:55<02:34,  1.96s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:58<02:40,  2.06s/it]predicting train subjects:  73%|███████▎  | 208/285 [07:00<02:45,  2.15s/it]predicting train subjects:  73%|███████▎  | 209/285 [07:02<02:45,  2.18s/it]predicting train subjects:  74%|███████▎  | 210/285 [07:05<02:49,  2.26s/it]predicting train subjects:  74%|███████▍  | 211/285 [07:07<02:38,  2.14s/it]predicting train subjects:  74%|███████▍  | 212/285 [07:09<02:35,  2.13s/it]predicting train subjects:  75%|███████▍  | 213/285 [07:11<02:36,  2.17s/it]predicting train subjects:  75%|███████▌  | 214/285 [07:13<02:28,  2.09s/it]predicting train subjects:  75%|███████▌  | 215/285 [07:15<02:36,  2.24s/it]predicting train subjects:  76%|███████▌  | 216/285 [07:17<02:24,  2.09s/it]predicting train subjects:  76%|███████▌  | 217/285 [07:19<02:26,  2.15s/it]predicting train subjects:  76%|███████▋  | 218/285 [07:22<02:34,  2.31s/it]predicting train subjects:  77%|███████▋  | 219/285 [07:25<02:36,  2.37s/it]predicting train subjects:  77%|███████▋  | 220/285 [07:27<02:25,  2.24s/it]predicting train subjects:  78%|███████▊  | 221/285 [07:29<02:24,  2.26s/it]predicting train subjects:  78%|███████▊  | 222/285 [07:31<02:20,  2.23s/it]predicting train subjects:  78%|███████▊  | 223/285 [07:33<02:14,  2.16s/it]predicting train subjects:  79%|███████▊  | 224/285 [07:35<02:11,  2.15s/it]predicting train subjects:  79%|███████▉  | 225/285 [07:37<02:10,  2.18s/it]predicting train subjects:  79%|███████▉  | 226/285 [07:40<02:18,  2.34s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:42<02:12,  2.29s/it]predicting train subjects:  80%|████████  | 228/285 [07:44<02:07,  2.23s/it]predicting train subjects:  80%|████████  | 229/285 [07:47<02:12,  2.37s/it]predicting train subjects:  81%|████████  | 230/285 [07:49<02:00,  2.19s/it]predicting train subjects:  81%|████████  | 231/285 [07:50<01:45,  1.96s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:52<01:39,  1.88s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:53<01:31,  1.76s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:55<01:29,  1.76s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:57<01:22,  1.64s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:58<01:22,  1.68s/it]predicting train subjects:  83%|████████▎ | 237/285 [08:00<01:22,  1.71s/it]predicting train subjects:  84%|████████▎ | 238/285 [08:02<01:20,  1.72s/it]predicting train subjects:  84%|████████▍ | 239/285 [08:03<01:17,  1.68s/it]predicting train subjects:  84%|████████▍ | 240/285 [08:05<01:11,  1.59s/it]predicting train subjects:  85%|████████▍ | 241/285 [08:06<01:08,  1.55s/it]predicting train subjects:  85%|████████▍ | 242/285 [08:08<01:03,  1.49s/it]predicting train subjects:  85%|████████▌ | 243/285 [08:09<01:00,  1.45s/it]predicting train subjects:  86%|████████▌ | 244/285 [08:11<01:03,  1.54s/it]predicting train subjects:  86%|████████▌ | 245/285 [08:12<00:58,  1.46s/it]predicting train subjects:  86%|████████▋ | 246/285 [08:14<01:02,  1.60s/it]predicting train subjects:  87%|████████▋ | 247/285 [08:16<01:02,  1.65s/it]predicting train subjects:  87%|████████▋ | 248/285 [08:18<01:02,  1.70s/it]predicting train subjects:  87%|████████▋ | 249/285 [08:19<00:58,  1.62s/it]predicting train subjects:  88%|████████▊ | 250/285 [08:20<00:54,  1.57s/it]predicting train subjects:  88%|████████▊ | 251/285 [08:22<00:51,  1.50s/it]predicting train subjects:  88%|████████▊ | 252/285 [08:23<00:48,  1.47s/it]predicting train subjects:  89%|████████▉ | 253/285 [08:25<00:50,  1.57s/it]predicting train subjects:  89%|████████▉ | 254/285 [08:27<00:50,  1.62s/it]predicting train subjects:  89%|████████▉ | 255/285 [08:28<00:48,  1.61s/it]predicting train subjects:  90%|████████▉ | 256/285 [08:30<00:44,  1.55s/it]predicting train subjects:  90%|█████████ | 257/285 [08:31<00:42,  1.53s/it]predicting train subjects:  91%|█████████ | 258/285 [08:33<00:44,  1.66s/it]predicting train subjects:  91%|█████████ | 259/285 [08:35<00:44,  1.71s/it]predicting train subjects:  91%|█████████ | 260/285 [08:36<00:40,  1.63s/it]predicting train subjects:  92%|█████████▏| 261/285 [08:38<00:37,  1.58s/it]predicting train subjects:  92%|█████████▏| 262/285 [08:39<00:34,  1.50s/it]predicting train subjects:  92%|█████████▏| 263/285 [08:41<00:31,  1.45s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:42<00:33,  1.59s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:44<00:32,  1.63s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:46<00:29,  1.55s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:47<00:28,  1.56s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:49<00:27,  1.64s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:51<00:27,  1.70s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:52<00:23,  1.58s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:53<00:21,  1.51s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:55<00:20,  1.55s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:57<00:18,  1.52s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:58<00:16,  1.48s/it]predicting train subjects:  96%|█████████▋| 275/285 [09:00<00:16,  1.61s/it]predicting train subjects:  97%|█████████▋| 276/285 [09:02<00:15,  1.67s/it]predicting train subjects:  97%|█████████▋| 277/285 [09:03<00:12,  1.58s/it]predicting train subjects:  98%|█████████▊| 278/285 [09:04<00:10,  1.51s/it]predicting train subjects:  98%|█████████▊| 279/285 [09:06<00:09,  1.57s/it]predicting train subjects:  98%|█████████▊| 280/285 [09:07<00:07,  1.52s/it]predicting train subjects:  99%|█████████▊| 281/285 [09:09<00:06,  1.51s/it]predicting train subjects:  99%|█████████▉| 282/285 [09:10<00:04,  1.48s/it]predicting train subjects:  99%|█████████▉| 283/285 [09:12<00:03,  1.58s/it]predicting train subjects: 100%|█████████▉| 284/285 [09:14<00:01,  1.66s/it]predicting train subjects: 100%|██████████| 285/285 [09:16<00:00,  1.74s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM10_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<09:01,  1.91s/it]Loading train:   1%|          | 2/285 [00:03<08:07,  1.72s/it]Loading train:   1%|          | 3/285 [00:04<07:50,  1.67s/it]Loading train:   1%|▏         | 4/285 [00:06<07:46,  1.66s/it]Loading train:   2%|▏         | 5/285 [00:08<08:02,  1.72s/it]Loading train:   2%|▏         | 6/285 [00:09<07:52,  1.70s/it]Loading train:   2%|▏         | 7/285 [00:11<07:40,  1.66s/it]Loading train:   3%|▎         | 8/285 [00:12<07:14,  1.57s/it]Loading train:   3%|▎         | 9/285 [00:14<07:24,  1.61s/it]Loading train:   4%|▎         | 10/285 [00:15<06:40,  1.46s/it]Loading train:   4%|▍         | 11/285 [00:16<06:01,  1.32s/it]Loading train:   4%|▍         | 12/285 [00:17<05:40,  1.25s/it]Loading train:   5%|▍         | 13/285 [00:18<05:00,  1.10s/it]Loading train:   5%|▍         | 14/285 [00:19<04:57,  1.10s/it]Loading train:   5%|▌         | 15/285 [00:20<04:49,  1.07s/it]Loading train:   6%|▌         | 16/285 [00:21<04:51,  1.08s/it]Loading train:   6%|▌         | 17/285 [00:22<04:41,  1.05s/it]Loading train:   6%|▋         | 18/285 [00:23<04:45,  1.07s/it]Loading train:   7%|▋         | 19/285 [00:24<04:27,  1.00s/it]Loading train:   7%|▋         | 20/285 [00:25<04:46,  1.08s/it]Loading train:   7%|▋         | 21/285 [00:27<05:03,  1.15s/it]Loading train:   8%|▊         | 22/285 [00:28<05:00,  1.14s/it]Loading train:   8%|▊         | 23/285 [00:29<04:46,  1.09s/it]Loading train:   8%|▊         | 24/285 [00:30<04:37,  1.06s/it]Loading train:   9%|▉         | 25/285 [00:31<04:31,  1.04s/it]Loading train:   9%|▉         | 26/285 [00:32<04:26,  1.03s/it]Loading train:   9%|▉         | 27/285 [00:33<04:07,  1.04it/s]Loading train:  10%|▉         | 28/285 [00:34<04:12,  1.02it/s]Loading train:  10%|█         | 29/285 [00:35<04:22,  1.02s/it]Loading train:  11%|█         | 30/285 [00:36<04:39,  1.10s/it]Loading train:  11%|█         | 31/285 [00:37<04:44,  1.12s/it]Loading train:  11%|█         | 32/285 [00:38<04:27,  1.06s/it]Loading train:  12%|█▏        | 33/285 [00:39<04:32,  1.08s/it]Loading train:  12%|█▏        | 34/285 [00:40<04:23,  1.05s/it]Loading train:  12%|█▏        | 35/285 [00:41<04:33,  1.10s/it]Loading train:  13%|█▎        | 36/285 [00:42<04:03,  1.02it/s]Loading train:  13%|█▎        | 37/285 [00:43<04:11,  1.01s/it]Loading train:  13%|█▎        | 38/285 [00:44<04:15,  1.03s/it]Loading train:  14%|█▎        | 39/285 [00:45<04:05,  1.00it/s]Loading train:  14%|█▍        | 40/285 [00:46<04:08,  1.01s/it]Loading train:  14%|█▍        | 41/285 [00:47<03:52,  1.05it/s]Loading train:  15%|█▍        | 42/285 [00:48<03:43,  1.09it/s]Loading train:  15%|█▌        | 43/285 [00:49<03:50,  1.05it/s]Loading train:  15%|█▌        | 44/285 [00:50<04:12,  1.05s/it]Loading train:  16%|█▌        | 45/285 [00:51<04:07,  1.03s/it]Loading train:  16%|█▌        | 46/285 [00:53<04:40,  1.17s/it]Loading train:  16%|█▋        | 47/285 [00:54<04:20,  1.10s/it]Loading train:  17%|█▋        | 48/285 [00:55<04:26,  1.12s/it]Loading train:  17%|█▋        | 49/285 [00:56<04:33,  1.16s/it]Loading train:  18%|█▊        | 50/285 [00:57<04:26,  1.13s/it]Loading train:  18%|█▊        | 51/285 [00:58<04:22,  1.12s/it]Loading train:  18%|█▊        | 52/285 [00:59<04:06,  1.06s/it]Loading train:  19%|█▊        | 53/285 [01:00<03:55,  1.01s/it]Loading train:  19%|█▉        | 54/285 [01:01<03:49,  1.01it/s]Loading train:  19%|█▉        | 55/285 [01:02<03:36,  1.06it/s]Loading train:  20%|█▉        | 56/285 [01:03<03:25,  1.12it/s]Loading train:  20%|██        | 57/285 [01:03<03:16,  1.16it/s]Loading train:  20%|██        | 58/285 [01:05<03:35,  1.05it/s]Loading train:  21%|██        | 59/285 [01:06<03:45,  1.00it/s]Loading train:  21%|██        | 60/285 [01:07<03:52,  1.03s/it]Loading train:  21%|██▏       | 61/285 [01:08<03:40,  1.01it/s]Loading train:  22%|██▏       | 62/285 [01:09<03:46,  1.01s/it]Loading train:  22%|██▏       | 63/285 [01:10<03:47,  1.02s/it]Loading train:  22%|██▏       | 64/285 [01:11<04:10,  1.14s/it]Loading train:  23%|██▎       | 65/285 [01:13<04:48,  1.31s/it]Loading train:  23%|██▎       | 66/285 [01:14<04:59,  1.37s/it]Loading train:  24%|██▎       | 67/285 [01:15<04:41,  1.29s/it]Loading train:  24%|██▍       | 68/285 [01:16<04:16,  1.18s/it]Loading train:  24%|██▍       | 69/285 [01:17<03:54,  1.09s/it]Loading train:  25%|██▍       | 70/285 [01:18<03:50,  1.07s/it]Loading train:  25%|██▍       | 71/285 [01:19<03:48,  1.07s/it]Loading train:  25%|██▌       | 72/285 [01:20<03:43,  1.05s/it]Loading train:  26%|██▌       | 73/285 [01:21<03:38,  1.03s/it]Loading train:  26%|██▌       | 74/285 [01:22<03:32,  1.01s/it]Loading train:  26%|██▋       | 75/285 [01:23<03:36,  1.03s/it]Loading train:  27%|██▋       | 76/285 [01:24<03:34,  1.03s/it]Loading train:  27%|██▋       | 77/285 [01:25<03:26,  1.01it/s]Loading train:  27%|██▋       | 78/285 [01:26<03:12,  1.07it/s]Loading train:  28%|██▊       | 79/285 [01:27<03:14,  1.06it/s]Loading train:  28%|██▊       | 80/285 [01:28<03:09,  1.08it/s]Loading train:  28%|██▊       | 81/285 [01:29<03:15,  1.04it/s]Loading train:  29%|██▉       | 82/285 [01:30<03:13,  1.05it/s]Loading train:  29%|██▉       | 83/285 [01:31<03:09,  1.07it/s]Loading train:  29%|██▉       | 84/285 [01:32<03:04,  1.09it/s]Loading train:  30%|██▉       | 85/285 [01:33<03:09,  1.06it/s]Loading train:  30%|███       | 86/285 [01:34<03:27,  1.04s/it]Loading train:  31%|███       | 87/285 [01:35<03:34,  1.08s/it]Loading train:  31%|███       | 88/285 [01:36<03:25,  1.04s/it]Loading train:  31%|███       | 89/285 [01:37<03:14,  1.01it/s]Loading train:  32%|███▏      | 90/285 [01:38<03:19,  1.02s/it]Loading train:  32%|███▏      | 91/285 [01:39<03:07,  1.04it/s]Loading train:  32%|███▏      | 92/285 [01:40<03:18,  1.03s/it]Loading train:  33%|███▎      | 93/285 [01:41<03:07,  1.02it/s]Loading train:  33%|███▎      | 94/285 [01:42<03:04,  1.03it/s]Loading train:  33%|███▎      | 95/285 [01:43<02:57,  1.07it/s]Loading train:  34%|███▎      | 96/285 [01:44<02:49,  1.12it/s]Loading train:  34%|███▍      | 97/285 [01:45<02:53,  1.08it/s]Loading train:  34%|███▍      | 98/285 [01:45<02:47,  1.12it/s]Loading train:  35%|███▍      | 99/285 [01:46<02:46,  1.12it/s]Loading train:  35%|███▌      | 100/285 [01:47<02:52,  1.07it/s]Loading train:  35%|███▌      | 101/285 [01:48<02:48,  1.09it/s]Loading train:  36%|███▌      | 102/285 [01:49<02:52,  1.06it/s]Loading train:  36%|███▌      | 103/285 [01:50<02:51,  1.06it/s]Loading train:  36%|███▋      | 104/285 [01:51<02:52,  1.05it/s]Loading train:  37%|███▋      | 105/285 [01:52<02:59,  1.01it/s]Loading train:  37%|███▋      | 106/285 [01:53<02:52,  1.04it/s]Loading train:  38%|███▊      | 107/285 [01:54<02:48,  1.05it/s]Loading train:  38%|███▊      | 108/285 [01:55<02:39,  1.11it/s]Loading train:  38%|███▊      | 109/285 [01:56<02:40,  1.10it/s]Loading train:  39%|███▊      | 110/285 [01:57<02:46,  1.05it/s]Loading train:  39%|███▉      | 111/285 [01:58<02:39,  1.09it/s]Loading train:  39%|███▉      | 112/285 [01:59<02:39,  1.08it/s]Loading train:  40%|███▉      | 113/285 [01:59<02:37,  1.09it/s]Loading train:  40%|████      | 114/285 [02:00<02:40,  1.06it/s]Loading train:  40%|████      | 115/285 [02:01<02:44,  1.03it/s]Loading train:  41%|████      | 116/285 [02:03<02:57,  1.05s/it]Loading train:  41%|████      | 117/285 [02:04<02:47,  1.00it/s]Loading train:  41%|████▏     | 118/285 [02:04<02:40,  1.04it/s]Loading train:  42%|████▏     | 119/285 [02:06<02:49,  1.02s/it]Loading train:  42%|████▏     | 120/285 [02:07<02:49,  1.03s/it]Loading train:  42%|████▏     | 121/285 [02:08<03:04,  1.13s/it]Loading train:  43%|████▎     | 122/285 [02:09<03:06,  1.14s/it]Loading train:  43%|████▎     | 123/285 [02:10<03:06,  1.15s/it]Loading train:  44%|████▎     | 124/285 [02:11<02:56,  1.09s/it]Loading train:  44%|████▍     | 125/285 [02:12<02:46,  1.04s/it]Loading train:  44%|████▍     | 126/285 [02:13<02:38,  1.00it/s]Loading train:  45%|████▍     | 127/285 [02:14<02:22,  1.11it/s]Loading train:  45%|████▍     | 128/285 [02:15<02:15,  1.16it/s]Loading train:  45%|████▌     | 129/285 [02:15<02:11,  1.18it/s]Loading train:  46%|████▌     | 130/285 [02:16<02:08,  1.20it/s]Loading train:  46%|████▌     | 131/285 [02:17<01:59,  1.29it/s]Loading train:  46%|████▋     | 132/285 [02:18<02:00,  1.27it/s]Loading train:  47%|████▋     | 133/285 [02:18<02:00,  1.26it/s]Loading train:  47%|████▋     | 134/285 [02:19<02:05,  1.20it/s]Loading train:  47%|████▋     | 135/285 [02:20<02:04,  1.20it/s]Loading train:  48%|████▊     | 136/285 [02:21<02:00,  1.24it/s]Loading train:  48%|████▊     | 137/285 [02:22<01:53,  1.30it/s]Loading train:  48%|████▊     | 138/285 [02:22<01:53,  1.30it/s]Loading train:  49%|████▉     | 139/285 [02:23<01:53,  1.29it/s]Loading train:  49%|████▉     | 140/285 [02:24<01:52,  1.29it/s]Loading train:  49%|████▉     | 141/285 [02:25<01:51,  1.29it/s]Loading train:  50%|████▉     | 142/285 [02:26<01:55,  1.23it/s]Loading train:  50%|█████     | 143/285 [02:27<01:57,  1.21it/s]Loading train:  51%|█████     | 144/285 [02:27<01:54,  1.23it/s]Loading train:  51%|█████     | 145/285 [02:28<01:56,  1.20it/s]Loading train:  51%|█████     | 146/285 [02:29<01:58,  1.17it/s]Loading train:  52%|█████▏    | 147/285 [02:30<01:58,  1.16it/s]Loading train:  52%|█████▏    | 148/285 [02:31<02:03,  1.11it/s]Loading train:  52%|█████▏    | 149/285 [02:32<01:56,  1.17it/s]Loading train:  53%|█████▎    | 150/285 [02:33<01:53,  1.19it/s]Loading train:  53%|█████▎    | 151/285 [02:33<01:56,  1.15it/s]Loading train:  53%|█████▎    | 152/285 [02:34<01:52,  1.18it/s]Loading train:  54%|█████▎    | 153/285 [02:35<01:52,  1.18it/s]Loading train:  54%|█████▍    | 154/285 [02:36<01:55,  1.14it/s]Loading train:  54%|█████▍    | 155/285 [02:37<01:48,  1.20it/s]Loading train:  55%|█████▍    | 156/285 [02:38<01:50,  1.17it/s]Loading train:  55%|█████▌    | 157/285 [02:39<01:52,  1.13it/s]Loading train:  55%|█████▌    | 158/285 [02:40<02:01,  1.04it/s]Loading train:  56%|█████▌    | 159/285 [02:41<01:55,  1.09it/s]Loading train:  56%|█████▌    | 160/285 [02:41<01:53,  1.10it/s]Loading train:  56%|█████▋    | 161/285 [02:42<01:54,  1.09it/s]Loading train:  57%|█████▋    | 162/285 [02:43<01:55,  1.07it/s]Loading train:  57%|█████▋    | 163/285 [02:44<01:50,  1.10it/s]Loading train:  58%|█████▊    | 164/285 [02:45<01:45,  1.14it/s]Loading train:  58%|█████▊    | 165/285 [02:46<01:38,  1.21it/s]Loading train:  58%|█████▊    | 166/285 [02:47<01:44,  1.13it/s]Loading train:  59%|█████▊    | 167/285 [02:48<01:44,  1.13it/s]Loading train:  59%|█████▉    | 168/285 [02:48<01:41,  1.15it/s]Loading train:  59%|█████▉    | 169/285 [02:49<01:39,  1.17it/s]Loading train:  60%|█████▉    | 170/285 [02:50<01:34,  1.21it/s]Loading train:  60%|██████    | 171/285 [02:51<01:31,  1.25it/s]Loading train:  60%|██████    | 172/285 [02:52<01:34,  1.20it/s]Loading train:  61%|██████    | 173/285 [02:53<01:34,  1.18it/s]Loading train:  61%|██████    | 174/285 [02:53<01:31,  1.21it/s]Loading train:  61%|██████▏   | 175/285 [02:54<01:33,  1.17it/s]Loading train:  62%|██████▏   | 176/285 [02:55<01:32,  1.17it/s]Loading train:  62%|██████▏   | 177/285 [02:56<01:25,  1.26it/s]Loading train:  62%|██████▏   | 178/285 [02:57<01:24,  1.26it/s]Loading train:  63%|██████▎   | 179/285 [02:57<01:24,  1.25it/s]Loading train:  63%|██████▎   | 180/285 [02:59<01:33,  1.12it/s]Loading train:  64%|██████▎   | 181/285 [02:59<01:32,  1.12it/s]Loading train:  64%|██████▍   | 182/285 [03:00<01:31,  1.13it/s]Loading train:  64%|██████▍   | 183/285 [03:01<01:28,  1.15it/s]Loading train:  65%|██████▍   | 184/285 [03:02<01:26,  1.17it/s]Loading train:  65%|██████▍   | 185/285 [03:03<01:24,  1.19it/s]Loading train:  65%|██████▌   | 186/285 [03:04<01:33,  1.06it/s]Loading train:  66%|██████▌   | 187/285 [03:05<01:32,  1.06it/s]Loading train:  66%|██████▌   | 188/285 [03:06<01:35,  1.02it/s]Loading train:  66%|██████▋   | 189/285 [03:07<01:29,  1.07it/s]Loading train:  67%|██████▋   | 190/285 [03:08<01:26,  1.10it/s]Loading train:  67%|██████▋   | 191/285 [03:08<01:22,  1.14it/s]Loading train:  67%|██████▋   | 192/285 [03:09<01:27,  1.07it/s]Loading train:  68%|██████▊   | 193/285 [03:10<01:22,  1.12it/s]Loading train:  68%|██████▊   | 194/285 [03:11<01:18,  1.16it/s]Loading train:  68%|██████▊   | 195/285 [03:12<01:16,  1.18it/s]Loading train:  69%|██████▉   | 196/285 [03:13<01:20,  1.11it/s]Loading train:  69%|██████▉   | 197/285 [03:14<01:24,  1.05it/s]Loading train:  69%|██████▉   | 198/285 [03:15<01:24,  1.03it/s]Loading train:  70%|██████▉   | 199/285 [03:16<01:17,  1.11it/s]Loading train:  70%|███████   | 200/285 [03:17<01:17,  1.10it/s]Loading train:  71%|███████   | 201/285 [03:18<01:18,  1.07it/s]Loading train:  71%|███████   | 202/285 [03:18<01:15,  1.11it/s]Loading train:  71%|███████   | 203/285 [03:19<01:13,  1.12it/s]Loading train:  72%|███████▏  | 204/285 [03:20<01:09,  1.16it/s]Loading train:  72%|███████▏  | 205/285 [03:21<01:10,  1.13it/s]Loading train:  72%|███████▏  | 206/285 [03:22<01:06,  1.19it/s]Loading train:  73%|███████▎  | 207/285 [03:23<01:06,  1.18it/s]Loading train:  73%|███████▎  | 208/285 [03:24<01:06,  1.15it/s]Loading train:  73%|███████▎  | 209/285 [03:25<01:07,  1.13it/s]Loading train:  74%|███████▎  | 210/285 [03:25<01:05,  1.14it/s]Loading train:  74%|███████▍  | 211/285 [03:26<01:04,  1.15it/s]Loading train:  74%|███████▍  | 212/285 [03:27<01:01,  1.18it/s]Loading train:  75%|███████▍  | 213/285 [03:28<00:59,  1.22it/s]Loading train:  75%|███████▌  | 214/285 [03:28<00:55,  1.28it/s]Loading train:  75%|███████▌  | 215/285 [03:29<00:58,  1.20it/s]Loading train:  76%|███████▌  | 216/285 [03:30<00:53,  1.28it/s]Loading train:  76%|███████▌  | 217/285 [03:31<00:55,  1.22it/s]Loading train:  76%|███████▋  | 218/285 [03:32<00:58,  1.14it/s]Loading train:  77%|███████▋  | 219/285 [03:33<01:01,  1.07it/s]Loading train:  77%|███████▋  | 220/285 [03:34<00:58,  1.11it/s]Loading train:  78%|███████▊  | 221/285 [03:35<00:57,  1.12it/s]Loading train:  78%|███████▊  | 222/285 [03:36<00:58,  1.08it/s]Loading train:  78%|███████▊  | 223/285 [03:37<00:56,  1.09it/s]Loading train:  79%|███████▊  | 224/285 [03:37<00:54,  1.13it/s]Loading train:  79%|███████▉  | 225/285 [03:38<00:53,  1.12it/s]Loading train:  79%|███████▉  | 226/285 [03:39<00:54,  1.08it/s]Loading train:  80%|███████▉  | 227/285 [03:40<00:53,  1.09it/s]Loading train:  80%|████████  | 228/285 [03:41<00:53,  1.07it/s]Loading train:  80%|████████  | 229/285 [03:42<00:50,  1.10it/s]Loading train:  81%|████████  | 230/285 [03:43<00:48,  1.13it/s]Loading train:  81%|████████  | 231/285 [03:44<00:45,  1.18it/s]Loading train:  81%|████████▏ | 232/285 [03:45<00:45,  1.17it/s]Loading train:  82%|████████▏ | 233/285 [03:45<00:42,  1.21it/s]Loading train:  82%|████████▏ | 234/285 [03:46<00:45,  1.12it/s]Loading train:  82%|████████▏ | 235/285 [03:47<00:41,  1.19it/s]Loading train:  83%|████████▎ | 236/285 [03:48<00:42,  1.15it/s]Loading train:  83%|████████▎ | 237/285 [03:49<00:43,  1.10it/s]Loading train:  84%|████████▎ | 238/285 [03:50<00:45,  1.03it/s]Loading train:  84%|████████▍ | 239/285 [03:51<00:44,  1.04it/s]Loading train:  84%|████████▍ | 240/285 [03:52<00:41,  1.09it/s]Loading train:  85%|████████▍ | 241/285 [03:53<00:39,  1.13it/s]Loading train:  85%|████████▍ | 242/285 [03:54<00:37,  1.15it/s]Loading train:  85%|████████▌ | 243/285 [03:54<00:35,  1.18it/s]Loading train:  86%|████████▌ | 244/285 [03:55<00:36,  1.11it/s]Loading train:  86%|████████▌ | 245/285 [03:56<00:34,  1.16it/s]Loading train:  86%|████████▋ | 246/285 [03:57<00:35,  1.11it/s]Loading train:  87%|████████▋ | 247/285 [03:58<00:35,  1.06it/s]Loading train:  87%|████████▋ | 248/285 [03:59<00:32,  1.12it/s]Loading train:  87%|████████▋ | 249/285 [04:00<00:31,  1.15it/s]Loading train:  88%|████████▊ | 250/285 [04:01<00:30,  1.15it/s]Loading train:  88%|████████▊ | 251/285 [04:01<00:29,  1.17it/s]Loading train:  88%|████████▊ | 252/285 [04:02<00:29,  1.13it/s]Loading train:  89%|████████▉ | 253/285 [04:03<00:28,  1.13it/s]Loading train:  89%|████████▉ | 254/285 [04:04<00:28,  1.08it/s]Loading train:  89%|████████▉ | 255/285 [04:05<00:27,  1.10it/s]Loading train:  90%|████████▉ | 256/285 [04:06<00:25,  1.14it/s]Loading train:  90%|█████████ | 257/285 [04:07<00:25,  1.10it/s]Loading train:  91%|█████████ | 258/285 [04:08<00:24,  1.10it/s]Loading train:  91%|█████████ | 259/285 [04:09<00:24,  1.07it/s]Loading train:  91%|█████████ | 260/285 [04:10<00:22,  1.10it/s]Loading train:  92%|█████████▏| 261/285 [04:11<00:21,  1.11it/s]Loading train:  92%|█████████▏| 262/285 [04:11<00:19,  1.16it/s]Loading train:  92%|█████████▏| 263/285 [04:12<00:18,  1.19it/s]Loading train:  93%|█████████▎| 264/285 [04:13<00:18,  1.15it/s]Loading train:  93%|█████████▎| 265/285 [04:14<00:18,  1.10it/s]Loading train:  93%|█████████▎| 266/285 [04:15<00:16,  1.13it/s]Loading train:  94%|█████████▎| 267/285 [04:16<00:15,  1.15it/s]Loading train:  94%|█████████▍| 268/285 [04:17<00:15,  1.10it/s]Loading train:  94%|█████████▍| 269/285 [04:18<00:14,  1.08it/s]Loading train:  95%|█████████▍| 270/285 [04:18<00:13,  1.14it/s]Loading train:  95%|█████████▌| 271/285 [04:19<00:11,  1.18it/s]Loading train:  95%|█████████▌| 272/285 [04:20<00:10,  1.21it/s]Loading train:  96%|█████████▌| 273/285 [04:21<00:09,  1.22it/s]Loading train:  96%|█████████▌| 274/285 [04:21<00:08,  1.32it/s]Loading train:  96%|█████████▋| 275/285 [04:22<00:08,  1.23it/s]Loading train:  97%|█████████▋| 276/285 [04:23<00:07,  1.17it/s]Loading train:  97%|█████████▋| 277/285 [04:24<00:06,  1.21it/s]Loading train:  98%|█████████▊| 278/285 [04:25<00:05,  1.22it/s]Loading train:  98%|█████████▊| 279/285 [04:26<00:05,  1.16it/s]Loading train:  98%|█████████▊| 280/285 [04:27<00:04,  1.19it/s]Loading train:  99%|█████████▊| 281/285 [04:28<00:03,  1.15it/s]Loading train:  99%|█████████▉| 282/285 [04:28<00:02,  1.18it/s]Loading train:  99%|█████████▉| 283/285 [04:29<00:01,  1.14it/s]Loading train: 100%|█████████▉| 284/285 [04:30<00:00,  1.06it/s]Loading train: 100%|██████████| 285/285 [04:32<00:00,  1.01s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   4%|▍         | 12/285 [00:00<00:02, 116.31it/s]concatenating: train:  14%|█▍        | 41/285 [00:00<00:01, 141.58it/s]concatenating: train:  26%|██▋       | 75/285 [00:00<00:01, 171.29it/s]concatenating: train:  33%|███▎      | 93/285 [00:00<00:01, 164.04it/s]concatenating: train:  39%|███▉      | 112/285 [00:00<00:01, 170.54it/s]concatenating: train:  48%|████▊     | 137/285 [00:00<00:00, 187.95it/s]concatenating: train:  55%|█████▌    | 157/285 [00:00<00:00, 190.02it/s]concatenating: train:  62%|██████▏   | 177/285 [00:00<00:00, 184.32it/s]concatenating: train:  69%|██████▉   | 196/285 [00:00<00:00, 185.95it/s]concatenating: train:  78%|███████▊  | 222/285 [00:01<00:00, 201.46it/s]concatenating: train:  87%|████████▋ | 247/285 [00:01<00:00, 213.90it/s]concatenating: train:  98%|█████████▊| 279/285 [00:01<00:00, 237.13it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 225.16it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.30s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.28s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.24s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 867.61it/s]2019-07-11 03:11:58.832040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 03:11:58.832152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 03:11:58.832182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 03:11:58.832194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 03:11:58.832635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.08it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.00it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.62it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  7.18it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.79it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.56it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.02it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.87it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.54it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.03it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.72it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  8.89it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.16it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.21it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.93it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.34it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.43it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.54it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.38it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 30)   4080        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 40, 45)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 60)   24360       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 20, 105)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 105)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 105)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 105)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 15)   4065        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 45)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 45)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 10)   4060        dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 10)   40          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 10)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 80, 10)   0           activation_11[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 10)   910         dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 80, 10)   40          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 80, 10)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 80, 10)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 55)   0           dropout_5[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 80, 13)   728         concatenate_7[0][0]              
==================================================================================================
Total params: 131,658
Trainable params: 33,158
Non-trainable params: 98,500
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 14s - loss: 3.3829 - acc: 0.4543 - mDice: 0.0572 - val_loss: 2.7434 - val_acc: 0.8483 - val_mDice: 0.1544

Epoch 00001: val_mDice improved from -inf to 0.15441, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 9s - loss: 1.6203 - acc: 0.8645 - mDice: 0.2115 - val_loss: 1.9905 - val_acc: 0.9073 - val_mDice: 0.2560

Epoch 00002: val_mDice improved from 0.15441 to 0.25599, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 8s - loss: 1.1063 - acc: 0.8740 - mDice: 0.3187 - val_loss: 1.6230 - val_acc: 0.9101 - val_mDice: 0.3263

Epoch 00003: val_mDice improved from 0.25599 to 0.32629, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 8s - loss: 0.9382 - acc: 0.8765 - mDice: 0.3756 - val_loss: 1.7317 - val_acc: 0.9084 - val_mDice: 0.3058

Epoch 00004: val_mDice did not improve from 0.32629
Epoch 5/300
 - 8s - loss: 0.8337 - acc: 0.8787 - mDice: 0.4171 - val_loss: 1.3040 - val_acc: 0.9099 - val_mDice: 0.4224

Epoch 00005: val_mDice improved from 0.32629 to 0.42243, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 8s - loss: 0.7594 - acc: 0.8821 - mDice: 0.4498 - val_loss: 1.3364 - val_acc: 0.9138 - val_mDice: 0.4109

Epoch 00006: val_mDice did not improve from 0.42243
Epoch 7/300
 - 8s - loss: 0.7061 - acc: 0.8866 - mDice: 0.4749 - val_loss: 1.2123 - val_acc: 0.9221 - val_mDice: 0.4417

Epoch 00007: val_mDice improved from 0.42243 to 0.44170, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 8s - loss: 0.6659 - acc: 0.8913 - mDice: 0.4953 - val_loss: 1.1676 - val_acc: 0.9239 - val_mDice: 0.4725

Epoch 00008: val_mDice improved from 0.44170 to 0.47248, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 9s - loss: 0.6339 - acc: 0.8961 - mDice: 0.5123 - val_loss: 1.1357 - val_acc: 0.9252 - val_mDice: 0.4748

Epoch 00009: val_mDice improved from 0.47248 to 0.47483, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 8s - loss: 0.6104 - acc: 0.8998 - mDice: 0.5251 - val_loss: 1.0875 - val_acc: 0.9272 - val_mDice: 0.4990

Epoch 00010: val_mDice improved from 0.47483 to 0.49898, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 8s - loss: 0.5893 - acc: 0.9031 - mDice: 0.5366 - val_loss: 1.0805 - val_acc: 0.9217 - val_mDice: 0.5114

Epoch 00011: val_mDice improved from 0.49898 to 0.51143, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 8s - loss: 0.5712 - acc: 0.9057 - mDice: 0.5469 - val_loss: 1.0436 - val_acc: 0.9278 - val_mDice: 0.5081

Epoch 00012: val_mDice did not improve from 0.51143
Epoch 13/300
 - 8s - loss: 0.5568 - acc: 0.9077 - mDice: 0.5555 - val_loss: 1.1635 - val_acc: 0.9210 - val_mDice: 0.4891

Epoch 00013: val_mDice did not improve from 0.51143
Epoch 14/300
 - 8s - loss: 0.5444 - acc: 0.9093 - mDice: 0.5626 - val_loss: 1.0211 - val_acc: 0.9254 - val_mDice: 0.5213

Epoch 00014: val_mDice improved from 0.51143 to 0.52128, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 8s - loss: 0.5317 - acc: 0.9109 - mDice: 0.5701 - val_loss: 1.0442 - val_acc: 0.9224 - val_mDice: 0.5030

Epoch 00015: val_mDice did not improve from 0.52128
Epoch 16/300
 - 8s - loss: 0.5218 - acc: 0.9122 - mDice: 0.5760 - val_loss: 1.0321 - val_acc: 0.9265 - val_mDice: 0.5083

Epoch 00016: val_mDice did not improve from 0.52128
Epoch 17/300
 - 8s - loss: 0.5158 - acc: 0.9132 - mDice: 0.5798 - val_loss: 1.0239 - val_acc: 0.9282 - val_mDice: 0.4945

Epoch 00017: val_mDice did not improve from 0.52128
Epoch 18/300
 - 9s - loss: 0.5043 - acc: 0.9144 - mDice: 0.5868 - val_loss: 1.0179 - val_acc: 0.9245 - val_mDice: 0.5190

Epoch 00018: val_mDice did not improve from 0.52128
Epoch 19/300
 - 8s - loss: 0.4951 - acc: 0.9153 - mDice: 0.5924 - val_loss: 1.0199 - val_acc: 0.9250 - val_mDice: 0.5105

Epoch 00019: val_mDice did not improve from 0.52128
Epoch 20/300
 - 8s - loss: 0.4920 - acc: 0.9161 - mDice: 0.5945 - val_loss: 0.9989 - val_acc: 0.9302 - val_mDice: 0.5004

Epoch 00020: val_mDice did not improve from 0.52128
Epoch 21/300
 - 8s - loss: 0.4827 - acc: 0.9172 - mDice: 0.6003 - val_loss: 1.0464 - val_acc: 0.9238 - val_mDice: 0.5159

Epoch 00021: val_mDice did not improve from 0.52128
Epoch 22/300
 - 8s - loss: 0.4768 - acc: 0.9176 - mDice: 0.6041 - val_loss: 1.0293 - val_acc: 0.9275 - val_mDice: 0.5111

Epoch 00022: val_mDice did not improve from 0.52128
Epoch 23/300
 - 8s - loss: 0.4718 - acc: 0.9185 - mDice: 0.6072 - val_loss: 0.9526 - val_acc: 0.9307 - val_mDice: 0.5451

Epoch 00023: val_mDice improved from 0.52128 to 0.54509, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 24/300
 - 8s - loss: 0.4673 - acc: 0.9191 - mDice: 0.6100 - val_loss: 1.0028 - val_acc: 0.9288 - val_mDice: 0.5282

Epoch 00024: val_mDice did not improve from 0.54509
Epoch 25/300
 - 8s - loss: 0.4630 - acc: 0.9197 - mDice: 0.6128 - val_loss: 1.0048 - val_acc: 0.9276 - val_mDice: 0.5167

Epoch 00025: val_mDice did not improve from 0.54509
Epoch 26/300
 - 8s - loss: 0.4576 - acc: 0.9204 - mDice: 0.6161 - val_loss: 0.9735 - val_acc: 0.9343 - val_mDice: 0.5273

Epoch 00026: val_mDice did not improve from 0.54509
Epoch 27/300
 - 8s - loss: 0.4529 - acc: 0.9211 - mDice: 0.6193 - val_loss: 0.9762 - val_acc: 0.9294 - val_mDice: 0.5221

Epoch 00027: val_mDice did not improve from 0.54509
Epoch 28/300
 - 8s - loss: 0.4485 - acc: 0.9215 - mDice: 0.6221 - val_loss: 0.9572 - val_acc: 0.9282 - val_mDice: 0.5351

Epoch 00028: val_mDice did not improve from 0.54509
Epoch 29/300
 - 9s - loss: 0.4447 - acc: 0.9219 - mDice: 0.6246 - val_loss: 0.9579 - val_acc: 0.9312 - val_mDice: 0.5180

Epoch 00029: val_mDice did not improve from 0.54509
Epoch 30/300
 - 9s - loss: 0.4428 - acc: 0.9222 - mDice: 0.6260 - val_loss: 1.0624 - val_acc: 0.9310 - val_mDice: 0.4679

Epoch 00030: val_mDice did not improve from 0.54509
Epoch 31/300
 - 8s - loss: 0.4400 - acc: 0.9226 - mDice: 0.6279 - val_loss: 0.8896 - val_acc: 0.9294 - val_mDice: 0.5272

Epoch 00031: val_mDice did not improve from 0.54509
Epoch 32/300
 - 8s - loss: 0.4338 - acc: 0.9231 - mDice: 0.6318 - val_loss: 1.0076 - val_acc: 0.9307 - val_mDice: 0.4892

Epoch 00032: val_mDice did not improve from 0.54509
Epoch 33/300
 - 8s - loss: 0.4308 - acc: 0.9236 - mDice: 0.6339 - val_loss: 0.9493 - val_acc: 0.9319 - val_mDice: 0.5225

Epoch 00033: val_mDice did not improve from 0.54509
Epoch 34/300
 - 8s - loss: 0.4314 - acc: 0.9238 - mDice: 0.6335 - val_loss: 0.9494 - val_acc: 0.9311 - val_mDice: 0.5423

Epoch 00034: val_mDice did not improve from 0.54509
Epoch 35/300
 - 8s - loss: 0.4264 - acc: 0.9241 - mDice: 0.6367 - val_loss: 1.0052 - val_acc: 0.9275 - val_mDice: 0.5186

Epoch 00035: val_mDice did not improve from 0.54509
Epoch 36/300
 - 8s - loss: 0.4241 - acc: 0.9245 - mDice: 0.6382 - val_loss: 0.9369 - val_acc: 0.9324 - val_mDice: 0.5178

Epoch 00036: val_mDice did not improve from 0.54509
Epoch 37/300
 - 8s - loss: 0.4206 - acc: 0.9251 - mDice: 0.6406 - val_loss: 0.9659 - val_acc: 0.9292 - val_mDice: 0.5313

Epoch 00037: val_mDice did not improve from 0.54509
Epoch 38/300
 - 8s - loss: 0.4217 - acc: 0.9250 - mDice: 0.6400 - val_loss: 0.9137 - val_acc: 0.9288 - val_mDice: 0.5273

Epoch 00038: val_mDice did not improve from 0.54509
Epoch 39/300
 - 8s - loss: 0.4145 - acc: 0.9258 - mDice: 0.6446 - val_loss: 0.8886 - val_acc: 0.9303 - val_mDice: 0.5194

Epoch 00039: val_mDice did not improve from 0.54509
Epoch 40/300
 - 8s - loss: 0.4131 - acc: 0.9258 - mDice: 0.6456 - val_loss: 0.8614 - val_acc: 0.9321 - val_mDice: 0.5350

Epoch 00040: val_mDice did not improve from 0.54509
Epoch 41/300
 - 8s - loss: 0.4126 - acc: 0.9261 - mDice: 0.6460 - val_loss: 0.8963 - val_acc: 0.9345 - val_mDice: 0.5203

Epoch 00041: val_mDice did not improve from 0.54509
Epoch 42/300
 - 9s - loss: 0.4075 - acc: 0.9265 - mDice: 0.6496 - val_loss: 0.9828 - val_acc: 0.9165 - val_mDice: 0.5093

Epoch 00042: val_mDice did not improve from 0.54509
Epoch 43/300
 - 8s - loss: 0.4046 - acc: 0.9268 - mDice: 0.6514 - val_loss: 0.9431 - val_acc: 0.9267 - val_mDice: 0.5047

Epoch 00043: val_mDice did not improve from 0.54509
Epoch 44/300
 - 8s - loss: 0.4060 - acc: 0.9267 - mDice: 0.6505 - val_loss: 0.8527 - val_acc: 0.9322 - val_mDice: 0.5297

Epoch 00044: val_mDice did not improve from 0.54509
Epoch 45/300
 - 8s - loss: 0.4032 - acc: 0.9269 - mDice: 0.6524 - val_loss: 0.8638 - val_acc: 0.9352 - val_mDice: 0.5005

Epoch 00045: val_mDice did not improve from 0.54509
Epoch 46/300
 - 8s - loss: 0.4013 - acc: 0.9272 - mDice: 0.6537 - val_loss: 0.8353 - val_acc: 0.9327 - val_mDice: 0.5208

Epoch 00046: val_mDice did not improve from 0.54509
Epoch 47/300
 - 8s - loss: 0.3984 - acc: 0.9277 - mDice: 0.6556 - val_loss: 0.8010 - val_acc: 0.9281 - val_mDice: 0.5401

Epoch 00047: val_mDice did not improve from 0.54509
Epoch 48/300
 - 8s - loss: 0.3987 - acc: 0.9278 - mDice: 0.6555 - val_loss: 0.8319 - val_acc: 0.9308 - val_mDice: 0.5094

Epoch 00048: val_mDice did not improve from 0.54509
Epoch 49/300
 - 8s - loss: 0.3957 - acc: 0.9277 - mDice: 0.6575 - val_loss: 0.8307 - val_acc: 0.9363 - val_mDice: 0.5029

Epoch 00049: val_mDice did not improve from 0.54509
Epoch 50/300
 - 8s - loss: 0.3951 - acc: 0.9280 - mDice: 0.6580 - val_loss: 0.7857 - val_acc: 0.9369 - val_mDice: 0.5243

Epoch 00050: val_mDice did not improve from 0.54509
Epoch 51/300
 - 8s - loss: 0.3940 - acc: 0.9282 - mDice: 0.6587 - val_loss: 0.7985 - val_acc: 0.9284 - val_mDice: 0.5032

Epoch 00051: val_mDice did not improve from 0.54509
Epoch 52/300
 - 8s - loss: 0.3907 - acc: 0.9285 - mDice: 0.6609 - val_loss: 0.7910 - val_acc: 0.9324 - val_mDice: 0.5316

Epoch 00052: val_mDice did not improve from 0.54509
Epoch 53/300
 - 8s - loss: 0.3894 - acc: 0.9288 - mDice: 0.6619 - val_loss: 0.8535 - val_acc: 0.9332 - val_mDice: 0.4998

Epoch 00053: val_mDice did not improve from 0.54509
Epoch 54/300
 - 8s - loss: 0.3844 - acc: 0.9292 - mDice: 0.6653 - val_loss: 0.8135 - val_acc: 0.9295 - val_mDice: 0.5131

Epoch 00054: val_mDice did not improve from 0.54509
Epoch 55/300
 - 9s - loss: 0.3861 - acc: 0.9291 - mDice: 0.6641 - val_loss: 0.7708 - val_acc: 0.9369 - val_mDice: 0.5130

Epoch 00055: val_mDice did not improve from 0.54509
Epoch 56/300
 - 8s - loss: 0.3834 - acc: 0.9292 - mDice: 0.6659 - val_loss: 0.7270 - val_acc: 0.9374 - val_mDice: 0.5332

Epoch 00056: val_mDice did not improve from 0.54509
Epoch 57/300
 - 8s - loss: 0.3830 - acc: 0.9297 - mDice: 0.6664 - val_loss: 0.7847 - val_acc: 0.9358 - val_mDice: 0.5095

Epoch 00057: val_mDice did not improve from 0.54509
Epoch 58/300
 - 8s - loss: 0.3844 - acc: 0.9294 - mDice: 0.6654 - val_loss: 0.8310 - val_acc: 0.9359 - val_mDice: 0.4749

Epoch 00058: val_mDice did not improve from 0.54509
Epoch 59/300
 - 8s - loss: 0.3817 - acc: 0.9297 - mDice: 0.6673 - val_loss: 0.7251 - val_acc: 0.9305 - val_mDice: 0.5300

Epoch 00059: val_mDice did not improve from 0.54509
Epoch 60/300
 - 8s - loss: 0.3785 - acc: 0.9300 - mDice: 0.6695 - val_loss: 0.7692 - val_acc: 0.9367 - val_mDice: 0.5095

Epoch 00060: val_mDice did not improve from 0.54509
Epoch 61/300
 - 8s - loss: 0.3779 - acc: 0.9301 - mDice: 0.6699 - val_loss: 0.8960 - val_acc: 0.9210 - val_mDice: 0.5188

Epoch 00061: val_mDice did not improve from 0.54509
Epoch 62/300
 - 8s - loss: 0.3777 - acc: 0.9301 - mDice: 0.6701 - val_loss: 0.8317 - val_acc: 0.9310 - val_mDice: 0.4982

Epoch 00062: val_mDice did not improve from 0.54509
Epoch 63/300
 - 8s - loss: 0.3750 - acc: 0.9302 - mDice: 0.6719 - val_loss: 0.7079 - val_acc: 0.9362 - val_mDice: 0.5252

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.32s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.07s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.85s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:31,  1.80s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:58,  1.69s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:59,  1.70s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:30,  1.60s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:47,  1.67s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:31,  1.62s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:45,  1.67s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:41,  1.67s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:04,  1.75s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:15,  1.80s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<07:49,  1.71s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:15,  1.81s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<07:53,  1.74s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<08:00,  1.77s/it]predicting train subjects:   5%|▌         | 15/285 [00:26<08:26,  1.88s/it]predicting train subjects:   6%|▌         | 16/285 [00:28<08:30,  1.90s/it]predicting train subjects:   6%|▌         | 17/285 [00:29<07:55,  1.77s/it]predicting train subjects:   6%|▋         | 18/285 [00:31<07:58,  1.79s/it]predicting train subjects:   7%|▋         | 19/285 [00:32<07:35,  1.71s/it]predicting train subjects:   7%|▋         | 20/285 [00:34<07:44,  1.75s/it]predicting train subjects:   7%|▋         | 21/285 [00:36<08:02,  1.83s/it]predicting train subjects:   8%|▊         | 22/285 [00:38<07:37,  1.74s/it]predicting train subjects:   8%|▊         | 23/285 [00:40<07:39,  1.75s/it]predicting train subjects:   8%|▊         | 24/285 [00:41<07:26,  1.71s/it]predicting train subjects:   9%|▉         | 25/285 [00:43<07:46,  1.80s/it]predicting train subjects:   9%|▉         | 26/285 [00:45<07:52,  1.83s/it]predicting train subjects:   9%|▉         | 27/285 [00:47<07:27,  1.74s/it]predicting train subjects:  10%|▉         | 28/285 [00:48<07:33,  1.76s/it]predicting train subjects:  10%|█         | 29/285 [00:50<07:35,  1.78s/it]predicting train subjects:  11%|█         | 30/285 [00:52<07:50,  1.85s/it]predicting train subjects:  11%|█         | 31/285 [00:54<07:52,  1.86s/it]predicting train subjects:  11%|█         | 32/285 [00:56<07:23,  1.75s/it]predicting train subjects:  12%|█▏        | 33/285 [00:57<07:29,  1.78s/it]predicting train subjects:  12%|█▏        | 34/285 [00:59<07:42,  1.84s/it]predicting train subjects:  12%|█▏        | 35/285 [01:01<07:47,  1.87s/it]predicting train subjects:  13%|█▎        | 36/285 [01:03<07:25,  1.79s/it]predicting train subjects:  13%|█▎        | 37/285 [01:05<07:29,  1.81s/it]predicting train subjects:  13%|█▎        | 38/285 [01:07<07:36,  1.85s/it]predicting train subjects:  14%|█▎        | 39/285 [01:08<07:24,  1.81s/it]predicting train subjects:  14%|█▍        | 40/285 [01:10<07:26,  1.82s/it]predicting train subjects:  14%|█▍        | 41/285 [01:12<07:12,  1.77s/it]predicting train subjects:  15%|█▍        | 42/285 [01:14<06:58,  1.72s/it]predicting train subjects:  15%|█▌        | 43/285 [01:16<07:10,  1.78s/it]predicting train subjects:  15%|█▌        | 44/285 [01:18<07:23,  1.84s/it]predicting train subjects:  16%|█▌        | 45/285 [01:19<07:00,  1.75s/it]predicting train subjects:  16%|█▌        | 46/285 [01:21<07:15,  1.82s/it]predicting train subjects:  16%|█▋        | 47/285 [01:23<06:51,  1.73s/it]predicting train subjects:  17%|█▋        | 48/285 [01:25<07:05,  1.80s/it]predicting train subjects:  17%|█▋        | 49/285 [01:26<07:17,  1.86s/it]predicting train subjects:  18%|█▊        | 50/285 [01:28<07:14,  1.85s/it]predicting train subjects:  18%|█▊        | 51/285 [01:30<07:20,  1.88s/it]predicting train subjects:  18%|█▊        | 52/285 [01:32<06:54,  1.78s/it]predicting train subjects:  19%|█▊        | 53/285 [01:34<07:00,  1.81s/it]predicting train subjects:  19%|█▉        | 54/285 [01:36<07:09,  1.86s/it]predicting train subjects:  19%|█▉        | 55/285 [01:37<06:44,  1.76s/it]predicting train subjects:  20%|█▉        | 56/285 [01:39<06:58,  1.83s/it]predicting train subjects:  20%|██        | 57/285 [01:41<06:46,  1.78s/it]predicting train subjects:  20%|██        | 58/285 [01:43<07:03,  1.86s/it]predicting train subjects:  21%|██        | 59/285 [01:45<07:06,  1.89s/it]predicting train subjects:  21%|██        | 60/285 [01:47<07:10,  1.91s/it]predicting train subjects:  21%|██▏       | 61/285 [01:48<06:50,  1.83s/it]predicting train subjects:  22%|██▏       | 62/285 [01:50<06:56,  1.87s/it]predicting train subjects:  22%|██▏       | 63/285 [01:52<06:58,  1.88s/it]predicting train subjects:  22%|██▏       | 64/285 [01:54<06:43,  1.83s/it]predicting train subjects:  23%|██▎       | 65/285 [01:56<06:51,  1.87s/it]predicting train subjects:  23%|██▎       | 66/285 [01:58<06:53,  1.89s/it]predicting train subjects:  24%|██▎       | 67/285 [02:00<06:52,  1.89s/it]predicting train subjects:  24%|██▍       | 68/285 [02:02<06:34,  1.82s/it]predicting train subjects:  24%|██▍       | 69/285 [02:03<06:36,  1.83s/it]predicting train subjects:  25%|██▍       | 70/285 [02:05<06:36,  1.85s/it]predicting train subjects:  25%|██▍       | 71/285 [02:07<06:46,  1.90s/it]predicting train subjects:  25%|██▌       | 72/285 [02:09<06:31,  1.84s/it]predicting train subjects:  26%|██▌       | 73/285 [02:11<06:27,  1.83s/it]predicting train subjects:  26%|██▌       | 74/285 [02:13<06:25,  1.83s/it]predicting train subjects:  26%|██▋       | 75/285 [02:15<06:42,  1.91s/it]predicting train subjects:  27%|██▋       | 76/285 [02:17<06:39,  1.91s/it]predicting train subjects:  27%|██▋       | 77/285 [02:18<06:22,  1.84s/it]predicting train subjects:  27%|██▋       | 78/285 [02:20<06:13,  1.80s/it]predicting train subjects:  28%|██▊       | 79/285 [02:22<06:17,  1.83s/it]predicting train subjects:  28%|██▊       | 80/285 [02:24<06:14,  1.83s/it]predicting train subjects:  28%|██▊       | 81/285 [02:25<06:03,  1.78s/it]predicting train subjects:  29%|██▉       | 82/285 [02:27<06:04,  1.79s/it]predicting train subjects:  29%|██▉       | 83/285 [02:29<05:55,  1.76s/it]predicting train subjects:  29%|██▉       | 84/285 [02:31<05:48,  1.73s/it]predicting train subjects:  30%|██▉       | 85/285 [02:32<05:51,  1.76s/it]predicting train subjects:  30%|███       | 86/285 [02:34<05:58,  1.80s/it]predicting train subjects:  31%|███       | 87/285 [02:36<05:56,  1.80s/it]predicting train subjects:  31%|███       | 88/285 [02:38<05:49,  1.78s/it]predicting train subjects:  31%|███       | 89/285 [02:40<05:48,  1.78s/it]predicting train subjects:  32%|███▏      | 90/285 [02:42<05:57,  1.84s/it]predicting train subjects:  32%|███▏      | 91/285 [02:43<05:49,  1.80s/it]predicting train subjects:  32%|███▏      | 92/285 [02:45<05:51,  1.82s/it]predicting train subjects:  33%|███▎      | 93/285 [02:47<05:38,  1.76s/it]predicting train subjects:  33%|███▎      | 94/285 [02:49<05:41,  1.79s/it]predicting train subjects:  33%|███▎      | 95/285 [02:50<05:44,  1.81s/it]predicting train subjects:  34%|███▎      | 96/285 [02:52<05:42,  1.81s/it]predicting train subjects:  34%|███▍      | 97/285 [02:54<05:44,  1.83s/it]predicting train subjects:  34%|███▍      | 98/285 [02:56<05:42,  1.83s/it]predicting train subjects:  35%|███▍      | 99/285 [02:58<05:39,  1.83s/it]predicting train subjects:  35%|███▌      | 100/285 [03:00<05:46,  1.87s/it]predicting train subjects:  35%|███▌      | 101/285 [03:01<05:34,  1.82s/it]predicting train subjects:  36%|███▌      | 102/285 [03:03<05:35,  1.83s/it]predicting train subjects:  36%|███▌      | 103/285 [03:05<05:31,  1.82s/it]predicting train subjects:  36%|███▋      | 104/285 [03:07<05:28,  1.81s/it]predicting train subjects:  37%|███▋      | 105/285 [03:09<05:31,  1.84s/it]predicting train subjects:  37%|███▋      | 106/285 [03:11<05:24,  1.81s/it]predicting train subjects:  38%|███▊      | 107/285 [03:12<05:24,  1.82s/it]predicting train subjects:  38%|███▊      | 108/285 [03:14<05:19,  1.80s/it]predicting train subjects:  38%|███▊      | 109/285 [03:16<05:16,  1.80s/it]predicting train subjects:  39%|███▊      | 110/285 [03:18<05:21,  1.84s/it]predicting train subjects:  39%|███▉      | 111/285 [03:20<05:10,  1.78s/it]predicting train subjects:  39%|███▉      | 112/285 [03:21<05:11,  1.80s/it]predicting train subjects:  40%|███▉      | 113/285 [03:23<05:22,  1.87s/it]predicting train subjects:  40%|████      | 114/285 [03:25<05:20,  1.87s/it]predicting train subjects:  40%|████      | 115/285 [03:27<05:21,  1.89s/it]predicting train subjects:  41%|████      | 116/285 [03:29<05:21,  1.91s/it]predicting train subjects:  41%|████      | 117/285 [03:31<05:10,  1.85s/it]predicting train subjects:  41%|████▏     | 118/285 [03:33<04:59,  1.79s/it]predicting train subjects:  42%|████▏     | 119/285 [03:35<05:04,  1.83s/it]predicting train subjects:  42%|████▏     | 120/285 [03:36<04:56,  1.79s/it]predicting train subjects:  42%|████▏     | 121/285 [03:38<04:45,  1.74s/it]predicting train subjects:  43%|████▎     | 122/285 [03:39<04:37,  1.70s/it]predicting train subjects:  43%|████▎     | 123/285 [03:41<04:22,  1.62s/it]predicting train subjects:  44%|████▎     | 124/285 [03:43<04:23,  1.63s/it]predicting train subjects:  44%|████▍     | 125/285 [03:44<04:21,  1.63s/it]predicting train subjects:  44%|████▍     | 126/285 [03:46<04:13,  1.60s/it]predicting train subjects:  45%|████▍     | 127/285 [03:47<04:03,  1.54s/it]predicting train subjects:  45%|████▍     | 128/285 [03:49<04:08,  1.58s/it]predicting train subjects:  45%|████▌     | 129/285 [03:50<04:01,  1.55s/it]predicting train subjects:  46%|████▌     | 130/285 [03:52<03:54,  1.51s/it]predicting train subjects:  46%|████▌     | 131/285 [03:53<03:55,  1.53s/it]predicting train subjects:  46%|████▋     | 132/285 [03:55<04:01,  1.58s/it]predicting train subjects:  47%|████▋     | 133/285 [03:56<03:56,  1.55s/it]predicting train subjects:  47%|████▋     | 134/285 [03:58<03:51,  1.54s/it]predicting train subjects:  47%|████▋     | 135/285 [03:59<03:47,  1.52s/it]predicting train subjects:  48%|████▊     | 136/285 [04:01<03:45,  1.51s/it]predicting train subjects:  48%|████▊     | 137/285 [04:03<03:52,  1.57s/it]predicting train subjects:  48%|████▊     | 138/285 [04:04<03:49,  1.56s/it]predicting train subjects:  49%|████▉     | 139/285 [04:06<03:57,  1.62s/it]predicting train subjects:  49%|████▉     | 140/285 [04:07<03:53,  1.61s/it]predicting train subjects:  49%|████▉     | 141/285 [04:09<03:41,  1.54s/it]predicting train subjects:  50%|████▉     | 142/285 [04:10<03:43,  1.57s/it]predicting train subjects:  50%|█████     | 143/285 [04:12<03:37,  1.53s/it]predicting train subjects:  51%|█████     | 144/285 [04:14<03:39,  1.55s/it]predicting train subjects:  51%|█████     | 145/285 [04:15<03:35,  1.54s/it]predicting train subjects:  51%|█████     | 146/285 [04:17<03:37,  1.56s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:18<03:32,  1.54s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:20<03:33,  1.56s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:21<03:27,  1.53s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:23<03:22,  1.50s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:24<03:29,  1.56s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:26<03:24,  1.54s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:27<03:17,  1.49s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:29<03:20,  1.53s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:30<03:19,  1.53s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:32<03:22,  1.57s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:34<03:22,  1.59s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:35<03:19,  1.57s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:37<03:15,  1.55s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:38<03:10,  1.53s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:40<03:12,  1.55s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:41<03:09,  1.54s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:43<03:11,  1.57s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:44<03:06,  1.54s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:46<03:03,  1.53s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:48<03:07,  1.57s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:49<03:09,  1.61s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:51<03:02,  1.56s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:52<03:02,  1.57s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:54<02:57,  1.54s/it]predicting train subjects:  60%|██████    | 171/285 [04:55<02:52,  1.52s/it]predicting train subjects:  60%|██████    | 172/285 [04:57<02:53,  1.54s/it]predicting train subjects:  61%|██████    | 173/285 [04:58<02:55,  1.57s/it]predicting train subjects:  61%|██████    | 174/285 [05:00<02:51,  1.54s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:02<02:54,  1.58s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:03<02:57,  1.63s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:05<02:50,  1.58s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:06<02:43,  1.53s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:08<02:38,  1.49s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:10<02:48,  1.60s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:11<02:49,  1.63s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:13<02:48,  1.63s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:14<02:40,  1.57s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:16<02:35,  1.54s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:17<02:29,  1.49s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:19<02:39,  1.61s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:21<02:45,  1.69s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:23<02:51,  1.76s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:24<02:39,  1.66s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:26<02:38,  1.67s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:28<02:40,  1.71s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:29<02:39,  1.71s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:31<02:29,  1.62s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:32<02:21,  1.56s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:34<02:17,  1.53s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:36<02:27,  1.65s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:38<02:31,  1.72s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:40<02:36,  1.80s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:41<02:24,  1.68s/it]predicting train subjects:  70%|███████   | 200/285 [05:42<02:17,  1.61s/it]predicting train subjects:  71%|███████   | 201/285 [05:44<02:22,  1.69s/it]predicting train subjects:  71%|███████   | 202/285 [05:46<02:20,  1.70s/it]predicting train subjects:  71%|███████   | 203/285 [05:48<02:18,  1.69s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:49<02:10,  1.61s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:51<02:04,  1.56s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:52<01:59,  1.51s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:54<02:07,  1.64s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:56<02:14,  1.74s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:58<02:16,  1.80s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:59<02:07,  1.69s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:01<01:58,  1.61s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:02<01:58,  1.62s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:04<01:57,  1.64s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:05<01:51,  1.57s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:07<01:57,  1.67s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:09<01:50,  1.60s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:11<01:54,  1.69s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:13<01:59,  1.78s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:14<01:58,  1.80s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:16<01:48,  1.67s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:17<01:43,  1.61s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:19<01:44,  1.65s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:20<01:38,  1.59s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:22<01:35,  1.57s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:23<01:32,  1.54s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:25<01:38,  1.68s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:27<01:42,  1.76s/it]predicting train subjects:  80%|████████  | 228/285 [06:29<01:43,  1.81s/it]predicting train subjects:  80%|████████  | 229/285 [06:31<01:39,  1.77s/it]predicting train subjects:  81%|████████  | 230/285 [06:32<01:32,  1.67s/it]predicting train subjects:  81%|████████  | 231/285 [06:34<01:27,  1.62s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:36<01:28,  1.66s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:37<01:22,  1.59s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:39<01:24,  1.67s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:40<01:20,  1.62s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:42<01:23,  1.71s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:44<01:24,  1.77s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:46<01:24,  1.80s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:48<01:19,  1.73s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:49<01:13,  1.62s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:51<01:08,  1.56s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:52<01:04,  1.50s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:53<01:01,  1.45s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:55<01:04,  1.58s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:57<01:02,  1.55s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:59<01:04,  1.66s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:00<01:04,  1.70s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:02<01:02,  1.69s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:03<00:58,  1.62s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:05<00:55,  1.58s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:06<00:52,  1.53s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:08<00:49,  1.49s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:10<00:50,  1.59s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:11<00:51,  1.65s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:13<00:50,  1.68s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:15<00:46,  1.60s/it]predicting train subjects:  90%|█████████ | 257/285 [07:16<00:44,  1.59s/it]predicting train subjects:  91%|█████████ | 258/285 [07:18<00:45,  1.69s/it]predicting train subjects:  91%|█████████ | 259/285 [07:20<00:43,  1.68s/it]predicting train subjects:  91%|█████████ | 260/285 [07:21<00:40,  1.61s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:23<00:38,  1.60s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:24<00:35,  1.56s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:26<00:33,  1.52s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:28<00:34,  1.66s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:29<00:34,  1.73s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:31<00:30,  1.62s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:32<00:28,  1.58s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:34<00:28,  1.69s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:36<00:27,  1.70s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:37<00:24,  1.62s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:39<00:22,  1.60s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:41<00:21,  1.65s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:42<00:19,  1.61s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:44<00:17,  1.57s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:46<00:16,  1.70s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:48<00:15,  1.74s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:49<00:13,  1.63s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:50<00:11,  1.59s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:52<00:09,  1.61s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:54<00:07,  1.56s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:55<00:06,  1.52s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:56<00:04,  1.48s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:58<00:03,  1.60s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:00<00:01,  1.68s/it]predicting train subjects: 100%|██████████| 285/285 [08:02<00:00,  1.76s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:50,  1.87s/it]Loading train:   1%|          | 2/285 [00:03<08:08,  1.73s/it]Loading train:   1%|          | 3/285 [00:05<08:49,  1.88s/it]
Epoch 00063: val_mDice did not improve from 0.54509
Restoring model weights from the end of the best epoch
Epoch 00063: early stopping
{'val_loss': [2.74338622320266, 1.990471022469657, 1.6229886327471053, 1.7316602979387556, 1.303991192863101, 1.3364462511880058, 1.212303842817034, 1.1675908792586553, 1.1356926986149378, 1.0875135489872523, 1.080477203641619, 1.043607575552804, 1.1635304519108363, 1.0210947536286854, 1.0441519419352214, 1.0320563089279902, 1.0238837855202811, 1.0178524993714833, 1.0199278309231712, 0.9989466667175293, 1.0464403515770322, 1.0293463525317965, 0.9525955063956124, 1.0027967521122523, 1.0047926902770996, 0.9735079606374105, 0.9762365477425712, 0.9571656272524879, 0.9579455966041202, 1.0623619669959659, 0.8896188735961914, 1.0075622740246, 0.9492743015289307, 0.949435483841669, 1.0051553703489757, 0.9368516377040318, 0.9659034184047154, 0.9136753309340704, 0.8886234760284424, 0.861432189033145, 0.8962826274690174, 0.98282333782741, 0.9431460925510952, 0.8526520956130255, 0.8637846992129371, 0.8353163628351121, 0.8010371526082357, 0.8318686939421154, 0.830683049701509, 0.7857292833782378, 0.7985082353864398, 0.7909748667762393, 0.8535189401535761, 0.8134825570242745, 0.7708028725215367, 0.7269702979496547, 0.7847115425836473, 0.8310006913684663, 0.7251384485335577, 0.7692242349897113, 0.896010330745152, 0.831741696312314, 0.7079343909309024], 'val_acc': [0.8483058838617235, 0.9072847933996291, 0.9100824367432367, 0.9083630811600458, 0.909945065066928, 0.9138278336752028, 0.9221085139683315, 0.9239377294267926, 0.9251900144985744, 0.9271726437977382, 0.9217422008514404, 0.9277678671337309, 0.9210142067500523, 0.9254029478345599, 0.9223992824554443, 0.9265293166750953, 0.9281822102410453, 0.9245031930151439, 0.9249542270387922, 0.9302243363289606, 0.9237614330791292, 0.9274999783152625, 0.930675364675976, 0.9287614623705546, 0.927591587815966, 0.9343314965566, 0.9293955933480036, 0.9281753840900603, 0.9311561357407343, 0.930952373005095, 0.9293726881345113, 0.9306547471455165, 0.931875018846421, 0.9311011660666693, 0.9275160006114415, 0.9324198507127308, 0.9291826742036002, 0.9287934956096467, 0.9302976074672881, 0.9320581668899173, 0.9345444128626869, 0.9164858290127346, 0.9266895680200486, 0.9321795077550978, 0.9352472310974485, 0.9327449741817656, 0.9281089561326163, 0.9308219041143145, 0.9362522874559674, 0.93694368714378, 0.9283837108384996, 0.9323511776470003, 0.933193686462584, 0.9295260821069989, 0.9368887572061448, 0.937364935874939, 0.9358425026848203, 0.9358653766768319, 0.9305265772910345, 0.9367238935970125, 0.9210165114629836, 0.9310393929481506, 0.9362294219789051], 'val_mDice': [0.15441287362149783, 0.2559897455253771, 0.3262933533461321, 0.3058449246344112, 0.42243415028566406, 0.4109237939119339, 0.44169721237960313, 0.47247956622214543, 0.4748326383885883, 0.4989776157197498, 0.5114288503925005, 0.5081332267395088, 0.4890521388678324, 0.5212801613268399, 0.5030330916245779, 0.508281145067442, 0.49452809599183856, 0.5189598607165473, 0.510478722907248, 0.5004111567423457, 0.5158568528436479, 0.5110674564327512, 0.5450881306259405, 0.5281500184819812, 0.5166971809452489, 0.5272772613735426, 0.5220707275328182, 0.5350649977723757, 0.5179651704217706, 0.46790502149434315, 0.5272237566255388, 0.489206306991123, 0.5225223558289664, 0.5423380212769622, 0.5185886507942563, 0.5177694415407521, 0.5312952416993323, 0.527269649718489, 0.5193525208603769, 0.5349956584118661, 0.5203091062250591, 0.5092730287994657, 0.5046728111448742, 0.529709976698671, 0.5004593572091489, 0.5208486322136152, 0.5401058619221052, 0.5094086691027596, 0.5029489341236296, 0.5243357274503935, 0.5032262550223441, 0.5315879210829735, 0.4997619142134984, 0.5130588174575851, 0.5130044917265574, 0.5332366054256757, 0.5095267421787694, 0.47488799283192273, 0.5300163035946233, 0.5095324541131655, 0.5187797908272062, 0.49824732896827517, 0.5251962244510651], 'loss': [3.3829185240112887, 1.620293637036312, 1.10627040344556, 0.9381643512218196, 0.8337403778880921, 0.7594254914565608, 0.7061491355124709, 0.6659277643062532, 0.633882251495062, 0.6103694320000824, 0.5892948876209564, 0.5711995810356493, 0.5568174151457733, 0.5443758627732687, 0.531724843453506, 0.5218218059720896, 0.5157803051476766, 0.5042803334332578, 0.4951221595983503, 0.49200607425150256, 0.48274298290629963, 0.47679485463098636, 0.4717599518765184, 0.46726036896842604, 0.46297556770337395, 0.4576426371687843, 0.4529497679865197, 0.4485274705499359, 0.444749966892912, 0.44283124699352655, 0.440007713636452, 0.4338159710657213, 0.43080430671339986, 0.4314174075128486, 0.4264130933576175, 0.4241042481823328, 0.4205749090900995, 0.42171280140910783, 0.4145130424031132, 0.41305799293040035, 0.4126369135616969, 0.4074727942345113, 0.40456014480323305, 0.4060419845068549, 0.4032184480069482, 0.40134801838998735, 0.39838282248866747, 0.39868228770368747, 0.39569116259255527, 0.3951458870181004, 0.3939644701108092, 0.39072359109834964, 0.38936786106240895, 0.38436224744088715, 0.38605810611928754, 0.38338857650733854, 0.38300815048258224, 0.38436401836072775, 0.3817360957727879, 0.3784669167519259, 0.3779267236541548, 0.37772008279097524, 0.3749857672623226], 'acc': [0.4543330893207773, 0.8644988293451957, 0.873978376262147, 0.8764786176399295, 0.8787122912114587, 0.8820906293881705, 0.8866468135598585, 0.8913386962030903, 0.8961469847870535, 0.8998250063384501, 0.9031447648588393, 0.9057477045684323, 0.9077130251246104, 0.9093184369088874, 0.9108782957715751, 0.912153164189469, 0.9131596795690297, 0.9144391364873846, 0.9152975097335968, 0.9160680687333294, 0.9172002693488461, 0.9176152955826156, 0.9184778054164557, 0.9190740555565046, 0.9196910305544432, 0.9203787478656927, 0.9210824550450687, 0.9214572131760161, 0.9219196049468881, 0.9222330956048121, 0.9225502726382228, 0.9231293402197092, 0.9235601264984133, 0.9237814363036883, 0.9241289937337608, 0.9245400394528317, 0.9251133063199412, 0.925014087764059, 0.9258105062739753, 0.9257906694528981, 0.9261226527879802, 0.9265118248434638, 0.9268039494482841, 0.9267336259647581, 0.9269473800453258, 0.9271918458931244, 0.9276518992360029, 0.927836834959196, 0.9277339532859343, 0.9280085833012449, 0.9282254006032059, 0.9285300204421552, 0.9287964484124875, 0.929195469989008, 0.9290708528793178, 0.9292016558640721, 0.9296683369400829, 0.9293879783978599, 0.9296516745518415, 0.9300132508288924, 0.9300893709244515, 0.9301448886923553, 0.9301979071790137], 'mDice': [0.05718468326636424, 0.21151901598562273, 0.31873564468382504, 0.37555290057936314, 0.4170530759026509, 0.44975501755103453, 0.47492295413985286, 0.49529531102247587, 0.512260563897103, 0.525134998800117, 0.5365617504371759, 0.5469071103792464, 0.5555262116538277, 0.5626301265806276, 0.5700908782097424, 0.5759999632996264, 0.5798480121621006, 0.5868051836939706, 0.5923679845972467, 0.5944884611573411, 0.600258417664545, 0.6040526581610332, 0.6071765025801481, 0.6099567442862358, 0.6128281119335404, 0.6161471418684472, 0.6193251910181158, 0.6220519463864737, 0.6246097003974642, 0.6259690125898196, 0.6278550034661455, 0.6318363153293272, 0.6338881904825623, 0.6334687874729472, 0.6367153860204868, 0.638210870568316, 0.6406395732724462, 0.6400143652263808, 0.6446426013588377, 0.6455599982912701, 0.6460446322357262, 0.6495684861263513, 0.6513667001943955, 0.6504741081939581, 0.6524288520110648, 0.6536854098981715, 0.6555863939913706, 0.6555057961126731, 0.6575327361735485, 0.6579734264528772, 0.6586898719273897, 0.6608729803748321, 0.6618952251753872, 0.6652847195788572, 0.6641427671056688, 0.6659446135867141, 0.6664186315842624, 0.6653626920263593, 0.6672711669651786, 0.6695362948511799, 0.6698518895978801, 0.6700913039663979, 0.6718583160083786]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      Loading train:   1%|▏         | 4/285 [00:07<09:14,  1.97s/it]Loading train:   2%|▏         | 5/285 [00:09<09:27,  2.03s/it]Loading train:   2%|▏         | 6/285 [00:11<08:55,  1.92s/it]Loading train:   2%|▏         | 7/285 [00:13<09:01,  1.95s/it]Loading train:   3%|▎         | 8/285 [00:15<08:40,  1.88s/it]Loading train:   3%|▎         | 9/285 [00:17<09:07,  1.98s/it]Loading train:   4%|▎         | 10/285 [00:19<08:44,  1.91s/it]Loading train:   4%|▍         | 11/285 [00:20<08:06,  1.77s/it]Loading train:   4%|▍         | 12/285 [00:22<08:06,  1.78s/it]Loading train:   5%|▍         | 13/285 [00:24<07:47,  1.72s/it]Loading train:   5%|▍         | 14/285 [00:25<07:28,  1.65s/it]Loading train:   5%|▌         | 15/285 [00:27<07:35,  1.69s/it]Loading train:   6%|▌         | 16/285 [00:29<08:01,  1.79s/it]Loading train:   6%|▌         | 17/285 [00:30<07:26,  1.67s/it]Loading train:   6%|▋         | 18/285 [00:32<07:16,  1.63s/it]Loading train:   7%|▋         | 19/285 [00:33<06:41,  1.51s/it]Loading train:   7%|▋         | 20/285 [00:35<06:46,  1.53s/it]Loading train:   7%|▋         | 21/285 [00:36<06:56,  1.58s/it]Loading train:   8%|▊         | 22/285 [00:38<06:52,  1.57s/it]Loading train:   8%|▊         | 23/285 [00:39<06:27,  1.48s/it]Loading train:   8%|▊         | 24/285 [00:40<06:19,  1.45s/it]Loading train:   9%|▉         | 25/285 [00:42<06:21,  1.47s/it]Loading train:   9%|▉         | 26/285 [00:44<06:40,  1.54s/it]Loading train:   9%|▉         | 27/285 [00:45<06:14,  1.45s/it]Loading train:  10%|▉         | 28/285 [00:46<06:11,  1.44s/it]Loading train:  10%|█         | 29/285 [00:48<06:00,  1.41s/it]Loading train:  11%|█         | 30/285 [00:50<06:37,  1.56s/it]Loading train:  11%|█         | 31/285 [00:52<07:29,  1.77s/it]Loading train:  11%|█         | 32/285 [00:53<07:05,  1.68s/it]Loading train:  12%|█▏        | 33/285 [00:55<06:45,  1.61s/it]Loading train:  12%|█▏        | 34/285 [00:56<06:39,  1.59s/it]Loading train:  12%|█▏        | 35/285 [00:58<06:36,  1.59s/it]Loading train:  13%|█▎        | 36/285 [00:59<06:06,  1.47s/it]Loading train:  13%|█▎        | 37/285 [01:00<05:56,  1.44s/it]Loading train:  13%|█▎        | 38/285 [01:02<06:05,  1.48s/it]Loading train:  14%|█▎        | 39/285 [01:03<05:46,  1.41s/it]Loading train:  14%|█▍        | 40/285 [01:05<05:36,  1.37s/it]Loading train:  14%|█▍        | 41/285 [01:06<05:36,  1.38s/it]Loading train:  15%|█▍        | 42/285 [01:07<05:38,  1.39s/it]Loading train:  15%|█▌        | 43/285 [01:09<05:31,  1.37s/it]Loading train:  15%|█▌        | 44/285 [01:10<05:56,  1.48s/it]Loading train:  16%|█▌        | 45/285 [01:12<05:45,  1.44s/it]Loading train:  16%|█▌        | 46/285 [01:13<05:47,  1.45s/it]Loading train:  16%|█▋        | 47/285 [01:14<05:29,  1.38s/it]Loading train:  17%|█▋        | 48/285 [01:16<05:48,  1.47s/it]Loading train:  17%|█▋        | 49/285 [01:18<06:43,  1.71s/it]Loading train:  18%|█▊        | 50/285 [01:20<06:30,  1.66s/it]Loading train:  18%|█▊        | 51/285 [01:22<07:12,  1.85s/it]Loading train:  18%|█▊        | 52/285 [01:25<07:39,  1.97s/it]Loading train:  19%|█▊        | 53/285 [01:26<07:18,  1.89s/it]Loading train:  19%|█▉        | 54/285 [01:28<07:22,  1.91s/it]Loading train:  19%|█▉        | 55/285 [01:30<07:18,  1.91s/it]Loading train:  20%|█▉        | 56/285 [01:32<07:29,  1.96s/it]Loading train:  20%|██        | 57/285 [01:34<07:08,  1.88s/it]Loading train:  20%|██        | 58/285 [01:36<07:17,  1.93s/it]Loading train:  21%|██        | 59/285 [01:38<07:34,  2.01s/it]Loading train:  21%|██        | 60/285 [01:41<08:36,  2.30s/it]Loading train:  21%|██▏       | 61/285 [01:43<07:54,  2.12s/it]Loading train:  22%|██▏       | 62/285 [01:44<07:25,  2.00s/it]Loading train:  22%|██▏       | 63/285 [01:46<07:12,  1.95s/it]Loading train:  22%|██▏       | 64/285 [01:49<07:38,  2.07s/it]Loading train:  23%|██▎       | 65/285 [01:52<08:31,  2.32s/it]Loading train:  23%|██▎       | 66/285 [01:55<09:27,  2.59s/it]Loading train:  24%|██▎       | 67/285 [01:57<08:41,  2.39s/it]Loading train:  24%|██▍       | 68/285 [01:59<08:55,  2.47s/it]Loading train:  24%|██▍       | 69/285 [02:01<08:05,  2.25s/it]Loading train:  25%|██▍       | 70/285 [02:03<08:03,  2.25s/it]Loading train:  25%|██▍       | 71/285 [02:05<07:50,  2.20s/it]Loading train:  25%|██▌       | 72/285 [02:07<07:28,  2.11s/it]Loading train:  26%|██▌       | 73/285 [02:10<07:38,  2.16s/it]Loading train:  26%|██▌       | 74/285 [02:12<07:52,  2.24s/it]Loading train:  26%|██▋       | 75/285 [02:15<08:11,  2.34s/it]Loading train:  27%|██▋       | 76/285 [02:16<07:23,  2.12s/it]Loading train:  27%|██▋       | 77/285 [02:19<07:33,  2.18s/it]Loading train:  27%|██▋       | 78/285 [02:21<07:55,  2.30s/it]Loading train:  28%|██▊       | 79/285 [02:23<07:57,  2.32s/it]Loading train:  28%|██▊       | 80/285 [02:26<08:29,  2.48s/it]Loading train:  28%|██▊       | 81/285 [02:29<08:34,  2.52s/it]Loading train:  29%|██▉       | 82/285 [02:31<08:09,  2.41s/it]Loading train:  29%|██▉       | 83/285 [02:33<07:34,  2.25s/it]Loading train:  29%|██▉       | 84/285 [02:35<07:46,  2.32s/it]Loading train:  30%|██▉       | 85/285 [02:37<07:23,  2.22s/it]Loading train:  30%|███       | 86/285 [02:40<07:42,  2.32s/it]Loading train:  31%|███       | 87/285 [02:43<07:49,  2.37s/it]Loading train:  31%|███       | 88/285 [02:44<07:08,  2.18s/it]Loading train:  31%|███       | 89/285 [02:46<07:04,  2.17s/it]Loading train:  32%|███▏      | 90/285 [02:49<07:07,  2.19s/it]Loading train:  32%|███▏      | 91/285 [02:52<07:45,  2.40s/it]Loading train:  32%|███▏      | 92/285 [02:54<07:58,  2.48s/it]Loading train:  33%|███▎      | 93/285 [02:56<07:27,  2.33s/it]Loading train:  33%|███▎      | 94/285 [02:58<07:22,  2.31s/it]Loading train:  33%|███▎      | 95/285 [03:01<07:51,  2.48s/it]Loading train:  34%|███▎      | 96/285 [03:04<07:35,  2.41s/it]Loading train:  34%|███▍      | 97/285 [03:06<07:07,  2.27s/it]Loading train:  34%|███▍      | 98/285 [03:08<07:05,  2.27s/it]Loading train:  35%|███▍      | 99/285 [03:10<06:52,  2.22s/it]Loading train:  35%|███▌      | 100/285 [03:12<06:51,  2.22s/it]Loading train:  35%|███▌      | 101/285 [03:14<06:34,  2.14s/it]Loading train:  36%|███▌      | 102/285 [03:16<06:44,  2.21s/it]Loading train:  36%|███▌      | 103/285 [03:19<07:05,  2.34s/it]Loading train:  36%|███▋      | 104/285 [03:21<06:53,  2.29s/it]Loading train:  37%|███▋      | 105/285 [03:23<06:39,  2.22s/it]Loading train:  37%|███▋      | 106/285 [03:25<06:35,  2.21s/it]Loading train:  38%|███▊      | 107/285 [03:28<06:53,  2.32s/it]Loading train:  38%|███▊      | 108/285 [03:30<06:30,  2.20s/it]Loading train:  38%|███▊      | 109/285 [03:32<06:28,  2.20s/it]Loading train:  39%|███▊      | 110/285 [03:34<06:15,  2.14s/it]Loading train:  39%|███▉      | 111/285 [03:37<06:29,  2.24s/it]Loading train:  39%|███▉      | 112/285 [03:39<06:18,  2.19s/it]Loading train:  40%|███▉      | 113/285 [03:41<06:08,  2.14s/it]Loading train:  40%|████      | 114/285 [03:42<05:43,  2.01s/it]Loading train:  40%|████      | 115/285 [03:45<06:11,  2.18s/it]Loading train:  41%|████      | 116/285 [03:48<06:31,  2.32s/it]Loading train:  41%|████      | 117/285 [03:50<06:51,  2.45s/it]Loading train:  41%|████▏     | 118/285 [03:52<06:19,  2.27s/it]Loading train:  42%|████▏     | 119/285 [03:55<06:14,  2.26s/it]Loading train:  42%|████▏     | 120/285 [03:57<06:11,  2.25s/it]Loading train:  42%|████▏     | 121/285 [04:00<06:34,  2.41s/it]Loading train:  43%|████▎     | 122/285 [04:02<06:33,  2.41s/it]Loading train:  43%|████▎     | 123/285 [04:05<06:52,  2.54s/it]Loading train:  44%|████▎     | 124/285 [04:08<07:16,  2.71s/it]Loading train:  44%|████▍     | 125/285 [04:11<07:09,  2.68s/it]Loading train:  44%|████▍     | 126/285 [04:13<06:55,  2.61s/it]Loading train:  45%|████▍     | 127/285 [04:15<06:06,  2.32s/it]Loading train:  45%|████▍     | 128/285 [04:17<05:51,  2.24s/it]Loading train:  45%|████▌     | 129/285 [04:19<05:38,  2.17s/it]Loading train:  46%|████▌     | 130/285 [04:20<05:19,  2.06s/it]Loading train:  46%|████▌     | 131/285 [04:22<04:47,  1.87s/it]Loading train:  46%|████▋     | 132/285 [04:24<04:39,  1.83s/it]Loading train:  47%|████▋     | 133/285 [04:26<04:41,  1.85s/it]Loading train:  47%|████▋     | 134/285 [04:28<04:46,  1.89s/it]Loading train:  47%|████▋     | 135/285 [04:29<04:43,  1.89s/it]Loading train:  48%|████▊     | 136/285 [04:32<05:12,  2.10s/it]Loading train:  48%|████▊     | 137/285 [04:34<05:05,  2.07s/it]Loading train:  48%|████▊     | 138/285 [04:36<05:04,  2.07s/it]Loading train:  49%|████▉     | 139/285 [04:38<04:56,  2.03s/it]Loading train:  49%|████▉     | 140/285 [04:40<04:46,  1.98s/it]Loading train:  49%|████▉     | 141/285 [04:41<04:15,  1.78s/it]Loading train:  50%|████▉     | 142/285 [04:43<04:12,  1.77s/it]Loading train:  50%|█████     | 143/285 [04:45<04:20,  1.83s/it]Loading train:  51%|█████     | 144/285 [04:47<04:22,  1.86s/it]Loading train:  51%|█████     | 145/285 [04:49<04:18,  1.85s/it]Loading train:  51%|█████     | 146/285 [04:51<04:36,  1.99s/it]Loading train:  52%|█████▏    | 147/285 [04:54<04:59,  2.17s/it]Loading train:  52%|█████▏    | 148/285 [04:55<04:38,  2.03s/it]Loading train:  52%|█████▏    | 149/285 [04:57<04:34,  2.02s/it]Loading train:  53%|█████▎    | 150/285 [04:59<04:22,  1.95s/it]Loading train:  53%|█████▎    | 151/285 [05:01<04:19,  1.93s/it]Loading train:  53%|█████▎    | 152/285 [05:03<04:02,  1.83s/it]Loading train:  54%|█████▎    | 153/285 [05:04<04:02,  1.84s/it]Loading train:  54%|█████▍    | 154/285 [05:06<03:52,  1.77s/it]Loading train:  54%|█████▍    | 155/285 [05:08<04:07,  1.90s/it]Loading train:  55%|█████▍    | 156/285 [05:10<04:00,  1.87s/it]Loading train:  55%|█████▌    | 157/285 [05:12<04:08,  1.94s/it]Loading train:  55%|█████▌    | 158/285 [05:14<04:17,  2.03s/it]Loading train:  56%|█████▌    | 159/285 [05:16<04:11,  1.99s/it]Loading train:  56%|█████▌    | 160/285 [05:18<04:12,  2.02s/it]Loading train:  56%|█████▋    | 161/285 [05:20<03:43,  1.81s/it]Loading train:  57%|█████▋    | 162/285 [05:21<03:39,  1.78s/it]Loading train:  57%|█████▋    | 163/285 [05:23<03:36,  1.78s/it]Loading train:  58%|█████▊    | 164/285 [05:25<03:50,  1.91s/it]Loading train:  58%|█████▊    | 165/285 [05:27<03:48,  1.90s/it]Loading train:  58%|█████▊    | 166/285 [05:29<03:44,  1.89s/it]Loading train:  59%|█████▊    | 167/285 [05:31<03:42,  1.89s/it]Loading train:  59%|█████▉    | 168/285 [05:33<03:42,  1.90s/it]Loading train:  59%|█████▉    | 169/285 [05:35<03:38,  1.89s/it]Loading train:  60%|█████▉    | 170/285 [05:37<03:37,  1.89s/it]Loading train:  60%|██████    | 171/285 [05:39<03:42,  1.95s/it]Loading train:  60%|██████    | 172/285 [05:41<03:44,  1.99s/it]Loading train:  61%|██████    | 173/285 [05:43<03:47,  2.03s/it]Loading train:  61%|██████    | 174/285 [05:45<03:48,  2.06s/it]Loading train:  61%|██████▏   | 175/285 [05:47<03:44,  2.04s/it]Loading train:  62%|██████▏   | 176/285 [05:49<03:39,  2.02s/it]Loading train:  62%|██████▏   | 177/285 [05:51<03:25,  1.90s/it]Loading train:  62%|██████▏   | 178/285 [05:52<03:20,  1.87s/it]Loading train:  63%|██████▎   | 179/285 [05:55<03:28,  1.97s/it]Loading train:  63%|██████▎   | 180/285 [05:58<03:54,  2.23s/it]Loading train:  64%|██████▎   | 181/285 [06:00<03:52,  2.24s/it]Loading train:  64%|██████▍   | 182/285 [06:02<03:45,  2.19s/it]Loading train:  64%|██████▍   | 183/285 [06:04<03:41,  2.17s/it]Loading train:  65%|██████▍   | 184/285 [06:06<03:34,  2.13s/it]Loading train:  65%|██████▍   | 185/285 [06:08<03:36,  2.16s/it]Loading train:  65%|██████▌   | 186/285 [06:10<03:28,  2.11s/it]Loading train:  66%|██████▌   | 187/285 [06:12<03:28,  2.12s/it]Loading train:  66%|██████▌   | 188/285 [06:15<03:34,  2.22s/it]Loading train:  66%|██████▋   | 189/285 [06:17<03:23,  2.12s/it]Loading train:  67%|██████▋   | 190/285 [06:19<03:16,  2.07s/it]Loading train:  67%|██████▋   | 191/285 [06:21<03:17,  2.10s/it]Loading train:  67%|██████▋   | 192/285 [06:23<03:12,  2.07s/it]Loading train:  68%|██████▊   | 193/285 [06:25<03:00,  1.96s/it]Loading train:  68%|██████▊   | 194/285 [06:26<02:57,  1.95s/it]Loading train:  68%|██████▊   | 195/285 [06:28<02:57,  1.97s/it]Loading train:  69%|██████▉   | 196/285 [06:31<03:09,  2.13s/it]Loading train:  69%|██████▉   | 197/285 [06:34<03:26,  2.34s/it]Loading train:  69%|██████▉   | 198/285 [06:36<03:07,  2.15s/it]Loading train:  70%|██████▉   | 199/285 [06:37<02:51,  2.00s/it]Loading train:  70%|███████   | 200/285 [06:39<02:52,  2.03s/it]Loading train:  71%|███████   | 201/285 [06:41<02:46,  1.98s/it]Loading train:  71%|███████   | 202/285 [06:43<02:34,  1.87s/it]Loading train:  71%|███████   | 203/285 [06:45<02:35,  1.90s/it]Loading train:  72%|███████▏  | 204/285 [06:46<02:26,  1.81s/it]Loading train:  72%|███████▏  | 205/285 [06:48<02:22,  1.78s/it]Loading train:  72%|███████▏  | 206/285 [06:50<02:25,  1.84s/it]Loading train:  73%|███████▎  | 207/285 [06:53<02:47,  2.15s/it]Loading train:  73%|███████▎  | 208/285 [06:56<02:58,  2.31s/it]Loading train:  73%|███████▎  | 209/285 [06:57<02:37,  2.07s/it]Loading train:  74%|███████▎  | 210/285 [06:59<02:34,  2.06s/it]Loading train:  74%|███████▍  | 211/285 [07:01<02:18,  1.87s/it]Loading train:  74%|███████▍  | 212/285 [07:03<02:18,  1.90s/it]Loading train:  75%|███████▍  | 213/285 [07:05<02:30,  2.10s/it]Loading train:  75%|███████▌  | 214/285 [07:06<02:13,  1.88s/it]Loading train:  75%|███████▌  | 215/285 [07:08<02:07,  1.83s/it]Loading train:  76%|███████▌  | 216/285 [07:10<01:57,  1.70s/it]Loading train:  76%|███████▌  | 217/285 [07:12<02:10,  1.92s/it]Loading train:  76%|███████▋  | 218/285 [07:14<02:13,  2.00s/it]Loading train:  77%|███████▋  | 219/285 [07:16<02:17,  2.09s/it]Loading train:  77%|███████▋  | 220/285 [07:18<02:08,  1.98s/it]Loading train:  78%|███████▊  | 221/285 [07:20<01:57,  1.83s/it]Loading train:  78%|███████▊  | 222/285 [07:23<02:14,  2.14s/it]Loading train:  78%|███████▊  | 223/285 [07:24<01:58,  1.92s/it]Loading train:  79%|███████▊  | 224/285 [07:26<01:54,  1.88s/it]Loading train:  79%|███████▉  | 225/285 [07:28<01:59,  1.99s/it]Loading train:  79%|███████▉  | 226/285 [07:30<02:02,  2.07s/it]Loading train:  80%|███████▉  | 227/285 [07:32<01:58,  2.05s/it]Loading train:  80%|████████  | 228/285 [07:34<01:55,  2.03s/it]Loading train:  80%|████████  | 229/285 [07:36<01:53,  2.02s/it]Loading train:  81%|████████  | 230/285 [07:38<01:42,  1.86s/it]Loading train:  81%|████████  | 231/285 [07:39<01:34,  1.74s/it]Loading train:  81%|████████▏ | 232/285 [07:40<01:24,  1.59s/it]Loading train:  82%|████████▏ | 233/285 [07:42<01:18,  1.50s/it]Loading train:  82%|████████▏ | 234/285 [07:43<01:14,  1.46s/it]Loading train:  82%|████████▏ | 235/285 [07:45<01:15,  1.50s/it]Loading train:  83%|████████▎ | 236/285 [07:46<01:13,  1.50s/it]Loading train:  83%|████████▎ | 237/285 [07:48<01:21,  1.70s/it]Loading train:  84%|████████▎ | 238/285 [07:50<01:20,  1.72s/it]Loading train:  84%|████████▍ | 239/285 [07:52<01:15,  1.65s/it]Loading train:  84%|████████▍ | 240/285 [07:53<01:10,  1.56s/it]Loading train:  85%|████████▍ | 241/285 [07:54<01:04,  1.46s/it]Loading train:  85%|████████▍ | 242/285 [07:56<01:02,  1.46s/it]Loading train:  85%|████████▌ | 243/285 [07:58<01:06,  1.59s/it]Loading train:  86%|████████▌ | 244/285 [07:59<01:08,  1.67s/it]Loading train:  86%|████████▌ | 245/285 [08:01<01:03,  1.60s/it]Loading train:  86%|████████▋ | 246/285 [08:02<01:02,  1.60s/it]Loading train:  87%|████████▋ | 247/285 [08:04<00:58,  1.55s/it]Loading train:  87%|████████▋ | 248/285 [08:05<00:52,  1.43s/it]Loading train:  87%|████████▋ | 249/285 [08:06<00:47,  1.33s/it]Loading train:  88%|████████▊ | 250/285 [08:08<00:47,  1.36s/it]Loading train:  88%|████████▊ | 251/285 [08:09<00:44,  1.31s/it]Loading train:  88%|████████▊ | 252/285 [08:10<00:43,  1.32s/it]Loading train:  89%|████████▉ | 253/285 [08:12<00:46,  1.44s/it]Loading train:  89%|████████▉ | 254/285 [08:13<00:46,  1.50s/it]Loading train:  89%|████████▉ | 255/285 [08:15<00:47,  1.57s/it]Loading train:  90%|████████▉ | 256/285 [08:17<00:46,  1.61s/it]Loading train:  90%|█████████ | 257/285 [08:19<00:46,  1.64s/it]Loading train:  91%|█████████ | 258/285 [08:20<00:44,  1.63s/it]Loading train:  91%|█████████ | 259/285 [08:22<00:40,  1.57s/it]Loading train:  91%|█████████ | 260/285 [08:23<00:36,  1.45s/it]Loading train:  92%|█████████▏| 261/285 [08:24<00:32,  1.35s/it]Loading train:  92%|█████████▏| 262/285 [08:25<00:32,  1.41s/it]Loading train:  92%|█████████▏| 263/285 [08:26<00:28,  1.28s/it]Loading train:  93%|█████████▎| 264/285 [08:28<00:28,  1.35s/it]Loading train:  93%|█████████▎| 265/285 [08:29<00:27,  1.37s/it]Loading train:  93%|█████████▎| 266/285 [08:31<00:25,  1.33s/it]Loading train:  94%|█████████▎| 267/285 [08:32<00:24,  1.38s/it]Loading train:  94%|█████████▍| 268/285 [08:34<00:23,  1.40s/it]Loading train:  94%|█████████▍| 269/285 [08:35<00:23,  1.45s/it]Loading train:  95%|█████████▍| 270/285 [08:36<00:20,  1.38s/it]Loading train:  95%|█████████▌| 271/285 [08:38<00:20,  1.44s/it]Loading train:  95%|█████████▌| 272/285 [08:39<00:19,  1.48s/it]Loading train:  96%|█████████▌| 273/285 [08:41<00:18,  1.57s/it]Loading train:  96%|█████████▌| 274/285 [08:43<00:17,  1.59s/it]Loading train:  96%|█████████▋| 275/285 [08:45<00:17,  1.71s/it]Loading train:  97%|█████████▋| 276/285 [08:47<00:15,  1.72s/it]Loading train:  97%|█████████▋| 277/285 [08:48<00:12,  1.53s/it]Loading train:  98%|█████████▊| 278/285 [08:49<00:10,  1.52s/it]Loading train:  98%|█████████▊| 279/285 [08:51<00:09,  1.58s/it]Loading train:  98%|█████████▊| 280/285 [08:52<00:07,  1.50s/it]Loading train:  99%|█████████▊| 281/285 [08:54<00:05,  1.47s/it]Loading train:  99%|█████████▉| 282/285 [08:55<00:04,  1.41s/it]Loading train:  99%|█████████▉| 283/285 [08:57<00:03,  1.52s/it]Loading train: 100%|█████████▉| 284/285 [08:59<00:01,  1.61s/it]Loading train: 100%|██████████| 285/285 [09:00<00:00,  1.63s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|          | 3/285 [00:00<00:11, 25.00it/s]concatenating: train:   3%|▎         | 9/285 [00:00<00:09, 30.28it/s]concatenating: train:   7%|▋         | 19/285 [00:00<00:07, 37.62it/s]concatenating: train:   8%|▊         | 24/285 [00:00<00:06, 37.36it/s]concatenating: train:  10%|█         | 29/285 [00:00<00:07, 35.29it/s]concatenating: train:  12%|█▏        | 35/285 [00:00<00:06, 39.63it/s]concatenating: train:  14%|█▍        | 40/285 [00:00<00:05, 41.01it/s]concatenating: train:  17%|█▋        | 48/285 [00:00<00:04, 47.69it/s]concatenating: train:  19%|█▉        | 54/285 [00:01<00:05, 44.10it/s]concatenating: train:  21%|██        | 59/285 [00:01<00:07, 28.68it/s]concatenating: train:  25%|██▍       | 70/285 [00:01<00:05, 36.71it/s]concatenating: train:  29%|██▉       | 82/285 [00:01<00:04, 46.15it/s]concatenating: train:  33%|███▎      | 95/285 [00:01<00:03, 56.92it/s]concatenating: train:  38%|███▊      | 107/285 [00:01<00:02, 67.18it/s]concatenating: train:  41%|████      | 117/285 [00:02<00:02, 61.80it/s]concatenating: train:  44%|████▍     | 126/285 [00:02<00:03, 43.37it/s]concatenating: train:  47%|████▋     | 133/285 [00:02<00:03, 43.16it/s]concatenating: train:  49%|████▉     | 139/285 [00:02<00:03, 45.83it/s]concatenating: train:  51%|█████     | 146/285 [00:02<00:02, 49.86it/s]concatenating: train:  54%|█████▎    | 153/285 [00:02<00:02, 54.52it/s]concatenating: train:  56%|█████▌    | 160/285 [00:03<00:02, 47.85it/s]concatenating: train:  58%|█████▊    | 166/285 [00:03<00:04, 26.30it/s]concatenating: train:  60%|██████    | 172/285 [00:03<00:03, 30.66it/s]concatenating: train:  62%|██████▏   | 178/285 [00:03<00:03, 35.64it/s]concatenating: train:  72%|███████▏  | 204/285 [00:03<00:01, 48.01it/s]concatenating: train:  82%|████████▏ | 234/285 [00:03<00:00, 64.08it/s]concatenating: train:  88%|████████▊ | 251/285 [00:04<00:00, 76.42it/s]concatenating: train:  94%|█████████▎| 267/285 [00:04<00:00, 53.76it/s]concatenating: train:  98%|█████████▊| 279/285 [00:04<00:00, 44.19it/s]concatenating: train: 100%|██████████| 285/285 [00:05<00:00, 52.62it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:02<00:04,  2.12s/it]Loading test:  67%|██████▋   | 2/3 [00:04<00:02,  2.23s/it]Loading test: 100%|██████████| 3/3 [00:06<00:00,  2.07s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation:  67%|██████▋   | 2/3 [00:00<00:00, 19.23it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 24.95it/s]2019-07-11 03:38:38.783961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 03:38:38.784098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 03:38:38.784116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 03:38:38.784129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 03:38:38.784657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:15,  2.83it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:11,  3.61it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:10,  3.91it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:01<00:07,  4.63it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:07,  4.52it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:06,  5.40it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:07,  4.54it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:02<00:04,  5.83it/s]loading the weights for Res Unet:  41%|████      | 18/44 [00:02<00:05,  5.09it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:02<00:04,  5.98it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:04,  5.46it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:03<00:02,  6.79it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  7.18it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:03<00:02,  6.31it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:03<00:01,  7.11it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:04<00:02,  4.59it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:04<00:01,  5.62it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:01,  6.35it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:05<00:01,  5.38it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:05<00:00,  5.47it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:05<00:00,  5.14it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:05<00:00,  7.82it/s]2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 26, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 13, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 26, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 10)   5410        dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 10)   40          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 10)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 52, 10)   0           activation_11[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 10)   910         dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 52, 10)   40          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 52, 10)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 52, 10)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 70)   0           dropout_5[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 52, 13)   923         concatenate_7[0][0]              
==================================================================================================
Total params: 230,363
Trainable params: 55,643
Non-trainable params: 174,720
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 18s - loss: 1.9883 - acc: 0.8112 - mDice: 0.2011 - val_loss: 0.9228 - val_acc: 0.9186 - val_mDice: 0.4120

Epoch 00001: val_mDice improved from -inf to 0.41204, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 13s - loss: 0.7670 - acc: 0.9043 - mDice: 0.4500 - val_loss: 0.7063 - val_acc: 0.9328 - val_mDice: 0.4850

Epoch 00002: val_mDice improved from 0.41204 to 0.48499, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 12s - loss: 0.6032 - acc: 0.9201 - mDice: 0.5322 - val_loss: 0.5637 - val_acc: 0.9428 - val_mDice: 0.5595

Epoch 00003: val_mDice improved from 0.48499 to 0.55952, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 12s - loss: 0.5169 - acc: 0.9316 - mDice: 0.5808 - val_loss: 0.5161 - val_acc: 0.9482 - val_mDice: 0.5827

Epoch 00004: val_mDice improved from 0.55952 to 0.58267, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 12s - loss: 0.4652 - acc: 0.9366 - mDice: 0.6122 - val_loss: 0.4934 - val_acc: 0.9486 - val_mDice: 0.5964

Epoch 00005: val_mDice improved from 0.58267 to 0.59643, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 13s - loss: 0.4349 - acc: 0.9392 - mDice: 0.6318 - val_loss: 0.5008 - val_acc: 0.9483 - val_mDice: 0.5904

Epoch 00006: val_mDice did not improve from 0.59643
Epoch 7/300
 - 12s - loss: 0.4125 - acc: 0.9412 - mDice: 0.6465 - val_loss: 0.5335 - val_acc: 0.9486 - val_mDice: 0.5786

Epoch 00007: val_mDice did not improve from 0.59643
Epoch 8/300
 - 12s - loss: 0.3968 - acc: 0.9426 - mDice: 0.6572 - val_loss: 0.4854 - val_acc: 0.9469 - val_mDice: 0.6029

Epoch 00008: val_mDice improved from 0.59643 to 0.60292, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 12s - loss: 0.3855 - acc: 0.9435 - mDice: 0.6651 - val_loss: 0.5286 - val_acc: 0.9467 - val_mDice: 0.5739

Epoch 00009: val_mDice did not improve from 0.60292
Epoch 10/300
 - 12s - loss: 0.3746 - acc: 0.9443 - mDice: 0.6726 - val_loss: 0.5070 - val_acc: 0.9478 - val_mDice: 0.5918

Epoch 00010: val_mDice did not improve from 0.60292
Epoch 11/300
 - 13s - loss: 0.3655 - acc: 0.9450 - mDice: 0.6790 - val_loss: 0.5669 - val_acc: 0.9463 - val_mDice: 0.5596

Epoch 00011: val_mDice did not improve from 0.60292
Epoch 12/300
 - 12s - loss: 0.3553 - acc: 0.9460 - mDice: 0.6863 - val_loss: 0.5010 - val_acc: 0.9485 - val_mDice: 0.5948

Epoch 00012: val_mDice did not improve from 0.60292
Epoch 13/300
 - 12s - loss: 0.3497 - acc: 0.9464 - mDice: 0.6903 - val_loss: 0.5324 - val_acc: 0.9488 - val_mDice: 0.5848

Epoch 00013: val_mDice did not improve from 0.60292
Epoch 14/300
 - 12s - loss: 0.3447 - acc: 0.9467 - mDice: 0.6939 - val_loss: 0.5245 - val_acc: 0.9478 - val_mDice: 0.5949

Epoch 00014: val_mDice did not improve from 0.60292
Epoch 15/300
 - 12s - loss: 0.3375 - acc: 0.9473 - mDice: 0.6990 - val_loss: 0.5374 - val_acc: 0.9478 - val_mDice: 0.5825

Epoch 00015: val_mDice did not improve from 0.60292
Epoch 16/300
 - 12s - loss: 0.3324 - acc: 0.9476 - mDice: 0.7028 - val_loss: 0.5074 - val_acc: 0.9491 - val_mDice: 0.5970

Epoch 00016: val_mDice did not improve from 0.60292
Epoch 17/300
 - 12s - loss: 0.3273 - acc: 0.9481 - mDice: 0.7065 - val_loss: 0.5187 - val_acc: 0.9473 - val_mDice: 0.5875

Epoch 00017: val_mDice did not improve from 0.60292
Epoch 18/300
 - 13s - loss: 0.3243 - acc: 0.9484 - mDice: 0.7087 - val_loss: 0.4932 - val_acc: 0.9498 - val_mDice: 0.6065

Epoch 00018: val_mDice improved from 0.60292 to 0.60654, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 19/300
 - 12s - loss: 0.3196 - acc: 0.9487 - mDice: 0.7122 - val_loss: 0.5110 - val_acc: 0.9477 - val_mDice: 0.5935

Epoch 00019: val_mDice did not improve from 0.60654
Epoch 20/300
 - 12s - loss: 0.3153 - acc: 0.9491 - mDice: 0.7154 - val_loss: 0.5486 - val_acc: 0.9506 - val_mDice: 0.5879

Epoch 00020: val_mDice did not improve from 0.60654
Epoch 21/300
 - 12s - loss: 0.3126 - acc: 0.9493 - mDice: 0.7175 - val_loss: 0.5480 - val_acc: 0.9477 - val_mDice: 0.5758

Epoch 00021: val_mDice did not improve from 0.60654
Epoch 22/300
 - 12s - loss: 0.3129 - acc: 0.9494 - mDice: 0.7174 - val_loss: 0.4804 - val_acc: 0.9494 - val_mDice: 0.6104

Epoch 00022: val_mDice improved from 0.60654 to 0.61042, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 23/300
 - 12s - loss: 0.3107 - acc: 0.9495 - mDice: 0.7191 - val_loss: 0.4935 - val_acc: 0.9483 - val_mDice: 0.5995

Epoch 00023: val_mDice did not improve from 0.61042
Epoch 24/300
 - 12s - loss: 0.3061 - acc: 0.9498 - mDice: 0.7224 - val_loss: 0.5789 - val_acc: 0.9444 - val_mDice: 0.5541

Epoch 00024: val_mDice did not improve from 0.61042
Epoch 25/300
 - 13s - loss: 0.3014 - acc: 0.9501 - mDice: 0.7259 - val_loss: 0.4917 - val_acc: 0.9491 - val_mDice: 0.6038

Epoch 00025: val_mDice did not improve from 0.61042
Epoch 26/300
 - 13s - loss: 0.3004 - acc: 0.9502 - mDice: 0.7267 - val_loss: 0.5269 - val_acc: 0.9480 - val_mDice: 0.5896

Epoch 00026: val_mDice did not improve from 0.61042
Epoch 27/300
 - 12s - loss: 0.2984 - acc: 0.9505 - mDice: 0.7283 - val_loss: 0.5612 - val_acc: 0.9442 - val_mDice: 0.5678

Epoch 00027: val_mDice did not improve from 0.61042
Epoch 28/300
 - 12s - loss: 0.2952 - acc: 0.9507 - mDice: 0.7306 - val_loss: 0.5480 - val_acc: 0.9506 - val_mDice: 0.5794

Epoch 00028: val_mDice did not improve from 0.61042
Epoch 29/300
 - 12s - loss: 0.2931 - acc: 0.9509 - mDice: 0.7323 - val_loss: 0.4998 - val_acc: 0.9482 - val_mDice: 0.6023

Epoch 00029: val_mDice did not improve from 0.61042
Epoch 30/300
 - 12s - loss: 0.2914 - acc: 0.9510 - mDice: 0.7336 - val_loss: 0.5132 - val_acc: 0.9452 - val_mDice: 0.5930

Epoch 00030: val_mDice did not improve from 0.61042
Epoch 31/300
 - 12s - loss: 0.2903 - acc: 0.9511 - mDice: 0.7344 - val_loss: 0.5174 - val_acc: 0.9505 - val_mDice: 0.5927

Epoch 00031: val_mDice did not improve from 0.61042
Epoch 32/300
 - 12s - loss: 0.2882 - acc: 0.9513 - mDice: 0.7360 - val_loss: 0.5276 - val_acc: 0.9462 - val_mDice: 0.5821

Epoch 00032: val_mDice did not improve from 0.61042
Epoch 33/300
 - 12s - loss: 0.2871 - acc: 0.9514 - mDice: 0.7369 - val_loss: 0.4994 - val_acc: 0.9503 - val_mDice: 0.6051

Epoch 00033: val_mDice did not improve from 0.61042
Epoch 34/300
 - 13s - loss: 0.2850 - acc: 0.9515 - mDice: 0.7385 - val_loss: 0.5442 - val_acc: 0.9485 - val_mDice: 0.5732

Epoch 00034: val_mDice did not improve from 0.61042
Epoch 35/300
 - 12s - loss: 0.2827 - acc: 0.9518 - mDice: 0.7403 - val_loss: 0.5199 - val_acc: 0.9465 - val_mDice: 0.5833

Epoch 00035: val_mDice did not improve from 0.61042
Epoch 36/300
 - 12s - loss: 0.2815 - acc: 0.9518 - mDice: 0.7412 - val_loss: 0.5308 - val_acc: 0.9484 - val_mDice: 0.5833

Epoch 00036: val_mDice did not improve from 0.61042
Epoch 37/300
 - 12s - loss: 0.2810 - acc: 0.9519 - mDice: 0.7417 - val_loss: 0.5272 - val_acc: 0.9453 - val_mDice: 0.5799

Epoch 00037: val_mDice did not improve from 0.61042
Epoch 38/300
 - 12s - loss: 0.2800 - acc: 0.9521 - mDice: 0.7425 - val_loss: 0.5129 - val_acc: 0.9489 - val_mDice: 0.5928

Epoch 00038: val_mDice did not improve from 0.61042
Epoch 39/300
 - 12s - loss: 0.2772 - acc: 0.9522 - mDice: 0.7446 - val_loss: 0.5377 - val_acc: 0.9439 - val_mDice: 0.5713

Epoch 00039: val_mDice did not improve from 0.61042
Epoch 40/300
 - 12s - loss: 0.2777 - acc: 0.9523 - mDice: 0.7443 - val_loss: 0.5178 - val_acc: 0.9492 - val_mDice: 0.5899

Epoch 00040: val_mDice did not improve from 0.61042
Epoch 41/300
 - 12s - loss: 0.2747 - acc: 0.9524 - mDice: 0.7465 - val_loss: 0.5254 - val_acc: 0.9515 - val_mDice: 0.5912

Epoch 00041: val_mDice did not improve from 0.61042
Epoch 42/300
 - 12s - loss: 0.2720 - acc: 0.9526 - mDice: 0.7486 - val_loss: 0.4914 - val_acc: 0.9502 - val_mDice: 0.6029

Epoch 00042: val_mDice did not improve from 0.61042
Epoch 43/300
 - 13s - loss: 0.2729 - acc: 0.9526 - mDice: 0.7479 - val_loss: 0.5154 - val_acc: 0.9449 - val_mDice: 0.5862

Epoch 00043: val_mDice did not improve from 0.61042
Epoch 44/300
 - 12s - loss: 0.2708 - acc: 0.9527 - mDice: 0.7496 - val_loss: 0.4910 - val_acc: 0.9508 - val_mDice: 0.6074

Epoch 00044: val_mDice did not improve from 0.61042
Epoch 45/300
 - 12s - loss: 0.2699 - acc: 0.9528 - mDice: 0.7503 - val_loss: 0.5453 - val_acc: 0.9488 - val_mDice: 0.5797

Epoch 00045: val_mDice did not improve from 0.61042
Epoch 46/300
 - 12s - loss: 0.2691 - acc: 0.9529 - mDice: 0.7509 - val_loss: 0.5106 - val_acc: 0.9471 - val_mDice: 0.5891

Epoch 00046: val_mDice did not improve from 0.61042
Epoch 47/300
 - 12s - loss: 0.2689 - acc: 0.9530 - mDice: 0.7512 - val_loss: 0.4987 - val_acc: 0.9493 - val_mDice: 0.5992

Epoch 00047: val_mDice did not improve from 0.61042
Epoch 48/300
 - 12s - loss: 0.2641 - acc: 0.9533 - mDice: 0.7548 - val_loss: 0.5192 - val_acc: 0.9446 - val_mDice: 0.5825

Epoch 00048: val_mDice did not improve from 0.61042
Epoch 49/300
 - 12s - loss: 0.2920 - acc: 0.9517 - mDice: 0.7391 - val_loss: 1.0934 - val_acc: 0.9304 - val_mDice: 0.3535

Epoch 00049: val_mDice did not improve from 0.61042
Epoch 50/300
 - 12s - loss: 0.2826 - acc: 0.9518 - mDice: 0.7401 - val_loss: 0.5023 - val_acc: 0.9490 - val_mDice: 0.5979

Epoch 00050: val_mDice did not improve from 0.61042
Epoch 51/300
 - 12s - loss: 0.2689 - acc: 0.9530 - mDice: 0.7510 - val_loss: 0.5120 - val_acc: 0.9492 - val_mDice: 0.6020

Epoch 00051: val_mDice did not improve from 0.61042
Epoch 52/300
 - 13s - loss: 0.2653 - acc: 0.9532 - mDice: 0.7538 - val_loss: 0.5019 - val_acc: 0.9504 - val_mDice: 0.5982

Epoch 00052: val_mDice did not improve from 0.61042
Epoch 53/300
 - 12s - loss: 0.2638 - acc: 0.9533 - mDice: 0.7550 - val_loss: 0.4960 - val_acc: 0.9493 - val_mDice: 0.6014

Epoch 00053: val_mDice did not improve from 0.61042
Epoch 54/300
 - 12s - loss: 0.2620 - acc: 0.9535 - mDice: 0.7565 - val_loss: 0.5007 - val_acc: 0.9504 - val_mDice: 0.6008

Epoch 00054: val_mDice did not improve from 0.61042
Epoch 55/300
 - 12s - loss: 0.2614 - acc: 0.9536 - mDice: 0.7570 - val_loss: 0.5163 - val_acc: 0.9489 - val_mDice: 0.5907

Epoch 00055: val_mDice did not improve from 0.61042
Epoch 56/300
 - 13s - loss: 0.2610 - acc: 0.9537 - mDice: 0.7573 - val_loss: 0.5077 - val_acc: 0.9503 - val_mDice: 0.6002

Epoch 00056: val_mDice did not improve from 0.61042
Epoch 57/300
 - 13s - loss: 0.2587 - acc: 0.9537 - mDice: 0.7591 - val_loss: 0.5357 - val_acc: 0.9503 - val_mDice: 0.5810

Epoch 00057: val_mDice did not improve from 0.61042
Epoch 58/300
 - 13s - loss: 0.2586 - acc: 0.9538 - mDice: 0.7592 - val_loss: 0.5298 - val_acc: 0.9482 - val_mDice: 0.5846

Epoch 00058: val_mDice did not improve from 0.61042
Epoch 59/300
 - 13s - loss: 0.2575 - acc: 0.9539 - mDice: 0.7601 - val_loss: 0.4971 - val_acc: 0.9478 - val_mDice: 0.6024

Epoch 00059: val_mDice did not improve from 0.61042
Epoch 60/300
 - 12s - loss: 0.2569 - acc: 0.9540 - mDice: 0.7605 - val_loss: 0.5568 - val_acc: 0.9498 - val_mDice: 0.5775

Epoch 00060: val_mDice did not improve from 0.61042
Epoch 61/300
 - 13s - loss: 0.2561 - acc: 0.9540 - mDice: 0.7613 - val_loss: 0.5039 - val_acc: 0.9506 - val_mDice: 0.5988

Epoch 00061: val_mDice did not improve from 0.61042
Epoch 62/300
 - 12s - loss: 0.2574 - acc: 0.9540 - mDice: 0.7602 - val_loss: 0.5070 - val_acc: 0.9492 - val_mDice: 0.5955

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.49s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.23s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  2.01s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:04,  1.92s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:27,  1.79s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:20,  1.78s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:57,  1.70s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:25,  1.80s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<08:11,  1.76s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:22,  1.81s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:16,  1.79s/it]predicting train subjects:   3%|▎         | 9/285 [00:16<08:55,  1.94s/it]predicting train subjects:   4%|▎         | 10/285 [00:18<09:12,  2.01s/it]predicting train subjects:   4%|▍         | 11/285 [00:20<08:46,  1.92s/it]predicting train subjects:   4%|▍         | 12/285 [00:22<09:04,  1.99s/it]predicting train subjects:   5%|▍         | 13/285 [00:24<08:41,  1.92s/it]predicting train subjects:   5%|▍         | 14/285 [00:26<08:42,  1.93s/it]predicting train subjects:   5%|▌         | 15/285 [00:28<09:08,  2.03s/it]predicting train subjects:   6%|▌         | 16/285 [00:30<09:19,  2.08s/it]predicting train subjects:   6%|▌         | 17/285 [00:32<08:46,  1.96s/it]predicting train subjects:   6%|▋         | 18/285 [00:34<08:48,  1.98s/it]predicting train subjects:   7%|▋         | 19/285 [00:36<08:27,  1.91s/it]predicting train subjects:   7%|▋         | 20/285 [00:37<08:29,  1.92s/it]predicting train subjects:   7%|▋         | 21/285 [00:40<08:45,  1.99s/it]predicting train subjects:   8%|▊         | 22/285 [00:41<08:29,  1.94s/it]predicting train subjects:   8%|▊         | 23/285 [00:43<08:37,  1.97s/it]predicting train subjects:   8%|▊         | 24/285 [00:45<08:12,  1.89s/it]predicting train subjects:   9%|▉         | 25/285 [00:47<08:31,  1.97s/it]predicting train subjects:   9%|▉         | 26/285 [00:49<08:44,  2.02s/it]predicting train subjects:   9%|▉         | 27/285 [00:51<08:20,  1.94s/it]predicting train subjects:  10%|▉         | 28/285 [00:53<08:18,  1.94s/it]predicting train subjects:  10%|█         | 29/285 [00:55<08:17,  1.94s/it]predicting train subjects:  11%|█         | 30/285 [00:57<08:30,  2.00s/it]predicting train subjects:  11%|█         | 31/285 [00:59<08:38,  2.04s/it]predicting train subjects:  11%|█         | 32/285 [01:01<08:13,  1.95s/it]predicting train subjects:  12%|█▏        | 33/285 [01:03<08:09,  1.94s/it]predicting train subjects:  12%|█▏        | 34/285 [01:05<08:09,  1.95s/it]predicting train subjects:  12%|█▏        | 35/285 [01:07<08:22,  2.01s/it]predicting train subjects:  13%|█▎        | 36/285 [01:09<08:04,  1.95s/it]predicting train subjects:  13%|█▎        | 37/285 [01:11<08:14,  1.99s/it]predicting train subjects:  13%|█▎        | 38/285 [01:13<08:31,  2.07s/it]predicting train subjects:  14%|█▎        | 39/285 [01:15<08:04,  1.97s/it]predicting train subjects:  14%|█▍        | 40/285 [01:17<07:55,  1.94s/it]predicting train subjects:  14%|█▍        | 41/285 [01:19<07:33,  1.86s/it]predicting train subjects:  15%|█▍        | 42/285 [01:20<07:18,  1.81s/it]predicting train subjects:  15%|█▌        | 43/285 [01:22<07:29,  1.86s/it]predicting train subjects:  15%|█▌        | 44/285 [01:24<07:46,  1.94s/it]predicting train subjects:  16%|█▌        | 45/285 [01:26<07:21,  1.84s/it]predicting train subjects:  16%|█▌        | 46/285 [01:28<07:43,  1.94s/it]predicting train subjects:  16%|█▋        | 47/285 [01:30<07:25,  1.87s/it]predicting train subjects:  17%|█▋        | 48/285 [01:32<07:23,  1.87s/it]predicting train subjects:  17%|█▋        | 49/285 [01:34<07:48,  1.99s/it]predicting train subjects:  18%|█▊        | 50/285 [01:36<07:40,  1.96s/it]predicting train subjects:  18%|█▊        | 51/285 [01:38<07:56,  2.04s/it]predicting train subjects:  18%|█▊        | 52/285 [01:40<07:37,  1.96s/it]predicting train subjects:  19%|█▊        | 53/285 [01:42<07:41,  1.99s/it]predicting train subjects:  19%|█▉        | 54/285 [01:44<07:52,  2.05s/it]predicting train subjects:  19%|█▉        | 55/285 [01:46<07:25,  1.94s/it]predicting train subjects:  20%|█▉        | 56/285 [01:48<07:20,  1.92s/it]predicting train subjects:  20%|██        | 57/285 [01:49<07:04,  1.86s/it]predicting train subjects:  20%|██        | 58/285 [01:51<07:03,  1.86s/it]predicting train subjects:  21%|██        | 59/285 [01:53<07:17,  1.94s/it]predicting train subjects:  21%|██        | 60/285 [01:56<07:36,  2.03s/it]predicting train subjects:  21%|██▏       | 61/285 [01:57<07:12,  1.93s/it]predicting train subjects:  22%|██▏       | 62/285 [01:59<07:01,  1.89s/it]predicting train subjects:  22%|██▏       | 63/285 [02:01<07:03,  1.91s/it]predicting train subjects:  22%|██▏       | 64/285 [02:03<06:55,  1.88s/it]predicting train subjects:  23%|██▎       | 65/285 [02:05<06:59,  1.91s/it]predicting train subjects:  23%|██▎       | 66/285 [02:07<07:05,  1.94s/it]predicting train subjects:  24%|██▎       | 67/285 [02:09<07:01,  1.94s/it]predicting train subjects:  24%|██▍       | 68/285 [02:11<06:50,  1.89s/it]predicting train subjects:  24%|██▍       | 69/285 [02:13<06:52,  1.91s/it]predicting train subjects:  25%|██▍       | 70/285 [02:15<06:54,  1.93s/it]predicting train subjects:  25%|██▍       | 71/285 [02:16<06:49,  1.91s/it]predicting train subjects:  25%|██▌       | 72/285 [02:18<06:38,  1.87s/it]predicting train subjects:  26%|██▌       | 73/285 [02:20<06:41,  1.89s/it]predicting train subjects:  26%|██▌       | 74/285 [02:22<06:36,  1.88s/it]predicting train subjects:  26%|██▋       | 75/285 [02:24<06:38,  1.90s/it]predicting train subjects:  27%|██▋       | 76/285 [02:26<06:40,  1.91s/it]predicting train subjects:  27%|██▋       | 77/285 [02:28<06:33,  1.89s/it]predicting train subjects:  27%|██▋       | 78/285 [02:29<06:24,  1.86s/it]predicting train subjects:  28%|██▊       | 79/285 [02:31<06:26,  1.88s/it]predicting train subjects:  28%|██▊       | 80/285 [02:33<06:25,  1.88s/it]predicting train subjects:  28%|██▊       | 81/285 [02:35<06:18,  1.85s/it]predicting train subjects:  29%|██▉       | 82/285 [02:37<06:18,  1.86s/it]predicting train subjects:  29%|██▉       | 83/285 [02:39<06:11,  1.84s/it]predicting train subjects:  29%|██▉       | 84/285 [02:41<06:10,  1.84s/it]predicting train subjects:  30%|██▉       | 85/285 [02:43<06:13,  1.87s/it]predicting train subjects:  30%|███       | 86/285 [02:45<06:19,  1.91s/it]predicting train subjects:  31%|███       | 87/285 [02:46<06:20,  1.92s/it]predicting train subjects:  31%|███       | 88/285 [02:48<06:14,  1.90s/it]predicting train subjects:  31%|███       | 89/285 [02:50<06:11,  1.89s/it]predicting train subjects:  32%|███▏      | 90/285 [02:52<06:15,  1.93s/it]predicting train subjects:  32%|███▏      | 91/285 [02:54<06:09,  1.90s/it]predicting train subjects:  32%|███▏      | 92/285 [02:56<06:10,  1.92s/it]predicting train subjects:  33%|███▎      | 93/285 [02:58<06:06,  1.91s/it]predicting train subjects:  33%|███▎      | 94/285 [03:00<06:10,  1.94s/it]predicting train subjects:  33%|███▎      | 95/285 [03:02<06:10,  1.95s/it]predicting train subjects:  34%|███▎      | 96/285 [03:04<06:08,  1.95s/it]predicting train subjects:  34%|███▍      | 97/285 [03:06<06:07,  1.96s/it]predicting train subjects:  34%|███▍      | 98/285 [03:08<06:03,  1.94s/it]predicting train subjects:  35%|███▍      | 99/285 [03:10<05:56,  1.92s/it]predicting train subjects:  35%|███▌      | 100/285 [03:12<05:58,  1.94s/it]predicting train subjects:  35%|███▌      | 101/285 [03:13<05:51,  1.91s/it]predicting train subjects:  36%|███▌      | 102/285 [03:15<05:55,  1.94s/it]predicting train subjects:  36%|███▌      | 103/285 [03:17<05:53,  1.94s/it]predicting train subjects:  36%|███▋      | 104/285 [03:19<05:49,  1.93s/it]predicting train subjects:  37%|███▋      | 105/285 [03:21<05:52,  1.96s/it]predicting train subjects:  37%|███▋      | 106/285 [03:23<05:51,  1.96s/it]predicting train subjects:  38%|███▊      | 107/285 [03:25<05:45,  1.94s/it]predicting train subjects:  38%|███▊      | 108/285 [03:27<05:34,  1.89s/it]predicting train subjects:  38%|███▊      | 109/285 [03:29<05:34,  1.90s/it]predicting train subjects:  39%|███▊      | 110/285 [03:31<05:33,  1.91s/it]predicting train subjects:  39%|███▉      | 111/285 [03:33<05:28,  1.89s/it]predicting train subjects:  39%|███▉      | 112/285 [03:35<05:30,  1.91s/it]predicting train subjects:  40%|███▉      | 113/285 [03:37<05:32,  1.93s/it]predicting train subjects:  40%|████      | 114/285 [03:39<05:32,  1.95s/it]predicting train subjects:  40%|████      | 115/285 [03:40<05:28,  1.93s/it]predicting train subjects:  41%|████      | 116/285 [03:42<05:27,  1.94s/it]predicting train subjects:  41%|████      | 117/285 [03:44<05:18,  1.90s/it]predicting train subjects:  41%|████▏     | 118/285 [03:46<05:16,  1.89s/it]predicting train subjects:  42%|████▏     | 119/285 [03:48<05:22,  1.94s/it]predicting train subjects:  42%|████▏     | 120/285 [03:50<05:15,  1.91s/it]predicting train subjects:  42%|████▏     | 121/285 [03:52<05:06,  1.87s/it]predicting train subjects:  43%|████▎     | 122/285 [03:53<04:52,  1.80s/it]predicting train subjects:  43%|████▎     | 123/285 [03:55<04:37,  1.71s/it]predicting train subjects:  44%|████▎     | 124/285 [03:57<04:37,  1.72s/it]predicting train subjects:  44%|████▍     | 125/285 [03:58<04:28,  1.68s/it]predicting train subjects:  44%|████▍     | 126/285 [04:00<04:24,  1.67s/it]predicting train subjects:  45%|████▍     | 127/285 [04:01<04:15,  1.61s/it]predicting train subjects:  45%|████▍     | 128/285 [04:03<04:21,  1.66s/it]predicting train subjects:  45%|████▌     | 129/285 [04:05<04:16,  1.64s/it]predicting train subjects:  46%|████▌     | 130/285 [04:06<04:13,  1.63s/it]predicting train subjects:  46%|████▌     | 131/285 [04:08<04:12,  1.64s/it]predicting train subjects:  46%|████▋     | 132/285 [04:10<04:17,  1.68s/it]predicting train subjects:  47%|████▋     | 133/285 [04:11<04:13,  1.67s/it]predicting train subjects:  47%|████▋     | 134/285 [04:13<04:15,  1.69s/it]predicting train subjects:  47%|████▋     | 135/285 [04:15<04:08,  1.66s/it]predicting train subjects:  48%|████▊     | 136/285 [04:16<04:00,  1.61s/it]predicting train subjects:  48%|████▊     | 137/285 [04:18<04:01,  1.63s/it]predicting train subjects:  48%|████▊     | 138/285 [04:19<03:55,  1.60s/it]predicting train subjects:  49%|████▉     | 139/285 [04:21<04:06,  1.69s/it]predicting train subjects:  49%|████▉     | 140/285 [04:23<04:09,  1.72s/it]predicting train subjects:  49%|████▉     | 141/285 [04:25<04:01,  1.68s/it]predicting train subjects:  50%|████▉     | 142/285 [04:26<03:57,  1.66s/it]predicting train subjects:  50%|█████     | 143/285 [04:28<03:52,  1.64s/it]predicting train subjects:  51%|█████     | 144/285 [04:30<03:53,  1.66s/it]predicting train subjects:  51%|█████     | 145/285 [04:31<03:52,  1.66s/it]predicting train subjects:  51%|█████     | 146/285 [04:33<03:55,  1.69s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:35<03:51,  1.67s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:37<03:56,  1.73s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:38<03:50,  1.70s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:40<03:47,  1.69s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:42<03:48,  1.71s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:43<03:42,  1.67s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:45<03:36,  1.64s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:46<03:37,  1.66s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:48<03:34,  1.65s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:50<03:41,  1.71s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:52<03:33,  1.67s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:53<03:33,  1.68s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:55<03:26,  1.64s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:56<03:21,  1.61s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:58<03:25,  1.66s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:00<03:20,  1.63s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:01<03:26,  1.70s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:03<03:22,  1.67s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:05<03:18,  1.66s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:07<03:22,  1.70s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:08<03:23,  1.72s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:10<03:16,  1.68s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:12<03:15,  1.68s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:13<03:12,  1.67s/it]predicting train subjects:  60%|██████    | 171/285 [05:15<03:06,  1.64s/it]predicting train subjects:  60%|██████    | 172/285 [05:16<03:07,  1.66s/it]predicting train subjects:  61%|██████    | 173/285 [05:18<02:59,  1.61s/it]predicting train subjects:  61%|██████    | 174/285 [05:20<03:02,  1.64s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:21<03:05,  1.68s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:23<03:06,  1.71s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:25<02:58,  1.65s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:26<02:53,  1.62s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:28<02:49,  1.59s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:30<02:55,  1.67s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:31<02:55,  1.68s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:33<02:58,  1.73s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:35<02:50,  1.67s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:36<02:46,  1.65s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:38<02:43,  1.64s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:40<02:54,  1.76s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:42<02:58,  1.82s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:44<02:59,  1.85s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:45<02:48,  1.76s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:47<02:41,  1.70s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:49<02:40,  1.70s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:50<02:38,  1.71s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:52<02:29,  1.63s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:54<02:35,  1.71s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:56<02:45,  1.83s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:58<02:59,  2.01s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:01<03:11,  2.17s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:03<03:06,  2.15s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:05<02:56,  2.05s/it]predicting train subjects:  70%|███████   | 200/285 [06:07<02:49,  1.99s/it]predicting train subjects:  71%|███████   | 201/285 [06:09<02:56,  2.10s/it]predicting train subjects:  71%|███████   | 202/285 [06:11<02:56,  2.12s/it]predicting train subjects:  71%|███████   | 203/285 [06:13<02:55,  2.14s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:15<02:48,  2.08s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:17<02:39,  1.99s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:19<02:36,  1.98s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:22<02:45,  2.13s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:24<02:48,  2.19s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:26<02:47,  2.20s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:28<02:34,  2.06s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:30<02:28,  2.01s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:32<02:25,  1.99s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:34<02:26,  2.04s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:36<02:17,  1.94s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:38<02:22,  2.03s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:40<02:19,  2.02s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:42<02:24,  2.12s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:44<02:24,  2.16s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:47<02:23,  2.17s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:48<02:11,  2.02s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:50<02:01,  1.90s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:52<02:04,  1.98s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:54<01:57,  1.90s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:56<01:57,  1.92s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:57<01:51,  1.86s/it]predicting train subjects:  79%|███████▉  | 226/285 [07:00<01:59,  2.02s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:02<02:05,  2.16s/it]predicting train subjects:  80%|████████  | 228/285 [07:05<02:04,  2.19s/it]predicting train subjects:  80%|████████  | 229/285 [07:07<02:05,  2.25s/it]predicting train subjects:  81%|████████  | 230/285 [07:09<01:56,  2.12s/it]predicting train subjects:  81%|████████  | 231/285 [07:11<01:52,  2.09s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:13<01:53,  2.14s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:15<01:43,  1.98s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:17<01:47,  2.10s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:19<01:40,  2.02s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:21<01:44,  2.14s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:24<01:44,  2.18s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:26<01:41,  2.16s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:28<01:37,  2.11s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:29<01:30,  2.02s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:31<01:29,  2.02s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:33<01:26,  2.00s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:35<01:20,  1.93s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:38<01:26,  2.11s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:40<01:20,  2.02s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:42<01:23,  2.14s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:44<01:22,  2.17s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:46<01:19,  2.15s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:48<01:14,  2.08s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:50<01:11,  2.03s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:52<01:05,  1.93s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:54<01:01,  1.88s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:56<01:04,  2.03s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:58<01:06,  2.14s/it]predicting train subjects:  89%|████████▉ | 255/285 [08:01<01:05,  2.19s/it]predicting train subjects:  90%|████████▉ | 256/285 [08:02<00:59,  2.04s/it]predicting train subjects:  90%|█████████ | 257/285 [08:04<00:55,  1.99s/it]predicting train subjects:  91%|█████████ | 258/285 [08:06<00:54,  2.03s/it]predicting train subjects:  91%|█████████ | 259/285 [08:08<00:52,  2.03s/it]predicting train subjects:  91%|█████████ | 260/285 [08:10<00:50,  2.02s/it]predicting train subjects:  92%|█████████▏| 261/285 [08:12<00:48,  2.03s/it]predicting train subjects:  92%|█████████▏| 262/285 [08:14<00:44,  1.91s/it]predicting train subjects:  92%|█████████▏| 263/285 [08:16<00:41,  1.87s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:18<00:42,  2.02s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:20<00:40,  2.03s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:22<00:37,  2.00s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:24<00:36,  2.02s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:27<00:36,  2.14s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:29<00:34,  2.18s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:31<00:31,  2.12s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:33<00:29,  2.12s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:35<00:27,  2.10s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:37<00:24,  2.04s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:39<00:21,  1.98s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:41<00:21,  2.11s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:43<00:19,  2.14s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:45<00:16,  2.02s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:47<00:13,  1.93s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:49<00:11,  1.94s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:51<00:09,  1.92s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:52<00:07,  1.83s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:54<00:05,  1.85s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:57<00:03,  1.99s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:59<00:02,  2.12s/it]predicting train subjects: 100%|██████████| 285/285 [09:01<00:00,  2.14s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:02<10:27,  2.21s/it]Loading train:   1%|          | 2/285 [00:03<09:14,  1.96s/it]Loading train:   1%|          | 3/285 [00:05<09:29,  2.02s/it]
Epoch 00062: val_mDice did not improve from 0.61042
Restoring model weights from the end of the best epoch
Epoch 00062: early stopping
{'val_loss': [0.922774682497845, 0.7062641572019908, 0.5637385505537748, 0.5161153534271198, 0.49343294870920024, 0.5007975114790421, 0.5335186706574936, 0.4854344629042641, 0.5285500404555038, 0.5069956626306032, 0.5669136656729202, 0.5009862597428221, 0.5323670386602093, 0.5244966162649612, 0.5374288292570487, 0.5073930418025182, 0.5187045372398206, 0.4931834962780915, 0.5110140479476758, 0.5485820427287225, 0.5480470008024291, 0.4803619534609704, 0.49346753705147256, 0.5788950557149323, 0.4917482397409791, 0.5268677056834684, 0.5612192530205796, 0.5480194724471875, 0.49976729614108634, 0.5131565272475088, 0.5173752754094214, 0.5276348937157146, 0.4993855340520763, 0.544246490774208, 0.5198804130101337, 0.5307518753259541, 0.5271625781858433, 0.5129109005022315, 0.5377319228715737, 0.5178146319016398, 0.5254140006763309, 0.49143681479565926, 0.5154460332247132, 0.490987435399487, 0.5452811847851929, 0.5106324110617185, 0.4986685241400863, 0.5192465632321448, 1.0933547439521918, 0.5023281720763478, 0.5119583393608391, 0.501853283557146, 0.49604424051732326, 0.5006617910369149, 0.5163140450109983, 0.5077334499225936, 0.5357255069903155, 0.5297725080777813, 0.4971059797196415, 0.5567736039614545, 0.5038726952488862, 0.5069679504666249], 'val_acc': [0.9186473055924783, 0.9327997428744865, 0.9427539649622401, 0.9482331372506125, 0.9486442657822337, 0.9483054383506988, 0.9485781575714409, 0.9469108285184679, 0.9467207779431476, 0.9478012839509122, 0.9463116829621725, 0.9484541859040713, 0.9488260825919039, 0.947751726851117, 0.9478488401327719, 0.9491090997637317, 0.947257921016416, 0.9498033310447991, 0.947660814117453, 0.9505656841080948, 0.9477083346697205, 0.949421100443302, 0.9482599683314062, 0.9443819795906877, 0.949076055814434, 0.9480389043605527, 0.9441692253064843, 0.9505780855370634, 0.9481752697981936, 0.9451505648357242, 0.9505408955685919, 0.9462001153876661, 0.9503094860295344, 0.9484851553453414, 0.9464687015757215, 0.9484335297312816, 0.945334454155501, 0.9488529219973687, 0.9438758365934787, 0.9491855775177812, 0.9514788782130407, 0.9501731345773409, 0.9448571891092056, 0.9507929612804391, 0.9487516736851058, 0.9470844122284617, 0.9492929950772717, 0.9445885989253081, 0.930359763140119, 0.9489521231065249, 0.9492144900993262, 0.950377668415368, 0.9492516827316924, 0.9503590877495665, 0.9489335021493155, 0.9503425273149373, 0.9503322197072333, 0.9481566654903263, 0.9477765353698304, 0.9497909109685674, 0.9506173430208388, 0.94920828588848], 'val_mDice': [0.4120370992069138, 0.4849871596810538, 0.559516020327307, 0.5826672735160956, 0.5964256521709804, 0.5903782165250299, 0.5786354821487512, 0.6029207133714047, 0.5738667053217329, 0.591830133725811, 0.559603123358508, 0.5948321379762788, 0.5847519779338517, 0.5949495671181705, 0.5825272125904787, 0.5969676019093177, 0.5874734647447171, 0.6065430704441817, 0.5935331899360572, 0.5878797849463351, 0.5757528360329527, 0.6104245269098761, 0.5994751793046237, 0.5541326513503517, 0.603825282118174, 0.5895513828906267, 0.567783418314417, 0.5794434154499842, 0.6023332979426038, 0.5930468310190978, 0.5926548225919628, 0.5821430783032039, 0.6050500003985186, 0.5732286146233202, 0.5832772977525296, 0.583342954766151, 0.5798560917044485, 0.5927592475987014, 0.5713175791601895, 0.5898531841832166, 0.5912115477316873, 0.6028567319475738, 0.5862130356234545, 0.6074027542295403, 0.5796890208841036, 0.5891110976981051, 0.5992315628009135, 0.5825370490218008, 0.35353825611775147, 0.597925854794806, 0.6019761445802018, 0.5982222144164187, 0.6014276023683601, 0.6007693250086055, 0.5907311119846792, 0.6002157253926027, 0.5810035027605195, 0.5846241715900059, 0.6024349138723405, 0.5774794700425431, 0.5988379030920273, 0.5955195713309602], 'loss': [1.9882998645685446, 0.7670218578403496, 0.6032199257534643, 0.5169487377457951, 0.46521562957587076, 0.4348516782367225, 0.41248960913535876, 0.3967923570040245, 0.38545135814869214, 0.37464361521979705, 0.3655140632998352, 0.3552618643004068, 0.3496697956677791, 0.34474527037102803, 0.3375246828823371, 0.3324200325324887, 0.3273002051182623, 0.324259993463331, 0.31964612962191846, 0.3153022394662822, 0.3125948947837855, 0.3129005612280301, 0.31073611978124765, 0.30608271328648884, 0.30141731392557497, 0.3004455334136094, 0.2983974450671149, 0.2951854432202471, 0.29309998350487276, 0.2914491800235174, 0.29025431410477226, 0.28819510627497996, 0.2870960118340664, 0.2850427689145096, 0.28272866401256325, 0.28149650147177935, 0.2809599590135305, 0.2800141357465297, 0.2771673646798276, 0.27770441882225055, 0.2747051271275039, 0.27197386199667994, 0.2729250604747252, 0.27078755037027935, 0.26990719574981054, 0.26908464393067233, 0.26886458692094367, 0.2640686724662625, 0.2920480455021785, 0.28264608733726476, 0.26888059663406405, 0.26528612372467614, 0.26375466180025614, 0.26198490698231985, 0.2613780757735013, 0.26103293012413126, 0.2587207538646834, 0.25861836923755505, 0.25748002600805553, 0.2568808215715989, 0.2560503093818844, 0.25744038606337954], 'acc': [0.8111626907187306, 0.9042958586338422, 0.9201382225254874, 0.9315747420425918, 0.936564576160959, 0.9392430251164475, 0.94117199949992, 0.9425682052113731, 0.943464713849492, 0.9443042028359966, 0.9450142385263497, 0.9459596712710934, 0.9463567454228895, 0.9467027218219378, 0.9472994621390449, 0.9476224118526657, 0.9481490983675264, 0.9484115045293082, 0.9487168724926058, 0.9490598483280668, 0.9492696848487511, 0.9493912791681214, 0.9494952557231209, 0.9498153232124453, 0.9501256270675084, 0.9502006349308573, 0.9504549274951777, 0.9506544907928896, 0.9508916577328836, 0.9509580279122472, 0.9510743646448743, 0.9512753186451312, 0.9513884336494827, 0.95152298122909, 0.9517531007614332, 0.9518465556926207, 0.9518775137562449, 0.95209921650959, 0.9522150315384507, 0.9522977732513525, 0.9524012391690978, 0.9525999419829807, 0.9525528503271965, 0.9527195622949427, 0.9527887875208843, 0.9529208381265202, 0.9529568936646774, 0.9533165231794257, 0.9516569222865571, 0.9517584581123472, 0.9529656529634336, 0.9532177470834237, 0.9532749304830636, 0.9534857136628888, 0.9535824120528401, 0.9537161155390029, 0.953729065364693, 0.9538047384361342, 0.9539289125481512, 0.9540385649806891, 0.9540495009705636, 0.9539978152383329], 'mDice': [0.20111082274831754, 0.4499637140414079, 0.532162304219581, 0.5808192805315205, 0.6121805276585576, 0.6318041767522691, 0.6464566380381227, 0.6572225597272102, 0.6650863806540835, 0.6726097443006273, 0.6790012127985252, 0.6862832769206988, 0.6903134674997633, 0.693852105299623, 0.6990484169811005, 0.7028158683804384, 0.7064852741417637, 0.708704283506118, 0.7121718063553683, 0.7154233187971067, 0.717488224720242, 0.7173813777281292, 0.7190518408297947, 0.7224328205720654, 0.72590455262725, 0.7266584651986081, 0.7283489721856679, 0.730627567424902, 0.7323204941345998, 0.7335894971389629, 0.7344241696864612, 0.7360348109423507, 0.7369389206708292, 0.7385403381623147, 0.7403126431117877, 0.7411832330559446, 0.7416808815909058, 0.7424538763193619, 0.7446162593201753, 0.7442606472935294, 0.7465429280190016, 0.7486309245822022, 0.7478737268570714, 0.7496307094491493, 0.750312203506805, 0.7509310715767652, 0.7511824825368255, 0.7548119139193475, 0.7391095284114287, 0.7401492423198626, 0.7510085430132798, 0.7538125825684013, 0.755043508748617, 0.7564729915991776, 0.757033169396166, 0.7573041857330961, 0.7590573385327829, 0.759175221619799, 0.7601000883306438, 0.760538980167589, 0.7612640142934228, 0.760166811284712]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label valuesLoading train:   1%|▏         | 4/285 [00:07<09:29,  2.03s/it]Loading train:   2%|▏         | 5/285 [00:09<09:04,  1.94s/it]Loading train:   2%|▏         | 6/285 [00:10<08:16,  1.78s/it]Loading train:   2%|▏         | 7/285 [00:13<08:43,  1.88s/it]Loading train:   3%|▎         | 8/285 [00:14<08:32,  1.85s/it]Loading train:   3%|▎         | 9/285 [00:16<08:47,  1.91s/it]Loading train:   4%|▎         | 10/285 [00:18<07:57,  1.74s/it]Loading train:   4%|▍         | 11/285 [00:19<07:47,  1.70s/it]Loading train:   4%|▍         | 12/285 [00:21<07:40,  1.69s/it]Loading train:   5%|▍         | 13/285 [00:23<07:32,  1.66s/it]Loading train:   5%|▍         | 14/285 [00:24<07:22,  1.63s/it]Loading train:   5%|▌         | 15/285 [00:26<07:15,  1.61s/it]Loading train:   6%|▌         | 16/285 [00:27<07:10,  1.60s/it]Loading train:   6%|▌         | 17/285 [00:28<06:17,  1.41s/it]Loading train:   6%|▋         | 18/285 [00:30<06:21,  1.43s/it]Loading train:   7%|▋         | 19/285 [00:31<06:02,  1.36s/it]Loading train:   7%|▋         | 20/285 [00:32<06:14,  1.41s/it]Loading train:   7%|▋         | 21/285 [00:34<06:40,  1.52s/it]Loading train:   8%|▊         | 22/285 [00:36<06:29,  1.48s/it]Loading train:   8%|▊         | 23/285 [00:37<06:51,  1.57s/it]Loading train:   8%|▊         | 24/285 [00:39<06:38,  1.53s/it]Loading train:   9%|▉         | 25/285 [00:40<06:17,  1.45s/it]Loading train:   9%|▉         | 26/285 [00:42<06:15,  1.45s/it]Loading train:   9%|▉         | 27/285 [00:43<06:20,  1.47s/it]Loading train:  10%|▉         | 28/285 [00:45<06:28,  1.51s/it]Loading train:  10%|█         | 29/285 [00:46<06:18,  1.48s/it]Loading train:  11%|█         | 30/285 [00:48<06:50,  1.61s/it]Loading train:  11%|█         | 31/285 [00:49<06:18,  1.49s/it]Loading train:  11%|█         | 32/285 [00:51<06:30,  1.54s/it]Loading train:  12%|█▏        | 33/285 [00:53<06:55,  1.65s/it]Loading train:  12%|█▏        | 34/285 [00:54<06:34,  1.57s/it]Loading train:  12%|█▏        | 35/285 [00:56<06:21,  1.52s/it]Loading train:  13%|█▎        | 36/285 [00:57<06:12,  1.50s/it]Loading train:  13%|█▎        | 37/285 [00:59<06:37,  1.60s/it]Loading train:  13%|█▎        | 38/285 [01:00<06:30,  1.58s/it]Loading train:  14%|█▎        | 39/285 [01:02<05:55,  1.45s/it]Loading train:  14%|█▍        | 40/285 [01:03<06:04,  1.49s/it]Loading train:  14%|█▍        | 41/285 [01:04<05:42,  1.40s/it]Loading train:  15%|█▍        | 42/285 [01:05<05:15,  1.30s/it]Loading train:  15%|█▌        | 43/285 [01:07<05:34,  1.38s/it]Loading train:  15%|█▌        | 44/285 [01:09<06:41,  1.67s/it]Loading train:  16%|█▌        | 45/285 [01:11<06:57,  1.74s/it]Loading train:  16%|█▌        | 46/285 [01:13<06:46,  1.70s/it]Loading train:  16%|█▋        | 47/285 [01:14<06:29,  1.64s/it]Loading train:  17%|█▋        | 48/285 [01:16<06:40,  1.69s/it]Loading train:  17%|█▋        | 49/285 [01:18<06:23,  1.63s/it]Loading train:  18%|█▊        | 50/285 [01:19<05:47,  1.48s/it]Loading train:  18%|█▊        | 51/285 [01:20<05:44,  1.47s/it]Loading train:  18%|█▊        | 52/285 [01:22<06:16,  1.62s/it]Loading train:  19%|█▊        | 53/285 [01:24<06:27,  1.67s/it]Loading train:  19%|█▉        | 54/285 [01:25<06:19,  1.64s/it]Loading train:  19%|█▉        | 55/285 [01:27<06:05,  1.59s/it]Loading train:  20%|█▉        | 56/285 [01:28<05:54,  1.55s/it]Loading train:  20%|██        | 57/285 [01:30<05:36,  1.48s/it]Loading train:  20%|██        | 58/285 [01:31<05:33,  1.47s/it]Loading train:  21%|██        | 59/285 [01:33<05:35,  1.48s/it]Loading train:  21%|██        | 60/285 [01:34<05:28,  1.46s/it]Loading train:  21%|██▏       | 61/285 [01:35<05:13,  1.40s/it]Loading train:  22%|██▏       | 62/285 [01:37<05:08,  1.38s/it]Loading train:  22%|██▏       | 63/285 [01:38<05:13,  1.41s/it]Loading train:  22%|██▏       | 64/285 [01:40<05:46,  1.57s/it]Loading train:  23%|██▎       | 65/285 [01:42<06:25,  1.75s/it]Loading train:  23%|██▎       | 66/285 [01:45<06:58,  1.91s/it]Loading train:  24%|██▎       | 67/285 [01:46<06:26,  1.77s/it]Loading train:  24%|██▍       | 68/285 [01:48<06:12,  1.72s/it]Loading train:  24%|██▍       | 69/285 [01:49<06:21,  1.77s/it]Loading train:  25%|██▍       | 70/285 [01:51<06:18,  1.76s/it]Loading train:  25%|██▍       | 71/285 [01:53<05:45,  1.61s/it]Loading train:  25%|██▌       | 72/285 [01:54<05:27,  1.54s/it]Loading train:  26%|██▌       | 73/285 [01:56<05:48,  1.64s/it]Loading train:  26%|██▌       | 74/285 [01:57<05:41,  1.62s/it]Loading train:  26%|██▋       | 75/285 [01:59<05:40,  1.62s/it]Loading train:  27%|██▋       | 76/285 [02:00<05:19,  1.53s/it]Loading train:  27%|██▋       | 77/285 [02:01<04:54,  1.42s/it]Loading train:  27%|██▋       | 78/285 [02:03<04:59,  1.45s/it]Loading train:  28%|██▊       | 79/285 [02:05<05:10,  1.51s/it]Loading train:  28%|██▊       | 80/285 [02:06<05:14,  1.53s/it]Loading train:  28%|██▊       | 81/285 [02:08<05:19,  1.56s/it]Loading train:  29%|██▉       | 82/285 [02:09<05:17,  1.56s/it]Loading train:  29%|██▉       | 83/285 [02:11<05:04,  1.51s/it]Loading train:  29%|██▉       | 84/285 [02:13<05:30,  1.65s/it]Loading train:  30%|██▉       | 85/285 [02:14<05:21,  1.61s/it]Loading train:  30%|███       | 86/285 [02:16<05:19,  1.60s/it]Loading train:  31%|███       | 87/285 [02:17<05:19,  1.62s/it]Loading train:  31%|███       | 88/285 [02:19<05:22,  1.64s/it]Loading train:  31%|███       | 89/285 [02:21<05:08,  1.58s/it]Loading train:  32%|███▏      | 90/285 [02:22<05:07,  1.57s/it]Loading train:  32%|███▏      | 91/285 [02:24<04:54,  1.52s/it]Loading train:  32%|███▏      | 92/285 [02:25<04:32,  1.41s/it]Loading train:  33%|███▎      | 93/285 [02:26<04:46,  1.49s/it]Loading train:  33%|███▎      | 94/285 [02:28<05:01,  1.58s/it]Loading train:  33%|███▎      | 95/285 [02:30<05:04,  1.61s/it]Loading train:  34%|███▎      | 96/285 [02:31<05:02,  1.60s/it]Loading train:  34%|███▍      | 97/285 [02:33<05:12,  1.66s/it]Loading train:  34%|███▍      | 98/285 [02:35<05:21,  1.72s/it]Loading train:  35%|███▍      | 99/285 [02:37<05:39,  1.83s/it]Loading train:  35%|███▌      | 100/285 [02:39<05:28,  1.77s/it]Loading train:  35%|███▌      | 101/285 [02:40<05:17,  1.73s/it]Loading train:  36%|███▌      | 102/285 [02:42<05:29,  1.80s/it]Loading train:  36%|███▌      | 103/285 [02:44<05:09,  1.70s/it]Loading train:  36%|███▋      | 104/285 [02:46<05:36,  1.86s/it]Loading train:  37%|███▋      | 105/285 [02:48<05:21,  1.78s/it]Loading train:  37%|███▋      | 106/285 [02:49<04:52,  1.63s/it]Loading train:  38%|███▊      | 107/285 [02:51<05:13,  1.76s/it]Loading train:  38%|███▊      | 108/285 [02:53<05:14,  1.78s/it]Loading train:  38%|███▊      | 109/285 [02:55<05:31,  1.88s/it]Loading train:  39%|███▊      | 110/285 [02:57<05:42,  1.96s/it]Loading train:  39%|███▉      | 111/285 [02:59<05:20,  1.84s/it]Loading train:  39%|███▉      | 112/285 [03:01<05:43,  1.98s/it]Loading train:  40%|███▉      | 113/285 [03:03<05:35,  1.95s/it]Loading train:  40%|████      | 114/285 [03:04<05:11,  1.82s/it]Loading train:  40%|████      | 115/285 [03:06<05:16,  1.86s/it]Loading train:  41%|████      | 116/285 [03:08<05:13,  1.86s/it]Loading train:  41%|████      | 117/285 [03:10<05:11,  1.86s/it]Loading train:  41%|████▏     | 118/285 [03:11<04:43,  1.70s/it]Loading train:  42%|████▏     | 119/285 [03:13<04:34,  1.65s/it]Loading train:  42%|████▏     | 120/285 [03:15<04:35,  1.67s/it]Loading train:  42%|████▏     | 121/285 [03:17<05:21,  1.96s/it]Loading train:  43%|████▎     | 122/285 [03:19<05:20,  1.97s/it]Loading train:  43%|████▎     | 123/285 [03:21<05:22,  1.99s/it]Loading train:  44%|████▎     | 124/285 [03:23<05:09,  1.92s/it]Loading train:  44%|████▍     | 125/285 [03:25<05:11,  1.95s/it]Loading train:  44%|████▍     | 126/285 [03:26<04:40,  1.77s/it]Loading train:  45%|████▍     | 127/285 [03:28<04:21,  1.66s/it]Loading train:  45%|████▍     | 128/285 [03:29<04:17,  1.64s/it]Loading train:  45%|████▌     | 129/285 [03:31<04:03,  1.56s/it]Loading train:  46%|████▌     | 130/285 [03:32<03:45,  1.45s/it]Loading train:  46%|████▌     | 131/285 [03:34<04:03,  1.58s/it]Loading train:  46%|████▋     | 132/285 [03:35<03:59,  1.57s/it]Loading train:  47%|████▋     | 133/285 [03:37<03:38,  1.44s/it]Loading train:  47%|████▋     | 134/285 [03:38<03:41,  1.47s/it]Loading train:  47%|████▋     | 135/285 [03:40<04:18,  1.72s/it]Loading train:  48%|████▊     | 136/285 [03:42<04:10,  1.68s/it]Loading train:  48%|████▊     | 137/285 [03:45<04:56,  2.00s/it]Loading train:  48%|████▊     | 138/285 [03:47<04:48,  1.97s/it]Loading train:  49%|████▉     | 139/285 [03:48<04:12,  1.73s/it]Loading train:  49%|████▉     | 140/285 [03:49<03:49,  1.58s/it]Loading train:  49%|████▉     | 141/285 [03:51<03:49,  1.59s/it]Loading train:  50%|████▉     | 142/285 [03:52<03:33,  1.49s/it]Loading train:  50%|█████     | 143/285 [03:54<03:38,  1.54s/it]Loading train:  51%|█████     | 144/285 [03:56<03:53,  1.66s/it]Loading train:  51%|█████     | 145/285 [03:57<03:42,  1.59s/it]Loading train:  51%|█████     | 146/285 [03:58<03:22,  1.45s/it]Loading train:  52%|█████▏    | 147/285 [03:59<03:18,  1.44s/it]Loading train:  52%|█████▏    | 148/285 [04:01<03:07,  1.37s/it]Loading train:  52%|█████▏    | 149/285 [04:02<03:05,  1.36s/it]Loading train:  53%|█████▎    | 150/285 [04:03<02:58,  1.32s/it]Loading train:  53%|█████▎    | 151/285 [04:04<02:53,  1.29s/it]Loading train:  53%|█████▎    | 152/285 [04:05<02:38,  1.19s/it]Loading train:  54%|█████▎    | 153/285 [04:07<02:39,  1.21s/it]Loading train:  54%|█████▍    | 154/285 [04:08<02:37,  1.20s/it]Loading train:  54%|█████▍    | 155/285 [04:09<02:28,  1.14s/it]Loading train:  55%|█████▍    | 156/285 [04:10<02:24,  1.12s/it]Loading train:  55%|█████▌    | 157/285 [04:11<02:22,  1.12s/it]Loading train:  55%|█████▌    | 158/285 [04:12<02:30,  1.19s/it]Loading train:  56%|█████▌    | 159/285 [04:14<02:38,  1.26s/it]Loading train:  56%|█████▌    | 160/285 [04:15<02:36,  1.25s/it]Loading train:  56%|█████▋    | 161/285 [04:16<02:34,  1.24s/it]Loading train:  57%|█████▋    | 162/285 [04:17<02:26,  1.19s/it]Loading train:  57%|█████▋    | 163/285 [04:19<02:25,  1.19s/it]Loading train:  58%|█████▊    | 164/285 [04:20<02:23,  1.19s/it]Loading train:  58%|█████▊    | 165/285 [04:21<02:17,  1.15s/it]Loading train:  58%|█████▊    | 166/285 [04:22<02:16,  1.15s/it]Loading train:  59%|█████▊    | 167/285 [04:23<02:12,  1.13s/it]Loading train:  59%|█████▉    | 168/285 [04:24<02:08,  1.09s/it]Loading train:  59%|█████▉    | 169/285 [04:25<02:02,  1.06s/it]Loading train:  60%|█████▉    | 170/285 [04:26<01:56,  1.02s/it]Loading train:  60%|██████    | 171/285 [04:27<02:03,  1.08s/it]Loading train:  60%|██████    | 172/285 [04:28<01:56,  1.03s/it]Loading train:  61%|██████    | 173/285 [04:29<01:52,  1.01s/it]Loading train:  61%|██████    | 174/285 [04:30<01:53,  1.02s/it]Loading train:  61%|██████▏   | 175/285 [04:31<01:54,  1.04s/it]Loading train:  62%|██████▏   | 176/285 [04:32<01:58,  1.09s/it]Loading train:  62%|██████▏   | 177/285 [04:33<01:57,  1.09s/it]Loading train:  62%|██████▏   | 178/285 [04:34<01:49,  1.03s/it]Loading train:  63%|██████▎   | 179/285 [04:35<01:50,  1.04s/it]Loading train:  63%|██████▎   | 180/285 [04:37<01:59,  1.14s/it]Loading train:  64%|██████▎   | 181/285 [04:38<01:58,  1.14s/it]Loading train:  64%|██████▍   | 182/285 [04:39<01:57,  1.14s/it]Loading train:  64%|██████▍   | 183/285 [04:40<01:56,  1.14s/it]Loading train:  65%|██████▍   | 184/285 [04:41<01:48,  1.07s/it]Loading train:  65%|██████▍   | 185/285 [04:42<01:47,  1.07s/it]Loading train:  65%|██████▌   | 186/285 [04:44<02:01,  1.22s/it]Loading train:  66%|██████▌   | 187/285 [04:45<02:03,  1.26s/it]Loading train:  66%|██████▌   | 188/285 [04:46<02:05,  1.29s/it]Loading train:  66%|██████▋   | 189/285 [04:47<01:53,  1.18s/it]Loading train:  67%|██████▋   | 190/285 [04:49<01:50,  1.16s/it]Loading train:  67%|██████▋   | 191/285 [04:50<01:44,  1.11s/it]Loading train:  67%|██████▋   | 192/285 [04:51<01:41,  1.09s/it]Loading train:  68%|██████▊   | 193/285 [04:51<01:33,  1.02s/it]Loading train:  68%|██████▊   | 194/285 [04:53<01:35,  1.05s/it]Loading train:  68%|██████▊   | 195/285 [04:54<01:34,  1.05s/it]Loading train:  69%|██████▉   | 196/285 [04:55<01:36,  1.08s/it]Loading train:  69%|██████▉   | 197/285 [04:56<01:40,  1.14s/it]Loading train:  69%|██████▉   | 198/285 [04:58<01:49,  1.26s/it]Loading train:  70%|██████▉   | 199/285 [04:58<01:38,  1.15s/it]Loading train:  70%|███████   | 200/285 [05:00<01:36,  1.14s/it]Loading train:  71%|███████   | 201/285 [05:01<01:37,  1.16s/it]Loading train:  71%|███████   | 202/285 [05:02<01:33,  1.12s/it]Loading train:  71%|███████   | 203/285 [05:03<01:32,  1.12s/it]Loading train:  72%|███████▏  | 204/285 [05:04<01:27,  1.08s/it]Loading train:  72%|███████▏  | 205/285 [05:05<01:23,  1.05s/it]Loading train:  72%|███████▏  | 206/285 [05:06<01:18,  1.01it/s]Loading train:  73%|███████▎  | 207/285 [05:07<01:23,  1.07s/it]Loading train:  73%|███████▎  | 208/285 [05:08<01:24,  1.10s/it]Loading train:  73%|███████▎  | 209/285 [05:09<01:28,  1.17s/it]Loading train:  74%|███████▎  | 210/285 [05:10<01:21,  1.09s/it]Loading train:  74%|███████▍  | 211/285 [05:12<01:22,  1.11s/it]Loading train:  74%|███████▍  | 212/285 [05:13<01:19,  1.09s/it]Loading train:  75%|███████▍  | 213/285 [05:14<01:19,  1.11s/it]Loading train:  75%|███████▌  | 214/285 [05:15<01:14,  1.06s/it]Loading train:  75%|███████▌  | 215/285 [05:16<01:20,  1.16s/it]Loading train:  76%|███████▌  | 216/285 [05:17<01:22,  1.20s/it]Loading train:  76%|███████▌  | 217/285 [05:19<01:22,  1.21s/it]Loading train:  76%|███████▋  | 218/285 [05:20<01:18,  1.16s/it]Loading train:  77%|███████▋  | 219/285 [05:21<01:18,  1.19s/it]Loading train:  77%|███████▋  | 220/285 [05:22<01:14,  1.15s/it]Loading train:  78%|███████▊  | 221/285 [05:23<01:08,  1.08s/it]Loading train:  78%|███████▊  | 222/285 [05:24<01:06,  1.06s/it]Loading train:  78%|███████▊  | 223/285 [05:25<01:04,  1.04s/it]Loading train:  79%|███████▊  | 224/285 [05:26<01:01,  1.01s/it]Loading train:  79%|███████▉  | 225/285 [05:27<01:06,  1.11s/it]Loading train:  79%|███████▉  | 226/285 [05:29<01:12,  1.22s/it]Loading train:  80%|███████▉  | 227/285 [05:30<01:07,  1.17s/it]Loading train:  80%|████████  | 228/285 [05:31<01:14,  1.32s/it]Loading train:  80%|████████  | 229/285 [05:33<01:11,  1.28s/it]Loading train:  81%|████████  | 230/285 [05:34<01:06,  1.21s/it]Loading train:  81%|████████  | 231/285 [05:35<01:01,  1.14s/it]Loading train:  81%|████████▏ | 232/285 [05:36<01:00,  1.14s/it]Loading train:  82%|████████▏ | 233/285 [05:37<00:56,  1.09s/it]Loading train:  82%|████████▏ | 234/285 [05:38<00:57,  1.13s/it]Loading train:  82%|████████▏ | 235/285 [05:39<00:53,  1.07s/it]Loading train:  83%|████████▎ | 236/285 [05:40<00:52,  1.08s/it]Loading train:  83%|████████▎ | 237/285 [05:41<00:54,  1.14s/it]Loading train:  84%|████████▎ | 238/285 [05:43<00:56,  1.19s/it]Loading train:  84%|████████▍ | 239/285 [05:44<00:52,  1.15s/it]Loading train:  84%|████████▍ | 240/285 [05:45<00:48,  1.09s/it]Loading train:  85%|████████▍ | 241/285 [05:46<00:46,  1.06s/it]Loading train:  85%|████████▍ | 242/285 [05:47<00:44,  1.03s/it]Loading train:  85%|████████▌ | 243/285 [05:47<00:41,  1.00it/s]Loading train:  86%|████████▌ | 244/285 [05:49<00:41,  1.02s/it]Loading train:  86%|████████▌ | 245/285 [05:49<00:40,  1.01s/it]Loading train:  86%|████████▋ | 246/285 [05:51<00:44,  1.13s/it]Loading train:  87%|████████▋ | 247/285 [05:52<00:44,  1.17s/it]Loading train:  87%|████████▋ | 248/285 [05:53<00:42,  1.15s/it]Loading train:  87%|████████▋ | 249/285 [05:54<00:38,  1.08s/it]Loading train:  88%|████████▊ | 250/285 [05:55<00:38,  1.09s/it]Loading train:  88%|████████▊ | 251/285 [05:56<00:34,  1.02s/it]Loading train:  88%|████████▊ | 252/285 [05:57<00:33,  1.03s/it]Loading train:  89%|████████▉ | 253/285 [05:58<00:33,  1.06s/it]Loading train:  89%|████████▉ | 254/285 [06:00<00:33,  1.09s/it]Loading train:  89%|████████▉ | 255/285 [06:01<00:32,  1.09s/it]Loading train:  90%|████████▉ | 256/285 [06:02<00:30,  1.05s/it]Loading train:  90%|█████████ | 257/285 [06:03<00:28,  1.03s/it]Loading train:  91%|█████████ | 258/285 [06:04<00:29,  1.10s/it]Loading train:  91%|█████████ | 259/285 [06:05<00:31,  1.22s/it]Loading train:  91%|█████████ | 260/285 [06:06<00:28,  1.13s/it]Loading train:  92%|█████████▏| 261/285 [06:07<00:26,  1.11s/it]Loading train:  92%|█████████▏| 262/285 [06:08<00:25,  1.10s/it]Loading train:  92%|█████████▏| 263/285 [06:09<00:23,  1.06s/it]Loading train:  93%|█████████▎| 264/285 [06:11<00:26,  1.26s/it]Loading train:  93%|█████████▎| 265/285 [06:12<00:25,  1.27s/it]Loading train:  93%|█████████▎| 266/285 [06:13<00:22,  1.16s/it]Loading train:  94%|█████████▎| 267/285 [06:14<00:19,  1.08s/it]Loading train:  94%|█████████▍| 268/285 [06:16<00:19,  1.17s/it]Loading train:  94%|█████████▍| 269/285 [06:17<00:18,  1.16s/it]Loading train:  95%|█████████▍| 270/285 [06:18<00:16,  1.09s/it]Loading train:  95%|█████████▌| 271/285 [06:19<00:14,  1.06s/it]Loading train:  95%|█████████▌| 272/285 [06:20<00:13,  1.02s/it]Loading train:  96%|█████████▌| 273/285 [06:20<00:11,  1.01it/s]Loading train:  96%|█████████▌| 274/285 [06:22<00:11,  1.04s/it]Loading train:  96%|█████████▋| 275/285 [06:23<00:10,  1.09s/it]Loading train:  97%|█████████▋| 276/285 [06:24<00:10,  1.15s/it]Loading train:  97%|█████████▋| 277/285 [06:25<00:08,  1.09s/it]Loading train:  98%|█████████▊| 278/285 [06:26<00:07,  1.08s/it]Loading train:  98%|█████████▊| 279/285 [06:27<00:06,  1.12s/it]Loading train:  98%|█████████▊| 280/285 [06:28<00:05,  1.06s/it]Loading train:  99%|█████████▊| 281/285 [06:29<00:04,  1.06s/it]Loading train:  99%|█████████▉| 282/285 [06:30<00:03,  1.07s/it]Loading train:  99%|█████████▉| 283/285 [06:32<00:02,  1.12s/it]Loading train: 100%|█████████▉| 284/285 [06:33<00:01,  1.12s/it]Loading train: 100%|██████████| 285/285 [06:34<00:00,  1.14s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:04, 60.90it/s]concatenating: train:   4%|▍         | 12/285 [00:00<00:05, 53.49it/s]concatenating: train:   6%|▋         | 18/285 [00:00<00:04, 54.02it/s]concatenating: train:   9%|▉         | 25/285 [00:00<00:04, 56.91it/s]concatenating: train:  12%|█▏        | 35/285 [00:00<00:03, 65.35it/s]concatenating: train:  17%|█▋        | 48/285 [00:00<00:03, 74.72it/s]concatenating: train:  20%|█▉        | 56/285 [00:00<00:03, 70.58it/s]concatenating: train:  22%|██▏       | 64/285 [00:00<00:03, 73.16it/s]concatenating: train:  26%|██▌       | 73/285 [00:01<00:02, 75.94it/s]concatenating: train:  28%|██▊       | 81/285 [00:01<00:02, 72.91it/s]concatenating: train:  31%|███       | 89/285 [00:01<00:02, 69.44it/s]concatenating: train:  34%|███▍      | 97/285 [00:01<00:02, 71.45it/s]concatenating: train:  39%|███▊      | 110/285 [00:01<00:02, 81.98it/s]concatenating: train:  42%|████▏     | 119/285 [00:01<00:01, 83.40it/s]concatenating: train:  45%|████▍     | 128/285 [00:01<00:01, 79.73it/s]concatenating: train:  49%|████▉     | 141/285 [00:01<00:01, 89.46it/s]concatenating: train:  53%|█████▎    | 151/285 [00:01<00:01, 90.48it/s]concatenating: train:  56%|█████▋    | 161/285 [00:02<00:01, 79.76it/s]concatenating: train:  60%|█████▉    | 170/285 [00:02<00:01, 73.63it/s]concatenating: train:  62%|██████▏   | 178/285 [00:02<00:01, 66.44it/s]concatenating: train:  65%|██████▌   | 186/285 [00:02<00:01, 61.03it/s]concatenating: train:  68%|██████▊   | 193/285 [00:02<00:01, 60.19it/s]concatenating: train:  70%|███████   | 200/285 [00:02<00:01, 61.25it/s]concatenating: train:  73%|███████▎  | 207/285 [00:02<00:01, 62.48it/s]concatenating: train:  75%|███████▌  | 215/285 [00:02<00:01, 66.24it/s]concatenating: train:  78%|███████▊  | 222/285 [00:03<00:00, 66.30it/s]concatenating: train:  82%|████████▏ | 234/285 [00:03<00:00, 76.15it/s]concatenating: train:  85%|████████▌ | 243/285 [00:03<00:00, 78.28it/s]concatenating: train:  88%|████████▊ | 252/285 [00:03<00:00, 74.21it/s]concatenating: train: 100%|██████████| 285/285 [00:03<00:00, 81.36it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.39s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.36s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.29s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 38.17it/s]2019-07-11 04:07:54.586889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 04:07:54.587040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 04:07:54.587060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 04:07:54.587073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 04:07:54.587630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:11,  3.83it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:08,  4.78it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:08,  4.80it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.28it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  5.99it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.53it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.16it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.03it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.52it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.23it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.66it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:02,  8.39it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  8.41it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.02it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.84it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.50it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.78it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  6.65it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.85it/s] min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 26, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 26, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 26, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 26, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 13, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 13, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 13, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 20, 13, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 40, 26, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 40, 26, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 40, 26, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 80, 52, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 80, 52, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 52, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 80, 52, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 10)   5410        dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 10)   40          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 10)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 80, 52, 10)   0           activation_11[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 10)   910         dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 80, 52, 10)   40          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 52, 10)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 80, 52, 10)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 70)   0           dropout_5[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 52, 13)   923         concatenate_7[0][0]              
==================================================================================================
Total params: 230,363
Trainable params: 55,643
Non-trainable params: 174,720
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 16s - loss: 2.4747 - acc: 0.7073 - mDice: 0.1422 - val_loss: 1.4630 - val_acc: 0.9038 - val_mDice: 0.3522

Epoch 00001: val_mDice improved from -inf to 0.35219, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 10s - loss: 0.7470 - acc: 0.8808 - mDice: 0.4650 - val_loss: 1.3272 - val_acc: 0.9028 - val_mDice: 0.3908

Epoch 00002: val_mDice improved from 0.35219 to 0.39078, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 10s - loss: 0.5402 - acc: 0.8856 - mDice: 0.5691 - val_loss: 0.8384 - val_acc: 0.9075 - val_mDice: 0.5715

Epoch 00003: val_mDice improved from 0.39078 to 0.57151, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 10s - loss: 0.4824 - acc: 0.8891 - mDice: 0.6037 - val_loss: 0.8280 - val_acc: 0.9092 - val_mDice: 0.5671

Epoch 00004: val_mDice did not improve from 0.57151
Epoch 5/300
 - 10s - loss: 0.4508 - acc: 0.8922 - mDice: 0.6239 - val_loss: 0.8361 - val_acc: 0.9123 - val_mDice: 0.5582

Epoch 00005: val_mDice did not improve from 0.57151
Epoch 6/300
 - 10s - loss: 0.4295 - acc: 0.8965 - mDice: 0.6376 - val_loss: 0.8004 - val_acc: 0.9176 - val_mDice: 0.5781

Epoch 00006: val_mDice improved from 0.57151 to 0.57806, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 11s - loss: 0.4127 - acc: 0.9032 - mDice: 0.6487 - val_loss: 0.8128 - val_acc: 0.9210 - val_mDice: 0.5688

Epoch 00007: val_mDice did not improve from 0.57806
Epoch 8/300
 - 10s - loss: 0.4019 - acc: 0.9196 - mDice: 0.6557 - val_loss: 0.8034 - val_acc: 0.9435 - val_mDice: 0.5722

Epoch 00008: val_mDice did not improve from 0.57806
Epoch 9/300
 - 10s - loss: 0.3911 - acc: 0.9360 - mDice: 0.6619 - val_loss: 0.8073 - val_acc: 0.9408 - val_mDice: 0.5698

Epoch 00009: val_mDice did not improve from 0.57806
Epoch 10/300
 - 10s - loss: 0.3793 - acc: 0.9388 - mDice: 0.6697 - val_loss: 0.8977 - val_acc: 0.9415 - val_mDice: 0.5278

Epoch 00010: val_mDice did not improve from 0.57806
Epoch 11/300
 - 10s - loss: 0.3724 - acc: 0.9397 - mDice: 0.6744 - val_loss: 0.8280 - val_acc: 0.9380 - val_mDice: 0.5647

Epoch 00011: val_mDice did not improve from 0.57806
Epoch 12/300
 - 10s - loss: 0.3663 - acc: 0.9404 - mDice: 0.6786 - val_loss: 0.8040 - val_acc: 0.9369 - val_mDice: 0.5792

Epoch 00012: val_mDice improved from 0.57806 to 0.57925, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 10s - loss: 0.3584 - acc: 0.9410 - mDice: 0.6839 - val_loss: 0.8319 - val_acc: 0.9394 - val_mDice: 0.5564

Epoch 00013: val_mDice did not improve from 0.57925
Epoch 14/300
 - 10s - loss: 0.3527 - acc: 0.9417 - mDice: 0.6880 - val_loss: 0.8154 - val_acc: 0.9375 - val_mDice: 0.5695

Epoch 00014: val_mDice did not improve from 0.57925
Epoch 15/300
 - 10s - loss: 0.3489 - acc: 0.9418 - mDice: 0.6908 - val_loss: 0.8184 - val_acc: 0.9413 - val_mDice: 0.5629

Epoch 00015: val_mDice did not improve from 0.57925
Epoch 16/300
 - 10s - loss: 0.3432 - acc: 0.9423 - mDice: 0.6948 - val_loss: 0.7943 - val_acc: 0.9399 - val_mDice: 0.5763

Epoch 00016: val_mDice did not improve from 0.57925
Epoch 17/300
 - 10s - loss: 0.3387 - acc: 0.9427 - mDice: 0.6981 - val_loss: 0.7457 - val_acc: 0.9421 - val_mDice: 0.5854

Epoch 00017: val_mDice improved from 0.57925 to 0.58535, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 10s - loss: 0.3354 - acc: 0.9431 - mDice: 0.7004 - val_loss: 0.8821 - val_acc: 0.9389 - val_mDice: 0.5226

Epoch 00018: val_mDice did not improve from 0.58535
Epoch 19/300
 - 10s - loss: 0.3344 - acc: 0.9433 - mDice: 0.7012 - val_loss: 0.8134 - val_acc: 0.9405 - val_mDice: 0.5712

Epoch 00019: val_mDice did not improve from 0.58535
Epoch 20/300
 - 10s - loss: 0.3276 - acc: 0.9438 - mDice: 0.7061 - val_loss: 0.8371 - val_acc: 0.9389 - val_mDice: 0.5507

Epoch 00020: val_mDice did not improve from 0.58535
Epoch 21/300
 - 10s - loss: 0.3265 - acc: 0.9437 - mDice: 0.7069 - val_loss: 0.8401 - val_acc: 0.9382 - val_mDice: 0.5549

Epoch 00021: val_mDice did not improve from 0.58535
Epoch 22/300
 - 10s - loss: 0.3239 - acc: 0.9442 - mDice: 0.7088 - val_loss: 0.8149 - val_acc: 0.9376 - val_mDice: 0.5639

Epoch 00022: val_mDice did not improve from 0.58535
Epoch 23/300
 - 10s - loss: 0.3220 - acc: 0.9444 - mDice: 0.7103 - val_loss: 0.8081 - val_acc: 0.9435 - val_mDice: 0.5739

Epoch 00023: val_mDice did not improve from 0.58535
Epoch 24/300
 - 10s - loss: 0.3196 - acc: 0.9444 - mDice: 0.7120 - val_loss: 0.8078 - val_acc: 0.9411 - val_mDice: 0.5810

Epoch 00024: val_mDice did not improve from 0.58535
Epoch 25/300
 - 10s - loss: 0.3155 - acc: 0.9449 - mDice: 0.7151 - val_loss: 0.7891 - val_acc: 0.9374 - val_mDice: 0.5825

Epoch 00025: val_mDice did not improve from 0.58535
Epoch 26/300
 - 10s - loss: 0.3138 - acc: 0.9449 - mDice: 0.7163 - val_loss: 0.8250 - val_acc: 0.9433 - val_mDice: 0.5644

Epoch 00026: val_mDice did not improve from 0.58535
Epoch 27/300
 - 10s - loss: 0.3108 - acc: 0.9452 - mDice: 0.7186 - val_loss: 0.8129 - val_acc: 0.9427 - val_mDice: 0.5717

Epoch 00027: val_mDice did not improve from 0.58535
Epoch 28/300
 - 10s - loss: 0.3094 - acc: 0.9453 - mDice: 0.7197 - val_loss: 0.8365 - val_acc: 0.9401 - val_mDice: 0.5434

Epoch 00028: val_mDice did not improve from 0.58535
Epoch 29/300
 - 10s - loss: 0.3091 - acc: 0.9453 - mDice: 0.7199 - val_loss: 0.9587 - val_acc: 0.9335 - val_mDice: 0.4990

Epoch 00029: val_mDice did not improve from 0.58535
Epoch 30/300
 - 10s - loss: 0.3049 - acc: 0.9457 - mDice: 0.7230 - val_loss: 0.7812 - val_acc: 0.9400 - val_mDice: 0.5801

Epoch 00030: val_mDice did not improve from 0.58535
Epoch 31/300
 - 10s - loss: 0.3044 - acc: 0.9457 - mDice: 0.7234 - val_loss: 0.8146 - val_acc: 0.9405 - val_mDice: 0.5567

Epoch 00031: val_mDice did not improve from 0.58535
Epoch 32/300
 - 10s - loss: 0.3022 - acc: 0.9459 - mDice: 0.7250 - val_loss: 0.7881 - val_acc: 0.9379 - val_mDice: 0.5713

Epoch 00032: val_mDice did not improve from 0.58535
Epoch 33/300
 - 10s - loss: 0.3013 - acc: 0.9459 - mDice: 0.7256 - val_loss: 0.7997 - val_acc: 0.9395 - val_mDice: 0.5649

Epoch 00033: val_mDice did not improve from 0.58535
Epoch 34/300
 - 10s - loss: 0.3000 - acc: 0.9460 - mDice: 0.7266 - val_loss: 0.7750 - val_acc: 0.9406 - val_mDice: 0.5797

Epoch 00034: val_mDice did not improve from 0.58535
Epoch 35/300
 - 10s - loss: 0.2986 - acc: 0.9462 - mDice: 0.7278 - val_loss: 0.7750 - val_acc: 0.9423 - val_mDice: 0.5770

Epoch 00035: val_mDice did not improve from 0.58535
Epoch 36/300
 - 10s - loss: 0.2952 - acc: 0.9465 - mDice: 0.7303 - val_loss: 0.7776 - val_acc: 0.9385 - val_mDice: 0.5766

Epoch 00036: val_mDice did not improve from 0.58535
Epoch 37/300
 - 10s - loss: 0.2952 - acc: 0.9465 - mDice: 0.7304 - val_loss: 0.8573 - val_acc: 0.9402 - val_mDice: 0.5281

Epoch 00037: val_mDice did not improve from 0.58535
Epoch 38/300
 - 10s - loss: 0.2944 - acc: 0.9466 - mDice: 0.7310 - val_loss: 0.7551 - val_acc: 0.9422 - val_mDice: 0.5824

Epoch 00038: val_mDice did not improve from 0.58535
Epoch 39/300
 - 10s - loss: 0.2928 - acc: 0.9467 - mDice: 0.7322 - val_loss: 0.8289 - val_acc: 0.9424 - val_mDice: 0.5472

Epoch 00039: val_mDice did not improve from 0.58535
Epoch 40/300
 - 10s - loss: 0.2930 - acc: 0.9466 - mDice: 0.7321 - val_loss: 0.7976 - val_acc: 0.9364 - val_mDice: 0.5587

Epoch 00040: val_mDice did not improve from 0.58535
Epoch 41/300
 - 11s - loss: 0.2910 - acc: 0.9468 - mDice: 0.7336 - val_loss: 0.7936 - val_acc: 0.9414 - val_mDice: 0.5569

Epoch 00041: val_mDice did not improve from 0.58535
Epoch 42/300
 - 10s - loss: 0.2900 - acc: 0.9469 - mDice: 0.7343 - val_loss: 0.7806 - val_acc: 0.9387 - val_mDice: 0.5673

Epoch 00042: val_mDice did not improve from 0.58535
Epoch 43/300
 - 10s - loss: 0.2880 - acc: 0.9470 - mDice: 0.7359 - val_loss: 0.7771 - val_acc: 0.9396 - val_mDice: 0.5706

Epoch 00043: val_mDice did not improve from 0.58535
Epoch 44/300
 - 10s - loss: 0.2864 - acc: 0.9472 - mDice: 0.7371 - val_loss: 0.7863 - val_acc: 0.9395 - val_mDice: 0.5639

Epoch 00044: val_mDice did not improve from 0.58535
Epoch 45/300
 - 10s - loss: 0.2835 - acc: 0.9475 - mDice: 0.7394 - val_loss: 0.8024 - val_acc: 0.9386 - val_mDice: 0.5530

Epoch 00045: val_mDice did not improve from 0.58535
Epoch 46/300
 - 10s - loss: 0.2840 - acc: 0.9473 - mDice: 0.7389 - val_loss: 0.8121 - val_acc: 0.9355 - val_mDice: 0.5413

Epoch 00046: val_mDice did not improve from 0.58535
Epoch 47/300
 - 10s - loss: 0.2838 - acc: 0.9474 - mDice: 0.7391 - val_loss: 0.7407 - val_acc: 0.9435 - val_mDice: 0.5805

Epoch 00047: val_mDice did not improve from 0.58535
Epoch 48/300
 - 10s - loss: 0.2823 - acc: 0.9475 - mDice: 0.7402 - val_loss: 0.7766 - val_acc: 0.9385 - val_mDice: 0.5593

Epoch 00048: val_mDice did not improve from 0.58535
Epoch 49/300
 - 11s - loss: 0.2814 - acc: 0.9475 - mDice: 0.7409 - val_loss: 0.7570 - val_acc: 0.9401 - val_mDice: 0.5694

Epoch 00049: val_mDice did not improve from 0.58535
Epoch 50/300
 - 10s - loss: 0.2803 - acc: 0.9477 - mDice: 0.7419 - val_loss: 0.7832 - val_acc: 0.9420 - val_mDice: 0.5572

Epoch 00050: val_mDice did not improve from 0.58535
Epoch 51/300
 - 10s - loss: 0.2803 - acc: 0.9477 - mDice: 0.7418 - val_loss: 0.7310 - val_acc: 0.9396 - val_mDice: 0.5788

Epoch 00051: val_mDice did not improve from 0.58535
Epoch 52/300
 - 10s - loss: 0.2793 - acc: 0.9477 - mDice: 0.7426 - val_loss: 0.7738 - val_acc: 0.9365 - val_mDice: 0.5628

Epoch 00052: val_mDice did not improve from 0.58535
Epoch 53/300
 - 11s - loss: 0.2787 - acc: 0.9478 - mDice: 0.7430 - val_loss: 0.7429 - val_acc: 0.9406 - val_mDice: 0.5758

Epoch 00053: val_mDice did not improve from 0.58535
Epoch 54/300
 - 10s - loss: 0.2776 - acc: 0.9479 - mDice: 0.7439 - val_loss: 0.7326 - val_acc: 0.9411 - val_mDice: 0.5708

Epoch 00054: val_mDice did not improve from 0.58535
Epoch 55/300
 - 10s - loss: 0.2763 - acc: 0.9480 - mDice: 0.7449 - val_loss: 0.7342 - val_acc: 0.9420 - val_mDice: 0.5736

Epoch 00055: val_mDice did not improve from 0.58535
Epoch 56/300
 - 11s - loss: 0.2760 - acc: 0.9479 - mDice: 0.7452 - val_loss: 0.7114 - val_acc: 0.9371 - val_mDice: 0.5580

Epoch 00056: val_mDice did not improve from 0.58535
Epoch 57/300
 - 11s - loss: 0.2749 - acc: 0.9481 - mDice: 0.7461 - val_loss: 0.7326 - val_acc: 0.9413 - val_mDice: 0.5749

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.23s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.01s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.83s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:05,  1.92s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:25,  1.79s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:19,  1.77s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:51,  1.68s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:58,  1.71s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:35,  1.63s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:47,  1.68s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:47,  1.69s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:10,  1.78s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:28,  1.85s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<07:55,  1.74s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:09,  1.79s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<07:50,  1.73s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<08:00,  1.77s/it]predicting train subjects:   5%|▌         | 15/285 [00:26<08:09,  1.81s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<08:15,  1.84s/it]predicting train subjects:   6%|▌         | 17/285 [00:29<07:47,  1.74s/it]predicting train subjects:   6%|▋         | 18/285 [00:31<07:41,  1.73s/it]predicting train subjects:   7%|▋         | 19/285 [00:32<07:34,  1.71s/it]predicting train subjects:   7%|▋         | 20/285 [00:34<07:41,  1.74s/it]predicting train subjects:   7%|▋         | 21/285 [00:36<07:54,  1.80s/it]predicting train subjects:   8%|▊         | 22/285 [00:38<07:33,  1.73s/it]predicting train subjects:   8%|▊         | 23/285 [00:39<07:40,  1.76s/it]predicting train subjects:   8%|▊         | 24/285 [00:41<07:23,  1.70s/it]predicting train subjects:   9%|▉         | 25/285 [00:43<07:41,  1.77s/it]predicting train subjects:   9%|▉         | 26/285 [00:45<07:53,  1.83s/it]predicting train subjects:   9%|▉         | 27/285 [00:47<07:39,  1.78s/it]predicting train subjects:  10%|▉         | 28/285 [00:48<07:35,  1.77s/it]predicting train subjects:  10%|█         | 29/285 [00:50<07:34,  1.77s/it]predicting train subjects:  11%|█         | 30/285 [00:52<07:44,  1.82s/it]predicting train subjects:  11%|█         | 31/285 [00:54<07:50,  1.85s/it]predicting train subjects:  11%|█         | 32/285 [00:56<07:30,  1.78s/it]predicting train subjects:  12%|█▏        | 33/285 [00:57<07:27,  1.77s/it]predicting train subjects:  12%|█▏        | 34/285 [00:59<07:29,  1.79s/it]predicting train subjects:  12%|█▏        | 35/285 [01:01<07:39,  1.84s/it]predicting train subjects:  13%|█▎        | 36/285 [01:03<07:32,  1.82s/it]predicting train subjects:  13%|█▎        | 37/285 [01:05<07:28,  1.81s/it]predicting train subjects:  13%|█▎        | 38/285 [01:07<07:39,  1.86s/it]predicting train subjects:  14%|█▎        | 39/285 [01:08<07:16,  1.77s/it]predicting train subjects:  14%|█▍        | 40/285 [01:10<07:24,  1.82s/it]predicting train subjects:  14%|█▍        | 41/285 [01:12<07:07,  1.75s/it]predicting train subjects:  15%|█▍        | 42/285 [01:14<07:04,  1.74s/it]predicting train subjects:  15%|█▌        | 43/285 [01:15<07:05,  1.76s/it]predicting train subjects:  15%|█▌        | 44/285 [01:17<07:13,  1.80s/it]predicting train subjects:  16%|█▌        | 45/285 [01:19<06:58,  1.75s/it]predicting train subjects:  16%|█▌        | 46/285 [01:21<07:10,  1.80s/it]predicting train subjects:  16%|█▋        | 47/285 [01:22<07:00,  1.77s/it]predicting train subjects:  17%|█▋        | 48/285 [01:24<07:09,  1.81s/it]predicting train subjects:  17%|█▋        | 49/285 [01:26<07:17,  1.85s/it]predicting train subjects:  18%|█▊        | 50/285 [01:28<07:06,  1.81s/it]predicting train subjects:  18%|█▊        | 51/285 [01:30<07:07,  1.83s/it]predicting train subjects:  18%|█▊        | 52/285 [01:32<06:58,  1.80s/it]predicting train subjects:  19%|█▊        | 53/285 [01:33<06:55,  1.79s/it]predicting train subjects:  19%|█▉        | 54/285 [01:35<07:00,  1.82s/it]predicting train subjects:  19%|█▉        | 55/285 [01:37<06:48,  1.78s/it]predicting train subjects:  20%|█▉        | 56/285 [01:39<06:48,  1.79s/it]predicting train subjects:  20%|██        | 57/285 [01:40<06:35,  1.74s/it]predicting train subjects:  20%|██        | 58/285 [01:42<06:43,  1.78s/it]predicting train subjects:  21%|██        | 59/285 [01:44<06:48,  1.81s/it]predicting train subjects:  21%|██        | 60/285 [01:46<07:03,  1.88s/it]predicting train subjects:  21%|██▏       | 61/285 [01:48<06:41,  1.79s/it]predicting train subjects:  22%|██▏       | 62/285 [01:50<06:47,  1.83s/it]predicting train subjects:  22%|██▏       | 63/285 [01:52<06:47,  1.84s/it]predicting train subjects:  22%|██▏       | 64/285 [01:53<06:29,  1.76s/it]predicting train subjects:  23%|██▎       | 65/285 [01:55<06:30,  1.77s/it]predicting train subjects:  23%|██▎       | 66/285 [01:57<06:33,  1.80s/it]predicting train subjects:  24%|██▎       | 67/285 [01:59<06:32,  1.80s/it]predicting train subjects:  24%|██▍       | 68/285 [02:00<06:20,  1.76s/it]predicting train subjects:  24%|██▍       | 69/285 [02:02<06:21,  1.76s/it]predicting train subjects:  25%|██▍       | 70/285 [02:04<06:21,  1.78s/it]predicting train subjects:  25%|██▍       | 71/285 [02:06<06:29,  1.82s/it]predicting train subjects:  25%|██▌       | 72/285 [02:07<06:16,  1.77s/it]predicting train subjects:  26%|██▌       | 73/285 [02:09<06:16,  1.78s/it]predicting train subjects:  26%|██▌       | 74/285 [02:11<06:13,  1.77s/it]predicting train subjects:  26%|██▋       | 75/285 [02:13<06:14,  1.79s/it]predicting train subjects:  27%|██▋       | 76/285 [02:15<06:20,  1.82s/it]predicting train subjects:  27%|██▋       | 77/285 [02:16<06:05,  1.76s/it]predicting train subjects:  27%|██▋       | 78/285 [02:18<05:56,  1.72s/it]predicting train subjects:  28%|██▊       | 79/285 [02:20<06:01,  1.75s/it]predicting train subjects:  28%|██▊       | 80/285 [02:22<06:02,  1.77s/it]predicting train subjects:  28%|██▊       | 81/285 [02:23<05:54,  1.74s/it]predicting train subjects:  29%|██▉       | 82/285 [02:25<05:55,  1.75s/it]predicting train subjects:  29%|██▉       | 83/285 [02:27<05:45,  1.71s/it]predicting train subjects:  29%|██▉       | 84/285 [02:28<05:41,  1.70s/it]predicting train subjects:  30%|██▉       | 85/285 [02:30<05:52,  1.76s/it]predicting train subjects:  30%|███       | 86/285 [02:32<05:52,  1.77s/it]predicting train subjects:  31%|███       | 87/285 [02:34<05:56,  1.80s/it]predicting train subjects:  31%|███       | 88/285 [02:35<05:43,  1.74s/it]predicting train subjects:  31%|███       | 89/285 [02:37<05:44,  1.76s/it]predicting train subjects:  32%|███▏      | 90/285 [02:39<05:47,  1.78s/it]predicting train subjects:  32%|███▏      | 91/285 [02:41<05:37,  1.74s/it]predicting train subjects:  32%|███▏      | 92/285 [02:43<05:42,  1.78s/it]predicting train subjects:  33%|███▎      | 93/285 [02:44<05:34,  1.74s/it]predicting train subjects:  33%|███▎      | 94/285 [02:46<05:36,  1.76s/it]predicting train subjects:  33%|███▎      | 95/285 [02:48<05:40,  1.79s/it]predicting train subjects:  34%|███▎      | 96/285 [02:50<05:41,  1.81s/it]predicting train subjects:  34%|███▍      | 97/285 [02:52<05:42,  1.82s/it]predicting train subjects:  34%|███▍      | 98/285 [02:54<05:46,  1.86s/it]predicting train subjects:  35%|███▍      | 99/285 [02:55<05:38,  1.82s/it]predicting train subjects:  35%|███▌      | 100/285 [02:57<05:36,  1.82s/it]predicting train subjects:  35%|███▌      | 101/285 [02:59<05:20,  1.74s/it]predicting train subjects:  36%|███▌      | 102/285 [03:01<05:24,  1.78s/it]predicting train subjects:  36%|███▌      | 103/285 [03:02<05:13,  1.72s/it]predicting train subjects:  36%|███▋      | 104/285 [03:04<05:16,  1.75s/it]predicting train subjects:  37%|███▋      | 105/285 [03:06<05:22,  1.79s/it]predicting train subjects:  37%|███▋      | 106/285 [03:07<05:11,  1.74s/it]predicting train subjects:  38%|███▊      | 107/285 [03:09<05:12,  1.75s/it]predicting train subjects:  38%|███▊      | 108/285 [03:11<05:03,  1.72s/it]predicting train subjects:  38%|███▊      | 109/285 [03:13<05:02,  1.72s/it]predicting train subjects:  39%|███▊      | 110/285 [03:14<05:07,  1.76s/it]predicting train subjects:  39%|███▉      | 111/285 [03:16<04:57,  1.71s/it]predicting train subjects:  39%|███▉      | 112/285 [03:18<05:01,  1.74s/it]predicting train subjects:  40%|███▉      | 113/285 [03:20<05:03,  1.76s/it]predicting train subjects:  40%|████      | 114/285 [03:22<05:07,  1.80s/it]predicting train subjects:  40%|████      | 115/285 [03:23<05:00,  1.77s/it]predicting train subjects:  41%|████      | 116/285 [03:25<05:02,  1.79s/it]predicting train subjects:  41%|████      | 117/285 [03:27<04:50,  1.73s/it]predicting train subjects:  41%|████▏     | 118/285 [03:28<04:41,  1.68s/it]predicting train subjects:  42%|████▏     | 119/285 [03:30<04:46,  1.72s/it]predicting train subjects:  42%|████▏     | 120/285 [03:32<04:42,  1.71s/it]predicting train subjects:  42%|████▏     | 121/285 [03:33<04:37,  1.69s/it]predicting train subjects:  43%|████▎     | 122/285 [03:35<04:25,  1.63s/it]predicting train subjects:  43%|████▎     | 123/285 [03:36<04:20,  1.61s/it]predicting train subjects:  44%|████▎     | 124/285 [03:38<04:16,  1.59s/it]predicting train subjects:  44%|████▍     | 125/285 [03:40<04:12,  1.58s/it]predicting train subjects:  44%|████▍     | 126/285 [03:41<04:04,  1.54s/it]predicting train subjects:  45%|████▍     | 127/285 [03:42<03:57,  1.50s/it]predicting train subjects:  45%|████▍     | 128/285 [03:44<03:58,  1.52s/it]predicting train subjects:  45%|████▌     | 129/285 [03:45<03:56,  1.52s/it]predicting train subjects:  46%|████▌     | 130/285 [03:47<03:56,  1.53s/it]predicting train subjects:  46%|████▌     | 131/285 [03:48<03:50,  1.50s/it]predicting train subjects:  46%|████▋     | 132/285 [03:50<03:54,  1.53s/it]predicting train subjects:  47%|████▋     | 133/285 [03:52<03:52,  1.53s/it]predicting train subjects:  47%|████▋     | 134/285 [03:53<03:44,  1.49s/it]predicting train subjects:  47%|████▋     | 135/285 [03:54<03:38,  1.46s/it]predicting train subjects:  48%|████▊     | 136/285 [03:56<03:38,  1.47s/it]predicting train subjects:  48%|████▊     | 137/285 [03:57<03:44,  1.51s/it]predicting train subjects:  48%|████▊     | 138/285 [03:59<03:38,  1.49s/it]predicting train subjects:  49%|████▉     | 139/285 [04:01<03:41,  1.52s/it]predicting train subjects:  49%|████▉     | 140/285 [04:02<03:46,  1.56s/it]predicting train subjects:  49%|████▉     | 141/285 [04:04<03:40,  1.53s/it]predicting train subjects:  50%|████▉     | 142/285 [04:05<03:34,  1.50s/it]predicting train subjects:  50%|█████     | 143/285 [04:07<03:35,  1.52s/it]predicting train subjects:  51%|█████     | 144/285 [04:08<03:35,  1.53s/it]predicting train subjects:  51%|█████     | 145/285 [04:10<03:30,  1.50s/it]predicting train subjects:  51%|█████     | 146/285 [04:11<03:31,  1.52s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:13<03:23,  1.47s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:14<03:27,  1.52s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:16<03:22,  1.49s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:17<03:23,  1.51s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:19<03:28,  1.56s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:20<03:19,  1.50s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:22<03:15,  1.48s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:23<03:21,  1.54s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:25<03:19,  1.54s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:26<03:21,  1.56s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:28<03:16,  1.54s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:29<03:15,  1.54s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:31<03:10,  1.51s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:32<03:08,  1.51s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:34<03:10,  1.53s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:35<03:05,  1.51s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:37<03:07,  1.53s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:39<03:05,  1.53s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:40<03:02,  1.52s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:42<03:08,  1.59s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:43<03:08,  1.59s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:45<02:57,  1.52s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:46<02:55,  1.51s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:48<02:51,  1.49s/it]predicting train subjects:  60%|██████    | 171/285 [04:49<02:48,  1.48s/it]predicting train subjects:  60%|██████    | 172/285 [04:51<02:49,  1.50s/it]predicting train subjects:  61%|██████    | 173/285 [04:52<02:46,  1.48s/it]predicting train subjects:  61%|██████    | 174/285 [04:54<02:44,  1.48s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:55<02:46,  1.51s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:57<02:47,  1.54s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:58<02:41,  1.50s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:00<02:36,  1.46s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:01<02:31,  1.43s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:03<02:42,  1.55s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:05<02:48,  1.62s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:06<02:47,  1.62s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:08<02:38,  1.55s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:09<02:33,  1.52s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:10<02:29,  1.49s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:12<02:39,  1.61s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:14<02:43,  1.67s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:16<02:46,  1.71s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:17<02:36,  1.63s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:19<02:31,  1.59s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:21<02:32,  1.63s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:22<02:32,  1.63s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:24<02:21,  1.54s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:25<02:16,  1.50s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:26<02:12,  1.47s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:28<02:21,  1.60s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:30<02:26,  1.66s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:32<02:27,  1.69s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:33<02:18,  1.61s/it]predicting train subjects:  70%|███████   | 200/285 [05:35<02:11,  1.55s/it]predicting train subjects:  71%|███████   | 201/285 [05:36<02:15,  1.62s/it]predicting train subjects:  71%|███████   | 202/285 [05:38<02:16,  1.64s/it]predicting train subjects:  71%|███████   | 203/285 [05:40<02:14,  1.64s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:41<02:06,  1.57s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:43<02:02,  1.53s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:44<01:56,  1.47s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:46<02:05,  1.61s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:48<02:07,  1.65s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:49<02:08,  1.69s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:51<01:58,  1.58s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:52<01:52,  1.52s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:54<01:53,  1.55s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:55<01:54,  1.58s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:57<01:50,  1.56s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:59<01:56,  1.66s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:00<01:48,  1.58s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:02<01:52,  1.66s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:04<01:54,  1.71s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:06<01:57,  1.78s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:07<01:48,  1.68s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:09<01:43,  1.62s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:10<01:43,  1.65s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:12<01:36,  1.56s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:13<01:33,  1.53s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:15<01:29,  1.48s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:16<01:32,  1.57s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:18<01:34,  1.64s/it]predicting train subjects:  80%|████████  | 228/285 [06:20<01:35,  1.67s/it]predicting train subjects:  80%|████████  | 229/285 [06:22<01:33,  1.68s/it]predicting train subjects:  81%|████████  | 230/285 [06:23<01:26,  1.58s/it]predicting train subjects:  81%|████████  | 231/285 [06:24<01:23,  1.54s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:26<01:25,  1.61s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:28<01:19,  1.54s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:30<01:25,  1.68s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:31<01:22,  1.65s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:33<01:30,  1.84s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:35<01:30,  1.89s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:38<01:31,  1.94s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:39<01:28,  1.93s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:41<01:21,  1.81s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:43<01:17,  1.76s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:44<01:13,  1.70s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:46<01:09,  1.65s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:48<01:12,  1.77s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:49<01:08,  1.72s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:51<01:11,  1.83s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:54<01:13,  1.94s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:56<01:12,  1.96s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:57<01:07,  1.86s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:59<01:03,  1.80s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:01<00:58,  1.73s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:02<00:58,  1.78s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:05<01:02,  1.96s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:07<01:03,  2.05s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:09<01:00,  2.01s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:11<00:54,  1.88s/it]predicting train subjects:  90%|█████████ | 257/285 [07:12<00:52,  1.86s/it]predicting train subjects:  91%|█████████ | 258/285 [07:14<00:51,  1.91s/it]predicting train subjects:  91%|█████████ | 259/285 [07:16<00:50,  1.93s/it]predicting train subjects:  91%|█████████ | 260/285 [07:18<00:46,  1.86s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:20<00:43,  1.80s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:22<00:42,  1.84s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:23<00:39,  1.81s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:25<00:39,  1.88s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:28<00:38,  1.94s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:29<00:34,  1.83s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:31<00:33,  1.86s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:33<00:33,  1.99s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:36<00:32,  2.05s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:37<00:29,  1.94s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:39<00:26,  1.88s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:41<00:25,  1.95s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:43<00:22,  1.88s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:44<00:20,  1.83s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:47<00:19,  1.94s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:49<00:18,  2.04s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:50<00:15,  1.88s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:52<00:12,  1.82s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:54<00:11,  1.90s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:56<00:09,  1.83s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:58<00:07,  1.80s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:59<00:05,  1.77s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:02<00:03,  1.91s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:04<00:02,  2.02s/it]predicting train subjects: 100%|██████████| 285/285 [08:06<00:00,  2.12s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a’: File exists

Epoch 00057: val_mDice did not improve from 0.58535
Restoring model weights from the end of the best epoch
Epoch 00057: early stopping
{'val_loss': [1.463046981738164, 1.3272057404884925, 0.8384210765361786, 0.8280175351179563, 0.8360507190227509, 0.8004281199895419, 0.812834748855004, 0.8034116304837741, 0.8072825693167173, 0.8977336218723884, 0.827970529978092, 0.8040145486593246, 0.8319009817563571, 0.8153729736804962, 0.8184207402742826, 0.7943124656493847, 0.7457173111347052, 0.882107885984274, 0.8134274161778964, 0.8371458214062911, 0.8400954329050504, 0.8149433594483596, 0.8080769250026116, 0.8077820505087192, 0.789121504013355, 0.8249514355109289, 0.8128786132885859, 0.8364689831550305, 0.9587215391489176, 0.7812139277274792, 0.8146117902719058, 0.7881193275635059, 0.7996981625373547, 0.7749634660207309, 0.7749560612898606, 0.7775541039613577, 0.8573105381085322, 0.7550821396020743, 0.8289055388707381, 0.7976371508378249, 0.7935921182999244, 0.7806016367215377, 0.7770848136681777, 0.7863207711623266, 0.8024317897283114, 0.8121089247556833, 0.7406762483028265, 0.7766478886971107, 0.7570263261978443, 0.7831974281714513, 0.7309859108466369, 0.7737547846940848, 0.7429184500987713, 0.7326061312968914, 0.7342079671529623, 0.7113904838378613, 0.7325869752810552], 'val_acc': [0.9038068445829245, 0.9028453047458942, 0.9075328088723696, 0.9091901045579177, 0.9122711878556472, 0.9176220206113962, 0.9210336483441867, 0.9435026920758761, 0.9407868087291718, 0.9414963905627911, 0.9380477712704585, 0.9369036578215085, 0.9394207848952367, 0.9374884687937223, 0.9413392085295457, 0.939945441025954, 0.9421273928422195, 0.9389076209985293, 0.9405186955745404, 0.9389376823718731, 0.9381564236604251, 0.9376386839609879, 0.9435257705358359, 0.9410595137339371, 0.9374468257794013, 0.9432807610585139, 0.9426936759398534, 0.9400956951654874, 0.933462028320019, 0.9400494419611417, 0.9404978935535138, 0.9379021777556493, 0.9394970490382268, 0.9406157594460708, 0.9423331457834977, 0.9384985313965724, 0.9401927796693949, 0.9421898011977856, 0.942400145989198, 0.9364275061167203, 0.9413692905352666, 0.9387435294114627, 0.9395825794109931, 0.9395132179443653, 0.9385840663543115, 0.9354659960820124, 0.9435466115291302, 0.9384522690222814, 0.9401488372912774, 0.9419633104250982, 0.9396103024482727, 0.9365083987896259, 0.9405764364279233, 0.9411196456505702, 0.9420234125394088, 0.9371093763754919, 0.9412767841265752], 'val_mDice': [0.35219300251740676, 0.39078022367679155, 0.5715094584111984, 0.5670501819023719, 0.5582124860240862, 0.5780553399370267, 0.5688270101180444, 0.5721537422102231, 0.5698253890642753, 0.5277624009893491, 0.5647218622840368, 0.5792464619645705, 0.5563755121368629, 0.5695157618476794, 0.5628638651508552, 0.576323348742265, 0.585353672504425, 0.5226203747666799, 0.5712353759087049, 0.5507320245871177, 0.5549467200270066, 0.5639125366623585, 0.5738680735230446, 0.5810311516890159, 0.5825194544517077, 0.5644054538928546, 0.5716509882074136, 0.5433894885847201, 0.4989566184007205, 0.5800709231541707, 0.5566674803312008, 0.571315695460026, 0.5649157335551885, 0.5796831445052073, 0.5770400682320962, 0.5765744378933539, 0.5280575190599148, 0.5824227166863588, 0.5472268310303872, 0.5587318763136864, 0.5569239680010539, 0.5673010888007971, 0.5705870647843068, 0.5639281946306045, 0.5529536730968035, 0.5412520537009606, 0.5804660142614291, 0.5592665294042001, 0.5694347236018914, 0.557249434865438, 0.5787923072393124, 0.5627682954072952, 0.5758122669962736, 0.5708491183244265, 0.5736435921146319, 0.5580222984919181, 0.5749418609417402], 'loss': [2.474731105671019, 0.7469833458821118, 0.5401756033228517, 0.48235094030273035, 0.450769748787131, 0.4294513645981726, 0.41269216242668144, 0.4018993436641538, 0.3911406087043111, 0.37925296611235304, 0.37235551446959353, 0.3662618423980353, 0.3584496068671919, 0.35272334029695857, 0.34887161562883207, 0.343249288141689, 0.3387208495848757, 0.3354172427435703, 0.33436155964019254, 0.32758399259007354, 0.3265472877886444, 0.32391575634627945, 0.3219636744962763, 0.31963349342137304, 0.31548039782952086, 0.31382883299510766, 0.31076062080176964, 0.3093748008051581, 0.30907220592481627, 0.3048884288736741, 0.30444905471342204, 0.3022488398788534, 0.3013340558918224, 0.3000452960701784, 0.29860396972224135, 0.2952250867469124, 0.2951838750164414, 0.29435943569917583, 0.29276938252285, 0.2930138681901949, 0.29100970006303506, 0.2900062234493174, 0.28801541805355285, 0.2863655792526749, 0.283468689894221, 0.2840363718036751, 0.2838200075148349, 0.282335310539482, 0.2814495917682794, 0.280295879140745, 0.28030474625103896, 0.2792977393965302, 0.278713375701023, 0.2776481117680428, 0.2763047649045058, 0.2759702594685047, 0.2748672198344451], 'acc': [0.707314695476837, 0.880794859065524, 0.8856156969448632, 0.8891467111671167, 0.8921847839114917, 0.896513191594702, 0.9032180240967171, 0.9196248126350997, 0.9360067892270281, 0.9387736877293029, 0.939657229977231, 0.9403716912021565, 0.9410432695210074, 0.9416640636875413, 0.9418475843493948, 0.9423350272699331, 0.9427454756335953, 0.9430848703792941, 0.9432909121749081, 0.9438339133472842, 0.943717652868765, 0.9441613774177366, 0.9443688615215207, 0.9443945599681918, 0.9448629323598216, 0.9449139487520197, 0.9451630887131646, 0.9453274970354546, 0.9453395796824807, 0.9457450133237212, 0.9456867357796874, 0.9459473133351017, 0.9459284957150279, 0.9459830072547725, 0.9462086938188974, 0.9464896710873486, 0.9465236125271181, 0.9465527193886893, 0.9467240035077649, 0.9466204674197971, 0.9467521580912734, 0.9468738234736851, 0.9470494064217859, 0.947168616096131, 0.9474908030638888, 0.9473398732026432, 0.9473666965846018, 0.9474842617028667, 0.9475369392192904, 0.9476807553049362, 0.947711457485402, 0.9476696244027577, 0.9477837049223384, 0.947904286789826, 0.9479741683406913, 0.9479115810504668, 0.9480906257459645], 'mDice': [0.14223276295834975, 0.4649561253968699, 0.569130564933222, 0.6037379099106114, 0.6238814187392883, 0.6376468897371574, 0.6487297723513846, 0.6556508396919238, 0.6618557868821369, 0.6696947481616181, 0.6743579033302182, 0.6786321770338998, 0.6839167330522967, 0.6880408139243332, 0.6907559420628642, 0.6948076439642614, 0.6980546852885539, 0.700392065975682, 0.7011941721724549, 0.7061157136465651, 0.7068617739471179, 0.7088131606716254, 0.7103084790402098, 0.7119947876271029, 0.7151055187632828, 0.7163491441151824, 0.7185768215218494, 0.7196748303298437, 0.719909359319705, 0.722958583360359, 0.7233529384094642, 0.7249842666011889, 0.7256477385564208, 0.7266460844019864, 0.7277889637272923, 0.7302732481394023, 0.7303879136233535, 0.7309949284416497, 0.7321527553838216, 0.7320772161356672, 0.7335768626051328, 0.7343082433035812, 0.7358878032479308, 0.7371035010394911, 0.7393765453371869, 0.7388849204221819, 0.7391498191136996, 0.7401961920765574, 0.7409247981548793, 0.7418554536829924, 0.741819865235453, 0.7425519457648824, 0.7430415411315632, 0.7439072543070961, 0.7448873548482184, 0.7451870346447533, 0.7460547381855515]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:02<11:00,  2.33s/it]Loading train:   1%|          | 2/285 [00:04<10:15,  2.18s/it]Loading train:   1%|          | 3/285 [00:05<09:33,  2.03s/it]Loading train:   1%|▏         | 4/285 [00:08<10:00,  2.14s/it]Loading train:   2%|▏         | 5/285 [00:10<09:57,  2.13s/it]Loading train:   2%|▏         | 6/285 [00:11<09:11,  1.98s/it]Loading train:   2%|▏         | 7/285 [00:13<09:06,  1.97s/it]Loading train:   3%|▎         | 8/285 [00:15<08:46,  1.90s/it]Loading train:   3%|▎         | 9/285 [00:17<09:19,  2.03s/it]Loading train:   4%|▎         | 10/285 [00:19<09:09,  2.00s/it]Loading train:   4%|▍         | 11/285 [00:21<08:45,  1.92s/it]Loading train:   4%|▍         | 12/285 [00:23<08:04,  1.77s/it]Loading train:   5%|▍         | 13/285 [00:24<07:56,  1.75s/it]Loading train:   5%|▍         | 14/285 [00:26<07:55,  1.75s/it]Loading train:   5%|▌         | 15/285 [00:28<08:28,  1.88s/it]Loading train:   6%|▌         | 16/285 [00:30<08:24,  1.88s/it]Loading train:   6%|▌         | 17/285 [00:32<07:55,  1.78s/it]Loading train:   6%|▋         | 18/285 [00:33<08:02,  1.81s/it]Loading train:   7%|▋         | 19/285 [00:35<07:45,  1.75s/it]Loading train:   7%|▋         | 20/285 [00:37<07:37,  1.73s/it]Loading train:   7%|▋         | 21/285 [00:39<07:48,  1.77s/it]Loading train:   8%|▊         | 22/285 [00:40<07:07,  1.62s/it]Loading train:   8%|▊         | 23/285 [00:41<06:51,  1.57s/it]Loading train:   8%|▊         | 24/285 [00:43<06:40,  1.53s/it]Loading train:   9%|▉         | 25/285 [00:45<06:48,  1.57s/it]Loading train:   9%|▉         | 26/285 [00:46<06:58,  1.62s/it]Loading train:   9%|▉         | 27/285 [00:48<06:54,  1.61s/it]Loading train:  10%|▉         | 28/285 [00:50<07:18,  1.71s/it]Loading train:  10%|█         | 29/285 [00:51<06:53,  1.61s/it]Loading train:  11%|█         | 30/285 [00:53<06:59,  1.65s/it]Loading train:  11%|█         | 31/285 [00:55<07:13,  1.70s/it]Loading train:  11%|█         | 32/285 [00:57<07:22,  1.75s/it]Loading train:  12%|█▏        | 33/285 [00:58<07:18,  1.74s/it]Loading train:  12%|█▏        | 34/285 [01:00<06:57,  1.66s/it]Loading train:  12%|█▏        | 35/285 [01:02<07:12,  1.73s/it]Loading train:  13%|█▎        | 36/285 [01:03<06:52,  1.66s/it]Loading train:  13%|█▎        | 37/285 [01:05<06:58,  1.69s/it]Loading train:  13%|█▎        | 38/285 [01:07<06:58,  1.70s/it]Loading train:  14%|█▎        | 39/285 [01:08<06:29,  1.58s/it]Loading train:  14%|█▍        | 40/285 [01:09<06:18,  1.54s/it]Loading train:  14%|█▍        | 41/285 [01:11<06:05,  1.50s/it]Loading train:  15%|█▍        | 42/285 [01:12<05:56,  1.47s/it]Loading train:  15%|█▌        | 43/285 [01:14<05:49,  1.44s/it]Loading train:  15%|█▌        | 44/285 [01:15<06:13,  1.55s/it]Loading train:  16%|█▌        | 45/285 [01:17<06:14,  1.56s/it]Loading train:  16%|█▌        | 46/285 [01:19<06:13,  1.56s/it]Loading train:  16%|█▋        | 47/285 [01:20<05:51,  1.48s/it]Loading train:  17%|█▋        | 48/285 [01:22<06:09,  1.56s/it]Loading train:  17%|█▋        | 49/285 [01:24<06:47,  1.73s/it]Loading train:  18%|█▊        | 50/285 [01:26<06:55,  1.77s/it]Loading train:  18%|█▊        | 51/285 [01:27<06:55,  1.78s/it]Loading train:  18%|█▊        | 52/285 [01:29<06:38,  1.71s/it]Loading train:  19%|█▊        | 53/285 [01:30<06:18,  1.63s/it]Loading train:  19%|█▉        | 54/285 [01:33<06:59,  1.82s/it]Loading train:  19%|█▉        | 55/285 [01:35<07:07,  1.86s/it]Loading train:  20%|█▉        | 56/285 [01:37<07:16,  1.91s/it]Loading train:  20%|██        | 57/285 [01:39<07:27,  1.96s/it]Loading train:  20%|██        | 58/285 [01:40<06:50,  1.81s/it]Loading train:  21%|██        | 59/285 [01:42<06:40,  1.77s/it]Loading train:  21%|██        | 60/285 [01:44<06:38,  1.77s/it]Loading train:  21%|██▏       | 61/285 [01:45<06:33,  1.76s/it]Loading train:  22%|██▏       | 62/285 [01:47<06:50,  1.84s/it]Loading train:  22%|██▏       | 63/285 [01:49<06:40,  1.80s/it]Loading train:  22%|██▏       | 64/285 [01:51<07:01,  1.91s/it]Loading train:  23%|██▎       | 65/285 [01:53<07:00,  1.91s/it]Loading train:  23%|██▎       | 66/285 [01:56<07:34,  2.07s/it]Loading train:  24%|██▎       | 67/285 [01:57<07:07,  1.96s/it]Loading train:  24%|██▍       | 68/285 [01:59<06:27,  1.78s/it]Loading train:  24%|██▍       | 69/285 [02:00<05:52,  1.63s/it]Loading train:  25%|██▍       | 70/285 [02:02<06:14,  1.74s/it]Loading train:  25%|██▍       | 71/285 [02:04<06:06,  1.71s/it]Loading train:  25%|██▌       | 72/285 [02:05<05:38,  1.59s/it]Loading train:  26%|██▌       | 73/285 [02:07<05:46,  1.64s/it]Loading train:  26%|██▌       | 74/285 [02:08<05:40,  1.61s/it]Loading train:  26%|██▋       | 75/285 [02:09<05:13,  1.49s/it]Loading train:  27%|██▋       | 76/285 [02:11<05:23,  1.55s/it]Loading train:  27%|██▋       | 77/285 [02:13<05:19,  1.54s/it]Loading train:  27%|██▋       | 78/285 [02:14<05:07,  1.49s/it]Loading train:  28%|██▊       | 79/285 [02:16<05:28,  1.60s/it]Loading train:  28%|██▊       | 80/285 [02:17<05:14,  1.53s/it]Loading train:  28%|██▊       | 81/285 [02:19<05:13,  1.54s/it]Loading train:  29%|██▉       | 82/285 [02:20<05:18,  1.57s/it]Loading train:  29%|██▉       | 83/285 [02:22<05:17,  1.57s/it]Loading train:  29%|██▉       | 84/285 [02:23<05:12,  1.55s/it]Loading train:  30%|██▉       | 85/285 [02:25<04:57,  1.49s/it]Loading train:  30%|███       | 86/285 [02:27<05:16,  1.59s/it]Loading train:  31%|███       | 87/285 [02:28<05:18,  1.61s/it]Loading train:  31%|███       | 88/285 [02:30<05:40,  1.73s/it]Loading train:  31%|███       | 89/285 [02:31<05:07,  1.57s/it]Loading train:  32%|███▏      | 90/285 [02:33<05:22,  1.65s/it]Loading train:  32%|███▏      | 91/285 [02:35<05:24,  1.67s/it]Loading train:  32%|███▏      | 92/285 [02:37<05:26,  1.69s/it]Loading train:  33%|███▎      | 93/285 [02:38<05:17,  1.65s/it]Loading train:  33%|███▎      | 94/285 [02:40<05:13,  1.64s/it]Loading train:  33%|███▎      | 95/285 [02:42<05:22,  1.70s/it]Loading train:  34%|███▎      | 96/285 [02:43<05:09,  1.64s/it]Loading train:  34%|███▍      | 97/285 [02:45<05:04,  1.62s/it]Loading train:  34%|███▍      | 98/285 [02:47<05:26,  1.75s/it]Loading train:  35%|███▍      | 99/285 [02:49<05:21,  1.73s/it]Loading train:  35%|███▌      | 100/285 [02:50<05:28,  1.78s/it]Loading train:  35%|███▌      | 101/285 [02:52<05:17,  1.73s/it]Loading train:  36%|███▌      | 102/285 [02:54<05:05,  1.67s/it]Loading train:  36%|███▌      | 103/285 [02:55<05:14,  1.73s/it]Loading train:  36%|███▋      | 104/285 [02:57<05:19,  1.76s/it]Loading train:  37%|███▋      | 105/285 [02:59<05:05,  1.70s/it]Loading train:  37%|███▋      | 106/285 [03:00<04:56,  1.66s/it]Loading train:  38%|███▊      | 107/285 [03:02<04:25,  1.49s/it]Loading train:  38%|███▊      | 108/285 [03:03<04:16,  1.45s/it]Loading train:  38%|███▊      | 109/285 [03:04<04:10,  1.42s/it]Loading train:  39%|███▊      | 110/285 [03:05<03:57,  1.36s/it]Loading train:  39%|███▉      | 111/285 [03:07<04:22,  1.51s/it]Loading train:  39%|███▉      | 112/285 [03:09<04:43,  1.64s/it]Loading train:  40%|███▉      | 113/285 [03:11<04:55,  1.72s/it]Loading train:  40%|████      | 114/285 [03:13<04:56,  1.73s/it]Loading train:  40%|████      | 115/285 [03:14<04:41,  1.66s/it]Loading train:  41%|████      | 116/285 [03:16<04:50,  1.72s/it]Loading train:  41%|████      | 117/285 [03:18<04:42,  1.68s/it]Loading train:  41%|████▏     | 118/285 [03:19<04:31,  1.63s/it]Loading train:  42%|████▏     | 119/285 [03:21<04:12,  1.52s/it]Loading train:  42%|████▏     | 120/285 [03:22<04:03,  1.48s/it]Loading train:  42%|████▏     | 121/285 [03:24<04:39,  1.70s/it]Loading train:  43%|████▎     | 122/285 [03:26<04:36,  1.70s/it]Loading train:  43%|████▎     | 123/285 [03:28<04:43,  1.75s/it]Loading train:  44%|████▎     | 124/285 [03:29<04:30,  1.68s/it]Loading train:  44%|████▍     | 125/285 [03:31<04:29,  1.69s/it]Loading train:  44%|████▍     | 126/285 [03:32<04:10,  1.58s/it]Loading train:  45%|████▍     | 127/285 [03:34<03:58,  1.51s/it]Loading train:  45%|████▍     | 128/285 [03:35<04:00,  1.53s/it]Loading train:  45%|████▌     | 129/285 [03:37<03:51,  1.48s/it]Loading train:  46%|████▌     | 130/285 [03:38<03:56,  1.52s/it]Loading train:  46%|████▌     | 131/285 [03:40<03:57,  1.54s/it]Loading train:  46%|████▋     | 132/285 [03:41<03:41,  1.45s/it]Loading train:  47%|████▋     | 133/285 [03:42<03:28,  1.37s/it]Loading train:  47%|████▋     | 134/285 [03:44<03:27,  1.38s/it]Loading train:  47%|████▋     | 135/285 [03:45<03:26,  1.37s/it]Loading train:  48%|████▊     | 136/285 [03:46<03:04,  1.24s/it]Loading train:  48%|████▊     | 137/285 [03:47<03:13,  1.31s/it]Loading train:  48%|████▊     | 138/285 [03:49<03:14,  1.32s/it]Loading train:  49%|████▉     | 139/285 [03:50<03:13,  1.33s/it]Loading train:  49%|████▉     | 140/285 [03:52<03:29,  1.44s/it]Loading train:  49%|████▉     | 141/285 [03:53<03:16,  1.37s/it]Loading train:  50%|████▉     | 142/285 [03:54<03:15,  1.37s/it]Loading train:  50%|█████     | 143/285 [03:56<03:18,  1.40s/it]Loading train:  51%|█████     | 144/285 [03:57<03:15,  1.39s/it]Loading train:  51%|█████     | 145/285 [03:58<03:06,  1.33s/it]Loading train:  51%|█████     | 146/285 [04:00<03:13,  1.39s/it]Loading train:  52%|█████▏    | 147/285 [04:01<03:02,  1.32s/it]Loading train:  52%|█████▏    | 148/285 [04:03<03:11,  1.40s/it]Loading train:  52%|█████▏    | 149/285 [04:04<03:04,  1.36s/it]Loading train:  53%|█████▎    | 150/285 [04:05<02:46,  1.23s/it]Loading train:  53%|█████▎    | 151/285 [04:06<02:48,  1.26s/it]Loading train:  53%|█████▎    | 152/285 [04:08<02:53,  1.30s/it]Loading train:  54%|█████▎    | 153/285 [04:09<02:52,  1.31s/it]Loading train:  54%|█████▍    | 154/285 [04:11<03:02,  1.40s/it]Loading train:  54%|█████▍    | 155/285 [04:12<02:57,  1.37s/it]Loading train:  55%|█████▍    | 156/285 [04:13<03:00,  1.40s/it]Loading train:  55%|█████▌    | 157/285 [04:14<02:45,  1.29s/it]Loading train:  55%|█████▌    | 158/285 [04:16<02:39,  1.26s/it]Loading train:  56%|█████▌    | 159/285 [04:17<02:29,  1.18s/it]Loading train:  56%|█████▌    | 160/285 [04:18<02:27,  1.18s/it]Loading train:  56%|█████▋    | 161/285 [04:19<02:32,  1.23s/it]Loading train:  57%|█████▋    | 162/285 [04:20<02:27,  1.20s/it]Loading train:  57%|█████▋    | 163/285 [04:22<02:35,  1.27s/it]Loading train:  58%|█████▊    | 164/285 [04:23<02:37,  1.30s/it]Loading train:  58%|█████▊    | 165/285 [04:24<02:28,  1.24s/it]Loading train:  58%|█████▊    | 166/285 [04:25<02:33,  1.29s/it]Loading train:  59%|█████▊    | 167/285 [04:27<02:45,  1.40s/it]Loading train:  59%|█████▉    | 168/285 [04:29<02:55,  1.50s/it]Loading train:  59%|█████▉    | 169/285 [04:30<02:45,  1.43s/it]Loading train:  60%|█████▉    | 170/285 [04:32<02:58,  1.55s/it]Loading train:  60%|██████    | 171/285 [04:33<02:39,  1.40s/it]Loading train:  60%|██████    | 172/285 [04:34<02:26,  1.29s/it]Loading train:  61%|██████    | 173/285 [04:35<02:26,  1.30s/it]Loading train:  61%|██████    | 174/285 [04:37<02:22,  1.28s/it]Loading train:  61%|██████▏   | 175/285 [04:38<02:37,  1.43s/it]Loading train:  62%|██████▏   | 176/285 [04:40<02:41,  1.49s/it]Loading train:  62%|██████▏   | 177/285 [04:42<02:52,  1.60s/it]Loading train:  62%|██████▏   | 178/285 [04:44<02:59,  1.68s/it]Loading train:  63%|██████▎   | 179/285 [04:46<03:08,  1.77s/it]Loading train:  63%|██████▎   | 180/285 [04:48<03:23,  1.93s/it]Loading train:  64%|██████▎   | 181/285 [04:49<02:53,  1.67s/it]Loading train:  64%|██████▍   | 182/285 [04:50<02:30,  1.46s/it]Loading train:  64%|██████▍   | 183/285 [04:51<02:27,  1.45s/it]Loading train:  65%|██████▍   | 184/285 [04:53<02:29,  1.48s/it]Loading train:  65%|██████▍   | 185/285 [04:54<02:16,  1.37s/it]Loading train:  65%|██████▌   | 186/285 [04:56<02:31,  1.53s/it]Loading train:  66%|██████▌   | 187/285 [04:57<02:17,  1.40s/it]Loading train:  66%|██████▌   | 188/285 [04:58<02:09,  1.33s/it]Loading train:  66%|██████▋   | 189/285 [04:59<01:48,  1.13s/it]Loading train:  67%|██████▋   | 190/285 [05:00<01:47,  1.13s/it]Loading train:  67%|██████▋   | 191/285 [05:01<01:41,  1.08s/it]Loading train:  67%|██████▋   | 192/285 [05:02<01:38,  1.06s/it]Loading train:  68%|██████▊   | 193/285 [05:03<01:34,  1.03s/it]Loading train:  68%|██████▊   | 194/285 [05:04<01:34,  1.04s/it]Loading train:  68%|██████▊   | 195/285 [05:05<01:26,  1.04it/s]Loading train:  69%|██████▉   | 196/285 [05:06<01:26,  1.03it/s]Loading train:  69%|██████▉   | 197/285 [05:07<01:31,  1.04s/it]Loading train:  69%|██████▉   | 198/285 [05:08<01:31,  1.05s/it]Loading train:  70%|██████▉   | 199/285 [05:09<01:23,  1.03it/s]Loading train:  70%|███████   | 200/285 [05:10<01:19,  1.07it/s]Loading train:  71%|███████   | 201/285 [05:11<01:26,  1.03s/it]Loading train:  71%|███████   | 202/285 [05:12<01:21,  1.01it/s]Loading train:  71%|███████   | 203/285 [05:13<01:20,  1.02it/s]Loading train:  72%|███████▏  | 204/285 [05:14<01:14,  1.09it/s]Loading train:  72%|███████▏  | 205/285 [05:15<01:15,  1.06it/s]Loading train:  72%|███████▏  | 206/285 [05:16<01:13,  1.07it/s]Loading train:  73%|███████▎  | 207/285 [05:17<01:18,  1.01s/it]Loading train:  73%|███████▎  | 208/285 [05:18<01:22,  1.07s/it]Loading train:  73%|███████▎  | 209/285 [05:19<01:24,  1.11s/it]Loading train:  74%|███████▎  | 210/285 [05:20<01:15,  1.01s/it]Loading train:  74%|███████▍  | 211/285 [05:21<01:12,  1.03it/s]Loading train:  74%|███████▍  | 212/285 [05:22<01:08,  1.07it/s]Loading train:  75%|███████▍  | 213/285 [05:23<01:11,  1.01it/s]Loading train:  75%|███████▌  | 214/285 [05:24<01:11,  1.01s/it]Loading train:  75%|███████▌  | 215/285 [05:25<01:09,  1.01it/s]Loading train:  76%|███████▌  | 216/285 [05:26<01:08,  1.01it/s]Loading train:  76%|███████▌  | 217/285 [05:27<01:08,  1.01s/it]Loading train:  76%|███████▋  | 218/285 [05:28<01:08,  1.02s/it]Loading train:  77%|███████▋  | 219/285 [05:29<01:07,  1.02s/it]Loading train:  77%|███████▋  | 220/285 [05:30<01:01,  1.05it/s]Loading train:  78%|███████▊  | 221/285 [05:31<00:58,  1.09it/s]Loading train:  78%|███████▊  | 222/285 [05:31<00:55,  1.13it/s]Loading train:  78%|███████▊  | 223/285 [05:32<00:54,  1.13it/s]Loading train:  79%|███████▊  | 224/285 [05:33<00:50,  1.20it/s]Loading train:  79%|███████▉  | 225/285 [05:34<00:51,  1.18it/s]Loading train:  79%|███████▉  | 226/285 [05:35<00:53,  1.10it/s]Loading train:  80%|███████▉  | 227/285 [05:36<00:55,  1.05it/s]Loading train:  80%|████████  | 228/285 [05:37<00:55,  1.02it/s]Loading train:  80%|████████  | 229/285 [05:38<00:55,  1.00it/s]Loading train:  81%|████████  | 230/285 [05:39<00:53,  1.02it/s]Loading train:  81%|████████  | 231/285 [05:40<00:52,  1.03it/s]Loading train:  81%|████████▏ | 232/285 [05:41<00:50,  1.05it/s]Loading train:  82%|████████▏ | 233/285 [05:42<00:48,  1.08it/s]Loading train:  82%|████████▏ | 234/285 [05:43<00:52,  1.03s/it]Loading train:  82%|████████▏ | 235/285 [05:44<00:47,  1.06it/s]Loading train:  83%|████████▎ | 236/285 [05:45<00:47,  1.04it/s]Loading train:  83%|████████▎ | 237/285 [05:46<00:47,  1.00it/s]Loading train:  84%|████████▎ | 238/285 [05:47<00:46,  1.00it/s]Loading train:  84%|████████▍ | 239/285 [05:48<00:44,  1.03it/s]Loading train:  84%|████████▍ | 240/285 [05:49<00:42,  1.07it/s]Loading train:  85%|████████▍ | 241/285 [05:49<00:39,  1.13it/s]Loading train:  85%|████████▍ | 242/285 [05:50<00:36,  1.18it/s]Loading train:  85%|████████▌ | 243/285 [05:51<00:35,  1.19it/s]Loading train:  86%|████████▌ | 244/285 [05:52<00:39,  1.03it/s]Loading train:  86%|████████▌ | 245/285 [05:53<00:36,  1.09it/s]Loading train:  86%|████████▋ | 246/285 [05:54<00:37,  1.04it/s]Loading train:  87%|████████▋ | 247/285 [05:55<00:36,  1.04it/s]Loading train:  87%|████████▋ | 248/285 [05:56<00:35,  1.04it/s]Loading train:  87%|████████▋ | 249/285 [05:57<00:34,  1.04it/s]Loading train:  88%|████████▊ | 250/285 [05:58<00:33,  1.05it/s]Loading train:  88%|████████▊ | 251/285 [05:59<00:33,  1.02it/s]Loading train:  88%|████████▊ | 252/285 [06:00<00:31,  1.06it/s]Loading train:  89%|████████▉ | 253/285 [06:01<00:30,  1.04it/s]Loading train:  89%|████████▉ | 254/285 [06:02<00:30,  1.03it/s]Loading train:  89%|████████▉ | 255/285 [06:03<00:27,  1.08it/s]Loading train:  90%|████████▉ | 256/285 [06:03<00:25,  1.13it/s]Loading train:  90%|█████████ | 257/285 [06:04<00:24,  1.16it/s]Loading train:  91%|█████████ | 258/285 [06:05<00:25,  1.07it/s]Loading train:  91%|█████████ | 259/285 [06:06<00:24,  1.04it/s]Loading train:  91%|█████████ | 260/285 [06:07<00:23,  1.06it/s]Loading train:  92%|█████████▏| 261/285 [06:08<00:21,  1.11it/s]Loading train:  92%|█████████▏| 262/285 [06:09<00:21,  1.08it/s]Loading train:  92%|█████████▏| 263/285 [06:10<00:20,  1.09it/s]Loading train:  93%|█████████▎| 264/285 [06:11<00:20,  1.04it/s]Loading train:  93%|█████████▎| 265/285 [06:12<00:20,  1.02s/it]Loading train:  93%|█████████▎| 266/285 [06:13<00:18,  1.05it/s]Loading train:  94%|█████████▎| 267/285 [06:14<00:17,  1.03it/s]Loading train:  94%|█████████▍| 268/285 [06:15<00:16,  1.02it/s]Loading train:  94%|█████████▍| 269/285 [06:16<00:15,  1.01it/s]Loading train:  95%|█████████▍| 270/285 [06:17<00:14,  1.05it/s]Loading train:  95%|█████████▌| 271/285 [06:18<00:13,  1.04it/s]Loading train:  95%|█████████▌| 272/285 [06:19<00:12,  1.06it/s]Loading train:  96%|█████████▌| 273/285 [06:19<00:10,  1.12it/s]Loading train:  96%|█████████▌| 274/285 [06:20<00:09,  1.14it/s]Loading train:  96%|█████████▋| 275/285 [06:21<00:09,  1.08it/s]Loading train:  97%|█████████▋| 276/285 [06:22<00:08,  1.02it/s]Loading train:  97%|█████████▋| 277/285 [06:23<00:07,  1.03it/s]Loading train:  98%|█████████▊| 278/285 [06:24<00:06,  1.00it/s]Loading train:  98%|█████████▊| 279/285 [06:25<00:05,  1.03it/s]Loading train:  98%|█████████▊| 280/285 [06:26<00:04,  1.04it/s]Loading train:  99%|█████████▊| 281/285 [06:27<00:03,  1.05it/s]Loading train:  99%|█████████▉| 282/285 [06:28<00:02,  1.09it/s]Loading train:  99%|█████████▉| 283/285 [06:29<00:01,  1.02it/s]Loading train: 100%|█████████▉| 284/285 [06:30<00:00,  1.03it/s]Loading train: 100%|██████████| 285/285 [06:31<00:00,  1.00s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:  10%|█         | 29/285 [00:00<00:00, 279.44it/s]concatenating: train:  14%|█▍        | 41/285 [00:00<00:01, 199.80it/s]concatenating: train:  20%|██        | 58/285 [00:00<00:01, 185.77it/s]concatenating: train:  28%|██▊       | 79/285 [00:00<00:01, 189.61it/s]concatenating: train:  39%|███▉      | 112/285 [00:00<00:00, 217.22it/s]concatenating: train:  46%|████▋     | 132/285 [00:00<00:01, 147.03it/s]concatenating: train:  58%|█████▊    | 166/285 [00:00<00:00, 176.80it/s]concatenating: train:  69%|██████▉   | 197/285 [00:00<00:00, 202.52it/s]concatenating: train:  81%|████████  | 231/285 [00:01<00:00, 230.09it/s]concatenating: train:  91%|█████████ | 259/285 [00:01<00:00, 197.04it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 212.60it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.28s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.25s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.22s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 120.94it/s]2019-07-11 04:33:12.835495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 04:33:12.835601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 04:33:12.835616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 04:33:12.835624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 04:33:12.836051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.54it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.42it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.29it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.84it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  6.07it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  6.85it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.80it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.52it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  7.66it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.32it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.90it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:02,  8.47it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  8.64it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.14it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.91it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.18it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.48it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.47it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.09it/s]
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 30)   4080        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 40, 45)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 60)   24360       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 20, 105)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 105)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 105)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 105)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 15)   4065        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 45)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 45)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 20)   8120        dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 80, 20)   0           activation_11[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 20)   3620        dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 80, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 80, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 80, 20)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 65)   0           dropout_5[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 80, 13)   858         concatenate_7[0][0]              
==================================================================================================
Total params: 138,638
Trainable params: 40,098
Non-trainable params: 98,540
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 14s - loss: 2.9414 - acc: 0.4411 - mDice: 0.0876 - val_loss: 2.6575 - val_acc: 0.8621 - val_mDice: 0.1759

Epoch 00001: val_mDice improved from -inf to 0.17592, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 9s - loss: 1.1638 - acc: 0.8668 - mDice: 0.3149 - val_loss: 1.6146 - val_acc: 0.8980 - val_mDice: 0.3345

Epoch 00002: val_mDice improved from 0.17592 to 0.33451, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 9s - loss: 0.8108 - acc: 0.8776 - mDice: 0.4305 - val_loss: 2.1358 - val_acc: 0.9062 - val_mDice: 0.2291

Epoch 00003: val_mDice did not improve from 0.33451
Epoch 4/300
 - 9s - loss: 0.6994 - acc: 0.8831 - mDice: 0.4814 - val_loss: 1.2277 - val_acc: 0.9088 - val_mDice: 0.4693

Epoch 00004: val_mDice improved from 0.33451 to 0.46925, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 9s - loss: 0.6302 - acc: 0.8880 - mDice: 0.5164 - val_loss: 1.3500 - val_acc: 0.9145 - val_mDice: 0.4068

Epoch 00005: val_mDice did not improve from 0.46925
Epoch 6/300
 - 9s - loss: 0.5836 - acc: 0.8933 - mDice: 0.5414 - val_loss: 1.0900 - val_acc: 0.9190 - val_mDice: 0.5049

Epoch 00006: val_mDice improved from 0.46925 to 0.50493, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 9s - loss: 0.5492 - acc: 0.8988 - mDice: 0.5614 - val_loss: 1.4262 - val_acc: 0.9139 - val_mDice: 0.3785

Epoch 00007: val_mDice did not improve from 0.50493
Epoch 8/300
 - 9s - loss: 0.5227 - acc: 0.9057 - mDice: 0.5770 - val_loss: 1.4376 - val_acc: 0.9216 - val_mDice: 0.3697

Epoch 00008: val_mDice did not improve from 0.50493
Epoch 9/300
 - 9s - loss: 0.4959 - acc: 0.9125 - mDice: 0.5934 - val_loss: 0.9714 - val_acc: 0.9370 - val_mDice: 0.5354

Epoch 00009: val_mDice improved from 0.50493 to 0.53542, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 9s - loss: 0.4797 - acc: 0.9179 - mDice: 0.6033 - val_loss: 1.0455 - val_acc: 0.9357 - val_mDice: 0.5038

Epoch 00010: val_mDice did not improve from 0.53542
Epoch 11/300
 - 9s - loss: 0.4628 - acc: 0.9222 - mDice: 0.6137 - val_loss: 0.9423 - val_acc: 0.9376 - val_mDice: 0.5574

Epoch 00011: val_mDice improved from 0.53542 to 0.55743, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 9s - loss: 0.4526 - acc: 0.9243 - mDice: 0.6203 - val_loss: 0.9518 - val_acc: 0.9383 - val_mDice: 0.5412

Epoch 00012: val_mDice did not improve from 0.55743
Epoch 13/300
 - 9s - loss: 0.4424 - acc: 0.9261 - mDice: 0.6270 - val_loss: 0.9415 - val_acc: 0.9310 - val_mDice: 0.5592

Epoch 00013: val_mDice improved from 0.55743 to 0.55922, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 9s - loss: 0.4353 - acc: 0.9273 - mDice: 0.6317 - val_loss: 0.9185 - val_acc: 0.9394 - val_mDice: 0.5615

Epoch 00014: val_mDice improved from 0.55922 to 0.56150, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 9s - loss: 0.4246 - acc: 0.9285 - mDice: 0.6386 - val_loss: 0.9168 - val_acc: 0.9420 - val_mDice: 0.5561

Epoch 00015: val_mDice did not improve from 0.56150
Epoch 16/300
 - 9s - loss: 0.4211 - acc: 0.9294 - mDice: 0.6410 - val_loss: 0.9386 - val_acc: 0.9276 - val_mDice: 0.5610

Epoch 00016: val_mDice did not improve from 0.56150
Epoch 17/300
 - 9s - loss: 0.4151 - acc: 0.9301 - mDice: 0.6451 - val_loss: 0.9085 - val_acc: 0.9322 - val_mDice: 0.5573

Epoch 00017: val_mDice did not improve from 0.56150
Epoch 18/300
 - 9s - loss: 0.4075 - acc: 0.9310 - mDice: 0.6500 - val_loss: 0.8985 - val_acc: 0.9401 - val_mDice: 0.5664

Epoch 00018: val_mDice improved from 0.56150 to 0.56636, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 19/300
 - 9s - loss: 0.4050 - acc: 0.9314 - mDice: 0.6518 - val_loss: 0.9045 - val_acc: 0.9433 - val_mDice: 0.5614

Epoch 00019: val_mDice did not improve from 0.56636
Epoch 20/300
 - 9s - loss: 0.4003 - acc: 0.9321 - mDice: 0.6549 - val_loss: 0.9066 - val_acc: 0.9399 - val_mDice: 0.5611

Epoch 00020: val_mDice did not improve from 0.56636
Epoch 21/300
 - 9s - loss: 0.3945 - acc: 0.9325 - mDice: 0.6590 - val_loss: 0.8538 - val_acc: 0.9429 - val_mDice: 0.5544

Epoch 00021: val_mDice did not improve from 0.56636
Epoch 22/300
 - 9s - loss: 0.3893 - acc: 0.9333 - mDice: 0.6625 - val_loss: 0.8834 - val_acc: 0.9400 - val_mDice: 0.5618

Epoch 00022: val_mDice did not improve from 0.56636
Epoch 23/300
 - 9s - loss: 0.3872 - acc: 0.9335 - mDice: 0.6639 - val_loss: 0.9201 - val_acc: 0.9430 - val_mDice: 0.5377

Epoch 00023: val_mDice did not improve from 0.56636
Epoch 24/300
 - 9s - loss: 0.3841 - acc: 0.9339 - mDice: 0.6661 - val_loss: 0.8789 - val_acc: 0.9418 - val_mDice: 0.5420

Epoch 00024: val_mDice did not improve from 0.56636
Epoch 25/300
 - 9s - loss: 0.3806 - acc: 0.9344 - mDice: 0.6686 - val_loss: 0.8856 - val_acc: 0.9416 - val_mDice: 0.5695

Epoch 00025: val_mDice improved from 0.56636 to 0.56954, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 26/300
 - 9s - loss: 0.3774 - acc: 0.9348 - mDice: 0.6707 - val_loss: 0.8977 - val_acc: 0.9372 - val_mDice: 0.5557

Epoch 00026: val_mDice did not improve from 0.56954
Epoch 27/300
 - 9s - loss: 0.3742 - acc: 0.9352 - mDice: 0.6729 - val_loss: 0.8703 - val_acc: 0.9415 - val_mDice: 0.5626

Epoch 00027: val_mDice did not improve from 0.56954
Epoch 28/300
 - 9s - loss: 0.3716 - acc: 0.9354 - mDice: 0.6749 - val_loss: 0.8621 - val_acc: 0.9425 - val_mDice: 0.5515

Epoch 00028: val_mDice did not improve from 0.56954
Epoch 29/300
 - 10s - loss: 0.3691 - acc: 0.9358 - mDice: 0.6765 - val_loss: 0.8653 - val_acc: 0.9357 - val_mDice: 0.5619

Epoch 00029: val_mDice did not improve from 0.56954
Epoch 30/300
 - 9s - loss: 0.3681 - acc: 0.9359 - mDice: 0.6772 - val_loss: 0.8305 - val_acc: 0.9445 - val_mDice: 0.5752

Epoch 00030: val_mDice improved from 0.56954 to 0.57520, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 31/300
 - 9s - loss: 0.3642 - acc: 0.9362 - mDice: 0.6799 - val_loss: 0.8909 - val_acc: 0.9402 - val_mDice: 0.5533

Epoch 00031: val_mDice did not improve from 0.57520
Epoch 32/300
 - 9s - loss: 0.3624 - acc: 0.9366 - mDice: 0.6812 - val_loss: 0.8574 - val_acc: 0.9441 - val_mDice: 0.5629

Epoch 00032: val_mDice did not improve from 0.57520
Epoch 33/300
 - 9s - loss: 0.3609 - acc: 0.9369 - mDice: 0.6824 - val_loss: 0.8233 - val_acc: 0.9401 - val_mDice: 0.5708

Epoch 00033: val_mDice did not improve from 0.57520
Epoch 34/300
 - 9s - loss: 0.3567 - acc: 0.9373 - mDice: 0.6853 - val_loss: 0.7800 - val_acc: 0.9404 - val_mDice: 0.5648

Epoch 00034: val_mDice did not improve from 0.57520
Epoch 35/300
 - 9s - loss: 0.3572 - acc: 0.9372 - mDice: 0.6850 - val_loss: 0.8825 - val_acc: 0.9417 - val_mDice: 0.5455

Epoch 00035: val_mDice did not improve from 0.57520
Epoch 36/300
 - 9s - loss: 0.3559 - acc: 0.9376 - mDice: 0.6858 - val_loss: 0.8837 - val_acc: 0.9343 - val_mDice: 0.5534

Epoch 00036: val_mDice did not improve from 0.57520
Epoch 37/300
 - 9s - loss: 0.3513 - acc: 0.9380 - mDice: 0.6891 - val_loss: 0.8160 - val_acc: 0.9448 - val_mDice: 0.5626

Epoch 00037: val_mDice did not improve from 0.57520
Epoch 38/300
 - 9s - loss: 0.3522 - acc: 0.9380 - mDice: 0.6885 - val_loss: 0.7900 - val_acc: 0.9397 - val_mDice: 0.5655

Epoch 00038: val_mDice did not improve from 0.57520
Epoch 39/300
 - 9s - loss: 0.3474 - acc: 0.9385 - mDice: 0.6919 - val_loss: 0.8191 - val_acc: 0.9331 - val_mDice: 0.5614

Epoch 00039: val_mDice did not improve from 0.57520
Epoch 40/300
 - 9s - loss: 0.3480 - acc: 0.9384 - mDice: 0.6914 - val_loss: 0.8582 - val_acc: 0.9377 - val_mDice: 0.5292

Epoch 00040: val_mDice did not improve from 0.57520
Epoch 41/300
 - 9s - loss: 0.3465 - acc: 0.9386 - mDice: 0.6925 - val_loss: 0.7808 - val_acc: 0.9430 - val_mDice: 0.5762

Epoch 00041: val_mDice improved from 0.57520 to 0.57623, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 42/300
 - 9s - loss: 0.3455 - acc: 0.9385 - mDice: 0.6932 - val_loss: 0.8238 - val_acc: 0.9358 - val_mDice: 0.5585

Epoch 00042: val_mDice did not improve from 0.57623
Epoch 43/300
 - 9s - loss: 0.3435 - acc: 0.9389 - mDice: 0.6946 - val_loss: 0.8059 - val_acc: 0.9384 - val_mDice: 0.5556

Epoch 00043: val_mDice did not improve from 0.57623
Epoch 44/300
 - 9s - loss: 0.3406 - acc: 0.9391 - mDice: 0.6967 - val_loss: 0.7386 - val_acc: 0.9427 - val_mDice: 0.5789

Epoch 00044: val_mDice improved from 0.57623 to 0.57886, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 45/300
 - 9s - loss: 0.3403 - acc: 0.9392 - mDice: 0.6969 - val_loss: 0.7428 - val_acc: 0.9460 - val_mDice: 0.5692

Epoch 00045: val_mDice did not improve from 0.57886
Epoch 46/300
 - 9s - loss: 0.3387 - acc: 0.9394 - mDice: 0.6981 - val_loss: 0.7823 - val_acc: 0.9444 - val_mDice: 0.5445

Epoch 00046: val_mDice did not improve from 0.57886
Epoch 47/300
 - 9s - loss: 0.3388 - acc: 0.9394 - mDice: 0.6981 - val_loss: 0.7552 - val_acc: 0.9420 - val_mDice: 0.5742

Epoch 00047: val_mDice did not improve from 0.57886
Epoch 48/300
 - 9s - loss: 0.3364 - acc: 0.9396 - mDice: 0.6999 - val_loss: 0.7278 - val_acc: 0.9381 - val_mDice: 0.5800

Epoch 00048: val_mDice improved from 0.57886 to 0.58000, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 49/300
 - 9s - loss: 0.3362 - acc: 0.9395 - mDice: 0.6999 - val_loss: 0.7403 - val_acc: 0.9404 - val_mDice: 0.5665

Epoch 00049: val_mDice did not improve from 0.58000
Epoch 50/300
 - 9s - loss: 0.3343 - acc: 0.9398 - mDice: 0.7014 - val_loss: 0.7715 - val_acc: 0.9423 - val_mDice: 0.5557

Epoch 00050: val_mDice did not improve from 0.58000
Epoch 51/300
 - 9s - loss: 0.3322 - acc: 0.9400 - mDice: 0.7028 - val_loss: 0.7755 - val_acc: 0.9406 - val_mDice: 0.5562

Epoch 00051: val_mDice did not improve from 0.58000
Epoch 52/300
 - 9s - loss: 0.3318 - acc: 0.9403 - mDice: 0.7032 - val_loss: 0.7803 - val_acc: 0.9403 - val_mDice: 0.5388

Epoch 00052: val_mDice did not improve from 0.58000
Epoch 53/300
 - 9s - loss: 0.3310 - acc: 0.9401 - mDice: 0.7037 - val_loss: 0.7527 - val_acc: 0.9391 - val_mDice: 0.5699

Epoch 00053: val_mDice did not improve from 0.58000
Epoch 54/300
 - 9s - loss: 0.3308 - acc: 0.9401 - mDice: 0.7038 - val_loss: 0.7083 - val_acc: 0.9453 - val_mDice: 0.5667

Epoch 00054: val_mDice did not improve from 0.58000
Epoch 55/300
 - 9s - loss: 0.3285 - acc: 0.9405 - mDice: 0.7056 - val_loss: 0.7185 - val_acc: 0.9367 - val_mDice: 0.5649

Epoch 00055: val_mDice did not improve from 0.58000
Epoch 56/300
 - 9s - loss: 0.3285 - acc: 0.9404 - mDice: 0.7056 - val_loss: 0.7141 - val_acc: 0.9428 - val_mDice: 0.5664

Epoch 00056: val_mDice did not improve from 0.58000
Epoch 57/300
 - 9s - loss: 0.3257 - acc: 0.9407 - mDice: 0.7076 - val_loss: 0.7097 - val_acc: 0.9424 - val_mDice: 0.5586

Epoch 00057: val_mDice did not improve from 0.58000
Epoch 58/300
 - 9s - loss: 0.3260 - acc: 0.9405 - mDice: 0.7073 - val_loss: 0.6887 - val_acc: 0.9339 - val_mDice: 0.5597

Epoch 00058: val_mDice did not improve from 0.58000
Epoch 59/300
 - 9s - loss: 0.3251 - acc: 0.9409 - mDice: 0.7080 - val_loss: 0.7860 - val_acc: 0.9408 - val_mDice: 0.5468

Epoch 00059: val_mDice did not improve from 0.58000
Epoch 60/300
 - 9s - loss: 0.3227 - acc: 0.9409 - mDice: 0.7098 - val_loss: 0.7871 - val_acc: 0.9418 - val_mDice: 0.5164

Epoch 00060: val_mDice did not improve from 0.58000
Epoch 61/300
 - 9s - loss: 0.3225 - acc: 0.9409 - mDice: 0.7099 - val_loss: 0.6981 - val_acc: 0.9310 - val_mDice: 0.5432

Epoch 00061: val_mDice did not improve from 0.58000
Epoch 62/300
 - 9s - loss: 0.3237 - acc: 0.9409 - mDice: 0.7092 - val_loss: 0.6334 - val_acc: 0.9344 - val_mDice: 0.5642

Epoch 00062: val_mDice did not improve from 0.58000
Epoch 63/300
 - 9s - loss: 0.3206 - acc: 0.9411 - mDice: 0.7114 - val_loss: 0.6578 - val_acc: 0.9443 - val_mDice: 0.5646

Epoch 00063: val_mDice did not improve from 0.58000
Epoch 64/300
 - 9s - loss: 0.3210 - acc: 0.9412 - mDice: 0.7111 - val_loss: 0.7102 - val_acc: 0.9271 - val_mDice: 0.5414

Epoch 00064: val_mDice did not improve from 0.58000
Epoch 65/300
 - 9s - loss: 0.3197 - acc: 0.9413 - mDice: 0.7121 - val_loss: 0.6776 - val_acc: 0.9412 - val_mDice: 0.5725

Epoch 00065: val_mDice did not improve from 0.58000
Epoch 66/300
 - 9s - loss: 0.3192 - acc: 0.9413 - mDice: 0.7123 - val_loss: 0.6531 - val_acc: 0.9444 - val_mDice: 0.5688

Epoch 00066: val_mDice did not improve from 0.58000
Epoch 67/300
 - 9s - loss: 0.3194 - acc: 0.9412 - mDice: 0.7123 - val_loss: 0.6408 - val_acc: 0.9408 - val_mDice: 0.5729

Epoch 00067: val_mDice did not improve from 0.58000
Epoch 68/300
 - 9s - loss: 0.3175 - acc: 0.9415 - mDice: 0.7136 - val_loss: 0.6005 - val_acc: 0.9428 - val_mDice: 0.5707

Epoch 00068: val_mDice did not improve from 0.58000
Epoch 69/300
 - 9s - loss: 0.3173 - acc: 0.9415 - mDice: 0.7139 - val_loss: 0.6034 - val_acc: 0.9446 - val_mDice: 0.5729

Epoch 00069: val_mDice did not improve from 0.58000
Epoch 70/300
 - 9s - loss: 0.3147 - acc: 0.9417 - mDice: 0.7158 - val_loss: 0.6020 - val_acc: 0.9426 - val_mDice: 0.5671

Epoch 00070: val_mDice did not improve from 0.58000
Epoch 71/300
 - 9s - loss: 0.3140 - acc: 0.9417 - mDice: 0.7163 - val_loss: 0.6019 - val_acc: 0.9437 - val_mDice: 0.5835

Epoch 00071: val_mDice improved from 0.58000 to 0.58354, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 72/300
 - 9s - loss: 0.3156 - acc: 0.9416 - mDice: 0.7151 - val_loss: 0.6201 - val_acc: 0.9388 - val_mDice: 0.5627

Epoch 00072: val_mDice did not improve from 0.58354
Epoch 73/300
 - 9s - loss: 0.3155 - acc: 0.9415 - mDice: 0.7151 - val_loss: 0.6115 - val_acc: 0.9393 - val_mDice: 0.5638

Epoch 00073: val_mDice did not improve from 0.58354
Epoch 74/300
 - 9s - loss: 0.3127 - acc: 0.9420 - mDice: 0.7173 - val_loss: 0.6293 - val_acc: 0.9374 - val_mDice: 0.5545

Epoch 00074: val_mDice did not improve from 0.58354
Epoch 75/300
 - 9s - loss: 0.3129 - acc: 0.9420 - mDice: 0.7171 - val_loss: 0.6000 - val_acc: 0.9349 - val_mDice: 0.5647

Epoch 00075: val_mDice did not improve from 0.58354
Epoch 76/300
 - 9s - loss: 0.3114 - acc: 0.9420 - mDice: 0.7182 - val_loss: 0.5980 - val_acc: 0.9358 - val_mDice: 0.5455

Epoch 00076: val_mDice did not improve from 0.58354
Epoch 77/300
 - 9s - loss: 0.3107 - acc: 0.9420 - mDice: 0.7187 - val_loss: 0.5747 - val_acc: 0.9411 - val_mDice: 0.5737

Epoch 00077: val_mDice did not improve from 0.58354
Epoch 78/300
 - 9s - loss: 0.3121 - acc: 0.9419 - mDice: 0.7177 - val_loss: 0.5985 - val_acc: 0.9439 - val_mDice: 0.5661

Epoch 00078: val_mDice did not improve from 0.58354
Epoch 79/300
 - 9s - loss: 0.3105 - acc: 0.9421 - mDice: 0.7189 - val_loss: 0.5643 - val_acc: 0.9451 - val_mDice: 0.5799

Epoch 00079: val_mDice did not improve from 0.58354
Epoch 80/300
 - 9s - loss: 0.3097 - acc: 0.9422 - mDice: 0.7195 - val_loss: 0.5509 - val_acc: 0.9423 - val_mDice: 0.5783

Epoch 00080: val_mDice did not improve from 0.58354
Epoch 81/300
 - 9s - loss: 0.3090 - acc: 0.9422 - mDice: 0.7200 - val_loss: 0.5533 - val_acc: 0.9421 - val_mDice: 0.5805

Epoch 00081: val_mDice did not improve from 0.58354
Epoch 82/300
 - 9s - loss: 0.3086 - acc: 0.9422 - mDice: 0.7203 - val_loss: 0.6999 - val_acc: 0.9288 - val_mDice: 0.5514

Epoch 00082: val_mDice did not improve from 0.58354
Epoch 83/300
 - 9s - loss: 0.3079 - acc: 0.9424 - mDice: 0.7209 - val_loss: 0.5703 - val_acc: 0.9399 - val_mDice: 0.5568

Epoch 00083: val_mDice did not improve from 0.58354
Epoch 84/300
 - 9s - loss: 0.3079 - acc: 0.9424 - mDice: 0.7208 - val_loss: 0.5668 - val_acc: 0.9429 - val_mDice: 0.5732

Epoch 00084: val_mDice did not improve from 0.58354
Epoch 85/300
 - 9s - loss: 0.3066 - acc: 0.9424 - mDice: 0.7218 - val_loss: 0.5644 - val_acc: 0.9396 - val_mDice: 0.5681

Epoch 00085: val_mDice did not improve from 0.58354
Epoch 86/300
 - 9s - loss: 0.3074 - acc: 0.9425 - mDice: 0.7212 - val_loss: 0.5664 - val_acc: 0.9401 - val_mDice: 0.5624

Epoch 00086: val_mDice did not improve from 0.58354
Epoch 87/300
 - 9s - loss: 0.3057 - acc: 0.9425 - mDice: 0.7225 - val_loss: 0.5340 - val_acc: 0.9457 - val_mDice: 0.5853

Epoch 00087: val_mDice improved from 0.58354 to 0.58531, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 88/300
 - 9s - loss: 0.3061 - acc: 0.9425 - mDice: 0.7222 - val_loss: 0.5393 - val_acc: 0.9472 - val_mDice: 0.5725

Epoch 00088: val_mDice did not improve from 0.58531
Epoch 89/300
 - 9s - loss: 0.3045 - acc: 0.9428 - mDice: 0.7234 - val_loss: 0.5282 - val_acc: 0.9401 - val_mDice: 0.5729

Epoch 00089: val_mDice did not improve from 0.58531
Epoch 90/300
 - 9s - loss: 0.3049 - acc: 0.9425 - mDice: 0.7231 - val_loss: 0.5353 - val_acc: 0.9410 - val_mDice: 0.5763

Epoch 00090: val_mDice did not improve from 0.58531
Epoch 91/300
 - 9s - loss: 0.3041 - acc: 0.9428 - mDice: 0.7238 - val_loss: 0.5860 - val_acc: 0.9365 - val_mDice: 0.5475

Epoch 00091: val_mDice did not improve from 0.58531
Epoch 92/300
 - 9s - loss: 0.3038 - acc: 0.9427 - mDice: 0.7239 - val_loss: 0.5382 - val_acc: 0.9422 - val_mDice: 0.5700

Epoch 00092: val_mDice did not improve from 0.58531
Epoch 93/300
 - 9s - loss: 0.3035 - acc: 0.9429 - mDice: 0.7241 - val_loss: 0.5412 - val_acc: 0.9445 - val_mDice: 0.5711

Epoch 00093: val_mDice did not improve from 0.58531
Epoch 94/300
 - 9s - loss: 0.3027 - acc: 0.9428 - mDice: 0.7247 - val_loss: 0.6448 - val_acc: 0.9333 - val_mDice: 0.5429

Epoch 00094: val_mDice did not improve from 0.58531
Epoch 95/300
 - 9s - loss: 0.3024 - acc: 0.9428 - mDice: 0.7250 - val_loss: 0.5508 - val_acc: 0.9466 - val_mDice: 0.5730

Epoch 00095: val_mDice did not improve from 0.58531
Epoch 96/300
 - 9s - loss: 0.3035 - acc: 0.9427 - mDice: 0.7241 - val_loss: 0.5906 - val_acc: 0.9312 - val_mDice: 0.5427

Epoch 00096: val_mDice did not improve from 0.58531
Epoch 97/300
 - 9s - loss: 0.3024 - acc: 0.9428 - mDice: 0.7250 - val_loss: 0.5366 - val_acc: 0.9414 - val_mDice: 0.5675

Epoch 00097: val_mDice did not improve from 0.58531
Epoch 98/300
 - 9s - loss: 0.3007 - acc: 0.9430 - mDice: 0.7263 - val_loss: 0.6572 - val_acc: 0.9324 - val_mDice: 0.5299

Epoch 00098: val_mDice did not improve from 0.58531
Epoch 99/300
 - 9s - loss: 0.3004 - acc: 0.9431 - mDice: 0.7264 - val_loss: 0.5346 - val_acc: 0.9368 - val_mDice: 0.5620

Epoch 00099: val_mDice did not improve from 0.58531
Epoch 100/300
 - 9s - loss: 0.3004 - acc: 0.9430 - mDice: 0.7265 - val_loss: 0.5415 - val_acc: 0.9444 - val_mDice: 0.5636

Epoch 00100: val_mDice did not improve from 0.58531
Epoch 101/300
 - 9s - loss: 0.3019 - acc: 0.9429 - mDice: 0.7253 - val_loss: 0.5209 - val_acc: 0.9409 - val_mDice: 0.5712

Epoch 00101: val_mDice did not improve from 0.58531
Epoch 102/300
 - 9s - loss: 0.2993 - acc: 0.9431 - mDice: 0.7274 - val_loss: 0.5315 - val_acc: 0.9432 - val_mDice: 0.5624

Epoch 00102: val_mDice did not improve from 0.58531
Epoch 103/300
 - 9s - loss: 0.3016 - acc: 0.9430 - mDice: 0.7256 - val_loss: 0.5325 - val_acc: 0.9433 - val_mDice: 0.5726

Epoch 00103: val_mDice did not improve from 0.58531
Epoch 104/300
 - 9s - loss: 0.2983 - acc: 0.9432 - mDice: 0.7281 - val_loss: 0.5423 - val_acc: 0.9423 - val_mDice: 0.5583

Epoch 00104: val_mDice did not improve from 0.58531
Epoch 105/300
 - 9s - loss: 0.2985 - acc: 0.9432 - mDice: 0.7279 - val_loss: 0.5488 - val_acc: 0.9452 - val_mDice: 0.5546

Epoch 00105: val_mDice did not improve from 0.58531
Epoch 106/300
 - 9s - loss: 0.2971 - acc: 0.9435 - mDice: 0.7290 - val_loss: 0.5555 - val_acc: 0.9433 - val_mDice: 0.5559

Epoch 00106: val_mDice did not improve from 0.58531
Epoch 107/300
 - 9s - loss: 0.2959 - acc: 0.9435 - mDice: 0.7299 - val_loss: 0.5306 - val_acc: 0.9430 - val_mDice: 0.5671

Epoch 00107: val_mDice did not improve from 0.58531
Epoch 108/300
 - 9s - loss: 0.2986 - acc: 0.9433 - mDice: 0.7279 - val_loss: 0.5462 - val_acc: 0.9404 - val_mDice: 0.5554

Epoch 00108: val_mDice did not improve from 0.58531
Epoch 109/300
 - 9s - loss: 0.2985 - acc: 0.9433 - mDice: 0.7279 - val_loss: 0.5137 - val_acc: 0.9415 - val_mDice: 0.5739

Epoch 00109: val_mDice did not improve from 0.58531
Epoch 110/300
 - 9s - loss: 0.2952 - acc: 0.9436 - mDice: 0.7304 - val_loss: 0.5280 - val_acc: 0.9410 - val_mDice: 0.5646

Epoch 00110: val_mDice did not improve from 0.58531
Epoch 111/300
 - 9s - loss: 0.2968 - acc: 0.9433 - mDice: 0.7292 - val_loss: 0.5942 - val_acc: 0.9375 - val_mDice: 0.5621

Epoch 00111: val_mDice did not improve from 0.58531
Epoch 112/300
 - 9s - loss: 0.2963 - acc: 0.9434 - mDice: 0.7296 - val_loss: 0.6075 - val_acc: 0.9364 - val_mDice: 0.5577

Epoch 00112: val_mDice did not improve from 0.58531
Epoch 113/300
 - 9s - loss: 0.2957 - acc: 0.9435 - mDice: 0.7300 - val_loss: 0.5754 - val_acc: 0.9422 - val_mDice: 0.5376

Epoch 00113: val_mDice did not improve from 0.58531
Epoch 114/300
 - 9s - loss: 0.2951 - acc: 0.9437 - mDice: 0.7305 - val_loss: 0.5248 - val_acc: 0.9403 - val_mDice: 0.5669

Epoch 00114: val_mDice did not improve from 0.58531
Epoch 115/300
 - 9s - loss: 0.2947 - acc: 0.9437 - mDice: 0.7309 - val_loss: 0.5542 - val_acc: 0.9409 - val_mDice: 0.5501

Epoch 00115: val_mDice did not improve from 0.58531
Epoch 116/300
 - 9s - loss: 0.2936 - acc: 0.9436 - mDice: 0.7317 - val_loss: 0.5536 - val_acc: 0.9399 - val_mDice: 0.5549

Epoch 00116: val_mDice did not improve from 0.58531
Epoch 117/300
 - 9s - loss: 0.2929 - acc: 0.9439 - mDice: 0.7323 - val_loss: 0.5499 - val_acc: 0.9393 - val_mDice: 0.5536

Epoch 00117: val_mDice did not improve from 0.58531
Epoch 118/300
 - 9s - loss: 0.2943 - acc: 0.9437 - mDice: 0.7312 - val_loss: 0.5367 - val_acc: 0.9418 - val_mDice: 0.5596

Epoch 00118: val_mDice did not improve from 0.58531
Epoch 119/300
 - 9s - loss: 0.2951 - acc: 0.9435 - mDice: 0.7305 - val_loss: 0.5386 - val_acc: 0.9405 - val_mDice: 0.5580

Epoch 00119: val_mDice did not improve from 0.58531
Epoch 120/300
 - 9s - loss: 0.2942 - acc: 0.9437 - mDice: 0.7312 - val_loss: 0.5137 - val_acc: 0.9431 - val_mDice: 0.5735

Epoch 00120: val_mDice did not improve from 0.58531
Epoch 121/300
 - 9s - loss: 0.2923 - acc: 0.9437 - mDice: 0.7326 - val_loss: 0.5359 - val_acc: 0.9450 - val_mDice: 0.5601

Epoch 00121: val_mDice did not improve from 0.58531
Epoch 122/300
 - 9s - loss: 0.2926 - acc: 0.9438 - mDice: 0.7325 - val_loss: 0.5216 - val_acc: 0.9426 - val_mDice: 0.5696

Epoch 00122: val_mDice did not improve from 0.58531
Epoch 123/300
 - 9s - loss: 0.2943 - acc: 0.9438 - mDice: 0.7312 - val_loss: 0.5369 - val_acc: 0.9418 - val_mDice: 0.5622

Epoch 00123: val_mDice did not improve from 0.58531
Epoch 124/300
 - 9s - loss: 0.2930 - acc: 0.9439 - mDice: 0.7322 - val_loss: 0.5304 - val_acc: 0.9400 - val_mDice: 0.5635

Epoch 00124: val_mDice did not improve from 0.58531
Epoch 125/300
 - 9s - loss: 0.2913 - acc: 0.9440 - mDice: 0.7335 - val_loss: 0.5525 - val_acc: 0.9317 - val_mDice: 0.5491

Epoch 00125: val_mDice did not improve from 0.58531
Epoch 126/300
 - 9s - loss: 0.2906 - acc: 0.9440 - mDice: 0.7339 - val_loss: 0.5527 - val_acc: 0.9404 - val_mDice: 0.5501

Epoch 00126: val_mDice did not improve from 0.58531
Epoch 127/300
 - 9s - loss: 0.2903 - acc: 0.9440 - mDice: 0.7342 - val_loss: 0.5665 - val_acc: 0.9298 - val_mDice: 0.5425

Epoch 00127: val_mDice did not improve from 0.58531
Restoring model weights from the end of the best epoch
Epoch 00127: early stopping
{'val_loss': [2.6575117111206055, 1.6146226156325567, 2.1358207748049782, 1.2277048996516637, 1.3500499384743827, 1.0900139581589472, 1.4261958258492606, 1.4375842185247512, 0.9714160079047793, 1.0454589185260592, 0.9422739119756789, 0.9518236092158726, 0.9415318965911865, 0.9185073943365187, 0.9167931193397159, 0.9385620980035692, 0.9085225604829335, 0.8985356433050973, 0.9045148349943615, 0.9066098758152553, 0.8537619227454776, 0.8833719208126977, 0.9201252574012393, 0.8789452825273786, 0.8855681759970528, 0.8976604711441767, 0.8703152111598423, 0.8620519183930897, 0.8652780737195697, 0.8305396011897496, 0.8908720130012149, 0.8574007806323823, 0.8232988119125366, 0.7800375620524088, 0.8825050308590844, 0.8837389945983887, 0.815977414449056, 0.7900146302722749, 0.8190911837986538, 0.8581548304784865, 0.7807575407482329, 0.8237966355823335, 0.8058749380565825, 0.7385972170602708, 0.7428221248445057, 0.7822606109437489, 0.7551580383664086, 0.7277595940090361, 0.7402743214652652, 0.7714759168170747, 0.7754825296856108, 0.780345292318435, 0.7526666720708212, 0.7082654975709461, 0.7185217142105103, 0.7140859535762242, 0.7096857570466542, 0.6887258348010835, 0.7860334033057803, 0.7870563779558454, 0.698082549231393, 0.633388394401187, 0.6577519462222144, 0.7102397737048921, 0.6776353461401803, 0.6530969199680147, 0.6408481824965704, 0.6005101998647054, 0.6034491402762276, 0.6020289545967465, 0.6018787168321156, 0.6201171647934687, 0.6115084716251918, 0.6292824518112909, 0.6000345320928664, 0.5979609602973575, 0.5746865669886271, 0.598516100928897, 0.5643466483978998, 0.550906260808309, 0.5532530092057728, 0.6998914764040992, 0.5702594461895171, 0.5667608635766166, 0.5644243047350929, 0.5664167688006446, 0.534039264633542, 0.5392664500645229, 0.5281671853292556, 0.5353174266361055, 0.5859566359292894, 0.5382405462719145, 0.5411610205968221, 0.6447721322377523, 0.5508493298575992, 0.5906220333916801, 0.5366260891868955, 0.6572254952930269, 0.5345585402988252, 0.5414961122331166, 0.5208636522293091, 0.5314889692124867, 0.5324904464540028, 0.5423305886132377, 0.5487809010914394, 0.5554648240407308, 0.5305655399958292, 0.5461630083265758, 0.5137316158839634, 0.5279788005919683, 0.5941919372195289, 0.6074551968347459, 0.575395425160726, 0.5248378117879232, 0.5542312519890922, 0.5536297957102457, 0.5498515140442621, 0.5367144913900466, 0.5386291628792172, 0.5137241170519874, 0.5359450465156919, 0.5215615885598319, 0.5368956043606713, 0.5304290169761294, 0.5524875209445045, 0.5526715062913441, 0.5664948338554019], 'val_acc': [0.8621428722427005, 0.8979693253835043, 0.906188170115153, 0.9088072180747986, 0.9144574261846996, 0.9190155665079752, 0.913903412364778, 0.9216117461522421, 0.9370352313632057, 0.9356501670110793, 0.9375892650513422, 0.9383058377674648, 0.9309523815200442, 0.93944365637643, 0.9420398473739624, 0.9276442300705683, 0.9322367253757659, 0.9400595142727807, 0.9432966907819113, 0.9398511733327594, 0.9429074809664771, 0.9400137464205424, 0.9429716382707868, 0.9417559788340614, 0.941577380611783, 0.9371726456142607, 0.9414697544915336, 0.9425022772380284, 0.9357440641948155, 0.944523831208547, 0.9402060338429042, 0.9440979929197402, 0.9401007237888518, 0.9403891676948184, 0.9416574864160447, 0.9343452141398475, 0.9448374680110386, 0.9397321598870414, 0.9330906811214629, 0.9377335026150658, 0.9429532743635631, 0.9358127315839132, 0.9383951624234518, 0.9426831432751247, 0.945982155345735, 0.9443521045503163, 0.9419757411593482, 0.938056346916017, 0.9404418553624835, 0.9422870846021743, 0.9406456010682243, 0.9402884897731599, 0.939072827498118, 0.9453411244210743, 0.9367445111274719, 0.9427930655933562, 0.9423855401220775, 0.9338919463611784, 0.9408195699964251, 0.9418017466862997, 0.9310141830217271, 0.934352091380528, 0.9443017641703287, 0.9271245428494045, 0.9412247935930887, 0.9443978951090858, 0.9408356490589324, 0.942831984588078, 0.9446016408148266, 0.9425503810246786, 0.9436790233566648, 0.9387591396059308, 0.9393360955374581, 0.9374427852176485, 0.9349084212666466, 0.9357738154275077, 0.9411309304691496, 0.943878227756137, 0.9451007502419608, 0.9422665011315119, 0.9421245455741882, 0.9288072217078436, 0.9398855169614156, 0.9429052159899757, 0.9396474361419678, 0.9401373437472752, 0.9456570630981809, 0.9472023901485261, 0.940073237532661, 0.9410073019209362, 0.9365063848949614, 0.9422184285663423, 0.9444551098914373, 0.9333287278811137, 0.9465613734154474, 0.9312270879745483, 0.9413896543639046, 0.9323557416598002, 0.9368132068997338, 0.9444024562835693, 0.9409455089342027, 0.9432097020603362, 0.9432508917081923, 0.9422802243913923, 0.945224370275225, 0.9432577916554042, 0.9429807492664882, 0.9404189842087882, 0.9414606406575158, 0.9410073501723153, 0.9374702402523586, 0.9364377288591295, 0.9421931987717038, 0.9402518329166231, 0.9408974590755644, 0.9398992515745617, 0.9393177628517151, 0.9418131936164129, 0.940505944547199, 0.9431112692469642, 0.9450343591826302, 0.9426465176400685, 0.9417948666073027, 0.9400274753570557, 0.931707881745838, 0.9404304169473194, 0.9298099591618493], 'val_mDice': [0.17592291303333782, 0.334508619670357, 0.22907133829513832, 0.4692530876823834, 0.4067989880485194, 0.5049291991052174, 0.37847830253165393, 0.3697213379921214, 0.5354230673540206, 0.503823809325695, 0.5574290729349568, 0.5412313233883608, 0.5592183170928842, 0.5615045312969458, 0.5561000594780559, 0.561048336327076, 0.5573488598068556, 0.5663629550309408, 0.5614358137051264, 0.5610581906068892, 0.55442448936048, 0.5617674033911455, 0.5377152884999911, 0.5419862298738389, 0.5695403023135095, 0.5557448275032497, 0.5625933215376877, 0.5515058303163165, 0.5618986244357768, 0.5752012295027574, 0.5533262533800942, 0.5629076382943562, 0.5708214420647848, 0.5648033374122211, 0.5455364010163716, 0.5534455112758137, 0.5626225233787582, 0.5655365946392218, 0.5613818860479763, 0.5291987414516154, 0.5762309515405268, 0.5584783765176932, 0.5555580180315745, 0.5788640461507297, 0.5691816102535951, 0.5444678811445123, 0.5741565805815515, 0.5800046746929487, 0.5664601130854516, 0.5557426297593684, 0.556156191442694, 0.538760839118844, 0.5699471600708508, 0.5667029248461837, 0.5648675026992956, 0.5664346301484675, 0.5586218709746996, 0.5596950313165074, 0.5468400482620511, 0.5164031831636315, 0.5432416319492317, 0.5641683359586057, 0.5645502200793653, 0.5414188163621085, 0.57249031730351, 0.5687600656279496, 0.5729181842789763, 0.5706817378245649, 0.572888566269761, 0.5671436501046022, 0.5835355953091667, 0.5626666733906383, 0.5638429733614126, 0.5544781457810175, 0.5647297343682676, 0.5455397984811238, 0.5737213291937396, 0.5661294616404033, 0.5799447629778158, 0.5782913143436114, 0.5804531011907827, 0.5513501901711736, 0.556806257438092, 0.5731888363758723, 0.5680626648522559, 0.5624496381552446, 0.5853051782718727, 0.5725491435400077, 0.5728966370224953, 0.5762664560405981, 0.547547309881165, 0.5699522335614476, 0.571079342670384, 0.5428945368954113, 0.5730432859134107, 0.5426892776574407, 0.5674813333011809, 0.5298962614365986, 0.5619603464645999, 0.5635893288112822, 0.5711609079014688, 0.5623965454953057, 0.5725546362144607, 0.5583285994472957, 0.5545511990785599, 0.5558637760224796, 0.5670927897805259, 0.5553908417267459, 0.5739205603798231, 0.5646014947976384, 0.5620647165037337, 0.5577294638469106, 0.5375850566086315, 0.5668769299629188, 0.5500881086502757, 0.554904721145119, 0.5536225867413339, 0.5596271426904769, 0.5579715539656934, 0.5735309186081091, 0.5600598921023664, 0.5695572765100569, 0.5621850504761651, 0.563521662638301, 0.5490586741694382, 0.5501287726774102, 0.5424848255657014], 'loss': [2.941413989686681, 1.1638234920163408, 0.8107612747803161, 0.6993968608132534, 0.6301500547109185, 0.583606048438828, 0.5491604820850476, 0.522731428583486, 0.49585999098269035, 0.4797382186735575, 0.462823485188202, 0.4526167114001146, 0.4423566673253344, 0.4352696381806638, 0.4245946770438758, 0.42105396127273337, 0.41505415382839383, 0.407498501440866, 0.40503638480609155, 0.40031832208954254, 0.39452006356872893, 0.3893142112974075, 0.3872241853966703, 0.3840979031337946, 0.3806166302004094, 0.37737178185989523, 0.37419642014771914, 0.371552414573041, 0.36910139910513345, 0.3680971495581657, 0.3642408795753885, 0.36239649728586937, 0.36085595978531326, 0.3566760386842879, 0.3571824214179001, 0.3559002548841146, 0.3512770543961206, 0.35222010710047735, 0.34743892238713286, 0.34800345874232597, 0.34645111907394904, 0.3455340867732471, 0.34348441617599634, 0.3406479589473036, 0.34034851149761636, 0.33868992627413946, 0.3387909709821208, 0.336428969558411, 0.33617956146629463, 0.3343177955401571, 0.33223364734456606, 0.33182141243986296, 0.3309989725840168, 0.33083571040586673, 0.3284937470134384, 0.32845776783080144, 0.3257007731312567, 0.32598488202599724, 0.3251499869252575, 0.3226545836416678, 0.3225488164463047, 0.32367623442971044, 0.32057109062028616, 0.32096800294275435, 0.31968217079226213, 0.3192300759507255, 0.3193716872673814, 0.317501685069847, 0.3172866035879796, 0.314703018783213, 0.31404810088986673, 0.3156346147037872, 0.3154886065936856, 0.31271541991375396, 0.31292826747397867, 0.3114090051601819, 0.3106728572594492, 0.3120732696294922, 0.31048418359993646, 0.30965156502431357, 0.3089867466926023, 0.3085812386437742, 0.3078517661415039, 0.3078547491546033, 0.30659825822073805, 0.30738836806680464, 0.30567914764615, 0.3060644470831781, 0.30448594841052506, 0.3048808510096197, 0.30408151286609464, 0.3037761960768254, 0.3035495925298977, 0.30270522007230666, 0.3023945208411238, 0.3034564586809106, 0.3023803801189067, 0.3007097540389878, 0.30038748861669184, 0.30044836709672645, 0.30190579047064253, 0.2992510211440164, 0.30159830116848735, 0.2983099706363237, 0.29854617925285026, 0.2970632113012156, 0.29585354706674316, 0.29858267281426387, 0.2985300896184762, 0.2952024830497711, 0.2968260349911579, 0.2963128367473745, 0.2957136776317676, 0.29514190040964, 0.2947274292563344, 0.2936141838716224, 0.29287179552430886, 0.29425409705119027, 0.2951181496478975, 0.29415681938663574, 0.2923280705496919, 0.2926077687294469, 0.2943120321798628, 0.29304205665750177, 0.2912546590571002, 0.290620966036471, 0.29029587620780584], 'acc': [0.4410531933641868, 0.8668108434720331, 0.8776031698890107, 0.8830884781121886, 0.8880298702110554, 0.8933333930584054, 0.898794968922933, 0.9056994141768416, 0.9125406191094845, 0.9179088165816577, 0.9221649265183588, 0.924342640130672, 0.9261154904861039, 0.9272566805783093, 0.9285022375186974, 0.9294213014851421, 0.930111292195913, 0.9310093580676753, 0.9313589783332609, 0.9320956351946883, 0.9325496624355857, 0.93328313944035, 0.9335066369670605, 0.9338988436769148, 0.934390477105007, 0.9348328041506337, 0.9351548979754436, 0.9353968772512193, 0.9358266465737913, 0.9359238263911219, 0.9362060872028851, 0.9366141399345302, 0.9369284685393026, 0.9373202812632592, 0.9371966818911, 0.9376149796580037, 0.9380431968121945, 0.9380145765164465, 0.9384975472074817, 0.9384144768908875, 0.9386450136376641, 0.9385047060620102, 0.9388824762786908, 0.9390750596099031, 0.9391718919575501, 0.9393605323501559, 0.9393977937565986, 0.9396183899493721, 0.939525218524293, 0.9397805495392686, 0.9400188914493534, 0.9402759370257773, 0.9400999740481446, 0.9400708919341839, 0.9405368530086086, 0.940407069243745, 0.9406759329032457, 0.9405056653924593, 0.9408674706768295, 0.9409112178661103, 0.9409051463280842, 0.9408617233848535, 0.9411443936611062, 0.9411905098563562, 0.9413151986364089, 0.9412892907024786, 0.9411893712892822, 0.9414853934081552, 0.9414540669098511, 0.941662863830576, 0.9417399825768501, 0.9416499836426009, 0.9415179277882081, 0.9419558956279721, 0.9420375538074559, 0.9419812934923107, 0.9420226073021463, 0.9419473710721091, 0.9420948577956793, 0.9421831682534123, 0.9421892388031987, 0.9422094417556026, 0.9423838588045539, 0.9423624248386969, 0.9423570932164366, 0.9424842400014894, 0.9424970959201354, 0.9424686895093408, 0.9427806978421517, 0.9425494440240347, 0.9427514293530738, 0.9427121810217182, 0.9428521178925637, 0.9427917522917093, 0.9427987305281915, 0.9427484680008102, 0.942785472281066, 0.9429765016397852, 0.9431458868133739, 0.9429932794107599, 0.9428662953635091, 0.9431462134955498, 0.9429727463518146, 0.9432497230457713, 0.9432363031639951, 0.9435055817003215, 0.9434531942277096, 0.9433268793681373, 0.9432512022108156, 0.9435990827033486, 0.9432719158073691, 0.9433950995557773, 0.943466327117775, 0.9436676467294658, 0.9436538141541843, 0.9436089524718086, 0.943889494079695, 0.9436835430480621, 0.9434967096977572, 0.9436581478956372, 0.943650407186243, 0.9438006306673626, 0.9437526168220186, 0.9438542286187255, 0.9440494015976623, 0.9439551150589659, 0.9439981030847885], 'mDice': [0.08762267731303927, 0.31491433838118427, 0.4305030895734261, 0.4813662636411059, 0.5163603707018997, 0.5414462989641105, 0.5614034814344612, 0.5770388594569097, 0.5933921599585771, 0.6032908373608028, 0.6136792908749967, 0.6202626356229126, 0.6269943097985868, 0.6316721869245853, 0.6386073128621381, 0.6410232403615271, 0.6450679356109115, 0.6499940287476218, 0.6518497910829599, 0.6549200162346109, 0.6589532733446191, 0.6625200554840547, 0.6639281159907102, 0.6661243254517415, 0.668585567971243, 0.6707026629128943, 0.6729470295140296, 0.6748621700608434, 0.6764576352812409, 0.677213266873971, 0.679854144727377, 0.6811942118589005, 0.6823653854775893, 0.6853277964216908, 0.6849694148248989, 0.6858477431592027, 0.6891027661746054, 0.6884646217832681, 0.6919251012278127, 0.6913933816364282, 0.6925496399253234, 0.6931967918229788, 0.6946041181479572, 0.6967261186886183, 0.696941498871688, 0.6981325236868946, 0.6980985917290304, 0.6998763470629494, 0.6999478933552407, 0.7013568081836469, 0.7028333616091241, 0.7031715049871434, 0.7037299013629639, 0.7038174515196141, 0.7055987412009782, 0.705638775918349, 0.707585404908379, 0.7073358070397621, 0.7080476890760325, 0.7098146959584826, 0.7099160649584786, 0.7091789190907549, 0.7114024491744025, 0.711138660711936, 0.71206058411555, 0.7123417331576233, 0.7122820949241884, 0.7136067290261965, 0.7138554978191405, 0.7157832575322393, 0.7162536892997569, 0.7151454054645107, 0.7150903887916029, 0.7172633679312549, 0.7171379293875128, 0.7181506352960569, 0.7186715277445116, 0.7177252034265824, 0.7189440812613203, 0.7194904481856745, 0.7200287935337121, 0.7202748287176842, 0.7208952907194907, 0.7208135102855601, 0.7218456423211378, 0.7212349498618975, 0.7225010846537709, 0.7222319342898385, 0.7234461933564009, 0.7230631790226403, 0.7237801609044823, 0.7239406112303549, 0.7241061012225963, 0.7247309455160049, 0.7249682146344131, 0.7241496736198486, 0.7249598440945619, 0.7262888801955111, 0.7264443168250356, 0.7264619292219135, 0.7252667743805311, 0.7273769964251602, 0.7255732888359083, 0.7281481450477822, 0.7278630015292517, 0.7289867156361348, 0.7299147119796964, 0.7278520715978992, 0.7279100444520488, 0.7304070348084168, 0.7292425150077927, 0.7295524776154271, 0.730048397820603, 0.7305383349696818, 0.7308745347214775, 0.7316843574966841, 0.7322782826648871, 0.7312297207646823, 0.7305347004997631, 0.7311799321901782, 0.7325722872808716, 0.7324633011703939, 0.7312361598819213, 0.7322227886492102, 0.7334760945726273, 0.7338993596230855, 0.7341603670180913]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.27s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.01s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.80s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:21,  1.76s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:41,  1.63s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:38,  1.62s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:11,  1.54s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:32,  1.61s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:11,  1.55s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:36,  1.64s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:23,  1.60s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:44,  1.68s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<07:58,  1.74s/it]predicting train subjects:   4%|▍         | 11/285 [00:17<07:33,  1.66s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<07:52,  1.73s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:30,  1.66s/it]predicting train subjects:   5%|▍         | 14/285 [00:22<07:40,  1.70s/it]predicting train subjects:   5%|▌         | 15/285 [00:24<07:59,  1.78s/it]predicting train subjects:   6%|▌         | 16/285 [00:26<08:06,  1.81s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<07:46,  1.74s/it]predicting train subjects:   6%|▋         | 18/285 [00:30<07:44,  1.74s/it]predicting train subjects:   7%|▋         | 19/285 [00:31<07:27,  1.68s/it]predicting train subjects:   7%|▋         | 20/285 [00:33<07:34,  1.72s/it]predicting train subjects:   7%|▋         | 21/285 [00:35<07:52,  1.79s/it]predicting train subjects:   8%|▊         | 22/285 [00:36<07:25,  1.69s/it]predicting train subjects:   8%|▊         | 23/285 [00:38<07:31,  1.72s/it]predicting train subjects:   8%|▊         | 24/285 [00:40<07:12,  1.66s/it]predicting train subjects:   9%|▉         | 25/285 [00:42<07:27,  1.72s/it]predicting train subjects:   9%|▉         | 26/285 [00:44<07:44,  1.79s/it]predicting train subjects:   9%|▉         | 27/285 [00:45<07:20,  1.71s/it]predicting train subjects:  10%|▉         | 28/285 [00:47<07:32,  1.76s/it]predicting train subjects:  10%|█         | 29/285 [00:49<07:32,  1.77s/it]predicting train subjects:  11%|█         | 30/285 [00:51<07:37,  1.79s/it]predicting train subjects:  11%|█         | 31/285 [00:52<07:44,  1.83s/it]predicting train subjects:  11%|█         | 32/285 [00:54<07:19,  1.74s/it]predicting train subjects:  12%|█▏        | 33/285 [00:56<07:20,  1.75s/it]predicting train subjects:  12%|█▏        | 34/285 [00:58<07:23,  1.77s/it]predicting train subjects:  12%|█▏        | 35/285 [01:00<07:36,  1.83s/it]predicting train subjects:  13%|█▎        | 36/285 [01:01<07:13,  1.74s/it]predicting train subjects:  13%|█▎        | 37/285 [01:03<07:15,  1.75s/it]predicting train subjects:  13%|█▎        | 38/285 [01:05<07:24,  1.80s/it]predicting train subjects:  14%|█▎        | 39/285 [01:06<07:08,  1.74s/it]predicting train subjects:  14%|█▍        | 40/285 [01:08<07:05,  1.74s/it]predicting train subjects:  14%|█▍        | 41/285 [01:10<06:49,  1.68s/it]predicting train subjects:  15%|█▍        | 42/285 [01:11<06:35,  1.63s/it]predicting train subjects:  15%|█▌        | 43/285 [01:13<06:42,  1.66s/it]predicting train subjects:  15%|█▌        | 44/285 [01:15<06:52,  1.71s/it]predicting train subjects:  16%|█▌        | 45/285 [01:16<06:36,  1.65s/it]predicting train subjects:  16%|█▌        | 46/285 [01:18<06:51,  1.72s/it]predicting train subjects:  16%|█▋        | 47/285 [01:20<06:32,  1.65s/it]predicting train subjects:  17%|█▋        | 48/285 [01:21<06:42,  1.70s/it]predicting train subjects:  17%|█▋        | 49/285 [01:23<06:58,  1.77s/it]predicting train subjects:  18%|█▊        | 50/285 [01:25<06:59,  1.78s/it]predicting train subjects:  18%|█▊        | 51/285 [01:27<07:04,  1.82s/it]predicting train subjects:  18%|█▊        | 52/285 [01:29<06:44,  1.74s/it]predicting train subjects:  19%|█▊        | 53/285 [01:30<06:50,  1.77s/it]predicting train subjects:  19%|█▉        | 54/285 [01:32<06:59,  1.82s/it]predicting train subjects:  19%|█▉        | 55/285 [01:34<06:35,  1.72s/it]predicting train subjects:  20%|█▉        | 56/285 [01:36<06:40,  1.75s/it]predicting train subjects:  20%|██        | 57/285 [01:37<06:22,  1.68s/it]predicting train subjects:  20%|██        | 58/285 [01:39<06:24,  1.69s/it]predicting train subjects:  21%|██        | 59/285 [01:41<06:37,  1.76s/it]predicting train subjects:  21%|██        | 60/285 [01:43<06:50,  1.82s/it]predicting train subjects:  21%|██▏       | 61/285 [01:44<06:30,  1.74s/it]predicting train subjects:  22%|██▏       | 62/285 [01:46<06:39,  1.79s/it]predicting train subjects:  22%|██▏       | 63/285 [01:48<06:39,  1.80s/it]predicting train subjects:  22%|██▏       | 64/285 [01:50<06:28,  1.76s/it]predicting train subjects:  23%|██▎       | 65/285 [01:52<06:32,  1.79s/it]predicting train subjects:  23%|██▎       | 66/285 [01:53<06:31,  1.79s/it]predicting train subjects:  24%|██▎       | 67/285 [01:55<06:34,  1.81s/it]predicting train subjects:  24%|██▍       | 68/285 [01:57<06:20,  1.75s/it]predicting train subjects:  24%|██▍       | 69/285 [01:59<06:21,  1.77s/it]predicting train subjects:  25%|██▍       | 70/285 [02:00<06:19,  1.77s/it]predicting train subjects:  25%|██▍       | 71/285 [02:02<06:22,  1.79s/it]predicting train subjects:  25%|██▌       | 72/285 [02:04<06:11,  1.75s/it]predicting train subjects:  26%|██▌       | 73/285 [02:06<06:20,  1.79s/it]predicting train subjects:  26%|██▌       | 74/285 [02:08<06:16,  1.78s/it]predicting train subjects:  26%|██▋       | 75/285 [02:10<06:23,  1.83s/it]predicting train subjects:  27%|██▋       | 76/285 [02:11<06:24,  1.84s/it]predicting train subjects:  27%|██▋       | 77/285 [02:13<06:10,  1.78s/it]predicting train subjects:  27%|██▋       | 78/285 [02:15<06:03,  1.76s/it]predicting train subjects:  28%|██▊       | 79/285 [02:16<06:00,  1.75s/it]predicting train subjects:  28%|██▊       | 80/285 [02:18<06:01,  1.76s/it]predicting train subjects:  28%|██▊       | 81/285 [02:20<05:51,  1.72s/it]predicting train subjects:  29%|██▉       | 82/285 [02:22<05:49,  1.72s/it]predicting train subjects:  29%|██▉       | 83/285 [02:23<05:40,  1.69s/it]predicting train subjects:  29%|██▉       | 84/285 [02:25<05:31,  1.65s/it]predicting train subjects:  30%|██▉       | 85/285 [02:27<05:38,  1.69s/it]predicting train subjects:  30%|███       | 86/285 [02:28<05:45,  1.74s/it]predicting train subjects:  31%|███       | 87/285 [02:30<05:49,  1.77s/it]predicting train subjects:  31%|███       | 88/285 [02:32<05:41,  1.73s/it]predicting train subjects:  31%|███       | 89/285 [02:34<05:40,  1.74s/it]predicting train subjects:  32%|███▏      | 90/285 [02:36<05:46,  1.78s/it]predicting train subjects:  32%|███▏      | 91/285 [02:37<05:35,  1.73s/it]predicting train subjects:  32%|███▏      | 92/285 [02:39<05:41,  1.77s/it]predicting train subjects:  33%|███▎      | 93/285 [02:41<05:27,  1.71s/it]predicting train subjects:  33%|███▎      | 94/285 [02:42<05:26,  1.71s/it]predicting train subjects:  33%|███▎      | 95/285 [02:44<05:32,  1.75s/it]predicting train subjects:  34%|███▎      | 96/285 [02:46<05:29,  1.74s/it]predicting train subjects:  34%|███▍      | 97/285 [02:48<05:35,  1.79s/it]predicting train subjects:  34%|███▍      | 98/285 [02:50<05:32,  1.78s/it]predicting train subjects:  35%|███▍      | 99/285 [02:51<05:31,  1.78s/it]predicting train subjects:  35%|███▌      | 100/285 [02:53<05:35,  1.81s/it]predicting train subjects:  35%|███▌      | 101/285 [02:55<05:23,  1.76s/it]predicting train subjects:  36%|███▌      | 102/285 [02:57<05:26,  1.78s/it]predicting train subjects:  36%|███▌      | 103/285 [02:58<05:18,  1.75s/it]predicting train subjects:  36%|███▋      | 104/285 [03:00<05:22,  1.78s/it]predicting train subjects:  37%|███▋      | 105/285 [03:02<05:22,  1.79s/it]predicting train subjects:  37%|███▋      | 106/285 [03:04<05:10,  1.74s/it]predicting train subjects:  38%|███▊      | 107/285 [03:05<05:09,  1.74s/it]predicting train subjects:  38%|███▊      | 108/285 [03:07<05:01,  1.70s/it]predicting train subjects:  38%|███▊      | 109/285 [03:09<05:00,  1.71s/it]predicting train subjects:  39%|███▊      | 110/285 [03:11<05:04,  1.74s/it]predicting train subjects:  39%|███▉      | 111/285 [03:12<04:56,  1.71s/it]predicting train subjects:  39%|███▉      | 112/285 [03:14<04:56,  1.71s/it]predicting train subjects:  40%|███▉      | 113/285 [03:16<05:04,  1.77s/it]predicting train subjects:  40%|████      | 114/285 [03:18<05:00,  1.76s/it]predicting train subjects:  40%|████      | 115/285 [03:19<05:02,  1.78s/it]predicting train subjects:  41%|████      | 116/285 [03:21<05:03,  1.80s/it]predicting train subjects:  41%|████      | 117/285 [03:23<04:53,  1.75s/it]predicting train subjects:  41%|████▏     | 118/285 [03:24<04:45,  1.71s/it]predicting train subjects:  42%|████▏     | 119/285 [03:26<04:49,  1.75s/it]predicting train subjects:  42%|████▏     | 120/285 [03:28<04:44,  1.73s/it]predicting train subjects:  42%|████▏     | 121/285 [03:30<04:36,  1.69s/it]predicting train subjects:  43%|████▎     | 122/285 [03:31<04:29,  1.65s/it]predicting train subjects:  43%|████▎     | 123/285 [03:33<04:18,  1.59s/it]predicting train subjects:  44%|████▎     | 124/285 [03:34<04:15,  1.59s/it]predicting train subjects:  44%|████▍     | 125/285 [03:36<04:07,  1.55s/it]predicting train subjects:  44%|████▍     | 126/285 [03:37<04:01,  1.52s/it]predicting train subjects:  45%|████▍     | 127/285 [03:38<03:54,  1.49s/it]predicting train subjects:  45%|████▍     | 128/285 [03:40<03:59,  1.53s/it]predicting train subjects:  45%|████▌     | 129/285 [03:42<03:53,  1.50s/it]predicting train subjects:  46%|████▌     | 130/285 [03:43<03:50,  1.49s/it]predicting train subjects:  46%|████▌     | 131/285 [03:44<03:44,  1.46s/it]predicting train subjects:  46%|████▋     | 132/285 [03:46<03:53,  1.53s/it]predicting train subjects:  47%|████▋     | 133/285 [03:47<03:44,  1.48s/it]predicting train subjects:  47%|████▋     | 134/285 [03:49<03:40,  1.46s/it]predicting train subjects:  47%|████▋     | 135/285 [03:50<03:34,  1.43s/it]predicting train subjects:  48%|████▊     | 136/285 [03:52<03:31,  1.42s/it]predicting train subjects:  48%|████▊     | 137/285 [03:53<03:36,  1.46s/it]predicting train subjects:  48%|████▊     | 138/285 [03:55<03:30,  1.43s/it]predicting train subjects:  49%|████▉     | 139/285 [03:56<03:35,  1.48s/it]predicting train subjects:  49%|████▉     | 140/285 [03:58<03:36,  1.49s/it]predicting train subjects:  49%|████▉     | 141/285 [03:59<03:32,  1.48s/it]predicting train subjects:  50%|████▉     | 142/285 [04:01<03:31,  1.48s/it]predicting train subjects:  50%|█████     | 143/285 [04:02<03:27,  1.46s/it]predicting train subjects:  51%|█████     | 144/285 [04:04<03:29,  1.49s/it]predicting train subjects:  51%|█████     | 145/285 [04:05<03:27,  1.49s/it]predicting train subjects:  51%|█████     | 146/285 [04:07<03:31,  1.52s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:08<03:25,  1.49s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:10<03:27,  1.52s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:11<03:22,  1.49s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:12<03:15,  1.45s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:14<03:21,  1.50s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:15<03:16,  1.48s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:17<03:12,  1.46s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:18<03:13,  1.48s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:20<03:08,  1.45s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:21<03:09,  1.47s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:23<03:07,  1.47s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:24<03:07,  1.47s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:26<03:01,  1.44s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:27<02:59,  1.44s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:29<03:03,  1.48s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:30<03:01,  1.47s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:32<03:03,  1.50s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:33<02:58,  1.48s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:34<02:56,  1.47s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:36<02:58,  1.50s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:38<03:00,  1.53s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:39<02:54,  1.50s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:40<02:49,  1.46s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:42<02:44,  1.43s/it]predicting train subjects:  60%|██████    | 171/285 [04:43<02:42,  1.42s/it]predicting train subjects:  60%|██████    | 172/285 [04:45<02:39,  1.41s/it]predicting train subjects:  61%|██████    | 173/285 [04:46<02:39,  1.42s/it]predicting train subjects:  61%|██████    | 174/285 [04:48<02:39,  1.43s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:49<02:41,  1.47s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:51<02:42,  1.49s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:52<02:38,  1.47s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:53<02:32,  1.43s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:55<02:29,  1.41s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:57<02:43,  1.56s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:58<02:42,  1.56s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:00<02:42,  1.58s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:01<02:33,  1.51s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:03<02:30,  1.49s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:04<02:26,  1.47s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:06<02:37,  1.59s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:08<02:44,  1.68s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:10<02:46,  1.72s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:11<02:34,  1.61s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:12<02:25,  1.53s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:14<02:26,  1.56s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:16<02:26,  1.58s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:17<02:19,  1.51s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:18<02:17,  1.52s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:20<02:13,  1.48s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:22<02:20,  1.58s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:24<02:27,  1.68s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:25<02:28,  1.71s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:27<02:17,  1.60s/it]predicting train subjects:  70%|███████   | 200/285 [05:28<02:10,  1.53s/it]predicting train subjects:  71%|███████   | 201/285 [05:30<02:15,  1.61s/it]predicting train subjects:  71%|███████   | 202/285 [05:32<02:15,  1.63s/it]predicting train subjects:  71%|███████   | 203/285 [05:33<02:12,  1.61s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:34<02:04,  1.54s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:36<01:59,  1.49s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:37<01:54,  1.46s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:39<02:02,  1.58s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:41<02:04,  1.62s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:43<02:06,  1.67s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:44<01:59,  1.59s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:45<01:54,  1.54s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:47<01:53,  1.56s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:49<01:54,  1.59s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:50<01:48,  1.53s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:52<01:52,  1.60s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:53<01:44,  1.51s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:55<01:50,  1.63s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:57<01:54,  1.71s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:59<01:57,  1.78s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:00<01:47,  1.66s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:02<01:41,  1.58s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:03<01:39,  1.58s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:05<01:32,  1.49s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:06<01:29,  1.46s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:07<01:24,  1.41s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:09<01:30,  1.54s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:11<01:34,  1.63s/it]predicting train subjects:  80%|████████  | 228/285 [06:13<01:35,  1.67s/it]predicting train subjects:  80%|████████  | 229/285 [06:14<01:32,  1.65s/it]predicting train subjects:  81%|████████  | 230/285 [06:16<01:25,  1.55s/it]predicting train subjects:  81%|████████  | 231/285 [06:17<01:21,  1.50s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:19<01:21,  1.53s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:20<01:16,  1.47s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:22<01:19,  1.55s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:23<01:14,  1.50s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:25<01:17,  1.59s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:27<01:20,  1.67s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:28<01:19,  1.70s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:30<01:17,  1.68s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:31<01:11,  1.59s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:33<01:08,  1.56s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:34<01:04,  1.50s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:36<01:01,  1.47s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:37<01:03,  1.56s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:39<00:59,  1.49s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:41<01:01,  1.59s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:42<01:02,  1.64s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:44<00:59,  1.61s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:45<00:54,  1.52s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:47<00:51,  1.48s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:48<00:49,  1.44s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:49<00:46,  1.41s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:51<00:49,  1.56s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:53<00:50,  1.64s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:55<00:49,  1.65s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:56<00:45,  1.58s/it]predicting train subjects:  90%|█████████ | 257/285 [06:58<00:43,  1.55s/it]predicting train subjects:  91%|█████████ | 258/285 [06:59<00:43,  1.61s/it]predicting train subjects:  91%|█████████ | 259/285 [07:01<00:41,  1.61s/it]predicting train subjects:  91%|█████████ | 260/285 [07:02<00:37,  1.52s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:04<00:35,  1.48s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:05<00:33,  1.45s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:06<00:31,  1.44s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:08<00:33,  1.58s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:10<00:33,  1.66s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:12<00:30,  1.59s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:13<00:28,  1.58s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:15<00:28,  1.66s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:17<00:26,  1.66s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:18<00:23,  1.57s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:19<00:21,  1.52s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:21<00:20,  1.56s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:23<00:18,  1.54s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:24<00:16,  1.48s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:26<00:15,  1.58s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:28<00:15,  1.68s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:29<00:12,  1.61s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:31<00:10,  1.56s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:32<00:09,  1.59s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:34<00:07,  1.54s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:35<00:06,  1.50s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:36<00:04,  1.48s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:38<00:03,  1.60s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:40<00:01,  1.64s/it]predicting train subjects: 100%|██████████| 285/285 [07:42<00:00,  1.71s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:14,  1.74s/it]Loading train:   1%|          | 2/285 [00:03<07:40,  1.63s/it]Loading train:   1%|          | 3/285 [00:04<07:28,  1.59s/it]Loading train:   1%|▏         | 4/285 [00:05<06:58,  1.49s/it]Loading train:   2%|▏         | 5/285 [00:07<07:12,  1.54s/it]Loading train:   2%|▏         | 6/285 [00:08<06:46,  1.46s/it]Loading train:   2%|▏         | 7/285 [00:10<06:54,  1.49s/it]Loading train:   3%|▎         | 8/285 [00:11<06:46,  1.47s/it]Loading train:   3%|▎         | 9/285 [00:13<07:09,  1.55s/it]Loading train:   4%|▎         | 10/285 [00:14<06:37,  1.45s/it]Loading train:   4%|▍         | 11/285 [00:15<06:17,  1.38s/it]Loading train:   4%|▍         | 12/285 [00:17<06:09,  1.35s/it]Loading train:   5%|▍         | 13/285 [00:18<05:37,  1.24s/it]Loading train:   5%|▍         | 14/285 [00:19<05:31,  1.22s/it]Loading train:   5%|▌         | 15/285 [00:20<05:31,  1.23s/it]Loading train:   6%|▌         | 16/285 [00:21<05:35,  1.25s/it]Loading train:   6%|▌         | 17/285 [00:23<05:26,  1.22s/it]Loading train:   6%|▋         | 18/285 [00:24<05:13,  1.18s/it]Loading train:   7%|▋         | 19/285 [00:25<04:59,  1.13s/it]Loading train:   7%|▋         | 20/285 [00:26<05:02,  1.14s/it]Loading train:   7%|▋         | 21/285 [00:27<05:08,  1.17s/it]Loading train:   8%|▊         | 22/285 [00:28<04:50,  1.10s/it]Loading train:   8%|▊         | 23/285 [00:29<04:50,  1.11s/it]Loading train:   8%|▊         | 24/285 [00:30<04:39,  1.07s/it]Loading train:   9%|▉         | 25/285 [00:31<05:00,  1.16s/it]Loading train:   9%|▉         | 26/285 [00:33<04:49,  1.12s/it]Loading train:   9%|▉         | 27/285 [00:34<04:42,  1.10s/it]Loading train:  10%|▉         | 28/285 [00:35<04:45,  1.11s/it]Loading train:  10%|█         | 29/285 [00:36<04:55,  1.15s/it]Loading train:  11%|█         | 30/285 [00:37<04:59,  1.17s/it]Loading train:  11%|█         | 31/285 [00:39<05:11,  1.23s/it]Loading train:  11%|█         | 32/285 [00:40<04:59,  1.18s/it]Loading train:  12%|█▏        | 33/285 [00:41<04:39,  1.11s/it]Loading train:  12%|█▏        | 34/285 [00:42<04:34,  1.09s/it]Loading train:  12%|█▏        | 35/285 [00:43<04:28,  1.07s/it]Loading train:  13%|█▎        | 36/285 [00:44<04:15,  1.03s/it]Loading train:  13%|█▎        | 37/285 [00:45<04:10,  1.01s/it]Loading train:  13%|█▎        | 38/285 [00:46<04:28,  1.09s/it]Loading train:  14%|█▎        | 39/285 [00:47<04:17,  1.05s/it]Loading train:  14%|█▍        | 40/285 [00:48<04:26,  1.09s/it]Loading train:  14%|█▍        | 41/285 [00:49<04:25,  1.09s/it]Loading train:  15%|█▍        | 42/285 [00:50<04:12,  1.04s/it]Loading train:  15%|█▌        | 43/285 [00:51<04:18,  1.07s/it]Loading train:  15%|█▌        | 44/285 [00:52<04:39,  1.16s/it]Loading train:  16%|█▌        | 45/285 [00:53<04:22,  1.09s/it]Loading train:  16%|█▌        | 46/285 [00:55<04:44,  1.19s/it]Loading train:  16%|█▋        | 47/285 [00:56<04:30,  1.14s/it]Loading train:  17%|█▋        | 48/285 [00:57<04:28,  1.13s/it]Loading train:  17%|█▋        | 49/285 [00:58<04:37,  1.17s/it]Loading train:  18%|█▊        | 50/285 [00:59<04:33,  1.16s/it]Loading train:  18%|█▊        | 51/285 [01:01<04:44,  1.22s/it]Loading train:  18%|█▊        | 52/285 [01:02<04:20,  1.12s/it]Loading train:  19%|█▊        | 53/285 [01:03<04:26,  1.15s/it]Loading train:  19%|█▉        | 54/285 [01:04<04:34,  1.19s/it]Loading train:  19%|█▉        | 55/285 [01:05<04:24,  1.15s/it]Loading train:  20%|█▉        | 56/285 [01:06<04:22,  1.14s/it]Loading train:  20%|██        | 57/285 [01:07<04:16,  1.12s/it]Loading train:  20%|██        | 58/285 [01:08<04:11,  1.11s/it]Loading train:  21%|██        | 59/285 [01:10<04:23,  1.17s/it]Loading train:  21%|██        | 60/285 [01:11<04:24,  1.17s/it]Loading train:  21%|██▏       | 61/285 [01:12<04:12,  1.13s/it]Loading train:  22%|██▏       | 62/285 [01:13<04:20,  1.17s/it]Loading train:  22%|██▏       | 63/285 [01:14<04:20,  1.17s/it]Loading train:  22%|██▏       | 64/285 [01:16<04:42,  1.28s/it]Loading train:  23%|██▎       | 65/285 [01:18<05:04,  1.38s/it]Loading train:  23%|██▎       | 66/285 [01:19<04:54,  1.35s/it]Loading train:  24%|██▎       | 67/285 [01:20<04:42,  1.30s/it]Loading train:  24%|██▍       | 68/285 [01:21<04:31,  1.25s/it]Loading train:  24%|██▍       | 69/285 [01:22<04:17,  1.19s/it]Loading train:  25%|██▍       | 70/285 [01:23<04:16,  1.19s/it]Loading train:  25%|██▍       | 71/285 [01:25<04:15,  1.19s/it]Loading train:  25%|██▌       | 72/285 [01:26<04:06,  1.16s/it]Loading train:  26%|██▌       | 73/285 [01:27<04:01,  1.14s/it]Loading train:  26%|██▌       | 74/285 [01:28<04:10,  1.19s/it]Loading train:  26%|██▋       | 75/285 [01:29<04:12,  1.20s/it]Loading train:  27%|██▋       | 76/285 [01:30<04:02,  1.16s/it]Loading train:  27%|██▋       | 77/285 [01:32<04:06,  1.19s/it]Loading train:  27%|██▋       | 78/285 [01:33<04:01,  1.17s/it]Loading train:  28%|██▊       | 79/285 [01:34<03:49,  1.12s/it]Loading train:  28%|██▊       | 80/285 [01:35<03:54,  1.14s/it]Loading train:  28%|██▊       | 81/285 [01:36<03:48,  1.12s/it]Loading train:  29%|██▉       | 82/285 [01:37<04:08,  1.23s/it]Loading train:  29%|██▉       | 83/285 [01:39<04:02,  1.20s/it]Loading train:  29%|██▉       | 84/285 [01:39<03:43,  1.11s/it]Loading train:  30%|██▉       | 85/285 [01:40<03:32,  1.06s/it]Loading train:  30%|███       | 86/285 [01:42<03:47,  1.14s/it]Loading train:  31%|███       | 87/285 [01:43<03:47,  1.15s/it]Loading train:  31%|███       | 88/285 [01:44<03:42,  1.13s/it]Loading train:  31%|███       | 89/285 [01:45<03:44,  1.15s/it]Loading train:  32%|███▏      | 90/285 [01:46<03:44,  1.15s/it]Loading train:  32%|███▏      | 91/285 [01:47<03:23,  1.05s/it]Loading train:  32%|███▏      | 92/285 [01:48<03:28,  1.08s/it]Loading train:  33%|███▎      | 93/285 [01:50<03:36,  1.13s/it]Loading train:  33%|███▎      | 94/285 [01:51<03:40,  1.15s/it]Loading train:  33%|███▎      | 95/285 [01:52<03:42,  1.17s/it]Loading train:  34%|███▎      | 96/285 [01:53<03:45,  1.19s/it]Loading train:  34%|███▍      | 97/285 [01:54<03:39,  1.17s/it]Loading train:  34%|███▍      | 98/285 [01:56<03:39,  1.18s/it]Loading train:  35%|███▍      | 99/285 [01:57<03:30,  1.13s/it]Loading train:  35%|███▌      | 100/285 [01:58<03:25,  1.11s/it]Loading train:  35%|███▌      | 101/285 [01:59<03:19,  1.08s/it]Loading train:  36%|███▌      | 102/285 [02:00<03:19,  1.09s/it]Loading train:  36%|███▌      | 103/285 [02:01<03:12,  1.06s/it]Loading train:  36%|███▋      | 104/285 [02:02<03:15,  1.08s/it]Loading train:  37%|███▋      | 105/285 [02:03<03:16,  1.09s/it]Loading train:  37%|███▋      | 106/285 [02:04<03:17,  1.10s/it]Loading train:  38%|███▊      | 107/285 [02:06<03:44,  1.26s/it]Loading train:  38%|███▊      | 108/285 [02:07<03:39,  1.24s/it]Loading train:  38%|███▊      | 109/285 [02:08<03:50,  1.31s/it]Loading train:  39%|███▊      | 110/285 [02:10<04:10,  1.43s/it]Loading train:  39%|███▉      | 111/285 [02:11<04:03,  1.40s/it]Loading train:  39%|███▉      | 112/285 [02:13<04:14,  1.47s/it]Loading train:  40%|███▉      | 113/285 [02:15<04:23,  1.53s/it]Loading train:  40%|████      | 114/285 [02:16<04:25,  1.55s/it]Loading train:  40%|████      | 115/285 [02:18<04:38,  1.64s/it]Loading train:  41%|████      | 116/285 [02:20<04:46,  1.70s/it]Loading train:  41%|████      | 117/285 [02:22<04:37,  1.65s/it]Loading train:  41%|████▏     | 118/285 [02:23<04:33,  1.64s/it]Loading train:  42%|████▏     | 119/285 [02:25<04:45,  1.72s/it]Loading train:  42%|████▏     | 120/285 [02:27<04:35,  1.67s/it]Loading train:  42%|████▏     | 121/285 [02:28<04:32,  1.66s/it]Loading train:  43%|████▎     | 122/285 [02:30<04:38,  1.71s/it]Loading train:  43%|████▎     | 123/285 [02:32<04:44,  1.75s/it]Loading train:  44%|████▎     | 124/285 [02:34<04:48,  1.79s/it]Loading train:  44%|████▍     | 125/285 [02:35<04:39,  1.75s/it]Loading train:  44%|████▍     | 126/285 [02:37<04:22,  1.65s/it]Loading train:  45%|████▍     | 127/285 [02:38<04:12,  1.60s/it]Loading train:  45%|████▍     | 128/285 [02:40<04:10,  1.59s/it]Loading train:  45%|████▌     | 129/285 [02:41<03:48,  1.47s/it]Loading train:  46%|████▌     | 130/285 [02:43<03:50,  1.49s/it]Loading train:  46%|████▌     | 131/285 [02:44<03:30,  1.37s/it]Loading train:  46%|████▋     | 132/285 [02:45<03:25,  1.34s/it]Loading train:  47%|████▋     | 133/285 [02:46<03:24,  1.35s/it]Loading train:  47%|████▋     | 134/285 [02:47<03:06,  1.23s/it]Loading train:  47%|████▋     | 135/285 [02:49<03:02,  1.21s/it]Loading train:  48%|████▊     | 136/285 [02:50<03:05,  1.25s/it]Loading train:  48%|████▊     | 137/285 [02:51<03:12,  1.30s/it]Loading train:  48%|████▊     | 138/285 [02:53<03:20,  1.36s/it]Loading train:  49%|████▉     | 139/285 [02:54<03:29,  1.43s/it]Loading train:  49%|████▉     | 140/285 [02:56<03:31,  1.46s/it]Loading train:  49%|████▉     | 141/285 [02:57<03:31,  1.47s/it]Loading train:  50%|████▉     | 142/285 [02:59<03:17,  1.38s/it]Loading train:  50%|█████     | 143/285 [03:00<03:10,  1.34s/it]Loading train:  51%|█████     | 144/285 [03:01<03:18,  1.41s/it]Loading train:  51%|█████     | 145/285 [03:03<03:05,  1.32s/it]Loading train:  51%|█████     | 146/285 [03:04<03:01,  1.30s/it]Loading train:  52%|█████▏    | 147/285 [03:05<02:52,  1.25s/it]Loading train:  52%|█████▏    | 148/285 [03:06<02:49,  1.24s/it]Loading train:  52%|█████▏    | 149/285 [03:07<02:42,  1.20s/it]Loading train:  53%|█████▎    | 150/285 [03:09<02:47,  1.24s/it]Loading train:  53%|█████▎    | 151/285 [03:10<02:46,  1.25s/it]Loading train:  53%|█████▎    | 152/285 [03:11<02:46,  1.25s/it]Loading train:  54%|█████▎    | 153/285 [03:13<03:01,  1.37s/it]Loading train:  54%|█████▍    | 154/285 [03:14<03:11,  1.46s/it]Loading train:  54%|█████▍    | 155/285 [03:16<03:05,  1.43s/it]Loading train:  55%|█████▍    | 156/285 [03:17<03:00,  1.40s/it]Loading train:  55%|█████▌    | 157/285 [03:18<02:51,  1.34s/it]Loading train:  55%|█████▌    | 158/285 [03:19<02:45,  1.30s/it]Loading train:  56%|█████▌    | 159/285 [03:21<02:46,  1.32s/it]Loading train:  56%|█████▌    | 160/285 [03:22<02:43,  1.31s/it]Loading train:  56%|█████▋    | 161/285 [03:24<02:53,  1.40s/it]Loading train:  57%|█████▋    | 162/285 [03:25<02:45,  1.34s/it]Loading train:  57%|█████▋    | 163/285 [03:26<02:45,  1.35s/it]Loading train:  58%|█████▊    | 164/285 [03:28<02:43,  1.35s/it]Loading train:  58%|█████▊    | 165/285 [03:29<02:37,  1.32s/it]Loading train:  58%|█████▊    | 166/285 [03:30<02:38,  1.33s/it]Loading train:  59%|█████▊    | 167/285 [03:31<02:27,  1.25s/it]Loading train:  59%|█████▉    | 168/285 [03:33<02:25,  1.24s/it]Loading train:  59%|█████▉    | 169/285 [03:34<02:19,  1.20s/it]Loading train:  60%|█████▉    | 170/285 [03:35<02:28,  1.29s/it]Loading train:  60%|██████    | 171/285 [03:37<02:32,  1.34s/it]Loading train:  60%|██████    | 172/285 [03:39<02:53,  1.54s/it]Loading train:  61%|██████    | 173/285 [03:40<02:54,  1.56s/it]Loading train:  61%|██████    | 174/285 [03:42<02:53,  1.56s/it]Loading train:  61%|██████▏   | 175/285 [03:43<02:49,  1.54s/it]Loading train:  62%|██████▏   | 176/285 [03:45<02:51,  1.57s/it]Loading train:  62%|██████▏   | 177/285 [03:46<02:36,  1.45s/it]Loading train:  62%|██████▏   | 178/285 [03:47<02:21,  1.32s/it]Loading train:  63%|██████▎   | 179/285 [03:48<02:19,  1.31s/it]Loading train:  63%|██████▎   | 180/285 [03:50<02:24,  1.37s/it]Loading train:  64%|██████▎   | 181/285 [03:52<02:32,  1.46s/it]Loading train:  64%|██████▍   | 182/285 [03:53<02:22,  1.39s/it]Loading train:  64%|██████▍   | 183/285 [03:54<02:14,  1.32s/it]Loading train:  65%|██████▍   | 184/285 [03:55<02:09,  1.28s/it]Loading train:  65%|██████▍   | 185/285 [03:57<02:13,  1.33s/it]Loading train:  65%|██████▌   | 186/285 [03:58<02:16,  1.38s/it]Loading train:  66%|██████▌   | 187/285 [03:59<02:09,  1.32s/it]Loading train:  66%|██████▌   | 188/285 [04:01<02:09,  1.34s/it]Loading train:  66%|██████▋   | 189/285 [04:02<02:06,  1.32s/it]Loading train:  67%|██████▋   | 190/285 [04:03<02:06,  1.34s/it]Loading train:  67%|██████▋   | 191/285 [04:05<02:16,  1.45s/it]Loading train:  67%|██████▋   | 192/285 [04:06<02:13,  1.44s/it]Loading train:  68%|██████▊   | 193/285 [04:08<02:16,  1.49s/it]Loading train:  68%|██████▊   | 194/285 [04:09<02:12,  1.46s/it]Loading train:  68%|██████▊   | 195/285 [04:11<02:02,  1.36s/it]Loading train:  69%|██████▉   | 196/285 [04:12<02:07,  1.43s/it]Loading train:  69%|██████▉   | 197/285 [04:13<02:02,  1.39s/it]Loading train:  69%|██████▉   | 198/285 [04:15<02:08,  1.48s/it]Loading train:  70%|██████▉   | 199/285 [04:16<02:00,  1.40s/it]Loading train:  70%|███████   | 200/285 [04:18<01:55,  1.36s/it]Loading train:  71%|███████   | 201/285 [04:19<01:51,  1.33s/it]Loading train:  71%|███████   | 202/285 [04:20<01:45,  1.27s/it]Loading train:  71%|███████   | 203/285 [04:21<01:44,  1.27s/it]Loading train:  72%|███████▏  | 204/285 [04:22<01:40,  1.24s/it]Loading train:  72%|███████▏  | 205/285 [04:24<01:41,  1.27s/it]Loading train:  72%|███████▏  | 206/285 [04:25<01:42,  1.30s/it]Loading train:  73%|███████▎  | 207/285 [04:27<01:44,  1.34s/it]Loading train:  73%|███████▎  | 208/285 [04:28<01:44,  1.36s/it]Loading train:  73%|███████▎  | 209/285 [04:29<01:46,  1.40s/it]Loading train:  74%|███████▎  | 210/285 [04:31<01:41,  1.36s/it]Loading train:  74%|███████▍  | 211/285 [04:32<01:36,  1.30s/it]Loading train:  74%|███████▍  | 212/285 [04:34<01:42,  1.40s/it]Loading train:  75%|███████▍  | 213/285 [04:35<01:38,  1.36s/it]Loading train:  75%|███████▌  | 214/285 [04:36<01:29,  1.27s/it]Loading train:  75%|███████▌  | 215/285 [04:37<01:33,  1.33s/it]Loading train:  76%|███████▌  | 216/285 [04:39<01:32,  1.34s/it]Loading train:  76%|███████▌  | 217/285 [04:40<01:38,  1.45s/it]Loading train:  76%|███████▋  | 218/285 [04:42<01:41,  1.52s/it]Loading train:  77%|███████▋  | 219/285 [04:44<01:48,  1.64s/it]Loading train:  77%|███████▋  | 220/285 [04:46<01:44,  1.61s/it]Loading train:  78%|███████▊  | 221/285 [04:47<01:41,  1.59s/it]Loading train:  78%|███████▊  | 222/285 [04:49<01:37,  1.54s/it]Loading train:  78%|███████▊  | 223/285 [04:50<01:27,  1.41s/it]Loading train:  79%|███████▊  | 224/285 [04:51<01:21,  1.33s/it]Loading train:  79%|███████▉  | 225/285 [04:52<01:17,  1.29s/it]Loading train:  79%|███████▉  | 226/285 [04:53<01:19,  1.35s/it]Loading train:  80%|███████▉  | 227/285 [04:55<01:24,  1.46s/it]Loading train:  80%|████████  | 228/285 [04:57<01:23,  1.46s/it]Loading train:  80%|████████  | 229/285 [04:58<01:20,  1.44s/it]Loading train:  81%|████████  | 230/285 [04:59<01:14,  1.35s/it]Loading train:  81%|████████  | 231/285 [05:01<01:14,  1.37s/it]Loading train:  81%|████████▏ | 232/285 [05:02<01:13,  1.39s/it]Loading train:  82%|████████▏ | 233/285 [05:04<01:16,  1.48s/it]Loading train:  82%|████████▏ | 234/285 [05:06<01:22,  1.62s/it]Loading train:  82%|████████▏ | 235/285 [05:07<01:22,  1.66s/it]Loading train:  83%|████████▎ | 236/285 [05:09<01:20,  1.64s/it]Loading train:  83%|████████▎ | 237/285 [05:10<01:14,  1.55s/it]Loading train:  84%|████████▎ | 238/285 [05:12<01:14,  1.59s/it]Loading train:  84%|████████▍ | 239/285 [05:14<01:15,  1.63s/it]Loading train:  84%|████████▍ | 240/285 [05:15<01:12,  1.61s/it]Loading train:  85%|████████▍ | 241/285 [05:17<01:07,  1.54s/it]Loading train:  85%|████████▍ | 242/285 [05:18<01:05,  1.52s/it]Loading train:  85%|████████▌ | 243/285 [05:19<00:59,  1.41s/it]Loading train:  86%|████████▌ | 244/285 [05:21<01:00,  1.48s/it]Loading train:  86%|████████▌ | 245/285 [05:22<00:55,  1.39s/it]Loading train:  86%|████████▋ | 246/285 [05:24<00:54,  1.41s/it]Loading train:  87%|████████▋ | 247/285 [05:25<00:55,  1.47s/it]Loading train:  87%|████████▋ | 248/285 [05:26<00:52,  1.42s/it]Loading train:  87%|████████▋ | 249/285 [05:28<00:55,  1.55s/it]Loading train:  88%|████████▊ | 250/285 [05:30<00:54,  1.56s/it]Loading train:  88%|████████▊ | 251/285 [05:31<00:53,  1.56s/it]Loading train:  88%|████████▊ | 252/285 [05:33<00:48,  1.47s/it]Loading train:  89%|████████▉ | 253/285 [05:34<00:46,  1.44s/it]Loading train:  89%|████████▉ | 254/285 [05:36<00:47,  1.54s/it]Loading train:  89%|████████▉ | 255/285 [05:37<00:44,  1.50s/it]Loading train:  90%|████████▉ | 256/285 [05:39<00:41,  1.43s/it]Loading train:  90%|█████████ | 257/285 [05:40<00:38,  1.39s/it]Loading train:  91%|█████████ | 258/285 [05:41<00:38,  1.41s/it]Loading train:  91%|█████████ | 259/285 [05:43<00:37,  1.43s/it]Loading train:  91%|█████████ | 260/285 [05:44<00:33,  1.36s/it]Loading train:  92%|█████████▏| 261/285 [05:45<00:32,  1.34s/it]Loading train:  92%|█████████▏| 262/285 [05:46<00:29,  1.27s/it]Loading train:  92%|█████████▏| 263/285 [05:48<00:28,  1.29s/it]Loading train:  93%|█████████▎| 264/285 [05:49<00:28,  1.37s/it]Loading train:  93%|█████████▎| 265/285 [05:51<00:30,  1.50s/it]Loading train:  93%|█████████▎| 266/285 [05:52<00:27,  1.43s/it]Loading train:  94%|█████████▎| 267/285 [05:54<00:25,  1.42s/it]Loading train:  94%|█████████▍| 268/285 [05:55<00:25,  1.50s/it]Loading train:  94%|█████████▍| 269/285 [05:57<00:23,  1.46s/it]Loading train:  95%|█████████▍| 270/285 [05:58<00:21,  1.43s/it]Loading train:  95%|█████████▌| 271/285 [06:00<00:19,  1.41s/it]Loading train:  95%|█████████▌| 272/285 [06:01<00:18,  1.43s/it]Loading train:  96%|█████████▌| 273/285 [06:02<00:16,  1.40s/it]Loading train:  96%|█████████▌| 274/285 [06:04<00:16,  1.50s/it]Loading train:  96%|█████████▋| 275/285 [06:06<00:14,  1.49s/it]Loading train:  97%|█████████▋| 276/285 [06:07<00:14,  1.62s/it]Loading train:  97%|█████████▋| 277/285 [06:09<00:11,  1.45s/it]Loading train:  98%|█████████▊| 278/285 [06:10<00:09,  1.41s/it]Loading train:  98%|█████████▊| 279/285 [06:11<00:08,  1.39s/it]Loading train:  98%|█████████▊| 280/285 [06:12<00:06,  1.35s/it]Loading train:  99%|█████████▊| 281/285 [06:14<00:05,  1.33s/it]Loading train:  99%|█████████▉| 282/285 [06:15<00:03,  1.31s/it]Loading train:  99%|█████████▉| 283/285 [06:17<00:02,  1.41s/it]Loading train: 100%|█████████▉| 284/285 [06:18<00:01,  1.48s/it]Loading train: 100%|██████████| 285/285 [06:20<00:00,  1.49s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   4%|▍         | 11/285 [00:00<00:02, 105.79it/s]concatenating: train:   6%|▌         | 17/285 [00:00<00:03, 83.27it/s] concatenating: train:   7%|▋         | 21/285 [00:00<00:06, 38.29it/s]concatenating: train:   9%|▉         | 25/285 [00:00<00:07, 34.34it/s]concatenating: train:  10%|█         | 29/285 [00:00<00:08, 31.21it/s]concatenating: train:  11%|█         | 32/285 [00:00<00:08, 30.41it/s]concatenating: train:  12%|█▏        | 35/285 [00:01<00:09, 26.20it/s]concatenating: train:  14%|█▎        | 39/285 [00:01<00:08, 28.59it/s]concatenating: train:  15%|█▍        | 42/285 [00:01<00:09, 25.85it/s]concatenating: train:  16%|█▌        | 45/285 [00:01<00:10, 23.66it/s]concatenating: train:  17%|█▋        | 48/285 [00:01<00:09, 25.01it/s]concatenating: train:  19%|█▉        | 55/285 [00:01<00:07, 30.50it/s]concatenating: train:  21%|██▏       | 61/285 [00:01<00:06, 35.03it/s]concatenating: train:  23%|██▎       | 66/285 [00:01<00:05, 37.07it/s]concatenating: train:  26%|██▌       | 74/285 [00:01<00:04, 43.89it/s]concatenating: train:  29%|██▉       | 83/285 [00:02<00:03, 51.51it/s]concatenating: train:  34%|███▎      | 96/285 [00:02<00:03, 62.54it/s]concatenating: train:  37%|███▋      | 105/285 [00:02<00:02, 63.12it/s]concatenating: train:  40%|███▉      | 113/285 [00:02<00:02, 65.94it/s]concatenating: train:  42%|████▏     | 121/285 [00:02<00:03, 53.50it/s]concatenating: train:  45%|████▍     | 128/285 [00:02<00:03, 46.92it/s]concatenating: train:  47%|████▋     | 134/285 [00:02<00:03, 45.99it/s]concatenating: train:  49%|████▉     | 141/285 [00:03<00:02, 50.00it/s]concatenating: train:  52%|█████▏    | 147/285 [00:03<00:02, 50.51it/s]concatenating: train:  54%|█████▎    | 153/285 [00:03<00:02, 48.98it/s]concatenating: train:  57%|█████▋    | 163/285 [00:03<00:02, 57.31it/s]concatenating: train:  60%|█████▉    | 170/285 [00:03<00:02, 50.73it/s]concatenating: train:  70%|██████▉   | 199/285 [00:03<00:01, 67.37it/s]concatenating: train:  76%|███████▋  | 218/285 [00:03<00:00, 81.87it/s]concatenating: train:  81%|████████▏ | 232/285 [00:04<00:00, 71.25it/s]concatenating: train:  86%|████████▌ | 244/285 [00:04<00:00, 57.39it/s]concatenating: train:  89%|████████▉ | 254/285 [00:04<00:00, 54.23it/s]concatenating: train:  92%|█████████▏| 262/285 [00:04<00:00, 50.49it/s]concatenating: train:  94%|█████████▍| 269/285 [00:05<00:00, 37.19it/s]concatenating: train:  97%|█████████▋| 276/285 [00:05<00:00, 43.24it/s]concatenating: train: 100%|██████████| 285/285 [00:05<00:00, 51.22it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.80s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.71s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.60s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 35.04it/s]2019-07-11 05:06:49.264701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 05:06:49.264818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 05:06:49.264834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 05:06:49.264843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 05:06:49.265277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:10,  4.26it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:08,  5.11it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:09,  4.29it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:06,  5.61it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.29it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  5.85it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.35it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  6.92it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  7.30it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.05it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.62it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  8.12it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  7.79it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:03<00:02,  5.73it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:02,  4.85it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:04<00:01,  6.19it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:01,  6.81it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:04<00:01,  5.67it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:04<00:00,  5.90it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:05<00:00,  5.32it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:05<00:00,  8.64it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 26, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 13, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 26, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   10820       dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 52, 20)   0           activation_11[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 20)   3620        dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 52, 20)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 80)   0           dropout_5[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 52, 13)   1053        concatenate_7[0][0]              
==================================================================================================
Total params: 238,693
Trainable params: 63,933
Non-trainable params: 174,760
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 23s - loss: 1.8383 - acc: 0.7860 - mDice: 0.2453 - val_loss: 1.7519 - val_acc: 0.9225 - val_mDice: 0.2609

Epoch 00001: val_mDice improved from -inf to 0.26085, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 17s - loss: 0.5682 - acc: 0.9285 - mDice: 0.5530 - val_loss: 0.5080 - val_acc: 0.9488 - val_mDice: 0.5990

Epoch 00002: val_mDice improved from 0.26085 to 0.59897, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 16s - loss: 0.4415 - acc: 0.9403 - mDice: 0.6287 - val_loss: 0.4997 - val_acc: 0.9525 - val_mDice: 0.6061

Epoch 00003: val_mDice improved from 0.59897 to 0.60607, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 14s - loss: 0.4015 - acc: 0.9444 - mDice: 0.6550 - val_loss: 0.4701 - val_acc: 0.9529 - val_mDice: 0.6237

Epoch 00004: val_mDice improved from 0.60607 to 0.62369, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 13s - loss: 0.3765 - acc: 0.9465 - mDice: 0.6722 - val_loss: 0.4684 - val_acc: 0.9529 - val_mDice: 0.6290

Epoch 00005: val_mDice improved from 0.62369 to 0.62902, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 13s - loss: 0.3584 - acc: 0.9478 - mDice: 0.6844 - val_loss: 0.5380 - val_acc: 0.9538 - val_mDice: 0.6117

Epoch 00006: val_mDice did not improve from 0.62902
Epoch 7/300
 - 14s - loss: 0.3449 - acc: 0.9489 - mDice: 0.6942 - val_loss: 0.5384 - val_acc: 0.9541 - val_mDice: 0.6090

Epoch 00007: val_mDice did not improve from 0.62902
Epoch 8/300
 - 13s - loss: 0.3372 - acc: 0.9495 - mDice: 0.6997 - val_loss: 0.5899 - val_acc: 0.9536 - val_mDice: 0.6041

Epoch 00008: val_mDice did not improve from 0.62902
Epoch 9/300
 - 13s - loss: 0.3287 - acc: 0.9501 - mDice: 0.7060 - val_loss: 0.4949 - val_acc: 0.9545 - val_mDice: 0.6248

Epoch 00009: val_mDice did not improve from 0.62902
Epoch 10/300
 - 13s - loss: 0.3220 - acc: 0.9507 - mDice: 0.7108 - val_loss: 0.5499 - val_acc: 0.9520 - val_mDice: 0.5961

Epoch 00010: val_mDice did not improve from 0.62902
Epoch 11/300
 - 13s - loss: 0.3156 - acc: 0.9512 - mDice: 0.7157 - val_loss: 0.5168 - val_acc: 0.9549 - val_mDice: 0.6189

Epoch 00011: val_mDice did not improve from 0.62902
Epoch 12/300
 - 13s - loss: 0.3130 - acc: 0.9517 - mDice: 0.7200 - val_loss: 0.6718 - val_acc: 0.9506 - val_mDice: 0.5667

Epoch 00012: val_mDice did not improve from 0.62902
Epoch 13/300
 - 13s - loss: 0.3076 - acc: 0.9517 - mDice: 0.7215 - val_loss: 0.5424 - val_acc: 0.9548 - val_mDice: 0.6149

Epoch 00013: val_mDice did not improve from 0.62902
Epoch 14/300
 - 13s - loss: 0.3013 - acc: 0.9523 - mDice: 0.7263 - val_loss: 0.6109 - val_acc: 0.9543 - val_mDice: 0.6169

Epoch 00014: val_mDice did not improve from 0.62902
Epoch 15/300
 - 13s - loss: 0.2960 - acc: 0.9527 - mDice: 0.7302 - val_loss: 0.4859 - val_acc: 0.9545 - val_mDice: 0.6185

Epoch 00015: val_mDice did not improve from 0.62902
Epoch 16/300
 - 13s - loss: 0.2959 - acc: 0.9527 - mDice: 0.7305 - val_loss: 0.4527 - val_acc: 0.9559 - val_mDice: 0.6349

Epoch 00016: val_mDice improved from 0.62902 to 0.63492, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 13s - loss: 0.2873 - acc: 0.9532 - mDice: 0.7368 - val_loss: 0.4931 - val_acc: 0.9537 - val_mDice: 0.6189

Epoch 00017: val_mDice did not improve from 0.63492
Epoch 18/300
 - 13s - loss: 0.2859 - acc: 0.9533 - mDice: 0.7379 - val_loss: 0.4612 - val_acc: 0.9538 - val_mDice: 0.6252

Epoch 00018: val_mDice did not improve from 0.63492
Epoch 19/300
 - 13s - loss: 0.2817 - acc: 0.9537 - mDice: 0.7411 - val_loss: 0.4845 - val_acc: 0.9535 - val_mDice: 0.6177

Epoch 00019: val_mDice did not improve from 0.63492
Epoch 20/300
 - 13s - loss: 0.2809 - acc: 0.9537 - mDice: 0.7419 - val_loss: 0.4781 - val_acc: 0.9531 - val_mDice: 0.6166

Epoch 00020: val_mDice did not improve from 0.63492
Epoch 21/300
 - 13s - loss: 0.2772 - acc: 0.9540 - mDice: 0.7447 - val_loss: 0.4504 - val_acc: 0.9541 - val_mDice: 0.6298

Epoch 00021: val_mDice did not improve from 0.63492
Epoch 22/300
 - 13s - loss: 0.2744 - acc: 0.9541 - mDice: 0.7468 - val_loss: 0.4711 - val_acc: 0.9526 - val_mDice: 0.6139

Epoch 00022: val_mDice did not improve from 0.63492
Epoch 23/300
 - 13s - loss: 0.2726 - acc: 0.9543 - mDice: 0.7482 - val_loss: 0.5036 - val_acc: 0.9547 - val_mDice: 0.6164

Epoch 00023: val_mDice did not improve from 0.63492
Epoch 24/300
 - 13s - loss: 0.2732 - acc: 0.9543 - mDice: 0.7481 - val_loss: 0.4933 - val_acc: 0.9539 - val_mDice: 0.6133

Epoch 00024: val_mDice did not improve from 0.63492
Epoch 25/300
 - 14s - loss: 0.2676 - acc: 0.9547 - mDice: 0.7521 - val_loss: 0.6467 - val_acc: 0.9554 - val_mDice: 0.6103

Epoch 00025: val_mDice did not improve from 0.63492
Epoch 26/300
 - 13s - loss: 0.2675 - acc: 0.9548 - mDice: 0.7523 - val_loss: 0.4594 - val_acc: 0.9536 - val_mDice: 0.6245

Epoch 00026: val_mDice did not improve from 0.63492
Epoch 27/300
 - 13s - loss: 0.2654 - acc: 0.9549 - mDice: 0.7540 - val_loss: 0.4605 - val_acc: 0.9526 - val_mDice: 0.6216

Epoch 00027: val_mDice did not improve from 0.63492
Epoch 28/300
 - 13s - loss: 0.2629 - acc: 0.9551 - mDice: 0.7559 - val_loss: 0.4512 - val_acc: 0.9549 - val_mDice: 0.6304

Epoch 00028: val_mDice did not improve from 0.63492
Epoch 29/300
 - 13s - loss: 0.2611 - acc: 0.9552 - mDice: 0.7573 - val_loss: 0.4492 - val_acc: 0.9537 - val_mDice: 0.6302

Epoch 00029: val_mDice did not improve from 0.63492
Epoch 30/300
 - 13s - loss: 0.2593 - acc: 0.9553 - mDice: 0.7587 - val_loss: 0.4775 - val_acc: 0.9548 - val_mDice: 0.6180

Epoch 00030: val_mDice did not improve from 0.63492
Epoch 31/300
 - 13s - loss: 0.2580 - acc: 0.9554 - mDice: 0.7598 - val_loss: 0.4600 - val_acc: 0.9557 - val_mDice: 0.6307

Epoch 00031: val_mDice did not improve from 0.63492
Epoch 32/300
 - 13s - loss: 0.2590 - acc: 0.9554 - mDice: 0.7591 - val_loss: 0.4514 - val_acc: 0.9550 - val_mDice: 0.6310

Epoch 00032: val_mDice did not improve from 0.63492
Epoch 33/300
 - 13s - loss: 0.2573 - acc: 0.9556 - mDice: 0.7604 - val_loss: 0.5007 - val_acc: 0.9545 - val_mDice: 0.6144

Epoch 00033: val_mDice did not improve from 0.63492
Epoch 34/300
 - 13s - loss: 0.2550 - acc: 0.9556 - mDice: 0.7621 - val_loss: 0.4878 - val_acc: 0.9543 - val_mDice: 0.6117

Epoch 00034: val_mDice did not improve from 0.63492
Epoch 35/300
 - 14s - loss: 0.2547 - acc: 0.9556 - mDice: 0.7624 - val_loss: 0.5041 - val_acc: 0.9533 - val_mDice: 0.6110

Epoch 00035: val_mDice did not improve from 0.63492
Epoch 36/300
 - 13s - loss: 0.2530 - acc: 0.9559 - mDice: 0.7638 - val_loss: 0.5094 - val_acc: 0.9547 - val_mDice: 0.6044

Epoch 00036: val_mDice did not improve from 0.63492
Epoch 37/300
 - 13s - loss: 0.2514 - acc: 0.9559 - mDice: 0.7651 - val_loss: 0.6417 - val_acc: 0.9527 - val_mDice: 0.5825

Epoch 00037: val_mDice did not improve from 0.63492
Epoch 38/300
 - 13s - loss: 0.2501 - acc: 0.9560 - mDice: 0.7661 - val_loss: 0.5556 - val_acc: 0.9552 - val_mDice: 0.6052

Epoch 00038: val_mDice did not improve from 0.63492
Epoch 39/300
 - 14s - loss: 0.2487 - acc: 0.9561 - mDice: 0.7672 - val_loss: 0.4636 - val_acc: 0.9550 - val_mDice: 0.6228

Epoch 00039: val_mDice did not improve from 0.63492
Epoch 40/300
 - 13s - loss: 0.2470 - acc: 0.9562 - mDice: 0.7685 - val_loss: 0.4653 - val_acc: 0.9543 - val_mDice: 0.6209

Epoch 00040: val_mDice did not improve from 0.63492
Epoch 41/300
 - 13s - loss: 0.2471 - acc: 0.9562 - mDice: 0.7685 - val_loss: 0.4633 - val_acc: 0.9546 - val_mDice: 0.6245

Epoch 00041: val_mDice did not improve from 0.63492
Epoch 42/300
 - 14s - loss: 0.2472 - acc: 0.9562 - mDice: 0.7684 - val_loss: 0.5131 - val_acc: 0.9545 - val_mDice: 0.6060

Epoch 00042: val_mDice did not improve from 0.63492
Epoch 43/300
 - 13s - loss: 0.2448 - acc: 0.9564 - mDice: 0.7703 - val_loss: 0.4912 - val_acc: 0.9546 - val_mDice: 0.6162

Epoch 00043: val_mDice did not improve from 0.63492
Epoch 44/300
 - 14s - loss: 0.2458 - acc: 0.9563 - mDice: 0.7695 - val_loss: 0.4460 - val_acc: 0.9541 - val_mDice: 0.6305

Epoch 00044: val_mDice did not improve from 0.63492
Epoch 45/300
 - 13s - loss: 0.2439 - acc: 0.9565 - mDice: 0.7712 - val_loss: 0.5022 - val_acc: 0.9549 - val_mDice: 0.6099

Epoch 00045: val_mDice did not improve from 0.63492
Epoch 46/300
 - 13s - loss: 0.2425 - acc: 0.9565 - mDice: 0.7723 - val_loss: 0.4796 - val_acc: 0.9543 - val_mDice: 0.6181

Epoch 00046: val_mDice did not improve from 0.63492
Epoch 47/300
 - 13s - loss: 0.2426 - acc: 0.9565 - mDice: 0.7722 - val_loss: 0.4536 - val_acc: 0.9537 - val_mDice: 0.6279

Epoch 00047: val_mDice did not improve from 0.63492
Epoch 48/300
 - 14s - loss: 0.2410 - acc: 0.9567 - mDice: 0.7735 - val_loss: 0.4610 - val_acc: 0.9550 - val_mDice: 0.6216

Epoch 00048: val_mDice did not improve from 0.63492
Epoch 49/300
 - 13s - loss: 0.2402 - acc: 0.9568 - mDice: 0.7741 - val_loss: 0.4689 - val_acc: 0.9537 - val_mDice: 0.6180

Epoch 00049: val_mDice did not improve from 0.63492
Epoch 50/300
 - 14s - loss: 0.2403 - acc: 0.9568 - mDice: 0.7740 - val_loss: 0.4692 - val_acc: 0.9540 - val_mDice: 0.6210

Epoch 00050: val_mDice did not improve from 0.63492
Epoch 51/300
 - 13s - loss: 0.2386 - acc: 0.9569 - mDice: 0.7754 - val_loss: 0.5370 - val_acc: 0.9537 - val_mDice: 0.6003

Epoch 00051: val_mDice did not improve from 0.63492
Epoch 52/300
 - 14s - loss: 0.2379 - acc: 0.9569 - mDice: 0.7760 - val_loss: 0.4630 - val_acc: 0.9523 - val_mDice: 0.6233

Epoch 00052: val_mDice did not improve from 0.63492
Epoch 53/300
 - 13s - loss: 0.2373 - acc: 0.9569 - mDice: 0.7764 - val_loss: 0.4757 - val_acc: 0.9548 - val_mDice: 0.6179

Epoch 00053: val_mDice did not improve from 0.63492
Epoch 54/300
 - 14s - loss: 0.2376 - acc: 0.9569 - mDice: 0.7762 - val_loss: 0.5143 - val_acc: 0.9539 - val_mDice: 0.6069

Epoch 00054: val_mDice did not improve from 0.63492
Epoch 55/300
 - 13s - loss: 0.2364 - acc: 0.9570 - mDice: 0.7772 - val_loss: 0.4658 - val_acc: 0.9546 - val_mDice: 0.6243

Epoch 00055: val_mDice did not improve from 0.63492
Epoch 56/300
 - 13s - loss: 0.2364 - acc: 0.9570 - mDice: 0.7772 - val_loss: 0.4862 - val_acc: 0.9544 - val_mDice: 0.6196

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.37s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.11s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.90s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:02<09:28,  2.00s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:38,  1.83s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:28,  1.80s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<08:05,  1.73s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:17,  1.78s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<07:46,  1.67s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<08:03,  1.74s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:53,  1.71s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:29,  1.85s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:53,  1.94s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:36,  1.88s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:53,  1.95s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:27,  1.87s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<08:29,  1.88s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:49,  1.96s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<09:02,  2.02s/it]predicting train subjects:   6%|▌         | 17/285 [00:31<08:38,  1.94s/it]predicting train subjects:   6%|▋         | 18/285 [00:33<08:29,  1.91s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<08:11,  1.85s/it]predicting train subjects:   7%|▋         | 20/285 [00:36<08:09,  1.85s/it]predicting train subjects:   7%|▋         | 21/285 [00:38<08:27,  1.92s/it]predicting train subjects:   8%|▊         | 22/285 [00:40<08:05,  1.84s/it]predicting train subjects:   8%|▊         | 23/285 [00:42<08:00,  1.83s/it]predicting train subjects:   8%|▊         | 24/285 [00:44<07:46,  1.79s/it]predicting train subjects:   9%|▉         | 25/285 [00:46<08:05,  1.87s/it]predicting train subjects:   9%|▉         | 26/285 [00:48<08:17,  1.92s/it]predicting train subjects:   9%|▉         | 27/285 [00:49<07:54,  1.84s/it]predicting train subjects:  10%|▉         | 28/285 [00:51<07:58,  1.86s/it]predicting train subjects:  10%|█         | 29/285 [00:53<07:51,  1.84s/it]predicting train subjects:  11%|█         | 30/285 [00:55<08:15,  1.94s/it]predicting train subjects:  11%|█         | 31/285 [00:57<08:24,  1.99s/it]predicting train subjects:  11%|█         | 32/285 [00:59<08:07,  1.93s/it]predicting train subjects:  12%|█▏        | 33/285 [01:01<08:20,  1.99s/it]predicting train subjects:  12%|█▏        | 34/285 [01:03<08:05,  1.94s/it]predicting train subjects:  12%|█▏        | 35/285 [01:05<08:12,  1.97s/it]predicting train subjects:  13%|█▎        | 36/285 [01:07<07:49,  1.88s/it]predicting train subjects:  13%|█▎        | 37/285 [01:09<07:46,  1.88s/it]predicting train subjects:  13%|█▎        | 38/285 [01:11<07:54,  1.92s/it]predicting train subjects:  14%|█▎        | 39/285 [01:12<07:34,  1.85s/it]predicting train subjects:  14%|█▍        | 40/285 [01:14<07:35,  1.86s/it]predicting train subjects:  14%|█▍        | 41/285 [01:16<07:18,  1.80s/it]predicting train subjects:  15%|█▍        | 42/285 [01:17<07:02,  1.74s/it]predicting train subjects:  15%|█▌        | 43/285 [01:19<07:07,  1.77s/it]predicting train subjects:  15%|█▌        | 44/285 [01:21<07:33,  1.88s/it]predicting train subjects:  16%|█▌        | 45/285 [01:23<07:19,  1.83s/it]predicting train subjects:  16%|█▌        | 46/285 [01:25<07:37,  1.92s/it]predicting train subjects:  16%|█▋        | 47/285 [01:27<07:20,  1.85s/it]predicting train subjects:  17%|█▋        | 48/285 [01:29<07:25,  1.88s/it]predicting train subjects:  17%|█▋        | 49/285 [01:31<07:46,  1.97s/it]predicting train subjects:  18%|█▊        | 50/285 [01:33<07:38,  1.95s/it]predicting train subjects:  18%|█▊        | 51/285 [01:35<07:56,  2.03s/it]predicting train subjects:  18%|█▊        | 52/285 [01:37<07:26,  1.92s/it]predicting train subjects:  19%|█▊        | 53/285 [01:39<07:22,  1.91s/it]predicting train subjects:  19%|█▉        | 54/285 [01:41<07:36,  1.98s/it]predicting train subjects:  19%|█▉        | 55/285 [01:43<07:14,  1.89s/it]predicting train subjects:  20%|█▉        | 56/285 [01:44<07:11,  1.89s/it]predicting train subjects:  20%|██        | 57/285 [01:46<06:53,  1.81s/it]predicting train subjects:  20%|██        | 58/285 [01:48<06:59,  1.85s/it]predicting train subjects:  21%|██        | 59/285 [01:50<07:15,  1.93s/it]predicting train subjects:  21%|██        | 60/285 [01:52<07:26,  1.99s/it]predicting train subjects:  21%|██▏       | 61/285 [01:54<07:02,  1.89s/it]predicting train subjects:  22%|██▏       | 62/285 [01:56<07:06,  1.91s/it]predicting train subjects:  22%|██▏       | 63/285 [01:58<07:04,  1.91s/it]predicting train subjects:  22%|██▏       | 64/285 [01:59<06:49,  1.85s/it]predicting train subjects:  23%|██▎       | 65/285 [02:01<06:50,  1.87s/it]predicting train subjects:  23%|██▎       | 66/285 [02:03<06:51,  1.88s/it]predicting train subjects:  24%|██▎       | 67/285 [02:05<06:51,  1.89s/it]predicting train subjects:  24%|██▍       | 68/285 [02:07<06:37,  1.83s/it]predicting train subjects:  24%|██▍       | 69/285 [02:09<06:44,  1.87s/it]predicting train subjects:  25%|██▍       | 70/285 [02:11<06:45,  1.89s/it]predicting train subjects:  25%|██▍       | 71/285 [02:13<06:46,  1.90s/it]predicting train subjects:  25%|██▌       | 72/285 [02:14<06:35,  1.86s/it]predicting train subjects:  26%|██▌       | 73/285 [02:16<06:39,  1.88s/it]predicting train subjects:  26%|██▌       | 74/285 [02:18<06:39,  1.90s/it]predicting train subjects:  26%|██▋       | 75/285 [02:20<06:43,  1.92s/it]predicting train subjects:  27%|██▋       | 76/285 [02:22<06:39,  1.91s/it]predicting train subjects:  27%|██▋       | 77/285 [02:24<06:29,  1.87s/it]predicting train subjects:  27%|██▋       | 78/285 [02:26<06:17,  1.82s/it]predicting train subjects:  28%|██▊       | 79/285 [02:28<06:18,  1.84s/it]predicting train subjects:  28%|██▊       | 80/285 [02:29<06:19,  1.85s/it]predicting train subjects:  28%|██▊       | 81/285 [02:31<06:17,  1.85s/it]predicting train subjects:  29%|██▉       | 82/285 [02:33<06:12,  1.84s/it]predicting train subjects:  29%|██▉       | 83/285 [02:35<06:09,  1.83s/it]predicting train subjects:  29%|██▉       | 84/285 [02:37<06:00,  1.79s/it]predicting train subjects:  30%|██▉       | 85/285 [02:38<06:01,  1.81s/it]predicting train subjects:  30%|███       | 86/285 [02:40<06:03,  1.83s/it]predicting train subjects:  31%|███       | 87/285 [02:42<06:05,  1.85s/it]predicting train subjects:  31%|███       | 88/285 [02:44<05:59,  1.82s/it]predicting train subjects:  31%|███       | 89/285 [02:46<06:04,  1.86s/it]predicting train subjects:  32%|███▏      | 90/285 [02:48<06:02,  1.86s/it]predicting train subjects:  32%|███▏      | 91/285 [02:49<05:50,  1.81s/it]predicting train subjects:  32%|███▏      | 92/285 [02:51<05:49,  1.81s/it]predicting train subjects:  33%|███▎      | 93/285 [02:53<05:44,  1.79s/it]predicting train subjects:  33%|███▎      | 94/285 [02:55<05:48,  1.83s/it]predicting train subjects:  33%|███▎      | 95/285 [02:57<05:49,  1.84s/it]predicting train subjects:  34%|███▎      | 96/285 [02:59<05:56,  1.89s/it]predicting train subjects:  34%|███▍      | 97/285 [03:01<05:54,  1.89s/it]predicting train subjects:  34%|███▍      | 98/285 [03:03<05:58,  1.92s/it]predicting train subjects:  35%|███▍      | 99/285 [03:05<05:52,  1.90s/it]predicting train subjects:  35%|███▌      | 100/285 [03:06<05:51,  1.90s/it]predicting train subjects:  35%|███▌      | 101/285 [03:08<05:42,  1.86s/it]predicting train subjects:  36%|███▌      | 102/285 [03:10<05:41,  1.87s/it]predicting train subjects:  36%|███▌      | 103/285 [03:12<05:29,  1.81s/it]predicting train subjects:  36%|███▋      | 104/285 [03:14<05:39,  1.87s/it]predicting train subjects:  37%|███▋      | 105/285 [03:16<05:37,  1.88s/it]predicting train subjects:  37%|███▋      | 106/285 [03:17<05:29,  1.84s/it]predicting train subjects:  38%|███▊      | 107/285 [03:19<05:31,  1.86s/it]predicting train subjects:  38%|███▊      | 108/285 [03:21<05:26,  1.85s/it]predicting train subjects:  38%|███▊      | 109/285 [03:23<05:25,  1.85s/it]predicting train subjects:  39%|███▊      | 110/285 [03:25<05:26,  1.87s/it]predicting train subjects:  39%|███▉      | 111/285 [03:27<05:16,  1.82s/it]predicting train subjects:  39%|███▉      | 112/285 [03:29<05:19,  1.85s/it]predicting train subjects:  40%|███▉      | 113/285 [03:31<05:25,  1.89s/it]predicting train subjects:  40%|████      | 114/285 [03:32<05:19,  1.87s/it]predicting train subjects:  40%|████      | 115/285 [03:34<05:17,  1.87s/it]predicting train subjects:  41%|████      | 116/285 [03:36<05:19,  1.89s/it]predicting train subjects:  41%|████      | 117/285 [03:38<05:16,  1.88s/it]predicting train subjects:  41%|████▏     | 118/285 [03:40<05:11,  1.87s/it]predicting train subjects:  42%|████▏     | 119/285 [03:42<05:16,  1.91s/it]predicting train subjects:  42%|████▏     | 120/285 [03:44<05:06,  1.86s/it]predicting train subjects:  42%|████▏     | 121/285 [03:45<05:01,  1.84s/it]predicting train subjects:  43%|████▎     | 122/285 [03:47<04:45,  1.75s/it]predicting train subjects:  43%|████▎     | 123/285 [03:49<04:36,  1.71s/it]predicting train subjects:  44%|████▎     | 124/285 [03:50<04:33,  1.70s/it]predicting train subjects:  44%|████▍     | 125/285 [03:52<04:24,  1.65s/it]predicting train subjects:  44%|████▍     | 126/285 [03:53<04:17,  1.62s/it]predicting train subjects:  45%|████▍     | 127/285 [03:55<04:12,  1.60s/it]predicting train subjects:  45%|████▍     | 128/285 [03:57<04:15,  1.63s/it]predicting train subjects:  45%|████▌     | 129/285 [03:58<04:12,  1.62s/it]predicting train subjects:  46%|████▌     | 130/285 [04:00<04:05,  1.58s/it]predicting train subjects:  46%|████▌     | 131/285 [04:01<03:59,  1.55s/it]predicting train subjects:  46%|████▋     | 132/285 [04:03<04:02,  1.58s/it]predicting train subjects:  47%|████▋     | 133/285 [04:04<03:57,  1.56s/it]predicting train subjects:  47%|████▋     | 134/285 [04:06<03:56,  1.56s/it]predicting train subjects:  47%|████▋     | 135/285 [04:07<03:53,  1.56s/it]predicting train subjects:  48%|████▊     | 136/285 [04:09<03:52,  1.56s/it]predicting train subjects:  48%|████▊     | 137/285 [04:11<03:54,  1.58s/it]predicting train subjects:  48%|████▊     | 138/285 [04:12<03:47,  1.55s/it]predicting train subjects:  49%|████▉     | 139/285 [04:14<03:52,  1.59s/it]predicting train subjects:  49%|████▉     | 140/285 [04:15<03:53,  1.61s/it]predicting train subjects:  49%|████▉     | 141/285 [04:17<03:45,  1.57s/it]predicting train subjects:  50%|████▉     | 142/285 [04:19<03:47,  1.59s/it]predicting train subjects:  50%|█████     | 143/285 [04:20<03:45,  1.59s/it]predicting train subjects:  51%|█████     | 144/285 [04:22<03:52,  1.65s/it]predicting train subjects:  51%|█████     | 145/285 [04:24<03:50,  1.65s/it]predicting train subjects:  51%|█████     | 146/285 [04:25<03:50,  1.66s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:27<03:41,  1.60s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:28<03:42,  1.62s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:30<03:41,  1.63s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:32<03:37,  1.61s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:33<03:40,  1.65s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:35<03:30,  1.58s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:36<03:27,  1.57s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:38<03:29,  1.60s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:40<03:25,  1.58s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:41<03:27,  1.61s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:43<03:22,  1.58s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:44<03:23,  1.60s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:46<03:17,  1.57s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:47<03:16,  1.57s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:49<03:18,  1.60s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:51<03:12,  1.57s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:52<03:16,  1.61s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:54<03:10,  1.58s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:55<03:05,  1.55s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:57<03:07,  1.58s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:59<03:11,  1.62s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:00<03:06,  1.59s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:02<03:03,  1.58s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:03<02:58,  1.55s/it]predicting train subjects:  60%|██████    | 171/285 [05:05<02:55,  1.54s/it]predicting train subjects:  60%|██████    | 172/285 [05:06<02:58,  1.58s/it]predicting train subjects:  61%|██████    | 173/285 [05:08<02:52,  1.54s/it]predicting train subjects:  61%|██████    | 174/285 [05:09<02:50,  1.54s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:11<02:52,  1.57s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:13<02:55,  1.61s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:14<02:51,  1.58s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:16<02:50,  1.59s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:17<02:45,  1.56s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:19<02:55,  1.67s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:21<02:53,  1.67s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:23<02:52,  1.68s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:24<02:44,  1.61s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:26<02:39,  1.58s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:27<02:36,  1.57s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:29<02:47,  1.70s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:31<02:51,  1.75s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:33<02:51,  1.77s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:34<02:41,  1.69s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:36<02:33,  1.62s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:38<02:34,  1.65s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:39<02:33,  1.65s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:41<02:26,  1.59s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:42<02:23,  1.58s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:44<02:18,  1.54s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:46<02:32,  1.71s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:48<02:45,  1.88s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:50<02:49,  1.95s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:52<02:37,  1.83s/it]predicting train subjects:  70%|███████   | 200/285 [05:53<02:32,  1.79s/it]predicting train subjects:  71%|███████   | 201/285 [05:56<02:39,  1.90s/it]predicting train subjects:  71%|███████   | 202/285 [05:58<02:39,  1.92s/it]predicting train subjects:  71%|███████   | 203/285 [05:59<02:35,  1.89s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:01<02:25,  1.80s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:03<02:19,  1.75s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:04<02:17,  1.74s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:06<02:22,  1.83s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:08<02:22,  1.85s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:10<02:23,  1.89s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:12<02:14,  1.79s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:13<02:08,  1.74s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:15<02:12,  1.81s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:17<02:16,  1.90s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:19<02:10,  1.83s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:21<02:16,  1.95s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:23<02:09,  1.88s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:25<02:13,  1.97s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:27<02:14,  2.01s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:29<02:13,  2.02s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:31<02:04,  1.92s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:33<01:57,  1.83s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:35<01:57,  1.87s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:36<01:52,  1.81s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:38<01:49,  1.79s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:40<01:44,  1.74s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:42<01:49,  1.85s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:44<01:53,  1.97s/it]predicting train subjects:  80%|████████  | 228/285 [06:46<01:51,  1.96s/it]predicting train subjects:  80%|████████  | 229/285 [06:48<01:47,  1.92s/it]predicting train subjects:  81%|████████  | 230/285 [06:50<01:43,  1.88s/it]predicting train subjects:  81%|████████  | 231/285 [06:51<01:39,  1.85s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:53<01:38,  1.87s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:55<01:35,  1.83s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:57<01:37,  1.91s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:59<01:36,  1.92s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:01<01:39,  2.03s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:04<01:39,  2.07s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:06<01:38,  2.10s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:08<01:34,  2.06s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:09<01:26,  1.92s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:11<01:21,  1.86s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:13<01:16,  1.77s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:14<01:13,  1.76s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:16<01:15,  1.85s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:18<01:09,  1.73s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:20<01:11,  1.83s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:22<01:13,  1.93s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:24<01:09,  1.88s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:26<01:06,  1.85s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:27<01:03,  1.83s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:29<01:00,  1.77s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:31<00:57,  1.75s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:33<01:00,  1.90s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:35<01:00,  1.97s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:37<00:59,  1.97s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:39<00:54,  1.89s/it]predicting train subjects:  90%|█████████ | 257/285 [07:40<00:50,  1.81s/it]predicting train subjects:  91%|█████████ | 258/285 [07:42<00:51,  1.90s/it]predicting train subjects:  91%|█████████ | 259/285 [07:44<00:49,  1.89s/it]predicting train subjects:  91%|█████████ | 260/285 [07:46<00:46,  1.87s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:48<00:44,  1.84s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:49<00:40,  1.74s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:51<00:37,  1.72s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:53<00:39,  1.89s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:55<00:39,  1.96s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:57<00:35,  1.85s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:59<00:32,  1.82s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:01<00:32,  1.91s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:03<00:30,  1.92s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:05<00:27,  1.86s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:06<00:26,  1.87s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:08<00:24,  1.90s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:10<00:22,  1.84s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:12<00:19,  1.79s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:14<00:19,  1.94s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:16<00:18,  2.01s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:18<00:15,  1.96s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:20<00:13,  1.88s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:22<00:11,  1.92s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:24<00:09,  1.92s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:26<00:07,  1.88s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:27<00:05,  1.80s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:29<00:03,  1.92s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:31<00:01,  1.95s/it]predicting train subjects: 100%|██████████| 285/285 [08:34<00:00,  2.01s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:57,  1.89s/it]Loading train:   1%|          | 2/285 [00:03<08:12,  1.74s/it]Loading train:   1%|          | 3/285 [00:04<08:04,  1.72s/it]Loading train:   1%|▏         | 4/285 [00:06<07:58,  1.70s/it]Loading train:   2%|▏         | 5/285 [00:08<08:15,  1.77s/it]Loading train:   2%|▏         | 6/285 [00:09<07:38,  1.64s/it]Loading train:   2%|▏         | 7/285 [00:11<08:02,  1.73s/it]Loading train:   3%|▎         | 8/285 [00:13<07:44,  1.68s/it]Loading train:   3%|▎         | 9/285 [00:15<07:50,  1.70s/it]Loading train:   4%|▎         | 10/285 [00:16<07:16,  1.59s/it]Loading train:   4%|▍         | 11/285 [00:17<06:21,  1.39s/it]Loading train:   4%|▍         | 12/285 [00:18<06:14,  1.37s/it]Loading train:   5%|▍         | 13/285 [00:19<06:05,  1.34s/it]Loading train:   5%|▍         | 14/285 [00:21<06:09,  1.36s/it]Loading train:   5%|▌         | 15/285 [00:22<05:48,  1.29s/it]Loading train:   6%|▌         | 16/285 [00:23<05:53,  1.32s/it]Loading train:   6%|▌         | 17/285 [00:24<05:22,  1.20s/it]Loading train:   6%|▋         | 18/285 [00:25<05:12,  1.17s/it]Loading train:   7%|▋         | 19/285 [00:27<05:18,  1.20s/it]Loading train:   7%|▋         | 20/285 [00:28<05:32,  1.25s/it]Loading train:   7%|▋         | 21/285 [00:30<06:12,  1.41s/it]Loading train:   8%|▊         | 22/285 [00:31<06:17,  1.43s/it]Loading train:   8%|▊         | 23/285 [00:33<05:57,  1.36s/it]Loading train:   8%|▊         | 24/285 [00:34<05:58,  1.37s/it]Loading train:   9%|▉         | 25/285 [00:36<06:32,  1.51s/it]Loading train:   9%|▉         | 26/285 [00:38<07:11,  1.66s/it]Loading train:   9%|▉         | 27/285 [00:40<07:22,  1.72s/it]Loading train:  10%|▉         | 28/285 [00:41<07:22,  1.72s/it]Loading train:  10%|█         | 29/285 [00:43<06:55,  1.62s/it]Loading train:  11%|█         | 30/285 [00:44<06:24,  1.51s/it]Loading train:  11%|█         | 31/285 [00:45<06:19,  1.49s/it]Loading train:  11%|█         | 32/285 [00:47<06:11,  1.47s/it]Loading train:  12%|█▏        | 33/285 [00:49<06:42,  1.60s/it]Loading train:  12%|█▏        | 34/285 [00:50<06:40,  1.60s/it]Loading train:  12%|█▏        | 35/285 [00:52<06:56,  1.67s/it]Loading train:  13%|█▎        | 36/285 [00:54<07:03,  1.70s/it]Loading train:  13%|█▎        | 37/285 [00:55<06:46,  1.64s/it]Loading train:  13%|█▎        | 38/285 [00:57<06:41,  1.63s/it]Loading train:  14%|█▎        | 39/285 [00:58<06:04,  1.48s/it]Loading train:  14%|█▍        | 40/285 [00:59<05:41,  1.39s/it]Loading train:  14%|█▍        | 41/285 [01:00<05:17,  1.30s/it]Loading train:  15%|█▍        | 42/285 [01:02<05:11,  1.28s/it]Loading train:  15%|█▌        | 43/285 [01:03<05:24,  1.34s/it]Loading train:  15%|█▌        | 44/285 [01:05<05:26,  1.36s/it]Loading train:  16%|█▌        | 45/285 [01:06<04:54,  1.23s/it]Loading train:  16%|█▌        | 46/285 [01:07<05:21,  1.35s/it]Loading train:  16%|█▋        | 47/285 [01:08<05:19,  1.34s/it]Loading train:  17%|█▋        | 48/285 [01:10<05:22,  1.36s/it]Loading train:  17%|█▋        | 49/285 [01:11<05:10,  1.32s/it]Loading train:  18%|█▊        | 50/285 [01:12<04:56,  1.26s/it]Loading train:  18%|█▊        | 51/285 [01:14<05:25,  1.39s/it]Loading train:  18%|█▊        | 52/285 [01:15<05:22,  1.38s/it]Loading train:  19%|█▊        | 53/285 [01:16<05:01,  1.30s/it]Loading train:  19%|█▉        | 54/285 [01:18<05:08,  1.34s/it]Loading train:  19%|█▉        | 55/285 [01:20<05:36,  1.46s/it]Loading train:  20%|█▉        | 56/285 [01:22<06:15,  1.64s/it]Loading train:  20%|██        | 57/285 [01:23<06:24,  1.69s/it]Loading train:  20%|██        | 58/285 [01:25<06:21,  1.68s/it]Loading train:  21%|██        | 59/285 [01:27<06:23,  1.70s/it]Loading train:  21%|██        | 60/285 [01:28<05:46,  1.54s/it]Loading train:  21%|██▏       | 61/285 [01:29<05:13,  1.40s/it]Loading train:  22%|██▏       | 62/285 [01:30<05:02,  1.36s/it]Loading train:  22%|██▏       | 63/285 [01:32<04:55,  1.33s/it]Loading train:  22%|██▏       | 64/285 [01:33<05:28,  1.49s/it]Loading train:  23%|██▎       | 65/285 [01:35<05:44,  1.57s/it]
Epoch 00056: val_mDice did not improve from 0.63492
Restoring model weights from the end of the best epoch
Epoch 00056: early stopping
{'val_loss': [1.7518662647162069, 0.5079985097799887, 0.4997341329824991, 0.4701258826522188, 0.4683849142250402, 0.5380305524644905, 0.5384370974322271, 0.5898828529778806, 0.4949154227805537, 0.5499287707179619, 0.5167599227175367, 0.6718477087313902, 0.5424441861706739, 0.6109054578083187, 0.4858506128774675, 0.45268611401818987, 0.4930903785055576, 0.4612475260675952, 0.48453710099172326, 0.4780912968699493, 0.45042939459145404, 0.47108303734710094, 0.5036032379672514, 0.49328207869769475, 0.6467152750691888, 0.459390971913684, 0.4605095716162101, 0.45124727887148297, 0.4492447802474379, 0.4774663564879135, 0.4600201835179462, 0.4513850541754142, 0.5007065934175886, 0.4878265667894033, 0.5041261558426159, 0.509386817170255, 0.6417329977344535, 0.555639179392234, 0.46364342300585526, 0.46531977766718946, 0.46328277061771417, 0.5130615490774869, 0.49116254518817926, 0.4459532056440854, 0.5021583907431064, 0.4795782056600688, 0.4535733511328031, 0.4610243789310562, 0.4689145727530538, 0.4692033369447932, 0.5369886199855272, 0.4629882780533263, 0.4756616483853516, 0.5142601152372094, 0.46579784621073544, 0.48621214102100396], 'val_acc': [0.9224819061476425, 0.9488467261111936, 0.9524871107586269, 0.9529044514927785, 0.9528858711599638, 0.9537783977705673, 0.9541151573538115, 0.9535697232411561, 0.9544787989648361, 0.9520057269980787, 0.9548734076862229, 0.9506256067553046, 0.9548134607309736, 0.9543155581591516, 0.9544787789856255, 0.9558898933106961, 0.9536606126657411, 0.953827972851652, 0.9534622703850603, 0.9530903990042277, 0.954129611313676, 0.9525656283900724, 0.9547370352558584, 0.9539498813325467, 0.9553609856680119, 0.9536275497361935, 0.9526296940595744, 0.954883719289769, 0.9536647730033491, 0.9547886955005497, 0.9556936331967402, 0.9549725744977343, 0.9544539857843068, 0.9542535656657298, 0.9533465820983802, 0.9547308563520123, 0.952683366210767, 0.9551709151134811, 0.9549746360192751, 0.9543196881949568, 0.9546047928612992, 0.9545077182061179, 0.9546254563597993, 0.9540800119245518, 0.9548837069692558, 0.9543114421087936, 0.9536895495553256, 0.9549869964908622, 0.9537391302971866, 0.9539850034527273, 0.9537205549591746, 0.9522990840773343, 0.9547804177806364, 0.9539312683670215, 0.954644038690535, 0.9543857877480917], 'val_mDice': [0.2608528378622492, 0.5989696466722968, 0.6060705521253235, 0.6236901063492845, 0.6290158406316235, 0.611707424984298, 0.6090025342376538, 0.6041126883895703, 0.6247974094731847, 0.5961017718528236, 0.6188709879054703, 0.5666913713156844, 0.6148984638672301, 0.6168718897430591, 0.6185459331427207, 0.6349161280600052, 0.618927789799994, 0.6251897359027543, 0.617745476728045, 0.6166286085570991, 0.6297516563085205, 0.6139241650117843, 0.6164275061484822, 0.6133205064848148, 0.6102742382933973, 0.6244729131293696, 0.6215553123857722, 0.6303937501747515, 0.6301881963980265, 0.6180483299260698, 0.6306536830337354, 0.6309986524075769, 0.6144051771590163, 0.6116754236168036, 0.610978673290274, 0.6044061936479707, 0.5825017577443043, 0.6051704177643333, 0.6227677930666747, 0.6209179129680442, 0.6244773388574909, 0.6060236769015562, 0.6161753062429375, 0.630497026709871, 0.6099010336332481, 0.6180562633375882, 0.6279158811995437, 0.6215688356474125, 0.6180239413037646, 0.6210304242272616, 0.6002569311823924, 0.6233354001071866, 0.6178744918141286, 0.6069351191627247, 0.624263726133208, 0.6195874620416311], 'loss': [1.8382817401383984, 0.568194139030373, 0.4415406306469975, 0.40147202499655166, 0.3764594559718578, 0.35835305146354, 0.3448741501968714, 0.33723279714818083, 0.32866905766221394, 0.32195601925877965, 0.3156120052028472, 0.3130373125222765, 0.30760422761738543, 0.30125041711558304, 0.29603757243141887, 0.2959204301320028, 0.28729494293169366, 0.28588108753860664, 0.2817200953391933, 0.28090516671259985, 0.2771914733124288, 0.2744305273960777, 0.2726134645897321, 0.27315127563907665, 0.2676467649863051, 0.2674683899825178, 0.265381522175988, 0.2629356592703694, 0.2611483739995663, 0.25933862350084547, 0.2580253148814522, 0.25895201865932427, 0.25730066812088415, 0.25504953777580364, 0.2547200962931143, 0.25302605214971297, 0.2513546121532079, 0.2501428272688962, 0.24869923561975382, 0.24703653130300307, 0.24709123077459322, 0.2471955175084503, 0.24483245327223893, 0.24575589361302988, 0.243916877931671, 0.2424789796720357, 0.24257327784614674, 0.2409788054400855, 0.24022538015560793, 0.2403424566094376, 0.23855739555505098, 0.23785758431824158, 0.23734634243940764, 0.23764055629719524, 0.23638778219204323, 0.23635223157528173], 'acc': [0.7859577982010882, 0.9285129770156924, 0.9403343434771657, 0.9443916769940819, 0.9464669232599343, 0.9477648962641924, 0.948863808953303, 0.949482764837938, 0.9501451260578294, 0.9506963020017428, 0.9511895343619918, 0.9516864102472765, 0.9517019189239672, 0.95233121050267, 0.9526998825072204, 0.9527173056256296, 0.9532215144079655, 0.9532965424663198, 0.9536570401617881, 0.9536835459230331, 0.9540204759594869, 0.9541382653690762, 0.9542568599786265, 0.9543374670330304, 0.9546985276435808, 0.9547762340771127, 0.9548601660455249, 0.9551053518050702, 0.955232183564872, 0.9553440698682142, 0.9554428468958939, 0.9554243960980983, 0.9555612381237875, 0.9555781601294798, 0.9556233161162281, 0.9559175860394217, 0.9558707778636008, 0.9560094923243583, 0.956062667107934, 0.9562258945883414, 0.9561843430610935, 0.9561952628196503, 0.9563803035678846, 0.9562668040825725, 0.9564516039126048, 0.9565385569934524, 0.9565363790233062, 0.9566895787988987, 0.9567678494427719, 0.9567916562442822, 0.9568808447671258, 0.9568930330356218, 0.9569221371289244, 0.9568797175605458, 0.9570273374571051, 0.956985058542833], 'mDice': [0.24530579871610908, 0.5530391732083382, 0.6286617996684737, 0.6549859047325587, 0.672222506233202, 0.6844487866995141, 0.6941553355464423, 0.6997149897507284, 0.7060174963766567, 0.7108418097079732, 0.7156986071454318, 0.7200239447231718, 0.7214656142093577, 0.7263193790068989, 0.730151066725683, 0.7304732140668382, 0.7367891171718565, 0.7379415791367505, 0.74108175553954, 0.7419385009910227, 0.7446905086972954, 0.7468246798857866, 0.7482002993228876, 0.7481030450589997, 0.7520773713543657, 0.7523265385068091, 0.7539636750872063, 0.7558698999966796, 0.7572807117807249, 0.7587137081661903, 0.7598059706896727, 0.7590914882512974, 0.7604389309292298, 0.7621133262396547, 0.7624268383509998, 0.7637982185639676, 0.7650916669033859, 0.7660572478522026, 0.767175961924329, 0.7684771756085492, 0.7685136271356712, 0.768449591269752, 0.7703399675083695, 0.7695264272599963, 0.7711694445863775, 0.7722510794630809, 0.7721816963973138, 0.7734970330581719, 0.7741124150825868, 0.7739997301691985, 0.7753784156600074, 0.775980946217271, 0.7764242684280851, 0.7761505523036232, 0.7772212995954877, 0.7771700986505146]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values minLoading train:  23%|██▎       | 66/285 [01:37<06:24,  1.76s/it]Loading train:  24%|██▎       | 67/285 [01:39<06:13,  1.71s/it]Loading train:  24%|██▍       | 68/285 [01:41<06:05,  1.69s/it]Loading train:  24%|██▍       | 69/285 [01:42<05:23,  1.50s/it]Loading train:  25%|██▍       | 70/285 [01:43<05:14,  1.46s/it]Loading train:  25%|██▍       | 71/285 [01:44<04:46,  1.34s/it]Loading train:  25%|██▌       | 72/285 [01:45<04:28,  1.26s/it]Loading train:  26%|██▌       | 73/285 [01:46<04:21,  1.23s/it]Loading train:  26%|██▌       | 74/285 [01:48<04:15,  1.21s/it]Loading train:  26%|██▋       | 75/285 [01:49<04:43,  1.35s/it]Loading train:  27%|██▋       | 76/285 [01:51<05:20,  1.53s/it]Loading train:  27%|██▋       | 77/285 [01:53<05:28,  1.58s/it]Loading train:  27%|██▋       | 78/285 [01:54<05:19,  1.54s/it]Loading train:  28%|██▊       | 79/285 [01:56<05:21,  1.56s/it]Loading train:  28%|██▊       | 80/285 [01:57<04:56,  1.45s/it]Loading train:  28%|██▊       | 81/285 [01:58<04:25,  1.30s/it]Loading train:  29%|██▉       | 82/285 [01:59<04:20,  1.28s/it]Loading train:  29%|██▉       | 83/285 [02:00<04:13,  1.26s/it]Loading train:  29%|██▉       | 84/285 [02:02<04:12,  1.26s/it]Loading train:  30%|██▉       | 85/285 [02:03<04:31,  1.36s/it]Loading train:  30%|███       | 86/285 [02:05<04:46,  1.44s/it]Loading train:  31%|███       | 87/285 [02:06<04:22,  1.33s/it]Loading train:  31%|███       | 88/285 [02:07<04:05,  1.25s/it]Loading train:  31%|███       | 89/285 [02:09<04:26,  1.36s/it]Loading train:  32%|███▏      | 90/285 [02:10<04:24,  1.35s/it]Loading train:  32%|███▏      | 91/285 [02:11<04:02,  1.25s/it]Loading train:  32%|███▏      | 92/285 [02:12<04:06,  1.28s/it]Loading train:  33%|███▎      | 93/285 [02:13<03:50,  1.20s/it]Loading train:  33%|███▎      | 94/285 [02:15<03:55,  1.23s/it]Loading train:  33%|███▎      | 95/285 [02:16<03:57,  1.25s/it]Loading train:  34%|███▎      | 96/285 [02:17<03:46,  1.20s/it]Loading train:  34%|███▍      | 97/285 [02:18<03:47,  1.21s/it]Loading train:  34%|███▍      | 98/285 [02:20<04:08,  1.33s/it]Loading train:  35%|███▍      | 99/285 [02:22<04:25,  1.43s/it]Loading train:  35%|███▌      | 100/285 [02:23<04:05,  1.33s/it]Loading train:  35%|███▌      | 101/285 [02:24<03:57,  1.29s/it]Loading train:  36%|███▌      | 102/285 [02:25<03:52,  1.27s/it]Loading train:  36%|███▌      | 103/285 [02:26<03:31,  1.16s/it]Loading train:  36%|███▋      | 104/285 [02:28<03:46,  1.25s/it]Loading train:  37%|███▋      | 105/285 [02:29<03:51,  1.28s/it]Loading train:  37%|███▋      | 106/285 [02:30<04:00,  1.35s/it]Loading train:  38%|███▊      | 107/285 [02:32<04:04,  1.37s/it]Loading train:  38%|███▊      | 108/285 [02:33<03:57,  1.34s/it]Loading train:  38%|███▊      | 109/285 [02:34<03:41,  1.26s/it]Loading train:  39%|███▊      | 110/285 [02:36<03:59,  1.37s/it]Loading train:  39%|███▉      | 111/285 [02:37<03:59,  1.38s/it]Loading train:  39%|███▉      | 112/285 [02:39<04:04,  1.41s/it]Loading train:  40%|███▉      | 113/285 [02:40<03:43,  1.30s/it]Loading train:  40%|████      | 114/285 [02:41<03:44,  1.31s/it]Loading train:  40%|████      | 115/285 [02:42<03:28,  1.23s/it]Loading train:  41%|████      | 116/285 [02:43<03:36,  1.28s/it]Loading train:  41%|████      | 117/285 [02:45<04:00,  1.43s/it]Loading train:  41%|████▏     | 118/285 [02:46<03:49,  1.38s/it]Loading train:  42%|████▏     | 119/285 [02:48<03:39,  1.32s/it]Loading train:  42%|████▏     | 120/285 [02:49<03:22,  1.23s/it]Loading train:  42%|████▏     | 121/285 [02:50<03:41,  1.35s/it]Loading train:  43%|████▎     | 122/285 [02:52<03:54,  1.44s/it]Loading train:  43%|████▎     | 123/285 [02:53<03:50,  1.42s/it]Loading train:  44%|████▎     | 124/285 [02:54<03:29,  1.30s/it]Loading train:  44%|████▍     | 125/285 [02:55<03:19,  1.25s/it]Loading train:  44%|████▍     | 126/285 [02:57<03:17,  1.24s/it]Loading train:  45%|████▍     | 127/285 [02:58<03:15,  1.23s/it]Loading train:  45%|████▍     | 128/285 [02:59<03:23,  1.29s/it]Loading train:  45%|████▌     | 129/285 [03:00<03:03,  1.18s/it]Loading train:  46%|████▌     | 130/285 [03:01<02:59,  1.16s/it]Loading train:  46%|████▌     | 131/285 [03:03<03:08,  1.22s/it]Loading train:  46%|████▋     | 132/285 [03:04<03:07,  1.22s/it]Loading train:  47%|████▋     | 133/285 [03:06<03:20,  1.32s/it]Loading train:  47%|████▋     | 134/285 [03:07<03:37,  1.44s/it]Loading train:  47%|████▋     | 135/285 [03:09<03:46,  1.51s/it]Loading train:  48%|████▊     | 136/285 [03:10<03:33,  1.43s/it]Loading train:  48%|████▊     | 137/285 [03:11<03:24,  1.38s/it]Loading train:  48%|████▊     | 138/285 [03:13<03:15,  1.33s/it]Loading train:  49%|████▉     | 139/285 [03:14<03:31,  1.45s/it]Loading train:  49%|████▉     | 140/285 [03:16<03:27,  1.43s/it]Loading train:  49%|████▉     | 141/285 [03:17<03:04,  1.28s/it]Loading train:  50%|████▉     | 142/285 [03:19<03:32,  1.49s/it]Loading train:  50%|█████     | 143/285 [03:21<03:56,  1.66s/it]Loading train:  51%|█████     | 144/285 [03:22<03:29,  1.49s/it]Loading train:  51%|█████     | 145/285 [03:23<02:56,  1.26s/it]Loading train:  51%|█████     | 146/285 [03:23<02:41,  1.16s/it]Loading train:  52%|█████▏    | 147/285 [03:25<02:52,  1.25s/it]Loading train:  52%|█████▏    | 148/285 [03:26<02:36,  1.14s/it]Loading train:  52%|█████▏    | 149/285 [03:27<02:42,  1.20s/it]Loading train:  53%|█████▎    | 150/285 [03:29<02:49,  1.25s/it]Loading train:  53%|█████▎    | 151/285 [03:30<02:40,  1.20s/it]Loading train:  53%|█████▎    | 152/285 [03:30<02:25,  1.09s/it]Loading train:  54%|█████▎    | 153/285 [03:31<02:15,  1.03s/it]Loading train:  54%|█████▍    | 154/285 [03:32<02:07,  1.03it/s]Loading train:  54%|█████▍    | 155/285 [03:33<01:59,  1.08it/s]Loading train:  55%|█████▍    | 156/285 [03:34<02:00,  1.07it/s]Loading train:  55%|█████▌    | 157/285 [03:35<01:52,  1.14it/s]Loading train:  55%|█████▌    | 158/285 [03:36<01:52,  1.13it/s]Loading train:  56%|█████▌    | 159/285 [03:36<01:48,  1.17it/s]Loading train:  56%|█████▌    | 160/285 [03:37<01:44,  1.19it/s]Loading train:  56%|█████▋    | 161/285 [03:38<01:43,  1.20it/s]Loading train:  57%|█████▋    | 162/285 [03:39<01:41,  1.21it/s]Loading train:  57%|█████▋    | 163/285 [03:40<01:42,  1.19it/s]Loading train:  58%|█████▊    | 164/285 [03:40<01:38,  1.23it/s]Loading train:  58%|█████▊    | 165/285 [03:41<01:36,  1.24it/s]Loading train:  58%|█████▊    | 166/285 [03:42<01:37,  1.22it/s]Loading train:  59%|█████▊    | 167/285 [03:43<01:36,  1.23it/s]Loading train:  59%|█████▉    | 168/285 [03:44<01:32,  1.27it/s]Loading train:  59%|█████▉    | 169/285 [03:44<01:33,  1.24it/s]Loading train:  60%|█████▉    | 170/285 [03:45<01:28,  1.30it/s]Loading train:  60%|██████    | 171/285 [03:46<01:27,  1.30it/s]Loading train:  60%|██████    | 172/285 [03:47<01:26,  1.30it/s]Loading train:  61%|██████    | 173/285 [03:47<01:25,  1.30it/s]Loading train:  61%|██████    | 174/285 [03:48<01:25,  1.29it/s]Loading train:  61%|██████▏   | 175/285 [03:49<01:26,  1.27it/s]Loading train:  62%|██████▏   | 176/285 [03:50<01:30,  1.21it/s]Loading train:  62%|██████▏   | 177/285 [03:51<01:26,  1.25it/s]Loading train:  62%|██████▏   | 178/285 [03:52<01:28,  1.21it/s]Loading train:  63%|██████▎   | 179/285 [03:52<01:27,  1.21it/s]Loading train:  63%|██████▎   | 180/285 [03:53<01:29,  1.18it/s]Loading train:  64%|██████▎   | 181/285 [03:54<01:34,  1.10it/s]Loading train:  64%|██████▍   | 182/285 [03:55<01:30,  1.14it/s]Loading train:  64%|██████▍   | 183/285 [03:56<01:31,  1.11it/s]Loading train:  65%|██████▍   | 184/285 [03:57<01:30,  1.12it/s]Loading train:  65%|██████▍   | 185/285 [03:58<01:27,  1.15it/s]Loading train:  65%|██████▌   | 186/285 [03:59<01:29,  1.10it/s]Loading train:  66%|██████▌   | 187/285 [04:00<01:33,  1.05it/s]Loading train:  66%|██████▌   | 188/285 [04:01<01:30,  1.07it/s]Loading train:  66%|██████▋   | 189/285 [04:02<01:24,  1.14it/s]Loading train:  67%|██████▋   | 190/285 [04:02<01:22,  1.15it/s]Loading train:  67%|██████▋   | 191/285 [04:03<01:25,  1.10it/s]Loading train:  67%|██████▋   | 192/285 [04:04<01:26,  1.07it/s]Loading train:  68%|██████▊   | 193/285 [04:05<01:22,  1.11it/s]Loading train:  68%|██████▊   | 194/285 [04:06<01:18,  1.16it/s]Loading train:  68%|██████▊   | 195/285 [04:07<01:14,  1.22it/s]Loading train:  69%|██████▉   | 196/285 [04:08<01:16,  1.16it/s]Loading train:  69%|██████▉   | 197/285 [04:09<01:17,  1.14it/s]Loading train:  69%|██████▉   | 198/285 [04:10<01:19,  1.10it/s]Loading train:  70%|██████▉   | 199/285 [04:10<01:14,  1.15it/s]Loading train:  70%|███████   | 200/285 [04:11<01:08,  1.24it/s]Loading train:  71%|███████   | 201/285 [04:12<01:13,  1.14it/s]Loading train:  71%|███████   | 202/285 [04:13<01:15,  1.10it/s]Loading train:  71%|███████   | 203/285 [04:14<01:11,  1.14it/s]Loading train:  72%|███████▏  | 204/285 [04:15<01:08,  1.18it/s]Loading train:  72%|███████▏  | 205/285 [04:15<01:02,  1.27it/s]Loading train:  72%|███████▏  | 206/285 [04:16<00:59,  1.32it/s]Loading train:  73%|███████▎  | 207/285 [04:17<01:01,  1.27it/s]Loading train:  73%|███████▎  | 208/285 [04:18<01:04,  1.19it/s]Loading train:  73%|███████▎  | 209/285 [04:19<01:09,  1.09it/s]Loading train:  74%|███████▎  | 210/285 [04:20<01:06,  1.13it/s]Loading train:  74%|███████▍  | 211/285 [04:21<01:08,  1.08it/s]Loading train:  74%|███████▍  | 212/285 [04:22<01:07,  1.09it/s]Loading train:  75%|███████▍  | 213/285 [04:22<01:02,  1.15it/s]Loading train:  75%|███████▌  | 214/285 [04:23<01:00,  1.16it/s]Loading train:  75%|███████▌  | 215/285 [04:24<01:03,  1.11it/s]Loading train:  76%|███████▌  | 216/285 [04:25<01:00,  1.14it/s]Loading train:  76%|███████▌  | 217/285 [04:26<01:00,  1.13it/s]Loading train:  76%|███████▋  | 218/285 [04:27<01:02,  1.08it/s]Loading train:  77%|███████▋  | 219/285 [04:28<01:02,  1.05it/s]Loading train:  77%|███████▋  | 220/285 [04:29<00:57,  1.14it/s]Loading train:  78%|███████▊  | 221/285 [04:30<00:57,  1.11it/s]Loading train:  78%|███████▊  | 222/285 [04:31<00:57,  1.10it/s]Loading train:  78%|███████▊  | 223/285 [04:31<00:52,  1.17it/s]Loading train:  79%|███████▊  | 224/285 [04:32<00:53,  1.15it/s]Loading train:  79%|███████▉  | 225/285 [04:33<00:51,  1.17it/s]Loading train:  79%|███████▉  | 226/285 [04:34<00:53,  1.10it/s]Loading train:  80%|███████▉  | 227/285 [04:35<00:54,  1.07it/s]Loading train:  80%|████████  | 228/285 [04:36<00:53,  1.06it/s]Loading train:  80%|████████  | 229/285 [04:37<00:51,  1.08it/s]Loading train:  81%|████████  | 230/285 [04:38<00:49,  1.10it/s]Loading train:  81%|████████  | 231/285 [04:39<00:47,  1.13it/s]Loading train:  81%|████████▏ | 232/285 [04:39<00:45,  1.16it/s]Loading train:  82%|████████▏ | 233/285 [04:40<00:42,  1.23it/s]Loading train:  82%|████████▏ | 234/285 [04:41<00:43,  1.17it/s]Loading train:  82%|████████▏ | 235/285 [04:42<00:41,  1.19it/s]Loading train:  83%|████████▎ | 236/285 [04:43<00:43,  1.14it/s]Loading train:  83%|████████▎ | 237/285 [04:44<00:43,  1.11it/s]Loading train:  84%|████████▎ | 238/285 [04:45<00:42,  1.11it/s]Loading train:  84%|████████▍ | 239/285 [04:46<00:41,  1.10it/s]Loading train:  84%|████████▍ | 240/285 [04:46<00:38,  1.16it/s]Loading train:  85%|████████▍ | 241/285 [04:47<00:37,  1.16it/s]Loading train:  85%|████████▍ | 242/285 [04:48<00:35,  1.23it/s]Loading train:  85%|████████▌ | 243/285 [04:49<00:33,  1.27it/s]Loading train:  86%|████████▌ | 244/285 [04:50<00:34,  1.20it/s]Loading train:  86%|████████▌ | 245/285 [04:50<00:32,  1.22it/s]Loading train:  86%|████████▋ | 246/285 [04:51<00:32,  1.21it/s]Loading train:  87%|████████▋ | 247/285 [04:52<00:34,  1.10it/s]Loading train:  87%|████████▋ | 248/285 [04:53<00:33,  1.11it/s]Loading train:  87%|████████▋ | 249/285 [04:54<00:31,  1.14it/s]Loading train:  88%|████████▊ | 250/285 [04:55<00:31,  1.13it/s]Loading train:  88%|████████▊ | 251/285 [04:56<00:27,  1.23it/s]Loading train:  88%|████████▊ | 252/285 [04:56<00:25,  1.29it/s]Loading train:  89%|████████▉ | 253/285 [04:57<00:26,  1.20it/s]Loading train:  89%|████████▉ | 254/285 [04:58<00:27,  1.12it/s]Loading train:  89%|████████▉ | 255/285 [04:59<00:26,  1.12it/s]Loading train:  90%|████████▉ | 256/285 [05:00<00:24,  1.18it/s]Loading train:  90%|█████████ | 257/285 [05:01<00:23,  1.21it/s]Loading train:  91%|█████████ | 258/285 [05:02<00:23,  1.15it/s]Loading train:  91%|█████████ | 259/285 [05:02<00:22,  1.15it/s]Loading train:  91%|█████████ | 260/285 [05:03<00:20,  1.21it/s]Loading train:  92%|█████████▏| 261/285 [05:04<00:19,  1.25it/s]Loading train:  92%|█████████▏| 262/285 [05:05<00:18,  1.25it/s]Loading train:  92%|█████████▏| 263/285 [05:05<00:17,  1.29it/s]Loading train:  93%|█████████▎| 264/285 [05:06<00:17,  1.21it/s]Loading train:  93%|█████████▎| 265/285 [05:07<00:17,  1.16it/s]Loading train:  93%|█████████▎| 266/285 [05:08<00:15,  1.24it/s]Loading train:  94%|█████████▎| 267/285 [05:09<00:14,  1.24it/s]Loading train:  94%|█████████▍| 268/285 [05:10<00:14,  1.17it/s]Loading train:  94%|█████████▍| 269/285 [05:11<00:13,  1.18it/s]Loading train:  95%|█████████▍| 270/285 [05:11<00:12,  1.20it/s]Loading train:  95%|█████████▌| 271/285 [05:12<00:11,  1.25it/s]Loading train:  95%|█████████▌| 272/285 [05:13<00:10,  1.19it/s]Loading train:  96%|█████████▌| 273/285 [05:14<00:09,  1.26it/s]Loading train:  96%|█████████▌| 274/285 [05:15<00:08,  1.27it/s]Loading train:  96%|█████████▋| 275/285 [05:15<00:08,  1.21it/s]Loading train:  97%|█████████▋| 276/285 [05:16<00:07,  1.15it/s]Loading train:  97%|█████████▋| 277/285 [05:17<00:06,  1.19it/s]Loading train:  98%|█████████▊| 278/285 [05:18<00:05,  1.23it/s]Loading train:  98%|█████████▊| 279/285 [05:19<00:04,  1.21it/s]Loading train:  98%|█████████▊| 280/285 [05:19<00:03,  1.27it/s]Loading train:  99%|█████████▊| 281/285 [05:20<00:03,  1.20it/s]Loading train:  99%|█████████▉| 282/285 [05:21<00:02,  1.24it/s]Loading train:  99%|█████████▉| 283/285 [05:22<00:01,  1.20it/s]Loading train: 100%|█████████▉| 284/285 [05:23<00:00,  1.16it/s]Loading train: 100%|██████████| 285/285 [05:24<00:00,  1.08it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   4%|▍         | 12/285 [00:00<00:02, 116.21it/s]concatenating: train:  11%|█         | 30/285 [00:00<00:01, 128.81it/s]concatenating: train:  19%|█▉        | 55/285 [00:00<00:01, 149.88it/s]concatenating: train:  31%|███       | 87/285 [00:00<00:01, 177.02it/s]concatenating: train:  39%|███▉      | 112/285 [00:00<00:00, 191.83it/s]concatenating: train:  46%|████▋     | 132/285 [00:00<00:00, 189.18it/s]concatenating: train:  54%|█████▍    | 154/285 [00:00<00:00, 196.07it/s]concatenating: train:  62%|██████▏   | 176/285 [00:00<00:00, 201.82it/s]concatenating: train:  69%|██████▉   | 197/285 [00:00<00:00, 200.54it/s]concatenating: train:  76%|███████▋  | 218/285 [00:01<00:00, 196.39it/s]concatenating: train:  84%|████████▎ | 238/285 [00:01<00:00, 195.19it/s]concatenating: train:  91%|█████████ | 258/285 [00:01<00:00, 194.34it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 210.25it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.20s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.20s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.16s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 770.49it/s]2019-07-11 05:34:06.020980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 05:34:06.021131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 05:34:06.021164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 05:34:06.021175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 05:34:06.021630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.34it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.20it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:08,  4.98it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.39it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  5.93it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  6.63it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.94it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.70it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  8.15it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.85it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.55it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.02it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.33it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.50it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.26it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.15it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.16it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.44it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.21it/s] 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 26, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 26, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 26, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 26, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 13, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 13, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 13, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 20, 13, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 40, 26, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 40, 26, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 40, 26, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 80, 52, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 80, 52, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 52, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 80, 52, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 20)   10820       dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 80, 52, 20)   0           activation_11[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 20)   3620        dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 80, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 80, 52, 20)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 80)   0           dropout_5[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 52, 13)   1053        concatenate_7[0][0]              
==================================================================================================
Total params: 238,693
Trainable params: 63,933
Non-trainable params: 174,760
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 16s - loss: 2.6761 - acc: 0.5801 - mDice: 0.1251 - val_loss: 1.8830 - val_acc: 0.9027 - val_mDice: 0.2314

Epoch 00001: val_mDice improved from -inf to 0.23140, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 11s - loss: 0.8937 - acc: 0.8911 - mDice: 0.4009 - val_loss: 1.0407 - val_acc: 0.9136 - val_mDice: 0.4477

Epoch 00002: val_mDice improved from 0.23140 to 0.44766, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 11s - loss: 0.6937 - acc: 0.9049 - mDice: 0.4879 - val_loss: 1.0269 - val_acc: 0.9304 - val_mDice: 0.4469

Epoch 00003: val_mDice did not improve from 0.44766
Epoch 4/300
 - 11s - loss: 0.6043 - acc: 0.9172 - mDice: 0.5329 - val_loss: 0.9231 - val_acc: 0.9357 - val_mDice: 0.5011

Epoch 00004: val_mDice improved from 0.44766 to 0.50111, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 11s - loss: 0.5455 - acc: 0.9254 - mDice: 0.5644 - val_loss: 0.8698 - val_acc: 0.9313 - val_mDice: 0.5204

Epoch 00005: val_mDice improved from 0.50111 to 0.52043, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 11s - loss: 0.5034 - acc: 0.9293 - mDice: 0.5889 - val_loss: 0.8487 - val_acc: 0.9369 - val_mDice: 0.5317

Epoch 00006: val_mDice improved from 0.52043 to 0.53169, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 11s - loss: 0.4730 - acc: 0.9318 - mDice: 0.6074 - val_loss: 0.8497 - val_acc: 0.9314 - val_mDice: 0.5306

Epoch 00007: val_mDice did not improve from 0.53169
Epoch 8/300
 - 11s - loss: 0.4510 - acc: 0.9336 - mDice: 0.6213 - val_loss: 0.8387 - val_acc: 0.9376 - val_mDice: 0.5464

Epoch 00008: val_mDice improved from 0.53169 to 0.54640, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 11s - loss: 0.4349 - acc: 0.9349 - mDice: 0.6317 - val_loss: 0.8831 - val_acc: 0.9335 - val_mDice: 0.5287

Epoch 00009: val_mDice did not improve from 0.54640
Epoch 10/300
 - 11s - loss: 0.4251 - acc: 0.9358 - mDice: 0.6383 - val_loss: 0.8628 - val_acc: 0.9392 - val_mDice: 0.5400

Epoch 00010: val_mDice did not improve from 0.54640
Epoch 11/300
 - 11s - loss: 0.4100 - acc: 0.9370 - mDice: 0.6481 - val_loss: 0.8585 - val_acc: 0.9342 - val_mDice: 0.5396

Epoch 00011: val_mDice did not improve from 0.54640
Epoch 12/300
 - 11s - loss: 0.3998 - acc: 0.9381 - mDice: 0.6551 - val_loss: 0.8393 - val_acc: 0.9330 - val_mDice: 0.5531

Epoch 00012: val_mDice improved from 0.54640 to 0.55306, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 11s - loss: 0.3911 - acc: 0.9387 - mDice: 0.6609 - val_loss: 0.8275 - val_acc: 0.9302 - val_mDice: 0.5515

Epoch 00013: val_mDice did not improve from 0.55306
Epoch 14/300
 - 11s - loss: 0.3829 - acc: 0.9395 - mDice: 0.6667 - val_loss: 0.8236 - val_acc: 0.9360 - val_mDice: 0.5583

Epoch 00014: val_mDice improved from 0.55306 to 0.55827, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 11s - loss: 0.3771 - acc: 0.9400 - mDice: 0.6707 - val_loss: 0.8210 - val_acc: 0.9373 - val_mDice: 0.5624

Epoch 00015: val_mDice improved from 0.55827 to 0.56242, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 11s - loss: 0.3709 - acc: 0.9403 - mDice: 0.6748 - val_loss: 0.7991 - val_acc: 0.9387 - val_mDice: 0.5673

Epoch 00016: val_mDice improved from 0.56242 to 0.56728, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 11s - loss: 0.3660 - acc: 0.9411 - mDice: 0.6783 - val_loss: 0.8723 - val_acc: 0.9281 - val_mDice: 0.5277

Epoch 00017: val_mDice did not improve from 0.56728
Epoch 18/300
 - 11s - loss: 0.3592 - acc: 0.9414 - mDice: 0.6830 - val_loss: 0.8345 - val_acc: 0.9409 - val_mDice: 0.5594

Epoch 00018: val_mDice did not improve from 0.56728
Epoch 19/300
 - 11s - loss: 0.3538 - acc: 0.9418 - mDice: 0.6869 - val_loss: 0.7568 - val_acc: 0.9414 - val_mDice: 0.5809

Epoch 00019: val_mDice improved from 0.56728 to 0.58095, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 20/300
 - 11s - loss: 0.3493 - acc: 0.9422 - mDice: 0.6903 - val_loss: 0.7601 - val_acc: 0.9418 - val_mDice: 0.5820

Epoch 00020: val_mDice improved from 0.58095 to 0.58198, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 21/300
 - 11s - loss: 0.3487 - acc: 0.9423 - mDice: 0.6907 - val_loss: 0.7706 - val_acc: 0.9378 - val_mDice: 0.5664

Epoch 00021: val_mDice did not improve from 0.58198
Epoch 22/300
 - 11s - loss: 0.3421 - acc: 0.9428 - mDice: 0.6954 - val_loss: 0.8509 - val_acc: 0.9368 - val_mDice: 0.5557

Epoch 00022: val_mDice did not improve from 0.58198
Epoch 23/300
 - 11s - loss: 0.3382 - acc: 0.9432 - mDice: 0.6982 - val_loss: 0.8482 - val_acc: 0.9420 - val_mDice: 0.5495

Epoch 00023: val_mDice did not improve from 0.58198
Epoch 24/300
 - 11s - loss: 0.3352 - acc: 0.9434 - mDice: 0.7004 - val_loss: 0.8011 - val_acc: 0.9402 - val_mDice: 0.5671

Epoch 00024: val_mDice did not improve from 0.58198
Epoch 25/300
 - 10s - loss: 0.3309 - acc: 0.9437 - mDice: 0.7035 - val_loss: 0.7676 - val_acc: 0.9433 - val_mDice: 0.5785

Epoch 00025: val_mDice did not improve from 0.58198
Epoch 26/300
 - 11s - loss: 0.3277 - acc: 0.9441 - mDice: 0.7059 - val_loss: 0.8018 - val_acc: 0.9384 - val_mDice: 0.5712

Epoch 00026: val_mDice did not improve from 0.58198
Epoch 27/300
 - 11s - loss: 0.3277 - acc: 0.9441 - mDice: 0.7060 - val_loss: 0.8237 - val_acc: 0.9364 - val_mDice: 0.5661

Epoch 00027: val_mDice did not improve from 0.58198
Epoch 28/300
 - 11s - loss: 0.3245 - acc: 0.9443 - mDice: 0.7083 - val_loss: 0.8143 - val_acc: 0.9404 - val_mDice: 0.5677

Epoch 00028: val_mDice did not improve from 0.58198
Epoch 29/300
 - 11s - loss: 0.3192 - acc: 0.9448 - mDice: 0.7121 - val_loss: 0.7557 - val_acc: 0.9409 - val_mDice: 0.5727

Epoch 00029: val_mDice did not improve from 0.58198
Epoch 30/300
 - 11s - loss: 0.3169 - acc: 0.9450 - mDice: 0.7138 - val_loss: 0.8106 - val_acc: 0.9406 - val_mDice: 0.5589

Epoch 00030: val_mDice did not improve from 0.58198
Epoch 31/300
 - 11s - loss: 0.3154 - acc: 0.9450 - mDice: 0.7149 - val_loss: 0.7611 - val_acc: 0.9423 - val_mDice: 0.5816

Epoch 00031: val_mDice did not improve from 0.58198
Epoch 32/300
 - 11s - loss: 0.3131 - acc: 0.9453 - mDice: 0.7168 - val_loss: 0.7683 - val_acc: 0.9442 - val_mDice: 0.5714

Epoch 00032: val_mDice did not improve from 0.58198
Epoch 33/300
 - 11s - loss: 0.3115 - acc: 0.9453 - mDice: 0.7179 - val_loss: 0.7824 - val_acc: 0.9399 - val_mDice: 0.5713

Epoch 00033: val_mDice did not improve from 0.58198
Epoch 34/300
 - 11s - loss: 0.3098 - acc: 0.9456 - mDice: 0.7192 - val_loss: 0.7761 - val_acc: 0.9374 - val_mDice: 0.5640

Epoch 00034: val_mDice did not improve from 0.58198
Epoch 35/300
 - 11s - loss: 0.3062 - acc: 0.9458 - mDice: 0.7218 - val_loss: 0.8090 - val_acc: 0.9415 - val_mDice: 0.5538

Epoch 00035: val_mDice did not improve from 0.58198
Epoch 36/300
 - 11s - loss: 0.3080 - acc: 0.9457 - mDice: 0.7206 - val_loss: 0.7692 - val_acc: 0.9423 - val_mDice: 0.5709

Epoch 00036: val_mDice did not improve from 0.58198
Epoch 37/300
 - 10s - loss: 0.3027 - acc: 0.9462 - mDice: 0.7245 - val_loss: 0.8344 - val_acc: 0.9425 - val_mDice: 0.5447

Epoch 00037: val_mDice did not improve from 0.58198
Epoch 38/300
 - 11s - loss: 0.3038 - acc: 0.9461 - mDice: 0.7238 - val_loss: 0.7982 - val_acc: 0.9391 - val_mDice: 0.5558

Epoch 00038: val_mDice did not improve from 0.58198
Epoch 39/300
 - 11s - loss: 0.3006 - acc: 0.9463 - mDice: 0.7262 - val_loss: 0.7779 - val_acc: 0.9420 - val_mDice: 0.5564

Epoch 00039: val_mDice did not improve from 0.58198
Epoch 40/300
 - 11s - loss: 0.3002 - acc: 0.9465 - mDice: 0.7264 - val_loss: 0.7755 - val_acc: 0.9398 - val_mDice: 0.5583

Epoch 00040: val_mDice did not improve from 0.58198
Epoch 41/300
 - 11s - loss: 0.3001 - acc: 0.9464 - mDice: 0.7266 - val_loss: 0.7932 - val_acc: 0.9387 - val_mDice: 0.5514

Epoch 00041: val_mDice did not improve from 0.58198
Epoch 42/300
 - 11s - loss: 0.2991 - acc: 0.9465 - mDice: 0.7273 - val_loss: 0.6932 - val_acc: 0.9430 - val_mDice: 0.5793

Epoch 00042: val_mDice did not improve from 0.58198
Epoch 43/300
 - 11s - loss: 0.3016 - acc: 0.9467 - mDice: 0.7289 - val_loss: 1.2710 - val_acc: 0.9348 - val_mDice: 0.4277

Epoch 00043: val_mDice did not improve from 0.58198
Epoch 44/300
 - 12s - loss: 0.3797 - acc: 0.9404 - mDice: 0.6718 - val_loss: 0.7998 - val_acc: 0.9334 - val_mDice: 0.5515

Epoch 00044: val_mDice did not improve from 0.58198
Epoch 45/300
 - 11s - loss: 0.3110 - acc: 0.9455 - mDice: 0.7184 - val_loss: 0.7342 - val_acc: 0.9407 - val_mDice: 0.5780

Epoch 00045: val_mDice did not improve from 0.58198
Epoch 46/300
 - 11s - loss: 0.3003 - acc: 0.9464 - mDice: 0.7264 - val_loss: 0.7761 - val_acc: 0.9457 - val_mDice: 0.5610

Epoch 00046: val_mDice did not improve from 0.58198
Epoch 47/300
 - 11s - loss: 0.2982 - acc: 0.9466 - mDice: 0.7280 - val_loss: 0.7598 - val_acc: 0.9424 - val_mDice: 0.5640

Epoch 00047: val_mDice did not improve from 0.58198
Epoch 48/300
 - 11s - loss: 0.2941 - acc: 0.9469 - mDice: 0.7310 - val_loss: 0.7313 - val_acc: 0.9422 - val_mDice: 0.5687

Epoch 00048: val_mDice did not improve from 0.58198
Epoch 49/300
 - 11s - loss: 0.2928 - acc: 0.9470 - mDice: 0.7320 - val_loss: 0.7224 - val_acc: 0.9402 - val_mDice: 0.5743

Epoch 00049: val_mDice did not improve from 0.58198
Epoch 50/300
 - 11s - loss: 0.2904 - acc: 0.9471 - mDice: 0.7339 - val_loss: 0.7388 - val_acc: 0.9397 - val_mDice: 0.5758

Epoch 00050: val_mDice did not improve from 0.58198
Epoch 51/300
 - 11s - loss: 0.2906 - acc: 0.9472 - mDice: 0.7338 - val_loss: 0.7419 - val_acc: 0.9421 - val_mDice: 0.5829

Epoch 00051: val_mDice improved from 0.58198 to 0.58287, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 52/300
 - 11s - loss: 0.2879 - acc: 0.9475 - mDice: 0.7359 - val_loss: 0.7378 - val_acc: 0.9395 - val_mDice: 0.5662

Epoch 00052: val_mDice did not improve from 0.58287
Epoch 53/300
 - 11s - loss: 0.2878 - acc: 0.9475 - mDice: 0.7360 - val_loss: 0.7479 - val_acc: 0.9421 - val_mDice: 0.5567

Epoch 00053: val_mDice did not improve from 0.58287
Epoch 54/300
 - 11s - loss: 0.2852 - acc: 0.9476 - mDice: 0.7379 - val_loss: 0.7312 - val_acc: 0.9415 - val_mDice: 0.5690

Epoch 00054: val_mDice did not improve from 0.58287
Epoch 55/300
 - 11s - loss: 0.2845 - acc: 0.9477 - mDice: 0.7385 - val_loss: 0.6522 - val_acc: 0.9396 - val_mDice: 0.5664

Epoch 00055: val_mDice did not improve from 0.58287
Epoch 56/300
 - 11s - loss: 0.2850 - acc: 0.9477 - mDice: 0.7381 - val_loss: 0.6929 - val_acc: 0.9398 - val_mDice: 0.5712

Epoch 00056: val_mDice did not improve from 0.58287
Epoch 57/300
 - 11s - loss: 0.2824 - acc: 0.9480 - mDice: 0.7401 - val_loss: 0.7347 - val_acc: 0.9358 - val_mDice: 0.5556

Epoch 00057: val_mDice did not improve from 0.58287
Epoch 58/300
 - 11s - loss: 0.2829 - acc: 0.9479 - mDice: 0.7397 - val_loss: 0.7143 - val_acc: 0.9432 - val_mDice: 0.5836

Epoch 00058: val_mDice improved from 0.58287 to 0.58358, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 59/300
 - 11s - loss: 0.2811 - acc: 0.9481 - mDice: 0.7411 - val_loss: 0.7166 - val_acc: 0.9393 - val_mDice: 0.5791

Epoch 00059: val_mDice did not improve from 0.58358
Epoch 60/300
 - 11s - loss: 0.2822 - acc: 0.9479 - mDice: 0.7403 - val_loss: 0.7126 - val_acc: 0.9415 - val_mDice: 0.5790

Epoch 00060: val_mDice did not improve from 0.58358
Epoch 61/300
 - 11s - loss: 0.2805 - acc: 0.9480 - mDice: 0.7416 - val_loss: 0.7657 - val_acc: 0.9429 - val_mDice: 0.5568

Epoch 00061: val_mDice did not improve from 0.58358
Epoch 62/300
 - 11s - loss: 0.2782 - acc: 0.9483 - mDice: 0.7434 - val_loss: 0.6618 - val_acc: 0.9400 - val_mDice: 0.5684

Epoch 00062: val_mDice did not improve from 0.58358
Epoch 63/300
 - 11s - loss: 0.2773 - acc: 0.9484 - mDice: 0.7441 - val_loss: 0.6926 - val_acc: 0.9392 - val_mDice: 0.5673

Epoch 00063: val_mDice did not improve from 0.58358
Epoch 64/300
 - 11s - loss: 0.2776 - acc: 0.9483 - mDice: 0.7438 - val_loss: 0.7596 - val_acc: 0.9398 - val_mDice: 0.5752

Epoch 00064: val_mDice did not improve from 0.58358
Epoch 65/300
 - 11s - loss: 0.2783 - acc: 0.9483 - mDice: 0.7433 - val_loss: 0.7329 - val_acc: 0.9424 - val_mDice: 0.5696

Epoch 00065: val_mDice did not improve from 0.58358
Epoch 66/300
 - 11s - loss: 0.2783 - acc: 0.9483 - mDice: 0.7434 - val_loss: 0.7057 - val_acc: 0.9417 - val_mDice: 0.5768

Epoch 00066: val_mDice did not improve from 0.58358
Epoch 67/300
 - 11s - loss: 0.2741 - acc: 0.9486 - mDice: 0.7466 - val_loss: 0.7202 - val_acc: 0.9405 - val_mDice: 0.5767

Epoch 00067: val_mDice did not improve from 0.58358
Epoch 68/300
 - 11s - loss: 0.2740 - acc: 0.9485 - mDice: 0.7467 - val_loss: 0.6927 - val_acc: 0.9393 - val_mDice: 0.5691

Epoch 00068: val_mDice did not improve from 0.58358
Epoch 69/300
 - 11s - loss: 0.2730 - acc: 0.9487 - mDice: 0.7474 - val_loss: 0.7199 - val_acc: 0.9407 - val_mDice: 0.5812

Epoch 00069: val_mDice did not improve from 0.58358
Epoch 70/300
 - 11s - loss: 0.2734 - acc: 0.9486 - mDice: 0.7471 - val_loss: 0.7141 - val_acc: 0.9397 - val_mDice: 0.5771

Epoch 00070: val_mDice did not improve from 0.58358
Epoch 71/300
 - 11s - loss: 0.2718 - acc: 0.9488 - mDice: 0.7485 - val_loss: 0.7408 - val_acc: 0.9383 - val_mDice: 0.5685

Epoch 00071: val_mDice did not improve from 0.58358
Epoch 72/300
 - 11s - loss: 0.2726 - acc: 0.9488 - mDice: 0.7478 - val_loss: 0.6718 - val_acc: 0.9417 - val_mDice: 0.5787

Epoch 00072: val_mDice did not improve from 0.58358
Epoch 73/300
 - 10s - loss: 0.2715 - acc: 0.9489 - mDice: 0.7487 - val_loss: 0.6619 - val_acc: 0.9414 - val_mDice: 0.5711

Epoch 00073: val_mDice did not improve from 0.58358
Epoch 74/300
 - 10s - loss: 0.2709 - acc: 0.9488 - mDice: 0.7491 - val_loss: 0.6675 - val_acc: 0.9396 - val_mDice: 0.5789

Epoch 00074: val_mDice did not improve from 0.58358
Epoch 75/300
 - 11s - loss: 0.2698 - acc: 0.9490 - mDice: 0.7500 - val_loss: 0.7023 - val_acc: 0.9413 - val_mDice: 0.5652

Epoch 00075: val_mDice did not improve from 0.58358
Epoch 76/300
 - 11s - loss: 0.2707 - acc: 0.9489 - mDice: 0.7493 - val_loss: 0.7034 - val_acc: 0.9428 - val_mDice: 0.5578

Epoch 00076: val_mDice did not improve from 0.58358
Epoch 77/300
 - 11s - loss: 0.2689 - acc: 0.9490 - mDice: 0.7507 - val_loss: 0.7514 - val_acc: 0.9415 - val_mDice: 0.5752

Epoch 00077: val_mDice did not improve from 0.58358
Epoch 78/300
 - 10s - loss: 0.2681 - acc: 0.9491 - mDice: 0.7513 - val_loss: 0.6326 - val_acc: 0.9414 - val_mDice: 0.5855

Epoch 00078: val_mDice improved from 0.58358 to 0.58555, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 79/300
 - 11s - loss: 0.2661 - acc: 0.9493 - mDice: 0.7529 - val_loss: 0.6271 - val_acc: 0.9422 - val_mDice: 0.5740

Epoch 00079: val_mDice did not improve from 0.58555
Epoch 80/300
 - 10s - loss: 0.2666 - acc: 0.9491 - mDice: 0.7525 - val_loss: 0.6024 - val_acc: 0.9428 - val_mDice: 0.5811

Epoch 00080: val_mDice did not improve from 0.58555
Epoch 81/300
 - 11s - loss: 0.2660 - acc: 0.9493 - mDice: 0.7529 - val_loss: 0.7423 - val_acc: 0.9403 - val_mDice: 0.5789

Epoch 00081: val_mDice did not improve from 0.58555
Epoch 82/300
 - 10s - loss: 0.2661 - acc: 0.9492 - mDice: 0.7529 - val_loss: 0.7821 - val_acc: 0.9459 - val_mDice: 0.5891

Epoch 00082: val_mDice improved from 0.58555 to 0.58914, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 83/300
 - 11s - loss: 0.2659 - acc: 0.9493 - mDice: 0.7531 - val_loss: 0.7603 - val_acc: 0.9430 - val_mDice: 0.5450

Epoch 00083: val_mDice did not improve from 0.58914
Epoch 84/300
 - 11s - loss: 0.2647 - acc: 0.9493 - mDice: 0.7540 - val_loss: 0.7050 - val_acc: 0.9449 - val_mDice: 0.5718

Epoch 00084: val_mDice did not improve from 0.58914
Epoch 85/300
 - 11s - loss: 0.2657 - acc: 0.9493 - mDice: 0.7533 - val_loss: 0.6851 - val_acc: 0.9423 - val_mDice: 0.5837

Epoch 00085: val_mDice did not improve from 0.58914
Epoch 86/300
 - 11s - loss: 0.2636 - acc: 0.9495 - mDice: 0.7549 - val_loss: 0.7169 - val_acc: 0.9421 - val_mDice: 0.5749

Epoch 00086: val_mDice did not improve from 0.58914
Epoch 87/300
 - 11s - loss: 0.2621 - acc: 0.9495 - mDice: 0.7560 - val_loss: 0.6557 - val_acc: 0.9388 - val_mDice: 0.5811

Epoch 00087: val_mDice did not improve from 0.58914
Epoch 88/300
 - 11s - loss: 0.2623 - acc: 0.9495 - mDice: 0.7559 - val_loss: 0.7395 - val_acc: 0.9387 - val_mDice: 0.5702

Epoch 00088: val_mDice did not improve from 0.58914
Epoch 89/300
 - 10s - loss: 0.2618 - acc: 0.9496 - mDice: 0.7563 - val_loss: 0.6747 - val_acc: 0.9438 - val_mDice: 0.5762

Epoch 00089: val_mDice did not improve from 0.58914
Epoch 90/300
 - 11s - loss: 0.2625 - acc: 0.9495 - mDice: 0.7557 - val_loss: 0.7780 - val_acc: 0.9339 - val_mDice: 0.5530

Epoch 00090: val_mDice did not improve from 0.58914
Epoch 91/300
 - 11s - loss: 0.2619 - acc: 0.9495 - mDice: 0.7563 - val_loss: 0.7380 - val_acc: 0.9417 - val_mDice: 0.5849

Epoch 00091: val_mDice did not improve from 0.58914
Epoch 92/300
 - 11s - loss: 0.2621 - acc: 0.9496 - mDice: 0.7562 - val_loss: 0.6917 - val_acc: 0.9339 - val_mDice: 0.5618

Epoch 00092: val_mDice did not improve from 0.58914
Epoch 93/300
 - 11s - loss: 0.2602 - acc: 0.9498 - mDice: 0.7576 - val_loss: 0.6688 - val_acc: 0.9436 - val_mDice: 0.5925

Epoch 00093: val_mDice improved from 0.58914 to 0.59249, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 94/300
 - 10s - loss: 0.2590 - acc: 0.9498 - mDice: 0.7585 - val_loss: 0.7066 - val_acc: 0.9418 - val_mDice: 0.5844

Epoch 00094: val_mDice did not improve from 0.59249
Epoch 95/300
 - 11s - loss: 0.2585 - acc: 0.9498 - mDice: 0.7590 - val_loss: 0.7055 - val_acc: 0.9383 - val_mDice: 0.5714

Epoch 00095: val_mDice did not improve from 0.59249
Epoch 96/300
 - 11s - loss: 0.2582 - acc: 0.9498 - mDice: 0.7592 - val_loss: 0.7024 - val_acc: 0.9441 - val_mDice: 0.5876

Epoch 00096: val_mDice did not improve from 0.59249
Epoch 97/300
 - 11s - loss: 0.2578 - acc: 0.9500 - mDice: 0.7595 - val_loss: 0.6878 - val_acc: 0.9371 - val_mDice: 0.5697

Epoch 00097: val_mDice did not improve from 0.59249
Epoch 98/300
 - 11s - loss: 0.2598 - acc: 0.9498 - mDice: 0.7579 - val_loss: 0.6937 - val_acc: 0.9371 - val_mDice: 0.5595

Epoch 00098: val_mDice did not improve from 0.59249
Epoch 99/300
 - 11s - loss: 0.2586 - acc: 0.9499 - mDice: 0.7589 - val_loss: 0.7187 - val_acc: 0.9378 - val_mDice: 0.5420

Epoch 00099: val_mDice did not improve from 0.59249
Epoch 100/300
 - 11s - loss: 0.2592 - acc: 0.9499 - mDice: 0.7585 - val_loss: 0.7241 - val_acc: 0.9408 - val_mDice: 0.5702

Epoch 00100: val_mDice did not improve from 0.59249
Epoch 101/300
 - 11s - loss: 0.2563 - acc: 0.9500 - mDice: 0.7607 - val_loss: 0.6511 - val_acc: 0.9421 - val_mDice: 0.5665

Epoch 00101: val_mDice did not improve from 0.59249
Epoch 102/300
 - 11s - loss: 0.2573 - acc: 0.9500 - mDice: 0.7600 - val_loss: 0.7192 - val_acc: 0.9425 - val_mDice: 0.5841

Epoch 00102: val_mDice did not improve from 0.59249
Epoch 103/300
 - 11s - loss: 0.2566 - acc: 0.9502 - mDice: 0.7604 - val_loss: 0.6890 - val_acc: 0.9415 - val_mDice: 0.5673

Epoch 00103: val_mDice did not improve from 0.59249
Epoch 104/300
 - 11s - loss: 0.2559 - acc: 0.9501 - mDice: 0.7610 - val_loss: 0.7302 - val_acc: 0.9424 - val_mDice: 0.5849

Epoch 00104: val_mDice did not improve from 0.59249
Epoch 105/300
 - 11s - loss: 0.2551 - acc: 0.9502 - mDice: 0.7617 - val_loss: 0.7837 - val_acc: 0.9389 - val_mDice: 0.5605

Epoch 00105: val_mDice did not improve from 0.59249
Epoch 106/300
 - 11s - loss: 0.2550 - acc: 0.9501 - mDice: 0.7617 - val_loss: 0.7279 - val_acc: 0.9421 - val_mDice: 0.5879

Epoch 00106: val_mDice did not improve from 0.59249
Epoch 107/300
 - 12s - loss: 0.2546 - acc: 0.9502 - mDice: 0.7620 - val_loss: 0.7067 - val_acc: 0.9429 - val_mDice: 0.5729

Epoch 00107: val_mDice did not improve from 0.59249
Epoch 108/300
 - 11s - loss: 0.2545 - acc: 0.9501 - mDice: 0.7621 - val_loss: 0.7039 - val_acc: 0.9442 - val_mDice: 0.5762

Epoch 00108: val_mDice did not improve from 0.59249
Epoch 109/300
 - 11s - loss: 0.2536 - acc: 0.9503 - mDice: 0.7628 - val_loss: 0.7117 - val_acc: 0.9434 - val_mDice: 0.5511

Epoch 00109: val_mDice did not improve from 0.59249
Epoch 110/300
 - 11s - loss: 0.2538 - acc: 0.9503 - mDice: 0.7628 - val_loss: 0.6972 - val_acc: 0.9444 - val_mDice: 0.5786

Epoch 00110: val_mDice did not improve from 0.59249
Epoch 111/300
 - 11s - loss: 0.2531 - acc: 0.9503 - mDice: 0.7633 - val_loss: 0.7433 - val_acc: 0.9415 - val_mDice: 0.5818

Epoch 00111: val_mDice did not improve from 0.59249
Epoch 112/300
 - 11s - loss: 0.2521 - acc: 0.9504 - mDice: 0.7641 - val_loss: 0.6408 - val_acc: 0.9398 - val_mDice: 0.5803

Epoch 00112: val_mDice did not improve from 0.59249
Epoch 113/300
 - 11s - loss: 0.2535 - acc: 0.9502 - mDice: 0.7629 - val_loss: 0.7842 - val_acc: 0.9368 - val_mDice: 0.5577

Epoch 00113: val_mDice did not improve from 0.59249
Epoch 114/300
 - 11s - loss: 0.2528 - acc: 0.9503 - mDice: 0.7635 - val_loss: 0.6828 - val_acc: 0.9435 - val_mDice: 0.5832

Epoch 00114: val_mDice did not improve from 0.59249
Epoch 115/300
 - 11s - loss: 0.2499 - acc: 0.9506 - mDice: 0.7659 - val_loss: 0.7280 - val_acc: 0.9412 - val_mDice: 0.5708

Epoch 00115: val_mDice did not improve from 0.59249
Epoch 116/300
 - 11s - loss: 0.2517 - acc: 0.9504 - mDice: 0.7644 - val_loss: 0.6819 - val_acc: 0.9382 - val_mDice: 0.5556

Epoch 00116: val_mDice did not improve from 0.59249
Epoch 117/300
 - 11s - loss: 0.2504 - acc: 0.9505 - mDice: 0.7654 - val_loss: 0.6885 - val_acc: 0.9427 - val_mDice: 0.5777

Epoch 00117: val_mDice did not improve from 0.59249
Epoch 118/300
 - 11s - loss: 0.2513 - acc: 0.9505 - mDice: 0.7647 - val_loss: 0.7796 - val_acc: 0.9407 - val_mDice: 0.5602

Epoch 00118: val_mDice did not improve from 0.59249
Epoch 119/300
 - 12s - loss: 0.2503 - acc: 0.9505 - mDice: 0.7655 - val_loss: 0.6870 - val_acc: 0.9442 - val_mDice: 0.5739

Epoch 00119: val_mDice did not improve from 0.59249
Epoch 120/300
 - 11s - loss: 0.2512 - acc: 0.9505 - mDice: 0.7648 - val_loss: 0.6849 - val_acc: 0.9421 - val_mDice: 0.5568

Epoch 00120: val_mDice did not improve from 0.59249
Epoch 121/300
 - 11s - loss: 0.2492 - acc: 0.9507 - mDice: 0.7664 - val_loss: 0.6631 - val_acc: 0.9408 - val_mDice: 0.5824

Epoch 00121: val_mDice did not improve from 0.59249
Epoch 122/300
 - 11s - loss: 0.2497 - acc: 0.9505 - mDice: 0.7660 - val_loss: 0.7444 - val_acc: 0.9385 - val_mDice: 0.5487

Epoch 00122: val_mDice did not improve from 0.59249
Epoch 123/300
 - 11s - loss: 0.2502 - acc: 0.9505 - mDice: 0.7656 - val_loss: 0.6947 - val_acc: 0.9417 - val_mDice: 0.5829

Epoch 00123: val_mDice did not improve from 0.59249
Epoch 124/300
 - 11s - loss: 0.2487 - acc: 0.9506 - mDice: 0.7667 - val_loss: 0.7008 - val_acc: 0.9379 - val_mDice: 0.5725

Epoch 00124: val_mDice did not improve from 0.59249
Epoch 125/300
 - 11s - loss: 0.2485 - acc: 0.9508 - mDice: 0.7670 - val_loss: 0.6537 - val_acc: 0.9426 - val_mDice: 0.5718

Epoch 00125: val_mDice did not improve from 0.59249
Epoch 126/300
 - 11s - loss: 0.2502 - acc: 0.9506 - mDice: 0.7656 - val_loss: 0.6607 - val_acc: 0.9440 - val_mDice: 0.5637

Epoch 00126: val_mDice did not improve from 0.59249
Epoch 127/300
 - 11s - loss: 0.2477 - acc: 0.9507 - mDice: 0.7677 - val_loss: 0.6825 - val_acc: 0.9425 - val_mDice: 0.5775

Epoch 00127: val_mDice did not improve from 0.59249
Epoch 128/300
 - 11s - loss: 0.2475 - acc: 0.9508 - mDice: 0.7678 - val_loss: 0.6586 - val_acc: 0.9445 - val_mDice: 0.5679

Epoch 00128: val_mDice did not improve from 0.59249
Epoch 129/300
 - 11s - loss: 0.2473 - acc: 0.9509 - mDice: 0.7679 - val_loss: 0.7915 - val_acc: 0.9362 - val_mDice: 0.5542

Epoch 00129: val_mDice did not improve from 0.59249
Epoch 130/300
 - 11s - loss: 0.2478 - acc: 0.9509 - mDice: 0.7675 - val_loss: 0.6870 - val_acc: 0.9421 - val_mDice: 0.5851

Epoch 00130: val_mDice did not improve from 0.59249
Epoch 131/300
 - 11s - loss: 0.2468 - acc: 0.9508 - mDice: 0.7683 - val_loss: 0.6562 - val_acc: 0.9414 - val_mDice: 0.5795

Epoch 00131: val_mDice did not improve from 0.59249
Epoch 132/300
 - 11s - loss: 0.2467 - acc: 0.9508 - mDice: 0.7684 - val_loss: 0.6475 - val_acc: 0.9446 - val_mDice: 0.5745

Epoch 00132: val_mDice did not improve from 0.59249
Epoch 133/300
 - 11s - loss: 0.2461 - acc: 0.9509 - mDice: 0.7689 - val_loss: 0.7338 - val_acc: 0.9392 - val_mDice: 0.5574

Epoch 00133: val_mDice did not improve from 0.59249
Restoring model weights from the end of the best epoch
Epoch 00133: early stopping
{'val_loss': [1.8830091907427862, 1.0407468859965985, 1.0269128817778368, 0.9231224381006681, 0.8697720559743735, 0.848731646170983, 0.8496586588712839, 0.8387490923588092, 0.8830543183363401, 0.8627523734019353, 0.8585094809532166, 0.8393182456493378, 0.8275173971286187, 0.8235546763126667, 0.8209580756150759, 0.7990794777870178, 0.8723011796291058, 0.8344777730795053, 0.7568140178918839, 0.7600798354699061, 0.7706265036876385, 0.8509007004591135, 0.8481954244466928, 0.8010741105446448, 0.7676381239524255, 0.8017624570773199, 0.8236639637213486, 0.8143358918336722, 0.7557164224294516, 0.8106408623548654, 0.7610869155480311, 0.7683198910493118, 0.7823701340418595, 0.7761126962991861, 0.8090046139863821, 0.7691769714538867, 0.8344198419497564, 0.7982242015691904, 0.7778620100938357, 0.7754585307378036, 0.7931816165263836, 0.6931818769528315, 1.2709500239445612, 0.7998239077054538, 0.7341783826167767, 0.7760692284657404, 0.7598361395872556, 0.7313445852353022, 0.7223507028359634, 0.7387596185390766, 0.7419227831638776, 0.7378152448397416, 0.7479398846626282, 0.7312280398148757, 0.6522378600560702, 0.6929322458230532, 0.73469844689736, 0.71428960447128, 0.7166491895914078, 0.7125734125192349, 0.7656704760514773, 0.6618460554343003, 0.6926402908105117, 0.7596089518987216, 0.7329410635508024, 0.7057214654408969, 0.720228237601427, 0.6926962756193601, 0.7199364304542542, 0.7140844108966681, 0.740759762433859, 0.6718277300779636, 0.6618557549439944, 0.6674600736452982, 0.7023407839811765, 0.7033666601547828, 0.7514326205620399, 0.6326470615772101, 0.6270982829424051, 0.6024116415243882, 0.7422969478827256, 0.7821426689624786, 0.76027489396242, 0.7050103751512674, 0.6850972290222461, 0.7168818918558267, 0.6556589442950028, 0.7394832464364859, 0.6747115827523745, 0.777966572688176, 0.7380403337570337, 0.6917097247563876, 0.6688405229495122, 0.7066375555900427, 0.7054612957514249, 0.7024348676204681, 0.6877825397711533, 0.693669305397914, 0.7187036871910095, 0.7240977952113519, 0.651130524965433, 0.7191783522184079, 0.6890108126860398, 0.7301932573318481, 0.7837304839721093, 0.7279252295310681, 0.7067435796444232, 0.70391079554191, 0.7117404135373923, 0.6971766742376181, 0.743312004667062, 0.6407631245943216, 0.7841590872177711, 0.6828343352446189, 0.7279869730655963, 0.6819275846848121, 0.6884910762310028, 0.7796036142569321, 0.6869652592218839, 0.68494274524542, 0.6631084359609164, 0.7444304319528433, 0.6947084481899555, 0.700776987350904, 0.6536604876701648, 0.6607357951310965, 0.6825041885559375, 0.65858338200129, 0.791450525705631, 0.6870022610976145, 0.6561615765094757, 0.6474898228278527, 0.7337685342018421], 'val_acc': [0.9027413381980016, 0.9136094405100896, 0.9304456458641932, 0.9356532234411973, 0.9313077628612518, 0.9368689770881946, 0.9314048886299133, 0.937585500570444, 0.9335313324744885, 0.9392011922139388, 0.9342039410884564, 0.9330205481785995, 0.9302029655529902, 0.9360045561423669, 0.9373128001506512, 0.9387019391243274, 0.9281157690745133, 0.9408676876471593, 0.941353059731997, 0.9418384914214795, 0.9378420939812293, 0.936776550916525, 0.9419633195950434, 0.9402043200456179, 0.9432715681883005, 0.9384476542472839, 0.936427517579152, 0.9404354920754066, 0.9408908234192774, 0.9405972705437586, 0.9422961335915786, 0.9441937758372381, 0.9399454708282764, 0.9373913453175471, 0.9415033299189347, 0.9423215480951163, 0.9425295866452731, 0.9390648351265833, 0.9419841055686657, 0.9398044485312241, 0.93868344105207, 0.9430288282724527, 0.934763300877351, 0.9333880383234757, 0.9407313190973722, 0.9456962049007416, 0.9424024361830491, 0.942150544661742, 0.9401835111471323, 0.9397073686122894, 0.942058074932832, 0.9395432541003594, 0.94209502522762, 0.9414593944182763, 0.9396310838369223, 0.9397836556801429, 0.9358496436705956, 0.9431929336144373, 0.9392843682032365, 0.9415125938562247, 0.9428971065924718, 0.9400494419611417, 0.9391711537654583, 0.9397859802612891, 0.9423700846158541, 0.9417344904862918, 0.9404840033787948, 0.9393398784674131, 0.9406642707494589, 0.9397189066960261, 0.9382835718301626, 0.9417483531511747, 0.9413553980680612, 0.9396426448455224, 0.9413368816559131, 0.9428439392493322, 0.9415333912922785, 0.9414155162297763, 0.942180567062818, 0.9428393405217391, 0.9402875556395605, 0.9458533364992875, 0.9430034412787511, 0.9448779775546148, 0.9422683807519766, 0.9420996858523443, 0.9387828272122604, 0.9387296529916617, 0.9438078082524813, 0.9338526221422049, 0.9416628021460313, 0.9339265777514532, 0.9436367612618667, 0.941833856014105, 0.9383251919196203, 0.9441244350029872, 0.9370816418757806, 0.9371093993003552, 0.9378027893029727, 0.9408168380077069, 0.9421204489011031, 0.9425272826965039, 0.9414940980764536, 0.9423608344334823, 0.9389423109017886, 0.9420742346690252, 0.9428624396140759, 0.9442122601545774, 0.9434263843756455, 0.9443509876728058, 0.9415403306484222, 0.9397720694541931, 0.9367580230419452, 0.9435465748493488, 0.941168147784013, 0.9381933900026175, 0.9427237258507655, 0.9407082360524398, 0.944196111880816, 0.9420719261352832, 0.9408399714873388, 0.9384684769006876, 0.9417321429802821, 0.9379137318867904, 0.9426451462965745, 0.9439557125935187, 0.9425087662843558, 0.9444619004543011, 0.9362264046302209, 0.9421066183310288, 0.9413877863150376, 0.9446075168939737, 0.9391688108444214], 'val_mDice': [0.23139884781378967, 0.4476587319603333, 0.44692882952781826, 0.5011099791870668, 0.5204257042362139, 0.531691869864097, 0.5305860180121201, 0.5463959010174642, 0.5287377948944385, 0.5400271576184493, 0.5395961782106986, 0.5530616325827745, 0.5514767135565097, 0.558271682033172, 0.5624185823477231, 0.5672804323526529, 0.5276899188756943, 0.5594088790508417, 0.5809478908777237, 0.5819833015020077, 0.5663996722835761, 0.5556709525676874, 0.5494921803474426, 0.5671497755325757, 0.5785324481817392, 0.571168030683811, 0.5661481710580679, 0.5676534072710917, 0.572667213013539, 0.5589052822727424, 0.5816395924641535, 0.5713936537504196, 0.5712787371415359, 0.5640025975612494, 0.55383934539098, 0.5709377183363988, 0.544689892576291, 0.5558195492395988, 0.5564469924339881, 0.5582800507545471, 0.5513951721099707, 0.5792945892764971, 0.4276658348166026, 0.5514898116771991, 0.5780447434920531, 0.5609502540184901, 0.5640361675849328, 0.5687163838973412, 0.5743476278506793, 0.5758345304773405, 0.5828710484963197, 0.5661916457689725, 0.5566975772380829, 0.5689667234053979, 0.5663506377201813, 0.5711892917752266, 0.5556134226230475, 0.5835824471253616, 0.5790882236682452, 0.5789614881460483, 0.556846233514639, 0.5684018169458096, 0.5672759797710639, 0.5752148593847568, 0.5696340976999357, 0.5768220923267878, 0.5766880615399435, 0.5691325039817736, 0.581186749614202, 0.57714632497384, 0.5685138249626527, 0.578667781673945, 0.5711362837598875, 0.5788762867450714, 0.5652409763290331, 0.5578362586406561, 0.5752024839703853, 0.585545607484304, 0.5739711872660197, 0.5810675678344873, 0.5788790841515248, 0.5891366176880323, 0.5449587347415777, 0.571835692685384, 0.5836961544477023, 0.5749300557833451, 0.5811448412445875, 0.5701725637683501, 0.5762102644030864, 0.553046431678992, 0.5848818157727902, 0.5617555540341598, 0.5924923316790507, 0.5843768503803474, 0.5714109138800547, 0.5876358415071781, 0.5697245380053153, 0.5595445701709161, 0.5419800413342623, 0.5702134405191128, 0.5664670639313184, 0.5840656957947291, 0.5672833564189764, 0.5849088625266001, 0.5605228021740913, 0.5879272709672267, 0.5729262989300948, 0.576166086185437, 0.5510886216966006, 0.5785577910450789, 0.5817568095830771, 0.5802962974860117, 0.5576529124608407, 0.5832375075954658, 0.5708078581553239, 0.5556109788326117, 0.5777261715668899, 0.5602209608142192, 0.5739424939338977, 0.5568086596635672, 0.5823846029547545, 0.5487353400542185, 0.5829445352921119, 0.5725337862968445, 0.5718295402251757, 0.5637319592329172, 0.5775424620279899, 0.5679220350889059, 0.5541557979125243, 0.5851031891428508, 0.5794636693138343, 0.5744536576362756, 0.5573590566905645], 'loss': [2.6760706061599198, 0.8936799774857714, 0.6937193859770192, 0.604345657602729, 0.5454944925346487, 0.5033782255954103, 0.472959237233152, 0.450979351466909, 0.4349487413699739, 0.4250891450272048, 0.40995674708898155, 0.3998355861080866, 0.391101764297393, 0.3828727998994521, 0.37710508878442356, 0.3708827409490958, 0.3660218560183322, 0.35921991352147525, 0.3538376963507983, 0.3493339626714113, 0.34871625531690537, 0.34211547813885634, 0.33823676726029367, 0.33522693901487266, 0.33087489037488227, 0.3276602903695869, 0.3277398761151231, 0.32447280300165976, 0.3192206696809619, 0.31692133618106944, 0.31543002246073293, 0.3130817723666721, 0.3114685104538195, 0.30977725055311633, 0.30617990876809703, 0.3080425593044489, 0.3026876195868058, 0.30384915453376427, 0.3005883325749214, 0.3001875574986983, 0.30009060548942246, 0.29908145891447013, 0.30155170378315155, 0.37966733028899036, 0.31095484628576664, 0.3002843911095012, 0.298185972116711, 0.2941363186900228, 0.29284298642858264, 0.2904449579384366, 0.29056599104601244, 0.2878995970431634, 0.28779988369466325, 0.2851945278632029, 0.2844664367496621, 0.2849975351004058, 0.2823657178465405, 0.2829342364528286, 0.28114232017986673, 0.2822250893862938, 0.28054523071404547, 0.27819367441470955, 0.2772953799347436, 0.2775804076447188, 0.2783327577112566, 0.27830509530170966, 0.2740664929192763, 0.27398206607052883, 0.27302907551169386, 0.27340015420765934, 0.2717913753523726, 0.2726150581776892, 0.2714662437238652, 0.27089555397592635, 0.2698304725371636, 0.2706601453131991, 0.26893099988836056, 0.2681237597956073, 0.26608439281419294, 0.26664284083012735, 0.2660346062357307, 0.2661421716097788, 0.2658717664149176, 0.26466305025233167, 0.26565347020557684, 0.2636171996120728, 0.26211201306870535, 0.26228071137524767, 0.2617694863443675, 0.26245756542002113, 0.26193024881302973, 0.2620545140598397, 0.26016586812277137, 0.2589760110377276, 0.2584652036942427, 0.2582097011200454, 0.2577504144156429, 0.2597647840401942, 0.2585807300675985, 0.25916558061865963, 0.2562651111005934, 0.25726928585769393, 0.2566392289930347, 0.2558562381014903, 0.25512250102688816, 0.2550315447374979, 0.2546432924621892, 0.25454917540467115, 0.25363459065865734, 0.2537786210884987, 0.25311913695225885, 0.25206020719877725, 0.2535366694128822, 0.25283914150308223, 0.2498621942124485, 0.25170496532444936, 0.2504006836380915, 0.25129337219484815, 0.25034267534016136, 0.251218464680069, 0.24924939221906164, 0.24967309104212204, 0.25023635298379243, 0.24872316151409365, 0.24846192434970207, 0.250184643983753, 0.2476820357719009, 0.24749846358470984, 0.24734094874462847, 0.24777636942603562, 0.24680882041759733, 0.24669513175883967, 0.2461380597812426], 'acc': [0.5801347385792014, 0.8910551346020099, 0.9048986116711596, 0.9172030973894003, 0.9253874120430391, 0.9293361015560816, 0.9317943066740612, 0.9336270208641534, 0.9349055629995578, 0.9358448185879378, 0.937020402167717, 0.9380970088184226, 0.938704517718161, 0.9394588807868659, 0.939959913379513, 0.9403295901322358, 0.9410561551788708, 0.9413649294909149, 0.9418333489923671, 0.9421972213422066, 0.9422968306807941, 0.9428081042232477, 0.943207707130677, 0.9434460126626957, 0.9437427553679355, 0.9441358612096695, 0.9440872404976194, 0.9442890967641558, 0.944760620187242, 0.9449865715723356, 0.9450319957977223, 0.9452548266930366, 0.9452599470360104, 0.9455781012765269, 0.9457842136928981, 0.9457204960033065, 0.9461724457239011, 0.9460749233999255, 0.9463022022485668, 0.946487741459123, 0.9464330049466132, 0.946514790391038, 0.9466575188334662, 0.9403668569098053, 0.9454569235330005, 0.9463820374013093, 0.9465866840260612, 0.9468964392503645, 0.9470210760422302, 0.9471115934324366, 0.9471570622389974, 0.9474682331491988, 0.9474576190038436, 0.9476292083747798, 0.9477253349781872, 0.9476999968089687, 0.9479965120347831, 0.9478844438082484, 0.9480675465119761, 0.9479379376383996, 0.9480199920760632, 0.9482612198463151, 0.9483771450700085, 0.948282680327433, 0.9482921252036945, 0.9482632591739127, 0.9486202539624098, 0.9485470057578256, 0.9486795336483568, 0.9485752055051966, 0.9488011587263088, 0.948779411095156, 0.9489093027705913, 0.9487786782927963, 0.9490233863960121, 0.9488972846480804, 0.949046331650105, 0.9491110662467187, 0.9492536404525773, 0.9491223968021942, 0.9492966271816645, 0.9492431546691202, 0.949278779496217, 0.9493305242601426, 0.9492550817218025, 0.9494925820881356, 0.9495267642992268, 0.9495278777346602, 0.9495890178023411, 0.949498148704602, 0.9495484730661503, 0.9495752078464613, 0.9498473420185345, 0.9497989443717688, 0.9498095439664005, 0.9498341074346518, 0.9499657467195911, 0.9498208474048684, 0.9498622373308542, 0.9498821931176439, 0.9499854566942532, 0.9500044560691896, 0.9501566748210978, 0.9500957735183109, 0.9501633235782229, 0.9501239269749217, 0.9501938046283699, 0.9501212246796417, 0.9502520003926102, 0.9502993774603161, 0.9503482650657273, 0.9503709877932477, 0.9501960470614196, 0.9502933039652469, 0.9505907959310504, 0.9504300211558403, 0.9505024727096881, 0.9504766643437624, 0.9504931196343642, 0.9504820570881534, 0.9506768365523302, 0.950541577622381, 0.9504613689222778, 0.950616714331669, 0.9507584637913066, 0.95055623277905, 0.9507176505181333, 0.9508034695968146, 0.9509224078812019, 0.9508809487527008, 0.9508116502367372, 0.9508218048386915, 0.9509288197919077], 'mDice': [0.125098003920559, 0.4008791741355807, 0.4878866833140025, 0.5328962378788619, 0.5644111578220219, 0.5888746362610694, 0.6074347371359345, 0.6213435868566947, 0.6316654920072273, 0.638335542579666, 0.6480807572133227, 0.6550548807409079, 0.6609397840260206, 0.6666593410361246, 0.6706930196264359, 0.674826088272029, 0.6783328541011419, 0.6830227581500171, 0.6868894183579641, 0.690296502353234, 0.6907197995829228, 0.6953766853576501, 0.6982215539914133, 0.7003735292334954, 0.7035284063357176, 0.7058654792918102, 0.7059594357100556, 0.7082614416314438, 0.7121249490488745, 0.7138366571961762, 0.7149456016012282, 0.7167532472145203, 0.717884658887621, 0.7192089942222172, 0.7218374343174779, 0.720557552460077, 0.7244961798372473, 0.7237613626449055, 0.7261695282645939, 0.7264372577122368, 0.7265902244328991, 0.7273053520721647, 0.7289362018270861, 0.6717724667355812, 0.7184224041539738, 0.7263669798781618, 0.7280103695532234, 0.7310297802828626, 0.7320327655334353, 0.7338720524617802, 0.7337851809815464, 0.7358669025876211, 0.7359899930174276, 0.7379430919448619, 0.7384901702222619, 0.7381127639954945, 0.740146366914216, 0.7397394361700902, 0.7411465113875194, 0.7403151060309476, 0.7416031362660134, 0.7433836645694343, 0.744101020437341, 0.7438373184067775, 0.7433127615544823, 0.7433664768392789, 0.7465949098221504, 0.7466688079443913, 0.747428765884462, 0.7470892457782612, 0.7484592268038839, 0.7477778277251593, 0.7486916430089061, 0.7491019605040099, 0.7500064474931889, 0.749348197274242, 0.7506727079376352, 0.7513010318149755, 0.7528541397313994, 0.7524541740563483, 0.7529425065829439, 0.752850189712955, 0.7530801180795826, 0.753998845197239, 0.7532863851777853, 0.7548877575801416, 0.7560489458273909, 0.7559213478286185, 0.756321536112698, 0.7557314760040931, 0.7562547127918862, 0.7561627893136522, 0.7576342561879765, 0.7585147329442321, 0.7589649949183292, 0.7591735696942122, 0.7595134607641545, 0.7579192809487779, 0.7589472492253726, 0.7584631872564117, 0.7606966212525157, 0.7599925369637199, 0.7603982583321868, 0.7610450815606973, 0.7616661972394017, 0.7617275164948171, 0.7620347595672199, 0.7620849073796235, 0.7628208974251435, 0.7627880252903924, 0.7632907763526172, 0.7641428093908899, 0.7628616969666555, 0.763515746786972, 0.7658785402274578, 0.7643640000783, 0.7654119477460692, 0.7647250086126827, 0.7654574817917635, 0.7647820215685653, 0.766356181352987, 0.7660053453574726, 0.7655948871045956, 0.766747274016648, 0.7670244812404693, 0.7656275892481971, 0.7676525557820651, 0.7678148563603221, 0.7679381478121939, 0.7675250777346857, 0.7683317800031249, 0.7684338985966611, 0.768891615724911]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.09s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.88s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.73s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:38,  1.82s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:51,  1.66s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:43,  1.64s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:12,  1.54s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:27,  1.60s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:12,  1.55s/it]predicting train subjects:   2%|▏         | 7/285 [00:10<07:31,  1.62s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:26,  1.61s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:48,  1.70s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:04,  1.76s/it]predicting train subjects:   4%|▍         | 11/285 [00:17<07:38,  1.67s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<07:58,  1.75s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:43,  1.70s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<07:49,  1.73s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<08:00,  1.78s/it]predicting train subjects:   6%|▌         | 16/285 [00:26<08:08,  1.82s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<07:47,  1.75s/it]predicting train subjects:   6%|▋         | 18/285 [00:30<07:48,  1.75s/it]predicting train subjects:   7%|▋         | 19/285 [00:31<07:29,  1.69s/it]predicting train subjects:   7%|▋         | 20/285 [00:33<07:35,  1.72s/it]predicting train subjects:   7%|▋         | 21/285 [00:35<07:52,  1.79s/it]predicting train subjects:   8%|▊         | 22/285 [00:37<07:29,  1.71s/it]predicting train subjects:   8%|▊         | 23/285 [00:38<07:31,  1.72s/it]predicting train subjects:   8%|▊         | 24/285 [00:40<07:16,  1.67s/it]predicting train subjects:   9%|▉         | 25/285 [00:42<07:38,  1.76s/it]predicting train subjects:   9%|▉         | 26/285 [00:44<07:48,  1.81s/it]predicting train subjects:   9%|▉         | 27/285 [00:45<07:34,  1.76s/it]predicting train subjects:  10%|▉         | 28/285 [00:47<07:37,  1.78s/it]predicting train subjects:  10%|█         | 29/285 [00:49<07:25,  1.74s/it]predicting train subjects:  11%|█         | 30/285 [00:51<07:32,  1.78s/it]predicting train subjects:  11%|█         | 31/285 [00:53<07:43,  1.82s/it]predicting train subjects:  11%|█         | 32/285 [00:54<07:25,  1.76s/it]predicting train subjects:  12%|█▏        | 33/285 [00:56<07:22,  1.75s/it]predicting train subjects:  12%|█▏        | 34/285 [00:58<07:14,  1.73s/it]predicting train subjects:  12%|█▏        | 35/285 [01:00<07:25,  1.78s/it]predicting train subjects:  13%|█▎        | 36/285 [01:01<07:10,  1.73s/it]predicting train subjects:  13%|█▎        | 37/285 [01:03<07:12,  1.74s/it]predicting train subjects:  13%|█▎        | 38/285 [01:05<07:16,  1.77s/it]predicting train subjects:  14%|█▎        | 39/285 [01:06<06:52,  1.67s/it]predicting train subjects:  14%|█▍        | 40/285 [01:08<06:52,  1.69s/it]predicting train subjects:  14%|█▍        | 41/285 [01:10<06:38,  1.63s/it]predicting train subjects:  15%|█▍        | 42/285 [01:11<06:31,  1.61s/it]predicting train subjects:  15%|█▌        | 43/285 [01:13<06:37,  1.64s/it]predicting train subjects:  15%|█▌        | 44/285 [01:15<06:58,  1.73s/it]predicting train subjects:  16%|█▌        | 45/285 [01:16<06:46,  1.69s/it]predicting train subjects:  16%|█▌        | 46/285 [01:18<06:50,  1.72s/it]predicting train subjects:  16%|█▋        | 47/285 [01:20<06:30,  1.64s/it]predicting train subjects:  17%|█▋        | 48/285 [01:21<06:43,  1.70s/it]predicting train subjects:  17%|█▋        | 49/285 [01:23<07:02,  1.79s/it]predicting train subjects:  18%|█▊        | 50/285 [01:25<07:02,  1.80s/it]predicting train subjects:  18%|█▊        | 51/285 [01:27<07:09,  1.83s/it]predicting train subjects:  18%|█▊        | 52/285 [01:29<06:50,  1.76s/it]predicting train subjects:  19%|█▊        | 53/285 [01:31<06:50,  1.77s/it]predicting train subjects:  19%|█▉        | 54/285 [01:32<06:59,  1.82s/it]predicting train subjects:  19%|█▉        | 55/285 [01:34<06:42,  1.75s/it]predicting train subjects:  20%|█▉        | 56/285 [01:36<06:39,  1.74s/it]predicting train subjects:  20%|██        | 57/285 [01:37<06:30,  1.71s/it]predicting train subjects:  20%|██        | 58/285 [01:39<06:38,  1.75s/it]predicting train subjects:  21%|██        | 59/285 [01:41<06:50,  1.82s/it]predicting train subjects:  21%|██        | 60/285 [01:43<06:54,  1.84s/it]predicting train subjects:  21%|██▏       | 61/285 [01:45<06:35,  1.77s/it]predicting train subjects:  22%|██▏       | 62/285 [01:47<06:35,  1.77s/it]predicting train subjects:  22%|██▏       | 63/285 [01:48<06:39,  1.80s/it]predicting train subjects:  22%|██▏       | 64/285 [01:50<06:28,  1.76s/it]predicting train subjects:  23%|██▎       | 65/285 [01:52<06:28,  1.77s/it]predicting train subjects:  23%|██▎       | 66/285 [01:54<06:25,  1.76s/it]predicting train subjects:  24%|██▎       | 67/285 [01:55<06:25,  1.77s/it]predicting train subjects:  24%|██▍       | 68/285 [01:57<06:11,  1.71s/it]predicting train subjects:  24%|██▍       | 69/285 [01:59<06:13,  1.73s/it]predicting train subjects:  25%|██▍       | 70/285 [02:01<06:19,  1.77s/it]predicting train subjects:  25%|██▍       | 71/285 [02:02<06:18,  1.77s/it]predicting train subjects:  25%|██▌       | 72/285 [02:04<06:05,  1.72s/it]predicting train subjects:  26%|██▌       | 73/285 [02:06<06:07,  1.73s/it]predicting train subjects:  26%|██▌       | 74/285 [02:07<06:04,  1.73s/it]predicting train subjects:  26%|██▋       | 75/285 [02:09<06:03,  1.73s/it]predicting train subjects:  27%|██▋       | 76/285 [02:11<06:05,  1.75s/it]predicting train subjects:  27%|██▋       | 77/285 [02:13<05:54,  1.71s/it]predicting train subjects:  27%|██▋       | 78/285 [02:14<05:47,  1.68s/it]predicting train subjects:  28%|██▊       | 79/285 [02:16<05:49,  1.70s/it]predicting train subjects:  28%|██▊       | 80/285 [02:18<05:52,  1.72s/it]predicting train subjects:  28%|██▊       | 81/285 [02:19<05:39,  1.66s/it]predicting train subjects:  29%|██▉       | 82/285 [02:21<05:50,  1.72s/it]predicting train subjects:  29%|██▉       | 83/285 [02:23<05:37,  1.67s/it]predicting train subjects:  29%|██▉       | 84/285 [02:24<05:31,  1.65s/it]predicting train subjects:  30%|██▉       | 85/285 [02:26<05:48,  1.74s/it]predicting train subjects:  30%|███       | 86/285 [02:28<05:45,  1.74s/it]predicting train subjects:  31%|███       | 87/285 [02:30<05:42,  1.73s/it]predicting train subjects:  31%|███       | 88/285 [02:31<05:35,  1.70s/it]predicting train subjects:  31%|███       | 89/285 [02:33<05:34,  1.70s/it]predicting train subjects:  32%|███▏      | 90/285 [02:35<05:35,  1.72s/it]predicting train subjects:  32%|███▏      | 91/285 [02:36<05:25,  1.68s/it]predicting train subjects:  32%|███▏      | 92/285 [02:38<05:33,  1.73s/it]predicting train subjects:  33%|███▎      | 93/285 [02:40<05:21,  1.68s/it]predicting train subjects:  33%|███▎      | 94/285 [02:41<05:24,  1.70s/it]predicting train subjects:  33%|███▎      | 95/285 [02:43<05:25,  1.71s/it]predicting train subjects:  34%|███▎      | 96/285 [02:45<05:22,  1.71s/it]predicting train subjects:  34%|███▍      | 97/285 [02:47<05:23,  1.72s/it]predicting train subjects:  34%|███▍      | 98/285 [02:48<05:22,  1.72s/it]predicting train subjects:  35%|███▍      | 99/285 [02:50<05:25,  1.75s/it]predicting train subjects:  35%|███▌      | 100/285 [02:52<05:27,  1.77s/it]predicting train subjects:  35%|███▌      | 101/285 [02:54<05:12,  1.70s/it]predicting train subjects:  36%|███▌      | 102/285 [02:56<05:27,  1.79s/it]predicting train subjects:  36%|███▌      | 103/285 [02:58<05:33,  1.83s/it]predicting train subjects:  36%|███▋      | 104/285 [02:59<05:33,  1.84s/it]predicting train subjects:  37%|███▋      | 105/285 [03:01<05:40,  1.89s/it]predicting train subjects:  37%|███▋      | 106/285 [03:03<05:29,  1.84s/it]predicting train subjects:  38%|███▊      | 107/285 [03:05<05:31,  1.86s/it]predicting train subjects:  38%|███▊      | 108/285 [03:07<05:23,  1.83s/it]predicting train subjects:  38%|███▊      | 109/285 [03:09<05:25,  1.85s/it]predicting train subjects:  39%|███▊      | 110/285 [03:11<05:26,  1.87s/it]predicting train subjects:  39%|███▉      | 111/285 [03:12<05:19,  1.84s/it]predicting train subjects:  39%|███▉      | 112/285 [03:14<05:18,  1.84s/it]predicting train subjects:  40%|███▉      | 113/285 [03:16<05:17,  1.85s/it]predicting train subjects:  40%|████      | 114/285 [03:18<05:16,  1.85s/it]predicting train subjects:  40%|████      | 115/285 [03:20<05:18,  1.87s/it]predicting train subjects:  41%|████      | 116/285 [03:22<05:22,  1.91s/it]predicting train subjects:  41%|████      | 117/285 [03:23<05:05,  1.82s/it]predicting train subjects:  41%|████▏     | 118/285 [03:25<04:59,  1.80s/it]predicting train subjects:  42%|████▏     | 119/285 [03:27<05:06,  1.85s/it]predicting train subjects:  42%|████▏     | 120/285 [03:29<04:59,  1.82s/it]predicting train subjects:  42%|████▏     | 121/285 [03:31<04:59,  1.83s/it]predicting train subjects:  43%|████▎     | 122/285 [03:32<04:51,  1.79s/it]predicting train subjects:  43%|████▎     | 123/285 [03:34<04:42,  1.74s/it]predicting train subjects:  44%|████▎     | 124/285 [03:36<04:43,  1.76s/it]predicting train subjects:  44%|████▍     | 125/285 [03:38<04:36,  1.73s/it]predicting train subjects:  44%|████▍     | 126/285 [03:39<04:26,  1.67s/it]predicting train subjects:  45%|████▍     | 127/285 [03:41<04:20,  1.65s/it]predicting train subjects:  45%|████▍     | 128/285 [03:42<04:26,  1.69s/it]predicting train subjects:  45%|████▌     | 129/285 [03:44<04:19,  1.66s/it]predicting train subjects:  46%|████▌     | 130/285 [03:46<04:14,  1.64s/it]predicting train subjects:  46%|████▌     | 131/285 [03:47<04:18,  1.68s/it]predicting train subjects:  46%|████▋     | 132/285 [03:49<04:26,  1.74s/it]predicting train subjects:  47%|████▋     | 133/285 [03:51<04:26,  1.75s/it]predicting train subjects:  47%|████▋     | 134/285 [03:53<04:11,  1.67s/it]predicting train subjects:  47%|████▋     | 135/285 [03:54<04:03,  1.62s/it]predicting train subjects:  48%|████▊     | 136/285 [03:56<03:56,  1.59s/it]predicting train subjects:  48%|████▊     | 137/285 [03:57<04:05,  1.66s/it]predicting train subjects:  48%|████▊     | 138/285 [03:59<04:03,  1.66s/it]predicting train subjects:  49%|████▉     | 139/285 [04:01<04:18,  1.77s/it]predicting train subjects:  49%|████▉     | 140/285 [04:03<04:16,  1.77s/it]predicting train subjects:  49%|████▉     | 141/285 [04:04<04:03,  1.69s/it]predicting train subjects:  50%|████▉     | 142/285 [04:06<04:01,  1.69s/it]predicting train subjects:  50%|█████     | 143/285 [04:08<03:53,  1.64s/it]predicting train subjects:  51%|█████     | 144/285 [04:09<03:51,  1.64s/it]predicting train subjects:  51%|█████     | 145/285 [04:11<03:52,  1.66s/it]predicting train subjects:  51%|█████     | 146/285 [04:13<03:57,  1.71s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:14<03:47,  1.65s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:16<03:52,  1.70s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:18<03:52,  1.71s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:19<03:46,  1.68s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:21<03:47,  1.70s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:23<03:42,  1.67s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:24<03:37,  1.65s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:26<03:50,  1.76s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:28<03:52,  1.79s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:30<04:03,  1.89s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:32<03:52,  1.82s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:34<03:48,  1.80s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:35<03:43,  1.77s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:37<03:30,  1.68s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:39<03:28,  1.68s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:40<03:27,  1.69s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:42<03:29,  1.72s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:44<03:22,  1.68s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:45<03:16,  1.64s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:47<03:16,  1.65s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:49<03:13,  1.64s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:50<03:08,  1.61s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:52<03:03,  1.58s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:53<02:58,  1.55s/it]predicting train subjects:  60%|██████    | 171/285 [04:55<02:53,  1.52s/it]predicting train subjects:  60%|██████    | 172/285 [04:56<02:57,  1.57s/it]predicting train subjects:  61%|██████    | 173/285 [04:58<02:54,  1.56s/it]predicting train subjects:  61%|██████    | 174/285 [04:59<02:50,  1.53s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:01<02:52,  1.57s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:03<03:00,  1.66s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:04<02:53,  1.60s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:06<02:45,  1.55s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:07<02:44,  1.55s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:09<02:56,  1.68s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:11<03:00,  1.73s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:13<02:57,  1.73s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:14<02:53,  1.70s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:16<02:47,  1.66s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:17<02:39,  1.60s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:19<02:52,  1.74s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:21<02:58,  1.82s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:23<02:59,  1.85s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:25<02:48,  1.75s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:26<02:40,  1.69s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:28<02:44,  1.75s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:30<02:42,  1.75s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:32<02:35,  1.69s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:33<02:29,  1.64s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:35<02:23,  1.60s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:37<02:37,  1.77s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:39<02:44,  1.87s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:41<02:48,  1.93s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:43<02:37,  1.84s/it]predicting train subjects:  70%|███████   | 200/285 [05:44<02:30,  1.77s/it]predicting train subjects:  71%|███████   | 201/285 [05:46<02:36,  1.86s/it]predicting train subjects:  71%|███████   | 202/285 [05:48<02:35,  1.87s/it]predicting train subjects:  71%|███████   | 203/285 [05:50<02:34,  1.89s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:52<02:25,  1.80s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:53<02:19,  1.74s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:55<02:11,  1.67s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:57<02:20,  1.80s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:59<02:25,  1.89s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:01<02:28,  1.96s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:03<02:17,  1.84s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:04<02:09,  1.75s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:06<02:08,  1.75s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:08<02:10,  1.81s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:10<02:05,  1.76s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:12<02:08,  1.84s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:13<01:57,  1.70s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:15<01:59,  1.75s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:17<02:02,  1.82s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:19<02:07,  1.94s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:21<01:59,  1.84s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:22<01:51,  1.74s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:24<01:51,  1.77s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:26<01:44,  1.69s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:27<01:41,  1.66s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:29<01:35,  1.59s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:31<01:42,  1.74s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:33<01:43,  1.78s/it]predicting train subjects:  80%|████████  | 228/285 [06:35<01:45,  1.85s/it]predicting train subjects:  80%|████████  | 229/285 [06:36<01:41,  1.82s/it]predicting train subjects:  81%|████████  | 230/285 [06:38<01:37,  1.77s/it]predicting train subjects:  81%|████████  | 231/285 [06:40<01:34,  1.74s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:42<01:34,  1.79s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:43<01:30,  1.74s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:45<01:33,  1.84s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:47<01:26,  1.73s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:49<01:27,  1.79s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:51<01:27,  1.82s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:52<01:25,  1.83s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:54<01:22,  1.80s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:56<01:17,  1.73s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:57<01:13,  1.67s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:59<01:10,  1.64s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:00<01:05,  1.56s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:02<01:09,  1.70s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:04<01:05,  1.65s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:06<01:11,  1.83s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:08<01:11,  1.89s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:10<01:08,  1.86s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:11<01:01,  1.71s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:13<00:58,  1.68s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:14<00:55,  1.64s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:16<00:51,  1.56s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:17<00:50,  1.59s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:19<00:49,  1.59s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:20<00:46,  1.56s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:22<00:42,  1.46s/it]predicting train subjects:  90%|█████████ | 257/285 [07:23<00:39,  1.42s/it]predicting train subjects:  91%|█████████ | 258/285 [07:25<00:40,  1.49s/it]predicting train subjects:  91%|█████████ | 259/285 [07:26<00:39,  1.53s/it]predicting train subjects:  91%|█████████ | 260/285 [07:28<00:36,  1.46s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:29<00:34,  1.44s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:30<00:32,  1.41s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:32<00:30,  1.39s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:33<00:31,  1.50s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:35<00:30,  1.54s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:36<00:27,  1.45s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:38<00:25,  1.41s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:39<00:25,  1.49s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:41<00:24,  1.52s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:42<00:21,  1.46s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:44<00:20,  1.43s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:45<00:19,  1.49s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:46<00:17,  1.43s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:48<00:15,  1.39s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:49<00:14,  1.49s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:51<00:14,  1.56s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:53<00:11,  1.49s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:54<00:10,  1.47s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:56<00:09,  1.51s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:57<00:07,  1.48s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:58<00:05,  1.45s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:00<00:04,  1.40s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:01<00:03,  1.51s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:03<00:01,  1.57s/it]predicting train subjects: 100%|██████████| 285/285 [08:05<00:00,  1.63s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:34,  1.60s/it]Loading train:   1%|          | 2/285 [00:02<06:54,  1.47s/it]Loading train:   1%|          | 3/285 [00:04<06:42,  1.43s/it]Loading train:   1%|▏         | 4/285 [00:05<06:02,  1.29s/it]Loading train:   2%|▏         | 5/285 [00:06<06:22,  1.37s/it]Loading train:   2%|▏         | 6/285 [00:07<06:03,  1.30s/it]Loading train:   2%|▏         | 7/285 [00:09<06:20,  1.37s/it]Loading train:   3%|▎         | 8/285 [00:10<06:11,  1.34s/it]Loading train:   3%|▎         | 9/285 [00:12<06:39,  1.45s/it]Loading train:   4%|▎         | 10/285 [00:13<05:57,  1.30s/it]Loading train:   4%|▍         | 11/285 [00:14<05:20,  1.17s/it]Loading train:   4%|▍         | 12/285 [00:14<04:57,  1.09s/it]Loading train:   5%|▍         | 13/285 [00:15<04:25,  1.02it/s]Loading train:   5%|▍         | 14/285 [00:16<04:30,  1.00it/s]Loading train:   5%|▌         | 15/285 [00:17<04:21,  1.03it/s]Loading train:   6%|▌         | 16/285 [00:18<04:14,  1.06it/s]Loading train:   6%|▌         | 17/285 [00:19<03:57,  1.13it/s]Loading train:   6%|▋         | 18/285 [00:20<04:00,  1.11it/s]Loading train:   7%|▋         | 19/285 [00:20<03:47,  1.17it/s]Loading train:   7%|▋         | 20/285 [00:21<03:50,  1.15it/s]Loading train:   7%|▋         | 21/285 [00:22<03:52,  1.14it/s]Loading train:   8%|▊         | 22/285 [00:23<03:35,  1.22it/s]Loading train:   8%|▊         | 23/285 [00:24<03:35,  1.21it/s]Loading train:   8%|▊         | 24/285 [00:25<03:29,  1.25it/s]Loading train:   9%|▉         | 25/285 [00:25<03:38,  1.19it/s]Loading train:   9%|▉         | 26/285 [00:26<03:39,  1.18it/s]Loading train:   9%|▉         | 27/285 [00:27<03:26,  1.25it/s]Loading train:  10%|▉         | 28/285 [00:28<03:35,  1.19it/s]Loading train:  10%|█         | 29/285 [00:29<03:47,  1.12it/s]Loading train:  11%|█         | 30/285 [00:30<03:54,  1.09it/s]Loading train:  11%|█         | 31/285 [00:31<04:00,  1.05it/s]Loading train:  11%|█         | 32/285 [00:32<04:02,  1.04it/s]Loading train:  12%|█▏        | 33/285 [00:33<04:00,  1.05it/s]Loading train:  12%|█▏        | 34/285 [00:34<03:57,  1.06it/s]Loading train:  12%|█▏        | 35/285 [00:35<03:58,  1.05it/s]Loading train:  13%|█▎        | 36/285 [00:36<03:43,  1.11it/s]Loading train:  13%|█▎        | 37/285 [00:36<03:44,  1.10it/s]Loading train:  13%|█▎        | 38/285 [00:37<03:42,  1.11it/s]Loading train:  14%|█▎        | 39/285 [00:38<03:25,  1.19it/s]Loading train:  14%|█▍        | 40/285 [00:39<03:34,  1.14it/s]Loading train:  14%|█▍        | 41/285 [00:40<03:25,  1.19it/s]Loading train:  15%|█▍        | 42/285 [00:41<03:15,  1.24it/s]Loading train:  15%|█▌        | 43/285 [00:41<03:23,  1.19it/s]Loading train:  15%|█▌        | 44/285 [00:42<03:30,  1.14it/s]Loading train:  16%|█▌        | 45/285 [00:43<03:17,  1.22it/s]Loading train:  16%|█▌        | 46/285 [00:44<03:39,  1.09it/s]Loading train:  16%|█▋        | 47/285 [00:45<03:26,  1.15it/s]Loading train:  17%|█▋        | 48/285 [00:46<03:29,  1.13it/s]Loading train:  17%|█▋        | 49/285 [00:47<03:30,  1.12it/s]Loading train:  18%|█▊        | 50/285 [00:48<03:30,  1.12it/s]Loading train:  18%|█▊        | 51/285 [00:49<03:28,  1.12it/s]Loading train:  18%|█▊        | 52/285 [00:49<03:12,  1.21it/s]Loading train:  19%|█▊        | 53/285 [00:50<03:10,  1.22it/s]Loading train:  19%|█▉        | 54/285 [00:51<03:12,  1.20it/s]Loading train:  19%|█▉        | 55/285 [00:52<03:09,  1.21it/s]Loading train:  20%|█▉        | 56/285 [00:53<03:21,  1.14it/s]Loading train:  20%|██        | 57/285 [00:54<03:15,  1.16it/s]Loading train:  20%|██        | 58/285 [00:54<03:19,  1.14it/s]Loading train:  21%|██        | 59/285 [00:55<03:26,  1.09it/s]Loading train:  21%|██        | 60/285 [00:56<03:29,  1.07it/s]Loading train:  21%|██▏       | 61/285 [00:57<03:19,  1.12it/s]Loading train:  22%|██▏       | 62/285 [00:58<03:16,  1.13it/s]Loading train:  22%|██▏       | 63/285 [00:59<03:23,  1.09it/s]Loading train:  22%|██▏       | 64/285 [01:00<03:45,  1.02s/it]Loading train:  23%|██▎       | 65/285 [01:02<04:17,  1.17s/it]Loading train:  23%|██▎       | 66/285 [01:03<04:17,  1.18s/it]Loading train:  24%|██▎       | 67/285 [01:04<03:58,  1.10s/it]Loading train:  24%|██▍       | 68/285 [01:05<03:38,  1.01s/it]Loading train:  24%|██▍       | 69/285 [01:06<03:28,  1.04it/s]Loading train:  25%|██▍       | 70/285 [01:07<03:34,  1.00it/s]Loading train:  25%|██▍       | 71/285 [01:08<03:33,  1.00it/s]Loading train:  25%|██▌       | 72/285 [01:08<03:14,  1.09it/s]Loading train:  26%|██▌       | 73/285 [01:09<03:12,  1.10it/s]Loading train:  26%|██▌       | 74/285 [01:10<03:03,  1.15it/s]Loading train:  26%|██▋       | 75/285 [01:11<03:02,  1.15it/s]Loading train:  27%|██▋       | 76/285 [01:12<03:02,  1.15it/s]Loading train:  27%|██▋       | 77/285 [01:13<02:56,  1.18it/s]Loading train:  27%|██▋       | 78/285 [01:13<02:46,  1.24it/s]Loading train:  28%|██▊       | 79/285 [01:14<02:43,  1.26it/s]Loading train:  28%|██▊       | 80/285 [01:15<02:42,  1.26it/s]Loading train:  28%|██▊       | 81/285 [01:16<02:39,  1.28it/s]Loading train:  29%|██▉       | 82/285 [01:17<02:41,  1.26it/s]Loading train:  29%|██▉       | 83/285 [01:17<02:35,  1.30it/s]Loading train:  29%|██▉       | 84/285 [01:18<02:30,  1.34it/s]Loading train:  30%|██▉       | 85/285 [01:19<02:31,  1.32it/s]Loading train:  30%|███       | 86/285 [01:20<02:39,  1.25it/s]Loading train:  31%|███       | 87/285 [01:20<02:41,  1.23it/s]Loading train:  31%|███       | 88/285 [01:21<02:34,  1.28it/s]Loading train:  31%|███       | 89/285 [01:22<02:39,  1.23it/s]Loading train:  32%|███▏      | 90/285 [01:23<02:43,  1.20it/s]Loading train:  32%|███▏      | 91/285 [01:24<02:42,  1.19it/s]Loading train:  32%|███▏      | 92/285 [01:25<02:48,  1.15it/s]Loading train:  33%|███▎      | 93/285 [01:26<02:49,  1.13it/s]Loading train:  33%|███▎      | 94/285 [01:26<02:46,  1.15it/s]Loading train:  33%|███▎      | 95/285 [01:27<02:47,  1.13it/s]Loading train:  34%|███▎      | 96/285 [01:28<02:50,  1.11it/s]Loading train:  34%|███▍      | 97/285 [01:29<02:49,  1.11it/s]Loading train:  34%|███▍      | 98/285 [01:30<02:45,  1.13it/s]Loading train:  35%|███▍      | 99/285 [01:31<02:43,  1.14it/s]Loading train:  35%|███▌      | 100/285 [01:32<02:50,  1.09it/s]Loading train:  35%|███▌      | 101/285 [01:33<02:43,  1.12it/s]Loading train:  36%|███▌      | 102/285 [01:34<02:44,  1.11it/s]Loading train:  36%|███▌      | 103/285 [01:35<02:38,  1.15it/s]Loading train:  36%|███▋      | 104/285 [01:35<02:34,  1.17it/s]Loading train:  37%|███▋      | 105/285 [01:36<02:34,  1.16it/s]Loading train:  37%|███▋      | 106/285 [01:37<02:29,  1.20it/s]Loading train:  38%|███▊      | 107/285 [01:38<02:30,  1.19it/s]Loading train:  38%|███▊      | 108/285 [01:39<02:28,  1.19it/s]Loading train:  38%|███▊      | 109/285 [01:39<02:26,  1.20it/s]Loading train:  39%|███▊      | 110/285 [01:40<02:33,  1.14it/s]Loading train:  39%|███▉      | 111/285 [01:41<02:24,  1.21it/s]Loading train:  39%|███▉      | 112/285 [01:42<02:21,  1.22it/s]Loading train:  40%|███▉      | 113/285 [01:43<02:22,  1.20it/s]Loading train:  40%|████      | 114/285 [01:44<02:19,  1.23it/s]Loading train:  40%|████      | 115/285 [01:45<02:26,  1.16it/s]Loading train:  41%|████      | 116/285 [01:45<02:27,  1.15it/s]Loading train:  41%|████      | 117/285 [01:46<02:20,  1.19it/s]Loading train:  41%|████▏     | 118/285 [01:47<02:16,  1.23it/s]Loading train:  42%|████▏     | 119/285 [01:48<02:22,  1.16it/s]Loading train:  42%|████▏     | 120/285 [01:49<02:15,  1.22it/s]Loading train:  42%|████▏     | 121/285 [01:50<02:35,  1.06it/s]Loading train:  43%|████▎     | 122/285 [01:51<02:38,  1.03it/s]Loading train:  43%|████▎     | 123/285 [01:52<02:46,  1.03s/it]Loading train:  44%|████▎     | 124/285 [01:53<02:31,  1.06it/s]Loading train:  44%|████▍     | 125/285 [01:54<02:19,  1.15it/s]Loading train:  44%|████▍     | 126/285 [01:54<02:11,  1.21it/s]Loading train:  45%|████▍     | 127/285 [01:55<02:04,  1.27it/s]Loading train:  45%|████▍     | 128/285 [01:56<02:04,  1.26it/s]Loading train:  45%|████▌     | 129/285 [01:57<02:01,  1.28it/s]Loading train:  46%|████▌     | 130/285 [01:57<01:54,  1.35it/s]Loading train:  46%|████▌     | 131/285 [01:58<01:50,  1.40it/s]Loading train:  46%|████▋     | 132/285 [01:59<02:00,  1.27it/s]Loading train:  47%|████▋     | 133/285 [02:00<01:57,  1.30it/s]Loading train:  47%|████▋     | 134/285 [02:00<01:53,  1.33it/s]Loading train:  47%|████▋     | 135/285 [02:01<01:50,  1.35it/s]Loading train:  48%|████▊     | 136/285 [02:02<01:48,  1.38it/s]Loading train:  48%|████▊     | 137/285 [02:02<01:46,  1.39it/s]Loading train:  48%|████▊     | 138/285 [02:03<01:42,  1.44it/s]Loading train:  49%|████▉     | 139/285 [02:04<01:39,  1.46it/s]Loading train:  49%|████▉     | 140/285 [02:04<01:44,  1.38it/s]Loading train:  49%|████▉     | 141/285 [02:05<01:44,  1.37it/s]Loading train:  50%|████▉     | 142/285 [02:06<01:44,  1.36it/s]Loading train:  50%|█████     | 143/285 [02:07<01:40,  1.41it/s]Loading train:  51%|█████     | 144/285 [02:07<01:40,  1.40it/s]Loading train:  51%|█████     | 145/285 [02:08<01:37,  1.44it/s]Loading train:  51%|█████     | 146/285 [02:09<01:38,  1.41it/s]Loading train:  52%|█████▏    | 147/285 [02:09<01:32,  1.49it/s]Loading train:  52%|█████▏    | 148/285 [02:10<01:31,  1.50it/s]Loading train:  52%|█████▏    | 149/285 [02:11<01:29,  1.53it/s]Loading train:  53%|█████▎    | 150/285 [02:11<01:30,  1.49it/s]Loading train:  53%|█████▎    | 151/285 [02:12<01:36,  1.40it/s]Loading train:  53%|█████▎    | 152/285 [02:13<01:33,  1.42it/s]Loading train:  54%|█████▎    | 153/285 [02:13<01:29,  1.47it/s]Loading train:  54%|█████▍    | 154/285 [02:14<01:35,  1.37it/s]Loading train:  54%|█████▍    | 155/285 [02:15<01:35,  1.36it/s]Loading train:  55%|█████▍    | 156/285 [02:16<01:38,  1.31it/s]Loading train:  55%|█████▌    | 157/285 [02:17<01:34,  1.35it/s]Loading train:  55%|█████▌    | 158/285 [02:17<01:31,  1.38it/s]Loading train:  56%|█████▌    | 159/285 [02:18<01:31,  1.37it/s]Loading train:  56%|█████▌    | 160/285 [02:19<01:33,  1.33it/s]Loading train:  56%|█████▋    | 161/285 [02:20<01:33,  1.32it/s]Loading train:  57%|█████▋    | 162/285 [02:20<01:36,  1.28it/s]Loading train:  57%|█████▋    | 163/285 [02:21<01:35,  1.27it/s]Loading train:  58%|█████▊    | 164/285 [02:22<01:32,  1.31it/s]Loading train:  58%|█████▊    | 165/285 [02:23<01:31,  1.32it/s]Loading train:  58%|█████▊    | 166/285 [02:23<01:29,  1.32it/s]Loading train:  59%|█████▊    | 167/285 [02:24<01:31,  1.29it/s]Loading train:  59%|█████▉    | 168/285 [02:25<01:27,  1.34it/s]Loading train:  59%|█████▉    | 169/285 [02:26<01:25,  1.36it/s]Loading train:  60%|█████▉    | 170/285 [02:26<01:27,  1.32it/s]Loading train:  60%|██████    | 171/285 [02:27<01:24,  1.35it/s]Loading train:  60%|██████    | 172/285 [02:28<01:22,  1.37it/s]Loading train:  61%|██████    | 173/285 [02:28<01:20,  1.39it/s]Loading train:  61%|██████    | 174/285 [02:29<01:16,  1.45it/s]Loading train:  61%|██████▏   | 175/285 [02:30<01:17,  1.42it/s]Loading train:  62%|██████▏   | 176/285 [02:31<01:19,  1.38it/s]Loading train:  62%|██████▏   | 177/285 [02:31<01:18,  1.38it/s]Loading train:  62%|██████▏   | 178/285 [02:32<01:18,  1.37it/s]Loading train:  63%|██████▎   | 179/285 [02:33<01:17,  1.38it/s]Loading train:  63%|██████▎   | 180/285 [02:34<01:20,  1.31it/s]Loading train:  64%|██████▎   | 181/285 [02:35<01:21,  1.27it/s]Loading train:  64%|██████▍   | 182/285 [02:35<01:19,  1.29it/s]Loading train:  64%|██████▍   | 183/285 [02:36<01:15,  1.36it/s]Loading train:  65%|██████▍   | 184/285 [02:37<01:11,  1.41it/s]Loading train:  65%|██████▍   | 185/285 [02:37<01:07,  1.47it/s]Loading train:  65%|██████▌   | 186/285 [02:38<01:13,  1.34it/s]Loading train:  66%|██████▌   | 187/285 [02:39<01:18,  1.25it/s]Loading train:  66%|██████▌   | 188/285 [02:40<01:23,  1.16it/s]Loading train:  66%|██████▋   | 189/285 [02:41<01:17,  1.24it/s]Loading train:  67%|██████▋   | 190/285 [02:41<01:14,  1.28it/s]Loading train:  67%|██████▋   | 191/285 [02:42<01:13,  1.27it/s]Loading train:  67%|██████▋   | 192/285 [02:43<01:15,  1.23it/s]Loading train:  68%|██████▊   | 193/285 [02:44<01:09,  1.32it/s]Loading train:  68%|██████▊   | 194/285 [02:44<01:08,  1.33it/s]Loading train:  68%|██████▊   | 195/285 [02:45<01:07,  1.33it/s]Loading train:  69%|██████▉   | 196/285 [02:46<01:09,  1.27it/s]Loading train:  69%|██████▉   | 197/285 [02:47<01:11,  1.23it/s]Loading train:  69%|██████▉   | 198/285 [02:48<01:11,  1.21it/s]Loading train:  70%|██████▉   | 199/285 [02:48<01:07,  1.27it/s]Loading train:  70%|███████   | 200/285 [02:49<01:05,  1.30it/s]Loading train:  71%|███████   | 201/285 [02:50<01:07,  1.25it/s]Loading train:  71%|███████   | 202/285 [02:51<01:03,  1.30it/s]Loading train:  71%|███████   | 203/285 [02:52<01:02,  1.32it/s]Loading train:  72%|███████▏  | 204/285 [02:52<00:58,  1.38it/s]Loading train:  72%|███████▏  | 205/285 [02:53<00:58,  1.37it/s]Loading train:  72%|███████▏  | 206/285 [02:54<00:56,  1.39it/s]Loading train:  73%|███████▎  | 207/285 [02:54<00:58,  1.34it/s]Loading train:  73%|███████▎  | 208/285 [02:55<01:00,  1.28it/s]Loading train:  73%|███████▎  | 209/285 [02:56<01:01,  1.23it/s]Loading train:  74%|███████▎  | 210/285 [02:57<00:57,  1.30it/s]Loading train:  74%|███████▍  | 211/285 [02:58<00:58,  1.26it/s]Loading train:  74%|███████▍  | 212/285 [02:58<00:57,  1.27it/s]Loading train:  75%|███████▍  | 213/285 [02:59<00:55,  1.30it/s]Loading train:  75%|███████▌  | 214/285 [03:00<00:51,  1.39it/s]Loading train:  75%|███████▌  | 215/285 [03:01<00:53,  1.31it/s]Loading train:  76%|███████▌  | 216/285 [03:01<00:49,  1.38it/s]Loading train:  76%|███████▌  | 217/285 [03:02<00:52,  1.30it/s]Loading train:  76%|███████▋  | 218/285 [03:03<00:54,  1.23it/s]Loading train:  77%|███████▋  | 219/285 [03:04<00:55,  1.18it/s]Loading train:  77%|███████▋  | 220/285 [03:05<00:51,  1.25it/s]Loading train:  78%|███████▊  | 221/285 [03:05<00:49,  1.30it/s]Loading train:  78%|███████▊  | 222/285 [03:06<00:47,  1.33it/s]Loading train:  78%|███████▊  | 223/285 [03:07<00:44,  1.38it/s]Loading train:  79%|███████▊  | 224/285 [03:08<00:44,  1.36it/s]Loading train:  79%|███████▉  | 225/285 [03:08<00:43,  1.39it/s]Loading train:  79%|███████▉  | 226/285 [03:09<00:45,  1.29it/s]Loading train:  80%|███████▉  | 227/285 [03:10<00:45,  1.26it/s]Loading train:  80%|████████  | 228/285 [03:11<00:47,  1.20it/s]Loading train:  80%|████████  | 229/285 [03:12<00:45,  1.24it/s]Loading train:  81%|████████  | 230/285 [03:12<00:41,  1.33it/s]Loading train:  81%|████████  | 231/285 [03:13<00:39,  1.36it/s]Loading train:  81%|████████▏ | 232/285 [03:14<00:40,  1.32it/s]Loading train:  82%|████████▏ | 233/285 [03:14<00:37,  1.38it/s]Loading train:  82%|████████▏ | 234/285 [03:15<00:39,  1.28it/s]Loading train:  82%|████████▏ | 235/285 [03:16<00:38,  1.28it/s]Loading train:  83%|████████▎ | 236/285 [03:17<00:38,  1.26it/s]Loading train:  83%|████████▎ | 237/285 [03:18<00:38,  1.25it/s]Loading train:  84%|████████▎ | 238/285 [03:19<00:37,  1.25it/s]Loading train:  84%|████████▍ | 239/285 [03:19<00:36,  1.26it/s]Loading train:  84%|████████▍ | 240/285 [03:20<00:34,  1.32it/s]Loading train:  85%|████████▍ | 241/285 [03:21<00:32,  1.34it/s]Loading train:  85%|████████▍ | 242/285 [03:21<00:30,  1.41it/s]Loading train:  85%|████████▌ | 243/285 [03:22<00:28,  1.48it/s]Loading train:  86%|████████▌ | 244/285 [03:23<00:30,  1.34it/s]Loading train:  86%|████████▌ | 245/285 [03:24<00:29,  1.35it/s]Loading train:  86%|████████▋ | 246/285 [03:24<00:30,  1.29it/s]Loading train:  87%|████████▋ | 247/285 [03:25<00:30,  1.23it/s]Loading train:  87%|████████▋ | 248/285 [03:26<00:30,  1.23it/s]Loading train:  87%|████████▋ | 249/285 [03:27<00:27,  1.32it/s]Loading train:  88%|████████▊ | 250/285 [03:27<00:26,  1.35it/s]Loading train:  88%|████████▊ | 251/285 [03:28<00:24,  1.41it/s]Loading train:  88%|████████▊ | 252/285 [03:29<00:22,  1.44it/s]Loading train:  89%|████████▉ | 253/285 [03:30<00:24,  1.32it/s]Loading train:  89%|████████▉ | 254/285 [03:31<00:25,  1.23it/s]Loading train:  89%|████████▉ | 255/285 [03:31<00:23,  1.27it/s]Loading train:  90%|████████▉ | 256/285 [03:32<00:22,  1.32it/s]Loading train:  90%|█████████ | 257/285 [03:33<00:21,  1.30it/s]Loading train:  91%|█████████ | 258/285 [03:34<00:22,  1.18it/s]Loading train:  91%|█████████ | 259/285 [03:35<00:22,  1.18it/s]Loading train:  91%|█████████ | 260/285 [03:35<00:20,  1.20it/s]Loading train:  92%|█████████▏| 261/285 [03:36<00:18,  1.28it/s]Loading train:  92%|█████████▏| 262/285 [03:37<00:17,  1.33it/s]Loading train:  92%|█████████▏| 263/285 [03:37<00:16,  1.37it/s]Loading train:  93%|█████████▎| 264/285 [03:38<00:16,  1.28it/s]Loading train:  93%|█████████▎| 265/285 [03:39<00:16,  1.25it/s]Loading train:  93%|█████████▎| 266/285 [03:40<00:14,  1.31it/s]Loading train:  94%|█████████▎| 267/285 [03:41<00:13,  1.36it/s]Loading train:  94%|█████████▍| 268/285 [03:42<00:13,  1.27it/s]Loading train:  94%|█████████▍| 269/285 [03:42<00:12,  1.28it/s]Loading train:  95%|█████████▍| 270/285 [03:43<00:11,  1.33it/s]Loading train:  95%|█████████▌| 271/285 [03:44<00:10,  1.38it/s]Loading train:  95%|█████████▌| 272/285 [03:44<00:09,  1.38it/s]Loading train:  96%|█████████▌| 273/285 [03:45<00:08,  1.42it/s]Loading train:  96%|█████████▌| 274/285 [03:46<00:07,  1.43it/s]Loading train:  96%|█████████▋| 275/285 [03:47<00:07,  1.33it/s]Loading train:  97%|█████████▋| 276/285 [03:47<00:07,  1.27it/s]Loading train:  97%|█████████▋| 277/285 [03:48<00:05,  1.37it/s]Loading train:  98%|█████████▊| 278/285 [03:49<00:04,  1.43it/s]Loading train:  98%|█████████▊| 279/285 [03:49<00:04,  1.42it/s]Loading train:  98%|█████████▊| 280/285 [03:50<00:03,  1.46it/s]Loading train:  99%|█████████▊| 281/285 [03:51<00:02,  1.48it/s]Loading train:  99%|█████████▉| 282/285 [03:51<00:02,  1.48it/s]Loading train:  99%|█████████▉| 283/285 [03:52<00:01,  1.37it/s]Loading train: 100%|█████████▉| 284/285 [03:53<00:00,  1.26it/s]Loading train: 100%|██████████| 285/285 [03:54<00:00,  1.25it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   9%|▉         | 26/285 [00:00<00:00, 259.27it/s]concatenating: train:  17%|█▋        | 49/285 [00:00<00:00, 248.83it/s]concatenating: train:  26%|██▌       | 74/285 [00:00<00:00, 247.75it/s]concatenating: train:  35%|███▌      | 100/285 [00:00<00:00, 249.48it/s]concatenating: train:  45%|████▌     | 129/285 [00:00<00:00, 260.18it/s]concatenating: train:  56%|█████▌    | 160/285 [00:00<00:00, 270.50it/s]concatenating: train:  68%|██████▊   | 193/285 [00:00<00:00, 284.24it/s]concatenating: train:  77%|███████▋  | 220/285 [00:00<00:00, 268.15it/s]concatenating: train:  89%|████████▉ | 253/285 [00:00<00:00, 283.16it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 282.31it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.19s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.18s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.15s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 48.55it/s]2019-07-11 06:10:58.666751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 06:10:58.666887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 06:10:58.666903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 06:10:58.666912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 06:10:58.667371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:10,  4.24it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.13it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.04it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.46it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.77it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  6.61it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.74it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.44it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  7.77it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.27it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.87it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:02,  8.22it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  8.47it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  6.67it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.24it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.49it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  8.65it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  6.88it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.61it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 30)   4080        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 40, 45)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 60)   24360       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 20, 105)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 105)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 105)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 105)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 15)   4065        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 45)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 45)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 30)   12180       dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 30)   120         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 30)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 80, 30)   0           activation_11[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 30)   8130        dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 80, 30)   120         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 80, 30)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 80, 30)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 75)   0           dropout_5[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 80, 13)   988         concatenate_7[0][0]              
==================================================================================================
Total params: 147,418
Trainable params: 48,838
Non-trainable params: 98,580
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 15s - loss: 2.9466 - acc: 0.2524 - mDice: 0.0988 - val_loss: 2.4968 - val_acc: 0.8058 - val_mDice: 0.1936

Epoch 00001: val_mDice improved from -inf to 0.19365, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 10s - loss: 1.1225 - acc: 0.8539 - mDice: 0.3325 - val_loss: 1.6710 - val_acc: 0.9064 - val_mDice: 0.3128

Epoch 00002: val_mDice improved from 0.19365 to 0.31282, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 10s - loss: 0.7030 - acc: 0.8819 - mDice: 0.4784 - val_loss: 1.3012 - val_acc: 0.9137 - val_mDice: 0.4397

Epoch 00003: val_mDice improved from 0.31282 to 0.43968, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 9s - loss: 0.5913 - acc: 0.8901 - mDice: 0.5368 - val_loss: 1.1168 - val_acc: 0.9255 - val_mDice: 0.5311

Epoch 00004: val_mDice improved from 0.43968 to 0.53110, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 10s - loss: 0.5356 - acc: 0.8986 - mDice: 0.5693 - val_loss: 1.0671 - val_acc: 0.9259 - val_mDice: 0.5341

Epoch 00005: val_mDice improved from 0.53110 to 0.53408, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 9s - loss: 0.5026 - acc: 0.9071 - mDice: 0.5895 - val_loss: 1.0134 - val_acc: 0.9341 - val_mDice: 0.5543

Epoch 00006: val_mDice improved from 0.53408 to 0.55426, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 10s - loss: 0.4776 - acc: 0.9146 - mDice: 0.6050 - val_loss: 1.0865 - val_acc: 0.9320 - val_mDice: 0.4923

Epoch 00007: val_mDice did not improve from 0.55426
Epoch 8/300
 - 9s - loss: 0.4572 - acc: 0.9206 - mDice: 0.6177 - val_loss: 1.0236 - val_acc: 0.9399 - val_mDice: 0.5261

Epoch 00008: val_mDice did not improve from 0.55426
Epoch 9/300
 - 10s - loss: 0.4444 - acc: 0.9270 - mDice: 0.6260 - val_loss: 1.0122 - val_acc: 0.9400 - val_mDice: 0.5480

Epoch 00009: val_mDice did not improve from 0.55426
Epoch 10/300
 - 10s - loss: 0.4340 - acc: 0.9294 - mDice: 0.6324 - val_loss: 0.9969 - val_acc: 0.9427 - val_mDice: 0.5408

Epoch 00010: val_mDice did not improve from 0.55426
Epoch 11/300
 - 10s - loss: 0.4222 - acc: 0.9311 - mDice: 0.6403 - val_loss: 0.9722 - val_acc: 0.9432 - val_mDice: 0.5501

Epoch 00011: val_mDice did not improve from 0.55426
Epoch 12/300
 - 10s - loss: 0.4117 - acc: 0.9322 - mDice: 0.6471 - val_loss: 0.9785 - val_acc: 0.9438 - val_mDice: 0.5448

Epoch 00012: val_mDice did not improve from 0.55426
Epoch 13/300
 - 10s - loss: 0.4042 - acc: 0.9329 - mDice: 0.6521 - val_loss: 0.9839 - val_acc: 0.9295 - val_mDice: 0.5373

Epoch 00013: val_mDice did not improve from 0.55426
Epoch 14/300
 - 10s - loss: 0.3993 - acc: 0.9334 - mDice: 0.6557 - val_loss: 0.9876 - val_acc: 0.9424 - val_mDice: 0.5464

Epoch 00014: val_mDice did not improve from 0.55426
Epoch 15/300
 - 9s - loss: 0.3934 - acc: 0.9341 - mDice: 0.6595 - val_loss: 0.9514 - val_acc: 0.9452 - val_mDice: 0.5710

Epoch 00015: val_mDice improved from 0.55426 to 0.57102, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 10s - loss: 0.3912 - acc: 0.9345 - mDice: 0.6612 - val_loss: 0.9445 - val_acc: 0.9403 - val_mDice: 0.5611

Epoch 00016: val_mDice did not improve from 0.57102
Epoch 17/300
 - 9s - loss: 0.3842 - acc: 0.9352 - mDice: 0.6659 - val_loss: 0.9443 - val_acc: 0.9432 - val_mDice: 0.5627

Epoch 00017: val_mDice did not improve from 0.57102
Epoch 18/300
 - 9s - loss: 0.3783 - acc: 0.9357 - mDice: 0.6700 - val_loss: 0.8929 - val_acc: 0.9437 - val_mDice: 0.5661

Epoch 00018: val_mDice did not improve from 0.57102
Epoch 19/300
 - 10s - loss: 0.3764 - acc: 0.9360 - mDice: 0.6713 - val_loss: 0.9242 - val_acc: 0.9417 - val_mDice: 0.5766

Epoch 00019: val_mDice improved from 0.57102 to 0.57658, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 20/300
 - 9s - loss: 0.3715 - acc: 0.9364 - mDice: 0.6746 - val_loss: 0.9200 - val_acc: 0.9431 - val_mDice: 0.5707

Epoch 00020: val_mDice did not improve from 0.57658
Epoch 21/300
 - 9s - loss: 0.3693 - acc: 0.9367 - mDice: 0.6764 - val_loss: 0.9316 - val_acc: 0.9437 - val_mDice: 0.5619

Epoch 00021: val_mDice did not improve from 0.57658
Epoch 22/300
 - 9s - loss: 0.3663 - acc: 0.9370 - mDice: 0.6783 - val_loss: 0.9680 - val_acc: 0.9420 - val_mDice: 0.5276

Epoch 00022: val_mDice did not improve from 0.57658
Epoch 23/300
 - 10s - loss: 0.3636 - acc: 0.9372 - mDice: 0.6804 - val_loss: 0.9222 - val_acc: 0.9414 - val_mDice: 0.5593

Epoch 00023: val_mDice did not improve from 0.57658
Epoch 24/300
 - 9s - loss: 0.3592 - acc: 0.9377 - mDice: 0.6834 - val_loss: 0.8964 - val_acc: 0.9446 - val_mDice: 0.5775

Epoch 00024: val_mDice improved from 0.57658 to 0.57751, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 25/300
 - 9s - loss: 0.3570 - acc: 0.9380 - mDice: 0.6848 - val_loss: 0.8815 - val_acc: 0.9424 - val_mDice: 0.5601

Epoch 00025: val_mDice did not improve from 0.57751
Epoch 26/300
 - 9s - loss: 0.3550 - acc: 0.9382 - mDice: 0.6864 - val_loss: 0.9401 - val_acc: 0.9429 - val_mDice: 0.5517

Epoch 00026: val_mDice did not improve from 0.57751
Epoch 27/300
 - 9s - loss: 0.3514 - acc: 0.9384 - mDice: 0.6889 - val_loss: 0.8987 - val_acc: 0.9424 - val_mDice: 0.5738

Epoch 00027: val_mDice did not improve from 0.57751
Epoch 28/300
 - 9s - loss: 0.3486 - acc: 0.9388 - mDice: 0.6909 - val_loss: 0.9119 - val_acc: 0.9416 - val_mDice: 0.5545

Epoch 00028: val_mDice did not improve from 0.57751
Epoch 29/300
 - 9s - loss: 0.3459 - acc: 0.9391 - mDice: 0.6929 - val_loss: 0.8878 - val_acc: 0.9430 - val_mDice: 0.5746

Epoch 00029: val_mDice did not improve from 0.57751
Epoch 30/300
 - 10s - loss: 0.3450 - acc: 0.9392 - mDice: 0.6935 - val_loss: 0.8934 - val_acc: 0.9400 - val_mDice: 0.5655

Epoch 00030: val_mDice did not improve from 0.57751
Epoch 31/300
 - 9s - loss: 0.3418 - acc: 0.9394 - mDice: 0.6958 - val_loss: 0.8520 - val_acc: 0.9456 - val_mDice: 0.5716

Epoch 00031: val_mDice did not improve from 0.57751
Epoch 32/300
 - 9s - loss: 0.3413 - acc: 0.9396 - mDice: 0.6962 - val_loss: 0.8924 - val_acc: 0.9442 - val_mDice: 0.5527

Epoch 00032: val_mDice did not improve from 0.57751
Epoch 33/300
 - 9s - loss: 0.3388 - acc: 0.9397 - mDice: 0.6979 - val_loss: 0.8487 - val_acc: 0.9444 - val_mDice: 0.5692

Epoch 00033: val_mDice did not improve from 0.57751
Epoch 34/300
 - 9s - loss: 0.3385 - acc: 0.9397 - mDice: 0.6982 - val_loss: 0.9031 - val_acc: 0.9388 - val_mDice: 0.5501

Epoch 00034: val_mDice did not improve from 0.57751
Epoch 35/300
 - 9s - loss: 0.3375 - acc: 0.9398 - mDice: 0.6989 - val_loss: 0.8951 - val_acc: 0.9312 - val_mDice: 0.5504

Epoch 00035: val_mDice did not improve from 0.57751
Epoch 36/300
 - 9s - loss: 0.3335 - acc: 0.9403 - mDice: 0.7018 - val_loss: 0.8910 - val_acc: 0.9445 - val_mDice: 0.5497

Epoch 00036: val_mDice did not improve from 0.57751
Epoch 37/300
 - 9s - loss: 0.3321 - acc: 0.9404 - mDice: 0.7028 - val_loss: 0.8561 - val_acc: 0.9446 - val_mDice: 0.5593

Epoch 00037: val_mDice did not improve from 0.57751
Epoch 38/300
 - 9s - loss: 0.3313 - acc: 0.9405 - mDice: 0.7034 - val_loss: 0.9014 - val_acc: 0.9444 - val_mDice: 0.5478

Epoch 00038: val_mDice did not improve from 0.57751
Epoch 39/300
 - 9s - loss: 0.3292 - acc: 0.9407 - mDice: 0.7049 - val_loss: 0.8506 - val_acc: 0.9458 - val_mDice: 0.5661

Epoch 00039: val_mDice did not improve from 0.57751
Epoch 40/300
 - 9s - loss: 0.3299 - acc: 0.9407 - mDice: 0.7045 - val_loss: 0.8197 - val_acc: 0.9438 - val_mDice: 0.5816

Epoch 00040: val_mDice improved from 0.57751 to 0.58157, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 41/300
 - 10s - loss: 0.3279 - acc: 0.9408 - mDice: 0.7059 - val_loss: 0.8895 - val_acc: 0.9397 - val_mDice: 0.5557

Epoch 00041: val_mDice did not improve from 0.58157
Epoch 42/300
 - 9s - loss: 0.3258 - acc: 0.9409 - mDice: 0.7074 - val_loss: 0.8840 - val_acc: 0.9411 - val_mDice: 0.5541

Epoch 00042: val_mDice did not improve from 0.58157
Epoch 43/300
 - 9s - loss: 0.3252 - acc: 0.9411 - mDice: 0.7079 - val_loss: 0.8429 - val_acc: 0.9350 - val_mDice: 0.5548

Epoch 00043: val_mDice did not improve from 0.58157
Epoch 44/300
 - 9s - loss: 0.3222 - acc: 0.9414 - mDice: 0.7101 - val_loss: 0.8307 - val_acc: 0.9433 - val_mDice: 0.5602

Epoch 00044: val_mDice did not improve from 0.58157
Epoch 45/300
 - 9s - loss: 0.3214 - acc: 0.9414 - mDice: 0.7107 - val_loss: 0.8646 - val_acc: 0.9429 - val_mDice: 0.5417

Epoch 00045: val_mDice did not improve from 0.58157
Epoch 46/300
 - 9s - loss: 0.3205 - acc: 0.9416 - mDice: 0.7113 - val_loss: 0.8431 - val_acc: 0.9419 - val_mDice: 0.5676

Epoch 00046: val_mDice did not improve from 0.58157
Epoch 47/300
 - 9s - loss: 0.3184 - acc: 0.9416 - mDice: 0.7129 - val_loss: 0.8785 - val_acc: 0.9425 - val_mDice: 0.5535

Epoch 00047: val_mDice did not improve from 0.58157
Epoch 48/300
 - 9s - loss: 0.3160 - acc: 0.9418 - mDice: 0.7146 - val_loss: 0.8123 - val_acc: 0.9447 - val_mDice: 0.5607

Epoch 00048: val_mDice did not improve from 0.58157
Epoch 49/300
 - 10s - loss: 0.3164 - acc: 0.9419 - mDice: 0.7144 - val_loss: 0.8019 - val_acc: 0.9438 - val_mDice: 0.5566

Epoch 00049: val_mDice did not improve from 0.58157
Epoch 50/300
 - 9s - loss: 0.3159 - acc: 0.9418 - mDice: 0.7146 - val_loss: 0.8376 - val_acc: 0.9437 - val_mDice: 0.5677

Epoch 00050: val_mDice did not improve from 0.58157
Epoch 51/300
 - 10s - loss: 0.3135 - acc: 0.9421 - mDice: 0.7164 - val_loss: 0.8491 - val_acc: 0.9410 - val_mDice: 0.5512

Epoch 00051: val_mDice did not improve from 0.58157
Epoch 52/300
 - 10s - loss: 0.3144 - acc: 0.9420 - mDice: 0.7159 - val_loss: 0.8295 - val_acc: 0.9431 - val_mDice: 0.5391

Epoch 00052: val_mDice did not improve from 0.58157
Epoch 53/300
 - 9s - loss: 0.3123 - acc: 0.9424 - mDice: 0.7175 - val_loss: 0.8731 - val_acc: 0.9449 - val_mDice: 0.5549

Epoch 00053: val_mDice did not improve from 0.58157
Epoch 54/300
 - 10s - loss: 0.3122 - acc: 0.9425 - mDice: 0.7175 - val_loss: 0.8211 - val_acc: 0.9425 - val_mDice: 0.5512

Epoch 00054: val_mDice did not improve from 0.58157
Epoch 55/300
 - 9s - loss: 0.3104 - acc: 0.9425 - mDice: 0.7188 - val_loss: 0.7719 - val_acc: 0.9440 - val_mDice: 0.5603

Epoch 00055: val_mDice did not improve from 0.58157
Epoch 56/300
 - 10s - loss: 0.3106 - acc: 0.9426 - mDice: 0.7188 - val_loss: 0.8386 - val_acc: 0.9263 - val_mDice: 0.5323

Epoch 00056: val_mDice did not improve from 0.58157
Epoch 57/300
 - 10s - loss: 0.3091 - acc: 0.9427 - mDice: 0.7198 - val_loss: 0.7967 - val_acc: 0.9443 - val_mDice: 0.5603

Epoch 00057: val_mDice did not improve from 0.58157
Epoch 58/300
 - 9s - loss: 0.3099 - acc: 0.9424 - mDice: 0.7193 - val_loss: 0.8225 - val_acc: 0.9432 - val_mDice: 0.5192

Epoch 00058: val_mDice did not improve from 0.58157
Epoch 59/300
 - 10s - loss: 0.3072 - acc: 0.9427 - mDice: 0.7212 - val_loss: 0.7574 - val_acc: 0.9447 - val_mDice: 0.5704

Epoch 00059: val_mDice did not improve from 0.58157
Epoch 60/300
 - 10s - loss: 0.3084 - acc: 0.9426 - mDice: 0.7204 - val_loss: 0.7389 - val_acc: 0.9424 - val_mDice: 0.5741

Epoch 00060: val_mDice did not improve from 0.58157
Epoch 61/300
 - 9s - loss: 0.3064 - acc: 0.9427 - mDice: 0.7218 - val_loss: 0.8119 - val_acc: 0.9384 - val_mDice: 0.5591

Epoch 00061: val_mDice did not improve from 0.58157
Epoch 62/300
 - 10s - loss: 0.3048 - acc: 0.9430 - mDice: 0.7230 - val_loss: 0.8194 - val_acc: 0.9327 - val_mDice: 0.5427

Epoch 00062: val_mDice did not improve from 0.58157
Epoch 63/300
 - 10s - loss: 0.3025 - acc: 0.9432 - mDice: 0.7248 - val_loss: 0.7784 - val_acc: 0.9448 - val_mDice: 0.5583

Epoch 00063: val_mDice did not improve from 0.58157
Epoch 64/300
 - 9s - loss: 0.3054 - acc: 0.9431 - mDice: 0.7226 - val_loss: 0.7762 - val_acc: 0.9441 - val_mDice: 0.5605

Epoch 00064: val_mDice did not improve from 0.58157
Epoch 65/300
 - 10s - loss: 0.3040 - acc: 0.9432 - mDice: 0.7237 - val_loss: 0.7905 - val_acc: 0.9409 - val_mDice: 0.5610

Epoch 00065: val_mDice did not improve from 0.58157
Epoch 66/300
 - 10s - loss: 0.3023 - acc: 0.9432 - mDice: 0.7248 - val_loss: 0.7882 - val_acc: 0.9446 - val_mDice: 0.5602

Epoch 00066: val_mDice did not improve from 0.58157
Epoch 67/300
 - 9s - loss: 0.3014 - acc: 0.9433 - mDice: 0.7256 - val_loss: 0.7785 - val_acc: 0.9449 - val_mDice: 0.5475

Epoch 00067: val_mDice did not improve from 0.58157
Epoch 68/300
 - 10s - loss: 0.3023 - acc: 0.9432 - mDice: 0.7249 - val_loss: 0.8376 - val_acc: 0.9446 - val_mDice: 0.5422

Epoch 00068: val_mDice did not improve from 0.58157
Epoch 69/300
 - 10s - loss: 0.3007 - acc: 0.9434 - mDice: 0.7261 - val_loss: 0.7571 - val_acc: 0.9461 - val_mDice: 0.5645

Epoch 00069: val_mDice did not improve from 0.58157
Epoch 70/300
 - 9s - loss: 0.2989 - acc: 0.9435 - mDice: 0.7274 - val_loss: 0.7501 - val_acc: 0.9441 - val_mDice: 0.5385

Epoch 00070: val_mDice did not improve from 0.58157
Epoch 71/300
 - 9s - loss: 0.2998 - acc: 0.9435 - mDice: 0.7268 - val_loss: 0.7625 - val_acc: 0.9423 - val_mDice: 0.5447

Epoch 00071: val_mDice did not improve from 0.58157
Epoch 72/300
 - 9s - loss: 0.2992 - acc: 0.9435 - mDice: 0.7272 - val_loss: 0.7716 - val_acc: 0.9429 - val_mDice: 0.5494

Epoch 00072: val_mDice did not improve from 0.58157
Epoch 73/300
 - 10s - loss: 0.2989 - acc: 0.9435 - mDice: 0.7276 - val_loss: 0.7626 - val_acc: 0.9442 - val_mDice: 0.5449

Epoch 00073: val_mDice did not improve from 0.58157
Epoch 74/300
 - 10s - loss: 0.2987 - acc: 0.9435 - mDice: 0.7276 - val_loss: 0.7202 - val_acc: 0.9450 - val_mDice: 0.5630

Epoch 00074: val_mDice did not improve from 0.58157
Epoch 75/300
 - 9s - loss: 0.2981 - acc: 0.9436 - mDice: 0.7281 - val_loss: 0.7128 - val_acc: 0.9462 - val_mDice: 0.5703

Epoch 00075: val_mDice did not improve from 0.58157
Epoch 76/300
 - 9s - loss: 0.2961 - acc: 0.9437 - mDice: 0.7296 - val_loss: 0.7192 - val_acc: 0.9414 - val_mDice: 0.5714

Epoch 00076: val_mDice did not improve from 0.58157
Epoch 77/300
 - 9s - loss: 0.2929 - acc: 0.9440 - mDice: 0.7320 - val_loss: 0.6804 - val_acc: 0.9387 - val_mDice: 0.5639

Epoch 00077: val_mDice did not improve from 0.58157
Epoch 78/300
 - 9s - loss: 0.2943 - acc: 0.9439 - mDice: 0.7309 - val_loss: 0.6936 - val_acc: 0.9450 - val_mDice: 0.5511

Epoch 00078: val_mDice did not improve from 0.58157
Epoch 79/300
 - 9s - loss: 0.2945 - acc: 0.9439 - mDice: 0.7309 - val_loss: 0.7154 - val_acc: 0.9454 - val_mDice: 0.5647

Epoch 00079: val_mDice did not improve from 0.58157
Epoch 80/300
 - 9s - loss: 0.2939 - acc: 0.9440 - mDice: 0.7312 - val_loss: 0.7683 - val_acc: 0.9445 - val_mDice: 0.5485

Epoch 00080: val_mDice did not improve from 0.58157
Restoring model weights from the end of the best epoch
Epoch 00080: early stopping
{'val_loss': [2.496756735302153, 1.6710205532255626, 1.3011682941800071, 1.1167585736229306, 1.067112956728254, 1.0133907000223796, 1.086457615806943, 1.0235550857725597, 1.012191341036842, 0.9968822456541515, 0.972215107509068, 0.9784574849264962, 0.9839354242597308, 0.9875782557896206, 0.9513708409808931, 0.9444966770353771, 0.9442801589057559, 0.8928769032160441, 0.9241719132377988, 0.9200399432863507, 0.9316169647943406, 0.9679883207593646, 0.9222398031325567, 0.8963591768628075, 0.8815072491055443, 0.9400897139594668, 0.8986778770174298, 0.9119357835678827, 0.8877859740030198, 0.893398296265375, 0.852040273802621, 0.892419247400193, 0.8487498306092762, 0.9030668167840867, 0.8950593244461786, 0.8910004865555536, 0.8560974257332938, 0.9013809022449312, 0.8505755152021136, 0.8197420778728667, 0.8894879250299363, 0.884015923454648, 0.8429154555002848, 0.8306754543667748, 0.8645879427591959, 0.8431396314076015, 0.8785491557348342, 0.8122809046790713, 0.8019483543577648, 0.8375857273737589, 0.8491270315079462, 0.8294956570579892, 0.8731002580551874, 0.8211154029482887, 0.7719131197248187, 0.8385729108537946, 0.7966639087313697, 0.8225473903474354, 0.7573642333348592, 0.7388556855065482, 0.8119202909015474, 0.8194342908405122, 0.778412591843378, 0.7761610121954055, 0.7904759702228364, 0.7881967226664225, 0.7784578119005475, 0.8376158419109526, 0.7571373326437814, 0.7500942775181362, 0.7624585628509521, 0.7716065020788283, 0.7625918615432012, 0.7201828729538691, 0.7127544993445987, 0.7192039887110392, 0.680434158870152, 0.6935526870545887, 0.7153876622517904, 0.7682548591068813], 'val_acc': [0.805844803651174, 0.9063759304228283, 0.9137179397401356, 0.9255380289895194, 0.9259203388577416, 0.9341346110616412, 0.9320260995910281, 0.9398947102682931, 0.9399862459727696, 0.9427037608055842, 0.9432005342983064, 0.9438163893563407, 0.9294596995626178, 0.942417562007904, 0.945153412364778, 0.940267835344587, 0.9431662304060799, 0.9437477248055595, 0.9416620986802238, 0.943086101895287, 0.9437133641470046, 0.942005489553724, 0.9414057022049314, 0.9445856383868626, 0.9423694922810509, 0.9429120903923398, 0.9423534926914033, 0.9416094308807736, 0.9430082326843625, 0.9399885677155995, 0.945554012343997, 0.9442330400149027, 0.9443956244559515, 0.9387843637239366, 0.9311858699435279, 0.9444711321876162, 0.9445787412779671, 0.9444459648359389, 0.9457577977861676, 0.9438484367870149, 0.939736715384892, 0.9410668327694848, 0.9350091559546334, 0.9432761158261981, 0.9428594594910031, 0.9419230733598981, 0.9425229174750192, 0.9446566133272081, 0.9437889201300484, 0.9437362409773327, 0.9410187942641122, 0.9431387299583072, 0.9449198927198138, 0.9424885312716166, 0.9440109814916339, 0.9262637382461911, 0.9443429736864, 0.9432325732140314, 0.9447458556720189, 0.9423878363200596, 0.9384157742772784, 0.932660250436692, 0.9448328841300238, 0.9440522193908691, 0.9408813998812721, 0.9446314090774173, 0.9449176021984645, 0.9445512663750422, 0.9460668563842773, 0.9441071237836566, 0.9422618803523836, 0.9428731685593015, 0.9442009869075957, 0.9449931070918128, 0.9461561129206703, 0.9414193857283819, 0.9387339722542536, 0.9449954458645412, 0.9454486909366789, 0.9445192359742665], 'val_mDice': [0.19364908693491348, 0.31281923218852, 0.43968001203168006, 0.5311037349913802, 0.5340801874796549, 0.5542596323149545, 0.49234005205688025, 0.5260996171051547, 0.5480261288938069, 0.5408046600364503, 0.5501275105135781, 0.5448074539502462, 0.5373393662628674, 0.5463766005067598, 0.5710220482377779, 0.5611398305211749, 0.5626532185290541, 0.5661466070229099, 0.5765753904623645, 0.5706502607180959, 0.561912922277337, 0.5276390016078949, 0.559317260271027, 0.577507899985427, 0.5601277823249499, 0.5516722479036876, 0.5738132592468035, 0.5544931214480173, 0.5745953156479767, 0.5655167294400079, 0.5715662223242578, 0.5526829464804559, 0.5691539013669604, 0.5500777473761922, 0.5503951571881771, 0.5496952132809729, 0.5592892613439333, 0.5478280364047914, 0.566126229152793, 0.5815741687658287, 0.5556856434614885, 0.5540764848036426, 0.5548459451113429, 0.5602187727178846, 0.5417351335996673, 0.5675738148746037, 0.5535245713378701, 0.560662492400124, 0.556588083150841, 0.5677137130073139, 0.5512328804248855, 0.5390754382879961, 0.5548596032673404, 0.5512188266785372, 0.560332020655984, 0.5322875385837895, 0.5602977474530538, 0.5192361344538984, 0.5704082963722092, 0.5740675234368869, 0.5590903423726559, 0.5426739223656201, 0.5582886817199844, 0.5605292298964092, 0.5609816107011977, 0.5602410332787604, 0.5475383642173949, 0.5422343687996978, 0.5644606912419909, 0.5385078374473822, 0.5447353477634135, 0.5493638130525748, 0.5449147565024239, 0.5629722758063248, 0.5703093500009605, 0.5714071582825411, 0.5639142796751999, 0.5510820694977329, 0.5647245563921475, 0.5485467178126177], 'loss': [2.9465596794691393, 1.12249176240689, 0.7030132092996578, 0.5912781322832072, 0.535649310273887, 0.502613609498329, 0.47756877481788024, 0.45717728989464895, 0.44437469461875684, 0.43401659943819826, 0.4221885925960008, 0.411695183564501, 0.40418631419272283, 0.39930785281455466, 0.393352755386521, 0.3912086699632682, 0.38419000276692783, 0.3783116228253666, 0.37639442629751635, 0.37154238007306273, 0.3692803540934435, 0.3663417583649986, 0.3635507321137097, 0.3592009483411957, 0.3570313569735028, 0.3549715133445994, 0.35139421053146014, 0.3486279776175863, 0.34587315713161904, 0.34496191805880355, 0.3417528341656272, 0.3413458995123187, 0.33877103206209075, 0.3384827439934848, 0.33750474447801393, 0.3334662047612867, 0.33210583905367486, 0.3312664175277182, 0.32916122411219906, 0.32988053001786605, 0.3278836740138836, 0.32582146581459853, 0.3251779921796709, 0.32217164810208976, 0.3213661192169947, 0.3204725812413179, 0.3183930151743399, 0.31603941153602055, 0.31637562034859557, 0.3158584989424912, 0.31347290153146734, 0.3144302431825087, 0.3122937193214721, 0.3122034647663779, 0.31044646623577254, 0.31055408240467774, 0.3090918817018208, 0.30988144086279207, 0.30719898645418653, 0.30835739035516296, 0.3063621605858307, 0.304820851965265, 0.302485742612866, 0.30541208785739, 0.3040319139646707, 0.30233536890207147, 0.3014207982088482, 0.30232398035854, 0.30068421680986573, 0.2989348035419932, 0.2997849780641725, 0.2992165239992136, 0.2988532874679345, 0.29870989985357527, 0.29813976866536596, 0.2960554418741726, 0.29287161888794927, 0.2942818692304138, 0.2944500745606832, 0.2939196393936614], 'acc': [0.2524284323286362, 0.8539078372256108, 0.881937043892526, 0.8901294039949094, 0.8986401392909311, 0.9070885889971902, 0.9145770521092236, 0.9206445515443071, 0.9270236648321841, 0.9294253145198222, 0.9311288343773013, 0.9322431200911642, 0.93291953316952, 0.93335435067341, 0.9341088716225838, 0.9345287452066752, 0.9352044581516598, 0.9356770247353141, 0.9359589057067973, 0.936434953215496, 0.9366637971995537, 0.9369561091102753, 0.9371521245061214, 0.9376894085076771, 0.9379924473009611, 0.9382360970695882, 0.9383896362903331, 0.9388280965837413, 0.9391076839082798, 0.9392128861292907, 0.9394442310493208, 0.939629074958149, 0.9397336944279837, 0.939748619525263, 0.9398271928684823, 0.9402516555965394, 0.940405817431293, 0.9405146990066919, 0.9407085337251833, 0.9407109181293063, 0.9408295846684075, 0.9408671676549513, 0.9410794482930722, 0.9413745620702534, 0.9414030395768523, 0.9415721711060756, 0.9416374018685492, 0.9417690395366624, 0.9418700260304292, 0.9417501784184545, 0.9420729862119919, 0.9419997625321535, 0.9423714833657636, 0.9424978642765212, 0.9424813419999887, 0.9425693277635164, 0.9426958442699571, 0.9424204687426861, 0.9427108375902509, 0.9425928206693834, 0.9427292639978915, 0.9430082001413985, 0.9432081966150099, 0.9430892106331633, 0.9431942941160222, 0.9431642172123762, 0.9432596380434354, 0.9432211968856026, 0.9434062953236155, 0.9434814379236844, 0.9434963395330335, 0.9434981691439717, 0.9435390680195257, 0.9435048857956969, 0.9435671496097122, 0.9437468041913092, 0.9439768996086106, 0.9438907017316206, 0.9439229552217685, 0.9439849857767354], 'mDice': [0.09883056109810992, 0.33245028842384927, 0.47837606316612985, 0.5367744144203807, 0.5692776204741298, 0.589547640536823, 0.6050015578316842, 0.617709716367933, 0.6260065098867863, 0.6324012889231426, 0.640275394109855, 0.647118854205549, 0.6521300654869123, 0.6556802915543151, 0.6595337704378492, 0.6612231541580839, 0.6659472277795554, 0.6700329370803862, 0.6713423389494017, 0.674595640060505, 0.6763920710797895, 0.6783115740155171, 0.680415643141728, 0.6833521909214569, 0.6848310864406076, 0.6863704600016092, 0.6888981552879682, 0.6908619527254165, 0.6928819891504178, 0.6935357484188709, 0.6957889463208833, 0.6961581382720209, 0.6978652579305902, 0.6982104493768684, 0.6989121320667308, 0.7018324993055222, 0.7027671462496237, 0.7034245027796207, 0.7048568206415348, 0.7044697357828226, 0.705930377158306, 0.7074222661223006, 0.7078854775231124, 0.7101034511139978, 0.7106839614105702, 0.7112711376139073, 0.712853698974541, 0.7145644779124425, 0.7143524784974701, 0.7146325696519006, 0.7164236182350172, 0.7158545906290467, 0.7174665331725604, 0.717524536213986, 0.7188030506159405, 0.718774737743185, 0.7198318852862573, 0.7192644128938251, 0.7212051617770565, 0.7203564391054352, 0.7218154980678054, 0.7229937140321557, 0.7247583459102512, 0.7225774285051895, 0.7236694033053516, 0.72482642883599, 0.7255781771062495, 0.7248584203391906, 0.7261017712871992, 0.7274406867172531, 0.7268176563263675, 0.7272437755050791, 0.7275553278571865, 0.7276052668394785, 0.7280983727792336, 0.7295990267630967, 0.731974390733442, 0.7309244677398575, 0.7308573658144127, 0.7312266385943669]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.28s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.06s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.90s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:05,  1.92s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:26,  1.79s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:22,  1.78s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:54,  1.69s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:16,  1.77s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<07:47,  1.68s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<08:03,  1.74s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:52,  1.70s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:19,  1.81s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:36,  1.88s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:07,  1.78s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:25,  1.85s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<08:05,  1.78s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<08:12,  1.82s/it]predicting train subjects:   5%|▌         | 15/285 [00:26<08:37,  1.92s/it]predicting train subjects:   6%|▌         | 16/285 [00:28<08:42,  1.94s/it]predicting train subjects:   6%|▌         | 17/285 [00:30<08:14,  1.85s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:15,  1.86s/it]predicting train subjects:   7%|▋         | 19/285 [00:33<07:50,  1.77s/it]predicting train subjects:   7%|▋         | 20/285 [00:35<08:04,  1.83s/it]predicting train subjects:   7%|▋         | 21/285 [00:37<08:14,  1.87s/it]predicting train subjects:   8%|▊         | 22/285 [00:39<07:51,  1.79s/it]predicting train subjects:   8%|▊         | 23/285 [00:41<07:59,  1.83s/it]predicting train subjects:   8%|▊         | 24/285 [00:43<07:38,  1.76s/it]predicting train subjects:   9%|▉         | 25/285 [00:44<07:52,  1.82s/it]predicting train subjects:   9%|▉         | 26/285 [00:47<08:06,  1.88s/it]predicting train subjects:   9%|▉         | 27/285 [00:48<07:45,  1.80s/it]predicting train subjects:  10%|▉         | 28/285 [00:50<07:55,  1.85s/it]predicting train subjects:  10%|█         | 29/285 [00:52<07:58,  1.87s/it]predicting train subjects:  11%|█         | 30/285 [00:54<08:07,  1.91s/it]predicting train subjects:  11%|█         | 31/285 [00:56<08:14,  1.95s/it]predicting train subjects:  11%|█         | 32/285 [00:58<07:46,  1.84s/it]predicting train subjects:  12%|█▏        | 33/285 [01:00<07:47,  1.86s/it]predicting train subjects:  12%|█▏        | 34/285 [01:01<07:47,  1.86s/it]predicting train subjects:  12%|█▏        | 35/285 [01:03<07:45,  1.86s/it]predicting train subjects:  13%|█▎        | 36/285 [01:05<07:24,  1.78s/it]predicting train subjects:  13%|█▎        | 37/285 [01:07<07:30,  1.82s/it]predicting train subjects:  13%|█▎        | 38/285 [01:09<07:42,  1.87s/it]predicting train subjects:  14%|█▎        | 39/285 [01:10<07:21,  1.79s/it]predicting train subjects:  14%|█▍        | 40/285 [01:12<07:27,  1.82s/it]predicting train subjects:  14%|█▍        | 41/285 [01:14<07:10,  1.76s/it]predicting train subjects:  15%|█▍        | 42/285 [01:16<06:57,  1.72s/it]predicting train subjects:  15%|█▌        | 43/285 [01:17<07:03,  1.75s/it]predicting train subjects:  15%|█▌        | 44/285 [01:19<07:14,  1.80s/it]predicting train subjects:  16%|█▌        | 45/285 [01:21<07:07,  1.78s/it]predicting train subjects:  16%|█▌        | 46/285 [01:23<07:10,  1.80s/it]predicting train subjects:  16%|█▋        | 47/285 [01:25<06:58,  1.76s/it]predicting train subjects:  17%|█▋        | 48/285 [01:26<07:09,  1.81s/it]predicting train subjects:  17%|█▋        | 49/285 [01:29<07:25,  1.89s/it]predicting train subjects:  18%|█▊        | 50/285 [01:30<07:20,  1.88s/it]predicting train subjects:  18%|█▊        | 51/285 [01:32<07:27,  1.91s/it]predicting train subjects:  18%|█▊        | 52/285 [01:34<07:06,  1.83s/it]predicting train subjects:  19%|█▊        | 53/285 [01:36<07:09,  1.85s/it]predicting train subjects:  19%|█▉        | 54/285 [01:38<07:14,  1.88s/it]predicting train subjects:  19%|█▉        | 55/285 [01:39<06:51,  1.79s/it]predicting train subjects:  20%|█▉        | 56/285 [01:41<06:55,  1.81s/it]predicting train subjects:  20%|██        | 57/285 [01:43<06:39,  1.75s/it]predicting train subjects:  20%|██        | 58/285 [01:45<06:39,  1.76s/it]predicting train subjects:  21%|██        | 59/285 [01:47<06:50,  1.82s/it]predicting train subjects:  21%|██        | 60/285 [01:49<07:01,  1.87s/it]predicting train subjects:  21%|██▏       | 61/285 [01:50<06:41,  1.79s/it]predicting train subjects:  22%|██▏       | 62/285 [01:52<06:43,  1.81s/it]predicting train subjects:  22%|██▏       | 63/285 [01:54<06:52,  1.86s/it]predicting train subjects:  22%|██▏       | 64/285 [01:56<06:38,  1.80s/it]predicting train subjects:  23%|██▎       | 65/285 [01:58<06:39,  1.82s/it]predicting train subjects:  23%|██▎       | 66/285 [01:59<06:38,  1.82s/it]predicting train subjects:  24%|██▎       | 67/285 [02:01<06:35,  1.82s/it]predicting train subjects:  24%|██▍       | 68/285 [02:03<06:22,  1.76s/it]predicting train subjects:  24%|██▍       | 69/285 [02:05<06:22,  1.77s/it]predicting train subjects:  25%|██▍       | 70/285 [02:06<06:19,  1.77s/it]predicting train subjects:  25%|██▍       | 71/285 [02:08<06:20,  1.78s/it]predicting train subjects:  25%|██▌       | 72/285 [02:10<06:06,  1.72s/it]predicting train subjects:  26%|██▌       | 73/285 [02:11<06:02,  1.71s/it]predicting train subjects:  26%|██▌       | 74/285 [02:13<06:00,  1.71s/it]predicting train subjects:  26%|██▋       | 75/285 [02:15<06:00,  1.72s/it]predicting train subjects:  27%|██▋       | 76/285 [02:17<06:03,  1.74s/it]predicting train subjects:  27%|██▋       | 77/285 [02:18<06:00,  1.73s/it]predicting train subjects:  27%|██▋       | 78/285 [02:20<06:10,  1.79s/it]predicting train subjects:  28%|██▊       | 79/285 [02:22<06:26,  1.88s/it]predicting train subjects:  28%|██▊       | 80/285 [02:25<06:38,  1.94s/it]predicting train subjects:  28%|██▊       | 81/285 [02:27<06:43,  1.98s/it]predicting train subjects:  29%|██▉       | 82/285 [02:28<06:37,  1.96s/it]predicting train subjects:  29%|██▉       | 83/285 [02:30<06:30,  1.94s/it]predicting train subjects:  29%|██▉       | 84/285 [02:32<06:15,  1.87s/it]predicting train subjects:  30%|██▉       | 85/285 [02:34<06:26,  1.93s/it]predicting train subjects:  30%|███       | 86/285 [02:36<06:38,  2.00s/it]predicting train subjects:  31%|███       | 87/285 [02:38<06:36,  2.00s/it]predicting train subjects:  31%|███       | 88/285 [02:40<06:26,  1.96s/it]predicting train subjects:  31%|███       | 89/285 [02:42<06:23,  1.95s/it]predicting train subjects:  32%|███▏      | 90/285 [02:44<06:33,  2.02s/it]predicting train subjects:  32%|███▏      | 91/285 [02:46<06:34,  2.03s/it]predicting train subjects:  32%|███▏      | 92/285 [02:48<06:36,  2.05s/it]predicting train subjects:  33%|███▎      | 93/285 [02:50<06:23,  2.00s/it]predicting train subjects:  33%|███▎      | 94/285 [02:52<06:26,  2.02s/it]predicting train subjects:  33%|███▎      | 95/285 [02:55<06:43,  2.13s/it]predicting train subjects:  34%|███▎      | 96/285 [02:57<06:35,  2.09s/it]predicting train subjects:  34%|███▍      | 97/285 [02:59<06:24,  2.05s/it]predicting train subjects:  34%|███▍      | 98/285 [03:01<06:26,  2.07s/it]predicting train subjects:  35%|███▍      | 99/285 [03:03<06:24,  2.07s/it]predicting train subjects:  35%|███▌      | 100/285 [03:05<06:27,  2.10s/it]predicting train subjects:  35%|███▌      | 101/285 [03:07<06:09,  2.01s/it]predicting train subjects:  36%|███▌      | 102/285 [03:09<06:06,  2.00s/it]predicting train subjects:  36%|███▌      | 103/285 [03:11<05:55,  1.96s/it]predicting train subjects:  36%|███▋      | 104/285 [03:13<06:00,  1.99s/it]predicting train subjects:  37%|███▋      | 105/285 [03:15<06:06,  2.03s/it]predicting train subjects:  37%|███▋      | 106/285 [03:17<05:51,  1.97s/it]predicting train subjects:  38%|███▊      | 107/285 [03:19<05:52,  1.98s/it]predicting train subjects:  38%|███▊      | 108/285 [03:21<05:51,  1.98s/it]predicting train subjects:  38%|███▊      | 109/285 [03:23<05:54,  2.02s/it]predicting train subjects:  39%|███▊      | 110/285 [03:25<05:55,  2.03s/it]predicting train subjects:  39%|███▉      | 111/285 [03:27<05:57,  2.06s/it]predicting train subjects:  39%|███▉      | 112/285 [03:29<05:45,  2.00s/it]predicting train subjects:  40%|███▉      | 113/285 [03:31<05:41,  1.98s/it]predicting train subjects:  40%|████      | 114/285 [03:33<05:49,  2.04s/it]predicting train subjects:  40%|████      | 115/285 [03:35<05:48,  2.05s/it]predicting train subjects:  41%|████      | 116/285 [03:37<05:51,  2.08s/it]predicting train subjects:  41%|████      | 117/285 [03:39<05:38,  2.02s/it]predicting train subjects:  41%|████▏     | 118/285 [03:41<05:25,  1.95s/it]predicting train subjects:  42%|████▏     | 119/285 [03:43<05:23,  1.95s/it]predicting train subjects:  42%|████▏     | 120/285 [03:45<05:16,  1.92s/it]predicting train subjects:  42%|████▏     | 121/285 [03:46<05:08,  1.88s/it]predicting train subjects:  43%|████▎     | 122/285 [03:48<04:55,  1.81s/it]predicting train subjects:  43%|████▎     | 123/285 [03:50<04:47,  1.78s/it]predicting train subjects:  44%|████▎     | 124/285 [03:52<04:48,  1.79s/it]predicting train subjects:  44%|████▍     | 125/285 [03:53<04:41,  1.76s/it]predicting train subjects:  44%|████▍     | 126/285 [03:55<04:40,  1.77s/it]predicting train subjects:  45%|████▍     | 127/285 [03:57<04:31,  1.72s/it]predicting train subjects:  45%|████▍     | 128/285 [03:59<04:43,  1.81s/it]predicting train subjects:  45%|████▌     | 129/285 [04:00<04:35,  1.76s/it]predicting train subjects:  46%|████▌     | 130/285 [04:02<04:21,  1.69s/it]predicting train subjects:  46%|████▌     | 131/285 [04:03<04:10,  1.62s/it]predicting train subjects:  46%|████▋     | 132/285 [04:05<04:30,  1.77s/it]predicting train subjects:  47%|████▋     | 133/285 [04:07<04:22,  1.73s/it]predicting train subjects:  47%|████▋     | 134/285 [04:09<04:14,  1.68s/it]predicting train subjects:  47%|████▋     | 135/285 [04:10<04:12,  1.68s/it]predicting train subjects:  48%|████▊     | 136/285 [04:12<04:13,  1.70s/it]predicting train subjects:  48%|████▊     | 137/285 [04:14<04:10,  1.69s/it]predicting train subjects:  48%|████▊     | 138/285 [04:15<04:00,  1.64s/it]predicting train subjects:  49%|████▉     | 139/285 [04:17<04:09,  1.71s/it]predicting train subjects:  49%|████▉     | 140/285 [04:19<04:09,  1.72s/it]predicting train subjects:  49%|████▉     | 141/285 [04:21<04:04,  1.69s/it]predicting train subjects:  50%|████▉     | 142/285 [04:22<04:06,  1.73s/it]predicting train subjects:  50%|█████     | 143/285 [04:24<04:03,  1.71s/it]predicting train subjects:  51%|█████     | 144/285 [04:26<04:08,  1.76s/it]predicting train subjects:  51%|█████     | 145/285 [04:28<04:09,  1.78s/it]predicting train subjects:  51%|█████     | 146/285 [04:30<04:10,  1.80s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:31<04:00,  1.74s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:33<04:00,  1.76s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:35<03:55,  1.73s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:36<03:57,  1.76s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:39<04:05,  1.83s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:40<03:53,  1.76s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:42<03:47,  1.72s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:43<03:40,  1.68s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:45<03:35,  1.66s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:47<03:41,  1.72s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:49<03:44,  1.75s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:50<03:42,  1.75s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:52<03:37,  1.72s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:54<03:30,  1.68s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:56<03:37,  1.76s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:57<03:33,  1.73s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:59<03:31,  1.73s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:01<03:27,  1.72s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:02<03:19,  1.66s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:04<03:25,  1.72s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:06<03:25,  1.74s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:07<03:20,  1.71s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:09<03:20,  1.73s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:11<03:16,  1.71s/it]predicting train subjects:  60%|██████    | 171/285 [05:12<03:10,  1.67s/it]predicting train subjects:  60%|██████    | 172/285 [05:14<03:12,  1.70s/it]predicting train subjects:  61%|██████    | 173/285 [05:16<03:10,  1.71s/it]predicting train subjects:  61%|██████    | 174/285 [05:18<03:12,  1.74s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:20<03:13,  1.76s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:21<03:14,  1.78s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:23<03:10,  1.76s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:25<03:02,  1.71s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:26<02:55,  1.65s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:28<03:05,  1.76s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:30<03:04,  1.77s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:32<03:05,  1.80s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:34<02:59,  1.76s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:35<02:58,  1.77s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:37<02:51,  1.72s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:39<02:59,  1.81s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:41<03:03,  1.88s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:43<03:15,  2.02s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:45<03:00,  1.88s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:47<02:52,  1.82s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:48<02:53,  1.84s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:51<02:56,  1.90s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:52<02:44,  1.79s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:54<02:38,  1.74s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:55<02:31,  1.68s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:57<02:38,  1.78s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:59<02:45,  1.88s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:01<02:46,  1.91s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:03<02:33,  1.79s/it]predicting train subjects:  70%|███████   | 200/285 [06:04<02:28,  1.75s/it]predicting train subjects:  71%|███████   | 201/285 [06:07<02:37,  1.87s/it]predicting train subjects:  71%|███████   | 202/285 [06:09<02:35,  1.88s/it]predicting train subjects:  71%|███████   | 203/285 [06:10<02:31,  1.85s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:12<02:24,  1.78s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:14<02:18,  1.74s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:15<02:10,  1.65s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:17<02:24,  1.85s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:20<02:32,  1.98s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:22<02:34,  2.04s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:23<02:19,  1.86s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:25<02:14,  1.82s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:27<02:17,  1.88s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:29<02:16,  1.89s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:31<02:11,  1.85s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:33<02:15,  1.94s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:34<02:01,  1.76s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:36<02:05,  1.84s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:38<02:06,  1.89s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:40<02:01,  1.84s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:41<01:49,  1.68s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:43<01:42,  1.60s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:44<01:40,  1.59s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:45<01:32,  1.50s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:47<01:29,  1.46s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:48<01:25,  1.43s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:50<01:31,  1.55s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:52<01:33,  1.62s/it]predicting train subjects:  80%|████████  | 228/285 [06:54<01:34,  1.66s/it]predicting train subjects:  80%|████████  | 229/285 [06:55<01:32,  1.64s/it]predicting train subjects:  81%|████████  | 230/285 [06:56<01:24,  1.54s/it]predicting train subjects:  81%|████████  | 231/285 [06:58<01:20,  1.48s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:59<01:19,  1.51s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:01<01:15,  1.45s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:02<01:18,  1.55s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:04<01:13,  1.48s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:06<01:16,  1.55s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:07<01:17,  1.61s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:09<01:16,  1.63s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:10<01:13,  1.60s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:12<01:08,  1.51s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:13<01:04,  1.47s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:14<01:00,  1.41s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:16<00:57,  1.38s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:17<01:00,  1.49s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:19<00:57,  1.43s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:21<00:59,  1.54s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:22<01:00,  1.60s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:24<00:59,  1.60s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:25<00:55,  1.54s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:27<00:52,  1.49s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:28<00:48,  1.44s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:29<00:46,  1.41s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:31<00:49,  1.53s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:33<00:49,  1.60s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:34<00:47,  1.59s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:36<00:43,  1.50s/it]predicting train subjects:  90%|█████████ | 257/285 [07:37<00:41,  1.47s/it]predicting train subjects:  91%|█████████ | 258/285 [07:39<00:41,  1.54s/it]predicting train subjects:  91%|█████████ | 259/285 [07:40<00:40,  1.55s/it]predicting train subjects:  91%|█████████ | 260/285 [07:42<00:37,  1.48s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:43<00:34,  1.45s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:44<00:32,  1.42s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:46<00:30,  1.38s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:48<00:31,  1.50s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:49<00:31,  1.57s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:51<00:28,  1.50s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:52<00:27,  1.50s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:54<00:26,  1.58s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:55<00:25,  1.59s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:57<00:23,  1.54s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:58<00:21,  1.51s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:00<00:20,  1.54s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:01<00:17,  1.48s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:03<00:15,  1.41s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:04<00:15,  1.53s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:06<00:14,  1.61s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:07<00:12,  1.52s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:09<00:10,  1.48s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:10<00:09,  1.51s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:12<00:07,  1.47s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:13<00:05,  1.45s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:14<00:04,  1.41s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:16<00:03,  1.54s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:18<00:01,  1.60s/it]predicting train subjects: 100%|██████████| 285/285 [08:20<00:00,  1.63s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:17,  1.75s/it]Loading train:   1%|          | 2/285 [00:03<07:46,  1.65s/it]Loading train:   1%|          | 3/285 [00:04<07:37,  1.62s/it]Loading train:   1%|▏         | 4/285 [00:05<06:55,  1.48s/it]Loading train:   2%|▏         | 5/285 [00:07<06:59,  1.50s/it]Loading train:   2%|▏         | 6/285 [00:08<06:41,  1.44s/it]Loading train:   2%|▏         | 7/285 [00:10<06:55,  1.50s/it]Loading train:   3%|▎         | 8/285 [00:11<06:46,  1.47s/it]Loading train:   3%|▎         | 9/285 [00:13<07:14,  1.57s/it]Loading train:   4%|▎         | 10/285 [00:14<06:36,  1.44s/it]Loading train:   4%|▍         | 11/285 [00:15<05:58,  1.31s/it]Loading train:   4%|▍         | 12/285 [00:16<05:39,  1.24s/it]Loading train:   5%|▍         | 13/285 [00:17<05:05,  1.12s/it]Loading train:   5%|▍         | 14/285 [00:18<04:50,  1.07s/it]Loading train:   5%|▌         | 15/285 [00:19<04:45,  1.06s/it]Loading train:   6%|▌         | 16/285 [00:20<04:53,  1.09s/it]Loading train:   6%|▌         | 17/285 [00:21<04:33,  1.02s/it]Loading train:   6%|▋         | 18/285 [00:22<04:32,  1.02s/it]Loading train:   7%|▋         | 19/285 [00:23<04:13,  1.05it/s]Loading train:   7%|▋         | 20/285 [00:24<04:08,  1.07it/s]Loading train:   7%|▋         | 21/285 [00:25<04:31,  1.03s/it]Loading train:   8%|▊         | 22/285 [00:26<04:17,  1.02it/s]Loading train:   8%|▊         | 23/285 [00:27<04:20,  1.00it/s]Loading train:   8%|▊         | 24/285 [00:28<04:15,  1.02it/s]Loading train:   9%|▉         | 25/285 [00:29<04:33,  1.05s/it]Loading train:   9%|▉         | 26/285 [00:30<04:36,  1.07s/it]Loading train:   9%|▉         | 27/285 [00:31<04:31,  1.05s/it]Loading train:  10%|▉         | 28/285 [00:32<04:30,  1.05s/it]Loading train:  10%|█         | 29/285 [00:33<04:23,  1.03s/it]Loading train:  11%|█         | 30/285 [00:34<04:26,  1.04s/it]Loading train:  11%|█         | 31/285 [00:35<04:30,  1.06s/it]Loading train:  11%|█         | 32/285 [00:37<04:26,  1.05s/it]Loading train:  12%|█▏        | 33/285 [00:38<04:28,  1.07s/it]Loading train:  12%|█▏        | 34/285 [00:39<04:22,  1.05s/it]Loading train:  12%|█▏        | 35/285 [00:40<04:36,  1.11s/it]Loading train:  13%|█▎        | 36/285 [00:41<04:31,  1.09s/it]Loading train:  13%|█▎        | 37/285 [00:42<04:30,  1.09s/it]Loading train:  13%|█▎        | 38/285 [00:43<04:34,  1.11s/it]Loading train:  14%|█▎        | 39/285 [00:44<04:21,  1.06s/it]Loading train:  14%|█▍        | 40/285 [00:45<04:20,  1.06s/it]Loading train:  14%|█▍        | 41/285 [00:46<04:07,  1.01s/it]Loading train:  15%|█▍        | 42/285 [00:47<03:53,  1.04it/s]Loading train:  15%|█▌        | 43/285 [00:48<03:54,  1.03it/s]Loading train:  15%|█▌        | 44/285 [00:49<04:09,  1.03s/it]Loading train:  16%|█▌        | 45/285 [00:50<04:03,  1.01s/it]Loading train:  16%|█▌        | 46/285 [00:51<04:09,  1.05s/it]Loading train:  16%|█▋        | 47/285 [00:52<03:54,  1.02it/s]Loading train:  17%|█▋        | 48/285 [00:53<03:49,  1.03it/s]Loading train:  17%|█▋        | 49/285 [00:54<03:55,  1.00it/s]Loading train:  18%|█▊        | 50/285 [00:55<03:54,  1.00it/s]Loading train:  18%|█▊        | 51/285 [00:56<04:00,  1.03s/it]Loading train:  18%|█▊        | 52/285 [00:57<03:54,  1.01s/it]Loading train:  19%|█▊        | 53/285 [00:58<03:49,  1.01it/s]Loading train:  19%|█▉        | 54/285 [00:59<03:58,  1.03s/it]Loading train:  19%|█▉        | 55/285 [01:00<03:50,  1.00s/it]Loading train:  20%|█▉        | 56/285 [01:01<03:50,  1.01s/it]Loading train:  20%|██        | 57/285 [01:02<03:38,  1.05it/s]Loading train:  20%|██        | 58/285 [01:03<03:36,  1.05it/s]Loading train:  21%|██        | 59/285 [01:04<03:42,  1.02it/s]Loading train:  21%|██        | 60/285 [01:05<03:42,  1.01it/s]Loading train:  21%|██▏       | 61/285 [01:06<03:33,  1.05it/s]Loading train:  22%|██▏       | 62/285 [01:07<03:33,  1.05it/s]Loading train:  22%|██▏       | 63/285 [01:08<03:32,  1.04it/s]Loading train:  22%|██▏       | 64/285 [01:09<04:00,  1.09s/it]Loading train:  23%|██▎       | 65/285 [01:11<04:23,  1.20s/it]Loading train:  23%|██▎       | 66/285 [01:12<04:28,  1.23s/it]Loading train:  24%|██▎       | 67/285 [01:13<04:11,  1.15s/it]Loading train:  24%|██▍       | 68/285 [01:14<03:50,  1.06s/it]Loading train:  24%|██▍       | 69/285 [01:15<03:43,  1.03s/it]Loading train:  25%|██▍       | 70/285 [01:16<03:37,  1.01s/it]Loading train:  25%|██▍       | 71/285 [01:17<03:31,  1.01it/s]Loading train:  25%|██▌       | 72/285 [01:18<03:32,  1.00it/s]Loading train:  26%|██▌       | 73/285 [01:19<03:34,  1.01s/it]Loading train:  26%|██▌       | 74/285 [01:20<03:26,  1.02it/s]Loading train:  26%|██▋       | 75/285 [01:20<03:25,  1.02it/s]Loading train:  27%|██▋       | 76/285 [01:21<03:20,  1.04it/s]Loading train:  27%|██▋       | 77/285 [01:22<03:14,  1.07it/s]Loading train:  27%|██▋       | 78/285 [01:23<03:08,  1.10it/s]Loading train:  28%|██▊       | 79/285 [01:24<03:08,  1.09it/s]Loading train:  28%|██▊       | 80/285 [01:25<03:07,  1.09it/s]Loading train:  28%|██▊       | 81/285 [01:26<03:08,  1.08it/s]Loading train:  29%|██▉       | 82/285 [01:27<03:12,  1.05it/s]Loading train:  29%|██▉       | 83/285 [01:28<03:11,  1.06it/s]Loading train:  29%|██▉       | 84/285 [01:29<03:14,  1.03it/s]Loading train:  30%|██▉       | 85/285 [01:30<03:19,  1.00it/s]Loading train:  30%|███       | 86/285 [01:31<03:27,  1.04s/it]Loading train:  31%|███       | 87/285 [01:32<03:25,  1.04s/it]Loading train:  31%|███       | 88/285 [01:33<03:26,  1.05s/it]Loading train:  31%|███       | 89/285 [01:34<03:21,  1.03s/it]Loading train:  32%|███▏      | 90/285 [01:35<03:14,  1.00it/s]Loading train:  32%|███▏      | 91/285 [01:36<03:13,  1.00it/s]Loading train:  32%|███▏      | 92/285 [01:37<03:14,  1.01s/it]Loading train:  33%|███▎      | 93/285 [01:38<03:17,  1.03s/it]Loading train:  33%|███▎      | 94/285 [01:39<03:22,  1.06s/it]Loading train:  33%|███▎      | 95/285 [01:40<03:25,  1.08s/it]Loading train:  34%|███▎      | 96/285 [01:41<03:19,  1.06s/it]Loading train:  34%|███▍      | 97/285 [01:43<03:20,  1.07s/it]Loading train:  34%|███▍      | 98/285 [01:44<03:20,  1.07s/it]Loading train:  35%|███▍      | 99/285 [01:45<03:14,  1.05s/it]Loading train:  35%|███▌      | 100/285 [01:46<03:13,  1.05s/it]Loading train:  35%|███▌      | 101/285 [01:47<03:07,  1.02s/it]Loading train:  36%|███▌      | 102/285 [01:48<03:03,  1.00s/it]Loading train:  36%|███▌      | 103/285 [01:49<02:56,  1.03it/s]Loading train:  36%|███▋      | 104/285 [01:49<02:53,  1.04it/s]Loading train:  37%|███▋      | 105/285 [01:50<02:53,  1.04it/s]Loading train:  37%|███▋      | 106/285 [01:51<02:46,  1.08it/s]Loading train:  38%|███▊      | 107/285 [01:52<02:43,  1.09it/s]Loading train:  38%|███▊      | 108/285 [01:53<02:45,  1.07it/s]Loading train:  38%|███▊      | 109/285 [01:54<02:47,  1.05it/s]Loading train:  39%|███▊      | 110/285 [01:55<02:56,  1.01s/it]Loading train:  39%|███▉      | 111/285 [01:56<03:00,  1.04s/it]Loading train:  39%|███▉      | 112/285 [01:58<03:05,  1.07s/it]Loading train:  40%|███▉      | 113/285 [01:58<02:59,  1.04s/it]Loading train:  40%|████      | 114/285 [01:59<02:52,  1.01s/it]Loading train:  40%|████      | 115/285 [02:01<02:55,  1.03s/it]Loading train:  41%|████      | 116/285 [02:01<02:52,  1.02s/it]Loading train:  41%|████      | 117/285 [02:02<02:44,  1.02it/s]Loading train:  41%|████▏     | 118/285 [02:03<02:42,  1.02it/s]Loading train:  42%|████▏     | 119/285 [02:04<02:47,  1.01s/it]Loading train:  42%|████▏     | 120/285 [02:05<02:46,  1.01s/it]Loading train:  42%|████▏     | 121/285 [02:07<03:00,  1.10s/it]Loading train:  43%|████▎     | 122/285 [02:08<03:09,  1.16s/it]Loading train:  43%|████▎     | 123/285 [02:09<03:12,  1.19s/it]Loading train:  44%|████▎     | 124/285 [02:10<02:58,  1.11s/it]Loading train:  44%|████▍     | 125/285 [02:11<02:41,  1.01s/it]Loading train:  44%|████▍     | 126/285 [02:12<02:36,  1.02it/s]Loading train:  45%|████▍     | 127/285 [02:13<02:27,  1.07it/s]Loading train:  45%|████▍     | 128/285 [02:14<02:27,  1.06it/s]Loading train:  45%|████▌     | 129/285 [02:15<02:23,  1.09it/s]Loading train:  46%|████▌     | 130/285 [02:16<02:26,  1.06it/s]Loading train:  46%|████▌     | 131/285 [02:16<02:21,  1.09it/s]Loading train:  46%|████▋     | 132/285 [02:17<02:21,  1.08it/s]Loading train:  47%|████▋     | 133/285 [02:18<02:18,  1.10it/s]Loading train:  47%|████▋     | 134/285 [02:19<02:11,  1.15it/s]Loading train:  47%|████▋     | 135/285 [02:20<02:08,  1.17it/s]Loading train:  48%|████▊     | 136/285 [02:21<02:10,  1.15it/s]Loading train:  48%|████▊     | 137/285 [02:22<02:13,  1.11it/s]Loading train:  48%|████▊     | 138/285 [02:23<02:10,  1.13it/s]Loading train:  49%|████▉     | 139/285 [02:23<02:09,  1.12it/s]Loading train:  49%|████▉     | 140/285 [02:24<02:11,  1.10it/s]Loading train:  49%|████▉     | 141/285 [02:25<02:05,  1.15it/s]Loading train:  50%|████▉     | 142/285 [02:26<02:10,  1.09it/s]Loading train:  50%|█████     | 143/285 [02:27<02:11,  1.08it/s]Loading train:  51%|█████     | 144/285 [02:28<02:13,  1.06it/s]Loading train:  51%|█████     | 145/285 [02:29<02:11,  1.06it/s]Loading train:  51%|█████     | 146/285 [02:30<02:07,  1.09it/s]Loading train:  52%|█████▏    | 147/285 [02:31<02:07,  1.09it/s]Loading train:  52%|█████▏    | 148/285 [02:32<02:05,  1.09it/s]Loading train:  52%|█████▏    | 149/285 [02:33<02:03,  1.11it/s]Loading train:  53%|█████▎    | 150/285 [02:34<01:58,  1.14it/s]Loading train:  53%|█████▎    | 151/285 [02:34<02:01,  1.10it/s]Loading train:  53%|█████▎    | 152/285 [02:35<01:57,  1.13it/s]Loading train:  54%|█████▎    | 153/285 [02:36<01:54,  1.15it/s]Loading train:  54%|█████▍    | 154/285 [02:37<01:54,  1.15it/s]Loading train:  54%|█████▍    | 155/285 [02:38<01:51,  1.17it/s]Loading train:  55%|█████▍    | 156/285 [02:39<01:50,  1.16it/s]Loading train:  55%|█████▌    | 157/285 [02:40<01:47,  1.19it/s]Loading train:  55%|█████▌    | 158/285 [02:40<01:47,  1.18it/s]Loading train:  56%|█████▌    | 159/285 [02:41<01:46,  1.19it/s]Loading train:  56%|█████▌    | 160/285 [02:42<01:45,  1.19it/s]Loading train:  56%|█████▋    | 161/285 [02:43<01:46,  1.16it/s]Loading train:  57%|█████▋    | 162/285 [02:44<01:46,  1.15it/s]Loading train:  57%|█████▋    | 163/285 [02:45<01:45,  1.15it/s]Loading train:  58%|█████▊    | 164/285 [02:46<01:46,  1.14it/s]Loading train:  58%|█████▊    | 165/285 [02:47<01:47,  1.12it/s]Loading train:  58%|█████▊    | 166/285 [02:47<01:46,  1.12it/s]Loading train:  59%|█████▊    | 167/285 [02:48<01:45,  1.12it/s]Loading train:  59%|█████▉    | 168/285 [02:49<01:44,  1.12it/s]Loading train:  59%|█████▉    | 169/285 [02:50<01:44,  1.11it/s]Loading train:  60%|█████▉    | 170/285 [02:51<01:42,  1.12it/s]Loading train:  60%|██████    | 171/285 [02:52<01:40,  1.13it/s]Loading train:  60%|██████    | 172/285 [02:53<01:38,  1.15it/s]Loading train:  61%|██████    | 173/285 [02:54<01:36,  1.16it/s]Loading train:  61%|██████    | 174/285 [02:54<01:37,  1.14it/s]Loading train:  61%|██████▏   | 175/285 [02:55<01:37,  1.13it/s]Loading train:  62%|██████▏   | 176/285 [02:56<01:40,  1.08it/s]Loading train:  62%|██████▏   | 177/285 [02:57<01:40,  1.08it/s]Loading train:  62%|██████▏   | 178/285 [02:58<01:38,  1.09it/s]Loading train:  63%|██████▎   | 179/285 [02:59<01:38,  1.07it/s]Loading train:  63%|██████▎   | 180/285 [03:00<01:43,  1.02it/s]Loading train:  64%|██████▎   | 181/285 [03:01<01:45,  1.02s/it]Loading train:  64%|██████▍   | 182/285 [03:02<01:46,  1.03s/it]Loading train:  64%|██████▍   | 183/285 [03:03<01:44,  1.03s/it]Loading train:  65%|██████▍   | 184/285 [03:04<01:37,  1.04it/s]Loading train:  65%|██████▍   | 185/285 [03:05<01:35,  1.05it/s]Loading train:  65%|██████▌   | 186/285 [03:06<01:39,  1.01s/it]Loading train:  66%|██████▌   | 187/285 [03:07<01:39,  1.02s/it]Loading train:  66%|██████▌   | 188/285 [03:08<01:37,  1.01s/it]Loading train:  66%|██████▋   | 189/285 [03:09<01:30,  1.06it/s]Loading train:  67%|██████▋   | 190/285 [03:10<01:22,  1.16it/s]Loading train:  67%|██████▋   | 191/285 [03:11<01:23,  1.13it/s]Loading train:  67%|██████▋   | 192/285 [03:12<01:21,  1.15it/s]Loading train:  68%|██████▊   | 193/285 [03:13<01:24,  1.09it/s]Loading train:  68%|██████▊   | 194/285 [03:14<01:23,  1.09it/s]Loading train:  68%|██████▊   | 195/285 [03:15<01:23,  1.07it/s]Loading train:  69%|██████▉   | 196/285 [03:16<01:30,  1.02s/it]Loading train:  69%|██████▉   | 197/285 [03:17<01:35,  1.08s/it]Loading train:  69%|██████▉   | 198/285 [03:18<01:35,  1.10s/it]Loading train:  70%|██████▉   | 199/285 [03:19<01:29,  1.04s/it]Loading train:  70%|███████   | 200/285 [03:20<01:21,  1.04it/s]Loading train:  71%|███████   | 201/285 [03:21<01:20,  1.04it/s]Loading train:  71%|███████   | 202/285 [03:22<01:16,  1.09it/s]Loading train:  71%|███████   | 203/285 [03:23<01:15,  1.08it/s]Loading train:  72%|███████▏  | 204/285 [03:23<01:14,  1.09it/s]Loading train:  72%|███████▏  | 205/285 [03:24<01:10,  1.14it/s]Loading train:  72%|███████▏  | 206/285 [03:25<01:09,  1.14it/s]Loading train:  73%|███████▎  | 207/285 [03:26<01:12,  1.08it/s]Loading train:  73%|███████▎  | 208/285 [03:27<01:13,  1.05it/s]Loading train:  73%|███████▎  | 209/285 [03:28<01:14,  1.01it/s]Loading train:  74%|███████▎  | 210/285 [03:29<01:12,  1.04it/s]Loading train:  74%|███████▍  | 211/285 [03:30<01:06,  1.11it/s]Loading train:  74%|███████▍  | 212/285 [03:31<01:07,  1.07it/s]Loading train:  75%|███████▍  | 213/285 [03:32<01:10,  1.03it/s]Loading train:  75%|███████▌  | 214/285 [03:33<01:08,  1.04it/s]Loading train:  75%|███████▌  | 215/285 [03:34<01:08,  1.03it/s]Loading train:  76%|███████▌  | 216/285 [03:35<01:05,  1.06it/s]Loading train:  76%|███████▌  | 217/285 [03:36<01:07,  1.01it/s]Loading train:  76%|███████▋  | 218/285 [03:37<01:09,  1.03s/it]Loading train:  77%|███████▋  | 219/285 [03:38<01:10,  1.07s/it]Loading train:  77%|███████▋  | 220/285 [03:39<01:04,  1.00it/s]Loading train:  78%|███████▊  | 221/285 [03:40<01:02,  1.03it/s]Loading train:  78%|███████▊  | 222/285 [03:41<00:59,  1.06it/s]Loading train:  78%|███████▊  | 223/285 [03:42<00:55,  1.11it/s]Loading train:  79%|███████▊  | 224/285 [03:42<00:52,  1.15it/s]Loading train:  79%|███████▉  | 225/285 [03:43<00:52,  1.15it/s]Loading train:  79%|███████▉  | 226/285 [03:44<00:54,  1.08it/s]Loading train:  80%|███████▉  | 227/285 [03:45<00:54,  1.06it/s]Loading train:  80%|████████  | 228/285 [03:46<00:56,  1.01it/s]Loading train:  80%|████████  | 229/285 [03:47<00:54,  1.03it/s]Loading train:  81%|████████  | 230/285 [03:48<00:50,  1.08it/s]Loading train:  81%|████████  | 231/285 [03:49<00:47,  1.13it/s]Loading train:  81%|████████▏ | 232/285 [03:50<00:49,  1.07it/s]Loading train:  82%|████████▏ | 233/285 [03:51<00:47,  1.10it/s]Loading train:  82%|████████▏ | 234/285 [03:52<00:49,  1.04it/s]Loading train:  82%|████████▏ | 235/285 [03:53<00:46,  1.08it/s]Loading train:  83%|████████▎ | 236/285 [03:54<00:47,  1.02it/s]Loading train:  83%|████████▎ | 237/285 [03:55<00:50,  1.04s/it]Loading train:  84%|████████▎ | 238/285 [03:56<00:48,  1.04s/it]Loading train:  84%|████████▍ | 239/285 [03:57<00:46,  1.01s/it]Loading train:  84%|████████▍ | 240/285 [03:58<00:44,  1.01it/s]Loading train:  85%|████████▍ | 241/285 [03:59<00:41,  1.05it/s]Loading train:  85%|████████▍ | 242/285 [04:00<00:39,  1.08it/s]Loading train:  85%|████████▌ | 243/285 [04:01<00:39,  1.07it/s]Loading train:  86%|████████▌ | 244/285 [04:02<00:40,  1.02it/s]Loading train:  86%|████████▌ | 245/285 [04:03<00:38,  1.05it/s]Loading train:  86%|████████▋ | 246/285 [04:04<00:38,  1.02it/s]Loading train:  87%|████████▋ | 247/285 [04:05<00:38,  1.00s/it]Loading train:  87%|████████▋ | 248/285 [04:06<00:35,  1.03it/s]Loading train:  87%|████████▋ | 249/285 [04:06<00:33,  1.07it/s]Loading train:  88%|████████▊ | 250/285 [04:07<00:31,  1.11it/s]Loading train:  88%|████████▊ | 251/285 [04:08<00:30,  1.13it/s]Loading train:  88%|████████▊ | 252/285 [04:09<00:29,  1.12it/s]Loading train:  89%|████████▉ | 253/285 [04:10<00:29,  1.08it/s]Loading train:  89%|████████▉ | 254/285 [04:11<00:28,  1.09it/s]Loading train:  89%|████████▉ | 255/285 [04:12<00:28,  1.05it/s]Loading train:  90%|████████▉ | 256/285 [04:13<00:26,  1.08it/s]Loading train:  90%|█████████ | 257/285 [04:14<00:24,  1.13it/s]Loading train:  91%|█████████ | 258/285 [04:15<00:24,  1.09it/s]Loading train:  91%|█████████ | 259/285 [04:16<00:23,  1.09it/s]Loading train:  91%|█████████ | 260/285 [04:16<00:22,  1.14it/s]Loading train:  92%|█████████▏| 261/285 [04:17<00:20,  1.18it/s]Loading train:  92%|█████████▏| 262/285 [04:18<00:19,  1.18it/s]Loading train:  92%|█████████▏| 263/285 [04:19<00:18,  1.19it/s]Loading train:  93%|█████████▎| 264/285 [04:20<00:19,  1.09it/s]Loading train:  93%|█████████▎| 265/285 [04:21<00:19,  1.05it/s]Loading train:  93%|█████████▎| 266/285 [04:22<00:17,  1.09it/s]Loading train:  94%|█████████▎| 267/285 [04:23<00:16,  1.08it/s]Loading train:  94%|█████████▍| 268/285 [04:24<00:16,  1.05it/s]Loading train:  94%|█████████▍| 269/285 [04:25<00:15,  1.03it/s]Loading train:  95%|█████████▍| 270/285 [04:26<00:14,  1.06it/s]Loading train:  95%|█████████▌| 271/285 [04:26<00:12,  1.10it/s]Loading train:  95%|█████████▌| 272/285 [04:27<00:12,  1.07it/s]Loading train:  96%|█████████▌| 273/285 [04:28<00:10,  1.09it/s]Loading train:  96%|█████████▌| 274/285 [04:29<00:10,  1.10it/s]Loading train:  96%|█████████▋| 275/285 [04:30<00:09,  1.06it/s]Loading train:  97%|█████████▋| 276/285 [04:31<00:08,  1.02it/s]Loading train:  97%|█████████▋| 277/285 [04:32<00:07,  1.07it/s]Loading train:  98%|█████████▊| 278/285 [04:33<00:06,  1.10it/s]Loading train:  98%|█████████▊| 279/285 [04:34<00:05,  1.10it/s]Loading train:  98%|█████████▊| 280/285 [04:35<00:04,  1.12it/s]Loading train:  99%|█████████▊| 281/285 [04:36<00:03,  1.15it/s]Loading train:  99%|█████████▉| 282/285 [04:36<00:02,  1.17it/s]Loading train:  99%|█████████▉| 283/285 [04:37<00:01,  1.06it/s]Loading train: 100%|█████████▉| 284/285 [04:39<00:00,  1.01it/s]Loading train: 100%|██████████| 285/285 [04:40<00:00,  1.01it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   4%|▍         | 12/285 [00:00<00:02, 116.15it/s]concatenating: train:  11%|█         | 30/285 [00:00<00:01, 129.56it/s]concatenating: train:  21%|██        | 59/285 [00:00<00:01, 155.11it/s]concatenating: train:  31%|███       | 88/285 [00:00<00:01, 179.85it/s]concatenating: train:  40%|███▉      | 113/285 [00:00<00:00, 195.67it/s]concatenating: train:  51%|█████     | 145/285 [00:00<00:00, 220.73it/s]concatenating: train:  61%|██████    | 173/285 [00:00<00:00, 234.18it/s]concatenating: train:  72%|███████▏  | 206/285 [00:00<00:00, 255.51it/s]concatenating: train:  83%|████████▎ | 237/285 [00:00<00:00, 269.28it/s]concatenating: train:  94%|█████████▎| 267/285 [00:01<00:00, 277.44it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 266.13it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.45s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.42s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.35s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 86.35it/s]2019-07-11 06:37:23.565047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 06:37:23.565175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 06:37:23.565191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 06:37:23.565199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 06:37:23.567147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.31it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.20it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.69it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.30it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.51it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.41it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.30it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.07it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.60it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.11it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.81it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.06it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.18it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.18it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.96it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.28it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.43it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.25it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.41it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 26, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 13, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 26, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 30)   16230       dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 30)   120         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 30)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 52, 30)   0           activation_11[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 30)   8130        dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 52, 30)   120         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 52, 30)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 52, 30)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 90)   0           dropout_5[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 52, 13)   1183        concatenate_7[0][0]              
==================================================================================================
Total params: 248,823
Trainable params: 74,023
Non-trainable params: 174,800
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 19s - loss: 2.0672 - acc: 0.7041 - mDice: 0.2080 - val_loss: 0.8464 - val_acc: 0.9171 - val_mDice: 0.4202

Epoch 00001: val_mDice improved from -inf to 0.42020, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 14s - loss: 0.6974 - acc: 0.8976 - mDice: 0.4843 - val_loss: 0.6295 - val_acc: 0.9241 - val_mDice: 0.5192

Epoch 00002: val_mDice improved from 0.42020 to 0.51923, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 13s - loss: 0.5271 - acc: 0.9065 - mDice: 0.5762 - val_loss: 0.6186 - val_acc: 0.9284 - val_mDice: 0.5354

Epoch 00003: val_mDice improved from 0.51923 to 0.53540, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 13s - loss: 0.4509 - acc: 0.9175 - mDice: 0.6233 - val_loss: 0.5486 - val_acc: 0.9418 - val_mDice: 0.5689

Epoch 00004: val_mDice improved from 0.53540 to 0.56894, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 14s - loss: 0.4157 - acc: 0.9276 - mDice: 0.6466 - val_loss: 0.6103 - val_acc: 0.9470 - val_mDice: 0.5593

Epoch 00005: val_mDice did not improve from 0.56894
Epoch 6/300
 - 13s - loss: 0.3886 - acc: 0.9362 - mDice: 0.6651 - val_loss: 0.4898 - val_acc: 0.9516 - val_mDice: 0.6074

Epoch 00006: val_mDice improved from 0.56894 to 0.60740, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 13s - loss: 0.3708 - acc: 0.9445 - mDice: 0.6765 - val_loss: 0.4949 - val_acc: 0.9506 - val_mDice: 0.6064

Epoch 00007: val_mDice did not improve from 0.60740
Epoch 8/300
 - 13s - loss: 0.3562 - acc: 0.9473 - mDice: 0.6863 - val_loss: 0.4713 - val_acc: 0.9503 - val_mDice: 0.6163

Epoch 00008: val_mDice improved from 0.60740 to 0.61628, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 13s - loss: 0.3447 - acc: 0.9483 - mDice: 0.6942 - val_loss: 0.4994 - val_acc: 0.9502 - val_mDice: 0.5961

Epoch 00009: val_mDice did not improve from 0.61628
Epoch 10/300
 - 14s - loss: 0.3372 - acc: 0.9489 - mDice: 0.6996 - val_loss: 0.4490 - val_acc: 0.9520 - val_mDice: 0.6297

Epoch 00010: val_mDice improved from 0.61628 to 0.62968, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 13s - loss: 0.3292 - acc: 0.9497 - mDice: 0.7055 - val_loss: 0.4879 - val_acc: 0.9496 - val_mDice: 0.6056

Epoch 00011: val_mDice did not improve from 0.62968
Epoch 12/300
 - 13s - loss: 0.3232 - acc: 0.9502 - mDice: 0.7098 - val_loss: 0.4731 - val_acc: 0.9505 - val_mDice: 0.6139

Epoch 00012: val_mDice did not improve from 0.62968
Epoch 13/300
 - 13s - loss: 0.3242 - acc: 0.9502 - mDice: 0.7097 - val_loss: 0.4681 - val_acc: 0.9526 - val_mDice: 0.6209

Epoch 00013: val_mDice did not improve from 0.62968
Epoch 14/300
 - 13s - loss: 0.3109 - acc: 0.9512 - mDice: 0.7190 - val_loss: 0.4844 - val_acc: 0.9528 - val_mDice: 0.6158

Epoch 00014: val_mDice did not improve from 0.62968
Epoch 15/300
 - 14s - loss: 0.3080 - acc: 0.9515 - mDice: 0.7213 - val_loss: 0.4657 - val_acc: 0.9524 - val_mDice: 0.6197

Epoch 00015: val_mDice did not improve from 0.62968
Epoch 16/300
 - 14s - loss: 0.3036 - acc: 0.9518 - mDice: 0.7244 - val_loss: 0.4459 - val_acc: 0.9537 - val_mDice: 0.6309

Epoch 00016: val_mDice improved from 0.62968 to 0.63090, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 13s - loss: 0.2980 - acc: 0.9521 - mDice: 0.7287 - val_loss: 0.4715 - val_acc: 0.9521 - val_mDice: 0.6183

Epoch 00017: val_mDice did not improve from 0.63090
Epoch 18/300
 - 13s - loss: 0.2944 - acc: 0.9525 - mDice: 0.7313 - val_loss: 0.4584 - val_acc: 0.9525 - val_mDice: 0.6248

Epoch 00018: val_mDice did not improve from 0.63090
Epoch 19/300
 - 13s - loss: 0.2923 - acc: 0.9527 - mDice: 0.7331 - val_loss: 0.5133 - val_acc: 0.9524 - val_mDice: 0.6040

Epoch 00019: val_mDice did not improve from 0.63090
Epoch 20/300
 - 15s - loss: 0.2901 - acc: 0.9529 - mDice: 0.7348 - val_loss: 0.4859 - val_acc: 0.9524 - val_mDice: 0.6129

Epoch 00020: val_mDice did not improve from 0.63090
Epoch 21/300
 - 14s - loss: 0.2857 - acc: 0.9530 - mDice: 0.7380 - val_loss: 0.4740 - val_acc: 0.9534 - val_mDice: 0.6172

Epoch 00021: val_mDice did not improve from 0.63090
Epoch 22/300
 - 14s - loss: 0.2808 - acc: 0.9535 - mDice: 0.7417 - val_loss: 0.4824 - val_acc: 0.9530 - val_mDice: 0.6114

Epoch 00022: val_mDice did not improve from 0.63090
Epoch 23/300
 - 15s - loss: 0.2796 - acc: 0.9536 - mDice: 0.7428 - val_loss: 0.5305 - val_acc: 0.9521 - val_mDice: 0.5935

Epoch 00023: val_mDice did not improve from 0.63090
Epoch 24/300
 - 14s - loss: 0.2771 - acc: 0.9538 - mDice: 0.7447 - val_loss: 0.5076 - val_acc: 0.9529 - val_mDice: 0.6151

Epoch 00024: val_mDice did not improve from 0.63090
Epoch 25/300
 - 14s - loss: 0.2744 - acc: 0.9540 - mDice: 0.7468 - val_loss: 0.5846 - val_acc: 0.9531 - val_mDice: 0.5916

Epoch 00025: val_mDice did not improve from 0.63090
Epoch 26/300
 - 15s - loss: 0.2732 - acc: 0.9540 - mDice: 0.7477 - val_loss: 0.4849 - val_acc: 0.9519 - val_mDice: 0.6167

Epoch 00026: val_mDice did not improve from 0.63090
Epoch 27/300
 - 14s - loss: 0.2705 - acc: 0.9542 - mDice: 0.7498 - val_loss: 0.5184 - val_acc: 0.9520 - val_mDice: 0.6055

Epoch 00027: val_mDice did not improve from 0.63090
Epoch 28/300
 - 14s - loss: 0.2673 - acc: 0.9545 - mDice: 0.7524 - val_loss: 0.5698 - val_acc: 0.9519 - val_mDice: 0.5922

Epoch 00028: val_mDice did not improve from 0.63090
Epoch 29/300
 - 14s - loss: 0.3094 - acc: 0.9513 - mDice: 0.7240 - val_loss: 0.4963 - val_acc: 0.9529 - val_mDice: 0.6065

Epoch 00029: val_mDice did not improve from 0.63090
Epoch 30/300
 - 14s - loss: 0.2846 - acc: 0.9533 - mDice: 0.7388 - val_loss: 0.4877 - val_acc: 0.9514 - val_mDice: 0.6102

Epoch 00030: val_mDice did not improve from 0.63090
Epoch 31/300
 - 14s - loss: 0.2720 - acc: 0.9542 - mDice: 0.7486 - val_loss: 0.4702 - val_acc: 0.9519 - val_mDice: 0.6147

Epoch 00031: val_mDice did not improve from 0.63090
Epoch 32/300
 - 14s - loss: 0.2654 - acc: 0.9547 - mDice: 0.7537 - val_loss: 0.4682 - val_acc: 0.9519 - val_mDice: 0.6212

Epoch 00032: val_mDice did not improve from 0.63090
Epoch 33/300
 - 15s - loss: 0.2637 - acc: 0.9549 - mDice: 0.7552 - val_loss: 0.5001 - val_acc: 0.9525 - val_mDice: 0.6057

Epoch 00033: val_mDice did not improve from 0.63090
Epoch 34/300
 - 14s - loss: 0.2603 - acc: 0.9552 - mDice: 0.7579 - val_loss: 0.5006 - val_acc: 0.9508 - val_mDice: 0.6054

Epoch 00034: val_mDice did not improve from 0.63090
Epoch 35/300
 - 14s - loss: 0.2601 - acc: 0.9551 - mDice: 0.7580 - val_loss: 0.4921 - val_acc: 0.9536 - val_mDice: 0.6177

Epoch 00035: val_mDice did not improve from 0.63090
Epoch 36/300
 - 15s - loss: 0.2580 - acc: 0.9553 - mDice: 0.7597 - val_loss: 0.5093 - val_acc: 0.9537 - val_mDice: 0.6100

Epoch 00036: val_mDice did not improve from 0.63090
Epoch 37/300
 - 14s - loss: 0.2568 - acc: 0.9554 - mDice: 0.7607 - val_loss: 0.5103 - val_acc: 0.9527 - val_mDice: 0.6065

Epoch 00037: val_mDice did not improve from 0.63090
Epoch 38/300
 - 14s - loss: 0.2559 - acc: 0.9555 - mDice: 0.7614 - val_loss: 0.4943 - val_acc: 0.9502 - val_mDice: 0.6056

Epoch 00038: val_mDice did not improve from 0.63090
Epoch 39/300
 - 14s - loss: 0.2545 - acc: 0.9555 - mDice: 0.7624 - val_loss: 0.4865 - val_acc: 0.9510 - val_mDice: 0.6117

Epoch 00039: val_mDice did not improve from 0.63090
Epoch 40/300
 - 14s - loss: 0.2545 - acc: 0.9556 - mDice: 0.7626 - val_loss: 0.4857 - val_acc: 0.9532 - val_mDice: 0.6161

Epoch 00040: val_mDice did not improve from 0.63090
Epoch 41/300
 - 14s - loss: 0.2540 - acc: 0.9556 - mDice: 0.7630 - val_loss: 0.5008 - val_acc: 0.9522 - val_mDice: 0.6119

Epoch 00041: val_mDice did not improve from 0.63090
Epoch 42/300
 - 14s - loss: 0.2509 - acc: 0.9559 - mDice: 0.7654 - val_loss: 0.4826 - val_acc: 0.9539 - val_mDice: 0.6155

Epoch 00042: val_mDice did not improve from 0.63090
Epoch 43/300
 - 14s - loss: 0.2501 - acc: 0.9559 - mDice: 0.7660 - val_loss: 0.4716 - val_acc: 0.9546 - val_mDice: 0.6214

Epoch 00043: val_mDice did not improve from 0.63090
Epoch 44/300
 - 14s - loss: 0.2481 - acc: 0.9560 - mDice: 0.7676 - val_loss: 0.4575 - val_acc: 0.9535 - val_mDice: 0.6249

Epoch 00044: val_mDice did not improve from 0.63090
Epoch 45/300
 - 14s - loss: 0.2476 - acc: 0.9561 - mDice: 0.7680 - val_loss: 0.5308 - val_acc: 0.9514 - val_mDice: 0.5922

Epoch 00045: val_mDice did not improve from 0.63090
Epoch 46/300
 - 13s - loss: 0.2482 - acc: 0.9561 - mDice: 0.7675 - val_loss: 0.5322 - val_acc: 0.9486 - val_mDice: 0.5926

Epoch 00046: val_mDice did not improve from 0.63090
Epoch 47/300
 - 14s - loss: 0.2459 - acc: 0.9562 - mDice: 0.7693 - val_loss: 0.5141 - val_acc: 0.9521 - val_mDice: 0.5988

Epoch 00047: val_mDice did not improve from 0.63090
Epoch 48/300
 - 14s - loss: 0.2445 - acc: 0.9563 - mDice: 0.7704 - val_loss: 0.5162 - val_acc: 0.9518 - val_mDice: 0.5988

Epoch 00048: val_mDice did not improve from 0.63090
Epoch 49/300
 - 14s - loss: 0.2461 - acc: 0.9563 - mDice: 0.7694 - val_loss: 0.4853 - val_acc: 0.9520 - val_mDice: 0.6134

Epoch 00049: val_mDice did not improve from 0.63090
Epoch 50/300
 - 14s - loss: 0.2443 - acc: 0.9564 - mDice: 0.7707 - val_loss: 0.4768 - val_acc: 0.9532 - val_mDice: 0.6161

Epoch 00050: val_mDice did not improve from 0.63090
Epoch 51/300
 - 14s - loss: 0.2432 - acc: 0.9565 - mDice: 0.7716 - val_loss: 0.4662 - val_acc: 0.9522 - val_mDice: 0.6232

Epoch 00051: val_mDice did not improve from 0.63090
Epoch 52/300
 - 14s - loss: 0.2422 - acc: 0.9565 - mDice: 0.7724 - val_loss: 0.4847 - val_acc: 0.9508 - val_mDice: 0.6070

Epoch 00052: val_mDice did not improve from 0.63090
Epoch 53/300
 - 15s - loss: 0.2415 - acc: 0.9566 - mDice: 0.7730 - val_loss: 0.4804 - val_acc: 0.9533 - val_mDice: 0.6140

Epoch 00053: val_mDice did not improve from 0.63090
Epoch 54/300
 - 15s - loss: 0.2393 - acc: 0.9567 - mDice: 0.7747 - val_loss: 0.4715 - val_acc: 0.9535 - val_mDice: 0.6163

Epoch 00054: val_mDice did not improve from 0.63090
Epoch 55/300
 - 15s - loss: 0.2390 - acc: 0.9568 - mDice: 0.7749 - val_loss: 0.4782 - val_acc: 0.9535 - val_mDice: 0.6161

Epoch 00055: val_mDice did not improve from 0.63090
Epoch 56/300
 - 15s - loss: 0.2399 - acc: 0.9567 - mDice: 0.7743 - val_loss: 0.4896 - val_acc: 0.9512 - val_mDice: 0.6068

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.71s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.40s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  2.17s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:02<09:31,  2.01s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:50,  1.88s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:59,  1.91s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<08:57,  1.91s/it]predicting train subjects:   2%|▏         | 5/285 [00:09<09:13,  1.98s/it]predicting train subjects:   2%|▏         | 6/285 [00:11<08:47,  1.89s/it]predicting train subjects:   2%|▏         | 7/285 [00:13<09:17,  2.01s/it]predicting train subjects:   3%|▎         | 8/285 [00:15<09:07,  1.98s/it]predicting train subjects:   3%|▎         | 9/285 [00:17<09:44,  2.12s/it]predicting train subjects:   4%|▎         | 10/285 [00:20<10:01,  2.19s/it]predicting train subjects:   4%|▍         | 11/285 [00:22<09:26,  2.07s/it]predicting train subjects:   4%|▍         | 12/285 [00:24<09:52,  2.17s/it]predicting train subjects:   5%|▍         | 13/285 [00:26<09:24,  2.07s/it]predicting train subjects:   5%|▍         | 14/285 [00:28<09:27,  2.09s/it]predicting train subjects:   5%|▌         | 15/285 [00:31<10:03,  2.23s/it]predicting train subjects:   6%|▌         | 16/285 [00:33<10:00,  2.23s/it]predicting train subjects:   6%|▌         | 17/285 [00:35<09:22,  2.10s/it]predicting train subjects:   6%|▋         | 18/285 [00:37<09:15,  2.08s/it]predicting train subjects:   7%|▋         | 19/285 [00:39<09:03,  2.04s/it]predicting train subjects:   7%|▋         | 20/285 [00:41<08:59,  2.04s/it]predicting train subjects:   7%|▋         | 21/285 [00:43<09:23,  2.13s/it]predicting train subjects:   8%|▊         | 22/285 [00:45<09:03,  2.07s/it]predicting train subjects:   8%|▊         | 23/285 [00:47<09:16,  2.12s/it]predicting train subjects:   8%|▊         | 24/285 [00:49<08:56,  2.06s/it]predicting train subjects:   9%|▉         | 25/285 [00:51<09:15,  2.14s/it]predicting train subjects:   9%|▉         | 26/285 [00:54<09:40,  2.24s/it]predicting train subjects:   9%|▉         | 27/285 [00:56<09:24,  2.19s/it]predicting train subjects:  10%|▉         | 28/285 [00:58<09:07,  2.13s/it]predicting train subjects:  10%|█         | 29/285 [01:00<09:19,  2.19s/it]predicting train subjects:  11%|█         | 30/285 [01:03<10:17,  2.42s/it]predicting train subjects:  11%|█         | 31/285 [01:05<10:04,  2.38s/it]predicting train subjects:  11%|█         | 32/285 [01:07<09:27,  2.24s/it]predicting train subjects:  12%|█▏        | 33/285 [01:09<09:11,  2.19s/it]predicting train subjects:  12%|█▏        | 34/285 [01:12<09:05,  2.18s/it]predicting train subjects:  12%|█▏        | 35/285 [01:14<09:27,  2.27s/it]predicting train subjects:  13%|█▎        | 36/285 [01:16<08:52,  2.14s/it]predicting train subjects:  13%|█▎        | 37/285 [01:18<09:03,  2.19s/it]predicting train subjects:  13%|█▎        | 38/285 [01:21<09:15,  2.25s/it]predicting train subjects:  14%|█▎        | 39/285 [01:23<09:02,  2.20s/it]predicting train subjects:  14%|█▍        | 40/285 [01:25<09:07,  2.23s/it]predicting train subjects:  14%|█▍        | 41/285 [01:27<08:43,  2.15s/it]predicting train subjects:  15%|█▍        | 42/285 [01:29<08:38,  2.14s/it]predicting train subjects:  15%|█▌        | 43/285 [01:31<08:33,  2.12s/it]predicting train subjects:  15%|█▌        | 44/285 [01:33<08:47,  2.19s/it]predicting train subjects:  16%|█▌        | 45/285 [01:35<08:20,  2.09s/it]predicting train subjects:  16%|█▌        | 46/285 [01:38<08:45,  2.20s/it]predicting train subjects:  16%|█▋        | 47/285 [01:40<08:43,  2.20s/it]predicting train subjects:  17%|█▋        | 48/285 [01:42<08:43,  2.21s/it]predicting train subjects:  17%|█▋        | 49/285 [01:45<08:56,  2.27s/it]predicting train subjects:  18%|█▊        | 50/285 [01:47<08:41,  2.22s/it]predicting train subjects:  18%|█▊        | 51/285 [01:49<09:17,  2.38s/it]predicting train subjects:  18%|█▊        | 52/285 [01:51<08:40,  2.23s/it]predicting train subjects:  19%|█▊        | 53/285 [01:54<08:38,  2.23s/it]predicting train subjects:  19%|█▉        | 54/285 [01:56<09:07,  2.37s/it]predicting train subjects:  19%|█▉        | 55/285 [01:58<08:37,  2.25s/it]predicting train subjects:  20%|█▉        | 56/285 [02:00<08:21,  2.19s/it]predicting train subjects:  20%|██        | 57/285 [02:02<08:05,  2.13s/it]predicting train subjects:  20%|██        | 58/285 [02:04<08:06,  2.14s/it]predicting train subjects:  21%|██        | 59/285 [02:07<08:15,  2.19s/it]predicting train subjects:  21%|██        | 60/285 [02:09<08:30,  2.27s/it]predicting train subjects:  21%|██▏       | 61/285 [02:11<08:18,  2.22s/it]predicting train subjects:  22%|██▏       | 62/285 [02:14<08:10,  2.20s/it]predicting train subjects:  22%|██▏       | 63/285 [02:16<08:02,  2.17s/it]predicting train subjects:  22%|██▏       | 64/285 [02:18<07:59,  2.17s/it]predicting train subjects:  23%|██▎       | 65/285 [02:20<07:56,  2.17s/it]predicting train subjects:  23%|██▎       | 66/285 [02:22<07:58,  2.18s/it]predicting train subjects:  24%|██▎       | 67/285 [02:24<07:54,  2.18s/it]predicting train subjects:  24%|██▍       | 68/285 [02:26<07:36,  2.10s/it]predicting train subjects:  24%|██▍       | 69/285 [02:28<07:42,  2.14s/it]predicting train subjects:  25%|██▍       | 70/285 [02:31<07:42,  2.15s/it]predicting train subjects:  25%|██▍       | 71/285 [02:33<08:04,  2.26s/it]predicting train subjects:  25%|██▌       | 72/285 [02:35<07:53,  2.22s/it]predicting train subjects:  26%|██▌       | 73/285 [02:37<07:44,  2.19s/it]predicting train subjects:  26%|██▌       | 74/285 [02:40<08:01,  2.28s/it]predicting train subjects:  26%|██▋       | 75/285 [02:42<07:50,  2.24s/it]predicting train subjects:  27%|██▋       | 76/285 [02:44<07:45,  2.23s/it]predicting train subjects:  27%|██▋       | 77/285 [02:46<07:31,  2.17s/it]predicting train subjects:  27%|██▋       | 78/285 [02:48<07:15,  2.10s/it]predicting train subjects:  28%|██▊       | 79/285 [02:50<07:06,  2.07s/it]predicting train subjects:  28%|██▊       | 80/285 [02:52<07:06,  2.08s/it]predicting train subjects:  28%|██▊       | 81/285 [02:54<06:55,  2.04s/it]predicting train subjects:  29%|██▉       | 82/285 [02:56<07:03,  2.09s/it]predicting train subjects:  29%|██▉       | 83/285 [02:58<06:56,  2.06s/it]predicting train subjects:  29%|██▉       | 84/285 [03:00<06:38,  1.98s/it]predicting train subjects:  30%|██▉       | 85/285 [03:02<06:43,  2.02s/it]predicting train subjects:  30%|███       | 86/285 [03:05<07:00,  2.11s/it]predicting train subjects:  31%|███       | 87/285 [03:07<07:07,  2.16s/it]predicting train subjects:  31%|███       | 88/285 [03:09<06:52,  2.09s/it]predicting train subjects:  31%|███       | 89/285 [03:11<06:50,  2.09s/it]predicting train subjects:  32%|███▏      | 90/285 [03:13<06:47,  2.09s/it]predicting train subjects:  32%|███▏      | 91/285 [03:15<06:48,  2.10s/it]predicting train subjects:  32%|███▏      | 92/285 [03:18<06:56,  2.16s/it]predicting train subjects:  33%|███▎      | 93/285 [03:20<06:54,  2.16s/it]predicting train subjects:  33%|███▎      | 94/285 [03:22<07:00,  2.20s/it]predicting train subjects:  33%|███▎      | 95/285 [03:24<06:59,  2.21s/it]predicting train subjects:  34%|███▎      | 96/285 [03:26<06:53,  2.19s/it]predicting train subjects:  34%|███▍      | 97/285 [03:29<06:55,  2.21s/it]predicting train subjects:  34%|███▍      | 98/285 [03:31<06:58,  2.24s/it]predicting train subjects:  35%|███▍      | 99/285 [03:33<06:50,  2.21s/it]predicting train subjects:  35%|███▌      | 100/285 [03:35<06:58,  2.26s/it]predicting train subjects:  35%|███▌      | 101/285 [03:38<06:51,  2.23s/it]predicting train subjects:  36%|███▌      | 102/285 [03:40<06:46,  2.22s/it]predicting train subjects:  36%|███▌      | 103/285 [03:42<06:40,  2.20s/it]predicting train subjects:  36%|███▋      | 104/285 [03:44<06:39,  2.21s/it]predicting train subjects:  37%|███▋      | 105/285 [03:46<06:41,  2.23s/it]predicting train subjects:  37%|███▋      | 106/285 [03:48<06:12,  2.08s/it]predicting train subjects:  38%|███▊      | 107/285 [03:51<06:25,  2.16s/it]predicting train subjects:  38%|███▊      | 108/285 [03:53<06:19,  2.15s/it]predicting train subjects:  38%|███▊      | 109/285 [03:54<06:01,  2.05s/it]predicting train subjects:  39%|███▊      | 110/285 [03:56<05:45,  1.98s/it]predicting train subjects:  39%|███▉      | 111/285 [03:58<05:34,  1.93s/it]predicting train subjects:  39%|███▉      | 112/285 [04:00<05:27,  1.89s/it]predicting train subjects:  40%|███▉      | 113/285 [04:02<05:28,  1.91s/it]predicting train subjects:  40%|████      | 114/285 [04:04<05:28,  1.92s/it]predicting train subjects:  40%|████      | 115/285 [04:06<05:28,  1.93s/it]predicting train subjects:  41%|████      | 116/285 [04:08<05:25,  1.93s/it]predicting train subjects:  41%|████      | 117/285 [04:10<05:21,  1.91s/it]predicting train subjects:  41%|████▏     | 118/285 [04:11<05:10,  1.86s/it]predicting train subjects:  42%|████▏     | 119/285 [04:13<05:11,  1.88s/it]predicting train subjects:  42%|████▏     | 120/285 [04:15<05:02,  1.84s/it]predicting train subjects:  42%|████▏     | 121/285 [04:17<04:57,  1.82s/it]predicting train subjects:  43%|████▎     | 122/285 [04:18<04:42,  1.73s/it]predicting train subjects:  43%|████▎     | 123/285 [04:20<04:26,  1.64s/it]predicting train subjects:  44%|████▎     | 124/285 [04:21<04:23,  1.64s/it]predicting train subjects:  44%|████▍     | 125/285 [04:23<04:15,  1.60s/it]predicting train subjects:  44%|████▍     | 126/285 [04:24<04:09,  1.57s/it]predicting train subjects:  45%|████▍     | 127/285 [04:26<04:00,  1.52s/it]predicting train subjects:  45%|████▍     | 128/285 [04:27<04:07,  1.58s/it]predicting train subjects:  45%|████▌     | 129/285 [04:29<04:03,  1.56s/it]predicting train subjects:  46%|████▌     | 130/285 [04:30<03:59,  1.54s/it]predicting train subjects:  46%|████▌     | 131/285 [04:32<03:50,  1.50s/it]predicting train subjects:  46%|████▋     | 132/285 [04:34<03:59,  1.57s/it]predicting train subjects:  47%|████▋     | 133/285 [04:35<03:56,  1.56s/it]predicting train subjects:  47%|████▋     | 134/285 [04:37<03:54,  1.55s/it]predicting train subjects:  47%|████▋     | 135/285 [04:38<03:48,  1.52s/it]predicting train subjects:  48%|████▊     | 136/285 [04:40<03:46,  1.52s/it]predicting train subjects:  48%|████▊     | 137/285 [04:41<03:52,  1.57s/it]predicting train subjects:  48%|████▊     | 138/285 [04:43<03:47,  1.55s/it]predicting train subjects:  49%|████▉     | 139/285 [04:44<03:51,  1.58s/it]predicting train subjects:  49%|████▉     | 140/285 [04:46<03:52,  1.60s/it]predicting train subjects:  49%|████▉     | 141/285 [04:48<03:42,  1.54s/it]predicting train subjects:  50%|████▉     | 142/285 [04:49<03:42,  1.56s/it]predicting train subjects:  50%|█████     | 143/285 [04:51<03:38,  1.54s/it]predicting train subjects:  51%|█████     | 144/285 [04:52<03:45,  1.60s/it]predicting train subjects:  51%|█████     | 145/285 [04:54<03:42,  1.59s/it]predicting train subjects:  51%|█████     | 146/285 [04:56<03:47,  1.64s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:57<03:40,  1.59s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:59<03:45,  1.65s/it]predicting train subjects:  52%|█████▏    | 149/285 [05:01<03:42,  1.63s/it]predicting train subjects:  53%|█████▎    | 150/285 [05:02<03:38,  1.62s/it]predicting train subjects:  53%|█████▎    | 151/285 [05:04<03:37,  1.62s/it]predicting train subjects:  53%|█████▎    | 152/285 [05:05<03:31,  1.59s/it]predicting train subjects:  54%|█████▎    | 153/285 [05:07<03:29,  1.59s/it]predicting train subjects:  54%|█████▍    | 154/285 [05:09<03:32,  1.62s/it]predicting train subjects:  54%|█████▍    | 155/285 [05:10<03:28,  1.60s/it]predicting train subjects:  55%|█████▍    | 156/285 [05:12<03:31,  1.64s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:13<03:22,  1.58s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:15<03:21,  1.59s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:16<03:15,  1.55s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:18<03:13,  1.55s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:20<03:15,  1.58s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:21<03:10,  1.55s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:23<03:14,  1.59s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:24<03:09,  1.57s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:26<03:06,  1.56s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:27<03:11,  1.61s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:29<03:14,  1.64s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:31<03:06,  1.60s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:32<03:04,  1.59s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:34<02:59,  1.56s/it]predicting train subjects:  60%|██████    | 171/285 [05:35<02:57,  1.56s/it]predicting train subjects:  60%|██████    | 172/285 [05:37<02:55,  1.56s/it]predicting train subjects:  61%|██████    | 173/285 [05:38<02:52,  1.54s/it]predicting train subjects:  61%|██████    | 174/285 [05:40<02:51,  1.54s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:42<02:55,  1.60s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:43<02:56,  1.62s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:45<02:50,  1.58s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:46<02:45,  1.54s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:48<02:44,  1.55s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:50<02:51,  1.63s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:51<02:53,  1.67s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:53<02:55,  1.71s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:55<02:48,  1.65s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:56<02:42,  1.61s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:58<02:39,  1.59s/it]predicting train subjects:  65%|██████▌   | 186/285 [06:00<02:48,  1.70s/it]predicting train subjects:  66%|██████▌   | 187/285 [06:02<02:53,  1.77s/it]predicting train subjects:  66%|██████▌   | 188/285 [06:04<02:53,  1.79s/it]predicting train subjects:  66%|██████▋   | 189/285 [06:05<02:42,  1.70s/it]predicting train subjects:  67%|██████▋   | 190/285 [06:07<02:35,  1.64s/it]predicting train subjects:  67%|██████▋   | 191/285 [06:08<02:36,  1.66s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:10<02:38,  1.70s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:12<02:30,  1.64s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:13<02:25,  1.60s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:15<02:21,  1.57s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:17<02:30,  1.69s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:18<02:35,  1.77s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:20<02:37,  1.81s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:22<02:28,  1.72s/it]predicting train subjects:  70%|███████   | 200/285 [06:23<02:20,  1.65s/it]predicting train subjects:  71%|███████   | 201/285 [06:25<02:22,  1.70s/it]predicting train subjects:  71%|███████   | 202/285 [06:27<02:21,  1.71s/it]predicting train subjects:  71%|███████   | 203/285 [06:29<02:21,  1.73s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:30<02:14,  1.66s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:32<02:09,  1.62s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:33<02:06,  1.60s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:35<02:15,  1.73s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:37<02:18,  1.80s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:39<02:17,  1.81s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:41<02:07,  1.71s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:42<02:01,  1.64s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:44<02:06,  1.73s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:46<02:03,  1.72s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:47<01:57,  1.65s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:49<01:59,  1.71s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:50<01:53,  1.64s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:52<01:57,  1.73s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:54<01:59,  1.78s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:56<02:01,  1.84s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:58<01:53,  1.74s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:59<01:47,  1.68s/it]predicting train subjects:  78%|███████▊  | 222/285 [07:01<01:46,  1.69s/it]predicting train subjects:  78%|███████▊  | 223/285 [07:03<01:40,  1.62s/it]predicting train subjects:  79%|███████▊  | 224/285 [07:04<01:36,  1.58s/it]predicting train subjects:  79%|███████▉  | 225/285 [07:05<01:33,  1.55s/it]predicting train subjects:  79%|███████▉  | 226/285 [07:07<01:38,  1.67s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:09<01:40,  1.73s/it]predicting train subjects:  80%|████████  | 228/285 [07:11<01:40,  1.77s/it]predicting train subjects:  80%|████████  | 229/285 [07:13<01:38,  1.75s/it]predicting train subjects:  81%|████████  | 230/285 [07:14<01:31,  1.67s/it]predicting train subjects:  81%|████████  | 231/285 [07:16<01:27,  1.63s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:18<01:29,  1.68s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:19<01:24,  1.62s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:21<01:26,  1.69s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:23<01:21,  1.63s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:24<01:23,  1.71s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:26<01:25,  1.78s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:28<01:23,  1.78s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:30<01:22,  1.79s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:31<01:15,  1.69s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:33<01:11,  1.64s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:34<01:07,  1.58s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:36<01:04,  1.54s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:38<01:07,  1.64s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:39<01:03,  1.59s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:41<01:06,  1.71s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:43<01:06,  1.75s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:45<01:04,  1.73s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:46<00:59,  1.66s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:48<00:56,  1.61s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:49<00:53,  1.58s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:51<00:50,  1.54s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:53<00:52,  1.65s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:54<00:53,  1.72s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:56<00:51,  1.71s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:58<00:47,  1.63s/it]predicting train subjects:  90%|█████████ | 257/285 [07:59<00:44,  1.59s/it]predicting train subjects:  91%|█████████ | 258/285 [08:01<00:45,  1.67s/it]predicting train subjects:  91%|█████████ | 259/285 [08:03<00:44,  1.70s/it]predicting train subjects:  91%|█████████ | 260/285 [08:04<00:40,  1.64s/it]predicting train subjects:  92%|█████████▏| 261/285 [08:06<00:38,  1.59s/it]predicting train subjects:  92%|█████████▏| 262/285 [08:07<00:36,  1.57s/it]predicting train subjects:  92%|█████████▏| 263/285 [08:09<00:34,  1.57s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:11<00:34,  1.67s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:12<00:34,  1.72s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:14<00:31,  1.65s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:15<00:28,  1.59s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:17<00:28,  1.68s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:19<00:27,  1.72s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:21<00:24,  1.65s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:22<00:22,  1.60s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:24<00:21,  1.66s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:25<00:19,  1.62s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:27<00:17,  1.60s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:29<00:17,  1.71s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:31<00:15,  1.76s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:32<00:13,  1.69s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:34<00:11,  1.65s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:36<00:10,  1.68s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:37<00:08,  1.63s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:39<00:06,  1.59s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:40<00:04,  1.54s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:42<00:03,  1.65s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:44<00:01,  1.73s/it]predicting train subjects: 100%|██████████| 285/285 [08:46<00:00,  1.78s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:39,  1.62s/it]Loading train:   1%|          | 2/285 [00:03<07:21,  1.56s/it]Loading train:   1%|          | 3/285 [00:04<07:16,  1.55s/it]Loading train:   1%|▏         | 4/285 [00:05<07:02,  1.51s/it]Loading train:   2%|▏         | 5/285 [00:07<07:15,  1.55s/it]Loading train:   2%|▏         | 6/285 [00:08<06:54,  1.49s/it]Loading train:   2%|▏         | 7/285 [00:10<07:13,  1.56s/it]Loading train:   3%|▎         | 8/285 [00:12<07:00,  1.52s/it]Loading train:   3%|▎         | 9/285 [00:13<07:27,  1.62s/it]Loading train:   4%|▎         | 10/285 [00:15<07:03,  1.54s/it]Loading train:   4%|▍         | 11/285 [00:16<06:25,  1.41s/it]Loading train:   4%|▍         | 12/285 [00:17<05:52,  1.29s/it]Loading train:   5%|▍         | 13/285 [00:18<05:17,  1.17s/it]Loading train:   5%|▍         | 14/285 [00:19<05:16,  1.17s/it]Loading train:   5%|▌         | 15/285 [00:20<05:32,  1.23s/it]Loading train:   6%|▌         | 16/285 [00:22<05:37,  1.25s/it]Loading train:   6%|▌         | 17/285 [00:23<05:10,  1.16s/it]Loading train:   6%|▋         | 18/285 [00:24<04:53,  1.10s/it]Loading train:   7%|▋         | 19/285 [00:25<04:40,  1.05s/it]Loading train:   7%|▋         | 20/285 [00:25<04:28,  1.01s/it]Loading train:   7%|▋         | 21/285 [00:27<04:41,  1.07s/it]Loading train:   8%|▊         | 22/285 [00:27<04:21,  1.01it/s]Loading train:   8%|▊         | 23/285 [00:28<04:11,  1.04it/s]Loading train:   8%|▊         | 24/285 [00:29<04:02,  1.08it/s]Loading train:   9%|▉         | 25/285 [00:30<04:04,  1.06it/s]Loading train:   9%|▉         | 26/285 [00:31<04:04,  1.06it/s]Loading train:   9%|▉         | 27/285 [00:32<04:04,  1.05it/s]Loading train:  10%|▉         | 28/285 [00:33<04:12,  1.02it/s]Loading train:  10%|█         | 29/285 [00:34<04:03,  1.05it/s]Loading train:  11%|█         | 30/285 [00:35<04:09,  1.02it/s]Loading train:  11%|█         | 31/285 [00:36<04:05,  1.03it/s]Loading train:  11%|█         | 32/285 [00:37<03:55,  1.08it/s]Loading train:  12%|█▏        | 33/285 [00:38<03:48,  1.10it/s]Loading train:  12%|█▏        | 34/285 [00:39<03:52,  1.08it/s]Loading train:  12%|█▏        | 35/285 [00:40<03:59,  1.05it/s]Loading train:  13%|█▎        | 36/285 [00:41<03:51,  1.07it/s]Loading train:  13%|█▎        | 37/285 [00:42<04:01,  1.03it/s]Loading train:  13%|█▎        | 38/285 [00:43<03:57,  1.04it/s]Loading train:  14%|█▎        | 39/285 [00:43<03:49,  1.07it/s]Loading train:  14%|█▍        | 40/285 [00:44<03:53,  1.05it/s]Loading train:  14%|█▍        | 41/285 [00:45<03:50,  1.06it/s]Loading train:  15%|█▍        | 42/285 [00:46<03:36,  1.12it/s]Loading train:  15%|█▌        | 43/285 [00:47<03:38,  1.11it/s]Loading train:  15%|█▌        | 44/285 [00:48<03:41,  1.09it/s]Loading train:  16%|█▌        | 45/285 [00:49<03:36,  1.11it/s]Loading train:  16%|█▌        | 46/285 [00:50<03:43,  1.07it/s]Loading train:  16%|█▋        | 47/285 [00:51<03:33,  1.11it/s]Loading train:  17%|█▋        | 48/285 [00:52<03:41,  1.07it/s]Loading train:  17%|█▋        | 49/285 [00:53<03:46,  1.04it/s]Loading train:  18%|█▊        | 50/285 [00:54<03:40,  1.07it/s]Loading train:  18%|█▊        | 51/285 [00:55<03:42,  1.05it/s]Loading train:  18%|█▊        | 52/285 [00:56<03:39,  1.06it/s]Loading train:  19%|█▊        | 53/285 [00:56<03:34,  1.08it/s]Loading train:  19%|█▉        | 54/285 [00:57<03:44,  1.03it/s]Loading train:  19%|█▉        | 55/285 [00:58<03:40,  1.04it/s]Loading train:  20%|█▉        | 56/285 [00:59<03:42,  1.03it/s]Loading train:  20%|██        | 57/285 [01:00<03:33,  1.07it/s]Loading train:  20%|██        | 58/285 [01:01<03:29,  1.08it/s]Loading train:  21%|██        | 59/285 [01:02<03:35,  1.05it/s]Loading train:  21%|██        | 60/285 [01:03<03:37,  1.03it/s]Loading train:  21%|██▏       | 61/285 [01:04<03:26,  1.08it/s]Loading train:  22%|██▏       | 62/285 [01:05<03:23,  1.10it/s]Loading train:  22%|██▏       | 63/285 [01:06<03:34,  1.04it/s]Loading train:  22%|██▏       | 64/285 [01:07<03:56,  1.07s/it]Loading train:  23%|██▎       | 65/285 [01:09<04:25,  1.21s/it]
Epoch 00056: val_mDice did not improve from 0.63090
Restoring model weights from the end of the best epoch
Epoch 00056: early stopping
{'val_loss': [0.8464328250405508, 0.6295266610950065, 0.618565500448536, 0.5486032972788678, 0.6103382383644914, 0.4898027707744577, 0.49489753173050266, 0.4712605426431368, 0.4993528647129762, 0.4490297306849304, 0.48791672963669847, 0.47313602709903396, 0.46805624289219605, 0.4844244595346504, 0.4657064742882159, 0.44585966464527493, 0.47153047409803506, 0.4584253217254937, 0.5132756113340069, 0.48591567850645695, 0.47396266027535805, 0.4824170320393653, 0.5305159384977884, 0.5075980394912165, 0.5845904003974446, 0.4848659751135544, 0.5183736375590277, 0.5698052881150272, 0.4962721770036154, 0.4876755472668056, 0.4701697972899709, 0.46817920227956505, 0.5000894089650841, 0.500596118039925, 0.4920625014012086, 0.509304959680781, 0.5103266292444154, 0.4943491117248322, 0.48654132182371684, 0.4856954773045119, 0.5008004940421887, 0.48261899721689067, 0.47159093851483735, 0.4574861250110179, 0.5308255117032781, 0.5321973066090205, 0.514086870507821, 0.516181680077281, 0.48525952293886154, 0.47683123869602906, 0.4661632130265902, 0.4846956992948521, 0.4803830471784709, 0.47145357944445904, 0.47817489088580595, 0.4896201987506291], 'val_acc': [0.9170709222388667, 0.9241244110315205, 0.9283804620444441, 0.941846952425035, 0.9469542230307723, 0.951565655250123, 0.9506255980976467, 0.9503115618695094, 0.9502309980339179, 0.9519830079718009, 0.9496421597523397, 0.9504706663126387, 0.9526482500843496, 0.9527887642050589, 0.9523858677741536, 0.9537473910347709, 0.9521028292911679, 0.9525160220082246, 0.9523652149312323, 0.9524085734809578, 0.9533713956118962, 0.9530222159524203, 0.9520718402036742, 0.952945780154713, 0.9531234616007884, 0.9519127534088476, 0.9519747425724008, 0.9519251405193819, 0.9528858625023059, 0.9514024127795043, 0.9519230923173148, 0.9519354860875859, 0.9525304916184708, 0.9507702182791087, 0.9535759197933048, 0.9537494702046144, 0.9527371039603676, 0.950179324136766, 0.951040858995981, 0.9532474092931055, 0.9521937403598977, 0.9539044352883067, 0.9546027586446794, 0.9535180693232147, 0.9513549072116447, 0.948621540096219, 0.9520552900916371, 0.9518032713309347, 0.9519933092527549, 0.9532411977565488, 0.9522122977166202, 0.9507702422541613, 0.9533032065663258, 0.9534870639193658, 0.953520146828124, 0.9512412754517028], 'val_mDice': [0.42019775593081, 0.519232000052596, 0.5353979924537616, 0.568943143223917, 0.5592631174865381, 0.6073996571189199, 0.6063787757351412, 0.616282185362704, 0.5960602680398099, 0.6296840486579767, 0.6055601921827434, 0.6139267416639701, 0.6208634383185616, 0.6158086188012661, 0.6196777464291237, 0.6308981696320646, 0.6182689749994758, 0.6248203436089628, 0.6040050390712376, 0.6128748002665003, 0.6171798086699161, 0.6113643955917998, 0.5935449939866305, 0.6150811158079009, 0.5915505686285776, 0.6167074268756632, 0.6055190646448615, 0.5922426441528278, 0.6065292877857912, 0.6101896469819479, 0.6147212562614313, 0.621236665954803, 0.6057334069433159, 0.6053771896069277, 0.6176593270381736, 0.6099760718851782, 0.6065206630935882, 0.6056015418228491, 0.6116973468045283, 0.6160616618294955, 0.6118737445863266, 0.6154994345244083, 0.6213875049985321, 0.6249316084984294, 0.5922354486401521, 0.5925917222513167, 0.5988235367077023, 0.5987629524156368, 0.6133503197957684, 0.61611900882348, 0.62316813016071, 0.607026290960152, 0.614038521351095, 0.616346510428956, 0.6161462354926424, 0.6067709213528554], 'loss': [2.067182271018682, 0.6973796315938778, 0.5270888426810151, 0.4509450023577212, 0.4157113477747578, 0.3885772851848192, 0.3708020900580808, 0.3562199842675982, 0.34465916009972764, 0.3371576489488593, 0.32924138860799645, 0.3232431457434323, 0.32422036103781293, 0.31089228799215723, 0.3079538686941226, 0.30362551033506596, 0.2979642258468364, 0.294431047174745, 0.29225947895566073, 0.2901116500693685, 0.2856807692898468, 0.28081906462675293, 0.2795914832309248, 0.27706740079222925, 0.27435466365697087, 0.2731667305949752, 0.2705389759579643, 0.2673266598516856, 0.30943620780650377, 0.28457566204981816, 0.27204638907192746, 0.26540386296488555, 0.2636506802784735, 0.2602956518745911, 0.2601286669334135, 0.25797398089486057, 0.25676822473258665, 0.2559244952372402, 0.2545361797519125, 0.25453101074433937, 0.25397158188307234, 0.25091859783834636, 0.25009813160718664, 0.248083883392792, 0.24763153040794095, 0.24821838876042293, 0.24594588293050032, 0.2445475798365818, 0.2460556684249458, 0.24434024933720525, 0.243187976287806, 0.24218334699013375, 0.24148674758942348, 0.23925752389580976, 0.2390150740522749, 0.2399448910626144], 'acc': [0.7041392121933708, 0.8976129914289673, 0.9065416036468401, 0.917536613893927, 0.9275730427596623, 0.9362082073134175, 0.9444546418202728, 0.9472949281736602, 0.9482753485267533, 0.9489218180270881, 0.9497099252322629, 0.9502351386576565, 0.9501977354072225, 0.9511755760488255, 0.9514766747730372, 0.9517943108336974, 0.9521456632951227, 0.9524713968452847, 0.9526777270897094, 0.9528516513947717, 0.9530477909232581, 0.9534634165297432, 0.9535646669310582, 0.953759639408326, 0.9539563254777411, 0.9540413441069018, 0.954221613737215, 0.9545355596013088, 0.9513033364282819, 0.953271425021616, 0.9542276930538932, 0.9546682342816318, 0.9548638512818007, 0.9551623521706331, 0.9551115749734244, 0.9552539964106846, 0.9553635684559986, 0.9554574488879328, 0.9554905607500248, 0.9555979608762278, 0.9556036779131416, 0.9558823818371229, 0.9558959551596653, 0.9559727561388794, 0.9561255905280335, 0.9561006757345771, 0.9562432570438241, 0.9563390532776613, 0.9563337811249337, 0.9564332362710959, 0.9564678397003871, 0.9565259273921825, 0.9565769873714078, 0.9567263570105053, 0.9567652724873597, 0.956737758946324], 'mDice': [0.20803020795252639, 0.4843463342009686, 0.5762264149347802, 0.6232849594444421, 0.6465801073636023, 0.6650697210243952, 0.6765158447420199, 0.6862563082000722, 0.6941590356765752, 0.6996228286081342, 0.7055115901945359, 0.7097519316527067, 0.7096612637166747, 0.7189619727114188, 0.7213443213315267, 0.7244061014535517, 0.7286763583079616, 0.7313348817790257, 0.7330555264372354, 0.7347777660139362, 0.7379936221430072, 0.7416976556708614, 0.7428106158544903, 0.7446644056285494, 0.7467857666650853, 0.7477162250875939, 0.7498290994433392, 0.7524306135729217, 0.7239873294613212, 0.7387874709333406, 0.7486009902927092, 0.7537389074617933, 0.7552080657005465, 0.7578593404404342, 0.7580057662541385, 0.7597277416986069, 0.7606603438009799, 0.7614154127043944, 0.7624280671364121, 0.7625608911903055, 0.7629815150720025, 0.7654025670483665, 0.7660195212836594, 0.7675612576808631, 0.7679907932506655, 0.7674800971612504, 0.7693096352853219, 0.7704383337700927, 0.7693516465484119, 0.770666359063165, 0.7715811434345797, 0.7724156029070782, 0.7729546328358619, 0.7747473983773479, 0.7749058883970946, 0.7742576453526174]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values minLoading train:  23%|██▎       | 66/285 [01:10<04:30,  1.23s/it]Loading train:  24%|██▎       | 67/285 [01:11<04:11,  1.15s/it]Loading train:  24%|██▍       | 68/285 [01:12<03:58,  1.10s/it]Loading train:  24%|██▍       | 69/285 [01:13<03:46,  1.05s/it]Loading train:  25%|██▍       | 70/285 [01:14<03:34,  1.00it/s]Loading train:  25%|██▍       | 71/285 [01:15<03:33,  1.00it/s]Loading train:  25%|██▌       | 72/285 [01:16<03:26,  1.03it/s]Loading train:  26%|██▌       | 73/285 [01:17<03:26,  1.03it/s]Loading train:  26%|██▌       | 74/285 [01:18<03:25,  1.03it/s]Loading train:  26%|██▋       | 75/285 [01:19<03:22,  1.04it/s]Loading train:  27%|██▋       | 76/285 [01:20<03:17,  1.06it/s]Loading train:  27%|██▋       | 77/285 [01:20<03:07,  1.11it/s]Loading train:  27%|██▋       | 78/285 [01:21<03:00,  1.15it/s]Loading train:  28%|██▊       | 79/285 [01:22<02:59,  1.15it/s]Loading train:  28%|██▊       | 80/285 [01:23<02:59,  1.14it/s]Loading train:  28%|██▊       | 81/285 [01:24<02:51,  1.19it/s]Loading train:  29%|██▉       | 82/285 [01:25<03:01,  1.12it/s]Loading train:  29%|██▉       | 83/285 [01:26<02:55,  1.15it/s]Loading train:  29%|██▉       | 84/285 [01:26<02:43,  1.23it/s]Loading train:  30%|██▉       | 85/285 [01:27<02:47,  1.19it/s]Loading train:  30%|███       | 86/285 [01:28<02:49,  1.18it/s]Loading train:  31%|███       | 87/285 [01:29<02:55,  1.13it/s]Loading train:  31%|███       | 88/285 [01:30<02:45,  1.19it/s]Loading train:  31%|███       | 89/285 [01:31<02:44,  1.19it/s]Loading train:  32%|███▏      | 90/285 [01:31<02:46,  1.17it/s]Loading train:  32%|███▏      | 91/285 [01:32<02:45,  1.17it/s]Loading train:  32%|███▏      | 92/285 [01:33<02:52,  1.12it/s]Loading train:  33%|███▎      | 93/285 [01:34<02:43,  1.18it/s]Loading train:  33%|███▎      | 94/285 [01:35<02:49,  1.13it/s]Loading train:  33%|███▎      | 95/285 [01:36<02:52,  1.10it/s]Loading train:  34%|███▎      | 96/285 [01:37<02:46,  1.13it/s]Loading train:  34%|███▍      | 97/285 [01:38<02:49,  1.11it/s]Loading train:  34%|███▍      | 98/285 [01:39<02:47,  1.12it/s]Loading train:  35%|███▍      | 99/285 [01:39<02:44,  1.13it/s]Loading train:  35%|███▌      | 100/285 [01:40<02:40,  1.15it/s]Loading train:  35%|███▌      | 101/285 [01:41<02:36,  1.18it/s]Loading train:  36%|███▌      | 102/285 [01:42<02:33,  1.19it/s]Loading train:  36%|███▌      | 103/285 [01:43<02:28,  1.23it/s]Loading train:  36%|███▋      | 104/285 [01:44<02:36,  1.16it/s]Loading train:  37%|███▋      | 105/285 [01:44<02:34,  1.16it/s]Loading train:  37%|███▋      | 106/285 [01:45<02:22,  1.26it/s]Loading train:  38%|███▊      | 107/285 [01:46<02:30,  1.18it/s]Loading train:  38%|███▊      | 108/285 [01:47<02:28,  1.19it/s]Loading train:  38%|███▊      | 109/285 [01:48<02:31,  1.16it/s]Loading train:  39%|███▊      | 110/285 [01:49<02:34,  1.13it/s]Loading train:  39%|███▉      | 111/285 [01:49<02:24,  1.20it/s]Loading train:  39%|███▉      | 112/285 [01:50<02:24,  1.20it/s]Loading train:  40%|███▉      | 113/285 [01:51<02:28,  1.16it/s]Loading train:  40%|████      | 114/285 [01:52<02:32,  1.12it/s]Loading train:  40%|████      | 115/285 [01:53<02:31,  1.12it/s]Loading train:  41%|████      | 116/285 [01:54<02:35,  1.08it/s]Loading train:  41%|████      | 117/285 [01:55<02:32,  1.10it/s]Loading train:  41%|████▏     | 118/285 [01:56<02:27,  1.13it/s]Loading train:  42%|████▏     | 119/285 [01:57<02:30,  1.10it/s]Loading train:  42%|████▏     | 120/285 [01:58<02:23,  1.15it/s]Loading train:  42%|████▏     | 121/285 [01:59<02:42,  1.01it/s]Loading train:  43%|████▎     | 122/285 [02:00<02:52,  1.06s/it]Loading train:  43%|████▎     | 123/285 [02:01<03:00,  1.11s/it]Loading train:  44%|████▎     | 124/285 [02:02<02:48,  1.05s/it]Loading train:  44%|████▍     | 125/285 [02:03<02:32,  1.05it/s]Loading train:  44%|████▍     | 126/285 [02:04<02:24,  1.10it/s]Loading train:  45%|████▍     | 127/285 [02:04<02:18,  1.14it/s]Loading train:  45%|████▍     | 128/285 [02:05<02:18,  1.14it/s]Loading train:  45%|████▌     | 129/285 [02:06<02:14,  1.16it/s]Loading train:  46%|████▌     | 130/285 [02:07<02:04,  1.24it/s]Loading train:  46%|████▌     | 131/285 [02:08<02:03,  1.25it/s]Loading train:  46%|████▋     | 132/285 [02:09<02:04,  1.23it/s]Loading train:  47%|████▋     | 133/285 [02:09<02:02,  1.24it/s]Loading train:  47%|████▋     | 134/285 [02:10<01:57,  1.28it/s]Loading train:  47%|████▋     | 135/285 [02:11<02:04,  1.21it/s]Loading train:  48%|████▊     | 136/285 [02:12<02:00,  1.24it/s]Loading train:  48%|████▊     | 137/285 [02:13<02:01,  1.22it/s]Loading train:  48%|████▊     | 138/285 [02:13<01:58,  1.24it/s]Loading train:  49%|████▉     | 139/285 [02:14<01:57,  1.25it/s]Loading train:  49%|████▉     | 140/285 [02:15<01:58,  1.22it/s]Loading train:  49%|████▉     | 141/285 [02:16<01:55,  1.25it/s]Loading train:  50%|████▉     | 142/285 [02:17<01:55,  1.24it/s]Loading train:  50%|█████     | 143/285 [02:17<01:55,  1.23it/s]Loading train:  51%|█████     | 144/285 [02:18<02:02,  1.15it/s]Loading train:  51%|█████     | 145/285 [02:19<01:57,  1.19it/s]Loading train:  51%|█████     | 146/285 [02:20<01:56,  1.19it/s]Loading train:  52%|█████▏    | 147/285 [02:21<01:56,  1.18it/s]Loading train:  52%|█████▏    | 148/285 [02:22<01:55,  1.18it/s]Loading train:  52%|█████▏    | 149/285 [02:22<01:51,  1.22it/s]Loading train:  53%|█████▎    | 150/285 [02:23<01:47,  1.26it/s]Loading train:  53%|█████▎    | 151/285 [02:24<01:53,  1.18it/s]Loading train:  53%|█████▎    | 152/285 [02:25<01:51,  1.19it/s]Loading train:  54%|█████▎    | 153/285 [02:26<01:51,  1.18it/s]Loading train:  54%|█████▍    | 154/285 [02:27<01:51,  1.17it/s]Loading train:  54%|█████▍    | 155/285 [02:27<01:46,  1.22it/s]Loading train:  55%|█████▍    | 156/285 [02:28<01:43,  1.25it/s]Loading train:  55%|█████▌    | 157/285 [02:29<01:44,  1.22it/s]Loading train:  55%|█████▌    | 158/285 [02:30<01:45,  1.21it/s]Loading train:  56%|█████▌    | 159/285 [02:31<01:44,  1.21it/s]Loading train:  56%|█████▌    | 160/285 [02:32<01:41,  1.23it/s]Loading train:  56%|█████▋    | 161/285 [02:32<01:39,  1.25it/s]Loading train:  57%|█████▋    | 162/285 [02:33<01:34,  1.30it/s]Loading train:  57%|█████▋    | 163/285 [02:34<01:34,  1.29it/s]Loading train:  58%|█████▊    | 164/285 [02:35<01:36,  1.26it/s]Loading train:  58%|█████▊    | 165/285 [02:35<01:35,  1.25it/s]Loading train:  58%|█████▊    | 166/285 [02:36<01:38,  1.20it/s]Loading train:  59%|█████▊    | 167/285 [02:37<01:41,  1.16it/s]Loading train:  59%|█████▉    | 168/285 [02:38<01:37,  1.19it/s]Loading train:  59%|█████▉    | 169/285 [02:39<01:39,  1.17it/s]Loading train:  60%|█████▉    | 170/285 [02:40<01:35,  1.20it/s]Loading train:  60%|██████    | 171/285 [02:40<01:31,  1.24it/s]Loading train:  60%|██████    | 172/285 [02:41<01:27,  1.29it/s]Loading train:  61%|██████    | 173/285 [02:42<01:23,  1.34it/s]Loading train:  61%|██████    | 174/285 [02:43<01:22,  1.34it/s]Loading train:  61%|██████▏   | 175/285 [02:43<01:24,  1.31it/s]Loading train:  62%|██████▏   | 176/285 [02:44<01:25,  1.28it/s]Loading train:  62%|██████▏   | 177/285 [02:45<01:26,  1.25it/s]Loading train:  62%|██████▏   | 178/285 [02:46<01:24,  1.27it/s]Loading train:  63%|██████▎   | 179/285 [02:47<01:23,  1.27it/s]Loading train:  63%|██████▎   | 180/285 [02:48<01:26,  1.21it/s]Loading train:  64%|██████▎   | 181/285 [02:48<01:26,  1.20it/s]Loading train:  64%|██████▍   | 182/285 [02:49<01:26,  1.20it/s]Loading train:  64%|██████▍   | 183/285 [02:50<01:23,  1.23it/s]Loading train:  65%|██████▍   | 184/285 [02:51<01:21,  1.25it/s]Loading train:  65%|██████▍   | 185/285 [02:52<01:20,  1.25it/s]Loading train:  65%|██████▌   | 186/285 [02:52<01:22,  1.21it/s]Loading train:  66%|██████▌   | 187/285 [02:53<01:22,  1.19it/s]Loading train:  66%|██████▌   | 188/285 [02:54<01:21,  1.18it/s]Loading train:  66%|██████▋   | 189/285 [02:55<01:16,  1.26it/s]Loading train:  67%|██████▋   | 190/285 [02:56<01:15,  1.25it/s]Loading train:  67%|██████▋   | 191/285 [02:57<01:16,  1.23it/s]Loading train:  67%|██████▋   | 192/285 [02:57<01:17,  1.20it/s]Loading train:  68%|██████▊   | 193/285 [02:58<01:11,  1.29it/s]Loading train:  68%|██████▊   | 194/285 [02:59<01:08,  1.32it/s]Loading train:  68%|██████▊   | 195/285 [03:00<01:08,  1.32it/s]Loading train:  69%|██████▉   | 196/285 [03:00<01:13,  1.22it/s]Loading train:  69%|██████▉   | 197/285 [03:01<01:14,  1.19it/s]Loading train:  69%|██████▉   | 198/285 [03:02<01:14,  1.17it/s]Loading train:  70%|██████▉   | 199/285 [03:03<01:10,  1.22it/s]Loading train:  70%|███████   | 200/285 [03:04<01:08,  1.24it/s]Loading train:  71%|███████   | 201/285 [03:05<01:09,  1.22it/s]Loading train:  71%|███████   | 202/285 [03:05<01:06,  1.25it/s]Loading train:  71%|███████   | 203/285 [03:06<01:06,  1.24it/s]Loading train:  72%|███████▏  | 204/285 [03:07<01:03,  1.27it/s]Loading train:  72%|███████▏  | 205/285 [03:08<01:01,  1.30it/s]Loading train:  72%|███████▏  | 206/285 [03:08<01:00,  1.31it/s]Loading train:  73%|███████▎  | 207/285 [03:09<01:03,  1.23it/s]Loading train:  73%|███████▎  | 208/285 [03:10<01:04,  1.20it/s]Loading train:  73%|███████▎  | 209/285 [03:11<01:04,  1.17it/s]Loading train:  74%|███████▎  | 210/285 [03:12<01:01,  1.22it/s]Loading train:  74%|███████▍  | 211/285 [03:13<00:56,  1.30it/s]Loading train:  74%|███████▍  | 212/285 [03:13<00:56,  1.29it/s]Loading train:  75%|███████▍  | 213/285 [03:14<00:58,  1.23it/s]Loading train:  75%|███████▌  | 214/285 [03:15<00:54,  1.31it/s]Loading train:  75%|███████▌  | 215/285 [03:16<00:58,  1.19it/s]Loading train:  76%|███████▌  | 216/285 [03:17<00:58,  1.18it/s]Loading train:  76%|███████▌  | 217/285 [03:18<01:00,  1.12it/s]Loading train:  76%|███████▋  | 218/285 [03:19<01:01,  1.08it/s]Loading train:  77%|███████▋  | 219/285 [03:20<01:02,  1.05it/s]Loading train:  77%|███████▋  | 220/285 [03:21<00:59,  1.10it/s]Loading train:  78%|███████▊  | 221/285 [03:21<00:54,  1.17it/s]Loading train:  78%|███████▊  | 222/285 [03:22<00:51,  1.22it/s]Loading train:  78%|███████▊  | 223/285 [03:23<00:49,  1.25it/s]Loading train:  79%|███████▊  | 224/285 [03:24<00:47,  1.29it/s]Loading train:  79%|███████▉  | 225/285 [03:24<00:45,  1.31it/s]Loading train:  79%|███████▉  | 226/285 [03:25<00:44,  1.32it/s]Loading train:  80%|███████▉  | 227/285 [03:26<00:44,  1.31it/s]Loading train:  80%|████████  | 228/285 [03:27<00:44,  1.28it/s]Loading train:  80%|████████  | 229/285 [03:27<00:44,  1.26it/s]Loading train:  81%|████████  | 230/285 [03:28<00:40,  1.35it/s]Loading train:  81%|████████  | 231/285 [03:29<00:39,  1.38it/s]Loading train:  81%|████████▏ | 232/285 [03:30<00:40,  1.32it/s]Loading train:  82%|████████▏ | 233/285 [03:30<00:38,  1.34it/s]Loading train:  82%|████████▏ | 234/285 [03:31<00:41,  1.22it/s]Loading train:  82%|████████▏ | 235/285 [03:32<00:40,  1.25it/s]Loading train:  83%|████████▎ | 236/285 [03:33<00:40,  1.20it/s]Loading train:  83%|████████▎ | 237/285 [03:34<00:40,  1.20it/s]Loading train:  84%|████████▎ | 238/285 [03:35<00:39,  1.18it/s]Loading train:  84%|████████▍ | 239/285 [03:35<00:37,  1.24it/s]Loading train:  84%|████████▍ | 240/285 [03:36<00:35,  1.28it/s]Loading train:  85%|████████▍ | 241/285 [03:37<00:33,  1.32it/s]Loading train:  85%|████████▍ | 242/285 [03:37<00:31,  1.36it/s]Loading train:  85%|████████▌ | 243/285 [03:38<00:29,  1.40it/s]Loading train:  86%|████████▌ | 244/285 [03:39<00:30,  1.33it/s]Loading train:  86%|████████▌ | 245/285 [03:40<00:30,  1.33it/s]Loading train:  86%|████████▋ | 246/285 [03:41<00:30,  1.27it/s]Loading train:  87%|████████▋ | 247/285 [03:42<00:31,  1.19it/s]Loading train:  87%|████████▋ | 248/285 [03:42<00:30,  1.19it/s]Loading train:  87%|████████▋ | 249/285 [03:43<00:28,  1.24it/s]Loading train:  88%|████████▊ | 250/285 [03:44<00:27,  1.27it/s]Loading train:  88%|████████▊ | 251/285 [03:45<00:25,  1.34it/s]Loading train:  88%|████████▊ | 252/285 [03:45<00:24,  1.33it/s]Loading train:  89%|████████▉ | 253/285 [03:46<00:26,  1.22it/s]Loading train:  89%|████████▉ | 254/285 [03:47<00:26,  1.15it/s]Loading train:  89%|████████▉ | 255/285 [03:48<00:24,  1.21it/s]Loading train:  90%|████████▉ | 256/285 [03:49<00:22,  1.30it/s]Loading train:  90%|█████████ | 257/285 [03:49<00:20,  1.37it/s]Loading train:  91%|█████████ | 258/285 [03:50<00:20,  1.33it/s]Loading train:  91%|█████████ | 259/285 [03:51<00:19,  1.35it/s]Loading train:  91%|█████████ | 260/285 [03:51<00:17,  1.39it/s]Loading train:  92%|█████████▏| 261/285 [03:52<00:17,  1.37it/s]Loading train:  92%|█████████▏| 262/285 [03:53<00:16,  1.36it/s]Loading train:  92%|█████████▏| 263/285 [03:54<00:16,  1.33it/s]Loading train:  93%|█████████▎| 264/285 [03:55<00:16,  1.25it/s]Loading train:  93%|█████████▎| 265/285 [03:56<00:16,  1.18it/s]Loading train:  93%|█████████▎| 266/285 [03:56<00:15,  1.26it/s]Loading train:  94%|█████████▎| 267/285 [03:57<00:13,  1.33it/s]Loading train:  94%|█████████▍| 268/285 [03:58<00:13,  1.24it/s]Loading train:  94%|█████████▍| 269/285 [03:59<00:13,  1.20it/s]Loading train:  95%|█████████▍| 270/285 [03:59<00:11,  1.26it/s]Loading train:  95%|█████████▌| 271/285 [04:00<00:10,  1.29it/s]Loading train:  95%|█████████▌| 272/285 [04:01<00:10,  1.23it/s]Loading train:  96%|█████████▌| 273/285 [04:02<00:09,  1.27it/s]Loading train:  96%|█████████▌| 274/285 [04:03<00:08,  1.28it/s]Loading train:  96%|█████████▋| 275/285 [04:03<00:08,  1.21it/s]Loading train:  97%|█████████▋| 276/285 [04:04<00:07,  1.17it/s]Loading train:  97%|█████████▋| 277/285 [04:05<00:06,  1.21it/s]Loading train:  98%|█████████▊| 278/285 [04:06<00:05,  1.27it/s]Loading train:  98%|█████████▊| 279/285 [04:07<00:04,  1.27it/s]Loading train:  98%|█████████▊| 280/285 [04:07<00:03,  1.31it/s]Loading train:  99%|█████████▊| 281/285 [04:08<00:03,  1.27it/s]Loading train:  99%|█████████▉| 282/285 [04:09<00:02,  1.27it/s]Loading train:  99%|█████████▉| 283/285 [04:10<00:01,  1.23it/s]Loading train: 100%|█████████▉| 284/285 [04:11<00:00,  1.22it/s]Loading train: 100%|██████████| 285/285 [04:12<00:00,  1.17it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:  10%|▉         | 28/285 [00:00<00:00, 275.37it/s]concatenating: train:  21%|██▏       | 61/285 [00:00<00:00, 286.89it/s]concatenating: train:  33%|███▎      | 93/285 [00:00<00:00, 295.58it/s]concatenating: train:  44%|████▍     | 126/285 [00:00<00:00, 302.80it/s]concatenating: train:  55%|█████▍    | 156/285 [00:00<00:00, 299.10it/s]concatenating: train:  66%|██████▌   | 187/285 [00:00<00:00, 299.69it/s]concatenating: train:  77%|███████▋  | 220/285 [00:00<00:00, 307.27it/s]concatenating: train:  88%|████████▊ | 251/285 [00:00<00:00, 307.92it/s]concatenating: train: 100%|██████████| 285/285 [00:00<00:00, 316.08it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.17s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.16s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.12s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 456.17it/s]2019-07-11 07:04:17.899497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 07:04:17.899620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 07:04:17.899638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 07:04:17.899648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 07:04:17.900070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.40it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.43it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  6.15it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.89it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:04,  8.40it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  7.29it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02,  9.37it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.72it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:02,  7.83it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:01,  9.67it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01, 10.16it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01, 10.37it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:02<00:01,  8.28it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00, 10.07it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00, 10.34it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 10.41it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  8.03it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 11.41it/s] 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 26, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 26, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 26, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 26, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 13, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 13, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 13, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 20, 13, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 40, 26, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 40, 26, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 40, 26, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 80, 52, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 80, 52, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 52, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 80, 52, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 30)   16230       dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 30)   120         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 30)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 80, 52, 30)   0           activation_11[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 30)   8130        dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 80, 52, 30)   120         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 52, 30)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 80, 52, 30)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 90)   0           dropout_5[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 52, 13)   1183        concatenate_7[0][0]              
==================================================================================================
Total params: 248,823
Trainable params: 74,023
Non-trainable params: 174,800
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 16s - loss: 2.8202 - acc: 0.3295 - mDice: 0.1082 - val_loss: 2.6179 - val_acc: 0.8544 - val_mDice: 0.1806

Epoch 00001: val_mDice improved from -inf to 0.18057, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 12s - loss: 1.1161 - acc: 0.8706 - mDice: 0.3347 - val_loss: 1.5523 - val_acc: 0.8861 - val_mDice: 0.2822

Epoch 00002: val_mDice improved from 0.18057 to 0.28224, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 11s - loss: 0.7927 - acc: 0.8899 - mDice: 0.4381 - val_loss: 1.0870 - val_acc: 0.9160 - val_mDice: 0.4275

Epoch 00003: val_mDice improved from 0.28224 to 0.42748, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 11s - loss: 0.6713 - acc: 0.9004 - mDice: 0.4948 - val_loss: 0.9790 - val_acc: 0.9242 - val_mDice: 0.4783

Epoch 00004: val_mDice improved from 0.42748 to 0.47830, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 11s - loss: 0.5968 - acc: 0.9129 - mDice: 0.5334 - val_loss: 0.9575 - val_acc: 0.9232 - val_mDice: 0.4898

Epoch 00005: val_mDice improved from 0.47830 to 0.48980, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 11s - loss: 0.5484 - acc: 0.9213 - mDice: 0.5608 - val_loss: 0.9294 - val_acc: 0.9272 - val_mDice: 0.5080

Epoch 00006: val_mDice improved from 0.48980 to 0.50800, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 11s - loss: 0.5143 - acc: 0.9252 - mDice: 0.5811 - val_loss: 0.9271 - val_acc: 0.9238 - val_mDice: 0.5157

Epoch 00007: val_mDice improved from 0.50800 to 0.51570, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 11s - loss: 0.4894 - acc: 0.9277 - mDice: 0.5961 - val_loss: 0.9483 - val_acc: 0.9183 - val_mDice: 0.4970

Epoch 00008: val_mDice did not improve from 0.51570
Epoch 9/300
 - 11s - loss: 0.4671 - acc: 0.9299 - mDice: 0.6102 - val_loss: 0.8886 - val_acc: 0.9320 - val_mDice: 0.5372

Epoch 00009: val_mDice improved from 0.51570 to 0.53724, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 11s - loss: 0.4530 - acc: 0.9315 - mDice: 0.6193 - val_loss: 0.8799 - val_acc: 0.9282 - val_mDice: 0.5302

Epoch 00010: val_mDice did not improve from 0.53724
Epoch 11/300
 - 11s - loss: 0.4401 - acc: 0.9329 - mDice: 0.6277 - val_loss: 0.8882 - val_acc: 0.9315 - val_mDice: 0.5315

Epoch 00011: val_mDice did not improve from 0.53724
Epoch 12/300
 - 11s - loss: 0.4302 - acc: 0.9339 - mDice: 0.6342 - val_loss: 0.8624 - val_acc: 0.9308 - val_mDice: 0.5263

Epoch 00012: val_mDice did not improve from 0.53724
Epoch 13/300
 - 11s - loss: 0.4212 - acc: 0.9347 - mDice: 0.6403 - val_loss: 0.8542 - val_acc: 0.9331 - val_mDice: 0.5453

Epoch 00013: val_mDice improved from 0.53724 to 0.54527, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 11s - loss: 0.4144 - acc: 0.9356 - mDice: 0.6448 - val_loss: 0.8850 - val_acc: 0.9337 - val_mDice: 0.5241

Epoch 00014: val_mDice did not improve from 0.54527
Epoch 15/300
 - 11s - loss: 0.4014 - acc: 0.9365 - mDice: 0.6535 - val_loss: 0.8505 - val_acc: 0.9346 - val_mDice: 0.5266

Epoch 00015: val_mDice did not improve from 0.54527
Epoch 16/300
 - 11s - loss: 0.3978 - acc: 0.9369 - mDice: 0.6560 - val_loss: 0.9541 - val_acc: 0.9193 - val_mDice: 0.5006

Epoch 00016: val_mDice did not improve from 0.54527
Epoch 17/300
 - 11s - loss: 0.3897 - acc: 0.9377 - mDice: 0.6617 - val_loss: 0.8265 - val_acc: 0.9396 - val_mDice: 0.5548

Epoch 00017: val_mDice improved from 0.54527 to 0.55475, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 11s - loss: 0.3849 - acc: 0.9383 - mDice: 0.6650 - val_loss: 0.8999 - val_acc: 0.9372 - val_mDice: 0.5310

Epoch 00018: val_mDice did not improve from 0.55475
Epoch 19/300
 - 12s - loss: 0.3791 - acc: 0.9385 - mDice: 0.6689 - val_loss: 0.8780 - val_acc: 0.9352 - val_mDice: 0.5256

Epoch 00019: val_mDice did not improve from 0.55475
Epoch 20/300
 - 11s - loss: 0.3740 - acc: 0.9392 - mDice: 0.6727 - val_loss: 0.8400 - val_acc: 0.9240 - val_mDice: 0.5222

Epoch 00020: val_mDice did not improve from 0.55475
Epoch 21/300
 - 11s - loss: 0.3696 - acc: 0.9396 - mDice: 0.6757 - val_loss: 0.8559 - val_acc: 0.9309 - val_mDice: 0.5326

Epoch 00021: val_mDice did not improve from 0.55475
Epoch 22/300
 - 11s - loss: 0.3661 - acc: 0.9398 - mDice: 0.6783 - val_loss: 0.7861 - val_acc: 0.9319 - val_mDice: 0.5477

Epoch 00022: val_mDice did not improve from 0.55475
Epoch 23/300
 - 12s - loss: 0.3614 - acc: 0.9403 - mDice: 0.6814 - val_loss: 0.8540 - val_acc: 0.9352 - val_mDice: 0.5408

Epoch 00023: val_mDice did not improve from 0.55475
Epoch 24/300
 - 11s - loss: 0.3574 - acc: 0.9406 - mDice: 0.6842 - val_loss: 0.8579 - val_acc: 0.9335 - val_mDice: 0.5318

Epoch 00024: val_mDice did not improve from 0.55475
Epoch 25/300
 - 11s - loss: 0.3547 - acc: 0.9407 - mDice: 0.6862 - val_loss: 0.7873 - val_acc: 0.9375 - val_mDice: 0.5620

Epoch 00025: val_mDice improved from 0.55475 to 0.56198, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 26/300
 - 11s - loss: 0.3515 - acc: 0.9413 - mDice: 0.6887 - val_loss: 0.8117 - val_acc: 0.9383 - val_mDice: 0.5540

Epoch 00026: val_mDice did not improve from 0.56198
Epoch 27/300
 - 11s - loss: 0.3483 - acc: 0.9414 - mDice: 0.6907 - val_loss: 0.8523 - val_acc: 0.9355 - val_mDice: 0.5392

Epoch 00027: val_mDice did not improve from 0.56198
Epoch 28/300
 - 11s - loss: 0.3478 - acc: 0.9415 - mDice: 0.6914 - val_loss: 0.7652 - val_acc: 0.9371 - val_mDice: 0.5627

Epoch 00028: val_mDice improved from 0.56198 to 0.56275, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 29/300
 - 12s - loss: 0.3413 - acc: 0.9421 - mDice: 0.6959 - val_loss: 0.7916 - val_acc: 0.9396 - val_mDice: 0.5632

Epoch 00029: val_mDice improved from 0.56275 to 0.56317, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 30/300
 - 11s - loss: 0.3397 - acc: 0.9423 - mDice: 0.6970 - val_loss: 0.8254 - val_acc: 0.9383 - val_mDice: 0.5443

Epoch 00030: val_mDice did not improve from 0.56317
Epoch 31/300
 - 11s - loss: 0.3369 - acc: 0.9424 - mDice: 0.6991 - val_loss: 0.7750 - val_acc: 0.9341 - val_mDice: 0.5433

Epoch 00031: val_mDice did not improve from 0.56317
Epoch 32/300
 - 11s - loss: 0.3333 - acc: 0.9428 - mDice: 0.7018 - val_loss: 0.8228 - val_acc: 0.9332 - val_mDice: 0.5363

Epoch 00032: val_mDice did not improve from 0.56317
Epoch 33/300
 - 11s - loss: 0.3316 - acc: 0.9428 - mDice: 0.7030 - val_loss: 0.8173 - val_acc: 0.9358 - val_mDice: 0.5490

Epoch 00033: val_mDice did not improve from 0.56317
Epoch 34/300
 - 11s - loss: 0.3306 - acc: 0.9430 - mDice: 0.7038 - val_loss: 0.8510 - val_acc: 0.9331 - val_mDice: 0.5255

Epoch 00034: val_mDice did not improve from 0.56317
Epoch 35/300
 - 12s - loss: 0.3248 - acc: 0.9434 - mDice: 0.7079 - val_loss: 0.8187 - val_acc: 0.9295 - val_mDice: 0.5201

Epoch 00035: val_mDice did not improve from 0.56317
Epoch 36/300
 - 11s - loss: 0.3274 - acc: 0.9433 - mDice: 0.7062 - val_loss: 0.7850 - val_acc: 0.9316 - val_mDice: 0.5393

Epoch 00036: val_mDice did not improve from 0.56317
Epoch 37/300
 - 11s - loss: 0.3236 - acc: 0.9437 - mDice: 0.7089 - val_loss: 0.7505 - val_acc: 0.9292 - val_mDice: 0.5414

Epoch 00037: val_mDice did not improve from 0.56317
Epoch 38/300
 - 12s - loss: 0.3232 - acc: 0.9438 - mDice: 0.7091 - val_loss: 0.7479 - val_acc: 0.9362 - val_mDice: 0.5486

Epoch 00038: val_mDice did not improve from 0.56317
Epoch 39/300
 - 11s - loss: 0.3198 - acc: 0.9440 - mDice: 0.7117 - val_loss: 0.7544 - val_acc: 0.9344 - val_mDice: 0.5456

Epoch 00039: val_mDice did not improve from 0.56317
Epoch 40/300
 - 12s - loss: 0.3204 - acc: 0.9440 - mDice: 0.7112 - val_loss: 0.7527 - val_acc: 0.9353 - val_mDice: 0.5461

Epoch 00040: val_mDice did not improve from 0.56317
Epoch 41/300
 - 12s - loss: 0.3182 - acc: 0.9442 - mDice: 0.7129 - val_loss: 0.8216 - val_acc: 0.9422 - val_mDice: 0.5478

Epoch 00041: val_mDice did not improve from 0.56317
Epoch 42/300
 - 12s - loss: 0.3142 - acc: 0.9445 - mDice: 0.7159 - val_loss: 0.8230 - val_acc: 0.9363 - val_mDice: 0.5424

Epoch 00042: val_mDice did not improve from 0.56317
Epoch 43/300
 - 12s - loss: 0.3123 - acc: 0.9447 - mDice: 0.7173 - val_loss: 0.6906 - val_acc: 0.9418 - val_mDice: 0.5710

Epoch 00043: val_mDice improved from 0.56317 to 0.57096, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 44/300
 - 12s - loss: 0.3114 - acc: 0.9448 - mDice: 0.7180 - val_loss: 0.7593 - val_acc: 0.9412 - val_mDice: 0.5386

Epoch 00044: val_mDice did not improve from 0.57096
Epoch 45/300
 - 12s - loss: 0.3095 - acc: 0.9448 - mDice: 0.7193 - val_loss: 0.6946 - val_acc: 0.9419 - val_mDice: 0.5621

Epoch 00045: val_mDice did not improve from 0.57096
Epoch 46/300
 - 11s - loss: 0.3086 - acc: 0.9450 - mDice: 0.7200 - val_loss: 0.8129 - val_acc: 0.9348 - val_mDice: 0.5499

Epoch 00046: val_mDice did not improve from 0.57096
Epoch 47/300
 - 12s - loss: 0.3090 - acc: 0.9450 - mDice: 0.7197 - val_loss: 0.7464 - val_acc: 0.9418 - val_mDice: 0.5736

Epoch 00047: val_mDice improved from 0.57096 to 0.57356, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 48/300
 - 11s - loss: 0.3063 - acc: 0.9452 - mDice: 0.7218 - val_loss: 0.7230 - val_acc: 0.9403 - val_mDice: 0.5593

Epoch 00048: val_mDice did not improve from 0.57356
Epoch 49/300
 - 12s - loss: 0.3049 - acc: 0.9453 - mDice: 0.7229 - val_loss: 0.7091 - val_acc: 0.9416 - val_mDice: 0.5689

Epoch 00049: val_mDice did not improve from 0.57356
Epoch 50/300
 - 11s - loss: 0.3060 - acc: 0.9452 - mDice: 0.7221 - val_loss: 0.8009 - val_acc: 0.9352 - val_mDice: 0.5253

Epoch 00050: val_mDice did not improve from 0.57356
Epoch 51/300
 - 11s - loss: 0.3035 - acc: 0.9454 - mDice: 0.7239 - val_loss: 0.7614 - val_acc: 0.9359 - val_mDice: 0.5334

Epoch 00051: val_mDice did not improve from 0.57356
Epoch 52/300
 - 12s - loss: 0.3020 - acc: 0.9456 - mDice: 0.7251 - val_loss: 0.7987 - val_acc: 0.9402 - val_mDice: 0.5501

Epoch 00052: val_mDice did not improve from 0.57356
Epoch 53/300
 - 11s - loss: 0.3000 - acc: 0.9457 - mDice: 0.7266 - val_loss: 0.8395 - val_acc: 0.9353 - val_mDice: 0.5311

Epoch 00053: val_mDice did not improve from 0.57356
Epoch 54/300
 - 12s - loss: 0.2992 - acc: 0.9458 - mDice: 0.7272 - val_loss: 0.7161 - val_acc: 0.9416 - val_mDice: 0.5656

Epoch 00054: val_mDice did not improve from 0.57356
Epoch 55/300
 - 11s - loss: 0.2996 - acc: 0.9457 - mDice: 0.7269 - val_loss: 0.7039 - val_acc: 0.9401 - val_mDice: 0.5692

Epoch 00055: val_mDice did not improve from 0.57356
Epoch 56/300
 - 12s - loss: 0.2957 - acc: 0.9462 - mDice: 0.7298 - val_loss: 0.7392 - val_acc: 0.9372 - val_mDice: 0.5526

Epoch 00056: val_mDice did not improve from 0.57356
Epoch 57/300
 - 12s - loss: 0.2953 - acc: 0.9461 - mDice: 0.7301 - val_loss: 0.7861 - val_acc: 0.9390 - val_mDice: 0.5394

Epoch 00057: val_mDice did not improve from 0.57356
Epoch 58/300
 - 11s - loss: 0.2950 - acc: 0.9462 - mDice: 0.7305 - val_loss: 0.7859 - val_acc: 0.9408 - val_mDice: 0.5558

Epoch 00058: val_mDice did not improve from 0.57356
Epoch 59/300
 - 12s - loss: 0.2928 - acc: 0.9463 - mDice: 0.7321 - val_loss: 0.7409 - val_acc: 0.9347 - val_mDice: 0.5607

Epoch 00059: val_mDice did not improve from 0.57356
Epoch 60/300
 - 11s - loss: 0.2927 - acc: 0.9464 - mDice: 0.7321 - val_loss: 0.7754 - val_acc: 0.9319 - val_mDice: 0.5179

Epoch 00060: val_mDice did not improve from 0.57356
Epoch 61/300
 - 11s - loss: 0.2917 - acc: 0.9464 - mDice: 0.7328 - val_loss: 0.6573 - val_acc: 0.9383 - val_mDice: 0.5634

Epoch 00061: val_mDice did not improve from 0.57356
Epoch 62/300
 - 11s - loss: 0.2893 - acc: 0.9467 - mDice: 0.7347 - val_loss: 0.6801 - val_acc: 0.9423 - val_mDice: 0.5680

Epoch 00062: val_mDice did not improve from 0.57356
Epoch 63/300
 - 12s - loss: 0.2888 - acc: 0.9467 - mDice: 0.7352 - val_loss: 0.8545 - val_acc: 0.9341 - val_mDice: 0.5118

Epoch 00063: val_mDice did not improve from 0.57356
Epoch 64/300
 - 11s - loss: 0.2877 - acc: 0.9468 - mDice: 0.7359 - val_loss: 0.7503 - val_acc: 0.9398 - val_mDice: 0.5478

Epoch 00064: val_mDice did not improve from 0.57356
Epoch 65/300
 - 11s - loss: 0.2874 - acc: 0.9468 - mDice: 0.7361 - val_loss: 0.7500 - val_acc: 0.9346 - val_mDice: 0.5424

Epoch 00065: val_mDice did not improve from 0.57356
Epoch 66/300
 - 11s - loss: 0.2857 - acc: 0.9471 - mDice: 0.7374 - val_loss: 0.7446 - val_acc: 0.9380 - val_mDice: 0.5542

Epoch 00066: val_mDice did not improve from 0.57356
Epoch 67/300
 - 11s - loss: 0.2864 - acc: 0.9469 - mDice: 0.7369 - val_loss: 0.7437 - val_acc: 0.9384 - val_mDice: 0.5490

Epoch 00067: val_mDice did not improve from 0.57356
Epoch 68/300
 - 12s - loss: 0.2889 - acc: 0.9467 - mDice: 0.7349 - val_loss: 0.7159 - val_acc: 0.9413 - val_mDice: 0.5704

Epoch 00068: val_mDice did not improve from 0.57356
Epoch 69/300
 - 11s - loss: 0.2863 - acc: 0.9470 - mDice: 0.7371 - val_loss: 0.7985 - val_acc: 0.9315 - val_mDice: 0.5136

Epoch 00069: val_mDice did not improve from 0.57356
Epoch 70/300
 - 11s - loss: 0.2851 - acc: 0.9470 - mDice: 0.7380 - val_loss: 0.6772 - val_acc: 0.9427 - val_mDice: 0.5472

Epoch 00070: val_mDice did not improve from 0.57356
Epoch 71/300
 - 11s - loss: 0.2841 - acc: 0.9472 - mDice: 0.7387 - val_loss: 0.6839 - val_acc: 0.9357 - val_mDice: 0.5391

Epoch 00071: val_mDice did not improve from 0.57356
Epoch 72/300
 - 11s - loss: 0.2821 - acc: 0.9473 - mDice: 0.7403 - val_loss: 0.6504 - val_acc: 0.9408 - val_mDice: 0.5715

Epoch 00072: val_mDice did not improve from 0.57356
Epoch 73/300
 - 11s - loss: 0.2819 - acc: 0.9473 - mDice: 0.7404 - val_loss: 0.6483 - val_acc: 0.9420 - val_mDice: 0.5577

Epoch 00073: val_mDice did not improve from 0.57356
Epoch 74/300
 - 12s - loss: 0.2817 - acc: 0.9475 - mDice: 0.7406 - val_loss: 0.6460 - val_acc: 0.9384 - val_mDice: 0.5653

Epoch 00074: val_mDice did not improve from 0.57356
Epoch 75/300
 - 12s - loss: 0.2802 - acc: 0.9476 - mDice: 0.7418 - val_loss: 0.6470 - val_acc: 0.9432 - val_mDice: 0.5751

Epoch 00075: val_mDice improved from 0.57356 to 0.57506, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 76/300
 - 11s - loss: 0.2803 - acc: 0.9476 - mDice: 0.7417 - val_loss: 0.8356 - val_acc: 0.9352 - val_mDice: 0.4929

Epoch 00076: val_mDice did not improve from 0.57506
Epoch 77/300
 - 11s - loss: 0.2777 - acc: 0.9476 - mDice: 0.7437 - val_loss: 0.6679 - val_acc: 0.9376 - val_mDice: 0.5557

Epoch 00077: val_mDice did not improve from 0.57506
Epoch 78/300
 - 13s - loss: 0.2784 - acc: 0.9476 - mDice: 0.7431 - val_loss: 0.6229 - val_acc: 0.9394 - val_mDice: 0.5716

Epoch 00078: val_mDice did not improve from 0.57506
Epoch 79/300
 - 13s - loss: 0.2780 - acc: 0.9476 - mDice: 0.7435 - val_loss: 0.6027 - val_acc: 0.9352 - val_mDice: 0.5646

Epoch 00079: val_mDice did not improve from 0.57506
Epoch 80/300
 - 13s - loss: 0.2776 - acc: 0.9477 - mDice: 0.7438 - val_loss: 0.6687 - val_acc: 0.9384 - val_mDice: 0.5610

Epoch 00080: val_mDice did not improve from 0.57506
Epoch 81/300
 - 14s - loss: 0.2773 - acc: 0.9478 - mDice: 0.7441 - val_loss: 0.7086 - val_acc: 0.9374 - val_mDice: 0.5405

Epoch 00081: val_mDice did not improve from 0.57506
Epoch 82/300
 - 13s - loss: 0.2790 - acc: 0.9477 - mDice: 0.7429 - val_loss: 0.8584 - val_acc: 0.9280 - val_mDice: 0.4947

Epoch 00082: val_mDice did not improve from 0.57506
Epoch 83/300
 - 13s - loss: 0.2757 - acc: 0.9479 - mDice: 0.7453 - val_loss: 0.6893 - val_acc: 0.9396 - val_mDice: 0.5590

Epoch 00083: val_mDice did not improve from 0.57506
Epoch 84/300
 - 13s - loss: 0.2737 - acc: 0.9480 - mDice: 0.7469 - val_loss: 0.7516 - val_acc: 0.9348 - val_mDice: 0.5406

Epoch 00084: val_mDice did not improve from 0.57506
Epoch 85/300
 - 14s - loss: 0.2756 - acc: 0.9479 - mDice: 0.7453 - val_loss: 0.6266 - val_acc: 0.9400 - val_mDice: 0.5599

Epoch 00085: val_mDice did not improve from 0.57506
Epoch 86/300
 - 14s - loss: 0.2755 - acc: 0.9478 - mDice: 0.7454 - val_loss: 0.6150 - val_acc: 0.9416 - val_mDice: 0.5663

Epoch 00086: val_mDice did not improve from 0.57506
Epoch 87/300
 - 13s - loss: 0.2725 - acc: 0.9481 - mDice: 0.7478 - val_loss: 0.7475 - val_acc: 0.9394 - val_mDice: 0.5345

Epoch 00087: val_mDice did not improve from 0.57506
Epoch 88/300
 - 14s - loss: 0.2712 - acc: 0.9481 - mDice: 0.7487 - val_loss: 0.7205 - val_acc: 0.9391 - val_mDice: 0.5507

Epoch 00088: val_mDice did not improve from 0.57506
Epoch 89/300
 - 13s - loss: 0.2716 - acc: 0.9482 - mDice: 0.7485 - val_loss: 0.7150 - val_acc: 0.9348 - val_mDice: 0.5435

Epoch 00089: val_mDice did not improve from 0.57506
Epoch 90/300
 - 14s - loss: 0.2720 - acc: 0.9482 - mDice: 0.7482 - val_loss: 0.7783 - val_acc: 0.9334 - val_mDice: 0.5055

Epoch 00090: val_mDice did not improve from 0.57506
Epoch 91/300
 - 13s - loss: 0.2709 - acc: 0.9483 - mDice: 0.7491 - val_loss: 0.6813 - val_acc: 0.9358 - val_mDice: 0.5415

Epoch 00091: val_mDice did not improve from 0.57506
Epoch 92/300
 - 12s - loss: 0.2725 - acc: 0.9482 - mDice: 0.7479 - val_loss: 0.5942 - val_acc: 0.9422 - val_mDice: 0.5782

Epoch 00092: val_mDice improved from 0.57506 to 0.57824, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 93/300
 - 12s - loss: 0.2712 - acc: 0.9484 - mDice: 0.7487 - val_loss: 0.6886 - val_acc: 0.9381 - val_mDice: 0.5511

Epoch 00093: val_mDice did not improve from 0.57824
Epoch 94/300
 - 12s - loss: 0.2708 - acc: 0.9484 - mDice: 0.7491 - val_loss: 0.6851 - val_acc: 0.9354 - val_mDice: 0.5490

Epoch 00094: val_mDice did not improve from 0.57824
Epoch 95/300
 - 12s - loss: 0.2690 - acc: 0.9484 - mDice: 0.7505 - val_loss: 0.6080 - val_acc: 0.9387 - val_mDice: 0.5658

Epoch 00095: val_mDice did not improve from 0.57824
Epoch 96/300
 - 12s - loss: 0.2695 - acc: 0.9483 - mDice: 0.7501 - val_loss: 0.6685 - val_acc: 0.9368 - val_mDice: 0.5462

Epoch 00096: val_mDice did not improve from 0.57824
Epoch 97/300
 - 12s - loss: 0.2689 - acc: 0.9484 - mDice: 0.7506 - val_loss: 0.6407 - val_acc: 0.9399 - val_mDice: 0.5509

Epoch 00097: val_mDice did not improve from 0.57824
Epoch 98/300
 - 12s - loss: 0.2701 - acc: 0.9483 - mDice: 0.7496 - val_loss: 0.6595 - val_acc: 0.9367 - val_mDice: 0.5543

Epoch 00098: val_mDice did not improve from 0.57824
Epoch 99/300
 - 12s - loss: 0.2668 - acc: 0.9486 - mDice: 0.7522 - val_loss: 0.6975 - val_acc: 0.9394 - val_mDice: 0.5404

Epoch 00099: val_mDice did not improve from 0.57824
Epoch 100/300
 - 12s - loss: 0.2681 - acc: 0.9485 - mDice: 0.7513 - val_loss: 0.6394 - val_acc: 0.9382 - val_mDice: 0.5580

Epoch 00100: val_mDice did not improve from 0.57824
Epoch 101/300
 - 12s - loss: 0.2668 - acc: 0.9486 - mDice: 0.7523 - val_loss: 0.6165 - val_acc: 0.9405 - val_mDice: 0.5582

Epoch 00101: val_mDice did not improve from 0.57824
Epoch 102/300
 - 11s - loss: 0.2667 - acc: 0.9487 - mDice: 0.7524 - val_loss: 0.7434 - val_acc: 0.9397 - val_mDice: 0.5588

Epoch 00102: val_mDice did not improve from 0.57824
Epoch 103/300
 - 11s - loss: 0.2669 - acc: 0.9487 - mDice: 0.7523 - val_loss: 0.7107 - val_acc: 0.9367 - val_mDice: 0.5540

Epoch 00103: val_mDice did not improve from 0.57824
Epoch 104/300
 - 11s - loss: 0.2674 - acc: 0.9486 - mDice: 0.7518 - val_loss: 0.7324 - val_acc: 0.9376 - val_mDice: 0.5338

Epoch 00104: val_mDice did not improve from 0.57824
Epoch 105/300
 - 12s - loss: 0.2652 - acc: 0.9487 - mDice: 0.7535 - val_loss: 0.6283 - val_acc: 0.9346 - val_mDice: 0.5508

Epoch 00105: val_mDice did not improve from 0.57824
Epoch 106/300
 - 11s - loss: 0.2677 - acc: 0.9485 - mDice: 0.7516 - val_loss: 0.6583 - val_acc: 0.9388 - val_mDice: 0.5661

Epoch 00106: val_mDice did not improve from 0.57824
Epoch 107/300
 - 11s - loss: 0.2645 - acc: 0.9488 - mDice: 0.7540 - val_loss: 0.6259 - val_acc: 0.9390 - val_mDice: 0.5597

Epoch 00107: val_mDice did not improve from 0.57824
Epoch 108/300
 - 11s - loss: 0.2634 - acc: 0.9489 - mDice: 0.7550 - val_loss: 0.7126 - val_acc: 0.9378 - val_mDice: 0.5401

Epoch 00108: val_mDice did not improve from 0.57824
Epoch 109/300
 - 11s - loss: 0.2625 - acc: 0.9489 - mDice: 0.7557 - val_loss: 0.6183 - val_acc: 0.9383 - val_mDice: 0.5615

Epoch 00109: val_mDice did not improve from 0.57824
Epoch 110/300
 - 12s - loss: 0.2645 - acc: 0.9488 - mDice: 0.7541 - val_loss: 0.7025 - val_acc: 0.9355 - val_mDice: 0.5467

Epoch 00110: val_mDice did not improve from 0.57824
Epoch 111/300
 - 11s - loss: 0.2642 - acc: 0.9489 - mDice: 0.7543 - val_loss: 0.6528 - val_acc: 0.9389 - val_mDice: 0.5447

Epoch 00111: val_mDice did not improve from 0.57824
Epoch 112/300
 - 11s - loss: 0.2615 - acc: 0.9490 - mDice: 0.7564 - val_loss: 0.7154 - val_acc: 0.9379 - val_mDice: 0.5426

Epoch 00112: val_mDice did not improve from 0.57824
Epoch 113/300
 - 11s - loss: 0.2620 - acc: 0.9490 - mDice: 0.7561 - val_loss: 0.6855 - val_acc: 0.9348 - val_mDice: 0.5469

Epoch 00113: val_mDice did not improve from 0.57824
Epoch 114/300
 - 11s - loss: 0.2636 - acc: 0.9489 - mDice: 0.7549 - val_loss: 0.6771 - val_acc: 0.9418 - val_mDice: 0.5590

Epoch 00114: val_mDice did not improve from 0.57824
Epoch 115/300
 - 11s - loss: 0.2609 - acc: 0.9491 - mDice: 0.7570 - val_loss: 0.7625 - val_acc: 0.9334 - val_mDice: 0.5261

Epoch 00115: val_mDice did not improve from 0.57824
Epoch 116/300
 - 12s - loss: 0.2629 - acc: 0.9490 - mDice: 0.7555 - val_loss: 0.6860 - val_acc: 0.9381 - val_mDice: 0.5503

Epoch 00116: val_mDice did not improve from 0.57824
Epoch 117/300
 - 11s - loss: 0.2611 - acc: 0.9491 - mDice: 0.7569 - val_loss: 0.6676 - val_acc: 0.9350 - val_mDice: 0.5328

Epoch 00117: val_mDice did not improve from 0.57824
Epoch 118/300
 - 11s - loss: 0.2615 - acc: 0.9490 - mDice: 0.7565 - val_loss: 0.6219 - val_acc: 0.9383 - val_mDice: 0.5628

Epoch 00118: val_mDice did not improve from 0.57824
Epoch 119/300
 - 11s - loss: 0.2599 - acc: 0.9492 - mDice: 0.7577 - val_loss: 0.6512 - val_acc: 0.9396 - val_mDice: 0.5542

Epoch 00119: val_mDice did not improve from 0.57824
Epoch 120/300
 - 11s - loss: 0.2592 - acc: 0.9492 - mDice: 0.7583 - val_loss: 0.7127 - val_acc: 0.9319 - val_mDice: 0.5311

Epoch 00120: val_mDice did not improve from 0.57824
Epoch 121/300
 - 11s - loss: 0.2589 - acc: 0.9493 - mDice: 0.7585 - val_loss: 0.6886 - val_acc: 0.9400 - val_mDice: 0.5684

Epoch 00121: val_mDice did not improve from 0.57824
Epoch 122/300
 - 11s - loss: 0.2580 - acc: 0.9492 - mDice: 0.7592 - val_loss: 0.6371 - val_acc: 0.9392 - val_mDice: 0.5624

Epoch 00122: val_mDice did not improve from 0.57824
Epoch 123/300
 - 12s - loss: 0.2595 - acc: 0.9491 - mDice: 0.7580 - val_loss: 0.6283 - val_acc: 0.9369 - val_mDice: 0.5532

Epoch 00123: val_mDice did not improve from 0.57824
Epoch 124/300
 - 11s - loss: 0.2587 - acc: 0.9493 - mDice: 0.7587 - val_loss: 0.7410 - val_acc: 0.9391 - val_mDice: 0.5353

Epoch 00124: val_mDice did not improve from 0.57824
Epoch 125/300
 - 11s - loss: 0.2587 - acc: 0.9493 - mDice: 0.7586 - val_loss: 0.6316 - val_acc: 0.9406 - val_mDice: 0.5671

Epoch 00125: val_mDice did not improve from 0.57824
Epoch 126/300
 - 11s - loss: 0.2583 - acc: 0.9494 - mDice: 0.7590 - val_loss: 0.6493 - val_acc: 0.9407 - val_mDice: 0.5636

Epoch 00126: val_mDice did not improve from 0.57824
Epoch 127/300
 - 11s - loss: 0.2582 - acc: 0.9493 - mDice: 0.7590 - val_loss: 0.6626 - val_acc: 0.9386 - val_mDice: 0.5645

Epoch 00127: val_mDice did not improve from 0.57824
Epoch 128/300
 - 11s - loss: 0.2553 - acc: 0.9496 - mDice: 0.7614 - val_loss: 0.6625 - val_acc: 0.9385 - val_mDice: 0.5685

Epoch 00128: val_mDice did not improve from 0.57824
Epoch 129/300
 - 11s - loss: 0.2581 - acc: 0.9493 - mDice: 0.7592 - val_loss: 0.7327 - val_acc: 0.9379 - val_mDice: 0.5426

Epoch 00129: val_mDice did not improve from 0.57824
Epoch 130/300
 - 12s - loss: 0.2571 - acc: 0.9494 - mDice: 0.7600 - val_loss: 0.6370 - val_acc: 0.9368 - val_mDice: 0.5654

Epoch 00130: val_mDice did not improve from 0.57824
Epoch 131/300
 - 11s - loss: 0.2566 - acc: 0.9495 - mDice: 0.7604 - val_loss: 0.6964 - val_acc: 0.9391 - val_mDice: 0.5525

Epoch 00131: val_mDice did not improve from 0.57824
Epoch 132/300
 - 11s - loss: 0.2582 - acc: 0.9494 - mDice: 0.7592 - val_loss: 0.6713 - val_acc: 0.9412 - val_mDice: 0.5611

Epoch 00132: val_mDice did not improve from 0.57824
Restoring model weights from the end of the best epoch
Epoch 00132: early stopping
{'val_loss': [2.617865956746615, 1.5523467935048616, 1.0870450047346263, 0.9790395360726577, 0.9575290427758143, 0.9294471809497247, 0.927117611353214, 0.9482584733229417, 0.8885522553553948, 0.8799263743253855, 0.8881665674539713, 0.8624013616488531, 0.8542478336737707, 0.8849906141941364, 0.8504675282881811, 0.9541266468855051, 0.8264515720880948, 0.8998940105621631, 0.8780396236823156, 0.8399830277149494, 0.8559350302586188, 0.786121687063804, 0.8539629509815803, 0.8579291838866013, 0.7872697642216315, 0.8117423286804786, 0.8523300381807181, 0.7651608402912433, 0.791617017525893, 0.8253833536918347, 0.7749803478901203, 0.822806349167457, 0.8173476411746099, 0.8510237886355474, 0.8187428483596215, 0.7849625257345346, 0.7505213113931509, 0.7478644893719599, 0.7543621544654553, 0.7527379256028396, 0.8216166817224942, 0.8230445201580341, 0.690587057517125, 0.7593294244546157, 0.6946370601654053, 0.8129133375791403, 0.7464296726080087, 0.7230209478965173, 0.7090833370502179, 0.8009038040271172, 0.7613859864381644, 0.7987100229813502, 0.839468790934636, 0.7160929418527163, 0.7039081912774307, 0.7392330307226914, 0.7861402470331925, 0.7858659602128543, 0.7408659504010127, 0.7754429899729215, 0.6572976616712717, 0.6801299498631403, 0.8545112197215741, 0.7502899078222421, 0.749979521219547, 0.7446209100576547, 0.7436871620324942, 0.715866336455712, 0.7985270940340482, 0.6772416807138003, 0.6838893294334412, 0.6504163833764883, 0.6483214589265677, 0.6459967173062838, 0.6469655495423537, 0.8356055594407595, 0.6679074466228485, 0.6228640217047471, 0.602674289391591, 0.6686699665509738, 0.7086466757150797, 0.8583947145021878, 0.6893240396793072, 0.7516020032075735, 0.626551451591345, 0.6149817613454965, 0.7474639003093426, 0.7205045727583078, 0.7150367590097281, 0.7783429874823644, 0.6812807527872232, 0.5941943182395055, 0.6885581727211292, 0.6851451167693505, 0.6079563727745643, 0.6684941328488864, 0.6406632386721097, 0.65952101120582, 0.6974713848187373, 0.6393864040191357, 0.6164881885051727, 0.7434253188279959, 0.7107423062507923, 0.7323879462022048, 0.6282871273847727, 0.6583118690894201, 0.625864354463724, 0.7126293778419495, 0.618295472401839, 0.7025393431003277, 0.6527641690694369, 0.7154207229614258, 0.6855333470381223, 0.6771243237532102, 0.7624902060398688, 0.6859571842046884, 0.667621387885167, 0.6218833717016073, 0.6511831146020156, 0.7126523760648874, 0.6886088160368112, 0.6371409663787255, 0.6282705320761754, 0.7409662420933063, 0.6315746926344358, 0.6493376103731302, 0.662621273444249, 0.6624667163078601, 0.7327031974609082, 0.6369816637956179, 0.696375296666072, 0.6712847925149478], 'val_acc': [0.8543824049142691, 0.8860900493768545, 0.9160109964700845, 0.924177172092291, 0.9232456523638505, 0.9271565217238206, 0.9238142462877127, 0.9183224004048568, 0.9320312394545629, 0.9282405582758096, 0.9314603392894452, 0.930778450690783, 0.9331106520616091, 0.9337232067034795, 0.9346061394764826, 0.9192700638220861, 0.9395709794301254, 0.9372342045490558, 0.9352255715773656, 0.924045395392638, 0.9309217952764951, 0.9318833236510937, 0.935179339005397, 0.9334527712601882, 0.9374699455041152, 0.938267354781811, 0.9355029624242049, 0.9370955274655268, 0.9395871712611272, 0.9383436349722055, 0.934086066025954, 0.9332077411504892, 0.9357733772351191, 0.9331175891252664, 0.9295395956589625, 0.9315504729747772, 0.9292483352697812, 0.9362079134354224, 0.9343518683543572, 0.9353134494561416, 0.9421620689905607, 0.9363489013451797, 0.9418453986828144, 0.941193585212414, 0.9418662098737863, 0.934791060594412, 0.9417529725111448, 0.9402575057286483, 0.9415587920408982, 0.9352186299287356, 0.9358774171425746, 0.9402135793979352, 0.9352995386490455, 0.941642029927327, 0.9401303850687467, 0.9371694578574254, 0.9390209225507883, 0.9407868064366854, 0.9347425080262698, 0.9319018331857828, 0.9383205358798687, 0.9423446930371798, 0.9341091697032635, 0.9397721084264609, 0.9345876207718482, 0.9379784579460437, 0.9383875590104324, 0.9412513627455785, 0.9315065649839548, 0.9427237533606015, 0.9356832595971915, 0.94075673360091, 0.9420303496030661, 0.9383552120282099, 0.9431629341382247, 0.9352417932106898, 0.9376386954234197, 0.9393699444257296, 0.9352209888971769, 0.9384453617609464, 0.9373798026488378, 0.9280001842058622, 0.9395872125258813, 0.9348210967504061, 0.9400333028573257, 0.9416304437013773, 0.939367590042261, 0.9390948483577142, 0.934837302336326, 0.9334018895259271, 0.9357988054935749, 0.9421852093476516, 0.9381194252234238, 0.9354382478273832, 0.9386649406873263, 0.9367788204779992, 0.9398576158743638, 0.9367256760597229, 0.9393722346195807, 0.9382188457709092, 0.9404562940964332, 0.939748974946829, 0.9367140990037185, 0.9376271298298469, 0.9345992069977981, 0.9387597189499781, 0.9389862211850973, 0.9378097149041983, 0.9382928311824799, 0.9354682633510003, 0.9389030383183405, 0.9378744661808014, 0.9348234167465796, 0.9418223110529093, 0.9334065157633561, 0.9381425472406241, 0.9349736456687634, 0.9383275027458484, 0.9396288119829618, 0.9319064250359168, 0.9400078539664929, 0.9392335346111884, 0.9368666937718024, 0.9391179772523733, 0.9405671954154968, 0.9406966727513534, 0.9385655636970813, 0.9384684631457696, 0.9378559566461123, 0.9367881165100977, 0.9391457300919753, 0.9411912996035355], 'val_mDice': [0.18057344366724676, 0.2822380352478761, 0.42747917198217833, 0.4783040313766553, 0.4898031594661566, 0.5079952466946381, 0.5157016401107495, 0.497005432844162, 0.5372414170549467, 0.5301633970095561, 0.5315023210759346, 0.526308193229712, 0.5452717359249408, 0.5240680300272428, 0.5266292484907004, 0.5005993252763381, 0.5547521876601073, 0.5310284426579108, 0.5255672530486033, 0.5222148299217224, 0.5326469511939929, 0.5476794563806974, 0.5407982726509755, 0.5318436654141316, 0.5619830397459177, 0.5540472836448596, 0.5391872614048995, 0.5627468537825805, 0.5631696914251034, 0.5442549397165959, 0.5433473260356829, 0.5362759799911425, 0.548974446952343, 0.5255322410510137, 0.5201474605844572, 0.5393021003558085, 0.5414436866457646, 0.5486383231786581, 0.5455938715201157, 0.5461202665017202, 0.5478430292927302, 0.5424240606908615, 0.5709591421943444, 0.5386031292952024, 0.5621370409543698, 0.5499475139837998, 0.5735577376416097, 0.559311561859571, 0.5688566009585674, 0.5253488140610548, 0.5333597499590653, 0.5501428573177412, 0.5310900056591401, 0.5656413974670264, 0.569232625170396, 0.5526018326099102, 0.5393688529729843, 0.5557592749022521, 0.5606894206542236, 0.5178882112869849, 0.5634426216666515, 0.5679777333369622, 0.5117988999073322, 0.5478341791492242, 0.5423560300125525, 0.5541818265158397, 0.5489854256694133, 0.5704037008377222, 0.5136170914539924, 0.5472416637035517, 0.5390650182962418, 0.5715346078460033, 0.5576578057729281, 0.5653218833299783, 0.5750636865313237, 0.4929283522069454, 0.5557493309562023, 0.5716165269796665, 0.5646479020898159, 0.5610377054948074, 0.5405023840184395, 0.4946789638354228, 0.5589780108286784, 0.540624795624843, 0.5599022817153197, 0.5662604604776089, 0.5344501630618022, 0.5507355246406335, 0.5434995706264789, 0.5054745430556628, 0.5414697636778538, 0.5782369375228882, 0.5511207557641543, 0.5489753172374688, 0.565782521206599, 0.5461769837599534, 0.5509443781696833, 0.5542585333952537, 0.5403563655339755, 0.5580462698753064, 0.5581761707480137, 0.5588015971275476, 0.5540257256764632, 0.5337862143149743, 0.5507711997398963, 0.5661134923306795, 0.5597316356232533, 0.5401393794096433, 0.5615183344254127, 0.5467217644819846, 0.5446524834976747, 0.5425940110133245, 0.5469280527188227, 0.5590157801142106, 0.5260683951469568, 0.5503294473657241, 0.532814409583807, 0.562829301907466, 0.5541723238734099, 0.531082370533393, 0.5683903854626876, 0.5624228555422562, 0.553195999791989, 0.5352923408723794, 0.5671282811806753, 0.5635527613071295, 0.5644523292206801, 0.5684666192302337, 0.5425791625793164, 0.5653627554957683, 0.552454358110061, 0.561097879249316], 'loss': [2.8201917635716165, 1.1161137310647002, 0.7926793959564491, 0.6713231932102155, 0.5967679132474565, 0.5483733181978496, 0.5142655963773691, 0.4894023014645311, 0.46710995100778724, 0.4529708043094008, 0.4400809068917503, 0.43020134697560286, 0.42120839901805135, 0.41442062985761835, 0.40142073359896663, 0.3978378766743798, 0.38967539603272827, 0.384907796603776, 0.37910862889147373, 0.3739540656532274, 0.36957571685264706, 0.3660725922252731, 0.3614269553059352, 0.3574413252329789, 0.3546777260646514, 0.35147308780787934, 0.3483131111085959, 0.34783746068640126, 0.3413259937739467, 0.33971095332236984, 0.33691469315320244, 0.3333201920987275, 0.3315792121202713, 0.3305548317431524, 0.3247820667638711, 0.32744287194212257, 0.32358123009840106, 0.32323480362900064, 0.3198064856645554, 0.3203989128988189, 0.31817413922177684, 0.3141835452412411, 0.31229803069462625, 0.3113761622615706, 0.30951310663296705, 0.30855855842110724, 0.3089884535518507, 0.30631869751831203, 0.30487530796353934, 0.3059724834443986, 0.3034554668994646, 0.3019600418493953, 0.3000265712020341, 0.29917040275414797, 0.2996194595083653, 0.2956809239183901, 0.29534447032356687, 0.29501404699216766, 0.2928164961630927, 0.2926948938099955, 0.2917069261401471, 0.28926758620007437, 0.28881271511527934, 0.2876730284396874, 0.28739472670681765, 0.2857409626764971, 0.28638896234501865, 0.2889359371969755, 0.2862782812526412, 0.2850876268173599, 0.2841302777423989, 0.28213122026139514, 0.2818624577261277, 0.2816699991243347, 0.28017716316579616, 0.28029994708766337, 0.27771170373157766, 0.2784041079094651, 0.27797270602299523, 0.2775888700255672, 0.277288688306031, 0.27903144208474384, 0.2757383714651892, 0.2736660162538199, 0.2756058342543891, 0.27554742346431765, 0.2724542822096166, 0.2712040771711777, 0.271621513993914, 0.2719761346782319, 0.2708594331736496, 0.27253263774562847, 0.2712139355227108, 0.27084279373971165, 0.26901937176696844, 0.2694749974884539, 0.26885147533886855, 0.2701376936900311, 0.2668218942054862, 0.2681076541703796, 0.26681065657509767, 0.2666546362996332, 0.2668846339237467, 0.2673924378717472, 0.26518107498691473, 0.2676554944675083, 0.2645392759110362, 0.2634203196215056, 0.2624558457878148, 0.2644608153206698, 0.2642341877612023, 0.26152249968965524, 0.26203395772725685, 0.263557049818148, 0.2609293745621251, 0.26287864598688754, 0.2611006572657072, 0.2614934618134654, 0.2599062884930237, 0.25923822190085866, 0.2589439891816769, 0.25803092956531976, 0.25949966181614165, 0.2586778970834658, 0.2587453051652568, 0.2583355596380943, 0.258187898466049, 0.25527575445094913, 0.258114401654081, 0.25705560445400727, 0.2565865107818601, 0.2581644217559885], 'acc': [0.3294537570916737, 0.8705841758303302, 0.8899116727585262, 0.9004044619134726, 0.9129345903677616, 0.9212920522377587, 0.925187399562606, 0.9276599003348878, 0.9299217768451181, 0.9315284950084751, 0.9329177924905724, 0.9338823932514281, 0.9346899660071423, 0.9355866562602244, 0.9365349341052315, 0.9369052555369108, 0.9377369262036896, 0.938289592673525, 0.9385432776606172, 0.9391614088523567, 0.9396342620917333, 0.9398086951588789, 0.9402943419033691, 0.9405660062085589, 0.9407288423765743, 0.9412808419208426, 0.9413523168446426, 0.941528697520904, 0.9420777473911021, 0.9422537339609904, 0.9423826465546882, 0.9428011865388486, 0.9428341523105562, 0.943025587235695, 0.9433598372094758, 0.9433408157088644, 0.9436859977615832, 0.9437959129318017, 0.9440288049625227, 0.9440064809699016, 0.9441737274033859, 0.9444599588133032, 0.9446696788800947, 0.9448374612166699, 0.9448192189136225, 0.9449645151107346, 0.94499078814882, 0.9451634015839533, 0.9453287628769358, 0.945237820822188, 0.9453904367203445, 0.9455524311067433, 0.945700523153636, 0.9457968492619195, 0.9457299215079211, 0.9461507632879053, 0.9460964725266674, 0.9462280027663852, 0.9463447750433778, 0.9464217225673904, 0.9464377499446871, 0.946654834128785, 0.9466876889807727, 0.9468055218609345, 0.9467924372753863, 0.9470733069663315, 0.9468803425056407, 0.9466579604784325, 0.9470274604786193, 0.9470218526891575, 0.9471852626185306, 0.947310987487882, 0.9472966207675605, 0.9474613389207639, 0.9475693299928011, 0.9475785706861866, 0.9476475660446703, 0.9475992139190762, 0.9475800817900892, 0.9477091090854854, 0.9477757950567027, 0.9477135416415414, 0.9478953798725565, 0.9479967616948543, 0.94787424647763, 0.9477735315918934, 0.9481445589452985, 0.9481438066448594, 0.948155228330631, 0.9482003410100212, 0.9482757820421662, 0.9482431942759366, 0.9483573921962736, 0.9484222619546512, 0.9483843247828685, 0.9483267746430795, 0.9483564390771604, 0.9483123860279594, 0.9485574505331991, 0.9484706973662337, 0.9485722823984276, 0.948691174787843, 0.9486634836891288, 0.9486057315982709, 0.9486652586135347, 0.9485265433947714, 0.94884587420448, 0.9489217387687717, 0.94891276185741, 0.9488210666116991, 0.948860551305421, 0.9489647902862333, 0.9490312799353733, 0.9489310276494038, 0.949091953874173, 0.9490239432044303, 0.949129312166833, 0.9490202834748435, 0.9491846920499983, 0.9492269705705819, 0.9493307671643244, 0.9492303389668696, 0.9491235925891155, 0.9493088192202273, 0.949326975312849, 0.9493542913250254, 0.9492647663579263, 0.9496391903625185, 0.9493281302840839, 0.949414544875998, 0.9494561584334658, 0.9493602075436497], 'mDice': [0.10819048740544861, 0.3346775339272677, 0.43811641346976227, 0.49480051784006135, 0.5334491099773007, 0.5608076155213185, 0.5810619673253556, 0.5960788387747847, 0.6101736061183617, 0.6192665375060704, 0.6277368080019017, 0.6342397252429096, 0.6403371202520237, 0.6448495592191894, 0.6535115126236266, 0.6560025299253976, 0.661714187519781, 0.6650258188019882, 0.6689324646894094, 0.6727368411878857, 0.6756504468402003, 0.6783046007024442, 0.6814127003235163, 0.684179953188405, 0.6862228479506751, 0.6886680586459198, 0.6907190727393785, 0.6914057087647588, 0.6958841075374336, 0.6970061985733742, 0.6990835725585001, 0.7017817301448065, 0.7029688829570022, 0.7037940330306597, 0.7078635988778144, 0.7061812141983204, 0.7088854157989517, 0.7091445823244796, 0.711678530626122, 0.7112154451384488, 0.7128828979171775, 0.7158644295020219, 0.7172798255784347, 0.7180167358266596, 0.7193476126047339, 0.7200485531401835, 0.719744112277662, 0.7217819776458515, 0.7229013877975691, 0.7221121611514237, 0.7239350164924987, 0.7250684727758738, 0.7265803493565545, 0.7271718763671853, 0.7269122287222878, 0.729806582349193, 0.7300780580611749, 0.7304578106594428, 0.7320547038906562, 0.7320972244798681, 0.7328169139496, 0.7347335711425271, 0.735151379121402, 0.7358699289621995, 0.7360807233473301, 0.7373829719315131, 0.7369238477037763, 0.7349300837314493, 0.7371309056698061, 0.7379645705442966, 0.7387099439869351, 0.7402631956900132, 0.7404096901257364, 0.7405605707333052, 0.741794223776825, 0.741742212889127, 0.7436712663749547, 0.7431264270454669, 0.7435241649481332, 0.7437663844488627, 0.7440907034301828, 0.7428578988966836, 0.7452770477014967, 0.7468823920995517, 0.7453448610431999, 0.7453732346131728, 0.747782552092759, 0.7487464565297592, 0.7484855805773208, 0.7482265088156471, 0.749065217030265, 0.747863534300967, 0.7487384043067054, 0.749063383177353, 0.7505394529891742, 0.7501198318483292, 0.7506235457869525, 0.7495987122650133, 0.7522230660971445, 0.7512574689552967, 0.7523349704617538, 0.7524082162916073, 0.752264380180164, 0.751794054314053, 0.753519673755575, 0.7516011246332743, 0.754039314403796, 0.7549746006515582, 0.7556639374715205, 0.7541393744465082, 0.7543032415500484, 0.756391810500115, 0.7560850923091934, 0.7549110679545988, 0.7569763709134879, 0.7554769257464379, 0.7568697883701738, 0.7565259658893426, 0.7577147196329334, 0.7582693354434592, 0.7584647045060299, 0.7591574810906375, 0.758018578680901, 0.7587060761728773, 0.7586224118161221, 0.7589532966863556, 0.7590464151874191, 0.7614433491217918, 0.7592066804234484, 0.7600257685183819, 0.7603803007494729, 0.7591648476541367]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.19s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.95s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.75s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:08,  1.72s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:35,  1.61s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:34,  1.61s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:08,  1.53s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:26,  1.59s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:07,  1.53s/it]predicting train subjects:   2%|▏         | 7/285 [00:10<07:24,  1.60s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:19,  1.59s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:38,  1.66s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<07:52,  1.72s/it]predicting train subjects:   4%|▍         | 11/285 [00:17<07:27,  1.63s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<07:37,  1.68s/it]predicting train subjects:   5%|▍         | 13/285 [00:20<07:25,  1.64s/it]predicting train subjects:   5%|▍         | 14/285 [00:22<07:36,  1.69s/it]predicting train subjects:   5%|▌         | 15/285 [00:24<07:50,  1.74s/it]predicting train subjects:   6%|▌         | 16/285 [00:26<08:01,  1.79s/it]predicting train subjects:   6%|▌         | 17/285 [00:27<07:34,  1.70s/it]predicting train subjects:   6%|▋         | 18/285 [00:29<07:32,  1.70s/it]predicting train subjects:   7%|▋         | 19/285 [00:31<07:13,  1.63s/it]predicting train subjects:   7%|▋         | 20/285 [00:32<07:23,  1.67s/it]predicting train subjects:   7%|▋         | 21/285 [00:34<07:38,  1.74s/it]predicting train subjects:   8%|▊         | 22/285 [00:36<07:14,  1.65s/it]predicting train subjects:   8%|▊         | 23/285 [00:38<07:22,  1.69s/it]predicting train subjects:   8%|▊         | 24/285 [00:39<07:14,  1.66s/it]predicting train subjects:   9%|▉         | 25/285 [00:41<07:29,  1.73s/it]predicting train subjects:   9%|▉         | 26/285 [00:43<07:39,  1.77s/it]predicting train subjects:   9%|▉         | 27/285 [00:44<07:14,  1.68s/it]predicting train subjects:  10%|▉         | 28/285 [00:46<07:16,  1.70s/it]predicting train subjects:  10%|█         | 29/285 [00:48<07:23,  1.73s/it]predicting train subjects:  11%|█         | 30/285 [00:50<07:32,  1.78s/it]predicting train subjects:  11%|█         | 31/285 [00:52<07:39,  1.81s/it]predicting train subjects:  11%|█         | 32/285 [00:53<07:16,  1.72s/it]predicting train subjects:  12%|█▏        | 33/285 [00:55<07:20,  1.75s/it]predicting train subjects:  12%|█▏        | 34/285 [00:57<07:13,  1.73s/it]predicting train subjects:  12%|█▏        | 35/285 [00:59<07:23,  1.77s/it]predicting train subjects:  13%|█▎        | 36/285 [01:00<07:09,  1.73s/it]predicting train subjects:  13%|█▎        | 37/285 [01:02<07:03,  1.71s/it]predicting train subjects:  13%|█▎        | 38/285 [01:04<07:09,  1.74s/it]predicting train subjects:  14%|█▎        | 39/285 [01:05<06:49,  1.67s/it]predicting train subjects:  14%|█▍        | 40/285 [01:07<06:52,  1.68s/it]predicting train subjects:  14%|█▍        | 41/285 [01:08<06:36,  1.62s/it]predicting train subjects:  15%|█▍        | 42/285 [01:10<06:26,  1.59s/it]predicting train subjects:  15%|█▌        | 43/285 [01:12<06:35,  1.64s/it]predicting train subjects:  15%|█▌        | 44/285 [01:13<06:47,  1.69s/it]predicting train subjects:  16%|█▌        | 45/285 [01:15<06:27,  1.62s/it]predicting train subjects:  16%|█▌        | 46/285 [01:17<06:40,  1.68s/it]predicting train subjects:  16%|█▋        | 47/285 [01:18<06:26,  1.62s/it]predicting train subjects:  17%|█▋        | 48/285 [01:20<06:27,  1.64s/it]predicting train subjects:  17%|█▋        | 49/285 [01:22<06:44,  1.71s/it]predicting train subjects:  18%|█▊        | 50/285 [01:23<06:39,  1.70s/it]predicting train subjects:  18%|█▊        | 51/285 [01:25<06:51,  1.76s/it]predicting train subjects:  18%|█▊        | 52/285 [01:27<06:35,  1.70s/it]predicting train subjects:  19%|█▊        | 53/285 [01:29<06:34,  1.70s/it]predicting train subjects:  19%|█▉        | 54/285 [01:30<06:40,  1.74s/it]predicting train subjects:  19%|█▉        | 55/285 [01:32<06:23,  1.67s/it]predicting train subjects:  20%|█▉        | 56/285 [01:34<06:24,  1.68s/it]predicting train subjects:  20%|██        | 57/285 [01:35<06:08,  1.62s/it]predicting train subjects:  20%|██        | 58/285 [01:37<06:18,  1.67s/it]predicting train subjects:  21%|██        | 59/285 [01:39<06:26,  1.71s/it]predicting train subjects:  21%|██        | 60/285 [01:41<06:38,  1.77s/it]predicting train subjects:  21%|██▏       | 61/285 [01:42<06:21,  1.70s/it]predicting train subjects:  22%|██▏       | 62/285 [01:44<06:22,  1.71s/it]predicting train subjects:  22%|██▏       | 63/285 [01:46<06:21,  1.72s/it]predicting train subjects:  22%|██▏       | 64/285 [01:47<06:06,  1.66s/it]predicting train subjects:  23%|██▎       | 65/285 [01:49<06:14,  1.70s/it]predicting train subjects:  23%|██▎       | 66/285 [01:51<06:12,  1.70s/it]predicting train subjects:  24%|██▎       | 67/285 [01:52<06:10,  1.70s/it]predicting train subjects:  24%|██▍       | 68/285 [01:54<06:00,  1.66s/it]predicting train subjects:  24%|██▍       | 69/285 [01:56<06:04,  1.69s/it]predicting train subjects:  25%|██▍       | 70/285 [01:57<06:02,  1.69s/it]predicting train subjects:  25%|██▍       | 71/285 [01:59<06:00,  1.69s/it]predicting train subjects:  25%|██▌       | 72/285 [02:01<05:49,  1.64s/it]predicting train subjects:  26%|██▌       | 73/285 [02:02<05:50,  1.65s/it]predicting train subjects:  26%|██▌       | 74/285 [02:04<05:53,  1.67s/it]predicting train subjects:  26%|██▋       | 75/285 [02:06<05:57,  1.70s/it]predicting train subjects:  27%|██▋       | 76/285 [02:07<05:57,  1.71s/it]predicting train subjects:  27%|██▋       | 77/285 [02:09<05:43,  1.65s/it]predicting train subjects:  27%|██▋       | 78/285 [02:10<05:29,  1.59s/it]predicting train subjects:  28%|██▊       | 79/285 [02:12<05:35,  1.63s/it]predicting train subjects:  28%|██▊       | 80/285 [02:14<05:39,  1.65s/it]predicting train subjects:  28%|██▊       | 81/285 [02:15<05:31,  1.62s/it]predicting train subjects:  29%|██▉       | 82/285 [02:17<05:36,  1.66s/it]predicting train subjects:  29%|██▉       | 83/285 [02:19<05:27,  1.62s/it]predicting train subjects:  29%|██▉       | 84/285 [02:20<05:18,  1.59s/it]predicting train subjects:  30%|██▉       | 85/285 [02:22<05:33,  1.67s/it]predicting train subjects:  30%|███       | 86/285 [02:24<05:36,  1.69s/it]predicting train subjects:  31%|███       | 87/285 [02:26<05:38,  1.71s/it]predicting train subjects:  31%|███       | 88/285 [02:27<05:26,  1.66s/it]predicting train subjects:  31%|███       | 89/285 [02:29<05:28,  1.68s/it]predicting train subjects:  32%|███▏      | 90/285 [02:30<05:28,  1.69s/it]predicting train subjects:  32%|███▏      | 91/285 [02:32<05:18,  1.64s/it]predicting train subjects:  32%|███▏      | 92/285 [02:34<05:22,  1.67s/it]predicting train subjects:  33%|███▎      | 93/285 [02:35<05:11,  1.62s/it]predicting train subjects:  33%|███▎      | 94/285 [02:37<05:18,  1.67s/it]predicting train subjects:  33%|███▎      | 95/285 [02:39<05:16,  1.66s/it]predicting train subjects:  34%|███▎      | 96/285 [02:40<05:19,  1.69s/it]predicting train subjects:  34%|███▍      | 97/285 [02:42<05:20,  1.70s/it]predicting train subjects:  34%|███▍      | 98/285 [02:44<05:20,  1.72s/it]predicting train subjects:  35%|███▍      | 99/285 [02:46<05:18,  1.71s/it]predicting train subjects:  35%|███▌      | 100/285 [02:47<05:14,  1.70s/it]predicting train subjects:  35%|███▌      | 101/285 [02:49<05:03,  1.65s/it]predicting train subjects:  36%|███▌      | 102/285 [02:51<05:08,  1.69s/it]predicting train subjects:  36%|███▌      | 103/285 [02:52<05:03,  1.67s/it]predicting train subjects:  36%|███▋      | 104/285 [02:54<05:06,  1.69s/it]predicting train subjects:  37%|███▋      | 105/285 [02:56<05:04,  1.69s/it]predicting train subjects:  37%|███▋      | 106/285 [02:57<04:52,  1.63s/it]predicting train subjects:  38%|███▊      | 107/285 [02:59<04:52,  1.64s/it]predicting train subjects:  38%|███▊      | 108/285 [03:00<04:46,  1.62s/it]predicting train subjects:  38%|███▊      | 109/285 [03:02<04:46,  1.63s/it]predicting train subjects:  39%|███▊      | 110/285 [03:04<04:46,  1.63s/it]predicting train subjects:  39%|███▉      | 111/285 [03:05<04:35,  1.58s/it]predicting train subjects:  39%|███▉      | 112/285 [03:07<04:38,  1.61s/it]predicting train subjects:  40%|███▉      | 113/285 [03:09<04:44,  1.66s/it]predicting train subjects:  40%|████      | 114/285 [03:10<04:44,  1.66s/it]predicting train subjects:  40%|████      | 115/285 [03:12<04:44,  1.68s/it]predicting train subjects:  41%|████      | 116/285 [03:14<04:41,  1.67s/it]predicting train subjects:  41%|████      | 117/285 [03:15<04:29,  1.61s/it]predicting train subjects:  41%|████▏     | 118/285 [03:17<04:26,  1.60s/it]predicting train subjects:  42%|████▏     | 119/285 [03:18<04:30,  1.63s/it]predicting train subjects:  42%|████▏     | 120/285 [03:20<04:27,  1.62s/it]predicting train subjects:  42%|████▏     | 121/285 [03:22<04:22,  1.60s/it]predicting train subjects:  43%|████▎     | 122/285 [03:23<04:12,  1.55s/it]predicting train subjects:  43%|████▎     | 123/285 [03:24<04:01,  1.49s/it]predicting train subjects:  44%|████▎     | 124/285 [03:26<04:05,  1.52s/it]predicting train subjects:  44%|████▍     | 125/285 [03:27<03:59,  1.50s/it]predicting train subjects:  44%|████▍     | 126/285 [03:29<03:56,  1.49s/it]predicting train subjects:  45%|████▍     | 127/285 [03:30<03:51,  1.47s/it]predicting train subjects:  45%|████▍     | 128/285 [03:32<03:59,  1.52s/it]predicting train subjects:  45%|████▌     | 129/285 [03:33<03:53,  1.50s/it]predicting train subjects:  46%|████▌     | 130/285 [03:35<03:43,  1.44s/it]predicting train subjects:  46%|████▌     | 131/285 [03:36<03:36,  1.40s/it]predicting train subjects:  46%|████▋     | 132/285 [03:37<03:40,  1.44s/it]predicting train subjects:  47%|████▋     | 133/285 [03:39<03:38,  1.44s/it]predicting train subjects:  47%|████▋     | 134/285 [03:40<03:33,  1.41s/it]predicting train subjects:  47%|████▋     | 135/285 [03:42<03:32,  1.41s/it]predicting train subjects:  48%|████▊     | 136/285 [03:43<03:27,  1.39s/it]predicting train subjects:  48%|████▊     | 137/285 [03:45<03:31,  1.43s/it]predicting train subjects:  48%|████▊     | 138/285 [03:46<03:31,  1.44s/it]predicting train subjects:  49%|████▉     | 139/285 [03:48<03:34,  1.47s/it]predicting train subjects:  49%|████▉     | 140/285 [03:49<03:34,  1.48s/it]predicting train subjects:  49%|████▉     | 141/285 [03:50<03:27,  1.44s/it]predicting train subjects:  50%|████▉     | 142/285 [03:52<03:26,  1.45s/it]predicting train subjects:  50%|█████     | 143/285 [03:53<03:22,  1.42s/it]predicting train subjects:  51%|█████     | 144/285 [03:55<03:27,  1.47s/it]predicting train subjects:  51%|█████     | 145/285 [03:56<03:22,  1.45s/it]predicting train subjects:  51%|█████     | 146/285 [03:58<03:22,  1.45s/it]predicting train subjects:  52%|█████▏    | 147/285 [03:59<03:17,  1.43s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:01<03:17,  1.44s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:02<03:15,  1.44s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:03<03:12,  1.43s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:05<03:14,  1.45s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:06<03:07,  1.41s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:08<03:06,  1.41s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:09<03:18,  1.52s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:11<03:13,  1.49s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:12<03:14,  1.51s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:14<03:10,  1.49s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:15<03:05,  1.46s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:16<02:59,  1.43s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:18<02:55,  1.41s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:19<03:00,  1.45s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:21<02:57,  1.45s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:22<03:02,  1.49s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:24<02:58,  1.47s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:25<02:54,  1.45s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:27<02:54,  1.46s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:28<02:52,  1.46s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:29<02:43,  1.40s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:31<02:41,  1.39s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:32<02:37,  1.37s/it]predicting train subjects:  60%|██████    | 171/285 [04:34<02:37,  1.38s/it]predicting train subjects:  60%|██████    | 172/285 [04:35<02:36,  1.38s/it]predicting train subjects:  61%|██████    | 173/285 [04:36<02:35,  1.38s/it]predicting train subjects:  61%|██████    | 174/285 [04:38<02:34,  1.39s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:39<02:36,  1.42s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:41<02:36,  1.43s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:42<02:29,  1.39s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:43<02:26,  1.37s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:45<02:27,  1.39s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:46<02:36,  1.49s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:48<02:40,  1.54s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:50<02:42,  1.58s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:51<02:33,  1.50s/it]predicting train subjects:  65%|██████▍   | 184/285 [04:53<02:27,  1.46s/it]predicting train subjects:  65%|██████▍   | 185/285 [04:54<02:21,  1.41s/it]predicting train subjects:  65%|██████▌   | 186/285 [04:56<02:29,  1.51s/it]predicting train subjects:  66%|██████▌   | 187/285 [04:57<02:35,  1.59s/it]predicting train subjects:  66%|██████▌   | 188/285 [04:59<02:37,  1.62s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:00<02:25,  1.52s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:02<02:20,  1.47s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:03<02:22,  1.51s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:05<02:22,  1.54s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:06<02:12,  1.44s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:07<02:08,  1.41s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:09<02:04,  1.38s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:11<02:13,  1.50s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:12<02:16,  1.55s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:14<02:18,  1.59s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:15<02:08,  1.49s/it]predicting train subjects:  70%|███████   | 200/285 [05:16<02:02,  1.45s/it]predicting train subjects:  71%|███████   | 201/285 [05:18<02:07,  1.52s/it]predicting train subjects:  71%|███████   | 202/285 [05:20<02:08,  1.55s/it]predicting train subjects:  71%|███████   | 203/285 [05:21<02:09,  1.58s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:23<02:00,  1.49s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:24<01:57,  1.47s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:25<01:53,  1.43s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:27<02:01,  1.55s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:29<02:04,  1.61s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:31<02:05,  1.65s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:32<01:56,  1.55s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:34<01:52,  1.52s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:35<01:51,  1.53s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:37<01:51,  1.55s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:38<01:44,  1.47s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:40<01:48,  1.55s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:41<01:41,  1.47s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:43<01:45,  1.55s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:44<01:47,  1.60s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:46<01:49,  1.66s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:48<01:40,  1.55s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:49<01:35,  1.49s/it]predicting train subjects:  78%|███████▊  | 222/285 [05:51<01:36,  1.54s/it]predicting train subjects:  78%|███████▊  | 223/285 [05:52<01:31,  1.48s/it]predicting train subjects:  79%|███████▊  | 224/285 [05:53<01:28,  1.46s/it]predicting train subjects:  79%|███████▉  | 225/285 [05:55<01:24,  1.41s/it]predicting train subjects:  79%|███████▉  | 226/285 [05:56<01:28,  1.50s/it]predicting train subjects:  80%|███████▉  | 227/285 [05:58<01:30,  1.56s/it]predicting train subjects:  80%|████████  | 228/285 [06:00<01:32,  1.61s/it]predicting train subjects:  80%|████████  | 229/285 [06:01<01:30,  1.61s/it]predicting train subjects:  81%|████████  | 230/285 [06:03<01:23,  1.51s/it]predicting train subjects:  81%|████████  | 231/285 [06:04<01:20,  1.49s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:06<01:21,  1.54s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:07<01:16,  1.48s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:09<01:20,  1.57s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:10<01:15,  1.51s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:12<01:18,  1.59s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:14<01:19,  1.65s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:16<01:20,  1.70s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:17<01:19,  1.73s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:19<01:11,  1.60s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:20<01:07,  1.53s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:21<01:03,  1.48s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:23<00:59,  1.42s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:24<01:01,  1.49s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:26<00:58,  1.46s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:28<01:00,  1.56s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:29<01:00,  1.60s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:31<00:59,  1.60s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:32<00:54,  1.52s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:34<00:52,  1.50s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:35<00:48,  1.44s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:36<00:45,  1.38s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:38<00:48,  1.52s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:40<00:48,  1.57s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:41<00:47,  1.57s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:43<00:43,  1.50s/it]predicting train subjects:  90%|█████████ | 257/285 [06:44<00:41,  1.47s/it]predicting train subjects:  91%|█████████ | 258/285 [06:46<00:41,  1.55s/it]predicting train subjects:  91%|█████████ | 259/285 [06:47<00:41,  1.58s/it]predicting train subjects:  91%|█████████ | 260/285 [06:49<00:37,  1.49s/it]predicting train subjects:  92%|█████████▏| 261/285 [06:50<00:35,  1.46s/it]predicting train subjects:  92%|█████████▏| 262/285 [06:51<00:32,  1.43s/it]predicting train subjects:  92%|█████████▏| 263/285 [06:53<00:30,  1.40s/it]predicting train subjects:  93%|█████████▎| 264/285 [06:55<00:31,  1.51s/it]predicting train subjects:  93%|█████████▎| 265/285 [06:56<00:31,  1.59s/it]predicting train subjects:  93%|█████████▎| 266/285 [06:58<00:28,  1.49s/it]predicting train subjects:  94%|█████████▎| 267/285 [06:59<00:26,  1.47s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:01<00:26,  1.58s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:02<00:25,  1.60s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:04<00:22,  1.53s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:05<00:21,  1.50s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:07<00:19,  1.54s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:08<00:17,  1.47s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:09<00:15,  1.42s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:11<00:15,  1.51s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:13<00:14,  1.56s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:14<00:11,  1.49s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:16<00:10,  1.44s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:17<00:08,  1.46s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:18<00:07,  1.43s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:20<00:05,  1.40s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:21<00:04,  1.35s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:23<00:02,  1.45s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:24<00:01,  1.52s/it]predicting train subjects: 100%|██████████| 285/285 [07:26<00:00,  1.57s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:18,  1.54s/it]Loading train:   1%|          | 2/285 [00:02<06:38,  1.41s/it]Loading train:   1%|          | 3/285 [00:04<06:35,  1.40s/it]Loading train:   1%|▏         | 4/285 [00:05<06:10,  1.32s/it]Loading train:   2%|▏         | 5/285 [00:06<06:28,  1.39s/it]Loading train:   2%|▏         | 6/285 [00:07<06:09,  1.33s/it]Loading train:   2%|▏         | 7/285 [00:09<06:21,  1.37s/it]Loading train:   3%|▎         | 8/285 [00:10<06:00,  1.30s/it]Loading train:   3%|▎         | 9/285 [00:12<06:25,  1.40s/it]Loading train:   4%|▎         | 10/285 [00:13<06:08,  1.34s/it]Loading train:   4%|▍         | 11/285 [00:14<05:28,  1.20s/it]Loading train:   4%|▍         | 12/285 [00:15<05:15,  1.16s/it]Loading train:   5%|▍         | 13/285 [00:16<04:50,  1.07s/it]Loading train:   5%|▍         | 14/285 [00:17<04:50,  1.07s/it]Loading train:   5%|▌         | 15/285 [00:18<05:00,  1.11s/it]Loading train:   6%|▌         | 16/285 [00:19<04:49,  1.08s/it]Loading train:   6%|▌         | 17/285 [00:20<04:24,  1.01it/s]Loading train:   6%|▋         | 18/285 [00:21<04:20,  1.03it/s]Loading train:   7%|▋         | 19/285 [00:22<04:13,  1.05it/s]Loading train:   7%|▋         | 20/285 [00:23<04:16,  1.03it/s]Loading train:   7%|▋         | 21/285 [00:24<04:20,  1.01it/s]Loading train:   8%|▊         | 22/285 [00:24<04:01,  1.09it/s]Loading train:   8%|▊         | 23/285 [00:25<04:03,  1.07it/s]Loading train:   8%|▊         | 24/285 [00:26<03:46,  1.15it/s]Loading train:   9%|▉         | 25/285 [00:27<03:47,  1.14it/s]Loading train:   9%|▉         | 26/285 [00:28<03:56,  1.10it/s]Loading train:   9%|▉         | 27/285 [00:29<03:37,  1.19it/s]Loading train:  10%|▉         | 28/285 [00:30<03:53,  1.10it/s]Loading train:  10%|█         | 29/285 [00:30<03:46,  1.13it/s]Loading train:  11%|█         | 30/285 [00:31<03:56,  1.08it/s]Loading train:  11%|█         | 31/285 [00:33<04:19,  1.02s/it]Loading train:  11%|█         | 32/285 [00:34<04:04,  1.03it/s]Loading train:  12%|█▏        | 33/285 [00:35<04:07,  1.02it/s]Loading train:  12%|█▏        | 34/285 [00:35<03:56,  1.06it/s]Loading train:  12%|█▏        | 35/285 [00:36<04:02,  1.03it/s]Loading train:  13%|█▎        | 36/285 [00:37<03:50,  1.08it/s]Loading train:  13%|█▎        | 37/285 [00:38<03:46,  1.10it/s]Loading train:  13%|█▎        | 38/285 [00:39<03:56,  1.04it/s]Loading train:  14%|█▎        | 39/285 [00:40<03:46,  1.09it/s]Loading train:  14%|█▍        | 40/285 [00:41<03:57,  1.03it/s]Loading train:  14%|█▍        | 41/285 [00:42<03:40,  1.11it/s]Loading train:  15%|█▍        | 42/285 [00:43<03:42,  1.09it/s]Loading train:  15%|█▌        | 43/285 [00:44<03:39,  1.10it/s]Loading train:  15%|█▌        | 44/285 [00:45<03:46,  1.07it/s]Loading train:  16%|█▌        | 45/285 [00:45<03:28,  1.15it/s]Loading train:  16%|█▌        | 46/285 [00:46<03:34,  1.11it/s]Loading train:  16%|█▋        | 47/285 [00:47<03:24,  1.16it/s]Loading train:  17%|█▋        | 48/285 [00:48<03:23,  1.17it/s]Loading train:  17%|█▋        | 49/285 [00:49<03:43,  1.06it/s]Loading train:  18%|█▊        | 50/285 [00:50<03:40,  1.07it/s]Loading train:  18%|█▊        | 51/285 [00:51<03:50,  1.01it/s]Loading train:  18%|█▊        | 52/285 [00:52<03:32,  1.10it/s]Loading train:  19%|█▊        | 53/285 [00:53<03:44,  1.03it/s]Loading train:  19%|█▉        | 54/285 [00:54<03:38,  1.06it/s]Loading train:  19%|█▉        | 55/285 [00:55<03:30,  1.10it/s]Loading train:  20%|█▉        | 56/285 [00:56<03:27,  1.10it/s]Loading train:  20%|██        | 57/285 [00:57<03:23,  1.12it/s]Loading train:  20%|██        | 58/285 [00:58<03:29,  1.08it/s]Loading train:  21%|██        | 59/285 [00:59<03:38,  1.03it/s]Loading train:  21%|██        | 60/285 [01:00<03:40,  1.02it/s]Loading train:  21%|██▏       | 61/285 [01:00<03:28,  1.08it/s]Loading train:  22%|██▏       | 62/285 [01:01<03:31,  1.06it/s]Loading train:  22%|██▏       | 63/285 [01:02<03:36,  1.02it/s]Loading train:  22%|██▏       | 64/285 [01:04<03:58,  1.08s/it]Loading train:  23%|██▎       | 65/285 [01:05<04:34,  1.25s/it]Loading train:  23%|██▎       | 66/285 [01:07<04:35,  1.26s/it]Loading train:  24%|██▎       | 67/285 [01:08<04:13,  1.16s/it]Loading train:  24%|██▍       | 68/285 [01:08<03:46,  1.05s/it]Loading train:  24%|██▍       | 69/285 [01:09<03:46,  1.05s/it]Loading train:  25%|██▍       | 70/285 [01:10<03:43,  1.04s/it]Loading train:  25%|██▍       | 71/285 [01:12<03:50,  1.08s/it]Loading train:  25%|██▌       | 72/285 [01:12<03:34,  1.01s/it]Loading train:  26%|██▌       | 73/285 [01:14<03:38,  1.03s/it]Loading train:  26%|██▌       | 74/285 [01:14<03:21,  1.05it/s]Loading train:  26%|██▋       | 75/285 [01:15<03:24,  1.03it/s]Loading train:  27%|██▋       | 76/285 [01:16<03:19,  1.05it/s]Loading train:  27%|██▋       | 77/285 [01:17<03:12,  1.08it/s]Loading train:  27%|██▋       | 78/285 [01:18<03:01,  1.14it/s]Loading train:  28%|██▊       | 79/285 [01:19<03:05,  1.11it/s]Loading train:  28%|██▊       | 80/285 [01:20<03:03,  1.12it/s]Loading train:  28%|██▊       | 81/285 [01:21<03:03,  1.11it/s]Loading train:  29%|██▉       | 82/285 [01:22<03:08,  1.08it/s]Loading train:  29%|██▉       | 83/285 [01:23<03:05,  1.09it/s]Loading train:  29%|██▉       | 84/285 [01:24<03:12,  1.04it/s]Loading train:  30%|██▉       | 85/285 [01:24<03:05,  1.08it/s]Loading train:  30%|███       | 86/285 [01:26<03:20,  1.01s/it]Loading train:  31%|███       | 87/285 [01:27<03:18,  1.00s/it]Loading train:  31%|███       | 88/285 [01:28<03:11,  1.03it/s]Loading train:  31%|███       | 89/285 [01:28<03:08,  1.04it/s]Loading train:  32%|███▏      | 90/285 [01:29<03:08,  1.03it/s]Loading train:  32%|███▏      | 91/285 [01:30<03:00,  1.07it/s]Loading train:  32%|███▏      | 92/285 [01:31<03:07,  1.03it/s]Loading train:  33%|███▎      | 93/285 [01:32<03:00,  1.06it/s]Loading train:  33%|███▎      | 94/285 [01:33<02:54,  1.09it/s]Loading train:  33%|███▎      | 95/285 [01:34<02:54,  1.09it/s]Loading train:  34%|███▎      | 96/285 [01:35<03:00,  1.04it/s]Loading train:  34%|███▍      | 97/285 [01:36<03:02,  1.03it/s]Loading train:  34%|███▍      | 98/285 [01:37<03:03,  1.02it/s]Loading train:  35%|███▍      | 99/285 [01:38<02:56,  1.05it/s]Loading train:  35%|███▌      | 100/285 [01:39<03:00,  1.03it/s]Loading train:  35%|███▌      | 101/285 [01:40<02:53,  1.06it/s]Loading train:  36%|███▌      | 102/285 [01:41<02:59,  1.02it/s]Loading train:  36%|███▌      | 103/285 [01:42<02:47,  1.09it/s]Loading train:  36%|███▋      | 104/285 [01:43<02:49,  1.07it/s]Loading train:  37%|███▋      | 105/285 [01:44<02:45,  1.09it/s]Loading train:  37%|███▋      | 106/285 [01:44<02:41,  1.11it/s]Loading train:  38%|███▊      | 107/285 [01:45<02:39,  1.12it/s]Loading train:  38%|███▊      | 108/285 [01:46<02:32,  1.16it/s]Loading train:  38%|███▊      | 109/285 [01:47<02:28,  1.18it/s]Loading train:  39%|███▊      | 110/285 [01:48<02:31,  1.15it/s]Loading train:  39%|███▉      | 111/285 [01:49<02:34,  1.13it/s]Loading train:  39%|███▉      | 112/285 [01:50<02:31,  1.14it/s]Loading train:  40%|███▉      | 113/285 [01:51<02:43,  1.05it/s]Loading train:  40%|████      | 114/285 [01:52<02:37,  1.09it/s]Loading train:  40%|████      | 115/285 [01:53<02:39,  1.07it/s]Loading train:  41%|████      | 116/285 [01:53<02:36,  1.08it/s]Loading train:  41%|████      | 117/285 [01:54<02:27,  1.14it/s]Loading train:  41%|████▏     | 118/285 [01:55<02:30,  1.11it/s]Loading train:  42%|████▏     | 119/285 [01:56<02:29,  1.11it/s]Loading train:  42%|████▏     | 120/285 [01:57<02:21,  1.16it/s]Loading train:  42%|████▏     | 121/285 [01:58<02:42,  1.01it/s]Loading train:  43%|████▎     | 122/285 [01:59<02:51,  1.05s/it]Loading train:  43%|████▎     | 123/285 [02:01<02:59,  1.11s/it]Loading train:  44%|████▎     | 124/285 [02:01<02:46,  1.03s/it]Loading train:  44%|████▍     | 125/285 [02:02<02:36,  1.02it/s]Loading train:  44%|████▍     | 126/285 [02:03<02:27,  1.07it/s]Loading train:  45%|████▍     | 127/285 [02:04<02:18,  1.14it/s]Loading train:  45%|████▍     | 128/285 [02:05<02:26,  1.07it/s]Loading train:  45%|████▌     | 129/285 [02:06<02:24,  1.08it/s]Loading train:  46%|████▌     | 130/285 [02:06<02:10,  1.18it/s]Loading train:  46%|████▌     | 131/285 [02:08<02:21,  1.09it/s]Loading train:  46%|████▋     | 132/285 [02:08<02:17,  1.12it/s]Loading train:  47%|████▋     | 133/285 [02:09<02:06,  1.20it/s]Loading train:  47%|████▋     | 134/285 [02:10<01:58,  1.28it/s]Loading train:  47%|████▋     | 135/285 [02:10<01:53,  1.33it/s]Loading train:  48%|████▊     | 136/285 [02:11<01:49,  1.36it/s]Loading train:  48%|████▊     | 137/285 [02:12<01:54,  1.29it/s]Loading train:  48%|████▊     | 138/285 [02:13<01:59,  1.23it/s]Loading train:  49%|████▉     | 139/285 [02:14<01:58,  1.23it/s]Loading train:  49%|████▉     | 140/285 [02:15<02:01,  1.19it/s]Loading train:  49%|████▉     | 141/285 [02:15<02:00,  1.19it/s]Loading train:  50%|████▉     | 142/285 [02:16<02:00,  1.19it/s]Loading train:  50%|█████     | 143/285 [02:17<01:57,  1.21it/s]Loading train:  51%|█████     | 144/285 [02:18<01:55,  1.23it/s]Loading train:  51%|█████     | 145/285 [02:19<01:54,  1.22it/s]Loading train:  51%|█████     | 146/285 [02:20<01:55,  1.21it/s]Loading train:  52%|█████▏    | 147/285 [02:20<01:53,  1.21it/s]Loading train:  52%|█████▏    | 148/285 [02:21<01:51,  1.23it/s]Loading train:  52%|█████▏    | 149/285 [02:22<01:47,  1.27it/s]Loading train:  53%|█████▎    | 150/285 [02:23<01:50,  1.22it/s]Loading train:  53%|█████▎    | 151/285 [02:24<01:47,  1.25it/s]Loading train:  53%|█████▎    | 152/285 [02:24<01:44,  1.28it/s]Loading train:  54%|█████▎    | 153/285 [02:25<01:38,  1.34it/s]Loading train:  54%|█████▍    | 154/285 [02:26<01:36,  1.36it/s]Loading train:  54%|█████▍    | 155/285 [02:26<01:35,  1.36it/s]Loading train:  55%|█████▍    | 156/285 [02:27<01:41,  1.27it/s]Loading train:  55%|█████▌    | 157/285 [02:28<01:43,  1.24it/s]Loading train:  55%|█████▌    | 158/285 [02:29<01:44,  1.22it/s]Loading train:  56%|█████▌    | 159/285 [02:30<01:43,  1.22it/s]Loading train:  56%|█████▌    | 160/285 [02:31<01:44,  1.20it/s]Loading train:  56%|█████▋    | 161/285 [02:31<01:42,  1.21it/s]Loading train:  57%|█████▋    | 162/285 [02:32<01:43,  1.18it/s]Loading train:  57%|█████▋    | 163/285 [02:33<01:38,  1.24it/s]Loading train:  58%|█████▊    | 164/285 [02:34<01:35,  1.27it/s]Loading train:  58%|█████▊    | 165/285 [02:35<01:37,  1.22it/s]Loading train:  58%|█████▊    | 166/285 [02:36<01:38,  1.21it/s]Loading train:  59%|█████▊    | 167/285 [02:37<01:43,  1.14it/s]Loading train:  59%|█████▉    | 168/285 [02:37<01:43,  1.13it/s]Loading train:  59%|█████▉    | 169/285 [02:38<01:38,  1.17it/s]Loading train:  60%|█████▉    | 170/285 [02:39<01:35,  1.21it/s]Loading train:  60%|██████    | 171/285 [02:40<01:30,  1.26it/s]Loading train:  60%|██████    | 172/285 [02:41<01:30,  1.25it/s]Loading train:  61%|██████    | 173/285 [02:41<01:27,  1.29it/s]Loading train:  61%|██████    | 174/285 [02:42<01:29,  1.23it/s]Loading train:  61%|██████▏   | 175/285 [02:43<01:30,  1.22it/s]Loading train:  62%|██████▏   | 176/285 [02:44<01:31,  1.19it/s]Loading train:  62%|██████▏   | 177/285 [02:45<01:30,  1.19it/s]Loading train:  62%|██████▏   | 178/285 [02:45<01:28,  1.22it/s]Loading train:  63%|██████▎   | 179/285 [02:46<01:28,  1.20it/s]Loading train:  63%|██████▎   | 180/285 [02:47<01:31,  1.15it/s]Loading train:  64%|██████▎   | 181/285 [02:48<01:33,  1.11it/s]Loading train:  64%|██████▍   | 182/285 [02:49<01:31,  1.13it/s]Loading train:  64%|██████▍   | 183/285 [02:50<01:27,  1.16it/s]Loading train:  65%|██████▍   | 184/285 [02:51<01:23,  1.22it/s]Loading train:  65%|██████▍   | 185/285 [02:51<01:20,  1.24it/s]Loading train:  65%|██████▌   | 186/285 [02:52<01:27,  1.13it/s]Loading train:  66%|██████▌   | 187/285 [02:53<01:27,  1.12it/s]Loading train:  66%|██████▌   | 188/285 [02:54<01:27,  1.11it/s]Loading train:  66%|██████▋   | 189/285 [02:55<01:20,  1.19it/s]Loading train:  67%|██████▋   | 190/285 [02:56<01:21,  1.16it/s]Loading train:  67%|██████▋   | 191/285 [02:57<01:17,  1.21it/s]Loading train:  67%|██████▋   | 192/285 [02:57<01:16,  1.21it/s]Loading train:  68%|██████▊   | 193/285 [02:58<01:11,  1.28it/s]Loading train:  68%|██████▊   | 194/285 [02:59<01:08,  1.33it/s]Loading train:  68%|██████▊   | 195/285 [03:00<01:06,  1.36it/s]Loading train:  69%|██████▉   | 196/285 [03:01<01:14,  1.19it/s]Loading train:  69%|██████▉   | 197/285 [03:02<01:18,  1.12it/s]Loading train:  69%|██████▉   | 198/285 [03:03<01:19,  1.10it/s]Loading train:  70%|██████▉   | 199/285 [03:03<01:14,  1.15it/s]Loading train:  70%|███████   | 200/285 [03:04<01:11,  1.18it/s]Loading train:  71%|███████   | 201/285 [03:05<01:13,  1.14it/s]Loading train:  71%|███████   | 202/285 [03:06<01:16,  1.08it/s]Loading train:  71%|███████   | 203/285 [03:07<01:11,  1.14it/s]Loading train:  72%|███████▏  | 204/285 [03:08<01:10,  1.15it/s]Loading train:  72%|███████▏  | 205/285 [03:09<01:07,  1.19it/s]Loading train:  72%|███████▏  | 206/285 [03:09<01:03,  1.24it/s]Loading train:  73%|███████▎  | 207/285 [03:10<01:05,  1.19it/s]Loading train:  73%|███████▎  | 208/285 [03:11<01:09,  1.11it/s]Loading train:  73%|███████▎  | 209/285 [03:12<01:07,  1.12it/s]Loading train:  74%|███████▎  | 210/285 [03:13<01:04,  1.15it/s]Loading train:  74%|███████▍  | 211/285 [03:14<01:07,  1.10it/s]Loading train:  74%|███████▍  | 212/285 [03:15<01:04,  1.13it/s]Loading train:  75%|███████▍  | 213/285 [03:16<01:04,  1.11it/s]Loading train:  75%|███████▌  | 214/285 [03:16<00:58,  1.21it/s]Loading train:  75%|███████▌  | 215/285 [03:17<00:57,  1.21it/s]Loading train:  76%|███████▌  | 216/285 [03:18<00:52,  1.31it/s]Loading train:  76%|███████▌  | 217/285 [03:19<00:53,  1.28it/s]Loading train:  76%|███████▋  | 218/285 [03:19<00:54,  1.23it/s]Loading train:  77%|███████▋  | 219/285 [03:20<00:54,  1.22it/s]Loading train:  77%|███████▋  | 220/285 [03:21<00:51,  1.27it/s]Loading train:  78%|███████▊  | 221/285 [03:22<00:48,  1.31it/s]Loading train:  78%|███████▊  | 222/285 [03:23<00:48,  1.30it/s]Loading train:  78%|███████▊  | 223/285 [03:23<00:48,  1.29it/s]Loading train:  79%|███████▊  | 224/285 [03:24<00:44,  1.37it/s]Loading train:  79%|███████▉  | 225/285 [03:25<00:41,  1.44it/s]Loading train:  79%|███████▉  | 226/285 [03:25<00:44,  1.32it/s]Loading train:  80%|███████▉  | 227/285 [03:26<00:46,  1.24it/s]Loading train:  80%|████████  | 228/285 [03:27<00:48,  1.17it/s]Loading train:  80%|████████  | 229/285 [03:28<00:46,  1.20it/s]Loading train:  81%|████████  | 230/285 [03:29<00:44,  1.24it/s]Loading train:  81%|████████  | 231/285 [03:30<00:43,  1.25it/s]Loading train:  81%|████████▏ | 232/285 [03:30<00:41,  1.27it/s]Loading train:  82%|████████▏ | 233/285 [03:31<00:41,  1.26it/s]Loading train:  82%|████████▏ | 234/285 [03:32<00:42,  1.20it/s]Loading train:  82%|████████▏ | 235/285 [03:33<00:41,  1.22it/s]Loading train:  83%|████████▎ | 236/285 [03:34<00:42,  1.16it/s]Loading train:  83%|████████▎ | 237/285 [03:35<00:41,  1.15it/s]Loading train:  84%|████████▎ | 238/285 [03:36<00:40,  1.16it/s]Loading train:  84%|████████▍ | 239/285 [03:36<00:37,  1.21it/s]Loading train:  84%|████████▍ | 240/285 [03:37<00:34,  1.29it/s]Loading train:  85%|████████▍ | 241/285 [03:38<00:32,  1.34it/s]Loading train:  85%|████████▍ | 242/285 [03:38<00:30,  1.39it/s]Loading train:  85%|████████▌ | 243/285 [03:39<00:29,  1.42it/s]Loading train:  86%|████████▌ | 244/285 [03:40<00:30,  1.35it/s]Loading train:  86%|████████▌ | 245/285 [03:41<00:28,  1.38it/s]Loading train:  86%|████████▋ | 246/285 [03:41<00:29,  1.34it/s]Loading train:  87%|████████▋ | 247/285 [03:42<00:30,  1.25it/s]Loading train:  87%|████████▋ | 248/285 [03:43<00:29,  1.24it/s]Loading train:  87%|████████▋ | 249/285 [03:44<00:28,  1.25it/s]Loading train:  88%|████████▊ | 250/285 [03:45<00:26,  1.32it/s]Loading train:  88%|████████▊ | 251/285 [03:45<00:25,  1.36it/s]Loading train:  88%|████████▊ | 252/285 [03:46<00:24,  1.35it/s]Loading train:  89%|████████▉ | 253/285 [03:47<00:24,  1.29it/s]Loading train:  89%|████████▉ | 254/285 [03:48<00:26,  1.15it/s]Loading train:  89%|████████▉ | 255/285 [03:49<00:26,  1.15it/s]Loading train:  90%|████████▉ | 256/285 [03:50<00:24,  1.20it/s]Loading train:  90%|█████████ | 257/285 [03:50<00:22,  1.26it/s]Loading train:  91%|█████████ | 258/285 [03:51<00:22,  1.20it/s]Loading train:  91%|█████████ | 259/285 [03:52<00:22,  1.18it/s]Loading train:  91%|█████████ | 260/285 [03:53<00:20,  1.20it/s]Loading train:  92%|█████████▏| 261/285 [03:54<00:20,  1.19it/s]Loading train:  92%|█████████▏| 262/285 [03:54<00:18,  1.22it/s]Loading train:  92%|█████████▏| 263/285 [03:55<00:17,  1.29it/s]Loading train:  93%|█████████▎| 264/285 [03:56<00:17,  1.18it/s]Loading train:  93%|█████████▎| 265/285 [03:57<00:17,  1.13it/s]Loading train:  93%|█████████▎| 266/285 [03:58<00:15,  1.20it/s]Loading train:  94%|█████████▎| 267/285 [03:59<00:14,  1.24it/s]Loading train:  94%|█████████▍| 268/285 [04:00<00:14,  1.14it/s]Loading train:  94%|█████████▍| 269/285 [04:00<00:13,  1.15it/s]Loading train:  95%|█████████▍| 270/285 [04:01<00:13,  1.15it/s]Loading train:  95%|█████████▌| 271/285 [04:02<00:11,  1.18it/s]Loading train:  95%|█████████▌| 272/285 [04:03<00:11,  1.16it/s]Loading train:  96%|█████████▌| 273/285 [04:04<00:09,  1.24it/s]Loading train:  96%|█████████▌| 274/285 [04:04<00:08,  1.31it/s]Loading train:  96%|█████████▋| 275/285 [04:05<00:08,  1.17it/s]Loading train:  97%|█████████▋| 276/285 [04:06<00:08,  1.11it/s]Loading train:  97%|█████████▋| 277/285 [04:07<00:06,  1.21it/s]Loading train:  98%|█████████▊| 278/285 [04:08<00:05,  1.29it/s]Loading train:  98%|█████████▊| 279/285 [04:09<00:04,  1.22it/s]Loading train:  98%|█████████▊| 280/285 [04:10<00:04,  1.19it/s]Loading train:  99%|█████████▊| 281/285 [04:10<00:03,  1.20it/s]Loading train:  99%|█████████▉| 282/285 [04:11<00:02,  1.26it/s]Loading train:  99%|█████████▉| 283/285 [04:12<00:01,  1.13it/s]Loading train: 100%|█████████▉| 284/285 [04:13<00:00,  1.12it/s]Loading train: 100%|██████████| 285/285 [04:14<00:00,  1.13it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:  10%|▉         | 28/285 [00:00<00:00, 271.95it/s]concatenating: train:  21%|██        | 59/285 [00:00<00:00, 281.75it/s]concatenating: train:  32%|███▏      | 92/285 [00:00<00:00, 293.70it/s]concatenating: train:  43%|████▎     | 122/285 [00:00<00:00, 274.69it/s]concatenating: train:  51%|█████     | 144/285 [00:00<00:00, 155.73it/s]concatenating: train:  57%|█████▋    | 162/285 [00:00<00:00, 150.11it/s]concatenating: train:  66%|██████▌   | 188/285 [00:00<00:00, 171.56it/s]concatenating: train:  78%|███████▊  | 223/285 [00:01<00:00, 201.83it/s]concatenating: train:  89%|████████▉ | 255/285 [00:01<00:00, 224.61it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 229.33it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.30s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.24s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.17s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 678.03it/s]2019-07-11 07:42:22.188737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 07:42:22.188857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 07:42:22.188874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 07:42:22.188882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 07:42:22.189737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.61it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.50it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.16it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.60it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.71it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.37it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.72it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.37it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  7.74it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.36it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.72it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:02,  8.23it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  8.54it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  6.65it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.20it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:00,  8.40it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  8.54it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  6.86it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.46it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 30)   4080        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 40, 45)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 60)   24360       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 20, 105)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 105)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 105)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 105)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 15)   4065        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 45)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 45)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 40)   16240       dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 40)   160         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 40)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 80, 40)   0           activation_11[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 40)   14440       dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 80, 40)   160         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 80, 40)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 80, 40)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 85)   0           dropout_5[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 80, 13)   1118        concatenate_7[0][0]              
==================================================================================================
Total params: 157,998
Trainable params: 59,378
Non-trainable params: 98,620
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 16s - loss: 2.7233 - acc: 0.6564 - mDice: 0.1187 - val_loss: 3.5859 - val_acc: 0.9093 - val_mDice: 0.1531

Epoch 00001: val_mDice improved from -inf to 0.15311, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 11s - loss: 0.9311 - acc: 0.8872 - mDice: 0.3995 - val_loss: 2.6361 - val_acc: 0.9115 - val_mDice: 0.1954

Epoch 00002: val_mDice improved from 0.15311 to 0.19541, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 11s - loss: 0.6486 - acc: 0.8993 - mDice: 0.5081 - val_loss: 1.5238 - val_acc: 0.9178 - val_mDice: 0.3551

Epoch 00003: val_mDice improved from 0.19541 to 0.35514, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 11s - loss: 0.5565 - acc: 0.9096 - mDice: 0.5578 - val_loss: 1.3516 - val_acc: 0.9227 - val_mDice: 0.3860

Epoch 00004: val_mDice improved from 0.35514 to 0.38595, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 11s - loss: 0.5058 - acc: 0.9169 - mDice: 0.5877 - val_loss: 1.1278 - val_acc: 0.9353 - val_mDice: 0.4895

Epoch 00005: val_mDice improved from 0.38595 to 0.48946, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 11s - loss: 0.4818 - acc: 0.9218 - mDice: 0.6023 - val_loss: 0.9992 - val_acc: 0.9399 - val_mDice: 0.5560

Epoch 00006: val_mDice improved from 0.48946 to 0.55598, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 11s - loss: 0.4629 - acc: 0.9262 - mDice: 0.6142 - val_loss: 1.0402 - val_acc: 0.9304 - val_mDice: 0.5515

Epoch 00007: val_mDice did not improve from 0.55598
Epoch 8/300
 - 11s - loss: 0.4455 - acc: 0.9289 - mDice: 0.6250 - val_loss: 0.9412 - val_acc: 0.9447 - val_mDice: 0.5632

Epoch 00008: val_mDice improved from 0.55598 to 0.56323, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 10s - loss: 0.4339 - acc: 0.9304 - mDice: 0.6326 - val_loss: 1.0126 - val_acc: 0.9420 - val_mDice: 0.5297

Epoch 00009: val_mDice did not improve from 0.56323
Epoch 10/300
 - 11s - loss: 0.4261 - acc: 0.9310 - mDice: 0.6376 - val_loss: 1.0155 - val_acc: 0.9417 - val_mDice: 0.5213

Epoch 00010: val_mDice did not improve from 0.56323
Epoch 11/300
 - 10s - loss: 0.4148 - acc: 0.9322 - mDice: 0.6453 - val_loss: 1.1074 - val_acc: 0.9347 - val_mDice: 0.4752

Epoch 00011: val_mDice did not improve from 0.56323
Epoch 12/300
 - 11s - loss: 0.4068 - acc: 0.9332 - mDice: 0.6504 - val_loss: 0.9290 - val_acc: 0.9446 - val_mDice: 0.5847

Epoch 00012: val_mDice improved from 0.56323 to 0.58468, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 11s - loss: 0.4019 - acc: 0.9336 - mDice: 0.6538 - val_loss: 0.9219 - val_acc: 0.9451 - val_mDice: 0.5734

Epoch 00013: val_mDice did not improve from 0.58468
Epoch 14/300
 - 10s - loss: 0.3952 - acc: 0.9341 - mDice: 0.6583 - val_loss: 0.9016 - val_acc: 0.9446 - val_mDice: 0.5693

Epoch 00014: val_mDice did not improve from 0.58468
Epoch 15/300
 - 11s - loss: 0.3938 - acc: 0.9346 - mDice: 0.6596 - val_loss: 0.9030 - val_acc: 0.9410 - val_mDice: 0.5780

Epoch 00015: val_mDice did not improve from 0.58468
Epoch 16/300
 - 10s - loss: 0.3870 - acc: 0.9352 - mDice: 0.6639 - val_loss: 0.9090 - val_acc: 0.9431 - val_mDice: 0.5691

Epoch 00016: val_mDice did not improve from 0.58468
Epoch 17/300
 - 10s - loss: 0.3844 - acc: 0.9352 - mDice: 0.6657 - val_loss: 0.9921 - val_acc: 0.9350 - val_mDice: 0.5251

Epoch 00017: val_mDice did not improve from 0.58468
Epoch 18/300
 - 10s - loss: 0.3788 - acc: 0.9359 - mDice: 0.6695 - val_loss: 0.9456 - val_acc: 0.9448 - val_mDice: 0.5459

Epoch 00018: val_mDice did not improve from 0.58468
Epoch 19/300
 - 11s - loss: 0.3760 - acc: 0.9362 - mDice: 0.6717 - val_loss: 0.9385 - val_acc: 0.9425 - val_mDice: 0.5329

Epoch 00019: val_mDice did not improve from 0.58468
Epoch 20/300
 - 11s - loss: 0.3712 - acc: 0.9367 - mDice: 0.6750 - val_loss: 0.8823 - val_acc: 0.9466 - val_mDice: 0.5674

Epoch 00020: val_mDice did not improve from 0.58468
Epoch 21/300
 - 11s - loss: 0.3652 - acc: 0.9372 - mDice: 0.6791 - val_loss: 0.8994 - val_acc: 0.9432 - val_mDice: 0.5728

Epoch 00021: val_mDice did not improve from 0.58468
Epoch 22/300
 - 11s - loss: 0.3614 - acc: 0.9375 - mDice: 0.6818 - val_loss: 0.8852 - val_acc: 0.9443 - val_mDice: 0.5713

Epoch 00022: val_mDice did not improve from 0.58468
Epoch 23/300
 - 12s - loss: 0.3613 - acc: 0.9376 - mDice: 0.6818 - val_loss: 0.8944 - val_acc: 0.9452 - val_mDice: 0.5515

Epoch 00023: val_mDice did not improve from 0.58468
Epoch 24/300
 - 11s - loss: 0.3590 - acc: 0.9379 - mDice: 0.6836 - val_loss: 0.9200 - val_acc: 0.9433 - val_mDice: 0.5521

Epoch 00024: val_mDice did not improve from 0.58468
Epoch 25/300
 - 12s - loss: 0.3577 - acc: 0.9381 - mDice: 0.6844 - val_loss: 0.9045 - val_acc: 0.9426 - val_mDice: 0.5722

Epoch 00025: val_mDice did not improve from 0.58468
Epoch 26/300
 - 11s - loss: 0.3563 - acc: 0.9381 - mDice: 0.6853 - val_loss: 0.8594 - val_acc: 0.9410 - val_mDice: 0.5621

Epoch 00026: val_mDice did not improve from 0.58468
Epoch 27/300
 - 12s - loss: 0.3497 - acc: 0.9385 - mDice: 0.6900 - val_loss: 0.8596 - val_acc: 0.9416 - val_mDice: 0.5735

Epoch 00027: val_mDice did not improve from 0.58468
Epoch 28/300
 - 11s - loss: 0.3497 - acc: 0.9387 - mDice: 0.6901 - val_loss: 0.8401 - val_acc: 0.9458 - val_mDice: 0.5769

Epoch 00028: val_mDice did not improve from 0.58468
Epoch 29/300
 - 12s - loss: 0.3480 - acc: 0.9387 - mDice: 0.6912 - val_loss: 0.8599 - val_acc: 0.9431 - val_mDice: 0.5719

Epoch 00029: val_mDice did not improve from 0.58468
Epoch 30/300
 - 11s - loss: 0.3467 - acc: 0.9391 - mDice: 0.6923 - val_loss: 0.8622 - val_acc: 0.9444 - val_mDice: 0.5771

Epoch 00030: val_mDice did not improve from 0.58468
Epoch 31/300
 - 12s - loss: 0.3424 - acc: 0.9393 - mDice: 0.6953 - val_loss: 0.9533 - val_acc: 0.9231 - val_mDice: 0.5242

Epoch 00031: val_mDice did not improve from 0.58468
Epoch 32/300
 - 11s - loss: 0.3410 - acc: 0.9394 - mDice: 0.6963 - val_loss: 0.8371 - val_acc: 0.9451 - val_mDice: 0.5748

Epoch 00032: val_mDice did not improve from 0.58468
Epoch 33/300
 - 11s - loss: 0.3399 - acc: 0.9396 - mDice: 0.6971 - val_loss: 0.8975 - val_acc: 0.9427 - val_mDice: 0.5315

Epoch 00033: val_mDice did not improve from 0.58468
Epoch 34/300
 - 12s - loss: 0.3362 - acc: 0.9400 - mDice: 0.6998 - val_loss: 0.8754 - val_acc: 0.9408 - val_mDice: 0.5489

Epoch 00034: val_mDice did not improve from 0.58468
Epoch 35/300
 - 11s - loss: 0.3364 - acc: 0.9400 - mDice: 0.6996 - val_loss: 0.8197 - val_acc: 0.9456 - val_mDice: 0.5778

Epoch 00035: val_mDice did not improve from 0.58468
Epoch 36/300
 - 12s - loss: 0.3361 - acc: 0.9400 - mDice: 0.6998 - val_loss: 0.8462 - val_acc: 0.9443 - val_mDice: 0.5664

Epoch 00036: val_mDice did not improve from 0.58468
Epoch 37/300
 - 11s - loss: 0.3330 - acc: 0.9402 - mDice: 0.7021 - val_loss: 0.8252 - val_acc: 0.9441 - val_mDice: 0.5728

Epoch 00037: val_mDice did not improve from 0.58468
Epoch 38/300
 - 12s - loss: 0.3309 - acc: 0.9404 - mDice: 0.7038 - val_loss: 0.8409 - val_acc: 0.9430 - val_mDice: 0.5512

Epoch 00038: val_mDice did not improve from 0.58468
Epoch 39/300
 - 11s - loss: 0.3289 - acc: 0.9406 - mDice: 0.7050 - val_loss: 0.8527 - val_acc: 0.9377 - val_mDice: 0.5713

Epoch 00039: val_mDice did not improve from 0.58468
Epoch 40/300
 - 12s - loss: 0.3281 - acc: 0.9407 - mDice: 0.7058 - val_loss: 0.8138 - val_acc: 0.9411 - val_mDice: 0.5773

Epoch 00040: val_mDice did not improve from 0.58468
Epoch 41/300
 - 11s - loss: 0.3280 - acc: 0.9407 - mDice: 0.7058 - val_loss: 0.8268 - val_acc: 0.9454 - val_mDice: 0.5561

Epoch 00041: val_mDice did not improve from 0.58468
Epoch 42/300
 - 12s - loss: 0.3262 - acc: 0.9409 - mDice: 0.7070 - val_loss: 0.9055 - val_acc: 0.9441 - val_mDice: 0.5501

Epoch 00042: val_mDice did not improve from 0.58468
Epoch 43/300
 - 11s - loss: 0.3232 - acc: 0.9411 - mDice: 0.7093 - val_loss: 0.7905 - val_acc: 0.9429 - val_mDice: 0.5596

Epoch 00043: val_mDice did not improve from 0.58468
Epoch 44/300
 - 11s - loss: 0.3228 - acc: 0.9411 - mDice: 0.7096 - val_loss: 0.8255 - val_acc: 0.9452 - val_mDice: 0.5512

Epoch 00044: val_mDice did not improve from 0.58468
Epoch 45/300
 - 10s - loss: 0.3212 - acc: 0.9413 - mDice: 0.7107 - val_loss: 0.8006 - val_acc: 0.9451 - val_mDice: 0.5581

Epoch 00045: val_mDice did not improve from 0.58468
Epoch 46/300
 - 11s - loss: 0.3212 - acc: 0.9414 - mDice: 0.7110 - val_loss: 0.7673 - val_acc: 0.9449 - val_mDice: 0.5732

Epoch 00046: val_mDice did not improve from 0.58468
Epoch 47/300
 - 11s - loss: 0.3202 - acc: 0.9414 - mDice: 0.7115 - val_loss: 0.8565 - val_acc: 0.9424 - val_mDice: 0.5185

Epoch 00047: val_mDice did not improve from 0.58468
Epoch 48/300
 - 10s - loss: 0.3195 - acc: 0.9415 - mDice: 0.7122 - val_loss: 0.7998 - val_acc: 0.9449 - val_mDice: 0.5521

Epoch 00048: val_mDice did not improve from 0.58468
Epoch 49/300
 - 11s - loss: 0.3182 - acc: 0.9416 - mDice: 0.7130 - val_loss: 0.8350 - val_acc: 0.9427 - val_mDice: 0.5520

Epoch 00049: val_mDice did not improve from 0.58468
Epoch 50/300
 - 10s - loss: 0.3151 - acc: 0.9419 - mDice: 0.7153 - val_loss: 0.8216 - val_acc: 0.9410 - val_mDice: 0.5542

Epoch 00050: val_mDice did not improve from 0.58468
Epoch 51/300
 - 10s - loss: 0.3151 - acc: 0.9418 - mDice: 0.7152 - val_loss: 0.8198 - val_acc: 0.9423 - val_mDice: 0.5348

Epoch 00051: val_mDice did not improve from 0.58468
Epoch 52/300
 - 10s - loss: 0.3147 - acc: 0.9418 - mDice: 0.7156 - val_loss: 0.8324 - val_acc: 0.9446 - val_mDice: 0.5590

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.14s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.94s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.77s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:33,  1.81s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:53,  1.67s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:54,  1.68s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:27,  1.59s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:44,  1.66s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:23,  1.59s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:41,  1.66s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:35,  1.64s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<08:02,  1.75s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:13,  1.79s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<07:49,  1.71s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:10,  1.80s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:47,  1.72s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<07:50,  1.74s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<07:57,  1.77s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<07:59,  1.78s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<07:47,  1.75s/it]predicting train subjects:   6%|▋         | 18/285 [00:30<07:56,  1.78s/it]predicting train subjects:   7%|▋         | 19/285 [00:32<07:35,  1.71s/it]predicting train subjects:   7%|▋         | 20/285 [00:34<07:37,  1.72s/it]predicting train subjects:   7%|▋         | 21/285 [00:36<07:57,  1.81s/it]predicting train subjects:   8%|▊         | 22/285 [00:37<07:33,  1.72s/it]predicting train subjects:   8%|▊         | 23/285 [00:39<07:36,  1.74s/it]predicting train subjects:   8%|▊         | 24/285 [00:40<07:13,  1.66s/it]predicting train subjects:   9%|▉         | 25/285 [00:42<07:39,  1.77s/it]predicting train subjects:   9%|▉         | 26/285 [00:44<07:53,  1.83s/it]predicting train subjects:   9%|▉         | 27/285 [00:46<07:25,  1.73s/it]predicting train subjects:  10%|▉         | 28/285 [00:48<07:32,  1.76s/it]predicting train subjects:  10%|█         | 29/285 [00:50<07:36,  1.78s/it]predicting train subjects:  11%|█         | 30/285 [00:51<07:44,  1.82s/it]predicting train subjects:  11%|█         | 31/285 [00:53<07:55,  1.87s/it]predicting train subjects:  11%|█         | 32/285 [00:55<07:26,  1.77s/it]predicting train subjects:  12%|█▏        | 33/285 [00:57<07:28,  1.78s/it]predicting train subjects:  12%|█▏        | 34/285 [00:59<07:29,  1.79s/it]predicting train subjects:  12%|█▏        | 35/285 [01:00<07:33,  1.81s/it]predicting train subjects:  13%|█▎        | 36/285 [01:02<07:13,  1.74s/it]predicting train subjects:  13%|█▎        | 37/285 [01:04<07:19,  1.77s/it]predicting train subjects:  13%|█▎        | 38/285 [01:06<07:28,  1.81s/it]predicting train subjects:  14%|█▎        | 39/285 [01:07<07:05,  1.73s/it]predicting train subjects:  14%|█▍        | 40/285 [01:09<07:14,  1.77s/it]predicting train subjects:  14%|█▍        | 41/285 [01:11<07:03,  1.73s/it]predicting train subjects:  15%|█▍        | 42/285 [01:12<06:46,  1.67s/it]predicting train subjects:  15%|█▌        | 43/285 [01:14<07:01,  1.74s/it]predicting train subjects:  15%|█▌        | 44/285 [01:16<07:17,  1.82s/it]predicting train subjects:  16%|█▌        | 45/285 [01:18<06:57,  1.74s/it]predicting train subjects:  16%|█▌        | 46/285 [01:20<07:09,  1.80s/it]predicting train subjects:  16%|█▋        | 47/285 [01:21<06:49,  1.72s/it]predicting train subjects:  17%|█▋        | 48/285 [01:23<06:55,  1.75s/it]predicting train subjects:  17%|█▋        | 49/285 [01:25<07:12,  1.83s/it]predicting train subjects:  18%|█▊        | 50/285 [01:27<07:08,  1.82s/it]predicting train subjects:  18%|█▊        | 51/285 [01:29<07:17,  1.87s/it]predicting train subjects:  18%|█▊        | 52/285 [01:31<07:01,  1.81s/it]predicting train subjects:  19%|█▊        | 53/285 [01:32<07:03,  1.83s/it]predicting train subjects:  19%|█▉        | 54/285 [01:34<07:08,  1.85s/it]predicting train subjects:  19%|█▉        | 55/285 [01:36<06:44,  1.76s/it]predicting train subjects:  20%|█▉        | 56/285 [01:38<06:43,  1.76s/it]predicting train subjects:  20%|██        | 57/285 [01:39<06:26,  1.70s/it]predicting train subjects:  20%|██        | 58/285 [01:41<06:28,  1.71s/it]predicting train subjects:  21%|██        | 59/285 [01:43<06:39,  1.77s/it]predicting train subjects:  21%|██        | 60/285 [01:45<06:50,  1.82s/it]predicting train subjects:  21%|██▏       | 61/285 [01:46<06:31,  1.75s/it]predicting train subjects:  22%|██▏       | 62/285 [01:48<06:43,  1.81s/it]predicting train subjects:  22%|██▏       | 63/285 [01:50<06:42,  1.81s/it]predicting train subjects:  22%|██▏       | 64/285 [01:52<06:26,  1.75s/it]predicting train subjects:  23%|██▎       | 65/285 [01:54<06:26,  1.76s/it]predicting train subjects:  23%|██▎       | 66/285 [01:55<06:25,  1.76s/it]predicting train subjects:  24%|██▎       | 67/285 [01:57<06:28,  1.78s/it]predicting train subjects:  24%|██▍       | 68/285 [01:59<06:16,  1.74s/it]predicting train subjects:  24%|██▍       | 69/285 [02:01<06:17,  1.75s/it]predicting train subjects:  25%|██▍       | 70/285 [02:02<06:22,  1.78s/it]predicting train subjects:  25%|██▍       | 71/285 [02:04<06:27,  1.81s/it]predicting train subjects:  25%|██▌       | 72/285 [02:06<06:13,  1.75s/it]predicting train subjects:  26%|██▌       | 73/285 [02:08<06:11,  1.75s/it]predicting train subjects:  26%|██▌       | 74/285 [02:09<06:11,  1.76s/it]predicting train subjects:  26%|██▋       | 75/285 [02:11<06:14,  1.78s/it]predicting train subjects:  27%|██▋       | 76/285 [02:13<06:16,  1.80s/it]predicting train subjects:  27%|██▋       | 77/285 [02:15<06:08,  1.77s/it]predicting train subjects:  27%|██▋       | 78/285 [02:16<05:54,  1.71s/it]predicting train subjects:  28%|██▊       | 79/285 [02:18<05:53,  1.71s/it]predicting train subjects:  28%|██▊       | 80/285 [02:20<05:52,  1.72s/it]predicting train subjects:  28%|██▊       | 81/285 [02:21<05:41,  1.68s/it]predicting train subjects:  29%|██▉       | 82/285 [02:23<05:44,  1.70s/it]predicting train subjects:  29%|██▉       | 83/285 [02:25<05:40,  1.68s/it]predicting train subjects:  29%|██▉       | 84/285 [02:27<05:36,  1.68s/it]predicting train subjects:  30%|██▉       | 85/285 [02:28<05:41,  1.71s/it]predicting train subjects:  30%|███       | 86/285 [02:30<05:46,  1.74s/it]predicting train subjects:  31%|███       | 87/285 [02:32<05:49,  1.77s/it]predicting train subjects:  31%|███       | 88/285 [02:34<05:40,  1.73s/it]predicting train subjects:  31%|███       | 89/285 [02:35<05:39,  1.73s/it]predicting train subjects:  32%|███▏      | 90/285 [02:37<05:41,  1.75s/it]predicting train subjects:  32%|███▏      | 91/285 [02:39<05:35,  1.73s/it]predicting train subjects:  32%|███▏      | 92/285 [02:41<05:37,  1.75s/it]predicting train subjects:  33%|███▎      | 93/285 [02:42<05:30,  1.72s/it]predicting train subjects:  33%|███▎      | 94/285 [02:44<05:30,  1.73s/it]predicting train subjects:  33%|███▎      | 95/285 [02:46<05:35,  1.76s/it]predicting train subjects:  34%|███▎      | 96/285 [02:48<05:33,  1.77s/it]predicting train subjects:  34%|███▍      | 97/285 [02:49<05:35,  1.78s/it]predicting train subjects:  34%|███▍      | 98/285 [02:51<05:34,  1.79s/it]predicting train subjects:  35%|███▍      | 99/285 [02:53<05:30,  1.77s/it]predicting train subjects:  35%|███▌      | 100/285 [02:55<05:31,  1.79s/it]predicting train subjects:  35%|███▌      | 101/285 [02:56<05:20,  1.74s/it]predicting train subjects:  36%|███▌      | 102/285 [02:58<05:22,  1.76s/it]predicting train subjects:  36%|███▌      | 103/285 [03:00<05:09,  1.70s/it]predicting train subjects:  36%|███▋      | 104/285 [03:02<05:10,  1.72s/it]predicting train subjects:  37%|███▋      | 105/285 [03:03<05:16,  1.76s/it]predicting train subjects:  37%|███▋      | 106/285 [03:05<05:05,  1.71s/it]predicting train subjects:  38%|███▊      | 107/285 [03:07<05:07,  1.73s/it]predicting train subjects:  38%|███▊      | 108/285 [03:08<04:57,  1.68s/it]predicting train subjects:  38%|███▊      | 109/285 [03:10<04:58,  1.70s/it]predicting train subjects:  39%|███▊      | 110/285 [03:12<05:02,  1.73s/it]predicting train subjects:  39%|███▉      | 111/285 [03:13<04:53,  1.69s/it]predicting train subjects:  39%|███▉      | 112/285 [03:15<04:53,  1.70s/it]predicting train subjects:  40%|███▉      | 113/285 [03:17<04:57,  1.73s/it]predicting train subjects:  40%|████      | 114/285 [03:19<04:55,  1.73s/it]predicting train subjects:  40%|████      | 115/285 [03:20<04:53,  1.73s/it]predicting train subjects:  41%|████      | 116/285 [03:22<04:54,  1.74s/it]predicting train subjects:  41%|████      | 117/285 [03:24<04:44,  1.69s/it]predicting train subjects:  41%|████▏     | 118/285 [03:25<04:36,  1.66s/it]predicting train subjects:  42%|████▏     | 119/285 [03:27<04:41,  1.70s/it]predicting train subjects:  42%|████▏     | 120/285 [03:29<04:39,  1.69s/it]predicting train subjects:  42%|████▏     | 121/285 [03:30<04:31,  1.65s/it]predicting train subjects:  43%|████▎     | 122/285 [03:32<04:21,  1.61s/it]predicting train subjects:  43%|████▎     | 123/285 [03:33<04:12,  1.56s/it]predicting train subjects:  44%|████▎     | 124/285 [03:35<04:10,  1.55s/it]predicting train subjects:  44%|████▍     | 125/285 [03:36<04:02,  1.52s/it]predicting train subjects:  44%|████▍     | 126/285 [03:38<03:59,  1.51s/it]predicting train subjects:  45%|████▍     | 127/285 [03:39<03:51,  1.47s/it]predicting train subjects:  45%|████▍     | 128/285 [03:41<03:55,  1.50s/it]predicting train subjects:  45%|████▌     | 129/285 [03:42<03:51,  1.49s/it]predicting train subjects:  46%|████▌     | 130/285 [03:44<03:48,  1.47s/it]predicting train subjects:  46%|████▌     | 131/285 [03:45<03:44,  1.46s/it]predicting train subjects:  46%|████▋     | 132/285 [03:47<03:50,  1.50s/it]predicting train subjects:  47%|████▋     | 133/285 [03:48<03:45,  1.48s/it]predicting train subjects:  47%|████▋     | 134/285 [03:50<03:40,  1.46s/it]predicting train subjects:  47%|████▋     | 135/285 [03:51<03:40,  1.47s/it]predicting train subjects:  48%|████▊     | 136/285 [03:52<03:37,  1.46s/it]predicting train subjects:  48%|████▊     | 137/285 [03:54<03:45,  1.52s/it]predicting train subjects:  48%|████▊     | 138/285 [03:56<03:37,  1.48s/it]predicting train subjects:  49%|████▉     | 139/285 [03:57<03:39,  1.50s/it]predicting train subjects:  49%|████▉     | 140/285 [03:59<03:40,  1.52s/it]predicting train subjects:  49%|████▉     | 141/285 [04:00<03:32,  1.48s/it]predicting train subjects:  50%|████▉     | 142/285 [04:02<03:32,  1.49s/it]predicting train subjects:  50%|█████     | 143/285 [04:03<03:27,  1.46s/it]predicting train subjects:  51%|█████     | 144/285 [04:04<03:30,  1.50s/it]predicting train subjects:  51%|█████     | 145/285 [04:06<03:28,  1.49s/it]predicting train subjects:  51%|█████     | 146/285 [04:08<03:34,  1.54s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:09<03:26,  1.50s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:11<03:28,  1.52s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:12<03:23,  1.50s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:13<03:18,  1.47s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:15<03:21,  1.51s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:17<03:20,  1.50s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:18<03:13,  1.47s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:20<03:16,  1.50s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:21<03:13,  1.49s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:23<03:17,  1.53s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:24<03:11,  1.50s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:25<03:06,  1.47s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:27<03:06,  1.48s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:28<03:00,  1.45s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:30<03:03,  1.48s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:31<02:58,  1.45s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:33<03:00,  1.48s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:34<02:55,  1.45s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:36<02:53,  1.45s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:37<02:56,  1.48s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:39<02:57,  1.51s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:40<02:53,  1.48s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:42<02:49,  1.46s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:43<02:45,  1.44s/it]predicting train subjects:  60%|██████    | 171/285 [04:44<02:42,  1.42s/it]predicting train subjects:  60%|██████    | 172/285 [04:46<02:40,  1.42s/it]predicting train subjects:  61%|██████    | 173/285 [04:47<02:37,  1.41s/it]predicting train subjects:  61%|██████    | 174/285 [04:49<02:36,  1.41s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:50<02:40,  1.46s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:52<02:43,  1.50s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:53<02:38,  1.47s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:54<02:33,  1.43s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:56<02:31,  1.43s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:58<02:42,  1.55s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:59<02:42,  1.56s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:01<02:44,  1.60s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:02<02:37,  1.54s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:04<02:31,  1.50s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:05<02:26,  1.46s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:07<02:35,  1.57s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:09<02:41,  1.65s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:11<02:42,  1.67s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:12<02:30,  1.57s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:13<02:24,  1.52s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:15<02:25,  1.55s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:16<02:25,  1.57s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:18<02:17,  1.50s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:19<02:13,  1.47s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:21<02:09,  1.44s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:22<02:19,  1.56s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:24<02:23,  1.64s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:26<02:26,  1.68s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:27<02:15,  1.57s/it]predicting train subjects:  70%|███████   | 200/285 [05:29<02:11,  1.54s/it]predicting train subjects:  71%|███████   | 201/285 [05:31<02:16,  1.62s/it]predicting train subjects:  71%|███████   | 202/285 [05:32<02:13,  1.61s/it]predicting train subjects:  71%|███████   | 203/285 [05:34<02:13,  1.62s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:35<02:04,  1.54s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:37<02:02,  1.53s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:38<01:56,  1.47s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:40<02:01,  1.56s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:42<02:06,  1.64s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:43<02:08,  1.69s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:45<02:00,  1.60s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:46<01:54,  1.54s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:48<01:56,  1.60s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:50<01:57,  1.64s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:51<01:52,  1.58s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:53<01:54,  1.64s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:54<01:46,  1.55s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:56<01:51,  1.63s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:58<01:54,  1.71s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:00<01:55,  1.75s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:01<01:46,  1.64s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:03<01:42,  1.59s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:04<01:41,  1.61s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:06<01:35,  1.54s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:07<01:32,  1.51s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:09<01:27,  1.46s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:10<01:32,  1.57s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:12<01:36,  1.66s/it]predicting train subjects:  80%|████████  | 228/285 [06:14<01:36,  1.69s/it]predicting train subjects:  80%|████████  | 229/285 [06:16<01:34,  1.68s/it]predicting train subjects:  81%|████████  | 230/285 [06:17<01:26,  1.58s/it]predicting train subjects:  81%|████████  | 231/285 [06:18<01:22,  1.52s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:20<01:22,  1.56s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:21<01:17,  1.50s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:23<01:21,  1.59s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:25<01:16,  1.53s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:26<01:19,  1.63s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:28<01:19,  1.67s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:30<01:20,  1.71s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:32<01:17,  1.69s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:33<01:12,  1.60s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:34<01:08,  1.55s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:36<01:03,  1.48s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:37<01:00,  1.45s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:39<01:03,  1.55s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:40<00:59,  1.49s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:42<01:01,  1.57s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:44<01:02,  1.64s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:45<01:00,  1.63s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:47<00:55,  1.55s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:48<00:52,  1.50s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:50<00:49,  1.44s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:51<00:47,  1.44s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:53<00:50,  1.56s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:55<00:50,  1.64s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:56<00:48,  1.63s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:58<00:44,  1.54s/it]predicting train subjects:  90%|█████████ | 257/285 [06:59<00:42,  1.52s/it]predicting train subjects:  91%|█████████ | 258/285 [07:01<00:43,  1.60s/it]predicting train subjects:  91%|█████████ | 259/285 [07:02<00:41,  1.61s/it]predicting train subjects:  91%|█████████ | 260/285 [07:04<00:37,  1.51s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:05<00:35,  1.49s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:06<00:33,  1.44s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:08<00:31,  1.41s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:10<00:32,  1.55s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:12<00:32,  1.63s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:13<00:29,  1.53s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:14<00:26,  1.49s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:16<00:27,  1.60s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:18<00:25,  1.61s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:19<00:22,  1.52s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:20<00:20,  1.50s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:22<00:20,  1.54s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:23<00:17,  1.49s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:25<00:15,  1.44s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:27<00:15,  1.58s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:28<00:14,  1.64s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:30<00:12,  1.54s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:31<00:10,  1.51s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:33<00:09,  1.54s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:34<00:07,  1.48s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:36<00:05,  1.47s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:37<00:04,  1.45s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:39<00:03,  1.56s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:41<00:01,  1.65s/it]predicting train subjects: 100%|██████████| 285/285 [07:43<00:00,  1.70s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:29,  1.58s/it]Loading train:   1%|          | 2/285 [00:02<06:59,  1.48s/it]Loading train:   1%|          | 3/285 [00:04<06:47,  1.44s/it]Loading train:   1%|▏         | 4/285 [00:05<06:24,  1.37s/it]Loading train:   2%|▏         | 5/285 [00:06<06:38,  1.42s/it]Loading train:   2%|▏         | 6/285 [00:08<06:15,  1.35s/it]Loading train:   2%|▏         | 7/285 [00:09<06:28,  1.40s/it]Loading train:   3%|▎         | 8/285 [00:10<06:14,  1.35s/it]Loading train:   3%|▎         | 9/285 [00:12<06:36,  1.44s/it]Loading train:   4%|▎         | 10/285 [00:13<06:09,  1.35s/it]Loading train:   4%|▍         | 11/285 [00:14<05:37,  1.23s/it]Loading train:   4%|▍         | 12/285 [00:15<05:27,  1.20s/it]Loading train:   5%|▍         | 13/285 [00:16<05:07,  1.13s/it]Loading train:   5%|▍         | 14/285 [00:17<04:59,  1.11s/it]Loading train:   5%|▌         | 15/285 [00:18<05:10,  1.15s/it]Loading train:   6%|▌         | 16/285 [00:20<05:17,  1.18s/it]Loading train:   6%|▌         | 17/285 [00:21<04:59,  1.12s/it]Loading train:   6%|▋         | 18/285 [00:22<04:59,  1.12s/it]Loading train:   7%|▋         | 19/285 [00:23<04:40,  1.05s/it]Loading train:   7%|▋         | 20/285 [00:24<04:33,  1.03s/it]Loading train:   7%|▋         | 21/285 [00:25<04:37,  1.05s/it]Loading train:   8%|▊         | 22/285 [00:26<04:20,  1.01it/s]Loading train:   8%|▊         | 23/285 [00:27<04:16,  1.02it/s]Loading train:   8%|▊         | 24/285 [00:28<04:11,  1.04it/s]Loading train:   9%|▉         | 25/285 [00:29<04:19,  1.00it/s]Loading train:   9%|▉         | 26/285 [00:30<04:25,  1.03s/it]Loading train:   9%|▉         | 27/285 [00:31<04:12,  1.02it/s]Loading train:  10%|▉         | 28/285 [00:32<04:14,  1.01it/s]Loading train:  10%|█         | 29/285 [00:33<04:11,  1.02it/s]Loading train:  11%|█         | 30/285 [00:34<04:28,  1.05s/it]Loading train:  11%|█         | 31/285 [00:35<04:42,  1.11s/it]Loading train:  11%|█         | 32/285 [00:36<04:28,  1.06s/it]Loading train:  12%|█▏        | 33/285 [00:37<04:35,  1.09s/it]Loading train:  12%|█▏        | 34/285 [00:38<04:24,  1.05s/it]Loading train:  12%|█▏        | 35/285 [00:39<04:24,  1.06s/it]Loading train:  13%|█▎        | 36/285 [00:40<04:10,  1.01s/it]Loading train:  13%|█▎        | 37/285 [00:41<04:07,  1.00it/s]Loading train:  13%|█▎        | 38/285 [00:42<04:19,  1.05s/it]Loading train:  14%|█▎        | 39/285 [00:43<04:00,  1.02it/s]Loading train:  14%|█▍        | 40/285 [00:44<04:00,  1.02it/s]Loading train:  14%|█▍        | 41/285 [00:45<03:53,  1.04it/s]Loading train:  15%|█▍        | 42/285 [00:46<03:42,  1.09it/s]Loading train:  15%|█▌        | 43/285 [00:47<03:42,  1.09it/s]Loading train:  15%|█▌        | 44/285 [00:48<03:56,  1.02it/s]Loading train:  16%|█▌        | 45/285 [00:49<03:56,  1.01it/s]Loading train:  16%|█▌        | 46/285 [00:50<04:13,  1.06s/it]Loading train:  16%|█▋        | 47/285 [00:51<04:06,  1.03s/it]Loading train:  17%|█▋        | 48/285 [00:52<04:03,  1.03s/it]Loading train:  17%|█▋        | 49/285 [00:53<04:11,  1.06s/it]Loading train:  18%|█▊        | 50/285 [00:54<04:04,  1.04s/it]Loading train:  18%|█▊        | 51/285 [00:55<04:01,  1.03s/it]Loading train:  18%|█▊        | 52/285 [00:56<03:46,  1.03it/s]Loading train:  19%|█▊        | 53/285 [00:57<03:46,  1.03it/s]Loading train:  19%|█▉        | 54/285 [00:58<03:55,  1.02s/it]Loading train:  19%|█▉        | 55/285 [00:59<03:40,  1.04it/s]Loading train:  20%|█▉        | 56/285 [01:00<03:33,  1.07it/s]Loading train:  20%|██        | 57/285 [01:01<03:27,  1.10it/s]Loading train:  20%|██        | 58/285 [01:02<03:26,  1.10it/s]Loading train:  21%|██        | 59/285 [01:03<03:38,  1.03it/s]Loading train:  21%|██        | 60/285 [01:04<03:46,  1.01s/it]Loading train:  21%|██▏       | 61/285 [01:05<03:41,  1.01it/s]Loading train:  22%|██▏       | 62/285 [01:06<03:38,  1.02it/s]Loading train:  22%|██▏       | 63/285 [01:07<03:36,  1.03it/s]Loading train:  22%|██▏       | 64/285 [01:08<03:59,  1.08s/it]Loading train:  23%|██▎       | 65/285 [01:09<04:27,  1.22s/it]Loading train:  23%|██▎       | 66/285 [01:11<04:34,  1.25s/it]Loading train:  24%|██▎       | 67/285 [01:12<04:17,  1.18s/it]Loading train:  24%|██▍       | 68/285 [01:13<03:59,  1.10s/it]Loading train:  24%|██▍       | 69/285 [01:14<03:47,  1.05s/it]Loading train:  25%|██▍       | 70/285 [01:15<03:44,  1.04s/it]Loading train:  25%|██▍       | 71/285 [01:16<03:37,  1.02s/it]Loading train:  25%|██▌       | 72/285 [01:17<03:26,  1.03it/s]Loading train:  26%|██▌       | 73/285 [01:17<03:22,  1.05it/s]Loading train:  26%|██▌       | 74/285 [01:18<03:25,  1.03it/s]Loading train:  26%|██▋       | 75/285 [01:20<03:32,  1.01s/it]Loading train:  27%|██▋       | 76/285 [01:21<03:28,  1.00it/s]Loading train:  27%|██▋       | 77/285 [01:21<03:24,  1.02it/s]Loading train:  27%|██▋       | 78/285 [01:23<03:32,  1.02s/it]Loading train:  28%|██▊       | 79/285 [01:24<03:40,  1.07s/it]Loading train:  28%|██▊       | 80/285 [01:25<03:35,  1.05s/it]Loading train:  28%|██▊       | 81/285 [01:26<03:33,  1.05s/it]Loading train:  29%|██▉       | 82/285 [01:27<03:24,  1.01s/it]Loading train:  29%|██▉       | 83/285 [01:28<03:12,  1.05it/s]Loading train:  29%|██▉       | 84/285 [01:28<03:07,  1.07it/s]Loading train:  30%|██▉       | 85/285 [01:29<03:09,  1.05it/s]Loading train:  30%|███       | 86/285 [01:30<03:10,  1.04it/s]Loading train:  31%|███       | 87/285 [01:31<03:10,  1.04it/s]Loading train:  31%|███       | 88/285 [01:32<03:01,  1.08it/s]Loading train:  31%|███       | 89/285 [01:33<03:09,  1.03it/s]Loading train:  32%|███▏      | 90/285 [01:34<03:13,  1.01it/s]Loading train:  32%|███▏      | 91/285 [01:35<03:07,  1.03it/s]Loading train:  32%|███▏      | 92/285 [01:36<03:06,  1.03it/s]Loading train:  33%|███▎      | 93/285 [01:37<02:59,  1.07it/s]Loading train:  33%|███▎      | 94/285 [01:38<02:59,  1.07it/s]Loading train:  33%|███▎      | 95/285 [01:39<02:57,  1.07it/s]Loading train:  34%|███▎      | 96/285 [01:40<03:03,  1.03it/s]Loading train:  34%|███▍      | 97/285 [01:41<03:08,  1.00s/it]Loading train:  34%|███▍      | 98/285 [01:42<03:07,  1.00s/it]Loading train:  35%|███▍      | 99/285 [01:43<03:01,  1.02it/s]Loading train:  35%|███▌      | 100/285 [01:44<03:06,  1.01s/it]Loading train:  35%|███▌      | 101/285 [01:45<03:09,  1.03s/it]Loading train:  36%|███▌      | 102/285 [01:46<03:08,  1.03s/it]Loading train:  36%|███▌      | 103/285 [01:47<03:04,  1.02s/it]Loading train:  36%|███▋      | 104/285 [01:48<03:08,  1.04s/it]Loading train:  37%|███▋      | 105/285 [01:49<03:12,  1.07s/it]Loading train:  37%|███▋      | 106/285 [01:50<03:12,  1.08s/it]Loading train:  38%|███▊      | 107/285 [01:52<03:11,  1.07s/it]Loading train:  38%|███▊      | 108/285 [01:53<03:11,  1.08s/it]Loading train:  38%|███▊      | 109/285 [01:54<03:10,  1.08s/it]Loading train:  39%|███▊      | 110/285 [01:55<03:09,  1.09s/it]Loading train:  39%|███▉      | 111/285 [01:56<03:06,  1.07s/it]Loading train:  39%|███▉      | 112/285 [01:57<03:02,  1.05s/it]Loading train:  40%|███▉      | 113/285 [01:58<03:09,  1.10s/it]Loading train:  40%|████      | 114/285 [01:59<03:03,  1.08s/it]Loading train:  40%|████      | 115/285 [02:00<03:02,  1.07s/it]Loading train:  41%|████      | 116/285 [02:01<02:55,  1.04s/it]Loading train:  41%|████      | 117/285 [02:02<02:54,  1.04s/it]Loading train:  41%|████▏     | 118/285 [02:03<02:51,  1.03s/it]Loading train:  42%|████▏     | 119/285 [02:04<02:53,  1.04s/it]Loading train:  42%|████▏     | 120/285 [02:05<02:49,  1.03s/it]Loading train:  42%|████▏     | 121/285 [02:07<03:11,  1.17s/it]Loading train:  43%|████▎     | 122/285 [02:08<03:13,  1.19s/it]Loading train:  43%|████▎     | 123/285 [02:09<03:13,  1.20s/it]Loading train:  44%|████▎     | 124/285 [02:10<02:57,  1.10s/it]Loading train:  44%|████▍     | 125/285 [02:11<02:46,  1.04s/it]Loading train:  44%|████▍     | 126/285 [02:12<02:40,  1.01s/it]Loading train:  45%|████▍     | 127/285 [02:13<02:35,  1.02it/s]Loading train:  45%|████▍     | 128/285 [02:14<02:39,  1.02s/it]Loading train:  45%|████▌     | 129/285 [02:15<02:32,  1.02it/s]Loading train:  46%|████▌     | 130/285 [02:16<02:24,  1.07it/s]Loading train:  46%|████▌     | 131/285 [02:16<02:17,  1.12it/s]Loading train:  46%|████▋     | 132/285 [02:17<02:16,  1.12it/s]Loading train:  47%|████▋     | 133/285 [02:18<02:13,  1.14it/s]Loading train:  47%|████▋     | 134/285 [02:19<02:08,  1.18it/s]Loading train:  47%|████▋     | 135/285 [02:20<02:05,  1.20it/s]Loading train:  48%|████▊     | 136/285 [02:21<02:07,  1.17it/s]Loading train:  48%|████▊     | 137/285 [02:22<02:11,  1.12it/s]Loading train:  48%|████▊     | 138/285 [02:23<02:09,  1.13it/s]Loading train:  49%|████▉     | 139/285 [02:23<02:12,  1.11it/s]Loading train:  49%|████▉     | 140/285 [02:25<02:18,  1.05it/s]Loading train:  49%|████▉     | 141/285 [02:25<02:15,  1.06it/s]Loading train:  50%|████▉     | 142/285 [02:26<02:08,  1.11it/s]Loading train:  50%|█████     | 143/285 [02:27<02:05,  1.13it/s]Loading train:  51%|█████     | 144/285 [02:28<02:07,  1.11it/s]Loading train:  51%|█████     | 145/285 [02:29<02:08,  1.09it/s]Loading train:  51%|█████     | 146/285 [02:30<02:04,  1.11it/s]Loading train:  52%|█████▏    | 147/285 [02:31<02:06,  1.09it/s]Loading train:  52%|█████▏    | 148/285 [02:32<02:04,  1.10it/s]Loading train:  52%|█████▏    | 149/285 [02:33<02:02,  1.11it/s]Loading train:  53%|█████▎    | 150/285 [02:33<02:00,  1.12it/s]Loading train:  53%|█████▎    | 151/285 [02:34<02:02,  1.09it/s]Loading train:  53%|█████▎    | 152/285 [02:35<01:59,  1.12it/s]Loading train:  54%|█████▎    | 153/285 [02:36<01:54,  1.16it/s]Loading train:  54%|█████▍    | 154/285 [02:37<01:57,  1.11it/s]Loading train:  54%|█████▍    | 155/285 [02:38<01:55,  1.13it/s]Loading train:  55%|█████▍    | 156/285 [02:39<01:57,  1.10it/s]Loading train:  55%|█████▌    | 157/285 [02:40<01:50,  1.15it/s]Loading train:  55%|█████▌    | 158/285 [02:40<01:48,  1.17it/s]Loading train:  56%|█████▌    | 159/285 [02:41<01:46,  1.18it/s]Loading train:  56%|█████▌    | 160/285 [02:42<01:46,  1.17it/s]Loading train:  56%|█████▋    | 161/285 [02:43<01:48,  1.14it/s]Loading train:  57%|█████▋    | 162/285 [02:44<01:46,  1.16it/s]Loading train:  57%|█████▋    | 163/285 [02:45<01:46,  1.15it/s]Loading train:  58%|█████▊    | 164/285 [02:46<01:43,  1.16it/s]Loading train:  58%|█████▊    | 165/285 [02:46<01:40,  1.20it/s]Loading train:  58%|█████▊    | 166/285 [02:47<01:42,  1.16it/s]Loading train:  59%|█████▊    | 167/285 [02:48<01:43,  1.14it/s]Loading train:  59%|█████▉    | 168/285 [02:49<01:42,  1.14it/s]Loading train:  59%|█████▉    | 169/285 [02:50<01:43,  1.12it/s]Loading train:  60%|█████▉    | 170/285 [02:51<01:45,  1.09it/s]Loading train:  60%|██████    | 171/285 [02:52<01:41,  1.13it/s]Loading train:  60%|██████    | 172/285 [02:53<01:41,  1.11it/s]Loading train:  61%|██████    | 173/285 [02:54<01:41,  1.10it/s]Loading train:  61%|██████    | 174/285 [02:55<01:38,  1.12it/s]Loading train:  61%|██████▏   | 175/285 [02:55<01:37,  1.13it/s]Loading train:  62%|██████▏   | 176/285 [02:56<01:39,  1.09it/s]Loading train:  62%|██████▏   | 177/285 [02:57<01:36,  1.12it/s]Loading train:  62%|██████▏   | 178/285 [02:58<01:34,  1.13it/s]Loading train:  63%|██████▎   | 179/285 [02:59<01:34,  1.12it/s]Loading train:  63%|██████▎   | 180/285 [03:00<01:39,  1.05it/s]Loading train:  64%|██████▎   | 181/285 [03:01<01:39,  1.04it/s]Loading train:  64%|██████▍   | 182/285 [03:02<01:35,  1.07it/s]Loading train:  64%|██████▍   | 183/285 [03:03<01:29,  1.13it/s]Loading train:  65%|██████▍   | 184/285 [03:04<01:28,  1.14it/s]Loading train:  65%|██████▍   | 185/285 [03:04<01:27,  1.14it/s]Loading train:  65%|██████▌   | 186/285 [03:05<01:30,  1.09it/s]Loading train:  66%|██████▌   | 187/285 [03:07<01:34,  1.04it/s]Loading train:  66%|██████▌   | 188/285 [03:08<01:37,  1.00s/it]Loading train:  66%|██████▋   | 189/285 [03:09<01:34,  1.02it/s]Loading train:  67%|██████▋   | 190/285 [03:09<01:30,  1.05it/s]Loading train:  67%|██████▋   | 191/285 [03:10<01:30,  1.04it/s]Loading train:  67%|██████▋   | 192/285 [03:11<01:27,  1.06it/s]Loading train:  68%|██████▊   | 193/285 [03:12<01:23,  1.10it/s]Loading train:  68%|██████▊   | 194/285 [03:13<01:18,  1.16it/s]Loading train:  68%|██████▊   | 195/285 [03:14<01:15,  1.18it/s]Loading train:  69%|██████▉   | 196/285 [03:15<01:19,  1.11it/s]Loading train:  69%|██████▉   | 197/285 [03:16<01:24,  1.04it/s]Loading train:  69%|██████▉   | 198/285 [03:17<01:26,  1.01it/s]Loading train:  70%|██████▉   | 199/285 [03:18<01:20,  1.07it/s]Loading train:  70%|███████   | 200/285 [03:19<01:20,  1.06it/s]Loading train:  71%|███████   | 201/285 [03:20<01:23,  1.01it/s]Loading train:  71%|███████   | 202/285 [03:21<01:19,  1.05it/s]Loading train:  71%|███████   | 203/285 [03:22<01:18,  1.04it/s]Loading train:  72%|███████▏  | 204/285 [03:22<01:14,  1.09it/s]Loading train:  72%|███████▏  | 205/285 [03:23<01:11,  1.11it/s]Loading train:  72%|███████▏  | 206/285 [03:24<01:11,  1.11it/s]Loading train:  73%|███████▎  | 207/285 [03:25<01:12,  1.08it/s]Loading train:  73%|███████▎  | 208/285 [03:26<01:14,  1.04it/s]Loading train:  73%|███████▎  | 209/285 [03:27<01:14,  1.02it/s]Loading train:  74%|███████▎  | 210/285 [03:28<01:11,  1.05it/s]Loading train:  74%|███████▍  | 211/285 [03:29<01:08,  1.07it/s]Loading train:  74%|███████▍  | 212/285 [03:30<01:10,  1.04it/s]Loading train:  75%|███████▍  | 213/285 [03:31<01:08,  1.04it/s]Loading train:  75%|███████▌  | 214/285 [03:32<01:08,  1.04it/s]Loading train:  75%|███████▌  | 215/285 [03:33<01:07,  1.04it/s]Loading train:  76%|███████▌  | 216/285 [03:34<01:05,  1.06it/s]Loading train:  76%|███████▌  | 217/285 [03:35<01:05,  1.04it/s]Loading train:  76%|███████▋  | 218/285 [03:36<01:06,  1.01it/s]Loading train:  77%|███████▋  | 219/285 [03:37<01:06,  1.01s/it]Loading train:  77%|███████▋  | 220/285 [03:38<01:04,  1.01it/s]Loading train:  78%|███████▊  | 221/285 [03:39<01:00,  1.06it/s]Loading train:  78%|███████▊  | 222/285 [03:40<00:59,  1.07it/s]Loading train:  78%|███████▊  | 223/285 [03:40<00:54,  1.13it/s]Loading train:  79%|███████▊  | 224/285 [03:41<00:53,  1.15it/s]Loading train:  79%|███████▉  | 225/285 [03:42<00:53,  1.12it/s]Loading train:  79%|███████▉  | 226/285 [03:43<00:54,  1.09it/s]Loading train:  80%|███████▉  | 227/285 [03:44<00:54,  1.07it/s]Loading train:  80%|████████  | 228/285 [03:45<00:56,  1.00it/s]Loading train:  80%|████████  | 229/285 [03:46<00:55,  1.00it/s]Loading train:  81%|████████  | 230/285 [03:47<00:51,  1.08it/s]Loading train:  81%|████████  | 231/285 [03:48<00:46,  1.15it/s]Loading train:  81%|████████▏ | 232/285 [03:49<00:45,  1.17it/s]Loading train:  82%|████████▏ | 233/285 [03:50<00:45,  1.14it/s]Loading train:  82%|████████▏ | 234/285 [03:51<00:45,  1.11it/s]Loading train:  82%|████████▏ | 235/285 [03:51<00:44,  1.12it/s]Loading train:  83%|████████▎ | 236/285 [03:52<00:46,  1.06it/s]Loading train:  83%|████████▎ | 237/285 [03:53<00:45,  1.06it/s]Loading train:  84%|████████▎ | 238/285 [03:54<00:44,  1.04it/s]Loading train:  84%|████████▍ | 239/285 [03:55<00:43,  1.07it/s]Loading train:  84%|████████▍ | 240/285 [03:56<00:39,  1.13it/s]Loading train:  85%|████████▍ | 241/285 [03:57<00:37,  1.18it/s]Loading train:  85%|████████▍ | 242/285 [03:58<00:34,  1.24it/s]Loading train:  85%|████████▌ | 243/285 [03:58<00:33,  1.26it/s]Loading train:  86%|████████▌ | 244/285 [03:59<00:34,  1.18it/s]Loading train:  86%|████████▌ | 245/285 [04:00<00:32,  1.23it/s]Loading train:  86%|████████▋ | 246/285 [04:01<00:32,  1.20it/s]Loading train:  87%|████████▋ | 247/285 [04:02<00:33,  1.12it/s]Loading train:  87%|████████▋ | 248/285 [04:03<00:32,  1.14it/s]Loading train:  87%|████████▋ | 249/285 [04:04<00:30,  1.18it/s]Loading train:  88%|████████▊ | 250/285 [04:04<00:29,  1.19it/s]Loading train:  88%|████████▊ | 251/285 [04:05<00:28,  1.21it/s]Loading train:  88%|████████▊ | 252/285 [04:06<00:26,  1.24it/s]Loading train:  89%|████████▉ | 253/285 [04:07<00:27,  1.17it/s]Loading train:  89%|████████▉ | 254/285 [04:08<00:27,  1.13it/s]Loading train:  89%|████████▉ | 255/285 [04:09<00:26,  1.14it/s]Loading train:  90%|████████▉ | 256/285 [04:09<00:24,  1.17it/s]Loading train:  90%|█████████ | 257/285 [04:10<00:23,  1.21it/s]Loading train:  91%|█████████ | 258/285 [04:11<00:22,  1.18it/s]Loading train:  91%|█████████ | 259/285 [04:12<00:22,  1.17it/s]Loading train:  91%|█████████ | 260/285 [04:13<00:20,  1.22it/s]Loading train:  92%|█████████▏| 261/285 [04:14<00:19,  1.25it/s]Loading train:  92%|█████████▏| 262/285 [04:14<00:18,  1.26it/s]Loading train:  92%|█████████▏| 263/285 [04:15<00:17,  1.29it/s]Loading train:  93%|█████████▎| 264/285 [04:16<00:17,  1.22it/s]Loading train:  93%|█████████▎| 265/285 [04:17<00:16,  1.19it/s]Loading train:  93%|█████████▎| 266/285 [04:18<00:15,  1.24it/s]Loading train:  94%|█████████▎| 267/285 [04:18<00:14,  1.27it/s]Loading train:  94%|█████████▍| 268/285 [04:19<00:14,  1.20it/s]Loading train:  94%|█████████▍| 269/285 [04:20<00:13,  1.17it/s]Loading train:  95%|█████████▍| 270/285 [04:21<00:12,  1.21it/s]Loading train:  95%|█████████▌| 271/285 [04:22<00:11,  1.23it/s]Loading train:  95%|█████████▌| 272/285 [04:23<00:10,  1.22it/s]Loading train:  96%|█████████▌| 273/285 [04:23<00:09,  1.25it/s]Loading train:  96%|█████████▌| 274/285 [04:24<00:08,  1.25it/s]Loading train:  96%|█████████▋| 275/285 [04:25<00:08,  1.14it/s]Loading train:  97%|█████████▋| 276/285 [04:26<00:08,  1.07it/s]Loading train:  97%|█████████▋| 277/285 [04:27<00:07,  1.10it/s]Loading train:  98%|█████████▊| 278/285 [04:28<00:05,  1.17it/s]Loading train:  98%|█████████▊| 279/285 [04:29<00:05,  1.14it/s]Loading train:  98%|█████████▊| 280/285 [04:29<00:04,  1.18it/s]Loading train:  99%|█████████▊| 281/285 [04:30<00:03,  1.23it/s]Loading train:  99%|█████████▉| 282/285 [04:31<00:02,  1.19it/s]Loading train:  99%|█████████▉| 283/285 [04:32<00:01,  1.14it/s]Loading train: 100%|█████████▉| 284/285 [04:33<00:00,  1.06it/s]Loading train: 100%|██████████| 285/285 [04:34<00:00,  1.01it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   3%|▎         | 9/285 [00:00<00:03, 88.86it/s]concatenating: train:   9%|▉         | 25/285 [00:00<00:02, 102.14it/s]concatenating: train:  17%|█▋        | 49/285 [00:00<00:01, 122.65it/s]concatenating: train:  26%|██▋       | 75/285 [00:00<00:01, 145.63it/s]concatenating: train:  33%|███▎      | 95/285 [00:00<00:01, 156.93it/s]concatenating: train:  42%|████▏     | 119/285 [00:00<00:00, 173.93it/s]concatenating: train:  53%|█████▎    | 151/285 [00:00<00:00, 200.81it/s]concatenating: train:  63%|██████▎   | 180/285 [00:00<00:00, 221.05it/s]concatenating: train:  74%|███████▎  | 210/285 [00:00<00:00, 239.97it/s]concatenating: train:  84%|████████▎ | 238/285 [00:01<00:00, 250.53it/s]concatenating: train:  94%|█████████▍| 268/285 [00:01<00:00, 262.32it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 245.52it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.39s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.34s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.26s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 36.75it/s]2019-07-11 08:04:57.452479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 08:04:57.452602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 08:04:57.452620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 08:04:57.452629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 08:04:57.453077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.69it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.59it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.26it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.77it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  6.03it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  6.85it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.03it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.79it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  8.13it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.80it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.45it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  8.57it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  8.87it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.15it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.78it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.08it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.16it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.14it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.07it/s]
Epoch 00052: val_mDice did not improve from 0.58468
Restoring model weights from the end of the best epoch
Epoch 00052: early stopping
{'val_loss': [3.585863567533947, 2.636133239382789, 1.5237976482936315, 1.3515537579854329, 1.1277684030078707, 0.9992417153858003, 1.0401866776602608, 0.9412038212730771, 1.0126337664467948, 1.015525602159046, 1.1074361687614804, 0.9289802199318296, 0.9219116426649547, 0.9015509230749947, 0.9029840741838727, 0.9089792569478353, 0.9921427000136602, 0.9456008502415248, 0.9384880406515939, 0.8823051963533673, 0.8993686778204781, 0.8852307399113973, 0.894404445375715, 0.9200081484658378, 0.90447807879675, 0.8594320728665307, 0.8596036604472569, 0.8401232617241996, 0.8599138997849964, 0.8622189249311175, 0.9532739207858131, 0.8371437447411674, 0.8974801018124535, 0.8753947416941324, 0.8196872075398763, 0.846221543493725, 0.825171635264442, 0.8408504440670922, 0.8527440173285348, 0.813820651599339, 0.8268418539138067, 0.9055259681883312, 0.7904902412777856, 0.825465474809919, 0.8005793662298293, 0.7673321848823911, 0.8564707665216356, 0.7997638157435826, 0.83500075340271, 0.8216345877874465, 0.8198113441467285, 0.8324211892627534], 'val_acc': [0.909326916649228, 0.9115407779103234, 0.9178388289042881, 0.9227243321282523, 0.9352907368115017, 0.9399015789940244, 0.930366283371335, 0.9447046660241627, 0.9419917606172108, 0.9416781181380862, 0.9347160912695385, 0.9446131246430534, 0.9450503502573285, 0.9446382976713634, 0.9409661378179278, 0.9430837943440392, 0.9350320725213914, 0.9447825040136065, 0.9424977160635448, 0.9465521801085699, 0.9432234707332793, 0.9443063225064959, 0.945206031912849, 0.9433424870173136, 0.942607601483663, 0.941025645959945, 0.941648332845597, 0.9458081637110028, 0.9430860678354899, 0.9443612552824474, 0.923099813007173, 0.9450549596831912, 0.9427426854769388, 0.9407554666201273, 0.9456227308227902, 0.9443292248816717, 0.9441140237308684, 0.9429647667067391, 0.9377335026150658, 0.9411034953026545, 0.9454075268336705, 0.9441048673221043, 0.9429418331100827, 0.9451991631871178, 0.945096146492731, 0.9449336301712763, 0.94242905435108, 0.944901534489223, 0.9427083134651184, 0.9409523719833011, 0.9422619200888134, 0.9445856241952806], 'val_mDice': [0.15310824059304737, 0.19541148247264487, 0.35514320096089724, 0.3859537582667101, 0.4894626239935557, 0.5559761229725111, 0.5514844943370137, 0.5632293383990016, 0.5297322647557372, 0.5213494762068703, 0.47516065037676264, 0.5846792386756057, 0.5734458833578087, 0.5692504651489712, 0.5779705015676362, 0.5691054449194953, 0.5250815789969194, 0.545897092138018, 0.5328717029520443, 0.5673850480289686, 0.5728447536627451, 0.5712532684916541, 0.5514562733116604, 0.5520633608102798, 0.572230305700075, 0.5620822665237245, 0.5735256152138823, 0.5768867443714824, 0.5718676625263124, 0.5770625273386637, 0.5242089499675092, 0.5747675618955067, 0.5314657844248272, 0.5488689497468018, 0.5777864198954332, 0.5663659771283468, 0.5728275495625678, 0.5511664542413893, 0.5712987099375043, 0.5772632513017881, 0.5560929227088179, 0.5500607838233312, 0.5596407839939708, 0.5511912687548569, 0.5581001531155336, 0.573217029372851, 0.5185290010912078, 0.5520558105338187, 0.5519535241737252, 0.5541612772004945, 0.5348458595219112, 0.5589941191886153], 'loss': [2.7232901368362725, 0.9311193409213354, 0.6486033885746028, 0.5565000212741813, 0.505845314279236, 0.4817896175239733, 0.4629322806258686, 0.4454680777811834, 0.4338864695366256, 0.42607614642764324, 0.4147904776690299, 0.40680733512126804, 0.40192151813119137, 0.395162447209714, 0.3938198592452753, 0.38701735234384665, 0.3843726289394115, 0.37883213574380253, 0.3760257602795163, 0.3711883994754808, 0.36522684580838033, 0.3613976766797925, 0.36131761293892045, 0.35896212358407625, 0.35768318447460895, 0.3563214735371634, 0.3497077461518096, 0.3496667009133559, 0.3479758979889476, 0.3467476739114894, 0.34242500436312895, 0.3410034936207991, 0.3399352613662005, 0.33617486682773806, 0.3364119070250105, 0.33605186909247575, 0.33299107614890994, 0.3308708340774181, 0.32891751005053405, 0.3280764173422564, 0.3279880569094703, 0.3262445768260625, 0.32316878291483625, 0.3228014172996564, 0.3212077176212368, 0.3211594602265109, 0.32024542106836545, 0.31946501331175825, 0.31816386491066, 0.31509656656884677, 0.31510958053690175, 0.31473908805654116], 'acc': [0.6564277976418084, 0.8872061592893195, 0.8993032241524909, 0.9095945545582268, 0.9169210018577524, 0.9218219128306808, 0.9262044954580311, 0.9288565354561424, 0.9303652530854576, 0.931011631133953, 0.93221438666495, 0.9331503906805253, 0.933591003911629, 0.9340507095664917, 0.9346327186894826, 0.9351645377368534, 0.9351951899683864, 0.9358726419050247, 0.9361814084897869, 0.9366745971888735, 0.9372092402002038, 0.9375338084968455, 0.9375928034436756, 0.9379399179699841, 0.9381000361209065, 0.9380643983463665, 0.938519492012838, 0.9387156426941059, 0.9386807006403318, 0.9390841867391926, 0.939345866861154, 0.9394399261736608, 0.9396122758251085, 0.9399977394880439, 0.9399855502634947, 0.9400121742805259, 0.9401769261151489, 0.9403634611089864, 0.9406387841446404, 0.9407383340596004, 0.9406746367464089, 0.9408654311338969, 0.9411419636026063, 0.9411273635097935, 0.9412856544859036, 0.9413761141696876, 0.9413867717260843, 0.9415091462900167, 0.9415673032210515, 0.9419005204193942, 0.9417538154394107, 0.9418429804487175], 'mDice': [0.11869715822525559, 0.399507544128932, 0.5080925738717266, 0.5578130289771457, 0.5876531491556309, 0.602302485080452, 0.6141884151349896, 0.6250122979539011, 0.6325911691199384, 0.6375817172394476, 0.6452979679187645, 0.6504249965981387, 0.6538421517280754, 0.6583016865258504, 0.6595852072813021, 0.6638935845275593, 0.6657099546277503, 0.6695333323498004, 0.6717205861181521, 0.6749546659551238, 0.6790517042752794, 0.6817512240096372, 0.6818169066619616, 0.6835866355932768, 0.6843514533453832, 0.6853181288057103, 0.6900029612892921, 0.6900971715037065, 0.6911605012446717, 0.6922631821973443, 0.6952876391750047, 0.6963025873650102, 0.6970959347476154, 0.6997936783623828, 0.6996116298504916, 0.6998205865213171, 0.7020698055403757, 0.703811052069858, 0.7050484926203714, 0.7057636437536504, 0.7057547061365649, 0.70704340623343, 0.7092872451260436, 0.7096037496967952, 0.7106869241762465, 0.7109670132967417, 0.7114613171783927, 0.7121624697236075, 0.7129652222755996, 0.7152998760207577, 0.7151945672652062, 0.7155540117023307]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 26, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 13, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 26, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 40)   21640       dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 40)   160         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 40)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 52, 40)   0           activation_11[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 40)   14440       dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 52, 40)   160         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 52, 40)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 52, 40)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 100)  0           dropout_5[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 52, 13)   1313        concatenate_7[0][0]              
==================================================================================================
Total params: 260,753
Trainable params: 85,913
Non-trainable params: 174,840
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 21s - loss: 1.7425 - acc: 0.7770 - mDice: 0.2499 - val_loss: 0.7907 - val_acc: 0.9292 - val_mDice: 0.4398

Epoch 00001: val_mDice improved from -inf to 0.43979, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 16s - loss: 0.6370 - acc: 0.9202 - mDice: 0.5136 - val_loss: 0.7074 - val_acc: 0.9377 - val_mDice: 0.4954

Epoch 00002: val_mDice improved from 0.43979 to 0.49540, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 15s - loss: 0.5004 - acc: 0.9349 - mDice: 0.5916 - val_loss: 0.6054 - val_acc: 0.9461 - val_mDice: 0.5462

Epoch 00003: val_mDice improved from 0.49540 to 0.54624, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 15s - loss: 0.4374 - acc: 0.9413 - mDice: 0.6316 - val_loss: 0.5763 - val_acc: 0.9471 - val_mDice: 0.5600

Epoch 00004: val_mDice improved from 0.54624 to 0.56005, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 16s - loss: 0.3980 - acc: 0.9447 - mDice: 0.6572 - val_loss: 0.4766 - val_acc: 0.9521 - val_mDice: 0.6094

Epoch 00005: val_mDice improved from 0.56005 to 0.60940, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 15s - loss: 0.3779 - acc: 0.9464 - mDice: 0.6710 - val_loss: 0.4673 - val_acc: 0.9521 - val_mDice: 0.6153

Epoch 00006: val_mDice improved from 0.60940 to 0.61531, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 15s - loss: 0.3575 - acc: 0.9480 - mDice: 0.6850 - val_loss: 0.4672 - val_acc: 0.9532 - val_mDice: 0.6175

Epoch 00007: val_mDice improved from 0.61531 to 0.61748, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 16s - loss: 0.3480 - acc: 0.9487 - mDice: 0.6919 - val_loss: 0.4696 - val_acc: 0.9527 - val_mDice: 0.6203

Epoch 00008: val_mDice improved from 0.61748 to 0.62028, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 15s - loss: 0.3356 - acc: 0.9497 - mDice: 0.7008 - val_loss: 0.4545 - val_acc: 0.9537 - val_mDice: 0.6242

Epoch 00009: val_mDice improved from 0.62028 to 0.62418, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 15s - loss: 0.3275 - acc: 0.9502 - mDice: 0.7066 - val_loss: 0.4830 - val_acc: 0.9530 - val_mDice: 0.6123

Epoch 00010: val_mDice did not improve from 0.62418
Epoch 11/300
 - 15s - loss: 0.3207 - acc: 0.9507 - mDice: 0.7116 - val_loss: 0.4457 - val_acc: 0.9511 - val_mDice: 0.6290

Epoch 00011: val_mDice improved from 0.62418 to 0.62905, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 15s - loss: 0.3146 - acc: 0.9513 - mDice: 0.7162 - val_loss: 0.4586 - val_acc: 0.9541 - val_mDice: 0.6243

Epoch 00012: val_mDice did not improve from 0.62905
Epoch 13/300
 - 16s - loss: 0.3067 - acc: 0.9518 - mDice: 0.7221 - val_loss: 0.4600 - val_acc: 0.9540 - val_mDice: 0.6247

Epoch 00013: val_mDice did not improve from 0.62905
Epoch 14/300
 - 15s - loss: 0.3030 - acc: 0.9521 - mDice: 0.7249 - val_loss: 0.4579 - val_acc: 0.9547 - val_mDice: 0.6234

Epoch 00014: val_mDice did not improve from 0.62905
Epoch 15/300
 - 15s - loss: 0.2982 - acc: 0.9524 - mDice: 0.7285 - val_loss: 0.4802 - val_acc: 0.9523 - val_mDice: 0.6122

Epoch 00015: val_mDice did not improve from 0.62905
Epoch 16/300
 - 15s - loss: 0.2932 - acc: 0.9528 - mDice: 0.7321 - val_loss: 0.5444 - val_acc: 0.9520 - val_mDice: 0.5973

Epoch 00016: val_mDice did not improve from 0.62905
Epoch 17/300
 - 16s - loss: 0.2904 - acc: 0.9530 - mDice: 0.7343 - val_loss: 0.4792 - val_acc: 0.9529 - val_mDice: 0.6110

Epoch 00017: val_mDice did not improve from 0.62905
Epoch 18/300
 - 15s - loss: 0.2849 - acc: 0.9533 - mDice: 0.7386 - val_loss: 0.5062 - val_acc: 0.9518 - val_mDice: 0.6022

Epoch 00018: val_mDice did not improve from 0.62905
Epoch 19/300
 - 15s - loss: 0.2848 - acc: 0.9534 - mDice: 0.7388 - val_loss: 0.4894 - val_acc: 0.9532 - val_mDice: 0.6082

Epoch 00019: val_mDice did not improve from 0.62905
Epoch 20/300
 - 15s - loss: 0.2795 - acc: 0.9538 - mDice: 0.7427 - val_loss: 0.5631 - val_acc: 0.9514 - val_mDice: 0.5897

Epoch 00020: val_mDice did not improve from 0.62905
Epoch 21/300
 - 15s - loss: 0.2756 - acc: 0.9541 - mDice: 0.7457 - val_loss: 0.4843 - val_acc: 0.9547 - val_mDice: 0.6152

Epoch 00021: val_mDice did not improve from 0.62905
Epoch 22/300
 - 15s - loss: 0.2728 - acc: 0.9543 - mDice: 0.7479 - val_loss: 0.4795 - val_acc: 0.9550 - val_mDice: 0.6161

Epoch 00022: val_mDice did not improve from 0.62905
Epoch 23/300
 - 15s - loss: 0.2712 - acc: 0.9544 - mDice: 0.7492 - val_loss: 0.4714 - val_acc: 0.9535 - val_mDice: 0.6170

Epoch 00023: val_mDice did not improve from 0.62905
Epoch 24/300
 - 16s - loss: 0.2682 - acc: 0.9547 - mDice: 0.7516 - val_loss: 0.4780 - val_acc: 0.9541 - val_mDice: 0.6145

Epoch 00024: val_mDice did not improve from 0.62905
Epoch 25/300
 - 16s - loss: 0.2667 - acc: 0.9547 - mDice: 0.7527 - val_loss: 0.4773 - val_acc: 0.9536 - val_mDice: 0.6172

Epoch 00025: val_mDice did not improve from 0.62905
Epoch 26/300
 - 16s - loss: 0.2655 - acc: 0.9548 - mDice: 0.7536 - val_loss: 0.4762 - val_acc: 0.9548 - val_mDice: 0.6174

Epoch 00026: val_mDice did not improve from 0.62905
Epoch 27/300
 - 16s - loss: 0.2648 - acc: 0.9549 - mDice: 0.7543 - val_loss: 0.4873 - val_acc: 0.9533 - val_mDice: 0.6108

Epoch 00027: val_mDice did not improve from 0.62905
Epoch 28/300
 - 16s - loss: 0.2613 - acc: 0.9552 - mDice: 0.7571 - val_loss: 0.4762 - val_acc: 0.9532 - val_mDice: 0.6143

Epoch 00028: val_mDice did not improve from 0.62905
Epoch 29/300
 - 16s - loss: 0.2597 - acc: 0.9552 - mDice: 0.7583 - val_loss: 0.4815 - val_acc: 0.9533 - val_mDice: 0.6109

Epoch 00029: val_mDice did not improve from 0.62905
Epoch 30/300
 - 16s - loss: 0.2587 - acc: 0.9554 - mDice: 0.7592 - val_loss: 0.4583 - val_acc: 0.9541 - val_mDice: 0.6236

Epoch 00030: val_mDice did not improve from 0.62905
Epoch 31/300
 - 16s - loss: 0.2561 - acc: 0.9555 - mDice: 0.7611 - val_loss: 0.4595 - val_acc: 0.9537 - val_mDice: 0.6214

Epoch 00031: val_mDice did not improve from 0.62905
Epoch 32/300
 - 16s - loss: 0.2580 - acc: 0.9553 - mDice: 0.7597 - val_loss: 0.4479 - val_acc: 0.9511 - val_mDice: 0.6276

Epoch 00032: val_mDice did not improve from 0.62905
Epoch 33/300
 - 16s - loss: 0.2540 - acc: 0.9557 - mDice: 0.7628 - val_loss: 0.4730 - val_acc: 0.9544 - val_mDice: 0.6178

Epoch 00033: val_mDice did not improve from 0.62905
Epoch 34/300
 - 15s - loss: 0.2530 - acc: 0.9558 - mDice: 0.7636 - val_loss: 0.4793 - val_acc: 0.9544 - val_mDice: 0.6162

Epoch 00034: val_mDice did not improve from 0.62905
Epoch 35/300
 - 16s - loss: 0.2507 - acc: 0.9560 - mDice: 0.7654 - val_loss: 0.4566 - val_acc: 0.9554 - val_mDice: 0.6260

Epoch 00035: val_mDice did not improve from 0.62905
Epoch 36/300
 - 16s - loss: 0.2490 - acc: 0.9561 - mDice: 0.7668 - val_loss: 0.4754 - val_acc: 0.9546 - val_mDice: 0.6155

Epoch 00036: val_mDice did not improve from 0.62905
Epoch 37/300
 - 15s - loss: 0.2489 - acc: 0.9561 - mDice: 0.7669 - val_loss: 0.4639 - val_acc: 0.9522 - val_mDice: 0.6175

Epoch 00037: val_mDice did not improve from 0.62905
Epoch 38/300
 - 16s - loss: 0.2482 - acc: 0.9560 - mDice: 0.7675 - val_loss: 0.4657 - val_acc: 0.9540 - val_mDice: 0.6200

Epoch 00038: val_mDice did not improve from 0.62905
Epoch 39/300
 - 15s - loss: 0.2456 - acc: 0.9563 - mDice: 0.7696 - val_loss: 0.4531 - val_acc: 0.9546 - val_mDice: 0.6260

Epoch 00039: val_mDice did not improve from 0.62905
Epoch 40/300
 - 15s - loss: 0.2444 - acc: 0.9564 - mDice: 0.7706 - val_loss: 0.4727 - val_acc: 0.9522 - val_mDice: 0.6146

Epoch 00040: val_mDice did not improve from 0.62905
Epoch 41/300
 - 15s - loss: 0.2438 - acc: 0.9564 - mDice: 0.7711 - val_loss: 0.4990 - val_acc: 0.9543 - val_mDice: 0.6059

Epoch 00041: val_mDice did not improve from 0.62905
Epoch 42/300
 - 16s - loss: 0.2424 - acc: 0.9565 - mDice: 0.7722 - val_loss: 0.4425 - val_acc: 0.9557 - val_mDice: 0.6330

Epoch 00042: val_mDice improved from 0.62905 to 0.63303, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 43/300
 - 15s - loss: 0.2423 - acc: 0.9566 - mDice: 0.7723 - val_loss: 0.4581 - val_acc: 0.9528 - val_mDice: 0.6211

Epoch 00043: val_mDice did not improve from 0.63303
Epoch 44/300
 - 16s - loss: 0.2396 - acc: 0.9568 - mDice: 0.7744 - val_loss: 0.4481 - val_acc: 0.9545 - val_mDice: 0.6282

Epoch 00044: val_mDice did not improve from 0.63303
Epoch 45/300
 - 15s - loss: 0.2403 - acc: 0.9567 - mDice: 0.7738 - val_loss: 0.4724 - val_acc: 0.9549 - val_mDice: 0.6234

Epoch 00045: val_mDice did not improve from 0.63303
Epoch 46/300
 - 16s - loss: 0.2381 - acc: 0.9569 - mDice: 0.7756 - val_loss: 0.4613 - val_acc: 0.9536 - val_mDice: 0.6204

Epoch 00046: val_mDice did not improve from 0.63303
Epoch 47/300
 - 15s - loss: 0.2381 - acc: 0.9568 - mDice: 0.7756 - val_loss: 0.4683 - val_acc: 0.9548 - val_mDice: 0.6234

Epoch 00047: val_mDice did not improve from 0.63303
Epoch 48/300
 - 16s - loss: 0.2378 - acc: 0.9569 - mDice: 0.7759 - val_loss: 0.4615 - val_acc: 0.9547 - val_mDice: 0.6234

Epoch 00048: val_mDice did not improve from 0.63303
Epoch 49/300
 - 16s - loss: 0.2359 - acc: 0.9570 - mDice: 0.7774 - val_loss: 0.4559 - val_acc: 0.9537 - val_mDice: 0.6241

Epoch 00049: val_mDice did not improve from 0.63303
Epoch 50/300
 - 16s - loss: 0.2345 - acc: 0.9571 - mDice: 0.7786 - val_loss: 0.4655 - val_acc: 0.9551 - val_mDice: 0.6209

Epoch 00050: val_mDice did not improve from 0.63303
Epoch 51/300
 - 16s - loss: 0.2353 - acc: 0.9571 - mDice: 0.7780 - val_loss: 0.4910 - val_acc: 0.9540 - val_mDice: 0.6070

Epoch 00051: val_mDice did not improve from 0.63303
Epoch 52/300
 - 16s - loss: 0.2339 - acc: 0.9572 - mDice: 0.7791 - val_loss: 0.4650 - val_acc: 0.9544 - val_mDice: 0.6198

Epoch 00052: val_mDice did not improve from 0.63303
Epoch 53/300
 - 16s - loss: 0.2341 - acc: 0.9572 - mDice: 0.7791 - val_loss: 0.4782 - val_acc: 0.9544 - val_mDice: 0.6153

Epoch 00053: val_mDice did not improve from 0.63303
Epoch 54/300
 - 16s - loss: 0.2327 - acc: 0.9573 - mDice: 0.7801 - val_loss: 0.4586 - val_acc: 0.9541 - val_mDice: 0.6231

Epoch 00054: val_mDice did not improve from 0.63303
Epoch 55/300
 - 16s - loss: 0.2321 - acc: 0.9573 - mDice: 0.7806 - val_loss: 0.4638 - val_acc: 0.9550 - val_mDice: 0.6242

Epoch 00055: val_mDice did not improve from 0.63303
Epoch 56/300
 - 15s - loss: 0.2308 - acc: 0.9574 - mDice: 0.7816 - val_loss: 0.4677 - val_acc: 0.9555 - val_mDice: 0.6214

Epoch 00056: val_mDice did not improve from 0.63303
Epoch 57/300
 - 16s - loss: 0.2307 - acc: 0.9574 - mDice: 0.7817 - val_loss: 0.4872 - val_acc: 0.9525 - val_mDice: 0.6045

Epoch 00057: val_mDice did not improve from 0.63303
Epoch 58/300
 - 16s - loss: 0.2306 - acc: 0.9575 - mDice: 0.7818 - val_loss: 0.4558 - val_acc: 0.9547 - val_mDice: 0.6242

Epoch 00058: val_mDice did not improve from 0.63303
Epoch 59/300
 - 16s - loss: 0.2285 - acc: 0.9576 - mDice: 0.7836 - val_loss: 0.4775 - val_acc: 0.9553 - val_mDice: 0.6175

Epoch 00059: val_mDice did not improve from 0.63303
Epoch 60/300
 - 15s - loss: 0.2291 - acc: 0.9576 - mDice: 0.7831 - val_loss: 0.5127 - val_acc: 0.9544 - val_mDice: 0.5998

Epoch 00060: val_mDice did not improve from 0.63303
Epoch 61/300
 - 16s - loss: 0.2282 - acc: 0.9576 - mDice: 0.7838 - val_loss: 0.4889 - val_acc: 0.9525 - val_mDice: 0.6048

Epoch 00061: val_mDice did not improve from 0.63303
Epoch 62/300
 - 15s - loss: 0.2272 - acc: 0.9577 - mDice: 0.7846 - val_loss: 0.4377 - val_acc: 0.9529 - val_mDice: 0.6352

Epoch 00062: val_mDice improved from 0.63303 to 0.63515, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 63/300
 - 16s - loss: 0.2279 - acc: 0.9576 - mDice: 0.7841 - val_loss: 0.4893 - val_acc: 0.9540 - val_mDice: 0.6063

Epoch 00063: val_mDice did not improve from 0.63515
Epoch 64/300
 - 15s - loss: 0.2264 - acc: 0.9578 - mDice: 0.7853 - val_loss: 0.4674 - val_acc: 0.9545 - val_mDice: 0.6197

Epoch 00064: val_mDice did not improve from 0.63515
Epoch 65/300
 - 16s - loss: 0.2262 - acc: 0.9578 - mDice: 0.7854 - val_loss: 0.4988 - val_acc: 0.9555 - val_mDice: 0.6080

Epoch 00065: val_mDice did not improve from 0.63515
Epoch 66/300
 - 16s - loss: 0.2259 - acc: 0.9579 - mDice: 0.7857 - val_loss: 0.4660 - val_acc: 0.9540 - val_mDice: 0.6187

Epoch 00066: val_mDice did not improve from 0.63515
Epoch 67/300
 - 16s - loss: 0.2260 - acc: 0.9578 - mDice: 0.7856 - val_loss: 0.4682 - val_acc: 0.9546 - val_mDice: 0.6168

Epoch 00067: val_mDice did not improve from 0.63515
Epoch 68/300
 - 16s - loss: 0.2250 - acc: 0.9578 - mDice: 0.7864 - val_loss: 0.5031 - val_acc: 0.9552 - val_mDice: 0.6049

Epoch 00068: val_mDice did not improve from 0.63515
Epoch 69/300
 - 15s - loss: 0.2252 - acc: 0.9579 - mDice: 0.7863 - val_loss: 0.5001 - val_acc: 0.9531 - val_mDice: 0.6022

Epoch 00069: val_mDice did not improve from 0.63515
Epoch 70/300
 - 16s - loss: 0.2230 - acc: 0.9580 - mDice: 0.7881 - val_loss: 0.5125 - val_acc: 0.9536 - val_mDice: 0.5966

Epoch 00070: val_mDice did not improve from 0.63515
Epoch 71/300
 - 16s - loss: 0.2241 - acc: 0.9579 - mDice: 0.7872 - val_loss: 0.4519 - val_acc: 0.9542 - val_mDice: 0.6248

Epoch 00071: val_mDice did not improve from 0.63515
Epoch 72/300
 - 15s - loss: 0.2226 - acc: 0.9580 - mDice: 0.7884 - val_loss: 0.4883 - val_acc: 0.9554 - val_mDice: 0.6132

Epoch 00072: val_mDice did not improve from 0.63515
Epoch 73/300
 - 16s - loss: 0.2219 - acc: 0.9581 - mDice: 0.7890 - val_loss: 0.4638 - val_acc: 0.9547 - val_mDice: 0.6205

Epoch 00073: val_mDice did not improve from 0.63515
Epoch 74/300
 - 15s - loss: 0.2219 - acc: 0.9581 - mDice: 0.7889 - val_loss: 0.4900 - val_acc: 0.9545 - val_mDice: 0.6065

Epoch 00074: val_mDice did not improve from 0.63515
Epoch 75/300
 - 17s - loss: 0.2224 - acc: 0.9581 - mDice: 0.7886 - val_loss: 0.4948 - val_acc: 0.9551 - val_mDice: 0.6064

Epoch 00075: val_mDice did not improve from 0.63515
Epoch 76/300
 - 16s - loss: 0.2203 - acc: 0.9582 - mDice: 0.7903 - val_loss: 0.4682 - val_acc: 0.9542 - val_mDice: 0.6162

Epoch 00076: val_mDice did not improve from 0.63515
Epoch 77/300
 - 16s - loss: 0.2211 - acc: 0.9582 - mDice: 0.7897 - val_loss: 0.4794 - val_acc: 0.9537 - val_mDice: 0.6113

Epoch 00077: val_mDice did not improve from 0.63515
Epoch 78/300
 - 16s - loss: 0.2214 - acc: 0.9581 - mDice: 0.7894 - val_loss: 0.4502 - val_acc: 0.9550 - val_mDice: 0.6281

Epoch 00078: val_mDice did not improve from 0.63515
Epoch 79/300
 - 17s - loss: 0.2205 - acc: 0.9583 - mDice: 0.7902 - val_loss: 0.5719 - val_acc: 0.9538 - val_mDice: 0.5956

Epoch 00079: val_mDice did not improve from 0.63515
Epoch 80/300
 - 17s - loss: 0.2197 - acc: 0.9582 - mDice: 0.7908 - val_loss: 0.4611 - val_acc: 0.9553 - val_mDice: 0.6225

Epoch 00080: val_mDice did not improve from 0.63515
Epoch 81/300
 - 17s - loss: 0.2190 - acc: 0.9583 - mDice: 0.7914 - val_loss: 0.4788 - val_acc: 0.9548 - val_mDice: 0.6128

Epoch 00081: val_mDice did not improve from 0.63515
Epoch 82/300
 - 17s - loss: 0.2186 - acc: 0.9583 - mDice: 0.7918 - val_loss: 0.4854 - val_acc: 0.9538 - val_mDice: 0.6124

Epoch 00082: val_mDice did not improve from 0.63515
Epoch 83/300
 - 17s - loss: 0.2187 - acc: 0.9584 - mDice: 0.7917 - val_loss: 0.4598 - val_acc: 0.9542 - val_mDice: 0.6228

Epoch 00083: val_mDice did not improve from 0.63515
Epoch 84/300
 - 16s - loss: 0.2187 - acc: 0.9584 - mDice: 0.7917 - val_loss: 0.4688 - val_acc: 0.9540 - val_mDice: 0.6176

Epoch 00084: val_mDice did not improve from 0.63515
Epoch 85/300
 - 17s - loss: 0.2168 - acc: 0.9584 - mDice: 0.7932 - val_loss: 0.5212 - val_acc: 0.9556 - val_mDice: 0.6001

Epoch 00085: val_mDice did not improve from 0.63515
Epoch 86/300
 - 18s - loss: 0.2176 - acc: 0.9584 - mDice: 0.7926 - val_loss: 0.5034 - val_acc: 0.9543 - val_mDice: 0.6101

Epoch 00086: val_mDice did not improve from 0.63515
Epoch 87/300
 - 19s - loss: 0.2176 - acc: 0.9584 - mDice: 0.7926 - val_loss: 0.4819 - val_acc: 0.9547 - val_mDice: 0.6122

Epoch 00087: val_mDice did not improve from 0.63515
Epoch 88/300
 - 19s - loss: 0.2172 - acc: 0.9585 - mDice: 0.7930 - val_loss: 0.4706 - val_acc: 0.9542 - val_mDice: 0.6162

Epoch 00088: val_mDice did not improve from 0.63515
Epoch 89/300
 - 18s - loss: 0.2164 - acc: 0.9586 - mDice: 0.7936 - val_loss: 0.4724 - val_acc: 0.9549 - val_mDice: 0.6176

Epoch 00089: val_mDice did not improve from 0.63515
Epoch 90/300
 - 18s - loss: 0.2164 - acc: 0.9586 - mDice: 0.7937 - val_loss: 0.5042 - val_acc: 0.9536 - val_mDice: 0.6059

Epoch 00090: val_mDice did not improve from 0.63515
Epoch 91/300
 - 18s - loss: 0.2148 - acc: 0.9586 - mDice: 0.7949 - val_loss: 0.4764 - val_acc: 0.9540 - val_mDice: 0.6150

Epoch 00091: val_mDice did not improve from 0.63515
Epoch 92/300
 - 18s - loss: 0.2172 - acc: 0.9584 - mDice: 0.7929 - val_loss: 0.4852 - val_acc: 0.9557 - val_mDice: 0.6131

Epoch 00092: val_mDice did not improve from 0.63515
Epoch 93/300
 - 18s - loss: 0.2148 - acc: 0.9586 - mDice: 0.7949 - val_loss: 0.4786 - val_acc: 0.9553 - val_mDice: 0.6141

Epoch 00093: val_mDice did not improve from 0.63515
Epoch 94/300
 - 16s - loss: 0.2152 - acc: 0.9587 - mDice: 0.7946 - val_loss: 0.4727 - val_acc: 0.9546 - val_mDice: 0.6161

Epoch 00094: val_mDice did not improve from 0.63515
Epoch 95/300
 - 15s - loss: 0.2136 - acc: 0.9587 - mDice: 0.7959 - val_loss: 0.4783 - val_acc: 0.9539 - val_mDice: 0.6130

Epoch 00095: val_mDice did not improve from 0.63515
Epoch 96/300
 - 15s - loss: 0.2138 - acc: 0.9586 - mDice: 0.7958 - val_loss: 0.4790 - val_acc: 0.9542 - val_mDice: 0.6129

Epoch 00096: val_mDice did not improve from 0.63515
Epoch 97/300
 - 15s - loss: 0.2153 - acc: 0.9587 - mDice: 0.7947 - val_loss: 0.4767 - val_acc: 0.9539 - val_mDice: 0.6129

Epoch 00097: val_mDice did not improve from 0.63515
Epoch 98/300
 - 15s - loss: 0.2132 - acc: 0.9588 - mDice: 0.7962 - val_loss: 0.4841 - val_acc: 0.9549 - val_mDice: 0.6118

Epoch 00098: val_mDice did not improve from 0.63515
Epoch 99/300
 - 15s - loss: 0.2126 - acc: 0.9589 - mDice: 0.7968 - val_loss: 0.4702 - val_acc: 0.9541 - val_mDice: 0.6156

Epoch 00099: val_mDice did not improve from 0.63515
Epoch 100/300
 - 15s - loss: 0.2145 - acc: 0.9587 - mDice: 0.7953 - val_loss: 0.5040 - val_acc: 0.9548 - val_mDice: 0.6047

Epoch 00100: val_mDice did not improve from 0.63515
Epoch 101/300
 - 15s - loss: 0.2123 - acc: 0.9589 - mDice: 0.7971 - val_loss: 0.4664 - val_acc: 0.9549 - val_mDice: 0.6186

Epoch 00101: val_mDice did not improve from 0.63515
Epoch 102/300
 - 15s - loss: 0.2119 - acc: 0.9588 - mDice: 0.7974 - val_loss: 0.4754 - val_acc: 0.9552 - val_mDice: 0.6156

Epoch 00102: val_mDice did not improve from 0.63515
Restoring model weights from the end of the best epoch
Epoch 00102: early stopping
{'val_loss': [0.7906777895362683, 0.707436514300341, 0.6053714042935292, 0.5763200201801748, 0.4765938723553492, 0.46728757373447527, 0.4671977465379172, 0.4695606591315243, 0.45446793193923696, 0.4830033336271787, 0.4457389559159732, 0.4585890383693759, 0.45997899371152484, 0.45790039294258844, 0.4801640723670661, 0.5444104804673009, 0.4792461458531172, 0.5061656523017244, 0.48943340345467934, 0.5630837392540617, 0.4842678338455754, 0.47953395204171123, 0.47141699418009325, 0.478038489818573, 0.4773217366394384, 0.47624691405109854, 0.48731035693397734, 0.47617623426394756, 0.4815182146413366, 0.458341191267834, 0.45948684382039073, 0.4478676322452183, 0.47304666941392354, 0.47930777938672287, 0.45657700699800885, 0.475404166642514, 0.4639158821638736, 0.4656898978702183, 0.45314215082030057, 0.47274795624130933, 0.4990433744212103, 0.44245627339325805, 0.45809407007760844, 0.4480522438134561, 0.4723501754872626, 0.4612795297659975, 0.4682690494553337, 0.46148160416320716, 0.45585407524801497, 0.4655125587346168, 0.49100754980268424, 0.4650415608336806, 0.4782003240878356, 0.4585544610156693, 0.46384921287025155, 0.4676883437114055, 0.48716897571553064, 0.45583708892321456, 0.4775199953404219, 0.5126817472820175, 0.4888620826119151, 0.4377010434699458, 0.4892876684332693, 0.4674333323979511, 0.4987630581056606, 0.46598755214467397, 0.4681726744055082, 0.5031010421960713, 0.5000863614695032, 0.5124531474859355, 0.4518502754206098, 0.4883083478032544, 0.4637678365467647, 0.48997435589742394, 0.4948134525528167, 0.4682240259713967, 0.4793978203608337, 0.45020569736065147, 0.5719243188144109, 0.4610730226479429, 0.4788091632240977, 0.48540020188805777, 0.4597728159174573, 0.46880291860196843, 0.5212453350674506, 0.5033563848314339, 0.48190164532741353, 0.4705676772740966, 0.47241845477226724, 0.5041796485139005, 0.4764342491187197, 0.4851758553329127, 0.47856414784266293, 0.4727150334992222, 0.4782990283806231, 0.47901369073537475, 0.4766940737569798, 0.48409076676022406, 0.47021830614718646, 0.5039557055388083, 0.466387078748735, 0.4754452518910669], 'val_acc': [0.9292440797363579, 0.9376942222344808, 0.9460844454152624, 0.947115393657258, 0.9521172955715457, 0.95205322923607, 0.9531565065490467, 0.9526668550581906, 0.9537102093909706, 0.9530366712442323, 0.9511297271904333, 0.9541337579988235, 0.9540345568896672, 0.9547473791591282, 0.9522784152510446, 0.9520305251942001, 0.9529127042386785, 0.9518383691430757, 0.9531998987304432, 0.9514210257450295, 0.9546750437613972, 0.9549890823204424, 0.953549044758248, 0.9540697003210057, 0.9536027855047301, 0.9547824719764667, 0.9532763411878874, 0.9531916033622273, 0.9532990595481915, 0.9540572952291819, 0.9536833619938216, 0.9510925185746987, 0.9543713497715955, 0.9544126584543197, 0.9553547654737974, 0.9545841463451279, 0.9521586278963355, 0.954007707827584, 0.9546481923684061, 0.9522123260205019, 0.9542701117819248, 0.9556626287918517, 0.9527804904809877, 0.9545139051016482, 0.9548651259704675, 0.9536296408935632, 0.9547742292201719, 0.9546502615486443, 0.9536564939514884, 0.9551254424302937, 0.9539849731509246, 0.9543837308883667, 0.9544064668969735, 0.9541420084138156, 0.9549911541645754, 0.9555159171200331, 0.9524767961581992, 0.9546812499701643, 0.9552989888457613, 0.9543920242586615, 0.9525118859786561, 0.9528713855663491, 0.9540221784367907, 0.9545159902652549, 0.95554692485479, 0.9539540060405625, 0.9545903478920793, 0.9551522941562717, 0.9530655914844748, 0.9536399771381356, 0.9542122356718479, 0.9553589181527079, 0.954650255887868, 0.954497387289335, 0.955141989878436, 0.954241188211814, 0.9537453241854407, 0.9549849656041108, 0.9537536115619724, 0.9552990061610771, 0.9547597692665442, 0.9538135202237348, 0.9542267322540283, 0.9540325013618896, 0.9555799624773377, 0.9542969555162185, 0.9547204904716108, 0.9541957248522582, 0.9548795949147401, 0.953608964741563, 0.9539870390012943, 0.9557369834217946, 0.9553279227384642, 0.9545593398243355, 0.9538589639370668, 0.9542329134887824, 0.9539250751447411, 0.9548775157448965, 0.9540676407973859, 0.9547659331859824, 0.9548795716056611, 0.9551936258150878], 'val_mDice': [0.4397916940337453, 0.4953977057720696, 0.5462405708249055, 0.5600473008342295, 0.6094010948468853, 0.6153107069058126, 0.6174818746870456, 0.6202765243679451, 0.6241842261905777, 0.6122762640761263, 0.6290451544623136, 0.6243086297418818, 0.6246634328831507, 0.6233721768389867, 0.6122481007149766, 0.5973292935493938, 0.6109778241738261, 0.6021717357235914, 0.6082162287648164, 0.5897443973818305, 0.6151957285470803, 0.6160729550782529, 0.6170316778081756, 0.6144804288555124, 0.6172281903261579, 0.6173956524060425, 0.6108316889022316, 0.6143037340494507, 0.6108714735041784, 0.6236023689781487, 0.6214088354696775, 0.6276144142257435, 0.6177857018715842, 0.6162360936569768, 0.6259826348480566, 0.6155059727210572, 0.6175498432953265, 0.6200130029097616, 0.6260107162944432, 0.6146245761956582, 0.6059410838441476, 0.6330318870491156, 0.6210756981173041, 0.6281739666475264, 0.6233820672141773, 0.6203997947650248, 0.6234095289720504, 0.6234273590855093, 0.6241176521311925, 0.6209127843046988, 0.6070451160382958, 0.6198069959379441, 0.6152539772694338, 0.6231036472586946, 0.6241796502853905, 0.6213937731428519, 0.6044951783878177, 0.6241884464658173, 0.6174660321720485, 0.5998413669330448, 0.604760841950358, 0.635151122868394, 0.606283411633369, 0.619721584479902, 0.6079742076010678, 0.6187169042379497, 0.6167985337406563, 0.6049149409352734, 0.6022331381643284, 0.5966425704556471, 0.6248087237001131, 0.6131984115312885, 0.6205411709886689, 0.6064671844077509, 0.6064027108293671, 0.6162203470421903, 0.6113027091132862, 0.6281293607290896, 0.5955745917458773, 0.6225203951643832, 0.6127875347377202, 0.6123746790033479, 0.6227698828920972, 0.6175767962493044, 0.6000866556966771, 0.6101268150286967, 0.6122144364111917, 0.6161659849422604, 0.6175564883807518, 0.6059147499127095, 0.6149547885916087, 0.6130806264264623, 0.6140776459731203, 0.6160667575271436, 0.6130407009710813, 0.612852599367749, 0.6128870778243635, 0.6118012959730692, 0.6156272069035962, 0.6046818348282542, 0.6185643426532852, 0.6156392946589593], 'loss': [1.7424582203004193, 0.6369844693567789, 0.5004247066148271, 0.43741705412633813, 0.39795811400551934, 0.3778517855440153, 0.3575332800399036, 0.34795804551682513, 0.3355998110634187, 0.327525434151343, 0.32068928355848886, 0.3146208668578379, 0.30672173870849256, 0.3029509515753499, 0.2982198673277975, 0.29323786905658356, 0.29039217556271507, 0.28486388493230885, 0.2847807869809391, 0.27947198212013663, 0.27561200687642595, 0.2727751678325442, 0.27120247097759687, 0.2681647020191105, 0.26669382026438215, 0.2655495310081622, 0.264771589196447, 0.261302309169092, 0.2597280676088577, 0.2586501108704748, 0.256124164548992, 0.2580380276941953, 0.25404562572301664, 0.2529649542318269, 0.250714394691872, 0.24900595773266887, 0.24888463633641278, 0.24823903302683833, 0.24562349894403743, 0.24443279394954906, 0.243771796165212, 0.24239605037054915, 0.2422512868409855, 0.2396331870356557, 0.2403321864558074, 0.2381153742007574, 0.2381468190748729, 0.23780344679759327, 0.23594282449824014, 0.23450362709043046, 0.235266010097465, 0.23389056048214835, 0.23409043641127011, 0.23268244318255452, 0.2320956567421139, 0.230795439991918, 0.2307421111771954, 0.23055015405430318, 0.22850514377106848, 0.2290883803931166, 0.22822731519718004, 0.22719098092907686, 0.22785323311184547, 0.22639250723253207, 0.22622155833657248, 0.22588814938502091, 0.22599466748518995, 0.225012791863805, 0.22522348355499658, 0.2230061247314245, 0.22406856402008954, 0.22258421357070418, 0.22188225906224793, 0.22190992380044253, 0.2223588837849653, 0.2202638404179188, 0.22107167613479697, 0.22138530502803808, 0.2205221269519739, 0.21968248527584094, 0.21901355009311152, 0.21861096584396317, 0.21869471790120398, 0.21869023615521457, 0.21679237940788504, 0.21758455965852797, 0.2176015305724268, 0.21718926593376447, 0.21637493937624921, 0.21638913409855753, 0.2148044269807289, 0.2171799867548303, 0.21481683568837343, 0.21516153767821017, 0.21363991077582137, 0.2137534373609415, 0.21533120131675704, 0.21320450945777264, 0.21263465367512832, 0.21446421271487587, 0.21229236275663718, 0.21187187334816088], 'acc': [0.7770476796600945, 0.9202105525427995, 0.934932754892363, 0.9413127101627896, 0.9447312664572732, 0.9463534822820299, 0.9479812360992814, 0.9486888374458257, 0.9496977552629544, 0.9502169086966767, 0.9507265588075181, 0.9512606951985365, 0.9517804935901593, 0.9521048771751375, 0.9524061552359319, 0.9527594227526197, 0.9529618667975781, 0.9533307022872064, 0.9533834909991523, 0.9537745472957778, 0.9540928058599336, 0.9542737597766301, 0.9543674180342879, 0.9546569974118215, 0.9546970581120184, 0.9548340203241223, 0.9549346911115757, 0.9551939333967443, 0.9552421145212948, 0.9553593177758013, 0.95549767184612, 0.9553372610804107, 0.9557049322943757, 0.955781489031214, 0.9559625230592019, 0.9560651247858852, 0.9560743312379658, 0.9560362634741398, 0.9563303930873309, 0.9564027002119926, 0.9564106971776977, 0.9565206311943809, 0.956564097390586, 0.9567590490755358, 0.9566862574655189, 0.9568517203781834, 0.9568377416038181, 0.9568660205229, 0.9570207887144885, 0.957136404925939, 0.9570933817570574, 0.9571690346432319, 0.9572023496662347, 0.957342552730353, 0.9573307523124391, 0.9574121841644969, 0.9574241886490291, 0.9574522046629662, 0.9576319737616438, 0.9575990988670511, 0.9576241760158856, 0.9576867776014182, 0.9576320904388478, 0.9577515311869886, 0.9578024311319142, 0.9578587062724645, 0.9578151416398102, 0.9578498229242398, 0.9578755657421362, 0.9580256619956471, 0.95793274768745, 0.9580498538656916, 0.9581394416692113, 0.9581154339726822, 0.9581301172738839, 0.9581911062844977, 0.958202786840623, 0.9581411118750466, 0.9582930832839949, 0.9582049021286666, 0.9583418064404141, 0.9583489365498749, 0.9583523411531606, 0.9584252736153059, 0.9584376019113795, 0.9584423138823789, 0.9584042669433335, 0.9584512141760992, 0.958553898477988, 0.9585759754592794, 0.9586091868907666, 0.9584124647878262, 0.9586119473185014, 0.9587011552767247, 0.9586712831401935, 0.958647821650228, 0.9586962621577275, 0.9588138681209644, 0.9588661371093645, 0.9586887461584278, 0.9588637392405727, 0.9588493569426648], 'mDice': [0.2499264753905752, 0.513607668750693, 0.5916257984926093, 0.6316001912645185, 0.6571579711524614, 0.6709687937436348, 0.6850194358389385, 0.6918729660811102, 0.7007984672488162, 0.7066211396946275, 0.7116496051444018, 0.7161650756405146, 0.7221000208183868, 0.7249457271755745, 0.728484791092971, 0.7321481237120114, 0.73433524913618, 0.738567340335687, 0.738801487659773, 0.742740140810595, 0.7457471073897639, 0.7478961237868507, 0.7491716681323496, 0.7515875534173496, 0.7527019599314952, 0.7536152387508074, 0.754269795712936, 0.7570707324569076, 0.758290190568424, 0.7591925878214697, 0.7611316901835914, 0.7596876738955853, 0.7627659905327541, 0.7636231192348635, 0.76542903049132, 0.7668305977089045, 0.7669291106660306, 0.7675034127186848, 0.7696027674710567, 0.7705694385768477, 0.7710654697778678, 0.7721502043622932, 0.7723236450390141, 0.7743867977039077, 0.7738280960705979, 0.7756308757767335, 0.7755523240843485, 0.775934696729897, 0.7773929014619376, 0.7785805329947448, 0.7780049979754908, 0.7790972105324849, 0.7791130549215192, 0.7801057427844011, 0.7805875156753028, 0.7816378962635884, 0.781746329396296, 0.7818139283935344, 0.7835524699688088, 0.7830502413423043, 0.7838213641875567, 0.7846132107182504, 0.7840732779678686, 0.7852947041785936, 0.7854204790686076, 0.7857117451462414, 0.7855571340543306, 0.786362572463209, 0.7862533983968194, 0.7880719795991091, 0.7871990048296473, 0.7884075611571679, 0.7889955347480678, 0.7889429433050644, 0.7886479620670975, 0.790325159672318, 0.7897196490418826, 0.7894342229469015, 0.7901587299866638, 0.7908140264865808, 0.7914127546077161, 0.7917847808497734, 0.7916657230081554, 0.7916929262745687, 0.7932490410774103, 0.7926060468645035, 0.7926274200201515, 0.7930134708705691, 0.7936047806075491, 0.7936581174803095, 0.794924400683926, 0.7929387433577854, 0.7948785318112128, 0.7946492202998338, 0.7958564684513211, 0.79578127687218, 0.7946997258756799, 0.7962298561633201, 0.796788596352502, 0.7952619382650931, 0.7970803639810983, 0.7973501934451246]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.20s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.02s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.86s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:05,  1.92s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:30,  1.80s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:27,  1.80s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:54,  1.69s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:10,  1.75s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<07:44,  1.67s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:59,  1.73s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:52,  1.70s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:23,  1.83s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:40,  1.89s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:15,  1.81s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:32,  1.88s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<08:07,  1.79s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<08:11,  1.81s/it]predicting train subjects:   5%|▌         | 15/285 [00:26<08:28,  1.88s/it]predicting train subjects:   6%|▌         | 16/285 [00:28<08:42,  1.94s/it]predicting train subjects:   6%|▌         | 17/285 [00:30<08:16,  1.85s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:18,  1.87s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<07:58,  1.80s/it]predicting train subjects:   7%|▋         | 20/285 [00:36<08:06,  1.84s/it]predicting train subjects:   7%|▋         | 21/285 [00:38<08:30,  1.93s/it]predicting train subjects:   8%|▊         | 22/285 [00:39<08:08,  1.86s/it]predicting train subjects:   8%|▊         | 23/285 [00:41<08:15,  1.89s/it]predicting train subjects:   8%|▊         | 24/285 [00:43<07:56,  1.82s/it]predicting train subjects:   9%|▉         | 25/285 [00:45<08:15,  1.90s/it]predicting train subjects:   9%|▉         | 26/285 [00:47<08:32,  1.98s/it]predicting train subjects:   9%|▉         | 27/285 [00:49<08:01,  1.87s/it]predicting train subjects:  10%|▉         | 28/285 [00:51<07:58,  1.86s/it]predicting train subjects:  10%|█         | 29/285 [00:53<07:55,  1.86s/it]predicting train subjects:  11%|█         | 30/285 [00:55<08:18,  1.96s/it]predicting train subjects:  11%|█         | 31/285 [00:57<08:21,  1.97s/it]predicting train subjects:  11%|█         | 32/285 [00:58<07:53,  1.87s/it]predicting train subjects:  12%|█▏        | 33/285 [01:00<07:47,  1.86s/it]predicting train subjects:  12%|█▏        | 34/285 [01:02<07:45,  1.86s/it]predicting train subjects:  12%|█▏        | 35/285 [01:04<08:03,  1.94s/it]predicting train subjects:  13%|█▎        | 36/285 [01:06<07:43,  1.86s/it]predicting train subjects:  13%|█▎        | 37/285 [01:08<07:47,  1.88s/it]predicting train subjects:  13%|█▎        | 38/285 [01:10<08:02,  1.95s/it]predicting train subjects:  14%|█▎        | 39/285 [01:12<07:37,  1.86s/it]predicting train subjects:  14%|█▍        | 40/285 [01:13<07:38,  1.87s/it]predicting train subjects:  14%|█▍        | 41/285 [01:15<07:24,  1.82s/it]predicting train subjects:  15%|█▍        | 42/285 [01:17<07:10,  1.77s/it]predicting train subjects:  15%|█▌        | 43/285 [01:19<07:19,  1.82s/it]predicting train subjects:  15%|█▌        | 44/285 [01:21<07:43,  1.92s/it]predicting train subjects:  16%|█▌        | 45/285 [01:23<07:24,  1.85s/it]predicting train subjects:  16%|█▌        | 46/285 [01:25<07:38,  1.92s/it]predicting train subjects:  16%|█▋        | 47/285 [01:26<07:16,  1.84s/it]predicting train subjects:  17%|█▋        | 48/285 [01:28<07:21,  1.86s/it]predicting train subjects:  17%|█▋        | 49/285 [01:30<07:40,  1.95s/it]predicting train subjects:  18%|█▊        | 50/285 [01:32<07:29,  1.91s/it]predicting train subjects:  18%|█▊        | 51/285 [01:34<07:46,  1.99s/it]predicting train subjects:  18%|█▊        | 52/285 [01:36<07:24,  1.91s/it]predicting train subjects:  19%|█▊        | 53/285 [01:38<07:19,  1.89s/it]predicting train subjects:  19%|█▉        | 54/285 [01:40<07:31,  1.96s/it]predicting train subjects:  19%|█▉        | 55/285 [01:42<07:05,  1.85s/it]predicting train subjects:  20%|█▉        | 56/285 [01:44<07:00,  1.83s/it]predicting train subjects:  20%|██        | 57/285 [01:45<06:41,  1.76s/it]predicting train subjects:  20%|██        | 58/285 [01:47<06:45,  1.79s/it]predicting train subjects:  21%|██        | 59/285 [01:49<07:00,  1.86s/it]predicting train subjects:  21%|██        | 60/285 [01:51<07:16,  1.94s/it]predicting train subjects:  21%|██▏       | 61/285 [01:53<06:54,  1.85s/it]predicting train subjects:  22%|██▏       | 62/285 [01:55<06:57,  1.87s/it]predicting train subjects:  22%|██▏       | 63/285 [01:57<06:52,  1.86s/it]predicting train subjects:  22%|██▏       | 64/285 [01:58<06:43,  1.83s/it]predicting train subjects:  23%|██▎       | 65/285 [02:00<06:51,  1.87s/it]predicting train subjects:  23%|██▎       | 66/285 [02:02<06:53,  1.89s/it]predicting train subjects:  24%|██▎       | 67/285 [02:04<06:50,  1.88s/it]predicting train subjects:  24%|██▍       | 68/285 [02:06<06:36,  1.83s/it]predicting train subjects:  24%|██▍       | 69/285 [02:08<06:46,  1.88s/it]predicting train subjects:  25%|██▍       | 70/285 [02:10<06:49,  1.90s/it]predicting train subjects:  25%|██▍       | 71/285 [02:12<06:45,  1.89s/it]predicting train subjects:  25%|██▌       | 72/285 [02:13<06:34,  1.85s/it]predicting train subjects:  26%|██▌       | 73/285 [02:15<06:41,  1.90s/it]predicting train subjects:  26%|██▌       | 74/285 [02:17<06:35,  1.88s/it]predicting train subjects:  26%|██▋       | 75/285 [02:19<06:31,  1.87s/it]predicting train subjects:  27%|██▋       | 76/285 [02:21<06:31,  1.87s/it]predicting train subjects:  27%|██▋       | 77/285 [02:23<06:18,  1.82s/it]predicting train subjects:  27%|██▋       | 78/285 [02:24<06:09,  1.79s/it]predicting train subjects:  28%|██▊       | 79/285 [02:26<06:15,  1.82s/it]predicting train subjects:  28%|██▊       | 80/285 [02:28<06:16,  1.84s/it]predicting train subjects:  28%|██▊       | 81/285 [02:30<06:06,  1.80s/it]predicting train subjects:  29%|██▉       | 82/285 [02:32<06:06,  1.81s/it]predicting train subjects:  29%|██▉       | 83/285 [02:33<05:57,  1.77s/it]predicting train subjects:  29%|██▉       | 84/285 [02:35<05:49,  1.74s/it]predicting train subjects:  30%|██▉       | 85/285 [02:37<05:53,  1.77s/it]predicting train subjects:  30%|███       | 86/285 [02:39<05:59,  1.81s/it]predicting train subjects:  31%|███       | 87/285 [02:41<06:06,  1.85s/it]predicting train subjects:  31%|███       | 88/285 [02:42<05:54,  1.80s/it]predicting train subjects:  31%|███       | 89/285 [02:44<06:02,  1.85s/it]predicting train subjects:  32%|███▏      | 90/285 [02:46<06:10,  1.90s/it]predicting train subjects:  32%|███▏      | 91/285 [02:48<05:54,  1.83s/it]predicting train subjects:  32%|███▏      | 92/285 [02:50<05:52,  1.83s/it]predicting train subjects:  33%|███▎      | 93/285 [02:51<05:39,  1.77s/it]predicting train subjects:  33%|███▎      | 94/285 [02:53<05:42,  1.80s/it]predicting train subjects:  33%|███▎      | 95/285 [02:55<05:43,  1.81s/it]predicting train subjects:  34%|███▎      | 96/285 [02:57<05:44,  1.82s/it]predicting train subjects:  34%|███▍      | 97/285 [02:59<05:47,  1.85s/it]predicting train subjects:  34%|███▍      | 98/285 [03:01<05:46,  1.85s/it]predicting train subjects:  35%|███▍      | 99/285 [03:03<05:46,  1.86s/it]predicting train subjects:  35%|███▌      | 100/285 [03:05<05:46,  1.87s/it]predicting train subjects:  35%|███▌      | 101/285 [03:06<05:36,  1.83s/it]predicting train subjects:  36%|███▌      | 102/285 [03:08<05:38,  1.85s/it]predicting train subjects:  36%|███▌      | 103/285 [03:10<05:27,  1.80s/it]predicting train subjects:  36%|███▋      | 104/285 [03:12<05:29,  1.82s/it]predicting train subjects:  37%|███▋      | 105/285 [03:14<05:33,  1.85s/it]predicting train subjects:  37%|███▋      | 106/285 [03:15<05:22,  1.80s/it]predicting train subjects:  38%|███▊      | 107/285 [03:17<05:21,  1.81s/it]predicting train subjects:  38%|███▊      | 108/285 [03:19<05:11,  1.76s/it]predicting train subjects:  38%|███▊      | 109/285 [03:21<05:15,  1.79s/it]predicting train subjects:  39%|███▊      | 110/285 [03:23<05:19,  1.83s/it]predicting train subjects:  39%|███▉      | 111/285 [03:24<05:13,  1.80s/it]predicting train subjects:  39%|███▉      | 112/285 [03:26<05:14,  1.82s/it]predicting train subjects:  40%|███▉      | 113/285 [03:28<05:20,  1.87s/it]predicting train subjects:  40%|████      | 114/285 [03:30<05:21,  1.88s/it]predicting train subjects:  40%|████      | 115/285 [03:32<05:16,  1.86s/it]predicting train subjects:  41%|████      | 116/285 [03:34<05:15,  1.87s/it]predicting train subjects:  41%|████      | 117/285 [03:35<05:06,  1.82s/it]predicting train subjects:  41%|████▏     | 118/285 [03:37<04:59,  1.79s/it]predicting train subjects:  42%|████▏     | 119/285 [03:39<04:59,  1.81s/it]predicting train subjects:  42%|████▏     | 120/285 [03:41<04:52,  1.77s/it]predicting train subjects:  42%|████▏     | 121/285 [03:42<04:47,  1.75s/it]predicting train subjects:  43%|████▎     | 122/285 [03:44<04:36,  1.69s/it]predicting train subjects:  43%|████▎     | 123/285 [03:46<04:27,  1.65s/it]predicting train subjects:  44%|████▎     | 124/285 [03:47<04:29,  1.68s/it]predicting train subjects:  44%|████▍     | 125/285 [03:49<04:23,  1.64s/it]predicting train subjects:  44%|████▍     | 126/285 [03:50<04:19,  1.63s/it]predicting train subjects:  45%|████▍     | 127/285 [03:52<04:12,  1.60s/it]predicting train subjects:  45%|████▍     | 128/285 [03:54<04:14,  1.62s/it]predicting train subjects:  45%|████▌     | 129/285 [03:55<04:11,  1.61s/it]predicting train subjects:  46%|████▌     | 130/285 [03:57<04:05,  1.59s/it]predicting train subjects:  46%|████▌     | 131/285 [03:58<03:58,  1.55s/it]predicting train subjects:  46%|████▋     | 132/285 [04:00<04:02,  1.58s/it]predicting train subjects:  47%|████▋     | 133/285 [04:01<03:56,  1.56s/it]predicting train subjects:  47%|████▋     | 134/285 [04:03<03:55,  1.56s/it]predicting train subjects:  47%|████▋     | 135/285 [04:05<03:54,  1.57s/it]predicting train subjects:  48%|████▊     | 136/285 [04:06<03:53,  1.57s/it]predicting train subjects:  48%|████▊     | 137/285 [04:08<04:00,  1.62s/it]predicting train subjects:  48%|████▊     | 138/285 [04:09<03:57,  1.62s/it]predicting train subjects:  49%|████▉     | 139/285 [04:11<03:58,  1.64s/it]predicting train subjects:  49%|████▉     | 140/285 [04:13<03:56,  1.63s/it]predicting train subjects:  49%|████▉     | 141/285 [04:14<03:50,  1.60s/it]predicting train subjects:  50%|████▉     | 142/285 [04:16<03:49,  1.60s/it]predicting train subjects:  50%|█████     | 143/285 [04:17<03:39,  1.55s/it]predicting train subjects:  51%|█████     | 144/285 [04:19<03:47,  1.61s/it]predicting train subjects:  51%|█████     | 145/285 [04:21<03:40,  1.58s/it]predicting train subjects:  51%|█████     | 146/285 [04:22<03:41,  1.59s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:24<03:35,  1.56s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:25<03:40,  1.61s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:27<03:39,  1.62s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:29<03:36,  1.61s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:30<03:39,  1.64s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:32<03:34,  1.61s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:33<03:31,  1.60s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:35<03:33,  1.63s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:37<03:27,  1.60s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:38<03:31,  1.64s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:40<03:24,  1.60s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:42<03:23,  1.60s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:43<03:20,  1.59s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:45<03:19,  1.59s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:46<03:20,  1.62s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:48<03:15,  1.59s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:50<03:20,  1.64s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:51<03:12,  1.59s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:53<03:11,  1.59s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:54<03:09,  1.59s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:56<03:10,  1.62s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:57<03:04,  1.57s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:59<03:01,  1.56s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:01<02:58,  1.55s/it]predicting train subjects:  60%|██████    | 171/285 [05:02<02:54,  1.53s/it]predicting train subjects:  60%|██████    | 172/285 [05:04<02:54,  1.55s/it]predicting train subjects:  61%|██████    | 173/285 [05:05<02:50,  1.52s/it]predicting train subjects:  61%|██████    | 174/285 [05:07<02:48,  1.51s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:08<02:52,  1.57s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:10<02:53,  1.59s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:11<02:49,  1.57s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:13<02:44,  1.54s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:15<02:47,  1.58s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:16<02:53,  1.66s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:18<02:57,  1.71s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:20<02:58,  1.74s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:22<02:53,  1.70s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:23<02:46,  1.65s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:25<02:38,  1.58s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:27<02:47,  1.69s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:28<02:53,  1.77s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:30<02:57,  1.82s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:32<02:44,  1.71s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:33<02:35,  1.63s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:35<02:35,  1.66s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:37<02:36,  1.68s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:38<02:29,  1.63s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:40<02:24,  1.59s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:41<02:20,  1.56s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:43<02:27,  1.66s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:45<02:32,  1.73s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:47<02:32,  1.76s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:48<02:22,  1.65s/it]predicting train subjects:  70%|███████   | 200/285 [05:50<02:16,  1.60s/it]predicting train subjects:  71%|███████   | 201/285 [05:52<02:20,  1.67s/it]predicting train subjects:  71%|███████   | 202/285 [05:53<02:20,  1.70s/it]predicting train subjects:  71%|███████   | 203/285 [05:55<02:17,  1.68s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:56<02:11,  1.62s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:58<02:06,  1.58s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:59<02:01,  1.54s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:01<02:08,  1.65s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:03<02:12,  1.72s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:05<02:13,  1.75s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:06<02:04,  1.65s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:08<01:58,  1.60s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:10<02:01,  1.66s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:11<01:59,  1.67s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:13<01:54,  1.61s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:15<01:57,  1.67s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:16<01:51,  1.62s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:18<01:55,  1.70s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:20<01:57,  1.75s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:22<01:59,  1.82s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:23<01:51,  1.72s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:25<01:46,  1.66s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:27<01:46,  1.69s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:28<01:40,  1.62s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:30<01:36,  1.58s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:31<01:33,  1.56s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:33<01:38,  1.67s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:35<01:42,  1.77s/it]predicting train subjects:  80%|████████  | 228/285 [06:37<01:44,  1.84s/it]predicting train subjects:  80%|████████  | 229/285 [06:39<01:41,  1.81s/it]predicting train subjects:  81%|████████  | 230/285 [06:40<01:34,  1.72s/it]predicting train subjects:  81%|████████  | 231/285 [06:42<01:29,  1.66s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:44<01:29,  1.69s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:45<01:24,  1.63s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:47<01:26,  1.69s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:48<01:21,  1.63s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:50<01:24,  1.72s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:52<01:24,  1.76s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:54<01:23,  1.78s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:56<01:21,  1.77s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:57<01:14,  1.66s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:59<01:11,  1.62s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:00<01:07,  1.56s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:02<01:04,  1.54s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:04<01:07,  1.66s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:05<01:03,  1.58s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:07<01:05,  1.69s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:09<01:06,  1.74s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:10<01:03,  1.73s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:12<00:59,  1.64s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:13<00:54,  1.57s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:15<00:51,  1.52s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:16<00:50,  1.53s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:18<00:52,  1.64s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:20<00:52,  1.70s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:22<00:50,  1.70s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:23<00:47,  1.64s/it]predicting train subjects:  90%|█████████ | 257/285 [07:25<00:44,  1.59s/it]predicting train subjects:  91%|█████████ | 258/285 [07:27<00:44,  1.67s/it]predicting train subjects:  91%|█████████ | 259/285 [07:28<00:43,  1.68s/it]predicting train subjects:  91%|█████████ | 260/285 [07:30<00:39,  1.60s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:31<00:37,  1.55s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:33<00:35,  1.53s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:34<00:33,  1.51s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:36<00:34,  1.64s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:38<00:33,  1.70s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:39<00:31,  1.63s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:41<00:28,  1.61s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:43<00:28,  1.69s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:45<00:27,  1.72s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:46<00:24,  1.65s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:48<00:22,  1.62s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:49<00:21,  1.65s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:51<00:18,  1.58s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:52<00:16,  1.53s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:54<00:16,  1.64s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:56<00:15,  1.71s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:57<00:13,  1.64s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:59<00:11,  1.59s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:01<00:09,  1.63s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:02<00:07,  1.57s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:03<00:06,  1.54s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:05<00:04,  1.52s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:07<00:03,  1.63s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:09<00:01,  1.71s/it]predicting train subjects: 100%|██████████| 285/285 [08:11<00:00,  1.76s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:17,  1.54s/it]Loading train:   1%|          | 2/285 [00:02<06:46,  1.44s/it]Loading train:   1%|          | 3/285 [00:04<06:40,  1.42s/it]Loading train:   1%|▏         | 4/285 [00:05<06:04,  1.30s/it]Loading train:   2%|▏         | 5/285 [00:06<06:09,  1.32s/it]Loading train:   2%|▏         | 6/285 [00:07<05:54,  1.27s/it]Loading train:   2%|▏         | 7/285 [00:09<06:05,  1.31s/it]Loading train:   3%|▎         | 8/285 [00:10<06:03,  1.31s/it]Loading train:   3%|▎         | 9/285 [00:11<06:22,  1.39s/it]Loading train:   4%|▎         | 10/285 [00:13<05:58,  1.30s/it]Loading train:   4%|▍         | 11/285 [00:14<05:31,  1.21s/it]Loading train:   4%|▍         | 12/285 [00:15<05:34,  1.23s/it]Loading train:   5%|▍         | 13/285 [00:16<05:09,  1.14s/it]Loading train:   5%|▍         | 14/285 [00:17<05:04,  1.12s/it]Loading train:   5%|▌         | 15/285 [00:18<04:56,  1.10s/it]Loading train:   6%|▌         | 16/285 [00:19<04:54,  1.10s/it]Loading train:   6%|▌         | 17/285 [00:20<04:31,  1.01s/it]Loading train:   6%|▋         | 18/285 [00:21<04:30,  1.01s/it]Loading train:   7%|▋         | 19/285 [00:22<04:12,  1.06it/s]Loading train:   7%|▋         | 20/285 [00:22<04:03,  1.09it/s]Loading train:   7%|▋         | 21/285 [00:23<04:04,  1.08it/s]Loading train:   8%|▊         | 22/285 [00:24<03:51,  1.14it/s]Loading train:   8%|▊         | 23/285 [00:25<03:48,  1.15it/s]Loading train:   8%|▊         | 24/285 [00:26<03:35,  1.21it/s]Loading train:   9%|▉         | 25/285 [00:27<03:42,  1.17it/s]Loading train:   9%|▉         | 26/285 [00:28<03:49,  1.13it/s]Loading train:   9%|▉         | 27/285 [00:28<03:34,  1.20it/s]Loading train:  10%|▉         | 28/285 [00:29<03:39,  1.17it/s]Loading train:  10%|█         | 29/285 [00:30<03:31,  1.21it/s]Loading train:  11%|█         | 30/285 [00:31<03:37,  1.17it/s]Loading train:  11%|█         | 31/285 [00:32<03:41,  1.15it/s]Loading train:  11%|█         | 32/285 [00:33<03:30,  1.20it/s]Loading train:  12%|█▏        | 33/285 [00:33<03:28,  1.21it/s]Loading train:  12%|█▏        | 34/285 [00:34<03:23,  1.23it/s]Loading train:  12%|█▏        | 35/285 [00:35<03:28,  1.20it/s]Loading train:  13%|█▎        | 36/285 [00:36<03:19,  1.25it/s]Loading train:  13%|█▎        | 37/285 [00:37<03:19,  1.24it/s]Loading train:  13%|█▎        | 38/285 [00:37<03:24,  1.21it/s]Loading train:  14%|█▎        | 39/285 [00:38<03:13,  1.27it/s]Loading train:  14%|█▍        | 40/285 [00:39<03:16,  1.25it/s]Loading train:  14%|█▍        | 41/285 [00:40<03:09,  1.28it/s]Loading train:  15%|█▍        | 42/285 [00:40<03:05,  1.31it/s]Loading train:  15%|█▌        | 43/285 [00:41<03:05,  1.31it/s]Loading train:  15%|█▌        | 44/285 [00:42<03:11,  1.26it/s]Loading train:  16%|█▌        | 45/285 [00:43<03:05,  1.29it/s]Loading train:  16%|█▌        | 46/285 [00:44<03:11,  1.25it/s]Loading train:  16%|█▋        | 47/285 [00:44<03:07,  1.27it/s]Loading train:  17%|█▋        | 48/285 [00:45<03:14,  1.22it/s]Loading train:  17%|█▋        | 49/285 [00:46<03:30,  1.12it/s]Loading train:  18%|█▊        | 50/285 [00:47<03:27,  1.13it/s]Loading train:  18%|█▊        | 51/285 [00:48<03:39,  1.07it/s]Loading train:  18%|█▊        | 52/285 [00:49<03:25,  1.14it/s]Loading train:  19%|█▊        | 53/285 [00:50<03:19,  1.16it/s]Loading train:  19%|█▉        | 54/285 [00:51<03:26,  1.12it/s]Loading train:  19%|█▉        | 55/285 [00:52<03:20,  1.14it/s]Loading train:  20%|█▉        | 56/285 [00:52<03:16,  1.17it/s]Loading train:  20%|██        | 57/285 [00:53<03:17,  1.16it/s]Loading train:  20%|██        | 58/285 [00:54<03:07,  1.21it/s]Loading train:  21%|██        | 59/285 [00:55<03:10,  1.18it/s]Loading train:  21%|██        | 60/285 [00:56<03:13,  1.16it/s]Loading train:  21%|██▏       | 61/285 [00:57<03:05,  1.20it/s]Loading train:  22%|██▏       | 62/285 [00:57<03:03,  1.21it/s]Loading train:  22%|██▏       | 63/285 [00:58<03:04,  1.21it/s]Loading train:  22%|██▏       | 64/285 [01:00<03:29,  1.05it/s]Loading train:  23%|██▎       | 65/285 [01:01<04:00,  1.09s/it]Loading train:  23%|██▎       | 66/285 [01:02<04:00,  1.10s/it]Loading train:  24%|██▎       | 67/285 [01:03<03:36,  1.01it/s]Loading train:  24%|██▍       | 68/285 [01:03<03:16,  1.10it/s]Loading train:  24%|██▍       | 69/285 [01:04<03:13,  1.12it/s]Loading train:  25%|██▍       | 70/285 [01:05<03:12,  1.12it/s]Loading train:  25%|██▍       | 71/285 [01:06<03:16,  1.09it/s]Loading train:  25%|██▌       | 72/285 [01:07<03:08,  1.13it/s]Loading train:  26%|██▌       | 73/285 [01:08<03:09,  1.12it/s]Loading train:  26%|██▌       | 74/285 [01:09<03:10,  1.11it/s]Loading train:  26%|██▋       | 75/285 [01:10<03:07,  1.12it/s]Loading train:  27%|██▋       | 76/285 [01:11<03:06,  1.12it/s]Loading train:  27%|██▋       | 77/285 [01:11<02:59,  1.16it/s]Loading train:  27%|██▋       | 78/285 [01:12<02:47,  1.24it/s]Loading train:  28%|██▊       | 79/285 [01:13<02:50,  1.21it/s]Loading train:  28%|██▊       | 80/285 [01:14<02:59,  1.14it/s]Loading train:  28%|██▊       | 81/285 [01:15<02:50,  1.20it/s]Loading train:  29%|██▉       | 82/285 [01:16<02:50,  1.19it/s]Loading train:  29%|██▉       | 83/285 [01:16<02:44,  1.23it/s]Loading train:  29%|██▉       | 84/285 [01:17<02:34,  1.30it/s]Loading train:  30%|██▉       | 85/285 [01:18<02:38,  1.26it/s]Loading train:  30%|███       | 86/285 [01:19<02:47,  1.19it/s]Loading train:  31%|███       | 87/285 [01:20<02:49,  1.17it/s]Loading train:  31%|███       | 88/285 [01:20<02:45,  1.19it/s]Loading train:  31%|███       | 89/285 [01:21<02:49,  1.15it/s]Loading train:  32%|███▏      | 90/285 [01:22<02:47,  1.17it/s]Loading train:  32%|███▏      | 91/285 [01:23<02:41,  1.20it/s]Loading train:  32%|███▏      | 92/285 [01:24<02:48,  1.15it/s]Loading train:  33%|███▎      | 93/285 [01:25<02:42,  1.18it/s]Loading train:  33%|███▎      | 94/285 [01:26<02:44,  1.16it/s]Loading train:  33%|███▎      | 95/285 [01:27<02:43,  1.17it/s]Loading train:  34%|███▎      | 96/285 [01:27<02:42,  1.16it/s]Loading train:  34%|███▍      | 97/285 [01:28<02:46,  1.13it/s]Loading train:  34%|███▍      | 98/285 [01:29<02:47,  1.12it/s]Loading train:  35%|███▍      | 99/285 [01:30<02:45,  1.12it/s]Loading train:  35%|███▌      | 100/285 [01:31<02:50,  1.09it/s]Loading train:  35%|███▌      | 101/285 [01:32<02:43,  1.12it/s]Loading train:  36%|███▌      | 102/285 [01:33<02:43,  1.12it/s]Loading train:  36%|███▌      | 103/285 [01:34<02:38,  1.15it/s]Loading train:  36%|███▋      | 104/285 [01:35<02:43,  1.11it/s]Loading train:  37%|███▋      | 105/285 [01:35<02:39,  1.13it/s]Loading train:  37%|███▋      | 106/285 [01:36<02:38,  1.13it/s]Loading train:  38%|███▊      | 107/285 [01:37<02:43,  1.09it/s]Loading train:  38%|███▊      | 108/285 [01:38<02:41,  1.10it/s]Loading train:  38%|███▊      | 109/285 [01:39<02:39,  1.10it/s]Loading train:  39%|███▊      | 110/285 [01:40<02:35,  1.12it/s]Loading train:  39%|███▉      | 111/285 [01:41<02:32,  1.14it/s]Loading train:  39%|███▉      | 112/285 [01:42<02:36,  1.11it/s]Loading train:  40%|███▉      | 113/285 [01:43<02:30,  1.14it/s]Loading train:  40%|████      | 114/285 [01:43<02:28,  1.15it/s]Loading train:  40%|████      | 115/285 [01:44<02:30,  1.13it/s]Loading train:  41%|████      | 116/285 [01:45<02:31,  1.11it/s]Loading train:  41%|████      | 117/285 [01:46<02:24,  1.16it/s]Loading train:  41%|████▏     | 118/285 [01:47<02:19,  1.20it/s]Loading train:  42%|████▏     | 119/285 [01:48<02:19,  1.19it/s]Loading train:  42%|████▏     | 120/285 [01:48<02:12,  1.24it/s]Loading train:  42%|████▏     | 121/285 [01:50<02:32,  1.07it/s]Loading train:  43%|████▎     | 122/285 [01:51<02:39,  1.02it/s]Loading train:  43%|████▎     | 123/285 [01:52<02:45,  1.02s/it]Loading train:  44%|████▎     | 124/285 [01:53<02:38,  1.02it/s]Loading train:  44%|████▍     | 125/285 [01:54<02:26,  1.09it/s]Loading train:  44%|████▍     | 126/285 [01:54<02:21,  1.13it/s]Loading train:  45%|████▍     | 127/285 [01:55<02:14,  1.18it/s]Loading train:  45%|████▍     | 128/285 [01:56<02:13,  1.17it/s]Loading train:  45%|████▌     | 129/285 [01:57<02:10,  1.19it/s]Loading train:  46%|████▌     | 130/285 [01:58<02:05,  1.23it/s]Loading train:  46%|████▌     | 131/285 [01:58<02:02,  1.26it/s]Loading train:  46%|████▋     | 132/285 [01:59<02:05,  1.22it/s]Loading train:  47%|████▋     | 133/285 [02:00<02:02,  1.24it/s]Loading train:  47%|████▋     | 134/285 [02:01<01:55,  1.30it/s]Loading train:  47%|████▋     | 135/285 [02:01<01:53,  1.32it/s]Loading train:  48%|████▊     | 136/285 [02:02<01:50,  1.35it/s]Loading train:  48%|████▊     | 137/285 [02:03<01:53,  1.30it/s]Loading train:  48%|████▊     | 138/285 [02:04<01:53,  1.29it/s]Loading train:  49%|████▉     | 139/285 [02:05<01:55,  1.26it/s]Loading train:  49%|████▉     | 140/285 [02:05<01:55,  1.25it/s]Loading train:  49%|████▉     | 141/285 [02:06<01:52,  1.28it/s]Loading train:  50%|████▉     | 142/285 [02:07<01:47,  1.33it/s]Loading train:  50%|█████     | 143/285 [02:08<01:49,  1.29it/s]Loading train:  51%|█████     | 144/285 [02:08<01:49,  1.28it/s]Loading train:  51%|█████     | 145/285 [02:09<01:47,  1.30it/s]Loading train:  51%|█████     | 146/285 [02:10<01:53,  1.23it/s]Loading train:  52%|█████▏    | 147/285 [02:11<01:51,  1.24it/s]Loading train:  52%|█████▏    | 148/285 [02:12<01:51,  1.23it/s]Loading train:  52%|█████▏    | 149/285 [02:12<01:47,  1.26it/s]Loading train:  53%|█████▎    | 150/285 [02:13<01:45,  1.28it/s]Loading train:  53%|█████▎    | 151/285 [02:14<01:46,  1.25it/s]Loading train:  53%|█████▎    | 152/285 [02:15<01:44,  1.28it/s]Loading train:  54%|█████▎    | 153/285 [02:15<01:40,  1.31it/s]Loading train:  54%|█████▍    | 154/285 [02:16<01:45,  1.24it/s]Loading train:  54%|█████▍    | 155/285 [02:17<01:45,  1.23it/s]Loading train:  55%|█████▍    | 156/285 [02:18<01:43,  1.24it/s]Loading train:  55%|█████▌    | 157/285 [02:19<01:40,  1.28it/s]Loading train:  55%|█████▌    | 158/285 [02:20<01:40,  1.27it/s]Loading train:  56%|█████▌    | 159/285 [02:20<01:41,  1.24it/s]Loading train:  56%|█████▌    | 160/285 [02:21<01:41,  1.24it/s]Loading train:  56%|█████▋    | 161/285 [02:22<01:42,  1.21it/s]Loading train:  57%|█████▋    | 162/285 [02:23<01:42,  1.20it/s]Loading train:  57%|█████▋    | 163/285 [02:24<01:42,  1.19it/s]Loading train:  58%|█████▊    | 164/285 [02:25<01:42,  1.18it/s]Loading train:  58%|█████▊    | 165/285 [02:25<01:42,  1.17it/s]Loading train:  58%|█████▊    | 166/285 [02:26<01:42,  1.16it/s]Loading train:  59%|█████▊    | 167/285 [02:27<01:42,  1.15it/s]Loading train:  59%|█████▉    | 168/285 [02:28<01:38,  1.19it/s]Loading train:  59%|█████▉    | 169/285 [02:29<01:37,  1.19it/s]Loading train:  60%|█████▉    | 170/285 [02:30<01:30,  1.27it/s]Loading train:  60%|██████    | 171/285 [02:30<01:28,  1.29it/s]Loading train:  60%|██████    | 172/285 [02:31<01:25,  1.32it/s]Loading train:  61%|██████    | 173/285 [02:32<01:25,  1.31it/s]Loading train:  61%|██████    | 174/285 [02:33<01:26,  1.29it/s]Loading train:  61%|██████▏   | 175/285 [02:33<01:23,  1.31it/s]Loading train:  62%|██████▏   | 176/285 [02:34<01:28,  1.23it/s]Loading train:  62%|██████▏   | 177/285 [02:35<01:24,  1.28it/s]Loading train:  62%|██████▏   | 178/285 [02:36<01:23,  1.29it/s]Loading train:  63%|██████▎   | 179/285 [02:37<01:23,  1.28it/s]Loading train:  63%|██████▎   | 180/285 [02:37<01:25,  1.23it/s]Loading train:  64%|██████▎   | 181/285 [02:38<01:26,  1.20it/s]Loading train:  64%|██████▍   | 182/285 [02:39<01:24,  1.22it/s]Loading train:  64%|██████▍   | 183/285 [02:40<01:20,  1.27it/s]Loading train:  65%|██████▍   | 184/285 [02:41<01:19,  1.27it/s]Loading train:  65%|██████▍   | 185/285 [02:41<01:18,  1.27it/s]Loading train:  65%|██████▌   | 186/285 [02:42<01:21,  1.22it/s]Loading train:  66%|██████▌   | 187/285 [02:43<01:20,  1.22it/s]Loading train:  66%|██████▌   | 188/285 [02:44<01:20,  1.20it/s]Loading train:  66%|██████▋   | 189/285 [02:45<01:16,  1.25it/s]Loading train:  67%|██████▋   | 190/285 [02:45<01:13,  1.30it/s]Loading train:  67%|██████▋   | 191/285 [02:46<01:14,  1.26it/s]Loading train:  67%|██████▋   | 192/285 [02:47<01:14,  1.24it/s]Loading train:  68%|██████▊   | 193/285 [02:48<01:08,  1.35it/s]Loading train:  68%|██████▊   | 194/285 [02:48<01:06,  1.36it/s]Loading train:  68%|██████▊   | 195/285 [02:49<01:02,  1.43it/s]Loading train:  69%|██████▉   | 196/285 [02:50<01:04,  1.37it/s]Loading train:  69%|██████▉   | 197/285 [02:51<01:05,  1.35it/s]Loading train:  69%|██████▉   | 198/285 [02:51<01:09,  1.25it/s]Loading train:  70%|██████▉   | 199/285 [02:52<01:06,  1.29it/s]Loading train:  70%|███████   | 200/285 [02:53<01:05,  1.30it/s]Loading train:  71%|███████   | 201/285 [02:54<01:10,  1.19it/s]Loading train:  71%|███████   | 202/285 [02:55<01:10,  1.18it/s]Loading train:  71%|███████   | 203/285 [02:56<01:10,  1.17it/s]Loading train:  72%|███████▏  | 204/285 [02:56<01:05,  1.23it/s]Loading train:  72%|███████▏  | 205/285 [02:57<01:03,  1.26it/s]Loading train:  72%|███████▏  | 206/285 [02:58<00:59,  1.33it/s]Loading train:  73%|███████▎  | 207/285 [02:59<01:02,  1.24it/s]Loading train:  73%|███████▎  | 208/285 [03:00<01:05,  1.17it/s]Loading train:  73%|███████▎  | 209/285 [03:01<01:08,  1.11it/s]Loading train:  74%|███████▎  | 210/285 [03:01<01:03,  1.19it/s]Loading train:  74%|███████▍  | 211/285 [03:02<01:00,  1.21it/s]Loading train:  74%|███████▍  | 212/285 [03:03<01:02,  1.17it/s]Loading train:  75%|███████▍  | 213/285 [03:04<01:01,  1.17it/s]Loading train:  75%|███████▌  | 214/285 [03:05<00:56,  1.26it/s]Loading train:  75%|███████▌  | 215/285 [03:05<00:57,  1.22it/s]Loading train:  76%|███████▌  | 216/285 [03:06<00:56,  1.22it/s]Loading train:  76%|███████▌  | 217/285 [03:07<00:56,  1.20it/s]Loading train:  76%|███████▋  | 218/285 [03:08<00:56,  1.18it/s]Loading train:  77%|███████▋  | 219/285 [03:09<00:55,  1.18it/s]Loading train:  77%|███████▋  | 220/285 [03:10<00:52,  1.25it/s]Loading train:  78%|███████▊  | 221/285 [03:10<00:49,  1.30it/s]Loading train:  78%|███████▊  | 222/285 [03:11<00:48,  1.30it/s]Loading train:  78%|███████▊  | 223/285 [03:12<00:45,  1.35it/s]Loading train:  79%|███████▊  | 224/285 [03:12<00:43,  1.39it/s]Loading train:  79%|███████▉  | 225/285 [03:13<00:44,  1.35it/s]Loading train:  79%|███████▉  | 226/285 [03:14<00:46,  1.26it/s]Loading train:  80%|███████▉  | 227/285 [03:15<00:49,  1.18it/s]Loading train:  80%|████████  | 228/285 [03:16<00:50,  1.13it/s]Loading train:  80%|████████  | 229/285 [03:17<00:49,  1.13it/s]Loading train:  81%|████████  | 230/285 [03:18<00:44,  1.24it/s]Loading train:  81%|████████  | 231/285 [03:18<00:42,  1.27it/s]Loading train:  81%|████████▏ | 232/285 [03:19<00:44,  1.19it/s]Loading train:  82%|████████▏ | 233/285 [03:20<00:42,  1.22it/s]Loading train:  82%|████████▏ | 234/285 [03:21<00:43,  1.18it/s]Loading train:  82%|████████▏ | 235/285 [03:22<00:41,  1.20it/s]Loading train:  83%|████████▎ | 236/285 [03:23<00:41,  1.17it/s]Loading train:  83%|████████▎ | 237/285 [03:23<00:40,  1.19it/s]Loading train:  84%|████████▎ | 238/285 [03:24<00:41,  1.12it/s]Loading train:  84%|████████▍ | 239/285 [03:25<00:40,  1.15it/s]Loading train:  84%|████████▍ | 240/285 [03:26<00:38,  1.16it/s]Loading train:  85%|████████▍ | 241/285 [03:27<00:37,  1.18it/s]Loading train:  85%|████████▍ | 242/285 [03:28<00:33,  1.27it/s]Loading train:  85%|████████▌ | 243/285 [03:28<00:32,  1.28it/s]Loading train:  86%|████████▌ | 244/285 [03:29<00:33,  1.21it/s]Loading train:  86%|████████▌ | 245/285 [03:30<00:31,  1.26it/s]Loading train:  86%|████████▋ | 246/285 [03:31<00:33,  1.17it/s]Loading train:  87%|████████▋ | 247/285 [03:32<00:33,  1.14it/s]Loading train:  87%|████████▋ | 248/285 [03:33<00:31,  1.16it/s]Loading train:  87%|████████▋ | 249/285 [03:34<00:31,  1.14it/s]Loading train:  88%|████████▊ | 250/285 [03:34<00:29,  1.19it/s]Loading train:  88%|████████▊ | 251/285 [03:35<00:26,  1.27it/s]Loading train:  88%|████████▊ | 252/285 [03:36<00:26,  1.25it/s]Loading train:  89%|████████▉ | 253/285 [03:37<00:26,  1.20it/s]Loading train:  89%|████████▉ | 254/285 [03:38<00:27,  1.13it/s]Loading train:  89%|████████▉ | 255/285 [03:39<00:25,  1.17it/s]Loading train:  90%|████████▉ | 256/285 [03:39<00:24,  1.17it/s]Loading train:  90%|█████████ | 257/285 [03:40<00:23,  1.19it/s]Loading train:  91%|█████████ | 258/285 [03:41<00:23,  1.13it/s]Loading train:  91%|█████████ | 259/285 [03:42<00:22,  1.17it/s]Loading train:  91%|█████████ | 260/285 [03:43<00:20,  1.24it/s]Loading train:  92%|█████████▏| 261/285 [03:44<00:19,  1.26it/s]Loading train:  92%|█████████▏| 262/285 [03:44<00:18,  1.27it/s]Loading train:  92%|█████████▏| 263/285 [03:45<00:17,  1.29it/s]Loading train:  93%|█████████▎| 264/285 [03:46<00:16,  1.25it/s]Loading train:  93%|█████████▎| 265/285 [03:47<00:16,  1.23it/s]Loading train:  93%|█████████▎| 266/285 [03:47<00:14,  1.30it/s]Loading train:  94%|█████████▎| 267/285 [03:48<00:13,  1.33it/s]Loading train:  94%|█████████▍| 268/285 [03:49<00:13,  1.23it/s]Loading train:  94%|█████████▍| 269/285 [03:50<00:12,  1.23it/s]Loading train:  95%|█████████▍| 270/285 [03:51<00:11,  1.31it/s]Loading train:  95%|█████████▌| 271/285 [03:51<00:10,  1.36it/s]Loading train:  95%|█████████▌| 272/285 [03:52<00:09,  1.32it/s]Loading train:  96%|█████████▌| 273/285 [03:53<00:08,  1.38it/s]Loading train:  96%|█████████▌| 274/285 [03:53<00:07,  1.40it/s]Loading train:  96%|█████████▋| 275/285 [03:54<00:07,  1.33it/s]Loading train:  97%|█████████▋| 276/285 [03:55<00:07,  1.24it/s]Loading train:  97%|█████████▋| 277/285 [03:56<00:06,  1.25it/s]Loading train:  98%|█████████▊| 278/285 [03:57<00:05,  1.29it/s]Loading train:  98%|█████████▊| 279/285 [03:58<00:04,  1.23it/s]Loading train:  98%|█████████▊| 280/285 [03:58<00:03,  1.30it/s]Loading train:  99%|█████████▊| 281/285 [03:59<00:03,  1.29it/s]Loading train:  99%|█████████▉| 282/285 [04:00<00:02,  1.32it/s]Loading train:  99%|█████████▉| 283/285 [04:01<00:01,  1.26it/s]Loading train: 100%|█████████▉| 284/285 [04:01<00:00,  1.23it/s]Loading train: 100%|██████████| 285/285 [04:02<00:00,  1.16it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   4%|▍         | 12/285 [00:00<00:02, 116.69it/s]concatenating: train:  16%|█▌        | 45/285 [00:00<00:01, 144.50it/s]concatenating: train:  26%|██▌       | 74/285 [00:00<00:01, 169.82it/s]concatenating: train:  36%|███▋      | 104/285 [00:00<00:00, 195.18it/s]concatenating: train:  48%|████▊     | 137/285 [00:00<00:00, 221.68it/s]concatenating: train:  59%|█████▉    | 168/285 [00:00<00:00, 240.84it/s]concatenating: train:  71%|███████   | 201/285 [00:00<00:00, 261.14it/s]concatenating: train:  82%|████████▏ | 234/285 [00:00<00:00, 277.23it/s]concatenating: train:  95%|█████████▌| 271/285 [00:00<00:00, 298.61it/s]concatenating: train: 100%|██████████| 285/285 [00:00<00:00, 301.32it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.24s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.21s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.17s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 173.68it/s]2019-07-11 08:44:55.038820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 08:44:55.038974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 08:44:55.039004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 08:44:55.039015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 08:44:55.039437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.77it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.64it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.34it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.84it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  6.06it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  6.87it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.20it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.01it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.48it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.82it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.33it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  8.69it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  8.81it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.06it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.72it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.91it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.16it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.32it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.09it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 26, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 26, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 26, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 26, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 13, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 13, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 13, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 20, 13, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 40, 26, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 40, 26, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 40, 26, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 80, 52, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 80, 52, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 52, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 80, 52, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 40)   21640       dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 40)   160         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 40)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 80, 52, 40)   0           activation_11[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 40)   14440       dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 80, 52, 40)   160         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 52, 40)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 80, 52, 40)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 100)  0           dropout_5[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 52, 13)   1313        concatenate_7[0][0]              
==================================================================================================
Total params: 260,753
Trainable params: 85,913
Non-trainable params: 174,840
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 18s - loss: 2.5240 - acc: 0.6982 - mDice: 0.1423 - val_loss: 2.1986 - val_acc: 0.9033 - val_mDice: 0.2102

Epoch 00001: val_mDice improved from -inf to 0.21019, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 13s - loss: 0.8515 - acc: 0.8821 - mDice: 0.4180 - val_loss: 1.1477 - val_acc: 0.9064 - val_mDice: 0.4126

Epoch 00002: val_mDice improved from 0.21019 to 0.41263, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 13s - loss: 0.6641 - acc: 0.8936 - mDice: 0.5013 - val_loss: 1.0349 - val_acc: 0.9161 - val_mDice: 0.4458

Epoch 00003: val_mDice improved from 0.41263 to 0.44582, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 13s - loss: 0.5812 - acc: 0.9177 - mDice: 0.5439 - val_loss: 0.9059 - val_acc: 0.9322 - val_mDice: 0.5014

Epoch 00004: val_mDice improved from 0.44582 to 0.50137, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 13s - loss: 0.5262 - acc: 0.9267 - mDice: 0.5743 - val_loss: 1.0052 - val_acc: 0.9337 - val_mDice: 0.4722

Epoch 00005: val_mDice did not improve from 0.50137
Epoch 6/300
 - 12s - loss: 0.4905 - acc: 0.9297 - mDice: 0.5955 - val_loss: 0.8511 - val_acc: 0.9380 - val_mDice: 0.5266

Epoch 00006: val_mDice improved from 0.50137 to 0.52658, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 13s - loss: 0.4657 - acc: 0.9320 - mDice: 0.6112 - val_loss: 0.7612 - val_acc: 0.9348 - val_mDice: 0.5576

Epoch 00007: val_mDice improved from 0.52658 to 0.55762, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 12s - loss: 0.4457 - acc: 0.9338 - mDice: 0.6239 - val_loss: 0.9478 - val_acc: 0.9375 - val_mDice: 0.4896

Epoch 00008: val_mDice did not improve from 0.55762
Epoch 9/300
 - 12s - loss: 0.4270 - acc: 0.9353 - mDice: 0.6361 - val_loss: 0.7751 - val_acc: 0.9395 - val_mDice: 0.5546

Epoch 00009: val_mDice did not improve from 0.55762
Epoch 10/300
 - 13s - loss: 0.4168 - acc: 0.9363 - mDice: 0.6429 - val_loss: 0.7772 - val_acc: 0.9415 - val_mDice: 0.5699

Epoch 00010: val_mDice improved from 0.55762 to 0.56990, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 13s - loss: 0.4034 - acc: 0.9375 - mDice: 0.6518 - val_loss: 0.7921 - val_acc: 0.9423 - val_mDice: 0.5623

Epoch 00011: val_mDice did not improve from 0.56990
Epoch 12/300
 - 13s - loss: 0.3949 - acc: 0.9383 - mDice: 0.6578 - val_loss: 0.8425 - val_acc: 0.9355 - val_mDice: 0.5349

Epoch 00012: val_mDice did not improve from 0.56990
Epoch 13/300
 - 13s - loss: 0.3863 - acc: 0.9390 - mDice: 0.6635 - val_loss: 0.7941 - val_acc: 0.9407 - val_mDice: 0.5670

Epoch 00013: val_mDice did not improve from 0.56990
Epoch 14/300
 - 13s - loss: 0.3767 - acc: 0.9398 - mDice: 0.6703 - val_loss: 0.8651 - val_acc: 0.9423 - val_mDice: 0.5348

Epoch 00014: val_mDice did not improve from 0.56990
Epoch 15/300
 - 13s - loss: 0.3742 - acc: 0.9401 - mDice: 0.6721 - val_loss: 0.7876 - val_acc: 0.9352 - val_mDice: 0.5563

Epoch 00015: val_mDice did not improve from 0.56990
Epoch 16/300
 - 13s - loss: 0.3684 - acc: 0.9406 - mDice: 0.6763 - val_loss: 0.7556 - val_acc: 0.9400 - val_mDice: 0.5755

Epoch 00016: val_mDice improved from 0.56990 to 0.57549, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 12s - loss: 0.3626 - acc: 0.9412 - mDice: 0.6803 - val_loss: 0.7918 - val_acc: 0.9415 - val_mDice: 0.5718

Epoch 00017: val_mDice did not improve from 0.57549
Epoch 18/300
 - 13s - loss: 0.3560 - acc: 0.9417 - mDice: 0.6849 - val_loss: 0.7833 - val_acc: 0.9401 - val_mDice: 0.5778

Epoch 00018: val_mDice improved from 0.57549 to 0.57782, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 19/300
 - 13s - loss: 0.3535 - acc: 0.9419 - mDice: 0.6868 - val_loss: 0.7741 - val_acc: 0.9384 - val_mDice: 0.5724

Epoch 00019: val_mDice did not improve from 0.57782
Epoch 20/300
 - 13s - loss: 0.3484 - acc: 0.9423 - mDice: 0.6905 - val_loss: 0.7875 - val_acc: 0.9423 - val_mDice: 0.5731

Epoch 00020: val_mDice did not improve from 0.57782
Epoch 21/300
 - 13s - loss: 0.3491 - acc: 0.9426 - mDice: 0.6919 - val_loss: 0.8324 - val_acc: 0.9362 - val_mDice: 0.5540

Epoch 00021: val_mDice did not improve from 0.57782
Epoch 22/300
 - 12s - loss: 0.4209 - acc: 0.9355 - mDice: 0.6453 - val_loss: 0.7965 - val_acc: 0.9397 - val_mDice: 0.5784

Epoch 00022: val_mDice improved from 0.57782 to 0.57842, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 23/300
 - 12s - loss: 0.3542 - acc: 0.9414 - mDice: 0.6861 - val_loss: 0.8108 - val_acc: 0.9413 - val_mDice: 0.5539

Epoch 00023: val_mDice did not improve from 0.57842
Epoch 24/300
 - 13s - loss: 0.3459 - acc: 0.9424 - mDice: 0.6923 - val_loss: 0.7954 - val_acc: 0.9413 - val_mDice: 0.5702

Epoch 00024: val_mDice did not improve from 0.57842
Epoch 25/300
 - 13s - loss: 0.3409 - acc: 0.9429 - mDice: 0.6959 - val_loss: 0.8062 - val_acc: 0.9412 - val_mDice: 0.5621

Epoch 00025: val_mDice did not improve from 0.57842
Epoch 26/300
 - 12s - loss: 0.3354 - acc: 0.9433 - mDice: 0.6999 - val_loss: 0.8550 - val_acc: 0.9390 - val_mDice: 0.5267

Epoch 00026: val_mDice did not improve from 0.57842
Epoch 27/300
 - 12s - loss: 0.3320 - acc: 0.9437 - mDice: 0.7025 - val_loss: 0.8362 - val_acc: 0.9417 - val_mDice: 0.5493

Epoch 00027: val_mDice did not improve from 0.57842
Epoch 28/300
 - 13s - loss: 0.3317 - acc: 0.9438 - mDice: 0.7028 - val_loss: 0.8004 - val_acc: 0.9425 - val_mDice: 0.5732

Epoch 00028: val_mDice did not improve from 0.57842
Epoch 29/300
 - 13s - loss: 0.3272 - acc: 0.9442 - mDice: 0.7061 - val_loss: 0.8092 - val_acc: 0.9441 - val_mDice: 0.5650

Epoch 00029: val_mDice did not improve from 0.57842
Epoch 30/300
 - 13s - loss: 0.3246 - acc: 0.9443 - mDice: 0.7081 - val_loss: 0.8331 - val_acc: 0.9422 - val_mDice: 0.5631

Epoch 00030: val_mDice did not improve from 0.57842
Epoch 31/300
 - 13s - loss: 0.3240 - acc: 0.9445 - mDice: 0.7086 - val_loss: 0.8790 - val_acc: 0.9422 - val_mDice: 0.5241

Epoch 00031: val_mDice did not improve from 0.57842
Epoch 32/300
 - 12s - loss: 0.3202 - acc: 0.9447 - mDice: 0.7112 - val_loss: 0.8075 - val_acc: 0.9440 - val_mDice: 0.5641

Epoch 00032: val_mDice did not improve from 0.57842
Epoch 33/300
 - 13s - loss: 0.3174 - acc: 0.9449 - mDice: 0.7133 - val_loss: 0.7916 - val_acc: 0.9411 - val_mDice: 0.5747

Epoch 00033: val_mDice did not improve from 0.57842
Epoch 34/300
 - 13s - loss: 0.3169 - acc: 0.9451 - mDice: 0.7137 - val_loss: 0.7797 - val_acc: 0.9429 - val_mDice: 0.5817

Epoch 00034: val_mDice improved from 0.57842 to 0.58168, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 35/300
 - 13s - loss: 0.3184 - acc: 0.9449 - mDice: 0.7127 - val_loss: 0.7738 - val_acc: 0.9401 - val_mDice: 0.5668

Epoch 00035: val_mDice did not improve from 0.58168
Epoch 36/300
 - 13s - loss: 0.3150 - acc: 0.9451 - mDice: 0.7151 - val_loss: 0.7930 - val_acc: 0.9405 - val_mDice: 0.5682

Epoch 00036: val_mDice did not improve from 0.58168
Epoch 37/300
 - 13s - loss: 0.3128 - acc: 0.9452 - mDice: 0.7168 - val_loss: 0.7781 - val_acc: 0.9431 - val_mDice: 0.5686

Epoch 00037: val_mDice did not improve from 0.58168
Epoch 38/300
 - 13s - loss: 0.3125 - acc: 0.9455 - mDice: 0.7171 - val_loss: 0.8029 - val_acc: 0.9411 - val_mDice: 0.5605

Epoch 00038: val_mDice did not improve from 0.58168
Epoch 39/300
 - 13s - loss: 0.3117 - acc: 0.9454 - mDice: 0.7176 - val_loss: 0.7948 - val_acc: 0.9438 - val_mDice: 0.5675

Epoch 00039: val_mDice did not improve from 0.58168
Epoch 40/300
 - 12s - loss: 0.3079 - acc: 0.9458 - mDice: 0.7205 - val_loss: 0.8020 - val_acc: 0.9421 - val_mDice: 0.5735

Epoch 00040: val_mDice did not improve from 0.58168
Epoch 41/300
 - 13s - loss: 0.3049 - acc: 0.9460 - mDice: 0.7227 - val_loss: 0.8187 - val_acc: 0.9422 - val_mDice: 0.5698

Epoch 00041: val_mDice did not improve from 0.58168
Epoch 42/300
 - 13s - loss: 0.3056 - acc: 0.9460 - mDice: 0.7223 - val_loss: 0.7933 - val_acc: 0.9442 - val_mDice: 0.5802

Epoch 00042: val_mDice did not improve from 0.58168
Epoch 43/300
 - 13s - loss: 0.3026 - acc: 0.9461 - mDice: 0.7245 - val_loss: 0.7996 - val_acc: 0.9427 - val_mDice: 0.5721

Epoch 00043: val_mDice did not improve from 0.58168
Epoch 44/300
 - 13s - loss: 0.3029 - acc: 0.9462 - mDice: 0.7242 - val_loss: 0.8274 - val_acc: 0.9411 - val_mDice: 0.5638

Epoch 00044: val_mDice did not improve from 0.58168
Epoch 45/300
 - 13s - loss: 0.3013 - acc: 0.9462 - mDice: 0.7254 - val_loss: 0.8124 - val_acc: 0.9431 - val_mDice: 0.5675

Epoch 00045: val_mDice did not improve from 0.58168
Epoch 46/300
 - 13s - loss: 0.2983 - acc: 0.9464 - mDice: 0.7277 - val_loss: 0.8133 - val_acc: 0.9411 - val_mDice: 0.5654

Epoch 00046: val_mDice did not improve from 0.58168
Epoch 47/300
 - 12s - loss: 0.2982 - acc: 0.9466 - mDice: 0.7278 - val_loss: 0.7869 - val_acc: 0.9407 - val_mDice: 0.5711

Epoch 00047: val_mDice did not improve from 0.58168
Epoch 48/300
 - 13s - loss: 0.2968 - acc: 0.9467 - mDice: 0.7289 - val_loss: 0.8235 - val_acc: 0.9435 - val_mDice: 0.5650

Epoch 00048: val_mDice did not improve from 0.58168
Epoch 49/300
 - 13s - loss: 0.2956 - acc: 0.9469 - mDice: 0.7299 - val_loss: 0.8187 - val_acc: 0.9432 - val_mDice: 0.5692

Epoch 00049: val_mDice did not improve from 0.58168
Epoch 50/300
 - 14s - loss: 0.2934 - acc: 0.9469 - mDice: 0.7315 - val_loss: 0.7980 - val_acc: 0.9402 - val_mDice: 0.5647

Epoch 00050: val_mDice did not improve from 0.58168
Epoch 51/300
 - 13s - loss: 0.2936 - acc: 0.9469 - mDice: 0.7314 - val_loss: 0.8207 - val_acc: 0.9394 - val_mDice: 0.5533

Epoch 00051: val_mDice did not improve from 0.58168
Epoch 52/300
 - 14s - loss: 0.2927 - acc: 0.9470 - mDice: 0.7321 - val_loss: 0.8078 - val_acc: 0.9425 - val_mDice: 0.5696

Epoch 00052: val_mDice did not improve from 0.58168
Epoch 53/300
 - 13s - loss: 0.2908 - acc: 0.9472 - mDice: 0.7334 - val_loss: 0.7730 - val_acc: 0.9425 - val_mDice: 0.5701

Epoch 00053: val_mDice did not improve from 0.58168
Epoch 54/300
 - 14s - loss: 0.2892 - acc: 0.9472 - mDice: 0.7347 - val_loss: 0.7728 - val_acc: 0.9419 - val_mDice: 0.5781

Epoch 00054: val_mDice did not improve from 0.58168
Epoch 55/300
 - 14s - loss: 0.2894 - acc: 0.9473 - mDice: 0.7346 - val_loss: 0.8015 - val_acc: 0.9433 - val_mDice: 0.5663

Epoch 00055: val_mDice did not improve from 0.58168
Epoch 56/300
 - 13s - loss: 0.2876 - acc: 0.9474 - mDice: 0.7360 - val_loss: 0.8400 - val_acc: 0.9395 - val_mDice: 0.5476

Epoch 00056: val_mDice did not improve from 0.58168
Epoch 57/300
 - 13s - loss: 0.2860 - acc: 0.9474 - mDice: 0.7371 - val_loss: 0.8063 - val_acc: 0.9417 - val_mDice: 0.5658

Epoch 00057: val_mDice did not improve from 0.58168
Epoch 58/300
 - 14s - loss: 0.2868 - acc: 0.9475 - mDice: 0.7365 - val_loss: 0.7483 - val_acc: 0.9378 - val_mDice: 0.5653

Epoch 00058: val_mDice did not improve from 0.58168
Epoch 59/300
 - 13s - loss: 0.2849 - acc: 0.9476 - mDice: 0.7380 - val_loss: 0.7685 - val_acc: 0.9417 - val_mDice: 0.5749

Epoch 00059: val_mDice did not improve from 0.58168
Epoch 60/300
 - 14s - loss: 0.2837 - acc: 0.9477 - mDice: 0.7390 - val_loss: 0.7722 - val_acc: 0.9394 - val_mDice: 0.5741

Epoch 00060: val_mDice did not improve from 0.58168
Epoch 61/300
 - 14s - loss: 0.2838 - acc: 0.9478 - mDice: 0.7389 - val_loss: 0.7205 - val_acc: 0.9432 - val_mDice: 0.5744

Epoch 00061: val_mDice did not improve from 0.58168
Epoch 62/300
 - 14s - loss: 0.2825 - acc: 0.9479 - mDice: 0.7399 - val_loss: 0.7243 - val_acc: 0.9408 - val_mDice: 0.5648

Epoch 00062: val_mDice did not improve from 0.58168
Epoch 63/300
 - 14s - loss: 0.2809 - acc: 0.9479 - mDice: 0.7412 - val_loss: 0.7549 - val_acc: 0.9432 - val_mDice: 0.5753

Epoch 00063: val_mDice did not improve from 0.58168
Epoch 64/300
 - 14s - loss: 0.2816 - acc: 0.9479 - mDice: 0.7406 - val_loss: 0.8196 - val_acc: 0.9427 - val_mDice: 0.5431

Epoch 00064: val_mDice did not improve from 0.58168
Epoch 65/300
 - 14s - loss: 0.2794 - acc: 0.9481 - mDice: 0.7424 - val_loss: 0.7438 - val_acc: 0.9415 - val_mDice: 0.5671

Epoch 00065: val_mDice did not improve from 0.58168
Epoch 66/300
 - 13s - loss: 0.2804 - acc: 0.9479 - mDice: 0.7416 - val_loss: 0.7792 - val_acc: 0.9424 - val_mDice: 0.5587

Epoch 00066: val_mDice did not improve from 0.58168
Epoch 67/300
 - 14s - loss: 0.2779 - acc: 0.9482 - mDice: 0.7435 - val_loss: 0.7774 - val_acc: 0.9442 - val_mDice: 0.5657

Epoch 00067: val_mDice did not improve from 0.58168
Epoch 68/300
 - 13s - loss: 0.2786 - acc: 0.9482 - mDice: 0.7429 - val_loss: 0.7492 - val_acc: 0.9432 - val_mDice: 0.5747

Epoch 00068: val_mDice did not improve from 0.58168
Epoch 69/300
 - 13s - loss: 0.2767 - acc: 0.9483 - mDice: 0.7444 - val_loss: 0.7417 - val_acc: 0.9414 - val_mDice: 0.5673

Epoch 00069: val_mDice did not improve from 0.58168
Epoch 70/300
 - 12s - loss: 0.2757 - acc: 0.9484 - mDice: 0.7452 - val_loss: 0.7315 - val_acc: 0.9419 - val_mDice: 0.5743

Epoch 00070: val_mDice did not improve from 0.58168
Epoch 71/300
 - 12s - loss: 0.2759 - acc: 0.9484 - mDice: 0.7451 - val_loss: 0.7632 - val_acc: 0.9404 - val_mDice: 0.5613

Epoch 00071: val_mDice did not improve from 0.58168
Epoch 72/300
 - 13s - loss: 0.2741 - acc: 0.9486 - mDice: 0.7464 - val_loss: 0.7557 - val_acc: 0.9425 - val_mDice: 0.5808

Epoch 00072: val_mDice did not improve from 0.58168
Epoch 73/300
 - 13s - loss: 0.2748 - acc: 0.9485 - mDice: 0.7460 - val_loss: 0.7671 - val_acc: 0.9388 - val_mDice: 0.5578

Epoch 00073: val_mDice did not improve from 0.58168
Epoch 74/300
 - 12s - loss: 0.2721 - acc: 0.9487 - mDice: 0.7480 - val_loss: 0.7589 - val_acc: 0.9431 - val_mDice: 0.5686

Epoch 00074: val_mDice did not improve from 0.58168
Restoring model weights from the end of the best epoch
Epoch 00074: early stopping
{'val_loss': [2.198637389219724, 1.1477299561867347, 1.0348958923266485, 0.9058857399683732, 1.005248757509085, 0.8510682170207684, 0.7612495720386505, 0.9477624870263613, 0.7751255241724161, 0.7772209162895496, 0.7920634288054246, 0.8425423984344189, 0.794130815909459, 0.8650872294719403, 0.7875554974262531, 0.7556217507674143, 0.791771228496845, 0.783338779440293, 0.7741295466056237, 0.7875351974597344, 0.8324126142721909, 0.7965179647390659, 0.8108349625880902, 0.7954494402958796, 0.8061711467229403, 0.854958155980477, 0.8361837726372939, 0.8003617227077484, 0.8091894227724808, 0.8331039823018588, 0.8789590069880853, 0.8074903304760273, 0.7915654411682715, 0.7796861621049734, 0.7737746353332813, 0.7930274193103497, 0.7780989683591403, 0.8029018961466275, 0.794839838376412, 0.8020107700274541, 0.8187105059623718, 0.7932942119928507, 0.7996485554254972, 0.8273962140083313, 0.8123978055440463, 0.8132518117244427, 0.7868772768057309, 0.8234526446232429, 0.8187192770150992, 0.7979959089022416, 0.8206850221523871, 0.8078485085414007, 0.7729562108333294, 0.7728289583554635, 0.8014575334695669, 0.8399594792952905, 0.8062536785235772, 0.7482934296131134, 0.7684777677059174, 0.7722128217036908, 0.7204841100252591, 0.7243412756002866, 0.7548764829452221, 0.819590110045213, 0.7437704320137317, 0.7791888392888583, 0.7774413594832787, 0.7491576373577118, 0.7416795652646285, 0.7315428715485793, 0.7631793985000024, 0.7556936614788495, 0.7671096187371474, 0.7588720986476312], 'val_acc': [0.9032613612138308, 0.9063632442401006, 0.916082657300509, 0.932213863501182, 0.9337485868197221, 0.9379923412433038, 0.9348118603229523, 0.9374676507252914, 0.9394924365557157, 0.9415356814861298, 0.9423123300075531, 0.9354914014156048, 0.9407497988297389, 0.9422961565164419, 0.9351585461543157, 0.9400402284585513, 0.9414686835729159, 0.9400864472756019, 0.9384291905623215, 0.9422984490027795, 0.9362148688389704, 0.939691213461069, 0.9412907063961029, 0.941302246772326, 0.9411750848476703, 0.9390324354171753, 0.9417298321540539, 0.9424671576573298, 0.9440504839787116, 0.942201364498872, 0.9421667135678805, 0.9439533971823179, 0.9411473893202268, 0.9429363883458651, 0.9401211257164295, 0.9405417923743908, 0.9430843385366293, 0.9411034538195684, 0.9438031636751615, 0.9420857819227072, 0.9422198602786431, 0.9441983906122354, 0.9427306835467999, 0.9410803226324228, 0.943077380840595, 0.941138146015314, 0.9407497965372525, 0.9435119468432206, 0.9432091460778163, 0.9402297666439643, 0.9394300144452316, 0.9425226747989655, 0.9424995298569019, 0.941873156107389, 0.9432669144410354, 0.9394554449961736, 0.941748348566202, 0.9378490447998047, 0.9416836110445169, 0.9393907005970294, 0.9431698459845322, 0.9408075740704169, 0.9432137814851907, 0.9427329920805417, 0.94145245047716, 0.9424001276493073, 0.9442099676682398, 0.9431629135058477, 0.941366936151798, 0.9418777800523318, 0.9404377914392031, 0.9425296118626227, 0.938826744373028, 0.9430588873533102], 'val_mDice': [0.21019432636407706, 0.41263103714356053, 0.44581618905067444, 0.5013711498333857, 0.4721599037830646, 0.5265783037130649, 0.5576194748282433, 0.48962097557691425, 0.5545647797676233, 0.5698978413756077, 0.5623357318914853, 0.5349005019435515, 0.5670039825714551, 0.5348441812854546, 0.5562827014006101, 0.5754886097632922, 0.5717977698032672, 0.5778243535986314, 0.5724456986555686, 0.5731139269012672, 0.5540336920664861, 0.578423638183337, 0.5539458382588166, 0.5702105800692852, 0.5621012816062341, 0.526675430054848, 0.5493486282917169, 0.5732237094869981, 0.5649882818643863, 0.5631326522964698, 0.5241127045681844, 0.5640756911956347, 0.5746810413323916, 0.5816768012367762, 0.5667699455068662, 0.5681631679718311, 0.568557273883086, 0.5604946372600702, 0.5675460507090275, 0.5735470962065917, 0.5697819739580154, 0.5801520267358193, 0.5721300949270909, 0.5638254829324209, 0.5675483976419156, 0.5654273600532458, 0.5711297140671656, 0.5649713942637811, 0.5691766303319198, 0.5647087842226028, 0.5532668138352724, 0.5695671295890441, 0.5700791483888259, 0.5781108656754861, 0.5662595251431832, 0.5476265260233328, 0.5658024549484253, 0.5653231229919654, 0.5749164206477312, 0.5741387829184532, 0.574384698501, 0.5647514250416023, 0.5753402520830815, 0.5430723311236272, 0.5670763414639693, 0.5587369249417231, 0.5656891465187073, 0.5746660822859178, 0.5673123449087143, 0.5743495002388954, 0.5613448124092358, 0.5808381186081812, 0.5577845799808319, 0.5685704310352986], 'loss': [2.524010005740896, 0.8515256774510161, 0.6641010343891046, 0.5812354241417506, 0.5262142663060063, 0.49052280009227145, 0.46573934635695613, 0.4456555028798604, 0.4269713820824486, 0.4168253911219872, 0.4033910027758987, 0.3949213039662844, 0.3862965244225753, 0.3767274629500237, 0.37418259227450656, 0.36837814803120394, 0.3626253151930996, 0.35604059401280125, 0.35349874512731266, 0.3483895468258895, 0.3490889961403102, 0.4208840544561525, 0.3541758812398452, 0.3459439175293629, 0.3408568826651184, 0.33541293331071215, 0.331965940102851, 0.33167755151656925, 0.327163694299126, 0.3245817047115139, 0.32399761038579417, 0.3201829891610297, 0.31743089523656687, 0.3169369217045114, 0.3183935604955859, 0.31502983209876395, 0.312844212502887, 0.3124527916893532, 0.3117400594361427, 0.30788777695363556, 0.3048650583008894, 0.3056037575130169, 0.3025917757467778, 0.3028948578867076, 0.30127507414114624, 0.2983384547990637, 0.2982284780095273, 0.29682360028391624, 0.2955776695905879, 0.2933903226446294, 0.2936105218406842, 0.29271210530669906, 0.2908408418029786, 0.28916176365858337, 0.2893698690540729, 0.2875531558553792, 0.2859833619091703, 0.2868319962760855, 0.2849169154371886, 0.2837458623903523, 0.2837547758133948, 0.28253079573848444, 0.28091214394795877, 0.2816151382023147, 0.27935941565314926, 0.28044197110081803, 0.2779223229638173, 0.2786358702719283, 0.27667474656827135, 0.275711104552772, 0.2758844720858836, 0.2741144924935386, 0.274810721705917, 0.2721101760144143], 'acc': [0.6981917596535083, 0.882080671362449, 0.8935730876017132, 0.917713972856602, 0.9266760418536665, 0.9296524185025251, 0.9320434247294135, 0.9338203622364067, 0.9352573507674052, 0.9363192920369063, 0.9374931263525658, 0.9382607934715277, 0.9390361498425305, 0.9398363828329234, 0.9401329865669353, 0.9405695559914059, 0.941185715205553, 0.9416623552281138, 0.9419143614179257, 0.9423386857187045, 0.9425751674519378, 0.9355183262936273, 0.9414035294654679, 0.942370278703587, 0.9428979815630238, 0.9433198003083767, 0.943717968070308, 0.9438402978496381, 0.9441995321742329, 0.9443335037142173, 0.9444732369229241, 0.944738053367398, 0.9449067395309301, 0.9451122074167656, 0.9448612033413816, 0.9451485468894257, 0.9451572560278965, 0.9454619984152703, 0.9453879345566059, 0.9457583162910569, 0.9459760911810127, 0.9460048454940005, 0.9461177521159615, 0.9462162574850567, 0.946211885204287, 0.9464255772887654, 0.9465986995484615, 0.9466651870317591, 0.9468784148783457, 0.9468969232337034, 0.94694614340038, 0.947015577572843, 0.9472212665175354, 0.9471837797860185, 0.9472580269607112, 0.9474199483241365, 0.9474266461205528, 0.9475244784293596, 0.9475997916108335, 0.9476837465312993, 0.9477721355799807, 0.9478614787207553, 0.9479193639174759, 0.9479317566043038, 0.9481372458242374, 0.9479370114329028, 0.9481696592456441, 0.9481585278927065, 0.9483156448458103, 0.9483679624805699, 0.9484389945005761, 0.9486020087239312, 0.948542970617374, 0.9487449354288994], 'mDice': [0.14230086638208334, 0.41797929607523465, 0.5013373211929084, 0.5439273090772849, 0.5743139609852521, 0.5954587685163639, 0.6112037765290436, 0.6238924538221766, 0.6360769150915219, 0.6429492252719344, 0.6518251223558871, 0.6577502272945482, 0.6635393141919612, 0.670260006768187, 0.6720772138834109, 0.6763143431521381, 0.6803229285717934, 0.6848887483769981, 0.6868062639471725, 0.6904757456136104, 0.691854510108978, 0.6453148001708922, 0.6860500938842011, 0.6922756394567738, 0.6959336613922731, 0.6998513443964957, 0.7025084392419548, 0.7027832586024505, 0.7060543418777151, 0.7080506478619841, 0.7085669360663919, 0.7112321845941808, 0.7133431226237722, 0.7137154149831051, 0.7126795500008414, 0.7150758450886403, 0.716756503987464, 0.7170803431357271, 0.717598129569918, 0.7205003816120785, 0.7227333961438618, 0.7222616599295002, 0.7245090964270795, 0.7241654415021993, 0.7254493353354319, 0.7277135607623025, 0.7278349342617086, 0.728916578189282, 0.7298789581315364, 0.7314629592678263, 0.7313996831352483, 0.7320799333719621, 0.7334438466249572, 0.7347398702150384, 0.7346472633640275, 0.7360279319592643, 0.7371228181940926, 0.7365242093622844, 0.7380290464931426, 0.7389605409663882, 0.7389368269261669, 0.7399039944027619, 0.7411644428262057, 0.7406373361781284, 0.7423995483254723, 0.7415507203932564, 0.7434729365507395, 0.7428715586013639, 0.7444412643087314, 0.745162827056305, 0.7451202175246276, 0.7464258777669773, 0.7459637189190689, 0.7480020198139946]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.14s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.92s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.75s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:14,  1.74s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:34,  1.60s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:40,  1.63s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:11,  1.54s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:28,  1.60s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:11,  1.55s/it]predicting train subjects:   2%|▏         | 7/285 [00:10<07:28,  1.61s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:23,  1.60s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:45,  1.69s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<07:56,  1.73s/it]predicting train subjects:   4%|▍         | 11/285 [00:17<07:37,  1.67s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<07:52,  1.73s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:36,  1.68s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<07:47,  1.72s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<08:02,  1.79s/it]predicting train subjects:   6%|▌         | 16/285 [00:26<08:08,  1.82s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<07:48,  1.75s/it]predicting train subjects:   6%|▋         | 18/285 [00:30<07:46,  1.75s/it]predicting train subjects:   7%|▋         | 19/285 [00:31<07:30,  1.69s/it]predicting train subjects:   7%|▋         | 20/285 [00:33<07:35,  1.72s/it]predicting train subjects:   7%|▋         | 21/285 [00:35<07:48,  1.77s/it]predicting train subjects:   8%|▊         | 22/285 [00:37<07:33,  1.72s/it]predicting train subjects:   8%|▊         | 23/285 [00:38<07:33,  1.73s/it]predicting train subjects:   8%|▊         | 24/285 [00:40<07:20,  1.69s/it]predicting train subjects:   9%|▉         | 25/285 [00:42<07:31,  1.74s/it]predicting train subjects:   9%|▉         | 26/285 [00:44<07:40,  1.78s/it]predicting train subjects:   9%|▉         | 27/285 [00:45<07:16,  1.69s/it]predicting train subjects:  10%|▉         | 28/285 [00:47<07:19,  1.71s/it]predicting train subjects:  10%|█         | 29/285 [00:49<07:18,  1.71s/it]predicting train subjects:  11%|█         | 30/285 [00:50<07:30,  1.77s/it]predicting train subjects:  11%|█         | 31/285 [00:52<07:37,  1.80s/it]predicting train subjects:  11%|█         | 32/285 [00:54<07:16,  1.73s/it]predicting train subjects:  12%|█▏        | 33/285 [00:56<07:14,  1.72s/it]predicting train subjects:  12%|█▏        | 34/285 [00:57<07:13,  1.73s/it]predicting train subjects:  12%|█▏        | 35/285 [00:59<07:21,  1.76s/it]predicting train subjects:  13%|█▎        | 36/285 [01:01<07:07,  1.72s/it]predicting train subjects:  13%|█▎        | 37/285 [01:03<07:05,  1.72s/it]predicting train subjects:  13%|█▎        | 38/285 [01:04<07:16,  1.77s/it]predicting train subjects:  14%|█▎        | 39/285 [01:06<06:59,  1.71s/it]predicting train subjects:  14%|█▍        | 40/285 [01:08<07:00,  1.71s/it]predicting train subjects:  14%|█▍        | 41/285 [01:09<06:48,  1.67s/it]predicting train subjects:  15%|█▍        | 42/285 [01:11<06:40,  1.65s/it]predicting train subjects:  15%|█▌        | 43/285 [01:13<06:47,  1.69s/it]predicting train subjects:  15%|█▌        | 44/285 [01:15<07:04,  1.76s/it]predicting train subjects:  16%|█▌        | 45/285 [01:16<06:58,  1.74s/it]predicting train subjects:  16%|█▌        | 46/285 [01:18<07:04,  1.78s/it]predicting train subjects:  16%|█▋        | 47/285 [01:20<06:43,  1.70s/it]predicting train subjects:  17%|█▋        | 48/285 [01:21<06:45,  1.71s/it]predicting train subjects:  17%|█▋        | 49/285 [01:23<06:59,  1.78s/it]predicting train subjects:  18%|█▊        | 50/285 [01:25<06:54,  1.76s/it]predicting train subjects:  18%|█▊        | 51/285 [01:27<06:58,  1.79s/it]predicting train subjects:  18%|█▊        | 52/285 [01:29<06:46,  1.75s/it]predicting train subjects:  19%|█▊        | 53/285 [01:30<06:53,  1.78s/it]predicting train subjects:  19%|█▉        | 54/285 [01:32<07:00,  1.82s/it]predicting train subjects:  19%|█▉        | 55/285 [01:34<06:40,  1.74s/it]predicting train subjects:  20%|█▉        | 56/285 [01:36<06:34,  1.72s/it]predicting train subjects:  20%|██        | 57/285 [01:37<06:24,  1.69s/it]predicting train subjects:  20%|██        | 58/285 [01:39<06:30,  1.72s/it]predicting train subjects:  21%|██        | 59/285 [01:41<06:40,  1.77s/it]predicting train subjects:  21%|██        | 60/285 [01:43<06:51,  1.83s/it]predicting train subjects:  21%|██▏       | 61/285 [01:44<06:33,  1.76s/it]predicting train subjects:  22%|██▏       | 62/285 [01:46<06:34,  1.77s/it]predicting train subjects:  22%|██▏       | 63/285 [01:48<06:28,  1.75s/it]predicting train subjects:  22%|██▏       | 64/285 [01:50<06:16,  1.70s/it]predicting train subjects:  23%|██▎       | 65/285 [01:51<06:19,  1.73s/it]predicting train subjects:  23%|██▎       | 66/285 [01:53<06:15,  1.72s/it]predicting train subjects:  24%|██▎       | 67/285 [01:55<06:19,  1.74s/it]predicting train subjects:  24%|██▍       | 68/285 [01:56<06:12,  1.72s/it]predicting train subjects:  24%|██▍       | 69/285 [01:58<06:19,  1.76s/it]predicting train subjects:  25%|██▍       | 70/285 [02:00<06:13,  1.74s/it]predicting train subjects:  25%|██▍       | 71/285 [02:02<06:15,  1.75s/it]predicting train subjects:  25%|██▌       | 72/285 [02:03<06:01,  1.70s/it]predicting train subjects:  26%|██▌       | 73/285 [02:05<06:03,  1.72s/it]predicting train subjects:  26%|██▌       | 74/285 [02:07<06:04,  1.73s/it]predicting train subjects:  26%|██▋       | 75/285 [02:09<06:04,  1.73s/it]predicting train subjects:  27%|██▋       | 76/285 [02:10<06:06,  1.75s/it]predicting train subjects:  27%|██▋       | 77/285 [02:12<05:55,  1.71s/it]predicting train subjects:  27%|██▋       | 78/285 [02:14<05:48,  1.68s/it]predicting train subjects:  28%|██▊       | 79/285 [02:15<05:49,  1.70s/it]predicting train subjects:  28%|██▊       | 80/285 [02:17<05:51,  1.71s/it]predicting train subjects:  28%|██▊       | 81/285 [02:19<05:38,  1.66s/it]predicting train subjects:  29%|██▉       | 82/285 [02:20<05:42,  1.69s/it]predicting train subjects:  29%|██▉       | 83/285 [02:22<05:34,  1.65s/it]predicting train subjects:  29%|██▉       | 84/285 [02:23<05:22,  1.60s/it]predicting train subjects:  30%|██▉       | 85/285 [02:25<05:29,  1.65s/it]predicting train subjects:  30%|███       | 86/285 [02:27<05:31,  1.67s/it]predicting train subjects:  31%|███       | 87/285 [02:29<05:31,  1.68s/it]predicting train subjects:  31%|███       | 88/285 [02:30<05:19,  1.62s/it]predicting train subjects:  31%|███       | 89/285 [02:32<05:21,  1.64s/it]predicting train subjects:  32%|███▏      | 90/285 [02:34<05:24,  1.67s/it]predicting train subjects:  32%|███▏      | 91/285 [02:35<05:23,  1.67s/it]predicting train subjects:  32%|███▏      | 92/285 [02:37<05:27,  1.70s/it]predicting train subjects:  33%|███▎      | 93/285 [02:39<05:18,  1.66s/it]predicting train subjects:  33%|███▎      | 94/285 [02:40<05:23,  1.69s/it]predicting train subjects:  33%|███▎      | 95/285 [02:42<05:23,  1.70s/it]predicting train subjects:  34%|███▎      | 96/285 [02:44<05:21,  1.70s/it]predicting train subjects:  34%|███▍      | 97/285 [02:45<05:22,  1.72s/it]predicting train subjects:  34%|███▍      | 98/285 [02:47<05:23,  1.73s/it]predicting train subjects:  35%|███▍      | 99/285 [02:49<05:22,  1.73s/it]predicting train subjects:  35%|███▌      | 100/285 [02:51<05:24,  1.75s/it]predicting train subjects:  35%|███▌      | 101/285 [02:52<05:13,  1.70s/it]predicting train subjects:  36%|███▌      | 102/285 [02:54<05:12,  1.71s/it]predicting train subjects:  36%|███▌      | 103/285 [02:56<05:06,  1.68s/it]predicting train subjects:  36%|███▋      | 104/285 [02:58<05:10,  1.71s/it]predicting train subjects:  37%|███▋      | 105/285 [02:59<05:08,  1.71s/it]predicting train subjects:  37%|███▋      | 106/285 [03:01<04:58,  1.67s/it]predicting train subjects:  38%|███▊      | 107/285 [03:02<04:56,  1.67s/it]predicting train subjects:  38%|███▊      | 108/285 [03:04<04:48,  1.63s/it]predicting train subjects:  38%|███▊      | 109/285 [03:06<04:47,  1.63s/it]predicting train subjects:  39%|███▊      | 110/285 [03:07<04:53,  1.68s/it]predicting train subjects:  39%|███▉      | 111/285 [03:09<04:45,  1.64s/it]predicting train subjects:  39%|███▉      | 112/285 [03:11<04:45,  1.65s/it]predicting train subjects:  40%|███▉      | 113/285 [03:12<04:46,  1.67s/it]predicting train subjects:  40%|████      | 114/285 [03:14<04:46,  1.67s/it]predicting train subjects:  40%|████      | 115/285 [03:16<04:46,  1.68s/it]predicting train subjects:  41%|████      | 116/285 [03:17<04:45,  1.69s/it]predicting train subjects:  41%|████      | 117/285 [03:19<04:36,  1.64s/it]predicting train subjects:  41%|████▏     | 118/285 [03:21<04:30,  1.62s/it]predicting train subjects:  42%|████▏     | 119/285 [03:22<04:36,  1.67s/it]predicting train subjects:  42%|████▏     | 120/285 [03:24<04:29,  1.63s/it]predicting train subjects:  42%|████▏     | 121/285 [03:25<04:23,  1.61s/it]predicting train subjects:  43%|████▎     | 122/285 [03:27<04:16,  1.57s/it]predicting train subjects:  43%|████▎     | 123/285 [03:28<04:07,  1.53s/it]predicting train subjects:  44%|████▎     | 124/285 [03:30<04:07,  1.54s/it]predicting train subjects:  44%|████▍     | 125/285 [03:31<04:05,  1.54s/it]predicting train subjects:  44%|████▍     | 126/285 [03:33<04:03,  1.53s/it]predicting train subjects:  45%|████▍     | 127/285 [03:34<03:55,  1.49s/it]predicting train subjects:  45%|████▍     | 128/285 [03:36<03:58,  1.52s/it]predicting train subjects:  45%|████▌     | 129/285 [03:37<03:54,  1.50s/it]predicting train subjects:  46%|████▌     | 130/285 [03:39<03:48,  1.47s/it]predicting train subjects:  46%|████▌     | 131/285 [03:40<03:42,  1.45s/it]predicting train subjects:  46%|████▋     | 132/285 [03:42<03:47,  1.49s/it]predicting train subjects:  47%|████▋     | 133/285 [03:43<03:44,  1.48s/it]predicting train subjects:  47%|████▋     | 134/285 [03:45<03:41,  1.47s/it]predicting train subjects:  47%|████▋     | 135/285 [03:46<03:34,  1.43s/it]predicting train subjects:  48%|████▊     | 136/285 [03:47<03:32,  1.43s/it]predicting train subjects:  48%|████▊     | 137/285 [03:49<03:39,  1.48s/it]predicting train subjects:  48%|████▊     | 138/285 [03:50<03:33,  1.45s/it]predicting train subjects:  49%|████▉     | 139/285 [03:52<03:37,  1.49s/it]predicting train subjects:  49%|████▉     | 140/285 [03:54<03:39,  1.52s/it]predicting train subjects:  49%|████▉     | 141/285 [03:55<03:33,  1.48s/it]predicting train subjects:  50%|████▉     | 142/285 [03:56<03:28,  1.46s/it]predicting train subjects:  50%|█████     | 143/285 [03:58<03:26,  1.46s/it]predicting train subjects:  51%|█████     | 144/285 [03:59<03:26,  1.46s/it]predicting train subjects:  51%|█████     | 145/285 [04:01<03:23,  1.46s/it]predicting train subjects:  51%|█████     | 146/285 [04:02<03:24,  1.47s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:04<03:19,  1.45s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:05<03:27,  1.51s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:07<03:22,  1.49s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:08<03:16,  1.45s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:10<03:17,  1.47s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:11<03:13,  1.45s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:13<03:12,  1.46s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:14<03:15,  1.49s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:16<03:10,  1.47s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:17<03:14,  1.51s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:18<03:08,  1.47s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:20<03:05,  1.46s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:21<03:01,  1.44s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:23<02:59,  1.44s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:24<03:05,  1.49s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:26<02:59,  1.46s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:27<03:01,  1.49s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:29<02:55,  1.45s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:30<02:52,  1.44s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:32<02:52,  1.45s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:33<02:52,  1.47s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:34<02:47,  1.43s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:36<02:47,  1.44s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:37<02:44,  1.43s/it]predicting train subjects:  60%|██████    | 171/285 [04:39<02:41,  1.42s/it]predicting train subjects:  60%|██████    | 172/285 [04:40<02:39,  1.41s/it]predicting train subjects:  61%|██████    | 173/285 [04:41<02:35,  1.39s/it]predicting train subjects:  61%|██████    | 174/285 [04:43<02:33,  1.39s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:44<02:38,  1.44s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:46<02:41,  1.48s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:47<02:37,  1.46s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:49<02:31,  1.42s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:50<02:31,  1.43s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:52<02:39,  1.52s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:54<02:43,  1.57s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:55<02:41,  1.57s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:56<02:32,  1.50s/it]predicting train subjects:  65%|██████▍   | 184/285 [04:58<02:29,  1.48s/it]predicting train subjects:  65%|██████▍   | 185/285 [04:59<02:23,  1.44s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:01<02:30,  1.52s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:03<02:35,  1.59s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:04<02:38,  1.63s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:06<02:27,  1.54s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:07<02:20,  1.48s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:09<02:22,  1.51s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:10<02:22,  1.53s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:12<02:14,  1.46s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:13<02:10,  1.44s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:14<02:06,  1.41s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:16<02:15,  1.52s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:18<02:20,  1.59s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:20<02:22,  1.63s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:21<02:13,  1.55s/it]predicting train subjects:  70%|███████   | 200/285 [05:22<02:09,  1.53s/it]predicting train subjects:  71%|███████   | 201/285 [05:24<02:12,  1.58s/it]predicting train subjects:  71%|███████   | 202/285 [05:26<02:12,  1.59s/it]predicting train subjects:  71%|███████   | 203/285 [05:27<02:10,  1.60s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:29<02:02,  1.51s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:30<01:57,  1.47s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:31<01:53,  1.43s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:33<02:00,  1.54s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:35<02:04,  1.62s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:37<02:06,  1.66s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:38<01:56,  1.56s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:40<01:56,  1.57s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:41<01:55,  1.58s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:43<01:54,  1.59s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:44<01:48,  1.52s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:46<01:50,  1.58s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:47<01:43,  1.50s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:49<01:47,  1.57s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:51<01:48,  1.62s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:52<01:48,  1.64s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:54<01:41,  1.56s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:55<01:36,  1.51s/it]predicting train subjects:  78%|███████▊  | 222/285 [05:57<01:36,  1.53s/it]predicting train subjects:  78%|███████▊  | 223/285 [05:58<01:30,  1.46s/it]predicting train subjects:  79%|███████▊  | 224/285 [05:59<01:27,  1.43s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:01<01:25,  1.42s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:02<01:28,  1.51s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:04<01:31,  1.57s/it]predicting train subjects:  80%|████████  | 228/285 [06:06<01:32,  1.62s/it]predicting train subjects:  80%|████████  | 229/285 [06:08<01:30,  1.61s/it]predicting train subjects:  81%|████████  | 230/285 [06:09<01:23,  1.52s/it]predicting train subjects:  81%|████████  | 231/285 [06:10<01:19,  1.48s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:12<01:20,  1.51s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:13<01:15,  1.46s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:15<01:18,  1.55s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:16<01:14,  1.50s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:18<01:17,  1.59s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:20<01:17,  1.62s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:21<01:17,  1.66s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:23<01:15,  1.64s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:24<01:09,  1.55s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:26<01:06,  1.51s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:27<01:02,  1.46s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:29<00:59,  1.42s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:30<01:01,  1.50s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:32<00:58,  1.46s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:33<01:00,  1.55s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:35<01:00,  1.59s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:37<00:58,  1.59s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:38<00:54,  1.51s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:39<00:51,  1.48s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:41<00:48,  1.43s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:42<00:45,  1.39s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:44<00:48,  1.51s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:46<00:49,  1.60s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:47<00:48,  1.62s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:49<00:44,  1.52s/it]predicting train subjects:  90%|█████████ | 257/285 [06:50<00:41,  1.47s/it]predicting train subjects:  91%|█████████ | 258/285 [06:52<00:41,  1.55s/it]predicting train subjects:  91%|█████████ | 259/285 [06:53<00:40,  1.56s/it]predicting train subjects:  91%|█████████ | 260/285 [06:54<00:36,  1.48s/it]predicting train subjects:  92%|█████████▏| 261/285 [06:56<00:35,  1.48s/it]predicting train subjects:  92%|█████████▏| 262/285 [06:57<00:32,  1.43s/it]predicting train subjects:  92%|█████████▏| 263/285 [06:59<00:30,  1.41s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:00<00:32,  1.53s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:02<00:32,  1.61s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:04<00:29,  1.53s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:05<00:27,  1.50s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:07<00:26,  1.58s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:08<00:25,  1.58s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:10<00:22,  1.53s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:11<00:20,  1.50s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:13<00:20,  1.55s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:14<00:17,  1.48s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:16<00:16,  1.46s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:17<00:15,  1.57s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:19<00:14,  1.63s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:21<00:12,  1.54s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:22<00:10,  1.53s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:24<00:09,  1.56s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:25<00:07,  1.50s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:26<00:05,  1.49s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:28<00:04,  1.45s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:30<00:03,  1.55s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:31<00:01,  1.62s/it]predicting train subjects: 100%|██████████| 285/285 [07:33<00:00,  1.67s/it]

