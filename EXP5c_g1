*** DATASET ALREADY EXIST; PLEASE REMOVE 'train' & 'test' SUBFOLDERS ***
(0/456) train vimp2_845_05312013_VZ
(1/456) train vimp2_823_05202013_AJ
(2/456) train vimp2_915_07112013_LC
(3/456) train vimp2_901_07052013_AS
(4/456) train vimp2_ctrl_911_07082013_TTO
(5/456) train vimp2_ctrl_925_07152013_LS
(6/456) train vimp2_869_06142013_BL
(7/456) train vimp2_ANON724_03272013
(8/456) train vimp2_819_05172013_DS
(9/456) train vimp2_ctrl_918_07112013_TQ
(10/456) train vimp2_ctrl_902_07052013_SI
(11/456) train vimp2_ANON606_20130110
(12/456) train vimp2_943_07242013_PA
(13/456) train vimp2_824_05212013_JS
(14/456) train vimp2_ANON624_20130117
(15/456) train vimp2_ctrl_920_07122013_SW
(16/456) train vimp2_884_06272013_TS
(17/456) train vimp2_668_02282013_CD
(18/456) train vimp2_964_08092013_TG
(19/456) train vimp2_ctrl_921_07122013_MP
(20/456) train vimp2_972_08152013_DC
(21/456) train vimp2_988_08302013_CB
(22/456) train vimp2_ANON702_03152013
(23/456) train vimp2_ANON714_03222013
(24/456) train vimp2_972_08152013_DC_Aug0_Rot_-1_sd0
(25/456) train vimp2_972_08152013_DC_Aug0_Rot_1_sd2
(26/456) train vimp2_972_08152013_DC_Aug0_Rot_-7_sd1
(27/456) train vimp2_972_08152013_DC_Aug1_Rot_2_sd0
(28/456) train vimp2_972_08152013_DC_Aug1_Rot_5_sd1
(29/456) train vimp2_972_08152013_DC_Aug1_Rot_6_sd2
(30/456) train vimp2_972_08152013_DC_Aug2_Rot_-3_sd1
(31/456) train vimp2_972_08152013_DC_Aug2_Rot_-3_sd2
(32/456) train vimp2_972_08152013_DC_Aug2_Rot_-5_sd0
(33/456) train vimp2_972_08152013_DC_Aug3_Rot_2_sd1
(34/456) train vimp2_972_08152013_DC_Aug3_Rot_-3_sd0
(35/456) train vimp2_972_08152013_DC_Aug3_Rot_-6_sd2
(36/456) train vimp2_972_08152013_DC_Aug4_Rot_-2_sd2
(37/456) train vimp2_972_08152013_DC_Aug4_Rot_3_sd0
(38/456) train vimp2_972_08152013_DC_Aug4_Rot_6_sd1
(39/456) train vimp2_972_08152013_DC_Aug5_Rot_-1_sd2
(40/456) train vimp2_972_08152013_DC_Aug5_Rot_7_sd0
(41/456) train vimp2_972_08152013_DC_Aug5_Rot_7_sd1
(42/456) train vimp2_988_08302013_CB_Aug0_Rot_-3_sd2
(43/456) train vimp2_988_08302013_CB_Aug0_Rot_4_sd0
(44/456) train vimp2_988_08302013_CB_Aug0_Rot_-5_sd1
(45/456) train vimp2_988_08302013_CB_Aug1_Rot_-2_sd2
(46/456) train vimp2_988_08302013_CB_Aug1_Rot_-3_sd0
(47/456) train vimp2_988_08302013_CB_Aug1_Rot_-6_sd1
(48/456) train vimp2_988_08302013_CB_Aug2_Rot_-2_sd0
(49/456) train vimp2_988_08302013_CB_Aug2_Rot_4_sd1
(50/456) train vimp2_988_08302013_CB_Aug2_Rot_-5_sd2
(51/456) train vimp2_988_08302013_CB_Aug3_Rot_2_sd2
(52/456) train vimp2_988_08302013_CB_Aug3_Rot_-3_sd0
(53/456) train vimp2_988_08302013_CB_Aug3_Rot_3_sd1
(54/456) train vimp2_988_08302013_CB_Aug4_Rot_-2_sd0
(55/456) train vimp2_988_08302013_CB_Aug4_Rot_-6_sd1
(56/456) train vimp2_988_08302013_CB_Aug4_Rot_7_sd2
(57/456) train vimp2_988_08302013_CB_Aug5_Rot_-1_sd0
(58/456) train vimp2_988_08302013_CB_Aug5_Rot_-6_sd1
(59/456) train vimp2_988_08302013_CB_Aug5_Rot_7_sd2
(60/456) train vimp2_ANON702_03152013_Aug0_Rot_-2_sd1
(61/456) train vimp2_ANON702_03152013_Aug0_Rot_-3_sd2
(62/456) train vimp2_ANON702_03152013_Aug0_Rot_-4_sd0
(63/456) train vimp2_ANON702_03152013_Aug1_Rot_-4_sd1
(64/456) train vimp2_ANON702_03152013_Aug1_Rot_-5_sd2
(65/456) train vimp2_ANON702_03152013_Aug1_Rot_-7_sd0
(66/456) train vimp2_ANON702_03152013_Aug2_Rot_6_sd0
(67/456) train vimp2_ANON702_03152013_Aug2_Rot_6_sd2
(68/456) train vimp2_ANON702_03152013_Aug2_Rot_-7_sd1
(69/456) train vimp2_ANON702_03152013_Aug3_Rot_-1_sd2
(70/456) train vimp2_ANON702_03152013_Aug3_Rot_-3_sd0
(71/456) train vimp2_ANON702_03152013_Aug3_Rot_-6_sd1
(72/456) train vimp2_ANON702_03152013_Aug4_Rot_-2_sd0
(73/456) train vimp2_ANON702_03152013_Aug4_Rot_-3_sd2
(74/456) train vimp2_ANON702_03152013_Aug4_Rot_-7_sd1
(75/456) train vimp2_ANON702_03152013_Aug5_Rot_3_sd0
(76/456) train vimp2_ANON702_03152013_Aug5_Rot_3_sd2
(77/456) train vimp2_ANON702_03152013_Aug5_Rot_4_sd1
(78/456) train vimp2_ANON714_03222013_Aug0_Rot_-1_sd2
(79/456) train vimp2_ANON714_03222013_Aug0_Rot_-2_sd1
(80/456) train vimp2_ANON714_03222013_Aug0_Rot_4_sd0
(81/456) train vimp2_ANON714_03222013_Aug1_Rot_0_sd0
(82/456) train vimp2_ANON714_03222013_Aug1_Rot_1_sd1
(83/456) train vimp2_ANON714_03222013_Aug1_Rot_-6_sd2
(84/456) train vimp2_ANON714_03222013_Aug2_Rot_-2_sd0
(85/456) train vimp2_ANON714_03222013_Aug2_Rot_4_sd1
(86/456) train vimp2_ANON714_03222013_Aug2_Rot_6_sd2
(87/456) train vimp2_ANON714_03222013_Aug3_Rot_2_sd0
(88/456) train vimp2_ANON714_03222013_Aug3_Rot_-3_sd2
(89/456) train vimp2_ANON714_03222013_Aug3_Rot_-7_sd1
(90/456) train vimp2_ANON714_03222013_Aug4_Rot_1_sd0
(91/456) train vimp2_ANON714_03222013_Aug4_Rot_-2_sd1
(92/456) train vimp2_ANON714_03222013_Aug4_Rot_4_sd2
(93/456) train vimp2_ANON714_03222013_Aug5_Rot_1_sd0
(94/456) train vimp2_ANON714_03222013_Aug5_Rot_6_sd1
(95/456) train vimp2_ANON714_03222013_Aug5_Rot_-7_sd2
(96/456) train vimp2_668_02282013_CD_Aug0_Rot_7_sd0
(97/456) train vimp2_668_02282013_CD_Aug1_Rot_-1_sd0
(98/456) train vimp2_668_02282013_CD_Aug2_Rot_-4_sd0
(99/456) train vimp2_668_02282013_CD_Aug3_Rot_3_sd0
(100/456) train vimp2_668_02282013_CD_Aug4_Rot_-5_sd0
(101/456) train vimp2_668_02282013_CD_Aug5_Rot_-6_sd0
(102/456) train vimp2_819_05172013_DS_Aug0_Rot_1_sd0
(103/456) train vimp2_819_05172013_DS_Aug1_Rot_5_sd0
(104/456) train vimp2_819_05172013_DS_Aug2_Rot_-4_sd0
(105/456) train vimp2_819_05172013_DS_Aug3_Rot_2_sd0
(106/456) train vimp2_819_05172013_DS_Aug4_Rot_5_sd0
(107/456) train vimp2_819_05172013_DS_Aug5_Rot_4_sd0
(108/456) train vimp2_823_05202013_AJ_Aug0_Rot_-7_sd0
(109/456) train vimp2_823_05202013_AJ_Aug1_Rot_7_sd0
(110/456) train vimp2_823_05202013_AJ_Aug2_Rot_3_sd0
(111/456) train vimp2_823_05202013_AJ_Aug3_Rot_-5_sd0
(112/456) train vimp2_823_05202013_AJ_Aug4_Rot_-3_sd0
(113/456) train vimp2_823_05202013_AJ_Aug5_Rot_1_sd0
(114/456) train vimp2_824_05212013_JS_Aug0_Rot_-2_sd0
(115/456) train vimp2_824_05212013_JS_Aug1_Rot_6_sd0
(116/456) train vimp2_824_05212013_JS_Aug2_Rot_1_sd0
(117/456) train vimp2_824_05212013_JS_Aug3_Rot_-4_sd0
(118/456) train vimp2_824_05212013_JS_Aug4_Rot_7_sd0
(119/456) train vimp2_824_05212013_JS_Aug5_Rot_2_sd0
(120/456) train vimp2_845_05312013_VZ_Aug0_Rot_1_sd0
(121/456) train vimp2_845_05312013_VZ_Aug1_Rot_5_sd0
(122/456) train vimp2_845_05312013_VZ_Aug2_Rot_-6_sd0
(123/456) train vimp2_845_05312013_VZ_Aug3_Rot_3_sd0
(124/456) train vimp2_845_05312013_VZ_Aug4_Rot_-2_sd0
(125/456) train vimp2_845_05312013_VZ_Aug5_Rot_5_sd0
(126/456) train vimp2_869_06142013_BL_Aug0_Rot_-2_sd0
(127/456) train vimp2_869_06142013_BL_Aug1_Rot_-4_sd0
(128/456) train vimp2_869_06142013_BL_Aug2_Rot_-1_sd0
(129/456) train vimp2_869_06142013_BL_Aug3_Rot_3_sd0
(130/456) train vimp2_869_06142013_BL_Aug4_Rot_3_sd0
(131/456) train vimp2_869_06142013_BL_Aug5_Rot_1_sd0
(132/456) train vimp2_884_06272013_TS_Aug0_Rot_-7_sd0
(133/456) train vimp2_884_06272013_TS_Aug1_Rot_7_sd0
(134/456) train vimp2_884_06272013_TS_Aug2_Rot_-5_sd0
(135/456) train vimp2_884_06272013_TS_Aug3_Rot_-2_sd0
(136/456) train vimp2_884_06272013_TS_Aug4_Rot_6_sd0
(137/456) train vimp2_884_06272013_TS_Aug5_Rot_-1_sd0
(138/456) train vimp2_901_07052013_AS_Aug0_Rot_-4_sd0
(139/456) train vimp2_901_07052013_AS_Aug1_Rot_-2_sd0
(140/456) train vimp2_901_07052013_AS_Aug2_Rot_1_sd0
(141/456) train vimp2_901_07052013_AS_Aug3_Rot_2_sd0
(142/456) train vimp2_901_07052013_AS_Aug4_Rot_-7_sd0
(143/456) train vimp2_901_07052013_AS_Aug5_Rot_-5_sd0
(144/456) train vimp2_915_07112013_LC_Aug0_Rot_-2_sd0
(145/456) train vimp2_915_07112013_LC_Aug1_Rot_4_sd0
(146/456) train vimp2_915_07112013_LC_Aug2_Rot_-2_sd0
(147/456) train vimp2_915_07112013_LC_Aug3_Rot_-1_sd0
(148/456) train vimp2_915_07112013_LC_Aug4_Rot_1_sd0
(149/456) train vimp2_915_07112013_LC_Aug5_Rot_4_sd0
(150/456) train vimp2_943_07242013_PA_Aug0_Rot_-5_sd0
(151/456) train vimp2_943_07242013_PA_Aug1_Rot_-7_sd0
(152/456) train vimp2_943_07242013_PA_Aug2_Rot_-4_sd0
(153/456) train vimp2_943_07242013_PA_Aug3_Rot_6_sd0
(154/456) train vimp2_943_07242013_PA_Aug4_Rot_6_sd0
(155/456) train vimp2_943_07242013_PA_Aug5_Rot_5_sd0
(156/456) train vimp2_964_08092013_TG_Aug0_Rot_5_sd0
(157/456) train vimp2_964_08092013_TG_Aug1_Rot_-4_sd0
(158/456) train vimp2_964_08092013_TG_Aug2_Rot_7_sd0
(159/456) train vimp2_964_08092013_TG_Aug3_Rot_-1_sd0
(160/456) train vimp2_964_08092013_TG_Aug4_Rot_-1_sd0
(161/456) train vimp2_964_08092013_TG_Aug5_Rot_2_sd0
(162/456) train vimp2_ANON606_20130110_Aug0_Rot_1_sd0
(163/456) train vimp2_ANON606_20130110_Aug1_Rot_2_sd0
(164/456) train vimp2_ANON606_20130110_Aug2_Rot_-5_sd0
(165/456) train vimp2_ANON606_20130110_Aug3_Rot_-5_sd0
(166/456) train vimp2_ANON606_20130110_Aug4_Rot_3_sd0
(167/456) train vimp2_ANON606_20130110_Aug5_Rot_-1_sd0
(168/456) train vimp2_ANON624_20130117_Aug0_Rot_1_sd0
(169/456) train vimp2_ANON624_20130117_Aug1_Rot_-2_sd0
(170/456) train vimp2_ANON624_20130117_Aug2_Rot_5_sd0
(171/456) train vimp2_ANON624_20130117_Aug3_Rot_1_sd0
(172/456) train vimp2_ANON624_20130117_Aug4_Rot_-5_sd0
(173/456) train vimp2_ANON624_20130117_Aug5_Rot_3_sd0
(174/456) train vimp2_ANON724_03272013_Aug0_Rot_-4_sd0
(175/456) train vimp2_ANON724_03272013_Aug1_Rot_-3_sd0
(176/456) train vimp2_ANON724_03272013_Aug2_Rot_-4_sd0
(177/456) train vimp2_ANON724_03272013_Aug3_Rot_5_sd0
(178/456) train vimp2_ANON724_03272013_Aug4_Rot_5_sd0
(179/456) train vimp2_ANON724_03272013_Aug5_Rot_-6_sd0
(180/456) train vimp2_ctrl_902_07052013_SI_Aug0_Rot_5_sd0
(181/456) train vimp2_ctrl_902_07052013_SI_Aug1_Rot_7_sd0
(182/456) train vimp2_ctrl_902_07052013_SI_Aug2_Rot_4_sd0
(183/456) train vimp2_ctrl_902_07052013_SI_Aug3_Rot_-4_sd0
(184/456) train vimp2_ctrl_902_07052013_SI_Aug4_Rot_3_sd0
(185/456) train vimp2_ctrl_902_07052013_SI_Aug5_Rot_-7_sd0
(186/456) train vimp2_ctrl_911_07082013_TTO_Aug0_Rot_6_sd0
(187/456) train vimp2_ctrl_911_07082013_TTO_Aug1_Rot_1_sd0
(188/456) train vimp2_ctrl_911_07082013_TTO_Aug2_Rot_4_sd0
(189/456) train vimp2_ctrl_911_07082013_TTO_Aug3_Rot_-2_sd0
(190/456) train vimp2_ctrl_911_07082013_TTO_Aug4_Rot_6_sd0
(191/456) train vimp2_ctrl_911_07082013_TTO_Aug5_Rot_-2_sd0
(192/456) train vimp2_ctrl_918_07112013_TQ_Aug0_Rot_5_sd0
(193/456) train vimp2_ctrl_918_07112013_TQ_Aug1_Rot_-3_sd0
(194/456) train vimp2_ctrl_918_07112013_TQ_Aug2_Rot_-4_sd0
(195/456) train vimp2_ctrl_918_07112013_TQ_Aug3_Rot_1_sd0
(196/456) train vimp2_ctrl_918_07112013_TQ_Aug4_Rot_3_sd0
(197/456) train vimp2_ctrl_918_07112013_TQ_Aug5_Rot_7_sd0
(198/456) train vimp2_ctrl_920_07122013_SW_Aug0_Rot_7_sd0
(199/456) train vimp2_ctrl_920_07122013_SW_Aug1_Rot_-6_sd0
(200/456) train vimp2_ctrl_920_07122013_SW_Aug2_Rot_-4_sd0
(201/456) train vimp2_ctrl_920_07122013_SW_Aug3_Rot_1_sd0
(202/456) train vimp2_ctrl_920_07122013_SW_Aug4_Rot_-2_sd0
(203/456) train vimp2_ctrl_920_07122013_SW_Aug5_Rot_4_sd0
(204/456) train vimp2_ctrl_921_07122013_MP_Aug0_Rot_-1_sd0
(205/456) train vimp2_ctrl_921_07122013_MP_Aug1_Rot_-3_sd0
(206/456) train vimp2_ctrl_921_07122013_MP_Aug2_Rot_6_sd0
(207/456) train vimp2_ctrl_921_07122013_MP_Aug3_Rot_3_sd0
(208/456) train vimp2_ctrl_921_07122013_MP_Aug4_Rot_1_sd0
(209/456) train vimp2_ctrl_921_07122013_MP_Aug5_Rot_-5_sd0
(210/456) train vimp2_ctrl_925_07152013_LS_Aug0_Rot_-5_sd0
(211/456) train vimp2_ctrl_925_07152013_LS_Aug1_Rot_-2_sd0
(212/456) train vimp2_ctrl_925_07152013_LS_Aug2_Rot_5_sd0
(213/456) train vimp2_ctrl_925_07152013_LS_Aug3_Rot_3_sd0
(214/456) train vimp2_ctrl_925_07152013_LS_Aug4_Rot_4_sd0
(215/456) train vimp2_ctrl_925_07152013_LS_Aug5_Rot_-7_sd0
(216/456) train vimp2_668_02282013_CD_Aug0_Rot_-5_sd1
(217/456) train vimp2_668_02282013_CD_Aug1_Rot_-6_sd1
(218/456) train vimp2_668_02282013_CD_Aug2_Rot_3_sd1
(219/456) train vimp2_668_02282013_CD_Aug3_Rot_4_sd1
(220/456) train vimp2_668_02282013_CD_Aug4_Rot_-6_sd1
(221/456) train vimp2_668_02282013_CD_Aug5_Rot_-2_sd1
(222/456) train vimp2_819_05172013_DS_Aug0_Rot_-1_sd1
(223/456) train vimp2_819_05172013_DS_Aug1_Rot_3_sd1
(224/456) train vimp2_819_05172013_DS_Aug2_Rot_6_sd1
(225/456) train vimp2_819_05172013_DS_Aug3_Rot_3_sd1
(226/456) train vimp2_819_05172013_DS_Aug4_Rot_-7_sd1
(227/456) train vimp2_819_05172013_DS_Aug5_Rot_-5_sd1
(228/456) train vimp2_823_05202013_AJ_Aug0_Rot_-7_sd1
(229/456) train vimp2_823_05202013_AJ_Aug1_Rot_3_sd1
(230/456) train vimp2_823_05202013_AJ_Aug2_Rot_6_sd1
(231/456) train vimp2_823_05202013_AJ_Aug3_Rot_-7_sd1
(232/456) train vimp2_823_05202013_AJ_Aug4_Rot_-4_sd1
(233/456) train vimp2_823_05202013_AJ_Aug5_Rot_-4_sd1
(234/456) train vimp2_824_05212013_JS_Aug0_Rot_7_sd1
(235/456) train vimp2_824_05212013_JS_Aug1_Rot_3_sd1
(236/456) train vimp2_824_05212013_JS_Aug2_Rot_3_sd1
(237/456) train vimp2_824_05212013_JS_Aug3_Rot_-4_sd1
(238/456) train vimp2_824_05212013_JS_Aug4_Rot_4_sd1
(239/456) train vimp2_824_05212013_JS_Aug5_Rot_6_sd1
(240/456) train vimp2_845_05312013_VZ_Aug0_Rot_5_sd1
(241/456) train vimp2_845_05312013_VZ_Aug1_Rot_6_sd1
(242/456) train vimp2_845_05312013_VZ_Aug2_Rot_1_sd1
(243/456) train vimp2_845_05312013_VZ_Aug3_Rot_-6_sd1
(244/456) train vimp2_845_05312013_VZ_Aug4_Rot_-2_sd1
(245/456) train vimp2_845_05312013_VZ_Aug5_Rot_-6_sd1
(246/456) train vimp2_869_06142013_BL_Aug0_Rot_-4_sd1
(247/456) train vimp2_869_06142013_BL_Aug1_Rot_-3_sd1
(248/456) train vimp2_869_06142013_BL_Aug2_Rot_-4_sd1
(249/456) train vimp2_869_06142013_BL_Aug3_Rot_1_sd1
(250/456) train vimp2_869_06142013_BL_Aug4_Rot_7_sd1
(251/456) train vimp2_869_06142013_BL_Aug5_Rot_5_sd1
(252/456) train vimp2_884_06272013_TS_Aug0_Rot_5_sd1
(253/456) train vimp2_884_06272013_TS_Aug1_Rot_-1_sd1
(254/456) train vimp2_884_06272013_TS_Aug2_Rot_-1_sd1
(255/456) train vimp2_884_06272013_TS_Aug3_Rot_3_sd1
(256/456) train vimp2_884_06272013_TS_Aug4_Rot_4_sd1
(257/456) train vimp2_884_06272013_TS_Aug5_Rot_3_sd1
(258/456) train vimp2_901_07052013_AS_Aug0_Rot_3_sd1
(259/456) train vimp2_901_07052013_AS_Aug1_Rot_5_sd1
(260/456) train vimp2_901_07052013_AS_Aug2_Rot_-5_sd1
(261/456) train vimp2_901_07052013_AS_Aug3_Rot_7_sd1
(262/456) train vimp2_901_07052013_AS_Aug4_Rot_7_sd1
(263/456) train vimp2_901_07052013_AS_Aug5_Rot_6_sd1
(264/456) train vimp2_915_07112013_LC_Aug0_Rot_-6_sd1
(265/456) train vimp2_915_07112013_LC_Aug1_Rot_-5_sd1
(266/456) train vimp2_915_07112013_LC_Aug2_Rot_7_sd1
(267/456) train vimp2_915_07112013_LC_Aug3_Rot_1_sd1
(268/456) train vimp2_915_07112013_LC_Aug4_Rot_6_sd1
(269/456) train vimp2_915_07112013_LC_Aug5_Rot_-7_sd1
(270/456) train vimp2_943_07242013_PA_Aug0_Rot_1_sd1
(271/456) train vimp2_943_07242013_PA_Aug1_Rot_6_sd1
(272/456) train vimp2_943_07242013_PA_Aug2_Rot_3_sd1
(273/456) train vimp2_943_07242013_PA_Aug3_Rot_6_sd1
(274/456) train vimp2_943_07242013_PA_Aug4_Rot_3_sd1
(275/456) train vimp2_943_07242013_PA_Aug5_Rot_3_sd1
(276/456) train vimp2_964_08092013_TG_Aug0_Rot_6_sd1
(277/456) train vimp2_964_08092013_TG_Aug1_Rot_-4_sd1
(278/456) train vimp2_964_08092013_TG_Aug2_Rot_5_sd1
(279/456) train vimp2_964_08092013_TG_Aug3_Rot_0_sd1
(280/456) train vimp2_964_08092013_TG_Aug4_Rot_3_sd1
(281/456) train vimp2_964_08092013_TG_Aug5_Rot_-1_sd1
(282/456) train vimp2_ANON606_20130110_Aug0_Rot_-6_sd1
(283/456) train vimp2_ANON606_20130110_Aug1_Rot_7_sd1
(284/456) train vimp2_ANON606_20130110_Aug2_Rot_1_sd1
(285/456) train vimp2_ANON606_20130110_Aug3_Rot_1_sd1
(286/456) train vimp2_ANON606_20130110_Aug4_Rot_4_sd1
(287/456) train vimp2_ANON606_20130110_Aug5_Rot_4_sd1
(288/456) train vimp2_ANON624_20130117_Aug0_Rot_7_sd1
(289/456) train vimp2_ANON624_20130117_Aug1_Rot_6_sd1
(290/456) train vimp2_ANON624_20130117_Aug2_Rot_-1_sd1
(291/456) train vimp2_ANON624_20130117_Aug3_Rot_1_sd1
(292/456) train vimp2_ANON624_20130117_Aug4_Rot_-5_sd1
(293/456) train vimp2_ANON624_20130117_Aug5_Rot_4_sd1
(294/456) train vimp2_ANON724_03272013_Aug0_Rot_-2_sd1
(295/456) train vimp2_ANON724_03272013_Aug1_Rot_4_sd1
(296/456) train vimp2_ANON724_03272013_Aug2_Rot_-1_sd1
(297/456) train vimp2_ANON724_03272013_Aug3_Rot_-6_sd1
(298/456) train vimp2_ANON724_03272013_Aug4_Rot_-5_sd1
(299/456) train vimp2_ANON724_03272013_Aug5_Rot_-4_sd1
(300/456) train vimp2_ctrl_902_07052013_SI_Aug0_Rot_-2_sd1
(301/456) train vimp2_ctrl_902_07052013_SI_Aug1_Rot_7_sd1
(302/456) train vimp2_ctrl_902_07052013_SI_Aug2_Rot_2_sd1
(303/456) train vimp2_ctrl_902_07052013_SI_Aug3_Rot_-4_sd1
(304/456) train vimp2_ctrl_902_07052013_SI_Aug4_Rot_-1_sd1
(305/456) train vimp2_ctrl_902_07052013_SI_Aug5_Rot_-4_sd1
(306/456) train vimp2_ctrl_911_07082013_TTO_Aug0_Rot_7_sd1
(307/456) train vimp2_ctrl_911_07082013_TTO_Aug1_Rot_-1_sd1
(308/456) train vimp2_ctrl_911_07082013_TTO_Aug2_Rot_-5_sd1
(309/456) train vimp2_ctrl_911_07082013_TTO_Aug3_Rot_-3_sd1
(310/456) train vimp2_ctrl_911_07082013_TTO_Aug4_Rot_6_sd1
(311/456) train vimp2_ctrl_911_07082013_TTO_Aug5_Rot_6_sd1
(312/456) train vimp2_ctrl_918_07112013_TQ_Aug0_Rot_1_sd1
(313/456) train vimp2_ctrl_918_07112013_TQ_Aug1_Rot_-2_sd1
(314/456) train vimp2_ctrl_918_07112013_TQ_Aug2_Rot_3_sd1
(315/456) train vimp2_ctrl_918_07112013_TQ_Aug3_Rot_-1_sd1
(316/456) train vimp2_ctrl_918_07112013_TQ_Aug4_Rot_7_sd1
(317/456) train vimp2_ctrl_918_07112013_TQ_Aug5_Rot_6_sd1
(318/456) train vimp2_ctrl_920_07122013_SW_Aug0_Rot_-3_sd1
(319/456) train vimp2_ctrl_920_07122013_SW_Aug1_Rot_7_sd1
(320/456) train vimp2_ctrl_920_07122013_SW_Aug2_Rot_-4_sd1
(321/456) train vimp2_ctrl_920_07122013_SW_Aug3_Rot_-1_sd1
(322/456) train vimp2_ctrl_920_07122013_SW_Aug4_Rot_-5_sd1
(323/456) train vimp2_ctrl_920_07122013_SW_Aug5_Rot_-5_sd1
(324/456) train vimp2_ctrl_921_07122013_MP_Aug0_Rot_4_sd1
(325/456) train vimp2_ctrl_921_07122013_MP_Aug1_Rot_3_sd1
(326/456) train vimp2_ctrl_921_07122013_MP_Aug2_Rot_-1_sd1
(327/456) train vimp2_ctrl_921_07122013_MP_Aug3_Rot_-2_sd1
(328/456) train vimp2_ctrl_921_07122013_MP_Aug4_Rot_2_sd1
(329/456) train vimp2_ctrl_921_07122013_MP_Aug5_Rot_4_sd1
(330/456) train vimp2_ctrl_925_07152013_LS_Aug0_Rot_-2_sd1
(331/456) train vimp2_ctrl_925_07152013_LS_Aug1_Rot_4_sd1
(332/456) train vimp2_ctrl_925_07152013_LS_Aug2_Rot_-2_sd1
(333/456) train vimp2_ctrl_925_07152013_LS_Aug3_Rot_2_sd1
(334/456) train vimp2_ctrl_925_07152013_LS_Aug4_Rot_3_sd1
(335/456) train vimp2_ctrl_925_07152013_LS_Aug5_Rot_-4_sd1
(336/456) train vimp2_668_02282013_CD_Aug0_Rot_-3_sd2
(337/456) train vimp2_668_02282013_CD_Aug1_Rot_6_sd2
(338/456) train vimp2_668_02282013_CD_Aug2_Rot_-6_sd2
(339/456) train vimp2_668_02282013_CD_Aug3_Rot_7_sd2
(340/456) train vimp2_668_02282013_CD_Aug4_Rot_1_sd2
(341/456) train vimp2_668_02282013_CD_Aug5_Rot_7_sd2
(342/456) train vimp2_819_05172013_DS_Aug0_Rot_3_sd2
(343/456) train vimp2_819_05172013_DS_Aug1_Rot_-1_sd2
(344/456) train vimp2_819_05172013_DS_Aug2_Rot_-2_sd2
(345/456) train vimp2_819_05172013_DS_Aug3_Rot_-1_sd2
(346/456) train vimp2_819_05172013_DS_Aug4_Rot_7_sd2
(347/456) train vimp2_819_05172013_DS_Aug5_Rot_3_sd2
(348/456) train vimp2_823_05202013_AJ_Aug0_Rot_-6_sd2
(349/456) train vimp2_823_05202013_AJ_Aug1_Rot_-7_sd2
(350/456) train vimp2_823_05202013_AJ_Aug2_Rot_7_sd2
(351/456) train vimp2_823_05202013_AJ_Aug3_Rot_-2_sd2
(352/456) train vimp2_823_05202013_AJ_Aug4_Rot_1_sd2
(353/456) train vimp2_823_05202013_AJ_Aug5_Rot_1_sd2
(354/456) train vimp2_824_05212013_JS_Aug0_Rot_-5_sd2
(355/456) train vimp2_824_05212013_JS_Aug1_Rot_3_sd2
(356/456) train vimp2_824_05212013_JS_Aug2_Rot_5_sd2
(357/456) train vimp2_824_05212013_JS_Aug3_Rot_2_sd2
(358/456) train vimp2_824_05212013_JS_Aug4_Rot_5_sd2
(359/456) train vimp2_824_05212013_JS_Aug5_Rot_-7_sd2
(360/456) train vimp2_845_05312013_VZ_Aug0_Rot_-5_sd2
(361/456) train vimp2_845_05312013_VZ_Aug1_Rot_3_sd2
(362/456) train vimp2_845_05312013_VZ_Aug2_Rot_-3_sd2
(363/456) train vimp2_845_05312013_VZ_Aug3_Rot_-1_sd2
(364/456) train vimp2_845_05312013_VZ_Aug4_Rot_4_sd2
(365/456) train vimp2_845_05312013_VZ_Aug5_Rot_-2_sd2
(366/456) train vimp2_869_06142013_BL_Aug0_Rot_3_sd2
(367/456) train vimp2_869_06142013_BL_Aug1_Rot_7_sd2
(368/456) train vimp2_869_06142013_BL_Aug2_Rot_4_sd2
(369/456) train vimp2_869_06142013_BL_Aug3_Rot_1_sd2
(370/456) train vimp2_869_06142013_BL_Aug4_Rot_1_sd2
(371/456) train vimp2_869_06142013_BL_Aug5_Rot_1_sd2
(372/456) train vimp2_884_06272013_TS_Aug0_Rot_3_sd2
(373/456) train vimp2_884_06272013_TS_Aug1_Rot_-5_sd2
(374/456) train vimp2_884_06272013_TS_Aug2_Rot_-7_sd2
(375/456) train vimp2_884_06272013_TS_Aug3_Rot_-6_sd2
(376/456) train vimp2_884_06272013_TS_Aug4_Rot_-2_sd2
(377/456) train vimp2_884_06272013_TS_Aug5_Rot_-6_sd2
(378/456) train vimp2_901_07052013_AS_Aug0_Rot_2_sd2
(379/456) train vimp2_901_07052013_AS_Aug1_Rot_-3_sd2
(380/456) train vimp2_901_07052013_AS_Aug2_Rot_-6_sd2
(381/456) train vimp2_901_07052013_AS_Aug3_Rot_6_sd2
(382/456) train vimp2_901_07052013_AS_Aug4_Rot_-5_sd2
(383/456) train vimp2_901_07052013_AS_Aug5_Rot_1_sd2
(384/456) train vimp2_915_07112013_LC_Aug0_Rot_1_sd2
(385/456) train vimp2_915_07112013_LC_Aug1_Rot_7_sd2
(386/456) train vimp2_915_07112013_LC_Aug2_Rot_3_sd2
(387/456) train vimp2_915_07112013_LC_Aug3_Rot_6_sd2
(388/456) train vimp2_915_07112013_LC_Aug4_Rot_4_sd2
(389/456) train vimp2_915_07112013_LC_Aug5_Rot_4_sd2
(390/456) train vimp2_943_07242013_PA_Aug0_Rot_3_sd2
(391/456) train vimp2_943_07242013_PA_Aug1_Rot_-4_sd2
(392/456) train vimp2_943_07242013_PA_Aug2_Rot_3_sd2
(393/456) train vimp2_943_07242013_PA_Aug3_Rot_2_sd2
(394/456) train vimp2_943_07242013_PA_Aug4_Rot_-1_sd2
(395/456) train vimp2_943_07242013_PA_Aug5_Rot_-3_sd2
(396/456) train vimp2_964_08092013_TG_Aug0_Rot_2_sd2
(397/456) train vimp2_964_08092013_TG_Aug1_Rot_-6_sd2
(398/456) train vimp2_964_08092013_TG_Aug2_Rot_5_sd2
(399/456) train vimp2_964_08092013_TG_Aug3_Rot_-7_sd2
(400/456) train vimp2_964_08092013_TG_Aug4_Rot_-6_sd2
(401/456) train vimp2_964_08092013_TG_Aug5_Rot_5_sd2
(402/456) train vimp2_ANON606_20130110_Aug0_Rot_-6_sd2
(403/456) train vimp2_ANON606_20130110_Aug1_Rot_-5_sd2
(404/456) train vimp2_ANON606_20130110_Aug2_Rot_-3_sd2
(405/456) train vimp2_ANON606_20130110_Aug3_Rot_3_sd2
(406/456) train vimp2_ANON606_20130110_Aug4_Rot_-2_sd2
(407/456) train vimp2_ANON606_20130110_Aug5_Rot_-3_sd2
(408/456) train vimp2_ANON624_20130117_Aug0_Rot_2_sd2
(409/456) train vimp2_ANON624_20130117_Aug1_Rot_-2_sd2
(410/456) train vimp2_ANON624_20130117_Aug2_Rot_-6_sd2
(411/456) train vimp2_ANON624_20130117_Aug3_Rot_1_sd2
(412/456) train vimp2_ANON624_20130117_Aug4_Rot_-5_sd2
(413/456) train vimp2_ANON624_20130117_Aug5_Rot_-7_sd2
(414/456) train vimp2_ANON724_03272013_Aug0_Rot_-5_sd2
(415/456) train vimp2_ANON724_03272013_Aug1_Rot_6_sd2
(416/456) train vimp2_ANON724_03272013_Aug2_Rot_-3_sd2
(417/456) train vimp2_ANON724_03272013_Aug3_Rot_-6_sd2
(418/456) train vimp2_ANON724_03272013_Aug4_Rot_-1_sd2
(419/456) train vimp2_ANON724_03272013_Aug5_Rot_-7_sd2
(420/456) train vimp2_ctrl_902_07052013_SI_Aug0_Rot_-4_sd2
(421/456) train vimp2_ctrl_902_07052013_SI_Aug1_Rot_-3_sd2
(422/456) train vimp2_ctrl_902_07052013_SI_Aug2_Rot_-5_sd2
(423/456) train vimp2_ctrl_902_07052013_SI_Aug3_Rot_5_sd2
(424/456) train vimp2_ctrl_902_07052013_SI_Aug4_Rot_-2_sd2
(425/456) train vimp2_ctrl_902_07052013_SI_Aug5_Rot_5_sd2
(426/456) train vimp2_ctrl_911_07082013_TTO_Aug0_Rot_-3_sd2
(427/456) train vimp2_ctrl_911_07082013_TTO_Aug1_Rot_7_sd2
(428/456) train vimp2_ctrl_911_07082013_TTO_Aug2_Rot_3_sd2
(429/456) train vimp2_ctrl_911_07082013_TTO_Aug3_Rot_5_sd2
(430/456) train vimp2_ctrl_911_07082013_TTO_Aug4_Rot_7_sd2
(431/456) train vimp2_ctrl_911_07082013_TTO_Aug5_Rot_2_sd2
(432/456) train vimp2_ctrl_918_07112013_TQ_Aug0_Rot_-7_sd2
(433/456) train vimp2_ctrl_918_07112013_TQ_Aug1_Rot_5_sd2
(434/456) train vimp2_ctrl_918_07112013_TQ_Aug2_Rot_5_sd2
(435/456) train vimp2_ctrl_918_07112013_TQ_Aug3_Rot_4_sd2
(436/456) train vimp2_ctrl_918_07112013_TQ_Aug4_Rot_5_sd2
(437/456) train vimp2_ctrl_918_07112013_TQ_Aug5_Rot_-4_sd2
(438/456) train vimp2_ctrl_920_07122013_SW_Aug0_Rot_7_sd2
(439/456) train vimp2_ctrl_920_07122013_SW_Aug1_Rot_-2_sd2
(440/456) train vimp2_ctrl_920_07122013_SW_Aug2_Rot_1_sd2
(441/456) train vimp2_ctrl_920_07122013_SW_Aug3_Rot_-7_sd2
(442/456) train vimp2_ctrl_920_07122013_SW_Aug4_Rot_-3_sd2
(443/456) train vimp2_ctrl_920_07122013_SW_Aug5_Rot_7_sd2
(444/456) train vimp2_ctrl_921_07122013_MP_Aug0_Rot_1_sd2
(445/456) train vimp2_ctrl_921_07122013_MP_Aug1_Rot_-7_sd2
(446/456) train vimp2_ctrl_921_07122013_MP_Aug2_Rot_6_sd2
(447/456) train vimp2_ctrl_921_07122013_MP_Aug3_Rot_-2_sd2
(448/456) train vimp2_ctrl_921_07122013_MP_Aug4_Rot_-5_sd2
(449/456) train vimp2_ctrl_921_07122013_MP_Aug5_Rot_6_sd2
(450/456) train vimp2_ctrl_925_07152013_LS_Aug0_Rot_2_sd2
(451/456) train vimp2_ctrl_925_07152013_LS_Aug1_Rot_5_sd2
(452/456) train vimp2_ctrl_925_07152013_LS_Aug2_Rot_2_sd2
(453/456) train vimp2_ctrl_925_07152013_LS_Aug3_Rot_5_sd2
(454/456) train vimp2_ctrl_925_07152013_LS_Aug4_Rot_-4_sd2
(455/456) train vimp2_ctrl_925_07152013_LS_Aug5_Rot_-3_sd22019-07-06 17:14:22.288796: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-06 17:14:24.635509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:05:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2019-07-06 17:14:24.635575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-06 17:14:25.010552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-06 17:14:25.010627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-06 17:14:25.010640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-06 17:14:25.011092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)
mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1’: File exists
mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1’: File exists
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using TensorFlow backend.
Loading train:   0%|          | 0/532 [00:00<?, ?it/s]Loading train:   0%|          | 1/532 [00:01<11:01,  1.25s/it]Loading train:   0%|          | 2/532 [00:02<10:01,  1.14s/it]Loading train:   1%|          | 3/532 [00:03<09:22,  1.06s/it]Loading train:   1%|          | 4/532 [00:03<08:36,  1.02it/s]Loading train:   1%|          | 5/532 [00:04<08:12,  1.07it/s]Loading train:   1%|          | 6/532 [00:05<07:37,  1.15it/s]Loading train:   1%|▏         | 7/532 [00:06<07:20,  1.19it/s]Loading train:   2%|▏         | 8/532 [00:06<07:02,  1.24it/s]Loading train:   2%|▏         | 9/532 [00:07<07:53,  1.10it/s]Loading train:   2%|▏         | 10/532 [00:08<07:34,  1.15it/s]Loading train:   2%|▏         | 11/532 [00:09<07:11,  1.21it/s]Loading train:   2%|▏         | 12/532 [00:10<07:51,  1.10it/s]Loading train:   2%|▏         | 13/532 [00:11<07:13,  1.20it/s]Loading train:   3%|▎         | 14/532 [00:11<06:53,  1.25it/s]Loading train:   3%|▎         | 15/532 [00:12<06:48,  1.27it/s]Loading train:   3%|▎         | 16/532 [00:13<07:08,  1.20it/s]Loading train:   3%|▎         | 17/532 [00:14<07:29,  1.15it/s]Loading train:   3%|▎         | 18/532 [00:15<07:49,  1.10it/s]Loading train:   4%|▎         | 19/532 [00:16<07:35,  1.13it/s]Loading train:   4%|▍         | 20/532 [00:17<07:53,  1.08it/s]Loading train:   4%|▍         | 21/532 [00:18<08:03,  1.06it/s]Loading train:   4%|▍         | 22/532 [00:19<07:34,  1.12it/s]Loading train:   4%|▍         | 23/532 [00:20<07:36,  1.12it/s]Loading train:   5%|▍         | 24/532 [00:20<07:23,  1.15it/s]Loading train:   5%|▍         | 25/532 [00:22<08:22,  1.01it/s]Loading train:   5%|▍         | 26/532 [00:23<08:13,  1.03it/s]Loading train:   5%|▌         | 27/532 [00:24<08:55,  1.06s/it]Loading train:   5%|▌         | 28/532 [00:25<08:24,  1.00s/it]Loading train:   5%|▌         | 29/532 [00:26<08:29,  1.01s/it]Loading train:   6%|▌         | 30/532 [00:27<07:56,  1.05it/s]Loading train:   6%|▌         | 31/532 [00:28<07:50,  1.06it/s]Loading train:   6%|▌         | 32/532 [00:29<08:04,  1.03it/s]Loading train:   6%|▌         | 33/532 [00:29<07:40,  1.08it/s]Loading train:   6%|▋         | 34/532 [00:30<07:52,  1.06it/s]Loading train:   7%|▋         | 35/532 [00:31<07:40,  1.08it/s]Loading train:   7%|▋         | 36/532 [00:32<07:39,  1.08it/s]Loading train:   7%|▋         | 37/532 [00:33<07:33,  1.09it/s]Loading train:   7%|▋         | 38/532 [00:34<07:46,  1.06it/s]Loading train:   7%|▋         | 39/532 [00:35<07:58,  1.03it/s]Loading train:   8%|▊         | 40/532 [00:36<07:29,  1.09it/s]Loading train:   8%|▊         | 41/532 [00:37<07:15,  1.13it/s]Loading train:   8%|▊         | 42/532 [00:38<07:12,  1.13it/s]Loading train:   8%|▊         | 43/532 [00:38<06:38,  1.23it/s]Loading train:   8%|▊         | 44/532 [00:39<06:04,  1.34it/s]Loading train:   8%|▊         | 45/532 [00:40<06:02,  1.34it/s]Loading train:   9%|▊         | 46/532 [00:41<06:41,  1.21it/s]Loading train:   9%|▉         | 47/532 [00:42<07:15,  1.11it/s]Loading train:   9%|▉         | 48/532 [00:43<07:30,  1.07it/s]Loading train:   9%|▉         | 49/532 [00:43<07:08,  1.13it/s]Loading train:   9%|▉         | 50/532 [00:45<07:30,  1.07it/s]Loading train:  10%|▉         | 51/532 [00:45<07:10,  1.12it/s]Loading train:  10%|▉         | 52/532 [00:46<07:13,  1.11it/s]Loading train:  10%|▉         | 53/532 [00:47<07:14,  1.10it/s]Loading train:  10%|█         | 54/532 [00:48<07:33,  1.05it/s]Loading train:  10%|█         | 55/532 [00:49<07:17,  1.09it/s]Loading train:  11%|█         | 56/532 [00:50<07:12,  1.10it/s]Loading train:  11%|█         | 57/532 [00:51<07:41,  1.03it/s]Loading train:  11%|█         | 58/532 [00:52<07:26,  1.06it/s]Loading train:  11%|█         | 59/532 [00:53<07:54,  1.00s/it]Loading train:  11%|█▏        | 60/532 [00:54<07:14,  1.09it/s]Loading train:  11%|█▏        | 61/532 [00:55<06:58,  1.13it/s]Loading train:  12%|█▏        | 62/532 [00:56<07:17,  1.07it/s]Loading train:  12%|█▏        | 63/532 [00:57<07:26,  1.05it/s]Loading train:  12%|█▏        | 64/532 [00:57<07:01,  1.11it/s]Loading train:  12%|█▏        | 65/532 [00:58<07:05,  1.10it/s]Loading train:  12%|█▏        | 66/532 [01:00<07:44,  1.00it/s]Loading train:  13%|█▎        | 67/532 [01:01<07:38,  1.01it/s]Loading train:  13%|█▎        | 68/532 [01:01<07:18,  1.06it/s]Loading train:  13%|█▎        | 69/532 [01:02<07:09,  1.08it/s]Loading train:  13%|█▎        | 70/532 [01:03<06:47,  1.13it/s]Loading train:  13%|█▎        | 71/532 [01:04<06:42,  1.15it/s]Loading train:  14%|█▎        | 72/532 [01:05<06:15,  1.23it/s]Loading train:  14%|█▎        | 73/532 [01:05<06:22,  1.20it/s]Loading train:  14%|█▍        | 74/532 [01:07<07:04,  1.08it/s]Loading train:  14%|█▍        | 75/532 [01:08<08:14,  1.08s/it]Loading train:  14%|█▍        | 76/532 [01:09<07:47,  1.03s/it]Loading train:  14%|█▍        | 77/532 [01:10<07:40,  1.01s/it]Loading train:  15%|█▍        | 78/532 [01:11<07:32,  1.00it/s]Loading train:  15%|█▍        | 79/532 [01:12<07:15,  1.04it/s]Loading train:  15%|█▌        | 80/532 [01:13<07:05,  1.06it/s]Loading train:  15%|█▌        | 81/532 [01:14<06:58,  1.08it/s]Loading train:  15%|█▌        | 82/532 [01:14<06:51,  1.09it/s]Loading train:  16%|█▌        | 83/532 [01:15<06:39,  1.12it/s]Loading train:  16%|█▌        | 84/532 [01:16<06:26,  1.16it/s]Loading train:  16%|█▌        | 85/532 [01:17<06:12,  1.20it/s]Loading train:  16%|█▌        | 86/532 [01:18<06:05,  1.22it/s]Loading train:  16%|█▋        | 87/532 [01:18<05:59,  1.24it/s]Loading train:  17%|█▋        | 88/532 [01:19<05:56,  1.25it/s]Loading train:  17%|█▋        | 89/532 [01:20<06:06,  1.21it/s]Loading train:  17%|█▋        | 90/532 [01:21<06:00,  1.23it/s]Loading train:  17%|█▋        | 91/532 [01:22<06:06,  1.20it/s]Loading train:  17%|█▋        | 92/532 [01:23<06:24,  1.14it/s]Loading train:  17%|█▋        | 93/532 [01:24<06:20,  1.15it/s]Loading train:  18%|█▊        | 94/532 [01:24<06:13,  1.17it/s]Loading train:  18%|█▊        | 95/532 [01:25<06:38,  1.10it/s]Loading train:  18%|█▊        | 96/532 [01:27<07:12,  1.01it/s]Loading train:  18%|█▊        | 97/532 [01:28<07:13,  1.00it/s]Loading train:  18%|█▊        | 98/532 [01:29<07:20,  1.01s/it]Loading train:  19%|█▊        | 99/532 [01:30<07:12,  1.00it/s]Loading train:  19%|█▉        | 100/532 [01:31<07:22,  1.02s/it]Loading train:  19%|█▉        | 101/532 [01:32<06:52,  1.04it/s]Loading train:  19%|█▉        | 102/532 [01:32<06:28,  1.11it/s]Loading train:  19%|█▉        | 103/532 [01:33<06:06,  1.17it/s]Loading train:  20%|█▉        | 104/532 [01:34<05:56,  1.20it/s]Loading train:  20%|█▉        | 105/532 [01:35<05:55,  1.20it/s]Loading train:  20%|█▉        | 106/532 [01:35<05:44,  1.24it/s]Loading train:  20%|██        | 107/532 [01:36<05:32,  1.28it/s]Loading train:  20%|██        | 108/532 [01:37<05:23,  1.31it/s]Loading train:  20%|██        | 109/532 [01:38<05:13,  1.35it/s]Loading train:  21%|██        | 110/532 [01:38<05:16,  1.34it/s]Loading train:  21%|██        | 111/532 [01:39<05:18,  1.32it/s]Loading train:  21%|██        | 112/532 [01:40<05:16,  1.33it/s]Loading train:  21%|██        | 113/532 [01:41<05:37,  1.24it/s]Loading train:  21%|██▏       | 114/532 [01:42<05:43,  1.22it/s]Loading train:  22%|██▏       | 115/532 [01:43<05:54,  1.18it/s]Loading train:  22%|██▏       | 116/532 [01:43<05:54,  1.17it/s]Loading train:  22%|██▏       | 117/532 [01:44<05:57,  1.16it/s]Loading train:  22%|██▏       | 118/532 [01:45<06:00,  1.15it/s]Loading train:  22%|██▏       | 119/532 [01:46<06:06,  1.13it/s]Loading train:  23%|██▎       | 120/532 [01:47<06:09,  1.11it/s]Loading train:  23%|██▎       | 121/532 [01:48<06:28,  1.06it/s]Loading train:  23%|██▎       | 122/532 [01:49<06:23,  1.07it/s]Loading train:  23%|██▎       | 123/532 [01:50<06:21,  1.07it/s]Loading train:  23%|██▎       | 124/532 [01:51<06:12,  1.10it/s]Loading train:  23%|██▎       | 125/532 [01:52<06:16,  1.08it/s]Loading train:  24%|██▎       | 126/532 [01:53<06:12,  1.09it/s]Loading train:  24%|██▍       | 127/532 [01:54<06:08,  1.10it/s]Loading train:  24%|██▍       | 128/532 [01:54<06:05,  1.11it/s]Loading train:  24%|██▍       | 129/532 [01:55<06:07,  1.10it/s]Loading train:  24%|██▍       | 130/532 [01:56<06:06,  1.10it/s]Loading train:  25%|██▍       | 131/532 [01:57<06:25,  1.04it/s]Loading train:  25%|██▍       | 132/532 [01:58<06:42,  1.01s/it]Loading train:  25%|██▌       | 133/532 [02:00<06:58,  1.05s/it]Loading train:  25%|██▌       | 134/532 [02:01<07:02,  1.06s/it]Loading train:  25%|██▌       | 135/532 [02:02<07:14,  1.10s/it]Loading train:  26%|██▌       | 136/532 [02:03<07:18,  1.11s/it]Loading train:  26%|██▌       | 137/532 [02:04<07:23,  1.12s/it]Loading train:  26%|██▌       | 138/532 [02:05<07:34,  1.15s/it]Loading train:  26%|██▌       | 139/532 [02:06<07:29,  1.14s/it]Loading train:  26%|██▋       | 140/532 [02:08<07:39,  1.17s/it]Loading train:  27%|██▋       | 141/532 [02:09<07:34,  1.16s/it]Loading train:  27%|██▋       | 142/532 [02:10<07:37,  1.17s/it]Loading train:  27%|██▋       | 143/532 [02:11<06:54,  1.07s/it]Loading train:  27%|██▋       | 144/532 [02:12<06:26,  1.00it/s]Loading train:  27%|██▋       | 145/532 [02:13<06:04,  1.06it/s]Loading train:  27%|██▋       | 146/532 [02:13<05:43,  1.12it/s]Loading train:  28%|██▊       | 147/532 [02:14<05:25,  1.18it/s]Loading train:  28%|██▊       | 148/532 [02:15<05:20,  1.20it/s]Loading train:  28%|██▊       | 149/532 [02:16<05:24,  1.18it/s]Loading train:  28%|██▊       | 150/532 [02:17<05:30,  1.16it/s]Loading train:  28%|██▊       | 151/532 [02:17<05:20,  1.19it/s]Loading train:  29%|██▊       | 152/532 [02:18<05:15,  1.20it/s]Loading train:  29%|██▉       | 153/532 [02:19<05:18,  1.19it/s]Loading train:  29%|██▉       | 154/532 [02:20<05:11,  1.21it/s]Loading train:  29%|██▉       | 155/532 [02:21<05:42,  1.10it/s]Loading train:  29%|██▉       | 156/532 [02:22<06:13,  1.01it/s]Loading train:  30%|██▉       | 157/532 [02:23<06:33,  1.05s/it]Loading train:  30%|██▉       | 158/532 [02:24<06:37,  1.06s/it]Loading train:  30%|██▉       | 159/532 [02:26<06:52,  1.10s/it]Loading train:  30%|███       | 160/532 [02:27<07:02,  1.14s/it]Loading train:  30%|███       | 161/532 [02:28<06:38,  1.07s/it]Loading train:  30%|███       | 162/532 [02:29<06:16,  1.02s/it]Loading train:  31%|███       | 163/532 [02:29<05:49,  1.05it/s]Loading train:  31%|███       | 164/532 [02:30<05:35,  1.10it/s]Loading train:  31%|███       | 165/532 [02:31<05:33,  1.10it/s]Loading train:  31%|███       | 166/532 [02:32<05:28,  1.11it/s]Loading train:  31%|███▏      | 167/532 [02:33<05:36,  1.08it/s]Loading train:  32%|███▏      | 168/532 [02:34<05:35,  1.09it/s]Loading train:  32%|███▏      | 169/532 [02:35<05:34,  1.08it/s]Loading train:  32%|███▏      | 170/532 [02:36<05:35,  1.08it/s]Loading train:  32%|███▏      | 171/532 [02:37<05:39,  1.06it/s]Loading train:  32%|███▏      | 172/532 [02:38<05:37,  1.07it/s]Loading train:  33%|███▎      | 173/532 [02:39<05:26,  1.10it/s]Loading train:  33%|███▎      | 174/532 [02:39<05:22,  1.11it/s]Loading train:  33%|███▎      | 175/532 [02:40<05:07,  1.16it/s]Loading train:  33%|███▎      | 176/532 [02:41<04:59,  1.19it/s]Loading train:  33%|███▎      | 177/532 [02:42<04:50,  1.22it/s]Loading train:  33%|███▎      | 178/532 [02:43<04:38,  1.27it/s]Loading train:  34%|███▎      | 179/532 [02:43<04:38,  1.27it/s]Loading train:  34%|███▍      | 180/532 [02:44<04:30,  1.30it/s]Loading train:  34%|███▍      | 181/532 [02:45<04:32,  1.29it/s]Loading train:  34%|███▍      | 182/532 [02:46<04:38,  1.26it/s]Loading train:  34%|███▍      | 183/532 [02:46<04:39,  1.25it/s]Loading train:  35%|███▍      | 184/532 [02:47<04:42,  1.23it/s]Loading train:  35%|███▍      | 185/532 [02:48<04:59,  1.16it/s]Loading train:  35%|███▍      | 186/532 [02:49<04:52,  1.18it/s]Loading train:  35%|███▌      | 187/532 [02:50<04:51,  1.18it/s]Loading train:  35%|███▌      | 188/532 [02:51<04:54,  1.17it/s]Loading train:  36%|███▌      | 189/532 [02:52<04:52,  1.17it/s]Loading train:  36%|███▌      | 190/532 [02:53<04:55,  1.16it/s]Loading train:  36%|███▌      | 191/532 [02:54<05:18,  1.07it/s]Loading train:  36%|███▌      | 192/532 [02:55<05:44,  1.01s/it]Loading train:  36%|███▋      | 193/532 [02:56<05:58,  1.06s/it]Loading train:  36%|███▋      | 194/532 [02:57<06:07,  1.09s/it]Loading train:  37%|███▋      | 195/532 [02:58<06:10,  1.10s/it]Loading train:  37%|███▋      | 196/532 [02:59<06:11,  1.11s/it]Loading train:  37%|███▋      | 197/532 [03:00<05:57,  1.07s/it]Loading train:  37%|███▋      | 198/532 [03:01<05:45,  1.03s/it]Loading train:  37%|███▋      | 199/532 [03:02<05:49,  1.05s/it]Loading train:  38%|███▊      | 200/532 [03:03<05:40,  1.03s/it]Loading train:  38%|███▊      | 201/532 [03:04<05:32,  1.00s/it]Loading train:  38%|███▊      | 202/532 [03:05<05:40,  1.03s/it]Loading train:  38%|███▊      | 203/532 [03:06<05:18,  1.03it/s]Loading train:  38%|███▊      | 204/532 [03:07<05:01,  1.09it/s]Loading train:  39%|███▊      | 205/532 [03:08<04:43,  1.15it/s]Loading train:  39%|███▊      | 206/532 [03:09<04:35,  1.18it/s]Loading train:  39%|███▉      | 207/532 [03:09<04:29,  1.21it/s]Loading train:  39%|███▉      | 208/532 [03:10<04:25,  1.22it/s]Loading train:  39%|███▉      | 209/532 [03:11<04:23,  1.22it/s]Loading train:  39%|███▉      | 210/532 [03:12<04:12,  1.28it/s]Loading train:  40%|███▉      | 211/532 [03:12<04:07,  1.30it/s]Loading train:  40%|███▉      | 212/532 [03:13<04:04,  1.31it/s]Loading train:  40%|████      | 213/532 [03:14<04:04,  1.31it/s]Loading train:  40%|████      | 214/532 [03:15<04:02,  1.31it/s]Loading train:  40%|████      | 215/532 [03:16<04:37,  1.14it/s]Loading train:  41%|████      | 216/532 [03:17<05:04,  1.04it/s]Loading train:  41%|████      | 217/532 [03:18<05:36,  1.07s/it]Loading train:  41%|████      | 218/532 [03:19<05:30,  1.05s/it]Loading train:  41%|████      | 219/532 [03:20<05:29,  1.05s/it]Loading train:  41%|████▏     | 220/532 [03:22<05:40,  1.09s/it]Loading train:  42%|████▏     | 221/532 [03:22<05:16,  1.02s/it]Loading train:  42%|████▏     | 222/532 [03:23<05:01,  1.03it/s]Loading train:  42%|████▏     | 223/532 [03:24<04:47,  1.07it/s]Loading train:  42%|████▏     | 224/532 [03:25<04:40,  1.10it/s]Loading train:  42%|████▏     | 225/532 [03:26<04:22,  1.17it/s]Loading train:  42%|████▏     | 226/532 [03:27<04:19,  1.18it/s]Loading train:  43%|████▎     | 227/532 [03:27<04:15,  1.19it/s]Loading train:  43%|████▎     | 228/532 [03:28<04:02,  1.26it/s]Loading train:  43%|████▎     | 229/532 [03:29<03:53,  1.30it/s]Loading train:  43%|████▎     | 230/532 [03:30<03:52,  1.30it/s]Loading train:  43%|████▎     | 231/532 [03:30<03:50,  1.31it/s]Loading train:  44%|████▎     | 232/532 [03:31<03:48,  1.31it/s]Loading train:  44%|████▍     | 233/532 [03:32<03:58,  1.25it/s]Loading train:  44%|████▍     | 234/532 [03:33<04:03,  1.22it/s]Loading train:  44%|████▍     | 235/532 [03:34<04:17,  1.15it/s]Loading train:  44%|████▍     | 236/532 [03:35<04:16,  1.15it/s]Loading train:  45%|████▍     | 237/532 [03:35<04:11,  1.17it/s]Loading train:  45%|████▍     | 238/532 [03:36<04:11,  1.17it/s]Loading train:  45%|████▍     | 239/532 [03:37<04:13,  1.15it/s]Loading train:  45%|████▌     | 240/532 [03:38<04:17,  1.13it/s]Loading train:  45%|████▌     | 241/532 [03:39<04:20,  1.12it/s]Loading train:  45%|████▌     | 242/532 [03:40<04:23,  1.10it/s]Loading train:  46%|████▌     | 243/532 [03:41<04:23,  1.10it/s]Loading train:  46%|████▌     | 244/532 [03:42<04:17,  1.12it/s]Loading train:  46%|████▌     | 245/532 [03:43<04:07,  1.16it/s]Loading train:  46%|████▌     | 246/532 [03:43<03:52,  1.23it/s]Loading train:  46%|████▋     | 247/532 [03:44<03:42,  1.28it/s]Loading train:  47%|████▋     | 248/532 [03:45<03:34,  1.33it/s]Loading train:  47%|████▋     | 249/532 [03:45<03:35,  1.31it/s]Loading train:  47%|████▋     | 250/532 [03:46<03:37,  1.30it/s]Loading train:  47%|████▋     | 251/532 [03:47<03:40,  1.27it/s]Loading train:  47%|████▋     | 252/532 [03:48<03:42,  1.26it/s]Loading train:  48%|████▊     | 253/532 [03:49<03:43,  1.25it/s]Loading train:  48%|████▊     | 254/532 [03:49<03:36,  1.28it/s]Loading train:  48%|████▊     | 255/532 [03:50<03:34,  1.29it/s]Loading train:  48%|████▊     | 256/532 [03:51<03:41,  1.25it/s]Loading train:  48%|████▊     | 257/532 [03:52<04:00,  1.14it/s]Loading train:  48%|████▊     | 258/532 [03:53<04:14,  1.08it/s]Loading train:  49%|████▊     | 259/532 [03:54<04:21,  1.04it/s]Loading train:  49%|████▉     | 260/532 [03:55<04:22,  1.03it/s]Loading train:  49%|████▉     | 261/532 [03:56<04:29,  1.01it/s]Loading train:  49%|████▉     | 262/532 [03:57<04:33,  1.01s/it]Loading train:  49%|████▉     | 263/532 [03:58<04:14,  1.06it/s]Loading train:  50%|████▉     | 264/532 [03:59<03:54,  1.14it/s]Loading train:  50%|████▉     | 265/532 [04:00<03:43,  1.20it/s]Loading train:  50%|█████     | 266/532 [04:00<03:30,  1.26it/s]Loading train:  50%|█████     | 267/532 [04:01<03:23,  1.30it/s]Loading train:  50%|█████     | 268/532 [04:02<03:14,  1.35it/s]Loading train:  51%|█████     | 269/532 [04:03<03:28,  1.26it/s]Loading train:  51%|█████     | 270/532 [04:03<03:31,  1.24it/s]Loading train:  51%|█████     | 271/532 [04:04<03:35,  1.21it/s]Loading train:  51%|█████     | 272/532 [04:05<03:35,  1.20it/s]Loading train:  51%|█████▏    | 273/532 [04:06<03:37,  1.19it/s]Loading train:  52%|█████▏    | 274/532 [04:07<03:36,  1.19it/s]Loading train:  52%|█████▏    | 275/532 [04:08<03:49,  1.12it/s]Loading train:  52%|█████▏    | 276/532 [04:09<04:12,  1.02it/s]Loading train:  52%|█████▏    | 277/532 [04:10<04:32,  1.07s/it]Loading train:  52%|█████▏    | 278/532 [04:11<04:31,  1.07s/it]Loading train:  52%|█████▏    | 279/532 [04:12<04:30,  1.07s/it]Loading train:  53%|█████▎    | 280/532 [04:13<04:28,  1.07s/it]Loading train:  53%|█████▎    | 281/532 [04:14<04:23,  1.05s/it]Loading train:  53%|█████▎    | 282/532 [04:15<04:20,  1.04s/it]Loading train:  53%|█████▎    | 283/532 [04:16<04:14,  1.02s/it]Loading train:  53%|█████▎    | 284/532 [04:17<04:09,  1.01s/it]Loading train:  54%|█████▎    | 285/532 [04:18<04:09,  1.01s/it]Loading train:  54%|█████▍    | 286/532 [04:19<04:10,  1.02s/it]Loading train:  54%|█████▍    | 287/532 [04:20<03:51,  1.06it/s]Loading train:  54%|█████▍    | 288/532 [04:21<03:39,  1.11it/s]Loading train:  54%|█████▍    | 289/532 [04:22<03:33,  1.14it/s]Loading train:  55%|█████▍    | 290/532 [04:23<03:25,  1.18it/s]Loading train:  55%|█████▍    | 291/532 [04:23<03:21,  1.20it/s]Loading train:  55%|█████▍    | 292/532 [04:24<03:16,  1.22it/s]Loading train:  55%|█████▌    | 293/532 [04:25<03:19,  1.20it/s]Loading train:  55%|█████▌    | 294/532 [04:26<03:24,  1.16it/s]Loading train:  55%|█████▌    | 295/532 [04:27<03:27,  1.14it/s]Loading train:  56%|█████▌    | 296/532 [04:28<03:29,  1.13it/s]Loading train:  56%|█████▌    | 297/532 [04:29<03:29,  1.12it/s]Loading train:  56%|█████▌    | 298/532 [04:30<03:32,  1.10it/s]Loading train:  56%|█████▌    | 299/532 [04:31<03:31,  1.10it/s]Loading train:  56%|█████▋    | 300/532 [04:31<03:21,  1.15it/s]Loading train:  57%|█████▋    | 301/532 [04:32<03:13,  1.19it/s]Loading train:  57%|█████▋    | 302/532 [04:33<03:10,  1.21it/s]Loading train:  57%|█████▋    | 303/532 [04:34<03:01,  1.26it/s]Loading train:  57%|█████▋    | 304/532 [04:34<02:58,  1.28it/s]Loading train:  57%|█████▋    | 305/532 [04:36<03:25,  1.11it/s]Loading train:  58%|█████▊    | 306/532 [04:37<03:39,  1.03it/s]Loading train:  58%|█████▊    | 307/532 [04:38<03:51,  1.03s/it]Loading train:  58%|█████▊    | 308/532 [04:39<04:00,  1.07s/it]Loading train:  58%|█████▊    | 309/532 [04:40<04:02,  1.09s/it]Loading train:  58%|█████▊    | 310/532 [04:41<04:04,  1.10s/it]Loading train:  58%|█████▊    | 311/532 [04:43<04:30,  1.22s/it]Loading train:  59%|█████▊    | 312/532 [04:44<04:40,  1.27s/it]Loading train:  59%|█████▉    | 313/532 [04:46<04:46,  1.31s/it]Loading train:  59%|█████▉    | 314/532 [04:47<04:48,  1.32s/it]Loading train:  59%|█████▉    | 315/532 [04:48<04:56,  1.36s/it]Loading train:  59%|█████▉    | 316/532 [04:50<04:54,  1.36s/it]Loading train:  60%|█████▉    | 317/532 [04:51<04:23,  1.23s/it]Loading train:  60%|█████▉    | 318/532 [04:52<03:54,  1.10s/it]Loading train:  60%|█████▉    | 319/532 [04:52<03:39,  1.03s/it]Loading train:  60%|██████    | 320/532 [04:53<03:24,  1.04it/s]Loading train:  60%|██████    | 321/532 [04:54<03:18,  1.06it/s]Loading train:  61%|██████    | 322/532 [04:55<03:19,  1.05it/s]Loading train:  61%|██████    | 323/532 [04:56<03:31,  1.01s/it]Loading train:  61%|██████    | 324/532 [04:57<03:37,  1.05s/it]Loading train:  61%|██████    | 325/532 [04:59<03:57,  1.15s/it]Loading train:  61%|██████▏   | 326/532 [05:00<03:58,  1.16s/it]Loading train:  61%|██████▏   | 327/532 [05:01<03:54,  1.14s/it]Loading train:  62%|██████▏   | 328/532 [05:02<03:51,  1.13s/it]Loading train:  62%|██████▏   | 329/532 [05:03<03:37,  1.07s/it]Loading train:  62%|██████▏   | 330/532 [05:04<03:23,  1.01s/it]Loading train:  62%|██████▏   | 331/532 [05:05<03:11,  1.05it/s]Loading train:  62%|██████▏   | 332/532 [05:06<03:05,  1.08it/s]Loading train:  63%|██████▎   | 333/532 [05:06<03:00,  1.10it/s]Loading train:  63%|██████▎   | 334/532 [05:07<02:52,  1.15it/s]Loading train:  63%|██████▎   | 335/532 [05:08<03:02,  1.08it/s]Loading train:  63%|██████▎   | 336/532 [05:09<03:09,  1.04it/s]Loading train:  63%|██████▎   | 337/532 [05:10<03:11,  1.02it/s]Loading train:  64%|██████▎   | 338/532 [05:11<03:12,  1.01it/s]Loading train:  64%|██████▎   | 339/532 [05:12<03:11,  1.01it/s]Loading train:  64%|██████▍   | 340/532 [05:13<03:09,  1.01it/s]Loading train:  64%|██████▍   | 341/532 [05:14<02:57,  1.07it/s]Loading train:  64%|██████▍   | 342/532 [05:15<02:49,  1.12it/s]Loading train:  64%|██████▍   | 343/532 [05:16<02:53,  1.09it/s]Loading train:  65%|██████▍   | 344/532 [05:17<02:48,  1.12it/s]Loading train:  65%|██████▍   | 345/532 [05:18<02:40,  1.16it/s]Loading train:  65%|██████▌   | 346/532 [05:18<02:37,  1.18it/s]Loading train:  65%|██████▌   | 347/532 [05:19<02:39,  1.16it/s]Loading train:  65%|██████▌   | 348/532 [05:20<02:37,  1.17it/s]Loading train:  66%|██████▌   | 349/532 [05:21<02:35,  1.17it/s]Loading train:  66%|██████▌   | 350/532 [05:22<02:33,  1.19it/s]Loading train:  66%|██████▌   | 351/532 [05:23<02:33,  1.18it/s]Loading train:  66%|██████▌   | 352/532 [05:23<02:29,  1.21it/s]Loading train:  66%|██████▋   | 353/532 [05:24<02:29,  1.20it/s]Loading train:  67%|██████▋   | 354/532 [05:25<02:25,  1.22it/s]Loading train:  67%|██████▋   | 355/532 [05:26<02:20,  1.26it/s]Loading train:  67%|██████▋   | 356/532 [05:27<02:17,  1.28it/s]Loading train:  67%|██████▋   | 357/532 [05:27<02:15,  1.29it/s]Loading train:  67%|██████▋   | 358/532 [05:28<02:14,  1.30it/s]Loading train:  67%|██████▋   | 359/532 [05:29<02:17,  1.25it/s]Loading train:  68%|██████▊   | 360/532 [05:30<02:13,  1.29it/s]Loading train:  68%|██████▊   | 361/532 [05:30<02:14,  1.27it/s]Loading train:  68%|██████▊   | 362/532 [05:31<02:21,  1.20it/s]Loading train:  68%|██████▊   | 363/532 [05:32<02:18,  1.22it/s]Loading train:  68%|██████▊   | 364/532 [05:33<02:17,  1.22it/s]Loading train:  69%|██████▊   | 365/532 [05:34<02:16,  1.23it/s]Loading train:  69%|██████▉   | 366/532 [05:35<02:15,  1.22it/s]Loading train:  69%|██████▉   | 367/532 [05:35<02:10,  1.27it/s]Loading train:  69%|██████▉   | 368/532 [05:36<02:11,  1.25it/s]Loading train:  69%|██████▉   | 369/532 [05:37<02:09,  1.26it/s]Loading train:  70%|██████▉   | 370/532 [05:38<02:06,  1.28it/s]Loading train:  70%|██████▉   | 371/532 [05:39<02:21,  1.14it/s]Loading train:  70%|██████▉   | 372/532 [05:40<02:28,  1.08it/s]Loading train:  70%|███████   | 373/532 [05:41<02:35,  1.03it/s]Loading train:  70%|███████   | 374/532 [05:42<02:38,  1.00s/it]Loading train:  70%|███████   | 375/532 [05:43<02:38,  1.01s/it]Loading train:  71%|███████   | 376/532 [05:44<02:37,  1.01s/it]Loading train:  71%|███████   | 377/532 [05:45<02:32,  1.02it/s]Loading train:  71%|███████   | 378/532 [05:46<02:26,  1.05it/s]Loading train:  71%|███████   | 379/532 [05:47<02:22,  1.07it/s]Loading train:  71%|███████▏  | 380/532 [05:48<02:18,  1.10it/s]Loading train:  72%|███████▏  | 381/532 [05:49<02:19,  1.08it/s]Loading train:  72%|███████▏  | 382/532 [05:49<02:14,  1.12it/s]Loading train:  72%|███████▏  | 383/532 [05:50<02:12,  1.13it/s]Loading train:  72%|███████▏  | 384/532 [05:51<02:10,  1.13it/s]Loading train:  72%|███████▏  | 385/532 [05:52<02:11,  1.12it/s]Loading train:  73%|███████▎  | 386/532 [05:53<02:08,  1.13it/s]Loading train:  73%|███████▎  | 387/532 [05:54<02:08,  1.12it/s]Loading train:  73%|███████▎  | 388/532 [05:55<02:05,  1.15it/s]Loading train:  73%|███████▎  | 389/532 [05:56<02:10,  1.09it/s]Loading train:  73%|███████▎  | 390/532 [05:57<02:13,  1.06it/s]Loading train:  73%|███████▎  | 391/532 [05:58<02:15,  1.04it/s]Loading train:  74%|███████▎  | 392/532 [05:59<02:16,  1.03it/s]Loading train:  74%|███████▍  | 393/532 [06:00<02:19,  1.00s/it]Loading train:  74%|███████▍  | 394/532 [06:01<02:16,  1.01it/s]Loading train:  74%|███████▍  | 395/532 [06:02<02:15,  1.01it/s]Loading train:  74%|███████▍  | 396/532 [06:03<02:15,  1.00it/s]Loading train:  75%|███████▍  | 397/532 [06:04<02:12,  1.02it/s]Loading train:  75%|███████▍  | 398/532 [06:05<02:10,  1.03it/s]Loading train:  75%|███████▌  | 399/532 [06:06<02:07,  1.05it/s]Loading train:  75%|███████▌  | 400/532 [06:06<02:07,  1.04it/s]Loading train:  75%|███████▌  | 401/532 [06:07<02:05,  1.04it/s]Loading train:  76%|███████▌  | 402/532 [06:08<02:04,  1.04it/s]Loading train:  76%|███████▌  | 403/532 [06:10<02:13,  1.03s/it]Loading train:  76%|███████▌  | 404/532 [06:11<02:10,  1.02s/it]Loading train:  76%|███████▌  | 405/532 [06:12<02:07,  1.01s/it]Loading train:  76%|███████▋  | 406/532 [06:13<02:05,  1.01it/s]Loading train:  77%|███████▋  | 407/532 [06:13<01:58,  1.05it/s]Loading train:  77%|███████▋  | 408/532 [06:14<01:53,  1.09it/s]Loading train:  77%|███████▋  | 409/532 [06:15<01:47,  1.14it/s]Loading train:  77%|███████▋  | 410/532 [06:16<01:45,  1.15it/s]Loading train:  77%|███████▋  | 411/532 [06:17<01:43,  1.17it/s]Loading train:  77%|███████▋  | 412/532 [06:18<01:42,  1.18it/s]Loading train:  78%|███████▊  | 413/532 [06:18<01:39,  1.19it/s]Loading train:  78%|███████▊  | 414/532 [06:19<01:35,  1.24it/s]Loading train:  78%|███████▊  | 415/532 [06:20<01:38,  1.18it/s]Loading train:  78%|███████▊  | 416/532 [06:21<01:36,  1.21it/s]Loading train:  78%|███████▊  | 417/532 [06:22<01:37,  1.17it/s]Loading train:  79%|███████▊  | 418/532 [06:23<01:38,  1.16it/s]Loading train:  79%|███████▉  | 419/532 [06:24<01:43,  1.10it/s]Loading train:  79%|███████▉  | 420/532 [06:25<01:42,  1.09it/s]Loading train:  79%|███████▉  | 421/532 [06:25<01:41,  1.09it/s]Loading train:  79%|███████▉  | 422/532 [06:26<01:41,  1.08it/s]Loading train:  80%|███████▉  | 423/532 [06:28<01:47,  1.01it/s]Loading train:  80%|███████▉  | 424/532 [06:28<01:43,  1.04it/s]Loading train:  80%|███████▉  | 425/532 [06:29<01:42,  1.04it/s]Loading train:  80%|████████  | 426/532 [06:30<01:40,  1.06it/s]Loading train:  80%|████████  | 427/532 [06:31<01:41,  1.04it/s]Loading train:  80%|████████  | 428/532 [06:32<01:38,  1.05it/s]Loading train:  81%|████████  | 429/532 [06:33<01:39,  1.04it/s]Loading train:  81%|████████  | 430/532 [06:34<01:39,  1.03it/s]Loading train:  81%|████████  | 431/532 [06:35<01:41,  1.01s/it]Loading train:  81%|████████  | 432/532 [06:36<01:39,  1.00it/s]Loading train:  81%|████████▏ | 433/532 [06:37<01:37,  1.02it/s]Loading train:  82%|████████▏ | 434/532 [06:38<01:35,  1.02it/s]Loading train:  82%|████████▏ | 435/532 [06:39<01:34,  1.03it/s]Loading train:  82%|████████▏ | 436/532 [06:40<01:34,  1.01it/s]Loading train:  82%|████████▏ | 437/532 [06:41<01:27,  1.09it/s]Loading train:  82%|████████▏ | 438/532 [06:42<01:23,  1.13it/s]Loading train:  83%|████████▎ | 439/532 [06:43<01:19,  1.16it/s]Loading train:  83%|████████▎ | 440/532 [06:43<01:14,  1.23it/s]Loading train:  83%|████████▎ | 441/532 [06:44<01:12,  1.26it/s]Loading train:  83%|████████▎ | 442/532 [06:45<01:09,  1.29it/s]Loading train:  83%|████████▎ | 443/532 [06:45<01:08,  1.29it/s]Loading train:  83%|████████▎ | 444/532 [06:46<01:07,  1.31it/s]Loading train:  84%|████████▎ | 445/532 [06:47<01:05,  1.32it/s]Loading train:  84%|████████▍ | 446/532 [06:48<01:05,  1.31it/s]Loading train:  84%|████████▍ | 447/532 [06:48<01:03,  1.34it/s]Loading train:  84%|████████▍ | 448/532 [06:49<01:02,  1.34it/s]Loading train:  84%|████████▍ | 449/532 [06:50<01:03,  1.30it/s]Loading train:  85%|████████▍ | 450/532 [06:51<01:03,  1.29it/s]Loading train:  85%|████████▍ | 451/532 [06:52<01:06,  1.23it/s]Loading train:  85%|████████▍ | 452/532 [06:53<01:08,  1.17it/s]Loading train:  85%|████████▌ | 453/532 [06:53<01:06,  1.19it/s]Loading train:  85%|████████▌ | 454/532 [06:54<01:06,  1.18it/s]Loading train:  86%|████████▌ | 455/532 [06:55<01:08,  1.13it/s]Loading train:  86%|████████▌ | 456/532 [06:56<01:08,  1.11it/s]Loading train:  86%|████████▌ | 457/532 [06:57<01:06,  1.13it/s]Loading train:  86%|████████▌ | 458/532 [06:58<01:04,  1.14it/s]Loading train:  86%|████████▋ | 459/532 [06:59<01:11,  1.03it/s]Loading train:  86%|████████▋ | 460/532 [07:00<01:11,  1.00it/s]Loading train:  87%|████████▋ | 461/532 [07:01<01:13,  1.03s/it]Loading train:  87%|████████▋ | 462/532 [07:02<01:12,  1.04s/it]Loading train:  87%|████████▋ | 463/532 [07:03<01:12,  1.06s/it]Loading train:  87%|████████▋ | 464/532 [07:04<01:11,  1.05s/it]Loading train:  87%|████████▋ | 465/532 [07:06<01:11,  1.07s/it]Loading train:  88%|████████▊ | 466/532 [07:07<01:13,  1.11s/it]Loading train:  88%|████████▊ | 467/532 [07:08<01:08,  1.05s/it]Loading train:  88%|████████▊ | 468/532 [07:09<01:04,  1.01s/it]Loading train:  88%|████████▊ | 469/532 [07:10<01:03,  1.01s/it]Loading train:  88%|████████▊ | 470/532 [07:11<01:01,  1.01it/s]Loading train:  89%|████████▊ | 471/532 [07:11<00:57,  1.06it/s]Loading train:  89%|████████▊ | 472/532 [07:12<00:55,  1.09it/s]Loading train:  89%|████████▉ | 473/532 [07:13<00:55,  1.07it/s]Loading train:  89%|████████▉ | 474/532 [07:14<00:55,  1.05it/s]Loading train:  89%|████████▉ | 475/532 [07:15<00:53,  1.07it/s]Loading train:  89%|████████▉ | 476/532 [07:16<00:51,  1.08it/s]Loading train:  90%|████████▉ | 477/532 [07:17<00:51,  1.06it/s]Loading train:  90%|████████▉ | 478/532 [07:18<00:51,  1.05it/s]Loading train:  90%|█████████ | 479/532 [07:19<00:48,  1.10it/s]Loading train:  90%|█████████ | 480/532 [07:20<00:45,  1.15it/s]Loading train:  90%|█████████ | 481/532 [07:20<00:43,  1.16it/s]Loading train:  91%|█████████ | 482/532 [07:21<00:42,  1.18it/s]Loading train:  91%|█████████ | 483/532 [07:22<00:40,  1.21it/s]Loading train:  91%|█████████ | 484/532 [07:23<00:38,  1.25it/s]Loading train:  91%|█████████ | 485/532 [07:24<00:43,  1.09it/s]Loading train:  91%|█████████▏| 486/532 [07:25<00:44,  1.03it/s]Loading train:  92%|█████████▏| 487/532 [07:26<00:43,  1.03it/s]Loading train:  92%|█████████▏| 488/532 [07:27<00:43,  1.02it/s]Loading train:  92%|█████████▏| 489/532 [07:28<00:42,  1.00it/s]Loading train:  92%|█████████▏| 490/532 [07:29<00:42,  1.02s/it]Loading train:  92%|█████████▏| 491/532 [07:30<00:39,  1.03it/s]Loading train:  92%|█████████▏| 492/532 [07:31<00:38,  1.04it/s]Loading train:  93%|█████████▎| 493/532 [07:32<00:36,  1.06it/s]Loading train:  93%|█████████▎| 494/532 [07:33<00:35,  1.07it/s]Loading train:  93%|█████████▎| 495/532 [07:34<00:32,  1.13it/s]Loading train:  93%|█████████▎| 496/532 [07:35<00:33,  1.09it/s]Loading train:  93%|█████████▎| 497/532 [07:35<00:32,  1.06it/s]Loading train:  94%|█████████▎| 498/532 [07:36<00:31,  1.07it/s]Loading train:  94%|█████████▍| 499/532 [07:37<00:30,  1.08it/s]Loading train:  94%|█████████▍| 500/532 [07:38<00:29,  1.09it/s]Loading train:  94%|█████████▍| 501/532 [07:39<00:27,  1.13it/s]Loading train:  94%|█████████▍| 502/532 [07:40<00:27,  1.07it/s]Loading train:  95%|█████████▍| 503/532 [07:41<00:26,  1.10it/s]Loading train:  95%|█████████▍| 504/532 [07:42<00:24,  1.14it/s]Loading train:  95%|█████████▍| 505/532 [07:43<00:23,  1.17it/s]Loading train:  95%|█████████▌| 506/532 [07:43<00:22,  1.17it/s]Loading train:  95%|█████████▌| 507/532 [07:44<00:20,  1.20it/s]Loading train:  95%|█████████▌| 508/532 [07:45<00:19,  1.21it/s]Loading train:  96%|█████████▌| 509/532 [07:46<00:20,  1.12it/s]Loading train:  96%|█████████▌| 510/532 [07:47<00:20,  1.08it/s]Loading train:  96%|█████████▌| 511/532 [07:48<00:20,  1.04it/s]Loading train:  96%|█████████▌| 512/532 [07:49<00:19,  1.02it/s]Loading train:  96%|█████████▋| 513/532 [07:50<00:18,  1.03it/s]Loading train:  97%|█████████▋| 514/532 [07:51<00:17,  1.02it/s]Loading train:  97%|█████████▋| 515/532 [07:52<00:17,  1.00s/it]Loading train:  97%|█████████▋| 516/532 [07:53<00:15,  1.02it/s]Loading train:  97%|█████████▋| 517/532 [07:54<00:14,  1.05it/s]Loading train:  97%|█████████▋| 518/532 [07:55<00:12,  1.09it/s]Loading train:  98%|█████████▊| 519/532 [07:56<00:11,  1.12it/s]Loading train:  98%|█████████▊| 520/532 [07:56<00:10,  1.14it/s]Loading train:  98%|█████████▊| 521/532 [07:57<00:09,  1.14it/s]Loading train:  98%|█████████▊| 522/532 [07:58<00:08,  1.14it/s]Loading train:  98%|█████████▊| 523/532 [07:59<00:07,  1.16it/s]Loading train:  98%|█████████▊| 524/532 [08:00<00:07,  1.13it/s]Loading train:  99%|█████████▊| 525/532 [08:01<00:06,  1.15it/s]Loading train:  99%|█████████▉| 526/532 [08:02<00:05,  1.14it/s]Loading train:  99%|█████████▉| 527/532 [08:03<00:04,  1.13it/s]Loading train:  99%|█████████▉| 528/532 [08:03<00:03,  1.16it/s]Loading train:  99%|█████████▉| 529/532 [08:04<00:02,  1.19it/s]Loading train: 100%|█████████▉| 530/532 [08:05<00:01,  1.25it/s]Loading train: 100%|█████████▉| 531/532 [08:06<00:00,  1.25it/s]Loading train: 100%|██████████| 532/532 [08:07<00:00,  1.24it/s]
concatenating: train:   0%|          | 0/532 [00:00<?, ?it/s]concatenating: train:   1%|          | 5/532 [00:00<00:12, 41.32it/s]concatenating: train:   3%|▎         | 17/532 [00:00<00:10, 51.03it/s]concatenating: train:   6%|▋         | 34/532 [00:00<00:07, 63.96it/s]concatenating: train:  10%|▉         | 52/532 [00:00<00:06, 78.62it/s]concatenating: train:  13%|█▎        | 71/532 [00:00<00:04, 95.32it/s]concatenating: train:  16%|█▋        | 87/532 [00:00<00:04, 108.32it/s]concatenating: train:  20%|█▉        | 106/532 [00:00<00:03, 123.78it/s]concatenating: train:  23%|██▎       | 123/532 [00:00<00:03, 133.42it/s]concatenating: train:  27%|██▋       | 142/532 [00:00<00:02, 143.02it/s]concatenating: train:  30%|██▉       | 159/532 [00:01<00:02, 148.52it/s]concatenating: train:  33%|███▎      | 176/532 [00:01<00:02, 143.72it/s]concatenating: train:  37%|███▋      | 197/532 [00:01<00:02, 157.90it/s]concatenating: train:  42%|████▏     | 223/532 [00:01<00:01, 177.60it/s]concatenating: train:  47%|████▋     | 248/532 [00:01<00:01, 193.31it/s]concatenating: train:  52%|█████▏    | 274/532 [00:01<00:01, 207.07it/s]concatenating: train:  56%|█████▌    | 299/532 [00:01<00:01, 218.12it/s]concatenating: train:  61%|██████    | 325/532 [00:01<00:00, 227.56it/s]concatenating: train:  66%|██████▌   | 350/532 [00:01<00:00, 231.20it/s]concatenating: train:  70%|███████   | 375/532 [00:02<00:00, 236.15it/s]concatenating: train:  75%|███████▌  | 400/532 [00:02<00:00, 235.14it/s]concatenating: train:  80%|████████  | 427/532 [00:02<00:00, 241.97it/s]concatenating: train:  85%|████████▌ | 453/532 [00:02<00:00, 245.24it/s]concatenating: train:  90%|█████████ | 479/532 [00:02<00:00, 247.83it/s]concatenating: train:  95%|█████████▍| 504/532 [00:02<00:00, 245.38it/s]concatenating: train: 100%|█████████▉| 530/532 [00:02<00:00, 248.65it/s]concatenating: train: 100%|██████████| 532/532 [00:02<00:00, 201.37it/s]
Loading test:   0%|          | 0/15 [00:00<?, ?it/s]Loading test:   7%|▋         | 1/15 [00:00<00:11,  1.23it/s]Loading test:  13%|█▎        | 2/15 [00:01<00:10,  1.24it/s]Loading test:  20%|██        | 3/15 [00:02<00:10,  1.16it/s]Loading test:  27%|██▋       | 4/15 [00:03<00:09,  1.15it/s]Loading test:  33%|███▎      | 5/15 [00:04<00:09,  1.05it/s]Loading test:  40%|████      | 6/15 [00:05<00:09,  1.02s/it]Loading test:  47%|████▋     | 7/15 [00:06<00:08,  1.00s/it]Loading test:  53%|█████▎    | 8/15 [00:08<00:07,  1.08s/it]Loading test:  60%|██████    | 9/15 [00:08<00:06,  1.03s/it]Loading test:  67%|██████▋   | 10/15 [00:09<00:04,  1.02it/s]Loading test:  73%|███████▎  | 11/15 [00:10<00:03,  1.06it/s]Loading test:  80%|████████  | 12/15 [00:11<00:02,  1.03it/s]Loading test:  87%|████████▋ | 13/15 [00:12<00:01,  1.00it/s]Loading test:  93%|█████████▎| 14/15 [00:13<00:00,  1.07it/s]Loading test: 100%|██████████| 15/15 [00:14<00:00,  1.08it/s]
concatenating: validation:   0%|          | 0/15 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 15/15 [00:00<00:00, 169.97it/s]
(0/4) test vimp2_ctrl_991_08302013_JF
(1/4) test vimp2_967_08132013_KW
(2/4) test vimp2_765_04162013_AW
(3/4) test vimp2_ANON695_03132013
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 56, 84, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 56, 84, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 56, 84, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 56, 84, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 56, 84, 10)   910         activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 84, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 56, 84, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 56, 84, 11)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 28, 42, 11)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28, 42, 11)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 42, 20)   2000        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 42, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 42, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 42, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 28, 42, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 28, 42, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 42, 31)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 21, 31)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 14, 21, 31)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 14, 21, 40)   11200       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 14, 21, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 14, 21, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 14, 21, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 14, 21, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 14, 21, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 14, 21, 71)   0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 14, 21, 71)   0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 28, 42, 20)   5700        dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 28, 42, 51)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 28, 42, 20)   9200        concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 28, 42, 20)   80          conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 28, 42, 20)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 28, 42, 20)   3620        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 28, 42, 20)   80          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 28, 42, 20)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 28, 42, 71)   0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 28, 42, 71)   0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 56, 84, 10)   2850        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 84, 21)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 56, 84, 10)   1900        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 56, 84, 10)   40          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 84, 10)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 56, 84, 10)   910         activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 56, 84, 10)   40          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 84, 10)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 84, 31)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 56, 84, 31)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 56, 84, 13)   416         dropout_5[0][0]                  
==================================================================================================
Total params: 57,666
Trainable params: 57,266
Non-trainable params: 400
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.53383120e-02 2.88786827e-02 1.16652967e-01 1.00133292e-02
 3.03165963e-02 5.79538965e-03 6.85058777e-02 1.28145429e-01
 7.55135052e-02 1.22435092e-02 2.73464902e-01 1.84941443e-01
 1.90056842e-04]
Train on 20749 samples, validate on 584 samples
Epoch 1/300
 - 26s - loss: 62.7980 - acc: 0.6741 - mDice: 0.0167 - val_loss: 4.7181 - val_acc: 0.9134 - val_mDice: 0.0220

Epoch 00001: val_mDice improved from -inf to 0.02197, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 16s - loss: 6.7406 - acc: 0.8978 - mDice: 0.0318 - val_loss: 3.9763 - val_acc: 0.9134 - val_mDice: 0.0399

Epoch 00002: val_mDice improved from 0.02197 to 0.03990, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 16s - loss: 5.1529 - acc: 0.8986 - mDice: 0.0468 - val_loss: 3.6039 - val_acc: 0.9129 - val_mDice: 0.0701

Epoch 00003: val_mDice improved from 0.03990 to 0.07006, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 16s - loss: 4.4989 - acc: 0.8993 - mDice: 0.0662 - val_loss: 3.2817 - val_acc: 0.9143 - val_mDice: 0.0939

Epoch 00004: val_mDice improved from 0.07006 to 0.09391, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 15s - loss: 4.0050 - acc: 0.9015 - mDice: 0.0952 - val_loss: 2.9519 - val_acc: 0.9149 - val_mDice: 0.1256

Epoch 00005: val_mDice improved from 0.09391 to 0.12558, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 16s - loss: 3.5703 - acc: 0.9066 - mDice: 0.1312 - val_loss: 2.5794 - val_acc: 0.9243 - val_mDice: 0.1780

Epoch 00006: val_mDice improved from 0.12558 to 0.17798, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 15s - loss: 3.1953 - acc: 0.9129 - mDice: 0.1741 - val_loss: 2.2686 - val_acc: 0.9328 - val_mDice: 0.2457

Epoch 00007: val_mDice improved from 0.17798 to 0.24565, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 16s - loss: 2.9081 - acc: 0.9190 - mDice: 0.2191 - val_loss: 1.9387 - val_acc: 0.9504 - val_mDice: 0.3158

Epoch 00008: val_mDice improved from 0.24565 to 0.31575, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 9/300
 - 15s - loss: 2.7071 - acc: 0.9240 - mDice: 0.2527 - val_loss: 1.7465 - val_acc: 0.9559 - val_mDice: 0.3709

Epoch 00009: val_mDice improved from 0.31575 to 0.37088, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 17s - loss: 2.5575 - acc: 0.9272 - mDice: 0.2780 - val_loss: 1.6531 - val_acc: 0.9574 - val_mDice: 0.3978

Epoch 00010: val_mDice improved from 0.37088 to 0.39776, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 11/300
 - 15s - loss: 2.4495 - acc: 0.9291 - mDice: 0.2977 - val_loss: 1.6261 - val_acc: 0.9578 - val_mDice: 0.4137

Epoch 00011: val_mDice improved from 0.39776 to 0.41373, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 12/300
 - 16s - loss: 2.3317 - acc: 0.9312 - mDice: 0.3187 - val_loss: 1.5228 - val_acc: 0.9601 - val_mDice: 0.4401

Epoch 00012: val_mDice improved from 0.41373 to 0.44013, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 13/300
 - 15s - loss: 2.2364 - acc: 0.9327 - mDice: 0.3366 - val_loss: 1.4346 - val_acc: 0.9631 - val_mDice: 0.4601

Epoch 00013: val_mDice improved from 0.44013 to 0.46014, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 14/300
 - 16s - loss: 2.1517 - acc: 0.9343 - mDice: 0.3532 - val_loss: 1.3703 - val_acc: 0.9630 - val_mDice: 0.4863

Epoch 00014: val_mDice improved from 0.46014 to 0.48631, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 15/300
 - 15s - loss: 2.0501 - acc: 0.9363 - mDice: 0.3748 - val_loss: 1.3313 - val_acc: 0.9647 - val_mDice: 0.5042

Epoch 00015: val_mDice improved from 0.48631 to 0.50419, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 16/300
 - 16s - loss: 1.9498 - acc: 0.9383 - mDice: 0.3993 - val_loss: 1.2274 - val_acc: 0.9656 - val_mDice: 0.5408

Epoch 00016: val_mDice improved from 0.50419 to 0.54084, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 17/300
 - 15s - loss: 1.8662 - acc: 0.9403 - mDice: 0.4200 - val_loss: 1.1446 - val_acc: 0.9679 - val_mDice: 0.5605

Epoch 00017: val_mDice improved from 0.54084 to 0.56046, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 18/300
 - 16s - loss: 1.7989 - acc: 0.9416 - mDice: 0.4355 - val_loss: 1.1616 - val_acc: 0.9675 - val_mDice: 0.5636

Epoch 00018: val_mDice improved from 0.56046 to 0.56357, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 19/300
 - 15s - loss: 1.7332 - acc: 0.9428 - mDice: 0.4526 - val_loss: 1.0787 - val_acc: 0.9692 - val_mDice: 0.5893

Epoch 00019: val_mDice improved from 0.56357 to 0.58933, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 20/300
 - 16s - loss: 1.6836 - acc: 0.9437 - mDice: 0.4649 - val_loss: 1.0603 - val_acc: 0.9701 - val_mDice: 0.5976

Epoch 00020: val_mDice improved from 0.58933 to 0.59758, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 21/300
 - 16s - loss: 1.6373 - acc: 0.9446 - mDice: 0.4766 - val_loss: 1.0351 - val_acc: 0.9690 - val_mDice: 0.6094

Epoch 00021: val_mDice improved from 0.59758 to 0.60935, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 22/300
 - 16s - loss: 1.5937 - acc: 0.9456 - mDice: 0.4875 - val_loss: 1.0163 - val_acc: 0.9697 - val_mDice: 0.6162

Epoch 00022: val_mDice improved from 0.60935 to 0.61623, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 23/300
 - 16s - loss: 1.5618 - acc: 0.9463 - mDice: 0.4965 - val_loss: 1.0016 - val_acc: 0.9715 - val_mDice: 0.6216

Epoch 00023: val_mDice improved from 0.61623 to 0.62158, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 24/300
 - 15s - loss: 1.5213 - acc: 0.9473 - mDice: 0.5066 - val_loss: 0.9868 - val_acc: 0.9703 - val_mDice: 0.6267

Epoch 00024: val_mDice improved from 0.62158 to 0.62673, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 25/300
 - 16s - loss: 1.4918 - acc: 0.9480 - mDice: 0.5149 - val_loss: 0.9754 - val_acc: 0.9717 - val_mDice: 0.6392

Epoch 00025: val_mDice improved from 0.62673 to 0.63919, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 26/300
 - 15s - loss: 1.4661 - acc: 0.9485 - mDice: 0.5222 - val_loss: 0.9699 - val_acc: 0.9715 - val_mDice: 0.6347

Epoch 00026: val_mDice did not improve from 0.63919
Epoch 27/300
 - 16s - loss: 1.4394 - acc: 0.9491 - mDice: 0.5293 - val_loss: 0.9473 - val_acc: 0.9711 - val_mDice: 0.6432

Epoch 00027: val_mDice improved from 0.63919 to 0.64321, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 28/300
 - 15s - loss: 1.4118 - acc: 0.9498 - mDice: 0.5365 - val_loss: 0.9311 - val_acc: 0.9725 - val_mDice: 0.6508

Epoch 00028: val_mDice improved from 0.64321 to 0.65078, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 29/300
 - 16s - loss: 1.3897 - acc: 0.9504 - mDice: 0.5431 - val_loss: 0.9229 - val_acc: 0.9723 - val_mDice: 0.6519

Epoch 00029: val_mDice improved from 0.65078 to 0.65194, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 30/300
 - 15s - loss: 1.3707 - acc: 0.9507 - mDice: 0.5485 - val_loss: 0.9119 - val_acc: 0.9720 - val_mDice: 0.6583

Epoch 00030: val_mDice improved from 0.65194 to 0.65833, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 31/300
 - 16s - loss: 1.3484 - acc: 0.9513 - mDice: 0.5555 - val_loss: 0.9039 - val_acc: 0.9722 - val_mDice: 0.6656

Epoch 00031: val_mDice improved from 0.65833 to 0.66565, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 32/300
 - 15s - loss: 1.3291 - acc: 0.9517 - mDice: 0.5609 - val_loss: 0.9076 - val_acc: 0.9730 - val_mDice: 0.6648

Epoch 00032: val_mDice did not improve from 0.66565
Epoch 33/300
 - 16s - loss: 1.3143 - acc: 0.9521 - mDice: 0.5656 - val_loss: 0.8683 - val_acc: 0.9736 - val_mDice: 0.6752

Epoch 00033: val_mDice improved from 0.66565 to 0.67519, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 34/300
 - 15s - loss: 1.3019 - acc: 0.9524 - mDice: 0.5698 - val_loss: 0.8755 - val_acc: 0.9733 - val_mDice: 0.6755

Epoch 00034: val_mDice improved from 0.67519 to 0.67547, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 35/300
 - 16s - loss: 1.2862 - acc: 0.9528 - mDice: 0.5747 - val_loss: 0.8839 - val_acc: 0.9728 - val_mDice: 0.6735

Epoch 00035: val_mDice did not improve from 0.67547
Epoch 36/300
 - 15s - loss: 1.2699 - acc: 0.9531 - mDice: 0.5796 - val_loss: 0.8644 - val_acc: 0.9741 - val_mDice: 0.6828

Epoch 00036: val_mDice improved from 0.67547 to 0.68284, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 37/300
 - 17s - loss: 1.2496 - acc: 0.9536 - mDice: 0.5855 - val_loss: 0.8508 - val_acc: 0.9738 - val_mDice: 0.6851

Epoch 00037: val_mDice improved from 0.68284 to 0.68514, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 38/300
 - 15s - loss: 1.2366 - acc: 0.9539 - mDice: 0.5900 - val_loss: 0.8532 - val_acc: 0.9736 - val_mDice: 0.6877

Epoch 00038: val_mDice improved from 0.68514 to 0.68774, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 39/300
 - 17s - loss: 1.2260 - acc: 0.9541 - mDice: 0.5934 - val_loss: 0.8719 - val_acc: 0.9731 - val_mDice: 0.6838

Epoch 00039: val_mDice did not improve from 0.68774
Epoch 40/300
 - 15s - loss: 1.2112 - acc: 0.9544 - mDice: 0.5982 - val_loss: 0.8610 - val_acc: 0.9739 - val_mDice: 0.6849

Epoch 00040: val_mDice did not improve from 0.68774
Epoch 41/300
 - 16s - loss: 1.2035 - acc: 0.9546 - mDice: 0.6004 - val_loss: 0.8338 - val_acc: 0.9746 - val_mDice: 0.6969

Epoch 00041: val_mDice improved from 0.68774 to 0.69694, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 42/300
 - 15s - loss: 1.1952 - acc: 0.9548 - mDice: 0.6033 - val_loss: 0.8520 - val_acc: 0.9739 - val_mDice: 0.6945

Epoch 00042: val_mDice did not improve from 0.69694
Epoch 43/300
 - 16s - loss: 1.1808 - acc: 0.9553 - mDice: 0.6080 - val_loss: 0.8360 - val_acc: 0.9753 - val_mDice: 0.6986

Epoch 00043: val_mDice improved from 0.69694 to 0.69855, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 44/300
 - 15s - loss: 1.1664 - acc: 0.9556 - mDice: 0.6123 - val_loss: 0.8247 - val_acc: 0.9750 - val_mDice: 0.7030

Epoch 00044: val_mDice improved from 0.69855 to 0.70296, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 45/300
 - 16s - loss: 1.1624 - acc: 0.9557 - mDice: 0.6143 - val_loss: 0.8360 - val_acc: 0.9749 - val_mDice: 0.6973

Epoch 00045: val_mDice did not improve from 0.70296
Epoch 46/300
 - 15s - loss: 1.1513 - acc: 0.9559 - mDice: 0.6172 - val_loss: 0.8220 - val_acc: 0.9751 - val_mDice: 0.7029

Epoch 00046: val_mDice did not improve from 0.70296
Epoch 47/300
 - 16s - loss: 1.1395 - acc: 0.9562 - mDice: 0.6210 - val_loss: 0.8249 - val_acc: 0.9750 - val_mDice: 0.7034

Epoch 00047: val_mDice improved from 0.70296 to 0.70344, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 48/300
 - 15s - loss: 1.1329 - acc: 0.9564 - mDice: 0.6231 - val_loss: 0.8194 - val_acc: 0.9752 - val_mDice: 0.7030

Epoch 00048: val_mDice did not improve from 0.70344
Epoch 49/300
 - 16s - loss: 1.1257 - acc: 0.9565 - mDice: 0.6251 - val_loss: 0.8025 - val_acc: 0.9748 - val_mDice: 0.7109

Epoch 00049: val_mDice improved from 0.70344 to 0.71087, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 50/300
 - 15s - loss: 1.1211 - acc: 0.9567 - mDice: 0.6268 - val_loss: 0.8201 - val_acc: 0.9745 - val_mDice: 0.7032

Epoch 00050: val_mDice did not improve from 0.71087
Epoch 51/300
 - 16s - loss: 1.1118 - acc: 0.9569 - mDice: 0.6296 - val_loss: 0.8130 - val_acc: 0.9761 - val_mDice: 0.7031

Epoch 00051: val_mDice did not improve from 0.71087
Epoch 52/300
 - 15s - loss: 1.1075 - acc: 0.9570 - mDice: 0.6314 - val_loss: 0.8210 - val_acc: 0.9758 - val_mDice: 0.7091

Epoch 00052: val_mDice did not improve from 0.71087
Epoch 53/300
 - 16s - loss: 1.0999 - acc: 0.9571 - mDice: 0.6330 - val_loss: 0.7963 - val_acc: 0.9762 - val_mDice: 0.7097

Epoch 00053: val_mDice did not improve from 0.71087
Epoch 54/300
 - 15s - loss: 1.0959 - acc: 0.9572 - mDice: 0.6349 - val_loss: 0.7974 - val_acc: 0.9760 - val_mDice: 0.7098

Epoch 00054: val_mDice did not improve from 0.71087
Epoch 55/300
 - 17s - loss: 1.0883 - acc: 0.9573 - mDice: 0.6368 - val_loss: 0.7953 - val_acc: 0.9753 - val_mDice: 0.7193

Epoch 00055: val_mDice improved from 0.71087 to 0.71926, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 56/300
 - 15s - loss: 1.0804 - acc: 0.9574 - mDice: 0.6391 - val_loss: 0.8099 - val_acc: 0.9760 - val_mDice: 0.7109

Epoch 00056: val_mDice did not improve from 0.71926
Epoch 57/300
 - 17s - loss: 1.0771 - acc: 0.9576 - mDice: 0.6405 - val_loss: 0.7882 - val_acc: 0.9755 - val_mDice: 0.7163

Epoch 00057: val_mDice did not improve from 0.71926
Epoch 58/300
 - 16s - loss: 1.0753 - acc: 0.9575 - mDice: 0.6412 - val_loss: 0.7868 - val_acc: 0.9753 - val_mDice: 0.7161

Epoch 00058: val_mDice did not improve from 0.71926
Epoch 59/300
 - 16s - loss: 1.0670 - acc: 0.9577 - mDice: 0.6439 - val_loss: 0.7969 - val_acc: 0.9765 - val_mDice: 0.7117

Epoch 00059: val_mDice did not improve from 0.71926
Epoch 60/300
 - 16s - loss: 1.0642 - acc: 0.9577 - mDice: 0.6443 - val_loss: 0.7965 - val_acc: 0.9764 - val_mDice: 0.7104

Epoch 00060: val_mDice did not improve from 0.71926
Epoch 61/300
 - 16s - loss: 1.0591 - acc: 0.9578 - mDice: 0.6464 - val_loss: 0.7987 - val_acc: 0.9761 - val_mDice: 0.7189

Epoch 00061: val_mDice did not improve from 0.71926
Epoch 62/300
 - 16s - loss: 1.0564 - acc: 0.9577 - mDice: 0.6467 - val_loss: 0.8006 - val_acc: 0.9761 - val_mDice: 0.7134

Epoch 00062: val_mDice did not improve from 0.71926
Epoch 63/300
 - 16s - loss: 1.0526 - acc: 0.9578 - mDice: 0.6479 - val_loss: 0.7955 - val_acc: 0.9761 - val_mDice: 0.7187

Epoch 00063: val_mDice did not improve from 0.71926
Epoch 64/300
 - 16s - loss: 1.0506 - acc: 0.9579 - mDice: 0.6490 - val_loss: 0.7788 - val_acc: 0.9764 - val_mDice: 0.7195

Epoch 00064: val_mDice improved from 0.71926 to 0.71952, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 65/300
 - 16s - loss: 1.0452 - acc: 0.9579 - mDice: 0.6499 - val_loss: 0.7920 - val_acc: 0.9763 - val_mDice: 0.7220

Epoch 00065: val_mDice improved from 0.71952 to 0.72202, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 66/300
 - 16s - loss: 1.0418 - acc: 0.9580 - mDice: 0.6514 - val_loss: 0.7738 - val_acc: 0.9764 - val_mDice: 0.7227

Epoch 00066: val_mDice improved from 0.72202 to 0.72272, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 67/300
 - 16s - loss: 1.0392 - acc: 0.9581 - mDice: 0.6522 - val_loss: 0.7782 - val_acc: 0.9762 - val_mDice: 0.7206

Epoch 00067: val_mDice did not improve from 0.72272
Epoch 68/300
 - 16s - loss: 1.0356 - acc: 0.9581 - mDice: 0.6532 - val_loss: 0.7936 - val_acc: 0.9756 - val_mDice: 0.7161

Epoch 00068: val_mDice did not improve from 0.72272
Epoch 69/300
 - 17s - loss: 1.0325 - acc: 0.9581 - mDice: 0.6539 - val_loss: 0.7749 - val_acc: 0.9769 - val_mDice: 0.7173

Epoch 00069: val_mDice did not improve from 0.72272
Epoch 70/300
 - 15s - loss: 1.0270 - acc: 0.9582 - mDice: 0.6557 - val_loss: 0.7880 - val_acc: 0.9758 - val_mDice: 0.7222

Epoch 00070: val_mDice did not improve from 0.72272
Epoch 71/300
 - 16s - loss: 1.0259 - acc: 0.9582 - mDice: 0.6561 - val_loss: 0.7678 - val_acc: 0.9768 - val_mDice: 0.7223

Epoch 00071: val_mDice did not improve from 0.72272
Epoch 72/300
 - 16s - loss: 1.0210 - acc: 0.9583 - mDice: 0.6578 - val_loss: 0.7870 - val_acc: 0.9763 - val_mDice: 0.7203

Epoch 00072: val_mDice did not improve from 0.72272
Epoch 73/300
 - 16s - loss: 1.0209 - acc: 0.9583 - mDice: 0.6578 - val_loss: 0.7748 - val_acc: 0.9758 - val_mDice: 0.7272

Epoch 00073: val_mDice improved from 0.72272 to 0.72722, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 74/300
 - 18s - loss: 1.0201 - acc: 0.9583 - mDice: 0.6582 - val_loss: 0.7720 - val_acc: 0.9764 - val_mDice: 0.7220

Epoch 00074: val_mDice did not improve from 0.72722
Epoch 75/300
 - 15s - loss: 1.0162 - acc: 0.9584 - mDice: 0.6591 - val_loss: 0.7832 - val_acc: 0.9764 - val_mDice: 0.7199

Epoch 00075: val_mDice did not improve from 0.72722
Epoch 76/300
 - 17s - loss: 1.0159 - acc: 0.9584 - mDice: 0.6596 - val_loss: 0.7756 - val_acc: 0.9762 - val_mDice: 0.7199

Epoch 00076: val_mDice did not improve from 0.72722
Epoch 77/300
 - 16s - loss: 1.0133 - acc: 0.9584 - mDice: 0.6604 - val_loss: 0.7723 - val_acc: 0.9758 - val_mDice: 0.7234

Epoch 00077: val_mDice did not improve from 0.72722
Epoch 78/300
 - 18s - loss: 1.0103 - acc: 0.9585 - mDice: 0.6612 - val_loss: 0.7706 - val_acc: 0.9770 - val_mDice: 0.7274

Epoch 00078: val_mDice improved from 0.72722 to 0.72743, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 79/300
 - 16s - loss: 1.0086 - acc: 0.9585 - mDice: 0.6613 - val_loss: 0.7797 - val_acc: 0.9760 - val_mDice: 0.7211

Epoch 00079: val_mDice did not improve from 0.72743
Epoch 80/300
 - 17s - loss: 1.0068 - acc: 0.9585 - mDice: 0.6620 - val_loss: 0.7759 - val_acc: 0.9768 - val_mDice: 0.7244

Epoch 00080: val_mDice did not improve from 0.72743
Epoch 81/300
 - 16s - loss: 1.0048 - acc: 0.9585 - mDice: 0.6628 - val_loss: 0.7847 - val_acc: 0.9764 - val_mDice: 0.7193

Epoch 00081: val_mDice did not improve from 0.72743
Epoch 82/300
 - 17s - loss: 1.0041 - acc: 0.9585 - mDice: 0.6629 - val_loss: 0.7606 - val_acc: 0.9770 - val_mDice: 0.7257

Epoch 00082: val_mDice did not improve from 0.72743
Epoch 83/300
 - 16s - loss: 1.0001 - acc: 0.9586 - mDice: 0.6642 - val_loss: 0.7706 - val_acc: 0.9772 - val_mDice: 0.7282

Epoch 00083: val_mDice improved from 0.72743 to 0.72821, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 84/300
 - 18s - loss: 0.9962 - acc: 0.9587 - mDice: 0.6657 - val_loss: 0.7622 - val_acc: 0.9770 - val_mDice: 0.7230

Epoch 00084: val_mDice did not improve from 0.72821
Epoch 85/300
 - 16s - loss: 0.9937 - acc: 0.9588 - mDice: 0.6661 - val_loss: 0.7566 - val_acc: 0.9772 - val_mDice: 0.7269

Epoch 00085: val_mDice did not improve from 0.72821
Epoch 86/300
 - 20s - loss: 0.9952 - acc: 0.9588 - mDice: 0.6656 - val_loss: 0.7635 - val_acc: 0.9767 - val_mDice: 0.7274

Epoch 00086: val_mDice did not improve from 0.72821
Epoch 87/300
 - 18s - loss: 0.9913 - acc: 0.9588 - mDice: 0.6666 - val_loss: 0.7570 - val_acc: 0.9768 - val_mDice: 0.7328

Epoch 00087: val_mDice improved from 0.72821 to 0.73282, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 88/300
 - 21s - loss: 0.9908 - acc: 0.9589 - mDice: 0.6671 - val_loss: 0.7630 - val_acc: 0.9768 - val_mDice: 0.7304

Epoch 00088: val_mDice did not improve from 0.73282
Epoch 89/300
 - 17s - loss: 0.9913 - acc: 0.9589 - mDice: 0.6671 - val_loss: 0.7714 - val_acc: 0.9765 - val_mDice: 0.7214

Epoch 00089: val_mDice did not improve from 0.73282
Epoch 90/300
 - 18s - loss: 0.9929 - acc: 0.9588 - mDice: 0.6666 - val_loss: 0.7700 - val_acc: 0.9769 - val_mDice: 0.7276

Epoch 00090: val_mDice did not improve from 0.73282
Epoch 91/300
 - 16s - loss: 0.9897 - acc: 0.9590 - mDice: 0.6675 - val_loss: 0.7626 - val_acc: 0.9761 - val_mDice: 0.7265

Epoch 00091: val_mDice did not improve from 0.73282
Epoch 92/300
 - 17s - loss: 0.9841 - acc: 0.9591 - mDice: 0.6689 - val_loss: 0.7560 - val_acc: 0.9772 - val_mDice: 0.7280

Epoch 00092: val_mDice did not improve from 0.73282
Epoch 93/300
 - 17s - loss: 0.9847 - acc: 0.9590 - mDice: 0.6688 - val_loss: 0.7675 - val_acc: 0.9769 - val_mDice: 0.7239

Epoch 00093: val_mDice did not improve from 0.73282
Epoch 94/300
 - 15s - loss: 0.9828 - acc: 0.9591 - mDice: 0.6699 - val_loss: 0.7822 - val_acc: 0.9768 - val_mDice: 0.7238

Epoch 00094: val_mDice did not improve from 0.73282
Epoch 95/300
 - 18s - loss: 0.9843 - acc: 0.9590 - mDice: 0.6691 - val_loss: 0.7547 - val_acc: 0.9767 - val_mDice: 0.7286

Epoch 00095: val_mDice did not improve from 0.73282
Epoch 96/300
 - 16s - loss: 0.9810 - acc: 0.9591 - mDice: 0.6702 - val_loss: 0.7639 - val_acc: 0.9755 - val_mDice: 0.7262

Epoch 00096: val_mDice did not improve from 0.73282
Epoch 97/300
 - 17s - loss: 0.9829 - acc: 0.9591 - mDice: 0.6697 - val_loss: 0.7655 - val_acc: 0.9771 - val_mDice: 0.7281

Epoch 00097: val_mDice did not improve from 0.73282
Epoch 98/300
 - 17s - loss: 0.9803 - acc: 0.9592 - mDice: 0.6705 - val_loss: 0.7557 - val_acc: 0.9769 - val_mDice: 0.7339

Epoch 00098: val_mDice improved from 0.73282 to 0.73388, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 99/300
 - 17s - loss: 0.9754 - acc: 0.9593 - mDice: 0.6716 - val_loss: 0.7586 - val_acc: 0.9768 - val_mDice: 0.7327

Epoch 00099: val_mDice did not improve from 0.73388
Epoch 100/300
 - 23s - loss: 0.9750 - acc: 0.9593 - mDice: 0.6718 - val_loss: 0.7658 - val_acc: 0.9768 - val_mDice: 0.7240

Epoch 00100: val_mDice did not improve from 0.73388
Epoch 101/300
 - 21s - loss: 0.9762 - acc: 0.9593 - mDice: 0.6714 - val_loss: 0.7561 - val_acc: 0.9775 - val_mDice: 0.7274

Epoch 00101: val_mDice did not improve from 0.73388
Epoch 102/300
 - 24s - loss: 0.9727 - acc: 0.9594 - mDice: 0.6727 - val_loss: 0.7543 - val_acc: 0.9765 - val_mDice: 0.7302

Epoch 00102: val_mDice did not improve from 0.73388
Epoch 103/300
 - 21s - loss: 0.9700 - acc: 0.9595 - mDice: 0.6732 - val_loss: 0.7561 - val_acc: 0.9766 - val_mDice: 0.7287

Epoch 00103: val_mDice did not improve from 0.73388
Epoch 104/300
 - 19s - loss: 0.9731 - acc: 0.9594 - mDice: 0.6727 - val_loss: 0.7540 - val_acc: 0.9769 - val_mDice: 0.7306

Epoch 00104: val_mDice did not improve from 0.73388
Epoch 105/300
 - 15s - loss: 0.9700 - acc: 0.9595 - mDice: 0.6737 - val_loss: 0.7468 - val_acc: 0.9768 - val_mDice: 0.7297

Epoch 00105: val_mDice did not improve from 0.73388
Epoch 106/300
 - 16s - loss: 0.9681 - acc: 0.9595 - mDice: 0.6741 - val_loss: 0.7554 - val_acc: 0.9774 - val_mDice: 0.7269

Epoch 00106: val_mDice did not improve from 0.73388
Epoch 107/300
 - 17s - loss: 0.9694 - acc: 0.9595 - mDice: 0.6738 - val_loss: 0.7526 - val_acc: 0.9763 - val_mDice: 0.7326

Epoch 00107: val_mDice did not improve from 0.73388
Epoch 108/300
 - 17s - loss: 0.9669 - acc: 0.9596 - mDice: 0.6745 - val_loss: 0.7586 - val_acc: 0.9771 - val_mDice: 0.7267

Epoch 00108: val_mDice did not improve from 0.73388
Epoch 109/300
 - 20s - loss: 0.9678 - acc: 0.9596 - mDice: 0.6744 - val_loss: 0.7524 - val_acc: 0.9766 - val_mDice: 0.7318

Epoch 00109: val_mDice did not improve from 0.73388
Epoch 110/300
 - 18s - loss: 0.9651 - acc: 0.9596 - mDice: 0.6751 - val_loss: 0.7481 - val_acc: 0.9774 - val_mDice: 0.7346

Epoch 00110: val_mDice improved from 0.73388 to 0.73456, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 111/300
 - 17s - loss: 0.9675 - acc: 0.9596 - mDice: 0.6744 - val_loss: 0.7459 - val_acc: 0.9766 - val_mDice: 0.7311

Epoch 00111: val_mDice did not improve from 0.73456
Epoch 112/300
 - 16s - loss: 0.9617 - acc: 0.9597 - mDice: 0.6761 - val_loss: 0.7441 - val_acc: 0.9770 - val_mDice: 0.7337

Epoch 00112: val_mDice did not improve from 0.73456
Epoch 113/300
 - 16s - loss: 0.9622 - acc: 0.9597 - mDice: 0.6763 - val_loss: 0.7374 - val_acc: 0.9771 - val_mDice: 0.7316

Epoch 00113: val_mDice did not improve from 0.73456
Epoch 114/300
 - 18s - loss: 0.9604 - acc: 0.9597 - mDice: 0.6766 - val_loss: 0.7625 - val_acc: 0.9767 - val_mDice: 0.7299

Epoch 00114: val_mDice did not improve from 0.73456
Epoch 115/300
 - 18s - loss: 0.9611 - acc: 0.9597 - mDice: 0.6762 - val_loss: 0.7418 - val_acc: 0.9771 - val_mDice: 0.7376

Epoch 00115: val_mDice improved from 0.73456 to 0.73762, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 116/300
 - 23s - loss: 0.9577 - acc: 0.9598 - mDice: 0.6776 - val_loss: 0.7504 - val_acc: 0.9772 - val_mDice: 0.7339

Epoch 00116: val_mDice did not improve from 0.73762
Epoch 117/300
 - 16s - loss: 0.9581 - acc: 0.9598 - mDice: 0.6774 - val_loss: 0.7608 - val_acc: 0.9772 - val_mDice: 0.7307

Epoch 00117: val_mDice did not improve from 0.73762
Epoch 118/300
 - 17s - loss: 0.9566 - acc: 0.9598 - mDice: 0.6778 - val_loss: 0.7483 - val_acc: 0.9766 - val_mDice: 0.7339

Epoch 00118: val_mDice did not improve from 0.73762
Epoch 119/300
 - 15s - loss: 0.9554 - acc: 0.9599 - mDice: 0.6780 - val_loss: 0.7500 - val_acc: 0.9769 - val_mDice: 0.7352

Epoch 00119: val_mDice did not improve from 0.73762
Epoch 120/300
 - 17s - loss: 0.9552 - acc: 0.9599 - mDice: 0.6780 - val_loss: 0.7544 - val_acc: 0.9773 - val_mDice: 0.7350

Epoch 00120: val_mDice did not improve from 0.73762
Epoch 121/300
 - 16s - loss: 0.9523 - acc: 0.9600 - mDice: 0.6789 - val_loss: 0.7597 - val_acc: 0.9772 - val_mDice: 0.7324

Epoch 00121: val_mDice did not improve from 0.73762
Epoch 122/300
 - 17s - loss: 0.9532 - acc: 0.9600 - mDice: 0.6788 - val_loss: 0.7562 - val_acc: 0.9767 - val_mDice: 0.7314

Epoch 00122: val_mDice did not improve from 0.73762
Epoch 123/300
 - 16s - loss: 0.9527 - acc: 0.9599 - mDice: 0.6792 - val_loss: 0.7474 - val_acc: 0.9765 - val_mDice: 0.7382

Epoch 00123: val_mDice improved from 0.73762 to 0.73816, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 124/300
 - 17s - loss: 0.9533 - acc: 0.9599 - mDice: 0.6790 - val_loss: 0.7614 - val_acc: 0.9772 - val_mDice: 0.7321

Epoch 00124: val_mDice did not improve from 0.73816
Epoch 125/300
 - 16s - loss: 0.9505 - acc: 0.9600 - mDice: 0.6796 - val_loss: 0.7486 - val_acc: 0.9768 - val_mDice: 0.7355

Epoch 00125: val_mDice did not improve from 0.73816
Epoch 126/300
 - 17s - loss: 0.9513 - acc: 0.9600 - mDice: 0.6798 - val_loss: 0.7453 - val_acc: 0.9768 - val_mDice: 0.7381

Epoch 00126: val_mDice did not improve from 0.73816
Epoch 127/300
 - 16s - loss: 0.9485 - acc: 0.9600 - mDice: 0.6804 - val_loss: 0.7506 - val_acc: 0.9764 - val_mDice: 0.7412

Epoch 00127: val_mDice improved from 0.73816 to 0.74120, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 128/300
 - 17s - loss: 0.9501 - acc: 0.9600 - mDice: 0.6805 - val_loss: 0.7501 - val_acc: 0.9772 - val_mDice: 0.7361

Epoch 00128: val_mDice did not improve from 0.74120
Epoch 129/300
 - 16s - loss: 0.9508 - acc: 0.9600 - mDice: 0.6797 - val_loss: 0.7420 - val_acc: 0.9772 - val_mDice: 0.7395

Epoch 00129: val_mDice did not improve from 0.74120
Epoch 130/300
 - 17s - loss: 0.9488 - acc: 0.9600 - mDice: 0.6806 - val_loss: 0.7539 - val_acc: 0.9772 - val_mDice: 0.7354

Epoch 00130: val_mDice did not improve from 0.74120
Epoch 131/300
 - 16s - loss: 0.9451 - acc: 0.9601 - mDice: 0.6815 - val_loss: 0.7427 - val_acc: 0.9771 - val_mDice: 0.7359

Epoch 00131: val_mDice did not improve from 0.74120
Epoch 132/300
 - 17s - loss: 0.9460 - acc: 0.9601 - mDice: 0.6812 - val_loss: 0.7437 - val_acc: 0.9772 - val_mDice: 0.7355

Epoch 00132: val_mDice did not improve from 0.74120
Epoch 133/300
 - 17s - loss: 0.9460 - acc: 0.9601 - mDice: 0.6816 - val_loss: 0.7402 - val_acc: 0.9773 - val_mDice: 0.7393

Epoch 00133: val_mDice did not improve from 0.74120
Epoch 134/300
 - 17s - loss: 0.9471 - acc: 0.9601 - mDice: 0.6811 - val_loss: 0.7398 - val_acc: 0.9774 - val_mDice: 0.7419

Epoch 00134: val_mDice improved from 0.74120 to 0.74192, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 135/300
 - 17s - loss: 0.9437 - acc: 0.9602 - mDice: 0.6822 - val_loss: 0.7557 - val_acc: 0.9775 - val_mDice: 0.7383

Epoch 00135: val_mDice did not improve from 0.74192
Epoch 136/300
 - 16s - loss: 0.9441 - acc: 0.9602 - mDice: 0.6819 - val_loss: 0.7431 - val_acc: 0.9769 - val_mDice: 0.7376

Epoch 00136: val_mDice did not improve from 0.74192
Epoch 137/300
 - 17s - loss: 0.9412 - acc: 0.9602 - mDice: 0.6830 - val_loss: 0.7324 - val_acc: 0.9773 - val_mDice: 0.7380

Epoch 00137: val_mDice did not improve from 0.74192
Epoch 138/300
 - 16s - loss: 0.9412 - acc: 0.9602 - mDice: 0.6824 - val_loss: 0.7434 - val_acc: 0.9771 - val_mDice: 0.7377

Epoch 00138: val_mDice did not improve from 0.74192
Epoch 139/300
 - 17s - loss: 0.9407 - acc: 0.9603 - mDice: 0.6832 - val_loss: 0.7331 - val_acc: 0.9774 - val_mDice: 0.7398

Epoch 00139: val_mDice did not improve from 0.74192
Epoch 140/300
 - 16s - loss: 0.9397 - acc: 0.9603 - mDice: 0.6833 - val_loss: 0.7445 - val_acc: 0.9775 - val_mDice: 0.7399

Epoch 00140: val_mDice did not improve from 0.74192
Epoch 141/300
 - 17s - loss: 0.9402 - acc: 0.9603 - mDice: 0.6831 - val_loss: 0.7374 - val_acc: 0.9773 - val_mDice: 0.7407

Epoch 00141: val_mDice did not improve from 0.74192
Epoch 142/300
 - 16s - loss: 0.9370 - acc: 0.9604 - mDice: 0.6842 - val_loss: 0.7285 - val_acc: 0.9777 - val_mDice: 0.7404

Epoch 00142: val_mDice did not improve from 0.74192
Epoch 143/300
 - 17s - loss: 0.9400 - acc: 0.9602 - mDice: 0.6834 - val_loss: 0.7424 - val_acc: 0.9776 - val_mDice: 0.7412

Epoch 00143: val_mDice did not improve from 0.74192
Epoch 144/300
 - 16s - loss: 0.9351 - acc: 0.9604 - mDice: 0.6848 - val_loss: 0.7393 - val_acc: 0.9777 - val_mDice: 0.7379

Epoch 00144: val_mDice did not improve from 0.74192
Epoch 145/300
 - 17s - loss: 0.9379 - acc: 0.9604 - mDice: 0.6838 - val_loss: 0.7338 - val_acc: 0.9775 - val_mDice: 0.7372

Epoch 00145: val_mDice did not improve from 0.74192
Epoch 146/300
 - 16s - loss: 0.9359 - acc: 0.9603 - mDice: 0.6845 - val_loss: 0.7431 - val_acc: 0.9773 - val_mDice: 0.7332

Epoch 00146: val_mDice did not improve from 0.74192
Epoch 147/300
 - 17s - loss: 0.9374 - acc: 0.9604 - mDice: 0.6843 - val_loss: 0.7367 - val_acc: 0.9768 - val_mDice: 0.7397

Epoch 00147: val_mDice did not improve from 0.74192
Epoch 148/300
 - 16s - loss: 0.9353 - acc: 0.9604 - mDice: 0.6852 - val_loss: 0.7366 - val_acc: 0.9775 - val_mDice: 0.7409

Epoch 00148: val_mDice did not improve from 0.74192
Epoch 149/300
 - 18s - loss: 0.9334 - acc: 0.9605 - mDice: 0.6854 - val_loss: 0.7304 - val_acc: 0.9779 - val_mDice: 0.7377

Epoch 00149: val_mDice did not improve from 0.74192
Epoch 150/300
 - 17s - loss: 0.9332 - acc: 0.9605 - mDice: 0.6856 - val_loss: 0.7431 - val_acc: 0.9773 - val_mDice: 0.7355

Epoch 00150: val_mDice did not improve from 0.74192
Epoch 151/300
 - 17s - loss: 0.9337 - acc: 0.9604 - mDice: 0.6853 - val_loss: 0.7371 - val_acc: 0.9770 - val_mDice: 0.7393

Epoch 00151: val_mDice did not improve from 0.74192
Epoch 152/300
 - 16s - loss: 0.9320 - acc: 0.9605 - mDice: 0.6857 - val_loss: 0.7383 - val_acc: 0.9773 - val_mDice: 0.7409

Epoch 00152: val_mDice did not improve from 0.74192
Epoch 153/300
 - 18s - loss: 0.9320 - acc: 0.9605 - mDice: 0.6859 - val_loss: 0.7351 - val_acc: 0.9781 - val_mDice: 0.7389

Epoch 00153: val_mDice did not improve from 0.74192
Epoch 154/300
 - 16s - loss: 0.9306 - acc: 0.9605 - mDice: 0.6859 - val_loss: 0.7345 - val_acc: 0.9774 - val_mDice: 0.7387

Epoch 00154: val_mDice did not improve from 0.74192
Epoch 155/300
 - 18s - loss: 0.9297 - acc: 0.9605 - mDice: 0.6866 - val_loss: 0.7411 - val_acc: 0.9763 - val_mDice: 0.7378

Epoch 00155: val_mDice did not improve from 0.74192
Epoch 156/300
 - 16s - loss: 0.9294 - acc: 0.9606 - mDice: 0.6866 - val_loss: 0.7315 - val_acc: 0.9775 - val_mDice: 0.7405

Epoch 00156: val_mDice did not improve from 0.74192
Epoch 157/300
 - 18s - loss: 0.9349 - acc: 0.9605 - mDice: 0.6851 - val_loss: 0.7340 - val_acc: 0.9776 - val_mDice: 0.7424

Epoch 00157: val_mDice improved from 0.74192 to 0.74236, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 158/300
 - 16s - loss: 0.9306 - acc: 0.9605 - mDice: 0.6863 - val_loss: 0.7410 - val_acc: 0.9778 - val_mDice: 0.7376

Epoch 00158: val_mDice did not improve from 0.74236
Epoch 159/300
 - 18s - loss: 0.9296 - acc: 0.9606 - mDice: 0.6867 - val_loss: 0.7433 - val_acc: 0.9768 - val_mDice: 0.7372

Epoch 00159: val_mDice did not improve from 0.74236
Epoch 160/300
 - 15s - loss: 0.9309 - acc: 0.9605 - mDice: 0.6863 - val_loss: 0.7348 - val_acc: 0.9781 - val_mDice: 0.7395

Epoch 00160: val_mDice did not improve from 0.74236
Epoch 161/300
 - 18s - loss: 0.9290 - acc: 0.9606 - mDice: 0.6868 - val_loss: 0.7238 - val_acc: 0.9779 - val_mDice: 0.7458

Epoch 00161: val_mDice improved from 0.74236 to 0.74578, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 162/300
 - 16s - loss: 0.9249 - acc: 0.9607 - mDice: 0.6878 - val_loss: 0.7299 - val_acc: 0.9778 - val_mDice: 0.7391

Epoch 00162: val_mDice did not improve from 0.74578
Epoch 163/300
 - 16s - loss: 0.9267 - acc: 0.9606 - mDice: 0.6875 - val_loss: 0.7268 - val_acc: 0.9769 - val_mDice: 0.7456

Epoch 00163: val_mDice did not improve from 0.74578
Epoch 164/300
 - 16s - loss: 0.9250 - acc: 0.9607 - mDice: 0.6880 - val_loss: 0.7245 - val_acc: 0.9780 - val_mDice: 0.7453

Epoch 00164: val_mDice did not improve from 0.74578
Epoch 165/300
 - 16s - loss: 0.9249 - acc: 0.9607 - mDice: 0.6882 - val_loss: 0.7332 - val_acc: 0.9769 - val_mDice: 0.7400

Epoch 00165: val_mDice did not improve from 0.74578
Epoch 166/300
 - 16s - loss: 0.9251 - acc: 0.9607 - mDice: 0.6881 - val_loss: 0.7230 - val_acc: 0.9777 - val_mDice: 0.7431

Epoch 00166: val_mDice did not improve from 0.74578
Epoch 167/300
 - 15s - loss: 0.9250 - acc: 0.9607 - mDice: 0.6879 - val_loss: 0.7332 - val_acc: 0.9771 - val_mDice: 0.7426
