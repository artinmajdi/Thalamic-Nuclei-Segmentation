*** DATASET ALREADY EXIST; PLEASE REMOVE 'train' & 'test' SUBFOLDERS ***
(0/456) train vimp2_845_05312013_VZ
(1/456) train vimp2_823_05202013_AJ
(2/456) train vimp2_915_07112013_LC
(3/456) train vimp2_901_07052013_AS
(4/456) train vimp2_ctrl_911_07082013_TTO
(5/456) train vimp2_ctrl_925_07152013_LS
(6/456) train vimp2_869_06142013_BL
(7/456) train vimp2_ANON724_03272013
(8/456) train vimp2_819_05172013_DS
(9/456) train vimp2_ctrl_918_07112013_TQ
(10/456) train vimp2_ctrl_902_07052013_SI
(11/456) train vimp2_ANON606_20130110
(12/456) train vimp2_943_07242013_PA
(13/456) train vimp2_824_05212013_JS
(14/456) train vimp2_ANON624_20130117
(15/456) train vimp2_ctrl_920_07122013_SW
(16/456) train vimp2_884_06272013_TS
(17/456) train vimp2_668_02282013_CD
(18/456) train vimp2_964_08092013_TG
(19/456) train vimp2_ctrl_921_07122013_MP
(20/456) train vimp2_972_08152013_DC
(21/456) train vimp2_988_08302013_CB
(22/456) train vimp2_ANON702_03152013
(23/456) train vimp2_ANON714_03222013
(24/456) train vimp2_972_08152013_DC_Aug0_Rot_-1_sd0
(25/456) train vimp2_972_08152013_DC_Aug0_Rot_1_sd2
(26/456) train vimp2_972_08152013_DC_Aug0_Rot_-7_sd1
(27/456) train vimp2_972_08152013_DC_Aug1_Rot_2_sd0
(28/456) train vimp2_972_08152013_DC_Aug1_Rot_5_sd1
(29/456) train vimp2_972_08152013_DC_Aug1_Rot_6_sd2
(30/456) train vimp2_972_08152013_DC_Aug2_Rot_-3_sd1
(31/456) train vimp2_972_08152013_DC_Aug2_Rot_-3_sd2
(32/456) train vimp2_972_08152013_DC_Aug2_Rot_-5_sd0
(33/456) train vimp2_972_08152013_DC_Aug3_Rot_2_sd1
(34/456) train vimp2_972_08152013_DC_Aug3_Rot_-3_sd0
(35/456) train vimp2_972_08152013_DC_Aug3_Rot_-6_sd2
(36/456) train vimp2_972_08152013_DC_Aug4_Rot_-2_sd2
(37/456) train vimp2_972_08152013_DC_Aug4_Rot_3_sd0
(38/456) train vimp2_972_08152013_DC_Aug4_Rot_6_sd1
(39/456) train vimp2_972_08152013_DC_Aug5_Rot_-1_sd2
(40/456) train vimp2_972_08152013_DC_Aug5_Rot_7_sd0
(41/456) train vimp2_972_08152013_DC_Aug5_Rot_7_sd1
(42/456) train vimp2_988_08302013_CB_Aug0_Rot_-3_sd2
(43/456) train vimp2_988_08302013_CB_Aug0_Rot_4_sd0
(44/456) train vimp2_988_08302013_CB_Aug0_Rot_-5_sd1
(45/456) train vimp2_988_08302013_CB_Aug1_Rot_-2_sd2
(46/456) train vimp2_988_08302013_CB_Aug1_Rot_-3_sd0
(47/456) train vimp2_988_08302013_CB_Aug1_Rot_-6_sd1
(48/456) train vimp2_988_08302013_CB_Aug2_Rot_-2_sd0
(49/456) train vimp2_988_08302013_CB_Aug2_Rot_4_sd1
(50/456) train vimp2_988_08302013_CB_Aug2_Rot_-5_sd2
(51/456) train vimp2_988_08302013_CB_Aug3_Rot_2_sd2
(52/456) train vimp2_988_08302013_CB_Aug3_Rot_-3_sd0
(53/456) train vimp2_988_08302013_CB_Aug3_Rot_3_sd1
(54/456) train vimp2_988_08302013_CB_Aug4_Rot_-2_sd0
(55/456) train vimp2_988_08302013_CB_Aug4_Rot_-6_sd1
(56/456) train vimp2_988_08302013_CB_Aug4_Rot_7_sd2
(57/456) train vimp2_988_08302013_CB_Aug5_Rot_-1_sd0
(58/456) train vimp2_988_08302013_CB_Aug5_Rot_-6_sd1
(59/456) train vimp2_988_08302013_CB_Aug5_Rot_7_sd2
(60/456) train vimp2_ANON702_03152013_Aug0_Rot_-2_sd1
(61/456) train vimp2_ANON702_03152013_Aug0_Rot_-3_sd2
(62/456) train vimp2_ANON702_03152013_Aug0_Rot_-4_sd0
(63/456) train vimp2_ANON702_03152013_Aug1_Rot_-4_sd1
(64/456) train vimp2_ANON702_03152013_Aug1_Rot_-5_sd2
(65/456) train vimp2_ANON702_03152013_Aug1_Rot_-7_sd0
(66/456) train vimp2_ANON702_03152013_Aug2_Rot_6_sd0
(67/456) train vimp2_ANON702_03152013_Aug2_Rot_6_sd2
(68/456) train vimp2_ANON702_03152013_Aug2_Rot_-7_sd1
(69/456) train vimp2_ANON702_03152013_Aug3_Rot_-1_sd2
(70/456) train vimp2_ANON702_03152013_Aug3_Rot_-3_sd0
(71/456) train vimp2_ANON702_03152013_Aug3_Rot_-6_sd1
(72/456) train vimp2_ANON702_03152013_Aug4_Rot_-2_sd0
(73/456) train vimp2_ANON702_03152013_Aug4_Rot_-3_sd2
(74/456) train vimp2_ANON702_03152013_Aug4_Rot_-7_sd1
(75/456) train vimp2_ANON702_03152013_Aug5_Rot_3_sd0
(76/456) train vimp2_ANON702_03152013_Aug5_Rot_3_sd2
(77/456) train vimp2_ANON702_03152013_Aug5_Rot_4_sd1
(78/456) train vimp2_ANON714_03222013_Aug0_Rot_-1_sd2
(79/456) train vimp2_ANON714_03222013_Aug0_Rot_-2_sd1
(80/456) train vimp2_ANON714_03222013_Aug0_Rot_4_sd0
(81/456) train vimp2_ANON714_03222013_Aug1_Rot_0_sd0
(82/456) train vimp2_ANON714_03222013_Aug1_Rot_1_sd1
(83/456) train vimp2_ANON714_03222013_Aug1_Rot_-6_sd2
(84/456) train vimp2_ANON714_03222013_Aug2_Rot_-2_sd0
(85/456) train vimp2_ANON714_03222013_Aug2_Rot_4_sd1
(86/456) train vimp2_ANON714_03222013_Aug2_Rot_6_sd2
(87/456) train vimp2_ANON714_03222013_Aug3_Rot_2_sd0
(88/456) train vimp2_ANON714_03222013_Aug3_Rot_-3_sd2
(89/456) train vimp2_ANON714_03222013_Aug3_Rot_-7_sd1
(90/456) train vimp2_ANON714_03222013_Aug4_Rot_1_sd0
(91/456) train vimp2_ANON714_03222013_Aug4_Rot_-2_sd1
(92/456) train vimp2_ANON714_03222013_Aug4_Rot_4_sd2
(93/456) train vimp2_ANON714_03222013_Aug5_Rot_1_sd0
(94/456) train vimp2_ANON714_03222013_Aug5_Rot_6_sd1
(95/456) train vimp2_ANON714_03222013_Aug5_Rot_-7_sd2
(96/456) train vimp2_668_02282013_CD_Aug0_Rot_7_sd0
(97/456) train vimp2_668_02282013_CD_Aug1_Rot_-1_sd0
(98/456) train vimp2_668_02282013_CD_Aug2_Rot_-4_sd0
(99/456) train vimp2_668_02282013_CD_Aug3_Rot_3_sd0
(100/456) train vimp2_668_02282013_CD_Aug4_Rot_-5_sd0
(101/456) train vimp2_668_02282013_CD_Aug5_Rot_-6_sd0
(102/456) train vimp2_819_05172013_DS_Aug0_Rot_1_sd0
(103/456) train vimp2_819_05172013_DS_Aug1_Rot_5_sd0
(104/456) train vimp2_819_05172013_DS_Aug2_Rot_-4_sd0
(105/456) train vimp2_819_05172013_DS_Aug3_Rot_2_sd0
(106/456) train vimp2_819_05172013_DS_Aug4_Rot_5_sd0
(107/456) train vimp2_819_05172013_DS_Aug5_Rot_4_sd0
(108/456) train vimp2_823_05202013_AJ_Aug0_Rot_-7_sd0
(109/456) train vimp2_823_05202013_AJ_Aug1_Rot_7_sd0
(110/456) train vimp2_823_05202013_AJ_Aug2_Rot_3_sd0
(111/456) train vimp2_823_05202013_AJ_Aug3_Rot_-5_sd0
(112/456) train vimp2_823_05202013_AJ_Aug4_Rot_-3_sd0
(113/456) train vimp2_823_05202013_AJ_Aug5_Rot_1_sd0
(114/456) train vimp2_824_05212013_JS_Aug0_Rot_-2_sd0
(115/456) train vimp2_824_05212013_JS_Aug1_Rot_6_sd0
(116/456) train vimp2_824_05212013_JS_Aug2_Rot_1_sd0
(117/456) train vimp2_824_05212013_JS_Aug3_Rot_-4_sd0
(118/456) train vimp2_824_05212013_JS_Aug4_Rot_7_sd0
(119/456) train vimp2_824_05212013_JS_Aug5_Rot_2_sd0
(120/456) train vimp2_845_05312013_VZ_Aug0_Rot_1_sd0
(121/456) train vimp2_845_05312013_VZ_Aug1_Rot_5_sd0
(122/456) train vimp2_845_05312013_VZ_Aug2_Rot_-6_sd0
(123/456) train vimp2_845_05312013_VZ_Aug3_Rot_3_sd0
(124/456) train vimp2_845_05312013_VZ_Aug4_Rot_-2_sd0
(125/456) train vimp2_845_05312013_VZ_Aug5_Rot_5_sd0
(126/456) train vimp2_869_06142013_BL_Aug0_Rot_-2_sd0
(127/456) train vimp2_869_06142013_BL_Aug1_Rot_-4_sd0
(128/456) train vimp2_869_06142013_BL_Aug2_Rot_-1_sd0
(129/456) train vimp2_869_06142013_BL_Aug3_Rot_3_sd0
(130/456) train vimp2_869_06142013_BL_Aug4_Rot_3_sd0
(131/456) train vimp2_869_06142013_BL_Aug5_Rot_1_sd0
(132/456) train vimp2_884_06272013_TS_Aug0_Rot_-7_sd0
(133/456) train vimp2_884_06272013_TS_Aug1_Rot_7_sd0
(134/456) train vimp2_884_06272013_TS_Aug2_Rot_-5_sd0
(135/456) train vimp2_884_06272013_TS_Aug3_Rot_-2_sd0
(136/456) train vimp2_884_06272013_TS_Aug4_Rot_6_sd0
(137/456) train vimp2_884_06272013_TS_Aug5_Rot_-1_sd0
(138/456) train vimp2_901_07052013_AS_Aug0_Rot_-4_sd0
(139/456) train vimp2_901_07052013_AS_Aug1_Rot_-2_sd0
(140/456) train vimp2_901_07052013_AS_Aug2_Rot_1_sd0
(141/456) train vimp2_901_07052013_AS_Aug3_Rot_2_sd0
(142/456) train vimp2_901_07052013_AS_Aug4_Rot_-7_sd0
(143/456) train vimp2_901_07052013_AS_Aug5_Rot_-5_sd0
(144/456) train vimp2_915_07112013_LC_Aug0_Rot_-2_sd0
(145/456) train vimp2_915_07112013_LC_Aug1_Rot_4_sd0
(146/456) train vimp2_915_07112013_LC_Aug2_Rot_-2_sd0
(147/456) train vimp2_915_07112013_LC_Aug3_Rot_-1_sd0
(148/456) train vimp2_915_07112013_LC_Aug4_Rot_1_sd0
(149/456) train vimp2_915_07112013_LC_Aug5_Rot_4_sd0
(150/456) train vimp2_943_07242013_PA_Aug0_Rot_-5_sd0
(151/456) train vimp2_943_07242013_PA_Aug1_Rot_-7_sd0
(152/456) train vimp2_943_07242013_PA_Aug2_Rot_-4_sd0
(153/456) train vimp2_943_07242013_PA_Aug3_Rot_6_sd0
(154/456) train vimp2_943_07242013_PA_Aug4_Rot_6_sd0
(155/456) train vimp2_943_07242013_PA_Aug5_Rot_5_sd0
(156/456) train vimp2_964_08092013_TG_Aug0_Rot_5_sd0
(157/456) train vimp2_964_08092013_TG_Aug1_Rot_-4_sd0
(158/456) train vimp2_964_08092013_TG_Aug2_Rot_7_sd0
(159/456) train vimp2_964_08092013_TG_Aug3_Rot_-1_sd0
(160/456) train vimp2_964_08092013_TG_Aug4_Rot_-1_sd0
(161/456) train vimp2_964_08092013_TG_Aug5_Rot_2_sd0
(162/456) train vimp2_ANON606_20130110_Aug0_Rot_1_sd0
(163/456) train vimp2_ANON606_20130110_Aug1_Rot_2_sd0
(164/456) train vimp2_ANON606_20130110_Aug2_Rot_-5_sd0
(165/456) train vimp2_ANON606_20130110_Aug3_Rot_-5_sd0
(166/456) train vimp2_ANON606_20130110_Aug4_Rot_3_sd0
(167/456) train vimp2_ANON606_20130110_Aug5_Rot_-1_sd0
(168/456) train vimp2_ANON624_20130117_Aug0_Rot_1_sd0
(169/456) train vimp2_ANON624_20130117_Aug1_Rot_-2_sd0
(170/456) train vimp2_ANON624_20130117_Aug2_Rot_5_sd0
(171/456) train vimp2_ANON624_20130117_Aug3_Rot_1_sd0
(172/456) train vimp2_ANON624_20130117_Aug4_Rot_-5_sd0
(173/456) train vimp2_ANON624_20130117_Aug5_Rot_3_sd0
(174/456) train vimp2_ANON724_03272013_Aug0_Rot_-4_sd0
(175/456) train vimp2_ANON724_03272013_Aug1_Rot_-3_sd0
(176/456) train vimp2_ANON724_03272013_Aug2_Rot_-4_sd0
(177/456) train vimp2_ANON724_03272013_Aug3_Rot_5_sd0
(178/456) train vimp2_ANON724_03272013_Aug4_Rot_5_sd0
(179/456) train vimp2_ANON724_03272013_Aug5_Rot_-6_sd0
(180/456) train vimp2_ctrl_902_07052013_SI_Aug0_Rot_5_sd0
(181/456) train vimp2_ctrl_902_07052013_SI_Aug1_Rot_7_sd0
(182/456) train vimp2_ctrl_902_07052013_SI_Aug2_Rot_4_sd0
(183/456) train vimp2_ctrl_902_07052013_SI_Aug3_Rot_-4_sd0
(184/456) train vimp2_ctrl_902_07052013_SI_Aug4_Rot_3_sd0
(185/456) train vimp2_ctrl_902_07052013_SI_Aug5_Rot_-7_sd0
(186/456) train vimp2_ctrl_911_07082013_TTO_Aug0_Rot_6_sd0
(187/456) train vimp2_ctrl_911_07082013_TTO_Aug1_Rot_1_sd0
(188/456) train vimp2_ctrl_911_07082013_TTO_Aug2_Rot_4_sd0
(189/456) train vimp2_ctrl_911_07082013_TTO_Aug3_Rot_-2_sd0
(190/456) train vimp2_ctrl_911_07082013_TTO_Aug4_Rot_6_sd0
(191/456) train vimp2_ctrl_911_07082013_TTO_Aug5_Rot_-2_sd0
(192/456) train vimp2_ctrl_918_07112013_TQ_Aug0_Rot_5_sd0
(193/456) train vimp2_ctrl_918_07112013_TQ_Aug1_Rot_-3_sd0
(194/456) train vimp2_ctrl_918_07112013_TQ_Aug2_Rot_-4_sd0
(195/456) train vimp2_ctrl_918_07112013_TQ_Aug3_Rot_1_sd0
(196/456) train vimp2_ctrl_918_07112013_TQ_Aug4_Rot_3_sd0
(197/456) train vimp2_ctrl_918_07112013_TQ_Aug5_Rot_7_sd0
(198/456) train vimp2_ctrl_920_07122013_SW_Aug0_Rot_7_sd0
(199/456) train vimp2_ctrl_920_07122013_SW_Aug1_Rot_-6_sd0
(200/456) train vimp2_ctrl_920_07122013_SW_Aug2_Rot_-4_sd0
(201/456) train vimp2_ctrl_920_07122013_SW_Aug3_Rot_1_sd0
(202/456) train vimp2_ctrl_920_07122013_SW_Aug4_Rot_-2_sd0
(203/456) train vimp2_ctrl_920_07122013_SW_Aug5_Rot_4_sd0
(204/456) train vimp2_ctrl_921_07122013_MP_Aug0_Rot_-1_sd0
(205/456) train vimp2_ctrl_921_07122013_MP_Aug1_Rot_-3_sd0
(206/456) train vimp2_ctrl_921_07122013_MP_Aug2_Rot_6_sd0
(207/456) train vimp2_ctrl_921_07122013_MP_Aug3_Rot_3_sd0
(208/456) train vimp2_ctrl_921_07122013_MP_Aug4_Rot_1_sd0
(209/456) train vimp2_ctrl_921_07122013_MP_Aug5_Rot_-5_sd0
(210/456) train vimp2_ctrl_925_07152013_LS_Aug0_Rot_-5_sd0
(211/456) train vimp2_ctrl_925_07152013_LS_Aug1_Rot_-2_sd0
(212/456) train vimp2_ctrl_925_07152013_LS_Aug2_Rot_5_sd0
(213/456) train vimp2_ctrl_925_07152013_LS_Aug3_Rot_3_sd0
(214/456) train vimp2_ctrl_925_07152013_LS_Aug4_Rot_4_sd0
(215/456) train vimp2_ctrl_925_07152013_LS_Aug5_Rot_-7_sd0
(216/456) train vimp2_668_02282013_CD_Aug0_Rot_-5_sd1
(217/456) train vimp2_668_02282013_CD_Aug1_Rot_-6_sd1
(218/456) train vimp2_668_02282013_CD_Aug2_Rot_3_sd1
(219/456) train vimp2_668_02282013_CD_Aug3_Rot_4_sd1
(220/456) train vimp2_668_02282013_CD_Aug4_Rot_-6_sd1
(221/456) train vimp2_668_02282013_CD_Aug5_Rot_-2_sd1
(222/456) train vimp2_819_05172013_DS_Aug0_Rot_-1_sd1
(223/456) train vimp2_819_05172013_DS_Aug1_Rot_3_sd1
(224/456) train vimp2_819_05172013_DS_Aug2_Rot_6_sd1
(225/456) train vimp2_819_05172013_DS_Aug3_Rot_3_sd1
(226/456) train vimp2_819_05172013_DS_Aug4_Rot_-7_sd1
(227/456) train vimp2_819_05172013_DS_Aug5_Rot_-5_sd1
(228/456) train vimp2_823_05202013_AJ_Aug0_Rot_-7_sd1
(229/456) train vimp2_823_05202013_AJ_Aug1_Rot_3_sd1
(230/456) train vimp2_823_05202013_AJ_Aug2_Rot_6_sd1
(231/456) train vimp2_823_05202013_AJ_Aug3_Rot_-7_sd1
(232/456) train vimp2_823_05202013_AJ_Aug4_Rot_-4_sd1
(233/456) train vimp2_823_05202013_AJ_Aug5_Rot_-4_sd1
(234/456) train vimp2_824_05212013_JS_Aug0_Rot_7_sd1
(235/456) train vimp2_824_05212013_JS_Aug1_Rot_3_sd1
(236/456) train vimp2_824_05212013_JS_Aug2_Rot_3_sd1
(237/456) train vimp2_824_05212013_JS_Aug3_Rot_-4_sd1
(238/456) train vimp2_824_05212013_JS_Aug4_Rot_4_sd1
(239/456) train vimp2_824_05212013_JS_Aug5_Rot_6_sd1
(240/456) train vimp2_845_05312013_VZ_Aug0_Rot_5_sd1
(241/456) train vimp2_845_05312013_VZ_Aug1_Rot_6_sd1
(242/456) train vimp2_845_05312013_VZ_Aug2_Rot_1_sd1
(243/456) train vimp2_845_05312013_VZ_Aug3_Rot_-6_sd1
(244/456) train vimp2_845_05312013_VZ_Aug4_Rot_-2_sd1
(245/456) train vimp2_845_05312013_VZ_Aug5_Rot_-6_sd1
(246/456) train vimp2_869_06142013_BL_Aug0_Rot_-4_sd1
(247/456) train vimp2_869_06142013_BL_Aug1_Rot_-3_sd1
(248/456) train vimp2_869_06142013_BL_Aug2_Rot_-4_sd1
(249/456) train vimp2_869_06142013_BL_Aug3_Rot_1_sd1
(250/456) train vimp2_869_06142013_BL_Aug4_Rot_7_sd1
(251/456) train vimp2_869_06142013_BL_Aug5_Rot_5_sd1
(252/456) train vimp2_884_06272013_TS_Aug0_Rot_5_sd1
(253/456) train vimp2_884_06272013_TS_Aug1_Rot_-1_sd1
(254/456) train vimp2_884_06272013_TS_Aug2_Rot_-1_sd1
(255/456) train vimp2_884_06272013_TS_Aug3_Rot_3_sd1
(256/456) train vimp2_884_06272013_TS_Aug4_Rot_4_sd1
(257/456) train vimp2_884_06272013_TS_Aug5_Rot_3_sd1
(258/456) train vimp2_901_07052013_AS_Aug0_Rot_3_sd1
(259/456) train vimp2_901_07052013_AS_Aug1_Rot_5_sd1
(260/456) train vimp2_901_07052013_AS_Aug2_Rot_-5_sd1
(261/456) train vimp2_901_07052013_AS_Aug3_Rot_7_sd1
(262/456) train vimp2_901_07052013_AS_Aug4_Rot_7_sd1
(263/456) train vimp2_901_07052013_AS_Aug5_Rot_6_sd1
(264/456) train vimp2_915_07112013_LC_Aug0_Rot_-6_sd1
(265/456) train vimp2_915_07112013_LC_Aug1_Rot_-5_sd1
(266/456) train vimp2_915_07112013_LC_Aug2_Rot_7_sd1
(267/456) train vimp2_915_07112013_LC_Aug3_Rot_1_sd1
(268/456) train vimp2_915_07112013_LC_Aug4_Rot_6_sd1
(269/456) train vimp2_915_07112013_LC_Aug5_Rot_-7_sd1
(270/456) train vimp2_943_07242013_PA_Aug0_Rot_1_sd1
(271/456) train vimp2_943_07242013_PA_Aug1_Rot_6_sd1
(272/456) train vimp2_943_07242013_PA_Aug2_Rot_3_sd1
(273/456) train vimp2_943_07242013_PA_Aug3_Rot_6_sd1
(274/456) train vimp2_943_07242013_PA_Aug4_Rot_3_sd1
(275/456) train vimp2_943_07242013_PA_Aug5_Rot_3_sd1
(276/456) train vimp2_964_08092013_TG_Aug0_Rot_6_sd1
(277/456) train vimp2_964_08092013_TG_Aug1_Rot_-4_sd1
(278/456) train vimp2_964_08092013_TG_Aug2_Rot_5_sd1
(279/456) train vimp2_964_08092013_TG_Aug3_Rot_0_sd1
(280/456) train vimp2_964_08092013_TG_Aug4_Rot_3_sd1
(281/456) train vimp2_964_08092013_TG_Aug5_Rot_-1_sd1
(282/456) train vimp2_ANON606_20130110_Aug0_Rot_-6_sd1
(283/456) train vimp2_ANON606_20130110_Aug1_Rot_7_sd1
(284/456) train vimp2_ANON606_20130110_Aug2_Rot_1_sd1
(285/456) train vimp2_ANON606_20130110_Aug3_Rot_1_sd1
(286/456) train vimp2_ANON606_20130110_Aug4_Rot_4_sd1
(287/456) train vimp2_ANON606_20130110_Aug5_Rot_4_sd1
(288/456) train vimp2_ANON624_20130117_Aug0_Rot_7_sd1
(289/456) train vimp2_ANON624_20130117_Aug1_Rot_6_sd1
(290/456) train vimp2_ANON624_20130117_Aug2_Rot_-1_sd1
(291/456) train vimp2_ANON624_20130117_Aug3_Rot_1_sd1
(292/456) train vimp2_ANON624_20130117_Aug4_Rot_-5_sd1
(293/456) train vimp2_ANON624_20130117_Aug5_Rot_4_sd1
(294/456) train vimp2_ANON724_03272013_Aug0_Rot_-2_sd1
(295/456) train vimp2_ANON724_03272013_Aug1_Rot_4_sd1
(296/456) train vimp2_ANON724_03272013_Aug2_Rot_-1_sd1
(297/456) train vimp2_ANON724_03272013_Aug3_Rot_-6_sd1
(298/456) train vimp2_ANON724_03272013_Aug4_Rot_-5_sd1
(299/456) train vimp2_ANON724_03272013_Aug5_Rot_-4_sd1
(300/456) train vimp2_ctrl_902_07052013_SI_Aug0_Rot_-2_sd1
(301/456) train vimp2_ctrl_902_07052013_SI_Aug1_Rot_7_sd1
(302/456) train vimp2_ctrl_902_07052013_SI_Aug2_Rot_2_sd1
(303/456) train vimp2_ctrl_902_07052013_SI_Aug3_Rot_-4_sd1
(304/456) train vimp2_ctrl_902_07052013_SI_Aug4_Rot_-1_sd1
(305/456) train vimp2_ctrl_902_07052013_SI_Aug5_Rot_-4_sd1
(306/456) train vimp2_ctrl_911_07082013_TTO_Aug0_Rot_7_sd1
(307/456) train vimp2_ctrl_911_07082013_TTO_Aug1_Rot_-1_sd1
(308/456) train vimp2_ctrl_911_07082013_TTO_Aug2_Rot_-5_sd1
(309/456) train vimp2_ctrl_911_07082013_TTO_Aug3_Rot_-3_sd1
(310/456) train vimp2_ctrl_911_07082013_TTO_Aug4_Rot_6_sd1
(311/456) train vimp2_ctrl_911_07082013_TTO_Aug5_Rot_6_sd1
(312/456) train vimp2_ctrl_918_07112013_TQ_Aug0_Rot_1_sd1
(313/456) train vimp2_ctrl_918_07112013_TQ_Aug1_Rot_-2_sd1
(314/456) train vimp2_ctrl_918_07112013_TQ_Aug2_Rot_3_sd1
(315/456) train vimp2_ctrl_918_07112013_TQ_Aug3_Rot_-1_sd1
(316/456) train vimp2_ctrl_918_07112013_TQ_Aug4_Rot_7_sd1
(317/456) train vimp2_ctrl_918_07112013_TQ_Aug5_Rot_6_sd1
(318/456) train vimp2_ctrl_920_07122013_SW_Aug0_Rot_-3_sd1
(319/456) train vimp2_ctrl_920_07122013_SW_Aug1_Rot_7_sd1
(320/456) train vimp2_ctrl_920_07122013_SW_Aug2_Rot_-4_sd1
(321/456) train vimp2_ctrl_920_07122013_SW_Aug3_Rot_-1_sd1
(322/456) train vimp2_ctrl_920_07122013_SW_Aug4_Rot_-5_sd1
(323/456) train vimp2_ctrl_920_07122013_SW_Aug5_Rot_-5_sd1
(324/456) train vimp2_ctrl_921_07122013_MP_Aug0_Rot_4_sd1
(325/456) train vimp2_ctrl_921_07122013_MP_Aug1_Rot_3_sd1
(326/456) train vimp2_ctrl_921_07122013_MP_Aug2_Rot_-1_sd1
(327/456) train vimp2_ctrl_921_07122013_MP_Aug3_Rot_-2_sd1
(328/456) train vimp2_ctrl_921_07122013_MP_Aug4_Rot_2_sd1
(329/456) train vimp2_ctrl_921_07122013_MP_Aug5_Rot_4_sd1
(330/456) train vimp2_ctrl_925_07152013_LS_Aug0_Rot_-2_sd1
(331/456) train vimp2_ctrl_925_07152013_LS_Aug1_Rot_4_sd1
(332/456) train vimp2_ctrl_925_07152013_LS_Aug2_Rot_-2_sd1
(333/456) train vimp2_ctrl_925_07152013_LS_Aug3_Rot_2_sd1
(334/456) train vimp2_ctrl_925_07152013_LS_Aug4_Rot_3_sd1
(335/456) train vimp2_ctrl_925_07152013_LS_Aug5_Rot_-4_sd1
(336/456) train vimp2_668_02282013_CD_Aug0_Rot_-3_sd2
(337/456) train vimp2_668_02282013_CD_Aug1_Rot_6_sd2
(338/456) train vimp2_668_02282013_CD_Aug2_Rot_-6_sd2
(339/456) train vimp2_668_02282013_CD_Aug3_Rot_7_sd2
(340/456) train vimp2_668_02282013_CD_Aug4_Rot_1_sd2
(341/456) train vimp2_668_02282013_CD_Aug5_Rot_7_sd2
(342/456) train vimp2_819_05172013_DS_Aug0_Rot_3_sd2
(343/456) train vimp2_819_05172013_DS_Aug1_Rot_-1_sd2
(344/456) train vimp2_819_05172013_DS_Aug2_Rot_-2_sd2
(345/456) train vimp2_819_05172013_DS_Aug3_Rot_-1_sd2
(346/456) train vimp2_819_05172013_DS_Aug4_Rot_7_sd2
(347/456) train vimp2_819_05172013_DS_Aug5_Rot_3_sd2
(348/456) train vimp2_823_05202013_AJ_Aug0_Rot_-6_sd2
(349/456) train vimp2_823_05202013_AJ_Aug1_Rot_-7_sd2
(350/456) train vimp2_823_05202013_AJ_Aug2_Rot_7_sd2
(351/456) train vimp2_823_05202013_AJ_Aug3_Rot_-2_sd2
(352/456) train vimp2_823_05202013_AJ_Aug4_Rot_1_sd2
(353/456) train vimp2_823_05202013_AJ_Aug5_Rot_1_sd2
(354/456) train vimp2_824_05212013_JS_Aug0_Rot_-5_sd2
(355/456) train vimp2_824_05212013_JS_Aug1_Rot_3_sd2
(356/456) train vimp2_824_05212013_JS_Aug2_Rot_5_sd2
(357/456) train vimp2_824_05212013_JS_Aug3_Rot_2_sd2
(358/456) train vimp2_824_05212013_JS_Aug4_Rot_5_sd2
(359/456) train vimp2_824_05212013_JS_Aug5_Rot_-7_sd2
(360/456) train vimp2_845_05312013_VZ_Aug0_Rot_-5_sd2
(361/456) train vimp2_845_05312013_VZ_Aug1_Rot_3_sd2
(362/456) train vimp2_845_05312013_VZ_Aug2_Rot_-3_sd2
(363/456) train vimp2_845_05312013_VZ_Aug3_Rot_-1_sd2
(364/456) train vimp2_845_05312013_VZ_Aug4_Rot_4_sd2
(365/456) train vimp2_845_05312013_VZ_Aug5_Rot_-2_sd2
(366/456) train vimp2_869_06142013_BL_Aug0_Rot_3_sd2
(367/456) train vimp2_869_06142013_BL_Aug1_Rot_7_sd2
(368/456) train vimp2_869_06142013_BL_Aug2_Rot_4_sd2
(369/456) train vimp2_869_06142013_BL_Aug3_Rot_1_sd2
(370/456) train vimp2_869_06142013_BL_Aug4_Rot_1_sd2
(371/456) train vimp2_869_06142013_BL_Aug5_Rot_1_sd2
(372/456) train vimp2_884_06272013_TS_Aug0_Rot_3_sd2
(373/456) train vimp2_884_06272013_TS_Aug1_Rot_-5_sd2
(374/456) train vimp2_884_06272013_TS_Aug2_Rot_-7_sd2
(375/456) train vimp2_884_06272013_TS_Aug3_Rot_-6_sd2
(376/456) train vimp2_884_06272013_TS_Aug4_Rot_-2_sd2
(377/456) train vimp2_884_06272013_TS_Aug5_Rot_-6_sd2
(378/456) train vimp2_901_07052013_AS_Aug0_Rot_2_sd2
(379/456) train vimp2_901_07052013_AS_Aug1_Rot_-3_sd2
(380/456) train vimp2_901_07052013_AS_Aug2_Rot_-6_sd2
(381/456) train vimp2_901_07052013_AS_Aug3_Rot_6_sd2
(382/456) train vimp2_901_07052013_AS_Aug4_Rot_-5_sd2
(383/456) train vimp2_901_07052013_AS_Aug5_Rot_1_sd2
(384/456) train vimp2_915_07112013_LC_Aug0_Rot_1_sd2
(385/456) train vimp2_915_07112013_LC_Aug1_Rot_7_sd2
(386/456) train vimp2_915_07112013_LC_Aug2_Rot_3_sd2
(387/456) train vimp2_915_07112013_LC_Aug3_Rot_6_sd2
(388/456) train vimp2_915_07112013_LC_Aug4_Rot_4_sd2
(389/456) train vimp2_915_07112013_LC_Aug5_Rot_4_sd2
(390/456) train vimp2_943_07242013_PA_Aug0_Rot_3_sd2
(391/456) train vimp2_943_07242013_PA_Aug1_Rot_-4_sd2
(392/456) train vimp2_943_07242013_PA_Aug2_Rot_3_sd2
(393/456) train vimp2_943_07242013_PA_Aug3_Rot_2_sd2
(394/456) train vimp2_943_07242013_PA_Aug4_Rot_-1_sd2
(395/456) train vimp2_943_07242013_PA_Aug5_Rot_-3_sd2
(396/456) train vimp2_964_08092013_TG_Aug0_Rot_2_sd2
(397/456) train vimp2_964_08092013_TG_Aug1_Rot_-6_sd2
(398/456) train vimp2_964_08092013_TG_Aug2_Rot_5_sd2
(399/456) train vimp2_964_08092013_TG_Aug3_Rot_-7_sd2
(400/456) train vimp2_964_08092013_TG_Aug4_Rot_-6_sd2
(401/456) train vimp2_964_08092013_TG_Aug5_Rot_5_sd2
(402/456) train vimp2_ANON606_20130110_Aug0_Rot_-6_sd2
(403/456) train vimp2_ANON606_20130110_Aug1_Rot_-5_sd2
(404/456) train vimp2_ANON606_20130110_Aug2_Rot_-3_sd2
(405/456) train vimp2_ANON606_20130110_Aug3_Rot_3_sd2
(406/456) train vimp2_ANON606_20130110_Aug4_Rot_-2_sd2
(407/456) train vimp2_ANON606_20130110_Aug5_Rot_-3_sd2
(408/456) train vimp2_ANON624_20130117_Aug0_Rot_2_sd2
(409/456) train vimp2_ANON624_20130117_Aug1_Rot_-2_sd2
(410/456) train vimp2_ANON624_20130117_Aug2_Rot_-6_sd2
(411/456) train vimp2_ANON624_20130117_Aug3_Rot_1_sd2
(412/456) train vimp2_ANON624_20130117_Aug4_Rot_-5_sd2
(413/456) train vimp2_ANON624_20130117_Aug5_Rot_-7_sd2
(414/456) train vimp2_ANON724_03272013_Aug0_Rot_-5_sd2
(415/456) train vimp2_ANON724_03272013_Aug1_Rot_6_sd2
(416/456) train vimp2_ANON724_03272013_Aug2_Rot_-3_sd2
(417/456) train vimp2_ANON724_03272013_Aug3_Rot_-6_sd2
(418/456) train vimp2_ANON724_03272013_Aug4_Rot_-1_sd2
(419/456) train vimp2_ANON724_03272013_Aug5_Rot_-7_sd2
(420/456) train vimp2_ctrl_902_07052013_SI_Aug0_Rot_-4_sd2
(421/456) train vimp2_ctrl_902_07052013_SI_Aug1_Rot_-3_sd2
(422/456) train vimp2_ctrl_902_07052013_SI_Aug2_Rot_-5_sd2
(423/456) train vimp2_ctrl_902_07052013_SI_Aug3_Rot_5_sd2
(424/456) train vimp2_ctrl_902_07052013_SI_Aug4_Rot_-2_sd2
(425/456) train vimp2_ctrl_902_07052013_SI_Aug5_Rot_5_sd2
(426/456) train vimp2_ctrl_911_07082013_TTO_Aug0_Rot_-3_sd2
(427/456) train vimp2_ctrl_911_07082013_TTO_Aug1_Rot_7_sd2
(428/456) train vimp2_ctrl_911_07082013_TTO_Aug2_Rot_3_sd2
(429/456) train vimp2_ctrl_911_07082013_TTO_Aug3_Rot_5_sd2
(430/456) train vimp2_ctrl_911_07082013_TTO_Aug4_Rot_7_sd2
(431/456) train vimp2_ctrl_911_07082013_TTO_Aug5_Rot_2_sd2
(432/456) train vimp2_ctrl_918_07112013_TQ_Aug0_Rot_-7_sd2
(433/456) train vimp2_ctrl_918_07112013_TQ_Aug1_Rot_5_sd2
(434/456) train vimp2_ctrl_918_07112013_TQ_Aug2_Rot_5_sd2
(435/456) train vimp2_ctrl_918_07112013_TQ_Aug3_Rot_4_sd2
(436/456) train vimp2_ctrl_918_07112013_TQ_Aug4_Rot_5_sd2
(437/456) train vimp2_ctrl_918_07112013_TQ_Aug5_Rot_-4_sd2
(438/456) train vimp2_ctrl_920_07122013_SW_Aug0_Rot_7_sd2
(439/456) train vimp2_ctrl_920_07122013_SW_Aug1_Rot_-2_sd2
(440/456) train vimp2_ctrl_920_07122013_SW_Aug2_Rot_1_sd2
(441/456) train vimp2_ctrl_920_07122013_SW_Aug3_Rot_-7_sd2
(442/456) train vimp2_ctrl_920_07122013_SW_Aug4_Rot_-3_sd2
(443/456) train vimp2_ctrl_920_07122013_SW_Aug5_Rot_7_sd2
(444/456) train vimp2_ctrl_921_07122013_MP_Aug0_Rot_1_sd2
(445/456) train vimp2_ctrl_921_07122013_MP_Aug1_Rot_-7_sd2
(446/456) train vimp2_ctrl_921_07122013_MP_Aug2_Rot_6_sd2
(447/456) train vimp2_ctrl_921_07122013_MP_Aug3_Rot_-2_sd2
(448/456) train vimp2_ctrl_921_07122013_MP_Aug4_Rot_-5_sd2
(449/456) train vimp2_ctrl_921_07122013_MP_Aug5_Rot_6_sd2
(450/456) train vimp2_ctrl_925_07152013_LS_Aug0_Rot_2_sd2
(451/456) train vimp2_ctrl_925_07152013_LS_Aug1_Rot_5_sd2
(452/456) train vimp2_ctrl_925_07152013_LS_Aug2_Rot_2_sd2
(453/456) train vimp2_ctrl_925_07152013_LS_Aug3_Rot_5_sd2
(454/456) train vimp2_ctrl_925_07152013_LS_Aug4_Rot_-4_sd2
(455/456) train vimp2_ctrl_925_07152013_LS_Aug5_Rot_-3_sd22019-07-06 17:14:22.288796: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-06 17:14:24.635509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:05:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2019-07-06 17:14:24.635575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-06 17:14:25.010552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-06 17:14:25.010627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-06 17:14:25.010640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-06 17:14:25.011092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)
mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1’: File exists
mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1’: File exists
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using TensorFlow backend.
Loading train:   0%|          | 0/532 [00:00<?, ?it/s]Loading train:   0%|          | 1/532 [00:01<11:01,  1.25s/it]Loading train:   0%|          | 2/532 [00:02<10:01,  1.14s/it]Loading train:   1%|          | 3/532 [00:03<09:22,  1.06s/it]Loading train:   1%|          | 4/532 [00:03<08:36,  1.02it/s]Loading train:   1%|          | 5/532 [00:04<08:12,  1.07it/s]Loading train:   1%|          | 6/532 [00:05<07:37,  1.15it/s]Loading train:   1%|▏         | 7/532 [00:06<07:20,  1.19it/s]Loading train:   2%|▏         | 8/532 [00:06<07:02,  1.24it/s]Loading train:   2%|▏         | 9/532 [00:07<07:53,  1.10it/s]Loading train:   2%|▏         | 10/532 [00:08<07:34,  1.15it/s]Loading train:   2%|▏         | 11/532 [00:09<07:11,  1.21it/s]Loading train:   2%|▏         | 12/532 [00:10<07:51,  1.10it/s]Loading train:   2%|▏         | 13/532 [00:11<07:13,  1.20it/s]Loading train:   3%|▎         | 14/532 [00:11<06:53,  1.25it/s]Loading train:   3%|▎         | 15/532 [00:12<06:48,  1.27it/s]Loading train:   3%|▎         | 16/532 [00:13<07:08,  1.20it/s]Loading train:   3%|▎         | 17/532 [00:14<07:29,  1.15it/s]Loading train:   3%|▎         | 18/532 [00:15<07:49,  1.10it/s]Loading train:   4%|▎         | 19/532 [00:16<07:35,  1.13it/s]Loading train:   4%|▍         | 20/532 [00:17<07:53,  1.08it/s]Loading train:   4%|▍         | 21/532 [00:18<08:03,  1.06it/s]Loading train:   4%|▍         | 22/532 [00:19<07:34,  1.12it/s]Loading train:   4%|▍         | 23/532 [00:20<07:36,  1.12it/s]Loading train:   5%|▍         | 24/532 [00:20<07:23,  1.15it/s]Loading train:   5%|▍         | 25/532 [00:22<08:22,  1.01it/s]Loading train:   5%|▍         | 26/532 [00:23<08:13,  1.03it/s]Loading train:   5%|▌         | 27/532 [00:24<08:55,  1.06s/it]Loading train:   5%|▌         | 28/532 [00:25<08:24,  1.00s/it]Loading train:   5%|▌         | 29/532 [00:26<08:29,  1.01s/it]Loading train:   6%|▌         | 30/532 [00:27<07:56,  1.05it/s]Loading train:   6%|▌         | 31/532 [00:28<07:50,  1.06it/s]Loading train:   6%|▌         | 32/532 [00:29<08:04,  1.03it/s]Loading train:   6%|▌         | 33/532 [00:29<07:40,  1.08it/s]Loading train:   6%|▋         | 34/532 [00:30<07:52,  1.06it/s]Loading train:   7%|▋         | 35/532 [00:31<07:40,  1.08it/s]Loading train:   7%|▋         | 36/532 [00:32<07:39,  1.08it/s]Loading train:   7%|▋         | 37/532 [00:33<07:33,  1.09it/s]Loading train:   7%|▋         | 38/532 [00:34<07:46,  1.06it/s]Loading train:   7%|▋         | 39/532 [00:35<07:58,  1.03it/s]Loading train:   8%|▊         | 40/532 [00:36<07:29,  1.09it/s]Loading train:   8%|▊         | 41/532 [00:37<07:15,  1.13it/s]Loading train:   8%|▊         | 42/532 [00:38<07:12,  1.13it/s]Loading train:   8%|▊         | 43/532 [00:38<06:38,  1.23it/s]Loading train:   8%|▊         | 44/532 [00:39<06:04,  1.34it/s]Loading train:   8%|▊         | 45/532 [00:40<06:02,  1.34it/s]Loading train:   9%|▊         | 46/532 [00:41<06:41,  1.21it/s]Loading train:   9%|▉         | 47/532 [00:42<07:15,  1.11it/s]Loading train:   9%|▉         | 48/532 [00:43<07:30,  1.07it/s]Loading train:   9%|▉         | 49/532 [00:43<07:08,  1.13it/s]Loading train:   9%|▉         | 50/532 [00:45<07:30,  1.07it/s]Loading train:  10%|▉         | 51/532 [00:45<07:10,  1.12it/s]Loading train:  10%|▉         | 52/532 [00:46<07:13,  1.11it/s]Loading train:  10%|▉         | 53/532 [00:47<07:14,  1.10it/s]Loading train:  10%|█         | 54/532 [00:48<07:33,  1.05it/s]Loading train:  10%|█         | 55/532 [00:49<07:17,  1.09it/s]Loading train:  11%|█         | 56/532 [00:50<07:12,  1.10it/s]Loading train:  11%|█         | 57/532 [00:51<07:41,  1.03it/s]Loading train:  11%|█         | 58/532 [00:52<07:26,  1.06it/s]Loading train:  11%|█         | 59/532 [00:53<07:54,  1.00s/it]Loading train:  11%|█▏        | 60/532 [00:54<07:14,  1.09it/s]Loading train:  11%|█▏        | 61/532 [00:55<06:58,  1.13it/s]Loading train:  12%|█▏        | 62/532 [00:56<07:17,  1.07it/s]Loading train:  12%|█▏        | 63/532 [00:57<07:26,  1.05it/s]Loading train:  12%|█▏        | 64/532 [00:57<07:01,  1.11it/s]Loading train:  12%|█▏        | 65/532 [00:58<07:05,  1.10it/s]Loading train:  12%|█▏        | 66/532 [01:00<07:44,  1.00it/s]Loading train:  13%|█▎        | 67/532 [01:01<07:38,  1.01it/s]Loading train:  13%|█▎        | 68/532 [01:01<07:18,  1.06it/s]Loading train:  13%|█▎        | 69/532 [01:02<07:09,  1.08it/s]Loading train:  13%|█▎        | 70/532 [01:03<06:47,  1.13it/s]Loading train:  13%|█▎        | 71/532 [01:04<06:42,  1.15it/s]Loading train:  14%|█▎        | 72/532 [01:05<06:15,  1.23it/s]Loading train:  14%|█▎        | 73/532 [01:05<06:22,  1.20it/s]Loading train:  14%|█▍        | 74/532 [01:07<07:04,  1.08it/s]Loading train:  14%|█▍        | 75/532 [01:08<08:14,  1.08s/it]Loading train:  14%|█▍        | 76/532 [01:09<07:47,  1.03s/it]Loading train:  14%|█▍        | 77/532 [01:10<07:40,  1.01s/it]Loading train:  15%|█▍        | 78/532 [01:11<07:32,  1.00it/s]Loading train:  15%|█▍        | 79/532 [01:12<07:15,  1.04it/s]Loading train:  15%|█▌        | 80/532 [01:13<07:05,  1.06it/s]Loading train:  15%|█▌        | 81/532 [01:14<06:58,  1.08it/s]Loading train:  15%|█▌        | 82/532 [01:14<06:51,  1.09it/s]Loading train:  16%|█▌        | 83/532 [01:15<06:39,  1.12it/s]Loading train:  16%|█▌        | 84/532 [01:16<06:26,  1.16it/s]Loading train:  16%|█▌        | 85/532 [01:17<06:12,  1.20it/s]Loading train:  16%|█▌        | 86/532 [01:18<06:05,  1.22it/s]Loading train:  16%|█▋        | 87/532 [01:18<05:59,  1.24it/s]Loading train:  17%|█▋        | 88/532 [01:19<05:56,  1.25it/s]Loading train:  17%|█▋        | 89/532 [01:20<06:06,  1.21it/s]Loading train:  17%|█▋        | 90/532 [01:21<06:00,  1.23it/s]Loading train:  17%|█▋        | 91/532 [01:22<06:06,  1.20it/s]Loading train:  17%|█▋        | 92/532 [01:23<06:24,  1.14it/s]Loading train:  17%|█▋        | 93/532 [01:24<06:20,  1.15it/s]Loading train:  18%|█▊        | 94/532 [01:24<06:13,  1.17it/s]Loading train:  18%|█▊        | 95/532 [01:25<06:38,  1.10it/s]Loading train:  18%|█▊        | 96/532 [01:27<07:12,  1.01it/s]Loading train:  18%|█▊        | 97/532 [01:28<07:13,  1.00it/s]Loading train:  18%|█▊        | 98/532 [01:29<07:20,  1.01s/it]Loading train:  19%|█▊        | 99/532 [01:30<07:12,  1.00it/s]Loading train:  19%|█▉        | 100/532 [01:31<07:22,  1.02s/it]Loading train:  19%|█▉        | 101/532 [01:32<06:52,  1.04it/s]Loading train:  19%|█▉        | 102/532 [01:32<06:28,  1.11it/s]Loading train:  19%|█▉        | 103/532 [01:33<06:06,  1.17it/s]Loading train:  20%|█▉        | 104/532 [01:34<05:56,  1.20it/s]Loading train:  20%|█▉        | 105/532 [01:35<05:55,  1.20it/s]Loading train:  20%|█▉        | 106/532 [01:35<05:44,  1.24it/s]Loading train:  20%|██        | 107/532 [01:36<05:32,  1.28it/s]Loading train:  20%|██        | 108/532 [01:37<05:23,  1.31it/s]Loading train:  20%|██        | 109/532 [01:38<05:13,  1.35it/s]Loading train:  21%|██        | 110/532 [01:38<05:16,  1.34it/s]Loading train:  21%|██        | 111/532 [01:39<05:18,  1.32it/s]Loading train:  21%|██        | 112/532 [01:40<05:16,  1.33it/s]Loading train:  21%|██        | 113/532 [01:41<05:37,  1.24it/s]Loading train:  21%|██▏       | 114/532 [01:42<05:43,  1.22it/s]Loading train:  22%|██▏       | 115/532 [01:43<05:54,  1.18it/s]Loading train:  22%|██▏       | 116/532 [01:43<05:54,  1.17it/s]Loading train:  22%|██▏       | 117/532 [01:44<05:57,  1.16it/s]Loading train:  22%|██▏       | 118/532 [01:45<06:00,  1.15it/s]Loading train:  22%|██▏       | 119/532 [01:46<06:06,  1.13it/s]Loading train:  23%|██▎       | 120/532 [01:47<06:09,  1.11it/s]Loading train:  23%|██▎       | 121/532 [01:48<06:28,  1.06it/s]Loading train:  23%|██▎       | 122/532 [01:49<06:23,  1.07it/s]Loading train:  23%|██▎       | 123/532 [01:50<06:21,  1.07it/s]Loading train:  23%|██▎       | 124/532 [01:51<06:12,  1.10it/s]Loading train:  23%|██▎       | 125/532 [01:52<06:16,  1.08it/s]Loading train:  24%|██▎       | 126/532 [01:53<06:12,  1.09it/s]Loading train:  24%|██▍       | 127/532 [01:54<06:08,  1.10it/s]Loading train:  24%|██▍       | 128/532 [01:54<06:05,  1.11it/s]Loading train:  24%|██▍       | 129/532 [01:55<06:07,  1.10it/s]Loading train:  24%|██▍       | 130/532 [01:56<06:06,  1.10it/s]Loading train:  25%|██▍       | 131/532 [01:57<06:25,  1.04it/s]Loading train:  25%|██▍       | 132/532 [01:58<06:42,  1.01s/it]Loading train:  25%|██▌       | 133/532 [02:00<06:58,  1.05s/it]Loading train:  25%|██▌       | 134/532 [02:01<07:02,  1.06s/it]Loading train:  25%|██▌       | 135/532 [02:02<07:14,  1.10s/it]Loading train:  26%|██▌       | 136/532 [02:03<07:18,  1.11s/it]Loading train:  26%|██▌       | 137/532 [02:04<07:23,  1.12s/it]Loading train:  26%|██▌       | 138/532 [02:05<07:34,  1.15s/it]Loading train:  26%|██▌       | 139/532 [02:06<07:29,  1.14s/it]Loading train:  26%|██▋       | 140/532 [02:08<07:39,  1.17s/it]Loading train:  27%|██▋       | 141/532 [02:09<07:34,  1.16s/it]Loading train:  27%|██▋       | 142/532 [02:10<07:37,  1.17s/it]Loading train:  27%|██▋       | 143/532 [02:11<06:54,  1.07s/it]Loading train:  27%|██▋       | 144/532 [02:12<06:26,  1.00it/s]Loading train:  27%|██▋       | 145/532 [02:13<06:04,  1.06it/s]Loading train:  27%|██▋       | 146/532 [02:13<05:43,  1.12it/s]Loading train:  28%|██▊       | 147/532 [02:14<05:25,  1.18it/s]Loading train:  28%|██▊       | 148/532 [02:15<05:20,  1.20it/s]Loading train:  28%|██▊       | 149/532 [02:16<05:24,  1.18it/s]Loading train:  28%|██▊       | 150/532 [02:17<05:30,  1.16it/s]Loading train:  28%|██▊       | 151/532 [02:17<05:20,  1.19it/s]Loading train:  29%|██▊       | 152/532 [02:18<05:15,  1.20it/s]Loading train:  29%|██▉       | 153/532 [02:19<05:18,  1.19it/s]Loading train:  29%|██▉       | 154/532 [02:20<05:11,  1.21it/s]Loading train:  29%|██▉       | 155/532 [02:21<05:42,  1.10it/s]Loading train:  29%|██▉       | 156/532 [02:22<06:13,  1.01it/s]Loading train:  30%|██▉       | 157/532 [02:23<06:33,  1.05s/it]Loading train:  30%|██▉       | 158/532 [02:24<06:37,  1.06s/it]Loading train:  30%|██▉       | 159/532 [02:26<06:52,  1.10s/it]Loading train:  30%|███       | 160/532 [02:27<07:02,  1.14s/it]Loading train:  30%|███       | 161/532 [02:28<06:38,  1.07s/it]Loading train:  30%|███       | 162/532 [02:29<06:16,  1.02s/it]Loading train:  31%|███       | 163/532 [02:29<05:49,  1.05it/s]Loading train:  31%|███       | 164/532 [02:30<05:35,  1.10it/s]Loading train:  31%|███       | 165/532 [02:31<05:33,  1.10it/s]Loading train:  31%|███       | 166/532 [02:32<05:28,  1.11it/s]Loading train:  31%|███▏      | 167/532 [02:33<05:36,  1.08it/s]Loading train:  32%|███▏      | 168/532 [02:34<05:35,  1.09it/s]Loading train:  32%|███▏      | 169/532 [02:35<05:34,  1.08it/s]Loading train:  32%|███▏      | 170/532 [02:36<05:35,  1.08it/s]Loading train:  32%|███▏      | 171/532 [02:37<05:39,  1.06it/s]Loading train:  32%|███▏      | 172/532 [02:38<05:37,  1.07it/s]Loading train:  33%|███▎      | 173/532 [02:39<05:26,  1.10it/s]Loading train:  33%|███▎      | 174/532 [02:39<05:22,  1.11it/s]Loading train:  33%|███▎      | 175/532 [02:40<05:07,  1.16it/s]Loading train:  33%|███▎      | 176/532 [02:41<04:59,  1.19it/s]Loading train:  33%|███▎      | 177/532 [02:42<04:50,  1.22it/s]Loading train:  33%|███▎      | 178/532 [02:43<04:38,  1.27it/s]Loading train:  34%|███▎      | 179/532 [02:43<04:38,  1.27it/s]Loading train:  34%|███▍      | 180/532 [02:44<04:30,  1.30it/s]Loading train:  34%|███▍      | 181/532 [02:45<04:32,  1.29it/s]Loading train:  34%|███▍      | 182/532 [02:46<04:38,  1.26it/s]Loading train:  34%|███▍      | 183/532 [02:46<04:39,  1.25it/s]Loading train:  35%|███▍      | 184/532 [02:47<04:42,  1.23it/s]Loading train:  35%|███▍      | 185/532 [02:48<04:59,  1.16it/s]Loading train:  35%|███▍      | 186/532 [02:49<04:52,  1.18it/s]Loading train:  35%|███▌      | 187/532 [02:50<04:51,  1.18it/s]Loading train:  35%|███▌      | 188/532 [02:51<04:54,  1.17it/s]Loading train:  36%|███▌      | 189/532 [02:52<04:52,  1.17it/s]Loading train:  36%|███▌      | 190/532 [02:53<04:55,  1.16it/s]Loading train:  36%|███▌      | 191/532 [02:54<05:18,  1.07it/s]Loading train:  36%|███▌      | 192/532 [02:55<05:44,  1.01s/it]Loading train:  36%|███▋      | 193/532 [02:56<05:58,  1.06s/it]Loading train:  36%|███▋      | 194/532 [02:57<06:07,  1.09s/it]Loading train:  37%|███▋      | 195/532 [02:58<06:10,  1.10s/it]Loading train:  37%|███▋      | 196/532 [02:59<06:11,  1.11s/it]Loading train:  37%|███▋      | 197/532 [03:00<05:57,  1.07s/it]Loading train:  37%|███▋      | 198/532 [03:01<05:45,  1.03s/it]Loading train:  37%|███▋      | 199/532 [03:02<05:49,  1.05s/it]Loading train:  38%|███▊      | 200/532 [03:03<05:40,  1.03s/it]Loading train:  38%|███▊      | 201/532 [03:04<05:32,  1.00s/it]Loading train:  38%|███▊      | 202/532 [03:05<05:40,  1.03s/it]Loading train:  38%|███▊      | 203/532 [03:06<05:18,  1.03it/s]Loading train:  38%|███▊      | 204/532 [03:07<05:01,  1.09it/s]Loading train:  39%|███▊      | 205/532 [03:08<04:43,  1.15it/s]Loading train:  39%|███▊      | 206/532 [03:09<04:35,  1.18it/s]Loading train:  39%|███▉      | 207/532 [03:09<04:29,  1.21it/s]Loading train:  39%|███▉      | 208/532 [03:10<04:25,  1.22it/s]Loading train:  39%|███▉      | 209/532 [03:11<04:23,  1.22it/s]Loading train:  39%|███▉      | 210/532 [03:12<04:12,  1.28it/s]Loading train:  40%|███▉      | 211/532 [03:12<04:07,  1.30it/s]Loading train:  40%|███▉      | 212/532 [03:13<04:04,  1.31it/s]Loading train:  40%|████      | 213/532 [03:14<04:04,  1.31it/s]Loading train:  40%|████      | 214/532 [03:15<04:02,  1.31it/s]Loading train:  40%|████      | 215/532 [03:16<04:37,  1.14it/s]Loading train:  41%|████      | 216/532 [03:17<05:04,  1.04it/s]Loading train:  41%|████      | 217/532 [03:18<05:36,  1.07s/it]Loading train:  41%|████      | 218/532 [03:19<05:30,  1.05s/it]Loading train:  41%|████      | 219/532 [03:20<05:29,  1.05s/it]Loading train:  41%|████▏     | 220/532 [03:22<05:40,  1.09s/it]Loading train:  42%|████▏     | 221/532 [03:22<05:16,  1.02s/it]Loading train:  42%|████▏     | 222/532 [03:23<05:01,  1.03it/s]Loading train:  42%|████▏     | 223/532 [03:24<04:47,  1.07it/s]Loading train:  42%|████▏     | 224/532 [03:25<04:40,  1.10it/s]Loading train:  42%|████▏     | 225/532 [03:26<04:22,  1.17it/s]Loading train:  42%|████▏     | 226/532 [03:27<04:19,  1.18it/s]Loading train:  43%|████▎     | 227/532 [03:27<04:15,  1.19it/s]Loading train:  43%|████▎     | 228/532 [03:28<04:02,  1.26it/s]Loading train:  43%|████▎     | 229/532 [03:29<03:53,  1.30it/s]Loading train:  43%|████▎     | 230/532 [03:30<03:52,  1.30it/s]Loading train:  43%|████▎     | 231/532 [03:30<03:50,  1.31it/s]Loading train:  44%|████▎     | 232/532 [03:31<03:48,  1.31it/s]Loading train:  44%|████▍     | 233/532 [03:32<03:58,  1.25it/s]Loading train:  44%|████▍     | 234/532 [03:33<04:03,  1.22it/s]Loading train:  44%|████▍     | 235/532 [03:34<04:17,  1.15it/s]Loading train:  44%|████▍     | 236/532 [03:35<04:16,  1.15it/s]Loading train:  45%|████▍     | 237/532 [03:35<04:11,  1.17it/s]Loading train:  45%|████▍     | 238/532 [03:36<04:11,  1.17it/s]Loading train:  45%|████▍     | 239/532 [03:37<04:13,  1.15it/s]Loading train:  45%|████▌     | 240/532 [03:38<04:17,  1.13it/s]Loading train:  45%|████▌     | 241/532 [03:39<04:20,  1.12it/s]Loading train:  45%|████▌     | 242/532 [03:40<04:23,  1.10it/s]Loading train:  46%|████▌     | 243/532 [03:41<04:23,  1.10it/s]Loading train:  46%|████▌     | 244/532 [03:42<04:17,  1.12it/s]Loading train:  46%|████▌     | 245/532 [03:43<04:07,  1.16it/s]Loading train:  46%|████▌     | 246/532 [03:43<03:52,  1.23it/s]Loading train:  46%|████▋     | 247/532 [03:44<03:42,  1.28it/s]Loading train:  47%|████▋     | 248/532 [03:45<03:34,  1.33it/s]Loading train:  47%|████▋     | 249/532 [03:45<03:35,  1.31it/s]Loading train:  47%|████▋     | 250/532 [03:46<03:37,  1.30it/s]Loading train:  47%|████▋     | 251/532 [03:47<03:40,  1.27it/s]Loading train:  47%|████▋     | 252/532 [03:48<03:42,  1.26it/s]Loading train:  48%|████▊     | 253/532 [03:49<03:43,  1.25it/s]Loading train:  48%|████▊     | 254/532 [03:49<03:36,  1.28it/s]Loading train:  48%|████▊     | 255/532 [03:50<03:34,  1.29it/s]Loading train:  48%|████▊     | 256/532 [03:51<03:41,  1.25it/s]Loading train:  48%|████▊     | 257/532 [03:52<04:00,  1.14it/s]Loading train:  48%|████▊     | 258/532 [03:53<04:14,  1.08it/s]Loading train:  49%|████▊     | 259/532 [03:54<04:21,  1.04it/s]Loading train:  49%|████▉     | 260/532 [03:55<04:22,  1.03it/s]Loading train:  49%|████▉     | 261/532 [03:56<04:29,  1.01it/s]Loading train:  49%|████▉     | 262/532 [03:57<04:33,  1.01s/it]Loading train:  49%|████▉     | 263/532 [03:58<04:14,  1.06it/s]Loading train:  50%|████▉     | 264/532 [03:59<03:54,  1.14it/s]Loading train:  50%|████▉     | 265/532 [04:00<03:43,  1.20it/s]Loading train:  50%|█████     | 266/532 [04:00<03:30,  1.26it/s]Loading train:  50%|█████     | 267/532 [04:01<03:23,  1.30it/s]Loading train:  50%|█████     | 268/532 [04:02<03:14,  1.35it/s]Loading train:  51%|█████     | 269/532 [04:03<03:28,  1.26it/s]Loading train:  51%|█████     | 270/532 [04:03<03:31,  1.24it/s]Loading train:  51%|█████     | 271/532 [04:04<03:35,  1.21it/s]Loading train:  51%|█████     | 272/532 [04:05<03:35,  1.20it/s]Loading train:  51%|█████▏    | 273/532 [04:06<03:37,  1.19it/s]Loading train:  52%|█████▏    | 274/532 [04:07<03:36,  1.19it/s]Loading train:  52%|█████▏    | 275/532 [04:08<03:49,  1.12it/s]Loading train:  52%|█████▏    | 276/532 [04:09<04:12,  1.02it/s]Loading train:  52%|█████▏    | 277/532 [04:10<04:32,  1.07s/it]Loading train:  52%|█████▏    | 278/532 [04:11<04:31,  1.07s/it]Loading train:  52%|█████▏    | 279/532 [04:12<04:30,  1.07s/it]Loading train:  53%|█████▎    | 280/532 [04:13<04:28,  1.07s/it]Loading train:  53%|█████▎    | 281/532 [04:14<04:23,  1.05s/it]Loading train:  53%|█████▎    | 282/532 [04:15<04:20,  1.04s/it]Loading train:  53%|█████▎    | 283/532 [04:16<04:14,  1.02s/it]Loading train:  53%|█████▎    | 284/532 [04:17<04:09,  1.01s/it]Loading train:  54%|█████▎    | 285/532 [04:18<04:09,  1.01s/it]Loading train:  54%|█████▍    | 286/532 [04:19<04:10,  1.02s/it]Loading train:  54%|█████▍    | 287/532 [04:20<03:51,  1.06it/s]Loading train:  54%|█████▍    | 288/532 [04:21<03:39,  1.11it/s]Loading train:  54%|█████▍    | 289/532 [04:22<03:33,  1.14it/s]Loading train:  55%|█████▍    | 290/532 [04:23<03:25,  1.18it/s]Loading train:  55%|█████▍    | 291/532 [04:23<03:21,  1.20it/s]Loading train:  55%|█████▍    | 292/532 [04:24<03:16,  1.22it/s]Loading train:  55%|█████▌    | 293/532 [04:25<03:19,  1.20it/s]Loading train:  55%|█████▌    | 294/532 [04:26<03:24,  1.16it/s]Loading train:  55%|█████▌    | 295/532 [04:27<03:27,  1.14it/s]Loading train:  56%|█████▌    | 296/532 [04:28<03:29,  1.13it/s]Loading train:  56%|█████▌    | 297/532 [04:29<03:29,  1.12it/s]Loading train:  56%|█████▌    | 298/532 [04:30<03:32,  1.10it/s]Loading train:  56%|█████▌    | 299/532 [04:31<03:31,  1.10it/s]Loading train:  56%|█████▋    | 300/532 [04:31<03:21,  1.15it/s]Loading train:  57%|█████▋    | 301/532 [04:32<03:13,  1.19it/s]Loading train:  57%|█████▋    | 302/532 [04:33<03:10,  1.21it/s]Loading train:  57%|█████▋    | 303/532 [04:34<03:01,  1.26it/s]Loading train:  57%|█████▋    | 304/532 [04:34<02:58,  1.28it/s]Loading train:  57%|█████▋    | 305/532 [04:36<03:25,  1.11it/s]Loading train:  58%|█████▊    | 306/532 [04:37<03:39,  1.03it/s]Loading train:  58%|█████▊    | 307/532 [04:38<03:51,  1.03s/it]Loading train:  58%|█████▊    | 308/532 [04:39<04:00,  1.07s/it]Loading train:  58%|█████▊    | 309/532 [04:40<04:02,  1.09s/it]Loading train:  58%|█████▊    | 310/532 [04:41<04:04,  1.10s/it]Loading train:  58%|█████▊    | 311/532 [04:43<04:30,  1.22s/it]Loading train:  59%|█████▊    | 312/532 [04:44<04:40,  1.27s/it]Loading train:  59%|█████▉    | 313/532 [04:46<04:46,  1.31s/it]Loading train:  59%|█████▉    | 314/532 [04:47<04:48,  1.32s/it]Loading train:  59%|█████▉    | 315/532 [04:48<04:56,  1.36s/it]Loading train:  59%|█████▉    | 316/532 [04:50<04:54,  1.36s/it]Loading train:  60%|█████▉    | 317/532 [04:51<04:23,  1.23s/it]Loading train:  60%|█████▉    | 318/532 [04:52<03:54,  1.10s/it]Loading train:  60%|█████▉    | 319/532 [04:52<03:39,  1.03s/it]Loading train:  60%|██████    | 320/532 [04:53<03:24,  1.04it/s]Loading train:  60%|██████    | 321/532 [04:54<03:18,  1.06it/s]Loading train:  61%|██████    | 322/532 [04:55<03:19,  1.05it/s]Loading train:  61%|██████    | 323/532 [04:56<03:31,  1.01s/it]Loading train:  61%|██████    | 324/532 [04:57<03:37,  1.05s/it]Loading train:  61%|██████    | 325/532 [04:59<03:57,  1.15s/it]Loading train:  61%|██████▏   | 326/532 [05:00<03:58,  1.16s/it]Loading train:  61%|██████▏   | 327/532 [05:01<03:54,  1.14s/it]Loading train:  62%|██████▏   | 328/532 [05:02<03:51,  1.13s/it]Loading train:  62%|██████▏   | 329/532 [05:03<03:37,  1.07s/it]Loading train:  62%|██████▏   | 330/532 [05:04<03:23,  1.01s/it]Loading train:  62%|██████▏   | 331/532 [05:05<03:11,  1.05it/s]Loading train:  62%|██████▏   | 332/532 [05:06<03:05,  1.08it/s]Loading train:  63%|██████▎   | 333/532 [05:06<03:00,  1.10it/s]Loading train:  63%|██████▎   | 334/532 [05:07<02:52,  1.15it/s]Loading train:  63%|██████▎   | 335/532 [05:08<03:02,  1.08it/s]Loading train:  63%|██████▎   | 336/532 [05:09<03:09,  1.04it/s]Loading train:  63%|██████▎   | 337/532 [05:10<03:11,  1.02it/s]Loading train:  64%|██████▎   | 338/532 [05:11<03:12,  1.01it/s]Loading train:  64%|██████▎   | 339/532 [05:12<03:11,  1.01it/s]Loading train:  64%|██████▍   | 340/532 [05:13<03:09,  1.01it/s]Loading train:  64%|██████▍   | 341/532 [05:14<02:57,  1.07it/s]Loading train:  64%|██████▍   | 342/532 [05:15<02:49,  1.12it/s]Loading train:  64%|██████▍   | 343/532 [05:16<02:53,  1.09it/s]Loading train:  65%|██████▍   | 344/532 [05:17<02:48,  1.12it/s]Loading train:  65%|██████▍   | 345/532 [05:18<02:40,  1.16it/s]Loading train:  65%|██████▌   | 346/532 [05:18<02:37,  1.18it/s]Loading train:  65%|██████▌   | 347/532 [05:19<02:39,  1.16it/s]Loading train:  65%|██████▌   | 348/532 [05:20<02:37,  1.17it/s]Loading train:  66%|██████▌   | 349/532 [05:21<02:35,  1.17it/s]Loading train:  66%|██████▌   | 350/532 [05:22<02:33,  1.19it/s]Loading train:  66%|██████▌   | 351/532 [05:23<02:33,  1.18it/s]Loading train:  66%|██████▌   | 352/532 [05:23<02:29,  1.21it/s]Loading train:  66%|██████▋   | 353/532 [05:24<02:29,  1.20it/s]Loading train:  67%|██████▋   | 354/532 [05:25<02:25,  1.22it/s]Loading train:  67%|██████▋   | 355/532 [05:26<02:20,  1.26it/s]Loading train:  67%|██████▋   | 356/532 [05:27<02:17,  1.28it/s]Loading train:  67%|██████▋   | 357/532 [05:27<02:15,  1.29it/s]Loading train:  67%|██████▋   | 358/532 [05:28<02:14,  1.30it/s]Loading train:  67%|██████▋   | 359/532 [05:29<02:17,  1.25it/s]Loading train:  68%|██████▊   | 360/532 [05:30<02:13,  1.29it/s]Loading train:  68%|██████▊   | 361/532 [05:30<02:14,  1.27it/s]Loading train:  68%|██████▊   | 362/532 [05:31<02:21,  1.20it/s]Loading train:  68%|██████▊   | 363/532 [05:32<02:18,  1.22it/s]Loading train:  68%|██████▊   | 364/532 [05:33<02:17,  1.22it/s]Loading train:  69%|██████▊   | 365/532 [05:34<02:16,  1.23it/s]Loading train:  69%|██████▉   | 366/532 [05:35<02:15,  1.22it/s]Loading train:  69%|██████▉   | 367/532 [05:35<02:10,  1.27it/s]Loading train:  69%|██████▉   | 368/532 [05:36<02:11,  1.25it/s]Loading train:  69%|██████▉   | 369/532 [05:37<02:09,  1.26it/s]Loading train:  70%|██████▉   | 370/532 [05:38<02:06,  1.28it/s]Loading train:  70%|██████▉   | 371/532 [05:39<02:21,  1.14it/s]Loading train:  70%|██████▉   | 372/532 [05:40<02:28,  1.08it/s]Loading train:  70%|███████   | 373/532 [05:41<02:35,  1.03it/s]Loading train:  70%|███████   | 374/532 [05:42<02:38,  1.00s/it]Loading train:  70%|███████   | 375/532 [05:43<02:38,  1.01s/it]Loading train:  71%|███████   | 376/532 [05:44<02:37,  1.01s/it]Loading train:  71%|███████   | 377/532 [05:45<02:32,  1.02it/s]Loading train:  71%|███████   | 378/532 [05:46<02:26,  1.05it/s]Loading train:  71%|███████   | 379/532 [05:47<02:22,  1.07it/s]Loading train:  71%|███████▏  | 380/532 [05:48<02:18,  1.10it/s]Loading train:  72%|███████▏  | 381/532 [05:49<02:19,  1.08it/s]Loading train:  72%|███████▏  | 382/532 [05:49<02:14,  1.12it/s]Loading train:  72%|███████▏  | 383/532 [05:50<02:12,  1.13it/s]Loading train:  72%|███████▏  | 384/532 [05:51<02:10,  1.13it/s]Loading train:  72%|███████▏  | 385/532 [05:52<02:11,  1.12it/s]Loading train:  73%|███████▎  | 386/532 [05:53<02:08,  1.13it/s]Loading train:  73%|███████▎  | 387/532 [05:54<02:08,  1.12it/s]Loading train:  73%|███████▎  | 388/532 [05:55<02:05,  1.15it/s]Loading train:  73%|███████▎  | 389/532 [05:56<02:10,  1.09it/s]Loading train:  73%|███████▎  | 390/532 [05:57<02:13,  1.06it/s]Loading train:  73%|███████▎  | 391/532 [05:58<02:15,  1.04it/s]Loading train:  74%|███████▎  | 392/532 [05:59<02:16,  1.03it/s]Loading train:  74%|███████▍  | 393/532 [06:00<02:19,  1.00s/it]Loading train:  74%|███████▍  | 394/532 [06:01<02:16,  1.01it/s]Loading train:  74%|███████▍  | 395/532 [06:02<02:15,  1.01it/s]Loading train:  74%|███████▍  | 396/532 [06:03<02:15,  1.00it/s]Loading train:  75%|███████▍  | 397/532 [06:04<02:12,  1.02it/s]Loading train:  75%|███████▍  | 398/532 [06:05<02:10,  1.03it/s]Loading train:  75%|███████▌  | 399/532 [06:06<02:07,  1.05it/s]Loading train:  75%|███████▌  | 400/532 [06:06<02:07,  1.04it/s]Loading train:  75%|███████▌  | 401/532 [06:07<02:05,  1.04it/s]Loading train:  76%|███████▌  | 402/532 [06:08<02:04,  1.04it/s]Loading train:  76%|███████▌  | 403/532 [06:10<02:13,  1.03s/it]Loading train:  76%|███████▌  | 404/532 [06:11<02:10,  1.02s/it]Loading train:  76%|███████▌  | 405/532 [06:12<02:07,  1.01s/it]Loading train:  76%|███████▋  | 406/532 [06:13<02:05,  1.01it/s]Loading train:  77%|███████▋  | 407/532 [06:13<01:58,  1.05it/s]Loading train:  77%|███████▋  | 408/532 [06:14<01:53,  1.09it/s]Loading train:  77%|███████▋  | 409/532 [06:15<01:47,  1.14it/s]Loading train:  77%|███████▋  | 410/532 [06:16<01:45,  1.15it/s]Loading train:  77%|███████▋  | 411/532 [06:17<01:43,  1.17it/s]Loading train:  77%|███████▋  | 412/532 [06:18<01:42,  1.18it/s]Loading train:  78%|███████▊  | 413/532 [06:18<01:39,  1.19it/s]Loading train:  78%|███████▊  | 414/532 [06:19<01:35,  1.24it/s]Loading train:  78%|███████▊  | 415/532 [06:20<01:38,  1.18it/s]Loading train:  78%|███████▊  | 416/532 [06:21<01:36,  1.21it/s]Loading train:  78%|███████▊  | 417/532 [06:22<01:37,  1.17it/s]Loading train:  79%|███████▊  | 418/532 [06:23<01:38,  1.16it/s]Loading train:  79%|███████▉  | 419/532 [06:24<01:43,  1.10it/s]Loading train:  79%|███████▉  | 420/532 [06:25<01:42,  1.09it/s]Loading train:  79%|███████▉  | 421/532 [06:25<01:41,  1.09it/s]Loading train:  79%|███████▉  | 422/532 [06:26<01:41,  1.08it/s]Loading train:  80%|███████▉  | 423/532 [06:28<01:47,  1.01it/s]Loading train:  80%|███████▉  | 424/532 [06:28<01:43,  1.04it/s]Loading train:  80%|███████▉  | 425/532 [06:29<01:42,  1.04it/s]Loading train:  80%|████████  | 426/532 [06:30<01:40,  1.06it/s]Loading train:  80%|████████  | 427/532 [06:31<01:41,  1.04it/s]Loading train:  80%|████████  | 428/532 [06:32<01:38,  1.05it/s]Loading train:  81%|████████  | 429/532 [06:33<01:39,  1.04it/s]Loading train:  81%|████████  | 430/532 [06:34<01:39,  1.03it/s]Loading train:  81%|████████  | 431/532 [06:35<01:41,  1.01s/it]Loading train:  81%|████████  | 432/532 [06:36<01:39,  1.00it/s]Loading train:  81%|████████▏ | 433/532 [06:37<01:37,  1.02it/s]Loading train:  82%|████████▏ | 434/532 [06:38<01:35,  1.02it/s]Loading train:  82%|████████▏ | 435/532 [06:39<01:34,  1.03it/s]Loading train:  82%|████████▏ | 436/532 [06:40<01:34,  1.01it/s]Loading train:  82%|████████▏ | 437/532 [06:41<01:27,  1.09it/s]Loading train:  82%|████████▏ | 438/532 [06:42<01:23,  1.13it/s]Loading train:  83%|████████▎ | 439/532 [06:43<01:19,  1.16it/s]Loading train:  83%|████████▎ | 440/532 [06:43<01:14,  1.23it/s]Loading train:  83%|████████▎ | 441/532 [06:44<01:12,  1.26it/s]Loading train:  83%|████████▎ | 442/532 [06:45<01:09,  1.29it/s]Loading train:  83%|████████▎ | 443/532 [06:45<01:08,  1.29it/s]Loading train:  83%|████████▎ | 444/532 [06:46<01:07,  1.31it/s]Loading train:  84%|████████▎ | 445/532 [06:47<01:05,  1.32it/s]Loading train:  84%|████████▍ | 446/532 [06:48<01:05,  1.31it/s]Loading train:  84%|████████▍ | 447/532 [06:48<01:03,  1.34it/s]Loading train:  84%|████████▍ | 448/532 [06:49<01:02,  1.34it/s]Loading train:  84%|████████▍ | 449/532 [06:50<01:03,  1.30it/s]Loading train:  85%|████████▍ | 450/532 [06:51<01:03,  1.29it/s]Loading train:  85%|████████▍ | 451/532 [06:52<01:06,  1.23it/s]Loading train:  85%|████████▍ | 452/532 [06:53<01:08,  1.17it/s]Loading train:  85%|████████▌ | 453/532 [06:53<01:06,  1.19it/s]Loading train:  85%|████████▌ | 454/532 [06:54<01:06,  1.18it/s]Loading train:  86%|████████▌ | 455/532 [06:55<01:08,  1.13it/s]Loading train:  86%|████████▌ | 456/532 [06:56<01:08,  1.11it/s]Loading train:  86%|████████▌ | 457/532 [06:57<01:06,  1.13it/s]Loading train:  86%|████████▌ | 458/532 [06:58<01:04,  1.14it/s]Loading train:  86%|████████▋ | 459/532 [06:59<01:11,  1.03it/s]Loading train:  86%|████████▋ | 460/532 [07:00<01:11,  1.00it/s]Loading train:  87%|████████▋ | 461/532 [07:01<01:13,  1.03s/it]Loading train:  87%|████████▋ | 462/532 [07:02<01:12,  1.04s/it]Loading train:  87%|████████▋ | 463/532 [07:03<01:12,  1.06s/it]Loading train:  87%|████████▋ | 464/532 [07:04<01:11,  1.05s/it]Loading train:  87%|████████▋ | 465/532 [07:06<01:11,  1.07s/it]Loading train:  88%|████████▊ | 466/532 [07:07<01:13,  1.11s/it]Loading train:  88%|████████▊ | 467/532 [07:08<01:08,  1.05s/it]Loading train:  88%|████████▊ | 468/532 [07:09<01:04,  1.01s/it]Loading train:  88%|████████▊ | 469/532 [07:10<01:03,  1.01s/it]Loading train:  88%|████████▊ | 470/532 [07:11<01:01,  1.01it/s]Loading train:  89%|████████▊ | 471/532 [07:11<00:57,  1.06it/s]Loading train:  89%|████████▊ | 472/532 [07:12<00:55,  1.09it/s]Loading train:  89%|████████▉ | 473/532 [07:13<00:55,  1.07it/s]Loading train:  89%|████████▉ | 474/532 [07:14<00:55,  1.05it/s]Loading train:  89%|████████▉ | 475/532 [07:15<00:53,  1.07it/s]Loading train:  89%|████████▉ | 476/532 [07:16<00:51,  1.08it/s]Loading train:  90%|████████▉ | 477/532 [07:17<00:51,  1.06it/s]Loading train:  90%|████████▉ | 478/532 [07:18<00:51,  1.05it/s]Loading train:  90%|█████████ | 479/532 [07:19<00:48,  1.10it/s]Loading train:  90%|█████████ | 480/532 [07:20<00:45,  1.15it/s]Loading train:  90%|█████████ | 481/532 [07:20<00:43,  1.16it/s]Loading train:  91%|█████████ | 482/532 [07:21<00:42,  1.18it/s]Loading train:  91%|█████████ | 483/532 [07:22<00:40,  1.21it/s]Loading train:  91%|█████████ | 484/532 [07:23<00:38,  1.25it/s]Loading train:  91%|█████████ | 485/532 [07:24<00:43,  1.09it/s]Loading train:  91%|█████████▏| 486/532 [07:25<00:44,  1.03it/s]Loading train:  92%|█████████▏| 487/532 [07:26<00:43,  1.03it/s]Loading train:  92%|█████████▏| 488/532 [07:27<00:43,  1.02it/s]Loading train:  92%|█████████▏| 489/532 [07:28<00:42,  1.00it/s]Loading train:  92%|█████████▏| 490/532 [07:29<00:42,  1.02s/it]Loading train:  92%|█████████▏| 491/532 [07:30<00:39,  1.03it/s]Loading train:  92%|█████████▏| 492/532 [07:31<00:38,  1.04it/s]Loading train:  93%|█████████▎| 493/532 [07:32<00:36,  1.06it/s]Loading train:  93%|█████████▎| 494/532 [07:33<00:35,  1.07it/s]Loading train:  93%|█████████▎| 495/532 [07:34<00:32,  1.13it/s]Loading train:  93%|█████████▎| 496/532 [07:35<00:33,  1.09it/s]Loading train:  93%|█████████▎| 497/532 [07:35<00:32,  1.06it/s]Loading train:  94%|█████████▎| 498/532 [07:36<00:31,  1.07it/s]Loading train:  94%|█████████▍| 499/532 [07:37<00:30,  1.08it/s]Loading train:  94%|█████████▍| 500/532 [07:38<00:29,  1.09it/s]Loading train:  94%|█████████▍| 501/532 [07:39<00:27,  1.13it/s]Loading train:  94%|█████████▍| 502/532 [07:40<00:27,  1.07it/s]Loading train:  95%|█████████▍| 503/532 [07:41<00:26,  1.10it/s]Loading train:  95%|█████████▍| 504/532 [07:42<00:24,  1.14it/s]Loading train:  95%|█████████▍| 505/532 [07:43<00:23,  1.17it/s]Loading train:  95%|█████████▌| 506/532 [07:43<00:22,  1.17it/s]Loading train:  95%|█████████▌| 507/532 [07:44<00:20,  1.20it/s]Loading train:  95%|█████████▌| 508/532 [07:45<00:19,  1.21it/s]Loading train:  96%|█████████▌| 509/532 [07:46<00:20,  1.12it/s]Loading train:  96%|█████████▌| 510/532 [07:47<00:20,  1.08it/s]Loading train:  96%|█████████▌| 511/532 [07:48<00:20,  1.04it/s]Loading train:  96%|█████████▌| 512/532 [07:49<00:19,  1.02it/s]Loading train:  96%|█████████▋| 513/532 [07:50<00:18,  1.03it/s]Loading train:  97%|█████████▋| 514/532 [07:51<00:17,  1.02it/s]Loading train:  97%|█████████▋| 515/532 [07:52<00:17,  1.00s/it]Loading train:  97%|█████████▋| 516/532 [07:53<00:15,  1.02it/s]Loading train:  97%|█████████▋| 517/532 [07:54<00:14,  1.05it/s]Loading train:  97%|█████████▋| 518/532 [07:55<00:12,  1.09it/s]Loading train:  98%|█████████▊| 519/532 [07:56<00:11,  1.12it/s]Loading train:  98%|█████████▊| 520/532 [07:56<00:10,  1.14it/s]Loading train:  98%|█████████▊| 521/532 [07:57<00:09,  1.14it/s]Loading train:  98%|█████████▊| 522/532 [07:58<00:08,  1.14it/s]Loading train:  98%|█████████▊| 523/532 [07:59<00:07,  1.16it/s]Loading train:  98%|█████████▊| 524/532 [08:00<00:07,  1.13it/s]Loading train:  99%|█████████▊| 525/532 [08:01<00:06,  1.15it/s]Loading train:  99%|█████████▉| 526/532 [08:02<00:05,  1.14it/s]Loading train:  99%|█████████▉| 527/532 [08:03<00:04,  1.13it/s]Loading train:  99%|█████████▉| 528/532 [08:03<00:03,  1.16it/s]Loading train:  99%|█████████▉| 529/532 [08:04<00:02,  1.19it/s]Loading train: 100%|█████████▉| 530/532 [08:05<00:01,  1.25it/s]Loading train: 100%|█████████▉| 531/532 [08:06<00:00,  1.25it/s]Loading train: 100%|██████████| 532/532 [08:07<00:00,  1.24it/s]
concatenating: train:   0%|          | 0/532 [00:00<?, ?it/s]concatenating: train:   1%|          | 5/532 [00:00<00:12, 41.32it/s]concatenating: train:   3%|▎         | 17/532 [00:00<00:10, 51.03it/s]concatenating: train:   6%|▋         | 34/532 [00:00<00:07, 63.96it/s]concatenating: train:  10%|▉         | 52/532 [00:00<00:06, 78.62it/s]concatenating: train:  13%|█▎        | 71/532 [00:00<00:04, 95.32it/s]concatenating: train:  16%|█▋        | 87/532 [00:00<00:04, 108.32it/s]concatenating: train:  20%|█▉        | 106/532 [00:00<00:03, 123.78it/s]concatenating: train:  23%|██▎       | 123/532 [00:00<00:03, 133.42it/s]concatenating: train:  27%|██▋       | 142/532 [00:00<00:02, 143.02it/s]concatenating: train:  30%|██▉       | 159/532 [00:01<00:02, 148.52it/s]concatenating: train:  33%|███▎      | 176/532 [00:01<00:02, 143.72it/s]concatenating: train:  37%|███▋      | 197/532 [00:01<00:02, 157.90it/s]concatenating: train:  42%|████▏     | 223/532 [00:01<00:01, 177.60it/s]concatenating: train:  47%|████▋     | 248/532 [00:01<00:01, 193.31it/s]concatenating: train:  52%|█████▏    | 274/532 [00:01<00:01, 207.07it/s]concatenating: train:  56%|█████▌    | 299/532 [00:01<00:01, 218.12it/s]concatenating: train:  61%|██████    | 325/532 [00:01<00:00, 227.56it/s]concatenating: train:  66%|██████▌   | 350/532 [00:01<00:00, 231.20it/s]concatenating: train:  70%|███████   | 375/532 [00:02<00:00, 236.15it/s]concatenating: train:  75%|███████▌  | 400/532 [00:02<00:00, 235.14it/s]concatenating: train:  80%|████████  | 427/532 [00:02<00:00, 241.97it/s]concatenating: train:  85%|████████▌ | 453/532 [00:02<00:00, 245.24it/s]concatenating: train:  90%|█████████ | 479/532 [00:02<00:00, 247.83it/s]concatenating: train:  95%|█████████▍| 504/532 [00:02<00:00, 245.38it/s]concatenating: train: 100%|█████████▉| 530/532 [00:02<00:00, 248.65it/s]concatenating: train: 100%|██████████| 532/532 [00:02<00:00, 201.37it/s]
Loading test:   0%|          | 0/15 [00:00<?, ?it/s]Loading test:   7%|▋         | 1/15 [00:00<00:11,  1.23it/s]Loading test:  13%|█▎        | 2/15 [00:01<00:10,  1.24it/s]Loading test:  20%|██        | 3/15 [00:02<00:10,  1.16it/s]Loading test:  27%|██▋       | 4/15 [00:03<00:09,  1.15it/s]Loading test:  33%|███▎      | 5/15 [00:04<00:09,  1.05it/s]Loading test:  40%|████      | 6/15 [00:05<00:09,  1.02s/it]Loading test:  47%|████▋     | 7/15 [00:06<00:08,  1.00s/it]Loading test:  53%|█████▎    | 8/15 [00:08<00:07,  1.08s/it]Loading test:  60%|██████    | 9/15 [00:08<00:06,  1.03s/it]Loading test:  67%|██████▋   | 10/15 [00:09<00:04,  1.02it/s]Loading test:  73%|███████▎  | 11/15 [00:10<00:03,  1.06it/s]Loading test:  80%|████████  | 12/15 [00:11<00:02,  1.03it/s]Loading test:  87%|████████▋ | 13/15 [00:12<00:01,  1.00it/s]Loading test:  93%|█████████▎| 14/15 [00:13<00:00,  1.07it/s]Loading test: 100%|██████████| 15/15 [00:14<00:00,  1.08it/s]
concatenating: validation:   0%|          | 0/15 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 15/15 [00:00<00:00, 169.97it/s]
(0/4) test vimp2_ctrl_991_08302013_JF
(1/4) test vimp2_967_08132013_KW
(2/4) test vimp2_765_04162013_AW
(3/4) test vimp2_ANON695_03132013
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 56, 84, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 56, 84, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 56, 84, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 56, 84, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 56, 84, 10)   910         activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 84, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 56, 84, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 56, 84, 11)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 28, 42, 11)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28, 42, 11)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 42, 20)   2000        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 42, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 42, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 42, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 28, 42, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 28, 42, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 42, 31)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 21, 31)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 14, 21, 31)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 14, 21, 40)   11200       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 14, 21, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 14, 21, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 14, 21, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 14, 21, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 14, 21, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 14, 21, 71)   0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 14, 21, 71)   0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 28, 42, 20)   5700        dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 28, 42, 51)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 28, 42, 20)   9200        concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 28, 42, 20)   80          conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 28, 42, 20)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 28, 42, 20)   3620        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 28, 42, 20)   80          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 28, 42, 20)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 28, 42, 71)   0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 28, 42, 71)   0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 56, 84, 10)   2850        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 84, 21)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 56, 84, 10)   1900        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 56, 84, 10)   40          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 84, 10)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 56, 84, 10)   910         activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 56, 84, 10)   40          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 84, 10)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 84, 31)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 56, 84, 31)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 56, 84, 13)   416         dropout_5[0][0]                  
==================================================================================================
Total params: 57,666
Trainable params: 57,266
Non-trainable params: 400
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.53383120e-02 2.88786827e-02 1.16652967e-01 1.00133292e-02
 3.03165963e-02 5.79538965e-03 6.85058777e-02 1.28145429e-01
 7.55135052e-02 1.22435092e-02 2.73464902e-01 1.84941443e-01
 1.90056842e-04]
Train on 20749 samples, validate on 584 samples
Epoch 1/300
 - 26s - loss: 62.7980 - acc: 0.6741 - mDice: 0.0167 - val_loss: 4.7181 - val_acc: 0.9134 - val_mDice: 0.0220

Epoch 00001: val_mDice improved from -inf to 0.02197, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 16s - loss: 6.7406 - acc: 0.8978 - mDice: 0.0318 - val_loss: 3.9763 - val_acc: 0.9134 - val_mDice: 0.0399

Epoch 00002: val_mDice improved from 0.02197 to 0.03990, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 16s - loss: 5.1529 - acc: 0.8986 - mDice: 0.0468 - val_loss: 3.6039 - val_acc: 0.9129 - val_mDice: 0.0701

Epoch 00003: val_mDice improved from 0.03990 to 0.07006, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 16s - loss: 4.4989 - acc: 0.8993 - mDice: 0.0662 - val_loss: 3.2817 - val_acc: 0.9143 - val_mDice: 0.0939

Epoch 00004: val_mDice improved from 0.07006 to 0.09391, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 15s - loss: 4.0050 - acc: 0.9015 - mDice: 0.0952 - val_loss: 2.9519 - val_acc: 0.9149 - val_mDice: 0.1256

Epoch 00005: val_mDice improved from 0.09391 to 0.12558, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 16s - loss: 3.5703 - acc: 0.9066 - mDice: 0.1312 - val_loss: 2.5794 - val_acc: 0.9243 - val_mDice: 0.1780

Epoch 00006: val_mDice improved from 0.12558 to 0.17798, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 15s - loss: 3.1953 - acc: 0.9129 - mDice: 0.1741 - val_loss: 2.2686 - val_acc: 0.9328 - val_mDice: 0.2457

Epoch 00007: val_mDice improved from 0.17798 to 0.24565, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 16s - loss: 2.9081 - acc: 0.9190 - mDice: 0.2191 - val_loss: 1.9387 - val_acc: 0.9504 - val_mDice: 0.3158

Epoch 00008: val_mDice improved from 0.24565 to 0.31575, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 9/300
 - 15s - loss: 2.7071 - acc: 0.9240 - mDice: 0.2527 - val_loss: 1.7465 - val_acc: 0.9559 - val_mDice: 0.3709

Epoch 00009: val_mDice improved from 0.31575 to 0.37088, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 17s - loss: 2.5575 - acc: 0.9272 - mDice: 0.2780 - val_loss: 1.6531 - val_acc: 0.9574 - val_mDice: 0.3978

Epoch 00010: val_mDice improved from 0.37088 to 0.39776, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 11/300
 - 15s - loss: 2.4495 - acc: 0.9291 - mDice: 0.2977 - val_loss: 1.6261 - val_acc: 0.9578 - val_mDice: 0.4137

Epoch 00011: val_mDice improved from 0.39776 to 0.41373, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 12/300
 - 16s - loss: 2.3317 - acc: 0.9312 - mDice: 0.3187 - val_loss: 1.5228 - val_acc: 0.9601 - val_mDice: 0.4401

Epoch 00012: val_mDice improved from 0.41373 to 0.44013, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 13/300
 - 15s - loss: 2.2364 - acc: 0.9327 - mDice: 0.3366 - val_loss: 1.4346 - val_acc: 0.9631 - val_mDice: 0.4601

Epoch 00013: val_mDice improved from 0.44013 to 0.46014, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 14/300
 - 16s - loss: 2.1517 - acc: 0.9343 - mDice: 0.3532 - val_loss: 1.3703 - val_acc: 0.9630 - val_mDice: 0.4863

Epoch 00014: val_mDice improved from 0.46014 to 0.48631, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 15/300
 - 15s - loss: 2.0501 - acc: 0.9363 - mDice: 0.3748 - val_loss: 1.3313 - val_acc: 0.9647 - val_mDice: 0.5042

Epoch 00015: val_mDice improved from 0.48631 to 0.50419, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 16/300
 - 16s - loss: 1.9498 - acc: 0.9383 - mDice: 0.3993 - val_loss: 1.2274 - val_acc: 0.9656 - val_mDice: 0.5408

Epoch 00016: val_mDice improved from 0.50419 to 0.54084, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 17/300
 - 15s - loss: 1.8662 - acc: 0.9403 - mDice: 0.4200 - val_loss: 1.1446 - val_acc: 0.9679 - val_mDice: 0.5605

Epoch 00017: val_mDice improved from 0.54084 to 0.56046, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 18/300
 - 16s - loss: 1.7989 - acc: 0.9416 - mDice: 0.4355 - val_loss: 1.1616 - val_acc: 0.9675 - val_mDice: 0.5636

Epoch 00018: val_mDice improved from 0.56046 to 0.56357, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 19/300
 - 15s - loss: 1.7332 - acc: 0.9428 - mDice: 0.4526 - val_loss: 1.0787 - val_acc: 0.9692 - val_mDice: 0.5893

Epoch 00019: val_mDice improved from 0.56357 to 0.58933, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 20/300
 - 16s - loss: 1.6836 - acc: 0.9437 - mDice: 0.4649 - val_loss: 1.0603 - val_acc: 0.9701 - val_mDice: 0.5976

Epoch 00020: val_mDice improved from 0.58933 to 0.59758, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 21/300
 - 16s - loss: 1.6373 - acc: 0.9446 - mDice: 0.4766 - val_loss: 1.0351 - val_acc: 0.9690 - val_mDice: 0.6094

Epoch 00021: val_mDice improved from 0.59758 to 0.60935, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 22/300
 - 16s - loss: 1.5937 - acc: 0.9456 - mDice: 0.4875 - val_loss: 1.0163 - val_acc: 0.9697 - val_mDice: 0.6162

Epoch 00022: val_mDice improved from 0.60935 to 0.61623, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 23/300
 - 16s - loss: 1.5618 - acc: 0.9463 - mDice: 0.4965 - val_loss: 1.0016 - val_acc: 0.9715 - val_mDice: 0.6216

Epoch 00023: val_mDice improved from 0.61623 to 0.62158, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 24/300
 - 15s - loss: 1.5213 - acc: 0.9473 - mDice: 0.5066 - val_loss: 0.9868 - val_acc: 0.9703 - val_mDice: 0.6267

Epoch 00024: val_mDice improved from 0.62158 to 0.62673, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 25/300
 - 16s - loss: 1.4918 - acc: 0.9480 - mDice: 0.5149 - val_loss: 0.9754 - val_acc: 0.9717 - val_mDice: 0.6392

Epoch 00025: val_mDice improved from 0.62673 to 0.63919, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 26/300
 - 15s - loss: 1.4661 - acc: 0.9485 - mDice: 0.5222 - val_loss: 0.9699 - val_acc: 0.9715 - val_mDice: 0.6347

Epoch 00026: val_mDice did not improve from 0.63919
Epoch 27/300
 - 16s - loss: 1.4394 - acc: 0.9491 - mDice: 0.5293 - val_loss: 0.9473 - val_acc: 0.9711 - val_mDice: 0.6432

Epoch 00027: val_mDice improved from 0.63919 to 0.64321, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 28/300
 - 15s - loss: 1.4118 - acc: 0.9498 - mDice: 0.5365 - val_loss: 0.9311 - val_acc: 0.9725 - val_mDice: 0.6508

Epoch 00028: val_mDice improved from 0.64321 to 0.65078, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 29/300
 - 16s - loss: 1.3897 - acc: 0.9504 - mDice: 0.5431 - val_loss: 0.9229 - val_acc: 0.9723 - val_mDice: 0.6519

Epoch 00029: val_mDice improved from 0.65078 to 0.65194, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 30/300
 - 15s - loss: 1.3707 - acc: 0.9507 - mDice: 0.5485 - val_loss: 0.9119 - val_acc: 0.9720 - val_mDice: 0.6583

Epoch 00030: val_mDice improved from 0.65194 to 0.65833, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 31/300
 - 16s - loss: 1.3484 - acc: 0.9513 - mDice: 0.5555 - val_loss: 0.9039 - val_acc: 0.9722 - val_mDice: 0.6656

Epoch 00031: val_mDice improved from 0.65833 to 0.66565, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 32/300
 - 15s - loss: 1.3291 - acc: 0.9517 - mDice: 0.5609 - val_loss: 0.9076 - val_acc: 0.9730 - val_mDice: 0.6648

Epoch 00032: val_mDice did not improve from 0.66565
Epoch 33/300
 - 16s - loss: 1.3143 - acc: 0.9521 - mDice: 0.5656 - val_loss: 0.8683 - val_acc: 0.9736 - val_mDice: 0.6752

Epoch 00033: val_mDice improved from 0.66565 to 0.67519, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 34/300
 - 15s - loss: 1.3019 - acc: 0.9524 - mDice: 0.5698 - val_loss: 0.8755 - val_acc: 0.9733 - val_mDice: 0.6755

Epoch 00034: val_mDice improved from 0.67519 to 0.67547, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 35/300
 - 16s - loss: 1.2862 - acc: 0.9528 - mDice: 0.5747 - val_loss: 0.8839 - val_acc: 0.9728 - val_mDice: 0.6735

Epoch 00035: val_mDice did not improve from 0.67547
Epoch 36/300
 - 15s - loss: 1.2699 - acc: 0.9531 - mDice: 0.5796 - val_loss: 0.8644 - val_acc: 0.9741 - val_mDice: 0.6828

Epoch 00036: val_mDice improved from 0.67547 to 0.68284, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 37/300
 - 17s - loss: 1.2496 - acc: 0.9536 - mDice: 0.5855 - val_loss: 0.8508 - val_acc: 0.9738 - val_mDice: 0.6851

Epoch 00037: val_mDice improved from 0.68284 to 0.68514, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 38/300
 - 15s - loss: 1.2366 - acc: 0.9539 - mDice: 0.5900 - val_loss: 0.8532 - val_acc: 0.9736 - val_mDice: 0.6877

Epoch 00038: val_mDice improved from 0.68514 to 0.68774, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 39/300
 - 17s - loss: 1.2260 - acc: 0.9541 - mDice: 0.5934 - val_loss: 0.8719 - val_acc: 0.9731 - val_mDice: 0.6838

Epoch 00039: val_mDice did not improve from 0.68774
Epoch 40/300
 - 15s - loss: 1.2112 - acc: 0.9544 - mDice: 0.5982 - val_loss: 0.8610 - val_acc: 0.9739 - val_mDice: 0.6849

Epoch 00040: val_mDice did not improve from 0.68774
Epoch 41/300
 - 16s - loss: 1.2035 - acc: 0.9546 - mDice: 0.6004 - val_loss: 0.8338 - val_acc: 0.9746 - val_mDice: 0.6969

Epoch 00041: val_mDice improved from 0.68774 to 0.69694, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 42/300
 - 15s - loss: 1.1952 - acc: 0.9548 - mDice: 0.6033 - val_loss: 0.8520 - val_acc: 0.9739 - val_mDice: 0.6945

Epoch 00042: val_mDice did not improve from 0.69694
Epoch 43/300
 - 16s - loss: 1.1808 - acc: 0.9553 - mDice: 0.6080 - val_loss: 0.8360 - val_acc: 0.9753 - val_mDice: 0.6986

Epoch 00043: val_mDice improved from 0.69694 to 0.69855, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 44/300
 - 15s - loss: 1.1664 - acc: 0.9556 - mDice: 0.6123 - val_loss: 0.8247 - val_acc: 0.9750 - val_mDice: 0.7030

Epoch 00044: val_mDice improved from 0.69855 to 0.70296, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 45/300
 - 16s - loss: 1.1624 - acc: 0.9557 - mDice: 0.6143 - val_loss: 0.8360 - val_acc: 0.9749 - val_mDice: 0.6973

Epoch 00045: val_mDice did not improve from 0.70296
Epoch 46/300
 - 15s - loss: 1.1513 - acc: 0.9559 - mDice: 0.6172 - val_loss: 0.8220 - val_acc: 0.9751 - val_mDice: 0.7029

Epoch 00046: val_mDice did not improve from 0.70296
Epoch 47/300
 - 16s - loss: 1.1395 - acc: 0.9562 - mDice: 0.6210 - val_loss: 0.8249 - val_acc: 0.9750 - val_mDice: 0.7034

Epoch 00047: val_mDice improved from 0.70296 to 0.70344, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 48/300
 - 15s - loss: 1.1329 - acc: 0.9564 - mDice: 0.6231 - val_loss: 0.8194 - val_acc: 0.9752 - val_mDice: 0.7030

Epoch 00048: val_mDice did not improve from 0.70344
Epoch 49/300
 - 16s - loss: 1.1257 - acc: 0.9565 - mDice: 0.6251 - val_loss: 0.8025 - val_acc: 0.9748 - val_mDice: 0.7109

Epoch 00049: val_mDice improved from 0.70344 to 0.71087, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 50/300
 - 15s - loss: 1.1211 - acc: 0.9567 - mDice: 0.6268 - val_loss: 0.8201 - val_acc: 0.9745 - val_mDice: 0.7032

Epoch 00050: val_mDice did not improve from 0.71087
Epoch 51/300
 - 16s - loss: 1.1118 - acc: 0.9569 - mDice: 0.6296 - val_loss: 0.8130 - val_acc: 0.9761 - val_mDice: 0.7031

Epoch 00051: val_mDice did not improve from 0.71087
Epoch 52/300
 - 15s - loss: 1.1075 - acc: 0.9570 - mDice: 0.6314 - val_loss: 0.8210 - val_acc: 0.9758 - val_mDice: 0.7091

Epoch 00052: val_mDice did not improve from 0.71087
Epoch 53/300
 - 16s - loss: 1.0999 - acc: 0.9571 - mDice: 0.6330 - val_loss: 0.7963 - val_acc: 0.9762 - val_mDice: 0.7097

Epoch 00053: val_mDice did not improve from 0.71087
Epoch 54/300
 - 15s - loss: 1.0959 - acc: 0.9572 - mDice: 0.6349 - val_loss: 0.7974 - val_acc: 0.9760 - val_mDice: 0.7098

Epoch 00054: val_mDice did not improve from 0.71087
Epoch 55/300
 - 17s - loss: 1.0883 - acc: 0.9573 - mDice: 0.6368 - val_loss: 0.7953 - val_acc: 0.9753 - val_mDice: 0.7193

Epoch 00055: val_mDice improved from 0.71087 to 0.71926, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 56/300
 - 15s - loss: 1.0804 - acc: 0.9574 - mDice: 0.6391 - val_loss: 0.8099 - val_acc: 0.9760 - val_mDice: 0.7109

Epoch 00056: val_mDice did not improve from 0.71926
Epoch 57/300
 - 17s - loss: 1.0771 - acc: 0.9576 - mDice: 0.6405 - val_loss: 0.7882 - val_acc: 0.9755 - val_mDice: 0.7163

Epoch 00057: val_mDice did not improve from 0.71926
Epoch 58/300
 - 16s - loss: 1.0753 - acc: 0.9575 - mDice: 0.6412 - val_loss: 0.7868 - val_acc: 0.9753 - val_mDice: 0.7161

Epoch 00058: val_mDice did not improve from 0.71926
Epoch 59/300
 - 16s - loss: 1.0670 - acc: 0.9577 - mDice: 0.6439 - val_loss: 0.7969 - val_acc: 0.9765 - val_mDice: 0.7117

Epoch 00059: val_mDice did not improve from 0.71926
Epoch 60/300
 - 16s - loss: 1.0642 - acc: 0.9577 - mDice: 0.6443 - val_loss: 0.7965 - val_acc: 0.9764 - val_mDice: 0.7104

Epoch 00060: val_mDice did not improve from 0.71926
Epoch 61/300
 - 16s - loss: 1.0591 - acc: 0.9578 - mDice: 0.6464 - val_loss: 0.7987 - val_acc: 0.9761 - val_mDice: 0.7189

Epoch 00061: val_mDice did not improve from 0.71926
Epoch 62/300
 - 16s - loss: 1.0564 - acc: 0.9577 - mDice: 0.6467 - val_loss: 0.8006 - val_acc: 0.9761 - val_mDice: 0.7134

Epoch 00062: val_mDice did not improve from 0.71926
Epoch 63/300
 - 16s - loss: 1.0526 - acc: 0.9578 - mDice: 0.6479 - val_loss: 0.7955 - val_acc: 0.9761 - val_mDice: 0.7187

Epoch 00063: val_mDice did not improve from 0.71926
Epoch 64/300
 - 16s - loss: 1.0506 - acc: 0.9579 - mDice: 0.6490 - val_loss: 0.7788 - val_acc: 0.9764 - val_mDice: 0.7195

Epoch 00064: val_mDice improved from 0.71926 to 0.71952, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 65/300
 - 16s - loss: 1.0452 - acc: 0.9579 - mDice: 0.6499 - val_loss: 0.7920 - val_acc: 0.9763 - val_mDice: 0.7220

Epoch 00065: val_mDice improved from 0.71952 to 0.72202, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 66/300
 - 16s - loss: 1.0418 - acc: 0.9580 - mDice: 0.6514 - val_loss: 0.7738 - val_acc: 0.9764 - val_mDice: 0.7227

Epoch 00066: val_mDice improved from 0.72202 to 0.72272, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 67/300
 - 16s - loss: 1.0392 - acc: 0.9581 - mDice: 0.6522 - val_loss: 0.7782 - val_acc: 0.9762 - val_mDice: 0.7206

Epoch 00067: val_mDice did not improve from 0.72272
Epoch 68/300
 - 16s - loss: 1.0356 - acc: 0.9581 - mDice: 0.6532 - val_loss: 0.7936 - val_acc: 0.9756 - val_mDice: 0.7161

Epoch 00068: val_mDice did not improve from 0.72272
Epoch 69/300
 - 17s - loss: 1.0325 - acc: 0.9581 - mDice: 0.6539 - val_loss: 0.7749 - val_acc: 0.9769 - val_mDice: 0.7173

Epoch 00069: val_mDice did not improve from 0.72272
Epoch 70/300
 - 15s - loss: 1.0270 - acc: 0.9582 - mDice: 0.6557 - val_loss: 0.7880 - val_acc: 0.9758 - val_mDice: 0.7222

Epoch 00070: val_mDice did not improve from 0.72272
Epoch 71/300
 - 16s - loss: 1.0259 - acc: 0.9582 - mDice: 0.6561 - val_loss: 0.7678 - val_acc: 0.9768 - val_mDice: 0.7223

Epoch 00071: val_mDice did not improve from 0.72272
Epoch 72/300
 - 16s - loss: 1.0210 - acc: 0.9583 - mDice: 0.6578 - val_loss: 0.7870 - val_acc: 0.9763 - val_mDice: 0.7203

Epoch 00072: val_mDice did not improve from 0.72272
Epoch 73/300
 - 16s - loss: 1.0209 - acc: 0.9583 - mDice: 0.6578 - val_loss: 0.7748 - val_acc: 0.9758 - val_mDice: 0.7272

Epoch 00073: val_mDice improved from 0.72272 to 0.72722, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 74/300
 - 18s - loss: 1.0201 - acc: 0.9583 - mDice: 0.6582 - val_loss: 0.7720 - val_acc: 0.9764 - val_mDice: 0.7220

Epoch 00074: val_mDice did not improve from 0.72722
Epoch 75/300
 - 15s - loss: 1.0162 - acc: 0.9584 - mDice: 0.6591 - val_loss: 0.7832 - val_acc: 0.9764 - val_mDice: 0.7199

Epoch 00075: val_mDice did not improve from 0.72722
Epoch 76/300
 - 17s - loss: 1.0159 - acc: 0.9584 - mDice: 0.6596 - val_loss: 0.7756 - val_acc: 0.9762 - val_mDice: 0.7199

Epoch 00076: val_mDice did not improve from 0.72722
Epoch 77/300
 - 16s - loss: 1.0133 - acc: 0.9584 - mDice: 0.6604 - val_loss: 0.7723 - val_acc: 0.9758 - val_mDice: 0.7234

Epoch 00077: val_mDice did not improve from 0.72722
Epoch 78/300
 - 18s - loss: 1.0103 - acc: 0.9585 - mDice: 0.6612 - val_loss: 0.7706 - val_acc: 0.9770 - val_mDice: 0.7274

Epoch 00078: val_mDice improved from 0.72722 to 0.72743, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 79/300
 - 16s - loss: 1.0086 - acc: 0.9585 - mDice: 0.6613 - val_loss: 0.7797 - val_acc: 0.9760 - val_mDice: 0.7211

Epoch 00079: val_mDice did not improve from 0.72743
Epoch 80/300
 - 17s - loss: 1.0068 - acc: 0.9585 - mDice: 0.6620 - val_loss: 0.7759 - val_acc: 0.9768 - val_mDice: 0.7244

Epoch 00080: val_mDice did not improve from 0.72743
Epoch 81/300
 - 16s - loss: 1.0048 - acc: 0.9585 - mDice: 0.6628 - val_loss: 0.7847 - val_acc: 0.9764 - val_mDice: 0.7193

Epoch 00081: val_mDice did not improve from 0.72743
Epoch 82/300
 - 17s - loss: 1.0041 - acc: 0.9585 - mDice: 0.6629 - val_loss: 0.7606 - val_acc: 0.9770 - val_mDice: 0.7257

Epoch 00082: val_mDice did not improve from 0.72743
Epoch 83/300
 - 16s - loss: 1.0001 - acc: 0.9586 - mDice: 0.6642 - val_loss: 0.7706 - val_acc: 0.9772 - val_mDice: 0.7282

Epoch 00083: val_mDice improved from 0.72743 to 0.72821, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 84/300
 - 18s - loss: 0.9962 - acc: 0.9587 - mDice: 0.6657 - val_loss: 0.7622 - val_acc: 0.9770 - val_mDice: 0.7230

Epoch 00084: val_mDice did not improve from 0.72821
Epoch 85/300
 - 16s - loss: 0.9937 - acc: 0.9588 - mDice: 0.6661 - val_loss: 0.7566 - val_acc: 0.9772 - val_mDice: 0.7269

Epoch 00085: val_mDice did not improve from 0.72821
Epoch 86/300
 - 20s - loss: 0.9952 - acc: 0.9588 - mDice: 0.6656 - val_loss: 0.7635 - val_acc: 0.9767 - val_mDice: 0.7274

Epoch 00086: val_mDice did not improve from 0.72821
Epoch 87/300
 - 18s - loss: 0.9913 - acc: 0.9588 - mDice: 0.6666 - val_loss: 0.7570 - val_acc: 0.9768 - val_mDice: 0.7328

Epoch 00087: val_mDice improved from 0.72821 to 0.73282, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 88/300
 - 21s - loss: 0.9908 - acc: 0.9589 - mDice: 0.6671 - val_loss: 0.7630 - val_acc: 0.9768 - val_mDice: 0.7304

Epoch 00088: val_mDice did not improve from 0.73282
Epoch 89/300
 - 17s - loss: 0.9913 - acc: 0.9589 - mDice: 0.6671 - val_loss: 0.7714 - val_acc: 0.9765 - val_mDice: 0.7214

Epoch 00089: val_mDice did not improve from 0.73282
Epoch 90/300
 - 18s - loss: 0.9929 - acc: 0.9588 - mDice: 0.6666 - val_loss: 0.7700 - val_acc: 0.9769 - val_mDice: 0.7276

Epoch 00090: val_mDice did not improve from 0.73282
Epoch 91/300
 - 16s - loss: 0.9897 - acc: 0.9590 - mDice: 0.6675 - val_loss: 0.7626 - val_acc: 0.9761 - val_mDice: 0.7265

Epoch 00091: val_mDice did not improve from 0.73282
Epoch 92/300
 - 17s - loss: 0.9841 - acc: 0.9591 - mDice: 0.6689 - val_loss: 0.7560 - val_acc: 0.9772 - val_mDice: 0.7280

Epoch 00092: val_mDice did not improve from 0.73282
Epoch 93/300
 - 17s - loss: 0.9847 - acc: 0.9590 - mDice: 0.6688 - val_loss: 0.7675 - val_acc: 0.9769 - val_mDice: 0.7239

Epoch 00093: val_mDice did not improve from 0.73282
Epoch 94/300
 - 15s - loss: 0.9828 - acc: 0.9591 - mDice: 0.6699 - val_loss: 0.7822 - val_acc: 0.9768 - val_mDice: 0.7238

Epoch 00094: val_mDice did not improve from 0.73282
Epoch 95/300
 - 18s - loss: 0.9843 - acc: 0.9590 - mDice: 0.6691 - val_loss: 0.7547 - val_acc: 0.9767 - val_mDice: 0.7286

Epoch 00095: val_mDice did not improve from 0.73282
Epoch 96/300
 - 16s - loss: 0.9810 - acc: 0.9591 - mDice: 0.6702 - val_loss: 0.7639 - val_acc: 0.9755 - val_mDice: 0.7262

Epoch 00096: val_mDice did not improve from 0.73282
Epoch 97/300
 - 17s - loss: 0.9829 - acc: 0.9591 - mDice: 0.6697 - val_loss: 0.7655 - val_acc: 0.9771 - val_mDice: 0.7281

Epoch 00097: val_mDice did not improve from 0.73282
Epoch 98/300
 - 17s - loss: 0.9803 - acc: 0.9592 - mDice: 0.6705 - val_loss: 0.7557 - val_acc: 0.9769 - val_mDice: 0.7339

Epoch 00098: val_mDice improved from 0.73282 to 0.73388, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 99/300
 - 17s - loss: 0.9754 - acc: 0.9593 - mDice: 0.6716 - val_loss: 0.7586 - val_acc: 0.9768 - val_mDice: 0.7327

Epoch 00099: val_mDice did not improve from 0.73388
Epoch 100/300
 - 23s - loss: 0.9750 - acc: 0.9593 - mDice: 0.6718 - val_loss: 0.7658 - val_acc: 0.9768 - val_mDice: 0.7240

Epoch 00100: val_mDice did not improve from 0.73388
Epoch 101/300
 - 21s - loss: 0.9762 - acc: 0.9593 - mDice: 0.6714 - val_loss: 0.7561 - val_acc: 0.9775 - val_mDice: 0.7274

Epoch 00101: val_mDice did not improve from 0.73388
Epoch 102/300
 - 24s - loss: 0.9727 - acc: 0.9594 - mDice: 0.6727 - val_loss: 0.7543 - val_acc: 0.9765 - val_mDice: 0.7302

Epoch 00102: val_mDice did not improve from 0.73388
Epoch 103/300
 - 21s - loss: 0.9700 - acc: 0.9595 - mDice: 0.6732 - val_loss: 0.7561 - val_acc: 0.9766 - val_mDice: 0.7287

Epoch 00103: val_mDice did not improve from 0.73388
Epoch 104/300
 - 19s - loss: 0.9731 - acc: 0.9594 - mDice: 0.6727 - val_loss: 0.7540 - val_acc: 0.9769 - val_mDice: 0.7306

Epoch 00104: val_mDice did not improve from 0.73388
Epoch 105/300
 - 15s - loss: 0.9700 - acc: 0.9595 - mDice: 0.6737 - val_loss: 0.7468 - val_acc: 0.9768 - val_mDice: 0.7297

Epoch 00105: val_mDice did not improve from 0.73388
Epoch 106/300
 - 16s - loss: 0.9681 - acc: 0.9595 - mDice: 0.6741 - val_loss: 0.7554 - val_acc: 0.9774 - val_mDice: 0.7269

Epoch 00106: val_mDice did not improve from 0.73388
Epoch 107/300
 - 17s - loss: 0.9694 - acc: 0.9595 - mDice: 0.6738 - val_loss: 0.7526 - val_acc: 0.9763 - val_mDice: 0.7326

Epoch 00107: val_mDice did not improve from 0.73388
Epoch 108/300
 - 17s - loss: 0.9669 - acc: 0.9596 - mDice: 0.6745 - val_loss: 0.7586 - val_acc: 0.9771 - val_mDice: 0.7267

Epoch 00108: val_mDice did not improve from 0.73388
Epoch 109/300
 - 20s - loss: 0.9678 - acc: 0.9596 - mDice: 0.6744 - val_loss: 0.7524 - val_acc: 0.9766 - val_mDice: 0.7318

Epoch 00109: val_mDice did not improve from 0.73388
Epoch 110/300
 - 18s - loss: 0.9651 - acc: 0.9596 - mDice: 0.6751 - val_loss: 0.7481 - val_acc: 0.9774 - val_mDice: 0.7346

Epoch 00110: val_mDice improved from 0.73388 to 0.73456, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 111/300
 - 17s - loss: 0.9675 - acc: 0.9596 - mDice: 0.6744 - val_loss: 0.7459 - val_acc: 0.9766 - val_mDice: 0.7311

Epoch 00111: val_mDice did not improve from 0.73456
Epoch 112/300
 - 16s - loss: 0.9617 - acc: 0.9597 - mDice: 0.6761 - val_loss: 0.7441 - val_acc: 0.9770 - val_mDice: 0.7337

Epoch 00112: val_mDice did not improve from 0.73456
Epoch 113/300
 - 16s - loss: 0.9622 - acc: 0.9597 - mDice: 0.6763 - val_loss: 0.7374 - val_acc: 0.9771 - val_mDice: 0.7316

Epoch 00113: val_mDice did not improve from 0.73456
Epoch 114/300
 - 18s - loss: 0.9604 - acc: 0.9597 - mDice: 0.6766 - val_loss: 0.7625 - val_acc: 0.9767 - val_mDice: 0.7299

Epoch 00114: val_mDice did not improve from 0.73456
Epoch 115/300
 - 18s - loss: 0.9611 - acc: 0.9597 - mDice: 0.6762 - val_loss: 0.7418 - val_acc: 0.9771 - val_mDice: 0.7376

Epoch 00115: val_mDice improved from 0.73456 to 0.73762, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 116/300
 - 23s - loss: 0.9577 - acc: 0.9598 - mDice: 0.6776 - val_loss: 0.7504 - val_acc: 0.9772 - val_mDice: 0.7339

Epoch 00116: val_mDice did not improve from 0.73762
Epoch 117/300
 - 16s - loss: 0.9581 - acc: 0.9598 - mDice: 0.6774 - val_loss: 0.7608 - val_acc: 0.9772 - val_mDice: 0.7307

Epoch 00117: val_mDice did not improve from 0.73762
Epoch 118/300
 - 17s - loss: 0.9566 - acc: 0.9598 - mDice: 0.6778 - val_loss: 0.7483 - val_acc: 0.9766 - val_mDice: 0.7339

Epoch 00118: val_mDice did not improve from 0.73762
Epoch 119/300
 - 15s - loss: 0.9554 - acc: 0.9599 - mDice: 0.6780 - val_loss: 0.7500 - val_acc: 0.9769 - val_mDice: 0.7352

Epoch 00119: val_mDice did not improve from 0.73762
Epoch 120/300
 - 17s - loss: 0.9552 - acc: 0.9599 - mDice: 0.6780 - val_loss: 0.7544 - val_acc: 0.9773 - val_mDice: 0.7350

Epoch 00120: val_mDice did not improve from 0.73762
Epoch 121/300
 - 16s - loss: 0.9523 - acc: 0.9600 - mDice: 0.6789 - val_loss: 0.7597 - val_acc: 0.9772 - val_mDice: 0.7324

Epoch 00121: val_mDice did not improve from 0.73762
Epoch 122/300
 - 17s - loss: 0.9532 - acc: 0.9600 - mDice: 0.6788 - val_loss: 0.7562 - val_acc: 0.9767 - val_mDice: 0.7314

Epoch 00122: val_mDice did not improve from 0.73762
Epoch 123/300
 - 16s - loss: 0.9527 - acc: 0.9599 - mDice: 0.6792 - val_loss: 0.7474 - val_acc: 0.9765 - val_mDice: 0.7382

Epoch 00123: val_mDice improved from 0.73762 to 0.73816, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 124/300
 - 17s - loss: 0.9533 - acc: 0.9599 - mDice: 0.6790 - val_loss: 0.7614 - val_acc: 0.9772 - val_mDice: 0.7321

Epoch 00124: val_mDice did not improve from 0.73816
Epoch 125/300
 - 16s - loss: 0.9505 - acc: 0.9600 - mDice: 0.6796 - val_loss: 0.7486 - val_acc: 0.9768 - val_mDice: 0.7355

Epoch 00125: val_mDice did not improve from 0.73816
Epoch 126/300
 - 17s - loss: 0.9513 - acc: 0.9600 - mDice: 0.6798 - val_loss: 0.7453 - val_acc: 0.9768 - val_mDice: 0.7381

Epoch 00126: val_mDice did not improve from 0.73816
Epoch 127/300
 - 16s - loss: 0.9485 - acc: 0.9600 - mDice: 0.6804 - val_loss: 0.7506 - val_acc: 0.9764 - val_mDice: 0.7412

Epoch 00127: val_mDice improved from 0.73816 to 0.74120, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 128/300
 - 17s - loss: 0.9501 - acc: 0.9600 - mDice: 0.6805 - val_loss: 0.7501 - val_acc: 0.9772 - val_mDice: 0.7361

Epoch 00128: val_mDice did not improve from 0.74120
Epoch 129/300
 - 16s - loss: 0.9508 - acc: 0.9600 - mDice: 0.6797 - val_loss: 0.7420 - val_acc: 0.9772 - val_mDice: 0.7395

Epoch 00129: val_mDice did not improve from 0.74120
Epoch 130/300
 - 17s - loss: 0.9488 - acc: 0.9600 - mDice: 0.6806 - val_loss: 0.7539 - val_acc: 0.9772 - val_mDice: 0.7354

Epoch 00130: val_mDice did not improve from 0.74120
Epoch 131/300
 - 16s - loss: 0.9451 - acc: 0.9601 - mDice: 0.6815 - val_loss: 0.7427 - val_acc: 0.9771 - val_mDice: 0.7359

Epoch 00131: val_mDice did not improve from 0.74120
Epoch 132/300
 - 17s - loss: 0.9460 - acc: 0.9601 - mDice: 0.6812 - val_loss: 0.7437 - val_acc: 0.9772 - val_mDice: 0.7355

Epoch 00132: val_mDice did not improve from 0.74120
Epoch 133/300
 - 17s - loss: 0.9460 - acc: 0.9601 - mDice: 0.6816 - val_loss: 0.7402 - val_acc: 0.9773 - val_mDice: 0.7393

Epoch 00133: val_mDice did not improve from 0.74120
Epoch 134/300
 - 17s - loss: 0.9471 - acc: 0.9601 - mDice: 0.6811 - val_loss: 0.7398 - val_acc: 0.9774 - val_mDice: 0.7419

Epoch 00134: val_mDice improved from 0.74120 to 0.74192, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 135/300
 - 17s - loss: 0.9437 - acc: 0.9602 - mDice: 0.6822 - val_loss: 0.7557 - val_acc: 0.9775 - val_mDice: 0.7383

Epoch 00135: val_mDice did not improve from 0.74192
Epoch 136/300
 - 16s - loss: 0.9441 - acc: 0.9602 - mDice: 0.6819 - val_loss: 0.7431 - val_acc: 0.9769 - val_mDice: 0.7376

Epoch 00136: val_mDice did not improve from 0.74192
Epoch 137/300
 - 17s - loss: 0.9412 - acc: 0.9602 - mDice: 0.6830 - val_loss: 0.7324 - val_acc: 0.9773 - val_mDice: 0.7380

Epoch 00137: val_mDice did not improve from 0.74192
Epoch 138/300
 - 16s - loss: 0.9412 - acc: 0.9602 - mDice: 0.6824 - val_loss: 0.7434 - val_acc: 0.9771 - val_mDice: 0.7377

Epoch 00138: val_mDice did not improve from 0.74192
Epoch 139/300
 - 17s - loss: 0.9407 - acc: 0.9603 - mDice: 0.6832 - val_loss: 0.7331 - val_acc: 0.9774 - val_mDice: 0.7398

Epoch 00139: val_mDice did not improve from 0.74192
Epoch 140/300
 - 16s - loss: 0.9397 - acc: 0.9603 - mDice: 0.6833 - val_loss: 0.7445 - val_acc: 0.9775 - val_mDice: 0.7399

Epoch 00140: val_mDice did not improve from 0.74192
Epoch 141/300
 - 17s - loss: 0.9402 - acc: 0.9603 - mDice: 0.6831 - val_loss: 0.7374 - val_acc: 0.9773 - val_mDice: 0.7407

Epoch 00141: val_mDice did not improve from 0.74192
Epoch 142/300
 - 16s - loss: 0.9370 - acc: 0.9604 - mDice: 0.6842 - val_loss: 0.7285 - val_acc: 0.9777 - val_mDice: 0.7404

Epoch 00142: val_mDice did not improve from 0.74192
Epoch 143/300
 - 17s - loss: 0.9400 - acc: 0.9602 - mDice: 0.6834 - val_loss: 0.7424 - val_acc: 0.9776 - val_mDice: 0.7412

Epoch 00143: val_mDice did not improve from 0.74192
Epoch 144/300
 - 16s - loss: 0.9351 - acc: 0.9604 - mDice: 0.6848 - val_loss: 0.7393 - val_acc: 0.9777 - val_mDice: 0.7379

Epoch 00144: val_mDice did not improve from 0.74192
Epoch 145/300
 - 17s - loss: 0.9379 - acc: 0.9604 - mDice: 0.6838 - val_loss: 0.7338 - val_acc: 0.9775 - val_mDice: 0.7372

Epoch 00145: val_mDice did not improve from 0.74192
Epoch 146/300
 - 16s - loss: 0.9359 - acc: 0.9603 - mDice: 0.6845 - val_loss: 0.7431 - val_acc: 0.9773 - val_mDice: 0.7332

Epoch 00146: val_mDice did not improve from 0.74192
Epoch 147/300
 - 17s - loss: 0.9374 - acc: 0.9604 - mDice: 0.6843 - val_loss: 0.7367 - val_acc: 0.9768 - val_mDice: 0.7397

Epoch 00147: val_mDice did not improve from 0.74192
Epoch 148/300
 - 16s - loss: 0.9353 - acc: 0.9604 - mDice: 0.6852 - val_loss: 0.7366 - val_acc: 0.9775 - val_mDice: 0.7409

Epoch 00148: val_mDice did not improve from 0.74192
Epoch 149/300
 - 18s - loss: 0.9334 - acc: 0.9605 - mDice: 0.6854 - val_loss: 0.7304 - val_acc: 0.9779 - val_mDice: 0.7377

Epoch 00149: val_mDice did not improve from 0.74192
Epoch 150/300
 - 17s - loss: 0.9332 - acc: 0.9605 - mDice: 0.6856 - val_loss: 0.7431 - val_acc: 0.9773 - val_mDice: 0.7355

Epoch 00150: val_mDice did not improve from 0.74192
Epoch 151/300
 - 17s - loss: 0.9337 - acc: 0.9604 - mDice: 0.6853 - val_loss: 0.7371 - val_acc: 0.9770 - val_mDice: 0.7393

Epoch 00151: val_mDice did not improve from 0.74192
Epoch 152/300
 - 16s - loss: 0.9320 - acc: 0.9605 - mDice: 0.6857 - val_loss: 0.7383 - val_acc: 0.9773 - val_mDice: 0.7409

Epoch 00152: val_mDice did not improve from 0.74192
Epoch 153/300
 - 18s - loss: 0.9320 - acc: 0.9605 - mDice: 0.6859 - val_loss: 0.7351 - val_acc: 0.9781 - val_mDice: 0.7389

Epoch 00153: val_mDice did not improve from 0.74192
Epoch 154/300
 - 16s - loss: 0.9306 - acc: 0.9605 - mDice: 0.6859 - val_loss: 0.7345 - val_acc: 0.9774 - val_mDice: 0.7387

Epoch 00154: val_mDice did not improve from 0.74192
Epoch 155/300
 - 18s - loss: 0.9297 - acc: 0.9605 - mDice: 0.6866 - val_loss: 0.7411 - val_acc: 0.9763 - val_mDice: 0.7378

Epoch 00155: val_mDice did not improve from 0.74192
Epoch 156/300
 - 16s - loss: 0.9294 - acc: 0.9606 - mDice: 0.6866 - val_loss: 0.7315 - val_acc: 0.9775 - val_mDice: 0.7405

Epoch 00156: val_mDice did not improve from 0.74192
Epoch 157/300
 - 18s - loss: 0.9349 - acc: 0.9605 - mDice: 0.6851 - val_loss: 0.7340 - val_acc: 0.9776 - val_mDice: 0.7424

Epoch 00157: val_mDice improved from 0.74192 to 0.74236, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 158/300
 - 16s - loss: 0.9306 - acc: 0.9605 - mDice: 0.6863 - val_loss: 0.7410 - val_acc: 0.9778 - val_mDice: 0.7376

Epoch 00158: val_mDice did not improve from 0.74236
Epoch 159/300
 - 18s - loss: 0.9296 - acc: 0.9606 - mDice: 0.6867 - val_loss: 0.7433 - val_acc: 0.9768 - val_mDice: 0.7372

Epoch 00159: val_mDice did not improve from 0.74236
Epoch 160/300
 - 15s - loss: 0.9309 - acc: 0.9605 - mDice: 0.6863 - val_loss: 0.7348 - val_acc: 0.9781 - val_mDice: 0.7395

Epoch 00160: val_mDice did not improve from 0.74236
Epoch 161/300
 - 18s - loss: 0.9290 - acc: 0.9606 - mDice: 0.6868 - val_loss: 0.7238 - val_acc: 0.9779 - val_mDice: 0.7458

Epoch 00161: val_mDice improved from 0.74236 to 0.74578, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 162/300
 - 16s - loss: 0.9249 - acc: 0.9607 - mDice: 0.6878 - val_loss: 0.7299 - val_acc: 0.9778 - val_mDice: 0.7391

Epoch 00162: val_mDice did not improve from 0.74578
Epoch 163/300
 - 16s - loss: 0.9267 - acc: 0.9606 - mDice: 0.6875 - val_loss: 0.7268 - val_acc: 0.9769 - val_mDice: 0.7456

Epoch 00163: val_mDice did not improve from 0.74578
Epoch 164/300
 - 16s - loss: 0.9250 - acc: 0.9607 - mDice: 0.6880 - val_loss: 0.7245 - val_acc: 0.9780 - val_mDice: 0.7453

Epoch 00164: val_mDice did not improve from 0.74578
Epoch 165/300
 - 16s - loss: 0.9249 - acc: 0.9607 - mDice: 0.6882 - val_loss: 0.7332 - val_acc: 0.9769 - val_mDice: 0.7400

Epoch 00165: val_mDice did not improve from 0.74578
Epoch 166/300
 - 16s - loss: 0.9251 - acc: 0.9607 - mDice: 0.6881 - val_loss: 0.7230 - val_acc: 0.9777 - val_mDice: 0.7431

Epoch 00166: val_mDice did not improve from 0.74578
Epoch 167/300
 - 15s - loss: 0.9250 - acc: 0.9607 - mDice: 0.6879 - val_loss: 0.7332 - val_acc: 0.9771 - val_mDice: 0.7426

Epoch 00167: val_mDice did not improve from 0.74578
Epoch 168/300
 - 17s - loss: 0.9254 - acc: 0.9607 - mDice: 0.6880 - val_loss: 0.7269 - val_acc: 0.9779 - val_mDice: 0.7453

Epoch 00168: val_mDice did not improve from 0.74578
Epoch 169/300
 - 15s - loss: 0.9252 - acc: 0.9607 - mDice: 0.6883 - val_loss: 0.7341 - val_acc: 0.9771 - val_mDice: 0.7363

Epoch 00169: val_mDice did not improve from 0.74578
Epoch 170/300
 - 17s - loss: 0.9213 - acc: 0.9608 - mDice: 0.6893 - val_loss: 0.7260 - val_acc: 0.9779 - val_mDice: 0.7417

Epoch 00170: val_mDice did not improve from 0.74578
Epoch 171/300
 - 15s - loss: 0.9229 - acc: 0.9607 - mDice: 0.6888 - val_loss: 0.7360 - val_acc: 0.9780 - val_mDice: 0.7428

Epoch 00171: val_mDice did not improve from 0.74578
Epoch 172/300
 - 16s - loss: 0.9218 - acc: 0.9608 - mDice: 0.6890 - val_loss: 0.7275 - val_acc: 0.9776 - val_mDice: 0.7422

Epoch 00172: val_mDice did not improve from 0.74578
Epoch 173/300
 - 16s - loss: 0.9227 - acc: 0.9608 - mDice: 0.6891 - val_loss: 0.7279 - val_acc: 0.9774 - val_mDice: 0.7418

Epoch 00173: val_mDice did not improve from 0.74578
Epoch 174/300
 - 15s - loss: 0.9212 - acc: 0.9608 - mDice: 0.6893 - val_loss: 0.7285 - val_acc: 0.9777 - val_mDice: 0.7426

Epoch 00174: val_mDice did not improve from 0.74578
Epoch 175/300
 - 16s - loss: 0.9217 - acc: 0.9608 - mDice: 0.6890 - val_loss: 0.7310 - val_acc: 0.9778 - val_mDice: 0.7394

Epoch 00175: val_mDice did not improve from 0.74578
Epoch 176/300
 - 15s - loss: 0.9214 - acc: 0.9608 - mDice: 0.6892 - val_loss: 0.7390 - val_acc: 0.9775 - val_mDice: 0.7405

Epoch 00176: val_mDice did not improve from 0.74578
Epoch 177/300
 - 16s - loss: 0.9198 - acc: 0.9608 - mDice: 0.6897 - val_loss: 0.7269 - val_acc: 0.9779 - val_mDice: 0.7427

Epoch 00177: val_mDice did not improve from 0.74578
Epoch 178/300
 - 16s - loss: 0.9197 - acc: 0.9608 - mDice: 0.6898 - val_loss: 0.7244 - val_acc: 0.9774 - val_mDice: 0.7429

Epoch 00178: val_mDice did not improve from 0.74578
Epoch 179/300
 - 15s - loss: 0.9190 - acc: 0.9608 - mDice: 0.6901 - val_loss: 0.7262 - val_acc: 0.9773 - val_mDice: 0.7425

Epoch 00179: val_mDice did not improve from 0.74578
Epoch 180/300
 - 15s - loss: 0.9172 - acc: 0.9609 - mDice: 0.6904 - val_loss: 0.7214 - val_acc: 0.9773 - val_mDice: 0.7488

Epoch 00180: val_mDice improved from 0.74578 to 0.74876, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 181/300
 - 15s - loss: 0.9197 - acc: 0.9608 - mDice: 0.6900 - val_loss: 0.7311 - val_acc: 0.9780 - val_mDice: 0.7403

Epoch 00181: val_mDice did not improve from 0.74876
Epoch 182/300
 - 16s - loss: 0.9165 - acc: 0.9610 - mDice: 0.6908 - val_loss: 0.7290 - val_acc: 0.9780 - val_mDice: 0.7453

Epoch 00182: val_mDice did not improve from 0.74876
Epoch 183/300
 - 15s - loss: 0.9191 - acc: 0.9609 - mDice: 0.6902 - val_loss: 0.7322 - val_acc: 0.9776 - val_mDice: 0.7429

Epoch 00183: val_mDice did not improve from 0.74876
Epoch 184/300
 - 15s - loss: 0.9175 - acc: 0.9609 - mDice: 0.6905 - val_loss: 0.7341 - val_acc: 0.9769 - val_mDice: 0.7427

Epoch 00184: val_mDice did not improve from 0.74876
Epoch 185/300
 - 15s - loss: 0.9160 - acc: 0.9609 - mDice: 0.6909 - val_loss: 0.7262 - val_acc: 0.9780 - val_mDice: 0.7445

Epoch 00185: val_mDice did not improve from 0.74876
Epoch 186/300
 - 16s - loss: 0.9155 - acc: 0.9609 - mDice: 0.6913 - val_loss: 0.7220 - val_acc: 0.9779 - val_mDice: 0.7481

Epoch 00186: val_mDice did not improve from 0.74876
Epoch 187/300
 - 16s - loss: 0.9164 - acc: 0.9609 - mDice: 0.6909 - val_loss: 0.7244 - val_acc: 0.9780 - val_mDice: 0.7477

Epoch 00187: val_mDice did not improve from 0.74876
Epoch 188/300
 - 17s - loss: 0.9152 - acc: 0.9610 - mDice: 0.6913 - val_loss: 0.7277 - val_acc: 0.9772 - val_mDice: 0.7437

Epoch 00188: val_mDice did not improve from 0.74876
Epoch 189/300
 - 15s - loss: 0.9161 - acc: 0.9610 - mDice: 0.6909 - val_loss: 0.7299 - val_acc: 0.9780 - val_mDice: 0.7429

Epoch 00189: val_mDice did not improve from 0.74876
Epoch 190/300
 - 17s - loss: 0.9146 - acc: 0.9610 - mDice: 0.6912 - val_loss: 0.7244 - val_acc: 0.9777 - val_mDice: 0.7428

Epoch 00190: val_mDice did not improve from 0.74876
Epoch 191/300
 - 15s - loss: 0.9129 - acc: 0.9610 - mDice: 0.6921 - val_loss: 0.7237 - val_acc: 0.9774 - val_mDice: 0.7467

Epoch 00191: val_mDice did not improve from 0.74876
Epoch 192/300
 - 16s - loss: 0.9129 - acc: 0.9610 - mDice: 0.6925 - val_loss: 0.7374 - val_acc: 0.9783 - val_mDice: 0.7416

Epoch 00192: val_mDice did not improve from 0.74876
Epoch 193/300
 - 15s - loss: 0.9141 - acc: 0.9610 - mDice: 0.6919 - val_loss: 0.7357 - val_acc: 0.9773 - val_mDice: 0.7373

Epoch 00193: val_mDice did not improve from 0.74876
Epoch 194/300
 - 15s - loss: 0.9131 - acc: 0.9610 - mDice: 0.6917 - val_loss: 0.7249 - val_acc: 0.9777 - val_mDice: 0.7422

Epoch 00194: val_mDice did not improve from 0.74876
Epoch 195/300
 - 16s - loss: 0.9122 - acc: 0.9611 - mDice: 0.6925 - val_loss: 0.7299 - val_acc: 0.9778 - val_mDice: 0.7453

Epoch 00195: val_mDice did not improve from 0.74876
Epoch 196/300
 - 16s - loss: 0.9128 - acc: 0.9611 - mDice: 0.6923 - val_loss: 0.7287 - val_acc: 0.9772 - val_mDice: 0.7439

Epoch 00196: val_mDice did not improve from 0.74876
Epoch 197/300
 - 16s - loss: 0.9107 - acc: 0.9611 - mDice: 0.6928 - val_loss: 0.7330 - val_acc: 0.9773 - val_mDice: 0.7410

Epoch 00197: val_mDice did not improve from 0.74876
Epoch 198/300
 - 16s - loss: 0.9109 - acc: 0.9611 - mDice: 0.6925 - val_loss: 0.7273 - val_acc: 0.9776 - val_mDice: 0.7413

Epoch 00198: val_mDice did not improve from 0.74876
Epoch 199/300
 - 15s - loss: 0.9089 - acc: 0.9612 - mDice: 0.6936 - val_loss: 0.7229 - val_acc: 0.9777 - val_mDice: 0.7441

Epoch 00199: val_mDice did not improve from 0.74876
Epoch 200/300
 - 15s - loss: 0.9082 - acc: 0.9611 - mDice: 0.6935 - val_loss: 0.7238 - val_acc: 0.9781 - val_mDice: 0.7432

Epoch 00200: val_mDice did not improve from 0.74876
Epoch 201/300
 - 16s - loss: 0.9096 - acc: 0.9612 - mDice: 0.6933 - val_loss: 0.7236 - val_acc: 0.9777 - val_mDice: 0.7439

Epoch 00201: val_mDice did not improve from 0.74876
Epoch 202/300
 - 15s - loss: 0.9082 - acc: 0.9612 - mDice: 0.6936 - val_loss: 0.7228 - val_acc: 0.9779 - val_mDice: 0.7441

Epoch 00202: val_mDice did not improve from 0.74876
Epoch 203/300
 - 15s - loss: 0.9090 - acc: 0.9611 - mDice: 0.6932 - val_loss: 0.7226 - val_acc: 0.9778 - val_mDice: 0.7468

Epoch 00203: val_mDice did not improve from 0.74876
Epoch 204/300
 - 15s - loss: 0.9082 - acc: 0.9611 - mDice: 0.6938 - val_loss: 0.7389 - val_acc: 0.9778 - val_mDice: 0.7370

Epoch 00204: val_mDice did not improve from 0.74876
Epoch 205/300
 - 15s - loss: 0.9085 - acc: 0.9611 - mDice: 0.6933 - val_loss: 0.7221 - val_acc: 0.9780 - val_mDice: 0.7499

Epoch 00205: val_mDice improved from 0.74876 to 0.74990, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 206/300
 - 16s - loss: 0.9078 - acc: 0.9611 - mDice: 0.6935 - val_loss: 0.7254 - val_acc: 0.9775 - val_mDice: 0.7452

Epoch 00206: val_mDice did not improve from 0.74990
Epoch 207/300
 - 15s - loss: 0.9085 - acc: 0.9612 - mDice: 0.6938 - val_loss: 0.7311 - val_acc: 0.9780 - val_mDice: 0.7470

Epoch 00207: val_mDice did not improve from 0.74990
Epoch 208/300
 - 15s - loss: 0.9074 - acc: 0.9612 - mDice: 0.6941 - val_loss: 0.7241 - val_acc: 0.9780 - val_mDice: 0.7468

Epoch 00208: val_mDice did not improve from 0.74990
Epoch 209/300
 - 17s - loss: 0.9063 - acc: 0.9612 - mDice: 0.6941 - val_loss: 0.7243 - val_acc: 0.9782 - val_mDice: 0.7477

Epoch 00209: val_mDice did not improve from 0.74990
Epoch 210/300
 - 15s - loss: 0.9065 - acc: 0.9612 - mDice: 0.6942 - val_loss: 0.7305 - val_acc: 0.9783 - val_mDice: 0.7433

Epoch 00210: val_mDice did not improve from 0.74990
Epoch 211/300
 - 16s - loss: 0.9109 - acc: 0.9612 - mDice: 0.6933 - val_loss: 0.7239 - val_acc: 0.9776 - val_mDice: 0.7446

Epoch 00211: val_mDice did not improve from 0.74990
Epoch 212/300
 - 15s - loss: 0.9055 - acc: 0.9612 - mDice: 0.6942 - val_loss: 0.7181 - val_acc: 0.9778 - val_mDice: 0.7457

Epoch 00212: val_mDice did not improve from 0.74990
Epoch 213/300
 - 17s - loss: 0.9041 - acc: 0.9613 - mDice: 0.6948 - val_loss: 0.7197 - val_acc: 0.9775 - val_mDice: 0.7483

Epoch 00213: val_mDice did not improve from 0.74990
Epoch 214/300
 - 15s - loss: 0.9059 - acc: 0.9612 - mDice: 0.6945 - val_loss: 0.7249 - val_acc: 0.9770 - val_mDice: 0.7424

Epoch 00214: val_mDice did not improve from 0.74990
Epoch 215/300
 - 16s - loss: 0.9044 - acc: 0.9613 - mDice: 0.6952 - val_loss: 0.7238 - val_acc: 0.9770 - val_mDice: 0.7475

Epoch 00215: val_mDice did not improve from 0.74990
Epoch 216/300
 - 16s - loss: 0.9028 - acc: 0.9613 - mDice: 0.6955 - val_loss: 0.7217 - val_acc: 0.9779 - val_mDice: 0.7484

Epoch 00216: val_mDice did not improve from 0.74990
Epoch 217/300
 - 16s - loss: 0.9031 - acc: 0.9613 - mDice: 0.6952 - val_loss: 0.7227 - val_acc: 0.9780 - val_mDice: 0.7469

Epoch 00217: val_mDice did not improve from 0.74990
Epoch 218/300
 - 17s - loss: 0.9032 - acc: 0.9613 - mDice: 0.6952 - val_loss: 0.7253 - val_acc: 0.9775 - val_mDice: 0.7463

Epoch 00218: val_mDice did not improve from 0.74990
Epoch 219/300
 - 16s - loss: 0.9045 - acc: 0.9613 - mDice: 0.6950 - val_loss: 0.7275 - val_acc: 0.9778 - val_mDice: 0.7483

Epoch 00219: val_mDice did not improve from 0.74990
Epoch 220/300
 - 17s - loss: 0.9042 - acc: 0.9613 - mDice: 0.6951 - val_loss: 0.7222 - val_acc: 0.9779 - val_mDice: 0.7458

Epoch 00220: val_mDice did not improve from 0.74990
Epoch 221/300
 - 16s - loss: 0.9009 - acc: 0.9614 - mDice: 0.6962 - val_loss: 0.7174 - val_acc: 0.9778 - val_mDice: 0.7463

Epoch 00221: val_mDice did not improve from 0.74990
Epoch 222/300
 - 16s - loss: 0.9012 - acc: 0.9613 - mDice: 0.6962 - val_loss: 0.7258 - val_acc: 0.9778 - val_mDice: 0.7456

Epoch 00222: val_mDice did not improve from 0.74990
Epoch 223/300
 - 16s - loss: 0.9021 - acc: 0.9613 - mDice: 0.6959 - val_loss: 0.7305 - val_acc: 0.9781 - val_mDice: 0.7451

Epoch 00223: val_mDice did not improve from 0.74990
Epoch 224/300
 - 16s - loss: 0.8992 - acc: 0.9614 - mDice: 0.6967 - val_loss: 0.7237 - val_acc: 0.9774 - val_mDice: 0.7493

Epoch 00224: val_mDice did not improve from 0.74990
Epoch 225/300
 - 17s - loss: 0.9013 - acc: 0.9614 - mDice: 0.6959 - val_loss: 0.7342 - val_acc: 0.9776 - val_mDice: 0.7463

Epoch 00225: val_mDice did not improve from 0.74990
Epoch 226/300
 - 16s - loss: 0.9019 - acc: 0.9614 - mDice: 0.6959 - val_loss: 0.7286 - val_acc: 0.9776 - val_mDice: 0.7479

Epoch 00226: val_mDice did not improve from 0.74990
Epoch 227/300
 - 17s - loss: 0.9009 - acc: 0.9614 - mDice: 0.6961 - val_loss: 0.7170 - val_acc: 0.9775 - val_mDice: 0.7483

Epoch 00227: val_mDice did not improve from 0.74990
Epoch 228/300
 - 15s - loss: 0.8997 - acc: 0.9614 - mDice: 0.6965 - val_loss: 0.7243 - val_acc: 0.9770 - val_mDice: 0.7460

Epoch 00228: val_mDice did not improve from 0.74990
Epoch 229/300
 - 16s - loss: 0.8992 - acc: 0.9614 - mDice: 0.6968 - val_loss: 0.7223 - val_acc: 0.9771 - val_mDice: 0.7441

Epoch 00229: val_mDice did not improve from 0.74990
Epoch 230/300
 - 16s - loss: 0.9013 - acc: 0.9614 - mDice: 0.6960 - val_loss: 0.7312 - val_acc: 0.9769 - val_mDice: 0.7478

Epoch 00230: val_mDice did not improve from 0.74990
Epoch 231/300
 - 16s - loss: 0.8989 - acc: 0.9615 - mDice: 0.6966 - val_loss: 0.7269 - val_acc: 0.9777 - val_mDice: 0.7461

Epoch 00231: val_mDice did not improve from 0.74990
Epoch 232/300
 - 15s - loss: 0.8981 - acc: 0.9615 - mDice: 0.6970 - val_loss: 0.7197 - val_acc: 0.9765 - val_mDice: 0.7458

Epoch 00232: val_mDice did not improve from 0.74990
Epoch 233/300
 - 17s - loss: 0.8988 - acc: 0.9615 - mDice: 0.6969 - val_loss: 0.7291 - val_acc: 0.9774 - val_mDice: 0.7461

Epoch 00233: val_mDice did not improve from 0.74990
Epoch 234/300
 - 15s - loss: 0.8991 - acc: 0.9615 - mDice: 0.6969 - val_loss: 0.7266 - val_acc: 0.9771 - val_mDice: 0.7474

Epoch 00234: val_mDice did not improve from 0.74990
Epoch 235/300
 - 16s - loss: 0.9001 - acc: 0.9615 - mDice: 0.6963 - val_loss: 0.7236 - val_acc: 0.9775 - val_mDice: 0.7474

Epoch 00235: val_mDice did not improve from 0.74990
Restoring model weights from the end of the best epoch
Epoch 00235: early stopping
{'val_loss': [4.718061734552252, 3.9762671385725885, 3.6039076978213167, 3.2817367625563114, 2.9518752228723812, 2.5794126497556085, 2.2685833197750456, 1.93867095692517, 1.7464829030102247, 1.6530940565344405, 1.626061992286003, 1.5227580740027231, 1.4346267099249852, 1.3702580202115726, 1.3312536045296552, 1.2274196760295188, 1.1446129573534614, 1.1615607068963247, 1.0787499885853022, 1.060268905881333, 1.0350652577942365, 1.0163461888489658, 1.001627408070107, 0.9867570208360071, 0.9753771534521286, 0.9698599193194141, 0.9473054992826018, 0.9311154558234018, 0.922878188629673, 0.9118549456335094, 0.9038527742640613, 0.9076343701310354, 0.8683127997672722, 0.8755130857637484, 0.883861001631985, 0.8644208471252494, 0.8508454740863957, 0.8531544453477207, 0.8718783373702063, 0.8610002051477563, 0.8337853514168361, 0.85197889355764, 0.8360460510809128, 0.8247132154360209, 0.8360272074398929, 0.8220485187556645, 0.8248513169484596, 0.819442528567902, 0.8024637135740829, 0.8201066378044756, 0.8130215692193541, 0.8210265285348239, 0.7962554146165717, 0.7973963806073959, 0.7952544897386472, 0.8099203399599415, 0.7882127492395166, 0.7867936067385216, 0.7968958477451377, 0.7964875257178529, 0.7987219274860539, 0.8006145194785236, 0.7955355329872811, 0.7787831654287365, 0.7919961683554192, 0.7738389552456059, 0.7781562792928252, 0.7935662045054239, 0.7749041143345506, 0.7880443114123933, 0.7677557113235944, 0.7870347434527254, 0.7748180297139573, 0.7719541216549808, 0.7832268341763379, 0.7756116912789541, 0.772295109621466, 0.7706081646762483, 0.7797145439337377, 0.7759118018901512, 0.7847033326756464, 0.7606063117719677, 0.770561252554802, 0.762188196998753, 0.7566199470056246, 0.7634781374506754, 0.7569664190076801, 0.7630422364359033, 0.7713648240043692, 0.7699926373076765, 0.7626427252815194, 0.7559953891251185, 0.7675474992353623, 0.7822261060753913, 0.7546894301290381, 0.7639414423132596, 0.7655421932266183, 0.7557035133446732, 0.7586119587290777, 0.765776126352075, 0.7561324565377954, 0.7543311445680383, 0.756062871381028, 0.7539815367901161, 0.7467836051771085, 0.7553882545804325, 0.7525885872644921, 0.758571010746368, 0.7524434389316872, 0.7480920516464808, 0.7459399034715679, 0.7440713713430378, 0.737430358994497, 0.7625319402511805, 0.7418161520402725, 0.7503722183508416, 0.760811010043915, 0.7482995746070391, 0.7500283897739567, 0.7543837526073195, 0.7596845100187275, 0.7562048965937471, 0.7473588643008715, 0.7614153954264236, 0.748598868308002, 0.7452638733060393, 0.7506275605665494, 0.750114669538524, 0.7419928002030882, 0.7539490077593555, 0.742719151794094, 0.743720337952653, 0.7401508186777978, 0.7397543236817399, 0.7557079898167963, 0.743149213186682, 0.732435795134061, 0.7433609358251911, 0.7331405673941521, 0.7444543744603248, 0.7374489291073525, 0.7285141610119441, 0.7424133685353684, 0.7393101368048419, 0.7338277068856645, 0.7431344908394225, 0.7366528592697562, 0.7365527728649035, 0.7304382463024087, 0.7431343989829494, 0.737141779432558, 0.7382825915127584, 0.7350900573273228, 0.7344608302802256, 0.7410933167150576, 0.7315466261073335, 0.734009083411465, 0.7409930253682071, 0.7432647588318342, 0.7347558989916763, 0.7237937295273559, 0.7299210735379833, 0.7267772722734164, 0.7244909601668789, 0.7332371011988758, 0.722975056465358, 0.7331525071026528, 0.7269004240427932, 0.734056487883607, 0.7259910902748369, 0.7359575098508024, 0.7275048375946201, 0.7278799998433623, 0.7285114057260017, 0.7310415192009652, 0.7389890620969746, 0.7268757991594811, 0.7244085391906843, 0.7261561412517339, 0.7213711742668936, 0.7311192505980191, 0.7289971913376899, 0.7322011875779662, 0.7340588100152473, 0.7262048786633635, 0.7220198654965179, 0.7244495667823373, 0.7276535593483546, 0.7299230600873085, 0.7243666146716027, 0.723662404981378, 0.737390059722613, 0.7357239784443215, 0.724913337051052, 0.7299108725704558, 0.7286898934677856, 0.7330196340606637, 0.7272864159655897, 0.7228906636368738, 0.7238485172186813, 0.7235509683824566, 0.7228363274711452, 0.7225779429690479, 0.7389246400904982, 0.7220766021780771, 0.7253705254972798, 0.7311427764696617, 0.7241224960921562, 0.724288232522468, 0.7305345449545612, 0.7239025026968081, 0.7180725429972558, 0.7196717282680616, 0.7248925668736027, 0.7238131165504456, 0.7216846363185203, 0.7226653980882201, 0.72531152016496, 0.7275155084590389, 0.7222253378123453, 0.717385812981488, 0.7258324729253168, 0.7305274593503508, 0.7236734089786059, 0.7341714150285068, 0.7285981288511459, 0.7170192827917126, 0.7243344069343723, 0.7222827440255308, 0.7311652943696061, 0.7269209966267625, 0.7196803264421959, 0.7291091945889878, 0.7265779988406456, 0.7236072510889132], 'val_acc': [0.9134473159705123, 0.9134473159705123, 0.9128601530643359, 0.9143136715235776, 0.9149346747626997, 0.9243215412309725, 0.932823510202643, 0.9503977984598239, 0.9559231886308487, 0.957415272111762, 0.957808061005318, 0.960125013165278, 0.9631153900329381, 0.9630193077538112, 0.9647225268083076, 0.9656351204604319, 0.9679386248327282, 0.9674530192597272, 0.9691664200939544, 0.9701412671232876, 0.9690037226840241, 0.9696524028908716, 0.9715037790879811, 0.9702639420555063, 0.9716774057852079, 0.9714702902591392, 0.9710920844992547, 0.9724644197993082, 0.9722609262760371, 0.97198501147636, 0.9722256293035534, 0.9730027816067003, 0.9735651898057494, 0.9732725314081532, 0.9728044030601031, 0.9740755562096426, 0.9737821441807158, 0.9736387349971353, 0.9731258288638233, 0.9738534917570141, 0.9745731476235063, 0.9738789849901852, 0.9753022687892391, 0.9750205208993938, 0.974862911929823, 0.9751399371721973, 0.9749946863683936, 0.9752309228459449, 0.974843977248832, 0.9745258301088254, 0.9761023786786485, 0.975768942947257, 0.9761664581625429, 0.9760037338080472, 0.9752764240519641, 0.9759899014479494, 0.9755352425248656, 0.9753426815548988, 0.9765392080561756, 0.976361194293793, 0.9761111221901358, 0.9761173112751687, 0.976123864928337, 0.9763677405984434, 0.9762716570945635, 0.9764154467680682, 0.9762028521054411, 0.9756007725245333, 0.9768744576467226, 0.9758290191219278, 0.9767714555132879, 0.976265454537248, 0.9757573028949842, 0.976415069135901, 0.9764096128613982, 0.9761548042297363, 0.975802432592601, 0.9770419124054582, 0.976037958305176, 0.9767718151824115, 0.976449290367022, 0.9769698324268812, 0.9772144470312824, 0.9770091412818596, 0.9771940879625817, 0.9767496067367188, 0.9767903726394862, 0.9767703544603635, 0.9765151841183232, 0.9769319785784368, 0.9760929235856827, 0.9772024375118621, 0.9768875694438203, 0.9768103977588758, 0.9766535118018111, 0.9755319850902034, 0.9770990552967542, 0.976943265085351, 0.9767681682763034, 0.9768136662163146, 0.9775238657650882, 0.9765133653601555, 0.976626208791994, 0.9769079587230943, 0.9768369606096451, 0.9773818919919941, 0.9763258940553012, 0.9770674048221275, 0.97658143019023, 0.9773607805167159, 0.9765686911262877, 0.9769854843616486, 0.9771092627962975, 0.9766778945922852, 0.9771365511090788, 0.9771565729624605, 0.9772388441105412, 0.9765595895786808, 0.9768933890617058, 0.9772854333054529, 0.9771937017571436, 0.9766946357406981, 0.9764532875524808, 0.9771580238864847, 0.9768282342446993, 0.9768162092117414, 0.9763804939511704, 0.9771576589100981, 0.9771867945586166, 0.9772479456581481, 0.9771372769793419, 0.977160585253206, 0.9773265874549134, 0.9774408756870113, 0.9774539736035752, 0.9768970192295231, 0.9772570423067433, 0.9771245489381764, 0.9773928192380357, 0.9774983664081521, 0.9773054465855637, 0.9777488251254983, 0.97760394297234, 0.977737546783604, 0.9775311452885197, 0.97733931182182, 0.9768267771969102, 0.9774674299645097, 0.9778594840062808, 0.9772577632779944, 0.9770491813143639, 0.9773425872195257, 0.9780593310316948, 0.9774011859338577, 0.9762552670420033, 0.9774634491090906, 0.9776258039964388, 0.9778351048900656, 0.9768304232865164, 0.9780866279177469, 0.9779428631475527, 0.9778427530641425, 0.976946186121196, 0.9780040028160566, 0.9769170496561755, 0.9777218875003187, 0.9770768468510614, 0.9779362964303526, 0.9771329062442257, 0.977874413745044, 0.9780131039554125, 0.9776192344214818, 0.9773931833979201, 0.9776774799987061, 0.9777622880184487, 0.9774561557051253, 0.9778780586098972, 0.9774368691117796, 0.9773327638841656, 0.9772836141390343, 0.9779741494622949, 0.9780076374746349, 0.9775624414012857, 0.9769028498701853, 0.97795267709314, 0.9778620367997313, 0.9780149157733133, 0.9772071695491059, 0.9780171129801501, 0.977704403743352, 0.9774255781141046, 0.978311590135914, 0.977349145771706, 0.9777386225249669, 0.9777997936287971, 0.977186430398732, 0.977270881198857, 0.9775806591935354, 0.9777033271854871, 0.9780942818073377, 0.9777451810771471, 0.9778846065475516, 0.9778285373563635, 0.9777870447668311, 0.9779555801659414, 0.9774656222291189, 0.9780098297824599, 0.9780305705658378, 0.9781692701659791, 0.978269733794748, 0.9775919322281668, 0.9778311081128578, 0.9774830990458188, 0.9769691049236141, 0.9769610974886646, 0.9779443018240471, 0.9779501189924267, 0.9774881903439352, 0.9778179999900191, 0.9778543788276307, 0.9778259890536739, 0.9778114418460898, 0.9780910080426359, 0.9773804463752328, 0.9775973958511875, 0.9775620886724289, 0.9775107711145322, 0.9769924042159563, 0.9770932336376138, 0.9769345403534092, 0.9776873114990862, 0.9765049819260427, 0.9773862672178713, 0.977096872378702, 0.9774721762905382], 'val_mDice': [0.021969316259332714, 0.03989798641980511, 0.0700635666614526, 0.09390539323834524, 0.1255771102868531, 0.1779832351085258, 0.2456524819135666, 0.31575343890549384, 0.37088307881191984, 0.39776264029006436, 0.41373358564834073, 0.4401286624065817, 0.46014309623470045, 0.4863060369883498, 0.5041932677977705, 0.5408372515684938, 0.5604575153899519, 0.5635691558661526, 0.5893342829730412, 0.597582125500457, 0.6093517211202073, 0.6162320746950907, 0.6215776135660198, 0.6267261358156596, 0.639189406617047, 0.634724251619757, 0.643205657397231, 0.6507812926214035, 0.6519437391464025, 0.6583304878783552, 0.665648148484426, 0.6647686537814467, 0.675190417733911, 0.6754676299552395, 0.6734525393949796, 0.6828359655321461, 0.6851410694318275, 0.6877418409471643, 0.6837680633753946, 0.6849194634450625, 0.6969358337252107, 0.6944504514948963, 0.6985506345964458, 0.7029556521814163, 0.6973151209419721, 0.7028541838469571, 0.7034424543380737, 0.7029941469839175, 0.7108679601590927, 0.7031637352623351, 0.7030885252234054, 0.7090625460833719, 0.709651964576277, 0.7098050717621633, 0.7192553265454018, 0.7109307054787466, 0.7162708868719128, 0.7161020624311003, 0.7116823347464, 0.7104235442533885, 0.7189048067347644, 0.7133951297361557, 0.7187330392125535, 0.7195241279798011, 0.7220219879934232, 0.722722932492217, 0.7206499098914944, 0.7160748725068079, 0.7173191329387769, 0.7222474813461304, 0.7222648707971181, 0.720307515908594, 0.7272180233099689, 0.7220312642724547, 0.7198631506260127, 0.7199452878677681, 0.7233582171675277, 0.7274253486770473, 0.7210896419335718, 0.7243577033689578, 0.719308560433453, 0.7256696493658301, 0.7282059519258264, 0.7229621728805646, 0.7269002680909143, 0.7274198932190464, 0.7328224382171892, 0.7304080618570928, 0.721434670360121, 0.727556438886956, 0.7265465904588568, 0.7280191770971638, 0.7239017633542623, 0.7237943390460864, 0.7286139281645213, 0.7262172319301187, 0.7281445485271819, 0.7338777739707738, 0.7327329144902426, 0.724039761987451, 0.7274154975806197, 0.7301806305369286, 0.7286699271365388, 0.7305550085355158, 0.7296654422805734, 0.7268738681322908, 0.7326399753355, 0.7267203624934366, 0.7317827829759415, 0.7345568100883536, 0.7311359252015205, 0.7337150210387087, 0.7316442621897344, 0.7299197801988418, 0.7376213939222571, 0.7338791926429696, 0.7307047778612947, 0.7339391283792992, 0.7352414343455066, 0.7349605094896604, 0.7324296770847007, 0.7314034704476187, 0.7381622783125263, 0.7320763068656398, 0.735511792032686, 0.7380644005455382, 0.7411964523465666, 0.7360552475877005, 0.7394550626408564, 0.7354232207553028, 0.7359015966114932, 0.735492907974818, 0.7392881475899318, 0.741915084727823, 0.7382902445858472, 0.737554814717541, 0.737998365947645, 0.7376820779826543, 0.739820417884278, 0.7399291151190457, 0.7406719943431959, 0.7403975978289565, 0.7412092579554205, 0.7378671781657493, 0.7372108616241037, 0.7331789091025314, 0.7397199305769515, 0.7408609030997917, 0.7377369865162732, 0.7355008684609035, 0.7392926371260865, 0.7408988528872189, 0.7389210103309318, 0.7387006384869145, 0.7377942722954162, 0.7404598565134284, 0.7423571340025288, 0.7375881831123404, 0.7372197884402863, 0.7395280154600535, 0.7457805712745614, 0.7391126119110683, 0.7456435148846613, 0.7452751075568265, 0.739960835812843, 0.7430862731313053, 0.7426477021550479, 0.7453335148014434, 0.7363208973244445, 0.7416824841336028, 0.742822871224521, 0.7422270325765218, 0.741768238070893, 0.742561301548187, 0.7393919437715452, 0.740536382753555, 0.742721678867732, 0.7429430799124992, 0.7425441051999183, 0.7487587985927111, 0.740269224529397, 0.7452777228126787, 0.742914618286368, 0.7426991479037559, 0.7444763840877846, 0.7481224014334482, 0.7477155352291995, 0.7436534762382507, 0.7428813854308978, 0.7428411620936982, 0.7467372417449951, 0.7416324505250748, 0.7373167076339461, 0.742234910187656, 0.7452859784642311, 0.7438650792592192, 0.7410420501885349, 0.7413443175897206, 0.7441352805862688, 0.7432217185627924, 0.7439490152548437, 0.7440812057011748, 0.7468320898813744, 0.7370050373959215, 0.749903336371461, 0.7452219132691213, 0.7470119485299881, 0.7467959870214331, 0.7477471563097549, 0.7433245308595161, 0.7446132302284241, 0.7457326736352216, 0.7482896814607594, 0.7423713570588255, 0.7475214727120857, 0.7484204205748153, 0.7468596247777547, 0.7462836099814062, 0.748323722653193, 0.745809259071742, 0.7463059992822882, 0.7455760326287518, 0.7450506409553632, 0.7492603067665884, 0.7462534092060508, 0.7479313554829115, 0.7482994709112872, 0.7460483937230828, 0.7441106324326502, 0.7477963685172878, 0.7461045310921866, 0.7457823479828769, 0.7461106132154596, 0.7474053563320473, 0.7474251405833519], 'loss': [62.79803777171926, 6.740626416600947, 5.152893008436144, 4.49885365795679, 4.004975396211742, 3.570331955439809, 3.1953195092063207, 2.9080622089679595, 2.7070656736831595, 2.5575159582277514, 2.449466434649556, 2.3317020628399328, 2.2364457679878424, 2.151682910106114, 2.050098715219057, 1.949835589382584, 1.8662293454791685, 1.7989286987992608, 1.733153679154397, 1.6835930283842124, 1.637337054851354, 1.5937361989178034, 1.5618274436898332, 1.521255053309419, 1.4918052379272262, 1.4661063392240803, 1.4393790852558734, 1.4117837149962797, 1.389692750133499, 1.3706767891532192, 1.348369034369415, 1.3290683923844768, 1.3143294869293574, 1.3018655215000738, 1.2862459690038013, 1.2698544270647905, 1.2496256953268443, 1.2365687639145997, 1.226016346704725, 1.2111966997130796, 1.2035414419712414, 1.1951747772073027, 1.1808362552399083, 1.166391742991289, 1.162385294503939, 1.151327432618152, 1.1394891354789378, 1.1329149851293885, 1.125737101987239, 1.1211143454802606, 1.1118338684747522, 1.1074649792813962, 1.099883903589092, 1.095913742440506, 1.0883336414330906, 1.0804164650739088, 1.0771003697968613, 1.0752758790173642, 1.0670212008785447, 1.0642456772660767, 1.059136874144655, 1.056393849877853, 1.0526163900344938, 1.0506174839389222, 1.0452339882416646, 1.041807860227957, 1.0391503309716925, 1.0356264245401514, 1.0324906254022677, 1.0270354278524603, 1.0259328640089294, 1.0209979171999748, 1.020865272437758, 1.0201163675372666, 1.016164931669437, 1.0159011901881392, 1.013258179162886, 1.010342033311622, 1.0086309429814864, 1.0068314321914738, 1.004759783751764, 1.004148420371046, 1.0000643542579435, 0.9961734229647697, 0.9936539972223163, 0.995183547030955, 0.9913023563286006, 0.9908350664044847, 0.9913205723744357, 0.9928672703264811, 0.9897421472396867, 0.98414785424378, 0.9847215637869878, 0.9827656684694442, 0.9843139114483413, 0.9810029434059848, 0.9828631664892066, 0.9802778148525876, 0.975366996428416, 0.9750128301033153, 0.9761915034980991, 0.9726705685846087, 0.9700205744424552, 0.9731024172318815, 0.9700119220838184, 0.9681364981586591, 0.9693723251529013, 0.9668794581344762, 0.9678049553985555, 0.9651141702537048, 0.9674577492852688, 0.9616795311971391, 0.9622159891860721, 0.9604029468920922, 0.9611179842375073, 0.9576919581296731, 0.9581217633838498, 0.9566480815381887, 0.9553582064372568, 0.9552029106158958, 0.9522825810092175, 0.9532224943916036, 0.9527276648306618, 0.9533180342311658, 0.9505039114849592, 0.9513300940601951, 0.9484890353131555, 0.9501337132095872, 0.9507673349292705, 0.9487677954140556, 0.9451395262335632, 0.946038396082773, 0.9459912109630092, 0.9470585733070402, 0.9437315562350634, 0.9441084768250567, 0.9411542603691386, 0.9411571847225616, 0.9407217118362501, 0.9396890170117781, 0.9402413902681899, 0.936954244617221, 0.9400307765405858, 0.9351155741860294, 0.937912470369754, 0.9359208038456038, 0.9373926556399371, 0.9352505988221874, 0.9333649472452841, 0.9332454029815939, 0.9336977227664096, 0.9319919461864776, 0.9319703802972698, 0.9306251004713864, 0.9297493136476636, 0.9294076370724116, 0.934902133948947, 0.9305910705281968, 0.9296489713510735, 0.9309272248131136, 0.9289558568677705, 0.924897480090846, 0.9266871906897034, 0.9249859437238016, 0.9249455195687479, 0.9251218201786738, 0.9249746431338712, 0.9254490345266907, 0.9252241929974451, 0.9213015367277639, 0.9228772607198525, 0.921780031148747, 0.9226651779254825, 0.9211804933737914, 0.9216831312968855, 0.9213789051438224, 0.919796767318224, 0.9197287284237453, 0.9189983312322626, 0.9171864166177148, 0.9197314578692042, 0.9165362191117524, 0.9190970907941417, 0.9175362036560718, 0.9160459365113465, 0.915529150236968, 0.9164110837591615, 0.9151878451271467, 0.9161293627144406, 0.9146399534899411, 0.9128942227681301, 0.9129490244028924, 0.9140532781166699, 0.9131035323608145, 0.9121852204913868, 0.9127630440923035, 0.9107124579918575, 0.9109346733431545, 0.9089464701852532, 0.9082252142288477, 0.9096349630492458, 0.9081903097643795, 0.9089797527521534, 0.9082219806890774, 0.9085491561442663, 0.9077949945544833, 0.908520169768358, 0.9073531419028719, 0.9063150517635675, 0.9065148865948517, 0.9108504327993933, 0.9054696651241958, 0.9040698793067824, 0.905887344185545, 0.9043984510472404, 0.9028368155877787, 0.9031437306704249, 0.9032076002172725, 0.9044871047779051, 0.9042148561088474, 0.9009469464759527, 0.901198913855256, 0.9020942960039864, 0.8992096547494653, 0.9013105042153448, 0.9018540231987587, 0.9008597831946349, 0.899701832514153, 0.8991566889774047, 0.9013183925549859, 0.8989267091250338, 0.8981253367914361, 0.8988486165896721, 0.8991438265685386, 0.9001003140365941], 'acc': [0.6740863049620347, 0.8977630728123831, 0.8986207504600863, 0.8992690057305004, 0.901505293831882, 0.9066382072547458, 0.9128900022097418, 0.9189700525814358, 0.9239856312261029, 0.9272331864214833, 0.9291152636587399, 0.931219002221991, 0.9327335633813999, 0.9342929970942909, 0.9363028172573599, 0.9383271227050008, 0.9402677330794268, 0.9415960304076036, 0.9428259479068228, 0.943686174225466, 0.9446467893647253, 0.9455970841848141, 0.9463095172433211, 0.9473002230301208, 0.9480019919705326, 0.9485394018513018, 0.9491318921346745, 0.9497826992244547, 0.9504099742775279, 0.9507266126992852, 0.9512587286109286, 0.9517231044082608, 0.9520578266103628, 0.9523738820935808, 0.9527801625257147, 0.9530751193808995, 0.9535749586836517, 0.95388547362658, 0.9541157187424577, 0.9544338740218467, 0.9545933181529758, 0.9548189338962568, 0.9552883113187229, 0.9556029512483624, 0.9556728980990397, 0.9558866638678563, 0.9562345930562375, 0.9563994043171794, 0.9564983466199073, 0.9566837676353147, 0.9568960349601955, 0.9569979577795547, 0.9571418172911315, 0.9571979004157021, 0.9572860643377511, 0.9574239474473801, 0.9575664234699137, 0.957508977846764, 0.9577089379400143, 0.9577149218999079, 0.9577628906258411, 0.9577398817937595, 0.9578019778546589, 0.9579266784788528, 0.9579373108972394, 0.957989634430617, 0.9580755643692009, 0.958096425181912, 0.9581243752962113, 0.9582307037689455, 0.9582132029903384, 0.9583193701636942, 0.9583095205629342, 0.9583108545964101, 0.958404682464982, 0.9583798903598286, 0.958427017803933, 0.9584781766811091, 0.9584511477284572, 0.9584628696947007, 0.958534964182686, 0.9585325190995572, 0.9586121777901219, 0.9587348575442434, 0.9587750397933191, 0.958763666819754, 0.9588478042267106, 0.9589004242895333, 0.9589036421446268, 0.9588366669915407, 0.9589637753543948, 0.9590838609663767, 0.9590411873959743, 0.9590662168079908, 0.9590471708703899, 0.959116411637706, 0.9591025075565919, 0.9591642886341334, 0.9593261282491916, 0.959299837455927, 0.9593328085627761, 0.9593997431568964, 0.9594742570666154, 0.9593831353764619, 0.9595263964687809, 0.9594651378489751, 0.9594935609510797, 0.9596043954447577, 0.9595689244273542, 0.9596275293808098, 0.9595858839610851, 0.9596748767464907, 0.9596568537370872, 0.9597106630661165, 0.9597041265287367, 0.959784760484466, 0.9597781927931813, 0.9598380051680006, 0.9598744059736237, 0.9598886774812206, 0.9599642944833481, 0.959960052367147, 0.9598915196940482, 0.9599337194665575, 0.9599814457493269, 0.9600194152725582, 0.9600109918944042, 0.9599956329474766, 0.9600229983163389, 0.9600443716617749, 0.9601001707155898, 0.960147739602914, 0.960139491950594, 0.9600845761049558, 0.9601580770402146, 0.960237202762012, 0.9601654635578116, 0.9601911808262159, 0.960267550373969, 0.9602721075539624, 0.9602616899093609, 0.9603687765064098, 0.960242744057809, 0.9604042984702867, 0.9603931601147829, 0.960344412676242, 0.9603502239122225, 0.9604405983826461, 0.960468753739273, 0.9604854847507089, 0.9603945877392428, 0.9604642356589385, 0.9604937522903949, 0.9605188938938133, 0.9605196017065107, 0.9605676449404044, 0.9604797487063801, 0.9605459234468494, 0.9605666179100607, 0.9605434749136661, 0.960564251663978, 0.9607073927139385, 0.9606299792705051, 0.9606987967066687, 0.9606954365806399, 0.960690149816124, 0.9607187871548278, 0.9606664925777767, 0.9607211098055523, 0.9607543672985144, 0.9607352205193573, 0.9607542044134323, 0.9607855858409357, 0.9607863153450241, 0.96079761549113, 0.9607591736436758, 0.960782820382482, 0.9608418757447025, 0.9608165164689937, 0.9608932959871974, 0.9608464751497994, 0.9609711357809398, 0.9608606757775945, 0.9608954890267615, 0.9609016485372573, 0.9609349542246927, 0.9609129678324576, 0.9609509719366671, 0.960993009872612, 0.9610100460142117, 0.9610230046626465, 0.9609944128870671, 0.9609854661836367, 0.9610060096918873, 0.9610790068215362, 0.961058252202131, 0.9610627175262219, 0.9610664977057077, 0.9611651639983397, 0.9611061918826854, 0.9611765046545762, 0.9611719157001852, 0.9611409748368702, 0.9611469982698674, 0.9611218260468573, 0.9611198276840087, 0.9611543234735921, 0.9611608922047766, 0.9612118934710587, 0.9612087090220289, 0.9611684745050602, 0.9612119966997883, 0.9613132328290561, 0.9612240545364384, 0.9612916751225958, 0.9613377207319124, 0.961319841363699, 0.9613007931337224, 0.9612973599418042, 0.9613058446539391, 0.9613763336917224, 0.9613224131508651, 0.9613329643392868, 0.9614020108090774, 0.9614120530871875, 0.961360842283964, 0.9614423687954777, 0.961432316293601, 0.9614418357462761, 0.9614272948845167, 0.9614844683699048, 0.9615095988705253, 0.9614654101689549, 0.9615335441410148, 0.961505257173862], 'mDice': [0.016687446481367496, 0.03178826913264862, 0.04680856195930154, 0.06622534237747807, 0.0951934592597536, 0.1312105335024812, 0.17410551680100153, 0.21910617287572398, 0.252726283818706, 0.2780466744026923, 0.297734692597241, 0.31873050462918673, 0.33662154964926366, 0.3531665209977217, 0.37481544925434696, 0.399318223733765, 0.4199944095279149, 0.43546194963337076, 0.4525758975244119, 0.46492984260390813, 0.476555324225858, 0.48753302822320327, 0.4964945084549179, 0.5066093593811413, 0.51486645676359, 0.5221906260436595, 0.5292938690690214, 0.5365341997036297, 0.5431019403462329, 0.5485112983965921, 0.5555238949229294, 0.5609469092824705, 0.5656463203243338, 0.5698010647944401, 0.5746829684909392, 0.5796102302563587, 0.5855262967108348, 0.5899599760180468, 0.5933630162620839, 0.5982397998107233, 0.6003888236068176, 0.6033235759044292, 0.6080163877822387, 0.6123157861267344, 0.6142935128325502, 0.61722381827722, 0.6209957392808989, 0.6230905207790658, 0.6251024926442446, 0.6268227875672212, 0.6296086773004145, 0.6313540432486363, 0.6330184372334694, 0.6348742230828225, 0.6368254891441117, 0.6391385469593377, 0.640457336994773, 0.6412099425410861, 0.6438867055517753, 0.6443195343189937, 0.6464074347196036, 0.6467162596127448, 0.6479496168765086, 0.6489988265540135, 0.6499260709603911, 0.6514208374773085, 0.6522305251644389, 0.6532396191407114, 0.6538780657686298, 0.6557398798138362, 0.656102061300394, 0.6578287087358264, 0.6577712947894041, 0.6582396310394635, 0.6590982900567156, 0.6595927331584225, 0.6603756729186463, 0.6611978487052873, 0.6613423471864698, 0.6620175521875543, 0.6627882975625143, 0.6628662271725769, 0.664180352846521, 0.6656609878545094, 0.6660688099007852, 0.6656376039259657, 0.6665632360710846, 0.6671021592732516, 0.6671272625353912, 0.6665619473192134, 0.6674944826899233, 0.6689187785626446, 0.6687918041084374, 0.6699284286095474, 0.6690918324947288, 0.6701984830095461, 0.6696655654299374, 0.6705280023687713, 0.6715875794769305, 0.671805127608448, 0.6714292262552951, 0.672742875511488, 0.6731528008183524, 0.67272122015786, 0.6737173162596422, 0.6741492230091631, 0.6737537389146523, 0.6745170549063104, 0.674447421160277, 0.6750835054575366, 0.6743866398717255, 0.6760789185404761, 0.6763007618546848, 0.6766390821044258, 0.6761807774548313, 0.6775700287581283, 0.6774482127873144, 0.677771764172951, 0.6780217447661913, 0.6780428917897834, 0.6788748753226529, 0.6787700458770028, 0.6791625275480425, 0.6789951484613208, 0.6796328906432894, 0.679753212895679, 0.6803513133265586, 0.6805244016270448, 0.6796853642497237, 0.6805625723220565, 0.6814721800705411, 0.6811692822329412, 0.681566886743515, 0.6810933992721252, 0.6821808890352089, 0.6819231446475671, 0.6829685136963818, 0.6824374371703559, 0.6832364802820389, 0.6832625989000667, 0.6831021806643242, 0.684194448876251, 0.6833646551339768, 0.684834789150255, 0.6838482832315715, 0.6845029166155111, 0.6842936037752944, 0.6852123147378778, 0.6853929203879984, 0.6855544795863134, 0.685348087543177, 0.6857127983763486, 0.6859216021970931, 0.6858629805650233, 0.6865876729680611, 0.6865848883834941, 0.6851162839506935, 0.6862726143925637, 0.6867015907762022, 0.6863311848167488, 0.6867735954047778, 0.6878041690749154, 0.6875299870424934, 0.687960052586181, 0.6882119879986189, 0.6880847105601189, 0.6879460756574989, 0.6879716319080444, 0.6882601891306718, 0.6893062339075399, 0.6887553077162567, 0.68896711201856, 0.6891196998143875, 0.6892791056904174, 0.6889506886048951, 0.689196448511914, 0.6896939667151735, 0.6897984921940838, 0.6901231623309522, 0.6903703279268645, 0.6899957449541096, 0.6908222335931209, 0.6902045009452077, 0.6905399250279818, 0.6908994675992546, 0.6913131583517755, 0.6909029547769113, 0.6913438458759599, 0.6909402420080807, 0.6912316874145766, 0.6920604635459313, 0.692499929080211, 0.6919196062567401, 0.6916684837385892, 0.6924737967711264, 0.6922955586971263, 0.6928088756215228, 0.6925168025866492, 0.693573114277225, 0.6935177824745306, 0.6933484839855306, 0.6935913057963621, 0.6932375588568269, 0.6938434324584425, 0.6932969153016451, 0.693452772223649, 0.693794370297955, 0.6940985400077262, 0.6940828851834453, 0.694228697750412, 0.6933288345871687, 0.6942081245102188, 0.6948205554874278, 0.6944949907925372, 0.6952307536128722, 0.6954738345081373, 0.695241228179062, 0.6952456254385495, 0.6949754688066312, 0.6950740064877856, 0.6962331572356434, 0.6961595495153124, 0.695926981800418, 0.6967117306645954, 0.6959384612832806, 0.6959094213826943, 0.6961436518887864, 0.6965472970998651, 0.6967730679921779, 0.6959991531433201, 0.6965791305534362, 0.6969722928360368, 0.6968704811394534, 0.6969271725048771, 0.6962986186910143]}
predicting test subjects:   0%|          | 0/15 [00:00<?, ?it/s]predicting test subjects:   7%|▋         | 1/15 [00:02<00:28,  2.01s/it]predicting test subjects:  13%|█▎        | 2/15 [00:03<00:24,  1.88s/it]predicting test subjects:  20%|██        | 3/15 [00:05<00:22,  1.90s/it]predicting test subjects:  27%|██▋       | 4/15 [00:07<00:21,  1.93s/it]predicting test subjects:  33%|███▎      | 5/15 [00:09<00:20,  2.05s/it]predicting test subjects:  40%|████      | 6/15 [00:12<00:19,  2.15s/it]predicting test subjects:  47%|████▋     | 7/15 [00:13<00:15,  1.92s/it]predicting test subjects:  53%|█████▎    | 8/15 [00:16<00:14,  2.10s/it]predicting test subjects:  60%|██████    | 9/15 [00:18<00:12,  2.05s/it]predicting test subjects:  67%|██████▋   | 10/15 [00:19<00:09,  1.91s/it]predicting test subjects:  73%|███████▎  | 11/15 [00:21<00:07,  1.89s/it]predicting test subjects:  80%|████████  | 12/15 [00:23<00:05,  1.95s/it]predicting test subjects:  87%|████████▋ | 13/15 [00:25<00:04,  2.02s/it]predicting test subjects:  93%|█████████▎| 14/15 [00:27<00:01,  1.97s/it]predicting test subjects: 100%|██████████| 15/15 [00:29<00:00,  1.98s/it]
predicting train subjects:   0%|          | 0/532 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/532 [00:02<21:05,  2.38s/it]predicting train subjects:   0%|          | 2/532 [00:04<19:34,  2.22s/it]predicting train subjects:   1%|          | 3/532 [00:06<18:27,  2.09s/it]predicting train subjects:   1%|          | 4/532 [00:07<17:32,  1.99s/it]predicting train subjects:   1%|          | 5/532 [00:09<17:17,  1.97s/it]predicting train subjects:   1%|          | 6/532 [00:11<16:27,  1.88s/it]predicting train subjects:   1%|▏         | 7/532 [00:13<16:16,  1.86s/it]predicting train subjects:   2%|▏         | 8/532 [00:14<15:40,  1.80s/it]predicting train subjects:   2%|▏         | 9/532 [00:16<16:37,  1.91s/it]predicting train subjects:   2%|▏         | 10/532 [00:18<16:03,  1.85s/it]predicting train subjects:   2%|▏         | 11/532 [00:20<15:16,  1.76s/it]predicting train subjects:   2%|▏         | 12/532 [00:22<16:38,  1.92s/it]predicting train subjects:   2%|▏         | 13/532 [00:24<15:38,  1.81s/it]predicting train subjects:   3%|▎         | 14/532 [00:25<14:51,  1.72s/it]predicting train subjects:   3%|▎         | 15/532 [00:27<14:32,  1.69s/it]predicting train subjects:   3%|▎         | 16/532 [00:29<15:03,  1.75s/it]predicting train subjects:   3%|▎         | 17/532 [00:30<14:37,  1.70s/it]predicting train subjects:   3%|▎         | 18/532 [00:32<15:18,  1.79s/it]predicting train subjects:   4%|▎         | 19/532 [00:34<14:32,  1.70s/it]predicting train subjects:   4%|▍         | 20/532 [00:36<15:06,  1.77s/it]predicting train subjects:   4%|▍         | 21/532 [00:38<15:40,  1.84s/it]predicting train subjects:   4%|▍         | 22/532 [00:39<15:00,  1.76s/it]predicting train subjects:   4%|▍         | 23/532 [00:41<14:59,  1.77s/it]predicting train subjects:   5%|▍         | 24/532 [00:43<14:30,  1.71s/it]predicting train subjects:   5%|▍         | 25/532 [00:45<15:42,  1.86s/it]predicting train subjects:   5%|▍         | 26/532 [00:46<15:10,  1.80s/it]predicting train subjects:   5%|▌         | 27/532 [00:49<16:39,  1.98s/it]predicting train subjects:   5%|▌         | 28/532 [00:51<16:02,  1.91s/it]predicting train subjects:   5%|▌         | 29/532 [00:53<17:00,  2.03s/it]predicting train subjects:   6%|▌         | 30/532 [00:54<15:41,  1.88s/it]predicting train subjects:   6%|▌         | 31/532 [00:56<15:34,  1.86s/it]predicting train subjects:   6%|▌         | 32/532 [00:58<15:11,  1.82s/it]predicting train subjects:   6%|▌         | 33/532 [01:00<14:26,  1.74s/it]predicting train subjects:   6%|▋         | 34/532 [01:02<15:30,  1.87s/it]predicting train subjects:   7%|▋         | 35/532 [01:04<15:22,  1.86s/it]predicting train subjects:   7%|▋         | 36/532 [01:06<16:01,  1.94s/it]predicting train subjects:   7%|▋         | 37/532 [01:08<15:51,  1.92s/it]predicting train subjects:   7%|▋         | 38/532 [01:10<16:19,  1.98s/it]predicting train subjects:   7%|▋         | 39/532 [01:11<15:53,  1.93s/it]predicting train subjects:   8%|▊         | 40/532 [01:13<15:11,  1.85s/it]predicting train subjects:   8%|▊         | 41/532 [01:15<15:31,  1.90s/it]predicting train subjects:   8%|▊         | 42/532 [01:17<15:31,  1.90s/it]predicting train subjects:   8%|▊         | 43/532 [01:19<14:36,  1.79s/it]predicting train subjects:   8%|▊         | 44/532 [01:20<13:45,  1.69s/it]predicting train subjects:   8%|▊         | 45/532 [01:22<13:44,  1.69s/it]predicting train subjects:   9%|▊         | 46/532 [01:24<14:15,  1.76s/it]predicting train subjects:   9%|▉         | 47/532 [01:26<15:13,  1.88s/it]predicting train subjects:   9%|▉         | 48/532 [01:28<15:19,  1.90s/it]predicting train subjects:   9%|▉         | 49/532 [01:29<14:33,  1.81s/it]predicting train subjects:   9%|▉         | 50/532 [01:31<15:16,  1.90s/it]predicting train subjects:  10%|▉         | 51/532 [01:33<15:19,  1.91s/it]predicting train subjects:  10%|▉         | 52/532 [01:35<15:04,  1.88s/it]predicting train subjects:  10%|▉         | 53/532 [01:37<14:24,  1.81s/it]predicting train subjects:  10%|█         | 54/532 [01:39<14:58,  1.88s/it]predicting train subjects:  10%|█         | 55/532 [01:41<14:44,  1.85s/it]predicting train subjects:  11%|█         | 56/532 [01:43<14:39,  1.85s/it]predicting train subjects:  11%|█         | 57/532 [01:44<14:21,  1.81s/it]predicting train subjects:  11%|█         | 58/532 [01:46<14:41,  1.86s/it]predicting train subjects:  11%|█         | 59/532 [01:48<15:35,  1.98s/it]predicting train subjects:  11%|█▏        | 60/532 [01:50<14:15,  1.81s/it]predicting train subjects:  11%|█▏        | 61/532 [01:51<13:38,  1.74s/it]predicting train subjects:  12%|█▏        | 62/532 [01:54<14:19,  1.83s/it]predicting train subjects:  12%|█▏        | 63/532 [01:56<14:47,  1.89s/it]predicting train subjects:  12%|█▏        | 64/532 [01:57<14:00,  1.80s/it]predicting train subjects:  12%|█▏        | 65/532 [01:59<14:01,  1.80s/it]predicting train subjects:  12%|█▏        | 66/532 [02:01<15:31,  2.00s/it]predicting train subjects:  13%|█▎        | 67/532 [02:04<17:10,  2.22s/it]predicting train subjects:  13%|█▎        | 68/532 [02:06<16:46,  2.17s/it]predicting train subjects:  13%|█▎        | 69/532 [02:08<16:28,  2.14s/it]predicting train subjects:  13%|█▎        | 70/532 [02:10<15:59,  2.08s/it]predicting train subjects:  13%|█▎        | 71/532 [02:12<15:11,  1.98s/it]predicting train subjects:  14%|█▎        | 72/532 [02:14<14:49,  1.93s/it]predicting train subjects:  14%|█▎        | 73/532 [02:16<15:10,  1.98s/it]predicting train subjects:  14%|█▍        | 74/532 [02:19<16:56,  2.22s/it]predicting train subjects:  14%|█▍        | 75/532 [02:22<19:26,  2.55s/it]predicting train subjects:  14%|█▍        | 76/532 [02:24<18:25,  2.42s/it]predicting train subjects:  14%|█▍        | 77/532 [02:26<17:31,  2.31s/it]predicting train subjects:  15%|█▍        | 78/532 [02:28<16:59,  2.25s/it]predicting train subjects:  15%|█▍        | 79/532 [02:30<16:52,  2.24s/it]predicting train subjects:  15%|█▌        | 80/532 [02:33<17:04,  2.27s/it]predicting train subjects:  15%|█▌        | 81/532 [02:35<17:22,  2.31s/it]predicting train subjects:  15%|█▌        | 82/532 [02:37<16:52,  2.25s/it]predicting train subjects:  16%|█▌        | 83/532 [02:39<16:00,  2.14s/it]predicting train subjects:  16%|█▌        | 84/532 [02:41<15:25,  2.07s/it]predicting train subjects:  16%|█▌        | 85/532 [02:43<14:44,  1.98s/it]predicting train subjects:  16%|█▌        | 86/532 [02:45<14:36,  1.97s/it]predicting train subjects:  16%|█▋        | 87/532 [02:47<14:09,  1.91s/it]predicting train subjects:  17%|█▋        | 88/532 [02:49<14:11,  1.92s/it]predicting train subjects:  17%|█▋        | 89/532 [02:51<14:25,  1.95s/it]predicting train subjects:  17%|█▋        | 90/532 [02:53<15:00,  2.04s/it]predicting train subjects:  17%|█▋        | 91/532 [02:55<15:11,  2.07s/it]predicting train subjects:  17%|█▋        | 92/532 [02:57<15:03,  2.05s/it]predicting train subjects:  17%|█▋        | 93/532 [02:59<15:10,  2.08s/it]predicting train subjects:  18%|█▊        | 94/532 [03:01<14:58,  2.05s/it]predicting train subjects:  18%|█▊        | 95/532 [03:04<15:56,  2.19s/it]predicting train subjects:  18%|█▊        | 96/532 [03:06<16:25,  2.26s/it]predicting train subjects:  18%|█▊        | 97/532 [03:09<17:09,  2.37s/it]predicting train subjects:  18%|█▊        | 98/532 [03:11<17:32,  2.43s/it]predicting train subjects:  19%|█▊        | 99/532 [03:14<17:51,  2.47s/it]predicting train subjects:  19%|█▉        | 100/532 [03:16<18:06,  2.52s/it]predicting train subjects:  19%|█▉        | 101/532 [03:18<16:48,  2.34s/it]predicting train subjects:  19%|█▉        | 102/532 [03:20<15:46,  2.20s/it]predicting train subjects:  19%|█▉        | 103/532 [03:22<15:08,  2.12s/it]predicting train subjects:  20%|█▉        | 104/532 [03:24<14:25,  2.02s/it]predicting train subjects:  20%|█▉        | 105/532 [03:26<14:23,  2.02s/it]predicting train subjects:  20%|█▉        | 106/532 [03:28<13:57,  1.97s/it]predicting train subjects:  20%|██        | 107/532 [03:29<13:07,  1.85s/it]predicting train subjects:  20%|██        | 108/532 [03:31<13:12,  1.87s/it]predicting train subjects:  20%|██        | 109/532 [03:33<13:17,  1.89s/it]predicting train subjects:  21%|██        | 110/532 [03:35<12:53,  1.83s/it]predicting train subjects:  21%|██        | 111/532 [03:36<12:18,  1.75s/it]predicting train subjects:  21%|██        | 112/532 [03:38<12:30,  1.79s/it]predicting train subjects:  21%|██        | 113/532 [03:41<13:21,  1.91s/it]predicting train subjects:  21%|██▏       | 114/532 [03:43<13:56,  2.00s/it]predicting train subjects:  22%|██▏       | 115/532 [03:45<14:20,  2.06s/it]predicting train subjects:  22%|██▏       | 116/532 [03:47<14:39,  2.12s/it]predicting train subjects:  22%|██▏       | 117/532 [03:49<14:53,  2.15s/it]predicting train subjects:  22%|██▏       | 118/532 [03:52<15:12,  2.21s/it]predicting train subjects:  22%|██▏       | 119/532 [03:54<15:05,  2.19s/it]predicting train subjects:  23%|██▎       | 120/532 [03:56<14:44,  2.15s/it]predicting train subjects:  23%|██▎       | 121/532 [03:58<15:03,  2.20s/it]predicting train subjects:  23%|██▎       | 122/532 [04:00<14:44,  2.16s/it]predicting train subjects:  23%|██▎       | 123/532 [04:02<14:34,  2.14s/it]predicting train subjects:  23%|██▎       | 124/532 [04:05<14:35,  2.14s/it]predicting train subjects:  23%|██▎       | 125/532 [04:07<14:52,  2.19s/it]predicting train subjects:  24%|██▎       | 126/532 [04:09<14:51,  2.20s/it]predicting train subjects:  24%|██▍       | 127/532 [04:11<14:25,  2.14s/it]predicting train subjects:  24%|██▍       | 128/532 [04:13<14:36,  2.17s/it]predicting train subjects:  24%|██▍       | 129/532 [04:16<15:03,  2.24s/it]predicting train subjects:  24%|██▍       | 130/532 [04:18<15:10,  2.27s/it]predicting train subjects:  25%|██▍       | 131/532 [04:21<15:53,  2.38s/it]predicting train subjects:  25%|██▍       | 132/532 [04:23<16:21,  2.45s/it]predicting train subjects:  25%|██▌       | 133/532 [04:26<16:48,  2.53s/it]predicting train subjects:  25%|██▌       | 134/532 [04:29<17:22,  2.62s/it]predicting train subjects:  25%|██▌       | 135/532 [04:32<17:34,  2.66s/it]predicting train subjects:  26%|██▌       | 136/532 [04:34<17:53,  2.71s/it]predicting train subjects:  26%|██▌       | 137/532 [04:37<17:59,  2.73s/it]predicting train subjects:  26%|██▌       | 138/532 [04:40<17:30,  2.67s/it]predicting train subjects:  26%|██▌       | 139/532 [04:42<17:38,  2.69s/it]predicting train subjects:  26%|██▋       | 140/532 [04:45<17:57,  2.75s/it]predicting train subjects:  27%|██▋       | 141/532 [04:48<17:42,  2.72s/it]predicting train subjects:  27%|██▋       | 142/532 [04:51<17:41,  2.72s/it]predicting train subjects:  27%|██▋       | 143/532 [04:53<16:03,  2.48s/it]predicting train subjects:  27%|██▋       | 144/532 [04:54<14:40,  2.27s/it]predicting train subjects:  27%|██▋       | 145/532 [04:57<14:15,  2.21s/it]predicting train subjects:  27%|██▋       | 146/532 [04:59<13:47,  2.14s/it]predicting train subjects:  28%|██▊       | 147/532 [05:01<13:41,  2.13s/it]predicting train subjects:  28%|██▊       | 148/532 [05:03<13:28,  2.11s/it]predicting train subjects:  28%|██▊       | 149/532 [05:05<13:54,  2.18s/it]predicting train subjects:  28%|██▊       | 150/532 [05:07<13:40,  2.15s/it]predicting train subjects:  28%|██▊       | 151/532 [05:09<13:23,  2.11s/it]predicting train subjects:  29%|██▊       | 152/532 [05:11<13:15,  2.09s/it]predicting train subjects:  29%|██▉       | 153/532 [05:13<13:24,  2.12s/it]predicting train subjects:  29%|██▉       | 154/532 [05:15<13:15,  2.11s/it]predicting train subjects:  29%|██▉       | 155/532 [05:18<14:42,  2.34s/it]predicting train subjects:  29%|██▉       | 156/532 [05:21<15:06,  2.41s/it]predicting train subjects:  30%|██▉       | 157/532 [05:24<15:48,  2.53s/it]predicting train subjects:  30%|██▉       | 158/532 [05:26<16:17,  2.61s/it]predicting train subjects:  30%|██▉       | 159/532 [05:29<16:25,  2.64s/it]predicting train subjects:  30%|███       | 160/532 [05:32<16:30,  2.66s/it]predicting train subjects:  30%|███       | 161/532 [05:34<15:38,  2.53s/it]predicting train subjects:  30%|███       | 162/532 [05:36<14:53,  2.41s/it]predicting train subjects:  31%|███       | 163/532 [05:38<14:20,  2.33s/it]predicting train subjects:  31%|███       | 164/532 [05:41<13:58,  2.28s/it]predicting train subjects:  31%|███       | 165/532 [05:43<13:59,  2.29s/it]predicting train subjects:  31%|███       | 166/532 [05:45<13:35,  2.23s/it]predicting train subjects:  31%|███▏      | 167/532 [05:47<13:21,  2.20s/it]predicting train subjects:  32%|███▏      | 168/532 [05:49<13:19,  2.20s/it]predicting train subjects:  32%|███▏      | 169/532 [05:51<13:15,  2.19s/it]predicting train subjects:  32%|███▏      | 170/532 [05:54<13:12,  2.19s/it]predicting train subjects:  32%|███▏      | 171/532 [05:56<13:17,  2.21s/it]predicting train subjects:  32%|███▏      | 172/532 [05:58<13:29,  2.25s/it]predicting train subjects:  33%|███▎      | 173/532 [06:00<13:02,  2.18s/it]predicting train subjects:  33%|███▎      | 174/532 [06:02<12:51,  2.16s/it]predicting train subjects:  33%|███▎      | 175/532 [06:04<12:30,  2.10s/it]predicting train subjects:  33%|███▎      | 176/532 [06:06<12:14,  2.06s/it]predicting train subjects:  33%|███▎      | 177/532 [06:08<11:58,  2.02s/it]predicting train subjects:  33%|███▎      | 178/532 [06:10<11:47,  2.00s/it]predicting train subjects:  34%|███▎      | 179/532 [06:12<11:41,  1.99s/it]predicting train subjects:  34%|███▍      | 180/532 [06:14<11:43,  2.00s/it]predicting train subjects:  34%|███▍      | 181/532 [06:16<11:39,  1.99s/it]predicting train subjects:  34%|███▍      | 182/532 [06:18<11:49,  2.03s/it]predicting train subjects:  34%|███▍      | 183/532 [06:20<11:39,  2.00s/it]predicting train subjects:  35%|███▍      | 184/532 [06:22<11:46,  2.03s/it]predicting train subjects:  35%|███▍      | 185/532 [06:24<11:20,  1.96s/it]predicting train subjects:  35%|███▍      | 186/532 [06:26<11:20,  1.97s/it]predicting train subjects:  35%|███▌      | 187/532 [06:28<11:13,  1.95s/it]predicting train subjects:  35%|███▌      | 188/532 [06:30<11:15,  1.96s/it]predicting train subjects:  36%|███▌      | 189/532 [06:32<11:06,  1.94s/it]predicting train subjects:  36%|███▌      | 190/532 [06:34<10:49,  1.90s/it]predicting train subjects:  36%|███▌      | 191/532 [06:37<12:24,  2.18s/it]predicting train subjects:  36%|███▌      | 192/532 [06:39<13:37,  2.40s/it]predicting train subjects:  36%|███▋      | 193/532 [06:42<14:10,  2.51s/it]predicting train subjects:  36%|███▋      | 194/532 [06:45<14:41,  2.61s/it]predicting train subjects:  37%|███▋      | 195/532 [06:48<14:57,  2.66s/it]predicting train subjects:  37%|███▋      | 196/532 [06:51<15:08,  2.70s/it]predicting train subjects:  37%|███▋      | 197/532 [06:53<14:43,  2.64s/it]predicting train subjects:  37%|███▋      | 198/532 [06:56<14:16,  2.57s/it]predicting train subjects:  37%|███▋      | 199/532 [06:58<14:19,  2.58s/it]predicting train subjects:  38%|███▊      | 200/532 [07:00<13:53,  2.51s/it]predicting train subjects:  38%|███▊      | 201/532 [07:03<13:31,  2.45s/it]predicting train subjects:  38%|███▊      | 202/532 [07:05<13:26,  2.45s/it]predicting train subjects:  38%|███▊      | 203/532 [07:07<12:32,  2.29s/it]predicting train subjects:  38%|███▊      | 204/532 [07:09<11:37,  2.13s/it]predicting train subjects:  39%|███▊      | 205/532 [07:11<10:54,  2.00s/it]predicting train subjects:  39%|███▊      | 206/532 [07:12<10:30,  1.93s/it]predicting train subjects:  39%|███▉      | 207/532 [07:14<10:11,  1.88s/it]predicting train subjects:  39%|███▉      | 208/532 [07:16<09:58,  1.85s/it]predicting train subjects:  39%|███▉      | 209/532 [07:17<09:27,  1.76s/it]predicting train subjects:  39%|███▉      | 210/532 [07:19<09:06,  1.70s/it]predicting train subjects:  40%|███▉      | 211/532 [07:21<08:45,  1.64s/it]predicting train subjects:  40%|███▉      | 212/532 [07:22<08:35,  1.61s/it]predicting train subjects:  40%|████      | 213/532 [07:24<08:33,  1.61s/it]predicting train subjects:  40%|████      | 214/532 [07:25<08:48,  1.66s/it]predicting train subjects:  40%|████      | 215/532 [07:28<09:44,  1.84s/it]predicting train subjects:  41%|████      | 216/532 [07:30<10:25,  1.98s/it]predicting train subjects:  41%|████      | 217/532 [07:32<10:49,  2.06s/it]predicting train subjects:  41%|████      | 218/532 [07:35<11:10,  2.14s/it]predicting train subjects:  41%|████      | 219/532 [07:37<11:28,  2.20s/it]predicting train subjects:  41%|████▏     | 220/532 [07:39<11:32,  2.22s/it]predicting train subjects:  42%|████▏     | 221/532 [07:41<10:25,  2.01s/it]predicting train subjects:  42%|████▏     | 222/532 [07:42<09:32,  1.85s/it]predicting train subjects:  42%|████▏     | 223/532 [07:44<09:04,  1.76s/it]predicting train subjects:  42%|████▏     | 224/532 [07:45<08:41,  1.69s/it]predicting train subjects:  42%|████▏     | 225/532 [07:47<08:22,  1.64s/it]predicting train subjects:  42%|████▏     | 226/532 [07:48<08:10,  1.60s/it]predicting train subjects:  43%|████▎     | 227/532 [07:50<08:01,  1.58s/it]predicting train subjects:  43%|████▎     | 228/532 [07:51<07:52,  1.55s/it]predicting train subjects:  43%|████▎     | 229/532 [07:53<07:44,  1.53s/it]predicting train subjects:  43%|████▎     | 230/532 [07:54<07:37,  1.52s/it]predicting train subjects:  43%|████▎     | 231/532 [07:56<07:28,  1.49s/it]predicting train subjects:  44%|████▎     | 232/532 [07:57<07:23,  1.48s/it]predicting train subjects:  44%|████▍     | 233/532 [07:59<07:39,  1.54s/it]predicting train subjects:  44%|████▍     | 234/532 [08:01<07:54,  1.59s/it]predicting train subjects:  44%|████▍     | 235/532 [08:02<07:59,  1.61s/it]predicting train subjects:  44%|████▍     | 236/532 [08:04<08:13,  1.67s/it]predicting train subjects:  45%|████▍     | 237/532 [08:06<08:24,  1.71s/it]predicting train subjects:  45%|████▍     | 238/532 [08:08<08:28,  1.73s/it]predicting train subjects:  45%|████▍     | 239/532 [08:10<08:44,  1.79s/it]predicting train subjects:  45%|████▌     | 240/532 [08:11<08:45,  1.80s/it]predicting train subjects:  45%|████▌     | 241/532 [08:13<08:54,  1.84s/it]predicting train subjects:  45%|████▌     | 242/532 [08:15<08:59,  1.86s/it]predicting train subjects:  46%|████▌     | 243/532 [08:17<09:05,  1.89s/it]predicting train subjects:  46%|████▌     | 244/532 [08:19<09:02,  1.88s/it]predicting train subjects:  46%|████▌     | 245/532 [08:21<08:31,  1.78s/it]predicting train subjects:  46%|████▌     | 246/532 [08:22<08:00,  1.68s/it]predicting train subjects:  46%|████▋     | 247/532 [08:23<07:40,  1.61s/it]predicting train subjects:  47%|████▋     | 248/532 [08:25<07:24,  1.57s/it]predicting train subjects:  47%|████▋     | 249/532 [08:26<07:12,  1.53s/it]predicting train subjects:  47%|████▋     | 250/532 [08:28<07:10,  1.53s/it]predicting train subjects:  47%|████▋     | 251/532 [08:30<07:18,  1.56s/it]predicting train subjects:  47%|████▋     | 252/532 [08:31<07:16,  1.56s/it]predicting train subjects:  48%|████▊     | 253/532 [08:33<07:23,  1.59s/it]predicting train subjects:  48%|████▊     | 254/532 [08:34<07:21,  1.59s/it]predicting train subjects:  48%|████▊     | 255/532 [08:36<07:19,  1.59s/it]predicting train subjects:  48%|████▊     | 256/532 [08:38<07:20,  1.60s/it]predicting train subjects:  48%|████▊     | 257/532 [08:40<07:59,  1.74s/it]predicting train subjects:  48%|████▊     | 258/532 [08:42<08:29,  1.86s/it]predicting train subjects:  49%|████▊     | 259/532 [08:44<09:00,  1.98s/it]predicting train subjects:  49%|████▉     | 260/532 [08:46<09:09,  2.02s/it]predicting train subjects:  49%|████▉     | 261/532 [08:48<09:12,  2.04s/it]predicting train subjects:  49%|████▉     | 262/532 [08:50<09:14,  2.05s/it]predicting train subjects:  49%|████▉     | 263/532 [08:52<08:31,  1.90s/it]predicting train subjects:  50%|████▉     | 264/532 [08:53<07:53,  1.77s/it]predicting train subjects:  50%|████▉     | 265/532 [08:55<07:24,  1.66s/it]predicting train subjects:  50%|█████     | 266/532 [08:56<07:02,  1.59s/it]predicting train subjects:  50%|█████     | 267/532 [08:58<06:57,  1.57s/it]predicting train subjects:  50%|█████     | 268/532 [08:59<06:46,  1.54s/it]predicting train subjects:  51%|█████     | 269/532 [09:01<07:10,  1.64s/it]predicting train subjects:  51%|█████     | 270/532 [09:03<07:19,  1.68s/it]predicting train subjects:  51%|█████     | 271/532 [09:05<07:34,  1.74s/it]predicting train subjects:  51%|█████     | 272/532 [09:07<07:44,  1.78s/it]predicting train subjects:  51%|█████▏    | 273/532 [09:08<07:46,  1.80s/it]predicting train subjects:  52%|█████▏    | 274/532 [09:10<07:54,  1.84s/it]predicting train subjects:  52%|█████▏    | 275/532 [09:13<08:27,  1.97s/it]predicting train subjects:  52%|█████▏    | 276/532 [09:15<09:00,  2.11s/it]predicting train subjects:  52%|█████▏    | 277/532 [09:17<09:11,  2.16s/it]predicting train subjects:  52%|█████▏    | 278/532 [09:20<09:26,  2.23s/it]predicting train subjects:  52%|█████▏    | 279/532 [09:22<09:30,  2.25s/it]predicting train subjects:  53%|█████▎    | 280/532 [09:24<09:31,  2.27s/it]predicting train subjects:  53%|█████▎    | 281/532 [09:26<09:19,  2.23s/it]predicting train subjects:  53%|█████▎    | 282/532 [09:29<09:11,  2.21s/it]predicting train subjects:  53%|█████▎    | 283/532 [09:31<09:06,  2.20s/it]predicting train subjects:  53%|█████▎    | 284/532 [09:33<09:03,  2.19s/it]predicting train subjects:  54%|█████▎    | 285/532 [09:35<08:59,  2.19s/it]predicting train subjects:  54%|█████▍    | 286/532 [09:37<08:53,  2.17s/it]predicting train subjects:  54%|█████▍    | 287/532 [09:39<08:08,  1.99s/it]predicting train subjects:  54%|█████▍    | 288/532 [09:40<07:37,  1.88s/it]predicting train subjects:  54%|█████▍    | 289/532 [09:42<07:15,  1.79s/it]predicting train subjects:  55%|█████▍    | 290/532 [09:44<07:02,  1.75s/it]predicting train subjects:  55%|█████▍    | 291/532 [09:45<06:45,  1.68s/it]predicting train subjects:  55%|█████▍    | 292/532 [09:47<06:49,  1.71s/it]predicting train subjects:  55%|█████▌    | 293/532 [09:49<06:54,  1.74s/it]predicting train subjects:  55%|█████▌    | 294/532 [09:51<07:04,  1.79s/it]predicting train subjects:  55%|█████▌    | 295/532 [09:53<07:07,  1.81s/it]predicting train subjects:  56%|█████▌    | 296/532 [09:54<07:13,  1.84s/it]predicting train subjects:  56%|█████▌    | 297/532 [09:56<07:08,  1.82s/it]predicting train subjects:  56%|█████▌    | 298/532 [09:58<07:17,  1.87s/it]predicting train subjects:  56%|█████▌    | 299/532 [10:00<07:00,  1.81s/it]predicting train subjects:  56%|█████▋    | 300/532 [10:01<06:40,  1.73s/it]predicting train subjects:  57%|█████▋    | 301/532 [10:03<06:25,  1.67s/it]predicting train subjects:  57%|█████▋    | 302/532 [10:04<06:11,  1.61s/it]predicting train subjects:  57%|█████▋    | 303/532 [10:06<05:58,  1.57s/it]predicting train subjects:  57%|█████▋    | 304/532 [10:07<05:56,  1.56s/it]predicting train subjects:  57%|█████▋    | 305/532 [10:10<06:52,  1.82s/it]predicting train subjects:  58%|█████▊    | 306/532 [10:12<07:26,  1.97s/it]predicting train subjects:  58%|█████▊    | 307/532 [10:14<07:44,  2.06s/it]predicting train subjects:  58%|█████▊    | 308/532 [10:17<07:52,  2.11s/it]predicting train subjects:  58%|█████▊    | 309/532 [10:19<08:01,  2.16s/it]predicting train subjects:  58%|█████▊    | 310/532 [10:21<08:02,  2.17s/it]predicting train subjects:  58%|█████▊    | 311/532 [10:24<08:50,  2.40s/it]predicting train subjects:  59%|█████▊    | 312/532 [10:27<09:24,  2.57s/it]predicting train subjects:  59%|█████▉    | 313/532 [10:30<09:48,  2.69s/it]predicting train subjects:  59%|█████▉    | 314/532 [10:33<10:13,  2.81s/it]predicting train subjects:  59%|█████▉    | 315/532 [10:36<10:20,  2.86s/it]predicting train subjects:  59%|█████▉    | 316/532 [10:39<10:23,  2.89s/it]predicting train subjects:  60%|█████▉    | 317/532 [10:41<09:02,  2.52s/it]predicting train subjects:  60%|█████▉    | 318/532 [10:43<08:13,  2.30s/it]predicting train subjects:  60%|█████▉    | 319/532 [10:44<07:34,  2.14s/it]predicting train subjects:  60%|██████    | 320/532 [10:46<07:08,  2.02s/it]predicting train subjects:  60%|██████    | 321/532 [10:48<06:46,  1.92s/it]predicting train subjects:  61%|██████    | 322/532 [10:49<06:30,  1.86s/it]predicting train subjects:  61%|██████    | 323/532 [10:52<06:59,  2.01s/it]predicting train subjects:  61%|██████    | 324/532 [10:54<07:25,  2.14s/it]predicting train subjects:  61%|██████    | 325/532 [10:57<07:38,  2.22s/it]predicting train subjects:  61%|██████▏   | 326/532 [10:59<07:52,  2.30s/it]predicting train subjects:  61%|██████▏   | 327/532 [11:02<08:07,  2.38s/it]predicting train subjects:  62%|██████▏   | 328/532 [11:04<08:04,  2.38s/it]predicting train subjects:  62%|██████▏   | 329/532 [11:06<07:28,  2.21s/it]predicting train subjects:  62%|██████▏   | 330/532 [11:08<07:08,  2.12s/it]predicting train subjects:  62%|██████▏   | 331/532 [11:10<06:47,  2.03s/it]predicting train subjects:  62%|██████▏   | 332/532 [11:11<06:32,  1.96s/it]predicting train subjects:  63%|██████▎   | 333/532 [11:13<06:19,  1.90s/it]predicting train subjects:  63%|██████▎   | 334/532 [11:15<06:13,  1.89s/it]predicting train subjects:  63%|██████▎   | 335/532 [11:17<06:27,  1.97s/it]predicting train subjects:  63%|██████▎   | 336/532 [11:19<06:35,  2.02s/it]predicting train subjects:  63%|██████▎   | 337/532 [11:22<06:53,  2.12s/it]predicting train subjects:  64%|██████▎   | 338/532 [11:24<06:54,  2.13s/it]predicting train subjects:  64%|██████▎   | 339/532 [11:26<06:48,  2.12s/it]predicting train subjects:  64%|██████▍   | 340/532 [11:28<06:47,  2.12s/it]predicting train subjects:  64%|██████▍   | 341/532 [11:30<06:14,  1.96s/it]predicting train subjects:  64%|██████▍   | 342/532 [11:31<05:55,  1.87s/it]predicting train subjects:  64%|██████▍   | 343/532 [11:33<05:37,  1.79s/it]predicting train subjects:  65%|██████▍   | 344/532 [11:34<05:24,  1.73s/it]predicting train subjects:  65%|██████▍   | 345/532 [11:36<05:15,  1.69s/it]predicting train subjects:  65%|██████▌   | 346/532 [11:38<05:10,  1.67s/it]predicting train subjects:  65%|██████▌   | 347/532 [11:40<05:18,  1.72s/it]predicting train subjects:  65%|██████▌   | 348/532 [11:41<05:21,  1.75s/it]predicting train subjects:  66%|██████▌   | 349/532 [11:43<05:19,  1.75s/it]predicting train subjects:  66%|██████▌   | 350/532 [11:45<05:23,  1.78s/it]predicting train subjects:  66%|██████▌   | 351/532 [11:47<05:27,  1.81s/it]predicting train subjects:  66%|██████▌   | 352/532 [11:49<05:29,  1.83s/it]predicting train subjects:  66%|██████▋   | 353/532 [11:50<05:25,  1.82s/it]predicting train subjects:  67%|██████▋   | 354/532 [11:52<05:23,  1.82s/it]predicting train subjects:  67%|██████▋   | 355/532 [11:54<05:15,  1.78s/it]predicting train subjects:  67%|██████▋   | 356/532 [11:56<05:14,  1.79s/it]predicting train subjects:  67%|██████▋   | 357/532 [11:58<05:15,  1.80s/it]predicting train subjects:  67%|██████▋   | 358/532 [12:00<05:17,  1.83s/it]predicting train subjects:  67%|██████▋   | 359/532 [12:01<05:02,  1.75s/it]predicting train subjects:  68%|██████▊   | 360/532 [12:03<04:54,  1.71s/it]predicting train subjects:  68%|██████▊   | 361/532 [12:04<04:44,  1.66s/it]predicting train subjects:  68%|██████▊   | 362/532 [12:06<04:38,  1.64s/it]predicting train subjects:  68%|██████▊   | 363/532 [12:07<04:34,  1.62s/it]predicting train subjects:  68%|██████▊   | 364/532 [12:09<04:32,  1.62s/it]predicting train subjects:  69%|██████▊   | 365/532 [12:11<04:24,  1.59s/it]predicting train subjects:  69%|██████▉   | 366/532 [12:12<04:27,  1.61s/it]predicting train subjects:  69%|██████▉   | 367/532 [12:14<04:25,  1.61s/it]predicting train subjects:  69%|██████▉   | 368/532 [12:15<04:24,  1.61s/it]predicting train subjects:  69%|██████▉   | 369/532 [12:17<04:24,  1.62s/it]predicting train subjects:  70%|██████▉   | 370/532 [12:19<04:23,  1.63s/it]predicting train subjects:  70%|██████▉   | 371/532 [12:21<04:58,  1.85s/it]predicting train subjects:  70%|██████▉   | 372/532 [12:23<05:16,  1.98s/it]predicting train subjects:  70%|███████   | 373/532 [12:26<05:28,  2.07s/it]predicting train subjects:  70%|███████   | 374/532 [12:28<05:36,  2.13s/it]predicting train subjects:  70%|███████   | 375/532 [12:30<05:46,  2.21s/it]predicting train subjects:  71%|███████   | 376/532 [12:33<05:44,  2.21s/it]predicting train subjects:  71%|███████   | 377/532 [12:35<05:32,  2.14s/it]predicting train subjects:  71%|███████   | 378/532 [12:36<05:15,  2.05s/it]predicting train subjects:  71%|███████   | 379/532 [12:38<05:03,  1.99s/it]predicting train subjects:  71%|███████▏  | 380/532 [12:40<04:51,  1.92s/it]predicting train subjects:  72%|███████▏  | 381/532 [12:42<04:44,  1.88s/it]predicting train subjects:  72%|███████▏  | 382/532 [12:44<04:39,  1.86s/it]predicting train subjects:  72%|███████▏  | 383/532 [12:45<04:38,  1.87s/it]predicting train subjects:  72%|███████▏  | 384/532 [12:47<04:36,  1.87s/it]predicting train subjects:  72%|███████▏  | 385/532 [12:49<04:34,  1.87s/it]predicting train subjects:  73%|███████▎  | 386/532 [12:51<04:31,  1.86s/it]predicting train subjects:  73%|███████▎  | 387/532 [12:53<04:28,  1.85s/it]predicting train subjects:  73%|███████▎  | 388/532 [12:55<04:26,  1.85s/it]predicting train subjects:  73%|███████▎  | 389/532 [12:57<04:28,  1.88s/it]predicting train subjects:  73%|███████▎  | 390/532 [12:59<04:29,  1.90s/it]predicting train subjects:  73%|███████▎  | 391/532 [13:01<04:37,  1.96s/it]predicting train subjects:  74%|███████▎  | 392/532 [13:03<04:38,  1.99s/it]predicting train subjects:  74%|███████▍  | 393/532 [13:05<04:42,  2.03s/it]predicting train subjects:  74%|███████▍  | 394/532 [13:07<04:39,  2.03s/it]predicting train subjects:  74%|███████▍  | 395/532 [13:09<04:31,  1.98s/it]predicting train subjects:  74%|███████▍  | 396/532 [13:11<04:27,  1.96s/it]predicting train subjects:  75%|███████▍  | 397/532 [13:13<04:22,  1.94s/it]predicting train subjects:  75%|███████▍  | 398/532 [13:15<04:18,  1.93s/it]predicting train subjects:  75%|███████▌  | 399/532 [13:16<04:15,  1.92s/it]predicting train subjects:  75%|███████▌  | 400/532 [13:18<04:13,  1.92s/it]predicting train subjects:  75%|███████▌  | 401/532 [13:20<04:21,  1.99s/it]predicting train subjects:  76%|███████▌  | 402/532 [13:23<04:22,  2.02s/it]predicting train subjects:  76%|███████▌  | 403/532 [13:25<04:23,  2.04s/it]predicting train subjects:  76%|███████▌  | 404/532 [13:27<04:20,  2.04s/it]predicting train subjects:  76%|███████▌  | 405/532 [13:29<04:17,  2.02s/it]predicting train subjects:  76%|███████▋  | 406/532 [13:31<04:13,  2.01s/it]predicting train subjects:  77%|███████▋  | 407/532 [13:32<04:03,  1.95s/it]predicting train subjects:  77%|███████▋  | 408/532 [13:34<03:54,  1.89s/it]predicting train subjects:  77%|███████▋  | 409/532 [13:36<03:48,  1.86s/it]predicting train subjects:  77%|███████▋  | 410/532 [13:38<03:46,  1.86s/it]predicting train subjects:  77%|███████▋  | 411/532 [13:40<03:41,  1.83s/it]predicting train subjects:  77%|███████▋  | 412/532 [13:41<03:39,  1.83s/it]predicting train subjects:  78%|███████▊  | 413/532 [13:43<03:33,  1.79s/it]predicting train subjects:  78%|███████▊  | 414/532 [13:45<03:24,  1.74s/it]predicting train subjects:  78%|███████▊  | 415/532 [13:46<03:20,  1.72s/it]predicting train subjects:  78%|███████▊  | 416/532 [13:48<03:18,  1.71s/it]predicting train subjects:  78%|███████▊  | 417/532 [13:50<03:15,  1.70s/it]predicting train subjects:  79%|███████▊  | 418/532 [13:52<03:14,  1.70s/it]predicting train subjects:  79%|███████▉  | 419/532 [13:53<03:19,  1.76s/it]predicting train subjects:  79%|███████▉  | 420/532 [13:55<03:21,  1.80s/it]predicting train subjects:  79%|███████▉  | 421/532 [13:57<03:25,  1.85s/it]predicting train subjects:  79%|███████▉  | 422/532 [13:59<03:25,  1.87s/it]predicting train subjects:  80%|███████▉  | 423/532 [14:01<03:30,  1.93s/it]predicting train subjects:  80%|███████▉  | 424/532 [14:03<03:28,  1.93s/it]predicting train subjects:  80%|███████▉  | 425/532 [14:05<03:30,  1.96s/it]predicting train subjects:  80%|████████  | 426/532 [14:07<03:29,  1.98s/it]predicting train subjects:  80%|████████  | 427/532 [14:09<03:28,  1.98s/it]predicting train subjects:  80%|████████  | 428/532 [14:11<03:24,  1.97s/it]predicting train subjects:  81%|████████  | 429/532 [14:13<03:21,  1.96s/it]predicting train subjects:  81%|████████  | 430/532 [14:15<03:19,  1.96s/it]predicting train subjects:  81%|████████  | 431/532 [14:17<03:22,  2.00s/it]predicting train subjects:  81%|████████  | 432/532 [14:19<03:26,  2.07s/it]predicting train subjects:  81%|████████▏ | 433/532 [14:21<03:23,  2.05s/it]predicting train subjects:  82%|████████▏ | 434/532 [14:24<03:23,  2.08s/it]predicting train subjects:  82%|████████▏ | 435/532 [14:26<03:19,  2.06s/it]predicting train subjects:  82%|████████▏ | 436/532 [14:28<03:17,  2.06s/it]predicting train subjects:  82%|████████▏ | 437/532 [14:29<03:00,  1.90s/it]predicting train subjects:  82%|████████▏ | 438/532 [14:31<02:50,  1.82s/it]predicting train subjects:  83%|████████▎ | 439/532 [14:32<02:43,  1.76s/it]predicting train subjects:  83%|████████▎ | 440/532 [14:34<02:37,  1.71s/it]predicting train subjects:  83%|████████▎ | 441/532 [14:36<02:33,  1.69s/it]predicting train subjects:  83%|████████▎ | 442/532 [14:37<02:28,  1.65s/it]predicting train subjects:  83%|████████▎ | 443/532 [14:39<02:22,  1.60s/it]predicting train subjects:  83%|████████▎ | 444/532 [14:40<02:21,  1.61s/it]predicting train subjects:  84%|████████▎ | 445/532 [14:42<02:16,  1.57s/it]predicting train subjects:  84%|████████▍ | 446/532 [14:43<02:10,  1.52s/it]predicting train subjects:  84%|████████▍ | 447/532 [14:45<02:08,  1.51s/it]predicting train subjects:  84%|████████▍ | 448/532 [14:46<02:05,  1.50s/it]predicting train subjects:  84%|████████▍ | 449/532 [14:48<02:11,  1.58s/it]predicting train subjects:  85%|████████▍ | 450/532 [14:50<02:10,  1.59s/it]predicting train subjects:  85%|████████▍ | 451/532 [14:51<02:10,  1.61s/it]predicting train subjects:  85%|████████▍ | 452/532 [14:53<02:10,  1.63s/it]predicting train subjects:  85%|████████▌ | 453/532 [14:55<02:08,  1.63s/it]predicting train subjects:  85%|████████▌ | 454/532 [14:56<02:06,  1.62s/it]predicting train subjects:  86%|████████▌ | 455/532 [14:58<02:11,  1.70s/it]predicting train subjects:  86%|████████▌ | 456/532 [15:00<02:14,  1.77s/it]predicting train subjects:  86%|████████▌ | 457/532 [15:02<02:15,  1.81s/it]predicting train subjects:  86%|████████▌ | 458/532 [15:04<02:15,  1.84s/it]predicting train subjects:  86%|████████▋ | 459/532 [15:06<02:15,  1.85s/it]predicting train subjects:  86%|████████▋ | 460/532 [15:08<02:13,  1.86s/it]predicting train subjects:  87%|████████▋ | 461/532 [15:10<02:25,  2.05s/it]predicting train subjects:  87%|████████▋ | 462/532 [15:12<02:27,  2.11s/it]predicting train subjects:  87%|████████▋ | 463/532 [15:15<02:29,  2.17s/it]predicting train subjects:  87%|████████▋ | 464/532 [15:17<02:27,  2.17s/it]predicting train subjects:  87%|████████▋ | 465/532 [15:19<02:29,  2.23s/it]predicting train subjects:  88%|████████▊ | 466/532 [15:21<02:27,  2.24s/it]predicting train subjects:  88%|████████▊ | 467/532 [15:23<02:18,  2.12s/it]predicting train subjects:  88%|████████▊ | 468/532 [15:25<02:10,  2.04s/it]predicting train subjects:  88%|████████▊ | 469/532 [15:27<02:06,  2.01s/it]predicting train subjects:  88%|████████▊ | 470/532 [15:29<01:59,  1.93s/it]predicting train subjects:  89%|████████▊ | 471/532 [15:31<01:55,  1.89s/it]predicting train subjects:  89%|████████▊ | 472/532 [15:32<01:50,  1.84s/it]predicting train subjects:  89%|████████▉ | 473/532 [15:34<01:50,  1.88s/it]predicting train subjects:  89%|████████▉ | 474/532 [15:36<01:50,  1.90s/it]predicting train subjects:  89%|████████▉ | 475/532 [15:38<01:49,  1.92s/it]predicting train subjects:  89%|████████▉ | 476/532 [15:40<01:47,  1.93s/it]predicting train subjects:  90%|████████▉ | 477/532 [15:42<01:48,  1.97s/it]predicting train subjects:  90%|████████▉ | 478/532 [15:44<01:49,  2.03s/it]predicting train subjects:  90%|█████████ | 479/532 [15:46<01:41,  1.92s/it]predicting train subjects:  90%|█████████ | 480/532 [15:48<01:35,  1.84s/it]predicting train subjects:  90%|█████████ | 481/532 [15:49<01:33,  1.83s/it]predicting train subjects:  91%|█████████ | 482/532 [15:51<01:29,  1.78s/it]predicting train subjects:  91%|█████████ | 483/532 [15:53<01:24,  1.73s/it]predicting train subjects:  91%|█████████ | 484/532 [15:54<01:21,  1.70s/it]predicting train subjects:  91%|█████████ | 485/532 [15:57<01:26,  1.84s/it]predicting train subjects:  91%|█████████▏| 486/532 [15:59<01:27,  1.91s/it]predicting train subjects:  92%|█████████▏| 487/532 [16:01<01:29,  1.98s/it]predicting train subjects:  92%|█████████▏| 488/532 [16:03<01:29,  2.04s/it]predicting train subjects:  92%|█████████▏| 489/532 [16:05<01:29,  2.08s/it]predicting train subjects:  92%|█████████▏| 490/532 [16:07<01:29,  2.13s/it]predicting train subjects:  92%|█████████▏| 491/532 [16:09<01:23,  2.04s/it]predicting train subjects:  92%|█████████▏| 492/532 [16:11<01:18,  1.97s/it]predicting train subjects:  93%|█████████▎| 493/532 [16:13<01:14,  1.90s/it]predicting train subjects:  93%|█████████▎| 494/532 [16:15<01:11,  1.89s/it]predicting train subjects:  93%|█████████▎| 495/532 [16:16<01:08,  1.86s/it]predicting train subjects:  93%|█████████▎| 496/532 [16:18<01:08,  1.91s/it]predicting train subjects:  93%|█████████▎| 497/532 [16:20<01:07,  1.93s/it]predicting train subjects:  94%|█████████▎| 498/532 [16:22<01:05,  1.92s/it]predicting train subjects:  94%|█████████▍| 499/532 [16:24<01:03,  1.92s/it]predicting train subjects:  94%|█████████▍| 500/532 [16:26<01:02,  1.95s/it]predicting train subjects:  94%|█████████▍| 501/532 [16:28<01:00,  1.94s/it]predicting train subjects:  94%|█████████▍| 502/532 [16:30<00:57,  1.92s/it]predicting train subjects:  95%|█████████▍| 503/532 [16:32<00:53,  1.86s/it]predicting train subjects:  95%|█████████▍| 504/532 [16:33<00:50,  1.80s/it]predicting train subjects:  95%|█████████▍| 505/532 [16:35<00:47,  1.75s/it]predicting train subjects:  95%|█████████▌| 506/532 [16:37<00:46,  1.77s/it]predicting train subjects:  95%|█████████▌| 507/532 [16:39<00:43,  1.75s/it]predicting train subjects:  95%|█████████▌| 508/532 [16:40<00:40,  1.71s/it]predicting train subjects:  96%|█████████▌| 509/532 [16:42<00:41,  1.81s/it]predicting train subjects:  96%|█████████▌| 510/532 [16:44<00:41,  1.90s/it]predicting train subjects:  96%|█████████▌| 511/532 [16:46<00:41,  1.98s/it]predicting train subjects:  96%|█████████▌| 512/532 [16:49<00:40,  2.05s/it]predicting train subjects:  96%|█████████▋| 513/532 [16:51<00:39,  2.08s/it]predicting train subjects:  97%|█████████▋| 514/532 [16:53<00:37,  2.09s/it]predicting train subjects:  97%|█████████▋| 515/532 [16:55<00:33,  2.00s/it]predicting train subjects:  97%|█████████▋| 516/532 [16:56<00:30,  1.92s/it]predicting train subjects:  97%|█████████▋| 517/532 [16:58<00:28,  1.88s/it]predicting train subjects:  97%|█████████▋| 518/532 [17:00<00:26,  1.87s/it]predicting train subjects:  98%|█████████▊| 519/532 [17:02<00:23,  1.84s/it]predicting train subjects:  98%|█████████▊| 520/532 [17:04<00:22,  1.84s/it]predicting train subjects:  98%|█████████▊| 521/532 [17:06<00:20,  1.89s/it]predicting train subjects:  98%|█████████▊| 522/532 [17:08<00:19,  1.92s/it]predicting train subjects:  98%|█████████▊| 523/532 [17:10<00:17,  1.92s/it]predicting train subjects:  98%|█████████▊| 524/532 [17:12<00:15,  1.93s/it]predicting train subjects:  99%|█████████▊| 525/532 [17:14<00:13,  1.96s/it]predicting train subjects:  99%|█████████▉| 526/532 [17:15<00:11,  1.93s/it]predicting train subjects:  99%|█████████▉| 527/532 [17:17<00:09,  1.87s/it]predicting train subjects:  99%|█████████▉| 528/532 [17:19<00:07,  1.81s/it]predicting train subjects:  99%|█████████▉| 529/532 [17:21<00:05,  1.77s/it]predicting train subjects: 100%|█████████▉| 530/532 [17:22<00:03,  1.74s/it]predicting train subjects: 100%|█████████▉| 531/532 [17:24<00:01,  1.75s/it]predicting train subjects: 100%|██████████| 532/532 [17:26<00:00,  1.76s/it]
Loading train:   0%|          | 0/532 [00:00<?, ?it/s]Loading train:   0%|          | 1/532 [00:01<12:53,  1.46s/it]Loading train:   0%|          | 2/532 [00:02<11:49,  1.34s/it]Loading train:   1%|          | 3/532 [00:03<11:14,  1.28s/it]Loading train:   1%|          | 4/532 [00:04<11:21,  1.29s/it]Loading train:   1%|          | 5/532 [00:06<11:07,  1.27s/it]Loading train:   1%|          | 6/532 [00:07<10:26,  1.19s/it]Loading train:   1%|▏         | 7/532 [00:08<09:45,  1.12s/it]Loading train:   2%|▏         | 8/532 [00:09<10:28,  1.20s/it]Loading train:   2%|▏         | 9/532 [00:10<10:55,  1.25s/it]Loading train:   2%|▏         | 10/532 [00:12<10:43,  1.23s/it]Loading train:   2%|▏         | 11/532 [00:13<10:01,  1.15s/it]Loading train:   2%|▏         | 12/532 [00:14<10:26,  1.21s/it]Loading train:   2%|▏         | 13/532 [00:15<09:47,  1.13s/it]Loading train:   3%|▎         | 14/532 [00:16<09:30,  1.10s/it]Loading train:   3%|▎         | 15/532 [00:17<09:39,  1.12s/it]Loading train:   3%|▎         | 16/532 [00:18<10:03,  1.17s/it]Loading train:   3%|▎         | 17/532 [00:19<09:28,  1.10s/it]Loading train:   3%|▎         | 18/532 [00:21<09:48,  1.15s/it]Loading train:   4%|▎         | 19/532 [00:22<09:28,  1.11s/it]Loading train:   4%|▍         | 20/532 [00:23<09:39,  1.13s/it]Loading train:   4%|▍         | 21/532 [00:24<10:31,  1.24s/it]Loading train:   4%|▍         | 22/532 [00:25<10:26,  1.23s/it]Loading train:   4%|▍         | 23/532 [00:27<10:40,  1.26s/it]Loading train:   5%|▍         | 24/532 [00:28<10:31,  1.24s/it]Loading train:   5%|▍         | 25/532 [00:29<11:04,  1.31s/it]Loading train:   5%|▍         | 26/532 [00:31<10:43,  1.27s/it]Loading train:   5%|▌         | 27/532 [00:32<11:21,  1.35s/it]Loading train:   5%|▌         | 28/532 [00:33<10:41,  1.27s/it]Loading train:   5%|▌         | 29/532 [00:34<10:34,  1.26s/it]Loading train:   6%|▌         | 30/532 [00:35<09:55,  1.19s/it]Loading train:   6%|▌         | 31/532 [00:37<09:37,  1.15s/it]Loading train:   6%|▌         | 32/532 [00:38<09:28,  1.14s/it]Loading train:   6%|▌         | 33/532 [00:39<09:04,  1.09s/it]Loading train:   6%|▋         | 34/532 [00:41<11:09,  1.35s/it]Loading train:   7%|▋         | 35/532 [00:42<11:26,  1.38s/it]Loading train:   7%|▋         | 36/532 [00:44<11:45,  1.42s/it]Loading train:   7%|▋         | 37/532 [00:45<12:14,  1.48s/it]Loading train:   7%|▋         | 38/532 [00:47<13:05,  1.59s/it]Loading train:   7%|▋         | 39/532 [00:48<12:46,  1.55s/it]Loading train:   8%|▊         | 40/532 [00:50<12:57,  1.58s/it]Loading train:   8%|▊         | 41/532 [00:52<14:01,  1.71s/it]Loading train:   8%|▊         | 42/532 [00:54<14:45,  1.81s/it]Loading train:   8%|▊         | 43/532 [00:56<14:42,  1.80s/it]Loading train:   8%|▊         | 44/532 [00:57<13:32,  1.67s/it]Loading train:   8%|▊         | 45/532 [00:59<12:55,  1.59s/it]Loading train:   9%|▊         | 46/532 [01:01<13:49,  1.71s/it]Loading train:   9%|▉         | 47/532 [01:03<14:27,  1.79s/it]Loading train:   9%|▉         | 48/532 [01:05<15:26,  1.91s/it]Loading train:   9%|▉         | 49/532 [01:07<15:09,  1.88s/it]Loading train:   9%|▉         | 50/532 [01:09<16:04,  2.00s/it]Loading train:  10%|▉         | 51/532 [01:11<15:44,  1.96s/it]Loading train:  10%|▉         | 52/532 [01:13<15:41,  1.96s/it]Loading train:  10%|▉         | 53/532 [01:15<15:01,  1.88s/it]Loading train:  10%|█         | 54/532 [01:16<15:11,  1.91s/it]Loading train:  10%|█         | 55/532 [01:19<16:13,  2.04s/it]Loading train:  11%|█         | 56/532 [01:21<15:17,  1.93s/it]Loading train:  11%|█         | 57/532 [01:22<15:01,  1.90s/it]Loading train:  11%|█         | 58/532 [01:25<15:39,  1.98s/it]Loading train:  11%|█         | 59/532 [01:27<16:29,  2.09s/it]Loading train:  11%|█▏        | 60/532 [01:29<15:51,  2.02s/it]Loading train:  11%|█▏        | 61/532 [01:30<14:31,  1.85s/it]Loading train:  12%|█▏        | 62/532 [01:32<14:29,  1.85s/it]Loading train:  12%|█▏        | 63/532 [01:34<15:06,  1.93s/it]Loading train:  12%|█▏        | 64/532 [01:36<15:31,  1.99s/it]Loading train:  12%|█▏        | 65/532 [01:38<14:53,  1.91s/it]Loading train:  12%|█▏        | 66/532 [01:40<14:38,  1.88s/it]Loading train:  13%|█▎        | 67/532 [01:42<15:26,  1.99s/it]Loading train:  13%|█▎        | 68/532 [01:44<14:08,  1.83s/it]Loading train:  13%|█▎        | 69/532 [01:45<14:01,  1.82s/it]Loading train:  13%|█▎        | 70/532 [01:47<14:37,  1.90s/it]Loading train:  13%|█▎        | 71/532 [01:50<15:15,  1.99s/it]Loading train:  14%|█▎        | 72/532 [01:51<14:47,  1.93s/it]Loading train:  14%|█▎        | 73/532 [01:54<15:25,  2.02s/it]Loading train:  14%|█▍        | 74/532 [01:56<15:27,  2.02s/it]Loading train:  14%|█▍        | 75/532 [01:58<16:47,  2.20s/it]Loading train:  14%|█▍        | 76/532 [02:00<15:22,  2.02s/it]Loading train:  14%|█▍        | 77/532 [02:02<15:13,  2.01s/it]Loading train:  15%|█▍        | 78/532 [02:04<15:46,  2.08s/it]Loading train:  15%|█▍        | 79/532 [02:06<15:23,  2.04s/it]Loading train:  15%|█▌        | 80/532 [02:08<14:19,  1.90s/it]Loading train:  15%|█▌        | 81/532 [02:09<13:16,  1.77s/it]Loading train:  15%|█▌        | 82/532 [02:11<13:24,  1.79s/it]Loading train:  16%|█▌        | 83/532 [02:13<14:08,  1.89s/it]Loading train:  16%|█▌        | 84/532 [02:15<13:33,  1.81s/it]Loading train:  16%|█▌        | 85/532 [02:16<13:31,  1.81s/it]Loading train:  16%|█▌        | 86/532 [02:18<13:36,  1.83s/it]Loading train:  16%|█▋        | 87/532 [02:20<13:48,  1.86s/it]Loading train:  17%|█▋        | 88/532 [02:22<13:36,  1.84s/it]Loading train:  17%|█▋        | 89/532 [02:24<13:59,  1.89s/it]Loading train:  17%|█▋        | 90/532 [02:26<13:54,  1.89s/it]Loading train:  17%|█▋        | 91/532 [02:27<12:44,  1.73s/it]Loading train:  17%|█▋        | 92/532 [02:29<12:23,  1.69s/it]Loading train:  17%|█▋        | 93/532 [02:31<13:34,  1.86s/it]Loading train:  18%|█▊        | 94/532 [02:32<12:13,  1.67s/it]Loading train:  18%|█▊        | 95/532 [02:34<12:28,  1.71s/it]Loading train:  18%|█▊        | 96/532 [02:36<13:12,  1.82s/it]Loading train:  18%|█▊        | 97/532 [02:38<13:27,  1.86s/it]Loading train:  18%|█▊        | 98/532 [02:40<13:17,  1.84s/it]Loading train:  19%|█▊        | 99/532 [02:42<13:43,  1.90s/it]Loading train:  19%|█▉        | 100/532 [02:44<13:32,  1.88s/it]Loading train:  19%|█▉        | 101/532 [02:46<13:44,  1.91s/it]Loading train:  19%|█▉        | 102/532 [02:47<13:00,  1.81s/it]Loading train:  19%|█▉        | 103/532 [02:49<12:08,  1.70s/it]Loading train:  20%|█▉        | 104/532 [02:51<11:54,  1.67s/it]Loading train:  20%|█▉        | 105/532 [02:52<12:15,  1.72s/it]Loading train:  20%|█▉        | 106/532 [02:54<11:11,  1.58s/it]Loading train:  20%|██        | 107/532 [02:55<11:09,  1.58s/it]Loading train:  20%|██        | 108/532 [02:57<10:58,  1.55s/it]Loading train:  20%|██        | 109/532 [02:58<10:22,  1.47s/it]Loading train:  21%|██        | 110/532 [02:59<10:08,  1.44s/it]Loading train:  21%|██        | 111/532 [03:01<10:52,  1.55s/it]Loading train:  21%|██        | 112/532 [03:02<10:24,  1.49s/it]Loading train:  21%|██        | 113/532 [03:05<11:54,  1.70s/it]Loading train:  21%|██▏       | 114/532 [03:07<12:29,  1.79s/it]Loading train:  22%|██▏       | 115/532 [03:09<12:56,  1.86s/it]Loading train:  22%|██▏       | 116/532 [03:11<12:59,  1.87s/it]Loading train:  22%|██▏       | 117/532 [03:13<13:45,  1.99s/it]Loading train:  22%|██▏       | 118/532 [03:15<13:31,  1.96s/it]Loading train:  22%|██▏       | 119/532 [03:17<13:31,  1.97s/it]Loading train:  23%|██▎       | 120/532 [03:18<12:51,  1.87s/it]Loading train:  23%|██▎       | 121/532 [03:20<12:13,  1.78s/it]Loading train:  23%|██▎       | 122/532 [03:22<12:04,  1.77s/it]Loading train:  23%|██▎       | 123/532 [03:23<11:20,  1.66s/it]Loading train:  23%|██▎       | 124/532 [03:25<10:51,  1.60s/it]Loading train:  23%|██▎       | 125/532 [03:26<11:11,  1.65s/it]Loading train:  24%|██▎       | 126/532 [03:28<11:36,  1.71s/it]Loading train:  24%|██▍       | 127/532 [03:30<11:13,  1.66s/it]Loading train:  24%|██▍       | 128/532 [03:31<10:41,  1.59s/it]Loading train:  24%|██▍       | 129/532 [03:33<10:36,  1.58s/it]Loading train:  24%|██▍       | 130/532 [03:35<11:22,  1.70s/it]Loading train:  25%|██▍       | 131/532 [03:37<12:00,  1.80s/it]Loading train:  25%|██▍       | 132/532 [03:39<12:33,  1.88s/it]Loading train:  25%|██▌       | 133/532 [03:41<12:19,  1.85s/it]Loading train:  25%|██▌       | 134/532 [03:43<13:13,  1.99s/it]Loading train:  25%|██▌       | 135/532 [03:45<12:35,  1.90s/it]Loading train:  26%|██▌       | 136/532 [03:47<12:45,  1.93s/it]Loading train:  26%|██▌       | 137/532 [03:49<13:25,  2.04s/it]Loading train:  26%|██▌       | 138/532 [03:51<13:49,  2.11s/it]Loading train:  26%|██▌       | 139/532 [03:53<13:27,  2.05s/it]Loading train:  26%|██▋       | 140/532 [03:55<13:18,  2.04s/it]Loading train:  27%|██▋       | 141/532 [03:57<13:23,  2.06s/it]Loading train:  27%|██▋       | 142/532 [03:59<13:17,  2.04s/it]Loading train:  27%|██▋       | 143/532 [04:01<13:26,  2.07s/it]Loading train:  27%|██▋       | 144/532 [04:03<12:13,  1.89s/it]Loading train:  27%|██▋       | 145/532 [04:04<11:16,  1.75s/it]Loading train:  27%|██▋       | 146/532 [04:06<11:10,  1.74s/it]Loading train:  28%|██▊       | 147/532 [04:08<11:21,  1.77s/it]Loading train:  28%|██▊       | 148/532 [04:10<11:19,  1.77s/it]Loading train:  28%|██▊       | 149/532 [04:11<10:48,  1.69s/it]Loading train:  28%|██▊       | 150/532 [04:12<10:07,  1.59s/it]Loading train:  28%|██▊       | 151/532 [04:14<10:06,  1.59s/it]Loading train:  29%|██▊       | 152/532 [04:16<09:57,  1.57s/it]Loading train:  29%|██▉       | 153/532 [04:17<09:54,  1.57s/it]Loading train:  29%|██▉       | 154/532 [04:19<10:39,  1.69s/it]Loading train:  29%|██▉       | 155/532 [04:21<11:29,  1.83s/it]Loading train:  29%|██▉       | 156/532 [04:23<12:00,  1.92s/it]Loading train:  30%|██▉       | 157/532 [04:26<12:34,  2.01s/it]Loading train:  30%|██▉       | 158/532 [04:28<13:08,  2.11s/it]Loading train:  30%|██▉       | 159/532 [04:30<12:50,  2.06s/it]Loading train:  30%|███       | 160/532 [04:32<12:27,  2.01s/it]Loading train:  30%|███       | 161/532 [04:34<12:54,  2.09s/it]Loading train:  30%|███       | 162/532 [04:36<12:05,  1.96s/it]Loading train:  31%|███       | 163/532 [04:37<11:31,  1.87s/it]Loading train:  31%|███       | 164/532 [04:39<10:46,  1.76s/it]Loading train:  31%|███       | 165/532 [04:41<11:26,  1.87s/it]Loading train:  31%|███       | 166/532 [04:42<10:31,  1.72s/it]Loading train:  31%|███▏      | 167/532 [04:44<10:57,  1.80s/it]Loading train:  32%|███▏      | 168/532 [04:46<10:13,  1.69s/it]Loading train:  32%|███▏      | 169/532 [04:48<10:53,  1.80s/it]Loading train:  32%|███▏      | 170/532 [04:49<10:04,  1.67s/it]Loading train:  32%|███▏      | 171/532 [04:51<10:12,  1.70s/it]Loading train:  32%|███▏      | 172/532 [04:53<10:13,  1.70s/it]Loading train:  33%|███▎      | 173/532 [04:54<09:49,  1.64s/it]Loading train:  33%|███▎      | 174/532 [04:56<10:18,  1.73s/it]Loading train:  33%|███▎      | 175/532 [04:58<10:44,  1.81s/it]Loading train:  33%|███▎      | 176/532 [04:59<09:50,  1.66s/it]Loading train:  33%|███▎      | 177/532 [05:01<09:48,  1.66s/it]Loading train:  33%|███▎      | 178/532 [05:03<10:02,  1.70s/it]Loading train:  34%|███▎      | 179/532 [05:04<09:49,  1.67s/it]Loading train:  34%|███▍      | 180/532 [05:06<10:09,  1.73s/it]Loading train:  34%|███▍      | 181/532 [05:08<09:48,  1.68s/it]Loading train:  34%|███▍      | 182/532 [05:09<09:06,  1.56s/it]Loading train:  34%|███▍      | 183/532 [05:11<08:49,  1.52s/it]Loading train:  35%|███▍      | 184/532 [05:12<08:42,  1.50s/it]Loading train:  35%|███▍      | 185/532 [05:14<09:00,  1.56s/it]Loading train:  35%|███▍      | 186/532 [05:16<09:29,  1.65s/it]Loading train:  35%|███▌      | 187/532 [05:17<09:37,  1.67s/it]Loading train:  35%|███▌      | 188/532 [05:19<10:25,  1.82s/it]Loading train:  36%|███▌      | 189/532 [05:21<10:26,  1.83s/it]Loading train:  36%|███▌      | 190/532 [05:23<10:00,  1.76s/it]Loading train:  36%|███▌      | 191/532 [05:25<10:43,  1.89s/it]Loading train:  36%|███▌      | 192/532 [05:27<10:58,  1.94s/it]Loading train:  36%|███▋      | 193/532 [05:29<11:15,  1.99s/it]Loading train:  36%|███▋      | 194/532 [05:31<10:46,  1.91s/it]Loading train:  37%|███▋      | 195/532 [05:33<10:25,  1.86s/it]Loading train:  37%|███▋      | 196/532 [05:35<11:07,  1.99s/it]Loading train:  37%|███▋      | 197/532 [05:37<11:03,  1.98s/it]Loading train:  37%|███▋      | 198/532 [05:39<10:17,  1.85s/it]Loading train:  37%|███▋      | 199/532 [05:40<10:03,  1.81s/it]Loading train:  38%|███▊      | 200/532 [05:42<10:15,  1.85s/it]Loading train:  38%|███▊      | 201/532 [05:44<09:40,  1.75s/it]Loading train:  38%|███▊      | 202/532 [05:46<09:40,  1.76s/it]Loading train:  38%|███▊      | 203/532 [05:47<09:58,  1.82s/it]Loading train:  38%|███▊      | 204/532 [05:49<09:37,  1.76s/it]Loading train:  39%|███▊      | 205/532 [05:50<08:48,  1.62s/it]Loading train:  39%|███▊      | 206/532 [05:52<08:57,  1.65s/it]Loading train:  39%|███▉      | 207/532 [05:54<08:42,  1.61s/it]Loading train:  39%|███▉      | 208/532 [05:55<08:36,  1.59s/it]Loading train:  39%|███▉      | 209/532 [05:57<09:19,  1.73s/it]Loading train:  39%|███▉      | 210/532 [05:59<08:40,  1.62s/it]Loading train:  40%|███▉      | 211/532 [06:00<08:26,  1.58s/it]Loading train:  40%|███▉      | 212/532 [06:02<08:27,  1.59s/it]Loading train:  40%|████      | 213/532 [06:04<09:10,  1.72s/it]Loading train:  40%|████      | 214/532 [06:05<09:14,  1.74s/it]Loading train:  40%|████      | 215/532 [06:08<10:09,  1.92s/it]Loading train:  41%|████      | 216/532 [06:10<10:01,  1.90s/it]Loading train:  41%|████      | 217/532 [06:12<09:50,  1.88s/it]Loading train:  41%|████      | 218/532 [06:14<10:08,  1.94s/it]Loading train:  41%|████      | 219/532 [06:15<09:46,  1.87s/it]Loading train:  41%|████▏     | 220/532 [06:17<09:37,  1.85s/it]Loading train:  42%|████▏     | 221/532 [06:19<08:52,  1.71s/it]Loading train:  42%|████▏     | 222/532 [06:20<09:06,  1.76s/it]Loading train:  42%|████▏     | 223/532 [06:22<09:32,  1.85s/it]Loading train:  42%|████▏     | 224/532 [06:24<09:24,  1.83s/it]Loading train:  42%|████▏     | 225/532 [06:26<08:32,  1.67s/it]Loading train:  42%|████▏     | 226/532 [06:27<08:06,  1.59s/it]Loading train:  43%|████▎     | 227/532 [06:29<08:07,  1.60s/it]Loading train:  43%|████▎     | 228/532 [06:30<07:39,  1.51s/it]Loading train:  43%|████▎     | 229/532 [06:31<07:07,  1.41s/it]Loading train:  43%|████▎     | 230/532 [06:32<06:47,  1.35s/it]Loading train:  43%|████▎     | 231/532 [06:33<06:22,  1.27s/it]Loading train:  44%|████▎     | 232/532 [06:35<06:27,  1.29s/it]Loading train:  44%|████▍     | 233/532 [06:36<06:53,  1.38s/it]Loading train:  44%|████▍     | 234/532 [06:38<06:51,  1.38s/it]Loading train:  44%|████▍     | 235/532 [06:39<07:10,  1.45s/it]Loading train:  44%|████▍     | 236/532 [06:41<07:31,  1.53s/it]Loading train:  45%|████▍     | 237/532 [06:43<07:54,  1.61s/it]Loading train:  45%|████▍     | 238/532 [06:44<07:49,  1.60s/it]Loading train:  45%|████▍     | 239/532 [06:46<08:37,  1.77s/it]Loading train:  45%|████▌     | 240/532 [06:48<08:31,  1.75s/it]Loading train:  45%|████▌     | 241/532 [06:50<08:58,  1.85s/it]Loading train:  45%|████▌     | 242/532 [06:52<09:10,  1.90s/it]Loading train:  46%|████▌     | 243/532 [06:54<08:21,  1.73s/it]Loading train:  46%|████▌     | 244/532 [06:56<08:49,  1.84s/it]Loading train:  46%|████▌     | 245/532 [06:57<08:19,  1.74s/it]Loading train:  46%|████▌     | 246/532 [06:59<08:12,  1.72s/it]Loading train:  46%|████▋     | 247/532 [07:00<07:24,  1.56s/it]Loading train:  47%|████▋     | 248/532 [07:01<06:51,  1.45s/it]Loading train:  47%|████▋     | 249/532 [07:03<06:38,  1.41s/it]Loading train:  47%|████▋     | 250/532 [07:04<06:24,  1.37s/it]Loading train:  47%|████▋     | 251/532 [07:05<06:37,  1.42s/it]Loading train:  47%|████▋     | 252/532 [07:07<06:09,  1.32s/it]Loading train:  48%|████▊     | 253/532 [07:08<06:12,  1.34s/it]Loading train:  48%|████▊     | 254/532 [07:09<06:06,  1.32s/it]Loading train:  48%|████▊     | 255/532 [07:10<05:45,  1.25s/it]Loading train:  48%|████▊     | 256/532 [07:11<05:44,  1.25s/it]Loading train:  48%|████▊     | 257/532 [07:14<06:48,  1.49s/it]Loading train:  48%|████▊     | 258/532 [07:15<07:20,  1.61s/it]Loading train:  49%|████▊     | 259/532 [07:18<07:59,  1.75s/it]Loading train:  49%|████▉     | 260/532 [07:19<08:07,  1.79s/it]Loading train:  49%|████▉     | 261/532 [07:22<08:42,  1.93s/it]Loading train:  49%|████▉     | 262/532 [07:24<09:32,  2.12s/it]Loading train:  49%|████▉     | 263/532 [07:26<08:44,  1.95s/it]Loading train:  50%|████▉     | 264/532 [07:27<08:06,  1.81s/it]Loading train:  50%|████▉     | 265/532 [07:29<08:18,  1.87s/it]Loading train:  50%|█████     | 266/532 [07:31<07:48,  1.76s/it]Loading train:  50%|█████     | 267/532 [07:32<06:34,  1.49s/it]Loading train:  50%|█████     | 268/532 [07:33<05:52,  1.34s/it]Loading train:  51%|█████     | 269/532 [07:34<05:31,  1.26s/it]Loading train:  51%|█████     | 270/532 [07:35<05:14,  1.20s/it]Loading train:  51%|█████     | 271/532 [07:36<05:42,  1.31s/it]Loading train:  51%|█████     | 272/532 [07:38<06:20,  1.46s/it]Loading train:  51%|█████▏    | 273/532 [07:40<06:51,  1.59s/it]Loading train:  52%|█████▏    | 274/532 [07:41<06:02,  1.41s/it]Loading train:  52%|█████▏    | 275/532 [07:42<05:50,  1.36s/it]Loading train:  52%|█████▏    | 276/532 [07:43<05:36,  1.32s/it]Loading train:  52%|█████▏    | 277/532 [07:45<05:30,  1.30s/it]Loading train:  52%|█████▏    | 278/532 [07:46<05:24,  1.28s/it]Loading train:  52%|█████▏    | 279/532 [07:47<05:18,  1.26s/it]Loading train:  53%|█████▎    | 280/532 [07:48<05:12,  1.24s/it]Loading train:  53%|█████▎    | 281/532 [07:50<05:07,  1.22s/it]Loading train:  53%|█████▎    | 282/532 [07:51<04:55,  1.18s/it]Loading train:  53%|█████▎    | 283/532 [07:52<04:46,  1.15s/it]Loading train:  53%|█████▎    | 284/532 [07:53<04:43,  1.14s/it]Loading train:  54%|█████▎    | 285/532 [07:54<04:45,  1.15s/it]Loading train:  54%|█████▍    | 286/532 [07:55<04:42,  1.15s/it]Loading train:  54%|█████▍    | 287/532 [07:56<04:23,  1.08s/it]Loading train:  54%|█████▍    | 288/532 [07:57<04:13,  1.04s/it]Loading train:  54%|█████▍    | 289/532 [07:58<04:09,  1.03s/it]Loading train:  55%|█████▍    | 290/532 [07:59<04:05,  1.01s/it]Loading train:  55%|█████▍    | 291/532 [08:00<04:09,  1.03s/it]Loading train:  55%|█████▍    | 292/532 [08:01<04:08,  1.04s/it]Loading train:  55%|█████▌    | 293/532 [08:02<04:04,  1.02s/it]Loading train:  55%|█████▌    | 294/532 [08:03<04:00,  1.01s/it]Loading train:  55%|█████▌    | 295/532 [08:04<04:04,  1.03s/it]Loading train:  56%|█████▌    | 296/532 [08:05<04:04,  1.03s/it]Loading train:  56%|█████▌    | 297/532 [08:06<04:02,  1.03s/it]Loading train:  56%|█████▌    | 298/532 [08:07<04:03,  1.04s/it]Loading train:  56%|█████▌    | 299/532 [08:08<03:50,  1.01it/s]Loading train:  56%|█████▋    | 300/532 [08:09<03:39,  1.06it/s]Loading train:  57%|█████▋    | 301/532 [08:10<03:32,  1.09it/s]Loading train:  57%|█████▋    | 302/532 [08:11<03:30,  1.09it/s]Loading train:  57%|█████▋    | 303/532 [08:12<03:34,  1.07it/s]Loading train:  57%|█████▋    | 304/532 [08:13<03:31,  1.08it/s]Loading train:  57%|█████▋    | 305/532 [08:14<03:59,  1.05s/it]Loading train:  58%|█████▊    | 306/532 [08:15<04:11,  1.11s/it]Loading train:  58%|█████▊    | 307/532 [08:16<04:16,  1.14s/it]Loading train:  58%|█████▊    | 308/532 [08:18<04:22,  1.17s/it]Loading train:  58%|█████▊    | 309/532 [08:19<04:25,  1.19s/it]Loading train:  58%|█████▊    | 310/532 [08:20<04:29,  1.21s/it]Loading train:  58%|█████▊    | 311/532 [08:22<04:54,  1.33s/it]Loading train:  59%|█████▊    | 312/532 [08:23<05:12,  1.42s/it]Loading train:  59%|█████▉    | 313/532 [08:25<05:23,  1.48s/it]Loading train:  59%|█████▉    | 314/532 [08:27<05:26,  1.50s/it]Loading train:  59%|█████▉    | 315/532 [08:28<05:32,  1.53s/it]Loading train:  59%|█████▉    | 316/532 [08:30<05:28,  1.52s/it]Loading train:  60%|█████▉    | 317/532 [08:31<04:54,  1.37s/it]Loading train:  60%|█████▉    | 318/532 [08:32<04:28,  1.25s/it]Loading train:  60%|█████▉    | 319/532 [08:33<04:20,  1.22s/it]Loading train:  60%|██████    | 320/532 [08:34<04:07,  1.17s/it]Loading train:  60%|██████    | 321/532 [08:35<03:54,  1.11s/it]Loading train:  61%|██████    | 322/532 [08:36<03:42,  1.06s/it]Loading train:  61%|██████    | 323/532 [08:37<03:59,  1.15s/it]Loading train:  61%|██████    | 324/532 [08:38<04:08,  1.19s/it]Loading train:  61%|██████    | 325/532 [08:40<04:12,  1.22s/it]Loading train:  61%|██████▏   | 326/532 [08:41<04:18,  1.25s/it]Loading train:  61%|██████▏   | 327/532 [08:42<04:13,  1.23s/it]Loading train:  62%|██████▏   | 328/532 [08:44<04:11,  1.23s/it]Loading train:  62%|██████▏   | 329/532 [08:45<04:02,  1.20s/it]Loading train:  62%|██████▏   | 330/532 [08:46<03:52,  1.15s/it]Loading train:  62%|██████▏   | 331/532 [08:47<03:45,  1.12s/it]Loading train:  62%|██████▏   | 332/532 [08:48<03:36,  1.08s/it]Loading train:  63%|██████▎   | 333/532 [08:49<03:32,  1.07s/it]Loading train:  63%|██████▎   | 334/532 [08:50<03:28,  1.05s/it]Loading train:  63%|██████▎   | 335/532 [08:51<03:32,  1.08s/it]Loading train:  63%|██████▎   | 336/532 [08:52<03:32,  1.08s/it]Loading train:  63%|██████▎   | 337/532 [08:53<03:34,  1.10s/it]Loading train:  64%|██████▎   | 338/532 [08:54<03:34,  1.11s/it]Loading train:  64%|██████▎   | 339/532 [08:55<03:31,  1.10s/it]Loading train:  64%|██████▍   | 340/532 [08:56<03:23,  1.06s/it]Loading train:  64%|██████▍   | 341/532 [08:57<03:19,  1.04s/it]Loading train:  64%|██████▍   | 342/532 [08:58<03:07,  1.01it/s]Loading train:  64%|██████▍   | 343/532 [08:59<03:01,  1.04it/s]Loading train:  65%|██████▍   | 344/532 [09:00<02:58,  1.05it/s]Loading train:  65%|██████▍   | 345/532 [09:01<02:54,  1.07it/s]Loading train:  65%|██████▌   | 346/532 [09:02<02:53,  1.07it/s]Loading train:  65%|██████▌   | 347/532 [09:03<02:59,  1.03it/s]Loading train:  65%|██████▌   | 348/532 [09:04<03:00,  1.02it/s]Loading train:  66%|██████▌   | 349/532 [09:05<03:04,  1.01s/it]Loading train:  66%|██████▌   | 350/532 [09:06<03:03,  1.01s/it]Loading train:  66%|██████▌   | 351/532 [09:07<02:56,  1.03it/s]Loading train:  66%|██████▌   | 352/532 [09:08<02:53,  1.04it/s]Loading train:  66%|██████▋   | 353/532 [09:09<02:55,  1.02it/s]Loading train:  67%|██████▋   | 354/532 [09:10<02:55,  1.01it/s]Loading train:  67%|██████▋   | 355/532 [09:11<02:52,  1.03it/s]Loading train:  67%|██████▋   | 356/532 [09:12<02:52,  1.02it/s]Loading train:  67%|██████▋   | 357/532 [09:13<02:49,  1.03it/s]Loading train:  67%|██████▋   | 358/532 [09:14<02:45,  1.05it/s]Loading train:  67%|██████▋   | 359/532 [09:14<02:39,  1.09it/s]Loading train:  68%|██████▊   | 360/532 [09:15<02:37,  1.09it/s]Loading train:  68%|██████▊   | 361/532 [09:16<02:39,  1.07it/s]Loading train:  68%|██████▊   | 362/532 [09:17<02:36,  1.09it/s]Loading train:  68%|██████▊   | 363/532 [09:18<02:30,  1.12it/s]Loading train:  68%|██████▊   | 364/532 [09:19<02:31,  1.11it/s]Loading train:  69%|██████▊   | 365/532 [09:20<02:31,  1.10it/s]Loading train:  69%|██████▉   | 366/532 [09:21<02:35,  1.07it/s]Loading train:  69%|██████▉   | 367/532 [09:22<02:35,  1.06it/s]Loading train:  69%|██████▉   | 368/532 [09:23<02:34,  1.06it/s]Loading train:  69%|██████▉   | 369/532 [09:24<02:33,  1.06it/s]Loading train:  70%|██████▉   | 370/532 [09:25<02:31,  1.07it/s]Loading train:  70%|██████▉   | 371/532 [09:26<02:48,  1.05s/it]Loading train:  70%|██████▉   | 372/532 [09:27<02:59,  1.12s/it]Loading train:  70%|███████   | 373/532 [09:28<03:03,  1.16s/it]Loading train:  70%|███████   | 374/532 [09:30<03:08,  1.19s/it]Loading train:  70%|███████   | 375/532 [09:31<03:11,  1.22s/it]Loading train:  71%|███████   | 376/532 [09:32<03:11,  1.22s/it]Loading train:  71%|███████   | 377/532 [09:33<02:58,  1.15s/it]Loading train:  71%|███████   | 378/532 [09:34<02:51,  1.12s/it]Loading train:  71%|███████   | 379/532 [09:35<02:43,  1.07s/it]Loading train:  71%|███████▏  | 380/532 [09:36<02:39,  1.05s/it]Loading train:  72%|███████▏  | 381/532 [09:37<02:36,  1.04s/it]Loading train:  72%|███████▏  | 382/532 [09:38<02:31,  1.01s/it]Loading train:  72%|███████▏  | 383/532 [09:39<02:32,  1.02s/it]Loading train:  72%|███████▏  | 384/532 [09:40<02:31,  1.02s/it]Loading train:  72%|███████▏  | 385/532 [09:41<02:32,  1.04s/it]Loading train:  73%|███████▎  | 386/532 [09:42<02:27,  1.01s/it]Loading train:  73%|███████▎  | 387/532 [09:43<02:28,  1.02s/it]Loading train:  73%|███████▎  | 388/532 [09:44<02:28,  1.03s/it]Loading train:  73%|███████▎  | 389/532 [09:45<02:29,  1.04s/it]Loading train:  73%|███████▎  | 390/532 [09:47<02:29,  1.06s/it]Loading train:  73%|███████▎  | 391/532 [09:48<02:31,  1.07s/it]Loading train:  74%|███████▎  | 392/532 [09:49<02:30,  1.07s/it]Loading train:  74%|███████▍  | 393/532 [09:50<02:29,  1.07s/it]Loading train:  74%|███████▍  | 394/532 [09:51<02:30,  1.09s/it]Loading train:  74%|███████▍  | 395/532 [09:52<02:28,  1.08s/it]Loading train:  74%|███████▍  | 396/532 [09:53<02:26,  1.08s/it]Loading train:  75%|███████▍  | 397/532 [09:54<02:26,  1.08s/it]Loading train:  75%|███████▍  | 398/532 [09:55<02:24,  1.08s/it]Loading train:  75%|███████▌  | 399/532 [09:56<02:23,  1.08s/it]Loading train:  75%|███████▌  | 400/532 [09:57<02:22,  1.08s/it]Loading train:  75%|███████▌  | 401/532 [09:59<02:23,  1.09s/it]Loading train:  76%|███████▌  | 402/532 [10:00<02:20,  1.08s/it]Loading train:  76%|███████▌  | 403/532 [10:01<02:18,  1.07s/it]Loading train:  76%|███████▌  | 404/532 [10:02<02:18,  1.08s/it]Loading train:  76%|███████▌  | 405/532 [10:03<02:20,  1.11s/it]Loading train:  76%|███████▋  | 406/532 [10:04<02:21,  1.12s/it]Loading train:  77%|███████▋  | 407/532 [10:05<02:18,  1.11s/it]Loading train:  77%|███████▋  | 408/532 [10:06<02:16,  1.10s/it]Loading train:  77%|███████▋  | 409/532 [10:07<02:12,  1.08s/it]Loading train:  77%|███████▋  | 410/532 [10:08<02:09,  1.06s/it]Loading train:  77%|███████▋  | 411/532 [10:09<02:08,  1.06s/it]Loading train:  77%|███████▋  | 412/532 [10:10<02:05,  1.05s/it]Loading train:  78%|███████▊  | 413/532 [10:11<02:04,  1.05s/it]Loading train:  78%|███████▊  | 414/532 [10:12<01:58,  1.01s/it]Loading train:  78%|███████▊  | 415/532 [10:13<01:53,  1.03it/s]Loading train:  78%|███████▊  | 416/532 [10:14<01:51,  1.04it/s]Loading train:  78%|███████▊  | 417/532 [10:15<01:50,  1.04it/s]Loading train:  79%|███████▊  | 418/532 [10:16<01:49,  1.04it/s]Loading train:  79%|███████▉  | 419/532 [10:17<01:57,  1.04s/it]Loading train:  79%|███████▉  | 420/532 [10:18<01:59,  1.07s/it]Loading train:  79%|███████▉  | 421/532 [10:20<02:00,  1.08s/it]Loading train:  79%|███████▉  | 422/532 [10:21<02:03,  1.13s/it]Loading train:  80%|███████▉  | 423/532 [10:22<02:02,  1.13s/it]Loading train:  80%|███████▉  | 424/532 [10:23<02:01,  1.13s/it]Loading train:  80%|███████▉  | 425/532 [10:24<02:00,  1.12s/it]Loading train:  80%|████████  | 426/532 [10:25<01:58,  1.12s/it]Loading train:  80%|████████  | 427/532 [10:26<01:58,  1.13s/it]Loading train:  80%|████████  | 428/532 [10:27<01:56,  1.12s/it]Loading train:  81%|████████  | 429/532 [10:29<01:55,  1.12s/it]Loading train:  81%|████████  | 430/532 [10:30<01:54,  1.12s/it]Loading train:  81%|████████  | 431/532 [10:31<01:54,  1.13s/it]Loading train:  81%|████████  | 432/532 [10:32<01:51,  1.12s/it]Loading train:  81%|████████▏ | 433/532 [10:33<01:51,  1.13s/it]Loading train:  82%|████████▏ | 434/532 [10:34<01:49,  1.12s/it]Loading train:  82%|████████▏ | 435/532 [10:35<01:47,  1.11s/it]Loading train:  82%|████████▏ | 436/532 [10:36<01:48,  1.13s/it]Loading train:  82%|████████▏ | 437/532 [10:37<01:43,  1.09s/it]Loading train:  82%|████████▏ | 438/532 [10:38<01:36,  1.03s/it]Loading train:  83%|████████▎ | 439/532 [10:39<01:30,  1.02it/s]Loading train:  83%|████████▎ | 440/532 [10:40<01:26,  1.07it/s]Loading train:  83%|████████▎ | 441/532 [10:41<01:23,  1.09it/s]Loading train:  83%|████████▎ | 442/532 [10:42<01:21,  1.10it/s]Loading train:  83%|████████▎ | 443/532 [10:43<01:23,  1.06it/s]Loading train:  83%|████████▎ | 444/532 [10:44<01:20,  1.09it/s]Loading train:  84%|████████▎ | 445/532 [10:45<01:21,  1.07it/s]Loading train:  84%|████████▍ | 446/532 [10:46<01:19,  1.08it/s]Loading train:  84%|████████▍ | 447/532 [10:47<01:20,  1.06it/s]Loading train:  84%|████████▍ | 448/532 [10:48<01:19,  1.06it/s]Loading train:  84%|████████▍ | 449/532 [10:49<01:19,  1.04it/s]Loading train:  85%|████████▍ | 450/532 [10:50<01:19,  1.03it/s]Loading train:  85%|████████▍ | 451/532 [10:50<01:17,  1.04it/s]Loading train:  85%|████████▍ | 452/532 [10:51<01:16,  1.04it/s]Loading train:  85%|████████▌ | 453/532 [10:52<01:13,  1.07it/s]Loading train:  85%|████████▌ | 454/532 [10:53<01:15,  1.04it/s]Loading train:  86%|████████▌ | 455/532 [10:54<01:16,  1.01it/s]Loading train:  86%|████████▌ | 456/532 [10:55<01:18,  1.03s/it]Loading train:  86%|████████▌ | 457/532 [10:57<01:17,  1.04s/it]Loading train:  86%|████████▌ | 458/532 [10:58<01:17,  1.04s/it]Loading train:  86%|████████▋ | 459/532 [10:59<01:15,  1.03s/it]Loading train:  86%|████████▋ | 460/532 [11:00<01:15,  1.04s/it]Loading train:  87%|████████▋ | 461/532 [11:01<01:17,  1.10s/it]Loading train:  87%|████████▋ | 462/532 [11:02<01:19,  1.13s/it]Loading train:  87%|████████▋ | 463/532 [11:03<01:19,  1.16s/it]Loading train:  87%|████████▋ | 464/532 [11:05<01:20,  1.18s/it]Loading train:  87%|████████▋ | 465/532 [11:06<01:20,  1.20s/it]Loading train:  88%|████████▊ | 466/532 [11:07<01:20,  1.22s/it]Loading train:  88%|████████▊ | 467/532 [11:08<01:14,  1.15s/it]Loading train:  88%|████████▊ | 468/532 [11:09<01:12,  1.13s/it]Loading train:  88%|████████▊ | 469/532 [11:10<01:09,  1.10s/it]Loading train:  88%|████████▊ | 470/532 [11:11<01:06,  1.07s/it]Loading train:  89%|████████▊ | 471/532 [11:12<01:02,  1.03s/it]Loading train:  89%|████████▊ | 472/532 [11:13<01:00,  1.01s/it]Loading train:  89%|████████▉ | 473/532 [11:14<01:01,  1.04s/it]Loading train:  89%|████████▉ | 474/532 [11:15<01:00,  1.04s/it]Loading train:  89%|████████▉ | 475/532 [11:16<01:00,  1.06s/it]Loading train:  89%|████████▉ | 476/532 [11:17<00:59,  1.06s/it]Loading train:  90%|████████▉ | 477/532 [11:18<00:57,  1.05s/it]Loading train:  90%|████████▉ | 478/532 [11:19<00:56,  1.05s/it]Loading train:  90%|█████████ | 479/532 [11:20<00:55,  1.04s/it]Loading train:  90%|█████████ | 480/532 [11:21<00:51,  1.00it/s]Loading train:  90%|█████████ | 481/532 [11:22<00:50,  1.02it/s]Loading train:  91%|█████████ | 482/532 [11:23<00:48,  1.02it/s]Loading train:  91%|█████████ | 483/532 [11:24<00:46,  1.05it/s]Loading train:  91%|█████████ | 484/532 [11:25<00:45,  1.05it/s]Loading train:  91%|█████████ | 485/532 [11:26<00:46,  1.01it/s]Loading train:  91%|█████████▏| 486/532 [11:27<00:48,  1.05s/it]Loading train:  92%|█████████▏| 487/532 [11:29<00:49,  1.10s/it]Loading train:  92%|█████████▏| 488/532 [11:30<00:48,  1.09s/it]Loading train:  92%|█████████▏| 489/532 [11:31<00:47,  1.11s/it]Loading train:  92%|█████████▏| 490/532 [11:32<00:47,  1.12s/it]Loading train:  92%|█████████▏| 491/532 [11:33<00:43,  1.07s/it]Loading train:  92%|█████████▏| 492/532 [11:34<00:41,  1.04s/it]Loading train:  93%|█████████▎| 493/532 [11:35<00:41,  1.06s/it]Loading train:  93%|█████████▎| 494/532 [11:36<00:39,  1.04s/it]Loading train:  93%|█████████▎| 495/532 [11:37<00:38,  1.04s/it]Loading train:  93%|█████████▎| 496/532 [11:38<00:37,  1.03s/it]Loading train:  93%|█████████▎| 497/532 [11:39<00:36,  1.05s/it]Loading train:  94%|█████████▎| 498/532 [11:40<00:34,  1.03s/it]Loading train:  94%|█████████▍| 499/532 [11:41<00:33,  1.02s/it]Loading train:  94%|█████████▍| 500/532 [11:42<00:32,  1.02s/it]Loading train:  94%|█████████▍| 501/532 [11:43<00:31,  1.01s/it]Loading train:  94%|█████████▍| 502/532 [11:44<00:30,  1.02s/it]Loading train:  95%|█████████▍| 503/532 [11:45<00:29,  1.02s/it]Loading train:  95%|█████████▍| 504/532 [11:46<00:27,  1.02it/s]Loading train:  95%|█████████▍| 505/532 [11:47<00:26,  1.02it/s]Loading train:  95%|█████████▌| 506/532 [11:48<00:25,  1.03it/s]Loading train:  95%|█████████▌| 507/532 [11:49<00:24,  1.01it/s]Loading train:  95%|█████████▌| 508/532 [11:50<00:23,  1.02it/s]Loading train:  96%|█████████▌| 509/532 [11:51<00:23,  1.04s/it]Loading train:  96%|█████████▌| 510/532 [11:52<00:23,  1.07s/it]Loading train:  96%|█████████▌| 511/532 [11:54<00:23,  1.10s/it]Loading train:  96%|█████████▌| 512/532 [11:55<00:22,  1.13s/it]Loading train:  96%|█████████▋| 513/532 [11:56<00:21,  1.13s/it]Loading train:  97%|█████████▋| 514/532 [11:57<00:20,  1.14s/it]Loading train:  97%|█████████▋| 515/532 [11:58<00:18,  1.08s/it]Loading train:  97%|█████████▋| 516/532 [11:59<00:16,  1.05s/it]Loading train:  97%|█████████▋| 517/532 [12:00<00:15,  1.05s/it]Loading train:  97%|█████████▋| 518/532 [12:01<00:14,  1.06s/it]Loading train:  98%|█████████▊| 519/532 [12:02<00:13,  1.06s/it]Loading train:  98%|█████████▊| 520/532 [12:03<00:12,  1.04s/it]Loading train:  98%|█████████▊| 521/532 [12:04<00:11,  1.06s/it]Loading train:  98%|█████████▊| 522/532 [12:06<00:11,  1.13s/it]Loading train:  98%|█████████▊| 523/532 [12:07<00:10,  1.15s/it]Loading train:  98%|█████████▊| 524/532 [12:08<00:09,  1.14s/it]Loading train:  99%|█████████▊| 525/532 [12:09<00:07,  1.12s/it]Loading train:  99%|█████████▉| 526/532 [12:10<00:06,  1.12s/it]Loading train:  99%|█████████▉| 527/532 [12:11<00:05,  1.10s/it]Loading train:  99%|█████████▉| 528/532 [12:12<00:04,  1.06s/it]Loading train:  99%|█████████▉| 529/532 [12:13<00:03,  1.01s/it]Loading train: 100%|█████████▉| 530/532 [12:14<00:01,  1.03it/s]Loading train: 100%|█████████▉| 531/532 [12:15<00:00,  1.05it/s]Loading train: 100%|██████████| 532/532 [12:16<00:00,  1.05it/s]
concatenating: train:   0%|          | 0/532 [00:00<?, ?it/s]concatenating: train:   3%|▎         | 15/532 [00:00<00:03, 141.99it/s]concatenating: train:   5%|▌         | 28/532 [00:00<00:03, 137.46it/s]concatenating: train:   9%|▉         | 48/532 [00:00<00:03, 150.60it/s]concatenating: train:  11%|█▏        | 60/532 [00:00<00:03, 139.64it/s]concatenating: train:  16%|█▌        | 84/532 [00:00<00:02, 159.55it/s]concatenating: train:  20%|██        | 107/532 [00:00<00:02, 174.06it/s]concatenating: train:  25%|██▍       | 132/532 [00:00<00:02, 191.17it/s]concatenating: train:  30%|██▉       | 157/532 [00:00<00:01, 205.03it/s]concatenating: train:  33%|███▎      | 178/532 [00:00<00:01, 193.89it/s]concatenating: train:  37%|███▋      | 199/532 [00:01<00:01, 194.89it/s]concatenating: train:  41%|████      | 219/532 [00:01<00:01, 194.05it/s]concatenating: train:  45%|████▍     | 239/532 [00:01<00:01, 195.73it/s]concatenating: train:  49%|████▉     | 263/532 [00:01<00:01, 206.35it/s]concatenating: train:  54%|█████▍    | 288/532 [00:01<00:01, 217.44it/s]concatenating: train:  58%|█████▊    | 311/532 [00:01<00:01, 218.25it/s]concatenating: train:  63%|██████▎   | 334/532 [00:01<00:00, 219.26it/s]concatenating: train:  67%|██████▋   | 357/532 [00:01<00:00, 214.64it/s]concatenating: train:  72%|███████▏  | 381/532 [00:01<00:00, 220.38it/s]concatenating: train:  76%|███████▋  | 406/532 [00:01<00:00, 226.29it/s]concatenating: train:  81%|████████  | 430/532 [00:02<00:00, 228.32it/s]concatenating: train:  85%|████████▌ | 453/532 [00:02<00:00, 202.08it/s]concatenating: train:  89%|████████▉ | 474/532 [00:02<00:00, 192.05it/s]concatenating: train:  93%|█████████▎| 494/532 [00:02<00:00, 183.30it/s]concatenating: train:  96%|█████████▋| 513/532 [00:02<00:00, 174.16it/s]concatenating: train: 100%|██████████| 532/532 [00:02<00:00, 198.01it/s]
Loading test:   0%|          | 0/15 [00:00<?, ?it/s]Loading test:   7%|▋         | 1/15 [00:01<00:14,  1.02s/it]Loading test:  13%|█▎        | 2/15 [00:01<00:12,  1.00it/s]Loading test:  20%|██        | 3/15 [00:03<00:12,  1.07s/it]Loading test:  27%|██▋       | 4/15 [00:04<00:12,  1.10s/it]Loading test:  33%|███▎      | 5/15 [00:05<00:11,  1.14s/it]Loading test:  40%|████      | 6/15 [00:06<00:10,  1.17s/it]Loading test:  47%|████▋     | 7/15 [00:07<00:09,  1.13s/it]Loading test:  53%|█████▎    | 8/15 [00:09<00:08,  1.16s/it]Loading test:  60%|██████    | 9/15 [00:10<00:06,  1.15s/it]Loading test:  67%|██████▋   | 10/15 [00:11<00:05,  1.10s/it]Loading test:  73%|███████▎  | 11/15 [00:12<00:04,  1.08s/it]Loading test:  80%|████████  | 12/15 [00:13<00:03,  1.09s/it]Loading test:  87%|████████▋ | 13/15 [00:14<00:02,  1.11s/it]Loading test:  93%|█████████▎| 14/15 [00:15<00:01,  1.14s/it]Loading test: 100%|██████████| 15/15 [00:16<00:00,  1.12s/it]
concatenating: validation:   0%|          | 0/15 [00:00<?, ?it/s]concatenating: validation:  40%|████      | 6/15 [00:00<00:00, 55.05it/s]concatenating: validation: 100%|██████████| 15/15 [00:00<00:00, 103.36it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 56, 56, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 56, 56, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 56, 56, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 56, 56, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 56, 56, 10)   910         activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 56, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 56, 56, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 56, 56, 11)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 11)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28, 28, 11)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 28, 20)   2000        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 28, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 28, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 28, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 28, 28, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 28, 28, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 28, 31)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 31)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 14, 14, 31)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 14, 14, 40)   11200       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 14, 14, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 14, 14, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 14, 14, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 14, 14, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 14, 14, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 14, 14, 71)   0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 14, 14, 71)   0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 28, 28, 20)   5700        dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 28, 28, 51)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 28, 28, 20)   9200        concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 28, 28, 20)   80          conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 28, 28, 20)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 28, 28, 20)   3620        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 28, 28, 20)   80          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 28, 28, 20)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 28, 28, 71)   0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-06 18:59:11.952592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-06 18:59:11.952699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-06 18:59:11.952714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-06 18:59:11.952722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-06 18:59:11.953182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 28, 28, 71)   0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 56, 56, 10)   2850        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 56, 21)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 56, 56, 10)   1900        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 56, 56, 10)   40          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 56, 10)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 56, 56, 10)   910         activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 56, 56, 10)   40          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 56, 10)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 56, 31)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 56, 56, 31)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 56, 56, 13)   416         dropout_5[0][0]                  
==================================================================================================
Total params: 57,666
Trainable params: 57,266
Non-trainable params: 400
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.53974061e-02 2.89048015e-02 1.16758472e-01 1.00223856e-02
 3.03440156e-02 5.80063118e-03 6.84518755e-02 1.28261328e-01
 7.55818021e-02 1.22545826e-02 2.73712232e-01 1.84335085e-01
 1.75382711e-04]
Train on 33496 samples, validate on 969 samples
Epoch 1/300
 - 26s - loss: 60.8083 - acc: 0.7431 - mDice: 0.0146 - val_loss: 4.3706 - val_acc: 0.9217 - val_mDice: 0.0193

Epoch 00001: val_mDice improved from -inf to 0.01927, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 19s - loss: 7.1670 - acc: 0.9008 - mDice: 0.0331 - val_loss: 3.3611 - val_acc: 0.9217 - val_mDice: 0.0544

Epoch 00002: val_mDice improved from 0.01927 to 0.05436, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 18s - loss: 5.4859 - acc: 0.9027 - mDice: 0.0493 - val_loss: 3.0761 - val_acc: 0.9212 - val_mDice: 0.0755

Epoch 00003: val_mDice improved from 0.05436 to 0.07548, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 19s - loss: 4.6700 - acc: 0.9037 - mDice: 0.0647 - val_loss: 2.7833 - val_acc: 0.9196 - val_mDice: 0.1040

Epoch 00004: val_mDice improved from 0.07548 to 0.10403, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 5/300
 - 18s - loss: 4.0583 - acc: 0.9068 - mDice: 0.0864 - val_loss: 2.5109 - val_acc: 0.9204 - val_mDice: 0.1419

Epoch 00005: val_mDice improved from 0.10403 to 0.14194, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 18s - loss: 3.5442 - acc: 0.9134 - mDice: 0.1179 - val_loss: 2.2003 - val_acc: 0.9322 - val_mDice: 0.1881

Epoch 00006: val_mDice improved from 0.14194 to 0.18809, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 7/300
 - 19s - loss: 3.1174 - acc: 0.9192 - mDice: 0.1598 - val_loss: 1.9489 - val_acc: 0.9420 - val_mDice: 0.2488

Epoch 00007: val_mDice improved from 0.18809 to 0.24884, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 8/300
 - 18s - loss: 2.7863 - acc: 0.9244 - mDice: 0.2023 - val_loss: 1.7747 - val_acc: 0.9465 - val_mDice: 0.3053

Epoch 00008: val_mDice improved from 0.24884 to 0.30535, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 9/300
 - 18s - loss: 2.5279 - acc: 0.9285 - mDice: 0.2474 - val_loss: 1.5820 - val_acc: 0.9523 - val_mDice: 0.3635

Epoch 00009: val_mDice improved from 0.30535 to 0.36352, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 10/300
 - 19s - loss: 2.3201 - acc: 0.9315 - mDice: 0.2854 - val_loss: 1.4605 - val_acc: 0.9568 - val_mDice: 0.4065

Epoch 00010: val_mDice improved from 0.36352 to 0.40652, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 11/300
 - 18s - loss: 2.1516 - acc: 0.9345 - mDice: 0.3187 - val_loss: 1.3525 - val_acc: 0.9605 - val_mDice: 0.4446

Epoch 00011: val_mDice improved from 0.40652 to 0.44460, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 12/300
 - 18s - loss: 2.0198 - acc: 0.9374 - mDice: 0.3479 - val_loss: 1.2494 - val_acc: 0.9645 - val_mDice: 0.4815

Epoch 00012: val_mDice improved from 0.44460 to 0.48147, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 13/300
 - 19s - loss: 1.8995 - acc: 0.9400 - mDice: 0.3754 - val_loss: 1.2026 - val_acc: 0.9654 - val_mDice: 0.5013

Epoch 00013: val_mDice improved from 0.48147 to 0.50134, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 14/300
 - 18s - loss: 1.8043 - acc: 0.9423 - mDice: 0.3984 - val_loss: 1.1386 - val_acc: 0.9685 - val_mDice: 0.5244

Epoch 00014: val_mDice improved from 0.50134 to 0.52445, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 15/300
 - 19s - loss: 1.7078 - acc: 0.9446 - mDice: 0.4238 - val_loss: 1.0583 - val_acc: 0.9707 - val_mDice: 0.5552

Epoch 00015: val_mDice improved from 0.52445 to 0.55525, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 16/300
 - 19s - loss: 1.6199 - acc: 0.9464 - mDice: 0.4486 - val_loss: 1.0004 - val_acc: 0.9714 - val_mDice: 0.5800

Epoch 00016: val_mDice improved from 0.55525 to 0.58001, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 17/300
 - 18s - loss: 1.5313 - acc: 0.9483 - mDice: 0.4746 - val_loss: 0.9616 - val_acc: 0.9728 - val_mDice: 0.6033

Epoch 00017: val_mDice improved from 0.58001 to 0.60335, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 18/300
 - 18s - loss: 1.4568 - acc: 0.9499 - mDice: 0.4967 - val_loss: 0.9142 - val_acc: 0.9739 - val_mDice: 0.6244

Epoch 00018: val_mDice improved from 0.60335 to 0.62444, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 19/300
 - 19s - loss: 1.4024 - acc: 0.9509 - mDice: 0.5129 - val_loss: 0.9075 - val_acc: 0.9735 - val_mDice: 0.6329

Epoch 00019: val_mDice improved from 0.62444 to 0.63291, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 20/300
 - 18s - loss: 1.3532 - acc: 0.9519 - mDice: 0.5270 - val_loss: 0.8777 - val_acc: 0.9742 - val_mDice: 0.6395

Epoch 00020: val_mDice improved from 0.63291 to 0.63949, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 21/300
 - 18s - loss: 1.3119 - acc: 0.9528 - mDice: 0.5396 - val_loss: 0.8680 - val_acc: 0.9749 - val_mDice: 0.6409

Epoch 00021: val_mDice improved from 0.63949 to 0.64085, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 22/300
 - 18s - loss: 1.2787 - acc: 0.9538 - mDice: 0.5498 - val_loss: 0.8407 - val_acc: 0.9751 - val_mDice: 0.6554

Epoch 00022: val_mDice improved from 0.64085 to 0.65539, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 23/300
 - 19s - loss: 1.2415 - acc: 0.9549 - mDice: 0.5604 - val_loss: 0.8330 - val_acc: 0.9759 - val_mDice: 0.6594

Epoch 00023: val_mDice improved from 0.65539 to 0.65940, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 24/300
 - 18s - loss: 1.2186 - acc: 0.9555 - mDice: 0.5683 - val_loss: 0.8137 - val_acc: 0.9759 - val_mDice: 0.6660

Epoch 00024: val_mDice improved from 0.65940 to 0.66595, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 25/300
 - 18s - loss: 1.1962 - acc: 0.9561 - mDice: 0.5754 - val_loss: 0.8102 - val_acc: 0.9767 - val_mDice: 0.6710

Epoch 00025: val_mDice improved from 0.66595 to 0.67102, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 26/300
 - 19s - loss: 1.1726 - acc: 0.9567 - mDice: 0.5827 - val_loss: 0.8084 - val_acc: 0.9764 - val_mDice: 0.6701

Epoch 00026: val_mDice did not improve from 0.67102
Epoch 27/300
 - 19s - loss: 1.1576 - acc: 0.9569 - mDice: 0.5872 - val_loss: 0.7979 - val_acc: 0.9765 - val_mDice: 0.6774

Epoch 00027: val_mDice improved from 0.67102 to 0.67739, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 28/300
 - 19s - loss: 1.1367 - acc: 0.9575 - mDice: 0.5943 - val_loss: 0.7950 - val_acc: 0.9767 - val_mDice: 0.6747

Epoch 00028: val_mDice did not improve from 0.67739
Epoch 29/300
 - 19s - loss: 1.1240 - acc: 0.9579 - mDice: 0.5985 - val_loss: 0.7950 - val_acc: 0.9771 - val_mDice: 0.6794

Epoch 00029: val_mDice improved from 0.67739 to 0.67938, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 30/300
 - 18s - loss: 1.1079 - acc: 0.9583 - mDice: 0.6037 - val_loss: 0.7793 - val_acc: 0.9764 - val_mDice: 0.6829

Epoch 00030: val_mDice improved from 0.67938 to 0.68292, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 31/300
 - 20s - loss: 1.0938 - acc: 0.9586 - mDice: 0.6083 - val_loss: 0.7853 - val_acc: 0.9768 - val_mDice: 0.6830

Epoch 00031: val_mDice improved from 0.68292 to 0.68301, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 32/300
 - 19s - loss: 1.0869 - acc: 0.9587 - mDice: 0.6102 - val_loss: 0.7766 - val_acc: 0.9770 - val_mDice: 0.6852

Epoch 00032: val_mDice improved from 0.68301 to 0.68521, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 33/300
 - 20s - loss: 1.0733 - acc: 0.9591 - mDice: 0.6153 - val_loss: 0.7540 - val_acc: 0.9772 - val_mDice: 0.6901

Epoch 00033: val_mDice improved from 0.68521 to 0.69009, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 34/300
 - 19s - loss: 1.0637 - acc: 0.9593 - mDice: 0.6178 - val_loss: 0.7730 - val_acc: 0.9771 - val_mDice: 0.6893

Epoch 00034: val_mDice did not improve from 0.69009
Epoch 35/300
 - 20s - loss: 1.0607 - acc: 0.9593 - mDice: 0.6186 - val_loss: 0.7604 - val_acc: 0.9773 - val_mDice: 0.6884

Epoch 00035: val_mDice did not improve from 0.69009
Epoch 36/300
 - 19s - loss: 1.0444 - acc: 0.9598 - mDice: 0.6242 - val_loss: 0.7638 - val_acc: 0.9768 - val_mDice: 0.6906

Epoch 00036: val_mDice improved from 0.69009 to 0.69055, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 37/300
 - 20s - loss: 1.0408 - acc: 0.9598 - mDice: 0.6253 - val_loss: 0.7482 - val_acc: 0.9780 - val_mDice: 0.6932

Epoch 00037: val_mDice improved from 0.69055 to 0.69317, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 38/300
 - 20s - loss: 1.0317 - acc: 0.9601 - mDice: 0.6282 - val_loss: 0.7434 - val_acc: 0.9779 - val_mDice: 0.6962

Epoch 00038: val_mDice improved from 0.69317 to 0.69625, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 39/300
 - 19s - loss: 1.0231 - acc: 0.9603 - mDice: 0.6306 - val_loss: 0.7312 - val_acc: 0.9778 - val_mDice: 0.7023

Epoch 00039: val_mDice improved from 0.69625 to 0.70232, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 40/300
 - 19s - loss: 1.0200 - acc: 0.9603 - mDice: 0.6320 - val_loss: 0.7355 - val_acc: 0.9772 - val_mDice: 0.7022

Epoch 00040: val_mDice did not improve from 0.70232
Epoch 41/300
 - 19s - loss: 1.0123 - acc: 0.9605 - mDice: 0.6345 - val_loss: 0.7345 - val_acc: 0.9776 - val_mDice: 0.7024

Epoch 00041: val_mDice improved from 0.70232 to 0.70238, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 42/300
 - 18s - loss: 1.0073 - acc: 0.9606 - mDice: 0.6363 - val_loss: 0.7411 - val_acc: 0.9781 - val_mDice: 0.7057

Epoch 00042: val_mDice improved from 0.70238 to 0.70567, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 43/300
 - 20s - loss: 1.0031 - acc: 0.9607 - mDice: 0.6372 - val_loss: 0.7668 - val_acc: 0.9766 - val_mDice: 0.7010

Epoch 00043: val_mDice did not improve from 0.70567
Epoch 44/300
 - 19s - loss: 1.0009 - acc: 0.9607 - mDice: 0.6384 - val_loss: 0.7295 - val_acc: 0.9780 - val_mDice: 0.7068

Epoch 00044: val_mDice improved from 0.70567 to 0.70680, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 45/300
 - 20s - loss: 0.9920 - acc: 0.9610 - mDice: 0.6411 - val_loss: 0.7478 - val_acc: 0.9777 - val_mDice: 0.7017

Epoch 00045: val_mDice did not improve from 0.70680
Epoch 46/300
 - 19s - loss: 0.9868 - acc: 0.9610 - mDice: 0.6425 - val_loss: 0.7229 - val_acc: 0.9782 - val_mDice: 0.7074

Epoch 00046: val_mDice improved from 0.70680 to 0.70742, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 47/300
 - 20s - loss: 0.9812 - acc: 0.9612 - mDice: 0.6446 - val_loss: 0.7192 - val_acc: 0.9776 - val_mDice: 0.7071

Epoch 00047: val_mDice did not improve from 0.70742
Epoch 48/300
 - 18s - loss: 0.9763 - acc: 0.9613 - mDice: 0.6466 - val_loss: 0.7180 - val_acc: 0.9784 - val_mDice: 0.7096

Epoch 00048: val_mDice improved from 0.70742 to 0.70965, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 49/300
 - 19s - loss: 0.9751 - acc: 0.9615 - mDice: 0.6476 - val_loss: 0.7318 - val_acc: 0.9778 - val_mDice: 0.7060

Epoch 00049: val_mDice did not improve from 0.70965
Epoch 50/300
 - 19s - loss: 0.9719 - acc: 0.9615 - mDice: 0.6484 - val_loss: 0.7206 - val_acc: 0.9786 - val_mDice: 0.7093

Epoch 00050: val_mDice did not improve from 0.70965
Epoch 51/300
 - 19s - loss: 0.9632 - acc: 0.9616 - mDice: 0.6508 - val_loss: 0.7174 - val_acc: 0.9790 - val_mDice: 0.7097

Epoch 00051: val_mDice improved from 0.70965 to 0.70973, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 52/300
 - 20s - loss: 0.9621 - acc: 0.9617 - mDice: 0.6512 - val_loss: 0.7288 - val_acc: 0.9784 - val_mDice: 0.7087

Epoch 00052: val_mDice did not improve from 0.70973
Epoch 53/300
 - 19s - loss: 0.9592 - acc: 0.9618 - mDice: 0.6521 - val_loss: 0.7243 - val_acc: 0.9791 - val_mDice: 0.7099

Epoch 00053: val_mDice improved from 0.70973 to 0.70988, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 54/300
 - 19s - loss: 0.9554 - acc: 0.9619 - mDice: 0.6535 - val_loss: 0.7191 - val_acc: 0.9784 - val_mDice: 0.7139

Epoch 00054: val_mDice improved from 0.70988 to 0.71386, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 55/300
 - 19s - loss: 0.9537 - acc: 0.9619 - mDice: 0.6545 - val_loss: 0.7314 - val_acc: 0.9786 - val_mDice: 0.7106

Epoch 00055: val_mDice did not improve from 0.71386
Epoch 56/300
 - 20s - loss: 0.9484 - acc: 0.9621 - mDice: 0.6560 - val_loss: 0.7263 - val_acc: 0.9782 - val_mDice: 0.7104

Epoch 00056: val_mDice did not improve from 0.71386
Epoch 57/300
 - 22s - loss: 0.9464 - acc: 0.9622 - mDice: 0.6567 - val_loss: 0.7377 - val_acc: 0.9784 - val_mDice: 0.7105

Epoch 00057: val_mDice did not improve from 0.71386
Epoch 58/300
 - 21s - loss: 0.9438 - acc: 0.9622 - mDice: 0.6576 - val_loss: 0.7071 - val_acc: 0.9790 - val_mDice: 0.7159

Epoch 00058: val_mDice improved from 0.71386 to 0.71585, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 59/300
 - 21s - loss: 0.9413 - acc: 0.9623 - mDice: 0.6581 - val_loss: 0.7078 - val_acc: 0.9783 - val_mDice: 0.7195

Epoch 00059: val_mDice improved from 0.71585 to 0.71946, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 60/300
 - 22s - loss: 0.9398 - acc: 0.9624 - mDice: 0.6593 - val_loss: 0.7118 - val_acc: 0.9786 - val_mDice: 0.7148

Epoch 00060: val_mDice did not improve from 0.71946
Epoch 61/300
 - 22s - loss: 0.9351 - acc: 0.9625 - mDice: 0.6607 - val_loss: 0.7155 - val_acc: 0.9788 - val_mDice: 0.7149

Epoch 00061: val_mDice did not improve from 0.71946
Epoch 62/300
 - 21s - loss: 0.9354 - acc: 0.9624 - mDice: 0.6605 - val_loss: 0.7021 - val_acc: 0.9792 - val_mDice: 0.7188

Epoch 00062: val_mDice did not improve from 0.71946
Epoch 63/300
 - 23s - loss: 0.9329 - acc: 0.9626 - mDice: 0.6615 - val_loss: 0.6977 - val_acc: 0.9792 - val_mDice: 0.7201

Epoch 00063: val_mDice improved from 0.71946 to 0.72015, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 64/300
 - 22s - loss: 0.9312 - acc: 0.9626 - mDice: 0.6619 - val_loss: 0.7067 - val_acc: 0.9790 - val_mDice: 0.7185

Epoch 00064: val_mDice did not improve from 0.72015
Epoch 65/300
 - 21s - loss: 0.9264 - acc: 0.9627 - mDice: 0.6637 - val_loss: 0.7082 - val_acc: 0.9787 - val_mDice: 0.7196

Epoch 00065: val_mDice did not improve from 0.72015
Epoch 66/300
 - 22s - loss: 0.9257 - acc: 0.9628 - mDice: 0.6637 - val_loss: 0.7336 - val_acc: 0.9782 - val_mDice: 0.7131

Epoch 00066: val_mDice did not improve from 0.72015
Epoch 67/300
 - 22s - loss: 0.9245 - acc: 0.9627 - mDice: 0.6644 - val_loss: 0.7023 - val_acc: 0.9794 - val_mDice: 0.7230

Epoch 00067: val_mDice improved from 0.72015 to 0.72303, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 68/300
 - 20s - loss: 0.9213 - acc: 0.9628 - mDice: 0.6655 - val_loss: 0.7136 - val_acc: 0.9789 - val_mDice: 0.7168

Epoch 00068: val_mDice did not improve from 0.72303
Epoch 69/300
 - 20s - loss: 0.9214 - acc: 0.9629 - mDice: 0.6654 - val_loss: 0.7096 - val_acc: 0.9789 - val_mDice: 0.7196

Epoch 00069: val_mDice did not improve from 0.72303
Epoch 70/300
 - 18s - loss: 0.9186 - acc: 0.9628 - mDice: 0.6659 - val_loss: 0.6980 - val_acc: 0.9791 - val_mDice: 0.7216

Epoch 00070: val_mDice did not improve from 0.72303
Epoch 71/300
 - 19s - loss: 0.9169 - acc: 0.9630 - mDice: 0.6671 - val_loss: 0.6897 - val_acc: 0.9789 - val_mDice: 0.7257

Epoch 00071: val_mDice improved from 0.72303 to 0.72565, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 72/300
 - 18s - loss: 0.9153 - acc: 0.9630 - mDice: 0.6673 - val_loss: 0.6906 - val_acc: 0.9791 - val_mDice: 0.7258

Epoch 00072: val_mDice improved from 0.72565 to 0.72585, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 73/300
 - 18s - loss: 0.9156 - acc: 0.9631 - mDice: 0.6672 - val_loss: 0.7067 - val_acc: 0.9791 - val_mDice: 0.7206

Epoch 00073: val_mDice did not improve from 0.72585
Epoch 74/300
 - 18s - loss: 0.9108 - acc: 0.9631 - mDice: 0.6686 - val_loss: 0.6956 - val_acc: 0.9795 - val_mDice: 0.7260

Epoch 00074: val_mDice improved from 0.72585 to 0.72604, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 75/300
 - 19s - loss: 0.9097 - acc: 0.9632 - mDice: 0.6692 - val_loss: 0.6949 - val_acc: 0.9790 - val_mDice: 0.7242

Epoch 00075: val_mDice did not improve from 0.72604
Epoch 76/300
 - 18s - loss: 0.9094 - acc: 0.9631 - mDice: 0.6697 - val_loss: 0.7103 - val_acc: 0.9786 - val_mDice: 0.7257

Epoch 00076: val_mDice did not improve from 0.72604
Epoch 77/300
 - 18s - loss: 0.9073 - acc: 0.9632 - mDice: 0.6702 - val_loss: 0.7010 - val_acc: 0.9789 - val_mDice: 0.7256

Epoch 00077: val_mDice did not improve from 0.72604
Epoch 78/300
 - 18s - loss: 0.9031 - acc: 0.9633 - mDice: 0.6721 - val_loss: 0.6994 - val_acc: 0.9792 - val_mDice: 0.7268

Epoch 00078: val_mDice improved from 0.72604 to 0.72684, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 79/300
 - 18s - loss: 0.9029 - acc: 0.9634 - mDice: 0.6719 - val_loss: 0.7124 - val_acc: 0.9784 - val_mDice: 0.7246

Epoch 00079: val_mDice did not improve from 0.72684
Epoch 80/300
 - 19s - loss: 0.9010 - acc: 0.9634 - mDice: 0.6730 - val_loss: 0.7001 - val_acc: 0.9791 - val_mDice: 0.7218

Epoch 00080: val_mDice did not improve from 0.72684
Epoch 81/300
 - 19s - loss: 0.8979 - acc: 0.9635 - mDice: 0.6739 - val_loss: 0.7005 - val_acc: 0.9790 - val_mDice: 0.7252

Epoch 00081: val_mDice did not improve from 0.72684
Epoch 82/300
 - 18s - loss: 0.8984 - acc: 0.9635 - mDice: 0.6737 - val_loss: 0.7005 - val_acc: 0.9789 - val_mDice: 0.7256

Epoch 00082: val_mDice did not improve from 0.72684
Epoch 83/300
 - 18s - loss: 0.8930 - acc: 0.9636 - mDice: 0.6759 - val_loss: 0.6944 - val_acc: 0.9793 - val_mDice: 0.7247

Epoch 00083: val_mDice did not improve from 0.72684
Epoch 84/300
 - 18s - loss: 0.8942 - acc: 0.9635 - mDice: 0.6748 - val_loss: 0.6810 - val_acc: 0.9793 - val_mDice: 0.7331

Epoch 00084: val_mDice improved from 0.72684 to 0.73307, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 85/300
 - 20s - loss: 0.8918 - acc: 0.9636 - mDice: 0.6760 - val_loss: 0.7023 - val_acc: 0.9794 - val_mDice: 0.7248

Epoch 00085: val_mDice did not improve from 0.73307
Epoch 86/300
 - 20s - loss: 0.8909 - acc: 0.9636 - mDice: 0.6763 - val_loss: 0.6954 - val_acc: 0.9795 - val_mDice: 0.7273

Epoch 00086: val_mDice did not improve from 0.73307
Epoch 87/300
 - 19s - loss: 0.8909 - acc: 0.9636 - mDice: 0.6767 - val_loss: 0.6902 - val_acc: 0.9793 - val_mDice: 0.7282

Epoch 00087: val_mDice did not improve from 0.73307
Epoch 88/300
 - 20s - loss: 0.8892 - acc: 0.9636 - mDice: 0.6768 - val_loss: 0.6884 - val_acc: 0.9790 - val_mDice: 0.7260

Epoch 00088: val_mDice did not improve from 0.73307
Epoch 89/300
 - 21s - loss: 0.8887 - acc: 0.9637 - mDice: 0.6770 - val_loss: 0.6993 - val_acc: 0.9795 - val_mDice: 0.7224

Epoch 00089: val_mDice did not improve from 0.73307
Epoch 90/300
 - 20s - loss: 0.8876 - acc: 0.9636 - mDice: 0.6775 - val_loss: 0.6995 - val_acc: 0.9792 - val_mDice: 0.7287

Epoch 00090: val_mDice did not improve from 0.73307
Epoch 91/300
 - 20s - loss: 0.8874 - acc: 0.9637 - mDice: 0.6776 - val_loss: 0.6951 - val_acc: 0.9788 - val_mDice: 0.7253

Epoch 00091: val_mDice did not improve from 0.73307
Epoch 92/300
 - 20s - loss: 0.8846 - acc: 0.9638 - mDice: 0.6783 - val_loss: 0.7082 - val_acc: 0.9795 - val_mDice: 0.7272

Epoch 00092: val_mDice did not improve from 0.73307
Epoch 93/300
 - 22s - loss: 0.8840 - acc: 0.9637 - mDice: 0.6787 - val_loss: 0.6908 - val_acc: 0.9795 - val_mDice: 0.7304

Epoch 00093: val_mDice did not improve from 0.73307
Epoch 94/300
 - 20s - loss: 0.8847 - acc: 0.9638 - mDice: 0.6788 - val_loss: 0.7039 - val_acc: 0.9795 - val_mDice: 0.7263

Epoch 00094: val_mDice did not improve from 0.73307
Epoch 95/300
 - 20s - loss: 0.8816 - acc: 0.9638 - mDice: 0.6799 - val_loss: 0.7005 - val_acc: 0.9797 - val_mDice: 0.7241

Epoch 00095: val_mDice did not improve from 0.73307
Epoch 96/300
 - 20s - loss: 0.8808 - acc: 0.9638 - mDice: 0.6797 - val_loss: 0.6948 - val_acc: 0.9795 - val_mDice: 0.7298

Epoch 00096: val_mDice did not improve from 0.73307
Epoch 97/300
 - 21s - loss: 0.8797 - acc: 0.9639 - mDice: 0.6803 - val_loss: 0.6902 - val_acc: 0.9794 - val_mDice: 0.7292

Epoch 00097: val_mDice did not improve from 0.73307
Epoch 98/300
 - 20s - loss: 0.8810 - acc: 0.9639 - mDice: 0.6798 - val_loss: 0.6824 - val_acc: 0.9794 - val_mDice: 0.7318

Epoch 00098: val_mDice did not improve from 0.73307
Epoch 99/300
 - 20s - loss: 0.8799 - acc: 0.9639 - mDice: 0.6800 - val_loss: 0.6868 - val_acc: 0.9793 - val_mDice: 0.7281

Epoch 00099: val_mDice did not improve from 0.73307
Epoch 100/300
 - 20s - loss: 0.8755 - acc: 0.9640 - mDice: 0.6820 - val_loss: 0.6968 - val_acc: 0.9796 - val_mDice: 0.7296

Epoch 00100: val_mDice did not improve from 0.73307
Epoch 101/300
 - 21s - loss: 0.8774 - acc: 0.9639 - mDice: 0.6816 - val_loss: 0.6935 - val_acc: 0.9796 - val_mDice: 0.7297

Epoch 00101: val_mDice did not improve from 0.73307
Epoch 102/300
 - 21s - loss: 0.8762 - acc: 0.9639 - mDice: 0.6815 - val_loss: 0.6928 - val_acc: 0.9795 - val_mDice: 0.7309

Epoch 00102: val_mDice did not improve from 0.73307
Epoch 103/300
 - 19s - loss: 0.8787 - acc: 0.9639 - mDice: 0.6810 - val_loss: 0.7008 - val_acc: 0.9789 - val_mDice: 0.7286

Epoch 00103: val_mDice did not improve from 0.73307
Epoch 104/300
 - 20s - loss: 0.8748 - acc: 0.9640 - mDice: 0.6822 - val_loss: 0.7023 - val_acc: 0.9795 - val_mDice: 0.7266

Epoch 00104: val_mDice did not improve from 0.73307
Epoch 105/300
 - 21s - loss: 0.8741 - acc: 0.9640 - mDice: 0.6820 - val_loss: 0.7052 - val_acc: 0.9796 - val_mDice: 0.7304

Epoch 00105: val_mDice did not improve from 0.73307
Epoch 106/300
 - 21s - loss: 0.8723 - acc: 0.9640 - mDice: 0.6829 - val_loss: 0.6882 - val_acc: 0.9799 - val_mDice: 0.7329

Epoch 00106: val_mDice did not improve from 0.73307
Epoch 107/300
 - 19s - loss: 0.8734 - acc: 0.9640 - mDice: 0.6829 - val_loss: 0.7013 - val_acc: 0.9796 - val_mDice: 0.7287

Epoch 00107: val_mDice did not improve from 0.73307
Epoch 108/300
 - 20s - loss: 0.8715 - acc: 0.9640 - mDice: 0.6834 - val_loss: 0.7066 - val_acc: 0.9792 - val_mDice: 0.7262

Epoch 00108: val_mDice did not improve from 0.73307
Epoch 109/300
 - 21s - loss: 0.8699 - acc: 0.9640 - mDice: 0.6834 - val_loss: 0.6970 - val_acc: 0.9795 - val_mDice: 0.7282

Epoch 00109: val_mDice did not improve from 0.73307
Epoch 110/300
 - 20s - loss: 0.8730 - acc: 0.9640 - mDice: 0.6828 - val_loss: 0.6946 - val_acc: 0.9792 - val_mDice: 0.7279

Epoch 00110: val_mDice did not improve from 0.73307
Epoch 111/300
 - 19s - loss: 0.8698 - acc: 0.9641 - mDice: 0.6837 - val_loss: 0.6845 - val_acc: 0.9798 - val_mDice: 0.7305

Epoch 00111: val_mDice did not improve from 0.73307
Epoch 112/300
 - 22s - loss: 0.8695 - acc: 0.9641 - mDice: 0.6840 - val_loss: 0.6983 - val_acc: 0.9795 - val_mDice: 0.7289

Epoch 00112: val_mDice did not improve from 0.73307
Epoch 113/300
 - 21s - loss: 0.8687 - acc: 0.9642 - mDice: 0.6840 - val_loss: 0.7027 - val_acc: 0.9794 - val_mDice: 0.7305

Epoch 00113: val_mDice did not improve from 0.73307
Epoch 114/300
 - 26s - loss: 0.8677 - acc: 0.9642 - mDice: 0.6842 - val_loss: 0.6868 - val_acc: 0.9798 - val_mDice: 0.7309

Epoch 00114: val_mDice did not improve from 0.73307
Restoring model weights from the end of the best epoch
Epoch 00114: early stopping
{'val_loss': [4.370564208803285, 3.361142444167713, 3.0760523775905773, 2.7832607622609173, 2.510891836248069, 2.2003449731813003, 1.9488589799318028, 1.7747362171779353, 1.582010926353919, 1.4605204988928402, 1.3525212967481899, 1.2493853466306555, 1.2026180068282766, 1.1386286548047613, 1.0583394051090236, 1.0003745368267607, 0.9616028545318619, 0.9141998263335449, 0.907506736439448, 0.8777201279644135, 0.8679903609710827, 0.8407199900708824, 0.8330483449501888, 0.8137294570727983, 0.8102308830363586, 0.8084382606118579, 0.7978852057235529, 0.7949523312511582, 0.7950010242476921, 0.7792869854268644, 0.7852706724030069, 0.776625907581042, 0.7539503012771331, 0.7730356151597542, 0.7604165548080015, 0.7637554989326111, 0.7482383276409901, 0.7434495108661514, 0.7312132340343621, 0.7354968653682339, 0.7345345758739763, 0.7410531207319384, 0.7667896885989989, 0.7294606137386417, 0.7477526054539794, 0.7229487464769951, 0.7191758458151782, 0.7179903159508149, 0.7318330331175935, 0.7206349087757961, 0.7173777893108726, 0.7288229423041683, 0.7243187190701472, 0.719067995423995, 0.7313624066218996, 0.7262805892833123, 0.7377352323940541, 0.7070559821138687, 0.7078382197240803, 0.711837979170068, 0.7154830705578236, 0.7020802278575268, 0.697668042929672, 0.7066868668800783, 0.7081917297052771, 0.7335547533874295, 0.702313233978116, 0.7136097343405949, 0.7096073189202476, 0.6979965214205232, 0.6897104176451424, 0.6905558958449723, 0.7066504512716496, 0.6956172877051882, 0.6948526855654269, 0.7102514339305299, 0.7010234548519024, 0.6994415231594976, 0.7123612787639886, 0.7000808876672888, 0.700539336023685, 0.7005180531364968, 0.6943665108075452, 0.681039479986925, 0.7022905032639656, 0.6954342261556501, 0.6902426988409277, 0.6884326086263293, 0.6993284148882049, 0.699522851175322, 0.6951249932910636, 0.7081533874951157, 0.6907690624765075, 0.7039029786153721, 0.7005326593807977, 0.6948204276423952, 0.6902490535633728, 0.6824162611343789, 0.6868386250162273, 0.6968452059755138, 0.6935057392491891, 0.6927897518325762, 0.7008440599106905, 0.7023368779535264, 0.7051974698916554, 0.6881501417534024, 0.7013437311531221, 0.7065817646997509, 0.6970062150982266, 0.6945699882396603, 0.6844888807142728, 0.6983457328242291, 0.7027466296842101, 0.686769997218568], 'val_acc': [0.9217279151743287, 0.9217279151743287, 0.92117176391761, 0.9195592813078464, 0.9204020448513445, 0.9322136664538192, 0.9419741599798449, 0.9465249947227069, 0.9523335682964423, 0.9568393160315121, 0.9604730024180299, 0.9644877632582027, 0.9654460482307017, 0.9684956241687385, 0.9707050629198489, 0.9714425136676391, 0.9727953609052211, 0.9738981205858559, 0.97347458997132, 0.974167967113302, 0.9749498432511762, 0.9751318314865277, 0.9758949639012324, 0.9759370836557126, 0.9766824436753649, 0.9764254291852316, 0.9764810492379746, 0.9766735690420011, 0.9770747132222596, 0.9763872696642291, 0.9767821595395682, 0.9769693972894651, 0.9771997583539862, 0.9771155193371177, 0.9772708474421034, 0.9767917042792273, 0.9780004081711311, 0.9778773364513897, 0.9777914500950045, 0.9772464840281736, 0.9776157196092162, 0.978131726614831, 0.9765504829900798, 0.9779629014101806, 0.9776591513425081, 0.9782264860052812, 0.9776328313707444, 0.9783643689564016, 0.9778105324389887, 0.9785855057561853, 0.9790287811320633, 0.9783505512587918, 0.9791120357803762, 0.9784120872416856, 0.9785572171088219, 0.9782314299921995, 0.9784163657356711, 0.9790047602141728, 0.9782768286787689, 0.9786082214000178, 0.9788464783884054, 0.979219983175197, 0.9792308419850588, 0.9790462185969909, 0.9786931194511115, 0.9782166177766365, 0.97936015982869, 0.9789066958722684, 0.9789099741892426, 0.9790669649501088, 0.9788836671964057, 0.9790817703378951, 0.97914922514198, 0.9794914675693885, 0.9789511148036449, 0.9786052540851944, 0.9789475104142022, 0.9791923386762755, 0.9784282154343077, 0.9791261957279792, 0.9790442562570759, 0.9788764142522625, 0.9793354889187651, 0.9793022455814823, 0.979414471408777, 0.9794957535677773, 0.9793456844501082, 0.9790060831420315, 0.9795365465806857, 0.9791883863777814, 0.978847139575533, 0.9794710668493966, 0.9794572460762119, 0.979521419672282, 0.9796767444556466, 0.9794615406246993, 0.9793983390948844, 0.9793512863025331, 0.9793460057246796, 0.9795553098030012, 0.9795793344115817, 0.9794618506426659, 0.9789050471794987, 0.9794845513392036, 0.9795967769204524, 0.9798834048311531, 0.9795984198311412, 0.9791808169569639, 0.9795484016923344, 0.9792170082329473, 0.9797807313094321, 0.9794523084864897, 0.9794045887249296, 0.9798014556414326], 'val_mDice': [0.019271828893522115, 0.05436193710048871, 0.07548236676229413, 0.10402925243318635, 0.14194002298501746, 0.18808839261777877, 0.2488381684257027, 0.3053494458720165, 0.36351734673521713, 0.4065171873852441, 0.44460100415321324, 0.48146790518234145, 0.5013383067798319, 0.524448390408074, 0.555245507366271, 0.5800097859680837, 0.6033476090406609, 0.6244377927514422, 0.6329064434403852, 0.6394876108819117, 0.6408501997574687, 0.6553915331238195, 0.6594032442852685, 0.6659534561867807, 0.6710239627289944, 0.6700624023920735, 0.6773930175385608, 0.6747043515383521, 0.6793830296326471, 0.6829233609978014, 0.683008539787387, 0.6852115225373653, 0.6900923854918426, 0.6893219524615812, 0.68842786802719, 0.690554798941125, 0.6931745759350842, 0.6962482812357884, 0.7023189738931056, 0.7022204624856097, 0.7023808262296506, 0.7056657291172213, 0.7010241331699832, 0.7068049565065264, 0.7017295301514145, 0.70741797711458, 0.7070543000203537, 0.7096454186213151, 0.7059687024176551, 0.7093055077873639, 0.7097340988300902, 0.7087133518190453, 0.7098849525884701, 0.7138569764677585, 0.710618677400091, 0.7104418988813433, 0.7104990801575014, 0.7158537861978552, 0.7194626616127597, 0.7147865617730423, 0.7148990281103074, 0.7187710275837019, 0.7201497824814543, 0.7184598118036032, 0.7195531770171765, 0.7130622960957703, 0.7230328776642019, 0.7168365902698938, 0.719606082013763, 0.7215598544838259, 0.7256527584280638, 0.7258493283953829, 0.7206141566713528, 0.7260375677370557, 0.7242404432857737, 0.7257229262584257, 0.7255670184075402, 0.7268433223321834, 0.7246241807568553, 0.7218442244918477, 0.7251787127848134, 0.7256367368348735, 0.7247162689488492, 0.733067744164521, 0.7247956460351422, 0.7273233900129241, 0.7282207500577834, 0.7260225923929913, 0.7224197585762346, 0.7287478245202725, 0.7253081145301323, 0.7272388693348911, 0.7304456154628435, 0.7262718141140461, 0.7241328594239258, 0.7298401083001411, 0.7292133808382032, 0.7318463448523491, 0.7280787663809163, 0.7296200644982243, 0.7296891588298652, 0.7309059877144662, 0.7286001111700808, 0.7266149693106227, 0.7304423255201956, 0.732867887453152, 0.7286733252345224, 0.7262285205355862, 0.7281918165238404, 0.7279483494497797, 0.7305452133479872, 0.7288974049290636, 0.7304731586523223, 0.7309345469509239], 'loss': [60.80829949603321, 7.167028731197396, 5.485919693702441, 4.6699779315526655, 4.058292924717215, 3.544184316249517, 3.1173621385058214, 2.7863121091080987, 2.527943088554499, 2.3201305707656372, 2.1516266023882085, 2.019751672346722, 1.8994761259395807, 1.8043242800141792, 1.707783412657178, 1.6198852322168216, 1.531309094667036, 1.4568282264298802, 1.402437698223268, 1.3532270159930924, 1.3119129153319524, 1.2786729053136185, 1.2415331586508527, 1.2185853627606682, 1.1962459057832864, 1.1726365690160714, 1.1576133567919047, 1.1366894478754637, 1.1240186435896713, 1.1079327071271081, 1.093838848844473, 1.0868739038741415, 1.0732730343058823, 1.0637068435645827, 1.0607278080666467, 1.044361487191134, 1.040765717828476, 1.0317001030728103, 1.0231472742082055, 1.0199660235325931, 1.0122573567954287, 1.0073132444487172, 1.003094587123619, 1.0008966548576086, 0.9920315235490186, 0.986750143950043, 0.9812111234875605, 0.9763466388606388, 0.9751301013486665, 0.9719028949580957, 0.9631817739875954, 0.9621203404879951, 0.959231319947376, 0.9554274090654047, 0.9537446585637105, 0.9483814961106788, 0.9464084480268334, 0.9437892084221923, 0.9413293171020063, 0.9397759077114509, 0.9351161445186507, 0.9354083279678467, 0.9328850402107721, 0.9311674799488073, 0.9263602142149491, 0.9256845568241127, 0.9245250419098977, 0.9212827761574124, 0.9213736276083355, 0.9186264898175125, 0.9169149140355579, 0.9153035657913212, 0.9155837709917384, 0.9108106714602384, 0.9096932404147203, 0.9094182013084474, 0.9073344995718114, 0.9030767919013915, 0.9029015811511204, 0.9010355357398331, 0.8978899674481642, 0.8984197124550557, 0.8929516254773652, 0.8941696407417993, 0.8917931117418133, 0.8909119211434464, 0.8908759233189677, 0.8891820592486775, 0.8886934885595476, 0.8875812555885497, 0.8873812897352834, 0.8845870140019083, 0.88404170290109, 0.8847008889675824, 0.8816384329683661, 0.8807561197684037, 0.8796766432509776, 0.8810285041333383, 0.8799150598086176, 0.8755083540216505, 0.8773514981383153, 0.8762094676565777, 0.8787103380099498, 0.8748220772383918, 0.8741210482130194, 0.87225546009335, 0.8734408540431884, 0.871510628259407, 0.869893683677133, 0.8729729866935952, 0.8697649447266516, 0.8695268107607964, 0.8686817434741171, 0.8676659881442266], 'acc': [0.7431005213086246, 0.9007580249768496, 0.902650689243103, 0.9037226271324691, 0.9068497129661928, 0.9133685679845147, 0.9191752782664038, 0.9243776906439192, 0.9284608932249808, 0.9315279749973252, 0.9344990328968582, 0.9373824000928007, 0.9399968703436004, 0.9422807265985031, 0.9445817648069028, 0.9464141603996112, 0.948288583210268, 0.9499334277914793, 0.9509447973469775, 0.9519299874164507, 0.9528489253003927, 0.9537779302337388, 0.9549323934443332, 0.9555305955317187, 0.9561438851177707, 0.9566673524259581, 0.9568968782468773, 0.9575055122005361, 0.9579044310765304, 0.9582907476629026, 0.9585698232150801, 0.9587238743662806, 0.9590536878776346, 0.9592777851631796, 0.9592702373317753, 0.9597765053616863, 0.9598314912443887, 0.9600522863087633, 0.9603286193853237, 0.9603166907548848, 0.9604854388284831, 0.9606404896208971, 0.9607128332317203, 0.9607413992595354, 0.9609760647034172, 0.9610412741350849, 0.9612022574616412, 0.9613290623503025, 0.9614551802836884, 0.9615234861531632, 0.961615544195986, 0.9617242518147792, 0.9617541903082272, 0.9619121995594612, 0.96193823861085, 0.962114783070211, 0.9621994717467904, 0.962223149346713, 0.9623077512428019, 0.9623591699861017, 0.9624888013762736, 0.9624259779739129, 0.9625669667109801, 0.9626087700164714, 0.9627185530812865, 0.9627553665939765, 0.9626804828601092, 0.9628216065582068, 0.9628616937282463, 0.9628444257629837, 0.9629898123106809, 0.9629911820928948, 0.9630546912405011, 0.9631042611650217, 0.9631674528363954, 0.9631368755824474, 0.9632146241686524, 0.9633248828748316, 0.9633501684691305, 0.9633573369348365, 0.9634662827586741, 0.9634978299582805, 0.963596494393728, 0.9635466874955462, 0.9635794251367134, 0.9636239905203047, 0.9636417511954694, 0.9636447508949524, 0.9637077531183651, 0.9636410852733591, 0.9636699027738396, 0.9637668816662358, 0.9636911598372522, 0.9637610265526476, 0.963811444373526, 0.9638031131759418, 0.9638737040158812, 0.9638800612135436, 0.9638780362998383, 0.9639623135449296, 0.96391342065344, 0.9639449801811149, 0.9639330809686358, 0.9639622585739872, 0.9639970921931985, 0.9640374458260373, 0.9639973090447758, 0.9640398446318356, 0.9640284583154031, 0.9639983583256827, 0.964062100923628, 0.9641182212448643, 0.964158090666481, 0.9641607009356649], 'mDice': [0.014577207551676987, 0.0330982387721172, 0.04925765000205422, 0.06472222339820116, 0.08641107985849936, 0.11785056072607342, 0.15984496812006724, 0.20226655988205525, 0.24739132839532407, 0.2853885052744802, 0.3186829672925706, 0.34790171698849726, 0.37538417681592556, 0.39842583514182356, 0.42379227278837306, 0.44864774608358665, 0.47455764179130655, 0.49667470525849655, 0.5128901961960427, 0.527018296311458, 0.539603661218178, 0.5498197788992332, 0.5603577537470568, 0.5682619621909146, 0.5754454044857827, 0.5826986444745225, 0.5871664185796742, 0.5943318333237445, 0.5984676325622993, 0.6036742475939901, 0.608305732731834, 0.6101946841355067, 0.6152667342363749, 0.6178426480048421, 0.6186345572442578, 0.6242449576213532, 0.6253406270922071, 0.6282449806821297, 0.6305920972099787, 0.631990805656209, 0.6344922062304073, 0.6363292220229888, 0.6371705153477001, 0.6384307904405186, 0.6411379769547674, 0.6424641118631574, 0.6445695291648539, 0.6466452786496525, 0.6475753059941258, 0.6484155510771323, 0.6508281156260557, 0.651219239689326, 0.6520691259481869, 0.6534779143484333, 0.6544783282299899, 0.6560145564784803, 0.6567311313262213, 0.6576268283669409, 0.6581057552110332, 0.6593140667837788, 0.6606877962786172, 0.6604911263970734, 0.6615172354039583, 0.6618542206979237, 0.6636743333563475, 0.6637390139124574, 0.6643645616058294, 0.6654807339285165, 0.665447172143165, 0.6659316308449412, 0.6671289069387205, 0.6673334686133182, 0.6672470892617376, 0.6685680579692161, 0.6691834768803102, 0.6696854606430941, 0.6702065063470982, 0.6720870001264253, 0.6718808397960344, 0.6729669781681573, 0.6738867246723129, 0.6737126857789684, 0.6758838256219135, 0.6747930033667605, 0.6760498371063339, 0.6763382315037784, 0.6766574039418229, 0.6768052616195118, 0.6769785011458118, 0.677496527946448, 0.6775937983634963, 0.6783492554264761, 0.6786689580070508, 0.6787755998487202, 0.6799192935306644, 0.6796872497658357, 0.6802824380818033, 0.6798431712387569, 0.6800422867613702, 0.6820072760182233, 0.6816014349318246, 0.6815198806310457, 0.6809904441390483, 0.6822097528684046, 0.6819983021311011, 0.6828965900307029, 0.6828544263712171, 0.6833500886891604, 0.6833604977784021, 0.6828103910376242, 0.6836958368908741, 0.6840158384484609, 0.6840103426140762, 0.684188568338677]}
predicting test subjects:   0%|          | 0/15 [00:00<?, ?it/s]predicting test subjects:   7%|▋         | 1/15 [00:03<00:43,  3.09s/it]predicting test subjects:  13%|█▎        | 2/15 [00:05<00:39,  3.03s/it]predicting test subjects:  20%|██        | 3/15 [00:08<00:35,  2.98s/it]predicting test subjects:  27%|██▋       | 4/15 [00:11<00:32,  2.94s/it]predicting test subjects:  33%|███▎      | 5/15 [00:15<00:31,  3.15s/it]predicting test subjects:  40%|████      | 6/15 [00:18<00:29,  3.28s/it]predicting test subjects:  47%|████▋     | 7/15 [00:20<00:23,  2.91s/it]predicting test subjects:  53%|█████▎    | 8/15 [00:24<00:21,  3.09s/it]predicting test subjects:  60%|██████    | 9/15 [00:27<00:17,  2.96s/it]predicting test subjects:  67%|██████▋   | 10/15 [00:29<00:13,  2.77s/it]predicting test subjects:  73%|███████▎  | 11/15 [00:31<00:10,  2.68s/it]predicting test subjects:  80%|████████  | 12/15 [00:35<00:08,  2.81s/it]predicting test subjects:  87%|████████▋ | 13/15 [00:38<00:05,  2.86s/it]predicting test subjects:  93%|█████████▎| 14/15 [00:40<00:02,  2.86s/it]predicting test subjects: 100%|██████████| 15/15 [00:44<00:00,  3.00s/it]
predicting train subjects:   0%|          | 0/532 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/532 [00:04<35:43,  4.04s/it]predicting train subjects:   0%|          | 2/532 [00:06<31:34,  3.57s/it]predicting train subjects:   1%|          | 3/532 [00:09<29:44,  3.37s/it]predicting train subjects:   1%|          | 4/532 [00:12<27:59,  3.18s/it]predicting train subjects:   1%|          | 5/532 [00:14<26:38,  3.03s/it]predicting train subjects:   1%|          | 6/532 [00:17<25:58,  2.96s/it]predicting train subjects:   1%|▏         | 7/532 [00:20<26:47,  3.06s/it]predicting train subjects:   2%|▏         | 8/532 [00:23<25:04,  2.87s/it]predicting train subjects:   2%|▏         | 9/532 [00:26<26:39,  3.06s/it]predicting train subjects:   2%|▏         | 10/532 [00:29<25:56,  2.98s/it]predicting train subjects:   2%|▏         | 11/532 [00:32<24:37,  2.84s/it]predicting train subjects:   2%|▏         | 12/532 [00:35<26:09,  3.02s/it]predicting train subjects:   2%|▏         | 13/532 [00:38<26:57,  3.12s/it]predicting train subjects:   3%|▎         | 14/532 [00:41<24:42,  2.86s/it]predicting train subjects:   3%|▎         | 15/532 [00:44<25:37,  2.97s/it]predicting train subjects:   3%|▎         | 16/532 [00:48<27:47,  3.23s/it]predicting train subjects:   3%|▎         | 17/532 [00:50<25:42,  3.00s/it]predicting train subjects:   3%|▎         | 18/532 [00:53<24:38,  2.88s/it]predicting train subjects:   4%|▎         | 19/532 [00:55<21:56,  2.57s/it]predicting train subjects:   4%|▍         | 20/532 [00:58<22:52,  2.68s/it]predicting train subjects:   4%|▍         | 21/532 [01:00<23:17,  2.73s/it]predicting train subjects:   4%|▍         | 22/532 [01:03<23:50,  2.81s/it]predicting train subjects:   4%|▍         | 23/532 [01:06<23:46,  2.80s/it]predicting train subjects:   5%|▍         | 24/532 [01:09<23:25,  2.77s/it]predicting train subjects:   5%|▍         | 25/532 [01:12<24:42,  2.92s/it]predicting train subjects:   5%|▍         | 26/532 [01:15<23:38,  2.80s/it]predicting train subjects:   5%|▌         | 27/532 [01:18<23:44,  2.82s/it]predicting train subjects:   5%|▌         | 28/532 [01:20<23:45,  2.83s/it]predicting train subjects:   5%|▌         | 29/532 [01:23<23:33,  2.81s/it]predicting train subjects:   6%|▌         | 30/532 [01:25<21:01,  2.51s/it]predicting train subjects:   6%|▌         | 31/532 [01:27<20:21,  2.44s/it]predicting train subjects:   6%|▌         | 32/532 [01:29<19:41,  2.36s/it]predicting train subjects:   6%|▌         | 33/532 [01:31<18:30,  2.23s/it]predicting train subjects:   6%|▋         | 34/532 [01:34<19:21,  2.33s/it]predicting train subjects:   7%|▋         | 35/532 [01:36<18:50,  2.28s/it]predicting train subjects:   7%|▋         | 36/532 [01:39<19:07,  2.31s/it]predicting train subjects:   7%|▋         | 37/532 [01:41<18:35,  2.25s/it]predicting train subjects:   7%|▋         | 38/532 [01:43<18:34,  2.26s/it]predicting train subjects:   7%|▋         | 39/532 [01:45<18:22,  2.24s/it]predicting train subjects:   8%|▊         | 40/532 [01:47<17:48,  2.17s/it]predicting train subjects:   8%|▊         | 41/532 [01:49<18:00,  2.20s/it]predicting train subjects:   8%|▊         | 42/532 [01:52<18:13,  2.23s/it]predicting train subjects:   8%|▊         | 43/532 [01:53<17:03,  2.09s/it]predicting train subjects:   8%|▊         | 44/532 [01:55<16:20,  2.01s/it]predicting train subjects:   8%|▊         | 45/532 [01:57<16:29,  2.03s/it]predicting train subjects:   9%|▊         | 46/532 [02:00<16:54,  2.09s/it]predicting train subjects:   9%|▉         | 47/532 [02:02<18:24,  2.28s/it]predicting train subjects:   9%|▉         | 48/532 [02:05<18:39,  2.31s/it]predicting train subjects:   9%|▉         | 49/532 [02:07<18:00,  2.24s/it]predicting train subjects:   9%|▉         | 50/532 [02:09<18:27,  2.30s/it]predicting train subjects:  10%|▉         | 51/532 [02:11<18:04,  2.25s/it]predicting train subjects:  10%|▉         | 52/532 [02:14<17:55,  2.24s/it]predicting train subjects:  10%|▉         | 53/532 [02:16<17:27,  2.19s/it]predicting train subjects:  10%|█         | 54/532 [02:18<18:09,  2.28s/it]predicting train subjects:  10%|█         | 55/532 [02:20<18:21,  2.31s/it]predicting train subjects:  11%|█         | 56/532 [02:23<17:54,  2.26s/it]predicting train subjects:  11%|█         | 57/532 [02:25<17:37,  2.23s/it]predicting train subjects:  11%|█         | 58/532 [02:27<18:00,  2.28s/it]predicting train subjects:  11%|█         | 59/532 [02:30<18:52,  2.39s/it]predicting train subjects:  11%|█▏        | 60/532 [02:32<17:36,  2.24s/it]predicting train subjects:  11%|█▏        | 61/532 [02:34<17:00,  2.17s/it]predicting train subjects:  12%|█▏        | 62/532 [02:36<17:50,  2.28s/it]predicting train subjects:  12%|█▏        | 63/532 [02:39<18:28,  2.36s/it]predicting train subjects:  12%|█▏        | 64/532 [02:41<17:33,  2.25s/it]predicting train subjects:  12%|█▏        | 65/532 [02:43<17:34,  2.26s/it]predicting train subjects:  12%|█▏        | 66/532 [02:46<18:21,  2.36s/it]predicting train subjects:  13%|█▎        | 67/532 [02:48<19:04,  2.46s/it]predicting train subjects:  13%|█▎        | 68/532 [02:51<19:02,  2.46s/it]predicting train subjects:  13%|█▎        | 69/532 [02:53<18:18,  2.37s/it]predicting train subjects:  13%|█▎        | 70/532 [02:55<17:24,  2.26s/it]predicting train subjects:  13%|█▎        | 71/532 [02:57<16:48,  2.19s/it]predicting train subjects:  14%|█▎        | 72/532 [02:59<16:21,  2.13s/it]predicting train subjects:  14%|█▎        | 73/532 [03:02<17:33,  2.30s/it]predicting train subjects:  14%|█▍        | 74/532 [03:05<18:46,  2.46s/it]predicting train subjects:  14%|█▍        | 75/532 [03:08<20:46,  2.73s/it]predicting train subjects:  14%|█▍        | 76/532 [03:10<19:23,  2.55s/it]predicting train subjects:  14%|█▍        | 77/532 [03:12<18:55,  2.49s/it]predicting train subjects:  15%|█▍        | 78/532 [03:15<18:25,  2.44s/it]predicting train subjects:  15%|█▍        | 79/532 [03:17<17:51,  2.37s/it]predicting train subjects:  15%|█▌        | 80/532 [03:19<17:30,  2.32s/it]predicting train subjects:  15%|█▌        | 81/532 [03:21<17:29,  2.33s/it]predicting train subjects:  15%|█▌        | 82/532 [03:24<17:20,  2.31s/it]predicting train subjects:  16%|█▌        | 83/532 [03:26<16:46,  2.24s/it]predicting train subjects:  16%|█▌        | 84/532 [03:28<16:11,  2.17s/it]predicting train subjects:  16%|█▌        | 85/532 [03:30<16:03,  2.16s/it]predicting train subjects:  16%|█▌        | 86/532 [03:32<15:17,  2.06s/it]predicting train subjects:  16%|█▋        | 87/532 [03:34<15:07,  2.04s/it]predicting train subjects:  17%|█▋        | 88/532 [03:36<14:58,  2.02s/it]predicting train subjects:  17%|█▋        | 89/532 [03:38<14:43,  1.99s/it]predicting train subjects:  17%|█▋        | 90/532 [03:40<15:09,  2.06s/it]predicting train subjects:  17%|█▋        | 91/532 [03:42<15:26,  2.10s/it]predicting train subjects:  17%|█▋        | 92/532 [03:44<15:30,  2.12s/it]predicting train subjects:  17%|█▋        | 93/532 [03:47<15:50,  2.16s/it]predicting train subjects:  18%|█▊        | 94/532 [03:49<15:54,  2.18s/it]predicting train subjects:  18%|█▊        | 95/532 [03:51<16:57,  2.33s/it]predicting train subjects:  18%|█▊        | 96/532 [03:54<16:57,  2.33s/it]predicting train subjects:  18%|█▊        | 97/532 [03:56<17:02,  2.35s/it]predicting train subjects:  18%|█▊        | 98/532 [03:59<17:05,  2.36s/it]predicting train subjects:  19%|█▊        | 99/532 [04:01<16:29,  2.29s/it]predicting train subjects:  19%|█▉        | 100/532 [04:03<16:07,  2.24s/it]predicting train subjects:  19%|█▉        | 101/532 [04:04<14:46,  2.06s/it]predicting train subjects:  19%|█▉        | 102/532 [04:06<13:46,  1.92s/it]predicting train subjects:  19%|█▉        | 103/532 [04:08<13:15,  1.86s/it]predicting train subjects:  20%|█▉        | 104/532 [04:09<12:48,  1.80s/it]predicting train subjects:  20%|█▉        | 105/532 [04:11<12:35,  1.77s/it]predicting train subjects:  20%|█▉        | 106/532 [04:13<12:23,  1.74s/it]predicting train subjects:  20%|██        | 107/532 [04:14<12:07,  1.71s/it]predicting train subjects:  20%|██        | 108/532 [04:16<12:04,  1.71s/it]predicting train subjects:  20%|██        | 109/532 [04:18<11:52,  1.68s/it]predicting train subjects:  21%|██        | 110/532 [04:19<11:35,  1.65s/it]predicting train subjects:  21%|██        | 111/532 [04:21<11:27,  1.63s/it]predicting train subjects:  21%|██        | 112/532 [04:22<11:17,  1.61s/it]predicting train subjects:  21%|██        | 113/532 [04:24<11:43,  1.68s/it]predicting train subjects:  21%|██▏       | 114/532 [04:26<12:03,  1.73s/it]predicting train subjects:  22%|██▏       | 115/532 [04:28<12:27,  1.79s/it]predicting train subjects:  22%|██▏       | 116/532 [04:30<12:34,  1.81s/it]predicting train subjects:  22%|██▏       | 117/532 [04:32<12:48,  1.85s/it]predicting train subjects:  22%|██▏       | 118/532 [04:34<12:48,  1.86s/it]predicting train subjects:  22%|██▏       | 119/532 [04:35<12:34,  1.83s/it]predicting train subjects:  23%|██▎       | 120/532 [04:37<12:42,  1.85s/it]predicting train subjects:  23%|██▎       | 121/532 [04:39<12:38,  1.84s/it]predicting train subjects:  23%|██▎       | 122/532 [04:41<12:35,  1.84s/it]predicting train subjects:  23%|██▎       | 123/532 [04:43<12:28,  1.83s/it]predicting train subjects:  23%|██▎       | 124/532 [04:45<12:20,  1.81s/it]predicting train subjects:  23%|██▎       | 125/532 [04:47<12:41,  1.87s/it]predicting train subjects:  24%|██▎       | 126/532 [04:49<12:56,  1.91s/it]predicting train subjects:  24%|██▍       | 127/532 [04:51<13:08,  1.95s/it]predicting train subjects:  24%|██▍       | 128/532 [04:53<13:11,  1.96s/it]predicting train subjects:  24%|██▍       | 129/532 [04:55<13:11,  1.96s/it]predicting train subjects:  24%|██▍       | 130/532 [04:57<13:36,  2.03s/it]predicting train subjects:  25%|██▍       | 131/532 [04:59<14:20,  2.15s/it]predicting train subjects:  25%|██▍       | 132/532 [05:02<14:31,  2.18s/it]predicting train subjects:  25%|██▌       | 133/532 [05:04<14:33,  2.19s/it]predicting train subjects:  25%|██▌       | 134/532 [05:06<14:46,  2.23s/it]predicting train subjects:  25%|██▌       | 135/532 [05:08<14:53,  2.25s/it]predicting train subjects:  26%|██▌       | 136/532 [05:11<14:53,  2.26s/it]predicting train subjects:  26%|██▌       | 137/532 [05:13<14:57,  2.27s/it]predicting train subjects:  26%|██▌       | 138/532 [05:15<14:53,  2.27s/it]predicting train subjects:  26%|██▌       | 139/532 [05:17<14:46,  2.26s/it]predicting train subjects:  26%|██▋       | 140/532 [05:20<14:46,  2.26s/it]predicting train subjects:  27%|██▋       | 141/532 [05:22<14:43,  2.26s/it]predicting train subjects:  27%|██▋       | 142/532 [05:24<14:45,  2.27s/it]predicting train subjects:  27%|██▋       | 143/532 [05:26<13:30,  2.08s/it]predicting train subjects:  27%|██▋       | 144/532 [05:28<12:49,  1.98s/it]predicting train subjects:  27%|██▋       | 145/532 [05:29<12:19,  1.91s/it]predicting train subjects:  27%|██▋       | 146/532 [05:31<11:57,  1.86s/it]predicting train subjects:  28%|██▊       | 147/532 [05:33<11:41,  1.82s/it]predicting train subjects:  28%|██▊       | 148/532 [05:34<11:18,  1.77s/it]predicting train subjects:  28%|██▊       | 149/532 [05:36<11:18,  1.77s/it]predicting train subjects:  28%|██▊       | 150/532 [05:38<11:19,  1.78s/it]predicting train subjects:  28%|██▊       | 151/532 [05:40<11:22,  1.79s/it]predicting train subjects:  29%|██▊       | 152/532 [05:42<11:25,  1.80s/it]predicting train subjects:  29%|██▉       | 153/532 [05:44<11:26,  1.81s/it]predicting train subjects:  29%|██▉       | 154/532 [05:46<11:43,  1.86s/it]predicting train subjects:  29%|██▉       | 155/532 [05:48<12:48,  2.04s/it]predicting train subjects:  29%|██▉       | 156/532 [05:50<13:12,  2.11s/it]predicting train subjects:  30%|██▉       | 157/532 [05:53<13:27,  2.15s/it]predicting train subjects:  30%|██▉       | 158/532 [05:55<13:41,  2.20s/it]predicting train subjects:  30%|██▉       | 159/532 [05:57<13:53,  2.24s/it]predicting train subjects:  30%|███       | 160/532 [05:59<13:53,  2.24s/it]predicting train subjects:  30%|███       | 161/532 [06:01<13:03,  2.11s/it]predicting train subjects:  30%|███       | 162/532 [06:03<12:36,  2.04s/it]predicting train subjects:  31%|███       | 163/532 [06:05<12:04,  1.96s/it]predicting train subjects:  31%|███       | 164/532 [06:07<11:45,  1.92s/it]predicting train subjects:  31%|███       | 165/532 [06:09<11:41,  1.91s/it]predicting train subjects:  31%|███       | 166/532 [06:10<11:33,  1.90s/it]predicting train subjects:  31%|███▏      | 167/532 [06:12<11:23,  1.87s/it]predicting train subjects:  32%|███▏      | 168/532 [06:14<11:15,  1.86s/it]predicting train subjects:  32%|███▏      | 169/532 [06:16<11:08,  1.84s/it]predicting train subjects:  32%|███▏      | 170/532 [06:18<11:02,  1.83s/it]predicting train subjects:  32%|███▏      | 171/532 [06:19<11:00,  1.83s/it]predicting train subjects:  32%|███▏      | 172/532 [06:21<10:57,  1.83s/it]predicting train subjects:  33%|███▎      | 173/532 [06:23<10:40,  1.78s/it]predicting train subjects:  33%|███▎      | 174/532 [06:25<10:34,  1.77s/it]predicting train subjects:  33%|███▎      | 175/532 [06:26<10:22,  1.75s/it]predicting train subjects:  33%|███▎      | 176/532 [06:28<10:17,  1.73s/it]predicting train subjects:  33%|███▎      | 177/532 [06:30<10:17,  1.74s/it]predicting train subjects:  33%|███▎      | 178/532 [06:32<10:12,  1.73s/it]predicting train subjects:  34%|███▎      | 179/532 [06:33<10:05,  1.72s/it]predicting train subjects:  34%|███▍      | 180/532 [06:35<10:04,  1.72s/it]predicting train subjects:  34%|███▍      | 181/532 [06:37<09:59,  1.71s/it]predicting train subjects:  34%|███▍      | 182/532 [06:38<10:03,  1.73s/it]predicting train subjects:  34%|███▍      | 183/532 [06:40<10:06,  1.74s/it]predicting train subjects:  35%|███▍      | 184/532 [06:42<10:06,  1.74s/it]predicting train subjects:  35%|███▍      | 185/532 [06:44<09:57,  1.72s/it]predicting train subjects:  35%|███▍      | 186/532 [06:45<09:49,  1.70s/it]predicting train subjects:  35%|███▌      | 187/532 [06:47<09:48,  1.71s/it]predicting train subjects:  35%|███▌      | 188/532 [06:49<09:45,  1.70s/it]predicting train subjects:  36%|███▌      | 189/532 [06:50<09:44,  1.70s/it]predicting train subjects:  36%|███▌      | 190/532 [06:52<09:38,  1.69s/it]predicting train subjects:  36%|███▌      | 191/532 [06:54<10:37,  1.87s/it]predicting train subjects:  36%|███▌      | 192/532 [06:57<11:17,  1.99s/it]predicting train subjects:  36%|███▋      | 193/532 [06:59<11:40,  2.07s/it]predicting train subjects:  36%|███▋      | 194/532 [07:01<11:59,  2.13s/it]predicting train subjects:  37%|███▋      | 195/532 [07:03<12:08,  2.16s/it]predicting train subjects:  37%|███▋      | 196/532 [07:06<12:23,  2.21s/it]predicting train subjects:  37%|███▋      | 197/532 [07:08<11:56,  2.14s/it]predicting train subjects:  37%|███▋      | 198/532 [07:10<11:38,  2.09s/it]predicting train subjects:  37%|███▋      | 199/532 [07:12<11:27,  2.06s/it]predicting train subjects:  38%|███▊      | 200/532 [07:14<11:21,  2.05s/it]predicting train subjects:  38%|███▊      | 201/532 [07:16<11:14,  2.04s/it]predicting train subjects:  38%|███▊      | 202/532 [07:18<11:06,  2.02s/it]predicting train subjects:  38%|███▊      | 203/532 [07:19<10:36,  1.94s/it]predicting train subjects:  38%|███▊      | 204/532 [07:21<10:16,  1.88s/it]predicting train subjects:  39%|███▊      | 205/532 [07:23<10:06,  1.85s/it]predicting train subjects:  39%|███▊      | 206/532 [07:25<09:55,  1.83s/it]predicting train subjects:  39%|███▉      | 207/532 [07:27<09:53,  1.83s/it]predicting train subjects:  39%|███▉      | 208/532 [07:28<09:42,  1.80s/it]predicting train subjects:  39%|███▉      | 209/532 [07:30<09:22,  1.74s/it]predicting train subjects:  39%|███▉      | 210/532 [07:31<09:06,  1.70s/it]predicting train subjects:  40%|███▉      | 211/532 [07:33<08:54,  1.66s/it]predicting train subjects:  40%|███▉      | 212/532 [07:35<08:42,  1.63s/it]predicting train subjects:  40%|████      | 213/532 [07:36<08:29,  1.60s/it]predicting train subjects:  40%|████      | 214/532 [07:38<08:17,  1.56s/it]predicting train subjects:  40%|████      | 215/532 [07:40<09:05,  1.72s/it]predicting train subjects:  41%|████      | 216/532 [07:42<09:42,  1.84s/it]predicting train subjects:  41%|████      | 217/532 [07:44<10:04,  1.92s/it]predicting train subjects:  41%|████      | 218/532 [07:46<10:22,  1.98s/it]predicting train subjects:  41%|████      | 219/532 [07:48<10:29,  2.01s/it]predicting train subjects:  41%|████▏     | 220/532 [07:50<10:48,  2.08s/it]predicting train subjects:  42%|████▏     | 221/532 [07:52<10:01,  1.93s/it]predicting train subjects:  42%|████▏     | 222/532 [07:54<09:34,  1.85s/it]predicting train subjects:  42%|████▏     | 223/532 [07:55<09:13,  1.79s/it]predicting train subjects:  42%|████▏     | 224/532 [07:57<08:59,  1.75s/it]predicting train subjects:  42%|████▏     | 225/532 [07:59<08:40,  1.69s/it]predicting train subjects:  42%|████▏     | 226/532 [08:00<08:29,  1.66s/it]predicting train subjects:  43%|████▎     | 227/532 [08:02<08:17,  1.63s/it]predicting train subjects:  43%|████▎     | 228/532 [08:03<08:02,  1.59s/it]predicting train subjects:  43%|████▎     | 229/532 [08:05<07:47,  1.54s/it]predicting train subjects:  43%|████▎     | 230/532 [08:06<07:43,  1.53s/it]predicting train subjects:  43%|████▎     | 231/532 [08:08<07:33,  1.51s/it]predicting train subjects:  44%|████▎     | 232/532 [08:09<07:29,  1.50s/it]predicting train subjects:  44%|████▍     | 233/532 [08:11<07:55,  1.59s/it]predicting train subjects:  44%|████▍     | 234/532 [08:13<08:09,  1.64s/it]predicting train subjects:  44%|████▍     | 235/532 [08:14<08:16,  1.67s/it]predicting train subjects:  44%|████▍     | 236/532 [08:16<08:13,  1.67s/it]predicting train subjects:  45%|████▍     | 237/532 [08:18<08:17,  1.69s/it]predicting train subjects:  45%|████▍     | 238/532 [08:19<08:15,  1.68s/it]predicting train subjects:  45%|████▍     | 239/532 [08:21<08:34,  1.76s/it]predicting train subjects:  45%|████▌     | 240/532 [08:23<08:43,  1.79s/it]predicting train subjects:  45%|████▌     | 241/532 [08:25<08:48,  1.81s/it]predicting train subjects:  45%|████▌     | 242/532 [08:27<08:48,  1.82s/it]predicting train subjects:  46%|████▌     | 243/532 [08:29<09:00,  1.87s/it]predicting train subjects:  46%|████▌     | 244/532 [08:31<08:57,  1.87s/it]predicting train subjects:  46%|████▌     | 245/532 [08:32<08:19,  1.74s/it]predicting train subjects:  46%|████▌     | 246/532 [08:34<07:58,  1.67s/it]predicting train subjects:  46%|████▋     | 247/532 [08:35<07:46,  1.64s/it]predicting train subjects:  47%|████▋     | 248/532 [08:37<07:36,  1.61s/it]predicting train subjects:  47%|████▋     | 249/532 [08:39<08:09,  1.73s/it]predicting train subjects:  47%|████▋     | 250/532 [08:40<07:48,  1.66s/it]predicting train subjects:  47%|████▋     | 251/532 [08:42<07:34,  1.62s/it]predicting train subjects:  47%|████▋     | 252/532 [08:43<07:26,  1.59s/it]predicting train subjects:  48%|████▊     | 253/532 [08:45<07:24,  1.59s/it]predicting train subjects:  48%|████▊     | 254/532 [08:47<07:22,  1.59s/it]predicting train subjects:  48%|████▊     | 255/532 [08:48<07:26,  1.61s/it]predicting train subjects:  48%|████▊     | 256/532 [08:50<07:19,  1.59s/it]predicting train subjects:  48%|████▊     | 257/532 [08:52<07:48,  1.71s/it]predicting train subjects:  48%|████▊     | 258/532 [08:54<08:10,  1.79s/it]predicting train subjects:  49%|████▊     | 259/532 [08:56<08:21,  1.84s/it]predicting train subjects:  49%|████▉     | 260/532 [08:58<08:38,  1.90s/it]predicting train subjects:  49%|████▉     | 261/532 [09:00<08:36,  1.91s/it]predicting train subjects:  49%|████▉     | 262/532 [09:02<08:47,  1.95s/it]predicting train subjects:  49%|████▉     | 263/532 [09:03<08:07,  1.81s/it]predicting train subjects:  50%|████▉     | 264/532 [09:05<07:35,  1.70s/it]predicting train subjects:  50%|████▉     | 265/532 [09:06<07:15,  1.63s/it]predicting train subjects:  50%|█████     | 266/532 [09:08<07:00,  1.58s/it]predicting train subjects:  50%|█████     | 267/532 [09:09<06:52,  1.56s/it]predicting train subjects:  50%|█████     | 268/532 [09:11<06:45,  1.54s/it]predicting train subjects:  51%|█████     | 269/532 [09:12<07:05,  1.62s/it]predicting train subjects:  51%|█████     | 270/532 [09:14<07:11,  1.65s/it]predicting train subjects:  51%|█████     | 271/532 [09:16<07:18,  1.68s/it]predicting train subjects:  51%|█████     | 272/532 [09:18<07:27,  1.72s/it]predicting train subjects:  51%|█████▏    | 273/532 [09:19<07:34,  1.76s/it]predicting train subjects:  52%|█████▏    | 274/532 [09:21<07:36,  1.77s/it]predicting train subjects:  52%|█████▏    | 275/532 [09:23<08:07,  1.90s/it]predicting train subjects:  52%|█████▏    | 276/532 [09:26<08:28,  1.99s/it]predicting train subjects:  52%|█████▏    | 277/532 [09:28<08:48,  2.07s/it]predicting train subjects:  52%|█████▏    | 278/532 [09:30<09:03,  2.14s/it]predicting train subjects:  52%|█████▏    | 279/532 [09:33<09:12,  2.18s/it]predicting train subjects:  53%|█████▎    | 280/532 [09:35<09:14,  2.20s/it]predicting train subjects:  53%|█████▎    | 281/532 [09:37<08:58,  2.15s/it]predicting train subjects:  53%|█████▎    | 282/532 [09:39<08:45,  2.10s/it]predicting train subjects:  53%|█████▎    | 283/532 [09:41<09:00,  2.17s/it]predicting train subjects:  53%|█████▎    | 284/532 [09:43<08:48,  2.13s/it]predicting train subjects:  54%|█████▎    | 285/532 [09:45<08:36,  2.09s/it]predicting train subjects:  54%|█████▍    | 286/532 [09:47<08:27,  2.06s/it]predicting train subjects:  54%|█████▍    | 287/532 [09:49<07:55,  1.94s/it]predicting train subjects:  54%|█████▍    | 288/532 [09:50<07:34,  1.86s/it]predicting train subjects:  54%|█████▍    | 289/532 [09:52<07:18,  1.81s/it]predicting train subjects:  55%|█████▍    | 290/532 [09:54<07:11,  1.78s/it]predicting train subjects:  55%|█████▍    | 291/532 [09:56<07:01,  1.75s/it]predicting train subjects:  55%|█████▍    | 292/532 [09:57<06:58,  1.74s/it]predicting train subjects:  55%|█████▌    | 293/532 [09:59<07:04,  1.78s/it]predicting train subjects:  55%|█████▌    | 294/532 [10:01<07:02,  1.77s/it]predicting train subjects:  55%|█████▌    | 295/532 [10:03<07:00,  1.77s/it]predicting train subjects:  56%|█████▌    | 296/532 [10:04<06:58,  1.77s/it]predicting train subjects:  56%|█████▌    | 297/532 [10:06<07:01,  1.79s/it]predicting train subjects:  56%|█████▌    | 298/532 [10:08<07:00,  1.80s/it]predicting train subjects:  56%|█████▌    | 299/532 [10:10<06:37,  1.71s/it]predicting train subjects:  56%|█████▋    | 300/532 [10:11<06:21,  1.64s/it]predicting train subjects:  57%|█████▋    | 301/532 [10:13<06:14,  1.62s/it]predicting train subjects:  57%|█████▋    | 302/532 [10:14<06:03,  1.58s/it]predicting train subjects:  57%|█████▋    | 303/532 [10:16<05:57,  1.56s/it]predicting train subjects:  57%|█████▋    | 304/532 [10:17<05:53,  1.55s/it]predicting train subjects:  57%|█████▋    | 305/532 [10:19<06:34,  1.74s/it]predicting train subjects:  58%|█████▊    | 306/532 [10:22<06:59,  1.86s/it]predicting train subjects:  58%|█████▊    | 307/532 [10:24<07:18,  1.95s/it]predicting train subjects:  58%|█████▊    | 308/532 [10:26<07:31,  2.01s/it]predicting train subjects:  58%|█████▊    | 309/532 [10:28<07:41,  2.07s/it]predicting train subjects:  58%|█████▊    | 310/532 [10:30<07:45,  2.10s/it]predicting train subjects:  58%|█████▊    | 311/532 [10:33<08:33,  2.33s/it]predicting train subjects:  59%|█████▊    | 312/532 [10:36<09:08,  2.49s/it]predicting train subjects:  59%|█████▉    | 313/532 [10:39<09:30,  2.61s/it]predicting train subjects:  59%|█████▉    | 314/532 [10:42<09:43,  2.68s/it]predicting train subjects:  59%|█████▉    | 315/532 [10:44<09:51,  2.72s/it]predicting train subjects:  59%|█████▉    | 316/532 [10:47<09:57,  2.76s/it]predicting train subjects:  60%|█████▉    | 317/532 [10:49<08:44,  2.44s/it]predicting train subjects:  60%|█████▉    | 318/532 [10:51<07:53,  2.21s/it]predicting train subjects:  60%|█████▉    | 319/532 [10:52<07:20,  2.07s/it]predicting train subjects:  60%|██████    | 320/532 [10:54<06:55,  1.96s/it]predicting train subjects:  60%|██████    | 321/532 [10:56<06:36,  1.88s/it]predicting train subjects:  61%|██████    | 322/532 [10:58<06:24,  1.83s/it]predicting train subjects:  61%|██████    | 323/532 [11:00<06:51,  1.97s/it]predicting train subjects:  61%|██████    | 324/532 [11:02<07:08,  2.06s/it]predicting train subjects:  61%|██████    | 325/532 [11:04<07:18,  2.12s/it]predicting train subjects:  61%|██████▏   | 326/532 [11:07<07:23,  2.15s/it]predicting train subjects:  61%|██████▏   | 327/532 [11:09<07:33,  2.21s/it]predicting train subjects:  62%|██████▏   | 328/532 [11:11<07:35,  2.23s/it]predicting train subjects:  62%|██████▏   | 329/532 [11:13<07:11,  2.12s/it]predicting train subjects:  62%|██████▏   | 330/532 [11:15<06:48,  2.02s/it]predicting train subjects:  62%|██████▏   | 331/532 [11:17<06:29,  1.94s/it]predicting train subjects:  62%|██████▏   | 332/532 [11:18<06:16,  1.88s/it]predicting train subjects:  63%|██████▎   | 333/532 [11:20<06:09,  1.86s/it]predicting train subjects:  63%|██████▎   | 334/532 [11:22<06:01,  1.83s/it]predicting train subjects:  63%|██████▎   | 335/532 [11:24<06:07,  1.87s/it]predicting train subjects:  63%|██████▎   | 336/532 [11:26<06:10,  1.89s/it]predicting train subjects:  63%|██████▎   | 337/532 [11:28<06:12,  1.91s/it]predicting train subjects:  64%|██████▎   | 338/532 [11:30<06:09,  1.91s/it]predicting train subjects:  64%|██████▎   | 339/532 [11:32<06:10,  1.92s/it]predicting train subjects:  64%|██████▍   | 340/532 [11:34<06:14,  1.95s/it]predicting train subjects:  64%|██████▍   | 341/532 [11:35<05:49,  1.83s/it]predicting train subjects:  64%|██████▍   | 342/532 [11:37<05:35,  1.76s/it]predicting train subjects:  64%|██████▍   | 343/532 [11:38<05:23,  1.71s/it]predicting train subjects:  65%|██████▍   | 344/532 [11:40<05:16,  1.68s/it]predicting train subjects:  65%|██████▍   | 345/532 [11:42<05:10,  1.66s/it]predicting train subjects:  65%|██████▌   | 346/532 [11:43<05:06,  1.65s/it]predicting train subjects:  65%|██████▌   | 347/532 [11:45<05:10,  1.68s/it]predicting train subjects:  65%|██████▌   | 348/532 [11:47<05:15,  1.71s/it]predicting train subjects:  66%|██████▌   | 349/532 [11:49<05:20,  1.75s/it]predicting train subjects:  66%|██████▌   | 350/532 [11:50<05:23,  1.78s/it]predicting train subjects:  66%|██████▌   | 351/532 [11:52<05:23,  1.79s/it]predicting train subjects:  66%|██████▌   | 352/532 [11:54<05:21,  1.79s/it]predicting train subjects:  66%|██████▋   | 353/532 [11:56<05:16,  1.77s/it]predicting train subjects:  67%|██████▋   | 354/532 [11:58<05:14,  1.77s/it]predicting train subjects:  67%|██████▋   | 355/532 [11:59<05:09,  1.75s/it]predicting train subjects:  67%|██████▋   | 356/532 [12:01<05:13,  1.78s/it]predicting train subjects:  67%|██████▋   | 357/532 [12:03<05:12,  1.78s/it]predicting train subjects:  67%|██████▋   | 358/532 [12:05<05:11,  1.79s/it]predicting train subjects:  67%|██████▋   | 359/532 [12:06<04:57,  1.72s/it]predicting train subjects:  68%|██████▊   | 360/532 [12:08<04:43,  1.65s/it]predicting train subjects:  68%|██████▊   | 361/532 [12:09<04:33,  1.60s/it]predicting train subjects:  68%|██████▊   | 362/532 [12:11<04:24,  1.56s/it]predicting train subjects:  68%|██████▊   | 363/532 [12:12<04:21,  1.55s/it]predicting train subjects:  68%|██████▊   | 364/532 [12:14<04:22,  1.57s/it]predicting train subjects:  69%|██████▊   | 365/532 [12:15<04:22,  1.57s/it]predicting train subjects:  69%|██████▉   | 366/532 [12:17<04:23,  1.59s/it]predicting train subjects:  69%|██████▉   | 367/532 [12:19<04:26,  1.61s/it]predicting train subjects:  69%|██████▉   | 368/532 [12:20<04:24,  1.61s/it]predicting train subjects:  69%|██████▉   | 369/532 [12:22<04:23,  1.62s/it]predicting train subjects:  70%|██████▉   | 370/532 [12:24<04:21,  1.61s/it]predicting train subjects:  70%|██████▉   | 371/532 [12:26<04:49,  1.80s/it]predicting train subjects:  70%|██████▉   | 372/532 [12:28<05:08,  1.93s/it]predicting train subjects:  70%|███████   | 373/532 [12:30<05:16,  1.99s/it]predicting train subjects:  70%|███████   | 374/532 [12:32<05:21,  2.03s/it]predicting train subjects:  70%|███████   | 375/532 [12:34<05:20,  2.04s/it]predicting train subjects:  71%|███████   | 376/532 [12:37<05:27,  2.10s/it]predicting train subjects:  71%|███████   | 377/532 [12:38<05:10,  2.00s/it]predicting train subjects:  71%|███████   | 378/532 [12:40<04:59,  1.95s/it]predicting train subjects:  71%|███████   | 379/532 [12:42<04:52,  1.91s/it]predicting train subjects:  71%|███████▏  | 380/532 [12:44<04:45,  1.88s/it]predicting train subjects:  72%|███████▏  | 381/532 [12:46<04:36,  1.83s/it]predicting train subjects:  72%|███████▏  | 382/532 [12:47<04:31,  1.81s/it]predicting train subjects:  72%|███████▏  | 383/532 [12:49<04:30,  1.81s/it]predicting train subjects:  72%|███████▏  | 384/532 [12:51<04:31,  1.84s/it]predicting train subjects:  72%|███████▏  | 385/532 [12:53<04:28,  1.83s/it]predicting train subjects:  73%|███████▎  | 386/532 [12:55<04:25,  1.82s/it]predicting train subjects:  73%|███████▎  | 387/532 [12:56<04:25,  1.83s/it]predicting train subjects:  73%|███████▎  | 388/532 [12:58<04:26,  1.85s/it]predicting train subjects:  73%|███████▎  | 389/532 [13:00<04:27,  1.87s/it]predicting train subjects:  73%|███████▎  | 390/532 [13:02<04:26,  1.88s/it]predicting train subjects:  73%|███████▎  | 391/532 [13:04<04:24,  1.88s/it]predicting train subjects:  74%|███████▎  | 392/532 [13:06<04:26,  1.90s/it]predicting train subjects:  74%|███████▍  | 393/532 [13:08<04:25,  1.91s/it]predicting train subjects:  74%|███████▍  | 394/532 [13:10<04:23,  1.91s/it]predicting train subjects:  74%|███████▍  | 395/532 [13:12<04:25,  1.93s/it]predicting train subjects:  74%|███████▍  | 396/532 [13:14<04:23,  1.94s/it]predicting train subjects:  75%|███████▍  | 397/532 [13:16<04:26,  1.97s/it]predicting train subjects:  75%|███████▍  | 398/532 [13:18<04:27,  1.99s/it]predicting train subjects:  75%|███████▌  | 399/532 [13:20<04:20,  1.96s/it]predicting train subjects:  75%|███████▌  | 400/532 [13:22<04:19,  1.97s/it]predicting train subjects:  75%|███████▌  | 401/532 [13:24<04:21,  1.99s/it]predicting train subjects:  76%|███████▌  | 402/532 [13:26<04:20,  2.00s/it]predicting train subjects:  76%|███████▌  | 403/532 [13:28<04:22,  2.03s/it]predicting train subjects:  76%|███████▌  | 404/532 [13:30<04:25,  2.07s/it]predicting train subjects:  76%|███████▌  | 405/532 [13:32<04:19,  2.04s/it]predicting train subjects:  76%|███████▋  | 406/532 [13:34<04:13,  2.01s/it]predicting train subjects:  77%|███████▋  | 407/532 [13:36<04:01,  1.93s/it]predicting train subjects:  77%|███████▋  | 408/532 [13:38<03:56,  1.91s/it]predicting train subjects:  77%|███████▋  | 409/532 [13:39<03:51,  1.88s/it]predicting train subjects:  77%|███████▋  | 410/532 [13:41<03:49,  1.88s/it]predicting train subjects:  77%|███████▋  | 411/532 [13:43<03:42,  1.84s/it]predicting train subjects:  77%|███████▋  | 412/532 [13:45<03:36,  1.81s/it]predicting train subjects:  78%|███████▊  | 413/532 [13:46<03:30,  1.77s/it]predicting train subjects:  78%|███████▊  | 414/532 [13:48<03:23,  1.73s/it]predicting train subjects:  78%|███████▊  | 415/532 [13:50<03:21,  1.72s/it]predicting train subjects:  78%|███████▊  | 416/532 [13:52<03:20,  1.73s/it]predicting train subjects:  78%|███████▊  | 417/532 [13:53<03:16,  1.71s/it]predicting train subjects:  79%|███████▊  | 418/532 [13:55<03:16,  1.72s/it]predicting train subjects:  79%|███████▉  | 419/532 [13:57<03:22,  1.79s/it]predicting train subjects:  79%|███████▉  | 420/532 [13:59<03:23,  1.82s/it]predicting train subjects:  79%|███████▉  | 421/532 [14:01<03:25,  1.85s/it]predicting train subjects:  79%|███████▉  | 422/532 [14:03<03:26,  1.88s/it]predicting train subjects:  80%|███████▉  | 423/532 [14:05<03:24,  1.88s/it]predicting train subjects:  80%|███████▉  | 424/532 [14:06<03:22,  1.87s/it]predicting train subjects:  80%|███████▉  | 425/532 [14:08<03:22,  1.89s/it]predicting train subjects:  80%|████████  | 426/532 [14:10<03:21,  1.90s/it]predicting train subjects:  80%|████████  | 427/532 [14:12<03:22,  1.93s/it]predicting train subjects:  80%|████████  | 428/532 [14:14<03:21,  1.94s/it]predicting train subjects:  81%|████████  | 429/532 [14:16<03:19,  1.94s/it]predicting train subjects:  81%|████████  | 430/532 [14:18<03:17,  1.94s/it]predicting train subjects:  81%|████████  | 431/532 [14:20<03:21,  2.00s/it]predicting train subjects:  81%|████████  | 432/532 [14:22<03:21,  2.02s/it]predicting train subjects:  81%|████████▏ | 433/532 [14:24<03:22,  2.04s/it]predicting train subjects:  82%|████████▏ | 434/532 [14:27<03:24,  2.09s/it]predicting train subjects:  82%|████████▏ | 435/532 [14:29<03:24,  2.11s/it]predicting train subjects:  82%|████████▏ | 436/532 [14:31<03:23,  2.12s/it]predicting train subjects:  82%|████████▏ | 437/532 [14:33<03:08,  1.98s/it]predicting train subjects:  82%|████████▏ | 438/532 [14:34<02:56,  1.88s/it]predicting train subjects:  83%|████████▎ | 439/532 [14:36<02:48,  1.81s/it]predicting train subjects:  83%|████████▎ | 440/532 [14:37<02:41,  1.75s/it]predicting train subjects:  83%|████████▎ | 441/532 [14:39<02:36,  1.72s/it]predicting train subjects:  83%|████████▎ | 442/532 [14:41<02:32,  1.69s/it]predicting train subjects:  83%|████████▎ | 443/532 [14:42<02:30,  1.70s/it]predicting train subjects:  83%|████████▎ | 444/532 [14:44<02:28,  1.69s/it]predicting train subjects:  84%|████████▎ | 445/532 [14:46<02:25,  1.67s/it]predicting train subjects:  84%|████████▍ | 446/532 [14:47<02:22,  1.66s/it]predicting train subjects:  84%|████████▍ | 447/532 [14:49<02:19,  1.64s/it]predicting train subjects:  84%|████████▍ | 448/532 [14:51<02:16,  1.62s/it]predicting train subjects:  84%|████████▍ | 449/532 [14:52<02:18,  1.67s/it]predicting train subjects:  85%|████████▍ | 450/532 [14:54<02:18,  1.68s/it]predicting train subjects:  85%|████████▍ | 451/532 [14:56<02:17,  1.70s/it]predicting train subjects:  85%|████████▍ | 452/532 [14:57<02:16,  1.70s/it]predicting train subjects:  85%|████████▌ | 453/532 [14:59<02:16,  1.73s/it]predicting train subjects:  85%|████████▌ | 454/532 [15:01<02:14,  1.72s/it]predicting train subjects:  86%|████████▌ | 455/532 [15:03<02:17,  1.78s/it]predicting train subjects:  86%|████████▌ | 456/532 [15:05<02:17,  1.81s/it]predicting train subjects:  86%|████████▌ | 457/532 [15:07<02:18,  1.85s/it]predicting train subjects:  86%|████████▌ | 458/532 [15:09<02:18,  1.87s/it]predicting train subjects:  86%|████████▋ | 459/532 [15:11<02:19,  1.91s/it]predicting train subjects:  86%|████████▋ | 460/532 [15:13<02:18,  1.93s/it]predicting train subjects:  87%|████████▋ | 461/532 [15:15<02:25,  2.04s/it]predicting train subjects:  87%|████████▋ | 462/532 [15:18<02:34,  2.20s/it]predicting train subjects:  87%|████████▋ | 463/532 [15:20<02:33,  2.23s/it]predicting train subjects:  87%|████████▋ | 464/532 [15:22<02:31,  2.22s/it]predicting train subjects:  87%|████████▋ | 465/532 [15:24<02:29,  2.23s/it]predicting train subjects:  88%|████████▊ | 466/532 [15:26<02:27,  2.23s/it]predicting train subjects:  88%|████████▊ | 467/532 [15:28<02:17,  2.12s/it]predicting train subjects:  88%|████████▊ | 468/532 [15:30<02:07,  1.99s/it]predicting train subjects:  88%|████████▊ | 469/532 [15:32<02:01,  1.93s/it]predicting train subjects:  88%|████████▊ | 470/532 [15:34<01:55,  1.86s/it]predicting train subjects:  89%|████████▊ | 471/532 [15:35<01:51,  1.83s/it]predicting train subjects:  89%|████████▊ | 472/532 [15:37<01:47,  1.80s/it]predicting train subjects:  89%|████████▉ | 473/532 [15:39<01:48,  1.84s/it]predicting train subjects:  89%|████████▉ | 474/532 [15:41<01:49,  1.89s/it]predicting train subjects:  89%|████████▉ | 475/532 [15:43<01:50,  1.95s/it]predicting train subjects:  89%|████████▉ | 476/532 [15:45<01:49,  1.96s/it]predicting train subjects:  90%|████████▉ | 477/532 [15:47<01:50,  2.01s/it]predicting train subjects:  90%|████████▉ | 478/532 [15:49<01:48,  2.01s/it]predicting train subjects:  90%|█████████ | 479/532 [15:51<01:41,  1.92s/it]predicting train subjects:  90%|█████████ | 480/532 [15:53<01:36,  1.85s/it]predicting train subjects:  90%|█████████ | 481/532 [15:54<01:32,  1.81s/it]predicting train subjects:  91%|█████████ | 482/532 [15:56<01:29,  1.79s/it]predicting train subjects:  91%|█████████ | 483/532 [15:58<01:26,  1.77s/it]predicting train subjects:  91%|█████████ | 484/532 [15:59<01:24,  1.76s/it]predicting train subjects:  91%|█████████ | 485/532 [16:02<01:30,  1.92s/it]predicting train subjects:  91%|█████████▏| 486/532 [16:04<01:31,  2.00s/it]predicting train subjects:  92%|█████████▏| 487/532 [16:06<01:32,  2.05s/it]predicting train subjects:  92%|█████████▏| 488/532 [16:08<01:31,  2.09s/it]predicting train subjects:  92%|█████████▏| 489/532 [16:10<01:31,  2.13s/it]predicting train subjects:  92%|█████████▏| 490/532 [16:13<01:30,  2.15s/it]predicting train subjects:  92%|█████████▏| 491/532 [16:15<01:24,  2.06s/it]predicting train subjects:  92%|█████████▏| 492/532 [16:16<01:19,  1.99s/it]predicting train subjects:  93%|█████████▎| 493/532 [16:18<01:15,  1.92s/it]predicting train subjects:  93%|█████████▎| 494/532 [16:20<01:11,  1.87s/it]predicting train subjects:  93%|█████████▎| 495/532 [16:22<01:08,  1.86s/it]predicting train subjects:  93%|█████████▎| 496/532 [16:24<01:06,  1.85s/it]predicting train subjects:  93%|█████████▎| 497/532 [16:25<01:05,  1.86s/it]predicting train subjects:  94%|█████████▎| 498/532 [16:27<01:03,  1.87s/it]predicting train subjects:  94%|█████████▍| 499/532 [16:29<01:01,  1.87s/it]predicting train subjects:  94%|█████████▍| 500/532 [16:31<00:59,  1.87s/it]predicting train subjects:  94%|█████████▍| 501/532 [16:33<00:57,  1.86s/it]predicting train subjects:  94%|█████████▍| 502/532 [16:35<00:55,  1.85s/it]predicting train subjects:  95%|█████████▍| 503/532 [16:36<00:52,  1.83s/it]predicting train subjects:  95%|█████████▍| 504/532 [16:38<00:50,  1.81s/it]predicting train subjects:  95%|█████████▍| 505/532 [16:40<00:48,  1.80s/it]predicting train subjects:  95%|█████████▌| 506/532 [16:42<00:46,  1.79s/it]predicting train subjects:  95%|█████████▌| 507/532 [16:43<00:43,  1.76s/it]predicting train subjects:  95%|█████████▌| 508/532 [16:45<00:41,  1.74s/it]predicting train subjects:  96%|█████████▌| 509/532 [16:47<00:42,  1.86s/it]predicting train subjects:  96%|█████████▌| 510/532 [16:49<00:42,  1.94s/it]predicting train subjects:  96%|█████████▌| 511/532 [16:52<00:41,  1.98s/it]predicting train subjects:  96%|█████████▌| 512/532 [16:54<00:41,  2.05s/it]predicting train subjects:  96%|█████████▋| 513/532 [16:56<00:39,  2.08s/it]predicting train subjects:  97%|█████████▋| 514/532 [16:58<00:37,  2.10s/it]predicting train subjects:  97%|█████████▋| 515/532 [17:00<00:34,  2.04s/it]predicting train subjects:  97%|█████████▋| 516/532 [17:02<00:31,  1.96s/it]predicting train subjects:  97%|█████████▋| 517/532 [17:04<00:28,  1.93s/it]predicting train subjects:  97%|█████████▋| 518/532 [17:05<00:26,  1.92s/it]predicting train subjects:  98%|█████████▊| 519/532 [17:07<00:24,  1.88s/it]predicting train subjects:  98%|█████████▊| 520/532 [17:09<00:22,  1.88s/it]predicting train subjects:  98%|█████████▊| 521/532 [17:11<00:20,  1.90s/it]predicting train subjects:  98%|█████████▊| 522/532 [17:13<00:19,  1.94s/it]predicting train subjects:  98%|█████████▊| 523/532 [17:15<00:17,  1.94s/it]predicting train subjects:  98%|█████████▊| 524/532 [17:17<00:15,  1.95s/it]predicting train subjects:  99%|█████████▊| 525/532 [17:19<00:13,  2.00s/it]predicting train subjects:  99%|█████████▉| 526/532 [17:21<00:11,  2.00s/it]predicting train subjects:  99%|█████████▉| 527/532 [17:23<00:09,  1.95s/it]predicting train subjects:  99%|█████████▉| 528/532 [17:25<00:07,  1.92s/it]predicting train subjects:  99%|█████████▉| 529/532 [17:27<00:05,  1.87s/it]predicting train subjects: 100%|█████████▉| 530/532 [17:28<00:03,  1.86s/it]predicting train subjects: 100%|█████████▉| 531/532 [17:30<00:01,  1.84s/it]predicting train subjects: 100%|██████████| 532/532 [17:32<00:00,  1.84s/it]
Loading train:   0%|          | 0/532 [00:00<?, ?it/s]Loading train:   0%|          | 1/532 [00:01<12:13,  1.38s/it]Loading train:   0%|          | 2/532 [00:02<10:47,  1.22s/it]Loading train:   1%|          | 3/532 [00:03<09:59,  1.13s/it]Loading train:   1%|          | 4/532 [00:04<09:29,  1.08s/it]Loading train:   1%|          | 5/532 [00:05<09:29,  1.08s/it]Loading train:   1%|          | 6/532 [00:06<09:09,  1.04s/it]Loading train:   1%|▏         | 7/532 [00:07<09:34,  1.09s/it]Loading train:   2%|▏         | 8/532 [00:08<08:53,  1.02s/it]Loading train:   2%|▏         | 9/532 [00:09<09:14,  1.06s/it]Loading train:   2%|▏         | 10/532 [00:10<09:13,  1.06s/it]Loading train:   2%|▏         | 11/532 [00:11<08:33,  1.01it/s]Loading train:   2%|▏         | 12/532 [00:12<09:03,  1.04s/it]Loading train:   2%|▏         | 13/532 [00:13<08:34,  1.01it/s]Loading train:   3%|▎         | 14/532 [00:14<08:00,  1.08it/s]Loading train:   3%|▎         | 15/532 [00:14<07:58,  1.08it/s]Loading train:   3%|▎         | 16/532 [00:16<08:27,  1.02it/s]Loading train:   3%|▎         | 17/532 [00:17<08:16,  1.04it/s]Loading train:   3%|▎         | 18/532 [00:18<08:24,  1.02it/s]Loading train:   4%|▎         | 19/532 [00:18<08:03,  1.06it/s]Loading train:   4%|▍         | 20/532 [00:19<08:12,  1.04it/s]Loading train:   4%|▍         | 21/532 [00:20<08:30,  1.00it/s]Loading train:   4%|▍         | 22/532 [00:21<08:12,  1.04it/s]Loading train:   4%|▍         | 23/532 [00:22<07:59,  1.06it/s]Loading train:   5%|▍         | 24/532 [00:23<07:44,  1.09it/s]Loading train:   5%|▍         | 25/532 [00:24<08:21,  1.01it/s]Loading train:   5%|▍         | 26/532 [00:25<07:55,  1.06it/s]Loading train:   5%|▌         | 27/532 [00:26<08:51,  1.05s/it]Loading train:   5%|▌         | 28/532 [00:27<08:26,  1.01s/it]Loading train:   5%|▌         | 29/532 [00:28<08:36,  1.03s/it]Loading train:   6%|▌         | 30/532 [00:29<07:50,  1.07it/s]Loading train:   6%|▌         | 31/532 [00:30<07:46,  1.07it/s]Loading train:   6%|▌         | 32/532 [00:31<07:50,  1.06it/s]Loading train:   6%|▌         | 33/532 [00:32<07:35,  1.10it/s]Loading train:   6%|▋         | 34/532 [00:33<07:54,  1.05it/s]Loading train:   7%|▋         | 35/532 [00:34<07:25,  1.12it/s]Loading train:   7%|▋         | 36/532 [00:35<07:32,  1.10it/s]Loading train:   7%|▋         | 37/532 [00:36<07:44,  1.07it/s]Loading train:   7%|▋         | 38/532 [00:37<08:09,  1.01it/s]Loading train:   7%|▋         | 39/532 [00:38<07:58,  1.03it/s]Loading train:   8%|▊         | 40/532 [00:39<07:47,  1.05it/s]Loading train:   8%|▊         | 41/532 [00:40<07:57,  1.03it/s]Loading train:   8%|▊         | 42/532 [00:40<07:49,  1.04it/s]Loading train:   8%|▊         | 43/532 [00:41<07:34,  1.08it/s]Loading train:   8%|▊         | 44/532 [00:42<07:02,  1.15it/s]Loading train:   8%|▊         | 45/532 [00:43<07:13,  1.12it/s]Loading train:   9%|▊         | 46/532 [00:44<07:31,  1.08it/s]Loading train:   9%|▉         | 47/532 [00:45<07:54,  1.02it/s]Loading train:   9%|▉         | 48/532 [00:46<07:51,  1.03it/s]Loading train:   9%|▉         | 49/532 [00:47<07:28,  1.08it/s]Loading train:   9%|▉         | 50/532 [00:48<07:43,  1.04it/s]Loading train:  10%|▉         | 51/532 [00:49<07:35,  1.06it/s]Loading train:  10%|▉         | 52/532 [00:50<07:17,  1.10it/s]Loading train:  10%|▉         | 53/532 [00:51<07:10,  1.11it/s]Loading train:  10%|█         | 54/532 [00:52<07:42,  1.03it/s]Loading train:  10%|█         | 55/532 [00:53<07:43,  1.03it/s]Loading train:  11%|█         | 56/532 [00:54<07:32,  1.05it/s]Loading train:  11%|█         | 57/532 [00:55<07:31,  1.05it/s]Loading train:  11%|█         | 58/532 [00:56<07:36,  1.04it/s]Loading train:  11%|█         | 59/532 [00:57<08:07,  1.03s/it]Loading train:  11%|█▏        | 60/532 [00:58<07:32,  1.04it/s]Loading train:  11%|█▏        | 61/532 [00:58<06:58,  1.13it/s]Loading train:  12%|█▏        | 62/532 [00:59<07:45,  1.01it/s]Loading train:  12%|█▏        | 63/532 [01:01<08:01,  1.03s/it]Loading train:  12%|█▏        | 64/532 [01:01<07:30,  1.04it/s]Loading train:  12%|█▏        | 65/532 [01:02<07:24,  1.05it/s]Loading train:  12%|█▏        | 66/532 [01:04<08:18,  1.07s/it]Loading train:  13%|█▎        | 67/532 [01:05<08:22,  1.08s/it]Loading train:  13%|█▎        | 68/532 [01:06<08:14,  1.07s/it]Loading train:  13%|█▎        | 69/532 [01:07<07:48,  1.01s/it]Loading train:  13%|█▎        | 70/532 [01:08<07:40,  1.00it/s]Loading train:  13%|█▎        | 71/532 [01:08<07:17,  1.05it/s]Loading train:  14%|█▎        | 72/532 [01:09<06:57,  1.10it/s]Loading train:  14%|█▎        | 73/532 [01:10<07:11,  1.06it/s]Loading train:  14%|█▍        | 74/532 [01:12<07:56,  1.04s/it]Loading train:  14%|█▍        | 75/532 [01:13<09:00,  1.18s/it]Loading train:  14%|█▍        | 76/532 [01:14<08:14,  1.09s/it]Loading train:  14%|█▍        | 77/532 [01:15<08:01,  1.06s/it]Loading train:  15%|█▍        | 78/532 [01:16<07:43,  1.02s/it]Loading train:  15%|█▍        | 79/532 [01:17<07:25,  1.02it/s]Loading train:  15%|█▌        | 80/532 [01:18<07:26,  1.01it/s]Loading train:  15%|█▌        | 81/532 [01:19<07:15,  1.04it/s]Loading train:  15%|█▌        | 82/532 [01:20<07:17,  1.03it/s]Loading train:  16%|█▌        | 83/532 [01:21<07:00,  1.07it/s]Loading train:  16%|█▌        | 84/532 [01:21<06:56,  1.07it/s]Loading train:  16%|█▌        | 85/532 [01:22<06:32,  1.14it/s]Loading train:  16%|█▌        | 86/532 [01:23<06:07,  1.21it/s]Loading train:  16%|█▋        | 87/532 [01:24<05:55,  1.25it/s]Loading train:  17%|█▋        | 88/532 [01:24<05:49,  1.27it/s]Loading train:  17%|█▋        | 89/532 [01:25<06:02,  1.22it/s]Loading train:  17%|█▋        | 90/532 [01:26<06:06,  1.21it/s]Loading train:  17%|█▋        | 91/532 [01:27<06:14,  1.18it/s]Loading train:  17%|█▋        | 92/532 [01:28<06:17,  1.16it/s]Loading train:  17%|█▋        | 93/532 [01:29<06:06,  1.20it/s]Loading train:  18%|█▊        | 94/532 [01:29<06:01,  1.21it/s]Loading train:  18%|█▊        | 95/532 [01:31<06:41,  1.09it/s]Loading train:  18%|█▊        | 96/532 [01:32<07:02,  1.03it/s]Loading train:  18%|█▊        | 97/532 [01:33<07:27,  1.03s/it]Loading train:  18%|█▊        | 98/532 [01:34<07:33,  1.04s/it]Loading train:  19%|█▊        | 99/532 [01:35<07:53,  1.09s/it]Loading train:  19%|█▉        | 100/532 [01:36<07:48,  1.08s/it]Loading train:  19%|█▉        | 101/532 [01:37<07:17,  1.02s/it]Loading train:  19%|█▉        | 102/532 [01:38<06:55,  1.03it/s]Loading train:  19%|█▉        | 103/532 [01:39<06:29,  1.10it/s]Loading train:  20%|█▉        | 104/532 [01:40<06:19,  1.13it/s]Loading train:  20%|█▉        | 105/532 [01:40<05:58,  1.19it/s]Loading train:  20%|█▉        | 106/532 [01:41<05:43,  1.24it/s]Loading train:  20%|██        | 107/532 [01:42<05:48,  1.22it/s]Loading train:  20%|██        | 108/532 [01:43<05:49,  1.21it/s]Loading train:  20%|██        | 109/532 [01:44<05:47,  1.22it/s]Loading train:  21%|██        | 110/532 [01:44<05:31,  1.27it/s]Loading train:  21%|██        | 111/532 [01:45<05:35,  1.25it/s]Loading train:  21%|██        | 112/532 [01:46<05:35,  1.25it/s]Loading train:  21%|██        | 113/532 [01:47<06:05,  1.15it/s]Loading train:  21%|██▏       | 114/532 [01:48<06:05,  1.14it/s]Loading train:  22%|██▏       | 115/532 [01:49<06:05,  1.14it/s]Loading train:  22%|██▏       | 116/532 [01:49<05:55,  1.17it/s]Loading train:  22%|██▏       | 117/532 [01:50<06:11,  1.12it/s]Loading train:  22%|██▏       | 118/532 [01:51<06:17,  1.10it/s]Loading train:  22%|██▏       | 119/532 [01:52<06:16,  1.10it/s]Loading train:  23%|██▎       | 120/532 [01:53<06:09,  1.11it/s]Loading train:  23%|██▎       | 121/532 [01:54<06:07,  1.12it/s]Loading train:  23%|██▎       | 122/532 [01:55<06:02,  1.13it/s]Loading train:  23%|██▎       | 123/532 [01:56<06:05,  1.12it/s]Loading train:  23%|██▎       | 124/532 [01:57<06:03,  1.12it/s]Loading train:  23%|██▎       | 125/532 [01:58<06:19,  1.07it/s]Loading train:  24%|██▎       | 126/532 [01:59<06:21,  1.06it/s]Loading train:  24%|██▍       | 127/532 [02:00<06:14,  1.08it/s]Loading train:  24%|██▍       | 128/532 [02:01<06:13,  1.08it/s]Loading train:  24%|██▍       | 129/532 [02:01<06:14,  1.08it/s]Loading train:  24%|██▍       | 130/532 [02:02<06:26,  1.04it/s]Loading train:  25%|██▍       | 131/532 [02:04<06:52,  1.03s/it]Loading train:  25%|██▍       | 132/532 [02:05<07:09,  1.07s/it]Loading train:  25%|██▌       | 133/532 [02:06<07:14,  1.09s/it]Loading train:  25%|██▌       | 134/532 [02:07<07:20,  1.11s/it]Loading train:  25%|██▌       | 135/532 [02:08<07:31,  1.14s/it]Loading train:  26%|██▌       | 136/532 [02:09<07:29,  1.14s/it]Loading train:  26%|██▌       | 137/532 [02:11<07:38,  1.16s/it]Loading train:  26%|██▌       | 138/532 [02:12<07:29,  1.14s/it]Loading train:  26%|██▌       | 139/532 [02:13<07:38,  1.17s/it]Loading train:  26%|██▋       | 140/532 [02:14<07:35,  1.16s/it]Loading train:  27%|██▋       | 141/532 [02:15<07:31,  1.15s/it]Loading train:  27%|██▋       | 142/532 [02:17<07:49,  1.20s/it]Loading train:  27%|██▋       | 143/532 [02:17<07:10,  1.11s/it]Loading train:  27%|██▋       | 144/532 [02:18<06:35,  1.02s/it]Loading train:  27%|██▋       | 145/532 [02:19<06:12,  1.04it/s]Loading train:  27%|██▋       | 146/532 [02:20<05:50,  1.10it/s]Loading train:  28%|██▊       | 147/532 [02:21<05:39,  1.14it/s]Loading train:  28%|██▊       | 148/532 [02:22<05:31,  1.16it/s]Loading train:  28%|██▊       | 149/532 [02:22<05:35,  1.14it/s]Loading train:  28%|██▊       | 150/532 [02:23<05:35,  1.14it/s]Loading train:  28%|██▊       | 151/532 [02:24<05:29,  1.16it/s]Loading train:  29%|██▊       | 152/532 [02:25<05:31,  1.15it/s]Loading train:  29%|██▉       | 153/532 [02:26<05:36,  1.12it/s]Loading train:  29%|██▉       | 154/532 [02:27<05:43,  1.10it/s]Loading train:  29%|██▉       | 155/532 [02:28<06:20,  1.01s/it]Loading train:  29%|██▉       | 156/532 [02:29<06:50,  1.09s/it]Loading train:  30%|██▉       | 157/532 [02:31<07:03,  1.13s/it]Loading train:  30%|██▉       | 158/532 [02:32<06:58,  1.12s/it]Loading train:  30%|██▉       | 159/532 [02:33<07:11,  1.16s/it]Loading train:  30%|███       | 160/532 [02:34<07:25,  1.20s/it]Loading train:  30%|███       | 161/532 [02:35<06:45,  1.09s/it]Loading train:  30%|███       | 162/532 [02:36<06:14,  1.01s/it]Loading train:  31%|███       | 163/532 [02:37<05:55,  1.04it/s]Loading train:  31%|███       | 164/532 [02:38<05:36,  1.09it/s]Loading train:  31%|███       | 165/532 [02:38<05:20,  1.14it/s]Loading train:  31%|███       | 166/532 [02:39<05:11,  1.18it/s]Loading train:  31%|███▏      | 167/532 [02:40<05:20,  1.14it/s]Loading train:  32%|███▏      | 168/532 [02:41<05:22,  1.13it/s]Loading train:  32%|███▏      | 169/532 [02:42<05:23,  1.12it/s]Loading train:  32%|███▏      | 170/532 [02:43<05:22,  1.12it/s]Loading train:  32%|███▏      | 171/532 [02:44<05:24,  1.11it/s]Loading train:  32%|███▏      | 172/532 [02:45<05:13,  1.15it/s]Loading train:  33%|███▎      | 173/532 [02:45<05:02,  1.19it/s]Loading train:  33%|███▎      | 174/532 [02:46<05:02,  1.18it/s]Loading train:  33%|███▎      | 175/532 [02:47<04:50,  1.23it/s]Loading train:  33%|███▎      | 176/532 [02:48<04:51,  1.22it/s]Loading train:  33%|███▎      | 177/532 [02:49<04:48,  1.23it/s]Loading train:  33%|███▎      | 178/532 [02:50<05:00,  1.18it/s]Loading train:  34%|███▎      | 179/532 [02:50<05:02,  1.17it/s]Loading train:  34%|███▍      | 180/532 [02:51<05:11,  1.13it/s]Loading train:  34%|███▍      | 181/532 [02:52<05:07,  1.14it/s]Loading train:  34%|███▍      | 182/532 [02:53<05:06,  1.14it/s]Loading train:  34%|███▍      | 183/532 [02:54<05:03,  1.15it/s]Loading train:  35%|███▍      | 184/532 [02:55<05:09,  1.12it/s]Loading train:  35%|███▍      | 185/532 [02:56<05:05,  1.14it/s]Loading train:  35%|███▍      | 186/532 [02:57<05:04,  1.14it/s]Loading train:  35%|███▌      | 187/532 [02:57<04:56,  1.16it/s]Loading train:  35%|███▌      | 188/532 [02:58<04:44,  1.21it/s]Loading train:  36%|███▌      | 189/532 [02:59<04:38,  1.23it/s]Loading train:  36%|███▌      | 190/532 [03:00<04:25,  1.29it/s]Loading train:  36%|███▌      | 191/532 [03:01<05:07,  1.11it/s]Loading train:  36%|███▌      | 192/532 [03:02<05:40,  1.00s/it]Loading train:  36%|███▋      | 193/532 [03:03<05:51,  1.04s/it]Loading train:  36%|███▋      | 194/532 [03:04<06:09,  1.09s/it]Loading train:  37%|███▋      | 195/532 [03:06<06:22,  1.14s/it]Loading train:  37%|███▋      | 196/532 [03:07<06:32,  1.17s/it]Loading train:  37%|███▋      | 197/532 [03:08<06:25,  1.15s/it]Loading train:  37%|███▋      | 198/532 [03:09<06:09,  1.11s/it]Loading train:  37%|███▋      | 199/532 [03:10<06:00,  1.08s/it]Loading train:  38%|███▊      | 200/532 [03:11<05:54,  1.07s/it]Loading train:  38%|███▊      | 201/532 [03:12<05:53,  1.07s/it]Loading train:  38%|███▊      | 202/532 [03:13<05:46,  1.05s/it]Loading train:  38%|███▊      | 203/532 [03:14<05:32,  1.01s/it]Loading train:  38%|███▊      | 204/532 [03:15<05:09,  1.06it/s]Loading train:  39%|███▊      | 205/532 [03:16<04:57,  1.10it/s]Loading train:  39%|███▊      | 206/532 [03:17<04:46,  1.14it/s]Loading train:  39%|███▉      | 207/532 [03:17<04:39,  1.16it/s]Loading train:  39%|███▉      | 208/532 [03:18<04:32,  1.19it/s]Loading train:  39%|███▉      | 209/532 [03:19<04:19,  1.25it/s]Loading train:  39%|███▉      | 210/532 [03:20<04:12,  1.27it/s]Loading train:  40%|███▉      | 211/532 [03:20<04:03,  1.32it/s]Loading train:  40%|███▉      | 212/532 [03:21<04:08,  1.29it/s]Loading train:  40%|████      | 213/532 [03:22<04:05,  1.30it/s]Loading train:  40%|████      | 214/532 [03:23<04:18,  1.23it/s]Loading train:  40%|████      | 215/532 [03:24<04:55,  1.07it/s]Loading train:  41%|████      | 216/532 [03:25<05:19,  1.01s/it]Loading train:  41%|████      | 217/532 [03:26<05:27,  1.04s/it]Loading train:  41%|████      | 218/532 [03:28<05:51,  1.12s/it]Loading train:  41%|████      | 219/532 [03:29<06:05,  1.17s/it]Loading train:  41%|████▏     | 220/532 [03:30<05:59,  1.15s/it]Loading train:  42%|████▏     | 221/532 [03:31<05:33,  1.07s/it]Loading train:  42%|████▏     | 222/532 [03:32<05:00,  1.03it/s]Loading train:  42%|████▏     | 223/532 [03:33<04:55,  1.05it/s]Loading train:  42%|████▏     | 224/532 [03:33<04:31,  1.13it/s]Loading train:  42%|████▏     | 225/532 [03:34<04:26,  1.15it/s]Loading train:  42%|████▏     | 226/532 [03:35<04:10,  1.22it/s]Loading train:  43%|████▎     | 227/532 [03:36<04:16,  1.19it/s]Loading train:  43%|████▎     | 228/532 [03:36<04:13,  1.20it/s]Loading train:  43%|████▎     | 229/532 [03:37<03:59,  1.26it/s]Loading train:  43%|████▎     | 230/532 [03:38<03:47,  1.33it/s]Loading train:  43%|████▎     | 231/532 [03:38<03:39,  1.37it/s]Loading train:  44%|████▎     | 232/532 [03:39<03:34,  1.40it/s]Loading train:  44%|████▍     | 233/532 [03:40<03:55,  1.27it/s]Loading train:  44%|████▍     | 234/532 [03:41<04:05,  1.22it/s]Loading train:  44%|████▍     | 235/532 [03:42<04:23,  1.13it/s]Loading train:  44%|████▍     | 236/532 [03:43<04:16,  1.15it/s]Loading train:  45%|████▍     | 237/532 [03:44<04:16,  1.15it/s]Loading train:  45%|████▍     | 238/532 [03:45<04:22,  1.12it/s]Loading train:  45%|████▍     | 239/532 [03:46<04:17,  1.14it/s]Loading train:  45%|████▌     | 240/532 [03:47<04:22,  1.11it/s]Loading train:  45%|████▌     | 241/532 [03:47<04:20,  1.12it/s]Loading train:  45%|████▌     | 242/532 [03:48<04:20,  1.11it/s]Loading train:  46%|████▌     | 243/532 [03:49<04:15,  1.13it/s]Loading train:  46%|████▌     | 244/532 [03:50<04:13,  1.14it/s]Loading train:  46%|████▌     | 245/532 [03:51<04:15,  1.12it/s]Loading train:  46%|████▌     | 246/532 [03:52<04:01,  1.18it/s]Loading train:  46%|████▋     | 247/532 [03:52<03:47,  1.25it/s]Loading train:  47%|████▋     | 248/532 [03:53<03:57,  1.20it/s]Loading train:  47%|████▋     | 249/532 [03:54<03:51,  1.22it/s]Loading train:  47%|████▋     | 250/532 [03:55<03:54,  1.20it/s]Loading train:  47%|████▋     | 251/532 [03:56<03:57,  1.18it/s]Loading train:  47%|████▋     | 252/532 [03:57<03:50,  1.21it/s]Loading train:  48%|████▊     | 253/532 [03:58<04:00,  1.16it/s]Loading train:  48%|████▊     | 254/532 [03:58<03:55,  1.18it/s]Loading train:  48%|████▊     | 255/532 [03:59<03:49,  1.21it/s]Loading train:  48%|████▊     | 256/532 [04:00<03:57,  1.16it/s]Loading train:  48%|████▊     | 257/532 [04:01<04:12,  1.09it/s]Loading train:  48%|████▊     | 258/532 [04:02<04:25,  1.03it/s]Loading train:  49%|████▊     | 259/532 [04:03<04:29,  1.01it/s]Loading train:  49%|████▉     | 260/532 [04:04<04:29,  1.01it/s]Loading train:  49%|████▉     | 261/532 [04:05<04:19,  1.04it/s]Loading train:  49%|████▉     | 262/532 [04:06<04:15,  1.06it/s]Loading train:  49%|████▉     | 263/532 [04:07<04:17,  1.05it/s]Loading train:  50%|████▉     | 264/532 [04:08<03:57,  1.13it/s]Loading train:  50%|████▉     | 265/532 [04:09<03:47,  1.17it/s]Loading train:  50%|█████     | 266/532 [04:09<03:46,  1.18it/s]Loading train:  50%|█████     | 267/532 [04:10<03:42,  1.19it/s]Loading train:  50%|█████     | 268/532 [04:11<03:35,  1.22it/s]Loading train:  51%|█████     | 269/532 [04:12<03:58,  1.10it/s]Loading train:  51%|█████     | 270/532 [04:13<03:57,  1.10it/s]Loading train:  51%|█████     | 271/532 [04:14<04:02,  1.08it/s]Loading train:  51%|█████     | 272/532 [04:15<04:01,  1.08it/s]Loading train:  51%|█████▏    | 273/532 [04:16<03:53,  1.11it/s]Loading train:  52%|█████▏    | 274/532 [04:17<03:56,  1.09it/s]Loading train:  52%|█████▏    | 275/532 [04:18<04:04,  1.05it/s]Loading train:  52%|█████▏    | 276/532 [04:19<04:22,  1.03s/it]Loading train:  52%|█████▏    | 277/532 [04:20<04:28,  1.05s/it]Loading train:  52%|█████▏    | 278/532 [04:21<04:40,  1.10s/it]Loading train:  52%|█████▏    | 279/532 [04:22<04:36,  1.09s/it]Loading train:  53%|█████▎    | 280/532 [04:23<04:42,  1.12s/it]Loading train:  53%|█████▎    | 281/532 [04:25<04:44,  1.13s/it]Loading train:  53%|█████▎    | 282/532 [04:26<04:44,  1.14s/it]Loading train:  53%|█████▎    | 283/532 [04:27<04:31,  1.09s/it]Loading train:  53%|█████▎    | 284/532 [04:28<04:32,  1.10s/it]Loading train:  54%|█████▎    | 285/532 [04:29<04:27,  1.08s/it]Loading train:  54%|█████▍    | 286/532 [04:30<04:25,  1.08s/it]Loading train:  54%|█████▍    | 287/532 [04:31<04:06,  1.01s/it]Loading train:  54%|█████▍    | 288/532 [04:32<03:54,  1.04it/s]Loading train:  54%|█████▍    | 289/532 [04:33<03:43,  1.09it/s]Loading train:  55%|█████▍    | 290/532 [04:33<03:35,  1.12it/s]Loading train:  55%|█████▍    | 291/532 [04:34<03:28,  1.15it/s]Loading train:  55%|█████▍    | 292/532 [04:35<03:24,  1.17it/s]Loading train:  55%|█████▌    | 293/532 [04:36<03:29,  1.14it/s]Loading train:  55%|█████▌    | 294/532 [04:37<03:38,  1.09it/s]Loading train:  55%|█████▌    | 295/532 [04:38<03:35,  1.10it/s]Loading train:  56%|█████▌    | 296/532 [04:39<03:39,  1.07it/s]Loading train:  56%|█████▌    | 297/532 [04:40<03:43,  1.05it/s]Loading train:  56%|█████▌    | 298/532 [04:41<03:43,  1.05it/s]Loading train:  56%|█████▌    | 299/532 [04:41<03:24,  1.14it/s]Loading train:  56%|█████▋    | 300/532 [04:42<03:15,  1.19it/s]Loading train:  57%|█████▋    | 301/532 [04:43<03:11,  1.21it/s]Loading train:  57%|█████▋    | 302/532 [04:44<03:04,  1.24it/s]Loading train:  57%|█████▋    | 303/532 [04:45<03:00,  1.27it/s]Loading train:  57%|█████▋    | 304/532 [04:46<03:17,  1.15it/s]Loading train:  57%|█████▋    | 305/532 [04:47<03:43,  1.02it/s]Loading train:  58%|█████▊    | 306/532 [04:48<03:58,  1.06s/it]Loading train:  58%|█████▊    | 307/532 [04:49<03:59,  1.06s/it]Loading train:  58%|█████▊    | 308/532 [04:50<04:02,  1.08s/it]Loading train:  58%|█████▊    | 309/532 [04:51<04:01,  1.08s/it]Loading train:  58%|█████▊    | 310/532 [04:53<04:10,  1.13s/it]Loading train:  58%|█████▊    | 311/532 [04:54<04:41,  1.28s/it]Loading train:  59%|█████▊    | 312/532 [04:56<04:56,  1.35s/it]Loading train:  59%|█████▉    | 313/532 [04:57<05:20,  1.46s/it]Loading train:  59%|█████▉    | 314/532 [04:59<05:27,  1.50s/it]Loading train:  59%|█████▉    | 315/532 [05:00<05:22,  1.48s/it]Loading train:  59%|█████▉    | 316/532 [05:02<05:19,  1.48s/it]Loading train:  60%|█████▉    | 317/532 [05:03<04:38,  1.29s/it]Loading train:  60%|█████▉    | 318/532 [05:04<04:03,  1.14s/it]Loading train:  60%|█████▉    | 319/532 [05:04<03:38,  1.03s/it]Loading train:  60%|██████    | 320/532 [05:05<03:18,  1.07it/s]Loading train:  60%|██████    | 321/532 [05:06<03:07,  1.13it/s]Loading train:  61%|██████    | 322/532 [05:07<03:01,  1.16it/s]Loading train:  61%|██████    | 323/532 [05:08<03:37,  1.04s/it]Loading train:  61%|██████    | 324/532 [05:09<03:42,  1.07s/it]Loading train:  61%|██████    | 325/532 [05:11<03:54,  1.13s/it]Loading train:  61%|██████▏   | 326/532 [05:12<04:09,  1.21s/it]Loading train:  61%|██████▏   | 327/532 [05:13<04:04,  1.19s/it]Loading train:  62%|██████▏   | 328/532 [05:14<04:03,  1.19s/it]Loading train:  62%|██████▏   | 329/532 [05:15<03:56,  1.17s/it]Loading train:  62%|██████▏   | 330/532 [05:16<03:32,  1.05s/it]Loading train:  62%|██████▏   | 331/532 [05:17<03:22,  1.01s/it]Loading train:  62%|██████▏   | 332/532 [05:18<03:10,  1.05it/s]Loading train:  63%|██████▎   | 333/532 [05:19<03:04,  1.08it/s]Loading train:  63%|██████▎   | 334/532 [05:20<02:56,  1.12it/s]Loading train:  63%|██████▎   | 335/532 [05:21<03:16,  1.00it/s]Loading train:  63%|██████▎   | 336/532 [05:22<03:16,  1.00s/it]Loading train:  63%|██████▎   | 337/532 [05:23<03:18,  1.02s/it]Loading train:  64%|██████▎   | 338/532 [05:24<03:17,  1.02s/it]Loading train:  64%|██████▎   | 339/532 [05:25<03:21,  1.05s/it]Loading train:  64%|██████▍   | 340/532 [05:26<03:22,  1.06s/it]Loading train:  64%|██████▍   | 341/532 [05:27<03:06,  1.02it/s]Loading train:  64%|██████▍   | 342/532 [05:28<02:59,  1.06it/s]Loading train:  64%|██████▍   | 343/532 [05:29<02:50,  1.11it/s]Loading train:  65%|██████▍   | 344/532 [05:29<02:41,  1.17it/s]Loading train:  65%|██████▍   | 345/532 [05:30<02:38,  1.18it/s]Loading train:  65%|██████▌   | 346/532 [05:31<02:34,  1.20it/s]Loading train:  65%|██████▌   | 347/532 [05:32<02:43,  1.13it/s]Loading train:  65%|██████▌   | 348/532 [05:33<02:40,  1.14it/s]Loading train:  66%|██████▌   | 349/532 [05:34<02:40,  1.14it/s]Loading train:  66%|██████▌   | 350/532 [05:35<02:43,  1.11it/s]Loading train:  66%|██████▌   | 351/532 [05:35<02:40,  1.13it/s]Loading train:  66%|██████▌   | 352/532 [05:36<02:39,  1.13it/s]Loading train:  66%|██████▋   | 353/532 [05:37<02:36,  1.14it/s]Loading train:  67%|██████▋   | 354/532 [05:38<02:38,  1.12it/s]Loading train:  67%|██████▋   | 355/532 [05:39<02:34,  1.15it/s]Loading train:  67%|██████▋   | 356/532 [05:40<02:34,  1.14it/s]Loading train:  67%|██████▋   | 357/532 [05:41<02:36,  1.12it/s]Loading train:  67%|██████▋   | 358/532 [05:42<02:42,  1.07it/s]Loading train:  67%|██████▋   | 359/532 [05:43<02:42,  1.07it/s]Loading train:  68%|██████▊   | 360/532 [05:44<02:42,  1.06it/s]Loading train:  68%|██████▊   | 361/532 [05:45<02:35,  1.10it/s]Loading train:  68%|██████▊   | 362/532 [05:45<02:34,  1.10it/s]Loading train:  68%|██████▊   | 363/532 [05:46<02:35,  1.09it/s]Loading train:  68%|██████▊   | 364/532 [05:47<02:28,  1.13it/s]Loading train:  69%|██████▊   | 365/532 [05:48<02:25,  1.15it/s]Loading train:  69%|██████▉   | 366/532 [05:49<02:20,  1.18it/s]Loading train:  69%|██████▉   | 367/532 [05:50<02:22,  1.16it/s]Loading train:  69%|██████▉   | 368/532 [05:51<02:24,  1.13it/s]Loading train:  69%|██████▉   | 369/532 [05:52<02:31,  1.08it/s]Loading train:  70%|██████▉   | 370/532 [05:53<02:26,  1.11it/s]Loading train:  70%|██████▉   | 371/532 [05:54<02:38,  1.01it/s]Loading train:  70%|██████▉   | 372/532 [05:55<02:44,  1.03s/it]Loading train:  70%|███████   | 373/532 [05:56<02:50,  1.07s/it]Loading train:  70%|███████   | 374/532 [05:57<02:50,  1.08s/it]Loading train:  70%|███████   | 375/532 [05:58<02:53,  1.11s/it]Loading train:  71%|███████   | 376/532 [05:59<02:52,  1.11s/it]Loading train:  71%|███████   | 377/532 [06:00<02:40,  1.04s/it]Loading train:  71%|███████   | 378/532 [06:01<02:30,  1.02it/s]Loading train:  71%|███████   | 379/532 [06:02<02:25,  1.05it/s]Loading train:  71%|███████▏  | 380/532 [06:03<02:20,  1.08it/s]Loading train:  72%|███████▏  | 381/532 [06:04<02:21,  1.06it/s]Loading train:  72%|███████▏  | 382/532 [06:05<02:15,  1.11it/s]Loading train:  72%|███████▏  | 383/532 [06:06<02:25,  1.03it/s]Loading train:  72%|███████▏  | 384/532 [06:07<02:22,  1.04it/s]Loading train:  72%|███████▏  | 385/532 [06:08<02:25,  1.01it/s]Loading train:  73%|███████▎  | 386/532 [06:09<02:23,  1.02it/s]Loading train:  73%|███████▎  | 387/532 [06:10<02:26,  1.01s/it]Loading train:  73%|███████▎  | 388/532 [06:11<02:22,  1.01it/s]Loading train:  73%|███████▎  | 389/532 [06:12<02:24,  1.01s/it]Loading train:  73%|███████▎  | 390/532 [06:13<02:21,  1.00it/s]Loading train:  73%|███████▎  | 391/532 [06:14<02:21,  1.00s/it]Loading train:  74%|███████▎  | 392/532 [06:15<02:17,  1.02it/s]Loading train:  74%|███████▍  | 393/532 [06:16<02:20,  1.01s/it]Loading train:  74%|███████▍  | 394/532 [06:17<02:15,  1.02it/s]Loading train:  74%|███████▍  | 395/532 [06:18<02:20,  1.03s/it]Loading train:  74%|███████▍  | 396/532 [06:19<02:16,  1.00s/it]Loading train:  75%|███████▍  | 397/532 [06:20<02:17,  1.02s/it]Loading train:  75%|███████▍  | 398/532 [06:21<02:12,  1.01it/s]Loading train:  75%|███████▌  | 399/532 [06:22<02:10,  1.02it/s]Loading train:  75%|███████▌  | 400/532 [06:23<02:07,  1.03it/s]Loading train:  75%|███████▌  | 401/532 [06:24<02:15,  1.04s/it]Loading train:  76%|███████▌  | 402/532 [06:25<02:14,  1.04s/it]Loading train:  76%|███████▌  | 403/532 [06:26<02:14,  1.04s/it]Loading train:  76%|███████▌  | 404/532 [06:27<02:12,  1.03s/it]Loading train:  76%|███████▌  | 405/532 [06:28<02:13,  1.05s/it]Loading train:  76%|███████▋  | 406/532 [06:29<02:11,  1.04s/it]Loading train:  77%|███████▋  | 407/532 [06:30<02:14,  1.08s/it]Loading train:  77%|███████▋  | 408/532 [06:31<02:06,  1.02s/it]Loading train:  77%|███████▋  | 409/532 [06:32<02:05,  1.02s/it]Loading train:  77%|███████▋  | 410/532 [06:33<01:59,  1.02it/s]Loading train:  77%|███████▋  | 411/532 [06:34<01:59,  1.01it/s]Loading train:  77%|███████▋  | 412/532 [06:35<01:54,  1.04it/s]Loading train:  78%|███████▊  | 413/532 [06:36<01:51,  1.07it/s]Loading train:  78%|███████▊  | 414/532 [06:37<01:48,  1.09it/s]Loading train:  78%|███████▊  | 415/532 [06:38<01:44,  1.12it/s]Loading train:  78%|███████▊  | 416/532 [06:38<01:43,  1.12it/s]Loading train:  78%|███████▊  | 417/532 [06:39<01:38,  1.17it/s]Loading train:  79%|███████▊  | 418/532 [06:40<01:33,  1.21it/s]Loading train:  79%|███████▉  | 419/532 [06:41<01:42,  1.11it/s]Loading train:  79%|███████▉  | 420/532 [06:42<01:43,  1.08it/s]Loading train:  79%|███████▉  | 421/532 [06:43<01:43,  1.07it/s]Loading train:  79%|███████▉  | 422/532 [06:44<01:43,  1.06it/s]Loading train:  80%|███████▉  | 423/532 [06:45<01:43,  1.06it/s]Loading train:  80%|███████▉  | 424/532 [06:46<01:43,  1.04it/s]Loading train:  80%|███████▉  | 425/532 [06:47<01:43,  1.04it/s]Loading train:  80%|████████  | 426/532 [06:48<01:46,  1.00s/it]Loading train:  80%|████████  | 427/532 [06:49<01:44,  1.01it/s]Loading train:  80%|████████  | 428/532 [06:50<01:42,  1.01it/s]Loading train:  81%|████████  | 429/532 [06:51<01:39,  1.04it/s]Loading train:  81%|████████  | 430/532 [06:52<01:36,  1.05it/s]Loading train:  81%|████████  | 431/532 [06:53<01:43,  1.02s/it]Loading train:  81%|████████  | 432/532 [06:54<01:41,  1.02s/it]Loading train:  81%|████████▏ | 433/532 [06:55<01:40,  1.01s/it]Loading train:  82%|████████▏ | 434/532 [06:56<01:39,  1.01s/it]Loading train:  82%|████████▏ | 435/532 [06:57<01:41,  1.05s/it]Loading train:  82%|████████▏ | 436/532 [06:58<01:37,  1.02s/it]Loading train:  82%|████████▏ | 437/532 [06:59<01:36,  1.01s/it]Loading train:  82%|████████▏ | 438/532 [07:00<01:29,  1.04it/s]Loading train:  83%|████████▎ | 439/532 [07:01<01:26,  1.08it/s]Loading train:  83%|████████▎ | 440/532 [07:01<01:21,  1.13it/s]Loading train:  83%|████████▎ | 441/532 [07:02<01:20,  1.12it/s]Loading train:  83%|████████▎ | 442/532 [07:03<01:20,  1.12it/s]Loading train:  83%|████████▎ | 443/532 [07:04<01:16,  1.16it/s]Loading train:  83%|████████▎ | 444/532 [07:05<01:14,  1.18it/s]Loading train:  84%|████████▎ | 445/532 [07:06<01:14,  1.16it/s]Loading train:  84%|████████▍ | 446/532 [07:06<01:10,  1.22it/s]Loading train:  84%|████████▍ | 447/532 [07:07<01:09,  1.23it/s]Loading train:  84%|████████▍ | 448/532 [07:08<01:06,  1.26it/s]Loading train:  84%|████████▍ | 449/532 [07:09<01:06,  1.24it/s]Loading train:  85%|████████▍ | 450/532 [07:10<01:09,  1.18it/s]Loading train:  85%|████████▍ | 451/532 [07:11<01:08,  1.19it/s]Loading train:  85%|████████▍ | 452/532 [07:11<01:05,  1.22it/s]Loading train:  85%|████████▌ | 453/532 [07:12<01:06,  1.19it/s]Loading train:  85%|████████▌ | 454/532 [07:13<01:05,  1.18it/s]Loading train:  86%|████████▌ | 455/532 [07:14<01:11,  1.07it/s]Loading train:  86%|████████▌ | 456/532 [07:15<01:11,  1.07it/s]Loading train:  86%|████████▌ | 457/532 [07:16<01:12,  1.03it/s]Loading train:  86%|████████▌ | 458/532 [07:17<01:11,  1.03it/s]Loading train:  86%|████████▋ | 459/532 [07:18<01:11,  1.01it/s]Loading train:  86%|████████▋ | 460/532 [07:19<01:10,  1.02it/s]Loading train:  87%|████████▋ | 461/532 [07:20<01:12,  1.02s/it]Loading train:  87%|████████▋ | 462/532 [07:21<01:12,  1.04s/it]Loading train:  87%|████████▋ | 463/532 [07:23<01:15,  1.09s/it]Loading train:  87%|████████▋ | 464/532 [07:24<01:15,  1.10s/it]Loading train:  87%|████████▋ | 465/532 [07:25<01:14,  1.10s/it]Loading train:  88%|████████▊ | 466/532 [07:26<01:12,  1.10s/it]Loading train:  88%|████████▊ | 467/532 [07:27<01:10,  1.08s/it]Loading train:  88%|████████▊ | 468/532 [07:28<01:03,  1.00it/s]Loading train:  88%|████████▊ | 469/532 [07:29<00:58,  1.08it/s]Loading train:  88%|████████▊ | 470/532 [07:29<00:56,  1.10it/s]Loading train:  89%|████████▊ | 471/532 [07:30<00:53,  1.14it/s]Loading train:  89%|████████▊ | 472/532 [07:31<00:53,  1.13it/s]Loading train:  89%|████████▉ | 473/532 [07:32<00:53,  1.10it/s]Loading train:  89%|████████▉ | 474/532 [07:33<00:55,  1.04it/s]Loading train:  89%|████████▉ | 475/532 [07:34<00:54,  1.04it/s]Loading train:  89%|████████▉ | 476/532 [07:35<00:52,  1.06it/s]Loading train:  90%|████████▉ | 477/532 [07:36<00:52,  1.04it/s]Loading train:  90%|████████▉ | 478/532 [07:37<00:52,  1.03it/s]Loading train:  90%|█████████ | 479/532 [07:38<00:52,  1.01it/s]Loading train:  90%|█████████ | 480/532 [07:39<00:48,  1.06it/s]Loading train:  90%|█████████ | 481/532 [07:40<00:48,  1.06it/s]Loading train:  91%|█████████ | 482/532 [07:41<00:45,  1.10it/s]Loading train:  91%|█████████ | 483/532 [07:42<00:43,  1.14it/s]Loading train:  91%|█████████ | 484/532 [07:42<00:42,  1.14it/s]Loading train:  91%|█████████ | 485/532 [07:43<00:43,  1.08it/s]Loading train:  91%|█████████▏| 486/532 [07:45<00:45,  1.01it/s]Loading train:  92%|█████████▏| 487/532 [07:46<00:45,  1.00s/it]Loading train:  92%|█████████▏| 488/532 [07:47<00:44,  1.02s/it]Loading train:  92%|█████████▏| 489/532 [07:48<00:45,  1.05s/it]Loading train:  92%|█████████▏| 490/532 [07:49<00:43,  1.04s/it]Loading train:  92%|█████████▏| 491/532 [07:50<00:41,  1.02s/it]Loading train:  92%|█████████▏| 492/532 [07:51<00:38,  1.04it/s]Loading train:  93%|█████████▎| 493/532 [07:52<00:38,  1.02it/s]Loading train:  93%|█████████▎| 494/532 [07:52<00:35,  1.08it/s]Loading train:  93%|█████████▎| 495/532 [07:53<00:33,  1.09it/s]Loading train:  93%|█████████▎| 496/532 [07:54<00:33,  1.08it/s]Loading train:  93%|█████████▎| 497/532 [07:55<00:33,  1.04it/s]Loading train:  94%|█████████▎| 498/532 [07:56<00:32,  1.06it/s]Loading train:  94%|█████████▍| 499/532 [07:57<00:32,  1.03it/s]Loading train:  94%|█████████▍| 500/532 [07:58<00:30,  1.06it/s]Loading train:  94%|█████████▍| 501/532 [07:59<00:29,  1.07it/s]Loading train:  94%|█████████▍| 502/532 [08:00<00:27,  1.09it/s]Loading train:  95%|█████████▍| 503/532 [08:01<00:27,  1.07it/s]Loading train:  95%|█████████▍| 504/532 [08:02<00:25,  1.11it/s]Loading train:  95%|█████████▍| 505/532 [08:03<00:24,  1.12it/s]Loading train:  95%|█████████▌| 506/532 [08:03<00:22,  1.13it/s]Loading train:  95%|█████████▌| 507/532 [08:04<00:21,  1.14it/s]Loading train:  95%|█████████▌| 508/532 [08:05<00:21,  1.11it/s]Loading train:  96%|█████████▌| 509/532 [08:06<00:22,  1.04it/s]Loading train:  96%|█████████▌| 510/532 [08:07<00:21,  1.03it/s]Loading train:  96%|█████████▌| 511/532 [08:08<00:20,  1.02it/s]Loading train:  96%|█████████▌| 512/532 [08:09<00:20,  1.00s/it]Loading train:  96%|█████████▋| 513/532 [08:10<00:18,  1.00it/s]Loading train:  97%|█████████▋| 514/532 [08:12<00:18,  1.03s/it]Loading train:  97%|█████████▋| 515/532 [08:12<00:17,  1.01s/it]Loading train:  97%|█████████▋| 516/532 [08:13<00:15,  1.01it/s]Loading train:  97%|█████████▋| 517/532 [08:14<00:14,  1.04it/s]Loading train:  97%|█████████▋| 518/532 [08:15<00:13,  1.05it/s]Loading train:  98%|█████████▊| 519/532 [08:16<00:11,  1.09it/s]Loading train:  98%|█████████▊| 520/532 [08:17<00:10,  1.10it/s]Loading train:  98%|█████████▊| 521/532 [08:18<00:10,  1.10it/s]Loading train:  98%|█████████▊| 522/532 [08:19<00:09,  1.07it/s]Loading train:  98%|█████████▊| 523/532 [08:20<00:08,  1.06it/s]Loading train:  98%|█████████▊| 524/532 [08:21<00:07,  1.09it/s]Loading train:  99%|█████████▊| 525/532 [08:22<00:06,  1.05it/s]Loading train:  99%|█████████▉| 526/532 [08:23<00:05,  1.05it/s]Loading train:  99%|█████████▉| 527/532 [08:24<00:04,  1.08it/s]Loading train:  99%|█████████▉| 528/532 [08:25<00:03,  1.05it/s]Loading train:  99%|█████████▉| 529/532 [08:25<00:02,  1.08it/s]Loading train: 100%|█████████▉| 530/532 [08:26<00:01,  1.11it/s]Loading train: 100%|█████████▉| 531/532 [08:27<00:00,  1.11it/s]Loading train: 100%|██████████| 532/532 [08:28<00:00,  1.13it/s]
concatenating: train:   0%|          | 0/532 [00:00<?, ?it/s]concatenating: train:   1%|          | 5/532 [00:00<00:10, 49.62it/s]concatenating: train:   4%|▍         | 22/532 [00:00<00:08, 62.93it/s]concatenating: train:   9%|▉         | 49/532 [00:00<00:05, 81.26it/s]concatenating: train:  13%|█▎        | 71/532 [00:00<00:04, 99.45it/s]concatenating: train:  18%|█▊        | 94/532 [00:00<00:03, 119.31it/s]concatenating: train:  22%|██▏       | 118/532 [00:00<00:02, 139.51it/s]concatenating: train:  28%|██▊       | 148/532 [00:00<00:02, 165.38it/s]concatenating: train:  33%|███▎      | 174/532 [00:00<00:01, 184.39it/s]concatenating: train:  38%|███▊      | 200/532 [00:00<00:01, 198.93it/s]concatenating: train:  43%|████▎     | 229/532 [00:01<00:01, 217.03it/s]concatenating: train:  48%|████▊     | 254/532 [00:01<00:01, 220.54it/s]concatenating: train:  53%|█████▎    | 282/532 [00:01<00:01, 235.43it/s]concatenating: train:  58%|█████▊    | 310/532 [00:01<00:00, 246.88it/s]concatenating: train:  63%|██████▎   | 337/532 [00:01<00:00, 250.21it/s]concatenating: train:  68%|██████▊   | 363/532 [00:01<00:00, 245.19it/s]concatenating: train:  73%|███████▎  | 389/532 [00:01<00:00, 245.07it/s]concatenating: train:  78%|███████▊  | 415/532 [00:01<00:00, 248.65it/s]concatenating: train:  84%|████████▎ | 445/532 [00:01<00:00, 259.93it/s]concatenating: train:  89%|████████▊ | 472/532 [00:01<00:00, 255.60it/s]concatenating: train:  94%|█████████▎| 498/532 [00:02<00:00, 159.02it/s]concatenating: train:  99%|█████████▊| 525/532 [00:02<00:00, 181.13it/s]concatenating: train: 100%|██████████| 532/532 [00:02<00:00, 220.52it/s]
Loading test:   0%|          | 0/15 [00:00<?, ?it/s]Loading test:   7%|▋         | 1/15 [00:00<00:09,  1.45it/s]Loading test:  13%|█▎        | 2/15 [00:01<00:09,  1.35it/s]Loading test:  20%|██        | 3/15 [00:02<00:09,  1.24it/s]Loading test:  27%|██▋       | 4/15 [00:03<00:09,  1.11it/s]Loading test:  33%|███▎      | 5/15 [00:04<00:10,  1.03s/it]Loading test:  40%|████      | 6/15 [00:06<00:09,  1.11s/it]Loading test:  47%|████▋     | 7/15 [00:07<00:08,  1.00s/it]Loading test:  53%|█████▎    | 8/15 [00:08<00:07,  1.10s/it]Loading test:  60%|██████    | 9/15 [00:09<00:06,  1.05s/it]Loading test:  67%|██████▋   | 10/15 [00:10<00:04,  1.02it/s]Loading test:  73%|███████▎  | 11/15 [00:11<00:03,  1.03it/s]Loading test:  80%|████████  | 12/15 [00:12<00:03,  1.03s/it]Loading test:  87%|████████▋ | 13/15 [00:13<00:02,  1.14s/it]Loading test:  93%|█████████▎| 14/15 [00:14<00:01,  1.06s/it]Loading test: 100%|██████████| 15/15 [00:15<00:00,  1.08s/it]
concatenating: validation:   0%|          | 0/15 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 15/15 [00:00<00:00, 396.67it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 84, 56, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 84, 56, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 84, 56, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 84, 56, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 84, 56, 10)   910         activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 84, 56, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 84, 56, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 84, 56, 11)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 42, 28, 11)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 42, 28, 11)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 42, 28, 20)   2000        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 42, 28, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 42, 28, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 42, 28, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 42, 28, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 42, 28, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 42, 28, 31)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 21, 14, 31)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 21, 14, 31)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 21, 14, 40)   11200       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 21, 14, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 21, 14, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 21, 14, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 21, 14, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 21, 14, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 21, 14, 71)   0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 21, 14, 71)   0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 42, 28, 20)   5700        dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 42, 28, 51)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 42, 28, 20)   9200        concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 42, 28, 20)   80          conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 42, 28, 20)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 42, 28, 20)   3620        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 42, 28, 20)   80          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 42, 28, 20)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 42, 28, 71)   0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-06 20:04:22.779948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-06 20:04:22.780045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-06 20:04:22.780064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-06 20:04:22.780072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-06 20:04:22.780493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 42, 28, 71)   0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 84, 56, 10)   2850        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 56, 21)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 84, 56, 10)   1900        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 84, 56, 10)   40          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 84, 56, 10)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 84, 56, 10)   910         activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 84, 56, 10)   40          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 56, 10)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 84, 56, 31)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 84, 56, 31)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 84, 56, 13)   416         dropout_5[0][0]                  
==================================================================================================
Total params: 57,666
Trainable params: 57,266
Non-trainable params: 400
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.53807809e-02 2.88974534e-02 1.16728790e-01 1.00198377e-02
 3.03363016e-02 5.79915656e-03 6.86746312e-02 1.28228722e-01
 7.55625878e-02 1.22514673e-02 2.73642650e-01 1.84278063e-01
 1.99559502e-04]
Train on 19871 samples, validate on 569 samples
Epoch 1/300
 - 23s - loss: 96.7971 - acc: 0.7812 - mDice: 0.0160 - val_loss: 9.0534 - val_acc: 0.9112 - val_mDice: 0.0081

Epoch 00001: val_mDice improved from -inf to 0.00805, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 16s - loss: 11.0019 - acc: 0.8916 - mDice: 0.0292 - val_loss: 5.7879 - val_acc: 0.9112 - val_mDice: 0.0455

Epoch 00002: val_mDice improved from 0.00805 to 0.04552, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 14s - loss: 8.3111 - acc: 0.8944 - mDice: 0.0432 - val_loss: 5.3845 - val_acc: 0.9112 - val_mDice: 0.0673

Epoch 00003: val_mDice improved from 0.04552 to 0.06732, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 16s - loss: 7.1574 - acc: 0.8957 - mDice: 0.0616 - val_loss: 4.7537 - val_acc: 0.9111 - val_mDice: 0.0971

Epoch 00004: val_mDice improved from 0.06732 to 0.09714, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 14s - loss: 6.2962 - acc: 0.8987 - mDice: 0.0902 - val_loss: 4.1811 - val_acc: 0.9142 - val_mDice: 0.1374

Epoch 00005: val_mDice improved from 0.09714 to 0.13739, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 15s - loss: 5.6795 - acc: 0.9029 - mDice: 0.1214 - val_loss: 3.7846 - val_acc: 0.9185 - val_mDice: 0.1827

Epoch 00006: val_mDice improved from 0.13739 to 0.18268, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 7/300
 - 15s - loss: 5.2156 - acc: 0.9068 - mDice: 0.1541 - val_loss: 3.4182 - val_acc: 0.9257 - val_mDice: 0.2345

Epoch 00007: val_mDice improved from 0.18268 to 0.23455, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 8/300
 - 14s - loss: 4.8175 - acc: 0.9114 - mDice: 0.1907 - val_loss: 3.0569 - val_acc: 0.9402 - val_mDice: 0.2936

Epoch 00008: val_mDice improved from 0.23455 to 0.29363, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 16s - loss: 4.4808 - acc: 0.9158 - mDice: 0.2264 - val_loss: 2.8648 - val_acc: 0.9362 - val_mDice: 0.3225

Epoch 00009: val_mDice improved from 0.29363 to 0.32250, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 10/300
 - 15s - loss: 4.2491 - acc: 0.9186 - mDice: 0.2517 - val_loss: 2.6876 - val_acc: 0.9363 - val_mDice: 0.3525

Epoch 00010: val_mDice improved from 0.32250 to 0.35253, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 11/300
 - 14s - loss: 4.0370 - acc: 0.9207 - mDice: 0.2772 - val_loss: 2.5126 - val_acc: 0.9420 - val_mDice: 0.3943

Epoch 00011: val_mDice improved from 0.35253 to 0.39426, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 12/300
 - 17s - loss: 3.8293 - acc: 0.9232 - mDice: 0.3034 - val_loss: 2.2872 - val_acc: 0.9544 - val_mDice: 0.4395

Epoch 00012: val_mDice improved from 0.39426 to 0.43946, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 13/300
 - 15s - loss: 3.6547 - acc: 0.9258 - mDice: 0.3260 - val_loss: 2.1568 - val_acc: 0.9585 - val_mDice: 0.4620

Epoch 00013: val_mDice improved from 0.43946 to 0.46199, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 14/300
 - 17s - loss: 3.5019 - acc: 0.9283 - mDice: 0.3459 - val_loss: 2.0749 - val_acc: 0.9618 - val_mDice: 0.4848

Epoch 00014: val_mDice improved from 0.46199 to 0.48485, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 15/300
 - 15s - loss: 3.3627 - acc: 0.9302 - mDice: 0.3636 - val_loss: 2.0279 - val_acc: 0.9631 - val_mDice: 0.4998

Epoch 00015: val_mDice improved from 0.48485 to 0.49975, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 16/300
 - 17s - loss: 3.2413 - acc: 0.9321 - mDice: 0.3799 - val_loss: 1.9370 - val_acc: 0.9652 - val_mDice: 0.5214

Epoch 00016: val_mDice improved from 0.49975 to 0.52136, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 17/300
 - 16s - loss: 3.1276 - acc: 0.9337 - mDice: 0.3949 - val_loss: 1.8335 - val_acc: 0.9661 - val_mDice: 0.5413

Epoch 00017: val_mDice improved from 0.52136 to 0.54131, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 18/300
 - 16s - loss: 3.0143 - acc: 0.9354 - mDice: 0.4099 - val_loss: 1.7773 - val_acc: 0.9673 - val_mDice: 0.5527

Epoch 00018: val_mDice improved from 0.54131 to 0.55266, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 19/300
 - 16s - loss: 2.9141 - acc: 0.9369 - mDice: 0.4243 - val_loss: 1.7167 - val_acc: 0.9677 - val_mDice: 0.5691

Epoch 00019: val_mDice improved from 0.55266 to 0.56914, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 20/300
 - 16s - loss: 2.8248 - acc: 0.9378 - mDice: 0.4379 - val_loss: 1.6684 - val_acc: 0.9679 - val_mDice: 0.5832

Epoch 00020: val_mDice improved from 0.56914 to 0.58318, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 21/300
 - 17s - loss: 2.7337 - acc: 0.9387 - mDice: 0.4525 - val_loss: 1.6256 - val_acc: 0.9678 - val_mDice: 0.5937

Epoch 00021: val_mDice improved from 0.58318 to 0.59367, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 22/300
 - 15s - loss: 2.6452 - acc: 0.9398 - mDice: 0.4686 - val_loss: 1.5977 - val_acc: 0.9688 - val_mDice: 0.6032

Epoch 00022: val_mDice improved from 0.59367 to 0.60324, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 23/300
 - 17s - loss: 2.5711 - acc: 0.9408 - mDice: 0.4805 - val_loss: 1.5578 - val_acc: 0.9695 - val_mDice: 0.6138

Epoch 00023: val_mDice improved from 0.60324 to 0.61378, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 24/300
 - 16s - loss: 2.4949 - acc: 0.9420 - mDice: 0.4930 - val_loss: 1.5313 - val_acc: 0.9692 - val_mDice: 0.6266

Epoch 00024: val_mDice improved from 0.61378 to 0.62663, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 25/300
 - 17s - loss: 2.4499 - acc: 0.9424 - mDice: 0.4991 - val_loss: 1.5275 - val_acc: 0.9696 - val_mDice: 0.6240

Epoch 00025: val_mDice did not improve from 0.62663
Epoch 26/300
 - 16s - loss: 2.3915 - acc: 0.9431 - mDice: 0.5093 - val_loss: 1.5129 - val_acc: 0.9698 - val_mDice: 0.6286

Epoch 00026: val_mDice improved from 0.62663 to 0.62864, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 27/300
 - 17s - loss: 2.3457 - acc: 0.9438 - mDice: 0.5168 - val_loss: 1.4668 - val_acc: 0.9708 - val_mDice: 0.6356

Epoch 00027: val_mDice improved from 0.62864 to 0.63561, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 28/300
 - 15s - loss: 2.2999 - acc: 0.9443 - mDice: 0.5239 - val_loss: 1.4800 - val_acc: 0.9696 - val_mDice: 0.6429

Epoch 00028: val_mDice improved from 0.63561 to 0.64287, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 29/300
 - 17s - loss: 2.2684 - acc: 0.9447 - mDice: 0.5300 - val_loss: 1.4609 - val_acc: 0.9705 - val_mDice: 0.6439

Epoch 00029: val_mDice improved from 0.64287 to 0.64387, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 30/300
 - 14s - loss: 2.2260 - acc: 0.9454 - mDice: 0.5369 - val_loss: 1.4454 - val_acc: 0.9712 - val_mDice: 0.6486

Epoch 00030: val_mDice improved from 0.64387 to 0.64861, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 31/300
 - 16s - loss: 2.1937 - acc: 0.9459 - mDice: 0.5429 - val_loss: 1.4177 - val_acc: 0.9721 - val_mDice: 0.6550

Epoch 00031: val_mDice improved from 0.64861 to 0.65495, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 32/300
 - 14s - loss: 2.1659 - acc: 0.9463 - mDice: 0.5480 - val_loss: 1.4189 - val_acc: 0.9720 - val_mDice: 0.6580

Epoch 00032: val_mDice improved from 0.65495 to 0.65802, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 33/300
 - 14s - loss: 2.1379 - acc: 0.9467 - mDice: 0.5529 - val_loss: 1.3917 - val_acc: 0.9715 - val_mDice: 0.6606

Epoch 00033: val_mDice improved from 0.65802 to 0.66059, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 34/300
 - 15s - loss: 2.1087 - acc: 0.9473 - mDice: 0.5588 - val_loss: 1.4067 - val_acc: 0.9716 - val_mDice: 0.6607

Epoch 00034: val_mDice improved from 0.66059 to 0.66075, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 35/300
 - 15s - loss: 2.0872 - acc: 0.9475 - mDice: 0.5630 - val_loss: 1.3806 - val_acc: 0.9711 - val_mDice: 0.6649

Epoch 00035: val_mDice improved from 0.66075 to 0.66488, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 36/300
 - 14s - loss: 2.0609 - acc: 0.9478 - mDice: 0.5673 - val_loss: 1.3785 - val_acc: 0.9718 - val_mDice: 0.6672

Epoch 00036: val_mDice improved from 0.66488 to 0.66723, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 37/300
 - 14s - loss: 2.0320 - acc: 0.9483 - mDice: 0.5733 - val_loss: 1.3658 - val_acc: 0.9721 - val_mDice: 0.6728

Epoch 00037: val_mDice improved from 0.66723 to 0.67285, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 38/300
 - 14s - loss: 2.0168 - acc: 0.9485 - mDice: 0.5761 - val_loss: 1.3519 - val_acc: 0.9724 - val_mDice: 0.6744

Epoch 00038: val_mDice improved from 0.67285 to 0.67436, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 39/300
 - 15s - loss: 1.9963 - acc: 0.9487 - mDice: 0.5805 - val_loss: 1.3477 - val_acc: 0.9724 - val_mDice: 0.6799

Epoch 00039: val_mDice improved from 0.67436 to 0.67987, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 40/300
 - 15s - loss: 1.9795 - acc: 0.9489 - mDice: 0.5830 - val_loss: 1.3284 - val_acc: 0.9724 - val_mDice: 0.6790

Epoch 00040: val_mDice did not improve from 0.67987
Epoch 41/300
 - 14s - loss: 1.9553 - acc: 0.9493 - mDice: 0.5881 - val_loss: 1.3317 - val_acc: 0.9729 - val_mDice: 0.6779

Epoch 00041: val_mDice did not improve from 0.67987
Epoch 42/300
 - 14s - loss: 1.9435 - acc: 0.9494 - mDice: 0.5903 - val_loss: 1.3336 - val_acc: 0.9729 - val_mDice: 0.6799

Epoch 00042: val_mDice improved from 0.67987 to 0.67987, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 43/300
 - 14s - loss: 1.9340 - acc: 0.9494 - mDice: 0.5922 - val_loss: 1.3113 - val_acc: 0.9728 - val_mDice: 0.6839

Epoch 00043: val_mDice improved from 0.67987 to 0.68393, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 44/300
 - 15s - loss: 1.9111 - acc: 0.9498 - mDice: 0.5964 - val_loss: 1.3101 - val_acc: 0.9725 - val_mDice: 0.6857

Epoch 00044: val_mDice improved from 0.68393 to 0.68570, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 45/300
 - 14s - loss: 1.8926 - acc: 0.9502 - mDice: 0.5996 - val_loss: 1.2995 - val_acc: 0.9725 - val_mDice: 0.6878

Epoch 00045: val_mDice improved from 0.68570 to 0.68784, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 46/300
 - 14s - loss: 1.8766 - acc: 0.9505 - mDice: 0.6034 - val_loss: 1.3194 - val_acc: 0.9728 - val_mDice: 0.6860

Epoch 00046: val_mDice did not improve from 0.68784
Epoch 47/300
 - 14s - loss: 1.8617 - acc: 0.9508 - mDice: 0.6065 - val_loss: 1.2983 - val_acc: 0.9723 - val_mDice: 0.6892

Epoch 00047: val_mDice improved from 0.68784 to 0.68921, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 48/300
 - 14s - loss: 1.8617 - acc: 0.9509 - mDice: 0.6067 - val_loss: 1.2941 - val_acc: 0.9722 - val_mDice: 0.6917

Epoch 00048: val_mDice improved from 0.68921 to 0.69168, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 49/300
 - 14s - loss: 1.8368 - acc: 0.9512 - mDice: 0.6113 - val_loss: 1.3156 - val_acc: 0.9725 - val_mDice: 0.6904

Epoch 00049: val_mDice did not improve from 0.69168
Epoch 50/300
 - 15s - loss: 1.8250 - acc: 0.9515 - mDice: 0.6134 - val_loss: 1.2848 - val_acc: 0.9726 - val_mDice: 0.6972

Epoch 00050: val_mDice improved from 0.69168 to 0.69723, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 51/300
 - 15s - loss: 1.8151 - acc: 0.9516 - mDice: 0.6154 - val_loss: 1.2885 - val_acc: 0.9730 - val_mDice: 0.6996

Epoch 00051: val_mDice improved from 0.69723 to 0.69958, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 52/300
 - 14s - loss: 1.8069 - acc: 0.9518 - mDice: 0.6173 - val_loss: 1.2738 - val_acc: 0.9734 - val_mDice: 0.6951

Epoch 00052: val_mDice did not improve from 0.69958
Epoch 53/300
 - 14s - loss: 1.7979 - acc: 0.9519 - mDice: 0.6190 - val_loss: 1.2704 - val_acc: 0.9734 - val_mDice: 0.6954

Epoch 00053: val_mDice did not improve from 0.69958
Epoch 54/300
 - 16s - loss: 1.7906 - acc: 0.9520 - mDice: 0.6204 - val_loss: 1.2982 - val_acc: 0.9723 - val_mDice: 0.6966

Epoch 00054: val_mDice did not improve from 0.69958
Epoch 55/300
 - 14s - loss: 1.7739 - acc: 0.9524 - mDice: 0.6234 - val_loss: 1.2782 - val_acc: 0.9736 - val_mDice: 0.6966

Epoch 00055: val_mDice did not improve from 0.69958
Epoch 56/300
 - 15s - loss: 1.7712 - acc: 0.9525 - mDice: 0.6244 - val_loss: 1.2619 - val_acc: 0.9734 - val_mDice: 0.6993

Epoch 00056: val_mDice did not improve from 0.69958
Epoch 57/300
 - 15s - loss: 1.7598 - acc: 0.9526 - mDice: 0.6265 - val_loss: 1.2557 - val_acc: 0.9737 - val_mDice: 0.7029

Epoch 00057: val_mDice improved from 0.69958 to 0.70289, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 58/300
 - 15s - loss: 1.7508 - acc: 0.9528 - mDice: 0.6284 - val_loss: 1.2545 - val_acc: 0.9736 - val_mDice: 0.6998

Epoch 00058: val_mDice did not improve from 0.70289
Epoch 59/300
 - 16s - loss: 1.7427 - acc: 0.9529 - mDice: 0.6296 - val_loss: 1.2613 - val_acc: 0.9743 - val_mDice: 0.7022

Epoch 00059: val_mDice did not improve from 0.70289
Epoch 60/300
 - 14s - loss: 1.7393 - acc: 0.9530 - mDice: 0.6307 - val_loss: 1.2644 - val_acc: 0.9735 - val_mDice: 0.6984

Epoch 00060: val_mDice did not improve from 0.70289
Epoch 61/300
 - 16s - loss: 1.7264 - acc: 0.9532 - mDice: 0.6328 - val_loss: 1.2411 - val_acc: 0.9742 - val_mDice: 0.7010

Epoch 00061: val_mDice did not improve from 0.70289
Epoch 62/300
 - 14s - loss: 1.7288 - acc: 0.9531 - mDice: 0.6326 - val_loss: 1.2331 - val_acc: 0.9745 - val_mDice: 0.7052

Epoch 00062: val_mDice improved from 0.70289 to 0.70521, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 63/300
 - 15s - loss: 1.7195 - acc: 0.9533 - mDice: 0.6346 - val_loss: 1.2485 - val_acc: 0.9741 - val_mDice: 0.7054

Epoch 00063: val_mDice improved from 0.70521 to 0.70541, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 64/300
 - 16s - loss: 1.7065 - acc: 0.9534 - mDice: 0.6369 - val_loss: 1.2451 - val_acc: 0.9741 - val_mDice: 0.7042

Epoch 00064: val_mDice did not improve from 0.70541
Epoch 65/300
 - 14s - loss: 1.6998 - acc: 0.9536 - mDice: 0.6385 - val_loss: 1.2506 - val_acc: 0.9744 - val_mDice: 0.7025

Epoch 00065: val_mDice did not improve from 0.70541
Epoch 66/300
 - 16s - loss: 1.6970 - acc: 0.9537 - mDice: 0.6388 - val_loss: 1.2174 - val_acc: 0.9745 - val_mDice: 0.7064

Epoch 00066: val_mDice improved from 0.70541 to 0.70643, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 67/300
 - 14s - loss: 1.6962 - acc: 0.9537 - mDice: 0.6389 - val_loss: 1.2519 - val_acc: 0.9744 - val_mDice: 0.7051

Epoch 00067: val_mDice did not improve from 0.70643
Epoch 68/300
 - 16s - loss: 1.6842 - acc: 0.9539 - mDice: 0.6412 - val_loss: 1.2326 - val_acc: 0.9743 - val_mDice: 0.7095

Epoch 00068: val_mDice improved from 0.70643 to 0.70946, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 69/300
 - 15s - loss: 1.6837 - acc: 0.9540 - mDice: 0.6414 - val_loss: 1.2496 - val_acc: 0.9740 - val_mDice: 0.7095

Epoch 00069: val_mDice improved from 0.70946 to 0.70949, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 70/300
 - 15s - loss: 1.6761 - acc: 0.9541 - mDice: 0.6429 - val_loss: 1.2336 - val_acc: 0.9743 - val_mDice: 0.7094

Epoch 00070: val_mDice did not improve from 0.70949
Epoch 71/300
 - 16s - loss: 1.6767 - acc: 0.9541 - mDice: 0.6433 - val_loss: 1.2191 - val_acc: 0.9752 - val_mDice: 0.7077

Epoch 00071: val_mDice did not improve from 0.70949
Epoch 72/300
 - 15s - loss: 1.6650 - acc: 0.9543 - mDice: 0.6455 - val_loss: 1.2246 - val_acc: 0.9745 - val_mDice: 0.7105

Epoch 00072: val_mDice improved from 0.70949 to 0.71054, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 73/300
 - 16s - loss: 1.6621 - acc: 0.9544 - mDice: 0.6459 - val_loss: 1.2271 - val_acc: 0.9746 - val_mDice: 0.7106

Epoch 00073: val_mDice improved from 0.71054 to 0.71056, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 74/300
 - 14s - loss: 1.6635 - acc: 0.9543 - mDice: 0.6456 - val_loss: 1.2296 - val_acc: 0.9751 - val_mDice: 0.7123

Epoch 00074: val_mDice improved from 0.71056 to 0.71233, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 75/300
 - 16s - loss: 1.6552 - acc: 0.9545 - mDice: 0.6473 - val_loss: 1.2109 - val_acc: 0.9751 - val_mDice: 0.7111

Epoch 00075: val_mDice did not improve from 0.71233
Epoch 76/300
 - 14s - loss: 1.6548 - acc: 0.9545 - mDice: 0.6476 - val_loss: 1.2186 - val_acc: 0.9752 - val_mDice: 0.7116

Epoch 00076: val_mDice did not improve from 0.71233
Epoch 77/300
 - 16s - loss: 1.6422 - acc: 0.9547 - mDice: 0.6497 - val_loss: 1.2296 - val_acc: 0.9750 - val_mDice: 0.7083

Epoch 00077: val_mDice did not improve from 0.71233
Epoch 78/300
 - 14s - loss: 1.6388 - acc: 0.9547 - mDice: 0.6504 - val_loss: 1.2124 - val_acc: 0.9755 - val_mDice: 0.7128

Epoch 00078: val_mDice improved from 0.71233 to 0.71280, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 79/300
 - 16s - loss: 1.6376 - acc: 0.9548 - mDice: 0.6510 - val_loss: 1.2129 - val_acc: 0.9752 - val_mDice: 0.7152

Epoch 00079: val_mDice improved from 0.71280 to 0.71519, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 80/300
 - 15s - loss: 1.6394 - acc: 0.9547 - mDice: 0.6504 - val_loss: 1.1990 - val_acc: 0.9750 - val_mDice: 0.7172

Epoch 00080: val_mDice improved from 0.71519 to 0.71723, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 81/300
 - 15s - loss: 1.6267 - acc: 0.9549 - mDice: 0.6530 - val_loss: 1.2209 - val_acc: 0.9753 - val_mDice: 0.7106

Epoch 00081: val_mDice did not improve from 0.71723
Epoch 82/300
 - 16s - loss: 1.6307 - acc: 0.9548 - mDice: 0.6522 - val_loss: 1.1908 - val_acc: 0.9750 - val_mDice: 0.7158

Epoch 00082: val_mDice did not improve from 0.71723
Epoch 83/300
 - 14s - loss: 1.6208 - acc: 0.9549 - mDice: 0.6540 - val_loss: 1.2060 - val_acc: 0.9746 - val_mDice: 0.7156

Epoch 00083: val_mDice did not improve from 0.71723
Epoch 84/300
 - 17s - loss: 1.6177 - acc: 0.9550 - mDice: 0.6552 - val_loss: 1.2142 - val_acc: 0.9751 - val_mDice: 0.7126

Epoch 00084: val_mDice did not improve from 0.71723
Epoch 85/300
 - 15s - loss: 1.6151 - acc: 0.9551 - mDice: 0.6553 - val_loss: 1.2400 - val_acc: 0.9746 - val_mDice: 0.7132

Epoch 00085: val_mDice did not improve from 0.71723
Epoch 86/300
 - 18s - loss: 1.6094 - acc: 0.9552 - mDice: 0.6565 - val_loss: 1.1875 - val_acc: 0.9751 - val_mDice: 0.7202

Epoch 00086: val_mDice improved from 0.71723 to 0.72025, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 87/300
 - 15s - loss: 1.6060 - acc: 0.9552 - mDice: 0.6575 - val_loss: 1.2064 - val_acc: 0.9743 - val_mDice: 0.7158

Epoch 00087: val_mDice did not improve from 0.72025
Epoch 88/300
 - 17s - loss: 1.6074 - acc: 0.9552 - mDice: 0.6570 - val_loss: 1.1955 - val_acc: 0.9751 - val_mDice: 0.7170

Epoch 00088: val_mDice did not improve from 0.72025
Epoch 89/300
 - 16s - loss: 1.6083 - acc: 0.9551 - mDice: 0.6565 - val_loss: 1.2158 - val_acc: 0.9753 - val_mDice: 0.7202

Epoch 00089: val_mDice did not improve from 0.72025
Epoch 90/300
 - 18s - loss: 1.5946 - acc: 0.9553 - mDice: 0.6590 - val_loss: 1.1980 - val_acc: 0.9755 - val_mDice: 0.7148

Epoch 00090: val_mDice did not improve from 0.72025
Epoch 91/300
 - 16s - loss: 1.5978 - acc: 0.9553 - mDice: 0.6590 - val_loss: 1.2160 - val_acc: 0.9752 - val_mDice: 0.7112

Epoch 00091: val_mDice did not improve from 0.72025
Epoch 92/300
 - 17s - loss: 1.5924 - acc: 0.9555 - mDice: 0.6602 - val_loss: 1.1934 - val_acc: 0.9754 - val_mDice: 0.7203

Epoch 00092: val_mDice improved from 0.72025 to 0.72034, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 93/300
 - 17s - loss: 1.5881 - acc: 0.9555 - mDice: 0.6608 - val_loss: 1.2261 - val_acc: 0.9749 - val_mDice: 0.7140

Epoch 00093: val_mDice did not improve from 0.72034
Epoch 94/300
 - 16s - loss: 1.5834 - acc: 0.9556 - mDice: 0.6621 - val_loss: 1.1932 - val_acc: 0.9754 - val_mDice: 0.7185

Epoch 00094: val_mDice did not improve from 0.72034
Epoch 95/300
 - 18s - loss: 1.5808 - acc: 0.9556 - mDice: 0.6621 - val_loss: 1.2019 - val_acc: 0.9755 - val_mDice: 0.7155

Epoch 00095: val_mDice did not improve from 0.72034
Epoch 96/300
 - 16s - loss: 1.5824 - acc: 0.9556 - mDice: 0.6623 - val_loss: 1.1837 - val_acc: 0.9754 - val_mDice: 0.7209

Epoch 00096: val_mDice improved from 0.72034 to 0.72090, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 97/300
 - 18s - loss: 1.5781 - acc: 0.9557 - mDice: 0.6629 - val_loss: 1.2265 - val_acc: 0.9748 - val_mDice: 0.7119

Epoch 00097: val_mDice did not improve from 0.72090
Epoch 98/300
 - 16s - loss: 1.5798 - acc: 0.9557 - mDice: 0.6627 - val_loss: 1.2141 - val_acc: 0.9751 - val_mDice: 0.7190

Epoch 00098: val_mDice did not improve from 0.72090
Epoch 99/300
 - 18s - loss: 1.5788 - acc: 0.9557 - mDice: 0.6629 - val_loss: 1.1923 - val_acc: 0.9753 - val_mDice: 0.7209

Epoch 00099: val_mDice did not improve from 0.72090
Epoch 100/300
 - 16s - loss: 1.5699 - acc: 0.9559 - mDice: 0.6647 - val_loss: 1.2100 - val_acc: 0.9753 - val_mDice: 0.7185

Epoch 00100: val_mDice did not improve from 0.72090
Epoch 101/300
 - 17s - loss: 1.5687 - acc: 0.9559 - mDice: 0.6647 - val_loss: 1.1787 - val_acc: 0.9755 - val_mDice: 0.7238

Epoch 00101: val_mDice improved from 0.72090 to 0.72383, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 102/300
 - 16s - loss: 1.5698 - acc: 0.9559 - mDice: 0.6643 - val_loss: 1.1827 - val_acc: 0.9757 - val_mDice: 0.7202

Epoch 00102: val_mDice did not improve from 0.72383
Epoch 103/300
 - 15s - loss: 1.5662 - acc: 0.9559 - mDice: 0.6656 - val_loss: 1.1919 - val_acc: 0.9758 - val_mDice: 0.7180

Epoch 00103: val_mDice did not improve from 0.72383
Epoch 104/300
 - 15s - loss: 1.5633 - acc: 0.9560 - mDice: 0.6658 - val_loss: 1.2038 - val_acc: 0.9750 - val_mDice: 0.7198

Epoch 00104: val_mDice did not improve from 0.72383
Epoch 105/300
 - 16s - loss: 1.5590 - acc: 0.9560 - mDice: 0.6666 - val_loss: 1.2175 - val_acc: 0.9752 - val_mDice: 0.7167

Epoch 00105: val_mDice did not improve from 0.72383
Epoch 106/300
 - 14s - loss: 1.5584 - acc: 0.9561 - mDice: 0.6671 - val_loss: 1.1895 - val_acc: 0.9757 - val_mDice: 0.7217

Epoch 00106: val_mDice did not improve from 0.72383
Epoch 107/300
 - 15s - loss: 1.5579 - acc: 0.9561 - mDice: 0.6672 - val_loss: 1.1623 - val_acc: 0.9757 - val_mDice: 0.7215

Epoch 00107: val_mDice did not improve from 0.72383
Epoch 108/300
 - 16s - loss: 1.5515 - acc: 0.9562 - mDice: 0.6681 - val_loss: 1.1939 - val_acc: 0.9757 - val_mDice: 0.7204

Epoch 00108: val_mDice did not improve from 0.72383
Epoch 109/300
 - 14s - loss: 1.5495 - acc: 0.9562 - mDice: 0.6686 - val_loss: 1.2236 - val_acc: 0.9754 - val_mDice: 0.7209

Epoch 00109: val_mDice did not improve from 0.72383
Epoch 110/300
 - 15s - loss: 1.5513 - acc: 0.9562 - mDice: 0.6689 - val_loss: 1.1996 - val_acc: 0.9752 - val_mDice: 0.7156

Epoch 00110: val_mDice did not improve from 0.72383
Epoch 111/300
 - 14s - loss: 1.5479 - acc: 0.9562 - mDice: 0.6691 - val_loss: 1.1828 - val_acc: 0.9754 - val_mDice: 0.7231

Epoch 00111: val_mDice did not improve from 0.72383
Epoch 112/300
 - 14s - loss: 1.5499 - acc: 0.9562 - mDice: 0.6687 - val_loss: 1.1885 - val_acc: 0.9754 - val_mDice: 0.7231

Epoch 00112: val_mDice did not improve from 0.72383
Epoch 113/300
 - 14s - loss: 1.5460 - acc: 0.9563 - mDice: 0.6693 - val_loss: 1.1868 - val_acc: 0.9756 - val_mDice: 0.7213

Epoch 00113: val_mDice did not improve from 0.72383
Epoch 114/300
 - 15s - loss: 1.5435 - acc: 0.9563 - mDice: 0.6699 - val_loss: 1.1664 - val_acc: 0.9757 - val_mDice: 0.7234

Epoch 00114: val_mDice did not improve from 0.72383
Epoch 115/300
 - 14s - loss: 1.5448 - acc: 0.9563 - mDice: 0.6699 - val_loss: 1.1807 - val_acc: 0.9757 - val_mDice: 0.7239

Epoch 00115: val_mDice improved from 0.72383 to 0.72390, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 116/300
 - 14s - loss: 1.5374 - acc: 0.9565 - mDice: 0.6711 - val_loss: 1.1843 - val_acc: 0.9756 - val_mDice: 0.7234

Epoch 00116: val_mDice did not improve from 0.72390
Epoch 117/300
 - 14s - loss: 1.5385 - acc: 0.9564 - mDice: 0.6710 - val_loss: 1.1880 - val_acc: 0.9751 - val_mDice: 0.7191

Epoch 00117: val_mDice did not improve from 0.72390
Epoch 118/300
 - 15s - loss: 1.5358 - acc: 0.9565 - mDice: 0.6713 - val_loss: 1.1782 - val_acc: 0.9753 - val_mDice: 0.7268

Epoch 00118: val_mDice improved from 0.72390 to 0.72681, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 119/300
 - 15s - loss: 1.5346 - acc: 0.9565 - mDice: 0.6718 - val_loss: 1.1854 - val_acc: 0.9755 - val_mDice: 0.7194

Epoch 00119: val_mDice did not improve from 0.72681
Epoch 120/300
 - 14s - loss: 1.5387 - acc: 0.9564 - mDice: 0.6712 - val_loss: 1.1810 - val_acc: 0.9760 - val_mDice: 0.7260

Epoch 00120: val_mDice did not improve from 0.72681
Epoch 121/300
 - 14s - loss: 1.5354 - acc: 0.9565 - mDice: 0.6717 - val_loss: 1.1676 - val_acc: 0.9760 - val_mDice: 0.7281

Epoch 00121: val_mDice improved from 0.72681 to 0.72807, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 122/300
 - 15s - loss: 1.5294 - acc: 0.9565 - mDice: 0.6731 - val_loss: 1.1595 - val_acc: 0.9760 - val_mDice: 0.7302

Epoch 00122: val_mDice improved from 0.72807 to 0.73024, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 123/300
 - 15s - loss: 1.5255 - acc: 0.9566 - mDice: 0.6737 - val_loss: 1.1667 - val_acc: 0.9759 - val_mDice: 0.7258

Epoch 00123: val_mDice did not improve from 0.73024
Epoch 124/300
 - 14s - loss: 1.5250 - acc: 0.9566 - mDice: 0.6739 - val_loss: 1.1667 - val_acc: 0.9759 - val_mDice: 0.7250

Epoch 00124: val_mDice did not improve from 0.73024
Epoch 125/300
 - 14s - loss: 1.5330 - acc: 0.9565 - mDice: 0.6724 - val_loss: 1.1731 - val_acc: 0.9756 - val_mDice: 0.7215

Epoch 00125: val_mDice did not improve from 0.73024
Epoch 126/300
 - 14s - loss: 1.5255 - acc: 0.9566 - mDice: 0.6735 - val_loss: 1.1721 - val_acc: 0.9753 - val_mDice: 0.7257

Epoch 00126: val_mDice did not improve from 0.73024
Epoch 127/300
 - 15s - loss: 1.5270 - acc: 0.9565 - mDice: 0.6734 - val_loss: 1.1965 - val_acc: 0.9750 - val_mDice: 0.7211

Epoch 00127: val_mDice did not improve from 0.73024
Epoch 128/300
 - 15s - loss: 1.5226 - acc: 0.9566 - mDice: 0.6743 - val_loss: 1.1712 - val_acc: 0.9759 - val_mDice: 0.7263

Epoch 00128: val_mDice did not improve from 0.73024
Epoch 129/300
 - 14s - loss: 1.5192 - acc: 0.9567 - mDice: 0.6747 - val_loss: 1.1918 - val_acc: 0.9758 - val_mDice: 0.7219

Epoch 00129: val_mDice did not improve from 0.73024
Epoch 130/300
 - 14s - loss: 1.5190 - acc: 0.9568 - mDice: 0.6753 - val_loss: 1.1597 - val_acc: 0.9758 - val_mDice: 0.7265

Epoch 00130: val_mDice did not improve from 0.73024
Epoch 131/300
 - 14s - loss: 1.5208 - acc: 0.9567 - mDice: 0.6748 - val_loss: 1.1757 - val_acc: 0.9757 - val_mDice: 0.7245

Epoch 00131: val_mDice did not improve from 0.73024
Epoch 132/300
 - 14s - loss: 1.5184 - acc: 0.9568 - mDice: 0.6753 - val_loss: 1.1773 - val_acc: 0.9761 - val_mDice: 0.7241

Epoch 00132: val_mDice did not improve from 0.73024
Epoch 133/300
 - 15s - loss: 1.5175 - acc: 0.9568 - mDice: 0.6752 - val_loss: 1.1832 - val_acc: 0.9756 - val_mDice: 0.7224

Epoch 00133: val_mDice did not improve from 0.73024
Epoch 134/300
 - 15s - loss: 1.5183 - acc: 0.9568 - mDice: 0.6753 - val_loss: 1.1576 - val_acc: 0.9760 - val_mDice: 0.7274

Epoch 00134: val_mDice did not improve from 0.73024
Epoch 135/300
 - 14s - loss: 1.5154 - acc: 0.9568 - mDice: 0.6755 - val_loss: 1.1753 - val_acc: 0.9757 - val_mDice: 0.7215

Epoch 00135: val_mDice did not improve from 0.73024
Epoch 136/300
 - 14s - loss: 1.5123 - acc: 0.9568 - mDice: 0.6762 - val_loss: 1.1740 - val_acc: 0.9757 - val_mDice: 0.7265

Epoch 00136: val_mDice did not improve from 0.73024
Epoch 137/300
 - 14s - loss: 1.5099 - acc: 0.9569 - mDice: 0.6771 - val_loss: 1.1621 - val_acc: 0.9759 - val_mDice: 0.7296

Epoch 00137: val_mDice did not improve from 0.73024
Epoch 138/300
 - 14s - loss: 1.5131 - acc: 0.9568 - mDice: 0.6762 - val_loss: 1.1853 - val_acc: 0.9757 - val_mDice: 0.7230

Epoch 00138: val_mDice did not improve from 0.73024
Epoch 139/300
 - 14s - loss: 1.5105 - acc: 0.9568 - mDice: 0.6769 - val_loss: 1.1832 - val_acc: 0.9758 - val_mDice: 0.7238

Epoch 00139: val_mDice did not improve from 0.73024
Epoch 140/300
 - 16s - loss: 1.5116 - acc: 0.9569 - mDice: 0.6764 - val_loss: 1.1622 - val_acc: 0.9756 - val_mDice: 0.7246

Epoch 00140: val_mDice did not improve from 0.73024
Epoch 141/300
 - 14s - loss: 1.5085 - acc: 0.9569 - mDice: 0.6775 - val_loss: 1.1569 - val_acc: 0.9758 - val_mDice: 0.7263

Epoch 00141: val_mDice did not improve from 0.73024
Epoch 142/300
 - 15s - loss: 1.5040 - acc: 0.9570 - mDice: 0.6780 - val_loss: 1.1567 - val_acc: 0.9757 - val_mDice: 0.7271

Epoch 00142: val_mDice did not improve from 0.73024
Epoch 143/300
 - 15s - loss: 1.5068 - acc: 0.9569 - mDice: 0.6773 - val_loss: 1.1457 - val_acc: 0.9760 - val_mDice: 0.7302

Epoch 00143: val_mDice did not improve from 0.73024
Epoch 144/300
 - 14s - loss: 1.5071 - acc: 0.9569 - mDice: 0.6778 - val_loss: 1.1556 - val_acc: 0.9758 - val_mDice: 0.7307

Epoch 00144: val_mDice improved from 0.73024 to 0.73068, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 145/300
 - 14s - loss: 1.5040 - acc: 0.9569 - mDice: 0.6778 - val_loss: 1.1640 - val_acc: 0.9759 - val_mDice: 0.7291

Epoch 00145: val_mDice did not improve from 0.73068
Epoch 146/300
 - 14s - loss: 1.5062 - acc: 0.9569 - mDice: 0.6777 - val_loss: 1.1590 - val_acc: 0.9760 - val_mDice: 0.7285

Epoch 00146: val_mDice did not improve from 0.73068
Epoch 147/300
 - 15s - loss: 1.5010 - acc: 0.9570 - mDice: 0.6784 - val_loss: 1.1527 - val_acc: 0.9759 - val_mDice: 0.7289

Epoch 00147: val_mDice did not improve from 0.73068
Epoch 148/300
 - 15s - loss: 1.5009 - acc: 0.9571 - mDice: 0.6789 - val_loss: 1.1544 - val_acc: 0.9760 - val_mDice: 0.7302

Epoch 00148: val_mDice did not improve from 0.73068
Epoch 149/300
 - 14s - loss: 1.4985 - acc: 0.9571 - mDice: 0.6791 - val_loss: 1.1607 - val_acc: 0.9759 - val_mDice: 0.7258

Epoch 00149: val_mDice did not improve from 0.73068
Epoch 150/300
 - 14s - loss: 1.4975 - acc: 0.9571 - mDice: 0.6794 - val_loss: 1.1642 - val_acc: 0.9758 - val_mDice: 0.7291

Epoch 00150: val_mDice did not improve from 0.73068
Epoch 151/300
 - 14s - loss: 1.4937 - acc: 0.9571 - mDice: 0.6803 - val_loss: 1.1469 - val_acc: 0.9760 - val_mDice: 0.7283

Epoch 00151: val_mDice did not improve from 0.73068
Epoch 152/300
 - 14s - loss: 1.4988 - acc: 0.9570 - mDice: 0.6788 - val_loss: 1.1577 - val_acc: 0.9761 - val_mDice: 0.7298

Epoch 00152: val_mDice did not improve from 0.73068
Epoch 153/300
 - 15s - loss: 1.4939 - acc: 0.9571 - mDice: 0.6799 - val_loss: 1.1415 - val_acc: 0.9759 - val_mDice: 0.7337

Epoch 00153: val_mDice improved from 0.73068 to 0.73375, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 154/300
 - 16s - loss: 1.4954 - acc: 0.9571 - mDice: 0.6800 - val_loss: 1.1565 - val_acc: 0.9759 - val_mDice: 0.7309

Epoch 00154: val_mDice did not improve from 0.73375
Epoch 155/300
 - 15s - loss: 1.4893 - acc: 0.9572 - mDice: 0.6811 - val_loss: 1.1615 - val_acc: 0.9755 - val_mDice: 0.7304

Epoch 00155: val_mDice did not improve from 0.73375
Epoch 156/300
 - 15s - loss: 1.4936 - acc: 0.9571 - mDice: 0.6801 - val_loss: 1.1518 - val_acc: 0.9760 - val_mDice: 0.7292

Epoch 00156: val_mDice did not improve from 0.73375
Epoch 157/300
 - 15s - loss: 1.4889 - acc: 0.9572 - mDice: 0.6812 - val_loss: 1.1658 - val_acc: 0.9758 - val_mDice: 0.7290

Epoch 00157: val_mDice did not improve from 0.73375
Epoch 158/300
 - 15s - loss: 1.4946 - acc: 0.9571 - mDice: 0.6801 - val_loss: 1.1520 - val_acc: 0.9762 - val_mDice: 0.7268

Epoch 00158: val_mDice did not improve from 0.73375
Epoch 159/300
 - 15s - loss: 1.4931 - acc: 0.9572 - mDice: 0.6802 - val_loss: 1.1421 - val_acc: 0.9761 - val_mDice: 0.7325

Epoch 00159: val_mDice did not improve from 0.73375
Epoch 160/300
 - 15s - loss: 1.4942 - acc: 0.9570 - mDice: 0.6803 - val_loss: 1.1678 - val_acc: 0.9761 - val_mDice: 0.7323

Epoch 00160: val_mDice did not improve from 0.73375
Epoch 161/300
 - 17s - loss: 1.4872 - acc: 0.9571 - mDice: 0.6814 - val_loss: 1.1625 - val_acc: 0.9754 - val_mDice: 0.7312

Epoch 00161: val_mDice did not improve from 0.73375
Epoch 162/300
 - 15s - loss: 1.4883 - acc: 0.9572 - mDice: 0.6812 - val_loss: 1.1578 - val_acc: 0.9755 - val_mDice: 0.7306

Epoch 00162: val_mDice did not improve from 0.73375
Epoch 163/300
 - 15s - loss: 1.4853 - acc: 0.9572 - mDice: 0.6819 - val_loss: 1.1574 - val_acc: 0.9758 - val_mDice: 0.7327

Epoch 00163: val_mDice did not improve from 0.73375
Epoch 164/300
 - 15s - loss: 1.4862 - acc: 0.9572 - mDice: 0.6817 - val_loss: 1.1539 - val_acc: 0.9756 - val_mDice: 0.7305

Epoch 00164: val_mDice did not improve from 0.73375
Epoch 165/300
 - 15s - loss: 1.4845 - acc: 0.9572 - mDice: 0.6821 - val_loss: 1.1637 - val_acc: 0.9760 - val_mDice: 0.7297

Epoch 00165: val_mDice did not improve from 0.73375
Epoch 166/300
 - 15s - loss: 1.4833 - acc: 0.9572 - mDice: 0.6824 - val_loss: 1.1866 - val_acc: 0.9756 - val_mDice: 0.7256

Epoch 00166: val_mDice did not improve from 0.73375
Epoch 167/300
 - 16s - loss: 1.4853 - acc: 0.9572 - mDice: 0.6821 - val_loss: 1.1564 - val_acc: 0.9762 - val_mDice: 0.7303

Epoch 00167: val_mDice did not improve from 0.73375
Epoch 168/300
 - 15s - loss: 1.4796 - acc: 0.9573 - mDice: 0.6829 - val_loss: 1.1659 - val_acc: 0.9755 - val_mDice: 0.7296

Epoch 00168: val_mDice did not improve from 0.73375
Epoch 169/300
 - 15s - loss: 1.4807 - acc: 0.9573 - mDice: 0.6824 - val_loss: 1.1587 - val_acc: 0.9756 - val_mDice: 0.7349

Epoch 00169: val_mDice improved from 0.73375 to 0.73495, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 170/300
 - 15s - loss: 1.4790 - acc: 0.9574 - mDice: 0.6835 - val_loss: 1.1410 - val_acc: 0.9762 - val_mDice: 0.7324

Epoch 00170: val_mDice did not improve from 0.73495
Epoch 171/300
 - 15s - loss: 1.4787 - acc: 0.9573 - mDice: 0.6835 - val_loss: 1.1489 - val_acc: 0.9762 - val_mDice: 0.7338

Epoch 00171: val_mDice did not improve from 0.73495
Epoch 172/300
 - 16s - loss: 1.4811 - acc: 0.9573 - mDice: 0.6824 - val_loss: 1.1479 - val_acc: 0.9762 - val_mDice: 0.7353

Epoch 00172: val_mDice improved from 0.73495 to 0.73529, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 173/300
 - 15s - loss: 1.4841 - acc: 0.9572 - mDice: 0.6820 - val_loss: 1.1674 - val_acc: 0.9755 - val_mDice: 0.7324

Epoch 00173: val_mDice did not improve from 0.73529
Epoch 174/300
 - 15s - loss: 1.4759 - acc: 0.9574 - mDice: 0.6840 - val_loss: 1.1547 - val_acc: 0.9760 - val_mDice: 0.7326

Epoch 00174: val_mDice did not improve from 0.73529
Epoch 175/300
 - 15s - loss: 1.4752 - acc: 0.9574 - mDice: 0.6840 - val_loss: 1.1507 - val_acc: 0.9761 - val_mDice: 0.7334

Epoch 00175: val_mDice did not improve from 0.73529
Epoch 176/300
 - 15s - loss: 1.4744 - acc: 0.9574 - mDice: 0.6839 - val_loss: 1.1443 - val_acc: 0.9761 - val_mDice: 0.7319

Epoch 00176: val_mDice did not improve from 0.73529
Epoch 177/300
 - 15s - loss: 1.4777 - acc: 0.9574 - mDice: 0.6833 - val_loss: 1.1358 - val_acc: 0.9762 - val_mDice: 0.7390

Epoch 00177: val_mDice improved from 0.73529 to 0.73897, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 178/300
 - 16s - loss: 1.4742 - acc: 0.9574 - mDice: 0.6841 - val_loss: 1.1482 - val_acc: 0.9760 - val_mDice: 0.7316

Epoch 00178: val_mDice did not improve from 0.73897
Epoch 179/300
 - 15s - loss: 1.4742 - acc: 0.9574 - mDice: 0.6839 - val_loss: 1.1662 - val_acc: 0.9758 - val_mDice: 0.7329

Epoch 00179: val_mDice did not improve from 0.73897
Epoch 180/300
 - 15s - loss: 1.4716 - acc: 0.9574 - mDice: 0.6846 - val_loss: 1.1462 - val_acc: 0.9758 - val_mDice: 0.7333

Epoch 00180: val_mDice did not improve from 0.73897
Epoch 181/300
 - 15s - loss: 1.4719 - acc: 0.9574 - mDice: 0.6852 - val_loss: 1.1733 - val_acc: 0.9761 - val_mDice: 0.7325

Epoch 00181: val_mDice did not improve from 0.73897
Epoch 182/300
 - 15s - loss: 1.4705 - acc: 0.9575 - mDice: 0.6847 - val_loss: 1.1540 - val_acc: 0.9758 - val_mDice: 0.7327

Epoch 00182: val_mDice did not improve from 0.73897
Epoch 183/300
 - 16s - loss: 1.4714 - acc: 0.9574 - mDice: 0.6848 - val_loss: 1.1418 - val_acc: 0.9760 - val_mDice: 0.7330

Epoch 00183: val_mDice did not improve from 0.73897
Epoch 184/300
 - 16s - loss: 1.4674 - acc: 0.9575 - mDice: 0.6856 - val_loss: 1.1605 - val_acc: 0.9759 - val_mDice: 0.7323

Epoch 00184: val_mDice did not improve from 0.73897
Epoch 185/300
 - 14s - loss: 1.4679 - acc: 0.9575 - mDice: 0.6855 - val_loss: 1.1375 - val_acc: 0.9762 - val_mDice: 0.7327

Epoch 00185: val_mDice did not improve from 0.73897
Epoch 186/300
 - 14s - loss: 1.4696 - acc: 0.9574 - mDice: 0.6850 - val_loss: 1.1629 - val_acc: 0.9758 - val_mDice: 0.7323

Epoch 00186: val_mDice did not improve from 0.73897
Epoch 187/300
 - 14s - loss: 1.4657 - acc: 0.9575 - mDice: 0.6859 - val_loss: 1.1612 - val_acc: 0.9758 - val_mDice: 0.7329

Epoch 00187: val_mDice did not improve from 0.73897
Epoch 188/300
 - 14s - loss: 1.4662 - acc: 0.9575 - mDice: 0.6863 - val_loss: 1.1513 - val_acc: 0.9761 - val_mDice: 0.7347

Epoch 00188: val_mDice did not improve from 0.73897
Epoch 189/300
 - 15s - loss: 1.4658 - acc: 0.9575 - mDice: 0.6860 - val_loss: 1.1465 - val_acc: 0.9759 - val_mDice: 0.7343

Epoch 00189: val_mDice did not improve from 0.73897
Epoch 190/300
 - 15s - loss: 1.4650 - acc: 0.9575 - mDice: 0.6864 - val_loss: 1.1662 - val_acc: 0.9759 - val_mDice: 0.7327

Epoch 00190: val_mDice did not improve from 0.73897
Epoch 191/300
 - 14s - loss: 1.4599 - acc: 0.9576 - mDice: 0.6869 - val_loss: 1.1362 - val_acc: 0.9761 - val_mDice: 0.7341

Epoch 00191: val_mDice did not improve from 0.73897
Epoch 192/300
 - 14s - loss: 1.4645 - acc: 0.9575 - mDice: 0.6859 - val_loss: 1.1363 - val_acc: 0.9761 - val_mDice: 0.7362

Epoch 00192: val_mDice did not improve from 0.73897
Epoch 193/300
 - 14s - loss: 1.4613 - acc: 0.9576 - mDice: 0.6870 - val_loss: 1.1441 - val_acc: 0.9759 - val_mDice: 0.7326

Epoch 00193: val_mDice did not improve from 0.73897
Epoch 194/300
 - 14s - loss: 1.4648 - acc: 0.9575 - mDice: 0.6862 - val_loss: 1.1459 - val_acc: 0.9756 - val_mDice: 0.7380

Epoch 00194: val_mDice did not improve from 0.73897
Epoch 195/300
 - 14s - loss: 1.4639 - acc: 0.9576 - mDice: 0.6865 - val_loss: 1.1369 - val_acc: 0.9763 - val_mDice: 0.7356

Epoch 00195: val_mDice did not improve from 0.73897
Epoch 196/300
 - 15s - loss: 1.4637 - acc: 0.9575 - mDice: 0.6864 - val_loss: 1.1337 - val_acc: 0.9762 - val_mDice: 0.7366

Epoch 00196: val_mDice did not improve from 0.73897
Epoch 197/300
 - 15s - loss: 1.4611 - acc: 0.9576 - mDice: 0.6867 - val_loss: 1.1428 - val_acc: 0.9759 - val_mDice: 0.7333

Epoch 00197: val_mDice did not improve from 0.73897
Epoch 198/300
 - 14s - loss: 1.4597 - acc: 0.9576 - mDice: 0.6874 - val_loss: 1.1284 - val_acc: 0.9759 - val_mDice: 0.7355

Epoch 00198: val_mDice did not improve from 0.73897
Epoch 199/300
 - 14s - loss: 1.4609 - acc: 0.9576 - mDice: 0.6868 - val_loss: 1.1343 - val_acc: 0.9762 - val_mDice: 0.7326

Epoch 00199: val_mDice did not improve from 0.73897
Epoch 200/300
 - 14s - loss: 1.4587 - acc: 0.9576 - mDice: 0.6873 - val_loss: 1.1396 - val_acc: 0.9760 - val_mDice: 0.7377

Epoch 00200: val_mDice did not improve from 0.73897
Epoch 201/300
 - 14s - loss: 1.4598 - acc: 0.9576 - mDice: 0.6874 - val_loss: 1.1678 - val_acc: 0.9755 - val_mDice: 0.7324

Epoch 00201: val_mDice did not improve from 0.73897
Epoch 202/300
 - 15s - loss: 1.4566 - acc: 0.9577 - mDice: 0.6874 - val_loss: 1.1498 - val_acc: 0.9760 - val_mDice: 0.7328

Epoch 00202: val_mDice did not improve from 0.73897
Epoch 203/300
 - 14s - loss: 1.4559 - acc: 0.9577 - mDice: 0.6880 - val_loss: 1.1382 - val_acc: 0.9763 - val_mDice: 0.7357

Epoch 00203: val_mDice did not improve from 0.73897
Epoch 204/300
 - 14s - loss: 1.4554 - acc: 0.9577 - mDice: 0.6882 - val_loss: 1.1385 - val_acc: 0.9757 - val_mDice: 0.7361

Epoch 00204: val_mDice did not improve from 0.73897
Epoch 205/300
 - 14s - loss: 1.4566 - acc: 0.9576 - mDice: 0.6878 - val_loss: 1.1317 - val_acc: 0.9760 - val_mDice: 0.7345

Epoch 00205: val_mDice did not improve from 0.73897
Epoch 206/300
 - 14s - loss: 1.4560 - acc: 0.9577 - mDice: 0.6879 - val_loss: 1.1608 - val_acc: 0.9758 - val_mDice: 0.7348

Epoch 00206: val_mDice did not improve from 0.73897
Epoch 207/300
 - 16s - loss: 1.4542 - acc: 0.9577 - mDice: 0.6883 - val_loss: 1.1281 - val_acc: 0.9760 - val_mDice: 0.7392

Epoch 00207: val_mDice improved from 0.73897 to 0.73920, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 208/300
 - 14s - loss: 1.4523 - acc: 0.9577 - mDice: 0.6889 - val_loss: 1.1508 - val_acc: 0.9758 - val_mDice: 0.7347

Epoch 00208: val_mDice did not improve from 0.73920
Epoch 209/300
 - 16s - loss: 1.4526 - acc: 0.9577 - mDice: 0.6885 - val_loss: 1.1233 - val_acc: 0.9763 - val_mDice: 0.7397

Epoch 00209: val_mDice improved from 0.73920 to 0.73971, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 210/300
 - 14s - loss: 1.4545 - acc: 0.9577 - mDice: 0.6881 - val_loss: 1.1529 - val_acc: 0.9758 - val_mDice: 0.7380

Epoch 00210: val_mDice did not improve from 0.73971
Epoch 211/300
 - 15s - loss: 1.4549 - acc: 0.9577 - mDice: 0.6886 - val_loss: 1.1350 - val_acc: 0.9760 - val_mDice: 0.7333

Epoch 00211: val_mDice did not improve from 0.73971
Epoch 212/300
 - 15s - loss: 1.4487 - acc: 0.9578 - mDice: 0.6892 - val_loss: 1.1250 - val_acc: 0.9761 - val_mDice: 0.7376

Epoch 00212: val_mDice did not improve from 0.73971
Epoch 213/300
 - 15s - loss: 1.4495 - acc: 0.9578 - mDice: 0.6892 - val_loss: 1.1362 - val_acc: 0.9761 - val_mDice: 0.7372

Epoch 00213: val_mDice did not improve from 0.73971
Epoch 214/300
 - 15s - loss: 1.4550 - acc: 0.9577 - mDice: 0.6880 - val_loss: 1.1533 - val_acc: 0.9760 - val_mDice: 0.7368

Epoch 00214: val_mDice did not improve from 0.73971
Epoch 215/300
 - 15s - loss: 1.4472 - acc: 0.9578 - mDice: 0.6900 - val_loss: 1.1319 - val_acc: 0.9761 - val_mDice: 0.7353

Epoch 00215: val_mDice did not improve from 0.73971
Epoch 216/300
 - 15s - loss: 1.4498 - acc: 0.9578 - mDice: 0.6893 - val_loss: 1.1415 - val_acc: 0.9762 - val_mDice: 0.7369

Epoch 00216: val_mDice did not improve from 0.73971
Epoch 217/300
 - 14s - loss: 1.4504 - acc: 0.9578 - mDice: 0.6894 - val_loss: 1.1326 - val_acc: 0.9761 - val_mDice: 0.7384

Epoch 00217: val_mDice did not improve from 0.73971
Epoch 218/300
 - 16s - loss: 1.4519 - acc: 0.9577 - mDice: 0.6890 - val_loss: 1.1383 - val_acc: 0.9760 - val_mDice: 0.7357

Epoch 00218: val_mDice did not improve from 0.73971
Epoch 219/300
 - 14s - loss: 1.4505 - acc: 0.9577 - mDice: 0.6892 - val_loss: 1.1543 - val_acc: 0.9759 - val_mDice: 0.7337

Epoch 00219: val_mDice did not improve from 0.73971
Epoch 220/300
 - 16s - loss: 1.4476 - acc: 0.9578 - mDice: 0.6894 - val_loss: 1.1400 - val_acc: 0.9759 - val_mDice: 0.7418

Epoch 00220: val_mDice improved from 0.73971 to 0.74182, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 221/300
 - 14s - loss: 1.4480 - acc: 0.9578 - mDice: 0.6901 - val_loss: 1.1389 - val_acc: 0.9760 - val_mDice: 0.7381

Epoch 00221: val_mDice did not improve from 0.74182
Epoch 222/300
 - 16s - loss: 1.4412 - acc: 0.9579 - mDice: 0.6908 - val_loss: 1.1350 - val_acc: 0.9762 - val_mDice: 0.7398

Epoch 00222: val_mDice did not improve from 0.74182
Epoch 223/300
 - 14s - loss: 1.4489 - acc: 0.9577 - mDice: 0.6894 - val_loss: 1.1347 - val_acc: 0.9758 - val_mDice: 0.7373

Epoch 00223: val_mDice did not improve from 0.74182
Epoch 224/300
 - 15s - loss: 1.4481 - acc: 0.9578 - mDice: 0.6894 - val_loss: 1.1267 - val_acc: 0.9758 - val_mDice: 0.7363

Epoch 00224: val_mDice did not improve from 0.74182
Epoch 225/300
 - 15s - loss: 1.4437 - acc: 0.9578 - mDice: 0.6906 - val_loss: 1.1331 - val_acc: 0.9759 - val_mDice: 0.7383

Epoch 00225: val_mDice did not improve from 0.74182
Epoch 226/300
 - 14s - loss: 1.4458 - acc: 0.9578 - mDice: 0.6903 - val_loss: 1.1521 - val_acc: 0.9763 - val_mDice: 0.7381

Epoch 00226: val_mDice did not improve from 0.74182
Epoch 227/300
 - 16s - loss: 1.4452 - acc: 0.9579 - mDice: 0.6901 - val_loss: 1.1366 - val_acc: 0.9754 - val_mDice: 0.7372

Epoch 00227: val_mDice did not improve from 0.74182
Epoch 228/300
 - 14s - loss: 1.4451 - acc: 0.9579 - mDice: 0.6903 - val_loss: 1.1261 - val_acc: 0.9763 - val_mDice: 0.7376

Epoch 00228: val_mDice did not improve from 0.74182
Epoch 229/300
 - 16s - loss: 1.4415 - acc: 0.9578 - mDice: 0.6910 - val_loss: 1.1423 - val_acc: 0.9758 - val_mDice: 0.7392

Epoch 00229: val_mDice did not improve from 0.74182
Epoch 230/300
 - 15s - loss: 1.4419 - acc: 0.9579 - mDice: 0.6909 - val_loss: 1.1398 - val_acc: 0.9763 - val_mDice: 0.7372

Epoch 00230: val_mDice did not improve from 0.74182
Epoch 231/300
 - 16s - loss: 1.4436 - acc: 0.9578 - mDice: 0.6907 - val_loss: 1.1490 - val_acc: 0.9761 - val_mDice: 0.7341

Epoch 00231: val_mDice did not improve from 0.74182
Epoch 232/300
 - 15s - loss: 1.4409 - acc: 0.9578 - mDice: 0.6910 - val_loss: 1.1404 - val_acc: 0.9763 - val_mDice: 0.7354

Epoch 00232: val_mDice did not improve from 0.74182
Epoch 233/300
 - 15s - loss: 1.4429 - acc: 0.9579 - mDice: 0.6908 - val_loss: 1.1280 - val_acc: 0.9758 - val_mDice: 0.7379

Epoch 00233: val_mDice did not improve from 0.74182
Epoch 234/300
 - 15s - loss: 1.4396 - acc: 0.9579 - mDice: 0.6914 - val_loss: 1.1196 - val_acc: 0.9763 - val_mDice: 0.7364

Epoch 00234: val_mDice did not improve from 0.74182
Epoch 235/300
 - 15s - loss: 1.4390 - acc: 0.9579 - mDice: 0.6915 - val_loss: 1.1261 - val_acc: 0.9765 - val_mDice: 0.7397

Epoch 00235: val_mDice did not improve from 0.74182
Epoch 236/300
 - 15s - loss: 1.4377 - acc: 0.9580 - mDice: 0.6918 - val_loss: 1.1412 - val_acc: 0.9762 - val_mDice: 0.7365

Epoch 00236: val_mDice did not improve from 0.74182
Epoch 237/300
 - 15s - loss: 1.4409 - acc: 0.9579 - mDice: 0.6914 - val_loss: 1.1460 - val_acc: 0.9761 - val_mDice: 0.7386

Epoch 00237: val_mDice did not improve from 0.74182
Epoch 238/300
 - 15s - loss: 1.4392 - acc: 0.9579 - mDice: 0.6915 - val_loss: 1.1299 - val_acc: 0.9761 - val_mDice: 0.7402

Epoch 00238: val_mDice did not improve from 0.74182
Epoch 239/300
 - 15s - loss: 1.4423 - acc: 0.9579 - mDice: 0.6907 - val_loss: 1.1384 - val_acc: 0.9758 - val_mDice: 0.7402

Epoch 00239: val_mDice did not improve from 0.74182
Epoch 240/300
 - 16s - loss: 1.4397 - acc: 0.9579 - mDice: 0.6917 - val_loss: 1.1379 - val_acc: 0.9760 - val_mDice: 0.7342

Epoch 00240: val_mDice did not improve from 0.74182
Epoch 241/300
 - 17s - loss: 1.4406 - acc: 0.9579 - mDice: 0.6907 - val_loss: 1.1328 - val_acc: 0.9761 - val_mDice: 0.7398

Epoch 00241: val_mDice did not improve from 0.74182
Epoch 242/300
 - 16s - loss: 1.4348 - acc: 0.9580 - mDice: 0.6920 - val_loss: 1.1304 - val_acc: 0.9762 - val_mDice: 0.7386

Epoch 00242: val_mDice did not improve from 0.74182
Epoch 243/300
 - 16s - loss: 1.4371 - acc: 0.9580 - mDice: 0.6923 - val_loss: 1.1242 - val_acc: 0.9761 - val_mDice: 0.7393

Epoch 00243: val_mDice did not improve from 0.74182
Epoch 244/300
 - 16s - loss: 1.4384 - acc: 0.9579 - mDice: 0.6916 - val_loss: 1.1486 - val_acc: 0.9757 - val_mDice: 0.7364

Epoch 00244: val_mDice did not improve from 0.74182
Epoch 245/300
 - 17s - loss: 1.4396 - acc: 0.9579 - mDice: 0.6914 - val_loss: 1.1312 - val_acc: 0.9763 - val_mDice: 0.7415

Epoch 00245: val_mDice did not improve from 0.74182
Epoch 246/300
 - 16s - loss: 1.4341 - acc: 0.9580 - mDice: 0.6928 - val_loss: 1.1264 - val_acc: 0.9761 - val_mDice: 0.7391

Epoch 00246: val_mDice did not improve from 0.74182
Epoch 247/300
 - 17s - loss: 1.4348 - acc: 0.9580 - mDice: 0.6923 - val_loss: 1.1323 - val_acc: 0.9759 - val_mDice: 0.7390

Epoch 00247: val_mDice did not improve from 0.74182
Epoch 248/300
 - 15s - loss: 1.4348 - acc: 0.9580 - mDice: 0.6924 - val_loss: 1.1243 - val_acc: 0.9760 - val_mDice: 0.7413

Epoch 00248: val_mDice did not improve from 0.74182
Epoch 249/300
 - 18s - loss: 1.4304 - acc: 0.9581 - mDice: 0.6930 - val_loss: 1.1516 - val_acc: 0.9765 - val_mDice: 0.7401

Epoch 00249: val_mDice did not improve from 0.74182
Epoch 250/300
 - 16s - loss: 1.4370 - acc: 0.9580 - mDice: 0.6919 - val_loss: 1.1328 - val_acc: 0.9759 - val_mDice: 0.7364

Epoch 00250: val_mDice did not improve from 0.74182
Restoring model weights from the end of the best epoch
Epoch 00250: early stopping
{'val_loss': [9.053437483541156, 5.787866203562865, 5.3844970056168435, 4.7536531219582985, 4.181149310512576, 3.7846202808440466, 3.418215171733514, 3.0568664128415826, 2.8648128283254293, 2.6875585654917415, 2.5125515029384298, 2.2871958392366163, 2.1568367527323153, 2.0748890361802648, 2.02785692378381, 1.936973727440792, 1.8334735380534757, 1.7773150995452291, 1.7166542941949907, 1.6683632124915901, 1.6256018049478111, 1.5977450910896744, 1.5578353486706378, 1.531266156315594, 1.5274844081623902, 1.5128808228957003, 1.4668067842460055, 1.4800475676575109, 1.46088297966285, 1.4454350326936987, 1.4176978071879838, 1.4189135774786736, 1.3917488368827136, 1.4067337261561979, 1.3806305028013688, 1.3784721146987486, 1.365837090254249, 1.3519152979021123, 1.347736323654966, 1.3283694322582706, 1.3316576962730797, 1.333644711279911, 1.3112967042596144, 1.31014095636998, 1.299470772642662, 1.3194411957410601, 1.2982666434847827, 1.2940609371305978, 1.3155837945234168, 1.2847635817234462, 1.2884642220968103, 1.2737918295005504, 1.270431808826165, 1.2981831104558466, 1.2781545180428007, 1.261944861843632, 1.2557109736809622, 1.2544555439890375, 1.2612723567783308, 1.2643635654281857, 1.2410929031237985, 1.2330708569717743, 1.2484810706391696, 1.2450615835944043, 1.2505793408056973, 1.217351099099761, 1.2518538746766759, 1.2326317847508328, 1.249612621242845, 1.2335585884762983, 1.219061206535212, 1.224576222456612, 1.2270613065503393, 1.2295600434598268, 1.2109202390605411, 1.2185995182798282, 1.2296326601442427, 1.2124035420233419, 1.21289913861739, 1.1989744285707524, 1.220949304124802, 1.1907706657696273, 1.2060172440507082, 1.21424579767016, 1.2399863720149693, 1.1875375559543684, 1.206443113161935, 1.1955230993420043, 1.2157570266137014, 1.1980444611899672, 1.2159995441906062, 1.1933745233790527, 1.2260822419122988, 1.1931931210946953, 1.201907041621753, 1.1836503216168583, 1.226481153173061, 1.2141267843740895, 1.192312700572458, 1.2100172031323813, 1.1787033528351407, 1.182717469434118, 1.1918621574428672, 1.203802605085926, 1.217539097701309, 1.1895068943605271, 1.1622629474671737, 1.1939458353657715, 1.2236254542070868, 1.1996271526457345, 1.1828376511488312, 1.1884700830875257, 1.1867793600462861, 1.1663609323057433, 1.180663274335945, 1.1843085231387134, 1.1880193877513463, 1.1782229607679304, 1.1854028663023495, 1.1810383467766439, 1.1675897383103262, 1.159538566856686, 1.166696631636058, 1.1666701784871374, 1.1731202400212548, 1.1720700207410253, 1.196466842833219, 1.1712463304321878, 1.1918374146015656, 1.1597336018441642, 1.1756718418510181, 1.1773204535298272, 1.1832420877287384, 1.1576094624237772, 1.1752943040406976, 1.1739545036074566, 1.1620855047539373, 1.185344168821412, 1.1831864536541836, 1.1622295413159738, 1.1568757541778847, 1.1567334024684082, 1.145657128106102, 1.1555681076745368, 1.1640289268719919, 1.1589554228765893, 1.1527351651124669, 1.154437627754647, 1.1606822536574097, 1.164168556880448, 1.146928455791909, 1.1577290393975161, 1.1415467709564786, 1.1565487216143282, 1.161534469345542, 1.1517882610037793, 1.1657993150302102, 1.1520216965717256, 1.14211212059316, 1.167786973222488, 1.1625247970616253, 1.1578067108491183, 1.1573799127853608, 1.153897761041544, 1.1637064387173979, 1.1865876303406298, 1.1564143746305644, 1.165909053571195, 1.1587456375727125, 1.1409761467801247, 1.1488623205303936, 1.1479397025384885, 1.1674144111953426, 1.1546871358355235, 1.1507073504644034, 1.1443165985896844, 1.135792696203624, 1.1482430169578177, 1.166195630503455, 1.1461521115789095, 1.1732615742616368, 1.1540389726157767, 1.1417683940151664, 1.1604966943419042, 1.137541157185298, 1.1628771957487969, 1.1612210850933524, 1.1513187522837902, 1.146459887233057, 1.1661902237650799, 1.1362216749174523, 1.1363096204709084, 1.144127341272123, 1.1459209540816309, 1.136860303908115, 1.1336856658303676, 1.1427739644930526, 1.1284236727783257, 1.1343379736156163, 1.1396452200014688, 1.1678069343885344, 1.1498231815537585, 1.1381702862012155, 1.1384641367856982, 1.1317220565933335, 1.1608174499811732, 1.1281466446358626, 1.1508467918121124, 1.1232502329538074, 1.1529496552026544, 1.1349901575824288, 1.1249989193646477, 1.1362133702829558, 1.1533464596644436, 1.1318833506379689, 1.141462102401445, 1.1326190422834117, 1.1383072665789424, 1.1542884377477878, 1.1400244249610365, 1.1389097180643064, 1.135015109197117, 1.1347334886686664, 1.1266548036481459, 1.1330832903959211, 1.152062490975291, 1.1365538446890657, 1.1260868078375952, 1.1423471785806814, 1.1397527874249356, 1.149027129992031, 1.1404420698883244, 1.1280490936210579, 1.1195551965693389, 1.1260767671261604, 1.1412089568659376, 1.1459961019207598, 1.1299270201860707, 1.1383948584851564, 1.1378643337787768, 1.1327729174877093, 1.130398123146989, 1.1241591086706084, 1.1486319831469356, 1.1311550939648767, 1.1263792420523029, 1.1323341495751915, 1.1242882867060562, 1.1516315577738314, 1.132801017777991], 'val_acc': [0.911152898532016, 0.911152898532016, 0.911152898532016, 0.9110505350444773, 0.9142221197721618, 0.9185440677540583, 0.9257020884322785, 0.9401896342451836, 0.9361505101979931, 0.9363111737323352, 0.9420038867080568, 0.9544481486343961, 0.9585492727207593, 0.9618202577785364, 0.9630569139976702, 0.9652477492347543, 0.9661421899426801, 0.9672929073679007, 0.9677281586063767, 0.9678794864191951, 0.9678111233484975, 0.968758981236255, 0.969539812034379, 0.9691505097965784, 0.9696216345461894, 0.9698308531345509, 0.9707562851151599, 0.9696220149055307, 0.9704955258981205, 0.9712434747307078, 0.9720822502523399, 0.9720419003171535, 0.9715378961160858, 0.9715532102149065, 0.9711291673732348, 0.9718255678253979, 0.9720512282869309, 0.9724326966517001, 0.9724375543778726, 0.9723829931869239, 0.9728675762253612, 0.9729348278632273, 0.9727917293672612, 0.9724532437031215, 0.9725156347864751, 0.9727921197829221, 0.9722720487256041, 0.972195817737043, 0.972466327813053, 0.9725974323669929, 0.9730203702705397, 0.9734081942293472, 0.9733543963759143, 0.9723482578207193, 0.9736002230057608, 0.9734250093386336, 0.9736630022002021, 0.9736271180042274, 0.97425629751125, 0.9735411930377538, 0.9741531714194688, 0.9744599086538559, 0.9740664908672259, 0.9740758496344822, 0.9743620245234619, 0.9745290135876366, 0.974365379144102, 0.974255171308199, 0.9740093093764803, 0.9742921477671457, 0.9752004054392998, 0.9744516822700969, 0.9745764867492636, 0.9750875793986664, 0.9751141081794913, 0.9752190892432402, 0.9749594190418196, 0.9754787483408078, 0.9751836025861529, 0.974999392493538, 0.9753106274169023, 0.974982963819286, 0.9746018719379848, 0.9750991555844124, 0.9745831926384374, 0.9750886937645911, 0.9742723426835608, 0.9750501940874726, 0.9752762423458334, 0.9754981677226316, 0.9752389001930116, 0.9753913145073688, 0.9749026216815352, 0.9753857185844796, 0.9754821138557943, 0.9753517065400189, 0.9748417422934869, 0.975069650761482, 0.9753012938951985, 0.975311363099539, 0.975546007311407, 0.9757383989533557, 0.9757929602490578, 0.9750404901579939, 0.9751970454762396, 0.9756633199371646, 0.9757174920742457, 0.9756987993662722, 0.9754118640728701, 0.9752104906708997, 0.9753700123939447, 0.9754051482321299, 0.9756498767328179, 0.9757193476747336, 0.9756920773450855, 0.9756386451855276, 0.9750744906795884, 0.9753188370401286, 0.9754645354089921, 0.975967811155403, 0.9760055414193125, 0.97602684080915, 0.9758762747625475, 0.9759394116896108, 0.975599794689507, 0.97533938346303, 0.9750479642033367, 0.9758661781128345, 0.9757570759483297, 0.9758052971534863, 0.9757365338203149, 0.9761086556739673, 0.9756136226528349, 0.9759954430935462, 0.9757290611367653, 0.9757238312220112, 0.9759046646957866, 0.9756973122879994, 0.9757862260764848, 0.9755669072767972, 0.9757922026729752, 0.9757159872926602, 0.9759980652789031, 0.9757813689788323, 0.9758706717164319, 0.9760144976195216, 0.9758841052834724, 0.9760216052377161, 0.9758736375974645, 0.9757705390558092, 0.9760428935237007, 0.9760739120322497, 0.9758852366194365, 0.975922228581876, 0.975452973783959, 0.9760025585682405, 0.9757634422272077, 0.9761949555526089, 0.9760529843072271, 0.9761355507771873, 0.9754481182576064, 0.9755198487288503, 0.9757977995386442, 0.9756136193007283, 0.9759756477520211, 0.9755665452492887, 0.9761605807473663, 0.9754649235200799, 0.9756476197175694, 0.9761770230395513, 0.9761901007595297, 0.9761740407122459, 0.9755318111401241, 0.9760346719585948, 0.9761295676859905, 0.976131827005812, 0.9762031750226482, 0.9759711720612431, 0.9758082695292253, 0.9758183671217182, 0.9761407931575876, 0.9757918468259131, 0.9760492522603389, 0.9759453839912147, 0.9761994483181797, 0.9757525978482251, 0.9758321861810131, 0.9760697927123004, 0.975928565006055, 0.9759117695903946, 0.976058597619169, 0.9760746624851059, 0.9759207275714104, 0.9756438693388485, 0.9763466599536487, 0.9762465152463929, 0.975933050229386, 0.9758867379441621, 0.9761957074720118, 0.975984621027023, 0.9755489897434657, 0.975980135489432, 0.9762950950221981, 0.9757017883977906, 0.9759898517798037, 0.9757634330089147, 0.976018612539831, 0.9757772525919761, 0.9762928416733163, 0.975800422038261, 0.9760294319875211, 0.9760668150988949, 0.9761109076610558, 0.9760253402176976, 0.9761206083431814, 0.9761908454509527, 0.9761486298589589, 0.9760328118537138, 0.9758859811013528, 0.9759330545242725, 0.9759644448023899, 0.9762405384403959, 0.9757944459655373, 0.9757933279332461, 0.9758942017236787, 0.9762887285338135, 0.9754357874288709, 0.9762790127672085, 0.9758026651213165, 0.9762969638216056, 0.976091079426985, 0.9762865004304843, 0.975752611780418, 0.976320121745024, 0.9764908539599401, 0.9762084125843953, 0.9761228493311702, 0.9761015523506593, 0.9758172479371404, 0.9759566012920521, 0.9760727852006789, 0.9762476385163507, 0.976107165243588, 0.9757002917869648, 0.9763372982532991, 0.9761228573971766, 0.9758572035807926, 0.9760223524432191, 0.97645723641652, 0.9759364160586326], 'val_mDice': [0.008054865952188342, 0.04552140482987796, 0.06731670465065012, 0.09714018888706064, 0.1373945338445305, 0.1826796451802832, 0.2345479705840716, 0.2936325235609849, 0.3224997168999355, 0.3525301630760957, 0.39425616099880534, 0.4394564804062902, 0.461992284011338, 0.48484854832265417, 0.49975006159244395, 0.5213574799586265, 0.5413123170185592, 0.5526556735089039, 0.569140174057865, 0.5831835100227584, 0.5936723725447964, 0.6032358814417164, 0.613776760277304, 0.6266300655207441, 0.6239635906655256, 0.6286394119472202, 0.6356072763148007, 0.6428681456979842, 0.6438738380039932, 0.6486098887840767, 0.6549523768190341, 0.6580244788805085, 0.6605930850040724, 0.660748562934319, 0.6648833682541269, 0.6672340836801512, 0.6728498722002669, 0.6743559493750386, 0.6798654468910137, 0.6790208639495192, 0.6779033549012116, 0.6798659847993633, 0.6839329143609648, 0.685698949913568, 0.6878430683080676, 0.6859936696364297, 0.689213385481407, 0.6916831686752333, 0.690402713308016, 0.6972306447205099, 0.6995792717841471, 0.6951260778313152, 0.6953979132464565, 0.6965778611456364, 0.6966108249235237, 0.6992501529532702, 0.7028929749356423, 0.6998002202313898, 0.702217896814296, 0.6984289936943926, 0.7009529345693404, 0.7052069581874855, 0.7054079257750553, 0.7041565791584277, 0.7024679157771628, 0.7064253600913317, 0.705132783402039, 0.7094641531079432, 0.7094867383449065, 0.709448315766239, 0.7077308004895497, 0.7105393732369261, 0.7105587893713966, 0.7123300752656531, 0.7110929195826419, 0.7115957070737815, 0.7082711128233187, 0.712804325330865, 0.715193667814057, 0.717225403484016, 0.7105676857574543, 0.7157574018401295, 0.7155891586690879, 0.7126052848903073, 0.7132287409896382, 0.7202488866966932, 0.7158025784945027, 0.7170063179699943, 0.7201662883817207, 0.714773461563097, 0.7112192977710852, 0.7203359298002112, 0.713977240405728, 0.7185075151061341, 0.7154912939180599, 0.7208971694399896, 0.7119305852427424, 0.7189998344922527, 0.7208642699806468, 0.7185386723080922, 0.7238257814375504, 0.7202406715215405, 0.7180200380474486, 0.7197883885438916, 0.7167460766534185, 0.7216669922344295, 0.7214882767682336, 0.7203689289847242, 0.7209059620154973, 0.7156090621160497, 0.7230516085515751, 0.7230981112783529, 0.7213379685195762, 0.7233841295611041, 0.7239028944491502, 0.7234094647824869, 0.7191054961383867, 0.7268079587361516, 0.7194489379968291, 0.726036273113244, 0.7280655602788674, 0.7302448410141447, 0.7258475906819577, 0.72498020828294, 0.7214952525019855, 0.7256989883412795, 0.7210892162339758, 0.7262962256248889, 0.7219140435354572, 0.7264577160820181, 0.7244567561023894, 0.7240902221056196, 0.7223568778674925, 0.7273789025149152, 0.7214816905073625, 0.7264922594353688, 0.7296129495481615, 0.7229568847243941, 0.7237765364780996, 0.724582008192535, 0.7262719423364462, 0.7270719504314483, 0.7302210548850061, 0.7306838236709889, 0.7290808111167331, 0.728528640706007, 0.7289248147622562, 0.7302480510751895, 0.7258001620404959, 0.7291186722175518, 0.7283016813031818, 0.7297799019486707, 0.7337495654245253, 0.7309078447429074, 0.7304383346611251, 0.7291579485358588, 0.7289885931987126, 0.7267677154398551, 0.732455923603373, 0.732295697518937, 0.7311762380683778, 0.7306341270151792, 0.7326783445681755, 0.7304621524257694, 0.7296553623906757, 0.7255923089117912, 0.7302632537164672, 0.7296321499955256, 0.7349495661489155, 0.7323639135159591, 0.7337900521675605, 0.7352863525045358, 0.7323945479988004, 0.7326177440334917, 0.733432820371249, 0.7319108244614358, 0.7389683855438903, 0.7316193846700899, 0.7328917223875049, 0.7333089181325139, 0.7325394261490901, 0.7327375067348849, 0.7329561463139808, 0.7322510945985523, 0.7326758955400732, 0.732292293454725, 0.7328931747924254, 0.7347346703490809, 0.7342552124720676, 0.7326543259913976, 0.7340590806124709, 0.7361646359540875, 0.7325738111154056, 0.7380132461474105, 0.7355525928348146, 0.7365650937930143, 0.7332844733144361, 0.7355373323696988, 0.7326161483260156, 0.7376871856947566, 0.7324223199921459, 0.7327961602194238, 0.7357033889197298, 0.7360643523439163, 0.7345086718485518, 0.7347726465738093, 0.7392032012369595, 0.7347406083963458, 0.7397053953004847, 0.7379850151249729, 0.7333391126513691, 0.7375752942633336, 0.7372494736958053, 0.7368139813151636, 0.7353292770670671, 0.7369206688106584, 0.7384091003917432, 0.7356564891778312, 0.733712981476306, 0.7418231062185157, 0.738129931195968, 0.7397829859872694, 0.7373355455264475, 0.7363229811924832, 0.7382834192319578, 0.7380682863753374, 0.7372242736062182, 0.7376221156497412, 0.7391896208057505, 0.737193922900148, 0.7340814123463756, 0.7354412212941684, 0.7379448814006597, 0.7363752510090913, 0.7396788092195883, 0.7364967173138905, 0.7385563102464056, 0.7401874859429411, 0.74022103487293, 0.7341869605446533, 0.7398179871126721, 0.738606986345851, 0.7393133354312715, 0.7363992972407484, 0.7415464852522463, 0.7390572943042159, 0.739013349025237, 0.7412602773659678, 0.7401391205972024, 0.7364218179496604], 'loss': [96.79710884745987, 11.001945087374693, 8.311115226737927, 7.157441598420822, 6.296228848695815, 5.679475067690211, 5.21559814089144, 4.81750243912705, 4.480828844074946, 4.249086895620605, 4.036953485820141, 3.829271231460245, 3.654727568702473, 3.5018740625987625, 3.3627149870492725, 3.241260936663247, 3.127554665249647, 3.014301785356799, 2.9140503001341456, 2.82476091810828, 2.733714893691991, 2.6452139820043974, 2.5711405399755023, 2.4948919946489503, 2.4498895588737506, 2.3915345193299378, 2.3457128503507256, 2.2998633291657633, 2.268447351596069, 2.225995229280539, 2.1937033947841984, 2.1658651350032976, 2.1379232356163285, 2.1087457156194533, 2.08721697757615, 2.0608730456662414, 2.0319995668236657, 2.016794051691364, 1.9962614799780465, 1.9795142064594393, 1.9552711117016244, 1.9434705705049022, 1.9340200615687493, 1.9110720386671183, 1.8925696807696903, 1.8765888412683494, 1.8616931965352184, 1.8616756870176572, 1.8367602485432417, 1.8250362746015203, 1.8151064642445982, 1.8068777335967314, 1.797851241820952, 1.790610782387788, 1.7738850732483422, 1.7712210855692299, 1.7598406135702966, 1.7507808720253835, 1.7426916698967707, 1.7393085121190588, 1.7264364655991755, 1.7287978206125505, 1.7194944758952986, 1.7065253643617375, 1.6998443700582018, 1.6970421464386454, 1.6962203215739249, 1.684182720349663, 1.6836836107555522, 1.6761313662076176, 1.6767350723396568, 1.6649936918859352, 1.6620990460618839, 1.663534563372788, 1.655219459658474, 1.6548406626172614, 1.6422267417099987, 1.638826235858095, 1.6375928424749826, 1.6394075821944725, 1.6266932417477606, 1.630695964260494, 1.6207987375020874, 1.6176820159660337, 1.6150522654096504, 1.6094224820180938, 1.6059721713816957, 1.6073958960676593, 1.6082698352611284, 1.5945803365435756, 1.5977829061416704, 1.5923599223354838, 1.588089072898088, 1.5834083597563238, 1.5807736696723507, 1.5823887520842845, 1.5781378461252635, 1.5798003933677003, 1.5787591569365245, 1.5699169001241653, 1.5687116178915044, 1.5698145306300555, 1.5662388885682916, 1.5632611482962047, 1.5590345861387327, 1.5583595384541675, 1.5578678694940478, 1.5514806984931233, 1.5494660740979491, 1.5513069532362829, 1.5479496617866964, 1.5499015192663739, 1.545992734285721, 1.5434930698721994, 1.5448312242451878, 1.537386584069551, 1.538454198254162, 1.5357735559556511, 1.5346215545942161, 1.5386710471808416, 1.5353907708894696, 1.5294356612493034, 1.5254968412448822, 1.5249711902912704, 1.533037274438502, 1.5255360073606774, 1.5269525099530157, 1.5226355793251616, 1.5192400042840695, 1.518953368891876, 1.5208216106565877, 1.5183792182228284, 1.5175253047022124, 1.5183124521719205, 1.5154314136464333, 1.512340256191873, 1.50991106063321, 1.5130714743746034, 1.51047362182684, 1.5116380976626356, 1.5084912857815687, 1.504049861600898, 1.5067610798373532, 1.5070724581731452, 1.5039744465563836, 1.5061584728802344, 1.5010476288291061, 1.5008904986962008, 1.4985231182624539, 1.497515321875739, 1.4936583415952376, 1.4987715601315166, 1.4939457322515604, 1.4953740285786834, 1.4893117449158937, 1.493553154842044, 1.4889495813230476, 1.4946387374198922, 1.4930714545315449, 1.4941562448364518, 1.4871984100696947, 1.4883285593682953, 1.485287974551594, 1.4862439606499405, 1.484537370059386, 1.4832771371915627, 1.4853305596241286, 1.4796489748139607, 1.4807487356303402, 1.4790170599341506, 1.4787043949647156, 1.4811366807172033, 1.4840511504083964, 1.475937186018893, 1.4751890772668388, 1.4744423808128122, 1.4777110458158245, 1.4742485793953928, 1.4742017334501358, 1.4716186203382364, 1.4719396437860017, 1.4705478658818207, 1.4714037312288348, 1.4673875476890335, 1.4679235960371655, 1.469571877723311, 1.4657027262109412, 1.4661898382728349, 1.4657984215206208, 1.46497215250287, 1.4599003896734375, 1.4645112531785427, 1.4612905480146443, 1.464806603087158, 1.4639062678218218, 1.463671768463334, 1.4611458448607575, 1.459724980354861, 1.4608634870189479, 1.4587070235344095, 1.4598458537901362, 1.4566005851564814, 1.4558699789959593, 1.4554443604440648, 1.4566076645691077, 1.4559697591810317, 1.4542227912564671, 1.4522622095957225, 1.4525612143240147, 1.4545474250461439, 1.4549020616171087, 1.4486525029890382, 1.4494984075243331, 1.4550147054599867, 1.4472055437310365, 1.4498283276469854, 1.450446155511477, 1.4518684749424258, 1.4504827665974298, 1.4475882196215222, 1.4479759498725004, 1.4412272221476603, 1.448876712379947, 1.4480746985381685, 1.443729493015816, 1.445808012144392, 1.445211175427416, 1.445082083456194, 1.4415387635135992, 1.441923947316532, 1.4436404833879548, 1.440941303885941, 1.4428919497124653, 1.439585538762582, 1.4390197230611603, 1.4377076415253491, 1.4408549360657583, 1.4391622336843906, 1.4422797060451955, 1.43974074231655, 1.4405562774649467, 1.4348385785421616, 1.4370626519103216, 1.4383909785989295, 1.4396236291991633, 1.4340653194886115, 1.434753869903399, 1.4348081672421387, 1.430434820738516, 1.436952575632529], 'acc': [0.7812257350933917, 0.8915737775898167, 0.8944110664560176, 0.8956658968441464, 0.8987144270790799, 0.9028578812034206, 0.9068403399696732, 0.9113679060721924, 0.9158434672136323, 0.9185662606805015, 0.920736603111525, 0.9232108748065322, 0.9257527386636453, 0.928257306633799, 0.9302488713474196, 0.9320564931846758, 0.9336622042382623, 0.9354038469792972, 0.9369267055009369, 0.9378297519572254, 0.9387027298454478, 0.9398148254547678, 0.9408246530487532, 0.9419757020226914, 0.9424202882777426, 0.9431152580926753, 0.9438094455992699, 0.9442854859611659, 0.9447455745561393, 0.9453740885246803, 0.9459227029783281, 0.946267297337984, 0.9467220130291171, 0.9472586150726334, 0.9474633043668187, 0.9478387620901283, 0.9483014722396189, 0.9485082150159524, 0.9487322555635291, 0.9489336184410029, 0.949252900074931, 0.9493854926094532, 0.9494192474327896, 0.9497661302796512, 0.950158679514117, 0.9504815307916618, 0.9508386914158112, 0.9508725944423728, 0.9512182451129577, 0.951500421744169, 0.9515787031628826, 0.9517803838278097, 0.9518651363354229, 0.9520096384334934, 0.9523627211622716, 0.9524509531761366, 0.9526208836967167, 0.9528052134228535, 0.9528727823532159, 0.952976760662806, 0.9531518459608028, 0.9531147688991692, 0.9532667800396415, 0.9534248463803117, 0.9535917817067503, 0.9536844372695337, 0.9536800315051223, 0.9538908707682209, 0.9540079316959235, 0.9540751831717859, 0.9541255717464461, 0.9542514560393122, 0.9543805180597327, 0.9543112372243406, 0.9544843563399518, 0.9545099037497821, 0.9546544275318128, 0.9546817182912649, 0.9547598493920497, 0.9546955615007597, 0.9548704782733799, 0.9548415602510333, 0.9549287207011073, 0.9549835376240132, 0.9550509591760348, 0.9551543889315197, 0.9551746185577832, 0.9551740209365561, 0.9551461930843924, 0.9553220837454954, 0.9553379055736325, 0.9554585722028972, 0.9555368393736081, 0.955607601233394, 0.9556289755022044, 0.9556182235903795, 0.9557211747899472, 0.9557215765716265, 0.9557424830200147, 0.9558833911418795, 0.9558664433315796, 0.9558601955013842, 0.955935030865157, 0.9560004814444644, 0.956006934148941, 0.956070609502095, 0.956079983209113, 0.9561526889014176, 0.9561829308781756, 0.9562319827472118, 0.9561576610734314, 0.9562029246954942, 0.9562822730916417, 0.9563405043099404, 0.9563296450161681, 0.9564508779210537, 0.9564099386338168, 0.9564635874364668, 0.956455744858819, 0.9564428335586915, 0.956477764334186, 0.9565192845649877, 0.956622338044218, 0.9566190546924698, 0.9565122950347619, 0.9566062066234788, 0.9565209855455487, 0.9566482288279151, 0.9567087712282384, 0.9567738566867275, 0.9566762060231444, 0.9567709390617126, 0.9567709059763504, 0.9567900788327491, 0.9567745425645829, 0.9568284624032397, 0.9569120180276288, 0.9568022502475917, 0.9568327967476625, 0.9568692219916662, 0.9569191448186137, 0.9569576986452383, 0.9569377985137871, 0.9569416264601955, 0.9569400675967129, 0.9568701551218625, 0.957045531895001, 0.9570663916489347, 0.9570779255151473, 0.9571263558803043, 0.9571479647522285, 0.9570215890592456, 0.9571315981374582, 0.9571303562245463, 0.9571903746583178, 0.9571104701041312, 0.957157946543007, 0.9571142555884917, 0.9571650091279922, 0.95704612985818, 0.957149847549303, 0.9572142189908811, 0.9571883961776562, 0.9571604299788854, 0.9571957352128893, 0.957231102910137, 0.9572426036099988, 0.9573040426716304, 0.9573489117499993, 0.9573579522277286, 0.9573036365045658, 0.9572847329384188, 0.9572470560208713, 0.9573893521111743, 0.9573665412177462, 0.9573607218174947, 0.9573551927795408, 0.9573877459743183, 0.9574372786789522, 0.9574191889527232, 0.9574255218689913, 0.9574617465101151, 0.9574181725811954, 0.9574876575409739, 0.9575157653468945, 0.9574219474920382, 0.9574847675270886, 0.9575315962877543, 0.9575210265043991, 0.9575003448295027, 0.9575703550756478, 0.9575060696710093, 0.9576066007258266, 0.9575110559500456, 0.9576118126542319, 0.957529563208746, 0.9575649298531415, 0.9576179728427127, 0.9576233970903557, 0.9575567998587831, 0.9576256651984182, 0.9577045959991032, 0.9576671628123903, 0.9576957505120406, 0.9576185506997102, 0.9576591374643627, 0.9576926890781845, 0.9577174131034347, 0.9576824728072748, 0.9577108779075215, 0.9577307861828311, 0.957751571580188, 0.9577868021666557, 0.9577366051301461, 0.9578270718337581, 0.9577850691805812, 0.9577717736733109, 0.9577466506169958, 0.9577398584830995, 0.9577903325007826, 0.9578433855059498, 0.9578852566155662, 0.957731992868681, 0.9577849530638581, 0.9578427109425084, 0.9577740933651425, 0.9578676182660644, 0.9578850454091726, 0.957831081731661, 0.9578724546201167, 0.9578264490010652, 0.9578478164428326, 0.957852564309289, 0.9579112341141078, 0.95788307549531, 0.9579533108538995, 0.9578766671546146, 0.9578948227606088, 0.9578634653122147, 0.9578822741696378, 0.9579381073920814, 0.9580179998159685, 0.9579629599523138, 0.9579486246258028, 0.9578718653557183, 0.9580260147314583, 0.9579940058223843, 0.9579802380673125, 0.9580999413396181, 0.958039292601201], 'mDice': [0.01602288564232823, 0.029228309806166152, 0.04321363932923608, 0.06158900625149237, 0.09020004364668012, 0.12144236346176854, 0.1540675546847774, 0.19073403029951522, 0.22643553916554068, 0.2516610800401055, 0.27722616669402306, 0.3033557879469438, 0.32600470454252145, 0.34589150286567905, 0.3635998146654309, 0.3798681551701265, 0.39493962113159325, 0.40993864725798834, 0.4243245659881891, 0.43786827833169806, 0.4525275370503077, 0.46864004843572526, 0.4805233325642576, 0.4930167108463729, 0.4990599712657914, 0.5093453655688778, 0.5167764530322985, 0.5239012138837897, 0.5299528784741333, 0.5369005674660988, 0.542934608599853, 0.5479530422888262, 0.5529051125574518, 0.5587607074033439, 0.5629981123898963, 0.5672969506758879, 0.5732547721429174, 0.5761097312381515, 0.58048528882783, 0.5830183287768556, 0.5880690034853663, 0.5902637636275784, 0.5922093410645762, 0.5963731693919139, 0.5996372121598591, 0.6034405893752994, 0.606461961003256, 0.6066916185994494, 0.6113408970176517, 0.6133993678955396, 0.6154487292243804, 0.6173105816387349, 0.6190455347475051, 0.620428407044051, 0.6234017547318791, 0.6244142764972024, 0.6265336710669651, 0.6283891328801375, 0.6296230146997822, 0.6306882971462501, 0.6327908236285376, 0.6326248264355938, 0.6346117182062554, 0.6369084840895671, 0.6384950509057432, 0.6387771617801721, 0.6388735568827565, 0.6411607143389525, 0.641394221121577, 0.6428713586812627, 0.6433238997432296, 0.645536510812145, 0.6459407019756753, 0.6456208372864783, 0.647297525953607, 0.6476155631999702, 0.649729235333889, 0.6504351393570929, 0.650996790553284, 0.6504343657595337, 0.6530421560552494, 0.6521685989902145, 0.6540351953295779, 0.6551757735782754, 0.6552505894777765, 0.6565087956286996, 0.6574721060133467, 0.6570315258497321, 0.6565421994202426, 0.6589722036865432, 0.6589614185723726, 0.6602302830302417, 0.6607512488506033, 0.6620777103076745, 0.662055601555822, 0.6622782877452492, 0.6628790986831292, 0.6626598012266782, 0.662884518188437, 0.664689572709573, 0.6646965666521802, 0.6643280947516161, 0.6655960033094809, 0.665847247538716, 0.6666035043485967, 0.6670924193377608, 0.6672402897806654, 0.6680620573444183, 0.6686182935046752, 0.6688696301089614, 0.6690983845347589, 0.6686984323710166, 0.6693059381664288, 0.6698598024241728, 0.6698972124991255, 0.6710629161708063, 0.670988557614196, 0.6713158324526575, 0.6717686688322275, 0.6711685590850563, 0.6716533282683688, 0.6730793882619752, 0.6737381992405599, 0.6738842074455081, 0.6723960055257958, 0.6735232718175289, 0.6734387018403292, 0.674293375127443, 0.6746911734431063, 0.6753411582219248, 0.6748413291336708, 0.6752810726395659, 0.6751717710721763, 0.6752714904677699, 0.6755222922680236, 0.676168186838197, 0.677087681539813, 0.6761586565351302, 0.6769201907572368, 0.6763508587117272, 0.6774740546100375, 0.6779940865083139, 0.6772544838259009, 0.6777915637024359, 0.6777909134565857, 0.6776837960690234, 0.6784422107884139, 0.6789367906154957, 0.6791216063755015, 0.6794204873921352, 0.6803084922259194, 0.6788044235353698, 0.6799305831352361, 0.6799573000991215, 0.6811043527362559, 0.6801213804137682, 0.6811772490488398, 0.6801120498467029, 0.680245497513355, 0.6803374330210737, 0.6814314486407999, 0.6812497489879862, 0.6818581666075814, 0.6816641121066382, 0.6820524881040976, 0.6823677063396224, 0.6821383233639334, 0.6828785234456045, 0.6823593929959654, 0.6835327885794139, 0.6835127720912734, 0.682434883950839, 0.6819875859979067, 0.6840209977435188, 0.6840112985401279, 0.6839011664011657, 0.6832936861891672, 0.6841258796014518, 0.6839000935325577, 0.684619818130429, 0.6851869981186084, 0.6847037166307547, 0.684791664167497, 0.6856048516919776, 0.6855231166623822, 0.6850069290642218, 0.6859183960331445, 0.686258198054578, 0.6859609413672499, 0.6863814556366495, 0.6869054319490082, 0.685932879340912, 0.6870143320946681, 0.686201335817379, 0.6865259995638565, 0.6863613302997671, 0.6866915604919548, 0.6873878501998683, 0.6867588071564916, 0.6872612065874416, 0.6874132046137522, 0.6874300215164024, 0.687996470594039, 0.6882159867618316, 0.6878081922334116, 0.6879107513849355, 0.6882524585173154, 0.6888509784513425, 0.6885359670548235, 0.6880876453244016, 0.6885969362653176, 0.6891654031121085, 0.6892479891674093, 0.6879960545193633, 0.6900212507046113, 0.6892661413568825, 0.6893671249102696, 0.6889712555492106, 0.6891715270536702, 0.6894315948220445, 0.6900846388480256, 0.6908126231450739, 0.689395219128095, 0.6894364134965753, 0.6906169616913893, 0.6902913660115477, 0.6901401198088484, 0.6903213853325171, 0.6909919345326683, 0.6908940563959718, 0.6906678048043334, 0.690992646068927, 0.6907568994522767, 0.6914134866595838, 0.6914908899273944, 0.6917989723731957, 0.6913760740199907, 0.6915044444573555, 0.6907267854675769, 0.6917191182419408, 0.690744882791741, 0.6919956522891149, 0.6922785227740634, 0.6916312231618453, 0.6913949872807788, 0.6927798000983074, 0.6923466948028851, 0.6924093289449935, 0.6930056520709633, 0.6919133098566635]}
predicting test subjects:   0%|          | 0/15 [00:00<?, ?it/s]predicting test subjects:   7%|▋         | 1/15 [00:02<00:36,  2.58s/it]predicting test subjects:  13%|█▎        | 2/15 [00:04<00:31,  2.42s/it]predicting test subjects:  20%|██        | 3/15 [00:06<00:28,  2.38s/it]predicting test subjects:  27%|██▋       | 4/15 [00:09<00:25,  2.29s/it]predicting test subjects:  33%|███▎      | 5/15 [00:11<00:24,  2.45s/it]predicting test subjects:  40%|████      | 6/15 [00:14<00:22,  2.51s/it]predicting test subjects:  47%|████▋     | 7/15 [00:16<00:17,  2.25s/it]predicting test subjects:  53%|█████▎    | 8/15 [00:18<00:16,  2.34s/it]predicting test subjects:  60%|██████    | 9/15 [00:20<00:13,  2.32s/it]predicting test subjects:  67%|██████▋   | 10/15 [00:22<00:11,  2.23s/it]predicting test subjects:  73%|███████▎  | 11/15 [00:24<00:08,  2.16s/it]predicting test subjects:  80%|████████  | 12/15 [00:27<00:06,  2.18s/it]predicting test subjects:  87%|████████▋ | 13/15 [00:29<00:04,  2.28s/it]predicting test subjects:  93%|█████████▎| 14/15 [00:31<00:02,  2.22s/it]predicting test subjects: 100%|██████████| 15/15 [00:34<00:00,  2.25s/it]
predicting train subjects:   0%|          | 0/532 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/532 [00:02<23:59,  2.71s/it]predicting train subjects:   0%|          | 2/532 [00:04<22:02,  2.50s/it]predicting train subjects:   1%|          | 3/532 [00:06<20:54,  2.37s/it]predicting train subjects:   1%|          | 4/532 [00:08<19:36,  2.23s/it]predicting train subjects:   1%|          | 5/532 [00:10<18:49,  2.14s/it]predicting train subjects:   1%|          | 6/532 [00:12<18:36,  2.12s/it]predicting train subjects:   1%|▏         | 7/532 [00:14<18:26,  2.11s/it]predicting train subjects:   2%|▏         | 8/532 [00:16<17:54,  2.05s/it]predicting train subjects:   2%|▏         | 9/532 [00:19<18:39,  2.14s/it]predicting train subjects:   2%|▏         | 10/532 [00:21<18:18,  2.10s/it]predicting train subjects:   2%|▏         | 11/532 [00:22<17:02,  1.96s/it]predicting train subjects:   2%|▏         | 12/532 [00:25<17:58,  2.07s/it]predicting train subjects:   2%|▏         | 13/532 [00:26<17:06,  1.98s/it]predicting train subjects:   3%|▎         | 14/532 [00:28<16:15,  1.88s/it]predicting train subjects:   3%|▎         | 15/532 [00:30<15:28,  1.80s/it]predicting train subjects:   3%|▎         | 16/532 [00:31<15:18,  1.78s/it]predicting train subjects:   3%|▎         | 17/532 [00:33<14:18,  1.67s/it]predicting train subjects:   3%|▎         | 18/532 [00:35<14:50,  1.73s/it]predicting train subjects:   4%|▎         | 19/532 [00:36<13:49,  1.62s/it]predicting train subjects:   4%|▍         | 20/532 [00:38<14:10,  1.66s/it]predicting train subjects:   4%|▍         | 21/532 [00:40<15:13,  1.79s/it]predicting train subjects:   4%|▍         | 22/532 [00:41<14:52,  1.75s/it]predicting train subjects:   4%|▍         | 23/532 [00:43<14:59,  1.77s/it]predicting train subjects:   5%|▍         | 24/532 [00:45<14:04,  1.66s/it]predicting train subjects:   5%|▍         | 25/532 [00:47<15:23,  1.82s/it]predicting train subjects:   5%|▍         | 26/532 [00:49<15:02,  1.78s/it]predicting train subjects:   5%|▌         | 27/532 [00:51<16:46,  1.99s/it]predicting train subjects:   5%|▌         | 28/532 [00:53<16:09,  1.92s/it]predicting train subjects:   5%|▌         | 29/532 [00:55<16:25,  1.96s/it]predicting train subjects:   6%|▌         | 30/532 [00:56<15:14,  1.82s/it]predicting train subjects:   6%|▌         | 31/532 [00:58<15:09,  1.82s/it]predicting train subjects:   6%|▌         | 32/532 [01:00<15:35,  1.87s/it]predicting train subjects:   6%|▌         | 33/532 [01:02<14:37,  1.76s/it]predicting train subjects:   6%|▋         | 34/532 [01:04<15:27,  1.86s/it]predicting train subjects:   7%|▋         | 35/532 [01:05<14:58,  1.81s/it]predicting train subjects:   7%|▋         | 36/532 [01:07<15:05,  1.82s/it]predicting train subjects:   7%|▋         | 37/532 [01:09<15:06,  1.83s/it]predicting train subjects:   7%|▋         | 38/532 [01:11<15:36,  1.90s/it]predicting train subjects:   7%|▋         | 39/532 [01:13<15:12,  1.85s/it]predicting train subjects:   8%|▊         | 40/532 [01:15<14:42,  1.79s/it]predicting train subjects:   8%|▊         | 41/532 [01:17<15:01,  1.84s/it]predicting train subjects:   8%|▊         | 42/532 [01:18<14:59,  1.84s/it]predicting train subjects:   8%|▊         | 43/532 [01:20<14:15,  1.75s/it]predicting train subjects:   8%|▊         | 44/532 [01:21<13:24,  1.65s/it]predicting train subjects:   8%|▊         | 45/532 [01:23<13:11,  1.63s/it]predicting train subjects:   9%|▊         | 46/532 [01:25<13:33,  1.67s/it]predicting train subjects:   9%|▉         | 47/532 [01:27<15:32,  1.92s/it]predicting train subjects:   9%|▉         | 48/532 [01:29<15:26,  1.91s/it]predicting train subjects:   9%|▉         | 49/532 [01:31<14:44,  1.83s/it]predicting train subjects:   9%|▉         | 50/532 [01:33<15:15,  1.90s/it]predicting train subjects:  10%|▉         | 51/532 [01:34<14:34,  1.82s/it]predicting train subjects:  10%|▉         | 52/532 [01:36<14:16,  1.78s/it]predicting train subjects:  10%|▉         | 53/532 [01:38<13:50,  1.73s/it]predicting train subjects:  10%|█         | 54/532 [01:40<14:29,  1.82s/it]predicting train subjects:  10%|█         | 55/532 [01:42<14:35,  1.83s/it]predicting train subjects:  11%|█         | 56/532 [01:43<14:27,  1.82s/it]predicting train subjects:  11%|█         | 57/532 [01:45<14:26,  1.83s/it]predicting train subjects:  11%|█         | 58/532 [01:47<14:22,  1.82s/it]predicting train subjects:  11%|█         | 59/532 [01:50<16:05,  2.04s/it]predicting train subjects:  11%|█▏        | 60/532 [01:51<14:39,  1.86s/it]predicting train subjects:  11%|█▏        | 61/532 [01:53<13:53,  1.77s/it]predicting train subjects:  12%|█▏        | 62/532 [01:55<14:28,  1.85s/it]predicting train subjects:  12%|█▏        | 63/532 [01:57<14:57,  1.91s/it]predicting train subjects:  12%|█▏        | 64/532 [01:58<14:12,  1.82s/it]predicting train subjects:  12%|█▏        | 65/532 [02:00<14:02,  1.80s/it]predicting train subjects:  12%|█▏        | 66/532 [02:02<15:28,  1.99s/it]predicting train subjects:  13%|█▎        | 67/532 [02:05<15:52,  2.05s/it]predicting train subjects:  13%|█▎        | 68/532 [02:07<15:37,  2.02s/it]predicting train subjects:  13%|█▎        | 69/532 [02:08<15:15,  1.98s/it]predicting train subjects:  13%|█▎        | 70/532 [02:10<14:27,  1.88s/it]predicting train subjects:  13%|█▎        | 71/532 [02:12<13:50,  1.80s/it]predicting train subjects:  14%|█▎        | 72/532 [02:13<13:24,  1.75s/it]predicting train subjects:  14%|█▎        | 73/532 [02:15<14:01,  1.83s/it]predicting train subjects:  14%|█▍        | 74/532 [02:18<15:15,  2.00s/it]predicting train subjects:  14%|█▍        | 75/532 [02:21<17:16,  2.27s/it]predicting train subjects:  14%|█▍        | 76/532 [02:22<15:56,  2.10s/it]predicting train subjects:  14%|█▍        | 77/532 [02:24<15:18,  2.02s/it]predicting train subjects:  15%|█▍        | 78/532 [02:27<15:53,  2.10s/it]predicting train subjects:  15%|█▍        | 79/532 [02:28<15:11,  2.01s/it]predicting train subjects:  15%|█▌        | 80/532 [02:30<14:41,  1.95s/it]predicting train subjects:  15%|█▌        | 81/532 [02:32<14:23,  1.91s/it]predicting train subjects:  15%|█▌        | 82/532 [02:34<14:03,  1.87s/it]predicting train subjects:  16%|█▌        | 83/532 [02:35<13:19,  1.78s/it]predicting train subjects:  16%|█▌        | 84/532 [02:37<12:48,  1.71s/it]predicting train subjects:  16%|█▌        | 85/532 [02:38<12:28,  1.67s/it]predicting train subjects:  16%|█▌        | 86/532 [02:40<12:08,  1.63s/it]predicting train subjects:  16%|█▋        | 87/532 [02:42<11:58,  1.61s/it]predicting train subjects:  17%|█▋        | 88/532 [02:43<11:45,  1.59s/it]predicting train subjects:  17%|█▋        | 89/532 [02:45<12:24,  1.68s/it]predicting train subjects:  17%|█▋        | 90/532 [02:47<12:28,  1.69s/it]predicting train subjects:  17%|█▋        | 91/532 [02:48<12:33,  1.71s/it]predicting train subjects:  17%|█▋        | 92/532 [02:50<12:39,  1.73s/it]predicting train subjects:  17%|█▋        | 93/532 [02:52<12:37,  1.73s/it]predicting train subjects:  18%|█▊        | 94/532 [02:54<12:38,  1.73s/it]predicting train subjects:  18%|█▊        | 95/532 [02:56<13:28,  1.85s/it]predicting train subjects:  18%|█▊        | 96/532 [02:58<13:39,  1.88s/it]predicting train subjects:  18%|█▊        | 97/532 [03:00<13:57,  1.93s/it]predicting train subjects:  18%|█▊        | 98/532 [03:02<14:02,  1.94s/it]predicting train subjects:  19%|█▊        | 99/532 [03:04<14:22,  1.99s/it]predicting train subjects:  19%|█▉        | 100/532 [03:06<14:22,  2.00s/it]predicting train subjects:  19%|█▉        | 101/532 [03:07<13:22,  1.86s/it]predicting train subjects:  19%|█▉        | 102/532 [03:09<12:45,  1.78s/it]predicting train subjects:  19%|█▉        | 103/532 [03:11<12:12,  1.71s/it]predicting train subjects:  20%|█▉        | 104/532 [03:12<11:50,  1.66s/it]predicting train subjects:  20%|█▉        | 105/532 [03:14<11:38,  1.64s/it]predicting train subjects:  20%|█▉        | 106/532 [03:15<11:18,  1.59s/it]predicting train subjects:  20%|██        | 107/532 [03:17<11:13,  1.58s/it]predicting train subjects:  20%|██        | 108/532 [03:18<11:09,  1.58s/it]predicting train subjects:  20%|██        | 109/532 [03:20<11:00,  1.56s/it]predicting train subjects:  21%|██        | 110/532 [03:22<11:12,  1.59s/it]predicting train subjects:  21%|██        | 111/532 [03:23<11:07,  1.59s/it]predicting train subjects:  21%|██        | 112/532 [03:25<11:07,  1.59s/it]predicting train subjects:  21%|██        | 113/532 [03:27<11:36,  1.66s/it]predicting train subjects:  21%|██▏       | 114/532 [03:28<11:50,  1.70s/it]predicting train subjects:  22%|██▏       | 115/532 [03:30<11:59,  1.72s/it]predicting train subjects:  22%|██▏       | 116/532 [03:32<12:06,  1.75s/it]predicting train subjects:  22%|██▏       | 117/532 [03:34<12:09,  1.76s/it]predicting train subjects:  22%|██▏       | 118/532 [03:35<12:14,  1.77s/it]predicting train subjects:  22%|██▏       | 119/532 [03:37<12:13,  1.78s/it]predicting train subjects:  23%|██▎       | 120/532 [03:39<12:25,  1.81s/it]predicting train subjects:  23%|██▎       | 121/532 [03:41<12:17,  1.80s/it]predicting train subjects:  23%|██▎       | 122/532 [03:43<12:12,  1.79s/it]predicting train subjects:  23%|██▎       | 123/532 [03:44<12:01,  1.76s/it]predicting train subjects:  23%|██▎       | 124/532 [03:46<11:59,  1.76s/it]predicting train subjects:  23%|██▎       | 125/532 [03:48<12:13,  1.80s/it]predicting train subjects:  24%|██▎       | 126/532 [03:50<12:37,  1.87s/it]predicting train subjects:  24%|██▍       | 127/532 [03:52<12:40,  1.88s/it]predicting train subjects:  24%|██▍       | 128/532 [03:54<12:37,  1.88s/it]predicting train subjects:  24%|██▍       | 129/532 [03:56<12:58,  1.93s/it]predicting train subjects:  24%|██▍       | 130/532 [03:58<13:03,  1.95s/it]predicting train subjects:  25%|██▍       | 131/532 [04:00<14:08,  2.12s/it]predicting train subjects:  25%|██▍       | 132/532 [04:03<14:40,  2.20s/it]predicting train subjects:  25%|██▌       | 133/532 [04:05<14:39,  2.21s/it]predicting train subjects:  25%|██▌       | 134/532 [04:07<14:42,  2.22s/it]predicting train subjects:  25%|██▌       | 135/532 [04:10<14:46,  2.23s/it]predicting train subjects:  26%|██▌       | 136/532 [04:12<14:39,  2.22s/it]predicting train subjects:  26%|██▌       | 137/532 [04:14<14:39,  2.23s/it]predicting train subjects:  26%|██▌       | 138/532 [04:16<14:43,  2.24s/it]predicting train subjects:  26%|██▌       | 139/532 [04:18<14:43,  2.25s/it]predicting train subjects:  26%|██▋       | 140/532 [04:21<14:48,  2.27s/it]predicting train subjects:  27%|██▋       | 141/532 [04:23<14:40,  2.25s/it]predicting train subjects:  27%|██▋       | 142/532 [04:25<14:35,  2.25s/it]predicting train subjects:  27%|██▋       | 143/532 [04:27<13:26,  2.07s/it]predicting train subjects:  27%|██▋       | 144/532 [04:29<12:37,  1.95s/it]predicting train subjects:  27%|██▋       | 145/532 [04:30<12:05,  1.88s/it]predicting train subjects:  27%|██▋       | 146/532 [04:32<11:31,  1.79s/it]predicting train subjects:  28%|██▊       | 147/532 [04:34<11:23,  1.78s/it]predicting train subjects:  28%|██▊       | 148/532 [04:35<11:11,  1.75s/it]predicting train subjects:  28%|██▊       | 149/532 [04:37<11:18,  1.77s/it]predicting train subjects:  28%|██▊       | 150/532 [04:39<11:19,  1.78s/it]predicting train subjects:  28%|██▊       | 151/532 [04:41<11:19,  1.78s/it]predicting train subjects:  29%|██▊       | 152/532 [04:43<11:23,  1.80s/it]predicting train subjects:  29%|██▉       | 153/532 [04:44<11:15,  1.78s/it]predicting train subjects:  29%|██▉       | 154/532 [04:46<11:11,  1.78s/it]predicting train subjects:  29%|██▉       | 155/532 [04:48<12:15,  1.95s/it]predicting train subjects:  29%|██▉       | 156/532 [04:51<12:56,  2.07s/it]predicting train subjects:  30%|██▉       | 157/532 [04:53<13:28,  2.16s/it]predicting train subjects:  30%|██▉       | 158/532 [04:55<13:44,  2.20s/it]predicting train subjects:  30%|██▉       | 159/532 [04:58<14:01,  2.26s/it]predicting train subjects:  30%|███       | 160/532 [05:00<14:10,  2.29s/it]predicting train subjects:  30%|███       | 161/532 [05:02<12:59,  2.10s/it]predicting train subjects:  30%|███       | 162/532 [05:04<12:09,  1.97s/it]predicting train subjects:  31%|███       | 163/532 [05:05<11:38,  1.89s/it]predicting train subjects:  31%|███       | 164/532 [05:07<11:12,  1.83s/it]predicting train subjects:  31%|███       | 165/532 [05:09<10:54,  1.78s/it]predicting train subjects:  31%|███       | 166/532 [05:10<10:40,  1.75s/it]predicting train subjects:  31%|███▏      | 167/532 [05:12<10:52,  1.79s/it]predicting train subjects:  32%|███▏      | 168/532 [05:14<10:45,  1.77s/it]predicting train subjects:  32%|███▏      | 169/532 [05:16<10:39,  1.76s/it]predicting train subjects:  32%|███▏      | 170/532 [05:17<10:35,  1.75s/it]predicting train subjects:  32%|███▏      | 171/532 [05:19<10:32,  1.75s/it]predicting train subjects:  32%|███▏      | 172/532 [05:21<10:23,  1.73s/it]predicting train subjects:  33%|███▎      | 173/532 [05:22<10:08,  1.70s/it]predicting train subjects:  33%|███▎      | 174/532 [05:24<10:00,  1.68s/it]predicting train subjects:  33%|███▎      | 175/532 [05:26<09:52,  1.66s/it]predicting train subjects:  33%|███▎      | 176/532 [05:27<09:49,  1.66s/it]predicting train subjects:  33%|███▎      | 177/532 [05:29<09:40,  1.63s/it]predicting train subjects:  33%|███▎      | 178/532 [05:31<09:53,  1.68s/it]predicting train subjects:  34%|███▎      | 179/532 [05:32<09:53,  1.68s/it]predicting train subjects:  34%|███▍      | 180/532 [05:34<09:54,  1.69s/it]predicting train subjects:  34%|███▍      | 181/532 [05:36<09:55,  1.70s/it]predicting train subjects:  34%|███▍      | 182/532 [05:38<10:22,  1.78s/it]predicting train subjects:  34%|███▍      | 183/532 [05:39<10:09,  1.75s/it]predicting train subjects:  35%|███▍      | 184/532 [05:41<10:15,  1.77s/it]predicting train subjects:  35%|███▍      | 185/532 [05:43<09:52,  1.71s/it]predicting train subjects:  35%|███▍      | 186/532 [05:44<09:42,  1.68s/it]predicting train subjects:  35%|███▌      | 187/532 [05:46<09:26,  1.64s/it]predicting train subjects:  35%|███▌      | 188/532 [05:48<09:18,  1.62s/it]predicting train subjects:  36%|███▌      | 189/532 [05:49<09:12,  1.61s/it]predicting train subjects:  36%|███▌      | 190/532 [05:51<09:05,  1.60s/it]predicting train subjects:  36%|███▌      | 191/532 [05:53<10:17,  1.81s/it]predicting train subjects:  36%|███▌      | 192/532 [05:56<11:36,  2.05s/it]predicting train subjects:  36%|███▋      | 193/532 [05:58<11:59,  2.12s/it]predicting train subjects:  36%|███▋      | 194/532 [06:00<12:18,  2.19s/it]predicting train subjects:  37%|███▋      | 195/532 [06:02<12:21,  2.20s/it]predicting train subjects:  37%|███▋      | 196/532 [06:05<12:28,  2.23s/it]predicting train subjects:  37%|███▋      | 197/532 [06:07<12:07,  2.17s/it]predicting train subjects:  37%|███▋      | 198/532 [06:09<11:52,  2.13s/it]predicting train subjects:  37%|███▋      | 199/532 [06:11<11:34,  2.09s/it]predicting train subjects:  38%|███▊      | 200/532 [06:13<11:23,  2.06s/it]predicting train subjects:  38%|███▊      | 201/532 [06:15<11:12,  2.03s/it]predicting train subjects:  38%|███▊      | 202/532 [06:17<11:11,  2.03s/it]predicting train subjects:  38%|███▊      | 203/532 [06:18<10:27,  1.91s/it]predicting train subjects:  38%|███▊      | 204/532 [06:20<10:00,  1.83s/it]predicting train subjects:  39%|███▊      | 205/532 [06:22<09:55,  1.82s/it]predicting train subjects:  39%|███▊      | 206/532 [06:24<09:35,  1.77s/it]predicting train subjects:  39%|███▉      | 207/532 [06:25<09:23,  1.73s/it]predicting train subjects:  39%|███▉      | 208/532 [06:27<09:20,  1.73s/it]predicting train subjects:  39%|███▉      | 209/532 [06:28<08:55,  1.66s/it]predicting train subjects:  39%|███▉      | 210/532 [06:30<08:29,  1.58s/it]predicting train subjects:  40%|███▉      | 211/532 [06:31<08:16,  1.55s/it]predicting train subjects:  40%|███▉      | 212/532 [06:33<08:07,  1.52s/it]predicting train subjects:  40%|████      | 213/532 [06:34<08:07,  1.53s/it]predicting train subjects:  40%|████      | 214/532 [06:36<08:00,  1.51s/it]predicting train subjects:  40%|████      | 215/532 [06:38<08:56,  1.69s/it]predicting train subjects:  41%|████      | 216/532 [06:40<09:35,  1.82s/it]predicting train subjects:  41%|████      | 217/532 [06:42<10:07,  1.93s/it]predicting train subjects:  41%|████      | 218/532 [06:44<10:26,  2.00s/it]predicting train subjects:  41%|████      | 219/532 [06:46<10:40,  2.05s/it]predicting train subjects:  41%|████▏     | 220/532 [06:49<10:46,  2.07s/it]predicting train subjects:  42%|████▏     | 221/532 [06:50<09:46,  1.89s/it]predicting train subjects:  42%|████▏     | 222/532 [06:51<09:01,  1.75s/it]predicting train subjects:  42%|████▏     | 223/532 [06:53<08:33,  1.66s/it]predicting train subjects:  42%|████▏     | 224/532 [06:55<08:50,  1.72s/it]predicting train subjects:  42%|████▏     | 225/532 [06:56<08:20,  1.63s/it]predicting train subjects:  42%|████▏     | 226/532 [06:58<08:02,  1.58s/it]predicting train subjects:  43%|████▎     | 227/532 [06:59<07:45,  1.53s/it]predicting train subjects:  43%|████▎     | 228/532 [07:00<07:32,  1.49s/it]predicting train subjects:  43%|████▎     | 229/532 [07:02<07:20,  1.45s/it]predicting train subjects:  43%|████▎     | 230/532 [07:03<07:11,  1.43s/it]predicting train subjects:  43%|████▎     | 231/532 [07:05<07:09,  1.43s/it]predicting train subjects:  44%|████▎     | 232/532 [07:06<07:05,  1.42s/it]predicting train subjects:  44%|████▍     | 233/532 [07:08<07:25,  1.49s/it]predicting train subjects:  44%|████▍     | 234/532 [07:09<07:37,  1.53s/it]predicting train subjects:  44%|████▍     | 235/532 [07:11<07:42,  1.56s/it]predicting train subjects:  44%|████▍     | 236/532 [07:13<07:46,  1.58s/it]predicting train subjects:  45%|████▍     | 237/532 [07:14<07:57,  1.62s/it]predicting train subjects:  45%|████▍     | 238/532 [07:16<08:02,  1.64s/it]predicting train subjects:  45%|████▍     | 239/532 [07:18<08:13,  1.69s/it]predicting train subjects:  45%|████▌     | 240/532 [07:20<08:28,  1.74s/it]predicting train subjects:  45%|████▌     | 241/532 [07:21<08:33,  1.76s/it]predicting train subjects:  45%|████▌     | 242/532 [07:23<08:34,  1.77s/it]predicting train subjects:  46%|████▌     | 243/532 [07:25<08:35,  1.78s/it]predicting train subjects:  46%|████▌     | 244/532 [07:27<08:29,  1.77s/it]predicting train subjects:  46%|████▌     | 245/532 [07:28<08:01,  1.68s/it]predicting train subjects:  46%|████▌     | 246/532 [07:30<07:40,  1.61s/it]predicting train subjects:  46%|████▋     | 247/532 [07:31<07:22,  1.55s/it]predicting train subjects:  47%|████▋     | 248/532 [07:33<07:08,  1.51s/it]predicting train subjects:  47%|████▋     | 249/532 [07:34<06:57,  1.48s/it]predicting train subjects:  47%|████▋     | 250/532 [07:35<06:52,  1.46s/it]predicting train subjects:  47%|████▋     | 251/532 [07:37<07:01,  1.50s/it]predicting train subjects:  47%|████▋     | 252/532 [07:39<07:06,  1.52s/it]predicting train subjects:  48%|████▊     | 253/532 [07:40<07:28,  1.61s/it]predicting train subjects:  48%|████▊     | 254/532 [07:42<07:16,  1.57s/it]predicting train subjects:  48%|████▊     | 255/532 [07:43<07:15,  1.57s/it]predicting train subjects:  48%|████▊     | 256/532 [07:45<07:12,  1.57s/it]predicting train subjects:  48%|████▊     | 257/532 [07:47<07:45,  1.69s/it]predicting train subjects:  48%|████▊     | 258/532 [07:49<08:05,  1.77s/it]predicting train subjects:  49%|████▊     | 259/532 [07:51<08:18,  1.83s/it]predicting train subjects:  49%|████▉     | 260/532 [07:53<08:25,  1.86s/it]predicting train subjects:  49%|████▉     | 261/532 [07:55<08:50,  1.96s/it]predicting train subjects:  49%|████▉     | 262/532 [07:57<08:45,  1.95s/it]predicting train subjects:  49%|████▉     | 263/532 [07:58<08:06,  1.81s/it]predicting train subjects:  50%|████▉     | 264/532 [08:00<07:31,  1.68s/it]predicting train subjects:  50%|████▉     | 265/532 [08:01<07:06,  1.60s/it]predicting train subjects:  50%|█████     | 266/532 [08:03<06:50,  1.54s/it]predicting train subjects:  50%|█████     | 267/532 [08:04<06:38,  1.51s/it]predicting train subjects:  50%|█████     | 268/532 [08:05<06:27,  1.47s/it]predicting train subjects:  51%|█████     | 269/532 [08:07<06:46,  1.54s/it]predicting train subjects:  51%|█████     | 270/532 [08:09<07:23,  1.69s/it]predicting train subjects:  51%|█████     | 271/532 [08:11<07:27,  1.72s/it]predicting train subjects:  51%|█████     | 272/532 [08:13<07:28,  1.72s/it]predicting train subjects:  51%|█████▏    | 273/532 [08:14<07:28,  1.73s/it]predicting train subjects:  52%|█████▏    | 274/532 [08:16<07:29,  1.74s/it]predicting train subjects:  52%|█████▏    | 275/532 [08:18<07:56,  1.86s/it]predicting train subjects:  52%|█████▏    | 276/532 [08:20<08:21,  1.96s/it]predicting train subjects:  52%|█████▏    | 277/532 [08:23<08:32,  2.01s/it]predicting train subjects:  52%|█████▏    | 278/532 [08:25<08:35,  2.03s/it]predicting train subjects:  52%|█████▏    | 279/532 [08:27<08:41,  2.06s/it]predicting train subjects:  53%|█████▎    | 280/532 [08:29<09:17,  2.21s/it]predicting train subjects:  53%|█████▎    | 281/532 [08:31<09:02,  2.16s/it]predicting train subjects:  53%|█████▎    | 282/532 [08:33<08:53,  2.13s/it]predicting train subjects:  53%|█████▎    | 283/532 [08:36<08:50,  2.13s/it]predicting train subjects:  53%|█████▎    | 284/532 [08:38<08:42,  2.11s/it]predicting train subjects:  54%|█████▎    | 285/532 [08:40<08:38,  2.10s/it]predicting train subjects:  54%|█████▍    | 286/532 [08:42<08:30,  2.08s/it]predicting train subjects:  54%|█████▍    | 287/532 [08:43<07:50,  1.92s/it]predicting train subjects:  54%|█████▍    | 288/532 [08:45<07:17,  1.79s/it]predicting train subjects:  54%|█████▍    | 289/532 [08:46<07:00,  1.73s/it]predicting train subjects:  55%|█████▍    | 290/532 [08:48<06:42,  1.66s/it]predicting train subjects:  55%|█████▍    | 291/532 [08:49<06:32,  1.63s/it]predicting train subjects:  55%|█████▍    | 292/532 [08:51<06:31,  1.63s/it]predicting train subjects:  55%|█████▌    | 293/532 [08:53<06:45,  1.70s/it]predicting train subjects:  55%|█████▌    | 294/532 [08:55<06:46,  1.71s/it]predicting train subjects:  55%|█████▌    | 295/532 [08:56<06:51,  1.74s/it]predicting train subjects:  56%|█████▌    | 296/532 [08:58<06:50,  1.74s/it]predicting train subjects:  56%|█████▌    | 297/532 [09:00<06:48,  1.74s/it]predicting train subjects:  56%|█████▌    | 298/532 [09:02<06:45,  1.73s/it]predicting train subjects:  56%|█████▌    | 299/532 [09:03<06:22,  1.64s/it]predicting train subjects:  56%|█████▋    | 300/532 [09:05<06:04,  1.57s/it]predicting train subjects:  57%|█████▋    | 301/532 [09:06<05:51,  1.52s/it]predicting train subjects:  57%|█████▋    | 302/532 [09:07<05:49,  1.52s/it]predicting train subjects:  57%|█████▋    | 303/532 [09:09<05:41,  1.49s/it]predicting train subjects:  57%|█████▋    | 304/532 [09:10<05:35,  1.47s/it]predicting train subjects:  57%|█████▋    | 305/532 [09:12<06:23,  1.69s/it]predicting train subjects:  58%|█████▊    | 306/532 [09:15<06:49,  1.81s/it]predicting train subjects:  58%|█████▊    | 307/532 [09:17<07:07,  1.90s/it]predicting train subjects:  58%|█████▊    | 308/532 [09:19<07:44,  2.08s/it]predicting train subjects:  58%|█████▊    | 309/532 [09:21<07:46,  2.09s/it]predicting train subjects:  58%|█████▊    | 310/532 [09:23<07:46,  2.10s/it]predicting train subjects:  58%|█████▊    | 311/532 [09:26<08:35,  2.33s/it]predicting train subjects:  59%|█████▊    | 312/532 [09:29<09:06,  2.48s/it]predicting train subjects:  59%|█████▉    | 313/532 [09:32<09:48,  2.69s/it]predicting train subjects:  59%|█████▉    | 314/532 [09:35<09:56,  2.74s/it]predicting train subjects:  59%|█████▉    | 315/532 [09:38<10:00,  2.77s/it]predicting train subjects:  59%|█████▉    | 316/532 [09:41<10:03,  2.79s/it]predicting train subjects:  60%|█████▉    | 317/532 [09:42<08:41,  2.43s/it]predicting train subjects:  60%|█████▉    | 318/532 [09:44<07:44,  2.17s/it]predicting train subjects:  60%|█████▉    | 319/532 [09:46<07:14,  2.04s/it]predicting train subjects:  60%|██████    | 320/532 [09:47<06:45,  1.91s/it]predicting train subjects:  60%|██████    | 321/532 [09:49<06:20,  1.80s/it]predicting train subjects:  61%|██████    | 322/532 [09:50<06:05,  1.74s/it]predicting train subjects:  61%|██████    | 323/532 [09:53<06:37,  1.90s/it]predicting train subjects:  61%|██████    | 324/532 [09:55<07:00,  2.02s/it]predicting train subjects:  61%|██████    | 325/532 [09:57<07:12,  2.09s/it]predicting train subjects:  61%|██████▏   | 326/532 [10:00<07:18,  2.13s/it]predicting train subjects:  61%|██████▏   | 327/532 [10:02<07:26,  2.18s/it]predicting train subjects:  62%|██████▏   | 328/532 [10:04<07:30,  2.21s/it]predicting train subjects:  62%|██████▏   | 329/532 [10:06<06:54,  2.04s/it]predicting train subjects:  62%|██████▏   | 330/532 [10:08<06:34,  1.95s/it]predicting train subjects:  62%|██████▏   | 331/532 [10:09<06:15,  1.87s/it]predicting train subjects:  62%|██████▏   | 332/532 [10:11<06:04,  1.82s/it]predicting train subjects:  63%|██████▎   | 333/532 [10:13<05:51,  1.77s/it]predicting train subjects:  63%|██████▎   | 334/532 [10:14<05:47,  1.76s/it]predicting train subjects:  63%|██████▎   | 335/532 [10:16<06:03,  1.84s/it]predicting train subjects:  63%|██████▎   | 336/532 [10:18<06:10,  1.89s/it]predicting train subjects:  63%|██████▎   | 337/532 [10:20<06:13,  1.91s/it]predicting train subjects:  64%|██████▎   | 338/532 [10:22<06:15,  1.94s/it]predicting train subjects:  64%|██████▎   | 339/532 [10:24<06:13,  1.94s/it]predicting train subjects:  64%|██████▍   | 340/532 [10:26<06:18,  1.97s/it]predicting train subjects:  64%|██████▍   | 341/532 [10:28<05:45,  1.81s/it]predicting train subjects:  64%|██████▍   | 342/532 [10:29<05:29,  1.73s/it]predicting train subjects:  64%|██████▍   | 343/532 [10:31<05:11,  1.65s/it]predicting train subjects:  65%|██████▍   | 344/532 [10:32<04:56,  1.58s/it]predicting train subjects:  65%|██████▍   | 345/532 [10:34<04:50,  1.55s/it]predicting train subjects:  65%|██████▌   | 346/532 [10:35<04:50,  1.56s/it]predicting train subjects:  65%|██████▌   | 347/532 [10:37<05:01,  1.63s/it]predicting train subjects:  65%|██████▌   | 348/532 [10:39<05:03,  1.65s/it]predicting train subjects:  66%|██████▌   | 349/532 [10:40<05:07,  1.68s/it]predicting train subjects:  66%|██████▌   | 350/532 [10:42<05:06,  1.68s/it]predicting train subjects:  66%|██████▌   | 351/532 [10:44<05:05,  1.69s/it]predicting train subjects:  66%|██████▌   | 352/532 [10:45<05:00,  1.67s/it]predicting train subjects:  66%|██████▋   | 353/532 [10:47<04:57,  1.66s/it]predicting train subjects:  67%|██████▋   | 354/532 [10:49<04:53,  1.65s/it]predicting train subjects:  67%|██████▋   | 355/532 [10:50<04:53,  1.66s/it]predicting train subjects:  67%|██████▋   | 356/532 [10:52<04:49,  1.64s/it]predicting train subjects:  67%|██████▋   | 357/532 [10:54<04:50,  1.66s/it]predicting train subjects:  67%|██████▋   | 358/532 [10:55<04:48,  1.66s/it]predicting train subjects:  67%|██████▋   | 359/532 [10:57<04:41,  1.63s/it]predicting train subjects:  68%|██████▊   | 360/532 [10:58<04:34,  1.60s/it]predicting train subjects:  68%|██████▊   | 361/532 [11:00<04:27,  1.56s/it]predicting train subjects:  68%|██████▊   | 362/532 [11:01<04:20,  1.53s/it]predicting train subjects:  68%|██████▊   | 363/532 [11:03<04:17,  1.52s/it]predicting train subjects:  68%|██████▊   | 364/532 [11:04<04:15,  1.52s/it]predicting train subjects:  69%|██████▊   | 365/532 [11:06<04:12,  1.51s/it]predicting train subjects:  69%|██████▉   | 366/532 [11:07<04:11,  1.51s/it]predicting train subjects:  69%|██████▉   | 367/532 [11:09<04:09,  1.51s/it]predicting train subjects:  69%|██████▉   | 368/532 [11:10<04:05,  1.50s/it]predicting train subjects:  69%|██████▉   | 369/532 [11:12<04:03,  1.49s/it]predicting train subjects:  70%|██████▉   | 370/532 [11:13<03:58,  1.47s/it]predicting train subjects:  70%|██████▉   | 371/532 [11:15<04:23,  1.63s/it]predicting train subjects:  70%|██████▉   | 372/532 [11:17<04:40,  1.75s/it]predicting train subjects:  70%|███████   | 373/532 [11:19<04:52,  1.84s/it]predicting train subjects:  70%|███████   | 374/532 [11:21<05:04,  1.93s/it]predicting train subjects:  70%|███████   | 375/532 [11:24<05:12,  1.99s/it]predicting train subjects:  71%|███████   | 376/532 [11:26<05:15,  2.03s/it]predicting train subjects:  71%|███████   | 377/532 [11:27<04:58,  1.92s/it]predicting train subjects:  71%|███████   | 378/532 [11:29<04:45,  1.85s/it]predicting train subjects:  71%|███████   | 379/532 [11:31<04:36,  1.81s/it]predicting train subjects:  71%|███████▏  | 380/532 [11:33<04:30,  1.78s/it]predicting train subjects:  72%|███████▏  | 381/532 [11:34<04:26,  1.77s/it]predicting train subjects:  72%|███████▏  | 382/532 [11:36<04:22,  1.75s/it]predicting train subjects:  72%|███████▏  | 383/532 [11:38<04:27,  1.80s/it]predicting train subjects:  72%|███████▏  | 384/532 [11:40<04:28,  1.81s/it]predicting train subjects:  72%|███████▏  | 385/532 [11:42<04:26,  1.82s/it]predicting train subjects:  73%|███████▎  | 386/532 [11:43<04:25,  1.82s/it]predicting train subjects:  73%|███████▎  | 387/532 [11:45<04:25,  1.83s/it]predicting train subjects:  73%|███████▎  | 388/532 [11:47<04:18,  1.79s/it]predicting train subjects:  73%|███████▎  | 389/532 [11:49<04:16,  1.80s/it]predicting train subjects:  73%|███████▎  | 390/532 [11:51<04:18,  1.82s/it]predicting train subjects:  73%|███████▎  | 391/532 [11:52<04:15,  1.81s/it]predicting train subjects:  74%|███████▎  | 392/532 [11:54<04:14,  1.82s/it]predicting train subjects:  74%|███████▍  | 393/532 [11:56<04:16,  1.84s/it]predicting train subjects:  74%|███████▍  | 394/532 [11:58<04:16,  1.86s/it]predicting train subjects:  74%|███████▍  | 395/532 [12:00<04:18,  1.89s/it]predicting train subjects:  74%|███████▍  | 396/532 [12:02<04:14,  1.87s/it]predicting train subjects:  75%|███████▍  | 397/532 [12:04<04:12,  1.87s/it]predicting train subjects:  75%|███████▍  | 398/532 [12:05<04:07,  1.85s/it]predicting train subjects:  75%|███████▌  | 399/532 [12:07<04:01,  1.82s/it]predicting train subjects:  75%|███████▌  | 400/532 [12:09<04:02,  1.83s/it]predicting train subjects:  75%|███████▌  | 401/532 [12:11<04:05,  1.88s/it]predicting train subjects:  76%|███████▌  | 402/532 [12:13<04:07,  1.90s/it]predicting train subjects:  76%|███████▌  | 403/532 [12:15<04:15,  1.98s/it]predicting train subjects:  76%|███████▌  | 404/532 [12:17<04:14,  1.99s/it]predicting train subjects:  76%|███████▌  | 405/532 [12:19<04:11,  1.98s/it]predicting train subjects:  76%|███████▋  | 406/532 [12:21<04:09,  1.98s/it]predicting train subjects:  77%|███████▋  | 407/532 [12:23<04:00,  1.92s/it]predicting train subjects:  77%|███████▋  | 408/532 [12:25<03:49,  1.85s/it]predicting train subjects:  77%|███████▋  | 409/532 [12:26<03:42,  1.81s/it]predicting train subjects:  77%|███████▋  | 410/532 [12:28<03:37,  1.78s/it]predicting train subjects:  77%|███████▋  | 411/532 [12:30<03:35,  1.78s/it]predicting train subjects:  77%|███████▋  | 412/532 [12:32<03:32,  1.77s/it]predicting train subjects:  78%|███████▊  | 413/532 [12:33<03:29,  1.76s/it]predicting train subjects:  78%|███████▊  | 414/532 [12:35<03:22,  1.72s/it]predicting train subjects:  78%|███████▊  | 415/532 [12:37<03:16,  1.68s/it]predicting train subjects:  78%|███████▊  | 416/532 [12:38<03:10,  1.65s/it]predicting train subjects:  78%|███████▊  | 417/532 [12:40<03:08,  1.64s/it]predicting train subjects:  79%|███████▊  | 418/532 [12:41<03:07,  1.65s/it]predicting train subjects:  79%|███████▉  | 419/532 [12:43<03:12,  1.70s/it]predicting train subjects:  79%|███████▉  | 420/532 [12:45<03:17,  1.76s/it]predicting train subjects:  79%|███████▉  | 421/532 [12:47<03:22,  1.82s/it]predicting train subjects:  79%|███████▉  | 422/532 [12:49<03:24,  1.86s/it]predicting train subjects:  80%|███████▉  | 423/532 [12:51<03:25,  1.89s/it]predicting train subjects:  80%|███████▉  | 424/532 [12:53<03:20,  1.86s/it]predicting train subjects:  80%|███████▉  | 425/532 [12:55<03:18,  1.86s/it]predicting train subjects:  80%|████████  | 426/532 [12:56<03:15,  1.84s/it]predicting train subjects:  80%|████████  | 427/532 [12:58<03:13,  1.84s/it]predicting train subjects:  80%|████████  | 428/532 [13:00<03:12,  1.85s/it]predicting train subjects:  81%|████████  | 429/532 [13:02<03:09,  1.84s/it]predicting train subjects:  81%|████████  | 430/532 [13:04<03:08,  1.85s/it]predicting train subjects:  81%|████████  | 431/532 [13:06<03:15,  1.93s/it]predicting train subjects:  81%|████████  | 432/532 [13:08<03:17,  1.97s/it]predicting train subjects:  81%|████████▏ | 433/532 [13:10<03:15,  1.98s/it]predicting train subjects:  82%|████████▏ | 434/532 [13:12<03:14,  1.99s/it]predicting train subjects:  82%|████████▏ | 435/532 [13:14<03:23,  2.10s/it]predicting train subjects:  82%|████████▏ | 436/532 [13:16<03:18,  2.07s/it]predicting train subjects:  82%|████████▏ | 437/532 [13:18<03:02,  1.92s/it]predicting train subjects:  82%|████████▏ | 438/532 [13:19<02:49,  1.81s/it]predicting train subjects:  83%|████████▎ | 439/532 [13:21<02:42,  1.75s/it]predicting train subjects:  83%|████████▎ | 440/532 [13:23<02:34,  1.68s/it]predicting train subjects:  83%|████████▎ | 441/532 [13:24<02:28,  1.63s/it]predicting train subjects:  83%|████████▎ | 442/532 [13:26<02:22,  1.59s/it]predicting train subjects:  83%|████████▎ | 443/532 [13:27<02:18,  1.55s/it]predicting train subjects:  83%|████████▎ | 444/532 [13:29<02:14,  1.53s/it]predicting train subjects:  84%|████████▎ | 445/532 [13:30<02:08,  1.48s/it]predicting train subjects:  84%|████████▍ | 446/532 [13:31<02:05,  1.46s/it]predicting train subjects:  84%|████████▍ | 447/532 [13:33<02:02,  1.44s/it]predicting train subjects:  84%|████████▍ | 448/532 [13:34<01:59,  1.42s/it]predicting train subjects:  84%|████████▍ | 449/532 [13:36<02:02,  1.48s/it]predicting train subjects:  85%|████████▍ | 450/532 [13:37<02:03,  1.50s/it]predicting train subjects:  85%|████████▍ | 451/532 [13:39<02:03,  1.53s/it]predicting train subjects:  85%|████████▍ | 452/532 [13:40<02:02,  1.54s/it]predicting train subjects:  85%|████████▌ | 453/532 [13:42<02:02,  1.55s/it]predicting train subjects:  85%|████████▌ | 454/532 [13:44<02:04,  1.59s/it]predicting train subjects:  86%|████████▌ | 455/532 [13:46<02:08,  1.67s/it]predicting train subjects:  86%|████████▌ | 456/532 [13:47<02:11,  1.73s/it]predicting train subjects:  86%|████████▌ | 457/532 [13:49<02:11,  1.75s/it]predicting train subjects:  86%|████████▌ | 458/532 [13:51<02:11,  1.77s/it]predicting train subjects:  86%|████████▋ | 459/532 [13:53<02:11,  1.80s/it]predicting train subjects:  86%|████████▋ | 460/532 [13:55<02:12,  1.84s/it]predicting train subjects:  87%|████████▋ | 461/532 [13:57<02:14,  1.90s/it]predicting train subjects:  87%|████████▋ | 462/532 [13:59<02:16,  1.95s/it]predicting train subjects:  87%|████████▋ | 463/532 [14:01<02:17,  1.99s/it]predicting train subjects:  87%|████████▋ | 464/532 [14:03<02:18,  2.04s/it]predicting train subjects:  87%|████████▋ | 465/532 [14:05<02:19,  2.08s/it]predicting train subjects:  88%|████████▊ | 466/532 [14:07<02:17,  2.08s/it]predicting train subjects:  88%|████████▊ | 467/532 [14:09<02:07,  1.97s/it]predicting train subjects:  88%|████████▊ | 468/532 [14:11<01:59,  1.87s/it]predicting train subjects:  88%|████████▊ | 469/532 [14:12<01:54,  1.81s/it]predicting train subjects:  88%|████████▊ | 470/532 [14:14<01:49,  1.77s/it]predicting train subjects:  89%|████████▊ | 471/532 [14:16<01:46,  1.75s/it]predicting train subjects:  89%|████████▊ | 472/532 [14:17<01:42,  1.71s/it]predicting train subjects:  89%|████████▉ | 473/532 [14:19<01:43,  1.75s/it]predicting train subjects:  89%|████████▉ | 474/532 [14:21<01:44,  1.81s/it]predicting train subjects:  89%|████████▉ | 475/532 [14:23<01:44,  1.83s/it]predicting train subjects:  89%|████████▉ | 476/532 [14:25<01:44,  1.87s/it]predicting train subjects:  90%|████████▉ | 477/532 [14:27<01:42,  1.86s/it]predicting train subjects:  90%|████████▉ | 478/532 [14:29<01:40,  1.85s/it]predicting train subjects:  90%|█████████ | 479/532 [14:30<01:34,  1.79s/it]predicting train subjects:  90%|█████████ | 480/532 [14:32<01:29,  1.73s/it]predicting train subjects:  90%|█████████ | 481/532 [14:34<01:27,  1.71s/it]predicting train subjects:  91%|█████████ | 482/532 [14:35<01:23,  1.68s/it]predicting train subjects:  91%|█████████ | 483/532 [14:37<01:20,  1.65s/it]predicting train subjects:  91%|█████████ | 484/532 [14:38<01:17,  1.62s/it]predicting train subjects:  91%|█████████ | 485/532 [14:40<01:21,  1.74s/it]predicting train subjects:  91%|█████████▏| 486/532 [14:42<01:23,  1.82s/it]predicting train subjects:  92%|█████████▏| 487/532 [14:44<01:24,  1.87s/it]predicting train subjects:  92%|█████████▏| 488/532 [14:46<01:23,  1.89s/it]predicting train subjects:  92%|█████████▏| 489/532 [14:48<01:22,  1.93s/it]predicting train subjects:  92%|█████████▏| 490/532 [14:50<01:21,  1.94s/it]predicting train subjects:  92%|█████████▏| 491/532 [14:52<01:17,  1.89s/it]predicting train subjects:  92%|█████████▏| 492/532 [14:54<01:14,  1.85s/it]predicting train subjects:  93%|█████████▎| 493/532 [14:56<01:10,  1.82s/it]predicting train subjects:  93%|█████████▎| 494/532 [14:57<01:07,  1.79s/it]predicting train subjects:  93%|█████████▎| 495/532 [14:59<01:06,  1.79s/it]predicting train subjects:  93%|█████████▎| 496/532 [15:01<01:03,  1.76s/it]predicting train subjects:  93%|█████████▎| 497/532 [15:03<01:01,  1.77s/it]predicting train subjects:  94%|█████████▎| 498/532 [15:04<01:00,  1.77s/it]predicting train subjects:  94%|█████████▍| 499/532 [15:06<00:58,  1.78s/it]predicting train subjects:  94%|█████████▍| 500/532 [15:08<00:56,  1.77s/it]predicting train subjects:  94%|█████████▍| 501/532 [15:10<00:54,  1.76s/it]predicting train subjects:  94%|█████████▍| 502/532 [15:11<00:52,  1.76s/it]predicting train subjects:  95%|█████████▍| 503/532 [15:13<00:50,  1.73s/it]predicting train subjects:  95%|█████████▍| 504/532 [15:15<00:48,  1.72s/it]predicting train subjects:  95%|█████████▍| 505/532 [15:16<00:45,  1.69s/it]predicting train subjects:  95%|█████████▌| 506/532 [15:18<00:45,  1.75s/it]predicting train subjects:  95%|█████████▌| 507/532 [15:20<00:43,  1.72s/it]predicting train subjects:  95%|█████████▌| 508/532 [15:21<00:39,  1.66s/it]predicting train subjects:  96%|█████████▌| 509/532 [15:23<00:40,  1.77s/it]predicting train subjects:  96%|█████████▌| 510/532 [15:26<00:41,  1.87s/it]predicting train subjects:  96%|█████████▌| 511/532 [15:28<00:40,  1.91s/it]predicting train subjects:  96%|█████████▌| 512/532 [15:30<00:39,  1.95s/it]predicting train subjects:  96%|█████████▋| 513/532 [15:32<00:36,  1.93s/it]predicting train subjects:  97%|█████████▋| 514/532 [15:33<00:34,  1.94s/it]predicting train subjects:  97%|█████████▋| 515/532 [15:35<00:31,  1.86s/it]predicting train subjects:  97%|█████████▋| 516/532 [15:37<00:29,  1.82s/it]predicting train subjects:  97%|█████████▋| 517/532 [15:39<00:28,  1.90s/it]predicting train subjects:  97%|█████████▋| 518/532 [15:41<00:25,  1.85s/it]predicting train subjects:  98%|█████████▊| 519/532 [15:42<00:23,  1.80s/it]predicting train subjects:  98%|█████████▊| 520/532 [15:44<00:21,  1.76s/it]predicting train subjects:  98%|█████████▊| 521/532 [15:46<00:19,  1.79s/it]predicting train subjects:  98%|█████████▊| 522/532 [15:48<00:18,  1.81s/it]predicting train subjects:  98%|█████████▊| 523/532 [15:50<00:16,  1.81s/it]predicting train subjects:  98%|█████████▊| 524/532 [15:51<00:14,  1.82s/it]predicting train subjects:  99%|█████████▊| 525/532 [15:53<00:12,  1.84s/it]predicting train subjects:  99%|█████████▉| 526/532 [15:55<00:11,  1.84s/it]predicting train subjects:  99%|█████████▉| 527/532 [15:57<00:09,  1.82s/it]predicting train subjects:  99%|█████████▉| 528/532 [15:59<00:07,  1.78s/it]predicting train subjects:  99%|█████████▉| 529/532 [16:00<00:05,  1.76s/it]predicting train subjects: 100%|█████████▉| 530/532 [16:02<00:03,  1.80s/it]predicting train subjects: 100%|█████████▉| 531/532 [16:04<00:01,  1.78s/it]predicting train subjects: 100%|██████████| 532/532 [16:06<00:00,  1.75s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1’: File exists

Loading train:   0%|          | 0/532 [00:00<?, ?it/s]Loading train:   0%|          | 1/532 [00:01<12:58,  1.47s/it]Loading train:   0%|          | 2/532 [00:02<11:52,  1.34s/it]Loading train:   1%|          | 3/532 [00:03<11:26,  1.30s/it]Loading train:   1%|          | 4/532 [00:04<11:15,  1.28s/it]Loading train:   1%|          | 5/532 [00:06<10:49,  1.23s/it]Loading train:   1%|          | 6/532 [00:07<10:27,  1.19s/it]Loading train:   1%|▏         | 7/532 [00:08<09:47,  1.12s/it]Loading train:   2%|▏         | 8/532 [00:09<09:50,  1.13s/it]Loading train:   2%|▏         | 9/532 [00:10<09:58,  1.14s/it]Loading train:   2%|▏         | 10/532 [00:11<09:27,  1.09s/it]Loading train:   2%|▏         | 11/532 [00:12<09:04,  1.05s/it]Loading train:   2%|▏         | 12/532 [00:13<09:37,  1.11s/it]Loading train:   2%|▏         | 13/532 [00:14<10:00,  1.16s/it]Loading train:   3%|▎         | 14/532 [00:15<09:28,  1.10s/it]Loading train:   3%|▎         | 15/532 [00:16<09:24,  1.09s/it]Loading train:   3%|▎         | 16/532 [00:18<09:43,  1.13s/it]Loading train:   3%|▎         | 17/532 [00:19<09:27,  1.10s/it]Loading train:   3%|▎         | 18/532 [00:20<09:50,  1.15s/it]Loading train:   4%|▎         | 19/532 [00:21<09:16,  1.09s/it]Loading train:   4%|▍         | 20/532 [00:22<08:57,  1.05s/it]Loading train:   4%|▍         | 21/532 [00:23<09:08,  1.07s/it]Loading train:   4%|▍         | 22/532 [00:24<08:45,  1.03s/it]Loading train:   4%|▍         | 23/532 [00:25<08:41,  1.02s/it]Loading train:   5%|▍         | 24/532 [00:26<08:41,  1.03s/it]Loading train:   5%|▍         | 25/532 [00:27<09:26,  1.12s/it]Loading train:   5%|▍         | 26/532 [00:28<09:14,  1.10s/it]Loading train:   5%|▌         | 27/532 [00:30<09:34,  1.14s/it]Loading train:   5%|▌         | 28/532 [00:31<09:27,  1.13s/it]Loading train:   5%|▌         | 29/532 [00:32<09:28,  1.13s/it]Loading train:   6%|▌         | 30/532 [00:33<09:23,  1.12s/it]Loading train:   6%|▌         | 31/532 [00:34<08:50,  1.06s/it]Loading train:   6%|▌         | 32/532 [00:35<09:14,  1.11s/it]Loading train:   6%|▌         | 33/532 [00:36<08:32,  1.03s/it]Loading train:   6%|▋         | 34/532 [00:37<09:02,  1.09s/it]Loading train:   7%|▋         | 35/532 [00:38<08:51,  1.07s/it]Loading train:   7%|▋         | 36/532 [00:39<09:16,  1.12s/it]Loading train:   7%|▋         | 37/532 [00:40<08:46,  1.06s/it]Loading train:   7%|▋         | 38/532 [00:41<09:04,  1.10s/it]Loading train:   7%|▋         | 39/532 [00:42<08:37,  1.05s/it]Loading train:   8%|▊         | 40/532 [00:43<08:22,  1.02s/it]Loading train:   8%|▊         | 41/532 [00:44<08:32,  1.04s/it]Loading train:   8%|▊         | 42/532 [00:46<08:37,  1.06s/it]Loading train:   8%|▊         | 43/532 [00:46<08:12,  1.01s/it]Loading train:   8%|▊         | 44/532 [00:47<07:34,  1.07it/s]Loading train:   8%|▊         | 45/532 [00:48<07:51,  1.03it/s]Loading train:   9%|▊         | 46/532 [00:49<08:04,  1.00it/s]Loading train:   9%|▉         | 47/532 [00:51<08:46,  1.08s/it]Loading train:   9%|▉         | 48/532 [00:52<09:14,  1.15s/it]Loading train:   9%|▉         | 49/532 [00:53<08:35,  1.07s/it]Loading train:   9%|▉         | 50/532 [00:54<09:39,  1.20s/it]Loading train:  10%|▉         | 51/532 [00:55<08:54,  1.11s/it]Loading train:  10%|▉         | 52/532 [00:56<08:46,  1.10s/it]Loading train:  10%|▉         | 53/532 [00:57<08:25,  1.06s/it]Loading train:  10%|█         | 54/532 [00:58<08:56,  1.12s/it]Loading train:  10%|█         | 55/532 [01:00<08:39,  1.09s/it]Loading train:  11%|█         | 56/532 [01:01<08:38,  1.09s/it]Loading train:  11%|█         | 57/532 [01:01<08:09,  1.03s/it]Loading train:  11%|█         | 58/532 [01:03<08:18,  1.05s/it]Loading train:  11%|█         | 59/532 [01:04<08:51,  1.12s/it]Loading train:  11%|█▏        | 60/532 [01:05<08:26,  1.07s/it]Loading train:  11%|█▏        | 61/532 [01:06<08:03,  1.03s/it]Loading train:  12%|█▏        | 62/532 [01:07<08:37,  1.10s/it]Loading train:  12%|█▏        | 63/532 [01:08<08:44,  1.12s/it]Loading train:  12%|█▏        | 64/532 [01:09<08:33,  1.10s/it]Loading train:  12%|█▏        | 65/532 [01:10<08:18,  1.07s/it]Loading train:  12%|█▏        | 66/532 [01:12<08:57,  1.15s/it]Loading train:  13%|█▎        | 67/532 [01:13<09:15,  1.19s/it]Loading train:  13%|█▎        | 68/532 [01:14<08:39,  1.12s/it]Loading train:  13%|█▎        | 69/532 [01:15<08:42,  1.13s/it]Loading train:  13%|█▎        | 70/532 [01:16<08:03,  1.05s/it]Loading train:  13%|█▎        | 71/532 [01:17<08:11,  1.07s/it]Loading train:  14%|█▎        | 72/532 [01:18<07:44,  1.01s/it]Loading train:  14%|█▎        | 73/532 [01:19<08:16,  1.08s/it]Loading train:  14%|█▍        | 74/532 [01:20<08:49,  1.16s/it]Loading train:  14%|█▍        | 75/532 [01:22<09:52,  1.30s/it]Loading train:  14%|█▍        | 76/532 [01:23<09:32,  1.26s/it]Loading train:  14%|█▍        | 77/532 [01:24<08:39,  1.14s/it]Loading train:  15%|█▍        | 78/532 [01:25<08:15,  1.09s/it]Loading train:  15%|█▍        | 79/532 [01:26<07:51,  1.04s/it]Loading train:  15%|█▌        | 80/532 [01:27<07:57,  1.06s/it]Loading train:  15%|█▌        | 81/532 [01:28<07:36,  1.01s/it]Loading train:  15%|█▌        | 82/532 [01:29<07:48,  1.04s/it]Loading train:  16%|█▌        | 83/532 [01:30<07:22,  1.02it/s]Loading train:  16%|█▌        | 84/532 [01:31<07:13,  1.03it/s]Loading train:  16%|█▌        | 85/532 [01:32<07:03,  1.05it/s]Loading train:  16%|█▌        | 86/532 [01:33<06:58,  1.07it/s]Loading train:  16%|█▋        | 87/532 [01:33<06:41,  1.11it/s]Loading train:  17%|█▋        | 88/532 [01:35<07:11,  1.03it/s]Loading train:  17%|█▋        | 89/532 [01:36<07:15,  1.02it/s]Loading train:  17%|█▋        | 90/532 [01:37<07:21,  1.00it/s]Loading train:  17%|█▋        | 91/532 [01:38<07:12,  1.02it/s]Loading train:  17%|█▋        | 92/532 [01:39<07:19,  1.00it/s]Loading train:  17%|█▋        | 93/532 [01:40<07:03,  1.04it/s]Loading train:  18%|█▊        | 94/532 [01:40<06:57,  1.05it/s]Loading train:  18%|█▊        | 95/532 [01:42<07:45,  1.06s/it]Loading train:  18%|█▊        | 96/532 [01:43<07:47,  1.07s/it]Loading train:  18%|█▊        | 97/532 [01:44<07:56,  1.09s/it]Loading train:  18%|█▊        | 98/532 [01:45<07:54,  1.09s/it]Loading train:  19%|█▊        | 99/532 [01:46<07:56,  1.10s/it]Loading train:  19%|█▉        | 100/532 [01:47<08:10,  1.13s/it]Loading train:  19%|█▉        | 101/532 [01:49<08:00,  1.11s/it]Loading train:  19%|█▉        | 102/532 [01:49<07:27,  1.04s/it]Loading train:  19%|█▉        | 103/532 [01:50<07:00,  1.02it/s]Loading train:  20%|█▉        | 104/532 [01:51<06:41,  1.07it/s]Loading train:  20%|█▉        | 105/532 [01:52<06:20,  1.12it/s]Loading train:  20%|█▉        | 106/532 [01:53<06:15,  1.13it/s]Loading train:  20%|██        | 107/532 [01:53<05:59,  1.18it/s]Loading train:  20%|██        | 108/532 [01:54<05:59,  1.18it/s]Loading train:  20%|██        | 109/532 [01:55<05:48,  1.21it/s]Loading train:  21%|██        | 110/532 [01:56<05:52,  1.20it/s]Loading train:  21%|██        | 111/532 [01:57<05:40,  1.24it/s]Loading train:  21%|██        | 112/532 [01:57<05:38,  1.24it/s]Loading train:  21%|██        | 113/532 [01:58<05:55,  1.18it/s]Loading train:  21%|██▏       | 114/532 [01:59<06:19,  1.10it/s]Loading train:  22%|██▏       | 115/532 [02:00<06:16,  1.11it/s]Loading train:  22%|██▏       | 116/532 [02:01<06:22,  1.09it/s]Loading train:  22%|██▏       | 117/532 [02:02<06:14,  1.11it/s]Loading train:  22%|██▏       | 118/532 [02:03<06:24,  1.08it/s]Loading train:  22%|██▏       | 119/532 [02:04<06:51,  1.00it/s]Loading train:  23%|██▎       | 120/532 [02:05<06:59,  1.02s/it]Loading train:  23%|██▎       | 121/532 [02:06<06:54,  1.01s/it]Loading train:  23%|██▎       | 122/532 [02:07<06:57,  1.02s/it]Loading train:  23%|██▎       | 123/532 [02:09<07:04,  1.04s/it]Loading train:  23%|██▎       | 124/532 [02:09<06:53,  1.01s/it]Loading train:  23%|██▎       | 125/532 [02:11<07:09,  1.05s/it]Loading train:  24%|██▎       | 126/532 [02:11<06:42,  1.01it/s]Loading train:  24%|██▍       | 127/532 [02:12<06:42,  1.01it/s]Loading train:  24%|██▍       | 128/532 [02:14<06:52,  1.02s/it]Loading train:  24%|██▍       | 129/532 [02:15<06:52,  1.02s/it]Loading train:  24%|██▍       | 130/532 [02:16<06:41,  1.00it/s]Loading train:  25%|██▍       | 131/532 [02:17<07:07,  1.07s/it]Loading train:  25%|██▍       | 132/532 [02:18<07:02,  1.06s/it]Loading train:  25%|██▌       | 133/532 [02:19<07:30,  1.13s/it]Loading train:  25%|██▌       | 134/532 [02:20<07:45,  1.17s/it]Loading train:  25%|██▌       | 135/532 [02:22<07:49,  1.18s/it]Loading train:  26%|██▌       | 136/532 [02:23<07:36,  1.15s/it]Loading train:  26%|██▌       | 137/532 [02:24<07:49,  1.19s/it]Loading train:  26%|██▌       | 138/532 [02:25<07:44,  1.18s/it]Loading train:  26%|██▌       | 139/532 [02:26<07:57,  1.21s/it]Loading train:  26%|██▋       | 140/532 [02:28<08:17,  1.27s/it]Loading train:  27%|██▋       | 141/532 [02:29<07:56,  1.22s/it]Loading train:  27%|██▋       | 142/532 [02:30<07:51,  1.21s/it]Loading train:  27%|██▋       | 143/532 [02:31<07:35,  1.17s/it]Loading train:  27%|██▋       | 144/532 [02:32<06:51,  1.06s/it]Loading train:  27%|██▋       | 145/532 [02:33<06:29,  1.01s/it]Loading train:  27%|██▋       | 146/532 [02:34<06:16,  1.03it/s]Loading train:  28%|██▊       | 147/532 [02:35<05:55,  1.08it/s]Loading train:  28%|██▊       | 148/532 [02:35<05:46,  1.11it/s]Loading train:  28%|██▊       | 149/532 [02:36<05:47,  1.10it/s]Loading train:  28%|██▊       | 150/532 [02:37<05:42,  1.12it/s]Loading train:  28%|██▊       | 151/532 [02:38<05:40,  1.12it/s]Loading train:  29%|██▊       | 152/532 [02:39<05:35,  1.13it/s]Loading train:  29%|██▉       | 153/532 [02:40<05:34,  1.13it/s]Loading train:  29%|██▉       | 154/532 [02:41<05:29,  1.15it/s]Loading train:  29%|██▉       | 155/532 [02:42<06:21,  1.01s/it]Loading train:  29%|██▉       | 156/532 [02:43<06:45,  1.08s/it]Loading train:  30%|██▉       | 157/532 [02:45<07:12,  1.15s/it]Loading train:  30%|██▉       | 158/532 [02:46<07:31,  1.21s/it]Loading train:  30%|██▉       | 159/532 [02:47<07:38,  1.23s/it]Loading train:  30%|███       | 160/532 [02:48<07:38,  1.23s/it]Loading train:  30%|███       | 161/532 [02:50<07:38,  1.24s/it]Loading train:  30%|███       | 162/532 [02:51<07:03,  1.14s/it]Loading train:  31%|███       | 163/532 [02:52<06:51,  1.12s/it]Loading train:  31%|███       | 164/532 [02:53<06:27,  1.05s/it]Loading train:  31%|███       | 165/532 [02:54<06:44,  1.10s/it]Loading train:  31%|███       | 166/532 [02:55<06:47,  1.11s/it]Loading train:  31%|███▏      | 167/532 [02:56<06:39,  1.10s/it]Loading train:  32%|███▏      | 168/532 [02:57<06:39,  1.10s/it]Loading train:  32%|███▏      | 169/532 [02:58<06:29,  1.07s/it]Loading train:  32%|███▏      | 170/532 [02:59<06:24,  1.06s/it]Loading train:  32%|███▏      | 171/532 [03:00<06:18,  1.05s/it]Loading train:  32%|███▏      | 172/532 [03:01<06:16,  1.05s/it]Loading train:  33%|███▎      | 173/532 [03:02<06:00,  1.00s/it]Loading train:  33%|███▎      | 174/532 [03:03<05:43,  1.04it/s]Loading train:  33%|███▎      | 175/532 [03:04<05:45,  1.03it/s]Loading train:  33%|███▎      | 176/532 [03:05<05:43,  1.04it/s]Loading train:  33%|███▎      | 177/532 [03:06<05:30,  1.07it/s]Loading train:  33%|███▎      | 178/532 [03:07<05:38,  1.05it/s]Loading train:  34%|███▎      | 179/532 [03:08<05:42,  1.03it/s]Loading train:  34%|███▍      | 180/532 [03:09<05:50,  1.01it/s]Loading train:  34%|███▍      | 181/532 [03:10<05:48,  1.01it/s]Loading train:  34%|███▍      | 182/532 [03:11<05:42,  1.02it/s]Loading train:  34%|███▍      | 183/532 [03:12<05:32,  1.05it/s]Loading train:  35%|███▍      | 184/532 [03:13<05:28,  1.06it/s]Loading train:  35%|███▍      | 185/532 [03:14<05:35,  1.03it/s]Loading train:  35%|███▍      | 186/532 [03:15<05:40,  1.02it/s]Loading train:  35%|███▌      | 187/532 [03:15<05:30,  1.04it/s]Loading train:  35%|███▌      | 188/532 [03:16<05:20,  1.07it/s]Loading train:  36%|███▌      | 189/532 [03:17<05:25,  1.05it/s]Loading train:  36%|███▌      | 190/532 [03:18<05:22,  1.06it/s]Loading train:  36%|███▌      | 191/532 [03:20<06:05,  1.07s/it]Loading train:  36%|███▌      | 192/532 [03:21<06:26,  1.14s/it]Loading train:  36%|███▋      | 193/532 [03:22<06:29,  1.15s/it]Loading train:  36%|███▋      | 194/532 [03:23<06:37,  1.18s/it]Loading train:  37%|███▋      | 195/532 [03:25<06:40,  1.19s/it]Loading train:  37%|███▋      | 196/532 [03:26<06:53,  1.23s/it]Loading train:  37%|███▋      | 197/532 [03:27<06:38,  1.19s/it]Loading train:  37%|███▋      | 198/532 [03:28<06:16,  1.13s/it]Loading train:  37%|███▋      | 199/532 [03:29<06:07,  1.10s/it]Loading train:  38%|███▊      | 200/532 [03:30<05:57,  1.08s/it]Loading train:  38%|███▊      | 201/532 [03:31<05:53,  1.07s/it]Loading train:  38%|███▊      | 202/532 [03:32<05:48,  1.06s/it]Loading train:  38%|███▊      | 203/532 [03:33<05:54,  1.08s/it]Loading train:  38%|███▊      | 204/532 [03:34<05:34,  1.02s/it]Loading train:  39%|███▊      | 205/532 [03:35<05:21,  1.02it/s]Loading train:  39%|███▊      | 206/532 [03:36<05:16,  1.03it/s]Loading train:  39%|███▉      | 207/532 [03:37<05:04,  1.07it/s]Loading train:  39%|███▉      | 208/532 [03:38<05:13,  1.03it/s]Loading train:  39%|███▉      | 209/532 [03:39<05:01,  1.07it/s]Loading train:  39%|███▉      | 210/532 [03:40<05:39,  1.05s/it]Loading train:  40%|███▉      | 211/532 [03:41<05:18,  1.01it/s]Loading train:  40%|███▉      | 212/532 [03:42<05:08,  1.04it/s]Loading train:  40%|████      | 213/532 [03:43<04:54,  1.08it/s]Loading train:  40%|████      | 214/532 [03:44<04:58,  1.07it/s]Loading train:  40%|████      | 215/532 [03:45<05:32,  1.05s/it]Loading train:  41%|████      | 216/532 [03:46<05:38,  1.07s/it]Loading train:  41%|████      | 217/532 [03:47<06:02,  1.15s/it]Loading train:  41%|████      | 218/532 [03:49<06:06,  1.17s/it]Loading train:  41%|████      | 219/532 [03:50<06:00,  1.15s/it]Loading train:  41%|████▏     | 220/532 [03:51<06:08,  1.18s/it]Loading train:  42%|████▏     | 221/532 [03:52<05:34,  1.08s/it]Loading train:  42%|████▏     | 222/532 [03:53<05:20,  1.03s/it]Loading train:  42%|████▏     | 223/532 [03:53<04:58,  1.03it/s]Loading train:  42%|████▏     | 224/532 [03:54<05:00,  1.02it/s]Loading train:  42%|████▏     | 225/532 [03:55<04:40,  1.10it/s]Loading train:  42%|████▏     | 226/532 [03:56<04:27,  1.14it/s]Loading train:  43%|████▎     | 227/532 [03:57<04:21,  1.16it/s]Loading train:  43%|████▎     | 228/532 [03:58<04:09,  1.22it/s]Loading train:  43%|████▎     | 229/532 [03:58<04:08,  1.22it/s]Loading train:  43%|████▎     | 230/532 [03:59<03:57,  1.27it/s]Loading train:  43%|████▎     | 231/532 [04:00<04:07,  1.22it/s]Loading train:  44%|████▎     | 232/532 [04:01<03:54,  1.28it/s]Loading train:  44%|████▍     | 233/532 [04:02<04:03,  1.23it/s]Loading train:  44%|████▍     | 234/532 [04:02<04:06,  1.21it/s]Loading train:  44%|████▍     | 235/532 [04:03<04:05,  1.21it/s]Loading train:  44%|████▍     | 236/532 [04:04<04:09,  1.19it/s]Loading train:  45%|████▍     | 237/532 [04:05<04:14,  1.16it/s]Loading train:  45%|████▍     | 238/532 [04:06<04:14,  1.15it/s]Loading train:  45%|████▍     | 239/532 [04:07<04:22,  1.12it/s]Loading train:  45%|████▌     | 240/532 [04:08<04:24,  1.10it/s]Loading train:  45%|████▌     | 241/532 [04:09<04:22,  1.11it/s]Loading train:  45%|████▌     | 242/532 [04:10<04:27,  1.08it/s]Loading train:  46%|████▌     | 243/532 [04:11<04:37,  1.04it/s]Loading train:  46%|████▌     | 244/532 [04:12<04:32,  1.06it/s]Loading train:  46%|████▌     | 245/532 [04:13<04:34,  1.05it/s]Loading train:  46%|████▌     | 246/532 [04:13<04:17,  1.11it/s]Loading train:  46%|████▋     | 247/532 [04:14<04:07,  1.15it/s]Loading train:  47%|████▋     | 248/532 [04:15<04:00,  1.18it/s]Loading train:  47%|████▋     | 249/532 [04:16<03:49,  1.23it/s]Loading train:  47%|████▋     | 250/532 [04:16<03:42,  1.27it/s]Loading train:  47%|████▋     | 251/532 [04:17<04:00,  1.17it/s]Loading train:  47%|████▋     | 252/532 [04:18<04:00,  1.16it/s]Loading train:  48%|████▊     | 253/532 [04:19<04:14,  1.10it/s]Loading train:  48%|████▊     | 254/532 [04:20<04:10,  1.11it/s]Loading train:  48%|████▊     | 255/532 [04:21<04:10,  1.11it/s]Loading train:  48%|████▊     | 256/532 [04:22<04:01,  1.14it/s]Loading train:  48%|████▊     | 257/532 [04:23<04:31,  1.01it/s]Loading train:  48%|████▊     | 258/532 [04:24<04:35,  1.00s/it]Loading train:  49%|████▊     | 259/532 [04:25<04:39,  1.02s/it]Loading train:  49%|████▉     | 260/532 [04:26<04:39,  1.03s/it]Loading train:  49%|████▉     | 261/532 [04:27<04:34,  1.01s/it]Loading train:  49%|████▉     | 262/532 [04:29<04:44,  1.05s/it]Loading train:  49%|████▉     | 263/532 [04:29<04:23,  1.02it/s]Loading train:  50%|████▉     | 264/532 [04:30<04:28,  1.00s/it]Loading train:  50%|████▉     | 265/532 [04:31<04:21,  1.02it/s]Loading train:  50%|█████     | 266/532 [04:32<04:03,  1.09it/s]Loading train:  50%|█████     | 267/532 [04:33<03:47,  1.17it/s]Loading train:  50%|█████     | 268/532 [04:34<03:38,  1.21it/s]Loading train:  51%|█████     | 269/532 [04:35<04:00,  1.09it/s]Loading train:  51%|█████     | 270/532 [04:36<04:02,  1.08it/s]Loading train:  51%|█████     | 271/532 [04:37<04:01,  1.08it/s]Loading train:  51%|█████     | 272/532 [04:37<04:01,  1.08it/s]Loading train:  51%|█████▏    | 273/532 [04:38<03:59,  1.08it/s]Loading train:  52%|█████▏    | 274/532 [04:39<04:05,  1.05it/s]Loading train:  52%|█████▏    | 275/532 [04:41<04:29,  1.05s/it]Loading train:  52%|█████▏    | 276/532 [04:42<04:38,  1.09s/it]Loading train:  52%|█████▏    | 277/532 [04:43<04:38,  1.09s/it]Loading train:  52%|█████▏    | 278/532 [04:44<04:48,  1.13s/it]Loading train:  52%|█████▏    | 279/532 [04:45<04:46,  1.13s/it]Loading train:  53%|█████▎    | 280/532 [04:47<04:57,  1.18s/it]Loading train:  53%|█████▎    | 281/532 [04:48<04:55,  1.18s/it]Loading train:  53%|█████▎    | 282/532 [04:49<04:53,  1.17s/it]Loading train:  53%|█████▎    | 283/532 [04:50<04:47,  1.16s/it]Loading train:  53%|█████▎    | 284/532 [04:51<04:37,  1.12s/it]Loading train:  54%|█████▎    | 285/532 [04:52<04:36,  1.12s/it]Loading train:  54%|█████▍    | 286/532 [04:53<04:37,  1.13s/it]Loading train:  54%|█████▍    | 287/532 [04:54<04:21,  1.07s/it]Loading train:  54%|█████▍    | 288/532 [04:55<04:05,  1.00s/it]Loading train:  54%|█████▍    | 289/532 [04:56<03:51,  1.05it/s]Loading train:  55%|█████▍    | 290/532 [04:57<03:38,  1.11it/s]Loading train:  55%|█████▍    | 291/532 [04:58<03:30,  1.14it/s]Loading train:  55%|█████▍    | 292/532 [04:58<03:31,  1.13it/s]Loading train:  55%|█████▌    | 293/532 [05:00<03:47,  1.05it/s]Loading train:  55%|█████▌    | 294/532 [05:01<03:49,  1.04it/s]Loading train:  55%|█████▌    | 295/532 [05:02<03:59,  1.01s/it]Loading train:  56%|█████▌    | 296/532 [05:03<03:56,  1.00s/it]Loading train:  56%|█████▌    | 297/532 [05:04<04:03,  1.04s/it]Loading train:  56%|█████▌    | 298/532 [05:05<03:58,  1.02s/it]Loading train:  56%|█████▌    | 299/532 [05:06<03:45,  1.03it/s]Loading train:  56%|█████▋    | 300/532 [05:06<03:31,  1.10it/s]Loading train:  57%|█████▋    | 301/532 [05:07<03:27,  1.11it/s]Loading train:  57%|█████▋    | 302/532 [05:08<03:24,  1.12it/s]Loading train:  57%|█████▋    | 303/532 [05:09<03:19,  1.15it/s]Loading train:  57%|█████▋    | 304/532 [05:10<03:17,  1.15it/s]Loading train:  57%|█████▋    | 305/532 [05:11<03:44,  1.01it/s]Loading train:  58%|█████▊    | 306/532 [05:12<03:52,  1.03s/it]Loading train:  58%|█████▊    | 307/532 [05:13<03:58,  1.06s/it]Loading train:  58%|█████▊    | 308/532 [05:15<04:11,  1.12s/it]Loading train:  58%|█████▊    | 309/532 [05:16<04:16,  1.15s/it]Loading train:  58%|█████▊    | 310/532 [05:17<04:12,  1.14s/it]Loading train:  58%|█████▊    | 311/532 [05:19<04:52,  1.32s/it]Loading train:  59%|█████▊    | 312/532 [05:20<05:12,  1.42s/it]Loading train:  59%|█████▉    | 313/532 [05:22<05:25,  1.49s/it]Loading train:  59%|█████▉    | 314/532 [05:24<05:38,  1.55s/it]Loading train:  59%|█████▉    | 315/532 [05:25<05:41,  1.57s/it]Loading train:  59%|█████▉    | 316/532 [05:27<05:36,  1.56s/it]Loading train:  60%|█████▉    | 317/532 [05:28<05:05,  1.42s/it]Loading train:  60%|█████▉    | 318/532 [05:29<04:23,  1.23s/it]Loading train:  60%|█████▉    | 319/532 [05:30<03:59,  1.12s/it]Loading train:  60%|██████    | 320/532 [05:31<03:51,  1.09s/it]Loading train:  60%|██████    | 321/532 [05:31<03:30,  1.00it/s]Loading train:  61%|██████    | 322/532 [05:32<03:23,  1.03it/s]Loading train:  61%|██████    | 323/532 [05:34<03:38,  1.05s/it]Loading train:  61%|██████    | 324/532 [05:35<03:55,  1.13s/it]Loading train:  61%|██████    | 325/532 [05:36<03:57,  1.15s/it]Loading train:  61%|██████▏   | 326/532 [05:37<04:10,  1.22s/it]Loading train:  61%|██████▏   | 327/532 [05:39<04:09,  1.22s/it]Loading train:  62%|██████▏   | 328/532 [05:40<04:15,  1.25s/it]Loading train:  62%|██████▏   | 329/532 [05:41<04:05,  1.21s/it]Loading train:  62%|██████▏   | 330/532 [05:42<03:50,  1.14s/it]Loading train:  62%|██████▏   | 331/532 [05:43<03:35,  1.07s/it]Loading train:  62%|██████▏   | 332/532 [05:44<03:41,  1.11s/it]Loading train:  63%|██████▎   | 333/532 [05:45<03:24,  1.03s/it]Loading train:  63%|██████▎   | 334/532 [05:46<03:19,  1.01s/it]Loading train:  63%|██████▎   | 335/532 [05:47<03:24,  1.04s/it]Loading train:  63%|██████▎   | 336/532 [05:48<03:30,  1.08s/it]Loading train:  63%|██████▎   | 337/532 [05:49<03:26,  1.06s/it]Loading train:  64%|██████▎   | 338/532 [05:50<03:26,  1.07s/it]Loading train:  64%|██████▎   | 339/532 [05:51<03:22,  1.05s/it]Loading train:  64%|██████▍   | 340/532 [05:52<03:26,  1.08s/it]Loading train:  64%|██████▍   | 341/532 [05:53<03:16,  1.03s/it]Loading train:  64%|██████▍   | 342/532 [05:54<03:03,  1.04it/s]Loading train:  64%|██████▍   | 343/532 [05:55<02:59,  1.05it/s]Loading train:  65%|██████▍   | 344/532 [05:56<02:51,  1.09it/s]Loading train:  65%|██████▍   | 345/532 [05:57<02:50,  1.09it/s]Loading train:  65%|██████▌   | 346/532 [05:58<02:53,  1.07it/s]Loading train:  65%|██████▌   | 347/532 [05:59<02:45,  1.11it/s]Loading train:  65%|██████▌   | 348/532 [06:00<02:51,  1.07it/s]Loading train:  66%|██████▌   | 349/532 [06:00<02:43,  1.12it/s]Loading train:  66%|██████▌   | 350/532 [06:01<02:41,  1.13it/s]Loading train:  66%|██████▌   | 351/532 [06:02<02:48,  1.08it/s]Loading train:  66%|██████▌   | 352/532 [06:03<02:45,  1.08it/s]Loading train:  66%|██████▋   | 353/532 [06:04<02:56,  1.02it/s]Loading train:  67%|██████▋   | 354/532 [06:05<02:49,  1.05it/s]Loading train:  67%|██████▋   | 355/532 [06:06<02:45,  1.07it/s]Loading train:  67%|██████▋   | 356/532 [06:07<02:40,  1.10it/s]Loading train:  67%|██████▋   | 357/532 [06:08<02:37,  1.11it/s]Loading train:  67%|██████▋   | 358/532 [06:09<02:43,  1.06it/s]Loading train:  67%|██████▋   | 359/532 [06:10<03:05,  1.07s/it]Loading train:  68%|██████▊   | 360/532 [06:12<03:23,  1.18s/it]Loading train:  68%|██████▊   | 361/532 [06:13<03:36,  1.27s/it]Loading train:  68%|██████▊   | 362/532 [06:14<03:22,  1.19s/it]Loading train:  68%|██████▊   | 363/532 [06:16<03:37,  1.29s/it]Loading train:  68%|██████▊   | 364/532 [06:17<03:52,  1.38s/it]Loading train:  69%|██████▊   | 365/532 [06:19<03:50,  1.38s/it]Loading train:  69%|██████▉   | 366/532 [06:20<03:24,  1.23s/it]Loading train:  69%|██████▉   | 367/532 [06:21<03:30,  1.28s/it]Loading train:  69%|██████▉   | 368/532 [06:22<03:18,  1.21s/it]Loading train:  69%|██████▉   | 369/532 [06:23<03:18,  1.22s/it]Loading train:  70%|██████▉   | 370/532 [06:24<03:07,  1.15s/it]Loading train:  70%|██████▉   | 371/532 [06:26<03:37,  1.35s/it]Loading train:  70%|██████▉   | 372/532 [06:28<04:04,  1.53s/it]Loading train:  70%|███████   | 373/532 [06:30<04:21,  1.64s/it]Loading train:  70%|███████   | 374/532 [06:32<04:29,  1.70s/it]Loading train:  70%|███████   | 375/532 [06:33<04:15,  1.63s/it]Loading train:  71%|███████   | 376/532 [06:35<04:07,  1.59s/it]Loading train:  71%|███████   | 377/532 [06:36<03:58,  1.54s/it]Loading train:  71%|███████   | 378/532 [06:37<03:40,  1.43s/it]Loading train:  71%|███████   | 379/532 [06:39<03:34,  1.40s/it]Loading train:  71%|███████▏  | 380/532 [06:40<03:42,  1.46s/it]Loading train:  72%|███████▏  | 381/532 [06:42<03:29,  1.39s/it]Loading train:  72%|███████▏  | 382/532 [06:43<03:32,  1.41s/it]Loading train:  72%|███████▏  | 383/532 [06:45<03:46,  1.52s/it]Loading train:  72%|███████▏  | 384/532 [06:46<03:32,  1.43s/it]Loading train:  72%|███████▏  | 385/532 [06:47<03:25,  1.40s/it]Loading train:  73%|███████▎  | 386/532 [06:49<03:28,  1.43s/it]Loading train:  73%|███████▎  | 387/532 [06:50<03:16,  1.36s/it]Loading train:  73%|███████▎  | 388/532 [06:52<03:31,  1.47s/it]Loading train:  73%|███████▎  | 389/532 [06:53<03:39,  1.54s/it]Loading train:  73%|███████▎  | 390/532 [06:55<03:37,  1.53s/it]Loading train:  73%|███████▎  | 391/532 [06:57<03:49,  1.63s/it]Loading train:  74%|███████▎  | 392/532 [06:58<03:35,  1.54s/it]Loading train:  74%|███████▍  | 393/532 [06:59<03:25,  1.48s/it]Loading train:  74%|███████▍  | 394/532 [07:01<03:18,  1.44s/it]Loading train:  74%|███████▍  | 395/532 [07:02<03:12,  1.40s/it]Loading train:  74%|███████▍  | 396/532 [07:04<03:14,  1.43s/it]Loading train:  75%|███████▍  | 397/532 [07:05<03:03,  1.36s/it]Loading train:  75%|███████▍  | 398/532 [07:06<02:52,  1.29s/it]Loading train:  75%|███████▌  | 399/532 [07:08<03:03,  1.38s/it]Loading train:  75%|███████▌  | 400/532 [07:09<03:06,  1.41s/it]Loading train:  75%|███████▌  | 401/532 [07:11<03:22,  1.55s/it]Loading train:  76%|███████▌  | 402/532 [07:12<03:22,  1.56s/it]Loading train:  76%|███████▌  | 403/532 [07:14<03:19,  1.54s/it]Loading train:  76%|███████▌  | 404/532 [07:15<03:11,  1.50s/it]Loading train:  76%|███████▌  | 405/532 [07:17<03:14,  1.53s/it]Loading train:  76%|███████▋  | 406/532 [07:18<03:09,  1.50s/it]Loading train:  77%|███████▋  | 407/532 [07:20<03:06,  1.49s/it]Loading train:  77%|███████▋  | 408/532 [07:21<02:58,  1.44s/it]Loading train:  77%|███████▋  | 409/532 [07:23<02:52,  1.41s/it]Loading train:  77%|███████▋  | 410/532 [07:24<02:48,  1.38s/it]Loading train:  77%|███████▋  | 411/532 [07:25<02:50,  1.41s/it]Loading train:  77%|███████▋  | 412/532 [07:27<02:52,  1.44s/it]Loading train:  78%|███████▊  | 413/532 [07:29<03:05,  1.56s/it]Loading train:  78%|███████▊  | 414/532 [07:30<02:55,  1.49s/it]Loading train:  78%|███████▊  | 415/532 [07:31<02:43,  1.40s/it]Loading train:  78%|███████▊  | 416/532 [07:32<02:31,  1.31s/it]Loading train:  78%|███████▊  | 417/532 [07:34<02:34,  1.34s/it]Loading train:  79%|███████▊  | 418/532 [07:35<02:27,  1.29s/it]Loading train:  79%|███████▉  | 419/532 [07:37<02:40,  1.42s/it]Loading train:  79%|███████▉  | 420/532 [07:38<02:31,  1.35s/it]Loading train:  79%|███████▉  | 421/532 [07:39<02:30,  1.35s/it]Loading train:  79%|███████▉  | 422/532 [07:40<02:25,  1.32s/it]Loading train:  80%|███████▉  | 423/532 [07:42<02:20,  1.29s/it]Loading train:  80%|███████▉  | 424/532 [07:43<02:12,  1.22s/it]Loading train:  80%|███████▉  | 425/532 [07:44<02:21,  1.32s/it]Loading train:  80%|████████  | 426/532 [07:46<02:22,  1.34s/it]Loading train:  80%|████████  | 427/532 [07:47<02:35,  1.48s/it]Loading train:  80%|████████  | 428/532 [07:49<02:38,  1.52s/it]Loading train:  81%|████████  | 429/532 [07:51<02:37,  1.53s/it]Loading train:  81%|████████  | 430/532 [07:52<02:38,  1.55s/it]Loading train:  81%|████████  | 431/532 [07:54<02:54,  1.73s/it]Loading train:  81%|████████  | 432/532 [07:56<02:49,  1.69s/it]Loading train:  81%|████████▏ | 433/532 [07:58<02:47,  1.70s/it]Loading train:  82%|████████▏ | 434/532 [07:59<02:45,  1.69s/it]Loading train:  82%|████████▏ | 435/532 [08:01<02:42,  1.68s/it]Loading train:  82%|████████▏ | 436/532 [08:02<02:35,  1.62s/it]Loading train:  82%|████████▏ | 437/532 [08:04<02:19,  1.47s/it]Loading train:  82%|████████▏ | 438/532 [08:05<02:15,  1.44s/it]Loading train:  83%|████████▎ | 439/532 [08:06<02:14,  1.45s/it]Loading train:  83%|████████▎ | 440/532 [08:08<02:04,  1.35s/it]Loading train:  83%|████████▎ | 441/532 [08:09<02:01,  1.33s/it]Loading train:  83%|████████▎ | 442/532 [08:10<01:52,  1.25s/it]Loading train:  83%|████████▎ | 443/532 [08:11<01:53,  1.28s/it]Loading train:  83%|████████▎ | 444/532 [08:12<01:51,  1.27s/it]Loading train:  84%|████████▎ | 445/532 [08:14<01:49,  1.26s/it]Loading train:  84%|████████▍ | 446/532 [08:15<01:54,  1.33s/it]Loading train:  84%|████████▍ | 447/532 [08:17<01:52,  1.33s/it]Loading train:  84%|████████▍ | 448/532 [08:18<01:57,  1.40s/it]Loading train:  84%|████████▍ | 449/532 [08:19<01:55,  1.39s/it]Loading train:  85%|████████▍ | 450/532 [08:21<01:51,  1.36s/it]Loading train:  85%|████████▍ | 451/532 [08:22<01:46,  1.32s/it]Loading train:  85%|████████▍ | 452/532 [08:23<01:39,  1.24s/it]Loading train:  85%|████████▌ | 453/532 [08:24<01:39,  1.25s/it]Loading train:  85%|████████▌ | 454/532 [08:26<01:38,  1.26s/it]Loading train:  86%|████████▌ | 455/532 [08:27<01:45,  1.37s/it]Loading train:  86%|████████▌ | 456/532 [08:29<01:51,  1.47s/it]Loading train:  86%|████████▌ | 457/532 [08:30<01:50,  1.47s/it]Loading train:  86%|████████▌ | 458/532 [08:32<01:42,  1.38s/it]Loading train:  86%|████████▋ | 459/532 [08:33<01:36,  1.32s/it]Loading train:  86%|████████▋ | 460/532 [08:34<01:34,  1.31s/it]Loading train:  87%|████████▋ | 461/532 [08:36<01:49,  1.54s/it]Loading train:  87%|████████▋ | 462/532 [08:38<02:02,  1.75s/it]Loading train:  87%|████████▋ | 463/532 [08:41<02:11,  1.90s/it]Loading train:  87%|████████▋ | 464/532 [08:43<02:12,  1.95s/it]Loading train:  87%|████████▋ | 465/532 [08:44<02:05,  1.88s/it]Loading train:  88%|████████▊ | 466/532 [08:46<02:01,  1.83s/it]Loading train:  88%|████████▊ | 467/532 [08:48<01:55,  1.78s/it]Loading train:  88%|████████▊ | 468/532 [08:49<01:43,  1.61s/it]Loading train:  88%|████████▊ | 469/532 [08:51<01:40,  1.60s/it]Loading train:  88%|████████▊ | 470/532 [08:52<01:28,  1.42s/it]Loading train:  89%|████████▊ | 471/532 [08:53<01:25,  1.40s/it]Loading train:  89%|████████▊ | 472/532 [08:54<01:19,  1.33s/it]Loading train:  89%|████████▉ | 473/532 [08:56<01:24,  1.44s/it]Loading train:  89%|████████▉ | 474/532 [08:57<01:20,  1.38s/it]Loading train:  89%|████████▉ | 475/532 [08:58<01:19,  1.40s/it]Loading train:  89%|████████▉ | 476/532 [09:00<01:13,  1.32s/it]Loading train:  90%|████████▉ | 477/532 [09:01<01:09,  1.27s/it]Loading train:  90%|████████▉ | 478/532 [09:02<01:10,  1.30s/it]Loading train:  90%|█████████ | 479/532 [09:03<01:08,  1.29s/it]Loading train:  90%|█████████ | 480/532 [09:04<01:03,  1.21s/it]Loading train:  90%|█████████ | 481/532 [09:06<01:03,  1.24s/it]Loading train:  91%|█████████ | 482/532 [09:07<01:00,  1.21s/it]Loading train:  91%|█████████ | 483/532 [09:08<00:58,  1.19s/it]Loading train:  91%|█████████ | 484/532 [09:09<00:59,  1.23s/it]Loading train:  91%|█████████ | 485/532 [09:11<01:07,  1.44s/it]Loading train:  91%|█████████▏| 486/532 [09:13<01:07,  1.48s/it]Loading train:  92%|█████████▏| 487/532 [09:14<01:06,  1.48s/it]Loading train:  92%|█████████▏| 488/532 [09:16<01:07,  1.54s/it]Loading train:  92%|█████████▏| 489/532 [09:18<01:10,  1.63s/it]Loading train:  92%|█████████▏| 490/532 [09:19<01:08,  1.63s/it]Loading train:  92%|█████████▏| 491/532 [09:21<01:03,  1.54s/it]Loading train:  92%|█████████▏| 492/532 [09:22<00:58,  1.47s/it]Loading train:  93%|█████████▎| 493/532 [09:23<00:53,  1.37s/it]Loading train:  93%|█████████▎| 494/532 [09:25<00:52,  1.38s/it]Loading train:  93%|█████████▎| 495/532 [09:26<00:51,  1.39s/it]Loading train:  93%|█████████▎| 496/532 [09:28<00:51,  1.43s/it]Loading train:  93%|█████████▎| 497/532 [09:29<00:49,  1.41s/it]Loading train:  94%|█████████▎| 498/532 [09:30<00:45,  1.34s/it]Loading train:  94%|█████████▍| 499/532 [09:32<00:44,  1.36s/it]Loading train:  94%|█████████▍| 500/532 [09:33<00:45,  1.41s/it]Loading train:  94%|█████████▍| 501/532 [09:35<00:47,  1.53s/it]Loading train:  94%|█████████▍| 502/532 [09:37<00:46,  1.57s/it]Loading train:  95%|█████████▍| 503/532 [09:38<00:43,  1.51s/it]Loading train:  95%|█████████▍| 504/532 [09:39<00:41,  1.49s/it]Loading train:  95%|█████████▍| 505/532 [09:41<00:39,  1.48s/it]Loading train:  95%|█████████▌| 506/532 [09:42<00:37,  1.45s/it]Loading train:  95%|█████████▌| 507/532 [09:43<00:33,  1.35s/it]Loading train:  95%|█████████▌| 508/532 [09:45<00:31,  1.32s/it]Loading train:  96%|█████████▌| 509/532 [09:46<00:32,  1.43s/it]Loading train:  96%|█████████▌| 510/532 [09:48<00:32,  1.49s/it]Loading train:  96%|█████████▌| 511/532 [09:50<00:32,  1.57s/it]Loading train:  96%|█████████▌| 512/532 [09:51<00:30,  1.51s/it]Loading train:  96%|█████████▋| 513/532 [09:53<00:29,  1.55s/it]Loading train:  97%|█████████▋| 514/532 [09:55<00:30,  1.67s/it]Loading train:  97%|█████████▋| 515/532 [09:57<00:29,  1.74s/it]Loading train:  97%|█████████▋| 516/532 [09:58<00:26,  1.63s/it]Loading train:  97%|█████████▋| 517/532 [09:59<00:22,  1.51s/it]Loading train:  97%|█████████▋| 518/532 [10:00<00:20,  1.43s/it]Loading train:  98%|█████████▊| 519/532 [10:01<00:16,  1.31s/it]Loading train:  98%|█████████▊| 520/532 [10:03<00:15,  1.30s/it]Loading train:  98%|█████████▊| 521/532 [10:04<00:15,  1.37s/it]Loading train:  98%|█████████▊| 522/532 [10:06<00:14,  1.49s/it]Loading train:  98%|█████████▊| 523/532 [10:08<00:13,  1.53s/it]Loading train:  98%|█████████▊| 524/532 [10:09<00:11,  1.49s/it]Loading train:  99%|█████████▊| 525/532 [10:11<00:10,  1.51s/it]Loading train:  99%|█████████▉| 526/532 [10:12<00:09,  1.53s/it]Loading train:  99%|█████████▉| 527/532 [10:13<00:07,  1.48s/it]Loading train:  99%|█████████▉| 528/532 [10:15<00:05,  1.38s/it]Loading train:  99%|█████████▉| 529/532 [10:16<00:04,  1.37s/it]Loading train: 100%|█████████▉| 530/532 [10:17<00:02,  1.32s/it]Loading train: 100%|█████████▉| 531/532 [10:19<00:01,  1.33s/it]Loading train: 100%|██████████| 532/532 [10:20<00:00,  1.31s/it]
concatenating: train:   0%|          | 0/532 [00:00<?, ?it/s]concatenating: train:   1%|          | 3/532 [00:00<00:22, 23.68it/s]concatenating: train:   2%|▏         | 9/532 [00:00<00:18, 27.97it/s]concatenating: train:   4%|▍         | 22/532 [00:00<00:13, 36.54it/s]concatenating: train:   8%|▊         | 40/532 [00:00<00:10, 47.90it/s]concatenating: train:   9%|▉         | 49/532 [00:00<00:10, 46.81it/s]concatenating: train:  11%|█         | 57/532 [00:00<00:12, 39.23it/s]concatenating: train:  12%|█▏        | 64/532 [00:01<00:15, 30.04it/s]concatenating: train:  13%|█▎        | 69/532 [00:01<00:16, 28.32it/s]concatenating: train:  14%|█▍        | 74/532 [00:01<00:15, 30.42it/s]concatenating: train:  15%|█▍        | 79/532 [00:01<00:15, 29.71it/s]concatenating: train:  16%|█▌        | 83/532 [00:01<00:15, 29.49it/s]concatenating: train:  17%|█▋        | 88/532 [00:02<00:13, 32.83it/s]concatenating: train:  18%|█▊        | 94/532 [00:02<00:12, 36.07it/s]concatenating: train:  19%|█▉        | 100/532 [00:02<00:10, 40.97it/s]concatenating: train:  20%|█▉        | 106/532 [00:02<00:09, 43.70it/s]concatenating: train:  21%|██        | 112/532 [00:02<00:08, 47.53it/s]concatenating: train:  23%|██▎       | 124/532 [00:02<00:07, 57.60it/s]concatenating: train:  26%|██▌       | 138/532 [00:02<00:05, 69.66it/s]concatenating: train:  29%|██▉       | 155/532 [00:02<00:04, 83.73it/s]concatenating: train:  31%|███▏      | 167/532 [00:02<00:04, 83.50it/s]concatenating: train:  34%|███▎      | 179/532 [00:03<00:03, 91.05it/s]concatenating: train:  36%|███▌      | 190/532 [00:03<00:03, 91.18it/s]concatenating: train:  38%|███▊      | 201/532 [00:03<00:03, 87.14it/s]concatenating: train:  40%|███▉      | 211/532 [00:03<00:04, 80.17it/s]concatenating: train:  41%|████▏     | 220/532 [00:03<00:04, 71.78it/s]concatenating: train:  43%|████▎     | 228/532 [00:03<00:04, 70.81it/s]concatenating: train:  44%|████▍     | 236/532 [00:03<00:05, 58.60it/s]concatenating: train:  46%|████▌     | 243/532 [00:04<00:04, 60.20it/s]concatenating: train:  47%|████▋     | 250/532 [00:04<00:04, 61.66it/s]concatenating: train:  48%|████▊     | 257/532 [00:04<00:04, 56.51it/s]concatenating: train:  49%|████▉     | 263/532 [00:04<00:04, 56.86it/s]concatenating: train:  51%|█████     | 271/532 [00:04<00:04, 61.12it/s]concatenating: train:  53%|█████▎    | 283/532 [00:04<00:03, 71.61it/s]concatenating: train:  56%|█████▌    | 296/532 [00:04<00:02, 82.13it/s]concatenating: train:  58%|█████▊    | 307/532 [00:04<00:02, 87.30it/s]concatenating: train:  60%|█████▉    | 318/532 [00:04<00:02, 92.01it/s]concatenating: train:  62%|██████▏   | 330/532 [00:05<00:02, 97.97it/s]concatenating: train:  64%|██████▍   | 342/532 [00:05<00:01, 102.61it/s]concatenating: train:  66%|██████▋   | 353/532 [00:05<00:01, 103.53it/s]concatenating: train:  68%|██████▊   | 364/532 [00:05<00:01, 105.34it/s]concatenating: train:  70%|███████   | 375/532 [00:05<00:01, 104.33it/s]concatenating: train:  73%|███████▎  | 386/532 [00:05<00:01, 104.74it/s]concatenating: train:  75%|███████▍  | 398/532 [00:05<00:01, 107.33it/s]concatenating: train:  77%|███████▋  | 409/532 [00:05<00:01, 106.03it/s]concatenating: train:  79%|███████▉  | 422/532 [00:05<00:01, 109.02it/s]concatenating: train:  81%|████████▏ | 433/532 [00:05<00:00, 105.22it/s]concatenating: train:  84%|████████▍ | 448/532 [00:06<00:00, 114.96it/s]concatenating: train:  86%|████████▋ | 460/532 [00:06<00:00, 107.99it/s]concatenating: train:  89%|████████▊ | 472/532 [00:06<00:00, 107.20it/s]concatenating: train:  91%|█████████ | 483/532 [00:06<00:00, 87.32it/s] concatenating: train:  93%|█████████▎| 493/532 [00:06<00:00, 79.50it/s]concatenating: train:  94%|█████████▍| 502/532 [00:06<00:00, 61.53it/s]concatenating: train:  96%|█████████▌| 510/532 [00:07<00:00, 50.89it/s]concatenating: train:  97%|█████████▋| 517/532 [00:07<00:00, 52.52it/s]concatenating: train:  98%|█████████▊| 524/532 [00:07<00:00, 56.22it/s]concatenating: train: 100%|█████████▉| 531/532 [00:07<00:00, 55.23it/s]concatenating: train: 100%|██████████| 532/532 [00:07<00:00, 70.87it/s]
Loading test:   0%|          | 0/15 [00:00<?, ?it/s]Loading test:   7%|▋         | 1/15 [00:01<00:17,  1.25s/it]Loading test:  13%|█▎        | 2/15 [00:02<00:16,  1.29s/it]Loading test:  20%|██        | 3/15 [00:04<00:17,  1.45s/it]Loading test:  27%|██▋       | 4/15 [00:06<00:18,  1.66s/it]Loading test:  33%|███▎      | 5/15 [00:08<00:17,  1.76s/it]Loading test:  40%|████      | 6/15 [00:10<00:15,  1.76s/it]Loading test:  47%|████▋     | 7/15 [00:11<00:12,  1.58s/it]Loading test:  53%|█████▎    | 8/15 [00:13<00:11,  1.65s/it]Loading test:  60%|██████    | 9/15 [00:15<00:10,  1.68s/it]Loading test:  67%|██████▋   | 10/15 [00:16<00:08,  1.60s/it]Loading test:  73%|███████▎  | 11/15 [00:18<00:06,  1.62s/it]Loading test:  80%|████████  | 12/15 [00:19<00:04,  1.65s/it]Loading test:  87%|████████▋ | 13/15 [00:21<00:03,  1.74s/it]Loading test:  93%|█████████▎| 14/15 [00:23<00:01,  1.67s/it]Loading test: 100%|██████████| 15/15 [00:24<00:00,  1.66s/it]
concatenating: validation:   0%|          | 0/15 [00:00<?, ?it/s]concatenating: validation:  27%|██▋       | 4/15 [00:00<00:00, 36.26it/s]concatenating: validation:  53%|█████▎    | 8/15 [00:00<00:00, 35.38it/s]concatenating: validation:  93%|█████████▎| 14/15 [00:00<00:00, 39.39it/s]concatenating: validation: 100%|██████████| 15/15 [00:00<00:00, 41.43it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 56, 84, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 56, 84, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 56, 84, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 56, 84, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 56, 84, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 84, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 56, 84, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 56, 84, 16)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 28, 42, 16)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28, 42, 16)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 42, 30)   4350        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 42, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 42, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 42, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 28, 42, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 28, 42, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 42, 46)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 21, 46)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 14, 21, 46)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 14, 21, 60)   24900       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 14, 21, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 14, 21, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 14, 21, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 14, 21, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 14, 21, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 14, 21, 106)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 14, 21, 106)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 28, 42, 30)   12750       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 28, 42, 76)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 28, 42, 30)   20550       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 28, 42, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________2019-07-06 21:37:21.223602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-06 21:37:21.223719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-06 21:37:21.223753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-06 21:37:21.223767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-06 21:37:21.224361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

activation_7 (Activation)       (None, 28, 42, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 28, 42, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 28, 42, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 28, 42, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 28, 42, 106)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 28, 42, 106)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 56, 84, 15)   6375        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 84, 31)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 56, 84, 15)   4200        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 56, 84, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 84, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 56, 84, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 56, 84, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 84, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 84, 46)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 56, 84, 46)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 56, 84, 13)   611         dropout_5[0][0]                  
==================================================================================================
Total params: 127,886
Trainable params: 127,286
Non-trainable params: 600
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.53383120e-02 2.88786827e-02 1.16652967e-01 1.00133292e-02
 3.03165963e-02 5.79538965e-03 6.85058777e-02 1.28145429e-01
 7.55135052e-02 1.22435092e-02 2.73464902e-01 1.84941443e-01
 1.90056842e-04]
Train on 20749 samples, validate on 584 samples
Epoch 1/300
 - 30s - loss: 46.3449 - acc: 0.7478 - mDice: 0.0150 - val_loss: 5.6633 - val_acc: 0.9134 - val_mDice: 0.0069

Epoch 00001: val_mDice improved from -inf to 0.00686, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 20s - loss: 5.7704 - acc: 0.8962 - mDice: 0.0380 - val_loss: 4.1396 - val_acc: 0.9134 - val_mDice: 0.0371

Epoch 00002: val_mDice improved from 0.00686 to 0.03714, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 18s - loss: 4.3004 - acc: 0.9042 - mDice: 0.0916 - val_loss: 2.7769 - val_acc: 0.9187 - val_mDice: 0.1434

Epoch 00003: val_mDice improved from 0.03714 to 0.14345, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 19s - loss: 3.4496 - acc: 0.9130 - mDice: 0.1676 - val_loss: 2.3616 - val_acc: 0.9194 - val_mDice: 0.2232

Epoch 00004: val_mDice improved from 0.14345 to 0.22317, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 18s - loss: 2.8463 - acc: 0.9216 - mDice: 0.2519 - val_loss: 1.7675 - val_acc: 0.9457 - val_mDice: 0.3760

Epoch 00005: val_mDice improved from 0.22317 to 0.37597, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 19s - loss: 2.4522 - acc: 0.9292 - mDice: 0.3203 - val_loss: 1.5403 - val_acc: 0.9525 - val_mDice: 0.4510

Epoch 00006: val_mDice improved from 0.37597 to 0.45095, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 18s - loss: 2.1560 - acc: 0.9356 - mDice: 0.3786 - val_loss: 1.2386 - val_acc: 0.9619 - val_mDice: 0.5431

Epoch 00007: val_mDice improved from 0.45095 to 0.54313, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 18s - loss: 1.9472 - acc: 0.9407 - mDice: 0.4242 - val_loss: 1.1182 - val_acc: 0.9680 - val_mDice: 0.5883

Epoch 00008: val_mDice improved from 0.54313 to 0.58828, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 9/300
 - 19s - loss: 1.7931 - acc: 0.9445 - mDice: 0.4601 - val_loss: 1.0817 - val_acc: 0.9676 - val_mDice: 0.6167

Epoch 00009: val_mDice improved from 0.58828 to 0.61674, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 18s - loss: 1.6649 - acc: 0.9475 - mDice: 0.4920 - val_loss: 0.9802 - val_acc: 0.9714 - val_mDice: 0.6519

Epoch 00010: val_mDice improved from 0.61674 to 0.65189, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 11/300
 - 18s - loss: 1.5705 - acc: 0.9495 - mDice: 0.5162 - val_loss: 0.9674 - val_acc: 0.9718 - val_mDice: 0.6565

Epoch 00011: val_mDice improved from 0.65189 to 0.65655, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 12/300
 - 18s - loss: 1.4998 - acc: 0.9510 - mDice: 0.5347 - val_loss: 0.9356 - val_acc: 0.9734 - val_mDice: 0.6658

Epoch 00012: val_mDice improved from 0.65655 to 0.66576, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 13/300
 - 19s - loss: 1.4419 - acc: 0.9523 - mDice: 0.5493 - val_loss: 0.9032 - val_acc: 0.9738 - val_mDice: 0.6811

Epoch 00013: val_mDice improved from 0.66576 to 0.68111, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 14/300
 - 18s - loss: 1.3914 - acc: 0.9534 - mDice: 0.5629 - val_loss: 0.8901 - val_acc: 0.9740 - val_mDice: 0.6899

Epoch 00014: val_mDice improved from 0.68111 to 0.68987, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 15/300
 - 18s - loss: 1.3408 - acc: 0.9544 - mDice: 0.5761 - val_loss: 0.8796 - val_acc: 0.9748 - val_mDice: 0.6948

Epoch 00015: val_mDice improved from 0.68987 to 0.69483, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 16/300
 - 18s - loss: 1.2986 - acc: 0.9553 - mDice: 0.5869 - val_loss: 0.8828 - val_acc: 0.9750 - val_mDice: 0.6993

Epoch 00016: val_mDice improved from 0.69483 to 0.69933, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 17/300
 - 18s - loss: 1.2629 - acc: 0.9560 - mDice: 0.5963 - val_loss: 0.8411 - val_acc: 0.9737 - val_mDice: 0.7087

Epoch 00017: val_mDice improved from 0.69933 to 0.70866, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 18/300
 - 19s - loss: 1.2339 - acc: 0.9566 - mDice: 0.6041 - val_loss: 0.8393 - val_acc: 0.9739 - val_mDice: 0.7113

Epoch 00018: val_mDice improved from 0.70866 to 0.71127, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 19/300
 - 18s - loss: 1.1995 - acc: 0.9574 - mDice: 0.6129 - val_loss: 0.8137 - val_acc: 0.9746 - val_mDice: 0.7157

Epoch 00019: val_mDice improved from 0.71127 to 0.71568, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 20/300
 - 18s - loss: 1.1707 - acc: 0.9579 - mDice: 0.6207 - val_loss: 0.8240 - val_acc: 0.9750 - val_mDice: 0.7157

Epoch 00020: val_mDice did not improve from 0.71568
Epoch 21/300
 - 20s - loss: 1.1448 - acc: 0.9584 - mDice: 0.6281 - val_loss: 0.8289 - val_acc: 0.9737 - val_mDice: 0.7161

Epoch 00021: val_mDice improved from 0.71568 to 0.71612, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 22/300
 - 19s - loss: 1.1263 - acc: 0.9587 - mDice: 0.6336 - val_loss: 0.8153 - val_acc: 0.9756 - val_mDice: 0.7186

Epoch 00022: val_mDice improved from 0.71612 to 0.71862, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 23/300
 - 19s - loss: 1.1048 - acc: 0.9591 - mDice: 0.6389 - val_loss: 0.7910 - val_acc: 0.9755 - val_mDice: 0.7275

Epoch 00023: val_mDice improved from 0.71862 to 0.72754, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 24/300
 - 19s - loss: 1.0859 - acc: 0.9595 - mDice: 0.6448 - val_loss: 0.7872 - val_acc: 0.9756 - val_mDice: 0.7307

Epoch 00024: val_mDice improved from 0.72754 to 0.73074, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 25/300
 - 19s - loss: 1.0662 - acc: 0.9598 - mDice: 0.6503 - val_loss: 0.7764 - val_acc: 0.9762 - val_mDice: 0.7291

Epoch 00025: val_mDice did not improve from 0.73074
Epoch 26/300
 - 19s - loss: 1.0517 - acc: 0.9600 - mDice: 0.6542 - val_loss: 0.7834 - val_acc: 0.9764 - val_mDice: 0.7301

Epoch 00026: val_mDice did not improve from 0.73074
Epoch 27/300
 - 19s - loss: 1.0387 - acc: 0.9603 - mDice: 0.6580 - val_loss: 0.7835 - val_acc: 0.9760 - val_mDice: 0.7291

Epoch 00027: val_mDice did not improve from 0.73074
Epoch 28/300
 - 19s - loss: 1.0178 - acc: 0.9607 - mDice: 0.6643 - val_loss: 0.7816 - val_acc: 0.9753 - val_mDice: 0.7318

Epoch 00028: val_mDice improved from 0.73074 to 0.73181, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 29/300
 - 19s - loss: 1.0036 - acc: 0.9610 - mDice: 0.6681 - val_loss: 0.7828 - val_acc: 0.9759 - val_mDice: 0.7377

Epoch 00029: val_mDice improved from 0.73181 to 0.73774, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 30/300
 - 19s - loss: 0.9914 - acc: 0.9611 - mDice: 0.6719 - val_loss: 0.7660 - val_acc: 0.9767 - val_mDice: 0.7390

Epoch 00030: val_mDice improved from 0.73774 to 0.73901, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 31/300
 - 19s - loss: 0.9813 - acc: 0.9615 - mDice: 0.6752 - val_loss: 0.7603 - val_acc: 0.9763 - val_mDice: 0.7391

Epoch 00031: val_mDice improved from 0.73901 to 0.73907, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 32/300
 - 20s - loss: 0.9693 - acc: 0.9618 - mDice: 0.6786 - val_loss: 0.7582 - val_acc: 0.9762 - val_mDice: 0.7407

Epoch 00032: val_mDice improved from 0.73907 to 0.74074, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 33/300
 - 19s - loss: 0.9520 - acc: 0.9622 - mDice: 0.6834 - val_loss: 0.7528 - val_acc: 0.9768 - val_mDice: 0.7428

Epoch 00033: val_mDice improved from 0.74074 to 0.74277, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 34/300
 - 20s - loss: 0.9485 - acc: 0.9622 - mDice: 0.6851 - val_loss: 0.7537 - val_acc: 0.9771 - val_mDice: 0.7450

Epoch 00034: val_mDice improved from 0.74277 to 0.74505, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 35/300
 - 18s - loss: 0.9375 - acc: 0.9626 - mDice: 0.6885 - val_loss: 0.7379 - val_acc: 0.9771 - val_mDice: 0.7430

Epoch 00035: val_mDice did not improve from 0.74505
Epoch 36/300
 - 20s - loss: 0.9317 - acc: 0.9627 - mDice: 0.6902 - val_loss: 0.7530 - val_acc: 0.9770 - val_mDice: 0.7458

Epoch 00036: val_mDice improved from 0.74505 to 0.74581, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 37/300
 - 19s - loss: 0.9242 - acc: 0.9628 - mDice: 0.6926 - val_loss: 0.7467 - val_acc: 0.9763 - val_mDice: 0.7502

Epoch 00037: val_mDice improved from 0.74581 to 0.75025, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 38/300
 - 19s - loss: 0.9168 - acc: 0.9630 - mDice: 0.6946 - val_loss: 0.7513 - val_acc: 0.9770 - val_mDice: 0.7445

Epoch 00038: val_mDice did not improve from 0.75025
Epoch 39/300
 - 20s - loss: 0.9088 - acc: 0.9632 - mDice: 0.6971 - val_loss: 0.7360 - val_acc: 0.9772 - val_mDice: 0.7511

Epoch 00039: val_mDice improved from 0.75025 to 0.75114, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 40/300
 - 19s - loss: 0.9025 - acc: 0.9633 - mDice: 0.6991 - val_loss: 0.7431 - val_acc: 0.9775 - val_mDice: 0.7487

Epoch 00040: val_mDice did not improve from 0.75114
Epoch 41/300
 - 20s - loss: 0.8948 - acc: 0.9635 - mDice: 0.7014 - val_loss: 0.7320 - val_acc: 0.9774 - val_mDice: 0.7482

Epoch 00041: val_mDice did not improve from 0.75114
Epoch 42/300
 - 19s - loss: 0.8887 - acc: 0.9635 - mDice: 0.7031 - val_loss: 0.7316 - val_acc: 0.9767 - val_mDice: 0.7544

Epoch 00042: val_mDice improved from 0.75114 to 0.75441, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 43/300
 - 19s - loss: 0.8849 - acc: 0.9636 - mDice: 0.7045 - val_loss: 0.7338 - val_acc: 0.9776 - val_mDice: 0.7453

Epoch 00043: val_mDice did not improve from 0.75441
Epoch 44/300
 - 19s - loss: 0.8772 - acc: 0.9638 - mDice: 0.7068 - val_loss: 0.7421 - val_acc: 0.9776 - val_mDice: 0.7536

Epoch 00044: val_mDice did not improve from 0.75441
Epoch 45/300
 - 19s - loss: 0.8738 - acc: 0.9638 - mDice: 0.7081 - val_loss: 0.7444 - val_acc: 0.9778 - val_mDice: 0.7455

Epoch 00045: val_mDice did not improve from 0.75441
Epoch 46/300
 - 21s - loss: 0.8682 - acc: 0.9640 - mDice: 0.7095 - val_loss: 0.7299 - val_acc: 0.9776 - val_mDice: 0.7523

Epoch 00046: val_mDice did not improve from 0.75441
Epoch 47/300
 - 24s - loss: 0.8653 - acc: 0.9639 - mDice: 0.7107 - val_loss: 0.7235 - val_acc: 0.9778 - val_mDice: 0.7531

Epoch 00047: val_mDice did not improve from 0.75441
Epoch 48/300
 - 24s - loss: 0.8595 - acc: 0.9641 - mDice: 0.7121 - val_loss: 0.7343 - val_acc: 0.9776 - val_mDice: 0.7513

Epoch 00048: val_mDice did not improve from 0.75441
Epoch 49/300
 - 24s - loss: 0.8541 - acc: 0.9642 - mDice: 0.7138 - val_loss: 0.7262 - val_acc: 0.9781 - val_mDice: 0.7528

Epoch 00049: val_mDice did not improve from 0.75441
Epoch 50/300
 - 24s - loss: 0.8493 - acc: 0.9643 - mDice: 0.7151 - val_loss: 0.7168 - val_acc: 0.9778 - val_mDice: 0.7572

Epoch 00050: val_mDice improved from 0.75441 to 0.75717, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 51/300
 - 24s - loss: 0.8499 - acc: 0.9643 - mDice: 0.7151 - val_loss: 0.7264 - val_acc: 0.9776 - val_mDice: 0.7569

Epoch 00051: val_mDice did not improve from 0.75717
Epoch 52/300
 - 23s - loss: 0.8429 - acc: 0.9644 - mDice: 0.7169 - val_loss: 0.7268 - val_acc: 0.9779 - val_mDice: 0.7533

Epoch 00052: val_mDice did not improve from 0.75717
Epoch 53/300
 - 25s - loss: 0.8406 - acc: 0.9645 - mDice: 0.7181 - val_loss: 0.7205 - val_acc: 0.9783 - val_mDice: 0.7586

Epoch 00053: val_mDice improved from 0.75717 to 0.75862, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 54/300
 - 26s - loss: 0.8357 - acc: 0.9646 - mDice: 0.7197 - val_loss: 0.7252 - val_acc: 0.9777 - val_mDice: 0.7545

Epoch 00054: val_mDice did not improve from 0.75862
Epoch 55/300
 - 24s - loss: 0.8326 - acc: 0.9646 - mDice: 0.7203 - val_loss: 0.7276 - val_acc: 0.9781 - val_mDice: 0.7561

Epoch 00055: val_mDice did not improve from 0.75862
Epoch 56/300
 - 23s - loss: 0.8269 - acc: 0.9647 - mDice: 0.7220 - val_loss: 0.7150 - val_acc: 0.9785 - val_mDice: 0.7576

Epoch 00056: val_mDice did not improve from 0.75862
Epoch 57/300
 - 26s - loss: 0.8230 - acc: 0.9648 - mDice: 0.7231 - val_loss: 0.7337 - val_acc: 0.9784 - val_mDice: 0.7561

Epoch 00057: val_mDice did not improve from 0.75862
Epoch 58/300
 - 25s - loss: 0.8226 - acc: 0.9647 - mDice: 0.7233 - val_loss: 0.7159 - val_acc: 0.9784 - val_mDice: 0.7567

Epoch 00058: val_mDice did not improve from 0.75862
Epoch 59/300
 - 23s - loss: 0.8205 - acc: 0.9648 - mDice: 0.7239 - val_loss: 0.7205 - val_acc: 0.9779 - val_mDice: 0.7608

Epoch 00059: val_mDice improved from 0.75862 to 0.76077, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 60/300
 - 24s - loss: 0.8163 - acc: 0.9649 - mDice: 0.7252 - val_loss: 0.7160 - val_acc: 0.9783 - val_mDice: 0.7590

Epoch 00060: val_mDice did not improve from 0.76077
Epoch 61/300
 - 26s - loss: 0.8150 - acc: 0.9649 - mDice: 0.7256 - val_loss: 0.7190 - val_acc: 0.9785 - val_mDice: 0.7547

Epoch 00061: val_mDice did not improve from 0.76077
Epoch 62/300
 - 19s - loss: 0.8090 - acc: 0.9650 - mDice: 0.7274 - val_loss: 0.7049 - val_acc: 0.9783 - val_mDice: 0.7571

Epoch 00062: val_mDice did not improve from 0.76077
Epoch 63/300
 - 19s - loss: 0.8094 - acc: 0.9650 - mDice: 0.7274 - val_loss: 0.7155 - val_acc: 0.9782 - val_mDice: 0.7599

Epoch 00063: val_mDice did not improve from 0.76077
Epoch 64/300
 - 18s - loss: 0.8051 - acc: 0.9650 - mDice: 0.7286 - val_loss: 0.7063 - val_acc: 0.9785 - val_mDice: 0.7623

Epoch 00064: val_mDice improved from 0.76077 to 0.76233, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 65/300
 - 18s - loss: 0.8018 - acc: 0.9651 - mDice: 0.7296 - val_loss: 0.7092 - val_acc: 0.9789 - val_mDice: 0.7598

Epoch 00065: val_mDice did not improve from 0.76233
Epoch 66/300
 - 19s - loss: 0.8007 - acc: 0.9651 - mDice: 0.7299 - val_loss: 0.7128 - val_acc: 0.9782 - val_mDice: 0.7599

Epoch 00066: val_mDice did not improve from 0.76233
Epoch 67/300
 - 18s - loss: 0.7998 - acc: 0.9651 - mDice: 0.7301 - val_loss: 0.7072 - val_acc: 0.9784 - val_mDice: 0.7617

Epoch 00067: val_mDice did not improve from 0.76233
Epoch 68/300
 - 18s - loss: 0.7973 - acc: 0.9652 - mDice: 0.7306 - val_loss: 0.7127 - val_acc: 0.9785 - val_mDice: 0.7594

Epoch 00068: val_mDice did not improve from 0.76233
Epoch 69/300
 - 18s - loss: 0.7924 - acc: 0.9653 - mDice: 0.7322 - val_loss: 0.7204 - val_acc: 0.9782 - val_mDice: 0.7604

Epoch 00069: val_mDice did not improve from 0.76233
Epoch 70/300
 - 18s - loss: 0.7914 - acc: 0.9653 - mDice: 0.7329 - val_loss: 0.7092 - val_acc: 0.9789 - val_mDice: 0.7581

Epoch 00070: val_mDice did not improve from 0.76233
Epoch 71/300
 - 19s - loss: 0.7893 - acc: 0.9654 - mDice: 0.7334 - val_loss: 0.7164 - val_acc: 0.9785 - val_mDice: 0.7600

Epoch 00071: val_mDice did not improve from 0.76233
Epoch 72/300
 - 18s - loss: 0.7881 - acc: 0.9653 - mDice: 0.7338 - val_loss: 0.7095 - val_acc: 0.9781 - val_mDice: 0.7586

Epoch 00072: val_mDice did not improve from 0.76233
Epoch 73/300
 - 18s - loss: 0.7861 - acc: 0.9654 - mDice: 0.7344 - val_loss: 0.6945 - val_acc: 0.9793 - val_mDice: 0.7623

Epoch 00073: val_mDice improved from 0.76233 to 0.76235, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 74/300
 - 18s - loss: 0.7831 - acc: 0.9655 - mDice: 0.7351 - val_loss: 0.7081 - val_acc: 0.9786 - val_mDice: 0.7586

Epoch 00074: val_mDice did not improve from 0.76235
Epoch 75/300
 - 19s - loss: 0.7847 - acc: 0.9655 - mDice: 0.7346 - val_loss: 0.7264 - val_acc: 0.9788 - val_mDice: 0.7583

Epoch 00075: val_mDice did not improve from 0.76235
Epoch 76/300
 - 18s - loss: 0.7817 - acc: 0.9655 - mDice: 0.7356 - val_loss: 0.6945 - val_acc: 0.9789 - val_mDice: 0.7627

Epoch 00076: val_mDice improved from 0.76235 to 0.76267, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 77/300
 - 18s - loss: 0.7792 - acc: 0.9656 - mDice: 0.7363 - val_loss: 0.7005 - val_acc: 0.9789 - val_mDice: 0.7607

Epoch 00077: val_mDice did not improve from 0.76267
Epoch 78/300
 - 18s - loss: 0.7780 - acc: 0.9656 - mDice: 0.7367 - val_loss: 0.7052 - val_acc: 0.9782 - val_mDice: 0.7630

Epoch 00078: val_mDice improved from 0.76267 to 0.76295, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 79/300
 - 18s - loss: 0.7754 - acc: 0.9657 - mDice: 0.7376 - val_loss: 0.6909 - val_acc: 0.9789 - val_mDice: 0.7677

Epoch 00079: val_mDice improved from 0.76295 to 0.76770, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 80/300
 - 19s - loss: 0.7747 - acc: 0.9657 - mDice: 0.7375 - val_loss: 0.6998 - val_acc: 0.9782 - val_mDice: 0.7605

Epoch 00080: val_mDice did not improve from 0.76770
Epoch 81/300
 - 18s - loss: 0.7719 - acc: 0.9658 - mDice: 0.7383 - val_loss: 0.7023 - val_acc: 0.9781 - val_mDice: 0.7655

Epoch 00081: val_mDice did not improve from 0.76770
Epoch 82/300
 - 18s - loss: 0.7740 - acc: 0.9657 - mDice: 0.7382 - val_loss: 0.7156 - val_acc: 0.9782 - val_mDice: 0.7622

Epoch 00082: val_mDice did not improve from 0.76770
Epoch 83/300
 - 18s - loss: 0.7671 - acc: 0.9659 - mDice: 0.7402 - val_loss: 0.6993 - val_acc: 0.9785 - val_mDice: 0.7668

Epoch 00083: val_mDice did not improve from 0.76770
Epoch 84/300
 - 18s - loss: 0.7709 - acc: 0.9658 - mDice: 0.7389 - val_loss: 0.7038 - val_acc: 0.9780 - val_mDice: 0.7641

Epoch 00084: val_mDice did not improve from 0.76770
Epoch 85/300
 - 18s - loss: 0.7677 - acc: 0.9658 - mDice: 0.7400 - val_loss: 0.7002 - val_acc: 0.9786 - val_mDice: 0.7635

Epoch 00085: val_mDice did not improve from 0.76770
Epoch 86/300
 - 19s - loss: 0.7663 - acc: 0.9659 - mDice: 0.7405 - val_loss: 0.7035 - val_acc: 0.9786 - val_mDice: 0.7667

Epoch 00086: val_mDice did not improve from 0.76770
Epoch 87/300
 - 18s - loss: 0.7651 - acc: 0.9659 - mDice: 0.7406 - val_loss: 0.7011 - val_acc: 0.9785 - val_mDice: 0.7656

Epoch 00087: val_mDice did not improve from 0.76770
Epoch 88/300
 - 18s - loss: 0.7625 - acc: 0.9660 - mDice: 0.7414 - val_loss: 0.6989 - val_acc: 0.9786 - val_mDice: 0.7652

Epoch 00088: val_mDice did not improve from 0.76770
Epoch 89/300
 - 18s - loss: 0.7619 - acc: 0.9660 - mDice: 0.7415 - val_loss: 0.7005 - val_acc: 0.9784 - val_mDice: 0.7646

Epoch 00089: val_mDice did not improve from 0.76770
Epoch 90/300
 - 19s - loss: 0.7591 - acc: 0.9661 - mDice: 0.7427 - val_loss: 0.7025 - val_acc: 0.9786 - val_mDice: 0.7671

Epoch 00090: val_mDice did not improve from 0.76770
Epoch 91/300
 - 18s - loss: 0.7607 - acc: 0.9660 - mDice: 0.7421 - val_loss: 0.7076 - val_acc: 0.9788 - val_mDice: 0.7646

Epoch 00091: val_mDice did not improve from 0.76770
Epoch 92/300
 - 18s - loss: 0.7600 - acc: 0.9660 - mDice: 0.7424 - val_loss: 0.6976 - val_acc: 0.9788 - val_mDice: 0.7612

Epoch 00092: val_mDice did not improve from 0.76770
Epoch 93/300
 - 18s - loss: 0.7594 - acc: 0.9661 - mDice: 0.7423 - val_loss: 0.6928 - val_acc: 0.9790 - val_mDice: 0.7650

Epoch 00093: val_mDice did not improve from 0.76770
Epoch 94/300
 - 18s - loss: 0.7558 - acc: 0.9661 - mDice: 0.7435 - val_loss: 0.6967 - val_acc: 0.9788 - val_mDice: 0.7661

Epoch 00094: val_mDice did not improve from 0.76770
Epoch 95/300
 - 19s - loss: 0.7541 - acc: 0.9662 - mDice: 0.7437 - val_loss: 0.7102 - val_acc: 0.9776 - val_mDice: 0.7686

Epoch 00095: val_mDice improved from 0.76770 to 0.76858, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 96/300
 - 18s - loss: 0.7539 - acc: 0.9662 - mDice: 0.7443 - val_loss: 0.6981 - val_acc: 0.9786 - val_mDice: 0.7652

Epoch 00096: val_mDice did not improve from 0.76858
Epoch 97/300
 - 18s - loss: 0.7532 - acc: 0.9663 - mDice: 0.7445 - val_loss: 0.6931 - val_acc: 0.9792 - val_mDice: 0.7650

Epoch 00097: val_mDice did not improve from 0.76858
Epoch 98/300
 - 18s - loss: 0.7527 - acc: 0.9662 - mDice: 0.7447 - val_loss: 0.7047 - val_acc: 0.9790 - val_mDice: 0.7668

Epoch 00098: val_mDice did not improve from 0.76858
Epoch 99/300
 - 18s - loss: 0.7502 - acc: 0.9663 - mDice: 0.7452 - val_loss: 0.6896 - val_acc: 0.9787 - val_mDice: 0.7684

Epoch 00099: val_mDice did not improve from 0.76858
Epoch 100/300
 - 19s - loss: 0.7532 - acc: 0.9663 - mDice: 0.7446 - val_loss: 0.6871 - val_acc: 0.9796 - val_mDice: 0.7681

Epoch 00100: val_mDice did not improve from 0.76858
Epoch 101/300
 - 18s - loss: 0.7495 - acc: 0.9663 - mDice: 0.7457 - val_loss: 0.7042 - val_acc: 0.9783 - val_mDice: 0.7689

Epoch 00101: val_mDice improved from 0.76858 to 0.76891, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 102/300
 - 18s - loss: 0.7476 - acc: 0.9664 - mDice: 0.7459 - val_loss: 0.7046 - val_acc: 0.9790 - val_mDice: 0.7644

Epoch 00102: val_mDice did not improve from 0.76891
Epoch 103/300
 - 18s - loss: 0.7462 - acc: 0.9664 - mDice: 0.7466 - val_loss: 0.6898 - val_acc: 0.9788 - val_mDice: 0.7673

Epoch 00103: val_mDice did not improve from 0.76891
Epoch 104/300
 - 18s - loss: 0.7465 - acc: 0.9665 - mDice: 0.7466 - val_loss: 0.6881 - val_acc: 0.9785 - val_mDice: 0.7695

Epoch 00104: val_mDice improved from 0.76891 to 0.76947, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 105/300
 - 19s - loss: 0.7455 - acc: 0.9664 - mDice: 0.7468 - val_loss: 0.6931 - val_acc: 0.9787 - val_mDice: 0.7693

Epoch 00105: val_mDice did not improve from 0.76947
Epoch 106/300
 - 18s - loss: 0.7447 - acc: 0.9665 - mDice: 0.7470 - val_loss: 0.6979 - val_acc: 0.9791 - val_mDice: 0.7664

Epoch 00106: val_mDice did not improve from 0.76947
Epoch 107/300
 - 18s - loss: 0.7431 - acc: 0.9665 - mDice: 0.7476 - val_loss: 0.6977 - val_acc: 0.9791 - val_mDice: 0.7663

Epoch 00107: val_mDice did not improve from 0.76947
Epoch 108/300
 - 18s - loss: 0.7429 - acc: 0.9665 - mDice: 0.7479 - val_loss: 0.6886 - val_acc: 0.9794 - val_mDice: 0.7655

Epoch 00108: val_mDice did not improve from 0.76947
Epoch 109/300
 - 18s - loss: 0.7424 - acc: 0.9665 - mDice: 0.7478 - val_loss: 0.6937 - val_acc: 0.9793 - val_mDice: 0.7691

Epoch 00109: val_mDice did not improve from 0.76947
Epoch 110/300
 - 19s - loss: 0.7428 - acc: 0.9666 - mDice: 0.7479 - val_loss: 0.6913 - val_acc: 0.9789 - val_mDice: 0.7648

Epoch 00110: val_mDice did not improve from 0.76947
Epoch 111/300
 - 19s - loss: 0.7413 - acc: 0.9666 - mDice: 0.7482 - val_loss: 0.7095 - val_acc: 0.9780 - val_mDice: 0.7643

Epoch 00111: val_mDice did not improve from 0.76947
Epoch 112/300
 - 18s - loss: 0.7394 - acc: 0.9666 - mDice: 0.7488 - val_loss: 0.6966 - val_acc: 0.9791 - val_mDice: 0.7690

Epoch 00112: val_mDice did not improve from 0.76947
Epoch 113/300
 - 18s - loss: 0.7404 - acc: 0.9666 - mDice: 0.7485 - val_loss: 0.6934 - val_acc: 0.9792 - val_mDice: 0.7683

Epoch 00113: val_mDice did not improve from 0.76947
Epoch 114/300
 - 18s - loss: 0.7385 - acc: 0.9667 - mDice: 0.7490 - val_loss: 0.6905 - val_acc: 0.9792 - val_mDice: 0.7645

Epoch 00114: val_mDice did not improve from 0.76947
Epoch 115/300
 - 18s - loss: 0.7371 - acc: 0.9667 - mDice: 0.7494 - val_loss: 0.6958 - val_acc: 0.9787 - val_mDice: 0.7687

Epoch 00115: val_mDice did not improve from 0.76947
Epoch 116/300
 - 19s - loss: 0.7367 - acc: 0.9668 - mDice: 0.7497 - val_loss: 0.6946 - val_acc: 0.9786 - val_mDice: 0.7671

Epoch 00116: val_mDice did not improve from 0.76947
Epoch 117/300
 - 18s - loss: 0.7359 - acc: 0.9668 - mDice: 0.7500 - val_loss: 0.6929 - val_acc: 0.9787 - val_mDice: 0.7672

Epoch 00117: val_mDice did not improve from 0.76947
Epoch 118/300
 - 18s - loss: 0.7337 - acc: 0.9668 - mDice: 0.7506 - val_loss: 0.6858 - val_acc: 0.9786 - val_mDice: 0.7683

Epoch 00118: val_mDice did not improve from 0.76947
Epoch 119/300
 - 18s - loss: 0.7335 - acc: 0.9668 - mDice: 0.7507 - val_loss: 0.6913 - val_acc: 0.9786 - val_mDice: 0.7656

Epoch 00119: val_mDice did not improve from 0.76947
Epoch 120/300
 - 18s - loss: 0.7335 - acc: 0.9668 - mDice: 0.7505 - val_loss: 0.6933 - val_acc: 0.9785 - val_mDice: 0.7703

Epoch 00120: val_mDice improved from 0.76947 to 0.77029, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 121/300
 - 19s - loss: 0.7326 - acc: 0.9669 - mDice: 0.7510 - val_loss: 0.7042 - val_acc: 0.9790 - val_mDice: 0.7672

Epoch 00121: val_mDice did not improve from 0.77029
Epoch 122/300
 - 18s - loss: 0.7301 - acc: 0.9669 - mDice: 0.7518 - val_loss: 0.6905 - val_acc: 0.9794 - val_mDice: 0.7682

Epoch 00122: val_mDice did not improve from 0.77029
Epoch 123/300
 - 18s - loss: 0.7300 - acc: 0.9669 - mDice: 0.7517 - val_loss: 0.6958 - val_acc: 0.9782 - val_mDice: 0.7701

Epoch 00123: val_mDice did not improve from 0.77029
Epoch 124/300
 - 18s - loss: 0.7304 - acc: 0.9669 - mDice: 0.7517 - val_loss: 0.7024 - val_acc: 0.9786 - val_mDice: 0.7642

Epoch 00124: val_mDice did not improve from 0.77029
Epoch 125/300
 - 18s - loss: 0.7302 - acc: 0.9669 - mDice: 0.7516 - val_loss: 0.6887 - val_acc: 0.9789 - val_mDice: 0.7700

Epoch 00125: val_mDice did not improve from 0.77029
Epoch 126/300
 - 18s - loss: 0.7296 - acc: 0.9669 - mDice: 0.7522 - val_loss: 0.6927 - val_acc: 0.9789 - val_mDice: 0.7683

Epoch 00126: val_mDice did not improve from 0.77029
Epoch 127/300
 - 19s - loss: 0.7303 - acc: 0.9669 - mDice: 0.7515 - val_loss: 0.6875 - val_acc: 0.9795 - val_mDice: 0.7694

Epoch 00127: val_mDice did not improve from 0.77029
Epoch 128/300
 - 18s - loss: 0.7291 - acc: 0.9669 - mDice: 0.7522 - val_loss: 0.6921 - val_acc: 0.9789 - val_mDice: 0.7710

Epoch 00128: val_mDice improved from 0.77029 to 0.77100, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 129/300
 - 18s - loss: 0.7274 - acc: 0.9670 - mDice: 0.7526 - val_loss: 0.6935 - val_acc: 0.9793 - val_mDice: 0.7648

Epoch 00129: val_mDice did not improve from 0.77100
Epoch 130/300
 - 18s - loss: 0.7260 - acc: 0.9670 - mDice: 0.7531 - val_loss: 0.6923 - val_acc: 0.9787 - val_mDice: 0.7709

Epoch 00130: val_mDice did not improve from 0.77100
Epoch 131/300
 - 18s - loss: 0.7267 - acc: 0.9670 - mDice: 0.7528 - val_loss: 0.7090 - val_acc: 0.9792 - val_mDice: 0.7656

Epoch 00131: val_mDice did not improve from 0.77100
Epoch 132/300
 - 19s - loss: 0.7263 - acc: 0.9670 - mDice: 0.7528 - val_loss: 0.6948 - val_acc: 0.9789 - val_mDice: 0.7694

Epoch 00132: val_mDice did not improve from 0.77100
Epoch 133/300
 - 18s - loss: 0.7252 - acc: 0.9671 - mDice: 0.7532 - val_loss: 0.6858 - val_acc: 0.9793 - val_mDice: 0.7692

Epoch 00133: val_mDice did not improve from 0.77100
Epoch 134/300
 - 18s - loss: 0.7230 - acc: 0.9671 - mDice: 0.7540 - val_loss: 0.6964 - val_acc: 0.9789 - val_mDice: 0.7685

Epoch 00134: val_mDice did not improve from 0.77100
Epoch 135/300
 - 18s - loss: 0.7232 - acc: 0.9672 - mDice: 0.7537 - val_loss: 0.6903 - val_acc: 0.9787 - val_mDice: 0.7715

Epoch 00135: val_mDice improved from 0.77100 to 0.77153, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 136/300
 - 18s - loss: 0.7225 - acc: 0.9671 - mDice: 0.7542 - val_loss: 0.7006 - val_acc: 0.9780 - val_mDice: 0.7677

Epoch 00136: val_mDice did not improve from 0.77153
Epoch 137/300
 - 19s - loss: 0.7233 - acc: 0.9671 - mDice: 0.7541 - val_loss: 0.6835 - val_acc: 0.9793 - val_mDice: 0.7701

Epoch 00137: val_mDice did not improve from 0.77153
Epoch 138/300
 - 18s - loss: 0.7226 - acc: 0.9671 - mDice: 0.7540 - val_loss: 0.7001 - val_acc: 0.9783 - val_mDice: 0.7675

Epoch 00138: val_mDice did not improve from 0.77153
Epoch 139/300
 - 18s - loss: 0.7219 - acc: 0.9671 - mDice: 0.7544 - val_loss: 0.6887 - val_acc: 0.9787 - val_mDice: 0.7730

Epoch 00139: val_mDice improved from 0.77153 to 0.77296, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 140/300
 - 18s - loss: 0.7187 - acc: 0.9672 - mDice: 0.7552 - val_loss: 0.6909 - val_acc: 0.9786 - val_mDice: 0.7727

Epoch 00140: val_mDice did not improve from 0.77296
Epoch 141/300
 - 19s - loss: 0.7199 - acc: 0.9672 - mDice: 0.7549 - val_loss: 0.7004 - val_acc: 0.9780 - val_mDice: 0.7717

Epoch 00141: val_mDice did not improve from 0.77296
Epoch 142/300
 - 18s - loss: 0.7199 - acc: 0.9672 - mDice: 0.7552 - val_loss: 0.6930 - val_acc: 0.9787 - val_mDice: 0.7721

Epoch 00142: val_mDice did not improve from 0.77296
Epoch 143/300
 - 18s - loss: 0.7189 - acc: 0.9672 - mDice: 0.7550 - val_loss: 0.6866 - val_acc: 0.9791 - val_mDice: 0.7708

Epoch 00143: val_mDice did not improve from 0.77296
Epoch 144/300
 - 19s - loss: 0.7185 - acc: 0.9672 - mDice: 0.7559 - val_loss: 0.6864 - val_acc: 0.9792 - val_mDice: 0.7737

Epoch 00144: val_mDice improved from 0.77296 to 0.77371, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 145/300
 - 18s - loss: 0.7192 - acc: 0.9672 - mDice: 0.7554 - val_loss: 0.6838 - val_acc: 0.9785 - val_mDice: 0.7724

Epoch 00145: val_mDice did not improve from 0.77371
Epoch 146/300
 - 19s - loss: 0.7187 - acc: 0.9672 - mDice: 0.7557 - val_loss: 0.6909 - val_acc: 0.9785 - val_mDice: 0.7739

Epoch 00146: val_mDice improved from 0.77371 to 0.77387, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 147/300
 - 18s - loss: 0.7174 - acc: 0.9673 - mDice: 0.7557 - val_loss: 0.6845 - val_acc: 0.9795 - val_mDice: 0.7737

Epoch 00147: val_mDice did not improve from 0.77387
Epoch 148/300
 - 18s - loss: 0.7159 - acc: 0.9673 - mDice: 0.7563 - val_loss: 0.6775 - val_acc: 0.9795 - val_mDice: 0.7721

Epoch 00148: val_mDice did not improve from 0.77387
Epoch 149/300
 - 18s - loss: 0.7156 - acc: 0.9673 - mDice: 0.7566 - val_loss: 0.6879 - val_acc: 0.9793 - val_mDice: 0.7707

Epoch 00149: val_mDice did not improve from 0.77387
Epoch 150/300
 - 19s - loss: 0.7160 - acc: 0.9673 - mDice: 0.7563 - val_loss: 0.7013 - val_acc: 0.9789 - val_mDice: 0.7756

Epoch 00150: val_mDice improved from 0.77387 to 0.77564, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 151/300
 - 18s - loss: 0.7140 - acc: 0.9673 - mDice: 0.7571 - val_loss: 0.6803 - val_acc: 0.9795 - val_mDice: 0.7722

Epoch 00151: val_mDice did not improve from 0.77564
Epoch 152/300
 - 18s - loss: 0.7152 - acc: 0.9673 - mDice: 0.7567 - val_loss: 0.6919 - val_acc: 0.9791 - val_mDice: 0.7719

Epoch 00152: val_mDice did not improve from 0.77564
Epoch 153/300
 - 18s - loss: 0.7122 - acc: 0.9674 - mDice: 0.7573 - val_loss: 0.6824 - val_acc: 0.9790 - val_mDice: 0.7740

Epoch 00153: val_mDice did not improve from 0.77564
Epoch 154/300
 - 18s - loss: 0.7142 - acc: 0.9674 - mDice: 0.7569 - val_loss: 0.6755 - val_acc: 0.9794 - val_mDice: 0.7742

Epoch 00154: val_mDice did not improve from 0.77564
Epoch 155/300
 - 18s - loss: 0.7118 - acc: 0.9674 - mDice: 0.7576 - val_loss: 0.6796 - val_acc: 0.9793 - val_mDice: 0.7750

Epoch 00155: val_mDice did not improve from 0.77564
Epoch 156/300
 - 19s - loss: 0.7118 - acc: 0.9674 - mDice: 0.7577 - val_loss: 0.6942 - val_acc: 0.9789 - val_mDice: 0.7729

Epoch 00156: val_mDice did not improve from 0.77564
Epoch 157/300
 - 18s - loss: 0.7117 - acc: 0.9674 - mDice: 0.7578 - val_loss: 0.6941 - val_acc: 0.9785 - val_mDice: 0.7711

Epoch 00157: val_mDice did not improve from 0.77564
Epoch 158/300
 - 18s - loss: 0.7111 - acc: 0.9674 - mDice: 0.7582 - val_loss: 0.6758 - val_acc: 0.9795 - val_mDice: 0.7746

Epoch 00158: val_mDice did not improve from 0.77564
Epoch 159/300
 - 18s - loss: 0.7109 - acc: 0.9674 - mDice: 0.7582 - val_loss: 0.6887 - val_acc: 0.9793 - val_mDice: 0.7686

Epoch 00159: val_mDice did not improve from 0.77564
Epoch 160/300
 - 18s - loss: 0.7095 - acc: 0.9674 - mDice: 0.7587 - val_loss: 0.6861 - val_acc: 0.9788 - val_mDice: 0.7758

Epoch 00160: val_mDice improved from 0.77564 to 0.77579, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 161/300
 - 20s - loss: 0.7103 - acc: 0.9674 - mDice: 0.7581 - val_loss: 0.6799 - val_acc: 0.9792 - val_mDice: 0.7743

Epoch 00161: val_mDice did not improve from 0.77579
Epoch 162/300
 - 18s - loss: 0.7105 - acc: 0.9674 - mDice: 0.7581 - val_loss: 0.6830 - val_acc: 0.9790 - val_mDice: 0.7735

Epoch 00162: val_mDice did not improve from 0.77579
Epoch 163/300
 - 19s - loss: 0.7102 - acc: 0.9674 - mDice: 0.7582 - val_loss: 0.6878 - val_acc: 0.9783 - val_mDice: 0.7734

Epoch 00163: val_mDice did not improve from 0.77579
Epoch 164/300
 - 19s - loss: 0.7078 - acc: 0.9675 - mDice: 0.7591 - val_loss: 0.6801 - val_acc: 0.9789 - val_mDice: 0.7741

Epoch 00164: val_mDice did not improve from 0.77579
Epoch 165/300
 - 18s - loss: 0.7085 - acc: 0.9674 - mDice: 0.7587 - val_loss: 0.6939 - val_acc: 0.9783 - val_mDice: 0.7733

Epoch 00165: val_mDice did not improve from 0.77579
Epoch 166/300
 - 19s - loss: 0.7064 - acc: 0.9675 - mDice: 0.7596 - val_loss: 0.6881 - val_acc: 0.9793 - val_mDice: 0.7757

Epoch 00166: val_mDice did not improve from 0.77579
Epoch 167/300
 - 19s - loss: 0.7065 - acc: 0.9676 - mDice: 0.7597 - val_loss: 0.6876 - val_acc: 0.9789 - val_mDice: 0.7734

Epoch 00167: val_mDice did not improve from 0.77579
Epoch 168/300
 - 18s - loss: 0.7076 - acc: 0.9675 - mDice: 0.7591 - val_loss: 0.6905 - val_acc: 0.9790 - val_mDice: 0.7734

Epoch 00168: val_mDice did not improve from 0.77579
Epoch 169/300
 - 19s - loss: 0.7064 - acc: 0.9675 - mDice: 0.7595 - val_loss: 0.6823 - val_acc: 0.9797 - val_mDice: 0.7730

Epoch 00169: val_mDice did not improve from 0.77579
Epoch 170/300
 - 19s - loss: 0.7064 - acc: 0.9675 - mDice: 0.7596 - val_loss: 0.6888 - val_acc: 0.9790 - val_mDice: 0.7708

Epoch 00170: val_mDice did not improve from 0.77579
Epoch 171/300
 - 18s - loss: 0.7069 - acc: 0.9675 - mDice: 0.7597 - val_loss: 0.6884 - val_acc: 0.9792 - val_mDice: 0.7702

Epoch 00171: val_mDice did not improve from 0.77579
Epoch 172/300
 - 19s - loss: 0.7029 - acc: 0.9676 - mDice: 0.7605 - val_loss: 0.6800 - val_acc: 0.9789 - val_mDice: 0.7727

Epoch 00172: val_mDice did not improve from 0.77579
Epoch 173/300
 - 20s - loss: 0.7047 - acc: 0.9676 - mDice: 0.7599 - val_loss: 0.6952 - val_acc: 0.9783 - val_mDice: 0.7732

Epoch 00173: val_mDice did not improve from 0.77579
Epoch 174/300
 - 18s - loss: 0.7037 - acc: 0.9676 - mDice: 0.7605 - val_loss: 0.6881 - val_acc: 0.9788 - val_mDice: 0.7751

Epoch 00174: val_mDice did not improve from 0.77579
Epoch 175/300
 - 18s - loss: 0.7033 - acc: 0.9676 - mDice: 0.7605 - val_loss: 0.6772 - val_acc: 0.9793 - val_mDice: 0.7754

Epoch 00175: val_mDice did not improve from 0.77579
Epoch 176/300
 - 19s - loss: 0.7029 - acc: 0.9676 - mDice: 0.7609 - val_loss: 0.6805 - val_acc: 0.9793 - val_mDice: 0.7725

Epoch 00176: val_mDice did not improve from 0.77579
Epoch 177/300
 - 19s - loss: 0.7039 - acc: 0.9676 - mDice: 0.7603 - val_loss: 0.6887 - val_acc: 0.9784 - val_mDice: 0.7753

Epoch 00177: val_mDice did not improve from 0.77579
Epoch 178/300
 - 20s - loss: 0.7022 - acc: 0.9676 - mDice: 0.7610 - val_loss: 0.6852 - val_acc: 0.9785 - val_mDice: 0.7754

Epoch 00178: val_mDice did not improve from 0.77579
Epoch 179/300
 - 18s - loss: 0.7033 - acc: 0.9676 - mDice: 0.7608 - val_loss: 0.6819 - val_acc: 0.9793 - val_mDice: 0.7761

Epoch 00179: val_mDice improved from 0.77579 to 0.77607, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 180/300
 - 19s - loss: 0.7018 - acc: 0.9676 - mDice: 0.7613 - val_loss: 0.6786 - val_acc: 0.9790 - val_mDice: 0.7715

Epoch 00180: val_mDice did not improve from 0.77607
Epoch 181/300
 - 19s - loss: 0.7021 - acc: 0.9676 - mDice: 0.7609 - val_loss: 0.6803 - val_acc: 0.9792 - val_mDice: 0.7752

Epoch 00181: val_mDice did not improve from 0.77607
Epoch 182/300
 - 19s - loss: 0.7005 - acc: 0.9676 - mDice: 0.7619 - val_loss: 0.6807 - val_acc: 0.9789 - val_mDice: 0.7729

Epoch 00182: val_mDice did not improve from 0.77607
Epoch 183/300
 - 20s - loss: 0.7014 - acc: 0.9676 - mDice: 0.7615 - val_loss: 0.6828 - val_acc: 0.9791 - val_mDice: 0.7763

Epoch 00183: val_mDice improved from 0.77607 to 0.77632, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 184/300
 - 19s - loss: 0.6997 - acc: 0.9677 - mDice: 0.7617 - val_loss: 0.6819 - val_acc: 0.9791 - val_mDice: 0.7776

Epoch 00184: val_mDice improved from 0.77632 to 0.77765, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 185/300
 - 21s - loss: 0.6989 - acc: 0.9677 - mDice: 0.7623 - val_loss: 0.6871 - val_acc: 0.9782 - val_mDice: 0.7751

Epoch 00185: val_mDice did not improve from 0.77765
Epoch 186/300
 - 20s - loss: 0.6990 - acc: 0.9677 - mDice: 0.7621 - val_loss: 0.6826 - val_acc: 0.9789 - val_mDice: 0.7744

Epoch 00186: val_mDice did not improve from 0.77765
Epoch 187/300
 - 20s - loss: 0.6995 - acc: 0.9677 - mDice: 0.7620 - val_loss: 0.6916 - val_acc: 0.9786 - val_mDice: 0.7738

Epoch 00187: val_mDice did not improve from 0.77765
Epoch 188/300
 - 21s - loss: 0.6991 - acc: 0.9676 - mDice: 0.7622 - val_loss: 0.6840 - val_acc: 0.9789 - val_mDice: 0.7726

Epoch 00188: val_mDice did not improve from 0.77765
Epoch 189/300
 - 20s - loss: 0.6987 - acc: 0.9677 - mDice: 0.7619 - val_loss: 0.6815 - val_acc: 0.9788 - val_mDice: 0.7742

Epoch 00189: val_mDice did not improve from 0.77765
Epoch 190/300
 - 21s - loss: 0.6970 - acc: 0.9677 - mDice: 0.7630 - val_loss: 0.6885 - val_acc: 0.9791 - val_mDice: 0.7744

Epoch 00190: val_mDice did not improve from 0.77765
Epoch 191/300
 - 21s - loss: 0.6944 - acc: 0.9678 - mDice: 0.7638 - val_loss: 0.6893 - val_acc: 0.9789 - val_mDice: 0.7762

Epoch 00191: val_mDice did not improve from 0.77765
Epoch 192/300
 - 20s - loss: 0.6965 - acc: 0.9677 - mDice: 0.7632 - val_loss: 0.6789 - val_acc: 0.9789 - val_mDice: 0.7769

Epoch 00192: val_mDice did not improve from 0.77765
Epoch 193/300
 - 22s - loss: 0.6963 - acc: 0.9677 - mDice: 0.7631 - val_loss: 0.6755 - val_acc: 0.9791 - val_mDice: 0.7713

Epoch 00193: val_mDice did not improve from 0.77765
Epoch 194/300
 - 20s - loss: 0.6950 - acc: 0.9678 - mDice: 0.7636 - val_loss: 0.6725 - val_acc: 0.9792 - val_mDice: 0.7792

Epoch 00194: val_mDice improved from 0.77765 to 0.77916, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 195/300
 - 21s - loss: 0.6953 - acc: 0.9677 - mDice: 0.7635 - val_loss: 0.6871 - val_acc: 0.9792 - val_mDice: 0.7737

Epoch 00195: val_mDice did not improve from 0.77916
Epoch 196/300
 - 21s - loss: 0.6958 - acc: 0.9678 - mDice: 0.7631 - val_loss: 0.6731 - val_acc: 0.9793 - val_mDice: 0.7799

Epoch 00196: val_mDice improved from 0.77916 to 0.77991, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 197/300
 - 19s - loss: 0.6928 - acc: 0.9678 - mDice: 0.7642 - val_loss: 0.6871 - val_acc: 0.9784 - val_mDice: 0.7760

Epoch 00197: val_mDice did not improve from 0.77991
Epoch 198/300
 - 20s - loss: 0.6935 - acc: 0.9678 - mDice: 0.7640 - val_loss: 0.6764 - val_acc: 0.9790 - val_mDice: 0.7753

Epoch 00198: val_mDice did not improve from 0.77991
Epoch 199/300
 - 19s - loss: 0.6924 - acc: 0.9678 - mDice: 0.7642 - val_loss: 0.6807 - val_acc: 0.9796 - val_mDice: 0.7762

Epoch 00199: val_mDice did not improve from 0.77991
Epoch 200/300
 - 19s - loss: 0.6923 - acc: 0.9678 - mDice: 0.7645 - val_loss: 0.6795 - val_acc: 0.9796 - val_mDice: 0.7749

Epoch 00200: val_mDice did not improve from 0.77991
Epoch 201/300
 - 20s - loss: 0.6926 - acc: 0.9678 - mDice: 0.7643 - val_loss: 0.6765 - val_acc: 0.9791 - val_mDice: 0.7773

Epoch 00201: val_mDice did not improve from 0.77991
Epoch 202/300
 - 18s - loss: 0.6914 - acc: 0.9679 - mDice: 0.7647 - val_loss: 0.6718 - val_acc: 0.9796 - val_mDice: 0.7792

Epoch 00202: val_mDice did not improve from 0.77991
Epoch 203/300
 - 19s - loss: 0.6917 - acc: 0.9678 - mDice: 0.7648 - val_loss: 0.6823 - val_acc: 0.9791 - val_mDice: 0.7763

Epoch 00203: val_mDice did not improve from 0.77991
Epoch 204/300
 - 19s - loss: 0.6916 - acc: 0.9678 - mDice: 0.7648 - val_loss: 0.6762 - val_acc: 0.9795 - val_mDice: 0.7776

Epoch 00204: val_mDice did not improve from 0.77991
Epoch 205/300
 - 20s - loss: 0.6906 - acc: 0.9679 - mDice: 0.7651 - val_loss: 0.6869 - val_acc: 0.9787 - val_mDice: 0.7781

Epoch 00205: val_mDice did not improve from 0.77991
Epoch 206/300
 - 18s - loss: 0.6906 - acc: 0.9678 - mDice: 0.7651 - val_loss: 0.6841 - val_acc: 0.9795 - val_mDice: 0.7778

Epoch 00206: val_mDice did not improve from 0.77991
Epoch 207/300
 - 20s - loss: 0.6890 - acc: 0.9679 - mDice: 0.7657 - val_loss: 0.6779 - val_acc: 0.9783 - val_mDice: 0.7799

Epoch 00207: val_mDice did not improve from 0.77991
Epoch 208/300
 - 20s - loss: 0.6898 - acc: 0.9679 - mDice: 0.7655 - val_loss: 0.6758 - val_acc: 0.9793 - val_mDice: 0.7777

Epoch 00208: val_mDice did not improve from 0.77991
Epoch 209/300
 - 20s - loss: 0.6876 - acc: 0.9679 - mDice: 0.7660 - val_loss: 0.6747 - val_acc: 0.9789 - val_mDice: 0.7784

Epoch 00209: val_mDice did not improve from 0.77991
Epoch 210/300
 - 20s - loss: 0.6892 - acc: 0.9679 - mDice: 0.7655 - val_loss: 0.6830 - val_acc: 0.9788 - val_mDice: 0.7801

Epoch 00210: val_mDice improved from 0.77991 to 0.78005, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 211/300
 - 19s - loss: 0.6889 - acc: 0.9678 - mDice: 0.7659 - val_loss: 0.6802 - val_acc: 0.9790 - val_mDice: 0.7768

Epoch 00211: val_mDice did not improve from 0.78005
Epoch 212/300
 - 21s - loss: 0.6877 - acc: 0.9679 - mDice: 0.7661 - val_loss: 0.6794 - val_acc: 0.9792 - val_mDice: 0.7797

Epoch 00212: val_mDice did not improve from 0.78005
Epoch 213/300
 - 20s - loss: 0.6866 - acc: 0.9680 - mDice: 0.7665 - val_loss: 0.6754 - val_acc: 0.9788 - val_mDice: 0.7784

Epoch 00213: val_mDice did not improve from 0.78005
Epoch 214/300
 - 20s - loss: 0.6863 - acc: 0.9679 - mDice: 0.7665 - val_loss: 0.6851 - val_acc: 0.9788 - val_mDice: 0.7777

Epoch 00214: val_mDice did not improve from 0.78005
Epoch 215/300
 - 21s - loss: 0.6887 - acc: 0.9679 - mDice: 0.7660 - val_loss: 0.6719 - val_acc: 0.9788 - val_mDice: 0.7766

Epoch 00215: val_mDice did not improve from 0.78005
Epoch 216/300
 - 20s - loss: 0.6868 - acc: 0.9680 - mDice: 0.7665 - val_loss: 0.6816 - val_acc: 0.9793 - val_mDice: 0.7769

Epoch 00216: val_mDice did not improve from 0.78005
Epoch 217/300
 - 20s - loss: 0.6874 - acc: 0.9679 - mDice: 0.7664 - val_loss: 0.6732 - val_acc: 0.9797 - val_mDice: 0.7778

Epoch 00217: val_mDice did not improve from 0.78005
Epoch 218/300
 - 21s - loss: 0.6866 - acc: 0.9679 - mDice: 0.7667 - val_loss: 0.6736 - val_acc: 0.9794 - val_mDice: 0.7788

Epoch 00218: val_mDice did not improve from 0.78005
Epoch 219/300
 - 19s - loss: 0.6857 - acc: 0.9680 - mDice: 0.7666 - val_loss: 0.6712 - val_acc: 0.9796 - val_mDice: 0.7801

Epoch 00219: val_mDice improved from 0.78005 to 0.78007, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 220/300
 - 20s - loss: 0.6848 - acc: 0.9679 - mDice: 0.7671 - val_loss: 0.6746 - val_acc: 0.9790 - val_mDice: 0.7784

Epoch 00220: val_mDice did not improve from 0.78007
Epoch 221/300
 - 18s - loss: 0.6849 - acc: 0.9680 - mDice: 0.7670 - val_loss: 0.6773 - val_acc: 0.9793 - val_mDice: 0.7792

Epoch 00221: val_mDice did not improve from 0.78007
Epoch 222/300
 - 19s - loss: 0.6841 - acc: 0.9680 - mDice: 0.7672 - val_loss: 0.6691 - val_acc: 0.9796 - val_mDice: 0.7769

Epoch 00222: val_mDice did not improve from 0.78007
Epoch 223/300
 - 18s - loss: 0.6841 - acc: 0.9680 - mDice: 0.7675 - val_loss: 0.6887 - val_acc: 0.9798 - val_mDice: 0.7755

Epoch 00223: val_mDice did not improve from 0.78007
Epoch 224/300
 - 18s - loss: 0.6830 - acc: 0.9680 - mDice: 0.7678 - val_loss: 0.6901 - val_acc: 0.9793 - val_mDice: 0.7786

Epoch 00224: val_mDice did not improve from 0.78007
Epoch 225/300
 - 19s - loss: 0.6842 - acc: 0.9680 - mDice: 0.7674 - val_loss: 0.6695 - val_acc: 0.9796 - val_mDice: 0.7826

Epoch 00225: val_mDice improved from 0.78007 to 0.78263, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 226/300
 - 18s - loss: 0.6836 - acc: 0.9680 - mDice: 0.7678 - val_loss: 0.6845 - val_acc: 0.9795 - val_mDice: 0.7753

Epoch 00226: val_mDice did not improve from 0.78263
Epoch 227/300
 - 17s - loss: 0.6830 - acc: 0.9680 - mDice: 0.7677 - val_loss: 0.6809 - val_acc: 0.9784 - val_mDice: 0.7795

Epoch 00227: val_mDice did not improve from 0.78263
Epoch 228/300
 - 17s - loss: 0.6830 - acc: 0.9681 - mDice: 0.7678 - val_loss: 0.6839 - val_acc: 0.9794 - val_mDice: 0.7752

Epoch 00228: val_mDice did not improve from 0.78263
Epoch 229/300
 - 18s - loss: 0.6832 - acc: 0.9681 - mDice: 0.7679 - val_loss: 0.6714 - val_acc: 0.9791 - val_mDice: 0.7787

Epoch 00229: val_mDice did not improve from 0.78263
Epoch 230/300
 - 19s - loss: 0.6824 - acc: 0.9680 - mDice: 0.7680 - val_loss: 0.6690 - val_acc: 0.9792 - val_mDice: 0.7800

Epoch 00230: val_mDice did not improve from 0.78263
Epoch 231/300
 - 17s - loss: 0.6813 - acc: 0.9681 - mDice: 0.7685 - val_loss: 0.6742 - val_acc: 0.9797 - val_mDice: 0.7783

Epoch 00231: val_mDice did not improve from 0.78263
Epoch 232/300
 - 17s - loss: 0.6814 - acc: 0.9681 - mDice: 0.7684 - val_loss: 0.6712 - val_acc: 0.9792 - val_mDice: 0.7776

Epoch 00232: val_mDice did not improve from 0.78263
Epoch 233/300
 - 18s - loss: 0.6800 - acc: 0.9681 - mDice: 0.7688 - val_loss: 0.6728 - val_acc: 0.9794 - val_mDice: 0.7794

Epoch 00233: val_mDice did not improve from 0.78263
Epoch 234/300
 - 18s - loss: 0.6826 - acc: 0.9681 - mDice: 0.7680 - val_loss: 0.6717 - val_acc: 0.9792 - val_mDice: 0.7779

Epoch 00234: val_mDice did not improve from 0.78263
Epoch 235/300
 - 19s - loss: 0.6808 - acc: 0.9681 - mDice: 0.7684 - val_loss: 0.6843 - val_acc: 0.9795 - val_mDice: 0.7792

Epoch 00235: val_mDice did not improve from 0.78263
Epoch 236/300
 - 18s - loss: 0.6796 - acc: 0.9682 - mDice: 0.7691 - val_loss: 0.6737 - val_acc: 0.9789 - val_mDice: 0.7794

Epoch 00236: val_mDice did not improve from 0.78263
Epoch 237/300
 - 18s - loss: 0.6800 - acc: 0.9682 - mDice: 0.7691 - val_loss: 0.6684 - val_acc: 0.9798 - val_mDice: 0.7790

Epoch 00237: val_mDice did not improve from 0.78263
Epoch 238/300
 - 18s - loss: 0.6789 - acc: 0.9681 - mDice: 0.7691 - val_loss: 0.6754 - val_acc: 0.9795 - val_mDice: 0.7810

Epoch 00238: val_mDice did not improve from 0.78263
Epoch 239/300
 - 18s - loss: 0.6801 - acc: 0.9681 - mDice: 0.7689 - val_loss: 0.6708 - val_acc: 0.9796 - val_mDice: 0.7801

Epoch 00239: val_mDice did not improve from 0.78263
Epoch 240/300
 - 19s - loss: 0.6795 - acc: 0.9682 - mDice: 0.7691 - val_loss: 0.6662 - val_acc: 0.9791 - val_mDice: 0.7816

Epoch 00240: val_mDice did not improve from 0.78263
Epoch 241/300
 - 18s - loss: 0.6789 - acc: 0.9682 - mDice: 0.7692 - val_loss: 0.6755 - val_acc: 0.9796 - val_mDice: 0.7820

Epoch 00241: val_mDice did not improve from 0.78263
Epoch 242/300
 - 18s - loss: 0.6794 - acc: 0.9682 - mDice: 0.7691 - val_loss: 0.6739 - val_acc: 0.9790 - val_mDice: 0.7807

Epoch 00242: val_mDice did not improve from 0.78263
Epoch 243/300
 - 18s - loss: 0.6784 - acc: 0.9682 - mDice: 0.7693 - val_loss: 0.6802 - val_acc: 0.9789 - val_mDice: 0.7797

Epoch 00243: val_mDice did not improve from 0.78263
Epoch 244/300
 - 18s - loss: 0.6765 - acc: 0.9682 - mDice: 0.7700 - val_loss: 0.6780 - val_acc: 0.9797 - val_mDice: 0.7815

Epoch 00244: val_mDice did not improve from 0.78263
Epoch 245/300
 - 19s - loss: 0.6765 - acc: 0.9682 - mDice: 0.7699 - val_loss: 0.6848 - val_acc: 0.9794 - val_mDice: 0.7774

Epoch 00245: val_mDice did not improve from 0.78263
Epoch 246/300
 - 18s - loss: 0.6753 - acc: 0.9683 - mDice: 0.7702 - val_loss: 0.6629 - val_acc: 0.9798 - val_mDice: 0.7829

Epoch 00246: val_mDice improved from 0.78263 to 0.78287, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 247/300
 - 18s - loss: 0.6775 - acc: 0.9683 - mDice: 0.7700 - val_loss: 0.6718 - val_acc: 0.9794 - val_mDice: 0.7802

Epoch 00247: val_mDice did not improve from 0.78287
Epoch 248/300
 - 18s - loss: 0.6765 - acc: 0.9683 - mDice: 0.7700 - val_loss: 0.6731 - val_acc: 0.9799 - val_mDice: 0.7797

Epoch 00248: val_mDice did not improve from 0.78287
Epoch 249/300
 - 19s - loss: 0.6754 - acc: 0.9683 - mDice: 0.7705 - val_loss: 0.6760 - val_acc: 0.9795 - val_mDice: 0.7793

Epoch 00249: val_mDice did not improve from 0.78287
Epoch 250/300
 - 18s - loss: 0.6772 - acc: 0.9683 - mDice: 0.7698 - val_loss: 0.6704 - val_acc: 0.9797 - val_mDice: 0.7792

Epoch 00250: val_mDice did not improve from 0.78287
Epoch 251/300
 - 18s - loss: 0.6756 - acc: 0.9683 - mDice: 0.7701 - val_loss: 0.6636 - val_acc: 0.9791 - val_mDice: 0.7801

Epoch 00251: val_mDice did not improve from 0.78287
Epoch 252/300
 - 18s - loss: 0.6749 - acc: 0.9683 - mDice: 0.7705 - val_loss: 0.6762 - val_acc: 0.9792 - val_mDice: 0.7798

Epoch 00252: val_mDice did not improve from 0.78287
Epoch 253/300
 - 18s - loss: 0.6759 - acc: 0.9683 - mDice: 0.7701 - val_loss: 0.6696 - val_acc: 0.9797 - val_mDice: 0.7800

Epoch 00253: val_mDice did not improve from 0.78287
Epoch 254/300
 - 19s - loss: 0.6762 - acc: 0.9683 - mDice: 0.7702 - val_loss: 0.6686 - val_acc: 0.9794 - val_mDice: 0.7823

Epoch 00254: val_mDice did not improve from 0.78287
Epoch 255/300
 - 18s - loss: 0.6765 - acc: 0.9683 - mDice: 0.7699 - val_loss: 0.6709 - val_acc: 0.9794 - val_mDice: 0.7813

Epoch 00255: val_mDice did not improve from 0.78287
Epoch 256/300
 - 18s - loss: 0.6751 - acc: 0.9683 - mDice: 0.7706 - val_loss: 0.6803 - val_acc: 0.9789 - val_mDice: 0.7814

Epoch 00256: val_mDice did not improve from 0.78287
Epoch 257/300
 - 17s - loss: 0.6752 - acc: 0.9684 - mDice: 0.7706 - val_loss: 0.6663 - val_acc: 0.9798 - val_mDice: 0.7805

Epoch 00257: val_mDice did not improve from 0.78287
Epoch 258/300
 - 18s - loss: 0.6749 - acc: 0.9684 - mDice: 0.7706 - val_loss: 0.6728 - val_acc: 0.9798 - val_mDice: 0.7805

Epoch 00258: val_mDice did not improve from 0.78287
Epoch 259/300
 - 19s - loss: 0.6720 - acc: 0.9684 - mDice: 0.7715 - val_loss: 0.6693 - val_acc: 0.9791 - val_mDice: 0.7826

Epoch 00259: val_mDice did not improve from 0.78287
Epoch 260/300
 - 18s - loss: 0.6718 - acc: 0.9684 - mDice: 0.7714 - val_loss: 0.6689 - val_acc: 0.9795 - val_mDice: 0.7815

Epoch 00260: val_mDice did not improve from 0.78287
Epoch 261/300
 - 18s - loss: 0.6732 - acc: 0.9684 - mDice: 0.7716 - val_loss: 0.6632 - val_acc: 0.9794 - val_mDice: 0.7822

Epoch 00261: val_mDice did not improve from 0.78287
Epoch 262/300
 - 17s - loss: 0.6727 - acc: 0.9684 - mDice: 0.7714 - val_loss: 0.6652 - val_acc: 0.9798 - val_mDice: 0.7831

Epoch 00262: val_mDice improved from 0.78287 to 0.78312, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 263/300
 - 18s - loss: 0.6730 - acc: 0.9684 - mDice: 0.7712 - val_loss: 0.6680 - val_acc: 0.9798 - val_mDice: 0.7817

Epoch 00263: val_mDice did not improve from 0.78312
Epoch 264/300
 - 19s - loss: 0.6737 - acc: 0.9684 - mDice: 0.7712 - val_loss: 0.6684 - val_acc: 0.9795 - val_mDice: 0.7813

Epoch 00264: val_mDice did not improve from 0.78312
Epoch 265/300
 - 18s - loss: 0.6708 - acc: 0.9684 - mDice: 0.7721 - val_loss: 0.6726 - val_acc: 0.9795 - val_mDice: 0.7812

Epoch 00265: val_mDice did not improve from 0.78312
Epoch 266/300
 - 18s - loss: 0.6716 - acc: 0.9684 - mDice: 0.7719 - val_loss: 0.6666 - val_acc: 0.9796 - val_mDice: 0.7803

Epoch 00266: val_mDice did not improve from 0.78312
Epoch 267/300
 - 19s - loss: 0.6716 - acc: 0.9685 - mDice: 0.7716 - val_loss: 0.6739 - val_acc: 0.9791 - val_mDice: 0.7821

Epoch 00267: val_mDice did not improve from 0.78312
Epoch 268/300
 - 18s - loss: 0.6722 - acc: 0.9684 - mDice: 0.7715 - val_loss: 0.6761 - val_acc: 0.9791 - val_mDice: 0.7794

Epoch 00268: val_mDice did not improve from 0.78312
Epoch 269/300
 - 17s - loss: 0.6730 - acc: 0.9684 - mDice: 0.7714 - val_loss: 0.6792 - val_acc: 0.9792 - val_mDice: 0.7809

Epoch 00269: val_mDice did not improve from 0.78312
Epoch 270/300
 - 18s - loss: 0.6730 - acc: 0.9684 - mDice: 0.7714 - val_loss: 0.6699 - val_acc: 0.9795 - val_mDice: 0.7793

Epoch 00270: val_mDice did not improve from 0.78312
Epoch 271/300
 - 19s - loss: 0.6710 - acc: 0.9685 - mDice: 0.7719 - val_loss: 0.6684 - val_acc: 0.9796 - val_mDice: 0.7817

Epoch 00271: val_mDice did not improve from 0.78312
Epoch 272/300
 - 18s - loss: 0.6700 - acc: 0.9685 - mDice: 0.7722 - val_loss: 0.6823 - val_acc: 0.9796 - val_mDice: 0.7819

Epoch 00272: val_mDice did not improve from 0.78312
Epoch 273/300
 - 17s - loss: 0.6693 - acc: 0.9685 - mDice: 0.7725 - val_loss: 0.6674 - val_acc: 0.9798 - val_mDice: 0.7812

Epoch 00273: val_mDice did not improve from 0.78312
Epoch 274/300
 - 18s - loss: 0.6705 - acc: 0.9685 - mDice: 0.7720 - val_loss: 0.6698 - val_acc: 0.9795 - val_mDice: 0.7822

Epoch 00274: val_mDice did not improve from 0.78312
Epoch 275/300
 - 18s - loss: 0.6697 - acc: 0.9685 - mDice: 0.7723 - val_loss: 0.6681 - val_acc: 0.9797 - val_mDice: 0.7805

Epoch 00275: val_mDice did not improve from 0.78312
Epoch 276/300
 - 19s - loss: 0.6686 - acc: 0.9685 - mDice: 0.7729 - val_loss: 0.6716 - val_acc: 0.9789 - val_mDice: 0.7809

Epoch 00276: val_mDice did not improve from 0.78312
Epoch 277/300
 - 18s - loss: 0.6696 - acc: 0.9685 - mDice: 0.7724 - val_loss: 0.6743 - val_acc: 0.9797 - val_mDice: 0.7802

Epoch 00277: val_mDice did not improve from 0.78312
Epoch 278/300
 - 18s - loss: 0.6687 - acc: 0.9685 - mDice: 0.7728 - val_loss: 0.6615 - val_acc: 0.9799 - val_mDice: 0.7834

Epoch 00278: val_mDice improved from 0.78312 to 0.78336, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 279/300
 - 17s - loss: 0.6689 - acc: 0.9686 - mDice: 0.7725 - val_loss: 0.6675 - val_acc: 0.9794 - val_mDice: 0.7825

Epoch 00279: val_mDice did not improve from 0.78336
Epoch 280/300
 - 18s - loss: 0.6692 - acc: 0.9685 - mDice: 0.7723 - val_loss: 0.6746 - val_acc: 0.9789 - val_mDice: 0.7805

Epoch 00280: val_mDice did not improve from 0.78336
Epoch 281/300
 - 19s - loss: 0.6700 - acc: 0.9686 - mDice: 0.7723 - val_loss: 0.6591 - val_acc: 0.9798 - val_mDice: 0.7836

Epoch 00281: val_mDice improved from 0.78336 to 0.78359, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 282/300
 - 18s - loss: 0.6674 - acc: 0.9686 - mDice: 0.7729 - val_loss: 0.6640 - val_acc: 0.9796 - val_mDice: 0.7820

Epoch 00282: val_mDice did not improve from 0.78359
Epoch 283/300
 - 18s - loss: 0.6685 - acc: 0.9686 - mDice: 0.7727 - val_loss: 0.6693 - val_acc: 0.9795 - val_mDice: 0.7814

Epoch 00283: val_mDice did not improve from 0.78359
Epoch 284/300
 - 18s - loss: 0.6667 - acc: 0.9686 - mDice: 0.7734 - val_loss: 0.6697 - val_acc: 0.9793 - val_mDice: 0.7824

Epoch 00284: val_mDice did not improve from 0.78359
Epoch 285/300
 - 17s - loss: 0.6679 - acc: 0.9686 - mDice: 0.7730 - val_loss: 0.6764 - val_acc: 0.9791 - val_mDice: 0.7820

Epoch 00285: val_mDice did not improve from 0.78359
Epoch 286/300
 - 19s - loss: 0.6664 - acc: 0.9686 - mDice: 0.7735 - val_loss: 0.6633 - val_acc: 0.9793 - val_mDice: 0.7820

Epoch 00286: val_mDice did not improve from 0.78359
Epoch 287/300
 - 18s - loss: 0.6700 - acc: 0.9685 - mDice: 0.7722 - val_loss: 0.6680 - val_acc: 0.9793 - val_mDice: 0.7832

Epoch 00287: val_mDice did not improve from 0.78359
Epoch 288/300
 - 18s - loss: 0.6663 - acc: 0.9686 - mDice: 0.7732 - val_loss: 0.6671 - val_acc: 0.9794 - val_mDice: 0.7832

Epoch 00288: val_mDice did not improve from 0.78359
Epoch 289/300
 - 18s - loss: 0.6660 - acc: 0.9686 - mDice: 0.7736 - val_loss: 0.6625 - val_acc: 0.9798 - val_mDice: 0.7844

Epoch 00289: val_mDice improved from 0.78359 to 0.78438, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 290/300
 - 18s - loss: 0.6663 - acc: 0.9686 - mDice: 0.7734 - val_loss: 0.6605 - val_acc: 0.9794 - val_mDice: 0.7840

Epoch 00290: val_mDice did not improve from 0.78438
Epoch 291/300
 - 18s - loss: 0.6678 - acc: 0.9686 - mDice: 0.7732 - val_loss: 0.6705 - val_acc: 0.9798 - val_mDice: 0.7856

Epoch 00291: val_mDice improved from 0.78438 to 0.78561, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 292/300
 - 19s - loss: 0.6657 - acc: 0.9686 - mDice: 0.7736 - val_loss: 0.6646 - val_acc: 0.9793 - val_mDice: 0.7824

Epoch 00292: val_mDice did not improve from 0.78561
Epoch 293/300
 - 18s - loss: 0.6677 - acc: 0.9686 - mDice: 0.7730 - val_loss: 0.6674 - val_acc: 0.9800 - val_mDice: 0.7843

Epoch 00293: val_mDice did not improve from 0.78561
Epoch 294/300
 - 19s - loss: 0.6655 - acc: 0.9686 - mDice: 0.7736 - val_loss: 0.6631 - val_acc: 0.9796 - val_mDice: 0.7845

Epoch 00294: val_mDice did not improve from 0.78561
Epoch 295/300
 - 19s - loss: 0.6660 - acc: 0.9687 - mDice: 0.7735 - val_loss: 0.6777 - val_acc: 0.9799 - val_mDice: 0.7823

Epoch 00295: val_mDice did not improve from 0.78561
Epoch 296/300
 - 18s - loss: 0.6667 - acc: 0.9686 - mDice: 0.7733 - val_loss: 0.6672 - val_acc: 0.9797 - val_mDice: 0.7841

Epoch 00296: val_mDice did not improve from 0.78561
Epoch 297/300
 - 20s - loss: 0.6656 - acc: 0.9687 - mDice: 0.7737 - val_loss: 0.6785 - val_acc: 0.9799 - val_mDice: 0.7818

Epoch 00297: val_mDice did not improve from 0.78561
Epoch 298/300
 - 18s - loss: 0.6648 - acc: 0.9686 - mDice: 0.7739 - val_loss: 0.6609 - val_acc: 0.9801 - val_mDice: 0.7824

Epoch 00298: val_mDice did not improve from 0.78561
Epoch 299/300
 - 20s - loss: 0.6649 - acc: 0.9687 - mDice: 0.7743 - val_loss: 0.6633 - val_acc: 0.9795 - val_mDice: 0.7844

Epoch 00299: val_mDice did not improve from 0.78561
Epoch 300/300
 - 18s - loss: 0.6628 - acc: 0.9687 - mDice: 0.7746 - val_loss: 0.6740 - val_acc: 0.9794 - val_mDice: 0.7787

Epoch 00300: val_mDice did not improve from 0.78561
{'val_loss': [5.663280098405603, 4.139637788681135, 2.7769381314107817, 2.361591745729316, 1.7674513320400291, 1.5402595262004906, 1.2385653690116045, 1.1182057971823705, 1.0817440601244366, 0.9802286996416849, 0.9674357290137304, 0.9355940067604797, 0.9032094948095818, 0.8901313506577113, 0.8795509138335921, 0.8828343859274094, 0.8411192412245764, 0.8393025026745993, 0.8136949384049194, 0.8239824702478435, 0.8289378334398139, 0.815319105778655, 0.7909661800894019, 0.7872337262107901, 0.7764436418879522, 0.7833886244525649, 0.7834576547962345, 0.781551428445398, 0.7828093252769889, 0.7660004178138629, 0.7602649910809243, 0.758214387991657, 0.7528418718952022, 0.7536982902108806, 0.7379492292665455, 0.7530382508284426, 0.7466983897228764, 0.7512846536015811, 0.735981038580202, 0.7430556914577745, 0.7320447445732273, 0.7315676355198638, 0.7338476662766443, 0.7421304359011454, 0.7443917116073713, 0.7298616032077841, 0.7234736783047245, 0.7343332620516215, 0.7262484516999493, 0.7168438124330077, 0.7264491809557562, 0.7267886110364574, 0.7205417854328678, 0.7252396773802091, 0.7275570978040564, 0.715001743950256, 0.7336964354123154, 0.7158729593231253, 0.7205256913622765, 0.7160221272951937, 0.7189782208775821, 0.704852965188353, 0.7154613059677489, 0.7063389612387304, 0.7092149290319991, 0.7127654732090153, 0.7072136610338132, 0.7127315504093693, 0.7203692899991389, 0.7092047027529103, 0.716377753917485, 0.7094653297777045, 0.694531939617575, 0.7081120459184255, 0.7264289570181337, 0.6944981939988594, 0.7005360853182127, 0.7052101260178709, 0.6908767002902619, 0.6997887479932341, 0.7023196146912771, 0.7155616577357462, 0.6993230189362617, 0.7037527414217387, 0.7001797695682473, 0.7034511243643826, 0.7011341403608453, 0.6989277466519238, 0.7005360808274518, 0.7024696808155269, 0.7076100564166291, 0.6976404312538774, 0.6927855251586601, 0.6966895318194611, 0.7102249991403867, 0.6981433748382412, 0.6931141843534496, 0.7046780071846427, 0.6895817959145324, 0.6870978519524613, 0.7042298047509912, 0.7046052025605555, 0.6897886179081382, 0.6881133064831773, 0.6930568593822114, 0.697892914487891, 0.697678609253609, 0.6886275206526665, 0.6937099711535728, 0.6913247663680822, 0.7094675224937804, 0.6965550184249878, 0.693448300639244, 0.690512384045614, 0.6958397251285918, 0.6946371352835877, 0.692850457070625, 0.685800360081947, 0.6912543046964358, 0.6932707526912428, 0.7042370961137014, 0.6905236138056402, 0.6958462489794378, 0.7023588949686861, 0.6886741400581516, 0.6926854661066238, 0.6874748435738969, 0.6921112365918617, 0.6935410568975422, 0.6923096571883111, 0.7089658069283995, 0.6947573031464668, 0.6857592171593888, 0.6963532346568696, 0.6902625148426996, 0.7006116386962263, 0.6834682299666208, 0.7001092168566299, 0.6886841205701436, 0.6908708263749945, 0.7003899192156857, 0.692987227684831, 0.6865716172407751, 0.6864313924149291, 0.6837972933298921, 0.6908977325648478, 0.6844622717328268, 0.6775231271573942, 0.6878736758068816, 0.7012664234801514, 0.6802565475849256, 0.6918937225047856, 0.6823841125181277, 0.6755009095554483, 0.6795521288701932, 0.6942059442605057, 0.6940936846275853, 0.6757822004083085, 0.6887095439923953, 0.686138391903002, 0.6799003138934097, 0.6829981440550661, 0.68780458708332, 0.6800928585333367, 0.6939247275052005, 0.6881215443758115, 0.6875647134976844, 0.6904931962490082, 0.6823082394795875, 0.6888349672702894, 0.6883789892882517, 0.6799961446899258, 0.6951810819645451, 0.6881086136380287, 0.6771685350431155, 0.680461487133209, 0.6886752517256018, 0.6851809494299431, 0.6818539739063342, 0.6785584512638719, 0.6803131866944979, 0.6806812494584958, 0.6828264324632409, 0.6818841771311956, 0.6871432592607525, 0.6826001924194701, 0.6916327766359669, 0.6840146306442888, 0.6815404724584867, 0.6884793402397469, 0.6893369555473328, 0.6788787229420388, 0.6754818074915507, 0.672456974852575, 0.6871257673387658, 0.6730645841931644, 0.6870626235661441, 0.676396344418395, 0.6806879174219419, 0.6794963593352331, 0.6764510661771853, 0.6717590977476068, 0.6822813373722442, 0.6762194872310717, 0.6868697249726073, 0.6841148182953873, 0.6779117069832267, 0.6758231494116457, 0.6746825861604246, 0.6830328423274706, 0.6802247532018243, 0.6794126288939829, 0.6754277675119165, 0.6850528514956775, 0.6718618935101652, 0.68163561045307, 0.6732329371040815, 0.6736491653200698, 0.6711677549636528, 0.6745616056739467, 0.6772552814385663, 0.6690773108642395, 0.6887284505040678, 0.6901253923161389, 0.669508939328259, 0.6845304602629518, 0.6808715938297036, 0.6838588753383453, 0.6714137886485009, 0.6690414323382181, 0.6741547282427958, 0.6712075198349887, 0.672843437897016, 0.6716761305315854, 0.6843424000560421, 0.6737047599194801, 0.6683600945015477, 0.6754097179190753, 0.6708024499351031, 0.6662199862607537, 0.6754764228650968, 0.6738993558165145, 0.6802146879777516, 0.6779708639807898, 0.6847619473525922, 0.6628932420113315, 0.6718160614167175, 0.6730829918221252, 0.675999690408576, 0.6704310058322671, 0.6636347962568884, 0.6762317582352521, 0.6696018668478483, 0.6685602595544842, 0.6709305944099818, 0.680301210243408, 0.6663033825485674, 0.6727980910098716, 0.6693105903798586, 0.6688919316415918, 0.6632120774625099, 0.665216961135603, 0.6680258818685192, 0.6683883752724896, 0.6725721281685241, 0.6665878875614846, 0.673881323370215, 0.676083895033353, 0.6792346916786612, 0.6699388008819868, 0.6683835460715097, 0.6823002467416737, 0.6673522518105703, 0.6697552894076256, 0.6680532012083759, 0.6715682263243689, 0.6742690038191129, 0.6614949201067833, 0.6675027325137021, 0.6745862093282072, 0.6590849308118428, 0.6639611863926665, 0.6692772713834292, 0.6696534038406529, 0.6764264849767293, 0.6632740460846522, 0.6679820873557705, 0.6670961406541197, 0.6625362706102736, 0.660544825130946, 0.670536854495741, 0.6645889069936047, 0.6673806762858613, 0.6631157275748579, 0.6777481308130369, 0.6671662204069634, 0.6785102627457005, 0.6608901868944299, 0.6632637808175936, 0.6739703651568661], 'val_acc': [0.9134473159705123, 0.9134480446985324, 0.9187004186519204, 0.9194000485825212, 0.9457151101876612, 0.9524916238980751, 0.961880671243145, 0.9680012048107304, 0.9675975250054712, 0.9713847371813369, 0.9717585787381211, 0.973364626299845, 0.973803996223293, 0.97399619915714, 0.9748356199427827, 0.9750285295590962, 0.9737340877317402, 0.973924115096053, 0.9745909971733616, 0.9749743052541393, 0.9736714930567023, 0.9755833144873789, 0.9755195865075882, 0.9756160562169062, 0.9761966683276712, 0.9763946900629017, 0.9760459526760937, 0.9752502245445774, 0.9759232891749029, 0.9766545997907038, 0.9762785638848396, 0.9762345164606016, 0.9767517978197908, 0.9770855968945646, 0.9770910617423384, 0.9769607325122781, 0.9762876760469724, 0.9769771119503126, 0.97717148882069, 0.9774922014099278, 0.9774132105585647, 0.9766767980301216, 0.9775937518028364, 0.9776432587675852, 0.9778201816833183, 0.9776469146552151, 0.9778376421699785, 0.9776247037600164, 0.9780706281531347, 0.9778463864979678, 0.9776163203259037, 0.977942850900023, 0.978318505907712, 0.9777320852018383, 0.9780957376303738, 0.9785092603670408, 0.9783960535918197, 0.9784488339130193, 0.9779402976983214, 0.9782904925411695, 0.9785019788023543, 0.9782839282734753, 0.9782467913137723, 0.978492161182508, 0.9788565313162869, 0.9782289670754786, 0.978354178062857, 0.9784717563896963, 0.9781805456501164, 0.9788641782656108, 0.9785460111213057, 0.9781095679492167, 0.979258755706761, 0.9785798653347851, 0.978759327979937, 0.978942433856938, 0.978855794423247, 0.9781958366910072, 0.9789133075981924, 0.9781827228526546, 0.9781448783939832, 0.9782333386270967, 0.9784994325409196, 0.9780232992074261, 0.9786140853411531, 0.9785591265926622, 0.9785077992367418, 0.9786180837513649, 0.9784015082333186, 0.9786173664543727, 0.9788011937108758, 0.978805566078996, 0.9789700895956118, 0.9788255769096009, 0.9776137822294888, 0.9785591123038775, 0.9791506475781742, 0.9789955885442969, 0.9787043594334224, 0.9795830882575414, 0.9783097746437543, 0.9789668223629259, 0.9788485116338077, 0.9785066965508135, 0.9787323932125144, 0.9790822124644502, 0.9791273523683417, 0.9793879834756459, 0.9793494013074326, 0.978852148333641, 0.9779941802971983, 0.9790836686957373, 0.9791866838932037, 0.9791637499854989, 0.9786621434231327, 0.9786210088697198, 0.978669773225915, 0.97862464842731, 0.9785864332767382, 0.9784524755118644, 0.978956990046044, 0.9793956296084678, 0.9782493498227368, 0.978596620363732, 0.9788772798564336, 0.9788659949825235, 0.9794509704798868, 0.9789176795580615, 0.9793217386284919, 0.978722919340003, 0.9791888692607619, 0.978936983297949, 0.9793082692035256, 0.9789125805031763, 0.9786759692512147, 0.977958866586424, 0.9793344772841832, 0.9783327020194432, 0.9787120051579933, 0.9785656843283405, 0.9780225590483783, 0.978715282188703, 0.9790702086605437, 0.9792205364736792, 0.97849469397166, 0.9785394856374557, 0.9794640659469448, 0.9795448767812285, 0.9792842371006535, 0.9788958450702772, 0.9795226740510496, 0.979084406405279, 0.9790028635769674, 0.979366512739495, 0.9793086300974023, 0.9788619737102561, 0.9784976076589872, 0.9794662517227538, 0.9792671428151327, 0.9788132171108298, 0.9792431107122604, 0.9789934060344957, 0.978335976600647, 0.978916586670157, 0.9782682800129668, 0.979319545504165, 0.9788863662987539, 0.9789548054949878, 0.9796624522503108, 0.9790399866561367, 0.9792285504406446, 0.9789318748532909, 0.9783312568109329, 0.9787633361881727, 0.9793464908861134, 0.979317743484288, 0.9783774700066815, 0.9785074338521043, 0.9792573068239917, 0.9789970390600701, 0.9792121787593789, 0.978878722615438, 0.9790909494439216, 0.9790607392787933, 0.9781787399559805, 0.9789173100909142, 0.9785634940617705, 0.978864894746101, 0.9787957488674007, 0.9790902317386784, 0.978931140001506, 0.9788856490017617, 0.979080026688641, 0.9792325582406293, 0.9791553787989159, 0.9792824175259839, 0.9784164257245521, 0.9790185228602527, 0.9796169559433036, 0.9796107648170158, 0.9790851281930323, 0.9796031199089469, 0.9791477302165881, 0.9794870096526734, 0.9787225580378754, 0.9794917351579013, 0.9783378092393483, 0.9792521991958357, 0.9788645318109696, 0.9788237634586961, 0.9789712004465599, 0.9792336445965178, 0.9787833600828092, 0.9788343134808214, 0.9788073885114226, 0.9792809719092226, 0.9797261626753089, 0.9793996361836995, 0.979586372228518, 0.9789963070660421, 0.979301343225453, 0.9795896521169846, 0.9797538233129945, 0.9792638592524071, 0.97957035776687, 0.9794585982414141, 0.9783898694057988, 0.9793585212263343, 0.9791127782161921, 0.9791710384904522, 0.9797236139643682, 0.9791630281977457, 0.9794065478729875, 0.9792223687041296, 0.9795059378016485, 0.9789122204258017, 0.9798324500044732, 0.9795426893724154, 0.9795736425543484, 0.9790556418569121, 0.9796344323517525, 0.978960641034662, 0.9789012968540192, 0.979689749952865, 0.9793781548330228, 0.9798451907014194, 0.9793595912521833, 0.9798655767146855, 0.9794640573736739, 0.9796985044871291, 0.9790953209955399, 0.979193241628882, 0.9796573601356925, 0.9794378509260204, 0.9793836311118244, 0.9789464408404207, 0.979760370025896, 0.9797585582079953, 0.9791389960948735, 0.9794578817609239, 0.9793654084205627, 0.9797618372799599, 0.9798211659470649, 0.9795022774232577, 0.9794637066860722, 0.9796184060508257, 0.979143010426874, 0.9790818499375696, 0.9792245675439704, 0.9795164817000088, 0.9795714543290335, 0.9796082026337924, 0.9797607415342984, 0.9795477859777947, 0.9796551853826602, 0.978897654438672, 0.9796555417857759, 0.9799179851192318, 0.9794233020854323, 0.978897651989166, 0.9797570999354532, 0.9795550683589831, 0.9795397707860763, 0.979251844833975, 0.9791440853517349, 0.9793464990511332, 0.9793133609098931, 0.9793672308529893, 0.9798342675378878, 0.97944259357779, 0.9798309900989272, 0.9793472159398745, 0.980034497502732, 0.9796413358760206, 0.9799365552320872, 0.979713064758745, 0.9799059686595446, 0.9800592317973098, 0.9794779023895525, 0.9793894511379607], 'val_mDice': [0.006863864132343498, 0.03714353292670152, 0.14344791874085386, 0.22316508689155318, 0.3759679369730492, 0.4509526907581173, 0.5431341696275424, 0.5882786981863518, 0.6167396098783572, 0.6518877748757193, 0.6565497995239414, 0.6657573074510653, 0.6811130830686386, 0.6898677536886032, 0.6948287780970743, 0.6993257660571843, 0.7086565698662849, 0.711269055327324, 0.7156768420787707, 0.7156590402942814, 0.7161200389470139, 0.7186183006796119, 0.7275443101582462, 0.730737467334695, 0.7290859120349361, 0.7301083084655134, 0.7290772473158902, 0.7318087873393542, 0.7377379063057573, 0.739014495725501, 0.7390726800650766, 0.7407400893838438, 0.7427737320939155, 0.7450493027086127, 0.7430215902524452, 0.7458075868756804, 0.7502495221895714, 0.7445470090598276, 0.7511440691066115, 0.7486959495773055, 0.748243263323013, 0.7544074140182914, 0.7452654736499263, 0.7536154532269256, 0.7454676656690362, 0.7523377545892376, 0.7531449774356738, 0.7512659977560174, 0.7528146435953167, 0.7571744208466517, 0.7568603770373619, 0.7532826592660931, 0.7586161379944788, 0.7544771616589533, 0.7561106877784206, 0.7575768473213667, 0.7560671396451454, 0.7567013979774632, 0.7607653251249497, 0.7589833842564936, 0.7546531692759632, 0.7571479882279487, 0.7599138168439473, 0.7623345909053332, 0.7598052502494969, 0.7599477947574772, 0.761660588930731, 0.759402482068702, 0.760382838445167, 0.758139678060192, 0.7600093855433268, 0.7585742044938754, 0.7623485583965093, 0.7585967685261817, 0.7583092402105462, 0.7626659192451058, 0.7607372268422009, 0.7629524604098438, 0.7677019083336608, 0.760534307319824, 0.7655454510695314, 0.7622037121694382, 0.7668415512124153, 0.7641205440645349, 0.7635123031596615, 0.7667034717455302, 0.7655823732892127, 0.7652354460873015, 0.7645712996998878, 0.7670759166756721, 0.7646368778731725, 0.7612030257100928, 0.7649620877553339, 0.7660503905929931, 0.7685846469990195, 0.7651765260794391, 0.7649841688267173, 0.7667906268002236, 0.7684257802081434, 0.7680634680676134, 0.7689138005857599, 0.7644055502055442, 0.7672674345643553, 0.7694707900693972, 0.7693176943145387, 0.7663540003234393, 0.7663149609141153, 0.7655104982526335, 0.769115195698934, 0.7648141098349062, 0.7643122346433875, 0.7689882055537341, 0.7682516480961891, 0.764473169225536, 0.7687348204932801, 0.7670546908901162, 0.7671890997723357, 0.7683307977571879, 0.7655750990730442, 0.7702888078885536, 0.7671500330101954, 0.7682096076338258, 0.7700781928349848, 0.7642288089615025, 0.7700227237727544, 0.7682561511046266, 0.7693821485728434, 0.7710025261526239, 0.7647904819005156, 0.7708707958051603, 0.7656263533520372, 0.7693649081334676, 0.7692470619939777, 0.7685254759167972, 0.7715314479723369, 0.7677314481506609, 0.7701166435463788, 0.7675076347507842, 0.7729562014749606, 0.7726703567864144, 0.7717480218573792, 0.7721174147031079, 0.7707842441454326, 0.7737147142625835, 0.7724436162269279, 0.773871998672616, 0.7737312602670225, 0.7720605861650754, 0.7706903905084689, 0.775635691129998, 0.7722336176323564, 0.7718856220376001, 0.773982188473009, 0.7741684868727645, 0.7749787360838015, 0.7729401184271459, 0.7710823914776109, 0.7745642551820572, 0.7686303449820165, 0.7757948935031891, 0.7743161083900765, 0.7735241226954003, 0.773424404124691, 0.7741344183275144, 0.773253857272945, 0.7757376612049259, 0.7734303588736547, 0.7733629794969951, 0.773010399243603, 0.7707800122156535, 0.7702221286623445, 0.7727144180911861, 0.7732138576572889, 0.7751280469437168, 0.7753533386204341, 0.7724534052692048, 0.7752965525405048, 0.7754164648382631, 0.7760718272973414, 0.7714882493019104, 0.7752454778919481, 0.7729188322204433, 0.7763180495941475, 0.7776466746852823, 0.7751021577070837, 0.7743648629482478, 0.7738116371305022, 0.7725986426007257, 0.7741640557165015, 0.7744211987273334, 0.7762005733300562, 0.77693377904696, 0.7713456268179907, 0.7791629886790498, 0.7736504179974125, 0.7799149404649866, 0.7760294247163485, 0.7752650122936457, 0.7761971464712326, 0.7748519321010537, 0.7772586860068856, 0.7791946085348521, 0.7762636060584082, 0.7775777390558426, 0.7781093279792838, 0.777762966204996, 0.7799079491667551, 0.7777230306847455, 0.7783989326594627, 0.7800543863479406, 0.7768091551245075, 0.7796945139153363, 0.7784174852175255, 0.7777163933401239, 0.7765592459129961, 0.7768843516911546, 0.7777512028609237, 0.7787622384829064, 0.7800659214797085, 0.7784451217684027, 0.7792477195393549, 0.7769258312166554, 0.77546791834374, 0.7786365829101981, 0.7826317148665859, 0.7753256653269677, 0.7795136297402316, 0.7752314287505738, 0.7787337886960539, 0.7800035860440503, 0.7782970164736657, 0.7775662418914168, 0.7794032349978408, 0.7778524895236917, 0.7792083743500383, 0.7794443458726962, 0.7789600226160598, 0.7809816913245475, 0.7801172843534653, 0.7815659940242767, 0.7820488647238849, 0.7807101423609747, 0.7797337398953634, 0.7814524573822544, 0.7774367442686264, 0.7828659880651186, 0.7801539081416718, 0.779715849112158, 0.7793029522242612, 0.7792027400781031, 0.7801125474172096, 0.7797768079254725, 0.7800008327993628, 0.7822742870409195, 0.781267374345701, 0.7813644543902515, 0.7804794940229964, 0.7805030427566947, 0.7826203303794338, 0.7815007751118647, 0.7822456751784234, 0.7831151024119495, 0.7816630246704572, 0.7812895109392193, 0.7812129348924716, 0.7802959590742032, 0.7820668898216666, 0.7794125729227719, 0.780942922585631, 0.7793432992615111, 0.7817063282613885, 0.7819257603116232, 0.7811755836009979, 0.7822449309368656, 0.7805233393629937, 0.7809022501723407, 0.7802374905919376, 0.7833570560363874, 0.782537484413957, 0.7805436531158343, 0.7835859097030065, 0.7819853363788292, 0.7813723609872061, 0.7823949007138814, 0.7820460984151657, 0.7820436350286823, 0.7831944815100056, 0.7832375021829997, 0.784375009471423, 0.7839981472655518, 0.7856121687856439, 0.7824445583232461, 0.7842524337441954, 0.7845338313546899, 0.7822735476983737, 0.784135928300962, 0.7818084302013868, 0.7824373763718017, 0.7843561115330213, 0.7787305279953839], 'loss': [46.344898201929894, 5.7704307401236, 4.300353125845865, 3.449579241517205, 2.8463411313825944, 2.4521851127213976, 2.1559989955305876, 1.9472221003549002, 1.7931308297198838, 1.6649257910987592, 1.5704761757880064, 1.4997887111346724, 1.441918143137799, 1.391365970819621, 1.340812771321722, 1.298585893065161, 1.2628512710047042, 1.2339141789537045, 1.1995234902126024, 1.170669935299314, 1.144818320418675, 1.1263209881595924, 1.1048332497731044, 1.0858791395134912, 1.0662172105784726, 1.0516604330417443, 1.0386824223517084, 1.0178426270014038, 1.0035981596797408, 0.9914392126750426, 0.9812999925295574, 0.9692685164048348, 0.951981281448809, 0.9484611061735208, 0.9375151817373691, 0.9317016473356066, 0.9241624906888221, 0.9168437106364364, 0.9088203463734096, 0.9025461779349603, 0.8948445381733404, 0.888688527585179, 0.8848880912055221, 0.8771628263490885, 0.8737558368599738, 0.8682253919177368, 0.8653413984978238, 0.8595101197051211, 0.8541307712604962, 0.8492953217002569, 0.8499051161967529, 0.8429048038518907, 0.8406159221505515, 0.8357320261079723, 0.8325820067666101, 0.8269056867887281, 0.8229761574922042, 0.8225802815938905, 0.8204650137302554, 0.8163489484015393, 0.8149680503248117, 0.8089976151599454, 0.8094197423051677, 0.805073670411295, 0.8018316983547525, 0.8006655280417928, 0.7997576578984037, 0.7973235043923684, 0.7924063185509891, 0.7914314208602243, 0.789272079159423, 0.7881259795493221, 0.7860736900613684, 0.7830976911010877, 0.7847264968557205, 0.7817275263661735, 0.7791593331254542, 0.7779971301840026, 0.775439608013195, 0.7746735453588416, 0.7719024521648766, 0.7740314664786233, 0.7670701404721876, 0.7709473660939733, 0.7677439479944166, 0.7663082401432688, 0.7650850090806907, 0.7625063170673841, 0.7619353516029217, 0.7590834380985829, 0.7606708032793927, 0.7599835150718367, 0.7594370016336867, 0.755784229994613, 0.7540666625608197, 0.753915004465596, 0.7532138847573372, 0.7526758248529996, 0.7501912677501781, 0.7532477657980755, 0.7494627294758612, 0.7475610771571718, 0.7461888237389388, 0.746504462812658, 0.7455006377861536, 0.744680069087126, 0.7430970175975007, 0.7428651817666864, 0.7423541446086372, 0.7428487105420472, 0.7412817028006724, 0.7393734065002576, 0.7404335654438579, 0.7384717521311157, 0.7370947606190468, 0.736681053873039, 0.735931742467951, 0.733744158637777, 0.733535370641033, 0.7334881856505385, 0.73255061994398, 0.7301040497410584, 0.7299919151470997, 0.7303934121219225, 0.730246940317358, 0.7295952700633268, 0.7303143800930882, 0.7291064059494765, 0.7273635605230832, 0.7260161898608288, 0.7266970725296561, 0.7262787241003037, 0.7252354683965204, 0.7230280748453075, 0.7232009093958738, 0.7224561162506611, 0.7232763897186819, 0.7226118265238088, 0.7219494950013526, 0.7187063497726335, 0.7199167934844187, 0.7199428222775086, 0.7188954896622723, 0.7185095518136566, 0.7191543321410365, 0.718743144042452, 0.7173739407710485, 0.7158773639723907, 0.715576499624421, 0.7159549494704095, 0.7139708060024158, 0.7152040654222352, 0.7122392394587622, 0.7142086290492742, 0.7118294346107908, 0.7117963649992874, 0.7117364173312033, 0.7110815385682502, 0.710931745483086, 0.70946696763171, 0.7102788672317246, 0.7105358858497248, 0.7102484332175937, 0.7077894395857273, 0.7084531784273066, 0.7064291372894522, 0.7064723103981407, 0.7076258528283708, 0.7063730501647145, 0.7063572048218809, 0.7068705947748224, 0.7028732829923785, 0.7046704557069646, 0.7036867942245411, 0.7032861709537274, 0.7029046957145467, 0.7039079442760319, 0.7021701760614135, 0.7032635241504164, 0.7017510817897676, 0.7021044375862097, 0.7004950491513015, 0.701426023343677, 0.6997103044337966, 0.6988908687515876, 0.6989850340346163, 0.6995157311666936, 0.6991314167180425, 0.6987176665590897, 0.696951209392839, 0.694431425176521, 0.6964817811402421, 0.6962866471430682, 0.6949901674272262, 0.6952919291886337, 0.6957730852590652, 0.692761808389629, 0.6934818428328793, 0.692392933370981, 0.6922888785171201, 0.6926139477629438, 0.691365005131302, 0.6917077726533921, 0.6915831859958989, 0.6905983056187417, 0.6906096766159227, 0.6890241362079436, 0.6897710176371765, 0.6876464409824509, 0.6891535705351256, 0.6889341794928561, 0.6877273994659228, 0.6865608299951724, 0.6863086239516784, 0.6886570308273272, 0.6867744909122114, 0.6874467710729587, 0.6866217894742929, 0.6856735132146649, 0.6848310573361651, 0.68492277286657, 0.684147556032972, 0.6840741757390194, 0.6830297598359533, 0.684155439313874, 0.6836033256288103, 0.6829773348017459, 0.6830329040764809, 0.6831797660201467, 0.6824459684223168, 0.6813430255410459, 0.6813623935703806, 0.6799577841144441, 0.6825629391809953, 0.6807973534292506, 0.6796472372276317, 0.6800338583723011, 0.6789294156208229, 0.6801286596890858, 0.679475245876389, 0.6789265246591003, 0.6793822779288446, 0.6784016586000979, 0.6765174710441483, 0.6764763157145592, 0.6753390485596683, 0.6774587040177552, 0.6765209355709484, 0.6753737225225848, 0.6771949146981928, 0.6755955377910975, 0.6748814620858612, 0.675856964948051, 0.6762030241437588, 0.6764676377189447, 0.6750846501746645, 0.6752368540004096, 0.674941606181542, 0.6719866942351649, 0.6717832057445824, 0.6732183244422094, 0.6726662834596447, 0.6730253367293249, 0.6736560492631849, 0.6707683795963151, 0.6715727924591053, 0.6715889631598776, 0.6721680662612914, 0.672974095590902, 0.6730002152488297, 0.6709510418135113, 0.6699625625858089, 0.6693297617377657, 0.6704686488037862, 0.6697064823782917, 0.6686442886767856, 0.6695586250063207, 0.6687342036163395, 0.6688824976672378, 0.6692073062730873, 0.6700163459891589, 0.6674273883103118, 0.6684503048964309, 0.6666962191282257, 0.667902959106089, 0.6664287294515432, 0.6699536067760734, 0.6663361515511753, 0.6660024237173702, 0.6662699350437904, 0.6677519551782334, 0.6656915219546893, 0.6676638265797429, 0.6654680724117898, 0.6659571639118014, 0.6667071929253281, 0.6655885112277571, 0.6647863759136273, 0.6649464705394397, 0.6627559635207029], 'acc': [0.7477909546469176, 0.8961977806170134, 0.904203879930317, 0.912995182233774, 0.921579472808598, 0.9292126656342738, 0.9355771252434365, 0.9406736008034734, 0.9445481933888553, 0.9474775720299902, 0.9495149623877146, 0.9510364083963634, 0.9523064077138912, 0.9533686870477005, 0.9544335799284099, 0.9552814089463093, 0.9560379475345094, 0.9566290055627081, 0.9573503234419882, 0.9578747421702716, 0.9583814775715668, 0.9587054486400887, 0.959134669716177, 0.9594956213430909, 0.9598079155718506, 0.9600453541171862, 0.9603460837923835, 0.9607349841863232, 0.9609876594300316, 0.9611383112167828, 0.9614609640629023, 0.9617830912741335, 0.9622254686715477, 0.9622360588504674, 0.9625819182159229, 0.9627005216948836, 0.9628359701720897, 0.9630002866475471, 0.9631658646392676, 0.9633334284891846, 0.9634542366936555, 0.9635448296608204, 0.9636234819007164, 0.9637704029692944, 0.9638062537598365, 0.9639735216720747, 0.9639498161932918, 0.9641105976154836, 0.9642167003552674, 0.9642623644247648, 0.964272098955726, 0.9644070821754317, 0.964453003298398, 0.9645544660080484, 0.9645822499566977, 0.9647388247485517, 0.9647651044074194, 0.9647277182306437, 0.964792520780208, 0.9648920448149616, 0.9649306844042504, 0.9649973499400913, 0.9649695523377297, 0.9650257600290849, 0.9650895491388196, 0.9650684450412579, 0.9650793973351278, 0.9651656637703564, 0.9652928209826483, 0.9653421040098146, 0.9653855124274371, 0.965340186308146, 0.9654408387060228, 0.9654982547408627, 0.9654609095596958, 0.9655191039049721, 0.9655772588891784, 0.9656075152312539, 0.9657127267539091, 0.9657033830127048, 0.9657574078221913, 0.9656818773644339, 0.9658579979036405, 0.965827095976243, 0.9658030806676389, 0.9658936328690071, 0.965882714136324, 0.9659594621472867, 0.9660019871815009, 0.9660579093830104, 0.9660396606550199, 0.9660150828381735, 0.9660923441689677, 0.9661401501821779, 0.9661723402754255, 0.9662130778884593, 0.9662744778168622, 0.96620905119239, 0.9663075219235298, 0.9662956685650819, 0.9663295784371865, 0.9664056721902926, 0.9664088491618108, 0.9664966323167837, 0.9664069542115415, 0.9664862138563491, 0.9665428512302892, 0.9665270932605855, 0.9665213077693073, 0.9665781372403218, 0.9665842317915507, 0.9666180032851627, 0.9666465078068271, 0.9667145470646963, 0.9667046194053787, 0.9667550372102989, 0.9668081186898869, 0.9668109988820393, 0.9668022384384557, 0.9668225649638523, 0.9668505368959392, 0.9669117321450542, 0.9669160553217336, 0.966936527444596, 0.9669130437287591, 0.9669341488920744, 0.9669291307951572, 0.9669431120787789, 0.9669827438359134, 0.9669785844463286, 0.9670235754162485, 0.9669877040919939, 0.9670502829393126, 0.9671248599008581, 0.9671505467392656, 0.9671430663089475, 0.9671155773442569, 0.9671346948510957, 0.9671434682905544, 0.9671942773506012, 0.9671814259353722, 0.9672455937323832, 0.9672223175368865, 0.9672090074683828, 0.9672158288751156, 0.9672466382830279, 0.9672737599418872, 0.9672796606724506, 0.9672961856458346, 0.967288892839873, 0.9673138382354526, 0.9672965239551223, 0.9673619618949686, 0.9673697054831399, 0.9673879671610431, 0.9674178818644279, 0.9674140507585773, 0.9674090688886674, 0.9674286405530813, 0.9674379955349707, 0.967433321822999, 0.9674084352507029, 0.9674378503770207, 0.9674528723188444, 0.9674390079205373, 0.9675319146245892, 0.967561454964038, 0.9674954850005267, 0.96752106634081, 0.9675327333503588, 0.9675220805102931, 0.9675709315222817, 0.9675923021817886, 0.9676015651325437, 0.9676217475485082, 0.9676103235164363, 0.967592312621004, 0.9675733901126177, 0.9675763706551028, 0.9675833592788761, 0.967598400364049, 0.9676354283010812, 0.9675828487684976, 0.9676602320778174, 0.9676947151386822, 0.9676784580429179, 0.9676814999481105, 0.967649207278225, 0.9676545345499991, 0.9676752089678485, 0.9677550627746446, 0.9677485283285551, 0.9677243497642967, 0.9677791622806626, 0.9677332719266659, 0.9677710386665593, 0.9677801139326324, 0.9678033532289213, 0.9678187316811523, 0.967835094562306, 0.9678229491385134, 0.9678516284322916, 0.9678044384994003, 0.9677943699307842, 0.9678719249470986, 0.9678300420854964, 0.9678891979416823, 0.9678936256713836, 0.9678818238712839, 0.9678683399269337, 0.9678445993529681, 0.9679189831545579, 0.9679755074695551, 0.9678864231241302, 0.9679270543140459, 0.967978600140244, 0.9679396277284317, 0.9678969342563002, 0.9679705798238138, 0.9679470665311577, 0.9679717982991402, 0.9680419881301671, 0.968020301895536, 0.968006304263655, 0.9680167359670125, 0.9680300933538307, 0.9680225553153606, 0.9680675972116454, 0.9680693388427618, 0.9680429256027294, 0.9680892631395035, 0.9680791113731563, 0.9681125202232501, 0.9681118659194311, 0.96807939635167, 0.9681611477372112, 0.9681536155733133, 0.968140420686642, 0.9681337929856686, 0.9681757979694289, 0.9681859438497133, 0.9681684909093707, 0.9681942808041487, 0.9682008573805443, 0.9682127543946761, 0.968254022505997, 0.9682597099278276, 0.9683015512853618, 0.9682894395232988, 0.9682605994357287, 0.9682880386633324, 0.9682887576132994, 0.9682958772385963, 0.9682755792415012, 0.9683027510482367, 0.9683163875160151, 0.9683620203425554, 0.9683559551153523, 0.968378689850524, 0.9684237415224416, 0.9684176775505873, 0.9683989037450029, 0.968393557335625, 0.9684066823910125, 0.9684440095836361, 0.9684184035586589, 0.9684558207485795, 0.9684229829959556, 0.9684016621482247, 0.9684365554984044, 0.9684643234866023, 0.9685115746127145, 0.9684953563753063, 0.9684770481403411, 0.9684825509540994, 0.9685103587515009, 0.9685167371695275, 0.968544743093699, 0.9685587750451468, 0.9685471794755667, 0.9685920755503189, 0.9685977614668801, 0.9685599463745177, 0.9686022876021293, 0.9686195242030918, 0.9685861118569812, 0.9685431121199888, 0.9686225568583468, 0.9685900875548695, 0.968643682931692, 0.9686294404177661, 0.9686212440365292, 0.9685936552443282, 0.9686303523955468, 0.9686712118722001, 0.9686431265594333, 0.9686854454291988, 0.9686256900219304, 0.9686864562692789, 0.9687157080853621], 'mDice': [0.01499170344237638, 0.03795083260016531, 0.09162830293452896, 0.16760187299445517, 0.2519010407556148, 0.3202874784102135, 0.3785920288311245, 0.4241804027420635, 0.4601082390325892, 0.4919779522975466, 0.5161919249207768, 0.5347349013619908, 0.5493218960018122, 0.562904872809946, 0.5761439816234393, 0.5869267486228651, 0.5962509643176049, 0.6040883094490312, 0.6128989230570112, 0.6207285249334937, 0.628093570713549, 0.6335506780077804, 0.6389496761940492, 0.6447647921814621, 0.650274666388458, 0.6541953841699647, 0.6579770905677712, 0.6643387833740793, 0.6680725453054941, 0.671949878836995, 0.6751636952065555, 0.6785851366991388, 0.6834379907136734, 0.6850632812047363, 0.6884622059935196, 0.6902321015009162, 0.6925718873671736, 0.6946071965233999, 0.6971200021601704, 0.6990803105353481, 0.7014476317107818, 0.7031066113652663, 0.704484127827096, 0.7068345490964247, 0.7080628605910201, 0.709501291437088, 0.7106949673818619, 0.7121370155568054, 0.713821471662451, 0.7151460389504002, 0.7151257169178304, 0.7168893625353714, 0.7180909041560031, 0.7196539924962762, 0.7203317708529945, 0.7220489324859909, 0.723104843042392, 0.7232858115687153, 0.7238937277863747, 0.7251671806830281, 0.7255926145014174, 0.7273975708288275, 0.7273778611248939, 0.7285606248320496, 0.7295628018888015, 0.72989831459, 0.7301204930736884, 0.7306411288273962, 0.732246615210581, 0.7328929120221479, 0.7333899811438075, 0.7337821883071479, 0.7344018076981652, 0.7350519112152814, 0.7346284841421374, 0.7356352243855968, 0.7363415510115885, 0.7367413277867111, 0.7376207734965217, 0.7375400071603958, 0.7383425949515995, 0.738154435273831, 0.7402240292607367, 0.7389082688068194, 0.7399824595381262, 0.7404835375655249, 0.7406226202599243, 0.7413538833360591, 0.741515533637642, 0.742701454411714, 0.7421122673126731, 0.7423908018716543, 0.7423358696260488, 0.7435298726624067, 0.7437228244312402, 0.7442903986344412, 0.7444911204830377, 0.7446896436702912, 0.7452405399859995, 0.7445674913119934, 0.7457159522114171, 0.7459088931417366, 0.7466474405926011, 0.7466185536693221, 0.746825125793232, 0.7470072457242158, 0.7476205125223431, 0.7478697011657977, 0.7478168031796931, 0.7478574508241564, 0.7481906517964512, 0.7487995448592335, 0.7484676135126967, 0.7489790671779147, 0.7493935372549181, 0.7496838906143504, 0.7499515963690018, 0.7505712092505908, 0.7507460025386515, 0.7504816533192146, 0.7510152371672356, 0.7517665411611426, 0.7517043077530324, 0.7516928989345225, 0.7516255916138777, 0.7521793099074566, 0.7515074964764434, 0.7521519094549022, 0.7526299666281728, 0.7531315553699082, 0.7527745674676715, 0.7528216118002243, 0.7532341690044861, 0.7540207066026456, 0.7537078748031308, 0.7541553230795598, 0.7540856484039886, 0.7539961119951515, 0.7544088003934047, 0.7551688911472552, 0.7549398877866711, 0.7551545640595982, 0.7549904527603973, 0.7558687389330713, 0.7553644572816944, 0.7556664875498323, 0.7557262933721335, 0.7562710518342649, 0.7565550155953112, 0.7563163955830179, 0.7570695068452541, 0.7567176769552958, 0.7573331065813118, 0.7568966599221781, 0.7575643985258469, 0.7577142530340443, 0.75775993262735, 0.7581856380233339, 0.7582251182136331, 0.7586919102612918, 0.7581401217919705, 0.7580603920750988, 0.7581881593609955, 0.759091896481431, 0.7587096633793469, 0.7596458085870575, 0.7596731209124109, 0.7591051594987767, 0.7594876138093851, 0.7596281195952005, 0.7596888646825986, 0.7605403208423508, 0.759853652548667, 0.7605101649109338, 0.7604931087756801, 0.7608791816705129, 0.7603450847468357, 0.760974405926333, 0.7608072875212392, 0.7612691164315479, 0.7608910074457615, 0.761893840219677, 0.7614653434711592, 0.7616594061919756, 0.7622856354246922, 0.7620906992311149, 0.7619773012579789, 0.7621692705340567, 0.7619330423804064, 0.763010467619567, 0.7637547734208989, 0.7631741575381458, 0.7631284301295569, 0.7636095145345165, 0.7634601658514031, 0.7630752420544917, 0.764182657573624, 0.7639575678559118, 0.7642493890483062, 0.7645252883747414, 0.764327632880474, 0.7646815603259352, 0.7647547151526576, 0.7647797301899262, 0.7650503452855241, 0.7651267765665567, 0.7656957388004628, 0.7655019546119304, 0.766047040590798, 0.765450841955716, 0.7658731394707137, 0.766094452774986, 0.766487134448637, 0.7664861220716884, 0.7660243503156527, 0.7665040771486306, 0.7663603707206491, 0.766739998913896, 0.7666102039468703, 0.7671058442547922, 0.7669706424176937, 0.7671611351509302, 0.767460694375788, 0.7677947684272903, 0.7674096204199339, 0.7677645846196638, 0.7677336820574104, 0.7678050286879372, 0.7679226832640557, 0.7679844453447531, 0.7684779751788589, 0.7683607028750857, 0.7687600599213608, 0.7679842896642809, 0.7684314226298695, 0.7691107798762549, 0.7690595602367555, 0.7690979574748054, 0.7688712732459477, 0.7691265215350436, 0.7691952953298865, 0.769129183770513, 0.7693302257330229, 0.7700011600522606, 0.769883548086181, 0.770242592307009, 0.7700143348476077, 0.7699607101841038, 0.7705165604188233, 0.7698201205369748, 0.7701410569020413, 0.7704548489858435, 0.7700615963296285, 0.770209992883912, 0.7699281287610408, 0.7706036680698096, 0.770628828727525, 0.7705955168638892, 0.7714771004784646, 0.7714083450800816, 0.7715626751016643, 0.7714270020721676, 0.7712123523253039, 0.7711586261135716, 0.7721198988372179, 0.7719091823591807, 0.7716118478448691, 0.7714649643161002, 0.7713728989111129, 0.7713997859375478, 0.7719374124449623, 0.7722435615236107, 0.7725164260000854, 0.7719641798197192, 0.7723197090728604, 0.7728672086362339, 0.7723910323056412, 0.7728434097014816, 0.772484549899131, 0.772345856595507, 0.772335909580264, 0.7728886035811362, 0.772741980420876, 0.7734338364271814, 0.7729671826890718, 0.7734663618507773, 0.7722282097583116, 0.7731577050134908, 0.7735952963811344, 0.7733803710723085, 0.7731981169511579, 0.7735511032528082, 0.7730210770686923, 0.7736398235758424, 0.773517381415849, 0.773288262953867, 0.7737266704101862, 0.7739003572735628, 0.7742546841497162, 0.774622774151723]}
predicting test subjects:   0%|          | 0/15 [00:00<?, ?it/s]predicting test subjects:   7%|▋         | 1/15 [00:02<00:29,  2.10s/it]predicting test subjects:  13%|█▎        | 2/15 [00:03<00:25,  1.99s/it]predicting test subjects:  20%|██        | 3/15 [00:05<00:24,  2.00s/it]predicting test subjects:  27%|██▋       | 4/15 [00:07<00:22,  2.00s/it]predicting test subjects:  33%|███▎      | 5/15 [00:10<00:20,  2.09s/it]predicting test subjects:  40%|████      | 6/15 [00:12<00:19,  2.18s/it]predicting test subjects:  47%|████▋     | 7/15 [00:14<00:15,  1.98s/it]predicting test subjects:  53%|█████▎    | 8/15 [00:16<00:14,  2.11s/it]predicting test subjects:  60%|██████    | 9/15 [00:18<00:12,  2.06s/it]predicting test subjects:  67%|██████▋   | 10/15 [00:20<00:09,  1.94s/it]predicting test subjects:  73%|███████▎  | 11/15 [00:21<00:07,  1.89s/it]predicting test subjects:  80%|████████  | 12/15 [00:24<00:05,  2.00s/it]predicting test subjects:  87%|████████▋ | 13/15 [00:26<00:04,  2.05s/it]predicting test subjects:  93%|█████████▎| 14/15 [00:28<00:02,  2.00s/it]predicting test subjects: 100%|██████████| 15/15 [00:30<00:00,  2.01s/it]
predicting train subjects:   0%|          | 0/532 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/532 [00:02<21:16,  2.40s/it]predicting train subjects:   0%|          | 2/532 [00:04<19:17,  2.18s/it]predicting train subjects:   1%|          | 3/532 [00:05<18:16,  2.07s/it]predicting train subjects:   1%|          | 4/532 [00:07<17:21,  1.97s/it]predicting train subjects:   1%|          | 5/532 [00:09<17:13,  1.96s/it]predicting train subjects:   1%|          | 6/532 [00:11<16:30,  1.88s/it]predicting train subjects:   1%|▏         | 7/532 [00:12<16:01,  1.83s/it]predicting train subjects:   2%|▏         | 8/532 [00:14<15:32,  1.78s/it]predicting train subjects:   2%|▏         | 9/532 [00:16<16:30,  1.89s/it]predicting train subjects:   2%|▏         | 10/532 [00:18<16:14,  1.87s/it]predicting train subjects:   2%|▏         | 11/532 [00:20<15:27,  1.78s/it]predicting train subjects:   2%|▏         | 12/532 [00:22<16:48,  1.94s/it]predicting train subjects:   2%|▏         | 13/532 [00:24<15:55,  1.84s/it]predicting train subjects:   3%|▎         | 14/532 [00:25<14:51,  1.72s/it]predicting train subjects:   3%|▎         | 15/532 [00:27<14:48,  1.72s/it]predicting train subjects:   3%|▎         | 16/532 [00:29<15:31,  1.80s/it]predicting train subjects:   3%|▎         | 17/532 [00:30<15:02,  1.75s/it]predicting train subjects:   3%|▎         | 18/532 [00:32<15:41,  1.83s/it]predicting train subjects:   4%|▎         | 19/532 [00:34<14:49,  1.73s/it]predicting train subjects:   4%|▍         | 20/532 [00:36<15:12,  1.78s/it]predicting train subjects:   4%|▍         | 21/532 [00:38<16:25,  1.93s/it]predicting train subjects:   4%|▍         | 22/532 [00:40<15:25,  1.82s/it]predicting train subjects:   4%|▍         | 23/532 [00:42<15:39,  1.85s/it]predicting train subjects:   5%|▍         | 24/532 [00:43<15:02,  1.78s/it]predicting train subjects:   5%|▍         | 25/532 [00:45<16:13,  1.92s/it]predicting train subjects:   5%|▍         | 26/532 [00:47<15:59,  1.90s/it]predicting train subjects:   5%|▌         | 27/532 [00:50<17:07,  2.03s/it]predicting train subjects:   5%|▌         | 28/532 [00:51<16:34,  1.97s/it]predicting train subjects:   5%|▌         | 29/532 [00:54<17:00,  2.03s/it]predicting train subjects:   6%|▌         | 30/532 [00:55<15:51,  1.90s/it]predicting train subjects:   6%|▌         | 31/532 [00:57<15:40,  1.88s/it]predicting train subjects:   6%|▌         | 32/532 [00:59<15:37,  1.87s/it]predicting train subjects:   6%|▌         | 33/532 [01:01<14:57,  1.80s/it]predicting train subjects:   6%|▋         | 34/532 [01:03<16:00,  1.93s/it]predicting train subjects:   7%|▋         | 35/532 [01:05<15:47,  1.91s/it]predicting train subjects:   7%|▋         | 36/532 [01:07<15:57,  1.93s/it]predicting train subjects:   7%|▋         | 37/532 [01:08<15:41,  1.90s/it]predicting train subjects:   7%|▋         | 38/532 [01:10<16:04,  1.95s/it]predicting train subjects:   7%|▋         | 39/532 [01:12<15:26,  1.88s/it]predicting train subjects:   8%|▊         | 40/532 [01:14<15:09,  1.85s/it]predicting train subjects:   8%|▊         | 41/532 [01:16<15:42,  1.92s/it]predicting train subjects:   8%|▊         | 42/532 [01:18<15:30,  1.90s/it]predicting train subjects:   8%|▊         | 43/532 [01:19<14:38,  1.80s/it]predicting train subjects:   8%|▊         | 44/532 [01:21<13:48,  1.70s/it]predicting train subjects:   8%|▊         | 45/532 [01:23<13:35,  1.68s/it]predicting train subjects:   9%|▊         | 46/532 [01:24<13:59,  1.73s/it]predicting train subjects:   9%|▉         | 47/532 [01:27<15:18,  1.89s/it]predicting train subjects:   9%|▉         | 48/532 [01:29<15:31,  1.92s/it]predicting train subjects:   9%|▉         | 49/532 [01:30<14:56,  1.86s/it]predicting train subjects:   9%|▉         | 50/532 [01:33<15:53,  1.98s/it]predicting train subjects:  10%|▉         | 51/532 [01:34<15:31,  1.94s/it]predicting train subjects:  10%|▉         | 52/532 [01:36<15:23,  1.92s/it]predicting train subjects:  10%|▉         | 53/532 [01:38<14:55,  1.87s/it]predicting train subjects:  10%|█         | 54/532 [01:40<15:29,  1.94s/it]predicting train subjects:  10%|█         | 55/532 [01:42<15:28,  1.95s/it]predicting train subjects:  11%|█         | 56/532 [01:44<15:23,  1.94s/it]predicting train subjects:  11%|█         | 57/532 [01:46<15:05,  1.91s/it]predicting train subjects:  11%|█         | 58/532 [01:48<15:44,  1.99s/it]predicting train subjects:  11%|█         | 59/532 [01:50<16:24,  2.08s/it]predicting train subjects:  11%|█▏        | 60/532 [01:52<15:07,  1.92s/it]predicting train subjects:  11%|█▏        | 61/532 [01:54<14:27,  1.84s/it]predicting train subjects:  12%|█▏        | 62/532 [01:56<15:09,  1.93s/it]predicting train subjects:  12%|█▏        | 63/532 [01:58<15:49,  2.02s/it]predicting train subjects:  12%|█▏        | 64/532 [02:00<15:01,  1.93s/it]predicting train subjects:  12%|█▏        | 65/532 [02:02<14:48,  1.90s/it]predicting train subjects:  12%|█▏        | 66/532 [02:04<15:52,  2.04s/it]predicting train subjects:  13%|█▎        | 67/532 [02:06<16:16,  2.10s/it]predicting train subjects:  13%|█▎        | 68/532 [02:08<15:35,  2.02s/it]predicting train subjects:  13%|█▎        | 69/532 [02:10<15:12,  1.97s/it]predicting train subjects:  13%|█▎        | 70/532 [02:12<14:42,  1.91s/it]predicting train subjects:  13%|█▎        | 71/532 [02:13<14:14,  1.85s/it]predicting train subjects:  14%|█▎        | 72/532 [02:15<13:41,  1.78s/it]predicting train subjects:  14%|█▎        | 73/532 [02:17<14:00,  1.83s/it]predicting train subjects:  14%|█▍        | 74/532 [02:19<15:23,  2.02s/it]predicting train subjects:  14%|█▍        | 75/532 [02:22<17:36,  2.31s/it]predicting train subjects:  14%|█▍        | 76/532 [02:24<16:15,  2.14s/it]predicting train subjects:  14%|█▍        | 77/532 [02:26<15:39,  2.06s/it]predicting train subjects:  15%|█▍        | 78/532 [02:28<15:26,  2.04s/it]predicting train subjects:  15%|█▍        | 79/532 [02:30<15:14,  2.02s/it]predicting train subjects:  15%|█▌        | 80/532 [02:32<14:58,  1.99s/it]predicting train subjects:  15%|█▌        | 81/532 [02:34<14:42,  1.96s/it]predicting train subjects:  15%|█▌        | 82/532 [02:36<14:34,  1.94s/it]predicting train subjects:  16%|█▌        | 83/532 [02:37<13:51,  1.85s/it]predicting train subjects:  16%|█▌        | 84/532 [02:39<13:27,  1.80s/it]predicting train subjects:  16%|█▌        | 85/532 [02:41<13:19,  1.79s/it]predicting train subjects:  16%|█▌        | 86/532 [02:42<13:03,  1.76s/it]predicting train subjects:  16%|█▋        | 87/532 [02:44<12:42,  1.71s/it]predicting train subjects:  17%|█▋        | 88/532 [02:46<12:44,  1.72s/it]predicting train subjects:  17%|█▋        | 89/532 [02:48<13:04,  1.77s/it]predicting train subjects:  17%|█▋        | 90/532 [02:49<13:11,  1.79s/it]predicting train subjects:  17%|█▋        | 91/532 [02:51<13:18,  1.81s/it]predicting train subjects:  17%|█▋        | 92/532 [02:53<13:24,  1.83s/it]predicting train subjects:  17%|█▋        | 93/532 [02:55<13:22,  1.83s/it]predicting train subjects:  18%|█▊        | 94/532 [02:57<13:09,  1.80s/it]predicting train subjects:  18%|█▊        | 95/532 [02:59<13:52,  1.90s/it]predicting train subjects:  18%|█▊        | 96/532 [03:01<14:18,  1.97s/it]predicting train subjects:  18%|█▊        | 97/532 [03:03<14:42,  2.03s/it]predicting train subjects:  18%|█▊        | 98/532 [03:05<15:00,  2.07s/it]predicting train subjects:  19%|█▊        | 99/532 [03:07<15:02,  2.08s/it]predicting train subjects:  19%|█▉        | 100/532 [03:10<15:02,  2.09s/it]predicting train subjects:  19%|█▉        | 101/532 [03:11<13:51,  1.93s/it]predicting train subjects:  19%|█▉        | 102/532 [03:13<13:05,  1.83s/it]predicting train subjects:  19%|█▉        | 103/532 [03:14<12:30,  1.75s/it]predicting train subjects:  20%|█▉        | 104/532 [03:16<12:30,  1.75s/it]predicting train subjects:  20%|█▉        | 105/532 [03:18<12:31,  1.76s/it]predicting train subjects:  20%|█▉        | 106/532 [03:20<12:17,  1.73s/it]predicting train subjects:  20%|██        | 107/532 [03:21<11:56,  1.69s/it]predicting train subjects:  20%|██        | 108/532 [03:23<11:40,  1.65s/it]predicting train subjects:  20%|██        | 109/532 [03:24<11:27,  1.63s/it]predicting train subjects:  21%|██        | 110/532 [03:26<11:10,  1.59s/it]predicting train subjects:  21%|██        | 111/532 [03:27<11:05,  1.58s/it]predicting train subjects:  21%|██        | 112/532 [03:29<11:05,  1.58s/it]predicting train subjects:  21%|██        | 113/532 [03:31<11:44,  1.68s/it]predicting train subjects:  21%|██▏       | 114/532 [03:33<12:15,  1.76s/it]predicting train subjects:  22%|██▏       | 115/532 [03:35<12:30,  1.80s/it]predicting train subjects:  22%|██▏       | 116/532 [03:37<12:37,  1.82s/it]predicting train subjects:  22%|██▏       | 117/532 [03:38<12:56,  1.87s/it]predicting train subjects:  22%|██▏       | 118/532 [03:40<12:58,  1.88s/it]predicting train subjects:  22%|██▏       | 119/532 [03:42<13:07,  1.91s/it]predicting train subjects:  23%|██▎       | 120/532 [03:44<12:55,  1.88s/it]predicting train subjects:  23%|██▎       | 121/532 [03:46<12:41,  1.85s/it]predicting train subjects:  23%|██▎       | 122/532 [03:48<12:35,  1.84s/it]predicting train subjects:  23%|██▎       | 123/532 [03:50<12:38,  1.85s/it]predicting train subjects:  23%|██▎       | 124/532 [03:52<12:39,  1.86s/it]predicting train subjects:  23%|██▎       | 125/532 [03:53<12:48,  1.89s/it]predicting train subjects:  24%|██▎       | 126/532 [03:55<12:54,  1.91s/it]predicting train subjects:  24%|██▍       | 127/532 [03:57<12:46,  1.89s/it]predicting train subjects:  24%|██▍       | 128/532 [03:59<12:49,  1.90s/it]predicting train subjects:  24%|██▍       | 129/532 [04:01<12:49,  1.91s/it]predicting train subjects:  24%|██▍       | 130/532 [04:03<12:58,  1.94s/it]predicting train subjects:  25%|██▍       | 131/532 [04:05<13:37,  2.04s/it]predicting train subjects:  25%|██▍       | 132/532 [04:08<14:06,  2.12s/it]predicting train subjects:  25%|██▌       | 133/532 [04:10<14:26,  2.17s/it]predicting train subjects:  25%|██▌       | 134/532 [04:12<14:33,  2.19s/it]predicting train subjects:  25%|██▌       | 135/532 [04:15<14:47,  2.24s/it]predicting train subjects:  26%|██▌       | 136/532 [04:17<14:58,  2.27s/it]predicting train subjects:  26%|██▌       | 137/532 [04:19<15:07,  2.30s/it]predicting train subjects:  26%|██▌       | 138/532 [04:22<15:19,  2.33s/it]predicting train subjects:  26%|██▌       | 139/532 [04:24<15:13,  2.33s/it]predicting train subjects:  26%|██▋       | 140/532 [04:26<15:10,  2.32s/it]predicting train subjects:  27%|██▋       | 141/532 [04:29<15:14,  2.34s/it]predicting train subjects:  27%|██▋       | 142/532 [04:31<15:19,  2.36s/it]predicting train subjects:  27%|██▋       | 143/532 [04:33<14:13,  2.20s/it]predicting train subjects:  27%|██▋       | 144/532 [04:35<13:14,  2.05s/it]predicting train subjects:  27%|██▋       | 145/532 [04:36<12:32,  1.94s/it]predicting train subjects:  27%|██▋       | 146/532 [04:38<11:58,  1.86s/it]predicting train subjects:  28%|██▊       | 147/532 [04:40<11:32,  1.80s/it]predicting train subjects:  28%|██▊       | 148/532 [04:41<11:16,  1.76s/it]predicting train subjects:  28%|██▊       | 149/532 [04:43<11:30,  1.80s/it]predicting train subjects:  28%|██▊       | 150/532 [04:45<11:27,  1.80s/it]predicting train subjects:  28%|██▊       | 151/532 [04:47<11:37,  1.83s/it]predicting train subjects:  29%|██▊       | 152/532 [04:49<11:35,  1.83s/it]predicting train subjects:  29%|██▉       | 153/532 [04:51<11:29,  1.82s/it]predicting train subjects:  29%|██▉       | 154/532 [04:52<11:28,  1.82s/it]predicting train subjects:  29%|██▉       | 155/532 [04:55<12:21,  1.97s/it]predicting train subjects:  29%|██▉       | 156/532 [04:57<13:03,  2.08s/it]predicting train subjects:  30%|██▉       | 157/532 [04:59<13:34,  2.17s/it]predicting train subjects:  30%|██▉       | 158/532 [05:02<14:10,  2.28s/it]predicting train subjects:  30%|██▉       | 159/532 [05:04<14:19,  2.31s/it]predicting train subjects:  30%|███       | 160/532 [05:07<14:37,  2.36s/it]predicting train subjects:  30%|███       | 161/532 [05:09<13:30,  2.18s/it]predicting train subjects:  30%|███       | 162/532 [05:10<12:50,  2.08s/it]predicting train subjects:  31%|███       | 163/532 [05:12<12:18,  2.00s/it]predicting train subjects:  31%|███       | 164/532 [05:14<11:47,  1.92s/it]predicting train subjects:  31%|███       | 165/532 [05:16<11:34,  1.89s/it]predicting train subjects:  31%|███       | 166/532 [05:18<11:17,  1.85s/it]predicting train subjects:  31%|███▏      | 167/532 [05:19<11:16,  1.85s/it]predicting train subjects:  32%|███▏      | 168/532 [05:21<11:10,  1.84s/it]predicting train subjects:  32%|███▏      | 169/532 [05:23<11:08,  1.84s/it]predicting train subjects:  32%|███▏      | 170/532 [05:25<11:23,  1.89s/it]predicting train subjects:  32%|███▏      | 171/532 [05:27<11:29,  1.91s/it]predicting train subjects:  32%|███▏      | 172/532 [05:29<11:22,  1.90s/it]predicting train subjects:  33%|███▎      | 173/532 [05:31<10:51,  1.82s/it]predicting train subjects:  33%|███▎      | 174/532 [05:33<11:16,  1.89s/it]predicting train subjects:  33%|███▎      | 175/532 [05:35<11:27,  1.93s/it]predicting train subjects:  33%|███▎      | 176/532 [05:37<11:23,  1.92s/it]predicting train subjects:  33%|███▎      | 177/532 [05:39<11:33,  1.95s/it]predicting train subjects:  33%|███▎      | 178/532 [05:40<11:30,  1.95s/it]predicting train subjects:  34%|███▎      | 179/532 [05:43<11:40,  1.99s/it]predicting train subjects:  34%|███▍      | 180/532 [05:45<11:56,  2.04s/it]predicting train subjects:  34%|███▍      | 181/532 [05:47<11:50,  2.02s/it]predicting train subjects:  34%|███▍      | 182/532 [05:49<12:06,  2.07s/it]predicting train subjects:  34%|███▍      | 183/532 [05:51<11:54,  2.05s/it]predicting train subjects:  35%|███▍      | 184/532 [05:53<11:47,  2.03s/it]predicting train subjects:  35%|███▍      | 185/532 [05:55<11:38,  2.01s/it]predicting train subjects:  35%|███▍      | 186/532 [05:57<11:17,  1.96s/it]predicting train subjects:  35%|███▌      | 187/532 [05:59<11:13,  1.95s/it]predicting train subjects:  35%|███▌      | 188/532 [06:01<11:20,  1.98s/it]predicting train subjects:  36%|███▌      | 189/532 [06:03<11:10,  1.95s/it]predicting train subjects:  36%|███▌      | 190/532 [06:04<10:58,  1.92s/it]predicting train subjects:  36%|███▌      | 191/532 [06:07<12:22,  2.18s/it]predicting train subjects:  36%|███▌      | 192/532 [06:10<13:16,  2.34s/it]predicting train subjects:  36%|███▋      | 193/532 [06:12<13:32,  2.40s/it]predicting train subjects:  36%|███▋      | 194/532 [06:15<14:13,  2.53s/it]predicting train subjects:  37%|███▋      | 195/532 [06:18<14:46,  2.63s/it]predicting train subjects:  37%|███▋      | 196/532 [06:21<15:06,  2.70s/it]predicting train subjects:  37%|███▋      | 197/532 [06:23<14:28,  2.59s/it]predicting train subjects:  37%|███▋      | 198/532 [06:26<14:01,  2.52s/it]predicting train subjects:  37%|███▋      | 199/532 [06:28<13:54,  2.51s/it]predicting train subjects:  38%|███▊      | 200/532 [06:30<13:33,  2.45s/it]predicting train subjects:  38%|███▊      | 201/532 [06:33<13:47,  2.50s/it]predicting train subjects:  38%|███▊      | 202/532 [06:35<13:35,  2.47s/it]predicting train subjects:  38%|███▊      | 203/532 [06:37<12:41,  2.32s/it]predicting train subjects:  38%|███▊      | 204/532 [06:40<12:16,  2.24s/it]predicting train subjects:  39%|███▊      | 205/532 [06:42<11:49,  2.17s/it]predicting train subjects:  39%|███▊      | 206/532 [06:43<11:27,  2.11s/it]predicting train subjects:  39%|███▉      | 207/532 [06:46<11:19,  2.09s/it]predicting train subjects:  39%|███▉      | 208/532 [06:48<11:15,  2.08s/it]predicting train subjects:  39%|███▉      | 209/532 [06:49<10:54,  2.03s/it]predicting train subjects:  39%|███▉      | 210/532 [06:51<10:42,  1.99s/it]predicting train subjects:  40%|███▉      | 211/532 [06:53<10:16,  1.92s/it]predicting train subjects:  40%|███▉      | 212/532 [06:55<10:01,  1.88s/it]predicting train subjects:  40%|████      | 213/532 [06:57<09:43,  1.83s/it]predicting train subjects:  40%|████      | 214/532 [06:58<09:37,  1.82s/it]predicting train subjects:  40%|████      | 215/532 [07:01<10:53,  2.06s/it]predicting train subjects:  41%|████      | 216/532 [07:04<11:37,  2.21s/it]predicting train subjects:  41%|████      | 217/532 [07:06<12:13,  2.33s/it]predicting train subjects:  41%|████      | 218/532 [07:09<12:38,  2.41s/it]predicting train subjects:  41%|████      | 219/532 [07:11<12:52,  2.47s/it]predicting train subjects:  41%|████▏     | 220/532 [07:14<12:55,  2.49s/it]predicting train subjects:  42%|████▏     | 221/532 [07:16<11:44,  2.26s/it]predicting train subjects:  42%|████▏     | 222/532 [07:17<10:53,  2.11s/it]predicting train subjects:  42%|████▏     | 223/532 [07:19<10:14,  1.99s/it]predicting train subjects:  42%|████▏     | 224/532 [07:21<09:55,  1.93s/it]predicting train subjects:  42%|████▏     | 225/532 [07:23<09:23,  1.84s/it]predicting train subjects:  42%|████▏     | 226/532 [07:24<09:11,  1.80s/it]predicting train subjects:  43%|████▎     | 227/532 [07:26<09:01,  1.78s/it]predicting train subjects:  43%|████▎     | 228/532 [07:28<08:56,  1.76s/it]predicting train subjects:  43%|████▎     | 229/532 [07:29<08:43,  1.73s/it]predicting train subjects:  43%|████▎     | 230/532 [07:31<08:40,  1.72s/it]predicting train subjects:  43%|████▎     | 231/532 [07:33<08:35,  1.71s/it]predicting train subjects:  44%|████▎     | 232/532 [07:35<08:44,  1.75s/it]predicting train subjects:  44%|████▍     | 233/532 [07:37<09:02,  1.81s/it]predicting train subjects:  44%|████▍     | 234/532 [07:39<09:29,  1.91s/it]predicting train subjects:  44%|████▍     | 235/532 [07:41<09:29,  1.92s/it]predicting train subjects:  44%|████▍     | 236/532 [07:43<09:49,  1.99s/it]predicting train subjects:  45%|████▍     | 237/532 [07:45<09:52,  2.01s/it]predicting train subjects:  45%|████▍     | 238/532 [07:47<09:47,  2.00s/it]predicting train subjects:  45%|████▍     | 239/532 [07:49<09:57,  2.04s/it]predicting train subjects:  45%|████▌     | 240/532 [07:51<10:05,  2.07s/it]predicting train subjects:  45%|████▌     | 241/532 [07:53<10:08,  2.09s/it]predicting train subjects:  45%|████▌     | 242/532 [07:56<10:38,  2.20s/it]predicting train subjects:  46%|████▌     | 243/532 [07:58<10:36,  2.20s/it]predicting train subjects:  46%|████▌     | 244/532 [08:00<10:24,  2.17s/it]predicting train subjects:  46%|████▌     | 245/532 [08:02<09:34,  2.00s/it]predicting train subjects:  46%|████▌     | 246/532 [08:03<09:01,  1.89s/it]predicting train subjects:  46%|████▋     | 247/532 [08:05<08:43,  1.84s/it]predicting train subjects:  47%|████▋     | 248/532 [08:07<08:21,  1.77s/it]predicting train subjects:  47%|████▋     | 249/532 [08:08<08:13,  1.75s/it]predicting train subjects:  47%|████▋     | 250/532 [08:10<08:15,  1.76s/it]predicting train subjects:  47%|████▋     | 251/532 [08:12<08:23,  1.79s/it]predicting train subjects:  47%|████▋     | 252/532 [08:14<08:15,  1.77s/it]predicting train subjects:  48%|████▊     | 253/532 [08:15<08:14,  1.77s/it]predicting train subjects:  48%|████▊     | 254/532 [08:17<08:35,  1.85s/it]predicting train subjects:  48%|████▊     | 255/532 [08:20<08:50,  1.92s/it]predicting train subjects:  48%|████▊     | 256/532 [08:21<08:42,  1.89s/it]predicting train subjects:  48%|████▊     | 257/532 [08:24<09:16,  2.02s/it]predicting train subjects:  48%|████▊     | 258/532 [08:26<09:52,  2.16s/it]predicting train subjects:  49%|████▊     | 259/532 [08:28<09:58,  2.19s/it]predicting train subjects:  49%|████▉     | 260/532 [08:31<10:19,  2.28s/it]predicting train subjects:  49%|████▉     | 261/532 [08:33<10:18,  2.28s/it]predicting train subjects:  49%|████▉     | 262/532 [08:36<10:21,  2.30s/it]predicting train subjects:  49%|████▉     | 263/532 [08:37<09:42,  2.16s/it]predicting train subjects:  50%|████▉     | 264/532 [08:39<09:10,  2.05s/it]predicting train subjects:  50%|████▉     | 265/532 [08:41<08:43,  1.96s/it]predicting train subjects:  50%|█████     | 266/532 [08:43<08:23,  1.89s/it]predicting train subjects:  50%|█████     | 267/532 [08:44<07:58,  1.81s/it]predicting train subjects:  50%|█████     | 268/532 [08:46<07:53,  1.79s/it]predicting train subjects:  51%|█████     | 269/532 [08:48<08:26,  1.93s/it]predicting train subjects:  51%|█████     | 270/532 [08:50<08:32,  1.96s/it]predicting train subjects:  51%|█████     | 271/532 [08:53<08:51,  2.04s/it]predicting train subjects:  51%|█████     | 272/532 [08:55<09:03,  2.09s/it]predicting train subjects:  51%|█████▏    | 273/532 [08:57<09:10,  2.12s/it]predicting train subjects:  52%|█████▏    | 274/532 [08:59<09:17,  2.16s/it]predicting train subjects:  52%|█████▏    | 275/532 [09:02<09:48,  2.29s/it]predicting train subjects:  52%|█████▏    | 276/532 [09:04<10:14,  2.40s/it]predicting train subjects:  52%|█████▏    | 277/532 [09:07<10:25,  2.45s/it]predicting train subjects:  52%|█████▏    | 278/532 [09:10<10:36,  2.51s/it]predicting train subjects:  52%|█████▏    | 279/532 [09:12<10:36,  2.52s/it]predicting train subjects:  53%|█████▎    | 280/532 [09:15<10:45,  2.56s/it]predicting train subjects:  53%|█████▎    | 281/532 [09:18<10:58,  2.62s/it]predicting train subjects:  53%|█████▎    | 282/532 [09:20<10:46,  2.59s/it]predicting train subjects:  53%|█████▎    | 283/532 [09:23<10:45,  2.59s/it]predicting train subjects:  53%|█████▎    | 284/532 [09:25<10:24,  2.52s/it]predicting train subjects:  54%|█████▎    | 285/532 [09:28<10:27,  2.54s/it]predicting train subjects:  54%|█████▍    | 286/532 [09:30<10:39,  2.60s/it]predicting train subjects:  54%|█████▍    | 287/532 [09:32<09:47,  2.40s/it]predicting train subjects:  54%|█████▍    | 288/532 [09:34<09:10,  2.26s/it]predicting train subjects:  54%|█████▍    | 289/532 [09:36<08:31,  2.11s/it]predicting train subjects:  55%|█████▍    | 290/532 [09:38<08:07,  2.02s/it]predicting train subjects:  55%|█████▍    | 291/532 [09:40<08:08,  2.03s/it]predicting train subjects:  55%|█████▍    | 292/532 [09:42<07:45,  1.94s/it]predicting train subjects:  55%|█████▌    | 293/532 [09:44<07:50,  1.97s/it]predicting train subjects:  55%|█████▌    | 294/532 [09:46<08:07,  2.05s/it]predicting train subjects:  55%|█████▌    | 295/532 [09:48<08:28,  2.15s/it]predicting train subjects:  56%|█████▌    | 296/532 [09:50<08:24,  2.14s/it]predicting train subjects:  56%|█████▌    | 297/532 [09:53<08:27,  2.16s/it]predicting train subjects:  56%|█████▌    | 298/532 [09:55<08:22,  2.15s/it]predicting train subjects:  56%|█████▌    | 299/532 [09:56<07:51,  2.02s/it]predicting train subjects:  56%|█████▋    | 300/532 [09:58<07:32,  1.95s/it]predicting train subjects:  57%|█████▋    | 301/532 [10:00<07:16,  1.89s/it]predicting train subjects:  57%|█████▋    | 302/532 [10:02<06:50,  1.78s/it]predicting train subjects:  57%|█████▋    | 303/532 [10:03<06:37,  1.74s/it]predicting train subjects:  57%|█████▋    | 304/532 [10:05<06:40,  1.76s/it]predicting train subjects:  57%|█████▋    | 305/532 [10:07<07:12,  1.91s/it]predicting train subjects:  58%|█████▊    | 306/532 [10:09<07:28,  1.98s/it]predicting train subjects:  58%|█████▊    | 307/532 [10:12<07:37,  2.03s/it]predicting train subjects:  58%|█████▊    | 308/532 [10:14<07:42,  2.07s/it]predicting train subjects:  58%|█████▊    | 309/532 [10:16<07:58,  2.14s/it]predicting train subjects:  58%|█████▊    | 310/532 [10:18<08:02,  2.17s/it]predicting train subjects:  58%|█████▊    | 311/532 [10:21<08:45,  2.38s/it]predicting train subjects:  59%|█████▊    | 312/532 [10:24<09:17,  2.53s/it]predicting train subjects:  59%|█████▉    | 313/532 [10:27<09:39,  2.64s/it]predicting train subjects:  59%|█████▉    | 314/532 [10:30<09:53,  2.72s/it]predicting train subjects:  59%|█████▉    | 315/532 [10:33<10:04,  2.78s/it]predicting train subjects:  59%|█████▉    | 316/532 [10:36<10:08,  2.82s/it]predicting train subjects:  60%|█████▉    | 317/532 [10:37<08:53,  2.48s/it]predicting train subjects:  60%|█████▉    | 318/532 [10:39<08:00,  2.24s/it]predicting train subjects:  60%|█████▉    | 319/532 [10:41<07:22,  2.08s/it]predicting train subjects:  60%|██████    | 320/532 [10:42<06:55,  1.96s/it]predicting train subjects:  60%|██████    | 321/532 [10:44<06:34,  1.87s/it]predicting train subjects:  61%|██████    | 322/532 [10:46<06:17,  1.80s/it]predicting train subjects:  61%|██████    | 323/532 [10:48<06:49,  1.96s/it]predicting train subjects:  61%|██████    | 324/532 [10:50<07:05,  2.04s/it]predicting train subjects:  61%|██████    | 325/532 [10:53<07:42,  2.24s/it]predicting train subjects:  61%|██████▏   | 326/532 [10:55<07:48,  2.27s/it]predicting train subjects:  61%|██████▏   | 327/532 [10:58<07:52,  2.30s/it]predicting train subjects:  62%|██████▏   | 328/532 [11:00<07:53,  2.32s/it]predicting train subjects:  62%|██████▏   | 329/532 [11:02<07:22,  2.18s/it]predicting train subjects:  62%|██████▏   | 330/532 [11:04<06:57,  2.07s/it]predicting train subjects:  62%|██████▏   | 331/532 [11:06<06:42,  2.00s/it]predicting train subjects:  62%|██████▏   | 332/532 [11:07<06:27,  1.94s/it]predicting train subjects:  63%|██████▎   | 333/532 [11:09<06:24,  1.93s/it]predicting train subjects:  63%|██████▎   | 334/532 [11:11<06:14,  1.89s/it]predicting train subjects:  63%|██████▎   | 335/532 [11:13<06:28,  1.97s/it]predicting train subjects:  63%|██████▎   | 336/532 [11:15<06:34,  2.01s/it]predicting train subjects:  63%|██████▎   | 337/532 [11:17<06:38,  2.04s/it]predicting train subjects:  64%|██████▎   | 338/532 [11:19<06:36,  2.04s/it]predicting train subjects:  64%|██████▎   | 339/532 [11:22<06:38,  2.06s/it]predicting train subjects:  64%|██████▍   | 340/532 [11:24<06:35,  2.06s/it]predicting train subjects:  64%|██████▍   | 341/532 [11:25<06:02,  1.90s/it]predicting train subjects:  64%|██████▍   | 342/532 [11:27<05:38,  1.78s/it]predicting train subjects:  64%|██████▍   | 343/532 [11:28<05:21,  1.70s/it]predicting train subjects:  65%|██████▍   | 344/532 [11:30<05:09,  1.65s/it]predicting train subjects:  65%|██████▍   | 345/532 [11:31<05:00,  1.61s/it]predicting train subjects:  65%|██████▌   | 346/532 [11:33<04:56,  1.60s/it]predicting train subjects:  65%|██████▌   | 347/532 [11:35<05:04,  1.65s/it]predicting train subjects:  65%|██████▌   | 348/532 [11:36<05:08,  1.68s/it]predicting train subjects:  66%|██████▌   | 349/532 [11:38<05:10,  1.70s/it]predicting train subjects:  66%|██████▌   | 350/532 [11:40<05:11,  1.71s/it]predicting train subjects:  66%|██████▌   | 351/532 [11:41<05:10,  1.71s/it]predicting train subjects:  66%|██████▌   | 352/532 [11:43<05:08,  1.71s/it]predicting train subjects:  66%|██████▋   | 353/532 [11:45<05:12,  1.74s/it]predicting train subjects:  67%|██████▋   | 354/532 [11:47<05:07,  1.73s/it]predicting train subjects:  67%|██████▋   | 355/532 [11:49<05:11,  1.76s/it]predicting train subjects:  67%|██████▋   | 356/532 [11:50<05:06,  1.74s/it]predicting train subjects:  67%|██████▋   | 357/532 [11:52<05:06,  1.75s/it]predicting train subjects:  67%|██████▋   | 358/532 [11:54<05:05,  1.76s/it]predicting train subjects:  67%|██████▋   | 359/532 [11:55<04:56,  1.71s/it]predicting train subjects:  68%|██████▊   | 360/532 [11:57<04:46,  1.66s/it]predicting train subjects:  68%|██████▊   | 361/532 [11:58<04:37,  1.63s/it]predicting train subjects:  68%|██████▊   | 362/532 [12:00<04:32,  1.60s/it]predicting train subjects:  68%|██████▊   | 363/532 [12:02<04:27,  1.58s/it]predicting train subjects:  68%|██████▊   | 364/532 [12:03<04:27,  1.59s/it]predicting train subjects:  69%|██████▊   | 365/532 [12:05<04:22,  1.57s/it]predicting train subjects:  69%|██████▉   | 366/532 [12:06<04:19,  1.56s/it]predicting train subjects:  69%|██████▉   | 367/532 [12:08<04:15,  1.55s/it]predicting train subjects:  69%|██████▉   | 368/532 [12:09<04:13,  1.55s/it]predicting train subjects:  69%|██████▉   | 369/532 [12:11<04:11,  1.55s/it]predicting train subjects:  70%|██████▉   | 370/532 [12:12<04:08,  1.53s/it]predicting train subjects:  70%|██████▉   | 371/532 [12:14<04:34,  1.71s/it]predicting train subjects:  70%|██████▉   | 372/532 [12:17<04:55,  1.85s/it]predicting train subjects:  70%|███████   | 373/532 [12:19<05:06,  1.93s/it]predicting train subjects:  70%|███████   | 374/532 [12:21<05:21,  2.03s/it]predicting train subjects:  70%|███████   | 375/532 [12:23<05:27,  2.09s/it]predicting train subjects:  71%|███████   | 376/532 [12:25<05:27,  2.10s/it]predicting train subjects:  71%|███████   | 377/532 [12:27<05:11,  2.01s/it]predicting train subjects:  71%|███████   | 378/532 [12:29<05:03,  1.97s/it]predicting train subjects:  71%|███████   | 379/532 [12:31<04:55,  1.93s/it]predicting train subjects:  71%|███████▏  | 380/532 [12:33<04:59,  1.97s/it]predicting train subjects:  72%|███████▏  | 381/532 [12:35<04:55,  1.96s/it]predicting train subjects:  72%|███████▏  | 382/532 [12:37<04:52,  1.95s/it]predicting train subjects:  72%|███████▏  | 383/532 [12:39<04:47,  1.93s/it]predicting train subjects:  72%|███████▏  | 384/532 [12:41<04:41,  1.90s/it]predicting train subjects:  72%|███████▏  | 385/532 [12:42<04:35,  1.87s/it]predicting train subjects:  73%|███████▎  | 386/532 [12:44<04:32,  1.87s/it]predicting train subjects:  73%|███████▎  | 387/532 [12:46<04:27,  1.85s/it]predicting train subjects:  73%|███████▎  | 388/532 [12:48<04:26,  1.85s/it]predicting train subjects:  73%|███████▎  | 389/532 [12:50<04:24,  1.85s/it]predicting train subjects:  73%|███████▎  | 390/532 [12:52<04:25,  1.87s/it]predicting train subjects:  73%|███████▎  | 391/532 [12:54<04:26,  1.89s/it]predicting train subjects:  74%|███████▎  | 392/532 [12:55<04:23,  1.88s/it]predicting train subjects:  74%|███████▍  | 393/532 [12:57<04:28,  1.93s/it]predicting train subjects:  74%|███████▍  | 394/532 [12:59<04:25,  1.92s/it]predicting train subjects:  74%|███████▍  | 395/532 [13:01<04:21,  1.91s/it]predicting train subjects:  74%|███████▍  | 396/532 [13:03<04:18,  1.90s/it]predicting train subjects:  75%|███████▍  | 397/532 [13:05<04:14,  1.88s/it]predicting train subjects:  75%|███████▍  | 398/532 [13:07<04:12,  1.89s/it]predicting train subjects:  75%|███████▌  | 399/532 [13:09<04:07,  1.86s/it]predicting train subjects:  75%|███████▌  | 400/532 [13:11<04:10,  1.90s/it]predicting train subjects:  75%|███████▌  | 401/532 [13:13<04:14,  1.94s/it]predicting train subjects:  76%|███████▌  | 402/532 [13:15<04:19,  2.00s/it]predicting train subjects:  76%|███████▌  | 403/532 [13:17<04:20,  2.02s/it]predicting train subjects:  76%|███████▌  | 404/532 [13:19<04:26,  2.08s/it]predicting train subjects:  76%|███████▌  | 405/532 [13:21<04:25,  2.09s/it]predicting train subjects:  76%|███████▋  | 406/532 [13:23<04:22,  2.08s/it]predicting train subjects:  77%|███████▋  | 407/532 [13:25<04:09,  1.99s/it]predicting train subjects:  77%|███████▋  | 408/532 [13:27<04:00,  1.94s/it]predicting train subjects:  77%|███████▋  | 409/532 [13:29<03:57,  1.93s/it]predicting train subjects:  77%|███████▋  | 410/532 [13:31<03:49,  1.88s/it]predicting train subjects:  77%|███████▋  | 411/532 [13:32<03:46,  1.87s/it]predicting train subjects:  77%|███████▋  | 412/532 [13:34<03:40,  1.84s/it]predicting train subjects:  78%|███████▊  | 413/532 [13:36<03:34,  1.80s/it]predicting train subjects:  78%|███████▊  | 414/532 [13:38<03:32,  1.80s/it]predicting train subjects:  78%|███████▊  | 415/532 [13:39<03:27,  1.78s/it]predicting train subjects:  78%|███████▊  | 416/532 [13:41<03:24,  1.76s/it]predicting train subjects:  78%|███████▊  | 417/532 [13:43<03:26,  1.80s/it]predicting train subjects:  79%|███████▊  | 418/532 [13:45<03:22,  1.78s/it]predicting train subjects:  79%|███████▉  | 419/532 [13:47<03:28,  1.84s/it]predicting train subjects:  79%|███████▉  | 420/532 [13:49<03:33,  1.90s/it]predicting train subjects:  79%|███████▉  | 421/532 [13:51<03:34,  1.94s/it]predicting train subjects:  79%|███████▉  | 422/532 [13:53<03:34,  1.95s/it]predicting train subjects:  80%|███████▉  | 423/532 [13:55<03:32,  1.95s/it]predicting train subjects:  80%|███████▉  | 424/532 [13:57<03:29,  1.94s/it]predicting train subjects:  80%|███████▉  | 425/532 [13:59<03:29,  1.96s/it]predicting train subjects:  80%|████████  | 426/532 [14:01<03:27,  1.96s/it]predicting train subjects:  80%|████████  | 427/532 [14:03<03:32,  2.03s/it]predicting train subjects:  80%|████████  | 428/532 [14:05<03:31,  2.04s/it]predicting train subjects:  81%|████████  | 429/532 [14:07<03:34,  2.08s/it]predicting train subjects:  81%|████████  | 430/532 [14:09<03:29,  2.05s/it]predicting train subjects:  81%|████████  | 431/532 [14:11<03:28,  2.07s/it]predicting train subjects:  81%|████████  | 432/532 [14:13<03:30,  2.10s/it]predicting train subjects:  81%|████████▏ | 433/532 [14:16<03:33,  2.16s/it]predicting train subjects:  82%|████████▏ | 434/532 [14:18<03:31,  2.15s/it]predicting train subjects:  82%|████████▏ | 435/532 [14:20<03:26,  2.13s/it]predicting train subjects:  82%|████████▏ | 436/532 [14:22<03:25,  2.15s/it]predicting train subjects:  82%|████████▏ | 437/532 [14:24<03:08,  1.98s/it]predicting train subjects:  82%|████████▏ | 438/532 [14:25<02:55,  1.87s/it]predicting train subjects:  83%|████████▎ | 439/532 [14:27<02:48,  1.82s/it]predicting train subjects:  83%|████████▎ | 440/532 [14:28<02:40,  1.74s/it]predicting train subjects:  83%|████████▎ | 441/532 [14:30<02:31,  1.67s/it]predicting train subjects:  83%|████████▎ | 442/532 [14:32<02:27,  1.64s/it]predicting train subjects:  83%|████████▎ | 443/532 [14:33<02:22,  1.60s/it]predicting train subjects:  83%|████████▎ | 444/532 [14:35<02:19,  1.59s/it]predicting train subjects:  84%|████████▎ | 445/532 [14:36<02:17,  1.58s/it]predicting train subjects:  84%|████████▍ | 446/532 [14:38<02:11,  1.53s/it]predicting train subjects:  84%|████████▍ | 447/532 [14:39<02:09,  1.52s/it]predicting train subjects:  84%|████████▍ | 448/532 [14:41<02:06,  1.51s/it]predicting train subjects:  84%|████████▍ | 449/532 [14:42<02:10,  1.57s/it]predicting train subjects:  85%|████████▍ | 450/532 [14:44<02:13,  1.63s/it]predicting train subjects:  85%|████████▍ | 451/532 [14:46<02:15,  1.67s/it]predicting train subjects:  85%|████████▍ | 452/532 [14:47<02:13,  1.66s/it]predicting train subjects:  85%|████████▌ | 453/532 [14:49<02:10,  1.66s/it]predicting train subjects:  85%|████████▌ | 454/532 [14:51<02:09,  1.66s/it]predicting train subjects:  86%|████████▌ | 455/532 [14:53<02:13,  1.73s/it]predicting train subjects:  86%|████████▌ | 456/532 [14:55<02:22,  1.88s/it]predicting train subjects:  86%|████████▌ | 457/532 [14:57<02:22,  1.90s/it]predicting train subjects:  86%|████████▌ | 458/532 [14:59<02:22,  1.92s/it]predicting train subjects:  86%|████████▋ | 459/532 [15:01<02:22,  1.95s/it]predicting train subjects:  86%|████████▋ | 460/532 [15:03<02:20,  1.95s/it]predicting train subjects:  87%|████████▋ | 461/532 [15:05<02:26,  2.06s/it]predicting train subjects:  87%|████████▋ | 462/532 [15:07<02:28,  2.13s/it]predicting train subjects:  87%|████████▋ | 463/532 [15:10<02:29,  2.17s/it]predicting train subjects:  87%|████████▋ | 464/532 [15:12<02:31,  2.23s/it]predicting train subjects:  87%|████████▋ | 465/532 [15:14<02:33,  2.29s/it]predicting train subjects:  88%|████████▊ | 466/532 [15:17<02:32,  2.30s/it]predicting train subjects:  88%|████████▊ | 467/532 [15:19<02:21,  2.17s/it]predicting train subjects:  88%|████████▊ | 468/532 [15:21<02:13,  2.09s/it]predicting train subjects:  88%|████████▊ | 469/532 [15:22<02:06,  2.01s/it]predicting train subjects:  88%|████████▊ | 470/532 [15:24<02:00,  1.95s/it]predicting train subjects:  89%|████████▊ | 471/532 [15:26<01:55,  1.90s/it]predicting train subjects:  89%|████████▊ | 472/532 [15:28<01:52,  1.87s/it]predicting train subjects:  89%|████████▉ | 473/532 [15:30<01:53,  1.92s/it]predicting train subjects:  89%|████████▉ | 474/532 [15:32<01:51,  1.93s/it]predicting train subjects:  89%|████████▉ | 475/532 [15:34<01:50,  1.93s/it]predicting train subjects:  89%|████████▉ | 476/532 [15:36<01:48,  1.94s/it]predicting train subjects:  90%|████████▉ | 477/532 [15:38<01:45,  1.92s/it]predicting train subjects:  90%|████████▉ | 478/532 [15:39<01:44,  1.93s/it]predicting train subjects:  90%|█████████ | 479/532 [15:41<01:39,  1.88s/it]predicting train subjects:  90%|█████████ | 480/532 [15:43<01:35,  1.83s/it]predicting train subjects:  90%|█████████ | 481/532 [15:45<01:32,  1.82s/it]predicting train subjects:  91%|█████████ | 482/532 [15:46<01:28,  1.77s/it]predicting train subjects:  91%|█████████ | 483/532 [15:48<01:26,  1.76s/it]predicting train subjects:  91%|█████████ | 484/532 [15:50<01:23,  1.73s/it]predicting train subjects:  91%|█████████ | 485/532 [15:52<01:27,  1.87s/it]predicting train subjects:  91%|█████████▏| 486/532 [15:54<01:32,  2.00s/it]predicting train subjects:  92%|█████████▏| 487/532 [15:57<01:34,  2.10s/it]predicting train subjects:  92%|█████████▏| 488/532 [15:59<01:34,  2.14s/it]predicting train subjects:  92%|█████████▏| 489/532 [16:01<01:34,  2.19s/it]predicting train subjects:  92%|█████████▏| 490/532 [16:03<01:31,  2.19s/it]predicting train subjects:  92%|█████████▏| 491/532 [16:05<01:25,  2.09s/it]predicting train subjects:  92%|█████████▏| 492/532 [16:07<01:20,  2.01s/it]predicting train subjects:  93%|█████████▎| 493/532 [16:09<01:15,  1.94s/it]predicting train subjects:  93%|█████████▎| 494/532 [16:11<01:13,  1.92s/it]predicting train subjects:  93%|█████████▎| 495/532 [16:13<01:09,  1.89s/it]predicting train subjects:  93%|█████████▎| 496/532 [16:14<01:08,  1.89s/it]predicting train subjects:  93%|█████████▎| 497/532 [16:16<01:06,  1.91s/it]predicting train subjects:  94%|█████████▎| 498/532 [16:18<01:05,  1.94s/it]predicting train subjects:  94%|█████████▍| 499/532 [16:21<01:06,  2.00s/it]predicting train subjects:  94%|█████████▍| 500/532 [16:23<01:07,  2.11s/it]predicting train subjects:  94%|█████████▍| 501/532 [16:25<01:06,  2.14s/it]predicting train subjects:  94%|█████████▍| 502/532 [16:27<01:04,  2.16s/it]predicting train subjects:  95%|█████████▍| 503/532 [16:29<01:02,  2.15s/it]predicting train subjects:  95%|█████████▍| 504/532 [16:31<00:58,  2.08s/it]predicting train subjects:  95%|█████████▍| 505/532 [16:33<00:54,  2.01s/it]predicting train subjects:  95%|█████████▌| 506/532 [16:35<00:51,  2.00s/it]predicting train subjects:  95%|█████████▌| 507/532 [16:37<00:49,  2.00s/it]predicting train subjects:  95%|█████████▌| 508/532 [16:39<00:48,  2.00s/it]predicting train subjects:  96%|█████████▌| 509/532 [16:42<00:49,  2.17s/it]predicting train subjects:  96%|█████████▌| 510/532 [16:44<00:50,  2.29s/it]predicting train subjects:  96%|█████████▌| 511/532 [16:47<00:48,  2.31s/it]predicting train subjects:  96%|█████████▌| 512/532 [16:49<00:48,  2.42s/it]predicting train subjects:  96%|█████████▋| 513/532 [16:52<00:45,  2.38s/it]predicting train subjects:  97%|█████████▋| 514/532 [16:54<00:42,  2.39s/it]predicting train subjects:  97%|█████████▋| 515/532 [16:56<00:38,  2.29s/it]predicting train subjects:  97%|█████████▋| 516/532 [16:58<00:35,  2.21s/it]predicting train subjects:  97%|█████████▋| 517/532 [17:00<00:32,  2.17s/it]predicting train subjects:  97%|█████████▋| 518/532 [17:02<00:30,  2.16s/it]predicting train subjects:  98%|█████████▊| 519/532 [17:04<00:27,  2.10s/it]predicting train subjects:  98%|█████████▊| 520/532 [17:06<00:25,  2.09s/it]predicting train subjects:  98%|█████████▊| 521/532 [17:09<00:23,  2.17s/it]predicting train subjects:  98%|█████████▊| 522/532 [17:11<00:21,  2.17s/it]predicting train subjects:  98%|█████████▊| 523/532 [17:13<00:19,  2.18s/it]predicting train subjects:  98%|█████████▊| 524/532 [17:15<00:17,  2.19s/it]predicting train subjects:  99%|█████████▊| 525/532 [17:18<00:15,  2.22s/it]predicting train subjects:  99%|█████████▉| 526/532 [17:20<00:12,  2.16s/it]predicting train subjects:  99%|█████████▉| 527/532 [17:22<00:10,  2.11s/it]predicting train subjects:  99%|█████████▉| 528/532 [17:24<00:08,  2.05s/it]predicting train subjects:  99%|█████████▉| 529/532 [17:26<00:06,  2.04s/it]predicting train subjects: 100%|█████████▉| 530/532 [17:28<00:04,  2.06s/it]predicting train subjects: 100%|█████████▉| 531/532 [17:30<00:02,  2.01s/it]predicting train subjects: 100%|██████████| 532/532 [17:32<00:00,  2.00s/it]
Loading train:   0%|          | 0/532 [00:00<?, ?it/s]Loading train:   0%|          | 1/532 [00:01<15:18,  1.73s/it]Loading train:   0%|          | 2/532 [00:03<14:21,  1.63s/it]Loading train:   1%|          | 3/532 [00:04<14:17,  1.62s/it]Loading train:   1%|          | 4/532 [00:06<14:12,  1.62s/it]Loading train:   1%|          | 5/532 [00:08<14:21,  1.63s/it]Loading train:   1%|          | 6/532 [00:10<15:40,  1.79s/it]Loading train:   1%|▏         | 7/532 [00:11<15:06,  1.73s/it]Loading train:   2%|▏         | 8/532 [00:13<14:49,  1.70s/it]Loading train:   2%|▏         | 9/532 [00:15<14:46,  1.70s/it]Loading train:   2%|▏         | 10/532 [00:16<14:12,  1.63s/it]Loading train:   2%|▏         | 11/532 [00:18<13:51,  1.60s/it]Loading train:   2%|▏         | 12/532 [00:19<14:28,  1.67s/it]Loading train:   2%|▏         | 13/532 [00:21<15:04,  1.74s/it]Loading train:   3%|▎         | 14/532 [00:23<15:09,  1.76s/it]Loading train:   3%|▎         | 15/532 [00:25<14:25,  1.67s/it]Loading train:   3%|▎         | 16/532 [00:26<14:09,  1.65s/it]Loading train:   3%|▎         | 17/532 [00:28<13:40,  1.59s/it]Loading train:   3%|▎         | 18/532 [00:29<13:27,  1.57s/it]Loading train:   4%|▎         | 19/532 [00:31<13:02,  1.53s/it]Loading train:   4%|▍         | 20/532 [00:32<13:13,  1.55s/it]Loading train:   4%|▍         | 21/532 [00:35<15:12,  1.79s/it]Loading train:   4%|▍         | 22/532 [00:36<14:47,  1.74s/it]Loading train:   4%|▍         | 23/532 [00:38<14:33,  1.72s/it]Loading train:   5%|▍         | 24/532 [00:40<14:40,  1.73s/it]Loading train:   5%|▍         | 25/532 [00:42<15:11,  1.80s/it]Loading train:   5%|▍         | 26/532 [00:43<15:25,  1.83s/it]Loading train:   5%|▌         | 27/532 [00:45<15:49,  1.88s/it]Loading train:   5%|▌         | 28/532 [00:47<14:36,  1.74s/it]Loading train:   5%|▌         | 29/532 [00:48<13:57,  1.66s/it]Loading train:   6%|▌         | 30/532 [00:50<13:41,  1.64s/it]Loading train:   6%|▌         | 31/532 [00:51<13:17,  1.59s/it]Loading train:   6%|▌         | 32/532 [00:53<13:39,  1.64s/it]Loading train:   6%|▌         | 33/532 [00:55<14:12,  1.71s/it]Loading train:   6%|▋         | 34/532 [00:58<16:19,  1.97s/it]Loading train:   7%|▋         | 35/532 [00:59<15:42,  1.90s/it]Loading train:   7%|▋         | 36/532 [01:01<15:30,  1.88s/it]Loading train:   7%|▋         | 37/532 [01:03<14:30,  1.76s/it]Loading train:   7%|▋         | 38/532 [01:05<14:56,  1.82s/it]Loading train:   7%|▋         | 39/532 [01:06<14:56,  1.82s/it]Loading train:   8%|▊         | 40/532 [01:08<13:31,  1.65s/it]Loading train:   8%|▊         | 41/532 [01:10<14:04,  1.72s/it]Loading train:   8%|▊         | 42/532 [01:11<14:39,  1.80s/it]Loading train:   8%|▊         | 43/532 [01:13<14:30,  1.78s/it]Loading train:   8%|▊         | 44/532 [01:15<14:26,  1.78s/it]Loading train:   8%|▊         | 45/532 [01:17<14:13,  1.75s/it]Loading train:   9%|▊         | 46/532 [01:18<13:47,  1.70s/it]Loading train:   9%|▉         | 47/532 [01:21<15:43,  1.94s/it]Loading train:   9%|▉         | 48/532 [01:23<15:36,  1.93s/it]Loading train:   9%|▉         | 49/532 [01:24<14:15,  1.77s/it]Loading train:   9%|▉         | 50/532 [01:26<13:40,  1.70s/it]Loading train:  10%|▉         | 51/532 [01:27<13:15,  1.65s/it]Loading train:  10%|▉         | 52/532 [01:29<13:36,  1.70s/it]Loading train:  10%|▉         | 53/532 [01:31<13:25,  1.68s/it]Loading train:  10%|█         | 54/532 [01:33<14:59,  1.88s/it]Loading train:  10%|█         | 55/532 [01:35<15:37,  1.96s/it]Loading train:  11%|█         | 56/532 [01:37<14:33,  1.84s/it]Loading train:  11%|█         | 57/532 [01:38<13:30,  1.71s/it]Loading train:  11%|█         | 58/532 [01:40<14:03,  1.78s/it]Loading train:  11%|█         | 59/532 [01:42<15:18,  1.94s/it]Loading train:  11%|█▏        | 60/532 [01:44<14:23,  1.83s/it]Loading train:  11%|█▏        | 61/532 [01:45<13:32,  1.72s/it]Loading train:  12%|█▏        | 62/532 [01:47<14:15,  1.82s/it]Loading train:  12%|█▏        | 63/532 [01:49<14:36,  1.87s/it]Loading train:  12%|█▏        | 64/532 [01:51<14:17,  1.83s/it]Loading train:  12%|█▏        | 65/532 [01:53<13:21,  1.72s/it]Loading train:  12%|█▏        | 66/532 [01:55<14:05,  1.81s/it]Loading train:  13%|█▎        | 67/532 [01:56<14:05,  1.82s/it]Loading train:  13%|█▎        | 68/532 [01:58<14:18,  1.85s/it]Loading train:  13%|█▎        | 69/532 [02:00<13:36,  1.76s/it]Loading train:  13%|█▎        | 70/532 [02:02<13:19,  1.73s/it]Loading train:  13%|█▎        | 71/532 [02:03<12:16,  1.60s/it]Loading train:  14%|█▎        | 72/532 [02:04<11:30,  1.50s/it]Loading train:  14%|█▎        | 73/532 [02:06<12:38,  1.65s/it]Loading train:  14%|█▍        | 74/532 [02:08<13:45,  1.80s/it]Loading train:  14%|█▍        | 75/532 [02:11<14:52,  1.95s/it]Loading train:  14%|█▍        | 76/532 [02:13<14:37,  1.92s/it]Loading train:  14%|█▍        | 77/532 [02:14<14:20,  1.89s/it]Loading train:  15%|█▍        | 78/532 [02:16<14:02,  1.86s/it]Loading train:  15%|█▍        | 79/532 [02:17<12:51,  1.70s/it]Loading train:  15%|█▌        | 80/532 [02:19<12:45,  1.69s/it]Loading train:  15%|█▌        | 81/532 [02:21<12:31,  1.67s/it]Loading train:  15%|█▌        | 82/532 [02:22<12:31,  1.67s/it]Loading train:  16%|█▌        | 83/532 [02:24<12:01,  1.61s/it]Loading train:  16%|█▌        | 84/532 [02:25<11:24,  1.53s/it]Loading train:  16%|█▌        | 85/532 [02:27<11:07,  1.49s/it]Loading train:  16%|█▌        | 86/532 [02:28<11:12,  1.51s/it]Loading train:  16%|█▋        | 87/532 [02:30<11:23,  1.54s/it]Loading train:  17%|█▋        | 88/532 [02:31<10:58,  1.48s/it]Loading train:  17%|█▋        | 89/532 [02:33<10:59,  1.49s/it]Loading train:  17%|█▋        | 90/532 [02:34<11:12,  1.52s/it]Loading train:  17%|█▋        | 91/532 [02:36<11:21,  1.55s/it]Loading train:  17%|█▋        | 92/532 [02:37<10:51,  1.48s/it]Loading train:  17%|█▋        | 93/532 [02:39<11:05,  1.52s/it]Loading train:  18%|█▊        | 94/532 [02:41<11:40,  1.60s/it]Loading train:  18%|█▊        | 95/532 [02:42<11:56,  1.64s/it]Loading train:  18%|█▊        | 96/532 [02:44<12:49,  1.76s/it]Loading train:  18%|█▊        | 97/532 [02:46<13:13,  1.82s/it]Loading train:  18%|█▊        | 98/532 [02:48<13:01,  1.80s/it]Loading train:  19%|█▊        | 99/532 [02:50<12:47,  1.77s/it]Loading train:  19%|█▉        | 100/532 [02:51<12:36,  1.75s/it]Loading train:  19%|█▉        | 101/532 [02:53<13:13,  1.84s/it]Loading train:  19%|█▉        | 102/532 [02:56<14:05,  1.97s/it]Loading train:  19%|█▉        | 103/532 [02:58<14:12,  1.99s/it]Loading train:  20%|█▉        | 104/532 [02:59<12:50,  1.80s/it]Loading train:  20%|█▉        | 105/532 [03:01<12:24,  1.74s/it]Loading train:  20%|█▉        | 106/532 [03:02<11:50,  1.67s/it]Loading train:  20%|██        | 107/532 [03:04<11:47,  1.66s/it]Loading train:  20%|██        | 108/532 [03:06<12:12,  1.73s/it]Loading train:  20%|██        | 109/532 [03:07<11:54,  1.69s/it]Loading train:  21%|██        | 110/532 [03:09<11:54,  1.69s/it]Loading train:  21%|██        | 111/532 [03:11<11:24,  1.63s/it]Loading train:  21%|██        | 112/532 [03:12<11:28,  1.64s/it]Loading train:  21%|██        | 113/532 [03:14<11:37,  1.66s/it]Loading train:  21%|██▏       | 114/532 [03:16<11:47,  1.69s/it]Loading train:  22%|██▏       | 115/532 [03:17<11:34,  1.67s/it]Loading train:  22%|██▏       | 116/532 [03:19<11:42,  1.69s/it]Loading train:  22%|██▏       | 117/532 [03:21<12:17,  1.78s/it]Loading train:  22%|██▏       | 118/532 [03:22<11:35,  1.68s/it]Loading train:  22%|██▏       | 119/532 [03:24<11:26,  1.66s/it]Loading train:  23%|██▎       | 120/532 [03:25<10:50,  1.58s/it]Loading train:  23%|██▎       | 121/532 [03:28<12:01,  1.76s/it]Loading train:  23%|██▎       | 122/532 [03:29<11:42,  1.71s/it]Loading train:  23%|██▎       | 123/532 [03:31<11:18,  1.66s/it]Loading train:  23%|██▎       | 124/532 [03:33<11:24,  1.68s/it]Loading train:  23%|██▎       | 125/532 [03:35<11:58,  1.77s/it]Loading train:  24%|██▎       | 126/532 [03:37<12:53,  1.91s/it]Loading train:  24%|██▍       | 127/532 [03:38<12:23,  1.84s/it]Loading train:  24%|██▍       | 128/532 [03:40<11:48,  1.75s/it]Loading train:  24%|██▍       | 129/532 [03:42<11:25,  1.70s/it]Loading train:  24%|██▍       | 130/532 [03:43<11:40,  1.74s/it]Loading train:  25%|██▍       | 131/532 [03:45<12:01,  1.80s/it]Loading train:  25%|██▍       | 132/532 [03:47<12:30,  1.88s/it]Loading train:  25%|██▌       | 133/532 [03:49<12:14,  1.84s/it]Loading train:  25%|██▌       | 134/532 [03:51<11:50,  1.78s/it]Loading train:  25%|██▌       | 135/532 [03:53<11:59,  1.81s/it]Loading train:  26%|██▌       | 136/532 [03:55<12:41,  1.92s/it]Loading train:  26%|██▌       | 137/532 [03:57<12:21,  1.88s/it]Loading train:  26%|██▌       | 138/532 [03:59<12:48,  1.95s/it]Loading train:  26%|██▌       | 139/532 [04:01<12:24,  1.90s/it]Loading train:  26%|██▋       | 140/532 [04:03<13:06,  2.01s/it]Loading train:  27%|██▋       | 141/532 [04:05<12:47,  1.96s/it]Loading train:  27%|██▋       | 142/532 [04:07<12:39,  1.95s/it]Loading train:  27%|██▋       | 143/532 [04:08<11:51,  1.83s/it]Loading train:  27%|██▋       | 144/532 [04:10<11:26,  1.77s/it]Loading train:  27%|██▋       | 145/532 [04:11<10:50,  1.68s/it]Loading train:  27%|██▋       | 146/532 [04:13<10:57,  1.70s/it]Loading train:  28%|██▊       | 147/532 [04:15<11:00,  1.72s/it]Loading train:  28%|██▊       | 148/532 [04:16<10:56,  1.71s/it]Loading train:  28%|██▊       | 149/532 [04:18<11:11,  1.75s/it]Loading train:  28%|██▊       | 150/532 [04:20<11:03,  1.74s/it]Loading train:  28%|██▊       | 151/532 [04:21<10:23,  1.64s/it]Loading train:  29%|██▊       | 152/532 [04:23<10:11,  1.61s/it]Loading train:  29%|██▉       | 153/532 [04:25<10:36,  1.68s/it]Loading train:  29%|██▉       | 154/532 [04:27<10:46,  1.71s/it]Loading train:  29%|██▉       | 155/532 [04:28<11:05,  1.77s/it]Loading train:  29%|██▉       | 156/532 [04:30<10:53,  1.74s/it]Loading train:  30%|██▉       | 157/532 [04:32<11:08,  1.78s/it]Loading train:  30%|██▉       | 158/532 [04:34<11:55,  1.91s/it]Loading train:  30%|██▉       | 159/532 [04:36<12:10,  1.96s/it]Loading train:  30%|███       | 160/532 [04:38<11:40,  1.88s/it]Loading train:  30%|███       | 161/532 [04:40<11:09,  1.80s/it]Loading train:  30%|███       | 162/532 [04:41<10:32,  1.71s/it]Loading train:  31%|███       | 163/532 [04:43<10:20,  1.68s/it]Loading train:  31%|███       | 164/532 [04:44<09:53,  1.61s/it]Loading train:  31%|███       | 165/532 [04:46<10:09,  1.66s/it]Loading train:  31%|███       | 166/532 [04:48<10:04,  1.65s/it]Loading train:  31%|███▏      | 167/532 [04:49<10:23,  1.71s/it]Loading train:  32%|███▏      | 168/532 [04:51<10:44,  1.77s/it]Loading train:  32%|███▏      | 169/532 [04:53<10:34,  1.75s/it]Loading train:  32%|███▏      | 170/532 [04:55<10:24,  1.73s/it]Loading train:  32%|███▏      | 171/532 [04:56<09:43,  1.62s/it]Loading train:  32%|███▏      | 172/532 [04:58<09:39,  1.61s/it]Loading train:  33%|███▎      | 173/532 [05:00<10:08,  1.69s/it]Loading train:  33%|███▎      | 174/532 [05:01<09:41,  1.62s/it]Loading train:  33%|███▎      | 175/532 [05:03<10:09,  1.71s/it]Loading train:  33%|███▎      | 176/532 [05:05<10:27,  1.76s/it]Loading train:  33%|███▎      | 177/532 [05:07<10:56,  1.85s/it]Loading train:  33%|███▎      | 178/532 [05:09<10:46,  1.83s/it]Loading train:  34%|███▎      | 179/532 [05:10<10:23,  1.77s/it]Loading train:  34%|███▍      | 180/532 [05:12<10:26,  1.78s/it]Loading train:  34%|███▍      | 181/532 [05:14<10:37,  1.82s/it]Loading train:  34%|███▍      | 182/532 [05:16<10:15,  1.76s/it]Loading train:  34%|███▍      | 183/532 [05:18<10:37,  1.83s/it]Loading train:  35%|███▍      | 184/532 [05:20<11:03,  1.91s/it]Loading train:  35%|███▍      | 185/532 [05:22<12:13,  2.11s/it]Loading train:  35%|███▍      | 186/532 [05:24<11:31,  2.00s/it]Loading train:  35%|███▌      | 187/532 [05:26<12:05,  2.10s/it]Loading train:  35%|███▌      | 188/532 [05:28<12:11,  2.13s/it]Loading train:  36%|███▌      | 189/532 [05:31<12:14,  2.14s/it]Loading train:  36%|███▌      | 190/532 [05:33<12:03,  2.12s/it]Loading train:  36%|███▌      | 191/532 [05:36<13:15,  2.33s/it]Loading train:  36%|███▌      | 192/532 [05:38<14:12,  2.51s/it]Loading train:  36%|███▋      | 193/532 [05:42<15:29,  2.74s/it]Loading train:  36%|███▋      | 194/532 [05:45<15:44,  2.80s/it]Loading train:  37%|███▋      | 195/532 [05:47<15:26,  2.75s/it]Loading train:  37%|███▋      | 196/532 [05:49<14:23,  2.57s/it]Loading train:  37%|███▋      | 197/532 [05:51<13:14,  2.37s/it]Loading train:  37%|███▋      | 198/532 [05:54<12:47,  2.30s/it]Loading train:  37%|███▋      | 199/532 [05:56<12:34,  2.27s/it]Loading train:  38%|███▊      | 200/532 [05:58<12:41,  2.29s/it]Loading train:  38%|███▊      | 201/532 [06:00<12:49,  2.33s/it]Loading train:  38%|███▊      | 202/532 [06:03<13:53,  2.53s/it]Loading train:  38%|███▊      | 203/532 [06:05<12:49,  2.34s/it]Loading train:  38%|███▊      | 204/532 [06:08<12:47,  2.34s/it]Loading train:  39%|███▊      | 205/532 [06:10<13:10,  2.42s/it]Loading train:  39%|███▊      | 206/532 [06:13<13:12,  2.43s/it]Loading train:  39%|███▉      | 207/532 [06:15<13:08,  2.43s/it]Loading train:  39%|███▉      | 208/532 [06:17<12:32,  2.32s/it]Loading train:  39%|███▉      | 209/532 [06:19<11:48,  2.19s/it]Loading train:  39%|███▉      | 210/532 [06:21<11:02,  2.06s/it]Loading train:  40%|███▉      | 211/532 [06:22<10:02,  1.88s/it]Loading train:  40%|███▉      | 212/532 [06:25<10:42,  2.01s/it]Loading train:  40%|████      | 213/532 [06:27<10:40,  2.01s/it]Loading train:  40%|████      | 214/532 [06:28<10:13,  1.93s/it]Loading train:  40%|████      | 215/532 [06:31<11:29,  2.17s/it]Loading train:  41%|████      | 216/532 [06:34<12:13,  2.32s/it]Loading train:  41%|████      | 217/532 [06:36<12:41,  2.42s/it]Loading train:  41%|████      | 218/532 [06:40<13:50,  2.64s/it]Loading train:  41%|████      | 219/532 [06:42<13:55,  2.67s/it]Loading train:  41%|████▏     | 220/532 [06:45<13:19,  2.56s/it]Loading train:  42%|████▏     | 221/532 [06:47<13:12,  2.55s/it]Loading train:  42%|████▏     | 222/532 [06:50<12:49,  2.48s/it]Loading train:  42%|████▏     | 223/532 [06:52<13:03,  2.53s/it]Loading train:  42%|████▏     | 224/532 [06:55<12:52,  2.51s/it]Loading train:  42%|████▏     | 225/532 [06:57<12:41,  2.48s/it]Loading train:  42%|████▏     | 226/532 [07:00<12:45,  2.50s/it]Loading train:  43%|████▎     | 227/532 [07:02<12:37,  2.48s/it]Loading train:  43%|████▎     | 228/532 [07:04<12:00,  2.37s/it]Loading train:  43%|████▎     | 229/532 [07:07<12:41,  2.51s/it]Loading train:  43%|████▎     | 230/532 [07:09<12:25,  2.47s/it]Loading train:  43%|████▎     | 231/532 [07:11<11:50,  2.36s/it]Loading train:  44%|████▎     | 232/532 [07:13<11:12,  2.24s/it]Loading train:  44%|████▍     | 233/532 [07:16<12:00,  2.41s/it]Loading train:  44%|████▍     | 234/532 [07:18<11:02,  2.22s/it]Loading train:  44%|████▍     | 235/532 [07:20<10:57,  2.21s/it]Loading train:  44%|████▍     | 236/532 [07:23<11:35,  2.35s/it]Loading train:  45%|████▍     | 237/532 [07:26<12:33,  2.56s/it]Loading train:  45%|████▍     | 238/532 [07:28<11:52,  2.42s/it]Loading train:  45%|████▍     | 239/532 [07:31<12:03,  2.47s/it]Loading train:  45%|████▌     | 240/532 [07:33<11:36,  2.39s/it]Loading train:  45%|████▌     | 241/532 [07:35<11:41,  2.41s/it]Loading train:  45%|████▌     | 242/532 [07:38<11:36,  2.40s/it]Loading train:  46%|████▌     | 243/532 [07:40<11:37,  2.41s/it]Loading train:  46%|████▌     | 244/532 [07:42<11:02,  2.30s/it]Loading train:  46%|████▌     | 245/532 [07:45<11:17,  2.36s/it]Loading train:  46%|████▌     | 246/532 [07:47<10:33,  2.22s/it]Loading train:  46%|████▋     | 247/532 [07:49<10:30,  2.21s/it]Loading train:  47%|████▋     | 248/532 [07:51<10:04,  2.13s/it]Loading train:  47%|████▋     | 249/532 [07:53<10:24,  2.21s/it]Loading train:  47%|████▋     | 250/532 [07:56<10:55,  2.32s/it]Loading train:  47%|████▋     | 251/532 [07:58<10:42,  2.29s/it]Loading train:  47%|████▋     | 252/532 [08:00<10:07,  2.17s/it]Loading train:  48%|████▊     | 253/532 [08:02<10:32,  2.27s/it]Loading train:  48%|████▊     | 254/532 [08:05<10:51,  2.34s/it]Loading train:  48%|████▊     | 255/532 [08:07<11:10,  2.42s/it]Loading train:  48%|████▊     | 256/532 [08:10<10:45,  2.34s/it]Loading train:  48%|████▊     | 257/532 [08:12<11:07,  2.43s/it]Loading train:  48%|████▊     | 258/532 [08:14<10:53,  2.38s/it]Loading train:  49%|████▊     | 259/532 [08:17<10:57,  2.41s/it]Loading train:  49%|████▉     | 260/532 [08:19<10:53,  2.40s/it]Loading train:  49%|████▉     | 261/532 [08:21<10:26,  2.31s/it]Loading train:  49%|████▉     | 262/532 [08:24<10:34,  2.35s/it]Loading train:  49%|████▉     | 263/532 [08:26<10:48,  2.41s/it]Loading train:  50%|████▉     | 264/532 [08:28<10:00,  2.24s/it]Loading train:  50%|████▉     | 265/532 [08:30<09:57,  2.24s/it]Loading train:  50%|█████     | 266/532 [08:32<09:13,  2.08s/it]Loading train:  50%|█████     | 267/532 [08:34<08:49,  2.00s/it]Loading train:  50%|█████     | 268/532 [08:36<09:10,  2.08s/it]Loading train:  51%|█████     | 269/532 [08:38<09:17,  2.12s/it]Loading train:  51%|█████     | 270/532 [08:41<09:13,  2.11s/it]Loading train:  51%|█████     | 271/532 [08:43<09:40,  2.22s/it]Loading train:  51%|█████     | 272/532 [08:46<10:16,  2.37s/it]Loading train:  51%|█████▏    | 273/532 [08:48<10:27,  2.42s/it]Loading train:  52%|█████▏    | 274/532 [08:50<10:05,  2.35s/it]Loading train:  52%|█████▏    | 275/532 [08:53<10:01,  2.34s/it]Loading train:  52%|█████▏    | 276/532 [08:55<10:12,  2.39s/it]Loading train:  52%|█████▏    | 277/532 [08:58<10:34,  2.49s/it]Loading train:  52%|█████▏    | 278/532 [09:00<10:14,  2.42s/it]Loading train:  52%|█████▏    | 279/532 [09:02<09:46,  2.32s/it]Loading train:  53%|█████▎    | 280/532 [09:05<09:54,  2.36s/it]Loading train:  53%|█████▎    | 281/532 [09:07<09:50,  2.35s/it]Loading train:  53%|█████▎    | 282/532 [09:09<09:17,  2.23s/it]Loading train:  53%|█████▎    | 283/532 [09:11<08:23,  2.02s/it]Loading train:  53%|█████▎    | 284/532 [09:13<09:02,  2.19s/it]Loading train:  54%|█████▎    | 285/532 [09:16<09:26,  2.29s/it]Loading train:  54%|█████▍    | 286/532 [09:18<09:49,  2.40s/it]Loading train:  54%|█████▍    | 287/532 [09:21<09:33,  2.34s/it]Loading train:  54%|█████▍    | 288/532 [09:23<09:37,  2.37s/it]Loading train:  54%|█████▍    | 289/532 [09:25<09:25,  2.33s/it]Loading train:  55%|█████▍    | 290/532 [09:27<09:17,  2.31s/it]Loading train:  55%|█████▍    | 291/532 [09:30<09:05,  2.26s/it]Loading train:  55%|█████▍    | 292/532 [09:32<09:15,  2.32s/it]Loading train:  55%|█████▌    | 293/532 [09:35<09:26,  2.37s/it]Loading train:  55%|█████▌    | 294/532 [09:37<09:31,  2.40s/it]Loading train:  55%|█████▌    | 295/532 [09:39<08:44,  2.21s/it]Loading train:  56%|█████▌    | 296/532 [09:41<08:33,  2.17s/it]Loading train:  56%|█████▌    | 297/532 [09:43<08:52,  2.27s/it]Loading train:  56%|█████▌    | 298/532 [09:45<08:33,  2.20s/it]Loading train:  56%|█████▌    | 299/532 [09:48<08:35,  2.21s/it]Loading train:  56%|█████▋    | 300/532 [09:50<08:45,  2.26s/it]Loading train:  57%|█████▋    | 301/532 [09:52<08:38,  2.25s/it]Loading train:  57%|█████▋    | 302/532 [09:54<08:19,  2.17s/it]Loading train:  57%|█████▋    | 303/532 [09:56<07:39,  2.01s/it]Loading train:  57%|█████▋    | 304/532 [09:57<07:04,  1.86s/it]Loading train:  57%|█████▋    | 305/532 [10:00<08:22,  2.21s/it]Loading train:  58%|█████▊    | 306/532 [10:03<08:48,  2.34s/it]Loading train:  58%|█████▊    | 307/532 [10:06<09:13,  2.46s/it]Loading train:  58%|█████▊    | 308/532 [10:08<09:15,  2.48s/it]Loading train:  58%|█████▊    | 309/532 [10:11<09:45,  2.63s/it]Loading train:  58%|█████▊    | 310/532 [10:14<09:16,  2.51s/it]Loading train:  58%|█████▊    | 311/532 [10:17<10:09,  2.76s/it]Loading train:  59%|█████▊    | 312/532 [10:19<09:56,  2.71s/it]Loading train:  59%|█████▉    | 313/532 [10:23<10:17,  2.82s/it]Loading train:  59%|█████▉    | 314/532 [10:26<11:18,  3.11s/it]Loading train:  59%|█████▉    | 315/532 [10:29<10:59,  3.04s/it]Loading train:  59%|█████▉    | 316/532 [10:32<11:05,  3.08s/it]Loading train:  60%|█████▉    | 317/532 [10:35<10:34,  2.95s/it]Loading train:  60%|█████▉    | 318/532 [10:37<09:37,  2.70s/it]Loading train:  60%|█████▉    | 319/532 [10:39<08:27,  2.38s/it]Loading train:  60%|██████    | 320/532 [10:40<07:36,  2.15s/it]Loading train:  60%|██████    | 321/532 [10:43<07:34,  2.16s/it]Loading train:  61%|██████    | 322/532 [10:45<07:20,  2.10s/it]Loading train:  61%|██████    | 323/532 [10:47<07:47,  2.24s/it]Loading train:  61%|██████    | 324/532 [10:50<07:57,  2.30s/it]Loading train:  61%|██████    | 325/532 [10:53<08:41,  2.52s/it]Loading train:  61%|██████▏   | 326/532 [10:56<10:00,  2.91s/it]Loading train:  61%|██████▏   | 327/532 [10:59<09:08,  2.68s/it]Loading train:  62%|██████▏   | 328/532 [11:01<09:10,  2.70s/it]Loading train:  62%|██████▏   | 329/532 [11:04<08:44,  2.59s/it]Loading train:  62%|██████▏   | 330/532 [11:06<08:18,  2.47s/it]Loading train:  62%|██████▏   | 331/532 [11:08<07:40,  2.29s/it]Loading train:  62%|██████▏   | 332/532 [11:10<07:13,  2.17s/it]Loading train:  63%|██████▎   | 333/532 [11:12<07:18,  2.20s/it]Loading train:  63%|██████▎   | 334/532 [11:14<07:18,  2.21s/it]Loading train:  63%|██████▎   | 335/532 [11:17<07:32,  2.29s/it]Loading train:  63%|██████▎   | 336/532 [11:18<07:06,  2.17s/it]Loading train:  63%|██████▎   | 337/532 [11:21<06:56,  2.13s/it]Loading train:  64%|██████▎   | 338/532 [11:23<07:07,  2.20s/it]Loading train:  64%|██████▎   | 339/532 [11:25<07:13,  2.24s/it]Loading train:  64%|██████▍   | 340/532 [11:27<06:47,  2.12s/it]Loading train:  64%|██████▍   | 341/532 [11:30<07:24,  2.33s/it]Loading train:  64%|██████▍   | 342/532 [11:32<06:58,  2.20s/it]Loading train:  64%|██████▍   | 343/532 [11:34<07:18,  2.32s/it]Loading train:  65%|██████▍   | 344/532 [11:37<07:13,  2.30s/it]Loading train:  65%|██████▍   | 345/532 [11:39<06:59,  2.24s/it]Loading train:  65%|██████▌   | 346/532 [11:41<07:02,  2.27s/it]Loading train:  65%|██████▌   | 347/532 [11:43<06:58,  2.26s/it]Loading train:  65%|██████▌   | 348/532 [11:46<07:01,  2.29s/it]Loading train:  66%|██████▌   | 349/532 [11:47<06:22,  2.09s/it]Loading train:  66%|██████▌   | 350/532 [11:49<05:57,  1.96s/it]Loading train:  66%|██████▌   | 351/532 [11:51<06:00,  1.99s/it]Loading train:  66%|██████▌   | 352/532 [11:53<06:02,  2.02s/it]Loading train:  66%|██████▋   | 353/532 [11:55<05:57,  2.00s/it]Loading train:  67%|██████▋   | 354/532 [11:57<06:00,  2.03s/it]Loading train:  67%|██████▋   | 355/532 [11:59<05:57,  2.02s/it]Loading train:  67%|██████▋   | 356/532 [12:01<05:45,  1.96s/it]Loading train:  67%|██████▋   | 357/532 [12:03<05:45,  1.97s/it]Loading train:  67%|██████▋   | 358/532 [12:05<05:59,  2.06s/it]Loading train:  67%|██████▋   | 359/532 [12:07<05:46,  2.01s/it]Loading train:  68%|██████▊   | 360/532 [12:09<05:42,  1.99s/it]Loading train:  68%|██████▊   | 361/532 [12:11<05:36,  1.97s/it]Loading train:  68%|██████▊   | 362/532 [12:13<05:41,  2.01s/it]Loading train:  68%|██████▊   | 363/532 [12:15<05:30,  1.96s/it]Loading train:  68%|██████▊   | 364/532 [12:17<05:44,  2.05s/it]Loading train:  69%|██████▊   | 365/532 [12:19<05:19,  1.91s/it]Loading train:  69%|██████▉   | 366/532 [12:21<05:12,  1.88s/it]Loading train:  69%|██████▉   | 367/532 [12:23<05:21,  1.95s/it]Loading train:  69%|██████▉   | 368/532 [12:24<04:59,  1.83s/it]Loading train:  69%|██████▉   | 369/532 [12:26<04:58,  1.83s/it]Loading train:  70%|██████▉   | 370/532 [12:27<04:24,  1.63s/it]Loading train:  70%|██████▉   | 371/532 [12:29<04:38,  1.73s/it]Loading train:  70%|██████▉   | 372/532 [12:31<04:46,  1.79s/it]Loading train:  70%|███████   | 373/532 [12:34<05:14,  1.98s/it]Loading train:  70%|███████   | 374/532 [12:36<05:32,  2.10s/it]Loading train:  70%|███████   | 375/532 [12:39<05:59,  2.29s/it]Loading train:  71%|███████   | 376/532 [12:42<06:31,  2.51s/it]Loading train:  71%|███████   | 377/532 [12:44<06:04,  2.35s/it]Loading train:  71%|███████   | 378/532 [12:46<06:04,  2.36s/it]Loading train:  71%|███████   | 379/532 [12:48<05:59,  2.35s/it]Loading train:  71%|███████▏  | 380/532 [12:50<05:44,  2.27s/it]Loading train:  72%|███████▏  | 381/532 [12:52<05:06,  2.03s/it]Loading train:  72%|███████▏  | 382/532 [12:53<04:33,  1.82s/it]Loading train:  72%|███████▏  | 383/532 [12:55<04:20,  1.75s/it]Loading train:  72%|███████▏  | 384/532 [12:57<04:27,  1.81s/it]Loading train:  72%|███████▏  | 385/532 [12:59<04:43,  1.93s/it]Loading train:  73%|███████▎  | 386/532 [13:01<04:56,  2.03s/it]Loading train:  73%|███████▎  | 387/532 [13:03<04:44,  1.96s/it]Loading train:  73%|███████▎  | 388/532 [13:05<04:42,  1.96s/it]Loading train:  73%|███████▎  | 389/532 [13:07<04:52,  2.05s/it]Loading train:  73%|███████▎  | 390/532 [13:10<04:57,  2.10s/it]Loading train:  73%|███████▎  | 391/532 [13:11<04:33,  1.94s/it]Loading train:  74%|███████▎  | 392/532 [13:13<04:14,  1.82s/it]Loading train:  74%|███████▍  | 393/532 [13:14<03:54,  1.68s/it]Loading train:  74%|███████▍  | 394/532 [13:16<04:05,  1.78s/it]Loading train:  74%|███████▍  | 395/532 [13:18<04:01,  1.76s/it]Loading train:  74%|███████▍  | 396/532 [13:20<04:15,  1.88s/it]Loading train:  75%|███████▍  | 397/532 [13:22<04:09,  1.85s/it]Loading train:  75%|███████▍  | 398/532 [13:23<03:49,  1.71s/it]Loading train:  75%|███████▌  | 399/532 [13:24<03:35,  1.62s/it]Loading train:  75%|███████▌  | 400/532 [13:26<03:30,  1.60s/it]Loading train:  75%|███████▌  | 401/532 [13:28<03:26,  1.58s/it]Loading train:  76%|███████▌  | 402/532 [13:29<03:22,  1.56s/it]Loading train:  76%|███████▌  | 403/532 [13:31<03:35,  1.67s/it]Loading train:  76%|███████▌  | 404/532 [13:33<03:42,  1.74s/it]Loading train:  76%|███████▌  | 405/532 [13:34<03:25,  1.62s/it]Loading train:  76%|███████▋  | 406/532 [13:36<03:14,  1.55s/it]Loading train:  77%|███████▋  | 407/532 [13:37<03:01,  1.45s/it]Loading train:  77%|███████▋  | 408/532 [13:38<02:57,  1.43s/it]Loading train:  77%|███████▋  | 409/532 [13:40<02:56,  1.44s/it]Loading train:  77%|███████▋  | 410/532 [13:41<02:56,  1.45s/it]Loading train:  77%|███████▋  | 411/532 [13:43<02:54,  1.44s/it]Loading train:  77%|███████▋  | 412/532 [13:44<03:03,  1.53s/it]Loading train:  78%|███████▊  | 413/532 [13:46<03:23,  1.71s/it]Loading train:  78%|███████▊  | 414/532 [13:48<03:13,  1.64s/it]Loading train:  78%|███████▊  | 415/532 [13:49<02:49,  1.45s/it]Loading train:  78%|███████▊  | 416/532 [13:50<02:34,  1.33s/it]Loading train:  78%|███████▊  | 417/532 [13:51<02:37,  1.37s/it]Loading train:  79%|███████▊  | 418/532 [13:53<02:38,  1.39s/it]Loading train:  79%|███████▉  | 419/532 [13:55<02:54,  1.55s/it]Loading train:  79%|███████▉  | 420/532 [13:56<02:40,  1.43s/it]Loading train:  79%|███████▉  | 421/532 [13:57<02:27,  1.33s/it]Loading train:  79%|███████▉  | 422/532 [13:58<02:21,  1.28s/it]Loading train:  80%|███████▉  | 423/532 [13:59<02:14,  1.23s/it]Loading train:  80%|███████▉  | 424/532 [14:00<02:08,  1.19s/it]Loading train:  80%|███████▉  | 425/532 [14:01<02:04,  1.16s/it]Loading train:  80%|████████  | 426/532 [14:03<01:59,  1.13s/it]Loading train:  80%|████████  | 427/532 [14:04<01:53,  1.08s/it]Loading train:  80%|████████  | 428/532 [14:05<01:51,  1.08s/it]Loading train:  81%|████████  | 429/532 [14:06<01:52,  1.09s/it]Loading train:  81%|████████  | 430/532 [14:07<01:51,  1.09s/it]Loading train:  81%|████████  | 431/532 [14:08<01:53,  1.13s/it]Loading train:  81%|████████  | 432/532 [14:09<01:52,  1.12s/it]Loading train:  81%|████████▏ | 433/532 [14:10<01:54,  1.16s/it]Loading train:  82%|████████▏ | 434/532 [14:12<01:53,  1.16s/it]Loading train:  82%|████████▏ | 435/532 [14:13<01:52,  1.16s/it]Loading train:  82%|████████▏ | 436/532 [14:14<01:51,  1.16s/it]Loading train:  82%|████████▏ | 437/532 [14:15<01:43,  1.09s/it]Loading train:  82%|████████▏ | 438/532 [14:16<01:38,  1.05s/it]Loading train:  83%|████████▎ | 439/532 [14:17<01:32,  1.01it/s]Loading train:  83%|████████▎ | 440/532 [14:18<01:31,  1.01it/s]Loading train:  83%|████████▎ | 441/532 [14:19<01:29,  1.01it/s]Loading train:  83%|████████▎ | 442/532 [14:19<01:25,  1.05it/s]Loading train:  83%|████████▎ | 443/532 [14:20<01:23,  1.07it/s]Loading train:  83%|████████▎ | 444/532 [14:21<01:22,  1.06it/s]Loading train:  84%|████████▎ | 445/532 [14:22<01:22,  1.05it/s]Loading train:  84%|████████▍ | 446/532 [14:24<01:30,  1.05s/it]Loading train:  84%|████████▍ | 447/532 [14:25<01:27,  1.03s/it]Loading train:  84%|████████▍ | 448/532 [14:25<01:23,  1.01it/s]Loading train:  84%|████████▍ | 449/532 [14:26<01:21,  1.01it/s]Loading train:  85%|████████▍ | 450/532 [14:27<01:19,  1.03it/s]Loading train:  85%|████████▍ | 451/532 [14:28<01:18,  1.04it/s]Loading train:  85%|████████▍ | 452/532 [14:29<01:17,  1.03it/s]Loading train:  85%|████████▌ | 453/532 [14:30<01:16,  1.04it/s]Loading train:  85%|████████▌ | 454/532 [14:31<01:14,  1.05it/s]Loading train:  86%|████████▌ | 455/532 [14:32<01:15,  1.01it/s]Loading train:  86%|████████▌ | 456/532 [14:33<01:18,  1.03s/it]Loading train:  86%|████████▌ | 457/532 [14:34<01:18,  1.04s/it]Loading train:  86%|████████▌ | 458/532 [14:35<01:15,  1.02s/it]Loading train:  86%|████████▋ | 459/532 [14:36<01:15,  1.03s/it]Loading train:  86%|████████▋ | 460/532 [14:38<01:15,  1.05s/it]Loading train:  87%|████████▋ | 461/532 [14:39<01:17,  1.10s/it]Loading train:  87%|████████▋ | 462/532 [14:40<01:17,  1.11s/it]Loading train:  87%|████████▋ | 463/532 [14:41<01:17,  1.12s/it]Loading train:  87%|████████▋ | 464/532 [14:42<01:15,  1.12s/it]Loading train:  87%|████████▋ | 465/532 [14:43<01:14,  1.11s/it]Loading train:  88%|████████▊ | 466/532 [14:44<01:15,  1.14s/it]Loading train:  88%|████████▊ | 467/532 [14:45<01:10,  1.08s/it]Loading train:  88%|████████▊ | 468/532 [14:46<01:07,  1.05s/it]Loading train:  88%|████████▊ | 469/532 [14:47<01:03,  1.01s/it]Loading train:  88%|████████▊ | 470/532 [14:48<01:00,  1.02it/s]Loading train:  89%|████████▊ | 471/532 [14:49<00:58,  1.05it/s]Loading train:  89%|████████▊ | 472/532 [14:50<00:56,  1.05it/s]Loading train:  89%|████████▉ | 473/532 [14:51<00:58,  1.01it/s]Loading train:  89%|████████▉ | 474/532 [14:52<00:58,  1.01s/it]Loading train:  89%|████████▉ | 475/532 [14:53<00:59,  1.05s/it]Loading train:  89%|████████▉ | 476/532 [14:54<00:58,  1.05s/it]Loading train:  90%|████████▉ | 477/532 [14:55<00:57,  1.05s/it]Loading train:  90%|████████▉ | 478/532 [14:56<00:56,  1.05s/it]Loading train:  90%|█████████ | 479/532 [14:57<00:54,  1.02s/it]Loading train:  90%|█████████ | 480/532 [14:58<00:51,  1.01it/s]Loading train:  90%|█████████ | 481/532 [14:59<00:49,  1.04it/s]Loading train:  91%|█████████ | 482/532 [15:00<00:47,  1.05it/s]Loading train:  91%|█████████ | 483/532 [15:01<00:48,  1.00it/s]Loading train:  91%|█████████ | 484/532 [15:02<00:47,  1.01it/s]Loading train:  91%|█████████ | 485/532 [15:03<00:48,  1.02s/it]Loading train:  91%|█████████▏| 486/532 [15:04<00:48,  1.05s/it]Loading train:  92%|█████████▏| 487/532 [15:06<00:47,  1.06s/it]Loading train:  92%|█████████▏| 488/532 [15:07<00:46,  1.06s/it]Loading train:  92%|█████████▏| 489/532 [15:08<00:47,  1.10s/it]Loading train:  92%|█████████▏| 490/532 [15:09<00:45,  1.09s/it]Loading train:  92%|█████████▏| 491/532 [15:10<00:42,  1.04s/it]Loading train:  92%|█████████▏| 492/532 [15:11<00:40,  1.01s/it]Loading train:  93%|█████████▎| 493/532 [15:12<00:38,  1.02it/s]Loading train:  93%|█████████▎| 494/532 [15:13<00:37,  1.03it/s]Loading train:  93%|█████████▎| 495/532 [15:14<00:36,  1.02it/s]Loading train:  93%|█████████▎| 496/532 [15:14<00:34,  1.06it/s]Loading train:  93%|█████████▎| 497/532 [15:15<00:34,  1.03it/s]Loading train:  94%|█████████▎| 498/532 [15:16<00:33,  1.02it/s]Loading train:  94%|█████████▍| 499/532 [15:17<00:32,  1.03it/s]Loading train:  94%|█████████▍| 500/532 [15:18<00:30,  1.04it/s]Loading train:  94%|█████████▍| 501/532 [15:19<00:30,  1.03it/s]Loading train:  94%|█████████▍| 502/532 [15:20<00:29,  1.03it/s]Loading train:  95%|█████████▍| 503/532 [15:21<00:27,  1.06it/s]Loading train:  95%|█████████▍| 504/532 [15:22<00:26,  1.06it/s]Loading train:  95%|█████████▍| 505/532 [15:23<00:25,  1.04it/s]Loading train:  95%|█████████▌| 506/532 [15:24<00:24,  1.06it/s]Loading train:  95%|█████████▌| 507/532 [15:25<00:23,  1.05it/s]Loading train:  95%|█████████▌| 508/532 [15:26<00:22,  1.07it/s]Loading train:  96%|█████████▌| 509/532 [15:27<00:22,  1.03it/s]Loading train:  96%|█████████▌| 510/532 [15:28<00:22,  1.01s/it]Loading train:  96%|█████████▌| 511/532 [15:29<00:21,  1.03s/it]Loading train:  96%|█████████▌| 512/532 [15:30<00:21,  1.07s/it]Loading train:  96%|█████████▋| 513/532 [15:31<00:20,  1.10s/it]Loading train:  97%|█████████▋| 514/532 [15:33<00:19,  1.10s/it]Loading train:  97%|█████████▋| 515/532 [15:34<00:18,  1.08s/it]Loading train:  97%|█████████▋| 516/532 [15:35<00:17,  1.07s/it]Loading train:  97%|█████████▋| 517/532 [15:36<00:15,  1.04s/it]Loading train:  97%|█████████▋| 518/532 [15:37<00:14,  1.02s/it]Loading train:  98%|█████████▊| 519/532 [15:38<00:13,  1.02s/it]Loading train:  98%|█████████▊| 520/532 [15:39<00:12,  1.01s/it]Loading train:  98%|█████████▊| 521/532 [15:40<00:11,  1.05s/it]Loading train:  98%|█████████▊| 522/532 [15:41<00:10,  1.07s/it]Loading train:  98%|█████████▊| 523/532 [15:42<00:09,  1.09s/it]Loading train:  98%|█████████▊| 524/532 [15:43<00:08,  1.09s/it]Loading train:  99%|█████████▊| 525/532 [15:44<00:07,  1.10s/it]Loading train:  99%|█████████▉| 526/532 [15:45<00:06,  1.11s/it]Loading train:  99%|█████████▉| 527/532 [15:46<00:05,  1.06s/it]Loading train:  99%|█████████▉| 528/532 [15:47<00:04,  1.04s/it]Loading train:  99%|█████████▉| 529/532 [15:48<00:03,  1.01s/it]Loading train: 100%|█████████▉| 530/532 [15:49<00:01,  1.02it/s]Loading train: 100%|█████████▉| 531/532 [15:50<00:00,  1.03it/s]Loading train: 100%|██████████| 532/532 [15:51<00:00,  1.06it/s]
concatenating: train:   0%|          | 0/532 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 10/532 [00:00<00:05, 98.72it/s]concatenating: train:   7%|▋         | 36/532 [00:00<00:04, 120.98it/s]concatenating: train:  12%|█▏        | 64/532 [00:00<00:03, 145.76it/s]concatenating: train:  17%|█▋        | 90/532 [00:00<00:02, 167.80it/s]concatenating: train:  21%|██▏       | 114/532 [00:00<00:02, 182.84it/s]concatenating: train:  26%|██▌       | 138/532 [00:00<00:02, 196.53it/s]concatenating: train:  31%|███       | 163/532 [00:00<00:01, 208.91it/s]concatenating: train:  35%|███▌      | 188/532 [00:00<00:01, 217.54it/s]concatenating: train:  40%|████      | 213/532 [00:00<00:01, 224.78it/s]concatenating: train:  45%|████▍     | 237/532 [00:01<00:01, 228.98it/s]concatenating: train:  49%|████▉     | 261/532 [00:01<00:01, 231.92it/s]concatenating: train:  54%|█████▎    | 285/532 [00:01<00:01, 232.85it/s]concatenating: train:  58%|█████▊    | 309/532 [00:01<00:00, 234.38it/s]concatenating: train:  63%|██████▎   | 334/532 [00:01<00:00, 236.44it/s]concatenating: train:  67%|██████▋   | 358/532 [00:01<00:00, 236.97it/s]concatenating: train:  72%|███████▏  | 383/532 [00:01<00:00, 238.05it/s]concatenating: train:  77%|███████▋  | 407/532 [00:01<00:00, 236.38it/s]concatenating: train:  81%|████████  | 432/532 [00:01<00:00, 237.98it/s]concatenating: train:  86%|████████▌ | 457/532 [00:01<00:00, 241.25it/s]concatenating: train:  91%|█████████ | 482/532 [00:02<00:00, 239.97it/s]concatenating: train:  95%|█████████▌| 508/532 [00:02<00:00, 243.05it/s]concatenating: train: 100%|██████████| 532/532 [00:02<00:00, 237.69it/s]
Loading test:   0%|          | 0/15 [00:00<?, ?it/s]Loading test:   7%|▋         | 1/15 [00:00<00:12,  1.10it/s]Loading test:  13%|█▎        | 2/15 [00:01<00:12,  1.04it/s]Loading test:  20%|██        | 3/15 [00:03<00:12,  1.01s/it]Loading test:  27%|██▋       | 4/15 [00:04<00:11,  1.03s/it]Loading test:  33%|███▎      | 5/15 [00:05<00:10,  1.09s/it]Loading test:  40%|████      | 6/15 [00:07<00:11,  1.33s/it]Loading test:  47%|████▋     | 7/15 [00:08<00:09,  1.21s/it]Loading test:  53%|█████▎    | 8/15 [00:09<00:08,  1.24s/it]Loading test:  60%|██████    | 9/15 [00:10<00:07,  1.19s/it]Loading test:  67%|██████▋   | 10/15 [00:11<00:05,  1.10s/it]Loading test:  73%|███████▎  | 11/15 [00:12<00:04,  1.06s/it]Loading test:  80%|████████  | 12/15 [00:13<00:03,  1.10s/it]Loading test:  87%|████████▋ | 13/15 [00:14<00:02,  1.12s/it]Loading test:  93%|█████████▎| 14/15 [00:15<00:01,  1.11s/it]Loading test: 100%|██████████| 15/15 [00:16<00:00,  1.10s/it]
concatenating: validation:   0%|          | 0/15 [00:00<?, ?it/s]concatenating: validation:  53%|█████▎    | 8/15 [00:00<00:00, 74.76it/s]concatenating: validation: 100%|██████████| 15/15 [00:00<00:00, 126.14it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 56, 56, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 56, 56, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 56, 56, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 56, 56, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 56, 56, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 56, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 56, 56, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 56, 56, 16)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 16)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28, 28, 16)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 28, 30)   4350        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 28, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 28, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 28, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 28, 28, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 28, 28, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 28, 46)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 46)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 14, 14, 46)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 14, 14, 60)   24900       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 14, 14, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 14, 14, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 14, 14, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 14, 14, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 14, 14, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 14, 14, 106)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 14, 14, 106)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 28, 28, 30)   12750       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 28, 28, 76)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 28, 28, 30)   20550       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 28, 28, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 28, 28, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 28, 28, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 28, 28, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 28, 28, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 28, 28, 106)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-06 23:46:42.214516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-06 23:46:42.214624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-06 23:46:42.214639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-06 23:46:42.214648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-06 23:46:42.215087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 28, 28, 106)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 56, 56, 15)   6375        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 56, 31)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 56, 56, 15)   4200        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 56, 56, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 56, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 56, 56, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 56, 56, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 56, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 56, 46)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 56, 56, 46)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 56, 56, 13)   611         dropout_5[0][0]                  
==================================================================================================
Total params: 127,886
Trainable params: 127,286
Non-trainable params: 600
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.53974061e-02 2.89048015e-02 1.16758472e-01 1.00223856e-02
 3.03440156e-02 5.80063118e-03 6.84518755e-02 1.28261328e-01
 7.55818021e-02 1.22545826e-02 2.73712232e-01 1.84335085e-01
 1.75382711e-04]
Train on 33496 samples, validate on 969 samples
Epoch 1/300
 - 30s - loss: 48.0647 - acc: 0.8060 - mDice: 0.0232 - val_loss: 3.6064 - val_acc: 0.9217 - val_mDice: 0.0380

Epoch 00001: val_mDice improved from -inf to 0.03800, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 21s - loss: 4.5855 - acc: 0.9056 - mDice: 0.0645 - val_loss: 2.8615 - val_acc: 0.9189 - val_mDice: 0.1000

Epoch 00002: val_mDice improved from 0.03800 to 0.09996, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 21s - loss: 3.4389 - acc: 0.9133 - mDice: 0.1353 - val_loss: 2.1160 - val_acc: 0.9305 - val_mDice: 0.2270

Epoch 00003: val_mDice improved from 0.09996 to 0.22696, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 22s - loss: 2.7007 - acc: 0.9245 - mDice: 0.2240 - val_loss: 1.6167 - val_acc: 0.9534 - val_mDice: 0.3775

Epoch 00004: val_mDice improved from 0.22696 to 0.37750, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 5/300
 - 21s - loss: 2.2097 - acc: 0.9361 - mDice: 0.3181 - val_loss: 1.3007 - val_acc: 0.9628 - val_mDice: 0.4728

Epoch 00005: val_mDice improved from 0.37750 to 0.47277, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 21s - loss: 1.9350 - acc: 0.9419 - mDice: 0.3798 - val_loss: 1.1167 - val_acc: 0.9698 - val_mDice: 0.5446

Epoch 00006: val_mDice improved from 0.47277 to 0.54464, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 7/300
 - 21s - loss: 1.7400 - acc: 0.9460 - mDice: 0.4280 - val_loss: 1.0223 - val_acc: 0.9725 - val_mDice: 0.5863

Epoch 00007: val_mDice improved from 0.54464 to 0.58634, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 8/300
 - 22s - loss: 1.5911 - acc: 0.9494 - mDice: 0.4669 - val_loss: 0.9485 - val_acc: 0.9741 - val_mDice: 0.6111

Epoch 00008: val_mDice improved from 0.58634 to 0.61114, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 9/300
 - 22s - loss: 1.4798 - acc: 0.9519 - mDice: 0.4980 - val_loss: 0.8872 - val_acc: 0.9752 - val_mDice: 0.6392

Epoch 00009: val_mDice improved from 0.61114 to 0.63923, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 10/300
 - 21s - loss: 1.3852 - acc: 0.9541 - mDice: 0.5242 - val_loss: 0.8408 - val_acc: 0.9757 - val_mDice: 0.6568

Epoch 00010: val_mDice improved from 0.63923 to 0.65676, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 11/300
 - 21s - loss: 1.3013 - acc: 0.9561 - mDice: 0.5498 - val_loss: 0.8307 - val_acc: 0.9765 - val_mDice: 0.6706

Epoch 00011: val_mDice improved from 0.65676 to 0.67056, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 12/300
 - 21s - loss: 1.2263 - acc: 0.9577 - mDice: 0.5725 - val_loss: 0.7939 - val_acc: 0.9770 - val_mDice: 0.6857

Epoch 00012: val_mDice improved from 0.67056 to 0.68572, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 13/300
 - 22s - loss: 1.1648 - acc: 0.9590 - mDice: 0.5900 - val_loss: 0.7860 - val_acc: 0.9773 - val_mDice: 0.6900

Epoch 00013: val_mDice improved from 0.68572 to 0.68995, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 14/300
 - 21s - loss: 1.1172 - acc: 0.9601 - mDice: 0.6044 - val_loss: 0.7743 - val_acc: 0.9777 - val_mDice: 0.6984

Epoch 00014: val_mDice improved from 0.68995 to 0.69845, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 15/300
 - 21s - loss: 1.0838 - acc: 0.9608 - mDice: 0.6149 - val_loss: 0.7791 - val_acc: 0.9775 - val_mDice: 0.6983

Epoch 00015: val_mDice did not improve from 0.69845
Epoch 16/300
 - 21s - loss: 1.0520 - acc: 0.9614 - mDice: 0.6260 - val_loss: 0.7488 - val_acc: 0.9776 - val_mDice: 0.7077

Epoch 00016: val_mDice improved from 0.69845 to 0.70768, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 17/300
 - 22s - loss: 1.0194 - acc: 0.9622 - mDice: 0.6364 - val_loss: 0.7348 - val_acc: 0.9778 - val_mDice: 0.7146

Epoch 00017: val_mDice improved from 0.70768 to 0.71456, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 18/300
 - 21s - loss: 0.9975 - acc: 0.9627 - mDice: 0.6433 - val_loss: 0.7176 - val_acc: 0.9782 - val_mDice: 0.7164

Epoch 00018: val_mDice improved from 0.71456 to 0.71635, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 19/300
 - 21s - loss: 0.9760 - acc: 0.9632 - mDice: 0.6503 - val_loss: 0.7341 - val_acc: 0.9771 - val_mDice: 0.7143

Epoch 00019: val_mDice did not improve from 0.71635
Epoch 20/300
 - 21s - loss: 0.9537 - acc: 0.9636 - mDice: 0.6585 - val_loss: 0.7028 - val_acc: 0.9790 - val_mDice: 0.7263

Epoch 00020: val_mDice improved from 0.71635 to 0.72633, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 21/300
 - 21s - loss: 0.9373 - acc: 0.9640 - mDice: 0.6637 - val_loss: 0.7125 - val_acc: 0.9792 - val_mDice: 0.7274

Epoch 00021: val_mDice improved from 0.72633 to 0.72736, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 22/300
 - 22s - loss: 0.9182 - acc: 0.9643 - mDice: 0.6698 - val_loss: 0.7063 - val_acc: 0.9787 - val_mDice: 0.7268

Epoch 00022: val_mDice did not improve from 0.72736
Epoch 23/300
 - 21s - loss: 0.8999 - acc: 0.9646 - mDice: 0.6764 - val_loss: 0.7031 - val_acc: 0.9789 - val_mDice: 0.7267

Epoch 00023: val_mDice did not improve from 0.72736
Epoch 24/300
 - 21s - loss: 0.8849 - acc: 0.9650 - mDice: 0.6814 - val_loss: 0.6967 - val_acc: 0.9795 - val_mDice: 0.7322

Epoch 00024: val_mDice improved from 0.72736 to 0.73222, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 25/300
 - 21s - loss: 0.8733 - acc: 0.9652 - mDice: 0.6852 - val_loss: 0.6975 - val_acc: 0.9797 - val_mDice: 0.7317

Epoch 00025: val_mDice did not improve from 0.73222
Epoch 26/300
 - 22s - loss: 0.8609 - acc: 0.9655 - mDice: 0.6894 - val_loss: 0.6905 - val_acc: 0.9796 - val_mDice: 0.7365

Epoch 00026: val_mDice improved from 0.73222 to 0.73653, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 27/300
 - 22s - loss: 0.8527 - acc: 0.9657 - mDice: 0.6921 - val_loss: 0.6719 - val_acc: 0.9801 - val_mDice: 0.7424

Epoch 00027: val_mDice improved from 0.73653 to 0.74237, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 28/300
 - 21s - loss: 0.8416 - acc: 0.9659 - mDice: 0.6959 - val_loss: 0.6848 - val_acc: 0.9791 - val_mDice: 0.7393

Epoch 00028: val_mDice did not improve from 0.74237
Epoch 29/300
 - 21s - loss: 0.8319 - acc: 0.9660 - mDice: 0.6992 - val_loss: 0.6796 - val_acc: 0.9794 - val_mDice: 0.7380

Epoch 00029: val_mDice did not improve from 0.74237
Epoch 30/300
 - 21s - loss: 0.8278 - acc: 0.9662 - mDice: 0.7003 - val_loss: 0.6821 - val_acc: 0.9798 - val_mDice: 0.7412

Epoch 00030: val_mDice did not improve from 0.74237
Epoch 31/300
 - 22s - loss: 0.8192 - acc: 0.9664 - mDice: 0.7030 - val_loss: 0.6706 - val_acc: 0.9794 - val_mDice: 0.7429

Epoch 00031: val_mDice improved from 0.74237 to 0.74289, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 32/300
 - 21s - loss: 0.8110 - acc: 0.9666 - mDice: 0.7061 - val_loss: 0.6622 - val_acc: 0.9799 - val_mDice: 0.7426

Epoch 00032: val_mDice did not improve from 0.74289
Epoch 33/300
 - 21s - loss: 0.8056 - acc: 0.9667 - mDice: 0.7076 - val_loss: 0.6658 - val_acc: 0.9799 - val_mDice: 0.7454

Epoch 00033: val_mDice improved from 0.74289 to 0.74536, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 34/300
 - 21s - loss: 0.7978 - acc: 0.9668 - mDice: 0.7102 - val_loss: 0.6672 - val_acc: 0.9800 - val_mDice: 0.7446

Epoch 00034: val_mDice did not improve from 0.74536
Epoch 35/300
 - 22s - loss: 0.7904 - acc: 0.9670 - mDice: 0.7129 - val_loss: 0.6668 - val_acc: 0.9797 - val_mDice: 0.7455

Epoch 00035: val_mDice improved from 0.74536 to 0.74551, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 36/300
 - 22s - loss: 0.7849 - acc: 0.9671 - mDice: 0.7149 - val_loss: 0.6839 - val_acc: 0.9795 - val_mDice: 0.7406

Epoch 00036: val_mDice did not improve from 0.74551
Epoch 37/300
 - 21s - loss: 0.7824 - acc: 0.9672 - mDice: 0.7154 - val_loss: 0.6725 - val_acc: 0.9803 - val_mDice: 0.7480

Epoch 00037: val_mDice improved from 0.74551 to 0.74796, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 38/300
 - 21s - loss: 0.7789 - acc: 0.9673 - mDice: 0.7166 - val_loss: 0.6766 - val_acc: 0.9807 - val_mDice: 0.7435

Epoch 00038: val_mDice did not improve from 0.74796
Epoch 39/300
 - 21s - loss: 0.7750 - acc: 0.9674 - mDice: 0.7180 - val_loss: 0.6643 - val_acc: 0.9805 - val_mDice: 0.7435

Epoch 00039: val_mDice did not improve from 0.74796
Epoch 40/300
 - 22s - loss: 0.7705 - acc: 0.9675 - mDice: 0.7195 - val_loss: 0.6571 - val_acc: 0.9803 - val_mDice: 0.7474

Epoch 00040: val_mDice did not improve from 0.74796
Epoch 41/300
 - 21s - loss: 0.7641 - acc: 0.9675 - mDice: 0.7216 - val_loss: 0.6657 - val_acc: 0.9801 - val_mDice: 0.7481

Epoch 00041: val_mDice improved from 0.74796 to 0.74811, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 42/300
 - 21s - loss: 0.7630 - acc: 0.9676 - mDice: 0.7218 - val_loss: 0.6546 - val_acc: 0.9806 - val_mDice: 0.7494

Epoch 00042: val_mDice improved from 0.74811 to 0.74937, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 43/300
 - 21s - loss: 0.7587 - acc: 0.9676 - mDice: 0.7232 - val_loss: 0.6547 - val_acc: 0.9809 - val_mDice: 0.7509

Epoch 00043: val_mDice improved from 0.74937 to 0.75093, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 44/300
 - 22s - loss: 0.7568 - acc: 0.9677 - mDice: 0.7238 - val_loss: 0.6415 - val_acc: 0.9804 - val_mDice: 0.7516

Epoch 00044: val_mDice improved from 0.75093 to 0.75164, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 45/300
 - 22s - loss: 0.7506 - acc: 0.9678 - mDice: 0.7263 - val_loss: 0.6495 - val_acc: 0.9807 - val_mDice: 0.7499

Epoch 00045: val_mDice did not improve from 0.75164
Epoch 46/300
 - 21s - loss: 0.7487 - acc: 0.9679 - mDice: 0.7264 - val_loss: 0.6495 - val_acc: 0.9805 - val_mDice: 0.7482

Epoch 00046: val_mDice did not improve from 0.75164
Epoch 47/300
 - 21s - loss: 0.7447 - acc: 0.9680 - mDice: 0.7282 - val_loss: 0.6717 - val_acc: 0.9805 - val_mDice: 0.7433

Epoch 00047: val_mDice did not improve from 0.75164
Epoch 48/300
 - 24s - loss: 0.7440 - acc: 0.9680 - mDice: 0.7281 - val_loss: 0.6442 - val_acc: 0.9811 - val_mDice: 0.7554

Epoch 00048: val_mDice improved from 0.75164 to 0.75539, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 49/300
 - 21s - loss: 0.7405 - acc: 0.9681 - mDice: 0.7295 - val_loss: 0.6448 - val_acc: 0.9803 - val_mDice: 0.7540

Epoch 00049: val_mDice did not improve from 0.75539
Epoch 50/300
 - 21s - loss: 0.7375 - acc: 0.9681 - mDice: 0.7306 - val_loss: 0.6457 - val_acc: 0.9805 - val_mDice: 0.7479

Epoch 00050: val_mDice did not improve from 0.75539
Epoch 51/300
 - 22s - loss: 0.7355 - acc: 0.9681 - mDice: 0.7308 - val_loss: 0.6547 - val_acc: 0.9809 - val_mDice: 0.7511

Epoch 00051: val_mDice did not improve from 0.75539
Epoch 52/300
 - 22s - loss: 0.7324 - acc: 0.9682 - mDice: 0.7323 - val_loss: 0.6543 - val_acc: 0.9810 - val_mDice: 0.7487

Epoch 00052: val_mDice did not improve from 0.75539
Epoch 53/300
 - 22s - loss: 0.7311 - acc: 0.9682 - mDice: 0.7323 - val_loss: 0.6581 - val_acc: 0.9801 - val_mDice: 0.7478

Epoch 00053: val_mDice did not improve from 0.75539
Epoch 54/300
 - 22s - loss: 0.7267 - acc: 0.9683 - mDice: 0.7339 - val_loss: 0.6460 - val_acc: 0.9813 - val_mDice: 0.7534

Epoch 00054: val_mDice did not improve from 0.75539
Epoch 55/300
 - 23s - loss: 0.7259 - acc: 0.9683 - mDice: 0.7342 - val_loss: 0.6392 - val_acc: 0.9812 - val_mDice: 0.7517

Epoch 00055: val_mDice did not improve from 0.75539
Epoch 56/300
 - 22s - loss: 0.7248 - acc: 0.9684 - mDice: 0.7347 - val_loss: 0.6385 - val_acc: 0.9810 - val_mDice: 0.7569

Epoch 00056: val_mDice improved from 0.75539 to 0.75687, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 57/300
 - 22s - loss: 0.7227 - acc: 0.9684 - mDice: 0.7355 - val_loss: 0.6488 - val_acc: 0.9805 - val_mDice: 0.7539

Epoch 00057: val_mDice did not improve from 0.75687
Epoch 58/300
 - 23s - loss: 0.7192 - acc: 0.9684 - mDice: 0.7366 - val_loss: 0.6412 - val_acc: 0.9812 - val_mDice: 0.7520

Epoch 00058: val_mDice did not improve from 0.75687
Epoch 59/300
 - 22s - loss: 0.7196 - acc: 0.9685 - mDice: 0.7365 - val_loss: 0.6469 - val_acc: 0.9808 - val_mDice: 0.7497

Epoch 00059: val_mDice did not improve from 0.75687
Epoch 60/300
 - 23s - loss: 0.7184 - acc: 0.9685 - mDice: 0.7371 - val_loss: 0.6469 - val_acc: 0.9804 - val_mDice: 0.7515

Epoch 00060: val_mDice did not improve from 0.75687
Epoch 61/300
 - 23s - loss: 0.7173 - acc: 0.9685 - mDice: 0.7373 - val_loss: 0.6405 - val_acc: 0.9804 - val_mDice: 0.7538

Epoch 00061: val_mDice did not improve from 0.75687
Epoch 62/300
 - 22s - loss: 0.7118 - acc: 0.9686 - mDice: 0.7394 - val_loss: 0.6559 - val_acc: 0.9803 - val_mDice: 0.7496

Epoch 00062: val_mDice did not improve from 0.75687
Epoch 63/300
 - 23s - loss: 0.7117 - acc: 0.9687 - mDice: 0.7393 - val_loss: 0.6546 - val_acc: 0.9812 - val_mDice: 0.7501

Epoch 00063: val_mDice did not improve from 0.75687
Epoch 64/300
 - 21s - loss: 0.7109 - acc: 0.9687 - mDice: 0.7395 - val_loss: 0.6478 - val_acc: 0.9808 - val_mDice: 0.7510

Epoch 00064: val_mDice did not improve from 0.75687
Epoch 65/300
 - 23s - loss: 0.7111 - acc: 0.9687 - mDice: 0.7398 - val_loss: 0.6399 - val_acc: 0.9808 - val_mDice: 0.7553

Epoch 00065: val_mDice did not improve from 0.75687
Epoch 66/300
 - 22s - loss: 0.7074 - acc: 0.9687 - mDice: 0.7409 - val_loss: 0.6330 - val_acc: 0.9812 - val_mDice: 0.7560

Epoch 00066: val_mDice did not improve from 0.75687
Epoch 67/300
 - 22s - loss: 0.7066 - acc: 0.9687 - mDice: 0.7408 - val_loss: 0.6424 - val_acc: 0.9815 - val_mDice: 0.7525

Epoch 00067: val_mDice did not improve from 0.75687
Epoch 68/300
 - 23s - loss: 0.7047 - acc: 0.9688 - mDice: 0.7416 - val_loss: 0.6484 - val_acc: 0.9814 - val_mDice: 0.7524

Epoch 00068: val_mDice did not improve from 0.75687
Epoch 69/300
 - 22s - loss: 0.7025 - acc: 0.9689 - mDice: 0.7425 - val_loss: 0.6498 - val_acc: 0.9806 - val_mDice: 0.7556

Epoch 00069: val_mDice did not improve from 0.75687
Epoch 70/300
 - 22s - loss: 0.7023 - acc: 0.9688 - mDice: 0.7423 - val_loss: 0.6473 - val_acc: 0.9808 - val_mDice: 0.7534

Epoch 00070: val_mDice did not improve from 0.75687
Epoch 71/300
 - 22s - loss: 0.7027 - acc: 0.9689 - mDice: 0.7423 - val_loss: 0.6571 - val_acc: 0.9810 - val_mDice: 0.7546

Epoch 00071: val_mDice did not improve from 0.75687
Epoch 72/300
 - 21s - loss: 0.7002 - acc: 0.9689 - mDice: 0.7431 - val_loss: 0.6392 - val_acc: 0.9812 - val_mDice: 0.7522

Epoch 00072: val_mDice did not improve from 0.75687
Epoch 73/300
 - 23s - loss: 0.6986 - acc: 0.9690 - mDice: 0.7439 - val_loss: 0.6362 - val_acc: 0.9815 - val_mDice: 0.7568

Epoch 00073: val_mDice did not improve from 0.75687
Epoch 74/300
 - 24s - loss: 0.6957 - acc: 0.9690 - mDice: 0.7447 - val_loss: 0.6349 - val_acc: 0.9810 - val_mDice: 0.7591

Epoch 00074: val_mDice improved from 0.75687 to 0.75914, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 75/300
 - 24s - loss: 0.6943 - acc: 0.9690 - mDice: 0.7456 - val_loss: 0.6328 - val_acc: 0.9810 - val_mDice: 0.7584

Epoch 00075: val_mDice did not improve from 0.75914
Epoch 76/300
 - 25s - loss: 0.6940 - acc: 0.9690 - mDice: 0.7455 - val_loss: 0.6337 - val_acc: 0.9816 - val_mDice: 0.7574

Epoch 00076: val_mDice did not improve from 0.75914
Epoch 77/300
 - 24s - loss: 0.6935 - acc: 0.9690 - mDice: 0.7455 - val_loss: 0.6335 - val_acc: 0.9811 - val_mDice: 0.7612

Epoch 00077: val_mDice improved from 0.75914 to 0.76122, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 78/300
 - 24s - loss: 0.6923 - acc: 0.9691 - mDice: 0.7458 - val_loss: 0.6501 - val_acc: 0.9810 - val_mDice: 0.7519

Epoch 00078: val_mDice did not improve from 0.76122
Epoch 79/300
 - 24s - loss: 0.6908 - acc: 0.9691 - mDice: 0.7464 - val_loss: 0.6314 - val_acc: 0.9812 - val_mDice: 0.7588

Epoch 00079: val_mDice did not improve from 0.76122
Epoch 80/300
 - 25s - loss: 0.6892 - acc: 0.9691 - mDice: 0.7471 - val_loss: 0.6308 - val_acc: 0.9818 - val_mDice: 0.7574

Epoch 00080: val_mDice did not improve from 0.76122
Epoch 81/300
 - 25s - loss: 0.6885 - acc: 0.9691 - mDice: 0.7475 - val_loss: 0.6373 - val_acc: 0.9815 - val_mDice: 0.7560

Epoch 00081: val_mDice did not improve from 0.76122
Epoch 82/300
 - 24s - loss: 0.6868 - acc: 0.9691 - mDice: 0.7479 - val_loss: 0.6253 - val_acc: 0.9813 - val_mDice: 0.7574

Epoch 00082: val_mDice did not improve from 0.76122
Epoch 83/300
 - 23s - loss: 0.6863 - acc: 0.9692 - mDice: 0.7480 - val_loss: 0.6332 - val_acc: 0.9810 - val_mDice: 0.7553

Epoch 00083: val_mDice did not improve from 0.76122
Epoch 84/300
 - 24s - loss: 0.6857 - acc: 0.9692 - mDice: 0.7482 - val_loss: 0.6367 - val_acc: 0.9813 - val_mDice: 0.7611

Epoch 00084: val_mDice did not improve from 0.76122
Epoch 85/300
 - 21s - loss: 0.6844 - acc: 0.9692 - mDice: 0.7488 - val_loss: 0.6336 - val_acc: 0.9815 - val_mDice: 0.7571

Epoch 00085: val_mDice did not improve from 0.76122
Epoch 86/300
 - 22s - loss: 0.6844 - acc: 0.9692 - mDice: 0.7485 - val_loss: 0.6341 - val_acc: 0.9816 - val_mDice: 0.7584

Epoch 00086: val_mDice did not improve from 0.76122
Epoch 87/300
 - 22s - loss: 0.6827 - acc: 0.9693 - mDice: 0.7493 - val_loss: 0.6289 - val_acc: 0.9815 - val_mDice: 0.7587

Epoch 00087: val_mDice did not improve from 0.76122
Epoch 88/300
 - 21s - loss: 0.6827 - acc: 0.9693 - mDice: 0.7494 - val_loss: 0.6317 - val_acc: 0.9815 - val_mDice: 0.7577

Epoch 00088: val_mDice did not improve from 0.76122
Epoch 89/300
 - 21s - loss: 0.6824 - acc: 0.9693 - mDice: 0.7495 - val_loss: 0.6452 - val_acc: 0.9809 - val_mDice: 0.7586

Epoch 00089: val_mDice did not improve from 0.76122
Epoch 90/300
 - 22s - loss: 0.6812 - acc: 0.9693 - mDice: 0.7498 - val_loss: 0.6312 - val_acc: 0.9814 - val_mDice: 0.7556

Epoch 00090: val_mDice did not improve from 0.76122
Epoch 91/300
 - 21s - loss: 0.6790 - acc: 0.9694 - mDice: 0.7505 - val_loss: 0.6309 - val_acc: 0.9820 - val_mDice: 0.7593

Epoch 00091: val_mDice did not improve from 0.76122
Epoch 92/300
 - 21s - loss: 0.6793 - acc: 0.9694 - mDice: 0.7503 - val_loss: 0.6453 - val_acc: 0.9807 - val_mDice: 0.7587

Epoch 00092: val_mDice did not improve from 0.76122
Epoch 93/300
 - 21s - loss: 0.6786 - acc: 0.9694 - mDice: 0.7508 - val_loss: 0.6445 - val_acc: 0.9809 - val_mDice: 0.7579

Epoch 00093: val_mDice did not improve from 0.76122
Epoch 94/300
 - 22s - loss: 0.6777 - acc: 0.9693 - mDice: 0.7509 - val_loss: 0.6311 - val_acc: 0.9820 - val_mDice: 0.7559

Epoch 00094: val_mDice did not improve from 0.76122
Epoch 95/300
 - 21s - loss: 0.6755 - acc: 0.9694 - mDice: 0.7518 - val_loss: 0.6412 - val_acc: 0.9817 - val_mDice: 0.7586

Epoch 00095: val_mDice did not improve from 0.76122
Epoch 96/300
 - 21s - loss: 0.6759 - acc: 0.9694 - mDice: 0.7514 - val_loss: 0.6440 - val_acc: 0.9813 - val_mDice: 0.7590

Epoch 00096: val_mDice did not improve from 0.76122
Epoch 97/300
 - 21s - loss: 0.6744 - acc: 0.9695 - mDice: 0.7520 - val_loss: 0.6295 - val_acc: 0.9816 - val_mDice: 0.7601

Epoch 00097: val_mDice did not improve from 0.76122
Epoch 98/300
 - 22s - loss: 0.6736 - acc: 0.9695 - mDice: 0.7524 - val_loss: 0.6435 - val_acc: 0.9809 - val_mDice: 0.7572

Epoch 00098: val_mDice did not improve from 0.76122
Epoch 99/300
 - 22s - loss: 0.6752 - acc: 0.9694 - mDice: 0.7519 - val_loss: 0.6303 - val_acc: 0.9815 - val_mDice: 0.7581

Epoch 00099: val_mDice did not improve from 0.76122
Epoch 100/300
 - 21s - loss: 0.6734 - acc: 0.9695 - mDice: 0.7525 - val_loss: 0.6377 - val_acc: 0.9815 - val_mDice: 0.7567

Epoch 00100: val_mDice did not improve from 0.76122
Epoch 101/300
 - 21s - loss: 0.6708 - acc: 0.9695 - mDice: 0.7535 - val_loss: 0.6478 - val_acc: 0.9806 - val_mDice: 0.7570

Epoch 00101: val_mDice did not improve from 0.76122
Epoch 102/300
 - 21s - loss: 0.6730 - acc: 0.9695 - mDice: 0.7525 - val_loss: 0.6364 - val_acc: 0.9817 - val_mDice: 0.7596

Epoch 00102: val_mDice did not improve from 0.76122
Epoch 103/300
 - 22s - loss: 0.6716 - acc: 0.9696 - mDice: 0.7532 - val_loss: 0.6280 - val_acc: 0.9816 - val_mDice: 0.7560

Epoch 00103: val_mDice did not improve from 0.76122
Epoch 104/300
 - 21s - loss: 0.6708 - acc: 0.9696 - mDice: 0.7534 - val_loss: 0.6361 - val_acc: 0.9819 - val_mDice: 0.7584

Epoch 00104: val_mDice did not improve from 0.76122
Epoch 105/300
 - 21s - loss: 0.6699 - acc: 0.9695 - mDice: 0.7538 - val_loss: 0.6404 - val_acc: 0.9812 - val_mDice: 0.7597

Epoch 00105: val_mDice did not improve from 0.76122
Epoch 106/300
 - 21s - loss: 0.6708 - acc: 0.9695 - mDice: 0.7536 - val_loss: 0.6276 - val_acc: 0.9816 - val_mDice: 0.7582

Epoch 00106: val_mDice did not improve from 0.76122
Epoch 107/300
 - 21s - loss: 0.6680 - acc: 0.9696 - mDice: 0.7543 - val_loss: 0.6311 - val_acc: 0.9818 - val_mDice: 0.7595

Epoch 00107: val_mDice did not improve from 0.76122
Restoring model weights from the end of the best epoch
Epoch 00107: early stopping
{'val_loss': [3.606372002600639, 2.861461086292877, 2.115966929247751, 1.6167068618000846, 1.3007426666647535, 1.116737120660835, 1.0223112918890174, 0.9485436371605462, 0.8872235026767995, 0.8408478997317138, 0.830663870301163, 0.7939059456004939, 0.7860248715023753, 0.7742658061877862, 0.7791151718089455, 0.7487722357852294, 0.7348357479331171, 0.7176096767217874, 0.7341013115872047, 0.7027984751759422, 0.7125356144149729, 0.7063299999702087, 0.703122478643561, 0.6966680805934103, 0.6975185482679137, 0.6905361806399067, 0.6718591051512581, 0.6848427683760876, 0.67959458167954, 0.6820846358381435, 0.6706400209167055, 0.6622167613791731, 0.6657927074422532, 0.6671541766547074, 0.6668342518917179, 0.6838810988870075, 0.6724936983656711, 0.6765968210925997, 0.6642607209667701, 0.6571047835982375, 0.6657397746117122, 0.6546436240675526, 0.6546722482293998, 0.6414949236393467, 0.6495135231529842, 0.649492228178786, 0.6716671671537668, 0.6442191902205917, 0.6448342498426467, 0.6457072340482529, 0.6546527292767791, 0.6542889818749068, 0.6580975715712989, 0.6459513583419493, 0.6391581749337869, 0.6384723381791937, 0.6488483391002482, 0.6412300450883045, 0.6468971597090348, 0.6468584175203361, 0.6405248653654959, 0.6558598338388929, 0.6546206853830162, 0.6477626534130797, 0.6399434092305639, 0.632987410998812, 0.6423699911164794, 0.6483500084087207, 0.6498180026240393, 0.6473483963339937, 0.657115311014886, 0.6392312960235942, 0.6362191907392567, 0.6349102944227933, 0.632796777475729, 0.6337184825425792, 0.6334720126000474, 0.6500590925861315, 0.6313768408738915, 0.6308484818359646, 0.6373122578680945, 0.6253325135530702, 0.6332397897976717, 0.6367343361840283, 0.6335662246611589, 0.6340576406910446, 0.6289243784236219, 0.6316602472427336, 0.6452359966203278, 0.6311506513040993, 0.6308738078126228, 0.64527257215866, 0.6444740842862517, 0.6310567749727621, 0.6411660766946027, 0.6439779699156282, 0.6294636588901189, 0.6435073896765832, 0.6302600690270356, 0.6376980994938574, 0.6478338150540126, 0.6363688032878073, 0.6280365877537781, 0.6361211186161474, 0.6403891543547312, 0.6275629321242019, 0.6311422078971154], 'val_acc': [0.9217147453773624, 0.9189277754479518, 0.9305488686812552, 0.9533579855757478, 0.9628486216867918, 0.9697836283190701, 0.9725383630847045, 0.9740932466937047, 0.9751746004949045, 0.9757333794614479, 0.9764711787334045, 0.9769710493653674, 0.9772721518550003, 0.9776683669956353, 0.9774666461167074, 0.9775591165411706, 0.9778493606515221, 0.9781596735658046, 0.9771227653919727, 0.9789915967528912, 0.9792328128750726, 0.9786608774595585, 0.9788839876713276, 0.9794582401020732, 0.9797438720800559, 0.97956124000382, 0.9800788731889951, 0.979096908072323, 0.9794101957443205, 0.9797827032451413, 0.979416762835224, 0.9798830772208971, 0.9799383643733951, 0.9800334602317574, 0.9797283980622503, 0.9794957503076678, 0.9802552643698189, 0.9807041243133899, 0.9804967940776341, 0.9802509820621204, 0.9801078251148772, 0.9806185680277207, 0.9809038752249766, 0.9804359294927772, 0.9806725361275845, 0.9804599506567138, 0.9805073377025632, 0.981105930787983, 0.9802980361462131, 0.980464545811908, 0.9808568180653087, 0.9810302469137406, 0.980133500323084, 0.9812708038786739, 0.9812398679608285, 0.9809835178564208, 0.9805079985206219, 0.9812313107268114, 0.9808439755710409, 0.9803681275177789, 0.9804000472505764, 0.9802891572685557, 0.981190512792983, 0.9807613820483441, 0.9807557838250978, 0.9812230804264238, 0.9815209019540879, 0.9813619561116639, 0.9806050693902684, 0.9807505201629072, 0.9809578451701854, 0.9811622053846117, 0.9815488661282817, 0.9810368236619499, 0.981029259961702, 0.9816110711102638, 0.981125015776962, 0.9810081941793578, 0.9811756976248679, 0.9817709926481217, 0.9815370223962608, 0.9813372649644551, 0.9809571897036274, 0.9813323402921482, 0.9815090449355827, 0.9815916442403606, 0.9815080594598201, 0.9814761441558507, 0.9808686574300131, 0.9814103278336264, 0.9819681135739582, 0.9807149829387173, 0.9809147429540062, 0.981989507766208, 0.9817203199654295, 0.981335298564781, 0.9815580840573346, 0.9808772222299448, 0.9815406432092744, 0.9814531131425509, 0.9806386422446638, 0.98171078709749, 0.9816373961874821, 0.9818996717563232, 0.9811855678833921, 0.9816308054761621, 0.9818101626185564], 'val_mDice': [0.038000678057302756, 0.09996465008448276, 0.22695668163191302, 0.3774953606635547, 0.47277108865133627, 0.5446405827199465, 0.5863411106684383, 0.6111427731927335, 0.6392274151399532, 0.6567566767565606, 0.670564614090265, 0.685723555653949, 0.6899538184713161, 0.6984452680906644, 0.6982567683708065, 0.7076776662478137, 0.7145593142976948, 0.7163544172965091, 0.7142694402405352, 0.7263281349058122, 0.7273605726082628, 0.7267575541393921, 0.7266844850575592, 0.7322171920347263, 0.7317275105369103, 0.7365316788601556, 0.7423703249147925, 0.7392929180979851, 0.7380048979546633, 0.7411666970750004, 0.7428893705885723, 0.7426346279642284, 0.7453633015984967, 0.7445682892489359, 0.7455093254737932, 0.7406172390692743, 0.7479578520491397, 0.7435282644103555, 0.7434762648630684, 0.7473593143855825, 0.7481088164667103, 0.7493668009745201, 0.7509329364518755, 0.7516430059084582, 0.7499008695407549, 0.7482381523332113, 0.7432580518279651, 0.7553865970472803, 0.7539887436895302, 0.7479116353211142, 0.7511357995378712, 0.7487024655037005, 0.7478190145010304, 0.753425865596539, 0.7517307160808575, 0.7568704333344726, 0.7538799657664186, 0.7520318410221883, 0.7496892334383953, 0.7514680783938082, 0.75383633750388, 0.7495896484091555, 0.7500671748652423, 0.7509554516297253, 0.7553062322708106, 0.7560426538696722, 0.7525489441012451, 0.7523769635411116, 0.7556317417245162, 0.7534314098741987, 0.7546200188197834, 0.7522261486580005, 0.7568337201334006, 0.7591385134602479, 0.7584366107011604, 0.7573768614000335, 0.7612198380862966, 0.7518791972176087, 0.7588389706562424, 0.7574076747869682, 0.7559951640381041, 0.7574083361586305, 0.755303677329092, 0.7611058008067995, 0.7570922371649766, 0.7584200102232312, 0.758681756793161, 0.7576552981931728, 0.7586176247173542, 0.755572729620033, 0.7592892326314629, 0.75865839017311, 0.7579114502920578, 0.7558697910500753, 0.7585672093987834, 0.7589658897973681, 0.7600945218305716, 0.757184016323188, 0.7581300805596745, 0.7567402850855738, 0.7570469684522095, 0.7595545644607583, 0.7559710395348453, 0.7583624312137056, 0.7597486435813431, 0.7582339245837539, 0.759541717968243], 'loss': [48.06472372097647, 4.58550228940464, 3.4388641837618645, 2.700732522785792, 2.209692079354107, 1.9349655315532643, 1.740040583871901, 1.5911314565041539, 1.479755162509438, 1.3852253023126628, 1.301294878869003, 1.2262959520501342, 1.1647903712731942, 1.117180363870561, 1.0838452500077858, 1.0520178200252193, 1.019351360847422, 0.997519619842973, 0.9760251588957504, 0.953715640554173, 0.9372904334712888, 0.9182177536422664, 0.8999389712099304, 0.8848550865822143, 0.8733381845799043, 0.8609430040013741, 0.8526754223178615, 0.8415899659956957, 0.8318745915548654, 0.827816777584346, 0.819201386292339, 0.8109784824041868, 0.80559206414627, 0.797770824791396, 0.790410004098859, 0.7848764355395613, 0.782384609262158, 0.7789090303025725, 0.7749597231926655, 0.7704838662876956, 0.7640805328364927, 0.7629836228146085, 0.7587351383259224, 0.7568364824048938, 0.7506413949626369, 0.748721309833661, 0.7446587803485087, 0.7439889521125623, 0.7405266409091685, 0.7374808033098604, 0.7355286949270803, 0.7324114488208667, 0.7311294207090064, 0.7267312178940314, 0.7259313495340796, 0.7247680654980159, 0.7227232380758358, 0.719238281613009, 0.7196017199237961, 0.7183967601692076, 0.717275041461361, 0.711778029931141, 0.7116803056888544, 0.7108641712113785, 0.711057100477952, 0.7073644280134707, 0.7065519861910774, 0.7046919208823396, 0.7025230986664283, 0.7023470878942729, 0.7027245953639937, 0.7001950556462608, 0.6986054256576213, 0.6956819068397575, 0.6943042075930104, 0.6939615232650664, 0.6935476649838186, 0.6923215251664202, 0.6907897831781799, 0.6892431757103893, 0.6884825067429603, 0.6867950464778337, 0.6863476863005921, 0.6857460898589427, 0.6844045017666426, 0.6843983269062366, 0.682700134174961, 0.6826701606618267, 0.682418595101744, 0.6811576605925048, 0.6790153260145034, 0.6793309699629211, 0.6786395766896225, 0.677749172475875, 0.6755192950955148, 0.675901084853608, 0.674413770380298, 0.6735570096787388, 0.6752019604863316, 0.6734113138047157, 0.6708399104579468, 0.6730051475477185, 0.6716217877103515, 0.6707939204777913, 0.6699221078310885, 0.6708356480710057, 0.6679829665761533], 'acc': [0.8059507969874512, 0.9055729373374872, 0.9133221576186504, 0.9244945736155751, 0.9361022934299794, 0.9419147441786914, 0.9460434063767259, 0.9494138772003059, 0.9519245252920728, 0.954111640133606, 0.956078778766407, 0.9577452026846758, 0.9589556057156484, 0.9600568653960943, 0.960802862139969, 0.9613631252517044, 0.9622301836343492, 0.9627279682662796, 0.9631745175456045, 0.9636410190491395, 0.9639855721684724, 0.9642644287408437, 0.9646214523348456, 0.9649786457814434, 0.9652174532071828, 0.9654541158622052, 0.9656756531802173, 0.965905386663605, 0.966019073227638, 0.9661511619605795, 0.9664099781545102, 0.9666077140936682, 0.966691794054076, 0.9667935324207764, 0.9670027981289594, 0.9671329542378807, 0.9672019075943059, 0.9672511156131466, 0.9673824601919918, 0.9674549462304413, 0.9675379866898302, 0.9675933262855989, 0.9676428581297697, 0.9677116954087471, 0.967827094862505, 0.9678672715106897, 0.9679635635332244, 0.9679951407842771, 0.9680704140125039, 0.9681233262101818, 0.968133036927161, 0.968242744293935, 0.9682282835835911, 0.9683484720719695, 0.9683494501746523, 0.9683520489770244, 0.9683930527944681, 0.9684343108534101, 0.9685002570722278, 0.9684988291872296, 0.9685373258229113, 0.9686151888565827, 0.968654477641837, 0.968650413393718, 0.9686886734899257, 0.9687204779988119, 0.9687044385341064, 0.9687994007267643, 0.9688807268657461, 0.9688471116255484, 0.9688696086065053, 0.9688930074440314, 0.9689515632278515, 0.9689716887069768, 0.9690101493976553, 0.9690237157607323, 0.9690402520707948, 0.9690645943258553, 0.9690668300409889, 0.9691167537639896, 0.9691223415891111, 0.9691476944610672, 0.9691792127053721, 0.9691566028215164, 0.9692436051605026, 0.969241921311493, 0.9692731746945086, 0.9692817422109143, 0.9692739543024782, 0.9693100357328989, 0.969365345455167, 0.9693914119315256, 0.9693569197186657, 0.9693476300707061, 0.96943460227995, 0.96941408807519, 0.9694577823867939, 0.969462314418201, 0.9694384958284522, 0.9694707597429496, 0.9695146551543897, 0.9694990422536628, 0.9695590557675103, 0.9695627091962739, 0.9695079504432842, 0.9695430628889524, 0.9695943926167653], 'mDice': [0.023227042180793203, 0.06446733399789673, 0.13532337888537885, 0.22400677332964666, 0.31807115164026883, 0.37977855608974065, 0.4280339903668626, 0.4668960617199017, 0.4980401421877317, 0.5242105569429776, 0.5498352087224501, 0.5725469202450929, 0.5900077090532135, 0.6043752061386851, 0.614868202135732, 0.6260093711272099, 0.6364378299139724, 0.6432812345007993, 0.6503495836360431, 0.6585017871338512, 0.6637060093102434, 0.66984696532167, 0.6764262728241824, 0.6813664119597235, 0.6852037101265124, 0.6894346548487698, 0.6920987311612743, 0.6958994859723222, 0.6992314165493227, 0.7003061318699317, 0.7030109662499439, 0.7061068645120379, 0.7075812521230244, 0.7102283118859891, 0.7128871302488512, 0.7148579700781219, 0.71536093517508, 0.7165745366636085, 0.7180420908234357, 0.7195010048650687, 0.7215514043535115, 0.7218454076590674, 0.7231855626418877, 0.7238430703899187, 0.7262564291169942, 0.7263804508872723, 0.7281815568530136, 0.728065431936561, 0.7294976622941017, 0.7305869479039303, 0.730843067389842, 0.7322859739257921, 0.7322932205380703, 0.7338564193331315, 0.7341661620942966, 0.7346516422890011, 0.7355111541783921, 0.7365801433817083, 0.7365012799808055, 0.7371070390459972, 0.7372725623901573, 0.7394468915513742, 0.7392913919090798, 0.7395199237759255, 0.7397826347853308, 0.7408587828239394, 0.7408460801659036, 0.7415786468885894, 0.7425123700413409, 0.7422585112968264, 0.7423229189698611, 0.7430938567128988, 0.7438636571418024, 0.7446598338289309, 0.7455500500823422, 0.7454503238315027, 0.7455032310965296, 0.7457946882502459, 0.7463712885580799, 0.747132428917533, 0.7475094816366983, 0.747867267079703, 0.7480200704410477, 0.748238754537244, 0.748769525912772, 0.7484593559683779, 0.7493395481782681, 0.7494109099851407, 0.74951187737779, 0.7498225995086103, 0.750518328276004, 0.7502767562453377, 0.7507724381159392, 0.7509325163330814, 0.7517811013187689, 0.7514047873014478, 0.7520339938615995, 0.7524300193712595, 0.7518639159937135, 0.7524874492579324, 0.7534861608410838, 0.7524980005683836, 0.7531878707059847, 0.753425278177061, 0.7537920453652637, 0.7536111190107235, 0.7543294151970444]}
predicting test subjects:   0%|          | 0/15 [00:00<?, ?it/s]predicting test subjects:   7%|▋         | 1/15 [00:01<00:27,  1.95s/it]predicting test subjects:  13%|█▎        | 2/15 [00:03<00:24,  1.88s/it]predicting test subjects:  20%|██        | 3/15 [00:05<00:22,  1.89s/it]predicting test subjects:  27%|██▋       | 4/15 [00:07<00:21,  1.92s/it]predicting test subjects:  33%|███▎      | 5/15 [00:09<00:20,  2.03s/it]predicting test subjects:  40%|████      | 6/15 [00:12<00:19,  2.11s/it]predicting test subjects:  47%|████▋     | 7/15 [00:13<00:15,  1.94s/it]predicting test subjects:  53%|█████▎    | 8/15 [00:15<00:14,  2.05s/it]predicting test subjects:  60%|██████    | 9/15 [00:17<00:11,  2.00s/it]predicting test subjects:  67%|██████▋   | 10/15 [00:19<00:09,  1.87s/it]predicting test subjects:  73%|███████▎  | 11/15 [00:21<00:07,  1.83s/it]predicting test subjects:  80%|████████  | 12/15 [00:23<00:05,  1.90s/it]predicting test subjects:  87%|████████▋ | 13/15 [00:25<00:03,  1.94s/it]predicting test subjects:  93%|█████████▎| 14/15 [00:27<00:01,  1.91s/it]predicting test subjects: 100%|██████████| 15/15 [00:29<00:00,  1.92s/it]
predicting train subjects:   0%|          | 0/532 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/532 [00:02<19:52,  2.25s/it]predicting train subjects:   0%|          | 2/532 [00:03<18:26,  2.09s/it]predicting train subjects:   1%|          | 3/532 [00:05<17:28,  1.98s/it]predicting train subjects:   1%|          | 4/532 [00:07<16:59,  1.93s/it]predicting train subjects:   1%|          | 5/532 [00:09<16:40,  1.90s/it]predicting train subjects:   1%|          | 6/532 [00:11<16:04,  1.83s/it]predicting train subjects:   1%|▏         | 7/532 [00:12<15:43,  1.80s/it]predicting train subjects:   2%|▏         | 8/532 [00:14<15:23,  1.76s/it]predicting train subjects:   2%|▏         | 9/532 [00:16<15:58,  1.83s/it]predicting train subjects:   2%|▏         | 10/532 [00:18<15:38,  1.80s/it]predicting train subjects:   2%|▏         | 11/532 [00:19<15:00,  1.73s/it]predicting train subjects:   2%|▏         | 12/532 [00:21<16:10,  1.87s/it]predicting train subjects:   2%|▏         | 13/532 [00:23<15:30,  1.79s/it]predicting train subjects:   3%|▎         | 14/532 [00:25<14:43,  1.71s/it]predicting train subjects:   3%|▎         | 15/532 [00:26<14:49,  1.72s/it]predicting train subjects:   3%|▎         | 16/532 [00:28<15:08,  1.76s/it]predicting train subjects:   3%|▎         | 17/532 [00:30<14:36,  1.70s/it]predicting train subjects:   3%|▎         | 18/532 [00:32<15:22,  1.79s/it]predicting train subjects:   4%|▎         | 19/532 [00:33<14:29,  1.69s/it]predicting train subjects:   4%|▍         | 20/532 [00:35<14:33,  1.71s/it]predicting train subjects:   4%|▍         | 21/532 [00:37<15:28,  1.82s/it]predicting train subjects:   4%|▍         | 22/532 [00:39<15:00,  1.77s/it]predicting train subjects:   4%|▍         | 23/532 [00:40<15:00,  1.77s/it]predicting train subjects:   5%|▍         | 24/532 [00:42<14:16,  1.69s/it]predicting train subjects:   5%|▍         | 25/532 [00:44<15:30,  1.83s/it]predicting train subjects:   5%|▍         | 26/532 [00:46<14:58,  1.78s/it]predicting train subjects:   5%|▌         | 27/532 [00:48<16:11,  1.92s/it]predicting train subjects:   5%|▌         | 28/532 [00:50<15:48,  1.88s/it]predicting train subjects:   5%|▌         | 29/532 [00:52<16:08,  1.93s/it]predicting train subjects:   6%|▌         | 30/532 [00:53<15:10,  1.81s/it]predicting train subjects:   6%|▌         | 31/532 [00:55<14:58,  1.79s/it]predicting train subjects:   6%|▌         | 32/532 [00:57<14:57,  1.80s/it]predicting train subjects:   6%|▌         | 33/532 [00:58<14:14,  1.71s/it]predicting train subjects:   6%|▋         | 34/532 [01:01<15:15,  1.84s/it]predicting train subjects:   7%|▋         | 35/532 [01:02<14:52,  1.80s/it]predicting train subjects:   7%|▋         | 36/532 [01:04<15:01,  1.82s/it]predicting train subjects:   7%|▋         | 37/532 [01:06<15:07,  1.83s/it]predicting train subjects:   7%|▋         | 38/532 [01:08<15:24,  1.87s/it]predicting train subjects:   7%|▋         | 39/532 [01:10<15:12,  1.85s/it]predicting train subjects:   8%|▊         | 40/532 [01:11<14:43,  1.80s/it]predicting train subjects:   8%|▊         | 41/532 [01:13<15:01,  1.84s/it]predicting train subjects:   8%|▊         | 42/532 [01:15<14:59,  1.84s/it]predicting train subjects:   8%|▊         | 43/532 [01:17<14:07,  1.73s/it]predicting train subjects:   8%|▊         | 44/532 [01:18<13:31,  1.66s/it]predicting train subjects:   8%|▊         | 45/532 [01:20<13:20,  1.64s/it]predicting train subjects:   9%|▊         | 46/532 [01:22<13:54,  1.72s/it]predicting train subjects:   9%|▉         | 47/532 [01:24<14:53,  1.84s/it]predicting train subjects:   9%|▉         | 48/532 [01:26<15:13,  1.89s/it]predicting train subjects:   9%|▉         | 49/532 [01:27<14:33,  1.81s/it]predicting train subjects:   9%|▉         | 50/532 [01:29<15:11,  1.89s/it]predicting train subjects:  10%|▉         | 51/532 [01:31<14:36,  1.82s/it]predicting train subjects:  10%|▉         | 52/532 [01:33<14:24,  1.80s/it]predicting train subjects:  10%|▉         | 53/532 [01:35<14:00,  1.75s/it]predicting train subjects:  10%|█         | 54/532 [01:37<14:46,  1.85s/it]predicting train subjects:  10%|█         | 55/532 [01:38<14:43,  1.85s/it]predicting train subjects:  11%|█         | 56/532 [01:40<14:37,  1.84s/it]predicting train subjects:  11%|█         | 57/532 [01:42<14:24,  1.82s/it]predicting train subjects:  11%|█         | 58/532 [01:44<14:24,  1.82s/it]predicting train subjects:  11%|█         | 59/532 [01:46<15:36,  1.98s/it]predicting train subjects:  11%|█▏        | 60/532 [01:48<14:35,  1.86s/it]predicting train subjects:  11%|█▏        | 61/532 [01:49<14:10,  1.81s/it]predicting train subjects:  12%|█▏        | 62/532 [01:51<14:35,  1.86s/it]predicting train subjects:  12%|█▏        | 63/532 [01:54<15:01,  1.92s/it]predicting train subjects:  12%|█▏        | 64/532 [01:55<14:28,  1.85s/it]predicting train subjects:  12%|█▏        | 65/532 [01:57<14:15,  1.83s/it]predicting train subjects:  12%|█▏        | 66/532 [01:59<15:24,  1.98s/it]predicting train subjects:  13%|█▎        | 67/532 [02:02<15:45,  2.03s/it]predicting train subjects:  13%|█▎        | 68/532 [02:03<15:36,  2.02s/it]predicting train subjects:  13%|█▎        | 69/532 [02:05<14:51,  1.92s/it]predicting train subjects:  13%|█▎        | 70/532 [02:07<14:13,  1.85s/it]predicting train subjects:  13%|█▎        | 71/532 [02:09<13:45,  1.79s/it]predicting train subjects:  14%|█▎        | 72/532 [02:10<13:28,  1.76s/it]predicting train subjects:  14%|█▎        | 73/532 [02:12<13:56,  1.82s/it]predicting train subjects:  14%|█▍        | 74/532 [02:14<14:59,  1.96s/it]predicting train subjects:  14%|█▍        | 75/532 [02:17<17:04,  2.24s/it]predicting train subjects:  14%|█▍        | 76/532 [02:19<15:59,  2.11s/it]predicting train subjects:  14%|█▍        | 77/532 [02:21<15:41,  2.07s/it]predicting train subjects:  15%|█▍        | 78/532 [02:23<15:12,  2.01s/it]predicting train subjects:  15%|█▍        | 79/532 [02:25<14:44,  1.95s/it]predicting train subjects:  15%|█▌        | 80/532 [02:27<14:29,  1.92s/it]predicting train subjects:  15%|█▌        | 81/532 [02:29<14:15,  1.90s/it]predicting train subjects:  15%|█▌        | 82/532 [02:30<14:08,  1.89s/it]predicting train subjects:  16%|█▌        | 83/532 [02:32<13:37,  1.82s/it]predicting train subjects:  16%|█▌        | 84/532 [02:34<13:08,  1.76s/it]predicting train subjects:  16%|█▌        | 85/532 [02:35<12:46,  1.71s/it]predicting train subjects:  16%|█▌        | 86/532 [02:37<12:38,  1.70s/it]predicting train subjects:  16%|█▋        | 87/532 [02:39<12:31,  1.69s/it]predicting train subjects:  17%|█▋        | 88/532 [02:40<12:23,  1.67s/it]predicting train subjects:  17%|█▋        | 89/532 [02:42<12:35,  1.70s/it]predicting train subjects:  17%|█▋        | 90/532 [02:44<12:36,  1.71s/it]predicting train subjects:  17%|█▋        | 91/532 [02:46<12:48,  1.74s/it]predicting train subjects:  17%|█▋        | 92/532 [02:47<12:58,  1.77s/it]predicting train subjects:  17%|█▋        | 93/532 [02:49<13:01,  1.78s/it]predicting train subjects:  18%|█▊        | 94/532 [02:51<13:08,  1.80s/it]predicting train subjects:  18%|█▊        | 95/532 [02:53<13:47,  1.89s/it]predicting train subjects:  18%|█▊        | 96/532 [02:55<14:01,  1.93s/it]predicting train subjects:  18%|█▊        | 97/532 [02:57<14:08,  1.95s/it]predicting train subjects:  18%|█▊        | 98/532 [02:59<14:22,  1.99s/it]predicting train subjects:  19%|█▊        | 99/532 [03:01<14:41,  2.03s/it]predicting train subjects:  19%|█▉        | 100/532 [03:04<15:12,  2.11s/it]predicting train subjects:  19%|█▉        | 101/532 [03:05<14:21,  2.00s/it]predicting train subjects:  19%|█▉        | 102/532 [03:07<13:42,  1.91s/it]predicting train subjects:  19%|█▉        | 103/532 [03:09<13:06,  1.83s/it]predicting train subjects:  20%|█▉        | 104/532 [03:10<12:39,  1.77s/it]predicting train subjects:  20%|█▉        | 105/532 [03:12<12:15,  1.72s/it]predicting train subjects:  20%|█▉        | 106/532 [03:14<12:06,  1.70s/it]predicting train subjects:  20%|██        | 107/532 [03:15<11:46,  1.66s/it]predicting train subjects:  20%|██        | 108/532 [03:17<11:39,  1.65s/it]predicting train subjects:  20%|██        | 109/532 [03:18<11:30,  1.63s/it]predicting train subjects:  21%|██        | 110/532 [03:20<11:24,  1.62s/it]predicting train subjects:  21%|██        | 111/532 [03:22<11:16,  1.61s/it]predicting train subjects:  21%|██        | 112/532 [03:23<11:09,  1.59s/it]predicting train subjects:  21%|██        | 113/532 [03:25<11:45,  1.68s/it]predicting train subjects:  21%|██▏       | 114/532 [03:27<12:15,  1.76s/it]predicting train subjects:  22%|██▏       | 115/532 [03:29<12:41,  1.83s/it]predicting train subjects:  22%|██▏       | 116/532 [03:31<12:45,  1.84s/it]predicting train subjects:  22%|██▏       | 117/532 [03:33<12:57,  1.87s/it]predicting train subjects:  22%|██▏       | 118/532 [03:35<13:03,  1.89s/it]predicting train subjects:  22%|██▏       | 119/532 [03:37<12:45,  1.85s/it]predicting train subjects:  23%|██▎       | 120/532 [03:38<12:34,  1.83s/it]predicting train subjects:  23%|██▎       | 121/532 [03:40<12:19,  1.80s/it]predicting train subjects:  23%|██▎       | 122/532 [03:42<12:18,  1.80s/it]predicting train subjects:  23%|██▎       | 123/532 [03:44<12:23,  1.82s/it]predicting train subjects:  23%|██▎       | 124/532 [03:46<12:28,  1.83s/it]predicting train subjects:  23%|██▎       | 125/532 [03:48<13:03,  1.92s/it]predicting train subjects:  24%|██▎       | 126/532 [03:50<13:10,  1.95s/it]predicting train subjects:  24%|██▍       | 127/532 [03:52<13:08,  1.95s/it]predicting train subjects:  24%|██▍       | 128/532 [03:54<13:05,  1.95s/it]predicting train subjects:  24%|██▍       | 129/532 [03:56<13:03,  1.94s/it]predicting train subjects:  24%|██▍       | 130/532 [03:57<13:03,  1.95s/it]predicting train subjects:  25%|██▍       | 131/532 [04:00<13:34,  2.03s/it]predicting train subjects:  25%|██▍       | 132/532 [04:02<13:49,  2.07s/it]predicting train subjects:  25%|██▌       | 133/532 [04:04<14:14,  2.14s/it]predicting train subjects:  25%|██▌       | 134/532 [04:06<14:21,  2.17s/it]predicting train subjects:  25%|██▌       | 135/532 [04:09<14:22,  2.17s/it]predicting train subjects:  26%|██▌       | 136/532 [04:11<14:25,  2.19s/it]predicting train subjects:  26%|██▌       | 137/532 [04:13<14:33,  2.21s/it]predicting train subjects:  26%|██▌       | 138/532 [04:15<14:42,  2.24s/it]predicting train subjects:  26%|██▌       | 139/532 [04:18<14:39,  2.24s/it]predicting train subjects:  26%|██▋       | 140/532 [04:20<14:38,  2.24s/it]predicting train subjects:  27%|██▋       | 141/532 [04:22<14:38,  2.25s/it]predicting train subjects:  27%|██▋       | 142/532 [04:24<14:27,  2.22s/it]predicting train subjects:  27%|██▋       | 143/532 [04:26<13:23,  2.07s/it]predicting train subjects:  27%|██▋       | 144/532 [04:28<12:41,  1.96s/it]predicting train subjects:  27%|██▋       | 145/532 [04:29<12:10,  1.89s/it]predicting train subjects:  27%|██▋       | 146/532 [04:31<11:56,  1.86s/it]predicting train subjects:  28%|██▊       | 147/532 [04:33<11:40,  1.82s/it]predicting train subjects:  28%|██▊       | 148/532 [04:35<11:30,  1.80s/it]predicting train subjects:  28%|██▊       | 149/532 [04:36<11:24,  1.79s/it]predicting train subjects:  28%|██▊       | 150/532 [04:38<11:28,  1.80s/it]predicting train subjects:  28%|██▊       | 151/532 [04:40<11:29,  1.81s/it]predicting train subjects:  29%|██▊       | 152/532 [04:42<11:32,  1.82s/it]predicting train subjects:  29%|██▉       | 153/532 [04:44<11:35,  1.83s/it]predicting train subjects:  29%|██▉       | 154/532 [04:46<11:25,  1.81s/it]predicting train subjects:  29%|██▉       | 155/532 [04:48<12:12,  1.94s/it]predicting train subjects:  29%|██▉       | 156/532 [04:50<12:40,  2.02s/it]predicting train subjects:  30%|██▉       | 157/532 [04:52<13:04,  2.09s/it]predicting train subjects:  30%|██▉       | 158/532 [04:55<13:24,  2.15s/it]predicting train subjects:  30%|██▉       | 159/532 [04:57<13:40,  2.20s/it]predicting train subjects:  30%|███       | 160/532 [04:59<13:52,  2.24s/it]predicting train subjects:  30%|███       | 161/532 [05:01<13:15,  2.14s/it]predicting train subjects:  30%|███       | 162/532 [05:03<12:31,  2.03s/it]predicting train subjects:  31%|███       | 163/532 [05:05<11:58,  1.95s/it]predicting train subjects:  31%|███       | 164/532 [05:06<11:35,  1.89s/it]predicting train subjects:  31%|███       | 165/532 [05:08<11:24,  1.86s/it]predicting train subjects:  31%|███       | 166/532 [05:10<11:11,  1.83s/it]predicting train subjects:  31%|███▏      | 167/532 [05:12<11:09,  1.83s/it]predicting train subjects:  32%|███▏      | 168/532 [05:14<11:06,  1.83s/it]predicting train subjects:  32%|███▏      | 169/532 [05:16<11:06,  1.84s/it]predicting train subjects:  32%|███▏      | 170/532 [05:17<11:01,  1.83s/it]predicting train subjects:  32%|███▏      | 171/532 [05:19<11:01,  1.83s/it]predicting train subjects:  32%|███▏      | 172/532 [05:21<10:59,  1.83s/it]predicting train subjects:  33%|███▎      | 173/532 [05:23<10:47,  1.80s/it]predicting train subjects:  33%|███▎      | 174/532 [05:25<10:45,  1.80s/it]predicting train subjects:  33%|███▎      | 175/532 [05:26<10:37,  1.79s/it]predicting train subjects:  33%|███▎      | 176/532 [05:28<10:24,  1.75s/it]predicting train subjects:  33%|███▎      | 177/532 [05:30<10:11,  1.72s/it]predicting train subjects:  33%|███▎      | 178/532 [05:31<10:05,  1.71s/it]predicting train subjects:  34%|███▎      | 179/532 [05:33<10:06,  1.72s/it]predicting train subjects:  34%|███▍      | 180/532 [05:35<10:06,  1.72s/it]predicting train subjects:  34%|███▍      | 181/532 [05:37<10:08,  1.73s/it]predicting train subjects:  34%|███▍      | 182/532 [05:38<10:07,  1.73s/it]predicting train subjects:  34%|███▍      | 183/532 [05:40<10:06,  1.74s/it]predicting train subjects:  35%|███▍      | 184/532 [05:42<10:06,  1.74s/it]predicting train subjects:  35%|███▍      | 185/532 [05:43<09:55,  1.72s/it]predicting train subjects:  35%|███▍      | 186/532 [05:45<09:47,  1.70s/it]predicting train subjects:  35%|███▌      | 187/532 [05:47<09:40,  1.68s/it]predicting train subjects:  35%|███▌      | 188/532 [05:48<09:46,  1.70s/it]predicting train subjects:  36%|███▌      | 189/532 [05:50<09:52,  1.73s/it]predicting train subjects:  36%|███▌      | 190/532 [05:52<09:49,  1.72s/it]predicting train subjects:  36%|███▌      | 191/532 [05:54<11:02,  1.94s/it]predicting train subjects:  36%|███▌      | 192/532 [05:57<11:48,  2.08s/it]predicting train subjects:  36%|███▋      | 193/532 [05:59<12:23,  2.19s/it]predicting train subjects:  36%|███▋      | 194/532 [06:02<12:51,  2.28s/it]predicting train subjects:  37%|███▋      | 195/532 [06:04<13:00,  2.31s/it]predicting train subjects:  37%|███▋      | 196/532 [06:07<13:06,  2.34s/it]predicting train subjects:  37%|███▋      | 197/532 [06:09<12:48,  2.29s/it]predicting train subjects:  37%|███▋      | 198/532 [06:11<12:27,  2.24s/it]predicting train subjects:  37%|███▋      | 199/532 [06:13<12:03,  2.17s/it]predicting train subjects:  38%|███▊      | 200/532 [06:15<11:49,  2.14s/it]predicting train subjects:  38%|███▊      | 201/532 [06:17<11:27,  2.08s/it]predicting train subjects:  38%|███▊      | 202/532 [06:19<11:13,  2.04s/it]predicting train subjects:  38%|███▊      | 203/532 [06:21<10:53,  1.99s/it]predicting train subjects:  38%|███▊      | 204/532 [06:22<10:26,  1.91s/it]predicting train subjects:  39%|███▊      | 205/532 [06:24<10:09,  1.87s/it]predicting train subjects:  39%|███▊      | 206/532 [06:26<09:59,  1.84s/it]predicting train subjects:  39%|███▉      | 207/532 [06:28<09:46,  1.80s/it]predicting train subjects:  39%|███▉      | 208/532 [06:30<09:53,  1.83s/it]predicting train subjects:  39%|███▉      | 209/532 [06:31<09:28,  1.76s/it]predicting train subjects:  39%|███▉      | 210/532 [06:33<09:00,  1.68s/it]predicting train subjects:  40%|███▉      | 211/532 [06:34<08:52,  1.66s/it]predicting train subjects:  40%|███▉      | 212/532 [06:36<08:41,  1.63s/it]predicting train subjects:  40%|████      | 213/532 [06:37<08:34,  1.61s/it]predicting train subjects:  40%|████      | 214/532 [06:39<08:26,  1.59s/it]predicting train subjects:  40%|████      | 215/532 [06:41<09:20,  1.77s/it]predicting train subjects:  41%|████      | 216/532 [06:43<09:55,  1.89s/it]predicting train subjects:  41%|████      | 217/532 [06:45<10:18,  1.96s/it]predicting train subjects:  41%|████      | 218/532 [06:48<10:42,  2.05s/it]predicting train subjects:  41%|████      | 219/532 [06:50<10:54,  2.09s/it]predicting train subjects:  41%|████▏     | 220/532 [06:52<11:03,  2.13s/it]predicting train subjects:  42%|████▏     | 221/532 [06:54<10:16,  1.98s/it]predicting train subjects:  42%|████▏     | 222/532 [06:55<09:38,  1.87s/it]predicting train subjects:  42%|████▏     | 223/532 [06:57<09:18,  1.81s/it]predicting train subjects:  42%|████▏     | 224/532 [06:59<09:00,  1.76s/it]predicting train subjects:  42%|████▏     | 225/532 [07:00<08:47,  1.72s/it]predicting train subjects:  42%|████▏     | 226/532 [07:02<08:34,  1.68s/it]predicting train subjects:  43%|████▎     | 227/532 [07:03<08:16,  1.63s/it]predicting train subjects:  43%|████▎     | 228/532 [07:05<08:07,  1.60s/it]predicting train subjects:  43%|████▎     | 229/532 [07:06<07:56,  1.57s/it]predicting train subjects:  43%|████▎     | 230/532 [07:08<07:51,  1.56s/it]predicting train subjects:  43%|████▎     | 231/532 [07:09<07:40,  1.53s/it]predicting train subjects:  44%|████▎     | 232/532 [07:11<07:35,  1.52s/it]predicting train subjects:  44%|████▍     | 233/532 [07:13<07:52,  1.58s/it]predicting train subjects:  44%|████▍     | 234/532 [07:14<08:08,  1.64s/it]predicting train subjects:  44%|████▍     | 235/532 [07:16<08:18,  1.68s/it]predicting train subjects:  44%|████▍     | 236/532 [07:18<08:24,  1.70s/it]predicting train subjects:  45%|████▍     | 237/532 [07:20<08:27,  1.72s/it]predicting train subjects:  45%|████▍     | 238/532 [07:21<08:35,  1.75s/it]predicting train subjects:  45%|████▍     | 239/532 [07:23<08:48,  1.80s/it]predicting train subjects:  45%|████▌     | 240/532 [07:25<08:50,  1.82s/it]predicting train subjects:  45%|████▌     | 241/532 [07:27<09:01,  1.86s/it]predicting train subjects:  45%|████▌     | 242/532 [07:29<09:03,  1.87s/it]predicting train subjects:  46%|████▌     | 243/532 [07:31<09:03,  1.88s/it]predicting train subjects:  46%|████▌     | 244/532 [07:33<08:57,  1.87s/it]predicting train subjects:  46%|████▌     | 245/532 [07:34<08:35,  1.80s/it]predicting train subjects:  46%|████▌     | 246/532 [07:36<08:09,  1.71s/it]predicting train subjects:  46%|████▋     | 247/532 [07:37<07:47,  1.64s/it]predicting train subjects:  47%|████▋     | 248/532 [07:39<07:30,  1.59s/it]predicting train subjects:  47%|████▋     | 249/532 [07:40<07:23,  1.57s/it]predicting train subjects:  47%|████▋     | 250/532 [07:42<07:19,  1.56s/it]predicting train subjects:  47%|████▋     | 251/532 [07:44<07:25,  1.59s/it]predicting train subjects:  47%|████▋     | 252/532 [07:45<07:26,  1.59s/it]predicting train subjects:  48%|████▊     | 253/532 [07:47<07:23,  1.59s/it]predicting train subjects:  48%|████▊     | 254/532 [07:48<07:24,  1.60s/it]predicting train subjects:  48%|████▊     | 255/532 [07:50<07:27,  1.62s/it]predicting train subjects:  48%|████▊     | 256/532 [07:52<07:28,  1.63s/it]predicting train subjects:  48%|████▊     | 257/532 [07:54<08:01,  1.75s/it]predicting train subjects:  48%|████▊     | 258/532 [07:56<08:29,  1.86s/it]predicting train subjects:  49%|████▊     | 259/532 [07:58<08:44,  1.92s/it]predicting train subjects:  49%|████▉     | 260/532 [08:00<08:47,  1.94s/it]predicting train subjects:  49%|████▉     | 261/532 [08:02<09:00,  1.99s/it]predicting train subjects:  49%|████▉     | 262/532 [08:04<09:03,  2.01s/it]predicting train subjects:  49%|████▉     | 263/532 [08:06<08:14,  1.84s/it]predicting train subjects:  50%|████▉     | 264/532 [08:07<07:46,  1.74s/it]predicting train subjects:  50%|████▉     | 265/532 [08:09<07:20,  1.65s/it]predicting train subjects:  50%|█████     | 266/532 [08:10<06:58,  1.57s/it]predicting train subjects:  50%|█████     | 267/532 [08:11<06:48,  1.54s/it]predicting train subjects:  50%|█████     | 268/532 [08:13<06:39,  1.51s/it]predicting train subjects:  51%|█████     | 269/532 [08:15<07:01,  1.60s/it]predicting train subjects:  51%|█████     | 270/532 [08:16<07:19,  1.68s/it]predicting train subjects:  51%|█████     | 271/532 [08:18<07:28,  1.72s/it]predicting train subjects:  51%|█████     | 272/532 [08:20<07:31,  1.74s/it]predicting train subjects:  51%|█████▏    | 273/532 [08:22<07:31,  1.74s/it]predicting train subjects:  52%|█████▏    | 274/532 [08:24<07:33,  1.76s/it]predicting train subjects:  52%|█████▏    | 275/532 [08:26<08:10,  1.91s/it]predicting train subjects:  52%|█████▏    | 276/532 [08:28<08:39,  2.03s/it]predicting train subjects:  52%|█████▏    | 277/532 [08:31<08:57,  2.11s/it]predicting train subjects:  52%|█████▏    | 278/532 [08:33<09:10,  2.17s/it]predicting train subjects:  52%|█████▏    | 279/532 [08:35<09:12,  2.18s/it]predicting train subjects:  53%|█████▎    | 280/532 [08:37<09:18,  2.22s/it]predicting train subjects:  53%|█████▎    | 281/532 [08:39<09:10,  2.19s/it]predicting train subjects:  53%|█████▎    | 282/532 [08:42<08:59,  2.16s/it]predicting train subjects:  53%|█████▎    | 283/532 [08:44<08:45,  2.11s/it]predicting train subjects:  53%|█████▎    | 284/532 [08:46<08:49,  2.14s/it]predicting train subjects:  54%|█████▎    | 285/532 [08:48<08:48,  2.14s/it]predicting train subjects:  54%|█████▍    | 286/532 [08:50<08:37,  2.10s/it]predicting train subjects:  54%|█████▍    | 287/532 [08:52<08:08,  1.99s/it]predicting train subjects:  54%|█████▍    | 288/532 [08:53<07:45,  1.91s/it]predicting train subjects:  54%|█████▍    | 289/532 [08:55<07:23,  1.83s/it]predicting train subjects:  55%|█████▍    | 290/532 [08:57<07:07,  1.77s/it]predicting train subjects:  55%|█████▍    | 291/532 [08:58<06:58,  1.74s/it]predicting train subjects:  55%|█████▍    | 292/532 [09:00<06:52,  1.72s/it]predicting train subjects:  55%|█████▌    | 293/532 [09:02<06:58,  1.75s/it]predicting train subjects:  55%|█████▌    | 294/532 [09:04<06:57,  1.76s/it]predicting train subjects:  55%|█████▌    | 295/532 [09:05<07:04,  1.79s/it]predicting train subjects:  56%|█████▌    | 296/532 [09:07<07:04,  1.80s/it]predicting train subjects:  56%|█████▌    | 297/532 [09:09<07:07,  1.82s/it]predicting train subjects:  56%|█████▌    | 298/532 [09:11<07:11,  1.85s/it]predicting train subjects:  56%|█████▌    | 299/532 [09:13<06:51,  1.77s/it]predicting train subjects:  56%|█████▋    | 300/532 [09:14<06:33,  1.70s/it]predicting train subjects:  57%|█████▋    | 301/532 [09:16<06:25,  1.67s/it]predicting train subjects:  57%|█████▋    | 302/532 [09:17<06:16,  1.64s/it]predicting train subjects:  57%|█████▋    | 303/532 [09:19<06:12,  1.63s/it]predicting train subjects:  57%|█████▋    | 304/532 [09:20<06:08,  1.62s/it]predicting train subjects:  57%|█████▋    | 305/532 [09:23<06:52,  1.82s/it]predicting train subjects:  58%|█████▊    | 306/532 [09:25<07:15,  1.93s/it]predicting train subjects:  58%|█████▊    | 307/532 [09:27<07:39,  2.04s/it]predicting train subjects:  58%|█████▊    | 308/532 [09:29<07:46,  2.08s/it]predicting train subjects:  58%|█████▊    | 309/532 [09:32<07:58,  2.15s/it]predicting train subjects:  58%|█████▊    | 310/532 [09:34<08:01,  2.17s/it]predicting train subjects:  58%|█████▊    | 311/532 [09:37<08:43,  2.37s/it]predicting train subjects:  59%|█████▊    | 312/532 [09:40<09:13,  2.51s/it]predicting train subjects:  59%|█████▉    | 313/532 [09:43<09:41,  2.65s/it]predicting train subjects:  59%|█████▉    | 314/532 [09:45<09:52,  2.72s/it]predicting train subjects:  59%|█████▉    | 315/532 [09:48<10:00,  2.77s/it]predicting train subjects:  59%|█████▉    | 316/532 [09:51<10:02,  2.79s/it]predicting train subjects:  60%|█████▉    | 317/532 [09:53<08:56,  2.50s/it]predicting train subjects:  60%|█████▉    | 318/532 [09:55<08:03,  2.26s/it]predicting train subjects:  60%|█████▉    | 319/532 [09:56<07:24,  2.09s/it]predicting train subjects:  60%|██████    | 320/532 [09:58<06:57,  1.97s/it]predicting train subjects:  60%|██████    | 321/532 [10:00<06:41,  1.90s/it]predicting train subjects:  61%|██████    | 322/532 [10:02<06:29,  1.86s/it]predicting train subjects:  61%|██████    | 323/532 [10:04<06:59,  2.01s/it]predicting train subjects:  61%|██████    | 324/532 [10:06<07:17,  2.10s/it]predicting train subjects:  61%|██████    | 325/532 [10:09<07:28,  2.17s/it]predicting train subjects:  61%|██████▏   | 326/532 [10:11<07:40,  2.23s/it]predicting train subjects:  61%|██████▏   | 327/532 [10:13<07:45,  2.27s/it]predicting train subjects:  62%|██████▏   | 328/532 [10:16<07:45,  2.28s/it]predicting train subjects:  62%|██████▏   | 329/532 [10:17<07:12,  2.13s/it]predicting train subjects:  62%|██████▏   | 330/532 [10:19<06:56,  2.06s/it]predicting train subjects:  62%|██████▏   | 331/532 [10:21<06:39,  1.99s/it]predicting train subjects:  62%|██████▏   | 332/532 [10:23<06:27,  1.94s/it]predicting train subjects:  63%|██████▎   | 333/532 [10:25<06:20,  1.91s/it]predicting train subjects:  63%|██████▎   | 334/532 [10:27<06:10,  1.87s/it]predicting train subjects:  63%|██████▎   | 335/532 [10:29<06:24,  1.95s/it]predicting train subjects:  63%|██████▎   | 336/532 [10:31<06:25,  1.97s/it]predicting train subjects:  63%|██████▎   | 337/532 [10:33<06:21,  1.96s/it]predicting train subjects:  64%|██████▎   | 338/532 [10:35<06:22,  1.97s/it]predicting train subjects:  64%|██████▎   | 339/532 [10:37<06:15,  1.95s/it]predicting train subjects:  64%|██████▍   | 340/532 [10:39<06:12,  1.94s/it]predicting train subjects:  64%|██████▍   | 341/532 [10:40<05:54,  1.86s/it]predicting train subjects:  64%|██████▍   | 342/532 [10:42<05:35,  1.77s/it]predicting train subjects:  64%|██████▍   | 343/532 [10:43<05:21,  1.70s/it]predicting train subjects:  65%|██████▍   | 344/532 [10:45<05:17,  1.69s/it]predicting train subjects:  65%|██████▍   | 345/532 [10:47<05:12,  1.67s/it]predicting train subjects:  65%|██████▌   | 346/532 [10:48<05:03,  1.63s/it]predicting train subjects:  65%|██████▌   | 347/532 [10:50<05:12,  1.69s/it]predicting train subjects:  65%|██████▌   | 348/532 [10:52<05:18,  1.73s/it]predicting train subjects:  66%|██████▌   | 349/532 [10:54<05:24,  1.78s/it]predicting train subjects:  66%|██████▌   | 350/532 [10:55<05:22,  1.77s/it]predicting train subjects:  66%|██████▌   | 351/532 [10:57<05:25,  1.80s/it]predicting train subjects:  66%|██████▌   | 352/532 [10:59<05:21,  1.79s/it]predicting train subjects:  66%|██████▋   | 353/532 [11:01<05:19,  1.79s/it]predicting train subjects:  67%|██████▋   | 354/532 [11:03<05:21,  1.80s/it]predicting train subjects:  67%|██████▋   | 355/532 [11:04<05:18,  1.80s/it]predicting train subjects:  67%|██████▋   | 356/532 [11:06<05:14,  1.79s/it]predicting train subjects:  67%|██████▋   | 357/532 [11:08<05:16,  1.81s/it]predicting train subjects:  67%|██████▋   | 358/532 [11:10<05:12,  1.80s/it]predicting train subjects:  67%|██████▋   | 359/532 [11:11<04:58,  1.72s/it]predicting train subjects:  68%|██████▊   | 360/532 [11:13<04:46,  1.66s/it]predicting train subjects:  68%|██████▊   | 361/532 [11:14<04:37,  1.62s/it]predicting train subjects:  68%|██████▊   | 362/532 [11:16<04:29,  1.59s/it]predicting train subjects:  68%|██████▊   | 363/532 [11:17<04:27,  1.58s/it]predicting train subjects:  68%|██████▊   | 364/532 [11:19<04:25,  1.58s/it]predicting train subjects:  69%|██████▊   | 365/532 [11:21<04:24,  1.59s/it]predicting train subjects:  69%|██████▉   | 366/532 [11:22<04:26,  1.61s/it]predicting train subjects:  69%|██████▉   | 367/532 [11:24<04:26,  1.62s/it]predicting train subjects:  69%|██████▉   | 368/532 [11:26<04:27,  1.63s/it]predicting train subjects:  69%|██████▉   | 369/532 [11:27<04:25,  1.63s/it]predicting train subjects:  70%|██████▉   | 370/532 [11:29<04:24,  1.63s/it]predicting train subjects:  70%|██████▉   | 371/532 [11:31<04:52,  1.82s/it]predicting train subjects:  70%|██████▉   | 372/532 [11:33<05:09,  1.93s/it]predicting train subjects:  70%|███████   | 373/532 [11:36<05:23,  2.04s/it]predicting train subjects:  70%|███████   | 374/532 [11:38<05:29,  2.09s/it]predicting train subjects:  70%|███████   | 375/532 [11:40<05:34,  2.13s/it]predicting train subjects:  71%|███████   | 376/532 [11:42<05:40,  2.18s/it]predicting train subjects:  71%|███████   | 377/532 [11:44<05:27,  2.11s/it]predicting train subjects:  71%|███████   | 378/532 [11:46<05:11,  2.03s/it]predicting train subjects:  71%|███████   | 379/532 [11:48<04:58,  1.95s/it]predicting train subjects:  71%|███████▏  | 380/532 [11:50<04:50,  1.91s/it]predicting train subjects:  72%|███████▏  | 381/532 [11:52<04:53,  1.94s/it]predicting train subjects:  72%|███████▏  | 382/532 [11:54<04:44,  1.90s/it]predicting train subjects:  72%|███████▏  | 383/532 [11:56<04:46,  1.92s/it]predicting train subjects:  72%|███████▏  | 384/532 [11:57<04:44,  1.92s/it]predicting train subjects:  72%|███████▏  | 385/532 [11:59<04:43,  1.93s/it]predicting train subjects:  73%|███████▎  | 386/532 [12:01<04:45,  1.96s/it]predicting train subjects:  73%|███████▎  | 387/532 [12:03<04:46,  1.98s/it]predicting train subjects:  73%|███████▎  | 388/532 [12:05<04:46,  1.99s/it]predicting train subjects:  73%|███████▎  | 389/532 [12:07<04:42,  1.98s/it]predicting train subjects:  73%|███████▎  | 390/532 [12:09<04:39,  1.97s/it]predicting train subjects:  73%|███████▎  | 391/532 [12:11<04:39,  1.98s/it]predicting train subjects:  74%|███████▎  | 392/532 [12:13<04:37,  1.98s/it]predicting train subjects:  74%|███████▍  | 393/532 [12:15<04:37,  2.00s/it]predicting train subjects:  74%|███████▍  | 394/532 [12:17<04:37,  2.01s/it]predicting train subjects:  74%|███████▍  | 395/532 [12:19<04:35,  2.01s/it]predicting train subjects:  74%|███████▍  | 396/532 [12:21<04:33,  2.01s/it]predicting train subjects:  75%|███████▍  | 397/532 [12:23<04:31,  2.01s/it]predicting train subjects:  75%|███████▍  | 398/532 [12:25<04:26,  1.99s/it]predicting train subjects:  75%|███████▌  | 399/532 [12:27<04:21,  1.97s/it]predicting train subjects:  75%|███████▌  | 400/532 [12:29<04:18,  1.96s/it]predicting train subjects:  75%|███████▌  | 401/532 [12:31<04:21,  1.99s/it]predicting train subjects:  76%|███████▌  | 402/532 [12:33<04:20,  2.00s/it]predicting train subjects:  76%|███████▌  | 403/532 [12:35<04:23,  2.04s/it]predicting train subjects:  76%|███████▌  | 404/532 [12:38<04:25,  2.07s/it]predicting train subjects:  76%|███████▌  | 405/532 [12:40<04:22,  2.07s/it]predicting train subjects:  76%|███████▋  | 406/532 [12:42<04:19,  2.06s/it]predicting train subjects:  77%|███████▋  | 407/532 [12:44<04:09,  1.99s/it]predicting train subjects:  77%|███████▋  | 408/532 [12:45<04:05,  1.98s/it]predicting train subjects:  77%|███████▋  | 409/532 [12:47<03:59,  1.95s/it]predicting train subjects:  77%|███████▋  | 410/532 [12:49<03:57,  1.95s/it]predicting train subjects:  77%|███████▋  | 411/532 [12:51<03:50,  1.91s/it]predicting train subjects:  77%|███████▋  | 412/532 [12:53<03:42,  1.85s/it]predicting train subjects:  78%|███████▊  | 413/532 [12:55<03:38,  1.84s/it]predicting train subjects:  78%|███████▊  | 414/532 [12:56<03:35,  1.83s/it]predicting train subjects:  78%|███████▊  | 415/532 [12:58<03:28,  1.78s/it]predicting train subjects:  78%|███████▊  | 416/532 [13:00<03:25,  1.77s/it]predicting train subjects:  78%|███████▊  | 417/532 [13:02<03:22,  1.76s/it]predicting train subjects:  79%|███████▊  | 418/532 [13:03<03:20,  1.76s/it]predicting train subjects:  79%|███████▉  | 419/532 [13:05<03:27,  1.84s/it]predicting train subjects:  79%|███████▉  | 420/532 [13:07<03:32,  1.89s/it]predicting train subjects:  79%|███████▉  | 421/532 [13:09<03:34,  1.93s/it]predicting train subjects:  79%|███████▉  | 422/532 [13:12<03:40,  2.00s/it]predicting train subjects:  80%|███████▉  | 423/532 [13:14<03:40,  2.02s/it]predicting train subjects:  80%|███████▉  | 424/532 [13:16<03:36,  2.00s/it]predicting train subjects:  80%|███████▉  | 425/532 [13:18<03:35,  2.02s/it]predicting train subjects:  80%|████████  | 426/532 [13:20<03:36,  2.04s/it]predicting train subjects:  80%|████████  | 427/532 [13:22<03:33,  2.03s/it]predicting train subjects:  80%|████████  | 428/532 [13:24<03:32,  2.05s/it]predicting train subjects:  81%|████████  | 429/532 [13:26<03:31,  2.05s/it]predicting train subjects:  81%|████████  | 430/532 [13:28<03:26,  2.03s/it]predicting train subjects:  81%|████████  | 431/532 [13:30<03:29,  2.07s/it]predicting train subjects:  81%|████████  | 432/532 [13:32<03:31,  2.11s/it]predicting train subjects:  81%|████████▏ | 433/532 [13:34<03:31,  2.14s/it]predicting train subjects:  82%|████████▏ | 434/532 [13:37<03:27,  2.12s/it]predicting train subjects:  82%|████████▏ | 435/532 [13:39<03:25,  2.12s/it]predicting train subjects:  82%|████████▏ | 436/532 [13:41<03:33,  2.23s/it]predicting train subjects:  82%|████████▏ | 437/532 [13:43<03:22,  2.13s/it]predicting train subjects:  82%|████████▏ | 438/532 [13:45<03:14,  2.07s/it]predicting train subjects:  83%|████████▎ | 439/532 [13:47<03:06,  2.01s/it]predicting train subjects:  83%|████████▎ | 440/532 [13:49<03:00,  1.96s/it]predicting train subjects:  83%|████████▎ | 441/532 [13:51<02:59,  1.97s/it]predicting train subjects:  83%|████████▎ | 442/532 [13:53<02:57,  1.97s/it]predicting train subjects:  83%|████████▎ | 443/532 [13:54<02:52,  1.94s/it]predicting train subjects:  83%|████████▎ | 444/532 [13:56<02:45,  1.88s/it]predicting train subjects:  84%|████████▎ | 445/532 [13:58<02:45,  1.90s/it]predicting train subjects:  84%|████████▍ | 446/532 [14:00<02:43,  1.90s/it]predicting train subjects:  84%|████████▍ | 447/532 [14:02<02:39,  1.88s/it]predicting train subjects:  84%|████████▍ | 448/532 [14:04<02:37,  1.88s/it]predicting train subjects:  84%|████████▍ | 449/532 [14:06<02:40,  1.93s/it]predicting train subjects:  85%|████████▍ | 450/532 [14:08<02:41,  1.97s/it]predicting train subjects:  85%|████████▍ | 451/532 [14:10<02:41,  1.99s/it]predicting train subjects:  85%|████████▍ | 452/532 [14:12<02:39,  1.99s/it]predicting train subjects:  85%|████████▌ | 453/532 [14:14<02:44,  2.08s/it]predicting train subjects:  85%|████████▌ | 454/532 [14:17<02:46,  2.14s/it]predicting train subjects:  86%|████████▌ | 455/532 [14:19<02:49,  2.20s/it]predicting train subjects:  86%|████████▌ | 456/532 [14:21<02:46,  2.19s/it]predicting train subjects:  86%|████████▌ | 457/532 [14:23<02:47,  2.24s/it]predicting train subjects:  86%|████████▌ | 458/532 [14:26<02:44,  2.22s/it]predicting train subjects:  86%|████████▋ | 459/532 [14:28<02:41,  2.21s/it]predicting train subjects:  86%|████████▋ | 460/532 [14:30<02:43,  2.27s/it]predicting train subjects:  87%|████████▋ | 461/532 [14:33<02:50,  2.41s/it]predicting train subjects:  87%|████████▋ | 462/532 [14:36<02:57,  2.54s/it]predicting train subjects:  87%|████████▋ | 463/532 [14:39<03:00,  2.62s/it]predicting train subjects:  87%|████████▋ | 464/532 [14:41<02:57,  2.61s/it]predicting train subjects:  87%|████████▋ | 465/532 [14:44<02:57,  2.66s/it]predicting train subjects:  88%|████████▊ | 466/532 [14:47<02:56,  2.67s/it]predicting train subjects:  88%|████████▊ | 467/532 [14:49<02:44,  2.53s/it]predicting train subjects:  88%|████████▊ | 468/532 [14:51<02:32,  2.39s/it]predicting train subjects:  88%|████████▊ | 469/532 [14:53<02:26,  2.32s/it]predicting train subjects:  88%|████████▊ | 470/532 [14:55<02:21,  2.29s/it]predicting train subjects:  89%|████████▊ | 471/532 [14:57<02:18,  2.28s/it]predicting train subjects:  89%|████████▊ | 472/532 [15:00<02:15,  2.26s/it]predicting train subjects:  89%|████████▉ | 473/532 [15:02<02:16,  2.31s/it]predicting train subjects:  89%|████████▉ | 474/532 [15:05<02:16,  2.36s/it]predicting train subjects:  89%|████████▉ | 475/532 [15:07<02:17,  2.42s/it]predicting train subjects:  89%|████████▉ | 476/532 [15:10<02:16,  2.44s/it]predicting train subjects:  90%|████████▉ | 477/532 [15:12<02:11,  2.39s/it]predicting train subjects:  90%|████████▉ | 478/532 [15:14<02:07,  2.37s/it]predicting train subjects:  90%|█████████ | 479/532 [15:16<02:02,  2.32s/it]predicting train subjects:  90%|█████████ | 480/532 [15:18<01:56,  2.24s/it]predicting train subjects:  90%|█████████ | 481/532 [15:21<01:51,  2.18s/it]predicting train subjects:  91%|█████████ | 482/532 [15:22<01:45,  2.11s/it]predicting train subjects:  91%|█████████ | 483/532 [15:25<01:42,  2.09s/it]predicting train subjects:  91%|█████████ | 484/532 [15:27<01:43,  2.15s/it]predicting train subjects:  91%|█████████ | 485/532 [15:29<01:46,  2.27s/it]predicting train subjects:  91%|█████████▏| 486/532 [15:32<01:47,  2.34s/it]predicting train subjects:  92%|█████████▏| 487/532 [15:34<01:47,  2.40s/it]predicting train subjects:  92%|█████████▏| 488/532 [15:37<01:47,  2.44s/it]predicting train subjects:  92%|█████████▏| 489/532 [15:39<01:45,  2.45s/it]predicting train subjects:  92%|█████████▏| 490/532 [15:42<01:41,  2.41s/it]predicting train subjects:  92%|█████████▏| 491/532 [15:44<01:35,  2.34s/it]predicting train subjects:  92%|█████████▏| 492/532 [15:46<01:31,  2.29s/it]predicting train subjects:  93%|█████████▎| 493/532 [15:48<01:27,  2.25s/it]predicting train subjects:  93%|█████████▎| 494/532 [15:50<01:25,  2.24s/it]predicting train subjects:  93%|█████████▎| 495/532 [15:53<01:22,  2.22s/it]predicting train subjects:  93%|█████████▎| 496/532 [15:55<01:20,  2.24s/it]predicting train subjects:  93%|█████████▎| 497/532 [15:57<01:18,  2.25s/it]predicting train subjects:  94%|█████████▎| 498/532 [15:59<01:16,  2.24s/it]predicting train subjects:  94%|█████████▍| 499/532 [16:02<01:14,  2.25s/it]predicting train subjects:  94%|█████████▍| 500/532 [16:04<01:12,  2.26s/it]predicting train subjects:  94%|█████████▍| 501/532 [16:06<01:09,  2.24s/it]predicting train subjects:  94%|█████████▍| 502/532 [16:08<01:06,  2.22s/it]predicting train subjects:  95%|█████████▍| 503/532 [16:10<01:02,  2.16s/it]predicting train subjects:  95%|█████████▍| 504/532 [16:12<01:00,  2.16s/it]predicting train subjects:  95%|█████████▍| 505/532 [16:15<00:58,  2.17s/it]predicting train subjects:  95%|█████████▌| 506/532 [16:17<00:55,  2.14s/it]predicting train subjects:  95%|█████████▌| 507/532 [16:19<00:52,  2.09s/it]predicting train subjects:  95%|█████████▌| 508/532 [16:21<00:50,  2.11s/it]predicting train subjects:  96%|█████████▌| 509/532 [16:24<00:52,  2.30s/it]predicting train subjects:  96%|█████████▌| 510/532 [16:26<00:53,  2.41s/it]predicting train subjects:  96%|█████████▌| 511/532 [16:29<00:52,  2.48s/it]predicting train subjects:  96%|█████████▌| 512/532 [16:32<00:50,  2.51s/it]predicting train subjects:  96%|█████████▋| 513/532 [16:34<00:49,  2.59s/it]predicting train subjects:  97%|█████████▋| 514/532 [16:37<00:46,  2.60s/it]predicting train subjects:  97%|█████████▋| 515/532 [16:39<00:42,  2.49s/it]predicting train subjects:  97%|█████████▋| 516/532 [16:41<00:38,  2.39s/it]predicting train subjects:  97%|█████████▋| 517/532 [16:43<00:34,  2.32s/it]predicting train subjects:  97%|█████████▋| 518/532 [16:46<00:31,  2.24s/it]predicting train subjects:  98%|█████████▊| 519/532 [16:48<00:29,  2.28s/it]predicting train subjects:  98%|█████████▊| 520/532 [16:50<00:27,  2.30s/it]predicting train subjects:  98%|█████████▊| 521/532 [16:53<00:25,  2.30s/it]predicting train subjects:  98%|█████████▊| 522/532 [16:55<00:23,  2.37s/it]predicting train subjects:  98%|█████████▊| 523/532 [16:58<00:21,  2.44s/it]predicting train subjects:  98%|█████████▊| 524/532 [17:00<00:19,  2.40s/it]predicting train subjects:  99%|█████████▊| 525/532 [17:02<00:16,  2.35s/it]predicting train subjects:  99%|█████████▉| 526/532 [17:05<00:14,  2.36s/it]predicting train subjects:  99%|█████████▉| 527/532 [17:07<00:11,  2.30s/it]predicting train subjects:  99%|█████████▉| 528/532 [17:09<00:08,  2.23s/it]predicting train subjects:  99%|█████████▉| 529/532 [17:11<00:06,  2.17s/it]predicting train subjects: 100%|█████████▉| 530/532 [17:13<00:04,  2.16s/it]predicting train subjects: 100%|█████████▉| 531/532 [17:15<00:02,  2.14s/it]predicting train subjects: 100%|██████████| 532/532 [17:17<00:00,  2.11s/it]
Loading train:   0%|          | 0/532 [00:00<?, ?it/s]Loading train:   0%|          | 1/532 [00:02<20:07,  2.27s/it]Loading train:   0%|          | 2/532 [00:03<18:01,  2.04s/it]Loading train:   1%|          | 3/532 [00:05<17:05,  1.94s/it]Loading train:   1%|          | 4/532 [00:07<16:17,  1.85s/it]Loading train:   1%|          | 5/532 [00:09<16:38,  1.89s/it]Loading train:   1%|          | 6/532 [00:10<16:08,  1.84s/it]Loading train:   1%|▏         | 7/532 [00:12<16:39,  1.90s/it]Loading train:   2%|▏         | 8/532 [00:14<17:02,  1.95s/it]Loading train:   2%|▏         | 9/532 [00:17<17:55,  2.06s/it]Loading train:   2%|▏         | 10/532 [00:18<16:52,  1.94s/it]Loading train:   2%|▏         | 11/532 [00:20<17:07,  1.97s/it]Loading train:   2%|▏         | 12/532 [00:22<16:39,  1.92s/it]Loading train:   2%|▏         | 13/532 [00:24<16:19,  1.89s/it]Loading train:   3%|▎         | 14/532 [00:26<15:52,  1.84s/it]Loading train:   3%|▎         | 15/532 [00:28<15:51,  1.84s/it]Loading train:   3%|▎         | 16/532 [00:29<15:46,  1.83s/it]Loading train:   3%|▎         | 17/532 [00:31<15:58,  1.86s/it]Loading train:   3%|▎         | 18/532 [00:34<16:44,  1.95s/it]Loading train:   4%|▎         | 19/532 [00:35<15:41,  1.83s/it]Loading train:   4%|▍         | 20/532 [00:37<15:20,  1.80s/it]Loading train:   4%|▍         | 21/532 [00:39<15:39,  1.84s/it]Loading train:   4%|▍         | 22/532 [00:40<14:17,  1.68s/it]Loading train:   4%|▍         | 23/532 [00:41<13:34,  1.60s/it]Loading train:   5%|▍         | 24/532 [00:43<12:46,  1.51s/it]Loading train:   5%|▍         | 25/532 [00:45<14:32,  1.72s/it]Loading train:   5%|▍         | 26/532 [00:47<13:59,  1.66s/it]Loading train:   5%|▌         | 27/532 [00:49<15:55,  1.89s/it]Loading train:   5%|▌         | 28/532 [00:51<15:53,  1.89s/it]Loading train:   5%|▌         | 29/532 [00:53<16:42,  1.99s/it]Loading train:   6%|▌         | 30/532 [00:54<14:57,  1.79s/it]Loading train:   6%|▌         | 31/532 [00:56<14:26,  1.73s/it]Loading train:   6%|▌         | 32/532 [00:58<14:16,  1.71s/it]Loading train:   6%|▌         | 33/532 [01:00<14:48,  1.78s/it]Loading train:   6%|▋         | 34/532 [01:02<15:41,  1.89s/it]Loading train:   7%|▋         | 35/532 [01:04<15:23,  1.86s/it]Loading train:   7%|▋         | 36/532 [01:05<15:38,  1.89s/it]Loading train:   7%|▋         | 37/532 [01:07<15:44,  1.91s/it]Loading train:   7%|▋         | 38/532 [01:10<16:16,  1.98s/it]Loading train:   7%|▋         | 39/532 [01:12<17:40,  2.15s/it]Loading train:   8%|▊         | 40/532 [01:14<17:30,  2.14s/it]Loading train:   8%|▊         | 41/532 [01:15<14:57,  1.83s/it]Loading train:   8%|▊         | 42/532 [01:16<12:47,  1.57s/it]Loading train:   8%|▊         | 43/532 [01:17<11:05,  1.36s/it]Loading train:   8%|▊         | 44/532 [01:18<10:27,  1.29s/it]Loading train:   8%|▊         | 45/532 [01:20<10:41,  1.32s/it]Loading train:   9%|▊         | 46/532 [01:21<11:53,  1.47s/it]Loading train:   9%|▉         | 47/532 [01:23<12:34,  1.56s/it]Loading train:   9%|▉         | 48/532 [01:24<11:06,  1.38s/it]Loading train:   9%|▉         | 49/532 [01:25<10:12,  1.27s/it]Loading train:   9%|▉         | 50/532 [01:26<09:52,  1.23s/it]Loading train:  10%|▉         | 51/532 [01:27<09:11,  1.15s/it]Loading train:  10%|▉         | 52/532 [01:28<08:34,  1.07s/it]Loading train:  10%|▉         | 53/532 [01:29<08:06,  1.02s/it]Loading train:  10%|█         | 54/532 [01:30<08:04,  1.01s/it]Loading train:  10%|█         | 55/532 [01:31<07:53,  1.01it/s]Loading train:  11%|█         | 56/532 [01:32<07:49,  1.01it/s]Loading train:  11%|█         | 57/532 [01:33<07:51,  1.01it/s]Loading train:  11%|█         | 58/532 [01:34<07:57,  1.01s/it]Loading train:  11%|█         | 59/532 [01:35<08:19,  1.06s/it]Loading train:  11%|█▏        | 60/532 [01:36<07:43,  1.02it/s]Loading train:  11%|█▏        | 61/532 [01:37<07:16,  1.08it/s]Loading train:  12%|█▏        | 62/532 [01:38<07:54,  1.01s/it]Loading train:  12%|█▏        | 63/532 [01:39<08:19,  1.06s/it]Loading train:  12%|█▏        | 64/532 [01:40<07:42,  1.01it/s]Loading train:  12%|█▏        | 65/532 [01:41<07:45,  1.00it/s]Loading train:  12%|█▏        | 66/532 [01:42<08:29,  1.09s/it]Loading train:  13%|█▎        | 67/532 [01:44<08:56,  1.15s/it]Loading train:  13%|█▎        | 68/532 [01:45<08:14,  1.06s/it]Loading train:  13%|█▎        | 69/532 [01:45<07:42,  1.00it/s]Loading train:  13%|█▎        | 70/532 [01:46<07:35,  1.01it/s]Loading train:  13%|█▎        | 71/532 [01:47<07:10,  1.07it/s]Loading train:  14%|█▎        | 72/532 [01:48<06:59,  1.10it/s]Loading train:  14%|█▎        | 73/532 [01:49<07:23,  1.04it/s]Loading train:  14%|█▍        | 74/532 [01:50<08:07,  1.06s/it]Loading train:  14%|█▍        | 75/532 [01:52<09:26,  1.24s/it]Loading train:  14%|█▍        | 76/532 [01:53<09:15,  1.22s/it]Loading train:  14%|█▍        | 77/532 [01:54<09:13,  1.22s/it]Loading train:  15%|█▍        | 78/532 [01:56<08:53,  1.18s/it]Loading train:  15%|█▍        | 79/532 [01:56<08:17,  1.10s/it]Loading train:  15%|█▌        | 80/532 [01:57<07:56,  1.05s/it]Loading train:  15%|█▌        | 81/532 [01:58<07:33,  1.01s/it]Loading train:  15%|█▌        | 82/532 [01:59<07:16,  1.03it/s]Loading train:  16%|█▌        | 83/532 [02:00<07:02,  1.06it/s]Loading train:  16%|█▌        | 84/532 [02:01<06:36,  1.13it/s]Loading train:  16%|█▌        | 85/532 [02:02<06:17,  1.18it/s]Loading train:  16%|█▌        | 86/532 [02:02<06:15,  1.19it/s]Loading train:  16%|█▋        | 87/532 [02:03<06:00,  1.24it/s]Loading train:  17%|█▋        | 88/532 [02:04<05:56,  1.25it/s]Loading train:  17%|█▋        | 89/532 [02:05<06:36,  1.12it/s]Loading train:  17%|█▋        | 90/532 [02:06<06:29,  1.13it/s]Loading train:  17%|█▋        | 91/532 [02:07<06:46,  1.09it/s]Loading train:  17%|█▋        | 92/532 [02:08<06:35,  1.11it/s]Loading train:  17%|█▋        | 93/532 [02:09<06:37,  1.10it/s]Loading train:  18%|█▊        | 94/532 [02:10<06:34,  1.11it/s]Loading train:  18%|█▊        | 95/532 [02:11<07:10,  1.01it/s]Loading train:  18%|█▊        | 96/532 [02:12<07:23,  1.02s/it]Loading train:  18%|█▊        | 97/532 [02:13<07:38,  1.05s/it]Loading train:  18%|█▊        | 98/532 [02:14<07:36,  1.05s/it]Loading train:  19%|█▊        | 99/532 [02:15<07:44,  1.07s/it]Loading train:  19%|█▉        | 100/532 [02:16<07:41,  1.07s/it]Loading train:  19%|█▉        | 101/532 [02:17<07:23,  1.03s/it]Loading train:  19%|█▉        | 102/532 [02:18<07:09,  1.00it/s]Loading train:  19%|█▉        | 103/532 [02:19<06:42,  1.07it/s]Loading train:  20%|█▉        | 104/532 [02:20<06:25,  1.11it/s]Loading train:  20%|█▉        | 105/532 [02:20<05:59,  1.19it/s]Loading train:  20%|█▉        | 106/532 [02:21<05:55,  1.20it/s]Loading train:  20%|██        | 107/532 [02:22<05:50,  1.21it/s]Loading train:  20%|██        | 108/532 [02:23<05:58,  1.18it/s]Loading train:  20%|██        | 109/532 [02:24<05:50,  1.21it/s]Loading train:  21%|██        | 110/532 [02:25<06:00,  1.17it/s]Loading train:  21%|██        | 111/532 [02:25<06:04,  1.16it/s]Loading train:  21%|██        | 112/532 [02:26<05:57,  1.18it/s]Loading train:  21%|██        | 113/532 [02:27<06:14,  1.12it/s]Loading train:  21%|██▏       | 114/532 [02:28<06:13,  1.12it/s]Loading train:  22%|██▏       | 115/532 [02:29<06:21,  1.09it/s]Loading train:  22%|██▏       | 116/532 [02:30<06:20,  1.09it/s]Loading train:  22%|██▏       | 117/532 [02:31<06:23,  1.08it/s]Loading train:  22%|██▏       | 118/532 [02:32<06:15,  1.10it/s]Loading train:  22%|██▏       | 119/532 [02:33<06:41,  1.03it/s]Loading train:  23%|██▎       | 120/532 [02:34<06:43,  1.02it/s]Loading train:  23%|██▎       | 121/532 [02:35<06:43,  1.02it/s]Loading train:  23%|██▎       | 122/532 [02:36<06:21,  1.08it/s]Loading train:  23%|██▎       | 123/532 [02:37<06:26,  1.06it/s]Loading train:  23%|██▎       | 124/532 [02:38<06:15,  1.09it/s]Loading train:  23%|██▎       | 125/532 [02:39<06:32,  1.04it/s]Loading train:  24%|██▎       | 126/532 [02:40<06:15,  1.08it/s]Loading train:  24%|██▍       | 127/532 [02:40<06:12,  1.09it/s]Loading train:  24%|██▍       | 128/532 [02:41<06:15,  1.08it/s]Loading train:  24%|██▍       | 129/532 [02:42<06:16,  1.07it/s]Loading train:  24%|██▍       | 130/532 [02:43<06:09,  1.09it/s]Loading train:  25%|██▍       | 131/532 [02:44<06:31,  1.02it/s]Loading train:  25%|██▍       | 132/532 [02:45<06:45,  1.01s/it]Loading train:  25%|██▌       | 133/532 [02:47<06:56,  1.04s/it]Loading train:  25%|██▌       | 134/532 [02:48<07:09,  1.08s/it]Loading train:  25%|██▌       | 135/532 [02:49<07:27,  1.13s/it]Loading train:  26%|██▌       | 136/532 [02:50<07:35,  1.15s/it]Loading train:  26%|██▌       | 137/532 [02:51<07:38,  1.16s/it]Loading train:  26%|██▌       | 138/532 [02:52<07:31,  1.15s/it]Loading train:  26%|██▌       | 139/532 [02:54<07:41,  1.17s/it]Loading train:  26%|██▋       | 140/532 [02:55<07:38,  1.17s/it]Loading train:  27%|██▋       | 141/532 [02:56<07:37,  1.17s/it]Loading train:  27%|██▋       | 142/532 [02:57<07:37,  1.17s/it]Loading train:  27%|██▋       | 143/532 [02:58<07:06,  1.10s/it]Loading train:  27%|██▋       | 144/532 [02:59<06:31,  1.01s/it]Loading train:  27%|██▋       | 145/532 [03:00<06:14,  1.03it/s]Loading train:  27%|██▋       | 146/532 [03:01<06:03,  1.06it/s]Loading train:  28%|██▊       | 147/532 [03:02<05:54,  1.09it/s]Loading train:  28%|██▊       | 148/532 [03:02<05:45,  1.11it/s]Loading train:  28%|██▊       | 149/532 [03:03<06:01,  1.06it/s]Loading train:  28%|██▊       | 150/532 [03:04<05:49,  1.09it/s]Loading train:  28%|██▊       | 151/532 [03:05<05:41,  1.12it/s]Loading train:  29%|██▊       | 152/532 [03:06<05:34,  1.14it/s]Loading train:  29%|██▉       | 153/532 [03:07<05:39,  1.12it/s]Loading train:  29%|██▉       | 154/532 [03:08<05:39,  1.11it/s]Loading train:  29%|██▉       | 155/532 [03:09<06:22,  1.01s/it]Loading train:  29%|██▉       | 156/532 [03:10<06:56,  1.11s/it]Loading train:  30%|██▉       | 157/532 [03:12<07:14,  1.16s/it]Loading train:  30%|██▉       | 158/532 [03:13<07:19,  1.17s/it]Loading train:  30%|██▉       | 159/532 [03:14<07:27,  1.20s/it]Loading train:  30%|███       | 160/532 [03:15<07:21,  1.19s/it]Loading train:  30%|███       | 161/532 [03:16<06:52,  1.11s/it]Loading train:  30%|███       | 162/532 [03:17<06:25,  1.04s/it]Loading train:  31%|███       | 163/532 [03:18<06:08,  1.00it/s]Loading train:  31%|███       | 164/532 [03:19<05:50,  1.05it/s]Loading train:  31%|███       | 165/532 [03:20<05:31,  1.11it/s]Loading train:  31%|███       | 166/532 [03:20<05:17,  1.15it/s]Loading train:  31%|███▏      | 167/532 [03:21<05:28,  1.11it/s]Loading train:  32%|███▏      | 168/532 [03:22<05:38,  1.08it/s]Loading train:  32%|███▏      | 169/532 [03:23<05:35,  1.08it/s]Loading train:  32%|███▏      | 170/532 [03:24<05:41,  1.06it/s]Loading train:  32%|███▏      | 171/532 [03:25<05:36,  1.07it/s]Loading train:  32%|███▏      | 172/532 [03:26<05:30,  1.09it/s]Loading train:  33%|███▎      | 173/532 [03:27<05:34,  1.07it/s]Loading train:  33%|███▎      | 174/532 [03:28<05:44,  1.04it/s]Loading train:  33%|███▎      | 175/532 [03:29<05:29,  1.08it/s]Loading train:  33%|███▎      | 176/532 [03:30<05:24,  1.10it/s]Loading train:  33%|███▎      | 177/532 [03:31<05:18,  1.11it/s]Loading train:  33%|███▎      | 178/532 [03:32<05:15,  1.12it/s]Loading train:  34%|███▎      | 179/532 [03:33<05:30,  1.07it/s]Loading train:  34%|███▍      | 180/532 [03:33<05:23,  1.09it/s]Loading train:  34%|███▍      | 181/532 [03:34<05:24,  1.08it/s]Loading train:  34%|███▍      | 182/532 [03:35<05:12,  1.12it/s]Loading train:  34%|███▍      | 183/532 [03:36<05:07,  1.14it/s]Loading train:  35%|███▍      | 184/532 [03:37<05:06,  1.14it/s]Loading train:  35%|███▍      | 185/532 [03:38<05:03,  1.14it/s]Loading train:  35%|███▍      | 186/532 [03:39<04:54,  1.18it/s]Loading train:  35%|███▌      | 187/532 [03:39<04:40,  1.23it/s]Loading train:  35%|███▌      | 188/532 [03:40<04:40,  1.23it/s]Loading train:  36%|███▌      | 189/532 [03:41<04:29,  1.27it/s]Loading train:  36%|███▌      | 190/532 [03:42<04:41,  1.21it/s]Loading train:  36%|███▌      | 191/532 [03:43<05:20,  1.06it/s]Loading train:  36%|███▌      | 192/532 [03:44<05:53,  1.04s/it]Loading train:  36%|███▋      | 193/532 [03:45<06:07,  1.08s/it]Loading train:  36%|███▋      | 194/532 [03:47<06:21,  1.13s/it]Loading train:  37%|███▋      | 195/532 [03:48<06:44,  1.20s/it]Loading train:  37%|███▋      | 196/532 [03:49<06:42,  1.20s/it]Loading train:  37%|███▋      | 197/532 [03:50<06:32,  1.17s/it]Loading train:  37%|███▋      | 198/532 [03:51<06:11,  1.11s/it]Loading train:  37%|███▋      | 199/532 [03:52<06:00,  1.08s/it]Loading train:  38%|███▊      | 200/532 [03:53<05:51,  1.06s/it]Loading train:  38%|███▊      | 201/532 [03:54<05:48,  1.05s/it]Loading train:  38%|███▊      | 202/532 [03:55<05:50,  1.06s/it]Loading train:  38%|███▊      | 203/532 [03:57<05:49,  1.06s/it]Loading train:  38%|███▊      | 204/532 [03:57<05:37,  1.03s/it]Loading train:  39%|███▊      | 205/532 [03:58<05:13,  1.04it/s]Loading train:  39%|███▊      | 206/532 [03:59<04:57,  1.09it/s]Loading train:  39%|███▉      | 207/532 [04:00<04:52,  1.11it/s]Loading train:  39%|███▉      | 208/532 [04:01<04:42,  1.15it/s]Loading train:  39%|███▉      | 209/532 [04:02<04:35,  1.17it/s]Loading train:  39%|███▉      | 210/532 [04:02<04:28,  1.20it/s]Loading train:  40%|███▉      | 211/532 [04:03<04:26,  1.20it/s]Loading train:  40%|███▉      | 212/532 [04:04<04:22,  1.22it/s]Loading train:  40%|████      | 213/532 [04:05<04:15,  1.25it/s]Loading train:  40%|████      | 214/532 [04:05<04:06,  1.29it/s]Loading train:  40%|████      | 215/532 [04:07<04:50,  1.09it/s]Loading train:  41%|████      | 216/532 [04:08<05:05,  1.03it/s]Loading train:  41%|████      | 217/532 [04:09<05:17,  1.01s/it]Loading train:  41%|████      | 218/532 [04:10<05:19,  1.02s/it]Loading train:  41%|████      | 219/532 [04:11<05:28,  1.05s/it]Loading train:  41%|████▏     | 220/532 [04:12<05:32,  1.07s/it]Loading train:  42%|████▏     | 221/532 [04:13<05:19,  1.03s/it]Loading train:  42%|████▏     | 222/532 [04:14<04:47,  1.08it/s]Loading train:  42%|████▏     | 223/532 [04:15<04:32,  1.14it/s]Loading train:  42%|████▏     | 224/532 [04:15<04:17,  1.20it/s]Loading train:  42%|████▏     | 225/532 [04:16<04:14,  1.21it/s]Loading train:  42%|████▏     | 226/532 [04:17<04:08,  1.23it/s]Loading train:  43%|████▎     | 227/532 [04:18<04:04,  1.25it/s]Loading train:  43%|████▎     | 228/532 [04:18<04:02,  1.26it/s]Loading train:  43%|████▎     | 229/532 [04:19<03:54,  1.29it/s]Loading train:  43%|████▎     | 230/532 [04:20<03:55,  1.28it/s]Loading train:  43%|████▎     | 231/532 [04:21<04:00,  1.25it/s]Loading train:  44%|████▎     | 232/532 [04:22<03:56,  1.27it/s]Loading train:  44%|████▍     | 233/532 [04:23<04:17,  1.16it/s]Loading train:  44%|████▍     | 234/532 [04:23<04:15,  1.17it/s]Loading train:  44%|████▍     | 235/532 [04:24<04:15,  1.16it/s]Loading train:  44%|████▍     | 236/532 [04:25<04:07,  1.20it/s]Loading train:  45%|████▍     | 237/532 [04:26<04:10,  1.18it/s]Loading train:  45%|████▍     | 238/532 [04:27<04:10,  1.17it/s]Loading train:  45%|████▍     | 239/532 [04:28<04:17,  1.14it/s]Loading train:  45%|████▌     | 240/532 [04:29<04:14,  1.15it/s]Loading train:  45%|████▌     | 241/532 [04:30<04:12,  1.15it/s]Loading train:  45%|████▌     | 242/532 [04:30<04:13,  1.14it/s]Loading train:  46%|████▌     | 243/532 [04:31<04:22,  1.10it/s]Loading train:  46%|████▌     | 244/532 [04:32<04:18,  1.12it/s]Loading train:  46%|████▌     | 245/532 [04:33<04:15,  1.12it/s]Loading train:  46%|████▌     | 246/532 [04:34<04:09,  1.15it/s]Loading train:  46%|████▋     | 247/532 [04:35<03:58,  1.20it/s]Loading train:  47%|████▋     | 248/532 [04:36<03:54,  1.21it/s]Loading train:  47%|████▋     | 249/532 [04:36<03:54,  1.21it/s]Loading train:  47%|████▋     | 250/532 [04:37<03:55,  1.20it/s]Loading train:  47%|████▋     | 251/532 [04:38<03:57,  1.18it/s]Loading train:  47%|████▋     | 252/532 [04:39<03:48,  1.23it/s]Loading train:  48%|████▊     | 253/532 [04:40<03:48,  1.22it/s]Loading train:  48%|████▊     | 254/532 [04:40<03:40,  1.26it/s]Loading train:  48%|████▊     | 255/532 [04:41<03:40,  1.25it/s]Loading train:  48%|████▊     | 256/532 [04:42<03:38,  1.26it/s]Loading train:  48%|████▊     | 257/532 [04:43<03:58,  1.15it/s]Loading train:  48%|████▊     | 258/532 [04:44<04:03,  1.13it/s]Loading train:  49%|████▊     | 259/532 [04:45<04:15,  1.07it/s]Loading train:  49%|████▉     | 260/532 [04:46<04:25,  1.02it/s]Loading train:  49%|████▉     | 261/532 [04:47<04:20,  1.04it/s]Loading train:  49%|████▉     | 262/532 [04:48<04:19,  1.04it/s]Loading train:  49%|████▉     | 263/532 [04:49<03:58,  1.13it/s]Loading train:  50%|████▉     | 264/532 [04:49<03:50,  1.16it/s]Loading train:  50%|████▉     | 265/532 [04:50<03:52,  1.15it/s]Loading train:  50%|█████     | 266/532 [04:51<03:36,  1.23it/s]Loading train:  50%|█████     | 267/532 [04:52<03:27,  1.28it/s]Loading train:  50%|█████     | 268/532 [04:53<03:28,  1.26it/s]Loading train:  51%|█████     | 269/532 [04:54<03:48,  1.15it/s]Loading train:  51%|█████     | 270/532 [04:55<03:56,  1.11it/s]Loading train:  51%|█████     | 271/532 [04:55<03:50,  1.13it/s]Loading train:  51%|█████     | 272/532 [04:56<03:46,  1.15it/s]Loading train:  51%|█████▏    | 273/532 [04:57<03:51,  1.12it/s]Loading train:  52%|█████▏    | 274/532 [04:58<03:45,  1.14it/s]Loading train:  52%|█████▏    | 275/532 [04:59<04:14,  1.01it/s]Loading train:  52%|█████▏    | 276/532 [05:00<04:19,  1.01s/it]Loading train:  52%|█████▏    | 277/532 [05:01<04:24,  1.04s/it]Loading train:  52%|█████▏    | 278/532 [05:02<04:21,  1.03s/it]Loading train:  52%|█████▏    | 279/532 [05:04<04:22,  1.04s/it]Loading train:  53%|█████▎    | 280/532 [05:05<04:28,  1.07s/it]Loading train:  53%|█████▎    | 281/532 [05:06<04:37,  1.10s/it]Loading train:  53%|█████▎    | 282/532 [05:07<04:31,  1.09s/it]Loading train:  53%|█████▎    | 283/532 [05:08<04:34,  1.10s/it]Loading train:  53%|█████▎    | 284/532 [05:09<04:30,  1.09s/it]Loading train:  54%|█████▎    | 285/532 [05:10<04:26,  1.08s/it]Loading train:  54%|█████▍    | 286/532 [05:11<04:24,  1.07s/it]Loading train:  54%|█████▍    | 287/532 [05:12<04:03,  1.00it/s]Loading train:  54%|█████▍    | 288/532 [05:13<03:47,  1.07it/s]Loading train:  54%|█████▍    | 289/532 [05:14<03:44,  1.08it/s]Loading train:  55%|█████▍    | 290/532 [05:15<03:34,  1.13it/s]Loading train:  55%|█████▍    | 291/532 [05:15<03:34,  1.12it/s]Loading train:  55%|█████▍    | 292/532 [05:16<03:33,  1.13it/s]Loading train:  55%|█████▌    | 293/532 [05:17<03:41,  1.08it/s]Loading train:  55%|█████▌    | 294/532 [05:18<03:35,  1.10it/s]Loading train:  55%|█████▌    | 295/532 [05:19<03:35,  1.10it/s]Loading train:  56%|█████▌    | 296/532 [05:20<03:31,  1.11it/s]Loading train:  56%|█████▌    | 297/532 [05:21<03:31,  1.11it/s]Loading train:  56%|█████▌    | 298/532 [05:22<03:35,  1.09it/s]Loading train:  56%|█████▌    | 299/532 [05:23<03:31,  1.10it/s]Loading train:  56%|█████▋    | 300/532 [05:23<03:17,  1.17it/s]Loading train:  57%|█████▋    | 301/532 [05:24<03:08,  1.22it/s]Loading train:  57%|█████▋    | 302/532 [05:25<03:11,  1.20it/s]Loading train:  57%|█████▋    | 303/532 [05:26<03:01,  1.26it/s]Loading train:  57%|█████▋    | 304/532 [05:27<03:00,  1.26it/s]Loading train:  57%|█████▋    | 305/532 [05:28<03:37,  1.05it/s]Loading train:  58%|█████▊    | 306/532 [05:29<03:56,  1.05s/it]Loading train:  58%|█████▊    | 307/532 [05:30<04:12,  1.12s/it]Loading train:  58%|█████▊    | 308/532 [05:32<04:15,  1.14s/it]Loading train:  58%|█████▊    | 309/532 [05:33<04:09,  1.12s/it]Loading train:  58%|█████▊    | 310/532 [05:34<04:09,  1.13s/it]Loading train:  58%|█████▊    | 311/532 [05:35<04:40,  1.27s/it]Loading train:  59%|█████▊    | 312/532 [05:37<04:58,  1.35s/it]Loading train:  59%|█████▉    | 313/532 [05:39<05:11,  1.42s/it]Loading train:  59%|█████▉    | 314/532 [05:40<05:17,  1.46s/it]Loading train:  59%|█████▉    | 315/532 [05:42<05:28,  1.51s/it]Loading train:  59%|█████▉    | 316/532 [05:43<05:39,  1.57s/it]Loading train:  60%|█████▉    | 317/532 [05:44<04:50,  1.35s/it]Loading train:  60%|█████▉    | 318/532 [05:45<04:26,  1.25s/it]Loading train:  60%|█████▉    | 319/532 [05:46<03:59,  1.13s/it]Loading train:  60%|██████    | 320/532 [05:47<03:43,  1.05s/it]Loading train:  60%|██████    | 321/532 [05:48<03:24,  1.03it/s]Loading train:  61%|██████    | 322/532 [05:49<03:10,  1.10it/s]Loading train:  61%|██████    | 323/532 [05:50<03:39,  1.05s/it]Loading train:  61%|██████    | 324/532 [05:51<03:58,  1.14s/it]Loading train:  61%|██████    | 325/532 [05:52<03:57,  1.15s/it]Loading train:  61%|██████▏   | 326/532 [05:54<04:09,  1.21s/it]Loading train:  61%|██████▏   | 327/532 [05:55<04:03,  1.19s/it]Loading train:  62%|██████▏   | 328/532 [05:56<04:08,  1.22s/it]Loading train:  62%|██████▏   | 329/532 [05:57<03:55,  1.16s/it]Loading train:  62%|██████▏   | 330/532 [05:58<03:39,  1.09s/it]Loading train:  62%|██████▏   | 331/532 [05:59<03:33,  1.06s/it]Loading train:  62%|██████▏   | 332/532 [06:00<03:19,  1.00it/s]Loading train:  63%|██████▎   | 333/532 [06:01<03:21,  1.01s/it]Loading train:  63%|██████▎   | 334/532 [06:02<03:09,  1.04it/s]Loading train:  63%|██████▎   | 335/532 [06:03<03:27,  1.05s/it]Loading train:  63%|██████▎   | 336/532 [06:04<03:24,  1.04s/it]Loading train:  63%|██████▎   | 337/532 [06:05<03:26,  1.06s/it]Loading train:  64%|██████▎   | 338/532 [06:06<03:25,  1.06s/it]Loading train:  64%|██████▎   | 339/532 [06:07<03:22,  1.05s/it]Loading train:  64%|██████▍   | 340/532 [06:08<03:23,  1.06s/it]Loading train:  64%|██████▍   | 341/532 [06:09<03:06,  1.03it/s]Loading train:  64%|██████▍   | 342/532 [06:10<03:05,  1.03it/s]Loading train:  64%|██████▍   | 343/532 [06:11<02:51,  1.10it/s]Loading train:  65%|██████▍   | 344/532 [06:12<02:54,  1.08it/s]Loading train:  65%|██████▍   | 345/532 [06:13<02:46,  1.12it/s]Loading train:  65%|██████▌   | 346/532 [06:14<02:42,  1.14it/s]Loading train:  65%|██████▌   | 347/532 [06:15<02:52,  1.07it/s]Loading train:  65%|██████▌   | 348/532 [06:16<02:59,  1.03it/s]Loading train:  66%|██████▌   | 349/532 [06:17<03:01,  1.01it/s]Loading train:  66%|██████▌   | 350/532 [06:18<02:51,  1.06it/s]Loading train:  66%|██████▌   | 351/532 [06:18<02:43,  1.11it/s]Loading train:  66%|██████▌   | 352/532 [06:20<02:54,  1.03it/s]Loading train:  66%|██████▋   | 353/532 [06:20<02:51,  1.04it/s]Loading train:  67%|██████▋   | 354/532 [06:21<02:49,  1.05it/s]Loading train:  67%|██████▋   | 355/532 [06:22<02:42,  1.09it/s]Loading train:  67%|██████▋   | 356/532 [06:23<02:40,  1.10it/s]Loading train:  67%|██████▋   | 357/532 [06:24<02:40,  1.09it/s]Loading train:  67%|██████▋   | 358/532 [06:25<02:36,  1.11it/s]Loading train:  67%|██████▋   | 359/532 [06:26<02:35,  1.11it/s]Loading train:  68%|██████▊   | 360/532 [06:27<02:37,  1.09it/s]Loading train:  68%|██████▊   | 361/532 [06:28<02:34,  1.11it/s]Loading train:  68%|██████▊   | 362/532 [06:29<02:32,  1.11it/s]Loading train:  68%|██████▊   | 363/532 [06:29<02:27,  1.15it/s]Loading train:  68%|██████▊   | 364/532 [06:30<02:20,  1.20it/s]Loading train:  69%|██████▊   | 365/532 [06:31<02:27,  1.14it/s]Loading train:  69%|██████▉   | 366/532 [06:32<02:21,  1.18it/s]Loading train:  69%|██████▉   | 367/532 [06:33<02:21,  1.17it/s]Loading train:  69%|██████▉   | 368/532 [06:33<02:15,  1.21it/s]Loading train:  69%|██████▉   | 369/532 [06:34<02:11,  1.24it/s]Loading train:  70%|██████▉   | 370/532 [06:35<02:26,  1.11it/s]Loading train:  70%|██████▉   | 371/532 [06:36<02:32,  1.06it/s]Loading train:  70%|██████▉   | 372/532 [06:38<02:50,  1.07s/it]Loading train:  70%|███████   | 373/532 [06:39<02:50,  1.08s/it]Loading train:  70%|███████   | 374/532 [06:40<02:51,  1.08s/it]Loading train:  70%|███████   | 375/532 [06:41<02:53,  1.10s/it]Loading train:  71%|███████   | 376/532 [06:42<02:58,  1.14s/it]Loading train:  71%|███████   | 377/532 [06:43<02:53,  1.12s/it]Loading train:  71%|███████   | 378/532 [06:44<02:47,  1.09s/it]Loading train:  71%|███████   | 379/532 [06:45<02:34,  1.01s/it]Loading train:  71%|███████▏  | 380/532 [06:46<02:27,  1.03it/s]Loading train:  72%|███████▏  | 381/532 [06:47<02:25,  1.03it/s]Loading train:  72%|███████▏  | 382/532 [06:48<02:19,  1.08it/s]Loading train:  72%|███████▏  | 383/532 [06:49<02:25,  1.02it/s]Loading train:  72%|███████▏  | 384/532 [06:50<02:27,  1.00it/s]Loading train:  72%|███████▏  | 385/532 [06:51<02:25,  1.01it/s]Loading train:  73%|███████▎  | 386/532 [06:52<02:29,  1.02s/it]Loading train:  73%|███████▎  | 387/532 [06:53<02:24,  1.00it/s]Loading train:  73%|███████▎  | 388/532 [06:54<02:24,  1.00s/it]Loading train:  73%|███████▎  | 389/532 [06:55<02:27,  1.03s/it]Loading train:  73%|███████▎  | 390/532 [06:56<02:24,  1.01s/it]Loading train:  73%|███████▎  | 391/532 [06:57<02:24,  1.02s/it]Loading train:  74%|███████▎  | 392/532 [06:58<02:28,  1.06s/it]Loading train:  74%|███████▍  | 393/532 [06:59<02:21,  1.01s/it]Loading train:  74%|███████▍  | 394/532 [07:00<02:18,  1.01s/it]Loading train:  74%|███████▍  | 395/532 [07:01<02:14,  1.02it/s]Loading train:  74%|███████▍  | 396/532 [07:02<02:12,  1.02it/s]Loading train:  75%|███████▍  | 397/532 [07:03<02:13,  1.01it/s]Loading train:  75%|███████▍  | 398/532 [07:04<02:09,  1.04it/s]Loading train:  75%|███████▌  | 399/532 [07:05<02:10,  1.02it/s]Loading train:  75%|███████▌  | 400/532 [07:06<02:11,  1.01it/s]Loading train:  75%|███████▌  | 401/532 [07:07<02:20,  1.08s/it]Loading train:  76%|███████▌  | 402/532 [07:08<02:19,  1.08s/it]Loading train:  76%|███████▌  | 403/532 [07:09<02:16,  1.06s/it]Loading train:  76%|███████▌  | 404/532 [07:11<02:18,  1.08s/it]Loading train:  76%|███████▌  | 405/532 [07:12<02:16,  1.07s/it]Loading train:  76%|███████▋  | 406/532 [07:13<02:14,  1.07s/it]Loading train:  77%|███████▋  | 407/532 [07:14<02:09,  1.04s/it]Loading train:  77%|███████▋  | 408/532 [07:15<02:03,  1.00it/s]Loading train:  77%|███████▋  | 409/532 [07:15<01:58,  1.03it/s]Loading train:  77%|███████▋  | 410/532 [07:16<01:56,  1.05it/s]Loading train:  77%|███████▋  | 411/532 [07:17<01:54,  1.05it/s]Loading train:  77%|███████▋  | 412/532 [07:18<01:53,  1.06it/s]Loading train:  78%|███████▊  | 413/532 [07:19<01:55,  1.03it/s]Loading train:  78%|███████▊  | 414/532 [07:20<01:52,  1.05it/s]Loading train:  78%|███████▊  | 415/532 [07:21<01:46,  1.10it/s]Loading train:  78%|███████▊  | 416/532 [07:22<01:45,  1.10it/s]Loading train:  78%|███████▊  | 417/532 [07:23<01:41,  1.13it/s]Loading train:  79%|███████▊  | 418/532 [07:24<01:44,  1.09it/s]Loading train:  79%|███████▉  | 419/532 [07:25<01:46,  1.06it/s]Loading train:  79%|███████▉  | 420/532 [07:26<01:49,  1.03it/s]Loading train:  79%|███████▉  | 421/532 [07:27<01:51,  1.00s/it]Loading train:  79%|███████▉  | 422/532 [07:28<01:52,  1.02s/it]Loading train:  80%|███████▉  | 423/532 [07:29<01:56,  1.07s/it]Loading train:  80%|███████▉  | 424/532 [07:30<01:54,  1.06s/it]Loading train:  80%|███████▉  | 425/532 [07:31<01:52,  1.05s/it]Loading train:  80%|████████  | 426/532 [07:32<01:48,  1.02s/it]Loading train:  80%|████████  | 427/532 [07:33<01:47,  1.02s/it]Loading train:  80%|████████  | 428/532 [07:34<01:47,  1.04s/it]Loading train:  81%|████████  | 429/532 [07:35<01:46,  1.03s/it]Loading train:  81%|████████  | 430/532 [07:36<01:44,  1.03s/it]Loading train:  81%|████████  | 431/532 [07:37<01:49,  1.08s/it]Loading train:  81%|████████  | 432/532 [07:39<01:47,  1.08s/it]Loading train:  81%|████████▏ | 433/532 [07:40<01:48,  1.10s/it]Loading train:  82%|████████▏ | 434/532 [07:41<01:47,  1.10s/it]Loading train:  82%|████████▏ | 435/532 [07:42<01:47,  1.11s/it]Loading train:  82%|████████▏ | 436/532 [07:43<01:45,  1.10s/it]Loading train:  82%|████████▏ | 437/532 [07:44<01:38,  1.04s/it]Loading train:  82%|████████▏ | 438/532 [07:45<01:33,  1.00it/s]Loading train:  83%|████████▎ | 439/532 [07:46<01:27,  1.06it/s]Loading train:  83%|████████▎ | 440/532 [07:47<01:27,  1.06it/s]Loading train:  83%|████████▎ | 441/532 [07:47<01:23,  1.09it/s]Loading train:  83%|████████▎ | 442/532 [07:48<01:22,  1.09it/s]Loading train:  83%|████████▎ | 443/532 [07:49<01:19,  1.12it/s]Loading train:  83%|████████▎ | 444/532 [07:50<01:13,  1.20it/s]Loading train:  84%|████████▎ | 445/532 [07:51<01:18,  1.11it/s]Loading train:  84%|████████▍ | 446/532 [07:52<01:14,  1.16it/s]Loading train:  84%|████████▍ | 447/532 [07:53<01:12,  1.17it/s]Loading train:  84%|████████▍ | 448/532 [07:53<01:12,  1.16it/s]Loading train:  84%|████████▍ | 449/532 [07:54<01:13,  1.14it/s]Loading train:  85%|████████▍ | 450/532 [07:55<01:09,  1.17it/s]Loading train:  85%|████████▍ | 451/532 [07:56<01:09,  1.16it/s]Loading train:  85%|████████▍ | 452/532 [07:57<01:11,  1.12it/s]Loading train:  85%|████████▌ | 453/532 [07:58<01:11,  1.10it/s]Loading train:  85%|████████▌ | 454/532 [07:59<01:11,  1.10it/s]Loading train:  86%|████████▌ | 455/532 [08:00<01:20,  1.04s/it]Loading train:  86%|████████▌ | 456/532 [08:01<01:20,  1.06s/it]Loading train:  86%|████████▌ | 457/532 [08:02<01:16,  1.02s/it]Loading train:  86%|████████▌ | 458/532 [08:03<01:14,  1.01s/it]Loading train:  86%|████████▋ | 459/532 [08:04<01:11,  1.02it/s]Loading train:  86%|████████▋ | 460/532 [08:05<01:10,  1.02it/s]Loading train:  87%|████████▋ | 461/532 [08:06<01:13,  1.04s/it]Loading train:  87%|████████▋ | 462/532 [08:08<01:19,  1.13s/it]Loading train:  87%|████████▋ | 463/532 [08:09<01:16,  1.10s/it]Loading train:  87%|████████▋ | 464/532 [08:10<01:16,  1.12s/it]Loading train:  87%|████████▋ | 465/532 [08:11<01:14,  1.11s/it]Loading train:  88%|████████▊ | 466/532 [08:12<01:14,  1.13s/it]Loading train:  88%|████████▊ | 467/532 [08:13<01:07,  1.03s/it]Loading train:  88%|████████▊ | 468/532 [08:14<01:04,  1.00s/it]Loading train:  88%|████████▊ | 469/532 [08:15<00:59,  1.06it/s]Loading train:  88%|████████▊ | 470/532 [08:15<00:56,  1.09it/s]Loading train:  89%|████████▊ | 471/532 [08:16<00:55,  1.10it/s]Loading train:  89%|████████▊ | 472/532 [08:17<00:53,  1.13it/s]Loading train:  89%|████████▉ | 473/532 [08:18<00:59,  1.00s/it]Loading train:  89%|████████▉ | 474/532 [08:19<00:56,  1.02it/s]Loading train:  89%|████████▉ | 475/532 [08:20<00:56,  1.01it/s]Loading train:  89%|████████▉ | 476/532 [08:21<00:55,  1.01it/s]Loading train:  90%|████████▉ | 477/532 [08:22<00:54,  1.01it/s]Loading train:  90%|████████▉ | 478/532 [08:23<00:54,  1.00s/it]Loading train:  90%|█████████ | 479/532 [08:24<00:50,  1.05it/s]Loading train:  90%|█████████ | 480/532 [08:25<00:48,  1.08it/s]Loading train:  90%|█████████ | 481/532 [08:26<00:48,  1.06it/s]Loading train:  91%|█████████ | 482/532 [08:27<00:46,  1.08it/s]Loading train:  91%|█████████ | 483/532 [08:28<00:45,  1.07it/s]Loading train:  91%|█████████ | 484/532 [08:29<00:44,  1.09it/s]Loading train:  91%|█████████ | 485/532 [08:30<00:47,  1.01s/it]Loading train:  91%|█████████▏| 486/532 [08:31<00:47,  1.04s/it]Loading train:  92%|█████████▏| 487/532 [08:32<00:48,  1.08s/it]Loading train:  92%|█████████▏| 488/532 [08:33<00:46,  1.05s/it]Loading train:  92%|█████████▏| 489/532 [08:34<00:43,  1.02s/it]Loading train:  92%|█████████▏| 490/532 [08:35<00:41,  1.00it/s]Loading train:  92%|█████████▏| 491/532 [08:36<00:38,  1.06it/s]Loading train:  92%|█████████▏| 492/532 [08:37<00:36,  1.10it/s]Loading train:  93%|█████████▎| 493/532 [08:38<00:35,  1.10it/s]Loading train:  93%|█████████▎| 494/532 [08:39<00:36,  1.04it/s]Loading train:  93%|█████████▎| 495/532 [08:40<00:34,  1.08it/s]Loading train:  93%|█████████▎| 496/532 [08:41<00:32,  1.10it/s]Loading train:  93%|█████████▎| 497/532 [08:41<00:32,  1.09it/s]Loading train:  94%|█████████▎| 498/532 [08:42<00:31,  1.10it/s]Loading train:  94%|█████████▍| 499/532 [08:43<00:30,  1.07it/s]Loading train:  94%|█████████▍| 500/532 [08:44<00:29,  1.08it/s]Loading train:  94%|█████████▍| 501/532 [08:45<00:30,  1.02it/s]Loading train:  94%|█████████▍| 502/532 [08:46<00:28,  1.06it/s]Loading train:  95%|█████████▍| 503/532 [08:47<00:26,  1.10it/s]Loading train:  95%|█████████▍| 504/532 [08:48<00:26,  1.07it/s]Loading train:  95%|█████████▍| 505/532 [08:49<00:24,  1.10it/s]Loading train:  95%|█████████▌| 506/532 [08:50<00:25,  1.03it/s]Loading train:  95%|█████████▌| 507/532 [08:51<00:23,  1.08it/s]Loading train:  95%|█████████▌| 508/532 [08:52<00:21,  1.12it/s]Loading train:  96%|█████████▌| 509/532 [08:53<00:21,  1.09it/s]Loading train:  96%|█████████▌| 510/532 [08:54<00:20,  1.06it/s]Loading train:  96%|█████████▌| 511/532 [08:55<00:20,  1.04it/s]Loading train:  96%|█████████▌| 512/532 [08:56<00:19,  1.05it/s]Loading train:  96%|█████████▋| 513/532 [08:57<00:19,  1.02s/it]Loading train:  97%|█████████▋| 514/532 [08:58<00:17,  1.01it/s]Loading train:  97%|█████████▋| 515/532 [08:59<00:17,  1.04s/it]Loading train:  97%|█████████▋| 516/532 [09:00<00:15,  1.00it/s]Loading train:  97%|█████████▋| 517/532 [09:01<00:14,  1.01it/s]Loading train:  97%|█████████▋| 518/532 [09:02<00:13,  1.05it/s]Loading train:  98%|█████████▊| 519/532 [09:03<00:12,  1.02it/s]Loading train:  98%|█████████▊| 520/532 [09:04<00:11,  1.01it/s]Loading train:  98%|█████████▊| 521/532 [09:05<00:11,  1.03s/it]Loading train:  98%|█████████▊| 522/532 [09:06<00:10,  1.07s/it]Loading train:  98%|█████████▊| 523/532 [09:07<00:09,  1.06s/it]Loading train:  98%|█████████▊| 524/532 [09:08<00:08,  1.06s/it]Loading train:  99%|█████████▊| 525/532 [09:09<00:07,  1.05s/it]Loading train:  99%|█████████▉| 526/532 [09:10<00:06,  1.02s/it]Loading train:  99%|█████████▉| 527/532 [09:11<00:04,  1.02it/s]Loading train:  99%|█████████▉| 528/532 [09:12<00:03,  1.08it/s]Loading train:  99%|█████████▉| 529/532 [09:13<00:02,  1.10it/s]Loading train: 100%|█████████▉| 530/532 [09:13<00:01,  1.12it/s]Loading train: 100%|█████████▉| 531/532 [09:14<00:00,  1.13it/s]Loading train: 100%|██████████| 532/532 [09:15<00:00,  1.12it/s]
concatenating: train:   0%|          | 0/532 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 11/532 [00:00<00:05, 100.10it/s]concatenating: train:   5%|▍         | 25/532 [00:00<00:04, 108.93it/s]concatenating: train:  10%|▉         | 53/532 [00:00<00:03, 132.76it/s]concatenating: train:  15%|█▌        | 82/532 [00:00<00:02, 157.87it/s]concatenating: train:  21%|██        | 111/532 [00:00<00:02, 182.10it/s]concatenating: train:  26%|██▌       | 138/532 [00:00<00:01, 201.00it/s]concatenating: train:  32%|███▏      | 169/532 [00:00<00:01, 224.56it/s]concatenating: train:  37%|███▋      | 199/532 [00:00<00:01, 241.47it/s]concatenating: train:  42%|████▏     | 226/532 [00:00<00:01, 247.60it/s]concatenating: train:  48%|████▊     | 255/532 [00:01<00:01, 257.35it/s]concatenating: train:  53%|█████▎    | 282/532 [00:01<00:00, 260.99it/s]concatenating: train:  58%|█████▊    | 309/532 [00:01<00:00, 252.40it/s]concatenating: train:  63%|██████▎   | 335/532 [00:01<00:00, 244.20it/s]concatenating: train:  68%|██████▊   | 360/532 [00:01<00:01, 148.18it/s]concatenating: train:  71%|███████▏  | 380/532 [00:01<00:01, 143.41it/s]concatenating: train:  75%|███████▍  | 398/532 [00:01<00:00, 134.37it/s]concatenating: train:  80%|███████▉  | 425/532 [00:02<00:00, 157.45it/s]concatenating: train:  85%|████████▍ | 450/532 [00:02<00:00, 175.30it/s]concatenating: train:  89%|████████▉ | 476/532 [00:02<00:00, 194.23it/s]concatenating: train:  94%|█████████▍| 500/532 [00:02<00:00, 205.18it/s]concatenating: train: 100%|█████████▉| 531/532 [00:02<00:00, 228.12it/s]concatenating: train: 100%|██████████| 532/532 [00:02<00:00, 212.62it/s]
Loading test:   0%|          | 0/15 [00:00<?, ?it/s]Loading test:   7%|▋         | 1/15 [00:00<00:12,  1.10it/s]Loading test:  13%|█▎        | 2/15 [00:01<00:12,  1.04it/s]Loading test:  20%|██        | 3/15 [00:03<00:11,  1.01it/s]Loading test:  27%|██▋       | 4/15 [00:04<00:10,  1.01it/s]Loading test:  33%|███▎      | 5/15 [00:05<00:11,  1.11s/it]Loading test:  40%|████      | 6/15 [00:06<00:10,  1.15s/it]Loading test:  47%|████▋     | 7/15 [00:07<00:08,  1.05s/it]Loading test:  53%|█████▎    | 8/15 [00:08<00:07,  1.11s/it]Loading test:  60%|██████    | 9/15 [00:09<00:06,  1.08s/it]Loading test:  67%|██████▋   | 10/15 [00:10<00:05,  1.00s/it]Loading test:  73%|███████▎  | 11/15 [00:11<00:03,  1.04it/s]Loading test:  80%|████████  | 12/15 [00:12<00:03,  1.02s/it]Loading test:  87%|████████▋ | 13/15 [00:13<00:02,  1.08s/it]Loading test:  93%|█████████▎| 14/15 [00:14<00:01,  1.05s/it]Loading test: 100%|██████████| 15/15 [00:15<00:00,  1.05s/it]
concatenating: validation:   0%|          | 0/15 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 15/15 [00:00<00:00, 342.71it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 84, 56, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 84, 56, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 84, 56, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 84, 56, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 84, 56, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 84, 56, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 84, 56, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 84, 56, 16)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 42, 28, 16)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 42, 28, 16)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 42, 28, 30)   4350        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 42, 28, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 42, 28, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 42, 28, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 42, 28, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 42, 28, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 42, 28, 46)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 21, 14, 46)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 21, 14, 46)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 21, 14, 60)   24900       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 21, 14, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 21, 14, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 21, 14, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 21, 14, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 21, 14, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 21, 14, 106)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 21, 14, 106)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 42, 28, 30)   12750       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 42, 28, 76)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 42, 28, 30)   20550       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 42, 28, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 42, 28, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 42, 28, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 42, 28, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 42, 28, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 42, 28, 106)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-07 00:53:53.304302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 00:53:53.304403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 00:53:53.304419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 00:53:53.304427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 00:53:53.304849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 42, 28, 106)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 84, 56, 15)   6375        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 56, 31)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 84, 56, 15)   4200        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 84, 56, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 84, 56, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 84, 56, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 84, 56, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 56, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 84, 56, 46)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 84, 56, 46)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 84, 56, 13)   611         dropout_5[0][0]                  
==================================================================================================
Total params: 127,886
Trainable params: 127,286
Non-trainable params: 600
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.53807809e-02 2.88974534e-02 1.16728790e-01 1.00198377e-02
 3.03363016e-02 5.79915656e-03 6.86746312e-02 1.28228722e-01
 7.55625878e-02 1.22514673e-02 2.73642650e-01 1.84278063e-01
 1.99559502e-04]
Train on 19871 samples, validate on 569 samples
Epoch 1/300
 - 27s - loss: 82.9479 - acc: 0.5625 - mDice: 0.0194 - val_loss: 9.6795 - val_acc: 0.9112 - val_mDice: 0.0072

Epoch 00001: val_mDice improved from -inf to 0.00723, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 18s - loss: 9.7551 - acc: 0.8937 - mDice: 0.0453 - val_loss: 7.1366 - val_acc: 0.9111 - val_mDice: 0.0317

Epoch 00002: val_mDice improved from 0.00723 to 0.03166, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 19s - loss: 7.8448 - acc: 0.8955 - mDice: 0.0643 - val_loss: 5.4594 - val_acc: 0.9150 - val_mDice: 0.0769

Epoch 00003: val_mDice improved from 0.03166 to 0.07694, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 17s - loss: 6.8831 - acc: 0.8978 - mDice: 0.0837 - val_loss: 4.6565 - val_acc: 0.9183 - val_mDice: 0.1165

Epoch 00004: val_mDice improved from 0.07694 to 0.11650, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 19s - loss: 6.0752 - acc: 0.9029 - mDice: 0.1126 - val_loss: 4.0627 - val_acc: 0.9219 - val_mDice: 0.1624

Epoch 00005: val_mDice improved from 0.11650 to 0.16236, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 17s - loss: 5.3188 - acc: 0.9113 - mDice: 0.1602 - val_loss: 3.6781 - val_acc: 0.9357 - val_mDice: 0.2290

Epoch 00006: val_mDice improved from 0.16236 to 0.22903, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 7/300
 - 19s - loss: 4.6990 - acc: 0.9191 - mDice: 0.2170 - val_loss: 3.1895 - val_acc: 0.9448 - val_mDice: 0.3249

Epoch 00007: val_mDice improved from 0.22903 to 0.32488, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 8/300
 - 18s - loss: 4.2041 - acc: 0.9253 - mDice: 0.2693 - val_loss: 2.5394 - val_acc: 0.9516 - val_mDice: 0.4053

Epoch 00008: val_mDice improved from 0.32488 to 0.40526, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 18s - loss: 3.7652 - acc: 0.9304 - mDice: 0.3211 - val_loss: 2.1744 - val_acc: 0.9583 - val_mDice: 0.4885

Epoch 00009: val_mDice improved from 0.40526 to 0.48849, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 10/300
 - 18s - loss: 3.3986 - acc: 0.9352 - mDice: 0.3722 - val_loss: 1.9599 - val_acc: 0.9618 - val_mDice: 0.5437

Epoch 00010: val_mDice improved from 0.48849 to 0.54368, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 11/300
 - 17s - loss: 3.1289 - acc: 0.9390 - mDice: 0.4111 - val_loss: 1.7931 - val_acc: 0.9657 - val_mDice: 0.5770

Epoch 00011: val_mDice improved from 0.54368 to 0.57696, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 12/300
 - 18s - loss: 2.9048 - acc: 0.9418 - mDice: 0.4445 - val_loss: 1.6347 - val_acc: 0.9670 - val_mDice: 0.6134

Epoch 00012: val_mDice improved from 0.57696 to 0.61342, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 13/300
 - 18s - loss: 2.7191 - acc: 0.9443 - mDice: 0.4720 - val_loss: 1.6176 - val_acc: 0.9689 - val_mDice: 0.6234

Epoch 00013: val_mDice improved from 0.61342 to 0.62342, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 14/300
 - 20s - loss: 2.5875 - acc: 0.9461 - mDice: 0.4930 - val_loss: 1.5664 - val_acc: 0.9692 - val_mDice: 0.6355

Epoch 00014: val_mDice improved from 0.62342 to 0.63554, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 15/300
 - 21s - loss: 2.4678 - acc: 0.9473 - mDice: 0.5125 - val_loss: 1.5342 - val_acc: 0.9694 - val_mDice: 0.6442

Epoch 00015: val_mDice improved from 0.63554 to 0.64415, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 16/300
 - 23s - loss: 2.3738 - acc: 0.9487 - mDice: 0.5278 - val_loss: 1.5025 - val_acc: 0.9696 - val_mDice: 0.6528

Epoch 00016: val_mDice improved from 0.64415 to 0.65276, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 17/300
 - 21s - loss: 2.2816 - acc: 0.9498 - mDice: 0.5432 - val_loss: 1.4341 - val_acc: 0.9710 - val_mDice: 0.6655

Epoch 00017: val_mDice improved from 0.65276 to 0.66550, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 18/300
 - 23s - loss: 2.2041 - acc: 0.9508 - mDice: 0.5558 - val_loss: 1.4017 - val_acc: 0.9710 - val_mDice: 0.6741

Epoch 00018: val_mDice improved from 0.66550 to 0.67407, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 19/300
 - 22s - loss: 2.1453 - acc: 0.9514 - mDice: 0.5654 - val_loss: 1.3846 - val_acc: 0.9707 - val_mDice: 0.6812

Epoch 00019: val_mDice improved from 0.67407 to 0.68119, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 20/300
 - 23s - loss: 2.0773 - acc: 0.9523 - mDice: 0.5768 - val_loss: 1.3642 - val_acc: 0.9716 - val_mDice: 0.6850

Epoch 00020: val_mDice improved from 0.68119 to 0.68503, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 21/300
 - 22s - loss: 2.0281 - acc: 0.9527 - mDice: 0.5845 - val_loss: 1.3488 - val_acc: 0.9714 - val_mDice: 0.6906

Epoch 00021: val_mDice improved from 0.68503 to 0.69064, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 22/300
 - 22s - loss: 1.9691 - acc: 0.9535 - mDice: 0.5943 - val_loss: 1.3216 - val_acc: 0.9729 - val_mDice: 0.6946

Epoch 00022: val_mDice improved from 0.69064 to 0.69463, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 23/300
 - 22s - loss: 1.9185 - acc: 0.9540 - mDice: 0.6028 - val_loss: 1.3283 - val_acc: 0.9730 - val_mDice: 0.6969

Epoch 00023: val_mDice improved from 0.69463 to 0.69690, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 24/300
 - 22s - loss: 1.8635 - acc: 0.9548 - mDice: 0.6125 - val_loss: 1.2740 - val_acc: 0.9733 - val_mDice: 0.7050

Epoch 00024: val_mDice improved from 0.69690 to 0.70497, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 25/300
 - 23s - loss: 1.8306 - acc: 0.9552 - mDice: 0.6185 - val_loss: 1.3105 - val_acc: 0.9719 - val_mDice: 0.7042

Epoch 00025: val_mDice did not improve from 0.70497
Epoch 26/300
 - 20s - loss: 1.8005 - acc: 0.9555 - mDice: 0.6242 - val_loss: 1.2967 - val_acc: 0.9728 - val_mDice: 0.7058

Epoch 00026: val_mDice improved from 0.70497 to 0.70583, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 27/300
 - 24s - loss: 1.7660 - acc: 0.9561 - mDice: 0.6308 - val_loss: 1.2524 - val_acc: 0.9746 - val_mDice: 0.7103

Epoch 00027: val_mDice improved from 0.70583 to 0.71030, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 28/300
 - 21s - loss: 1.7354 - acc: 0.9565 - mDice: 0.6359 - val_loss: 1.2548 - val_acc: 0.9723 - val_mDice: 0.7147

Epoch 00028: val_mDice improved from 0.71030 to 0.71475, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 29/300
 - 23s - loss: 1.7172 - acc: 0.9567 - mDice: 0.6392 - val_loss: 1.2422 - val_acc: 0.9740 - val_mDice: 0.7187

Epoch 00029: val_mDice improved from 0.71475 to 0.71870, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 30/300
 - 22s - loss: 1.6915 - acc: 0.9571 - mDice: 0.6442 - val_loss: 1.2165 - val_acc: 0.9746 - val_mDice: 0.7193

Epoch 00030: val_mDice improved from 0.71870 to 0.71927, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 31/300
 - 23s - loss: 1.6695 - acc: 0.9573 - mDice: 0.6480 - val_loss: 1.2342 - val_acc: 0.9740 - val_mDice: 0.7165

Epoch 00031: val_mDice did not improve from 0.71927
Epoch 32/300
 - 21s - loss: 1.6557 - acc: 0.9576 - mDice: 0.6508 - val_loss: 1.2435 - val_acc: 0.9744 - val_mDice: 0.7220

Epoch 00032: val_mDice improved from 0.71927 to 0.72203, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 33/300
 - 17s - loss: 1.6247 - acc: 0.9581 - mDice: 0.6565 - val_loss: 1.2014 - val_acc: 0.9736 - val_mDice: 0.7295

Epoch 00033: val_mDice improved from 0.72203 to 0.72952, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 34/300
 - 18s - loss: 1.6150 - acc: 0.9583 - mDice: 0.6589 - val_loss: 1.1853 - val_acc: 0.9754 - val_mDice: 0.7291

Epoch 00034: val_mDice did not improve from 0.72952
Epoch 35/300
 - 17s - loss: 1.5942 - acc: 0.9585 - mDice: 0.6626 - val_loss: 1.1779 - val_acc: 0.9748 - val_mDice: 0.7303

Epoch 00035: val_mDice improved from 0.72952 to 0.73027, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 36/300
 - 17s - loss: 1.5688 - acc: 0.9589 - mDice: 0.6675 - val_loss: 1.1726 - val_acc: 0.9746 - val_mDice: 0.7316

Epoch 00036: val_mDice improved from 0.73027 to 0.73155, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 37/300
 - 17s - loss: 1.5561 - acc: 0.9591 - mDice: 0.6699 - val_loss: 1.1816 - val_acc: 0.9754 - val_mDice: 0.7325

Epoch 00037: val_mDice improved from 0.73155 to 0.73246, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 38/300
 - 18s - loss: 1.5476 - acc: 0.9591 - mDice: 0.6720 - val_loss: 1.1879 - val_acc: 0.9755 - val_mDice: 0.7336

Epoch 00038: val_mDice improved from 0.73246 to 0.73355, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 39/300
 - 17s - loss: 1.5296 - acc: 0.9595 - mDice: 0.6748 - val_loss: 1.1558 - val_acc: 0.9761 - val_mDice: 0.7359

Epoch 00039: val_mDice improved from 0.73355 to 0.73586, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 40/300
 - 17s - loss: 1.5207 - acc: 0.9597 - mDice: 0.6775 - val_loss: 1.1820 - val_acc: 0.9760 - val_mDice: 0.7351

Epoch 00040: val_mDice did not improve from 0.73586
Epoch 41/300
 - 18s - loss: 1.5024 - acc: 0.9599 - mDice: 0.6804 - val_loss: 1.1456 - val_acc: 0.9766 - val_mDice: 0.7358

Epoch 00041: val_mDice did not improve from 0.73586
Epoch 42/300
 - 17s - loss: 1.4940 - acc: 0.9600 - mDice: 0.6818 - val_loss: 1.1464 - val_acc: 0.9753 - val_mDice: 0.7412

Epoch 00042: val_mDice improved from 0.73586 to 0.74118, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 43/300
 - 17s - loss: 1.4778 - acc: 0.9603 - mDice: 0.6848 - val_loss: 1.1735 - val_acc: 0.9745 - val_mDice: 0.7378

Epoch 00043: val_mDice did not improve from 0.74118
Epoch 44/300
 - 17s - loss: 1.4677 - acc: 0.9605 - mDice: 0.6873 - val_loss: 1.1754 - val_acc: 0.9755 - val_mDice: 0.7388

Epoch 00044: val_mDice did not improve from 0.74118
Epoch 45/300
 - 18s - loss: 1.4568 - acc: 0.9606 - mDice: 0.6888 - val_loss: 1.1456 - val_acc: 0.9758 - val_mDice: 0.7431

Epoch 00045: val_mDice improved from 0.74118 to 0.74310, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 46/300
 - 17s - loss: 1.4482 - acc: 0.9607 - mDice: 0.6910 - val_loss: 1.1188 - val_acc: 0.9758 - val_mDice: 0.7444

Epoch 00046: val_mDice improved from 0.74310 to 0.74444, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 47/300
 - 17s - loss: 1.4382 - acc: 0.9608 - mDice: 0.6927 - val_loss: 1.1439 - val_acc: 0.9752 - val_mDice: 0.7400

Epoch 00047: val_mDice did not improve from 0.74444
Epoch 48/300
 - 17s - loss: 1.4277 - acc: 0.9610 - mDice: 0.6949 - val_loss: 1.1234 - val_acc: 0.9766 - val_mDice: 0.7441

Epoch 00048: val_mDice did not improve from 0.74444
Epoch 49/300
 - 17s - loss: 1.4222 - acc: 0.9611 - mDice: 0.6966 - val_loss: 1.1585 - val_acc: 0.9758 - val_mDice: 0.7432

Epoch 00049: val_mDice did not improve from 0.74444
Epoch 50/300
 - 18s - loss: 1.4153 - acc: 0.9611 - mDice: 0.6975 - val_loss: 1.1351 - val_acc: 0.9765 - val_mDice: 0.7490

Epoch 00050: val_mDice improved from 0.74444 to 0.74904, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 51/300
 - 17s - loss: 1.4058 - acc: 0.9613 - mDice: 0.6997 - val_loss: 1.1142 - val_acc: 0.9766 - val_mDice: 0.7497

Epoch 00051: val_mDice improved from 0.74904 to 0.74974, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 52/300
 - 17s - loss: 1.3977 - acc: 0.9614 - mDice: 0.7008 - val_loss: 1.1131 - val_acc: 0.9761 - val_mDice: 0.7460

Epoch 00052: val_mDice did not improve from 0.74974
Epoch 53/300
 - 19s - loss: 1.3888 - acc: 0.9615 - mDice: 0.7032 - val_loss: 1.1155 - val_acc: 0.9769 - val_mDice: 0.7492

Epoch 00053: val_mDice did not improve from 0.74974
Epoch 54/300
 - 17s - loss: 1.3825 - acc: 0.9616 - mDice: 0.7042 - val_loss: 1.1669 - val_acc: 0.9764 - val_mDice: 0.7423

Epoch 00054: val_mDice did not improve from 0.74974
Epoch 55/300
 - 19s - loss: 1.3738 - acc: 0.9618 - mDice: 0.7057 - val_loss: 1.1258 - val_acc: 0.9769 - val_mDice: 0.7524

Epoch 00055: val_mDice improved from 0.74974 to 0.75244, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 56/300
 - 18s - loss: 1.3685 - acc: 0.9619 - mDice: 0.7069 - val_loss: 1.1126 - val_acc: 0.9766 - val_mDice: 0.7484

Epoch 00056: val_mDice did not improve from 0.75244
Epoch 57/300
 - 18s - loss: 1.3674 - acc: 0.9618 - mDice: 0.7066 - val_loss: 1.0904 - val_acc: 0.9774 - val_mDice: 0.7566

Epoch 00057: val_mDice improved from 0.75244 to 0.75662, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 58/300
 - 18s - loss: 1.3554 - acc: 0.9620 - mDice: 0.7093 - val_loss: 1.1133 - val_acc: 0.9765 - val_mDice: 0.7501

Epoch 00058: val_mDice did not improve from 0.75662
Epoch 59/300
 - 18s - loss: 1.3535 - acc: 0.9620 - mDice: 0.7098 - val_loss: 1.1602 - val_acc: 0.9767 - val_mDice: 0.7459

Epoch 00059: val_mDice did not improve from 0.75662
Epoch 60/300
 - 18s - loss: 1.3489 - acc: 0.9620 - mDice: 0.7104 - val_loss: 1.1057 - val_acc: 0.9767 - val_mDice: 0.7533

Epoch 00060: val_mDice did not improve from 0.75662
Epoch 61/300
 - 18s - loss: 1.3425 - acc: 0.9622 - mDice: 0.7119 - val_loss: 1.0996 - val_acc: 0.9769 - val_mDice: 0.7524

Epoch 00061: val_mDice did not improve from 0.75662
Epoch 62/300
 - 17s - loss: 1.3372 - acc: 0.9622 - mDice: 0.7130 - val_loss: 1.1265 - val_acc: 0.9770 - val_mDice: 0.7514

Epoch 00062: val_mDice did not improve from 0.75662
Epoch 63/300
 - 18s - loss: 1.3370 - acc: 0.9622 - mDice: 0.7126 - val_loss: 1.1064 - val_acc: 0.9772 - val_mDice: 0.7539

Epoch 00063: val_mDice did not improve from 0.75662
Epoch 64/300
 - 17s - loss: 1.3282 - acc: 0.9624 - mDice: 0.7146 - val_loss: 1.1008 - val_acc: 0.9775 - val_mDice: 0.7514

Epoch 00064: val_mDice did not improve from 0.75662
Epoch 65/300
 - 18s - loss: 1.3210 - acc: 0.9624 - mDice: 0.7156 - val_loss: 1.1054 - val_acc: 0.9765 - val_mDice: 0.7545

Epoch 00065: val_mDice did not improve from 0.75662
Epoch 66/300
 - 17s - loss: 1.3214 - acc: 0.9624 - mDice: 0.7161 - val_loss: 1.1205 - val_acc: 0.9778 - val_mDice: 0.7561

Epoch 00066: val_mDice did not improve from 0.75662
Epoch 67/300
 - 18s - loss: 1.3143 - acc: 0.9626 - mDice: 0.7171 - val_loss: 1.0778 - val_acc: 0.9778 - val_mDice: 0.7549

Epoch 00067: val_mDice did not improve from 0.75662
Epoch 68/300
 - 17s - loss: 1.3129 - acc: 0.9626 - mDice: 0.7174 - val_loss: 1.0890 - val_acc: 0.9770 - val_mDice: 0.7554

Epoch 00068: val_mDice did not improve from 0.75662
Epoch 69/300
 - 18s - loss: 1.3052 - acc: 0.9627 - mDice: 0.7190 - val_loss: 1.0937 - val_acc: 0.9774 - val_mDice: 0.7549

Epoch 00069: val_mDice did not improve from 0.75662
Epoch 70/300
 - 18s - loss: 1.3007 - acc: 0.9628 - mDice: 0.7197 - val_loss: 1.1111 - val_acc: 0.9772 - val_mDice: 0.7578

Epoch 00070: val_mDice improved from 0.75662 to 0.75777, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 71/300
 - 19s - loss: 1.2994 - acc: 0.9628 - mDice: 0.7205 - val_loss: 1.1009 - val_acc: 0.9771 - val_mDice: 0.7542

Epoch 00071: val_mDice did not improve from 0.75777
Epoch 72/300
 - 17s - loss: 1.2972 - acc: 0.9628 - mDice: 0.7209 - val_loss: 1.1087 - val_acc: 0.9776 - val_mDice: 0.7536

Epoch 00072: val_mDice did not improve from 0.75777
Epoch 73/300
 - 19s - loss: 1.2948 - acc: 0.9629 - mDice: 0.7213 - val_loss: 1.0919 - val_acc: 0.9776 - val_mDice: 0.7609

Epoch 00073: val_mDice improved from 0.75777 to 0.76090, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 74/300
 - 17s - loss: 1.2844 - acc: 0.9631 - mDice: 0.7231 - val_loss: 1.0973 - val_acc: 0.9775 - val_mDice: 0.7565

Epoch 00074: val_mDice did not improve from 0.76090
Epoch 75/300
 - 19s - loss: 1.2852 - acc: 0.9631 - mDice: 0.7229 - val_loss: 1.1026 - val_acc: 0.9775 - val_mDice: 0.7521

Epoch 00075: val_mDice did not improve from 0.76090
Epoch 76/300
 - 17s - loss: 1.2854 - acc: 0.9631 - mDice: 0.7229 - val_loss: 1.1064 - val_acc: 0.9769 - val_mDice: 0.7544

Epoch 00076: val_mDice did not improve from 0.76090
Epoch 77/300
 - 19s - loss: 1.2796 - acc: 0.9632 - mDice: 0.7240 - val_loss: 1.0850 - val_acc: 0.9775 - val_mDice: 0.7574

Epoch 00077: val_mDice did not improve from 0.76090
Epoch 78/300
 - 17s - loss: 1.2772 - acc: 0.9631 - mDice: 0.7245 - val_loss: 1.1086 - val_acc: 0.9775 - val_mDice: 0.7573

Epoch 00078: val_mDice did not improve from 0.76090
Epoch 79/300
 - 19s - loss: 1.2737 - acc: 0.9632 - mDice: 0.7251 - val_loss: 1.0843 - val_acc: 0.9772 - val_mDice: 0.7567

Epoch 00079: val_mDice did not improve from 0.76090
Epoch 80/300
 - 18s - loss: 1.2715 - acc: 0.9633 - mDice: 0.7256 - val_loss: 1.0920 - val_acc: 0.9775 - val_mDice: 0.7610

Epoch 00080: val_mDice improved from 0.76090 to 0.76102, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 81/300
 - 19s - loss: 1.2700 - acc: 0.9633 - mDice: 0.7259 - val_loss: 1.0966 - val_acc: 0.9775 - val_mDice: 0.7570

Epoch 00081: val_mDice did not improve from 0.76102
Epoch 82/300
 - 19s - loss: 1.2647 - acc: 0.9634 - mDice: 0.7268 - val_loss: 1.1002 - val_acc: 0.9776 - val_mDice: 0.7554

Epoch 00082: val_mDice did not improve from 0.76102
Epoch 83/300
 - 19s - loss: 1.2611 - acc: 0.9634 - mDice: 0.7276 - val_loss: 1.0849 - val_acc: 0.9775 - val_mDice: 0.7606

Epoch 00083: val_mDice did not improve from 0.76102
Epoch 84/300
 - 19s - loss: 1.2644 - acc: 0.9634 - mDice: 0.7270 - val_loss: 1.0746 - val_acc: 0.9777 - val_mDice: 0.7599

Epoch 00084: val_mDice did not improve from 0.76102
Epoch 85/300
 - 18s - loss: 1.2553 - acc: 0.9636 - mDice: 0.7290 - val_loss: 1.1031 - val_acc: 0.9781 - val_mDice: 0.7517

Epoch 00085: val_mDice did not improve from 0.76102
Epoch 86/300
 - 20s - loss: 1.2568 - acc: 0.9636 - mDice: 0.7281 - val_loss: 1.0905 - val_acc: 0.9781 - val_mDice: 0.7629

Epoch 00086: val_mDice improved from 0.76102 to 0.76286, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 87/300
 - 18s - loss: 1.2508 - acc: 0.9636 - mDice: 0.7296 - val_loss: 1.0922 - val_acc: 0.9777 - val_mDice: 0.7578

Epoch 00087: val_mDice did not improve from 0.76286
Epoch 88/300
 - 20s - loss: 1.2522 - acc: 0.9637 - mDice: 0.7295 - val_loss: 1.0728 - val_acc: 0.9781 - val_mDice: 0.7602

Epoch 00088: val_mDice did not improve from 0.76286
Epoch 89/300
 - 19s - loss: 1.2457 - acc: 0.9637 - mDice: 0.7304 - val_loss: 1.0686 - val_acc: 0.9778 - val_mDice: 0.7641

Epoch 00089: val_mDice improved from 0.76286 to 0.76406, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 90/300
 - 19s - loss: 1.2450 - acc: 0.9637 - mDice: 0.7309 - val_loss: 1.0999 - val_acc: 0.9772 - val_mDice: 0.7560

Epoch 00090: val_mDice did not improve from 0.76406
Epoch 91/300
 - 20s - loss: 1.2476 - acc: 0.9637 - mDice: 0.7305 - val_loss: 1.0911 - val_acc: 0.9776 - val_mDice: 0.7607

Epoch 00091: val_mDice did not improve from 0.76406
Epoch 92/300
 - 18s - loss: 1.2404 - acc: 0.9638 - mDice: 0.7317 - val_loss: 1.0886 - val_acc: 0.9781 - val_mDice: 0.7607

Epoch 00092: val_mDice did not improve from 0.76406
Epoch 93/300
 - 19s - loss: 1.2408 - acc: 0.9638 - mDice: 0.7318 - val_loss: 1.0668 - val_acc: 0.9781 - val_mDice: 0.7624

Epoch 00093: val_mDice did not improve from 0.76406
Epoch 94/300
 - 17s - loss: 1.2359 - acc: 0.9639 - mDice: 0.7326 - val_loss: 1.0751 - val_acc: 0.9779 - val_mDice: 0.7603

Epoch 00094: val_mDice did not improve from 0.76406
Epoch 95/300
 - 18s - loss: 1.2323 - acc: 0.9640 - mDice: 0.7333 - val_loss: 1.0607 - val_acc: 0.9778 - val_mDice: 0.7620

Epoch 00095: val_mDice did not improve from 0.76406
Epoch 96/300
 - 17s - loss: 1.2327 - acc: 0.9639 - mDice: 0.7332 - val_loss: 1.0862 - val_acc: 0.9776 - val_mDice: 0.7646

Epoch 00096: val_mDice improved from 0.76406 to 0.76461, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 97/300
 - 17s - loss: 1.2314 - acc: 0.9640 - mDice: 0.7335 - val_loss: 1.0858 - val_acc: 0.9781 - val_mDice: 0.7582

Epoch 00097: val_mDice did not improve from 0.76461
Epoch 98/300
 - 18s - loss: 1.2330 - acc: 0.9640 - mDice: 0.7330 - val_loss: 1.0706 - val_acc: 0.9774 - val_mDice: 0.7624

Epoch 00098: val_mDice did not improve from 0.76461
Epoch 99/300
 - 17s - loss: 1.2302 - acc: 0.9640 - mDice: 0.7338 - val_loss: 1.0781 - val_acc: 0.9776 - val_mDice: 0.7604

Epoch 00099: val_mDice did not improve from 0.76461
Epoch 100/300
 - 18s - loss: 1.2233 - acc: 0.9642 - mDice: 0.7351 - val_loss: 1.0809 - val_acc: 0.9774 - val_mDice: 0.7587

Epoch 00100: val_mDice did not improve from 0.76461
Epoch 101/300
 - 17s - loss: 1.2246 - acc: 0.9641 - mDice: 0.7349 - val_loss: 1.0685 - val_acc: 0.9783 - val_mDice: 0.7665

Epoch 00101: val_mDice improved from 0.76461 to 0.76646, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 102/300
 - 17s - loss: 1.2246 - acc: 0.9641 - mDice: 0.7348 - val_loss: 1.0742 - val_acc: 0.9777 - val_mDice: 0.7642

Epoch 00102: val_mDice did not improve from 0.76646
Epoch 103/300
 - 18s - loss: 1.2178 - acc: 0.9643 - mDice: 0.7362 - val_loss: 1.0803 - val_acc: 0.9776 - val_mDice: 0.7622

Epoch 00103: val_mDice did not improve from 0.76646
Epoch 104/300
 - 17s - loss: 1.2139 - acc: 0.9643 - mDice: 0.7373 - val_loss: 1.1002 - val_acc: 0.9777 - val_mDice: 0.7613

Epoch 00104: val_mDice did not improve from 0.76646
Epoch 105/300
 - 17s - loss: 1.2153 - acc: 0.9644 - mDice: 0.7369 - val_loss: 1.0653 - val_acc: 0.9785 - val_mDice: 0.7609

Epoch 00105: val_mDice did not improve from 0.76646
Epoch 106/300
 - 17s - loss: 1.2152 - acc: 0.9643 - mDice: 0.7369 - val_loss: 1.0616 - val_acc: 0.9783 - val_mDice: 0.7646

Epoch 00106: val_mDice did not improve from 0.76646
Epoch 107/300
 - 17s - loss: 1.2108 - acc: 0.9644 - mDice: 0.7377 - val_loss: 1.0899 - val_acc: 0.9779 - val_mDice: 0.7657

Epoch 00107: val_mDice did not improve from 0.76646
Epoch 108/300
 - 17s - loss: 1.2115 - acc: 0.9644 - mDice: 0.7376 - val_loss: 1.0623 - val_acc: 0.9783 - val_mDice: 0.7658

Epoch 00108: val_mDice did not improve from 0.76646
Epoch 109/300
 - 18s - loss: 1.2080 - acc: 0.9645 - mDice: 0.7384 - val_loss: 1.0621 - val_acc: 0.9788 - val_mDice: 0.7661

Epoch 00109: val_mDice did not improve from 0.76646
Epoch 110/300
 - 17s - loss: 1.2053 - acc: 0.9645 - mDice: 0.7388 - val_loss: 1.0604 - val_acc: 0.9787 - val_mDice: 0.7636

Epoch 00110: val_mDice did not improve from 0.76646
Epoch 111/300
 - 17s - loss: 1.2054 - acc: 0.9645 - mDice: 0.7387 - val_loss: 1.0633 - val_acc: 0.9782 - val_mDice: 0.7648

Epoch 00111: val_mDice did not improve from 0.76646
Epoch 112/300
 - 17s - loss: 1.2051 - acc: 0.9645 - mDice: 0.7389 - val_loss: 1.0663 - val_acc: 0.9779 - val_mDice: 0.7661

Epoch 00112: val_mDice did not improve from 0.76646
Epoch 113/300
 - 17s - loss: 1.2007 - acc: 0.9646 - mDice: 0.7400 - val_loss: 1.0538 - val_acc: 0.9781 - val_mDice: 0.7666

Epoch 00113: val_mDice improved from 0.76646 to 0.76660, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 114/300
 - 18s - loss: 1.2006 - acc: 0.9646 - mDice: 0.7401 - val_loss: 1.0571 - val_acc: 0.9788 - val_mDice: 0.7668

Epoch 00114: val_mDice improved from 0.76660 to 0.76684, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 115/300
 - 17s - loss: 1.1984 - acc: 0.9647 - mDice: 0.7401 - val_loss: 1.0727 - val_acc: 0.9784 - val_mDice: 0.7646

Epoch 00115: val_mDice did not improve from 0.76684
Epoch 116/300
 - 17s - loss: 1.1997 - acc: 0.9646 - mDice: 0.7401 - val_loss: 1.0580 - val_acc: 0.9789 - val_mDice: 0.7671

Epoch 00116: val_mDice improved from 0.76684 to 0.76714, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 117/300
 - 17s - loss: 1.1961 - acc: 0.9647 - mDice: 0.7409 - val_loss: 1.0573 - val_acc: 0.9787 - val_mDice: 0.7665

Epoch 00117: val_mDice did not improve from 0.76714
Epoch 118/300
 - 17s - loss: 1.1952 - acc: 0.9647 - mDice: 0.7408 - val_loss: 1.0716 - val_acc: 0.9781 - val_mDice: 0.7657

Epoch 00118: val_mDice did not improve from 0.76714
Epoch 119/300
 - 18s - loss: 1.1937 - acc: 0.9647 - mDice: 0.7411 - val_loss: 1.0627 - val_acc: 0.9787 - val_mDice: 0.7656

Epoch 00119: val_mDice did not improve from 0.76714
Epoch 120/300
 - 17s - loss: 1.1912 - acc: 0.9648 - mDice: 0.7421 - val_loss: 1.0698 - val_acc: 0.9779 - val_mDice: 0.7629

Epoch 00120: val_mDice did not improve from 0.76714
Epoch 121/300
 - 17s - loss: 1.1902 - acc: 0.9649 - mDice: 0.7421 - val_loss: 1.0660 - val_acc: 0.9784 - val_mDice: 0.7695

Epoch 00121: val_mDice improved from 0.76714 to 0.76947, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 122/300
 - 18s - loss: 1.1916 - acc: 0.9648 - mDice: 0.7416 - val_loss: 1.0565 - val_acc: 0.9784 - val_mDice: 0.7695

Epoch 00122: val_mDice improved from 0.76947 to 0.76953, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 123/300
 - 18s - loss: 1.1885 - acc: 0.9649 - mDice: 0.7423 - val_loss: 1.0542 - val_acc: 0.9789 - val_mDice: 0.7704

Epoch 00123: val_mDice improved from 0.76953 to 0.77035, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 124/300
 - 17s - loss: 1.1848 - acc: 0.9649 - mDice: 0.7432 - val_loss: 1.0475 - val_acc: 0.9788 - val_mDice: 0.7663

Epoch 00124: val_mDice did not improve from 0.77035
Epoch 125/300
 - 18s - loss: 1.1823 - acc: 0.9649 - mDice: 0.7436 - val_loss: 1.0549 - val_acc: 0.9777 - val_mDice: 0.7706

Epoch 00125: val_mDice improved from 0.77035 to 0.77063, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 126/300
 - 17s - loss: 1.1847 - acc: 0.9650 - mDice: 0.7435 - val_loss: 1.0455 - val_acc: 0.9787 - val_mDice: 0.7671

Epoch 00126: val_mDice did not improve from 0.77063
Epoch 127/300
 - 17s - loss: 1.1831 - acc: 0.9649 - mDice: 0.7434 - val_loss: 1.0617 - val_acc: 0.9782 - val_mDice: 0.7650

Epoch 00127: val_mDice did not improve from 0.77063
Epoch 128/300
 - 17s - loss: 1.1812 - acc: 0.9650 - mDice: 0.7438 - val_loss: 1.0700 - val_acc: 0.9783 - val_mDice: 0.7668

Epoch 00128: val_mDice did not improve from 0.77063
Epoch 129/300
 - 18s - loss: 1.1814 - acc: 0.9650 - mDice: 0.7438 - val_loss: 1.0595 - val_acc: 0.9781 - val_mDice: 0.7693

Epoch 00129: val_mDice did not improve from 0.77063
Epoch 130/300
 - 17s - loss: 1.1791 - acc: 0.9650 - mDice: 0.7445 - val_loss: 1.0409 - val_acc: 0.9787 - val_mDice: 0.7686

Epoch 00130: val_mDice did not improve from 0.77063
Epoch 131/300
 - 17s - loss: 1.1792 - acc: 0.9650 - mDice: 0.7444 - val_loss: 1.0505 - val_acc: 0.9781 - val_mDice: 0.7690

Epoch 00131: val_mDice did not improve from 0.77063
Epoch 132/300
 - 17s - loss: 1.1814 - acc: 0.9650 - mDice: 0.7438 - val_loss: 1.0682 - val_acc: 0.9774 - val_mDice: 0.7697

Epoch 00132: val_mDice did not improve from 0.77063
Epoch 133/300
 - 17s - loss: 1.1773 - acc: 0.9650 - mDice: 0.7447 - val_loss: 1.0867 - val_acc: 0.9783 - val_mDice: 0.7626

Epoch 00133: val_mDice did not improve from 0.77063
Epoch 134/300
 - 18s - loss: 1.1763 - acc: 0.9650 - mDice: 0.7450 - val_loss: 1.0589 - val_acc: 0.9785 - val_mDice: 0.7667

Epoch 00134: val_mDice did not improve from 0.77063
Epoch 135/300
 - 17s - loss: 1.1766 - acc: 0.9651 - mDice: 0.7449 - val_loss: 1.0443 - val_acc: 0.9791 - val_mDice: 0.7696

Epoch 00135: val_mDice did not improve from 0.77063
Epoch 136/300
 - 17s - loss: 1.1721 - acc: 0.9651 - mDice: 0.7461 - val_loss: 1.0678 - val_acc: 0.9789 - val_mDice: 0.7665

Epoch 00136: val_mDice did not improve from 0.77063
Epoch 137/300
 - 17s - loss: 1.1697 - acc: 0.9651 - mDice: 0.7462 - val_loss: 1.0576 - val_acc: 0.9782 - val_mDice: 0.7700

Epoch 00137: val_mDice did not improve from 0.77063
Epoch 138/300
 - 18s - loss: 1.1708 - acc: 0.9651 - mDice: 0.7461 - val_loss: 1.0528 - val_acc: 0.9787 - val_mDice: 0.7720

Epoch 00138: val_mDice improved from 0.77063 to 0.77205, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 139/300
 - 17s - loss: 1.1682 - acc: 0.9652 - mDice: 0.7467 - val_loss: 1.0436 - val_acc: 0.9790 - val_mDice: 0.7719

Epoch 00139: val_mDice did not improve from 0.77205
Epoch 140/300
 - 19s - loss: 1.1674 - acc: 0.9652 - mDice: 0.7469 - val_loss: 1.0520 - val_acc: 0.9782 - val_mDice: 0.7708

Epoch 00140: val_mDice did not improve from 0.77205
Epoch 141/300
 - 17s - loss: 1.1690 - acc: 0.9652 - mDice: 0.7465 - val_loss: 1.0554 - val_acc: 0.9786 - val_mDice: 0.7687

Epoch 00141: val_mDice did not improve from 0.77205
Epoch 142/300
 - 18s - loss: 1.1666 - acc: 0.9652 - mDice: 0.7468 - val_loss: 1.0645 - val_acc: 0.9787 - val_mDice: 0.7675

Epoch 00142: val_mDice did not improve from 0.77205
Epoch 143/300
 - 18s - loss: 1.1651 - acc: 0.9652 - mDice: 0.7475 - val_loss: 1.0486 - val_acc: 0.9785 - val_mDice: 0.7699

Epoch 00143: val_mDice did not improve from 0.77205
Epoch 144/300
 - 18s - loss: 1.1648 - acc: 0.9653 - mDice: 0.7471 - val_loss: 1.0576 - val_acc: 0.9778 - val_mDice: 0.7697

Epoch 00144: val_mDice did not improve from 0.77205
Epoch 145/300
 - 19s - loss: 1.1613 - acc: 0.9653 - mDice: 0.7479 - val_loss: 1.0483 - val_acc: 0.9788 - val_mDice: 0.7720

Epoch 00145: val_mDice did not improve from 0.77205
Epoch 146/300
 - 20s - loss: 1.1620 - acc: 0.9653 - mDice: 0.7480 - val_loss: 1.0413 - val_acc: 0.9790 - val_mDice: 0.7706

Epoch 00146: val_mDice did not improve from 0.77205
Epoch 147/300
 - 19s - loss: 1.1625 - acc: 0.9652 - mDice: 0.7479 - val_loss: 1.0551 - val_acc: 0.9789 - val_mDice: 0.7739

Epoch 00147: val_mDice improved from 0.77205 to 0.77386, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 148/300
 - 21s - loss: 1.1597 - acc: 0.9654 - mDice: 0.7485 - val_loss: 1.0763 - val_acc: 0.9786 - val_mDice: 0.7707

Epoch 00148: val_mDice did not improve from 0.77386
Epoch 149/300
 - 24s - loss: 1.1589 - acc: 0.9653 - mDice: 0.7487 - val_loss: 1.0432 - val_acc: 0.9785 - val_mDice: 0.7706

Epoch 00149: val_mDice did not improve from 0.77386
Epoch 150/300
 - 23s - loss: 1.1608 - acc: 0.9653 - mDice: 0.7482 - val_loss: 1.0593 - val_acc: 0.9779 - val_mDice: 0.7693

Epoch 00150: val_mDice did not improve from 0.77386
Epoch 151/300
 - 24s - loss: 1.1575 - acc: 0.9654 - mDice: 0.7491 - val_loss: 1.0478 - val_acc: 0.9789 - val_mDice: 0.7731

Epoch 00151: val_mDice did not improve from 0.77386
Epoch 152/300
 - 24s - loss: 1.1625 - acc: 0.9653 - mDice: 0.7482 - val_loss: 1.0657 - val_acc: 0.9780 - val_mDice: 0.7685

Epoch 00152: val_mDice did not improve from 0.77386
Epoch 153/300
 - 22s - loss: 1.1561 - acc: 0.9654 - mDice: 0.7493 - val_loss: 1.0554 - val_acc: 0.9787 - val_mDice: 0.7686

Epoch 00153: val_mDice did not improve from 0.77386
Epoch 154/300
 - 24s - loss: 1.1560 - acc: 0.9654 - mDice: 0.7493 - val_loss: 1.0510 - val_acc: 0.9786 - val_mDice: 0.7689

Epoch 00154: val_mDice did not improve from 0.77386
Epoch 155/300
 - 22s - loss: 1.1557 - acc: 0.9654 - mDice: 0.7492 - val_loss: 1.0407 - val_acc: 0.9788 - val_mDice: 0.7738

Epoch 00155: val_mDice did not improve from 0.77386
Epoch 156/300
 - 23s - loss: 1.1512 - acc: 0.9655 - mDice: 0.7508 - val_loss: 1.0303 - val_acc: 0.9790 - val_mDice: 0.7733

Epoch 00156: val_mDice did not improve from 0.77386
Epoch 157/300
 - 23s - loss: 1.1537 - acc: 0.9654 - mDice: 0.7497 - val_loss: 1.0532 - val_acc: 0.9781 - val_mDice: 0.7746

Epoch 00157: val_mDice improved from 0.77386 to 0.77464, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 158/300
 - 23s - loss: 1.1529 - acc: 0.9655 - mDice: 0.7500 - val_loss: 1.0428 - val_acc: 0.9778 - val_mDice: 0.7747

Epoch 00158: val_mDice improved from 0.77464 to 0.77467, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 159/300
 - 22s - loss: 1.1512 - acc: 0.9655 - mDice: 0.7507 - val_loss: 1.0659 - val_acc: 0.9788 - val_mDice: 0.7706

Epoch 00159: val_mDice did not improve from 0.77467
Epoch 160/300
 - 18s - loss: 1.1513 - acc: 0.9655 - mDice: 0.7505 - val_loss: 1.0451 - val_acc: 0.9790 - val_mDice: 0.7743

Epoch 00160: val_mDice did not improve from 0.77467
Epoch 161/300
 - 19s - loss: 1.1471 - acc: 0.9655 - mDice: 0.7511 - val_loss: 1.0455 - val_acc: 0.9784 - val_mDice: 0.7733

Epoch 00161: val_mDice did not improve from 0.77467
Epoch 162/300
 - 17s - loss: 1.1470 - acc: 0.9655 - mDice: 0.7511 - val_loss: 1.0464 - val_acc: 0.9788 - val_mDice: 0.7755

Epoch 00162: val_mDice improved from 0.77467 to 0.77553, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 163/300
 - 18s - loss: 1.1469 - acc: 0.9655 - mDice: 0.7514 - val_loss: 1.0362 - val_acc: 0.9787 - val_mDice: 0.7719

Epoch 00163: val_mDice did not improve from 0.77553
Epoch 164/300
 - 18s - loss: 1.1435 - acc: 0.9656 - mDice: 0.7519 - val_loss: 1.0312 - val_acc: 0.9786 - val_mDice: 0.7724

Epoch 00164: val_mDice did not improve from 0.77553
Epoch 165/300
 - 17s - loss: 1.1450 - acc: 0.9656 - mDice: 0.7518 - val_loss: 1.0520 - val_acc: 0.9786 - val_mDice: 0.7722

Epoch 00165: val_mDice did not improve from 0.77553
Epoch 166/300
 - 19s - loss: 1.1417 - acc: 0.9656 - mDice: 0.7524 - val_loss: 1.0529 - val_acc: 0.9785 - val_mDice: 0.7737

Epoch 00166: val_mDice did not improve from 0.77553
Epoch 167/300
 - 19s - loss: 1.1437 - acc: 0.9656 - mDice: 0.7518 - val_loss: 1.0435 - val_acc: 0.9783 - val_mDice: 0.7735

Epoch 00167: val_mDice did not improve from 0.77553
Epoch 168/300
 - 21s - loss: 1.1439 - acc: 0.9656 - mDice: 0.7520 - val_loss: 1.0647 - val_acc: 0.9790 - val_mDice: 0.7723

Epoch 00168: val_mDice did not improve from 0.77553
Epoch 169/300
 - 22s - loss: 1.1423 - acc: 0.9656 - mDice: 0.7525 - val_loss: 1.0377 - val_acc: 0.9789 - val_mDice: 0.7734

Epoch 00169: val_mDice did not improve from 0.77553
Epoch 170/300
 - 23s - loss: 1.1412 - acc: 0.9656 - mDice: 0.7527 - val_loss: 1.0493 - val_acc: 0.9785 - val_mDice: 0.7729

Epoch 00170: val_mDice did not improve from 0.77553
Epoch 171/300
 - 22s - loss: 1.1387 - acc: 0.9657 - mDice: 0.7531 - val_loss: 1.0382 - val_acc: 0.9793 - val_mDice: 0.7737

Epoch 00171: val_mDice did not improve from 0.77553
Epoch 172/300
 - 23s - loss: 1.1411 - acc: 0.9656 - mDice: 0.7526 - val_loss: 1.0266 - val_acc: 0.9788 - val_mDice: 0.7740

Epoch 00172: val_mDice did not improve from 0.77553
Epoch 173/300
 - 24s - loss: 1.1393 - acc: 0.9656 - mDice: 0.7530 - val_loss: 1.0456 - val_acc: 0.9791 - val_mDice: 0.7725

Epoch 00173: val_mDice did not improve from 0.77553
Epoch 174/300
 - 21s - loss: 1.1396 - acc: 0.9657 - mDice: 0.7531 - val_loss: 1.0376 - val_acc: 0.9790 - val_mDice: 0.7741

Epoch 00174: val_mDice did not improve from 0.77553
Epoch 175/300
 - 23s - loss: 1.1376 - acc: 0.9657 - mDice: 0.7536 - val_loss: 1.0498 - val_acc: 0.9789 - val_mDice: 0.7730

Epoch 00175: val_mDice did not improve from 0.77553
Epoch 176/300
 - 21s - loss: 1.1354 - acc: 0.9657 - mDice: 0.7538 - val_loss: 1.0486 - val_acc: 0.9788 - val_mDice: 0.7748

Epoch 00176: val_mDice did not improve from 0.77553
Epoch 177/300
 - 22s - loss: 1.1343 - acc: 0.9657 - mDice: 0.7542 - val_loss: 1.0364 - val_acc: 0.9789 - val_mDice: 0.7770

Epoch 00177: val_mDice improved from 0.77553 to 0.77704, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 178/300
 - 21s - loss: 1.1338 - acc: 0.9657 - mDice: 0.7543 - val_loss: 1.0382 - val_acc: 0.9786 - val_mDice: 0.7736

Epoch 00178: val_mDice did not improve from 0.77704
Epoch 179/300
 - 19s - loss: 1.1329 - acc: 0.9657 - mDice: 0.7545 - val_loss: 1.0350 - val_acc: 0.9792 - val_mDice: 0.7757

Epoch 00179: val_mDice did not improve from 0.77704
Epoch 180/300
 - 20s - loss: 1.1320 - acc: 0.9658 - mDice: 0.7548 - val_loss: 1.0389 - val_acc: 0.9784 - val_mDice: 0.7731

Epoch 00180: val_mDice did not improve from 0.77704
Epoch 181/300
 - 18s - loss: 1.1332 - acc: 0.9658 - mDice: 0.7546 - val_loss: 1.0415 - val_acc: 0.9790 - val_mDice: 0.7703

Epoch 00181: val_mDice did not improve from 0.77704
Epoch 182/300
 - 18s - loss: 1.1318 - acc: 0.9658 - mDice: 0.7547 - val_loss: 1.0327 - val_acc: 0.9793 - val_mDice: 0.7785

Epoch 00182: val_mDice improved from 0.77704 to 0.77845, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 183/300
 - 18s - loss: 1.1306 - acc: 0.9658 - mDice: 0.7547 - val_loss: 1.0391 - val_acc: 0.9786 - val_mDice: 0.7756

Epoch 00183: val_mDice did not improve from 0.77845
Epoch 184/300
 - 18s - loss: 1.1286 - acc: 0.9658 - mDice: 0.7554 - val_loss: 1.0471 - val_acc: 0.9780 - val_mDice: 0.7752

Epoch 00184: val_mDice did not improve from 0.77845
Epoch 185/300
 - 17s - loss: 1.1275 - acc: 0.9658 - mDice: 0.7557 - val_loss: 1.0205 - val_acc: 0.9792 - val_mDice: 0.7766

Epoch 00185: val_mDice did not improve from 0.77845
Epoch 186/300
 - 17s - loss: 1.1334 - acc: 0.9658 - mDice: 0.7544 - val_loss: 1.0374 - val_acc: 0.9789 - val_mDice: 0.7773

Epoch 00186: val_mDice did not improve from 0.77845
Epoch 187/300
 - 17s - loss: 1.1300 - acc: 0.9658 - mDice: 0.7552 - val_loss: 1.0406 - val_acc: 0.9792 - val_mDice: 0.7760

Epoch 00187: val_mDice did not improve from 0.77845
Epoch 188/300
 - 18s - loss: 1.1272 - acc: 0.9659 - mDice: 0.7559 - val_loss: 1.0355 - val_acc: 0.9785 - val_mDice: 0.7746

Epoch 00188: val_mDice did not improve from 0.77845
Epoch 189/300
 - 17s - loss: 1.1278 - acc: 0.9659 - mDice: 0.7555 - val_loss: 1.0318 - val_acc: 0.9785 - val_mDice: 0.7765

Epoch 00189: val_mDice did not improve from 0.77845
Epoch 190/300
 - 17s - loss: 1.1281 - acc: 0.9659 - mDice: 0.7557 - val_loss: 1.0356 - val_acc: 0.9791 - val_mDice: 0.7751

Epoch 00190: val_mDice did not improve from 0.77845
Epoch 191/300
 - 17s - loss: 1.1228 - acc: 0.9659 - mDice: 0.7568 - val_loss: 1.0274 - val_acc: 0.9788 - val_mDice: 0.7800

Epoch 00191: val_mDice improved from 0.77845 to 0.77996, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 192/300
 - 17s - loss: 1.1252 - acc: 0.9659 - mDice: 0.7560 - val_loss: 1.0383 - val_acc: 0.9790 - val_mDice: 0.7782

Epoch 00192: val_mDice did not improve from 0.77996
Epoch 193/300
 - 17s - loss: 1.1222 - acc: 0.9659 - mDice: 0.7570 - val_loss: 1.0520 - val_acc: 0.9790 - val_mDice: 0.7755

Epoch 00193: val_mDice did not improve from 0.77996
Epoch 194/300
 - 18s - loss: 1.1236 - acc: 0.9659 - mDice: 0.7565 - val_loss: 1.0313 - val_acc: 0.9792 - val_mDice: 0.7766

Epoch 00194: val_mDice did not improve from 0.77996
Epoch 195/300
 - 17s - loss: 1.1253 - acc: 0.9659 - mDice: 0.7562 - val_loss: 1.0389 - val_acc: 0.9788 - val_mDice: 0.7785

Epoch 00195: val_mDice did not improve from 0.77996
Epoch 196/300
 - 17s - loss: 1.1216 - acc: 0.9659 - mDice: 0.7571 - val_loss: 1.0246 - val_acc: 0.9788 - val_mDice: 0.7773

Epoch 00196: val_mDice did not improve from 0.77996
Epoch 197/300
 - 17s - loss: 1.1221 - acc: 0.9660 - mDice: 0.7572 - val_loss: 1.0499 - val_acc: 0.9788 - val_mDice: 0.7762

Epoch 00197: val_mDice did not improve from 0.77996
Epoch 198/300
 - 17s - loss: 1.1221 - acc: 0.9660 - mDice: 0.7569 - val_loss: 1.0279 - val_acc: 0.9789 - val_mDice: 0.7779

Epoch 00198: val_mDice did not improve from 0.77996
Epoch 199/300
 - 17s - loss: 1.1171 - acc: 0.9660 - mDice: 0.7580 - val_loss: 1.0638 - val_acc: 0.9787 - val_mDice: 0.7749

Epoch 00199: val_mDice did not improve from 0.77996
Epoch 200/300
 - 18s - loss: 1.1217 - acc: 0.9659 - mDice: 0.7572 - val_loss: 1.0320 - val_acc: 0.9793 - val_mDice: 0.7764

Epoch 00200: val_mDice did not improve from 0.77996
Epoch 201/300
 - 17s - loss: 1.1194 - acc: 0.9660 - mDice: 0.7574 - val_loss: 1.0346 - val_acc: 0.9791 - val_mDice: 0.7766

Epoch 00201: val_mDice did not improve from 0.77996
Epoch 202/300
 - 17s - loss: 1.1200 - acc: 0.9660 - mDice: 0.7572 - val_loss: 1.0449 - val_acc: 0.9787 - val_mDice: 0.7759

Epoch 00202: val_mDice did not improve from 0.77996
Epoch 203/300
 - 17s - loss: 1.1160 - acc: 0.9660 - mDice: 0.7580 - val_loss: 1.0425 - val_acc: 0.9788 - val_mDice: 0.7800

Epoch 00203: val_mDice improved from 0.77996 to 0.77997, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 204/300
 - 17s - loss: 1.1183 - acc: 0.9661 - mDice: 0.7580 - val_loss: 1.0284 - val_acc: 0.9791 - val_mDice: 0.7745

Epoch 00204: val_mDice did not improve from 0.77997
Epoch 205/300
 - 17s - loss: 1.1142 - acc: 0.9661 - mDice: 0.7585 - val_loss: 1.0404 - val_acc: 0.9785 - val_mDice: 0.7805

Epoch 00205: val_mDice improved from 0.77997 to 0.78051, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 206/300
 - 18s - loss: 1.1154 - acc: 0.9660 - mDice: 0.7583 - val_loss: 1.0297 - val_acc: 0.9788 - val_mDice: 0.7792

Epoch 00206: val_mDice did not improve from 0.78051
Epoch 207/300
 - 17s - loss: 1.1125 - acc: 0.9661 - mDice: 0.7592 - val_loss: 1.0382 - val_acc: 0.9790 - val_mDice: 0.7770

Epoch 00207: val_mDice did not improve from 0.78051
Epoch 208/300
 - 17s - loss: 1.1129 - acc: 0.9661 - mDice: 0.7591 - val_loss: 1.0511 - val_acc: 0.9788 - val_mDice: 0.7746

Epoch 00208: val_mDice did not improve from 0.78051
Epoch 209/300
 - 17s - loss: 1.1132 - acc: 0.9661 - mDice: 0.7589 - val_loss: 1.0364 - val_acc: 0.9784 - val_mDice: 0.7774

Epoch 00209: val_mDice did not improve from 0.78051
Epoch 210/300
 - 17s - loss: 1.1145 - acc: 0.9661 - mDice: 0.7588 - val_loss: 1.0198 - val_acc: 0.9791 - val_mDice: 0.7766

Epoch 00210: val_mDice did not improve from 0.78051
Epoch 211/300
 - 17s - loss: 1.1144 - acc: 0.9661 - mDice: 0.7587 - val_loss: 1.0137 - val_acc: 0.9792 - val_mDice: 0.7770

Epoch 00211: val_mDice did not improve from 0.78051
Epoch 212/300
 - 18s - loss: 1.1112 - acc: 0.9661 - mDice: 0.7593 - val_loss: 1.0201 - val_acc: 0.9790 - val_mDice: 0.7788

Epoch 00212: val_mDice did not improve from 0.78051
Epoch 213/300
 - 17s - loss: 1.1155 - acc: 0.9660 - mDice: 0.7586 - val_loss: 1.0189 - val_acc: 0.9790 - val_mDice: 0.7789

Epoch 00213: val_mDice did not improve from 0.78051
Epoch 214/300
 - 17s - loss: 1.1096 - acc: 0.9661 - mDice: 0.7598 - val_loss: 1.0413 - val_acc: 0.9791 - val_mDice: 0.7761

Epoch 00214: val_mDice did not improve from 0.78051
Epoch 215/300
 - 17s - loss: 1.1081 - acc: 0.9661 - mDice: 0.7597 - val_loss: 1.0286 - val_acc: 0.9795 - val_mDice: 0.7780

Epoch 00215: val_mDice did not improve from 0.78051
Epoch 216/300
 - 17s - loss: 1.1075 - acc: 0.9662 - mDice: 0.7602 - val_loss: 1.0179 - val_acc: 0.9796 - val_mDice: 0.7785

Epoch 00216: val_mDice did not improve from 0.78051
Epoch 217/300
 - 18s - loss: 1.1078 - acc: 0.9662 - mDice: 0.7606 - val_loss: 1.0191 - val_acc: 0.9794 - val_mDice: 0.7803

Epoch 00217: val_mDice did not improve from 0.78051
Epoch 218/300
 - 17s - loss: 1.1092 - acc: 0.9662 - mDice: 0.7600 - val_loss: 1.0303 - val_acc: 0.9793 - val_mDice: 0.7785

Epoch 00218: val_mDice did not improve from 0.78051
Epoch 219/300
 - 18s - loss: 1.1085 - acc: 0.9662 - mDice: 0.7601 - val_loss: 1.0187 - val_acc: 0.9792 - val_mDice: 0.7779

Epoch 00219: val_mDice did not improve from 0.78051
Epoch 220/300
 - 18s - loss: 1.1073 - acc: 0.9662 - mDice: 0.7602 - val_loss: 1.0197 - val_acc: 0.9796 - val_mDice: 0.7827

Epoch 00220: val_mDice improved from 0.78051 to 0.78270, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 221/300
 - 17s - loss: 1.1032 - acc: 0.9662 - mDice: 0.7610 - val_loss: 1.0225 - val_acc: 0.9794 - val_mDice: 0.7805

Epoch 00221: val_mDice did not improve from 0.78270
Epoch 222/300
 - 18s - loss: 1.1058 - acc: 0.9662 - mDice: 0.7606 - val_loss: 1.0299 - val_acc: 0.9784 - val_mDice: 0.7788

Epoch 00222: val_mDice did not improve from 0.78270
Epoch 223/300
 - 18s - loss: 1.1071 - acc: 0.9662 - mDice: 0.7603 - val_loss: 1.0247 - val_acc: 0.9795 - val_mDice: 0.7769

Epoch 00223: val_mDice did not improve from 0.78270
Epoch 224/300
 - 19s - loss: 1.1045 - acc: 0.9662 - mDice: 0.7611 - val_loss: 1.0076 - val_acc: 0.9794 - val_mDice: 0.7803

Epoch 00224: val_mDice did not improve from 0.78270
Epoch 225/300
 - 17s - loss: 1.1025 - acc: 0.9662 - mDice: 0.7612 - val_loss: 1.0257 - val_acc: 0.9791 - val_mDice: 0.7789

Epoch 00225: val_mDice did not improve from 0.78270
Epoch 226/300
 - 19s - loss: 1.1035 - acc: 0.9663 - mDice: 0.7614 - val_loss: 1.0295 - val_acc: 0.9789 - val_mDice: 0.7785

Epoch 00226: val_mDice did not improve from 0.78270
Epoch 227/300
 - 17s - loss: 1.1021 - acc: 0.9663 - mDice: 0.7614 - val_loss: 1.0213 - val_acc: 0.9792 - val_mDice: 0.7828

Epoch 00227: val_mDice improved from 0.78270 to 0.78280, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 228/300
 - 18s - loss: 1.1004 - acc: 0.9663 - mDice: 0.7614 - val_loss: 1.0205 - val_acc: 0.9795 - val_mDice: 0.7814

Epoch 00228: val_mDice did not improve from 0.78280
Epoch 229/300
 - 18s - loss: 1.1001 - acc: 0.9663 - mDice: 0.7621 - val_loss: 1.0106 - val_acc: 0.9797 - val_mDice: 0.7806

Epoch 00229: val_mDice did not improve from 0.78280
Epoch 230/300
 - 17s - loss: 1.1015 - acc: 0.9663 - mDice: 0.7616 - val_loss: 1.0158 - val_acc: 0.9795 - val_mDice: 0.7756

Epoch 00230: val_mDice did not improve from 0.78280
Epoch 231/300
 - 19s - loss: 1.0995 - acc: 0.9662 - mDice: 0.7620 - val_loss: 1.0281 - val_acc: 0.9784 - val_mDice: 0.7787

Epoch 00231: val_mDice did not improve from 0.78280
Epoch 232/300
 - 17s - loss: 1.1021 - acc: 0.9663 - mDice: 0.7615 - val_loss: 1.0230 - val_acc: 0.9791 - val_mDice: 0.7816

Epoch 00232: val_mDice did not improve from 0.78280
Epoch 233/300
 - 18s - loss: 1.0988 - acc: 0.9663 - mDice: 0.7622 - val_loss: 1.0204 - val_acc: 0.9785 - val_mDice: 0.7828

Epoch 00233: val_mDice did not improve from 0.78280
Epoch 234/300
 - 17s - loss: 1.0973 - acc: 0.9663 - mDice: 0.7624 - val_loss: 1.0162 - val_acc: 0.9785 - val_mDice: 0.7822

Epoch 00234: val_mDice did not improve from 0.78280
Epoch 235/300
 - 17s - loss: 1.0995 - acc: 0.9663 - mDice: 0.7618 - val_loss: 1.0182 - val_acc: 0.9794 - val_mDice: 0.7815

Epoch 00235: val_mDice did not improve from 0.78280
Epoch 236/300
 - 18s - loss: 1.0973 - acc: 0.9664 - mDice: 0.7624 - val_loss: 1.0028 - val_acc: 0.9799 - val_mDice: 0.7836

Epoch 00236: val_mDice improved from 0.78280 to 0.78359, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 237/300
 - 17s - loss: 1.0947 - acc: 0.9664 - mDice: 0.7633 - val_loss: 1.0123 - val_acc: 0.9793 - val_mDice: 0.7803

Epoch 00237: val_mDice did not improve from 0.78359
Epoch 238/300
 - 17s - loss: 1.0973 - acc: 0.9664 - mDice: 0.7624 - val_loss: 1.0355 - val_acc: 0.9787 - val_mDice: 0.7792

Epoch 00238: val_mDice did not improve from 0.78359
Epoch 239/300
 - 17s - loss: 1.0967 - acc: 0.9663 - mDice: 0.7628 - val_loss: 1.0069 - val_acc: 0.9792 - val_mDice: 0.7809

Epoch 00239: val_mDice did not improve from 0.78359
Epoch 240/300
 - 17s - loss: 1.0967 - acc: 0.9663 - mDice: 0.7624 - val_loss: 1.0116 - val_acc: 0.9795 - val_mDice: 0.7812

Epoch 00240: val_mDice did not improve from 0.78359
Epoch 241/300
 - 18s - loss: 1.0952 - acc: 0.9664 - mDice: 0.7627 - val_loss: 1.0184 - val_acc: 0.9794 - val_mDice: 0.7804

Epoch 00241: val_mDice did not improve from 0.78359
Epoch 242/300
 - 17s - loss: 1.0922 - acc: 0.9664 - mDice: 0.7636 - val_loss: 1.0196 - val_acc: 0.9797 - val_mDice: 0.7800

Epoch 00242: val_mDice did not improve from 0.78359
Epoch 243/300
 - 17s - loss: 1.0931 - acc: 0.9664 - mDice: 0.7632 - val_loss: 1.0101 - val_acc: 0.9797 - val_mDice: 0.7834

Epoch 00243: val_mDice did not improve from 0.78359
Epoch 244/300
 - 20s - loss: 1.0949 - acc: 0.9664 - mDice: 0.7631 - val_loss: 1.0210 - val_acc: 0.9794 - val_mDice: 0.7823

Epoch 00244: val_mDice did not improve from 0.78359
Epoch 245/300
 - 19s - loss: 1.0955 - acc: 0.9664 - mDice: 0.7627 - val_loss: 1.0124 - val_acc: 0.9795 - val_mDice: 0.7778

Epoch 00245: val_mDice did not improve from 0.78359
Epoch 246/300
 - 19s - loss: 1.0904 - acc: 0.9664 - mDice: 0.7640 - val_loss: 1.0199 - val_acc: 0.9792 - val_mDice: 0.7814

Epoch 00246: val_mDice did not improve from 0.78359
Epoch 247/300
 - 20s - loss: 1.0937 - acc: 0.9664 - mDice: 0.7632 - val_loss: 1.0061 - val_acc: 0.9797 - val_mDice: 0.7813

Epoch 00247: val_mDice did not improve from 0.78359
Epoch 248/300
 - 19s - loss: 1.0925 - acc: 0.9664 - mDice: 0.7634 - val_loss: 1.0086 - val_acc: 0.9795 - val_mDice: 0.7802

Epoch 00248: val_mDice did not improve from 0.78359
Epoch 249/300
 - 21s - loss: 1.0906 - acc: 0.9664 - mDice: 0.7641 - val_loss: 1.0071 - val_acc: 0.9795 - val_mDice: 0.7817

Epoch 00249: val_mDice did not improve from 0.78359
Epoch 250/300
 - 19s - loss: 1.0913 - acc: 0.9664 - mDice: 0.7639 - val_loss: 1.0173 - val_acc: 0.9797 - val_mDice: 0.7783

Epoch 00250: val_mDice did not improve from 0.78359
Epoch 251/300
 - 20s - loss: 1.0898 - acc: 0.9665 - mDice: 0.7641 - val_loss: 1.0001 - val_acc: 0.9800 - val_mDice: 0.7815

Epoch 00251: val_mDice did not improve from 0.78359
Epoch 252/300
 - 20s - loss: 1.0871 - acc: 0.9665 - mDice: 0.7648 - val_loss: 1.0129 - val_acc: 0.9798 - val_mDice: 0.7802

Epoch 00252: val_mDice did not improve from 0.78359
Epoch 253/300
 - 19s - loss: 1.0857 - acc: 0.9665 - mDice: 0.7651 - val_loss: 1.0024 - val_acc: 0.9794 - val_mDice: 0.7805

Epoch 00253: val_mDice did not improve from 0.78359
Epoch 254/300
 - 20s - loss: 1.0899 - acc: 0.9664 - mDice: 0.7642 - val_loss: 1.0131 - val_acc: 0.9787 - val_mDice: 0.7848

Epoch 00254: val_mDice improved from 0.78359 to 0.78480, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 255/300
 - 20s - loss: 1.0891 - acc: 0.9665 - mDice: 0.7643 - val_loss: 1.0306 - val_acc: 0.9788 - val_mDice: 0.7799

Epoch 00255: val_mDice did not improve from 0.78480
Epoch 256/300
 - 19s - loss: 1.0893 - acc: 0.9664 - mDice: 0.7642 - val_loss: 0.9981 - val_acc: 0.9799 - val_mDice: 0.7813

Epoch 00256: val_mDice did not improve from 0.78480
Epoch 257/300
 - 20s - loss: 1.0893 - acc: 0.9664 - mDice: 0.7641 - val_loss: 1.0034 - val_acc: 0.9791 - val_mDice: 0.7857

Epoch 00257: val_mDice improved from 0.78480 to 0.78568, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 258/300
 - 19s - loss: 1.0872 - acc: 0.9665 - mDice: 0.7647 - val_loss: 0.9932 - val_acc: 0.9799 - val_mDice: 0.7807

Epoch 00258: val_mDice did not improve from 0.78568
Epoch 259/300
 - 19s - loss: 1.0861 - acc: 0.9665 - mDice: 0.7649 - val_loss: 1.0174 - val_acc: 0.9793 - val_mDice: 0.7790

Epoch 00259: val_mDice did not improve from 0.78568
Epoch 260/300
 - 18s - loss: 1.0878 - acc: 0.9665 - mDice: 0.7647 - val_loss: 1.0160 - val_acc: 0.9794 - val_mDice: 0.7843

Epoch 00260: val_mDice did not improve from 0.78568
Epoch 261/300
 - 18s - loss: 1.0872 - acc: 0.9665 - mDice: 0.7650 - val_loss: 1.0509 - val_acc: 0.9794 - val_mDice: 0.7794

Epoch 00261: val_mDice did not improve from 0.78568
Epoch 262/300
 - 17s - loss: 1.0863 - acc: 0.9665 - mDice: 0.7650 - val_loss: 1.0145 - val_acc: 0.9792 - val_mDice: 0.7802

Epoch 00262: val_mDice did not improve from 0.78568
Epoch 263/300
 - 17s - loss: 1.0884 - acc: 0.9665 - mDice: 0.7644 - val_loss: 1.0004 - val_acc: 0.9797 - val_mDice: 0.7841

Epoch 00263: val_mDice did not improve from 0.78568
Epoch 264/300
 - 18s - loss: 1.0838 - acc: 0.9665 - mDice: 0.7653 - val_loss: 1.0036 - val_acc: 0.9798 - val_mDice: 0.7844

Epoch 00264: val_mDice did not improve from 0.78568
Epoch 265/300
 - 17s - loss: 1.0812 - acc: 0.9665 - mDice: 0.7659 - val_loss: 1.0258 - val_acc: 0.9793 - val_mDice: 0.7807

Epoch 00265: val_mDice did not improve from 0.78568
Epoch 266/300
 - 18s - loss: 1.0818 - acc: 0.9666 - mDice: 0.7660 - val_loss: 1.0116 - val_acc: 0.9795 - val_mDice: 0.7785

Epoch 00266: val_mDice did not improve from 0.78568
Epoch 267/300
 - 18s - loss: 1.0846 - acc: 0.9665 - mDice: 0.7654 - val_loss: 1.0028 - val_acc: 0.9792 - val_mDice: 0.7828

Epoch 00267: val_mDice did not improve from 0.78568
Epoch 268/300
 - 18s - loss: 1.0833 - acc: 0.9665 - mDice: 0.7658 - val_loss: 1.0078 - val_acc: 0.9787 - val_mDice: 0.7819

Epoch 00268: val_mDice did not improve from 0.78568
Epoch 269/300
 - 18s - loss: 1.0830 - acc: 0.9665 - mDice: 0.7655 - val_loss: 1.0091 - val_acc: 0.9795 - val_mDice: 0.7821

Epoch 00269: val_mDice did not improve from 0.78568
Epoch 270/300
 - 17s - loss: 1.0811 - acc: 0.9666 - mDice: 0.7661 - val_loss: 1.0054 - val_acc: 0.9798 - val_mDice: 0.7808

Epoch 00270: val_mDice did not improve from 0.78568
Epoch 271/300
 - 19s - loss: 1.0807 - acc: 0.9666 - mDice: 0.7659 - val_loss: 1.0027 - val_acc: 0.9793 - val_mDice: 0.7822

Epoch 00271: val_mDice did not improve from 0.78568
Epoch 272/300
 - 17s - loss: 1.0816 - acc: 0.9666 - mDice: 0.7657 - val_loss: 1.0136 - val_acc: 0.9797 - val_mDice: 0.7826

Epoch 00272: val_mDice did not improve from 0.78568
Epoch 273/300
 - 19s - loss: 1.0836 - acc: 0.9665 - mDice: 0.7654 - val_loss: 1.0053 - val_acc: 0.9796 - val_mDice: 0.7818

Epoch 00273: val_mDice did not improve from 0.78568
Epoch 274/300
 - 17s - loss: 1.0803 - acc: 0.9665 - mDice: 0.7659 - val_loss: 1.0104 - val_acc: 0.9796 - val_mDice: 0.7801

Epoch 00274: val_mDice did not improve from 0.78568
Epoch 275/300
 - 18s - loss: 1.0797 - acc: 0.9666 - mDice: 0.7663 - val_loss: 1.0206 - val_acc: 0.9791 - val_mDice: 0.7834

Epoch 00275: val_mDice did not improve from 0.78568
Epoch 276/300
 - 18s - loss: 1.0798 - acc: 0.9666 - mDice: 0.7662 - val_loss: 0.9995 - val_acc: 0.9793 - val_mDice: 0.7841

Epoch 00276: val_mDice did not improve from 0.78568
Epoch 277/300
 - 17s - loss: 1.0803 - acc: 0.9666 - mDice: 0.7663 - val_loss: 1.0222 - val_acc: 0.9796 - val_mDice: 0.7790

Epoch 00277: val_mDice did not improve from 0.78568
Epoch 278/300
 - 19s - loss: 1.0810 - acc: 0.9666 - mDice: 0.7661 - val_loss: 1.0040 - val_acc: 0.9798 - val_mDice: 0.7810

Epoch 00278: val_mDice did not improve from 0.78568
Epoch 279/300
 - 18s - loss: 1.0804 - acc: 0.9666 - mDice: 0.7662 - val_loss: 1.0196 - val_acc: 0.9793 - val_mDice: 0.7812

Epoch 00279: val_mDice did not improve from 0.78568
Epoch 280/300
 - 18s - loss: 1.0784 - acc: 0.9666 - mDice: 0.7665 - val_loss: 1.0109 - val_acc: 0.9795 - val_mDice: 0.7825

Epoch 00280: val_mDice did not improve from 0.78568
Epoch 281/300
 - 18s - loss: 1.0787 - acc: 0.9665 - mDice: 0.7664 - val_loss: 1.0186 - val_acc: 0.9792 - val_mDice: 0.7825

Epoch 00281: val_mDice did not improve from 0.78568
Epoch 282/300
 - 19s - loss: 1.0794 - acc: 0.9666 - mDice: 0.7667 - val_loss: 1.0125 - val_acc: 0.9797 - val_mDice: 0.7822

Epoch 00282: val_mDice did not improve from 0.78568
Epoch 283/300
 - 18s - loss: 1.0798 - acc: 0.9666 - mDice: 0.7662 - val_loss: 1.0070 - val_acc: 0.9790 - val_mDice: 0.7827

Epoch 00283: val_mDice did not improve from 0.78568
Epoch 284/300
 - 17s - loss: 1.0830 - acc: 0.9666 - mDice: 0.7659 - val_loss: 1.0037 - val_acc: 0.9794 - val_mDice: 0.7822

Epoch 00284: val_mDice did not improve from 0.78568
Epoch 285/300
 - 17s - loss: 1.0773 - acc: 0.9666 - mDice: 0.7667 - val_loss: 1.0081 - val_acc: 0.9796 - val_mDice: 0.7805

Epoch 00285: val_mDice did not improve from 0.78568
Epoch 286/300
 - 19s - loss: 1.0771 - acc: 0.9667 - mDice: 0.7670 - val_loss: 1.0232 - val_acc: 0.9792 - val_mDice: 0.7808

Epoch 00286: val_mDice did not improve from 0.78568
Epoch 287/300
 - 18s - loss: 1.0765 - acc: 0.9666 - mDice: 0.7670 - val_loss: 1.0047 - val_acc: 0.9794 - val_mDice: 0.7810

Epoch 00287: val_mDice did not improve from 0.78568
Restoring model weights from the end of the best epoch
Epoch 00287: early stopping
{'val_loss': [9.679488039603342, 7.136562175616648, 5.4594478741262, 4.656529501159078, 4.062663601655742, 3.678085968238817, 3.189517543269796, 2.539400082690435, 2.1744042773238386, 1.95986785704306, 1.79307768969209, 1.6347438652192772, 1.6175967442339878, 1.5664081022483811, 1.5342005424214582, 1.5025345705096038, 1.4340775109343034, 1.4017272789574675, 1.3846480542620372, 1.3641987180039417, 1.3488078205363403, 1.321634379547803, 1.3283279849271992, 1.2739872972240347, 1.3105461327179035, 1.2966886647765792, 1.2523758678528463, 1.2548040344342197, 1.2421956395432483, 1.2164617830294926, 1.2342191788978443, 1.2434553908338026, 1.2013751460085436, 1.185313479866839, 1.1778971679600345, 1.1725756373053486, 1.1816104781439098, 1.1879304537454682, 1.1557584270861112, 1.1820340562998097, 1.1456438353275373, 1.1464258387344375, 1.173546755460528, 1.1754396926539643, 1.145591318816837, 1.1187572128324392, 1.1439471937231522, 1.1234166344565542, 1.1585401124820138, 1.1350728490231117, 1.1142175838691697, 1.1131385735552004, 1.1154750504895967, 1.1668902309791485, 1.1258358382382585, 1.1125822915762715, 1.0903929466731939, 1.113333173502099, 1.1602378257129649, 1.105650342935418, 1.0995646972857376, 1.12648659148409, 1.1064084046544844, 1.1007921710374695, 1.1053871868574348, 1.1205424844485385, 1.0777803326323498, 1.089009522867957, 1.0937197564565864, 1.1111029604407312, 1.1009288063577274, 1.108661829377729, 1.091857878415991, 1.097272606118073, 1.1025884893112317, 1.1063645097618573, 1.0849559817247105, 1.1086155959717627, 1.084271205854332, 1.091955377473144, 1.0966221889209244, 1.1002120443722905, 1.0849227707289644, 1.0745995657515233, 1.103088285256773, 1.0905102134169928, 1.0921535674214153, 1.0727710264009835, 1.0685880184173584, 1.099883692335789, 1.0911239072392402, 1.088638816231793, 1.0667938780700805, 1.075097803910294, 1.0607372575778324, 1.0862037718610311, 1.0858377949424702, 1.0705807979999402, 1.0781336508442523, 1.0809103611902529, 1.0685343453251415, 1.074222488960608, 1.0803199404153339, 1.1001941928335568, 1.0653252966165123, 1.0615882101503114, 1.0899288997918315, 1.062268865862714, 1.062124589415552, 1.060447298998573, 1.063347934210028, 1.0662747005586675, 1.0537823255326082, 1.0570912782253405, 1.0727015693912607, 1.0580251956446938, 1.0573020579525791, 1.0715645252086994, 1.0626665980199939, 1.0697831906417552, 1.066014031429492, 1.0564912712636858, 1.0542492534448058, 1.047536269746891, 1.0549366229028818, 1.0455051113725338, 1.061677614708148, 1.0699678006825841, 1.0594565872567818, 1.0409154569327517, 1.0504872898435342, 1.0681731186558368, 1.086652876098881, 1.0588631800691775, 1.044346837042086, 1.0677681289783472, 1.0576469361886827, 1.052751043349871, 1.043600825203324, 1.0519820943029567, 1.0554295518486279, 1.0644852815487262, 1.0486367991184309, 1.0575581247442007, 1.0482653467433105, 1.0413424060508112, 1.0550531785810768, 1.0763022541371297, 1.0432454798049793, 1.059259025618984, 1.0477719549973525, 1.0657025596588483, 1.0554138106704807, 1.050969652635142, 1.04067725163143, 1.0303057155625892, 1.0532335170752554, 1.0427894504292359, 1.0659465765701657, 1.045103247639165, 1.045467507964907, 1.046379645595651, 1.0362494582660589, 1.0312456384903517, 1.0520483178916422, 1.052873280220166, 1.043479892511988, 1.0646978385209618, 1.0376765212610441, 1.0492744523318245, 1.038172167298664, 1.0266357466499918, 1.0456143344223814, 1.0376308361340072, 1.0497836606783273, 1.0486497235842873, 1.0364318342326186, 1.0381859208871276, 1.0350444108404886, 1.0388790622536872, 1.0414890977955031, 1.0326696124143886, 1.039118240818198, 1.0471231320411334, 1.0205186770963752, 1.0373763866290475, 1.0406255403595774, 1.0355048291712527, 1.0317583734624625, 1.0355502636235712, 1.0273588773236333, 1.038288856327848, 1.0520189078704754, 1.0313328402951647, 1.038925072011294, 1.0245875288815824, 1.0499082269484212, 1.027930719990722, 1.0638086769618553, 1.0320065555756877, 1.034575429134503, 1.044875418259934, 1.0425207628516615, 1.0284014595623385, 1.040393310921473, 1.0296921901836966, 1.038176771940791, 1.051052688295267, 1.0364464763388272, 1.0197843097425303, 1.013663548262551, 1.020125156441975, 1.018860400665833, 1.0413255029487274, 1.0286078747420822, 1.0178910125118987, 1.0191475808725206, 1.0303489240066448, 1.018674499330705, 1.0197024143224023, 1.0225138167714822, 1.0298957987074693, 1.0246906840947894, 1.007632284675625, 1.0257386606062233, 1.029462078648418, 1.0212882081527912, 1.0205164539164524, 1.0106186311567604, 1.0158403191080412, 1.0280706510602484, 1.0230022739023232, 1.020399480377224, 1.0162112511733714, 1.0181887521685113, 1.0027626775899126, 1.0122973871775796, 1.035499781841553, 1.0068734637044225, 1.011580866543815, 1.0184090006540027, 1.0195501570332868, 1.0101367631151303, 1.0209667788448569, 1.0123807581531143, 1.0198596065408945, 1.0060710681762763, 1.0085644133271148, 1.007129118082184, 1.017312821688258, 1.0001324039142454, 1.0129098224933202, 1.0024284257411118, 1.0130968842858379, 1.0305781810690104, 0.9980538911685374, 1.00338676838967, 0.9931853678607773, 1.0173728671350462, 1.016007009834732, 1.0508799801182873, 1.014508853268749, 1.000353566896308, 1.003623805062842, 1.025775623656744, 1.011584000134929, 1.002823870295171, 1.007783870181635, 1.0090582843195575, 1.0053881898077175, 1.0026848753014013, 1.0135611595294598, 1.0053383485923124, 1.010439608868061, 1.020634602264277, 0.9994502397538908, 1.0222344595434796, 1.0040326667376687, 1.019631421419355, 1.0108718350398729, 1.018624461074286, 1.012508542340753, 1.006994208887298, 1.003695970365159, 1.008125751739227, 1.0231602253729513, 1.0047282245540452], 'val_acc': [0.911152898532016, 0.9111461838435624, 0.9149925153578103, 0.9183333455363979, 0.9219196584396496, 0.9356607073011214, 0.9447536689535385, 0.9515881592862845, 0.9583127809744099, 0.9618179966779082, 0.9657151508415102, 0.9670411042463172, 0.9688804015543423, 0.9692390625003352, 0.969413537132719, 0.9696208970827461, 0.9710223044159123, 0.9709711218341164, 0.9706699898456648, 0.9716241989278207, 0.9714078588938252, 0.9728746618453564, 0.9730121556191537, 0.9733278625669295, 0.9718640555606366, 0.9727980841232728, 0.974647832985293, 0.9723030470167606, 0.9739742038120075, 0.9746037513174785, 0.9739884060589835, 0.9744375022308269, 0.9735680922263535, 0.975372637302888, 0.9748103453111565, 0.9746411172493061, 0.9753562021339296, 0.9754529630991193, 0.9760896005194719, 0.975964072823315, 0.9765708201379893, 0.9752743692515395, 0.9744591631244063, 0.9755265685502171, 0.9758157306899086, 0.9758280737747836, 0.9751615465630128, 0.9766354451908588, 0.9757555928506835, 0.9765013263598478, 0.9765805236484548, 0.9760873603695097, 0.9768711902554719, 0.9764079183392449, 0.9769291076383607, 0.9766455329365387, 0.9773871464972337, 0.976488993226539, 0.9767438065398137, 0.97670568481271, 0.9768562419552794, 0.9770060539874126, 0.9772317262860719, 0.9774663640032334, 0.9764740476499333, 0.9778186864299808, 0.97779402288695, 0.9770142941986111, 0.9773811789095297, 0.9772429571000889, 0.9771372031662712, 0.9776195490925929, 0.9775552707732457, 0.977500371857561, 0.9775190308349623, 0.9768689573334893, 0.9774708510073711, 0.9775298667289252, 0.977204452813824, 0.9774910235656377, 0.9774876515559446, 0.9776273981548571, 0.977516423734085, 0.9776819302243801, 0.9781298965268059, 0.9781205548343423, 0.9776647488974519, 0.9780660057947799, 0.9778201680610804, 0.9771558914746048, 0.9775904052496376, 0.978070877348392, 0.9780637693111842, 0.9779408370882848, 0.97781083307283, 0.9776408301505976, 0.9781429635619446, 0.9773733320470853, 0.9776329900971197, 0.9773524168924623, 0.9783275371486148, 0.9776897730014446, 0.9775672254327731, 0.9776722240950814, 0.9784672668822411, 0.9783450921306711, 0.9779258917211858, 0.9783469662724983, 0.9787549523142394, 0.9787287915318629, 0.9781519493025929, 0.9778556748308072, 0.9781392365432162, 0.978776984034607, 0.9783936722207363, 0.9788924428406834, 0.9787048825270681, 0.9780753368024039, 0.9786966570860891, 0.9779329948349871, 0.9783626583213337, 0.9783645167501613, 0.9788756345403634, 0.9787635272123273, 0.9777144346589154, 0.9787254378540026, 0.9781500606000528, 0.9783286615708591, 0.9781063495495198, 0.9786626577167813, 0.9781063442071, 0.9774476837609062, 0.9782718760477009, 0.978504626843129, 0.9791442396770672, 0.9788819643650826, 0.9781934094135707, 0.9787045042627934, 0.978979868608116, 0.9782431039743138, 0.9786073497393428, 0.9786675257087801, 0.978470251618873, 0.9777809287206989, 0.9787739991932217, 0.978982855544568, 0.9788558136390257, 0.9785670148886361, 0.9784982735536639, 0.9779288898662439, 0.9789118651556005, 0.9780133201074517, 0.9787411306361113, 0.9785935440884743, 0.9787885807520057, 0.9790441263958105, 0.9781362470926844, 0.9777618927360628, 0.9787792254416092, 0.9790426307277645, 0.9784224167439975, 0.9788113626109695, 0.9787179554283933, 0.9786058806786428, 0.9786227003970758, 0.9785326429117334, 0.9783174354707419, 0.979030307441269, 0.9788961757255983, 0.9785397437209614, 0.9792533314709924, 0.9787967930988184, 0.9791378925680486, 0.9789974234854191, 0.9788928104201184, 0.9788199617070766, 0.9788707786997508, 0.9785800921896011, 0.9792365390931784, 0.9783589225033256, 0.9789570725026994, 0.9792907080876597, 0.9785778544489654, 0.9779643784088913, 0.9791830947822343, 0.9789159725336701, 0.9792410194978564, 0.9785128471511948, 0.9784605393091279, 0.9791192096021347, 0.9788210792156011, 0.9789779919522089, 0.9790250729173684, 0.9792346711317977, 0.9787695253880037, 0.9787639149044016, 0.9788255754380318, 0.9789398831097648, 0.978692931429154, 0.9792540784669886, 0.9791285576845514, 0.9787239267872172, 0.9787814729243045, 0.979065416253095, 0.9784975151395546, 0.9788390077480323, 0.9789996653114346, 0.9788307957154795, 0.97837947563044, 0.979141261539895, 0.9792309258859899, 0.9790295436847398, 0.9790347845985935, 0.9790904407761009, 0.9795122589713031, 0.9796037899169855, 0.9793870811512684, 0.9793105017531316, 0.9792186025994942, 0.979615750023686, 0.9794416450658038, 0.9784183209935475, 0.9794917001875088, 0.9793927074526232, 0.9791173439453272, 0.9788928160767982, 0.9792055316884823, 0.9794864748819012, 0.9796960759246706, 0.9794786320000834, 0.9784078557168662, 0.9791199579599243, 0.9784874396500143, 0.9785109673526878, 0.979370674894229, 0.9799381765833219, 0.9793101386780898, 0.9787048857744214, 0.979187966545353, 0.9794887048707905, 0.9793930829933113, 0.9797267064268853, 0.9796553549531893, 0.9793620600851223, 0.9795421441535749, 0.9792245877857577, 0.9796998011625924, 0.9794595786263947, 0.9795298222288725, 0.9797132564135721, 0.9799904818065556, 0.9797808675648667, 0.9793661733293785, 0.9787325312257441, 0.978846476660462, 0.97992846720667, 0.9791453717463046, 0.979916124750315, 0.9792555973902738, 0.9793762569896786, 0.9793986698026607, 0.9792055238319826, 0.9797382946592643, 0.9798189861493706, 0.9792526008165156, 0.9795425208465496, 0.9792264311301059, 0.9786574293733271, 0.9794943244679322, 0.9798074172963577, 0.9793026580332872, 0.9796587168018093, 0.9795645696417099, 0.9795645494243173, 0.9791259371752479, 0.9792794939294222, 0.9796161239930741, 0.9797536128434648, 0.979252976461957, 0.9795443749804907, 0.9792335387483003, 0.9796650712435611, 0.979045997499791, 0.97942558219018, 0.9796400416923952, 0.9791513471905083, 0.979403533185513], 'val_mDice': [0.0072260096993277696, 0.031661444184859736, 0.07693721930151036, 0.11649938841695735, 0.16235674909841408, 0.2290324528418442, 0.3248815125342203, 0.405256135287729, 0.4884900207678756, 0.5436847756742803, 0.5769582215847157, 0.6134221774832016, 0.6234163832580687, 0.6355375886382453, 0.6441534106048423, 0.6527638053014115, 0.6655015907723372, 0.6740700928314289, 0.6811870422430324, 0.6850334487606645, 0.6906367410465368, 0.6946253324015907, 0.696902911776189, 0.7049720479021592, 0.7041797704981584, 0.7058264726285147, 0.7103026468431174, 0.7147467800519169, 0.7186950828572358, 0.7192668799566259, 0.7165019072212527, 0.7220317838690612, 0.7295172214508057, 0.7291290799846548, 0.7302680441910018, 0.7315504877764227, 0.7324615508475077, 0.7335507784870262, 0.7358637005876364, 0.7350776245807722, 0.7357760433153444, 0.7411799933663152, 0.7378336178606969, 0.7387856903939339, 0.7430968659623856, 0.7444440361066527, 0.7400058130807323, 0.7440778995440169, 0.7431555695190162, 0.749043259134611, 0.7497417752897803, 0.7459603466342329, 0.7492428163233457, 0.742271846857557, 0.7524401437628667, 0.748400343532931, 0.7566170661017849, 0.7500874093211598, 0.7458769473752992, 0.7533145330073754, 0.752422002371669, 0.751430478372557, 0.7539367029453203, 0.7514303876561733, 0.7544748803014705, 0.7560871927516113, 0.7548976084888506, 0.7554055014477883, 0.7548597754619243, 0.7577726507857311, 0.7542235767485178, 0.7536378707114758, 0.7608992859642619, 0.7565277666115384, 0.7521439250198525, 0.7544091732514554, 0.7573571814803541, 0.7572546365600479, 0.7567467354303504, 0.761016625092612, 0.7569846431274615, 0.7553956084385488, 0.760604652558144, 0.7599047221282664, 0.7517009577558413, 0.7628552980707902, 0.7578304177428381, 0.7601915512017918, 0.7640575367453228, 0.7559574486291681, 0.7607274390691613, 0.7606551385302954, 0.7624286707549607, 0.7602917077461738, 0.7619865720008085, 0.7646092248717176, 0.7581702768278876, 0.7624323414163975, 0.7604037130444666, 0.7586772291019218, 0.7664578889082522, 0.7641640457411433, 0.7621684002122058, 0.7613375399569426, 0.7609468359100797, 0.7646441870288815, 0.7656559286301919, 0.7658105684290452, 0.7661439798418792, 0.7636424266391144, 0.7647918011266444, 0.7661232229695378, 0.7666037852609094, 0.7668426267292043, 0.7645612919477252, 0.7671422367565243, 0.7665182934494554, 0.7656774152142302, 0.7655699448971003, 0.7629244421823163, 0.7694737488020912, 0.769528888021915, 0.7703542191869136, 0.7663046897819465, 0.7706288237563336, 0.7670903821821162, 0.7649516647645584, 0.7667559833643935, 0.7692544778746754, 0.7685782819305447, 0.768990684686939, 0.7697271795809164, 0.7626030767739134, 0.7667135515615265, 0.769611109748666, 0.766549899309926, 0.7700110181563767, 0.7720485609319382, 0.7719164517935634, 0.7708143172867479, 0.7687122729624931, 0.7674793437620877, 0.7698759247003834, 0.7697357257765919, 0.7719969601748489, 0.7706452696101318, 0.7738617705754111, 0.77070447011656, 0.7705941814110862, 0.7692869529782783, 0.7731021907710861, 0.7685179897896645, 0.7686446100630534, 0.768938684714909, 0.7737758375429311, 0.7732685993970593, 0.7746398812438147, 0.7746691108797472, 0.7706210767238127, 0.7743425570389089, 0.773282788864129, 0.7755313895917735, 0.7719186373670407, 0.7724463989948347, 0.7722028791380683, 0.7736801738688732, 0.7735067254001101, 0.7723322369302303, 0.7734041421400851, 0.7728983048604955, 0.7737397802944552, 0.7739758799490903, 0.7725198279365714, 0.774099683300682, 0.7730212664143272, 0.7747715775493159, 0.7770422593361465, 0.7735735377025101, 0.7756648780172445, 0.7730827371349234, 0.770319915509182, 0.7784549377086083, 0.7755982525947852, 0.775207143676302, 0.7766431072474783, 0.7773036177422334, 0.7759799439793941, 0.7746109396795396, 0.776498743436039, 0.7750543257473642, 0.7799648512645849, 0.7781671493040866, 0.7754509113794471, 0.7766495290456212, 0.7785141781260553, 0.7772853093742277, 0.7762120658358287, 0.7778883280988736, 0.7749416264582603, 0.7763998975653221, 0.776555324794957, 0.7758886930393628, 0.7799658979598584, 0.7744994821364096, 0.7805130860927025, 0.7792084886445312, 0.7770200029198859, 0.7745967931613352, 0.7773511784776443, 0.7765938706682939, 0.7770299475725171, 0.7787700641134292, 0.7789395209565523, 0.7761309983860211, 0.7780164857321339, 0.7785214174191856, 0.780344210944821, 0.7785205995051848, 0.7778894120863327, 0.782695923936807, 0.7805026788493661, 0.7787925118092703, 0.7768979592147318, 0.780307799734843, 0.778885049434454, 0.7785281847985641, 0.7827968243345854, 0.781429154487402, 0.7805966897253831, 0.7756452038753221, 0.7787099013429115, 0.781605421973029, 0.782788348323641, 0.7822313078258494, 0.7814522467304826, 0.7835871774199139, 0.7803290694794881, 0.7792152104562112, 0.7809369727471591, 0.7812139118492918, 0.7803545327094401, 0.779968250614897, 0.7833951064279083, 0.7823113790714887, 0.7777987894567747, 0.7813738391772306, 0.7813250384766524, 0.7801805076783487, 0.7816796149855548, 0.7782502073814245, 0.7814564172748103, 0.7801877593323719, 0.7804782449256347, 0.7847981117731239, 0.7799351437439609, 0.7813439799737847, 0.7856814692644746, 0.7807432380627664, 0.7789641467883842, 0.7843411331227039, 0.7794170227746343, 0.7801707819601773, 0.7841301731149845, 0.7843717978792576, 0.7807451920266311, 0.7785232044062421, 0.7827721505257283, 0.7818687635691598, 0.7820564057998791, 0.7807691842055697, 0.7822333873889568, 0.782611807536576, 0.7817918617402732, 0.7801494802657666, 0.7833920218613529, 0.7840659511529289, 0.7789593289732305, 0.7809644456697474, 0.7811956786941769, 0.7824862420244669, 0.7825229867690476, 0.7821574018374479, 0.7827007660547334, 0.7822453346109977, 0.7805415859121849, 0.7807784473330358, 0.7809959790409136], 'loss': [82.94791842632401, 9.755148246564142, 7.844776642975849, 6.883082524644645, 6.075238293834988, 5.3187883105049325, 4.699012095720262, 4.20412944545144, 3.7651968603075123, 3.3986341458107, 3.1289033997935345, 2.9048285518629156, 2.7190510055618207, 2.587512496985005, 2.4678092004848375, 2.373769761199686, 2.281589462427037, 2.2041363132227336, 2.1452714929546612, 2.077309585278722, 2.0280888453324675, 1.9690532957107933, 1.918543740401336, 1.8634895655788621, 1.83055466384402, 1.800529247381074, 1.7659735053494234, 1.7353847336741508, 1.717244373114874, 1.6914552561224487, 1.669513515986708, 1.655734069957736, 1.6247100507563335, 1.6149696421655626, 1.594245847041447, 1.5688203554989486, 1.5561269181440955, 1.547554651004284, 1.529612827844549, 1.5207368977074294, 1.5023599354743622, 1.4939806079547746, 1.4777781498893494, 1.4677021062810254, 1.4567869708604166, 1.4482241003054162, 1.4381587362410613, 1.4276501896258875, 1.422154904041777, 1.415273503780629, 1.4057953873174276, 1.39765590079855, 1.3887648502999634, 1.3825186111025838, 1.3738155217590897, 1.3685179100795635, 1.3674335844905139, 1.3554086061688064, 1.3534838682595776, 1.3489094628828664, 1.3425088502861497, 1.3371666161836793, 1.3370167626557583, 1.3282236194977743, 1.321012469406103, 1.3213951506238417, 1.3143187138954002, 1.3128950956255192, 1.3052306090673786, 1.3007113619087314, 1.29943463978233, 1.2972473733966625, 1.294766199765151, 1.2844009216559695, 1.2851694305933785, 1.2853686618856524, 1.2796239724223313, 1.277227345965216, 1.2737051572145055, 1.271465324226488, 1.269956188439231, 1.2647416263100342, 1.2611132100150255, 1.2644194373516473, 1.2552865739017733, 1.2567993741943495, 1.250834135211088, 1.2522025222591386, 1.2456675135107262, 1.2449842223637082, 1.2476413133555802, 1.240443497612734, 1.2408047299081273, 1.235902739518434, 1.2323160533588033, 1.2326676933228247, 1.2313802220412118, 1.2330318412185166, 1.2302343707596743, 1.2232610570227191, 1.2245513880704575, 1.2246438816139522, 1.2177577994471018, 1.2139389018372702, 1.2153350392493465, 1.2151935703260934, 1.2108372974471342, 1.2114525056858378, 1.2080085568936527, 1.2053432648923772, 1.2054302493091271, 1.2050580836273477, 1.2007111431631947, 1.2006176278219327, 1.1984032432246259, 1.1997277396601487, 1.1961127662657491, 1.195168112731833, 1.193650461627231, 1.191154925535012, 1.1902396720318758, 1.1916096949366162, 1.1884574984383507, 1.1848164129182812, 1.1822537002497007, 1.184670824216528, 1.1830850720591553, 1.181223591778636, 1.1813553346792578, 1.1791348686384318, 1.1792211207198386, 1.181442430674367, 1.1773284065856, 1.1762642778134131, 1.1765751076610909, 1.1721362186950404, 1.169671072110899, 1.1707638552513908, 1.1682454777540208, 1.1674327245326606, 1.1690362835919081, 1.1666126167172486, 1.165083984026017, 1.164837876363751, 1.161335218496252, 1.1620439200892998, 1.1624507364578356, 1.1597330235227905, 1.15892862329053, 1.1608188375571937, 1.1574568983551168, 1.162456624986397, 1.1561341815281332, 1.155981926545842, 1.1556684428411752, 1.1512146850913922, 1.1537344724061378, 1.1528911240075304, 1.1511665781468992, 1.1513434652863184, 1.1471104240610654, 1.146953284518479, 1.1469212295268647, 1.1435121245763604, 1.144986545341879, 1.1417149780776983, 1.1437438121289998, 1.1439086157202594, 1.1423276206020572, 1.1411961766669354, 1.1386504366481727, 1.1411165563439059, 1.139252588677062, 1.1396385964764892, 1.1375608159763742, 1.1354240869895051, 1.13426258438193, 1.1338482951879154, 1.1329162084914124, 1.13195116676746, 1.133239624439803, 1.1317555786924893, 1.130646092243424, 1.1285674264414083, 1.127534103461945, 1.133429782016007, 1.1300187013504532, 1.1272435141709987, 1.1277508291808955, 1.128052004806877, 1.1228079340381247, 1.1251910198353345, 1.1222398411939072, 1.1236027936907589, 1.1252742207744426, 1.1216285240367616, 1.1221148817673956, 1.1221152903521212, 1.1171230023061196, 1.1216839980655562, 1.1193854443668558, 1.1199632139896076, 1.1160126193037307, 1.1182697455066302, 1.1142148213413892, 1.1153731527994877, 1.1124668604510162, 1.1129338835219325, 1.1132387999235416, 1.1144862266684938, 1.1143922965213784, 1.1111762973977997, 1.1154838974015966, 1.1095538864311638, 1.1081215665100577, 1.107532561002323, 1.1078475302367523, 1.1091638487986282, 1.1085240216939332, 1.1073344130141944, 1.1032476320395586, 1.1058314947553805, 1.107093696811168, 1.1044669664234252, 1.102466811963893, 1.1035007986903136, 1.1020805448298185, 1.1004423372465113, 1.10009983149408, 1.1014736038792279, 1.0994588205693299, 1.1021372252685016, 1.0988373286524558, 1.0972600404086335, 1.099483428984786, 1.0972518541601606, 1.0946790964606663, 1.097268792992719, 1.0966703465663878, 1.0967086895645657, 1.095166251461541, 1.0922122043702054, 1.0930879884820586, 1.0948908462011366, 1.0955023124583816, 1.0904466405283684, 1.0937134124457486, 1.0924747761605724, 1.090560344275672, 1.0913455361815056, 1.0898375214241056, 1.0871178502585601, 1.0856807728993396, 1.0898950820594049, 1.089094506947949, 1.089257160176641, 1.0893334558557104, 1.0872203486296041, 1.0861122234137248, 1.0878183829287063, 1.0871606153838558, 1.0863419692605474, 1.0884070167375448, 1.083765741659455, 1.0812042340179568, 1.081809369731601, 1.0846120463326596, 1.083269873195011, 1.082974087579472, 1.0811289646810174, 1.0806872734641473, 1.0815882847567195, 1.0835510124876337, 1.080330800130655, 1.079705231908187, 1.0798444722968303, 1.080260113977257, 1.080953657411136, 1.0804361157457851, 1.0783609560652903, 1.0787114454685942, 1.0794499284559633, 1.0797791964490295, 1.0829934175598455, 1.077342278349892, 1.0770770477832254, 1.0764686704119883], 'acc': [0.5625330176061776, 0.8936603562316311, 0.8954723410892904, 0.8977771419432807, 0.9029275069094695, 0.9112896901492977, 0.9191373654205194, 0.9252522610213039, 0.9304164581375377, 0.9352009571538671, 0.9389521590621067, 0.9418397786050838, 0.9443448719995851, 0.9461132064150501, 0.9473401903776186, 0.9486897886654289, 0.9498311642473581, 0.9507721147313583, 0.9513525075913916, 0.9522758405519705, 0.9527489106252337, 0.9534507151081004, 0.9540449266470671, 0.9547708580318871, 0.9551568617788824, 0.9555360716162303, 0.9560754130137512, 0.9564536191497953, 0.9566865077940688, 0.9570842804963224, 0.9573479606373237, 0.9575658820336673, 0.9580571473583674, 0.95827271474469, 0.9585049430375299, 0.9588777992645103, 0.9590937872698716, 0.9591366529800675, 0.9594859745750717, 0.9597018869850298, 0.9599273085600176, 0.9600338544046974, 0.9603205000824492, 0.9604523797069052, 0.9606482859652737, 0.960683461296487, 0.9608358356560442, 0.9610104009379354, 0.9611217589600566, 0.9611255670492485, 0.9612842666581487, 0.9614458701299928, 0.9615332017420739, 0.961634847620618, 0.9617530312789392, 0.961852213203874, 0.9617566273848464, 0.9620083662567438, 0.9619673806649979, 0.9619955702274581, 0.9621509516954866, 0.9621572210956584, 0.9621907489858056, 0.9623520173536237, 0.9624212109972382, 0.962424722506004, 0.9625537090570035, 0.9625982778834611, 0.9627092431406389, 0.9627926017166498, 0.9628184808619783, 0.9628491322543455, 0.9628929525087359, 0.9630646035491379, 0.9630699669293132, 0.9630984981588794, 0.9631572946749362, 0.9631450993864401, 0.9632343756469253, 0.9632667186941608, 0.9633199948410486, 0.9633680506127151, 0.9634481261609323, 0.9634395459176885, 0.9635859528537437, 0.9635778304333236, 0.9636446856287356, 0.9636530728010435, 0.9637267826085938, 0.9637404126859648, 0.9637157855081387, 0.9637728495870441, 0.9638193125129916, 0.9638812869485759, 0.963974213355393, 0.963939400862318, 0.9640199267854028, 0.9640027217071662, 0.9639845588751849, 0.9641686880254379, 0.9641276273902113, 0.9641366981187001, 0.9642506568632586, 0.9643074637792124, 0.9643651184693274, 0.964332497124103, 0.9644041001499764, 0.9644023044216969, 0.9645245851187058, 0.9645385167708029, 0.9645415920957118, 0.9645453052452122, 0.9646152311191843, 0.9645975995217361, 0.9646526644198813, 0.9646459782281344, 0.9647172158392306, 0.9647069687236448, 0.9647397583362819, 0.9648174050949605, 0.9648633884841282, 0.9647959759428435, 0.9648826456077145, 0.9649197241241442, 0.9649254798163261, 0.9649591486327188, 0.9649432183697817, 0.9649696947193956, 0.9649609450748982, 0.9650229213912188, 0.9650182668656782, 0.9649692265270257, 0.9650234994041944, 0.9650367185211729, 0.965088778164587, 0.9651251415572609, 0.9651424402193792, 0.9651426357199745, 0.9652316968656139, 0.9652000493308833, 0.9651966926574131, 0.9652039025937429, 0.9652268624072958, 0.9652625191080318, 0.9652909550379569, 0.9652710344553725, 0.9652466298343491, 0.9653569626511808, 0.9653229336722748, 0.9652754521791075, 0.965392030996391, 0.9653163840123892, 0.9653950935430912, 0.9654392095110291, 0.9654085383724299, 0.9655063762757662, 0.9654268203717066, 0.9654773620779012, 0.9655051887452312, 0.9654570992312945, 0.9654932388643345, 0.9655247989523231, 0.9655313012998409, 0.9656039525527766, 0.965553094390942, 0.9656325613484698, 0.9655920048765709, 0.9655628838546803, 0.9656090780992908, 0.9655720621990838, 0.9656866833077938, 0.9656478283653789, 0.9656225359887987, 0.9657115566191175, 0.9657179328253175, 0.965730301126561, 0.9657188418928867, 0.965722158437982, 0.9657486682958988, 0.9657573564460165, 0.9657703109130928, 0.9657838677797265, 0.9658099241192163, 0.9658235887607423, 0.9658398482005361, 0.9657950891257472, 0.9658068138912, 0.9658678038857806, 0.9658661560967634, 0.9658597925787848, 0.9659378121102092, 0.9659006800182895, 0.9659099043942405, 0.9659334831440325, 0.9659141807117974, 0.9659404005493685, 0.9659734732473234, 0.9659733846217468, 0.966006229255671, 0.9659305606447008, 0.966005146728417, 0.9659770127241687, 0.9660155353191713, 0.9660648230361468, 0.9660918055468084, 0.9660315642352794, 0.9660509366807001, 0.9660850231525469, 0.9660797566977848, 0.9660580228063854, 0.9660630580205621, 0.9660996040786304, 0.9660458883943558, 0.966132288571003, 0.9661280301789333, 0.966169388336454, 0.9661649475489521, 0.9661514043514025, 0.9661902176506548, 0.966169462279089, 0.9662014199523452, 0.9661914045302811, 0.9661854141629952, 0.9661720714123474, 0.9662384122548601, 0.9662700172045602, 0.9662581709471378, 0.9662601428167262, 0.9662914335634705, 0.9662633734088703, 0.9662306984401626, 0.9662658010525694, 0.966266784623695, 0.966312443692325, 0.9662968579250976, 0.9663627908367929, 0.9663610026674538, 0.9663757466086863, 0.9663190996243137, 0.9663464333797388, 0.9663688713894367, 0.9664133827739463, 0.9664114252393483, 0.9663986196324051, 0.9663611007267081, 0.9664116719127703, 0.9663939869797984, 0.9664311091881035, 0.9664359211405764, 0.9663729766019787, 0.9664807916017515, 0.9664707680988202, 0.9665334592299398, 0.9664326734058355, 0.9664718185425717, 0.9664441631302356, 0.9664392734106639, 0.9664797860617055, 0.966487780313092, 0.9665340911363609, 0.9664921989037054, 0.9664992483175369, 0.9664584856605405, 0.9665224616285552, 0.9665232969904562, 0.9665753127170266, 0.9665423733443824, 0.9665020722836807, 0.9665163443400607, 0.966571908356241, 0.9665736116944714, 0.9665821898680054, 0.9665038240321251, 0.9665455710041427, 0.9665517117853439, 0.9665852625562839, 0.9665868984099741, 0.9666085188722737, 0.9665780414615182, 0.9666120702604494, 0.9665428548008931, 0.9666029777220179, 0.9665807824202977, 0.9665638314334432, 0.9665610197625758, 0.9666809460086255, 0.9666449803931922], 'mDice': [0.01941067037035244, 0.04528682948693848, 0.064309652565344, 0.08371477856707918, 0.1125540378967077, 0.16024716084235377, 0.2170270844393375, 0.26928483834534706, 0.3210626807431079, 0.3722099249324911, 0.41111623329153046, 0.4445388673293225, 0.4720218442753501, 0.4930453482625541, 0.5125314548801364, 0.527751910165166, 0.5431515658233518, 0.5558380947626085, 0.5654300581430443, 0.576849599530332, 0.5845336190023994, 0.5943226305511335, 0.6027996402778825, 0.6124683651810869, 0.6184593618417037, 0.6241947213198781, 0.6307978894898795, 0.635930509087568, 0.6392429207082928, 0.6441739821048875, 0.6480315914572075, 0.6507860695456086, 0.6564739917174216, 0.6589321716911245, 0.6626156251381679, 0.6675258195698396, 0.6699007527888569, 0.6719663422118854, 0.674846169084219, 0.6775372161832119, 0.6803988272239935, 0.6817631247832979, 0.6848028306122137, 0.6872634410702176, 0.6888286099988941, 0.6909622039272275, 0.6927164358165483, 0.6948583137736479, 0.6965539195410265, 0.6974787279587796, 0.6997337753150863, 0.7008070210182854, 0.7031845656412428, 0.7042275127356225, 0.7057194048730496, 0.7068551080671196, 0.7066276946753394, 0.7093220141626173, 0.7097588654559354, 0.710390873598672, 0.7118822479186856, 0.7129760134094741, 0.7126248596862929, 0.7146304108393305, 0.71562036694185, 0.7160849204379451, 0.7171498779039679, 0.7174450321740073, 0.7189655230105431, 0.7197186846712936, 0.7204806954995908, 0.7208849869990563, 0.7213030138551352, 0.7231015307716956, 0.7229249419314615, 0.7229293450652416, 0.7240415558854117, 0.7244800843306309, 0.7251067172508524, 0.7255765021816185, 0.7258729746978696, 0.7268356864114369, 0.7276391723208648, 0.7269565828384892, 0.7289671774365498, 0.7280853062749635, 0.7296469953014436, 0.72950038589677, 0.7303901412791667, 0.730899892106617, 0.730478499452347, 0.7316957157191258, 0.7318121633138038, 0.7325533602307411, 0.7333357564444679, 0.7331812208248705, 0.7335411347990625, 0.7329920673549136, 0.7337715426770833, 0.7350500353382959, 0.7349008762070364, 0.7348422268533508, 0.7362371239512912, 0.7372885008390042, 0.7368585910316466, 0.7368552724078428, 0.7376823637603208, 0.7375953755551019, 0.7383787562818221, 0.7387635476077714, 0.7387296556916524, 0.7389118848302441, 0.7399929373111094, 0.7400679476853496, 0.7401416729707302, 0.740112340277511, 0.7409003883739715, 0.7408486573584913, 0.7411327856871186, 0.7420656256860254, 0.74206395184566, 0.741553434109713, 0.7422546494271673, 0.7432211938144804, 0.7435669312988961, 0.7435302079626781, 0.7434389817265354, 0.7438364203176239, 0.7437806767946065, 0.7444729327939548, 0.74437512255874, 0.7437847114300417, 0.744733041140641, 0.7450018985109117, 0.7449031200774164, 0.7461278679554334, 0.7461883784072352, 0.746083656240917, 0.7467240688995305, 0.7469230767351279, 0.7465233390563196, 0.7468015567374862, 0.7474550126177346, 0.7471195086668089, 0.7479410970356809, 0.7480380436319582, 0.7479002581683675, 0.74854708249421, 0.7487309985753304, 0.7481993945662025, 0.7490540106063412, 0.7482303096726031, 0.74926130507434, 0.7492771526298707, 0.7492360487767024, 0.750776045323978, 0.7496910412120421, 0.7500100592219243, 0.7507429435181033, 0.7505256491028712, 0.751101888280157, 0.751135718617908, 0.7514396057827928, 0.751857143278469, 0.7517610277666923, 0.752389900139993, 0.7518112189120276, 0.7520407423280301, 0.7524572511958966, 0.7526866102019456, 0.7531208041557625, 0.7526278943565806, 0.7529817139950608, 0.7530725759022742, 0.75363324787673, 0.7538373442500295, 0.754238214912019, 0.7542827152070831, 0.7544621431823346, 0.7547530805444893, 0.7546299004745521, 0.7546689205888137, 0.7546937181967494, 0.7554436697764807, 0.7556581167898543, 0.7543864857088031, 0.7551832926014782, 0.7559317845438178, 0.7555365215837551, 0.7556702133951835, 0.7567969595178325, 0.756015054608236, 0.7569907919089104, 0.7565290707027922, 0.7562369998325298, 0.7570809670443935, 0.7571809325254916, 0.7569375868790535, 0.7579503710475939, 0.7572065854875258, 0.757401938563438, 0.757173388397008, 0.7579770507836977, 0.758011079474644, 0.7585148067714571, 0.7582937386122187, 0.7592389542463411, 0.7591020298840433, 0.7588667654498019, 0.7587879061770904, 0.7587068986655133, 0.7593445128454103, 0.7585678339772409, 0.75982927990802, 0.7597371739431954, 0.7601693895003389, 0.7605612719912671, 0.759973865931326, 0.7601293756733735, 0.7601827153633539, 0.7610059509543227, 0.7605929263890356, 0.7603275043412103, 0.7611341125309651, 0.7612101844534002, 0.7613569295290558, 0.7613815442166326, 0.7614072110487227, 0.7621082180843735, 0.7615504928968446, 0.7619781807956635, 0.7615436386416563, 0.7621623362432302, 0.7623655965167319, 0.7617751232487441, 0.7624371909098154, 0.7632531167984393, 0.7623541627314903, 0.762780348677849, 0.7623516956793153, 0.7626571882791544, 0.7636498122287021, 0.7632411774700634, 0.7630663740155585, 0.7627218406013595, 0.7639965730226728, 0.7631700398919447, 0.7633875068999831, 0.7641296775104307, 0.7639041308229807, 0.7641243598558457, 0.764793282438012, 0.7651343994631116, 0.76424708316781, 0.7643473702938206, 0.7642400242663084, 0.7641228800582799, 0.7647476234143756, 0.7648614479247507, 0.764711480982728, 0.7650289990168729, 0.764989066226548, 0.7644005630344001, 0.7653489924930169, 0.7658907257432541, 0.7659806371707032, 0.7654474912097221, 0.7657753825757603, 0.7654882161800013, 0.7661256139372359, 0.7659071269881701, 0.7657080015600565, 0.7654493727889672, 0.7659306053360361, 0.7662646373722911, 0.766160059515744, 0.766311702802781, 0.766129701842204, 0.7661617530753452, 0.7665413866422958, 0.766416467944075, 0.7667308981360658, 0.7661723208249854, 0.7658953843962162, 0.7666683209499735, 0.76699326235253, 0.7670239504267553]}
predicting test subjects:   0%|          | 0/15 [00:00<?, ?it/s]predicting test subjects:   7%|▋         | 1/15 [00:02<00:30,  2.17s/it]predicting test subjects:  13%|█▎        | 2/15 [00:03<00:26,  2.05s/it]predicting test subjects:  20%|██        | 3/15 [00:05<00:24,  2.03s/it]predicting test subjects:  27%|██▋       | 4/15 [00:07<00:22,  2.01s/it]predicting test subjects:  33%|███▎      | 5/15 [00:10<00:21,  2.12s/it]predicting test subjects:  40%|████      | 6/15 [00:12<00:19,  2.18s/it]predicting test subjects:  47%|████▋     | 7/15 [00:14<00:16,  2.01s/it]predicting test subjects:  53%|█████▎    | 8/15 [00:16<00:15,  2.19s/it]predicting test subjects:  60%|██████    | 9/15 [00:18<00:13,  2.19s/it]predicting test subjects:  67%|██████▋   | 10/15 [00:20<00:10,  2.03s/it]predicting test subjects:  73%|███████▎  | 11/15 [00:22<00:07,  1.96s/it]predicting test subjects:  80%|████████  | 12/15 [00:24<00:06,  2.02s/it]predicting test subjects:  87%|████████▋ | 13/15 [00:26<00:04,  2.10s/it]predicting test subjects:  93%|█████████▎| 14/15 [00:28<00:02,  2.03s/it]predicting test subjects: 100%|██████████| 15/15 [00:30<00:00,  2.04s/it]
predicting train subjects:   0%|          | 0/532 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/532 [00:02<21:10,  2.39s/it]predicting train subjects:   0%|          | 2/532 [00:04<19:32,  2.21s/it]predicting train subjects:   1%|          | 3/532 [00:06<18:39,  2.12s/it]predicting train subjects:   1%|          | 4/532 [00:07<17:56,  2.04s/it]predicting train subjects:   1%|          | 5/532 [00:09<17:35,  2.00s/it]predicting train subjects:   1%|          | 6/532 [00:11<17:00,  1.94s/it]predicting train subjects:   1%|▏         | 7/532 [00:13<16:42,  1.91s/it]predicting train subjects:   2%|▏         | 8/532 [00:15<16:26,  1.88s/it]predicting train subjects:   2%|▏         | 9/532 [00:17<17:17,  1.98s/it]predicting train subjects:   2%|▏         | 10/532 [00:19<16:48,  1.93s/it]predicting train subjects:   2%|▏         | 11/532 [00:21<16:17,  1.88s/it]predicting train subjects:   2%|▏         | 12/532 [00:23<17:41,  2.04s/it]predicting train subjects:   2%|▏         | 13/532 [00:25<16:32,  1.91s/it]predicting train subjects:   3%|▎         | 14/532 [00:26<15:33,  1.80s/it]predicting train subjects:   3%|▎         | 15/532 [00:28<16:19,  1.89s/it]predicting train subjects:   3%|▎         | 16/532 [00:30<16:28,  1.92s/it]predicting train subjects:   3%|▎         | 17/532 [00:32<15:40,  1.83s/it]predicting train subjects:   3%|▎         | 18/532 [00:34<16:20,  1.91s/it]predicting train subjects:   4%|▎         | 19/532 [00:36<15:36,  1.83s/it]predicting train subjects:   4%|▍         | 20/532 [00:38<15:56,  1.87s/it]predicting train subjects:   4%|▍         | 21/532 [00:40<16:58,  1.99s/it]predicting train subjects:   4%|▍         | 22/532 [00:42<16:27,  1.94s/it]predicting train subjects:   4%|▍         | 23/532 [00:44<16:33,  1.95s/it]predicting train subjects:   5%|▍         | 24/532 [00:45<15:41,  1.85s/it]predicting train subjects:   5%|▍         | 25/532 [00:47<16:33,  1.96s/it]predicting train subjects:   5%|▍         | 26/532 [00:49<16:02,  1.90s/it]predicting train subjects:   5%|▌         | 27/532 [00:52<17:06,  2.03s/it]predicting train subjects:   5%|▌         | 28/532 [00:53<16:39,  1.98s/it]predicting train subjects:   5%|▌         | 29/532 [00:56<17:01,  2.03s/it]predicting train subjects:   6%|▌         | 30/532 [00:57<16:06,  1.92s/it]predicting train subjects:   6%|▌         | 31/532 [00:59<15:47,  1.89s/it]predicting train subjects:   6%|▌         | 32/532 [01:01<15:40,  1.88s/it]predicting train subjects:   6%|▌         | 33/532 [01:03<15:19,  1.84s/it]predicting train subjects:   6%|▋         | 34/532 [01:05<16:28,  1.99s/it]predicting train subjects:   7%|▋         | 35/532 [01:07<16:06,  1.94s/it]predicting train subjects:   7%|▋         | 36/532 [01:09<16:08,  1.95s/it]predicting train subjects:   7%|▋         | 37/532 [01:11<16:01,  1.94s/it]predicting train subjects:   7%|▋         | 38/532 [01:13<16:34,  2.01s/it]predicting train subjects:   7%|▋         | 39/532 [01:15<16:11,  1.97s/it]predicting train subjects:   8%|▊         | 40/532 [01:17<15:35,  1.90s/it]predicting train subjects:   8%|▊         | 41/532 [01:19<15:46,  1.93s/it]predicting train subjects:   8%|▊         | 42/532 [01:21<15:52,  1.94s/it]predicting train subjects:   8%|▊         | 43/532 [01:22<15:03,  1.85s/it]predicting train subjects:   8%|▊         | 44/532 [01:24<14:18,  1.76s/it]predicting train subjects:   8%|▊         | 45/532 [01:26<14:57,  1.84s/it]predicting train subjects:   9%|▊         | 46/532 [01:28<16:41,  2.06s/it]predicting train subjects:   9%|▉         | 47/532 [01:31<19:05,  2.36s/it]predicting train subjects:   9%|▉         | 48/532 [01:34<19:39,  2.44s/it]predicting train subjects:   9%|▉         | 49/532 [01:36<18:36,  2.31s/it]predicting train subjects:   9%|▉         | 50/532 [01:39<19:23,  2.41s/it]predicting train subjects:  10%|▉         | 51/532 [01:41<19:47,  2.47s/it]predicting train subjects:  10%|▉         | 52/532 [01:44<19:17,  2.41s/it]predicting train subjects:  10%|▉         | 53/532 [01:46<19:33,  2.45s/it]predicting train subjects:  10%|█         | 54/532 [01:49<20:23,  2.56s/it]predicting train subjects:  10%|█         | 55/532 [01:52<21:29,  2.70s/it]predicting train subjects:  11%|█         | 56/532 [01:54<21:03,  2.65s/it]predicting train subjects:  11%|█         | 57/532 [01:57<20:09,  2.55s/it]predicting train subjects:  11%|█         | 58/532 [01:59<20:18,  2.57s/it]predicting train subjects:  11%|█         | 59/532 [02:02<21:04,  2.67s/it]predicting train subjects:  11%|█▏        | 60/532 [02:05<20:30,  2.61s/it]predicting train subjects:  11%|█▏        | 61/532 [02:07<18:47,  2.39s/it]predicting train subjects:  12%|█▏        | 62/532 [02:10<20:01,  2.56s/it]predicting train subjects:  12%|█▏        | 63/532 [02:13<21:05,  2.70s/it]predicting train subjects:  12%|█▏        | 64/532 [02:15<20:07,  2.58s/it]predicting train subjects:  12%|█▏        | 65/532 [02:17<19:39,  2.53s/it]predicting train subjects:  12%|█▏        | 66/532 [02:21<22:18,  2.87s/it]predicting train subjects:  13%|█▎        | 67/532 [02:24<22:39,  2.92s/it]predicting train subjects:  13%|█▎        | 68/532 [02:27<21:50,  2.82s/it]predicting train subjects:  13%|█▎        | 69/532 [02:29<20:34,  2.67s/it]predicting train subjects:  13%|█▎        | 70/532 [02:31<19:16,  2.50s/it]predicting train subjects:  13%|█▎        | 71/532 [02:33<17:48,  2.32s/it]predicting train subjects:  14%|█▎        | 72/532 [02:35<17:16,  2.25s/it]predicting train subjects:  14%|█▎        | 73/532 [02:38<19:33,  2.56s/it]predicting train subjects:  14%|█▍        | 74/532 [02:41<20:47,  2.72s/it]predicting train subjects:  14%|█▍        | 75/532 [02:45<23:13,  3.05s/it]predicting train subjects:  14%|█▍        | 76/532 [02:47<21:05,  2.78s/it]predicting train subjects:  14%|█▍        | 77/532 [02:50<20:33,  2.71s/it]predicting train subjects:  15%|█▍        | 78/532 [02:52<19:53,  2.63s/it]predicting train subjects:  15%|█▍        | 79/532 [02:55<20:09,  2.67s/it]predicting train subjects:  15%|█▌        | 80/532 [02:58<20:01,  2.66s/it]predicting train subjects:  15%|█▌        | 81/532 [03:00<19:15,  2.56s/it]predicting train subjects:  15%|█▌        | 82/532 [03:03<20:19,  2.71s/it]predicting train subjects:  16%|█▌        | 83/532 [03:06<19:48,  2.65s/it]predicting train subjects:  16%|█▌        | 84/532 [03:08<18:23,  2.46s/it]predicting train subjects:  16%|█▌        | 85/532 [03:10<17:33,  2.36s/it]predicting train subjects:  16%|█▌        | 86/532 [03:12<17:36,  2.37s/it]predicting train subjects:  16%|█▋        | 87/532 [03:14<16:52,  2.28s/it]predicting train subjects:  17%|█▋        | 88/532 [03:16<16:45,  2.26s/it]predicting train subjects:  17%|█▋        | 89/532 [03:19<16:35,  2.25s/it]predicting train subjects:  17%|█▋        | 90/532 [03:21<16:25,  2.23s/it]predicting train subjects:  17%|█▋        | 91/532 [03:23<16:52,  2.30s/it]predicting train subjects:  17%|█▋        | 92/532 [03:26<16:37,  2.27s/it]predicting train subjects:  17%|█▋        | 93/532 [03:28<17:22,  2.37s/it]predicting train subjects:  18%|█▊        | 94/532 [03:31<17:58,  2.46s/it]predicting train subjects:  18%|█▊        | 95/532 [03:33<18:15,  2.51s/it]predicting train subjects:  18%|█▊        | 96/532 [03:36<18:36,  2.56s/it]predicting train subjects:  18%|█▊        | 97/532 [03:39<18:39,  2.57s/it]predicting train subjects:  18%|█▊        | 98/532 [03:42<19:28,  2.69s/it]predicting train subjects:  19%|█▊        | 99/532 [03:44<19:13,  2.66s/it]predicting train subjects:  19%|█▉        | 100/532 [03:47<20:13,  2.81s/it]predicting train subjects:  19%|█▉        | 101/532 [03:49<18:35,  2.59s/it]predicting train subjects:  19%|█▉        | 102/532 [03:52<17:35,  2.45s/it]predicting train subjects:  19%|█▉        | 103/532 [03:54<18:01,  2.52s/it]predicting train subjects:  20%|█▉        | 104/532 [03:56<16:47,  2.35s/it]predicting train subjects:  20%|█▉        | 105/532 [03:58<16:08,  2.27s/it]predicting train subjects:  20%|█▉        | 106/532 [04:00<15:49,  2.23s/it]predicting train subjects:  20%|██        | 107/532 [04:02<15:02,  2.12s/it]predicting train subjects:  20%|██        | 108/532 [04:04<14:51,  2.10s/it]predicting train subjects:  20%|██        | 109/532 [04:06<14:27,  2.05s/it]predicting train subjects:  21%|██        | 110/532 [04:08<14:11,  2.02s/it]predicting train subjects:  21%|██        | 111/532 [04:10<14:02,  2.00s/it]predicting train subjects:  21%|██        | 112/532 [04:12<13:48,  1.97s/it]predicting train subjects:  21%|██        | 113/532 [04:15<14:47,  2.12s/it]predicting train subjects:  21%|██▏       | 114/532 [04:17<15:30,  2.23s/it]predicting train subjects:  22%|██▏       | 115/532 [04:19<15:26,  2.22s/it]predicting train subjects:  22%|██▏       | 116/532 [04:22<16:17,  2.35s/it]predicting train subjects:  22%|██▏       | 117/532 [04:25<16:58,  2.45s/it]predicting train subjects:  22%|██▏       | 118/532 [04:27<17:03,  2.47s/it]predicting train subjects:  22%|██▏       | 119/532 [04:29<16:38,  2.42s/it]predicting train subjects:  23%|██▎       | 120/532 [04:32<16:46,  2.44s/it]predicting train subjects:  23%|██▎       | 121/532 [04:34<16:25,  2.40s/it]predicting train subjects:  23%|██▎       | 122/532 [04:36<15:43,  2.30s/it]predicting train subjects:  23%|██▎       | 123/532 [04:39<15:58,  2.34s/it]predicting train subjects:  23%|██▎       | 124/532 [04:41<15:39,  2.30s/it]predicting train subjects:  23%|██▎       | 125/532 [04:44<16:20,  2.41s/it]predicting train subjects:  24%|██▎       | 126/532 [04:46<16:45,  2.48s/it]predicting train subjects:  24%|██▍       | 127/532 [04:49<16:42,  2.48s/it]predicting train subjects:  24%|██▍       | 128/532 [04:52<17:35,  2.61s/it]predicting train subjects:  24%|██▍       | 129/532 [04:54<17:40,  2.63s/it]predicting train subjects:  24%|██▍       | 130/532 [04:57<17:18,  2.58s/it]predicting train subjects:  25%|██▍       | 131/532 [05:00<17:33,  2.63s/it]predicting train subjects:  25%|██▍       | 132/532 [05:03<19:33,  2.93s/it]predicting train subjects:  25%|██▌       | 133/532 [05:06<19:02,  2.86s/it]predicting train subjects:  25%|██▌       | 134/532 [05:09<19:44,  2.98s/it]predicting train subjects:  25%|██▌       | 135/532 [05:12<19:45,  2.99s/it]predicting train subjects:  26%|██▌       | 136/532 [05:15<19:46,  3.00s/it]predicting train subjects:  26%|██▌       | 137/532 [05:18<19:45,  3.00s/it]predicting train subjects:  26%|██▌       | 138/532 [05:21<20:00,  3.05s/it]predicting train subjects:  26%|██▌       | 139/532 [05:25<20:29,  3.13s/it]predicting train subjects:  26%|██▋       | 140/532 [05:28<20:35,  3.15s/it]predicting train subjects:  27%|██▋       | 141/532 [05:31<20:42,  3.18s/it]predicting train subjects:  27%|██▋       | 142/532 [05:34<20:45,  3.19s/it]predicting train subjects:  27%|██▋       | 143/532 [05:37<19:07,  2.95s/it]predicting train subjects:  27%|██▋       | 144/532 [05:39<18:12,  2.82s/it]predicting train subjects:  27%|██▋       | 145/532 [05:41<16:49,  2.61s/it]predicting train subjects:  27%|██▋       | 146/532 [05:43<15:41,  2.44s/it]predicting train subjects:  28%|██▊       | 147/532 [05:46<15:53,  2.48s/it]predicting train subjects:  28%|██▊       | 148/532 [05:49<16:26,  2.57s/it]predicting train subjects:  28%|██▊       | 149/532 [05:51<15:35,  2.44s/it]predicting train subjects:  28%|██▊       | 150/532 [05:53<15:41,  2.46s/it]predicting train subjects:  28%|██▊       | 151/532 [05:56<16:01,  2.52s/it]predicting train subjects:  29%|██▊       | 152/532 [05:59<16:07,  2.55s/it]predicting train subjects:  29%|██▉       | 153/532 [06:01<15:14,  2.41s/it]predicting train subjects:  29%|██▉       | 154/532 [06:03<14:48,  2.35s/it]predicting train subjects:  29%|██▉       | 155/532 [06:06<16:09,  2.57s/it]predicting train subjects:  29%|██▉       | 156/532 [06:09<17:01,  2.72s/it]predicting train subjects:  30%|██▉       | 157/532 [06:12<18:10,  2.91s/it]predicting train subjects:  30%|██▉       | 158/532 [06:16<18:31,  2.97s/it]predicting train subjects:  30%|██▉       | 159/532 [06:19<18:57,  3.05s/it]predicting train subjects:  30%|███       | 160/532 [06:22<18:49,  3.04s/it]predicting train subjects:  30%|███       | 161/532 [06:24<17:15,  2.79s/it]predicting train subjects:  30%|███       | 162/532 [06:26<16:14,  2.63s/it]predicting train subjects:  31%|███       | 163/532 [06:28<15:05,  2.45s/it]predicting train subjects:  31%|███       | 164/532 [06:30<14:30,  2.37s/it]predicting train subjects:  31%|███       | 165/532 [06:33<15:05,  2.47s/it]predicting train subjects:  31%|███       | 166/532 [06:35<14:30,  2.38s/it]predicting train subjects:  31%|███▏      | 167/532 [06:38<14:49,  2.44s/it]predicting train subjects:  32%|███▏      | 168/532 [06:41<16:00,  2.64s/it]predicting train subjects:  32%|███▏      | 169/532 [06:44<15:46,  2.61s/it]predicting train subjects:  32%|███▏      | 170/532 [06:46<15:24,  2.55s/it]predicting train subjects:  32%|███▏      | 171/532 [06:49<16:18,  2.71s/it]predicting train subjects:  32%|███▏      | 172/532 [06:52<16:04,  2.68s/it]predicting train subjects:  33%|███▎      | 173/532 [06:54<15:24,  2.57s/it]predicting train subjects:  33%|███▎      | 174/532 [06:56<14:55,  2.50s/it]predicting train subjects:  33%|███▎      | 175/532 [06:59<14:18,  2.40s/it]predicting train subjects:  33%|███▎      | 176/532 [07:01<13:41,  2.31s/it]predicting train subjects:  33%|███▎      | 177/532 [07:03<13:29,  2.28s/it]predicting train subjects:  33%|███▎      | 178/532 [07:05<13:40,  2.32s/it]predicting train subjects:  34%|███▎      | 179/532 [07:08<13:43,  2.33s/it]predicting train subjects:  34%|███▍      | 180/532 [07:10<14:16,  2.43s/it]predicting train subjects:  34%|███▍      | 181/532 [07:13<14:05,  2.41s/it]predicting train subjects:  34%|███▍      | 182/532 [07:15<14:20,  2.46s/it]predicting train subjects:  34%|███▍      | 183/532 [07:18<14:10,  2.44s/it]predicting train subjects:  35%|███▍      | 184/532 [07:20<14:26,  2.49s/it]predicting train subjects:  35%|███▍      | 185/532 [07:22<13:27,  2.33s/it]predicting train subjects:  35%|███▍      | 186/532 [07:24<13:15,  2.30s/it]predicting train subjects:  35%|███▌      | 187/532 [07:26<12:52,  2.24s/it]predicting train subjects:  35%|███▌      | 188/532 [07:29<12:34,  2.19s/it]predicting train subjects:  36%|███▌      | 189/532 [07:31<13:11,  2.31s/it]predicting train subjects:  36%|███▌      | 190/532 [07:33<12:55,  2.27s/it]predicting train subjects:  36%|███▌      | 191/532 [07:36<13:53,  2.44s/it]predicting train subjects:  36%|███▌      | 192/532 [07:40<16:00,  2.83s/it]predicting train subjects:  36%|███▋      | 193/532 [07:43<16:41,  2.95s/it]predicting train subjects:  36%|███▋      | 194/532 [07:46<16:11,  2.88s/it]predicting train subjects:  37%|███▋      | 195/532 [07:49<17:05,  3.04s/it]predicting train subjects:  37%|███▋      | 196/532 [07:52<16:47,  3.00s/it]predicting train subjects:  37%|███▋      | 197/532 [07:54<15:14,  2.73s/it]predicting train subjects:  37%|███▋      | 198/532 [07:56<14:07,  2.54s/it]predicting train subjects:  37%|███▋      | 199/532 [07:58<13:14,  2.39s/it]predicting train subjects:  38%|███▊      | 200/532 [08:00<12:41,  2.29s/it]predicting train subjects:  38%|███▊      | 201/532 [08:03<12:18,  2.23s/it]predicting train subjects:  38%|███▊      | 202/532 [08:05<12:03,  2.19s/it]predicting train subjects:  38%|███▊      | 203/532 [08:07<11:38,  2.12s/it]predicting train subjects:  38%|███▊      | 204/532 [08:08<11:07,  2.03s/it]predicting train subjects:  39%|███▊      | 205/532 [08:10<10:45,  1.97s/it]predicting train subjects:  39%|███▊      | 206/532 [08:12<10:44,  1.98s/it]predicting train subjects:  39%|███▉      | 207/532 [08:14<10:29,  1.94s/it]predicting train subjects:  39%|███▉      | 208/532 [08:16<10:11,  1.89s/it]predicting train subjects:  39%|███▉      | 209/532 [08:17<09:45,  1.81s/it]predicting train subjects:  39%|███▉      | 210/532 [08:19<09:12,  1.72s/it]predicting train subjects:  40%|███▉      | 211/532 [08:21<09:03,  1.69s/it]predicting train subjects:  40%|███▉      | 212/532 [08:22<08:43,  1.64s/it]predicting train subjects:  40%|████      | 213/532 [08:24<08:25,  1.59s/it]predicting train subjects:  40%|████      | 214/532 [08:25<08:22,  1.58s/it]predicting train subjects:  40%|████      | 215/532 [08:27<09:23,  1.78s/it]predicting train subjects:  41%|████      | 216/532 [08:30<10:05,  1.91s/it]predicting train subjects:  41%|████      | 217/532 [08:32<10:54,  2.08s/it]predicting train subjects:  41%|████      | 218/532 [08:34<11:10,  2.13s/it]predicting train subjects:  41%|████      | 219/532 [08:37<11:27,  2.20s/it]predicting train subjects:  41%|████▏     | 220/532 [08:39<11:26,  2.20s/it]predicting train subjects:  42%|████▏     | 221/532 [08:40<10:19,  1.99s/it]predicting train subjects:  42%|████▏     | 222/532 [08:42<09:29,  1.84s/it]predicting train subjects:  42%|████▏     | 223/532 [08:44<09:08,  1.78s/it]predicting train subjects:  42%|████▏     | 224/532 [08:45<08:49,  1.72s/it]predicting train subjects:  42%|████▏     | 225/532 [08:47<08:31,  1.67s/it]predicting train subjects:  42%|████▏     | 226/532 [08:48<08:02,  1.58s/it]predicting train subjects:  43%|████▎     | 227/532 [08:50<07:51,  1.55s/it]predicting train subjects:  43%|████▎     | 228/532 [08:51<07:45,  1.53s/it]predicting train subjects:  43%|████▎     | 229/532 [08:52<07:28,  1.48s/it]predicting train subjects:  43%|████▎     | 230/532 [08:54<07:18,  1.45s/it]predicting train subjects:  43%|████▎     | 231/532 [08:55<07:08,  1.42s/it]predicting train subjects:  44%|████▎     | 232/532 [08:57<07:10,  1.44s/it]predicting train subjects:  44%|████▍     | 233/532 [08:58<07:33,  1.52s/it]predicting train subjects:  44%|████▍     | 234/532 [09:00<07:46,  1.56s/it]predicting train subjects:  44%|████▍     | 235/532 [09:02<07:53,  1.59s/it]predicting train subjects:  44%|████▍     | 236/532 [09:03<07:55,  1.61s/it]predicting train subjects:  45%|████▍     | 237/532 [09:05<07:58,  1.62s/it]predicting train subjects:  45%|████▍     | 238/532 [09:07<08:02,  1.64s/it]predicting train subjects:  45%|████▍     | 239/532 [09:08<08:05,  1.66s/it]predicting train subjects:  45%|████▌     | 240/532 [09:10<08:20,  1.72s/it]predicting train subjects:  45%|████▌     | 241/532 [09:12<08:22,  1.73s/it]predicting train subjects:  45%|████▌     | 242/532 [09:14<08:22,  1.73s/it]predicting train subjects:  46%|████▌     | 243/532 [09:16<08:36,  1.79s/it]predicting train subjects:  46%|████▌     | 244/532 [09:17<08:43,  1.82s/it]predicting train subjects:  46%|████▌     | 245/532 [09:19<08:10,  1.71s/it]predicting train subjects:  46%|████▌     | 246/532 [09:20<07:47,  1.64s/it]predicting train subjects:  46%|████▋     | 247/532 [09:22<07:39,  1.61s/it]predicting train subjects:  47%|████▋     | 248/532 [09:23<07:21,  1.56s/it]predicting train subjects:  47%|████▋     | 249/532 [09:25<07:08,  1.51s/it]predicting train subjects:  47%|████▋     | 250/532 [09:26<07:06,  1.51s/it]predicting train subjects:  47%|████▋     | 251/532 [09:28<07:07,  1.52s/it]predicting train subjects:  47%|████▋     | 252/532 [09:29<06:59,  1.50s/it]predicting train subjects:  48%|████▊     | 253/532 [09:31<06:59,  1.50s/it]predicting train subjects:  48%|████▊     | 254/532 [09:32<06:58,  1.50s/it]predicting train subjects:  48%|████▊     | 255/532 [09:34<07:13,  1.57s/it]predicting train subjects:  48%|████▊     | 256/532 [09:36<07:08,  1.55s/it]predicting train subjects:  48%|████▊     | 257/532 [09:37<07:40,  1.67s/it]predicting train subjects:  48%|████▊     | 258/532 [09:39<07:54,  1.73s/it]predicting train subjects:  49%|████▊     | 259/532 [09:41<08:07,  1.79s/it]predicting train subjects:  49%|████▉     | 260/532 [09:43<08:17,  1.83s/it]predicting train subjects:  49%|████▉     | 261/532 [09:45<08:29,  1.88s/it]predicting train subjects:  49%|████▉     | 262/532 [09:47<08:36,  1.91s/it]predicting train subjects:  49%|████▉     | 263/532 [09:49<07:56,  1.77s/it]predicting train subjects:  50%|████▉     | 264/532 [09:50<07:25,  1.66s/it]predicting train subjects:  50%|████▉     | 265/532 [09:51<06:59,  1.57s/it]predicting train subjects:  50%|█████     | 266/532 [09:53<06:42,  1.51s/it]predicting train subjects:  50%|█████     | 267/532 [09:54<06:32,  1.48s/it]predicting train subjects:  50%|█████     | 268/532 [09:56<06:24,  1.46s/it]predicting train subjects:  51%|█████     | 269/532 [09:57<06:47,  1.55s/it]predicting train subjects:  51%|█████     | 270/532 [09:59<07:03,  1.62s/it]predicting train subjects:  51%|█████     | 271/532 [10:01<07:14,  1.67s/it]predicting train subjects:  51%|█████     | 272/532 [10:03<07:18,  1.69s/it]predicting train subjects:  51%|█████▏    | 273/532 [10:04<07:26,  1.72s/it]predicting train subjects:  52%|█████▏    | 274/532 [10:06<07:27,  1.73s/it]predicting train subjects:  52%|█████▏    | 275/532 [10:08<08:00,  1.87s/it]predicting train subjects:  52%|█████▏    | 276/532 [10:10<08:11,  1.92s/it]predicting train subjects:  52%|█████▏    | 277/532 [10:13<08:27,  1.99s/it]predicting train subjects:  52%|█████▏    | 278/532 [10:15<08:43,  2.06s/it]predicting train subjects:  52%|█████▏    | 279/532 [10:17<08:41,  2.06s/it]predicting train subjects:  53%|█████▎    | 280/532 [10:19<08:37,  2.05s/it]predicting train subjects:  53%|█████▎    | 281/532 [10:21<08:29,  2.03s/it]predicting train subjects:  53%|█████▎    | 282/532 [10:23<08:22,  2.01s/it]predicting train subjects:  53%|█████▎    | 283/532 [10:25<08:18,  2.00s/it]predicting train subjects:  53%|█████▎    | 284/532 [10:27<08:19,  2.01s/it]predicting train subjects:  54%|█████▎    | 285/532 [10:29<08:21,  2.03s/it]predicting train subjects:  54%|█████▍    | 286/532 [10:31<08:19,  2.03s/it]predicting train subjects:  54%|█████▍    | 287/532 [10:32<07:40,  1.88s/it]predicting train subjects:  54%|█████▍    | 288/532 [10:34<07:15,  1.79s/it]predicting train subjects:  54%|█████▍    | 289/532 [10:36<06:58,  1.72s/it]predicting train subjects:  55%|█████▍    | 290/532 [10:37<06:44,  1.67s/it]predicting train subjects:  55%|█████▍    | 291/532 [10:39<06:36,  1.64s/it]predicting train subjects:  55%|█████▍    | 292/532 [10:41<06:45,  1.69s/it]predicting train subjects:  55%|█████▌    | 293/532 [10:42<07:00,  1.76s/it]predicting train subjects:  55%|█████▌    | 294/532 [10:44<06:57,  1.75s/it]predicting train subjects:  55%|█████▌    | 295/532 [10:46<06:58,  1.77s/it]predicting train subjects:  56%|█████▌    | 296/532 [10:48<07:09,  1.82s/it]predicting train subjects:  56%|█████▌    | 297/532 [10:50<07:06,  1.82s/it]predicting train subjects:  56%|█████▌    | 298/532 [10:52<07:11,  1.84s/it]predicting train subjects:  56%|█████▌    | 299/532 [10:53<06:38,  1.71s/it]predicting train subjects:  56%|█████▋    | 300/532 [10:54<06:15,  1.62s/it]predicting train subjects:  57%|█████▋    | 301/532 [10:56<06:00,  1.56s/it]predicting train subjects:  57%|█████▋    | 302/532 [10:57<05:54,  1.54s/it]predicting train subjects:  57%|█████▋    | 303/532 [10:59<05:46,  1.51s/it]predicting train subjects:  57%|█████▋    | 304/532 [11:00<05:38,  1.49s/it]predicting train subjects:  57%|█████▋    | 305/532 [11:03<06:29,  1.72s/it]predicting train subjects:  58%|█████▊    | 306/532 [11:05<06:54,  1.84s/it]predicting train subjects:  58%|█████▊    | 307/532 [11:07<07:07,  1.90s/it]predicting train subjects:  58%|█████▊    | 308/532 [11:09<07:14,  1.94s/it]predicting train subjects:  58%|█████▊    | 309/532 [11:11<07:20,  1.98s/it]predicting train subjects:  58%|█████▊    | 310/532 [11:13<07:24,  2.00s/it]predicting train subjects:  58%|█████▊    | 311/532 [11:16<08:13,  2.23s/it]predicting train subjects:  59%|█████▊    | 312/532 [11:19<08:56,  2.44s/it]predicting train subjects:  59%|█████▉    | 313/532 [11:21<09:22,  2.57s/it]predicting train subjects:  59%|█████▉    | 314/532 [11:24<09:39,  2.66s/it]predicting train subjects:  59%|█████▉    | 315/532 [11:27<09:44,  2.69s/it]predicting train subjects:  59%|█████▉    | 316/532 [11:30<10:00,  2.78s/it]predicting train subjects:  60%|█████▉    | 317/532 [11:32<08:41,  2.43s/it]predicting train subjects:  60%|█████▉    | 318/532 [11:33<07:47,  2.18s/it]predicting train subjects:  60%|█████▉    | 319/532 [11:35<07:07,  2.01s/it]predicting train subjects:  60%|██████    | 320/532 [11:36<06:36,  1.87s/it]predicting train subjects:  60%|██████    | 321/532 [11:38<06:16,  1.78s/it]predicting train subjects:  61%|██████    | 322/532 [11:40<06:08,  1.76s/it]predicting train subjects:  61%|██████    | 323/532 [11:42<06:49,  1.96s/it]predicting train subjects:  61%|██████    | 324/532 [11:44<06:58,  2.01s/it]predicting train subjects:  61%|██████    | 325/532 [11:46<07:08,  2.07s/it]predicting train subjects:  61%|██████▏   | 326/532 [11:49<07:20,  2.14s/it]predicting train subjects:  61%|██████▏   | 327/532 [11:51<07:27,  2.18s/it]predicting train subjects:  62%|██████▏   | 328/532 [11:53<07:35,  2.23s/it]predicting train subjects:  62%|██████▏   | 329/532 [11:55<07:03,  2.08s/it]predicting train subjects:  62%|██████▏   | 330/532 [11:57<06:33,  1.95s/it]predicting train subjects:  62%|██████▏   | 331/532 [11:58<06:14,  1.86s/it]predicting train subjects:  62%|██████▏   | 332/532 [12:00<05:56,  1.78s/it]predicting train subjects:  63%|██████▎   | 333/532 [12:02<05:42,  1.72s/it]predicting train subjects:  63%|██████▎   | 334/532 [12:03<05:33,  1.69s/it]predicting train subjects:  63%|██████▎   | 335/532 [12:05<05:55,  1.80s/it]predicting train subjects:  63%|██████▎   | 336/532 [12:07<06:07,  1.87s/it]predicting train subjects:  63%|██████▎   | 337/532 [12:09<06:15,  1.93s/it]predicting train subjects:  64%|██████▎   | 338/532 [12:11<06:21,  1.97s/it]predicting train subjects:  64%|██████▎   | 339/532 [12:13<06:20,  1.97s/it]predicting train subjects:  64%|██████▍   | 340/532 [12:15<06:19,  1.98s/it]predicting train subjects:  64%|██████▍   | 341/532 [12:17<05:47,  1.82s/it]predicting train subjects:  64%|██████▍   | 342/532 [12:18<05:27,  1.72s/it]predicting train subjects:  64%|██████▍   | 343/532 [12:20<05:16,  1.67s/it]predicting train subjects:  65%|██████▍   | 344/532 [12:21<05:04,  1.62s/it]predicting train subjects:  65%|██████▍   | 345/532 [12:23<05:00,  1.61s/it]predicting train subjects:  65%|██████▌   | 346/532 [12:24<04:55,  1.59s/it]predicting train subjects:  65%|██████▌   | 347/532 [12:26<04:57,  1.61s/it]predicting train subjects:  65%|██████▌   | 348/532 [12:28<04:58,  1.62s/it]predicting train subjects:  66%|██████▌   | 349/532 [12:30<05:03,  1.66s/it]predicting train subjects:  66%|██████▌   | 350/532 [12:31<05:04,  1.67s/it]predicting train subjects:  66%|██████▌   | 351/532 [12:33<05:11,  1.72s/it]predicting train subjects:  66%|██████▌   | 352/532 [12:35<05:09,  1.72s/it]predicting train subjects:  66%|██████▋   | 353/532 [12:37<05:12,  1.75s/it]predicting train subjects:  67%|██████▋   | 354/532 [12:38<05:09,  1.74s/it]predicting train subjects:  67%|██████▋   | 355/532 [12:40<05:03,  1.72s/it]predicting train subjects:  67%|██████▋   | 356/532 [12:42<05:01,  1.71s/it]predicting train subjects:  67%|██████▋   | 357/532 [12:43<05:00,  1.72s/it]predicting train subjects:  67%|██████▋   | 358/532 [12:45<04:55,  1.70s/it]predicting train subjects:  67%|██████▋   | 359/532 [12:47<04:46,  1.65s/it]predicting train subjects:  68%|██████▊   | 360/532 [12:48<04:37,  1.61s/it]predicting train subjects:  68%|██████▊   | 361/532 [12:50<04:28,  1.57s/it]predicting train subjects:  68%|██████▊   | 362/532 [12:51<04:23,  1.55s/it]predicting train subjects:  68%|██████▊   | 363/532 [12:53<04:24,  1.57s/it]predicting train subjects:  68%|██████▊   | 364/532 [12:54<04:17,  1.53s/it]predicting train subjects:  69%|██████▊   | 365/532 [12:56<04:18,  1.55s/it]predicting train subjects:  69%|██████▉   | 366/532 [12:57<04:19,  1.57s/it]predicting train subjects:  69%|██████▉   | 367/532 [12:59<04:16,  1.55s/it]predicting train subjects:  69%|██████▉   | 368/532 [13:00<04:13,  1.55s/it]predicting train subjects:  69%|██████▉   | 369/532 [13:02<04:11,  1.54s/it]predicting train subjects:  70%|██████▉   | 370/532 [13:03<04:08,  1.53s/it]predicting train subjects:  70%|██████▉   | 371/532 [13:06<04:31,  1.69s/it]predicting train subjects:  70%|██████▉   | 372/532 [13:08<04:48,  1.80s/it]predicting train subjects:  70%|███████   | 373/532 [13:10<04:59,  1.89s/it]predicting train subjects:  70%|███████   | 374/532 [13:12<05:12,  1.98s/it]predicting train subjects:  70%|███████   | 375/532 [13:14<05:19,  2.04s/it]predicting train subjects:  71%|███████   | 376/532 [13:16<05:19,  2.05s/it]predicting train subjects:  71%|███████   | 377/532 [13:18<04:58,  1.92s/it]predicting train subjects:  71%|███████   | 378/532 [13:19<04:42,  1.84s/it]predicting train subjects:  71%|███████   | 379/532 [13:21<04:35,  1.80s/it]predicting train subjects:  71%|███████▏  | 380/532 [13:23<04:28,  1.77s/it]predicting train subjects:  72%|███████▏  | 381/532 [13:25<04:28,  1.78s/it]predicting train subjects:  72%|███████▏  | 382/532 [13:26<04:25,  1.77s/it]predicting train subjects:  72%|███████▏  | 383/532 [13:28<04:25,  1.78s/it]predicting train subjects:  72%|███████▏  | 384/532 [13:30<04:24,  1.79s/it]predicting train subjects:  72%|███████▏  | 385/532 [13:32<04:29,  1.83s/it]predicting train subjects:  73%|███████▎  | 386/532 [13:34<04:31,  1.86s/it]predicting train subjects:  73%|███████▎  | 387/532 [13:36<04:26,  1.83s/it]predicting train subjects:  73%|███████▎  | 388/532 [13:37<04:19,  1.80s/it]predicting train subjects:  73%|███████▎  | 389/532 [13:39<04:18,  1.81s/it]predicting train subjects:  73%|███████▎  | 390/532 [13:41<04:19,  1.83s/it]predicting train subjects:  73%|███████▎  | 391/532 [13:43<04:18,  1.83s/it]predicting train subjects:  74%|███████▎  | 392/532 [13:45<04:14,  1.82s/it]predicting train subjects:  74%|███████▍  | 393/532 [13:46<04:12,  1.82s/it]predicting train subjects:  74%|███████▍  | 394/532 [13:48<04:11,  1.82s/it]predicting train subjects:  74%|███████▍  | 395/532 [13:50<04:08,  1.81s/it]predicting train subjects:  74%|███████▍  | 396/532 [13:52<04:07,  1.82s/it]predicting train subjects:  75%|███████▍  | 397/532 [13:54<04:06,  1.83s/it]predicting train subjects:  75%|███████▍  | 398/532 [13:55<03:57,  1.77s/it]predicting train subjects:  75%|███████▌  | 399/532 [13:57<03:53,  1.75s/it]predicting train subjects:  75%|███████▌  | 400/532 [13:59<03:56,  1.79s/it]predicting train subjects:  75%|███████▌  | 401/532 [14:01<04:06,  1.88s/it]predicting train subjects:  76%|███████▌  | 402/532 [14:03<04:10,  1.92s/it]predicting train subjects:  76%|███████▌  | 403/532 [14:05<04:12,  1.96s/it]predicting train subjects:  76%|███████▌  | 404/532 [14:07<04:11,  1.97s/it]predicting train subjects:  76%|███████▌  | 405/532 [14:09<04:08,  1.96s/it]predicting train subjects:  76%|███████▋  | 406/532 [14:11<04:10,  1.99s/it]predicting train subjects:  77%|███████▋  | 407/532 [14:13<03:59,  1.92s/it]predicting train subjects:  77%|███████▋  | 408/532 [14:15<03:48,  1.84s/it]predicting train subjects:  77%|███████▋  | 409/532 [14:16<03:42,  1.81s/it]predicting train subjects:  77%|███████▋  | 410/532 [14:18<03:39,  1.80s/it]predicting train subjects:  77%|███████▋  | 411/532 [14:20<03:39,  1.82s/it]predicting train subjects:  77%|███████▋  | 412/532 [14:22<03:36,  1.81s/it]predicting train subjects:  78%|███████▊  | 413/532 [14:23<03:27,  1.75s/it]predicting train subjects:  78%|███████▊  | 414/532 [14:25<03:17,  1.67s/it]predicting train subjects:  78%|███████▊  | 415/532 [14:26<03:12,  1.65s/it]predicting train subjects:  78%|███████▊  | 416/532 [14:28<03:14,  1.67s/it]predicting train subjects:  78%|███████▊  | 417/532 [14:30<03:13,  1.68s/it]predicting train subjects:  79%|███████▊  | 418/532 [14:31<03:09,  1.67s/it]predicting train subjects:  79%|███████▉  | 419/532 [14:33<03:17,  1.75s/it]predicting train subjects:  79%|███████▉  | 420/532 [14:35<03:20,  1.79s/it]predicting train subjects:  79%|███████▉  | 421/532 [14:37<03:20,  1.80s/it]predicting train subjects:  79%|███████▉  | 422/532 [14:39<03:21,  1.84s/it]predicting train subjects:  80%|███████▉  | 423/532 [14:41<03:22,  1.86s/it]predicting train subjects:  80%|███████▉  | 424/532 [14:43<03:19,  1.85s/it]predicting train subjects:  80%|███████▉  | 425/532 [14:45<03:18,  1.86s/it]predicting train subjects:  80%|████████  | 426/532 [14:46<03:14,  1.83s/it]predicting train subjects:  80%|████████  | 427/532 [14:48<03:12,  1.84s/it]predicting train subjects:  80%|████████  | 428/532 [14:50<03:11,  1.84s/it]predicting train subjects:  81%|████████  | 429/532 [14:52<03:08,  1.83s/it]predicting train subjects:  81%|████████  | 430/532 [14:54<03:09,  1.86s/it]predicting train subjects:  81%|████████  | 431/532 [14:56<03:12,  1.91s/it]predicting train subjects:  81%|████████  | 432/532 [14:58<03:15,  1.96s/it]predicting train subjects:  81%|████████▏ | 433/532 [15:00<03:16,  1.99s/it]predicting train subjects:  82%|████████▏ | 434/532 [15:02<03:23,  2.08s/it]predicting train subjects:  82%|████████▏ | 435/532 [15:04<03:22,  2.09s/it]predicting train subjects:  82%|████████▏ | 436/532 [15:06<03:19,  2.07s/it]predicting train subjects:  82%|████████▏ | 437/532 [15:08<03:00,  1.90s/it]predicting train subjects:  82%|████████▏ | 438/532 [15:09<02:46,  1.78s/it]predicting train subjects:  83%|████████▎ | 439/532 [15:11<02:35,  1.67s/it]predicting train subjects:  83%|████████▎ | 440/532 [15:13<02:36,  1.70s/it]predicting train subjects:  83%|████████▎ | 441/532 [15:14<02:35,  1.71s/it]predicting train subjects:  83%|████████▎ | 442/532 [15:16<02:37,  1.75s/it]predicting train subjects:  83%|████████▎ | 443/532 [15:18<02:37,  1.77s/it]predicting train subjects:  83%|████████▎ | 444/532 [15:20<02:30,  1.71s/it]predicting train subjects:  84%|████████▎ | 445/532 [15:21<02:30,  1.73s/it]predicting train subjects:  84%|████████▍ | 446/532 [15:23<02:33,  1.78s/it]predicting train subjects:  84%|████████▍ | 447/532 [15:25<02:34,  1.82s/it]predicting train subjects:  84%|████████▍ | 448/532 [15:27<02:30,  1.79s/it]predicting train subjects:  84%|████████▍ | 449/532 [15:29<02:29,  1.80s/it]predicting train subjects:  85%|████████▍ | 450/532 [15:31<02:29,  1.82s/it]predicting train subjects:  85%|████████▍ | 451/532 [15:32<02:28,  1.83s/it]predicting train subjects:  85%|████████▍ | 452/532 [15:34<02:24,  1.80s/it]predicting train subjects:  85%|████████▌ | 453/532 [15:36<02:24,  1.83s/it]predicting train subjects:  85%|████████▌ | 454/532 [15:38<02:26,  1.88s/it]predicting train subjects:  86%|████████▌ | 455/532 [15:40<02:31,  1.97s/it]predicting train subjects:  86%|████████▌ | 456/532 [15:42<02:33,  2.02s/it]predicting train subjects:  86%|████████▌ | 457/532 [15:44<02:33,  2.04s/it]predicting train subjects:  86%|████████▌ | 458/532 [15:47<02:33,  2.07s/it]predicting train subjects:  86%|████████▋ | 459/532 [15:49<02:30,  2.06s/it]predicting train subjects:  86%|████████▋ | 460/532 [15:51<02:31,  2.10s/it]predicting train subjects:  87%|████████▋ | 461/532 [15:54<02:41,  2.27s/it]predicting train subjects:  87%|████████▋ | 462/532 [15:56<02:44,  2.35s/it]predicting train subjects:  87%|████████▋ | 463/532 [15:58<02:44,  2.38s/it]predicting train subjects:  87%|████████▋ | 464/532 [16:01<02:43,  2.41s/it]predicting train subjects:  87%|████████▋ | 465/532 [16:03<02:41,  2.42s/it]predicting train subjects:  88%|████████▊ | 466/532 [16:06<02:40,  2.43s/it]predicting train subjects:  88%|████████▊ | 467/532 [16:08<02:30,  2.31s/it]predicting train subjects:  88%|████████▊ | 468/532 [16:10<02:21,  2.21s/it]predicting train subjects:  88%|████████▊ | 469/532 [16:12<02:13,  2.12s/it]predicting train subjects:  88%|████████▊ | 470/532 [16:14<02:08,  2.07s/it]predicting train subjects:  89%|████████▊ | 471/532 [16:16<02:01,  2.00s/it]predicting train subjects:  89%|████████▊ | 472/532 [16:17<01:56,  1.95s/it]predicting train subjects:  89%|████████▉ | 473/532 [16:20<01:58,  2.01s/it]predicting train subjects:  89%|████████▉ | 474/532 [16:22<01:58,  2.04s/it]predicting train subjects:  89%|████████▉ | 475/532 [16:24<02:01,  2.13s/it]predicting train subjects:  89%|████████▉ | 476/532 [16:26<02:00,  2.15s/it]predicting train subjects:  90%|████████▉ | 477/532 [16:29<02:04,  2.26s/it]predicting train subjects:  90%|████████▉ | 478/532 [16:31<02:02,  2.27s/it]predicting train subjects:  90%|█████████ | 479/532 [16:33<01:55,  2.18s/it]predicting train subjects:  90%|█████████ | 480/532 [16:35<01:49,  2.10s/it]predicting train subjects:  90%|█████████ | 481/532 [16:37<01:42,  2.02s/it]predicting train subjects:  91%|█████████ | 482/532 [16:39<01:38,  1.96s/it]predicting train subjects:  91%|█████████ | 483/532 [16:40<01:33,  1.92s/it]predicting train subjects:  91%|█████████ | 484/532 [16:42<01:34,  1.97s/it]predicting train subjects:  91%|█████████ | 485/532 [16:45<01:39,  2.13s/it]predicting train subjects:  91%|█████████▏| 486/532 [16:47<01:40,  2.18s/it]predicting train subjects:  92%|█████████▏| 487/532 [16:50<01:39,  2.22s/it]predicting train subjects:  92%|█████████▏| 488/532 [16:52<01:39,  2.26s/it]predicting train subjects:  92%|█████████▏| 489/532 [16:54<01:38,  2.30s/it]predicting train subjects:  92%|█████████▏| 490/532 [16:57<01:38,  2.34s/it]predicting train subjects:  92%|█████████▏| 491/532 [16:59<01:31,  2.23s/it]predicting train subjects:  92%|█████████▏| 492/532 [17:01<01:28,  2.22s/it]predicting train subjects:  93%|█████████▎| 493/532 [17:03<01:27,  2.24s/it]predicting train subjects:  93%|█████████▎| 494/532 [17:05<01:23,  2.20s/it]predicting train subjects:  93%|█████████▎| 495/532 [17:07<01:20,  2.19s/it]predicting train subjects:  93%|█████████▎| 496/532 [17:09<01:16,  2.13s/it]predicting train subjects:  93%|█████████▎| 497/532 [17:12<01:13,  2.10s/it]predicting train subjects:  94%|█████████▎| 498/532 [17:13<01:09,  2.03s/it]predicting train subjects:  94%|█████████▍| 499/532 [17:15<01:06,  2.02s/it]predicting train subjects:  94%|█████████▍| 500/532 [17:18<01:06,  2.08s/it]predicting train subjects:  94%|█████████▍| 501/532 [17:20<01:04,  2.08s/it]predicting train subjects:  94%|█████████▍| 502/532 [17:22<01:03,  2.11s/it]predicting train subjects:  95%|█████████▍| 503/532 [17:24<00:59,  2.04s/it]predicting train subjects:  95%|█████████▍| 504/532 [17:26<00:55,  1.99s/it]predicting train subjects:  95%|█████████▍| 505/532 [17:28<00:53,  1.98s/it]predicting train subjects:  95%|█████████▌| 506/532 [17:29<00:50,  1.95s/it]predicting train subjects:  95%|█████████▌| 507/532 [17:31<00:48,  1.94s/it]predicting train subjects:  95%|█████████▌| 508/532 [17:33<00:46,  1.92s/it]predicting train subjects:  96%|█████████▌| 509/532 [17:36<00:49,  2.15s/it]predicting train subjects:  96%|█████████▌| 510/532 [17:38<00:49,  2.25s/it]predicting train subjects:  96%|█████████▌| 511/532 [17:41<00:47,  2.27s/it]predicting train subjects:  96%|█████████▌| 512/532 [17:43<00:45,  2.27s/it]predicting train subjects:  96%|█████████▋| 513/532 [17:45<00:43,  2.30s/it]predicting train subjects:  97%|█████████▋| 514/532 [17:48<00:41,  2.32s/it]predicting train subjects:  97%|█████████▋| 515/532 [17:50<00:37,  2.20s/it]predicting train subjects:  97%|█████████▋| 516/532 [17:52<00:34,  2.15s/it]predicting train subjects:  97%|█████████▋| 517/532 [17:54<00:32,  2.14s/it]predicting train subjects:  97%|█████████▋| 518/532 [17:56<00:30,  2.15s/it]predicting train subjects:  98%|█████████▊| 519/532 [17:58<00:27,  2.09s/it]predicting train subjects:  98%|█████████▊| 520/532 [18:00<00:24,  2.06s/it]predicting train subjects:  98%|█████████▊| 521/532 [18:02<00:23,  2.09s/it]predicting train subjects:  98%|█████████▊| 522/532 [18:04<00:21,  2.13s/it]predicting train subjects:  98%|█████████▊| 523/532 [18:06<00:19,  2.11s/it]predicting train subjects:  98%|█████████▊| 524/532 [18:09<00:17,  2.21s/it]predicting train subjects:  99%|█████████▊| 525/532 [18:11<00:15,  2.24s/it]predicting train subjects:  99%|█████████▉| 526/532 [18:13<00:13,  2.27s/it]predicting train subjects:  99%|█████████▉| 527/532 [18:15<00:10,  2.17s/it]predicting train subjects:  99%|█████████▉| 528/532 [18:17<00:08,  2.09s/it]predicting train subjects:  99%|█████████▉| 529/532 [18:19<00:06,  2.02s/it]predicting train subjects: 100%|█████████▉| 530/532 [18:21<00:03,  1.98s/it]predicting train subjects: 100%|█████████▉| 531/532 [18:23<00:02,  2.03s/it]predicting train subjects: 100%|██████████| 532/532 [18:25<00:00,  1.98s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1’: File exists

Loading train:   0%|          | 0/532 [00:00<?, ?it/s]Loading train:   0%|          | 1/532 [00:02<22:51,  2.58s/it]Loading train:   0%|          | 2/532 [00:04<20:39,  2.34s/it]Loading train:   1%|          | 3/532 [00:06<20:14,  2.30s/it]Loading train:   1%|          | 4/532 [00:08<19:28,  2.21s/it]Loading train:   1%|          | 5/532 [00:10<19:13,  2.19s/it]Loading train:   1%|          | 6/532 [00:12<19:06,  2.18s/it]Loading train:   1%|▏         | 7/532 [00:14<18:52,  2.16s/it]Loading train:   2%|▏         | 8/532 [00:17<18:52,  2.16s/it]Loading train:   2%|▏         | 9/532 [00:19<18:41,  2.14s/it]Loading train:   2%|▏         | 10/532 [00:20<17:22,  2.00s/it]Loading train:   2%|▏         | 11/532 [00:22<15:50,  1.82s/it]Loading train:   2%|▏         | 12/532 [00:24<16:09,  1.86s/it]Loading train:   2%|▏         | 13/532 [00:26<16:19,  1.89s/it]Loading train:   3%|▎         | 14/532 [00:28<16:19,  1.89s/it]Loading train:   3%|▎         | 15/532 [00:30<16:51,  1.96s/it]Loading train:   3%|▎         | 16/532 [00:32<17:15,  2.01s/it]Loading train:   3%|▎         | 17/532 [00:34<16:43,  1.95s/it]Loading train:   3%|▎         | 18/532 [00:36<16:43,  1.95s/it]Loading train:   4%|▎         | 19/532 [00:37<15:43,  1.84s/it]Loading train:   4%|▍         | 20/532 [00:39<15:58,  1.87s/it]Loading train:   4%|▍         | 21/532 [00:41<16:59,  2.00s/it]Loading train:   4%|▍         | 22/532 [00:43<16:57,  1.99s/it]Loading train:   4%|▍         | 23/532 [00:46<17:45,  2.09s/it]Loading train:   5%|▍         | 24/532 [00:47<15:39,  1.85s/it]Loading train:   5%|▍         | 25/532 [00:49<16:16,  1.93s/it]Loading train:   5%|▍         | 26/532 [00:51<15:54,  1.89s/it]Loading train:   5%|▌         | 27/532 [00:53<16:53,  2.01s/it]Loading train:   5%|▌         | 28/532 [00:55<15:50,  1.89s/it]Loading train:   5%|▌         | 29/532 [00:57<15:22,  1.83s/it]Loading train:   6%|▌         | 30/532 [00:58<14:57,  1.79s/it]Loading train:   6%|▌         | 31/532 [01:00<14:21,  1.72s/it]Loading train:   6%|▌         | 32/532 [01:01<13:42,  1.64s/it]Loading train:   6%|▌         | 33/532 [01:03<12:46,  1.54s/it]Loading train:   6%|▋         | 34/532 [01:05<14:25,  1.74s/it]Loading train:   7%|▋         | 35/532 [01:07<15:03,  1.82s/it]Loading train:   7%|▋         | 36/532 [01:09<15:24,  1.86s/it]Loading train:   7%|▋         | 37/532 [01:11<16:12,  1.96s/it]Loading train:   7%|▋         | 38/532 [01:13<15:47,  1.92s/it]Loading train:   7%|▋         | 39/532 [01:14<14:40,  1.79s/it]Loading train:   8%|▊         | 40/532 [01:16<14:06,  1.72s/it]Loading train:   8%|▊         | 41/532 [01:18<14:41,  1.79s/it]Loading train:   8%|▊         | 42/532 [01:20<14:55,  1.83s/it]Loading train:   8%|▊         | 43/532 [01:21<13:52,  1.70s/it]Loading train:   8%|▊         | 44/532 [01:23<13:27,  1.65s/it]Loading train:   8%|▊         | 45/532 [01:25<15:48,  1.95s/it]Loading train:   9%|▊         | 46/532 [01:28<16:46,  2.07s/it]Loading train:   9%|▉         | 47/532 [01:29<14:46,  1.83s/it]Loading train:   9%|▉         | 48/532 [01:30<12:52,  1.60s/it]Loading train:   9%|▉         | 49/532 [01:31<11:25,  1.42s/it]Loading train:   9%|▉         | 50/532 [01:33<12:44,  1.59s/it]Loading train:  10%|▉         | 51/532 [01:35<13:14,  1.65s/it]Loading train:  10%|▉         | 52/532 [01:36<13:30,  1.69s/it]Loading train:  10%|▉         | 53/532 [01:37<11:41,  1.46s/it]Loading train:  10%|█         | 54/532 [01:39<11:14,  1.41s/it]Loading train:  10%|█         | 55/532 [01:40<10:24,  1.31s/it]Loading train:  11%|█         | 56/532 [01:41<09:51,  1.24s/it]Loading train:  11%|█         | 57/532 [01:42<08:48,  1.11s/it]Loading train:  11%|█         | 58/532 [01:43<08:53,  1.13s/it]Loading train:  11%|█         | 59/532 [01:44<09:15,  1.17s/it]Loading train:  11%|█▏        | 60/532 [01:45<08:31,  1.08s/it]Loading train:  11%|█▏        | 61/532 [01:46<08:07,  1.04s/it]Loading train:  12%|█▏        | 62/532 [01:47<08:17,  1.06s/it]Loading train:  12%|█▏        | 63/532 [01:48<08:27,  1.08s/it]Loading train:  12%|█▏        | 64/532 [01:49<07:57,  1.02s/it]Loading train:  12%|█▏        | 65/532 [01:50<08:04,  1.04s/it]Loading train:  12%|█▏        | 66/532 [01:51<08:18,  1.07s/it]Loading train:  13%|█▎        | 67/532 [01:53<08:52,  1.14s/it]Loading train:  13%|█▎        | 68/532 [01:54<08:27,  1.09s/it]Loading train:  13%|█▎        | 69/532 [01:55<08:12,  1.06s/it]Loading train:  13%|█▎        | 70/532 [01:56<08:00,  1.04s/it]Loading train:  13%|█▎        | 71/532 [01:56<07:28,  1.03it/s]Loading train:  14%|█▎        | 72/532 [01:57<07:05,  1.08it/s]Loading train:  14%|█▎        | 73/532 [01:58<07:39,  1.00s/it]Loading train:  14%|█▍        | 74/532 [02:00<08:15,  1.08s/it]Loading train:  14%|█▍        | 75/532 [02:01<09:25,  1.24s/it]Loading train:  14%|█▍        | 76/532 [02:02<08:59,  1.18s/it]Loading train:  14%|█▍        | 77/532 [02:03<08:25,  1.11s/it]Loading train:  15%|█▍        | 78/532 [02:04<08:28,  1.12s/it]Loading train:  15%|█▍        | 79/532 [02:05<08:10,  1.08s/it]Loading train:  15%|█▌        | 80/532 [02:06<07:41,  1.02s/it]Loading train:  15%|█▌        | 81/532 [02:07<07:38,  1.02s/it]Loading train:  15%|█▌        | 82/532 [02:08<07:22,  1.02it/s]Loading train:  16%|█▌        | 83/532 [02:09<07:16,  1.03it/s]Loading train:  16%|█▌        | 84/532 [02:10<06:55,  1.08it/s]Loading train:  16%|█▌        | 85/532 [02:11<06:31,  1.14it/s]Loading train:  16%|█▌        | 86/532 [02:11<06:26,  1.16it/s]Loading train:  16%|█▋        | 87/532 [02:12<06:19,  1.17it/s]Loading train:  17%|█▋        | 88/532 [02:13<06:17,  1.17it/s]Loading train:  17%|█▋        | 89/532 [02:14<06:31,  1.13it/s]Loading train:  17%|█▋        | 90/532 [02:15<06:21,  1.16it/s]Loading train:  17%|█▋        | 91/532 [02:16<06:19,  1.16it/s]Loading train:  17%|█▋        | 92/532 [02:17<06:06,  1.20it/s]Loading train:  17%|█▋        | 93/532 [02:17<06:18,  1.16it/s]Loading train:  18%|█▊        | 94/532 [02:18<06:14,  1.17it/s]Loading train:  18%|█▊        | 95/532 [02:19<06:52,  1.06it/s]Loading train:  18%|█▊        | 96/532 [02:21<07:09,  1.02it/s]Loading train:  18%|█▊        | 97/532 [02:22<07:29,  1.03s/it]Loading train:  18%|█▊        | 98/532 [02:23<07:48,  1.08s/it]Loading train:  19%|█▊        | 99/532 [02:24<07:51,  1.09s/it]Loading train:  19%|█▉        | 100/532 [02:25<07:54,  1.10s/it]Loading train:  19%|█▉        | 101/532 [02:26<07:58,  1.11s/it]Loading train:  19%|█▉        | 102/532 [02:27<07:29,  1.05s/it]Loading train:  19%|█▉        | 103/532 [02:28<07:16,  1.02s/it]Loading train:  20%|█▉        | 104/532 [02:29<06:48,  1.05it/s]Loading train:  20%|█▉        | 105/532 [02:30<06:40,  1.07it/s]Loading train:  20%|█▉        | 106/532 [02:31<06:17,  1.13it/s]Loading train:  20%|██        | 107/532 [02:31<06:13,  1.14it/s]Loading train:  20%|██        | 108/532 [02:32<05:52,  1.20it/s]Loading train:  20%|██        | 109/532 [02:33<05:40,  1.24it/s]Loading train:  21%|██        | 110/532 [02:34<05:28,  1.28it/s]Loading train:  21%|██        | 111/532 [02:34<05:22,  1.31it/s]Loading train:  21%|██        | 112/532 [02:35<05:24,  1.29it/s]Loading train:  21%|██        | 113/532 [02:36<06:17,  1.11it/s]Loading train:  21%|██▏       | 114/532 [02:37<06:20,  1.10it/s]Loading train:  22%|██▏       | 115/532 [02:38<06:42,  1.04it/s]Loading train:  22%|██▏       | 116/532 [02:39<06:30,  1.07it/s]Loading train:  22%|██▏       | 117/532 [02:40<06:28,  1.07it/s]Loading train:  22%|██▏       | 118/532 [02:41<06:40,  1.03it/s]Loading train:  22%|██▏       | 119/532 [02:42<06:38,  1.04it/s]Loading train:  23%|██▎       | 120/532 [02:43<06:39,  1.03it/s]Loading train:  23%|██▎       | 121/532 [02:44<06:35,  1.04it/s]Loading train:  23%|██▎       | 122/532 [02:45<06:26,  1.06it/s]Loading train:  23%|██▎       | 123/532 [02:46<06:28,  1.05it/s]Loading train:  23%|██▎       | 124/532 [02:47<06:23,  1.06it/s]Loading train:  23%|██▎       | 125/532 [02:48<06:33,  1.04it/s]Loading train:  24%|██▎       | 126/532 [02:49<06:28,  1.05it/s]Loading train:  24%|██▍       | 127/532 [02:50<06:32,  1.03it/s]Loading train:  24%|██▍       | 128/532 [02:51<06:28,  1.04it/s]Loading train:  24%|██▍       | 129/532 [02:52<06:38,  1.01it/s]Loading train:  24%|██▍       | 130/532 [02:53<06:40,  1.00it/s]Loading train:  25%|██▍       | 131/532 [02:54<07:09,  1.07s/it]Loading train:  25%|██▍       | 132/532 [02:55<07:05,  1.06s/it]Loading train:  25%|██▌       | 133/532 [02:56<07:35,  1.14s/it]Loading train:  25%|██▌       | 134/532 [02:58<07:35,  1.14s/it]Loading train:  25%|██▌       | 135/532 [02:59<07:25,  1.12s/it]Loading train:  26%|██▌       | 136/532 [03:00<07:32,  1.14s/it]Loading train:  26%|██▌       | 137/532 [03:01<07:51,  1.19s/it]Loading train:  26%|██▌       | 138/532 [03:02<08:00,  1.22s/it]Loading train:  26%|██▌       | 139/532 [03:04<08:06,  1.24s/it]Loading train:  26%|██▋       | 140/532 [03:05<08:01,  1.23s/it]Loading train:  27%|██▋       | 141/532 [03:06<08:11,  1.26s/it]Loading train:  27%|██▋       | 142/532 [03:07<08:00,  1.23s/it]Loading train:  27%|██▋       | 143/532 [03:09<07:38,  1.18s/it]Loading train:  27%|██▋       | 144/532 [03:09<06:59,  1.08s/it]Loading train:  27%|██▋       | 145/532 [03:10<06:49,  1.06s/it]Loading train:  27%|██▋       | 146/532 [03:11<06:20,  1.01it/s]Loading train:  28%|██▊       | 147/532 [03:12<06:01,  1.07it/s]Loading train:  28%|██▊       | 148/532 [03:13<05:59,  1.07it/s]Loading train:  28%|██▊       | 149/532 [03:14<05:54,  1.08it/s]Loading train:  28%|██▊       | 150/532 [03:15<05:50,  1.09it/s]Loading train:  28%|██▊       | 151/532 [03:16<05:40,  1.12it/s]Loading train:  29%|██▊       | 152/532 [03:17<05:42,  1.11it/s]Loading train:  29%|██▉       | 153/532 [03:17<05:32,  1.14it/s]Loading train:  29%|██▉       | 154/532 [03:18<05:25,  1.16it/s]Loading train:  29%|██▉       | 155/532 [03:19<06:09,  1.02it/s]Loading train:  29%|██▉       | 156/532 [03:21<06:53,  1.10s/it]Loading train:  30%|██▉       | 157/532 [03:22<07:06,  1.14s/it]Loading train:  30%|██▉       | 158/532 [03:23<07:29,  1.20s/it]Loading train:  30%|██▉       | 159/532 [03:25<07:25,  1.19s/it]Loading train:  30%|███       | 160/532 [03:26<07:31,  1.21s/it]Loading train:  30%|███       | 161/532 [03:27<07:14,  1.17s/it]Loading train:  30%|███       | 162/532 [03:28<07:05,  1.15s/it]Loading train:  31%|███       | 163/532 [03:29<06:57,  1.13s/it]Loading train:  31%|███       | 164/532 [03:30<06:41,  1.09s/it]Loading train:  31%|███       | 165/532 [03:31<06:16,  1.02s/it]Loading train:  31%|███       | 166/532 [03:32<05:55,  1.03it/s]Loading train:  31%|███▏      | 167/532 [03:33<05:54,  1.03it/s]Loading train:  32%|███▏      | 168/532 [03:34<05:41,  1.07it/s]Loading train:  32%|███▏      | 169/532 [03:35<05:57,  1.02it/s]Loading train:  32%|███▏      | 170/532 [03:36<05:50,  1.03it/s]Loading train:  32%|███▏      | 171/532 [03:37<05:52,  1.02it/s]Loading train:  32%|███▏      | 172/532 [03:38<05:53,  1.02it/s]Loading train:  33%|███▎      | 173/532 [03:38<05:38,  1.06it/s]Loading train:  33%|███▎      | 174/532 [03:39<05:26,  1.10it/s]Loading train:  33%|███▎      | 175/532 [03:40<05:14,  1.14it/s]Loading train:  33%|███▎      | 176/532 [03:41<05:08,  1.15it/s]Loading train:  33%|███▎      | 177/532 [03:42<05:08,  1.15it/s]Loading train:  33%|███▎      | 178/532 [03:43<05:05,  1.16it/s]Loading train:  34%|███▎      | 179/532 [03:44<05:11,  1.13it/s]Loading train:  34%|███▍      | 180/532 [03:45<05:23,  1.09it/s]Loading train:  34%|███▍      | 181/532 [03:45<05:15,  1.11it/s]Loading train:  34%|███▍      | 182/532 [03:46<05:21,  1.09it/s]Loading train:  34%|███▍      | 183/532 [03:47<05:11,  1.12it/s]Loading train:  35%|███▍      | 184/532 [03:48<05:16,  1.10it/s]Loading train:  35%|███▍      | 185/532 [03:49<05:12,  1.11it/s]Loading train:  35%|███▍      | 186/532 [03:50<05:26,  1.06it/s]Loading train:  35%|███▌      | 187/532 [03:51<05:20,  1.08it/s]Loading train:  35%|███▌      | 188/532 [03:52<05:28,  1.05it/s]Loading train:  36%|███▌      | 189/532 [03:53<05:19,  1.07it/s]Loading train:  36%|███▌      | 190/532 [03:54<05:14,  1.09it/s]Loading train:  36%|███▌      | 191/532 [03:55<05:40,  1.00it/s]Loading train:  36%|███▌      | 192/532 [03:56<06:06,  1.08s/it]Loading train:  36%|███▋      | 193/532 [03:57<06:16,  1.11s/it]Loading train:  36%|███▋      | 194/532 [03:59<06:29,  1.15s/it]Loading train:  37%|███▋      | 195/532 [04:00<06:35,  1.17s/it]Loading train:  37%|███▋      | 196/532 [04:01<06:40,  1.19s/it]Loading train:  37%|███▋      | 197/532 [04:02<06:34,  1.18s/it]Loading train:  37%|███▋      | 198/532 [04:03<06:20,  1.14s/it]Loading train:  37%|███▋      | 199/532 [04:04<06:16,  1.13s/it]Loading train:  38%|███▊      | 200/532 [04:05<06:00,  1.09s/it]Loading train:  38%|███▊      | 201/532 [04:06<05:56,  1.08s/it]Loading train:  38%|███▊      | 202/532 [04:08<05:50,  1.06s/it]Loading train:  38%|███▊      | 203/532 [04:09<05:45,  1.05s/it]Loading train:  38%|███▊      | 204/532 [04:09<05:28,  1.00s/it]Loading train:  39%|███▊      | 205/532 [04:10<05:19,  1.02it/s]Loading train:  39%|███▊      | 206/532 [04:11<05:11,  1.05it/s]Loading train:  39%|███▉      | 207/532 [04:12<05:00,  1.08it/s]Loading train:  39%|███▉      | 208/532 [04:13<04:58,  1.08it/s]Loading train:  39%|███▉      | 209/532 [04:14<04:45,  1.13it/s]Loading train:  39%|███▉      | 210/532 [04:15<04:37,  1.16it/s]Loading train:  40%|███▉      | 211/532 [04:15<04:24,  1.21it/s]Loading train:  40%|███▉      | 212/532 [04:16<04:23,  1.21it/s]Loading train:  40%|████      | 213/532 [04:17<04:29,  1.18it/s]Loading train:  40%|████      | 214/532 [04:18<04:20,  1.22it/s]Loading train:  40%|████      | 215/532 [04:19<05:16,  1.00it/s]Loading train:  41%|████      | 216/532 [04:20<05:30,  1.04s/it]Loading train:  41%|████      | 217/532 [04:22<05:45,  1.10s/it]Loading train:  41%|████      | 218/532 [04:23<05:49,  1.11s/it]Loading train:  41%|████      | 219/532 [04:24<05:47,  1.11s/it]Loading train:  41%|████▏     | 220/532 [04:25<05:49,  1.12s/it]Loading train:  42%|████▏     | 221/532 [04:26<05:18,  1.02s/it]Loading train:  42%|████▏     | 222/532 [04:27<04:56,  1.05it/s]Loading train:  42%|████▏     | 223/532 [04:27<04:37,  1.11it/s]Loading train:  42%|████▏     | 224/532 [04:28<04:24,  1.17it/s]Loading train:  42%|████▏     | 225/532 [04:29<04:14,  1.21it/s]Loading train:  42%|████▏     | 226/532 [04:30<04:06,  1.24it/s]Loading train:  43%|████▎     | 227/532 [04:31<04:10,  1.22it/s]Loading train:  43%|████▎     | 228/532 [04:31<04:01,  1.26it/s]Loading train:  43%|████▎     | 229/532 [04:32<04:01,  1.25it/s]Loading train:  43%|████▎     | 230/532 [04:33<04:01,  1.25it/s]Loading train:  43%|████▎     | 231/532 [04:34<03:55,  1.28it/s]Loading train:  44%|████▎     | 232/532 [04:34<03:47,  1.32it/s]Loading train:  44%|████▍     | 233/532 [04:35<03:56,  1.26it/s]Loading train:  44%|████▍     | 234/532 [04:36<03:59,  1.24it/s]Loading train:  44%|████▍     | 235/532 [04:37<03:56,  1.26it/s]Loading train:  44%|████▍     | 236/532 [04:38<04:01,  1.23it/s]Loading train:  45%|████▍     | 237/532 [04:38<03:59,  1.23it/s]Loading train:  45%|████▍     | 238/532 [04:39<04:02,  1.21it/s]Loading train:  45%|████▍     | 239/532 [04:40<04:22,  1.12it/s]Loading train:  45%|████▌     | 240/532 [04:41<04:21,  1.12it/s]Loading train:  45%|████▌     | 241/532 [04:43<05:14,  1.08s/it]Loading train:  45%|████▌     | 242/532 [04:44<05:19,  1.10s/it]Loading train:  46%|████▌     | 243/532 [04:45<05:58,  1.24s/it]Loading train:  46%|████▌     | 244/532 [04:47<06:07,  1.27s/it]Loading train:  46%|████▌     | 245/532 [04:49<07:04,  1.48s/it]Loading train:  46%|████▌     | 246/532 [04:50<06:51,  1.44s/it]Loading train:  46%|████▋     | 247/532 [04:51<06:15,  1.32s/it]Loading train:  47%|████▋     | 248/532 [04:53<06:26,  1.36s/it]Loading train:  47%|████▋     | 249/532 [04:54<06:02,  1.28s/it]Loading train:  47%|████▋     | 250/532 [04:55<05:55,  1.26s/it]Loading train:  47%|████▋     | 251/532 [04:56<06:17,  1.34s/it]Loading train:  47%|████▋     | 252/532 [04:57<05:44,  1.23s/it]Loading train:  48%|████▊     | 253/532 [04:59<06:11,  1.33s/it]Loading train:  48%|████▊     | 254/532 [05:00<06:07,  1.32s/it]Loading train:  48%|████▊     | 255/532 [05:02<06:00,  1.30s/it]Loading train:  48%|████▊     | 256/532 [05:03<05:50,  1.27s/it]Loading train:  48%|████▊     | 257/532 [05:04<06:23,  1.39s/it]Loading train:  48%|████▊     | 258/532 [05:06<06:38,  1.46s/it]Loading train:  49%|████▊     | 259/532 [05:07<06:35,  1.45s/it]Loading train:  49%|████▉     | 260/532 [05:09<06:38,  1.47s/it]Loading train:  49%|████▉     | 261/532 [05:10<06:36,  1.46s/it]Loading train:  49%|████▉     | 262/532 [05:12<06:39,  1.48s/it]Loading train:  49%|████▉     | 263/532 [05:13<06:05,  1.36s/it]Loading train:  50%|████▉     | 264/532 [05:14<05:42,  1.28s/it]Loading train:  50%|████▉     | 265/532 [05:16<06:09,  1.39s/it]Loading train:  50%|█████     | 266/532 [05:17<06:33,  1.48s/it]Loading train:  50%|█████     | 267/532 [05:19<06:13,  1.41s/it]Loading train:  50%|█████     | 268/532 [05:20<05:26,  1.24s/it]Loading train:  51%|█████     | 269/532 [05:21<05:56,  1.36s/it]Loading train:  51%|█████     | 270/532 [05:22<05:50,  1.34s/it]Loading train:  51%|█████     | 271/532 [05:24<06:07,  1.41s/it]Loading train:  51%|█████     | 272/532 [05:25<05:43,  1.32s/it]Loading train:  51%|█████▏    | 273/532 [05:26<05:37,  1.30s/it]Loading train:  52%|█████▏    | 274/532 [05:28<05:38,  1.31s/it]Loading train:  52%|█████▏    | 275/532 [05:29<06:09,  1.44s/it]Loading train:  52%|█████▏    | 276/532 [05:31<06:26,  1.51s/it]Loading train:  52%|█████▏    | 277/532 [05:33<06:29,  1.53s/it]Loading train:  52%|█████▏    | 278/532 [05:34<06:29,  1.53s/it]Loading train:  52%|█████▏    | 279/532 [05:36<06:48,  1.61s/it]Loading train:  53%|█████▎    | 280/532 [05:38<06:47,  1.62s/it]Loading train:  53%|█████▎    | 281/532 [05:40<07:06,  1.70s/it]Loading train:  53%|█████▎    | 282/532 [05:42<07:24,  1.78s/it]Loading train:  53%|█████▎    | 283/532 [05:44<07:47,  1.88s/it]Loading train:  53%|█████▎    | 284/532 [05:45<07:22,  1.78s/it]Loading train:  54%|█████▎    | 285/532 [05:47<07:13,  1.76s/it]Loading train:  54%|█████▍    | 286/532 [05:49<07:13,  1.76s/it]Loading train:  54%|█████▍    | 287/532 [05:50<07:02,  1.73s/it]Loading train:  54%|█████▍    | 288/532 [05:51<06:12,  1.53s/it]Loading train:  54%|█████▍    | 289/532 [05:53<05:57,  1.47s/it]Loading train:  55%|█████▍    | 290/532 [05:54<05:50,  1.45s/it]Loading train:  55%|█████▍    | 291/532 [05:56<05:55,  1.48s/it]Loading train:  55%|█████▍    | 292/532 [05:57<05:54,  1.48s/it]Loading train:  55%|█████▌    | 293/532 [05:59<06:19,  1.59s/it]Loading train:  55%|█████▌    | 294/532 [06:01<06:33,  1.65s/it]Loading train:  55%|█████▌    | 295/532 [06:03<06:36,  1.67s/it]Loading train:  56%|█████▌    | 296/532 [06:04<06:25,  1.63s/it]Loading train:  56%|█████▌    | 297/532 [06:06<06:51,  1.75s/it]Loading train:  56%|█████▌    | 298/532 [06:08<07:17,  1.87s/it]Loading train:  56%|█████▌    | 299/532 [06:10<07:09,  1.84s/it]Loading train:  56%|█████▋    | 300/532 [06:11<06:33,  1.70s/it]Loading train:  57%|█████▋    | 301/532 [06:12<05:50,  1.52s/it]Loading train:  57%|█████▋    | 302/532 [06:14<05:30,  1.44s/it]Loading train:  57%|█████▋    | 303/532 [06:15<05:15,  1.38s/it]Loading train:  57%|█████▋    | 304/532 [06:16<04:45,  1.25s/it]Loading train:  57%|█████▋    | 305/532 [06:18<05:14,  1.39s/it]Loading train:  58%|█████▊    | 306/532 [06:19<05:42,  1.52s/it]Loading train:  58%|█████▊    | 307/532 [06:22<06:17,  1.68s/it]Loading train:  58%|█████▊    | 308/532 [06:23<06:13,  1.67s/it]Loading train:  58%|█████▊    | 309/532 [06:24<05:48,  1.56s/it]Loading train:  58%|█████▊    | 310/532 [06:26<06:08,  1.66s/it]Loading train:  58%|█████▊    | 311/532 [06:29<07:19,  1.99s/it]Loading train:  59%|█████▊    | 312/532 [06:31<07:42,  2.10s/it]Loading train:  59%|█████▉    | 313/532 [06:34<07:51,  2.15s/it]Loading train:  59%|█████▉    | 314/532 [06:37<08:30,  2.34s/it]Loading train:  59%|█████▉    | 315/532 [06:39<08:37,  2.39s/it]Loading train:  59%|█████▉    | 316/532 [06:41<08:29,  2.36s/it]Loading train:  60%|█████▉    | 317/532 [06:44<08:36,  2.40s/it]Loading train:  60%|█████▉    | 318/532 [06:45<07:01,  1.97s/it]Loading train:  60%|█████▉    | 319/532 [06:46<06:28,  1.83s/it]Loading train:  60%|██████    | 320/532 [06:47<05:45,  1.63s/it]Loading train:  60%|██████    | 321/532 [06:49<05:18,  1.51s/it]Loading train:  61%|██████    | 322/532 [06:50<05:05,  1.46s/it]Loading train:  61%|██████    | 323/532 [06:52<05:38,  1.62s/it]Loading train:  61%|██████    | 324/532 [06:54<05:33,  1.60s/it]Loading train:  61%|██████    | 325/532 [06:55<05:39,  1.64s/it]Loading train:  61%|██████▏   | 326/532 [06:57<06:03,  1.77s/it]Loading train:  61%|██████▏   | 327/532 [07:00<06:31,  1.91s/it]Loading train:  62%|██████▏   | 328/532 [07:02<06:36,  1.94s/it]Loading train:  62%|██████▏   | 329/532 [07:03<06:08,  1.81s/it]Loading train:  62%|██████▏   | 330/532 [07:04<05:27,  1.62s/it]Loading train:  62%|██████▏   | 331/532 [07:06<05:25,  1.62s/it]Loading train:  62%|██████▏   | 332/532 [07:07<05:12,  1.56s/it]Loading train:  63%|██████▎   | 333/532 [07:09<04:46,  1.44s/it]Loading train:  63%|██████▎   | 334/532 [07:10<04:48,  1.46s/it]Loading train:  63%|██████▎   | 335/532 [07:12<05:01,  1.53s/it]Loading train:  63%|██████▎   | 336/532 [07:13<04:51,  1.49s/it]Loading train:  63%|██████▎   | 337/532 [07:14<04:42,  1.45s/it]Loading train:  64%|██████▎   | 338/532 [07:16<04:29,  1.39s/it]Loading train:  64%|██████▎   | 339/532 [07:17<04:41,  1.46s/it]Loading train:  64%|██████▍   | 340/532 [07:19<05:11,  1.62s/it]Loading train:  64%|██████▍   | 341/532 [07:21<05:38,  1.77s/it]Loading train:  64%|██████▍   | 342/532 [07:23<05:36,  1.77s/it]Loading train:  64%|██████▍   | 343/532 [07:25<05:27,  1.73s/it]Loading train:  65%|██████▍   | 344/532 [07:26<05:12,  1.66s/it]Loading train:  65%|██████▍   | 345/532 [07:28<05:25,  1.74s/it]Loading train:  65%|██████▌   | 346/532 [07:30<05:20,  1.72s/it]Loading train:  65%|██████▌   | 347/532 [07:32<05:15,  1.71s/it]Loading train:  65%|██████▌   | 348/532 [07:33<05:15,  1.72s/it]Loading train:  66%|██████▌   | 349/532 [07:35<04:54,  1.61s/it]Loading train:  66%|██████▌   | 350/532 [07:36<04:46,  1.57s/it]Loading train:  66%|██████▌   | 351/532 [07:38<04:28,  1.48s/it]Loading train:  66%|██████▌   | 352/532 [07:39<04:20,  1.45s/it]Loading train:  66%|██████▋   | 353/532 [07:41<04:35,  1.54s/it]Loading train:  67%|██████▋   | 354/532 [07:42<04:13,  1.42s/it]Loading train:  67%|██████▋   | 355/532 [07:43<04:13,  1.43s/it]Loading train:  67%|██████▋   | 356/532 [07:45<04:14,  1.44s/it]Loading train:  67%|██████▋   | 357/532 [07:47<04:34,  1.57s/it]Loading train:  67%|██████▋   | 358/532 [07:49<05:07,  1.77s/it]Loading train:  67%|██████▋   | 359/532 [07:51<05:11,  1.80s/it]Loading train:  68%|██████▊   | 360/532 [07:52<04:50,  1.69s/it]Loading train:  68%|██████▊   | 361/532 [07:53<04:16,  1.50s/it]Loading train:  68%|██████▊   | 362/532 [07:54<04:03,  1.43s/it]Loading train:  68%|██████▊   | 363/532 [07:55<03:40,  1.31s/it]Loading train:  68%|██████▊   | 364/532 [07:57<03:52,  1.39s/it]Loading train:  69%|██████▊   | 365/532 [07:58<03:42,  1.33s/it]Loading train:  69%|██████▉   | 366/532 [07:59<03:25,  1.24s/it]Loading train:  69%|██████▉   | 367/532 [08:00<03:16,  1.19s/it]Loading train:  69%|██████▉   | 368/532 [08:02<03:16,  1.20s/it]Loading train:  69%|██████▉   | 369/532 [08:03<03:11,  1.17s/it]Loading train:  70%|██████▉   | 370/532 [08:04<03:18,  1.22s/it]Loading train:  70%|██████▉   | 371/532 [08:06<03:41,  1.38s/it]Loading train:  70%|██████▉   | 372/532 [08:07<03:53,  1.46s/it]Loading train:  70%|███████   | 373/532 [08:09<04:04,  1.54s/it]Loading train:  70%|███████   | 374/532 [08:11<04:18,  1.64s/it]Loading train:  70%|███████   | 375/532 [08:13<04:29,  1.71s/it]Loading train:  71%|███████   | 376/532 [08:15<04:36,  1.77s/it]Loading train:  71%|███████   | 377/532 [08:17<04:53,  1.89s/it]Loading train:  71%|███████   | 378/532 [08:19<04:48,  1.88s/it]Loading train:  71%|███████   | 379/532 [08:20<04:35,  1.80s/it]Loading train:  71%|███████▏  | 380/532 [08:22<04:20,  1.71s/it]Loading train:  72%|███████▏  | 381/532 [08:23<04:12,  1.67s/it]Loading train:  72%|███████▏  | 382/532 [08:25<04:06,  1.64s/it]Loading train:  72%|███████▏  | 383/532 [08:27<03:58,  1.60s/it]Loading train:  72%|███████▏  | 384/532 [08:28<03:55,  1.59s/it]Loading train:  72%|███████▏  | 385/532 [08:30<04:04,  1.66s/it]Loading train:  73%|███████▎  | 386/532 [08:31<03:56,  1.62s/it]Loading train:  73%|███████▎  | 387/532 [08:33<03:59,  1.65s/it]Loading train:  73%|███████▎  | 388/532 [08:35<03:55,  1.63s/it]Loading train:  73%|███████▎  | 389/532 [08:37<03:58,  1.67s/it]Loading train:  73%|███████▎  | 390/532 [08:38<03:59,  1.69s/it]Loading train:  73%|███████▎  | 391/532 [08:40<04:09,  1.77s/it]Loading train:  74%|███████▎  | 392/532 [08:42<04:01,  1.73s/it]Loading train:  74%|███████▍  | 393/532 [08:43<03:48,  1.65s/it]Loading train:  74%|███████▍  | 394/532 [08:45<04:02,  1.76s/it]Loading train:  74%|███████▍  | 395/532 [08:47<04:06,  1.80s/it]Loading train:  74%|███████▍  | 396/532 [08:49<03:49,  1.68s/it]Loading train:  75%|███████▍  | 397/532 [08:51<03:55,  1.74s/it]Loading train:  75%|███████▍  | 398/532 [08:53<04:12,  1.88s/it]Loading train:  75%|███████▌  | 399/532 [08:54<03:48,  1.72s/it]Loading train:  75%|███████▌  | 400/532 [08:56<04:00,  1.83s/it]Loading train:  75%|███████▌  | 401/532 [08:58<04:07,  1.89s/it]Loading train:  76%|███████▌  | 402/532 [09:00<03:48,  1.76s/it]Loading train:  76%|███████▌  | 403/532 [09:01<03:47,  1.77s/it]Loading train:  76%|███████▌  | 404/532 [09:03<03:53,  1.82s/it]Loading train:  76%|███████▌  | 405/532 [09:06<04:05,  1.93s/it]Loading train:  76%|███████▋  | 406/532 [09:07<03:51,  1.83s/it]Loading train:  77%|███████▋  | 407/532 [09:09<03:51,  1.85s/it]Loading train:  77%|███████▋  | 408/532 [09:10<03:28,  1.68s/it]Loading train:  77%|███████▋  | 409/532 [09:12<03:21,  1.63s/it]Loading train:  77%|███████▋  | 410/532 [09:13<03:10,  1.56s/it]Loading train:  77%|███████▋  | 411/532 [09:15<02:57,  1.47s/it]Loading train:  77%|███████▋  | 412/532 [09:16<03:03,  1.53s/it]Loading train:  78%|███████▊  | 413/532 [09:18<03:14,  1.64s/it]Loading train:  78%|███████▊  | 414/532 [09:20<03:15,  1.65s/it]Loading train:  78%|███████▊  | 415/532 [09:21<03:11,  1.64s/it]Loading train:  78%|███████▊  | 416/532 [09:23<03:04,  1.59s/it]Loading train:  78%|███████▊  | 417/532 [09:25<03:06,  1.62s/it]Loading train:  79%|███████▊  | 418/532 [09:26<03:15,  1.71s/it]Loading train:  79%|███████▉  | 419/532 [09:28<03:21,  1.79s/it]Loading train:  79%|███████▉  | 420/532 [09:30<03:25,  1.83s/it]Loading train:  79%|███████▉  | 421/532 [09:32<03:22,  1.83s/it]Loading train:  79%|███████▉  | 422/532 [09:34<03:29,  1.91s/it]Loading train:  80%|███████▉  | 423/532 [09:36<03:16,  1.81s/it]Loading train:  80%|███████▉  | 424/532 [09:37<03:03,  1.70s/it]Loading train:  80%|███████▉  | 425/532 [09:39<02:46,  1.56s/it]Loading train:  80%|████████  | 426/532 [09:40<02:43,  1.54s/it]Loading train:  80%|████████  | 427/532 [09:42<02:45,  1.58s/it]Loading train:  80%|████████  | 428/532 [09:44<03:01,  1.75s/it]Loading train:  81%|████████  | 429/532 [09:46<02:59,  1.74s/it]Loading train:  81%|████████  | 430/532 [09:47<02:58,  1.75s/it]Loading train:  81%|████████  | 431/532 [09:50<03:16,  1.95s/it]Loading train:  81%|████████  | 432/532 [09:52<03:17,  1.97s/it]Loading train:  81%|████████▏ | 433/532 [09:54<03:22,  2.04s/it]Loading train:  82%|████████▏ | 434/532 [09:56<03:09,  1.93s/it]Loading train:  82%|████████▏ | 435/532 [09:57<02:57,  1.83s/it]Loading train:  82%|████████▏ | 436/532 [09:59<02:57,  1.85s/it]Loading train:  82%|████████▏ | 437/532 [10:01<02:54,  1.84s/it]Loading train:  82%|████████▏ | 438/532 [10:02<02:43,  1.74s/it]Loading train:  83%|████████▎ | 439/532 [10:04<02:37,  1.70s/it]Loading train:  83%|████████▎ | 440/532 [10:06<02:31,  1.65s/it]Loading train:  83%|████████▎ | 441/532 [10:07<02:11,  1.44s/it]Loading train:  83%|████████▎ | 442/532 [10:08<02:02,  1.37s/it]Loading train:  83%|████████▎ | 443/532 [10:09<02:03,  1.38s/it]Loading train:  83%|████████▎ | 444/532 [10:10<01:54,  1.30s/it]Loading train:  84%|████████▎ | 445/532 [10:11<01:51,  1.28s/it]Loading train:  84%|████████▍ | 446/532 [10:13<01:48,  1.26s/it]Loading train:  84%|████████▍ | 447/532 [10:14<01:48,  1.28s/it]Loading train:  84%|████████▍ | 448/532 [10:15<01:42,  1.22s/it]Loading train:  84%|████████▍ | 449/532 [10:17<01:51,  1.35s/it]Loading train:  85%|████████▍ | 450/532 [10:18<01:50,  1.34s/it]Loading train:  85%|████████▍ | 451/532 [10:19<01:46,  1.32s/it]Loading train:  85%|████████▍ | 452/532 [10:21<01:43,  1.30s/it]Loading train:  85%|████████▌ | 453/532 [10:22<01:42,  1.30s/it]Loading train:  85%|████████▌ | 454/532 [10:23<01:45,  1.35s/it]Loading train:  86%|████████▌ | 455/532 [10:25<01:54,  1.49s/it]Loading train:  86%|████████▌ | 456/532 [10:27<02:01,  1.60s/it]Loading train:  86%|████████▌ | 457/532 [10:28<01:54,  1.53s/it]Loading train:  86%|████████▌ | 458/532 [10:30<01:45,  1.42s/it]Loading train:  86%|████████▋ | 459/532 [10:31<01:45,  1.44s/it]Loading train:  86%|████████▋ | 460/532 [10:33<01:44,  1.45s/it]Loading train:  87%|████████▋ | 461/532 [10:35<01:54,  1.61s/it]Loading train:  87%|████████▋ | 462/532 [10:37<02:05,  1.79s/it]Loading train:  87%|████████▋ | 463/532 [10:39<02:09,  1.88s/it]Loading train:  87%|████████▋ | 464/532 [10:42<02:29,  2.20s/it]Loading train:  87%|████████▋ | 465/532 [10:44<02:26,  2.18s/it]Loading train:  88%|████████▊ | 466/532 [10:46<02:22,  2.16s/it]Loading train:  88%|████████▊ | 467/532 [10:48<02:09,  2.00s/it]Loading train:  88%|████████▊ | 468/532 [10:49<01:56,  1.81s/it]Loading train:  88%|████████▊ | 469/532 [10:51<01:50,  1.75s/it]Loading train:  88%|████████▊ | 470/532 [10:52<01:48,  1.75s/it]Loading train:  89%|████████▊ | 471/532 [10:54<01:38,  1.61s/it]Loading train:  89%|████████▊ | 472/532 [10:55<01:33,  1.57s/it]Loading train:  89%|████████▉ | 473/532 [10:57<01:37,  1.65s/it]Loading train:  89%|████████▉ | 474/532 [10:59<01:42,  1.77s/it]Loading train:  89%|████████▉ | 475/532 [11:00<01:34,  1.65s/it]Loading train:  89%|████████▉ | 476/532 [11:02<01:34,  1.68s/it]Loading train:  90%|████████▉ | 477/532 [11:04<01:34,  1.72s/it]Loading train:  90%|████████▉ | 478/532 [11:05<01:27,  1.62s/it]Loading train:  90%|█████████ | 479/532 [11:07<01:20,  1.52s/it]Loading train:  90%|█████████ | 480/532 [11:08<01:17,  1.49s/it]Loading train:  90%|█████████ | 481/532 [11:09<01:13,  1.45s/it]Loading train:  91%|█████████ | 482/532 [11:11<01:16,  1.54s/it]Loading train:  91%|█████████ | 483/532 [11:13<01:17,  1.58s/it]Loading train:  91%|█████████ | 484/532 [11:14<01:16,  1.59s/it]Loading train:  91%|█████████ | 485/532 [11:17<01:22,  1.76s/it]Loading train:  91%|█████████▏| 486/532 [11:18<01:21,  1.78s/it]Loading train:  92%|█████████▏| 487/532 [11:20<01:20,  1.78s/it]Loading train:  92%|█████████▏| 488/532 [11:22<01:15,  1.72s/it]Loading train:  92%|█████████▏| 489/532 [11:24<01:17,  1.80s/it]Loading train:  92%|█████████▏| 490/532 [11:26<01:18,  1.87s/it]Loading train:  92%|█████████▏| 491/532 [11:27<01:09,  1.70s/it]Loading train:  92%|█████████▏| 492/532 [11:29<01:05,  1.64s/it]Loading train:  93%|█████████▎| 493/532 [11:30<01:05,  1.69s/it]Loading train:  93%|█████████▎| 494/532 [11:32<01:03,  1.67s/it]Loading train:  93%|█████████▎| 495/532 [11:34<01:03,  1.71s/it]Loading train:  93%|█████████▎| 496/532 [11:36<01:09,  1.92s/it]Loading train:  93%|█████████▎| 497/532 [11:37<00:59,  1.70s/it]Loading train:  94%|█████████▎| 498/532 [11:38<00:50,  1.49s/it]Loading train:  94%|█████████▍| 499/532 [11:40<00:49,  1.50s/it]Loading train:  94%|█████████▍| 500/532 [11:41<00:48,  1.51s/it]Loading train:  94%|█████████▍| 501/532 [11:43<00:46,  1.50s/it]Loading train:  94%|█████████▍| 502/532 [11:44<00:44,  1.48s/it]Loading train:  95%|█████████▍| 503/532 [11:45<00:38,  1.31s/it]Loading train:  95%|█████████▍| 504/532 [11:46<00:32,  1.18s/it]Loading train:  95%|█████████▍| 505/532 [11:47<00:29,  1.09s/it]Loading train:  95%|█████████▌| 506/532 [11:48<00:27,  1.04s/it]Loading train:  95%|█████████▌| 507/532 [11:49<00:24,  1.03it/s]Loading train:  95%|█████████▌| 508/532 [11:50<00:22,  1.06it/s]Loading train:  96%|█████████▌| 509/532 [11:51<00:24,  1.05s/it]Loading train:  96%|█████████▌| 510/532 [11:52<00:22,  1.04s/it]Loading train:  96%|█████████▌| 511/532 [11:53<00:21,  1.04s/it]Loading train:  96%|█████████▌| 512/532 [11:54<00:21,  1.05s/it]Loading train:  96%|█████████▋| 513/532 [11:55<00:20,  1.07s/it]Loading train:  97%|█████████▋| 514/532 [11:56<00:18,  1.04s/it]Loading train:  97%|█████████▋| 515/532 [11:57<00:16,  1.03it/s]Loading train:  97%|█████████▋| 516/532 [11:58<00:15,  1.07it/s]Loading train:  97%|█████████▋| 517/532 [11:59<00:13,  1.11it/s]Loading train:  97%|█████████▋| 518/532 [12:00<00:12,  1.11it/s]Loading train:  98%|█████████▊| 519/532 [12:00<00:11,  1.12it/s]Loading train:  98%|█████████▊| 520/532 [12:01<00:10,  1.15it/s]Loading train:  98%|█████████▊| 521/532 [12:02<00:10,  1.09it/s]Loading train:  98%|█████████▊| 522/532 [12:03<00:09,  1.09it/s]Loading train:  98%|█████████▊| 523/532 [12:04<00:08,  1.06it/s]Loading train:  98%|█████████▊| 524/532 [12:05<00:07,  1.07it/s]Loading train:  99%|█████████▊| 525/532 [12:06<00:06,  1.09it/s]Loading train:  99%|█████████▉| 526/532 [12:07<00:05,  1.12it/s]Loading train:  99%|█████████▉| 527/532 [12:08<00:04,  1.13it/s]Loading train:  99%|█████████▉| 528/532 [12:09<00:03,  1.15it/s]Loading train:  99%|█████████▉| 529/532 [12:09<00:02,  1.17it/s]Loading train: 100%|█████████▉| 530/532 [12:10<00:01,  1.23it/s]Loading train: 100%|█████████▉| 531/532 [12:11<00:00,  1.24it/s]Loading train: 100%|██████████| 532/532 [12:12<00:00,  1.24it/s]
concatenating: train:   0%|          | 0/532 [00:00<?, ?it/s]concatenating: train:   4%|▍         | 23/532 [00:00<00:02, 228.36it/s]concatenating: train:   9%|▉         | 49/532 [00:00<00:02, 235.54it/s]concatenating: train:  14%|█▍        | 76/532 [00:00<00:01, 233.84it/s]concatenating: train:  17%|█▋        | 92/532 [00:00<00:02, 179.18it/s]concatenating: train:  23%|██▎       | 120/532 [00:00<00:02, 200.76it/s]concatenating: train:  27%|██▋       | 146/532 [00:00<00:01, 214.33it/s]concatenating: train:  33%|███▎      | 174/532 [00:00<00:01, 226.79it/s]concatenating: train:  38%|███▊      | 200/532 [00:00<00:01, 234.41it/s]concatenating: train:  43%|████▎     | 227/532 [00:00<00:01, 242.83it/s]concatenating: train:  48%|████▊     | 254/532 [00:01<00:01, 246.95it/s]concatenating: train:  52%|█████▏    | 279/532 [00:01<00:01, 247.03it/s]concatenating: train:  58%|█████▊    | 307/532 [00:01<00:00, 254.48it/s]concatenating: train:  63%|██████▎   | 334/532 [00:01<00:00, 255.64it/s]concatenating: train:  68%|██████▊   | 360/532 [00:01<00:00, 249.76it/s]concatenating: train:  73%|███████▎  | 386/532 [00:01<00:00, 248.59it/s]concatenating: train:  77%|███████▋  | 411/532 [00:01<00:00, 243.86it/s]concatenating: train:  83%|████████▎ | 440/532 [00:01<00:00, 253.25it/s]concatenating: train:  88%|████████▊ | 467/532 [00:01<00:00, 255.97it/s]concatenating: train:  93%|█████████▎| 494/532 [00:02<00:00, 258.24it/s]concatenating: train:  98%|█████████▊| 523/532 [00:02<00:00, 266.49it/s]concatenating: train: 100%|██████████| 532/532 [00:02<00:00, 248.98it/s]
Loading test:   0%|          | 0/15 [00:00<?, ?it/s]Loading test:   7%|▋         | 1/15 [00:00<00:11,  1.23it/s]Loading test:  13%|█▎        | 2/15 [00:01<00:10,  1.23it/s]Loading test:  20%|██        | 3/15 [00:02<00:10,  1.15it/s]Loading test:  27%|██▋       | 4/15 [00:03<00:09,  1.11it/s]Loading test:  33%|███▎      | 5/15 [00:04<00:10,  1.01s/it]Loading test:  40%|████      | 6/15 [00:06<00:09,  1.05s/it]Loading test:  47%|████▋     | 7/15 [00:06<00:07,  1.04it/s]Loading test:  53%|█████▎    | 8/15 [00:08<00:07,  1.05s/it]Loading test:  60%|██████    | 9/15 [00:09<00:06,  1.03s/it]Loading test:  67%|██████▋   | 10/15 [00:09<00:04,  1.03it/s]Loading test:  73%|███████▎  | 11/15 [00:10<00:03,  1.05it/s]Loading test:  80%|████████  | 12/15 [00:11<00:03,  1.00s/it]Loading test:  87%|████████▋ | 13/15 [00:12<00:02,  1.01s/it]Loading test:  93%|█████████▎| 14/15 [00:13<00:01,  1.01s/it]Loading test: 100%|██████████| 15/15 [00:14<00:00,  1.01it/s]
concatenating: validation:   0%|          | 0/15 [00:00<?, ?it/s]concatenating: validation:  53%|█████▎    | 8/15 [00:00<00:00, 79.12it/s]concatenating: validation: 100%|██████████| 15/15 [00:00<00:00, 114.37it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 56, 84, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 56, 84, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 56, 84, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 56, 84, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 56, 84, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 84, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 56, 84, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 56, 84, 21)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 28, 42, 21)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28, 42, 21)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 42, 40)   7600        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 42, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 42, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 42, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 28, 42, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 28, 42, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 42, 61)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 21, 61)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 14, 21, 61)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 14, 21, 80)   44000       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 14, 21, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 14, 21, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 14, 21, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 14, 21, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 14, 21, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 14, 21, 141)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 14, 21, 141)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 28, 42, 40)   22600       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 28, 42, 101)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 28, 42, 40)   36400       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 28, 42, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________2019-07-07 02:55:04.882977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 02:55:04.883126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 02:55:04.883142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 02:55:04.883151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 02:55:04.883618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

activation_7 (Activation)       (None, 28, 42, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 28, 42, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 28, 42, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 28, 42, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 28, 42, 141)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 28, 42, 141)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 56, 84, 20)   11300       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 84, 41)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 56, 84, 20)   7400        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 56, 84, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 84, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 56, 84, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 56, 84, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 84, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 84, 61)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 56, 84, 61)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 56, 84, 13)   806         dropout_5[0][0]                  
==================================================================================================
Total params: 225,706
Trainable params: 224,906
Non-trainable params: 800
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.53383120e-02 2.88786827e-02 1.16652967e-01 1.00133292e-02
 3.03165963e-02 5.79538965e-03 6.85058777e-02 1.28145429e-01
 7.55135052e-02 1.22435092e-02 2.73464902e-01 1.84941443e-01
 1.90056842e-04]
Train on 20749 samples, validate on 584 samples
Epoch 1/300
 - 31s - loss: 34.9270 - acc: 0.7513 - mDice: 0.0288 - val_loss: 3.9896 - val_acc: 0.9134 - val_mDice: 0.0444

Epoch 00001: val_mDice improved from -inf to 0.04445, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 23s - loss: 4.4459 - acc: 0.8994 - mDice: 0.0769 - val_loss: 3.1429 - val_acc: 0.9121 - val_mDice: 0.1183

Epoch 00002: val_mDice improved from 0.04445 to 0.11826, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 21s - loss: 3.3493 - acc: 0.9093 - mDice: 0.1613 - val_loss: 2.2346 - val_acc: 0.9313 - val_mDice: 0.2551

Epoch 00003: val_mDice improved from 0.11826 to 0.25506, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 21s - loss: 2.5468 - acc: 0.9259 - mDice: 0.2907 - val_loss: 1.5961 - val_acc: 0.9552 - val_mDice: 0.4338

Epoch 00004: val_mDice improved from 0.25506 to 0.43378, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 22s - loss: 2.0621 - acc: 0.9385 - mDice: 0.3968 - val_loss: 1.2473 - val_acc: 0.9652 - val_mDice: 0.5522

Epoch 00005: val_mDice improved from 0.43378 to 0.55225, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 21s - loss: 1.7655 - acc: 0.9457 - mDice: 0.4706 - val_loss: 1.0851 - val_acc: 0.9702 - val_mDice: 0.6235

Epoch 00006: val_mDice improved from 0.55225 to 0.62349, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 21s - loss: 1.5765 - acc: 0.9506 - mDice: 0.5211 - val_loss: 0.9571 - val_acc: 0.9710 - val_mDice: 0.6650

Epoch 00007: val_mDice improved from 0.62349 to 0.66502, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 21s - loss: 1.4456 - acc: 0.9538 - mDice: 0.5559 - val_loss: 0.9227 - val_acc: 0.9723 - val_mDice: 0.6815

Epoch 00008: val_mDice improved from 0.66502 to 0.68148, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 9/300
 - 22s - loss: 1.3486 - acc: 0.9557 - mDice: 0.5807 - val_loss: 0.8546 - val_acc: 0.9746 - val_mDice: 0.7035

Epoch 00009: val_mDice improved from 0.68148 to 0.70355, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 21s - loss: 1.2729 - acc: 0.9574 - mDice: 0.6012 - val_loss: 0.8456 - val_acc: 0.9747 - val_mDice: 0.7073

Epoch 00010: val_mDice improved from 0.70355 to 0.70730, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 11/300
 - 21s - loss: 1.2148 - acc: 0.9586 - mDice: 0.6165 - val_loss: 0.8179 - val_acc: 0.9753 - val_mDice: 0.7173

Epoch 00011: val_mDice improved from 0.70730 to 0.71727, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 12/300
 - 21s - loss: 1.1651 - acc: 0.9596 - mDice: 0.6300 - val_loss: 0.8249 - val_acc: 0.9746 - val_mDice: 0.7222

Epoch 00012: val_mDice improved from 0.71727 to 0.72219, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 13/300
 - 22s - loss: 1.1194 - acc: 0.9605 - mDice: 0.6420 - val_loss: 0.7985 - val_acc: 0.9740 - val_mDice: 0.7302

Epoch 00013: val_mDice improved from 0.72219 to 0.73016, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 14/300
 - 21s - loss: 1.0879 - acc: 0.9610 - mDice: 0.6508 - val_loss: 0.7915 - val_acc: 0.9746 - val_mDice: 0.7311

Epoch 00014: val_mDice improved from 0.73016 to 0.73115, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 15/300
 - 21s - loss: 1.0502 - acc: 0.9618 - mDice: 0.6608 - val_loss: 0.7733 - val_acc: 0.9762 - val_mDice: 0.7372

Epoch 00015: val_mDice improved from 0.73115 to 0.73721, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 16/300
 - 22s - loss: 1.0213 - acc: 0.9623 - mDice: 0.6686 - val_loss: 0.7863 - val_acc: 0.9756 - val_mDice: 0.7367

Epoch 00016: val_mDice did not improve from 0.73721
Epoch 17/300
 - 22s - loss: 1.0028 - acc: 0.9626 - mDice: 0.6736 - val_loss: 0.7716 - val_acc: 0.9763 - val_mDice: 0.7393

Epoch 00017: val_mDice improved from 0.73721 to 0.73932, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 18/300
 - 23s - loss: 0.9798 - acc: 0.9631 - mDice: 0.6799 - val_loss: 0.7561 - val_acc: 0.9774 - val_mDice: 0.7439

Epoch 00018: val_mDice improved from 0.73932 to 0.74385, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 19/300
 - 22s - loss: 0.9617 - acc: 0.9635 - mDice: 0.6847 - val_loss: 0.7506 - val_acc: 0.9771 - val_mDice: 0.7473

Epoch 00019: val_mDice improved from 0.74385 to 0.74728, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 20/300
 - 23s - loss: 0.9456 - acc: 0.9638 - mDice: 0.6892 - val_loss: 0.7412 - val_acc: 0.9766 - val_mDice: 0.7491

Epoch 00020: val_mDice improved from 0.74728 to 0.74908, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 21/300
 - 22s - loss: 0.9249 - acc: 0.9641 - mDice: 0.6949 - val_loss: 0.7394 - val_acc: 0.9765 - val_mDice: 0.7465

Epoch 00021: val_mDice did not improve from 0.74908
Epoch 22/300
 - 22s - loss: 0.9102 - acc: 0.9644 - mDice: 0.6992 - val_loss: 0.7415 - val_acc: 0.9767 - val_mDice: 0.7512

Epoch 00022: val_mDice improved from 0.74908 to 0.75115, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 23/300
 - 23s - loss: 0.8981 - acc: 0.9647 - mDice: 0.7022 - val_loss: 0.7342 - val_acc: 0.9761 - val_mDice: 0.7550

Epoch 00023: val_mDice improved from 0.75115 to 0.75504, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 24/300
 - 22s - loss: 0.8861 - acc: 0.9650 - mDice: 0.7061 - val_loss: 0.7425 - val_acc: 0.9770 - val_mDice: 0.7522

Epoch 00024: val_mDice did not improve from 0.75504
Epoch 25/300
 - 22s - loss: 0.8768 - acc: 0.9652 - mDice: 0.7090 - val_loss: 0.7354 - val_acc: 0.9770 - val_mDice: 0.7544

Epoch 00025: val_mDice did not improve from 0.75504
Epoch 26/300
 - 23s - loss: 0.8653 - acc: 0.9655 - mDice: 0.7122 - val_loss: 0.7294 - val_acc: 0.9789 - val_mDice: 0.7503

Epoch 00026: val_mDice did not improve from 0.75504
Epoch 27/300
 - 22s - loss: 0.8521 - acc: 0.9658 - mDice: 0.7161 - val_loss: 0.7406 - val_acc: 0.9782 - val_mDice: 0.7521

Epoch 00027: val_mDice did not improve from 0.75504
Epoch 28/300
 - 22s - loss: 0.8455 - acc: 0.9660 - mDice: 0.7181 - val_loss: 0.7216 - val_acc: 0.9786 - val_mDice: 0.7567

Epoch 00028: val_mDice improved from 0.75504 to 0.75668, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 29/300
 - 22s - loss: 0.8309 - acc: 0.9663 - mDice: 0.7222 - val_loss: 0.7303 - val_acc: 0.9762 - val_mDice: 0.7568

Epoch 00029: val_mDice improved from 0.75668 to 0.75683, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 30/300
 - 22s - loss: 0.8255 - acc: 0.9664 - mDice: 0.7241 - val_loss: 0.7136 - val_acc: 0.9778 - val_mDice: 0.7590

Epoch 00030: val_mDice improved from 0.75683 to 0.75899, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 31/300
 - 22s - loss: 0.8183 - acc: 0.9666 - mDice: 0.7261 - val_loss: 0.7186 - val_acc: 0.9778 - val_mDice: 0.7579

Epoch 00031: val_mDice did not improve from 0.75899
Epoch 32/300
 - 22s - loss: 0.8085 - acc: 0.9668 - mDice: 0.7288 - val_loss: 0.7121 - val_acc: 0.9783 - val_mDice: 0.7600

Epoch 00032: val_mDice improved from 0.75899 to 0.75998, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 33/300
 - 22s - loss: 0.8020 - acc: 0.9670 - mDice: 0.7307 - val_loss: 0.7241 - val_acc: 0.9767 - val_mDice: 0.7579

Epoch 00033: val_mDice did not improve from 0.75998
Epoch 34/300
 - 23s - loss: 0.8013 - acc: 0.9669 - mDice: 0.7309 - val_loss: 0.7174 - val_acc: 0.9775 - val_mDice: 0.7602

Epoch 00034: val_mDice improved from 0.75998 to 0.76024, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 35/300
 - 23s - loss: 0.7854 - acc: 0.9673 - mDice: 0.7360 - val_loss: 0.6897 - val_acc: 0.9791 - val_mDice: 0.7629

Epoch 00035: val_mDice improved from 0.76024 to 0.76295, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 36/300
 - 23s - loss: 0.7821 - acc: 0.9674 - mDice: 0.7372 - val_loss: 0.6962 - val_acc: 0.9789 - val_mDice: 0.7648

Epoch 00036: val_mDice improved from 0.76295 to 0.76479, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 37/300
 - 24s - loss: 0.7775 - acc: 0.9674 - mDice: 0.7383 - val_loss: 0.7016 - val_acc: 0.9793 - val_mDice: 0.7628

Epoch 00037: val_mDice did not improve from 0.76479
Epoch 38/300
 - 24s - loss: 0.7749 - acc: 0.9675 - mDice: 0.7393 - val_loss: 0.7108 - val_acc: 0.9790 - val_mDice: 0.7618

Epoch 00038: val_mDice did not improve from 0.76479
Epoch 39/300
 - 23s - loss: 0.7699 - acc: 0.9675 - mDice: 0.7405 - val_loss: 0.6974 - val_acc: 0.9785 - val_mDice: 0.7657

Epoch 00039: val_mDice improved from 0.76479 to 0.76568, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 40/300
 - 24s - loss: 0.7626 - acc: 0.9677 - mDice: 0.7430 - val_loss: 0.7098 - val_acc: 0.9781 - val_mDice: 0.7655

Epoch 00040: val_mDice did not improve from 0.76568
Epoch 41/300
 - 24s - loss: 0.7611 - acc: 0.9677 - mDice: 0.7431 - val_loss: 0.7000 - val_acc: 0.9786 - val_mDice: 0.7622

Epoch 00041: val_mDice did not improve from 0.76568
Epoch 42/300
 - 24s - loss: 0.7536 - acc: 0.9678 - mDice: 0.7455 - val_loss: 0.7033 - val_acc: 0.9780 - val_mDice: 0.7655

Epoch 00042: val_mDice did not improve from 0.76568
Epoch 43/300
 - 24s - loss: 0.7476 - acc: 0.9680 - mDice: 0.7473 - val_loss: 0.6985 - val_acc: 0.9791 - val_mDice: 0.7690

Epoch 00043: val_mDice improved from 0.76568 to 0.76896, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 44/300
 - 24s - loss: 0.7458 - acc: 0.9680 - mDice: 0.7479 - val_loss: 0.6962 - val_acc: 0.9791 - val_mDice: 0.7660

Epoch 00044: val_mDice did not improve from 0.76896
Epoch 45/300
 - 23s - loss: 0.7400 - acc: 0.9681 - mDice: 0.7498 - val_loss: 0.6934 - val_acc: 0.9794 - val_mDice: 0.7671

Epoch 00045: val_mDice did not improve from 0.76896
Epoch 46/300
 - 23s - loss: 0.7371 - acc: 0.9681 - mDice: 0.7506 - val_loss: 0.6982 - val_acc: 0.9791 - val_mDice: 0.7722

Epoch 00046: val_mDice improved from 0.76896 to 0.77215, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 47/300
 - 21s - loss: 0.7340 - acc: 0.9681 - mDice: 0.7516 - val_loss: 0.6950 - val_acc: 0.9794 - val_mDice: 0.7668

Epoch 00047: val_mDice did not improve from 0.77215
Epoch 48/300
 - 23s - loss: 0.7298 - acc: 0.9682 - mDice: 0.7528 - val_loss: 0.6898 - val_acc: 0.9792 - val_mDice: 0.7678

Epoch 00048: val_mDice did not improve from 0.77215
Epoch 49/300
 - 21s - loss: 0.7258 - acc: 0.9683 - mDice: 0.7542 - val_loss: 0.7000 - val_acc: 0.9789 - val_mDice: 0.7675

Epoch 00049: val_mDice did not improve from 0.77215
Epoch 50/300
 - 21s - loss: 0.7226 - acc: 0.9683 - mDice: 0.7550 - val_loss: 0.6875 - val_acc: 0.9793 - val_mDice: 0.7716

Epoch 00050: val_mDice did not improve from 0.77215
Epoch 51/300
 - 21s - loss: 0.7205 - acc: 0.9684 - mDice: 0.7558 - val_loss: 0.6880 - val_acc: 0.9794 - val_mDice: 0.7704

Epoch 00051: val_mDice did not improve from 0.77215
Epoch 52/300
 - 22s - loss: 0.7186 - acc: 0.9684 - mDice: 0.7563 - val_loss: 0.7128 - val_acc: 0.9776 - val_mDice: 0.7672

Epoch 00052: val_mDice did not improve from 0.77215
Epoch 53/300
 - 21s - loss: 0.7156 - acc: 0.9685 - mDice: 0.7571 - val_loss: 0.6811 - val_acc: 0.9798 - val_mDice: 0.7710

Epoch 00053: val_mDice did not improve from 0.77215
Epoch 54/300
 - 21s - loss: 0.7131 - acc: 0.9685 - mDice: 0.7579 - val_loss: 0.6867 - val_acc: 0.9793 - val_mDice: 0.7708

Epoch 00054: val_mDice did not improve from 0.77215
Epoch 55/300
 - 21s - loss: 0.7072 - acc: 0.9686 - mDice: 0.7595 - val_loss: 0.6916 - val_acc: 0.9789 - val_mDice: 0.7699

Epoch 00055: val_mDice did not improve from 0.77215
Epoch 56/300
 - 22s - loss: 0.7066 - acc: 0.9686 - mDice: 0.7599 - val_loss: 0.6834 - val_acc: 0.9792 - val_mDice: 0.7758

Epoch 00056: val_mDice improved from 0.77215 to 0.77581, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 57/300
 - 21s - loss: 0.7047 - acc: 0.9686 - mDice: 0.7605 - val_loss: 0.6950 - val_acc: 0.9798 - val_mDice: 0.7711

Epoch 00057: val_mDice did not improve from 0.77581
Epoch 58/300
 - 21s - loss: 0.7005 - acc: 0.9687 - mDice: 0.7620 - val_loss: 0.6809 - val_acc: 0.9792 - val_mDice: 0.7736

Epoch 00058: val_mDice did not improve from 0.77581
Epoch 59/300
 - 21s - loss: 0.6986 - acc: 0.9687 - mDice: 0.7624 - val_loss: 0.7081 - val_acc: 0.9789 - val_mDice: 0.7701

Epoch 00059: val_mDice did not improve from 0.77581
Epoch 60/300
 - 22s - loss: 0.6960 - acc: 0.9688 - mDice: 0.7634 - val_loss: 0.6862 - val_acc: 0.9788 - val_mDice: 0.7764

Epoch 00060: val_mDice improved from 0.77581 to 0.77644, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 61/300
 - 21s - loss: 0.6950 - acc: 0.9688 - mDice: 0.7635 - val_loss: 0.6916 - val_acc: 0.9785 - val_mDice: 0.7743

Epoch 00061: val_mDice did not improve from 0.77644
Epoch 62/300
 - 21s - loss: 0.6921 - acc: 0.9688 - mDice: 0.7645 - val_loss: 0.6978 - val_acc: 0.9793 - val_mDice: 0.7715

Epoch 00062: val_mDice did not improve from 0.77644
Epoch 63/300
 - 21s - loss: 0.6899 - acc: 0.9689 - mDice: 0.7653 - val_loss: 0.6907 - val_acc: 0.9795 - val_mDice: 0.7719

Epoch 00063: val_mDice did not improve from 0.77644
Epoch 64/300
 - 21s - loss: 0.6878 - acc: 0.9689 - mDice: 0.7658 - val_loss: 0.6752 - val_acc: 0.9796 - val_mDice: 0.7752

Epoch 00064: val_mDice did not improve from 0.77644
Epoch 65/300
 - 23s - loss: 0.6834 - acc: 0.9689 - mDice: 0.7671 - val_loss: 0.6961 - val_acc: 0.9788 - val_mDice: 0.7759

Epoch 00065: val_mDice did not improve from 0.77644
Epoch 66/300
 - 22s - loss: 0.6843 - acc: 0.9689 - mDice: 0.7671 - val_loss: 0.6957 - val_acc: 0.9798 - val_mDice: 0.7724

Epoch 00066: val_mDice did not improve from 0.77644
Epoch 67/300
 - 22s - loss: 0.6830 - acc: 0.9689 - mDice: 0.7671 - val_loss: 0.6837 - val_acc: 0.9796 - val_mDice: 0.7757

Epoch 00067: val_mDice did not improve from 0.77644
Epoch 68/300
 - 21s - loss: 0.6791 - acc: 0.9690 - mDice: 0.7687 - val_loss: 0.6824 - val_acc: 0.9796 - val_mDice: 0.7778

Epoch 00068: val_mDice improved from 0.77644 to 0.77782, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 69/300
 - 22s - loss: 0.6776 - acc: 0.9690 - mDice: 0.7690 - val_loss: 0.6792 - val_acc: 0.9792 - val_mDice: 0.7729

Epoch 00069: val_mDice did not improve from 0.77782
Epoch 70/300
 - 22s - loss: 0.6764 - acc: 0.9690 - mDice: 0.7694 - val_loss: 0.6869 - val_acc: 0.9793 - val_mDice: 0.7748

Epoch 00070: val_mDice did not improve from 0.77782
Epoch 71/300
 - 21s - loss: 0.6770 - acc: 0.9690 - mDice: 0.7690 - val_loss: 0.6937 - val_acc: 0.9785 - val_mDice: 0.7789

Epoch 00071: val_mDice improved from 0.77782 to 0.77889, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 72/300
 - 23s - loss: 0.6740 - acc: 0.9691 - mDice: 0.7701 - val_loss: 0.6784 - val_acc: 0.9800 - val_mDice: 0.7756

Epoch 00072: val_mDice did not improve from 0.77889
Epoch 73/300
 - 22s - loss: 0.6706 - acc: 0.9692 - mDice: 0.7712 - val_loss: 0.6785 - val_acc: 0.9800 - val_mDice: 0.7790

Epoch 00073: val_mDice improved from 0.77889 to 0.77896, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 74/300
 - 23s - loss: 0.6709 - acc: 0.9691 - mDice: 0.7711 - val_loss: 0.6905 - val_acc: 0.9786 - val_mDice: 0.7792

Epoch 00074: val_mDice improved from 0.77896 to 0.77921, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 75/300
 - 22s - loss: 0.6679 - acc: 0.9692 - mDice: 0.7721 - val_loss: 0.6842 - val_acc: 0.9786 - val_mDice: 0.7770

Epoch 00075: val_mDice did not improve from 0.77921
Epoch 76/300
 - 23s - loss: 0.6674 - acc: 0.9692 - mDice: 0.7723 - val_loss: 0.6780 - val_acc: 0.9796 - val_mDice: 0.7791

Epoch 00076: val_mDice did not improve from 0.77921
Epoch 77/300
 - 22s - loss: 0.6661 - acc: 0.9692 - mDice: 0.7727 - val_loss: 0.6820 - val_acc: 0.9797 - val_mDice: 0.7764

Epoch 00077: val_mDice did not improve from 0.77921
Epoch 78/300
 - 23s - loss: 0.6630 - acc: 0.9692 - mDice: 0.7735 - val_loss: 0.6790 - val_acc: 0.9793 - val_mDice: 0.7810

Epoch 00078: val_mDice improved from 0.77921 to 0.78100, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 79/300
 - 23s - loss: 0.6617 - acc: 0.9692 - mDice: 0.7741 - val_loss: 0.6752 - val_acc: 0.9795 - val_mDice: 0.7774

Epoch 00079: val_mDice did not improve from 0.78100
Epoch 80/300
 - 22s - loss: 0.6614 - acc: 0.9693 - mDice: 0.7742 - val_loss: 0.6749 - val_acc: 0.9797 - val_mDice: 0.7776

Epoch 00080: val_mDice did not improve from 0.78100
Epoch 81/300
 - 22s - loss: 0.6603 - acc: 0.9693 - mDice: 0.7745 - val_loss: 0.6849 - val_acc: 0.9798 - val_mDice: 0.7745

Epoch 00081: val_mDice did not improve from 0.78100
Epoch 82/300
 - 23s - loss: 0.6586 - acc: 0.9693 - mDice: 0.7749 - val_loss: 0.6774 - val_acc: 0.9797 - val_mDice: 0.7794

Epoch 00082: val_mDice did not improve from 0.78100
Epoch 83/300
 - 22s - loss: 0.6572 - acc: 0.9694 - mDice: 0.7753 - val_loss: 0.6846 - val_acc: 0.9795 - val_mDice: 0.7806

Epoch 00083: val_mDice did not improve from 0.78100
Epoch 84/300
 - 23s - loss: 0.6554 - acc: 0.9694 - mDice: 0.7762 - val_loss: 0.6834 - val_acc: 0.9793 - val_mDice: 0.7793

Epoch 00084: val_mDice did not improve from 0.78100
Epoch 85/300
 - 23s - loss: 0.6541 - acc: 0.9694 - mDice: 0.7767 - val_loss: 0.6795 - val_acc: 0.9794 - val_mDice: 0.7801

Epoch 00085: val_mDice did not improve from 0.78100
Epoch 86/300
 - 22s - loss: 0.6558 - acc: 0.9694 - mDice: 0.7759 - val_loss: 0.6777 - val_acc: 0.9798 - val_mDice: 0.7799

Epoch 00086: val_mDice did not improve from 0.78100
Epoch 87/300
 - 23s - loss: 0.6544 - acc: 0.9694 - mDice: 0.7765 - val_loss: 0.6809 - val_acc: 0.9793 - val_mDice: 0.7759

Epoch 00087: val_mDice did not improve from 0.78100
Epoch 88/300
 - 23s - loss: 0.6503 - acc: 0.9695 - mDice: 0.7778 - val_loss: 0.6936 - val_acc: 0.9794 - val_mDice: 0.7762

Epoch 00088: val_mDice did not improve from 0.78100
Epoch 89/300
 - 22s - loss: 0.6502 - acc: 0.9695 - mDice: 0.7776 - val_loss: 0.6752 - val_acc: 0.9791 - val_mDice: 0.7829

Epoch 00089: val_mDice improved from 0.78100 to 0.78292, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 90/300
 - 24s - loss: 0.6478 - acc: 0.9695 - mDice: 0.7785 - val_loss: 0.6751 - val_acc: 0.9797 - val_mDice: 0.7810

Epoch 00090: val_mDice did not improve from 0.78292
Epoch 91/300
 - 24s - loss: 0.6452 - acc: 0.9696 - mDice: 0.7794 - val_loss: 0.6858 - val_acc: 0.9804 - val_mDice: 0.7782

Epoch 00091: val_mDice did not improve from 0.78292
Epoch 92/300
 - 24s - loss: 0.6462 - acc: 0.9696 - mDice: 0.7791 - val_loss: 0.6865 - val_acc: 0.9793 - val_mDice: 0.7814

Epoch 00092: val_mDice did not improve from 0.78292
Epoch 93/300
 - 24s - loss: 0.6440 - acc: 0.9696 - mDice: 0.7799 - val_loss: 0.6771 - val_acc: 0.9796 - val_mDice: 0.7813

Epoch 00093: val_mDice did not improve from 0.78292
Epoch 94/300
 - 25s - loss: 0.6447 - acc: 0.9696 - mDice: 0.7796 - val_loss: 0.6825 - val_acc: 0.9803 - val_mDice: 0.7808

Epoch 00094: val_mDice did not improve from 0.78292
Epoch 95/300
 - 25s - loss: 0.6432 - acc: 0.9696 - mDice: 0.7800 - val_loss: 0.6944 - val_acc: 0.9786 - val_mDice: 0.7852

Epoch 00095: val_mDice improved from 0.78292 to 0.78521, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 96/300
 - 24s - loss: 0.6422 - acc: 0.9696 - mDice: 0.7805 - val_loss: 0.6804 - val_acc: 0.9795 - val_mDice: 0.7796

Epoch 00096: val_mDice did not improve from 0.78521
Epoch 97/300
 - 25s - loss: 0.6394 - acc: 0.9697 - mDice: 0.7814 - val_loss: 0.6863 - val_acc: 0.9796 - val_mDice: 0.7824

Epoch 00097: val_mDice did not improve from 0.78521
Epoch 98/300
 - 26s - loss: 0.6416 - acc: 0.9696 - mDice: 0.7804 - val_loss: 0.6820 - val_acc: 0.9801 - val_mDice: 0.7854

Epoch 00098: val_mDice improved from 0.78521 to 0.78545, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 99/300
 - 26s - loss: 0.6402 - acc: 0.9697 - mDice: 0.7810 - val_loss: 0.6809 - val_acc: 0.9793 - val_mDice: 0.7807

Epoch 00099: val_mDice did not improve from 0.78545
Epoch 100/300
 - 25s - loss: 0.6384 - acc: 0.9697 - mDice: 0.7814 - val_loss: 0.6934 - val_acc: 0.9796 - val_mDice: 0.7798

Epoch 00100: val_mDice did not improve from 0.78545
Epoch 101/300
 - 24s - loss: 0.6373 - acc: 0.9698 - mDice: 0.7821 - val_loss: 0.6816 - val_acc: 0.9788 - val_mDice: 0.7839

Epoch 00101: val_mDice did not improve from 0.78545
Epoch 102/300
 - 25s - loss: 0.6360 - acc: 0.9698 - mDice: 0.7826 - val_loss: 0.6790 - val_acc: 0.9797 - val_mDice: 0.7846

Epoch 00102: val_mDice did not improve from 0.78545
Epoch 103/300
 - 26s - loss: 0.6356 - acc: 0.9698 - mDice: 0.7826 - val_loss: 0.6710 - val_acc: 0.9798 - val_mDice: 0.7832

Epoch 00103: val_mDice did not improve from 0.78545
Epoch 104/300
 - 24s - loss: 0.6334 - acc: 0.9698 - mDice: 0.7834 - val_loss: 0.6700 - val_acc: 0.9798 - val_mDice: 0.7824

Epoch 00104: val_mDice did not improve from 0.78545
Epoch 105/300
 - 24s - loss: 0.6339 - acc: 0.9698 - mDice: 0.7830 - val_loss: 0.6797 - val_acc: 0.9790 - val_mDice: 0.7835

Epoch 00105: val_mDice did not improve from 0.78545
Epoch 106/300
 - 25s - loss: 0.6319 - acc: 0.9698 - mDice: 0.7838 - val_loss: 0.6744 - val_acc: 0.9793 - val_mDice: 0.7858

Epoch 00106: val_mDice improved from 0.78545 to 0.78578, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 107/300
 - 26s - loss: 0.6320 - acc: 0.9698 - mDice: 0.7838 - val_loss: 0.6735 - val_acc: 0.9795 - val_mDice: 0.7865

Epoch 00107: val_mDice improved from 0.78578 to 0.78654, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 108/300
 - 29s - loss: 0.6319 - acc: 0.9698 - mDice: 0.7838 - val_loss: 0.6758 - val_acc: 0.9795 - val_mDice: 0.7839

Epoch 00108: val_mDice did not improve from 0.78654
Epoch 109/300
 - 30s - loss: 0.6298 - acc: 0.9699 - mDice: 0.7845 - val_loss: 0.6858 - val_acc: 0.9799 - val_mDice: 0.7871

Epoch 00109: val_mDice improved from 0.78654 to 0.78715, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 110/300
 - 32s - loss: 0.6276 - acc: 0.9699 - mDice: 0.7852 - val_loss: 0.6700 - val_acc: 0.9798 - val_mDice: 0.7875

Epoch 00110: val_mDice improved from 0.78715 to 0.78755, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 111/300
 - 30s - loss: 0.6271 - acc: 0.9699 - mDice: 0.7856 - val_loss: 0.6757 - val_acc: 0.9798 - val_mDice: 0.7855

Epoch 00111: val_mDice did not improve from 0.78755
Epoch 112/300
 - 31s - loss: 0.6259 - acc: 0.9699 - mDice: 0.7857 - val_loss: 0.6715 - val_acc: 0.9798 - val_mDice: 0.7873

Epoch 00112: val_mDice did not improve from 0.78755
Epoch 113/300
 - 31s - loss: 0.6255 - acc: 0.9699 - mDice: 0.7860 - val_loss: 0.6803 - val_acc: 0.9802 - val_mDice: 0.7839

Epoch 00113: val_mDice did not improve from 0.78755
Epoch 114/300
 - 29s - loss: 0.6259 - acc: 0.9699 - mDice: 0.7860 - val_loss: 0.6813 - val_acc: 0.9797 - val_mDice: 0.7862

Epoch 00114: val_mDice did not improve from 0.78755
Epoch 115/300
 - 25s - loss: 0.6262 - acc: 0.9699 - mDice: 0.7858 - val_loss: 0.6749 - val_acc: 0.9798 - val_mDice: 0.7882

Epoch 00115: val_mDice improved from 0.78755 to 0.78819, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 116/300
 - 24s - loss: 0.6250 - acc: 0.9699 - mDice: 0.7862 - val_loss: 0.6818 - val_acc: 0.9794 - val_mDice: 0.7893

Epoch 00116: val_mDice improved from 0.78819 to 0.78934, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 117/300
 - 25s - loss: 0.6222 - acc: 0.9700 - mDice: 0.7870 - val_loss: 0.6777 - val_acc: 0.9799 - val_mDice: 0.7872

Epoch 00117: val_mDice did not improve from 0.78934
Epoch 118/300
 - 24s - loss: 0.6222 - acc: 0.9700 - mDice: 0.7873 - val_loss: 0.6752 - val_acc: 0.9801 - val_mDice: 0.7878

Epoch 00118: val_mDice did not improve from 0.78934
Epoch 119/300
 - 24s - loss: 0.6204 - acc: 0.9700 - mDice: 0.7878 - val_loss: 0.6783 - val_acc: 0.9801 - val_mDice: 0.7843

Epoch 00119: val_mDice did not improve from 0.78934
Epoch 120/300
 - 24s - loss: 0.6207 - acc: 0.9700 - mDice: 0.7877 - val_loss: 0.6809 - val_acc: 0.9801 - val_mDice: 0.7861

Epoch 00120: val_mDice did not improve from 0.78934
Epoch 121/300
 - 24s - loss: 0.6194 - acc: 0.9700 - mDice: 0.7882 - val_loss: 0.6726 - val_acc: 0.9795 - val_mDice: 0.7862

Epoch 00121: val_mDice did not improve from 0.78934
Epoch 122/300
 - 22s - loss: 0.6198 - acc: 0.9700 - mDice: 0.7882 - val_loss: 0.6670 - val_acc: 0.9800 - val_mDice: 0.7895

Epoch 00122: val_mDice improved from 0.78934 to 0.78948, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 123/300
 - 22s - loss: 0.6201 - acc: 0.9700 - mDice: 0.7879 - val_loss: 0.6675 - val_acc: 0.9798 - val_mDice: 0.7888

Epoch 00123: val_mDice did not improve from 0.78948
Epoch 124/300
 - 21s - loss: 0.6174 - acc: 0.9701 - mDice: 0.7887 - val_loss: 0.6750 - val_acc: 0.9794 - val_mDice: 0.7877

Epoch 00124: val_mDice did not improve from 0.78948
Epoch 125/300
 - 23s - loss: 0.6163 - acc: 0.9701 - mDice: 0.7894 - val_loss: 0.6724 - val_acc: 0.9799 - val_mDice: 0.7883

Epoch 00125: val_mDice did not improve from 0.78948
Epoch 126/300
 - 21s - loss: 0.6150 - acc: 0.9702 - mDice: 0.7895 - val_loss: 0.6672 - val_acc: 0.9801 - val_mDice: 0.7906

Epoch 00126: val_mDice improved from 0.78948 to 0.79064, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 127/300
 - 21s - loss: 0.6143 - acc: 0.9702 - mDice: 0.7898 - val_loss: 0.6722 - val_acc: 0.9797 - val_mDice: 0.7879

Epoch 00127: val_mDice did not improve from 0.79064
Epoch 128/300
 - 22s - loss: 0.6149 - acc: 0.9701 - mDice: 0.7902 - val_loss: 0.6658 - val_acc: 0.9799 - val_mDice: 0.7902

Epoch 00128: val_mDice did not improve from 0.79064
Epoch 129/300
 - 22s - loss: 0.6148 - acc: 0.9701 - mDice: 0.7899 - val_loss: 0.6705 - val_acc: 0.9801 - val_mDice: 0.7878

Epoch 00129: val_mDice did not improve from 0.79064
Epoch 130/300
 - 21s - loss: 0.6146 - acc: 0.9701 - mDice: 0.7900 - val_loss: 0.6707 - val_acc: 0.9799 - val_mDice: 0.7915

Epoch 00130: val_mDice improved from 0.79064 to 0.79150, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 131/300
 - 22s - loss: 0.6125 - acc: 0.9702 - mDice: 0.7905 - val_loss: 0.6683 - val_acc: 0.9804 - val_mDice: 0.7901

Epoch 00131: val_mDice did not improve from 0.79150
Epoch 132/300
 - 22s - loss: 0.6131 - acc: 0.9702 - mDice: 0.7906 - val_loss: 0.6676 - val_acc: 0.9799 - val_mDice: 0.7871

Epoch 00132: val_mDice did not improve from 0.79150
Epoch 133/300
 - 21s - loss: 0.6097 - acc: 0.9702 - mDice: 0.7914 - val_loss: 0.6731 - val_acc: 0.9805 - val_mDice: 0.7904

Epoch 00133: val_mDice did not improve from 0.79150
Epoch 134/300
 - 21s - loss: 0.6088 - acc: 0.9702 - mDice: 0.7920 - val_loss: 0.6582 - val_acc: 0.9806 - val_mDice: 0.7923

Epoch 00134: val_mDice improved from 0.79150 to 0.79235, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 135/300
 - 22s - loss: 0.6086 - acc: 0.9702 - mDice: 0.7920 - val_loss: 0.6685 - val_acc: 0.9793 - val_mDice: 0.7910

Epoch 00135: val_mDice did not improve from 0.79235
Epoch 136/300
 - 22s - loss: 0.6082 - acc: 0.9703 - mDice: 0.7922 - val_loss: 0.6663 - val_acc: 0.9799 - val_mDice: 0.7922

Epoch 00136: val_mDice did not improve from 0.79235
Epoch 137/300
 - 22s - loss: 0.6086 - acc: 0.9703 - mDice: 0.7921 - val_loss: 0.6796 - val_acc: 0.9786 - val_mDice: 0.7901

Epoch 00137: val_mDice did not improve from 0.79235
Epoch 138/300
 - 22s - loss: 0.6065 - acc: 0.9703 - mDice: 0.7931 - val_loss: 0.6626 - val_acc: 0.9804 - val_mDice: 0.7898

Epoch 00138: val_mDice did not improve from 0.79235
Epoch 139/300
 - 22s - loss: 0.6071 - acc: 0.9703 - mDice: 0.7926 - val_loss: 0.6683 - val_acc: 0.9799 - val_mDice: 0.7927

Epoch 00139: val_mDice improved from 0.79235 to 0.79267, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 140/300
 - 23s - loss: 0.6062 - acc: 0.9703 - mDice: 0.7928 - val_loss: 0.6585 - val_acc: 0.9808 - val_mDice: 0.7861

Epoch 00140: val_mDice did not improve from 0.79267
Epoch 141/300
 - 23s - loss: 0.6048 - acc: 0.9703 - mDice: 0.7934 - val_loss: 0.6664 - val_acc: 0.9803 - val_mDice: 0.7935

Epoch 00141: val_mDice improved from 0.79267 to 0.79350, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 142/300
 - 22s - loss: 0.6045 - acc: 0.9703 - mDice: 0.7937 - val_loss: 0.6731 - val_acc: 0.9804 - val_mDice: 0.7882

Epoch 00142: val_mDice did not improve from 0.79350
Epoch 143/300
 - 23s - loss: 0.6029 - acc: 0.9703 - mDice: 0.7941 - val_loss: 0.6600 - val_acc: 0.9802 - val_mDice: 0.7933

Epoch 00143: val_mDice did not improve from 0.79350
Epoch 144/300
 - 22s - loss: 0.6021 - acc: 0.9704 - mDice: 0.7943 - val_loss: 0.6600 - val_acc: 0.9802 - val_mDice: 0.7954

Epoch 00144: val_mDice improved from 0.79350 to 0.79545, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 145/300
 - 23s - loss: 0.6017 - acc: 0.9704 - mDice: 0.7944 - val_loss: 0.6604 - val_acc: 0.9804 - val_mDice: 0.7943

Epoch 00145: val_mDice did not improve from 0.79545
Epoch 146/300
 - 23s - loss: 0.5994 - acc: 0.9704 - mDice: 0.7954 - val_loss: 0.6690 - val_acc: 0.9800 - val_mDice: 0.7952

Epoch 00146: val_mDice did not improve from 0.79545
Epoch 147/300
 - 22s - loss: 0.6002 - acc: 0.9704 - mDice: 0.7950 - val_loss: 0.6620 - val_acc: 0.9799 - val_mDice: 0.7924

Epoch 00147: val_mDice did not improve from 0.79545
Epoch 148/300
 - 23s - loss: 0.6000 - acc: 0.9704 - mDice: 0.7952 - val_loss: 0.6668 - val_acc: 0.9797 - val_mDice: 0.7931

Epoch 00148: val_mDice did not improve from 0.79545
Epoch 149/300
 - 22s - loss: 0.5996 - acc: 0.9704 - mDice: 0.7953 - val_loss: 0.6656 - val_acc: 0.9806 - val_mDice: 0.7948

Epoch 00149: val_mDice did not improve from 0.79545
Epoch 150/300
 - 22s - loss: 0.5996 - acc: 0.9704 - mDice: 0.7955 - val_loss: 0.6639 - val_acc: 0.9795 - val_mDice: 0.7951

Epoch 00150: val_mDice did not improve from 0.79545
Epoch 151/300
 - 23s - loss: 0.5974 - acc: 0.9705 - mDice: 0.7961 - val_loss: 0.6640 - val_acc: 0.9800 - val_mDice: 0.7938

Epoch 00151: val_mDice did not improve from 0.79545
Epoch 152/300
 - 22s - loss: 0.5966 - acc: 0.9705 - mDice: 0.7963 - val_loss: 0.6622 - val_acc: 0.9802 - val_mDice: 0.7962

Epoch 00152: val_mDice improved from 0.79545 to 0.79620, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 153/300
 - 23s - loss: 0.5973 - acc: 0.9704 - mDice: 0.7961 - val_loss: 0.6655 - val_acc: 0.9804 - val_mDice: 0.7935

Epoch 00153: val_mDice did not improve from 0.79620
Epoch 154/300
 - 23s - loss: 0.5943 - acc: 0.9705 - mDice: 0.7972 - val_loss: 0.6618 - val_acc: 0.9803 - val_mDice: 0.7961

Epoch 00154: val_mDice did not improve from 0.79620
Epoch 155/300
 - 22s - loss: 0.5939 - acc: 0.9705 - mDice: 0.7973 - val_loss: 0.6650 - val_acc: 0.9801 - val_mDice: 0.7920

Epoch 00155: val_mDice did not improve from 0.79620
Epoch 156/300
 - 22s - loss: 0.5938 - acc: 0.9705 - mDice: 0.7972 - val_loss: 0.6686 - val_acc: 0.9800 - val_mDice: 0.7966

Epoch 00156: val_mDice improved from 0.79620 to 0.79662, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 157/300
 - 23s - loss: 0.5926 - acc: 0.9705 - mDice: 0.7978 - val_loss: 0.6566 - val_acc: 0.9806 - val_mDice: 0.7946

Epoch 00157: val_mDice did not improve from 0.79662
Epoch 158/300
 - 22s - loss: 0.5931 - acc: 0.9705 - mDice: 0.7978 - val_loss: 0.6604 - val_acc: 0.9800 - val_mDice: 0.7960

Epoch 00158: val_mDice did not improve from 0.79662
Epoch 159/300
 - 23s - loss: 0.5915 - acc: 0.9706 - mDice: 0.7980 - val_loss: 0.6577 - val_acc: 0.9802 - val_mDice: 0.7947

Epoch 00159: val_mDice did not improve from 0.79662
Epoch 160/300
 - 24s - loss: 0.5917 - acc: 0.9705 - mDice: 0.7981 - val_loss: 0.6688 - val_acc: 0.9798 - val_mDice: 0.7932

Epoch 00160: val_mDice did not improve from 0.79662
Epoch 161/300
 - 27s - loss: 0.5920 - acc: 0.9705 - mDice: 0.7980 - val_loss: 0.6619 - val_acc: 0.9799 - val_mDice: 0.7964

Epoch 00161: val_mDice did not improve from 0.79662
Epoch 162/300
 - 26s - loss: 0.5906 - acc: 0.9706 - mDice: 0.7982 - val_loss: 0.6525 - val_acc: 0.9808 - val_mDice: 0.7963

Epoch 00162: val_mDice did not improve from 0.79662
Epoch 163/300
 - 28s - loss: 0.5896 - acc: 0.9706 - mDice: 0.7990 - val_loss: 0.6594 - val_acc: 0.9807 - val_mDice: 0.7944

Epoch 00163: val_mDice did not improve from 0.79662
Epoch 164/300
 - 27s - loss: 0.5899 - acc: 0.9706 - mDice: 0.7988 - val_loss: 0.6565 - val_acc: 0.9803 - val_mDice: 0.7948

Epoch 00164: val_mDice did not improve from 0.79662
Epoch 165/300
 - 27s - loss: 0.5889 - acc: 0.9706 - mDice: 0.7991 - val_loss: 0.6660 - val_acc: 0.9805 - val_mDice: 0.7945

Epoch 00165: val_mDice did not improve from 0.79662
Epoch 166/300
 - 27s - loss: 0.5872 - acc: 0.9706 - mDice: 0.7997 - val_loss: 0.6575 - val_acc: 0.9805 - val_mDice: 0.7949

Epoch 00166: val_mDice did not improve from 0.79662
Epoch 167/300
 - 27s - loss: 0.5867 - acc: 0.9706 - mDice: 0.7997 - val_loss: 0.6537 - val_acc: 0.9804 - val_mDice: 0.7958

Epoch 00167: val_mDice did not improve from 0.79662
Epoch 168/300
 - 28s - loss: 0.5862 - acc: 0.9707 - mDice: 0.8001 - val_loss: 0.6572 - val_acc: 0.9803 - val_mDice: 0.7985

Epoch 00168: val_mDice improved from 0.79662 to 0.79849, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 169/300
 - 27s - loss: 0.5865 - acc: 0.9706 - mDice: 0.8000 - val_loss: 0.6618 - val_acc: 0.9807 - val_mDice: 0.7972

Epoch 00169: val_mDice did not improve from 0.79849
Epoch 170/300
 - 29s - loss: 0.5839 - acc: 0.9707 - mDice: 0.8009 - val_loss: 0.6679 - val_acc: 0.9793 - val_mDice: 0.7949

Epoch 00170: val_mDice did not improve from 0.79849
Epoch 171/300
 - 26s - loss: 0.5856 - acc: 0.9706 - mDice: 0.8002 - val_loss: 0.6643 - val_acc: 0.9805 - val_mDice: 0.7957

Epoch 00171: val_mDice did not improve from 0.79849
Epoch 172/300
 - 28s - loss: 0.5836 - acc: 0.9707 - mDice: 0.8010 - val_loss: 0.6558 - val_acc: 0.9805 - val_mDice: 0.7959

Epoch 00172: val_mDice did not improve from 0.79849
Epoch 173/300
 - 24s - loss: 0.5853 - acc: 0.9706 - mDice: 0.8006 - val_loss: 0.6463 - val_acc: 0.9808 - val_mDice: 0.7976

Epoch 00173: val_mDice did not improve from 0.79849
Epoch 174/300
 - 22s - loss: 0.5840 - acc: 0.9707 - mDice: 0.8007 - val_loss: 0.6538 - val_acc: 0.9807 - val_mDice: 0.7955

Epoch 00174: val_mDice did not improve from 0.79849
Epoch 175/300
 - 23s - loss: 0.5828 - acc: 0.9707 - mDice: 0.8010 - val_loss: 0.6561 - val_acc: 0.9803 - val_mDice: 0.7958

Epoch 00175: val_mDice did not improve from 0.79849
Epoch 176/300
 - 21s - loss: 0.5818 - acc: 0.9707 - mDice: 0.8016 - val_loss: 0.6546 - val_acc: 0.9811 - val_mDice: 0.7969

Epoch 00176: val_mDice did not improve from 0.79849
Epoch 177/300
 - 22s - loss: 0.5822 - acc: 0.9707 - mDice: 0.8014 - val_loss: 0.6607 - val_acc: 0.9801 - val_mDice: 0.7957

Epoch 00177: val_mDice did not improve from 0.79849
Epoch 178/300
 - 22s - loss: 0.5810 - acc: 0.9707 - mDice: 0.8017 - val_loss: 0.6529 - val_acc: 0.9806 - val_mDice: 0.7979

Epoch 00178: val_mDice did not improve from 0.79849
Epoch 179/300
 - 21s - loss: 0.5816 - acc: 0.9707 - mDice: 0.8018 - val_loss: 0.6655 - val_acc: 0.9805 - val_mDice: 0.7966

Epoch 00179: val_mDice did not improve from 0.79849
Epoch 180/300
 - 21s - loss: 0.5814 - acc: 0.9707 - mDice: 0.8019 - val_loss: 0.6572 - val_acc: 0.9810 - val_mDice: 0.7980

Epoch 00180: val_mDice did not improve from 0.79849
Epoch 181/300
 - 21s - loss: 0.5788 - acc: 0.9707 - mDice: 0.8025 - val_loss: 0.6651 - val_acc: 0.9798 - val_mDice: 0.7973

Epoch 00181: val_mDice did not improve from 0.79849
Epoch 182/300
 - 22s - loss: 0.5801 - acc: 0.9708 - mDice: 0.8024 - val_loss: 0.6627 - val_acc: 0.9807 - val_mDice: 0.7989

Epoch 00182: val_mDice improved from 0.79849 to 0.79888, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 183/300
 - 21s - loss: 0.5800 - acc: 0.9707 - mDice: 0.8022 - val_loss: 0.6578 - val_acc: 0.9804 - val_mDice: 0.7987

Epoch 00183: val_mDice did not improve from 0.79888
Epoch 184/300
 - 21s - loss: 0.5789 - acc: 0.9708 - mDice: 0.8026 - val_loss: 0.6767 - val_acc: 0.9805 - val_mDice: 0.7987

Epoch 00184: val_mDice did not improve from 0.79888
Epoch 185/300
 - 21s - loss: 0.5800 - acc: 0.9707 - mDice: 0.8024 - val_loss: 0.6535 - val_acc: 0.9803 - val_mDice: 0.7990

Epoch 00185: val_mDice improved from 0.79888 to 0.79900, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 186/300
 - 22s - loss: 0.5774 - acc: 0.9707 - mDice: 0.8030 - val_loss: 0.6533 - val_acc: 0.9805 - val_mDice: 0.7979

Epoch 00186: val_mDice did not improve from 0.79900
Epoch 187/300
 - 22s - loss: 0.5771 - acc: 0.9708 - mDice: 0.8032 - val_loss: 0.6623 - val_acc: 0.9804 - val_mDice: 0.7994

Epoch 00187: val_mDice improved from 0.79900 to 0.79939, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 188/300
 - 21s - loss: 0.5764 - acc: 0.9708 - mDice: 0.8035 - val_loss: 0.6591 - val_acc: 0.9802 - val_mDice: 0.7978

Epoch 00188: val_mDice did not improve from 0.79939
Epoch 189/300
 - 21s - loss: 0.5776 - acc: 0.9708 - mDice: 0.8029 - val_loss: 0.6460 - val_acc: 0.9811 - val_mDice: 0.7979

Epoch 00189: val_mDice did not improve from 0.79939
Epoch 190/300
 - 22s - loss: 0.5760 - acc: 0.9708 - mDice: 0.8035 - val_loss: 0.6565 - val_acc: 0.9804 - val_mDice: 0.7971

Epoch 00190: val_mDice did not improve from 0.79939
Epoch 191/300
 - 21s - loss: 0.5754 - acc: 0.9708 - mDice: 0.8036 - val_loss: 0.6618 - val_acc: 0.9798 - val_mDice: 0.7985

Epoch 00191: val_mDice did not improve from 0.79939
Epoch 192/300
 - 21s - loss: 0.5760 - acc: 0.9708 - mDice: 0.8038 - val_loss: 0.6546 - val_acc: 0.9806 - val_mDice: 0.7998

Epoch 00192: val_mDice improved from 0.79939 to 0.79981, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 193/300
 - 22s - loss: 0.5754 - acc: 0.9708 - mDice: 0.8040 - val_loss: 0.6587 - val_acc: 0.9798 - val_mDice: 0.7980

Epoch 00193: val_mDice did not improve from 0.79981
Epoch 194/300
 - 21s - loss: 0.5749 - acc: 0.9708 - mDice: 0.8042 - val_loss: 0.6651 - val_acc: 0.9800 - val_mDice: 0.7970

Epoch 00194: val_mDice did not improve from 0.79981
Epoch 195/300
 - 21s - loss: 0.5746 - acc: 0.9708 - mDice: 0.8040 - val_loss: 0.6557 - val_acc: 0.9807 - val_mDice: 0.7981

Epoch 00195: val_mDice did not improve from 0.79981
Epoch 196/300
 - 22s - loss: 0.5740 - acc: 0.9708 - mDice: 0.8045 - val_loss: 0.6539 - val_acc: 0.9798 - val_mDice: 0.7991

Epoch 00196: val_mDice did not improve from 0.79981
Epoch 197/300
 - 22s - loss: 0.5724 - acc: 0.9709 - mDice: 0.8046 - val_loss: 0.6526 - val_acc: 0.9797 - val_mDice: 0.8013

Epoch 00197: val_mDice improved from 0.79981 to 0.80133, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 198/300
 - 21s - loss: 0.5728 - acc: 0.9709 - mDice: 0.8048 - val_loss: 0.6503 - val_acc: 0.9806 - val_mDice: 0.8002

Epoch 00198: val_mDice did not improve from 0.80133
Epoch 199/300
 - 21s - loss: 0.5712 - acc: 0.9709 - mDice: 0.8050 - val_loss: 0.6543 - val_acc: 0.9804 - val_mDice: 0.7997

Epoch 00199: val_mDice did not improve from 0.80133
Epoch 200/300
 - 22s - loss: 0.5728 - acc: 0.9708 - mDice: 0.8048 - val_loss: 0.6524 - val_acc: 0.9805 - val_mDice: 0.7988

Epoch 00200: val_mDice did not improve from 0.80133
Epoch 201/300
 - 22s - loss: 0.5725 - acc: 0.9709 - mDice: 0.8048 - val_loss: 0.6491 - val_acc: 0.9802 - val_mDice: 0.7994

Epoch 00201: val_mDice did not improve from 0.80133
Epoch 202/300
 - 21s - loss: 0.5710 - acc: 0.9709 - mDice: 0.8053 - val_loss: 0.6489 - val_acc: 0.9807 - val_mDice: 0.7982

Epoch 00202: val_mDice did not improve from 0.80133
Epoch 203/300
 - 23s - loss: 0.5724 - acc: 0.9708 - mDice: 0.8047 - val_loss: 0.6567 - val_acc: 0.9808 - val_mDice: 0.7997

Epoch 00203: val_mDice did not improve from 0.80133
Epoch 204/300
 - 21s - loss: 0.5700 - acc: 0.9710 - mDice: 0.8058 - val_loss: 0.6474 - val_acc: 0.9803 - val_mDice: 0.7981

Epoch 00204: val_mDice did not improve from 0.80133
Epoch 205/300
 - 23s - loss: 0.5715 - acc: 0.9709 - mDice: 0.8051 - val_loss: 0.6611 - val_acc: 0.9803 - val_mDice: 0.8006

Epoch 00205: val_mDice did not improve from 0.80133
Epoch 206/300
 - 21s - loss: 0.5702 - acc: 0.9709 - mDice: 0.8056 - val_loss: 0.6536 - val_acc: 0.9794 - val_mDice: 0.7982

Epoch 00206: val_mDice did not improve from 0.80133
Epoch 207/300
 - 23s - loss: 0.5698 - acc: 0.9709 - mDice: 0.8057 - val_loss: 0.6524 - val_acc: 0.9810 - val_mDice: 0.7972

Epoch 00207: val_mDice did not improve from 0.80133
Epoch 208/300
 - 21s - loss: 0.5691 - acc: 0.9709 - mDice: 0.8060 - val_loss: 0.6587 - val_acc: 0.9804 - val_mDice: 0.8009

Epoch 00208: val_mDice did not improve from 0.80133
Epoch 209/300
 - 23s - loss: 0.5682 - acc: 0.9709 - mDice: 0.8064 - val_loss: 0.6602 - val_acc: 0.9803 - val_mDice: 0.8033

Epoch 00209: val_mDice improved from 0.80133 to 0.80326, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 210/300
 - 22s - loss: 0.5675 - acc: 0.9710 - mDice: 0.8065 - val_loss: 0.6523 - val_acc: 0.9806 - val_mDice: 0.7996

Epoch 00210: val_mDice did not improve from 0.80326
Epoch 211/300
 - 22s - loss: 0.5686 - acc: 0.9710 - mDice: 0.8061 - val_loss: 0.6558 - val_acc: 0.9804 - val_mDice: 0.8017

Epoch 00211: val_mDice did not improve from 0.80326
Epoch 212/300
 - 22s - loss: 0.5691 - acc: 0.9709 - mDice: 0.8061 - val_loss: 0.6465 - val_acc: 0.9807 - val_mDice: 0.7975

Epoch 00212: val_mDice did not improve from 0.80326
Epoch 213/300
 - 22s - loss: 0.5671 - acc: 0.9710 - mDice: 0.8068 - val_loss: 0.6544 - val_acc: 0.9808 - val_mDice: 0.7986

Epoch 00213: val_mDice did not improve from 0.80326
Epoch 214/300
 - 23s - loss: 0.5686 - acc: 0.9710 - mDice: 0.8063 - val_loss: 0.6530 - val_acc: 0.9802 - val_mDice: 0.8004

Epoch 00214: val_mDice did not improve from 0.80326
Epoch 215/300
 - 22s - loss: 0.5665 - acc: 0.9710 - mDice: 0.8069 - val_loss: 0.6484 - val_acc: 0.9806 - val_mDice: 0.7996

Epoch 00215: val_mDice did not improve from 0.80326
Epoch 216/300
 - 23s - loss: 0.5670 - acc: 0.9710 - mDice: 0.8066 - val_loss: 0.6518 - val_acc: 0.9805 - val_mDice: 0.8018

Epoch 00216: val_mDice did not improve from 0.80326
Epoch 217/300
 - 22s - loss: 0.5663 - acc: 0.9710 - mDice: 0.8070 - val_loss: 0.6579 - val_acc: 0.9808 - val_mDice: 0.7970

Epoch 00217: val_mDice did not improve from 0.80326
Epoch 218/300
 - 22s - loss: 0.5658 - acc: 0.9710 - mDice: 0.8071 - val_loss: 0.6488 - val_acc: 0.9805 - val_mDice: 0.8014

Epoch 00218: val_mDice did not improve from 0.80326
Epoch 219/300
 - 23s - loss: 0.5665 - acc: 0.9710 - mDice: 0.8070 - val_loss: 0.6508 - val_acc: 0.9802 - val_mDice: 0.8021

Epoch 00219: val_mDice did not improve from 0.80326
Epoch 220/300
 - 22s - loss: 0.5648 - acc: 0.9710 - mDice: 0.8075 - val_loss: 0.6563 - val_acc: 0.9805 - val_mDice: 0.8000

Epoch 00220: val_mDice did not improve from 0.80326
Epoch 221/300
 - 22s - loss: 0.5636 - acc: 0.9710 - mDice: 0.8077 - val_loss: 0.6434 - val_acc: 0.9810 - val_mDice: 0.8001

Epoch 00221: val_mDice did not improve from 0.80326
Epoch 222/300
 - 23s - loss: 0.5656 - acc: 0.9710 - mDice: 0.8074 - val_loss: 0.6496 - val_acc: 0.9806 - val_mDice: 0.8011

Epoch 00222: val_mDice did not improve from 0.80326
Epoch 223/300
 - 22s - loss: 0.5651 - acc: 0.9710 - mDice: 0.8072 - val_loss: 0.6528 - val_acc: 0.9802 - val_mDice: 0.7987

Epoch 00223: val_mDice did not improve from 0.80326
Epoch 224/300
 - 24s - loss: 0.5653 - acc: 0.9711 - mDice: 0.8074 - val_loss: 0.6560 - val_acc: 0.9806 - val_mDice: 0.8018

Epoch 00224: val_mDice did not improve from 0.80326
Epoch 225/300
 - 24s - loss: 0.5651 - acc: 0.9710 - mDice: 0.8074 - val_loss: 0.6501 - val_acc: 0.9813 - val_mDice: 0.7996

Epoch 00225: val_mDice did not improve from 0.80326
Epoch 226/300
 - 23s - loss: 0.5646 - acc: 0.9710 - mDice: 0.8076 - val_loss: 0.6490 - val_acc: 0.9810 - val_mDice: 0.7990

Epoch 00226: val_mDice did not improve from 0.80326
Epoch 227/300
 - 24s - loss: 0.5623 - acc: 0.9711 - mDice: 0.8083 - val_loss: 0.6480 - val_acc: 0.9807 - val_mDice: 0.8008

Epoch 00227: val_mDice did not improve from 0.80326
Epoch 228/300
 - 25s - loss: 0.5642 - acc: 0.9710 - mDice: 0.8079 - val_loss: 0.6544 - val_acc: 0.9808 - val_mDice: 0.8001

Epoch 00228: val_mDice did not improve from 0.80326
Epoch 229/300
 - 24s - loss: 0.5631 - acc: 0.9710 - mDice: 0.8081 - val_loss: 0.6560 - val_acc: 0.9806 - val_mDice: 0.8009

Epoch 00229: val_mDice did not improve from 0.80326
Epoch 230/300
 - 24s - loss: 0.5632 - acc: 0.9710 - mDice: 0.8081 - val_loss: 0.6531 - val_acc: 0.9808 - val_mDice: 0.7986

Epoch 00230: val_mDice did not improve from 0.80326
Epoch 231/300
 - 24s - loss: 0.5623 - acc: 0.9711 - mDice: 0.8083 - val_loss: 0.6587 - val_acc: 0.9806 - val_mDice: 0.8008

Epoch 00231: val_mDice did not improve from 0.80326
Epoch 232/300
 - 24s - loss: 0.5637 - acc: 0.9711 - mDice: 0.8079 - val_loss: 0.6483 - val_acc: 0.9803 - val_mDice: 0.8003

Epoch 00232: val_mDice did not improve from 0.80326
Epoch 233/300
 - 25s - loss: 0.5617 - acc: 0.9711 - mDice: 0.8087 - val_loss: 0.6521 - val_acc: 0.9799 - val_mDice: 0.7990

Epoch 00233: val_mDice did not improve from 0.80326
Epoch 234/300
 - 24s - loss: 0.5620 - acc: 0.9711 - mDice: 0.8084 - val_loss: 0.6550 - val_acc: 0.9806 - val_mDice: 0.8010

Epoch 00234: val_mDice did not improve from 0.80326
Epoch 235/300
 - 24s - loss: 0.5622 - acc: 0.9711 - mDice: 0.8084 - val_loss: 0.6519 - val_acc: 0.9808 - val_mDice: 0.8000

Epoch 00235: val_mDice did not improve from 0.80326
Epoch 236/300
 - 23s - loss: 0.5624 - acc: 0.9711 - mDice: 0.8084 - val_loss: 0.6568 - val_acc: 0.9809 - val_mDice: 0.8002

Epoch 00236: val_mDice did not improve from 0.80326
Epoch 237/300
 - 23s - loss: 0.5618 - acc: 0.9711 - mDice: 0.8086 - val_loss: 0.6504 - val_acc: 0.9809 - val_mDice: 0.8016

Epoch 00237: val_mDice did not improve from 0.80326
Epoch 238/300
 - 23s - loss: 0.5601 - acc: 0.9711 - mDice: 0.8091 - val_loss: 0.6669 - val_acc: 0.9799 - val_mDice: 0.7975

Epoch 00238: val_mDice did not improve from 0.80326
Epoch 239/300
 - 23s - loss: 0.5612 - acc: 0.9711 - mDice: 0.8085 - val_loss: 0.6529 - val_acc: 0.9804 - val_mDice: 0.8008

Epoch 00239: val_mDice did not improve from 0.80326
Restoring model weights from the end of the best epoch
Epoch 00239: early stopping
{'val_loss': [3.9895817988539397, 3.142933909207174, 2.2345734671370625, 1.5961056841562873, 1.2472861139741662, 1.085128072598209, 0.9571484686577156, 0.9226888152834487, 0.8545852850561273, 0.8456304767360426, 0.8178569400963718, 0.8248944637710101, 0.79846512944731, 0.7914741990500933, 0.7733008224670201, 0.7863093655403346, 0.7715587187303256, 0.7560858395818162, 0.750618088327042, 0.7411982923337858, 0.7394425632202462, 0.7415122083605152, 0.7341933597440589, 0.7425101174883646, 0.7353887010927069, 0.7293845080349544, 0.7405755099368422, 0.7215764559295079, 0.7302832697352318, 0.7135975022022039, 0.7185664711749717, 0.7121315949583706, 0.7241170508404301, 0.7174151237696818, 0.6896536795243825, 0.6962401544394559, 0.7016090554733799, 0.710771575365981, 0.6973834923685414, 0.7098339195937327, 0.6999598194475043, 0.7033342812975792, 0.6984960489893612, 0.6962321470045063, 0.6933549605820277, 0.6981942029031989, 0.6950230806657712, 0.6898484164721346, 0.6999884321265024, 0.6874742781462735, 0.688008234925466, 0.7127531799551559, 0.681080116801066, 0.6867300192378971, 0.6915779930271514, 0.6834259686404711, 0.6950370779592697, 0.6808874880614346, 0.7081307960699682, 0.686174260018623, 0.6915809516220877, 0.69779459907584, 0.6907022999574061, 0.6752188460875864, 0.6960682721987163, 0.69571482563672, 0.6836672482425219, 0.682352991953288, 0.6792418136172098, 0.6868794578803729, 0.6936927086686435, 0.678393396204465, 0.6784881706515403, 0.6905423782459678, 0.6841593846066357, 0.6779874842869092, 0.6819938574343511, 0.6789972961765446, 0.6751866614165372, 0.674947300594147, 0.6848969867784683, 0.6774020346060191, 0.6845512520777036, 0.683431107908079, 0.6795056298987506, 0.677668739467451, 0.6808763807767058, 0.693622547469727, 0.6751940270809278, 0.6750749406749255, 0.6857972935046235, 0.6865054805801339, 0.6770819682781011, 0.6824966844630568, 0.6943857751480521, 0.6803927560375161, 0.6863045110686185, 0.6819528463768633, 0.6809485922121021, 0.6933797512152423, 0.6816065358380748, 0.6790191329097095, 0.6709771450251749, 0.6700383138983217, 0.6796596397275794, 0.6743941582637291, 0.6734796405246813, 0.6758099520859653, 0.6858195286907561, 0.6699543187063034, 0.675663922951646, 0.6714796446365853, 0.6803044250158414, 0.6813140568667895, 0.6749192059856571, 0.6817872985585095, 0.6777029929504003, 0.6751677053023691, 0.6783074299766593, 0.6809120917156951, 0.6725553184339444, 0.6670406242347744, 0.6674561933295368, 0.6750167822592879, 0.672378681498031, 0.6672430267072704, 0.6722031848071373, 0.6657690411969407, 0.6705227528941141, 0.670679167525409, 0.6683006903080091, 0.6676432049437745, 0.6731167878598383, 0.6582280303517433, 0.6685376093812185, 0.6663374835497713, 0.6795623982197618, 0.6626346578744993, 0.6683148033406636, 0.6585357115693289, 0.666351487579411, 0.6731255783201897, 0.6599768949289845, 0.6599901606367059, 0.6603741719298166, 0.6689973195938215, 0.6620406437001817, 0.666755226989315, 0.6655934018223253, 0.6638763871503203, 0.6639847277778469, 0.6621714532375336, 0.6655221712099363, 0.6618297508318131, 0.6650149281302543, 0.6685771419577402, 0.6566126493558492, 0.6603757441043854, 0.6576508583679591, 0.6688444304139647, 0.6618713591605017, 0.6525222287602621, 0.6593620597499691, 0.6565381998885168, 0.6660037640839407, 0.6575159303946038, 0.6536505157000398, 0.6572406428725752, 0.6618239171292684, 0.6678795904329379, 0.6642812023015872, 0.6558227183884138, 0.6463140128818277, 0.6538165913869257, 0.6560997705753535, 0.6546070191958179, 0.6606812028035726, 0.6528790344114173, 0.6654894474434526, 0.6572020257989021, 0.6651172097006889, 0.6626577309957923, 0.6578480744198577, 0.6767191143885051, 0.6534669566644381, 0.6533483497492255, 0.6622945213154571, 0.6590656119666688, 0.6459966677508943, 0.6564892871330862, 0.6617888130553781, 0.6546276366873963, 0.6586992626320826, 0.6650514949674475, 0.6557074442301711, 0.6539210211740781, 0.6526437281337503, 0.6502870076323208, 0.6543411351230046, 0.6524483569680828, 0.6491248648460597, 0.6488559629819165, 0.6566593932778868, 0.6473956365291387, 0.6610715050403386, 0.6536224574258883, 0.6524449074513292, 0.6586826012967384, 0.6601986978968529, 0.6523045031991723, 0.6557526239385344, 0.6465481403347564, 0.6544400492351349, 0.6530399896102409, 0.6484054910810026, 0.6517764946369276, 0.6579095676337203, 0.6488284235947752, 0.650831353990999, 0.6563286089325604, 0.6433881243614301, 0.6496388032420041, 0.6527753854042864, 0.6560108212575521, 0.650111339271885, 0.6490147424070802, 0.6480398316905923, 0.6543693683327061, 0.6559683123271759, 0.6530972862080352, 0.6586996841512315, 0.6483350716633339, 0.65214708916945, 0.6550127075959559, 0.6519076081171428, 0.6568429055687499, 0.6503740573582584, 0.6668882590450652, 0.6528941919542339], 'val_acc': [0.9134473159705123, 0.9120629682932815, 0.9312607645988464, 0.9551525683435675, 0.9651779132346584, 0.9701707371293682, 0.9710331179507791, 0.9723191620552376, 0.9745596867718108, 0.974720594409394, 0.9752895485048425, 0.9745676970645173, 0.9740336892539507, 0.9745953621929639, 0.9761595362669802, 0.9755603589423715, 0.9762858376927572, 0.9774470566070244, 0.9771405523770476, 0.9765781437697476, 0.9765111722358285, 0.9766600523909478, 0.9761158489201167, 0.9769763901625594, 0.9769625627014735, 0.9788849243562515, 0.9781758172871315, 0.9786206471593413, 0.9761868400932991, 0.9777604794665559, 0.9778489323511516, 0.9782773827853268, 0.9766738859757985, 0.9774674569090752, 0.9790945861437549, 0.9788805593366492, 0.9793079050436412, 0.9789584528093469, 0.9784670219029465, 0.9781448759444772, 0.9786424796058707, 0.9779777857538772, 0.9791004147431622, 0.9791386274442281, 0.979425847938616, 0.9791251653677797, 0.9793705176817228, 0.9792438414815354, 0.978861975751511, 0.9792766089308752, 0.9794458587692209, 0.9775540767467186, 0.9798000659028144, 0.9792940653350255, 0.9788627093785429, 0.9791717533379385, 0.979780764204182, 0.9791692127920177, 0.9788874657186744, 0.9787535038712907, 0.9784855993643199, 0.9792598539019284, 0.9795470703138064, 0.9795805517941305, 0.9788175739654122, 0.9797934959196064, 0.9796471473288862, 0.979577999817182, 0.9791921520069854, 0.9792584001201473, 0.9784812310787097, 0.9799532861742255, 0.9799674892262237, 0.9786410294983485, 0.9786264643277207, 0.9796420784845744, 0.9797137873630001, 0.9792816953299797, 0.9794942744790691, 0.9797159547675146, 0.9798251570087589, 0.9797188680465907, 0.9795208528433761, 0.9792551230894376, 0.9793512229233572, 0.9798269961794762, 0.9793213797758703, 0.9793548637057004, 0.9790909502604236, 0.979685026080641, 0.9803788372098583, 0.979305721717338, 0.9795761835085203, 0.9802951265687811, 0.9785656720808108, 0.9794757206962533, 0.9795801868177441, 0.9801225592828777, 0.9793384850841679, 0.9796162378298093, 0.9787982828813057, 0.9796824643056686, 0.9797603647186331, 0.9798193365743716, 0.9790283466038638, 0.9792813242298283, 0.9795372273823987, 0.97946916500183, 0.9798906951734464, 0.9797803971865405, 0.9797887806206533, 0.9798317208682021, 0.9802375986968002, 0.9797075913377005, 0.9798058724566682, 0.9793934446491607, 0.9798899550143987, 0.9801065644172773, 0.9800588647796683, 0.9801265662663603, 0.9795492487410976, 0.9800410336011076, 0.9797902250126617, 0.9794123801466537, 0.9799394774926852, 0.980089449310956, 0.9797061375559193, 0.9799132673707727, 0.9801473348108056, 0.9798757687006912, 0.9804039515861093, 0.979853920332373, 0.9804774914702324, 0.9805557429790497, 0.9792948079435793, 0.9798746745880336, 0.9785849656144233, 0.9804210577109088, 0.9799256381923205, 0.9807756138991003, 0.9802761792320095, 0.9804225392537574, 0.98022485228434, 0.9801542452753407, 0.9803780999085675, 0.9799500258818065, 0.9799365523743303, 0.9797298026411501, 0.9806205332279205, 0.9795044546257959, 0.9799638570171513, 0.9801997509721208, 0.9803580984677354, 0.9802750904266149, 0.9800737957431845, 0.9800064612741339, 0.980580499319181, 0.9800250097496869, 0.9802412366213864, 0.9798470033358221, 0.9798670280469607, 0.9808378587030384, 0.9807246437627976, 0.9802881981412025, 0.98054010655782, 0.9805102364657676, 0.9804480035011083, 0.980257612793413, 0.9807177300322546, 0.9792736862620263, 0.9805127921169752, 0.9804516446917024, 0.9807919888463739, 0.9806933443840236, 0.9803205846923672, 0.9810719273678244, 0.9800606851708399, 0.9805859678412137, 0.9804683935968843, 0.9809590663811932, 0.9798062394743097, 0.980677698573021, 0.9803642761217405, 0.9804643874299036, 0.9803049364318587, 0.9804895058886646, 0.9803540837274839, 0.9802019351149258, 0.981082117312575, 0.9803693727271198, 0.9797749490770575, 0.9806431229800394, 0.9798328133478557, 0.9799613099392146, 0.9806937032366452, 0.9798178987143791, 0.9797436358177498, 0.9805928746314898, 0.980358457320357, 0.980523362143399, 0.9802292262854642, 0.9807024610369173, 0.980778888888555, 0.9803038308881733, 0.9803118415891308, 0.9794291196620628, 0.9810012991297735, 0.9804403520610234, 0.9803300618308864, 0.9805757713644472, 0.9803988647787538, 0.9807304784859696, 0.9808454962625895, 0.9801819071377793, 0.9805815868998227, 0.9804527261485793, 0.9807752542299767, 0.9805444634124024, 0.9802434362777291, 0.9804869616684848, 0.9810005683604985, 0.9806434732593902, 0.9801877369619396, 0.9805677696450116, 0.9812517566223667, 0.9809710726346055, 0.9806638564148994, 0.9808069206263921, 0.9805983337637496, 0.9807992806173351, 0.9805703142734423, 0.9803209623245344, 0.9798713971490729, 0.9806154456040631, 0.9807603175509466, 0.9809132202030861, 0.980882271103663, 0.9798823178630985, 0.9803879281429395], 'val_mDice': [0.044447820174367464, 0.11825900096191119, 0.25506135372266375, 0.4337830851747565, 0.5522476557182939, 0.6234937579664466, 0.6650215056661057, 0.681484628213595, 0.703547281761692, 0.7072973132949986, 0.717272255518665, 0.7221862751327149, 0.7301614415155698, 0.7311492892977309, 0.737207777696113, 0.7367008716276248, 0.7393150296929765, 0.7438543079650566, 0.7472839645326954, 0.7490848707009669, 0.7465461582353671, 0.7511539802159348, 0.7550352930206142, 0.7522029713408588, 0.7543651486096317, 0.7502572883481848, 0.7520552265317473, 0.7566814900261082, 0.7568274548608963, 0.7589887258124678, 0.7579162006508814, 0.7599842523875302, 0.7578916504775008, 0.760242807946793, 0.7629485301775475, 0.7647880711784102, 0.7627516372563088, 0.7618088248657854, 0.7656782375623102, 0.7655048149905793, 0.7622353610110609, 0.7655294206860948, 0.7689561647911595, 0.7660416205451913, 0.7671361194081503, 0.7721542687448737, 0.7668034838487024, 0.7677660551789689, 0.7674543837161913, 0.7715793884780309, 0.7703559186360608, 0.7672367789973952, 0.7709871559110406, 0.7707612661466207, 0.7698987857119678, 0.7758098281409642, 0.771096749664986, 0.7735752095914867, 0.7700668687689795, 0.7764419166192617, 0.7742987993645342, 0.7715120005281004, 0.7719059811063009, 0.7752201912337786, 0.7758877885668245, 0.7723970249907611, 0.7757209988489543, 0.7778156371149298, 0.7729014137836352, 0.7748466272876687, 0.7788914078718996, 0.7755511823582323, 0.7789603863676934, 0.7792102486303408, 0.7769565472047623, 0.7791285988402693, 0.7764309252778144, 0.7810040426580873, 0.7773997016149025, 0.7776315416375251, 0.7745495369173077, 0.7793843056241126, 0.780583817664891, 0.7792866650509508, 0.7800693087381859, 0.7799423949359214, 0.7758992694012107, 0.7761602867139529, 0.7829154623697882, 0.781009603853095, 0.7782459316188342, 0.781399915071383, 0.7812761635812995, 0.7807813964477958, 0.7852131724357605, 0.7796468012136956, 0.7823789744344476, 0.7854459310231143, 0.7807481260332343, 0.7798328211862747, 0.7839259313393946, 0.7845653671107881, 0.7831626628359704, 0.7824259004364275, 0.7834769822146794, 0.785780036286132, 0.7865375978489445, 0.783881959849841, 0.7871466479072832, 0.7875467632731347, 0.7855271607229154, 0.7872658486235632, 0.7839280913953912, 0.7861944008363436, 0.7881879365607484, 0.7893417522515336, 0.7872274379207663, 0.7878023447239235, 0.7843206745304473, 0.7861288128650352, 0.786235900366143, 0.7894767241118705, 0.7888263659934475, 0.7876630078439844, 0.7882801453544669, 0.7906350746546706, 0.7878667320290657, 0.7901851616493644, 0.7878064492793933, 0.791498354036514, 0.7901376387844347, 0.7870598786497769, 0.7904227045300889, 0.7923495259186993, 0.7910165664267866, 0.7921918116203727, 0.7901206004292998, 0.789759541211063, 0.792673306105888, 0.7861286924309927, 0.7934975109688224, 0.7882439196109772, 0.7932831404143816, 0.795446421185585, 0.7942831814289093, 0.7951681291403836, 0.7924269070364025, 0.7930574511011986, 0.7947998859294473, 0.7950705624606511, 0.7937688325365929, 0.7961978536762603, 0.7935253626679721, 0.7960684283138955, 0.7919580732306389, 0.7966205836975411, 0.7945723962293912, 0.7959785073587339, 0.7946769746199046, 0.7931587083698952, 0.7964249355335759, 0.7963134409630135, 0.7944478662046668, 0.7948413581064303, 0.794473895063139, 0.7949361082625716, 0.7957884734624052, 0.7984878690275428, 0.7971747419605516, 0.7949331068012813, 0.7957310358138934, 0.7959221185070194, 0.7976048572422707, 0.7954871327909705, 0.7958111101633882, 0.7968954599066956, 0.7957097447081788, 0.7979248206909388, 0.7965583556318936, 0.7979818533544671, 0.7973394108145204, 0.798881664259793, 0.7987104515506797, 0.7987119645288546, 0.7989984701757562, 0.7978587983405754, 0.7993893288586238, 0.7977901782891522, 0.7978645007904261, 0.7971238473506823, 0.7984960075110605, 0.7998124634566373, 0.7980466040029918, 0.7970192044565122, 0.798116239782882, 0.7990658324058741, 0.8013275032990599, 0.8001918564104054, 0.7997056339701561, 0.7988072156089626, 0.7993614922647607, 0.7982386869110473, 0.7997119189941719, 0.7981281476478054, 0.8005977370967604, 0.798156839119245, 0.797217215168966, 0.8008993484386026, 0.8032581700037603, 0.7995578401709256, 0.8017298844579148, 0.7975060331494841, 0.7985566507463586, 0.8004434447582454, 0.7996044077285348, 0.8017622608028047, 0.7969690230611253, 0.8014336591714049, 0.8020590029350699, 0.7999514753687872, 0.8001341129819007, 0.8011450465411356, 0.7987433712776393, 0.8017641530461508, 0.7995927742082779, 0.7989909681555343, 0.8008287324480814, 0.8001095550517513, 0.8008590422264518, 0.7985597738664444, 0.8008265299339817, 0.8002637134839411, 0.7989903402655092, 0.8010286100923198, 0.8000189216986094, 0.8001885842787076, 0.8016278531453381, 0.7974530740143502, 0.800799796842549], 'loss': [34.927037322668866, 4.445854197962266, 3.3492570150570153, 2.546844126643994, 2.062067225433969, 1.7655034514069643, 1.5764841006154802, 1.4456338890547167, 1.3486045423263675, 1.272884403365429, 1.2148372947356747, 1.1650590733123851, 1.1193963648485927, 1.0878899318794784, 1.0501766797548155, 1.0213271597533795, 1.0027520136032526, 0.9798452155628207, 0.961689722962285, 0.9456311523026688, 0.9249496510074342, 0.9101508257317137, 0.8980689500103721, 0.8861408945873414, 0.8768084889058866, 0.8653127788632707, 0.8520659975827105, 0.8454776195823339, 0.8308694268948854, 0.8255224687285329, 0.8182827825517308, 0.8085275011293238, 0.8019903955591622, 0.8013233063212245, 0.785371550171167, 0.7821176907655285, 0.7774624480997903, 0.7748608415621127, 0.7699408053668115, 0.7626235101362487, 0.7610800007612333, 0.7536174540140754, 0.7475632225710476, 0.7458030408224696, 0.7400284574714832, 0.7370709657577142, 0.734011191927707, 0.7298092220388462, 0.7257746048011322, 0.7225737012569069, 0.7205183007477668, 0.7186117273717623, 0.7156138907953011, 0.7130506556260109, 0.7071570652474254, 0.7065571598506467, 0.7047458004406247, 0.7005258807303377, 0.6986419909835994, 0.6959724089867684, 0.694952405040836, 0.6921382863637401, 0.6899260266961071, 0.6877790874711313, 0.6833913794160895, 0.6842564446299074, 0.6829893011918464, 0.6790749427697602, 0.6775582181921327, 0.6764159334143119, 0.6770282103297877, 0.6740020684184405, 0.6705727025804028, 0.6708669776318763, 0.667894691164232, 0.6673906531610961, 0.6660683149415054, 0.662971095225226, 0.6617327916348685, 0.6613726649041796, 0.6602935876778634, 0.6585619161632171, 0.6571627651127202, 0.6553763599316812, 0.654089681724105, 0.6557713571060272, 0.6543930395435807, 0.650317135604182, 0.6502208585488986, 0.6478383018054803, 0.6451689956506951, 0.6461569544817891, 0.6439643208248264, 0.644713554053578, 0.6431961087133403, 0.6421601812712192, 0.6393639727758323, 0.641612866703726, 0.6401915777415573, 0.6383879284604991, 0.6373067804905723, 0.6359994774614738, 0.6356361691529702, 0.6334145441518484, 0.6339436143448545, 0.6319146310629871, 0.6319719837888981, 0.6319095655701937, 0.6298172202987713, 0.6276301250936807, 0.6271009110914345, 0.6258554888151371, 0.6255167318103434, 0.6259416324746793, 0.6261653124458779, 0.6250054783416407, 0.6222132053959656, 0.622211253091774, 0.620353531878255, 0.6207302915423145, 0.6194306242606158, 0.6197612635459869, 0.6200687447463618, 0.6174304080363371, 0.6162500590024221, 0.6150438158381353, 0.6142891362834433, 0.6148707476620089, 0.6147590450954366, 0.614596775305852, 0.6124845854092393, 0.6131469926030798, 0.6097076214593924, 0.6088056232898894, 0.6085834873257513, 0.608198699625011, 0.6085592167303587, 0.6065470398627187, 0.6070740066845393, 0.6062203323337232, 0.6048160846336553, 0.6045148812769074, 0.6028903472339672, 0.6021469654683705, 0.6016981942914263, 0.5994150623599445, 0.6001504626803941, 0.6000160269420908, 0.5996270009486484, 0.5996373439186756, 0.5974415818035324, 0.5966339216165539, 0.5973006446273409, 0.5943078459963821, 0.5938610026184763, 0.5938464885930267, 0.592565962899604, 0.5931066611633685, 0.5915324372655542, 0.5917097808289307, 0.5920241875595986, 0.59057616815348, 0.5895542276426133, 0.5899275115248244, 0.5888755494436302, 0.5871870536604032, 0.5866548716275053, 0.5862162287401644, 0.5865368185485609, 0.5839412619268539, 0.5856060821600171, 0.5835996192503253, 0.5853468545190201, 0.5840440849260145, 0.5827820535593535, 0.5817908695881221, 0.5821827575883967, 0.5809674807525932, 0.5815969043306238, 0.5814287879463104, 0.5788447963248633, 0.5800707334538265, 0.5799506530614524, 0.5789368608960634, 0.5800491416274487, 0.5773803194397427, 0.5771464957269486, 0.5764329087301027, 0.577619366124082, 0.5760387989709311, 0.5753976435634083, 0.5759984290816995, 0.575411525479144, 0.5748567260272865, 0.5745962507054343, 0.5739998762317666, 0.5724422084210241, 0.5728408498273446, 0.5712229317024797, 0.5728152393217495, 0.5724904504538881, 0.5709511876519924, 0.5723646215671137, 0.569975299659169, 0.5715186269870809, 0.5701541426388739, 0.5697800125080199, 0.5691279935457028, 0.568210472300332, 0.5674525124678308, 0.5685969619536907, 0.5690564037825758, 0.5670888648905739, 0.568555488431992, 0.5664872230435056, 0.5669749888924381, 0.5662780195450207, 0.5658487327584669, 0.5664979713676326, 0.5647676811861047, 0.5636272450104766, 0.5655941473968897, 0.565094647232185, 0.5652803655583989, 0.5651048559632105, 0.5645718872863141, 0.5622683513454083, 0.5642281269112508, 0.5631451756429992, 0.5631920597649085, 0.5622854441687298, 0.5637137064951473, 0.5617135185578672, 0.5620185503862445, 0.5622453460107798, 0.5624379096800944, 0.5618337637068559, 0.5600552133904508, 0.5611837430140261], 'acc': [0.7512958383016101, 0.8994015016735729, 0.9092716917117663, 0.9259453921687133, 0.9385420349030456, 0.9456955730423846, 0.9506354065732879, 0.9537745133912031, 0.9557435250470734, 0.9573525859796086, 0.9585839096158549, 0.959610635464183, 0.9604637958042949, 0.9610337840286448, 0.9618092721511361, 0.9623432185392597, 0.9626403810822928, 0.9631305890828135, 0.9634543180184179, 0.9638161804079808, 0.9641472638196282, 0.9644242882659633, 0.9646586392223303, 0.964987576387033, 0.9652473505901839, 0.9655176609290629, 0.9658265018573444, 0.9660009948269328, 0.9662757615099942, 0.9664395448989056, 0.9666070920558452, 0.966839981912745, 0.966972662124917, 0.9669298042480707, 0.9672736445934412, 0.9673541750015767, 0.9674300865768737, 0.9674584162488628, 0.9675005052203334, 0.9676688462976973, 0.9676550352100556, 0.9678126135282191, 0.9679645543885786, 0.9680005374762103, 0.9680760671526065, 0.9681392729359941, 0.9681377363403744, 0.9682237798865775, 0.9683257108183043, 0.9683453235185441, 0.9683928409423177, 0.9683801127322363, 0.9684554410932196, 0.96850464837144, 0.9685969096136942, 0.968623148590072, 0.9686333743961376, 0.9687135971433036, 0.9687083519288181, 0.9687602758993613, 0.9687969543237652, 0.9688188513219601, 0.9688757748263469, 0.9688654471531886, 0.968936900152253, 0.9688907103875418, 0.9689171868833589, 0.968979593463516, 0.9690298360194624, 0.9690477325661314, 0.9690140152995607, 0.9690818031630841, 0.9691685832025367, 0.9691337180014685, 0.9691756714527345, 0.9691879240982423, 0.9692158231080724, 0.9692357611245974, 0.9692449114042176, 0.9692711305334468, 0.9693031390981046, 0.9693363822019556, 0.9693729191827477, 0.9693839237272748, 0.9693978073809646, 0.9693677359055, 0.9693900498977781, 0.9695184184238763, 0.9694763609740101, 0.9695194919394656, 0.9695844799129353, 0.969560494859096, 0.9696012532385271, 0.9695697051656408, 0.9696341688974581, 0.9696263629440239, 0.9697029494315413, 0.9696276641775656, 0.969679702284296, 0.9696859833941275, 0.9697515740987048, 0.9698022500429563, 0.9697674970821252, 0.9698300127943106, 0.9698097796387037, 0.9698235386509201, 0.9698178027961862, 0.9698159780334097, 0.9698647075552235, 0.9698524735704596, 0.9698893178071774, 0.9699312413053068, 0.9699423381136528, 0.9699389955883595, 0.96992545304192, 0.9699282077509119, 0.9699767928559198, 0.9700131650499346, 0.9700166981900145, 0.9700018847423597, 0.9700154884073313, 0.9700345263216167, 0.9700263506665598, 0.9700545645505873, 0.9701113487026526, 0.970151112573027, 0.9701553628217042, 0.9701446539103551, 0.9701271758917653, 0.9701269102892857, 0.9701584059506464, 0.9701818978104501, 0.9702378080473664, 0.9702346614167928, 0.9702210552870862, 0.9702504924150414, 0.9702538427970364, 0.9703001530148954, 0.9702725220148267, 0.970327906944337, 0.9703224658150231, 0.9703004395274049, 0.97033565364359, 0.9703945356786403, 0.9703631531940011, 0.9704024033050284, 0.9703969525006244, 0.9703802843226933, 0.9704145149809118, 0.9704239490181689, 0.9704587839443636, 0.9704884351279409, 0.9704123223004292, 0.9705031269475336, 0.970493927666225, 0.970454605193108, 0.9705012931703768, 0.9704882321147908, 0.9705692914125287, 0.9705489948057968, 0.9705403688683717, 0.9705694166658769, 0.9706165554598272, 0.970578892520321, 0.9706280301827064, 0.970628840164125, 0.9706444026527706, 0.9706823526304815, 0.9706469855772064, 0.9706860198084777, 0.9706237062706281, 0.9707241959414187, 0.9706268108570753, 0.9706735813713653, 0.9707084901160841, 0.970706017383685, 0.9707194016297942, 0.9707403114327029, 0.9706944542434671, 0.9706997786339716, 0.9707077948109111, 0.9707556089307435, 0.9707473513131958, 0.9707780036014375, 0.9707323513011932, 0.9707340399721076, 0.970771643051303, 0.9707809152864676, 0.9707538875748011, 0.9707814260410214, 0.9707769398729716, 0.9707971552583566, 0.970791603006267, 0.9708412519919912, 0.970834909117281, 0.9708171034469404, 0.9708717729311184, 0.9708711172656626, 0.9709070479906038, 0.9708337727049884, 0.9708979093825664, 0.9708913317260538, 0.9708395105045073, 0.9709608178551475, 0.9708854275282001, 0.9709275606867951, 0.970949158294384, 0.970919004480111, 0.9709433986483508, 0.9709688087441363, 0.9709528567957714, 0.9709479673103318, 0.9709654374291302, 0.9709673728694215, 0.9709877732650499, 0.9709950978051921, 0.9709932656510835, 0.9710020329947758, 0.9709720380266371, 0.9710212756544201, 0.9710415718618534, 0.971026654082371, 0.9710024120842234, 0.9710504626146517, 0.9710335009178143, 0.9710352004703323, 0.9710782640376397, 0.971043466412824, 0.9710498497603204, 0.9710421456050353, 0.9710677088217606, 0.9710548684174046, 0.9711250113409061, 0.9710547987986969, 0.9710764985491531, 0.9710777596460088, 0.971084254618995, 0.9710859663228287, 0.9710715108017983], 'mDice': [0.028834092750397756, 0.0768978138077178, 0.16134214268097724, 0.29066378312677615, 0.39681120676111614, 0.4706440800109239, 0.5210550292221126, 0.5558858910918701, 0.5807089810888706, 0.6011575122495244, 0.6165408306773573, 0.630011233963319, 0.6419583837482359, 0.6507625750440753, 0.6607881226168005, 0.6686354915235891, 0.6735838450571503, 0.6799386776788039, 0.684692521435168, 0.6892246438587216, 0.6948663209959929, 0.6992128072885083, 0.7021555732983246, 0.7061180727781402, 0.7089588579238021, 0.7122358312991287, 0.7161243005260581, 0.7180894359955587, 0.7221835895017622, 0.7240876499914458, 0.7260643166860067, 0.7288454830821747, 0.7307182837120911, 0.7309485552937067, 0.736029982719084, 0.7372233047847995, 0.7382961502074735, 0.7393326861461138, 0.7405237114178405, 0.7429910490866644, 0.7431042128266745, 0.7454505087731919, 0.747263086997513, 0.7478540936023783, 0.7497808673570366, 0.7506095195105004, 0.7515533879450289, 0.7528008217179372, 0.7541546367485499, 0.7549720868425913, 0.7558264161737357, 0.7563123919945567, 0.7571047719596202, 0.7578942971181523, 0.7594772894340306, 0.7599109202713856, 0.760534129583311, 0.7620207088252965, 0.7624248207790363, 0.7633757244863247, 0.7635190600607503, 0.7645216682249221, 0.7653036654050094, 0.7658335602802279, 0.7671389730730782, 0.7670534370726773, 0.7670913057284985, 0.7686720632163523, 0.7690067494700941, 0.7693753123909625, 0.7690288757863082, 0.7700857158695177, 0.7712259479612148, 0.7711162033112768, 0.7721274176748858, 0.7722645100125164, 0.7726963393124817, 0.7734893424849124, 0.7741001664693054, 0.7742375714806823, 0.774536253460988, 0.7749035690134017, 0.7752683517002038, 0.7761879620870812, 0.7766917728103439, 0.7759469458439694, 0.7764981577290564, 0.7778183620196318, 0.7776456816557591, 0.7784788013998356, 0.7794495112316034, 0.7791188267134628, 0.7798501936187112, 0.7795986604205648, 0.7800100820886927, 0.7805191453114849, 0.7813761303456894, 0.7804012011060302, 0.781041869014549, 0.7813822119987134, 0.7820598795859921, 0.782617478515678, 0.782648688621122, 0.7833679262756055, 0.7829985872763509, 0.7837867985128397, 0.7837746210647287, 0.7837698446755765, 0.7844695761879529, 0.7852427056395431, 0.7855513572256229, 0.7857155426851933, 0.7860296115288534, 0.7859658408241965, 0.7857792102961352, 0.7862346409383961, 0.7869606989941842, 0.7872796553382817, 0.7878182086205044, 0.7877253153805699, 0.7881680641313812, 0.788242187056003, 0.7879322098188443, 0.7887486336294315, 0.7893618595439834, 0.7894802265864946, 0.789789052146091, 0.7901540774771424, 0.789878185386916, 0.7899776488403233, 0.7905403774952887, 0.7905781803788826, 0.7913628234950151, 0.79195239611537, 0.7920069231562537, 0.7921792572909386, 0.7920820947164305, 0.7930883847809371, 0.7925829390881062, 0.7927898241816455, 0.7934239947070236, 0.7936565087349353, 0.7940746407473459, 0.7943172586803592, 0.7944042436231664, 0.7953529911067918, 0.7950420123283257, 0.7952358177428798, 0.7952547864607371, 0.7954606421338868, 0.7960916963179282, 0.7963185150242178, 0.7961248698547791, 0.7972438936923186, 0.7973341788634994, 0.7971872903794069, 0.7978275187377832, 0.7977519793575704, 0.7980048532135269, 0.798125962882658, 0.7979538989955302, 0.7982142617676171, 0.7989616527420175, 0.7987710320580131, 0.7990820370408057, 0.7997493743034689, 0.7997372453600776, 0.800073389972777, 0.8000135149253214, 0.8009127647631186, 0.8001729232373597, 0.8010288789775711, 0.8006292842280073, 0.8007152385209301, 0.8009981827262718, 0.801552893925968, 0.8013798892914551, 0.8017324404093931, 0.8017551447088227, 0.8018677356335173, 0.8024952191577784, 0.8023693594761806, 0.8022202557325651, 0.802591583238601, 0.8023882737572932, 0.8030254242477535, 0.8031501547446498, 0.8035299307903937, 0.8029247983960486, 0.8035093583861422, 0.8035898317836372, 0.803784920612676, 0.8040446674308407, 0.8041523123937685, 0.8039767047837129, 0.8045045602142946, 0.8046368265147381, 0.8047525261510073, 0.8049946184232785, 0.8047600902760251, 0.8047650899908457, 0.8053066228417248, 0.8046931249617703, 0.8058286962684272, 0.805100988965993, 0.8055585815082763, 0.8057242442432142, 0.8059978052486114, 0.8063870272387527, 0.8065104184538389, 0.8060642901923468, 0.8061150162270215, 0.8068211530626777, 0.8062555058110829, 0.8068951509465274, 0.8065922950812378, 0.8069713761665268, 0.8070616500510601, 0.806989952020573, 0.8074851666503863, 0.8077281322517856, 0.8074042137930023, 0.8072356480829135, 0.8074305938711465, 0.8074145188899929, 0.8075838355398952, 0.8083347239616814, 0.8078698700775876, 0.8080936593546099, 0.8081030727030312, 0.8083442876100988, 0.807918281734774, 0.8086667280035356, 0.8084270799181261, 0.8084306476822738, 0.8083574899972631, 0.8085604853684991, 0.8091246934849197, 0.8085476293599004]}
predicting test subjects:   0%|          | 0/15 [00:00<?, ?it/s]predicting test subjects:   7%|▋         | 1/15 [00:02<00:30,  2.16s/it]predicting test subjects:  13%|█▎        | 2/15 [00:03<00:26,  2.04s/it]predicting test subjects:  20%|██        | 3/15 [00:05<00:24,  2.03s/it]predicting test subjects:  27%|██▋       | 4/15 [00:07<00:22,  2.02s/it]predicting test subjects:  33%|███▎      | 5/15 [00:10<00:21,  2.14s/it]predicting test subjects:  40%|████      | 6/15 [00:12<00:19,  2.19s/it]predicting test subjects:  47%|████▋     | 7/15 [00:14<00:15,  1.98s/it]predicting test subjects:  53%|█████▎    | 8/15 [00:16<00:14,  2.10s/it]predicting test subjects:  60%|██████    | 9/15 [00:18<00:12,  2.02s/it]predicting test subjects:  67%|██████▋   | 10/15 [00:19<00:09,  1.89s/it]predicting test subjects:  73%|███████▎  | 11/15 [00:21<00:07,  1.87s/it]predicting test subjects:  80%|████████  | 12/15 [00:23<00:05,  1.92s/it]predicting test subjects:  87%|████████▋ | 13/15 [00:26<00:04,  2.02s/it]predicting test subjects:  93%|█████████▎| 14/15 [00:27<00:01,  1.96s/it]predicting test subjects: 100%|██████████| 15/15 [00:29<00:00,  2.00s/it]
predicting train subjects:   0%|          | 0/532 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/532 [00:02<20:20,  2.30s/it]predicting train subjects:   0%|          | 2/532 [00:03<18:33,  2.10s/it]predicting train subjects:   1%|          | 3/532 [00:05<17:32,  1.99s/it]predicting train subjects:   1%|          | 4/532 [00:07<17:00,  1.93s/it]predicting train subjects:   1%|          | 5/532 [00:09<17:04,  1.94s/it]predicting train subjects:   1%|          | 6/532 [00:11<16:12,  1.85s/it]predicting train subjects:   1%|▏         | 7/532 [00:12<16:22,  1.87s/it]predicting train subjects:   2%|▏         | 8/532 [00:14<16:01,  1.84s/it]predicting train subjects:   2%|▏         | 9/532 [00:16<16:32,  1.90s/it]predicting train subjects:   2%|▏         | 10/532 [00:18<16:18,  1.87s/it]predicting train subjects:   2%|▏         | 11/532 [00:20<15:32,  1.79s/it]predicting train subjects:   2%|▏         | 12/532 [00:22<16:44,  1.93s/it]predicting train subjects:   2%|▏         | 13/532 [00:23<15:29,  1.79s/it]predicting train subjects:   3%|▎         | 14/532 [00:25<14:49,  1.72s/it]predicting train subjects:   3%|▎         | 15/532 [00:27<14:45,  1.71s/it]predicting train subjects:   3%|▎         | 16/532 [00:29<15:15,  1.77s/it]predicting train subjects:   3%|▎         | 17/532 [00:30<14:40,  1.71s/it]predicting train subjects:   3%|▎         | 18/532 [00:32<15:24,  1.80s/it]predicting train subjects:   4%|▎         | 19/532 [00:34<14:32,  1.70s/it]predicting train subjects:   4%|▍         | 20/532 [00:35<14:35,  1.71s/it]predicting train subjects:   4%|▍         | 21/532 [00:37<15:24,  1.81s/it]predicting train subjects:   4%|▍         | 22/532 [00:39<14:44,  1.73s/it]predicting train subjects:   4%|▍         | 23/532 [00:41<14:49,  1.75s/it]predicting train subjects:   5%|▍         | 24/532 [00:42<14:04,  1.66s/it]predicting train subjects:   5%|▍         | 25/532 [00:44<15:21,  1.82s/it]predicting train subjects:   5%|▍         | 26/532 [00:46<14:43,  1.75s/it]predicting train subjects:   5%|▌         | 27/532 [00:48<16:02,  1.91s/it]predicting train subjects:   5%|▌         | 28/532 [00:50<15:28,  1.84s/it]predicting train subjects:   5%|▌         | 29/532 [00:52<16:06,  1.92s/it]predicting train subjects:   6%|▌         | 30/532 [00:54<15:04,  1.80s/it]predicting train subjects:   6%|▌         | 31/532 [00:55<15:01,  1.80s/it]predicting train subjects:   6%|▌         | 32/532 [00:57<14:50,  1.78s/it]predicting train subjects:   6%|▌         | 33/532 [00:59<14:23,  1.73s/it]predicting train subjects:   6%|▋         | 34/532 [01:01<15:18,  1.85s/it]predicting train subjects:   7%|▋         | 35/532 [01:03<14:58,  1.81s/it]predicting train subjects:   7%|▋         | 36/532 [01:04<15:19,  1.85s/it]predicting train subjects:   7%|▋         | 37/532 [01:06<15:10,  1.84s/it]predicting train subjects:   7%|▋         | 38/532 [01:08<15:34,  1.89s/it]predicting train subjects:   7%|▋         | 39/532 [01:10<15:07,  1.84s/it]predicting train subjects:   8%|▊         | 40/532 [01:12<14:33,  1.78s/it]predicting train subjects:   8%|▊         | 41/532 [01:14<15:58,  1.95s/it]predicting train subjects:   8%|▊         | 42/532 [01:16<16:49,  2.06s/it]predicting train subjects:   8%|▊         | 43/532 [01:18<16:31,  2.03s/it]predicting train subjects:   8%|▊         | 44/532 [01:20<15:34,  1.92s/it]predicting train subjects:   8%|▊         | 45/532 [01:22<15:35,  1.92s/it]predicting train subjects:   9%|▊         | 46/532 [01:24<16:35,  2.05s/it]predicting train subjects:   9%|▉         | 47/532 [01:27<18:09,  2.25s/it]predicting train subjects:   9%|▉         | 48/532 [01:29<18:14,  2.26s/it]predicting train subjects:   9%|▉         | 49/532 [01:31<17:00,  2.11s/it]predicting train subjects:   9%|▉         | 50/532 [01:34<17:56,  2.23s/it]predicting train subjects:  10%|▉         | 51/532 [01:36<17:36,  2.20s/it]predicting train subjects:  10%|▉         | 52/532 [01:38<17:44,  2.22s/it]predicting train subjects:  10%|▉         | 53/532 [01:40<17:17,  2.17s/it]predicting train subjects:  10%|█         | 54/532 [01:43<18:17,  2.30s/it]predicting train subjects:  10%|█         | 55/532 [01:45<18:00,  2.26s/it]predicting train subjects:  11%|█         | 56/532 [01:47<18:15,  2.30s/it]predicting train subjects:  11%|█         | 57/532 [01:49<18:17,  2.31s/it]predicting train subjects:  11%|█         | 58/532 [01:52<17:42,  2.24s/it]predicting train subjects:  11%|█         | 59/532 [01:54<18:46,  2.38s/it]predicting train subjects:  11%|█▏        | 60/532 [01:56<17:02,  2.17s/it]predicting train subjects:  11%|█▏        | 61/532 [01:58<16:35,  2.11s/it]predicting train subjects:  12%|█▏        | 62/532 [02:00<17:32,  2.24s/it]predicting train subjects:  12%|█▏        | 63/532 [02:03<17:22,  2.22s/it]predicting train subjects:  12%|█▏        | 64/532 [02:04<16:32,  2.12s/it]predicting train subjects:  12%|█▏        | 65/532 [02:07<17:05,  2.20s/it]predicting train subjects:  12%|█▏        | 66/532 [02:09<18:05,  2.33s/it]predicting train subjects:  13%|█▎        | 67/532 [02:12<18:43,  2.42s/it]predicting train subjects:  13%|█▎        | 68/532 [02:14<18:21,  2.37s/it]predicting train subjects:  13%|█▎        | 69/532 [02:17<17:48,  2.31s/it]predicting train subjects:  13%|█▎        | 70/532 [02:19<17:13,  2.24s/it]predicting train subjects:  13%|█▎        | 71/532 [02:21<16:24,  2.14s/it]predicting train subjects:  14%|█▎        | 72/532 [02:22<15:43,  2.05s/it]predicting train subjects:  14%|█▎        | 73/532 [02:24<15:44,  2.06s/it]predicting train subjects:  14%|█▍        | 74/532 [02:27<17:32,  2.30s/it]predicting train subjects:  14%|█▍        | 75/532 [02:31<20:08,  2.64s/it]predicting train subjects:  14%|█▍        | 76/532 [02:33<18:46,  2.47s/it]predicting train subjects:  14%|█▍        | 77/532 [02:35<18:08,  2.39s/it]predicting train subjects:  15%|█▍        | 78/532 [02:37<17:35,  2.33s/it]predicting train subjects:  15%|█▍        | 79/532 [02:39<17:19,  2.30s/it]predicting train subjects:  15%|█▌        | 80/532 [02:42<17:17,  2.29s/it]predicting train subjects:  15%|█▌        | 81/532 [02:44<17:01,  2.26s/it]predicting train subjects:  15%|█▌        | 82/532 [02:46<16:58,  2.26s/it]predicting train subjects:  16%|█▌        | 83/532 [02:48<15:57,  2.13s/it]predicting train subjects:  16%|█▌        | 84/532 [02:50<14:56,  2.00s/it]predicting train subjects:  16%|█▌        | 85/532 [02:52<15:00,  2.02s/it]predicting train subjects:  16%|█▌        | 86/532 [02:54<14:43,  1.98s/it]predicting train subjects:  16%|█▋        | 87/532 [02:56<14:34,  1.97s/it]predicting train subjects:  17%|█▋        | 88/532 [02:57<14:22,  1.94s/it]predicting train subjects:  17%|█▋        | 89/532 [03:00<14:49,  2.01s/it]predicting train subjects:  17%|█▋        | 90/532 [03:02<14:57,  2.03s/it]predicting train subjects:  17%|█▋        | 91/532 [03:04<14:48,  2.01s/it]predicting train subjects:  17%|█▋        | 92/532 [03:06<14:58,  2.04s/it]predicting train subjects:  17%|█▋        | 93/532 [03:08<14:50,  2.03s/it]predicting train subjects:  18%|█▊        | 94/532 [03:10<14:46,  2.02s/it]predicting train subjects:  18%|█▊        | 95/532 [03:12<15:43,  2.16s/it]predicting train subjects:  18%|█▊        | 96/532 [03:15<16:01,  2.21s/it]predicting train subjects:  18%|█▊        | 97/532 [03:17<16:54,  2.33s/it]predicting train subjects:  18%|█▊        | 98/532 [03:20<16:54,  2.34s/it]predicting train subjects:  19%|█▊        | 99/532 [03:22<17:06,  2.37s/it]predicting train subjects:  19%|█▉        | 100/532 [03:24<17:18,  2.40s/it]predicting train subjects:  19%|█▉        | 101/532 [03:26<15:53,  2.21s/it]predicting train subjects:  19%|█▉        | 102/532 [03:28<14:57,  2.09s/it]predicting train subjects:  19%|█▉        | 103/532 [03:30<14:06,  1.97s/it]predicting train subjects:  20%|█▉        | 104/532 [03:32<13:55,  1.95s/it]predicting train subjects:  20%|█▉        | 105/532 [03:33<13:09,  1.85s/it]predicting train subjects:  20%|█▉        | 106/532 [03:35<12:56,  1.82s/it]predicting train subjects:  20%|██        | 107/532 [03:37<12:45,  1.80s/it]predicting train subjects:  20%|██        | 108/532 [03:39<12:58,  1.83s/it]predicting train subjects:  20%|██        | 109/532 [03:40<12:27,  1.77s/it]predicting train subjects:  21%|██        | 110/532 [03:42<12:24,  1.76s/it]predicting train subjects:  21%|██        | 111/532 [03:44<12:52,  1.83s/it]predicting train subjects:  21%|██        | 112/532 [03:46<12:57,  1.85s/it]predicting train subjects:  21%|██        | 113/532 [03:48<13:40,  1.96s/it]predicting train subjects:  21%|██▏       | 114/532 [03:50<14:24,  2.07s/it]predicting train subjects:  22%|██▏       | 115/532 [03:53<14:48,  2.13s/it]predicting train subjects:  22%|██▏       | 116/532 [03:55<14:52,  2.15s/it]predicting train subjects:  22%|██▏       | 117/532 [03:57<15:03,  2.18s/it]predicting train subjects:  22%|██▏       | 118/532 [03:59<15:06,  2.19s/it]predicting train subjects:  22%|██▏       | 119/532 [04:02<14:59,  2.18s/it]predicting train subjects:  23%|██▎       | 120/532 [04:04<14:46,  2.15s/it]predicting train subjects:  23%|██▎       | 121/532 [04:06<14:36,  2.13s/it]predicting train subjects:  23%|██▎       | 122/532 [04:08<14:57,  2.19s/it]predicting train subjects:  23%|██▎       | 123/532 [04:10<14:46,  2.17s/it]predicting train subjects:  23%|██▎       | 124/532 [04:12<14:32,  2.14s/it]predicting train subjects:  23%|██▎       | 125/532 [04:14<14:35,  2.15s/it]predicting train subjects:  24%|██▎       | 126/532 [04:17<14:43,  2.18s/it]predicting train subjects:  24%|██▍       | 127/532 [04:19<14:44,  2.18s/it]predicting train subjects:  24%|██▍       | 128/532 [04:21<14:17,  2.12s/it]predicting train subjects:  24%|██▍       | 129/532 [04:23<14:19,  2.13s/it]predicting train subjects:  24%|██▍       | 130/532 [04:25<14:43,  2.20s/it]predicting train subjects:  25%|██▍       | 131/532 [04:28<15:33,  2.33s/it]predicting train subjects:  25%|██▍       | 132/532 [04:31<16:03,  2.41s/it]predicting train subjects:  25%|██▌       | 133/532 [04:33<16:39,  2.50s/it]predicting train subjects:  25%|██▌       | 134/532 [04:36<16:56,  2.55s/it]predicting train subjects:  25%|██▌       | 135/532 [04:38<16:46,  2.54s/it]predicting train subjects:  26%|██▌       | 136/532 [04:41<17:09,  2.60s/it]predicting train subjects:  26%|██▌       | 137/532 [04:44<17:13,  2.62s/it]predicting train subjects:  26%|██▌       | 138/532 [04:46<17:11,  2.62s/it]predicting train subjects:  26%|██▌       | 139/532 [04:49<17:03,  2.60s/it]predicting train subjects:  26%|██▋       | 140/532 [04:52<17:36,  2.69s/it]predicting train subjects:  27%|██▋       | 141/532 [04:55<17:26,  2.68s/it]predicting train subjects:  27%|██▋       | 142/532 [04:57<17:10,  2.64s/it]predicting train subjects:  27%|██▋       | 143/532 [04:59<15:56,  2.46s/it]predicting train subjects:  27%|██▋       | 144/532 [05:01<15:11,  2.35s/it]predicting train subjects:  27%|██▋       | 145/532 [05:03<14:29,  2.25s/it]predicting train subjects:  27%|██▋       | 146/532 [05:05<13:54,  2.16s/it]predicting train subjects:  28%|██▊       | 147/532 [05:07<13:27,  2.10s/it]predicting train subjects:  28%|██▊       | 148/532 [05:09<12:59,  2.03s/it]predicting train subjects:  28%|██▊       | 149/532 [05:11<12:53,  2.02s/it]predicting train subjects:  28%|██▊       | 150/532 [05:13<12:48,  2.01s/it]predicting train subjects:  28%|██▊       | 151/532 [05:15<12:52,  2.03s/it]predicting train subjects:  29%|██▊       | 152/532 [05:17<13:08,  2.08s/it]predicting train subjects:  29%|██▉       | 153/532 [05:19<13:08,  2.08s/it]predicting train subjects:  29%|██▉       | 154/532 [05:22<13:12,  2.10s/it]predicting train subjects:  29%|██▉       | 155/532 [05:24<14:28,  2.30s/it]predicting train subjects:  29%|██▉       | 156/532 [05:27<15:33,  2.48s/it]predicting train subjects:  30%|██▉       | 157/532 [05:30<15:39,  2.51s/it]predicting train subjects:  30%|██▉       | 158/532 [05:32<15:57,  2.56s/it]predicting train subjects:  30%|██▉       | 159/532 [05:35<15:25,  2.48s/it]predicting train subjects:  30%|███       | 160/532 [05:37<15:16,  2.46s/it]predicting train subjects:  30%|███       | 161/532 [05:39<13:59,  2.26s/it]predicting train subjects:  30%|███       | 162/532 [05:41<13:11,  2.14s/it]predicting train subjects:  31%|███       | 163/532 [05:43<12:29,  2.03s/it]predicting train subjects:  31%|███       | 164/532 [05:44<11:51,  1.93s/it]predicting train subjects:  31%|███       | 165/532 [05:46<11:24,  1.87s/it]predicting train subjects:  31%|███       | 166/532 [05:48<11:04,  1.82s/it]predicting train subjects:  31%|███▏      | 167/532 [05:50<11:03,  1.82s/it]predicting train subjects:  32%|███▏      | 168/532 [05:51<11:03,  1.82s/it]predicting train subjects:  32%|███▏      | 169/532 [05:53<11:00,  1.82s/it]predicting train subjects:  32%|███▏      | 170/532 [05:55<11:04,  1.84s/it]predicting train subjects:  32%|███▏      | 171/532 [05:57<11:08,  1.85s/it]predicting train subjects:  32%|███▏      | 172/532 [05:59<11:08,  1.86s/it]predicting train subjects:  33%|███▎      | 173/532 [06:00<10:40,  1.78s/it]predicting train subjects:  33%|███▎      | 174/532 [06:02<10:28,  1.76s/it]predicting train subjects:  33%|███▎      | 175/532 [06:04<10:11,  1.71s/it]predicting train subjects:  33%|███▎      | 176/532 [06:05<10:02,  1.69s/it]predicting train subjects:  33%|███▎      | 177/532 [06:07<09:48,  1.66s/it]predicting train subjects:  33%|███▎      | 178/532 [06:09<09:36,  1.63s/it]predicting train subjects:  34%|███▎      | 179/532 [06:10<09:37,  1.63s/it]predicting train subjects:  34%|███▍      | 180/532 [06:12<09:40,  1.65s/it]predicting train subjects:  34%|███▍      | 181/532 [06:14<09:42,  1.66s/it]predicting train subjects:  34%|███▍      | 182/532 [06:15<09:47,  1.68s/it]predicting train subjects:  34%|███▍      | 183/532 [06:17<09:43,  1.67s/it]predicting train subjects:  35%|███▍      | 184/532 [06:19<09:49,  1.69s/it]predicting train subjects:  35%|███▍      | 185/532 [06:20<09:38,  1.67s/it]predicting train subjects:  35%|███▍      | 186/532 [06:22<09:34,  1.66s/it]predicting train subjects:  35%|███▌      | 187/532 [06:23<09:23,  1.63s/it]predicting train subjects:  35%|███▌      | 188/532 [06:25<09:17,  1.62s/it]predicting train subjects:  36%|███▌      | 189/532 [06:27<09:09,  1.60s/it]predicting train subjects:  36%|███▌      | 190/532 [06:28<09:01,  1.58s/it]predicting train subjects:  36%|███▌      | 191/532 [06:30<10:14,  1.80s/it]predicting train subjects:  36%|███▌      | 192/532 [06:33<11:08,  1.97s/it]predicting train subjects:  36%|███▋      | 193/532 [06:35<11:46,  2.08s/it]predicting train subjects:  36%|███▋      | 194/532 [06:38<12:21,  2.19s/it]predicting train subjects:  37%|███▋      | 195/532 [06:40<12:43,  2.27s/it]predicting train subjects:  37%|███▋      | 196/532 [06:42<12:48,  2.29s/it]predicting train subjects:  37%|███▋      | 197/532 [06:44<12:21,  2.21s/it]predicting train subjects:  37%|███▋      | 198/532 [06:46<11:54,  2.14s/it]predicting train subjects:  37%|███▋      | 199/532 [06:48<11:38,  2.10s/it]predicting train subjects:  38%|███▊      | 200/532 [06:50<11:30,  2.08s/it]predicting train subjects:  38%|███▊      | 201/532 [06:53<11:36,  2.10s/it]predicting train subjects:  38%|███▊      | 202/532 [06:55<11:34,  2.10s/it]predicting train subjects:  38%|███▊      | 203/532 [06:56<10:54,  1.99s/it]predicting train subjects:  38%|███▊      | 204/532 [06:58<10:28,  1.92s/it]predicting train subjects:  39%|███▊      | 205/532 [07:00<10:04,  1.85s/it]predicting train subjects:  39%|███▊      | 206/532 [07:02<09:54,  1.82s/it]predicting train subjects:  39%|███▉      | 207/532 [07:03<09:48,  1.81s/it]predicting train subjects:  39%|███▉      | 208/532 [07:05<09:36,  1.78s/it]predicting train subjects:  39%|███▉      | 209/532 [07:07<09:10,  1.70s/it]predicting train subjects:  39%|███▉      | 210/532 [07:08<08:50,  1.65s/it]predicting train subjects:  40%|███▉      | 211/532 [07:10<08:36,  1.61s/it]predicting train subjects:  40%|███▉      | 212/532 [07:11<08:29,  1.59s/it]predicting train subjects:  40%|████      | 213/532 [07:13<08:25,  1.58s/it]predicting train subjects:  40%|████      | 214/532 [07:14<08:22,  1.58s/it]predicting train subjects:  40%|████      | 215/532 [07:17<09:23,  1.78s/it]predicting train subjects:  41%|████      | 216/532 [07:19<10:11,  1.94s/it]predicting train subjects:  41%|████      | 217/532 [07:21<10:34,  2.01s/it]predicting train subjects:  41%|████      | 218/532 [07:23<10:45,  2.06s/it]predicting train subjects:  41%|████      | 219/532 [07:25<10:56,  2.10s/it]predicting train subjects:  41%|████▏     | 220/532 [07:28<11:11,  2.15s/it]predicting train subjects:  42%|████▏     | 221/532 [07:29<10:01,  1.93s/it]predicting train subjects:  42%|████▏     | 222/532 [07:31<09:14,  1.79s/it]predicting train subjects:  42%|████▏     | 223/532 [07:32<08:51,  1.72s/it]predicting train subjects:  42%|████▏     | 224/532 [07:34<08:30,  1.66s/it]predicting train subjects:  42%|████▏     | 225/532 [07:35<08:12,  1.60s/it]predicting train subjects:  42%|████▏     | 226/532 [07:37<08:01,  1.57s/it]predicting train subjects:  43%|████▎     | 227/532 [07:38<07:48,  1.54s/it]predicting train subjects:  43%|████▎     | 228/532 [07:40<07:35,  1.50s/it]predicting train subjects:  43%|████▎     | 229/532 [07:41<07:25,  1.47s/it]predicting train subjects:  43%|████▎     | 230/532 [07:42<07:20,  1.46s/it]predicting train subjects:  43%|████▎     | 231/532 [07:44<07:22,  1.47s/it]predicting train subjects:  44%|████▎     | 232/532 [07:45<07:21,  1.47s/it]predicting train subjects:  44%|████▍     | 233/532 [07:47<07:44,  1.55s/it]predicting train subjects:  44%|████▍     | 234/532 [07:49<07:47,  1.57s/it]predicting train subjects:  44%|████▍     | 235/532 [07:50<07:54,  1.60s/it]predicting train subjects:  44%|████▍     | 236/532 [07:52<08:05,  1.64s/it]predicting train subjects:  45%|████▍     | 237/532 [07:54<08:07,  1.65s/it]predicting train subjects:  45%|████▍     | 238/532 [07:56<08:17,  1.69s/it]predicting train subjects:  45%|████▍     | 239/532 [07:58<08:42,  1.78s/it]predicting train subjects:  45%|████▌     | 240/532 [07:59<08:48,  1.81s/it]predicting train subjects:  45%|████▌     | 241/532 [08:01<08:50,  1.82s/it]predicting train subjects:  45%|████▌     | 242/532 [08:03<08:52,  1.84s/it]predicting train subjects:  46%|████▌     | 243/532 [08:05<08:58,  1.86s/it]predicting train subjects:  46%|████▌     | 244/532 [08:07<08:58,  1.87s/it]predicting train subjects:  46%|████▌     | 245/532 [08:09<08:28,  1.77s/it]predicting train subjects:  46%|████▌     | 246/532 [08:10<07:55,  1.66s/it]predicting train subjects:  46%|████▋     | 247/532 [08:11<07:34,  1.60s/it]predicting train subjects:  47%|████▋     | 248/532 [08:13<07:22,  1.56s/it]predicting train subjects:  47%|████▋     | 249/532 [08:14<07:08,  1.52s/it]predicting train subjects:  47%|████▋     | 250/532 [08:16<07:03,  1.50s/it]predicting train subjects:  47%|████▋     | 251/532 [08:17<07:13,  1.54s/it]predicting train subjects:  47%|████▋     | 252/532 [08:19<07:15,  1.56s/it]predicting train subjects:  48%|████▊     | 253/532 [08:21<07:18,  1.57s/it]predicting train subjects:  48%|████▊     | 254/532 [08:22<07:09,  1.55s/it]predicting train subjects:  48%|████▊     | 255/532 [08:24<07:10,  1.55s/it]predicting train subjects:  48%|████▊     | 256/532 [08:25<07:15,  1.58s/it]predicting train subjects:  48%|████▊     | 257/532 [08:27<07:51,  1.71s/it]predicting train subjects:  48%|████▊     | 258/532 [08:29<08:17,  1.81s/it]predicting train subjects:  49%|████▊     | 259/532 [08:31<08:36,  1.89s/it]predicting train subjects:  49%|████▉     | 260/532 [08:33<08:42,  1.92s/it]predicting train subjects:  49%|████▉     | 261/532 [08:35<08:45,  1.94s/it]predicting train subjects:  49%|████▉     | 262/532 [08:37<08:46,  1.95s/it]predicting train subjects:  49%|████▉     | 263/532 [08:39<08:02,  1.80s/it]predicting train subjects:  50%|████▉     | 264/532 [08:40<07:30,  1.68s/it]predicting train subjects:  50%|████▉     | 265/532 [08:42<07:12,  1.62s/it]predicting train subjects:  50%|█████     | 266/532 [08:43<06:55,  1.56s/it]predicting train subjects:  50%|█████     | 267/532 [08:45<06:41,  1.52s/it]predicting train subjects:  50%|█████     | 268/532 [08:46<06:34,  1.49s/it]predicting train subjects:  51%|█████     | 269/532 [08:48<07:08,  1.63s/it]predicting train subjects:  51%|█████     | 270/532 [08:50<07:16,  1.66s/it]predicting train subjects:  51%|█████     | 271/532 [08:51<07:20,  1.69s/it]predicting train subjects:  51%|█████     | 272/532 [08:53<07:29,  1.73s/it]predicting train subjects:  51%|█████▏    | 273/532 [08:55<07:32,  1.75s/it]predicting train subjects:  52%|█████▏    | 274/532 [08:57<07:37,  1.77s/it]predicting train subjects:  52%|█████▏    | 275/532 [08:59<08:10,  1.91s/it]predicting train subjects:  52%|█████▏    | 276/532 [09:01<08:34,  2.01s/it]predicting train subjects:  52%|█████▏    | 277/532 [09:04<08:50,  2.08s/it]predicting train subjects:  52%|█████▏    | 278/532 [09:06<08:58,  2.12s/it]predicting train subjects:  52%|█████▏    | 279/532 [09:08<09:05,  2.16s/it]predicting train subjects:  53%|█████▎    | 280/532 [09:10<09:08,  2.18s/it]predicting train subjects:  53%|█████▎    | 281/532 [09:12<09:05,  2.17s/it]predicting train subjects:  53%|█████▎    | 282/532 [09:15<08:58,  2.15s/it]predicting train subjects:  53%|█████▎    | 283/532 [09:17<08:58,  2.16s/it]predicting train subjects:  53%|█████▎    | 284/532 [09:19<08:53,  2.15s/it]predicting train subjects:  54%|█████▎    | 285/532 [09:21<08:53,  2.16s/it]predicting train subjects:  54%|█████▍    | 286/532 [09:23<08:43,  2.13s/it]predicting train subjects:  54%|█████▍    | 287/532 [09:25<07:58,  1.95s/it]predicting train subjects:  54%|█████▍    | 288/532 [09:26<07:26,  1.83s/it]predicting train subjects:  54%|█████▍    | 289/532 [09:28<07:06,  1.76s/it]predicting train subjects:  55%|█████▍    | 290/532 [09:29<06:51,  1.70s/it]predicting train subjects:  55%|█████▍    | 291/532 [09:31<06:42,  1.67s/it]predicting train subjects:  55%|█████▍    | 292/532 [09:33<06:37,  1.65s/it]predicting train subjects:  55%|█████▌    | 293/532 [09:34<06:46,  1.70s/it]predicting train subjects:  55%|█████▌    | 294/532 [09:36<06:54,  1.74s/it]predicting train subjects:  55%|█████▌    | 295/532 [09:38<06:55,  1.75s/it]predicting train subjects:  56%|█████▌    | 296/532 [09:40<06:54,  1.76s/it]predicting train subjects:  56%|█████▌    | 297/532 [09:41<06:52,  1.75s/it]predicting train subjects:  56%|█████▌    | 298/532 [09:43<06:55,  1.78s/it]predicting train subjects:  56%|█████▌    | 299/532 [09:45<06:29,  1.67s/it]predicting train subjects:  56%|█████▋    | 300/532 [09:46<06:17,  1.63s/it]predicting train subjects:  57%|█████▋    | 301/532 [09:48<06:08,  1.59s/it]predicting train subjects:  57%|█████▋    | 302/532 [09:49<06:02,  1.58s/it]predicting train subjects:  57%|█████▋    | 303/532 [09:51<05:53,  1.54s/it]predicting train subjects:  57%|█████▋    | 304/532 [09:52<05:52,  1.55s/it]predicting train subjects:  57%|█████▋    | 305/532 [09:55<06:36,  1.75s/it]predicting train subjects:  58%|█████▊    | 306/532 [09:57<07:03,  1.87s/it]predicting train subjects:  58%|█████▊    | 307/532 [09:59<07:26,  1.98s/it]predicting train subjects:  58%|█████▊    | 308/532 [10:01<07:37,  2.04s/it]predicting train subjects:  58%|█████▊    | 309/532 [10:03<07:48,  2.10s/it]predicting train subjects:  58%|█████▊    | 310/532 [10:06<08:06,  2.19s/it]predicting train subjects:  58%|█████▊    | 311/532 [10:09<08:52,  2.41s/it]predicting train subjects:  59%|█████▊    | 312/532 [10:12<09:36,  2.62s/it]predicting train subjects:  59%|█████▉    | 313/532 [10:15<09:48,  2.69s/it]predicting train subjects:  59%|█████▉    | 314/532 [10:18<10:02,  2.76s/it]predicting train subjects:  59%|█████▉    | 315/532 [10:20<10:11,  2.82s/it]predicting train subjects:  59%|█████▉    | 316/532 [10:23<10:11,  2.83s/it]predicting train subjects:  60%|█████▉    | 317/532 [10:25<08:59,  2.51s/it]predicting train subjects:  60%|█████▉    | 318/532 [10:27<08:00,  2.25s/it]predicting train subjects:  60%|█████▉    | 319/532 [10:28<07:20,  2.07s/it]predicting train subjects:  60%|██████    | 320/532 [10:30<06:55,  1.96s/it]predicting train subjects:  60%|██████    | 321/532 [10:32<06:43,  1.91s/it]predicting train subjects:  61%|██████    | 322/532 [10:34<06:25,  1.84s/it]predicting train subjects:  61%|██████    | 323/532 [10:36<06:57,  2.00s/it]predicting train subjects:  61%|██████    | 324/532 [10:38<07:11,  2.07s/it]predicting train subjects:  61%|██████    | 325/532 [10:41<07:24,  2.15s/it]predicting train subjects:  61%|██████▏   | 326/532 [10:43<07:37,  2.22s/it]predicting train subjects:  61%|██████▏   | 327/532 [10:45<07:47,  2.28s/it]predicting train subjects:  62%|██████▏   | 328/532 [10:48<07:49,  2.30s/it]predicting train subjects:  62%|██████▏   | 329/532 [10:49<07:14,  2.14s/it]predicting train subjects:  62%|██████▏   | 330/532 [10:51<06:47,  2.02s/it]predicting train subjects:  62%|██████▏   | 331/532 [10:53<06:32,  1.95s/it]predicting train subjects:  62%|██████▏   | 332/532 [10:55<06:20,  1.90s/it]predicting train subjects:  63%|██████▎   | 333/532 [10:57<06:12,  1.87s/it]predicting train subjects:  63%|██████▎   | 334/532 [10:58<06:00,  1.82s/it]predicting train subjects:  63%|██████▎   | 335/532 [11:00<06:14,  1.90s/it]predicting train subjects:  63%|██████▎   | 336/532 [11:02<06:18,  1.93s/it]predicting train subjects:  63%|██████▎   | 337/532 [11:04<06:23,  1.97s/it]predicting train subjects:  64%|██████▎   | 338/532 [11:07<06:30,  2.01s/it]predicting train subjects:  64%|██████▎   | 339/532 [11:09<06:28,  2.02s/it]predicting train subjects:  64%|██████▍   | 340/532 [11:11<06:27,  2.02s/it]predicting train subjects:  64%|██████▍   | 341/532 [11:12<06:01,  1.89s/it]predicting train subjects:  64%|██████▍   | 342/532 [11:14<05:42,  1.80s/it]predicting train subjects:  64%|██████▍   | 343/532 [11:15<05:33,  1.76s/it]predicting train subjects:  65%|██████▍   | 344/532 [11:17<05:14,  1.67s/it]predicting train subjects:  65%|██████▍   | 345/532 [11:19<05:08,  1.65s/it]predicting train subjects:  65%|██████▌   | 346/532 [11:20<05:02,  1.63s/it]predicting train subjects:  65%|██████▌   | 347/532 [11:22<05:08,  1.67s/it]predicting train subjects:  65%|██████▌   | 348/532 [11:24<05:14,  1.71s/it]predicting train subjects:  66%|██████▌   | 349/532 [11:25<05:13,  1.71s/it]predicting train subjects:  66%|██████▌   | 350/532 [11:27<05:16,  1.74s/it]predicting train subjects:  66%|██████▌   | 351/532 [11:29<05:20,  1.77s/it]predicting train subjects:  66%|██████▌   | 352/532 [11:31<05:22,  1.79s/it]predicting train subjects:  66%|██████▋   | 353/532 [11:33<05:18,  1.78s/it]predicting train subjects:  67%|██████▋   | 354/532 [11:34<05:11,  1.75s/it]predicting train subjects:  67%|██████▋   | 355/532 [11:36<05:11,  1.76s/it]predicting train subjects:  67%|██████▋   | 356/532 [11:38<05:08,  1.75s/it]predicting train subjects:  67%|██████▋   | 357/532 [11:40<05:12,  1.78s/it]predicting train subjects:  67%|██████▋   | 358/532 [11:41<05:06,  1.76s/it]predicting train subjects:  67%|██████▋   | 359/532 [11:43<04:56,  1.71s/it]predicting train subjects:  68%|██████▊   | 360/532 [11:45<04:49,  1.68s/it]predicting train subjects:  68%|██████▊   | 361/532 [11:46<04:40,  1.64s/it]predicting train subjects:  68%|██████▊   | 362/532 [11:48<04:33,  1.61s/it]predicting train subjects:  68%|██████▊   | 363/532 [11:49<04:29,  1.59s/it]predicting train subjects:  68%|██████▊   | 364/532 [11:51<04:29,  1.61s/it]predicting train subjects:  69%|██████▊   | 365/532 [11:52<04:26,  1.60s/it]predicting train subjects:  69%|██████▉   | 366/532 [11:54<04:21,  1.58s/it]predicting train subjects:  69%|██████▉   | 367/532 [11:56<04:20,  1.58s/it]predicting train subjects:  69%|██████▉   | 368/532 [11:57<04:17,  1.57s/it]predicting train subjects:  69%|██████▉   | 369/532 [11:59<04:15,  1.57s/it]predicting train subjects:  70%|██████▉   | 370/532 [12:00<04:15,  1.58s/it]predicting train subjects:  70%|██████▉   | 371/532 [12:02<04:45,  1.77s/it]predicting train subjects:  70%|██████▉   | 372/532 [12:05<05:01,  1.88s/it]predicting train subjects:  70%|███████   | 373/532 [12:07<05:11,  1.96s/it]predicting train subjects:  70%|███████   | 374/532 [12:09<05:17,  2.01s/it]predicting train subjects:  70%|███████   | 375/532 [12:11<05:20,  2.04s/it]predicting train subjects:  71%|███████   | 376/532 [12:13<05:30,  2.12s/it]predicting train subjects:  71%|███████   | 377/532 [12:15<05:15,  2.03s/it]predicting train subjects:  71%|███████   | 378/532 [12:17<05:10,  2.01s/it]predicting train subjects:  71%|███████   | 379/532 [12:19<05:02,  1.98s/it]predicting train subjects:  71%|███████▏  | 380/532 [12:21<04:56,  1.95s/it]predicting train subjects:  72%|███████▏  | 381/532 [12:23<04:54,  1.95s/it]predicting train subjects:  72%|███████▏  | 382/532 [12:25<04:49,  1.93s/it]predicting train subjects:  72%|███████▏  | 383/532 [12:27<04:53,  1.97s/it]predicting train subjects:  72%|███████▏  | 384/532 [12:29<04:46,  1.94s/it]predicting train subjects:  72%|███████▏  | 385/532 [12:31<04:47,  1.96s/it]predicting train subjects:  73%|███████▎  | 386/532 [12:33<04:44,  1.95s/it]predicting train subjects:  73%|███████▎  | 387/532 [12:35<04:47,  1.98s/it]predicting train subjects:  73%|███████▎  | 388/532 [12:36<04:40,  1.95s/it]predicting train subjects:  73%|███████▎  | 389/532 [12:39<04:44,  1.99s/it]predicting train subjects:  73%|███████▎  | 390/532 [12:41<04:44,  2.00s/it]predicting train subjects:  73%|███████▎  | 391/532 [12:43<04:48,  2.05s/it]predicting train subjects:  74%|███████▎  | 392/532 [12:45<04:45,  2.04s/it]predicting train subjects:  74%|███████▍  | 393/532 [12:47<04:46,  2.06s/it]predicting train subjects:  74%|███████▍  | 394/532 [12:49<04:48,  2.09s/it]predicting train subjects:  74%|███████▍  | 395/532 [12:51<04:52,  2.14s/it]predicting train subjects:  74%|███████▍  | 396/532 [12:53<04:46,  2.11s/it]predicting train subjects:  75%|███████▍  | 397/532 [12:56<04:50,  2.15s/it]predicting train subjects:  75%|███████▍  | 398/532 [12:58<04:44,  2.13s/it]predicting train subjects:  75%|███████▌  | 399/532 [13:00<04:44,  2.14s/it]predicting train subjects:  75%|███████▌  | 400/532 [13:02<04:35,  2.08s/it]predicting train subjects:  75%|███████▌  | 401/532 [13:04<04:34,  2.10s/it]predicting train subjects:  76%|███████▌  | 402/532 [13:06<04:39,  2.15s/it]predicting train subjects:  76%|███████▌  | 403/532 [13:08<04:36,  2.14s/it]predicting train subjects:  76%|███████▌  | 404/532 [13:10<04:34,  2.14s/it]predicting train subjects:  76%|███████▌  | 405/532 [13:13<04:38,  2.19s/it]predicting train subjects:  76%|███████▋  | 406/532 [13:15<04:32,  2.16s/it]predicting train subjects:  77%|███████▋  | 407/532 [13:17<04:19,  2.08s/it]predicting train subjects:  77%|███████▋  | 408/532 [13:19<04:10,  2.02s/it]predicting train subjects:  77%|███████▋  | 409/532 [13:20<04:02,  1.97s/it]predicting train subjects:  77%|███████▋  | 410/532 [13:22<03:58,  1.95s/it]predicting train subjects:  77%|███████▋  | 411/532 [13:24<03:51,  1.91s/it]predicting train subjects:  77%|███████▋  | 412/532 [13:26<03:49,  1.91s/it]predicting train subjects:  78%|███████▊  | 413/532 [13:28<03:40,  1.85s/it]predicting train subjects:  78%|███████▊  | 414/532 [13:30<03:35,  1.83s/it]predicting train subjects:  78%|███████▊  | 415/532 [13:31<03:34,  1.83s/it]predicting train subjects:  78%|███████▊  | 416/532 [13:33<03:31,  1.82s/it]predicting train subjects:  78%|███████▊  | 417/532 [13:35<03:30,  1.83s/it]predicting train subjects:  79%|███████▊  | 418/532 [13:37<03:28,  1.83s/it]predicting train subjects:  79%|███████▉  | 419/532 [13:39<03:36,  1.91s/it]predicting train subjects:  79%|███████▉  | 420/532 [13:41<03:36,  1.93s/it]predicting train subjects:  79%|███████▉  | 421/532 [13:43<03:39,  1.98s/it]predicting train subjects:  79%|███████▉  | 422/532 [13:45<03:45,  2.05s/it]predicting train subjects:  80%|███████▉  | 423/532 [13:47<03:41,  2.03s/it]predicting train subjects:  80%|███████▉  | 424/532 [13:49<03:40,  2.04s/it]predicting train subjects:  80%|███████▉  | 425/532 [13:52<03:46,  2.12s/it]predicting train subjects:  80%|████████  | 426/532 [13:54<03:47,  2.14s/it]predicting train subjects:  80%|████████  | 427/532 [13:56<03:47,  2.17s/it]predicting train subjects:  80%|████████  | 428/532 [13:58<03:40,  2.12s/it]predicting train subjects:  81%|████████  | 429/532 [14:00<03:42,  2.16s/it]predicting train subjects:  81%|████████  | 430/532 [14:03<03:47,  2.24s/it]predicting train subjects:  81%|████████  | 431/532 [14:06<04:12,  2.50s/it]predicting train subjects:  81%|████████  | 432/532 [14:09<04:17,  2.58s/it]predicting train subjects:  81%|████████▏ | 433/532 [14:12<04:26,  2.69s/it]predicting train subjects:  82%|████████▏ | 434/532 [14:15<04:33,  2.80s/it]predicting train subjects:  82%|████████▏ | 435/532 [14:17<04:28,  2.77s/it]predicting train subjects:  82%|████████▏ | 436/532 [14:20<04:29,  2.81s/it]predicting train subjects:  82%|████████▏ | 437/532 [14:22<04:04,  2.57s/it]predicting train subjects:  82%|████████▏ | 438/532 [14:25<03:55,  2.50s/it]predicting train subjects:  83%|████████▎ | 439/532 [14:27<03:38,  2.34s/it]predicting train subjects:  83%|████████▎ | 440/532 [14:29<03:27,  2.26s/it]predicting train subjects:  83%|████████▎ | 441/532 [14:31<03:19,  2.19s/it]predicting train subjects:  83%|████████▎ | 442/532 [14:33<03:09,  2.11s/it]predicting train subjects:  83%|████████▎ | 443/532 [14:35<03:09,  2.12s/it]predicting train subjects:  83%|████████▎ | 444/532 [14:37<03:06,  2.12s/it]predicting train subjects:  84%|████████▎ | 445/532 [14:39<02:57,  2.04s/it]predicting train subjects:  84%|████████▍ | 446/532 [14:41<02:55,  2.04s/it]predicting train subjects:  84%|████████▍ | 447/532 [14:43<02:53,  2.04s/it]predicting train subjects:  84%|████████▍ | 448/532 [14:45<02:49,  2.01s/it]predicting train subjects:  84%|████████▍ | 449/532 [14:47<02:59,  2.16s/it]predicting train subjects:  85%|████████▍ | 450/532 [14:50<03:02,  2.23s/it]predicting train subjects:  85%|████████▍ | 451/532 [14:52<03:04,  2.28s/it]predicting train subjects:  85%|████████▍ | 452/532 [14:54<03:01,  2.26s/it]predicting train subjects:  85%|████████▌ | 453/532 [14:56<02:57,  2.25s/it]predicting train subjects:  85%|████████▌ | 454/532 [14:59<02:57,  2.28s/it]predicting train subjects:  86%|████████▌ | 455/532 [15:02<03:11,  2.48s/it]predicting train subjects:  86%|████████▌ | 456/532 [15:05<03:19,  2.63s/it]predicting train subjects:  86%|████████▌ | 457/532 [15:07<03:11,  2.55s/it]predicting train subjects:  86%|████████▌ | 458/532 [15:10<03:06,  2.51s/it]predicting train subjects:  86%|████████▋ | 459/532 [15:12<03:07,  2.57s/it]predicting train subjects:  86%|████████▋ | 460/532 [15:15<03:01,  2.52s/it]predicting train subjects:  87%|████████▋ | 461/532 [15:18<03:10,  2.69s/it]predicting train subjects:  87%|████████▋ | 462/532 [15:21<03:19,  2.85s/it]predicting train subjects:  87%|████████▋ | 463/532 [15:24<03:16,  2.85s/it]predicting train subjects:  87%|████████▋ | 464/532 [15:27<03:17,  2.90s/it]predicting train subjects:  87%|████████▋ | 465/532 [15:30<03:23,  3.03s/it]predicting train subjects:  88%|████████▊ | 466/532 [15:33<03:22,  3.07s/it]predicting train subjects:  88%|████████▊ | 467/532 [15:36<03:14,  2.99s/it]predicting train subjects:  88%|████████▊ | 468/532 [15:39<03:03,  2.87s/it]predicting train subjects:  88%|████████▊ | 469/532 [15:41<02:56,  2.80s/it]predicting train subjects:  88%|████████▊ | 470/532 [15:44<02:47,  2.71s/it]predicting train subjects:  89%|████████▊ | 471/532 [15:46<02:38,  2.60s/it]predicting train subjects:  89%|████████▊ | 472/532 [15:49<02:36,  2.62s/it]predicting train subjects:  89%|████████▉ | 473/532 [15:52<02:41,  2.73s/it]predicting train subjects:  89%|████████▉ | 474/532 [15:54<02:34,  2.66s/it]predicting train subjects:  89%|████████▉ | 475/532 [15:57<02:24,  2.54s/it]predicting train subjects:  89%|████████▉ | 476/532 [15:59<02:21,  2.52s/it]predicting train subjects:  90%|████████▉ | 477/532 [16:02<02:23,  2.62s/it]predicting train subjects:  90%|████████▉ | 478/532 [16:05<02:22,  2.63s/it]predicting train subjects:  90%|█████████ | 479/532 [16:07<02:11,  2.49s/it]predicting train subjects:  90%|█████████ | 480/532 [16:09<02:05,  2.41s/it]predicting train subjects:  90%|█████████ | 481/532 [16:11<02:00,  2.37s/it]predicting train subjects:  91%|█████████ | 482/532 [16:13<01:56,  2.33s/it]predicting train subjects:  91%|█████████ | 483/532 [16:16<01:56,  2.37s/it]predicting train subjects:  91%|█████████ | 484/532 [16:18<01:53,  2.36s/it]predicting train subjects:  91%|█████████ | 485/532 [16:21<01:58,  2.53s/it]predicting train subjects:  91%|█████████▏| 486/532 [16:24<02:00,  2.62s/it]predicting train subjects:  92%|█████████▏| 487/532 [16:27<01:57,  2.62s/it]predicting train subjects:  92%|█████████▏| 488/532 [16:29<01:55,  2.63s/it]predicting train subjects:  92%|█████████▏| 489/532 [16:32<02:00,  2.79s/it]predicting train subjects:  92%|█████████▏| 490/532 [16:35<01:59,  2.85s/it]predicting train subjects:  92%|█████████▏| 491/532 [16:38<01:50,  2.71s/it]predicting train subjects:  92%|█████████▏| 492/532 [16:40<01:45,  2.64s/it]predicting train subjects:  93%|█████████▎| 493/532 [16:43<01:38,  2.52s/it]predicting train subjects:  93%|█████████▎| 494/532 [16:45<01:32,  2.43s/it]predicting train subjects:  93%|█████████▎| 495/532 [16:47<01:28,  2.39s/it]predicting train subjects:  93%|█████████▎| 496/532 [16:49<01:25,  2.36s/it]predicting train subjects:  93%|█████████▎| 497/532 [16:52<01:23,  2.40s/it]predicting train subjects:  94%|█████████▎| 498/532 [16:54<01:21,  2.41s/it]predicting train subjects:  94%|█████████▍| 499/532 [16:57<01:19,  2.40s/it]predicting train subjects:  94%|█████████▍| 500/532 [16:59<01:17,  2.43s/it]predicting train subjects:  94%|█████████▍| 501/532 [17:01<01:14,  2.39s/it]predicting train subjects:  94%|█████████▍| 502/532 [17:04<01:13,  2.44s/it]predicting train subjects:  95%|█████████▍| 503/532 [17:06<01:10,  2.43s/it]predicting train subjects:  95%|█████████▍| 504/532 [17:09<01:07,  2.39s/it]predicting train subjects:  95%|█████████▍| 505/532 [17:12<01:08,  2.53s/it]predicting train subjects:  95%|█████████▌| 506/532 [17:14<01:06,  2.54s/it]predicting train subjects:  95%|█████████▌| 507/532 [17:16<01:00,  2.43s/it]predicting train subjects:  95%|█████████▌| 508/532 [17:19<00:57,  2.41s/it]predicting train subjects:  96%|█████████▌| 509/532 [17:21<00:57,  2.49s/it]predicting train subjects:  96%|█████████▌| 510/532 [17:25<00:59,  2.71s/it]predicting train subjects:  96%|█████████▌| 511/532 [17:28<00:59,  2.81s/it]predicting train subjects:  96%|█████████▌| 512/532 [17:31<00:57,  2.89s/it]predicting train subjects:  96%|█████████▋| 513/532 [17:33<00:52,  2.78s/it]predicting train subjects:  97%|█████████▋| 514/532 [17:36<00:50,  2.81s/it]predicting train subjects:  97%|█████████▋| 515/532 [17:38<00:44,  2.63s/it]predicting train subjects:  97%|█████████▋| 516/532 [17:41<00:40,  2.51s/it]predicting train subjects:  97%|█████████▋| 517/532 [17:43<00:36,  2.46s/it]predicting train subjects:  97%|█████████▋| 518/532 [17:45<00:34,  2.49s/it]predicting train subjects:  98%|█████████▊| 519/532 [17:48<00:31,  2.46s/it]predicting train subjects:  98%|█████████▊| 520/532 [17:50<00:29,  2.46s/it]predicting train subjects:  98%|█████████▊| 521/532 [17:53<00:27,  2.49s/it]predicting train subjects:  98%|█████████▊| 522/532 [17:55<00:24,  2.48s/it]predicting train subjects:  98%|█████████▊| 523/532 [17:58<00:22,  2.50s/it]predicting train subjects:  98%|█████████▊| 524/532 [18:00<00:20,  2.50s/it]predicting train subjects:  99%|█████████▊| 525/532 [18:03<00:17,  2.56s/it]predicting train subjects:  99%|█████████▉| 526/532 [18:06<00:15,  2.53s/it]predicting train subjects:  99%|█████████▉| 527/532 [18:09<00:13,  2.67s/it]predicting train subjects:  99%|█████████▉| 528/532 [18:11<00:10,  2.51s/it]predicting train subjects:  99%|█████████▉| 529/532 [18:13<00:07,  2.45s/it]predicting train subjects: 100%|█████████▉| 530/532 [18:15<00:04,  2.45s/it]predicting train subjects: 100%|█████████▉| 531/532 [18:18<00:02,  2.39s/it]predicting train subjects: 100%|██████████| 532/532 [18:20<00:00,  2.31s/it]
Loading train:   0%|          | 0/532 [00:00<?, ?it/s]Loading train:   0%|          | 1/532 [00:02<25:20,  2.86s/it]Loading train:   0%|          | 2/532 [00:05<23:42,  2.68s/it]Loading train:   1%|          | 3/532 [00:07<22:48,  2.59s/it]Loading train:   1%|          | 4/532 [00:10<22:50,  2.60s/it]Loading train:   1%|          | 5/532 [00:12<22:04,  2.51s/it]Loading train:   1%|          | 6/532 [00:14<21:14,  2.42s/it]Loading train:   1%|▏         | 7/532 [00:16<18:57,  2.17s/it]Loading train:   2%|▏         | 8/532 [00:18<18:40,  2.14s/it]Loading train:   2%|▏         | 9/532 [00:20<19:48,  2.27s/it]Loading train:   2%|▏         | 10/532 [00:22<19:23,  2.23s/it]Loading train:   2%|▏         | 11/532 [00:25<18:49,  2.17s/it]Loading train:   2%|▏         | 12/532 [00:27<19:38,  2.27s/it]Loading train:   2%|▏         | 13/532 [00:29<18:17,  2.12s/it]Loading train:   3%|▎         | 14/532 [00:31<18:20,  2.13s/it]Loading train:   3%|▎         | 15/532 [00:33<18:25,  2.14s/it]Loading train:   3%|▎         | 16/532 [00:35<17:59,  2.09s/it]Loading train:   3%|▎         | 17/532 [00:37<17:57,  2.09s/it]Loading train:   3%|▎         | 18/532 [00:39<18:18,  2.14s/it]Loading train:   4%|▎         | 19/532 [00:41<17:40,  2.07s/it]Loading train:   4%|▍         | 20/532 [00:43<16:20,  1.91s/it]Loading train:   4%|▍         | 21/532 [00:45<17:00,  2.00s/it]Loading train:   4%|▍         | 22/532 [00:47<17:15,  2.03s/it]Loading train:   4%|▍         | 23/532 [00:49<17:44,  2.09s/it]Loading train:   5%|▍         | 24/532 [00:52<18:52,  2.23s/it]Loading train:   5%|▍         | 25/532 [00:54<19:34,  2.32s/it]Loading train:   5%|▍         | 26/532 [00:56<18:20,  2.18s/it]Loading train:   5%|▌         | 27/532 [00:59<18:55,  2.25s/it]Loading train:   5%|▌         | 28/532 [01:01<18:36,  2.21s/it]Loading train:   5%|▌         | 29/532 [01:03<17:51,  2.13s/it]Loading train:   6%|▌         | 30/532 [01:05<16:44,  2.00s/it]Loading train:   6%|▌         | 31/532 [01:06<16:34,  1.98s/it]Loading train:   6%|▌         | 32/532 [01:08<16:12,  1.95s/it]Loading train:   6%|▌         | 33/532 [01:10<16:25,  1.97s/it]Loading train:   6%|▋         | 34/532 [01:13<17:28,  2.11s/it]Loading train:   7%|▋         | 35/532 [01:15<16:33,  2.00s/it]Loading train:   7%|▋         | 36/532 [01:16<16:25,  1.99s/it]Loading train:   7%|▋         | 37/532 [01:19<17:57,  2.18s/it]Loading train:   7%|▋         | 38/532 [01:21<18:04,  2.20s/it]Loading train:   7%|▋         | 39/532 [01:23<17:09,  2.09s/it]Loading train:   8%|▊         | 40/532 [01:25<16:58,  2.07s/it]Loading train:   8%|▊         | 41/532 [01:28<18:00,  2.20s/it]Loading train:   8%|▊         | 42/532 [01:30<18:18,  2.24s/it]Loading train:   8%|▊         | 43/532 [01:33<19:26,  2.38s/it]Loading train:   8%|▊         | 44/532 [01:35<18:31,  2.28s/it]Loading train:   8%|▊         | 45/532 [01:37<18:02,  2.22s/it]Loading train:   9%|▊         | 46/532 [01:39<18:18,  2.26s/it]Loading train:   9%|▉         | 47/532 [01:42<18:50,  2.33s/it]Loading train:   9%|▉         | 48/532 [01:43<17:27,  2.16s/it]Loading train:   9%|▉         | 49/532 [01:45<16:07,  2.00s/it]Loading train:   9%|▉         | 50/532 [01:47<16:34,  2.06s/it]Loading train:  10%|▉         | 51/532 [01:50<17:05,  2.13s/it]Loading train:  10%|▉         | 52/532 [01:52<17:38,  2.21s/it]Loading train:  10%|▉         | 53/532 [01:54<17:52,  2.24s/it]Loading train:  10%|█         | 54/532 [01:57<17:45,  2.23s/it]Loading train:  10%|█         | 55/532 [01:59<18:54,  2.38s/it]Loading train:  11%|█         | 56/532 [02:01<17:57,  2.26s/it]Loading train:  11%|█         | 57/532 [02:03<16:56,  2.14s/it]Loading train:  11%|█         | 58/532 [02:05<16:51,  2.13s/it]Loading train:  11%|█         | 59/532 [02:08<19:15,  2.44s/it]Loading train:  11%|█▏        | 60/532 [02:11<20:29,  2.61s/it]Loading train:  11%|█▏        | 61/532 [02:14<20:56,  2.67s/it]Loading train:  12%|█▏        | 62/532 [02:16<17:56,  2.29s/it]Loading train:  12%|█▏        | 63/532 [02:17<16:09,  2.07s/it]Loading train:  12%|█▏        | 64/532 [02:18<14:27,  1.85s/it]Loading train:  12%|█▏        | 65/532 [02:21<15:02,  1.93s/it]Loading train:  12%|█▏        | 66/532 [02:23<16:31,  2.13s/it]Loading train:  13%|█▎        | 67/532 [02:25<16:15,  2.10s/it]Loading train:  13%|█▎        | 68/532 [02:27<14:48,  1.91s/it]Loading train:  13%|█▎        | 69/532 [02:28<13:31,  1.75s/it]Loading train:  13%|█▎        | 70/532 [02:29<12:16,  1.59s/it]Loading train:  13%|█▎        | 71/532 [02:31<11:30,  1.50s/it]Loading train:  14%|█▎        | 72/532 [02:32<11:21,  1.48s/it]Loading train:  14%|█▎        | 73/532 [02:33<11:11,  1.46s/it]Loading train:  14%|█▍        | 74/532 [02:35<11:33,  1.51s/it]Loading train:  14%|█▍        | 75/532 [02:37<12:30,  1.64s/it]Loading train:  14%|█▍        | 76/532 [02:38<11:47,  1.55s/it]Loading train:  14%|█▍        | 77/532 [02:40<11:38,  1.54s/it]Loading train:  15%|█▍        | 78/532 [02:41<11:15,  1.49s/it]Loading train:  15%|█▍        | 79/532 [02:43<11:03,  1.47s/it]Loading train:  15%|█▌        | 80/532 [02:44<10:57,  1.45s/it]Loading train:  15%|█▌        | 81/532 [02:46<10:58,  1.46s/it]Loading train:  15%|█▌        | 82/532 [02:47<10:44,  1.43s/it]Loading train:  16%|█▌        | 83/532 [02:48<10:51,  1.45s/it]Loading train:  16%|█▌        | 84/532 [02:50<10:25,  1.40s/it]Loading train:  16%|█▌        | 85/532 [02:51<10:10,  1.36s/it]Loading train:  16%|█▌        | 86/532 [02:52<10:06,  1.36s/it]Loading train:  16%|█▋        | 87/532 [02:53<09:32,  1.29s/it]Loading train:  17%|█▋        | 88/532 [02:55<09:42,  1.31s/it]Loading train:  17%|█▋        | 89/532 [02:56<09:55,  1.34s/it]Loading train:  17%|█▋        | 90/532 [02:57<09:40,  1.31s/it]Loading train:  17%|█▋        | 91/532 [02:59<09:45,  1.33s/it]Loading train:  17%|█▋        | 92/532 [03:00<09:57,  1.36s/it]Loading train:  17%|█▋        | 93/532 [03:02<10:00,  1.37s/it]Loading train:  18%|█▊        | 94/532 [03:03<10:03,  1.38s/it]Loading train:  18%|█▊        | 95/532 [03:05<10:46,  1.48s/it]Loading train:  18%|█▊        | 96/532 [03:06<11:01,  1.52s/it]Loading train:  18%|█▊        | 97/532 [03:08<11:01,  1.52s/it]Loading train:  18%|█▊        | 98/532 [03:09<10:31,  1.45s/it]Loading train:  19%|█▊        | 99/532 [03:11<11:03,  1.53s/it]Loading train:  19%|█▉        | 100/532 [03:12<10:48,  1.50s/it]Loading train:  19%|█▉        | 101/532 [03:14<10:25,  1.45s/it]Loading train:  19%|█▉        | 102/532 [03:15<09:42,  1.35s/it]Loading train:  19%|█▉        | 103/532 [03:16<09:17,  1.30s/it]Loading train:  20%|█▉        | 104/532 [03:17<08:54,  1.25s/it]Loading train:  20%|█▉        | 105/532 [03:18<08:51,  1.24s/it]Loading train:  20%|█▉        | 106/532 [03:20<09:02,  1.27s/it]Loading train:  20%|██        | 107/532 [03:21<09:24,  1.33s/it]Loading train:  20%|██        | 108/532 [03:22<09:20,  1.32s/it]Loading train:  20%|██        | 109/532 [03:24<09:19,  1.32s/it]Loading train:  21%|██        | 110/532 [03:25<08:55,  1.27s/it]Loading train:  21%|██        | 111/532 [03:26<08:54,  1.27s/it]Loading train:  21%|██        | 112/532 [03:27<08:54,  1.27s/it]Loading train:  21%|██        | 113/532 [03:29<09:32,  1.37s/it]Loading train:  21%|██▏       | 114/532 [03:30<09:27,  1.36s/it]Loading train:  22%|██▏       | 115/532 [03:32<09:44,  1.40s/it]Loading train:  22%|██▏       | 116/532 [03:33<09:51,  1.42s/it]Loading train:  22%|██▏       | 117/532 [03:35<09:38,  1.39s/it]Loading train:  22%|██▏       | 118/532 [03:36<09:40,  1.40s/it]Loading train:  22%|██▏       | 119/532 [03:38<09:45,  1.42s/it]Loading train:  23%|██▎       | 120/532 [03:39<09:55,  1.45s/it]Loading train:  23%|██▎       | 121/532 [03:40<09:24,  1.37s/it]Loading train:  23%|██▎       | 122/532 [03:42<09:15,  1.35s/it]Loading train:  23%|██▎       | 123/532 [03:43<09:08,  1.34s/it]Loading train:  23%|██▎       | 124/532 [03:44<09:15,  1.36s/it]Loading train:  23%|██▎       | 125/532 [03:46<09:34,  1.41s/it]Loading train:  24%|██▎       | 126/532 [03:47<09:54,  1.46s/it]Loading train:  24%|██▍       | 127/532 [03:49<09:54,  1.47s/it]Loading train:  24%|██▍       | 128/532 [03:50<09:49,  1.46s/it]Loading train:  24%|██▍       | 129/532 [03:52<10:20,  1.54s/it]Loading train:  24%|██▍       | 130/532 [03:54<10:22,  1.55s/it]Loading train:  25%|██▍       | 131/532 [03:56<11:03,  1.66s/it]Loading train:  25%|██▍       | 132/532 [03:57<11:02,  1.66s/it]Loading train:  25%|██▌       | 133/532 [03:58<10:11,  1.53s/it]Loading train:  25%|██▌       | 134/532 [04:00<09:48,  1.48s/it]Loading train:  25%|██▌       | 135/532 [04:01<09:36,  1.45s/it]Loading train:  26%|██▌       | 136/532 [04:03<10:04,  1.53s/it]Loading train:  26%|██▌       | 137/532 [04:04<10:11,  1.55s/it]Loading train:  26%|██▌       | 138/532 [04:06<10:27,  1.59s/it]Loading train:  26%|██▌       | 139/532 [04:08<10:43,  1.64s/it]Loading train:  26%|██▋       | 140/532 [04:10<10:36,  1.62s/it]Loading train:  27%|██▋       | 141/532 [04:11<10:17,  1.58s/it]Loading train:  27%|██▋       | 142/532 [04:12<09:51,  1.52s/it]Loading train:  27%|██▋       | 143/532 [04:13<08:53,  1.37s/it]Loading train:  27%|██▋       | 144/532 [04:15<08:25,  1.30s/it]Loading train:  27%|██▋       | 145/532 [04:16<07:48,  1.21s/it]Loading train:  27%|██▋       | 146/532 [04:17<07:31,  1.17s/it]Loading train:  28%|██▊       | 147/532 [04:18<07:12,  1.12s/it]Loading train:  28%|██▊       | 148/532 [04:19<07:09,  1.12s/it]Loading train:  28%|██▊       | 149/532 [04:20<07:03,  1.11s/it]Loading train:  28%|██▊       | 150/532 [04:21<07:01,  1.10s/it]Loading train:  28%|██▊       | 151/532 [04:22<06:45,  1.06s/it]Loading train:  29%|██▊       | 152/532 [04:23<06:45,  1.07s/it]Loading train:  29%|██▉       | 153/532 [04:24<06:40,  1.06s/it]Loading train:  29%|██▉       | 154/532 [04:25<06:35,  1.05s/it]Loading train:  29%|██▉       | 155/532 [04:26<07:07,  1.13s/it]Loading train:  29%|██▉       | 156/532 [04:28<07:33,  1.21s/it]Loading train:  30%|██▉       | 157/532 [04:29<07:41,  1.23s/it]Loading train:  30%|██▉       | 158/532 [04:30<07:51,  1.26s/it]Loading train:  30%|██▉       | 159/532 [04:32<07:57,  1.28s/it]Loading train:  30%|███       | 160/532 [04:33<07:57,  1.28s/it]Loading train:  30%|███       | 161/532 [04:34<07:42,  1.25s/it]Loading train:  30%|███       | 162/532 [04:35<07:18,  1.18s/it]Loading train:  31%|███       | 163/532 [04:36<07:07,  1.16s/it]Loading train:  31%|███       | 164/532 [04:37<06:55,  1.13s/it]Loading train:  31%|███       | 165/532 [04:38<06:38,  1.09s/it]Loading train:  31%|███       | 166/532 [04:39<06:33,  1.07s/it]Loading train:  31%|███▏      | 167/532 [04:40<06:24,  1.05s/it]Loading train:  32%|███▏      | 168/532 [04:41<06:24,  1.06s/it]Loading train:  32%|███▏      | 169/532 [04:42<06:20,  1.05s/it]Loading train:  32%|███▏      | 170/532 [04:44<06:22,  1.06s/it]Loading train:  32%|███▏      | 171/532 [04:45<06:15,  1.04s/it]Loading train:  32%|███▏      | 172/532 [04:46<06:23,  1.07s/it]Loading train:  33%|███▎      | 173/532 [04:47<06:10,  1.03s/it]Loading train:  33%|███▎      | 174/532 [04:48<06:04,  1.02s/it]Loading train:  33%|███▎      | 175/532 [04:49<06:05,  1.02s/it]Loading train:  33%|███▎      | 176/532 [04:50<05:51,  1.01it/s]Loading train:  33%|███▎      | 177/532 [04:50<05:48,  1.02it/s]Loading train:  33%|███▎      | 178/532 [04:51<05:46,  1.02it/s]Loading train:  34%|███▎      | 179/532 [04:52<05:47,  1.02it/s]Loading train:  34%|███▍      | 180/532 [04:54<05:52,  1.00s/it]Loading train:  34%|███▍      | 181/532 [04:54<05:41,  1.03it/s]Loading train:  34%|███▍      | 182/532 [04:56<05:52,  1.01s/it]Loading train:  34%|███▍      | 183/532 [04:56<05:42,  1.02it/s]Loading train:  35%|███▍      | 184/532 [04:57<05:51,  1.01s/it]Loading train:  35%|███▍      | 185/532 [04:59<05:55,  1.02s/it]Loading train:  35%|███▍      | 186/532 [04:59<05:46,  1.00s/it]Loading train:  35%|███▌      | 187/532 [05:00<05:37,  1.02it/s]Loading train:  35%|███▌      | 188/532 [05:01<05:35,  1.02it/s]Loading train:  36%|███▌      | 189/532 [05:03<05:55,  1.04s/it]Loading train:  36%|███▌      | 190/532 [05:04<05:43,  1.00s/it]Loading train:  36%|███▌      | 191/532 [05:05<06:30,  1.14s/it]Loading train:  36%|███▌      | 192/532 [05:06<06:53,  1.22s/it]Loading train:  36%|███▋      | 193/532 [05:08<07:07,  1.26s/it]Loading train:  36%|███▋      | 194/532 [05:09<07:13,  1.28s/it]Loading train:  37%|███▋      | 195/532 [05:10<07:05,  1.26s/it]Loading train:  37%|███▋      | 196/532 [05:12<07:14,  1.29s/it]Loading train:  37%|███▋      | 197/532 [05:13<06:59,  1.25s/it]Loading train:  37%|███▋      | 198/532 [05:14<06:59,  1.26s/it]Loading train:  37%|███▋      | 199/532 [05:15<06:58,  1.26s/it]Loading train:  38%|███▊      | 200/532 [05:16<06:47,  1.23s/it]Loading train:  38%|███▊      | 201/532 [05:18<06:32,  1.18s/it]Loading train:  38%|███▊      | 202/532 [05:19<06:26,  1.17s/it]Loading train:  38%|███▊      | 203/532 [05:20<06:12,  1.13s/it]Loading train:  38%|███▊      | 204/532 [05:21<06:04,  1.11s/it]Loading train:  39%|███▊      | 205/532 [05:22<05:44,  1.05s/it]Loading train:  39%|███▊      | 206/532 [05:23<05:28,  1.01s/it]Loading train:  39%|███▉      | 207/532 [05:24<05:24,  1.00it/s]Loading train:  39%|███▉      | 208/532 [05:25<05:25,  1.00s/it]Loading train:  39%|███▉      | 209/532 [05:26<05:13,  1.03it/s]Loading train:  39%|███▉      | 210/532 [05:27<05:22,  1.00s/it]Loading train:  40%|███▉      | 211/532 [05:28<05:16,  1.01it/s]Loading train:  40%|███▉      | 212/532 [05:28<05:11,  1.03it/s]Loading train:  40%|████      | 213/532 [05:29<05:06,  1.04it/s]Loading train:  40%|████      | 214/532 [05:30<05:00,  1.06it/s]Loading train:  40%|████      | 215/532 [05:32<05:28,  1.04s/it]Loading train:  41%|████      | 216/532 [05:33<05:42,  1.08s/it]Loading train:  41%|████      | 217/532 [05:34<06:09,  1.17s/it]Loading train:  41%|████      | 218/532 [05:35<06:13,  1.19s/it]Loading train:  41%|████      | 219/532 [05:37<06:15,  1.20s/it]Loading train:  41%|████▏     | 220/532 [05:38<06:24,  1.23s/it]Loading train:  42%|████▏     | 221/532 [05:39<05:59,  1.15s/it]Loading train:  42%|████▏     | 222/532 [05:40<05:40,  1.10s/it]Loading train:  42%|████▏     | 223/532 [05:41<05:34,  1.08s/it]Loading train:  42%|████▏     | 224/532 [05:42<05:11,  1.01s/it]Loading train:  42%|████▏     | 225/532 [05:43<05:00,  1.02it/s]Loading train:  42%|████▏     | 226/532 [05:44<04:54,  1.04it/s]Loading train:  43%|████▎     | 227/532 [05:45<04:52,  1.04it/s]Loading train:  43%|████▎     | 228/532 [05:45<04:50,  1.05it/s]Loading train:  43%|████▎     | 229/532 [05:46<04:54,  1.03it/s]Loading train:  43%|████▎     | 230/532 [05:47<04:45,  1.06it/s]Loading train:  43%|████▎     | 231/532 [05:48<04:54,  1.02it/s]Loading train:  44%|████▎     | 232/532 [05:49<04:44,  1.05it/s]Loading train:  44%|████▍     | 233/532 [05:50<05:05,  1.02s/it]Loading train:  44%|████▍     | 234/532 [05:51<04:57,  1.00it/s]Loading train:  44%|████▍     | 235/532 [05:52<04:59,  1.01s/it]Loading train:  44%|████▍     | 236/532 [05:53<04:56,  1.00s/it]Loading train:  45%|████▍     | 237/532 [05:55<05:02,  1.02s/it]Loading train:  45%|████▍     | 238/532 [05:56<04:58,  1.01s/it]Loading train:  45%|████▍     | 239/532 [05:57<05:07,  1.05s/it]Loading train:  45%|████▌     | 240/532 [05:58<05:05,  1.05s/it]Loading train:  45%|████▌     | 241/532 [05:59<05:02,  1.04s/it]Loading train:  45%|████▌     | 242/532 [06:00<04:58,  1.03s/it]Loading train:  46%|████▌     | 243/532 [06:01<05:00,  1.04s/it]Loading train:  46%|████▌     | 244/532 [06:02<04:58,  1.04s/it]Loading train:  46%|████▌     | 245/532 [06:03<04:46,  1.00it/s]Loading train:  46%|████▌     | 246/532 [06:04<04:43,  1.01it/s]Loading train:  46%|████▋     | 247/532 [06:05<04:49,  1.02s/it]Loading train:  47%|████▋     | 248/532 [06:06<04:37,  1.02it/s]Loading train:  47%|████▋     | 249/532 [06:07<04:38,  1.01it/s]Loading train:  47%|████▋     | 250/532 [06:07<04:25,  1.06it/s]Loading train:  47%|████▋     | 251/532 [06:09<04:32,  1.03it/s]Loading train:  47%|████▋     | 252/532 [06:09<04:30,  1.04it/s]Loading train:  48%|████▊     | 253/532 [06:10<04:26,  1.05it/s]Loading train:  48%|████▊     | 254/532 [06:11<04:27,  1.04it/s]Loading train:  48%|████▊     | 255/532 [06:12<04:27,  1.04it/s]Loading train:  48%|████▊     | 256/532 [06:13<04:37,  1.01s/it]Loading train:  48%|████▊     | 257/532 [06:15<04:53,  1.07s/it]Loading train:  48%|████▊     | 258/532 [06:16<05:03,  1.11s/it]Loading train:  49%|████▊     | 259/532 [06:17<05:04,  1.12s/it]Loading train:  49%|████▉     | 260/532 [06:18<05:05,  1.12s/it]Loading train:  49%|████▉     | 261/532 [06:19<05:10,  1.14s/it]Loading train:  49%|████▉     | 262/532 [06:20<05:06,  1.14s/it]Loading train:  49%|████▉     | 263/532 [06:21<04:43,  1.06s/it]Loading train:  50%|████▉     | 264/532 [06:22<04:29,  1.01s/it]Loading train:  50%|████▉     | 265/532 [06:23<04:15,  1.05it/s]Loading train:  50%|█████     | 266/532 [06:24<04:18,  1.03it/s]Loading train:  50%|█████     | 267/532 [06:25<04:05,  1.08it/s]Loading train:  50%|█████     | 268/532 [06:26<04:01,  1.09it/s]Loading train:  51%|█████     | 269/532 [06:27<04:09,  1.05it/s]Loading train:  51%|█████     | 270/532 [06:28<04:12,  1.04it/s]Loading train:  51%|█████     | 271/532 [06:29<04:15,  1.02it/s]Loading train:  51%|█████     | 272/532 [06:30<04:17,  1.01it/s]Loading train:  51%|█████▏    | 273/532 [06:31<04:18,  1.00it/s]Loading train:  52%|█████▏    | 274/532 [06:32<04:14,  1.02it/s]Loading train:  52%|█████▏    | 275/532 [06:33<04:36,  1.07s/it]Loading train:  52%|█████▏    | 276/532 [06:34<04:48,  1.13s/it]Loading train:  52%|█████▏    | 277/532 [06:36<04:52,  1.15s/it]Loading train:  52%|█████▏    | 278/532 [06:37<05:10,  1.22s/it]Loading train:  52%|█████▏    | 279/532 [06:38<05:11,  1.23s/it]Loading train:  53%|█████▎    | 280/532 [06:39<05:12,  1.24s/it]Loading train:  53%|█████▎    | 281/532 [06:41<05:16,  1.26s/it]Loading train:  53%|█████▎    | 282/532 [06:42<05:08,  1.24s/it]Loading train:  53%|█████▎    | 283/532 [06:43<05:14,  1.26s/it]Loading train:  53%|█████▎    | 284/532 [06:44<05:04,  1.23s/it]Loading train:  54%|█████▎    | 285/532 [06:46<05:00,  1.22s/it]Loading train:  54%|█████▍    | 286/532 [06:47<04:52,  1.19s/it]Loading train:  54%|█████▍    | 287/532 [06:48<04:33,  1.12s/it]Loading train:  54%|█████▍    | 288/532 [06:49<04:36,  1.13s/it]Loading train:  54%|█████▍    | 289/532 [06:50<04:31,  1.12s/it]Loading train:  55%|█████▍    | 290/532 [06:51<04:22,  1.08s/it]Loading train:  55%|█████▍    | 291/532 [06:52<04:20,  1.08s/it]Loading train:  55%|█████▍    | 292/532 [06:53<04:09,  1.04s/it]Loading train:  55%|█████▌    | 293/532 [06:54<04:09,  1.04s/it]Loading train:  55%|█████▌    | 294/532 [06:55<04:07,  1.04s/it]Loading train:  55%|█████▌    | 295/532 [06:56<04:01,  1.02s/it]Loading train:  56%|█████▌    | 296/532 [06:57<04:01,  1.02s/it]Loading train:  56%|█████▌    | 297/532 [06:58<04:02,  1.03s/it]Loading train:  56%|█████▌    | 298/532 [06:59<04:16,  1.10s/it]Loading train:  56%|█████▌    | 299/532 [07:00<04:13,  1.09s/it]Loading train:  56%|█████▋    | 300/532 [07:01<04:10,  1.08s/it]Loading train:  57%|█████▋    | 301/532 [07:03<04:09,  1.08s/it]Loading train:  57%|█████▋    | 302/532 [07:04<04:06,  1.07s/it]Loading train:  57%|█████▋    | 303/532 [07:05<03:59,  1.05s/it]Loading train:  57%|█████▋    | 304/532 [07:06<04:15,  1.12s/it]Loading train:  57%|█████▋    | 305/532 [07:07<04:33,  1.20s/it]Loading train:  58%|█████▊    | 306/532 [07:09<04:50,  1.29s/it]Loading train:  58%|█████▊    | 307/532 [07:10<04:56,  1.32s/it]Loading train:  58%|█████▊    | 308/532 [07:11<04:52,  1.31s/it]Loading train:  58%|█████▊    | 309/532 [07:13<04:47,  1.29s/it]Loading train:  58%|█████▊    | 310/532 [07:14<04:53,  1.32s/it]Loading train:  58%|█████▊    | 311/532 [07:16<05:14,  1.42s/it]Loading train:  59%|█████▊    | 312/532 [07:17<05:27,  1.49s/it]Loading train:  59%|█████▉    | 313/532 [07:19<05:46,  1.58s/it]Loading train:  59%|█████▉    | 314/532 [07:21<05:59,  1.65s/it]Loading train:  59%|█████▉    | 315/532 [07:23<06:00,  1.66s/it]Loading train:  59%|█████▉    | 316/532 [07:24<05:59,  1.67s/it]Loading train:  60%|█████▉    | 317/532 [07:25<05:24,  1.51s/it]Loading train:  60%|█████▉    | 318/532 [07:27<04:53,  1.37s/it]Loading train:  60%|█████▉    | 319/532 [07:28<04:29,  1.26s/it]Loading train:  60%|██████    | 320/532 [07:29<04:12,  1.19s/it]Loading train:  60%|██████    | 321/532 [07:30<04:03,  1.15s/it]Loading train:  61%|██████    | 322/532 [07:31<03:50,  1.10s/it]Loading train:  61%|██████    | 323/532 [07:32<04:08,  1.19s/it]Loading train:  61%|██████    | 324/532 [07:33<04:23,  1.27s/it]Loading train:  61%|██████    | 325/532 [07:35<04:21,  1.26s/it]Loading train:  61%|██████▏   | 326/532 [07:36<04:23,  1.28s/it]Loading train:  61%|██████▏   | 327/532 [07:37<04:33,  1.33s/it]Loading train:  62%|██████▏   | 328/532 [07:39<04:24,  1.30s/it]Loading train:  62%|██████▏   | 329/532 [07:40<04:13,  1.25s/it]Loading train:  62%|██████▏   | 330/532 [07:41<04:07,  1.23s/it]Loading train:  62%|██████▏   | 331/532 [07:42<03:55,  1.17s/it]Loading train:  62%|██████▏   | 332/532 [07:43<03:58,  1.19s/it]Loading train:  63%|██████▎   | 333/532 [07:44<03:46,  1.14s/it]Loading train:  63%|██████▎   | 334/532 [07:46<03:49,  1.16s/it]Loading train:  63%|██████▎   | 335/532 [07:47<03:50,  1.17s/it]Loading train:  63%|██████▎   | 336/532 [07:48<03:45,  1.15s/it]Loading train:  63%|██████▎   | 337/532 [07:49<03:56,  1.21s/it]Loading train:  64%|██████▎   | 338/532 [07:50<03:47,  1.17s/it]Loading train:  64%|██████▎   | 339/532 [07:51<03:44,  1.16s/it]Loading train:  64%|██████▍   | 340/532 [07:53<03:46,  1.18s/it]Loading train:  64%|██████▍   | 341/532 [07:54<03:33,  1.12s/it]Loading train:  64%|██████▍   | 342/532 [07:55<03:34,  1.13s/it]Loading train:  64%|██████▍   | 343/532 [07:56<03:23,  1.07s/it]Loading train:  65%|██████▍   | 344/532 [07:57<03:24,  1.09s/it]Loading train:  65%|██████▍   | 345/532 [07:58<03:13,  1.03s/it]Loading train:  65%|██████▌   | 346/532 [07:59<03:07,  1.01s/it]Loading train:  65%|██████▌   | 347/532 [08:00<03:08,  1.02s/it]Loading train:  65%|██████▌   | 348/532 [08:01<03:03,  1.00it/s]Loading train:  66%|██████▌   | 349/532 [08:02<03:12,  1.05s/it]Loading train:  66%|██████▌   | 350/532 [08:03<03:19,  1.09s/it]Loading train:  66%|██████▌   | 351/532 [08:04<03:15,  1.08s/it]Loading train:  66%|██████▌   | 352/532 [08:05<03:13,  1.07s/it]Loading train:  66%|██████▋   | 353/532 [08:06<03:11,  1.07s/it]Loading train:  67%|██████▋   | 354/532 [08:07<03:09,  1.07s/it]Loading train:  67%|██████▋   | 355/532 [08:08<03:11,  1.08s/it]Loading train:  67%|██████▋   | 356/532 [08:09<03:02,  1.04s/it]Loading train:  67%|██████▋   | 357/532 [08:10<03:03,  1.05s/it]Loading train:  67%|██████▋   | 358/532 [08:11<02:59,  1.03s/it]Loading train:  67%|██████▋   | 359/532 [08:13<03:05,  1.07s/it]Loading train:  68%|██████▊   | 360/532 [08:14<03:01,  1.05s/it]Loading train:  68%|██████▊   | 361/532 [08:14<02:52,  1.01s/it]Loading train:  68%|██████▊   | 362/532 [08:15<02:44,  1.03it/s]Loading train:  68%|██████▊   | 363/532 [08:16<02:37,  1.07it/s]Loading train:  68%|██████▊   | 364/532 [08:17<02:39,  1.05it/s]Loading train:  69%|██████▊   | 365/532 [08:18<02:36,  1.07it/s]Loading train:  69%|██████▉   | 366/532 [08:19<02:37,  1.05it/s]Loading train:  69%|██████▉   | 367/532 [08:20<02:48,  1.02s/it]Loading train:  69%|██████▉   | 368/532 [08:21<02:43,  1.00it/s]Loading train:  69%|██████▉   | 369/532 [08:22<02:41,  1.01it/s]Loading train:  70%|██████▉   | 370/532 [08:23<02:48,  1.04s/it]Loading train:  70%|██████▉   | 371/532 [08:25<03:05,  1.15s/it]Loading train:  70%|██████▉   | 372/532 [08:26<03:06,  1.17s/it]Loading train:  70%|███████   | 373/532 [08:27<03:09,  1.19s/it]Loading train:  70%|███████   | 374/532 [08:28<03:11,  1.21s/it]Loading train:  70%|███████   | 375/532 [08:30<03:17,  1.26s/it]Loading train:  71%|███████   | 376/532 [08:31<03:23,  1.31s/it]Loading train:  71%|███████   | 377/532 [08:32<03:12,  1.24s/it]Loading train:  71%|███████   | 378/532 [08:33<03:07,  1.22s/it]Loading train:  71%|███████   | 379/532 [08:34<02:56,  1.16s/it]Loading train:  71%|███████▏  | 380/532 [08:36<02:52,  1.14s/it]Loading train:  72%|███████▏  | 381/532 [08:37<03:00,  1.20s/it]Loading train:  72%|███████▏  | 382/532 [08:38<02:52,  1.15s/it]Loading train:  72%|███████▏  | 383/532 [08:39<02:48,  1.13s/it]Loading train:  72%|███████▏  | 384/532 [08:40<02:48,  1.14s/it]Loading train:  72%|███████▏  | 385/532 [08:41<02:40,  1.09s/it]Loading train:  73%|███████▎  | 386/532 [08:42<02:39,  1.09s/it]Loading train:  73%|███████▎  | 387/532 [08:43<02:36,  1.08s/it]Loading train:  73%|███████▎  | 388/532 [08:44<02:35,  1.08s/it]Loading train:  73%|███████▎  | 389/532 [08:46<02:45,  1.16s/it]Loading train:  73%|███████▎  | 390/532 [08:47<02:47,  1.18s/it]Loading train:  73%|███████▎  | 391/532 [08:48<02:41,  1.14s/it]Loading train:  74%|███████▎  | 392/532 [08:49<02:38,  1.14s/it]Loading train:  74%|███████▍  | 393/532 [08:50<02:39,  1.15s/it]Loading train:  74%|███████▍  | 394/532 [08:52<02:41,  1.17s/it]Loading train:  74%|███████▍  | 395/532 [08:53<02:35,  1.14s/it]Loading train:  74%|███████▍  | 396/532 [08:54<02:37,  1.16s/it]Loading train:  75%|███████▍  | 397/532 [08:55<02:39,  1.18s/it]Loading train:  75%|███████▍  | 398/532 [08:56<02:34,  1.15s/it]Loading train:  75%|███████▌  | 399/532 [08:57<02:33,  1.15s/it]Loading train:  75%|███████▌  | 400/532 [08:58<02:34,  1.17s/it]Loading train:  75%|███████▌  | 401/532 [09:00<02:37,  1.20s/it]Loading train:  76%|███████▌  | 402/532 [09:01<02:31,  1.17s/it]Loading train:  76%|███████▌  | 403/532 [09:02<02:33,  1.19s/it]Loading train:  76%|███████▌  | 404/532 [09:03<02:28,  1.16s/it]Loading train:  76%|███████▌  | 405/532 [09:04<02:24,  1.14s/it]Loading train:  76%|███████▋  | 406/532 [09:05<02:23,  1.14s/it]Loading train:  77%|███████▋  | 407/532 [09:07<02:24,  1.16s/it]Loading train:  77%|███████▋  | 408/532 [09:08<02:26,  1.18s/it]Loading train:  77%|███████▋  | 409/532 [09:09<02:19,  1.14s/it]Loading train:  77%|███████▋  | 410/532 [09:10<02:22,  1.17s/it]Loading train:  77%|███████▋  | 411/532 [09:11<02:16,  1.13s/it]Loading train:  77%|███████▋  | 412/532 [09:12<02:14,  1.12s/it]Loading train:  78%|███████▊  | 413/532 [09:13<02:12,  1.11s/it]Loading train:  78%|███████▊  | 414/532 [09:14<02:09,  1.10s/it]Loading train:  78%|███████▊  | 415/532 [09:15<02:07,  1.09s/it]Loading train:  78%|███████▊  | 416/532 [09:17<02:04,  1.08s/it]Loading train:  78%|███████▊  | 417/532 [09:18<02:03,  1.07s/it]Loading train:  79%|███████▊  | 418/532 [09:18<01:56,  1.02s/it]Loading train:  79%|███████▉  | 419/532 [09:20<02:00,  1.07s/it]Loading train:  79%|███████▉  | 420/532 [09:21<02:06,  1.13s/it]Loading train:  79%|███████▉  | 421/532 [09:22<02:07,  1.15s/it]Loading train:  79%|███████▉  | 422/532 [09:23<02:04,  1.13s/it]Loading train:  80%|███████▉  | 423/532 [09:25<02:09,  1.18s/it]Loading train:  80%|███████▉  | 424/532 [09:26<02:12,  1.22s/it]Loading train:  80%|███████▉  | 425/532 [09:27<02:08,  1.20s/it]Loading train:  80%|████████  | 426/532 [09:28<02:05,  1.19s/it]Loading train:  80%|████████  | 427/532 [09:29<02:03,  1.18s/it]Loading train:  80%|████████  | 428/532 [09:30<01:59,  1.15s/it]Loading train:  81%|████████  | 429/532 [09:32<01:58,  1.15s/it]Loading train:  81%|████████  | 430/532 [09:33<01:57,  1.15s/it]Loading train:  81%|████████  | 431/532 [09:34<02:01,  1.21s/it]Loading train:  81%|████████  | 432/532 [09:35<01:59,  1.20s/it]Loading train:  81%|████████▏ | 433/532 [09:36<01:58,  1.19s/it]Loading train:  82%|████████▏ | 434/532 [09:38<02:02,  1.25s/it]Loading train:  82%|████████▏ | 435/532 [09:39<01:58,  1.22s/it]Loading train:  82%|████████▏ | 436/532 [09:40<01:57,  1.23s/it]Loading train:  82%|████████▏ | 437/532 [09:41<01:49,  1.15s/it]Loading train:  82%|████████▏ | 438/532 [09:42<01:41,  1.08s/it]Loading train:  83%|████████▎ | 439/532 [09:43<01:42,  1.11s/it]Loading train:  83%|████████▎ | 440/532 [09:44<01:36,  1.05s/it]Loading train:  83%|████████▎ | 441/532 [09:45<01:33,  1.03s/it]Loading train:  83%|████████▎ | 442/532 [09:46<01:28,  1.01it/s]Loading train:  83%|████████▎ | 443/532 [09:47<01:36,  1.08s/it]Loading train:  83%|████████▎ | 444/532 [09:48<01:31,  1.04s/it]Loading train:  84%|████████▎ | 445/532 [09:49<01:31,  1.05s/it]Loading train:  84%|████████▍ | 446/532 [09:50<01:29,  1.05s/it]Loading train:  84%|████████▍ | 447/532 [09:51<01:28,  1.05s/it]Loading train:  84%|████████▍ | 448/532 [09:52<01:24,  1.01s/it]Loading train:  84%|████████▍ | 449/532 [09:53<01:22,  1.00it/s]Loading train:  85%|████████▍ | 450/532 [09:54<01:21,  1.00it/s]Loading train:  85%|████████▍ | 451/532 [09:55<01:18,  1.03it/s]Loading train:  85%|████████▍ | 452/532 [09:56<01:16,  1.04it/s]Loading train:  85%|████████▌ | 453/532 [09:57<01:14,  1.05it/s]Loading train:  85%|████████▌ | 454/532 [09:58<01:15,  1.04it/s]Loading train:  86%|████████▌ | 455/532 [09:59<01:19,  1.03s/it]Loading train:  86%|████████▌ | 456/532 [10:00<01:20,  1.06s/it]Loading train:  86%|████████▌ | 457/532 [10:02<01:21,  1.08s/it]Loading train:  86%|████████▌ | 458/532 [10:03<01:18,  1.06s/it]Loading train:  86%|████████▋ | 459/532 [10:04<01:19,  1.09s/it]Loading train:  86%|████████▋ | 460/532 [10:05<01:17,  1.08s/it]Loading train:  87%|████████▋ | 461/532 [10:06<01:20,  1.14s/it]Loading train:  87%|████████▋ | 462/532 [10:07<01:22,  1.19s/it]Loading train:  87%|████████▋ | 463/532 [10:09<01:23,  1.21s/it]Loading train:  87%|████████▋ | 464/532 [10:10<01:21,  1.20s/it]Loading train:  87%|████████▋ | 465/532 [10:11<01:20,  1.20s/it]Loading train:  88%|████████▊ | 466/532 [10:12<01:22,  1.24s/it]Loading train:  88%|████████▊ | 467/532 [10:13<01:17,  1.19s/it]Loading train:  88%|████████▊ | 468/532 [10:14<01:11,  1.12s/it]Loading train:  88%|████████▊ | 469/532 [10:15<01:08,  1.08s/it]Loading train:  88%|████████▊ | 470/532 [10:16<01:05,  1.06s/it]Loading train:  89%|████████▊ | 471/532 [10:17<01:02,  1.03s/it]Loading train:  89%|████████▊ | 472/532 [10:18<01:01,  1.03s/it]Loading train:  89%|████████▉ | 473/532 [10:19<01:01,  1.04s/it]Loading train:  89%|████████▉ | 474/532 [10:21<01:05,  1.13s/it]Loading train:  89%|████████▉ | 475/532 [10:22<01:07,  1.19s/it]Loading train:  89%|████████▉ | 476/532 [10:23<01:04,  1.15s/it]Loading train:  90%|████████▉ | 477/532 [10:24<01:04,  1.16s/it]Loading train:  90%|████████▉ | 478/532 [10:25<01:02,  1.15s/it]Loading train:  90%|█████████ | 479/532 [10:26<00:59,  1.12s/it]Loading train:  90%|█████████ | 480/532 [10:27<00:55,  1.07s/it]Loading train:  90%|█████████ | 481/532 [10:28<00:53,  1.05s/it]Loading train:  91%|█████████ | 482/532 [10:29<00:51,  1.03s/it]Loading train:  91%|█████████ | 483/532 [10:30<00:50,  1.02s/it]Loading train:  91%|█████████ | 484/532 [10:31<00:47,  1.01it/s]Loading train:  91%|█████████ | 485/532 [10:33<00:52,  1.11s/it]Loading train:  91%|█████████▏| 486/532 [10:34<00:51,  1.11s/it]Loading train:  92%|█████████▏| 487/532 [10:35<00:50,  1.13s/it]Loading train:  92%|█████████▏| 488/532 [10:36<00:49,  1.13s/it]Loading train:  92%|█████████▏| 489/532 [10:37<00:48,  1.13s/it]Loading train:  92%|█████████▏| 490/532 [10:39<00:49,  1.17s/it]Loading train:  92%|█████████▏| 491/532 [10:39<00:44,  1.09s/it]Loading train:  92%|█████████▏| 492/532 [10:41<00:43,  1.10s/it]Loading train:  93%|█████████▎| 493/532 [10:42<00:42,  1.10s/it]Loading train:  93%|█████████▎| 494/532 [10:43<00:42,  1.11s/it]Loading train:  93%|█████████▎| 495/532 [10:44<00:41,  1.13s/it]Loading train:  93%|█████████▎| 496/532 [10:45<00:39,  1.11s/it]Loading train:  93%|█████████▎| 497/532 [10:46<00:39,  1.12s/it]Loading train:  94%|█████████▎| 498/532 [10:47<00:36,  1.09s/it]Loading train:  94%|█████████▍| 499/532 [10:48<00:36,  1.10s/it]Loading train:  94%|█████████▍| 500/532 [10:49<00:35,  1.09s/it]Loading train:  94%|█████████▍| 501/532 [10:50<00:33,  1.09s/it]Loading train:  94%|█████████▍| 502/532 [10:52<00:32,  1.08s/it]Loading train:  95%|█████████▍| 503/532 [10:52<00:30,  1.05s/it]Loading train:  95%|█████████▍| 504/532 [10:54<00:30,  1.08s/it]Loading train:  95%|█████████▍| 505/532 [10:55<00:28,  1.07s/it]Loading train:  95%|█████████▌| 506/532 [10:56<00:28,  1.08s/it]Loading train:  95%|█████████▌| 507/532 [10:57<00:27,  1.09s/it]Loading train:  95%|█████████▌| 508/532 [10:58<00:26,  1.11s/it]Loading train:  96%|█████████▌| 509/532 [10:59<00:26,  1.13s/it]Loading train:  96%|█████████▌| 510/532 [11:01<00:26,  1.19s/it]Loading train:  96%|█████████▌| 511/532 [11:02<00:25,  1.21s/it]Loading train:  96%|█████████▌| 512/532 [11:03<00:24,  1.20s/it]Loading train:  96%|█████████▋| 513/532 [11:04<00:23,  1.23s/it]Loading train:  97%|█████████▋| 514/532 [11:06<00:22,  1.25s/it]Loading train:  97%|█████████▋| 515/532 [11:07<00:20,  1.19s/it]Loading train:  97%|█████████▋| 516/532 [11:08<00:18,  1.17s/it]Loading train:  97%|█████████▋| 517/532 [11:09<00:16,  1.12s/it]Loading train:  97%|█████████▋| 518/532 [11:10<00:16,  1.14s/it]Loading train:  98%|█████████▊| 519/532 [11:11<00:14,  1.10s/it]Loading train:  98%|█████████▊| 520/532 [11:12<00:12,  1.07s/it]Loading train:  98%|█████████▊| 521/532 [11:13<00:12,  1.12s/it]Loading train:  98%|█████████▊| 522/532 [11:14<00:11,  1.15s/it]Loading train:  98%|█████████▊| 523/532 [11:16<00:10,  1.16s/it]Loading train:  98%|█████████▊| 524/532 [11:17<00:09,  1.15s/it]Loading train:  99%|█████████▊| 525/532 [11:18<00:08,  1.19s/it]Loading train:  99%|█████████▉| 526/532 [11:19<00:07,  1.19s/it]Loading train:  99%|█████████▉| 527/532 [11:20<00:05,  1.14s/it]Loading train:  99%|█████████▉| 528/532 [11:22<00:04,  1.17s/it]Loading train:  99%|█████████▉| 529/532 [11:22<00:03,  1.11s/it]Loading train: 100%|█████████▉| 530/532 [11:23<00:02,  1.07s/it]Loading train: 100%|█████████▉| 531/532 [11:25<00:01,  1.07s/it]Loading train: 100%|██████████| 532/532 [11:26<00:00,  1.05s/it]
concatenating: train:   0%|          | 0/532 [00:00<?, ?it/s]concatenating: train:   1%|          | 6/532 [00:00<00:09, 58.00it/s]concatenating: train:   4%|▎         | 19/532 [00:00<00:07, 69.50it/s]concatenating: train:   8%|▊         | 45/532 [00:00<00:05, 88.74it/s]concatenating: train:  13%|█▎        | 70/532 [00:00<00:04, 109.57it/s]concatenating: train:  18%|█▊        | 96/532 [00:00<00:03, 132.15it/s]concatenating: train:  23%|██▎       | 121/532 [00:00<00:02, 153.33it/s]concatenating: train:  28%|██▊       | 147/532 [00:00<00:02, 174.36it/s]concatenating: train:  32%|███▏      | 172/532 [00:00<00:01, 190.72it/s]concatenating: train:  37%|███▋      | 196/532 [00:00<00:01, 202.12it/s]concatenating: train:  42%|████▏     | 223/532 [00:01<00:01, 217.48it/s]concatenating: train:  47%|████▋     | 248/532 [00:01<00:01, 224.12it/s]concatenating: train:  52%|█████▏    | 275/532 [00:01<00:01, 235.26it/s]concatenating: train:  57%|█████▋    | 301/532 [00:01<00:00, 240.07it/s]concatenating: train:  61%|██████▏   | 327/532 [00:01<00:00, 244.19it/s]concatenating: train:  66%|██████▋   | 353/532 [00:01<00:00, 245.33it/s]concatenating: train:  71%|███████   | 378/532 [00:01<00:00, 245.95it/s]concatenating: train:  76%|███████▌  | 403/532 [00:01<00:00, 236.05it/s]concatenating: train:  80%|████████  | 427/532 [00:02<00:00, 123.47it/s]concatenating: train:  85%|████████▍ | 452/532 [00:02<00:00, 145.08it/s]concatenating: train:  90%|█████████ | 479/532 [00:02<00:00, 167.62it/s]concatenating: train:  95%|█████████▍| 505/532 [00:02<00:00, 186.26it/s]concatenating: train: 100%|██████████| 532/532 [00:02<00:00, 204.78it/s]
Loading test:   0%|          | 0/15 [00:00<?, ?it/s]Loading test:   7%|▋         | 1/15 [00:01<00:17,  1.25s/it]Loading test:  13%|█▎        | 2/15 [00:02<00:15,  1.22s/it]Loading test:  20%|██        | 3/15 [00:03<00:14,  1.23s/it]Loading test:  27%|██▋       | 4/15 [00:04<00:13,  1.20s/it]Loading test:  33%|███▎      | 5/15 [00:06<00:12,  1.25s/it]Loading test:  40%|████      | 6/15 [00:07<00:11,  1.27s/it]Loading test:  47%|████▋     | 7/15 [00:08<00:09,  1.23s/it]Loading test:  53%|█████▎    | 8/15 [00:09<00:08,  1.26s/it]Loading test:  60%|██████    | 9/15 [00:11<00:07,  1.20s/it]Loading test:  67%|██████▋   | 10/15 [00:11<00:05,  1.11s/it]Loading test:  73%|███████▎  | 11/15 [00:12<00:04,  1.09s/it]Loading test:  80%|████████  | 12/15 [00:14<00:03,  1.10s/it]Loading test:  87%|████████▋ | 13/15 [00:15<00:02,  1.10s/it]Loading test:  93%|█████████▎| 14/15 [00:16<00:01,  1.07s/it]Loading test: 100%|██████████| 15/15 [00:17<00:00,  1.12s/it]
concatenating: validation:   0%|          | 0/15 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 15/15 [00:00<00:00, 209.08it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 56, 56, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 56, 56, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 56, 56, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 56, 56, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 56, 56, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 56, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 56, 56, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 56, 56, 21)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 21)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28, 28, 21)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 28, 40)   7600        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 28, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 28, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 28, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 28, 28, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 28, 28, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 28, 61)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 61)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 14, 14, 61)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 14, 14, 80)   44000       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 14, 14, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 14, 14, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 14, 14, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 14, 14, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 14, 14, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 14, 14, 141)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 14, 14, 141)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 28, 28, 40)   22600       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 28, 28, 101)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 28, 28, 40)   36400       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 28, 28, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 28, 28, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 28, 28, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 28, 28, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 28, 28, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 28, 28, 141)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-07 04:58:15.702007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 04:58:15.702131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 04:58:15.702149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 04:58:15.702162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 04:58:15.702723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 28, 28, 141)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 56, 56, 20)   11300       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 56, 41)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 56, 56, 20)   7400        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 56, 56, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 56, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 56, 56, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 56, 56, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 56, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 56, 61)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 56, 56, 61)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 56, 56, 13)   806         dropout_5[0][0]                  
==================================================================================================
Total params: 225,706
Trainable params: 224,906
Non-trainable params: 800
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.53974061e-02 2.89048015e-02 1.16758472e-01 1.00223856e-02
 3.03440156e-02 5.80063118e-03 6.84518755e-02 1.28261328e-01
 7.55818021e-02 1.22545826e-02 2.73712232e-01 1.84335085e-01
 1.75382711e-04]
Train on 33496 samples, validate on 969 samples
Epoch 1/300
 - 37s - loss: 27.9569 - acc: 0.8049 - mDice: 0.0278 - val_loss: 3.4533 - val_acc: 0.9213 - val_mDice: 0.0594

Epoch 00001: val_mDice improved from -inf to 0.05943, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 29s - loss: 3.8483 - acc: 0.9120 - mDice: 0.1064 - val_loss: 2.2809 - val_acc: 0.9319 - val_mDice: 0.1946

Epoch 00002: val_mDice improved from 0.05943 to 0.19462, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 29s - loss: 2.6894 - acc: 0.9290 - mDice: 0.2406 - val_loss: 1.5503 - val_acc: 0.9573 - val_mDice: 0.3880

Epoch 00003: val_mDice improved from 0.19462 to 0.38802, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 28s - loss: 2.0031 - acc: 0.9412 - mDice: 0.3730 - val_loss: 1.1426 - val_acc: 0.9689 - val_mDice: 0.5356

Epoch 00004: val_mDice improved from 0.38802 to 0.53558, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 5/300
 - 29s - loss: 1.6538 - acc: 0.9491 - mDice: 0.4573 - val_loss: 0.9768 - val_acc: 0.9737 - val_mDice: 0.6047

Epoch 00005: val_mDice improved from 0.53558 to 0.60474, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 29s - loss: 1.4521 - acc: 0.9539 - mDice: 0.5136 - val_loss: 0.8710 - val_acc: 0.9758 - val_mDice: 0.6533

Epoch 00006: val_mDice improved from 0.60474 to 0.65331, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 7/300
 - 29s - loss: 1.3163 - acc: 0.9570 - mDice: 0.5529 - val_loss: 0.8227 - val_acc: 0.9748 - val_mDice: 0.6785

Epoch 00007: val_mDice improved from 0.65331 to 0.67855, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 8/300
 - 30s - loss: 1.2219 - acc: 0.9589 - mDice: 0.5809 - val_loss: 0.7870 - val_acc: 0.9770 - val_mDice: 0.6903

Epoch 00008: val_mDice improved from 0.67855 to 0.69032, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 9/300
 - 29s - loss: 1.1437 - acc: 0.9605 - mDice: 0.6042 - val_loss: 0.7737 - val_acc: 0.9768 - val_mDice: 0.7028

Epoch 00009: val_mDice improved from 0.69032 to 0.70282, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 10/300
 - 29s - loss: 1.0855 - acc: 0.9616 - mDice: 0.6213 - val_loss: 0.7535 - val_acc: 0.9774 - val_mDice: 0.7112

Epoch 00010: val_mDice improved from 0.70282 to 0.71119, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 11/300
 - 27s - loss: 1.0423 - acc: 0.9624 - mDice: 0.6339 - val_loss: 0.7258 - val_acc: 0.9775 - val_mDice: 0.7214

Epoch 00011: val_mDice improved from 0.71119 to 0.72141, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 12/300
 - 25s - loss: 0.9987 - acc: 0.9633 - mDice: 0.6467 - val_loss: 0.7233 - val_acc: 0.9784 - val_mDice: 0.7257

Epoch 00012: val_mDice improved from 0.72141 to 0.72566, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 13/300
 - 27s - loss: 0.9592 - acc: 0.9640 - mDice: 0.6591 - val_loss: 0.7011 - val_acc: 0.9781 - val_mDice: 0.7320

Epoch 00013: val_mDice improved from 0.72566 to 0.73199, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 14/300
 - 25s - loss: 0.9317 - acc: 0.9645 - mDice: 0.6676 - val_loss: 0.6994 - val_acc: 0.9792 - val_mDice: 0.7312

Epoch 00014: val_mDice did not improve from 0.73199
Epoch 15/300
 - 26s - loss: 0.9019 - acc: 0.9652 - mDice: 0.6768 - val_loss: 0.6878 - val_acc: 0.9791 - val_mDice: 0.7375

Epoch 00015: val_mDice improved from 0.73199 to 0.73749, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 16/300
 - 26s - loss: 0.8789 - acc: 0.9658 - mDice: 0.6844 - val_loss: 0.6921 - val_acc: 0.9787 - val_mDice: 0.7381

Epoch 00016: val_mDice improved from 0.73749 to 0.73811, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 17/300
 - 27s - loss: 0.8575 - acc: 0.9663 - mDice: 0.6914 - val_loss: 0.7332 - val_acc: 0.9786 - val_mDice: 0.7286

Epoch 00017: val_mDice did not improve from 0.73811
Epoch 18/300
 - 27s - loss: 0.8400 - acc: 0.9667 - mDice: 0.6972 - val_loss: 0.6909 - val_acc: 0.9794 - val_mDice: 0.7414

Epoch 00018: val_mDice improved from 0.73811 to 0.74142, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 19/300
 - 26s - loss: 0.8243 - acc: 0.9670 - mDice: 0.7025 - val_loss: 0.6698 - val_acc: 0.9798 - val_mDice: 0.7431

Epoch 00019: val_mDice improved from 0.74142 to 0.74311, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 20/300
 - 26s - loss: 0.8132 - acc: 0.9672 - mDice: 0.7060 - val_loss: 0.6696 - val_acc: 0.9799 - val_mDice: 0.7477

Epoch 00020: val_mDice improved from 0.74311 to 0.74771, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 21/300
 - 27s - loss: 0.7976 - acc: 0.9676 - mDice: 0.7113 - val_loss: 0.6732 - val_acc: 0.9792 - val_mDice: 0.7466

Epoch 00021: val_mDice did not improve from 0.74771
Epoch 22/300
 - 27s - loss: 0.7858 - acc: 0.9678 - mDice: 0.7153 - val_loss: 0.6655 - val_acc: 0.9801 - val_mDice: 0.7476

Epoch 00022: val_mDice did not improve from 0.74771
Epoch 23/300
 - 26s - loss: 0.7761 - acc: 0.9680 - mDice: 0.7185 - val_loss: 0.6579 - val_acc: 0.9805 - val_mDice: 0.7500

Epoch 00023: val_mDice improved from 0.74771 to 0.75001, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 24/300
 - 26s - loss: 0.7639 - acc: 0.9683 - mDice: 0.7223 - val_loss: 0.6432 - val_acc: 0.9804 - val_mDice: 0.7548

Epoch 00024: val_mDice improved from 0.75001 to 0.75478, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 25/300
 - 26s - loss: 0.7552 - acc: 0.9685 - mDice: 0.7256 - val_loss: 0.6639 - val_acc: 0.9805 - val_mDice: 0.7494

Epoch 00025: val_mDice did not improve from 0.75478
Epoch 26/300
 - 27s - loss: 0.7451 - acc: 0.9688 - mDice: 0.7290 - val_loss: 0.7014 - val_acc: 0.9802 - val_mDice: 0.7438

Epoch 00026: val_mDice did not improve from 0.75478
Epoch 27/300
 - 27s - loss: 0.7405 - acc: 0.9689 - mDice: 0.7305 - val_loss: 0.6553 - val_acc: 0.9810 - val_mDice: 0.7503

Epoch 00027: val_mDice did not improve from 0.75478
Epoch 28/300
 - 27s - loss: 0.7316 - acc: 0.9691 - mDice: 0.7337 - val_loss: 0.6448 - val_acc: 0.9814 - val_mDice: 0.7531

Epoch 00028: val_mDice did not improve from 0.75478
Epoch 29/300
 - 27s - loss: 0.7225 - acc: 0.9693 - mDice: 0.7364 - val_loss: 0.6640 - val_acc: 0.9809 - val_mDice: 0.7569

Epoch 00029: val_mDice improved from 0.75478 to 0.75692, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 30/300
 - 26s - loss: 0.7160 - acc: 0.9695 - mDice: 0.7388 - val_loss: 0.6479 - val_acc: 0.9811 - val_mDice: 0.7576

Epoch 00030: val_mDice improved from 0.75692 to 0.75763, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 31/300
 - 27s - loss: 0.7096 - acc: 0.9697 - mDice: 0.7409 - val_loss: 0.6365 - val_acc: 0.9816 - val_mDice: 0.7603

Epoch 00031: val_mDice improved from 0.75763 to 0.76034, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 32/300
 - 25s - loss: 0.7035 - acc: 0.9698 - mDice: 0.7430 - val_loss: 0.6423 - val_acc: 0.9812 - val_mDice: 0.7598

Epoch 00032: val_mDice did not improve from 0.76034
Epoch 33/300
 - 27s - loss: 0.6983 - acc: 0.9700 - mDice: 0.7446 - val_loss: 0.6528 - val_acc: 0.9811 - val_mDice: 0.7579

Epoch 00033: val_mDice did not improve from 0.76034
Epoch 34/300
 - 26s - loss: 0.6930 - acc: 0.9700 - mDice: 0.7463 - val_loss: 0.6437 - val_acc: 0.9811 - val_mDice: 0.7610

Epoch 00034: val_mDice improved from 0.76034 to 0.76098, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 35/300
 - 33s - loss: 0.6867 - acc: 0.9702 - mDice: 0.7485 - val_loss: 0.6360 - val_acc: 0.9815 - val_mDice: 0.7610

Epoch 00035: val_mDice did not improve from 0.76098
Epoch 36/300
 - 33s - loss: 0.6850 - acc: 0.9703 - mDice: 0.7487 - val_loss: 0.6330 - val_acc: 0.9817 - val_mDice: 0.7643

Epoch 00036: val_mDice improved from 0.76098 to 0.76429, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 37/300
 - 34s - loss: 0.6788 - acc: 0.9705 - mDice: 0.7510 - val_loss: 0.6317 - val_acc: 0.9815 - val_mDice: 0.7610

Epoch 00037: val_mDice did not improve from 0.76429
Epoch 38/300
 - 36s - loss: 0.6734 - acc: 0.9705 - mDice: 0.7530 - val_loss: 0.6547 - val_acc: 0.9817 - val_mDice: 0.7595

Epoch 00038: val_mDice did not improve from 0.76429
Epoch 39/300
 - 34s - loss: 0.6703 - acc: 0.9706 - mDice: 0.7546 - val_loss: 0.6317 - val_acc: 0.9814 - val_mDice: 0.7628

Epoch 00039: val_mDice did not improve from 0.76429
Epoch 40/300
 - 35s - loss: 0.6676 - acc: 0.9707 - mDice: 0.7548 - val_loss: 0.6390 - val_acc: 0.9808 - val_mDice: 0.7636

Epoch 00040: val_mDice did not improve from 0.76429
Epoch 41/300
 - 35s - loss: 0.6627 - acc: 0.9707 - mDice: 0.7563 - val_loss: 0.6277 - val_acc: 0.9816 - val_mDice: 0.7674

Epoch 00041: val_mDice improved from 0.76429 to 0.76742, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 42/300
 - 34s - loss: 0.6618 - acc: 0.9708 - mDice: 0.7569 - val_loss: 0.6380 - val_acc: 0.9809 - val_mDice: 0.7693

Epoch 00042: val_mDice improved from 0.76742 to 0.76927, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 43/300
 - 35s - loss: 0.6547 - acc: 0.9710 - mDice: 0.7592 - val_loss: 0.6375 - val_acc: 0.9813 - val_mDice: 0.7638

Epoch 00043: val_mDice did not improve from 0.76927
Epoch 44/300
 - 34s - loss: 0.6542 - acc: 0.9710 - mDice: 0.7593 - val_loss: 0.6309 - val_acc: 0.9814 - val_mDice: 0.7664

Epoch 00044: val_mDice did not improve from 0.76927
Epoch 45/300
 - 35s - loss: 0.6511 - acc: 0.9711 - mDice: 0.7605 - val_loss: 0.6408 - val_acc: 0.9810 - val_mDice: 0.7641

Epoch 00045: val_mDice did not improve from 0.76927
Epoch 46/300
 - 27s - loss: 0.6484 - acc: 0.9711 - mDice: 0.7614 - val_loss: 0.6359 - val_acc: 0.9804 - val_mDice: 0.7668

Epoch 00046: val_mDice did not improve from 0.76927
Epoch 47/300
 - 25s - loss: 0.6454 - acc: 0.9712 - mDice: 0.7621 - val_loss: 0.6264 - val_acc: 0.9817 - val_mDice: 0.7710

Epoch 00047: val_mDice improved from 0.76927 to 0.77101, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 48/300
 - 26s - loss: 0.6426 - acc: 0.9713 - mDice: 0.7632 - val_loss: 0.6346 - val_acc: 0.9815 - val_mDice: 0.7686

Epoch 00048: val_mDice did not improve from 0.77101
Epoch 49/300
 - 26s - loss: 0.6403 - acc: 0.9713 - mDice: 0.7642 - val_loss: 0.6225 - val_acc: 0.9816 - val_mDice: 0.7671

Epoch 00049: val_mDice did not improve from 0.77101
Epoch 50/300
 - 26s - loss: 0.6354 - acc: 0.9714 - mDice: 0.7656 - val_loss: 0.6470 - val_acc: 0.9814 - val_mDice: 0.7668

Epoch 00050: val_mDice did not improve from 0.77101
Epoch 51/300
 - 26s - loss: 0.6335 - acc: 0.9715 - mDice: 0.7666 - val_loss: 0.6265 - val_acc: 0.9819 - val_mDice: 0.7675

Epoch 00051: val_mDice did not improve from 0.77101
Epoch 52/300
 - 27s - loss: 0.6333 - acc: 0.9715 - mDice: 0.7667 - val_loss: 0.6207 - val_acc: 0.9816 - val_mDice: 0.7697

Epoch 00052: val_mDice did not improve from 0.77101
Epoch 53/300
 - 27s - loss: 0.6296 - acc: 0.9715 - mDice: 0.7678 - val_loss: 0.6334 - val_acc: 0.9821 - val_mDice: 0.7677

Epoch 00053: val_mDice did not improve from 0.77101
Epoch 54/300
 - 26s - loss: 0.6294 - acc: 0.9715 - mDice: 0.7681 - val_loss: 0.6129 - val_acc: 0.9821 - val_mDice: 0.7720

Epoch 00054: val_mDice improved from 0.77101 to 0.77203, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 55/300
 - 26s - loss: 0.6263 - acc: 0.9716 - mDice: 0.7688 - val_loss: 0.6259 - val_acc: 0.9813 - val_mDice: 0.7708

Epoch 00055: val_mDice did not improve from 0.77203
Epoch 56/300
 - 27s - loss: 0.6237 - acc: 0.9716 - mDice: 0.7699 - val_loss: 0.6199 - val_acc: 0.9811 - val_mDice: 0.7727

Epoch 00056: val_mDice improved from 0.77203 to 0.77275, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 57/300
 - 27s - loss: 0.6207 - acc: 0.9717 - mDice: 0.7708 - val_loss: 0.6216 - val_acc: 0.9818 - val_mDice: 0.7720

Epoch 00057: val_mDice did not improve from 0.77275
Epoch 58/300
 - 26s - loss: 0.6210 - acc: 0.9717 - mDice: 0.7708 - val_loss: 0.6241 - val_acc: 0.9818 - val_mDice: 0.7750

Epoch 00058: val_mDice improved from 0.77275 to 0.77504, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 59/300
 - 26s - loss: 0.6175 - acc: 0.9718 - mDice: 0.7722 - val_loss: 0.6222 - val_acc: 0.9810 - val_mDice: 0.7741

Epoch 00059: val_mDice did not improve from 0.77504
Epoch 60/300
 - 26s - loss: 0.6183 - acc: 0.9717 - mDice: 0.7717 - val_loss: 0.6216 - val_acc: 0.9821 - val_mDice: 0.7713

Epoch 00060: val_mDice did not improve from 0.77504
Epoch 61/300
 - 26s - loss: 0.6159 - acc: 0.9718 - mDice: 0.7727 - val_loss: 0.6261 - val_acc: 0.9817 - val_mDice: 0.7738

Epoch 00061: val_mDice did not improve from 0.77504
Epoch 62/300
 - 26s - loss: 0.6130 - acc: 0.9719 - mDice: 0.7735 - val_loss: 0.6275 - val_acc: 0.9819 - val_mDice: 0.7732

Epoch 00062: val_mDice did not improve from 0.77504
Epoch 63/300
 - 26s - loss: 0.6122 - acc: 0.9719 - mDice: 0.7739 - val_loss: 0.6365 - val_acc: 0.9813 - val_mDice: 0.7703

Epoch 00063: val_mDice did not improve from 0.77504
Epoch 64/300
 - 26s - loss: 0.6108 - acc: 0.9719 - mDice: 0.7744 - val_loss: 0.6247 - val_acc: 0.9820 - val_mDice: 0.7717

Epoch 00064: val_mDice did not improve from 0.77504
Epoch 65/300
 - 26s - loss: 0.6085 - acc: 0.9720 - mDice: 0.7752 - val_loss: 0.6253 - val_acc: 0.9817 - val_mDice: 0.7715

Epoch 00065: val_mDice did not improve from 0.77504
Epoch 66/300
 - 26s - loss: 0.6067 - acc: 0.9721 - mDice: 0.7757 - val_loss: 0.6309 - val_acc: 0.9821 - val_mDice: 0.7722

Epoch 00066: val_mDice did not improve from 0.77504
Epoch 67/300
 - 27s - loss: 0.6074 - acc: 0.9720 - mDice: 0.7757 - val_loss: 0.6309 - val_acc: 0.9817 - val_mDice: 0.7730

Epoch 00067: val_mDice did not improve from 0.77504
Epoch 68/300
 - 29s - loss: 0.6039 - acc: 0.9721 - mDice: 0.7769 - val_loss: 0.6404 - val_acc: 0.9819 - val_mDice: 0.7751

Epoch 00068: val_mDice improved from 0.77504 to 0.77508, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 69/300
 - 29s - loss: 0.6026 - acc: 0.9722 - mDice: 0.7771 - val_loss: 0.6313 - val_acc: 0.9820 - val_mDice: 0.7721

Epoch 00069: val_mDice did not improve from 0.77508
Epoch 70/300
 - 29s - loss: 0.6016 - acc: 0.9722 - mDice: 0.7774 - val_loss: 0.6396 - val_acc: 0.9819 - val_mDice: 0.7708

Epoch 00070: val_mDice did not improve from 0.77508
Epoch 71/300
 - 30s - loss: 0.6007 - acc: 0.9722 - mDice: 0.7780 - val_loss: 0.6226 - val_acc: 0.9821 - val_mDice: 0.7724

Epoch 00071: val_mDice did not improve from 0.77508
Epoch 72/300
 - 30s - loss: 0.6010 - acc: 0.9722 - mDice: 0.7777 - val_loss: 0.6210 - val_acc: 0.9818 - val_mDice: 0.7747

Epoch 00072: val_mDice did not improve from 0.77508
Epoch 73/300
 - 29s - loss: 0.5966 - acc: 0.9723 - mDice: 0.7794 - val_loss: 0.6239 - val_acc: 0.9820 - val_mDice: 0.7747

Epoch 00073: val_mDice did not improve from 0.77508
Epoch 74/300
 - 29s - loss: 0.5969 - acc: 0.9723 - mDice: 0.7793 - val_loss: 0.6228 - val_acc: 0.9816 - val_mDice: 0.7752

Epoch 00074: val_mDice improved from 0.77508 to 0.77522, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 75/300
 - 29s - loss: 0.5962 - acc: 0.9723 - mDice: 0.7795 - val_loss: 0.6199 - val_acc: 0.9821 - val_mDice: 0.7748

Epoch 00075: val_mDice did not improve from 0.77522
Epoch 76/300
 - 28s - loss: 0.5956 - acc: 0.9723 - mDice: 0.7797 - val_loss: 0.6232 - val_acc: 0.9819 - val_mDice: 0.7709

Epoch 00076: val_mDice did not improve from 0.77522
Epoch 77/300
 - 27s - loss: 0.5945 - acc: 0.9724 - mDice: 0.7800 - val_loss: 0.6295 - val_acc: 0.9815 - val_mDice: 0.7751

Epoch 00077: val_mDice did not improve from 0.77522
Epoch 78/300
 - 28s - loss: 0.5928 - acc: 0.9724 - mDice: 0.7807 - val_loss: 0.6388 - val_acc: 0.9816 - val_mDice: 0.7725

Epoch 00078: val_mDice did not improve from 0.77522
Epoch 79/300
 - 28s - loss: 0.5912 - acc: 0.9724 - mDice: 0.7813 - val_loss: 0.6297 - val_acc: 0.9819 - val_mDice: 0.7758

Epoch 00079: val_mDice improved from 0.77522 to 0.77576, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 80/300
 - 27s - loss: 0.5902 - acc: 0.9725 - mDice: 0.7817 - val_loss: 0.6251 - val_acc: 0.9823 - val_mDice: 0.7766

Epoch 00080: val_mDice improved from 0.77576 to 0.77663, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 81/300
 - 26s - loss: 0.5900 - acc: 0.9725 - mDice: 0.7816 - val_loss: 0.6320 - val_acc: 0.9817 - val_mDice: 0.7748

Epoch 00081: val_mDice did not improve from 0.77663
Epoch 82/300
 - 26s - loss: 0.5882 - acc: 0.9725 - mDice: 0.7823 - val_loss: 0.6332 - val_acc: 0.9814 - val_mDice: 0.7754

Epoch 00082: val_mDice did not improve from 0.77663
Epoch 83/300
 - 25s - loss: 0.5871 - acc: 0.9725 - mDice: 0.7829 - val_loss: 0.6301 - val_acc: 0.9814 - val_mDice: 0.7751

Epoch 00083: val_mDice did not improve from 0.77663
Epoch 84/300
 - 26s - loss: 0.5861 - acc: 0.9725 - mDice: 0.7829 - val_loss: 0.6291 - val_acc: 0.9814 - val_mDice: 0.7767

Epoch 00084: val_mDice improved from 0.77663 to 0.77675, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 85/300
 - 24s - loss: 0.5857 - acc: 0.9726 - mDice: 0.7831 - val_loss: 0.6257 - val_acc: 0.9821 - val_mDice: 0.7799

Epoch 00085: val_mDice improved from 0.77675 to 0.77990, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 86/300
 - 25s - loss: 0.5868 - acc: 0.9725 - mDice: 0.7829 - val_loss: 0.6273 - val_acc: 0.9816 - val_mDice: 0.7771

Epoch 00086: val_mDice did not improve from 0.77990
Epoch 87/300
 - 26s - loss: 0.5855 - acc: 0.9726 - mDice: 0.7835 - val_loss: 0.6249 - val_acc: 0.9822 - val_mDice: 0.7799

Epoch 00087: val_mDice improved from 0.77990 to 0.77993, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 88/300
 - 24s - loss: 0.5838 - acc: 0.9726 - mDice: 0.7838 - val_loss: 0.6327 - val_acc: 0.9820 - val_mDice: 0.7751

Epoch 00088: val_mDice did not improve from 0.77993
Epoch 89/300
 - 24s - loss: 0.5834 - acc: 0.9726 - mDice: 0.7840 - val_loss: 0.6135 - val_acc: 0.9823 - val_mDice: 0.7782

Epoch 00089: val_mDice did not improve from 0.77993
Epoch 90/300
 - 26s - loss: 0.5815 - acc: 0.9726 - mDice: 0.7847 - val_loss: 0.6404 - val_acc: 0.9810 - val_mDice: 0.7765

Epoch 00090: val_mDice did not improve from 0.77993
Epoch 91/300
 - 25s - loss: 0.5811 - acc: 0.9727 - mDice: 0.7845 - val_loss: 0.6372 - val_acc: 0.9819 - val_mDice: 0.7777

Epoch 00091: val_mDice did not improve from 0.77993
Epoch 92/300
 - 24s - loss: 0.5798 - acc: 0.9727 - mDice: 0.7856 - val_loss: 0.6395 - val_acc: 0.9822 - val_mDice: 0.7739

Epoch 00092: val_mDice did not improve from 0.77993
Epoch 93/300
 - 24s - loss: 0.5797 - acc: 0.9727 - mDice: 0.7853 - val_loss: 0.6302 - val_acc: 0.9816 - val_mDice: 0.7783

Epoch 00093: val_mDice did not improve from 0.77993
Epoch 94/300
 - 26s - loss: 0.5792 - acc: 0.9727 - mDice: 0.7856 - val_loss: 0.6226 - val_acc: 0.9815 - val_mDice: 0.7781

Epoch 00094: val_mDice did not improve from 0.77993
Epoch 95/300
 - 25s - loss: 0.5775 - acc: 0.9728 - mDice: 0.7863 - val_loss: 0.6325 - val_acc: 0.9817 - val_mDice: 0.7769

Epoch 00095: val_mDice did not improve from 0.77993
Epoch 96/300
 - 24s - loss: 0.5775 - acc: 0.9728 - mDice: 0.7859 - val_loss: 0.6461 - val_acc: 0.9819 - val_mDice: 0.7741

Epoch 00096: val_mDice did not improve from 0.77993
Epoch 97/300
 - 24s - loss: 0.5772 - acc: 0.9728 - mDice: 0.7863 - val_loss: 0.6255 - val_acc: 0.9822 - val_mDice: 0.7754

Epoch 00097: val_mDice did not improve from 0.77993
Epoch 98/300
 - 26s - loss: 0.5757 - acc: 0.9728 - mDice: 0.7869 - val_loss: 0.6418 - val_acc: 0.9813 - val_mDice: 0.7793

Epoch 00098: val_mDice did not improve from 0.77993
Epoch 99/300
 - 25s - loss: 0.5759 - acc: 0.9728 - mDice: 0.7868 - val_loss: 0.6260 - val_acc: 0.9818 - val_mDice: 0.7776

Epoch 00099: val_mDice did not improve from 0.77993
Epoch 100/300
 - 26s - loss: 0.5740 - acc: 0.9728 - mDice: 0.7875 - val_loss: 0.6270 - val_acc: 0.9820 - val_mDice: 0.7764

Epoch 00100: val_mDice did not improve from 0.77993
Epoch 101/300
 - 27s - loss: 0.5736 - acc: 0.9728 - mDice: 0.7881 - val_loss: 0.6338 - val_acc: 0.9820 - val_mDice: 0.7755

Epoch 00101: val_mDice did not improve from 0.77993
Epoch 102/300
 - 26s - loss: 0.5745 - acc: 0.9728 - mDice: 0.7873 - val_loss: 0.6245 - val_acc: 0.9821 - val_mDice: 0.7761

Epoch 00102: val_mDice did not improve from 0.77993
Epoch 103/300
 - 26s - loss: 0.5746 - acc: 0.9728 - mDice: 0.7871 - val_loss: 0.6382 - val_acc: 0.9818 - val_mDice: 0.7763

Epoch 00103: val_mDice did not improve from 0.77993
Epoch 104/300
 - 26s - loss: 0.5706 - acc: 0.9729 - mDice: 0.7886 - val_loss: 0.6334 - val_acc: 0.9819 - val_mDice: 0.7747

Epoch 00104: val_mDice did not improve from 0.77993
Epoch 105/300
 - 26s - loss: 0.5704 - acc: 0.9729 - mDice: 0.7886 - val_loss: 0.6320 - val_acc: 0.9821 - val_mDice: 0.7759

Epoch 00105: val_mDice did not improve from 0.77993
Epoch 106/300
 - 26s - loss: 0.5695 - acc: 0.9729 - mDice: 0.7891 - val_loss: 0.6439 - val_acc: 0.9816 - val_mDice: 0.7768

Epoch 00106: val_mDice did not improve from 0.77993
Epoch 107/300
 - 26s - loss: 0.5695 - acc: 0.9729 - mDice: 0.7887 - val_loss: 0.6331 - val_acc: 0.9824 - val_mDice: 0.7795

Epoch 00107: val_mDice did not improve from 0.77993
Epoch 108/300
 - 27s - loss: 0.5701 - acc: 0.9729 - mDice: 0.7885 - val_loss: 0.6337 - val_acc: 0.9824 - val_mDice: 0.7760

Epoch 00108: val_mDice did not improve from 0.77993
Epoch 109/300
 - 27s - loss: 0.5694 - acc: 0.9729 - mDice: 0.7888 - val_loss: 0.6319 - val_acc: 0.9815 - val_mDice: 0.7796

Epoch 00109: val_mDice did not improve from 0.77993
Epoch 110/300
 - 27s - loss: 0.5684 - acc: 0.9730 - mDice: 0.7893 - val_loss: 0.6437 - val_acc: 0.9817 - val_mDice: 0.7784

Epoch 00110: val_mDice did not improve from 0.77993
Epoch 111/300
 - 26s - loss: 0.5673 - acc: 0.9730 - mDice: 0.7900 - val_loss: 0.6279 - val_acc: 0.9823 - val_mDice: 0.7755

Epoch 00111: val_mDice did not improve from 0.77993
Epoch 112/300
 - 26s - loss: 0.5682 - acc: 0.9730 - mDice: 0.7893 - val_loss: 0.6325 - val_acc: 0.9820 - val_mDice: 0.7784

Epoch 00112: val_mDice did not improve from 0.77993
Epoch 113/300
 - 26s - loss: 0.5662 - acc: 0.9730 - mDice: 0.7901 - val_loss: 0.6411 - val_acc: 0.9816 - val_mDice: 0.7767

Epoch 00113: val_mDice did not improve from 0.77993
Epoch 114/300
 - 26s - loss: 0.5662 - acc: 0.9730 - mDice: 0.7903 - val_loss: 0.6291 - val_acc: 0.9822 - val_mDice: 0.7761

Epoch 00114: val_mDice did not improve from 0.77993
Epoch 115/300
 - 26s - loss: 0.5659 - acc: 0.9730 - mDice: 0.7902 - val_loss: 0.6387 - val_acc: 0.9821 - val_mDice: 0.7773

Epoch 00115: val_mDice did not improve from 0.77993
Epoch 116/300
 - 26s - loss: 0.5661 - acc: 0.9730 - mDice: 0.7902 - val_loss: 0.6348 - val_acc: 0.9821 - val_mDice: 0.7769

Epoch 00116: val_mDice did not improve from 0.77993
Epoch 117/300
 - 27s - loss: 0.5643 - acc: 0.9730 - mDice: 0.7906 - val_loss: 0.6245 - val_acc: 0.9823 - val_mDice: 0.7812

Epoch 00117: val_mDice improved from 0.77993 to 0.78121, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 118/300
 - 28s - loss: 0.5647 - acc: 0.9731 - mDice: 0.7907 - val_loss: 0.6267 - val_acc: 0.9819 - val_mDice: 0.7786

Epoch 00118: val_mDice did not improve from 0.78121
Epoch 119/300
 - 27s - loss: 0.5648 - acc: 0.9731 - mDice: 0.7908 - val_loss: 0.6269 - val_acc: 0.9819 - val_mDice: 0.7784

Epoch 00119: val_mDice did not improve from 0.78121
Epoch 120/300
 - 28s - loss: 0.5630 - acc: 0.9731 - mDice: 0.7913 - val_loss: 0.6348 - val_acc: 0.9816 - val_mDice: 0.7787

Epoch 00120: val_mDice did not improve from 0.78121
Epoch 121/300
 - 29s - loss: 0.5637 - acc: 0.9730 - mDice: 0.7910 - val_loss: 0.6319 - val_acc: 0.9820 - val_mDice: 0.7797

Epoch 00121: val_mDice did not improve from 0.78121
Epoch 122/300
 - 29s - loss: 0.5630 - acc: 0.9731 - mDice: 0.7912 - val_loss: 0.6325 - val_acc: 0.9817 - val_mDice: 0.7784

Epoch 00122: val_mDice did not improve from 0.78121
Epoch 123/300
 - 29s - loss: 0.5616 - acc: 0.9731 - mDice: 0.7919 - val_loss: 0.6346 - val_acc: 0.9821 - val_mDice: 0.7791

Epoch 00123: val_mDice did not improve from 0.78121
Epoch 124/300
 - 29s - loss: 0.5620 - acc: 0.9731 - mDice: 0.7917 - val_loss: 0.6449 - val_acc: 0.9819 - val_mDice: 0.7747

Epoch 00124: val_mDice did not improve from 0.78121
Epoch 125/300
 - 29s - loss: 0.5611 - acc: 0.9731 - mDice: 0.7918 - val_loss: 0.6398 - val_acc: 0.9819 - val_mDice: 0.7793

Epoch 00125: val_mDice did not improve from 0.78121
Epoch 126/300
 - 28s - loss: 0.5620 - acc: 0.9731 - mDice: 0.7921 - val_loss: 0.6309 - val_acc: 0.9820 - val_mDice: 0.7787

Epoch 00126: val_mDice did not improve from 0.78121
Epoch 127/300
 - 27s - loss: 0.5596 - acc: 0.9732 - mDice: 0.7928 - val_loss: 0.6404 - val_acc: 0.9817 - val_mDice: 0.7777

Epoch 00127: val_mDice did not improve from 0.78121
Epoch 128/300
 - 27s - loss: 0.5597 - acc: 0.9731 - mDice: 0.7927 - val_loss: 0.6457 - val_acc: 0.9814 - val_mDice: 0.7790

Epoch 00128: val_mDice did not improve from 0.78121
Epoch 129/300
 - 25s - loss: 0.5589 - acc: 0.9732 - mDice: 0.7929 - val_loss: 0.6409 - val_acc: 0.9813 - val_mDice: 0.7793

Epoch 00129: val_mDice did not improve from 0.78121
Epoch 130/300
 - 26s - loss: 0.5601 - acc: 0.9732 - mDice: 0.7925 - val_loss: 0.6304 - val_acc: 0.9820 - val_mDice: 0.7786

Epoch 00130: val_mDice did not improve from 0.78121
Epoch 131/300
 - 24s - loss: 0.5589 - acc: 0.9732 - mDice: 0.7927 - val_loss: 0.6290 - val_acc: 0.9822 - val_mDice: 0.7809

Epoch 00131: val_mDice did not improve from 0.78121
Epoch 132/300
 - 25s - loss: 0.5578 - acc: 0.9732 - mDice: 0.7933 - val_loss: 0.6426 - val_acc: 0.9817 - val_mDice: 0.7769

Epoch 00132: val_mDice did not improve from 0.78121
Epoch 133/300
 - 26s - loss: 0.5583 - acc: 0.9732 - mDice: 0.7929 - val_loss: 0.6486 - val_acc: 0.9814 - val_mDice: 0.7759

Epoch 00133: val_mDice did not improve from 0.78121
Epoch 134/300
 - 24s - loss: 0.5580 - acc: 0.9732 - mDice: 0.7934 - val_loss: 0.6254 - val_acc: 0.9821 - val_mDice: 0.7807

Epoch 00134: val_mDice did not improve from 0.78121
Epoch 135/300
 - 25s - loss: 0.5568 - acc: 0.9732 - mDice: 0.7939 - val_loss: 0.6359 - val_acc: 0.9819 - val_mDice: 0.7774

Epoch 00135: val_mDice did not improve from 0.78121
Epoch 136/300
 - 25s - loss: 0.5572 - acc: 0.9733 - mDice: 0.7933 - val_loss: 0.6514 - val_acc: 0.9821 - val_mDice: 0.7791

Epoch 00136: val_mDice did not improve from 0.78121
Epoch 137/300
 - 24s - loss: 0.5567 - acc: 0.9733 - mDice: 0.7937 - val_loss: 0.6402 - val_acc: 0.9817 - val_mDice: 0.7822

Epoch 00137: val_mDice improved from 0.78121 to 0.78216, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 138/300
 - 26s - loss: 0.5560 - acc: 0.9733 - mDice: 0.7941 - val_loss: 0.6467 - val_acc: 0.9821 - val_mDice: 0.7793

Epoch 00138: val_mDice did not improve from 0.78216
Epoch 139/300
 - 25s - loss: 0.5537 - acc: 0.9733 - mDice: 0.7949 - val_loss: 0.6458 - val_acc: 0.9819 - val_mDice: 0.7752

Epoch 00139: val_mDice did not improve from 0.78216
Epoch 140/300
 - 24s - loss: 0.5553 - acc: 0.9733 - mDice: 0.7942 - val_loss: 0.6305 - val_acc: 0.9822 - val_mDice: 0.7801

Epoch 00140: val_mDice did not improve from 0.78216
Epoch 141/300
 - 26s - loss: 0.5543 - acc: 0.9733 - mDice: 0.7946 - val_loss: 0.6332 - val_acc: 0.9818 - val_mDice: 0.7789

Epoch 00141: val_mDice did not improve from 0.78216
Epoch 142/300
 - 25s - loss: 0.5552 - acc: 0.9733 - mDice: 0.7942 - val_loss: 0.6381 - val_acc: 0.9823 - val_mDice: 0.7800

Epoch 00142: val_mDice did not improve from 0.78216
Epoch 143/300
 - 26s - loss: 0.5531 - acc: 0.9733 - mDice: 0.7952 - val_loss: 0.6276 - val_acc: 0.9818 - val_mDice: 0.7798

Epoch 00143: val_mDice did not improve from 0.78216
Epoch 144/300
 - 24s - loss: 0.5537 - acc: 0.9733 - mDice: 0.7949 - val_loss: 0.6409 - val_acc: 0.9817 - val_mDice: 0.7791

Epoch 00144: val_mDice did not improve from 0.78216
Epoch 145/300
 - 26s - loss: 0.5534 - acc: 0.9733 - mDice: 0.7948 - val_loss: 0.6258 - val_acc: 0.9821 - val_mDice: 0.7809

Epoch 00145: val_mDice did not improve from 0.78216
Epoch 146/300
 - 25s - loss: 0.5538 - acc: 0.9733 - mDice: 0.7948 - val_loss: 0.6426 - val_acc: 0.9819 - val_mDice: 0.7742

Epoch 00146: val_mDice did not improve from 0.78216
Epoch 147/300
 - 24s - loss: 0.5523 - acc: 0.9733 - mDice: 0.7953 - val_loss: 0.6382 - val_acc: 0.9824 - val_mDice: 0.7833

Epoch 00147: val_mDice improved from 0.78216 to 0.78334, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 148/300
 - 25s - loss: 0.5530 - acc: 0.9733 - mDice: 0.7951 - val_loss: 0.6242 - val_acc: 0.9820 - val_mDice: 0.7797

Epoch 00148: val_mDice did not improve from 0.78334
Epoch 149/300
 - 26s - loss: 0.5518 - acc: 0.9734 - mDice: 0.7954 - val_loss: 0.6334 - val_acc: 0.9821 - val_mDice: 0.7797

Epoch 00149: val_mDice did not improve from 0.78334
Epoch 150/300
 - 24s - loss: 0.5503 - acc: 0.9734 - mDice: 0.7958 - val_loss: 0.6468 - val_acc: 0.9815 - val_mDice: 0.7772

Epoch 00150: val_mDice did not improve from 0.78334
Epoch 151/300
 - 25s - loss: 0.5509 - acc: 0.9734 - mDice: 0.7958 - val_loss: 0.6483 - val_acc: 0.9818 - val_mDice: 0.7740

Epoch 00151: val_mDice did not improve from 0.78334
Epoch 152/300
 - 27s - loss: 0.5504 - acc: 0.9734 - mDice: 0.7960 - val_loss: 0.6331 - val_acc: 0.9822 - val_mDice: 0.7782

Epoch 00152: val_mDice did not improve from 0.78334
Epoch 153/300
 - 27s - loss: 0.5508 - acc: 0.9733 - mDice: 0.7960 - val_loss: 0.6333 - val_acc: 0.9823 - val_mDice: 0.7815

Epoch 00153: val_mDice did not improve from 0.78334
Epoch 154/300
 - 27s - loss: 0.5482 - acc: 0.9734 - mDice: 0.7968 - val_loss: 0.6321 - val_acc: 0.9823 - val_mDice: 0.7807

Epoch 00154: val_mDice did not improve from 0.78334
Epoch 155/300
 - 27s - loss: 0.5512 - acc: 0.9734 - mDice: 0.7957 - val_loss: 0.6260 - val_acc: 0.9823 - val_mDice: 0.7800

Epoch 00155: val_mDice did not improve from 0.78334
Epoch 156/300
 - 27s - loss: 0.5506 - acc: 0.9734 - mDice: 0.7961 - val_loss: 0.6342 - val_acc: 0.9821 - val_mDice: 0.7785

Epoch 00156: val_mDice did not improve from 0.78334
Epoch 157/300
 - 27s - loss: 0.5486 - acc: 0.9734 - mDice: 0.7965 - val_loss: 0.6300 - val_acc: 0.9824 - val_mDice: 0.7822

Epoch 00157: val_mDice did not improve from 0.78334
Epoch 158/300
 - 27s - loss: 0.5488 - acc: 0.9734 - mDice: 0.7969 - val_loss: 0.6349 - val_acc: 0.9819 - val_mDice: 0.7816

Epoch 00158: val_mDice did not improve from 0.78334
Epoch 159/300
 - 27s - loss: 0.5492 - acc: 0.9734 - mDice: 0.7966 - val_loss: 0.6353 - val_acc: 0.9818 - val_mDice: 0.7800

Epoch 00159: val_mDice did not improve from 0.78334
Epoch 160/300
 - 26s - loss: 0.5484 - acc: 0.9734 - mDice: 0.7968 - val_loss: 0.6326 - val_acc: 0.9819 - val_mDice: 0.7810

Epoch 00160: val_mDice did not improve from 0.78334
Epoch 161/300
 - 27s - loss: 0.5464 - acc: 0.9735 - mDice: 0.7976 - val_loss: 0.6456 - val_acc: 0.9821 - val_mDice: 0.7796

Epoch 00161: val_mDice did not improve from 0.78334
Epoch 162/300
 - 27s - loss: 0.5491 - acc: 0.9734 - mDice: 0.7966 - val_loss: 0.6266 - val_acc: 0.9821 - val_mDice: 0.7804

Epoch 00162: val_mDice did not improve from 0.78334
Epoch 163/300
 - 26s - loss: 0.5470 - acc: 0.9735 - mDice: 0.7971 - val_loss: 0.6309 - val_acc: 0.9821 - val_mDice: 0.7835

Epoch 00163: val_mDice improved from 0.78334 to 0.78353, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 164/300
 - 27s - loss: 0.5462 - acc: 0.9735 - mDice: 0.7977 - val_loss: 0.6370 - val_acc: 0.9820 - val_mDice: 0.7831

Epoch 00164: val_mDice did not improve from 0.78353
Epoch 165/300
 - 27s - loss: 0.5460 - acc: 0.9735 - mDice: 0.7978 - val_loss: 0.6371 - val_acc: 0.9823 - val_mDice: 0.7811

Epoch 00165: val_mDice did not improve from 0.78353
Epoch 166/300
 - 28s - loss: 0.5459 - acc: 0.9735 - mDice: 0.7977 - val_loss: 0.6384 - val_acc: 0.9818 - val_mDice: 0.7815

Epoch 00166: val_mDice did not improve from 0.78353
Epoch 167/300
 - 27s - loss: 0.5461 - acc: 0.9735 - mDice: 0.7971 - val_loss: 0.6335 - val_acc: 0.9825 - val_mDice: 0.7826

Epoch 00167: val_mDice did not improve from 0.78353
Epoch 168/300
 - 27s - loss: 0.5452 - acc: 0.9735 - mDice: 0.7981 - val_loss: 0.6352 - val_acc: 0.9821 - val_mDice: 0.7792

Epoch 00168: val_mDice did not improve from 0.78353
Epoch 169/300
 - 27s - loss: 0.5446 - acc: 0.9735 - mDice: 0.7982 - val_loss: 0.6344 - val_acc: 0.9824 - val_mDice: 0.7813

Epoch 00169: val_mDice did not improve from 0.78353
Epoch 170/300
 - 28s - loss: 0.5443 - acc: 0.9735 - mDice: 0.7982 - val_loss: 0.6313 - val_acc: 0.9825 - val_mDice: 0.7824

Epoch 00170: val_mDice did not improve from 0.78353
Epoch 171/300
 - 28s - loss: 0.5444 - acc: 0.9735 - mDice: 0.7984 - val_loss: 0.6311 - val_acc: 0.9824 - val_mDice: 0.7837

Epoch 00171: val_mDice improved from 0.78353 to 0.78368, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 172/300
 - 28s - loss: 0.5454 - acc: 0.9735 - mDice: 0.7978 - val_loss: 0.6356 - val_acc: 0.9824 - val_mDice: 0.7806

Epoch 00172: val_mDice did not improve from 0.78368
Epoch 173/300
 - 29s - loss: 0.5450 - acc: 0.9735 - mDice: 0.7981 - val_loss: 0.6344 - val_acc: 0.9825 - val_mDice: 0.7788

Epoch 00173: val_mDice did not improve from 0.78368
Epoch 174/300
 - 29s - loss: 0.5452 - acc: 0.9735 - mDice: 0.7980 - val_loss: 0.6286 - val_acc: 0.9817 - val_mDice: 0.7834

Epoch 00174: val_mDice did not improve from 0.78368
Epoch 175/300
 - 28s - loss: 0.5429 - acc: 0.9736 - mDice: 0.7987 - val_loss: 0.6434 - val_acc: 0.9817 - val_mDice: 0.7799

Epoch 00175: val_mDice did not improve from 0.78368
Epoch 176/300
 - 28s - loss: 0.5433 - acc: 0.9735 - mDice: 0.7987 - val_loss: 0.6561 - val_acc: 0.9821 - val_mDice: 0.7785

Epoch 00176: val_mDice did not improve from 0.78368
Epoch 177/300
 - 28s - loss: 0.5446 - acc: 0.9735 - mDice: 0.7981 - val_loss: 0.6334 - val_acc: 0.9823 - val_mDice: 0.7794

Epoch 00177: val_mDice did not improve from 0.78368
Epoch 178/300
 - 28s - loss: 0.5410 - acc: 0.9735 - mDice: 0.7995 - val_loss: 0.6360 - val_acc: 0.9826 - val_mDice: 0.7838

Epoch 00178: val_mDice improved from 0.78368 to 0.78376, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 179/300
 - 28s - loss: 0.5414 - acc: 0.9736 - mDice: 0.7994 - val_loss: 0.6394 - val_acc: 0.9824 - val_mDice: 0.7827

Epoch 00179: val_mDice did not improve from 0.78376
Epoch 180/300
 - 27s - loss: 0.5424 - acc: 0.9735 - mDice: 0.7991 - val_loss: 0.6466 - val_acc: 0.9818 - val_mDice: 0.7821

Epoch 00180: val_mDice did not improve from 0.78376
Epoch 181/300
 - 26s - loss: 0.5413 - acc: 0.9736 - mDice: 0.7994 - val_loss: 0.6364 - val_acc: 0.9822 - val_mDice: 0.7834

Epoch 00181: val_mDice did not improve from 0.78376
Epoch 182/300
 - 27s - loss: 0.5417 - acc: 0.9736 - mDice: 0.7993 - val_loss: 0.6414 - val_acc: 0.9817 - val_mDice: 0.7804

Epoch 00182: val_mDice did not improve from 0.78376
Epoch 183/300
 - 24s - loss: 0.5417 - acc: 0.9736 - mDice: 0.7991 - val_loss: 0.6424 - val_acc: 0.9819 - val_mDice: 0.7835

Epoch 00183: val_mDice did not improve from 0.78376
Epoch 184/300
 - 25s - loss: 0.5410 - acc: 0.9736 - mDice: 0.7995 - val_loss: 0.6373 - val_acc: 0.9823 - val_mDice: 0.7819

Epoch 00184: val_mDice did not improve from 0.78376
Epoch 185/300
 - 26s - loss: 0.5412 - acc: 0.9736 - mDice: 0.7993 - val_loss: 0.6392 - val_acc: 0.9824 - val_mDice: 0.7799

Epoch 00185: val_mDice did not improve from 0.78376
Epoch 186/300
 - 24s - loss: 0.5412 - acc: 0.9736 - mDice: 0.7995 - val_loss: 0.6398 - val_acc: 0.9817 - val_mDice: 0.7827

Epoch 00186: val_mDice did not improve from 0.78376
Epoch 187/300
 - 24s - loss: 0.5409 - acc: 0.9736 - mDice: 0.7998 - val_loss: 0.6411 - val_acc: 0.9820 - val_mDice: 0.7785

Epoch 00187: val_mDice did not improve from 0.78376
Epoch 188/300
 - 26s - loss: 0.5411 - acc: 0.9736 - mDice: 0.7998 - val_loss: 0.6406 - val_acc: 0.9820 - val_mDice: 0.7833

Epoch 00188: val_mDice did not improve from 0.78376
Epoch 189/300
 - 25s - loss: 0.5404 - acc: 0.9736 - mDice: 0.7999 - val_loss: 0.6486 - val_acc: 0.9820 - val_mDice: 0.7808

Epoch 00189: val_mDice did not improve from 0.78376
Epoch 190/300
 - 24s - loss: 0.5403 - acc: 0.9736 - mDice: 0.7996 - val_loss: 0.6348 - val_acc: 0.9819 - val_mDice: 0.7835

Epoch 00190: val_mDice did not improve from 0.78376
Epoch 191/300
 - 24s - loss: 0.5404 - acc: 0.9736 - mDice: 0.7997 - val_loss: 0.6349 - val_acc: 0.9825 - val_mDice: 0.7814

Epoch 00191: val_mDice did not improve from 0.78376
Epoch 192/300
 - 26s - loss: 0.5398 - acc: 0.9736 - mDice: 0.7998 - val_loss: 0.6454 - val_acc: 0.9818 - val_mDice: 0.7804

Epoch 00192: val_mDice did not improve from 0.78376
Epoch 193/300
 - 25s - loss: 0.5401 - acc: 0.9736 - mDice: 0.7998 - val_loss: 0.6381 - val_acc: 0.9813 - val_mDice: 0.7813

Epoch 00193: val_mDice did not improve from 0.78376
Epoch 194/300
 - 24s - loss: 0.5392 - acc: 0.9736 - mDice: 0.8002 - val_loss: 0.6424 - val_acc: 0.9820 - val_mDice: 0.7818

Epoch 00194: val_mDice did not improve from 0.78376
Epoch 195/300
 - 25s - loss: 0.5385 - acc: 0.9736 - mDice: 0.8007 - val_loss: 0.6355 - val_acc: 0.9817 - val_mDice: 0.7809

Epoch 00195: val_mDice did not improve from 0.78376
Epoch 196/300
 - 26s - loss: 0.5376 - acc: 0.9737 - mDice: 0.8009 - val_loss: 0.6413 - val_acc: 0.9822 - val_mDice: 0.7813

Epoch 00196: val_mDice did not improve from 0.78376
Epoch 197/300
 - 24s - loss: 0.5384 - acc: 0.9737 - mDice: 0.8005 - val_loss: 0.6356 - val_acc: 0.9819 - val_mDice: 0.7845

Epoch 00197: val_mDice improved from 0.78376 to 0.78445, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 198/300
 - 24s - loss: 0.5377 - acc: 0.9737 - mDice: 0.8008 - val_loss: 0.6408 - val_acc: 0.9822 - val_mDice: 0.7774

Epoch 00198: val_mDice did not improve from 0.78445
Epoch 199/300
 - 26s - loss: 0.5373 - acc: 0.9737 - mDice: 0.8008 - val_loss: 0.6427 - val_acc: 0.9824 - val_mDice: 0.7834

Epoch 00199: val_mDice did not improve from 0.78445
Epoch 200/300
 - 25s - loss: 0.5392 - acc: 0.9736 - mDice: 0.8003 - val_loss: 0.6440 - val_acc: 0.9820 - val_mDice: 0.7837

Epoch 00200: val_mDice did not improve from 0.78445
Epoch 201/300
 - 24s - loss: 0.5375 - acc: 0.9737 - mDice: 0.8008 - val_loss: 0.6499 - val_acc: 0.9820 - val_mDice: 0.7793

Epoch 00201: val_mDice did not improve from 0.78445
Epoch 202/300
 - 24s - loss: 0.5383 - acc: 0.9737 - mDice: 0.8007 - val_loss: 0.6474 - val_acc: 0.9821 - val_mDice: 0.7799

Epoch 00202: val_mDice did not improve from 0.78445
Epoch 203/300
 - 26s - loss: 0.5372 - acc: 0.9737 - mDice: 0.8009 - val_loss: 0.6449 - val_acc: 0.9822 - val_mDice: 0.7814

Epoch 00203: val_mDice did not improve from 0.78445
Epoch 204/300
 - 25s - loss: 0.5378 - acc: 0.9737 - mDice: 0.8009 - val_loss: 0.6417 - val_acc: 0.9819 - val_mDice: 0.7808

Epoch 00204: val_mDice did not improve from 0.78445
Epoch 205/300
 - 24s - loss: 0.5365 - acc: 0.9737 - mDice: 0.8014 - val_loss: 0.6431 - val_acc: 0.9820 - val_mDice: 0.7809

Epoch 00205: val_mDice did not improve from 0.78445
Epoch 206/300
 - 24s - loss: 0.5368 - acc: 0.9737 - mDice: 0.8009 - val_loss: 0.6445 - val_acc: 0.9823 - val_mDice: 0.7811

Epoch 00206: val_mDice did not improve from 0.78445
Epoch 207/300
 - 26s - loss: 0.5369 - acc: 0.9737 - mDice: 0.8010 - val_loss: 0.6504 - val_acc: 0.9814 - val_mDice: 0.7823

Epoch 00207: val_mDice did not improve from 0.78445
Epoch 208/300
 - 25s - loss: 0.5365 - acc: 0.9737 - mDice: 0.8012 - val_loss: 0.6391 - val_acc: 0.9828 - val_mDice: 0.7828

Epoch 00208: val_mDice did not improve from 0.78445
Epoch 209/300
 - 24s - loss: 0.5358 - acc: 0.9737 - mDice: 0.8012 - val_loss: 0.6423 - val_acc: 0.9822 - val_mDice: 0.7828

Epoch 00209: val_mDice did not improve from 0.78445
Epoch 210/300
 - 24s - loss: 0.5364 - acc: 0.9737 - mDice: 0.8013 - val_loss: 0.6474 - val_acc: 0.9817 - val_mDice: 0.7829

Epoch 00210: val_mDice did not improve from 0.78445
Epoch 211/300
 - 26s - loss: 0.5366 - acc: 0.9737 - mDice: 0.8011 - val_loss: 0.6308 - val_acc: 0.9824 - val_mDice: 0.7827

Epoch 00211: val_mDice did not improve from 0.78445
Epoch 212/300
 - 25s - loss: 0.5354 - acc: 0.9737 - mDice: 0.8016 - val_loss: 0.6339 - val_acc: 0.9824 - val_mDice: 0.7817

Epoch 00212: val_mDice did not improve from 0.78445
Epoch 213/300
 - 24s - loss: 0.5347 - acc: 0.9737 - mDice: 0.8018 - val_loss: 0.6434 - val_acc: 0.9819 - val_mDice: 0.7815

Epoch 00213: val_mDice did not improve from 0.78445
Epoch 214/300
 - 24s - loss: 0.5340 - acc: 0.9737 - mDice: 0.8023 - val_loss: 0.6447 - val_acc: 0.9824 - val_mDice: 0.7831

Epoch 00214: val_mDice did not improve from 0.78445
Epoch 215/300
 - 26s - loss: 0.5346 - acc: 0.9737 - mDice: 0.8020 - val_loss: 0.6369 - val_acc: 0.9824 - val_mDice: 0.7820

Epoch 00215: val_mDice did not improve from 0.78445
Epoch 216/300
 - 25s - loss: 0.5335 - acc: 0.9737 - mDice: 0.8025 - val_loss: 0.6478 - val_acc: 0.9820 - val_mDice: 0.7818

Epoch 00216: val_mDice did not improve from 0.78445
Epoch 217/300
 - 24s - loss: 0.5344 - acc: 0.9737 - mDice: 0.8020 - val_loss: 0.6395 - val_acc: 0.9824 - val_mDice: 0.7830

Epoch 00217: val_mDice did not improve from 0.78445
Epoch 218/300
 - 24s - loss: 0.5344 - acc: 0.9738 - mDice: 0.8022 - val_loss: 0.6428 - val_acc: 0.9817 - val_mDice: 0.7809

Epoch 00218: val_mDice did not improve from 0.78445
Epoch 219/300
 - 26s - loss: 0.5342 - acc: 0.9737 - mDice: 0.8021 - val_loss: 0.6400 - val_acc: 0.9820 - val_mDice: 0.7829

Epoch 00219: val_mDice did not improve from 0.78445
Epoch 220/300
 - 25s - loss: 0.5333 - acc: 0.9738 - mDice: 0.8024 - val_loss: 0.6541 - val_acc: 0.9822 - val_mDice: 0.7816

Epoch 00220: val_mDice did not improve from 0.78445
Epoch 221/300
 - 24s - loss: 0.5325 - acc: 0.9738 - mDice: 0.8026 - val_loss: 0.6392 - val_acc: 0.9819 - val_mDice: 0.7824

Epoch 00221: val_mDice did not improve from 0.78445
Epoch 222/300
 - 25s - loss: 0.5322 - acc: 0.9738 - mDice: 0.8026 - val_loss: 0.6411 - val_acc: 0.9823 - val_mDice: 0.7834

Epoch 00222: val_mDice did not improve from 0.78445
Epoch 223/300
 - 26s - loss: 0.5334 - acc: 0.9738 - mDice: 0.8025 - val_loss: 0.6478 - val_acc: 0.9824 - val_mDice: 0.7785

Epoch 00223: val_mDice did not improve from 0.78445
Epoch 224/300
 - 25s - loss: 0.5323 - acc: 0.9738 - mDice: 0.8025 - val_loss: 0.6495 - val_acc: 0.9820 - val_mDice: 0.7818

Epoch 00224: val_mDice did not improve from 0.78445
Epoch 225/300
 - 25s - loss: 0.5322 - acc: 0.9738 - mDice: 0.8026 - val_loss: 0.6308 - val_acc: 0.9823 - val_mDice: 0.7816

Epoch 00225: val_mDice did not improve from 0.78445
Epoch 226/300
 - 25s - loss: 0.5325 - acc: 0.9738 - mDice: 0.8026 - val_loss: 0.6432 - val_acc: 0.9824 - val_mDice: 0.7797

Epoch 00226: val_mDice did not improve from 0.78445
Epoch 227/300
 - 26s - loss: 0.5319 - acc: 0.9738 - mDice: 0.8028 - val_loss: 0.6428 - val_acc: 0.9817 - val_mDice: 0.7844

Epoch 00227: val_mDice did not improve from 0.78445
Restoring model weights from the end of the best epoch
Epoch 00227: early stopping
{'val_loss': [3.453322178562113, 2.2808817103428245, 1.5502989823604147, 1.1426161509180217, 0.9768386863333522, 0.8709764660819519, 0.8227261657931364, 0.7869530713533592, 0.7736612165306375, 0.7535140007826566, 0.7257982104924441, 0.7233296533118091, 0.7011279181737772, 0.6993584783576713, 0.6877762638378438, 0.6920918534414687, 0.7332455288884071, 0.6909337377462101, 0.6698278785982122, 0.6696455653053319, 0.6732402914448788, 0.6655163699136307, 0.6578576586625401, 0.64324251395507, 0.6639480744599066, 0.701373753625173, 0.6553049114281917, 0.6447771722441241, 0.6640084539958198, 0.6478991048992971, 0.6364603581135733, 0.6423450164320053, 0.65276435703439, 0.6437496850180552, 0.635951162430278, 0.6329850288429004, 0.6317114634410516, 0.6547070993850598, 0.6316552342706666, 0.6389937101564417, 0.6276561476989919, 0.6380028936885089, 0.6374684217298486, 0.6308630592928829, 0.640791032920804, 0.6358746557474383, 0.6263527640740323, 0.6346069777036476, 0.6224872887257575, 0.647004879849614, 0.6265262712266054, 0.6206708214600389, 0.6333684817925326, 0.6129105549663213, 0.6258970396622047, 0.6198566643938315, 0.6215810262750915, 0.6240915728365797, 0.6222184433902627, 0.6215900455527508, 0.6260852376373929, 0.6275455437454522, 0.6365161718352783, 0.6247342488468001, 0.6252596872878886, 0.6308533599748208, 0.6308810839773578, 0.6403695538378599, 0.6313240786762553, 0.6395639461014416, 0.6225613098518521, 0.621019595332436, 0.6238842549338799, 0.6227735937933435, 0.6199418367554652, 0.623208831153787, 0.629450905833574, 0.6387782838383941, 0.6296986240290021, 0.6250887887150633, 0.6319587612361238, 0.6331737825129915, 0.6300888704933741, 0.6290640880817968, 0.6256728795106197, 0.6273119637225557, 0.6248675667218503, 0.6327374698392378, 0.6135467405289688, 0.6404163608917633, 0.6372127113142988, 0.6394620670622716, 0.6301743633606854, 0.6226349604326628, 0.6324530786405038, 0.6460777260939772, 0.6255016338591483, 0.6418394768078137, 0.6260430060242475, 0.6269761071731678, 0.6337801128533602, 0.6244648976714742, 0.6382252533676946, 0.633414346982328, 0.6319899730638084, 0.6439234700795913, 0.6330604116490997, 0.6337486071237224, 0.6319076759650365, 0.6436570693341818, 0.627944911196751, 0.6325024803725559, 0.6411405010735164, 0.6291013182870375, 0.638688315640293, 0.6347650124069584, 0.6245434020633422, 0.6266686381508815, 0.6269398338715974, 0.6347881541717163, 0.6319444042364264, 0.6324677666951013, 0.6345681130455497, 0.6448826312834264, 0.6397889295537159, 0.6308794712380605, 0.6404428683813388, 0.6457053200256222, 0.6408930041964701, 0.6303515071654836, 0.6290100498280659, 0.6426411794558152, 0.648600066962995, 0.625436836259653, 0.6359459767954269, 0.6514096622988659, 0.6402451463343558, 0.6466727581863186, 0.6457994921350134, 0.6304948785725761, 0.6331797010266251, 0.6380574962179973, 0.6276254983939868, 0.6409362318346006, 0.6258460113815233, 0.6425707634573012, 0.6382075525720299, 0.624205760942278, 0.6334215091354953, 0.646753459123143, 0.6482986552242893, 0.6330520528511858, 0.633290451254515, 0.6321447580529932, 0.625956349144041, 0.6342429764130536, 0.6299511106575236, 0.6348566900711926, 0.6353410610965654, 0.6326056224273824, 0.6456398632688788, 0.6265523347876758, 0.6309008537738808, 0.6369512164186767, 0.6370600757522603, 0.6383712712456199, 0.633470449961868, 0.6351651106456485, 0.634410244238758, 0.6312695876056073, 0.6310607201666778, 0.6355644616733763, 0.6344350585319924, 0.6285985601514239, 0.6434029202958256, 0.6561062283683241, 0.6334387406291607, 0.6360431616458854, 0.6393733970028943, 0.6465918745295797, 0.6364443484228585, 0.6414349655494848, 0.6423758413831023, 0.6373273298159718, 0.639213539652288, 0.6398435296535, 0.6410681123703995, 0.6405634929582676, 0.6486456103553713, 0.6347718632196617, 0.6348695021172672, 0.6453834057653898, 0.638148355410195, 0.6424496313797308, 0.6354908801699817, 0.6413177014073843, 0.6356353778834191, 0.640841372703251, 0.6426889892394575, 0.6439563122081068, 0.649918770334915, 0.6473781973953956, 0.6448957455662628, 0.6417426292864284, 0.6430993351097324, 0.6445236823937718, 0.6504415565846013, 0.6390546896447831, 0.642344218412543, 0.6474044484742778, 0.6307756721481327, 0.6339315839411673, 0.6434226441125014, 0.6446647703709125, 0.6368949396691456, 0.6477795096250757, 0.639479927264992, 0.6428052946017868, 0.6399774925689087, 0.6540514886440754, 0.6391693266306622, 0.6411216665286151, 0.6478004661322379, 0.6495384029559675, 0.6307702711615154, 0.6432406199544329, 0.6427939188800237], 'val_acc': [0.9212639012572935, 0.9318589287030562, 0.9572506558661368, 0.9688905075238585, 0.9736983662296251, 0.9757560941826079, 0.9747961763873065, 0.9769865188313219, 0.9768371228955233, 0.9773580439934667, 0.9774988886003524, 0.9783670028788879, 0.9780714807126544, 0.9791686413703934, 0.979143616892359, 0.9787250475494731, 0.9786328976614433, 0.9793914187434288, 0.9797876399737024, 0.979912680922647, 0.9792262291145521, 0.9800653680313236, 0.9805093119141979, 0.9803740504602406, 0.9805385931111464, 0.9802437390828403, 0.9810499885995075, 0.9813744586318639, 0.98088973643733, 0.9811497023108082, 0.9815837545291558, 0.9811559577229345, 0.9810621611720145, 0.9810542662938436, 0.9814919374183482, 0.981664380852529, 0.9815482020501136, 0.9816995864067039, 0.9813668817066433, 0.9808400251178918, 0.9815547942377096, 0.9809407287337831, 0.9813372708695591, 0.9813728154751292, 0.9810131277708323, 0.9803513418902308, 0.9816591103625617, 0.9814889752089793, 0.9816123832736099, 0.9814284323292743, 0.9819154690785796, 0.9816064716492644, 0.9821181839218572, 0.9820572861823013, 0.9812665266149184, 0.9810832218489042, 0.9817983056000512, 0.9817571823318922, 0.9810466982262791, 0.9821287020810249, 0.981707488912301, 0.9819361948253447, 0.9812977796860647, 0.9819960886971992, 0.9817111132929814, 0.9820589430561006, 0.9817176890570066, 0.9818595150798959, 0.9819796354162926, 0.9819141424600308, 0.9820724309290403, 0.9817654082034517, 0.9819681172031367, 0.9816239000720013, 0.9821336356109879, 0.9819263232135674, 0.9815044473814398, 0.981637714817059, 0.9818897994064079, 0.9822629789818921, 0.98171767853854, 0.9814481670027301, 0.9813616266560629, 0.9813576762644253, 0.9820786830810571, 0.9816166520487782, 0.9822086661715749, 0.9819654810662363, 0.9822791045295196, 0.9810022689609704, 0.9818878083406218, 0.982199464297024, 0.9815988932477677, 0.9815472341051289, 0.9817308440297011, 0.9818624855933175, 0.9822231520686233, 0.9813023894194848, 0.9818364892335623, 0.981997736036716, 0.981963503963561, 0.9820885444204136, 0.9818335187201407, 0.9819496884188539, 0.9821076369753071, 0.9816498869589854, 0.9823781472118523, 0.9823639910164509, 0.9815205766197574, 0.9816999197990409, 0.982332077988407, 0.9819960902964983, 0.9816087593235099, 0.9822011055469021, 0.9820684904407545, 0.9821326533338234, 0.9822807443031216, 0.9819148045698309, 0.9819427827071356, 0.9816387077972247, 0.9819756844095401, 0.9817176972995478, 0.9821431908691138, 0.9818825563041049, 0.9819315892131951, 0.9820250515721285, 0.9817357877090619, 0.9813981505862454, 0.9812852847932908, 0.982043138967579, 0.9822353309768149, 0.9817417047464195, 0.9814076874524325, 0.9820915210849852, 0.9818717081972443, 0.9820658573179176, 0.9817331604913292, 0.982086907537852, 0.9818901184665653, 0.9821547070523903, 0.9818206915422367, 0.9823264805648103, 0.9817617829000986, 0.981690036807636, 0.9821056687917995, 0.9818944032962355, 0.9824133636535629, 0.9820095900411576, 0.9821405443982812, 0.9815166103581526, 0.9817644173761886, 0.9822155881223295, 0.982289617644744, 0.9823179307736849, 0.9823445733117614, 0.9821194947934618, 0.9823975644244498, 0.9818581962733077, 0.9818456936300847, 0.9819019717943803, 0.9820921800576988, 0.9820872414222812, 0.9821033691843227, 0.98204776143388, 0.9822797487394729, 0.9817677023364049, 0.9825058287880369, 0.9821431907460908, 0.9824130370274909, 0.9824788588857503, 0.9823840841174248, 0.9824304666189463, 0.9825417086928007, 0.9817492708456159, 0.9816528501525383, 0.9820872512026099, 0.9822787686767224, 0.9825584862623421, 0.9824275069930605, 0.9818476677186964, 0.9822103173248047, 0.9817186733640507, 0.9819128199627525, 0.9823287828787931, 0.9824479115882772, 0.9817025478779347, 0.9819944340993253, 0.981954624040208, 0.981995755304862, 0.981866763472188, 0.9824564723899613, 0.9818463506344303, 0.9813037034896874, 0.9819799616732957, 0.9817157122618889, 0.9821635842077258, 0.9818769586959737, 0.9822096651183563, 0.9823705741618562, 0.9820131933233932, 0.9820345948355117, 0.9821073252350184, 0.9822070313188929, 0.9819190885998517, 0.9819839209841009, 0.9823083781605535, 0.9814461916223768, 0.9827500115484153, 0.9821510885768139, 0.9816798487191845, 0.9823528144996848, 0.9823995387591076, 0.9819289530762947, 0.9824199463683877, 0.9823686109607803, 0.9820263631818711, 0.9823926206835776, 0.9816979374063766, 0.9820339252828199, 0.9821517456426709, 0.9819016409855262, 0.982330765332969, 0.9823699240467989, 0.9819832575825592, 0.9822629683404023, 0.9824047987306082, 0.9817249252700215], 'val_mDice': [0.05943224029336797, 0.19462395709304003, 0.388020561637032, 0.5355832663482926, 0.6047388451756338, 0.6533072136257947, 0.678546107221314, 0.6903187917974096, 0.7028160670962496, 0.7111851894695569, 0.7214142401521051, 0.7256567219831626, 0.7319854722426525, 0.7311702716338253, 0.7374882251485583, 0.7381149513802662, 0.7286494470848265, 0.7414229474077529, 0.7431104083548389, 0.7477148437893674, 0.7465873683569232, 0.7476110797302395, 0.7500125608946148, 0.7547768480514472, 0.7494387953889137, 0.7438048191976006, 0.7503337948683984, 0.7530807822604421, 0.7569170747379032, 0.7576275740368571, 0.7603398880107238, 0.759801120519392, 0.7579272351274795, 0.7609777838699097, 0.7609704901436412, 0.76429107849812, 0.761025887832307, 0.7594762499241391, 0.762827127895119, 0.7635939061580181, 0.7674157412797674, 0.7692728519316674, 0.7637968205446061, 0.7664426627296904, 0.7640800468077723, 0.7668218545008247, 0.7710127872333192, 0.7686432679986314, 0.7670986467839763, 0.7668489196844268, 0.7675291932773295, 0.7697345404679069, 0.7677394496767145, 0.7720337447982332, 0.7707669775552425, 0.7727495504483596, 0.7720213760655484, 0.7750384771909999, 0.7741176665013789, 0.7712976105195942, 0.7737609571224642, 0.7731884384548947, 0.7703246405373171, 0.7716836510427965, 0.7715450727656653, 0.7722430152297635, 0.7729685430802304, 0.7750835361495476, 0.7721390917943358, 0.7707674959741756, 0.7723625227270726, 0.7747475799515274, 0.7746792378440361, 0.7752245537882865, 0.7748379484664791, 0.7709000821699176, 0.7750587770936412, 0.7725411053781539, 0.7757605863552467, 0.776629950301443, 0.7747678716731391, 0.7754137674721402, 0.7750727357141005, 0.7767450801482264, 0.7799028247379544, 0.7771302058723812, 0.7799327416562689, 0.7750713742800418, 0.778155757054702, 0.7765016071075502, 0.7776770051664859, 0.7738774771906889, 0.7782943127571121, 0.7780725530303546, 0.7768569435497555, 0.7740756040756178, 0.7753740076679194, 0.7793254411257458, 0.7776269377569666, 0.7763509083581537, 0.7754774395649401, 0.7760576480928466, 0.7763111838615346, 0.7747027360986999, 0.7758810736077488, 0.776772234461994, 0.7795360863393306, 0.7760186603194789, 0.7795635547923353, 0.7783662046933445, 0.7754963679456366, 0.77842936814754, 0.7767231266934067, 0.7761488077687282, 0.7773324096165943, 0.7768551520272797, 0.781213946325245, 0.7786007615803934, 0.7784300766985237, 0.7787307972017333, 0.7797369924984234, 0.7783858050256813, 0.7791075464741734, 0.774653461756967, 0.7792662875448095, 0.7786615783093023, 0.7777223497844455, 0.7790265277689332, 0.7793214241786638, 0.778625039923917, 0.780897879809664, 0.7769012641857529, 0.7758692654293757, 0.7807227530592612, 0.7773846597617379, 0.7791176958718905, 0.7821644419733093, 0.7792762815644744, 0.7751926565686985, 0.7801242690952447, 0.778856756455881, 0.7800023096879816, 0.7798029244622702, 0.7790845989934924, 0.7808518350062847, 0.7741669276181389, 0.7833357439198607, 0.7797356907920325, 0.7796983100681482, 0.7772394135763525, 0.7739507949635217, 0.7782416138855666, 0.7814715821430533, 0.7807396766571069, 0.7799944504864814, 0.7785215925259978, 0.7821527910183335, 0.7815677014297745, 0.7800496101871487, 0.7809835139688939, 0.7796203665689049, 0.7803767300734702, 0.7835290182239623, 0.783075676982986, 0.7810651575694758, 0.7814740912587035, 0.7825604973070639, 0.7792160670331634, 0.7813097856731238, 0.7823699974792292, 0.7836780010485181, 0.7806326437537762, 0.7787789288443062, 0.7834311340492454, 0.7798727496120583, 0.7784981197986072, 0.7794190626764446, 0.7837578017645207, 0.7826835602306607, 0.7820535017363919, 0.7833703341129764, 0.780377325135734, 0.7835108973047435, 0.7819078887579242, 0.7799301921890739, 0.7826974332886215, 0.7785315786721906, 0.7832904758837201, 0.7807906103946107, 0.7834672126976698, 0.7813694582881081, 0.7803852969032815, 0.7812516622868115, 0.7817826173868957, 0.7809107141229021, 0.7812635431102678, 0.784452712572765, 0.7774296650822564, 0.7833960074758382, 0.7836766036302313, 0.7792868995568085, 0.7798725635397667, 0.7813723324745186, 0.7807760397347134, 0.7808518281169966, 0.7810983357660788, 0.7822524673921528, 0.7828061033205598, 0.7827757530537183, 0.7828771936389068, 0.7827039130947047, 0.7817372818111266, 0.7814869825315919, 0.7831000641403553, 0.7819998461149549, 0.7817581826811358, 0.7830208226254112, 0.7809460262765088, 0.7828951472468421, 0.7815564628479036, 0.7824310416161584, 0.7834166317901375, 0.7785046838139356, 0.7818341458791057, 0.7816158070529824, 0.7797325490305913, 0.7843719136481192], 'loss': [27.956913325733634, 3.8482538928899044, 2.689401873276403, 2.0031297032492015, 1.6538270948210507, 1.4520951037848795, 1.3162743952298808, 1.2219306497321027, 1.143678232191114, 1.0854596755001804, 1.042277214747498, 0.9987152158744244, 0.9591843678654023, 0.9316993296886646, 0.9019056920265565, 0.8789248666502508, 0.8575493084849108, 0.8399661690359729, 0.8243056826555049, 0.8132297489974503, 0.7976222159983806, 0.7858190397060882, 0.7760620409089397, 0.7638860966699744, 0.7552443168984412, 0.7450797301873917, 0.7404941335295561, 0.7315748279906698, 0.7225133174212246, 0.7160417394704115, 0.7096091444235529, 0.703516585575757, 0.6982622973483873, 0.693043859393038, 0.6866955145506635, 0.6850436662599811, 0.6788167373388685, 0.6733992254716956, 0.6703199906155007, 0.6675948487429679, 0.6627276418870749, 0.6617570448197925, 0.6546618787263497, 0.6542286308633988, 0.6510716435026377, 0.6483672236254542, 0.6454153203554247, 0.6425807990021657, 0.6402729199329538, 0.635444535157377, 0.6335073801272235, 0.6332865053752683, 0.6295789227384299, 0.6293901732529095, 0.6262645736276207, 0.6236761829926798, 0.6206939080705614, 0.6210158606125912, 0.6175102793233674, 0.6183236108130591, 0.6159426297183705, 0.6130019774692054, 0.6121696820898559, 0.610849353363584, 0.6084826635643893, 0.6066662882360605, 0.6073819768508522, 0.6038670719118314, 0.6025814330639063, 0.6016071773220253, 0.6006977591554162, 0.6009636693697485, 0.5966280472785384, 0.5969226921312217, 0.5961556873978935, 0.5955961146544294, 0.5944877882112829, 0.5927545606933404, 0.5912418051546958, 0.5902285828727339, 0.5899961452965865, 0.5882108277641904, 0.5870741611061445, 0.5860869965420608, 0.5856784629222457, 0.5867618980130405, 0.5854516957984609, 0.5837780000067623, 0.5834170115365599, 0.5815075981729435, 0.581131706110811, 0.579833512459816, 0.5797175125216482, 0.5791548086267568, 0.5774861798562325, 0.5774583189234632, 0.577192878698944, 0.5756762475878576, 0.5759017029112098, 0.5739800024458238, 0.5736329500846599, 0.574486212159416, 0.5745817062135582, 0.5706024043153458, 0.5704134302838821, 0.5695363457971067, 0.569472772546392, 0.5701057796962853, 0.5694268360887019, 0.5684238803544703, 0.5672911566390552, 0.5682341672510357, 0.5661723792431945, 0.5662191714766717, 0.5659032309214768, 0.5660771524419299, 0.5643288750643658, 0.5646609750978697, 0.5647963865691049, 0.5630433818969118, 0.5637059818525316, 0.5629984030354583, 0.5616476897168963, 0.5619521853617446, 0.5611472028855466, 0.5620310996515187, 0.5595974663091441, 0.5596892905955614, 0.5589200120774265, 0.5600981275698493, 0.5589162763274881, 0.5578080335863741, 0.5582994965528115, 0.5580066937676529, 0.5567536389582876, 0.5571929004878795, 0.5567105487611831, 0.5559970013724326, 0.5537006617311307, 0.5552680705437547, 0.5543442061017457, 0.555185542108479, 0.553144138650704, 0.5536515928336878, 0.5533896909498616, 0.5537637240360823, 0.5522816300691099, 0.5530173558842347, 0.5517761238953194, 0.5503219741254027, 0.5508728232337035, 0.5503718586612323, 0.5508386854243387, 0.5481787765149942, 0.5511710712206173, 0.5506403857144986, 0.548638316564011, 0.5488422391649246, 0.5492092038798168, 0.5484264674635414, 0.5463841261294567, 0.54912877412024, 0.5469571439732166, 0.5462399922793538, 0.5459754764286351, 0.5459084637856353, 0.5460654775738175, 0.5451539922776985, 0.5446027742846928, 0.5443485454596795, 0.544383045740591, 0.5453783255404095, 0.5449519727511654, 0.5452468925582101, 0.5428773460886146, 0.543263091637008, 0.5446475088340103, 0.5410325028908005, 0.5413502395252695, 0.5423579044997735, 0.541291861786659, 0.541703518429348, 0.5416580692613384, 0.541044184860222, 0.5412290279104227, 0.5412498527155989, 0.5409469276680877, 0.5411086609177354, 0.5403647729390727, 0.5402812831137611, 0.5404079255986276, 0.5398158734414752, 0.5401276028651681, 0.539215630585435, 0.5385175210060981, 0.5376458834507085, 0.5384317942271518, 0.5376709249250525, 0.5373052949584524, 0.5391914195581071, 0.5374832131112707, 0.5383266046027565, 0.5372347699370167, 0.5378131872113747, 0.5364652173044233, 0.5368356643000394, 0.5369034582735218, 0.5365159566658108, 0.535789860534816, 0.5364395324679072, 0.5366153210607952, 0.5353591565673551, 0.5346915065985977, 0.5339901457154327, 0.5345720227746369, 0.5335067670720274, 0.5343961748191102, 0.534403158417174, 0.5342366836408114, 0.5333067803137166, 0.5325385741275565, 0.53223841473841, 0.5334332054451995, 0.5322954169934309, 0.5321747411655474, 0.5324960745709136, 0.5319463426902523], 'acc': [0.8049471438943571, 0.912038842334023, 0.928984666741888, 0.9412080464626172, 0.949050609930791, 0.9539300877808214, 0.9569780155357951, 0.958927589810091, 0.960478080516218, 0.9615713894182155, 0.9623840048870039, 0.9632866695355993, 0.9640252407607299, 0.9645074697690503, 0.9652201648128041, 0.9657593629853891, 0.966308411839813, 0.9666936797716466, 0.9669947275006177, 0.9672352361997956, 0.9676027697568182, 0.967821239699092, 0.96804525414742, 0.968301680931078, 0.9685412475579902, 0.9687785983284931, 0.9689423489576312, 0.9691480164571169, 0.9693186518569137, 0.9695052017111012, 0.9697184186862082, 0.9698443379540531, 0.9699633829500273, 0.9700466164376419, 0.9702165083381821, 0.9702971216984287, 0.9704745503052169, 0.9705379183206405, 0.9706385130027555, 0.970662114463332, 0.9707369683877591, 0.9708261309644901, 0.9710004592756112, 0.9709777933744932, 0.9710630619400635, 0.9710703054560891, 0.9711629912979654, 0.9712907374474608, 0.9713168826184638, 0.9714075845951166, 0.9714800327738686, 0.971482307209956, 0.9715293067820407, 0.9715252809630449, 0.9716310253327235, 0.9716370150656868, 0.9716759127123645, 0.971727805111156, 0.9718110859251717, 0.9717271220564472, 0.9718416067703772, 0.9718794843690447, 0.9719210293901146, 0.9719284764046825, 0.9720245317667402, 0.972060516003296, 0.9720416774691675, 0.9721457657564617, 0.9721583326847422, 0.9722144237588464, 0.9722194673054424, 0.9722341486611628, 0.9722908580747345, 0.972298330791759, 0.9723323073753287, 0.9722950861537716, 0.9723620868210352, 0.9723996613143536, 0.9724267642097141, 0.9724677004220806, 0.9724757055451029, 0.9724875092791122, 0.9725304630880627, 0.972521105635727, 0.9725694858518227, 0.9725430393193369, 0.972588002247545, 0.972619590346159, 0.9726138859595779, 0.9726484440265306, 0.9726736161485048, 0.9727052574741946, 0.9726970236199495, 0.9727417188753283, 0.9727623490792401, 0.9727812851204176, 0.9727773318960925, 0.9727710696217096, 0.9728058538788226, 0.972839717452726, 0.9728415067309208, 0.9728252845303609, 0.9728438965042024, 0.9729335836075017, 0.9729340302366216, 0.9729047945854287, 0.9729476041588261, 0.9729157715274236, 0.9729411874561683, 0.9729545084821429, 0.9729590114870702, 0.9729746993028778, 0.9730171772996367, 0.9729942719407374, 0.9730171286279671, 0.9729649893119166, 0.9730061336636457, 0.9730524950090672, 0.9730574362796731, 0.9730780931825367, 0.9730495446360934, 0.9730606063086462, 0.9731384596336079, 0.973098153255992, 0.9731255035312699, 0.9731196667531922, 0.9731541759207051, 0.973136947053641, 0.9731564630122808, 0.9731856330940938, 0.9732099638396355, 0.973197065711961, 0.9732040053610304, 0.9731833259658481, 0.9732429014987298, 0.973252698227475, 0.9732615528554828, 0.9732634184224981, 0.9733130059778647, 0.9732891869610467, 0.9732760887015598, 0.9733086262109145, 0.9733264473875696, 0.9733061334640962, 0.9732854182449138, 0.9733139018554633, 0.9733425095723641, 0.9733477912385907, 0.9733546185755405, 0.9733913263743323, 0.9733529997122495, 0.973375247462655, 0.9733438143617418, 0.973425341472439, 0.9733812727562591, 0.9733973240151962, 0.9734013030558633, 0.9733888128577083, 0.9734066439566078, 0.9734205806813377, 0.9734731036907225, 0.973418117452129, 0.97345443484548, 0.973459005391424, 0.9734606037553866, 0.9735193515851727, 0.973496358755354, 0.9734868778870959, 0.9735053096590277, 0.9735004517452398, 0.9735043469237233, 0.9734991381582339, 0.9734851075351907, 0.9734834598589547, 0.9735609119166786, 0.9735238326173823, 0.9734861828246206, 0.9735408277778658, 0.9735730999134479, 0.9735388001095631, 0.9735906907716059, 0.9735905399449492, 0.9735669675393238, 0.9736044476716706, 0.9735669120416626, 0.9735978029709259, 0.9736104262438884, 0.9735807162040682, 0.9736008284511616, 0.9736348840995025, 0.973600070246484, 0.9736347407465594, 0.973616978291939, 0.9736262496969197, 0.9736478782821903, 0.9736680225950737, 0.9736606060091966, 0.9736691739882607, 0.9736565612425575, 0.9736149195614594, 0.973685007100177, 0.9736679927571622, 0.973652751470825, 0.9736907439013213, 0.9736864894151631, 0.9736730387451713, 0.973651674337879, 0.973702226151764, 0.9736888221889229, 0.9737318343141923, 0.9736793021441702, 0.9737238842546442, 0.973718781117639, 0.9737315195213789, 0.9737036740378432, 0.9737387921564158, 0.9737373934900786, 0.9737523965713715, 0.9737218472264051, 0.9737580973563343, 0.973759385589657, 0.9737755871627677, 0.9737644968053906, 0.973781145413337, 0.9737534424713127, 0.973779186254075, 0.9737982445723236], 'mDice': [0.027755533227710804, 0.10636560408723704, 0.24061826701939518, 0.3730199654353727, 0.45733433983221755, 0.5136100492031557, 0.5528919771189106, 0.5808887156404969, 0.6042042718971149, 0.621268331171762, 0.6338952111904622, 0.6466996734897362, 0.6590868974247325, 0.667569801015617, 0.6768488742185146, 0.6844346022047859, 0.6914408351360314, 0.6972366248561968, 0.7024507721597322, 0.7059580903648903, 0.7112522780297336, 0.715337155235107, 0.7184652685336119, 0.7223147802430347, 0.7255536344161261, 0.7289791272026501, 0.7304801648375469, 0.7337254726120872, 0.7363834048843566, 0.7387942900684986, 0.7409357177220411, 0.743036796262562, 0.7446354252713547, 0.7462680547013042, 0.748489760479894, 0.7487128405004975, 0.7510398906912074, 0.7530312191651378, 0.7545686199609836, 0.7548345008142985, 0.7563049186164336, 0.75690605147431, 0.7592190459730063, 0.7592510448197974, 0.760539583916991, 0.7613785275559964, 0.7621485717062566, 0.7632494703921037, 0.7641780864361052, 0.7655626345298613, 0.7665607553408713, 0.7666643843933822, 0.7677637318138977, 0.7680724202974446, 0.7688400940704893, 0.7699284034353866, 0.7708450928704107, 0.7708372047287996, 0.7721975731456766, 0.771711268237362, 0.7726994312575417, 0.7735353412450513, 0.7739017587702286, 0.7743788779365552, 0.7752400436875699, 0.7757055844203197, 0.775661218556408, 0.776887833794518, 0.7770747078014554, 0.7773606514614694, 0.7779595227166921, 0.7777036424323202, 0.7794044773135061, 0.7793472210234038, 0.7795041140506113, 0.779728176522887, 0.7800382974254849, 0.7806749959563708, 0.7812603039874761, 0.78166892602844, 0.7816066563926621, 0.7823377093111156, 0.7829111650575451, 0.7829005776383811, 0.7831306944378583, 0.7828617197376235, 0.7834609894770155, 0.7837966024121151, 0.7840453214696065, 0.7846934531877854, 0.7845331089206775, 0.7856198632477974, 0.785305177785344, 0.785560560832879, 0.7862869420896034, 0.7859415106238685, 0.7862978763958421, 0.786890703715884, 0.7867744369768203, 0.7874703220658295, 0.7881161293736898, 0.7873325690765896, 0.7871047540527555, 0.788555003063816, 0.7885911319131694, 0.7891289795287788, 0.788709750266869, 0.7884651025112586, 0.7888220594397358, 0.7892983831467024, 0.7899903329340632, 0.789299097505594, 0.7901009137003525, 0.7902975165604805, 0.7902351779743569, 0.790172574534062, 0.79061854512019, 0.7907125988936464, 0.7908037099813772, 0.7912980718660503, 0.7910359131142494, 0.7912359574699789, 0.7918974839761259, 0.7917237513626793, 0.7918291013267008, 0.7920582657117162, 0.792754898748621, 0.7926825870185243, 0.7929237195023039, 0.7924865512068356, 0.7927233404950365, 0.7932901765385134, 0.792909478106304, 0.7933735677997793, 0.7938608987493108, 0.7933320869316427, 0.7937360707361715, 0.7941168955809067, 0.7948510116471121, 0.7941520924225951, 0.794630263617308, 0.7942045331713063, 0.7951813599133452, 0.794860733638722, 0.7947985493598703, 0.7948385417489866, 0.7952891576680188, 0.7950765141189198, 0.7954208704945237, 0.7958418198565125, 0.7958089893206453, 0.7960010074845982, 0.7959575488369761, 0.7968379368296893, 0.7956828804268938, 0.796061101942322, 0.7965132468763729, 0.796862205892182, 0.7966371100615681, 0.7967807080855597, 0.7976329397736684, 0.7965841274045662, 0.7971293160432502, 0.7976761533475475, 0.7978078140217677, 0.7976861791064639, 0.7970913604474847, 0.7981329304750022, 0.7981930398587996, 0.7981994507461965, 0.7983754155656902, 0.7978285569506327, 0.798135132878727, 0.7979712816178158, 0.7987022871813969, 0.7987103393176361, 0.798146335775994, 0.7995201141916256, 0.7993512498555162, 0.7991318035828974, 0.7994199589781013, 0.7993245849055324, 0.7990650733928849, 0.799544669383461, 0.7993230711938317, 0.7994515047541432, 0.799795052082464, 0.7997726585946449, 0.7998708481716887, 0.7996438468217223, 0.7996839718514591, 0.7998457759341164, 0.7997521866839855, 0.8001917131211327, 0.800698197162718, 0.8008853591140427, 0.8004500857181358, 0.80080705367212, 0.8008225400393181, 0.8002730491610054, 0.800770983117732, 0.8006522249415292, 0.8008911459819497, 0.8008674771511842, 0.8013537290174864, 0.8008549445806326, 0.8009974151771451, 0.8011510219626932, 0.8011692419794085, 0.8013142890710377, 0.8010932314729019, 0.8016326583126493, 0.8017888800864975, 0.8022655949035692, 0.8019690308048129, 0.8024557184740271, 0.8020473428378391, 0.8022333056069172, 0.802130354961177, 0.8023584182760098, 0.8025629241112909, 0.8026171163781491, 0.8024843096704622, 0.8025363030996248, 0.8026070034614975, 0.8025577809934773, 0.802780388568619]}
predicting test subjects:   0%|          | 0/15 [00:00<?, ?it/s]predicting test subjects:   7%|▋         | 1/15 [00:02<00:31,  2.27s/it]predicting test subjects:  13%|█▎        | 2/15 [00:04<00:28,  2.15s/it]predicting test subjects:  20%|██        | 3/15 [00:06<00:26,  2.18s/it]predicting test subjects:  27%|██▋       | 4/15 [00:08<00:23,  2.17s/it]predicting test subjects:  33%|███▎      | 5/15 [00:11<00:22,  2.27s/it]predicting test subjects:  40%|████      | 6/15 [00:13<00:20,  2.33s/it]predicting test subjects:  47%|████▋     | 7/15 [00:15<00:17,  2.14s/it]predicting test subjects:  53%|█████▎    | 8/15 [00:17<00:16,  2.30s/it]predicting test subjects:  60%|██████    | 9/15 [00:20<00:13,  2.25s/it]predicting test subjects:  67%|██████▋   | 10/15 [00:21<00:10,  2.11s/it]predicting test subjects:  73%|███████▎  | 11/15 [00:23<00:08,  2.05s/it]predicting test subjects:  80%|████████  | 12/15 [00:25<00:06,  2.08s/it]predicting test subjects:  87%|████████▋ | 13/15 [00:28<00:04,  2.12s/it]predicting test subjects:  93%|█████████▎| 14/15 [00:30<00:02,  2.08s/it]predicting test subjects: 100%|██████████| 15/15 [00:32<00:00,  2.08s/it]
predicting train subjects:   0%|          | 0/532 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/532 [00:02<22:10,  2.51s/it]predicting train subjects:   0%|          | 2/532 [00:04<20:44,  2.35s/it]predicting train subjects:   1%|          | 3/532 [00:06<19:46,  2.24s/it]predicting train subjects:   1%|          | 4/532 [00:08<19:05,  2.17s/it]predicting train subjects:   1%|          | 5/532 [00:10<18:32,  2.11s/it]predicting train subjects:   1%|          | 6/532 [00:12<17:44,  2.02s/it]predicting train subjects:   1%|▏         | 7/532 [00:14<17:21,  1.98s/it]predicting train subjects:   2%|▏         | 8/532 [00:15<16:52,  1.93s/it]predicting train subjects:   2%|▏         | 9/532 [00:18<17:22,  1.99s/it]predicting train subjects:   2%|▏         | 10/532 [00:19<16:56,  1.95s/it]predicting train subjects:   2%|▏         | 11/532 [00:21<16:07,  1.86s/it]predicting train subjects:   2%|▏         | 12/532 [00:23<17:25,  2.01s/it]predicting train subjects:   2%|▏         | 13/532 [00:25<16:35,  1.92s/it]predicting train subjects:   3%|▎         | 14/532 [00:27<15:39,  1.81s/it]predicting train subjects:   3%|▎         | 15/532 [00:29<15:37,  1.81s/it]predicting train subjects:   3%|▎         | 16/532 [00:31<16:01,  1.86s/it]predicting train subjects:   3%|▎         | 17/532 [00:32<15:46,  1.84s/it]predicting train subjects:   3%|▎         | 18/532 [00:34<16:36,  1.94s/it]predicting train subjects:   4%|▎         | 19/532 [00:36<15:41,  1.84s/it]predicting train subjects:   4%|▍         | 20/532 [00:38<15:56,  1.87s/it]predicting train subjects:   4%|▍         | 21/532 [00:40<16:53,  1.98s/it]predicting train subjects:   4%|▍         | 22/532 [00:42<16:35,  1.95s/it]predicting train subjects:   4%|▍         | 23/532 [00:44<16:36,  1.96s/it]predicting train subjects:   5%|▍         | 24/532 [00:46<15:41,  1.85s/it]predicting train subjects:   5%|▍         | 25/532 [00:48<17:00,  2.01s/it]predicting train subjects:   5%|▍         | 26/532 [00:50<16:38,  1.97s/it]predicting train subjects:   5%|▌         | 27/532 [00:52<17:51,  2.12s/it]predicting train subjects:   5%|▌         | 28/532 [00:54<17:33,  2.09s/it]predicting train subjects:   5%|▌         | 29/532 [00:57<17:43,  2.12s/it]predicting train subjects:   6%|▌         | 30/532 [00:58<16:45,  2.00s/it]predicting train subjects:   6%|▌         | 31/532 [01:00<16:40,  2.00s/it]predicting train subjects:   6%|▌         | 32/532 [01:02<16:34,  1.99s/it]predicting train subjects:   6%|▌         | 33/532 [01:04<15:57,  1.92s/it]predicting train subjects:   6%|▋         | 34/532 [01:07<17:07,  2.06s/it]predicting train subjects:   7%|▋         | 35/532 [01:08<16:34,  2.00s/it]predicting train subjects:   7%|▋         | 36/532 [01:10<16:39,  2.01s/it]predicting train subjects:   7%|▋         | 37/532 [01:12<16:47,  2.04s/it]predicting train subjects:   7%|▋         | 38/532 [01:15<16:53,  2.05s/it]predicting train subjects:   7%|▋         | 39/532 [01:16<16:27,  2.00s/it]predicting train subjects:   8%|▊         | 40/532 [01:18<15:59,  1.95s/it]predicting train subjects:   8%|▊         | 41/532 [01:20<16:26,  2.01s/it]predicting train subjects:   8%|▊         | 42/532 [01:23<16:46,  2.05s/it]predicting train subjects:   8%|▊         | 43/532 [01:24<15:52,  1.95s/it]predicting train subjects:   8%|▊         | 44/532 [01:26<15:11,  1.87s/it]predicting train subjects:   8%|▊         | 45/532 [01:28<15:03,  1.85s/it]predicting train subjects:   9%|▊         | 46/532 [01:30<15:19,  1.89s/it]predicting train subjects:   9%|▉         | 47/532 [01:32<16:30,  2.04s/it]predicting train subjects:   9%|▉         | 48/532 [01:34<16:33,  2.05s/it]predicting train subjects:   9%|▉         | 49/532 [01:36<15:45,  1.96s/it]predicting train subjects:   9%|▉         | 50/532 [01:38<16:18,  2.03s/it]predicting train subjects:  10%|▉         | 51/532 [01:40<16:07,  2.01s/it]predicting train subjects:  10%|▉         | 52/532 [01:42<15:48,  1.98s/it]predicting train subjects:  10%|▉         | 53/532 [01:44<15:21,  1.92s/it]predicting train subjects:  10%|█         | 54/532 [01:46<16:03,  2.02s/it]predicting train subjects:  10%|█         | 55/532 [01:48<16:09,  2.03s/it]predicting train subjects:  11%|█         | 56/532 [01:50<16:08,  2.04s/it]predicting train subjects:  11%|█         | 57/532 [01:52<15:50,  2.00s/it]predicting train subjects:  11%|█         | 58/532 [01:54<15:40,  1.98s/it]predicting train subjects:  11%|█         | 59/532 [01:56<16:33,  2.10s/it]predicting train subjects:  11%|█▏        | 60/532 [01:58<15:21,  1.95s/it]predicting train subjects:  11%|█▏        | 61/532 [02:00<14:36,  1.86s/it]predicting train subjects:  12%|█▏        | 62/532 [02:02<15:27,  1.97s/it]predicting train subjects:  12%|█▏        | 63/532 [02:04<16:31,  2.11s/it]predicting train subjects:  12%|█▏        | 64/532 [02:06<15:49,  2.03s/it]predicting train subjects:  12%|█▏        | 65/532 [02:08<15:42,  2.02s/it]predicting train subjects:  12%|█▏        | 66/532 [02:11<16:37,  2.14s/it]predicting train subjects:  13%|█▎        | 67/532 [02:13<17:12,  2.22s/it]predicting train subjects:  13%|█▎        | 68/532 [02:15<16:52,  2.18s/it]predicting train subjects:  13%|█▎        | 69/532 [02:17<16:21,  2.12s/it]predicting train subjects:  13%|█▎        | 70/532 [02:19<15:31,  2.02s/it]predicting train subjects:  13%|█▎        | 71/532 [02:21<14:56,  1.94s/it]predicting train subjects:  14%|█▎        | 72/532 [02:22<14:24,  1.88s/it]predicting train subjects:  14%|█▎        | 73/532 [02:24<14:56,  1.95s/it]predicting train subjects:  14%|█▍        | 74/532 [02:27<16:02,  2.10s/it]predicting train subjects:  14%|█▍        | 75/532 [02:30<18:03,  2.37s/it]predicting train subjects:  14%|█▍        | 76/532 [02:32<16:55,  2.23s/it]predicting train subjects:  14%|█▍        | 77/532 [02:34<16:23,  2.16s/it]predicting train subjects:  15%|█▍        | 78/532 [02:36<16:12,  2.14s/it]predicting train subjects:  15%|█▍        | 79/532 [02:38<15:55,  2.11s/it]predicting train subjects:  15%|█▌        | 80/532 [02:40<15:42,  2.09s/it]predicting train subjects:  15%|█▌        | 81/532 [02:42<15:37,  2.08s/it]predicting train subjects:  15%|█▌        | 82/532 [02:44<15:29,  2.07s/it]predicting train subjects:  16%|█▌        | 83/532 [02:46<14:40,  1.96s/it]predicting train subjects:  16%|█▌        | 84/532 [02:48<14:04,  1.89s/it]predicting train subjects:  16%|█▌        | 85/532 [02:49<13:38,  1.83s/it]predicting train subjects:  16%|█▌        | 86/532 [02:51<13:22,  1.80s/it]predicting train subjects:  16%|█▋        | 87/532 [02:53<13:14,  1.78s/it]predicting train subjects:  17%|█▋        | 88/532 [02:54<13:02,  1.76s/it]predicting train subjects:  17%|█▋        | 89/532 [02:56<13:23,  1.81s/it]predicting train subjects:  17%|█▋        | 90/532 [02:58<13:42,  1.86s/it]predicting train subjects:  17%|█▋        | 91/532 [03:00<14:04,  1.91s/it]predicting train subjects:  17%|█▋        | 92/532 [03:02<14:02,  1.91s/it]predicting train subjects:  17%|█▋        | 93/532 [03:04<14:02,  1.92s/it]predicting train subjects:  18%|█▊        | 94/532 [03:06<14:07,  1.94s/it]predicting train subjects:  18%|█▊        | 95/532 [03:08<14:41,  2.02s/it]predicting train subjects:  18%|█▊        | 96/532 [03:11<15:03,  2.07s/it]predicting train subjects:  18%|█▊        | 97/532 [03:13<15:12,  2.10s/it]predicting train subjects:  18%|█▊        | 98/532 [03:15<15:23,  2.13s/it]predicting train subjects:  19%|█▊        | 99/532 [03:17<15:29,  2.15s/it]predicting train subjects:  19%|█▉        | 100/532 [03:19<15:37,  2.17s/it]predicting train subjects:  19%|█▉        | 101/532 [03:21<14:58,  2.09s/it]predicting train subjects:  19%|█▉        | 102/532 [03:23<14:30,  2.02s/it]predicting train subjects:  19%|█▉        | 103/532 [03:25<14:11,  1.99s/it]predicting train subjects:  20%|█▉        | 104/532 [03:27<13:49,  1.94s/it]predicting train subjects:  20%|█▉        | 105/532 [03:29<13:29,  1.90s/it]predicting train subjects:  20%|█▉        | 106/532 [03:30<13:18,  1.87s/it]predicting train subjects:  20%|██        | 107/532 [03:32<13:05,  1.85s/it]predicting train subjects:  20%|██        | 108/532 [03:34<12:47,  1.81s/it]predicting train subjects:  20%|██        | 109/532 [03:36<12:28,  1.77s/it]predicting train subjects:  21%|██        | 110/532 [03:37<12:16,  1.75s/it]predicting train subjects:  21%|██        | 111/532 [03:39<12:26,  1.77s/it]predicting train subjects:  21%|██        | 112/532 [03:41<12:21,  1.77s/it]predicting train subjects:  21%|██        | 113/532 [03:43<13:10,  1.89s/it]predicting train subjects:  21%|██▏       | 114/532 [03:45<13:30,  1.94s/it]predicting train subjects:  22%|██▏       | 115/532 [03:47<13:47,  1.98s/it]predicting train subjects:  22%|██▏       | 116/532 [03:49<13:57,  2.01s/it]predicting train subjects:  22%|██▏       | 117/532 [03:51<14:02,  2.03s/it]predicting train subjects:  22%|██▏       | 118/532 [03:53<14:06,  2.04s/it]predicting train subjects:  22%|██▏       | 119/532 [03:55<13:45,  2.00s/it]predicting train subjects:  23%|██▎       | 120/532 [03:57<13:28,  1.96s/it]predicting train subjects:  23%|██▎       | 121/532 [03:59<13:17,  1.94s/it]predicting train subjects:  23%|██▎       | 122/532 [04:01<13:21,  1.96s/it]predicting train subjects:  23%|██▎       | 123/532 [04:03<13:24,  1.97s/it]predicting train subjects:  23%|██▎       | 124/532 [04:05<13:24,  1.97s/it]predicting train subjects:  23%|██▎       | 125/532 [04:07<13:48,  2.03s/it]predicting train subjects:  24%|██▎       | 126/532 [04:09<13:59,  2.07s/it]predicting train subjects:  24%|██▍       | 127/532 [04:12<13:58,  2.07s/it]predicting train subjects:  24%|██▍       | 128/532 [04:14<13:53,  2.06s/it]predicting train subjects:  24%|██▍       | 129/532 [04:16<14:06,  2.10s/it]predicting train subjects:  24%|██▍       | 130/532 [04:18<14:03,  2.10s/it]predicting train subjects:  25%|██▍       | 131/532 [04:20<14:35,  2.18s/it]predicting train subjects:  25%|██▍       | 132/532 [04:23<15:03,  2.26s/it]predicting train subjects:  25%|██▌       | 133/532 [04:25<15:12,  2.29s/it]predicting train subjects:  25%|██▌       | 134/532 [04:27<15:20,  2.31s/it]predicting train subjects:  25%|██▌       | 135/532 [04:30<15:23,  2.33s/it]predicting train subjects:  26%|██▌       | 136/532 [04:32<15:33,  2.36s/it]predicting train subjects:  26%|██▌       | 137/532 [04:35<15:38,  2.38s/it]predicting train subjects:  26%|██▌       | 138/532 [04:37<15:44,  2.40s/it]predicting train subjects:  26%|██▌       | 139/532 [04:40<15:52,  2.42s/it]predicting train subjects:  26%|██▋       | 140/532 [04:42<15:40,  2.40s/it]predicting train subjects:  27%|██▋       | 141/532 [04:44<15:36,  2.39s/it]predicting train subjects:  27%|██▋       | 142/532 [04:47<15:40,  2.41s/it]predicting train subjects:  27%|██▋       | 143/532 [04:49<14:27,  2.23s/it]predicting train subjects:  27%|██▋       | 144/532 [04:50<13:42,  2.12s/it]predicting train subjects:  27%|██▋       | 145/532 [04:52<13:01,  2.02s/it]predicting train subjects:  27%|██▋       | 146/532 [04:54<12:30,  1.94s/it]predicting train subjects:  28%|██▊       | 147/532 [04:56<12:12,  1.90s/it]predicting train subjects:  28%|██▊       | 148/532 [04:58<11:57,  1.87s/it]predicting train subjects:  28%|██▊       | 149/532 [04:59<12:03,  1.89s/it]predicting train subjects:  28%|██▊       | 150/532 [05:01<12:06,  1.90s/it]predicting train subjects:  28%|██▊       | 151/532 [05:03<12:21,  1.95s/it]predicting train subjects:  29%|██▊       | 152/532 [05:05<12:20,  1.95s/it]predicting train subjects:  29%|██▉       | 153/532 [05:07<12:21,  1.96s/it]predicting train subjects:  29%|██▉       | 154/532 [05:09<12:19,  1.96s/it]predicting train subjects:  29%|██▉       | 155/532 [05:12<13:14,  2.11s/it]predicting train subjects:  29%|██▉       | 156/532 [05:14<14:01,  2.24s/it]predicting train subjects:  30%|██▉       | 157/532 [05:17<14:31,  2.32s/it]predicting train subjects:  30%|██▉       | 158/532 [05:19<14:41,  2.36s/it]predicting train subjects:  30%|██▉       | 159/532 [05:22<15:01,  2.42s/it]predicting train subjects:  30%|███       | 160/532 [05:24<15:00,  2.42s/it]predicting train subjects:  30%|███       | 161/532 [05:26<14:10,  2.29s/it]predicting train subjects:  30%|███       | 162/532 [05:29<14:09,  2.30s/it]predicting train subjects:  31%|███       | 163/532 [05:31<13:29,  2.19s/it]predicting train subjects:  31%|███       | 164/532 [05:33<13:05,  2.14s/it]predicting train subjects:  31%|███       | 165/532 [05:35<12:49,  2.10s/it]predicting train subjects:  31%|███       | 166/532 [05:37<12:34,  2.06s/it]predicting train subjects:  31%|███▏      | 167/532 [05:39<12:25,  2.04s/it]predicting train subjects:  32%|███▏      | 168/532 [05:41<12:35,  2.07s/it]predicting train subjects:  32%|███▏      | 169/532 [05:43<12:17,  2.03s/it]predicting train subjects:  32%|███▏      | 170/532 [05:45<12:06,  2.01s/it]predicting train subjects:  32%|███▏      | 171/532 [05:47<12:09,  2.02s/it]predicting train subjects:  32%|███▏      | 172/532 [05:48<11:48,  1.97s/it]predicting train subjects:  33%|███▎      | 173/532 [05:50<11:23,  1.90s/it]predicting train subjects:  33%|███▎      | 174/532 [05:52<11:05,  1.86s/it]predicting train subjects:  33%|███▎      | 175/532 [05:54<10:55,  1.84s/it]predicting train subjects:  33%|███▎      | 176/532 [05:55<10:46,  1.82s/it]predicting train subjects:  33%|███▎      | 177/532 [05:57<10:41,  1.81s/it]predicting train subjects:  33%|███▎      | 178/532 [05:59<10:40,  1.81s/it]predicting train subjects:  34%|███▎      | 179/532 [06:01<10:30,  1.79s/it]predicting train subjects:  34%|███▍      | 180/532 [06:03<10:33,  1.80s/it]predicting train subjects:  34%|███▍      | 181/532 [06:04<10:32,  1.80s/it]predicting train subjects:  34%|███▍      | 182/532 [06:06<10:27,  1.79s/it]predicting train subjects:  34%|███▍      | 183/532 [06:08<10:23,  1.79s/it]predicting train subjects:  35%|███▍      | 184/532 [06:10<10:23,  1.79s/it]predicting train subjects:  35%|███▍      | 185/532 [06:12<10:11,  1.76s/it]predicting train subjects:  35%|███▍      | 186/532 [06:13<10:14,  1.78s/it]predicting train subjects:  35%|███▌      | 187/532 [06:15<10:19,  1.79s/it]predicting train subjects:  35%|███▌      | 188/532 [06:17<10:10,  1.77s/it]predicting train subjects:  36%|███▌      | 189/532 [06:19<10:09,  1.78s/it]predicting train subjects:  36%|███▌      | 190/532 [06:20<10:00,  1.76s/it]predicting train subjects:  36%|███▌      | 191/532 [06:23<10:53,  1.92s/it]predicting train subjects:  36%|███▌      | 192/532 [06:25<11:30,  2.03s/it]predicting train subjects:  36%|███▋      | 193/532 [06:27<11:54,  2.11s/it]predicting train subjects:  36%|███▋      | 194/532 [06:30<12:10,  2.16s/it]predicting train subjects:  37%|███▋      | 195/532 [06:32<12:28,  2.22s/it]predicting train subjects:  37%|███▋      | 196/532 [06:34<12:35,  2.25s/it]predicting train subjects:  37%|███▋      | 197/532 [06:36<12:15,  2.20s/it]predicting train subjects:  37%|███▋      | 198/532 [06:38<11:52,  2.13s/it]predicting train subjects:  37%|███▋      | 199/532 [06:40<11:44,  2.12s/it]predicting train subjects:  38%|███▊      | 200/532 [06:42<11:37,  2.10s/it]predicting train subjects:  38%|███▊      | 201/532 [06:45<11:35,  2.10s/it]predicting train subjects:  38%|███▊      | 202/532 [06:47<11:34,  2.10s/it]predicting train subjects:  38%|███▊      | 203/532 [06:48<11:00,  2.01s/it]predicting train subjects:  38%|███▊      | 204/532 [06:50<10:41,  1.96s/it]predicting train subjects:  39%|███▊      | 205/532 [06:52<10:27,  1.92s/it]predicting train subjects:  39%|███▊      | 206/532 [06:54<10:08,  1.87s/it]predicting train subjects:  39%|███▉      | 207/532 [06:56<10:14,  1.89s/it]predicting train subjects:  39%|███▉      | 208/532 [06:57<09:56,  1.84s/it]predicting train subjects:  39%|███▉      | 209/532 [06:59<09:33,  1.78s/it]predicting train subjects:  39%|███▉      | 210/532 [07:01<09:07,  1.70s/it]predicting train subjects:  40%|███▉      | 211/532 [07:02<08:51,  1.66s/it]predicting train subjects:  40%|███▉      | 212/532 [07:04<08:45,  1.64s/it]predicting train subjects:  40%|████      | 213/532 [07:05<08:30,  1.60s/it]predicting train subjects:  40%|████      | 214/532 [07:07<08:24,  1.59s/it]predicting train subjects:  40%|████      | 215/532 [07:09<09:17,  1.76s/it]predicting train subjects:  41%|████      | 216/532 [07:11<09:49,  1.87s/it]predicting train subjects:  41%|████      | 217/532 [07:13<10:32,  2.01s/it]predicting train subjects:  41%|████      | 218/532 [07:16<10:52,  2.08s/it]predicting train subjects:  41%|████      | 219/532 [07:18<11:04,  2.12s/it]predicting train subjects:  41%|████▏     | 220/532 [07:20<11:16,  2.17s/it]predicting train subjects:  42%|████▏     | 221/532 [07:22<10:29,  2.03s/it]predicting train subjects:  42%|████▏     | 222/532 [07:24<09:50,  1.90s/it]predicting train subjects:  42%|████▏     | 223/532 [07:25<09:22,  1.82s/it]predicting train subjects:  42%|████▏     | 224/532 [07:27<09:00,  1.76s/it]predicting train subjects:  42%|████▏     | 225/532 [07:28<08:45,  1.71s/it]predicting train subjects:  42%|████▏     | 226/532 [07:30<08:30,  1.67s/it]predicting train subjects:  43%|████▎     | 227/532 [07:31<08:14,  1.62s/it]predicting train subjects:  43%|████▎     | 228/532 [07:33<08:08,  1.61s/it]predicting train subjects:  43%|████▎     | 229/532 [07:35<07:55,  1.57s/it]predicting train subjects:  43%|████▎     | 230/532 [07:36<07:50,  1.56s/it]predicting train subjects:  43%|████▎     | 231/532 [07:38<07:53,  1.57s/it]predicting train subjects:  44%|████▎     | 232/532 [07:39<07:46,  1.55s/it]predicting train subjects:  44%|████▍     | 233/532 [07:41<08:08,  1.63s/it]predicting train subjects:  44%|████▍     | 234/532 [07:43<08:16,  1.67s/it]predicting train subjects:  44%|████▍     | 235/532 [07:44<08:21,  1.69s/it]predicting train subjects:  44%|████▍     | 236/532 [07:46<08:45,  1.78s/it]predicting train subjects:  45%|████▍     | 237/532 [07:48<08:51,  1.80s/it]predicting train subjects:  45%|████▍     | 238/532 [07:50<08:57,  1.83s/it]predicting train subjects:  45%|████▍     | 239/532 [07:52<09:13,  1.89s/it]predicting train subjects:  45%|████▌     | 240/532 [07:54<09:20,  1.92s/it]predicting train subjects:  45%|████▌     | 241/532 [07:56<09:23,  1.94s/it]predicting train subjects:  45%|████▌     | 242/532 [07:58<09:25,  1.95s/it]predicting train subjects:  46%|████▌     | 243/532 [08:00<09:22,  1.95s/it]predicting train subjects:  46%|████▌     | 244/532 [08:02<09:14,  1.93s/it]predicting train subjects:  46%|████▌     | 245/532 [08:04<08:40,  1.81s/it]predicting train subjects:  46%|████▌     | 246/532 [08:05<08:12,  1.72s/it]predicting train subjects:  46%|████▋     | 247/532 [08:07<07:58,  1.68s/it]predicting train subjects:  47%|████▋     | 248/532 [08:08<07:45,  1.64s/it]predicting train subjects:  47%|████▋     | 249/532 [08:10<07:39,  1.62s/it]predicting train subjects:  47%|████▋     | 250/532 [08:11<07:32,  1.60s/it]predicting train subjects:  47%|████▋     | 251/532 [08:13<07:36,  1.63s/it]predicting train subjects:  47%|████▋     | 252/532 [08:15<07:33,  1.62s/it]predicting train subjects:  48%|████▊     | 253/532 [08:16<07:31,  1.62s/it]predicting train subjects:  48%|████▊     | 254/532 [08:18<07:32,  1.63s/it]predicting train subjects:  48%|████▊     | 255/532 [08:19<07:22,  1.60s/it]predicting train subjects:  48%|████▊     | 256/532 [08:21<07:18,  1.59s/it]predicting train subjects:  48%|████▊     | 257/532 [08:23<07:57,  1.74s/it]predicting train subjects:  48%|████▊     | 258/532 [08:25<08:24,  1.84s/it]predicting train subjects:  49%|████▊     | 259/532 [08:27<08:41,  1.91s/it]predicting train subjects:  49%|████▉     | 260/532 [08:29<08:55,  1.97s/it]predicting train subjects:  49%|████▉     | 261/532 [08:31<09:02,  2.00s/it]predicting train subjects:  49%|████▉     | 262/532 [08:33<09:02,  2.01s/it]predicting train subjects:  49%|████▉     | 263/532 [08:35<08:14,  1.84s/it]predicting train subjects:  50%|████▉     | 264/532 [08:36<07:42,  1.72s/it]predicting train subjects:  50%|████▉     | 265/532 [08:38<07:21,  1.65s/it]predicting train subjects:  50%|█████     | 266/532 [08:39<07:04,  1.60s/it]predicting train subjects:  50%|█████     | 267/532 [08:41<06:54,  1.56s/it]predicting train subjects:  50%|█████     | 268/532 [08:42<06:46,  1.54s/it]predicting train subjects:  51%|█████     | 269/532 [08:44<07:06,  1.62s/it]predicting train subjects:  51%|█████     | 270/532 [08:46<07:19,  1.68s/it]predicting train subjects:  51%|█████     | 271/532 [08:48<07:21,  1.69s/it]predicting train subjects:  51%|█████     | 272/532 [08:49<07:33,  1.74s/it]predicting train subjects:  51%|█████▏    | 273/532 [08:51<07:35,  1.76s/it]predicting train subjects:  52%|█████▏    | 274/532 [08:53<07:36,  1.77s/it]predicting train subjects:  52%|█████▏    | 275/532 [08:55<08:12,  1.91s/it]predicting train subjects:  52%|█████▏    | 276/532 [08:57<08:29,  1.99s/it]predicting train subjects:  52%|█████▏    | 277/532 [09:00<08:39,  2.04s/it]predicting train subjects:  52%|█████▏    | 278/532 [09:02<08:50,  2.09s/it]predicting train subjects:  52%|█████▏    | 279/532 [09:04<08:58,  2.13s/it]predicting train subjects:  53%|█████▎    | 280/532 [09:06<09:04,  2.16s/it]predicting train subjects:  53%|█████▎    | 281/532 [09:08<08:55,  2.13s/it]predicting train subjects:  53%|█████▎    | 282/532 [09:10<08:50,  2.12s/it]predicting train subjects:  53%|█████▎    | 283/532 [09:13<08:46,  2.11s/it]predicting train subjects:  53%|█████▎    | 284/532 [09:15<08:57,  2.17s/it]predicting train subjects:  54%|█████▎    | 285/532 [09:17<09:01,  2.19s/it]predicting train subjects:  54%|█████▍    | 286/532 [09:19<08:55,  2.18s/it]predicting train subjects:  54%|█████▍    | 287/532 [09:21<08:16,  2.03s/it]predicting train subjects:  54%|█████▍    | 288/532 [09:23<07:51,  1.93s/it]predicting train subjects:  54%|█████▍    | 289/532 [09:24<07:32,  1.86s/it]predicting train subjects:  55%|█████▍    | 290/532 [09:26<07:26,  1.84s/it]predicting train subjects:  55%|█████▍    | 291/532 [09:28<07:15,  1.81s/it]predicting train subjects:  55%|█████▍    | 292/532 [09:30<07:05,  1.77s/it]predicting train subjects:  55%|█████▌    | 293/532 [09:31<07:14,  1.82s/it]predicting train subjects:  55%|█████▌    | 294/532 [09:33<07:18,  1.84s/it]predicting train subjects:  55%|█████▌    | 295/532 [09:35<07:18,  1.85s/it]predicting train subjects:  56%|█████▌    | 296/532 [09:37<07:16,  1.85s/it]predicting train subjects:  56%|█████▌    | 297/532 [09:39<07:14,  1.85s/it]predicting train subjects:  56%|█████▌    | 298/532 [09:41<07:17,  1.87s/it]predicting train subjects:  56%|█████▌    | 299/532 [09:42<06:52,  1.77s/it]predicting train subjects:  56%|█████▋    | 300/532 [09:44<06:35,  1.70s/it]predicting train subjects:  57%|█████▋    | 301/532 [09:45<06:22,  1.65s/it]predicting train subjects:  57%|█████▋    | 302/532 [09:47<06:13,  1.62s/it]predicting train subjects:  57%|█████▋    | 303/532 [09:49<06:04,  1.59s/it]predicting train subjects:  57%|█████▋    | 304/532 [09:50<06:02,  1.59s/it]predicting train subjects:  57%|█████▋    | 305/532 [09:52<06:41,  1.77s/it]predicting train subjects:  58%|█████▊    | 306/532 [09:55<07:11,  1.91s/it]predicting train subjects:  58%|█████▊    | 307/532 [09:57<07:37,  2.03s/it]predicting train subjects:  58%|█████▊    | 308/532 [09:59<07:54,  2.12s/it]predicting train subjects:  58%|█████▊    | 309/532 [10:01<08:03,  2.17s/it]predicting train subjects:  58%|█████▊    | 310/532 [10:04<08:06,  2.19s/it]predicting train subjects:  58%|█████▊    | 311/532 [10:07<08:47,  2.38s/it]predicting train subjects:  59%|█████▊    | 312/532 [10:09<09:20,  2.55s/it]predicting train subjects:  59%|█████▉    | 313/532 [10:12<09:39,  2.65s/it]predicting train subjects:  59%|█████▉    | 314/532 [10:15<09:49,  2.71s/it]predicting train subjects:  59%|█████▉    | 315/532 [10:18<09:57,  2.75s/it]predicting train subjects:  59%|█████▉    | 316/532 [10:21<10:02,  2.79s/it]predicting train subjects:  60%|█████▉    | 317/532 [10:23<08:51,  2.47s/it]predicting train subjects:  60%|█████▉    | 318/532 [10:24<08:04,  2.26s/it]predicting train subjects:  60%|█████▉    | 319/532 [10:26<07:27,  2.10s/it]predicting train subjects:  60%|██████    | 320/532 [10:28<07:01,  1.99s/it]predicting train subjects:  60%|██████    | 321/532 [10:30<06:45,  1.92s/it]predicting train subjects:  61%|██████    | 322/532 [10:31<06:32,  1.87s/it]predicting train subjects:  61%|██████    | 323/532 [10:34<07:06,  2.04s/it]predicting train subjects:  61%|██████    | 324/532 [10:36<07:31,  2.17s/it]predicting train subjects:  61%|██████    | 325/532 [10:39<07:46,  2.25s/it]predicting train subjects:  61%|██████▏   | 326/532 [10:41<07:51,  2.29s/it]predicting train subjects:  61%|██████▏   | 327/532 [10:44<07:55,  2.32s/it]predicting train subjects:  62%|██████▏   | 328/532 [10:46<08:02,  2.37s/it]predicting train subjects:  62%|██████▏   | 329/532 [10:48<07:30,  2.22s/it]predicting train subjects:  62%|██████▏   | 330/532 [10:50<07:05,  2.11s/it]predicting train subjects:  62%|██████▏   | 331/532 [10:52<06:49,  2.04s/it]predicting train subjects:  62%|██████▏   | 332/532 [10:53<06:36,  1.98s/it]predicting train subjects:  63%|██████▎   | 333/532 [10:55<06:27,  1.95s/it]predicting train subjects:  63%|██████▎   | 334/532 [10:57<06:18,  1.91s/it]predicting train subjects:  63%|██████▎   | 335/532 [10:59<06:25,  1.96s/it]predicting train subjects:  63%|██████▎   | 336/532 [11:01<06:30,  1.99s/it]predicting train subjects:  63%|██████▎   | 337/532 [11:03<06:28,  1.99s/it]predicting train subjects:  64%|██████▎   | 338/532 [11:05<06:25,  1.99s/it]predicting train subjects:  64%|██████▎   | 339/532 [11:07<06:22,  1.98s/it]predicting train subjects:  64%|██████▍   | 340/532 [11:09<06:17,  1.97s/it]predicting train subjects:  64%|██████▍   | 341/532 [11:11<06:02,  1.90s/it]predicting train subjects:  64%|██████▍   | 342/532 [11:12<05:44,  1.81s/it]predicting train subjects:  64%|██████▍   | 343/532 [11:14<05:31,  1.76s/it]predicting train subjects:  65%|██████▍   | 344/532 [11:16<05:18,  1.70s/it]predicting train subjects:  65%|██████▍   | 345/532 [11:17<05:12,  1.67s/it]predicting train subjects:  65%|██████▌   | 346/532 [11:19<05:02,  1.63s/it]predicting train subjects:  65%|██████▌   | 347/532 [11:21<05:09,  1.67s/it]predicting train subjects:  65%|██████▌   | 348/532 [11:22<05:15,  1.71s/it]predicting train subjects:  66%|██████▌   | 349/532 [11:24<05:16,  1.73s/it]predicting train subjects:  66%|██████▌   | 350/532 [11:26<05:16,  1.74s/it]predicting train subjects:  66%|██████▌   | 351/532 [11:28<05:14,  1.74s/it]predicting train subjects:  66%|██████▌   | 352/532 [11:30<05:23,  1.79s/it]predicting train subjects:  66%|██████▋   | 353/532 [11:31<05:21,  1.79s/it]predicting train subjects:  67%|██████▋   | 354/532 [11:33<05:16,  1.78s/it]predicting train subjects:  67%|██████▋   | 355/532 [11:35<05:20,  1.81s/it]predicting train subjects:  67%|██████▋   | 356/532 [11:37<05:19,  1.82s/it]predicting train subjects:  67%|██████▋   | 357/532 [11:39<05:15,  1.80s/it]predicting train subjects:  67%|██████▋   | 358/532 [11:40<05:15,  1.81s/it]predicting train subjects:  67%|██████▋   | 359/532 [11:42<05:08,  1.78s/it]predicting train subjects:  68%|██████▊   | 360/532 [11:44<04:57,  1.73s/it]predicting train subjects:  68%|██████▊   | 361/532 [11:45<04:48,  1.69s/it]predicting train subjects:  68%|██████▊   | 362/532 [11:47<04:46,  1.69s/it]predicting train subjects:  68%|██████▊   | 363/532 [11:49<04:39,  1.65s/it]predicting train subjects:  68%|██████▊   | 364/532 [11:50<04:38,  1.66s/it]predicting train subjects:  69%|██████▊   | 365/532 [11:52<04:35,  1.65s/it]predicting train subjects:  69%|██████▉   | 366/532 [11:54<04:33,  1.64s/it]predicting train subjects:  69%|██████▉   | 367/532 [11:55<04:29,  1.63s/it]predicting train subjects:  69%|██████▉   | 368/532 [11:57<04:24,  1.61s/it]predicting train subjects:  69%|██████▉   | 369/532 [11:58<04:24,  1.63s/it]predicting train subjects:  70%|██████▉   | 370/532 [12:00<04:21,  1.61s/it]predicting train subjects:  70%|██████▉   | 371/532 [12:02<04:45,  1.77s/it]predicting train subjects:  70%|██████▉   | 372/532 [12:05<05:22,  2.01s/it]predicting train subjects:  70%|███████   | 373/532 [12:07<05:36,  2.11s/it]predicting train subjects:  70%|███████   | 374/532 [12:09<05:40,  2.16s/it]predicting train subjects:  70%|███████   | 375/532 [12:11<05:40,  2.17s/it]predicting train subjects:  71%|███████   | 376/532 [12:14<05:38,  2.17s/it]predicting train subjects:  71%|███████   | 377/532 [12:15<05:15,  2.04s/it]predicting train subjects:  71%|███████   | 378/532 [12:17<05:03,  1.97s/it]predicting train subjects:  71%|███████   | 379/532 [12:19<04:53,  1.92s/it]predicting train subjects:  71%|███████▏  | 380/532 [12:21<04:48,  1.90s/it]predicting train subjects:  72%|███████▏  | 381/532 [12:23<04:41,  1.87s/it]predicting train subjects:  72%|███████▏  | 382/532 [12:25<04:40,  1.87s/it]predicting train subjects:  72%|███████▏  | 383/532 [12:26<04:44,  1.91s/it]predicting train subjects:  72%|███████▏  | 384/532 [12:29<04:47,  1.94s/it]predicting train subjects:  72%|███████▏  | 385/532 [12:30<04:42,  1.92s/it]predicting train subjects:  73%|███████▎  | 386/532 [12:32<04:41,  1.93s/it]predicting train subjects:  73%|███████▎  | 387/532 [12:34<04:44,  1.96s/it]predicting train subjects:  73%|███████▎  | 388/532 [12:36<04:42,  1.96s/it]predicting train subjects:  73%|███████▎  | 389/532 [12:38<04:38,  1.95s/it]predicting train subjects:  73%|███████▎  | 390/532 [12:40<04:41,  1.98s/it]predicting train subjects:  73%|███████▎  | 391/532 [12:42<04:46,  2.03s/it]predicting train subjects:  74%|███████▎  | 392/532 [12:44<04:44,  2.03s/it]predicting train subjects:  74%|███████▍  | 393/532 [12:46<04:37,  1.99s/it]predicting train subjects:  74%|███████▍  | 394/532 [12:48<04:33,  1.98s/it]predicting train subjects:  74%|███████▍  | 395/532 [12:50<04:27,  1.96s/it]predicting train subjects:  74%|███████▍  | 396/532 [12:52<04:25,  1.95s/it]predicting train subjects:  75%|███████▍  | 397/532 [12:54<04:21,  1.94s/it]predicting train subjects:  75%|███████▍  | 398/532 [12:56<04:19,  1.94s/it]predicting train subjects:  75%|███████▌  | 399/532 [12:58<04:14,  1.91s/it]predicting train subjects:  75%|███████▌  | 400/532 [13:00<04:15,  1.93s/it]predicting train subjects:  75%|███████▌  | 401/532 [13:02<04:16,  1.96s/it]predicting train subjects:  76%|███████▌  | 402/532 [13:04<04:19,  2.00s/it]predicting train subjects:  76%|███████▌  | 403/532 [13:06<04:17,  2.00s/it]predicting train subjects:  76%|███████▌  | 404/532 [13:08<04:19,  2.02s/it]predicting train subjects:  76%|███████▌  | 405/532 [13:10<04:21,  2.06s/it]predicting train subjects:  76%|███████▋  | 406/532 [13:12<04:20,  2.07s/it]predicting train subjects:  77%|███████▋  | 407/532 [13:14<04:09,  2.00s/it]predicting train subjects:  77%|███████▋  | 408/532 [13:16<04:01,  1.95s/it]predicting train subjects:  77%|███████▋  | 409/532 [13:18<03:59,  1.95s/it]predicting train subjects:  77%|███████▋  | 410/532 [13:20<03:55,  1.93s/it]predicting train subjects:  77%|███████▋  | 411/532 [13:22<03:50,  1.91s/it]predicting train subjects:  77%|███████▋  | 412/532 [13:23<03:45,  1.88s/it]predicting train subjects:  78%|███████▊  | 413/532 [13:25<03:40,  1.85s/it]predicting train subjects:  78%|███████▊  | 414/532 [13:27<03:35,  1.83s/it]predicting train subjects:  78%|███████▊  | 415/532 [13:29<03:32,  1.81s/it]predicting train subjects:  78%|███████▊  | 416/532 [13:30<03:25,  1.77s/it]predicting train subjects:  78%|███████▊  | 417/532 [13:32<03:23,  1.77s/it]predicting train subjects:  79%|███████▊  | 418/532 [13:34<03:18,  1.74s/it]predicting train subjects:  79%|███████▉  | 419/532 [13:36<03:24,  1.81s/it]predicting train subjects:  79%|███████▉  | 420/532 [13:38<03:28,  1.86s/it]predicting train subjects:  79%|███████▉  | 421/532 [13:40<03:29,  1.89s/it]predicting train subjects:  79%|███████▉  | 422/532 [13:42<03:30,  1.92s/it]predicting train subjects:  80%|███████▉  | 423/532 [13:44<03:29,  1.93s/it]predicting train subjects:  80%|███████▉  | 424/532 [13:46<03:30,  1.95s/it]predicting train subjects:  80%|███████▉  | 425/532 [13:48<03:29,  1.96s/it]predicting train subjects:  80%|████████  | 426/532 [13:50<03:28,  1.97s/it]predicting train subjects:  80%|████████  | 427/532 [13:52<03:28,  1.99s/it]predicting train subjects:  80%|████████  | 428/532 [13:54<03:23,  1.95s/it]predicting train subjects:  81%|████████  | 429/532 [13:55<03:17,  1.92s/it]predicting train subjects:  81%|████████  | 430/532 [13:57<03:15,  1.92s/it]predicting train subjects:  81%|████████  | 431/532 [13:59<03:18,  1.97s/it]predicting train subjects:  81%|████████  | 432/532 [14:02<03:19,  1.99s/it]predicting train subjects:  81%|████████▏ | 433/532 [14:04<03:23,  2.05s/it]predicting train subjects:  82%|████████▏ | 434/532 [14:06<03:20,  2.05s/it]predicting train subjects:  82%|████████▏ | 435/532 [14:08<03:20,  2.07s/it]predicting train subjects:  82%|████████▏ | 436/532 [14:10<03:20,  2.09s/it]predicting train subjects:  82%|████████▏ | 437/532 [14:12<03:07,  1.97s/it]predicting train subjects:  82%|████████▏ | 438/532 [14:13<02:54,  1.86s/it]predicting train subjects:  83%|████████▎ | 439/532 [14:15<02:45,  1.78s/it]predicting train subjects:  83%|████████▎ | 440/532 [14:17<02:40,  1.75s/it]predicting train subjects:  83%|████████▎ | 441/532 [14:18<02:35,  1.71s/it]predicting train subjects:  83%|████████▎ | 442/532 [14:20<02:35,  1.72s/it]predicting train subjects:  83%|████████▎ | 443/532 [14:22<02:31,  1.70s/it]predicting train subjects:  83%|████████▎ | 444/532 [14:23<02:28,  1.69s/it]predicting train subjects:  84%|████████▎ | 445/532 [14:25<02:26,  1.68s/it]predicting train subjects:  84%|████████▍ | 446/532 [14:27<02:22,  1.66s/it]predicting train subjects:  84%|████████▍ | 447/532 [14:28<02:20,  1.65s/it]predicting train subjects:  84%|████████▍ | 448/532 [14:30<02:18,  1.65s/it]predicting train subjects:  84%|████████▍ | 449/532 [14:32<02:18,  1.67s/it]predicting train subjects:  85%|████████▍ | 450/532 [14:33<02:16,  1.66s/it]predicting train subjects:  85%|████████▍ | 451/532 [14:35<02:14,  1.66s/it]predicting train subjects:  85%|████████▍ | 452/532 [14:37<02:15,  1.69s/it]predicting train subjects:  85%|████████▌ | 453/532 [14:38<02:14,  1.71s/it]predicting train subjects:  85%|████████▌ | 454/532 [14:40<02:14,  1.73s/it]predicting train subjects:  86%|████████▌ | 455/532 [14:42<02:17,  1.78s/it]predicting train subjects:  86%|████████▌ | 456/532 [14:44<02:18,  1.83s/it]predicting train subjects:  86%|████████▌ | 457/532 [14:46<02:18,  1.85s/it]predicting train subjects:  86%|████████▌ | 458/532 [14:48<02:19,  1.88s/it]predicting train subjects:  86%|████████▋ | 459/532 [14:50<02:18,  1.90s/it]predicting train subjects:  86%|████████▋ | 460/532 [14:52<02:16,  1.89s/it]predicting train subjects:  87%|████████▋ | 461/532 [14:54<02:20,  1.97s/it]predicting train subjects:  87%|████████▋ | 462/532 [14:56<02:22,  2.04s/it]predicting train subjects:  87%|████████▋ | 463/532 [14:58<02:22,  2.06s/it]predicting train subjects:  87%|████████▋ | 464/532 [15:00<02:21,  2.08s/it]predicting train subjects:  87%|████████▋ | 465/532 [15:02<02:22,  2.12s/it]predicting train subjects:  88%|████████▊ | 466/532 [15:05<02:19,  2.11s/it]predicting train subjects:  88%|████████▊ | 467/532 [15:06<02:10,  2.01s/it]predicting train subjects:  88%|████████▊ | 468/532 [15:08<02:02,  1.92s/it]predicting train subjects:  88%|████████▊ | 469/532 [15:10<01:58,  1.88s/it]predicting train subjects:  88%|████████▊ | 470/532 [15:11<01:53,  1.84s/it]predicting train subjects:  89%|████████▊ | 471/532 [15:13<01:53,  1.86s/it]predicting train subjects:  89%|████████▊ | 472/532 [15:15<01:49,  1.83s/it]predicting train subjects:  89%|████████▉ | 473/532 [15:17<01:51,  1.89s/it]predicting train subjects:  89%|████████▉ | 474/532 [15:19<01:51,  1.93s/it]predicting train subjects:  89%|████████▉ | 475/532 [15:21<01:51,  1.96s/it]predicting train subjects:  89%|████████▉ | 476/532 [15:23<01:49,  1.96s/it]predicting train subjects:  90%|████████▉ | 477/532 [15:25<01:48,  1.97s/it]predicting train subjects:  90%|████████▉ | 478/532 [15:27<01:46,  1.98s/it]predicting train subjects:  90%|█████████ | 479/532 [15:29<01:41,  1.91s/it]predicting train subjects:  90%|█████████ | 480/532 [15:31<01:36,  1.86s/it]predicting train subjects:  90%|█████████ | 481/532 [15:32<01:32,  1.81s/it]predicting train subjects:  91%|█████████ | 482/532 [15:34<01:28,  1.76s/it]predicting train subjects:  91%|█████████ | 483/532 [15:36<01:25,  1.75s/it]predicting train subjects:  91%|█████████ | 484/532 [15:38<01:24,  1.76s/it]predicting train subjects:  91%|█████████ | 485/532 [15:40<01:27,  1.86s/it]predicting train subjects:  91%|█████████▏| 486/532 [15:42<01:29,  1.95s/it]predicting train subjects:  92%|█████████▏| 487/532 [15:44<01:32,  2.05s/it]predicting train subjects:  92%|█████████▏| 488/532 [15:46<01:30,  2.06s/it]predicting train subjects:  92%|█████████▏| 489/532 [15:48<01:28,  2.06s/it]predicting train subjects:  92%|█████████▏| 490/532 [15:50<01:28,  2.10s/it]predicting train subjects:  92%|█████████▏| 491/532 [15:52<01:24,  2.06s/it]predicting train subjects:  92%|█████████▏| 492/532 [15:54<01:19,  1.98s/it]predicting train subjects:  93%|█████████▎| 493/532 [15:56<01:14,  1.91s/it]predicting train subjects:  93%|█████████▎| 494/532 [15:58<01:10,  1.85s/it]predicting train subjects:  93%|█████████▎| 495/532 [15:59<01:07,  1.82s/it]predicting train subjects:  93%|█████████▎| 496/532 [16:01<01:05,  1.81s/it]predicting train subjects:  93%|█████████▎| 497/532 [16:03<01:03,  1.81s/it]predicting train subjects:  94%|█████████▎| 498/532 [16:05<01:00,  1.79s/it]predicting train subjects:  94%|█████████▍| 499/532 [16:07<00:59,  1.79s/it]predicting train subjects:  94%|█████████▍| 500/532 [16:08<00:57,  1.81s/it]predicting train subjects:  94%|█████████▍| 501/532 [16:11<00:58,  1.90s/it]predicting train subjects:  94%|█████████▍| 502/532 [16:12<00:56,  1.88s/it]predicting train subjects:  95%|█████████▍| 503/532 [16:14<00:53,  1.83s/it]predicting train subjects:  95%|█████████▍| 504/532 [16:16<00:50,  1.81s/it]predicting train subjects:  95%|█████████▍| 505/532 [16:18<00:47,  1.78s/it]predicting train subjects:  95%|█████████▌| 506/532 [16:19<00:45,  1.75s/it]predicting train subjects:  95%|█████████▌| 507/532 [16:21<00:42,  1.71s/it]predicting train subjects:  95%|█████████▌| 508/532 [16:23<00:40,  1.71s/it]predicting train subjects:  96%|█████████▌| 509/532 [16:25<00:41,  1.82s/it]predicting train subjects:  96%|█████████▌| 510/532 [16:27<00:42,  1.91s/it]predicting train subjects:  96%|█████████▌| 511/532 [16:29<00:41,  1.99s/it]predicting train subjects:  96%|█████████▌| 512/532 [16:31<00:41,  2.06s/it]predicting train subjects:  96%|█████████▋| 513/532 [16:33<00:39,  2.07s/it]predicting train subjects:  97%|█████████▋| 514/532 [16:35<00:38,  2.12s/it]predicting train subjects:  97%|█████████▋| 515/532 [16:37<00:34,  2.05s/it]predicting train subjects:  97%|█████████▋| 516/532 [16:39<00:31,  1.97s/it]predicting train subjects:  97%|█████████▋| 517/532 [16:41<00:29,  1.97s/it]predicting train subjects:  97%|█████████▋| 518/532 [16:43<00:26,  1.92s/it]predicting train subjects:  98%|█████████▊| 519/532 [16:45<00:24,  1.90s/it]predicting train subjects:  98%|█████████▊| 520/532 [16:47<00:22,  1.86s/it]predicting train subjects:  98%|█████████▊| 521/532 [16:48<00:20,  1.89s/it]predicting train subjects:  98%|█████████▊| 522/532 [16:50<00:18,  1.88s/it]predicting train subjects:  98%|█████████▊| 523/532 [16:52<00:17,  1.93s/it]predicting train subjects:  98%|█████████▊| 524/532 [16:54<00:15,  1.97s/it]predicting train subjects:  99%|█████████▊| 525/532 [16:56<00:13,  1.97s/it]predicting train subjects:  99%|█████████▉| 526/532 [16:58<00:11,  1.99s/it]predicting train subjects:  99%|█████████▉| 527/532 [17:00<00:09,  1.90s/it]predicting train subjects:  99%|█████████▉| 528/532 [17:02<00:07,  1.85s/it]predicting train subjects:  99%|█████████▉| 529/532 [17:04<00:05,  1.81s/it]predicting train subjects: 100%|█████████▉| 530/532 [17:05<00:03,  1.77s/it]predicting train subjects: 100%|█████████▉| 531/532 [17:07<00:01,  1.79s/it]predicting train subjects: 100%|██████████| 532/532 [17:09<00:00,  1.80s/it]
Loading train:   0%|          | 0/532 [00:00<?, ?it/s]Loading train:   0%|          | 1/532 [00:01<12:04,  1.36s/it]Loading train:   0%|          | 2/532 [00:02<10:44,  1.22s/it]Loading train:   1%|          | 3/532 [00:03<10:07,  1.15s/it]Loading train:   1%|          | 4/532 [00:04<09:47,  1.11s/it]Loading train:   1%|          | 5/532 [00:05<09:25,  1.07s/it]Loading train:   1%|          | 6/532 [00:06<09:25,  1.08s/it]Loading train:   1%|▏         | 7/532 [00:07<09:12,  1.05s/it]Loading train:   2%|▏         | 8/532 [00:08<08:57,  1.03s/it]Loading train:   2%|▏         | 9/532 [00:09<09:32,  1.09s/it]Loading train:   2%|▏         | 10/532 [00:10<09:21,  1.08s/it]Loading train:   2%|▏         | 11/532 [00:11<08:59,  1.03s/it]Loading train:   2%|▏         | 12/532 [00:12<09:25,  1.09s/it]Loading train:   2%|▏         | 13/532 [00:13<08:40,  1.00s/it]Loading train:   3%|▎         | 14/532 [00:14<08:12,  1.05it/s]Loading train:   3%|▎         | 15/532 [00:15<08:23,  1.03it/s]Loading train:   3%|▎         | 16/532 [00:16<08:20,  1.03it/s]Loading train:   3%|▎         | 17/532 [00:17<08:27,  1.01it/s]Loading train:   3%|▎         | 18/532 [00:18<08:33,  1.00it/s]Loading train:   4%|▎         | 19/532 [00:19<08:06,  1.06it/s]Loading train:   4%|▍         | 20/532 [00:20<08:05,  1.05it/s]Loading train:   4%|▍         | 21/532 [00:21<08:33,  1.00s/it]Loading train:   4%|▍         | 22/532 [00:22<08:53,  1.05s/it]Loading train:   4%|▍         | 23/532 [00:23<08:53,  1.05s/it]Loading train:   5%|▍         | 24/532 [00:24<08:44,  1.03s/it]Loading train:   5%|▍         | 25/532 [00:25<09:05,  1.08s/it]Loading train:   5%|▍         | 26/532 [00:26<09:02,  1.07s/it]Loading train:   5%|▌         | 27/532 [00:28<09:59,  1.19s/it]Loading train:   5%|▌         | 28/532 [00:29<09:16,  1.10s/it]Loading train:   5%|▌         | 29/532 [00:30<09:45,  1.16s/it]Loading train:   6%|▌         | 30/532 [00:31<09:17,  1.11s/it]Loading train:   6%|▌         | 31/532 [00:32<08:45,  1.05s/it]Loading train:   6%|▌         | 32/532 [00:33<08:32,  1.02s/it]Loading train:   6%|▌         | 33/532 [00:34<08:00,  1.04it/s]Loading train:   6%|▋         | 34/532 [00:35<08:49,  1.06s/it]Loading train:   7%|▋         | 35/532 [00:36<08:13,  1.01it/s]Loading train:   7%|▋         | 36/532 [00:37<08:43,  1.06s/it]Loading train:   7%|▋         | 37/532 [00:38<08:38,  1.05s/it]Loading train:   7%|▋         | 38/532 [00:39<09:17,  1.13s/it]Loading train:   7%|▋         | 39/532 [00:40<08:42,  1.06s/it]Loading train:   8%|▊         | 40/532 [00:41<08:14,  1.01s/it]Loading train:   8%|▊         | 41/532 [00:42<08:16,  1.01s/it]Loading train:   8%|▊         | 42/532 [00:43<08:23,  1.03s/it]Loading train:   8%|▊         | 43/532 [00:44<08:01,  1.02it/s]Loading train:   8%|▊         | 44/532 [00:45<07:42,  1.06it/s]Loading train:   8%|▊         | 45/532 [00:46<07:40,  1.06it/s]Loading train:   9%|▊         | 46/532 [00:47<07:41,  1.05it/s]Loading train:   9%|▉         | 47/532 [00:48<08:46,  1.09s/it]Loading train:   9%|▉         | 48/532 [00:49<08:29,  1.05s/it]Loading train:   9%|▉         | 49/532 [00:50<07:58,  1.01it/s]Loading train:   9%|▉         | 50/532 [00:51<07:50,  1.03it/s]Loading train:  10%|▉         | 51/532 [00:52<07:30,  1.07it/s]Loading train:  10%|▉         | 52/532 [00:53<07:17,  1.10it/s]Loading train:  10%|▉         | 53/532 [00:53<07:02,  1.13it/s]Loading train:  10%|█         | 54/532 [00:55<07:42,  1.03it/s]Loading train:  10%|█         | 55/532 [00:56<07:51,  1.01it/s]Loading train:  11%|█         | 56/532 [00:57<07:54,  1.00it/s]Loading train:  11%|█         | 57/532 [00:58<07:48,  1.01it/s]Loading train:  11%|█         | 58/532 [00:58<07:26,  1.06it/s]Loading train:  11%|█         | 59/532 [01:00<08:32,  1.08s/it]Loading train:  11%|█▏        | 60/532 [01:01<07:41,  1.02it/s]Loading train:  11%|█▏        | 61/532 [01:02<07:45,  1.01it/s]Loading train:  12%|█▏        | 62/532 [01:03<07:47,  1.00it/s]Loading train:  12%|█▏        | 63/532 [01:04<08:08,  1.04s/it]Loading train:  12%|█▏        | 64/532 [01:05<08:06,  1.04s/it]Loading train:  12%|█▏        | 65/532 [01:06<07:38,  1.02it/s]Loading train:  12%|█▏        | 66/532 [01:07<08:36,  1.11s/it]Loading train:  13%|█▎        | 67/532 [01:08<08:52,  1.15s/it]Loading train:  13%|█▎        | 68/532 [01:09<08:21,  1.08s/it]Loading train:  13%|█▎        | 69/532 [01:10<08:20,  1.08s/it]Loading train:  13%|█▎        | 70/532 [01:11<07:38,  1.01it/s]Loading train:  13%|█▎        | 71/532 [01:12<07:04,  1.09it/s]Loading train:  14%|█▎        | 72/532 [01:13<06:57,  1.10it/s]Loading train:  14%|█▎        | 73/532 [01:14<06:54,  1.11it/s]Loading train:  14%|█▍        | 74/532 [01:15<08:03,  1.05s/it]Loading train:  14%|█▍        | 75/532 [01:17<09:28,  1.24s/it]Loading train:  14%|█▍        | 76/532 [01:18<08:25,  1.11s/it]Loading train:  14%|█▍        | 77/532 [01:18<07:59,  1.05s/it]Loading train:  15%|█▍        | 78/532 [01:19<07:41,  1.02s/it]Loading train:  15%|█▍        | 79/532 [01:20<07:22,  1.02it/s]Loading train:  15%|█▌        | 80/532 [01:21<07:33,  1.00s/it]Loading train:  15%|█▌        | 81/532 [01:22<07:19,  1.03it/s]Loading train:  15%|█▌        | 82/532 [01:23<07:17,  1.03it/s]Loading train:  16%|█▌        | 83/532 [01:24<06:46,  1.10it/s]Loading train:  16%|█▌        | 84/532 [01:25<06:34,  1.14it/s]Loading train:  16%|█▌        | 85/532 [01:26<06:40,  1.12it/s]Loading train:  16%|█▌        | 86/532 [01:27<06:31,  1.14it/s]Loading train:  16%|█▋        | 87/532 [01:27<06:16,  1.18it/s]Loading train:  17%|█▋        | 88/532 [01:28<06:22,  1.16it/s]Loading train:  17%|█▋        | 89/532 [01:29<06:37,  1.11it/s]Loading train:  17%|█▋        | 90/532 [01:30<06:43,  1.09it/s]Loading train:  17%|█▋        | 91/532 [01:31<06:33,  1.12it/s]Loading train:  17%|█▋        | 92/532 [01:32<06:31,  1.12it/s]Loading train:  17%|█▋        | 93/532 [01:33<06:49,  1.07it/s]Loading train:  18%|█▊        | 94/532 [01:34<06:42,  1.09it/s]Loading train:  18%|█▊        | 95/532 [01:35<07:08,  1.02it/s]Loading train:  18%|█▊        | 96/532 [01:36<07:33,  1.04s/it]Loading train:  18%|█▊        | 97/532 [01:37<07:39,  1.06s/it]Loading train:  18%|█▊        | 98/532 [01:38<07:36,  1.05s/it]Loading train:  19%|█▊        | 99/532 [01:39<07:37,  1.06s/it]Loading train:  19%|█▉        | 100/532 [01:40<07:35,  1.05s/it]Loading train:  19%|█▉        | 101/532 [01:41<07:03,  1.02it/s]Loading train:  19%|█▉        | 102/532 [01:42<06:55,  1.03it/s]Loading train:  19%|█▉        | 103/532 [01:43<06:33,  1.09it/s]Loading train:  20%|█▉        | 104/532 [01:44<06:08,  1.16it/s]Loading train:  20%|█▉        | 105/532 [01:45<06:14,  1.14it/s]Loading train:  20%|█▉        | 106/532 [01:45<05:57,  1.19it/s]Loading train:  20%|██        | 107/532 [01:46<05:52,  1.21it/s]Loading train:  20%|██        | 108/532 [01:47<05:44,  1.23it/s]Loading train:  20%|██        | 109/532 [01:48<05:45,  1.22it/s]Loading train:  21%|██        | 110/532 [01:49<06:12,  1.13it/s]Loading train:  21%|██        | 111/532 [01:50<06:07,  1.14it/s]Loading train:  21%|██        | 112/532 [01:50<05:57,  1.18it/s]Loading train:  21%|██        | 113/532 [01:51<06:05,  1.15it/s]Loading train:  21%|██▏       | 114/532 [01:52<05:56,  1.17it/s]Loading train:  22%|██▏       | 115/532 [01:53<06:03,  1.15it/s]Loading train:  22%|██▏       | 116/532 [01:54<06:40,  1.04it/s]Loading train:  22%|██▏       | 117/532 [01:55<07:16,  1.05s/it]Loading train:  22%|██▏       | 118/532 [01:57<08:40,  1.26s/it]Loading train:  22%|██▏       | 119/532 [01:59<09:34,  1.39s/it]Loading train:  23%|██▎       | 120/532 [02:00<08:49,  1.29s/it]Loading train:  23%|██▎       | 121/532 [02:01<09:04,  1.32s/it]Loading train:  23%|██▎       | 122/532 [02:03<09:14,  1.35s/it]Loading train:  23%|██▎       | 123/532 [02:04<09:29,  1.39s/it]Loading train:  23%|██▎       | 124/532 [02:05<08:45,  1.29s/it]Loading train:  23%|██▎       | 125/532 [02:07<10:20,  1.52s/it]Loading train:  24%|██▎       | 126/532 [02:09<10:11,  1.51s/it]Loading train:  24%|██▍       | 127/532 [02:10<09:30,  1.41s/it]Loading train:  24%|██▍       | 128/532 [02:11<09:08,  1.36s/it]Loading train:  24%|██▍       | 129/532 [02:13<09:26,  1.41s/it]Loading train:  24%|██▍       | 130/532 [02:14<09:12,  1.37s/it]Loading train:  25%|██▍       | 131/532 [02:16<10:11,  1.53s/it]Loading train:  25%|██▍       | 132/532 [02:18<11:06,  1.67s/it]Loading train:  25%|██▌       | 133/532 [02:20<11:25,  1.72s/it]Loading train:  25%|██▌       | 134/532 [02:22<11:41,  1.76s/it]Loading train:  25%|██▌       | 135/532 [02:24<11:55,  1.80s/it]Loading train:  26%|██▌       | 136/532 [02:25<11:59,  1.82s/it]Loading train:  26%|██▌       | 137/532 [02:27<12:29,  1.90s/it]Loading train:  26%|██▌       | 138/532 [02:29<12:23,  1.89s/it]Loading train:  26%|██▌       | 139/532 [02:31<11:37,  1.77s/it]Loading train:  26%|██▋       | 140/532 [02:32<10:57,  1.68s/it]Loading train:  27%|██▋       | 141/532 [02:34<10:43,  1.65s/it]Loading train:  27%|██▋       | 142/532 [02:35<10:28,  1.61s/it]Loading train:  27%|██▋       | 143/532 [02:36<09:10,  1.42s/it]Loading train:  27%|██▋       | 144/532 [02:38<09:02,  1.40s/it]Loading train:  27%|██▋       | 145/532 [02:39<08:47,  1.36s/it]Loading train:  27%|██▋       | 146/532 [02:40<08:48,  1.37s/it]Loading train:  28%|██▊       | 147/532 [02:42<08:38,  1.35s/it]Loading train:  28%|██▊       | 148/532 [02:43<08:16,  1.29s/it]Loading train:  28%|██▊       | 149/532 [02:45<09:20,  1.46s/it]Loading train:  28%|██▊       | 150/532 [02:46<09:15,  1.45s/it]Loading train:  28%|██▊       | 151/532 [02:48<09:42,  1.53s/it]Loading train:  29%|██▊       | 152/532 [02:49<09:35,  1.51s/it]Loading train:  29%|██▉       | 153/532 [02:50<08:37,  1.36s/it]Loading train:  29%|██▉       | 154/532 [02:52<08:30,  1.35s/it]Loading train:  29%|██▉       | 155/532 [02:54<10:15,  1.63s/it]Loading train:  29%|██▉       | 156/532 [02:56<10:30,  1.68s/it]Loading train:  30%|██▉       | 157/532 [02:57<10:36,  1.70s/it]Loading train:  30%|██▉       | 158/532 [02:59<10:30,  1.68s/it]Loading train:  30%|██▉       | 159/532 [03:01<11:12,  1.80s/it]Loading train:  30%|███       | 160/532 [03:03<11:49,  1.91s/it]Loading train:  30%|███       | 161/532 [03:05<10:31,  1.70s/it]Loading train:  30%|███       | 162/532 [03:05<09:00,  1.46s/it]Loading train:  31%|███       | 163/532 [03:07<08:41,  1.41s/it]Loading train:  31%|███       | 164/532 [03:08<08:35,  1.40s/it]Loading train:  31%|███       | 165/532 [03:09<08:21,  1.37s/it]Loading train:  31%|███       | 166/532 [03:11<07:47,  1.28s/it]Loading train:  31%|███▏      | 167/532 [03:12<07:41,  1.26s/it]Loading train:  32%|███▏      | 168/532 [03:13<07:32,  1.24s/it]Loading train:  32%|███▏      | 169/532 [03:14<07:26,  1.23s/it]Loading train:  32%|███▏      | 170/532 [03:15<07:25,  1.23s/it]Loading train:  32%|███▏      | 171/532 [03:17<07:29,  1.25s/it]Loading train:  32%|███▏      | 172/532 [03:18<07:21,  1.23s/it]Loading train:  33%|███▎      | 173/532 [03:19<07:18,  1.22s/it]Loading train:  33%|███▎      | 174/532 [03:20<07:12,  1.21s/it]Loading train:  33%|███▎      | 175/532 [03:22<07:19,  1.23s/it]Loading train:  33%|███▎      | 176/532 [03:23<07:26,  1.25s/it]Loading train:  33%|███▎      | 177/532 [03:24<06:54,  1.17s/it]Loading train:  33%|███▎      | 178/532 [03:25<07:09,  1.21s/it]Loading train:  34%|███▎      | 179/532 [03:27<07:53,  1.34s/it]Loading train:  34%|███▍      | 180/532 [03:28<07:33,  1.29s/it]Loading train:  34%|███▍      | 181/532 [03:29<07:37,  1.30s/it]Loading train:  34%|███▍      | 182/532 [03:31<07:53,  1.35s/it]Loading train:  34%|███▍      | 183/532 [03:33<08:49,  1.52s/it]Loading train:  35%|███▍      | 184/532 [03:34<09:03,  1.56s/it]Loading train:  35%|███▍      | 185/532 [03:35<08:15,  1.43s/it]Loading train:  35%|███▍      | 186/532 [03:37<07:43,  1.34s/it]Loading train:  35%|███▌      | 187/532 [03:38<07:46,  1.35s/it]Loading train:  35%|███▌      | 188/532 [03:39<07:23,  1.29s/it]Loading train:  36%|███▌      | 189/532 [03:40<06:51,  1.20s/it]Loading train:  36%|███▌      | 190/532 [03:41<06:15,  1.10s/it]Loading train:  36%|███▌      | 191/532 [03:43<07:46,  1.37s/it]Loading train:  36%|███▌      | 192/532 [03:45<09:15,  1.63s/it]Loading train:  36%|███▋      | 193/532 [03:47<09:59,  1.77s/it]Loading train:  36%|███▋      | 194/532 [03:49<10:31,  1.87s/it]Loading train:  37%|███▋      | 195/532 [03:51<10:17,  1.83s/it]Loading train:  37%|███▋      | 196/532 [03:53<09:47,  1.75s/it]Loading train:  37%|███▋      | 197/532 [03:54<09:25,  1.69s/it]Loading train:  37%|███▋      | 198/532 [03:56<10:05,  1.81s/it]Loading train:  37%|███▋      | 199/532 [03:58<09:37,  1.74s/it]Loading train:  38%|███▊      | 200/532 [04:00<09:38,  1.74s/it]Loading train:  38%|███▊      | 201/532 [04:01<09:04,  1.65s/it]Loading train:  38%|███▊      | 202/532 [04:03<08:51,  1.61s/it]Loading train:  38%|███▊      | 203/532 [04:04<08:07,  1.48s/it]Loading train:  38%|███▊      | 204/532 [04:05<07:30,  1.37s/it]Loading train:  39%|███▊      | 205/532 [04:06<07:40,  1.41s/it]Loading train:  39%|███▊      | 206/532 [04:08<07:27,  1.37s/it]Loading train:  39%|███▉      | 207/532 [04:09<07:04,  1.31s/it]Loading train:  39%|███▉      | 208/532 [04:10<07:14,  1.34s/it]Loading train:  39%|███▉      | 209/532 [04:12<07:18,  1.36s/it]Loading train:  39%|███▉      | 210/532 [04:13<06:43,  1.25s/it]Loading train:  40%|███▉      | 211/532 [04:14<06:59,  1.31s/it]Loading train:  40%|███▉      | 212/532 [04:15<06:48,  1.28s/it]Loading train:  40%|████      | 213/532 [04:17<07:08,  1.34s/it]Loading train:  40%|████      | 214/532 [04:18<07:33,  1.43s/it]Loading train:  40%|████      | 215/532 [04:20<08:15,  1.56s/it]Loading train:  41%|████      | 216/532 [04:22<08:38,  1.64s/it]Loading train:  41%|████      | 217/532 [04:24<08:41,  1.66s/it]Loading train:  41%|████      | 218/532 [04:25<08:36,  1.65s/it]Loading train:  41%|████      | 219/532 [04:27<08:43,  1.67s/it]Loading train:  41%|████▏     | 220/532 [04:29<08:28,  1.63s/it]Loading train:  42%|████▏     | 221/532 [04:30<08:01,  1.55s/it]Loading train:  42%|████▏     | 222/532 [04:31<07:22,  1.43s/it]Loading train:  42%|████▏     | 223/532 [04:32<07:10,  1.39s/it]Loading train:  42%|████▏     | 224/532 [04:34<06:46,  1.32s/it]Loading train:  42%|████▏     | 225/532 [04:35<06:50,  1.34s/it]Loading train:  42%|████▏     | 226/532 [04:36<06:40,  1.31s/it]Loading train:  43%|████▎     | 227/532 [04:38<06:51,  1.35s/it]Loading train:  43%|████▎     | 228/532 [04:39<06:40,  1.32s/it]Loading train:  43%|████▎     | 229/532 [04:40<06:50,  1.36s/it]Loading train:  43%|████▎     | 230/532 [04:42<06:41,  1.33s/it]Loading train:  43%|████▎     | 231/532 [04:43<06:21,  1.27s/it]Loading train:  44%|████▎     | 232/532 [04:44<05:53,  1.18s/it]Loading train:  44%|████▍     | 233/532 [04:45<06:24,  1.29s/it]Loading train:  44%|████▍     | 234/532 [04:46<06:15,  1.26s/it]Loading train:  44%|████▍     | 235/532 [04:48<06:12,  1.25s/it]Loading train:  44%|████▍     | 236/532 [04:49<06:04,  1.23s/it]Loading train:  45%|████▍     | 237/532 [04:50<06:30,  1.32s/it]Loading train:  45%|████▍     | 238/532 [04:52<06:20,  1.30s/it]Loading train:  45%|████▍     | 239/532 [04:53<05:44,  1.18s/it]Loading train:  45%|████▌     | 240/532 [04:54<06:02,  1.24s/it]Loading train:  45%|████▌     | 241/532 [04:55<06:06,  1.26s/it]Loading train:  45%|████▌     | 242/532 [04:56<05:44,  1.19s/it]Loading train:  46%|████▌     | 243/532 [04:58<05:52,  1.22s/it]Loading train:  46%|████▌     | 244/532 [04:59<05:58,  1.24s/it]Loading train:  46%|████▌     | 245/532 [05:00<06:26,  1.35s/it]Loading train:  46%|████▌     | 246/532 [05:01<05:47,  1.21s/it]Loading train:  46%|████▋     | 247/532 [05:02<05:25,  1.14s/it]Loading train:  47%|████▋     | 248/532 [05:03<05:26,  1.15s/it]Loading train:  47%|████▋     | 249/532 [05:05<05:22,  1.14s/it]Loading train:  47%|████▋     | 250/532 [05:06<05:14,  1.12s/it]Loading train:  47%|████▋     | 251/532 [05:07<05:31,  1.18s/it]Loading train:  47%|████▋     | 252/532 [05:08<05:11,  1.11s/it]Loading train:  48%|████▊     | 253/532 [05:09<05:28,  1.18s/it]Loading train:  48%|████▊     | 254/532 [05:11<06:01,  1.30s/it]Loading train:  48%|████▊     | 255/532 [05:12<05:42,  1.24s/it]Loading train:  48%|████▊     | 256/532 [05:13<05:33,  1.21s/it]Loading train:  48%|████▊     | 257/532 [05:14<05:45,  1.26s/it]Loading train:  48%|████▊     | 258/532 [05:16<05:54,  1.29s/it]Loading train:  49%|████▊     | 259/532 [05:17<06:01,  1.32s/it]Loading train:  49%|████▉     | 260/532 [05:19<06:25,  1.42s/it]Loading train:  49%|████▉     | 261/532 [05:20<06:03,  1.34s/it]Loading train:  49%|████▉     | 262/532 [05:22<06:37,  1.47s/it]Loading train:  49%|████▉     | 263/532 [05:23<06:28,  1.45s/it]Loading train:  50%|████▉     | 264/532 [05:24<06:04,  1.36s/it]Loading train:  50%|████▉     | 265/532 [05:25<05:42,  1.28s/it]Loading train:  50%|█████     | 266/532 [05:27<05:57,  1.34s/it]Loading train:  50%|█████     | 267/532 [05:28<05:31,  1.25s/it]Loading train:  50%|█████     | 268/532 [05:29<05:15,  1.19s/it]Loading train:  51%|█████     | 269/532 [05:30<05:16,  1.20s/it]Loading train:  51%|█████     | 270/532 [05:32<05:28,  1.26s/it]Loading train:  51%|█████     | 271/532 [05:33<05:38,  1.30s/it]Loading train:  51%|█████     | 272/532 [05:34<05:45,  1.33s/it]Loading train:  51%|█████▏    | 273/532 [05:36<06:05,  1.41s/it]Loading train:  52%|█████▏    | 274/532 [05:38<06:09,  1.43s/it]Loading train:  52%|█████▏    | 275/532 [05:39<06:38,  1.55s/it]Loading train:  52%|█████▏    | 276/532 [05:41<07:15,  1.70s/it]Loading train:  52%|█████▏    | 277/532 [05:43<07:42,  1.81s/it]Loading train:  52%|█████▏    | 278/532 [05:45<07:32,  1.78s/it]Loading train:  52%|█████▏    | 279/532 [05:47<07:41,  1.83s/it]Loading train:  53%|█████▎    | 280/532 [05:49<07:16,  1.73s/it]Loading train:  53%|█████▎    | 281/532 [05:50<07:13,  1.73s/it]Loading train:  53%|█████▎    | 282/532 [05:52<07:30,  1.80s/it]Loading train:  53%|█████▎    | 283/532 [05:54<07:20,  1.77s/it]Loading train:  53%|█████▎    | 284/532 [05:55<06:40,  1.62s/it]Loading train:  54%|█████▎    | 285/532 [05:56<06:02,  1.47s/it]Loading train:  54%|█████▍    | 286/532 [05:58<06:03,  1.48s/it]Loading train:  54%|█████▍    | 287/532 [05:59<06:03,  1.48s/it]Loading train:  54%|█████▍    | 288/532 [06:01<05:53,  1.45s/it]Loading train:  54%|█████▍    | 289/532 [06:02<05:40,  1.40s/it]Loading train:  55%|█████▍    | 290/532 [06:03<05:20,  1.32s/it]Loading train:  55%|█████▍    | 291/532 [06:04<05:08,  1.28s/it]Loading train:  55%|█████▍    | 292/532 [06:05<04:50,  1.21s/it]Loading train:  55%|█████▌    | 293/532 [06:07<05:02,  1.27s/it]Loading train:  55%|█████▌    | 294/532 [06:08<05:12,  1.31s/it]Loading train:  55%|█████▌    | 295/532 [06:10<05:49,  1.47s/it]Loading train:  56%|█████▌    | 296/532 [06:11<05:39,  1.44s/it]Loading train:  56%|█████▌    | 297/532 [06:13<05:53,  1.50s/it]Loading train:  56%|█████▌    | 298/532 [06:15<06:01,  1.54s/it]Loading train:  56%|█████▌    | 299/532 [06:16<05:25,  1.40s/it]Loading train:  56%|█████▋    | 300/532 [06:17<05:09,  1.33s/it]Loading train:  57%|█████▋    | 301/532 [06:18<05:00,  1.30s/it]Loading train:  57%|█████▋    | 302/532 [06:19<04:50,  1.26s/it]Loading train:  57%|█████▋    | 303/532 [06:21<04:55,  1.29s/it]Loading train:  57%|█████▋    | 304/532 [06:22<04:38,  1.22s/it]Loading train:  57%|█████▋    | 305/532 [06:24<05:10,  1.37s/it]Loading train:  58%|█████▊    | 306/532 [06:25<05:24,  1.43s/it]Loading train:  58%|█████▊    | 307/532 [06:27<05:43,  1.52s/it]Loading train:  58%|█████▊    | 308/532 [06:29<06:26,  1.73s/it]Loading train:  58%|█████▊    | 309/532 [06:31<06:09,  1.66s/it]Loading train:  58%|█████▊    | 310/532 [06:32<06:02,  1.63s/it]Loading train:  58%|█████▊    | 311/532 [06:34<06:46,  1.84s/it]Loading train:  59%|█████▊    | 312/532 [06:37<07:04,  1.93s/it]Loading train:  59%|█████▉    | 313/532 [06:39<07:30,  2.06s/it]Loading train:  59%|█████▉    | 314/532 [06:41<07:22,  2.03s/it]Loading train:  59%|█████▉    | 315/532 [06:43<07:12,  1.99s/it]Loading train:  59%|█████▉    | 316/532 [06:45<07:24,  2.06s/it]Loading train:  60%|█████▉    | 317/532 [06:46<06:38,  1.85s/it]Loading train:  60%|█████▉    | 318/532 [06:48<06:05,  1.71s/it]Loading train:  60%|█████▉    | 319/532 [06:49<05:31,  1.56s/it]Loading train:  60%|██████    | 320/532 [06:50<05:08,  1.46s/it]Loading train:  60%|██████    | 321/532 [06:52<05:06,  1.45s/it]Loading train:  61%|██████    | 322/532 [06:53<04:49,  1.38s/it]Loading train:  61%|██████    | 323/532 [06:55<05:21,  1.54s/it]Loading train:  61%|██████    | 324/532 [06:57<05:54,  1.70s/it]Loading train:  61%|██████    | 325/532 [06:58<05:46,  1.67s/it]Loading train:  61%|██████▏   | 326/532 [07:00<05:50,  1.70s/it]Loading train:  61%|██████▏   | 327/532 [07:02<06:07,  1.79s/it]Loading train:  62%|██████▏   | 328/532 [07:04<06:20,  1.86s/it]Loading train:  62%|██████▏   | 329/532 [07:06<06:12,  1.84s/it]Loading train:  62%|██████▏   | 330/532 [07:07<05:50,  1.73s/it]Loading train:  62%|██████▏   | 331/532 [07:09<05:37,  1.68s/it]Loading train:  62%|██████▏   | 332/532 [07:10<05:06,  1.53s/it]Loading train:  63%|██████▎   | 333/532 [07:12<04:52,  1.47s/it]Loading train:  63%|██████▎   | 334/532 [07:13<04:59,  1.51s/it]Loading train:  63%|██████▎   | 335/532 [07:15<05:18,  1.62s/it]Loading train:  63%|██████▎   | 336/532 [07:17<05:36,  1.72s/it]Loading train:  63%|██████▎   | 337/532 [07:19<05:26,  1.67s/it]Loading train:  64%|██████▎   | 338/532 [07:20<05:16,  1.63s/it]Loading train:  64%|██████▎   | 339/532 [07:21<05:00,  1.56s/it]Loading train:  64%|██████▍   | 340/532 [07:23<04:58,  1.56s/it]Loading train:  64%|██████▍   | 341/532 [07:24<04:27,  1.40s/it]Loading train:  64%|██████▍   | 342/532 [07:25<04:27,  1.41s/it]Loading train:  64%|██████▍   | 343/532 [07:27<04:16,  1.36s/it]Loading train:  65%|██████▍   | 344/532 [07:28<04:11,  1.34s/it]Loading train:  65%|██████▍   | 345/532 [07:29<04:07,  1.33s/it]Loading train:  65%|██████▌   | 346/532 [07:31<04:03,  1.31s/it]Loading train:  65%|██████▌   | 347/532 [07:32<04:27,  1.45s/it]Loading train:  65%|██████▌   | 348/532 [07:34<04:40,  1.52s/it]Loading train:  66%|██████▌   | 349/532 [07:36<05:04,  1.66s/it]Loading train:  66%|██████▌   | 350/532 [07:38<05:03,  1.67s/it]Loading train:  66%|██████▌   | 351/532 [07:39<04:53,  1.62s/it]Loading train:  66%|██████▌   | 352/532 [07:40<04:29,  1.50s/it]Loading train:  66%|██████▋   | 353/532 [07:42<04:24,  1.48s/it]Loading train:  67%|██████▋   | 354/532 [07:44<04:38,  1.57s/it]Loading train:  67%|██████▋   | 355/532 [07:45<04:35,  1.56s/it]Loading train:  67%|██████▋   | 356/532 [07:47<04:24,  1.50s/it]Loading train:  67%|██████▋   | 357/532 [07:48<04:15,  1.46s/it]Loading train:  67%|██████▋   | 358/532 [07:49<04:01,  1.39s/it]Loading train:  67%|██████▋   | 359/532 [07:50<03:45,  1.30s/it]Loading train:  68%|██████▊   | 360/532 [07:51<03:26,  1.20s/it]Loading train:  68%|██████▊   | 361/532 [07:53<03:34,  1.25s/it]Loading train:  68%|██████▊   | 362/532 [07:54<03:20,  1.18s/it]Loading train:  68%|██████▊   | 363/532 [07:55<03:12,  1.14s/it]Loading train:  68%|██████▊   | 364/532 [07:56<03:29,  1.25s/it]Loading train:  69%|██████▊   | 365/532 [07:58<03:37,  1.30s/it]Loading train:  69%|██████▉   | 366/532 [07:59<03:50,  1.39s/it]Loading train:  69%|██████▉   | 367/532 [08:00<03:37,  1.32s/it]Loading train:  69%|██████▉   | 368/532 [08:01<03:13,  1.18s/it]Loading train:  69%|██████▉   | 369/532 [08:02<03:11,  1.18s/it]Loading train:  70%|██████▉   | 370/532 [08:04<03:25,  1.27s/it]Loading train:  70%|██████▉   | 371/532 [08:06<03:55,  1.46s/it]Loading train:  70%|██████▉   | 372/532 [08:07<03:57,  1.48s/it]Loading train:  70%|███████   | 373/532 [08:09<03:47,  1.43s/it]Loading train:  70%|███████   | 374/532 [08:10<03:50,  1.46s/it]Loading train:  70%|███████   | 375/532 [08:12<04:05,  1.56s/it]Loading train:  71%|███████   | 376/532 [08:13<04:01,  1.55s/it]Loading train:  71%|███████   | 377/532 [08:15<03:55,  1.52s/it]Loading train:  71%|███████   | 378/532 [08:16<03:29,  1.36s/it]Loading train:  71%|███████   | 379/532 [08:17<03:16,  1.29s/it]Loading train:  71%|███████▏  | 380/532 [08:18<03:12,  1.27s/it]Loading train:  72%|███████▏  | 381/532 [08:19<03:01,  1.20s/it]Loading train:  72%|███████▏  | 382/532 [08:21<03:12,  1.28s/it]Loading train:  72%|███████▏  | 383/532 [08:22<03:24,  1.37s/it]Loading train:  72%|███████▏  | 384/532 [08:24<03:20,  1.36s/it]Loading train:  72%|███████▏  | 385/532 [08:25<03:11,  1.30s/it]Loading train:  73%|███████▎  | 386/532 [08:26<03:19,  1.37s/it]Loading train:  73%|███████▎  | 387/532 [08:28<03:42,  1.53s/it]Loading train:  73%|███████▎  | 388/532 [08:30<04:01,  1.67s/it]Loading train:  73%|███████▎  | 389/532 [08:31<03:40,  1.54s/it]Loading train:  73%|███████▎  | 390/532 [08:32<03:12,  1.36s/it]Loading train:  73%|███████▎  | 391/532 [08:33<02:53,  1.23s/it]Loading train:  74%|███████▎  | 392/532 [08:35<03:01,  1.29s/it]Loading train:  74%|███████▍  | 393/532 [08:36<03:13,  1.39s/it]Loading train:  74%|███████▍  | 394/532 [08:38<03:12,  1.40s/it]Loading train:  74%|███████▍  | 395/532 [08:39<02:56,  1.29s/it]Loading train:  74%|███████▍  | 396/532 [08:40<02:39,  1.17s/it]Loading train:  75%|███████▍  | 397/532 [08:41<02:29,  1.11s/it]Loading train:  75%|███████▍  | 398/532 [08:42<02:20,  1.05s/it]Loading train:  75%|███████▌  | 399/532 [08:43<02:16,  1.02s/it]Loading train:  75%|███████▌  | 400/532 [08:43<02:09,  1.02it/s]Loading train:  75%|███████▌  | 401/532 [08:45<02:16,  1.05s/it]Loading train:  76%|███████▌  | 402/532 [08:46<02:10,  1.00s/it]Loading train:  76%|███████▌  | 403/532 [08:47<02:08,  1.01it/s]Loading train:  76%|███████▌  | 404/532 [08:47<02:01,  1.06it/s]Loading train:  76%|███████▌  | 405/532 [08:48<02:00,  1.05it/s]Loading train:  76%|███████▋  | 406/532 [08:49<02:01,  1.04it/s]Loading train:  77%|███████▋  | 407/532 [08:50<01:56,  1.07it/s]Loading train:  77%|███████▋  | 408/532 [08:51<01:52,  1.10it/s]Loading train:  77%|███████▋  | 409/532 [08:52<01:53,  1.08it/s]Loading train:  77%|███████▋  | 410/532 [08:53<01:50,  1.10it/s]Loading train:  77%|███████▋  | 411/532 [08:54<01:48,  1.11it/s]Loading train:  77%|███████▋  | 412/532 [08:55<01:47,  1.11it/s]Loading train:  78%|███████▊  | 413/532 [08:56<01:51,  1.07it/s]Loading train:  78%|███████▊  | 414/532 [08:56<01:46,  1.11it/s]Loading train:  78%|███████▊  | 415/532 [08:57<01:41,  1.16it/s]Loading train:  78%|███████▊  | 416/532 [08:58<01:37,  1.19it/s]Loading train:  78%|███████▊  | 417/532 [08:59<01:31,  1.25it/s]Loading train:  79%|███████▊  | 418/532 [08:59<01:27,  1.30it/s]Loading train:  79%|███████▉  | 419/532 [09:01<01:37,  1.16it/s]Loading train:  79%|███████▉  | 420/532 [09:02<01:40,  1.11it/s]Loading train:  79%|███████▉  | 421/532 [09:02<01:41,  1.09it/s]Loading train:  79%|███████▉  | 422/532 [09:03<01:45,  1.05it/s]Loading train:  80%|███████▉  | 423/532 [09:04<01:43,  1.05it/s]Loading train:  80%|███████▉  | 424/532 [09:05<01:41,  1.06it/s]Loading train:  80%|███████▉  | 425/532 [09:06<01:40,  1.06it/s]Loading train:  80%|████████  | 426/532 [09:07<01:34,  1.12it/s]Loading train:  80%|████████  | 427/532 [09:08<01:33,  1.13it/s]Loading train:  80%|████████  | 428/532 [09:09<01:31,  1.13it/s]Loading train:  81%|████████  | 429/532 [09:10<01:30,  1.14it/s]Loading train:  81%|████████  | 430/532 [09:11<01:30,  1.12it/s]Loading train:  81%|████████  | 431/532 [09:12<01:38,  1.03it/s]Loading train:  81%|████████  | 432/532 [09:13<01:38,  1.01it/s]Loading train:  81%|████████▏ | 433/532 [09:14<01:35,  1.04it/s]Loading train:  82%|████████▏ | 434/532 [09:15<01:33,  1.05it/s]Loading train:  82%|████████▏ | 435/532 [09:16<01:34,  1.02it/s]Loading train:  82%|████████▏ | 436/532 [09:17<01:33,  1.02it/s]Loading train:  82%|████████▏ | 437/532 [09:17<01:26,  1.10it/s]Loading train:  82%|████████▏ | 438/532 [09:18<01:20,  1.17it/s]Loading train:  83%|████████▎ | 439/532 [09:19<01:13,  1.26it/s]Loading train:  83%|████████▎ | 440/532 [09:19<01:10,  1.30it/s]Loading train:  83%|████████▎ | 441/532 [09:20<01:10,  1.30it/s]Loading train:  83%|████████▎ | 442/532 [09:21<01:09,  1.30it/s]Loading train:  83%|████████▎ | 443/532 [09:22<01:10,  1.27it/s]Loading train:  83%|████████▎ | 444/532 [09:23<01:08,  1.28it/s]Loading train:  84%|████████▎ | 445/532 [09:23<01:09,  1.26it/s]Loading train:  84%|████████▍ | 446/532 [09:24<01:08,  1.26it/s]Loading train:  84%|████████▍ | 447/532 [09:25<01:08,  1.23it/s]Loading train:  84%|████████▍ | 448/532 [09:26<01:05,  1.27it/s]Loading train:  84%|████████▍ | 449/532 [09:27<01:05,  1.26it/s]Loading train:  85%|████████▍ | 450/532 [09:27<01:05,  1.25it/s]Loading train:  85%|████████▍ | 451/532 [09:28<01:05,  1.23it/s]Loading train:  85%|████████▍ | 452/532 [09:29<01:05,  1.23it/s]Loading train:  85%|████████▌ | 453/532 [09:30<01:05,  1.21it/s]Loading train:  85%|████████▌ | 454/532 [09:31<01:03,  1.23it/s]Loading train:  86%|████████▌ | 455/532 [09:32<01:05,  1.17it/s]Loading train:  86%|████████▌ | 456/532 [09:33<01:04,  1.18it/s]Loading train:  86%|████████▌ | 457/532 [09:33<01:02,  1.20it/s]Loading train:  86%|████████▌ | 458/532 [09:34<01:02,  1.19it/s]Loading train:  86%|████████▋ | 459/532 [09:35<01:01,  1.19it/s]Loading train:  86%|████████▋ | 460/532 [09:36<01:02,  1.15it/s]Loading train:  87%|████████▋ | 461/532 [09:37<01:06,  1.06it/s]Loading train:  87%|████████▋ | 462/532 [09:38<01:06,  1.05it/s]Loading train:  87%|████████▋ | 463/532 [09:39<01:05,  1.05it/s]Loading train:  87%|████████▋ | 464/532 [09:40<01:06,  1.03it/s]Loading train:  87%|████████▋ | 465/532 [09:41<01:05,  1.03it/s]Loading train:  88%|████████▊ | 466/532 [09:42<01:05,  1.01it/s]Loading train:  88%|████████▊ | 467/532 [09:43<01:00,  1.07it/s]Loading train:  88%|████████▊ | 468/532 [09:44<00:56,  1.14it/s]Loading train:  88%|████████▊ | 469/532 [09:44<00:52,  1.21it/s]Loading train:  88%|████████▊ | 470/532 [09:45<00:48,  1.27it/s]Loading train:  89%|████████▊ | 471/532 [09:46<00:47,  1.28it/s]Loading train:  89%|████████▊ | 472/532 [09:46<00:45,  1.32it/s]Loading train:  89%|████████▉ | 473/532 [09:47<00:47,  1.25it/s]Loading train:  89%|████████▉ | 474/532 [09:48<00:47,  1.22it/s]Loading train:  89%|████████▉ | 475/532 [09:49<00:46,  1.22it/s]Loading train:  89%|████████▉ | 476/532 [09:50<00:46,  1.20it/s]Loading train:  90%|████████▉ | 477/532 [09:51<00:46,  1.19it/s]Loading train:  90%|████████▉ | 478/532 [09:52<00:46,  1.17it/s]Loading train:  90%|█████████ | 479/532 [09:52<00:45,  1.17it/s]Loading train:  90%|█████████ | 480/532 [09:53<00:42,  1.24it/s]Loading train:  90%|█████████ | 481/532 [09:54<00:41,  1.24it/s]Loading train:  91%|█████████ | 482/532 [09:55<00:40,  1.23it/s]Loading train:  91%|█████████ | 483/532 [09:56<00:40,  1.22it/s]Loading train:  91%|█████████ | 484/532 [09:56<00:38,  1.24it/s]Loading train:  91%|█████████ | 485/532 [09:58<00:42,  1.11it/s]Loading train:  91%|█████████▏| 486/532 [09:59<00:43,  1.07it/s]Loading train:  92%|█████████▏| 487/532 [10:00<00:42,  1.05it/s]Loading train:  92%|█████████▏| 488/532 [10:01<00:42,  1.04it/s]Loading train:  92%|█████████▏| 489/532 [10:02<00:44,  1.04s/it]Loading train:  92%|█████████▏| 490/532 [10:03<00:45,  1.08s/it]Loading train:  92%|█████████▏| 491/532 [10:04<00:42,  1.03s/it]Loading train:  92%|█████████▏| 492/532 [10:05<00:38,  1.03it/s]Loading train:  93%|█████████▎| 493/532 [10:06<00:37,  1.05it/s]Loading train:  93%|█████████▎| 494/532 [10:06<00:35,  1.08it/s]Loading train:  93%|█████████▎| 495/532 [10:07<00:33,  1.10it/s]Loading train:  93%|█████████▎| 496/532 [10:08<00:32,  1.12it/s]Loading train:  93%|█████████▎| 497/532 [10:09<00:31,  1.12it/s]Loading train:  94%|█████████▎| 498/532 [10:10<00:30,  1.13it/s]Loading train:  94%|█████████▍| 499/532 [10:11<00:28,  1.14it/s]Loading train:  94%|█████████▍| 500/532 [10:12<00:28,  1.14it/s]Loading train:  94%|█████████▍| 501/532 [10:13<00:27,  1.14it/s]Loading train:  94%|█████████▍| 502/532 [10:13<00:26,  1.12it/s]Loading train:  95%|█████████▍| 503/532 [10:14<00:25,  1.12it/s]Loading train:  95%|█████████▍| 504/532 [10:15<00:24,  1.16it/s]Loading train:  95%|█████████▍| 505/532 [10:16<00:22,  1.18it/s]Loading train:  95%|█████████▌| 506/532 [10:17<00:21,  1.20it/s]Loading train:  95%|█████████▌| 507/532 [10:18<00:20,  1.20it/s]Loading train:  95%|█████████▌| 508/532 [10:18<00:19,  1.22it/s]Loading train:  96%|█████████▌| 509/532 [10:19<00:19,  1.17it/s]Loading train:  96%|█████████▌| 510/532 [10:20<00:20,  1.10it/s]Loading train:  96%|█████████▌| 511/532 [10:21<00:19,  1.05it/s]Loading train:  96%|█████████▌| 512/532 [10:22<00:18,  1.06it/s]Loading train:  96%|█████████▋| 513/532 [10:23<00:17,  1.06it/s]Loading train:  97%|█████████▋| 514/532 [10:24<00:16,  1.07it/s]Loading train:  97%|█████████▋| 515/532 [10:25<00:15,  1.12it/s]Loading train:  97%|█████████▋| 516/532 [10:26<00:13,  1.15it/s]Loading train:  97%|█████████▋| 517/532 [10:27<00:12,  1.18it/s]Loading train:  97%|█████████▋| 518/532 [10:27<00:11,  1.17it/s]Loading train:  98%|█████████▊| 519/532 [10:28<00:11,  1.17it/s]Loading train:  98%|█████████▊| 520/532 [10:29<00:10,  1.18it/s]Loading train:  98%|█████████▊| 521/532 [10:30<00:09,  1.13it/s]Loading train:  98%|█████████▊| 522/532 [10:31<00:09,  1.10it/s]Loading train:  98%|█████████▊| 523/532 [10:32<00:08,  1.09it/s]Loading train:  98%|█████████▊| 524/532 [10:33<00:07,  1.06it/s]Loading train:  99%|█████████▊| 525/532 [10:34<00:06,  1.07it/s]Loading train:  99%|█████████▉| 526/532 [10:35<00:05,  1.06it/s]Loading train:  99%|█████████▉| 527/532 [10:36<00:04,  1.07it/s]Loading train:  99%|█████████▉| 528/532 [10:37<00:03,  1.12it/s]Loading train:  99%|█████████▉| 529/532 [10:37<00:02,  1.16it/s]Loading train: 100%|█████████▉| 530/532 [10:38<00:01,  1.17it/s]Loading train: 100%|█████████▉| 531/532 [10:39<00:00,  1.18it/s]Loading train: 100%|██████████| 532/532 [10:40<00:00,  1.18it/s]
concatenating: train:   0%|          | 0/532 [00:00<?, ?it/s]concatenating: train:   4%|▍         | 21/532 [00:00<00:02, 206.26it/s]concatenating: train:   8%|▊         | 43/532 [00:00<00:02, 208.71it/s]concatenating: train:  13%|█▎        | 70/532 [00:00<00:02, 222.30it/s]concatenating: train:  19%|█▊        | 99/532 [00:00<00:01, 237.14it/s]concatenating: train:  24%|██▍       | 127/532 [00:00<00:01, 247.49it/s]concatenating: train:  30%|██▉       | 158/532 [00:00<00:01, 261.17it/s]concatenating: train:  36%|███▌      | 189/532 [00:00<00:01, 272.48it/s]concatenating: train:  41%|████      | 219/532 [00:00<00:01, 278.43it/s]concatenating: train:  46%|████▋     | 247/532 [00:00<00:01, 274.08it/s]concatenating: train:  52%|█████▏    | 274/532 [00:01<00:00, 261.62it/s]concatenating: train:  56%|█████▋    | 300/532 [00:01<00:00, 260.13it/s]concatenating: train:  61%|██████▏   | 326/532 [00:01<00:00, 255.18it/s]concatenating: train:  66%|██████▌   | 352/532 [00:01<00:00, 241.50it/s]concatenating: train:  71%|███████   | 377/532 [00:01<00:00, 237.22it/s]concatenating: train:  75%|███████▌  | 401/532 [00:01<00:00, 229.13it/s]concatenating: train:  80%|████████  | 426/532 [00:01<00:00, 234.53it/s]concatenating: train:  85%|████████▌ | 453/532 [00:01<00:00, 243.76it/s]concatenating: train:  91%|█████████ | 484/532 [00:01<00:00, 260.38it/s]concatenating: train:  97%|█████████▋| 516/532 [00:01<00:00, 274.22it/s]concatenating: train: 100%|██████████| 532/532 [00:02<00:00, 260.59it/s]
Loading test:   0%|          | 0/15 [00:00<?, ?it/s]Loading test:   7%|▋         | 1/15 [00:00<00:10,  1.29it/s]Loading test:  13%|█▎        | 2/15 [00:01<00:10,  1.25it/s]Loading test:  20%|██        | 3/15 [00:02<00:10,  1.19it/s]Loading test:  27%|██▋       | 4/15 [00:03<00:09,  1.16it/s]Loading test:  33%|███▎      | 5/15 [00:04<00:09,  1.08it/s]Loading test:  40%|████      | 6/15 [00:05<00:09,  1.01s/it]Loading test:  47%|████▋     | 7/15 [00:06<00:07,  1.07it/s]Loading test:  53%|█████▎    | 8/15 [00:07<00:07,  1.02s/it]Loading test:  60%|██████    | 9/15 [00:08<00:06,  1.00s/it]Loading test:  67%|██████▋   | 10/15 [00:09<00:04,  1.07it/s]Loading test:  73%|███████▎  | 11/15 [00:10<00:03,  1.10it/s]Loading test:  80%|████████  | 12/15 [00:11<00:02,  1.08it/s]Loading test:  87%|████████▋ | 13/15 [00:12<00:01,  1.02it/s]Loading test:  93%|█████████▎| 14/15 [00:13<00:00,  1.07it/s]Loading test: 100%|██████████| 15/15 [00:14<00:00,  1.07it/s]
concatenating: validation:   0%|          | 0/15 [00:00<?, ?it/s]concatenating: validation:  73%|███████▎  | 11/15 [00:00<00:00, 109.13it/s]concatenating: validation: 100%|██████████| 15/15 [00:00<00:00, 120.11it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 84, 56, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 84, 56, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 84, 56, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 84, 56, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 84, 56, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 84, 56, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 84, 56, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 84, 56, 21)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 42, 28, 21)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 42, 28, 21)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 42, 28, 40)   7600        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 42, 28, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 42, 28, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 42, 28, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 42, 28, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 42, 28, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 42, 28, 61)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 21, 14, 61)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 21, 14, 61)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 21, 14, 80)   44000       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 21, 14, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 21, 14, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 21, 14, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 21, 14, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 21, 14, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 21, 14, 141)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 21, 14, 141)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 42, 28, 40)   22600       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 42, 28, 101)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 42, 28, 40)   36400       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 42, 28, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 42, 28, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 42, 28, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 42, 28, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 42, 28, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 42, 28, 141)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-07 07:08:51.486750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 07:08:51.486846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 07:08:51.486861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 07:08:51.486869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 07:08:51.487286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 42, 28, 141)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 84, 56, 20)   11300       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 56, 41)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 84, 56, 20)   7400        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 84, 56, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 84, 56, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 84, 56, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 84, 56, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 56, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 84, 56, 61)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 84, 56, 61)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 84, 56, 13)   806         dropout_5[0][0]                  
==================================================================================================
Total params: 225,706
Trainable params: 224,906
Non-trainable params: 800
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.53807809e-02 2.88974534e-02 1.16728790e-01 1.00198377e-02
 3.03363016e-02 5.79915656e-03 6.86746312e-02 1.28228722e-01
 7.55625878e-02 1.22514673e-02 2.73642650e-01 1.84278063e-01
 1.99559502e-04]
Train on 19871 samples, validate on 569 samples
Epoch 1/300
 - 27s - loss: 80.3424 - acc: 0.7378 - mDice: 0.0219 - val_loss: 7.6984 - val_acc: 0.9112 - val_mDice: 0.0119

Epoch 00001: val_mDice improved from -inf to 0.01193, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 21s - loss: 9.8145 - acc: 0.8926 - mDice: 0.0565 - val_loss: 5.1130 - val_acc: 0.9138 - val_mDice: 0.0922

Epoch 00002: val_mDice improved from 0.01193 to 0.09222, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 20s - loss: 6.5027 - acc: 0.9011 - mDice: 0.1160 - val_loss: 3.7561 - val_acc: 0.9252 - val_mDice: 0.1928

Epoch 00003: val_mDice improved from 0.09222 to 0.19283, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 20s - loss: 4.7836 - acc: 0.9125 - mDice: 0.2120 - val_loss: 2.8096 - val_acc: 0.9472 - val_mDice: 0.3593

Epoch 00004: val_mDice improved from 0.19283 to 0.35929, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 21s - loss: 3.7762 - acc: 0.9286 - mDice: 0.3183 - val_loss: 2.1269 - val_acc: 0.9579 - val_mDice: 0.4989

Epoch 00005: val_mDice improved from 0.35929 to 0.49895, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 20s - loss: 3.1968 - acc: 0.9366 - mDice: 0.3957 - val_loss: 1.8745 - val_acc: 0.9650 - val_mDice: 0.5588

Epoch 00006: val_mDice improved from 0.49895 to 0.55880, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 7/300
 - 20s - loss: 2.7872 - acc: 0.9417 - mDice: 0.4559 - val_loss: 1.7162 - val_acc: 0.9664 - val_mDice: 0.6088

Epoch 00007: val_mDice improved from 0.55880 to 0.60880, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 8/300
 - 20s - loss: 2.5058 - acc: 0.9457 - mDice: 0.5026 - val_loss: 1.5414 - val_acc: 0.9684 - val_mDice: 0.6451

Epoch 00008: val_mDice improved from 0.60880 to 0.64509, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 21s - loss: 2.3254 - acc: 0.9485 - mDice: 0.5339 - val_loss: 1.4326 - val_acc: 0.9711 - val_mDice: 0.6690

Epoch 00009: val_mDice improved from 0.64509 to 0.66903, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 10/300
 - 20s - loss: 2.1930 - acc: 0.9507 - mDice: 0.5579 - val_loss: 1.4335 - val_acc: 0.9710 - val_mDice: 0.6772

Epoch 00010: val_mDice improved from 0.66903 to 0.67721, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 11/300
 - 20s - loss: 2.0985 - acc: 0.9522 - mDice: 0.5753 - val_loss: 1.4348 - val_acc: 0.9711 - val_mDice: 0.6801

Epoch 00011: val_mDice improved from 0.67721 to 0.68014, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 12/300
 - 20s - loss: 1.9932 - acc: 0.9538 - mDice: 0.5939 - val_loss: 1.3702 - val_acc: 0.9721 - val_mDice: 0.6935

Epoch 00012: val_mDice improved from 0.68014 to 0.69353, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 13/300
 - 21s - loss: 1.9145 - acc: 0.9550 - mDice: 0.6078 - val_loss: 1.3058 - val_acc: 0.9735 - val_mDice: 0.7094

Epoch 00013: val_mDice improved from 0.69353 to 0.70940, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 14/300
 - 20s - loss: 1.8665 - acc: 0.9557 - mDice: 0.6165 - val_loss: 1.3068 - val_acc: 0.9727 - val_mDice: 0.7076

Epoch 00014: val_mDice did not improve from 0.70940
Epoch 15/300
 - 20s - loss: 1.8008 - acc: 0.9567 - mDice: 0.6282 - val_loss: 1.2727 - val_acc: 0.9730 - val_mDice: 0.7177

Epoch 00015: val_mDice improved from 0.70940 to 0.71769, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 16/300
 - 20s - loss: 1.7528 - acc: 0.9574 - mDice: 0.6370 - val_loss: 1.2814 - val_acc: 0.9734 - val_mDice: 0.7181

Epoch 00016: val_mDice improved from 0.71769 to 0.71810, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 17/300
 - 21s - loss: 1.7113 - acc: 0.9581 - mDice: 0.6439 - val_loss: 1.2690 - val_acc: 0.9746 - val_mDice: 0.7184

Epoch 00017: val_mDice improved from 0.71810 to 0.71844, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 18/300
 - 20s - loss: 1.6730 - acc: 0.9587 - mDice: 0.6514 - val_loss: 1.2709 - val_acc: 0.9749 - val_mDice: 0.7195

Epoch 00018: val_mDice improved from 0.71844 to 0.71950, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 19/300
 - 20s - loss: 1.6356 - acc: 0.9592 - mDice: 0.6584 - val_loss: 1.2219 - val_acc: 0.9750 - val_mDice: 0.7242

Epoch 00019: val_mDice improved from 0.71950 to 0.72423, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 20/300
 - 20s - loss: 1.6000 - acc: 0.9599 - mDice: 0.6647 - val_loss: 1.2097 - val_acc: 0.9748 - val_mDice: 0.7293

Epoch 00020: val_mDice improved from 0.72423 to 0.72926, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 21/300
 - 20s - loss: 1.5715 - acc: 0.9604 - mDice: 0.6701 - val_loss: 1.2064 - val_acc: 0.9755 - val_mDice: 0.7347

Epoch 00021: val_mDice improved from 0.72926 to 0.73473, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 22/300
 - 20s - loss: 1.5343 - acc: 0.9610 - mDice: 0.6771 - val_loss: 1.1753 - val_acc: 0.9761 - val_mDice: 0.7352

Epoch 00022: val_mDice improved from 0.73473 to 0.73520, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 23/300
 - 21s - loss: 1.5090 - acc: 0.9614 - mDice: 0.6814 - val_loss: 1.1952 - val_acc: 0.9757 - val_mDice: 0.7366

Epoch 00023: val_mDice improved from 0.73520 to 0.73659, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 24/300
 - 20s - loss: 1.4832 - acc: 0.9618 - mDice: 0.6868 - val_loss: 1.1385 - val_acc: 0.9761 - val_mDice: 0.7440

Epoch 00024: val_mDice improved from 0.73659 to 0.74399, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 25/300
 - 20s - loss: 1.4595 - acc: 0.9622 - mDice: 0.6914 - val_loss: 1.1509 - val_acc: 0.9761 - val_mDice: 0.7444

Epoch 00025: val_mDice improved from 0.74399 to 0.74440, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 26/300
 - 21s - loss: 1.4433 - acc: 0.9625 - mDice: 0.6941 - val_loss: 1.1741 - val_acc: 0.9761 - val_mDice: 0.7446

Epoch 00026: val_mDice improved from 0.74440 to 0.74456, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 27/300
 - 20s - loss: 1.4199 - acc: 0.9628 - mDice: 0.6987 - val_loss: 1.1525 - val_acc: 0.9761 - val_mDice: 0.7439

Epoch 00027: val_mDice did not improve from 0.74456
Epoch 28/300
 - 20s - loss: 1.4044 - acc: 0.9631 - mDice: 0.7014 - val_loss: 1.1464 - val_acc: 0.9764 - val_mDice: 0.7476

Epoch 00028: val_mDice improved from 0.74456 to 0.74761, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 29/300
 - 20s - loss: 1.3919 - acc: 0.9634 - mDice: 0.7040 - val_loss: 1.1620 - val_acc: 0.9765 - val_mDice: 0.7436

Epoch 00029: val_mDice did not improve from 0.74761
Epoch 30/300
 - 21s - loss: 1.3727 - acc: 0.9636 - mDice: 0.7080 - val_loss: 1.1237 - val_acc: 0.9775 - val_mDice: 0.7488

Epoch 00030: val_mDice improved from 0.74761 to 0.74881, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 31/300
 - 20s - loss: 1.3599 - acc: 0.9638 - mDice: 0.7101 - val_loss: 1.1311 - val_acc: 0.9764 - val_mDice: 0.7504

Epoch 00031: val_mDice improved from 0.74881 to 0.75044, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 32/300
 - 20s - loss: 1.3393 - acc: 0.9641 - mDice: 0.7140 - val_loss: 1.1123 - val_acc: 0.9769 - val_mDice: 0.7538

Epoch 00032: val_mDice improved from 0.75044 to 0.75379, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 33/300
 - 20s - loss: 1.3275 - acc: 0.9643 - mDice: 0.7164 - val_loss: 1.1481 - val_acc: 0.9773 - val_mDice: 0.7499

Epoch 00033: val_mDice did not improve from 0.75379
Epoch 34/300
 - 21s - loss: 1.3209 - acc: 0.9643 - mDice: 0.7176 - val_loss: 1.0898 - val_acc: 0.9770 - val_mDice: 0.7585

Epoch 00034: val_mDice improved from 0.75379 to 0.75847, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 35/300
 - 20s - loss: 1.3059 - acc: 0.9646 - mDice: 0.7204 - val_loss: 1.1280 - val_acc: 0.9769 - val_mDice: 0.7538

Epoch 00035: val_mDice did not improve from 0.75847
Epoch 36/300
 - 20s - loss: 1.2882 - acc: 0.9649 - mDice: 0.7240 - val_loss: 1.0944 - val_acc: 0.9771 - val_mDice: 0.7557

Epoch 00036: val_mDice did not improve from 0.75847
Epoch 37/300
 - 20s - loss: 1.2854 - acc: 0.9649 - mDice: 0.7244 - val_loss: 1.0966 - val_acc: 0.9775 - val_mDice: 0.7594

Epoch 00037: val_mDice improved from 0.75847 to 0.75939, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 38/300
 - 20s - loss: 1.2702 - acc: 0.9651 - mDice: 0.7274 - val_loss: 1.1087 - val_acc: 0.9773 - val_mDice: 0.7569

Epoch 00038: val_mDice did not improve from 0.75939
Epoch 39/300
 - 21s - loss: 1.2615 - acc: 0.9652 - mDice: 0.7291 - val_loss: 1.0885 - val_acc: 0.9783 - val_mDice: 0.7568

Epoch 00039: val_mDice did not improve from 0.75939
Epoch 40/300
 - 20s - loss: 1.2538 - acc: 0.9653 - mDice: 0.7305 - val_loss: 1.0915 - val_acc: 0.9774 - val_mDice: 0.7586

Epoch 00040: val_mDice did not improve from 0.75939
Epoch 41/300
 - 20s - loss: 1.2424 - acc: 0.9655 - mDice: 0.7327 - val_loss: 1.0922 - val_acc: 0.9783 - val_mDice: 0.7580

Epoch 00041: val_mDice did not improve from 0.75939
Epoch 42/300
 - 20s - loss: 1.2355 - acc: 0.9656 - mDice: 0.7340 - val_loss: 1.0989 - val_acc: 0.9775 - val_mDice: 0.7585

Epoch 00042: val_mDice did not improve from 0.75939
Epoch 43/300
 - 20s - loss: 1.2291 - acc: 0.9657 - mDice: 0.7353 - val_loss: 1.1024 - val_acc: 0.9778 - val_mDice: 0.7577

Epoch 00043: val_mDice did not improve from 0.75939
Epoch 44/300
 - 20s - loss: 1.2214 - acc: 0.9658 - mDice: 0.7369 - val_loss: 1.0744 - val_acc: 0.9779 - val_mDice: 0.7631

Epoch 00044: val_mDice improved from 0.75939 to 0.76314, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 45/300
 - 21s - loss: 1.2102 - acc: 0.9659 - mDice: 0.7390 - val_loss: 1.0801 - val_acc: 0.9777 - val_mDice: 0.7627

Epoch 00045: val_mDice did not improve from 0.76314
Epoch 46/300
 - 20s - loss: 1.2050 - acc: 0.9660 - mDice: 0.7402 - val_loss: 1.0819 - val_acc: 0.9783 - val_mDice: 0.7594

Epoch 00046: val_mDice did not improve from 0.76314
Epoch 47/300
 - 20s - loss: 1.1983 - acc: 0.9661 - mDice: 0.7412 - val_loss: 1.0917 - val_acc: 0.9780 - val_mDice: 0.7635

Epoch 00047: val_mDice improved from 0.76314 to 0.76353, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 48/300
 - 20s - loss: 1.1939 - acc: 0.9662 - mDice: 0.7421 - val_loss: 1.1024 - val_acc: 0.9777 - val_mDice: 0.7605

Epoch 00048: val_mDice did not improve from 0.76353
Epoch 49/300
 - 20s - loss: 1.1872 - acc: 0.9663 - mDice: 0.7434 - val_loss: 1.0814 - val_acc: 0.9785 - val_mDice: 0.7612

Epoch 00049: val_mDice did not improve from 0.76353
Epoch 50/300
 - 21s - loss: 1.1786 - acc: 0.9664 - mDice: 0.7453 - val_loss: 1.0770 - val_acc: 0.9784 - val_mDice: 0.7590

Epoch 00050: val_mDice did not improve from 0.76353
Epoch 51/300
 - 20s - loss: 1.1766 - acc: 0.9664 - mDice: 0.7457 - val_loss: 1.0497 - val_acc: 0.9787 - val_mDice: 0.7631

Epoch 00051: val_mDice did not improve from 0.76353
Epoch 52/300
 - 20s - loss: 1.1679 - acc: 0.9665 - mDice: 0.7473 - val_loss: 1.0578 - val_acc: 0.9788 - val_mDice: 0.7627

Epoch 00052: val_mDice did not improve from 0.76353
Epoch 53/300
 - 20s - loss: 1.1604 - acc: 0.9666 - mDice: 0.7485 - val_loss: 1.0613 - val_acc: 0.9788 - val_mDice: 0.7663

Epoch 00053: val_mDice improved from 0.76353 to 0.76626, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 54/300
 - 21s - loss: 1.1508 - acc: 0.9667 - mDice: 0.7505 - val_loss: 1.0722 - val_acc: 0.9785 - val_mDice: 0.7661

Epoch 00054: val_mDice did not improve from 0.76626
Epoch 55/300
 - 21s - loss: 1.1494 - acc: 0.9668 - mDice: 0.7509 - val_loss: 1.0655 - val_acc: 0.9784 - val_mDice: 0.7654

Epoch 00055: val_mDice did not improve from 0.76626
Epoch 56/300
 - 22s - loss: 1.1432 - acc: 0.9669 - mDice: 0.7523 - val_loss: 1.0471 - val_acc: 0.9786 - val_mDice: 0.7677

Epoch 00056: val_mDice improved from 0.76626 to 0.76770, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 57/300
 - 21s - loss: 1.1385 - acc: 0.9669 - mDice: 0.7534 - val_loss: 1.0810 - val_acc: 0.9783 - val_mDice: 0.7642

Epoch 00057: val_mDice did not improve from 0.76770
Epoch 58/300
 - 21s - loss: 1.1395 - acc: 0.9669 - mDice: 0.7527 - val_loss: 1.0470 - val_acc: 0.9789 - val_mDice: 0.7648

Epoch 00058: val_mDice did not improve from 0.76770
Epoch 59/300
 - 22s - loss: 1.1288 - acc: 0.9671 - mDice: 0.7550 - val_loss: 1.0576 - val_acc: 0.9791 - val_mDice: 0.7656

Epoch 00059: val_mDice did not improve from 0.76770
Epoch 60/300
 - 21s - loss: 1.1247 - acc: 0.9671 - mDice: 0.7559 - val_loss: 1.0431 - val_acc: 0.9782 - val_mDice: 0.7657

Epoch 00060: val_mDice did not improve from 0.76770
Epoch 61/300
 - 21s - loss: 1.1201 - acc: 0.9672 - mDice: 0.7567 - val_loss: 1.0458 - val_acc: 0.9789 - val_mDice: 0.7682

Epoch 00061: val_mDice improved from 0.76770 to 0.76817, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 62/300
 - 21s - loss: 1.1158 - acc: 0.9672 - mDice: 0.7575 - val_loss: 1.0660 - val_acc: 0.9787 - val_mDice: 0.7672

Epoch 00062: val_mDice did not improve from 0.76817
Epoch 63/300
 - 21s - loss: 1.1161 - acc: 0.9672 - mDice: 0.7577 - val_loss: 1.0509 - val_acc: 0.9788 - val_mDice: 0.7661

Epoch 00063: val_mDice did not improve from 0.76817
Epoch 64/300
 - 22s - loss: 1.1117 - acc: 0.9673 - mDice: 0.7586 - val_loss: 1.0543 - val_acc: 0.9783 - val_mDice: 0.7667

Epoch 00064: val_mDice did not improve from 0.76817
Epoch 65/300
 - 21s - loss: 1.1035 - acc: 0.9674 - mDice: 0.7600 - val_loss: 1.0549 - val_acc: 0.9784 - val_mDice: 0.7717

Epoch 00065: val_mDice improved from 0.76817 to 0.77170, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 66/300
 - 21s - loss: 1.1019 - acc: 0.9674 - mDice: 0.7604 - val_loss: 1.0419 - val_acc: 0.9791 - val_mDice: 0.7680

Epoch 00066: val_mDice did not improve from 0.77170
Epoch 67/300
 - 22s - loss: 1.0991 - acc: 0.9674 - mDice: 0.7611 - val_loss: 1.0647 - val_acc: 0.9783 - val_mDice: 0.7679

Epoch 00067: val_mDice did not improve from 0.77170
Epoch 68/300
 - 21s - loss: 1.0936 - acc: 0.9675 - mDice: 0.7620 - val_loss: 1.0530 - val_acc: 0.9792 - val_mDice: 0.7722

Epoch 00068: val_mDice improved from 0.77170 to 0.77221, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 69/300
 - 21s - loss: 1.0956 - acc: 0.9675 - mDice: 0.7617 - val_loss: 1.0461 - val_acc: 0.9795 - val_mDice: 0.7670

Epoch 00069: val_mDice did not improve from 0.77221
Epoch 70/300
 - 22s - loss: 1.0917 - acc: 0.9675 - mDice: 0.7625 - val_loss: 1.0442 - val_acc: 0.9786 - val_mDice: 0.7708

Epoch 00070: val_mDice did not improve from 0.77221
Epoch 71/300
 - 21s - loss: 1.0856 - acc: 0.9676 - mDice: 0.7639 - val_loss: 1.0425 - val_acc: 0.9789 - val_mDice: 0.7713

Epoch 00071: val_mDice did not improve from 0.77221
Epoch 72/300
 - 21s - loss: 1.0856 - acc: 0.9676 - mDice: 0.7638 - val_loss: 1.0398 - val_acc: 0.9789 - val_mDice: 0.7751

Epoch 00072: val_mDice improved from 0.77221 to 0.77507, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 73/300
 - 21s - loss: 1.0778 - acc: 0.9676 - mDice: 0.7653 - val_loss: 1.0402 - val_acc: 0.9789 - val_mDice: 0.7715

Epoch 00073: val_mDice did not improve from 0.77507
Epoch 74/300
 - 21s - loss: 1.0792 - acc: 0.9677 - mDice: 0.7652 - val_loss: 1.0300 - val_acc: 0.9789 - val_mDice: 0.7756

Epoch 00074: val_mDice improved from 0.77507 to 0.77562, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 75/300
 - 21s - loss: 1.0731 - acc: 0.9678 - mDice: 0.7664 - val_loss: 1.0408 - val_acc: 0.9790 - val_mDice: 0.7721

Epoch 00075: val_mDice did not improve from 0.77562
Epoch 76/300
 - 21s - loss: 1.0714 - acc: 0.9678 - mDice: 0.7665 - val_loss: 1.0419 - val_acc: 0.9791 - val_mDice: 0.7694

Epoch 00076: val_mDice did not improve from 0.77562
Epoch 77/300
 - 22s - loss: 1.0672 - acc: 0.9678 - mDice: 0.7674 - val_loss: 1.0443 - val_acc: 0.9784 - val_mDice: 0.7739

Epoch 00077: val_mDice did not improve from 0.77562
Epoch 78/300
 - 21s - loss: 1.0687 - acc: 0.9678 - mDice: 0.7671 - val_loss: 1.0528 - val_acc: 0.9790 - val_mDice: 0.7746

Epoch 00078: val_mDice did not improve from 0.77562
Epoch 79/300
 - 21s - loss: 1.0628 - acc: 0.9679 - mDice: 0.7683 - val_loss: 1.0417 - val_acc: 0.9790 - val_mDice: 0.7740

Epoch 00079: val_mDice did not improve from 0.77562
Epoch 80/300
 - 21s - loss: 1.0591 - acc: 0.9679 - mDice: 0.7692 - val_loss: 1.0458 - val_acc: 0.9791 - val_mDice: 0.7713

Epoch 00080: val_mDice did not improve from 0.77562
Epoch 81/300
 - 21s - loss: 1.0574 - acc: 0.9679 - mDice: 0.7696 - val_loss: 1.0461 - val_acc: 0.9788 - val_mDice: 0.7735

Epoch 00081: val_mDice did not improve from 0.77562
Epoch 82/300
 - 22s - loss: 1.0564 - acc: 0.9680 - mDice: 0.7696 - val_loss: 1.0565 - val_acc: 0.9784 - val_mDice: 0.7735

Epoch 00082: val_mDice did not improve from 0.77562
Epoch 83/300
 - 21s - loss: 1.0541 - acc: 0.9680 - mDice: 0.7702 - val_loss: 1.0433 - val_acc: 0.9792 - val_mDice: 0.7749

Epoch 00083: val_mDice did not improve from 0.77562
Epoch 84/300
 - 22s - loss: 1.0491 - acc: 0.9680 - mDice: 0.7710 - val_loss: 1.0306 - val_acc: 0.9788 - val_mDice: 0.7762

Epoch 00084: val_mDice improved from 0.77562 to 0.77615, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 85/300
 - 22s - loss: 1.0480 - acc: 0.9681 - mDice: 0.7712 - val_loss: 1.0303 - val_acc: 0.9795 - val_mDice: 0.7783

Epoch 00085: val_mDice improved from 0.77615 to 0.77826, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 86/300
 - 21s - loss: 1.0470 - acc: 0.9680 - mDice: 0.7719 - val_loss: 1.0415 - val_acc: 0.9783 - val_mDice: 0.7738

Epoch 00086: val_mDice did not improve from 0.77826
Epoch 87/300
 - 21s - loss: 1.0421 - acc: 0.9681 - mDice: 0.7727 - val_loss: 1.0489 - val_acc: 0.9786 - val_mDice: 0.7725

Epoch 00087: val_mDice did not improve from 0.77826
Epoch 88/300
 - 23s - loss: 1.0450 - acc: 0.9681 - mDice: 0.7722 - val_loss: 1.0407 - val_acc: 0.9793 - val_mDice: 0.7737

Epoch 00088: val_mDice did not improve from 0.77826
Epoch 89/300
 - 22s - loss: 1.0425 - acc: 0.9681 - mDice: 0.7727 - val_loss: 1.0451 - val_acc: 0.9790 - val_mDice: 0.7750

Epoch 00089: val_mDice did not improve from 0.77826
Epoch 90/300
 - 21s - loss: 1.0405 - acc: 0.9681 - mDice: 0.7729 - val_loss: 1.0448 - val_acc: 0.9786 - val_mDice: 0.7729

Epoch 00090: val_mDice did not improve from 0.77826
Epoch 91/300
 - 22s - loss: 1.0358 - acc: 0.9682 - mDice: 0.7739 - val_loss: 1.0400 - val_acc: 0.9794 - val_mDice: 0.7742

Epoch 00091: val_mDice did not improve from 0.77826
Epoch 92/300
 - 22s - loss: 1.0345 - acc: 0.9682 - mDice: 0.7742 - val_loss: 1.0496 - val_acc: 0.9790 - val_mDice: 0.7733

Epoch 00092: val_mDice did not improve from 0.77826
Epoch 93/300
 - 21s - loss: 1.0307 - acc: 0.9683 - mDice: 0.7750 - val_loss: 1.0336 - val_acc: 0.9789 - val_mDice: 0.7764

Epoch 00093: val_mDice did not improve from 0.77826
Epoch 94/300
 - 23s - loss: 1.0335 - acc: 0.9683 - mDice: 0.7745 - val_loss: 1.0257 - val_acc: 0.9795 - val_mDice: 0.7796

Epoch 00094: val_mDice improved from 0.77826 to 0.77957, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 95/300
 - 22s - loss: 1.0284 - acc: 0.9683 - mDice: 0.7755 - val_loss: 1.0191 - val_acc: 0.9796 - val_mDice: 0.7725

Epoch 00095: val_mDice did not improve from 0.77957
Epoch 96/300
 - 21s - loss: 1.0274 - acc: 0.9683 - mDice: 0.7757 - val_loss: 1.0411 - val_acc: 0.9790 - val_mDice: 0.7757

Epoch 00096: val_mDice did not improve from 0.77957
Epoch 97/300
 - 22s - loss: 1.0226 - acc: 0.9683 - mDice: 0.7768 - val_loss: 1.0323 - val_acc: 0.9793 - val_mDice: 0.7769

Epoch 00097: val_mDice did not improve from 0.77957
Epoch 98/300
 - 22s - loss: 1.0204 - acc: 0.9684 - mDice: 0.7772 - val_loss: 1.0216 - val_acc: 0.9792 - val_mDice: 0.7794

Epoch 00098: val_mDice did not improve from 0.77957
Epoch 99/300
 - 22s - loss: 1.0169 - acc: 0.9684 - mDice: 0.7777 - val_loss: 1.0592 - val_acc: 0.9786 - val_mDice: 0.7775

Epoch 00099: val_mDice did not improve from 0.77957
Epoch 100/300
 - 22s - loss: 1.0194 - acc: 0.9684 - mDice: 0.7775 - val_loss: 1.0180 - val_acc: 0.9798 - val_mDice: 0.7794

Epoch 00100: val_mDice did not improve from 0.77957
Epoch 101/300
 - 22s - loss: 1.0159 - acc: 0.9684 - mDice: 0.7782 - val_loss: 1.0205 - val_acc: 0.9794 - val_mDice: 0.7793

Epoch 00101: val_mDice did not improve from 0.77957
Epoch 102/300
 - 22s - loss: 1.0163 - acc: 0.9684 - mDice: 0.7783 - val_loss: 1.0215 - val_acc: 0.9795 - val_mDice: 0.7755

Epoch 00102: val_mDice did not improve from 0.77957
Epoch 103/300
 - 22s - loss: 1.0121 - acc: 0.9685 - mDice: 0.7792 - val_loss: 1.0065 - val_acc: 0.9797 - val_mDice: 0.7802

Epoch 00103: val_mDice improved from 0.77957 to 0.78019, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 104/300
 - 22s - loss: 1.0099 - acc: 0.9685 - mDice: 0.7795 - val_loss: 1.0276 - val_acc: 0.9793 - val_mDice: 0.7786

Epoch 00104: val_mDice did not improve from 0.78019
Epoch 105/300
 - 21s - loss: 1.0095 - acc: 0.9685 - mDice: 0.7798 - val_loss: 1.0165 - val_acc: 0.9791 - val_mDice: 0.7806

Epoch 00105: val_mDice improved from 0.78019 to 0.78058, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 106/300
 - 22s - loss: 1.0081 - acc: 0.9685 - mDice: 0.7799 - val_loss: 1.0140 - val_acc: 0.9803 - val_mDice: 0.7778

Epoch 00106: val_mDice did not improve from 0.78058
Epoch 107/300
 - 22s - loss: 1.0052 - acc: 0.9686 - mDice: 0.7805 - val_loss: 1.0183 - val_acc: 0.9794 - val_mDice: 0.7756

Epoch 00107: val_mDice did not improve from 0.78058
Epoch 108/300
 - 21s - loss: 1.0059 - acc: 0.9686 - mDice: 0.7803 - val_loss: 1.0173 - val_acc: 0.9794 - val_mDice: 0.7792

Epoch 00108: val_mDice did not improve from 0.78058
Epoch 109/300
 - 22s - loss: 1.0033 - acc: 0.9686 - mDice: 0.7809 - val_loss: 1.0220 - val_acc: 0.9797 - val_mDice: 0.7796

Epoch 00109: val_mDice did not improve from 0.78058
Epoch 110/300
 - 22s - loss: 0.9999 - acc: 0.9687 - mDice: 0.7820 - val_loss: 1.0098 - val_acc: 0.9796 - val_mDice: 0.7833

Epoch 00110: val_mDice improved from 0.78058 to 0.78328, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 111/300
 - 22s - loss: 0.9994 - acc: 0.9687 - mDice: 0.7821 - val_loss: 1.0364 - val_acc: 0.9785 - val_mDice: 0.7811

Epoch 00111: val_mDice did not improve from 0.78328
Epoch 112/300
 - 22s - loss: 0.9967 - acc: 0.9687 - mDice: 0.7828 - val_loss: 1.0168 - val_acc: 0.9792 - val_mDice: 0.7822

Epoch 00112: val_mDice did not improve from 0.78328
Epoch 113/300
 - 22s - loss: 0.9954 - acc: 0.9687 - mDice: 0.7829 - val_loss: 1.0252 - val_acc: 0.9796 - val_mDice: 0.7806

Epoch 00113: val_mDice did not improve from 0.78328
Epoch 114/300
 - 21s - loss: 0.9933 - acc: 0.9687 - mDice: 0.7832 - val_loss: 1.0166 - val_acc: 0.9797 - val_mDice: 0.7804

Epoch 00114: val_mDice did not improve from 0.78328
Epoch 115/300
 - 22s - loss: 0.9937 - acc: 0.9687 - mDice: 0.7834 - val_loss: 0.9938 - val_acc: 0.9800 - val_mDice: 0.7803

Epoch 00115: val_mDice did not improve from 0.78328
Epoch 116/300
 - 22s - loss: 0.9927 - acc: 0.9688 - mDice: 0.7836 - val_loss: 1.0066 - val_acc: 0.9802 - val_mDice: 0.7835

Epoch 00116: val_mDice improved from 0.78328 to 0.78352, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 117/300
 - 21s - loss: 0.9872 - acc: 0.9688 - mDice: 0.7847 - val_loss: 1.0234 - val_acc: 0.9789 - val_mDice: 0.7816

Epoch 00117: val_mDice did not improve from 0.78352
Epoch 118/300
 - 22s - loss: 0.9869 - acc: 0.9688 - mDice: 0.7847 - val_loss: 1.0184 - val_acc: 0.9801 - val_mDice: 0.7815

Epoch 00118: val_mDice did not improve from 0.78352
Epoch 119/300
 - 22s - loss: 0.9878 - acc: 0.9688 - mDice: 0.7847 - val_loss: 1.0265 - val_acc: 0.9800 - val_mDice: 0.7822

Epoch 00119: val_mDice did not improve from 0.78352
Epoch 120/300
 - 21s - loss: 0.9870 - acc: 0.9688 - mDice: 0.7850 - val_loss: 0.9969 - val_acc: 0.9796 - val_mDice: 0.7863

Epoch 00120: val_mDice improved from 0.78352 to 0.78626, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 121/300
 - 23s - loss: 0.9809 - acc: 0.9689 - mDice: 0.7859 - val_loss: 1.0167 - val_acc: 0.9796 - val_mDice: 0.7840

Epoch 00121: val_mDice did not improve from 0.78626
Epoch 122/300
 - 22s - loss: 0.9767 - acc: 0.9689 - mDice: 0.7873 - val_loss: 1.0044 - val_acc: 0.9794 - val_mDice: 0.7823

Epoch 00122: val_mDice did not improve from 0.78626
Epoch 123/300
 - 22s - loss: 0.9796 - acc: 0.9689 - mDice: 0.7867 - val_loss: 1.0141 - val_acc: 0.9797 - val_mDice: 0.7803

Epoch 00123: val_mDice did not improve from 0.78626
Epoch 124/300
 - 22s - loss: 0.9781 - acc: 0.9689 - mDice: 0.7871 - val_loss: 0.9925 - val_acc: 0.9801 - val_mDice: 0.7876

Epoch 00124: val_mDice improved from 0.78626 to 0.78762, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 125/300
 - 22s - loss: 0.9734 - acc: 0.9690 - mDice: 0.7879 - val_loss: 0.9961 - val_acc: 0.9794 - val_mDice: 0.7863

Epoch 00125: val_mDice did not improve from 0.78762
Epoch 126/300
 - 22s - loss: 0.9708 - acc: 0.9690 - mDice: 0.7884 - val_loss: 1.0016 - val_acc: 0.9797 - val_mDice: 0.7846

Epoch 00126: val_mDice did not improve from 0.78762
Epoch 127/300
 - 22s - loss: 0.9681 - acc: 0.9690 - mDice: 0.7895 - val_loss: 0.9883 - val_acc: 0.9798 - val_mDice: 0.7876

Epoch 00127: val_mDice did not improve from 0.78762
Epoch 128/300
 - 22s - loss: 0.9673 - acc: 0.9691 - mDice: 0.7895 - val_loss: 0.9968 - val_acc: 0.9797 - val_mDice: 0.7889

Epoch 00128: val_mDice improved from 0.78762 to 0.78892, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 129/300
 - 22s - loss: 0.9659 - acc: 0.9691 - mDice: 0.7898 - val_loss: 1.0129 - val_acc: 0.9800 - val_mDice: 0.7859

Epoch 00129: val_mDice did not improve from 0.78892
Epoch 130/300
 - 22s - loss: 0.9673 - acc: 0.9690 - mDice: 0.7896 - val_loss: 0.9932 - val_acc: 0.9798 - val_mDice: 0.7859

Epoch 00130: val_mDice did not improve from 0.78892
Epoch 131/300
 - 23s - loss: 0.9602 - acc: 0.9691 - mDice: 0.7913 - val_loss: 1.0110 - val_acc: 0.9795 - val_mDice: 0.7855

Epoch 00131: val_mDice did not improve from 0.78892
Epoch 132/300
 - 22s - loss: 0.9597 - acc: 0.9691 - mDice: 0.7912 - val_loss: 0.9902 - val_acc: 0.9800 - val_mDice: 0.7862

Epoch 00132: val_mDice did not improve from 0.78892
Epoch 133/300
 - 22s - loss: 0.9615 - acc: 0.9691 - mDice: 0.7909 - val_loss: 0.9955 - val_acc: 0.9799 - val_mDice: 0.7877

Epoch 00133: val_mDice did not improve from 0.78892
Epoch 134/300
 - 23s - loss: 0.9565 - acc: 0.9692 - mDice: 0.7921 - val_loss: 1.0025 - val_acc: 0.9799 - val_mDice: 0.7844

Epoch 00134: val_mDice did not improve from 0.78892
Epoch 135/300
 - 22s - loss: 0.9582 - acc: 0.9691 - mDice: 0.7917 - val_loss: 0.9927 - val_acc: 0.9800 - val_mDice: 0.7876

Epoch 00135: val_mDice did not improve from 0.78892
Epoch 136/300
 - 21s - loss: 0.9550 - acc: 0.9691 - mDice: 0.7924 - val_loss: 0.9972 - val_acc: 0.9798 - val_mDice: 0.7896

Epoch 00136: val_mDice improved from 0.78892 to 0.78965, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 137/300
 - 23s - loss: 0.9541 - acc: 0.9692 - mDice: 0.7927 - val_loss: 0.9946 - val_acc: 0.9798 - val_mDice: 0.7876

Epoch 00137: val_mDice did not improve from 0.78965
Epoch 138/300
 - 23s - loss: 0.9543 - acc: 0.9692 - mDice: 0.7926 - val_loss: 0.9900 - val_acc: 0.9798 - val_mDice: 0.7888

Epoch 00138: val_mDice did not improve from 0.78965
Epoch 139/300
 - 21s - loss: 0.9509 - acc: 0.9692 - mDice: 0.7933 - val_loss: 1.0085 - val_acc: 0.9801 - val_mDice: 0.7877

Epoch 00139: val_mDice did not improve from 0.78965
Epoch 140/300
 - 22s - loss: 0.9488 - acc: 0.9693 - mDice: 0.7937 - val_loss: 0.9949 - val_acc: 0.9796 - val_mDice: 0.7881

Epoch 00140: val_mDice did not improve from 0.78965
Epoch 141/300
 - 22s - loss: 0.9456 - acc: 0.9693 - mDice: 0.7943 - val_loss: 1.0017 - val_acc: 0.9802 - val_mDice: 0.7894

Epoch 00141: val_mDice did not improve from 0.78965
Epoch 142/300
 - 21s - loss: 0.9464 - acc: 0.9693 - mDice: 0.7945 - val_loss: 0.9829 - val_acc: 0.9799 - val_mDice: 0.7875

Epoch 00142: val_mDice did not improve from 0.78965
Epoch 143/300
 - 23s - loss: 0.9468 - acc: 0.9692 - mDice: 0.7942 - val_loss: 0.9922 - val_acc: 0.9802 - val_mDice: 0.7901

Epoch 00143: val_mDice improved from 0.78965 to 0.79008, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 144/300
 - 22s - loss: 0.9428 - acc: 0.9693 - mDice: 0.7950 - val_loss: 1.0024 - val_acc: 0.9791 - val_mDice: 0.7869

Epoch 00144: val_mDice did not improve from 0.79008
Epoch 145/300
 - 22s - loss: 0.9430 - acc: 0.9693 - mDice: 0.7953 - val_loss: 0.9987 - val_acc: 0.9797 - val_mDice: 0.7863

Epoch 00145: val_mDice did not improve from 0.79008
Epoch 146/300
 - 22s - loss: 0.9449 - acc: 0.9693 - mDice: 0.7944 - val_loss: 1.0014 - val_acc: 0.9795 - val_mDice: 0.7862

Epoch 00146: val_mDice did not improve from 0.79008
Epoch 147/300
 - 23s - loss: 0.9398 - acc: 0.9693 - mDice: 0.7956 - val_loss: 0.9921 - val_acc: 0.9797 - val_mDice: 0.7928

Epoch 00147: val_mDice improved from 0.79008 to 0.79282, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 148/300
 - 22s - loss: 0.9342 - acc: 0.9694 - mDice: 0.7970 - val_loss: 1.0059 - val_acc: 0.9802 - val_mDice: 0.7899

Epoch 00148: val_mDice did not improve from 0.79282
Epoch 149/300
 - 22s - loss: 0.9402 - acc: 0.9694 - mDice: 0.7956 - val_loss: 0.9910 - val_acc: 0.9800 - val_mDice: 0.7900

Epoch 00149: val_mDice did not improve from 0.79282
Epoch 150/300
 - 23s - loss: 0.9367 - acc: 0.9694 - mDice: 0.7965 - val_loss: 0.9945 - val_acc: 0.9801 - val_mDice: 0.7912

Epoch 00150: val_mDice did not improve from 0.79282
Epoch 151/300
 - 21s - loss: 0.9347 - acc: 0.9694 - mDice: 0.7969 - val_loss: 0.9961 - val_acc: 0.9799 - val_mDice: 0.7911

Epoch 00151: val_mDice did not improve from 0.79282
Epoch 152/300
 - 22s - loss: 0.9365 - acc: 0.9694 - mDice: 0.7965 - val_loss: 1.0015 - val_acc: 0.9800 - val_mDice: 0.7884

Epoch 00152: val_mDice did not improve from 0.79282
Epoch 153/300
 - 23s - loss: 0.9354 - acc: 0.9694 - mDice: 0.7968 - val_loss: 0.9986 - val_acc: 0.9801 - val_mDice: 0.7879

Epoch 00153: val_mDice did not improve from 0.79282
Epoch 154/300
 - 22s - loss: 0.9353 - acc: 0.9694 - mDice: 0.7969 - val_loss: 1.0040 - val_acc: 0.9800 - val_mDice: 0.7901

Epoch 00154: val_mDice did not improve from 0.79282
Epoch 155/300
 - 22s - loss: 0.9322 - acc: 0.9695 - mDice: 0.7974 - val_loss: 0.9799 - val_acc: 0.9804 - val_mDice: 0.7927

Epoch 00155: val_mDice did not improve from 0.79282
Epoch 156/300
 - 23s - loss: 0.9322 - acc: 0.9694 - mDice: 0.7976 - val_loss: 1.0001 - val_acc: 0.9800 - val_mDice: 0.7919

Epoch 00156: val_mDice did not improve from 0.79282
Epoch 157/300
 - 22s - loss: 0.9329 - acc: 0.9694 - mDice: 0.7974 - val_loss: 0.9775 - val_acc: 0.9797 - val_mDice: 0.7922

Epoch 00157: val_mDice did not improve from 0.79282
Epoch 158/300
 - 22s - loss: 0.9296 - acc: 0.9695 - mDice: 0.7981 - val_loss: 1.0056 - val_acc: 0.9797 - val_mDice: 0.7906

Epoch 00158: val_mDice did not improve from 0.79282
Epoch 159/300
 - 23s - loss: 0.9295 - acc: 0.9695 - mDice: 0.7982 - val_loss: 0.9989 - val_acc: 0.9799 - val_mDice: 0.7900

Epoch 00159: val_mDice did not improve from 0.79282
Epoch 160/300
 - 23s - loss: 0.9296 - acc: 0.9695 - mDice: 0.7979 - val_loss: 1.0143 - val_acc: 0.9795 - val_mDice: 0.7896

Epoch 00160: val_mDice did not improve from 0.79282
Epoch 161/300
 - 22s - loss: 0.9250 - acc: 0.9695 - mDice: 0.7991 - val_loss: 0.9976 - val_acc: 0.9798 - val_mDice: 0.7908

Epoch 00161: val_mDice did not improve from 0.79282
Epoch 162/300
 - 22s - loss: 0.9294 - acc: 0.9695 - mDice: 0.7981 - val_loss: 0.9833 - val_acc: 0.9798 - val_mDice: 0.7952

Epoch 00162: val_mDice improved from 0.79282 to 0.79516, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 163/300
 - 22s - loss: 0.9260 - acc: 0.9695 - mDice: 0.7989 - val_loss: 0.9928 - val_acc: 0.9804 - val_mDice: 0.7909

Epoch 00163: val_mDice did not improve from 0.79516
Epoch 164/300
 - 20s - loss: 0.9280 - acc: 0.9695 - mDice: 0.7984 - val_loss: 1.0023 - val_acc: 0.9802 - val_mDice: 0.7905

Epoch 00164: val_mDice did not improve from 0.79516
Epoch 165/300
 - 21s - loss: 0.9259 - acc: 0.9696 - mDice: 0.7988 - val_loss: 1.0016 - val_acc: 0.9802 - val_mDice: 0.7909

Epoch 00165: val_mDice did not improve from 0.79516
Epoch 166/300
 - 20s - loss: 0.9230 - acc: 0.9696 - mDice: 0.7994 - val_loss: 0.9895 - val_acc: 0.9802 - val_mDice: 0.7940

Epoch 00166: val_mDice did not improve from 0.79516
Epoch 167/300
 - 20s - loss: 0.9221 - acc: 0.9696 - mDice: 0.7998 - val_loss: 1.0050 - val_acc: 0.9803 - val_mDice: 0.7890

Epoch 00167: val_mDice did not improve from 0.79516
Epoch 168/300
 - 20s - loss: 0.9209 - acc: 0.9696 - mDice: 0.7998 - val_loss: 0.9921 - val_acc: 0.9795 - val_mDice: 0.7928

Epoch 00168: val_mDice did not improve from 0.79516
Epoch 169/300
 - 21s - loss: 0.9225 - acc: 0.9696 - mDice: 0.7998 - val_loss: 1.0019 - val_acc: 0.9797 - val_mDice: 0.7901

Epoch 00169: val_mDice did not improve from 0.79516
Epoch 170/300
 - 20s - loss: 0.9192 - acc: 0.9696 - mDice: 0.8000 - val_loss: 0.9930 - val_acc: 0.9801 - val_mDice: 0.7911

Epoch 00170: val_mDice did not improve from 0.79516
Epoch 171/300
 - 20s - loss: 0.9201 - acc: 0.9696 - mDice: 0.8000 - val_loss: 1.0090 - val_acc: 0.9795 - val_mDice: 0.7911

Epoch 00171: val_mDice did not improve from 0.79516
Epoch 172/300
 - 20s - loss: 0.9187 - acc: 0.9696 - mDice: 0.8003 - val_loss: 0.9912 - val_acc: 0.9795 - val_mDice: 0.7931

Epoch 00172: val_mDice did not improve from 0.79516
Epoch 173/300
 - 20s - loss: 0.9202 - acc: 0.9696 - mDice: 0.8000 - val_loss: 0.9965 - val_acc: 0.9798 - val_mDice: 0.7945

Epoch 00173: val_mDice did not improve from 0.79516
Epoch 174/300
 - 21s - loss: 0.9200 - acc: 0.9696 - mDice: 0.8003 - val_loss: 0.9811 - val_acc: 0.9803 - val_mDice: 0.7905

Epoch 00174: val_mDice did not improve from 0.79516
Epoch 175/300
 - 20s - loss: 0.9173 - acc: 0.9696 - mDice: 0.8004 - val_loss: 0.9989 - val_acc: 0.9799 - val_mDice: 0.7914

Epoch 00175: val_mDice did not improve from 0.79516
Epoch 176/300
 - 20s - loss: 0.9142 - acc: 0.9697 - mDice: 0.8013 - val_loss: 0.9817 - val_acc: 0.9801 - val_mDice: 0.7927

Epoch 00176: val_mDice did not improve from 0.79516
Epoch 177/300
 - 20s - loss: 0.9152 - acc: 0.9697 - mDice: 0.8011 - val_loss: 1.0014 - val_acc: 0.9800 - val_mDice: 0.7905

Epoch 00177: val_mDice did not improve from 0.79516
Epoch 178/300
 - 20s - loss: 0.9146 - acc: 0.9697 - mDice: 0.8013 - val_loss: 0.9998 - val_acc: 0.9800 - val_mDice: 0.7916

Epoch 00178: val_mDice did not improve from 0.79516
Epoch 179/300
 - 21s - loss: 0.9126 - acc: 0.9697 - mDice: 0.8015 - val_loss: 1.0030 - val_acc: 0.9797 - val_mDice: 0.7929

Epoch 00179: val_mDice did not improve from 0.79516
Epoch 180/300
 - 20s - loss: 0.9108 - acc: 0.9697 - mDice: 0.8022 - val_loss: 1.0038 - val_acc: 0.9798 - val_mDice: 0.7946

Epoch 00180: val_mDice did not improve from 0.79516
Epoch 181/300
 - 20s - loss: 0.9114 - acc: 0.9697 - mDice: 0.8021 - val_loss: 0.9920 - val_acc: 0.9799 - val_mDice: 0.7951

Epoch 00181: val_mDice did not improve from 0.79516
Epoch 182/300
 - 20s - loss: 0.9126 - acc: 0.9697 - mDice: 0.8018 - val_loss: 1.0012 - val_acc: 0.9797 - val_mDice: 0.7941

Epoch 00182: val_mDice did not improve from 0.79516
Epoch 183/300
 - 20s - loss: 0.9103 - acc: 0.9698 - mDice: 0.8024 - val_loss: 1.0017 - val_acc: 0.9803 - val_mDice: 0.7936

Epoch 00183: val_mDice did not improve from 0.79516
Epoch 184/300
 - 21s - loss: 0.9070 - acc: 0.9698 - mDice: 0.8028 - val_loss: 1.0069 - val_acc: 0.9797 - val_mDice: 0.7909

Epoch 00184: val_mDice did not improve from 0.79516
Epoch 185/300
 - 20s - loss: 0.9076 - acc: 0.9698 - mDice: 0.8027 - val_loss: 1.0198 - val_acc: 0.9792 - val_mDice: 0.7908

Epoch 00185: val_mDice did not improve from 0.79516
Epoch 186/300
 - 20s - loss: 0.9068 - acc: 0.9698 - mDice: 0.8030 - val_loss: 0.9830 - val_acc: 0.9804 - val_mDice: 0.7925

Epoch 00186: val_mDice did not improve from 0.79516
Epoch 187/300
 - 20s - loss: 0.9113 - acc: 0.9697 - mDice: 0.8021 - val_loss: 0.9863 - val_acc: 0.9800 - val_mDice: 0.7926

Epoch 00187: val_mDice did not improve from 0.79516
Epoch 188/300
 - 20s - loss: 0.9080 - acc: 0.9698 - mDice: 0.8027 - val_loss: 0.9733 - val_acc: 0.9799 - val_mDice: 0.7938

Epoch 00188: val_mDice did not improve from 0.79516
Epoch 189/300
 - 21s - loss: 0.9075 - acc: 0.9698 - mDice: 0.8027 - val_loss: 0.9904 - val_acc: 0.9797 - val_mDice: 0.7925

Epoch 00189: val_mDice did not improve from 0.79516
Epoch 190/300
 - 20s - loss: 0.9068 - acc: 0.9698 - mDice: 0.8029 - val_loss: 0.9922 - val_acc: 0.9796 - val_mDice: 0.7923

Epoch 00190: val_mDice did not improve from 0.79516
Epoch 191/300
 - 20s - loss: 0.9046 - acc: 0.9698 - mDice: 0.8036 - val_loss: 1.0075 - val_acc: 0.9796 - val_mDice: 0.7900

Epoch 00191: val_mDice did not improve from 0.79516
Epoch 192/300
 - 20s - loss: 0.9040 - acc: 0.9698 - mDice: 0.8037 - val_loss: 1.0013 - val_acc: 0.9801 - val_mDice: 0.7934

Epoch 00192: val_mDice did not improve from 0.79516
Restoring model weights from the end of the best epoch
Epoch 00192: early stopping
{'val_loss': [7.698394132624192, 5.11302326433688, 3.756140374969724, 2.8096019400444097, 2.1268626501773906, 1.8745138898675178, 1.7161770960568126, 1.5413660250983883, 1.4325604639908132, 1.4335363793247404, 1.4347782264903894, 1.3701805881959483, 1.3057970018085152, 1.3068257827959915, 1.2726759532423975, 1.2814330658719912, 1.2690429312483078, 1.270945303155165, 1.2219498658222139, 1.2097384784049854, 1.2064036826467264, 1.1752950940903126, 1.1951836273205092, 1.1385463145160508, 1.150916016793209, 1.1741055630422434, 1.152455927722274, 1.1464394275459129, 1.1620039477918185, 1.1237466575181756, 1.1311202069158504, 1.112308343286464, 1.1481182591986363, 1.089806261402023, 1.127967741451699, 1.094380644901356, 1.0965621485022963, 1.108692892825457, 1.0884712527003564, 1.0914939133898864, 1.0921797757618037, 1.0988505689037704, 1.1023566606593678, 1.074443432798704, 1.0801331527622806, 1.0818918566293163, 1.0917450668313173, 1.1023809515948035, 1.0814174269121435, 1.0769948481675402, 1.0497309587542327, 1.0578127393404084, 1.0612619294014045, 1.0722331795415896, 1.065514243864217, 1.0471321343328077, 1.0809574997697438, 1.0469788607268844, 1.057597597579755, 1.0431380606074745, 1.0458487094181912, 1.066006665594339, 1.0509221764356684, 1.0542946556330983, 1.0548698208663083, 1.0419110627501207, 1.064702748833306, 1.053008333555634, 1.0461466879123962, 1.0441823068528266, 1.042510354665545, 1.0398065969478896, 1.0401685978490565, 1.0299838925916407, 1.0408096652877352, 1.041850810101246, 1.0442549377836954, 1.05277408929198, 1.0416518095717069, 1.0458140735676502, 1.0460619888741438, 1.0564647106378484, 1.0432523880775868, 1.0305799776933733, 1.0303222680552773, 1.0415076369350948, 1.0488846528299665, 1.0406897511130269, 1.0451144517410829, 1.0447602149472295, 1.0399956472728709, 1.0495830893726048, 1.033612626717673, 1.025695910038973, 1.0191314921228245, 1.0411117224575974, 1.0323263672826999, 1.0216234411212808, 1.059221981489386, 1.0179745318181486, 1.0205376769411123, 1.0215336316918238, 1.006458645545745, 1.0275939457864878, 1.0164888956844282, 1.0139678132135965, 1.0182905057821625, 1.0172870458743695, 1.0220281441936594, 1.0097522455904313, 1.0364231939684527, 1.016816374287664, 1.0251500648438197, 1.0166344530553098, 0.9938095890784305, 1.0065540059589124, 1.023362933018086, 1.0184394769593157, 1.026490446239029, 0.9968504803042421, 1.0167395797261873, 1.0043734429381224, 1.014143226016804, 0.9925012519363778, 0.996117514968966, 1.0016277264836384, 0.9883135125590963, 0.9967552502042171, 1.0129313186099114, 0.9932315365291857, 1.0110176942050981, 0.9902088488132966, 0.9955277640915923, 1.0025471544223845, 0.9926710429426236, 0.9972198602394815, 0.9945675048761082, 0.9899950314489945, 1.0085186650338198, 0.9949275685739434, 1.001709036751665, 0.9828891286950538, 0.9921691606250086, 1.002368094003473, 0.9986554663922959, 1.0013537654139246, 0.992131074514037, 1.0059151502820436, 0.9909750625412578, 0.9944906822407392, 0.9961458320986407, 1.0014847369311355, 0.9985619108790044, 1.0039582985775752, 0.9799294739909248, 1.000100673606819, 0.9774967069575573, 1.0056093354007272, 0.9989412287626619, 1.0142850905185425, 0.9975893155971185, 0.9832884977278684, 0.9928009229301359, 1.0023380161798272, 1.0016063902206287, 0.9894838232566686, 1.0050180517726288, 0.9920729003807363, 1.0019227296690112, 0.9930053882313948, 1.0090221797225765, 0.9911897946116376, 0.9964502946144668, 0.9810778999370514, 0.9989040323217221, 0.9817014843592116, 1.0014407736345838, 0.999778634634504, 1.0030297384530253, 1.003813952574202, 0.9919643264872747, 1.0011964732607554, 1.0016949314015193, 1.0069022488719759, 1.0198110150327162, 0.9829567649871478, 0.986303354084806, 0.9733037134675024, 0.9903931655448015, 0.9922320060235544, 1.0074560012674918, 1.0012641974408933], 'val_acc': [0.911152898532016, 0.9138264734631892, 0.9252335709930514, 0.9471817607410343, 0.9579182420128888, 0.9650052937765742, 0.9663992291594641, 0.968421208732786, 0.9710611445413533, 0.9709722334764544, 0.9710712460097194, 0.9721136223033777, 0.9734604878249613, 0.9726979387874972, 0.9730472798297192, 0.9733655905262657, 0.9745562963829308, 0.9749321684057977, 0.9749964111090126, 0.9748092260218253, 0.9755239540118534, 0.9761224775616021, 0.9756509851278027, 0.9760567328003882, 0.9760638053262171, 0.9761064233805048, 0.9761131437256382, 0.9763903661855285, 0.9765491368271974, 0.9775238939035547, 0.9763593419155463, 0.9769238739524868, 0.9773370802716757, 0.9769840328471313, 0.976911914683813, 0.9771353478800433, 0.9775332386338648, 0.9773169218551085, 0.9783409898855145, 0.9773964998173169, 0.9783047505757512, 0.9775048357112127, 0.9778291301274761, 0.9779419653864024, 0.9777099620059839, 0.9783237964072001, 0.9779647641106524, 0.9777435936911035, 0.9784885679481319, 0.9784022618890437, 0.9786604159955191, 0.9787949225186044, 0.9787758610789092, 0.9784896636679637, 0.9783682607389292, 0.9785681502052267, 0.9782785821463814, 0.9789335258396732, 0.979145000814763, 0.9782464634136072, 0.978852829321407, 0.9786634221018303, 0.9788098650573637, 0.9782939125867217, 0.9783555492365926, 0.9790590583544834, 0.9782864371795855, 0.9792451180766463, 0.9794790077502782, 0.9785673964002639, 0.978902899632345, 0.9789421294401736, 0.9788991601479703, 0.9789331608790715, 0.9789637913812862, 0.979120335595679, 0.9783809485670133, 0.9790459963475044, 0.9789660306932219, 0.9790747646497716, 0.9787930578045769, 0.9784280331985393, 0.9792058989536574, 0.9787583050493197, 0.979464808645902, 0.978313702900087, 0.9785662716637596, 0.9793209600113397, 0.9790019135274032, 0.9786122357489145, 0.9793957040263814, 0.9790101297500892, 0.9789421274498603, 0.9795018008178483, 0.9795503676042406, 0.9790329138088729, 0.9792877157040346, 0.9792032812726937, 0.97864883373408, 0.9798324459047435, 0.9794494897284282, 0.9794860928465067, 0.9797240971261881, 0.9793030365070685, 0.979078124717585, 0.9802609652752198, 0.9794222170942068, 0.9794065336351445, 0.9796628245988923, 0.979588476865698, 0.9785121109447915, 0.9792219544965479, 0.9795686811051595, 0.9797442687416748, 0.9799643246905456, 0.9801959642626489, 0.978938395088712, 0.9801305972419431, 0.9799785233759084, 0.9795948149659303, 0.9795813738566501, 0.979449127491413, 0.9797173623250951, 0.9800928467606409, 0.9793938189902079, 0.9796639501734232, 0.9797666972676564, 0.9796699282364603, 0.9800072851834691, 0.9798051767273821, 0.9794864822146344, 0.9800211107374704, 0.979922492914753, 0.9798787705508603, 0.9799751606892617, 0.9797808910296126, 0.9797502510995982, 0.9797760304751002, 0.9800704272434456, 0.9795686640303667, 0.9801597352187118, 0.9799269653581777, 0.9802139012800998, 0.9790848446437052, 0.9796658183443107, 0.9795208514679505, 0.9796777701754981, 0.9801881286088109, 0.9799990723128897, 0.9800554828191265, 0.979884009579154, 0.9800181317622716, 0.9801346915258464, 0.9800304586103805, 0.980350282783039, 0.9800076586290906, 0.9797345589460095, 0.9797084005729595, 0.9799026852123348, 0.9794760237469196, 0.9797779036741474, 0.9797954576086705, 0.9804250085710012, 0.9801597251623921, 0.9801739184005818, 0.9801978325382896, 0.9803147746515191, 0.9795316796101668, 0.9797188743346604, 0.9801470214118019, 0.9794700382463961, 0.9795088928277966, 0.9798440295279759, 0.9803233671481664, 0.9799374309491189, 0.9801167691738618, 0.9800155093674081, 0.9800248485457919, 0.9796684277497612, 0.979772286381579, 0.9799292054033866, 0.9796650503976483, 0.9802527483192605, 0.97966058444893, 0.9792088846330693, 0.9803614776666638, 0.9800293323025762, 0.9799097766985164, 0.9796740282817968, 0.97960826864561, 0.9796086426149981, 0.9801055496732045], 'val_mDice': [0.011934778581067318, 0.09222238402165511, 0.1928273583966944, 0.35929029551457436, 0.49894799310419385, 0.5588047210068191, 0.6087976161960139, 0.6450937784199975, 0.6690266659263986, 0.6772142816302228, 0.6801367046962933, 0.6935318888595527, 0.7093989178669264, 0.7075502918558506, 0.7176860681946122, 0.7180994037794103, 0.7184409406985466, 0.7194982018118793, 0.7242275367512225, 0.729261417485289, 0.734729664920713, 0.7352031276598966, 0.7365853736186907, 0.7439887036548138, 0.7444003380455325, 0.744558763210719, 0.7439139645631787, 0.7476122109039387, 0.7436228169288702, 0.7488106465088252, 0.7504367436591687, 0.753789916189358, 0.7498918113892862, 0.7584671138250555, 0.7537736828800664, 0.7557418471061492, 0.7593903606512006, 0.7568785668676473, 0.7567729810629243, 0.7586085404578747, 0.7579983152278907, 0.7584759665289746, 0.7576572332524667, 0.7631370756244827, 0.7626938223838806, 0.7593763551309783, 0.7635339458713633, 0.7604601600048622, 0.7611572153748444, 0.7589718166260812, 0.7630846365264933, 0.7626822908230532, 0.7662635084195799, 0.7661298965946861, 0.765388866091026, 0.7677033716429725, 0.764247235807677, 0.7648248934368677, 0.765627353074052, 0.7657252039976405, 0.7681739304103415, 0.7671970200245326, 0.7661473468234125, 0.7667068818122516, 0.7717048341444381, 0.7680197558210269, 0.7679341375723036, 0.7722057336663111, 0.7669869398400319, 0.7708482343199383, 0.7712605174480297, 0.7750698308115056, 0.7714743659240709, 0.7756226458742246, 0.7721393741078033, 0.7694022072011012, 0.7739326899416208, 0.7746157937393456, 0.7739864927184603, 0.7713125062114534, 0.7735378126268437, 0.7735082384572087, 0.7748652361398841, 0.7761539108723874, 0.7782590060326253, 0.7738285596844182, 0.7724962124506074, 0.7736685765229545, 0.7749614749097238, 0.7728952741371516, 0.774247052066146, 0.7732778754091849, 0.7763546732481837, 0.77957095768833, 0.7724786684676507, 0.7757286785566534, 0.776937418118093, 0.7793542542650327, 0.7774879529103244, 0.7794066077795515, 0.779287261472645, 0.7755020125679056, 0.7801941433145627, 0.7785897632055836, 0.7805848111167734, 0.7777923871427512, 0.775587870806508, 0.779171462532506, 0.7796482074030254, 0.7832797962668072, 0.7810610697223348, 0.7822430611494765, 0.7805580195098435, 0.7803545660209991, 0.780337131086259, 0.7835170483128258, 0.7816326986926302, 0.7815041197414767, 0.782202020785092, 0.786258688081966, 0.7840178052654165, 0.7822601484079144, 0.7803076467949812, 0.787619969337812, 0.7863068847748433, 0.7846060392098184, 0.7876121710809127, 0.7889243742493628, 0.7858746961047235, 0.7859094620589003, 0.7854977876524095, 0.786191177493868, 0.7877341032237705, 0.7844353057378625, 0.7876476780601461, 0.7896470234766996, 0.7875580263892041, 0.7887977601564203, 0.787669477542381, 0.7880893690095845, 0.7893628205691574, 0.787522175085775, 0.7900779630681123, 0.786860980551775, 0.7863496321994936, 0.7861602924410613, 0.7928236970164025, 0.7898746661854964, 0.7899615579204525, 0.7911793251238725, 0.7911190479627184, 0.7883597922450838, 0.7879453178868352, 0.7901490658574029, 0.7927241947613198, 0.7919191501262108, 0.7922119821940659, 0.7905659297438623, 0.7900232463184685, 0.7895593240935689, 0.7907655894861071, 0.7951603977039116, 0.790924999437349, 0.790481459591636, 0.7909489096991835, 0.7939791350456868, 0.7890037479425775, 0.7928316540793501, 0.79005429447221, 0.7910834551905077, 0.7910680057503846, 0.7931424142606229, 0.7944619562378668, 0.7905030112274921, 0.7913691676982887, 0.7926635530585774, 0.7905419982171017, 0.7915962898877886, 0.7928667229801574, 0.7946080870284766, 0.7950884499742612, 0.7941112940466467, 0.7935911506047777, 0.7909022125502253, 0.7908266436027098, 0.7925440211287701, 0.792628832043579, 0.7937650001740414, 0.7925046880341582, 0.792348050379795, 0.789958340631428, 0.7933776609088918], 'loss': [80.34236257414976, 9.814526554658821, 6.50270657822288, 4.783616939180601, 3.7762056602984644, 3.196811531277681, 2.7871984785476958, 2.505765553689628, 2.32543689429769, 2.193049542269549, 2.0985403663108673, 1.993177504365754, 1.914470341597822, 1.8665114001619227, 1.8007797422073584, 1.7528231708292308, 1.7113063212255966, 1.672998227024947, 1.6356063730661152, 1.5999835339713653, 1.571540005703432, 1.5342811933551723, 1.5090103722813686, 1.483194052390175, 1.4595384977885038, 1.4432588398027633, 1.4198857158037024, 1.4043692831490133, 1.3918558904469676, 1.3726938162168651, 1.3598995557231384, 1.3392562368520702, 1.3274826602075271, 1.3208687454289576, 1.3059220461575196, 1.2881794960981983, 1.2853992089106496, 1.27020154331802, 1.261546371930511, 1.2537982348232874, 1.2423882403837334, 1.2354502872740172, 1.229078281403284, 1.2214493572001044, 1.2102192078753282, 1.204956942668025, 1.1982974546058003, 1.19392147948665, 1.187215235874497, 1.1785875767413914, 1.176577786000648, 1.1678910352318548, 1.160354578520822, 1.1507583438801205, 1.1493981978228693, 1.1432383572873492, 1.1384936352061923, 1.1394710638197827, 1.1288353645455393, 1.1247051802010752, 1.1201122555193523, 1.115842205556888, 1.1160759203423551, 1.1116536790876719, 1.103485131334523, 1.1018802922737028, 1.0990802283933998, 1.0935577274172723, 1.0956397099353594, 1.091739262178016, 1.0855753497642813, 1.0855953499737039, 1.0777931653147261, 1.0791580884153438, 1.0731153494548284, 1.0714326089650286, 1.0671548159629636, 1.0687310107580628, 1.0627973630224223, 1.059104776419641, 1.0573936787358793, 1.05641325112768, 1.0541491110829628, 1.0491409009448787, 1.0479917490220167, 1.047025240728644, 1.0420609429320418, 1.0449821061939473, 1.0425339471915307, 1.0404763513179869, 1.035795329822447, 1.0344768028231441, 1.0306991154225722, 1.033530073670183, 1.0284225699418168, 1.0274373372651797, 1.0225949616318446, 1.0203900565007307, 1.0169344269919183, 1.0194252685382066, 1.0158899164986919, 1.016331968073048, 1.012136591254096, 1.009919344320024, 1.0094905851543727, 1.0080597863260439, 1.0052276047899105, 1.0059049109268918, 1.003257040414517, 0.9999208512798624, 0.9994223929814547, 0.9966715257508928, 0.9953694497595303, 0.9933447698289151, 0.9937230310552367, 0.992692364386419, 0.9872197490754482, 0.9868845814253806, 0.9878318089554806, 0.9870487369154896, 0.9808864133700314, 0.9767218209717992, 0.9795875056065549, 0.978054940229597, 0.9733992233519213, 0.9708095324170841, 0.9680935443842467, 0.9673371845958013, 0.9659248220891167, 0.9673151273587277, 0.9602323883997165, 0.9596573184915256, 0.9614607405364979, 0.9564859724495937, 0.9581759300237213, 0.9549890245268734, 0.9541338224498839, 0.9543051161413781, 0.9508990462194313, 0.9488070194833166, 0.945591274280144, 0.946432007681315, 0.9468150767446866, 0.9427897688499137, 0.9429666864530627, 0.9448894777341648, 0.9398465697859297, 0.9341983701399159, 0.9401964459311986, 0.9367149563843792, 0.9346899102261007, 0.9364580100594491, 0.9354225073305376, 0.9353258928117104, 0.9322417749773544, 0.9321949330725312, 0.9329200926925353, 0.9295675038367511, 0.9295062393386497, 0.9296339367453582, 0.9249783603829854, 0.9293578366983472, 0.9260219433432311, 0.9279526458233618, 0.92591744041918, 0.9229941004673972, 0.9220690251440582, 0.9209269431971453, 0.9224676074118291, 0.919206931083985, 0.9200775985910706, 0.918721375422919, 0.9202278626984376, 0.9200142110115772, 0.9172748509419714, 0.9141692859940161, 0.9151811245781061, 0.9145824507956452, 0.9126198319734645, 0.9107658918679832, 0.9114180940769679, 0.9126413740057583, 0.910313851087888, 0.90696569842425, 0.9076171122117537, 0.9067821077285179, 0.9113116493241176, 0.908009457165855, 0.9074988145634114, 0.9067744941147745, 0.9046163105633507, 0.9040454527097249], 'acc': [0.7378018692658488, 0.8926078403075852, 0.9010616788254141, 0.9124887312708212, 0.92858930484715, 0.936586421915008, 0.9417414605740506, 0.94568132997537, 0.9484901351283441, 0.9506751154024727, 0.9521673191482195, 0.9537513984220928, 0.9550099827540034, 0.9557197912908826, 0.9567014864014065, 0.9574472604367352, 0.9581372790947084, 0.9587062948375564, 0.9592416681873079, 0.9599056027446826, 0.9603519221387867, 0.9609825859329708, 0.9613559535132712, 0.9618142032460114, 0.962211601558746, 0.9624842996356364, 0.9628447664203368, 0.963112597580459, 0.9633646167120704, 0.9636195037986592, 0.9638087429905998, 0.964059573607814, 0.964281061453222, 0.9643385005515581, 0.964646428360036, 0.9648724906812058, 0.9649010566519021, 0.9650988662064715, 0.9651894384322915, 0.9653248030282334, 0.9655277067507155, 0.9655619204497279, 0.9656968990687749, 0.9658348642761697, 0.9659231042689163, 0.9660163837892349, 0.966070537265141, 0.9662468193503753, 0.9662831646885799, 0.9664063869925967, 0.9664230542312264, 0.9665336841264145, 0.9666220443093131, 0.9667355515211663, 0.9668333522777097, 0.9669180762173275, 0.9669458685364722, 0.9669254338799494, 0.9670504971159092, 0.9670968089620346, 0.9671700806899938, 0.9672271035906713, 0.9672241190150414, 0.9672747972710948, 0.9673731017890222, 0.9673779253408693, 0.967445594136233, 0.9675429802578989, 0.9675009047929285, 0.9675439853810033, 0.9675824019498682, 0.9675762309179076, 0.9676360347197656, 0.9676822399788322, 0.9677662400239235, 0.9677984955374292, 0.9678196348281782, 0.9678000700107237, 0.9678559451282945, 0.967910872834671, 0.9679459722345282, 0.9679525852635309, 0.9679921438953044, 0.9679972272107384, 0.9680760644365405, 0.9680363745611643, 0.9680945927552888, 0.9680914155676587, 0.9681026168104975, 0.9681210278876804, 0.9682224344927653, 0.968208090728437, 0.9682544255783379, 0.9682797888139852, 0.9683019675790234, 0.9683201215412481, 0.9683371763285522, 0.968387713346404, 0.968442468112023, 0.9683846763531219, 0.9684462555821052, 0.9684054107966213, 0.9685146263600668, 0.9684987307572711, 0.9685239670777092, 0.9685349424882046, 0.9685874520685477, 0.9685735643002991, 0.9686318693502483, 0.9686538006649734, 0.9687021798603033, 0.9686967980567105, 0.9687054930398703, 0.9687412721864422, 0.9687099989692408, 0.9687531780095149, 0.9687958413230822, 0.9688073553830711, 0.9688141356356328, 0.9688131180192796, 0.9688646931886061, 0.9689330789284704, 0.9689170423754327, 0.9688911297637955, 0.9689671869013031, 0.9689862823235563, 0.9690163644617201, 0.9690710437669169, 0.9690510169122295, 0.9690437622761655, 0.9691078333008554, 0.9691212404764723, 0.9691210453478248, 0.9691738333191439, 0.9691461664604124, 0.9691355230703753, 0.9691530786164844, 0.9692044732351199, 0.9692261483017652, 0.9692546160632283, 0.9692781396927468, 0.9692958047355069, 0.9692343527876817, 0.9693145159536168, 0.9693471993541425, 0.9693055285294506, 0.9693247196502891, 0.9694198838004252, 0.9693537255063234, 0.9694159232546042, 0.9694141258825552, 0.9694321317915335, 0.9694300561514914, 0.9694310112356102, 0.9694740458011363, 0.9694489171416066, 0.9694401980418275, 0.969464065957085, 0.9695305531010895, 0.9694617210807837, 0.9695397672544733, 0.9694925875280052, 0.9695337203061188, 0.9695153740228534, 0.9695582098902324, 0.9695896640000768, 0.9695917381793238, 0.9695891713701325, 0.9695773592569239, 0.9696285310577935, 0.9696184319114656, 0.9696160242509653, 0.9695865387351684, 0.9696175961506204, 0.9696185176994401, 0.9696716035410045, 0.9696537027882856, 0.969656966213827, 0.9696944855784597, 0.9697056106229798, 0.9697374312034533, 0.9697314385534874, 0.9697546208788492, 0.9697977438449835, 0.9697614244651401, 0.969754171520839, 0.9697230249128898, 0.9697552177201855, 0.9697579908104609, 0.9697797501892875, 0.9698394241303492, 0.9698142944029693], 'mDice': [0.02186688172076184, 0.05651951979171419, 0.1159765997086142, 0.211954695467176, 0.3183313850745552, 0.3957126323343865, 0.45585424998831087, 0.5025948902440116, 0.5338670534862257, 0.5578852099913019, 0.5753227481663986, 0.5938629028235748, 0.6078464357261779, 0.6164857955111165, 0.6281877774656176, 0.6369852580155971, 0.6439424305831797, 0.6513622859500866, 0.6583794118185707, 0.664726370942292, 0.6701374152041328, 0.6771260506853256, 0.6814456138161623, 0.6867980459700964, 0.691433775041611, 0.6941137783366956, 0.6986582182888824, 0.7013654249026763, 0.7040488830474692, 0.7079952555072067, 0.7101107468231174, 0.713950178141587, 0.7164174429118066, 0.7175508530893058, 0.7204128346471492, 0.7239841150023258, 0.724354170452912, 0.7274097201208795, 0.7291390759002688, 0.7305017349632533, 0.732707383354179, 0.7339983703709652, 0.7353208094668805, 0.7369004063340859, 0.7390345832037042, 0.7402340552688191, 0.7411599954009314, 0.742083277449647, 0.7434423290233201, 0.7452790861454676, 0.7456665675933225, 0.7472697907956496, 0.7485482759939083, 0.7505431360845914, 0.7509095481169025, 0.7522583693756346, 0.7533812656609439, 0.7527212969076531, 0.7550189612820166, 0.7558827010292177, 0.7566825454281031, 0.7574501725461233, 0.7576875850362559, 0.7585740467843457, 0.7600401498058242, 0.7604411796644982, 0.7610627880820414, 0.761999168481664, 0.7616852312945652, 0.7625171682218032, 0.7638909851777033, 0.7637768366527475, 0.7653108451814081, 0.7652094198049546, 0.7664402082722174, 0.7664885350258983, 0.767392616883047, 0.7670725898146119, 0.7683322913099214, 0.7691766585757067, 0.7696392784438527, 0.7695867111965932, 0.7702074794379101, 0.7710450740700657, 0.7712065942495856, 0.7718507670041186, 0.7726800570063955, 0.772223366728055, 0.7727230761090892, 0.7729142783668523, 0.7738623844467996, 0.7741757766642908, 0.7750055861757443, 0.7744990436745592, 0.7754586769166587, 0.7756943661303557, 0.7767999247740106, 0.777215823344427, 0.7777053530374235, 0.7775131434968586, 0.7781518571936282, 0.7783202884013781, 0.7792265669226041, 0.7795319825052394, 0.7797698369714168, 0.7799268346638871, 0.7805352879364845, 0.7803107564957199, 0.7809009908052043, 0.7819514674891056, 0.782082348070605, 0.7828060132940896, 0.7828730693023522, 0.7831707019959727, 0.7833997579904971, 0.7836419861885762, 0.7847096247927638, 0.7847247163852635, 0.7847111037054537, 0.7850249463488055, 0.7859303816912261, 0.7873436981751847, 0.786662900479641, 0.7871368075645742, 0.7878830607827324, 0.7884276436605161, 0.7894646704277919, 0.7894922717547094, 0.7897573271309338, 0.7896086336514003, 0.791286069321816, 0.7912437051863107, 0.790852623049191, 0.79206746032845, 0.7916914561987343, 0.792376353719575, 0.7926944198248929, 0.7925959003960911, 0.7933008471274855, 0.7937231764814513, 0.7943060554349904, 0.7944911091756367, 0.7941870810125166, 0.7950430116753748, 0.7953384929985688, 0.7944482837167985, 0.795595973125672, 0.7970248005523468, 0.795589675520454, 0.7965290625546144, 0.7968990497587671, 0.7965445808133051, 0.7968290845273119, 0.7969160497437533, 0.7973694397587162, 0.7976015305958243, 0.7974188201117063, 0.79811708852525, 0.798193138304789, 0.7979057771343331, 0.7990503844062525, 0.7980759432178925, 0.7988505882931538, 0.7983553233921039, 0.7987614240609647, 0.7993687013064146, 0.7998323258807234, 0.7998395353731155, 0.7997681483079693, 0.8000116611629684, 0.8000165578205676, 0.8003481561689707, 0.8000143659558175, 0.8003288307749543, 0.8003958578462732, 0.801334830131572, 0.8010659712045195, 0.8012656238897237, 0.8015261693471367, 0.802190989257405, 0.8020986699384878, 0.801815043427517, 0.8023529646291172, 0.802761823759304, 0.8027486921640571, 0.8029860289837968, 0.8020621096474146, 0.8026899870091935, 0.8027496145107649, 0.8028938555314324, 0.8035717696381901, 0.8037190340280497]}
predicting test subjects:   0%|          | 0/15 [00:00<?, ?it/s]predicting test subjects:   7%|▋         | 1/15 [00:02<00:28,  2.02s/it]predicting test subjects:  13%|█▎        | 2/15 [00:03<00:24,  1.92s/it]predicting test subjects:  20%|██        | 3/15 [00:05<00:23,  1.92s/it]predicting test subjects:  27%|██▋       | 4/15 [00:07<00:21,  1.93s/it]predicting test subjects:  33%|███▎      | 5/15 [00:09<00:20,  2.05s/it]predicting test subjects:  40%|████      | 6/15 [00:12<00:19,  2.14s/it]predicting test subjects:  47%|████▋     | 7/15 [00:13<00:15,  1.91s/it]predicting test subjects:  53%|█████▎    | 8/15 [00:15<00:14,  2.04s/it]predicting test subjects:  60%|██████    | 9/15 [00:17<00:12,  2.01s/it]predicting test subjects:  67%|██████▋   | 10/15 [00:19<00:09,  1.90s/it]predicting test subjects:  73%|███████▎  | 11/15 [00:21<00:07,  1.87s/it]predicting test subjects:  80%|████████  | 12/15 [00:23<00:05,  1.92s/it]predicting test subjects:  87%|████████▋ | 13/15 [00:25<00:03,  2.00s/it]predicting test subjects:  93%|█████████▎| 14/15 [00:27<00:01,  1.95s/it]predicting test subjects: 100%|██████████| 15/15 [00:29<00:00,  1.96s/it]
predicting train subjects:   0%|          | 0/532 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/532 [00:02<19:53,  2.25s/it]predicting train subjects:   0%|          | 2/532 [00:03<18:15,  2.07s/it]predicting train subjects:   1%|          | 3/532 [00:05<17:34,  1.99s/it]predicting train subjects:   1%|          | 4/532 [00:07<16:49,  1.91s/it]predicting train subjects:   1%|          | 5/532 [00:09<16:34,  1.89s/it]predicting train subjects:   1%|          | 6/532 [00:10<16:02,  1.83s/it]predicting train subjects:   1%|▏         | 7/532 [00:12<15:44,  1.80s/it]predicting train subjects:   2%|▏         | 8/532 [00:14<15:19,  1.75s/it]predicting train subjects:   2%|▏         | 9/532 [00:16<16:09,  1.85s/it]predicting train subjects:   2%|▏         | 10/532 [00:18<15:50,  1.82s/it]predicting train subjects:   2%|▏         | 11/532 [00:19<15:11,  1.75s/it]predicting train subjects:   2%|▏         | 12/532 [00:21<16:25,  1.90s/it]predicting train subjects:   2%|▏         | 13/532 [00:23<15:23,  1.78s/it]predicting train subjects:   3%|▎         | 14/532 [00:24<14:32,  1.68s/it]predicting train subjects:   3%|▎         | 15/532 [00:26<14:38,  1.70s/it]predicting train subjects:   3%|▎         | 16/532 [00:28<14:55,  1.73s/it]predicting train subjects:   3%|▎         | 17/532 [00:30<14:28,  1.69s/it]predicting train subjects:   3%|▎         | 18/532 [00:32<15:11,  1.77s/it]predicting train subjects:   4%|▎         | 19/532 [00:33<14:20,  1.68s/it]predicting train subjects:   4%|▍         | 20/532 [00:35<14:32,  1.70s/it]predicting train subjects:   4%|▍         | 21/532 [00:37<15:27,  1.82s/it]predicting train subjects:   4%|▍         | 22/532 [00:38<14:56,  1.76s/it]predicting train subjects:   4%|▍         | 23/532 [00:40<15:03,  1.78s/it]predicting train subjects:   5%|▍         | 24/532 [00:42<14:41,  1.73s/it]predicting train subjects:   5%|▍         | 25/532 [00:44<15:46,  1.87s/it]predicting train subjects:   5%|▍         | 26/532 [00:46<15:15,  1.81s/it]predicting train subjects:   5%|▌         | 27/532 [00:48<16:32,  1.97s/it]predicting train subjects:   5%|▌         | 28/532 [00:50<16:06,  1.92s/it]predicting train subjects:   5%|▌         | 29/532 [00:52<16:46,  2.00s/it]predicting train subjects:   6%|▌         | 30/532 [00:54<15:29,  1.85s/it]predicting train subjects:   6%|▌         | 31/532 [00:55<15:09,  1.82s/it]predicting train subjects:   6%|▌         | 32/532 [00:57<14:55,  1.79s/it]predicting train subjects:   6%|▌         | 33/532 [00:59<14:15,  1.71s/it]predicting train subjects:   6%|▋         | 34/532 [01:01<15:36,  1.88s/it]predicting train subjects:   7%|▋         | 35/532 [01:03<15:19,  1.85s/it]predicting train subjects:   7%|▋         | 36/532 [01:05<15:28,  1.87s/it]predicting train subjects:   7%|▋         | 37/532 [01:06<15:25,  1.87s/it]predicting train subjects:   7%|▋         | 38/532 [01:09<16:04,  1.95s/it]predicting train subjects:   7%|▋         | 39/532 [01:10<15:39,  1.91s/it]predicting train subjects:   8%|▊         | 40/532 [01:12<14:56,  1.82s/it]predicting train subjects:   8%|▊         | 41/532 [01:14<15:10,  1.85s/it]predicting train subjects:   8%|▊         | 42/532 [01:16<15:16,  1.87s/it]predicting train subjects:   8%|▊         | 43/532 [01:17<14:31,  1.78s/it]predicting train subjects:   8%|▊         | 44/532 [01:19<13:54,  1.71s/it]predicting train subjects:   8%|▊         | 45/532 [01:21<13:48,  1.70s/it]predicting train subjects:   9%|▊         | 46/532 [01:23<14:15,  1.76s/it]predicting train subjects:   9%|▉         | 47/532 [01:25<15:11,  1.88s/it]predicting train subjects:   9%|▉         | 48/532 [01:27<15:19,  1.90s/it]predicting train subjects:   9%|▉         | 49/532 [01:28<14:38,  1.82s/it]predicting train subjects:   9%|▉         | 50/532 [01:30<15:17,  1.90s/it]predicting train subjects:  10%|▉         | 51/532 [01:32<15:03,  1.88s/it]predicting train subjects:  10%|▉         | 52/532 [01:34<14:41,  1.84s/it]predicting train subjects:  10%|▉         | 53/532 [01:36<14:13,  1.78s/it]predicting train subjects:  10%|█         | 54/532 [01:38<14:47,  1.86s/it]predicting train subjects:  10%|█         | 55/532 [01:40<15:01,  1.89s/it]predicting train subjects:  11%|█         | 56/532 [01:41<14:58,  1.89s/it]predicting train subjects:  11%|█         | 57/532 [01:43<14:39,  1.85s/it]predicting train subjects:  11%|█         | 58/532 [01:45<14:45,  1.87s/it]predicting train subjects:  11%|█         | 59/532 [01:47<15:45,  2.00s/it]predicting train subjects:  11%|█▏        | 60/532 [01:49<14:34,  1.85s/it]predicting train subjects:  11%|█▏        | 61/532 [01:51<13:52,  1.77s/it]predicting train subjects:  12%|█▏        | 62/532 [01:53<14:58,  1.91s/it]predicting train subjects:  12%|█▏        | 63/532 [01:55<15:19,  1.96s/it]predicting train subjects:  12%|█▏        | 64/532 [01:56<14:30,  1.86s/it]predicting train subjects:  12%|█▏        | 65/532 [01:58<14:36,  1.88s/it]predicting train subjects:  12%|█▏        | 66/532 [02:01<15:46,  2.03s/it]predicting train subjects:  13%|█▎        | 67/532 [02:03<15:59,  2.06s/it]predicting train subjects:  13%|█▎        | 68/532 [02:05<15:32,  2.01s/it]predicting train subjects:  13%|█▎        | 69/532 [02:07<14:49,  1.92s/it]predicting train subjects:  13%|█▎        | 70/532 [02:08<14:25,  1.87s/it]predicting train subjects:  13%|█▎        | 71/532 [02:10<13:45,  1.79s/it]predicting train subjects:  14%|█▎        | 72/532 [02:12<13:18,  1.74s/it]predicting train subjects:  14%|█▎        | 73/532 [02:14<14:05,  1.84s/it]predicting train subjects:  14%|█▍        | 74/532 [02:16<15:23,  2.02s/it]predicting train subjects:  14%|█▍        | 75/532 [02:19<17:14,  2.26s/it]predicting train subjects:  14%|█▍        | 76/532 [02:21<15:53,  2.09s/it]predicting train subjects:  14%|█▍        | 77/532 [02:22<15:27,  2.04s/it]predicting train subjects:  15%|█▍        | 78/532 [02:24<14:59,  1.98s/it]predicting train subjects:  15%|█▍        | 79/532 [02:26<14:37,  1.94s/it]predicting train subjects:  15%|█▌        | 80/532 [02:28<14:25,  1.91s/it]predicting train subjects:  15%|█▌        | 81/532 [02:30<14:23,  1.91s/it]predicting train subjects:  15%|█▌        | 82/532 [02:32<14:07,  1.88s/it]predicting train subjects:  16%|█▌        | 83/532 [02:33<13:28,  1.80s/it]predicting train subjects:  16%|█▌        | 84/532 [02:35<12:55,  1.73s/it]predicting train subjects:  16%|█▌        | 85/532 [02:36<12:25,  1.67s/it]predicting train subjects:  16%|█▌        | 86/532 [02:38<12:10,  1.64s/it]predicting train subjects:  16%|█▋        | 87/532 [02:40<11:57,  1.61s/it]predicting train subjects:  17%|█▋        | 88/532 [02:41<11:51,  1.60s/it]predicting train subjects:  17%|█▋        | 89/532 [02:43<12:18,  1.67s/it]predicting train subjects:  17%|█▋        | 90/532 [02:45<12:30,  1.70s/it]predicting train subjects:  17%|█▋        | 91/532 [02:47<12:43,  1.73s/it]predicting train subjects:  17%|█▋        | 92/532 [02:48<12:55,  1.76s/it]predicting train subjects:  17%|█▋        | 93/532 [02:50<12:53,  1.76s/it]predicting train subjects:  18%|█▊        | 94/532 [02:52<13:02,  1.79s/it]predicting train subjects:  18%|█▊        | 95/532 [02:54<13:40,  1.88s/it]predicting train subjects:  18%|█▊        | 96/532 [02:56<14:06,  1.94s/it]predicting train subjects:  18%|█▊        | 97/532 [02:58<14:27,  1.99s/it]predicting train subjects:  18%|█▊        | 98/532 [03:00<14:41,  2.03s/it]predicting train subjects:  19%|█▊        | 99/532 [03:03<14:50,  2.06s/it]predicting train subjects:  19%|█▉        | 100/532 [03:05<14:42,  2.04s/it]predicting train subjects:  19%|█▉        | 101/532 [03:06<13:52,  1.93s/it]predicting train subjects:  19%|█▉        | 102/532 [03:08<13:06,  1.83s/it]predicting train subjects:  19%|█▉        | 103/532 [03:09<12:30,  1.75s/it]predicting train subjects:  20%|█▉        | 104/532 [03:11<12:01,  1.69s/it]predicting train subjects:  20%|█▉        | 105/532 [03:12<11:42,  1.64s/it]predicting train subjects:  20%|█▉        | 106/532 [03:14<11:30,  1.62s/it]predicting train subjects:  20%|██        | 107/532 [03:16<11:18,  1.60s/it]predicting train subjects:  20%|██        | 108/532 [03:17<11:19,  1.60s/it]predicting train subjects:  20%|██        | 109/532 [03:19<11:12,  1.59s/it]predicting train subjects:  21%|██        | 110/532 [03:20<11:09,  1.59s/it]predicting train subjects:  21%|██        | 111/532 [03:22<11:13,  1.60s/it]predicting train subjects:  21%|██        | 112/532 [03:24<11:18,  1.62s/it]predicting train subjects:  21%|██        | 113/532 [03:26<12:02,  1.72s/it]predicting train subjects:  21%|██▏       | 114/532 [03:28<12:37,  1.81s/it]predicting train subjects:  22%|██▏       | 115/532 [03:29<12:35,  1.81s/it]predicting train subjects:  22%|██▏       | 116/532 [03:31<12:38,  1.82s/it]predicting train subjects:  22%|██▏       | 117/532 [03:33<12:52,  1.86s/it]predicting train subjects:  22%|██▏       | 118/532 [03:35<12:51,  1.86s/it]predicting train subjects:  22%|██▏       | 119/532 [03:37<12:46,  1.86s/it]predicting train subjects:  23%|██▎       | 120/532 [03:39<12:35,  1.83s/it]predicting train subjects:  23%|██▎       | 121/532 [03:40<12:30,  1.83s/it]predicting train subjects:  23%|██▎       | 122/532 [03:42<12:23,  1.81s/it]predicting train subjects:  23%|██▎       | 123/532 [03:44<12:15,  1.80s/it]predicting train subjects:  23%|██▎       | 124/532 [03:46<12:11,  1.79s/it]predicting train subjects:  23%|██▎       | 125/532 [03:48<12:31,  1.85s/it]predicting train subjects:  24%|██▎       | 126/532 [03:50<12:43,  1.88s/it]predicting train subjects:  24%|██▍       | 127/532 [03:52<12:52,  1.91s/it]predicting train subjects:  24%|██▍       | 128/532 [03:54<12:52,  1.91s/it]predicting train subjects:  24%|██▍       | 129/532 [03:56<12:53,  1.92s/it]predicting train subjects:  24%|██▍       | 130/532 [03:58<13:01,  1.94s/it]predicting train subjects:  25%|██▍       | 131/532 [04:00<13:36,  2.04s/it]predicting train subjects:  25%|██▍       | 132/532 [04:02<13:56,  2.09s/it]predicting train subjects:  25%|██▌       | 133/532 [04:04<14:09,  2.13s/it]predicting train subjects:  25%|██▌       | 134/532 [04:07<14:22,  2.17s/it]predicting train subjects:  25%|██▌       | 135/532 [04:09<14:32,  2.20s/it]predicting train subjects:  26%|██▌       | 136/532 [04:11<14:38,  2.22s/it]predicting train subjects:  26%|██▌       | 137/532 [04:13<14:36,  2.22s/it]predicting train subjects:  26%|██▌       | 138/532 [04:16<14:37,  2.23s/it]predicting train subjects:  26%|██▌       | 139/532 [04:18<14:34,  2.22s/it]predicting train subjects:  26%|██▋       | 140/532 [04:20<14:33,  2.23s/it]predicting train subjects:  27%|██▋       | 141/532 [04:22<14:31,  2.23s/it]predicting train subjects:  27%|██▋       | 142/532 [04:24<14:31,  2.24s/it]predicting train subjects:  27%|██▋       | 143/532 [04:26<13:27,  2.07s/it]predicting train subjects:  27%|██▋       | 144/532 [04:28<12:38,  1.95s/it]predicting train subjects:  27%|██▋       | 145/532 [04:29<12:03,  1.87s/it]predicting train subjects:  27%|██▋       | 146/532 [04:31<11:36,  1.81s/it]predicting train subjects:  28%|██▊       | 147/532 [04:33<11:16,  1.76s/it]predicting train subjects:  28%|██▊       | 148/532 [04:34<11:02,  1.73s/it]predicting train subjects:  28%|██▊       | 149/532 [04:36<11:06,  1.74s/it]predicting train subjects:  28%|██▊       | 150/532 [04:38<11:07,  1.75s/it]predicting train subjects:  28%|██▊       | 151/532 [04:40<11:13,  1.77s/it]predicting train subjects:  29%|██▊       | 152/532 [04:42<11:11,  1.77s/it]predicting train subjects:  29%|██▉       | 153/532 [04:43<11:09,  1.77s/it]predicting train subjects:  29%|██▉       | 154/532 [04:45<11:07,  1.77s/it]predicting train subjects:  29%|██▉       | 155/532 [04:47<12:14,  1.95s/it]predicting train subjects:  29%|██▉       | 156/532 [04:50<12:59,  2.07s/it]predicting train subjects:  30%|██▉       | 157/532 [04:52<13:40,  2.19s/it]predicting train subjects:  30%|██▉       | 158/532 [04:55<14:04,  2.26s/it]predicting train subjects:  30%|██▉       | 159/532 [04:57<14:10,  2.28s/it]predicting train subjects:  30%|███       | 160/532 [04:59<14:27,  2.33s/it]predicting train subjects:  30%|███       | 161/532 [05:01<13:20,  2.16s/it]predicting train subjects:  30%|███       | 162/532 [05:03<12:30,  2.03s/it]predicting train subjects:  31%|███       | 163/532 [05:05<11:53,  1.93s/it]predicting train subjects:  31%|███       | 164/532 [05:06<11:27,  1.87s/it]predicting train subjects:  31%|███       | 165/532 [05:08<11:12,  1.83s/it]predicting train subjects:  31%|███       | 166/532 [05:10<11:03,  1.81s/it]predicting train subjects:  31%|███▏      | 167/532 [05:12<11:11,  1.84s/it]predicting train subjects:  32%|███▏      | 168/532 [05:14<11:09,  1.84s/it]predicting train subjects:  32%|███▏      | 169/532 [05:15<10:59,  1.82s/it]predicting train subjects:  32%|███▏      | 170/532 [05:17<10:58,  1.82s/it]predicting train subjects:  32%|███▏      | 171/532 [05:19<11:00,  1.83s/it]predicting train subjects:  32%|███▏      | 172/532 [05:21<10:52,  1.81s/it]predicting train subjects:  33%|███▎      | 173/532 [05:23<10:32,  1.76s/it]predicting train subjects:  33%|███▎      | 174/532 [05:24<10:25,  1.75s/it]predicting train subjects:  33%|███▎      | 175/532 [05:26<10:14,  1.72s/it]predicting train subjects:  33%|███▎      | 176/532 [05:28<10:07,  1.71s/it]predicting train subjects:  33%|███▎      | 177/532 [05:29<10:09,  1.72s/it]predicting train subjects:  33%|███▎      | 178/532 [05:31<10:05,  1.71s/it]predicting train subjects:  34%|███▎      | 179/532 [05:33<10:09,  1.73s/it]predicting train subjects:  34%|███▍      | 180/532 [05:34<10:07,  1.73s/it]predicting train subjects:  34%|███▍      | 181/532 [05:36<10:03,  1.72s/it]predicting train subjects:  34%|███▍      | 182/532 [05:38<10:06,  1.73s/it]predicting train subjects:  34%|███▍      | 183/532 [05:40<10:05,  1.73s/it]predicting train subjects:  35%|███▍      | 184/532 [05:41<10:08,  1.75s/it]predicting train subjects:  35%|███▍      | 185/532 [05:43<09:50,  1.70s/it]predicting train subjects:  35%|███▍      | 186/532 [05:45<09:33,  1.66s/it]predicting train subjects:  35%|███▌      | 187/532 [05:46<09:35,  1.67s/it]predicting train subjects:  35%|███▌      | 188/532 [05:48<09:30,  1.66s/it]predicting train subjects:  36%|███▌      | 189/532 [05:50<09:23,  1.64s/it]predicting train subjects:  36%|███▌      | 190/532 [05:51<09:19,  1.63s/it]predicting train subjects:  36%|███▌      | 191/532 [05:53<10:27,  1.84s/it]predicting train subjects:  36%|███▌      | 192/532 [05:56<11:25,  2.02s/it]predicting train subjects:  36%|███▋      | 193/532 [05:58<11:49,  2.09s/it]predicting train subjects:  36%|███▋      | 194/532 [06:01<12:15,  2.18s/it]predicting train subjects:  37%|███▋      | 195/532 [06:03<12:34,  2.24s/it]predicting train subjects:  37%|███▋      | 196/532 [06:05<12:52,  2.30s/it]predicting train subjects:  37%|███▋      | 197/532 [06:07<12:15,  2.20s/it]predicting train subjects:  37%|███▋      | 198/532 [06:09<11:50,  2.13s/it]predicting train subjects:  37%|███▋      | 199/532 [06:11<11:36,  2.09s/it]predicting train subjects:  38%|███▊      | 200/532 [06:13<11:30,  2.08s/it]predicting train subjects:  38%|███▊      | 201/532 [06:15<11:30,  2.09s/it]predicting train subjects:  38%|███▊      | 202/532 [06:18<11:27,  2.08s/it]predicting train subjects:  38%|███▊      | 203/532 [06:19<10:49,  1.97s/it]predicting train subjects:  38%|███▊      | 204/532 [06:21<10:24,  1.90s/it]predicting train subjects:  39%|███▊      | 205/532 [06:23<10:01,  1.84s/it]predicting train subjects:  39%|███▊      | 206/532 [06:24<09:47,  1.80s/it]predicting train subjects:  39%|███▉      | 207/532 [06:26<09:41,  1.79s/it]predicting train subjects:  39%|███▉      | 208/532 [06:28<09:31,  1.76s/it]predicting train subjects:  39%|███▉      | 209/532 [06:29<09:06,  1.69s/it]predicting train subjects:  39%|███▉      | 210/532 [06:31<08:50,  1.65s/it]predicting train subjects:  40%|███▉      | 211/532 [06:32<08:34,  1.60s/it]predicting train subjects:  40%|███▉      | 212/532 [06:34<08:25,  1.58s/it]predicting train subjects:  40%|████      | 213/532 [06:35<08:17,  1.56s/it]predicting train subjects:  40%|████      | 214/532 [06:37<08:11,  1.55s/it]predicting train subjects:  40%|████      | 215/532 [06:39<09:16,  1.76s/it]predicting train subjects:  41%|████      | 216/532 [06:41<09:58,  1.89s/it]predicting train subjects:  41%|████      | 217/532 [06:44<10:29,  2.00s/it]predicting train subjects:  41%|████      | 218/532 [06:46<11:24,  2.18s/it]predicting train subjects:  41%|████      | 219/532 [06:48<11:21,  2.18s/it]predicting train subjects:  41%|████▏     | 220/532 [06:51<11:24,  2.19s/it]predicting train subjects:  42%|████▏     | 221/532 [06:52<10:20,  1.99s/it]predicting train subjects:  42%|████▏     | 222/532 [06:54<09:32,  1.85s/it]predicting train subjects:  42%|████▏     | 223/532 [06:55<09:04,  1.76s/it]predicting train subjects:  42%|████▏     | 224/532 [06:57<08:43,  1.70s/it]predicting train subjects:  42%|████▏     | 225/532 [06:58<08:19,  1.63s/it]predicting train subjects:  42%|████▏     | 226/532 [07:00<07:59,  1.57s/it]predicting train subjects:  43%|████▎     | 227/532 [07:01<07:42,  1.52s/it]predicting train subjects:  43%|████▎     | 228/532 [07:03<07:30,  1.48s/it]predicting train subjects:  43%|████▎     | 229/532 [07:04<07:14,  1.43s/it]predicting train subjects:  43%|████▎     | 230/532 [07:05<06:58,  1.38s/it]predicting train subjects:  43%|████▎     | 231/532 [07:07<06:55,  1.38s/it]predicting train subjects:  44%|████▎     | 232/532 [07:08<06:47,  1.36s/it]predicting train subjects:  44%|████▍     | 233/532 [07:09<07:06,  1.43s/it]predicting train subjects:  44%|████▍     | 234/532 [07:11<07:24,  1.49s/it]predicting train subjects:  44%|████▍     | 235/532 [07:13<07:38,  1.54s/it]predicting train subjects:  44%|████▍     | 236/532 [07:14<07:39,  1.55s/it]predicting train subjects:  45%|████▍     | 237/532 [07:16<07:40,  1.56s/it]predicting train subjects:  45%|████▍     | 238/532 [07:17<07:43,  1.58s/it]predicting train subjects:  45%|████▍     | 239/532 [07:19<07:58,  1.63s/it]predicting train subjects:  45%|████▌     | 240/532 [07:21<08:08,  1.67s/it]predicting train subjects:  45%|████▌     | 241/532 [07:23<08:08,  1.68s/it]predicting train subjects:  45%|████▌     | 242/532 [07:24<08:05,  1.68s/it]predicting train subjects:  46%|████▌     | 243/532 [07:26<08:12,  1.70s/it]predicting train subjects:  46%|████▌     | 244/532 [07:28<08:10,  1.70s/it]predicting train subjects:  46%|████▌     | 245/532 [07:29<07:43,  1.61s/it]predicting train subjects:  46%|████▌     | 246/532 [07:31<07:22,  1.55s/it]predicting train subjects:  46%|████▋     | 247/532 [07:32<07:03,  1.49s/it]predicting train subjects:  47%|████▋     | 248/532 [07:33<06:54,  1.46s/it]predicting train subjects:  47%|████▋     | 249/532 [07:35<06:41,  1.42s/it]predicting train subjects:  47%|████▋     | 250/532 [07:36<06:40,  1.42s/it]predicting train subjects:  47%|████▋     | 251/532 [07:38<06:44,  1.44s/it]predicting train subjects:  47%|████▋     | 252/532 [07:39<06:48,  1.46s/it]predicting train subjects:  48%|████▊     | 253/532 [07:41<06:50,  1.47s/it]predicting train subjects:  48%|████▊     | 254/532 [07:42<06:47,  1.47s/it]predicting train subjects:  48%|████▊     | 255/532 [07:44<06:45,  1.46s/it]predicting train subjects:  48%|████▊     | 256/532 [07:45<06:45,  1.47s/it]predicting train subjects:  48%|████▊     | 257/532 [07:47<07:16,  1.59s/it]predicting train subjects:  48%|████▊     | 258/532 [07:49<07:42,  1.69s/it]predicting train subjects:  49%|████▊     | 259/532 [07:51<08:02,  1.77s/it]predicting train subjects:  49%|████▉     | 260/532 [07:53<08:12,  1.81s/it]predicting train subjects:  49%|████▉     | 261/532 [07:55<08:15,  1.83s/it]predicting train subjects:  49%|████▉     | 262/532 [07:56<08:17,  1.84s/it]predicting train subjects:  49%|████▉     | 263/532 [07:58<07:41,  1.72s/it]predicting train subjects:  50%|████▉     | 264/532 [07:59<07:14,  1.62s/it]predicting train subjects:  50%|████▉     | 265/532 [08:01<06:53,  1.55s/it]predicting train subjects:  50%|█████     | 266/532 [08:02<06:38,  1.50s/it]predicting train subjects:  50%|█████     | 267/532 [08:03<06:31,  1.48s/it]predicting train subjects:  50%|█████     | 268/532 [08:05<06:21,  1.44s/it]predicting train subjects:  51%|█████     | 269/532 [08:07<06:46,  1.54s/it]predicting train subjects:  51%|█████     | 270/532 [08:08<07:03,  1.62s/it]predicting train subjects:  51%|█████     | 271/532 [08:10<07:04,  1.63s/it]predicting train subjects:  51%|█████     | 272/532 [08:12<07:06,  1.64s/it]predicting train subjects:  51%|█████▏    | 273/532 [08:13<07:11,  1.66s/it]predicting train subjects:  52%|█████▏    | 274/532 [08:15<07:14,  1.68s/it]predicting train subjects:  52%|█████▏    | 275/532 [08:17<07:37,  1.78s/it]predicting train subjects:  52%|█████▏    | 276/532 [08:19<07:58,  1.87s/it]predicting train subjects:  52%|█████▏    | 277/532 [08:21<08:13,  1.93s/it]predicting train subjects:  52%|█████▏    | 278/532 [08:23<08:19,  1.97s/it]predicting train subjects:  52%|█████▏    | 279/532 [08:25<08:30,  2.02s/it]predicting train subjects:  53%|█████▎    | 280/532 [08:28<08:32,  2.03s/it]predicting train subjects:  53%|█████▎    | 281/532 [08:30<08:26,  2.02s/it]predicting train subjects:  53%|█████▎    | 282/532 [08:32<08:24,  2.02s/it]predicting train subjects:  53%|█████▎    | 283/532 [08:34<08:22,  2.02s/it]predicting train subjects:  53%|█████▎    | 284/532 [08:36<08:22,  2.03s/it]predicting train subjects:  54%|█████▎    | 285/532 [08:38<08:23,  2.04s/it]predicting train subjects:  54%|█████▍    | 286/532 [08:40<08:26,  2.06s/it]predicting train subjects:  54%|█████▍    | 287/532 [08:41<07:49,  1.92s/it]predicting train subjects:  54%|█████▍    | 288/532 [08:43<07:28,  1.84s/it]predicting train subjects:  54%|█████▍    | 289/532 [08:45<07:03,  1.74s/it]predicting train subjects:  55%|█████▍    | 290/532 [08:46<06:45,  1.67s/it]predicting train subjects:  55%|█████▍    | 291/532 [08:48<06:32,  1.63s/it]predicting train subjects:  55%|█████▍    | 292/532 [08:49<06:30,  1.63s/it]predicting train subjects:  55%|█████▌    | 293/532 [08:51<06:36,  1.66s/it]predicting train subjects:  55%|█████▌    | 294/532 [08:53<06:38,  1.67s/it]predicting train subjects:  55%|█████▌    | 295/532 [08:54<06:40,  1.69s/it]predicting train subjects:  56%|█████▌    | 296/532 [08:56<06:55,  1.76s/it]predicting train subjects:  56%|█████▌    | 297/532 [08:58<06:53,  1.76s/it]predicting train subjects:  56%|█████▌    | 298/532 [09:00<06:51,  1.76s/it]predicting train subjects:  56%|█████▌    | 299/532 [09:01<06:25,  1.65s/it]predicting train subjects:  56%|█████▋    | 300/532 [09:03<06:08,  1.59s/it]predicting train subjects:  57%|█████▋    | 301/532 [09:04<05:51,  1.52s/it]predicting train subjects:  57%|█████▋    | 302/532 [09:05<05:42,  1.49s/it]predicting train subjects:  57%|█████▋    | 303/532 [09:07<05:36,  1.47s/it]predicting train subjects:  57%|█████▋    | 304/532 [09:08<05:33,  1.46s/it]predicting train subjects:  57%|█████▋    | 305/532 [09:10<06:16,  1.66s/it]predicting train subjects:  58%|█████▊    | 306/532 [09:13<06:44,  1.79s/it]predicting train subjects:  58%|█████▊    | 307/532 [09:15<07:03,  1.88s/it]predicting train subjects:  58%|█████▊    | 308/532 [09:17<07:11,  1.93s/it]predicting train subjects:  58%|█████▊    | 309/532 [09:19<07:17,  1.96s/it]predicting train subjects:  58%|█████▊    | 310/532 [09:21<07:20,  1.99s/it]predicting train subjects:  58%|█████▊    | 311/532 [09:24<08:17,  2.25s/it]predicting train subjects:  59%|█████▊    | 312/532 [09:26<08:54,  2.43s/it]predicting train subjects:  59%|█████▉    | 313/532 [09:29<09:25,  2.58s/it]predicting train subjects:  59%|█████▉    | 314/532 [09:32<09:37,  2.65s/it]predicting train subjects:  59%|█████▉    | 315/532 [09:35<09:53,  2.73s/it]predicting train subjects:  59%|█████▉    | 316/532 [09:38<09:58,  2.77s/it]predicting train subjects:  60%|█████▉    | 317/532 [09:40<08:47,  2.45s/it]predicting train subjects:  60%|█████▉    | 318/532 [09:41<07:53,  2.21s/it]predicting train subjects:  60%|█████▉    | 319/532 [09:43<07:10,  2.02s/it]predicting train subjects:  60%|██████    | 320/532 [09:44<06:37,  1.88s/it]predicting train subjects:  60%|██████    | 321/532 [09:46<06:15,  1.78s/it]predicting train subjects:  61%|██████    | 322/532 [09:48<06:00,  1.72s/it]predicting train subjects:  61%|██████    | 323/532 [09:50<06:31,  1.87s/it]predicting train subjects:  61%|██████    | 324/532 [09:52<06:51,  1.98s/it]predicting train subjects:  61%|██████    | 325/532 [09:54<07:00,  2.03s/it]predicting train subjects:  61%|██████▏   | 326/532 [09:56<07:14,  2.11s/it]predicting train subjects:  61%|██████▏   | 327/532 [09:59<07:25,  2.17s/it]predicting train subjects:  62%|██████▏   | 328/532 [10:01<07:24,  2.18s/it]predicting train subjects:  62%|██████▏   | 329/532 [10:03<06:46,  2.00s/it]predicting train subjects:  62%|██████▏   | 330/532 [10:04<06:16,  1.86s/it]predicting train subjects:  62%|██████▏   | 331/532 [10:06<06:02,  1.80s/it]predicting train subjects:  62%|██████▏   | 332/532 [10:07<05:50,  1.75s/it]predicting train subjects:  63%|██████▎   | 333/532 [10:09<05:41,  1.72s/it]predicting train subjects:  63%|██████▎   | 334/532 [10:11<05:33,  1.69s/it]predicting train subjects:  63%|██████▎   | 335/532 [10:13<05:50,  1.78s/it]predicting train subjects:  63%|██████▎   | 336/532 [10:15<06:01,  1.84s/it]predicting train subjects:  63%|██████▎   | 337/532 [10:17<06:10,  1.90s/it]predicting train subjects:  64%|██████▎   | 338/532 [10:19<06:14,  1.93s/it]predicting train subjects:  64%|██████▎   | 339/532 [10:21<06:12,  1.93s/it]predicting train subjects:  64%|██████▍   | 340/532 [10:23<06:14,  1.95s/it]predicting train subjects:  64%|██████▍   | 341/532 [10:24<05:46,  1.82s/it]predicting train subjects:  64%|██████▍   | 342/532 [10:26<05:25,  1.71s/it]predicting train subjects:  64%|██████▍   | 343/532 [10:27<05:08,  1.63s/it]predicting train subjects:  65%|██████▍   | 344/532 [10:29<04:58,  1.59s/it]predicting train subjects:  65%|██████▍   | 345/532 [10:30<04:50,  1.56s/it]predicting train subjects:  65%|██████▌   | 346/532 [10:31<04:45,  1.53s/it]predicting train subjects:  65%|██████▌   | 347/532 [10:33<04:50,  1.57s/it]predicting train subjects:  65%|██████▌   | 348/532 [10:35<04:55,  1.61s/it]predicting train subjects:  66%|██████▌   | 349/532 [10:37<05:02,  1.65s/it]predicting train subjects:  66%|██████▌   | 350/532 [10:38<05:02,  1.66s/it]predicting train subjects:  66%|██████▌   | 351/532 [10:40<05:03,  1.68s/it]predicting train subjects:  66%|██████▌   | 352/532 [10:42<05:05,  1.70s/it]predicting train subjects:  66%|██████▋   | 353/532 [10:43<04:59,  1.67s/it]predicting train subjects:  67%|██████▋   | 354/532 [10:45<04:54,  1.66s/it]predicting train subjects:  67%|██████▋   | 355/532 [10:47<04:49,  1.64s/it]predicting train subjects:  67%|██████▋   | 356/532 [10:48<04:48,  1.64s/it]predicting train subjects:  67%|██████▋   | 357/532 [10:50<04:51,  1.66s/it]predicting train subjects:  67%|██████▋   | 358/532 [10:52<04:52,  1.68s/it]predicting train subjects:  67%|██████▋   | 359/532 [10:53<04:40,  1.62s/it]predicting train subjects:  68%|██████▊   | 360/532 [10:55<04:35,  1.60s/it]predicting train subjects:  68%|██████▊   | 361/532 [10:56<04:26,  1.56s/it]predicting train subjects:  68%|██████▊   | 362/532 [10:58<04:20,  1.53s/it]predicting train subjects:  68%|██████▊   | 363/532 [10:59<04:16,  1.52s/it]predicting train subjects:  68%|██████▊   | 364/532 [11:01<04:11,  1.50s/it]predicting train subjects:  69%|██████▊   | 365/532 [11:02<04:08,  1.49s/it]predicting train subjects:  69%|██████▉   | 366/532 [11:03<04:07,  1.49s/it]predicting train subjects:  69%|██████▉   | 367/532 [11:05<04:08,  1.50s/it]predicting train subjects:  69%|██████▉   | 368/532 [11:07<04:07,  1.51s/it]predicting train subjects:  69%|██████▉   | 369/532 [11:08<04:06,  1.51s/it]predicting train subjects:  70%|██████▉   | 370/532 [11:10<04:02,  1.50s/it]predicting train subjects:  70%|██████▉   | 371/532 [11:12<04:28,  1.67s/it]predicting train subjects:  70%|██████▉   | 372/532 [11:14<04:49,  1.81s/it]predicting train subjects:  70%|███████   | 373/532 [11:16<05:01,  1.90s/it]predicting train subjects:  70%|███████   | 374/532 [11:18<05:08,  1.95s/it]predicting train subjects:  70%|███████   | 375/532 [11:20<05:11,  1.99s/it]predicting train subjects:  71%|███████   | 376/532 [11:22<05:14,  2.02s/it]predicting train subjects:  71%|███████   | 377/532 [11:24<04:57,  1.92s/it]predicting train subjects:  71%|███████   | 378/532 [11:25<04:42,  1.84s/it]predicting train subjects:  71%|███████   | 379/532 [11:27<04:30,  1.77s/it]predicting train subjects:  71%|███████▏  | 380/532 [11:29<04:23,  1.73s/it]predicting train subjects:  72%|███████▏  | 381/532 [11:30<04:18,  1.71s/it]predicting train subjects:  72%|███████▏  | 382/532 [11:32<04:15,  1.70s/it]predicting train subjects:  72%|███████▏  | 383/532 [11:34<04:17,  1.73s/it]predicting train subjects:  72%|███████▏  | 384/532 [11:36<04:16,  1.73s/it]predicting train subjects:  72%|███████▏  | 385/532 [11:37<04:18,  1.76s/it]predicting train subjects:  73%|███████▎  | 386/532 [11:39<04:19,  1.78s/it]predicting train subjects:  73%|███████▎  | 387/532 [11:41<04:20,  1.80s/it]predicting train subjects:  73%|███████▎  | 388/532 [11:43<04:15,  1.77s/it]predicting train subjects:  73%|███████▎  | 389/532 [11:45<04:13,  1.77s/it]predicting train subjects:  73%|███████▎  | 390/532 [11:46<04:11,  1.77s/it]predicting train subjects:  73%|███████▎  | 391/532 [11:48<04:08,  1.76s/it]predicting train subjects:  74%|███████▎  | 392/532 [11:50<04:09,  1.78s/it]predicting train subjects:  74%|███████▍  | 393/532 [11:52<04:09,  1.80s/it]predicting train subjects:  74%|███████▍  | 394/532 [11:53<04:05,  1.78s/it]predicting train subjects:  74%|███████▍  | 395/532 [11:55<04:02,  1.77s/it]predicting train subjects:  74%|███████▍  | 396/532 [11:57<04:01,  1.77s/it]predicting train subjects:  75%|███████▍  | 397/532 [11:59<03:59,  1.77s/it]predicting train subjects:  75%|███████▍  | 398/532 [12:00<03:55,  1.76s/it]predicting train subjects:  75%|███████▌  | 399/532 [12:02<03:52,  1.75s/it]predicting train subjects:  75%|███████▌  | 400/532 [12:04<03:50,  1.75s/it]predicting train subjects:  75%|███████▌  | 401/532 [12:06<03:56,  1.80s/it]predicting train subjects:  76%|███████▌  | 402/532 [12:08<03:55,  1.81s/it]predicting train subjects:  76%|███████▌  | 403/532 [12:10<04:02,  1.88s/it]predicting train subjects:  76%|███████▌  | 404/532 [12:12<04:03,  1.90s/it]predicting train subjects:  76%|███████▌  | 405/532 [12:14<04:02,  1.91s/it]predicting train subjects:  76%|███████▋  | 406/532 [12:16<04:03,  1.93s/it]predicting train subjects:  77%|███████▋  | 407/532 [12:17<03:57,  1.90s/it]predicting train subjects:  77%|███████▋  | 408/532 [12:19<03:49,  1.85s/it]predicting train subjects:  77%|███████▋  | 409/532 [12:21<03:41,  1.80s/it]predicting train subjects:  77%|███████▋  | 410/532 [12:23<03:35,  1.76s/it]predicting train subjects:  77%|███████▋  | 411/532 [12:24<03:32,  1.75s/it]predicting train subjects:  77%|███████▋  | 412/532 [12:26<03:28,  1.73s/it]predicting train subjects:  78%|███████▊  | 413/532 [12:28<03:24,  1.72s/it]predicting train subjects:  78%|███████▊  | 414/532 [12:29<03:18,  1.68s/it]predicting train subjects:  78%|███████▊  | 415/532 [12:31<03:12,  1.64s/it]predicting train subjects:  78%|███████▊  | 416/532 [12:32<03:08,  1.63s/it]predicting train subjects:  78%|███████▊  | 417/532 [12:34<03:04,  1.61s/it]predicting train subjects:  79%|███████▊  | 418/532 [12:36<03:03,  1.61s/it]predicting train subjects:  79%|███████▉  | 419/532 [12:37<03:08,  1.67s/it]predicting train subjects:  79%|███████▉  | 420/532 [12:39<03:12,  1.72s/it]predicting train subjects:  79%|███████▉  | 421/532 [12:41<03:16,  1.77s/it]predicting train subjects:  79%|███████▉  | 422/532 [12:43<03:18,  1.81s/it]predicting train subjects:  80%|███████▉  | 423/532 [12:45<03:16,  1.80s/it]predicting train subjects:  80%|███████▉  | 424/532 [12:47<03:14,  1.80s/it]predicting train subjects:  80%|███████▉  | 425/532 [12:48<03:12,  1.80s/it]predicting train subjects:  80%|████████  | 426/532 [12:50<03:10,  1.80s/it]predicting train subjects:  80%|████████  | 427/532 [12:52<03:09,  1.80s/it]predicting train subjects:  80%|████████  | 428/532 [12:54<03:03,  1.76s/it]predicting train subjects:  81%|████████  | 429/532 [12:55<02:59,  1.75s/it]predicting train subjects:  81%|████████  | 430/532 [12:57<03:00,  1.77s/it]predicting train subjects:  81%|████████  | 431/532 [12:59<03:05,  1.84s/it]predicting train subjects:  81%|████████  | 432/532 [13:01<03:07,  1.88s/it]predicting train subjects:  81%|████████▏ | 433/532 [13:03<03:09,  1.92s/it]predicting train subjects:  82%|████████▏ | 434/532 [13:05<03:11,  1.95s/it]predicting train subjects:  82%|████████▏ | 435/532 [13:07<03:12,  1.99s/it]predicting train subjects:  82%|████████▏ | 436/532 [13:09<03:10,  1.98s/it]predicting train subjects:  82%|████████▏ | 437/532 [13:11<02:53,  1.83s/it]predicting train subjects:  82%|████████▏ | 438/532 [13:12<02:41,  1.72s/it]predicting train subjects:  83%|████████▎ | 439/532 [13:14<02:31,  1.63s/it]predicting train subjects:  83%|████████▎ | 440/532 [13:15<02:28,  1.61s/it]predicting train subjects:  83%|████████▎ | 441/532 [13:17<02:24,  1.59s/it]predicting train subjects:  83%|████████▎ | 442/532 [13:18<02:20,  1.56s/it]predicting train subjects:  83%|████████▎ | 443/532 [13:20<02:16,  1.54s/it]predicting train subjects:  83%|████████▎ | 444/532 [13:21<02:11,  1.50s/it]predicting train subjects:  84%|████████▎ | 445/532 [13:22<02:08,  1.47s/it]predicting train subjects:  84%|████████▍ | 446/532 [13:24<02:04,  1.45s/it]predicting train subjects:  84%|████████▍ | 447/532 [13:25<02:03,  1.45s/it]predicting train subjects:  84%|████████▍ | 448/532 [13:27<01:59,  1.43s/it]predicting train subjects:  84%|████████▍ | 449/532 [13:28<02:02,  1.47s/it]predicting train subjects:  85%|████████▍ | 450/532 [13:30<02:03,  1.50s/it]predicting train subjects:  85%|████████▍ | 451/532 [13:31<02:02,  1.51s/it]predicting train subjects:  85%|████████▍ | 452/532 [13:33<02:02,  1.53s/it]predicting train subjects:  85%|████████▌ | 453/532 [13:34<02:01,  1.54s/it]predicting train subjects:  85%|████████▌ | 454/532 [13:36<02:01,  1.56s/it]predicting train subjects:  86%|████████▌ | 455/532 [13:38<02:05,  1.63s/it]predicting train subjects:  86%|████████▌ | 456/532 [13:40<02:09,  1.70s/it]predicting train subjects:  86%|████████▌ | 457/532 [13:42<02:09,  1.72s/it]predicting train subjects:  86%|████████▌ | 458/532 [13:43<02:10,  1.76s/it]predicting train subjects:  86%|████████▋ | 459/532 [13:45<02:09,  1.78s/it]predicting train subjects:  86%|████████▋ | 460/532 [13:47<02:11,  1.82s/it]predicting train subjects:  87%|████████▋ | 461/532 [13:49<02:15,  1.91s/it]predicting train subjects:  87%|████████▋ | 462/532 [13:51<02:18,  1.98s/it]predicting train subjects:  87%|████████▋ | 463/532 [13:53<02:17,  1.99s/it]predicting train subjects:  87%|████████▋ | 464/532 [13:55<02:16,  2.01s/it]predicting train subjects:  87%|████████▋ | 465/532 [13:57<02:14,  2.01s/it]predicting train subjects:  88%|████████▊ | 466/532 [14:00<02:15,  2.05s/it]predicting train subjects:  88%|████████▊ | 467/532 [14:01<02:06,  1.95s/it]predicting train subjects:  88%|████████▊ | 468/532 [14:03<01:59,  1.86s/it]predicting train subjects:  88%|████████▊ | 469/532 [14:05<01:53,  1.81s/it]predicting train subjects:  88%|████████▊ | 470/532 [14:06<01:50,  1.78s/it]predicting train subjects:  89%|████████▊ | 471/532 [14:08<01:46,  1.74s/it]predicting train subjects:  89%|████████▊ | 472/532 [14:10<01:42,  1.71s/it]predicting train subjects:  89%|████████▉ | 473/532 [14:12<01:43,  1.75s/it]predicting train subjects:  89%|████████▉ | 474/532 [14:13<01:44,  1.79s/it]predicting train subjects:  89%|████████▉ | 475/532 [14:15<01:42,  1.80s/it]predicting train subjects:  89%|████████▉ | 476/532 [14:17<01:41,  1.81s/it]predicting train subjects:  90%|████████▉ | 477/532 [14:19<01:41,  1.84s/it]predicting train subjects:  90%|████████▉ | 478/532 [14:21<01:39,  1.84s/it]predicting train subjects:  90%|█████████ | 479/532 [14:22<01:33,  1.76s/it]predicting train subjects:  90%|█████████ | 480/532 [14:24<01:29,  1.72s/it]predicting train subjects:  90%|█████████ | 481/532 [14:26<01:26,  1.69s/it]predicting train subjects:  91%|█████████ | 482/532 [14:27<01:22,  1.65s/it]predicting train subjects:  91%|█████████ | 483/532 [14:29<01:19,  1.62s/it]predicting train subjects:  91%|█████████ | 484/532 [14:30<01:16,  1.60s/it]predicting train subjects:  91%|█████████ | 485/532 [14:32<01:20,  1.72s/it]predicting train subjects:  91%|█████████▏| 486/532 [14:34<01:22,  1.80s/it]predicting train subjects:  92%|█████████▏| 487/532 [14:36<01:24,  1.88s/it]predicting train subjects:  92%|█████████▏| 488/532 [14:38<01:24,  1.92s/it]predicting train subjects:  92%|█████████▏| 489/532 [14:40<01:22,  1.93s/it]predicting train subjects:  92%|█████████▏| 490/532 [14:42<01:21,  1.95s/it]predicting train subjects:  92%|█████████▏| 491/532 [14:44<01:17,  1.90s/it]predicting train subjects:  92%|█████████▏| 492/532 [14:46<01:14,  1.85s/it]predicting train subjects:  93%|█████████▎| 493/532 [14:48<01:12,  1.85s/it]predicting train subjects:  93%|█████████▎| 494/532 [14:49<01:07,  1.79s/it]predicting train subjects:  93%|█████████▎| 495/532 [14:51<01:05,  1.77s/it]predicting train subjects:  93%|█████████▎| 496/532 [14:53<01:01,  1.71s/it]predicting train subjects:  93%|█████████▎| 497/532 [14:54<00:59,  1.70s/it]predicting train subjects:  94%|█████████▎| 498/532 [14:56<00:57,  1.69s/it]predicting train subjects:  94%|█████████▍| 499/532 [14:58<00:56,  1.70s/it]predicting train subjects:  94%|█████████▍| 500/532 [14:59<00:54,  1.70s/it]predicting train subjects:  94%|█████████▍| 501/532 [15:01<00:53,  1.74s/it]predicting train subjects:  94%|█████████▍| 502/532 [15:03<00:51,  1.72s/it]predicting train subjects:  95%|█████████▍| 503/532 [15:05<00:49,  1.70s/it]predicting train subjects:  95%|█████████▍| 504/532 [15:06<00:46,  1.67s/it]predicting train subjects:  95%|█████████▍| 505/532 [15:08<00:43,  1.62s/it]predicting train subjects:  95%|█████████▌| 506/532 [15:09<00:41,  1.60s/it]predicting train subjects:  95%|█████████▌| 507/532 [15:11<00:39,  1.60s/it]predicting train subjects:  95%|█████████▌| 508/532 [15:12<00:38,  1.59s/it]predicting train subjects:  96%|█████████▌| 509/532 [15:14<00:39,  1.73s/it]predicting train subjects:  96%|█████████▌| 510/532 [15:16<00:39,  1.81s/it]predicting train subjects:  96%|█████████▌| 511/532 [15:18<00:38,  1.85s/it]predicting train subjects:  96%|█████████▌| 512/532 [15:20<00:37,  1.88s/it]predicting train subjects:  96%|█████████▋| 513/532 [15:22<00:36,  1.91s/it]predicting train subjects:  97%|█████████▋| 514/532 [15:24<00:35,  1.96s/it]predicting train subjects:  97%|█████████▋| 515/532 [15:26<00:31,  1.87s/it]predicting train subjects:  97%|█████████▋| 516/532 [15:28<00:28,  1.81s/it]predicting train subjects:  97%|█████████▋| 517/532 [15:29<00:26,  1.77s/it]predicting train subjects:  97%|█████████▋| 518/532 [15:31<00:24,  1.74s/it]predicting train subjects:  98%|█████████▊| 519/532 [15:33<00:22,  1.71s/it]predicting train subjects:  98%|█████████▊| 520/532 [15:34<00:20,  1.70s/it]predicting train subjects:  98%|█████████▊| 521/532 [15:36<00:19,  1.75s/it]predicting train subjects:  98%|█████████▊| 522/532 [15:38<00:17,  1.75s/it]predicting train subjects:  98%|█████████▊| 523/532 [15:40<00:15,  1.77s/it]predicting train subjects:  98%|█████████▊| 524/532 [15:42<00:14,  1.76s/it]predicting train subjects:  99%|█████████▊| 525/532 [15:43<00:12,  1.80s/it]predicting train subjects:  99%|█████████▉| 526/532 [15:45<00:10,  1.80s/it]predicting train subjects:  99%|█████████▉| 527/532 [15:47<00:08,  1.75s/it]predicting train subjects:  99%|█████████▉| 528/532 [15:48<00:06,  1.70s/it]predicting train subjects:  99%|█████████▉| 529/532 [15:50<00:05,  1.68s/it]predicting train subjects: 100%|█████████▉| 530/532 [15:52<00:03,  1.64s/it]predicting train subjects: 100%|█████████▉| 531/532 [15:53<00:01,  1.62s/it]predicting train subjects: 100%|██████████| 532/532 [15:55<00:00,  1.63s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1’: File exists

Loading train:   0%|          | 0/532 [00:00<?, ?it/s]Loading train:   0%|          | 1/532 [00:01<12:47,  1.45s/it]Loading train:   0%|          | 2/532 [00:02<11:47,  1.33s/it]Loading train:   1%|          | 3/532 [00:03<11:37,  1.32s/it]Loading train:   1%|          | 4/532 [00:04<11:09,  1.27s/it]Loading train:   1%|          | 5/532 [00:05<10:33,  1.20s/it]Loading train:   1%|          | 6/532 [00:07<10:08,  1.16s/it]Loading train:   1%|▏         | 7/532 [00:07<09:31,  1.09s/it]Loading train:   2%|▏         | 8/532 [00:08<09:16,  1.06s/it]Loading train:   2%|▏         | 9/532 [00:10<09:35,  1.10s/it]Loading train:   2%|▏         | 10/532 [00:11<09:13,  1.06s/it]Loading train:   2%|▏         | 11/532 [00:12<08:54,  1.03s/it]Loading train:   2%|▏         | 12/532 [00:13<09:34,  1.11s/it]Loading train:   2%|▏         | 13/532 [00:14<09:17,  1.07s/it]Loading train:   3%|▎         | 14/532 [00:15<08:48,  1.02s/it]Loading train:   3%|▎         | 15/532 [00:16<08:16,  1.04it/s]Loading train:   3%|▎         | 16/532 [00:17<08:49,  1.03s/it]Loading train:   3%|▎         | 17/532 [00:18<09:09,  1.07s/it]Loading train:   3%|▎         | 18/532 [00:19<09:04,  1.06s/it]Loading train:   4%|▎         | 19/532 [00:20<08:16,  1.03it/s]Loading train:   4%|▍         | 20/532 [00:21<08:35,  1.01s/it]Loading train:   4%|▍         | 21/532 [00:22<09:22,  1.10s/it]Loading train:   4%|▍         | 22/532 [00:23<08:42,  1.03s/it]Loading train:   4%|▍         | 23/532 [00:24<08:37,  1.02s/it]Loading train:   5%|▍         | 24/532 [00:25<08:18,  1.02it/s]Loading train:   5%|▍         | 25/532 [00:26<08:36,  1.02s/it]Loading train:   5%|▍         | 26/532 [00:27<08:27,  1.00s/it]Loading train:   5%|▌         | 27/532 [00:28<09:18,  1.11s/it]Loading train:   5%|▌         | 28/532 [00:29<08:55,  1.06s/it]Loading train:   5%|▌         | 29/532 [00:30<09:10,  1.09s/it]Loading train:   6%|▌         | 30/532 [00:31<09:00,  1.08s/it]Loading train:   6%|▌         | 31/532 [00:32<08:25,  1.01s/it]Loading train:   6%|▌         | 32/532 [00:33<08:20,  1.00s/it]Loading train:   6%|▌         | 33/532 [00:34<07:48,  1.06it/s]Loading train:   6%|▋         | 34/532 [00:35<08:06,  1.02it/s]Loading train:   7%|▋         | 35/532 [00:36<07:51,  1.05it/s]Loading train:   7%|▋         | 36/532 [00:37<07:59,  1.03it/s]Loading train:   7%|▋         | 37/532 [00:38<08:14,  1.00it/s]Loading train:   7%|▋         | 38/532 [00:39<08:32,  1.04s/it]Loading train:   7%|▋         | 39/532 [00:40<08:24,  1.02s/it]Loading train:   8%|▊         | 40/532 [00:41<08:01,  1.02it/s]Loading train:   8%|▊         | 41/532 [00:42<08:23,  1.03s/it]Loading train:   8%|▊         | 42/532 [00:43<08:34,  1.05s/it]Loading train:   8%|▊         | 43/532 [00:44<08:02,  1.01it/s]Loading train:   8%|▊         | 44/532 [00:45<07:30,  1.08it/s]Loading train:   8%|▊         | 45/532 [00:46<07:32,  1.08it/s]Loading train:   9%|▊         | 46/532 [00:47<07:36,  1.07it/s]Loading train:   9%|▉         | 47/532 [00:48<08:07,  1.01s/it]Loading train:   9%|▉         | 48/532 [00:49<08:24,  1.04s/it]Loading train:   9%|▉         | 49/532 [00:50<08:03,  1.00s/it]Loading train:   9%|▉         | 50/532 [00:51<08:27,  1.05s/it]Loading train:  10%|▉         | 51/532 [00:52<08:06,  1.01s/it]Loading train:  10%|▉         | 52/532 [00:53<07:59,  1.00it/s]Loading train:  10%|▉         | 53/532 [00:54<07:51,  1.02it/s]Loading train:  10%|█         | 54/532 [00:55<08:11,  1.03s/it]Loading train:  10%|█         | 55/532 [00:56<08:03,  1.01s/it]Loading train:  11%|█         | 56/532 [00:57<08:04,  1.02s/it]Loading train:  11%|█         | 57/532 [00:58<07:47,  1.02it/s]Loading train:  11%|█         | 58/532 [00:59<08:02,  1.02s/it]Loading train:  11%|█         | 59/532 [01:01<08:37,  1.09s/it]Loading train:  11%|█▏        | 60/532 [01:01<07:56,  1.01s/it]Loading train:  11%|█▏        | 61/532 [01:02<07:41,  1.02it/s]Loading train:  12%|█▏        | 62/532 [01:03<07:55,  1.01s/it]Loading train:  12%|█▏        | 63/532 [01:05<08:23,  1.07s/it]Loading train:  12%|█▏        | 64/532 [01:05<07:57,  1.02s/it]Loading train:  12%|█▏        | 65/532 [01:06<07:53,  1.01s/it]Loading train:  12%|█▏        | 66/532 [01:08<08:14,  1.06s/it]Loading train:  13%|█▎        | 67/532 [01:09<08:20,  1.08s/it]Loading train:  13%|█▎        | 68/532 [01:10<08:11,  1.06s/it]Loading train:  13%|█▎        | 69/532 [01:11<07:51,  1.02s/it]Loading train:  13%|█▎        | 70/532 [01:12<07:44,  1.01s/it]Loading train:  13%|█▎        | 71/532 [01:12<07:23,  1.04it/s]Loading train:  14%|█▎        | 72/532 [01:13<07:05,  1.08it/s]Loading train:  14%|█▎        | 73/532 [01:14<07:11,  1.06it/s]Loading train:  14%|█▍        | 74/532 [01:15<07:44,  1.01s/it]Loading train:  14%|█▍        | 75/532 [01:17<08:59,  1.18s/it]Loading train:  14%|█▍        | 76/532 [01:18<08:36,  1.13s/it]Loading train:  14%|█▍        | 77/532 [01:19<08:39,  1.14s/it]Loading train:  15%|█▍        | 78/532 [01:20<08:08,  1.08s/it]Loading train:  15%|█▍        | 79/532 [01:21<07:55,  1.05s/it]Loading train:  15%|█▌        | 80/532 [01:22<07:41,  1.02s/it]Loading train:  15%|█▌        | 81/532 [01:23<07:37,  1.02s/it]Loading train:  15%|█▌        | 82/532 [01:24<07:31,  1.00s/it]Loading train:  16%|█▌        | 83/532 [01:25<07:05,  1.06it/s]Loading train:  16%|█▌        | 84/532 [01:26<06:54,  1.08it/s]Loading train:  16%|█▌        | 85/532 [01:27<06:42,  1.11it/s]Loading train:  16%|█▌        | 86/532 [01:27<06:37,  1.12it/s]Loading train:  16%|█▋        | 87/532 [01:28<06:37,  1.12it/s]Loading train:  17%|█▋        | 88/532 [01:29<06:18,  1.17it/s]Loading train:  17%|█▋        | 89/532 [01:30<06:36,  1.12it/s]Loading train:  17%|█▋        | 90/532 [01:31<06:37,  1.11it/s]Loading train:  17%|█▋        | 91/532 [01:32<06:28,  1.14it/s]Loading train:  17%|█▋        | 92/532 [01:33<06:15,  1.17it/s]Loading train:  17%|█▋        | 93/532 [01:34<06:17,  1.16it/s]Loading train:  18%|█▊        | 94/532 [01:34<06:12,  1.18it/s]Loading train:  18%|█▊        | 95/532 [01:36<06:57,  1.05it/s]Loading train:  18%|█▊        | 96/532 [01:37<07:08,  1.02it/s]Loading train:  18%|█▊        | 97/532 [01:38<07:26,  1.03s/it]Loading train:  18%|█▊        | 98/532 [01:39<07:27,  1.03s/it]Loading train:  19%|█▊        | 99/532 [01:40<07:26,  1.03s/it]Loading train:  19%|█▉        | 100/532 [01:41<07:37,  1.06s/it]Loading train:  19%|█▉        | 101/532 [01:42<07:22,  1.03s/it]Loading train:  19%|█▉        | 102/532 [01:43<06:47,  1.06it/s]Loading train:  19%|█▉        | 103/532 [01:43<06:19,  1.13it/s]Loading train:  20%|█▉        | 104/532 [01:44<06:07,  1.16it/s]Loading train:  20%|█▉        | 105/532 [01:45<06:05,  1.17it/s]Loading train:  20%|█▉        | 106/532 [01:46<05:48,  1.22it/s]Loading train:  20%|██        | 107/532 [01:47<05:43,  1.24it/s]Loading train:  20%|██        | 108/532 [01:47<05:31,  1.28it/s]Loading train:  20%|██        | 109/532 [01:48<05:25,  1.30it/s]Loading train:  21%|██        | 110/532 [01:49<05:14,  1.34it/s]Loading train:  21%|██        | 111/532 [01:49<05:14,  1.34it/s]Loading train:  21%|██        | 112/532 [01:50<05:10,  1.35it/s]Loading train:  21%|██        | 113/532 [01:51<06:11,  1.13it/s]Loading train:  21%|██▏       | 114/532 [01:52<06:12,  1.12it/s]Loading train:  22%|██▏       | 115/532 [01:53<06:14,  1.11it/s]Loading train:  22%|██▏       | 116/532 [01:54<06:11,  1.12it/s]Loading train:  22%|██▏       | 117/532 [01:55<06:14,  1.11it/s]Loading train:  22%|██▏       | 118/532 [01:56<06:11,  1.11it/s]Loading train:  22%|██▏       | 119/532 [01:57<06:22,  1.08it/s]Loading train:  23%|██▎       | 120/532 [01:58<06:14,  1.10it/s]Loading train:  23%|██▎       | 121/532 [01:59<06:25,  1.07it/s]Loading train:  23%|██▎       | 122/532 [02:00<06:23,  1.07it/s]Loading train:  23%|██▎       | 123/532 [02:01<06:17,  1.08it/s]Loading train:  23%|██▎       | 124/532 [02:02<06:17,  1.08it/s]Loading train:  23%|██▎       | 125/532 [02:03<06:36,  1.03it/s]Loading train:  24%|██▎       | 126/532 [02:04<06:26,  1.05it/s]Loading train:  24%|██▍       | 127/532 [02:04<06:25,  1.05it/s]Loading train:  24%|██▍       | 128/532 [02:05<06:22,  1.06it/s]Loading train:  24%|██▍       | 129/532 [02:06<06:22,  1.05it/s]Loading train:  24%|██▍       | 130/532 [02:07<06:33,  1.02it/s]Loading train:  25%|██▍       | 131/532 [02:09<07:00,  1.05s/it]Loading train:  25%|██▍       | 132/532 [02:10<07:01,  1.05s/it]Loading train:  25%|██▌       | 133/532 [02:11<07:07,  1.07s/it]Loading train:  25%|██▌       | 134/532 [02:12<07:09,  1.08s/it]Loading train:  25%|██▌       | 135/532 [02:13<07:08,  1.08s/it]Loading train:  26%|██▌       | 136/532 [02:14<07:14,  1.10s/it]Loading train:  26%|██▌       | 137/532 [02:15<07:16,  1.10s/it]Loading train:  26%|██▌       | 138/532 [02:16<07:22,  1.12s/it]Loading train:  26%|██▌       | 139/532 [02:18<07:30,  1.15s/it]Loading train:  26%|██▋       | 140/532 [02:19<07:31,  1.15s/it]Loading train:  27%|██▋       | 141/532 [02:20<07:37,  1.17s/it]Loading train:  27%|██▋       | 142/532 [02:21<07:29,  1.15s/it]Loading train:  27%|██▋       | 143/532 [02:22<07:00,  1.08s/it]Loading train:  27%|██▋       | 144/532 [02:23<06:35,  1.02s/it]Loading train:  27%|██▋       | 145/532 [02:24<06:14,  1.03it/s]Loading train:  27%|██▋       | 146/532 [02:25<06:05,  1.06it/s]Loading train:  28%|██▊       | 147/532 [02:25<05:49,  1.10it/s]Loading train:  28%|██▊       | 148/532 [02:26<05:42,  1.12it/s]Loading train:  28%|██▊       | 149/532 [02:27<05:46,  1.10it/s]Loading train:  28%|██▊       | 150/532 [02:28<05:36,  1.14it/s]Loading train:  28%|██▊       | 151/532 [02:29<05:28,  1.16it/s]Loading train:  29%|██▊       | 152/532 [02:30<05:16,  1.20it/s]Loading train:  29%|██▉       | 153/532 [02:30<05:11,  1.22it/s]Loading train:  29%|██▉       | 154/532 [02:31<05:17,  1.19it/s]Loading train:  29%|██▉       | 155/532 [02:33<06:14,  1.01it/s]Loading train:  29%|██▉       | 156/532 [02:34<06:43,  1.07s/it]Loading train:  30%|██▉       | 157/532 [02:35<06:59,  1.12s/it]Loading train:  30%|██▉       | 158/532 [02:36<07:03,  1.13s/it]Loading train:  30%|██▉       | 159/532 [02:38<07:15,  1.17s/it]Loading train:  30%|███       | 160/532 [02:39<07:20,  1.18s/it]Loading train:  30%|███       | 161/532 [02:40<07:12,  1.17s/it]Loading train:  30%|███       | 162/532 [02:41<06:50,  1.11s/it]Loading train:  31%|███       | 163/532 [02:42<06:26,  1.05s/it]Loading train:  31%|███       | 164/532 [02:43<06:11,  1.01s/it]Loading train:  31%|███       | 165/532 [02:44<06:04,  1.01it/s]Loading train:  31%|███       | 166/532 [02:45<05:52,  1.04it/s]Loading train:  31%|███▏      | 167/532 [02:46<06:03,  1.00it/s]Loading train:  32%|███▏      | 168/532 [02:47<06:00,  1.01it/s]Loading train:  32%|███▏      | 169/532 [02:48<06:02,  1.00it/s]Loading train:  32%|███▏      | 170/532 [02:49<06:04,  1.01s/it]Loading train:  32%|███▏      | 171/532 [02:50<06:02,  1.00s/it]Loading train:  32%|███▏      | 172/532 [02:51<06:02,  1.01s/it]Loading train:  33%|███▎      | 173/532 [02:52<05:47,  1.03it/s]Loading train:  33%|███▎      | 174/532 [02:52<05:33,  1.07it/s]Loading train:  33%|███▎      | 175/532 [02:53<05:24,  1.10it/s]Loading train:  33%|███▎      | 176/532 [02:54<05:21,  1.11it/s]Loading train:  33%|███▎      | 177/532 [02:55<05:18,  1.12it/s]Loading train:  33%|███▎      | 178/532 [02:56<05:21,  1.10it/s]Loading train:  34%|███▎      | 179/532 [02:57<05:27,  1.08it/s]Loading train:  34%|███▍      | 180/532 [02:58<05:16,  1.11it/s]Loading train:  34%|███▍      | 181/532 [02:59<05:12,  1.12it/s]Loading train:  34%|███▍      | 182/532 [02:59<05:08,  1.13it/s]Loading train:  34%|███▍      | 183/532 [03:00<05:02,  1.15it/s]Loading train:  35%|███▍      | 184/532 [03:01<04:58,  1.17it/s]Loading train:  35%|███▍      | 185/532 [03:02<05:08,  1.12it/s]Loading train:  35%|███▍      | 186/532 [03:03<05:07,  1.13it/s]Loading train:  35%|███▌      | 187/532 [03:04<04:53,  1.18it/s]Loading train:  35%|███▌      | 188/532 [03:05<04:40,  1.22it/s]Loading train:  36%|███▌      | 189/532 [03:05<04:42,  1.21it/s]Loading train:  36%|███▌      | 190/532 [03:06<04:38,  1.23it/s]Loading train:  36%|███▌      | 191/532 [03:07<05:26,  1.04it/s]Loading train:  36%|███▌      | 192/532 [03:09<05:41,  1.00s/it]Loading train:  36%|███▋      | 193/532 [03:10<05:52,  1.04s/it]Loading train:  36%|███▋      | 194/532 [03:11<05:54,  1.05s/it]Loading train:  37%|███▋      | 195/532 [03:12<06:00,  1.07s/it]Loading train:  37%|███▋      | 196/532 [03:13<06:03,  1.08s/it]Loading train:  37%|███▋      | 197/532 [03:14<06:00,  1.08s/it]Loading train:  37%|███▋      | 198/532 [03:15<05:53,  1.06s/it]Loading train:  37%|███▋      | 199/532 [03:16<05:55,  1.07s/it]Loading train:  38%|███▊      | 200/532 [03:17<05:50,  1.06s/it]Loading train:  38%|███▊      | 201/532 [03:18<05:43,  1.04s/it]Loading train:  38%|███▊      | 202/532 [03:19<05:49,  1.06s/it]Loading train:  38%|███▊      | 203/532 [03:20<05:41,  1.04s/it]Loading train:  38%|███▊      | 204/532 [03:21<05:20,  1.02it/s]Loading train:  39%|███▊      | 205/532 [03:22<05:11,  1.05it/s]Loading train:  39%|███▊      | 206/532 [03:23<05:00,  1.09it/s]Loading train:  39%|███▉      | 207/532 [03:24<04:57,  1.09it/s]Loading train:  39%|███▉      | 208/532 [03:25<04:51,  1.11it/s]Loading train:  39%|███▉      | 209/532 [03:26<04:54,  1.10it/s]Loading train:  39%|███▉      | 210/532 [03:26<04:43,  1.14it/s]Loading train:  40%|███▉      | 211/532 [03:27<04:30,  1.18it/s]Loading train:  40%|███▉      | 212/532 [03:28<04:30,  1.18it/s]Loading train:  40%|████      | 213/532 [03:29<04:37,  1.15it/s]Loading train:  40%|████      | 214/532 [03:30<04:33,  1.16it/s]Loading train:  40%|████      | 215/532 [03:31<05:02,  1.05it/s]Loading train:  41%|████      | 216/532 [03:32<05:21,  1.02s/it]Loading train:  41%|████      | 217/532 [03:33<05:33,  1.06s/it]Loading train:  41%|████      | 218/532 [03:34<05:47,  1.11s/it]Loading train:  41%|████      | 219/532 [03:36<05:48,  1.11s/it]Loading train:  41%|████▏     | 220/532 [03:37<05:51,  1.13s/it]Loading train:  42%|████▏     | 221/532 [03:38<05:21,  1.03s/it]Loading train:  42%|████▏     | 222/532 [03:38<04:58,  1.04it/s]Loading train:  42%|████▏     | 223/532 [03:39<04:42,  1.09it/s]Loading train:  42%|████▏     | 224/532 [03:40<04:27,  1.15it/s]Loading train:  42%|████▏     | 225/532 [03:41<04:15,  1.20it/s]Loading train:  42%|████▏     | 226/532 [03:41<04:07,  1.24it/s]Loading train:  43%|████▎     | 227/532 [03:42<03:59,  1.27it/s]Loading train:  43%|████▎     | 228/532 [03:43<03:50,  1.32it/s]Loading train:  43%|████▎     | 229/532 [03:44<03:49,  1.32it/s]Loading train:  43%|████▎     | 230/532 [03:44<03:47,  1.33it/s]Loading train:  43%|████▎     | 231/532 [03:45<03:43,  1.35it/s]Loading train:  44%|████▎     | 232/532 [03:46<03:43,  1.34it/s]Loading train:  44%|████▍     | 233/532 [03:47<03:48,  1.31it/s]Loading train:  44%|████▍     | 234/532 [03:47<03:54,  1.27it/s]Loading train:  44%|████▍     | 235/532 [03:48<04:06,  1.21it/s]Loading train:  44%|████▍     | 236/532 [03:49<04:13,  1.17it/s]Loading train:  45%|████▍     | 237/532 [03:50<04:16,  1.15it/s]Loading train:  45%|████▍     | 238/532 [03:51<04:28,  1.09it/s]Loading train:  45%|████▍     | 239/532 [03:52<04:48,  1.02it/s]Loading train:  45%|████▌     | 240/532 [03:53<04:54,  1.01s/it]Loading train:  45%|████▌     | 241/532 [03:54<04:58,  1.03s/it]Loading train:  45%|████▌     | 242/532 [03:56<04:58,  1.03s/it]Loading train:  46%|████▌     | 243/532 [03:56<04:47,  1.00it/s]Loading train:  46%|████▌     | 244/532 [03:57<04:38,  1.03it/s]Loading train:  46%|████▌     | 245/532 [03:58<04:24,  1.08it/s]Loading train:  46%|████▌     | 246/532 [03:59<04:06,  1.16it/s]Loading train:  46%|████▋     | 247/532 [04:00<03:57,  1.20it/s]Loading train:  47%|████▋     | 248/532 [04:00<03:55,  1.21it/s]Loading train:  47%|████▋     | 249/532 [04:01<03:43,  1.27it/s]Loading train:  47%|████▋     | 250/532 [04:02<03:36,  1.30it/s]Loading train:  47%|████▋     | 251/532 [04:03<03:35,  1.30it/s]Loading train:  47%|████▋     | 252/532 [04:03<03:38,  1.28it/s]Loading train:  48%|████▊     | 253/532 [04:04<03:45,  1.24it/s]Loading train:  48%|████▊     | 254/532 [04:05<03:43,  1.24it/s]Loading train:  48%|████▊     | 255/532 [04:06<03:48,  1.21it/s]Loading train:  48%|████▊     | 256/532 [04:07<03:50,  1.20it/s]Loading train:  48%|████▊     | 257/532 [04:08<04:13,  1.09it/s]Loading train:  48%|████▊     | 258/532 [04:09<04:21,  1.05it/s]Loading train:  49%|████▊     | 259/532 [04:10<04:19,  1.05it/s]Loading train:  49%|████▉     | 260/532 [04:11<04:23,  1.03it/s]Loading train:  49%|████▉     | 261/532 [04:12<04:26,  1.02it/s]Loading train:  49%|████▉     | 262/532 [04:13<04:30,  1.00s/it]Loading train:  49%|████▉     | 263/532 [04:14<04:26,  1.01it/s]Loading train:  50%|████▉     | 264/532 [04:15<04:02,  1.11it/s]Loading train:  50%|████▉     | 265/532 [04:15<03:48,  1.17it/s]Loading train:  50%|█████     | 266/532 [04:16<03:31,  1.26it/s]Loading train:  50%|█████     | 267/532 [04:17<03:25,  1.29it/s]Loading train:  50%|█████     | 268/532 [04:18<03:18,  1.33it/s]Loading train:  51%|█████     | 269/532 [04:18<03:35,  1.22it/s]Loading train:  51%|█████     | 270/532 [04:19<03:40,  1.19it/s]Loading train:  51%|█████     | 271/532 [04:20<03:40,  1.18it/s]Loading train:  51%|█████     | 272/532 [04:21<03:45,  1.15it/s]Loading train:  51%|█████▏    | 273/532 [04:22<03:36,  1.20it/s]Loading train:  52%|█████▏    | 274/532 [04:23<03:35,  1.20it/s]Loading train:  52%|█████▏    | 275/532 [04:24<03:49,  1.12it/s]Loading train:  52%|█████▏    | 276/532 [04:25<03:58,  1.07it/s]Loading train:  52%|█████▏    | 277/532 [04:26<04:08,  1.03it/s]Loading train:  52%|█████▏    | 278/532 [04:27<04:16,  1.01s/it]Loading train:  52%|█████▏    | 279/532 [04:28<04:23,  1.04s/it]Loading train:  53%|█████▎    | 280/532 [04:29<04:27,  1.06s/it]Loading train:  53%|█████▎    | 281/532 [04:30<04:29,  1.07s/it]Loading train:  53%|█████▎    | 282/532 [04:31<04:29,  1.08s/it]Loading train:  53%|█████▎    | 283/532 [04:32<04:27,  1.07s/it]Loading train:  53%|█████▎    | 284/532 [04:34<04:28,  1.08s/it]Loading train:  54%|█████▎    | 285/532 [04:35<04:22,  1.06s/it]Loading train:  54%|█████▍    | 286/532 [04:36<04:15,  1.04s/it]Loading train:  54%|█████▍    | 287/532 [04:36<03:57,  1.03it/s]Loading train:  54%|█████▍    | 288/532 [04:37<03:40,  1.11it/s]Loading train:  54%|█████▍    | 289/532 [04:38<03:27,  1.17it/s]Loading train:  55%|█████▍    | 290/532 [04:39<03:14,  1.24it/s]Loading train:  55%|█████▍    | 291/532 [04:39<03:14,  1.24it/s]Loading train:  55%|█████▍    | 292/532 [04:40<03:09,  1.27it/s]Loading train:  55%|█████▌    | 293/532 [04:41<03:19,  1.20it/s]Loading train:  55%|█████▌    | 294/532 [04:42<03:24,  1.17it/s]Loading train:  55%|█████▌    | 295/532 [04:43<03:23,  1.17it/s]Loading train:  56%|█████▌    | 296/532 [04:44<03:32,  1.11it/s]Loading train:  56%|█████▌    | 297/532 [04:45<03:40,  1.06it/s]Loading train:  56%|█████▌    | 298/532 [04:46<03:54,  1.00s/it]Loading train:  56%|█████▌    | 299/532 [04:47<03:39,  1.06it/s]Loading train:  56%|█████▋    | 300/532 [04:48<03:31,  1.10it/s]Loading train:  57%|█████▋    | 301/532 [04:48<03:24,  1.13it/s]Loading train:  57%|█████▋    | 302/532 [04:49<03:18,  1.16it/s]Loading train:  57%|█████▋    | 303/532 [04:50<03:12,  1.19it/s]Loading train:  57%|█████▋    | 304/532 [04:51<03:14,  1.17it/s]Loading train:  57%|█████▋    | 305/532 [04:52<03:37,  1.05it/s]Loading train:  58%|█████▊    | 306/532 [04:53<03:45,  1.00it/s]Loading train:  58%|█████▊    | 307/532 [04:54<03:51,  1.03s/it]Loading train:  58%|█████▊    | 308/532 [04:56<04:02,  1.08s/it]Loading train:  58%|█████▊    | 309/532 [04:57<04:06,  1.11s/it]Loading train:  58%|█████▊    | 310/532 [04:58<04:07,  1.11s/it]Loading train:  58%|█████▊    | 311/532 [04:59<04:29,  1.22s/it]Loading train:  59%|█████▊    | 312/532 [05:01<04:40,  1.28s/it]Loading train:  59%|█████▉    | 313/532 [05:02<04:58,  1.36s/it]Loading train:  59%|█████▉    | 314/532 [05:04<05:00,  1.38s/it]Loading train:  59%|█████▉    | 315/532 [05:05<05:08,  1.42s/it]Loading train:  59%|█████▉    | 316/532 [05:07<05:09,  1.43s/it]Loading train:  60%|█████▉    | 317/532 [05:08<04:33,  1.27s/it]Loading train:  60%|█████▉    | 318/532 [05:08<04:04,  1.14s/it]Loading train:  60%|█████▉    | 319/532 [05:09<03:43,  1.05s/it]Loading train:  60%|██████    | 320/532 [05:10<03:29,  1.01it/s]Loading train:  60%|██████    | 321/532 [05:11<03:22,  1.04it/s]Loading train:  61%|██████    | 322/532 [05:12<03:13,  1.09it/s]Loading train:  61%|██████    | 323/532 [05:13<03:36,  1.04s/it]Loading train:  61%|██████    | 324/532 [05:14<03:41,  1.07s/it]Loading train:  61%|██████    | 325/532 [05:15<03:46,  1.10s/it]Loading train:  61%|██████▏   | 326/532 [05:17<03:49,  1.11s/it]Loading train:  61%|██████▏   | 327/532 [05:18<03:51,  1.13s/it]Loading train:  62%|██████▏   | 328/532 [05:19<03:51,  1.13s/it]Loading train:  62%|██████▏   | 329/532 [05:20<03:58,  1.17s/it]Loading train:  62%|██████▏   | 330/532 [05:21<03:37,  1.08s/it]Loading train:  62%|██████▏   | 331/532 [05:22<03:23,  1.01s/it]Loading train:  62%|██████▏   | 332/532 [05:23<03:18,  1.01it/s]Loading train:  63%|██████▎   | 333/532 [05:24<03:11,  1.04it/s]Loading train:  63%|██████▎   | 334/532 [05:25<03:03,  1.08it/s]Loading train:  63%|██████▎   | 335/532 [05:26<03:12,  1.03it/s]Loading train:  63%|██████▎   | 336/532 [05:27<03:17,  1.01s/it]Loading train:  63%|██████▎   | 337/532 [05:28<03:14,  1.00it/s]Loading train:  64%|██████▎   | 338/532 [05:29<03:10,  1.02it/s]Loading train:  64%|██████▎   | 339/532 [05:30<03:10,  1.01it/s]Loading train:  64%|██████▍   | 340/532 [05:31<03:17,  1.03s/it]Loading train:  64%|██████▍   | 341/532 [05:32<03:03,  1.04it/s]Loading train:  64%|██████▍   | 342/532 [05:32<02:55,  1.09it/s]Loading train:  64%|██████▍   | 343/532 [05:33<02:51,  1.10it/s]Loading train:  65%|██████▍   | 344/532 [05:34<02:43,  1.15it/s]Loading train:  65%|██████▍   | 345/532 [05:35<02:35,  1.21it/s]Loading train:  65%|██████▌   | 346/532 [05:36<02:33,  1.21it/s]Loading train:  65%|██████▌   | 347/532 [05:37<02:47,  1.10it/s]Loading train:  65%|██████▌   | 348/532 [05:38<02:44,  1.12it/s]Loading train:  66%|██████▌   | 349/532 [05:38<02:44,  1.11it/s]Loading train:  66%|██████▌   | 350/532 [05:39<02:44,  1.11it/s]Loading train:  66%|██████▌   | 351/532 [05:40<02:42,  1.12it/s]Loading train:  66%|██████▌   | 352/532 [05:41<02:43,  1.10it/s]Loading train:  66%|██████▋   | 353/532 [05:42<02:42,  1.10it/s]Loading train:  67%|██████▋   | 354/532 [05:43<02:42,  1.09it/s]Loading train:  67%|██████▋   | 355/532 [05:44<02:38,  1.12it/s]Loading train:  67%|██████▋   | 356/532 [05:45<02:33,  1.15it/s]Loading train:  67%|██████▋   | 357/532 [05:45<02:28,  1.18it/s]Loading train:  67%|██████▋   | 358/532 [05:46<02:24,  1.21it/s]Loading train:  67%|██████▋   | 359/532 [05:47<02:23,  1.21it/s]Loading train:  68%|██████▊   | 360/532 [05:48<02:25,  1.18it/s]Loading train:  68%|██████▊   | 361/532 [05:49<02:24,  1.18it/s]Loading train:  68%|██████▊   | 362/532 [05:50<02:23,  1.18it/s]Loading train:  68%|██████▊   | 363/532 [05:51<02:22,  1.19it/s]Loading train:  68%|██████▊   | 364/532 [05:51<02:21,  1.19it/s]Loading train:  69%|██████▊   | 365/532 [05:52<02:20,  1.19it/s]Loading train:  69%|██████▉   | 366/532 [05:53<02:19,  1.19it/s]Loading train:  69%|██████▉   | 367/532 [05:54<02:17,  1.20it/s]Loading train:  69%|██████▉   | 368/532 [05:55<02:16,  1.20it/s]Loading train:  69%|██████▉   | 369/532 [05:55<02:11,  1.24it/s]Loading train:  70%|██████▉   | 370/532 [05:56<02:08,  1.26it/s]Loading train:  70%|██████▉   | 371/532 [05:57<02:29,  1.08it/s]Loading train:  70%|██████▉   | 372/532 [05:58<02:35,  1.03it/s]Loading train:  70%|███████   | 373/532 [06:00<02:37,  1.01it/s]Loading train:  70%|███████   | 374/532 [06:01<02:38,  1.00s/it]Loading train:  70%|███████   | 375/532 [06:02<02:39,  1.02s/it]Loading train:  71%|███████   | 376/532 [06:03<02:41,  1.04s/it]Loading train:  71%|███████   | 377/532 [06:04<02:36,  1.01s/it]Loading train:  71%|███████   | 378/532 [06:05<02:38,  1.03s/it]Loading train:  71%|███████   | 379/532 [06:06<02:32,  1.00it/s]Loading train:  71%|███████▏  | 380/532 [06:07<02:27,  1.03it/s]Loading train:  72%|███████▏  | 381/532 [06:07<02:21,  1.06it/s]Loading train:  72%|███████▏  | 382/532 [06:08<02:20,  1.07it/s]Loading train:  72%|███████▏  | 383/532 [06:09<02:21,  1.05it/s]Loading train:  72%|███████▏  | 384/532 [06:10<02:15,  1.10it/s]Loading train:  72%|███████▏  | 385/532 [06:11<02:10,  1.12it/s]Loading train:  73%|███████▎  | 386/532 [06:12<02:09,  1.13it/s]Loading train:  73%|███████▎  | 387/532 [06:13<02:06,  1.15it/s]Loading train:  73%|███████▎  | 388/532 [06:14<02:09,  1.11it/s]Loading train:  73%|███████▎  | 389/532 [06:15<02:11,  1.09it/s]Loading train:  73%|███████▎  | 390/532 [06:16<02:13,  1.06it/s]Loading train:  73%|███████▎  | 391/532 [06:17<02:14,  1.05it/s]Loading train:  74%|███████▎  | 392/532 [06:18<02:14,  1.04it/s]Loading train:  74%|███████▍  | 393/532 [06:19<02:18,  1.00it/s]Loading train:  74%|███████▍  | 394/532 [06:20<02:15,  1.02it/s]Loading train:  74%|███████▍  | 395/532 [06:21<02:11,  1.04it/s]Loading train:  74%|███████▍  | 396/532 [06:21<02:10,  1.04it/s]Loading train:  75%|███████▍  | 397/532 [06:22<02:09,  1.04it/s]Loading train:  75%|███████▍  | 398/532 [06:23<02:08,  1.04it/s]Loading train:  75%|███████▌  | 399/532 [06:24<02:05,  1.06it/s]Loading train:  75%|███████▌  | 400/532 [06:25<02:04,  1.06it/s]Loading train:  75%|███████▌  | 401/532 [06:26<02:11,  1.00s/it]Loading train:  76%|███████▌  | 402/532 [06:27<02:08,  1.01it/s]Loading train:  76%|███████▌  | 403/532 [06:28<02:07,  1.01it/s]Loading train:  76%|███████▌  | 404/532 [06:29<02:07,  1.01it/s]Loading train:  76%|███████▌  | 405/532 [06:30<02:09,  1.02s/it]Loading train:  76%|███████▋  | 406/532 [06:31<02:08,  1.02s/it]Loading train:  77%|███████▋  | 407/532 [06:32<02:04,  1.01it/s]Loading train:  77%|███████▋  | 408/532 [06:33<01:57,  1.06it/s]Loading train:  77%|███████▋  | 409/532 [06:34<01:53,  1.09it/s]Loading train:  77%|███████▋  | 410/532 [06:35<01:45,  1.15it/s]Loading train:  77%|███████▋  | 411/532 [06:36<01:40,  1.20it/s]Loading train:  77%|███████▋  | 412/532 [06:36<01:39,  1.20it/s]Loading train:  78%|███████▊  | 413/532 [06:37<01:37,  1.23it/s]Loading train:  78%|███████▊  | 414/532 [06:38<01:34,  1.25it/s]Loading train:  78%|███████▊  | 415/532 [06:39<01:33,  1.25it/s]Loading train:  78%|███████▊  | 416/532 [06:40<01:33,  1.25it/s]Loading train:  78%|███████▊  | 417/532 [06:40<01:30,  1.27it/s]Loading train:  79%|███████▊  | 418/532 [06:41<01:31,  1.25it/s]Loading train:  79%|███████▉  | 419/532 [06:42<01:37,  1.16it/s]Loading train:  79%|███████▉  | 420/532 [06:43<01:40,  1.12it/s]Loading train:  79%|███████▉  | 421/532 [06:44<01:41,  1.09it/s]Loading train:  79%|███████▉  | 422/532 [06:45<01:42,  1.07it/s]Loading train:  80%|███████▉  | 423/532 [06:46<01:42,  1.06it/s]Loading train:  80%|███████▉  | 424/532 [06:47<01:40,  1.07it/s]Loading train:  80%|███████▉  | 425/532 [06:48<01:44,  1.03it/s]Loading train:  80%|████████  | 426/532 [06:49<01:42,  1.04it/s]Loading train:  80%|████████  | 427/532 [06:50<01:42,  1.02it/s]Loading train:  80%|████████  | 428/532 [06:51<01:43,  1.01it/s]Loading train:  81%|████████  | 429/532 [06:52<01:43,  1.00s/it]Loading train:  81%|████████  | 430/532 [06:53<01:41,  1.01it/s]Loading train:  81%|████████  | 431/532 [06:54<01:42,  1.01s/it]Loading train:  81%|████████  | 432/532 [06:55<01:44,  1.04s/it]Loading train:  81%|████████▏ | 433/532 [06:56<01:42,  1.04s/it]Loading train:  82%|████████▏ | 434/532 [06:57<01:43,  1.05s/it]Loading train:  82%|████████▏ | 435/532 [06:58<01:40,  1.03s/it]Loading train:  82%|████████▏ | 436/532 [06:59<01:42,  1.07s/it]Loading train:  82%|████████▏ | 437/532 [07:00<01:33,  1.02it/s]Loading train:  82%|████████▏ | 438/532 [07:01<01:24,  1.11it/s]Loading train:  83%|████████▎ | 439/532 [07:02<01:19,  1.17it/s]Loading train:  83%|████████▎ | 440/532 [07:02<01:17,  1.18it/s]Loading train:  83%|████████▎ | 441/532 [07:03<01:15,  1.20it/s]Loading train:  83%|████████▎ | 442/532 [07:04<01:12,  1.24it/s]Loading train:  83%|████████▎ | 443/532 [07:05<01:10,  1.27it/s]Loading train:  83%|████████▎ | 444/532 [07:05<01:07,  1.30it/s]Loading train:  84%|████████▎ | 445/532 [07:06<01:06,  1.31it/s]Loading train:  84%|████████▍ | 446/532 [07:07<01:04,  1.34it/s]Loading train:  84%|████████▍ | 447/532 [07:08<01:01,  1.38it/s]Loading train:  84%|████████▍ | 448/532 [07:08<01:02,  1.35it/s]Loading train:  84%|████████▍ | 449/532 [07:09<01:06,  1.25it/s]Loading train:  85%|████████▍ | 450/532 [07:10<01:08,  1.19it/s]Loading train:  85%|████████▍ | 451/532 [07:11<01:10,  1.14it/s]Loading train:  85%|████████▍ | 452/532 [07:12<01:11,  1.13it/s]Loading train:  85%|████████▌ | 453/532 [07:13<01:08,  1.15it/s]Loading train:  85%|████████▌ | 454/532 [07:14<01:05,  1.19it/s]Loading train:  86%|████████▌ | 455/532 [07:15<01:07,  1.13it/s]Loading train:  86%|████████▌ | 456/532 [07:16<01:08,  1.11it/s]Loading train:  86%|████████▌ | 457/532 [07:17<01:08,  1.09it/s]Loading train:  86%|████████▌ | 458/532 [07:18<01:07,  1.09it/s]Loading train:  86%|████████▋ | 459/532 [07:19<01:08,  1.07it/s]Loading train:  86%|████████▋ | 460/532 [07:19<01:08,  1.05it/s]Loading train:  87%|████████▋ | 461/532 [07:21<01:10,  1.01it/s]Loading train:  87%|████████▋ | 462/532 [07:22<01:11,  1.02s/it]Loading train:  87%|████████▋ | 463/532 [07:23<01:12,  1.04s/it]Loading train:  87%|████████▋ | 464/532 [07:24<01:12,  1.07s/it]Loading train:  87%|████████▋ | 465/532 [07:25<01:15,  1.13s/it]Loading train:  88%|████████▊ | 466/532 [07:26<01:16,  1.16s/it]Loading train:  88%|████████▊ | 467/532 [07:27<01:10,  1.09s/it]Loading train:  88%|████████▊ | 468/532 [07:28<01:07,  1.05s/it]Loading train:  88%|████████▊ | 469/532 [07:29<01:04,  1.02s/it]Loading train:  88%|████████▊ | 470/532 [07:30<01:02,  1.01s/it]Loading train:  89%|████████▊ | 471/532 [07:31<01:01,  1.00s/it]Loading train:  89%|████████▊ | 472/532 [07:32<00:58,  1.03it/s]Loading train:  89%|████████▉ | 473/532 [07:33<00:57,  1.02it/s]Loading train:  89%|████████▉ | 474/532 [07:34<00:58,  1.01s/it]Loading train:  89%|████████▉ | 475/532 [07:35<00:54,  1.04it/s]Loading train:  89%|████████▉ | 476/532 [07:36<00:52,  1.07it/s]Loading train:  90%|████████▉ | 477/532 [07:37<00:52,  1.06it/s]Loading train:  90%|████████▉ | 478/532 [07:38<00:50,  1.07it/s]Loading train:  90%|█████████ | 479/532 [07:39<00:46,  1.13it/s]Loading train:  90%|█████████ | 480/532 [07:39<00:44,  1.18it/s]Loading train:  90%|█████████ | 481/532 [07:40<00:41,  1.23it/s]Loading train:  91%|█████████ | 482/532 [07:41<00:39,  1.27it/s]Loading train:  91%|█████████ | 483/532 [07:42<00:39,  1.24it/s]Loading train:  91%|█████████ | 484/532 [07:42<00:38,  1.23it/s]Loading train:  91%|█████████ | 485/532 [07:44<00:42,  1.09it/s]Loading train:  91%|█████████▏| 486/532 [07:45<00:46,  1.00s/it]Loading train:  92%|█████████▏| 487/532 [07:46<00:45,  1.02s/it]Loading train:  92%|█████████▏| 488/532 [07:47<00:44,  1.02s/it]Loading train:  92%|█████████▏| 489/532 [07:48<00:44,  1.04s/it]Loading train:  92%|█████████▏| 490/532 [07:49<00:43,  1.04s/it]Loading train:  92%|█████████▏| 491/532 [07:50<00:40,  1.02it/s]Loading train:  92%|█████████▏| 492/532 [07:51<00:38,  1.05it/s]Loading train:  93%|█████████▎| 493/532 [07:52<00:35,  1.11it/s]Loading train:  93%|█████████▎| 494/532 [07:52<00:32,  1.16it/s]Loading train:  93%|█████████▎| 495/532 [07:53<00:31,  1.16it/s]Loading train:  93%|█████████▎| 496/532 [07:54<00:31,  1.15it/s]Loading train:  93%|█████████▎| 497/532 [07:55<00:32,  1.09it/s]Loading train:  94%|█████████▎| 498/532 [07:56<00:32,  1.06it/s]Loading train:  94%|█████████▍| 499/532 [07:57<00:31,  1.06it/s]Loading train:  94%|█████████▍| 500/532 [07:58<00:29,  1.07it/s]Loading train:  94%|█████████▍| 501/532 [07:59<00:29,  1.04it/s]Loading train:  94%|█████████▍| 502/532 [08:00<00:30,  1.01s/it]Loading train:  95%|█████████▍| 503/532 [08:01<00:28,  1.03it/s]Loading train:  95%|█████████▍| 504/532 [08:02<00:26,  1.07it/s]Loading train:  95%|█████████▍| 505/532 [08:03<00:24,  1.12it/s]Loading train:  95%|█████████▌| 506/532 [08:03<00:23,  1.13it/s]Loading train:  95%|█████████▌| 507/532 [08:04<00:21,  1.15it/s]Loading train:  95%|█████████▌| 508/532 [08:05<00:20,  1.19it/s]Loading train:  96%|█████████▌| 509/532 [08:06<00:21,  1.09it/s]Loading train:  96%|█████████▌| 510/532 [08:07<00:20,  1.07it/s]Loading train:  96%|█████████▌| 511/532 [08:08<00:20,  1.01it/s]Loading train:  96%|█████████▌| 512/532 [08:09<00:20,  1.01s/it]Loading train:  96%|█████████▋| 513/532 [08:10<00:19,  1.02s/it]Loading train:  97%|█████████▋| 514/532 [08:12<00:19,  1.06s/it]Loading train:  97%|█████████▋| 515/532 [08:12<00:17,  1.00s/it]Loading train:  97%|█████████▋| 516/532 [08:13<00:15,  1.02it/s]Loading train:  97%|█████████▋| 517/532 [08:14<00:14,  1.05it/s]Loading train:  97%|█████████▋| 518/532 [08:15<00:13,  1.06it/s]Loading train:  98%|█████████▊| 519/532 [08:16<00:11,  1.09it/s]Loading train:  98%|█████████▊| 520/532 [08:17<00:10,  1.12it/s]Loading train:  98%|█████████▊| 521/532 [08:18<00:09,  1.11it/s]Loading train:  98%|█████████▊| 522/532 [08:19<00:08,  1.11it/s]Loading train:  98%|█████████▊| 523/532 [08:20<00:08,  1.11it/s]Loading train:  98%|█████████▊| 524/532 [08:20<00:07,  1.11it/s]Loading train:  99%|█████████▊| 525/532 [08:21<00:06,  1.12it/s]Loading train:  99%|█████████▉| 526/532 [08:22<00:05,  1.12it/s]Loading train:  99%|█████████▉| 527/532 [08:23<00:04,  1.08it/s]Loading train:  99%|█████████▉| 528/532 [08:24<00:03,  1.11it/s]Loading train:  99%|█████████▉| 529/532 [08:25<00:02,  1.11it/s]Loading train: 100%|█████████▉| 530/532 [08:26<00:01,  1.15it/s]Loading train: 100%|█████████▉| 531/532 [08:27<00:00,  1.16it/s]Loading train: 100%|██████████| 532/532 [08:27<00:00,  1.18it/s]
concatenating: train:   0%|          | 0/532 [00:00<?, ?it/s]concatenating: train:   4%|▍         | 23/532 [00:00<00:02, 223.62it/s]concatenating: train:   9%|▉         | 50/532 [00:00<00:02, 235.18it/s]concatenating: train:  15%|█▍        | 79/532 [00:00<00:01, 248.99it/s]concatenating: train:  20%|█▉        | 105/532 [00:00<00:01, 250.60it/s]concatenating: train:  25%|██▌       | 135/532 [00:00<00:01, 261.81it/s]concatenating: train:  31%|███       | 165/532 [00:00<00:01, 271.46it/s]concatenating: train:  36%|███▋      | 194/532 [00:00<00:01, 275.47it/s]concatenating: train:  42%|████▏     | 223/532 [00:00<00:01, 277.65it/s]concatenating: train:  47%|████▋     | 250/532 [00:00<00:01, 273.03it/s]concatenating: train:  52%|█████▏    | 277/532 [00:01<00:00, 265.46it/s]concatenating: train:  57%|█████▋    | 304/532 [00:01<00:00, 260.86it/s]concatenating: train:  63%|██████▎   | 333/532 [00:01<00:00, 266.68it/s]concatenating: train:  68%|██████▊   | 360/532 [00:01<00:00, 252.96it/s]concatenating: train:  73%|███████▎  | 386/532 [00:01<00:00, 250.11it/s]concatenating: train:  78%|███████▊  | 414/532 [00:01<00:00, 257.96it/s]concatenating: train:  83%|████████▎ | 440/532 [00:01<00:00, 250.29it/s]concatenating: train:  88%|████████▊ | 469/532 [00:01<00:00, 258.36it/s]concatenating: train:  93%|█████████▎| 495/532 [00:01<00:00, 253.96it/s]concatenating: train:  99%|█████████▉| 528/532 [00:01<00:00, 272.51it/s]concatenating: train: 100%|██████████| 532/532 [00:01<00:00, 266.96it/s]
Loading test:   0%|          | 0/15 [00:00<?, ?it/s]Loading test:   7%|▋         | 1/15 [00:00<00:11,  1.22it/s]Loading test:  13%|█▎        | 2/15 [00:01<00:10,  1.26it/s]Loading test:  20%|██        | 3/15 [00:02<00:10,  1.18it/s]Loading test:  27%|██▋       | 4/15 [00:03<00:09,  1.13it/s]Loading test:  33%|███▎      | 5/15 [00:04<00:09,  1.04it/s]Loading test:  40%|████      | 6/15 [00:05<00:09,  1.00s/it]Loading test:  47%|████▋     | 7/15 [00:06<00:07,  1.07it/s]Loading test:  53%|█████▎    | 8/15 [00:07<00:07,  1.06s/it]Loading test:  60%|██████    | 9/15 [00:08<00:06,  1.06s/it]Loading test:  67%|██████▋   | 10/15 [00:09<00:05,  1.02s/it]Loading test:  73%|███████▎  | 11/15 [00:10<00:03,  1.02it/s]Loading test:  80%|████████  | 12/15 [00:11<00:03,  1.01s/it]Loading test:  87%|████████▋ | 13/15 [00:12<00:02,  1.02s/it]Loading test:  93%|█████████▎| 14/15 [00:13<00:00,  1.03it/s]Loading test: 100%|██████████| 15/15 [00:14<00:00,  1.06it/s]
concatenating: validation:   0%|          | 0/15 [00:00<?, ?it/s]concatenating: validation:  67%|██████▋   | 10/15 [00:00<00:00, 98.22it/s]concatenating: validation: 100%|██████████| 15/15 [00:00<00:00, 105.63it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 56, 84, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 56, 84, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 56, 84, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 56, 84, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 56, 84, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 84, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 56, 84, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 56, 84, 31)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 28, 42, 31)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28, 42, 31)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 42, 60)   16800       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 42, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 42, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 42, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 28, 42, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 28, 42, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 42, 91)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 21, 91)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 14, 21, 91)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 14, 21, 120)  98400       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 14, 21, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 14, 21, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 14, 21, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 14, 21, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 14, 21, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 14, 21, 211)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 14, 21, 211)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 28, 42, 60)   50700       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 28, 42, 151)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 28, 42, 60)   81600       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 28, 42, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________2019-07-07 08:42:48.016279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 08:42:48.016390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 08:42:48.016405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 08:42:48.016414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 08:42:48.016830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

activation_7 (Activation)       (None, 28, 42, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 28, 42, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 28, 42, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 28, 42, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 28, 42, 211)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 28, 42, 211)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 56, 84, 30)   25350       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 84, 61)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 56, 84, 30)   16500       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 56, 84, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 84, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 56, 84, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 56, 84, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 84, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 84, 91)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 56, 84, 91)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 56, 84, 13)   1196        dropout_5[0][0]                  
==================================================================================================
Total params: 504,146
Trainable params: 502,946
Non-trainable params: 1,200
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.53383120e-02 2.88786827e-02 1.16652967e-01 1.00133292e-02
 3.03165963e-02 5.79538965e-03 6.85058777e-02 1.28145429e-01
 7.55135052e-02 1.22435092e-02 2.73464902e-01 1.84941443e-01
 1.90056842e-04]
Train on 20749 samples, validate on 584 samples
Epoch 1/300
 - 36s - loss: 21.0558 - acc: 0.8553 - mDice: 0.0365 - val_loss: 3.6316 - val_acc: 0.9128 - val_mDice: 0.0619

Epoch 00001: val_mDice improved from -inf to 0.06192, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 27s - loss: 3.5241 - acc: 0.9101 - mDice: 0.1510 - val_loss: 2.2436 - val_acc: 0.9412 - val_mDice: 0.2618

Epoch 00002: val_mDice improved from 0.06192 to 0.26184, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 28s - loss: 2.2853 - acc: 0.9355 - mDice: 0.3577 - val_loss: 1.4335 - val_acc: 0.9632 - val_mDice: 0.5084

Epoch 00003: val_mDice improved from 0.26184 to 0.50837, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 27s - loss: 1.7047 - acc: 0.9479 - mDice: 0.4945 - val_loss: 1.0929 - val_acc: 0.9673 - val_mDice: 0.6394

Epoch 00004: val_mDice improved from 0.50837 to 0.63935, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 28s - loss: 1.4177 - acc: 0.9555 - mDice: 0.5739 - val_loss: 0.9045 - val_acc: 0.9725 - val_mDice: 0.7054

Epoch 00005: val_mDice improved from 0.63935 to 0.70543, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 27s - loss: 1.2688 - acc: 0.9587 - mDice: 0.6145 - val_loss: 0.8274 - val_acc: 0.9745 - val_mDice: 0.7308

Epoch 00006: val_mDice improved from 0.70543 to 0.73082, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 28s - loss: 1.1738 - acc: 0.9607 - mDice: 0.6395 - val_loss: 0.8320 - val_acc: 0.9751 - val_mDice: 0.7335

Epoch 00007: val_mDice improved from 0.73082 to 0.73355, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 27s - loss: 1.0968 - acc: 0.9623 - mDice: 0.6601 - val_loss: 0.8085 - val_acc: 0.9757 - val_mDice: 0.7400

Epoch 00008: val_mDice improved from 0.73355 to 0.73996, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 9/300
 - 27s - loss: 1.0393 - acc: 0.9634 - mDice: 0.6750 - val_loss: 0.7802 - val_acc: 0.9762 - val_mDice: 0.7472

Epoch 00009: val_mDice improved from 0.73996 to 0.74717, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 27s - loss: 0.9914 - acc: 0.9644 - mDice: 0.6873 - val_loss: 0.7572 - val_acc: 0.9752 - val_mDice: 0.7579

Epoch 00010: val_mDice improved from 0.74717 to 0.75792, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 11/300
 - 26s - loss: 0.9562 - acc: 0.9651 - mDice: 0.6966 - val_loss: 0.7553 - val_acc: 0.9754 - val_mDice: 0.7599

Epoch 00011: val_mDice improved from 0.75792 to 0.75991, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 12/300
 - 27s - loss: 0.9193 - acc: 0.9658 - mDice: 0.7061 - val_loss: 0.7384 - val_acc: 0.9775 - val_mDice: 0.7606

Epoch 00012: val_mDice improved from 0.75991 to 0.76061, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 13/300
 - 27s - loss: 0.8895 - acc: 0.9664 - mDice: 0.7140 - val_loss: 0.7445 - val_acc: 0.9772 - val_mDice: 0.7642

Epoch 00013: val_mDice improved from 0.76061 to 0.76422, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 14/300
 - 26s - loss: 0.8674 - acc: 0.9668 - mDice: 0.7193 - val_loss: 0.7373 - val_acc: 0.9768 - val_mDice: 0.7648

Epoch 00014: val_mDice improved from 0.76422 to 0.76485, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 15/300
 - 28s - loss: 0.8509 - acc: 0.9671 - mDice: 0.7235 - val_loss: 0.7477 - val_acc: 0.9758 - val_mDice: 0.7641

Epoch 00015: val_mDice did not improve from 0.76485
Epoch 16/300
 - 27s - loss: 0.8294 - acc: 0.9675 - mDice: 0.7294 - val_loss: 0.7140 - val_acc: 0.9782 - val_mDice: 0.7663

Epoch 00016: val_mDice improved from 0.76485 to 0.76629, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 17/300
 - 27s - loss: 0.8092 - acc: 0.9679 - mDice: 0.7346 - val_loss: 0.7105 - val_acc: 0.9781 - val_mDice: 0.7694

Epoch 00017: val_mDice improved from 0.76629 to 0.76941, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 18/300
 - 27s - loss: 0.7941 - acc: 0.9681 - mDice: 0.7385 - val_loss: 0.7207 - val_acc: 0.9774 - val_mDice: 0.7675

Epoch 00018: val_mDice did not improve from 0.76941
Epoch 19/300
 - 27s - loss: 0.7814 - acc: 0.9684 - mDice: 0.7421 - val_loss: 0.7021 - val_acc: 0.9775 - val_mDice: 0.7713

Epoch 00019: val_mDice improved from 0.76941 to 0.77127, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 20/300
 - 28s - loss: 0.7683 - acc: 0.9686 - mDice: 0.7453 - val_loss: 0.6973 - val_acc: 0.9792 - val_mDice: 0.7710

Epoch 00020: val_mDice did not improve from 0.77127
Epoch 21/300
 - 27s - loss: 0.7534 - acc: 0.9689 - mDice: 0.7492 - val_loss: 0.6955 - val_acc: 0.9792 - val_mDice: 0.7745

Epoch 00021: val_mDice improved from 0.77127 to 0.77450, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 22/300
 - 28s - loss: 0.7441 - acc: 0.9690 - mDice: 0.7518 - val_loss: 0.7011 - val_acc: 0.9787 - val_mDice: 0.7760

Epoch 00022: val_mDice improved from 0.77450 to 0.77605, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 23/300
 - 27s - loss: 0.7370 - acc: 0.9692 - mDice: 0.7538 - val_loss: 0.6935 - val_acc: 0.9778 - val_mDice: 0.7742

Epoch 00023: val_mDice did not improve from 0.77605
Epoch 24/300
 - 28s - loss: 0.7236 - acc: 0.9694 - mDice: 0.7577 - val_loss: 0.6796 - val_acc: 0.9782 - val_mDice: 0.7740

Epoch 00024: val_mDice did not improve from 0.77605
Epoch 25/300
 - 28s - loss: 0.7170 - acc: 0.9696 - mDice: 0.7592 - val_loss: 0.6915 - val_acc: 0.9787 - val_mDice: 0.7755

Epoch 00025: val_mDice did not improve from 0.77605
Epoch 26/300
 - 28s - loss: 0.7077 - acc: 0.9698 - mDice: 0.7617 - val_loss: 0.6999 - val_acc: 0.9789 - val_mDice: 0.7686

Epoch 00026: val_mDice did not improve from 0.77605
Epoch 27/300
 - 28s - loss: 0.7007 - acc: 0.9699 - mDice: 0.7640 - val_loss: 0.6841 - val_acc: 0.9790 - val_mDice: 0.7780

Epoch 00027: val_mDice improved from 0.77605 to 0.77805, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 28/300
 - 27s - loss: 0.6932 - acc: 0.9700 - mDice: 0.7662 - val_loss: 0.6820 - val_acc: 0.9793 - val_mDice: 0.7734

Epoch 00028: val_mDice did not improve from 0.77805
Epoch 29/300
 - 28s - loss: 0.6902 - acc: 0.9701 - mDice: 0.7671 - val_loss: 0.6879 - val_acc: 0.9795 - val_mDice: 0.7742

Epoch 00029: val_mDice did not improve from 0.77805
Epoch 30/300
 - 27s - loss: 0.6812 - acc: 0.9702 - mDice: 0.7696 - val_loss: 0.6893 - val_acc: 0.9798 - val_mDice: 0.7741

Epoch 00030: val_mDice did not improve from 0.77805
Epoch 31/300
 - 27s - loss: 0.6731 - acc: 0.9704 - mDice: 0.7720 - val_loss: 0.6852 - val_acc: 0.9798 - val_mDice: 0.7746

Epoch 00031: val_mDice did not improve from 0.77805
Epoch 32/300
 - 28s - loss: 0.6690 - acc: 0.9705 - mDice: 0.7734 - val_loss: 0.6752 - val_acc: 0.9781 - val_mDice: 0.7824

Epoch 00032: val_mDice improved from 0.77805 to 0.78239, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 33/300
 - 27s - loss: 0.6631 - acc: 0.9706 - mDice: 0.7751 - val_loss: 0.6754 - val_acc: 0.9794 - val_mDice: 0.7788

Epoch 00033: val_mDice did not improve from 0.78239
Epoch 34/300
 - 27s - loss: 0.6596 - acc: 0.9706 - mDice: 0.7760 - val_loss: 0.6949 - val_acc: 0.9802 - val_mDice: 0.7737

Epoch 00034: val_mDice did not improve from 0.78239
Epoch 35/300
 - 28s - loss: 0.6554 - acc: 0.9707 - mDice: 0.7772 - val_loss: 0.6751 - val_acc: 0.9797 - val_mDice: 0.7794

Epoch 00035: val_mDice did not improve from 0.78239
Epoch 36/300
 - 27s - loss: 0.6503 - acc: 0.9708 - mDice: 0.7787 - val_loss: 0.7076 - val_acc: 0.9797 - val_mDice: 0.7745

Epoch 00036: val_mDice did not improve from 0.78239
Epoch 37/300
 - 27s - loss: 0.6449 - acc: 0.9709 - mDice: 0.7804 - val_loss: 0.6846 - val_acc: 0.9803 - val_mDice: 0.7780

Epoch 00037: val_mDice did not improve from 0.78239
Epoch 38/300
 - 27s - loss: 0.6419 - acc: 0.9709 - mDice: 0.7812 - val_loss: 0.6765 - val_acc: 0.9793 - val_mDice: 0.7810

Epoch 00038: val_mDice did not improve from 0.78239
Epoch 39/300
 - 28s - loss: 0.6333 - acc: 0.9711 - mDice: 0.7843 - val_loss: 0.6808 - val_acc: 0.9793 - val_mDice: 0.7754

Epoch 00039: val_mDice did not improve from 0.78239
Epoch 40/300
 - 27s - loss: 0.6301 - acc: 0.9711 - mDice: 0.7849 - val_loss: 0.6797 - val_acc: 0.9806 - val_mDice: 0.7785

Epoch 00040: val_mDice did not improve from 0.78239
Epoch 41/300
 - 27s - loss: 0.6265 - acc: 0.9712 - mDice: 0.7861 - val_loss: 0.6666 - val_acc: 0.9802 - val_mDice: 0.7796

Epoch 00041: val_mDice did not improve from 0.78239
Epoch 42/300
 - 27s - loss: 0.6232 - acc: 0.9713 - mDice: 0.7873 - val_loss: 0.6744 - val_acc: 0.9798 - val_mDice: 0.7825

Epoch 00042: val_mDice improved from 0.78239 to 0.78252, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 43/300
 - 28s - loss: 0.6224 - acc: 0.9713 - mDice: 0.7872 - val_loss: 0.6814 - val_acc: 0.9791 - val_mDice: 0.7796

Epoch 00043: val_mDice did not improve from 0.78252
Epoch 44/300
 - 27s - loss: 0.6150 - acc: 0.9714 - mDice: 0.7896 - val_loss: 0.6805 - val_acc: 0.9803 - val_mDice: 0.7800

Epoch 00044: val_mDice did not improve from 0.78252
Epoch 45/300
 - 26s - loss: 0.6144 - acc: 0.9714 - mDice: 0.7897 - val_loss: 0.6767 - val_acc: 0.9801 - val_mDice: 0.7817

Epoch 00045: val_mDice did not improve from 0.78252
Epoch 46/300
 - 27s - loss: 0.6112 - acc: 0.9715 - mDice: 0.7907 - val_loss: 0.6921 - val_acc: 0.9791 - val_mDice: 0.7806

Epoch 00046: val_mDice did not improve from 0.78252
Epoch 47/300
 - 27s - loss: 0.6072 - acc: 0.9715 - mDice: 0.7922 - val_loss: 0.6701 - val_acc: 0.9801 - val_mDice: 0.7847

Epoch 00047: val_mDice improved from 0.78252 to 0.78466, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 48/300
 - 26s - loss: 0.6021 - acc: 0.9716 - mDice: 0.7936 - val_loss: 0.6713 - val_acc: 0.9797 - val_mDice: 0.7813

Epoch 00048: val_mDice did not improve from 0.78466
Epoch 49/300
 - 27s - loss: 0.5987 - acc: 0.9717 - mDice: 0.7947 - val_loss: 0.6742 - val_acc: 0.9802 - val_mDice: 0.7824

Epoch 00049: val_mDice did not improve from 0.78466
Epoch 50/300
 - 27s - loss: 0.5977 - acc: 0.9717 - mDice: 0.7951 - val_loss: 0.6735 - val_acc: 0.9802 - val_mDice: 0.7799

Epoch 00050: val_mDice did not improve from 0.78466
Epoch 51/300
 - 26s - loss: 0.5933 - acc: 0.9718 - mDice: 0.7964 - val_loss: 0.6737 - val_acc: 0.9806 - val_mDice: 0.7834

Epoch 00051: val_mDice did not improve from 0.78466
Epoch 52/300
 - 27s - loss: 0.5925 - acc: 0.9718 - mDice: 0.7967 - val_loss: 0.6719 - val_acc: 0.9792 - val_mDice: 0.7845

Epoch 00052: val_mDice did not improve from 0.78466
Epoch 53/300
 - 28s - loss: 0.5893 - acc: 0.9719 - mDice: 0.7976 - val_loss: 0.6853 - val_acc: 0.9804 - val_mDice: 0.7824

Epoch 00053: val_mDice did not improve from 0.78466
Epoch 54/300
 - 26s - loss: 0.5875 - acc: 0.9718 - mDice: 0.7981 - val_loss: 0.6837 - val_acc: 0.9799 - val_mDice: 0.7818

Epoch 00054: val_mDice did not improve from 0.78466
Epoch 55/300
 - 26s - loss: 0.5843 - acc: 0.9719 - mDice: 0.7993 - val_loss: 0.6734 - val_acc: 0.9800 - val_mDice: 0.7854

Epoch 00055: val_mDice improved from 0.78466 to 0.78540, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 56/300
 - 27s - loss: 0.5817 - acc: 0.9720 - mDice: 0.8000 - val_loss: 0.6850 - val_acc: 0.9800 - val_mDice: 0.7825

Epoch 00056: val_mDice did not improve from 0.78540
Epoch 57/300
 - 28s - loss: 0.5786 - acc: 0.9720 - mDice: 0.8009 - val_loss: 0.6773 - val_acc: 0.9795 - val_mDice: 0.7850

Epoch 00057: val_mDice did not improve from 0.78540
Epoch 58/300
 - 27s - loss: 0.5762 - acc: 0.9721 - mDice: 0.8015 - val_loss: 0.6595 - val_acc: 0.9804 - val_mDice: 0.7875

Epoch 00058: val_mDice improved from 0.78540 to 0.78751, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 59/300
 - 28s - loss: 0.5758 - acc: 0.9720 - mDice: 0.8019 - val_loss: 0.6670 - val_acc: 0.9810 - val_mDice: 0.7842

Epoch 00059: val_mDice did not improve from 0.78751
Epoch 60/300
 - 27s - loss: 0.5717 - acc: 0.9721 - mDice: 0.8032 - val_loss: 0.6793 - val_acc: 0.9795 - val_mDice: 0.7816

Epoch 00060: val_mDice did not improve from 0.78751
Epoch 61/300
 - 27s - loss: 0.5703 - acc: 0.9722 - mDice: 0.8037 - val_loss: 0.6697 - val_acc: 0.9799 - val_mDice: 0.7848

Epoch 00061: val_mDice did not improve from 0.78751
Epoch 62/300
 - 28s - loss: 0.5689 - acc: 0.9722 - mDice: 0.8040 - val_loss: 0.6792 - val_acc: 0.9799 - val_mDice: 0.7893

Epoch 00062: val_mDice improved from 0.78751 to 0.78930, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 63/300
 - 27s - loss: 0.5662 - acc: 0.9722 - mDice: 0.8050 - val_loss: 0.6907 - val_acc: 0.9794 - val_mDice: 0.7851

Epoch 00063: val_mDice did not improve from 0.78930
Epoch 64/300
 - 27s - loss: 0.5647 - acc: 0.9722 - mDice: 0.8054 - val_loss: 0.6817 - val_acc: 0.9803 - val_mDice: 0.7884

Epoch 00064: val_mDice did not improve from 0.78930
Epoch 65/300
 - 27s - loss: 0.5619 - acc: 0.9723 - mDice: 0.8063 - val_loss: 0.6713 - val_acc: 0.9805 - val_mDice: 0.7905

Epoch 00065: val_mDice improved from 0.78930 to 0.79053, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 66/300
 - 27s - loss: 0.5586 - acc: 0.9724 - mDice: 0.8076 - val_loss: 0.6758 - val_acc: 0.9809 - val_mDice: 0.7843

Epoch 00066: val_mDice did not improve from 0.79053
Epoch 67/300
 - 28s - loss: 0.5563 - acc: 0.9724 - mDice: 0.8086 - val_loss: 0.6666 - val_acc: 0.9801 - val_mDice: 0.7893

Epoch 00067: val_mDice did not improve from 0.79053
Epoch 68/300
 - 28s - loss: 0.5498 - acc: 0.9725 - mDice: 0.8108 - val_loss: 0.6690 - val_acc: 0.9803 - val_mDice: 0.7890

Epoch 00068: val_mDice did not improve from 0.79053
Epoch 69/300
 - 27s - loss: 0.5462 - acc: 0.9725 - mDice: 0.8121 - val_loss: 0.6483 - val_acc: 0.9812 - val_mDice: 0.7954

Epoch 00069: val_mDice improved from 0.79053 to 0.79535, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 70/300
 - 27s - loss: 0.5449 - acc: 0.9725 - mDice: 0.8129 - val_loss: 0.6496 - val_acc: 0.9807 - val_mDice: 0.7956

Epoch 00070: val_mDice improved from 0.79535 to 0.79561, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 71/300
 - 27s - loss: 0.5380 - acc: 0.9727 - mDice: 0.8154 - val_loss: 0.6749 - val_acc: 0.9805 - val_mDice: 0.7898

Epoch 00071: val_mDice did not improve from 0.79561
Epoch 72/300
 - 27s - loss: 0.5353 - acc: 0.9727 - mDice: 0.8164 - val_loss: 0.6648 - val_acc: 0.9801 - val_mDice: 0.7981

Epoch 00072: val_mDice improved from 0.79561 to 0.79813, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 73/300
 - 27s - loss: 0.5318 - acc: 0.9728 - mDice: 0.8179 - val_loss: 0.6501 - val_acc: 0.9805 - val_mDice: 0.8012

Epoch 00073: val_mDice improved from 0.79813 to 0.80116, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 74/300
 - 28s - loss: 0.5291 - acc: 0.9729 - mDice: 0.8188 - val_loss: 0.6368 - val_acc: 0.9810 - val_mDice: 0.7987

Epoch 00074: val_mDice did not improve from 0.80116
Epoch 75/300
 - 27s - loss: 0.5271 - acc: 0.9729 - mDice: 0.8195 - val_loss: 0.6544 - val_acc: 0.9803 - val_mDice: 0.7974

Epoch 00075: val_mDice did not improve from 0.80116
Epoch 76/300
 - 28s - loss: 0.5226 - acc: 0.9730 - mDice: 0.8211 - val_loss: 0.6502 - val_acc: 0.9817 - val_mDice: 0.8002

Epoch 00076: val_mDice did not improve from 0.80116
Epoch 77/300
 - 27s - loss: 0.5189 - acc: 0.9730 - mDice: 0.8223 - val_loss: 0.6445 - val_acc: 0.9805 - val_mDice: 0.8020

Epoch 00077: val_mDice improved from 0.80116 to 0.80199, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 78/300
 - 28s - loss: 0.5176 - acc: 0.9730 - mDice: 0.8228 - val_loss: 0.6506 - val_acc: 0.9798 - val_mDice: 0.8046

Epoch 00078: val_mDice improved from 0.80199 to 0.80459, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 79/300
 - 28s - loss: 0.5158 - acc: 0.9731 - mDice: 0.8232 - val_loss: 0.6439 - val_acc: 0.9807 - val_mDice: 0.8020

Epoch 00079: val_mDice did not improve from 0.80459
Epoch 80/300
 - 27s - loss: 0.5130 - acc: 0.9731 - mDice: 0.8245 - val_loss: 0.6516 - val_acc: 0.9800 - val_mDice: 0.8036

Epoch 00080: val_mDice did not improve from 0.80459
Epoch 81/300
 - 28s - loss: 0.5097 - acc: 0.9732 - mDice: 0.8257 - val_loss: 0.6431 - val_acc: 0.9812 - val_mDice: 0.8072

Epoch 00081: val_mDice improved from 0.80459 to 0.80724, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 82/300
 - 27s - loss: 0.5067 - acc: 0.9732 - mDice: 0.8267 - val_loss: 0.6634 - val_acc: 0.9809 - val_mDice: 0.8019

Epoch 00082: val_mDice did not improve from 0.80724
Epoch 83/300
 - 28s - loss: 0.5059 - acc: 0.9732 - mDice: 0.8270 - val_loss: 0.6630 - val_acc: 0.9801 - val_mDice: 0.8057

Epoch 00083: val_mDice did not improve from 0.80724
Epoch 84/300
 - 27s - loss: 0.5051 - acc: 0.9733 - mDice: 0.8273 - val_loss: 0.6416 - val_acc: 0.9807 - val_mDice: 0.8094

Epoch 00084: val_mDice improved from 0.80724 to 0.80938, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 85/300
 - 28s - loss: 0.5005 - acc: 0.9733 - mDice: 0.8289 - val_loss: 0.6430 - val_acc: 0.9799 - val_mDice: 0.8055

Epoch 00085: val_mDice did not improve from 0.80938
Epoch 86/300
 - 26s - loss: 0.4996 - acc: 0.9734 - mDice: 0.8292 - val_loss: 0.6444 - val_acc: 0.9817 - val_mDice: 0.8055

Epoch 00086: val_mDice did not improve from 0.80938
Epoch 87/300
 - 28s - loss: 0.4986 - acc: 0.9734 - mDice: 0.8296 - val_loss: 0.6551 - val_acc: 0.9810 - val_mDice: 0.8017

Epoch 00087: val_mDice did not improve from 0.80938
Epoch 88/300
 - 27s - loss: 0.4962 - acc: 0.9735 - mDice: 0.8306 - val_loss: 0.6376 - val_acc: 0.9812 - val_mDice: 0.8078

Epoch 00088: val_mDice did not improve from 0.80938
Epoch 89/300
 - 28s - loss: 0.4940 - acc: 0.9735 - mDice: 0.8312 - val_loss: 0.6468 - val_acc: 0.9808 - val_mDice: 0.8097

Epoch 00089: val_mDice improved from 0.80938 to 0.80975, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 90/300
 - 26s - loss: 0.4928 - acc: 0.9735 - mDice: 0.8316 - val_loss: 0.6449 - val_acc: 0.9806 - val_mDice: 0.8083

Epoch 00090: val_mDice did not improve from 0.80975
Epoch 91/300
 - 28s - loss: 0.4901 - acc: 0.9735 - mDice: 0.8325 - val_loss: 0.6570 - val_acc: 0.9805 - val_mDice: 0.8057

Epoch 00091: val_mDice did not improve from 0.80975
Epoch 92/300
 - 27s - loss: 0.4887 - acc: 0.9736 - mDice: 0.8329 - val_loss: 0.6578 - val_acc: 0.9809 - val_mDice: 0.8043

Epoch 00092: val_mDice did not improve from 0.80975
Epoch 93/300
 - 27s - loss: 0.4877 - acc: 0.9735 - mDice: 0.8334 - val_loss: 0.6486 - val_acc: 0.9816 - val_mDice: 0.8064

Epoch 00093: val_mDice did not improve from 0.80975
Epoch 94/300
 - 28s - loss: 0.4865 - acc: 0.9736 - mDice: 0.8337 - val_loss: 0.6453 - val_acc: 0.9811 - val_mDice: 0.8092

Epoch 00094: val_mDice did not improve from 0.80975
Epoch 95/300
 - 27s - loss: 0.4839 - acc: 0.9736 - mDice: 0.8345 - val_loss: 0.6555 - val_acc: 0.9811 - val_mDice: 0.8127

Epoch 00095: val_mDice improved from 0.80975 to 0.81273, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 96/300
 - 28s - loss: 0.4838 - acc: 0.9736 - mDice: 0.8345 - val_loss: 0.6475 - val_acc: 0.9807 - val_mDice: 0.8118

Epoch 00096: val_mDice did not improve from 0.81273
Epoch 97/300
 - 27s - loss: 0.4829 - acc: 0.9737 - mDice: 0.8350 - val_loss: 0.6660 - val_acc: 0.9803 - val_mDice: 0.8101

Epoch 00097: val_mDice did not improve from 0.81273
Epoch 98/300
 - 27s - loss: 0.4807 - acc: 0.9737 - mDice: 0.8358 - val_loss: 0.6608 - val_acc: 0.9813 - val_mDice: 0.8076

Epoch 00098: val_mDice did not improve from 0.81273
Epoch 99/300
 - 28s - loss: 0.4784 - acc: 0.9738 - mDice: 0.8365 - val_loss: 0.6530 - val_acc: 0.9811 - val_mDice: 0.8089

Epoch 00099: val_mDice did not improve from 0.81273
Epoch 100/300
 - 27s - loss: 0.4788 - acc: 0.9737 - mDice: 0.8364 - val_loss: 0.6541 - val_acc: 0.9813 - val_mDice: 0.8104

Epoch 00100: val_mDice did not improve from 0.81273
Epoch 101/300
 - 27s - loss: 0.4783 - acc: 0.9737 - mDice: 0.8366 - val_loss: 0.6479 - val_acc: 0.9811 - val_mDice: 0.8142

Epoch 00101: val_mDice improved from 0.81273 to 0.81419, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 102/300
 - 28s - loss: 0.4779 - acc: 0.9737 - mDice: 0.8368 - val_loss: 0.6555 - val_acc: 0.9805 - val_mDice: 0.8098

Epoch 00102: val_mDice did not improve from 0.81419
Epoch 103/300
 - 27s - loss: 0.4752 - acc: 0.9738 - mDice: 0.8376 - val_loss: 0.6587 - val_acc: 0.9811 - val_mDice: 0.8100

Epoch 00103: val_mDice did not improve from 0.81419
Epoch 104/300
 - 27s - loss: 0.4742 - acc: 0.9738 - mDice: 0.8379 - val_loss: 0.6678 - val_acc: 0.9814 - val_mDice: 0.8095

Epoch 00104: val_mDice did not improve from 0.81419
Epoch 105/300
 - 28s - loss: 0.4723 - acc: 0.9738 - mDice: 0.8383 - val_loss: 0.6832 - val_acc: 0.9804 - val_mDice: 0.8082

Epoch 00105: val_mDice did not improve from 0.81419
Epoch 106/300
 - 27s - loss: 0.4719 - acc: 0.9738 - mDice: 0.8387 - val_loss: 0.6446 - val_acc: 0.9820 - val_mDice: 0.8122

Epoch 00106: val_mDice did not improve from 0.81419
Epoch 107/300
 - 28s - loss: 0.4714 - acc: 0.9738 - mDice: 0.8390 - val_loss: 0.6488 - val_acc: 0.9815 - val_mDice: 0.8103

Epoch 00107: val_mDice did not improve from 0.81419
Epoch 108/300
 - 27s - loss: 0.4700 - acc: 0.9739 - mDice: 0.8391 - val_loss: 0.6593 - val_acc: 0.9808 - val_mDice: 0.8113

Epoch 00108: val_mDice did not improve from 0.81419
Epoch 109/300
 - 28s - loss: 0.4688 - acc: 0.9739 - mDice: 0.8398 - val_loss: 0.6687 - val_acc: 0.9804 - val_mDice: 0.8124

Epoch 00109: val_mDice did not improve from 0.81419
Epoch 110/300
 - 26s - loss: 0.4674 - acc: 0.9739 - mDice: 0.8404 - val_loss: 0.6514 - val_acc: 0.9810 - val_mDice: 0.8120

Epoch 00110: val_mDice did not improve from 0.81419
Epoch 111/300
 - 28s - loss: 0.4684 - acc: 0.9739 - mDice: 0.8401 - val_loss: 0.6570 - val_acc: 0.9814 - val_mDice: 0.8120

Epoch 00111: val_mDice did not improve from 0.81419
Epoch 112/300
 - 27s - loss: 0.4671 - acc: 0.9739 - mDice: 0.8405 - val_loss: 0.6773 - val_acc: 0.9815 - val_mDice: 0.8091

Epoch 00112: val_mDice did not improve from 0.81419
Epoch 113/300
 - 27s - loss: 0.4655 - acc: 0.9739 - mDice: 0.8409 - val_loss: 0.6585 - val_acc: 0.9809 - val_mDice: 0.8103

Epoch 00113: val_mDice did not improve from 0.81419
Epoch 114/300
 - 27s - loss: 0.4652 - acc: 0.9740 - mDice: 0.8410 - val_loss: 0.6609 - val_acc: 0.9813 - val_mDice: 0.8151

Epoch 00114: val_mDice improved from 0.81419 to 0.81511, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 115/300
 - 26s - loss: 0.4635 - acc: 0.9740 - mDice: 0.8415 - val_loss: 0.6549 - val_acc: 0.9813 - val_mDice: 0.8109

Epoch 00115: val_mDice did not improve from 0.81511
Epoch 116/300
 - 27s - loss: 0.4628 - acc: 0.9740 - mDice: 0.8418 - val_loss: 0.6428 - val_acc: 0.9818 - val_mDice: 0.8119

Epoch 00116: val_mDice did not improve from 0.81511
Epoch 117/300
 - 28s - loss: 0.4620 - acc: 0.9740 - mDice: 0.8421 - val_loss: 0.6759 - val_acc: 0.9810 - val_mDice: 0.8135

Epoch 00117: val_mDice did not improve from 0.81511
Epoch 118/300
 - 28s - loss: 0.4617 - acc: 0.9740 - mDice: 0.8423 - val_loss: 0.6609 - val_acc: 0.9812 - val_mDice: 0.8118

Epoch 00118: val_mDice did not improve from 0.81511
Epoch 119/300
 - 28s - loss: 0.4586 - acc: 0.9741 - mDice: 0.8433 - val_loss: 0.6823 - val_acc: 0.9817 - val_mDice: 0.8115

Epoch 00119: val_mDice did not improve from 0.81511
Epoch 120/300
 - 27s - loss: 0.4587 - acc: 0.9740 - mDice: 0.8432 - val_loss: 0.6599 - val_acc: 0.9813 - val_mDice: 0.8148

Epoch 00120: val_mDice did not improve from 0.81511
Epoch 121/300
 - 27s - loss: 0.4578 - acc: 0.9740 - mDice: 0.8435 - val_loss: 0.6564 - val_acc: 0.9808 - val_mDice: 0.8172

Epoch 00121: val_mDice improved from 0.81511 to 0.81720, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 122/300
 - 28s - loss: 0.4584 - acc: 0.9740 - mDice: 0.8434 - val_loss: 0.6618 - val_acc: 0.9818 - val_mDice: 0.8104

Epoch 00122: val_mDice did not improve from 0.81720
Epoch 123/300
 - 26s - loss: 0.4590 - acc: 0.9740 - mDice: 0.8431 - val_loss: 0.6549 - val_acc: 0.9811 - val_mDice: 0.8159

Epoch 00123: val_mDice did not improve from 0.81720
Epoch 124/300
 - 27s - loss: 0.4565 - acc: 0.9741 - mDice: 0.8438 - val_loss: 0.6620 - val_acc: 0.9815 - val_mDice: 0.8089

Epoch 00124: val_mDice did not improve from 0.81720
Epoch 125/300
 - 28s - loss: 0.4559 - acc: 0.9741 - mDice: 0.8441 - val_loss: 0.6648 - val_acc: 0.9811 - val_mDice: 0.8143

Epoch 00125: val_mDice did not improve from 0.81720
Epoch 126/300
 - 27s - loss: 0.4564 - acc: 0.9741 - mDice: 0.8442 - val_loss: 0.6505 - val_acc: 0.9813 - val_mDice: 0.8156

Epoch 00126: val_mDice did not improve from 0.81720
Epoch 127/300
 - 27s - loss: 0.4557 - acc: 0.9741 - mDice: 0.8441 - val_loss: 0.6575 - val_acc: 0.9810 - val_mDice: 0.8116

Epoch 00127: val_mDice did not improve from 0.81720
Epoch 128/300
 - 28s - loss: 0.4564 - acc: 0.9741 - mDice: 0.8441 - val_loss: 0.6627 - val_acc: 0.9813 - val_mDice: 0.8150

Epoch 00128: val_mDice did not improve from 0.81720
Epoch 129/300
 - 27s - loss: 0.4542 - acc: 0.9742 - mDice: 0.8447 - val_loss: 0.6602 - val_acc: 0.9813 - val_mDice: 0.8157

Epoch 00129: val_mDice did not improve from 0.81720
Epoch 130/300
 - 28s - loss: 0.4517 - acc: 0.9742 - mDice: 0.8455 - val_loss: 0.6640 - val_acc: 0.9817 - val_mDice: 0.8167

Epoch 00130: val_mDice did not improve from 0.81720
Epoch 131/300
 - 27s - loss: 0.4525 - acc: 0.9742 - mDice: 0.8453 - val_loss: 0.6502 - val_acc: 0.9815 - val_mDice: 0.8118

Epoch 00131: val_mDice did not improve from 0.81720
Epoch 132/300
 - 28s - loss: 0.4506 - acc: 0.9742 - mDice: 0.8459 - val_loss: 0.6685 - val_acc: 0.9814 - val_mDice: 0.8142

Epoch 00132: val_mDice did not improve from 0.81720
Epoch 133/300
 - 27s - loss: 0.4508 - acc: 0.9742 - mDice: 0.8460 - val_loss: 0.6702 - val_acc: 0.9809 - val_mDice: 0.8135

Epoch 00133: val_mDice did not improve from 0.81720
Epoch 134/300
 - 28s - loss: 0.4505 - acc: 0.9742 - mDice: 0.8463 - val_loss: 0.6776 - val_acc: 0.9815 - val_mDice: 0.8155

Epoch 00134: val_mDice did not improve from 0.81720
Epoch 135/300
 - 26s - loss: 0.4493 - acc: 0.9742 - mDice: 0.8465 - val_loss: 0.6777 - val_acc: 0.9809 - val_mDice: 0.8123

Epoch 00135: val_mDice did not improve from 0.81720
Epoch 136/300
 - 27s - loss: 0.4478 - acc: 0.9742 - mDice: 0.8470 - val_loss: 0.6806 - val_acc: 0.9814 - val_mDice: 0.8100

Epoch 00136: val_mDice did not improve from 0.81720
Epoch 137/300
 - 28s - loss: 0.4506 - acc: 0.9742 - mDice: 0.8461 - val_loss: 0.6665 - val_acc: 0.9811 - val_mDice: 0.8125

Epoch 00137: val_mDice did not improve from 0.81720
Epoch 138/300
 - 29s - loss: 0.4471 - acc: 0.9743 - mDice: 0.8473 - val_loss: 0.6692 - val_acc: 0.9809 - val_mDice: 0.8154

Epoch 00138: val_mDice did not improve from 0.81720
Epoch 139/300
 - 28s - loss: 0.4478 - acc: 0.9743 - mDice: 0.8470 - val_loss: 0.6669 - val_acc: 0.9816 - val_mDice: 0.8146

Epoch 00139: val_mDice did not improve from 0.81720
Epoch 140/300
 - 28s - loss: 0.4467 - acc: 0.9743 - mDice: 0.8473 - val_loss: 0.6675 - val_acc: 0.9819 - val_mDice: 0.8125

Epoch 00140: val_mDice did not improve from 0.81720
Epoch 141/300
 - 28s - loss: 0.4456 - acc: 0.9743 - mDice: 0.8478 - val_loss: 0.6835 - val_acc: 0.9813 - val_mDice: 0.8092

Epoch 00141: val_mDice did not improve from 0.81720
Epoch 142/300
 - 29s - loss: 0.4453 - acc: 0.9743 - mDice: 0.8479 - val_loss: 0.6588 - val_acc: 0.9806 - val_mDice: 0.8137

Epoch 00142: val_mDice did not improve from 0.81720
Epoch 143/300
 - 29s - loss: 0.4436 - acc: 0.9743 - mDice: 0.8485 - val_loss: 0.6833 - val_acc: 0.9809 - val_mDice: 0.8138

Epoch 00143: val_mDice did not improve from 0.81720
Epoch 144/300
 - 29s - loss: 0.4444 - acc: 0.9743 - mDice: 0.8481 - val_loss: 0.6704 - val_acc: 0.9815 - val_mDice: 0.8134

Epoch 00144: val_mDice did not improve from 0.81720
Epoch 145/300
 - 29s - loss: 0.4425 - acc: 0.9743 - mDice: 0.8488 - val_loss: 0.6780 - val_acc: 0.9819 - val_mDice: 0.8161

Epoch 00145: val_mDice did not improve from 0.81720
Epoch 146/300
 - 29s - loss: 0.4423 - acc: 0.9743 - mDice: 0.8490 - val_loss: 0.6757 - val_acc: 0.9807 - val_mDice: 0.8118

Epoch 00146: val_mDice did not improve from 0.81720
Epoch 147/300
 - 29s - loss: 0.4411 - acc: 0.9744 - mDice: 0.8494 - val_loss: 0.6715 - val_acc: 0.9815 - val_mDice: 0.8114

Epoch 00147: val_mDice did not improve from 0.81720
Epoch 148/300
 - 29s - loss: 0.4422 - acc: 0.9743 - mDice: 0.8489 - val_loss: 0.6826 - val_acc: 0.9815 - val_mDice: 0.8136

Epoch 00148: val_mDice did not improve from 0.81720
Epoch 149/300
 - 29s - loss: 0.4411 - acc: 0.9743 - mDice: 0.8493 - val_loss: 0.6724 - val_acc: 0.9816 - val_mDice: 0.8149

Epoch 00149: val_mDice did not improve from 0.81720
Epoch 150/300
 - 29s - loss: 0.4425 - acc: 0.9743 - mDice: 0.8488 - val_loss: 0.6905 - val_acc: 0.9811 - val_mDice: 0.8128

Epoch 00150: val_mDice did not improve from 0.81720
Epoch 151/300
 - 30s - loss: 0.4405 - acc: 0.9744 - mDice: 0.8496 - val_loss: 0.6694 - val_acc: 0.9812 - val_mDice: 0.8138

Epoch 00151: val_mDice did not improve from 0.81720
Restoring model weights from the end of the best epoch
Epoch 00151: early stopping
{'val_loss': [3.6316428315149594, 2.2436252930392957, 1.4335470493525675, 1.0928830655470287, 0.9045209925468654, 0.8274054074124114, 0.832041570176817, 0.8084769804183751, 0.7801721879880722, 0.7571502409569205, 0.7552987561650473, 0.738368228690265, 0.7445114275364026, 0.7372890461797583, 0.7477379853594793, 0.7139710175664458, 0.7104964693115182, 0.7207297205108486, 0.7020814965849054, 0.6973435903248721, 0.6955078129899012, 0.7011116959460794, 0.6934726915947379, 0.6796225386939637, 0.6915004004354346, 0.6999272148903102, 0.684144623067281, 0.6820105065221655, 0.687855794005198, 0.6893104551589653, 0.6851726488707817, 0.6752378124080293, 0.6753868407582584, 0.6948819082893737, 0.6751164055033906, 0.7075793779876134, 0.6846346224415792, 0.6764994671899979, 0.6807535915342096, 0.679667036623171, 0.6666252488551074, 0.6744417933976814, 0.681387041529564, 0.680497021299519, 0.6766829760107276, 0.6921244051358472, 0.6701382996693049, 0.6713301574122416, 0.6741821306617293, 0.6735011851542616, 0.6736572913519324, 0.6719341657749595, 0.6852668242095268, 0.6837134063243866, 0.6734470549511583, 0.6850342342298325, 0.6772528972527753, 0.6595281231893252, 0.6669823641646399, 0.6792925865682837, 0.6696545965459249, 0.6792205302682641, 0.6907416596396329, 0.681699565420412, 0.6713065682616952, 0.6757507773294841, 0.6665844843812185, 0.6690385039538553, 0.648315718729202, 0.6496366836028556, 0.6748549135988706, 0.6648495703527372, 0.650073136368843, 0.636844228391778, 0.6543773984255856, 0.6501813928966653, 0.6445317186721383, 0.6506174568035831, 0.643914937360646, 0.6515929676490287, 0.6430969946596721, 0.6633877425569378, 0.6629617130511427, 0.6415750212865333, 0.6429767424929632, 0.6443646380754366, 0.6551094953327963, 0.6376189013866529, 0.6468157037480237, 0.644928366354067, 0.6570355230814791, 0.6578475073592304, 0.6485798593661557, 0.6453445116951041, 0.6554751285951431, 0.6474570491134304, 0.6660369079406947, 0.660761907288473, 0.6530491421892218, 0.6540715829150318, 0.6479455457158285, 0.655528623355578, 0.6586903917462859, 0.6678256582315654, 0.6832101669621794, 0.6446000125310193, 0.6488249857131749, 0.6592852244638416, 0.6687234186962859, 0.6514214495681736, 0.657019072607772, 0.6773106104707065, 0.6585004450115439, 0.6609249094577685, 0.6548662246906594, 0.6428155262176305, 0.6758615980817847, 0.6609132142916118, 0.6823435513532325, 0.659854142633203, 0.6563522699352813, 0.66183890177779, 0.6549362232015558, 0.6619657337257306, 0.6648105519683394, 0.6504977727181291, 0.6575053485289012, 0.6626588847130945, 0.6601834140003544, 0.6640089762537447, 0.6502362704032087, 0.6684862652870074, 0.6701975511769726, 0.6775743767415008, 0.6776698333759831, 0.6805553115802269, 0.6665340253751572, 0.6692481267533891, 0.6669035284486535, 0.6675088193318616, 0.6834675120572521, 0.6587915004116215, 0.6832767643340646, 0.6704197654577151, 0.6779724294192171, 0.6756669811598243, 0.6715365878931464, 0.6826328312697476, 0.672408549344703, 0.6904603371473208, 0.6693684838406028], 'val_acc': [0.9128062990430283, 0.9412307914805739, 0.9631827420567813, 0.96725935478733, 0.9724833548885502, 0.9744883498100385, 0.9751210020829554, 0.9757008830161944, 0.976170102619145, 0.9752443971699232, 0.9753536014524224, 0.9774903838765131, 0.9772035312162687, 0.9768467896605191, 0.9757776787019756, 0.9781983984659796, 0.9780844429584399, 0.9774463319615142, 0.977543149908928, 0.9791790402098878, 0.9792241776642734, 0.9787167425025, 0.9777582981815077, 0.9782453436557561, 0.9786894505154596, 0.9789380663878298, 0.9790246992895048, 0.9793399384576981, 0.9795310476871386, 0.9798481064300014, 0.9797844058030272, 0.9781430633100745, 0.9793970903305158, 0.9801658959421393, 0.9796799225349949, 0.9796995863522568, 0.9803071397624604, 0.979304263036545, 0.9792674996264993, 0.9805877776178595, 0.9801731754655707, 0.9797876803842309, 0.9791259079763334, 0.9802783678655755, 0.980081803994636, 0.9791273654323734, 0.9800810785326239, 0.9797105144148004, 0.9801997517886227, 0.9802241288635829, 0.980613259828254, 0.9791921430254635, 0.9803839342234886, 0.9799482054906349, 0.9799500336385754, 0.9800417582466178, 0.979504842464238, 0.9804469118379566, 0.9809590835277349, 0.9795357801326333, 0.9798568234051743, 0.9799143618916812, 0.9793686772862525, 0.980252888921189, 0.9804760372802003, 0.9808986497251955, 0.9800908932947132, 0.9803402513673861, 0.9811567378370729, 0.9807424941291548, 0.9805397415814334, 0.9801211079506025, 0.9804887820596564, 0.9809652538332221, 0.9803158571458843, 0.9817457223591739, 0.9805430084058683, 0.9798331893470189, 0.980660226655333, 0.97997623641197, 0.9812197117772821, 0.9809062978992723, 0.9801185637304227, 0.9807373999732815, 0.9798604837835652, 0.9816638112884678, 0.9809987622581117, 0.981176396755323, 0.9807996325296898, 0.9806227259439965, 0.9804556459596713, 0.9809175725669077, 0.9816212396915645, 0.9811115922176674, 0.9810540900654989, 0.9806620441887477, 0.98026272082982, 0.9813249123423067, 0.9811261520810324, 0.9813372803060976, 0.9810970384780675, 0.9805277136907186, 0.9810795796244112, 0.9813747761184222, 0.9803544568688902, 0.9819983358252539, 0.9814566843313713, 0.9807985424995422, 0.9803533603067267, 0.9810355317919222, 0.9814057272591002, 0.9814504907555777, 0.9808804596940132, 0.9813271079161395, 0.981326021560251, 0.9817762995419437, 0.9809743615045939, 0.9812386313529864, 0.9817158739044242, 0.981265956408357, 0.9808487945223507, 0.9817639172893681, 0.9811272645649844, 0.9815065566807577, 0.9810770178494388, 0.9813300158879529, 0.9809739912209445, 0.9813223734293899, 0.9812746893053186, 0.9816707282850187, 0.9814974612569156, 0.9813678570806164, 0.98094379493635, 0.9814861755665034, 0.9808757133679847, 0.9813787855514108, 0.9810966914647246, 0.9808877375844407, 0.9815600673629813, 0.9819211661815643, 0.9813456743547361, 0.9805786928085432, 0.9809423256410311, 0.9814737904561709, 0.9819422862301134, 0.9807020817717461, 0.9815495144830991, 0.9815003704534818, 0.9816310511876459, 0.9811298022531483, 0.9812437471461622], 'val_mDice': [0.061917191856119734, 0.2618443531124559, 0.5083675155900929, 0.6393508996865521, 0.7054343840030775, 0.7308180344431368, 0.73354513187931, 0.7399620940423992, 0.747172084981448, 0.7579190661645916, 0.7599119503204137, 0.7606131034354641, 0.7642178976372497, 0.7648479893599471, 0.7640931042906356, 0.7662933917894755, 0.7694130637874342, 0.7675354746106553, 0.7712713304447801, 0.7709641419861415, 0.7745049012033907, 0.7760454024354072, 0.7742460892625052, 0.7740185709848796, 0.7755385253527393, 0.768628425794105, 0.7780483859042598, 0.7734018368263768, 0.7742293758751595, 0.7741244574115701, 0.7745749215557151, 0.7823872868328878, 0.7787830156006225, 0.7737480626530844, 0.7794422842051885, 0.774512573464276, 0.7779647495648633, 0.7809748453636692, 0.7753749301988785, 0.7785355824313752, 0.7796429412005699, 0.7825224681259835, 0.7796308908560504, 0.7800423049763457, 0.7817493591406574, 0.7805708426318757, 0.7846577253243695, 0.7813334167003632, 0.7823798133902353, 0.7798638870454815, 0.7834000611958438, 0.784492357544703, 0.7824349930025127, 0.7818164241640535, 0.7854044355758248, 0.7824682679078351, 0.7850228580710006, 0.7875082990894579, 0.7841927396924528, 0.7816105803398237, 0.7848435562767394, 0.7892993268084852, 0.7851420971628738, 0.788418369342203, 0.7905287424178973, 0.7842673504189269, 0.7892509343689436, 0.7890436526847212, 0.7953518686229235, 0.7956069360857141, 0.7898399878854621, 0.7981269776004635, 0.8011645882913511, 0.7987148990369823, 0.7974131817687048, 0.8001984333338803, 0.8019857720969474, 0.8045904415927522, 0.8019723806479205, 0.8035921593234964, 0.8072369768194956, 0.8019032760025704, 0.8056892381138998, 0.8093769905501849, 0.8054723453848329, 0.8054592188906996, 0.8016942796641833, 0.8077628098122062, 0.8097455289265881, 0.8082953373046771, 0.8057372345499796, 0.8043344412764458, 0.8064472222164886, 0.8092164209444229, 0.8127305968983533, 0.8117507304230781, 0.810063852022772, 0.8076160586860082, 0.8089288713997358, 0.8104232051601149, 0.8141945473951836, 0.8097787336127399, 0.8100033451433051, 0.8094569893732463, 0.808195268454617, 0.812167032124245, 0.810267009147226, 0.8113285437838672, 0.8123662337048413, 0.8120334577070524, 0.8119930412671338, 0.809092057486103, 0.810255328678105, 0.8151130623196903, 0.8108952171998481, 0.8118732167433386, 0.8134641055374929, 0.8117551485153094, 0.8114866634754285, 0.8147696991489358, 0.8171950656257264, 0.8104209099730401, 0.815852262385904, 0.8088516401101465, 0.8142847729055849, 0.8155901064611462, 0.8116464774086051, 0.8150195667188461, 0.8156706780603488, 0.8166520995636509, 0.8118177517636181, 0.8142298672297229, 0.8135038397900046, 0.8155268618505295, 0.812323562086445, 0.8100028356460676, 0.8125331989706379, 0.8153530587888744, 0.8146361986251727, 0.8124504791547175, 0.8092105200845902, 0.8137412895895031, 0.8138462349976578, 0.8133531710872911, 0.8160730690172274, 0.8117972285780188, 0.811384573374709, 0.8136352218993722, 0.8148868500369869, 0.8128146476125064, 0.8138111519486937], 'loss': [21.05576618772925, 3.5240574850048567, 2.2852769059510716, 1.7047190623453676, 1.417740236894729, 1.268789185559102, 1.173813955655379, 1.0967855753022577, 1.0393046104633363, 0.9914480457722902, 0.9562348521579069, 0.9193215422833924, 0.8895452771409631, 0.8673517156209744, 0.8509418732922096, 0.8294264009225351, 0.8091586143564067, 0.7940637161343452, 0.7813559918698015, 0.768266019075599, 0.753442121546575, 0.7441232569781067, 0.7369838104609312, 0.7236129053888956, 0.7169624960340932, 0.7076564995609046, 0.7007123398243063, 0.6932214993405925, 0.6901527444545524, 0.6811661319598455, 0.6730616406504691, 0.6689600752008307, 0.6631199723597325, 0.6595563753334102, 0.6554464411671475, 0.6503177342072896, 0.6449122508337218, 0.6419196745459846, 0.6333259379492018, 0.6300933117754253, 0.6264505779316893, 0.6231833182275655, 0.6224000379303127, 0.6150407598253514, 0.6143613594202508, 0.6112315772217356, 0.6071979611935377, 0.6020863114196057, 0.5986662306962653, 0.5977138689991549, 0.5932535941649405, 0.5924974021463373, 0.5893361835578785, 0.5875058892798876, 0.5842845179634305, 0.5817075311488384, 0.5786228893297173, 0.5761689047387344, 0.5758059477382662, 0.5716715996449491, 0.5702612620085669, 0.568861371353739, 0.5661554095733481, 0.5647408547094169, 0.5619043775900708, 0.5585664700178291, 0.5562828064705988, 0.5498226277095346, 0.5461968821533342, 0.5449457702705548, 0.5379572448210403, 0.535278940882055, 0.5318191899317501, 0.5291342394033899, 0.5271428779734951, 0.5225964270216499, 0.5189492675782835, 0.5176135577465047, 0.5157865104149483, 0.5129946778072404, 0.5097248626089113, 0.506654862939803, 0.5059230550739402, 0.5051278238184705, 0.5005222590086035, 0.49955173594083285, 0.4986051536176893, 0.4961994139358126, 0.4940171760223568, 0.492826195115859, 0.49014157045748763, 0.4886604659569925, 0.48768419990743966, 0.4865007651819425, 0.483878230465723, 0.48383615265593966, 0.4829367078670887, 0.4806957447868961, 0.47838037778003584, 0.4788234446999757, 0.47830814019163703, 0.4779452467887992, 0.4752411102875439, 0.47415507153876635, 0.4723486287463768, 0.471863836687044, 0.47144286633916715, 0.47003772798070126, 0.4687598230488427, 0.46735864772777214, 0.4683649448108843, 0.467139727755813, 0.4654803820752633, 0.4652401086473886, 0.4634770634894061, 0.4628244332656429, 0.46202093045595694, 0.4616547737067174, 0.45863076734240643, 0.45874501768867854, 0.45781820967755404, 0.45844800822708637, 0.45895504731719217, 0.45652028009646645, 0.45593817830961914, 0.4563630699365936, 0.4556800844000129, 0.4564052271565171, 0.4542285490143161, 0.4517311995342798, 0.452523090865642, 0.45063983830602905, 0.45084418387515063, 0.45052050910338914, 0.4492812674975383, 0.44777668300416246, 0.4506310770257857, 0.44712518569667503, 0.4478335673105022, 0.44670711612062536, 0.44563698075301295, 0.4453202515920965, 0.4435816922736884, 0.4443978107910891, 0.44248209630065877, 0.4423112836227204, 0.4411177735958302, 0.44218119576589887, 0.4410881198211212, 0.44248163063811463, 0.44045403070883943], 'acc': [0.8553174576837934, 0.9100735292123756, 0.9354560102311736, 0.9478858280850638, 0.9554719552430045, 0.9586942737616942, 0.960719553986149, 0.9622932510167077, 0.9634499148786129, 0.9644283433036118, 0.9650938419716819, 0.9658072692720888, 0.9663564739666696, 0.9667779364220016, 0.9670735627773314, 0.967490114210956, 0.9678574092152941, 0.9681203591748314, 0.9684008920420807, 0.9686137642583029, 0.9688929950273424, 0.9690256477338767, 0.969170845766011, 0.9694174765948761, 0.9695964065814479, 0.969800241203548, 0.9699064497574478, 0.9699965461063766, 0.970087167156582, 0.9702229509641362, 0.9703941142147113, 0.9704543074772578, 0.970582745958164, 0.9706485915128866, 0.9707416946861886, 0.9707854865539435, 0.9708823271157155, 0.9709057895653138, 0.9710819321521202, 0.9711465475628064, 0.971242661875204, 0.9712501501047707, 0.9712737882026414, 0.971420883112594, 0.9714107715317678, 0.9714595926452001, 0.9715336563501125, 0.9716171268624187, 0.9716874736062854, 0.9716964176697491, 0.971771864786143, 0.9717719071778603, 0.971850050300614, 0.9718261896526907, 0.9719495334661554, 0.971992268821545, 0.9720396009937724, 0.9720572169139946, 0.9720449389374465, 0.9721398848591957, 0.9721749446220734, 0.9722112870037116, 0.9722239293818405, 0.9722300069930438, 0.9723141638507233, 0.9723573160163466, 0.9723734327773427, 0.9724551302374711, 0.9725103540514526, 0.9725497261754771, 0.9726562707003263, 0.9727176748429087, 0.9727871998418491, 0.9728573827497861, 0.9729091212878062, 0.9730047317831032, 0.9730180008445075, 0.9730487261612942, 0.9731092692926778, 0.9731349667110606, 0.9731848500448167, 0.973242553112116, 0.9732174628487242, 0.973261160269445, 0.9733425301180396, 0.9733686970195929, 0.9733793310811362, 0.9734754989024121, 0.9734847342469869, 0.9735066013380076, 0.9734935688135957, 0.9735672443572272, 0.9735469392675555, 0.9736030054549734, 0.9736193744175302, 0.9736499899071069, 0.9736791678730669, 0.9736791567099434, 0.9737598917686403, 0.9736859697400245, 0.9737433126802485, 0.9737337070681387, 0.9737736837100601, 0.9737932613639523, 0.9738151669456296, 0.9738463840718338, 0.9738264044736792, 0.9738649911516011, 0.9738668049983021, 0.9738853794188952, 0.9739271300580968, 0.9739275931151461, 0.9739427454868359, 0.97396102335213, 0.9739756250336656, 0.9739685642057985, 0.9740004285145187, 0.9739943731807273, 0.974088016202797, 0.9740354781369369, 0.974048765850467, 0.9740482239161544, 0.9740470531555686, 0.9741003927285254, 0.9741159253387234, 0.9740850755758036, 0.9740939384868641, 0.974102605419898, 0.9741612934274521, 0.9741761770654721, 0.9741648802602599, 0.974176057655097, 0.9741923563928166, 0.9742143249774854, 0.9742221196586353, 0.9742490265437095, 0.9741659969288192, 0.9742837477473789, 0.9742579492001747, 0.9742606451318456, 0.9742793014804578, 0.9743059791078383, 0.9743200978851759, 0.974308757208831, 0.9743466544618974, 0.9743007851414545, 0.9743550560538629, 0.9743214611880974, 0.9743204059138448, 0.9743128331306555, 0.974374748157061], 'mDice': [0.03645682659742918, 0.15099609530577057, 0.35765887508392796, 0.4944741172907502, 0.573930557000849, 0.6144627627593775, 0.6395078663728548, 0.6600733716359535, 0.6750251612201806, 0.6873270225436424, 0.6965582358233297, 0.7060649681507268, 0.7139897078162211, 0.719282960120704, 0.7235480841800238, 0.7294223190841976, 0.734600689843325, 0.7384662211984088, 0.7420632234423573, 0.7453089356508604, 0.749243760948911, 0.7517699239351553, 0.7537747260874866, 0.7576707938250716, 0.7591926205375981, 0.7617157657460492, 0.7639997425300655, 0.7661723622736158, 0.7670725779657714, 0.7695622832621487, 0.7720289442520715, 0.7733913959638258, 0.7751157157443749, 0.7760196912029552, 0.7771635391125133, 0.7787425713203827, 0.7803636693059349, 0.781237350230539, 0.7842840425157738, 0.7848729898776886, 0.7860936721845836, 0.7873221976773481, 0.787198506807372, 0.7895781200066194, 0.7897415032265669, 0.7906770898730584, 0.7921523531980816, 0.7935920110627412, 0.7947463460201596, 0.7950945554960147, 0.7963904133589448, 0.796674923179431, 0.7975854145612445, 0.7981486715772443, 0.7993036836674429, 0.7999985535820798, 0.8009386730341171, 0.8015435288581994, 0.8019274877113827, 0.803240296294749, 0.8037271040124464, 0.8039840084540424, 0.8050222219263273, 0.8054222064889467, 0.8063399479000694, 0.8075993585123477, 0.8085879546066923, 0.8108384488571051, 0.8120703823917245, 0.8128523164596596, 0.815419057615292, 0.8163966881038999, 0.8179218105778269, 0.8187765132789698, 0.8195219189869397, 0.8211209752242636, 0.8223265644940844, 0.8227675247838155, 0.8232376973734367, 0.8245078097240535, 0.8257498983888949, 0.8267395539228368, 0.8269668228281878, 0.8273308628455398, 0.8288535211906588, 0.8291963929583971, 0.8296394405913552, 0.83059124604404, 0.8311840439194386, 0.8315570534950361, 0.8324655670908033, 0.8329437028368362, 0.8334019556609261, 0.8336871670087485, 0.8345067406960054, 0.8345487126959819, 0.8350212323969546, 0.8357545734342365, 0.836544118270431, 0.8363723084405966, 0.8365549821785613, 0.836771064436265, 0.8376251308020238, 0.8379019222820723, 0.838338482040366, 0.8386935415575433, 0.8390424444196403, 0.8391397621230715, 0.839777514138126, 0.840381499376462, 0.8400969211265457, 0.8405269192864484, 0.8408562103474454, 0.8409627259360767, 0.8415371767727344, 0.8418229301841387, 0.8421362352472334, 0.8422718375290702, 0.8433160613752789, 0.8431720036708612, 0.8435041562230496, 0.8433790861500264, 0.8431387618855571, 0.843841096976733, 0.8441176500267118, 0.8441525029989029, 0.8441396659182046, 0.844062579368142, 0.8446736951622137, 0.8455424770325762, 0.8453309916491635, 0.8458636800802394, 0.8459969741636612, 0.8462735171019069, 0.8464801684248171, 0.8470460250984474, 0.8460739278219954, 0.8473043733834933, 0.8469862169176994, 0.8473361914683792, 0.8478138185942384, 0.847943151047146, 0.8485434208268332, 0.8481313606113794, 0.8487890099087614, 0.8489956295578168, 0.849391644848669, 0.848938696188745, 0.8492847246413369, 0.8488273283528549, 0.8495933993924778]}
predicting test subjects:   0%|          | 0/15 [00:00<?, ?it/s]predicting test subjects:   7%|▋         | 1/15 [00:02<00:30,  2.14s/it]predicting test subjects:  13%|█▎        | 2/15 [00:04<00:26,  2.06s/it]predicting test subjects:  20%|██        | 3/15 [00:06<00:25,  2.08s/it]predicting test subjects:  27%|██▋       | 4/15 [00:08<00:23,  2.13s/it]predicting test subjects:  33%|███▎      | 5/15 [00:10<00:22,  2.24s/it]predicting test subjects:  40%|████      | 6/15 [00:13<00:21,  2.35s/it]predicting test subjects:  47%|████▋     | 7/15 [00:15<00:17,  2.16s/it]predicting test subjects:  53%|█████▎    | 8/15 [00:17<00:15,  2.28s/it]predicting test subjects:  60%|██████    | 9/15 [00:19<00:13,  2.19s/it]predicting test subjects:  67%|██████▋   | 10/15 [00:21<00:10,  2.10s/it]predicting test subjects:  73%|███████▎  | 11/15 [00:23<00:07,  2.00s/it]predicting test subjects:  80%|████████  | 12/15 [00:25<00:06,  2.14s/it]predicting test subjects:  87%|████████▋ | 13/15 [00:27<00:04,  2.11s/it]predicting test subjects:  93%|█████████▎| 14/15 [00:29<00:02,  2.04s/it]predicting test subjects: 100%|██████████| 15/15 [00:31<00:00,  2.08s/it]
predicting train subjects:   0%|          | 0/532 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/532 [00:02<20:41,  2.34s/it]predicting train subjects:   0%|          | 2/532 [00:03<18:49,  2.13s/it]predicting train subjects:   1%|          | 3/532 [00:06<18:40,  2.12s/it]predicting train subjects:   1%|          | 4/532 [00:07<18:02,  2.05s/it]predicting train subjects:   1%|          | 5/532 [00:10<18:11,  2.07s/it]predicting train subjects:   1%|          | 6/532 [00:11<17:15,  1.97s/it]predicting train subjects:   1%|▏         | 7/532 [00:13<16:54,  1.93s/it]predicting train subjects:   2%|▏         | 8/532 [00:15<16:53,  1.93s/it]predicting train subjects:   2%|▏         | 9/532 [00:18<18:05,  2.08s/it]predicting train subjects:   2%|▏         | 10/532 [00:19<17:23,  2.00s/it]predicting train subjects:   2%|▏         | 11/532 [00:21<16:44,  1.93s/it]predicting train subjects:   2%|▏         | 12/532 [00:24<18:25,  2.13s/it]predicting train subjects:   2%|▏         | 13/532 [00:25<16:42,  1.93s/it]predicting train subjects:   3%|▎         | 14/532 [00:27<15:44,  1.82s/it]predicting train subjects:   3%|▎         | 15/532 [00:29<15:59,  1.86s/it]predicting train subjects:   3%|▎         | 16/532 [00:31<16:09,  1.88s/it]predicting train subjects:   3%|▎         | 17/532 [00:32<15:34,  1.82s/it]predicting train subjects:   3%|▎         | 18/532 [00:34<16:21,  1.91s/it]predicting train subjects:   4%|▎         | 19/532 [00:36<15:11,  1.78s/it]predicting train subjects:   4%|▍         | 20/532 [00:38<15:13,  1.78s/it]predicting train subjects:   4%|▍         | 21/532 [00:40<16:38,  1.95s/it]predicting train subjects:   4%|▍         | 22/532 [00:42<15:53,  1.87s/it]predicting train subjects:   4%|▍         | 23/532 [00:44<16:09,  1.90s/it]predicting train subjects:   5%|▍         | 24/532 [00:45<15:18,  1.81s/it]predicting train subjects:   5%|▍         | 25/532 [00:48<16:37,  1.97s/it]predicting train subjects:   5%|▍         | 26/532 [00:49<15:42,  1.86s/it]predicting train subjects:   5%|▌         | 27/532 [00:52<17:25,  2.07s/it]predicting train subjects:   5%|▌         | 28/532 [00:54<16:36,  1.98s/it]predicting train subjects:   5%|▌         | 29/532 [00:56<17:25,  2.08s/it]predicting train subjects:   6%|▌         | 30/532 [00:58<16:35,  1.98s/it]predicting train subjects:   6%|▌         | 31/532 [00:59<16:02,  1.92s/it]predicting train subjects:   6%|▌         | 32/532 [01:01<16:07,  1.94s/it]predicting train subjects:   6%|▌         | 33/532 [01:03<15:21,  1.85s/it]predicting train subjects:   6%|▋         | 34/532 [01:05<16:14,  1.96s/it]predicting train subjects:   7%|▋         | 35/532 [01:07<16:19,  1.97s/it]predicting train subjects:   7%|▋         | 36/532 [01:09<16:29,  1.99s/it]predicting train subjects:   7%|▋         | 37/532 [01:11<16:28,  2.00s/it]predicting train subjects:   7%|▋         | 38/532 [01:14<17:05,  2.08s/it]predicting train subjects:   7%|▋         | 39/532 [01:15<16:28,  2.01s/it]predicting train subjects:   8%|▊         | 40/532 [01:17<16:03,  1.96s/it]predicting train subjects:   8%|▊         | 41/532 [01:19<16:15,  1.99s/it]predicting train subjects:   8%|▊         | 42/532 [01:21<16:11,  1.98s/it]predicting train subjects:   8%|▊         | 43/532 [01:23<15:36,  1.91s/it]predicting train subjects:   8%|▊         | 44/532 [01:25<14:50,  1.83s/it]predicting train subjects:   8%|▊         | 45/532 [01:26<14:18,  1.76s/it]predicting train subjects:   9%|▊         | 46/532 [01:28<14:30,  1.79s/it]predicting train subjects:   9%|▉         | 47/532 [01:31<16:36,  2.06s/it]predicting train subjects:   9%|▉         | 48/532 [01:33<16:10,  2.01s/it]predicting train subjects:   9%|▉         | 49/532 [01:34<15:01,  1.87s/it]predicting train subjects:   9%|▉         | 50/532 [01:36<15:56,  1.98s/it]predicting train subjects:  10%|▉         | 51/532 [01:38<15:28,  1.93s/it]predicting train subjects:  10%|▉         | 52/532 [01:40<15:32,  1.94s/it]predicting train subjects:  10%|▉         | 53/532 [01:42<15:35,  1.95s/it]predicting train subjects:  10%|█         | 54/532 [01:45<16:26,  2.06s/it]predicting train subjects:  10%|█         | 55/532 [01:47<16:53,  2.12s/it]predicting train subjects:  11%|█         | 56/532 [01:49<16:39,  2.10s/it]predicting train subjects:  11%|█         | 57/532 [01:51<15:54,  2.01s/it]predicting train subjects:  11%|█         | 58/532 [01:53<16:15,  2.06s/it]predicting train subjects:  11%|█         | 59/532 [01:55<17:02,  2.16s/it]predicting train subjects:  11%|█▏        | 60/532 [01:57<15:53,  2.02s/it]predicting train subjects:  11%|█▏        | 61/532 [01:59<15:42,  2.00s/it]predicting train subjects:  12%|█▏        | 62/532 [02:01<15:58,  2.04s/it]predicting train subjects:  12%|█▏        | 63/532 [02:03<16:51,  2.16s/it]predicting train subjects:  12%|█▏        | 64/532 [02:05<15:45,  2.02s/it]predicting train subjects:  12%|█▏        | 65/532 [02:07<15:33,  2.00s/it]predicting train subjects:  12%|█▏        | 66/532 [02:10<17:22,  2.24s/it]predicting train subjects:  13%|█▎        | 67/532 [02:12<17:52,  2.31s/it]predicting train subjects:  13%|█▎        | 68/532 [02:14<17:22,  2.25s/it]predicting train subjects:  13%|█▎        | 69/532 [02:16<16:10,  2.10s/it]predicting train subjects:  13%|█▎        | 70/532 [02:18<15:51,  2.06s/it]predicting train subjects:  13%|█▎        | 71/532 [02:20<15:14,  1.98s/it]predicting train subjects:  14%|█▎        | 72/532 [02:22<14:22,  1.87s/it]predicting train subjects:  14%|█▎        | 73/532 [02:24<15:00,  1.96s/it]predicting train subjects:  14%|█▍        | 74/532 [02:26<16:10,  2.12s/it]predicting train subjects:  14%|█▍        | 75/532 [02:29<18:17,  2.40s/it]predicting train subjects:  14%|█▍        | 76/532 [02:31<16:54,  2.22s/it]predicting train subjects:  14%|█▍        | 77/532 [02:33<16:40,  2.20s/it]predicting train subjects:  15%|█▍        | 78/532 [02:35<16:32,  2.19s/it]predicting train subjects:  15%|█▍        | 79/532 [02:37<15:52,  2.10s/it]predicting train subjects:  15%|█▌        | 80/532 [02:39<15:45,  2.09s/it]predicting train subjects:  15%|█▌        | 81/532 [02:41<15:21,  2.04s/it]predicting train subjects:  15%|█▌        | 82/532 [02:44<15:52,  2.12s/it]predicting train subjects:  16%|█▌        | 83/532 [02:46<15:25,  2.06s/it]predicting train subjects:  16%|█▌        | 84/532 [02:47<14:21,  1.92s/it]predicting train subjects:  16%|█▌        | 85/532 [02:49<14:00,  1.88s/it]predicting train subjects:  16%|█▌        | 86/532 [02:51<13:48,  1.86s/it]predicting train subjects:  16%|█▋        | 87/532 [02:52<13:23,  1.81s/it]predicting train subjects:  17%|█▋        | 88/532 [02:54<13:29,  1.82s/it]predicting train subjects:  17%|█▋        | 89/532 [02:56<13:52,  1.88s/it]predicting train subjects:  17%|█▋        | 90/532 [02:58<14:17,  1.94s/it]predicting train subjects:  17%|█▋        | 91/532 [03:00<14:17,  1.94s/it]predicting train subjects:  17%|█▋        | 92/532 [03:02<14:19,  1.95s/it]predicting train subjects:  17%|█▋        | 93/532 [03:04<14:22,  1.96s/it]predicting train subjects:  18%|█▊        | 94/532 [03:06<14:11,  1.94s/it]predicting train subjects:  18%|█▊        | 95/532 [03:08<14:42,  2.02s/it]predicting train subjects:  18%|█▊        | 96/532 [03:11<15:13,  2.10s/it]predicting train subjects:  18%|█▊        | 97/532 [03:13<15:14,  2.10s/it]predicting train subjects:  18%|█▊        | 98/532 [03:15<15:12,  2.10s/it]predicting train subjects:  19%|█▊        | 99/532 [03:17<15:25,  2.14s/it]predicting train subjects:  19%|█▉        | 100/532 [03:19<15:43,  2.18s/it]predicting train subjects:  19%|█▉        | 101/532 [03:21<14:54,  2.07s/it]predicting train subjects:  19%|█▉        | 102/532 [03:23<13:55,  1.94s/it]predicting train subjects:  19%|█▉        | 103/532 [03:25<13:43,  1.92s/it]predicting train subjects:  20%|█▉        | 104/532 [03:26<13:12,  1.85s/it]predicting train subjects:  20%|█▉        | 105/532 [03:28<12:40,  1.78s/it]predicting train subjects:  20%|█▉        | 106/532 [03:30<12:42,  1.79s/it]predicting train subjects:  20%|██        | 107/532 [03:31<12:28,  1.76s/it]predicting train subjects:  20%|██        | 108/532 [03:33<11:58,  1.70s/it]predicting train subjects:  20%|██        | 109/532 [03:35<12:21,  1.75s/it]predicting train subjects:  21%|██        | 110/532 [03:37<12:31,  1.78s/it]predicting train subjects:  21%|██        | 111/532 [03:38<12:08,  1.73s/it]predicting train subjects:  21%|██        | 112/532 [03:40<12:16,  1.75s/it]predicting train subjects:  21%|██        | 113/532 [03:42<13:10,  1.89s/it]predicting train subjects:  21%|██▏       | 114/532 [03:44<13:05,  1.88s/it]predicting train subjects:  22%|██▏       | 115/532 [03:46<13:40,  1.97s/it]predicting train subjects:  22%|██▏       | 116/532 [03:48<13:44,  1.98s/it]predicting train subjects:  22%|██▏       | 117/532 [03:51<13:58,  2.02s/it]predicting train subjects:  22%|██▏       | 118/532 [03:53<14:29,  2.10s/it]predicting train subjects:  22%|██▏       | 119/532 [03:55<14:32,  2.11s/it]predicting train subjects:  23%|██▎       | 120/532 [03:57<14:21,  2.09s/it]predicting train subjects:  23%|██▎       | 121/532 [03:59<13:54,  2.03s/it]predicting train subjects:  23%|██▎       | 122/532 [04:01<13:55,  2.04s/it]predicting train subjects:  23%|██▎       | 123/532 [04:03<13:50,  2.03s/it]predicting train subjects:  23%|██▎       | 124/532 [04:05<13:35,  2.00s/it]predicting train subjects:  23%|██▎       | 125/532 [04:07<13:51,  2.04s/it]predicting train subjects:  24%|██▎       | 126/532 [04:09<14:00,  2.07s/it]predicting train subjects:  24%|██▍       | 127/532 [04:11<14:22,  2.13s/it]predicting train subjects:  24%|██▍       | 128/532 [04:14<14:21,  2.13s/it]predicting train subjects:  24%|██▍       | 129/532 [04:16<14:07,  2.10s/it]predicting train subjects:  24%|██▍       | 130/532 [04:18<14:16,  2.13s/it]predicting train subjects:  25%|██▍       | 131/532 [04:20<14:50,  2.22s/it]predicting train subjects:  25%|██▍       | 132/532 [04:23<15:28,  2.32s/it]predicting train subjects:  25%|██▌       | 133/532 [04:25<15:27,  2.32s/it]predicting train subjects:  25%|██▌       | 134/532 [04:28<15:54,  2.40s/it]predicting train subjects:  25%|██▌       | 135/532 [04:30<15:50,  2.40s/it]predicting train subjects:  26%|██▌       | 136/532 [04:32<15:47,  2.39s/it]predicting train subjects:  26%|██▌       | 137/532 [04:35<15:43,  2.39s/it]predicting train subjects:  26%|██▌       | 138/532 [04:37<15:42,  2.39s/it]predicting train subjects:  26%|██▌       | 139/532 [04:40<15:49,  2.42s/it]predicting train subjects:  26%|██▋       | 140/532 [04:42<16:06,  2.47s/it]predicting train subjects:  27%|██▋       | 141/532 [04:45<15:59,  2.45s/it]predicting train subjects:  27%|██▋       | 142/532 [04:47<15:55,  2.45s/it]predicting train subjects:  27%|██▋       | 143/532 [04:49<14:40,  2.26s/it]predicting train subjects:  27%|██▋       | 144/532 [04:51<13:43,  2.12s/it]predicting train subjects:  27%|██▋       | 145/532 [04:53<13:09,  2.04s/it]predicting train subjects:  27%|██▋       | 146/532 [04:54<12:26,  1.93s/it]predicting train subjects:  28%|██▊       | 147/532 [04:56<11:53,  1.85s/it]predicting train subjects:  28%|██▊       | 148/532 [04:58<11:41,  1.83s/it]predicting train subjects:  28%|██▊       | 149/532 [05:00<11:54,  1.87s/it]predicting train subjects:  28%|██▊       | 150/532 [05:02<11:58,  1.88s/it]predicting train subjects:  28%|██▊       | 151/532 [05:04<11:55,  1.88s/it]predicting train subjects:  29%|██▊       | 152/532 [05:05<12:00,  1.90s/it]predicting train subjects:  29%|██▉       | 153/532 [05:07<12:07,  1.92s/it]predicting train subjects:  29%|██▉       | 154/532 [05:09<11:59,  1.90s/it]predicting train subjects:  29%|██▉       | 155/532 [05:12<13:33,  2.16s/it]predicting train subjects:  29%|██▉       | 156/532 [05:14<13:48,  2.20s/it]predicting train subjects:  30%|██▉       | 157/532 [05:17<14:33,  2.33s/it]predicting train subjects:  30%|██▉       | 158/532 [05:19<14:50,  2.38s/it]predicting train subjects:  30%|██▉       | 159/532 [05:22<14:56,  2.40s/it]predicting train subjects:  30%|███       | 160/532 [05:24<14:41,  2.37s/it]predicting train subjects:  30%|███       | 161/532 [05:26<13:52,  2.24s/it]predicting train subjects:  30%|███       | 162/532 [05:28<13:06,  2.12s/it]predicting train subjects:  31%|███       | 163/532 [05:30<12:33,  2.04s/it]predicting train subjects:  31%|███       | 164/532 [05:32<11:56,  1.95s/it]predicting train subjects:  31%|███       | 165/532 [05:33<11:33,  1.89s/it]predicting train subjects:  31%|███       | 166/532 [05:35<11:36,  1.90s/it]predicting train subjects:  31%|███▏      | 167/532 [05:37<12:01,  1.98s/it]predicting train subjects:  32%|███▏      | 168/532 [05:40<12:20,  2.03s/it]predicting train subjects:  32%|███▏      | 169/532 [05:41<12:03,  1.99s/it]predicting train subjects:  32%|███▏      | 170/532 [05:43<11:58,  1.99s/it]predicting train subjects:  32%|███▏      | 171/532 [05:46<12:04,  2.01s/it]predicting train subjects:  32%|███▏      | 172/532 [05:48<12:13,  2.04s/it]predicting train subjects:  33%|███▎      | 173/532 [05:49<11:40,  1.95s/it]predicting train subjects:  33%|███▎      | 174/532 [05:51<11:15,  1.89s/it]predicting train subjects:  33%|███▎      | 175/532 [05:53<11:02,  1.86s/it]predicting train subjects:  33%|███▎      | 176/532 [05:55<11:00,  1.85s/it]predicting train subjects:  33%|███▎      | 177/532 [05:57<10:51,  1.84s/it]predicting train subjects:  33%|███▎      | 178/532 [05:58<10:37,  1.80s/it]predicting train subjects:  34%|███▎      | 179/532 [06:00<10:31,  1.79s/it]predicting train subjects:  34%|███▍      | 180/532 [06:02<10:20,  1.76s/it]predicting train subjects:  34%|███▍      | 181/532 [06:04<10:31,  1.80s/it]predicting train subjects:  34%|███▍      | 182/532 [06:05<10:34,  1.81s/it]predicting train subjects:  34%|███▍      | 183/532 [06:07<10:39,  1.83s/it]predicting train subjects:  35%|███▍      | 184/532 [06:09<10:36,  1.83s/it]predicting train subjects:  35%|███▍      | 185/532 [06:11<10:25,  1.80s/it]predicting train subjects:  35%|███▍      | 186/532 [06:13<10:12,  1.77s/it]predicting train subjects:  35%|███▌      | 187/532 [06:14<10:00,  1.74s/it]predicting train subjects:  35%|███▌      | 188/532 [06:16<10:01,  1.75s/it]predicting train subjects:  36%|███▌      | 189/532 [06:18<09:54,  1.73s/it]predicting train subjects:  36%|███▌      | 190/532 [06:19<09:42,  1.70s/it]predicting train subjects:  36%|███▌      | 191/532 [06:22<11:11,  1.97s/it]predicting train subjects:  36%|███▌      | 192/532 [06:25<12:10,  2.15s/it]predicting train subjects:  36%|███▋      | 193/532 [06:27<12:34,  2.23s/it]predicting train subjects:  36%|███▋      | 194/532 [06:29<12:57,  2.30s/it]predicting train subjects:  37%|███▋      | 195/532 [06:32<13:11,  2.35s/it]predicting train subjects:  37%|███▋      | 196/532 [06:34<13:37,  2.43s/it]predicting train subjects:  37%|███▋      | 197/532 [06:37<13:00,  2.33s/it]predicting train subjects:  37%|███▋      | 198/532 [06:39<12:37,  2.27s/it]predicting train subjects:  37%|███▋      | 199/532 [06:41<12:14,  2.20s/it]predicting train subjects:  38%|███▊      | 200/532 [06:43<11:52,  2.15s/it]predicting train subjects:  38%|███▊      | 201/532 [06:45<11:59,  2.17s/it]predicting train subjects:  38%|███▊      | 202/532 [06:47<11:55,  2.17s/it]predicting train subjects:  38%|███▊      | 203/532 [06:49<11:35,  2.11s/it]predicting train subjects:  38%|███▊      | 204/532 [06:51<11:13,  2.05s/it]predicting train subjects:  39%|███▊      | 205/532 [06:53<10:47,  1.98s/it]predicting train subjects:  39%|███▊      | 206/532 [06:55<10:33,  1.94s/it]predicting train subjects:  39%|███▉      | 207/532 [06:56<10:05,  1.86s/it]predicting train subjects:  39%|███▉      | 208/532 [06:58<10:04,  1.87s/it]predicting train subjects:  39%|███▉      | 209/532 [07:00<09:50,  1.83s/it]predicting train subjects:  39%|███▉      | 210/532 [07:02<09:31,  1.78s/it]predicting train subjects:  40%|███▉      | 211/532 [07:03<09:17,  1.74s/it]predicting train subjects:  40%|███▉      | 212/532 [07:05<09:12,  1.73s/it]predicting train subjects:  40%|████      | 213/532 [07:07<08:49,  1.66s/it]predicting train subjects:  40%|████      | 214/532 [07:08<08:44,  1.65s/it]predicting train subjects:  40%|████      | 215/532 [07:11<09:51,  1.86s/it]predicting train subjects:  41%|████      | 216/532 [07:13<10:41,  2.03s/it]predicting train subjects:  41%|████      | 217/532 [07:15<11:05,  2.11s/it]predicting train subjects:  41%|████      | 218/532 [07:18<11:24,  2.18s/it]predicting train subjects:  41%|████      | 219/532 [07:20<11:56,  2.29s/it]predicting train subjects:  41%|████▏     | 220/532 [07:23<12:36,  2.42s/it]predicting train subjects:  42%|████▏     | 221/532 [07:24<11:14,  2.17s/it]predicting train subjects:  42%|████▏     | 222/532 [07:26<10:47,  2.09s/it]predicting train subjects:  42%|████▏     | 223/532 [07:28<10:10,  1.98s/it]predicting train subjects:  42%|████▏     | 224/532 [07:30<09:34,  1.86s/it]predicting train subjects:  42%|████▏     | 225/532 [07:31<09:13,  1.80s/it]predicting train subjects:  42%|████▏     | 226/532 [07:33<09:05,  1.78s/it]predicting train subjects:  43%|████▎     | 227/532 [07:34<08:33,  1.68s/it]predicting train subjects:  43%|████▎     | 228/532 [07:36<08:11,  1.62s/it]predicting train subjects:  43%|████▎     | 229/532 [07:37<08:02,  1.59s/it]predicting train subjects:  43%|████▎     | 230/532 [07:39<07:53,  1.57s/it]predicting train subjects:  43%|████▎     | 231/532 [07:41<07:53,  1.57s/it]predicting train subjects:  44%|████▎     | 232/532 [07:42<08:13,  1.65s/it]predicting train subjects:  44%|████▍     | 233/532 [07:44<08:27,  1.70s/it]predicting train subjects:  44%|████▍     | 234/532 [07:46<08:47,  1.77s/it]predicting train subjects:  44%|████▍     | 235/532 [07:48<09:06,  1.84s/it]predicting train subjects:  44%|████▍     | 236/532 [07:50<09:01,  1.83s/it]predicting train subjects:  45%|████▍     | 237/532 [07:52<08:59,  1.83s/it]predicting train subjects:  45%|████▍     | 238/532 [07:54<09:16,  1.89s/it]predicting train subjects:  45%|████▍     | 239/532 [07:56<09:40,  1.98s/it]predicting train subjects:  45%|████▌     | 240/532 [07:58<09:57,  2.05s/it]predicting train subjects:  45%|████▌     | 241/532 [08:01<10:23,  2.14s/it]predicting train subjects:  45%|████▌     | 242/532 [08:03<10:13,  2.11s/it]predicting train subjects:  46%|████▌     | 243/532 [08:05<10:05,  2.09s/it]predicting train subjects:  46%|████▌     | 244/532 [08:07<09:51,  2.05s/it]predicting train subjects:  46%|████▌     | 245/532 [08:08<08:59,  1.88s/it]predicting train subjects:  46%|████▌     | 246/532 [08:10<08:39,  1.82s/it]predicting train subjects:  46%|████▋     | 247/532 [08:11<08:26,  1.78s/it]predicting train subjects:  47%|████▋     | 248/532 [08:13<07:54,  1.67s/it]predicting train subjects:  47%|████▋     | 249/532 [08:14<07:46,  1.65s/it]predicting train subjects:  47%|████▋     | 250/532 [08:16<07:41,  1.64s/it]predicting train subjects:  47%|████▋     | 251/532 [08:18<07:34,  1.62s/it]predicting train subjects:  47%|████▋     | 252/532 [08:20<07:55,  1.70s/it]predicting train subjects:  48%|████▊     | 253/532 [08:21<08:02,  1.73s/it]predicting train subjects:  48%|████▊     | 254/532 [08:23<07:48,  1.69s/it]predicting train subjects:  48%|████▊     | 255/532 [08:25<07:55,  1.72s/it]predicting train subjects:  48%|████▊     | 256/532 [08:26<07:52,  1.71s/it]predicting train subjects:  48%|████▊     | 257/532 [08:29<08:37,  1.88s/it]predicting train subjects:  48%|████▊     | 258/532 [08:31<08:51,  1.94s/it]predicting train subjects:  49%|████▊     | 259/532 [08:33<09:09,  2.01s/it]predicting train subjects:  49%|████▉     | 260/532 [08:35<09:27,  2.08s/it]predicting train subjects:  49%|████▉     | 261/532 [08:37<09:33,  2.12s/it]predicting train subjects:  49%|████▉     | 262/532 [08:40<09:40,  2.15s/it]predicting train subjects:  49%|████▉     | 263/532 [08:41<08:41,  1.94s/it]predicting train subjects:  50%|████▉     | 264/532 [08:43<08:12,  1.84s/it]predicting train subjects:  50%|████▉     | 265/532 [08:44<07:46,  1.75s/it]predicting train subjects:  50%|█████     | 266/532 [08:46<07:20,  1.66s/it]predicting train subjects:  50%|█████     | 267/532 [08:47<07:29,  1.70s/it]predicting train subjects:  50%|█████     | 268/532 [08:49<07:20,  1.67s/it]predicting train subjects:  51%|█████     | 269/532 [08:51<07:33,  1.72s/it]predicting train subjects:  51%|█████     | 270/532 [08:53<07:41,  1.76s/it]predicting train subjects:  51%|█████     | 271/532 [08:55<08:09,  1.87s/it]predicting train subjects:  51%|█████     | 272/532 [08:57<08:00,  1.85s/it]predicting train subjects:  51%|█████▏    | 273/532 [08:59<08:02,  1.86s/it]predicting train subjects:  52%|█████▏    | 274/532 [09:01<08:11,  1.91s/it]predicting train subjects:  52%|█████▏    | 275/532 [09:03<08:57,  2.09s/it]predicting train subjects:  52%|█████▏    | 276/532 [09:06<09:28,  2.22s/it]predicting train subjects:  52%|█████▏    | 277/532 [09:08<09:42,  2.28s/it]predicting train subjects:  52%|█████▏    | 278/532 [09:10<09:34,  2.26s/it]predicting train subjects:  52%|█████▏    | 279/532 [09:13<10:13,  2.42s/it]predicting train subjects:  53%|█████▎    | 280/532 [09:16<10:15,  2.44s/it]predicting train subjects:  53%|█████▎    | 281/532 [09:18<10:12,  2.44s/it]predicting train subjects:  53%|█████▎    | 282/532 [09:20<09:54,  2.38s/it]predicting train subjects:  53%|█████▎    | 283/532 [09:23<09:52,  2.38s/it]predicting train subjects:  53%|█████▎    | 284/532 [09:25<09:43,  2.35s/it]predicting train subjects:  54%|█████▎    | 285/532 [09:27<09:30,  2.31s/it]predicting train subjects:  54%|█████▍    | 286/532 [09:30<09:35,  2.34s/it]predicting train subjects:  54%|█████▍    | 287/532 [09:31<08:45,  2.15s/it]predicting train subjects:  54%|█████▍    | 288/532 [09:33<08:05,  1.99s/it]predicting train subjects:  54%|█████▍    | 289/532 [09:35<07:54,  1.95s/it]predicting train subjects:  55%|█████▍    | 290/532 [09:36<07:36,  1.89s/it]predicting train subjects:  55%|█████▍    | 291/532 [09:38<07:15,  1.81s/it]predicting train subjects:  55%|█████▍    | 292/532 [09:40<07:11,  1.80s/it]predicting train subjects:  55%|█████▌    | 293/532 [09:42<07:32,  1.89s/it]predicting train subjects:  55%|█████▌    | 294/532 [09:44<07:34,  1.91s/it]predicting train subjects:  55%|█████▌    | 295/532 [09:46<07:51,  1.99s/it]predicting train subjects:  56%|█████▌    | 296/532 [09:48<07:58,  2.03s/it]predicting train subjects:  56%|█████▌    | 297/532 [09:50<07:35,  1.94s/it]predicting train subjects:  56%|█████▌    | 298/532 [09:52<08:01,  2.06s/it]predicting train subjects:  56%|█████▌    | 299/532 [09:54<07:31,  1.94s/it]predicting train subjects:  56%|█████▋    | 300/532 [09:55<06:54,  1.78s/it]predicting train subjects:  57%|█████▋    | 301/532 [09:57<06:46,  1.76s/it]predicting train subjects:  57%|█████▋    | 302/532 [09:59<06:35,  1.72s/it]predicting train subjects:  57%|█████▋    | 303/532 [10:00<06:33,  1.72s/it]predicting train subjects:  57%|█████▋    | 304/532 [10:02<06:21,  1.67s/it]predicting train subjects:  57%|█████▋    | 305/532 [10:04<07:15,  1.92s/it]predicting train subjects:  58%|█████▊    | 306/532 [10:07<07:53,  2.10s/it]predicting train subjects:  58%|█████▊    | 307/532 [10:09<08:18,  2.21s/it]predicting train subjects:  58%|█████▊    | 308/532 [10:12<08:29,  2.28s/it]predicting train subjects:  58%|█████▊    | 309/532 [10:14<08:50,  2.38s/it]predicting train subjects:  58%|█████▊    | 310/532 [10:17<08:53,  2.40s/it]predicting train subjects:  58%|█████▊    | 311/532 [10:20<09:21,  2.54s/it]predicting train subjects:  59%|█████▊    | 312/532 [10:23<10:17,  2.81s/it]predicting train subjects:  59%|█████▉    | 313/532 [10:26<10:35,  2.90s/it]predicting train subjects:  59%|█████▉    | 314/532 [10:30<10:59,  3.02s/it]predicting train subjects:  59%|█████▉    | 315/532 [10:33<11:15,  3.11s/it]predicting train subjects:  59%|█████▉    | 316/532 [10:36<11:03,  3.07s/it]predicting train subjects:  60%|█████▉    | 317/532 [10:38<09:44,  2.72s/it]predicting train subjects:  60%|█████▉    | 318/532 [10:40<08:59,  2.52s/it]predicting train subjects:  60%|█████▉    | 319/532 [10:42<08:00,  2.26s/it]predicting train subjects:  60%|██████    | 320/532 [10:43<07:36,  2.15s/it]predicting train subjects:  60%|██████    | 321/532 [10:45<07:14,  2.06s/it]predicting train subjects:  61%|██████    | 322/532 [10:47<06:47,  1.94s/it]predicting train subjects:  61%|██████    | 323/532 [10:49<07:14,  2.08s/it]predicting train subjects:  61%|██████    | 324/532 [10:52<07:44,  2.24s/it]predicting train subjects:  61%|██████    | 325/532 [10:54<07:59,  2.31s/it]predicting train subjects:  61%|██████▏   | 326/532 [10:57<08:05,  2.36s/it]predicting train subjects:  61%|██████▏   | 327/532 [10:59<08:02,  2.35s/it]predicting train subjects:  62%|██████▏   | 328/532 [11:02<08:12,  2.41s/it]predicting train subjects:  62%|██████▏   | 329/532 [11:04<07:38,  2.26s/it]predicting train subjects:  62%|██████▏   | 330/532 [11:06<07:31,  2.24s/it]predicting train subjects:  62%|██████▏   | 331/532 [11:08<07:09,  2.14s/it]predicting train subjects:  62%|██████▏   | 332/532 [11:10<06:47,  2.04s/it]predicting train subjects:  63%|██████▎   | 333/532 [11:11<06:27,  1.95s/it]predicting train subjects:  63%|██████▎   | 334/532 [11:13<06:20,  1.92s/it]predicting train subjects:  63%|██████▎   | 335/532 [11:15<06:34,  2.00s/it]predicting train subjects:  63%|██████▎   | 336/532 [11:18<06:54,  2.11s/it]predicting train subjects:  63%|██████▎   | 337/532 [11:20<07:05,  2.18s/it]predicting train subjects:  64%|██████▎   | 338/532 [11:22<06:59,  2.16s/it]predicting train subjects:  64%|██████▎   | 339/532 [11:24<06:59,  2.18s/it]predicting train subjects:  64%|██████▍   | 340/532 [11:27<06:56,  2.17s/it]predicting train subjects:  64%|██████▍   | 341/532 [11:28<06:29,  2.04s/it]predicting train subjects:  64%|██████▍   | 342/532 [11:30<06:20,  2.00s/it]predicting train subjects:  64%|██████▍   | 343/532 [11:32<05:58,  1.90s/it]predicting train subjects:  65%|██████▍   | 344/532 [11:34<05:42,  1.82s/it]predicting train subjects:  65%|██████▍   | 345/532 [11:35<05:27,  1.75s/it]predicting train subjects:  65%|██████▌   | 346/532 [11:37<05:23,  1.74s/it]predicting train subjects:  65%|██████▌   | 347/532 [11:39<05:27,  1.77s/it]predicting train subjects:  65%|██████▌   | 348/532 [11:41<05:33,  1.81s/it]predicting train subjects:  66%|██████▌   | 349/532 [11:43<05:37,  1.85s/it]predicting train subjects:  66%|██████▌   | 350/532 [11:44<05:32,  1.83s/it]predicting train subjects:  66%|██████▌   | 351/532 [11:46<05:40,  1.88s/it]predicting train subjects:  66%|██████▌   | 352/532 [11:48<05:45,  1.92s/it]predicting train subjects:  66%|██████▋   | 353/532 [11:50<05:45,  1.93s/it]predicting train subjects:  67%|██████▋   | 354/532 [11:52<05:50,  1.97s/it]predicting train subjects:  67%|██████▋   | 355/532 [11:54<05:46,  1.96s/it]predicting train subjects:  67%|██████▋   | 356/532 [11:56<05:38,  1.92s/it]predicting train subjects:  67%|██████▋   | 357/532 [11:58<05:40,  1.94s/it]predicting train subjects:  67%|██████▋   | 358/532 [12:00<05:39,  1.95s/it]predicting train subjects:  67%|██████▋   | 359/532 [12:02<05:28,  1.90s/it]predicting train subjects:  68%|██████▊   | 360/532 [12:04<05:22,  1.87s/it]predicting train subjects:  68%|██████▊   | 361/532 [12:05<05:17,  1.86s/it]predicting train subjects:  68%|██████▊   | 362/532 [12:07<04:58,  1.75s/it]predicting train subjects:  68%|██████▊   | 363/532 [12:09<05:00,  1.78s/it]predicting train subjects:  68%|██████▊   | 364/532 [12:11<05:00,  1.79s/it]predicting train subjects:  69%|██████▊   | 365/532 [12:12<04:45,  1.71s/it]predicting train subjects:  69%|██████▉   | 366/532 [12:14<04:44,  1.71s/it]predicting train subjects:  69%|██████▉   | 367/532 [12:16<04:38,  1.69s/it]predicting train subjects:  69%|██████▉   | 368/532 [12:17<04:32,  1.66s/it]predicting train subjects:  69%|██████▉   | 369/532 [12:19<04:41,  1.73s/it]predicting train subjects:  70%|██████▉   | 370/532 [12:21<04:39,  1.72s/it]predicting train subjects:  70%|██████▉   | 371/532 [12:23<05:07,  1.91s/it]predicting train subjects:  70%|██████▉   | 372/532 [12:26<05:32,  2.08s/it]predicting train subjects:  70%|███████   | 373/532 [12:28<05:47,  2.19s/it]predicting train subjects:  70%|███████   | 374/532 [12:30<05:59,  2.28s/it]predicting train subjects:  70%|███████   | 375/532 [12:33<05:57,  2.27s/it]predicting train subjects:  71%|███████   | 376/532 [12:35<06:04,  2.34s/it]predicting train subjects:  71%|███████   | 377/532 [12:37<05:50,  2.26s/it]predicting train subjects:  71%|███████   | 378/532 [12:39<05:30,  2.14s/it]predicting train subjects:  71%|███████   | 379/532 [12:41<05:14,  2.06s/it]predicting train subjects:  71%|███████▏  | 380/532 [12:43<05:07,  2.02s/it]predicting train subjects:  72%|███████▏  | 381/532 [12:45<05:01,  2.00s/it]predicting train subjects:  72%|███████▏  | 382/532 [12:47<04:58,  1.99s/it]predicting train subjects:  72%|███████▏  | 383/532 [12:49<04:48,  1.93s/it]predicting train subjects:  72%|███████▏  | 384/532 [12:51<04:55,  1.99s/it]predicting train subjects:  72%|███████▏  | 385/532 [12:53<04:55,  2.01s/it]predicting train subjects:  73%|███████▎  | 386/532 [12:55<04:46,  1.96s/it]predicting train subjects:  73%|███████▎  | 387/532 [12:57<04:46,  1.98s/it]predicting train subjects:  73%|███████▎  | 388/532 [12:59<04:42,  1.96s/it]predicting train subjects:  73%|███████▎  | 389/532 [13:01<04:49,  2.03s/it]predicting train subjects:  73%|███████▎  | 390/532 [13:03<05:01,  2.13s/it]predicting train subjects:  73%|███████▎  | 391/532 [13:05<05:06,  2.17s/it]predicting train subjects:  74%|███████▎  | 392/532 [13:08<05:06,  2.19s/it]predicting train subjects:  74%|███████▍  | 393/532 [13:10<04:58,  2.15s/it]predicting train subjects:  74%|███████▍  | 394/532 [13:12<04:54,  2.13s/it]predicting train subjects:  74%|███████▍  | 395/532 [13:14<04:50,  2.12s/it]predicting train subjects:  74%|███████▍  | 396/532 [13:16<04:48,  2.12s/it]predicting train subjects:  75%|███████▍  | 397/532 [13:18<04:44,  2.11s/it]predicting train subjects:  75%|███████▍  | 398/532 [13:20<04:37,  2.07s/it]predicting train subjects:  75%|███████▌  | 399/532 [13:22<04:35,  2.07s/it]predicting train subjects:  75%|███████▌  | 400/532 [13:24<04:36,  2.09s/it]predicting train subjects:  75%|███████▌  | 401/532 [13:26<04:34,  2.10s/it]predicting train subjects:  76%|███████▌  | 402/532 [13:29<04:46,  2.20s/it]predicting train subjects:  76%|███████▌  | 403/532 [13:31<04:45,  2.22s/it]predicting train subjects:  76%|███████▌  | 404/532 [13:34<04:50,  2.27s/it]predicting train subjects:  76%|███████▌  | 405/532 [13:36<04:39,  2.20s/it]predicting train subjects:  76%|███████▋  | 406/532 [13:38<04:45,  2.26s/it]predicting train subjects:  77%|███████▋  | 407/532 [13:40<04:26,  2.13s/it]predicting train subjects:  77%|███████▋  | 408/532 [13:41<04:07,  1.99s/it]predicting train subjects:  77%|███████▋  | 409/532 [13:43<03:55,  1.92s/it]predicting train subjects:  77%|███████▋  | 410/532 [13:45<04:01,  1.98s/it]predicting train subjects:  77%|███████▋  | 411/532 [13:47<04:02,  2.00s/it]predicting train subjects:  77%|███████▋  | 412/532 [13:50<04:08,  2.07s/it]predicting train subjects:  78%|███████▊  | 413/532 [13:51<03:57,  2.00s/it]predicting train subjects:  78%|███████▊  | 414/532 [13:53<03:54,  1.98s/it]predicting train subjects:  78%|███████▊  | 415/532 [13:56<04:01,  2.07s/it]predicting train subjects:  78%|███████▊  | 416/532 [13:58<03:55,  2.03s/it]predicting train subjects:  78%|███████▊  | 417/532 [14:00<03:51,  2.01s/it]predicting train subjects:  79%|███████▊  | 418/532 [14:02<03:48,  2.01s/it]predicting train subjects:  79%|███████▉  | 419/532 [14:04<03:54,  2.07s/it]predicting train subjects:  79%|███████▉  | 420/532 [14:06<04:06,  2.20s/it]predicting train subjects:  79%|███████▉  | 421/532 [14:08<04:01,  2.18s/it]predicting train subjects:  79%|███████▉  | 422/532 [14:11<04:10,  2.28s/it]predicting train subjects:  80%|███████▉  | 423/532 [14:13<04:09,  2.29s/it]predicting train subjects:  80%|███████▉  | 424/532 [14:15<03:56,  2.19s/it]predicting train subjects:  80%|███████▉  | 425/532 [14:18<04:11,  2.35s/it]predicting train subjects:  80%|████████  | 426/532 [14:20<04:02,  2.29s/it]predicting train subjects:  80%|████████  | 427/532 [14:23<04:05,  2.34s/it]predicting train subjects:  80%|████████  | 428/532 [14:25<04:05,  2.36s/it]predicting train subjects:  81%|████████  | 429/532 [14:27<04:00,  2.34s/it]predicting train subjects:  81%|████████  | 430/532 [14:29<03:55,  2.31s/it]predicting train subjects:  81%|████████  | 431/532 [14:32<03:54,  2.32s/it]predicting train subjects:  81%|████████  | 432/532 [14:34<03:56,  2.36s/it]predicting train subjects:  81%|████████▏ | 433/532 [14:37<04:01,  2.44s/it]predicting train subjects:  82%|████████▏ | 434/532 [14:39<03:55,  2.40s/it]predicting train subjects:  82%|████████▏ | 435/532 [14:42<03:54,  2.41s/it]predicting train subjects:  82%|████████▏ | 436/532 [14:44<03:47,  2.37s/it]predicting train subjects:  82%|████████▏ | 437/532 [14:46<03:27,  2.18s/it]predicting train subjects:  82%|████████▏ | 438/532 [14:47<03:15,  2.08s/it]predicting train subjects:  83%|████████▎ | 439/532 [14:49<03:07,  2.01s/it]predicting train subjects:  83%|████████▎ | 440/532 [14:51<02:58,  1.94s/it]predicting train subjects:  83%|████████▎ | 441/532 [14:53<02:47,  1.84s/it]predicting train subjects:  83%|████████▎ | 442/532 [14:54<02:40,  1.78s/it]predicting train subjects:  83%|████████▎ | 443/532 [14:56<02:39,  1.79s/it]predicting train subjects:  83%|████████▎ | 444/532 [14:58<02:36,  1.77s/it]predicting train subjects:  84%|████████▎ | 445/532 [15:00<02:32,  1.75s/it]predicting train subjects:  84%|████████▍ | 446/532 [15:01<02:29,  1.74s/it]predicting train subjects:  84%|████████▍ | 447/532 [15:03<02:23,  1.69s/it]predicting train subjects:  84%|████████▍ | 448/532 [15:04<02:18,  1.65s/it]predicting train subjects:  84%|████████▍ | 449/532 [15:06<02:21,  1.70s/it]predicting train subjects:  85%|████████▍ | 450/532 [15:08<02:24,  1.77s/it]predicting train subjects:  85%|████████▍ | 451/532 [15:10<02:27,  1.82s/it]predicting train subjects:  85%|████████▍ | 452/532 [15:12<02:29,  1.87s/it]predicting train subjects:  85%|████████▌ | 453/532 [15:14<02:25,  1.84s/it]predicting train subjects:  85%|████████▌ | 454/532 [15:16<02:22,  1.82s/it]predicting train subjects:  86%|████████▌ | 455/532 [15:18<02:27,  1.92s/it]predicting train subjects:  86%|████████▌ | 456/532 [15:20<02:29,  1.97s/it]predicting train subjects:  86%|████████▌ | 457/532 [15:22<02:34,  2.05s/it]predicting train subjects:  86%|████████▌ | 458/532 [15:24<02:28,  2.01s/it]predicting train subjects:  86%|████████▋ | 459/532 [15:26<02:29,  2.05s/it]predicting train subjects:  86%|████████▋ | 460/532 [15:28<02:29,  2.07s/it]predicting train subjects:  87%|████████▋ | 461/532 [15:31<02:40,  2.26s/it]predicting train subjects:  87%|████████▋ | 462/532 [15:34<02:43,  2.34s/it]predicting train subjects:  87%|████████▋ | 463/532 [15:36<02:45,  2.39s/it]predicting train subjects:  87%|████████▋ | 464/532 [15:39<02:45,  2.43s/it]predicting train subjects:  87%|████████▋ | 465/532 [15:41<02:47,  2.50s/it]predicting train subjects:  88%|████████▊ | 466/532 [15:44<02:44,  2.49s/it]predicting train subjects:  88%|████████▊ | 467/532 [15:46<02:34,  2.37s/it]predicting train subjects:  88%|████████▊ | 468/532 [15:48<02:25,  2.27s/it]predicting train subjects:  88%|████████▊ | 469/532 [15:50<02:20,  2.23s/it]predicting train subjects:  88%|████████▊ | 470/532 [15:52<02:13,  2.16s/it]predicting train subjects:  89%|████████▊ | 471/532 [15:54<02:09,  2.12s/it]predicting train subjects:  89%|████████▊ | 472/532 [15:56<02:03,  2.06s/it]predicting train subjects:  89%|████████▉ | 473/532 [15:58<02:04,  2.11s/it]predicting train subjects:  89%|████████▉ | 474/532 [16:00<02:03,  2.13s/it]predicting train subjects:  89%|████████▉ | 475/532 [16:03<02:03,  2.16s/it]predicting train subjects:  89%|████████▉ | 476/532 [16:05<01:59,  2.13s/it]predicting train subjects:  90%|████████▉ | 477/532 [16:07<01:56,  2.13s/it]predicting train subjects:  90%|████████▉ | 478/532 [16:09<01:57,  2.17s/it]predicting train subjects:  90%|█████████ | 479/532 [16:11<01:50,  2.08s/it]predicting train subjects:  90%|█████████ | 480/532 [16:13<01:46,  2.05s/it]predicting train subjects:  90%|█████████ | 481/532 [16:15<01:38,  1.93s/it]predicting train subjects:  91%|█████████ | 482/532 [16:16<01:35,  1.90s/it]predicting train subjects:  91%|█████████ | 483/532 [16:18<01:35,  1.94s/it]predicting train subjects:  91%|█████████ | 484/532 [16:20<01:34,  1.97s/it]predicting train subjects:  91%|█████████ | 485/532 [16:23<01:39,  2.11s/it]predicting train subjects:  91%|█████████▏| 486/532 [16:25<01:39,  2.16s/it]predicting train subjects:  92%|█████████▏| 487/532 [16:28<01:41,  2.26s/it]predicting train subjects:  92%|█████████▏| 488/532 [16:30<01:44,  2.37s/it]predicting train subjects:  92%|█████████▏| 489/532 [16:33<01:48,  2.51s/it]predicting train subjects:  92%|█████████▏| 490/532 [16:35<01:42,  2.43s/it]predicting train subjects:  92%|█████████▏| 491/532 [16:37<01:34,  2.31s/it]predicting train subjects:  92%|█████████▏| 492/532 [16:39<01:29,  2.23s/it]predicting train subjects:  93%|█████████▎| 493/532 [16:41<01:24,  2.16s/it]predicting train subjects:  93%|█████████▎| 494/532 [16:43<01:20,  2.11s/it]predicting train subjects:  93%|█████████▎| 495/532 [16:45<01:15,  2.04s/it]predicting train subjects:  93%|█████████▎| 496/532 [16:47<01:12,  2.02s/it]predicting train subjects:  93%|█████████▎| 497/532 [16:49<01:12,  2.08s/it]predicting train subjects:  94%|█████████▎| 498/532 [16:52<01:11,  2.10s/it]predicting train subjects:  94%|█████████▍| 499/532 [16:54<01:10,  2.13s/it]predicting train subjects:  94%|█████████▍| 500/532 [16:56<01:06,  2.08s/it]predicting train subjects:  94%|█████████▍| 501/532 [16:58<01:04,  2.09s/it]predicting train subjects:  94%|█████████▍| 502/532 [17:00<01:02,  2.10s/it]predicting train subjects:  95%|█████████▍| 503/532 [17:02<00:59,  2.05s/it]predicting train subjects:  95%|█████████▍| 504/532 [17:04<00:55,  1.97s/it]predicting train subjects:  95%|█████████▍| 505/532 [17:05<00:51,  1.90s/it]predicting train subjects:  95%|█████████▌| 506/532 [17:07<00:49,  1.92s/it]predicting train subjects:  95%|█████████▌| 507/532 [17:10<00:49,  1.97s/it]predicting train subjects:  95%|█████████▌| 508/532 [17:12<00:47,  1.99s/it]predicting train subjects:  96%|█████████▌| 509/532 [17:14<00:48,  2.11s/it]predicting train subjects:  96%|█████████▌| 510/532 [17:17<00:49,  2.25s/it]predicting train subjects:  96%|█████████▌| 511/532 [17:19<00:48,  2.31s/it]predicting train subjects:  96%|█████████▌| 512/532 [17:22<00:47,  2.39s/it]predicting train subjects:  96%|█████████▋| 513/532 [17:24<00:45,  2.39s/it]predicting train subjects:  97%|█████████▋| 514/532 [17:26<00:43,  2.40s/it]predicting train subjects:  97%|█████████▋| 515/532 [17:29<00:39,  2.33s/it]predicting train subjects:  97%|█████████▋| 516/532 [17:31<00:36,  2.28s/it]predicting train subjects:  97%|█████████▋| 517/532 [17:33<00:32,  2.20s/it]predicting train subjects:  97%|█████████▋| 518/532 [17:35<00:29,  2.09s/it]predicting train subjects:  98%|█████████▊| 519/532 [17:37<00:26,  2.07s/it]predicting train subjects:  98%|█████████▊| 520/532 [17:39<00:24,  2.04s/it]predicting train subjects:  98%|█████████▊| 521/532 [17:41<00:22,  2.09s/it]predicting train subjects:  98%|█████████▊| 522/532 [17:43<00:21,  2.11s/it]predicting train subjects:  98%|█████████▊| 523/532 [17:45<00:19,  2.15s/it]predicting train subjects:  98%|█████████▊| 524/532 [17:48<00:18,  2.26s/it]predicting train subjects:  99%|█████████▊| 525/532 [17:50<00:15,  2.23s/it]predicting train subjects:  99%|█████████▉| 526/532 [17:52<00:13,  2.23s/it]predicting train subjects:  99%|█████████▉| 527/532 [17:54<00:11,  2.24s/it]predicting train subjects:  99%|█████████▉| 528/532 [17:56<00:08,  2.14s/it]predicting train subjects:  99%|█████████▉| 529/532 [17:58<00:06,  2.17s/it]predicting train subjects: 100%|█████████▉| 530/532 [18:00<00:04,  2.10s/it]predicting train subjects: 100%|█████████▉| 531/532 [18:03<00:02,  2.18s/it]predicting train subjects: 100%|██████████| 532/532 [18:05<00:00,  2.16s/it]
Loading train:   0%|          | 0/532 [00:00<?, ?it/s]Loading train:   0%|          | 1/532 [00:02<20:42,  2.34s/it]Loading train:   0%|          | 2/532 [00:04<20:09,  2.28s/it]Loading train:   1%|          | 3/532 [00:06<19:46,  2.24s/it]Loading train:   1%|          | 4/532 [00:08<19:11,  2.18s/it]Loading train:   1%|          | 5/532 [00:10<17:37,  2.01s/it]Loading train:   1%|          | 6/532 [00:11<16:40,  1.90s/it]Loading train:   1%|▏         | 7/532 [00:13<16:42,  1.91s/it]Loading train:   2%|▏         | 8/532 [00:15<16:31,  1.89s/it]Loading train:   2%|▏         | 9/532 [00:17<16:30,  1.89s/it]Loading train:   2%|▏         | 10/532 [00:19<16:19,  1.88s/it]Loading train:   2%|▏         | 11/532 [00:21<16:04,  1.85s/it]Loading train:   2%|▏         | 12/532 [00:23<16:03,  1.85s/it]Loading train:   2%|▏         | 13/532 [00:24<15:31,  1.79s/it]Loading train:   3%|▎         | 14/532 [00:25<13:53,  1.61s/it]Loading train:   3%|▎         | 15/532 [00:27<14:41,  1.71s/it]Loading train:   3%|▎         | 16/532 [00:29<15:45,  1.83s/it]Loading train:   3%|▎         | 17/532 [00:31<15:08,  1.76s/it]Loading train:   3%|▎         | 18/532 [00:33<14:48,  1.73s/it]Loading train:   4%|▎         | 19/532 [00:34<14:34,  1.71s/it]Loading train:   4%|▍         | 20/532 [00:37<15:35,  1.83s/it]Loading train:   4%|▍         | 21/532 [00:39<16:21,  1.92s/it]Loading train:   4%|▍         | 22/532 [00:40<15:23,  1.81s/it]Loading train:   4%|▍         | 23/532 [00:42<15:19,  1.81s/it]Loading train:   5%|▍         | 24/532 [00:44<15:46,  1.86s/it]Loading train:   5%|▍         | 25/532 [00:47<17:59,  2.13s/it]Loading train:   5%|▍         | 26/532 [00:48<16:08,  1.91s/it]Loading train:   5%|▌         | 27/532 [00:51<17:35,  2.09s/it]Loading train:   5%|▌         | 28/532 [00:53<17:58,  2.14s/it]Loading train:   5%|▌         | 29/532 [00:54<16:22,  1.95s/it]Loading train:   6%|▌         | 30/532 [00:56<14:31,  1.74s/it]Loading train:   6%|▌         | 31/532 [00:57<14:34,  1.75s/it]Loading train:   6%|▌         | 32/532 [00:59<14:48,  1.78s/it]Loading train:   6%|▌         | 33/532 [01:01<14:39,  1.76s/it]Loading train:   6%|▋         | 34/532 [01:03<15:49,  1.91s/it]Loading train:   7%|▋         | 35/532 [01:05<15:38,  1.89s/it]Loading train:   7%|▋         | 36/532 [01:08<17:26,  2.11s/it]Loading train:   7%|▋         | 37/532 [01:10<17:28,  2.12s/it]Loading train:   7%|▋         | 38/532 [01:12<17:16,  2.10s/it]Loading train:   7%|▋         | 39/532 [01:14<17:33,  2.14s/it]Loading train:   8%|▊         | 40/532 [01:16<16:52,  2.06s/it]Loading train:   8%|▊         | 41/532 [01:18<17:16,  2.11s/it]Loading train:   8%|▊         | 42/532 [01:20<16:24,  2.01s/it]Loading train:   8%|▊         | 43/532 [01:22<16:33,  2.03s/it]Loading train:   8%|▊         | 44/532 [01:24<15:33,  1.91s/it]Loading train:   8%|▊         | 45/532 [01:25<13:59,  1.72s/it]Loading train:   9%|▊         | 46/532 [01:27<13:44,  1.70s/it]Loading train:   9%|▉         | 47/532 [01:29<15:04,  1.86s/it]Loading train:   9%|▉         | 48/532 [01:31<14:49,  1.84s/it]Loading train:   9%|▉         | 49/532 [01:32<14:13,  1.77s/it]Loading train:   9%|▉         | 50/532 [01:34<14:13,  1.77s/it]Loading train:  10%|▉         | 51/532 [01:36<14:37,  1.82s/it]Loading train:  10%|▉         | 52/532 [01:38<14:48,  1.85s/it]Loading train:  10%|▉         | 53/532 [01:40<14:23,  1.80s/it]Loading train:  10%|█         | 54/532 [01:41<14:21,  1.80s/it]Loading train:  10%|█         | 55/532 [01:44<15:05,  1.90s/it]Loading train:  11%|█         | 56/532 [01:46<15:30,  1.95s/it]Loading train:  11%|█         | 57/532 [01:47<14:37,  1.85s/it]Loading train:  11%|█         | 58/532 [01:49<14:04,  1.78s/it]Loading train:  11%|█         | 59/532 [01:51<14:11,  1.80s/it]Loading train:  11%|█▏        | 60/532 [01:52<13:58,  1.78s/it]Loading train:  11%|█▏        | 61/532 [01:54<13:39,  1.74s/it]Loading train:  12%|█▏        | 62/532 [01:57<15:21,  1.96s/it]Loading train:  12%|█▏        | 63/532 [01:58<14:34,  1.87s/it]Loading train:  12%|█▏        | 64/532 [02:00<14:23,  1.84s/it]Loading train:  12%|█▏        | 65/532 [02:02<14:40,  1.89s/it]Loading train:  12%|█▏        | 66/532 [02:04<14:42,  1.89s/it]Loading train:  13%|█▎        | 67/532 [02:06<15:02,  1.94s/it]Loading train:  13%|█▎        | 68/532 [02:07<13:57,  1.81s/it]Loading train:  13%|█▎        | 69/532 [02:09<13:47,  1.79s/it]Loading train:  13%|█▎        | 70/532 [02:11<13:36,  1.77s/it]Loading train:  13%|█▎        | 71/532 [02:12<13:10,  1.71s/it]Loading train:  14%|█▎        | 72/532 [02:14<13:17,  1.73s/it]Loading train:  14%|█▎        | 73/532 [02:16<13:10,  1.72s/it]Loading train:  14%|█▍        | 74/532 [02:18<13:47,  1.81s/it]Loading train:  14%|█▍        | 75/532 [02:21<16:07,  2.12s/it]Loading train:  14%|█▍        | 76/532 [02:22<15:05,  1.99s/it]Loading train:  14%|█▍        | 77/532 [02:25<15:33,  2.05s/it]Loading train:  15%|█▍        | 78/532 [02:27<15:32,  2.05s/it]Loading train:  15%|█▍        | 79/532 [02:29<15:23,  2.04s/it]Loading train:  15%|█▌        | 80/532 [02:31<15:05,  2.00s/it]Loading train:  15%|█▌        | 81/532 [02:33<15:14,  2.03s/it]Loading train:  15%|█▌        | 82/532 [02:34<13:53,  1.85s/it]Loading train:  16%|█▌        | 83/532 [02:36<13:25,  1.79s/it]Loading train:  16%|█▌        | 84/532 [02:37<12:55,  1.73s/it]Loading train:  16%|█▌        | 85/532 [02:39<12:18,  1.65s/it]Loading train:  16%|█▌        | 86/532 [02:41<12:32,  1.69s/it]Loading train:  16%|█▋        | 87/532 [02:42<11:36,  1.57s/it]Loading train:  17%|█▋        | 88/532 [02:44<11:45,  1.59s/it]Loading train:  17%|█▋        | 89/532 [02:45<11:43,  1.59s/it]Loading train:  17%|█▋        | 90/532 [02:47<11:28,  1.56s/it]Loading train:  17%|█▋        | 91/532 [02:48<11:00,  1.50s/it]Loading train:  17%|█▋        | 92/532 [02:50<11:05,  1.51s/it]Loading train:  17%|█▋        | 93/532 [02:51<10:53,  1.49s/it]Loading train:  18%|█▊        | 94/532 [02:53<11:05,  1.52s/it]Loading train:  18%|█▊        | 95/532 [02:55<12:25,  1.71s/it]Loading train:  18%|█▊        | 96/532 [02:56<12:14,  1.69s/it]Loading train:  18%|█▊        | 97/532 [02:58<12:25,  1.71s/it]Loading train:  18%|█▊        | 98/532 [03:00<11:44,  1.62s/it]Loading train:  19%|█▊        | 99/532 [03:02<13:04,  1.81s/it]Loading train:  19%|█▉        | 100/532 [03:04<13:27,  1.87s/it]Loading train:  19%|█▉        | 101/532 [03:06<13:12,  1.84s/it]Loading train:  19%|█▉        | 102/532 [03:07<13:03,  1.82s/it]Loading train:  19%|█▉        | 103/532 [03:09<12:06,  1.69s/it]Loading train:  20%|█▉        | 104/532 [03:10<11:46,  1.65s/it]Loading train:  20%|█▉        | 105/532 [03:12<12:19,  1.73s/it]Loading train:  20%|█▉        | 106/532 [03:14<11:50,  1.67s/it]Loading train:  20%|██        | 107/532 [03:15<11:18,  1.60s/it]Loading train:  20%|██        | 108/532 [03:17<10:59,  1.55s/it]Loading train:  20%|██        | 109/532 [03:18<10:52,  1.54s/it]Loading train:  21%|██        | 110/532 [03:20<11:13,  1.60s/it]Loading train:  21%|██        | 111/532 [03:21<11:00,  1.57s/it]Loading train:  21%|██        | 112/532 [03:23<11:36,  1.66s/it]Loading train:  21%|██        | 113/532 [03:25<11:28,  1.64s/it]Loading train:  21%|██▏       | 114/532 [03:27<11:33,  1.66s/it]Loading train:  22%|██▏       | 115/532 [03:29<12:17,  1.77s/it]Loading train:  22%|██▏       | 116/532 [03:30<11:48,  1.70s/it]Loading train:  22%|██▏       | 117/532 [03:32<11:48,  1.71s/it]Loading train:  22%|██▏       | 118/532 [03:33<11:21,  1.65s/it]Loading train:  22%|██▏       | 119/532 [03:35<11:35,  1.68s/it]Loading train:  23%|██▎       | 120/532 [03:37<11:28,  1.67s/it]Loading train:  23%|██▎       | 121/532 [03:38<10:52,  1.59s/it]Loading train:  23%|██▎       | 122/532 [03:40<11:08,  1.63s/it]Loading train:  23%|██▎       | 123/532 [03:41<10:09,  1.49s/it]Loading train:  23%|██▎       | 124/532 [03:43<10:40,  1.57s/it]Loading train:  23%|██▎       | 125/532 [03:45<11:15,  1.66s/it]Loading train:  24%|██▎       | 126/532 [03:46<11:28,  1.70s/it]Loading train:  24%|██▍       | 127/532 [03:48<11:39,  1.73s/it]Loading train:  24%|██▍       | 128/532 [03:50<11:16,  1.67s/it]Loading train:  24%|██▍       | 129/532 [03:52<11:25,  1.70s/it]Loading train:  24%|██▍       | 130/532 [03:53<11:45,  1.76s/it]Loading train:  25%|██▍       | 131/532 [03:56<12:20,  1.85s/it]Loading train:  25%|██▍       | 132/532 [03:58<12:57,  1.94s/it]Loading train:  25%|██▌       | 133/532 [04:00<13:27,  2.02s/it]Loading train:  25%|██▌       | 134/532 [04:02<13:34,  2.05s/it]Loading train:  25%|██▌       | 135/532 [04:04<14:01,  2.12s/it]Loading train:  26%|██▌       | 136/532 [04:06<12:54,  1.96s/it]Loading train:  26%|██▌       | 137/532 [04:08<13:05,  1.99s/it]Loading train:  26%|██▌       | 138/532 [04:10<13:24,  2.04s/it]Loading train:  26%|██▌       | 139/532 [04:12<13:41,  2.09s/it]Loading train:  26%|██▋       | 140/532 [04:14<13:07,  2.01s/it]Loading train:  27%|██▋       | 141/532 [04:16<12:55,  1.98s/it]Loading train:  27%|██▋       | 142/532 [04:18<13:28,  2.07s/it]Loading train:  27%|██▋       | 143/532 [04:20<13:26,  2.07s/it]Loading train:  27%|██▋       | 144/532 [04:22<11:58,  1.85s/it]Loading train:  27%|██▋       | 145/532 [04:23<10:55,  1.69s/it]Loading train:  27%|██▋       | 146/532 [04:25<11:08,  1.73s/it]Loading train:  28%|██▊       | 147/532 [04:27<11:02,  1.72s/it]Loading train:  28%|██▊       | 148/532 [04:28<11:10,  1.74s/it]Loading train:  28%|██▊       | 149/532 [04:30<11:14,  1.76s/it]Loading train:  28%|██▊       | 150/532 [04:32<10:45,  1.69s/it]Loading train:  28%|██▊       | 151/532 [04:33<10:35,  1.67s/it]Loading train:  29%|██▊       | 152/532 [04:35<10:39,  1.68s/it]Loading train:  29%|██▉       | 153/532 [04:36<10:10,  1.61s/it]Loading train:  29%|██▉       | 154/532 [04:38<09:55,  1.58s/it]Loading train:  29%|██▉       | 155/532 [04:40<09:51,  1.57s/it]Loading train:  29%|██▉       | 156/532 [04:41<10:09,  1.62s/it]Loading train:  30%|██▉       | 157/532 [04:43<10:53,  1.74s/it]Loading train:  30%|██▉       | 158/532 [04:45<10:55,  1.75s/it]Loading train:  30%|██▉       | 159/532 [04:47<11:23,  1.83s/it]Loading train:  30%|███       | 160/532 [04:49<11:46,  1.90s/it]Loading train:  30%|███       | 161/532 [04:51<11:07,  1.80s/it]Loading train:  30%|███       | 162/532 [04:52<11:03,  1.79s/it]Loading train:  31%|███       | 163/532 [04:54<11:13,  1.82s/it]Loading train:  31%|███       | 164/532 [04:56<10:49,  1.77s/it]Loading train:  31%|███       | 165/532 [04:58<10:57,  1.79s/it]Loading train:  31%|███       | 166/532 [05:00<10:59,  1.80s/it]Loading train:  31%|███▏      | 167/532 [05:02<11:31,  1.89s/it]Loading train:  32%|███▏      | 168/532 [05:03<11:08,  1.84s/it]Loading train:  32%|███▏      | 169/532 [05:05<10:48,  1.79s/it]Loading train:  32%|███▏      | 170/532 [05:07<11:14,  1.86s/it]Loading train:  32%|███▏      | 171/532 [05:09<10:44,  1.78s/it]Loading train:  32%|███▏      | 172/532 [05:10<10:21,  1.73s/it]Loading train:  33%|███▎      | 173/532 [05:12<10:00,  1.67s/it]Loading train:  33%|███▎      | 174/532 [05:14<10:21,  1.74s/it]Loading train:  33%|███▎      | 175/532 [05:16<10:30,  1.76s/it]Loading train:  33%|███▎      | 176/532 [05:17<10:24,  1.75s/it]Loading train:  33%|███▎      | 177/532 [05:19<10:04,  1.70s/it]Loading train:  33%|███▎      | 178/532 [05:21<09:49,  1.67s/it]Loading train:  34%|███▎      | 179/532 [05:22<09:56,  1.69s/it]Loading train:  34%|███▍      | 180/532 [05:24<10:18,  1.76s/it]Loading train:  34%|███▍      | 181/532 [05:26<10:08,  1.73s/it]Loading train:  34%|███▍      | 182/532 [05:27<09:06,  1.56s/it]Loading train:  34%|███▍      | 183/532 [05:29<09:32,  1.64s/it]Loading train:  35%|███▍      | 184/532 [05:31<09:37,  1.66s/it]Loading train:  35%|███▍      | 185/532 [05:32<10:00,  1.73s/it]Loading train:  35%|███▍      | 186/532 [05:34<10:03,  1.74s/it]Loading train:  35%|███▌      | 187/532 [05:36<09:12,  1.60s/it]Loading train:  35%|███▌      | 188/532 [05:37<09:24,  1.64s/it]Loading train:  36%|███▌      | 189/532 [05:39<09:13,  1.61s/it]Loading train:  36%|███▌      | 190/532 [05:40<09:05,  1.59s/it]Loading train:  36%|███▌      | 191/532 [05:43<10:10,  1.79s/it]Loading train:  36%|███▌      | 192/532 [05:45<10:29,  1.85s/it]Loading train:  36%|███▋      | 193/532 [05:46<10:05,  1.79s/it]Loading train:  36%|███▋      | 194/532 [05:48<10:23,  1.84s/it]Loading train:  37%|███▋      | 195/532 [05:50<10:51,  1.93s/it]Loading train:  37%|███▋      | 196/532 [05:52<10:41,  1.91s/it]Loading train:  37%|███▋      | 197/532 [05:54<10:32,  1.89s/it]Loading train:  37%|███▋      | 198/532 [05:56<10:16,  1.85s/it]Loading train:  37%|███▋      | 199/532 [05:58<10:20,  1.86s/it]Loading train:  38%|███▊      | 200/532 [06:00<10:25,  1.88s/it]Loading train:  38%|███▊      | 201/532 [06:01<09:52,  1.79s/it]Loading train:  38%|███▊      | 202/532 [06:03<09:16,  1.69s/it]Loading train:  38%|███▊      | 203/532 [06:04<08:59,  1.64s/it]Loading train:  38%|███▊      | 204/532 [06:06<08:31,  1.56s/it]Loading train:  39%|███▊      | 205/532 [06:07<08:45,  1.61s/it]Loading train:  39%|███▊      | 206/532 [06:09<09:31,  1.75s/it]Loading train:  39%|███▉      | 207/532 [06:11<08:34,  1.58s/it]Loading train:  39%|███▉      | 208/532 [06:12<08:07,  1.50s/it]Loading train:  39%|███▉      | 209/532 [06:13<07:47,  1.45s/it]Loading train:  39%|███▉      | 210/532 [06:15<07:46,  1.45s/it]Loading train:  40%|███▉      | 211/532 [06:16<07:45,  1.45s/it]Loading train:  40%|███▉      | 212/532 [06:17<07:33,  1.42s/it]Loading train:  40%|████      | 213/532 [06:19<07:22,  1.39s/it]Loading train:  40%|████      | 214/532 [06:20<07:19,  1.38s/it]Loading train:  40%|████      | 215/532 [06:22<07:29,  1.42s/it]Loading train:  41%|████      | 216/532 [06:23<07:55,  1.51s/it]Loading train:  41%|████      | 217/532 [06:25<08:28,  1.61s/it]Loading train:  41%|████      | 218/532 [06:27<08:16,  1.58s/it]Loading train:  41%|████      | 219/532 [06:28<08:28,  1.63s/it]Loading train:  41%|████▏     | 220/532 [06:30<08:48,  1.69s/it]Loading train:  42%|████▏     | 221/532 [06:32<08:47,  1.70s/it]Loading train:  42%|████▏     | 222/532 [06:33<08:22,  1.62s/it]Loading train:  42%|████▏     | 223/532 [06:35<08:08,  1.58s/it]Loading train:  42%|████▏     | 224/532 [06:36<07:40,  1.49s/it]Loading train:  42%|████▏     | 225/532 [06:37<07:12,  1.41s/it]Loading train:  42%|████▏     | 226/532 [06:38<06:35,  1.29s/it]Loading train:  43%|████▎     | 227/532 [06:40<06:17,  1.24s/it]Loading train:  43%|████▎     | 228/532 [06:41<05:54,  1.17s/it]Loading train:  43%|████▎     | 229/532 [06:42<05:45,  1.14s/it]Loading train:  43%|████▎     | 230/532 [06:43<05:37,  1.12s/it]Loading train:  43%|████▎     | 231/532 [06:44<05:28,  1.09s/it]Loading train:  44%|████▎     | 232/532 [06:45<05:27,  1.09s/it]Loading train:  44%|████▍     | 233/532 [06:46<05:29,  1.10s/it]Loading train:  44%|████▍     | 234/532 [06:47<05:25,  1.09s/it]Loading train:  44%|████▍     | 235/532 [06:48<05:40,  1.15s/it]Loading train:  44%|████▍     | 236/532 [06:49<05:40,  1.15s/it]Loading train:  45%|████▍     | 237/532 [06:51<05:39,  1.15s/it]Loading train:  45%|████▍     | 238/532 [06:52<05:59,  1.22s/it]Loading train:  45%|████▍     | 239/532 [06:53<06:02,  1.24s/it]Loading train:  45%|████▌     | 240/532 [06:55<06:13,  1.28s/it]Loading train:  45%|████▌     | 241/532 [06:56<06:22,  1.31s/it]Loading train:  45%|████▌     | 242/532 [06:57<06:29,  1.34s/it]Loading train:  46%|████▌     | 243/532 [06:59<06:11,  1.29s/it]Loading train:  46%|████▌     | 244/532 [07:00<06:04,  1.26s/it]Loading train:  46%|████▌     | 245/532 [07:01<05:56,  1.24s/it]Loading train:  46%|████▌     | 246/532 [07:02<05:52,  1.23s/it]Loading train:  46%|████▋     | 247/532 [07:03<05:38,  1.19s/it]Loading train:  47%|████▋     | 248/532 [07:04<05:25,  1.15s/it]Loading train:  47%|████▋     | 249/532 [07:05<05:22,  1.14s/it]Loading train:  47%|████▋     | 250/532 [07:07<05:22,  1.14s/it]Loading train:  47%|████▋     | 251/532 [07:08<05:38,  1.20s/it]Loading train:  47%|████▋     | 252/532 [07:09<05:32,  1.19s/it]Loading train:  48%|████▊     | 253/532 [07:10<05:42,  1.23s/it]Loading train:  48%|████▊     | 254/532 [07:11<05:14,  1.13s/it]Loading train:  48%|████▊     | 255/532 [07:12<04:56,  1.07s/it]Loading train:  48%|████▊     | 256/532 [07:13<05:05,  1.11s/it]Loading train:  48%|████▊     | 257/532 [07:15<05:51,  1.28s/it]Loading train:  48%|████▊     | 258/532 [07:16<05:52,  1.28s/it]Loading train:  49%|████▊     | 259/532 [07:18<05:45,  1.27s/it]Loading train:  49%|████▉     | 260/532 [07:19<05:41,  1.25s/it]Loading train:  49%|████▉     | 261/532 [07:20<05:52,  1.30s/it]Loading train:  49%|████▉     | 262/532 [07:22<05:56,  1.32s/it]Loading train:  49%|████▉     | 263/532 [07:23<05:50,  1.30s/it]Loading train:  50%|████▉     | 264/532 [07:24<05:06,  1.14s/it]Loading train:  50%|████▉     | 265/532 [07:25<04:45,  1.07s/it]Loading train:  50%|█████     | 266/532 [07:26<04:46,  1.08s/it]Loading train:  50%|█████     | 267/532 [07:27<04:51,  1.10s/it]Loading train:  50%|█████     | 268/532 [07:28<04:52,  1.11s/it]Loading train:  51%|█████     | 269/532 [07:29<04:56,  1.13s/it]Loading train:  51%|█████     | 270/532 [07:30<04:44,  1.09s/it]Loading train:  51%|█████     | 271/532 [07:31<04:58,  1.15s/it]Loading train:  51%|█████     | 272/532 [07:33<05:00,  1.15s/it]Loading train:  51%|█████▏    | 273/532 [07:34<05:00,  1.16s/it]Loading train:  52%|█████▏    | 274/532 [07:35<05:10,  1.20s/it]Loading train:  52%|█████▏    | 275/532 [07:36<05:13,  1.22s/it]Loading train:  52%|█████▏    | 276/532 [07:38<05:42,  1.34s/it]Loading train:  52%|█████▏    | 277/532 [07:39<05:45,  1.35s/it]Loading train:  52%|█████▏    | 278/532 [07:41<05:54,  1.40s/it]Loading train:  52%|█████▏    | 279/532 [07:42<05:48,  1.38s/it]Loading train:  53%|█████▎    | 280/532 [07:43<05:43,  1.36s/it]Loading train:  53%|█████▎    | 281/532 [07:45<05:49,  1.39s/it]Loading train:  53%|█████▎    | 282/532 [07:46<05:52,  1.41s/it]Loading train:  53%|█████▎    | 283/532 [07:48<05:38,  1.36s/it]Loading train:  53%|█████▎    | 284/532 [07:49<05:22,  1.30s/it]Loading train:  54%|█████▎    | 285/532 [07:50<05:16,  1.28s/it]Loading train:  54%|█████▍    | 286/532 [07:51<05:20,  1.30s/it]Loading train:  54%|█████▍    | 287/532 [07:53<05:20,  1.31s/it]Loading train:  54%|█████▍    | 288/532 [07:54<05:19,  1.31s/it]Loading train:  54%|█████▍    | 289/532 [07:55<05:00,  1.24s/it]Loading train:  55%|█████▍    | 290/532 [07:56<04:57,  1.23s/it]Loading train:  55%|█████▍    | 291/532 [07:58<05:09,  1.28s/it]Loading train:  55%|█████▍    | 292/532 [07:59<05:00,  1.25s/it]Loading train:  55%|█████▌    | 293/532 [08:00<04:55,  1.24s/it]Loading train:  55%|█████▌    | 294/532 [08:01<04:37,  1.17s/it]Loading train:  55%|█████▌    | 295/532 [08:02<04:50,  1.23s/it]Loading train:  56%|█████▌    | 296/532 [08:04<04:48,  1.22s/it]Loading train:  56%|█████▌    | 297/532 [08:05<04:40,  1.19s/it]Loading train:  56%|█████▌    | 298/532 [08:06<04:46,  1.22s/it]Loading train:  56%|█████▌    | 299/532 [08:07<04:28,  1.15s/it]Loading train:  56%|█████▋    | 300/532 [08:08<04:23,  1.14s/it]Loading train:  57%|█████▋    | 301/532 [08:09<04:16,  1.11s/it]Loading train:  57%|█████▋    | 302/532 [08:10<04:23,  1.14s/it]Loading train:  57%|█████▋    | 303/532 [08:12<04:17,  1.12s/it]Loading train:  57%|█████▋    | 304/532 [08:13<04:07,  1.08s/it]Loading train:  57%|█████▋    | 305/532 [08:14<04:24,  1.16s/it]Loading train:  58%|█████▊    | 306/532 [08:15<04:38,  1.23s/it]Loading train:  58%|█████▊    | 307/532 [08:17<04:53,  1.30s/it]Loading train:  58%|█████▊    | 308/532 [08:18<05:08,  1.38s/it]Loading train:  58%|█████▊    | 309/532 [08:20<05:16,  1.42s/it]Loading train:  58%|█████▊    | 310/532 [08:21<05:01,  1.36s/it]Loading train:  58%|█████▊    | 311/532 [08:23<06:01,  1.64s/it]Loading train:  59%|█████▊    | 312/532 [08:25<06:03,  1.65s/it]Loading train:  59%|█████▉    | 313/532 [08:27<06:25,  1.76s/it]Loading train:  59%|█████▉    | 314/532 [08:29<06:32,  1.80s/it]Loading train:  59%|█████▉    | 315/532 [08:31<06:26,  1.78s/it]Loading train:  59%|█████▉    | 316/532 [08:32<06:15,  1.74s/it]Loading train:  60%|█████▉    | 317/532 [08:33<05:33,  1.55s/it]Loading train:  60%|█████▉    | 318/532 [08:34<04:58,  1.39s/it]Loading train:  60%|█████▉    | 319/532 [08:36<04:41,  1.32s/it]Loading train:  60%|██████    | 320/532 [08:37<04:31,  1.28s/it]Loading train:  60%|██████    | 321/532 [08:38<04:24,  1.25s/it]Loading train:  61%|██████    | 322/532 [08:39<04:15,  1.22s/it]Loading train:  61%|██████    | 323/532 [08:40<04:24,  1.26s/it]Loading train:  61%|██████    | 324/532 [08:42<04:51,  1.40s/it]Loading train:  61%|██████    | 325/532 [08:44<04:55,  1.43s/it]Loading train:  61%|██████▏   | 326/532 [08:45<04:52,  1.42s/it]Loading train:  61%|██████▏   | 327/532 [08:46<04:44,  1.39s/it]Loading train:  62%|██████▏   | 328/532 [08:48<04:50,  1.43s/it]Loading train:  62%|██████▏   | 329/532 [08:49<04:42,  1.39s/it]Loading train:  62%|██████▏   | 330/532 [08:50<04:30,  1.34s/it]Loading train:  62%|██████▏   | 331/532 [08:52<04:23,  1.31s/it]Loading train:  62%|██████▏   | 332/532 [08:53<04:08,  1.24s/it]Loading train:  63%|██████▎   | 333/532 [08:54<04:03,  1.23s/it]Loading train:  63%|██████▎   | 334/532 [08:55<04:00,  1.21s/it]Loading train:  63%|██████▎   | 335/532 [08:57<04:17,  1.31s/it]Loading train:  63%|██████▎   | 336/532 [08:58<04:11,  1.28s/it]Loading train:  63%|██████▎   | 337/532 [08:59<03:59,  1.23s/it]Loading train:  64%|██████▎   | 338/532 [09:00<04:02,  1.25s/it]Loading train:  64%|██████▎   | 339/532 [09:02<04:07,  1.28s/it]Loading train:  64%|██████▍   | 340/532 [09:03<04:03,  1.27s/it]Loading train:  64%|██████▍   | 341/532 [09:04<03:55,  1.23s/it]Loading train:  64%|██████▍   | 342/532 [09:05<03:35,  1.13s/it]Loading train:  64%|██████▍   | 343/532 [09:06<03:41,  1.17s/it]Loading train:  65%|██████▍   | 344/532 [09:07<03:37,  1.16s/it]Loading train:  65%|██████▍   | 345/532 [09:09<03:42,  1.19s/it]Loading train:  65%|██████▌   | 346/532 [09:10<03:34,  1.15s/it]Loading train:  65%|██████▌   | 347/532 [09:11<03:36,  1.17s/it]Loading train:  65%|██████▌   | 348/532 [09:12<03:30,  1.14s/it]Loading train:  66%|██████▌   | 349/532 [09:13<03:33,  1.16s/it]Loading train:  66%|██████▌   | 350/532 [09:14<03:34,  1.18s/it]Loading train:  66%|██████▌   | 351/532 [09:15<03:28,  1.15s/it]Loading train:  66%|██████▌   | 352/532 [09:17<03:26,  1.15s/it]Loading train:  66%|██████▋   | 353/532 [09:18<03:16,  1.10s/it]Loading train:  67%|██████▋   | 354/532 [09:19<03:11,  1.08s/it]Loading train:  67%|██████▋   | 355/532 [09:20<03:34,  1.21s/it]Loading train:  67%|██████▋   | 356/532 [09:21<03:38,  1.24s/it]Loading train:  67%|██████▋   | 357/532 [09:23<03:29,  1.20s/it]Loading train:  67%|██████▋   | 358/532 [09:24<03:30,  1.21s/it]Loading train:  67%|██████▋   | 359/532 [09:25<03:13,  1.12s/it]Loading train:  68%|██████▊   | 360/532 [09:26<03:12,  1.12s/it]Loading train:  68%|██████▊   | 361/532 [09:27<03:07,  1.10s/it]Loading train:  68%|██████▊   | 362/532 [09:28<02:58,  1.05s/it]Loading train:  68%|██████▊   | 363/532 [09:29<02:57,  1.05s/it]Loading train:  68%|██████▊   | 364/532 [09:30<02:48,  1.00s/it]Loading train:  69%|██████▊   | 365/532 [09:31<03:03,  1.10s/it]Loading train:  69%|██████▉   | 366/532 [09:33<03:34,  1.29s/it]Loading train:  69%|██████▉   | 367/532 [09:34<03:54,  1.42s/it]Loading train:  69%|██████▉   | 368/532 [09:35<03:29,  1.27s/it]Loading train:  69%|██████▉   | 369/532 [09:36<03:11,  1.18s/it]Loading train:  70%|██████▉   | 370/532 [09:37<03:01,  1.12s/it]Loading train:  70%|██████▉   | 371/532 [09:39<03:08,  1.17s/it]Loading train:  70%|██████▉   | 372/532 [09:40<03:08,  1.18s/it]Loading train:  70%|███████   | 373/532 [09:41<03:07,  1.18s/it]Loading train:  70%|███████   | 374/532 [09:42<03:15,  1.24s/it]Loading train:  70%|███████   | 375/532 [09:44<03:18,  1.26s/it]Loading train:  71%|███████   | 376/532 [09:45<03:13,  1.24s/it]Loading train:  71%|███████   | 377/532 [09:46<03:08,  1.22s/it]Loading train:  71%|███████   | 378/532 [09:47<03:10,  1.23s/it]Loading train:  71%|███████   | 379/532 [09:48<02:59,  1.17s/it]Loading train:  71%|███████▏  | 380/532 [09:49<02:48,  1.11s/it]Loading train:  72%|███████▏  | 381/532 [09:50<02:48,  1.12s/it]Loading train:  72%|███████▏  | 382/532 [09:52<02:44,  1.10s/it]Loading train:  72%|███████▏  | 383/532 [09:52<02:38,  1.06s/it]Loading train:  72%|███████▏  | 384/532 [09:53<02:32,  1.03s/it]Loading train:  72%|███████▏  | 385/532 [09:54<02:26,  1.01it/s]Loading train:  73%|███████▎  | 386/532 [09:55<02:24,  1.01it/s]Loading train:  73%|███████▎  | 387/532 [09:56<02:25,  1.01s/it]Loading train:  73%|███████▎  | 388/532 [09:57<02:29,  1.04s/it]Loading train:  73%|███████▎  | 389/532 [09:59<02:37,  1.10s/it]Loading train:  73%|███████▎  | 390/532 [10:00<02:34,  1.09s/it]Loading train:  73%|███████▎  | 391/532 [10:01<02:36,  1.11s/it]Loading train:  74%|███████▎  | 392/532 [10:02<02:40,  1.15s/it]Loading train:  74%|███████▍  | 393/532 [10:03<02:41,  1.16s/it]Loading train:  74%|███████▍  | 394/532 [10:05<02:39,  1.16s/it]Loading train:  74%|███████▍  | 395/532 [10:06<02:33,  1.12s/it]Loading train:  74%|███████▍  | 396/532 [10:07<02:26,  1.08s/it]Loading train:  75%|███████▍  | 397/532 [10:08<02:27,  1.09s/it]Loading train:  75%|███████▍  | 398/532 [10:09<02:31,  1.13s/it]Loading train:  75%|███████▌  | 399/532 [10:10<02:31,  1.14s/it]Loading train:  75%|███████▌  | 400/532 [10:11<02:31,  1.15s/it]Loading train:  75%|███████▌  | 401/532 [10:12<02:33,  1.17s/it]Loading train:  76%|███████▌  | 402/532 [10:14<02:34,  1.19s/it]Loading train:  76%|███████▌  | 403/532 [10:15<02:36,  1.21s/it]Loading train:  76%|███████▌  | 404/532 [10:16<02:33,  1.20s/it]Loading train:  76%|███████▌  | 405/532 [10:17<02:28,  1.17s/it]Loading train:  76%|███████▋  | 406/532 [10:18<02:25,  1.16s/it]Loading train:  77%|███████▋  | 407/532 [10:19<02:18,  1.11s/it]Loading train:  77%|███████▋  | 408/532 [10:20<02:11,  1.06s/it]Loading train:  77%|███████▋  | 409/532 [10:21<02:09,  1.05s/it]Loading train:  77%|███████▋  | 410/532 [10:22<02:07,  1.05s/it]Loading train:  77%|███████▋  | 411/532 [10:23<02:04,  1.02s/it]Loading train:  77%|███████▋  | 412/532 [10:24<02:05,  1.04s/it]Loading train:  78%|███████▊  | 413/532 [10:25<02:04,  1.05s/it]Loading train:  78%|███████▊  | 414/532 [10:27<02:03,  1.05s/it]Loading train:  78%|███████▊  | 415/532 [10:27<01:57,  1.01s/it]Loading train:  78%|███████▊  | 416/532 [10:28<01:56,  1.01s/it]Loading train:  78%|███████▊  | 417/532 [10:30<01:59,  1.04s/it]Loading train:  79%|███████▊  | 418/532 [10:31<01:56,  1.02s/it]Loading train:  79%|███████▉  | 419/532 [10:32<01:59,  1.06s/it]Loading train:  79%|███████▉  | 420/532 [10:33<01:58,  1.06s/it]Loading train:  79%|███████▉  | 421/532 [10:34<01:56,  1.05s/it]Loading train:  79%|███████▉  | 422/532 [10:35<01:55,  1.05s/it]Loading train:  80%|███████▉  | 423/532 [10:36<01:55,  1.06s/it]Loading train:  80%|███████▉  | 424/532 [10:37<01:54,  1.06s/it]Loading train:  80%|███████▉  | 425/532 [10:38<01:54,  1.07s/it]Loading train:  80%|████████  | 426/532 [10:39<01:52,  1.06s/it]Loading train:  80%|████████  | 427/532 [10:40<01:50,  1.05s/it]Loading train:  80%|████████  | 428/532 [10:41<01:50,  1.06s/it]Loading train:  81%|████████  | 429/532 [10:42<01:52,  1.09s/it]Loading train:  81%|████████  | 430/532 [10:43<01:51,  1.10s/it]Loading train:  81%|████████  | 431/532 [10:45<01:52,  1.11s/it]Loading train:  81%|████████  | 432/532 [10:46<01:54,  1.14s/it]Loading train:  81%|████████▏ | 433/532 [10:47<01:54,  1.15s/it]Loading train:  82%|████████▏ | 434/532 [10:48<01:56,  1.19s/it]Loading train:  82%|████████▏ | 435/532 [10:49<01:56,  1.20s/it]Loading train:  82%|████████▏ | 436/532 [10:51<01:50,  1.16s/it]Loading train:  82%|████████▏ | 437/532 [10:51<01:40,  1.06s/it]Loading train:  82%|████████▏ | 438/532 [10:52<01:31,  1.02it/s]Loading train:  83%|████████▎ | 439/532 [10:53<01:25,  1.09it/s]Loading train:  83%|████████▎ | 440/532 [10:54<01:19,  1.15it/s]Loading train:  83%|████████▎ | 441/532 [10:54<01:16,  1.20it/s]Loading train:  83%|████████▎ | 442/532 [10:55<01:15,  1.18it/s]Loading train:  83%|████████▎ | 443/532 [10:56<01:14,  1.19it/s]Loading train:  83%|████████▎ | 444/532 [10:57<01:14,  1.18it/s]Loading train:  84%|████████▎ | 445/532 [10:58<01:17,  1.13it/s]Loading train:  84%|████████▍ | 446/532 [10:59<01:19,  1.08it/s]Loading train:  84%|████████▍ | 447/532 [11:00<01:20,  1.05it/s]Loading train:  84%|████████▍ | 448/532 [11:01<01:19,  1.06it/s]Loading train:  84%|████████▍ | 449/532 [11:02<01:19,  1.05it/s]Loading train:  85%|████████▍ | 450/532 [11:03<01:19,  1.04it/s]Loading train:  85%|████████▍ | 451/532 [11:04<01:15,  1.08it/s]Loading train:  85%|████████▍ | 452/532 [11:05<01:13,  1.08it/s]Loading train:  85%|████████▌ | 453/532 [11:06<01:12,  1.09it/s]Loading train:  85%|████████▌ | 454/532 [11:07<01:13,  1.07it/s]Loading train:  86%|████████▌ | 455/532 [11:08<01:15,  1.02it/s]Loading train:  86%|████████▌ | 456/532 [11:09<01:16,  1.01s/it]Loading train:  86%|████████▌ | 457/532 [11:10<01:15,  1.01s/it]Loading train:  86%|████████▌ | 458/532 [11:11<01:15,  1.02s/it]Loading train:  86%|████████▋ | 459/532 [11:12<01:13,  1.01s/it]Loading train:  86%|████████▋ | 460/532 [11:13<01:13,  1.02s/it]Loading train:  87%|████████▋ | 461/532 [11:14<01:15,  1.06s/it]Loading train:  87%|████████▋ | 462/532 [11:15<01:16,  1.09s/it]Loading train:  87%|████████▋ | 463/532 [11:16<01:16,  1.11s/it]Loading train:  87%|████████▋ | 464/532 [11:17<01:17,  1.13s/it]Loading train:  87%|████████▋ | 465/532 [11:19<01:18,  1.17s/it]Loading train:  88%|████████▊ | 466/532 [11:20<01:18,  1.19s/it]Loading train:  88%|████████▊ | 467/532 [11:21<01:13,  1.14s/it]Loading train:  88%|████████▊ | 468/532 [11:22<01:10,  1.10s/it]Loading train:  88%|████████▊ | 469/532 [11:23<01:07,  1.07s/it]Loading train:  88%|████████▊ | 470/532 [11:24<01:03,  1.03s/it]Loading train:  89%|████████▊ | 471/532 [11:25<01:02,  1.02s/it]Loading train:  89%|████████▊ | 472/532 [11:26<00:59,  1.00it/s]Loading train:  89%|████████▉ | 473/532 [11:27<01:01,  1.04s/it]Loading train:  89%|████████▉ | 474/532 [11:28<01:01,  1.05s/it]Loading train:  89%|████████▉ | 475/532 [11:29<01:00,  1.07s/it]Loading train:  89%|████████▉ | 476/532 [11:30<01:00,  1.09s/it]Loading train:  90%|████████▉ | 477/532 [11:31<00:59,  1.08s/it]Loading train:  90%|████████▉ | 478/532 [11:32<00:58,  1.08s/it]Loading train:  90%|█████████ | 479/532 [11:33<00:55,  1.05s/it]Loading train:  90%|█████████ | 480/532 [11:34<00:52,  1.01s/it]Loading train:  90%|█████████ | 481/532 [11:35<00:49,  1.02it/s]Loading train:  91%|█████████ | 482/532 [11:36<00:49,  1.02it/s]Loading train:  91%|█████████ | 483/532 [11:37<00:46,  1.04it/s]Loading train:  91%|█████████ | 484/532 [11:38<00:46,  1.03it/s]Loading train:  91%|█████████ | 485/532 [11:39<00:48,  1.04s/it]Loading train:  91%|█████████▏| 486/532 [11:41<00:49,  1.07s/it]Loading train:  92%|█████████▏| 487/532 [11:42<00:48,  1.07s/it]Loading train:  92%|█████████▏| 488/532 [11:43<00:45,  1.05s/it]Loading train:  92%|█████████▏| 489/532 [11:44<00:44,  1.04s/it]Loading train:  92%|█████████▏| 490/532 [11:45<00:43,  1.04s/it]Loading train:  92%|█████████▏| 491/532 [11:46<00:41,  1.02s/it]Loading train:  92%|█████████▏| 492/532 [11:47<00:40,  1.01s/it]Loading train:  93%|█████████▎| 493/532 [11:48<00:39,  1.01s/it]Loading train:  93%|█████████▎| 494/532 [11:49<00:38,  1.01s/it]Loading train:  93%|█████████▎| 495/532 [11:50<00:37,  1.01s/it]Loading train:  93%|█████████▎| 496/532 [11:51<00:36,  1.02s/it]Loading train:  93%|█████████▎| 497/532 [11:52<00:35,  1.03s/it]Loading train:  94%|█████████▎| 498/532 [11:53<00:34,  1.01s/it]Loading train:  94%|█████████▍| 499/532 [11:54<00:33,  1.01s/it]Loading train:  94%|█████████▍| 500/532 [11:55<00:31,  1.00it/s]Loading train:  94%|█████████▍| 501/532 [11:56<00:30,  1.02it/s]Loading train:  94%|█████████▍| 502/532 [11:57<00:29,  1.01it/s]Loading train:  95%|█████████▍| 503/532 [11:58<00:28,  1.01it/s]Loading train:  95%|█████████▍| 504/532 [11:59<00:27,  1.02it/s]Loading train:  95%|█████████▍| 505/532 [11:59<00:26,  1.04it/s]Loading train:  95%|█████████▌| 506/532 [12:00<00:24,  1.04it/s]Loading train:  95%|█████████▌| 507/532 [12:01<00:23,  1.06it/s]Loading train:  95%|█████████▌| 508/532 [12:02<00:22,  1.07it/s]Loading train:  96%|█████████▌| 509/532 [12:03<00:23,  1.02s/it]Loading train:  96%|█████████▌| 510/532 [12:05<00:23,  1.05s/it]Loading train:  96%|█████████▌| 511/532 [12:06<00:22,  1.08s/it]Loading train:  96%|█████████▌| 512/532 [12:07<00:21,  1.10s/it]Loading train:  96%|█████████▋| 513/532 [12:08<00:21,  1.12s/it]Loading train:  97%|█████████▋| 514/532 [12:09<00:20,  1.11s/it]Loading train:  97%|█████████▋| 515/532 [12:10<00:18,  1.08s/it]Loading train:  97%|█████████▋| 516/532 [12:11<00:16,  1.04s/it]Loading train:  97%|█████████▋| 517/532 [12:12<00:15,  1.05s/it]Loading train:  97%|█████████▋| 518/532 [12:13<00:14,  1.04s/it]Loading train:  98%|█████████▊| 519/532 [12:14<00:13,  1.05s/it]Loading train:  98%|█████████▊| 520/532 [12:15<00:12,  1.03s/it]Loading train:  98%|█████████▊| 521/532 [12:16<00:11,  1.07s/it]Loading train:  98%|█████████▊| 522/532 [12:17<00:10,  1.07s/it]Loading train:  98%|█████████▊| 523/532 [12:19<00:09,  1.08s/it]Loading train:  98%|█████████▊| 524/532 [12:20<00:08,  1.07s/it]Loading train:  99%|█████████▊| 525/532 [12:21<00:07,  1.07s/it]Loading train:  99%|█████████▉| 526/532 [12:22<00:06,  1.09s/it]Loading train:  99%|█████████▉| 527/532 [12:23<00:05,  1.07s/it]Loading train:  99%|█████████▉| 528/532 [12:24<00:04,  1.05s/it]Loading train:  99%|█████████▉| 529/532 [12:25<00:03,  1.01s/it]Loading train: 100%|█████████▉| 530/532 [12:26<00:02,  1.00s/it]Loading train: 100%|█████████▉| 531/532 [12:27<00:00,  1.01it/s]Loading train: 100%|██████████| 532/532 [12:28<00:00,  1.02s/it]
concatenating: train:   0%|          | 0/532 [00:00<?, ?it/s]concatenating: train:   4%|▍         | 22/532 [00:00<00:02, 212.05it/s]concatenating: train:   9%|▉         | 49/532 [00:00<00:02, 225.31it/s]concatenating: train:  14%|█▍        | 77/532 [00:00<00:01, 239.24it/s]concatenating: train:  20%|█▉        | 105/532 [00:00<00:01, 248.39it/s]concatenating: train:  25%|██▍       | 131/532 [00:00<00:01, 250.21it/s]concatenating: train:  30%|██▉       | 159/532 [00:00<00:01, 256.89it/s]concatenating: train:  35%|███▍      | 186/532 [00:00<00:01, 259.24it/s]concatenating: train:  40%|████      | 213/532 [00:00<00:01, 261.63it/s]concatenating: train:  45%|████▌     | 240/532 [00:00<00:01, 262.32it/s]concatenating: train:  50%|█████     | 268/532 [00:01<00:00, 266.38it/s]concatenating: train:  56%|█████▌    | 297/532 [00:01<00:00, 271.73it/s]concatenating: train:  61%|██████    | 324/532 [00:01<00:00, 268.18it/s]concatenating: train:  66%|██████▌   | 352/532 [00:01<00:00, 269.46it/s]concatenating: train:  71%|███████   | 379/532 [00:01<00:00, 267.69it/s]concatenating: train:  76%|███████▋  | 406/532 [00:01<00:00, 258.80it/s]concatenating: train:  81%|████████▏ | 433/532 [00:01<00:00, 261.46it/s]concatenating: train:  86%|████████▋ | 460/532 [00:01<00:00, 258.91it/s]concatenating: train:  92%|█████████▏| 488/532 [00:01<00:00, 262.75it/s]concatenating: train:  97%|█████████▋| 515/532 [00:01<00:00, 262.58it/s]concatenating: train: 100%|██████████| 532/532 [00:02<00:00, 265.68it/s]
Loading test:   0%|          | 0/15 [00:00<?, ?it/s]Loading test:   7%|▋         | 1/15 [00:00<00:13,  1.06it/s]Loading test:  13%|█▎        | 2/15 [00:02<00:12,  1.01it/s]Loading test:  20%|██        | 3/15 [00:03<00:12,  1.03s/it]Loading test:  27%|██▋       | 4/15 [00:04<00:11,  1.04s/it]Loading test:  33%|███▎      | 5/15 [00:05<00:10,  1.10s/it]Loading test:  40%|████      | 6/15 [00:06<00:10,  1.15s/it]Loading test:  47%|████▋     | 7/15 [00:07<00:08,  1.07s/it]Loading test:  53%|█████▎    | 8/15 [00:08<00:07,  1.12s/it]Loading test:  60%|██████    | 9/15 [00:09<00:06,  1.08s/it]Loading test:  67%|██████▋   | 10/15 [00:10<00:04,  1.00it/s]Loading test:  73%|███████▎  | 11/15 [00:11<00:03,  1.01it/s]Loading test:  80%|████████  | 12/15 [00:12<00:03,  1.02s/it]Loading test:  87%|████████▋ | 13/15 [00:13<00:02,  1.05s/it]Loading test:  93%|█████████▎| 14/15 [00:14<00:01,  1.08s/it]Loading test: 100%|██████████| 15/15 [00:15<00:00,  1.05s/it]
concatenating: validation:   0%|          | 0/15 [00:00<?, ?it/s]concatenating: validation:  47%|████▋     | 7/15 [00:00<00:00, 66.89it/s]concatenating: validation: 100%|██████████| 15/15 [00:00<00:00, 97.30it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 56, 56, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 56, 56, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 56, 56, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 56, 56, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 56, 56, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 56, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 56, 56, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 56, 56, 31)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 31)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28, 28, 31)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 28, 60)   16800       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 28, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 28, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 28, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 28, 28, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 28, 28, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 28, 91)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 91)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 14, 14, 91)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 14, 14, 120)  98400       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 14, 14, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 14, 14, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 14, 14, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 14, 14, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 14, 14, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 14, 14, 211)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 14, 14, 211)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 28, 28, 60)   50700       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 28, 28, 151)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 28, 28, 60)   81600       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 28, 28, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 28, 28, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 28, 28, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 28, 28, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 28, 28, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 28, 28, 211)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-07 10:24:10.055815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 10:24:10.055973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 10:24:10.055989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 10:24:10.055998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 10:24:10.056366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 28, 28, 211)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 56, 56, 30)   25350       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 56, 61)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 56, 56, 30)   16500       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 56, 56, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 56, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 56, 56, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 56, 56, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 56, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 56, 91)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 56, 56, 91)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 56, 56, 13)   1196        dropout_5[0][0]                  
==================================================================================================
Total params: 504,146
Trainable params: 502,946
Non-trainable params: 1,200
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.53974061e-02 2.89048015e-02 1.16758472e-01 1.00223856e-02
 3.03440156e-02 5.80063118e-03 6.84518755e-02 1.28261328e-01
 7.55818021e-02 1.22545826e-02 2.73712232e-01 1.84335085e-01
 1.75382711e-04]
Train on 33496 samples, validate on 969 samples
Epoch 1/300
 - 39s - loss: 21.1516 - acc: 0.8541 - mDice: 0.0585 - val_loss: 2.6484 - val_acc: 0.9127 - val_mDice: 0.1306

Epoch 00001: val_mDice improved from -inf to 0.13056, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 31s - loss: 2.3933 - acc: 0.9329 - mDice: 0.3038 - val_loss: 1.2573 - val_acc: 0.9657 - val_mDice: 0.5299

Epoch 00002: val_mDice improved from 0.13056 to 0.52988, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 31s - loss: 1.4883 - acc: 0.9545 - mDice: 0.5165 - val_loss: 0.8860 - val_acc: 0.9740 - val_mDice: 0.6723

Epoch 00003: val_mDice improved from 0.52988 to 0.67232, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 31s - loss: 1.2296 - acc: 0.9602 - mDice: 0.5915 - val_loss: 0.8050 - val_acc: 0.9763 - val_mDice: 0.7047

Epoch 00004: val_mDice improved from 0.67232 to 0.70473, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 5/300
 - 30s - loss: 1.1015 - acc: 0.9628 - mDice: 0.6288 - val_loss: 0.7657 - val_acc: 0.9782 - val_mDice: 0.7192

Epoch 00005: val_mDice improved from 0.70473 to 0.71919, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 31s - loss: 1.0077 - acc: 0.9647 - mDice: 0.6553 - val_loss: 0.7320 - val_acc: 0.9787 - val_mDice: 0.7343

Epoch 00006: val_mDice improved from 0.71919 to 0.73435, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 7/300
 - 31s - loss: 0.9420 - acc: 0.9659 - mDice: 0.6748 - val_loss: 0.7089 - val_acc: 0.9779 - val_mDice: 0.7409

Epoch 00007: val_mDice improved from 0.73435 to 0.74093, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 8/300
 - 30s - loss: 0.8954 - acc: 0.9668 - mDice: 0.6886 - val_loss: 0.7059 - val_acc: 0.9781 - val_mDice: 0.7408

Epoch 00008: val_mDice did not improve from 0.74093
Epoch 9/300
 - 31s - loss: 0.8555 - acc: 0.9675 - mDice: 0.7004 - val_loss: 0.6946 - val_acc: 0.9785 - val_mDice: 0.7460

Epoch 00009: val_mDice improved from 0.74093 to 0.74598, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 10/300
 - 30s - loss: 0.8208 - acc: 0.9683 - mDice: 0.7104 - val_loss: 0.6818 - val_acc: 0.9796 - val_mDice: 0.7491

Epoch 00010: val_mDice improved from 0.74598 to 0.74905, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 11/300
 - 30s - loss: 0.7929 - acc: 0.9688 - mDice: 0.7185 - val_loss: 0.6642 - val_acc: 0.9794 - val_mDice: 0.7543

Epoch 00011: val_mDice improved from 0.74905 to 0.75432, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 12/300
 - 31s - loss: 0.7712 - acc: 0.9693 - mDice: 0.7252 - val_loss: 0.6557 - val_acc: 0.9782 - val_mDice: 0.7587

Epoch 00012: val_mDice improved from 0.75432 to 0.75870, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 13/300
 - 31s - loss: 0.7520 - acc: 0.9696 - mDice: 0.7310 - val_loss: 0.6782 - val_acc: 0.9806 - val_mDice: 0.7547

Epoch 00013: val_mDice did not improve from 0.75870
Epoch 14/300
 - 30s - loss: 0.7323 - acc: 0.9701 - mDice: 0.7371 - val_loss: 0.6448 - val_acc: 0.9807 - val_mDice: 0.7608

Epoch 00014: val_mDice improved from 0.75870 to 0.76077, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 15/300
 - 31s - loss: 0.7161 - acc: 0.9705 - mDice: 0.7419 - val_loss: 0.6444 - val_acc: 0.9806 - val_mDice: 0.7579

Epoch 00015: val_mDice did not improve from 0.76077
Epoch 16/300
 - 31s - loss: 0.7015 - acc: 0.9708 - mDice: 0.7465 - val_loss: 0.6536 - val_acc: 0.9805 - val_mDice: 0.7603

Epoch 00016: val_mDice did not improve from 0.76077
Epoch 17/300
 - 30s - loss: 0.6877 - acc: 0.9711 - mDice: 0.7511 - val_loss: 0.6764 - val_acc: 0.9804 - val_mDice: 0.7529

Epoch 00017: val_mDice did not improve from 0.76077
Epoch 18/300
 - 30s - loss: 0.6784 - acc: 0.9713 - mDice: 0.7538 - val_loss: 0.6331 - val_acc: 0.9806 - val_mDice: 0.7627

Epoch 00018: val_mDice improved from 0.76077 to 0.76268, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 19/300
 - 31s - loss: 0.6654 - acc: 0.9715 - mDice: 0.7580 - val_loss: 0.6277 - val_acc: 0.9805 - val_mDice: 0.7681

Epoch 00019: val_mDice improved from 0.76268 to 0.76806, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 20/300
 - 30s - loss: 0.6551 - acc: 0.9718 - mDice: 0.7612 - val_loss: 0.6244 - val_acc: 0.9816 - val_mDice: 0.7633

Epoch 00020: val_mDice did not improve from 0.76806
Epoch 21/300
 - 32s - loss: 0.6443 - acc: 0.9721 - mDice: 0.7648 - val_loss: 0.6175 - val_acc: 0.9822 - val_mDice: 0.7705

Epoch 00021: val_mDice improved from 0.76806 to 0.77048, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 22/300
 - 30s - loss: 0.6371 - acc: 0.9722 - mDice: 0.7668 - val_loss: 0.6217 - val_acc: 0.9818 - val_mDice: 0.7684

Epoch 00022: val_mDice did not improve from 0.77048
Epoch 23/300
 - 31s - loss: 0.6291 - acc: 0.9723 - mDice: 0.7699 - val_loss: 0.6163 - val_acc: 0.9812 - val_mDice: 0.7651

Epoch 00023: val_mDice did not improve from 0.77048
Epoch 24/300
 - 30s - loss: 0.6255 - acc: 0.9724 - mDice: 0.7708 - val_loss: 0.6198 - val_acc: 0.9818 - val_mDice: 0.7699

Epoch 00024: val_mDice did not improve from 0.77048
Epoch 25/300
 - 30s - loss: 0.6168 - acc: 0.9726 - mDice: 0.7740 - val_loss: 0.6184 - val_acc: 0.9818 - val_mDice: 0.7639

Epoch 00025: val_mDice did not improve from 0.77048
Epoch 26/300
 - 31s - loss: 0.6097 - acc: 0.9728 - mDice: 0.7759 - val_loss: 0.6171 - val_acc: 0.9824 - val_mDice: 0.7685

Epoch 00026: val_mDice did not improve from 0.77048
Epoch 27/300
 - 31s - loss: 0.6034 - acc: 0.9729 - mDice: 0.7781 - val_loss: 0.6196 - val_acc: 0.9814 - val_mDice: 0.7717

Epoch 00027: val_mDice improved from 0.77048 to 0.77170, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 28/300
 - 30s - loss: 0.5972 - acc: 0.9731 - mDice: 0.7803 - val_loss: 0.6143 - val_acc: 0.9818 - val_mDice: 0.7718

Epoch 00028: val_mDice improved from 0.77170 to 0.77181, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 29/300
 - 31s - loss: 0.5890 - acc: 0.9732 - mDice: 0.7830 - val_loss: 0.6197 - val_acc: 0.9817 - val_mDice: 0.7730

Epoch 00029: val_mDice improved from 0.77181 to 0.77299, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 30/300
 - 31s - loss: 0.5870 - acc: 0.9732 - mDice: 0.7836 - val_loss: 0.6204 - val_acc: 0.9811 - val_mDice: 0.7712

Epoch 00030: val_mDice did not improve from 0.77299
Epoch 31/300
 - 30s - loss: 0.5806 - acc: 0.9733 - mDice: 0.7858 - val_loss: 0.6243 - val_acc: 0.9819 - val_mDice: 0.7670

Epoch 00031: val_mDice did not improve from 0.77299
Epoch 32/300
 - 30s - loss: 0.5749 - acc: 0.9734 - mDice: 0.7877 - val_loss: 0.6081 - val_acc: 0.9823 - val_mDice: 0.7740

Epoch 00032: val_mDice improved from 0.77299 to 0.77398, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 33/300
 - 32s - loss: 0.5704 - acc: 0.9735 - mDice: 0.7893 - val_loss: 0.6216 - val_acc: 0.9811 - val_mDice: 0.7712

Epoch 00033: val_mDice did not improve from 0.77398
Epoch 34/300
 - 31s - loss: 0.5662 - acc: 0.9736 - mDice: 0.7908 - val_loss: 0.6090 - val_acc: 0.9825 - val_mDice: 0.7728

Epoch 00034: val_mDice did not improve from 0.77398
Epoch 35/300
 - 31s - loss: 0.5620 - acc: 0.9736 - mDice: 0.7919 - val_loss: 0.6199 - val_acc: 0.9823 - val_mDice: 0.7747

Epoch 00035: val_mDice improved from 0.77398 to 0.77465, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 36/300
 - 31s - loss: 0.5584 - acc: 0.9737 - mDice: 0.7934 - val_loss: 0.6272 - val_acc: 0.9824 - val_mDice: 0.7732

Epoch 00036: val_mDice did not improve from 0.77465
Epoch 37/300
 - 31s - loss: 0.5545 - acc: 0.9737 - mDice: 0.7947 - val_loss: 0.6214 - val_acc: 0.9815 - val_mDice: 0.7790

Epoch 00037: val_mDice improved from 0.77465 to 0.77895, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 38/300
 - 32s - loss: 0.5517 - acc: 0.9738 - mDice: 0.7956 - val_loss: 0.6189 - val_acc: 0.9823 - val_mDice: 0.7743

Epoch 00038: val_mDice did not improve from 0.77895
Epoch 39/300
 - 31s - loss: 0.5478 - acc: 0.9739 - mDice: 0.7969 - val_loss: 0.6198 - val_acc: 0.9820 - val_mDice: 0.7758

Epoch 00039: val_mDice did not improve from 0.77895
Epoch 40/300
 - 31s - loss: 0.5441 - acc: 0.9739 - mDice: 0.7979 - val_loss: 0.6235 - val_acc: 0.9812 - val_mDice: 0.7754

Epoch 00040: val_mDice did not improve from 0.77895
Epoch 41/300
 - 32s - loss: 0.5411 - acc: 0.9740 - mDice: 0.7992 - val_loss: 0.6326 - val_acc: 0.9817 - val_mDice: 0.7772

Epoch 00041: val_mDice did not improve from 0.77895
Epoch 42/300
 - 30s - loss: 0.5397 - acc: 0.9740 - mDice: 0.8000 - val_loss: 0.6351 - val_acc: 0.9823 - val_mDice: 0.7757

Epoch 00042: val_mDice did not improve from 0.77895
Epoch 43/300
 - 32s - loss: 0.5355 - acc: 0.9741 - mDice: 0.8013 - val_loss: 0.6126 - val_acc: 0.9827 - val_mDice: 0.7815

Epoch 00043: val_mDice improved from 0.77895 to 0.78148, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 44/300
 - 31s - loss: 0.5335 - acc: 0.9741 - mDice: 0.8021 - val_loss: 0.6407 - val_acc: 0.9822 - val_mDice: 0.7739

Epoch 00044: val_mDice did not improve from 0.78148
Epoch 45/300
 - 31s - loss: 0.5306 - acc: 0.9742 - mDice: 0.8029 - val_loss: 0.6166 - val_acc: 0.9826 - val_mDice: 0.7774

Epoch 00045: val_mDice did not improve from 0.78148
Epoch 46/300
 - 31s - loss: 0.5282 - acc: 0.9742 - mDice: 0.8037 - val_loss: 0.6284 - val_acc: 0.9822 - val_mDice: 0.7758

Epoch 00046: val_mDice did not improve from 0.78148
Epoch 47/300
 - 30s - loss: 0.5250 - acc: 0.9742 - mDice: 0.8048 - val_loss: 0.6272 - val_acc: 0.9820 - val_mDice: 0.7792

Epoch 00047: val_mDice did not improve from 0.78148
Epoch 48/300
 - 32s - loss: 0.5230 - acc: 0.9743 - mDice: 0.8057 - val_loss: 0.6333 - val_acc: 0.9823 - val_mDice: 0.7759

Epoch 00048: val_mDice did not improve from 0.78148
Epoch 49/300
 - 31s - loss: 0.5187 - acc: 0.9743 - mDice: 0.8071 - val_loss: 0.6166 - val_acc: 0.9823 - val_mDice: 0.7780

Epoch 00049: val_mDice did not improve from 0.78148
Epoch 50/300
 - 31s - loss: 0.5199 - acc: 0.9743 - mDice: 0.8066 - val_loss: 0.6253 - val_acc: 0.9824 - val_mDice: 0.7789

Epoch 00050: val_mDice did not improve from 0.78148
Epoch 51/300
 - 32s - loss: 0.5180 - acc: 0.9744 - mDice: 0.8074 - val_loss: 0.6311 - val_acc: 0.9818 - val_mDice: 0.7804

Epoch 00051: val_mDice did not improve from 0.78148
Epoch 52/300
 - 32s - loss: 0.5149 - acc: 0.9744 - mDice: 0.8087 - val_loss: 0.6200 - val_acc: 0.9823 - val_mDice: 0.7796

Epoch 00052: val_mDice did not improve from 0.78148
Epoch 53/300
 - 31s - loss: 0.5123 - acc: 0.9744 - mDice: 0.8095 - val_loss: 0.6385 - val_acc: 0.9819 - val_mDice: 0.7751

Epoch 00053: val_mDice did not improve from 0.78148
Epoch 54/300
 - 31s - loss: 0.5101 - acc: 0.9745 - mDice: 0.8104 - val_loss: 0.6302 - val_acc: 0.9823 - val_mDice: 0.7772

Epoch 00054: val_mDice did not improve from 0.78148
Epoch 55/300
 - 32s - loss: 0.5105 - acc: 0.9745 - mDice: 0.8101 - val_loss: 0.6338 - val_acc: 0.9822 - val_mDice: 0.7815

Epoch 00055: val_mDice did not improve from 0.78148
Epoch 56/300
 - 30s - loss: 0.5075 - acc: 0.9745 - mDice: 0.8112 - val_loss: 0.6355 - val_acc: 0.9818 - val_mDice: 0.7804

Epoch 00056: val_mDice did not improve from 0.78148
Epoch 57/300
 - 32s - loss: 0.5067 - acc: 0.9746 - mDice: 0.8115 - val_loss: 0.6453 - val_acc: 0.9827 - val_mDice: 0.7805

Epoch 00057: val_mDice did not improve from 0.78148
Epoch 58/300
 - 32s - loss: 0.5026 - acc: 0.9746 - mDice: 0.8129 - val_loss: 0.6368 - val_acc: 0.9827 - val_mDice: 0.7838

Epoch 00058: val_mDice improved from 0.78148 to 0.78382, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 59/300
 - 31s - loss: 0.5018 - acc: 0.9746 - mDice: 0.8134 - val_loss: 0.6422 - val_acc: 0.9821 - val_mDice: 0.7825

Epoch 00059: val_mDice did not improve from 0.78382
Epoch 60/300
 - 32s - loss: 0.5006 - acc: 0.9746 - mDice: 0.8139 - val_loss: 0.6305 - val_acc: 0.9821 - val_mDice: 0.7834

Epoch 00060: val_mDice did not improve from 0.78382
Epoch 61/300
 - 32s - loss: 0.4998 - acc: 0.9746 - mDice: 0.8141 - val_loss: 0.6443 - val_acc: 0.9817 - val_mDice: 0.7799

Epoch 00061: val_mDice did not improve from 0.78382
Epoch 62/300
 - 30s - loss: 0.4979 - acc: 0.9747 - mDice: 0.8147 - val_loss: 0.6439 - val_acc: 0.9822 - val_mDice: 0.7828

Epoch 00062: val_mDice did not improve from 0.78382
Epoch 63/300
 - 32s - loss: 0.4974 - acc: 0.9747 - mDice: 0.8151 - val_loss: 0.6392 - val_acc: 0.9822 - val_mDice: 0.7820

Epoch 00063: val_mDice did not improve from 0.78382
Epoch 64/300
 - 31s - loss: 0.4947 - acc: 0.9748 - mDice: 0.8158 - val_loss: 0.6561 - val_acc: 0.9816 - val_mDice: 0.7776

Epoch 00064: val_mDice did not improve from 0.78382
Epoch 65/300
 - 31s - loss: 0.4936 - acc: 0.9748 - mDice: 0.8164 - val_loss: 0.6467 - val_acc: 0.9820 - val_mDice: 0.7767

Epoch 00065: val_mDice did not improve from 0.78382
Epoch 66/300
 - 32s - loss: 0.4923 - acc: 0.9748 - mDice: 0.8166 - val_loss: 0.6361 - val_acc: 0.9822 - val_mDice: 0.7804

Epoch 00066: val_mDice did not improve from 0.78382
Epoch 67/300
 - 32s - loss: 0.4904 - acc: 0.9748 - mDice: 0.8175 - val_loss: 0.6472 - val_acc: 0.9820 - val_mDice: 0.7828

Epoch 00067: val_mDice did not improve from 0.78382
Epoch 68/300
 - 32s - loss: 0.4904 - acc: 0.9748 - mDice: 0.8176 - val_loss: 0.6285 - val_acc: 0.9826 - val_mDice: 0.7834

Epoch 00068: val_mDice did not improve from 0.78382
Epoch 69/300
 - 31s - loss: 0.4878 - acc: 0.9749 - mDice: 0.8182 - val_loss: 0.6417 - val_acc: 0.9826 - val_mDice: 0.7837

Epoch 00069: val_mDice did not improve from 0.78382
Epoch 70/300
 - 31s - loss: 0.4882 - acc: 0.9749 - mDice: 0.8182 - val_loss: 0.6360 - val_acc: 0.9823 - val_mDice: 0.7855

Epoch 00070: val_mDice improved from 0.78382 to 0.78548, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 71/300
 - 32s - loss: 0.4863 - acc: 0.9749 - mDice: 0.8189 - val_loss: 0.6450 - val_acc: 0.9824 - val_mDice: 0.7807

Epoch 00071: val_mDice did not improve from 0.78548
Epoch 72/300
 - 31s - loss: 0.4849 - acc: 0.9749 - mDice: 0.8194 - val_loss: 0.6539 - val_acc: 0.9826 - val_mDice: 0.7804

Epoch 00072: val_mDice did not improve from 0.78548
Epoch 73/300
 - 31s - loss: 0.4851 - acc: 0.9749 - mDice: 0.8195 - val_loss: 0.6491 - val_acc: 0.9824 - val_mDice: 0.7803

Epoch 00073: val_mDice did not improve from 0.78548
Epoch 74/300
 - 32s - loss: 0.4830 - acc: 0.9749 - mDice: 0.8200 - val_loss: 0.6527 - val_acc: 0.9824 - val_mDice: 0.7820

Epoch 00074: val_mDice did not improve from 0.78548
Epoch 75/300
 - 31s - loss: 0.4811 - acc: 0.9750 - mDice: 0.8210 - val_loss: 0.6615 - val_acc: 0.9820 - val_mDice: 0.7801

Epoch 00075: val_mDice did not improve from 0.78548
Epoch 76/300
 - 31s - loss: 0.4803 - acc: 0.9750 - mDice: 0.8214 - val_loss: 0.6600 - val_acc: 0.9824 - val_mDice: 0.7805

Epoch 00076: val_mDice did not improve from 0.78548
Epoch 77/300
 - 32s - loss: 0.4794 - acc: 0.9750 - mDice: 0.8215 - val_loss: 0.6519 - val_acc: 0.9823 - val_mDice: 0.7837

Epoch 00077: val_mDice did not improve from 0.78548
Epoch 78/300
 - 31s - loss: 0.4793 - acc: 0.9750 - mDice: 0.8216 - val_loss: 0.6774 - val_acc: 0.9824 - val_mDice: 0.7803

Epoch 00078: val_mDice did not improve from 0.78548
Epoch 79/300
 - 31s - loss: 0.4772 - acc: 0.9751 - mDice: 0.8225 - val_loss: 0.6529 - val_acc: 0.9820 - val_mDice: 0.7821

Epoch 00079: val_mDice did not improve from 0.78548
Epoch 80/300
 - 32s - loss: 0.4757 - acc: 0.9751 - mDice: 0.8229 - val_loss: 0.6797 - val_acc: 0.9824 - val_mDice: 0.7799

Epoch 00080: val_mDice did not improve from 0.78548
Epoch 81/300
 - 31s - loss: 0.4748 - acc: 0.9751 - mDice: 0.8230 - val_loss: 0.6377 - val_acc: 0.9824 - val_mDice: 0.7819

Epoch 00081: val_mDice did not improve from 0.78548
Epoch 82/300
 - 31s - loss: 0.4730 - acc: 0.9751 - mDice: 0.8241 - val_loss: 0.6457 - val_acc: 0.9826 - val_mDice: 0.7823

Epoch 00082: val_mDice did not improve from 0.78548
Epoch 83/300
 - 31s - loss: 0.4733 - acc: 0.9751 - mDice: 0.8240 - val_loss: 0.6626 - val_acc: 0.9827 - val_mDice: 0.7851

Epoch 00083: val_mDice did not improve from 0.78548
Epoch 84/300
 - 31s - loss: 0.4723 - acc: 0.9751 - mDice: 0.8242 - val_loss: 0.6553 - val_acc: 0.9826 - val_mDice: 0.7846

Epoch 00084: val_mDice did not improve from 0.78548
Epoch 85/300
 - 31s - loss: 0.4710 - acc: 0.9751 - mDice: 0.8249 - val_loss: 0.6653 - val_acc: 0.9826 - val_mDice: 0.7746

Epoch 00085: val_mDice did not improve from 0.78548
Epoch 86/300
 - 31s - loss: 0.4715 - acc: 0.9751 - mDice: 0.8246 - val_loss: 0.6701 - val_acc: 0.9824 - val_mDice: 0.7829

Epoch 00086: val_mDice did not improve from 0.78548
Epoch 87/300
 - 32s - loss: 0.4705 - acc: 0.9752 - mDice: 0.8246 - val_loss: 0.6528 - val_acc: 0.9820 - val_mDice: 0.7850

Epoch 00087: val_mDice did not improve from 0.78548
Epoch 88/300
 - 30s - loss: 0.4699 - acc: 0.9752 - mDice: 0.8251 - val_loss: 0.6593 - val_acc: 0.9824 - val_mDice: 0.7847

Epoch 00088: val_mDice did not improve from 0.78548
Epoch 89/300
 - 31s - loss: 0.4693 - acc: 0.9752 - mDice: 0.8252 - val_loss: 0.6689 - val_acc: 0.9827 - val_mDice: 0.7830

Epoch 00089: val_mDice did not improve from 0.78548
Epoch 90/300
 - 31s - loss: 0.4662 - acc: 0.9752 - mDice: 0.8262 - val_loss: 0.6565 - val_acc: 0.9825 - val_mDice: 0.7823

Epoch 00090: val_mDice did not improve from 0.78548
Epoch 91/300
 - 30s - loss: 0.4662 - acc: 0.9752 - mDice: 0.8263 - val_loss: 0.6668 - val_acc: 0.9822 - val_mDice: 0.7819

Epoch 00091: val_mDice did not improve from 0.78548
Epoch 92/300
 - 32s - loss: 0.4658 - acc: 0.9753 - mDice: 0.8264 - val_loss: 0.6577 - val_acc: 0.9821 - val_mDice: 0.7843

Epoch 00092: val_mDice did not improve from 0.78548
Epoch 93/300
 - 31s - loss: 0.4661 - acc: 0.9753 - mDice: 0.8265 - val_loss: 0.6673 - val_acc: 0.9822 - val_mDice: 0.7788

Epoch 00093: val_mDice did not improve from 0.78548
Epoch 94/300
 - 30s - loss: 0.4647 - acc: 0.9753 - mDice: 0.8272 - val_loss: 0.6556 - val_acc: 0.9826 - val_mDice: 0.7837

Epoch 00094: val_mDice did not improve from 0.78548
Epoch 95/300
 - 32s - loss: 0.4628 - acc: 0.9753 - mDice: 0.8277 - val_loss: 0.6563 - val_acc: 0.9830 - val_mDice: 0.7834

Epoch 00095: val_mDice did not improve from 0.78548
Epoch 96/300
 - 31s - loss: 0.4639 - acc: 0.9753 - mDice: 0.8274 - val_loss: 0.6625 - val_acc: 0.9825 - val_mDice: 0.7864

Epoch 00096: val_mDice improved from 0.78548 to 0.78641, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 97/300
 - 30s - loss: 0.4620 - acc: 0.9753 - mDice: 0.8280 - val_loss: 0.6659 - val_acc: 0.9830 - val_mDice: 0.7836

Epoch 00097: val_mDice did not improve from 0.78641
Epoch 98/300
 - 32s - loss: 0.4616 - acc: 0.9753 - mDice: 0.8280 - val_loss: 0.6681 - val_acc: 0.9820 - val_mDice: 0.7829

Epoch 00098: val_mDice did not improve from 0.78641
Epoch 99/300
 - 30s - loss: 0.4603 - acc: 0.9753 - mDice: 0.8286 - val_loss: 0.6790 - val_acc: 0.9818 - val_mDice: 0.7802

Epoch 00099: val_mDice did not improve from 0.78641
Epoch 100/300
 - 31s - loss: 0.4607 - acc: 0.9753 - mDice: 0.8285 - val_loss: 0.6653 - val_acc: 0.9826 - val_mDice: 0.7842

Epoch 00100: val_mDice did not improve from 0.78641
Epoch 101/300
 - 31s - loss: 0.4590 - acc: 0.9754 - mDice: 0.8291 - val_loss: 0.6637 - val_acc: 0.9828 - val_mDice: 0.7843

Epoch 00101: val_mDice did not improve from 0.78641
Epoch 102/300
 - 30s - loss: 0.4586 - acc: 0.9754 - mDice: 0.8292 - val_loss: 0.6704 - val_acc: 0.9818 - val_mDice: 0.7852

Epoch 00102: val_mDice did not improve from 0.78641
Epoch 103/300
 - 32s - loss: 0.4590 - acc: 0.9754 - mDice: 0.8291 - val_loss: 0.6660 - val_acc: 0.9824 - val_mDice: 0.7833

Epoch 00103: val_mDice did not improve from 0.78641
Epoch 104/300
 - 31s - loss: 0.4572 - acc: 0.9754 - mDice: 0.8296 - val_loss: 0.6729 - val_acc: 0.9827 - val_mDice: 0.7846

Epoch 00104: val_mDice did not improve from 0.78641
Epoch 105/300
 - 31s - loss: 0.4581 - acc: 0.9754 - mDice: 0.8295 - val_loss: 0.6630 - val_acc: 0.9826 - val_mDice: 0.7862

Epoch 00105: val_mDice did not improve from 0.78641
Epoch 106/300
 - 31s - loss: 0.4556 - acc: 0.9754 - mDice: 0.8304 - val_loss: 0.6691 - val_acc: 0.9826 - val_mDice: 0.7834

Epoch 00106: val_mDice did not improve from 0.78641
Epoch 107/300
 - 32s - loss: 0.4562 - acc: 0.9754 - mDice: 0.8302 - val_loss: 0.6749 - val_acc: 0.9822 - val_mDice: 0.7852

Epoch 00107: val_mDice did not improve from 0.78641
Epoch 108/300
 - 30s - loss: 0.4546 - acc: 0.9754 - mDice: 0.8307 - val_loss: 0.6628 - val_acc: 0.9824 - val_mDice: 0.7836

Epoch 00108: val_mDice did not improve from 0.78641
Epoch 109/300
 - 32s - loss: 0.4559 - acc: 0.9755 - mDice: 0.8305 - val_loss: 0.6696 - val_acc: 0.9825 - val_mDice: 0.7834

Epoch 00109: val_mDice did not improve from 0.78641
Epoch 110/300
 - 31s - loss: 0.4532 - acc: 0.9755 - mDice: 0.8313 - val_loss: 0.6816 - val_acc: 0.9822 - val_mDice: 0.7820

Epoch 00110: val_mDice did not improve from 0.78641
Epoch 111/300
 - 32s - loss: 0.4535 - acc: 0.9754 - mDice: 0.8312 - val_loss: 0.6849 - val_acc: 0.9824 - val_mDice: 0.7822

Epoch 00111: val_mDice did not improve from 0.78641
Epoch 112/300
 - 32s - loss: 0.4532 - acc: 0.9755 - mDice: 0.8312 - val_loss: 0.6976 - val_acc: 0.9827 - val_mDice: 0.7818

Epoch 00112: val_mDice did not improve from 0.78641
Epoch 113/300
 - 32s - loss: 0.4533 - acc: 0.9755 - mDice: 0.8313 - val_loss: 0.6693 - val_acc: 0.9827 - val_mDice: 0.7858

Epoch 00113: val_mDice did not improve from 0.78641
Epoch 114/300
 - 31s - loss: 0.4526 - acc: 0.9755 - mDice: 0.8315 - val_loss: 0.6839 - val_acc: 0.9825 - val_mDice: 0.7798

Epoch 00114: val_mDice did not improve from 0.78641
Epoch 115/300
 - 31s - loss: 0.4503 - acc: 0.9755 - mDice: 0.8323 - val_loss: 0.6750 - val_acc: 0.9827 - val_mDice: 0.7828

Epoch 00115: val_mDice did not improve from 0.78641
Epoch 116/300
 - 32s - loss: 0.4503 - acc: 0.9755 - mDice: 0.8324 - val_loss: 0.7004 - val_acc: 0.9820 - val_mDice: 0.7811

Epoch 00116: val_mDice did not improve from 0.78641
Epoch 117/300
 - 31s - loss: 0.4496 - acc: 0.9755 - mDice: 0.8325 - val_loss: 0.6692 - val_acc: 0.9825 - val_mDice: 0.7864

Epoch 00117: val_mDice did not improve from 0.78641
Epoch 118/300
 - 31s - loss: 0.4497 - acc: 0.9755 - mDice: 0.8326 - val_loss: 0.6868 - val_acc: 0.9821 - val_mDice: 0.7833

Epoch 00118: val_mDice did not improve from 0.78641
Epoch 119/300
 - 32s - loss: 0.4496 - acc: 0.9755 - mDice: 0.8328 - val_loss: 0.7071 - val_acc: 0.9828 - val_mDice: 0.7812

Epoch 00119: val_mDice did not improve from 0.78641
Epoch 120/300
 - 32s - loss: 0.4483 - acc: 0.9755 - mDice: 0.8331 - val_loss: 0.7126 - val_acc: 0.9822 - val_mDice: 0.7801

Epoch 00120: val_mDice did not improve from 0.78641
Epoch 121/300
 - 31s - loss: 0.4476 - acc: 0.9756 - mDice: 0.8335 - val_loss: 0.6750 - val_acc: 0.9827 - val_mDice: 0.7862

Epoch 00121: val_mDice did not improve from 0.78641
Epoch 122/300
 - 31s - loss: 0.4482 - acc: 0.9756 - mDice: 0.8330 - val_loss: 0.6745 - val_acc: 0.9826 - val_mDice: 0.7842

Epoch 00122: val_mDice did not improve from 0.78641
Epoch 123/300
 - 31s - loss: 0.4458 - acc: 0.9756 - mDice: 0.8340 - val_loss: 0.6668 - val_acc: 0.9826 - val_mDice: 0.7864

Epoch 00123: val_mDice did not improve from 0.78641
Epoch 124/300
 - 31s - loss: 0.4458 - acc: 0.9756 - mDice: 0.8340 - val_loss: 0.6891 - val_acc: 0.9826 - val_mDice: 0.7826

Epoch 00124: val_mDice did not improve from 0.78641
Epoch 125/300
 - 31s - loss: 0.4451 - acc: 0.9756 - mDice: 0.8344 - val_loss: 0.6830 - val_acc: 0.9820 - val_mDice: 0.7870

Epoch 00125: val_mDice improved from 0.78641 to 0.78701, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 126/300
 - 31s - loss: 0.4464 - acc: 0.9756 - mDice: 0.8338 - val_loss: 0.6819 - val_acc: 0.9824 - val_mDice: 0.7856

Epoch 00126: val_mDice did not improve from 0.78701
Epoch 127/300
 - 31s - loss: 0.4444 - acc: 0.9756 - mDice: 0.8345 - val_loss: 0.6965 - val_acc: 0.9820 - val_mDice: 0.7850

Epoch 00127: val_mDice did not improve from 0.78701
Epoch 128/300
 - 30s - loss: 0.4447 - acc: 0.9756 - mDice: 0.8344 - val_loss: 0.6882 - val_acc: 0.9824 - val_mDice: 0.7844

Epoch 00128: val_mDice did not improve from 0.78701
Epoch 129/300
 - 32s - loss: 0.4446 - acc: 0.9756 - mDice: 0.8343 - val_loss: 0.7024 - val_acc: 0.9825 - val_mDice: 0.7838

Epoch 00129: val_mDice did not improve from 0.78701
Epoch 130/300
 - 31s - loss: 0.4436 - acc: 0.9756 - mDice: 0.8349 - val_loss: 0.6828 - val_acc: 0.9821 - val_mDice: 0.7884

Epoch 00130: val_mDice improved from 0.78701 to 0.78838, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 131/300
 - 31s - loss: 0.4436 - acc: 0.9756 - mDice: 0.8348 - val_loss: 0.6895 - val_acc: 0.9826 - val_mDice: 0.7869

Epoch 00131: val_mDice did not improve from 0.78838
Epoch 132/300
 - 31s - loss: 0.4424 - acc: 0.9757 - mDice: 0.8352 - val_loss: 0.7035 - val_acc: 0.9824 - val_mDice: 0.7837

Epoch 00132: val_mDice did not improve from 0.78838
Epoch 133/300
 - 32s - loss: 0.4422 - acc: 0.9757 - mDice: 0.8352 - val_loss: 0.6807 - val_acc: 0.9820 - val_mDice: 0.7864

Epoch 00133: val_mDice did not improve from 0.78838
Epoch 134/300
 - 31s - loss: 0.4421 - acc: 0.9757 - mDice: 0.8354 - val_loss: 0.6857 - val_acc: 0.9824 - val_mDice: 0.7852

Epoch 00134: val_mDice did not improve from 0.78838
Epoch 135/300
 - 31s - loss: 0.4429 - acc: 0.9757 - mDice: 0.8353 - val_loss: 0.6960 - val_acc: 0.9824 - val_mDice: 0.7808

Epoch 00135: val_mDice did not improve from 0.78838
Epoch 136/300
 - 32s - loss: 0.4402 - acc: 0.9757 - mDice: 0.8362 - val_loss: 0.6955 - val_acc: 0.9825 - val_mDice: 0.7871

Epoch 00136: val_mDice did not improve from 0.78838
Epoch 137/300
 - 32s - loss: 0.4407 - acc: 0.9757 - mDice: 0.8359 - val_loss: 0.6956 - val_acc: 0.9826 - val_mDice: 0.7875

Epoch 00137: val_mDice did not improve from 0.78838
Epoch 138/300
 - 30s - loss: 0.4401 - acc: 0.9757 - mDice: 0.8364 - val_loss: 0.6807 - val_acc: 0.9827 - val_mDice: 0.7872

Epoch 00138: val_mDice did not improve from 0.78838
Epoch 139/300
 - 32s - loss: 0.4384 - acc: 0.9757 - mDice: 0.8367 - val_loss: 0.6931 - val_acc: 0.9824 - val_mDice: 0.7845

Epoch 00139: val_mDice did not improve from 0.78838
Epoch 140/300
 - 31s - loss: 0.4399 - acc: 0.9757 - mDice: 0.8362 - val_loss: 0.6825 - val_acc: 0.9832 - val_mDice: 0.7834

Epoch 00140: val_mDice did not improve from 0.78838
Epoch 141/300
 - 31s - loss: 0.4392 - acc: 0.9757 - mDice: 0.8365 - val_loss: 0.6976 - val_acc: 0.9824 - val_mDice: 0.7841

Epoch 00141: val_mDice did not improve from 0.78838
Epoch 142/300
 - 31s - loss: 0.4397 - acc: 0.9757 - mDice: 0.8361 - val_loss: 0.6929 - val_acc: 0.9823 - val_mDice: 0.7845

Epoch 00142: val_mDice did not improve from 0.78838
Epoch 143/300
 - 31s - loss: 0.4375 - acc: 0.9757 - mDice: 0.8371 - val_loss: 0.6950 - val_acc: 0.9828 - val_mDice: 0.7835

Epoch 00143: val_mDice did not improve from 0.78838
Epoch 144/300
 - 32s - loss: 0.4387 - acc: 0.9757 - mDice: 0.8366 - val_loss: 0.6983 - val_acc: 0.9827 - val_mDice: 0.7824

Epoch 00144: val_mDice did not improve from 0.78838
Epoch 145/300
 - 32s - loss: 0.4365 - acc: 0.9757 - mDice: 0.8375 - val_loss: 0.6936 - val_acc: 0.9825 - val_mDice: 0.7841

Epoch 00145: val_mDice did not improve from 0.78838
Epoch 146/300
 - 31s - loss: 0.4374 - acc: 0.9757 - mDice: 0.8370 - val_loss: 0.6974 - val_acc: 0.9825 - val_mDice: 0.7836

Epoch 00146: val_mDice did not improve from 0.78838
Epoch 147/300
 - 31s - loss: 0.4374 - acc: 0.9757 - mDice: 0.8370 - val_loss: 0.6976 - val_acc: 0.9828 - val_mDice: 0.7851

Epoch 00147: val_mDice did not improve from 0.78838
Epoch 148/300
 - 32s - loss: 0.4356 - acc: 0.9758 - mDice: 0.8381 - val_loss: 0.7208 - val_acc: 0.9827 - val_mDice: 0.7813

Epoch 00148: val_mDice did not improve from 0.78838
Epoch 149/300
 - 31s - loss: 0.4355 - acc: 0.9758 - mDice: 0.8380 - val_loss: 0.6964 - val_acc: 0.9824 - val_mDice: 0.7841

Epoch 00149: val_mDice did not improve from 0.78838
Epoch 150/300
 - 31s - loss: 0.4361 - acc: 0.9758 - mDice: 0.8379 - val_loss: 0.7042 - val_acc: 0.9826 - val_mDice: 0.7876

Epoch 00150: val_mDice did not improve from 0.78838
Epoch 151/300
 - 31s - loss: 0.4359 - acc: 0.9758 - mDice: 0.8378 - val_loss: 0.6909 - val_acc: 0.9825 - val_mDice: 0.7875

Epoch 00151: val_mDice did not improve from 0.78838
Epoch 152/300
 - 31s - loss: 0.4346 - acc: 0.9757 - mDice: 0.8383 - val_loss: 0.7042 - val_acc: 0.9827 - val_mDice: 0.7846

Epoch 00152: val_mDice did not improve from 0.78838
Epoch 153/300
 - 31s - loss: 0.4351 - acc: 0.9758 - mDice: 0.8380 - val_loss: 0.6946 - val_acc: 0.9825 - val_mDice: 0.7850

Epoch 00153: val_mDice did not improve from 0.78838
Epoch 154/300
 - 31s - loss: 0.4345 - acc: 0.9758 - mDice: 0.8383 - val_loss: 0.6904 - val_acc: 0.9822 - val_mDice: 0.7858

Epoch 00154: val_mDice did not improve from 0.78838
Epoch 155/300
 - 32s - loss: 0.4341 - acc: 0.9758 - mDice: 0.8384 - val_loss: 0.6937 - val_acc: 0.9826 - val_mDice: 0.7852

Epoch 00155: val_mDice did not improve from 0.78838
Epoch 156/300
 - 30s - loss: 0.4331 - acc: 0.9758 - mDice: 0.8389 - val_loss: 0.7218 - val_acc: 0.9821 - val_mDice: 0.7821

Epoch 00156: val_mDice did not improve from 0.78838
Epoch 157/300
 - 32s - loss: 0.4335 - acc: 0.9758 - mDice: 0.8388 - val_loss: 0.7057 - val_acc: 0.9826 - val_mDice: 0.7801

Epoch 00157: val_mDice did not improve from 0.78838
Epoch 158/300
 - 31s - loss: 0.4318 - acc: 0.9758 - mDice: 0.8394 - val_loss: 0.7207 - val_acc: 0.9825 - val_mDice: 0.7818

Epoch 00158: val_mDice did not improve from 0.78838
Epoch 159/300
 - 31s - loss: 0.4319 - acc: 0.9758 - mDice: 0.8392 - val_loss: 0.7142 - val_acc: 0.9827 - val_mDice: 0.7832

Epoch 00159: val_mDice did not improve from 0.78838
Epoch 160/300
 - 31s - loss: 0.4312 - acc: 0.9758 - mDice: 0.8397 - val_loss: 0.7047 - val_acc: 0.9827 - val_mDice: 0.7836

Epoch 00160: val_mDice did not improve from 0.78838
Restoring model weights from the end of the best epoch
Epoch 00160: early stopping
{'val_loss': [2.64838196938498, 1.2573348475068469, 0.8859955261858378, 0.8050176618145961, 0.7656789056041784, 0.7319649980779279, 0.7088699047102893, 0.7059475260068757, 0.6946099526311345, 0.6818196712325109, 0.664206804844125, 0.6557452443398928, 0.6782081622641891, 0.6448451894171098, 0.644419227960309, 0.6535514476560095, 0.6763535981884435, 0.6331480872520352, 0.6276873415960739, 0.6243671050258711, 0.6175221982570624, 0.6217026897812775, 0.6162632045915621, 0.6198063397432136, 0.6183500061094207, 0.6171495169862505, 0.6195907135127867, 0.6143102259274238, 0.6197013215568412, 0.620427282755835, 0.6243038041242259, 0.6081230076966024, 0.6215815121544404, 0.609040439590212, 0.6199199091047203, 0.6272428920579031, 0.6214029620736992, 0.618939237913234, 0.6197786725465482, 0.6235057168454701, 0.6326438519792291, 0.6351249009155514, 0.6125801698342196, 0.6407455060750216, 0.6165639343522528, 0.6284344708402828, 0.6272313284800148, 0.6332926696975657, 0.6166342511327151, 0.6252897386395895, 0.631107712647002, 0.6200395138209572, 0.6384752601292849, 0.630174760109869, 0.6338220863334904, 0.6354954786775528, 0.6453409436686489, 0.6367758795449854, 0.6421590324710397, 0.6305411089253992, 0.6443408834983444, 0.6438792430948547, 0.6391787000915461, 0.6561484350693115, 0.6467164339357362, 0.6360628411127687, 0.6472196638645649, 0.6285246383356482, 0.6417303594949937, 0.6360050628674904, 0.6450107093627485, 0.653922519416878, 0.6490872714849203, 0.6526509704543095, 0.6614585015980452, 0.659969734579663, 0.6518707838528419, 0.677437494598306, 0.6529003874128694, 0.6796603434410626, 0.6377487249357167, 0.6456672254300093, 0.6626249882089833, 0.6552880219077178, 0.6652606410138747, 0.6700541644950154, 0.6528183913821406, 0.6593114347711313, 0.6688798793021616, 0.6564762751630462, 0.6668470968156899, 0.6576884097666686, 0.667272593706877, 0.6556348661335629, 0.6562511498960056, 0.6625113748052418, 0.665937721421721, 0.6680847753619754, 0.6789894796008296, 0.6653412294461631, 0.6637499715029517, 0.6704036663560307, 0.6660106989129286, 0.672866375453701, 0.6629965292103397, 0.669098625303668, 0.6749002084335921, 0.6628122433666351, 0.6695620565222513, 0.6816492841893306, 0.6849317075482833, 0.6975915284656272, 0.6693399460569132, 0.6838617171050348, 0.6749570607154854, 0.7003942796935484, 0.6692302422319281, 0.6867876266301355, 0.7070916695799006, 0.7126320865931772, 0.6750335395951266, 0.674462637419056, 0.666838687332299, 0.689077110513199, 0.6830457066972927, 0.6818591189888855, 0.6965065810702533, 0.6881547722469542, 0.7023827034376477, 0.6827912194994581, 0.6895323127231362, 0.7035335585920927, 0.680704361421774, 0.6857138938579028, 0.6960220744120201, 0.6954795254703892, 0.6955809135247556, 0.6807131538142607, 0.6930528467346148, 0.6825246336044296, 0.6976149482008597, 0.6929009509406469, 0.6950219556520105, 0.6982861133859376, 0.6935668124503026, 0.6974117107866227, 0.6976332443355899, 0.7208098365980036, 0.6963520649785966, 0.7041994886255609, 0.6909389228582136, 0.7041987845956725, 0.6946164840453672, 0.6903902407585651, 0.6936991544761402, 0.7217714016713102, 0.7057189395491675, 0.7206868946982857, 0.7142496596794995, 0.7046552130066327], 'val_acc': [0.9126630926156807, 0.965718856659959, 0.97400341314428, 0.9762605749785715, 0.9782136567359861, 0.978672068862108, 0.977898729228875, 0.9780721396238565, 0.9784542127167354, 0.9795865690252975, 0.9794184120815974, 0.9781567167694477, 0.9806198787147907, 0.9806982091213774, 0.9805840095130283, 0.9805116157044568, 0.9804112476953166, 0.9806359953432506, 0.9805392447639915, 0.981596914730328, 0.9821964963670855, 0.9818150951643354, 0.9812457851212091, 0.9817696751947865, 0.9818470157582939, 0.9824077680137997, 0.9814251484147536, 0.981823322266125, 0.9816709513880766, 0.9811177782722056, 0.9818707114033655, 0.9823192361092543, 0.981089476338358, 0.9824768720642578, 0.9823409646165138, 0.9823992137938461, 0.9815159541534566, 0.9823426136783525, 0.982014842016163, 0.9812368965247344, 0.9817035379055484, 0.9822929197666692, 0.9827230242998853, 0.9821892522190869, 0.9825782240728845, 0.9822073568377578, 0.982045453829908, 0.9823271476570421, 0.9822797571665486, 0.9823653157281432, 0.9818088376608181, 0.9823465550277993, 0.9819477067643275, 0.9823202310577881, 0.9821649031988484, 0.981783505010162, 0.9827045888108489, 0.9827325771590627, 0.9821132348294843, 0.9821395621211167, 0.9816801725772389, 0.9822330235573775, 0.9822060461506879, 0.9816443038675684, 0.9820079363659563, 0.9822455221408415, 0.9819756823181491, 0.9825960051410585, 0.9826006020185748, 0.9822994955306944, 0.9823863689006298, 0.982553219955157, 0.9824011834536297, 0.9824284985584617, 0.9819766650258941, 0.9823926235131066, 0.9822915892113843, 0.9824018433490159, 0.981982923821153, 0.9823541207579267, 0.9823564316835197, 0.982592714644807, 0.9826535931312632, 0.9826157484261244, 0.9825960040338514, 0.9823949423121717, 0.9819964252266229, 0.9824459394065219, 0.9826809047299396, 0.9825216300470295, 0.9822024250916284, 0.9821398923148558, 0.9822478282685373, 0.9826062009184476, 0.9829704914053651, 0.9825012236064679, 0.9830441989150702, 0.9820490648010813, 0.9818437162813634, 0.9825558500639302, 0.9827941071138293, 0.9818397792377216, 0.9824071006140104, 0.9826545731325022, 0.9825673585582689, 0.9826302140243774, 0.9822491509503501, 0.9823541206349037, 0.9824804955222658, 0.982241898006207, 0.9824314525252894, 0.9827138055096716, 0.9826575477056828, 0.9825357766466367, 0.9827315795040229, 0.9820408399752173, 0.9824933246070263, 0.9821185072263082, 0.9827763411159732, 0.9822060363088476, 0.9826684079918206, 0.9826150912372443, 0.9825627618652871, 0.982614095735107, 0.9819990390348484, 0.9824150054570445, 0.9819684425374672, 0.9823610360039277, 0.9825351201343832, 0.9820671731719538, 0.98264996290699, 0.9824041539670513, 0.9820451142249093, 0.9824064476079124, 0.9823501837757965, 0.9825124084272867, 0.9825558544927583, 0.9826664272599668, 0.9824416607280019, 0.9831692492137629, 0.9823817732533434, 0.9822790983168579, 0.9828276719717295, 0.9827305846170006, 0.9824679842674326, 0.9824995785428766, 0.9827651481141247, 0.9826753086595958, 0.982403161294443, 0.9825795468162087, 0.9825140619794651, 0.9827493515915177, 0.9824795053101176, 0.9822412515818396, 0.9825867784158611, 0.982113897861957, 0.9825992974211434, 0.9824521897131937, 0.9827167613833558, 0.9826920922572645], 'val_mDice': [0.13056188921748793, 0.5298771967705804, 0.6723186954379204, 0.7047288229590968, 0.7191879399912768, 0.7343499209612638, 0.7409325039669702, 0.7408119890342925, 0.7459799152778768, 0.7490507855134851, 0.7543216560524192, 0.7587049525342613, 0.7547002626031298, 0.7607664697802596, 0.7579072274044695, 0.7602888397388045, 0.7528720976029387, 0.7626765307012111, 0.7680615071049661, 0.7633270982987371, 0.7704764848154027, 0.7684415576996818, 0.765089517776442, 0.7699270860452524, 0.7638723368000074, 0.7685166170476514, 0.7717035709888942, 0.7718108140155134, 0.7729906091010976, 0.771203758977392, 0.7669643789868114, 0.7739841014116049, 0.7712244323163578, 0.7727662527278235, 0.7746514722289685, 0.7731952326462611, 0.778954710323129, 0.7743188256572767, 0.7757782328362558, 0.7754125336129353, 0.7772011807951519, 0.7757418047409924, 0.7814803977253759, 0.7739213019824741, 0.7773813607768992, 0.7757834902857849, 0.7792358311706283, 0.7759294127901272, 0.7780158960167223, 0.7788610785000095, 0.7803878298238827, 0.7795946878545424, 0.7750737898366985, 0.7772427913574242, 0.7814615517700911, 0.7804360890413093, 0.7805390686442608, 0.7838154455456572, 0.7825095277083548, 0.783390601168476, 0.7798601705100391, 0.7827657271710958, 0.7819630156114498, 0.7776037177188232, 0.7767266156257614, 0.7804228415553168, 0.7828289534285342, 0.7834362490996488, 0.7837052377261859, 0.7854839965039855, 0.7807170323666158, 0.7804464678769264, 0.7802964416942852, 0.7820094955471893, 0.7801327936666546, 0.7805196429430762, 0.7837413818843594, 0.780342462262133, 0.7820689085221266, 0.7799025909327378, 0.7819317287089778, 0.7823439856800871, 0.78512024282794, 0.7845962830003201, 0.7746478162313762, 0.782907111602917, 0.7850086057887358, 0.7847110478993663, 0.7829507403575476, 0.7822729589031208, 0.7818739567993841, 0.784277666402429, 0.7787568022346103, 0.7837081791446674, 0.7833804800660494, 0.7864118858756665, 0.7835888865070323, 0.782892789080416, 0.7802463215078977, 0.7841925524459658, 0.7843458385536423, 0.7851758048753374, 0.7832945117763445, 0.7845888643441924, 0.7862252561054486, 0.783440724861019, 0.7851802671656889, 0.7835584822946042, 0.7833766701051694, 0.7819813913728184, 0.7821871841901104, 0.781847451862536, 0.785836096518549, 0.7797656553202492, 0.7828172542485413, 0.7810945099352314, 0.7864027094053656, 0.7832869031111891, 0.7811528762304623, 0.7800683145429573, 0.786244272570615, 0.7842405523924143, 0.7863680001259834, 0.7826286577710918, 0.7870135986398986, 0.785574688077342, 0.7850238599029242, 0.7843553251649327, 0.7837553600039644, 0.7883786552338654, 0.7868700603213472, 0.7836972240077945, 0.7864223258537159, 0.7852193285068122, 0.7807649745537647, 0.7870929334062787, 0.7875406834978315, 0.7871628667547976, 0.784455908279793, 0.7833879185903921, 0.7841203814935634, 0.7844669026610037, 0.7835455126560632, 0.782364940126614, 0.7841130842611393, 0.783584386817688, 0.7850976897590054, 0.7812953388973901, 0.7841317001018977, 0.7875796519565877, 0.7875226438353059, 0.7846061250865767, 0.7850058521648678, 0.7858083627049276, 0.7851661252409559, 0.7821309265091446, 0.7801345814369288, 0.7818015556709439, 0.7831910271639672, 0.7836090538523883], 'loss': [21.151594336260068, 2.393304703455994, 1.4882685258532584, 1.2296004796159106, 1.1014744387283397, 1.0076792286266312, 0.941999216025047, 0.8954083169520201, 0.8555446354606028, 0.820783200413736, 0.7928825144426676, 0.7712093987868058, 0.7519664560407507, 0.732303122204871, 0.7161362729352728, 0.7014779663894523, 0.6876800904161241, 0.6783902469229692, 0.6654336311907139, 0.6551182286990466, 0.6443196696578275, 0.6370841323980603, 0.6290947922572391, 0.6254519831815368, 0.6167922711846422, 0.609727226804514, 0.6033989954014681, 0.5972113625613779, 0.5890198309060808, 0.5870231546591482, 0.5805971459113017, 0.5748971347624344, 0.5704358524067008, 0.566209384271573, 0.5620204407872121, 0.5584325596480202, 0.5544768362838783, 0.5517243015643717, 0.5478228241461457, 0.5441282274317621, 0.5410723721593839, 0.5396932112179823, 0.5355025284047453, 0.5334987211069402, 0.5305838965311921, 0.5282089420362278, 0.5250447616319198, 0.5229554713405855, 0.5186831736040765, 0.5199017334602202, 0.5180149612526123, 0.5149001983410992, 0.5123481996693758, 0.5101376698506542, 0.5104813176434793, 0.5074670130330451, 0.5067186591404277, 0.5025656090193841, 0.5018116271357733, 0.5006170982438453, 0.49976161609537023, 0.49787180073041465, 0.49737658114458344, 0.49473016458363983, 0.49362370785719917, 0.49234473665431944, 0.4903974488416719, 0.49042887682842984, 0.4877856017860217, 0.48821132408923457, 0.4863423896143366, 0.4848514227051993, 0.4851366238233039, 0.48296586234600297, 0.4811241053754799, 0.4803254779580387, 0.47937760763146126, 0.47930311736369835, 0.477220107860203, 0.47574586721445455, 0.4748476359086587, 0.47302316997581945, 0.47325179354157115, 0.4723358106109217, 0.47097388614553637, 0.47145855602954434, 0.47047929749415945, 0.4698772489141957, 0.4692616788169949, 0.46617254832991273, 0.46619083025744745, 0.46576360759200985, 0.46606005250283006, 0.4646681501397319, 0.4628386810254675, 0.46386285350420664, 0.46203560937139965, 0.46163445294743255, 0.46027692663789166, 0.4607224549901551, 0.45904632515943733, 0.45863415049231077, 0.4589638785648836, 0.45716862645999384, 0.45805080484839994, 0.4555883123627249, 0.45618007356820994, 0.45461301191313785, 0.45594976334546783, 0.45323658332225103, 0.4534680619213044, 0.4531767606692523, 0.4533149268302879, 0.4526297255464348, 0.4503293525270098, 0.4502866918228679, 0.44956681856199127, 0.44968142495153623, 0.44960558591693006, 0.4483319672381989, 0.4475927778230751, 0.4482495917115429, 0.44579223704446264, 0.44578993173482057, 0.44507307455153633, 0.44644111138284703, 0.4444467763336171, 0.4446973921128324, 0.4445707414994127, 0.4435648298153935, 0.4435682835572085, 0.44244579127018796, 0.44223100171543006, 0.4421356396506275, 0.4428674335165983, 0.44017987683547094, 0.44072468251751523, 0.44012771558229186, 0.4384160296306822, 0.4399379481271653, 0.43915614204230785, 0.4397304837512093, 0.4374683365343236, 0.4386759235163079, 0.4364889471484506, 0.4374415904838714, 0.4374068355699812, 0.4356475166348304, 0.4355039500858495, 0.4360652419791633, 0.4359180854354521, 0.43461603553690314, 0.43507371091930913, 0.43453189126696995, 0.4341404702161188, 0.433081564365579, 0.4335115704341125, 0.43184687811120587, 0.43191452128294405, 0.4311673608854331], 'acc': [0.8540561442359738, 0.932926597417554, 0.954524450778164, 0.9601879065065815, 0.9627607646721885, 0.964655619540817, 0.9658740390548565, 0.9667569590990032, 0.9674886364924871, 0.9682539863676964, 0.968782929373949, 0.9692721538777735, 0.9696345950670563, 0.9701326091562276, 0.9704895644404878, 0.9707784447076072, 0.97110841560825, 0.9712771060773118, 0.9715188267281097, 0.9717949778446583, 0.972064189689382, 0.9722069031602305, 0.9723485097669888, 0.9724248903717891, 0.9726379817244487, 0.972811414570805, 0.9729031382752741, 0.9730500314524386, 0.9731741404516303, 0.9732178942824652, 0.973301278774682, 0.97344778914824, 0.9734846026395766, 0.9735527655404708, 0.9736062958427281, 0.9736678607357924, 0.9737332994040482, 0.9737587478398878, 0.9738617614712384, 0.9738977737164253, 0.9739709646968874, 0.9740017317689231, 0.9740642292817852, 0.9741082580669814, 0.974151963973518, 0.9741616735231743, 0.9742398993308999, 0.9742665245847882, 0.9743440662274248, 0.974333823503046, 0.9743557940213868, 0.9744048036380459, 0.974435886115028, 0.9744515934834937, 0.9744700423951419, 0.9745239350586197, 0.9745504189027304, 0.9746131539800328, 0.9746099077761244, 0.9746420485451764, 0.9746416843617933, 0.9746627809681356, 0.9747134072059717, 0.9747526408921627, 0.9747683543890736, 0.9748009128960043, 0.9748176317924471, 0.9748137190258244, 0.9748720376295664, 0.9748678483426614, 0.9748766540569936, 0.9749336408805757, 0.974922054503509, 0.9749433621746388, 0.9749830186096557, 0.9749933293448276, 0.9750014786749317, 0.9750210528075339, 0.9750627036706229, 0.9750659571631815, 0.9751042077998031, 0.9751225427907038, 0.9750901284196766, 0.9751183356736536, 0.9751386609144646, 0.9751438021033483, 0.9751574530190376, 0.9751608902866526, 0.9751728361564574, 0.9752400092743222, 0.9752440174838254, 0.9752554037290796, 0.975260934725507, 0.9752592500508301, 0.9752863138266387, 0.9752565511505217, 0.9753211941530006, 0.9753213930890189, 0.9753430328207993, 0.9753455075808803, 0.9753705077362653, 0.9753606921737622, 0.9753557992118168, 0.9753996677250062, 0.9753973339832225, 0.9754288350379863, 0.9754148792019032, 0.9754212105903416, 0.9754524926510636, 0.9754661910782174, 0.97544334376516, 0.9754734650798763, 0.9754931805581958, 0.9754633629396078, 0.9754911823576778, 0.9755199044295134, 0.975509746613638, 0.9755272894478482, 0.9755311077538498, 0.9755381621849232, 0.9755741090244401, 0.9755676839512232, 0.9755791550124492, 0.9755727956224974, 0.9756137790900868, 0.9755545445720762, 0.9755869982975435, 0.9756169496600144, 0.9756022120307902, 0.9756239347350264, 0.9756317126215686, 0.9756537403600837, 0.9756543625787645, 0.97566020609742, 0.9756600545732167, 0.9756734877262475, 0.9756591391287244, 0.9756978950168513, 0.9756939840723912, 0.975684092484427, 0.9756866825176419, 0.9756980389961628, 0.9757231037173147, 0.9756971719243915, 0.9757225136498378, 0.9757321213719268, 0.9757101673384626, 0.9757682369892484, 0.9757584705681911, 0.9757787005440671, 0.975758270706856, 0.9757468474560431, 0.9757712258126988, 0.9757692572721468, 0.9757867742615438, 0.9757848892628733, 0.9758079263370761, 0.9758332877646547, 0.9758273084379478, 0.9758285647122479], 'mDice': [0.05851159925083891, 0.30384848481086435, 0.5165030388586385, 0.5914683337709287, 0.6287798183414741, 0.6553436535438832, 0.6748255307616896, 0.6885568596652222, 0.7003607071824025, 0.7103719884124439, 0.7184649494772228, 0.7252255006681515, 0.7309857202310792, 0.7371342765536147, 0.7418669558009869, 0.7465276308580148, 0.7510901054477305, 0.753840035111858, 0.7580006500118411, 0.7612437392750246, 0.7648307647985805, 0.7668454486486136, 0.7698808052544381, 0.7707680103415545, 0.7740461612718613, 0.7759244031785979, 0.7781298892692191, 0.7803003606845804, 0.7830141370567525, 0.7835988150324547, 0.7857972598101491, 0.7876632587634096, 0.7893007187533555, 0.7907703317646654, 0.7919096123255435, 0.793433941567972, 0.7947067879024713, 0.7956299789984812, 0.796852205088351, 0.7979191507862097, 0.7992200071184739, 0.799952921340367, 0.8012823620217211, 0.8021166534733596, 0.8029078276766095, 0.8036967528401624, 0.8048271126271092, 0.8056753452805878, 0.8070852546809196, 0.8065980386486309, 0.8073634317147865, 0.8086655108035251, 0.809531446278508, 0.8103883008072021, 0.8100719523580768, 0.8112071198283387, 0.811508409015199, 0.8129449963840119, 0.8134495540083181, 0.8138878736756199, 0.8141363240922582, 0.814737121245159, 0.8150801256829296, 0.8158354575434135, 0.816361129483204, 0.8165802468554855, 0.8175273643050753, 0.81755282736804, 0.8182339292381725, 0.8182408400244721, 0.8189242295556061, 0.8194072898188154, 0.8194882794413898, 0.8199940332442216, 0.8210455749280874, 0.8214365814262852, 0.8215050647715438, 0.8216225944329538, 0.8224626033537309, 0.822863904415408, 0.8230220749920867, 0.8240786689632343, 0.8239716973528532, 0.8241573697147775, 0.8249420624075968, 0.824579155193128, 0.824639490909442, 0.825066394500696, 0.8252237020129374, 0.8261865012139502, 0.8262984736924642, 0.8264276388154441, 0.826497935546962, 0.8271679324966528, 0.8277245482013025, 0.8273808067770827, 0.8280333079698406, 0.8280344173678755, 0.828553593027754, 0.828488442282532, 0.8291496026265414, 0.8291672395654814, 0.8290526892537002, 0.8296378985463733, 0.8294925400357785, 0.830445534742502, 0.830216342363091, 0.8306589363396866, 0.8304944153771014, 0.8313106631631921, 0.8312349073252531, 0.8311925365798423, 0.8313393898616123, 0.8314992977563823, 0.8323192111427129, 0.8323843207042144, 0.8325435969278355, 0.8326090126553497, 0.8328079073688766, 0.8330739368779123, 0.8334918291992409, 0.8329934027247934, 0.8340493904710072, 0.834028451246836, 0.8343858991199955, 0.8337695594829849, 0.8344895130044269, 0.8344113996155882, 0.8343422223609417, 0.8349371983451492, 0.8348441513022574, 0.8352028382744116, 0.8352041296324583, 0.8353890199022929, 0.8352723943324484, 0.8362217270476681, 0.8359423281114654, 0.8363875672488102, 0.8366953497474507, 0.8362315047504738, 0.8365350436033997, 0.8361091761464347, 0.8371364275211077, 0.8366010015239174, 0.8374803373102986, 0.8370353980396936, 0.8370375278487477, 0.8380584031848826, 0.8379970432779855, 0.8378812363288953, 0.8377678136652456, 0.8383188998753284, 0.8380320505293565, 0.8383135881149487, 0.8384372524353039, 0.83890782844374, 0.8388406388481164, 0.8393535769111022, 0.8391952460410631, 0.83965542239849]}
predicting test subjects:   0%|          | 0/15 [00:00<?, ?it/s]predicting test subjects:   7%|▋         | 1/15 [00:02<00:28,  2.03s/it]predicting test subjects:  13%|█▎        | 2/15 [00:03<00:25,  2.00s/it]predicting test subjects:  20%|██        | 3/15 [00:06<00:24,  2.06s/it]predicting test subjects:  27%|██▋       | 4/15 [00:08<00:22,  2.06s/it]predicting test subjects:  33%|███▎      | 5/15 [00:10<00:21,  2.14s/it]predicting test subjects:  40%|████      | 6/15 [00:12<00:19,  2.19s/it]predicting test subjects:  47%|████▋     | 7/15 [00:14<00:15,  1.99s/it]predicting test subjects:  53%|█████▎    | 8/15 [00:16<00:14,  2.07s/it]predicting test subjects:  60%|██████    | 9/15 [00:18<00:12,  2.02s/it]predicting test subjects:  67%|██████▋   | 10/15 [00:20<00:09,  1.90s/it]predicting test subjects:  73%|███████▎  | 11/15 [00:21<00:07,  1.84s/it]predicting test subjects:  80%|████████  | 12/15 [00:23<00:05,  1.92s/it]predicting test subjects:  87%|████████▋ | 13/15 [00:26<00:03,  1.99s/it]predicting test subjects:  93%|█████████▎| 14/15 [00:27<00:01,  1.94s/it]predicting test subjects: 100%|██████████| 15/15 [00:29<00:00,  1.95s/it]
predicting train subjects:   0%|          | 0/532 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/532 [00:02<20:46,  2.35s/it]predicting train subjects:   0%|          | 2/532 [00:04<19:12,  2.17s/it]predicting train subjects:   1%|          | 3/532 [00:05<18:15,  2.07s/it]predicting train subjects:   1%|          | 4/532 [00:07<17:45,  2.02s/it]predicting train subjects:   1%|          | 5/532 [00:09<17:33,  2.00s/it]predicting train subjects:   1%|          | 6/532 [00:11<16:56,  1.93s/it]predicting train subjects:   1%|▏         | 7/532 [00:13<16:22,  1.87s/it]predicting train subjects:   2%|▏         | 8/532 [00:14<15:50,  1.81s/it]predicting train subjects:   2%|▏         | 9/532 [00:16<16:16,  1.87s/it]predicting train subjects:   2%|▏         | 10/532 [00:18<16:02,  1.84s/it]predicting train subjects:   2%|▏         | 11/532 [00:20<15:18,  1.76s/it]predicting train subjects:   2%|▏         | 12/532 [00:22<16:16,  1.88s/it]predicting train subjects:   2%|▏         | 13/532 [00:24<15:27,  1.79s/it]predicting train subjects:   3%|▎         | 14/532 [00:25<14:59,  1.74s/it]predicting train subjects:   3%|▎         | 15/532 [00:27<15:07,  1.75s/it]predicting train subjects:   3%|▎         | 16/532 [00:29<15:45,  1.83s/it]predicting train subjects:   3%|▎         | 17/532 [00:31<15:11,  1.77s/it]predicting train subjects:   3%|▎         | 18/532 [00:33<15:52,  1.85s/it]predicting train subjects:   4%|▎         | 19/532 [00:34<14:51,  1.74s/it]predicting train subjects:   4%|▍         | 20/532 [00:36<15:17,  1.79s/it]predicting train subjects:   4%|▍         | 21/532 [00:38<15:53,  1.87s/it]predicting train subjects:   4%|▍         | 22/532 [00:40<15:27,  1.82s/it]predicting train subjects:   4%|▍         | 23/532 [00:42<15:31,  1.83s/it]predicting train subjects:   5%|▍         | 24/532 [00:43<14:42,  1.74s/it]predicting train subjects:   5%|▍         | 25/532 [00:45<15:56,  1.89s/it]predicting train subjects:   5%|▍         | 26/532 [00:47<15:35,  1.85s/it]predicting train subjects:   5%|▌         | 27/532 [00:50<16:53,  2.01s/it]predicting train subjects:   5%|▌         | 28/532 [00:51<16:28,  1.96s/it]predicting train subjects:   5%|▌         | 29/532 [00:53<16:38,  1.98s/it]predicting train subjects:   6%|▌         | 30/532 [00:55<15:48,  1.89s/it]predicting train subjects:   6%|▌         | 31/532 [00:57<15:34,  1.86s/it]predicting train subjects:   6%|▌         | 32/532 [00:59<15:26,  1.85s/it]predicting train subjects:   6%|▌         | 33/532 [01:00<14:50,  1.78s/it]predicting train subjects:   6%|▋         | 34/532 [01:03<15:50,  1.91s/it]predicting train subjects:   7%|▋         | 35/532 [01:04<15:32,  1.88s/it]predicting train subjects:   7%|▋         | 36/532 [01:06<15:42,  1.90s/it]predicting train subjects:   7%|▋         | 37/532 [01:08<15:56,  1.93s/it]predicting train subjects:   7%|▋         | 38/532 [01:10<16:03,  1.95s/it]predicting train subjects:   7%|▋         | 39/532 [01:12<15:50,  1.93s/it]predicting train subjects:   8%|▊         | 40/532 [01:14<15:13,  1.86s/it]predicting train subjects:   8%|▊         | 41/532 [01:16<15:29,  1.89s/it]predicting train subjects:   8%|▊         | 42/532 [01:18<15:31,  1.90s/it]predicting train subjects:   8%|▊         | 43/532 [01:19<14:47,  1.81s/it]predicting train subjects:   8%|▊         | 44/532 [01:21<14:04,  1.73s/it]predicting train subjects:   8%|▊         | 45/532 [01:23<13:45,  1.70s/it]predicting train subjects:   9%|▊         | 46/532 [01:24<14:09,  1.75s/it]predicting train subjects:   9%|▉         | 47/532 [01:27<15:14,  1.89s/it]predicting train subjects:   9%|▉         | 48/532 [01:29<15:32,  1.93s/it]predicting train subjects:   9%|▉         | 49/532 [01:30<14:52,  1.85s/it]predicting train subjects:   9%|▉         | 50/532 [01:32<15:23,  1.92s/it]predicting train subjects:  10%|▉         | 51/532 [01:34<15:00,  1.87s/it]predicting train subjects:  10%|▉         | 52/532 [01:36<14:54,  1.86s/it]predicting train subjects:  10%|▉         | 53/532 [01:38<14:27,  1.81s/it]predicting train subjects:  10%|█         | 54/532 [01:40<15:07,  1.90s/it]predicting train subjects:  10%|█         | 55/532 [01:42<15:20,  1.93s/it]predicting train subjects:  11%|█         | 56/532 [01:44<15:10,  1.91s/it]predicting train subjects:  11%|█         | 57/532 [01:46<15:04,  1.90s/it]predicting train subjects:  11%|█         | 58/532 [01:47<15:06,  1.91s/it]predicting train subjects:  11%|█         | 59/532 [01:50<15:52,  2.01s/it]predicting train subjects:  11%|█▏        | 60/532 [01:51<14:38,  1.86s/it]predicting train subjects:  11%|█▏        | 61/532 [01:53<13:48,  1.76s/it]predicting train subjects:  12%|█▏        | 62/532 [01:55<14:32,  1.86s/it]predicting train subjects:  12%|█▏        | 63/532 [01:57<15:02,  1.92s/it]predicting train subjects:  12%|█▏        | 64/532 [01:59<14:41,  1.88s/it]predicting train subjects:  12%|█▏        | 65/532 [02:01<14:33,  1.87s/it]predicting train subjects:  12%|█▏        | 66/532 [02:03<15:40,  2.02s/it]predicting train subjects:  13%|█▎        | 67/532 [02:05<16:18,  2.10s/it]predicting train subjects:  13%|█▎        | 68/532 [02:07<15:57,  2.06s/it]predicting train subjects:  13%|█▎        | 69/532 [02:09<15:26,  2.00s/it]predicting train subjects:  13%|█▎        | 70/532 [02:11<14:46,  1.92s/it]predicting train subjects:  13%|█▎        | 71/532 [02:12<14:13,  1.85s/it]predicting train subjects:  14%|█▎        | 72/532 [02:14<13:45,  1.79s/it]predicting train subjects:  14%|█▎        | 73/532 [02:16<14:16,  1.87s/it]predicting train subjects:  14%|█▍        | 74/532 [02:19<15:35,  2.04s/it]predicting train subjects:  14%|█▍        | 75/532 [02:22<17:32,  2.30s/it]predicting train subjects:  14%|█▍        | 76/532 [02:23<16:25,  2.16s/it]predicting train subjects:  14%|█▍        | 77/532 [02:25<15:47,  2.08s/it]predicting train subjects:  15%|█▍        | 78/532 [02:27<15:36,  2.06s/it]predicting train subjects:  15%|█▍        | 79/532 [02:29<15:11,  2.01s/it]predicting train subjects:  15%|█▌        | 80/532 [02:31<15:05,  2.00s/it]predicting train subjects:  15%|█▌        | 81/532 [02:33<15:03,  2.00s/it]predicting train subjects:  15%|█▌        | 82/532 [02:35<14:53,  1.98s/it]predicting train subjects:  16%|█▌        | 83/532 [02:37<14:06,  1.89s/it]predicting train subjects:  16%|█▌        | 84/532 [02:38<13:31,  1.81s/it]predicting train subjects:  16%|█▌        | 85/532 [02:40<13:05,  1.76s/it]predicting train subjects:  16%|█▌        | 86/532 [02:42<12:58,  1.75s/it]predicting train subjects:  16%|█▋        | 87/532 [02:43<12:45,  1.72s/it]predicting train subjects:  17%|█▋        | 88/532 [02:45<12:36,  1.70s/it]predicting train subjects:  17%|█▋        | 89/532 [02:47<12:49,  1.74s/it]predicting train subjects:  17%|█▋        | 90/532 [02:49<13:03,  1.77s/it]predicting train subjects:  17%|█▋        | 91/532 [02:51<13:17,  1.81s/it]predicting train subjects:  17%|█▋        | 92/532 [02:52<13:23,  1.83s/it]predicting train subjects:  17%|█▋        | 93/532 [02:54<13:28,  1.84s/it]predicting train subjects:  18%|█▊        | 94/532 [02:56<13:47,  1.89s/it]predicting train subjects:  18%|█▊        | 95/532 [02:59<14:35,  2.00s/it]predicting train subjects:  18%|█▊        | 96/532 [03:01<15:18,  2.11s/it]predicting train subjects:  18%|█▊        | 97/532 [03:03<15:35,  2.15s/it]predicting train subjects:  18%|█▊        | 98/532 [03:05<15:42,  2.17s/it]predicting train subjects:  19%|█▊        | 99/532 [03:08<15:53,  2.20s/it]predicting train subjects:  19%|█▉        | 100/532 [03:10<15:47,  2.19s/it]predicting train subjects:  19%|█▉        | 101/532 [03:12<15:06,  2.10s/it]predicting train subjects:  19%|█▉        | 102/532 [03:14<14:20,  2.00s/it]predicting train subjects:  19%|█▉        | 103/532 [03:15<14:03,  1.97s/it]predicting train subjects:  20%|█▉        | 104/532 [03:17<13:26,  1.88s/it]predicting train subjects:  20%|█▉        | 105/532 [03:19<13:01,  1.83s/it]predicting train subjects:  20%|█▉        | 106/532 [03:21<12:45,  1.80s/it]predicting train subjects:  20%|██        | 107/532 [03:22<12:38,  1.79s/it]predicting train subjects:  20%|██        | 108/532 [03:24<12:42,  1.80s/it]predicting train subjects:  20%|██        | 109/532 [03:26<12:31,  1.78s/it]predicting train subjects:  21%|██        | 110/532 [03:28<12:35,  1.79s/it]predicting train subjects:  21%|██        | 111/532 [03:29<12:23,  1.76s/it]predicting train subjects:  21%|██        | 112/532 [03:31<12:24,  1.77s/it]predicting train subjects:  21%|██        | 113/532 [03:33<13:12,  1.89s/it]predicting train subjects:  21%|██▏       | 114/532 [03:35<13:30,  1.94s/it]predicting train subjects:  22%|██▏       | 115/532 [03:38<13:53,  2.00s/it]predicting train subjects:  22%|██▏       | 116/532 [03:40<14:08,  2.04s/it]predicting train subjects:  22%|██▏       | 117/532 [03:42<14:16,  2.06s/it]predicting train subjects:  22%|██▏       | 118/532 [03:44<14:34,  2.11s/it]predicting train subjects:  22%|██▏       | 119/532 [03:46<14:18,  2.08s/it]predicting train subjects:  23%|██▎       | 120/532 [03:48<13:54,  2.02s/it]predicting train subjects:  23%|██▎       | 121/532 [03:50<13:34,  1.98s/it]predicting train subjects:  23%|██▎       | 122/532 [03:52<13:32,  1.98s/it]predicting train subjects:  23%|██▎       | 123/532 [03:54<13:22,  1.96s/it]predicting train subjects:  23%|██▎       | 124/532 [03:56<13:20,  1.96s/it]predicting train subjects:  23%|██▎       | 125/532 [03:58<13:32,  2.00s/it]predicting train subjects:  24%|██▎       | 126/532 [04:00<13:35,  2.01s/it]predicting train subjects:  24%|██▍       | 127/532 [04:02<14:04,  2.08s/it]predicting train subjects:  24%|██▍       | 128/532 [04:04<14:03,  2.09s/it]predicting train subjects:  24%|██▍       | 129/532 [04:06<14:18,  2.13s/it]predicting train subjects:  24%|██▍       | 130/532 [04:09<14:17,  2.13s/it]predicting train subjects:  25%|██▍       | 131/532 [04:11<14:46,  2.21s/it]predicting train subjects:  25%|██▍       | 132/532 [04:13<15:13,  2.28s/it]predicting train subjects:  25%|██▌       | 133/532 [04:16<15:12,  2.29s/it]predicting train subjects:  25%|██▌       | 134/532 [04:18<15:24,  2.32s/it]predicting train subjects:  25%|██▌       | 135/532 [04:20<15:33,  2.35s/it]predicting train subjects:  26%|██▌       | 136/532 [04:23<15:22,  2.33s/it]predicting train subjects:  26%|██▌       | 137/532 [04:25<15:35,  2.37s/it]predicting train subjects:  26%|██▌       | 138/532 [04:28<15:39,  2.38s/it]predicting train subjects:  26%|██▌       | 139/532 [04:30<15:33,  2.38s/it]predicting train subjects:  26%|██▋       | 140/532 [04:32<15:39,  2.40s/it]predicting train subjects:  27%|██▋       | 141/532 [04:35<15:51,  2.43s/it]predicting train subjects:  27%|██▋       | 142/532 [04:37<15:51,  2.44s/it]predicting train subjects:  27%|██▋       | 143/532 [04:39<14:46,  2.28s/it]predicting train subjects:  27%|██▋       | 144/532 [04:41<13:45,  2.13s/it]predicting train subjects:  27%|██▋       | 145/532 [04:43<13:23,  2.08s/it]predicting train subjects:  27%|██▋       | 146/532 [04:45<12:42,  1.98s/it]predicting train subjects:  28%|██▊       | 147/532 [04:47<12:14,  1.91s/it]predicting train subjects:  28%|██▊       | 148/532 [04:48<12:01,  1.88s/it]predicting train subjects:  28%|██▊       | 149/532 [04:50<12:17,  1.93s/it]predicting train subjects:  28%|██▊       | 150/532 [04:52<12:23,  1.95s/it]predicting train subjects:  28%|██▊       | 151/532 [04:54<12:32,  1.98s/it]predicting train subjects:  29%|██▊       | 152/532 [04:56<12:30,  1.98s/it]predicting train subjects:  29%|██▉       | 153/532 [04:58<12:36,  2.00s/it]predicting train subjects:  29%|██▉       | 154/532 [05:00<12:36,  2.00s/it]predicting train subjects:  29%|██▉       | 155/532 [05:03<13:28,  2.15s/it]predicting train subjects:  29%|██▉       | 156/532 [05:05<13:49,  2.21s/it]predicting train subjects:  30%|██▉       | 157/532 [05:08<14:11,  2.27s/it]predicting train subjects:  30%|██▉       | 158/532 [05:10<14:34,  2.34s/it]predicting train subjects:  30%|██▉       | 159/532 [05:13<14:53,  2.39s/it]predicting train subjects:  30%|███       | 160/532 [05:15<14:58,  2.42s/it]predicting train subjects:  30%|███       | 161/532 [05:17<14:08,  2.29s/it]predicting train subjects:  30%|███       | 162/532 [05:19<13:22,  2.17s/it]predicting train subjects:  31%|███       | 163/532 [05:21<12:55,  2.10s/it]predicting train subjects:  31%|███       | 164/532 [05:23<12:52,  2.10s/it]predicting train subjects:  31%|███       | 165/532 [05:25<12:36,  2.06s/it]predicting train subjects:  31%|███       | 166/532 [05:27<12:12,  2.00s/it]predicting train subjects:  31%|███▏      | 167/532 [05:29<12:02,  1.98s/it]predicting train subjects:  32%|███▏      | 168/532 [05:31<12:26,  2.05s/it]predicting train subjects:  32%|███▏      | 169/532 [05:33<12:16,  2.03s/it]predicting train subjects:  32%|███▏      | 170/532 [05:35<12:07,  2.01s/it]predicting train subjects:  32%|███▏      | 171/532 [05:37<12:03,  2.00s/it]predicting train subjects:  32%|███▏      | 172/532 [05:39<11:47,  1.97s/it]predicting train subjects:  33%|███▎      | 173/532 [05:41<11:30,  1.92s/it]predicting train subjects:  33%|███▎      | 174/532 [05:43<11:19,  1.90s/it]predicting train subjects:  33%|███▎      | 175/532 [05:45<11:24,  1.92s/it]predicting train subjects:  33%|███▎      | 176/532 [05:46<11:14,  1.89s/it]predicting train subjects:  33%|███▎      | 177/532 [05:48<10:59,  1.86s/it]predicting train subjects:  33%|███▎      | 178/532 [05:50<10:49,  1.84s/it]predicting train subjects:  34%|███▎      | 179/532 [05:52<10:48,  1.84s/it]predicting train subjects:  34%|███▍      | 180/532 [05:53<10:35,  1.80s/it]predicting train subjects:  34%|███▍      | 181/532 [05:55<10:42,  1.83s/it]predicting train subjects:  34%|███▍      | 182/532 [05:57<10:32,  1.81s/it]predicting train subjects:  34%|███▍      | 183/532 [05:59<10:39,  1.83s/it]predicting train subjects:  35%|███▍      | 184/532 [06:01<10:53,  1.88s/it]predicting train subjects:  35%|███▍      | 185/532 [06:03<10:47,  1.87s/it]predicting train subjects:  35%|███▍      | 186/532 [06:05<10:49,  1.88s/it]predicting train subjects:  35%|███▌      | 187/532 [06:06<10:20,  1.80s/it]predicting train subjects:  35%|███▌      | 188/532 [06:08<10:30,  1.83s/it]predicting train subjects:  36%|███▌      | 189/532 [06:10<10:32,  1.84s/it]predicting train subjects:  36%|███▌      | 190/532 [06:12<10:23,  1.82s/it]predicting train subjects:  36%|███▌      | 191/532 [06:14<11:31,  2.03s/it]predicting train subjects:  36%|███▌      | 192/532 [06:17<12:27,  2.20s/it]predicting train subjects:  36%|███▋      | 193/532 [06:19<12:52,  2.28s/it]predicting train subjects:  36%|███▋      | 194/532 [06:22<12:57,  2.30s/it]predicting train subjects:  37%|███▋      | 195/532 [06:24<13:09,  2.34s/it]predicting train subjects:  37%|███▋      | 196/532 [06:27<13:27,  2.40s/it]predicting train subjects:  37%|███▋      | 197/532 [06:29<13:14,  2.37s/it]predicting train subjects:  37%|███▋      | 198/532 [06:31<13:03,  2.35s/it]predicting train subjects:  37%|███▋      | 199/532 [06:34<12:38,  2.28s/it]predicting train subjects:  38%|███▊      | 200/532 [06:36<12:34,  2.27s/it]predicting train subjects:  38%|███▊      | 201/532 [06:38<12:34,  2.28s/it]predicting train subjects:  38%|███▊      | 202/532 [06:40<12:34,  2.29s/it]predicting train subjects:  38%|███▊      | 203/532 [06:42<11:56,  2.18s/it]predicting train subjects:  38%|███▊      | 204/532 [06:44<11:25,  2.09s/it]predicting train subjects:  39%|███▊      | 205/532 [06:46<11:08,  2.04s/it]predicting train subjects:  39%|███▊      | 206/532 [06:48<11:00,  2.02s/it]predicting train subjects:  39%|███▉      | 207/532 [06:50<10:46,  1.99s/it]predicting train subjects:  39%|███▉      | 208/532 [06:52<10:27,  1.94s/it]predicting train subjects:  39%|███▉      | 209/532 [06:53<09:56,  1.85s/it]predicting train subjects:  39%|███▉      | 210/532 [06:55<09:24,  1.75s/it]predicting train subjects:  40%|███▉      | 211/532 [06:57<09:19,  1.74s/it]predicting train subjects:  40%|███▉      | 212/532 [06:58<09:20,  1.75s/it]predicting train subjects:  40%|████      | 213/532 [07:00<09:21,  1.76s/it]predicting train subjects:  40%|████      | 214/532 [07:02<09:03,  1.71s/it]predicting train subjects:  40%|████      | 215/532 [07:04<09:51,  1.87s/it]predicting train subjects:  41%|████      | 216/532 [07:06<10:14,  1.94s/it]predicting train subjects:  41%|████      | 217/532 [07:09<11:03,  2.11s/it]predicting train subjects:  41%|████      | 218/532 [07:11<11:14,  2.15s/it]predicting train subjects:  41%|████      | 219/532 [07:13<11:37,  2.23s/it]predicting train subjects:  41%|████▏     | 220/532 [07:16<11:53,  2.29s/it]predicting train subjects:  42%|████▏     | 221/532 [07:18<11:15,  2.17s/it]predicting train subjects:  42%|████▏     | 222/532 [07:20<10:40,  2.07s/it]predicting train subjects:  42%|████▏     | 223/532 [07:21<10:04,  1.96s/it]predicting train subjects:  42%|████▏     | 224/532 [07:23<09:39,  1.88s/it]predicting train subjects:  42%|████▏     | 225/532 [07:25<09:24,  1.84s/it]predicting train subjects:  42%|████▏     | 226/532 [07:26<09:20,  1.83s/it]predicting train subjects:  43%|████▎     | 227/532 [07:28<09:08,  1.80s/it]predicting train subjects:  43%|████▎     | 228/532 [07:30<08:44,  1.73s/it]predicting train subjects:  43%|████▎     | 229/532 [07:31<08:35,  1.70s/it]predicting train subjects:  43%|████▎     | 230/532 [07:33<08:20,  1.66s/it]predicting train subjects:  43%|████▎     | 231/532 [07:35<08:27,  1.69s/it]predicting train subjects:  44%|████▎     | 232/532 [07:36<08:26,  1.69s/it]predicting train subjects:  44%|████▍     | 233/532 [07:38<08:39,  1.74s/it]predicting train subjects:  44%|████▍     | 234/532 [07:40<08:40,  1.75s/it]predicting train subjects:  44%|████▍     | 235/532 [07:42<08:43,  1.76s/it]predicting train subjects:  44%|████▍     | 236/532 [07:44<08:46,  1.78s/it]predicting train subjects:  45%|████▍     | 237/532 [07:46<09:02,  1.84s/it]predicting train subjects:  45%|████▍     | 238/532 [07:48<09:14,  1.89s/it]predicting train subjects:  45%|████▍     | 239/532 [07:50<09:27,  1.94s/it]predicting train subjects:  45%|████▌     | 240/532 [07:52<09:38,  1.98s/it]predicting train subjects:  45%|████▌     | 241/532 [07:54<09:46,  2.02s/it]predicting train subjects:  45%|████▌     | 242/532 [07:56<09:55,  2.05s/it]predicting train subjects:  46%|████▌     | 243/532 [07:58<09:57,  2.07s/it]predicting train subjects:  46%|████▌     | 244/532 [08:00<10:00,  2.08s/it]predicting train subjects:  46%|████▌     | 245/532 [08:02<09:29,  1.99s/it]predicting train subjects:  46%|████▌     | 246/532 [08:04<08:56,  1.88s/it]predicting train subjects:  46%|████▋     | 247/532 [08:05<08:21,  1.76s/it]predicting train subjects:  47%|████▋     | 248/532 [08:07<08:00,  1.69s/it]predicting train subjects:  47%|████▋     | 249/532 [08:08<07:45,  1.64s/it]predicting train subjects:  47%|████▋     | 250/532 [08:10<07:42,  1.64s/it]predicting train subjects:  47%|████▋     | 251/532 [08:11<07:47,  1.67s/it]predicting train subjects:  47%|████▋     | 252/532 [08:13<07:43,  1.66s/it]predicting train subjects:  48%|████▊     | 253/532 [08:15<07:44,  1.66s/it]predicting train subjects:  48%|████▊     | 254/532 [08:17<07:50,  1.69s/it]predicting train subjects:  48%|████▊     | 255/532 [08:18<08:05,  1.75s/it]predicting train subjects:  48%|████▊     | 256/532 [08:21<08:31,  1.85s/it]predicting train subjects:  48%|████▊     | 257/532 [08:23<09:12,  2.01s/it]predicting train subjects:  48%|████▊     | 258/532 [08:25<09:41,  2.12s/it]predicting train subjects:  49%|████▊     | 259/532 [08:28<10:03,  2.21s/it]predicting train subjects:  49%|████▉     | 260/532 [08:30<10:28,  2.31s/it]predicting train subjects:  49%|████▉     | 261/532 [08:33<10:21,  2.29s/it]predicting train subjects:  49%|████▉     | 262/532 [08:35<10:45,  2.39s/it]predicting train subjects:  49%|████▉     | 263/532 [08:37<10:05,  2.25s/it]predicting train subjects:  50%|████▉     | 264/532 [08:39<09:37,  2.15s/it]predicting train subjects:  50%|████▉     | 265/532 [08:41<09:20,  2.10s/it]predicting train subjects:  50%|█████     | 266/532 [08:43<08:54,  2.01s/it]predicting train subjects:  50%|█████     | 267/532 [08:45<08:57,  2.03s/it]predicting train subjects:  50%|█████     | 268/532 [08:47<08:36,  1.95s/it]predicting train subjects:  51%|█████     | 269/532 [08:49<08:56,  2.04s/it]predicting train subjects:  51%|█████     | 270/532 [08:51<09:09,  2.10s/it]predicting train subjects:  51%|█████     | 271/532 [08:53<09:00,  2.07s/it]predicting train subjects:  51%|█████     | 272/532 [08:55<09:17,  2.14s/it]predicting train subjects:  51%|█████▏    | 273/532 [08:58<09:12,  2.13s/it]predicting train subjects:  52%|█████▏    | 274/532 [09:00<09:37,  2.24s/it]predicting train subjects:  52%|█████▏    | 275/532 [09:03<10:00,  2.34s/it]predicting train subjects:  52%|█████▏    | 276/532 [09:05<10:31,  2.47s/it]predicting train subjects:  52%|█████▏    | 277/532 [09:08<10:52,  2.56s/it]predicting train subjects:  52%|█████▏    | 278/532 [09:11<11:16,  2.66s/it]predicting train subjects:  52%|█████▏    | 279/532 [09:14<11:02,  2.62s/it]predicting train subjects:  53%|█████▎    | 280/532 [09:16<11:03,  2.63s/it]predicting train subjects:  53%|█████▎    | 281/532 [09:19<10:45,  2.57s/it]predicting train subjects:  53%|█████▎    | 282/532 [09:21<10:40,  2.56s/it]predicting train subjects:  53%|█████▎    | 283/532 [09:23<10:18,  2.48s/it]predicting train subjects:  53%|█████▎    | 284/532 [09:26<10:21,  2.51s/it]predicting train subjects:  54%|█████▎    | 285/532 [09:29<10:21,  2.52s/it]predicting train subjects:  54%|█████▍    | 286/532 [09:31<10:23,  2.53s/it]predicting train subjects:  54%|█████▍    | 287/532 [09:33<09:36,  2.35s/it]predicting train subjects:  54%|█████▍    | 288/532 [09:35<09:10,  2.26s/it]predicting train subjects:  54%|█████▍    | 289/532 [09:37<08:59,  2.22s/it]predicting train subjects:  55%|█████▍    | 290/532 [09:39<08:41,  2.16s/it]predicting train subjects:  55%|█████▍    | 291/532 [09:41<08:46,  2.19s/it]predicting train subjects:  55%|█████▍    | 292/532 [09:43<08:28,  2.12s/it]predicting train subjects:  55%|█████▌    | 293/532 [09:46<08:53,  2.23s/it]predicting train subjects:  55%|█████▌    | 294/532 [09:48<08:41,  2.19s/it]predicting train subjects:  55%|█████▌    | 295/532 [09:50<08:33,  2.17s/it]predicting train subjects:  56%|█████▌    | 296/532 [09:52<08:31,  2.17s/it]predicting train subjects:  56%|█████▌    | 297/532 [09:54<08:27,  2.16s/it]predicting train subjects:  56%|█████▌    | 298/532 [09:57<08:36,  2.21s/it]predicting train subjects:  56%|█████▌    | 299/532 [09:59<08:13,  2.12s/it]predicting train subjects:  56%|█████▋    | 300/532 [10:01<07:50,  2.03s/it]predicting train subjects:  57%|█████▋    | 301/532 [10:02<07:40,  1.99s/it]predicting train subjects:  57%|█████▋    | 302/532 [10:04<07:39,  2.00s/it]predicting train subjects:  57%|█████▋    | 303/532 [10:06<07:28,  1.96s/it]predicting train subjects:  57%|█████▋    | 304/532 [10:08<07:12,  1.90s/it]predicting train subjects:  57%|█████▋    | 305/532 [10:11<08:22,  2.21s/it]predicting train subjects:  58%|█████▊    | 306/532 [10:13<08:37,  2.29s/it]predicting train subjects:  58%|█████▊    | 307/532 [10:17<09:24,  2.51s/it]predicting train subjects:  58%|█████▊    | 308/532 [10:19<09:32,  2.55s/it]predicting train subjects:  58%|█████▊    | 309/532 [10:22<09:36,  2.58s/it]predicting train subjects:  58%|█████▊    | 310/532 [10:25<09:53,  2.67s/it]predicting train subjects:  58%|█████▊    | 311/532 [10:28<10:38,  2.89s/it]predicting train subjects:  59%|█████▊    | 312/532 [10:32<11:10,  3.05s/it]predicting train subjects:  59%|█████▉    | 313/532 [10:35<11:30,  3.15s/it]predicting train subjects:  59%|█████▉    | 314/532 [10:38<11:29,  3.16s/it]predicting train subjects:  59%|█████▉    | 315/532 [10:41<11:40,  3.23s/it]predicting train subjects:  59%|█████▉    | 316/532 [10:45<11:33,  3.21s/it]predicting train subjects:  60%|█████▉    | 317/532 [10:47<10:28,  2.92s/it]predicting train subjects:  60%|█████▉    | 318/532 [10:49<09:37,  2.70s/it]predicting train subjects:  60%|█████▉    | 319/532 [10:51<08:49,  2.49s/it]predicting train subjects:  60%|██████    | 320/532 [10:53<08:27,  2.39s/it]predicting train subjects:  60%|██████    | 321/532 [10:55<08:06,  2.31s/it]predicting train subjects:  61%|██████    | 322/532 [10:57<07:43,  2.21s/it]predicting train subjects:  61%|██████    | 323/532 [11:00<08:31,  2.45s/it]predicting train subjects:  61%|██████    | 324/532 [11:03<08:50,  2.55s/it]predicting train subjects:  61%|██████    | 325/532 [11:06<09:11,  2.66s/it]predicting train subjects:  61%|██████▏   | 326/532 [11:09<09:16,  2.70s/it]predicting train subjects:  61%|██████▏   | 327/532 [11:12<09:18,  2.73s/it]predicting train subjects:  62%|██████▏   | 328/532 [11:15<09:33,  2.81s/it]predicting train subjects:  62%|██████▏   | 329/532 [11:17<08:38,  2.55s/it]predicting train subjects:  62%|██████▏   | 330/532 [11:19<08:17,  2.46s/it]predicting train subjects:  62%|██████▏   | 331/532 [11:21<08:11,  2.44s/it]predicting train subjects:  62%|██████▏   | 332/532 [11:23<07:48,  2.34s/it]predicting train subjects:  63%|██████▎   | 333/532 [11:26<07:48,  2.35s/it]predicting train subjects:  63%|██████▎   | 334/532 [11:28<07:47,  2.36s/it]predicting train subjects:  63%|██████▎   | 335/532 [11:31<07:53,  2.40s/it]predicting train subjects:  63%|██████▎   | 336/532 [11:33<07:55,  2.43s/it]predicting train subjects:  63%|██████▎   | 337/532 [11:35<07:42,  2.37s/it]predicting train subjects:  64%|██████▎   | 338/532 [11:38<07:44,  2.40s/it]predicting train subjects:  64%|██████▎   | 339/532 [11:40<07:43,  2.40s/it]predicting train subjects:  64%|██████▍   | 340/532 [11:43<07:41,  2.40s/it]predicting train subjects:  64%|██████▍   | 341/532 [11:45<07:11,  2.26s/it]predicting train subjects:  64%|██████▍   | 342/532 [11:46<06:48,  2.15s/it]predicting train subjects:  64%|██████▍   | 343/532 [11:48<06:31,  2.07s/it]predicting train subjects:  65%|██████▍   | 344/532 [11:50<06:21,  2.03s/it]predicting train subjects:  65%|██████▍   | 345/532 [11:52<06:21,  2.04s/it]predicting train subjects:  65%|██████▌   | 346/532 [11:54<06:00,  1.94s/it]predicting train subjects:  65%|██████▌   | 347/532 [11:56<06:20,  2.06s/it]predicting train subjects:  65%|██████▌   | 348/532 [11:59<06:31,  2.13s/it]predicting train subjects:  66%|██████▌   | 349/532 [12:01<06:28,  2.12s/it]predicting train subjects:  66%|██████▌   | 350/532 [12:03<06:26,  2.13s/it]predicting train subjects:  66%|██████▌   | 351/532 [12:05<06:21,  2.11s/it]predicting train subjects:  66%|██████▌   | 352/532 [12:07<06:30,  2.17s/it]predicting train subjects:  66%|██████▋   | 353/532 [12:10<06:32,  2.20s/it]predicting train subjects:  67%|██████▋   | 354/532 [12:12<06:32,  2.20s/it]predicting train subjects:  67%|██████▋   | 355/532 [12:14<06:50,  2.32s/it]predicting train subjects:  67%|██████▋   | 356/532 [12:16<06:36,  2.25s/it]predicting train subjects:  67%|██████▋   | 357/532 [12:18<06:22,  2.18s/it]predicting train subjects:  67%|██████▋   | 358/532 [12:21<06:35,  2.28s/it]predicting train subjects:  67%|██████▋   | 359/532 [12:23<06:11,  2.15s/it]predicting train subjects:  68%|██████▊   | 360/532 [12:25<05:54,  2.06s/it]predicting train subjects:  68%|██████▊   | 361/532 [12:27<05:49,  2.05s/it]predicting train subjects:  68%|██████▊   | 362/532 [12:29<05:41,  2.01s/it]predicting train subjects:  68%|██████▊   | 363/532 [12:30<05:25,  1.93s/it]predicting train subjects:  68%|██████▊   | 364/532 [12:32<05:25,  1.94s/it]predicting train subjects:  69%|██████▊   | 365/532 [12:34<05:25,  1.95s/it]predicting train subjects:  69%|██████▉   | 366/532 [12:36<05:24,  1.95s/it]predicting train subjects:  69%|██████▉   | 367/532 [12:38<05:29,  2.00s/it]predicting train subjects:  69%|██████▉   | 368/532 [12:40<05:28,  2.00s/it]predicting train subjects:  69%|██████▉   | 369/532 [12:42<05:18,  1.95s/it]predicting train subjects:  70%|██████▉   | 370/532 [12:44<05:18,  1.97s/it]predicting train subjects:  70%|██████▉   | 371/532 [12:47<05:56,  2.22s/it]predicting train subjects:  70%|██████▉   | 372/532 [12:50<06:11,  2.32s/it]predicting train subjects:  70%|███████   | 373/532 [12:52<06:28,  2.44s/it]predicting train subjects:  70%|███████   | 374/532 [12:55<06:28,  2.46s/it]predicting train subjects:  70%|███████   | 375/532 [12:57<06:34,  2.51s/it]predicting train subjects:  71%|███████   | 376/532 [13:00<06:34,  2.53s/it]predicting train subjects:  71%|███████   | 377/532 [13:02<06:19,  2.45s/it]predicting train subjects:  71%|███████   | 378/532 [13:04<06:07,  2.39s/it]predicting train subjects:  71%|███████   | 379/532 [13:06<05:47,  2.27s/it]predicting train subjects:  71%|███████▏  | 380/532 [13:09<05:46,  2.28s/it]predicting train subjects:  72%|███████▏  | 381/532 [13:11<05:35,  2.22s/it]predicting train subjects:  72%|███████▏  | 382/532 [13:13<05:28,  2.19s/it]predicting train subjects:  72%|███████▏  | 383/532 [13:15<05:38,  2.27s/it]predicting train subjects:  72%|███████▏  | 384/532 [13:18<05:33,  2.25s/it]predicting train subjects:  72%|███████▏  | 385/532 [13:20<05:43,  2.34s/it]predicting train subjects:  73%|███████▎  | 386/532 [13:22<05:38,  2.32s/it]predicting train subjects:  73%|███████▎  | 387/532 [13:25<05:35,  2.32s/it]predicting train subjects:  73%|███████▎  | 388/532 [13:27<05:29,  2.29s/it]predicting train subjects:  73%|███████▎  | 389/532 [13:29<05:23,  2.26s/it]predicting train subjects:  73%|███████▎  | 390/532 [13:32<05:24,  2.29s/it]predicting train subjects:  73%|███████▎  | 391/532 [13:34<05:24,  2.30s/it]predicting train subjects:  74%|███████▎  | 392/532 [13:37<05:37,  2.41s/it]predicting train subjects:  74%|███████▍  | 393/532 [13:39<05:39,  2.44s/it]predicting train subjects:  74%|███████▍  | 394/532 [13:41<05:34,  2.42s/it]predicting train subjects:  74%|███████▍  | 395/532 [13:44<05:36,  2.45s/it]predicting train subjects:  74%|███████▍  | 396/532 [13:46<05:26,  2.40s/it]predicting train subjects:  75%|███████▍  | 397/532 [13:49<05:35,  2.49s/it]predicting train subjects:  75%|███████▍  | 398/532 [13:51<05:24,  2.42s/it]predicting train subjects:  75%|███████▌  | 399/532 [13:54<05:21,  2.42s/it]predicting train subjects:  75%|███████▌  | 400/532 [13:56<05:15,  2.39s/it]predicting train subjects:  75%|███████▌  | 401/532 [13:58<05:16,  2.42s/it]predicting train subjects:  76%|███████▌  | 402/532 [14:01<05:20,  2.47s/it]predicting train subjects:  76%|███████▌  | 403/532 [14:03<05:17,  2.46s/it]predicting train subjects:  76%|███████▌  | 404/532 [14:06<05:18,  2.49s/it]predicting train subjects:  76%|███████▌  | 405/532 [14:08<05:09,  2.43s/it]predicting train subjects:  76%|███████▋  | 406/532 [14:11<05:07,  2.44s/it]predicting train subjects:  77%|███████▋  | 407/532 [14:13<04:51,  2.33s/it]predicting train subjects:  77%|███████▋  | 408/532 [14:15<04:48,  2.32s/it]predicting train subjects:  77%|███████▋  | 409/532 [14:17<04:45,  2.32s/it]predicting train subjects:  77%|███████▋  | 410/532 [14:20<04:37,  2.28s/it]predicting train subjects:  77%|███████▋  | 411/532 [14:22<04:36,  2.28s/it]predicting train subjects:  77%|███████▋  | 412/532 [14:24<04:28,  2.24s/it]predicting train subjects:  78%|███████▊  | 413/532 [14:26<04:28,  2.25s/it]predicting train subjects:  78%|███████▊  | 414/532 [14:28<04:19,  2.20s/it]predicting train subjects:  78%|███████▊  | 415/532 [14:31<04:18,  2.21s/it]predicting train subjects:  78%|███████▊  | 416/532 [14:33<04:13,  2.19s/it]predicting train subjects:  78%|███████▊  | 417/532 [14:35<04:03,  2.12s/it]predicting train subjects:  79%|███████▊  | 418/532 [14:37<04:04,  2.15s/it]predicting train subjects:  79%|███████▉  | 419/532 [14:39<04:14,  2.25s/it]predicting train subjects:  79%|███████▉  | 420/532 [14:42<04:25,  2.37s/it]predicting train subjects:  79%|███████▉  | 421/532 [14:45<04:29,  2.43s/it]predicting train subjects:  79%|███████▉  | 422/532 [14:47<04:26,  2.42s/it]predicting train subjects:  80%|███████▉  | 423/532 [14:50<04:27,  2.45s/it]predicting train subjects:  80%|███████▉  | 424/532 [14:52<04:22,  2.43s/it]predicting train subjects:  80%|███████▉  | 425/532 [14:54<04:19,  2.42s/it]predicting train subjects:  80%|████████  | 426/532 [14:57<04:12,  2.38s/it]predicting train subjects:  80%|████████  | 427/532 [14:59<04:12,  2.41s/it]predicting train subjects:  80%|████████  | 428/532 [15:01<04:08,  2.39s/it]predicting train subjects:  81%|████████  | 429/532 [15:04<04:01,  2.35s/it]predicting train subjects:  81%|████████  | 430/532 [15:06<03:59,  2.35s/it]predicting train subjects:  81%|████████  | 431/532 [15:08<03:57,  2.35s/it]predicting train subjects:  81%|████████  | 432/532 [15:11<03:59,  2.39s/it]predicting train subjects:  81%|████████▏ | 433/532 [15:13<03:59,  2.42s/it]predicting train subjects:  82%|████████▏ | 434/532 [15:16<04:05,  2.51s/it]predicting train subjects:  82%|████████▏ | 435/532 [15:19<04:01,  2.49s/it]predicting train subjects:  82%|████████▏ | 436/532 [15:21<04:00,  2.51s/it]predicting train subjects:  82%|████████▏ | 437/532 [15:23<03:40,  2.32s/it]predicting train subjects:  82%|████████▏ | 438/532 [15:25<03:27,  2.21s/it]predicting train subjects:  83%|████████▎ | 439/532 [15:27<03:22,  2.18s/it]predicting train subjects:  83%|████████▎ | 440/532 [15:29<03:12,  2.09s/it]predicting train subjects:  83%|████████▎ | 441/532 [15:31<03:04,  2.02s/it]predicting train subjects:  83%|████████▎ | 442/532 [15:33<02:59,  2.00s/it]predicting train subjects:  83%|████████▎ | 443/532 [15:35<02:56,  1.98s/it]predicting train subjects:  83%|████████▎ | 444/532 [15:36<02:48,  1.91s/it]predicting train subjects:  84%|████████▎ | 445/532 [15:38<02:49,  1.95s/it]predicting train subjects:  84%|████████▍ | 446/532 [15:40<02:49,  1.97s/it]predicting train subjects:  84%|████████▍ | 447/532 [15:42<02:40,  1.88s/it]predicting train subjects:  84%|████████▍ | 448/532 [15:44<02:37,  1.88s/it]predicting train subjects:  84%|████████▍ | 449/532 [15:46<02:38,  1.91s/it]predicting train subjects:  85%|████████▍ | 450/532 [15:48<02:37,  1.93s/it]predicting train subjects:  85%|████████▍ | 451/532 [15:50<02:43,  2.01s/it]predicting train subjects:  85%|████████▍ | 452/532 [15:52<02:43,  2.05s/it]predicting train subjects:  85%|████████▌ | 453/532 [15:54<02:41,  2.05s/it]predicting train subjects:  85%|████████▌ | 454/532 [15:56<02:40,  2.05s/it]predicting train subjects:  86%|████████▌ | 455/532 [15:59<02:39,  2.07s/it]predicting train subjects:  86%|████████▌ | 456/532 [16:01<02:41,  2.12s/it]predicting train subjects:  86%|████████▌ | 457/532 [16:03<02:39,  2.13s/it]predicting train subjects:  86%|████████▌ | 458/532 [16:05<02:36,  2.12s/it]predicting train subjects:  86%|████████▋ | 459/532 [16:07<02:37,  2.15s/it]predicting train subjects:  86%|████████▋ | 460/532 [16:09<02:36,  2.18s/it]predicting train subjects:  87%|████████▋ | 461/532 [16:12<02:43,  2.31s/it]predicting train subjects:  87%|████████▋ | 462/532 [16:15<02:46,  2.38s/it]predicting train subjects:  87%|████████▋ | 463/532 [16:17<02:46,  2.41s/it]predicting train subjects:  87%|████████▋ | 464/532 [16:20<02:43,  2.41s/it]predicting train subjects:  87%|████████▋ | 465/532 [16:22<02:44,  2.45s/it]predicting train subjects:  88%|████████▊ | 466/532 [16:25<02:43,  2.47s/it]predicting train subjects:  88%|████████▊ | 467/532 [16:27<02:32,  2.34s/it]predicting train subjects:  88%|████████▊ | 468/532 [16:28<02:19,  2.18s/it]predicting train subjects:  88%|████████▊ | 469/532 [16:31<02:16,  2.16s/it]predicting train subjects:  88%|████████▊ | 470/532 [16:33<02:11,  2.13s/it]predicting train subjects:  89%|████████▊ | 471/532 [16:35<02:09,  2.11s/it]predicting train subjects:  89%|████████▊ | 472/532 [16:37<02:04,  2.08s/it]predicting train subjects:  89%|████████▉ | 473/532 [16:39<02:02,  2.08s/it]predicting train subjects:  89%|████████▉ | 474/532 [16:41<02:03,  2.12s/it]predicting train subjects:  89%|████████▉ | 475/532 [16:43<02:03,  2.16s/it]predicting train subjects:  89%|████████▉ | 476/532 [16:46<02:03,  2.21s/it]predicting train subjects:  90%|████████▉ | 477/532 [16:48<01:59,  2.17s/it]predicting train subjects:  90%|████████▉ | 478/532 [16:50<01:57,  2.17s/it]predicting train subjects:  90%|█████████ | 479/532 [16:52<01:50,  2.09s/it]predicting train subjects:  90%|█████████ | 480/532 [16:54<01:50,  2.12s/it]predicting train subjects:  90%|█████████ | 481/532 [16:56<01:47,  2.10s/it]predicting train subjects:  91%|█████████ | 482/532 [16:58<01:40,  2.01s/it]predicting train subjects:  91%|█████████ | 483/532 [17:00<01:35,  1.95s/it]predicting train subjects:  91%|█████████ | 484/532 [17:02<01:36,  2.01s/it]predicting train subjects:  91%|█████████ | 485/532 [17:04<01:43,  2.21s/it]predicting train subjects:  91%|█████████▏| 486/532 [17:07<01:42,  2.24s/it]predicting train subjects:  92%|█████████▏| 487/532 [17:09<01:39,  2.22s/it]predicting train subjects:  92%|█████████▏| 488/532 [17:11<01:39,  2.26s/it]predicting train subjects:  92%|█████████▏| 489/532 [17:13<01:36,  2.25s/it]predicting train subjects:  92%|█████████▏| 490/532 [17:16<01:35,  2.28s/it]predicting train subjects:  92%|█████████▏| 491/532 [17:18<01:27,  2.13s/it]predicting train subjects:  92%|█████████▏| 492/532 [17:20<01:22,  2.07s/it]predicting train subjects:  93%|█████████▎| 493/532 [17:21<01:18,  2.01s/it]predicting train subjects:  93%|█████████▎| 494/532 [17:23<01:15,  1.99s/it]predicting train subjects:  93%|█████████▎| 495/532 [17:25<01:12,  1.97s/it]predicting train subjects:  93%|█████████▎| 496/532 [17:27<01:08,  1.91s/it]predicting train subjects:  93%|█████████▎| 497/532 [17:29<01:05,  1.88s/it]predicting train subjects:  94%|█████████▎| 498/532 [17:31<01:04,  1.90s/it]predicting train subjects:  94%|█████████▍| 499/532 [17:33<01:03,  1.94s/it]predicting train subjects:  94%|█████████▍| 500/532 [17:35<01:01,  1.93s/it]predicting train subjects:  94%|█████████▍| 501/532 [17:37<01:00,  1.96s/it]predicting train subjects:  94%|█████████▍| 502/532 [17:39<00:59,  2.00s/it]predicting train subjects:  95%|█████████▍| 503/532 [17:41<00:56,  1.95s/it]predicting train subjects:  95%|█████████▍| 504/532 [17:42<00:53,  1.90s/it]predicting train subjects:  95%|█████████▍| 505/532 [17:44<00:49,  1.84s/it]predicting train subjects:  95%|█████████▌| 506/532 [17:46<00:48,  1.85s/it]predicting train subjects:  95%|█████████▌| 507/532 [17:48<00:45,  1.83s/it]predicting train subjects:  95%|█████████▌| 508/532 [17:50<00:44,  1.85s/it]predicting train subjects:  96%|█████████▌| 509/532 [17:52<00:45,  1.98s/it]predicting train subjects:  96%|█████████▌| 510/532 [17:54<00:44,  2.02s/it]predicting train subjects:  96%|█████████▌| 511/532 [17:56<00:43,  2.06s/it]predicting train subjects:  96%|█████████▌| 512/532 [17:58<00:42,  2.12s/it]predicting train subjects:  96%|█████████▋| 513/532 [18:01<00:41,  2.18s/it]predicting train subjects:  97%|█████████▋| 514/532 [18:03<00:39,  2.18s/it]predicting train subjects:  97%|█████████▋| 515/532 [18:05<00:35,  2.11s/it]predicting train subjects:  97%|█████████▋| 516/532 [18:07<00:32,  2.04s/it]predicting train subjects:  97%|█████████▋| 517/532 [18:09<00:29,  1.97s/it]predicting train subjects:  97%|█████████▋| 518/532 [18:11<00:27,  1.96s/it]predicting train subjects:  98%|█████████▊| 519/532 [18:13<00:25,  1.97s/it]predicting train subjects:  98%|█████████▊| 520/532 [18:14<00:23,  1.95s/it]predicting train subjects:  98%|█████████▊| 521/532 [18:17<00:22,  2.05s/it]predicting train subjects:  98%|█████████▊| 522/532 [18:19<00:20,  2.05s/it]predicting train subjects:  98%|█████████▊| 523/532 [18:21<00:18,  2.01s/it]predicting train subjects:  98%|█████████▊| 524/532 [18:23<00:15,  1.98s/it]predicting train subjects:  99%|█████████▊| 525/532 [18:25<00:14,  2.02s/it]predicting train subjects:  99%|█████████▉| 526/532 [18:27<00:12,  2.01s/it]predicting train subjects:  99%|█████████▉| 527/532 [18:29<00:09,  1.99s/it]predicting train subjects:  99%|█████████▉| 528/532 [18:30<00:07,  1.90s/it]predicting train subjects:  99%|█████████▉| 529/532 [18:32<00:05,  1.91s/it]predicting train subjects: 100%|█████████▉| 530/532 [18:34<00:03,  1.88s/it]predicting train subjects: 100%|█████████▉| 531/532 [18:36<00:01,  1.84s/it]predicting train subjects: 100%|██████████| 532/532 [18:38<00:00,  1.85s/it]
Loading train:   0%|          | 0/532 [00:00<?, ?it/s]Loading train:   0%|          | 1/532 [00:01<12:43,  1.44s/it]Loading train:   0%|          | 2/532 [00:02<11:30,  1.30s/it]Loading train:   1%|          | 3/532 [00:03<10:52,  1.23s/it]Loading train:   1%|          | 4/532 [00:04<10:16,  1.17s/it]Loading train:   1%|          | 5/532 [00:05<10:15,  1.17s/it]Loading train:   1%|          | 6/532 [00:06<09:30,  1.08s/it]Loading train:   1%|▏         | 7/532 [00:07<09:17,  1.06s/it]Loading train:   2%|▏         | 8/532 [00:08<08:43,  1.00it/s]Loading train:   2%|▏         | 9/532 [00:09<10:03,  1.15s/it]Loading train:   2%|▏         | 10/532 [00:11<10:12,  1.17s/it]Loading train:   2%|▏         | 11/532 [00:12<09:46,  1.13s/it]Loading train:   2%|▏         | 12/532 [00:13<10:12,  1.18s/it]Loading train:   2%|▏         | 13/532 [00:14<09:11,  1.06s/it]Loading train:   3%|▎         | 14/532 [00:15<09:25,  1.09s/it]Loading train:   3%|▎         | 15/532 [00:16<10:19,  1.20s/it]Loading train:   3%|▎         | 16/532 [00:18<10:51,  1.26s/it]Loading train:   3%|▎         | 17/532 [00:19<09:58,  1.16s/it]Loading train:   3%|▎         | 18/532 [00:20<10:07,  1.18s/it]Loading train:   4%|▎         | 19/532 [00:21<09:39,  1.13s/it]Loading train:   4%|▍         | 20/532 [00:22<09:59,  1.17s/it]Loading train:   4%|▍         | 21/532 [00:24<10:26,  1.23s/it]Loading train:   4%|▍         | 22/532 [00:25<10:30,  1.24s/it]Loading train:   4%|▍         | 23/532 [00:26<10:37,  1.25s/it]Loading train:   5%|▍         | 24/532 [00:27<10:00,  1.18s/it]Loading train:   5%|▍         | 25/532 [00:29<10:39,  1.26s/it]Loading train:   5%|▍         | 26/532 [00:30<10:27,  1.24s/it]Loading train:   5%|▌         | 27/532 [00:31<10:37,  1.26s/it]Loading train:   5%|▌         | 28/532 [00:32<10:46,  1.28s/it]Loading train:   5%|▌         | 29/532 [00:34<11:24,  1.36s/it]Loading train:   6%|▌         | 30/532 [00:35<10:58,  1.31s/it]Loading train:   6%|▌         | 31/532 [00:36<10:06,  1.21s/it]Loading train:   6%|▌         | 32/532 [00:37<09:43,  1.17s/it]Loading train:   6%|▌         | 33/532 [00:38<09:51,  1.19s/it]Loading train:   6%|▋         | 34/532 [00:40<11:02,  1.33s/it]Loading train:   7%|▋         | 35/532 [00:41<10:28,  1.27s/it]Loading train:   7%|▋         | 36/532 [00:42<10:05,  1.22s/it]Loading train:   7%|▋         | 37/532 [00:43<09:45,  1.18s/it]Loading train:   7%|▋         | 38/532 [00:45<10:52,  1.32s/it]Loading train:   7%|▋         | 39/532 [00:46<11:05,  1.35s/it]Loading train:   8%|▊         | 40/532 [00:48<10:34,  1.29s/it]Loading train:   8%|▊         | 41/532 [00:49<10:08,  1.24s/it]Loading train:   8%|▊         | 42/532 [00:50<10:30,  1.29s/it]Loading train:   8%|▊         | 43/532 [00:51<10:26,  1.28s/it]Loading train:   8%|▊         | 44/532 [00:52<09:49,  1.21s/it]Loading train:   8%|▊         | 45/532 [00:54<09:31,  1.17s/it]Loading train:   9%|▊         | 46/532 [00:55<09:19,  1.15s/it]Loading train:   9%|▉         | 47/532 [00:56<10:07,  1.25s/it]Loading train:   9%|▉         | 48/532 [00:58<10:34,  1.31s/it]Loading train:   9%|▉         | 49/532 [00:59<10:47,  1.34s/it]Loading train:   9%|▉         | 50/532 [01:00<09:51,  1.23s/it]Loading train:  10%|▉         | 51/532 [01:01<10:05,  1.26s/it]Loading train:  10%|▉         | 52/532 [01:03<10:04,  1.26s/it]Loading train:  10%|▉         | 53/532 [01:04<09:51,  1.23s/it]Loading train:  10%|█         | 54/532 [01:05<10:02,  1.26s/it]Loading train:  10%|█         | 55/532 [01:06<09:40,  1.22s/it]Loading train:  11%|█         | 56/532 [01:07<09:49,  1.24s/it]Loading train:  11%|█         | 57/532 [01:09<09:44,  1.23s/it]Loading train:  11%|█         | 58/532 [01:10<10:38,  1.35s/it]Loading train:  11%|█         | 59/532 [01:12<10:19,  1.31s/it]Loading train:  11%|█▏        | 60/532 [01:13<10:12,  1.30s/it]Loading train:  11%|█▏        | 61/532 [01:14<09:58,  1.27s/it]Loading train:  12%|█▏        | 62/532 [01:15<10:25,  1.33s/it]Loading train:  12%|█▏        | 63/532 [01:17<10:05,  1.29s/it]Loading train:  12%|█▏        | 64/532 [01:18<09:14,  1.18s/it]Loading train:  12%|█▏        | 65/532 [01:19<09:36,  1.23s/it]Loading train:  12%|█▏        | 66/532 [01:21<10:43,  1.38s/it]Loading train:  13%|█▎        | 67/532 [01:22<10:50,  1.40s/it]Loading train:  13%|█▎        | 68/532 [01:23<10:14,  1.32s/it]Loading train:  13%|█▎        | 69/532 [01:25<10:18,  1.34s/it]Loading train:  13%|█▎        | 70/532 [01:26<09:56,  1.29s/it]Loading train:  13%|█▎        | 71/532 [01:27<09:39,  1.26s/it]Loading train:  14%|█▎        | 72/532 [01:28<09:07,  1.19s/it]Loading train:  14%|█▎        | 73/532 [01:29<09:23,  1.23s/it]Loading train:  14%|█▍        | 74/532 [01:31<10:27,  1.37s/it]Loading train:  14%|█▍        | 75/532 [01:33<11:23,  1.50s/it]Loading train:  14%|█▍        | 76/532 [01:34<10:13,  1.35s/it]Loading train:  14%|█▍        | 77/532 [01:35<09:21,  1.23s/it]Loading train:  15%|█▍        | 78/532 [01:36<09:39,  1.28s/it]Loading train:  15%|█▍        | 79/532 [01:37<09:31,  1.26s/it]Loading train:  15%|█▌        | 80/532 [01:39<09:18,  1.24s/it]Loading train:  15%|█▌        | 81/532 [01:40<08:56,  1.19s/it]Loading train:  15%|█▌        | 82/532 [01:41<09:09,  1.22s/it]Loading train:  16%|█▌        | 83/532 [01:42<09:07,  1.22s/it]Loading train:  16%|█▌        | 84/532 [01:43<09:07,  1.22s/it]Loading train:  16%|█▌        | 85/532 [01:44<08:40,  1.16s/it]Loading train:  16%|█▌        | 86/532 [01:45<07:52,  1.06s/it]Loading train:  16%|█▋        | 87/532 [01:46<07:29,  1.01s/it]Loading train:  17%|█▋        | 88/532 [01:47<08:01,  1.08s/it]Loading train:  17%|█▋        | 89/532 [01:49<08:55,  1.21s/it]Loading train:  17%|█▋        | 90/532 [01:50<08:57,  1.22s/it]Loading train:  17%|█▋        | 91/532 [01:51<08:15,  1.12s/it]Loading train:  17%|█▋        | 92/532 [01:52<08:05,  1.10s/it]Loading train:  17%|█▋        | 93/532 [01:53<07:57,  1.09s/it]Loading train:  18%|█▊        | 94/532 [01:54<07:40,  1.05s/it]Loading train:  18%|█▊        | 95/532 [01:55<08:21,  1.15s/it]Loading train:  18%|█▊        | 96/532 [01:57<08:38,  1.19s/it]Loading train:  18%|█▊        | 97/532 [01:58<08:52,  1.22s/it]Loading train:  18%|█▊        | 98/532 [01:59<08:38,  1.19s/it]Loading train:  19%|█▊        | 99/532 [02:01<08:51,  1.23s/it]Loading train:  19%|█▉        | 100/532 [02:02<09:00,  1.25s/it]Loading train:  19%|█▉        | 101/532 [02:03<08:27,  1.18s/it]Loading train:  19%|█▉        | 102/532 [02:04<07:52,  1.10s/it]Loading train:  19%|█▉        | 103/532 [02:05<07:33,  1.06s/it]Loading train:  20%|█▉        | 104/532 [02:05<07:01,  1.02it/s]Loading train:  20%|█▉        | 105/532 [02:06<06:38,  1.07it/s]Loading train:  20%|█▉        | 106/532 [02:07<06:57,  1.02it/s]Loading train:  20%|██        | 107/532 [02:09<07:14,  1.02s/it]Loading train:  20%|██        | 108/532 [02:10<07:10,  1.02s/it]Loading train:  20%|██        | 109/532 [02:11<07:09,  1.02s/it]Loading train:  21%|██        | 110/532 [02:12<07:05,  1.01s/it]Loading train:  21%|██        | 111/532 [02:12<06:35,  1.07it/s]Loading train:  21%|██        | 112/532 [02:13<06:20,  1.10it/s]Loading train:  21%|██        | 113/532 [02:14<07:09,  1.03s/it]Loading train:  21%|██▏       | 114/532 [02:16<07:31,  1.08s/it]Loading train:  22%|██▏       | 115/532 [02:17<07:24,  1.07s/it]Loading train:  22%|██▏       | 116/532 [02:18<07:42,  1.11s/it]Loading train:  22%|██▏       | 117/532 [02:19<07:36,  1.10s/it]Loading train:  22%|██▏       | 118/532 [02:20<07:08,  1.04s/it]Loading train:  22%|██▏       | 119/532 [02:21<07:18,  1.06s/it]Loading train:  23%|██▎       | 120/532 [02:22<07:23,  1.08s/it]Loading train:  23%|██▎       | 121/532 [02:23<07:29,  1.09s/it]Loading train:  23%|██▎       | 122/532 [02:25<07:53,  1.16s/it]Loading train:  23%|██▎       | 123/532 [02:26<07:54,  1.16s/it]Loading train:  23%|██▎       | 124/532 [02:27<07:11,  1.06s/it]Loading train:  23%|██▎       | 125/532 [02:28<07:22,  1.09s/it]Loading train:  24%|██▎       | 126/532 [02:29<07:28,  1.10s/it]Loading train:  24%|██▍       | 127/532 [02:30<07:32,  1.12s/it]Loading train:  24%|██▍       | 128/532 [02:31<07:36,  1.13s/it]Loading train:  24%|██▍       | 129/532 [02:32<07:34,  1.13s/it]Loading train:  24%|██▍       | 130/532 [02:33<07:13,  1.08s/it]Loading train:  25%|██▍       | 131/532 [02:35<07:49,  1.17s/it]Loading train:  25%|██▍       | 132/532 [02:36<08:32,  1.28s/it]Loading train:  25%|██▌       | 133/532 [02:38<09:05,  1.37s/it]Loading train:  25%|██▌       | 134/532 [02:39<08:58,  1.35s/it]Loading train:  25%|██▌       | 135/532 [02:40<08:38,  1.31s/it]Loading train:  26%|██▌       | 136/532 [02:42<08:38,  1.31s/it]Loading train:  26%|██▌       | 137/532 [02:43<08:58,  1.36s/it]Loading train:  26%|██▌       | 138/532 [02:44<08:54,  1.36s/it]Loading train:  26%|██▌       | 139/532 [02:46<08:54,  1.36s/it]Loading train:  26%|██▋       | 140/532 [02:47<08:46,  1.34s/it]Loading train:  27%|██▋       | 141/532 [02:48<08:49,  1.35s/it]Loading train:  27%|██▋       | 142/532 [02:50<08:48,  1.36s/it]Loading train:  27%|██▋       | 143/532 [02:51<08:29,  1.31s/it]Loading train:  27%|██▋       | 144/532 [02:52<08:16,  1.28s/it]Loading train:  27%|██▋       | 145/532 [02:53<07:39,  1.19s/it]Loading train:  27%|██▋       | 146/532 [02:54<06:43,  1.05s/it]Loading train:  28%|██▊       | 147/532 [02:55<06:17,  1.02it/s]Loading train:  28%|██▊       | 148/532 [02:56<06:10,  1.04it/s]Loading train:  28%|██▊       | 149/532 [02:57<06:34,  1.03s/it]Loading train:  28%|██▊       | 150/532 [02:58<06:54,  1.09s/it]Loading train:  28%|██▊       | 151/532 [02:59<07:05,  1.12s/it]Loading train:  29%|██▊       | 152/532 [03:00<07:05,  1.12s/it]Loading train:  29%|██▉       | 153/532 [03:01<06:21,  1.01s/it]Loading train:  29%|██▉       | 154/532 [03:02<06:19,  1.00s/it]Loading train:  29%|██▉       | 155/532 [03:04<07:32,  1.20s/it]Loading train:  29%|██▉       | 156/532 [03:05<07:49,  1.25s/it]Loading train:  30%|██▉       | 157/532 [03:07<08:14,  1.32s/it]Loading train:  30%|██▉       | 158/532 [03:08<08:04,  1.30s/it]Loading train:  30%|██▉       | 159/532 [03:09<08:01,  1.29s/it]Loading train:  30%|███       | 160/532 [03:11<08:40,  1.40s/it]Loading train:  30%|███       | 161/532 [03:12<08:19,  1.35s/it]Loading train:  30%|███       | 162/532 [03:13<07:43,  1.25s/it]Loading train:  31%|███       | 163/532 [03:14<07:28,  1.22s/it]Loading train:  31%|███       | 164/532 [03:15<06:49,  1.11s/it]Loading train:  31%|███       | 165/532 [03:16<06:09,  1.01s/it]Loading train:  31%|███       | 166/532 [03:17<06:23,  1.05s/it]Loading train:  31%|███▏      | 167/532 [03:18<06:47,  1.12s/it]Loading train:  32%|███▏      | 168/532 [03:19<06:57,  1.15s/it]Loading train:  32%|███▏      | 169/532 [03:21<07:06,  1.17s/it]Loading train:  32%|███▏      | 170/532 [03:22<06:42,  1.11s/it]Loading train:  32%|███▏      | 171/532 [03:22<06:15,  1.04s/it]Loading train:  32%|███▏      | 172/532 [03:24<06:37,  1.10s/it]Loading train:  33%|███▎      | 173/532 [03:25<06:37,  1.11s/it]Loading train:  33%|███▎      | 174/532 [03:26<06:21,  1.07s/it]Loading train:  33%|███▎      | 175/532 [03:27<06:23,  1.07s/it]Loading train:  33%|███▎      | 176/532 [03:28<06:26,  1.09s/it]Loading train:  33%|███▎      | 177/532 [03:29<05:52,  1.01it/s]Loading train:  33%|███▎      | 178/532 [03:30<05:43,  1.03it/s]Loading train:  34%|███▎      | 179/532 [03:31<06:13,  1.06s/it]Loading train:  34%|███▍      | 180/532 [03:32<06:23,  1.09s/it]Loading train:  34%|███▍      | 181/532 [03:33<06:22,  1.09s/it]Loading train:  34%|███▍      | 182/532 [03:34<06:22,  1.09s/it]Loading train:  34%|███▍      | 183/532 [03:35<06:12,  1.07s/it]Loading train:  35%|███▍      | 184/532 [03:36<06:00,  1.04s/it]Loading train:  35%|███▍      | 185/532 [03:37<05:51,  1.01s/it]Loading train:  35%|███▍      | 186/532 [03:38<05:45,  1.00it/s]Loading train:  35%|███▌      | 187/532 [03:39<05:53,  1.02s/it]Loading train:  35%|███▌      | 188/532 [03:40<05:59,  1.05s/it]Loading train:  36%|███▌      | 189/532 [03:42<06:10,  1.08s/it]Loading train:  36%|███▌      | 190/532 [03:43<06:00,  1.05s/it]Loading train:  36%|███▌      | 191/532 [03:44<06:21,  1.12s/it]Loading train:  36%|███▌      | 192/532 [03:45<06:47,  1.20s/it]Loading train:  36%|███▋      | 193/532 [03:47<07:25,  1.31s/it]Loading train:  36%|███▋      | 194/532 [03:48<07:27,  1.32s/it]Loading train:  37%|███▋      | 195/532 [03:50<07:46,  1.38s/it]Loading train:  37%|███▋      | 196/532 [03:51<07:18,  1.31s/it]Loading train:  37%|███▋      | 197/532 [03:52<07:10,  1.29s/it]Loading train:  37%|███▋      | 198/532 [03:53<07:04,  1.27s/it]Loading train:  37%|███▋      | 199/532 [03:55<06:59,  1.26s/it]Loading train:  38%|███▊      | 200/532 [03:56<06:49,  1.23s/it]Loading train:  38%|███▊      | 201/532 [03:57<06:51,  1.24s/it]Loading train:  38%|███▊      | 202/532 [03:58<06:38,  1.21s/it]Loading train:  38%|███▊      | 203/532 [03:59<06:32,  1.19s/it]Loading train:  38%|███▊      | 204/532 [04:00<06:32,  1.20s/it]Loading train:  39%|███▊      | 205/532 [04:02<06:21,  1.17s/it]Loading train:  39%|███▊      | 206/532 [04:02<05:56,  1.09s/it]Loading train:  39%|███▉      | 207/532 [04:03<05:44,  1.06s/it]Loading train:  39%|███▉      | 208/532 [04:04<05:40,  1.05s/it]Loading train:  39%|███▉      | 209/532 [04:05<05:12,  1.03it/s]Loading train:  39%|███▉      | 210/532 [04:06<05:20,  1.00it/s]Loading train:  40%|███▉      | 211/532 [04:07<05:27,  1.02s/it]Loading train:  40%|███▉      | 212/532 [04:08<05:14,  1.02it/s]Loading train:  40%|████      | 213/532 [04:09<05:20,  1.00s/it]Loading train:  40%|████      | 214/532 [04:10<05:13,  1.02it/s]Loading train:  40%|████      | 215/532 [04:11<05:33,  1.05s/it]Loading train:  41%|████      | 216/532 [04:13<06:15,  1.19s/it]Loading train:  41%|████      | 217/532 [04:14<06:17,  1.20s/it]Loading train:  41%|████      | 218/532 [04:16<06:33,  1.25s/it]Loading train:  41%|████      | 219/532 [04:17<06:57,  1.33s/it]Loading train:  41%|████▏     | 220/532 [04:18<06:58,  1.34s/it]Loading train:  42%|████▏     | 221/532 [04:19<06:01,  1.16s/it]Loading train:  42%|████▏     | 222/532 [04:20<05:43,  1.11s/it]Loading train:  42%|████▏     | 223/532 [04:21<05:26,  1.06s/it]Loading train:  42%|████▏     | 224/532 [04:22<05:15,  1.02s/it]Loading train:  42%|████▏     | 225/532 [04:23<05:16,  1.03s/it]Loading train:  42%|████▏     | 226/532 [04:24<05:21,  1.05s/it]Loading train:  43%|████▎     | 227/532 [04:25<05:10,  1.02s/it]Loading train:  43%|████▎     | 228/532 [04:26<04:39,  1.09it/s]Loading train:  43%|████▎     | 229/532 [04:27<04:42,  1.07it/s]Loading train:  43%|████▎     | 230/532 [04:28<04:39,  1.08it/s]Loading train:  43%|████▎     | 231/532 [04:29<04:44,  1.06it/s]Loading train:  44%|████▎     | 232/532 [04:30<04:49,  1.04it/s]Loading train:  44%|████▍     | 233/532 [04:31<05:00,  1.01s/it]Loading train:  44%|████▍     | 234/532 [04:32<04:52,  1.02it/s]Loading train:  44%|████▍     | 235/532 [04:33<04:37,  1.07it/s]Loading train:  44%|████▍     | 236/532 [04:34<04:46,  1.03it/s]Loading train:  45%|████▍     | 237/532 [04:35<05:04,  1.03s/it]Loading train:  45%|████▍     | 238/532 [04:36<05:04,  1.04s/it]Loading train:  45%|████▍     | 239/532 [04:37<05:27,  1.12s/it]Loading train:  45%|████▌     | 240/532 [04:38<05:26,  1.12s/it]Loading train:  45%|████▌     | 241/532 [04:39<05:02,  1.04s/it]Loading train:  45%|████▌     | 242/532 [04:40<04:59,  1.03s/it]Loading train:  46%|████▌     | 243/532 [04:41<05:17,  1.10s/it]Loading train:  46%|████▌     | 244/532 [04:43<05:26,  1.13s/it]Loading train:  46%|████▌     | 245/532 [04:44<05:15,  1.10s/it]Loading train:  46%|████▌     | 246/532 [04:44<04:46,  1.00s/it]Loading train:  46%|████▋     | 247/532 [04:45<04:39,  1.02it/s]Loading train:  47%|████▋     | 248/532 [04:46<04:23,  1.08it/s]Loading train:  47%|████▋     | 249/532 [04:47<04:19,  1.09it/s]Loading train:  47%|████▋     | 250/532 [04:48<04:24,  1.07it/s]Loading train:  47%|████▋     | 251/532 [04:49<04:31,  1.04it/s]Loading train:  47%|████▋     | 252/532 [04:50<04:40,  1.00s/it]Loading train:  48%|████▊     | 253/532 [04:51<04:34,  1.02it/s]Loading train:  48%|████▊     | 254/532 [04:52<04:36,  1.01it/s]Loading train:  48%|████▊     | 255/532 [04:53<04:21,  1.06it/s]Loading train:  48%|████▊     | 256/532 [04:54<04:25,  1.04it/s]Loading train:  48%|████▊     | 257/532 [04:55<05:09,  1.12s/it]Loading train:  48%|████▊     | 258/532 [04:57<05:19,  1.17s/it]Loading train:  49%|████▊     | 259/532 [04:58<05:25,  1.19s/it]Loading train:  49%|████▉     | 260/532 [04:59<05:19,  1.17s/it]Loading train:  49%|████▉     | 261/532 [05:00<04:54,  1.09s/it]Loading train:  49%|████▉     | 262/532 [05:01<05:19,  1.18s/it]Loading train:  49%|████▉     | 263/532 [05:03<05:15,  1.17s/it]Loading train:  50%|████▉     | 264/532 [05:03<04:49,  1.08s/it]Loading train:  50%|████▉     | 265/532 [05:04<04:48,  1.08s/it]Loading train:  50%|█████     | 266/532 [05:05<04:41,  1.06s/it]Loading train:  50%|█████     | 267/532 [05:06<04:17,  1.03it/s]Loading train:  50%|█████     | 268/532 [05:07<04:09,  1.06it/s]Loading train:  51%|█████     | 269/532 [05:09<04:42,  1.08s/it]Loading train:  51%|█████     | 270/532 [05:10<04:37,  1.06s/it]Loading train:  51%|█████     | 271/532 [05:11<04:36,  1.06s/it]Loading train:  51%|█████     | 272/532 [05:12<04:41,  1.08s/it]Loading train:  51%|█████▏    | 273/532 [05:13<04:35,  1.07s/it]Loading train:  52%|█████▏    | 274/532 [05:14<04:19,  1.01s/it]Loading train:  52%|█████▏    | 275/532 [05:15<05:11,  1.21s/it]Loading train:  52%|█████▏    | 276/532 [05:17<05:19,  1.25s/it]Loading train:  52%|█████▏    | 277/532 [05:18<05:43,  1.35s/it]Loading train:  52%|█████▏    | 278/532 [05:20<05:48,  1.37s/it]Loading train:  52%|█████▏    | 279/532 [05:21<05:27,  1.29s/it]Loading train:  53%|█████▎    | 280/532 [05:22<05:34,  1.33s/it]Loading train:  53%|█████▎    | 281/532 [05:24<05:33,  1.33s/it]Loading train:  53%|█████▎    | 282/532 [05:25<05:50,  1.40s/it]Loading train:  53%|█████▎    | 283/532 [05:26<05:34,  1.34s/it]Loading train:  53%|█████▎    | 284/532 [05:27<05:10,  1.25s/it]Loading train:  54%|█████▎    | 285/532 [05:29<05:09,  1.25s/it]Loading train:  54%|█████▍    | 286/532 [05:30<05:21,  1.31s/it]Loading train:  54%|█████▍    | 287/532 [05:31<04:57,  1.21s/it]Loading train:  54%|█████▍    | 288/532 [05:32<04:42,  1.16s/it]Loading train:  54%|█████▍    | 289/532 [05:33<04:49,  1.19s/it]Loading train:  55%|█████▍    | 290/532 [05:34<04:22,  1.09s/it]Loading train:  55%|█████▍    | 291/532 [05:35<04:22,  1.09s/it]Loading train:  55%|█████▍    | 292/532 [05:36<04:14,  1.06s/it]Loading train:  55%|█████▌    | 293/532 [05:37<04:18,  1.08s/it]Loading train:  55%|█████▌    | 294/532 [05:39<04:22,  1.10s/it]Loading train:  55%|█████▌    | 295/532 [05:40<04:12,  1.06s/it]Loading train:  56%|█████▌    | 296/532 [05:40<04:06,  1.04s/it]Loading train:  56%|█████▌    | 297/532 [05:42<04:07,  1.05s/it]Loading train:  56%|█████▌    | 298/532 [05:43<04:23,  1.13s/it]Loading train:  56%|█████▌    | 299/532 [05:44<04:18,  1.11s/it]Loading train:  56%|█████▋    | 300/532 [05:45<04:00,  1.04s/it]Loading train:  57%|█████▋    | 301/532 [05:46<03:49,  1.01it/s]Loading train:  57%|█████▋    | 302/532 [05:46<03:34,  1.07it/s]Loading train:  57%|█████▋    | 303/532 [05:47<03:16,  1.16it/s]Loading train:  57%|█████▋    | 304/532 [05:48<03:16,  1.16it/s]Loading train:  57%|█████▋    | 305/532 [05:49<03:48,  1.01s/it]Loading train:  58%|█████▊    | 306/532 [05:51<03:58,  1.05s/it]Loading train:  58%|█████▊    | 307/532 [05:52<04:12,  1.12s/it]Loading train:  58%|█████▊    | 308/532 [05:53<04:32,  1.22s/it]Loading train:  58%|█████▊    | 309/532 [05:55<04:37,  1.25s/it]Loading train:  58%|█████▊    | 310/532 [05:56<04:42,  1.27s/it]Loading train:  58%|█████▊    | 311/532 [05:58<05:29,  1.49s/it]Loading train:  59%|█████▊    | 312/532 [06:00<05:44,  1.57s/it]Loading train:  59%|█████▉    | 313/532 [06:01<05:44,  1.57s/it]Loading train:  59%|█████▉    | 314/532 [06:03<05:48,  1.60s/it]Loading train:  59%|█████▉    | 315/532 [06:05<06:10,  1.71s/it]Loading train:  59%|█████▉    | 316/532 [06:07<06:07,  1.70s/it]Loading train:  60%|█████▉    | 317/532 [06:07<05:12,  1.45s/it]Loading train:  60%|█████▉    | 318/532 [06:09<04:48,  1.35s/it]Loading train:  60%|█████▉    | 319/532 [06:10<04:28,  1.26s/it]Loading train:  60%|██████    | 320/532 [06:11<04:18,  1.22s/it]Loading train:  60%|██████    | 321/532 [06:12<04:13,  1.20s/it]Loading train:  61%|██████    | 322/532 [06:13<04:00,  1.15s/it]Loading train:  61%|██████    | 323/532 [06:14<04:09,  1.20s/it]Loading train:  61%|██████    | 324/532 [06:16<04:35,  1.32s/it]Loading train:  61%|██████    | 325/532 [06:17<04:55,  1.43s/it]Loading train:  61%|██████▏   | 326/532 [06:19<05:02,  1.47s/it]Loading train:  61%|██████▏   | 327/532 [06:20<04:47,  1.40s/it]Loading train:  62%|██████▏   | 328/532 [06:22<04:46,  1.40s/it]Loading train:  62%|██████▏   | 329/532 [06:23<04:30,  1.33s/it]Loading train:  62%|██████▏   | 330/532 [06:24<04:09,  1.23s/it]Loading train:  62%|██████▏   | 331/532 [06:25<04:06,  1.22s/it]Loading train:  62%|██████▏   | 332/532 [06:26<03:39,  1.10s/it]Loading train:  63%|██████▎   | 333/532 [06:27<03:40,  1.11s/it]Loading train:  63%|██████▎   | 334/532 [06:28<03:37,  1.10s/it]Loading train:  63%|██████▎   | 335/532 [06:30<03:54,  1.19s/it]Loading train:  63%|██████▎   | 336/532 [06:31<03:56,  1.20s/it]Loading train:  63%|██████▎   | 337/532 [06:32<04:00,  1.23s/it]Loading train:  64%|██████▎   | 338/532 [06:33<03:49,  1.18s/it]Loading train:  64%|██████▎   | 339/532 [06:34<03:56,  1.22s/it]Loading train:  64%|██████▍   | 340/532 [06:36<04:00,  1.25s/it]Loading train:  64%|██████▍   | 341/532 [06:37<03:43,  1.17s/it]Loading train:  64%|██████▍   | 342/532 [06:38<03:26,  1.09s/it]Loading train:  64%|██████▍   | 343/532 [06:38<03:06,  1.01it/s]Loading train:  65%|██████▍   | 344/532 [06:39<02:53,  1.09it/s]Loading train:  65%|██████▍   | 345/532 [06:40<03:07,  1.00s/it]Loading train:  65%|██████▌   | 346/532 [06:41<03:09,  1.02s/it]Loading train:  65%|██████▌   | 347/532 [06:43<03:22,  1.10s/it]Loading train:  65%|██████▌   | 348/532 [06:44<03:16,  1.07s/it]Loading train:  66%|██████▌   | 349/532 [06:45<03:17,  1.08s/it]Loading train:  66%|██████▌   | 350/532 [06:46<03:04,  1.01s/it]Loading train:  66%|██████▌   | 351/532 [06:47<03:21,  1.11s/it]Loading train:  66%|██████▌   | 352/532 [06:48<03:24,  1.14s/it]Loading train:  66%|██████▋   | 353/532 [06:49<03:21,  1.13s/it]Loading train:  67%|██████▋   | 354/532 [06:50<03:09,  1.06s/it]Loading train:  67%|██████▋   | 355/532 [06:51<03:02,  1.03s/it]Loading train:  67%|██████▋   | 356/532 [06:52<02:47,  1.05it/s]Loading train:  67%|██████▋   | 357/532 [06:53<03:04,  1.05s/it]Loading train:  67%|██████▋   | 358/532 [06:54<03:04,  1.06s/it]Loading train:  67%|██████▋   | 359/532 [06:55<03:00,  1.04s/it]Loading train:  68%|██████▊   | 360/532 [06:56<02:54,  1.01s/it]Loading train:  68%|██████▊   | 361/532 [06:57<02:49,  1.01it/s]Loading train:  68%|██████▊   | 362/532 [06:58<02:48,  1.01it/s]Loading train:  68%|██████▊   | 363/532 [06:59<02:37,  1.07it/s]Loading train:  68%|██████▊   | 364/532 [07:00<02:36,  1.07it/s]Loading train:  69%|██████▊   | 365/532 [07:01<02:45,  1.01it/s]Loading train:  69%|██████▉   | 366/532 [07:02<02:50,  1.03s/it]Loading train:  69%|██████▉   | 367/532 [07:03<02:57,  1.08s/it]Loading train:  69%|██████▉   | 368/532 [07:04<02:59,  1.09s/it]Loading train:  69%|██████▉   | 369/532 [07:05<02:43,  1.00s/it]Loading train:  70%|██████▉   | 370/532 [07:06<02:36,  1.04it/s]Loading train:  70%|██████▉   | 371/532 [07:07<02:49,  1.05s/it]Loading train:  70%|██████▉   | 372/532 [07:09<03:06,  1.17s/it]Loading train:  70%|███████   | 373/532 [07:10<03:18,  1.25s/it]Loading train:  70%|███████   | 374/532 [07:12<03:19,  1.26s/it]Loading train:  70%|███████   | 375/532 [07:13<03:29,  1.33s/it]Loading train:  71%|███████   | 376/532 [07:14<03:29,  1.34s/it]Loading train:  71%|███████   | 377/532 [07:16<03:19,  1.29s/it]Loading train:  71%|███████   | 378/532 [07:17<03:05,  1.20s/it]Loading train:  71%|███████   | 379/532 [07:18<02:56,  1.15s/it]Loading train:  71%|███████▏  | 380/532 [07:19<02:52,  1.14s/it]Loading train:  72%|███████▏  | 381/532 [07:20<02:53,  1.15s/it]Loading train:  72%|███████▏  | 382/532 [07:21<02:46,  1.11s/it]Loading train:  72%|███████▏  | 383/532 [07:22<02:48,  1.13s/it]Loading train:  72%|███████▏  | 384/532 [07:23<02:38,  1.07s/it]Loading train:  72%|███████▏  | 385/532 [07:24<02:31,  1.03s/it]Loading train:  73%|███████▎  | 386/532 [07:25<02:28,  1.01s/it]Loading train:  73%|███████▎  | 387/532 [07:26<02:35,  1.07s/it]Loading train:  73%|███████▎  | 388/532 [07:27<02:39,  1.11s/it]Loading train:  73%|███████▎  | 389/532 [07:29<02:48,  1.18s/it]Loading train:  73%|███████▎  | 390/532 [07:30<02:46,  1.17s/it]Loading train:  73%|███████▎  | 391/532 [07:31<02:35,  1.10s/it]Loading train:  74%|███████▎  | 392/532 [07:32<02:43,  1.17s/it]Loading train:  74%|███████▍  | 393/532 [07:33<02:41,  1.16s/it]Loading train:  74%|███████▍  | 394/532 [07:34<02:41,  1.17s/it]Loading train:  74%|███████▍  | 395/532 [07:36<02:44,  1.20s/it]Loading train:  74%|███████▍  | 396/532 [07:37<02:39,  1.17s/it]Loading train:  75%|███████▍  | 397/532 [07:38<02:30,  1.11s/it]Loading train:  75%|███████▍  | 398/532 [07:39<02:33,  1.14s/it]Loading train:  75%|███████▌  | 399/532 [07:40<02:36,  1.17s/it]Loading train:  75%|███████▌  | 400/532 [07:41<02:33,  1.16s/it]Loading train:  75%|███████▌  | 401/532 [07:43<02:42,  1.24s/it]Loading train:  76%|███████▌  | 402/532 [07:44<02:33,  1.18s/it]Loading train:  76%|███████▌  | 403/532 [07:45<02:32,  1.18s/it]Loading train:  76%|███████▌  | 404/532 [07:46<02:32,  1.19s/it]Loading train:  76%|███████▌  | 405/532 [07:47<02:33,  1.21s/it]Loading train:  76%|███████▋  | 406/532 [07:49<02:31,  1.21s/it]Loading train:  77%|███████▋  | 407/532 [07:50<02:26,  1.17s/it]Loading train:  77%|███████▋  | 408/532 [07:51<02:15,  1.09s/it]Loading train:  77%|███████▋  | 409/532 [07:52<02:11,  1.07s/it]Loading train:  77%|███████▋  | 410/532 [07:53<02:24,  1.19s/it]Loading train:  77%|███████▋  | 411/532 [07:54<02:24,  1.20s/it]Loading train:  77%|███████▋  | 412/532 [07:55<02:18,  1.16s/it]Loading train:  78%|███████▊  | 413/532 [07:57<02:15,  1.14s/it]Loading train:  78%|███████▊  | 414/532 [07:57<02:07,  1.08s/it]Loading train:  78%|███████▊  | 415/532 [07:59<02:07,  1.09s/it]Loading train:  78%|███████▊  | 416/532 [08:00<02:05,  1.08s/it]Loading train:  78%|███████▊  | 417/532 [08:01<02:03,  1.07s/it]Loading train:  79%|███████▊  | 418/532 [08:02<01:53,  1.00it/s]Loading train:  79%|███████▉  | 419/532 [08:03<01:57,  1.04s/it]Loading train:  79%|███████▉  | 420/532 [08:04<01:55,  1.03s/it]Loading train:  79%|███████▉  | 421/532 [08:05<01:58,  1.07s/it]Loading train:  79%|███████▉  | 422/532 [08:06<02:05,  1.14s/it]Loading train:  80%|███████▉  | 423/532 [08:07<02:06,  1.16s/it]Loading train:  80%|███████▉  | 424/532 [08:08<02:00,  1.12s/it]Loading train:  80%|███████▉  | 425/532 [08:09<01:59,  1.12s/it]Loading train:  80%|████████  | 426/532 [08:10<01:53,  1.07s/it]Loading train:  80%|████████  | 427/532 [08:12<01:54,  1.09s/it]Loading train:  80%|████████  | 428/532 [08:13<01:51,  1.07s/it]Loading train:  81%|████████  | 429/532 [08:14<01:49,  1.06s/it]Loading train:  81%|████████  | 430/532 [08:15<01:50,  1.08s/it]Loading train:  81%|████████  | 431/532 [08:16<01:50,  1.09s/it]Loading train:  81%|████████  | 432/532 [08:17<01:54,  1.14s/it]Loading train:  81%|████████▏ | 433/532 [08:18<01:56,  1.17s/it]Loading train:  82%|████████▏ | 434/532 [08:20<01:56,  1.19s/it]Loading train:  82%|████████▏ | 435/532 [08:21<02:00,  1.24s/it]Loading train:  82%|████████▏ | 436/532 [08:22<01:52,  1.17s/it]Loading train:  82%|████████▏ | 437/532 [08:23<01:53,  1.20s/it]Loading train:  82%|████████▏ | 438/532 [08:24<01:52,  1.19s/it]Loading train:  83%|████████▎ | 439/532 [08:25<01:43,  1.12s/it]Loading train:  83%|████████▎ | 440/532 [08:26<01:36,  1.04s/it]Loading train:  83%|████████▎ | 441/532 [08:28<01:41,  1.12s/it]Loading train:  83%|████████▎ | 442/532 [08:28<01:33,  1.03s/it]Loading train:  83%|████████▎ | 443/532 [08:30<01:36,  1.08s/it]Loading train:  83%|████████▎ | 444/532 [08:31<01:31,  1.04s/it]Loading train:  84%|████████▎ | 445/532 [08:31<01:27,  1.01s/it]Loading train:  84%|████████▍ | 446/532 [08:32<01:25,  1.00it/s]Loading train:  84%|████████▍ | 447/532 [08:33<01:21,  1.04it/s]Loading train:  84%|████████▍ | 448/532 [08:34<01:16,  1.10it/s]Loading train:  84%|████████▍ | 449/532 [08:35<01:15,  1.10it/s]Loading train:  85%|████████▍ | 450/532 [08:36<01:18,  1.04it/s]Loading train:  85%|████████▍ | 451/532 [08:37<01:22,  1.02s/it]Loading train:  85%|████████▍ | 452/532 [08:38<01:22,  1.03s/it]Loading train:  85%|████████▌ | 453/532 [08:39<01:23,  1.05s/it]Loading train:  85%|████████▌ | 454/532 [08:40<01:21,  1.04s/it]Loading train:  86%|████████▌ | 455/532 [08:41<01:20,  1.04s/it]Loading train:  86%|████████▌ | 456/532 [08:43<01:23,  1.09s/it]Loading train:  86%|████████▌ | 457/532 [08:44<01:24,  1.13s/it]Loading train:  86%|████████▌ | 458/532 [08:45<01:22,  1.12s/it]Loading train:  86%|████████▋ | 459/532 [08:46<01:22,  1.12s/it]Loading train:  86%|████████▋ | 460/532 [08:47<01:19,  1.10s/it]Loading train:  87%|████████▋ | 461/532 [08:48<01:22,  1.17s/it]Loading train:  87%|████████▋ | 462/532 [08:50<01:25,  1.22s/it]Loading train:  87%|████████▋ | 463/532 [08:51<01:24,  1.22s/it]Loading train:  87%|████████▋ | 464/532 [08:53<01:27,  1.29s/it]Loading train:  87%|████████▋ | 465/532 [08:54<01:24,  1.26s/it]Loading train:  88%|████████▊ | 466/532 [08:55<01:21,  1.23s/it]Loading train:  88%|████████▊ | 467/532 [08:56<01:18,  1.20s/it]Loading train:  88%|████████▊ | 468/532 [08:57<01:13,  1.15s/it]Loading train:  88%|████████▊ | 469/532 [08:58<01:06,  1.06s/it]Loading train:  88%|████████▊ | 470/532 [08:59<01:00,  1.02it/s]Loading train:  89%|████████▊ | 471/532 [09:00<00:57,  1.06it/s]Loading train:  89%|████████▊ | 472/532 [09:00<00:55,  1.08it/s]Loading train:  89%|████████▉ | 473/532 [09:02<00:58,  1.01it/s]Loading train:  89%|████████▉ | 474/532 [09:03<00:57,  1.01it/s]Loading train:  89%|████████▉ | 475/532 [09:03<00:56,  1.02it/s]Loading train:  89%|████████▉ | 476/532 [09:04<00:55,  1.01it/s]Loading train:  90%|████████▉ | 477/532 [09:05<00:54,  1.02it/s]Loading train:  90%|████████▉ | 478/532 [09:06<00:52,  1.03it/s]Loading train:  90%|█████████ | 479/532 [09:07<00:50,  1.04it/s]Loading train:  90%|█████████ | 480/532 [09:08<00:51,  1.01it/s]Loading train:  90%|█████████ | 481/532 [09:09<00:49,  1.03it/s]Loading train:  91%|█████████ | 482/532 [09:10<00:46,  1.07it/s]Loading train:  91%|█████████ | 483/532 [09:11<00:44,  1.09it/s]Loading train:  91%|█████████ | 484/532 [09:12<00:43,  1.11it/s]Loading train:  91%|█████████ | 485/532 [09:13<00:44,  1.05it/s]Loading train:  91%|█████████▏| 486/532 [09:14<00:45,  1.01it/s]Loading train:  92%|█████████▏| 487/532 [09:15<00:44,  1.00it/s]Loading train:  92%|█████████▏| 488/532 [09:16<00:43,  1.01it/s]Loading train:  92%|█████████▏| 489/532 [09:17<00:44,  1.03s/it]Loading train:  92%|█████████▏| 490/532 [09:18<00:43,  1.05s/it]Loading train:  92%|█████████▏| 491/532 [09:19<00:41,  1.01s/it]Loading train:  92%|█████████▏| 492/532 [09:20<00:39,  1.01it/s]Loading train:  93%|█████████▎| 493/532 [09:21<00:40,  1.03s/it]Loading train:  93%|█████████▎| 494/532 [09:22<00:39,  1.03s/it]Loading train:  93%|█████████▎| 495/532 [09:23<00:37,  1.01s/it]Loading train:  93%|█████████▎| 496/532 [09:24<00:35,  1.02it/s]Loading train:  93%|█████████▎| 497/532 [09:25<00:35,  1.00s/it]Loading train:  94%|█████████▎| 498/532 [09:26<00:33,  1.02it/s]Loading train:  94%|█████████▍| 499/532 [09:27<00:31,  1.06it/s]Loading train:  94%|█████████▍| 500/532 [09:28<00:33,  1.05s/it]Loading train:  94%|█████████▍| 501/532 [09:30<00:34,  1.10s/it]Loading train:  94%|█████████▍| 502/532 [09:31<00:34,  1.15s/it]Loading train:  95%|█████████▍| 503/532 [09:32<00:33,  1.15s/it]Loading train:  95%|█████████▍| 504/532 [09:33<00:31,  1.13s/it]Loading train:  95%|█████████▍| 505/532 [09:34<00:32,  1.19s/it]Loading train:  95%|█████████▌| 506/532 [09:36<00:31,  1.23s/it]Loading train:  95%|█████████▌| 507/532 [09:37<00:28,  1.16s/it]Loading train:  95%|█████████▌| 508/532 [09:38<00:27,  1.16s/it]Loading train:  96%|█████████▌| 509/532 [09:39<00:26,  1.17s/it]Loading train:  96%|█████████▌| 510/532 [09:41<00:29,  1.32s/it]Loading train:  96%|█████████▌| 511/532 [09:42<00:27,  1.33s/it]Loading train:  96%|█████████▌| 512/532 [09:43<00:27,  1.36s/it]Loading train:  96%|█████████▋| 513/532 [09:45<00:26,  1.38s/it]Loading train:  97%|█████████▋| 514/532 [09:46<00:23,  1.32s/it]Loading train:  97%|█████████▋| 515/532 [09:48<00:23,  1.39s/it]Loading train:  97%|█████████▋| 516/532 [09:49<00:22,  1.42s/it]Loading train:  97%|█████████▋| 517/532 [09:50<00:21,  1.40s/it]Loading train:  97%|█████████▋| 518/532 [09:52<00:19,  1.38s/it]Loading train:  98%|█████████▊| 519/532 [09:53<00:17,  1.32s/it]Loading train:  98%|█████████▊| 520/532 [09:54<00:15,  1.30s/it]Loading train:  98%|█████████▊| 521/532 [09:56<00:15,  1.40s/it]Loading train:  98%|█████████▊| 522/532 [09:57<00:13,  1.36s/it]Loading train:  98%|█████████▊| 523/532 [09:58<00:12,  1.36s/it]Loading train:  98%|█████████▊| 524/532 [10:00<00:11,  1.39s/it]Loading train:  99%|█████████▊| 525/532 [10:01<00:09,  1.34s/it]Loading train:  99%|█████████▉| 526/532 [10:03<00:08,  1.38s/it]Loading train:  99%|█████████▉| 527/532 [10:04<00:06,  1.36s/it]Loading train:  99%|█████████▉| 528/532 [10:05<00:05,  1.37s/it]Loading train:  99%|█████████▉| 529/532 [10:07<00:03,  1.32s/it]Loading train: 100%|█████████▉| 530/532 [10:08<00:02,  1.30s/it]Loading train: 100%|█████████▉| 531/532 [10:09<00:01,  1.34s/it]Loading train: 100%|██████████| 532/532 [10:11<00:00,  1.34s/it]
concatenating: train:   0%|          | 0/532 [00:00<?, ?it/s]concatenating: train:   0%|          | 2/532 [00:00<00:28, 18.84it/s]concatenating: train:   1%|          | 4/532 [00:00<00:27, 18.95it/s]concatenating: train:   2%|▏         | 10/532 [00:00<00:22, 23.40it/s]concatenating: train:   3%|▎         | 17/532 [00:00<00:17, 28.81it/s]concatenating: train:   5%|▍         | 24/532 [00:00<00:14, 34.37it/s]concatenating: train:   6%|▌         | 31/532 [00:00<00:12, 40.28it/s]concatenating: train:   8%|▊         | 44/532 [00:00<00:09, 50.56it/s]concatenating: train:  11%|█         | 57/532 [00:00<00:07, 61.56it/s]concatenating: train:  12%|█▏        | 66/532 [00:01<00:08, 55.85it/s]concatenating: train:  14%|█▍        | 74/532 [00:01<00:10, 45.18it/s]concatenating: train:  15%|█▌        | 81/532 [00:01<00:10, 43.41it/s]concatenating: train:  17%|█▋        | 89/532 [00:01<00:08, 50.27it/s]concatenating: train:  19%|█▉        | 102/532 [00:01<00:07, 61.25it/s]concatenating: train:  22%|██▏       | 115/532 [00:01<00:05, 72.32it/s]concatenating: train:  24%|██▍       | 128/532 [00:01<00:04, 82.78it/s]concatenating: train:  26%|██▌       | 139/532 [00:02<00:04, 80.05it/s]concatenating: train:  28%|██▊       | 149/532 [00:02<00:04, 77.98it/s]concatenating: train:  30%|██▉       | 158/532 [00:02<00:06, 59.90it/s]concatenating: train:  31%|███       | 166/532 [00:02<00:06, 53.37it/s]concatenating: train:  33%|███▎      | 173/532 [00:02<00:07, 48.01it/s]concatenating: train:  35%|███▍      | 185/532 [00:02<00:05, 58.51it/s]concatenating: train:  37%|███▋      | 197/532 [00:02<00:04, 68.66it/s]concatenating: train:  39%|███▉      | 210/532 [00:03<00:04, 79.40it/s]concatenating: train:  41%|████▏     | 220/532 [00:03<00:03, 83.78it/s]concatenating: train:  44%|████▍     | 233/532 [00:03<00:03, 92.97it/s]concatenating: train:  46%|████▌     | 245/532 [00:03<00:02, 98.73it/s]concatenating: train:  48%|████▊     | 258/532 [00:03<00:02, 105.39it/s]concatenating: train:  51%|█████     | 271/532 [00:03<00:02, 110.58it/s]concatenating: train:  54%|█████▍    | 287/532 [00:03<00:02, 121.86it/s]concatenating: train:  56%|█████▋    | 300/532 [00:03<00:02, 106.10it/s]concatenating: train:  59%|█████▊    | 312/532 [00:04<00:02, 81.32it/s] concatenating: train:  61%|██████    | 322/532 [00:04<00:03, 65.75it/s]concatenating: train:  62%|██████▏   | 331/532 [00:04<00:02, 68.21it/s]concatenating: train:  65%|██████▍   | 345/532 [00:04<00:02, 80.06it/s]concatenating: train:  69%|██████▉   | 368/532 [00:04<00:01, 99.52it/s]concatenating: train:  72%|███████▏  | 382/532 [00:04<00:01, 83.29it/s]concatenating: train:  74%|███████▍  | 394/532 [00:05<00:01, 83.25it/s]concatenating: train:  80%|███████▉  | 424/532 [00:05<00:01, 106.08it/s]concatenating: train:  83%|████████▎ | 441/532 [00:05<00:00, 98.61it/s] concatenating: train:  86%|████████▌ | 455/532 [00:05<00:01, 76.89it/s]concatenating: train:  91%|█████████ | 483/532 [00:05<00:00, 97.98it/s]concatenating: train:  94%|█████████▍| 500/532 [00:05<00:00, 97.22it/s]concatenating: train:  97%|█████████▋| 515/532 [00:06<00:00, 89.28it/s]concatenating: train:  99%|█████████▉| 528/532 [00:06<00:00, 91.78it/s]concatenating: train: 100%|██████████| 532/532 [00:06<00:00, 85.01it/s]
Loading test:   0%|          | 0/15 [00:00<?, ?it/s]Loading test:   7%|▋         | 1/15 [00:01<00:15,  1.14s/it]Loading test:  13%|█▎        | 2/15 [00:02<00:15,  1.18s/it]Loading test:  20%|██        | 3/15 [00:04<00:15,  1.31s/it]Loading test:  27%|██▋       | 4/15 [00:05<00:14,  1.33s/it]Loading test:  33%|███▎      | 5/15 [00:06<00:13,  1.38s/it]Loading test:  40%|████      | 6/15 [00:08<00:14,  1.57s/it]Loading test:  47%|████▋     | 7/15 [00:09<00:10,  1.37s/it]Loading test:  53%|█████▎    | 8/15 [00:11<00:10,  1.47s/it]Loading test:  60%|██████    | 9/15 [00:12<00:08,  1.44s/it]Loading test:  67%|██████▋   | 10/15 [00:14<00:06,  1.40s/it]Loading test:  73%|███████▎  | 11/15 [00:15<00:05,  1.41s/it]Loading test:  80%|████████  | 12/15 [00:17<00:04,  1.48s/it]Loading test:  87%|████████▋ | 13/15 [00:18<00:03,  1.52s/it]Loading test:  93%|█████████▎| 14/15 [00:20<00:01,  1.47s/it]Loading test: 100%|██████████| 15/15 [00:21<00:00,  1.48s/it]
concatenating: validation:   0%|          | 0/15 [00:00<?, ?it/s]concatenating: validation:  53%|█████▎    | 8/15 [00:00<00:00, 71.55it/s]concatenating: validation:  93%|█████████▎| 14/15 [00:00<00:00, 66.74it/s]concatenating: validation: 100%|██████████| 15/15 [00:00<00:00, 64.46it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 84, 56, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 84, 56, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 84, 56, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 84, 56, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 84, 56, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 84, 56, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 84, 56, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 84, 56, 31)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 42, 28, 31)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 42, 28, 31)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 42, 28, 60)   16800       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 42, 28, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 42, 28, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 42, 28, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 42, 28, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 42, 28, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 42, 28, 91)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 21, 14, 91)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 21, 14, 91)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 21, 14, 120)  98400       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 21, 14, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 21, 14, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 21, 14, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 21, 14, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 21, 14, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 21, 14, 211)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 21, 14, 211)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 42, 28, 60)   50700       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 42, 28, 151)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 42, 28, 60)   81600       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 42, 28, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 42, 28, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 42, 28, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 42, 28, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 42, 28, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 42, 28, 211)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-07 12:17:47.339622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 12:17:47.339730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 12:17:47.339744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 12:17:47.339753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 12:17:47.340102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 42, 28, 211)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 84, 56, 30)   25350       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 56, 61)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 84, 56, 30)   16500       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 84, 56, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 84, 56, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 84, 56, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 84, 56, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 56, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 84, 56, 91)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 84, 56, 91)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 84, 56, 13)   1196        dropout_5[0][0]                  
==================================================================================================
Total params: 504,146
Trainable params: 502,946
Non-trainable params: 1,200
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.53807809e-02 2.88974534e-02 1.16728790e-01 1.00198377e-02
 3.03363016e-02 5.79915656e-03 6.86746312e-02 1.28228722e-01
 7.55625878e-02 1.22514673e-02 2.73642650e-01 1.84278063e-01
 1.99559502e-04]
Train on 19871 samples, validate on 569 samples
Epoch 1/300
 - 37s - loss: 40.1590 - acc: 0.8279 - mDice: 0.0349 - val_loss: 5.7376 - val_acc: 0.9092 - val_mDice: 0.0550

Epoch 00001: val_mDice improved from -inf to 0.05501, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 29s - loss: 5.6823 - acc: 0.9029 - mDice: 0.1353 - val_loss: 3.8931 - val_acc: 0.9309 - val_mDice: 0.2087

Epoch 00002: val_mDice improved from 0.05501 to 0.20867, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 28s - loss: 3.8597 - acc: 0.9237 - mDice: 0.3096 - val_loss: 2.3731 - val_acc: 0.9519 - val_mDice: 0.4681

Epoch 00003: val_mDice improved from 0.20867 to 0.46805, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 30s - loss: 2.8914 - acc: 0.9425 - mDice: 0.4566 - val_loss: 1.8075 - val_acc: 0.9657 - val_mDice: 0.6118

Epoch 00004: val_mDice improved from 0.46805 to 0.61185, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 28s - loss: 2.4049 - acc: 0.9504 - mDice: 0.5397 - val_loss: 1.5203 - val_acc: 0.9684 - val_mDice: 0.6748

Epoch 00005: val_mDice improved from 0.61185 to 0.67481, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 29s - loss: 2.1486 - acc: 0.9542 - mDice: 0.5837 - val_loss: 1.4118 - val_acc: 0.9721 - val_mDice: 0.6963

Epoch 00006: val_mDice improved from 0.67481 to 0.69627, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 7/300
 - 27s - loss: 1.9654 - acc: 0.9568 - mDice: 0.6141 - val_loss: 1.3131 - val_acc: 0.9732 - val_mDice: 0.7177

Epoch 00007: val_mDice improved from 0.69627 to 0.71773, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 8/300
 - 29s - loss: 1.8499 - acc: 0.9584 - mDice: 0.6338 - val_loss: 1.3088 - val_acc: 0.9739 - val_mDice: 0.7255

Epoch 00008: val_mDice improved from 0.71773 to 0.72545, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 27s - loss: 1.7432 - acc: 0.9598 - mDice: 0.6517 - val_loss: 1.2775 - val_acc: 0.9747 - val_mDice: 0.7304

Epoch 00009: val_mDice improved from 0.72545 to 0.73044, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 10/300
 - 29s - loss: 1.6540 - acc: 0.9609 - mDice: 0.6674 - val_loss: 1.2253 - val_acc: 0.9750 - val_mDice: 0.7389

Epoch 00010: val_mDice improved from 0.73044 to 0.73887, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 11/300
 - 28s - loss: 1.5845 - acc: 0.9619 - mDice: 0.6787 - val_loss: 1.2253 - val_acc: 0.9753 - val_mDice: 0.7430

Epoch 00011: val_mDice improved from 0.73887 to 0.74302, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 12/300
 - 29s - loss: 1.5255 - acc: 0.9626 - mDice: 0.6884 - val_loss: 1.1882 - val_acc: 0.9760 - val_mDice: 0.7448

Epoch 00012: val_mDice improved from 0.74302 to 0.74477, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 13/300
 - 27s - loss: 1.4756 - acc: 0.9632 - mDice: 0.6969 - val_loss: 1.1852 - val_acc: 0.9767 - val_mDice: 0.7471

Epoch 00013: val_mDice improved from 0.74477 to 0.74715, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 14/300
 - 30s - loss: 1.4375 - acc: 0.9637 - mDice: 0.7030 - val_loss: 1.1958 - val_acc: 0.9774 - val_mDice: 0.7442

Epoch 00014: val_mDice did not improve from 0.74715
Epoch 15/300
 - 28s - loss: 1.3987 - acc: 0.9642 - mDice: 0.7098 - val_loss: 1.1819 - val_acc: 0.9760 - val_mDice: 0.7510

Epoch 00015: val_mDice improved from 0.74715 to 0.75101, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 16/300
 - 29s - loss: 1.3705 - acc: 0.9646 - mDice: 0.7144 - val_loss: 1.1286 - val_acc: 0.9773 - val_mDice: 0.7537

Epoch 00016: val_mDice improved from 0.75101 to 0.75372, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 17/300
 - 28s - loss: 1.3381 - acc: 0.9651 - mDice: 0.7200 - val_loss: 1.1800 - val_acc: 0.9765 - val_mDice: 0.7515

Epoch 00017: val_mDice did not improve from 0.75372
Epoch 18/300
 - 27s - loss: 1.3131 - acc: 0.9655 - mDice: 0.7238 - val_loss: 1.1631 - val_acc: 0.9773 - val_mDice: 0.7535

Epoch 00018: val_mDice did not improve from 0.75372
Epoch 19/300
 - 27s - loss: 1.2827 - acc: 0.9658 - mDice: 0.7289 - val_loss: 1.1240 - val_acc: 0.9781 - val_mDice: 0.7562

Epoch 00019: val_mDice improved from 0.75372 to 0.75624, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 20/300
 - 27s - loss: 1.2619 - acc: 0.9661 - mDice: 0.7329 - val_loss: 1.1023 - val_acc: 0.9767 - val_mDice: 0.7640

Epoch 00020: val_mDice improved from 0.75624 to 0.76399, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 21/300
 - 25s - loss: 1.2487 - acc: 0.9662 - mDice: 0.7354 - val_loss: 1.1195 - val_acc: 0.9778 - val_mDice: 0.7570

Epoch 00021: val_mDice did not improve from 0.76399
Epoch 22/300
 - 27s - loss: 1.2314 - acc: 0.9665 - mDice: 0.7382 - val_loss: 1.0962 - val_acc: 0.9780 - val_mDice: 0.7623

Epoch 00022: val_mDice did not improve from 0.76399
Epoch 23/300
 - 25s - loss: 1.2123 - acc: 0.9667 - mDice: 0.7417 - val_loss: 1.1182 - val_acc: 0.9785 - val_mDice: 0.7570

Epoch 00023: val_mDice did not improve from 0.76399
Epoch 24/300
 - 25s - loss: 1.1964 - acc: 0.9669 - mDice: 0.7443 - val_loss: 1.1098 - val_acc: 0.9766 - val_mDice: 0.7614

Epoch 00024: val_mDice did not improve from 0.76399
Epoch 25/300
 - 26s - loss: 1.1751 - acc: 0.9672 - mDice: 0.7487 - val_loss: 1.0963 - val_acc: 0.9781 - val_mDice: 0.7574

Epoch 00025: val_mDice did not improve from 0.76399
Epoch 26/300
 - 26s - loss: 1.1661 - acc: 0.9673 - mDice: 0.7499 - val_loss: 1.0849 - val_acc: 0.9778 - val_mDice: 0.7650

Epoch 00026: val_mDice improved from 0.76399 to 0.76505, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 27/300
 - 25s - loss: 1.1521 - acc: 0.9674 - mDice: 0.7524 - val_loss: 1.0914 - val_acc: 0.9785 - val_mDice: 0.7648

Epoch 00027: val_mDice did not improve from 0.76505
Epoch 28/300
 - 25s - loss: 1.1409 - acc: 0.9676 - mDice: 0.7547 - val_loss: 1.0891 - val_acc: 0.9787 - val_mDice: 0.7643

Epoch 00028: val_mDice did not improve from 0.76505
Epoch 29/300
 - 27s - loss: 1.1234 - acc: 0.9678 - mDice: 0.7577 - val_loss: 1.0816 - val_acc: 0.9782 - val_mDice: 0.7681

Epoch 00029: val_mDice improved from 0.76505 to 0.76808, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 30/300
 - 25s - loss: 1.1138 - acc: 0.9680 - mDice: 0.7595 - val_loss: 1.0672 - val_acc: 0.9790 - val_mDice: 0.7658

Epoch 00030: val_mDice did not improve from 0.76808
Epoch 31/300
 - 25s - loss: 1.0965 - acc: 0.9681 - mDice: 0.7628 - val_loss: 1.0941 - val_acc: 0.9790 - val_mDice: 0.7625

Epoch 00031: val_mDice did not improve from 0.76808
Epoch 32/300
 - 26s - loss: 1.0918 - acc: 0.9682 - mDice: 0.7642 - val_loss: 1.0811 - val_acc: 0.9783 - val_mDice: 0.7640

Epoch 00032: val_mDice did not improve from 0.76808
Epoch 33/300
 - 26s - loss: 1.0806 - acc: 0.9683 - mDice: 0.7659 - val_loss: 1.0607 - val_acc: 0.9785 - val_mDice: 0.7696

Epoch 00033: val_mDice improved from 0.76808 to 0.76963, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 34/300
 - 25s - loss: 1.0735 - acc: 0.9684 - mDice: 0.7675 - val_loss: 1.0679 - val_acc: 0.9788 - val_mDice: 0.7686

Epoch 00034: val_mDice did not improve from 0.76963
Epoch 35/300
 - 25s - loss: 1.0633 - acc: 0.9686 - mDice: 0.7694 - val_loss: 1.0483 - val_acc: 0.9790 - val_mDice: 0.7681

Epoch 00035: val_mDice did not improve from 0.76963
Epoch 36/300
 - 26s - loss: 1.0586 - acc: 0.9687 - mDice: 0.7704 - val_loss: 1.0954 - val_acc: 0.9788 - val_mDice: 0.7639

Epoch 00036: val_mDice did not improve from 0.76963
Epoch 37/300
 - 27s - loss: 1.0476 - acc: 0.9687 - mDice: 0.7723 - val_loss: 1.0763 - val_acc: 0.9790 - val_mDice: 0.7678

Epoch 00037: val_mDice did not improve from 0.76963
Epoch 38/300
 - 25s - loss: 1.0347 - acc: 0.9689 - mDice: 0.7748 - val_loss: 1.0588 - val_acc: 0.9790 - val_mDice: 0.7686

Epoch 00038: val_mDice did not improve from 0.76963
Epoch 39/300
 - 25s - loss: 1.0290 - acc: 0.9690 - mDice: 0.7761 - val_loss: 1.0964 - val_acc: 0.9788 - val_mDice: 0.7671

Epoch 00039: val_mDice did not improve from 0.76963
Epoch 40/300
 - 26s - loss: 1.0218 - acc: 0.9690 - mDice: 0.7775 - val_loss: 1.0526 - val_acc: 0.9794 - val_mDice: 0.7701

Epoch 00040: val_mDice improved from 0.76963 to 0.77012, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 41/300
 - 26s - loss: 1.0170 - acc: 0.9691 - mDice: 0.7784 - val_loss: 1.0484 - val_acc: 0.9782 - val_mDice: 0.7755

Epoch 00041: val_mDice improved from 0.77012 to 0.77546, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 42/300
 - 25s - loss: 1.0077 - acc: 0.9693 - mDice: 0.7804 - val_loss: 1.0554 - val_acc: 0.9790 - val_mDice: 0.7730

Epoch 00042: val_mDice did not improve from 0.77546
Epoch 43/300
 - 25s - loss: 1.0022 - acc: 0.9693 - mDice: 0.7813 - val_loss: 1.0585 - val_acc: 0.9796 - val_mDice: 0.7736

Epoch 00043: val_mDice did not improve from 0.77546
Epoch 44/300
 - 26s - loss: 0.9922 - acc: 0.9695 - mDice: 0.7835 - val_loss: 1.0585 - val_acc: 0.9787 - val_mDice: 0.7740

Epoch 00044: val_mDice did not improve from 0.77546
Epoch 45/300
 - 27s - loss: 0.9925 - acc: 0.9694 - mDice: 0.7836 - val_loss: 1.0519 - val_acc: 0.9798 - val_mDice: 0.7702

Epoch 00045: val_mDice did not improve from 0.77546
Epoch 46/300
 - 25s - loss: 0.9822 - acc: 0.9696 - mDice: 0.7855 - val_loss: 1.0541 - val_acc: 0.9797 - val_mDice: 0.7771

Epoch 00046: val_mDice improved from 0.77546 to 0.77713, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 47/300
 - 25s - loss: 0.9792 - acc: 0.9696 - mDice: 0.7859 - val_loss: 1.0618 - val_acc: 0.9791 - val_mDice: 0.7747

Epoch 00047: val_mDice did not improve from 0.77713
Epoch 48/300
 - 25s - loss: 0.9730 - acc: 0.9697 - mDice: 0.7873 - val_loss: 1.0323 - val_acc: 0.9799 - val_mDice: 0.7767

Epoch 00048: val_mDice did not improve from 0.77713
Epoch 49/300
 - 27s - loss: 0.9665 - acc: 0.9697 - mDice: 0.7886 - val_loss: 1.0506 - val_acc: 0.9796 - val_mDice: 0.7713

Epoch 00049: val_mDice did not improve from 0.77713
Epoch 50/300
 - 25s - loss: 0.9619 - acc: 0.9698 - mDice: 0.7896 - val_loss: 1.0459 - val_acc: 0.9792 - val_mDice: 0.7798

Epoch 00050: val_mDice improved from 0.77713 to 0.77979, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 51/300
 - 25s - loss: 0.9564 - acc: 0.9699 - mDice: 0.7908 - val_loss: 1.0579 - val_acc: 0.9793 - val_mDice: 0.7715

Epoch 00051: val_mDice did not improve from 0.77979
Epoch 52/300
 - 25s - loss: 0.9525 - acc: 0.9699 - mDice: 0.7915 - val_loss: 1.0716 - val_acc: 0.9793 - val_mDice: 0.7764

Epoch 00052: val_mDice did not improve from 0.77979
Epoch 53/300
 - 26s - loss: 0.9462 - acc: 0.9699 - mDice: 0.7928 - val_loss: 1.0448 - val_acc: 0.9800 - val_mDice: 0.7785

Epoch 00053: val_mDice did not improve from 0.77979
Epoch 54/300
 - 25s - loss: 0.9393 - acc: 0.9700 - mDice: 0.7940 - val_loss: 1.0505 - val_acc: 0.9793 - val_mDice: 0.7811

Epoch 00054: val_mDice improved from 0.77979 to 0.78112, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 55/300
 - 25s - loss: 0.9368 - acc: 0.9701 - mDice: 0.7950 - val_loss: 1.0452 - val_acc: 0.9791 - val_mDice: 0.7789

Epoch 00055: val_mDice did not improve from 0.78112
Epoch 56/300
 - 25s - loss: 0.9320 - acc: 0.9701 - mDice: 0.7960 - val_loss: 1.0505 - val_acc: 0.9792 - val_mDice: 0.7803

Epoch 00056: val_mDice did not improve from 0.78112
Epoch 57/300
 - 26s - loss: 0.9256 - acc: 0.9702 - mDice: 0.7971 - val_loss: 1.0428 - val_acc: 0.9797 - val_mDice: 0.7783

Epoch 00057: val_mDice did not improve from 0.78112
Epoch 58/300
 - 25s - loss: 0.9248 - acc: 0.9701 - mDice: 0.7974 - val_loss: 1.0364 - val_acc: 0.9797 - val_mDice: 0.7823

Epoch 00058: val_mDice improved from 0.78112 to 0.78228, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 59/300
 - 25s - loss: 0.9144 - acc: 0.9703 - mDice: 0.7997 - val_loss: 1.0564 - val_acc: 0.9787 - val_mDice: 0.7838

Epoch 00059: val_mDice improved from 0.78228 to 0.78378, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 60/300
 - 27s - loss: 0.9133 - acc: 0.9703 - mDice: 0.7999 - val_loss: 1.0170 - val_acc: 0.9796 - val_mDice: 0.7857

Epoch 00060: val_mDice improved from 0.78378 to 0.78569, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 61/300
 - 25s - loss: 0.9083 - acc: 0.9703 - mDice: 0.8008 - val_loss: 1.0443 - val_acc: 0.9800 - val_mDice: 0.7848

Epoch 00061: val_mDice did not improve from 0.78569
Epoch 62/300
 - 26s - loss: 0.9059 - acc: 0.9704 - mDice: 0.8014 - val_loss: 1.0442 - val_acc: 0.9799 - val_mDice: 0.7827

Epoch 00062: val_mDice did not improve from 0.78569
Epoch 63/300
 - 26s - loss: 0.9004 - acc: 0.9704 - mDice: 0.8025 - val_loss: 1.0227 - val_acc: 0.9791 - val_mDice: 0.7856

Epoch 00063: val_mDice did not improve from 0.78569
Epoch 64/300
 - 25s - loss: 0.8959 - acc: 0.9705 - mDice: 0.8038 - val_loss: 1.0497 - val_acc: 0.9800 - val_mDice: 0.7816

Epoch 00064: val_mDice did not improve from 0.78569
Epoch 65/300
 - 25s - loss: 0.8949 - acc: 0.9705 - mDice: 0.8039 - val_loss: 1.0731 - val_acc: 0.9796 - val_mDice: 0.7806

Epoch 00065: val_mDice did not improve from 0.78569
Epoch 66/300
 - 26s - loss: 0.8887 - acc: 0.9706 - mDice: 0.8050 - val_loss: 1.0377 - val_acc: 0.9791 - val_mDice: 0.7891

Epoch 00066: val_mDice improved from 0.78569 to 0.78913, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 67/300
 - 26s - loss: 0.8803 - acc: 0.9706 - mDice: 0.8069 - val_loss: 1.0662 - val_acc: 0.9800 - val_mDice: 0.7865

Epoch 00067: val_mDice did not improve from 0.78913
Epoch 68/300
 - 25s - loss: 0.8779 - acc: 0.9707 - mDice: 0.8076 - val_loss: 1.0390 - val_acc: 0.9799 - val_mDice: 0.7864

Epoch 00068: val_mDice did not improve from 0.78913
Epoch 69/300
 - 25s - loss: 0.8780 - acc: 0.9707 - mDice: 0.8076 - val_loss: 1.0434 - val_acc: 0.9802 - val_mDice: 0.7893

Epoch 00069: val_mDice improved from 0.78913 to 0.78926, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 70/300
 - 26s - loss: 0.8734 - acc: 0.9708 - mDice: 0.8086 - val_loss: 1.0119 - val_acc: 0.9802 - val_mDice: 0.7886

Epoch 00070: val_mDice did not improve from 0.78926
Epoch 71/300
 - 26s - loss: 0.8706 - acc: 0.9708 - mDice: 0.8093 - val_loss: 1.0409 - val_acc: 0.9803 - val_mDice: 0.7905

Epoch 00071: val_mDice improved from 0.78926 to 0.79050, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 72/300
 - 25s - loss: 0.8668 - acc: 0.9708 - mDice: 0.8101 - val_loss: 1.0451 - val_acc: 0.9796 - val_mDice: 0.7929

Epoch 00072: val_mDice improved from 0.79050 to 0.79295, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 73/300
 - 26s - loss: 0.8621 - acc: 0.9709 - mDice: 0.8109 - val_loss: 1.0287 - val_acc: 0.9797 - val_mDice: 0.7897

Epoch 00073: val_mDice did not improve from 0.79295
Epoch 74/300
 - 26s - loss: 0.8580 - acc: 0.9709 - mDice: 0.8120 - val_loss: 1.0319 - val_acc: 0.9799 - val_mDice: 0.7938

Epoch 00074: val_mDice improved from 0.79295 to 0.79379, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 75/300
 - 25s - loss: 0.8533 - acc: 0.9709 - mDice: 0.8130 - val_loss: 1.0171 - val_acc: 0.9799 - val_mDice: 0.7911

Epoch 00075: val_mDice did not improve from 0.79379
Epoch 76/300
 - 26s - loss: 0.8509 - acc: 0.9710 - mDice: 0.8134 - val_loss: 1.0477 - val_acc: 0.9804 - val_mDice: 0.7922

Epoch 00076: val_mDice did not improve from 0.79379
Epoch 77/300
 - 26s - loss: 0.8491 - acc: 0.9710 - mDice: 0.8140 - val_loss: 1.0282 - val_acc: 0.9798 - val_mDice: 0.7914

Epoch 00077: val_mDice did not improve from 0.79379
Epoch 78/300
 - 25s - loss: 0.8432 - acc: 0.9710 - mDice: 0.8153 - val_loss: 1.0253 - val_acc: 0.9795 - val_mDice: 0.7968

Epoch 00078: val_mDice improved from 0.79379 to 0.79678, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 79/300
 - 25s - loss: 0.8404 - acc: 0.9711 - mDice: 0.8160 - val_loss: 1.0321 - val_acc: 0.9798 - val_mDice: 0.7965

Epoch 00079: val_mDice did not improve from 0.79678
Epoch 80/300
 - 26s - loss: 0.8382 - acc: 0.9711 - mDice: 0.8162 - val_loss: 1.0327 - val_acc: 0.9804 - val_mDice: 0.7933

Epoch 00080: val_mDice did not improve from 0.79678
Epoch 81/300
 - 26s - loss: 0.8335 - acc: 0.9712 - mDice: 0.8175 - val_loss: 1.0146 - val_acc: 0.9788 - val_mDice: 0.7975

Epoch 00081: val_mDice improved from 0.79678 to 0.79752, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 82/300
 - 25s - loss: 0.8327 - acc: 0.9712 - mDice: 0.8175 - val_loss: 1.0234 - val_acc: 0.9799 - val_mDice: 0.7963

Epoch 00082: val_mDice did not improve from 0.79752
Epoch 83/300
 - 25s - loss: 0.8253 - acc: 0.9713 - mDice: 0.8193 - val_loss: 1.0324 - val_acc: 0.9802 - val_mDice: 0.7994

Epoch 00083: val_mDice improved from 0.79752 to 0.79940, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 84/300
 - 26s - loss: 0.8254 - acc: 0.9713 - mDice: 0.8193 - val_loss: 1.0372 - val_acc: 0.9802 - val_mDice: 0.7945

Epoch 00084: val_mDice did not improve from 0.79940
Epoch 85/300
 - 26s - loss: 0.8221 - acc: 0.9714 - mDice: 0.8201 - val_loss: 1.0129 - val_acc: 0.9798 - val_mDice: 0.8002

Epoch 00085: val_mDice improved from 0.79940 to 0.80019, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 86/300
 - 25s - loss: 0.8173 - acc: 0.9714 - mDice: 0.8212 - val_loss: 1.0411 - val_acc: 0.9799 - val_mDice: 0.7950

Epoch 00086: val_mDice did not improve from 0.80019
Epoch 87/300
 - 25s - loss: 0.8169 - acc: 0.9714 - mDice: 0.8212 - val_loss: 1.0095 - val_acc: 0.9801 - val_mDice: 0.7982

Epoch 00087: val_mDice did not improve from 0.80019
Epoch 88/300
 - 26s - loss: 0.8135 - acc: 0.9715 - mDice: 0.8219 - val_loss: 1.0475 - val_acc: 0.9796 - val_mDice: 0.7928

Epoch 00088: val_mDice did not improve from 0.80019
Epoch 89/300
 - 26s - loss: 0.8086 - acc: 0.9715 - mDice: 0.8233 - val_loss: 1.0360 - val_acc: 0.9809 - val_mDice: 0.7963

Epoch 00089: val_mDice did not improve from 0.80019
Epoch 90/300
 - 26s - loss: 0.8082 - acc: 0.9715 - mDice: 0.8230 - val_loss: 1.0094 - val_acc: 0.9805 - val_mDice: 0.8018

Epoch 00090: val_mDice improved from 0.80019 to 0.80182, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 91/300
 - 26s - loss: 0.8050 - acc: 0.9716 - mDice: 0.8237 - val_loss: 1.0352 - val_acc: 0.9798 - val_mDice: 0.7991

Epoch 00091: val_mDice did not improve from 0.80182
Epoch 92/300
 - 26s - loss: 0.8006 - acc: 0.9716 - mDice: 0.8248 - val_loss: 1.0230 - val_acc: 0.9800 - val_mDice: 0.7966

Epoch 00092: val_mDice did not improve from 0.80182
Epoch 93/300
 - 26s - loss: 0.7980 - acc: 0.9717 - mDice: 0.8253 - val_loss: 1.0382 - val_acc: 0.9801 - val_mDice: 0.7975

Epoch 00093: val_mDice did not improve from 0.80182
Epoch 94/300
 - 26s - loss: 0.7973 - acc: 0.9717 - mDice: 0.8257 - val_loss: 1.0102 - val_acc: 0.9806 - val_mDice: 0.8032

Epoch 00094: val_mDice improved from 0.80182 to 0.80324, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 95/300
 - 26s - loss: 0.7910 - acc: 0.9718 - mDice: 0.8270 - val_loss: 1.0352 - val_acc: 0.9797 - val_mDice: 0.7949

Epoch 00095: val_mDice did not improve from 0.80324
Epoch 96/300
 - 26s - loss: 0.7911 - acc: 0.9718 - mDice: 0.8272 - val_loss: 1.0019 - val_acc: 0.9807 - val_mDice: 0.7996

Epoch 00096: val_mDice did not improve from 0.80324
Epoch 97/300
 - 26s - loss: 0.7891 - acc: 0.9717 - mDice: 0.8275 - val_loss: 1.0205 - val_acc: 0.9793 - val_mDice: 0.8028

Epoch 00097: val_mDice did not improve from 0.80324
Epoch 98/300
 - 26s - loss: 0.7853 - acc: 0.9718 - mDice: 0.8283 - val_loss: 1.0078 - val_acc: 0.9807 - val_mDice: 0.8056

Epoch 00098: val_mDice improved from 0.80324 to 0.80563, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 99/300
 - 26s - loss: 0.7843 - acc: 0.9719 - mDice: 0.8286 - val_loss: 1.0325 - val_acc: 0.9803 - val_mDice: 0.8014

Epoch 00099: val_mDice did not improve from 0.80563
Epoch 100/300
 - 25s - loss: 0.7795 - acc: 0.9718 - mDice: 0.8296 - val_loss: 1.0055 - val_acc: 0.9806 - val_mDice: 0.8051

Epoch 00100: val_mDice did not improve from 0.80563
Epoch 101/300
 - 25s - loss: 0.7748 - acc: 0.9719 - mDice: 0.8308 - val_loss: 1.0068 - val_acc: 0.9807 - val_mDice: 0.8022

Epoch 00101: val_mDice did not improve from 0.80563
Epoch 102/300
 - 27s - loss: 0.7739 - acc: 0.9719 - mDice: 0.8310 - val_loss: 1.0099 - val_acc: 0.9804 - val_mDice: 0.8031

Epoch 00102: val_mDice did not improve from 0.80563
Epoch 103/300
 - 26s - loss: 0.7758 - acc: 0.9719 - mDice: 0.8305 - val_loss: 1.0048 - val_acc: 0.9803 - val_mDice: 0.8023

Epoch 00103: val_mDice did not improve from 0.80563
Epoch 104/300
 - 25s - loss: 0.7712 - acc: 0.9720 - mDice: 0.8316 - val_loss: 1.0378 - val_acc: 0.9799 - val_mDice: 0.8021

Epoch 00104: val_mDice did not improve from 0.80563
Epoch 105/300
 - 26s - loss: 0.7695 - acc: 0.9720 - mDice: 0.8318 - val_loss: 1.0088 - val_acc: 0.9808 - val_mDice: 0.8090

Epoch 00105: val_mDice improved from 0.80563 to 0.80896, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 106/300
 - 26s - loss: 0.7651 - acc: 0.9720 - mDice: 0.8329 - val_loss: 1.0120 - val_acc: 0.9801 - val_mDice: 0.8052

Epoch 00106: val_mDice did not improve from 0.80896
Epoch 107/300
 - 25s - loss: 0.7645 - acc: 0.9720 - mDice: 0.8330 - val_loss: 1.0051 - val_acc: 0.9809 - val_mDice: 0.8081

Epoch 00107: val_mDice did not improve from 0.80896
Epoch 108/300
 - 25s - loss: 0.7636 - acc: 0.9721 - mDice: 0.8332 - val_loss: 1.0036 - val_acc: 0.9807 - val_mDice: 0.8057

Epoch 00108: val_mDice did not improve from 0.80896
Epoch 109/300
 - 26s - loss: 0.7610 - acc: 0.9721 - mDice: 0.8339 - val_loss: 1.0069 - val_acc: 0.9807 - val_mDice: 0.8038

Epoch 00109: val_mDice did not improve from 0.80896
Epoch 110/300
 - 26s - loss: 0.7595 - acc: 0.9720 - mDice: 0.8342 - val_loss: 1.0281 - val_acc: 0.9808 - val_mDice: 0.8067

Epoch 00110: val_mDice did not improve from 0.80896
Epoch 111/300
 - 25s - loss: 0.7575 - acc: 0.9721 - mDice: 0.8345 - val_loss: 1.0097 - val_acc: 0.9806 - val_mDice: 0.8086

Epoch 00111: val_mDice did not improve from 0.80896
Epoch 112/300
 - 26s - loss: 0.7518 - acc: 0.9722 - mDice: 0.8358 - val_loss: 1.0056 - val_acc: 0.9800 - val_mDice: 0.8074

Epoch 00112: val_mDice did not improve from 0.80896
Epoch 113/300
 - 26s - loss: 0.7516 - acc: 0.9722 - mDice: 0.8359 - val_loss: 1.0137 - val_acc: 0.9800 - val_mDice: 0.8051

Epoch 00113: val_mDice did not improve from 0.80896
Epoch 114/300
 - 25s - loss: 0.7501 - acc: 0.9722 - mDice: 0.8363 - val_loss: 0.9847 - val_acc: 0.9810 - val_mDice: 0.8078

Epoch 00114: val_mDice did not improve from 0.80896
Epoch 115/300
 - 26s - loss: 0.7504 - acc: 0.9722 - mDice: 0.8359 - val_loss: 1.0316 - val_acc: 0.9810 - val_mDice: 0.8081

Epoch 00115: val_mDice did not improve from 0.80896
Epoch 116/300
 - 26s - loss: 0.7491 - acc: 0.9722 - mDice: 0.8364 - val_loss: 1.0061 - val_acc: 0.9809 - val_mDice: 0.8064

Epoch 00116: val_mDice did not improve from 0.80896
Epoch 117/300
 - 25s - loss: 0.7475 - acc: 0.9722 - mDice: 0.8369 - val_loss: 1.0170 - val_acc: 0.9806 - val_mDice: 0.8107

Epoch 00117: val_mDice improved from 0.80896 to 0.81066, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 118/300
 - 25s - loss: 0.7465 - acc: 0.9723 - mDice: 0.8371 - val_loss: 1.0149 - val_acc: 0.9808 - val_mDice: 0.8094

Epoch 00118: val_mDice did not improve from 0.81066
Epoch 119/300
 - 27s - loss: 0.7431 - acc: 0.9723 - mDice: 0.8379 - val_loss: 1.0265 - val_acc: 0.9808 - val_mDice: 0.8058

Epoch 00119: val_mDice did not improve from 0.81066
Epoch 120/300
 - 25s - loss: 0.7408 - acc: 0.9723 - mDice: 0.8382 - val_loss: 1.0077 - val_acc: 0.9808 - val_mDice: 0.8092

Epoch 00120: val_mDice did not improve from 0.81066
Epoch 121/300
 - 25s - loss: 0.7374 - acc: 0.9723 - mDice: 0.8389 - val_loss: 0.9900 - val_acc: 0.9807 - val_mDice: 0.8103

Epoch 00121: val_mDice did not improve from 0.81066
Epoch 122/300
 - 25s - loss: 0.7420 - acc: 0.9723 - mDice: 0.8380 - val_loss: 1.0023 - val_acc: 0.9805 - val_mDice: 0.8075

Epoch 00122: val_mDice did not improve from 0.81066
Epoch 123/300
 - 27s - loss: 0.7363 - acc: 0.9724 - mDice: 0.8391 - val_loss: 1.0080 - val_acc: 0.9807 - val_mDice: 0.8108

Epoch 00123: val_mDice improved from 0.81066 to 0.81083, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 124/300
 - 25s - loss: 0.7368 - acc: 0.9724 - mDice: 0.8393 - val_loss: 1.0053 - val_acc: 0.9809 - val_mDice: 0.8084

Epoch 00124: val_mDice did not improve from 0.81083
Epoch 125/300
 - 25s - loss: 0.7329 - acc: 0.9724 - mDice: 0.8401 - val_loss: 0.9927 - val_acc: 0.9805 - val_mDice: 0.8093

Epoch 00125: val_mDice did not improve from 0.81083
Epoch 126/300
 - 27s - loss: 0.7363 - acc: 0.9724 - mDice: 0.8392 - val_loss: 1.0154 - val_acc: 0.9807 - val_mDice: 0.8083

Epoch 00126: val_mDice did not improve from 0.81083
Epoch 127/300
 - 26s - loss: 0.7309 - acc: 0.9724 - mDice: 0.8403 - val_loss: 1.0053 - val_acc: 0.9808 - val_mDice: 0.8100

Epoch 00127: val_mDice did not improve from 0.81083
Epoch 128/300
 - 25s - loss: 0.7331 - acc: 0.9724 - mDice: 0.8400 - val_loss: 1.0121 - val_acc: 0.9810 - val_mDice: 0.8094

Epoch 00128: val_mDice did not improve from 0.81083
Epoch 129/300
 - 26s - loss: 0.7306 - acc: 0.9724 - mDice: 0.8404 - val_loss: 1.0015 - val_acc: 0.9809 - val_mDice: 0.8125

Epoch 00129: val_mDice improved from 0.81083 to 0.81246, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 130/300
 - 26s - loss: 0.7290 - acc: 0.9725 - mDice: 0.8410 - val_loss: 1.0332 - val_acc: 0.9806 - val_mDice: 0.8046

Epoch 00130: val_mDice did not improve from 0.81246
Epoch 131/300
 - 25s - loss: 0.7252 - acc: 0.9725 - mDice: 0.8417 - val_loss: 1.0287 - val_acc: 0.9805 - val_mDice: 0.8067

Epoch 00131: val_mDice did not improve from 0.81246
Epoch 132/300
 - 26s - loss: 0.7256 - acc: 0.9725 - mDice: 0.8416 - val_loss: 1.0137 - val_acc: 0.9806 - val_mDice: 0.8090

Epoch 00132: val_mDice did not improve from 0.81246
Epoch 133/300
 - 27s - loss: 0.7235 - acc: 0.9725 - mDice: 0.8422 - val_loss: 1.0370 - val_acc: 0.9807 - val_mDice: 0.8109

Epoch 00133: val_mDice did not improve from 0.81246
Epoch 134/300
 - 25s - loss: 0.7245 - acc: 0.9725 - mDice: 0.8418 - val_loss: 1.0445 - val_acc: 0.9809 - val_mDice: 0.8099

Epoch 00134: val_mDice did not improve from 0.81246
Epoch 135/300
 - 26s - loss: 0.7228 - acc: 0.9725 - mDice: 0.8423 - val_loss: 1.0063 - val_acc: 0.9811 - val_mDice: 0.8120

Epoch 00135: val_mDice did not improve from 0.81246
Epoch 136/300
 - 27s - loss: 0.7227 - acc: 0.9726 - mDice: 0.8422 - val_loss: 1.0469 - val_acc: 0.9811 - val_mDice: 0.8072

Epoch 00136: val_mDice did not improve from 0.81246
Epoch 137/300
 - 25s - loss: 0.7215 - acc: 0.9726 - mDice: 0.8426 - val_loss: 1.0078 - val_acc: 0.9804 - val_mDice: 0.8107

Epoch 00137: val_mDice did not improve from 0.81246
Epoch 138/300
 - 25s - loss: 0.7191 - acc: 0.9726 - mDice: 0.8431 - val_loss: 1.0397 - val_acc: 0.9805 - val_mDice: 0.8093

Epoch 00138: val_mDice did not improve from 0.81246
Epoch 139/300
 - 26s - loss: 0.7177 - acc: 0.9726 - mDice: 0.8435 - val_loss: 1.0039 - val_acc: 0.9809 - val_mDice: 0.8114

Epoch 00139: val_mDice did not improve from 0.81246
Epoch 140/300
 - 26s - loss: 0.7157 - acc: 0.9726 - mDice: 0.8436 - val_loss: 1.0099 - val_acc: 0.9809 - val_mDice: 0.8111

Epoch 00140: val_mDice did not improve from 0.81246
Epoch 141/300
 - 25s - loss: 0.7142 - acc: 0.9726 - mDice: 0.8442 - val_loss: 1.0411 - val_acc: 0.9805 - val_mDice: 0.8100

Epoch 00141: val_mDice did not improve from 0.81246
Epoch 142/300
 - 25s - loss: 0.7163 - acc: 0.9726 - mDice: 0.8437 - val_loss: 1.0372 - val_acc: 0.9801 - val_mDice: 0.8109

Epoch 00142: val_mDice did not improve from 0.81246
Epoch 143/300
 - 26s - loss: 0.7138 - acc: 0.9727 - mDice: 0.8441 - val_loss: 1.0371 - val_acc: 0.9813 - val_mDice: 0.8126

Epoch 00143: val_mDice improved from 0.81246 to 0.81259, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 144/300
 - 26s - loss: 0.7139 - acc: 0.9727 - mDice: 0.8443 - val_loss: 1.0158 - val_acc: 0.9809 - val_mDice: 0.8119

Epoch 00144: val_mDice did not improve from 0.81259
Epoch 145/300
 - 25s - loss: 0.7141 - acc: 0.9727 - mDice: 0.8442 - val_loss: 1.0184 - val_acc: 0.9804 - val_mDice: 0.8132

Epoch 00145: val_mDice improved from 0.81259 to 0.81316, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 146/300
 - 26s - loss: 0.7127 - acc: 0.9727 - mDice: 0.8444 - val_loss: 1.0057 - val_acc: 0.9802 - val_mDice: 0.8102

Epoch 00146: val_mDice did not improve from 0.81316
Epoch 147/300
 - 26s - loss: 0.7113 - acc: 0.9727 - mDice: 0.8447 - val_loss: 1.0431 - val_acc: 0.9808 - val_mDice: 0.8121

Epoch 00147: val_mDice did not improve from 0.81316
Epoch 148/300
 - 25s - loss: 0.7101 - acc: 0.9727 - mDice: 0.8450 - val_loss: 1.0203 - val_acc: 0.9805 - val_mDice: 0.8095

Epoch 00148: val_mDice did not improve from 0.81316
Epoch 149/300
 - 25s - loss: 0.7089 - acc: 0.9728 - mDice: 0.8451 - val_loss: 1.0381 - val_acc: 0.9814 - val_mDice: 0.8094

Epoch 00149: val_mDice did not improve from 0.81316
Epoch 150/300
 - 27s - loss: 0.7084 - acc: 0.9727 - mDice: 0.8453 - val_loss: 0.9979 - val_acc: 0.9813 - val_mDice: 0.8139

Epoch 00150: val_mDice improved from 0.81316 to 0.81385, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 151/300
 - 25s - loss: 0.7083 - acc: 0.9727 - mDice: 0.8456 - val_loss: 1.0158 - val_acc: 0.9813 - val_mDice: 0.8128

Epoch 00151: val_mDice did not improve from 0.81385
Epoch 152/300
 - 27s - loss: 0.7038 - acc: 0.9728 - mDice: 0.8464 - val_loss: 1.0219 - val_acc: 0.9807 - val_mDice: 0.8112

Epoch 00152: val_mDice did not improve from 0.81385
Epoch 153/300
 - 26s - loss: 0.7042 - acc: 0.9728 - mDice: 0.8462 - val_loss: 1.0347 - val_acc: 0.9812 - val_mDice: 0.8102

Epoch 00153: val_mDice did not improve from 0.81385
Epoch 154/300
 - 27s - loss: 0.7056 - acc: 0.9728 - mDice: 0.8460 - val_loss: 1.0092 - val_acc: 0.9805 - val_mDice: 0.8132

Epoch 00154: val_mDice did not improve from 0.81385
Epoch 155/300
 - 25s - loss: 0.7046 - acc: 0.9728 - mDice: 0.8463 - val_loss: 1.0284 - val_acc: 0.9809 - val_mDice: 0.8106

Epoch 00155: val_mDice did not improve from 0.81385
Epoch 156/300
 - 25s - loss: 0.7052 - acc: 0.9728 - mDice: 0.8462 - val_loss: 1.0240 - val_acc: 0.9805 - val_mDice: 0.8100

Epoch 00156: val_mDice did not improve from 0.81385
Epoch 157/300
 - 27s - loss: 0.7012 - acc: 0.9728 - mDice: 0.8470 - val_loss: 1.0193 - val_acc: 0.9812 - val_mDice: 0.8143

Epoch 00157: val_mDice improved from 0.81385 to 0.81430, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 158/300
 - 25s - loss: 0.7025 - acc: 0.9728 - mDice: 0.8465 - val_loss: 1.0522 - val_acc: 0.9807 - val_mDice: 0.8089

Epoch 00158: val_mDice did not improve from 0.81430
Epoch 159/300
 - 25s - loss: 0.6998 - acc: 0.9728 - mDice: 0.8473 - val_loss: 1.0302 - val_acc: 0.9809 - val_mDice: 0.8137

Epoch 00159: val_mDice did not improve from 0.81430
Epoch 160/300
 - 27s - loss: 0.6984 - acc: 0.9729 - mDice: 0.8476 - val_loss: 1.0288 - val_acc: 0.9811 - val_mDice: 0.8129

Epoch 00160: val_mDice did not improve from 0.81430
Epoch 161/300
 - 27s - loss: 0.6995 - acc: 0.9729 - mDice: 0.8475 - val_loss: 1.0319 - val_acc: 0.9810 - val_mDice: 0.8139

Epoch 00161: val_mDice did not improve from 0.81430
Epoch 162/300
 - 26s - loss: 0.6981 - acc: 0.9729 - mDice: 0.8476 - val_loss: 1.0615 - val_acc: 0.9812 - val_mDice: 0.8102

Epoch 00162: val_mDice did not improve from 0.81430
Epoch 163/300
 - 27s - loss: 0.6974 - acc: 0.9729 - mDice: 0.8479 - val_loss: 1.0164 - val_acc: 0.9808 - val_mDice: 0.8135

Epoch 00163: val_mDice did not improve from 0.81430
Epoch 164/300
 - 27s - loss: 0.6949 - acc: 0.9729 - mDice: 0.8483 - val_loss: 1.0509 - val_acc: 0.9813 - val_mDice: 0.8102

Epoch 00164: val_mDice did not improve from 0.81430
Epoch 165/300
 - 26s - loss: 0.6961 - acc: 0.9729 - mDice: 0.8481 - val_loss: 1.0382 - val_acc: 0.9810 - val_mDice: 0.8115

Epoch 00165: val_mDice did not improve from 0.81430
Epoch 166/300
 - 26s - loss: 0.6944 - acc: 0.9730 - mDice: 0.8486 - val_loss: 1.0383 - val_acc: 0.9808 - val_mDice: 0.8139

Epoch 00166: val_mDice did not improve from 0.81430
Epoch 167/300
 - 25s - loss: 0.6958 - acc: 0.9729 - mDice: 0.8482 - val_loss: 1.0403 - val_acc: 0.9808 - val_mDice: 0.8133

Epoch 00167: val_mDice did not improve from 0.81430
Epoch 168/300
 - 26s - loss: 0.6949 - acc: 0.9730 - mDice: 0.8484 - val_loss: 1.0510 - val_acc: 0.9805 - val_mDice: 0.8150

Epoch 00168: val_mDice improved from 0.81430 to 0.81499, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 169/300
 - 25s - loss: 0.6906 - acc: 0.9730 - mDice: 0.8492 - val_loss: 1.0298 - val_acc: 0.9809 - val_mDice: 0.8134

Epoch 00169: val_mDice did not improve from 0.81499
Epoch 170/300
 - 25s - loss: 0.6928 - acc: 0.9730 - mDice: 0.8486 - val_loss: 1.0319 - val_acc: 0.9811 - val_mDice: 0.8143

Epoch 00170: val_mDice did not improve from 0.81499
Epoch 171/300
 - 26s - loss: 0.6915 - acc: 0.9729 - mDice: 0.8490 - val_loss: 1.0443 - val_acc: 0.9813 - val_mDice: 0.8126

Epoch 00171: val_mDice did not improve from 0.81499
Epoch 172/300
 - 26s - loss: 0.6903 - acc: 0.9730 - mDice: 0.8495 - val_loss: 1.0403 - val_acc: 0.9806 - val_mDice: 0.8150

Epoch 00172: val_mDice improved from 0.81499 to 0.81504, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 173/300
 - 25s - loss: 0.6881 - acc: 0.9730 - mDice: 0.8498 - val_loss: 1.0299 - val_acc: 0.9813 - val_mDice: 0.8127

Epoch 00173: val_mDice did not improve from 0.81504
Epoch 174/300
 - 27s - loss: 0.6897 - acc: 0.9730 - mDice: 0.8496 - val_loss: 1.0455 - val_acc: 0.9813 - val_mDice: 0.8143

Epoch 00174: val_mDice did not improve from 0.81504
Epoch 175/300
 - 25s - loss: 0.6899 - acc: 0.9730 - mDice: 0.8496 - val_loss: 1.0480 - val_acc: 0.9807 - val_mDice: 0.8095

Epoch 00175: val_mDice did not improve from 0.81504
Epoch 176/300
 - 26s - loss: 0.6903 - acc: 0.9730 - mDice: 0.8495 - val_loss: 1.0479 - val_acc: 0.9808 - val_mDice: 0.8098

Epoch 00176: val_mDice did not improve from 0.81504
Epoch 177/300
 - 26s - loss: 0.6874 - acc: 0.9730 - mDice: 0.8501 - val_loss: 1.0534 - val_acc: 0.9808 - val_mDice: 0.8156

Epoch 00177: val_mDice improved from 0.81504 to 0.81564, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 178/300
 - 27s - loss: 0.6848 - acc: 0.9730 - mDice: 0.8506 - val_loss: 1.0353 - val_acc: 0.9808 - val_mDice: 0.8152

Epoch 00178: val_mDice did not improve from 0.81564
Epoch 179/300
 - 26s - loss: 0.6853 - acc: 0.9731 - mDice: 0.8503 - val_loss: 1.0408 - val_acc: 0.9817 - val_mDice: 0.8178

Epoch 00179: val_mDice improved from 0.81564 to 0.81780, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 180/300
 - 26s - loss: 0.6851 - acc: 0.9731 - mDice: 0.8504 - val_loss: 1.0518 - val_acc: 0.9811 - val_mDice: 0.8099

Epoch 00180: val_mDice did not improve from 0.81780
Epoch 181/300
 - 26s - loss: 0.6839 - acc: 0.9731 - mDice: 0.8509 - val_loss: 1.0362 - val_acc: 0.9808 - val_mDice: 0.8130

Epoch 00181: val_mDice did not improve from 0.81780
Epoch 182/300
 - 26s - loss: 0.6846 - acc: 0.9731 - mDice: 0.8506 - val_loss: 1.0292 - val_acc: 0.9802 - val_mDice: 0.8159

Epoch 00182: val_mDice did not improve from 0.81780
Epoch 183/300
 - 25s - loss: 0.6842 - acc: 0.9731 - mDice: 0.8509 - val_loss: 1.0416 - val_acc: 0.9808 - val_mDice: 0.8123

Epoch 00183: val_mDice did not improve from 0.81780
Epoch 184/300
 - 27s - loss: 0.6862 - acc: 0.9731 - mDice: 0.8503 - val_loss: 1.0451 - val_acc: 0.9808 - val_mDice: 0.8136

Epoch 00184: val_mDice did not improve from 0.81780
Epoch 185/300
 - 26s - loss: 0.6811 - acc: 0.9731 - mDice: 0.8515 - val_loss: 1.0500 - val_acc: 0.9814 - val_mDice: 0.8140

Epoch 00185: val_mDice did not improve from 0.81780
Epoch 186/300
 - 26s - loss: 0.6804 - acc: 0.9731 - mDice: 0.8518 - val_loss: 1.0541 - val_acc: 0.9814 - val_mDice: 0.8104

Epoch 00186: val_mDice did not improve from 0.81780
Epoch 187/300
 - 26s - loss: 0.6800 - acc: 0.9731 - mDice: 0.8517 - val_loss: 1.0512 - val_acc: 0.9811 - val_mDice: 0.8176

Epoch 00187: val_mDice did not improve from 0.81780
Epoch 188/300
 - 25s - loss: 0.6804 - acc: 0.9732 - mDice: 0.8517 - val_loss: 1.0389 - val_acc: 0.9811 - val_mDice: 0.8163

Epoch 00188: val_mDice did not improve from 0.81780
Epoch 189/300
 - 26s - loss: 0.6804 - acc: 0.9731 - mDice: 0.8516 - val_loss: 1.0476 - val_acc: 0.9812 - val_mDice: 0.8157

Epoch 00189: val_mDice did not improve from 0.81780
Epoch 190/300
 - 26s - loss: 0.6818 - acc: 0.9731 - mDice: 0.8514 - val_loss: 1.0462 - val_acc: 0.9807 - val_mDice: 0.8168

Epoch 00190: val_mDice did not improve from 0.81780
Epoch 191/300
 - 25s - loss: 0.6773 - acc: 0.9732 - mDice: 0.8523 - val_loss: 1.0434 - val_acc: 0.9816 - val_mDice: 0.8148

Epoch 00191: val_mDice did not improve from 0.81780
Epoch 192/300
 - 26s - loss: 0.6793 - acc: 0.9731 - mDice: 0.8520 - val_loss: 1.0345 - val_acc: 0.9813 - val_mDice: 0.8116

Epoch 00192: val_mDice did not improve from 0.81780
Epoch 193/300
 - 26s - loss: 0.6757 - acc: 0.9732 - mDice: 0.8527 - val_loss: 1.0313 - val_acc: 0.9815 - val_mDice: 0.8119

Epoch 00193: val_mDice did not improve from 0.81780
Epoch 194/300
 - 25s - loss: 0.6768 - acc: 0.9732 - mDice: 0.8523 - val_loss: 1.0319 - val_acc: 0.9815 - val_mDice: 0.8124

Epoch 00194: val_mDice did not improve from 0.81780
Epoch 195/300
 - 27s - loss: 0.6751 - acc: 0.9732 - mDice: 0.8529 - val_loss: 1.0482 - val_acc: 0.9805 - val_mDice: 0.8152

Epoch 00195: val_mDice did not improve from 0.81780
Epoch 196/300
 - 25s - loss: 0.6748 - acc: 0.9732 - mDice: 0.8529 - val_loss: 1.0434 - val_acc: 0.9812 - val_mDice: 0.8134

Epoch 00196: val_mDice did not improve from 0.81780
Epoch 197/300
 - 26s - loss: 0.6765 - acc: 0.9732 - mDice: 0.8525 - val_loss: 1.0502 - val_acc: 0.9809 - val_mDice: 0.8162

Epoch 00197: val_mDice did not improve from 0.81780
Epoch 198/300
 - 27s - loss: 0.6748 - acc: 0.9732 - mDice: 0.8528 - val_loss: 1.0530 - val_acc: 0.9807 - val_mDice: 0.8154

Epoch 00198: val_mDice did not improve from 0.81780
Epoch 199/300
 - 26s - loss: 0.6730 - acc: 0.9732 - mDice: 0.8534 - val_loss: 1.0496 - val_acc: 0.9814 - val_mDice: 0.8165

Epoch 00199: val_mDice did not improve from 0.81780
Epoch 200/300
 - 27s - loss: 0.6745 - acc: 0.9732 - mDice: 0.8530 - val_loss: 1.0497 - val_acc: 0.9812 - val_mDice: 0.8143

Epoch 00200: val_mDice did not improve from 0.81780
Epoch 201/300
 - 26s - loss: 0.6736 - acc: 0.9732 - mDice: 0.8531 - val_loss: 1.0548 - val_acc: 0.9809 - val_mDice: 0.8129

Epoch 00201: val_mDice did not improve from 0.81780
Epoch 202/300
 - 26s - loss: 0.6731 - acc: 0.9732 - mDice: 0.8532 - val_loss: 1.0562 - val_acc: 0.9806 - val_mDice: 0.8139

Epoch 00202: val_mDice did not improve from 0.81780
Epoch 203/300
 - 25s - loss: 0.6737 - acc: 0.9732 - mDice: 0.8531 - val_loss: 1.0389 - val_acc: 0.9812 - val_mDice: 0.8162

Epoch 00203: val_mDice did not improve from 0.81780
Epoch 204/300
 - 27s - loss: 0.6707 - acc: 0.9733 - mDice: 0.8537 - val_loss: 1.0808 - val_acc: 0.9814 - val_mDice: 0.8143

Epoch 00204: val_mDice did not improve from 0.81780
Epoch 205/300
 - 25s - loss: 0.6708 - acc: 0.9733 - mDice: 0.8538 - val_loss: 1.0584 - val_acc: 0.9815 - val_mDice: 0.8145

Epoch 00205: val_mDice did not improve from 0.81780
Epoch 206/300
 - 27s - loss: 0.6696 - acc: 0.9733 - mDice: 0.8539 - val_loss: 1.0619 - val_acc: 0.9804 - val_mDice: 0.8139

Epoch 00206: val_mDice did not improve from 0.81780
Epoch 207/300
 - 25s - loss: 0.6710 - acc: 0.9733 - mDice: 0.8536 - val_loss: 1.0693 - val_acc: 0.9811 - val_mDice: 0.8102

Epoch 00207: val_mDice did not improve from 0.81780
Epoch 208/300
 - 26s - loss: 0.6689 - acc: 0.9733 - mDice: 0.8541 - val_loss: 1.0805 - val_acc: 0.9804 - val_mDice: 0.8104

Epoch 00208: val_mDice did not improve from 0.81780
Epoch 209/300
 - 26s - loss: 0.6689 - acc: 0.9733 - mDice: 0.8542 - val_loss: 1.0336 - val_acc: 0.9815 - val_mDice: 0.8139

Epoch 00209: val_mDice did not improve from 0.81780
Restoring model weights from the end of the best epoch
Epoch 00209: early stopping
{'val_loss': [5.737552668801092, 3.8931450512790513, 2.37307113712827, 1.807543199804001, 1.5203393704023846, 1.411769027869186, 1.3130519143935875, 1.3088356373808714, 1.2775403158526428, 1.2253226384337212, 1.2252969756486756, 1.1881884286189959, 1.1851991049434683, 1.1957638048958066, 1.1818766305861448, 1.1285670169208506, 1.1799658687755805, 1.163109898986213, 1.1239568824717785, 1.1023405362935392, 1.119525774187279, 1.0961628540538526, 1.118183489214557, 1.1097871741846281, 1.0962668240384603, 1.0848862839918354, 1.0913736382352028, 1.0891405122979874, 1.0816015741527605, 1.0671812981000475, 1.0940612568168104, 1.0810887097055337, 1.0606663650284751, 1.0679269860415133, 1.0482573534357107, 1.0953763646903483, 1.0763441498124537, 1.0588391624351796, 1.0964045500503903, 1.052601260229657, 1.0483899924164288, 1.0553539876150122, 1.058508165167589, 1.0584516878287278, 1.0519264806553015, 1.054059847796529, 1.0618385288124554, 1.032315273067025, 1.0506331486944993, 1.0458781861672293, 1.0578649122601862, 1.071578878090964, 1.044790446339257, 1.0504871842521775, 1.0452343881234971, 1.0504647252429768, 1.0427824363557652, 1.0363536374430664, 1.0564346784866547, 1.0169803394374612, 1.044283314832275, 1.0442491659799653, 1.0226660179128126, 1.0496878866990127, 1.073087158018759, 1.0376600758262593, 1.0661580785716145, 1.0389695154971104, 1.0434107993105803, 1.01186834016458, 1.0408602769638826, 1.0451316212308848, 1.0287127700128538, 1.0319015886536382, 1.017083413990604, 1.047687933922652, 1.02820717167561, 1.0252718979947806, 1.0320971971655981, 1.0327447640246372, 1.0145955515243048, 1.0233661477930307, 1.0323780064842614, 1.037162030413616, 1.0129010782090977, 1.0411125201542055, 1.009509017157429, 1.0475267156146741, 1.035964402561657, 1.0093832073605542, 1.035209921835177, 1.0230111978385068, 1.0382343621790304, 1.0102286708585406, 1.0351968183458795, 1.001897489563652, 1.0205191247073544, 1.0078356560378585, 1.0325299720353527, 1.005492711423361, 1.0068097663470437, 1.00992898153295, 1.0048043537223694, 1.0377867643988195, 1.0087572953194013, 1.012037283402126, 1.0050924590057144, 1.0036397960776813, 1.0069291940472875, 1.0280751336647462, 1.0096525961569198, 1.0055797006836675, 1.013693433863836, 0.9847294202169341, 1.031644767847547, 1.0060876530377434, 1.0170338722649692, 1.0149089307483345, 1.0265388341067336, 1.007671636521083, 0.9899894593051113, 1.002301843597935, 1.0080027123536712, 1.0053341192813665, 0.9926830238952369, 1.0154419372706087, 1.0053319570678818, 1.012144408976047, 1.0015468636170841, 1.0332164910011425, 1.0287174240985528, 1.0137274617260494, 1.0370392155144461, 1.0444598120419548, 1.0062665186154611, 1.0469094490753537, 1.0078240045344682, 1.0396894197681876, 1.0039153904613167, 1.0098607121117296, 1.04106185033996, 1.037242506007109, 1.0370775715747491, 1.015765421000851, 1.0183516982779142, 1.0056811514554418, 1.0430613376972755, 1.0202975824134841, 1.038127125042813, 0.9979477393815723, 1.0157869410012015, 1.0218553970484408, 1.0347358782387786, 1.0092107762561322, 1.0283734936705793, 1.0240125333487673, 1.0192505634522395, 1.052180445152343, 1.0301770071363199, 1.0288117907168786, 1.0318759433623985, 1.0614747290871056, 1.0163755569809978, 1.050891488004862, 1.0381864186749516, 1.03833743002796, 1.0402828778659103, 1.0510345572746491, 1.0298134167081232, 1.0319280184425663, 1.0443045427803415, 1.0403008150928679, 1.0299169074462462, 1.0454625689501502, 1.0480102331022387, 1.0478772819565974, 1.0533783992061716, 1.0353109827150568, 1.0408389173408803, 1.0517558497368555, 1.0362224734939884, 1.0292324615488573, 1.0416031699817503, 1.045091188016801, 1.050029517896146, 1.054076574913018, 1.0512288903100628, 1.0389168503414348, 1.047610482767303, 1.046173212503088, 1.0433924116443036, 1.0345309307579416, 1.0312672059439607, 1.031909229361529, 1.0482262250409184, 1.043388780370119, 1.0502082707592808, 1.0530181421336893, 1.0495933717499717, 1.049747600811018, 1.0547654752362592, 1.0562458751700254, 1.0389339637882051, 1.0807604611653225, 1.0584056547111282, 1.0619301211435892, 1.0693448138781716, 1.0804793118173501, 1.033592785703696], 'val_acc': [0.9091761321719795, 0.9309173287113438, 0.9518941384208224, 0.965690875095307, 0.9684443845690239, 0.972106524427243, 0.9731623675995007, 0.9739461972759562, 0.9747322708734938, 0.9749923075020628, 0.975261684461302, 0.9759550968247265, 0.976673552147743, 0.9773598739677657, 0.9759984332773514, 0.977294866984255, 0.9764647040719098, 0.9772731934155228, 0.9780921695102497, 0.9767124203470763, 0.977766005351799, 0.9780230435210497, 0.9784822071164271, 0.9766332081834964, 0.9781489539858746, 0.9777693686669656, 0.9785326474161266, 0.9786862000849209, 0.9782180644715817, 0.9790430028115927, 0.9790048852746223, 0.9782565506355205, 0.9785337646103911, 0.978841243288848, 0.9789895631097951, 0.9787889413129676, 0.9790392626986981, 0.9790127443932062, 0.9788068868154381, 0.9793807455651161, 0.9781979125497211, 0.9790418922167881, 0.9796310687316533, 0.9787030105850608, 0.9797521052335394, 0.979722608686122, 0.9791192145255412, 0.9799124081021663, 0.9795768868525124, 0.9792451293900059, 0.9792910779716679, 0.9792959441828603, 0.9799945846802322, 0.9792985459413176, 0.9791166079484306, 0.9791902082666153, 0.9797252202913924, 0.9796796427460253, 0.9786731225744492, 0.979593330296984, 0.9799647051546402, 0.9799475160759656, 0.9791341650255535, 0.9800424112795946, 0.9796097770935622, 0.9791341678538934, 0.9800364410730573, 0.9799037945500996, 0.9801724341506489, 0.9801757973610622, 0.9802628426644002, 0.9795985678587312, 0.9796956978699025, 0.9799176294271472, 0.9799299756546221, 0.980407430438459, 0.979825338915069, 0.979499917457728, 0.9797592169371138, 0.9803846436560887, 0.9788240627999465, 0.979890355535886, 0.9802180187144891, 0.9801926037758222, 0.9797820025671974, 0.9799303157886847, 0.9801033091042289, 0.9796172576336115, 0.980872949732628, 0.9804750541601533, 0.9797902229800166, 0.9800431701127171, 0.9801421653616826, 0.9805609912780131, 0.979653851847657, 0.9807242499713529, 0.979289216609747, 0.9807455567986768, 0.9802934821754014, 0.9805609788123669, 0.9806827741473756, 0.9803909962122805, 0.9803420485427803, 0.9799120211433652, 0.9808154143851335, 0.9800947229975346, 0.9808736873008246, 0.980665587582781, 0.9806655823451145, 0.9807743218535908, 0.9805658427189858, 0.9800005619052424, 0.9800233514111993, 0.9809678587636964, 0.9810358372849195, 0.9808621069249454, 0.9805673352444318, 0.9808113042834773, 0.9807859027532366, 0.980780681847269, 0.9806700672541855, 0.9805400587343374, 0.9807205035732585, 0.9809286160712083, 0.9805277271723286, 0.9807160447477666, 0.9807619964720286, 0.9810380939859078, 0.9809181673455531, 0.9806185228543877, 0.9804709415444172, 0.9806215126191794, 0.9806659711894754, 0.9809084499028948, 0.9811064622942718, 0.9810956265050623, 0.9804320971240896, 0.9805381919252433, 0.9809058240511714, 0.98091816126986, 0.9804507547396977, 0.9801066734669288, 0.9812529023167119, 0.9809076964121921, 0.9804444229246653, 0.9801500069864605, 0.9807631145043197, 0.9804978370666504, 0.9814180467794985, 0.9812637569615208, 0.9813067079218913, 0.9806891322554938, 0.9811695805752424, 0.9805467886120238, 0.9809099368764144, 0.9804933630519257, 0.9812009807001727, 0.9807272340794648, 0.9809383345613999, 0.9811266259485054, 0.9810466924534951, 0.9811976270223125, 0.980756760062568, 0.9812629998044515, 0.9809872792978069, 0.9808243892314354, 0.9808426913142414, 0.9805363266874491, 0.9809334777780073, 0.9810784384739211, 0.9812891438262953, 0.9806088098113692, 0.981295497953787, 0.9813310052472803, 0.9807283554638626, 0.980754155580524, 0.9807504002783964, 0.9808060778255832, 0.9816971515519757, 0.9810683497854612, 0.980765353082982, 0.9801963365559838, 0.9807870264422076, 0.9807702146850278, 0.9813597654835411, 0.981368361960815, 0.9811023459074157, 0.9811173017498479, 0.9812402032800215, 0.9806670879647267, 0.9815600227387802, 0.9813093257076082, 0.981458033639643, 0.9815181830017344, 0.9804959671149563, 0.9812450665581205, 0.9808636062593578, 0.9807003500800979, 0.981398991939263, 0.9811669905491579, 0.9808688383739317, 0.9806058155421842, 0.9812390995989365, 0.9813668634644293, 0.981476334779669, 0.9804171356249778, 0.9811400880084515, 0.9804488871973303, 0.9814871691023319], 'val_mDice': [0.055005362895702015, 0.20867230443313378, 0.46805075282371733, 0.6118467195591315, 0.6748083608850235, 0.6962652047195836, 0.7177265492809678, 0.7254519330596253, 0.7304365281899491, 0.7388715297769369, 0.7430173521092152, 0.7447723810199275, 0.7471483700723766, 0.7441717093983937, 0.7510051802717319, 0.7537202233798893, 0.7515001730675857, 0.753532044078847, 0.7562423035214362, 0.7639927310977125, 0.7569745407163154, 0.7622978859081838, 0.7569941942218318, 0.7613619826799537, 0.757441918125052, 0.7650496548005692, 0.7648061498187757, 0.7643037211077913, 0.7680785871767202, 0.7658290429358323, 0.7625466084438385, 0.7640347327834064, 0.7696318805532003, 0.768632154473102, 0.7681435636770118, 0.763939842817444, 0.7678218765711323, 0.7685979881269861, 0.7670653283281779, 0.7701241596092868, 0.775462774798824, 0.7730010618015417, 0.7736423006166683, 0.7740384715303177, 0.7702207078204633, 0.7771345968824699, 0.7747281330960077, 0.7767244923093826, 0.7713026069170142, 0.7797876935851595, 0.7714580865233142, 0.7763888925994846, 0.7785238104042562, 0.7811150115068433, 0.7788989868650118, 0.7802709473038391, 0.7782739277254718, 0.7822823564281363, 0.7837842876756128, 0.7856882178930071, 0.7847689391230028, 0.782710264248672, 0.7855785943711788, 0.7815532511483178, 0.7805689003429849, 0.7891314443469257, 0.7865091113926865, 0.7864082289077277, 0.7892568827932455, 0.7885676431739687, 0.7904950310140586, 0.7929469026454933, 0.7896534653874818, 0.7937942585123863, 0.7910519693773534, 0.7922054802596254, 0.7914365246132514, 0.7967806691025598, 0.7964504145360789, 0.7932908786411654, 0.797519083391803, 0.796263849169592, 0.79939740267705, 0.7945062031016827, 0.800191772633571, 0.7950164952261377, 0.7982182610642512, 0.7928169782425691, 0.7963174235841721, 0.8018235135790753, 0.7990528129316172, 0.7965546475562982, 0.7974625902351888, 0.8032439255756317, 0.7949187004503341, 0.7995510080367694, 0.8027963817433859, 0.8056262179502075, 0.8013859855269715, 0.8051101646021087, 0.8022398373573651, 0.8030906832909542, 0.8023423775637716, 0.8020876487864341, 0.8089598770300827, 0.8051561863015951, 0.8080750806469909, 0.8056833237042955, 0.8038250176475003, 0.8066820984146507, 0.8085931422211793, 0.8073503933388655, 0.8050886959308899, 0.8078065104978994, 0.8081098099375023, 0.8063669498021238, 0.8106578551822052, 0.8093513796115801, 0.8058223832261164, 0.8092421368681064, 0.8103396220031229, 0.807540974633765, 0.8108280672968377, 0.8083855305489002, 0.8093364958394391, 0.8083114682685302, 0.8100385321255099, 0.8094321619228235, 0.8124567982601575, 0.8045680936694355, 0.8067312316022983, 0.80904935994341, 0.8108862512769515, 0.8098747783679325, 0.8120117707076517, 0.8072194707414597, 0.8106614939986297, 0.8093315016196776, 0.8113640601270438, 0.8110574881934114, 0.8099846030161544, 0.8109366461137058, 0.812590751895167, 0.8118583425905667, 0.8131619867834349, 0.8102337505360688, 0.8121124767880029, 0.809493562563442, 0.8093660342881885, 0.8138545300084803, 0.8128087351946504, 0.8112004016949967, 0.8102485089184739, 0.8131640428817963, 0.810591073258271, 0.8100472510594265, 0.8142994903093482, 0.8089017084487083, 0.8136656726391328, 0.812914461787849, 0.813885350952249, 0.8102114179641375, 0.8134955354231314, 0.8102106284382892, 0.8114559503766481, 0.8139341594045736, 0.8132839452193785, 0.8149914890265841, 0.8133789544993838, 0.814281837278175, 0.8125762432447008, 0.8150372437098323, 0.8127432039207231, 0.8143117964162977, 0.8095055082141829, 0.8098467233310894, 0.8156404997007709, 0.8151894918854081, 0.8177977113187418, 0.8098870658287893, 0.8130229055776746, 0.8158998605656079, 0.8123334598038444, 0.8135589644024787, 0.8140007821034463, 0.8103596432975809, 0.8175731156748083, 0.8162828459681023, 0.8157384940316681, 0.8168172258065329, 0.814844002413624, 0.8115648410441796, 0.8118703456461325, 0.8124044450598986, 0.8152122212629536, 0.8133616202325938, 0.8162264371379189, 0.8153590061333561, 0.8165008437235451, 0.8142869545830993, 0.8128780011342992, 0.8138576343734151, 0.8162214508794104, 0.814290421080296, 0.814453031036263, 0.8138698604488205, 0.8101950161067379, 0.8103721866708229, 0.8139007405782207], 'loss': [40.158972461884346, 5.682263122687887, 3.859720549845718, 2.8914327337219805, 2.4048531609772734, 2.148640753758415, 1.9654039363845246, 1.8499493550464783, 1.743227173983196, 1.6540389579841388, 1.5845080094742767, 1.5255484712195262, 1.4756081722791863, 1.4375137772607394, 1.3986814877244331, 1.3705241496151055, 1.3380790260464297, 1.313149360980261, 1.2826725310602831, 1.2619003737094592, 1.2486998225894994, 1.2313729729063767, 1.2123146223515582, 1.1963576202477526, 1.1751061705738841, 1.1660951082752404, 1.15206952913557, 1.140947417661328, 1.1234499300727847, 1.1137863057625923, 1.0965437902057305, 1.0917776437447875, 1.080580655371595, 1.0735333721804863, 1.0632814652642248, 1.058573355879795, 1.0476165699056528, 1.0346848359645975, 1.028972721095054, 1.0218231564564935, 1.0170245664144077, 1.0077110445197663, 1.0021542546661648, 0.9922448474851782, 0.9924649045791452, 0.9821848874542999, 0.9791944373668419, 0.9730294189391454, 0.9665231905593755, 0.9619121533066258, 0.9564284691932511, 0.9525073968910029, 0.9462350534418498, 0.9392903178118897, 0.9368468859818302, 0.9319725865044968, 0.9256181609264036, 0.9248193339279017, 0.9143948936989128, 0.9132704828209153, 0.9082966975012493, 0.9059340066731255, 0.90035140641256, 0.8959211583532497, 0.894880641287235, 0.8886833638785188, 0.8803053364516876, 0.8779188645341353, 0.8780308600898886, 0.8734436806528121, 0.8706050824911448, 0.8667655054770984, 0.8621023003651039, 0.8579643053525192, 0.8532888787297045, 0.8508604131697121, 0.8490547142129115, 0.8432173796853352, 0.8404270286745072, 0.8382214049491241, 0.8335135399524366, 0.8327158413747555, 0.825261591269214, 0.8254137368658385, 0.8221464932435808, 0.817343289740198, 0.8168995464959758, 0.8134671748809321, 0.8085898754251278, 0.8081831722307274, 0.8049632321395833, 0.8005597824497471, 0.7980341868721889, 0.797340212332741, 0.7909849556731468, 0.7911401249359217, 0.7890540699037091, 0.785274662790202, 0.7842804663170866, 0.7794739922581618, 0.7748433073905638, 0.7738708462201501, 0.7758094741323143, 0.7712102026147744, 0.7695012452449888, 0.765122144832434, 0.764470544739546, 0.7636476982000412, 0.7610036516776293, 0.7594942355376714, 0.7575243610985644, 0.7517594787688268, 0.7515788766021704, 0.7501203883732699, 0.7503768496361948, 0.7491400448522836, 0.7474807070249593, 0.7465317584831062, 0.7431193656814842, 0.7408015580597488, 0.737439495792423, 0.7419894980703973, 0.7362799772732236, 0.7368221150497553, 0.7328867578919211, 0.736287195416403, 0.7308550604270057, 0.733074673723367, 0.7305898910217655, 0.7289702219737745, 0.7251518342084742, 0.7256437586847762, 0.7234756647475646, 0.7244602846326013, 0.7228421702411825, 0.7227025118596324, 0.7215454238517301, 0.7191135859454646, 0.7177471016146961, 0.7156767168808617, 0.7141667137711837, 0.7162530202191535, 0.7137593642093893, 0.7138587299365593, 0.7140929732599374, 0.7127194465508513, 0.7113082005251612, 0.7100849648461681, 0.7088826168052, 0.7083789657546988, 0.7082938817380557, 0.7037628345440069, 0.7041911256432707, 0.7055946114672658, 0.7045816002140575, 0.705177870616418, 0.7011778065755271, 0.7024580957989023, 0.69980193477417, 0.6984343875558944, 0.6994916087343699, 0.6981101059138544, 0.697352785300095, 0.694870105159762, 0.6961308819923335, 0.6944264606826949, 0.6957704451254393, 0.6949099186163149, 0.6905587779819309, 0.6928419936741732, 0.6914770177989533, 0.6902558264473917, 0.6880883655369441, 0.6897455421837171, 0.6898635989388272, 0.6902539165236199, 0.6874055603878001, 0.6847661501624841, 0.6852509224788573, 0.6850674333188922, 0.6838510311679927, 0.6846264902271518, 0.6842215532301704, 0.6861805290255212, 0.6811371794476926, 0.6804368635136651, 0.6800098791827218, 0.6804082953682736, 0.680426603993318, 0.6818248881354713, 0.6772845137533835, 0.6793246588456325, 0.6757107493016051, 0.6768424625539748, 0.6751435916018015, 0.6748223558572954, 0.6765027282510488, 0.6747784284789216, 0.6729802546302708, 0.6745462557472932, 0.6735574082503722, 0.6731006817866041, 0.6737232656929059, 0.6706933805863466, 0.6708381073304268, 0.6696291064290394, 0.6710312173432658, 0.6689217552151991, 0.6688905636315545], 'acc': [0.8279464717268806, 0.9028772563994558, 0.9236918474880284, 0.9424765400585138, 0.9503635174374678, 0.9541512672005239, 0.9567893497339522, 0.9583747039161122, 0.9597585004610995, 0.9609227283066577, 0.9618696307633257, 0.9625914961821024, 0.9632402263597876, 0.9637062219067396, 0.9642479919948129, 0.9645558898134948, 0.9651347156631875, 0.9654540693920096, 0.965816280267228, 0.966088914492069, 0.9662022526206239, 0.9664867756399245, 0.9667187328457646, 0.9668934136864572, 0.9671615863187126, 0.9672596470368154, 0.9674490576967201, 0.9675857838138073, 0.9677730235280295, 0.9679594415554337, 0.9681299612954185, 0.9681693738296716, 0.9682934314745925, 0.9684045116546608, 0.9685541364886393, 0.9686680510913857, 0.9687378138962165, 0.9688954221560991, 0.9690336531922308, 0.9690497760071763, 0.9691432137043221, 0.9692505511560364, 0.9692717951621067, 0.9694686227953192, 0.9694084551954574, 0.9695585642275624, 0.9695822275295021, 0.969674831025584, 0.9696911889085783, 0.9697765290068245, 0.9698761724590638, 0.9699166883196554, 0.9699283049652642, 0.9700292026076941, 0.9700694477682319, 0.97009163880455, 0.9701707712849639, 0.9701269295505845, 0.9702895100094773, 0.9702834450726444, 0.9703044027208556, 0.9703504769222935, 0.9704043996435462, 0.9704534726626175, 0.9704597003866313, 0.9705718603403397, 0.9706443817684739, 0.9706541391817051, 0.9706912410108668, 0.9707553872890078, 0.9707602860913064, 0.9707930664322432, 0.9708534680802967, 0.9709051840528857, 0.9709268190031545, 0.9709880526955742, 0.9709903336928298, 0.9710403253091346, 0.9710967257700642, 0.9711183675953693, 0.9711948508951386, 0.9712153161803679, 0.9712949110249689, 0.9713048074207178, 0.9713628143154617, 0.9714310885909507, 0.9714204769964565, 0.9714632594803189, 0.9715355366226963, 0.9715277277753204, 0.9715655134966159, 0.9715788546064936, 0.9716531330413352, 0.9716674464559178, 0.9717653347551898, 0.9717648138692062, 0.9717287163952566, 0.9717891165525191, 0.9718628172473467, 0.9718353989907669, 0.9719497291942553, 0.9719159332136882, 0.9719079534952645, 0.9719745930149093, 0.9719711378922394, 0.9720367932168462, 0.9720484207149337, 0.9720589506068807, 0.9720562964979268, 0.9720455323328197, 0.9720958687987843, 0.97218705064115, 0.9721799139245564, 0.9722319190686101, 0.9721850353196525, 0.9721955008976149, 0.9722218182575156, 0.9722542036108207, 0.9722917744392394, 0.9723257405409593, 0.9723265020952065, 0.9722652422104584, 0.9723528505277516, 0.9723663209345049, 0.9724148786168149, 0.9723905298479621, 0.9724244346022816, 0.972427196306153, 0.9724255783329564, 0.9724580289211171, 0.9725090492612181, 0.9725274906941458, 0.9725440396713531, 0.9725225889912538, 0.9725413211764246, 0.9725782635719353, 0.9725954973561481, 0.972591616218196, 0.9725992657009114, 0.9726305986487399, 0.9726353182621568, 0.9726489375770365, 0.972686669116927, 0.9726865528202292, 0.9726933887899807, 0.9726919636867479, 0.9727031784066976, 0.9727333800601081, 0.972757973510662, 0.97272155310498, 0.97273842793551, 0.972802562707264, 0.9727997593872261, 0.9727638643728962, 0.9727821200868575, 0.9727851777922363, 0.9728007455319908, 0.972800787256142, 0.9728418495951299, 0.9728738913885943, 0.9728668157614373, 0.9728652114213295, 0.9729040241116672, 0.9729383573379246, 0.9729169796375952, 0.972951578887562, 0.9729213048273013, 0.9729517948122942, 0.9729588533148517, 0.9729645766805651, 0.9729446141308635, 0.9729680116520597, 0.9730165931960247, 0.9730080119839168, 0.9729881142881243, 0.9729974115298611, 0.9730116300617441, 0.9730177149697774, 0.9730534491376545, 0.9730773477086146, 0.9730959636750768, 0.9730903674255446, 0.9730755194678927, 0.973083262618478, 0.9731214047468133, 0.9731293946968028, 0.9731073763732743, 0.9731533702099775, 0.9731273812860375, 0.9731049394908702, 0.9731531133229873, 0.9731373558538284, 0.973162580862852, 0.9731505551495854, 0.973202623806736, 0.9732159966911597, 0.9731524613163839, 0.9731961534977271, 0.9732421888516105, 0.9732249181635708, 0.9732270062278714, 0.9732414820456887, 0.9732377774059956, 0.9732531843922841, 0.9732500510195122, 0.9732799932662857, 0.9732532904064234, 0.9732878153868011, 0.9732819109184742], 'mDice': [0.03494185459851667, 0.13528306499385287, 0.3096238973741112, 0.4565864517256692, 0.5396890303705966, 0.5837476776336233, 0.6140532938098998, 0.6338208208931908, 0.6517356028614896, 0.6673696823907447, 0.6786741073577539, 0.6884354271902411, 0.6968571309336394, 0.7029804258280327, 0.7097724298995068, 0.7144049398612679, 0.7199554766954014, 0.7238475961711817, 0.7289463323085659, 0.7329073235310832, 0.7353539349874308, 0.7382399160010928, 0.7416869006047256, 0.7443292322525242, 0.7486576098247752, 0.7499252193305604, 0.7524025145537372, 0.7547207184259271, 0.7577185125729139, 0.7595009864003529, 0.7627784782420418, 0.7642077649163406, 0.7659012979352716, 0.7674562896385652, 0.769394737473972, 0.770354907325851, 0.7723253588240674, 0.774796523638589, 0.7761121893749762, 0.7775011552513399, 0.7783850848473802, 0.7803958946982673, 0.7813144946073132, 0.7834822865918516, 0.783596155672979, 0.7854931082910779, 0.7859308072265756, 0.7873341309502935, 0.7886030924175641, 0.7895601515584945, 0.7907773525064206, 0.7915198016278271, 0.7927753078272224, 0.7939616712408741, 0.7949573072631971, 0.7959981691308785, 0.7971027581964464, 0.7974497155048702, 0.7996770741955023, 0.7999341000782803, 0.8008489145179633, 0.8014476867886183, 0.8025186433956971, 0.8038007610877623, 0.803880936213021, 0.8049811679963814, 0.8069002178329495, 0.8075601191796892, 0.8075774781363557, 0.8085743036929329, 0.8093030464246657, 0.810101856241576, 0.8109022608089385, 0.812038966657459, 0.8129869314092172, 0.8134028904091627, 0.8139637591620348, 0.8153280593819662, 0.8160319546587508, 0.8162456155093265, 0.8174825848921646, 0.817476236306093, 0.8192949104150704, 0.819253779496696, 0.820052161165623, 0.8211825197448872, 0.821191298080363, 0.8219089242923806, 0.8233288434117989, 0.8230304494038975, 0.8237359210287137, 0.8248297662933197, 0.8252969498597383, 0.8257063855870993, 0.8270300531908056, 0.827152167837091, 0.8274923345324053, 0.8283360759149253, 0.8286101879156156, 0.8295600862053355, 0.8307511812397209, 0.8309550349890307, 0.83050762181325, 0.8316103735643678, 0.8318343420380477, 0.8328805464778212, 0.832972258039932, 0.8331854781112951, 0.8338593540971061, 0.8341686017145766, 0.834540091960037, 0.8358293877328974, 0.835860882718012, 0.8362851573682912, 0.8358878851548804, 0.8364018300454178, 0.836871244288146, 0.8370950327270626, 0.8378596148939162, 0.8382016644103016, 0.8389438367935007, 0.8379580152694067, 0.8391006411990656, 0.8392946762237388, 0.8400609339677143, 0.8392339947089162, 0.840281923453981, 0.8400150706157201, 0.8403785729419062, 0.8409616969760906, 0.8416738588750815, 0.8416153817122587, 0.8422155196104836, 0.8418491341214518, 0.8423396148071406, 0.8422220234637904, 0.8426004730337106, 0.8431490394310949, 0.8434506188604721, 0.8436391358916433, 0.844192158254402, 0.84365275865304, 0.8441298209956773, 0.8443274489856979, 0.8442224411424252, 0.8444150865098969, 0.8447320214407799, 0.8450241478812526, 0.8451009273085115, 0.8452532207094173, 0.8455824696611527, 0.846377710914295, 0.8462224662420909, 0.846032469875289, 0.8463093341671702, 0.8461530158224706, 0.8469905824895462, 0.846548996026992, 0.8472921819201198, 0.8475760513010457, 0.8474992583576815, 0.8475957506706392, 0.8478970922423588, 0.8483470585642461, 0.8481176126033861, 0.8486195579009953, 0.8481866506498117, 0.8483764261395754, 0.849196243691676, 0.8486474274533137, 0.8490100252982876, 0.849545852688393, 0.8498291744870776, 0.8495778251285792, 0.849597431742175, 0.8495275668016612, 0.8501054098211245, 0.850559022299903, 0.8502995067811158, 0.8504085258841004, 0.8509114546808453, 0.8505765589666585, 0.8509209256972228, 0.8503135761619064, 0.8515135638457433, 0.8517667871495569, 0.8517269507117254, 0.8517375773131161, 0.8515709238211706, 0.8514321012019656, 0.8523070361328547, 0.8520260698679775, 0.8526679748054071, 0.8522840035195067, 0.8529003127598749, 0.8529053078666738, 0.8524970031097763, 0.8528352491473234, 0.8533623517834422, 0.8530376123065804, 0.8531060620184772, 0.8531563362941595, 0.853117077803313, 0.8536942987249804, 0.8538376801591425, 0.8539005871370055, 0.853597913053074, 0.85411071582971, 0.8541751395869547]}
predicting test subjects:   0%|          | 0/15 [00:00<?, ?it/s]predicting test subjects:   7%|▋         | 1/15 [00:02<00:28,  2.06s/it]predicting test subjects:  13%|█▎        | 2/15 [00:03<00:25,  1.95s/it]predicting test subjects:  20%|██        | 3/15 [00:05<00:23,  1.96s/it]predicting test subjects:  27%|██▋       | 4/15 [00:07<00:21,  1.95s/it]predicting test subjects:  33%|███▎      | 5/15 [00:09<00:20,  2.04s/it]predicting test subjects:  40%|████      | 6/15 [00:12<00:19,  2.13s/it]predicting test subjects:  47%|████▋     | 7/15 [00:13<00:15,  1.92s/it]predicting test subjects:  53%|█████▎    | 8/15 [00:16<00:14,  2.06s/it]predicting test subjects:  60%|██████    | 9/15 [00:18<00:12,  2.05s/it]predicting test subjects:  67%|██████▋   | 10/15 [00:19<00:09,  1.90s/it]predicting test subjects:  73%|███████▎  | 11/15 [00:21<00:07,  1.85s/it]predicting test subjects:  80%|████████  | 12/15 [00:23<00:05,  1.90s/it]predicting test subjects:  87%|████████▋ | 13/15 [00:25<00:03,  1.99s/it]predicting test subjects:  93%|█████████▎| 14/15 [00:27<00:01,  1.95s/it]predicting test subjects: 100%|██████████| 15/15 [00:29<00:00,  1.95s/it]
predicting train subjects:   0%|          | 0/532 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/532 [00:02<19:50,  2.24s/it]predicting train subjects:   0%|          | 2/532 [00:03<18:21,  2.08s/it]predicting train subjects:   1%|          | 3/532 [00:05<17:39,  2.00s/it]predicting train subjects:   1%|          | 4/532 [00:07<17:04,  1.94s/it]predicting train subjects:   1%|          | 5/532 [00:09<16:37,  1.89s/it]predicting train subjects:   1%|          | 6/532 [00:11<15:59,  1.82s/it]predicting train subjects:   1%|▏         | 7/532 [00:12<16:06,  1.84s/it]predicting train subjects:   2%|▏         | 8/532 [00:14<15:38,  1.79s/it]predicting train subjects:   2%|▏         | 9/532 [00:16<16:29,  1.89s/it]predicting train subjects:   2%|▏         | 10/532 [00:18<15:56,  1.83s/it]predicting train subjects:   2%|▏         | 11/532 [00:19<15:04,  1.74s/it]predicting train subjects:   2%|▏         | 12/532 [00:22<16:20,  1.88s/it]predicting train subjects:   2%|▏         | 13/532 [00:23<15:21,  1.78s/it]predicting train subjects:   3%|▎         | 14/532 [00:25<14:29,  1.68s/it]predicting train subjects:   3%|▎         | 15/532 [00:26<14:38,  1.70s/it]predicting train subjects:   3%|▎         | 16/532 [00:28<15:20,  1.78s/it]predicting train subjects:   3%|▎         | 17/532 [00:30<14:44,  1.72s/it]predicting train subjects:   3%|▎         | 18/532 [00:32<15:33,  1.82s/it]predicting train subjects:   4%|▎         | 19/532 [00:33<14:38,  1.71s/it]predicting train subjects:   4%|▍         | 20/532 [00:35<14:54,  1.75s/it]predicting train subjects:   4%|▍         | 21/532 [00:37<15:51,  1.86s/it]predicting train subjects:   4%|▍         | 22/532 [00:39<15:35,  1.83s/it]predicting train subjects:   4%|▍         | 23/532 [00:41<15:38,  1.84s/it]predicting train subjects:   5%|▍         | 24/532 [00:42<14:43,  1.74s/it]predicting train subjects:   5%|▍         | 25/532 [00:45<15:45,  1.87s/it]predicting train subjects:   5%|▍         | 26/532 [00:46<15:08,  1.80s/it]predicting train subjects:   5%|▌         | 27/532 [00:49<16:47,  1.99s/it]predicting train subjects:   5%|▌         | 28/532 [00:50<16:06,  1.92s/it]predicting train subjects:   5%|▌         | 29/532 [00:53<16:37,  1.98s/it]predicting train subjects:   6%|▌         | 30/532 [00:54<15:32,  1.86s/it]predicting train subjects:   6%|▌         | 31/532 [00:56<15:12,  1.82s/it]predicting train subjects:   6%|▌         | 32/532 [00:58<14:54,  1.79s/it]predicting train subjects:   6%|▌         | 33/532 [00:59<14:13,  1.71s/it]predicting train subjects:   6%|▋         | 34/532 [01:01<15:28,  1.87s/it]predicting train subjects:   7%|▋         | 35/532 [01:03<15:08,  1.83s/it]predicting train subjects:   7%|▋         | 36/532 [01:05<15:18,  1.85s/it]predicting train subjects:   7%|▋         | 37/532 [01:07<15:15,  1.85s/it]predicting train subjects:   7%|▋         | 38/532 [01:09<16:10,  1.97s/it]predicting train subjects:   7%|▋         | 39/532 [01:11<15:33,  1.89s/it]predicting train subjects:   8%|▊         | 40/532 [01:12<14:55,  1.82s/it]predicting train subjects:   8%|▊         | 41/532 [01:14<15:05,  1.84s/it]predicting train subjects:   8%|▊         | 42/532 [01:16<15:05,  1.85s/it]predicting train subjects:   8%|▊         | 43/532 [01:18<14:40,  1.80s/it]predicting train subjects:   8%|▊         | 44/532 [01:19<13:47,  1.70s/it]predicting train subjects:   8%|▊         | 45/532 [01:21<13:35,  1.67s/it]predicting train subjects:   9%|▊         | 46/532 [01:23<13:52,  1.71s/it]predicting train subjects:   9%|▉         | 47/532 [01:25<14:50,  1.84s/it]predicting train subjects:   9%|▉         | 48/532 [01:27<14:57,  1.85s/it]predicting train subjects:   9%|▉         | 49/532 [01:28<14:21,  1.78s/it]predicting train subjects:   9%|▉         | 50/532 [01:31<15:08,  1.89s/it]predicting train subjects:  10%|▉         | 51/532 [01:32<14:54,  1.86s/it]predicting train subjects:  10%|▉         | 52/532 [01:34<14:41,  1.84s/it]predicting train subjects:  10%|▉         | 53/532 [01:36<14:12,  1.78s/it]predicting train subjects:  10%|█         | 54/532 [01:38<14:51,  1.87s/it]predicting train subjects:  10%|█         | 55/532 [01:40<14:55,  1.88s/it]predicting train subjects:  11%|█         | 56/532 [01:42<14:49,  1.87s/it]predicting train subjects:  11%|█         | 57/532 [01:43<14:43,  1.86s/it]predicting train subjects:  11%|█         | 58/532 [01:45<14:33,  1.84s/it]predicting train subjects:  11%|█         | 59/532 [01:48<15:31,  1.97s/it]predicting train subjects:  11%|█▏        | 60/532 [01:49<14:29,  1.84s/it]predicting train subjects:  11%|█▏        | 61/532 [01:51<13:47,  1.76s/it]predicting train subjects:  12%|█▏        | 62/532 [01:53<14:33,  1.86s/it]predicting train subjects:  12%|█▏        | 63/532 [01:55<15:10,  1.94s/it]predicting train subjects:  12%|█▏        | 64/532 [01:56<14:18,  1.84s/it]predicting train subjects:  12%|█▏        | 65/532 [01:58<14:20,  1.84s/it]predicting train subjects:  12%|█▏        | 66/532 [02:01<15:34,  2.00s/it]predicting train subjects:  13%|█▎        | 67/532 [02:03<15:53,  2.05s/it]predicting train subjects:  13%|█▎        | 68/532 [02:05<15:44,  2.04s/it]predicting train subjects:  13%|█▎        | 69/532 [02:07<15:14,  1.98s/it]predicting train subjects:  13%|█▎        | 70/532 [02:09<14:51,  1.93s/it]predicting train subjects:  13%|█▎        | 71/532 [02:10<14:03,  1.83s/it]predicting train subjects:  14%|█▎        | 72/532 [02:12<13:28,  1.76s/it]predicting train subjects:  14%|█▎        | 73/532 [02:14<14:05,  1.84s/it]predicting train subjects:  14%|█▍        | 74/532 [02:16<15:23,  2.02s/it]predicting train subjects:  14%|█▍        | 75/532 [02:19<17:25,  2.29s/it]predicting train subjects:  14%|█▍        | 76/532 [02:21<16:06,  2.12s/it]predicting train subjects:  14%|█▍        | 77/532 [02:23<15:30,  2.04s/it]predicting train subjects:  15%|█▍        | 78/532 [02:25<15:06,  2.00s/it]predicting train subjects:  15%|█▍        | 79/532 [02:26<14:46,  1.96s/it]predicting train subjects:  15%|█▌        | 80/532 [02:28<14:48,  1.97s/it]predicting train subjects:  15%|█▌        | 81/532 [02:30<14:28,  1.93s/it]predicting train subjects:  15%|█▌        | 82/532 [02:32<14:23,  1.92s/it]predicting train subjects:  16%|█▌        | 83/532 [02:34<13:33,  1.81s/it]predicting train subjects:  16%|█▌        | 84/532 [02:35<13:01,  1.74s/it]predicting train subjects:  16%|█▌        | 85/532 [02:37<12:35,  1.69s/it]predicting train subjects:  16%|█▌        | 86/532 [02:39<12:38,  1.70s/it]predicting train subjects:  16%|█▋        | 87/532 [02:40<12:30,  1.69s/it]predicting train subjects:  17%|█▋        | 88/532 [02:42<12:25,  1.68s/it]predicting train subjects:  17%|█▋        | 89/532 [02:44<12:42,  1.72s/it]predicting train subjects:  17%|█▋        | 90/532 [02:45<12:38,  1.72s/it]predicting train subjects:  17%|█▋        | 91/532 [02:47<12:47,  1.74s/it]predicting train subjects:  17%|█▋        | 92/532 [02:49<13:12,  1.80s/it]predicting train subjects:  17%|█▋        | 93/532 [02:51<13:13,  1.81s/it]predicting train subjects:  18%|█▊        | 94/532 [02:53<13:16,  1.82s/it]predicting train subjects:  18%|█▊        | 95/532 [02:55<13:54,  1.91s/it]predicting train subjects:  18%|█▊        | 96/532 [02:57<14:15,  1.96s/it]predicting train subjects:  18%|█▊        | 97/532 [02:59<14:35,  2.01s/it]predicting train subjects:  18%|█▊        | 98/532 [03:01<14:39,  2.03s/it]predicting train subjects:  19%|█▊        | 99/532 [03:03<14:53,  2.06s/it]predicting train subjects:  19%|█▉        | 100/532 [03:06<15:05,  2.10s/it]predicting train subjects:  19%|█▉        | 101/532 [03:07<13:53,  1.93s/it]predicting train subjects:  19%|█▉        | 102/532 [03:09<13:12,  1.84s/it]predicting train subjects:  19%|█▉        | 103/532 [03:10<12:36,  1.76s/it]predicting train subjects:  20%|█▉        | 104/532 [03:12<12:16,  1.72s/it]predicting train subjects:  20%|█▉        | 105/532 [03:14<11:56,  1.68s/it]predicting train subjects:  20%|█▉        | 106/532 [03:15<11:38,  1.64s/it]predicting train subjects:  20%|██        | 107/532 [03:17<11:28,  1.62s/it]predicting train subjects:  20%|██        | 108/532 [03:18<11:38,  1.65s/it]predicting train subjects:  20%|██        | 109/532 [03:20<11:29,  1.63s/it]predicting train subjects:  21%|██        | 110/532 [03:22<11:25,  1.63s/it]predicting train subjects:  21%|██        | 111/532 [03:23<11:24,  1.63s/it]predicting train subjects:  21%|██        | 112/532 [03:25<11:17,  1.61s/it]predicting train subjects:  21%|██        | 113/532 [03:27<11:58,  1.72s/it]predicting train subjects:  21%|██▏       | 114/532 [03:29<12:15,  1.76s/it]predicting train subjects:  22%|██▏       | 115/532 [03:31<12:40,  1.82s/it]predicting train subjects:  22%|██▏       | 116/532 [03:32<12:44,  1.84s/it]predicting train subjects:  22%|██▏       | 117/532 [03:34<12:48,  1.85s/it]predicting train subjects:  22%|██▏       | 118/532 [03:36<12:47,  1.85s/it]predicting train subjects:  22%|██▏       | 119/532 [03:38<12:40,  1.84s/it]predicting train subjects:  23%|██▎       | 120/532 [03:40<12:32,  1.83s/it]predicting train subjects:  23%|██▎       | 121/532 [03:42<12:21,  1.80s/it]predicting train subjects:  23%|██▎       | 122/532 [03:43<12:20,  1.81s/it]predicting train subjects:  23%|██▎       | 123/532 [03:45<12:12,  1.79s/it]predicting train subjects:  23%|██▎       | 124/532 [03:47<12:21,  1.82s/it]predicting train subjects:  23%|██▎       | 125/532 [03:49<12:32,  1.85s/it]predicting train subjects:  24%|██▎       | 126/532 [03:51<12:55,  1.91s/it]predicting train subjects:  24%|██▍       | 127/532 [03:53<13:08,  1.95s/it]predicting train subjects:  24%|██▍       | 128/532 [03:55<13:03,  1.94s/it]predicting train subjects:  24%|██▍       | 129/532 [03:57<13:00,  1.94s/it]predicting train subjects:  24%|██▍       | 130/532 [03:59<13:02,  1.95s/it]predicting train subjects:  25%|██▍       | 131/532 [04:01<13:34,  2.03s/it]predicting train subjects:  25%|██▍       | 132/532 [04:03<13:52,  2.08s/it]predicting train subjects:  25%|██▌       | 133/532 [04:05<14:03,  2.11s/it]predicting train subjects:  25%|██▌       | 134/532 [04:08<14:13,  2.14s/it]predicting train subjects:  25%|██▌       | 135/532 [04:10<14:29,  2.19s/it]predicting train subjects:  26%|██▌       | 136/532 [04:12<14:31,  2.20s/it]predicting train subjects:  26%|██▌       | 137/532 [04:14<14:41,  2.23s/it]predicting train subjects:  26%|██▌       | 138/532 [04:17<14:35,  2.22s/it]predicting train subjects:  26%|██▌       | 139/532 [04:19<14:35,  2.23s/it]predicting train subjects:  26%|██▋       | 140/532 [04:21<14:52,  2.28s/it]predicting train subjects:  27%|██▋       | 141/532 [04:24<14:51,  2.28s/it]predicting train subjects:  27%|██▋       | 142/532 [04:26<14:44,  2.27s/it]predicting train subjects:  27%|██▋       | 143/532 [04:27<13:23,  2.07s/it]predicting train subjects:  27%|██▋       | 144/532 [04:29<12:38,  1.95s/it]predicting train subjects:  27%|██▋       | 145/532 [04:31<12:06,  1.88s/it]predicting train subjects:  27%|██▋       | 146/532 [04:33<11:43,  1.82s/it]predicting train subjects:  28%|██▊       | 147/532 [04:34<11:26,  1.78s/it]predicting train subjects:  28%|██▊       | 148/532 [04:36<11:07,  1.74s/it]predicting train subjects:  28%|██▊       | 149/532 [04:38<11:11,  1.75s/it]predicting train subjects:  28%|██▊       | 150/532 [04:39<11:12,  1.76s/it]predicting train subjects:  28%|██▊       | 151/532 [04:41<11:13,  1.77s/it]predicting train subjects:  29%|██▊       | 152/532 [04:43<11:10,  1.76s/it]predicting train subjects:  29%|██▉       | 153/532 [04:45<11:05,  1.76s/it]predicting train subjects:  29%|██▉       | 154/532 [04:46<11:11,  1.78s/it]predicting train subjects:  29%|██▉       | 155/532 [04:49<12:18,  1.96s/it]predicting train subjects:  29%|██▉       | 156/532 [04:51<12:53,  2.06s/it]predicting train subjects:  30%|██▉       | 157/532 [04:53<13:21,  2.14s/it]predicting train subjects:  30%|██▉       | 158/532 [04:56<13:35,  2.18s/it]predicting train subjects:  30%|██▉       | 159/532 [04:58<13:49,  2.22s/it]predicting train subjects:  30%|███       | 160/532 [05:01<14:10,  2.29s/it]predicting train subjects:  30%|███       | 161/532 [05:02<13:03,  2.11s/it]predicting train subjects:  30%|███       | 162/532 [05:04<12:14,  1.98s/it]predicting train subjects:  31%|███       | 163/532 [05:06<11:45,  1.91s/it]predicting train subjects:  31%|███       | 164/532 [05:07<11:19,  1.85s/it]predicting train subjects:  31%|███       | 165/532 [05:09<11:03,  1.81s/it]predicting train subjects:  31%|███       | 166/532 [05:11<10:50,  1.78s/it]predicting train subjects:  31%|███▏      | 167/532 [05:13<11:12,  1.84s/it]predicting train subjects:  32%|███▏      | 168/532 [05:15<11:07,  1.83s/it]predicting train subjects:  32%|███▏      | 169/532 [05:16<11:06,  1.84s/it]predicting train subjects:  32%|███▏      | 170/532 [05:18<10:55,  1.81s/it]predicting train subjects:  32%|███▏      | 171/532 [05:20<10:55,  1.82s/it]predicting train subjects:  32%|███▏      | 172/532 [05:22<10:55,  1.82s/it]predicting train subjects:  33%|███▎      | 173/532 [05:24<10:41,  1.79s/it]predicting train subjects:  33%|███▎      | 174/532 [05:25<10:39,  1.79s/it]predicting train subjects:  33%|███▎      | 175/532 [05:27<10:25,  1.75s/it]predicting train subjects:  33%|███▎      | 176/532 [05:29<10:13,  1.72s/it]predicting train subjects:  33%|███▎      | 177/532 [05:30<09:59,  1.69s/it]predicting train subjects:  33%|███▎      | 178/532 [05:32<09:55,  1.68s/it]predicting train subjects:  34%|███▎      | 179/532 [05:34<10:17,  1.75s/it]predicting train subjects:  34%|███▍      | 180/532 [05:36<10:14,  1.75s/it]predicting train subjects:  34%|███▍      | 181/532 [05:37<10:09,  1.74s/it]predicting train subjects:  34%|███▍      | 182/532 [05:39<10:06,  1.73s/it]predicting train subjects:  34%|███▍      | 183/532 [05:41<09:58,  1.72s/it]predicting train subjects:  35%|███▍      | 184/532 [05:42<10:04,  1.74s/it]predicting train subjects:  35%|███▍      | 185/532 [05:44<09:43,  1.68s/it]predicting train subjects:  35%|███▍      | 186/532 [05:46<09:25,  1.63s/it]predicting train subjects:  35%|███▌      | 187/532 [05:47<09:12,  1.60s/it]predicting train subjects:  35%|███▌      | 188/532 [05:49<09:07,  1.59s/it]predicting train subjects:  36%|███▌      | 189/532 [05:50<09:02,  1.58s/it]predicting train subjects:  36%|███▌      | 190/532 [05:52<09:00,  1.58s/it]predicting train subjects:  36%|███▌      | 191/532 [05:54<10:15,  1.81s/it]predicting train subjects:  36%|███▌      | 192/532 [05:56<11:02,  1.95s/it]predicting train subjects:  36%|███▋      | 193/532 [05:59<11:27,  2.03s/it]predicting train subjects:  36%|███▋      | 194/532 [06:01<11:44,  2.08s/it]predicting train subjects:  37%|███▋      | 195/532 [06:03<12:06,  2.16s/it]predicting train subjects:  37%|███▋      | 196/532 [06:05<12:16,  2.19s/it]predicting train subjects:  37%|███▋      | 197/532 [06:07<11:49,  2.12s/it]predicting train subjects:  37%|███▋      | 198/532 [06:09<11:32,  2.07s/it]predicting train subjects:  37%|███▋      | 199/532 [06:11<11:19,  2.04s/it]predicting train subjects:  38%|███▊      | 200/532 [06:13<11:05,  2.01s/it]predicting train subjects:  38%|███▊      | 201/532 [06:15<11:03,  2.00s/it]predicting train subjects:  38%|███▊      | 202/532 [06:17<11:03,  2.01s/it]predicting train subjects:  38%|███▊      | 203/532 [06:19<10:20,  1.89s/it]predicting train subjects:  38%|███▊      | 204/532 [06:21<10:07,  1.85s/it]predicting train subjects:  39%|███▊      | 205/532 [06:22<09:41,  1.78s/it]predicting train subjects:  39%|███▊      | 206/532 [06:24<09:20,  1.72s/it]predicting train subjects:  39%|███▉      | 207/532 [06:26<09:17,  1.72s/it]predicting train subjects:  39%|███▉      | 208/532 [06:27<09:04,  1.68s/it]predicting train subjects:  39%|███▉      | 209/532 [06:29<08:37,  1.60s/it]predicting train subjects:  39%|███▉      | 210/532 [06:30<08:21,  1.56s/it]predicting train subjects:  40%|███▉      | 211/532 [06:31<08:07,  1.52s/it]predicting train subjects:  40%|███▉      | 212/532 [06:33<07:58,  1.49s/it]predicting train subjects:  40%|████      | 213/532 [06:34<07:54,  1.49s/it]predicting train subjects:  40%|████      | 214/532 [06:36<07:45,  1.46s/it]predicting train subjects:  40%|████      | 215/532 [06:38<08:42,  1.65s/it]predicting train subjects:  41%|████      | 216/532 [06:40<09:21,  1.78s/it]predicting train subjects:  41%|████      | 217/532 [06:42<09:50,  1.88s/it]predicting train subjects:  41%|████      | 218/532 [06:44<10:02,  1.92s/it]predicting train subjects:  41%|████      | 219/532 [06:46<10:11,  1.95s/it]predicting train subjects:  41%|████▏     | 220/532 [06:48<10:25,  2.01s/it]predicting train subjects:  42%|████▏     | 221/532 [06:50<09:32,  1.84s/it]predicting train subjects:  42%|████▏     | 222/532 [06:51<08:58,  1.74s/it]predicting train subjects:  42%|████▏     | 223/532 [06:53<08:33,  1.66s/it]predicting train subjects:  42%|████▏     | 224/532 [06:54<08:06,  1.58s/it]predicting train subjects:  42%|████▏     | 225/532 [06:55<07:45,  1.52s/it]predicting train subjects:  42%|████▏     | 226/532 [06:57<07:27,  1.46s/it]predicting train subjects:  43%|████▎     | 227/532 [06:58<07:20,  1.44s/it]predicting train subjects:  43%|████▎     | 228/532 [07:00<07:15,  1.43s/it]predicting train subjects:  43%|████▎     | 229/532 [07:01<07:05,  1.40s/it]predicting train subjects:  43%|████▎     | 230/532 [07:02<07:00,  1.39s/it]predicting train subjects:  43%|████▎     | 231/532 [07:04<07:04,  1.41s/it]predicting train subjects:  44%|████▎     | 232/532 [07:05<07:03,  1.41s/it]predicting train subjects:  44%|████▍     | 233/532 [07:07<07:21,  1.48s/it]predicting train subjects:  44%|████▍     | 234/532 [07:08<07:26,  1.50s/it]predicting train subjects:  44%|████▍     | 235/532 [07:10<07:34,  1.53s/it]predicting train subjects:  44%|████▍     | 236/532 [07:11<07:37,  1.55s/it]predicting train subjects:  45%|████▍     | 237/532 [07:13<07:38,  1.55s/it]predicting train subjects:  45%|████▍     | 238/532 [07:15<07:42,  1.57s/it]predicting train subjects:  45%|████▍     | 239/532 [07:16<08:04,  1.65s/it]predicting train subjects:  45%|████▌     | 240/532 [07:18<08:13,  1.69s/it]predicting train subjects:  45%|████▌     | 241/532 [07:20<08:17,  1.71s/it]predicting train subjects:  45%|████▌     | 242/532 [07:22<08:13,  1.70s/it]predicting train subjects:  46%|████▌     | 243/532 [07:24<08:22,  1.74s/it]predicting train subjects:  46%|████▌     | 244/532 [07:25<08:27,  1.76s/it]predicting train subjects:  46%|████▌     | 245/532 [07:27<07:56,  1.66s/it]predicting train subjects:  46%|████▌     | 246/532 [07:28<07:27,  1.57s/it]predicting train subjects:  46%|████▋     | 247/532 [07:30<07:17,  1.54s/it]predicting train subjects:  47%|████▋     | 248/532 [07:31<07:09,  1.51s/it]predicting train subjects:  47%|████▋     | 249/532 [07:32<06:58,  1.48s/it]predicting train subjects:  47%|████▋     | 250/532 [07:34<06:54,  1.47s/it]predicting train subjects:  47%|████▋     | 251/532 [07:35<06:56,  1.48s/it]predicting train subjects:  47%|████▋     | 252/532 [07:37<06:58,  1.50s/it]predicting train subjects:  48%|████▊     | 253/532 [07:38<07:02,  1.51s/it]predicting train subjects:  48%|████▊     | 254/532 [07:40<06:57,  1.50s/it]predicting train subjects:  48%|████▊     | 255/532 [07:41<06:52,  1.49s/it]predicting train subjects:  48%|████▊     | 256/532 [07:43<06:45,  1.47s/it]predicting train subjects:  48%|████▊     | 257/532 [07:45<07:29,  1.63s/it]predicting train subjects:  48%|████▊     | 258/532 [07:47<07:53,  1.73s/it]predicting train subjects:  49%|████▊     | 259/532 [07:49<08:05,  1.78s/it]predicting train subjects:  49%|████▉     | 260/532 [07:51<08:09,  1.80s/it]predicting train subjects:  49%|████▉     | 261/532 [07:52<08:10,  1.81s/it]predicting train subjects:  49%|████▉     | 262/532 [07:54<08:17,  1.84s/it]predicting train subjects:  49%|████▉     | 263/532 [07:56<07:37,  1.70s/it]predicting train subjects:  50%|████▉     | 264/532 [07:57<07:08,  1.60s/it]predicting train subjects:  50%|████▉     | 265/532 [07:58<06:50,  1.54s/it]predicting train subjects:  50%|█████     | 266/532 [08:00<06:34,  1.48s/it]predicting train subjects:  50%|█████     | 267/532 [08:01<06:30,  1.47s/it]predicting train subjects:  50%|█████     | 268/532 [08:03<06:18,  1.43s/it]predicting train subjects:  51%|█████     | 269/532 [08:04<06:41,  1.53s/it]predicting train subjects:  51%|█████     | 270/532 [08:06<06:52,  1.57s/it]predicting train subjects:  51%|█████     | 271/532 [08:08<06:59,  1.61s/it]predicting train subjects:  51%|█████     | 272/532 [08:09<07:07,  1.64s/it]predicting train subjects:  51%|█████▏    | 273/532 [08:11<07:07,  1.65s/it]predicting train subjects:  52%|█████▏    | 274/532 [08:13<07:07,  1.66s/it]predicting train subjects:  52%|█████▏    | 275/532 [08:15<07:38,  1.78s/it]predicting train subjects:  52%|█████▏    | 276/532 [08:17<07:58,  1.87s/it]predicting train subjects:  52%|█████▏    | 277/532 [08:19<08:23,  1.97s/it]predicting train subjects:  52%|█████▏    | 278/532 [08:21<08:30,  2.01s/it]predicting train subjects:  52%|█████▏    | 279/532 [08:23<08:33,  2.03s/it]predicting train subjects:  53%|█████▎    | 280/532 [08:25<08:37,  2.05s/it]predicting train subjects:  53%|█████▎    | 281/532 [08:27<08:33,  2.05s/it]predicting train subjects:  53%|█████▎    | 282/532 [08:30<08:34,  2.06s/it]predicting train subjects:  53%|█████▎    | 283/532 [08:31<08:21,  2.01s/it]predicting train subjects:  53%|█████▎    | 284/532 [08:33<08:20,  2.02s/it]predicting train subjects:  54%|█████▎    | 285/532 [08:35<08:17,  2.01s/it]predicting train subjects:  54%|█████▍    | 286/532 [08:37<08:13,  2.01s/it]predicting train subjects:  54%|█████▍    | 287/532 [08:39<07:37,  1.87s/it]predicting train subjects:  54%|█████▍    | 288/532 [08:40<07:09,  1.76s/it]predicting train subjects:  54%|█████▍    | 289/532 [08:42<06:51,  1.69s/it]predicting train subjects:  55%|█████▍    | 290/532 [08:44<06:36,  1.64s/it]predicting train subjects:  55%|█████▍    | 291/532 [08:45<06:22,  1.59s/it]predicting train subjects:  55%|█████▍    | 292/532 [08:47<06:20,  1.59s/it]predicting train subjects:  55%|█████▌    | 293/532 [08:48<06:29,  1.63s/it]predicting train subjects:  55%|█████▌    | 294/532 [08:50<06:39,  1.68s/it]predicting train subjects:  55%|█████▌    | 295/532 [08:52<06:39,  1.69s/it]predicting train subjects:  56%|█████▌    | 296/532 [08:54<06:44,  1.71s/it]predicting train subjects:  56%|█████▌    | 297/532 [08:55<06:43,  1.72s/it]predicting train subjects:  56%|█████▌    | 298/532 [08:57<06:38,  1.70s/it]predicting train subjects:  56%|█████▌    | 299/532 [08:58<06:14,  1.61s/it]predicting train subjects:  56%|█████▋    | 300/532 [09:00<05:55,  1.53s/it]predicting train subjects:  57%|█████▋    | 301/532 [09:01<05:40,  1.48s/it]predicting train subjects:  57%|█████▋    | 302/532 [09:02<05:30,  1.44s/it]predicting train subjects:  57%|█████▋    | 303/532 [09:04<05:26,  1.43s/it]predicting train subjects:  57%|█████▋    | 304/532 [09:05<05:24,  1.42s/it]predicting train subjects:  57%|█████▋    | 305/532 [09:07<06:10,  1.63s/it]predicting train subjects:  58%|█████▊    | 306/532 [09:09<06:35,  1.75s/it]predicting train subjects:  58%|█████▊    | 307/532 [09:11<06:53,  1.84s/it]predicting train subjects:  58%|█████▊    | 308/532 [09:13<07:05,  1.90s/it]predicting train subjects:  58%|█████▊    | 309/532 [09:16<07:16,  1.96s/it]predicting train subjects:  58%|█████▊    | 310/532 [09:18<07:20,  1.98s/it]predicting train subjects:  58%|█████▊    | 311/532 [09:20<08:11,  2.22s/it]predicting train subjects:  59%|█████▊    | 312/532 [09:23<08:44,  2.38s/it]predicting train subjects:  59%|█████▉    | 313/532 [09:26<09:05,  2.49s/it]predicting train subjects:  59%|█████▉    | 314/532 [09:29<09:16,  2.55s/it]predicting train subjects:  59%|█████▉    | 315/532 [09:31<09:35,  2.65s/it]predicting train subjects:  59%|█████▉    | 316/532 [09:34<09:42,  2.70s/it]predicting train subjects:  60%|█████▉    | 317/532 [09:36<08:24,  2.35s/it]predicting train subjects:  60%|█████▉    | 318/532 [09:37<07:32,  2.11s/it]predicting train subjects:  60%|█████▉    | 319/532 [09:39<06:55,  1.95s/it]predicting train subjects:  60%|██████    | 320/532 [09:41<06:34,  1.86s/it]predicting train subjects:  60%|██████    | 321/532 [09:42<06:12,  1.77s/it]predicting train subjects:  61%|██████    | 322/532 [09:44<05:59,  1.71s/it]predicting train subjects:  61%|██████    | 323/532 [09:46<06:29,  1.86s/it]predicting train subjects:  61%|██████    | 324/532 [09:48<06:48,  1.96s/it]predicting train subjects:  61%|██████    | 325/532 [09:50<07:02,  2.04s/it]predicting train subjects:  61%|██████▏   | 326/532 [09:53<07:12,  2.10s/it]predicting train subjects:  61%|██████▏   | 327/532 [09:55<07:15,  2.12s/it]predicting train subjects:  62%|██████▏   | 328/532 [09:57<07:18,  2.15s/it]predicting train subjects:  62%|██████▏   | 329/532 [09:59<06:44,  1.99s/it]predicting train subjects:  62%|██████▏   | 330/532 [10:00<06:21,  1.89s/it]predicting train subjects:  62%|██████▏   | 331/532 [10:02<06:03,  1.81s/it]predicting train subjects:  62%|██████▏   | 332/532 [10:03<05:47,  1.74s/it]predicting train subjects:  63%|██████▎   | 333/532 [10:05<05:35,  1.68s/it]predicting train subjects:  63%|██████▎   | 334/532 [10:07<05:32,  1.68s/it]predicting train subjects:  63%|██████▎   | 335/532 [10:09<05:45,  1.75s/it]predicting train subjects:  63%|██████▎   | 336/532 [10:10<05:50,  1.79s/it]predicting train subjects:  63%|██████▎   | 337/532 [10:12<05:52,  1.81s/it]predicting train subjects:  64%|██████▎   | 338/532 [10:14<05:57,  1.84s/it]predicting train subjects:  64%|██████▎   | 339/532 [10:16<06:00,  1.87s/it]predicting train subjects:  64%|██████▍   | 340/532 [10:18<06:02,  1.89s/it]predicting train subjects:  64%|██████▍   | 341/532 [10:20<05:37,  1.77s/it]predicting train subjects:  64%|██████▍   | 342/532 [10:21<05:18,  1.68s/it]predicting train subjects:  64%|██████▍   | 343/532 [10:23<05:04,  1.61s/it]predicting train subjects:  65%|██████▍   | 344/532 [10:24<04:52,  1.56s/it]predicting train subjects:  65%|██████▍   | 345/532 [10:25<04:47,  1.54s/it]predicting train subjects:  65%|██████▌   | 346/532 [10:27<04:46,  1.54s/it]predicting train subjects:  65%|██████▌   | 347/532 [10:29<04:53,  1.59s/it]predicting train subjects:  65%|██████▌   | 348/532 [10:30<04:58,  1.62s/it]predicting train subjects:  66%|██████▌   | 349/532 [10:32<05:06,  1.68s/it]predicting train subjects:  66%|██████▌   | 350/532 [10:34<05:05,  1.68s/it]predicting train subjects:  66%|██████▌   | 351/532 [10:36<05:06,  1.69s/it]predicting train subjects:  66%|██████▌   | 352/532 [10:37<05:04,  1.69s/it]predicting train subjects:  66%|██████▋   | 353/532 [10:39<04:58,  1.67s/it]predicting train subjects:  67%|██████▋   | 354/532 [10:41<04:57,  1.67s/it]predicting train subjects:  67%|██████▋   | 355/532 [10:42<04:54,  1.66s/it]predicting train subjects:  67%|██████▋   | 356/532 [10:44<04:53,  1.67s/it]predicting train subjects:  67%|██████▋   | 357/532 [10:46<04:55,  1.69s/it]predicting train subjects:  67%|██████▋   | 358/532 [10:47<04:51,  1.68s/it]predicting train subjects:  67%|██████▋   | 359/532 [10:49<04:41,  1.63s/it]predicting train subjects:  68%|██████▊   | 360/532 [10:50<04:32,  1.58s/it]predicting train subjects:  68%|██████▊   | 361/532 [10:52<04:23,  1.54s/it]predicting train subjects:  68%|██████▊   | 362/532 [10:53<04:18,  1.52s/it]predicting train subjects:  68%|██████▊   | 363/532 [10:55<04:12,  1.49s/it]predicting train subjects:  68%|██████▊   | 364/532 [10:56<04:06,  1.47s/it]predicting train subjects:  69%|██████▊   | 365/532 [10:57<04:04,  1.46s/it]predicting train subjects:  69%|██████▉   | 366/532 [10:59<04:04,  1.47s/it]predicting train subjects:  69%|██████▉   | 367/532 [11:00<04:04,  1.48s/it]predicting train subjects:  69%|██████▉   | 368/532 [11:02<04:04,  1.49s/it]predicting train subjects:  69%|██████▉   | 369/532 [11:03<04:02,  1.49s/it]predicting train subjects:  70%|██████▉   | 370/532 [11:05<03:59,  1.48s/it]predicting train subjects:  70%|██████▉   | 371/532 [11:07<04:26,  1.65s/it]predicting train subjects:  70%|██████▉   | 372/532 [11:09<04:43,  1.77s/it]predicting train subjects:  70%|███████   | 373/532 [11:11<04:54,  1.85s/it]predicting train subjects:  70%|███████   | 374/532 [11:13<05:03,  1.92s/it]predicting train subjects:  70%|███████   | 375/532 [11:15<05:11,  1.98s/it]predicting train subjects:  71%|███████   | 376/532 [11:17<05:12,  2.00s/it]predicting train subjects:  71%|███████   | 377/532 [11:19<04:56,  1.92s/it]predicting train subjects:  71%|███████   | 378/532 [11:21<04:42,  1.83s/it]predicting train subjects:  71%|███████   | 379/532 [11:22<04:32,  1.78s/it]predicting train subjects:  71%|███████▏  | 380/532 [11:24<04:23,  1.73s/it]predicting train subjects:  72%|███████▏  | 381/532 [11:26<04:15,  1.69s/it]predicting train subjects:  72%|███████▏  | 382/532 [11:27<04:12,  1.68s/it]predicting train subjects:  72%|███████▏  | 383/532 [11:29<04:15,  1.71s/it]predicting train subjects:  72%|███████▏  | 384/532 [11:31<04:18,  1.74s/it]predicting train subjects:  72%|███████▏  | 385/532 [11:33<04:22,  1.79s/it]predicting train subjects:  73%|███████▎  | 386/532 [11:35<04:20,  1.78s/it]predicting train subjects:  73%|███████▎  | 387/532 [11:36<04:15,  1.76s/it]predicting train subjects:  73%|███████▎  | 388/532 [11:38<04:11,  1.75s/it]predicting train subjects:  73%|███████▎  | 389/532 [11:40<04:10,  1.75s/it]predicting train subjects:  73%|███████▎  | 390/532 [11:41<04:08,  1.75s/it]predicting train subjects:  73%|███████▎  | 391/532 [11:43<04:07,  1.75s/it]predicting train subjects:  74%|███████▎  | 392/532 [11:45<04:07,  1.77s/it]predicting train subjects:  74%|███████▍  | 393/532 [11:47<04:11,  1.81s/it]predicting train subjects:  74%|███████▍  | 394/532 [11:49<04:10,  1.82s/it]predicting train subjects:  74%|███████▍  | 395/532 [11:51<04:06,  1.80s/it]predicting train subjects:  74%|███████▍  | 396/532 [11:52<04:07,  1.82s/it]predicting train subjects:  75%|███████▍  | 397/532 [11:54<04:04,  1.81s/it]predicting train subjects:  75%|███████▍  | 398/532 [11:56<04:01,  1.80s/it]predicting train subjects:  75%|███████▌  | 399/532 [11:58<03:58,  1.79s/it]predicting train subjects:  75%|███████▌  | 400/532 [12:00<04:01,  1.83s/it]predicting train subjects:  75%|███████▌  | 401/532 [12:02<04:02,  1.85s/it]predicting train subjects:  76%|███████▌  | 402/532 [12:03<04:03,  1.87s/it]predicting train subjects:  76%|███████▌  | 403/532 [12:06<04:08,  1.93s/it]predicting train subjects:  76%|███████▌  | 404/532 [12:07<04:06,  1.92s/it]predicting train subjects:  76%|███████▌  | 405/532 [12:09<04:04,  1.93s/it]predicting train subjects:  76%|███████▋  | 406/532 [12:11<04:04,  1.94s/it]predicting train subjects:  77%|███████▋  | 407/532 [12:13<03:53,  1.87s/it]predicting train subjects:  77%|███████▋  | 408/532 [12:15<03:43,  1.80s/it]predicting train subjects:  77%|███████▋  | 409/532 [12:16<03:38,  1.78s/it]predicting train subjects:  77%|███████▋  | 410/532 [12:18<03:32,  1.74s/it]predicting train subjects:  77%|███████▋  | 411/532 [12:20<03:25,  1.70s/it]predicting train subjects:  77%|███████▋  | 412/532 [12:21<03:20,  1.67s/it]predicting train subjects:  78%|███████▊  | 413/532 [12:23<03:15,  1.64s/it]predicting train subjects:  78%|███████▊  | 414/532 [12:24<03:08,  1.60s/it]predicting train subjects:  78%|███████▊  | 415/532 [12:26<03:02,  1.56s/it]predicting train subjects:  78%|███████▊  | 416/532 [12:27<03:02,  1.57s/it]predicting train subjects:  78%|███████▊  | 417/532 [12:29<02:57,  1.54s/it]predicting train subjects:  79%|███████▊  | 418/532 [12:30<02:57,  1.56s/it]predicting train subjects:  79%|███████▉  | 419/532 [12:32<03:06,  1.65s/it]predicting train subjects:  79%|███████▉  | 420/532 [12:34<03:07,  1.67s/it]predicting train subjects:  79%|███████▉  | 421/532 [12:36<03:10,  1.72s/it]predicting train subjects:  79%|███████▉  | 422/532 [12:38<03:10,  1.73s/it]predicting train subjects:  80%|███████▉  | 423/532 [12:39<03:10,  1.75s/it]predicting train subjects:  80%|███████▉  | 424/532 [12:41<03:06,  1.73s/it]predicting train subjects:  80%|███████▉  | 425/532 [12:43<03:05,  1.73s/it]predicting train subjects:  80%|████████  | 426/532 [12:45<03:02,  1.72s/it]predicting train subjects:  80%|████████  | 427/532 [12:46<02:58,  1.70s/it]predicting train subjects:  80%|████████  | 428/532 [12:48<02:59,  1.72s/it]predicting train subjects:  81%|████████  | 429/532 [12:50<02:58,  1.74s/it]predicting train subjects:  81%|████████  | 430/532 [12:51<02:56,  1.73s/it]predicting train subjects:  81%|████████  | 431/532 [12:53<03:01,  1.79s/it]predicting train subjects:  81%|████████  | 432/532 [12:55<03:06,  1.87s/it]predicting train subjects:  81%|████████▏ | 433/532 [12:58<03:10,  1.93s/it]predicting train subjects:  82%|████████▏ | 434/532 [12:59<03:10,  1.94s/it]predicting train subjects:  82%|████████▏ | 435/532 [13:02<03:11,  1.97s/it]predicting train subjects:  82%|████████▏ | 436/532 [13:03<03:08,  1.97s/it]predicting train subjects:  82%|████████▏ | 437/532 [13:05<02:53,  1.83s/it]predicting train subjects:  82%|████████▏ | 438/532 [13:06<02:38,  1.69s/it]predicting train subjects:  83%|████████▎ | 439/532 [13:08<02:29,  1.61s/it]predicting train subjects:  83%|████████▎ | 440/532 [13:09<02:23,  1.56s/it]predicting train subjects:  83%|████████▎ | 441/532 [13:11<02:18,  1.52s/it]predicting train subjects:  83%|████████▎ | 442/532 [13:12<02:15,  1.51s/it]predicting train subjects:  83%|████████▎ | 443/532 [13:13<02:10,  1.47s/it]predicting train subjects:  83%|████████▎ | 444/532 [13:15<02:07,  1.45s/it]predicting train subjects:  84%|████████▎ | 445/532 [13:16<02:06,  1.45s/it]predicting train subjects:  84%|████████▍ | 446/532 [13:18<02:03,  1.44s/it]predicting train subjects:  84%|████████▍ | 447/532 [13:19<02:02,  1.45s/it]predicting train subjects:  84%|████████▍ | 448/532 [13:21<02:00,  1.43s/it]predicting train subjects:  84%|████████▍ | 449/532 [13:22<02:04,  1.50s/it]predicting train subjects:  85%|████████▍ | 450/532 [13:24<02:03,  1.51s/it]predicting train subjects:  85%|████████▍ | 451/532 [13:25<02:01,  1.50s/it]predicting train subjects:  85%|████████▍ | 452/532 [13:27<02:01,  1.52s/it]predicting train subjects:  85%|████████▌ | 453/532 [13:28<02:01,  1.54s/it]predicting train subjects:  85%|████████▌ | 454/532 [13:30<02:01,  1.55s/it]predicting train subjects:  86%|████████▌ | 455/532 [13:32<02:04,  1.62s/it]predicting train subjects:  86%|████████▌ | 456/532 [13:34<02:07,  1.68s/it]predicting train subjects:  86%|████████▌ | 457/532 [13:35<02:08,  1.71s/it]predicting train subjects:  86%|████████▌ | 458/532 [13:37<02:09,  1.75s/it]predicting train subjects:  86%|████████▋ | 459/532 [13:39<02:08,  1.76s/it]predicting train subjects:  86%|████████▋ | 460/532 [13:41<02:08,  1.78s/it]predicting train subjects:  87%|████████▋ | 461/532 [13:43<02:11,  1.85s/it]predicting train subjects:  87%|████████▋ | 462/532 [13:45<02:13,  1.91s/it]predicting train subjects:  87%|████████▋ | 463/532 [13:47<02:13,  1.94s/it]predicting train subjects:  87%|████████▋ | 464/532 [13:49<02:13,  1.96s/it]predicting train subjects:  87%|████████▋ | 465/532 [13:51<02:14,  2.01s/it]predicting train subjects:  88%|████████▊ | 466/532 [13:53<02:15,  2.05s/it]predicting train subjects:  88%|████████▊ | 467/532 [13:55<02:04,  1.92s/it]predicting train subjects:  88%|████████▊ | 468/532 [13:56<01:57,  1.84s/it]predicting train subjects:  88%|████████▊ | 469/532 [13:58<01:49,  1.74s/it]predicting train subjects:  88%|████████▊ | 470/532 [14:00<01:44,  1.69s/it]predicting train subjects:  89%|████████▊ | 471/532 [14:01<01:42,  1.67s/it]predicting train subjects:  89%|████████▊ | 472/532 [14:03<01:39,  1.66s/it]predicting train subjects:  89%|████████▉ | 473/532 [14:05<01:40,  1.71s/it]predicting train subjects:  89%|████████▉ | 474/532 [14:07<01:41,  1.76s/it]predicting train subjects:  89%|████████▉ | 475/532 [14:08<01:41,  1.78s/it]predicting train subjects:  89%|████████▉ | 476/532 [14:10<01:40,  1.79s/it]predicting train subjects:  90%|████████▉ | 477/532 [14:12<01:39,  1.80s/it]predicting train subjects:  90%|████████▉ | 478/532 [14:14<01:38,  1.83s/it]predicting train subjects:  90%|█████████ | 479/532 [14:15<01:32,  1.75s/it]predicting train subjects:  90%|█████████ | 480/532 [14:17<01:27,  1.69s/it]predicting train subjects:  90%|█████████ | 481/532 [14:19<01:24,  1.65s/it]predicting train subjects:  91%|█████████ | 482/532 [14:20<01:21,  1.63s/it]predicting train subjects:  91%|█████████ | 483/532 [14:22<01:19,  1.62s/it]predicting train subjects:  91%|█████████ | 484/532 [14:23<01:16,  1.58s/it]predicting train subjects:  91%|█████████ | 485/532 [14:25<01:19,  1.69s/it]predicting train subjects:  91%|█████████▏| 486/532 [14:27<01:21,  1.78s/it]predicting train subjects:  92%|█████████▏| 487/532 [14:29<01:23,  1.85s/it]predicting train subjects:  92%|█████████▏| 488/532 [14:31<01:23,  1.90s/it]predicting train subjects:  92%|█████████▏| 489/532 [14:33<01:23,  1.93s/it]predicting train subjects:  92%|█████████▏| 490/532 [14:35<01:21,  1.93s/it]predicting train subjects:  92%|█████████▏| 491/532 [14:37<01:15,  1.83s/it]predicting train subjects:  92%|█████████▏| 492/532 [14:38<01:10,  1.76s/it]predicting train subjects:  93%|█████████▎| 493/532 [14:40<01:07,  1.74s/it]predicting train subjects:  93%|█████████▎| 494/532 [14:42<01:05,  1.73s/it]predicting train subjects:  93%|█████████▎| 495/532 [14:43<01:03,  1.70s/it]predicting train subjects:  93%|█████████▎| 496/532 [14:45<01:00,  1.69s/it]predicting train subjects:  93%|█████████▎| 497/532 [14:47<00:59,  1.69s/it]predicting train subjects:  94%|█████████▎| 498/532 [14:48<00:57,  1.68s/it]predicting train subjects:  94%|█████████▍| 499/532 [14:50<00:56,  1.70s/it]predicting train subjects:  94%|█████████▍| 500/532 [14:52<00:54,  1.70s/it]predicting train subjects:  94%|█████████▍| 501/532 [14:53<00:52,  1.69s/it]predicting train subjects:  94%|█████████▍| 502/532 [14:55<00:50,  1.68s/it]predicting train subjects:  95%|█████████▍| 503/532 [14:57<00:47,  1.65s/it]predicting train subjects:  95%|█████████▍| 504/532 [14:58<00:45,  1.62s/it]predicting train subjects:  95%|█████████▍| 505/532 [15:00<00:44,  1.63s/it]predicting train subjects:  95%|█████████▌| 506/532 [15:01<00:41,  1.61s/it]predicting train subjects:  95%|█████████▌| 507/532 [15:03<00:39,  1.58s/it]predicting train subjects:  95%|█████████▌| 508/532 [15:05<00:38,  1.59s/it]predicting train subjects:  96%|█████████▌| 509/532 [15:07<00:39,  1.70s/it]predicting train subjects:  96%|█████████▌| 510/532 [15:09<00:39,  1.79s/it]predicting train subjects:  96%|█████████▌| 511/532 [15:10<00:38,  1.84s/it]predicting train subjects:  96%|█████████▌| 512/532 [15:13<00:38,  1.90s/it]predicting train subjects:  96%|█████████▋| 513/532 [15:15<00:36,  1.93s/it]predicting train subjects:  97%|█████████▋| 514/532 [15:17<00:34,  1.94s/it]predicting train subjects:  97%|█████████▋| 515/532 [15:18<00:31,  1.87s/it]predicting train subjects:  97%|█████████▋| 516/532 [15:20<00:28,  1.81s/it]predicting train subjects:  97%|█████████▋| 517/532 [15:22<00:26,  1.76s/it]predicting train subjects:  97%|█████████▋| 518/532 [15:23<00:24,  1.73s/it]predicting train subjects:  98%|█████████▊| 519/532 [15:25<00:22,  1.71s/it]predicting train subjects:  98%|█████████▊| 520/532 [15:27<00:20,  1.70s/it]predicting train subjects:  98%|█████████▊| 521/532 [15:28<00:19,  1.76s/it]predicting train subjects:  98%|█████████▊| 522/532 [15:30<00:18,  1.81s/it]predicting train subjects:  98%|█████████▊| 523/532 [15:32<00:16,  1.85s/it]predicting train subjects:  98%|█████████▊| 524/532 [15:34<00:15,  1.88s/it]predicting train subjects:  99%|█████████▊| 525/532 [15:36<00:13,  1.89s/it]predicting train subjects:  99%|█████████▉| 526/532 [15:38<00:11,  1.89s/it]predicting train subjects:  99%|█████████▉| 527/532 [15:40<00:09,  1.81s/it]predicting train subjects:  99%|█████████▉| 528/532 [15:41<00:07,  1.77s/it]predicting train subjects:  99%|█████████▉| 529/532 [15:43<00:05,  1.74s/it]predicting train subjects: 100%|█████████▉| 530/532 [15:45<00:03,  1.69s/it]predicting train subjects: 100%|█████████▉| 531/532 [15:46<00:01,  1.73s/it]predicting train subjects: 100%|██████████| 532/532 [15:48<00:00,  1.76s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a’: File exists
mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a’: File exists

Loading train:   0%|          | 0/456 [00:00<?, ?it/s]Loading train:   0%|          | 1/456 [00:01<11:36,  1.53s/it]Loading train:   0%|          | 2/456 [00:02<10:53,  1.44s/it]Loading train:   1%|          | 3/456 [00:04<10:33,  1.40s/it]Loading train:   1%|          | 4/456 [00:05<10:01,  1.33s/it]Loading train:   1%|          | 5/456 [00:06<10:07,  1.35s/it]Loading train:   1%|▏         | 6/456 [00:07<09:32,  1.27s/it]Loading train:   2%|▏         | 7/456 [00:08<08:24,  1.12s/it]Loading train:   2%|▏         | 8/456 [00:09<08:05,  1.08s/it]Loading train:   2%|▏         | 9/456 [00:10<07:50,  1.05s/it]Loading train:   2%|▏         | 10/456 [00:11<08:11,  1.10s/it]Loading train:   2%|▏         | 11/456 [00:13<08:41,  1.17s/it]Loading train:   3%|▎         | 12/456 [00:14<08:27,  1.14s/it]Loading train:   3%|▎         | 13/456 [00:15<08:26,  1.14s/it]Loading train:   3%|▎         | 14/456 [00:16<08:13,  1.12s/it]Loading train:   3%|▎         | 15/456 [00:16<07:15,  1.01it/s]Loading train:   4%|▎         | 16/456 [00:18<07:42,  1.05s/it]Loading train:   4%|▎         | 17/456 [00:19<08:15,  1.13s/it]Loading train:   4%|▍         | 18/456 [00:20<08:04,  1.11s/it]Loading train:   4%|▍         | 19/456 [00:21<07:49,  1.07s/it]Loading train:   4%|▍         | 20/456 [00:22<07:15,  1.00it/s]Loading train:   5%|▍         | 21/456 [00:23<07:47,  1.08s/it]Loading train:   5%|▍         | 22/456 [00:24<07:34,  1.05s/it]Loading train:   5%|▌         | 23/456 [00:25<07:37,  1.06s/it]Loading train:   5%|▌         | 24/456 [00:26<06:57,  1.03it/s]Loading train:   5%|▌         | 25/456 [00:27<06:43,  1.07it/s]Loading train:   6%|▌         | 26/456 [00:28<06:46,  1.06it/s]Loading train:   6%|▌         | 27/456 [00:29<07:01,  1.02it/s]Loading train:   6%|▌         | 28/456 [00:30<06:50,  1.04it/s]Loading train:   6%|▋         | 29/456 [00:31<06:29,  1.10it/s]Loading train:   7%|▋         | 30/456 [00:31<06:17,  1.13it/s]Loading train:   7%|▋         | 31/456 [00:32<06:32,  1.08it/s]Loading train:   7%|▋         | 32/456 [00:33<06:33,  1.08it/s]Loading train:   7%|▋         | 33/456 [00:34<06:25,  1.10it/s]Loading train:   7%|▋         | 34/456 [00:35<06:22,  1.10it/s]Loading train:   8%|▊         | 35/456 [00:36<06:10,  1.14it/s]Loading train:   8%|▊         | 36/456 [00:37<06:11,  1.13it/s]Loading train:   8%|▊         | 37/456 [00:38<06:22,  1.10it/s]Loading train:   8%|▊         | 38/456 [00:39<06:42,  1.04it/s]Loading train:   9%|▊         | 39/456 [00:40<06:34,  1.06it/s]Loading train:   9%|▉         | 40/456 [00:41<06:27,  1.07it/s]Loading train:   9%|▉         | 41/456 [00:42<06:25,  1.08it/s]Loading train:   9%|▉         | 42/456 [00:43<06:32,  1.05it/s]Loading train:   9%|▉         | 43/456 [00:44<06:49,  1.01it/s]Loading train:  10%|▉         | 44/456 [00:45<06:34,  1.04it/s]Loading train:  10%|▉         | 45/456 [00:45<06:31,  1.05it/s]Loading train:  10%|█         | 46/456 [00:47<06:44,  1.01it/s]Loading train:  10%|█         | 47/456 [00:47<06:27,  1.06it/s]Loading train:  11%|█         | 48/456 [00:48<06:32,  1.04it/s]Loading train:  11%|█         | 49/456 [00:49<06:40,  1.02it/s]Loading train:  11%|█         | 50/456 [00:50<06:48,  1.01s/it]Loading train:  11%|█         | 51/456 [00:52<06:54,  1.02s/it]Loading train:  11%|█▏        | 52/456 [00:53<06:55,  1.03s/it]Loading train:  12%|█▏        | 53/456 [00:53<06:27,  1.04it/s]Loading train:  12%|█▏        | 54/456 [00:54<06:25,  1.04it/s]Loading train:  12%|█▏        | 55/456 [00:55<06:42,  1.00s/it]Loading train:  12%|█▏        | 56/456 [00:56<06:35,  1.01it/s]Loading train:  12%|█▎        | 57/456 [00:57<06:36,  1.01it/s]Loading train:  13%|█▎        | 58/456 [00:58<06:35,  1.01it/s]Loading train:  13%|█▎        | 59/456 [00:59<06:29,  1.02it/s]Loading train:  13%|█▎        | 60/456 [01:00<06:32,  1.01it/s]Loading train:  13%|█▎        | 61/456 [01:02<07:14,  1.10s/it]Loading train:  14%|█▎        | 62/456 [01:03<07:11,  1.10s/it]Loading train:  14%|█▍        | 63/456 [01:04<06:51,  1.05s/it]Loading train:  14%|█▍        | 64/456 [01:05<07:05,  1.09s/it]Loading train:  14%|█▍        | 65/456 [01:06<06:42,  1.03s/it]Loading train:  14%|█▍        | 66/456 [01:07<06:48,  1.05s/it]Loading train:  15%|█▍        | 67/456 [01:08<06:45,  1.04s/it]Loading train:  15%|█▍        | 68/456 [01:09<07:12,  1.11s/it]Loading train:  15%|█▌        | 69/456 [01:10<07:08,  1.11s/it]Loading train:  15%|█▌        | 70/456 [01:11<06:47,  1.05s/it]Loading train:  16%|█▌        | 71/456 [01:12<06:34,  1.02s/it]Loading train:  16%|█▌        | 72/456 [01:13<06:44,  1.05s/it]Loading train:  16%|█▌        | 73/456 [01:14<06:31,  1.02s/it]Loading train:  16%|█▌        | 74/456 [01:15<06:37,  1.04s/it]Loading train:  16%|█▋        | 75/456 [01:16<06:43,  1.06s/it]Loading train:  17%|█▋        | 76/456 [01:18<06:48,  1.07s/it]Loading train:  17%|█▋        | 77/456 [01:19<06:44,  1.07s/it]Loading train:  17%|█▋        | 78/456 [01:20<06:40,  1.06s/it]Loading train:  17%|█▋        | 79/456 [01:21<06:18,  1.00s/it]Loading train:  18%|█▊        | 80/456 [01:21<05:42,  1.10it/s]Loading train:  18%|█▊        | 81/456 [01:22<05:52,  1.06it/s]Loading train:  18%|█▊        | 82/456 [01:23<05:27,  1.14it/s]Loading train:  18%|█▊        | 83/456 [01:24<05:20,  1.16it/s]Loading train:  18%|█▊        | 84/456 [01:25<05:07,  1.21it/s]Loading train:  19%|█▊        | 85/456 [01:25<05:01,  1.23it/s]Loading train:  19%|█▉        | 86/456 [01:26<04:59,  1.24it/s]Loading train:  19%|█▉        | 87/456 [01:27<05:01,  1.22it/s]Loading train:  19%|█▉        | 88/456 [01:28<04:58,  1.23it/s]Loading train:  20%|█▉        | 89/456 [01:28<04:39,  1.31it/s]Loading train:  20%|█▉        | 90/456 [01:29<04:50,  1.26it/s]Loading train:  20%|█▉        | 91/456 [01:30<04:57,  1.23it/s]Loading train:  20%|██        | 92/456 [01:31<04:50,  1.25it/s]Loading train:  20%|██        | 93/456 [01:32<04:45,  1.27it/s]Loading train:  21%|██        | 94/456 [01:33<04:55,  1.22it/s]Loading train:  21%|██        | 95/456 [01:33<04:45,  1.26it/s]Loading train:  21%|██        | 96/456 [01:34<04:54,  1.22it/s]Loading train:  21%|██▏       | 97/456 [01:35<05:26,  1.10it/s]Loading train:  21%|██▏       | 98/456 [01:36<05:36,  1.06it/s]Loading train:  22%|██▏       | 99/456 [01:37<05:42,  1.04it/s]Loading train:  22%|██▏       | 100/456 [01:38<05:52,  1.01it/s]Loading train:  22%|██▏       | 101/456 [01:39<05:55,  1.00s/it]Loading train:  22%|██▏       | 102/456 [01:40<06:04,  1.03s/it]Loading train:  23%|██▎       | 103/456 [01:42<06:13,  1.06s/it]Loading train:  23%|██▎       | 104/456 [01:43<06:06,  1.04s/it]Loading train:  23%|██▎       | 105/456 [01:43<05:48,  1.01it/s]Loading train:  23%|██▎       | 106/456 [01:45<06:17,  1.08s/it]Loading train:  23%|██▎       | 107/456 [01:46<06:10,  1.06s/it]Loading train:  24%|██▎       | 108/456 [01:47<06:23,  1.10s/it]Loading train:  24%|██▍       | 109/456 [01:48<06:25,  1.11s/it]Loading train:  24%|██▍       | 110/456 [01:49<06:46,  1.17s/it]Loading train:  24%|██▍       | 111/456 [01:50<06:12,  1.08s/it]Loading train:  25%|██▍       | 112/456 [01:51<05:49,  1.01s/it]Loading train:  25%|██▍       | 113/456 [01:52<05:37,  1.02it/s]Loading train:  25%|██▌       | 114/456 [01:53<05:33,  1.03it/s]Loading train:  25%|██▌       | 115/456 [01:54<05:35,  1.02it/s]Loading train:  25%|██▌       | 116/456 [01:55<05:48,  1.02s/it]Loading train:  26%|██▌       | 117/456 [01:56<05:44,  1.02s/it]Loading train:  26%|██▌       | 118/456 [01:57<05:32,  1.02it/s]Loading train:  26%|██▌       | 119/456 [01:58<06:00,  1.07s/it]Loading train:  26%|██▋       | 120/456 [01:59<05:47,  1.03s/it]Loading train:  27%|██▋       | 121/456 [02:00<05:37,  1.01s/it]Loading train:  27%|██▋       | 122/456 [02:01<05:39,  1.02s/it]Loading train:  27%|██▋       | 123/456 [02:02<05:41,  1.03s/it]Loading train:  27%|██▋       | 124/456 [02:03<05:36,  1.01s/it]Loading train:  27%|██▋       | 125/456 [02:04<05:39,  1.03s/it]Loading train:  28%|██▊       | 126/456 [02:05<05:30,  1.00s/it]Loading train:  28%|██▊       | 127/456 [02:06<05:27,  1.00it/s]Loading train:  28%|██▊       | 128/456 [02:07<05:26,  1.01it/s]Loading train:  28%|██▊       | 129/456 [02:08<05:23,  1.01it/s]Loading train:  29%|██▊       | 130/456 [02:09<04:57,  1.10it/s]Loading train:  29%|██▊       | 131/456 [02:10<04:39,  1.16it/s]Loading train:  29%|██▉       | 132/456 [02:11<04:46,  1.13it/s]Loading train:  29%|██▉       | 133/456 [02:12<05:32,  1.03s/it]Loading train:  29%|██▉       | 134/456 [02:13<05:49,  1.09s/it]Loading train:  30%|██▉       | 135/456 [02:14<05:55,  1.11s/it]Loading train:  30%|██▉       | 136/456 [02:16<06:15,  1.17s/it]Loading train:  30%|███       | 137/456 [02:17<06:24,  1.21s/it]Loading train:  30%|███       | 138/456 [02:18<06:17,  1.19s/it]Loading train:  30%|███       | 139/456 [02:19<05:57,  1.13s/it]Loading train:  31%|███       | 140/456 [02:20<05:47,  1.10s/it]Loading train:  31%|███       | 141/456 [02:21<05:34,  1.06s/it]Loading train:  31%|███       | 142/456 [02:22<05:44,  1.10s/it]Loading train:  31%|███▏      | 143/456 [02:23<05:34,  1.07s/it]Loading train:  32%|███▏      | 144/456 [02:24<05:23,  1.04s/it]Loading train:  32%|███▏      | 145/456 [02:26<05:41,  1.10s/it]Loading train:  32%|███▏      | 146/456 [02:26<05:17,  1.03s/it]Loading train:  32%|███▏      | 147/456 [02:27<04:57,  1.04it/s]Loading train:  32%|███▏      | 148/456 [02:28<04:53,  1.05it/s]Loading train:  33%|███▎      | 149/456 [02:29<04:54,  1.04it/s]Loading train:  33%|███▎      | 150/456 [02:30<04:43,  1.08it/s]Loading train:  33%|███▎      | 151/456 [02:31<04:54,  1.04it/s]Loading train:  33%|███▎      | 152/456 [02:32<05:06,  1.01s/it]Loading train:  34%|███▎      | 153/456 [02:33<05:01,  1.00it/s]Loading train:  34%|███▍      | 154/456 [02:34<04:57,  1.02it/s]Loading train:  34%|███▍      | 155/456 [02:35<05:10,  1.03s/it]Loading train:  34%|███▍      | 156/456 [02:36<05:15,  1.05s/it]Loading train:  34%|███▍      | 157/456 [02:37<05:08,  1.03s/it]Loading train:  35%|███▍      | 158/456 [02:38<05:07,  1.03s/it]Loading train:  35%|███▍      | 159/456 [02:39<04:49,  1.02it/s]Loading train:  35%|███▌      | 160/456 [02:40<04:27,  1.11it/s]Loading train:  35%|███▌      | 161/456 [02:41<04:14,  1.16it/s]Loading train:  36%|███▌      | 162/456 [02:41<04:06,  1.19it/s]Loading train:  36%|███▌      | 163/456 [02:43<04:41,  1.04it/s]Loading train:  36%|███▌      | 164/456 [02:44<04:42,  1.03it/s]Loading train:  36%|███▌      | 165/456 [02:44<04:30,  1.08it/s]Loading train:  36%|███▋      | 166/456 [02:45<04:20,  1.11it/s]Loading train:  37%|███▋      | 167/456 [02:46<04:00,  1.20it/s]Loading train:  37%|███▋      | 168/456 [02:47<04:16,  1.12it/s]Loading train:  37%|███▋      | 169/456 [02:48<03:56,  1.21it/s]Loading train:  37%|███▋      | 170/456 [02:48<03:49,  1.25it/s]Loading train:  38%|███▊      | 171/456 [02:49<03:57,  1.20it/s]Loading train:  38%|███▊      | 172/456 [02:50<03:48,  1.24it/s]Loading train:  38%|███▊      | 173/456 [02:51<03:32,  1.33it/s]Loading train:  38%|███▊      | 174/456 [02:51<03:33,  1.32it/s]Loading train:  38%|███▊      | 175/456 [02:52<03:43,  1.26it/s]Loading train:  39%|███▊      | 176/456 [02:53<03:55,  1.19it/s]Loading train:  39%|███▉      | 177/456 [02:54<03:54,  1.19it/s]Loading train:  39%|███▉      | 178/456 [02:55<03:50,  1.20it/s]Loading train:  39%|███▉      | 179/456 [02:56<03:48,  1.21it/s]Loading train:  39%|███▉      | 180/456 [02:56<03:37,  1.27it/s]Loading train:  40%|███▉      | 181/456 [02:58<04:42,  1.03s/it]Loading train:  40%|███▉      | 182/456 [02:59<04:59,  1.09s/it]Loading train:  40%|████      | 183/456 [03:01<05:07,  1.12s/it]Loading train:  40%|████      | 184/456 [03:02<04:58,  1.10s/it]Loading train:  41%|████      | 185/456 [03:03<04:45,  1.05s/it]Loading train:  41%|████      | 186/456 [03:04<04:58,  1.10s/it]Loading train:  41%|████      | 187/456 [03:05<05:11,  1.16s/it]Loading train:  41%|████      | 188/456 [03:06<05:08,  1.15s/it]Loading train:  41%|████▏     | 189/456 [03:07<05:15,  1.18s/it]Loading train:  42%|████▏     | 190/456 [03:09<05:17,  1.19s/it]Loading train:  42%|████▏     | 191/456 [03:10<05:16,  1.19s/it]Loading train:  42%|████▏     | 192/456 [03:11<05:24,  1.23s/it]Loading train:  42%|████▏     | 193/456 [03:13<05:37,  1.28s/it]Loading train:  43%|████▎     | 194/456 [03:13<05:09,  1.18s/it]Loading train:  43%|████▎     | 195/456 [03:15<04:58,  1.15s/it]Loading train:  43%|████▎     | 196/456 [03:16<04:53,  1.13s/it]Loading train:  43%|████▎     | 197/456 [03:17<04:56,  1.15s/it]Loading train:  43%|████▎     | 198/456 [03:18<05:01,  1.17s/it]Loading train:  44%|████▎     | 199/456 [03:19<04:59,  1.17s/it]Loading train:  44%|████▍     | 200/456 [03:20<04:54,  1.15s/it]Loading train:  44%|████▍     | 201/456 [03:21<04:48,  1.13s/it]Loading train:  44%|████▍     | 202/456 [03:22<04:28,  1.06s/it]Loading train:  45%|████▍     | 203/456 [03:23<04:14,  1.01s/it]Loading train:  45%|████▍     | 204/456 [03:24<04:09,  1.01it/s]Loading train:  45%|████▍     | 205/456 [03:25<04:00,  1.04it/s]Loading train:  45%|████▌     | 206/456 [03:26<04:00,  1.04it/s]Loading train:  45%|████▌     | 207/456 [03:27<03:59,  1.04it/s]Loading train:  46%|████▌     | 208/456 [03:28<04:02,  1.02it/s]Loading train:  46%|████▌     | 209/456 [03:29<03:59,  1.03it/s]Loading train:  46%|████▌     | 210/456 [03:30<03:55,  1.05it/s]Loading train:  46%|████▋     | 211/456 [03:31<04:14,  1.04s/it]Loading train:  46%|████▋     | 212/456 [03:32<04:24,  1.08s/it]Loading train:  47%|████▋     | 213/456 [03:33<04:16,  1.06s/it]Loading train:  47%|████▋     | 214/456 [03:34<04:18,  1.07s/it]Loading train:  47%|████▋     | 215/456 [03:35<04:19,  1.08s/it]Loading train:  47%|████▋     | 216/456 [03:36<04:15,  1.06s/it]Loading train:  48%|████▊     | 217/456 [03:38<04:26,  1.11s/it]Loading train:  48%|████▊     | 218/456 [03:39<04:19,  1.09s/it]Loading train:  48%|████▊     | 219/456 [03:40<04:18,  1.09s/it]Loading train:  48%|████▊     | 220/456 [03:41<04:23,  1.12s/it]Loading train:  48%|████▊     | 221/456 [03:42<04:33,  1.16s/it]Loading train:  49%|████▊     | 222/456 [03:43<04:31,  1.16s/it]Loading train:  49%|████▉     | 223/456 [03:45<04:40,  1.20s/it]Loading train:  49%|████▉     | 224/456 [03:46<04:40,  1.21s/it]Loading train:  49%|████▉     | 225/456 [03:47<04:38,  1.20s/it]Loading train:  50%|████▉     | 226/456 [03:48<04:24,  1.15s/it]Loading train:  50%|████▉     | 227/456 [03:49<04:06,  1.08s/it]Loading train:  50%|█████     | 228/456 [03:50<03:47,  1.00it/s]Loading train:  50%|█████     | 229/456 [03:51<03:58,  1.05s/it]Loading train:  50%|█████     | 230/456 [03:52<03:52,  1.03s/it]Loading train:  51%|█████     | 231/456 [03:53<03:44,  1.00it/s]Loading train:  51%|█████     | 232/456 [03:54<03:47,  1.02s/it]Loading train:  51%|█████     | 233/456 [03:55<03:40,  1.01it/s]Loading train:  51%|█████▏    | 234/456 [03:56<03:46,  1.02s/it]Loading train:  52%|█████▏    | 235/456 [03:57<03:58,  1.08s/it]Loading train:  52%|█████▏    | 236/456 [03:58<03:45,  1.02s/it]Loading train:  52%|█████▏    | 237/456 [03:59<03:44,  1.03s/it]Loading train:  52%|█████▏    | 238/456 [04:00<03:49,  1.05s/it]Loading train:  52%|█████▏    | 239/456 [04:01<03:41,  1.02s/it]Loading train:  53%|█████▎    | 240/456 [04:02<03:33,  1.01it/s]Loading train:  53%|█████▎    | 241/456 [04:03<03:44,  1.04s/it]Loading train:  53%|█████▎    | 242/456 [04:04<03:41,  1.03s/it]Loading train:  53%|█████▎    | 243/456 [04:05<03:29,  1.02it/s]Loading train:  54%|█████▎    | 244/456 [04:06<03:26,  1.03it/s]Loading train:  54%|█████▎    | 245/456 [04:08<03:52,  1.10s/it]Loading train:  54%|█████▍    | 246/456 [04:09<03:44,  1.07s/it]Loading train:  54%|█████▍    | 247/456 [04:10<03:40,  1.05s/it]Loading train:  54%|█████▍    | 248/456 [04:10<03:21,  1.03it/s]Loading train:  55%|█████▍    | 249/456 [04:11<03:13,  1.07it/s]Loading train:  55%|█████▍    | 250/456 [04:12<03:14,  1.06it/s]Loading train:  55%|█████▌    | 251/456 [04:13<02:59,  1.14it/s]Loading train:  55%|█████▌    | 252/456 [04:14<03:02,  1.11it/s]Loading train:  55%|█████▌    | 253/456 [04:15<03:37,  1.07s/it]Loading train:  56%|█████▌    | 254/456 [04:17<04:04,  1.21s/it]Loading train:  56%|█████▌    | 255/456 [04:18<04:14,  1.26s/it]Loading train:  56%|█████▌    | 256/456 [04:20<04:14,  1.27s/it]Loading train:  56%|█████▋    | 257/456 [04:21<04:28,  1.35s/it]Loading train:  57%|█████▋    | 258/456 [04:22<04:32,  1.38s/it]Loading train:  57%|█████▋    | 259/456 [04:23<04:03,  1.24s/it]Loading train:  57%|█████▋    | 260/456 [04:24<03:32,  1.08s/it]Loading train:  57%|█████▋    | 261/456 [04:25<03:35,  1.10s/it]Loading train:  57%|█████▋    | 262/456 [04:26<03:30,  1.09s/it]Loading train:  58%|█████▊    | 263/456 [04:27<03:29,  1.09s/it]Loading train:  58%|█████▊    | 264/456 [04:28<03:24,  1.06s/it]Loading train:  58%|█████▊    | 265/456 [04:30<03:36,  1.14s/it]Loading train:  58%|█████▊    | 266/456 [04:31<03:32,  1.12s/it]Loading train:  59%|█████▊    | 267/456 [04:32<03:25,  1.08s/it]Loading train:  59%|█████▉    | 268/456 [04:33<03:19,  1.06s/it]Loading train:  59%|█████▉    | 269/456 [04:34<03:12,  1.03s/it]Loading train:  59%|█████▉    | 270/456 [04:35<02:56,  1.05it/s]Loading train:  59%|█████▉    | 271/456 [04:35<02:54,  1.06it/s]Loading train:  60%|█████▉    | 272/456 [04:36<02:55,  1.05it/s]Loading train:  60%|█████▉    | 273/456 [04:37<02:51,  1.06it/s]Loading train:  60%|██████    | 274/456 [04:39<03:03,  1.01s/it]Loading train:  60%|██████    | 275/456 [04:40<03:04,  1.02s/it]Loading train:  61%|██████    | 276/456 [04:41<03:06,  1.04s/it]Loading train:  61%|██████    | 277/456 [04:42<03:11,  1.07s/it]Loading train:  61%|██████    | 278/456 [04:43<03:01,  1.02s/it]Loading train:  61%|██████    | 279/456 [04:44<03:03,  1.04s/it]Loading train:  61%|██████▏   | 280/456 [04:45<03:02,  1.04s/it]Loading train:  62%|██████▏   | 281/456 [04:46<03:00,  1.03s/it]Loading train:  62%|██████▏   | 282/456 [04:47<02:49,  1.03it/s]Loading train:  62%|██████▏   | 283/456 [04:47<02:37,  1.10it/s]Loading train:  62%|██████▏   | 284/456 [04:48<02:40,  1.07it/s]Loading train:  62%|██████▎   | 285/456 [04:49<02:47,  1.02it/s]Loading train:  63%|██████▎   | 286/456 [04:51<02:49,  1.00it/s]Loading train:  63%|██████▎   | 287/456 [04:52<02:49,  1.00s/it]Loading train:  63%|██████▎   | 288/456 [04:52<02:43,  1.03it/s]Loading train:  63%|██████▎   | 289/456 [04:53<02:37,  1.06it/s]Loading train:  64%|██████▎   | 290/456 [04:54<02:38,  1.05it/s]Loading train:  64%|██████▍   | 291/456 [04:55<02:35,  1.06it/s]Loading train:  64%|██████▍   | 292/456 [04:56<02:31,  1.08it/s]Loading train:  64%|██████▍   | 293/456 [04:57<02:18,  1.18it/s]Loading train:  64%|██████▍   | 294/456 [04:57<02:11,  1.23it/s]Loading train:  65%|██████▍   | 295/456 [04:58<02:15,  1.19it/s]Loading train:  65%|██████▍   | 296/456 [04:59<02:15,  1.18it/s]Loading train:  65%|██████▌   | 297/456 [05:00<02:17,  1.15it/s]Loading train:  65%|██████▌   | 298/456 [05:01<02:11,  1.20it/s]Loading train:  66%|██████▌   | 299/456 [05:02<02:12,  1.18it/s]Loading train:  66%|██████▌   | 300/456 [05:03<02:16,  1.14it/s]Loading train:  66%|██████▌   | 301/456 [05:04<02:32,  1.02it/s]Loading train:  66%|██████▌   | 302/456 [05:05<02:42,  1.06s/it]Loading train:  66%|██████▋   | 303/456 [05:06<02:49,  1.11s/it]Loading train:  67%|██████▋   | 304/456 [05:08<02:50,  1.12s/it]Loading train:  67%|██████▋   | 305/456 [05:09<02:46,  1.10s/it]Loading train:  67%|██████▋   | 306/456 [05:10<02:38,  1.06s/it]Loading train:  67%|██████▋   | 307/456 [05:11<02:44,  1.11s/it]Loading train:  68%|██████▊   | 308/456 [05:12<02:44,  1.11s/it]Loading train:  68%|██████▊   | 309/456 [05:13<02:50,  1.16s/it]Loading train:  68%|██████▊   | 310/456 [05:15<03:00,  1.24s/it]Loading train:  68%|██████▊   | 311/456 [05:16<03:11,  1.32s/it]Loading train:  68%|██████▊   | 312/456 [05:17<03:00,  1.26s/it]Loading train:  69%|██████▊   | 313/456 [05:18<02:54,  1.22s/it]Loading train:  69%|██████▉   | 314/456 [05:20<02:50,  1.20s/it]Loading train:  69%|██████▉   | 315/456 [05:21<02:53,  1.23s/it]Loading train:  69%|██████▉   | 316/456 [05:22<02:39,  1.14s/it]Loading train:  70%|██████▉   | 317/456 [05:23<02:35,  1.12s/it]Loading train:  70%|██████▉   | 318/456 [05:24<02:35,  1.12s/it]Loading train:  70%|██████▉   | 319/456 [05:25<02:28,  1.09s/it]Loading train:  70%|███████   | 320/456 [05:26<02:32,  1.12s/it]Loading train:  70%|███████   | 321/456 [05:27<02:25,  1.07s/it]Loading train:  71%|███████   | 322/456 [05:28<02:30,  1.12s/it]Loading train:  71%|███████   | 323/456 [05:29<02:26,  1.10s/it]Loading train:  71%|███████   | 324/456 [05:31<02:24,  1.09s/it]Loading train:  71%|███████▏  | 325/456 [05:31<02:14,  1.02s/it]Loading train:  71%|███████▏  | 326/456 [05:32<02:15,  1.04s/it]Loading train:  72%|███████▏  | 327/456 [05:33<02:12,  1.03s/it]Loading train:  72%|███████▏  | 328/456 [05:34<02:05,  1.02it/s]Loading train:  72%|███████▏  | 329/456 [05:35<02:01,  1.05it/s]Loading train:  72%|███████▏  | 330/456 [05:36<01:58,  1.06it/s]Loading train:  73%|███████▎  | 331/456 [05:37<02:07,  1.02s/it]Loading train:  73%|███████▎  | 332/456 [05:39<02:12,  1.06s/it]Loading train:  73%|███████▎  | 333/456 [05:40<02:09,  1.05s/it]Loading train:  73%|███████▎  | 334/456 [05:40<02:05,  1.03s/it]Loading train:  73%|███████▎  | 335/456 [05:41<02:00,  1.00it/s]Loading train:  74%|███████▎  | 336/456 [05:42<02:02,  1.02s/it]Loading train:  74%|███████▍  | 337/456 [05:43<01:57,  1.01it/s]Loading train:  74%|███████▍  | 338/456 [05:45<02:01,  1.03s/it]Loading train:  74%|███████▍  | 339/456 [05:45<01:51,  1.05it/s]Loading train:  75%|███████▍  | 340/456 [05:47<01:59,  1.03s/it]Loading train:  75%|███████▍  | 341/456 [05:48<02:04,  1.08s/it]Loading train:  75%|███████▌  | 342/456 [05:49<02:05,  1.10s/it]Loading train:  75%|███████▌  | 343/456 [05:50<02:08,  1.14s/it]Loading train:  75%|███████▌  | 344/456 [05:51<02:06,  1.13s/it]Loading train:  76%|███████▌  | 345/456 [05:52<01:55,  1.04s/it]Loading train:  76%|███████▌  | 346/456 [05:53<02:07,  1.16s/it]Loading train:  76%|███████▌  | 347/456 [05:55<02:02,  1.12s/it]Loading train:  76%|███████▋  | 348/456 [05:56<02:02,  1.13s/it]Loading train:  77%|███████▋  | 349/456 [05:57<01:57,  1.10s/it]Loading train:  77%|███████▋  | 350/456 [05:58<01:47,  1.02s/it]Loading train:  77%|███████▋  | 351/456 [05:58<01:44,  1.00it/s]Loading train:  77%|███████▋  | 352/456 [06:00<01:51,  1.08s/it]Loading train:  77%|███████▋  | 353/456 [06:01<01:49,  1.06s/it]Loading train:  78%|███████▊  | 354/456 [06:02<01:47,  1.06s/it]Loading train:  78%|███████▊  | 355/456 [06:03<01:57,  1.17s/it]Loading train:  78%|███████▊  | 356/456 [06:04<01:48,  1.09s/it]Loading train:  78%|███████▊  | 357/456 [06:05<01:52,  1.13s/it]Loading train:  79%|███████▊  | 358/456 [06:07<01:54,  1.16s/it]Loading train:  79%|███████▊  | 359/456 [06:08<01:59,  1.24s/it]Loading train:  79%|███████▉  | 360/456 [06:09<01:55,  1.21s/it]Loading train:  79%|███████▉  | 361/456 [06:10<01:52,  1.19s/it]Loading train:  79%|███████▉  | 362/456 [06:12<01:53,  1.21s/it]Loading train:  80%|███████▉  | 363/456 [06:13<01:51,  1.20s/it]Loading train:  80%|███████▉  | 364/456 [06:14<01:47,  1.17s/it]Loading train:  80%|████████  | 365/456 [06:15<01:47,  1.18s/it]Loading train:  80%|████████  | 366/456 [06:16<01:42,  1.14s/it]Loading train:  80%|████████  | 367/456 [06:17<01:42,  1.15s/it]Loading train:  81%|████████  | 368/456 [06:19<01:54,  1.30s/it]Loading train:  81%|████████  | 369/456 [06:20<01:55,  1.33s/it]Loading train:  81%|████████  | 370/456 [06:22<01:59,  1.39s/it]Loading train:  81%|████████▏ | 371/456 [06:23<01:53,  1.34s/it]Loading train:  82%|████████▏ | 372/456 [06:24<01:43,  1.23s/it]Loading train:  82%|████████▏ | 373/456 [06:26<01:57,  1.41s/it]Loading train:  82%|████████▏ | 374/456 [06:28<02:08,  1.57s/it]Loading train:  82%|████████▏ | 375/456 [06:29<02:08,  1.59s/it]Loading train:  82%|████████▏ | 376/456 [06:31<02:06,  1.59s/it]Loading train:  83%|████████▎ | 377/456 [06:33<02:15,  1.71s/it]Loading train:  83%|████████▎ | 378/456 [06:35<02:16,  1.75s/it]Loading train:  83%|████████▎ | 379/456 [06:36<02:06,  1.65s/it]Loading train:  83%|████████▎ | 380/456 [06:38<01:57,  1.55s/it]Loading train:  84%|████████▎ | 381/456 [06:39<01:43,  1.38s/it]Loading train:  84%|████████▍ | 382/456 [06:40<01:48,  1.46s/it]Loading train:  84%|████████▍ | 383/456 [06:42<01:49,  1.49s/it]Loading train:  84%|████████▍ | 384/456 [06:43<01:50,  1.54s/it]Loading train:  84%|████████▍ | 385/456 [06:45<01:47,  1.52s/it]Loading train:  85%|████████▍ | 386/456 [06:46<01:44,  1.50s/it]Loading train:  85%|████████▍ | 387/456 [06:48<01:45,  1.53s/it]Loading train:  85%|████████▌ | 388/456 [06:49<01:40,  1.48s/it]Loading train:  85%|████████▌ | 389/456 [06:51<01:34,  1.42s/it]Loading train:  86%|████████▌ | 390/456 [06:52<01:26,  1.30s/it]Loading train:  86%|████████▌ | 391/456 [06:53<01:30,  1.39s/it]Loading train:  86%|████████▌ | 392/456 [06:55<01:30,  1.41s/it]Loading train:  86%|████████▌ | 393/456 [06:56<01:31,  1.45s/it]Loading train:  86%|████████▋ | 394/456 [06:58<01:32,  1.49s/it]Loading train:  87%|████████▋ | 395/456 [06:59<01:21,  1.33s/it]Loading train:  87%|████████▋ | 396/456 [07:00<01:19,  1.33s/it]Loading train:  87%|████████▋ | 397/456 [07:02<01:21,  1.38s/it]Loading train:  87%|████████▋ | 398/456 [07:03<01:17,  1.34s/it]Loading train:  88%|████████▊ | 399/456 [07:04<01:17,  1.36s/it]Loading train:  88%|████████▊ | 400/456 [07:06<01:16,  1.36s/it]Loading train:  88%|████████▊ | 401/456 [07:07<01:12,  1.31s/it]Loading train:  88%|████████▊ | 402/456 [07:08<01:10,  1.31s/it]Loading train:  88%|████████▊ | 403/456 [07:09<01:09,  1.31s/it]Loading train:  89%|████████▊ | 404/456 [07:11<01:10,  1.35s/it]Loading train:  89%|████████▉ | 405/456 [07:12<01:08,  1.34s/it]Loading train:  89%|████████▉ | 406/456 [07:13<01:02,  1.26s/it]Loading train:  89%|████████▉ | 407/456 [07:15<01:04,  1.31s/it]Loading train:  89%|████████▉ | 408/456 [07:16<01:02,  1.31s/it]Loading train:  90%|████████▉ | 409/456 [07:17<01:00,  1.28s/it]Loading train:  90%|████████▉ | 410/456 [07:19<01:00,  1.31s/it]Loading train:  90%|█████████ | 411/456 [07:20<00:56,  1.26s/it]Loading train:  90%|█████████ | 412/456 [07:21<00:53,  1.23s/it]Loading train:  91%|█████████ | 413/456 [07:22<00:53,  1.24s/it]Loading train:  91%|█████████ | 414/456 [07:23<00:52,  1.24s/it]Loading train:  91%|█████████ | 415/456 [07:25<00:52,  1.28s/it]Loading train:  91%|█████████ | 416/456 [07:26<00:55,  1.38s/it]Loading train:  91%|█████████▏| 417/456 [07:27<00:49,  1.27s/it]Loading train:  92%|█████████▏| 418/456 [07:29<00:48,  1.27s/it]Loading train:  92%|█████████▏| 419/456 [07:30<00:49,  1.34s/it]Loading train:  92%|█████████▏| 420/456 [07:31<00:46,  1.30s/it]Loading train:  92%|█████████▏| 421/456 [07:33<00:47,  1.34s/it]Loading train:  93%|█████████▎| 422/456 [07:34<00:44,  1.32s/it]Loading train:  93%|█████████▎| 423/456 [07:36<00:46,  1.42s/it]Loading train:  93%|█████████▎| 424/456 [07:37<00:47,  1.48s/it]Loading train:  93%|█████████▎| 425/456 [07:39<00:47,  1.53s/it]Loading train:  93%|█████████▎| 426/456 [07:40<00:43,  1.46s/it]Loading train:  94%|█████████▎| 427/456 [07:42<00:44,  1.52s/it]Loading train:  94%|█████████▍| 428/456 [07:44<00:45,  1.62s/it]Loading train:  94%|█████████▍| 429/456 [07:46<00:44,  1.66s/it]Loading train:  94%|█████████▍| 430/456 [07:47<00:41,  1.60s/it]Loading train:  95%|█████████▍| 431/456 [07:48<00:38,  1.53s/it]Loading train:  95%|█████████▍| 432/456 [07:50<00:39,  1.66s/it]Loading train:  95%|█████████▍| 433/456 [07:52<00:38,  1.66s/it]Loading train:  95%|█████████▌| 434/456 [07:53<00:35,  1.59s/it]Loading train:  95%|█████████▌| 435/456 [07:55<00:33,  1.58s/it]Loading train:  96%|█████████▌| 436/456 [07:56<00:29,  1.48s/it]Loading train:  96%|█████████▌| 437/456 [07:58<00:27,  1.45s/it]Loading train:  96%|█████████▌| 438/456 [07:59<00:26,  1.47s/it]Loading train:  96%|█████████▋| 439/456 [08:00<00:24,  1.42s/it]Loading train:  96%|█████████▋| 440/456 [08:02<00:22,  1.39s/it]Loading train:  97%|█████████▋| 441/456 [08:03<00:19,  1.29s/it]Loading train:  97%|█████████▋| 442/456 [08:04<00:16,  1.18s/it]Loading train:  97%|█████████▋| 443/456 [08:05<00:15,  1.16s/it]Loading train:  97%|█████████▋| 444/456 [08:06<00:14,  1.19s/it]Loading train:  98%|█████████▊| 445/456 [08:07<00:12,  1.17s/it]Loading train:  98%|█████████▊| 446/456 [08:09<00:12,  1.24s/it]Loading train:  98%|█████████▊| 447/456 [08:10<00:11,  1.27s/it]Loading train:  98%|█████████▊| 448/456 [08:11<00:10,  1.28s/it]Loading train:  98%|█████████▊| 449/456 [08:12<00:08,  1.24s/it]Loading train:  99%|█████████▊| 450/456 [08:14<00:07,  1.26s/it]Loading train:  99%|█████████▉| 451/456 [08:15<00:06,  1.40s/it]Loading train:  99%|█████████▉| 452/456 [08:17<00:05,  1.50s/it]Loading train:  99%|█████████▉| 453/456 [08:19<00:04,  1.45s/it]Loading train: 100%|█████████▉| 454/456 [08:20<00:02,  1.45s/it]Loading train: 100%|█████████▉| 455/456 [08:21<00:01,  1.36s/it]Loading train: 100%|██████████| 456/456 [08:23<00:00,  1.37s/it]
concatenating: train:   0%|          | 0/456 [00:00<?, ?it/s]concatenating: train:   1%|▏         | 6/456 [00:00<00:11, 40.77it/s]concatenating: train:   2%|▏         | 10/456 [00:00<00:11, 37.30it/s]concatenating: train:   3%|▎         | 13/456 [00:00<00:12, 34.34it/s]concatenating: train:   4%|▍         | 18/456 [00:00<00:11, 37.23it/s]concatenating: train:   5%|▌         | 24/456 [00:00<00:10, 41.32it/s]concatenating: train:   6%|▋         | 29/456 [00:00<00:10, 41.79it/s]concatenating: train:   7%|▋         | 34/456 [00:00<00:10, 41.38it/s]concatenating: train:   8%|▊         | 38/456 [00:00<00:11, 37.71it/s]concatenating: train:   9%|▉         | 43/456 [00:01<00:10, 38.82it/s]concatenating: train:  11%|█         | 49/456 [00:01<00:09, 43.05it/s]concatenating: train:  12%|█▏        | 55/456 [00:01<00:08, 45.74it/s]concatenating: train:  14%|█▎        | 62/456 [00:01<00:08, 48.50it/s]concatenating: train:  15%|█▍        | 67/456 [00:01<00:09, 42.46it/s]concatenating: train:  16%|█▌        | 72/456 [00:01<00:08, 43.54it/s]concatenating: train:  17%|█▋        | 79/456 [00:01<00:07, 47.90it/s]concatenating: train:  20%|█▉        | 89/456 [00:01<00:06, 55.64it/s]concatenating: train:  21%|██        | 96/456 [00:02<00:06, 54.26it/s]concatenating: train:  22%|██▏       | 102/456 [00:02<00:08, 41.67it/s]concatenating: train:  24%|██▎       | 108/456 [00:02<00:07, 44.89it/s]concatenating: train:  25%|██▌       | 115/456 [00:02<00:06, 49.45it/s]concatenating: train:  27%|██▋       | 122/456 [00:02<00:06, 53.72it/s]concatenating: train:  28%|██▊       | 128/456 [00:02<00:06, 53.11it/s]concatenating: train:  30%|███       | 137/456 [00:02<00:05, 60.00it/s]concatenating: train:  32%|███▏      | 144/456 [00:03<00:06, 46.53it/s]concatenating: train:  33%|███▎      | 150/456 [00:03<00:07, 43.51it/s]concatenating: train:  36%|███▌      | 163/456 [00:03<00:05, 54.09it/s]concatenating: train:  39%|███▊      | 176/456 [00:03<00:04, 64.85it/s]concatenating: train:  41%|████▏     | 189/456 [00:03<00:03, 76.25it/s]concatenating: train:  44%|████▎     | 199/456 [00:03<00:03, 78.22it/s]concatenating: train:  46%|████▌     | 209/456 [00:03<00:03, 79.82it/s]concatenating: train:  48%|████▊     | 219/456 [00:04<00:04, 53.05it/s]concatenating: train:  50%|████▉     | 227/456 [00:04<00:04, 57.00it/s]concatenating: train:  52%|█████▏    | 238/456 [00:04<00:03, 66.56it/s]concatenating: train:  55%|█████▍    | 250/456 [00:04<00:02, 76.23it/s]concatenating: train:  57%|█████▋    | 260/456 [00:04<00:03, 61.56it/s]concatenating: train:  59%|█████▉    | 268/456 [00:04<00:03, 51.36it/s]concatenating: train:  60%|██████    | 275/456 [00:05<00:03, 46.48it/s]concatenating: train:  62%|██████▏   | 284/456 [00:05<00:03, 53.97it/s]concatenating: train:  64%|██████▍   | 291/456 [00:05<00:02, 55.21it/s]concatenating: train:  65%|██████▌   | 298/456 [00:05<00:02, 57.21it/s]concatenating: train:  67%|██████▋   | 305/456 [00:05<00:02, 58.70it/s]concatenating: train:  68%|██████▊   | 312/456 [00:05<00:02, 48.38it/s]concatenating: train:  70%|██████▉   | 318/456 [00:05<00:03, 41.85it/s]concatenating: train:  71%|███████   | 323/456 [00:05<00:03, 42.28it/s]concatenating: train:  72%|███████▏  | 328/456 [00:06<00:03, 41.26it/s]concatenating: train:  74%|███████▍  | 338/456 [00:06<00:02, 49.46it/s]concatenating: train:  76%|███████▌  | 345/456 [00:06<00:02, 53.72it/s]concatenating: train:  78%|███████▊  | 357/456 [00:06<00:01, 62.44it/s]concatenating: train:  80%|████████  | 365/456 [00:06<00:01, 56.08it/s]concatenating: train:  82%|████████▏ | 372/456 [00:06<00:01, 43.60it/s]concatenating: train:  84%|████████▍ | 382/456 [00:06<00:01, 52.47it/s]concatenating: train:  86%|████████▌ | 393/456 [00:07<00:01, 61.87it/s]concatenating: train:  89%|████████▉ | 406/456 [00:07<00:00, 72.85it/s]concatenating: train:  92%|█████████▏| 419/456 [00:07<00:00, 83.28it/s]concatenating: train:  94%|█████████▍| 430/456 [00:07<00:00, 87.26it/s]concatenating: train:  97%|█████████▋| 441/456 [00:07<00:00, 82.95it/s]concatenating: train:  99%|█████████▉| 451/456 [00:07<00:00, 81.42it/s]concatenating: train: 100%|██████████| 456/456 [00:07<00:00, 59.04it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:01<00:03,  1.32s/it]Loading test:  50%|█████     | 2/4 [00:02<00:02,  1.24s/it]Loading test:  75%|███████▌  | 3/4 [00:03<00:01,  1.28s/it]Loading test: 100%|██████████| 4/4 [00:05<00:00,  1.49s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 38.23it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 56, 88, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 56, 88, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 56, 88, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 56, 88, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 56, 88, 10)   910         activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 88, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 56, 88, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 56, 88, 11)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 28, 44, 11)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28, 44, 11)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 44, 20)   2000        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 44, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 44, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 44, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 28, 44, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 28, 44, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 44, 31)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 22, 31)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 14, 22, 31)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 14, 22, 40)   11200       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 14, 22, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 14, 22, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 14, 22, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 14, 22, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 14, 22, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 14, 22, 71)   0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 14, 22, 71)   0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 28, 44, 20)   5700        dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 28, 44, 51)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 28, 44, 20)   9200        concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 28, 44, 20)   80          conv2d_7[0][0]                   
__________________________________________________________________________________________________2019-07-07 14:14:16.401752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 14:14:16.401907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 14:14:16.401952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 14:14:16.401966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 14:14:16.402975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

activation_7 (Activation)       (None, 28, 44, 20)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 28, 44, 20)   3620        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 28, 44, 20)   80          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 28, 44, 20)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 28, 44, 71)   0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 28, 44, 71)   0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 56, 88, 10)   2850        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 88, 21)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 56, 88, 10)   1900        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 56, 88, 10)   40          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 88, 10)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 56, 88, 10)   910         activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 56, 88, 10)   40          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 88, 10)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 88, 31)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 56, 88, 31)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 56, 88, 13)   416         dropout_5[0][0]                  
==================================================================================================
Total params: 57,666
Trainable params: 57,266
Non-trainable params: 400
__________________________________________________________________________________________________
----- /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/model_weights.h5
 --- initialized from Model_3T /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2
------------------------------------------------------------------
class_weights [6.11551387e-02 2.80417065e-02 7.36205865e-02 1.00307357e-02
 2.46459952e-02 6.20541010e-03 7.62197172e-02 1.11197709e-01
 6.32300513e-02 1.29380128e-02 3.51235945e-01 1.81283761e-01
 1.95230038e-04]
Train on 17190 samples, validate on 142 samples
Epoch 1/300
 - 24s - loss: 1.4648 - acc: 0.9472 - mDice: 0.5604 - val_loss: 1.1542 - val_acc: 0.9663 - val_mDice: 0.6462

Epoch 00001: val_mDice improved from -inf to 0.64621, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 16s - loss: 1.3121 - acc: 0.9493 - mDice: 0.5837 - val_loss: 1.1407 - val_acc: 0.9670 - val_mDice: 0.6562

Epoch 00002: val_mDice improved from 0.64621 to 0.65620, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 15s - loss: 1.2697 - acc: 0.9499 - mDice: 0.5936 - val_loss: 1.1594 - val_acc: 0.9658 - val_mDice: 0.6537

Epoch 00003: val_mDice did not improve from 0.65620
Epoch 4/300
 - 14s - loss: 1.2388 - acc: 0.9505 - mDice: 0.6008 - val_loss: 1.1774 - val_acc: 0.9652 - val_mDice: 0.6520

Epoch 00004: val_mDice did not improve from 0.65620
Epoch 5/300
 - 14s - loss: 1.2185 - acc: 0.9509 - mDice: 0.6061 - val_loss: 1.1487 - val_acc: 0.9659 - val_mDice: 0.6587

Epoch 00005: val_mDice improved from 0.65620 to 0.65871, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 16s - loss: 1.1992 - acc: 0.9513 - mDice: 0.6114 - val_loss: 1.1547 - val_acc: 0.9666 - val_mDice: 0.6614

Epoch 00006: val_mDice improved from 0.65871 to 0.66135, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 15s - loss: 1.1888 - acc: 0.9514 - mDice: 0.6142 - val_loss: 1.1586 - val_acc: 0.9653 - val_mDice: 0.6633

Epoch 00007: val_mDice improved from 0.66135 to 0.66332, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 14s - loss: 1.1783 - acc: 0.9517 - mDice: 0.6174 - val_loss: 1.1547 - val_acc: 0.9648 - val_mDice: 0.6590

Epoch 00008: val_mDice did not improve from 0.66332
Epoch 9/300
 - 16s - loss: 1.1659 - acc: 0.9519 - mDice: 0.6211 - val_loss: 1.1744 - val_acc: 0.9662 - val_mDice: 0.6600

Epoch 00009: val_mDice did not improve from 0.66332
Epoch 10/300
 - 15s - loss: 1.1572 - acc: 0.9521 - mDice: 0.6229 - val_loss: 1.1673 - val_acc: 0.9661 - val_mDice: 0.6636

Epoch 00010: val_mDice improved from 0.66332 to 0.66364, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 11/300
 - 14s - loss: 1.1494 - acc: 0.9522 - mDice: 0.6254 - val_loss: 1.1560 - val_acc: 0.9666 - val_mDice: 0.6689

Epoch 00011: val_mDice improved from 0.66364 to 0.66892, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 12/300
 - 16s - loss: 1.1464 - acc: 0.9523 - mDice: 0.6266 - val_loss: 1.1573 - val_acc: 0.9661 - val_mDice: 0.6688

Epoch 00012: val_mDice did not improve from 0.66892
Epoch 13/300
 - 15s - loss: 1.1373 - acc: 0.9525 - mDice: 0.6292 - val_loss: 1.1806 - val_acc: 0.9655 - val_mDice: 0.6689

Epoch 00013: val_mDice improved from 0.66892 to 0.66894, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 14/300
 - 16s - loss: 1.1350 - acc: 0.9527 - mDice: 0.6299 - val_loss: 1.1857 - val_acc: 0.9665 - val_mDice: 0.6682

Epoch 00014: val_mDice did not improve from 0.66894
Epoch 15/300
 - 15s - loss: 1.1253 - acc: 0.9527 - mDice: 0.6330 - val_loss: 1.1875 - val_acc: 0.9663 - val_mDice: 0.6714

Epoch 00015: val_mDice improved from 0.66894 to 0.67142, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 16/300
 - 14s - loss: 1.1231 - acc: 0.9528 - mDice: 0.6335 - val_loss: 1.2047 - val_acc: 0.9664 - val_mDice: 0.6695

Epoch 00016: val_mDice did not improve from 0.67142
Epoch 17/300
 - 16s - loss: 1.1161 - acc: 0.9530 - mDice: 0.6355 - val_loss: 1.1638 - val_acc: 0.9663 - val_mDice: 0.6748

Epoch 00017: val_mDice improved from 0.67142 to 0.67478, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 18/300
 - 14s - loss: 1.1120 - acc: 0.9530 - mDice: 0.6369 - val_loss: 1.1878 - val_acc: 0.9668 - val_mDice: 0.6720

Epoch 00018: val_mDice did not improve from 0.67478
Epoch 19/300
 - 15s - loss: 1.1090 - acc: 0.9531 - mDice: 0.6379 - val_loss: 1.1940 - val_acc: 0.9661 - val_mDice: 0.6744

Epoch 00019: val_mDice did not improve from 0.67478
Epoch 20/300
 - 14s - loss: 1.1064 - acc: 0.9532 - mDice: 0.6386 - val_loss: 1.1791 - val_acc: 0.9663 - val_mDice: 0.6716

Epoch 00020: val_mDice did not improve from 0.67478
Epoch 21/300
 - 15s - loss: 1.1006 - acc: 0.9533 - mDice: 0.6402 - val_loss: 1.2146 - val_acc: 0.9655 - val_mDice: 0.6742

Epoch 00021: val_mDice did not improve from 0.67478
Epoch 22/300
 - 14s - loss: 1.0965 - acc: 0.9534 - mDice: 0.6417 - val_loss: 1.1992 - val_acc: 0.9656 - val_mDice: 0.6719

Epoch 00022: val_mDice did not improve from 0.67478
Epoch 23/300
 - 14s - loss: 1.0951 - acc: 0.9534 - mDice: 0.6419 - val_loss: 1.2200 - val_acc: 0.9652 - val_mDice: 0.6735

Epoch 00023: val_mDice did not improve from 0.67478
Epoch 24/300
 - 13s - loss: 1.0927 - acc: 0.9535 - mDice: 0.6426 - val_loss: 1.1969 - val_acc: 0.9661 - val_mDice: 0.6759

Epoch 00024: val_mDice improved from 0.67478 to 0.67593, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 25/300
 - 14s - loss: 1.0891 - acc: 0.9536 - mDice: 0.6442 - val_loss: 1.2178 - val_acc: 0.9663 - val_mDice: 0.6703

Epoch 00025: val_mDice did not improve from 0.67593
Epoch 26/300
 - 15s - loss: 1.0858 - acc: 0.9536 - mDice: 0.6450 - val_loss: 1.2384 - val_acc: 0.9658 - val_mDice: 0.6714

Epoch 00026: val_mDice did not improve from 0.67593
Epoch 27/300
 - 14s - loss: 1.0820 - acc: 0.9538 - mDice: 0.6462 - val_loss: 1.2386 - val_acc: 0.9657 - val_mDice: 0.6684

Epoch 00027: val_mDice did not improve from 0.67593
Epoch 28/300
 - 14s - loss: 1.0837 - acc: 0.9537 - mDice: 0.6458 - val_loss: 1.2050 - val_acc: 0.9659 - val_mDice: 0.6728

Epoch 00028: val_mDice did not improve from 0.67593
Epoch 29/300
 - 14s - loss: 1.0785 - acc: 0.9537 - mDice: 0.6473 - val_loss: 1.2107 - val_acc: 0.9661 - val_mDice: 0.6744

Epoch 00029: val_mDice did not improve from 0.67593
Epoch 30/300
 - 14s - loss: 1.0787 - acc: 0.9538 - mDice: 0.6477 - val_loss: 1.2186 - val_acc: 0.9657 - val_mDice: 0.6721

Epoch 00030: val_mDice did not improve from 0.67593
Epoch 31/300
 - 15s - loss: 1.0748 - acc: 0.9539 - mDice: 0.6486 - val_loss: 1.2099 - val_acc: 0.9662 - val_mDice: 0.6789

Epoch 00031: val_mDice improved from 0.67593 to 0.67889, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 32/300
 - 14s - loss: 1.0738 - acc: 0.9539 - mDice: 0.6487 - val_loss: 1.2232 - val_acc: 0.9658 - val_mDice: 0.6731

Epoch 00032: val_mDice did not improve from 0.67889
Epoch 33/300
 - 15s - loss: 1.0707 - acc: 0.9540 - mDice: 0.6501 - val_loss: 1.2185 - val_acc: 0.9660 - val_mDice: 0.6710

Epoch 00033: val_mDice did not improve from 0.67889
Epoch 34/300
 - 14s - loss: 1.0680 - acc: 0.9540 - mDice: 0.6506 - val_loss: 1.2272 - val_acc: 0.9652 - val_mDice: 0.6760

Epoch 00034: val_mDice did not improve from 0.67889
Epoch 35/300
 - 15s - loss: 1.0653 - acc: 0.9540 - mDice: 0.6514 - val_loss: 1.2470 - val_acc: 0.9655 - val_mDice: 0.6725

Epoch 00035: val_mDice did not improve from 0.67889
Epoch 36/300
 - 16s - loss: 1.0639 - acc: 0.9542 - mDice: 0.6518 - val_loss: 1.2424 - val_acc: 0.9661 - val_mDice: 0.6766

Epoch 00036: val_mDice did not improve from 0.67889
Epoch 37/300
 - 15s - loss: 1.0637 - acc: 0.9541 - mDice: 0.6521 - val_loss: 1.2225 - val_acc: 0.9662 - val_mDice: 0.6735

Epoch 00037: val_mDice did not improve from 0.67889
Epoch 38/300
 - 16s - loss: 1.0605 - acc: 0.9541 - mDice: 0.6531 - val_loss: 1.2438 - val_acc: 0.9665 - val_mDice: 0.6779

Epoch 00038: val_mDice did not improve from 0.67889
Epoch 39/300
 - 15s - loss: 1.0575 - acc: 0.9542 - mDice: 0.6537 - val_loss: 1.2520 - val_acc: 0.9661 - val_mDice: 0.6769

Epoch 00039: val_mDice did not improve from 0.67889
Epoch 40/300
 - 14s - loss: 1.0591 - acc: 0.9542 - mDice: 0.6534 - val_loss: 1.2411 - val_acc: 0.9650 - val_mDice: 0.6757

Epoch 00040: val_mDice did not improve from 0.67889
Epoch 41/300
 - 15s - loss: 1.0549 - acc: 0.9543 - mDice: 0.6546 - val_loss: 1.2531 - val_acc: 0.9659 - val_mDice: 0.6743

Epoch 00041: val_mDice did not improve from 0.67889
Epoch 42/300
 - 15s - loss: 1.0552 - acc: 0.9543 - mDice: 0.6543 - val_loss: 1.2350 - val_acc: 0.9661 - val_mDice: 0.6751

Epoch 00042: val_mDice did not improve from 0.67889
Epoch 43/300
 - 14s - loss: 1.0517 - acc: 0.9543 - mDice: 0.6560 - val_loss: 1.2273 - val_acc: 0.9661 - val_mDice: 0.6766

Epoch 00043: val_mDice did not improve from 0.67889
Epoch 44/300
 - 15s - loss: 1.0523 - acc: 0.9544 - mDice: 0.6556 - val_loss: 1.2565 - val_acc: 0.9660 - val_mDice: 0.6746

Epoch 00044: val_mDice did not improve from 0.67889
Epoch 45/300
 - 15s - loss: 1.0484 - acc: 0.9545 - mDice: 0.6570 - val_loss: 1.2226 - val_acc: 0.9660 - val_mDice: 0.6797

Epoch 00045: val_mDice improved from 0.67889 to 0.67973, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 46/300
 - 14s - loss: 1.0482 - acc: 0.9545 - mDice: 0.6567 - val_loss: 1.2156 - val_acc: 0.9658 - val_mDice: 0.6798

Epoch 00046: val_mDice improved from 0.67973 to 0.67983, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 47/300
 - 14s - loss: 1.0440 - acc: 0.9545 - mDice: 0.6581 - val_loss: 1.2641 - val_acc: 0.9653 - val_mDice: 0.6756

Epoch 00047: val_mDice did not improve from 0.67983
Epoch 48/300
 - 16s - loss: 1.0441 - acc: 0.9545 - mDice: 0.6582 - val_loss: 1.2402 - val_acc: 0.9654 - val_mDice: 0.6726

Epoch 00048: val_mDice did not improve from 0.67983
Epoch 49/300
 - 14s - loss: 1.0428 - acc: 0.9546 - mDice: 0.6587 - val_loss: 1.2455 - val_acc: 0.9653 - val_mDice: 0.6741

Epoch 00049: val_mDice did not improve from 0.67983
Epoch 50/300
 - 14s - loss: 1.0457 - acc: 0.9545 - mDice: 0.6574 - val_loss: 1.2204 - val_acc: 0.9661 - val_mDice: 0.6763

Epoch 00050: val_mDice did not improve from 0.67983
Epoch 51/300
 - 16s - loss: 1.0404 - acc: 0.9546 - mDice: 0.6593 - val_loss: 1.2597 - val_acc: 0.9663 - val_mDice: 0.6761

Epoch 00051: val_mDice did not improve from 0.67983
Epoch 52/300
 - 15s - loss: 1.0397 - acc: 0.9546 - mDice: 0.6595 - val_loss: 1.2540 - val_acc: 0.9655 - val_mDice: 0.6775

Epoch 00052: val_mDice did not improve from 0.67983
Epoch 53/300
 - 14s - loss: 1.0392 - acc: 0.9547 - mDice: 0.6599 - val_loss: 1.2495 - val_acc: 0.9660 - val_mDice: 0.6737

Epoch 00053: val_mDice did not improve from 0.67983
Epoch 54/300
 - 15s - loss: 1.0390 - acc: 0.9547 - mDice: 0.6602 - val_loss: 1.2187 - val_acc: 0.9658 - val_mDice: 0.6752

Epoch 00054: val_mDice did not improve from 0.67983
Epoch 55/300
 - 14s - loss: 1.0376 - acc: 0.9547 - mDice: 0.6601 - val_loss: 1.2339 - val_acc: 0.9663 - val_mDice: 0.6817

Epoch 00055: val_mDice improved from 0.67983 to 0.68165, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 56/300
 - 14s - loss: 1.0343 - acc: 0.9548 - mDice: 0.6616 - val_loss: 1.2438 - val_acc: 0.9662 - val_mDice: 0.6784

Epoch 00056: val_mDice did not improve from 0.68165
Epoch 57/300
 - 14s - loss: 1.0358 - acc: 0.9548 - mDice: 0.6608 - val_loss: 1.2575 - val_acc: 0.9654 - val_mDice: 0.6783

Epoch 00057: val_mDice did not improve from 0.68165
Epoch 58/300
 - 15s - loss: 1.0350 - acc: 0.9548 - mDice: 0.6613 - val_loss: 1.2539 - val_acc: 0.9651 - val_mDice: 0.6794

Epoch 00058: val_mDice did not improve from 0.68165
Epoch 59/300
 - 13s - loss: 1.0329 - acc: 0.9548 - mDice: 0.6616 - val_loss: 1.2259 - val_acc: 0.9655 - val_mDice: 0.6807

Epoch 00059: val_mDice did not improve from 0.68165
Epoch 60/300
 - 15s - loss: 1.0333 - acc: 0.9548 - mDice: 0.6619 - val_loss: 1.2304 - val_acc: 0.9660 - val_mDice: 0.6799

Epoch 00060: val_mDice did not improve from 0.68165
Epoch 61/300
 - 13s - loss: 1.0289 - acc: 0.9549 - mDice: 0.6631 - val_loss: 1.2538 - val_acc: 0.9657 - val_mDice: 0.6783

Epoch 00061: val_mDice did not improve from 0.68165
Epoch 62/300
 - 15s - loss: 1.0290 - acc: 0.9549 - mDice: 0.6627 - val_loss: 1.2446 - val_acc: 0.9660 - val_mDice: 0.6800

Epoch 00062: val_mDice did not improve from 0.68165
Epoch 63/300
 - 13s - loss: 1.0291 - acc: 0.9549 - mDice: 0.6632 - val_loss: 1.2046 - val_acc: 0.9661 - val_mDice: 0.6790

Epoch 00063: val_mDice did not improve from 0.68165
Epoch 64/300
 - 15s - loss: 1.0257 - acc: 0.9550 - mDice: 0.6642 - val_loss: 1.2459 - val_acc: 0.9659 - val_mDice: 0.6776

Epoch 00064: val_mDice did not improve from 0.68165
Epoch 65/300
 - 14s - loss: 1.0265 - acc: 0.9550 - mDice: 0.6640 - val_loss: 1.2654 - val_acc: 0.9657 - val_mDice: 0.6809

Epoch 00065: val_mDice did not improve from 0.68165
Epoch 66/300
 - 14s - loss: 1.0269 - acc: 0.9550 - mDice: 0.6636 - val_loss: 1.2675 - val_acc: 0.9651 - val_mDice: 0.6756

Epoch 00066: val_mDice did not improve from 0.68165
Epoch 67/300
 - 14s - loss: 1.0267 - acc: 0.9550 - mDice: 0.6640 - val_loss: 1.2709 - val_acc: 0.9658 - val_mDice: 0.6808

Epoch 00067: val_mDice did not improve from 0.68165
Epoch 68/300
 - 14s - loss: 1.0228 - acc: 0.9550 - mDice: 0.6648 - val_loss: 1.2728 - val_acc: 0.9657 - val_mDice: 0.6775

Epoch 00068: val_mDice did not improve from 0.68165
Epoch 69/300
 - 14s - loss: 1.0250 - acc: 0.9550 - mDice: 0.6642 - val_loss: 1.2479 - val_acc: 0.9663 - val_mDice: 0.6802

Epoch 00069: val_mDice did not improve from 0.68165
Epoch 70/300
 - 14s - loss: 1.0238 - acc: 0.9550 - mDice: 0.6649 - val_loss: 1.2521 - val_acc: 0.9654 - val_mDice: 0.6787

Epoch 00070: val_mDice did not improve from 0.68165
Epoch 71/300
 - 14s - loss: 1.0232 - acc: 0.9551 - mDice: 0.6649 - val_loss: 1.2349 - val_acc: 0.9656 - val_mDice: 0.6736

Epoch 00071: val_mDice did not improve from 0.68165
Epoch 72/300
 - 14s - loss: 1.0213 - acc: 0.9551 - mDice: 0.6653 - val_loss: 1.2697 - val_acc: 0.9649 - val_mDice: 0.6782

Epoch 00072: val_mDice did not improve from 0.68165
Epoch 73/300
 - 14s - loss: 1.0198 - acc: 0.9551 - mDice: 0.6661 - val_loss: 1.2247 - val_acc: 0.9656 - val_mDice: 0.6789

Epoch 00073: val_mDice did not improve from 0.68165
Epoch 74/300
 - 14s - loss: 1.0198 - acc: 0.9551 - mDice: 0.6659 - val_loss: 1.2667 - val_acc: 0.9662 - val_mDice: 0.6811

Epoch 00074: val_mDice did not improve from 0.68165
Epoch 75/300
 - 14s - loss: 1.0209 - acc: 0.9552 - mDice: 0.6661 - val_loss: 1.2648 - val_acc: 0.9653 - val_mDice: 0.6754

Epoch 00075: val_mDice did not improve from 0.68165
Epoch 76/300
 - 14s - loss: 1.0190 - acc: 0.9552 - mDice: 0.6661 - val_loss: 1.2650 - val_acc: 0.9661 - val_mDice: 0.6786

Epoch 00076: val_mDice did not improve from 0.68165
Epoch 77/300
 - 14s - loss: 1.0187 - acc: 0.9552 - mDice: 0.6660 - val_loss: 1.2574 - val_acc: 0.9659 - val_mDice: 0.6775

Epoch 00077: val_mDice did not improve from 0.68165
Epoch 78/300
 - 14s - loss: 1.0140 - acc: 0.9553 - mDice: 0.6677 - val_loss: 1.2719 - val_acc: 0.9662 - val_mDice: 0.6771

Epoch 00078: val_mDice did not improve from 0.68165
Epoch 79/300
 - 15s - loss: 1.0171 - acc: 0.9552 - mDice: 0.6670 - val_loss: 1.2704 - val_acc: 0.9654 - val_mDice: 0.6722

Epoch 00079: val_mDice did not improve from 0.68165
Epoch 80/300
 - 13s - loss: 1.0161 - acc: 0.9552 - mDice: 0.6671 - val_loss: 1.2657 - val_acc: 0.9662 - val_mDice: 0.6789

Epoch 00080: val_mDice did not improve from 0.68165
Epoch 81/300
 - 15s - loss: 1.0154 - acc: 0.9553 - mDice: 0.6675 - val_loss: 1.2760 - val_acc: 0.9655 - val_mDice: 0.6801

Epoch 00081: val_mDice did not improve from 0.68165
Epoch 82/300
 - 13s - loss: 1.0127 - acc: 0.9553 - mDice: 0.6684 - val_loss: 1.2416 - val_acc: 0.9665 - val_mDice: 0.6825

Epoch 00082: val_mDice improved from 0.68165 to 0.68246, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 83/300
 - 15s - loss: 1.0164 - acc: 0.9553 - mDice: 0.6671 - val_loss: 1.2580 - val_acc: 0.9658 - val_mDice: 0.6746

Epoch 00083: val_mDice did not improve from 0.68246
Epoch 84/300
 - 14s - loss: 1.0156 - acc: 0.9553 - mDice: 0.6671 - val_loss: 1.2784 - val_acc: 0.9660 - val_mDice: 0.6803

Epoch 00084: val_mDice did not improve from 0.68246
Epoch 85/300
 - 15s - loss: 1.0128 - acc: 0.9554 - mDice: 0.6680 - val_loss: 1.2988 - val_acc: 0.9655 - val_mDice: 0.6775

Epoch 00085: val_mDice did not improve from 0.68246
Epoch 86/300
 - 14s - loss: 1.0113 - acc: 0.9554 - mDice: 0.6685 - val_loss: 1.2732 - val_acc: 0.9660 - val_mDice: 0.6802

Epoch 00086: val_mDice did not improve from 0.68246
Epoch 87/300
 - 14s - loss: 1.0123 - acc: 0.9554 - mDice: 0.6684 - val_loss: 1.2430 - val_acc: 0.9662 - val_mDice: 0.6822

Epoch 00087: val_mDice did not improve from 0.68246
Epoch 88/300
 - 13s - loss: 1.0100 - acc: 0.9554 - mDice: 0.6690 - val_loss: 1.2691 - val_acc: 0.9655 - val_mDice: 0.6828

Epoch 00088: val_mDice improved from 0.68246 to 0.68282, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 89/300
 - 15s - loss: 1.0109 - acc: 0.9555 - mDice: 0.6691 - val_loss: 1.2522 - val_acc: 0.9658 - val_mDice: 0.6813

Epoch 00089: val_mDice did not improve from 0.68282
Epoch 90/300
 - 14s - loss: 1.0082 - acc: 0.9554 - mDice: 0.6697 - val_loss: 1.3030 - val_acc: 0.9660 - val_mDice: 0.6771

Epoch 00090: val_mDice did not improve from 0.68282
Epoch 91/300
 - 14s - loss: 1.0084 - acc: 0.9555 - mDice: 0.6696 - val_loss: 1.3051 - val_acc: 0.9652 - val_mDice: 0.6757

Epoch 00091: val_mDice did not improve from 0.68282
Epoch 92/300
 - 13s - loss: 1.0082 - acc: 0.9554 - mDice: 0.6695 - val_loss: 1.2736 - val_acc: 0.9655 - val_mDice: 0.6778

Epoch 00092: val_mDice did not improve from 0.68282
Epoch 93/300
 - 15s - loss: 1.0090 - acc: 0.9555 - mDice: 0.6695 - val_loss: 1.2628 - val_acc: 0.9651 - val_mDice: 0.6763

Epoch 00093: val_mDice did not improve from 0.68282
Epoch 94/300
 - 14s - loss: 1.0071 - acc: 0.9555 - mDice: 0.6699 - val_loss: 1.2698 - val_acc: 0.9654 - val_mDice: 0.6801

Epoch 00094: val_mDice did not improve from 0.68282
Epoch 95/300
 - 15s - loss: 1.0053 - acc: 0.9555 - mDice: 0.6706 - val_loss: 1.2681 - val_acc: 0.9660 - val_mDice: 0.6810

Epoch 00095: val_mDice did not improve from 0.68282
Epoch 96/300
 - 14s - loss: 1.0054 - acc: 0.9555 - mDice: 0.6705 - val_loss: 1.2826 - val_acc: 0.9657 - val_mDice: 0.6791

Epoch 00096: val_mDice did not improve from 0.68282
Epoch 97/300
 - 14s - loss: 1.0062 - acc: 0.9555 - mDice: 0.6707 - val_loss: 1.2845 - val_acc: 0.9656 - val_mDice: 0.6757

Epoch 00097: val_mDice did not improve from 0.68282
Epoch 98/300
 - 15s - loss: 1.0046 - acc: 0.9556 - mDice: 0.6706 - val_loss: 1.2473 - val_acc: 0.9660 - val_mDice: 0.6821

Epoch 00098: val_mDice did not improve from 0.68282
Epoch 99/300
 - 14s - loss: 1.0064 - acc: 0.9556 - mDice: 0.6701 - val_loss: 1.2757 - val_acc: 0.9657 - val_mDice: 0.6778

Epoch 00099: val_mDice did not improve from 0.68282
Epoch 100/300
 - 15s - loss: 1.0031 - acc: 0.9556 - mDice: 0.6711 - val_loss: 1.2533 - val_acc: 0.9659 - val_mDice: 0.6810

Epoch 00100: val_mDice did not improve from 0.68282
Epoch 101/300
 - 14s - loss: 1.0041 - acc: 0.9556 - mDice: 0.6709 - val_loss: 1.2549 - val_acc: 0.9660 - val_mDice: 0.6815

Epoch 00101: val_mDice did not improve from 0.68282
Epoch 102/300
 - 15s - loss: 1.0029 - acc: 0.9556 - mDice: 0.6714 - val_loss: 1.2767 - val_acc: 0.9657 - val_mDice: 0.6832

Epoch 00102: val_mDice improved from 0.68282 to 0.68320, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 103/300
 - 13s - loss: 1.0041 - acc: 0.9556 - mDice: 0.6713 - val_loss: 1.2622 - val_acc: 0.9660 - val_mDice: 0.6797

Epoch 00103: val_mDice did not improve from 0.68320
Epoch 104/300
 - 14s - loss: 1.0010 - acc: 0.9557 - mDice: 0.6720 - val_loss: 1.2744 - val_acc: 0.9658 - val_mDice: 0.6797

Epoch 00104: val_mDice did not improve from 0.68320
Epoch 105/300
 - 13s - loss: 1.0029 - acc: 0.9556 - mDice: 0.6717 - val_loss: 1.2749 - val_acc: 0.9660 - val_mDice: 0.6813

Epoch 00105: val_mDice did not improve from 0.68320
Epoch 106/300
 - 14s - loss: 0.9989 - acc: 0.9557 - mDice: 0.6726 - val_loss: 1.2908 - val_acc: 0.9662 - val_mDice: 0.6807

Epoch 00106: val_mDice did not improve from 0.68320
Epoch 107/300
 - 13s - loss: 1.0014 - acc: 0.9557 - mDice: 0.6721 - val_loss: 1.2899 - val_acc: 0.9661 - val_mDice: 0.6826

Epoch 00107: val_mDice did not improve from 0.68320
Epoch 108/300
 - 13s - loss: 0.9997 - acc: 0.9557 - mDice: 0.6723 - val_loss: 1.2521 - val_acc: 0.9662 - val_mDice: 0.6800

Epoch 00108: val_mDice did not improve from 0.68320
Epoch 109/300
 - 13s - loss: 1.0012 - acc: 0.9557 - mDice: 0.6722 - val_loss: 1.2622 - val_acc: 0.9662 - val_mDice: 0.6829

Epoch 00109: val_mDice did not improve from 0.68320
Epoch 110/300
 - 13s - loss: 1.0006 - acc: 0.9557 - mDice: 0.6718 - val_loss: 1.2689 - val_acc: 0.9657 - val_mDice: 0.6825

Epoch 00110: val_mDice did not improve from 0.68320
Epoch 111/300
 - 12s - loss: 1.0003 - acc: 0.9557 - mDice: 0.6721 - val_loss: 1.2669 - val_acc: 0.9657 - val_mDice: 0.6758

Epoch 00111: val_mDice did not improve from 0.68320
Epoch 112/300
 - 14s - loss: 0.9991 - acc: 0.9557 - mDice: 0.6729 - val_loss: 1.2852 - val_acc: 0.9661 - val_mDice: 0.6784

Epoch 00112: val_mDice did not improve from 0.68320
Epoch 113/300
 - 13s - loss: 0.9990 - acc: 0.9557 - mDice: 0.6726 - val_loss: 1.2965 - val_acc: 0.9661 - val_mDice: 0.6829

Epoch 00113: val_mDice did not improve from 0.68320
Epoch 114/300
 - 12s - loss: 0.9971 - acc: 0.9558 - mDice: 0.6738 - val_loss: 1.2841 - val_acc: 0.9658 - val_mDice: 0.6788

Epoch 00114: val_mDice did not improve from 0.68320
Epoch 115/300
 - 12s - loss: 0.9980 - acc: 0.9558 - mDice: 0.6733 - val_loss: 1.2678 - val_acc: 0.9657 - val_mDice: 0.6792

Epoch 00115: val_mDice did not improve from 0.68320
Epoch 116/300
 - 12s - loss: 0.9974 - acc: 0.9558 - mDice: 0.6734 - val_loss: 1.2926 - val_acc: 0.9658 - val_mDice: 0.6776

Epoch 00116: val_mDice did not improve from 0.68320
Epoch 117/300
 - 13s - loss: 0.9980 - acc: 0.9558 - mDice: 0.6729 - val_loss: 1.3190 - val_acc: 0.9655 - val_mDice: 0.6797

Epoch 00117: val_mDice did not improve from 0.68320
Epoch 118/300
 - 13s - loss: 0.9977 - acc: 0.9558 - mDice: 0.6731 - val_loss: 1.2849 - val_acc: 0.9655 - val_mDice: 0.6811

Epoch 00118: val_mDice did not improve from 0.68320
Epoch 119/300
 - 13s - loss: 0.9966 - acc: 0.9558 - mDice: 0.6733 - val_loss: 1.2802 - val_acc: 0.9656 - val_mDice: 0.6811

Epoch 00119: val_mDice did not improve from 0.68320
Epoch 120/300
 - 13s - loss: 0.9952 - acc: 0.9559 - mDice: 0.6740 - val_loss: 1.2715 - val_acc: 0.9659 - val_mDice: 0.6799

Epoch 00120: val_mDice did not improve from 0.68320
Epoch 121/300
 - 12s - loss: 0.9950 - acc: 0.9558 - mDice: 0.6741 - val_loss: 1.3155 - val_acc: 0.9659 - val_mDice: 0.6811

Epoch 00121: val_mDice did not improve from 0.68320
Epoch 122/300
 - 12s - loss: 0.9979 - acc: 0.9557 - mDice: 0.6728 - val_loss: 1.2861 - val_acc: 0.9659 - val_mDice: 0.6815

Epoch 00122: val_mDice did not improve from 0.68320
Epoch 123/300
 - 12s - loss: 0.9951 - acc: 0.9558 - mDice: 0.6738 - val_loss: 1.2773 - val_acc: 0.9655 - val_mDice: 0.6829

Epoch 00123: val_mDice did not improve from 0.68320
Epoch 124/300
 - 13s - loss: 0.9934 - acc: 0.9559 - mDice: 0.6741 - val_loss: 1.3168 - val_acc: 0.9651 - val_mDice: 0.6781

Epoch 00124: val_mDice did not improve from 0.68320
Epoch 125/300
 - 13s - loss: 0.9920 - acc: 0.9559 - mDice: 0.6750 - val_loss: 1.2900 - val_acc: 0.9658 - val_mDice: 0.6810

Epoch 00125: val_mDice did not improve from 0.68320
Epoch 126/300
 - 13s - loss: 0.9923 - acc: 0.9560 - mDice: 0.6748 - val_loss: 1.2578 - val_acc: 0.9659 - val_mDice: 0.6816

Epoch 00126: val_mDice did not improve from 0.68320
Epoch 127/300
 - 13s - loss: 0.9931 - acc: 0.9559 - mDice: 0.6744 - val_loss: 1.2829 - val_acc: 0.9658 - val_mDice: 0.6786

Epoch 00127: val_mDice did not improve from 0.68320
Epoch 128/300
 - 12s - loss: 0.9920 - acc: 0.9559 - mDice: 0.6749 - val_loss: 1.2768 - val_acc: 0.9655 - val_mDice: 0.6827

Epoch 00128: val_mDice did not improve from 0.68320
Epoch 129/300
 - 12s - loss: 0.9909 - acc: 0.9559 - mDice: 0.6753 - val_loss: 1.2889 - val_acc: 0.9658 - val_mDice: 0.6799

Epoch 00129: val_mDice did not improve from 0.68320
Epoch 130/300
 - 12s - loss: 0.9917 - acc: 0.9559 - mDice: 0.6747 - val_loss: 1.3097 - val_acc: 0.9659 - val_mDice: 0.6817

Epoch 00130: val_mDice did not improve from 0.68320
Epoch 131/300
 - 13s - loss: 0.9934 - acc: 0.9559 - mDice: 0.6748 - val_loss: 1.2886 - val_acc: 0.9655 - val_mDice: 0.6772

Epoch 00131: val_mDice did not improve from 0.68320
Epoch 132/300
 - 13s - loss: 0.9899 - acc: 0.9559 - mDice: 0.6753 - val_loss: 1.2875 - val_acc: 0.9656 - val_mDice: 0.6787

Epoch 00132: val_mDice did not improve from 0.68320
Restoring model weights from the end of the best epoch
Epoch 00132: early stopping
{'val_loss': [1.1541939864695911, 1.1407241922029308, 1.159366013298572, 1.17741979595641, 1.148688360838823, 1.154747397966788, 1.1586234057453317, 1.1547333077645638, 1.1744225512088184, 1.1672812440025975, 1.1559556647085807, 1.1573021772881629, 1.1805699157043241, 1.1856777223063186, 1.187495768070221, 1.2047474753688758, 1.1637914692851858, 1.1877793082049195, 1.1939815627017492, 1.179098967934998, 1.2145800514959952, 1.1991579750893822, 1.2200348477968028, 1.1969426979481335, 1.2178169220266208, 1.2383920080225232, 1.2386285998451878, 1.2050031608259175, 1.2107073286889305, 1.2185685726958262, 1.2098923543809166, 1.223157398297753, 1.2184776495879805, 1.2271631578324547, 1.2470313461733535, 1.2423916702539148, 1.222467859865914, 1.2437922920979245, 1.2519835636649332, 1.2411312679169884, 1.2531096448361034, 1.2349577814760342, 1.2273426248993673, 1.2564995910080385, 1.2225679352249899, 1.2155685550729993, 1.2640963834776004, 1.2402449015160681, 1.2454609325234318, 1.220433107564147, 1.2596528085184768, 1.2540418791099333, 1.2495149575488669, 1.218683789313679, 1.233875917716765, 1.2438317680023085, 1.2574645146517687, 1.2538537450239693, 1.2259392335381307, 1.2304084502475363, 1.253785143435841, 1.2445754761427221, 1.2045962063359543, 1.2459403486318992, 1.2654077964769284, 1.2675027100133225, 1.2708550196298412, 1.272776617130763, 1.247898925358141, 1.2521253765468867, 1.234928247794299, 1.2696834005100626, 1.2246650432197141, 1.2666800240395775, 1.264780387072496, 1.264970301742285, 1.2573992013931274, 1.2718605860857897, 1.2704428610667375, 1.2657451621243652, 1.2759625164555832, 1.2415848777327738, 1.2580347145107431, 1.2784388417928991, 1.298814725707954, 1.273168663743516, 1.2429954980460691, 1.2690535624262314, 1.2521931948796126, 1.3029612596605864, 1.3050578891391484, 1.273628186172163, 1.2627718381478752, 1.2697769571358049, 1.2681003397619222, 1.2826248726374667, 1.284469809330685, 1.247277558689386, 1.275672866425044, 1.2533291460762561, 1.2548620818366467, 1.276733528560316, 1.2622467858690611, 1.2743638879816297, 1.2748919834553356, 1.2907617948424648, 1.28992206445882, 1.2521093538109684, 1.2622053891840115, 1.268881682778748, 1.2668810679878988, 1.2852092821833114, 1.2965356682387876, 1.2840721204247274, 1.2678439717897227, 1.29257539544307, 1.3189655995704759, 1.2848725209773426, 1.2802261978807583, 1.271548650634121, 1.3155293296760238, 1.2860764004814793, 1.2773190619240344, 1.3168464109931193, 1.2899653449864454, 1.2578131522930844, 1.2829229714165271, 1.276767461232736, 1.2888959419559425, 1.3096536910030203, 1.2886093577868503, 1.2874531964181175], 'val_acc': [0.9662677654078309, 0.9669522794199662, 0.9657561871367442, 0.9652474413455372, 0.965916247435019, 0.9666007505336278, 0.9653017445349358, 0.9648216140102333, 0.9662134588604242, 0.9660605771440856, 0.9665678882263076, 0.9660648586044849, 0.9654932693696358, 0.9664964264547321, 0.966314927792885, 0.966416380774807, 0.9662763308471357, 0.9668336989174426, 0.9660877165660052, 0.9663135039974267, 0.9655318327353034, 0.9655575584357893, 0.9651702860711326, 0.9661148492719086, 0.9662978002722834, 0.9657619117011487, 0.9657347378596454, 0.9659433851779347, 0.9661334425630704, 0.9656918678485172, 0.9662020256821539, 0.9658162174090533, 0.9660105612916006, 0.9652302961953929, 0.9654689498350654, 0.9661148937655167, 0.9661806066271285, 0.9665364497144457, 0.9660762691162001, 0.9650116571238343, 0.9658876657485962, 0.9661362960305012, 0.9661362968700032, 0.9660077178981942, 0.9660134004874968, 0.965819067518476, 0.9653432050221403, 0.9653889083526503, 0.9653188854875699, 0.9660719801002825, 0.9662634982189662, 0.965504678202347, 0.9660491238177662, 0.9658390594200349, 0.966294912385269, 0.9662234741197505, 0.9654275052983996, 0.9651431223036537, 0.9655360999241681, 0.9660048182581512, 0.9657161680745406, 0.9660234039937946, 0.9661363203760603, 0.9659133553504944, 0.9656890135415843, 0.9651259973015583, 0.9657847612676486, 0.9657376047591089, 0.9662806425296085, 0.9653503315549501, 0.9656375596221064, 0.9648501789066154, 0.9656447365250386, 0.9662391904374243, 0.9652831823053495, 0.966143462859409, 0.9659147967754955, 0.9661920633114559, 0.9653903522961577, 0.966167732863359, 0.9655318083897443, 0.9665135497778234, 0.965784770502171, 0.9660277190342755, 0.9654617922406801, 0.9660019832597652, 0.9662263351426997, 0.9655232605799823, 0.965794779045481, 0.9659576693051298, 0.9651945862971562, 0.96550036064336, 0.9651431357356864, 0.9654489579335065, 0.9660134088825172, 0.9657033203353345, 0.9656447130189815, 0.9660019723462386, 0.9656833024092124, 0.9659133948070903, 0.9660005384767559, 0.9657390310730732, 0.9659905416864745, 0.9657904665235063, 0.9659776947867702, 0.9661562938085744, 0.9661263126722524, 0.9661720143237584, 0.9661563030430969, 0.9657261531117937, 0.965651873971375, 0.9660762783507226, 0.9661463112898276, 0.9657776229818102, 0.965727620561358, 0.9657518863677979, 0.9655289843048848, 0.9655332573702637, 0.9655546890178197, 0.9659419403949254, 0.9659276621442445, 0.9658762292123176, 0.9654961236765687, 0.9650873877632786, 0.9657733507559333, 0.9659062422497172, 0.9658104634620774, 0.9654803628652868, 0.9657833551017332, 0.9658562138047017, 0.965548960255905, 0.9655689932930638], 'val_mDice': [0.6462060473334621, 0.6561989532390111, 0.6537074950379385, 0.6519634765638432, 0.6587080846370106, 0.6613547399010457, 0.663315366691267, 0.6589681564922064, 0.6600138167260399, 0.6636352068941358, 0.6689215361232489, 0.6687923871295552, 0.6689358378799868, 0.6681555442407098, 0.6714215782326711, 0.669484664017046, 0.6747847980176899, 0.6719564182657591, 0.6744290791766744, 0.6715911458915388, 0.6742332602890444, 0.6719186121309307, 0.6734916509037286, 0.6759326021436235, 0.6702576573465912, 0.6714315481588874, 0.6683956435028936, 0.6727966674616639, 0.6744190429297972, 0.67212249191714, 0.6788881698124846, 0.6731486605926299, 0.6709918488918896, 0.6760279595012396, 0.6725247300846476, 0.6765704843359934, 0.6735345326678853, 0.677891236795506, 0.6769086659794122, 0.6757265875037287, 0.6743313443492835, 0.6751287453611132, 0.6766120908965527, 0.6746452156926545, 0.6797288379199068, 0.6798280124932947, 0.6755510786889305, 0.672621167881388, 0.6741430541159401, 0.6762529888623198, 0.6760526400216869, 0.677540293881591, 0.6736547191378096, 0.6751607228332842, 0.681651619118704, 0.6784491723691913, 0.6782779634838373, 0.6794215776550938, 0.68065482797757, 0.6798986129357781, 0.6782938418254046, 0.6800043683656505, 0.679034730917971, 0.6776384459414952, 0.6809415254794376, 0.6755669771785467, 0.6807800732867818, 0.6774557938038464, 0.6801635967174047, 0.6786646255305115, 0.6735739892637226, 0.6782463595900737, 0.6788935300330041, 0.6810716944681087, 0.6754063577719138, 0.6786122103811989, 0.6774802165971675, 0.677079054671274, 0.6721720216979443, 0.6788626405554758, 0.6800529738547096, 0.6824585451206691, 0.6746299930021796, 0.6802812210271056, 0.6774612043944883, 0.6802487045946256, 0.6821897835798667, 0.6828229469312749, 0.6812606529450752, 0.6771228951467595, 0.6756856046931844, 0.6778358565249913, 0.676340831837184, 0.6801208862116639, 0.6810045813170957, 0.6790821132525592, 0.6757107670878021, 0.682083031661074, 0.6777914997557519, 0.681025227190743, 0.681470403369044, 0.6831973883467661, 0.6796694876442493, 0.679689388879588, 0.6813339062140021, 0.6806581037145265, 0.6826154346197424, 0.6800100635474836, 0.6829207858569185, 0.6825355912598086, 0.6758291016162281, 0.6783598695002812, 0.6828664440504262, 0.6788043950645017, 0.6791944461809077, 0.6776402265253202, 0.6796552219860991, 0.6810527116480009, 0.681062037676153, 0.6799124512873905, 0.6810654703999909, 0.6815101050994765, 0.6829156136848558, 0.6780813781308456, 0.681029715168644, 0.6816188021444939, 0.6785534704235238, 0.6826509724200611, 0.679864097648943, 0.6816855400380953, 0.6771692482518478, 0.6787322969503806], 'loss': [1.4647625832449496, 1.3120506848617652, 1.2696817264506954, 1.238821155737832, 1.2185169943132117, 1.1991974593179735, 1.1888006494238046, 1.1783160509378012, 1.165941470164487, 1.1572418775996751, 1.1494040773870502, 1.1463976209076288, 1.1372566587221768, 1.1349836579584118, 1.1252987707958033, 1.1230660041728084, 1.1160991903374957, 1.1120363012727712, 1.1089886200157553, 1.1063705776721118, 1.1005996665752094, 1.0965009895849533, 1.0951417455706505, 1.092705572462831, 1.0890512644308399, 1.0858239079714516, 1.0820205499433793, 1.0836767464477424, 1.0784692263589342, 1.078664862603348, 1.074785883964807, 1.0737859711111666, 1.0707349296292987, 1.0680168721827052, 1.0653074369519306, 1.0638849162445156, 1.063662002917429, 1.0604923322077335, 1.057512667027929, 1.0591210537763998, 1.0548872721964984, 1.055215206723216, 1.0517168446915868, 1.052340457854124, 1.0484462975415467, 1.0482454021841097, 1.0440212007592486, 1.044114907443905, 1.042822945908518, 1.0457293088176765, 1.0404491133992237, 1.0397208823652861, 1.0391755631803565, 1.0389515995771266, 1.0375722966407745, 1.034292351998445, 1.0358329529052144, 1.0350363935544922, 1.032883287620378, 1.033310642555885, 1.0288902120648462, 1.0289739015284078, 1.0291311048435015, 1.0257295135012057, 1.0264670155019244, 1.0269133473219325, 1.0267088227732504, 1.022762333049963, 1.0250339787876002, 1.0237978076851597, 1.0232116636181376, 1.0212620259926304, 1.0197657860594478, 1.0198202189350627, 1.0209011336341023, 1.0189538533220186, 1.0186719050790212, 1.0140260748560863, 1.0170598143474385, 1.0160887773609772, 1.015420915221946, 1.012712936508163, 1.0164286573658579, 1.0155514412109348, 1.012822071121764, 1.0112516849869, 1.012333533457367, 1.0099758304711897, 1.0109078529409505, 1.0081676840088685, 1.0083712644532643, 1.0082114024381432, 1.0089919067802229, 1.0071395257658013, 1.0053475620512216, 1.0053893585341, 1.0061791015267718, 1.004563025779125, 1.006401014716352, 1.003082328996664, 1.004104409126295, 1.002900897416353, 1.0041420079026546, 1.001028966633229, 1.0029025076432863, 0.9988927856789833, 1.0014498383240202, 0.999723328137689, 1.0011714169839012, 1.0005669079942021, 1.0003370145089825, 0.9991448985205756, 0.9989600433312994, 0.9970527829438742, 0.998002352306772, 0.9973795393513274, 0.997983498619073, 0.9977371363600996, 0.9965867988934276, 0.9951764417637774, 0.9950005697122211, 0.9978549354571531, 0.9950852207557762, 0.9933629893785025, 0.9920319396094432, 0.9923073028394689, 0.9930614240645252, 0.9920233173936241, 0.9908925431491747, 0.9917472396013416, 0.9934418790904916, 0.9899041975841334], 'acc': [0.947166137358281, 0.9492537321705954, 0.9498986571316389, 0.9505109538374563, 0.9508593774868209, 0.9512731332013328, 0.9514348815873032, 0.95169418009996, 0.9519157194342288, 0.9521206727965479, 0.9521919610612679, 0.9522614198898839, 0.9525327612106851, 0.9526566969855987, 0.9527432591919291, 0.9528056247210767, 0.9529814802677983, 0.9530311059022518, 0.9531372287996014, 0.9531660558804306, 0.9532743857793159, 0.9533774517801628, 0.9533912531160351, 0.9534848565414522, 0.953580989818229, 0.9536033826834106, 0.9537553217883995, 0.953721252480796, 0.9537204836190197, 0.9538432800055521, 0.9538565465986486, 0.9539233731141681, 0.9539570977619874, 0.9539955469187503, 0.9540258613417771, 0.9541539646914838, 0.9540987780026186, 0.9541341330229786, 0.9542339046102682, 0.9541960490380975, 0.9542624876553267, 0.9543232906689957, 0.9543421681084003, 0.9543742143254837, 0.954472833764352, 0.9545208074243489, 0.9545467882533626, 0.9545405666241471, 0.9545863678526088, 0.9544985082483763, 0.9546339664783777, 0.9546104263884859, 0.9546543772724079, 0.9546837715162241, 0.9546878180786785, 0.9548090259788895, 0.954800527653353, 0.9547504068045092, 0.9547919369908944, 0.9548286475574922, 0.9549097736052402, 0.9549188233517574, 0.9549440960678824, 0.9549963929196857, 0.9550045006076842, 0.9550100959893782, 0.9550028480090951, 0.9550258560954589, 0.9550041723140386, 0.9550130349942041, 0.9550592627824913, 0.9551033644637373, 0.9551438313365468, 0.9551050674783552, 0.9551626829784786, 0.9551682440675643, 0.9551755044611475, 0.9553270897870844, 0.9552387282070273, 0.9552426023355676, 0.9552662699218404, 0.9553055339181333, 0.9553315957803377, 0.9552805212571774, 0.9553557032759347, 0.9553519956520506, 0.955380103420282, 0.9554308968758153, 0.9555072401969359, 0.9554490411676869, 0.9554781303147787, 0.9554388308469607, 0.9555327485923922, 0.9555475141434838, 0.9555225844574641, 0.9555195043293663, 0.9555143460484006, 0.9555886217922301, 0.9555685901933108, 0.9556153807409841, 0.9555786230870635, 0.9555809722867659, 0.9556131751264092, 0.9556540672067573, 0.9556499329883738, 0.9556790438414036, 0.9556694096989102, 0.9557257416360665, 0.9556954791547255, 0.9557280795667115, 0.9556536519506631, 0.9557089819819377, 0.955735776957001, 0.9558048558623518, 0.9557577090737708, 0.955773387245136, 0.9557787094648804, 0.9557631888175996, 0.9558234502577102, 0.9558675619944228, 0.9558036897056251, 0.9557469453903185, 0.9558141018638366, 0.9558873828446331, 0.9558935000356926, 0.9559662741169532, 0.9559119025103362, 0.9559059188489376, 0.9559358804637849, 0.9559274249606662, 0.9559112894389434, 0.9559448016737006], 'mDice': [0.5603504540824558, 0.5836906220900451, 0.593614997351981, 0.6008050706651475, 0.6060635843132733, 0.611374550742282, 0.6141944860496654, 0.6174096724125727, 0.62113293871899, 0.622901235263385, 0.6253657936703125, 0.6266119524515805, 0.6291907355492721, 0.6299101334106374, 0.6329568329420528, 0.6335297796253273, 0.635451020058537, 0.6369061422875067, 0.637852035337163, 0.6385792820449483, 0.6402197067927593, 0.6417192360077437, 0.6419101495462631, 0.642635139009854, 0.6442189828610267, 0.6450345346995604, 0.646233613647785, 0.6457933425001796, 0.6473429016487205, 0.6476605765135778, 0.6485554017321602, 0.6487181966494793, 0.6501376336920462, 0.6506462858956245, 0.6514232675997306, 0.6518405782337311, 0.6520867890712478, 0.6531295865826166, 0.6536835124494033, 0.6534202631439422, 0.6546320014391062, 0.6542852421774984, 0.655958775589118, 0.6555841565825622, 0.6569908530022808, 0.656743804440379, 0.658077303929132, 0.6581919519897115, 0.6587418220707537, 0.6574223845971747, 0.6592855034282278, 0.6595284310172227, 0.65986302122257, 0.6602275779318019, 0.660097766609092, 0.6616388506636917, 0.6608132474501511, 0.6613389312562171, 0.6616324000472312, 0.6618835997484395, 0.6630873936702513, 0.6627111939790292, 0.6632202688242683, 0.6641692493529151, 0.6639790118191393, 0.6636303630660203, 0.6640196768886617, 0.664806304663125, 0.6642129293980468, 0.6648763284009165, 0.6648737736536084, 0.6652986144104137, 0.6661160063646504, 0.6659150992873937, 0.6660686655749132, 0.6660827603223645, 0.6659657325489428, 0.6676589561937297, 0.6670357944522922, 0.6671023717656116, 0.6674737766289724, 0.6683954766768921, 0.6670911910576901, 0.6671333137537727, 0.6680149665885778, 0.6684555103780226, 0.6683887428776895, 0.6690392015700148, 0.669142633763214, 0.6697439401561677, 0.6696214511201714, 0.6694647713481444, 0.6694709439482919, 0.6699025967635687, 0.6705869623157019, 0.6704983051742767, 0.670705180517666, 0.6705826561141666, 0.6701307380664064, 0.6711407085710518, 0.6708573511757776, 0.6714432183013814, 0.6712951498922045, 0.6720042194024708, 0.6717218627341616, 0.6726329059639665, 0.6720797381753351, 0.6723066435226387, 0.6721781465881019, 0.6718269635106742, 0.6720555950001689, 0.6728581106544859, 0.6725930773012162, 0.6738366603227186, 0.6732873371550342, 0.6733608730592445, 0.6728841182518449, 0.673140076754605, 0.673273723613668, 0.6740341667105391, 0.6740583715707913, 0.6728084635914863, 0.6737975712568695, 0.6740549439049655, 0.6749646585995961, 0.6747587308278952, 0.6744412367880657, 0.6748767854724949, 0.6753218166352428, 0.674678955472022, 0.6748210480561293, 0.6753275833066082]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:02<00:07,  2.37s/it]predicting test subjects:  50%|█████     | 2/4 [00:03<00:04,  2.11s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:05<00:01,  1.95s/it]predicting test subjects: 100%|██████████| 4/4 [00:07<00:00,  1.90s/it]
predicting train subjects:   0%|          | 0/456 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/456 [00:01<13:36,  1.79s/it]predicting train subjects:   0%|          | 2/456 [00:03<13:08,  1.74s/it]predicting train subjects:   1%|          | 3/456 [00:04<12:37,  1.67s/it]predicting train subjects:   1%|          | 4/456 [00:06<11:54,  1.58s/it]predicting train subjects:   1%|          | 5/456 [00:08<13:10,  1.75s/it]predicting train subjects:   1%|▏         | 6/456 [00:10<13:14,  1.77s/it]predicting train subjects:   2%|▏         | 7/456 [00:11<12:16,  1.64s/it]predicting train subjects:   2%|▏         | 8/456 [00:12<10:50,  1.45s/it]predicting train subjects:   2%|▏         | 9/456 [00:14<11:15,  1.51s/it]predicting train subjects:   2%|▏         | 10/456 [00:16<12:02,  1.62s/it]predicting train subjects:   2%|▏         | 11/456 [00:18<12:38,  1.70s/it]predicting train subjects:   3%|▎         | 12/456 [00:19<11:16,  1.52s/it]predicting train subjects:   3%|▎         | 13/456 [00:20<11:33,  1.56s/it]predicting train subjects:   3%|▎         | 14/456 [00:22<11:45,  1.60s/it]predicting train subjects:   3%|▎         | 15/456 [00:23<10:45,  1.46s/it]predicting train subjects:   4%|▎         | 16/456 [00:25<11:22,  1.55s/it]predicting train subjects:   4%|▎         | 17/456 [00:27<12:38,  1.73s/it]predicting train subjects:   4%|▍         | 18/456 [00:29<12:30,  1.71s/it]predicting train subjects:   4%|▍         | 19/456 [00:30<11:58,  1.64s/it]predicting train subjects:   4%|▍         | 20/456 [00:32<11:24,  1.57s/it]predicting train subjects:   5%|▍         | 21/456 [00:33<11:35,  1.60s/it]predicting train subjects:   5%|▍         | 22/456 [00:35<11:54,  1.65s/it]predicting train subjects:   5%|▌         | 23/456 [00:37<12:16,  1.70s/it]predicting train subjects:   5%|▌         | 24/456 [00:38<10:40,  1.48s/it]predicting train subjects:   5%|▌         | 25/456 [00:39<10:50,  1.51s/it]predicting train subjects:   6%|▌         | 26/456 [00:41<11:01,  1.54s/it]predicting train subjects:   6%|▌         | 27/456 [00:43<11:07,  1.56s/it]predicting train subjects:   6%|▌         | 28/456 [00:44<11:10,  1.57s/it]predicting train subjects:   6%|▋         | 29/456 [00:46<11:12,  1.58s/it]predicting train subjects:   7%|▋         | 30/456 [00:47<11:17,  1.59s/it]predicting train subjects:   7%|▋         | 31/456 [00:49<11:34,  1.63s/it]predicting train subjects:   7%|▋         | 32/456 [00:51<11:28,  1.62s/it]predicting train subjects:   7%|▋         | 33/456 [00:52<11:26,  1.62s/it]predicting train subjects:   7%|▋         | 34/456 [00:54<11:22,  1.62s/it]predicting train subjects:   8%|▊         | 35/456 [00:56<11:18,  1.61s/it]predicting train subjects:   8%|▊         | 36/456 [00:57<11:18,  1.61s/it]predicting train subjects:   8%|▊         | 37/456 [00:59<11:15,  1.61s/it]predicting train subjects:   8%|▊         | 38/456 [01:00<11:12,  1.61s/it]predicting train subjects:   9%|▊         | 39/456 [01:02<11:06,  1.60s/it]predicting train subjects:   9%|▉         | 40/456 [01:04<11:09,  1.61s/it]predicting train subjects:   9%|▉         | 41/456 [01:05<11:09,  1.61s/it]predicting train subjects:   9%|▉         | 42/456 [01:07<11:12,  1.63s/it]predicting train subjects:   9%|▉         | 43/456 [01:09<11:20,  1.65s/it]predicting train subjects:  10%|▉         | 44/456 [01:10<11:30,  1.68s/it]predicting train subjects:  10%|▉         | 45/456 [01:12<11:30,  1.68s/it]predicting train subjects:  10%|█         | 46/456 [01:14<11:24,  1.67s/it]predicting train subjects:  10%|█         | 47/456 [01:15<11:22,  1.67s/it]predicting train subjects:  11%|█         | 48/456 [01:17<11:32,  1.70s/it]predicting train subjects:  11%|█         | 49/456 [01:19<11:27,  1.69s/it]predicting train subjects:  11%|█         | 50/456 [01:20<11:27,  1.69s/it]predicting train subjects:  11%|█         | 51/456 [01:22<11:25,  1.69s/it]predicting train subjects:  11%|█▏        | 52/456 [01:24<11:32,  1.71s/it]predicting train subjects:  12%|█▏        | 53/456 [01:26<11:23,  1.70s/it]predicting train subjects:  12%|█▏        | 54/456 [01:27<11:20,  1.69s/it]predicting train subjects:  12%|█▏        | 55/456 [01:29<11:09,  1.67s/it]predicting train subjects:  12%|█▏        | 56/456 [01:31<11:15,  1.69s/it]predicting train subjects:  12%|█▎        | 57/456 [01:32<11:15,  1.69s/it]predicting train subjects:  13%|█▎        | 58/456 [01:34<11:11,  1.69s/it]predicting train subjects:  13%|█▎        | 59/456 [01:36<11:16,  1.70s/it]predicting train subjects:  13%|█▎        | 60/456 [01:37<11:14,  1.70s/it]predicting train subjects:  13%|█▎        | 61/456 [01:39<11:33,  1.76s/it]predicting train subjects:  14%|█▎        | 62/456 [01:41<11:44,  1.79s/it]predicting train subjects:  14%|█▍        | 63/456 [01:43<11:46,  1.80s/it]predicting train subjects:  14%|█▍        | 64/456 [01:45<11:48,  1.81s/it]predicting train subjects:  14%|█▍        | 65/456 [01:47<11:54,  1.83s/it]predicting train subjects:  14%|█▍        | 66/456 [01:48<11:52,  1.83s/it]predicting train subjects:  15%|█▍        | 67/456 [01:50<11:53,  1.83s/it]predicting train subjects:  15%|█▍        | 68/456 [01:52<11:49,  1.83s/it]predicting train subjects:  15%|█▌        | 69/456 [01:54<11:40,  1.81s/it]predicting train subjects:  15%|█▌        | 70/456 [01:56<11:39,  1.81s/it]predicting train subjects:  16%|█▌        | 71/456 [01:58<11:35,  1.81s/it]predicting train subjects:  16%|█▌        | 72/456 [01:59<11:22,  1.78s/it]predicting train subjects:  16%|█▌        | 73/456 [02:01<11:15,  1.76s/it]predicting train subjects:  16%|█▌        | 74/456 [02:03<11:14,  1.77s/it]predicting train subjects:  16%|█▋        | 75/456 [02:04<11:09,  1.76s/it]predicting train subjects:  17%|█▋        | 76/456 [02:06<11:18,  1.79s/it]predicting train subjects:  17%|█▋        | 77/456 [02:08<11:14,  1.78s/it]predicting train subjects:  17%|█▋        | 78/456 [02:10<11:11,  1.78s/it]predicting train subjects:  17%|█▋        | 79/456 [02:11<09:42,  1.54s/it]predicting train subjects:  18%|█▊        | 80/456 [02:12<08:38,  1.38s/it]predicting train subjects:  18%|█▊        | 81/456 [02:13<07:53,  1.26s/it]predicting train subjects:  18%|█▊        | 82/456 [02:14<07:27,  1.20s/it]predicting train subjects:  18%|█▊        | 83/456 [02:15<07:05,  1.14s/it]predicting train subjects:  18%|█▊        | 84/456 [02:16<06:49,  1.10s/it]predicting train subjects:  19%|█▊        | 85/456 [02:17<06:33,  1.06s/it]predicting train subjects:  19%|█▉        | 86/456 [02:18<06:23,  1.04s/it]predicting train subjects:  19%|█▉        | 87/456 [02:19<06:17,  1.02s/it]predicting train subjects:  19%|█▉        | 88/456 [02:20<06:07,  1.00it/s]predicting train subjects:  20%|█▉        | 89/456 [02:21<06:05,  1.01it/s]predicting train subjects:  20%|█▉        | 90/456 [02:22<06:01,  1.01it/s]predicting train subjects:  20%|█▉        | 91/456 [02:23<05:58,  1.02it/s]predicting train subjects:  20%|██        | 92/456 [02:24<05:53,  1.03it/s]predicting train subjects:  20%|██        | 93/456 [02:25<05:54,  1.02it/s]predicting train subjects:  21%|██        | 94/456 [02:26<05:59,  1.01it/s]predicting train subjects:  21%|██        | 95/456 [02:27<05:55,  1.02it/s]predicting train subjects:  21%|██        | 96/456 [02:28<05:57,  1.01it/s]predicting train subjects:  21%|██▏       | 97/456 [02:29<07:12,  1.20s/it]predicting train subjects:  21%|██▏       | 98/456 [02:31<08:10,  1.37s/it]predicting train subjects:  22%|██▏       | 99/456 [02:33<09:01,  1.52s/it]predicting train subjects:  22%|██▏       | 100/456 [02:35<09:18,  1.57s/it]predicting train subjects:  22%|██▏       | 101/456 [02:36<09:30,  1.61s/it]predicting train subjects:  22%|██▏       | 102/456 [02:38<09:28,  1.60s/it]predicting train subjects:  23%|██▎       | 103/456 [02:40<09:25,  1.60s/it]predicting train subjects:  23%|██▎       | 104/456 [02:41<09:36,  1.64s/it]predicting train subjects:  23%|██▎       | 105/456 [02:43<09:34,  1.64s/it]predicting train subjects:  23%|██▎       | 106/456 [02:45<09:32,  1.64s/it]predicting train subjects:  23%|██▎       | 107/456 [02:46<09:38,  1.66s/it]predicting train subjects:  24%|██▎       | 108/456 [02:48<09:37,  1.66s/it]predicting train subjects:  24%|██▍       | 109/456 [02:50<09:28,  1.64s/it]predicting train subjects:  24%|██▍       | 110/456 [02:51<09:33,  1.66s/it]predicting train subjects:  24%|██▍       | 111/456 [02:53<09:43,  1.69s/it]predicting train subjects:  25%|██▍       | 112/456 [02:55<09:27,  1.65s/it]predicting train subjects:  25%|██▍       | 113/456 [02:56<09:30,  1.66s/it]predicting train subjects:  25%|██▌       | 114/456 [02:58<09:23,  1.65s/it]predicting train subjects:  25%|██▌       | 115/456 [03:00<09:26,  1.66s/it]predicting train subjects:  25%|██▌       | 116/456 [03:01<09:27,  1.67s/it]predicting train subjects:  26%|██▌       | 117/456 [03:03<09:25,  1.67s/it]predicting train subjects:  26%|██▌       | 118/456 [03:05<09:26,  1.68s/it]predicting train subjects:  26%|██▌       | 119/456 [03:06<09:24,  1.67s/it]predicting train subjects:  26%|██▋       | 120/456 [03:08<09:21,  1.67s/it]predicting train subjects:  27%|██▋       | 121/456 [03:10<09:26,  1.69s/it]predicting train subjects:  27%|██▋       | 122/456 [03:11<09:30,  1.71s/it]predicting train subjects:  27%|██▋       | 123/456 [03:13<09:26,  1.70s/it]predicting train subjects:  27%|██▋       | 124/456 [03:15<09:35,  1.73s/it]predicting train subjects:  27%|██▋       | 125/456 [03:17<09:34,  1.73s/it]predicting train subjects:  28%|██▊       | 126/456 [03:19<09:45,  1.77s/it]predicting train subjects:  28%|██▊       | 127/456 [03:20<09:02,  1.65s/it]predicting train subjects:  28%|██▊       | 128/456 [03:21<08:32,  1.56s/it]predicting train subjects:  28%|██▊       | 129/456 [03:23<08:11,  1.50s/it]predicting train subjects:  29%|██▊       | 130/456 [03:24<07:56,  1.46s/it]predicting train subjects:  29%|██▊       | 131/456 [03:25<07:43,  1.43s/it]predicting train subjects:  29%|██▉       | 132/456 [03:27<07:38,  1.42s/it]predicting train subjects:  29%|██▉       | 133/456 [03:29<08:40,  1.61s/it]predicting train subjects:  29%|██▉       | 134/456 [03:31<09:31,  1.77s/it]predicting train subjects:  30%|██▉       | 135/456 [03:33<10:03,  1.88s/it]predicting train subjects:  30%|██▉       | 136/456 [03:35<10:19,  1.94s/it]predicting train subjects:  30%|███       | 137/456 [03:37<10:30,  1.98s/it]predicting train subjects:  30%|███       | 138/456 [03:39<10:35,  2.00s/it]predicting train subjects:  30%|███       | 139/456 [03:41<09:34,  1.81s/it]predicting train subjects:  31%|███       | 140/456 [03:42<08:56,  1.70s/it]predicting train subjects:  31%|███       | 141/456 [03:43<08:30,  1.62s/it]predicting train subjects:  31%|███       | 142/456 [03:45<08:10,  1.56s/it]predicting train subjects:  31%|███▏      | 143/456 [03:46<07:57,  1.52s/it]predicting train subjects:  32%|███▏      | 144/456 [03:48<07:47,  1.50s/it]predicting train subjects:  32%|███▏      | 145/456 [03:49<07:54,  1.53s/it]predicting train subjects:  32%|███▏      | 146/456 [03:51<08:02,  1.56s/it]predicting train subjects:  32%|███▏      | 147/456 [03:52<07:56,  1.54s/it]predicting train subjects:  32%|███▏      | 148/456 [03:54<08:08,  1.58s/it]predicting train subjects:  33%|███▎      | 149/456 [03:56<08:01,  1.57s/it]predicting train subjects:  33%|███▎      | 150/456 [03:57<07:58,  1.57s/it]predicting train subjects:  33%|███▎      | 151/456 [03:59<08:03,  1.59s/it]predicting train subjects:  33%|███▎      | 152/456 [04:01<08:05,  1.60s/it]predicting train subjects:  34%|███▎      | 153/456 [04:02<07:58,  1.58s/it]predicting train subjects:  34%|███▍      | 154/456 [04:04<08:02,  1.60s/it]predicting train subjects:  34%|███▍      | 155/456 [04:05<08:07,  1.62s/it]predicting train subjects:  34%|███▍      | 156/456 [04:07<08:03,  1.61s/it]predicting train subjects:  34%|███▍      | 157/456 [04:08<07:51,  1.58s/it]predicting train subjects:  35%|███▍      | 158/456 [04:10<07:35,  1.53s/it]predicting train subjects:  35%|███▍      | 159/456 [04:11<07:26,  1.50s/it]predicting train subjects:  35%|███▌      | 160/456 [04:13<07:17,  1.48s/it]predicting train subjects:  35%|███▌      | 161/456 [04:14<07:11,  1.46s/it]predicting train subjects:  36%|███▌      | 162/456 [04:16<07:08,  1.46s/it]predicting train subjects:  36%|███▌      | 163/456 [04:17<06:29,  1.33s/it]predicting train subjects:  36%|███▌      | 164/456 [04:18<06:04,  1.25s/it]predicting train subjects:  36%|███▌      | 165/456 [04:19<05:43,  1.18s/it]predicting train subjects:  36%|███▋      | 166/456 [04:20<05:28,  1.13s/it]predicting train subjects:  37%|███▋      | 167/456 [04:21<05:19,  1.10s/it]predicting train subjects:  37%|███▋      | 168/456 [04:22<05:12,  1.08s/it]predicting train subjects:  37%|███▋      | 169/456 [04:23<05:07,  1.07s/it]predicting train subjects:  37%|███▋      | 170/456 [04:24<05:02,  1.06s/it]predicting train subjects:  38%|███▊      | 171/456 [04:25<05:03,  1.06s/it]predicting train subjects:  38%|███▊      | 172/456 [04:26<04:56,  1.05s/it]predicting train subjects:  38%|███▊      | 173/456 [04:27<04:55,  1.04s/it]predicting train subjects:  38%|███▊      | 174/456 [04:28<04:51,  1.03s/it]predicting train subjects:  38%|███▊      | 175/456 [04:29<04:48,  1.03s/it]predicting train subjects:  39%|███▊      | 176/456 [04:30<04:58,  1.07s/it]predicting train subjects:  39%|███▉      | 177/456 [04:31<04:50,  1.04s/it]predicting train subjects:  39%|███▉      | 178/456 [04:32<04:48,  1.04s/it]predicting train subjects:  39%|███▉      | 179/456 [04:33<04:47,  1.04s/it]predicting train subjects:  39%|███▉      | 180/456 [04:34<04:44,  1.03s/it]predicting train subjects:  40%|███▉      | 181/456 [04:36<05:47,  1.26s/it]predicting train subjects:  40%|███▉      | 182/456 [04:38<06:29,  1.42s/it]predicting train subjects:  40%|████      | 183/456 [04:40<06:59,  1.54s/it]predicting train subjects:  40%|████      | 184/456 [04:42<07:24,  1.64s/it]predicting train subjects:  41%|████      | 185/456 [04:43<07:41,  1.70s/it]predicting train subjects:  41%|████      | 186/456 [04:45<07:49,  1.74s/it]predicting train subjects:  41%|████      | 187/456 [04:47<08:14,  1.84s/it]predicting train subjects:  41%|████      | 188/456 [04:49<08:41,  1.95s/it]predicting train subjects:  41%|████▏     | 189/456 [04:51<08:45,  1.97s/it]predicting train subjects:  42%|████▏     | 190/456 [04:53<08:44,  1.97s/it]predicting train subjects:  42%|████▏     | 191/456 [04:55<08:43,  1.98s/it]predicting train subjects:  42%|████▏     | 192/456 [04:58<08:48,  2.00s/it]predicting train subjects:  42%|████▏     | 193/456 [05:00<08:46,  2.00s/it]predicting train subjects:  43%|████▎     | 194/456 [05:01<08:38,  1.98s/it]predicting train subjects:  43%|████▎     | 195/456 [05:03<08:32,  1.96s/it]predicting train subjects:  43%|████▎     | 196/456 [05:05<08:29,  1.96s/it]predicting train subjects:  43%|████▎     | 197/456 [05:07<08:18,  1.93s/it]predicting train subjects:  43%|████▎     | 198/456 [05:09<08:16,  1.92s/it]predicting train subjects:  44%|████▎     | 199/456 [05:11<07:54,  1.84s/it]predicting train subjects:  44%|████▍     | 200/456 [05:12<07:41,  1.80s/it]predicting train subjects:  44%|████▍     | 201/456 [05:14<07:25,  1.75s/it]predicting train subjects:  44%|████▍     | 202/456 [05:16<07:17,  1.72s/it]predicting train subjects:  45%|████▍     | 203/456 [05:17<07:04,  1.68s/it]predicting train subjects:  45%|████▍     | 204/456 [05:19<07:04,  1.68s/it]predicting train subjects:  45%|████▍     | 205/456 [05:20<06:38,  1.59s/it]predicting train subjects:  45%|████▌     | 206/456 [05:22<06:23,  1.53s/it]predicting train subjects:  45%|████▌     | 207/456 [05:23<06:15,  1.51s/it]predicting train subjects:  46%|████▌     | 208/456 [05:25<06:07,  1.48s/it]predicting train subjects:  46%|████▌     | 209/456 [05:26<05:58,  1.45s/it]predicting train subjects:  46%|████▌     | 210/456 [05:27<05:49,  1.42s/it]predicting train subjects:  46%|████▋     | 211/456 [05:29<06:14,  1.53s/it]predicting train subjects:  46%|████▋     | 212/456 [05:31<06:22,  1.57s/it]predicting train subjects:  47%|████▋     | 213/456 [05:32<06:27,  1.60s/it]predicting train subjects:  47%|████▋     | 214/456 [05:34<06:35,  1.63s/it]predicting train subjects:  47%|████▋     | 215/456 [05:36<06:38,  1.65s/it]predicting train subjects:  47%|████▋     | 216/456 [05:38<06:37,  1.66s/it]predicting train subjects:  48%|████▊     | 217/456 [05:39<06:34,  1.65s/it]predicting train subjects:  48%|████▊     | 218/456 [05:41<06:31,  1.65s/it]predicting train subjects:  48%|████▊     | 219/456 [05:42<06:27,  1.64s/it]predicting train subjects:  48%|████▊     | 220/456 [05:44<06:23,  1.62s/it]predicting train subjects:  48%|████▊     | 221/456 [05:46<06:21,  1.62s/it]predicting train subjects:  49%|████▊     | 222/456 [05:47<06:18,  1.62s/it]predicting train subjects:  49%|████▉     | 223/456 [05:49<06:14,  1.61s/it]predicting train subjects:  49%|████▉     | 224/456 [05:50<06:09,  1.59s/it]predicting train subjects:  49%|████▉     | 225/456 [05:52<06:11,  1.61s/it]predicting train subjects:  50%|████▉     | 226/456 [05:54<06:08,  1.60s/it]predicting train subjects:  50%|████▉     | 227/456 [05:55<06:08,  1.61s/it]predicting train subjects:  50%|█████     | 228/456 [05:57<06:07,  1.61s/it]predicting train subjects:  50%|█████     | 229/456 [05:58<06:04,  1.61s/it]predicting train subjects:  50%|█████     | 230/456 [06:00<06:01,  1.60s/it]predicting train subjects:  51%|█████     | 231/456 [06:02<05:57,  1.59s/it]predicting train subjects:  51%|█████     | 232/456 [06:03<05:53,  1.58s/it]predicting train subjects:  51%|█████     | 233/456 [06:05<05:51,  1.57s/it]predicting train subjects:  51%|█████▏    | 234/456 [06:06<05:48,  1.57s/it]predicting train subjects:  52%|█████▏    | 235/456 [06:08<05:56,  1.61s/it]predicting train subjects:  52%|█████▏    | 236/456 [06:10<06:03,  1.65s/it]predicting train subjects:  52%|█████▏    | 237/456 [06:11<06:03,  1.66s/it]predicting train subjects:  52%|█████▏    | 238/456 [06:13<06:02,  1.66s/it]predicting train subjects:  52%|█████▏    | 239/456 [06:15<05:58,  1.65s/it]predicting train subjects:  53%|█████▎    | 240/456 [06:16<05:55,  1.65s/it]predicting train subjects:  53%|█████▎    | 241/456 [06:18<06:01,  1.68s/it]predicting train subjects:  53%|█████▎    | 242/456 [06:20<06:09,  1.73s/it]predicting train subjects:  53%|█████▎    | 243/456 [06:22<06:09,  1.73s/it]predicting train subjects:  54%|█████▎    | 244/456 [06:23<06:06,  1.73s/it]predicting train subjects:  54%|█████▎    | 245/456 [06:25<06:10,  1.75s/it]predicting train subjects:  54%|█████▍    | 246/456 [06:27<06:10,  1.76s/it]predicting train subjects:  54%|█████▍    | 247/456 [06:28<05:45,  1.65s/it]predicting train subjects:  54%|█████▍    | 248/456 [06:30<05:33,  1.60s/it]predicting train subjects:  55%|█████▍    | 249/456 [06:31<05:17,  1.53s/it]predicting train subjects:  55%|█████▍    | 250/456 [06:33<05:10,  1.51s/it]predicting train subjects:  55%|█████▌    | 251/456 [06:34<05:02,  1.47s/it]predicting train subjects:  55%|█████▌    | 252/456 [06:36<05:00,  1.47s/it]predicting train subjects:  55%|█████▌    | 253/456 [06:38<05:39,  1.67s/it]predicting train subjects:  56%|█████▌    | 254/456 [06:40<06:03,  1.80s/it]predicting train subjects:  56%|█████▌    | 255/456 [06:42<06:20,  1.89s/it]predicting train subjects:  56%|█████▌    | 256/456 [06:44<06:34,  1.97s/it]predicting train subjects:  56%|█████▋    | 257/456 [06:46<06:40,  2.01s/it]predicting train subjects:  57%|█████▋    | 258/456 [06:48<06:46,  2.05s/it]predicting train subjects:  57%|█████▋    | 259/456 [06:50<06:05,  1.86s/it]predicting train subjects:  57%|█████▋    | 260/456 [06:51<05:40,  1.74s/it]predicting train subjects:  57%|█████▋    | 261/456 [06:53<05:32,  1.70s/it]predicting train subjects:  57%|█████▋    | 262/456 [06:54<05:12,  1.61s/it]predicting train subjects:  58%|█████▊    | 263/456 [06:56<05:00,  1.56s/it]predicting train subjects:  58%|█████▊    | 264/456 [06:57<04:50,  1.51s/it]predicting train subjects:  58%|█████▊    | 265/456 [06:59<04:47,  1.51s/it]predicting train subjects:  58%|█████▊    | 266/456 [07:00<04:47,  1.51s/it]predicting train subjects:  59%|█████▊    | 267/456 [07:02<04:49,  1.53s/it]predicting train subjects:  59%|█████▉    | 268/456 [07:03<04:50,  1.55s/it]predicting train subjects:  59%|█████▉    | 269/456 [07:05<04:49,  1.55s/it]predicting train subjects:  59%|█████▉    | 270/456 [07:06<04:41,  1.52s/it]predicting train subjects:  59%|█████▉    | 271/456 [07:08<04:45,  1.54s/it]predicting train subjects:  60%|█████▉    | 272/456 [07:09<04:45,  1.55s/it]predicting train subjects:  60%|█████▉    | 273/456 [07:11<04:47,  1.57s/it]predicting train subjects:  60%|██████    | 274/456 [07:13<04:48,  1.59s/it]predicting train subjects:  60%|██████    | 275/456 [07:14<04:50,  1.60s/it]predicting train subjects:  61%|██████    | 276/456 [07:16<04:49,  1.61s/it]predicting train subjects:  61%|██████    | 277/456 [07:17<04:42,  1.58s/it]predicting train subjects:  61%|██████    | 278/456 [07:19<04:37,  1.56s/it]predicting train subjects:  61%|██████    | 279/456 [07:20<04:32,  1.54s/it]predicting train subjects:  61%|██████▏   | 280/456 [07:22<04:28,  1.53s/it]predicting train subjects:  62%|██████▏   | 281/456 [07:23<04:23,  1.51s/it]predicting train subjects:  62%|██████▏   | 282/456 [07:25<04:20,  1.50s/it]predicting train subjects:  62%|██████▏   | 283/456 [07:26<04:01,  1.39s/it]predicting train subjects:  62%|██████▏   | 284/456 [07:27<03:43,  1.30s/it]predicting train subjects:  62%|██████▎   | 285/456 [07:28<03:33,  1.25s/it]predicting train subjects:  63%|██████▎   | 286/456 [07:29<03:24,  1.20s/it]predicting train subjects:  63%|██████▎   | 287/456 [07:31<03:27,  1.23s/it]predicting train subjects:  63%|██████▎   | 288/456 [07:32<03:20,  1.19s/it]predicting train subjects:  63%|██████▎   | 289/456 [07:33<03:12,  1.15s/it]predicting train subjects:  64%|██████▎   | 290/456 [07:34<03:10,  1.15s/it]predicting train subjects:  64%|██████▍   | 291/456 [07:35<03:06,  1.13s/it]predicting train subjects:  64%|██████▍   | 292/456 [07:36<03:09,  1.15s/it]predicting train subjects:  64%|██████▍   | 293/456 [07:37<03:08,  1.15s/it]predicting train subjects:  64%|██████▍   | 294/456 [07:38<03:02,  1.13s/it]predicting train subjects:  65%|██████▍   | 295/456 [07:39<02:57,  1.10s/it]predicting train subjects:  65%|██████▍   | 296/456 [07:41<02:54,  1.09s/it]predicting train subjects:  65%|██████▌   | 297/456 [07:42<02:52,  1.09s/it]predicting train subjects:  65%|██████▌   | 298/456 [07:43<02:54,  1.10s/it]predicting train subjects:  66%|██████▌   | 299/456 [07:44<02:56,  1.13s/it]predicting train subjects:  66%|██████▌   | 300/456 [07:45<02:55,  1.13s/it]predicting train subjects:  66%|██████▌   | 301/456 [07:47<03:32,  1.37s/it]predicting train subjects:  66%|██████▌   | 302/456 [07:49<03:55,  1.53s/it]predicting train subjects:  66%|██████▋   | 303/456 [07:51<04:13,  1.66s/it]predicting train subjects:  67%|██████▋   | 304/456 [07:53<04:27,  1.76s/it]predicting train subjects:  67%|██████▋   | 305/456 [07:55<04:31,  1.80s/it]predicting train subjects:  67%|██████▋   | 306/456 [07:57<04:37,  1.85s/it]predicting train subjects:  67%|██████▋   | 307/456 [07:59<04:46,  1.92s/it]predicting train subjects:  68%|██████▊   | 308/456 [08:01<04:53,  1.98s/it]predicting train subjects:  68%|██████▊   | 309/456 [08:03<05:00,  2.05s/it]predicting train subjects:  68%|██████▊   | 310/456 [08:05<05:01,  2.07s/it]predicting train subjects:  68%|██████▊   | 311/456 [08:07<05:00,  2.07s/it]predicting train subjects:  68%|██████▊   | 312/456 [08:09<04:59,  2.08s/it]predicting train subjects:  69%|██████▊   | 313/456 [08:11<04:51,  2.04s/it]predicting train subjects:  69%|██████▉   | 314/456 [08:13<04:43,  2.00s/it]predicting train subjects:  69%|██████▉   | 315/456 [08:15<04:37,  1.97s/it]predicting train subjects:  69%|██████▉   | 316/456 [08:17<04:32,  1.95s/it]predicting train subjects:  70%|██████▉   | 317/456 [08:19<04:31,  1.95s/it]predicting train subjects:  70%|██████▉   | 318/456 [08:21<04:29,  1.95s/it]predicting train subjects:  70%|██████▉   | 319/456 [08:23<04:15,  1.86s/it]predicting train subjects:  70%|███████   | 320/456 [08:24<04:08,  1.82s/it]predicting train subjects:  70%|███████   | 321/456 [08:26<04:01,  1.79s/it]predicting train subjects:  71%|███████   | 322/456 [08:28<03:57,  1.77s/it]predicting train subjects:  71%|███████   | 323/456 [08:29<03:52,  1.74s/it]predicting train subjects:  71%|███████   | 324/456 [08:31<03:47,  1.72s/it]predicting train subjects:  71%|███████▏  | 325/456 [08:33<03:33,  1.63s/it]predicting train subjects:  71%|███████▏  | 326/456 [08:34<03:22,  1.56s/it]predicting train subjects:  72%|███████▏  | 327/456 [08:35<03:15,  1.51s/it]predicting train subjects:  72%|███████▏  | 328/456 [08:37<03:12,  1.50s/it]predicting train subjects:  72%|███████▏  | 329/456 [08:38<03:06,  1.47s/it]predicting train subjects:  72%|███████▏  | 330/456 [08:40<03:01,  1.44s/it]predicting train subjects:  73%|███████▎  | 331/456 [08:41<03:09,  1.51s/it]predicting train subjects:  73%|███████▎  | 332/456 [08:43<03:13,  1.56s/it]predicting train subjects:  73%|███████▎  | 333/456 [08:45<03:17,  1.60s/it]predicting train subjects:  73%|███████▎  | 334/456 [08:46<03:18,  1.63s/it]predicting train subjects:  73%|███████▎  | 335/456 [08:48<03:19,  1.65s/it]predicting train subjects:  74%|███████▎  | 336/456 [08:50<03:20,  1.67s/it]predicting train subjects:  74%|███████▍  | 337/456 [08:51<03:18,  1.67s/it]predicting train subjects:  74%|███████▍  | 338/456 [08:53<03:16,  1.67s/it]predicting train subjects:  74%|███████▍  | 339/456 [08:55<03:17,  1.69s/it]predicting train subjects:  75%|███████▍  | 340/456 [08:57<03:16,  1.70s/it]predicting train subjects:  75%|███████▍  | 341/456 [08:58<03:14,  1.69s/it]predicting train subjects:  75%|███████▌  | 342/456 [09:00<03:12,  1.69s/it]predicting train subjects:  75%|███████▌  | 343/456 [09:02<03:08,  1.67s/it]predicting train subjects:  75%|███████▌  | 344/456 [09:03<03:07,  1.67s/it]predicting train subjects:  76%|███████▌  | 345/456 [09:05<03:06,  1.68s/it]predicting train subjects:  76%|███████▌  | 346/456 [09:07<03:04,  1.67s/it]predicting train subjects:  76%|███████▌  | 347/456 [09:08<03:02,  1.68s/it]predicting train subjects:  76%|███████▋  | 348/456 [09:10<02:59,  1.66s/it]predicting train subjects:  77%|███████▋  | 349/456 [09:12<02:58,  1.66s/it]predicting train subjects:  77%|███████▋  | 350/456 [09:13<02:57,  1.68s/it]predicting train subjects:  77%|███████▋  | 351/456 [09:15<02:53,  1.66s/it]predicting train subjects:  77%|███████▋  | 352/456 [09:17<02:52,  1.66s/it]predicting train subjects:  77%|███████▋  | 353/456 [09:18<02:51,  1.66s/it]predicting train subjects:  78%|███████▊  | 354/456 [09:20<02:48,  1.65s/it]predicting train subjects:  78%|███████▊  | 355/456 [09:22<02:50,  1.69s/it]predicting train subjects:  78%|███████▊  | 356/456 [09:23<02:50,  1.70s/it]predicting train subjects:  78%|███████▊  | 357/456 [09:25<02:53,  1.75s/it]predicting train subjects:  79%|███████▊  | 358/456 [09:27<02:51,  1.75s/it]predicting train subjects:  79%|███████▊  | 359/456 [09:29<02:48,  1.73s/it]predicting train subjects:  79%|███████▉  | 360/456 [09:30<02:47,  1.75s/it]predicting train subjects:  79%|███████▉  | 361/456 [09:32<02:47,  1.76s/it]predicting train subjects:  79%|███████▉  | 362/456 [09:34<02:46,  1.77s/it]predicting train subjects:  80%|███████▉  | 363/456 [09:36<02:45,  1.77s/it]predicting train subjects:  80%|███████▉  | 364/456 [09:38<02:43,  1.77s/it]predicting train subjects:  80%|████████  | 365/456 [09:39<02:40,  1.76s/it]predicting train subjects:  80%|████████  | 366/456 [09:41<02:40,  1.78s/it]predicting train subjects:  80%|████████  | 367/456 [09:43<02:29,  1.68s/it]predicting train subjects:  81%|████████  | 368/456 [09:44<02:19,  1.59s/it]predicting train subjects:  81%|████████  | 369/456 [09:45<02:14,  1.55s/it]predicting train subjects:  81%|████████  | 370/456 [09:47<02:10,  1.52s/it]predicting train subjects:  81%|████████▏ | 371/456 [09:48<02:07,  1.50s/it]predicting train subjects:  82%|████████▏ | 372/456 [09:50<02:02,  1.46s/it]predicting train subjects:  82%|████████▏ | 373/456 [09:52<02:16,  1.64s/it]predicting train subjects:  82%|████████▏ | 374/456 [09:54<02:24,  1.76s/it]predicting train subjects:  82%|████████▏ | 375/456 [09:56<02:34,  1.91s/it]predicting train subjects:  82%|████████▏ | 376/456 [09:58<02:36,  1.96s/it]predicting train subjects:  83%|████████▎ | 377/456 [10:00<02:40,  2.03s/it]predicting train subjects:  83%|████████▎ | 378/456 [10:02<02:40,  2.05s/it]predicting train subjects:  83%|████████▎ | 379/456 [10:04<02:24,  1.87s/it]predicting train subjects:  83%|████████▎ | 380/456 [10:05<02:12,  1.75s/it]predicting train subjects:  84%|████████▎ | 381/456 [10:07<02:05,  1.67s/it]predicting train subjects:  84%|████████▍ | 382/456 [10:08<01:58,  1.60s/it]predicting train subjects:  84%|████████▍ | 383/456 [10:10<01:53,  1.56s/it]predicting train subjects:  84%|████████▍ | 384/456 [10:11<01:50,  1.54s/it]predicting train subjects:  84%|████████▍ | 385/456 [10:13<01:49,  1.55s/it]predicting train subjects:  85%|████████▍ | 386/456 [10:14<01:48,  1.55s/it]predicting train subjects:  85%|████████▍ | 387/456 [10:16<01:46,  1.54s/it]predicting train subjects:  85%|████████▌ | 388/456 [10:17<01:43,  1.52s/it]predicting train subjects:  85%|████████▌ | 389/456 [10:19<01:43,  1.54s/it]predicting train subjects:  86%|████████▌ | 390/456 [10:20<01:42,  1.55s/it]predicting train subjects:  86%|████████▌ | 391/456 [10:22<01:41,  1.57s/it]predicting train subjects:  86%|████████▌ | 392/456 [10:24<01:42,  1.59s/it]predicting train subjects:  86%|████████▌ | 393/456 [10:25<01:40,  1.60s/it]predicting train subjects:  86%|████████▋ | 394/456 [10:27<01:38,  1.59s/it]predicting train subjects:  87%|████████▋ | 395/456 [10:29<01:37,  1.61s/it]predicting train subjects:  87%|████████▋ | 396/456 [10:30<01:37,  1.63s/it]predicting train subjects:  87%|████████▋ | 397/456 [10:32<01:34,  1.60s/it]predicting train subjects:  87%|████████▋ | 398/456 [10:33<01:30,  1.56s/it]predicting train subjects:  88%|████████▊ | 399/456 [10:35<01:27,  1.54s/it]predicting train subjects:  88%|████████▊ | 400/456 [10:36<01:24,  1.51s/it]predicting train subjects:  88%|████████▊ | 401/456 [10:38<01:22,  1.50s/it]predicting train subjects:  88%|████████▊ | 402/456 [10:39<01:20,  1.49s/it]predicting train subjects:  88%|████████▊ | 403/456 [10:40<01:12,  1.37s/it]predicting train subjects:  89%|████████▊ | 404/456 [10:41<01:07,  1.29s/it]predicting train subjects:  89%|████████▉ | 405/456 [10:42<01:02,  1.23s/it]predicting train subjects:  89%|████████▉ | 406/456 [10:43<00:59,  1.19s/it]predicting train subjects:  89%|████████▉ | 407/456 [10:45<00:56,  1.16s/it]predicting train subjects:  89%|████████▉ | 408/456 [10:46<00:54,  1.14s/it]predicting train subjects:  90%|████████▉ | 409/456 [10:47<00:52,  1.11s/it]predicting train subjects:  90%|████████▉ | 410/456 [10:48<00:50,  1.09s/it]predicting train subjects:  90%|█████████ | 411/456 [10:49<00:48,  1.07s/it]predicting train subjects:  90%|█████████ | 412/456 [10:50<00:47,  1.07s/it]predicting train subjects:  91%|█████████ | 413/456 [10:51<00:46,  1.08s/it]predicting train subjects:  91%|█████████ | 414/456 [10:52<00:46,  1.11s/it]predicting train subjects:  91%|█████████ | 415/456 [10:53<00:44,  1.09s/it]predicting train subjects:  91%|█████████ | 416/456 [10:54<00:43,  1.09s/it]predicting train subjects:  91%|█████████▏| 417/456 [10:55<00:42,  1.08s/it]predicting train subjects:  92%|█████████▏| 418/456 [10:56<00:41,  1.08s/it]predicting train subjects:  92%|█████████▏| 419/456 [10:58<00:40,  1.09s/it]predicting train subjects:  92%|█████████▏| 420/456 [10:59<00:38,  1.08s/it]predicting train subjects:  92%|█████████▏| 421/456 [11:00<00:46,  1.32s/it]predicting train subjects:  93%|█████████▎| 422/456 [11:02<00:50,  1.50s/it]predicting train subjects:  93%|█████████▎| 423/456 [11:04<00:53,  1.61s/it]predicting train subjects:  93%|█████████▎| 424/456 [11:06<00:54,  1.70s/it]predicting train subjects:  93%|█████████▎| 425/456 [11:08<00:55,  1.78s/it]predicting train subjects:  93%|█████████▎| 426/456 [11:10<00:54,  1.82s/it]predicting train subjects:  94%|█████████▎| 427/456 [11:12<00:55,  1.91s/it]predicting train subjects:  94%|█████████▍| 428/456 [11:14<00:55,  1.99s/it]predicting train subjects:  94%|█████████▍| 429/456 [11:16<00:54,  2.02s/it]predicting train subjects:  94%|█████████▍| 430/456 [11:18<00:52,  2.03s/it]predicting train subjects:  95%|█████████▍| 431/456 [11:20<00:50,  2.03s/it]predicting train subjects:  95%|█████████▍| 432/456 [11:23<00:49,  2.04s/it]predicting train subjects:  95%|█████████▍| 433/456 [11:25<00:46,  2.04s/it]predicting train subjects:  95%|█████████▌| 434/456 [11:27<00:43,  2.00s/it]predicting train subjects:  95%|█████████▌| 435/456 [11:29<00:42,  2.01s/it]predicting train subjects:  96%|█████████▌| 436/456 [11:31<00:40,  2.01s/it]predicting train subjects:  96%|█████████▌| 437/456 [11:32<00:37,  1.98s/it]predicting train subjects:  96%|█████████▌| 438/456 [11:34<00:35,  1.98s/it]predicting train subjects:  96%|█████████▋| 439/456 [11:36<00:32,  1.92s/it]predicting train subjects:  96%|█████████▋| 440/456 [11:38<00:29,  1.84s/it]predicting train subjects:  97%|█████████▋| 441/456 [11:40<00:26,  1.78s/it]predicting train subjects:  97%|█████████▋| 442/456 [11:41<00:24,  1.75s/it]predicting train subjects:  97%|█████████▋| 443/456 [11:43<00:22,  1.73s/it]predicting train subjects:  97%|█████████▋| 444/456 [11:45<00:20,  1.71s/it]predicting train subjects:  98%|█████████▊| 445/456 [11:46<00:18,  1.64s/it]predicting train subjects:  98%|█████████▊| 446/456 [11:47<00:15,  1.56s/it]predicting train subjects:  98%|█████████▊| 447/456 [11:49<00:13,  1.51s/it]predicting train subjects:  98%|█████████▊| 448/456 [11:50<00:12,  1.52s/it]predicting train subjects:  98%|█████████▊| 449/456 [11:52<00:10,  1.48s/it]predicting train subjects:  99%|█████████▊| 450/456 [11:53<00:08,  1.44s/it]predicting train subjects:  99%|█████████▉| 451/456 [11:55<00:07,  1.52s/it]predicting train subjects:  99%|█████████▉| 452/456 [11:56<00:06,  1.58s/it]predicting train subjects:  99%|█████████▉| 453/456 [11:58<00:04,  1.61s/it]predicting train subjects: 100%|█████████▉| 454/456 [12:00<00:03,  1.65s/it]predicting train subjects: 100%|█████████▉| 455/456 [12:02<00:01,  1.67s/it]predicting train subjects: 100%|██████████| 456/456 [12:03<00:00,  1.70s/it]
Loading train:   0%|          | 0/456 [00:00<?, ?it/s]Loading train:   0%|          | 1/456 [00:01<11:54,  1.57s/it]Loading train:   0%|          | 2/456 [00:03<11:37,  1.54s/it]Loading train:   1%|          | 3/456 [00:04<11:32,  1.53s/it]Loading train:   1%|          | 4/456 [00:05<11:03,  1.47s/it]Loading train:   1%|          | 5/456 [00:08<12:47,  1.70s/it]Loading train:   1%|▏         | 6/456 [00:09<12:12,  1.63s/it]Loading train:   2%|▏         | 7/456 [00:10<11:34,  1.55s/it]Loading train:   2%|▏         | 8/456 [00:11<10:05,  1.35s/it]Loading train:   2%|▏         | 9/456 [00:13<10:19,  1.39s/it]Loading train:   2%|▏         | 10/456 [00:14<10:52,  1.46s/it]Loading train:   2%|▏         | 11/456 [00:16<11:28,  1.55s/it]Loading train:   3%|▎         | 12/456 [00:17<10:30,  1.42s/it]Loading train:   3%|▎         | 13/456 [00:19<10:24,  1.41s/it]Loading train:   3%|▎         | 14/456 [00:20<10:37,  1.44s/it]Loading train:   3%|▎         | 15/456 [00:21<09:34,  1.30s/it]Loading train:   4%|▎         | 16/456 [00:23<09:54,  1.35s/it]Loading train:   4%|▎         | 17/456 [00:24<10:25,  1.42s/it]Loading train:   4%|▍         | 18/456 [00:26<10:06,  1.38s/it]Loading train:   4%|▍         | 19/456 [00:27<10:06,  1.39s/it]Loading train:   4%|▍         | 20/456 [00:28<09:45,  1.34s/it]Loading train:   5%|▍         | 21/456 [00:30<09:45,  1.35s/it]Loading train:   5%|▍         | 22/456 [00:31<09:36,  1.33s/it]Loading train:   5%|▌         | 23/456 [00:32<09:44,  1.35s/it]Loading train:   5%|▌         | 24/456 [00:33<08:43,  1.21s/it]Loading train:   5%|▌         | 25/456 [00:34<08:56,  1.24s/it]Loading train:   6%|▌         | 26/456 [00:36<09:01,  1.26s/it]Loading train:   6%|▌         | 27/456 [00:37<08:58,  1.25s/it]Loading train:   6%|▌         | 28/456 [00:38<08:37,  1.21s/it]Loading train:   6%|▋         | 29/456 [00:39<08:58,  1.26s/it]Loading train:   7%|▋         | 30/456 [00:41<08:59,  1.27s/it]Loading train:   7%|▋         | 31/456 [00:42<08:55,  1.26s/it]Loading train:   7%|▋         | 32/456 [00:43<08:51,  1.25s/it]Loading train:   7%|▋         | 33/456 [00:45<09:00,  1.28s/it]Loading train:   7%|▋         | 34/456 [00:46<08:53,  1.27s/it]Loading train:   8%|▊         | 35/456 [00:47<09:02,  1.29s/it]Loading train:   8%|▊         | 36/456 [00:49<09:23,  1.34s/it]Loading train:   8%|▊         | 37/456 [00:50<10:02,  1.44s/it]Loading train:   8%|▊         | 38/456 [00:51<09:38,  1.38s/it]Loading train:   9%|▊         | 39/456 [00:53<09:36,  1.38s/it]Loading train:   9%|▉         | 40/456 [00:54<09:41,  1.40s/it]Loading train:   9%|▉         | 41/456 [00:56<09:35,  1.39s/it]Loading train:   9%|▉         | 42/456 [00:57<10:12,  1.48s/it]Loading train:   9%|▉         | 43/456 [00:59<09:44,  1.41s/it]Loading train:  10%|▉         | 44/456 [01:00<09:29,  1.38s/it]Loading train:  10%|▉         | 45/456 [01:01<09:16,  1.35s/it]Loading train:  10%|█         | 46/456 [01:03<09:34,  1.40s/it]Loading train:  10%|█         | 47/456 [01:04<09:30,  1.40s/it]Loading train:  11%|█         | 48/456 [01:05<09:25,  1.38s/it]Loading train:  11%|█         | 49/456 [01:07<08:53,  1.31s/it]Loading train:  11%|█         | 50/456 [01:08<08:51,  1.31s/it]Loading train:  11%|█         | 51/456 [01:09<09:01,  1.34s/it]Loading train:  11%|█▏        | 52/456 [01:11<09:05,  1.35s/it]Loading train:  12%|█▏        | 53/456 [01:12<09:10,  1.36s/it]Loading train:  12%|█▏        | 54/456 [01:13<09:04,  1.35s/it]Loading train:  12%|█▏        | 55/456 [01:15<09:37,  1.44s/it]Loading train:  12%|█▏        | 56/456 [01:17<09:43,  1.46s/it]Loading train:  12%|█▎        | 57/456 [01:18<09:36,  1.45s/it]Loading train:  13%|█▎        | 58/456 [01:19<08:48,  1.33s/it]Loading train:  13%|█▎        | 59/456 [01:20<08:38,  1.31s/it]Loading train:  13%|█▎        | 60/456 [01:22<08:44,  1.33s/it]Loading train:  13%|█▎        | 61/456 [01:23<09:20,  1.42s/it]Loading train:  14%|█▎        | 62/456 [01:25<09:36,  1.46s/it]Loading train:  14%|█▍        | 63/456 [01:26<09:31,  1.45s/it]Loading train:  14%|█▍        | 64/456 [01:27<08:57,  1.37s/it]Loading train:  14%|█▍        | 65/456 [01:29<08:18,  1.28s/it]Loading train:  14%|█▍        | 66/456 [01:30<07:52,  1.21s/it]Loading train:  15%|█▍        | 67/456 [01:31<07:30,  1.16s/it]Loading train:  15%|█▍        | 68/456 [01:32<07:13,  1.12s/it]Loading train:  15%|█▌        | 69/456 [01:33<06:56,  1.08s/it]Loading train:  15%|█▌        | 70/456 [01:34<06:39,  1.03s/it]Loading train:  16%|█▌        | 71/456 [01:34<06:17,  1.02it/s]Loading train:  16%|█▌        | 72/456 [01:35<06:21,  1.01it/s]Loading train:  16%|█▌        | 73/456 [01:36<06:23,  1.00s/it]Loading train:  16%|█▌        | 74/456 [01:37<06:19,  1.01it/s]Loading train:  16%|█▋        | 75/456 [01:39<06:27,  1.02s/it]Loading train:  17%|█▋        | 76/456 [01:39<06:23,  1.01s/it]Loading train:  17%|█▋        | 77/456 [01:40<06:17,  1.00it/s]Loading train:  17%|█▋        | 78/456 [01:41<06:11,  1.02it/s]Loading train:  17%|█▋        | 79/456 [01:42<05:25,  1.16it/s]Loading train:  18%|█▊        | 80/456 [01:43<04:44,  1.32it/s]Loading train:  18%|█▊        | 81/456 [01:43<04:15,  1.47it/s]Loading train:  18%|█▊        | 82/456 [01:44<03:58,  1.57it/s]Loading train:  18%|█▊        | 83/456 [01:44<03:43,  1.67it/s]Loading train:  18%|█▊        | 84/456 [01:45<03:36,  1.72it/s]Loading train:  19%|█▊        | 85/456 [01:45<03:26,  1.80it/s]Loading train:  19%|█▉        | 86/456 [01:46<03:15,  1.89it/s]Loading train:  19%|█▉        | 87/456 [01:46<03:17,  1.87it/s]Loading train:  19%|█▉        | 88/456 [01:47<03:26,  1.78it/s]Loading train:  20%|█▉        | 89/456 [01:47<03:23,  1.81it/s]Loading train:  20%|█▉        | 90/456 [01:48<03:24,  1.79it/s]Loading train:  20%|█▉        | 91/456 [01:48<03:17,  1.85it/s]Loading train:  20%|██        | 92/456 [01:49<03:12,  1.89it/s]Loading train:  20%|██        | 93/456 [01:49<03:08,  1.93it/s]Loading train:  21%|██        | 94/456 [01:50<03:09,  1.91it/s]Loading train:  21%|██        | 95/456 [01:50<03:08,  1.92it/s]Loading train:  21%|██        | 96/456 [01:51<03:16,  1.83it/s]Loading train:  21%|██▏       | 97/456 [01:52<03:55,  1.53it/s]Loading train:  21%|██▏       | 98/456 [01:53<04:26,  1.34it/s]Loading train:  22%|██▏       | 99/456 [01:54<04:51,  1.23it/s]Loading train:  22%|██▏       | 100/456 [01:55<05:02,  1.18it/s]Loading train:  22%|██▏       | 101/456 [01:56<05:08,  1.15it/s]Loading train:  22%|██▏       | 102/456 [01:57<05:10,  1.14it/s]Loading train:  23%|██▎       | 103/456 [01:58<05:24,  1.09it/s]Loading train:  23%|██▎       | 104/456 [01:59<05:31,  1.06it/s]Loading train:  23%|██▎       | 105/456 [02:00<05:44,  1.02it/s]Loading train:  23%|██▎       | 106/456 [02:01<05:44,  1.02it/s]Loading train:  23%|██▎       | 107/456 [02:02<05:45,  1.01it/s]Loading train:  24%|██▎       | 108/456 [02:03<05:44,  1.01it/s]Loading train:  24%|██▍       | 109/456 [02:04<05:53,  1.02s/it]Loading train:  24%|██▍       | 110/456 [02:05<05:41,  1.01it/s]Loading train:  24%|██▍       | 111/456 [02:06<05:43,  1.00it/s]Loading train:  25%|██▍       | 112/456 [02:07<05:56,  1.04s/it]Loading train:  25%|██▍       | 113/456 [02:08<05:49,  1.02s/it]Loading train:  25%|██▌       | 114/456 [02:09<05:35,  1.02it/s]Loading train:  25%|██▌       | 115/456 [02:10<05:44,  1.01s/it]Loading train:  25%|██▌       | 116/456 [02:11<05:44,  1.01s/it]Loading train:  26%|██▌       | 117/456 [02:12<05:40,  1.00s/it]Loading train:  26%|██▌       | 118/456 [02:13<05:38,  1.00s/it]Loading train:  26%|██▌       | 119/456 [02:14<05:58,  1.06s/it]Loading train:  26%|██▋       | 120/456 [02:15<05:54,  1.06s/it]Loading train:  27%|██▋       | 121/456 [02:16<05:54,  1.06s/it]Loading train:  27%|██▋       | 122/456 [02:17<05:58,  1.07s/it]Loading train:  27%|██▋       | 123/456 [02:18<05:57,  1.07s/it]Loading train:  27%|██▋       | 124/456 [02:19<06:03,  1.10s/it]Loading train:  27%|██▋       | 125/456 [02:20<05:50,  1.06s/it]Loading train:  28%|██▊       | 126/456 [02:21<05:44,  1.04s/it]Loading train:  28%|██▊       | 127/456 [02:22<05:32,  1.01s/it]Loading train:  28%|██▊       | 128/456 [02:23<05:14,  1.04it/s]Loading train:  28%|██▊       | 129/456 [02:24<05:05,  1.07it/s]Loading train:  29%|██▊       | 130/456 [02:25<04:58,  1.09it/s]Loading train:  29%|██▊       | 131/456 [02:26<05:03,  1.07it/s]Loading train:  29%|██▉       | 132/456 [02:27<05:03,  1.07it/s]Loading train:  29%|██▉       | 133/456 [02:28<05:35,  1.04s/it]Loading train:  29%|██▉       | 134/456 [02:29<05:51,  1.09s/it]Loading train:  30%|██▉       | 135/456 [02:31<06:01,  1.13s/it]Loading train:  30%|██▉       | 136/456 [02:32<06:30,  1.22s/it]Loading train:  30%|███       | 137/456 [02:33<06:29,  1.22s/it]Loading train:  30%|███       | 138/456 [02:35<06:43,  1.27s/it]Loading train:  30%|███       | 139/456 [02:35<06:10,  1.17s/it]Loading train:  31%|███       | 140/456 [02:36<05:47,  1.10s/it]Loading train:  31%|███       | 141/456 [02:37<05:27,  1.04s/it]Loading train:  31%|███       | 142/456 [02:38<05:25,  1.04s/it]Loading train:  31%|███▏      | 143/456 [02:39<05:14,  1.01s/it]Loading train:  32%|███▏      | 144/456 [02:41<05:37,  1.08s/it]Loading train:  32%|███▏      | 145/456 [02:42<05:31,  1.07s/it]Loading train:  32%|███▏      | 146/456 [02:43<05:18,  1.03s/it]Loading train:  32%|███▏      | 147/456 [02:43<05:01,  1.03it/s]Loading train:  32%|███▏      | 148/456 [02:44<04:53,  1.05it/s]Loading train:  33%|███▎      | 149/456 [02:45<04:43,  1.08it/s]Loading train:  33%|███▎      | 150/456 [02:46<04:42,  1.08it/s]Loading train:  33%|███▎      | 151/456 [02:47<04:41,  1.08it/s]Loading train:  33%|███▎      | 152/456 [02:48<04:38,  1.09it/s]Loading train:  34%|███▎      | 153/456 [02:49<04:48,  1.05it/s]Loading train:  34%|███▍      | 154/456 [02:50<04:49,  1.04it/s]Loading train:  34%|███▍      | 155/456 [02:51<04:50,  1.03it/s]Loading train:  34%|███▍      | 156/456 [02:52<04:47,  1.04it/s]Loading train:  34%|███▍      | 157/456 [02:53<04:57,  1.01it/s]Loading train:  35%|███▍      | 158/456 [02:54<04:49,  1.03it/s]Loading train:  35%|███▍      | 159/456 [02:55<04:43,  1.05it/s]Loading train:  35%|███▌      | 160/456 [02:56<04:41,  1.05it/s]Loading train:  35%|███▌      | 161/456 [02:57<04:46,  1.03it/s]Loading train:  36%|███▌      | 162/456 [02:58<04:47,  1.02it/s]Loading train:  36%|███▌      | 163/456 [02:58<04:15,  1.15it/s]Loading train:  36%|███▌      | 164/456 [02:59<03:55,  1.24it/s]Loading train:  36%|███▌      | 165/456 [03:00<03:40,  1.32it/s]Loading train:  36%|███▋      | 166/456 [03:00<03:45,  1.29it/s]Loading train:  37%|███▋      | 167/456 [03:01<03:25,  1.41it/s]Loading train:  37%|███▋      | 168/456 [03:02<03:10,  1.51it/s]Loading train:  37%|███▋      | 169/456 [03:02<03:13,  1.49it/s]Loading train:  37%|███▋      | 170/456 [03:03<03:06,  1.54it/s]Loading train:  38%|███▊      | 171/456 [03:03<03:04,  1.54it/s]Loading train:  38%|███▊      | 172/456 [03:04<03:09,  1.50it/s]Loading train:  38%|███▊      | 173/456 [03:05<03:04,  1.53it/s]Loading train:  38%|███▊      | 174/456 [03:05<02:55,  1.61it/s]Loading train:  38%|███▊      | 175/456 [03:06<02:51,  1.64it/s]Loading train:  39%|███▊      | 176/456 [03:06<02:45,  1.69it/s]Loading train:  39%|███▉      | 177/456 [03:07<02:40,  1.74it/s]Loading train:  39%|███▉      | 178/456 [03:08<02:43,  1.70it/s]Loading train:  39%|███▉      | 179/456 [03:08<02:43,  1.69it/s]Loading train:  39%|███▉      | 180/456 [03:09<02:43,  1.69it/s]Loading train:  40%|███▉      | 181/456 [03:10<03:41,  1.24it/s]Loading train:  40%|███▉      | 182/456 [03:11<04:06,  1.11it/s]Loading train:  40%|████      | 183/456 [03:12<04:23,  1.04it/s]Loading train:  40%|████      | 184/456 [03:13<04:30,  1.00it/s]Loading train:  41%|████      | 185/456 [03:15<04:42,  1.04s/it]Loading train:  41%|████      | 186/456 [03:16<05:01,  1.12s/it]Loading train:  41%|████      | 187/456 [03:17<05:17,  1.18s/it]Loading train:  41%|████      | 188/456 [03:18<05:17,  1.18s/it]Loading train:  41%|████▏     | 189/456 [03:20<05:20,  1.20s/it]Loading train:  42%|████▏     | 190/456 [03:21<05:14,  1.18s/it]Loading train:  42%|████▏     | 191/456 [03:22<05:09,  1.17s/it]Loading train:  42%|████▏     | 192/456 [03:23<05:10,  1.17s/it]Loading train:  42%|████▏     | 193/456 [03:24<05:09,  1.18s/it]Loading train:  43%|████▎     | 194/456 [03:25<05:02,  1.16s/it]Loading train:  43%|████▎     | 195/456 [03:27<05:09,  1.19s/it]Loading train:  43%|████▎     | 196/456 [03:28<05:06,  1.18s/it]Loading train:  43%|████▎     | 197/456 [03:29<05:01,  1.17s/it]Loading train:  43%|████▎     | 198/456 [03:30<04:58,  1.16s/it]Loading train:  44%|████▎     | 199/456 [03:31<04:48,  1.12s/it]Loading train:  44%|████▍     | 200/456 [03:32<04:36,  1.08s/it]Loading train:  44%|████▍     | 201/456 [03:33<04:32,  1.07s/it]Loading train:  44%|████▍     | 202/456 [03:34<04:24,  1.04s/it]Loading train:  45%|████▍     | 203/456 [03:35<04:23,  1.04s/it]Loading train:  45%|████▍     | 204/456 [03:36<04:20,  1.03s/it]Loading train:  45%|████▍     | 205/456 [03:37<04:09,  1.01it/s]Loading train:  45%|████▌     | 206/456 [03:38<03:59,  1.04it/s]Loading train:  45%|████▌     | 207/456 [03:39<03:55,  1.06it/s]Loading train:  46%|████▌     | 208/456 [03:40<03:45,  1.10it/s]Loading train:  46%|████▌     | 209/456 [03:41<03:42,  1.11it/s]Loading train:  46%|████▌     | 210/456 [03:42<03:45,  1.09it/s]Loading train:  46%|████▋     | 211/456 [03:42<03:44,  1.09it/s]Loading train:  46%|████▋     | 212/456 [03:43<03:46,  1.08it/s]Loading train:  47%|████▋     | 213/456 [03:44<03:37,  1.12it/s]Loading train:  47%|████▋     | 214/456 [03:45<03:35,  1.12it/s]Loading train:  47%|████▋     | 215/456 [03:46<03:28,  1.15it/s]Loading train:  47%|████▋     | 216/456 [03:47<03:30,  1.14it/s]Loading train:  48%|████▊     | 217/456 [03:48<03:37,  1.10it/s]Loading train:  48%|████▊     | 218/456 [03:49<03:43,  1.07it/s]Loading train:  48%|████▊     | 219/456 [03:50<03:38,  1.08it/s]Loading train:  48%|████▊     | 220/456 [03:51<03:32,  1.11it/s]Loading train:  48%|████▊     | 221/456 [03:51<03:32,  1.11it/s]Loading train:  49%|████▊     | 222/456 [03:52<03:29,  1.12it/s]Loading train:  49%|████▉     | 223/456 [03:53<03:47,  1.03it/s]Loading train:  49%|████▉     | 224/456 [03:54<03:50,  1.01it/s]Loading train:  49%|████▉     | 225/456 [03:56<04:03,  1.06s/it]Loading train:  50%|████▉     | 226/456 [03:57<04:05,  1.07s/it]Loading train:  50%|████▉     | 227/456 [03:58<04:01,  1.05s/it]Loading train:  50%|█████     | 228/456 [03:59<03:55,  1.03s/it]Loading train:  50%|█████     | 229/456 [04:00<04:16,  1.13s/it]Loading train:  50%|█████     | 230/456 [04:01<04:05,  1.09s/it]Loading train:  51%|█████     | 231/456 [04:02<03:55,  1.05s/it]Loading train:  51%|█████     | 232/456 [04:03<03:42,  1.01it/s]Loading train:  51%|█████     | 233/456 [04:04<03:30,  1.06it/s]Loading train:  51%|█████▏    | 234/456 [04:05<03:28,  1.07it/s]Loading train:  52%|█████▏    | 235/456 [04:06<03:31,  1.04it/s]Loading train:  52%|█████▏    | 236/456 [04:07<03:28,  1.06it/s]Loading train:  52%|█████▏    | 237/456 [04:08<03:23,  1.08it/s]Loading train:  52%|█████▏    | 238/456 [04:08<03:24,  1.07it/s]Loading train:  52%|█████▏    | 239/456 [04:09<03:24,  1.06it/s]Loading train:  53%|█████▎    | 240/456 [04:10<03:25,  1.05it/s]Loading train:  53%|█████▎    | 241/456 [04:11<03:23,  1.05it/s]Loading train:  53%|█████▎    | 242/456 [04:12<03:24,  1.05it/s]Loading train:  53%|█████▎    | 243/456 [04:13<03:30,  1.01it/s]Loading train:  54%|█████▎    | 244/456 [04:14<03:37,  1.03s/it]Loading train:  54%|█████▎    | 245/456 [04:15<03:31,  1.00s/it]Loading train:  54%|█████▍    | 246/456 [04:16<03:29,  1.00it/s]Loading train:  54%|█████▍    | 247/456 [04:17<03:21,  1.04it/s]Loading train:  54%|█████▍    | 248/456 [04:18<03:13,  1.08it/s]Loading train:  55%|█████▍    | 249/456 [04:19<03:08,  1.10it/s]Loading train:  55%|█████▍    | 250/456 [04:20<02:56,  1.16it/s]Loading train:  55%|█████▌    | 251/456 [04:21<02:50,  1.20it/s]Loading train:  55%|█████▌    | 252/456 [04:21<02:55,  1.16it/s]Loading train:  55%|█████▌    | 253/456 [04:23<03:18,  1.02it/s]Loading train:  56%|█████▌    | 254/456 [04:24<03:35,  1.07s/it]Loading train:  56%|█████▌    | 255/456 [04:25<03:40,  1.09s/it]Loading train:  56%|█████▌    | 256/456 [04:26<03:48,  1.14s/it]Loading train:  56%|█████▋    | 257/456 [04:28<03:57,  1.19s/it]Loading train:  57%|█████▋    | 258/456 [04:29<03:56,  1.19s/it]Loading train:  57%|█████▋    | 259/456 [04:30<03:40,  1.12s/it]Loading train:  57%|█████▋    | 260/456 [04:31<03:40,  1.13s/it]Loading train:  57%|█████▋    | 261/456 [04:32<03:26,  1.06s/it]Loading train:  57%|█████▋    | 262/456 [04:33<03:19,  1.03s/it]Loading train:  58%|█████▊    | 263/456 [04:34<03:06,  1.03it/s]Loading train:  58%|█████▊    | 264/456 [04:35<03:01,  1.06it/s]Loading train:  58%|█████▊    | 265/456 [04:36<03:08,  1.01it/s]Loading train:  58%|█████▊    | 266/456 [04:37<03:09,  1.00it/s]Loading train:  59%|█████▊    | 267/456 [04:38<03:03,  1.03it/s]Loading train:  59%|█████▉    | 268/456 [04:39<03:01,  1.04it/s]Loading train:  59%|█████▉    | 269/456 [04:40<03:05,  1.01it/s]Loading train:  59%|█████▉    | 270/456 [04:40<02:59,  1.04it/s]Loading train:  59%|█████▉    | 271/456 [04:42<03:01,  1.02it/s]Loading train:  60%|█████▉    | 272/456 [04:42<03:00,  1.02it/s]Loading train:  60%|█████▉    | 273/456 [04:43<02:55,  1.04it/s]Loading train:  60%|██████    | 274/456 [04:44<02:54,  1.04it/s]Loading train:  60%|██████    | 275/456 [04:45<02:53,  1.05it/s]Loading train:  61%|██████    | 276/456 [04:46<02:57,  1.01it/s]Loading train:  61%|██████    | 277/456 [04:47<02:57,  1.01it/s]Loading train:  61%|██████    | 278/456 [04:48<02:53,  1.03it/s]Loading train:  61%|██████    | 279/456 [04:49<02:48,  1.05it/s]Loading train:  61%|██████▏   | 280/456 [04:50<02:49,  1.04it/s]Loading train:  62%|██████▏   | 281/456 [04:51<02:45,  1.06it/s]Loading train:  62%|██████▏   | 282/456 [04:52<02:43,  1.07it/s]Loading train:  62%|██████▏   | 283/456 [04:53<02:35,  1.11it/s]Loading train:  62%|██████▏   | 284/456 [04:53<02:19,  1.24it/s]Loading train:  62%|██████▎   | 285/456 [04:54<02:06,  1.36it/s]Loading train:  63%|██████▎   | 286/456 [04:55<02:11,  1.29it/s]Loading train:  63%|██████▎   | 287/456 [04:55<02:03,  1.37it/s]Loading train:  63%|██████▎   | 288/456 [04:56<01:57,  1.43it/s]Loading train:  63%|██████▎   | 289/456 [04:57<01:51,  1.50it/s]Loading train:  64%|██████▎   | 290/456 [04:57<01:51,  1.49it/s]Loading train:  64%|██████▍   | 291/456 [04:58<01:47,  1.54it/s]Loading train:  64%|██████▍   | 292/456 [04:59<01:44,  1.57it/s]Loading train:  64%|██████▍   | 293/456 [04:59<01:41,  1.61it/s]Loading train:  64%|██████▍   | 294/456 [05:00<01:41,  1.60it/s]Loading train:  65%|██████▍   | 295/456 [05:00<01:38,  1.64it/s]Loading train:  65%|██████▍   | 296/456 [05:01<01:33,  1.71it/s]Loading train:  65%|██████▌   | 297/456 [05:01<01:32,  1.71it/s]Loading train:  65%|██████▌   | 298/456 [05:02<01:30,  1.74it/s]Loading train:  66%|██████▌   | 299/456 [05:03<01:29,  1.75it/s]Loading train:  66%|██████▌   | 300/456 [05:03<01:30,  1.73it/s]Loading train:  66%|██████▌   | 301/456 [05:04<01:53,  1.37it/s]Loading train:  66%|██████▌   | 302/456 [05:05<02:09,  1.19it/s]Loading train:  66%|██████▋   | 303/456 [05:07<02:27,  1.04it/s]Loading train:  67%|██████▋   | 304/456 [05:08<02:27,  1.03it/s]Loading train:  67%|██████▋   | 305/456 [05:09<02:28,  1.02it/s]Loading train:  67%|██████▋   | 306/456 [05:10<02:31,  1.01s/it]Loading train:  67%|██████▋   | 307/456 [05:11<02:50,  1.15s/it]Loading train:  68%|██████▊   | 308/456 [05:12<02:56,  1.19s/it]Loading train:  68%|██████▊   | 309/456 [05:14<02:58,  1.22s/it]Loading train:  68%|██████▊   | 310/456 [05:15<02:54,  1.19s/it]Loading train:  68%|██████▊   | 311/456 [05:16<02:55,  1.21s/it]Loading train:  68%|██████▊   | 312/456 [05:17<02:50,  1.18s/it]Loading train:  69%|██████▊   | 313/456 [05:18<02:40,  1.12s/it]Loading train:  69%|██████▉   | 314/456 [05:19<02:37,  1.11s/it]Loading train:  69%|██████▉   | 315/456 [05:20<02:36,  1.11s/it]Loading train:  69%|██████▉   | 316/456 [05:21<02:31,  1.08s/it]Loading train:  70%|██████▉   | 317/456 [05:22<02:26,  1.05s/it]Loading train:  70%|██████▉   | 318/456 [05:23<02:22,  1.03s/it]Loading train:  70%|██████▉   | 319/456 [05:24<02:14,  1.02it/s]Loading train:  70%|███████   | 320/456 [05:25<02:09,  1.05it/s]Loading train:  70%|███████   | 321/456 [05:26<02:08,  1.05it/s]Loading train:  71%|███████   | 322/456 [05:27<02:10,  1.03it/s]Loading train:  71%|███████   | 323/456 [05:28<02:10,  1.02it/s]Loading train:  71%|███████   | 324/456 [05:29<02:11,  1.00it/s]Loading train:  71%|███████▏  | 325/456 [05:30<02:05,  1.04it/s]Loading train:  71%|███████▏  | 326/456 [05:31<02:03,  1.05it/s]Loading train:  72%|███████▏  | 327/456 [05:32<02:00,  1.07it/s]Loading train:  72%|███████▏  | 328/456 [05:33<01:55,  1.11it/s]Loading train:  72%|███████▏  | 329/456 [05:34<01:55,  1.10it/s]Loading train:  72%|███████▏  | 330/456 [05:35<01:54,  1.10it/s]Loading train:  73%|███████▎  | 331/456 [05:36<01:57,  1.06it/s]Loading train:  73%|███████▎  | 332/456 [05:37<01:59,  1.04it/s]Loading train:  73%|███████▎  | 333/456 [05:38<02:07,  1.04s/it]Loading train:  73%|███████▎  | 334/456 [05:39<02:03,  1.01s/it]Loading train:  73%|███████▎  | 335/456 [05:40<01:58,  1.02it/s]Loading train:  74%|███████▎  | 336/456 [05:40<01:53,  1.06it/s]Loading train:  74%|███████▍  | 337/456 [05:41<01:51,  1.07it/s]Loading train:  74%|███████▍  | 338/456 [05:42<01:49,  1.07it/s]Loading train:  74%|███████▍  | 339/456 [05:43<01:51,  1.05it/s]Loading train:  75%|███████▍  | 340/456 [05:44<01:48,  1.07it/s]Loading train:  75%|███████▍  | 341/456 [05:45<01:46,  1.08it/s]Loading train:  75%|███████▌  | 342/456 [05:46<01:50,  1.03it/s]Loading train:  75%|███████▌  | 343/456 [05:47<01:55,  1.02s/it]Loading train:  75%|███████▌  | 344/456 [05:48<01:56,  1.04s/it]Loading train:  76%|███████▌  | 345/456 [05:49<01:55,  1.04s/it]Loading train:  76%|███████▌  | 346/456 [05:50<01:52,  1.02s/it]Loading train:  76%|███████▌  | 347/456 [05:51<01:51,  1.03s/it]Loading train:  76%|███████▋  | 348/456 [05:52<01:50,  1.02s/it]Loading train:  77%|███████▋  | 349/456 [05:54<01:50,  1.03s/it]Loading train:  77%|███████▋  | 350/456 [05:55<01:47,  1.01s/it]Loading train:  77%|███████▋  | 351/456 [05:56<01:48,  1.03s/it]Loading train:  77%|███████▋  | 352/456 [05:57<01:44,  1.01s/it]Loading train:  77%|███████▋  | 353/456 [05:58<01:42,  1.01it/s]Loading train:  78%|███████▊  | 354/456 [05:58<01:40,  1.01it/s]Loading train:  78%|███████▊  | 355/456 [05:59<01:37,  1.04it/s]Loading train:  78%|███████▊  | 356/456 [06:00<01:37,  1.03it/s]Loading train:  78%|███████▊  | 357/456 [06:01<01:35,  1.03it/s]Loading train:  79%|███████▊  | 358/456 [06:02<01:31,  1.07it/s]Loading train:  79%|███████▊  | 359/456 [06:03<01:29,  1.09it/s]Loading train:  79%|███████▉  | 360/456 [06:04<01:36,  1.00s/it]Loading train:  79%|███████▉  | 361/456 [06:05<01:35,  1.00s/it]Loading train:  79%|███████▉  | 362/456 [06:06<01:37,  1.03s/it]Loading train:  80%|███████▉  | 363/456 [06:07<01:35,  1.03s/it]Loading train:  80%|███████▉  | 364/456 [06:08<01:33,  1.01s/it]Loading train:  80%|████████  | 365/456 [06:09<01:31,  1.01s/it]Loading train:  80%|████████  | 366/456 [06:10<01:33,  1.04s/it]Loading train:  80%|████████  | 367/456 [06:11<01:27,  1.01it/s]Loading train:  81%|████████  | 368/456 [06:12<01:24,  1.05it/s]Loading train:  81%|████████  | 369/456 [06:13<01:20,  1.08it/s]Loading train:  81%|████████  | 370/456 [06:14<01:20,  1.07it/s]Loading train:  81%|████████▏ | 371/456 [06:15<01:17,  1.10it/s]Loading train:  82%|████████▏ | 372/456 [06:16<01:15,  1.11it/s]Loading train:  82%|████████▏ | 373/456 [06:17<01:22,  1.01it/s]Loading train:  82%|████████▏ | 374/456 [06:18<01:27,  1.06s/it]Loading train:  82%|████████▏ | 375/456 [06:19<01:28,  1.09s/it]Loading train:  82%|████████▏ | 376/456 [06:20<01:27,  1.09s/it]Loading train:  83%|████████▎ | 377/456 [06:22<01:28,  1.13s/it]Loading train:  83%|████████▎ | 378/456 [06:23<01:30,  1.15s/it]Loading train:  83%|████████▎ | 379/456 [06:24<01:22,  1.07s/it]Loading train:  83%|████████▎ | 380/456 [06:25<01:17,  1.02s/it]Loading train:  84%|████████▎ | 381/456 [06:26<01:14,  1.01it/s]Loading train:  84%|████████▍ | 382/456 [06:26<01:11,  1.04it/s]Loading train:  84%|████████▍ | 383/456 [06:27<01:07,  1.08it/s]Loading train:  84%|████████▍ | 384/456 [06:28<01:05,  1.09it/s]Loading train:  84%|████████▍ | 385/456 [06:29<01:05,  1.08it/s]Loading train:  85%|████████▍ | 386/456 [06:30<01:06,  1.06it/s]Loading train:  85%|████████▍ | 387/456 [06:31<01:07,  1.02it/s]Loading train:  85%|████████▌ | 388/456 [06:32<01:09,  1.02s/it]Loading train:  85%|████████▌ | 389/456 [06:33<01:08,  1.03s/it]Loading train:  86%|████████▌ | 390/456 [06:34<01:08,  1.03s/it]Loading train:  86%|████████▌ | 391/456 [06:36<01:09,  1.07s/it]Loading train:  86%|████████▌ | 392/456 [06:37<01:06,  1.03s/it]Loading train:  86%|████████▌ | 393/456 [06:37<01:02,  1.01it/s]Loading train:  86%|████████▋ | 394/456 [06:38<01:00,  1.02it/s]Loading train:  87%|████████▋ | 395/456 [06:39<01:00,  1.01it/s]Loading train:  87%|████████▋ | 396/456 [06:40<00:59,  1.01it/s]Loading train:  87%|████████▋ | 397/456 [06:41<00:58,  1.01it/s]Loading train:  87%|████████▋ | 398/456 [06:42<00:56,  1.02it/s]Loading train:  88%|████████▊ | 399/456 [06:43<00:56,  1.02it/s]Loading train:  88%|████████▊ | 400/456 [06:44<00:55,  1.01it/s]Loading train:  88%|████████▊ | 401/456 [06:45<00:54,  1.01it/s]Loading train:  88%|████████▊ | 402/456 [06:46<00:52,  1.04it/s]Loading train:  88%|████████▊ | 403/456 [06:47<00:45,  1.16it/s]Loading train:  89%|████████▊ | 404/456 [06:47<00:41,  1.26it/s]Loading train:  89%|████████▉ | 405/456 [06:48<00:39,  1.31it/s]Loading train:  89%|████████▉ | 406/456 [06:49<00:35,  1.41it/s]Loading train:  89%|████████▉ | 407/456 [06:49<00:34,  1.43it/s]Loading train:  89%|████████▉ | 408/456 [06:50<00:32,  1.49it/s]Loading train:  90%|████████▉ | 409/456 [06:51<00:30,  1.52it/s]Loading train:  90%|████████▉ | 410/456 [06:51<00:29,  1.58it/s]Loading train:  90%|█████████ | 411/456 [06:52<00:27,  1.65it/s]Loading train:  90%|█████████ | 412/456 [06:52<00:26,  1.64it/s]Loading train:  91%|█████████ | 413/456 [06:53<00:26,  1.64it/s]Loading train:  91%|█████████ | 414/456 [06:54<00:26,  1.58it/s]Loading train:  91%|█████████ | 415/456 [06:54<00:26,  1.55it/s]Loading train:  91%|█████████ | 416/456 [06:55<00:24,  1.61it/s]Loading train:  91%|█████████▏| 417/456 [06:56<00:24,  1.61it/s]Loading train:  92%|█████████▏| 418/456 [06:56<00:23,  1.62it/s]Loading train:  92%|█████████▏| 419/456 [06:57<00:22,  1.65it/s]Loading train:  92%|█████████▏| 420/456 [06:57<00:22,  1.57it/s]Loading train:  92%|█████████▏| 421/456 [06:59<00:27,  1.25it/s]Loading train:  93%|█████████▎| 422/456 [07:00<00:29,  1.14it/s]Loading train:  93%|█████████▎| 423/456 [07:01<00:30,  1.08it/s]Loading train:  93%|█████████▎| 424/456 [07:02<00:32,  1.01s/it]Loading train:  93%|█████████▎| 425/456 [07:03<00:32,  1.04s/it]Loading train:  93%|█████████▎| 426/456 [07:04<00:31,  1.06s/it]Loading train:  94%|█████████▎| 427/456 [07:05<00:32,  1.12s/it]Loading train:  94%|█████████▍| 428/456 [07:07<00:34,  1.23s/it]Loading train:  94%|█████████▍| 429/456 [07:08<00:34,  1.26s/it]Loading train:  94%|█████████▍| 430/456 [07:09<00:31,  1.22s/it]Loading train:  95%|█████████▍| 431/456 [07:11<00:30,  1.22s/it]Loading train:  95%|█████████▍| 432/456 [07:12<00:29,  1.25s/it]Loading train:  95%|█████████▍| 433/456 [07:13<00:27,  1.19s/it]Loading train:  95%|█████████▌| 434/456 [07:14<00:25,  1.16s/it]Loading train:  95%|█████████▌| 435/456 [07:15<00:25,  1.20s/it]Loading train:  96%|█████████▌| 436/456 [07:16<00:23,  1.15s/it]Loading train:  96%|█████████▌| 437/456 [07:17<00:21,  1.13s/it]Loading train:  96%|█████████▌| 438/456 [07:19<00:20,  1.13s/it]Loading train:  96%|█████████▋| 439/456 [07:20<00:20,  1.18s/it]Loading train:  96%|█████████▋| 440/456 [07:21<00:17,  1.11s/it]Loading train:  97%|█████████▋| 441/456 [07:22<00:16,  1.08s/it]Loading train:  97%|█████████▋| 442/456 [07:23<00:14,  1.05s/it]Loading train:  97%|█████████▋| 443/456 [07:24<00:13,  1.05s/it]Loading train:  97%|█████████▋| 444/456 [07:25<00:12,  1.03s/it]Loading train:  98%|█████████▊| 445/456 [07:26<00:11,  1.02s/it]Loading train:  98%|█████████▊| 446/456 [07:27<00:09,  1.06it/s]Loading train:  98%|█████████▊| 447/456 [07:28<00:08,  1.07it/s]Loading train:  98%|█████████▊| 448/456 [07:29<00:07,  1.03it/s]Loading train:  98%|█████████▊| 449/456 [07:29<00:06,  1.06it/s]Loading train:  99%|█████████▊| 450/456 [07:30<00:05,  1.07it/s]Loading train:  99%|█████████▉| 451/456 [07:31<00:04,  1.08it/s]Loading train:  99%|█████████▉| 452/456 [07:32<00:03,  1.07it/s]Loading train:  99%|█████████▉| 453/456 [07:33<00:02,  1.07it/s]Loading train: 100%|█████████▉| 454/456 [07:34<00:01,  1.07it/s]Loading train: 100%|█████████▉| 455/456 [07:35<00:00,  1.08it/s]Loading train: 100%|██████████| 456/456 [07:36<00:00,  1.11it/s]
concatenating: train:   0%|          | 0/456 [00:00<?, ?it/s]concatenating: train:   6%|▌         | 26/456 [00:00<00:01, 251.33it/s]concatenating: train:  11%|█▏        | 52/456 [00:00<00:01, 253.21it/s]concatenating: train:  17%|█▋        | 79/456 [00:00<00:01, 256.71it/s]concatenating: train:  25%|██▍       | 113/456 [00:00<00:01, 277.02it/s]concatenating: train:  31%|███       | 141/456 [00:00<00:01, 276.09it/s]concatenating: train:  37%|███▋      | 170/456 [00:00<00:01, 280.08it/s]concatenating: train:  44%|████▍     | 200/456 [00:00<00:00, 284.34it/s]concatenating: train:  50%|█████     | 228/456 [00:00<00:00, 280.23it/s]concatenating: train:  56%|█████▌    | 255/456 [00:00<00:00, 260.41it/s]concatenating: train:  62%|██████▏   | 281/456 [00:01<00:00, 259.79it/s]concatenating: train:  69%|██████▊   | 313/456 [00:01<00:00, 273.65it/s]concatenating: train:  75%|███████▍  | 341/456 [00:01<00:00, 271.13it/s]concatenating: train:  81%|████████  | 369/456 [00:01<00:00, 267.68it/s]concatenating: train:  87%|████████▋ | 396/456 [00:01<00:00, 266.64it/s]concatenating: train:  94%|█████████▍| 430/456 [00:01<00:00, 283.64it/s]concatenating: train: 100%|██████████| 456/456 [00:01<00:00, 280.50it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:01<00:03,  1.05s/it]Loading test:  50%|█████     | 2/4 [00:01<00:01,  1.00it/s]Loading test:  75%|███████▌  | 3/4 [00:02<00:00,  1.05it/s]Loading test: 100%|██████████| 4/4 [00:03<00:00,  1.00it/s]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 59.40it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 56, 56, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 56, 56, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 56, 56, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 56, 56, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 56, 56, 10)   910         activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 56, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 56, 56, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 56, 56, 11)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 11)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28, 28, 11)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 28, 20)   2000        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 28, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 28, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 28, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 28, 28, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 28, 28, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 28, 31)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 31)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 14, 14, 31)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 14, 14, 40)   11200       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 14, 14, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 14, 14, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 14, 14, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 14, 14, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 14, 14, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 14, 14, 71)   0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 14, 14, 71)   0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 28, 28, 20)   5700        dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 28, 28, 51)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 28, 28, 20)   9200        concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 28, 28, 20)   80          conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 28, 28, 20)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 28, 28, 20)   3620        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 28, 28, 20)   80          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 28, 28, 20)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 28, 28, 71)   0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-07 15:06:12.931846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 15:06:12.931989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 15:06:12.932006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 15:06:12.932016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 15:06:13.017121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 28, 28, 71)   0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 56, 56, 10)   2850        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 56, 21)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 56, 56, 10)   1900        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 56, 56, 10)   40          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 56, 10)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 56, 56, 10)   910         activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 56, 56, 10)   40          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 56, 10)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 56, 31)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 56, 56, 31)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 56, 56, 13)   416         dropout_5[0][0]                  
==================================================================================================
Total params: 57,666
Trainable params: 57,266
Non-trainable params: 400
__________________________________________________________________________________________________
----- /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/model_weights.h5
 --- initialized from Model_3T /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1
------------------------------------------------------------------
class_weights [6.20353721e-02 2.84453234e-02 7.46802407e-02 1.01751126e-02
 2.50007361e-02 6.29472736e-03 7.25125636e-02 1.12798228e-01
 6.41401498e-02 1.31242354e-02 3.56291442e-01 1.74306703e-01
 1.95165508e-04]
Train on 27379 samples, validate on 259 samples
Epoch 1/300
 - 22s - loss: 1.3991 - acc: 0.9493 - mDice: 0.5681 - val_loss: 1.0279 - val_acc: 0.9710 - val_mDice: 0.6327

Epoch 00001: val_mDice improved from -inf to 0.63270, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 15s - loss: 1.2908 - acc: 0.9511 - mDice: 0.5869 - val_loss: 1.0320 - val_acc: 0.9711 - val_mDice: 0.6472

Epoch 00002: val_mDice improved from 0.63270 to 0.64718, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 14s - loss: 1.2558 - acc: 0.9519 - mDice: 0.5951 - val_loss: 1.0384 - val_acc: 0.9711 - val_mDice: 0.6470

Epoch 00003: val_mDice did not improve from 0.64718
Epoch 4/300
 - 14s - loss: 1.2339 - acc: 0.9523 - mDice: 0.6010 - val_loss: 1.0699 - val_acc: 0.9711 - val_mDice: 0.6435

Epoch 00004: val_mDice did not improve from 0.64718
Epoch 5/300
 - 15s - loss: 1.2150 - acc: 0.9527 - mDice: 0.6056 - val_loss: 1.0594 - val_acc: 0.9712 - val_mDice: 0.6454

Epoch 00005: val_mDice did not improve from 0.64718
Epoch 6/300
 - 14s - loss: 1.2000 - acc: 0.9531 - mDice: 0.6101 - val_loss: 1.0689 - val_acc: 0.9711 - val_mDice: 0.6452

Epoch 00006: val_mDice did not improve from 0.64718
Epoch 7/300
 - 15s - loss: 1.1887 - acc: 0.9532 - mDice: 0.6137 - val_loss: 1.0807 - val_acc: 0.9707 - val_mDice: 0.6434

Epoch 00007: val_mDice did not improve from 0.64718
Epoch 8/300
 - 15s - loss: 1.1775 - acc: 0.9536 - mDice: 0.6171 - val_loss: 1.0926 - val_acc: 0.9707 - val_mDice: 0.6481

Epoch 00008: val_mDice improved from 0.64718 to 0.64815, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 9/300
 - 14s - loss: 1.1691 - acc: 0.9537 - mDice: 0.6192 - val_loss: 1.0771 - val_acc: 0.9711 - val_mDice: 0.6524

Epoch 00009: val_mDice improved from 0.64815 to 0.65238, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 10/300
 - 14s - loss: 1.1607 - acc: 0.9540 - mDice: 0.6215 - val_loss: 1.0879 - val_acc: 0.9709 - val_mDice: 0.6518

Epoch 00010: val_mDice did not improve from 0.65238
Epoch 11/300
 - 15s - loss: 1.1548 - acc: 0.9541 - mDice: 0.6238 - val_loss: 1.0950 - val_acc: 0.9712 - val_mDice: 0.6526

Epoch 00011: val_mDice improved from 0.65238 to 0.65256, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 12/300
 - 15s - loss: 1.1499 - acc: 0.9542 - mDice: 0.6254 - val_loss: 1.0907 - val_acc: 0.9710 - val_mDice: 0.6572

Epoch 00012: val_mDice improved from 0.65256 to 0.65724, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 13/300
 - 14s - loss: 1.1427 - acc: 0.9543 - mDice: 0.6276 - val_loss: 1.0662 - val_acc: 0.9714 - val_mDice: 0.6505

Epoch 00013: val_mDice did not improve from 0.65724
Epoch 14/300
 - 15s - loss: 1.1390 - acc: 0.9544 - mDice: 0.6282 - val_loss: 1.0907 - val_acc: 0.9714 - val_mDice: 0.6518

Epoch 00014: val_mDice did not improve from 0.65724
Epoch 15/300
 - 14s - loss: 1.1327 - acc: 0.9546 - mDice: 0.6302 - val_loss: 1.1114 - val_acc: 0.9707 - val_mDice: 0.6509

Epoch 00015: val_mDice did not improve from 0.65724
Epoch 16/300
 - 14s - loss: 1.1273 - acc: 0.9547 - mDice: 0.6316 - val_loss: 1.0729 - val_acc: 0.9714 - val_mDice: 0.6569

Epoch 00016: val_mDice did not improve from 0.65724
Epoch 17/300
 - 15s - loss: 1.1253 - acc: 0.9547 - mDice: 0.6328 - val_loss: 1.1208 - val_acc: 0.9713 - val_mDice: 0.6569

Epoch 00017: val_mDice did not improve from 0.65724
Epoch 18/300
 - 14s - loss: 1.1178 - acc: 0.9548 - mDice: 0.6345 - val_loss: 1.1345 - val_acc: 0.9704 - val_mDice: 0.6585

Epoch 00018: val_mDice improved from 0.65724 to 0.65850, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 19/300
 - 15s - loss: 1.1140 - acc: 0.9549 - mDice: 0.6364 - val_loss: 1.0913 - val_acc: 0.9705 - val_mDice: 0.6582

Epoch 00019: val_mDice did not improve from 0.65850
Epoch 20/300
 - 15s - loss: 1.1143 - acc: 0.9549 - mDice: 0.6361 - val_loss: 1.0980 - val_acc: 0.9707 - val_mDice: 0.6552

Epoch 00020: val_mDice did not improve from 0.65850
Epoch 21/300
 - 14s - loss: 1.1068 - acc: 0.9550 - mDice: 0.6384 - val_loss: 1.1079 - val_acc: 0.9709 - val_mDice: 0.6584

Epoch 00021: val_mDice did not improve from 0.65850
Epoch 22/300
 - 14s - loss: 1.1075 - acc: 0.9550 - mDice: 0.6383 - val_loss: 1.1108 - val_acc: 0.9709 - val_mDice: 0.6562

Epoch 00022: val_mDice did not improve from 0.65850
Epoch 23/300
 - 15s - loss: 1.1004 - acc: 0.9550 - mDice: 0.6398 - val_loss: 1.1246 - val_acc: 0.9706 - val_mDice: 0.6564

Epoch 00023: val_mDice did not improve from 0.65850
Epoch 24/300
 - 15s - loss: 1.0986 - acc: 0.9551 - mDice: 0.6410 - val_loss: 1.1679 - val_acc: 0.9704 - val_mDice: 0.6557

Epoch 00024: val_mDice did not improve from 0.65850
Epoch 25/300
 - 14s - loss: 1.0971 - acc: 0.9551 - mDice: 0.6416 - val_loss: 1.1342 - val_acc: 0.9709 - val_mDice: 0.6588

Epoch 00025: val_mDice improved from 0.65850 to 0.65880, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 26/300
 - 15s - loss: 1.0942 - acc: 0.9552 - mDice: 0.6421 - val_loss: 1.1242 - val_acc: 0.9710 - val_mDice: 0.6597

Epoch 00026: val_mDice improved from 0.65880 to 0.65966, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 27/300
 - 14s - loss: 1.0931 - acc: 0.9552 - mDice: 0.6426 - val_loss: 1.1236 - val_acc: 0.9710 - val_mDice: 0.6619

Epoch 00027: val_mDice improved from 0.65966 to 0.66193, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 28/300
 - 14s - loss: 1.0885 - acc: 0.9552 - mDice: 0.6438 - val_loss: 1.1339 - val_acc: 0.9709 - val_mDice: 0.6598

Epoch 00028: val_mDice did not improve from 0.66193
Epoch 29/300
 - 15s - loss: 1.0870 - acc: 0.9553 - mDice: 0.6437 - val_loss: 1.1223 - val_acc: 0.9711 - val_mDice: 0.6589

Epoch 00029: val_mDice did not improve from 0.66193
Epoch 30/300
 - 15s - loss: 1.0879 - acc: 0.9553 - mDice: 0.6443 - val_loss: 1.1144 - val_acc: 0.9707 - val_mDice: 0.6570

Epoch 00030: val_mDice did not improve from 0.66193
Epoch 31/300
 - 14s - loss: 1.0838 - acc: 0.9554 - mDice: 0.6453 - val_loss: 1.1082 - val_acc: 0.9709 - val_mDice: 0.6596

Epoch 00031: val_mDice did not improve from 0.66193
Epoch 32/300
 - 15s - loss: 1.0799 - acc: 0.9554 - mDice: 0.6463 - val_loss: 1.1172 - val_acc: 0.9709 - val_mDice: 0.6648

Epoch 00032: val_mDice improved from 0.66193 to 0.66476, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 33/300
 - 14s - loss: 1.0776 - acc: 0.9555 - mDice: 0.6473 - val_loss: 1.1201 - val_acc: 0.9710 - val_mDice: 0.6654

Epoch 00033: val_mDice improved from 0.66476 to 0.66538, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 34/300
 - 14s - loss: 1.0793 - acc: 0.9554 - mDice: 0.6470 - val_loss: 1.1150 - val_acc: 0.9714 - val_mDice: 0.6626

Epoch 00034: val_mDice did not improve from 0.66538
Epoch 35/300
 - 15s - loss: 1.0728 - acc: 0.9556 - mDice: 0.6486 - val_loss: 1.1162 - val_acc: 0.9711 - val_mDice: 0.6603

Epoch 00035: val_mDice did not improve from 0.66538
Epoch 36/300
 - 15s - loss: 1.0740 - acc: 0.9556 - mDice: 0.6487 - val_loss: 1.1358 - val_acc: 0.9710 - val_mDice: 0.6601

Epoch 00036: val_mDice did not improve from 0.66538
Epoch 37/300
 - 14s - loss: 1.0696 - acc: 0.9556 - mDice: 0.6500 - val_loss: 1.1333 - val_acc: 0.9702 - val_mDice: 0.6570

Epoch 00037: val_mDice did not improve from 0.66538
Epoch 38/300
 - 14s - loss: 1.0686 - acc: 0.9556 - mDice: 0.6500 - val_loss: 1.1397 - val_acc: 0.9711 - val_mDice: 0.6647

Epoch 00038: val_mDice did not improve from 0.66538
Epoch 39/300
 - 15s - loss: 1.0667 - acc: 0.9557 - mDice: 0.6510 - val_loss: 1.1362 - val_acc: 0.9708 - val_mDice: 0.6646

Epoch 00039: val_mDice did not improve from 0.66538
Epoch 40/300
 - 14s - loss: 1.0652 - acc: 0.9558 - mDice: 0.6513 - val_loss: 1.1636 - val_acc: 0.9703 - val_mDice: 0.6635

Epoch 00040: val_mDice did not improve from 0.66538
Epoch 41/300
 - 14s - loss: 1.0664 - acc: 0.9557 - mDice: 0.6511 - val_loss: 1.1380 - val_acc: 0.9705 - val_mDice: 0.6632

Epoch 00041: val_mDice did not improve from 0.66538
Epoch 42/300
 - 14s - loss: 1.0648 - acc: 0.9558 - mDice: 0.6513 - val_loss: 1.1341 - val_acc: 0.9709 - val_mDice: 0.6608

Epoch 00042: val_mDice did not improve from 0.66538
Epoch 43/300
 - 15s - loss: 1.0609 - acc: 0.9558 - mDice: 0.6527 - val_loss: 1.1200 - val_acc: 0.9706 - val_mDice: 0.6606

Epoch 00043: val_mDice did not improve from 0.66538
Epoch 44/300
 - 15s - loss: 1.0609 - acc: 0.9559 - mDice: 0.6528 - val_loss: 1.1317 - val_acc: 0.9704 - val_mDice: 0.6655

Epoch 00044: val_mDice improved from 0.66538 to 0.66550, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 45/300
 - 14s - loss: 1.0576 - acc: 0.9559 - mDice: 0.6537 - val_loss: 1.1344 - val_acc: 0.9706 - val_mDice: 0.6678

Epoch 00045: val_mDice improved from 0.66550 to 0.66781, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 46/300
 - 14s - loss: 1.0560 - acc: 0.9560 - mDice: 0.6541 - val_loss: 1.1545 - val_acc: 0.9704 - val_mDice: 0.6644

Epoch 00046: val_mDice did not improve from 0.66781
Epoch 47/300
 - 15s - loss: 1.0563 - acc: 0.9560 - mDice: 0.6544 - val_loss: 1.1612 - val_acc: 0.9709 - val_mDice: 0.6634

Epoch 00047: val_mDice did not improve from 0.66781
Epoch 48/300
 - 15s - loss: 1.0565 - acc: 0.9559 - mDice: 0.6542 - val_loss: 1.1506 - val_acc: 0.9710 - val_mDice: 0.6664

Epoch 00048: val_mDice did not improve from 0.66781
Epoch 49/300
 - 15s - loss: 1.0530 - acc: 0.9560 - mDice: 0.6550 - val_loss: 1.1358 - val_acc: 0.9709 - val_mDice: 0.6689

Epoch 00049: val_mDice improved from 0.66781 to 0.66895, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 50/300
 - 15s - loss: 1.0519 - acc: 0.9560 - mDice: 0.6557 - val_loss: 1.1477 - val_acc: 0.9710 - val_mDice: 0.6634

Epoch 00050: val_mDice did not improve from 0.66895
Epoch 51/300
 - 14s - loss: 1.0542 - acc: 0.9560 - mDice: 0.6548 - val_loss: 1.1574 - val_acc: 0.9709 - val_mDice: 0.6649

Epoch 00051: val_mDice did not improve from 0.66895
Epoch 52/300
 - 15s - loss: 1.0516 - acc: 0.9561 - mDice: 0.6559 - val_loss: 1.1547 - val_acc: 0.9705 - val_mDice: 0.6647

Epoch 00052: val_mDice did not improve from 0.66895
Epoch 53/300
 - 15s - loss: 1.0487 - acc: 0.9561 - mDice: 0.6565 - val_loss: 1.1591 - val_acc: 0.9710 - val_mDice: 0.6642

Epoch 00053: val_mDice did not improve from 0.66895
Epoch 54/300
 - 14s - loss: 1.0463 - acc: 0.9562 - mDice: 0.6568 - val_loss: 1.1473 - val_acc: 0.9703 - val_mDice: 0.6659

Epoch 00054: val_mDice did not improve from 0.66895
Epoch 55/300
 - 15s - loss: 1.0452 - acc: 0.9562 - mDice: 0.6573 - val_loss: 1.1982 - val_acc: 0.9706 - val_mDice: 0.6665

Epoch 00055: val_mDice did not improve from 0.66895
Epoch 56/300
 - 14s - loss: 1.0462 - acc: 0.9562 - mDice: 0.6573 - val_loss: 1.1798 - val_acc: 0.9708 - val_mDice: 0.6632

Epoch 00056: val_mDice did not improve from 0.66895
Epoch 57/300
 - 14s - loss: 1.0463 - acc: 0.9562 - mDice: 0.6571 - val_loss: 1.1860 - val_acc: 0.9705 - val_mDice: 0.6638

Epoch 00057: val_mDice did not improve from 0.66895
Epoch 58/300
 - 15s - loss: 1.0423 - acc: 0.9562 - mDice: 0.6584 - val_loss: 1.1588 - val_acc: 0.9705 - val_mDice: 0.6624

Epoch 00058: val_mDice did not improve from 0.66895
Epoch 59/300
 - 15s - loss: 1.0447 - acc: 0.9562 - mDice: 0.6577 - val_loss: 1.1458 - val_acc: 0.9708 - val_mDice: 0.6688

Epoch 00059: val_mDice did not improve from 0.66895
Epoch 60/300
 - 14s - loss: 1.0420 - acc: 0.9563 - mDice: 0.6590 - val_loss: 1.1626 - val_acc: 0.9705 - val_mDice: 0.6649

Epoch 00060: val_mDice did not improve from 0.66895
Epoch 61/300
 - 14s - loss: 1.0421 - acc: 0.9563 - mDice: 0.6585 - val_loss: 1.1784 - val_acc: 0.9703 - val_mDice: 0.6634

Epoch 00061: val_mDice did not improve from 0.66895
Epoch 62/300
 - 15s - loss: 1.0421 - acc: 0.9563 - mDice: 0.6586 - val_loss: 1.1617 - val_acc: 0.9705 - val_mDice: 0.6676

Epoch 00062: val_mDice did not improve from 0.66895
Epoch 63/300
 - 15s - loss: 1.0407 - acc: 0.9564 - mDice: 0.6589 - val_loss: 1.1721 - val_acc: 0.9700 - val_mDice: 0.6687

Epoch 00063: val_mDice did not improve from 0.66895
Epoch 64/300
 - 14s - loss: 1.0388 - acc: 0.9564 - mDice: 0.6599 - val_loss: 1.1823 - val_acc: 0.9705 - val_mDice: 0.6668

Epoch 00064: val_mDice did not improve from 0.66895
Epoch 65/300
 - 14s - loss: 1.0356 - acc: 0.9565 - mDice: 0.6607 - val_loss: 1.1742 - val_acc: 0.9704 - val_mDice: 0.6630

Epoch 00065: val_mDice did not improve from 0.66895
Epoch 66/300
 - 15s - loss: 1.0378 - acc: 0.9564 - mDice: 0.6598 - val_loss: 1.1824 - val_acc: 0.9705 - val_mDice: 0.6658

Epoch 00066: val_mDice did not improve from 0.66895
Epoch 67/300
 - 15s - loss: 1.0385 - acc: 0.9564 - mDice: 0.6599 - val_loss: 1.2059 - val_acc: 0.9704 - val_mDice: 0.6622

Epoch 00067: val_mDice did not improve from 0.66895
Epoch 68/300
 - 14s - loss: 1.0362 - acc: 0.9564 - mDice: 0.6606 - val_loss: 1.1477 - val_acc: 0.9707 - val_mDice: 0.6665

Epoch 00068: val_mDice did not improve from 0.66895
Epoch 69/300
 - 15s - loss: 1.0352 - acc: 0.9564 - mDice: 0.6606 - val_loss: 1.1741 - val_acc: 0.9707 - val_mDice: 0.6673

Epoch 00069: val_mDice did not improve from 0.66895
Epoch 70/300
 - 15s - loss: 1.0359 - acc: 0.9564 - mDice: 0.6608 - val_loss: 1.2095 - val_acc: 0.9706 - val_mDice: 0.6618

Epoch 00070: val_mDice did not improve from 0.66895
Epoch 71/300
 - 15s - loss: 1.0326 - acc: 0.9565 - mDice: 0.6613 - val_loss: 1.2051 - val_acc: 0.9707 - val_mDice: 0.6641

Epoch 00071: val_mDice did not improve from 0.66895
Epoch 72/300
 - 15s - loss: 1.0326 - acc: 0.9565 - mDice: 0.6615 - val_loss: 1.1799 - val_acc: 0.9708 - val_mDice: 0.6647

Epoch 00072: val_mDice did not improve from 0.66895
Epoch 73/300
 - 15s - loss: 1.0333 - acc: 0.9565 - mDice: 0.6613 - val_loss: 1.1840 - val_acc: 0.9707 - val_mDice: 0.6653

Epoch 00073: val_mDice did not improve from 0.66895
Epoch 74/300
 - 14s - loss: 1.0308 - acc: 0.9565 - mDice: 0.6622 - val_loss: 1.2181 - val_acc: 0.9702 - val_mDice: 0.6666

Epoch 00074: val_mDice did not improve from 0.66895
Epoch 75/300
 - 14s - loss: 1.0321 - acc: 0.9565 - mDice: 0.6622 - val_loss: 1.1558 - val_acc: 0.9705 - val_mDice: 0.6622

Epoch 00075: val_mDice did not improve from 0.66895
Epoch 76/300
 - 15s - loss: 1.0302 - acc: 0.9566 - mDice: 0.6627 - val_loss: 1.2360 - val_acc: 0.9702 - val_mDice: 0.6637

Epoch 00076: val_mDice did not improve from 0.66895
Epoch 77/300
 - 15s - loss: 1.0281 - acc: 0.9566 - mDice: 0.6628 - val_loss: 1.2203 - val_acc: 0.9700 - val_mDice: 0.6624

Epoch 00077: val_mDice did not improve from 0.66895
Epoch 78/300
 - 14s - loss: 1.0276 - acc: 0.9566 - mDice: 0.6628 - val_loss: 1.2011 - val_acc: 0.9704 - val_mDice: 0.6655

Epoch 00078: val_mDice did not improve from 0.66895
Epoch 79/300
 - 15s - loss: 1.0245 - acc: 0.9567 - mDice: 0.6640 - val_loss: 1.2245 - val_acc: 0.9703 - val_mDice: 0.6658

Epoch 00079: val_mDice did not improve from 0.66895
Restoring model weights from the end of the best epoch
Epoch 00079: early stopping
{'val_loss': [1.0278836769486948, 1.0319769207575147, 1.0384110398734399, 1.0698764216025363, 1.0594086092411321, 1.0688868162714837, 1.0807001300760217, 1.0925687841466956, 1.077141199102733, 1.0878759822790227, 1.094984453387242, 1.0906511137844512, 1.0661981895163253, 1.0906533601201178, 1.1113871777840103, 1.0729408503499271, 1.1207813528513817, 1.1345243578251725, 1.0913383571797817, 1.098030697194766, 1.1079499965468889, 1.1108395781756368, 1.1246162300864702, 1.1678674469583283, 1.1342182665718108, 1.124210185986228, 1.1236274200977046, 1.133944408543782, 1.1223234163748252, 1.114363822237405, 1.108163764578035, 1.117213909230177, 1.1201095201333977, 1.114989495415485, 1.1162122639910135, 1.1357913930903991, 1.133307612540639, 1.1397017958541635, 1.1361835378017204, 1.163570696552748, 1.1379957541995986, 1.134074806476652, 1.1200013892530936, 1.131716604858752, 1.1343900526812638, 1.1545213661138616, 1.1611521156598241, 1.1505573884400622, 1.1358307830155125, 1.1476779034699252, 1.1574306603103992, 1.1547039958961223, 1.1590624364186437, 1.1473072237950035, 1.198205229858634, 1.1797796694928615, 1.1860399400405441, 1.158844853690232, 1.145839768487054, 1.16264432001298, 1.1784225334071745, 1.1617288320221035, 1.172063986767213, 1.182309296600607, 1.1741770952364652, 1.1824081958951176, 1.2058748356623998, 1.1477176599981243, 1.174106585933435, 1.2094503392584075, 1.2050786579897965, 1.1798880272850567, 1.1839599135299448, 1.2180778409523394, 1.1557532141567657, 1.2359968702305237, 1.220289142435582, 1.2010820703616933, 1.224455966452374], 'val_acc': [0.9710178529433762, 0.9710794061307281, 0.9710609560767656, 0.9710621698022349, 0.9711828282440952, 0.971052332044108, 0.9706842082347649, 0.9707223554375549, 0.9710510789657651, 0.9709107282078865, 0.971224682901817, 0.9709956947440807, 0.9714007421349927, 0.9713699744014667, 0.9707371272635736, 0.9713884237650279, 0.9712702509979484, 0.9704194982539733, 0.9705032110214233, 0.9706767990782454, 0.9708910296782564, 0.9709402847474146, 0.9705856990169834, 0.9703973412053465, 0.9709008734198611, 0.9710326056682925, 0.9709821421667416, 0.9709255023352428, 0.9710880198073664, 0.9706866559374747, 0.9709131947815648, 0.9709390535317793, 0.9709993750432283, 0.9713613453058663, 0.9710757221494403, 0.970964897323299, 0.9701830938055709, 0.9710880301633857, 0.9708294762607707, 0.970270540033068, 0.9704995141526447, 0.9708873459271022, 0.9706435719051877, 0.9704268751917658, 0.9706066271513125, 0.9704465686584531, 0.9708553400739279, 0.9709870677196841, 0.970876272120531, 0.9709944681311206, 0.9709168760012475, 0.9704896589043518, 0.971024015695432, 0.9702914444636194, 0.970578316095713, 0.9708060716570114, 0.9705376818373397, 0.9704515022660775, 0.9708467326109014, 0.970495820275605, 0.9702532735570517, 0.9705093470779625, 0.9700366019282102, 0.9705192310929759, 0.9703997868368525, 0.9705007543434968, 0.9704244037852784, 0.9707162170796781, 0.9707100598508327, 0.9706435682230474, 0.9706866639921564, 0.9708294863866563, 0.9707149759682909, 0.9702101876836946, 0.9704675039269289, 0.9702434247525042, 0.9699713412859265, 0.9703813043340292, 0.9703197640341681], 'val_mDice': [0.6327047601169601, 0.6471848103530619, 0.6469916360718864, 0.6435409116929102, 0.6453835598290196, 0.645175195568777, 0.6433813445356361, 0.6481457870439212, 0.6523815087369971, 0.6518150761320785, 0.6525626396580553, 0.6572379064836097, 0.6505479757389967, 0.6517994332497644, 0.6508779719069198, 0.6569258236977125, 0.6569238328105235, 0.65849614718706, 0.6581653158637087, 0.6551746673105306, 0.6584073201569811, 0.6562215991922327, 0.6563690196593296, 0.6556853792382024, 0.658798335141657, 0.6596622011376164, 0.6619323176766915, 0.6597662809732798, 0.6588790582413839, 0.657009338319992, 0.6595591147894104, 0.6647629399557371, 0.6653824202342383, 0.6625875078112923, 0.6602624820466207, 0.6600870409527341, 0.6570011750151292, 0.664668662437601, 0.6645897760354414, 0.6634948078729932, 0.66320244893144, 0.6607761479712821, 0.6606257544060932, 0.6654995882373058, 0.6678056077147082, 0.6643935752651406, 0.6633822908732881, 0.6663520992032349, 0.6689460489280435, 0.6633902447564262, 0.6649154017330596, 0.6647100968710704, 0.6641767453042697, 0.6659443353133773, 0.6664918069673781, 0.6631593349817637, 0.663796261010483, 0.6624089322955452, 0.6687953601012359, 0.6649089407276463, 0.6634122487661, 0.66763686029147, 0.6687185462837514, 0.666847394700216, 0.6630338280817717, 0.6657899383412365, 0.6622373229288226, 0.6665422274339153, 0.6672899016542324, 0.6617863979118671, 0.6641083016819015, 0.6646740648277017, 0.6652518437175677, 0.6665619160677936, 0.6622456300672878, 0.6636975078509121, 0.6624464944983081, 0.6655068427439362, 0.6657520141380634], 'loss': [1.399077738810458, 1.2908440392135534, 1.255821665614999, 1.23393446259295, 1.2149927315080988, 1.1999963994610323, 1.1887173240691333, 1.1775160369424928, 1.1690748112070808, 1.1607205648606678, 1.1548192337051388, 1.1499407766938945, 1.1426731305955913, 1.139040384396577, 1.1327038007646548, 1.1273383739209775, 1.1252733181686232, 1.1178472340966887, 1.1140012445906655, 1.114328908750045, 1.1068401525635303, 1.1075123154641138, 1.1003931721645135, 1.098635996891046, 1.0970822905008542, 1.094197676375461, 1.0931185506856522, 1.0885168911354532, 1.0870189347204975, 1.0879239945990944, 1.0837966619739967, 1.079887174150159, 1.0776348652151373, 1.0792717593081695, 1.0728299274298807, 1.0740159592063674, 1.0696325364887525, 1.0686449896989283, 1.0666835714894776, 1.0652323340001588, 1.066393237417168, 1.0647943398037178, 1.0609250037446076, 1.0609408970241232, 1.057583874505616, 1.0560126213518155, 1.056258283716335, 1.056502178716818, 1.0529900461358033, 1.0519253110653985, 1.0542171535239757, 1.0515880468638064, 1.0487039738869344, 1.0462863706176122, 1.0452149970823446, 1.0462457356392334, 1.0463035613447542, 1.04229017327477, 1.0446527171284727, 1.0419624393157585, 1.0420814676426557, 1.0421047613376844, 1.0406705288321172, 1.0388230770981997, 1.035592509219939, 1.0377550277752978, 1.038525946936034, 1.036204680092362, 1.0352147247123467, 1.0358989670616343, 1.032616218237346, 1.0325996503209418, 1.0332889556950076, 1.0308221626448932, 1.032130082467191, 1.030205273134922, 1.028072206273203, 1.027590083505113, 1.0244782009728748], 'acc': [0.9492966406113471, 0.9510533157339437, 0.951869533368854, 0.9523140800182542, 0.9527225347544732, 0.9530570175097471, 0.9532481979699422, 0.9535707913282263, 0.9537125121049795, 0.9539658045737389, 0.9540811086215636, 0.9541675043927251, 0.9543384910174076, 0.9544124489587473, 0.9545660450384595, 0.954681289747236, 0.9547267593852946, 0.9547800322965132, 0.954889653822247, 0.9548816265837471, 0.9549795550405554, 0.954989988596437, 0.9550297183370289, 0.9551051402288783, 0.955138404723599, 0.9551773851054272, 0.955202449945977, 0.9552445167072103, 0.9552989310106936, 0.955296218800159, 0.9553644120934857, 0.9554224111682125, 0.9554743344246756, 0.9554324747242178, 0.9555553590442828, 0.9555686012875403, 0.9556078750054672, 0.9555942130413617, 0.9556948877464205, 0.955755523049312, 0.9557092367433693, 0.9557548123587867, 0.9557950869923751, 0.9558697078342856, 0.9559044719608825, 0.9559653618837396, 0.9559783129004313, 0.9559279868259567, 0.9560069173629961, 0.9560452257987332, 0.9560432561546582, 0.9560798261371913, 0.9561379097695721, 0.956189656130056, 0.9561601197416097, 0.9561884796942921, 0.9562390505028823, 0.9562479602097115, 0.956249778398469, 0.9562978435696475, 0.9562717550243853, 0.9563201920676777, 0.9563674773517338, 0.9563757716301016, 0.9564594989444868, 0.956395292032618, 0.9563606657484293, 0.9564277390822583, 0.9564262727631502, 0.9564135771632138, 0.9565181290721514, 0.9565125627615927, 0.9564845628576258, 0.9565373370090897, 0.9565318733123932, 0.9565699354705071, 0.9565896650041454, 0.956591317998409, 0.9566738464058244], 'mDice': [0.5680703578966599, 0.5868912303442063, 0.5951398036683632, 0.601005370463041, 0.6056479126843052, 0.6100582236778467, 0.6136512194240958, 0.617057787270032, 0.6192040537685398, 0.6215002474162572, 0.6237715712953482, 0.6253612963920523, 0.627630636476435, 0.6282429612402615, 0.6301708774355218, 0.6316488003808276, 0.6328196163143355, 0.6345289853079045, 0.6364142119638487, 0.6361361546806223, 0.6384112439082779, 0.6382833483090354, 0.639784446758926, 0.6410178330813764, 0.6415884568212397, 0.6421318730686575, 0.6425625086396713, 0.6437904739393816, 0.6436780195439279, 0.6443410586690775, 0.6453028434906646, 0.6462722406520041, 0.6473466966197386, 0.6470064688466456, 0.6486338079095414, 0.6487450610054798, 0.6500452899128235, 0.6499924697064906, 0.6509887414546518, 0.6513444517709761, 0.6510779406056132, 0.6512689277224389, 0.6527442417111162, 0.6528492933551138, 0.6537358511869674, 0.6540677297946512, 0.6544208868730103, 0.6542446410173983, 0.6550448238076798, 0.6557184738745199, 0.6547601769511174, 0.6558670206359751, 0.6565374882253703, 0.6568205377279596, 0.6572808059400279, 0.6573377227873767, 0.6571398890259241, 0.6583645539886526, 0.6576704867588271, 0.6589611270206606, 0.6584551259839921, 0.6585805221590394, 0.6589184702172021, 0.6599202740117959, 0.6607398015756404, 0.6598026956110423, 0.6598790811806173, 0.6605940179996552, 0.6606497226036067, 0.6607626944289432, 0.6613456097768681, 0.6615093888635244, 0.6613229418990427, 0.6622082099463821, 0.6621576602657759, 0.6626573956675846, 0.6628119394304528, 0.6627730623199469, 0.6639613207116565]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:02<00:08,  2.67s/it]predicting test subjects:  50%|█████     | 2/4 [00:04<00:04,  2.37s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:05<00:02,  2.14s/it]predicting test subjects: 100%|██████████| 4/4 [00:07<00:00,  2.09s/it]
predicting train subjects:   0%|          | 0/456 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/456 [00:01<13:58,  1.84s/it]predicting train subjects:   0%|          | 2/456 [00:03<13:42,  1.81s/it]predicting train subjects:   1%|          | 3/456 [00:05<13:21,  1.77s/it]predicting train subjects:   1%|          | 4/456 [00:06<12:41,  1.68s/it]predicting train subjects:   1%|          | 5/456 [00:09<14:07,  1.88s/it]predicting train subjects:   1%|▏         | 6/456 [00:10<13:39,  1.82s/it]predicting train subjects:   2%|▏         | 7/456 [00:12<12:58,  1.73s/it]predicting train subjects:   2%|▏         | 8/456 [00:13<11:11,  1.50s/it]predicting train subjects:   2%|▏         | 9/456 [00:15<11:46,  1.58s/it]predicting train subjects:   2%|▏         | 10/456 [00:17<12:55,  1.74s/it]predicting train subjects:   2%|▏         | 11/456 [00:19<13:28,  1.82s/it]predicting train subjects:   3%|▎         | 12/456 [00:20<11:42,  1.58s/it]predicting train subjects:   3%|▎         | 13/456 [00:21<12:00,  1.63s/it]predicting train subjects:   3%|▎         | 14/456 [00:23<12:24,  1.68s/it]predicting train subjects:   3%|▎         | 15/456 [00:24<10:51,  1.48s/it]predicting train subjects:   4%|▎         | 16/456 [00:26<11:35,  1.58s/it]predicting train subjects:   4%|▎         | 17/456 [00:28<12:46,  1.75s/it]predicting train subjects:   4%|▍         | 18/456 [00:30<12:40,  1.74s/it]predicting train subjects:   4%|▍         | 19/456 [00:32<12:39,  1.74s/it]predicting train subjects:   4%|▍         | 20/456 [00:33<11:55,  1.64s/it]predicting train subjects:   5%|▍         | 21/456 [00:35<12:20,  1.70s/it]predicting train subjects:   5%|▍         | 22/456 [00:37<12:36,  1.74s/it]predicting train subjects:   5%|▌         | 23/456 [00:39<12:51,  1.78s/it]predicting train subjects:   5%|▌         | 24/456 [00:40<11:06,  1.54s/it]predicting train subjects:   5%|▌         | 25/456 [00:41<11:48,  1.64s/it]predicting train subjects:   6%|▌         | 26/456 [00:43<11:57,  1.67s/it]predicting train subjects:   6%|▌         | 27/456 [00:45<12:07,  1.70s/it]predicting train subjects:   6%|▌         | 28/456 [00:47<12:08,  1.70s/it]predicting train subjects:   6%|▋         | 29/456 [00:48<12:18,  1.73s/it]predicting train subjects:   7%|▋         | 30/456 [00:50<12:23,  1.75s/it]predicting train subjects:   7%|▋         | 31/456 [00:52<12:21,  1.74s/it]predicting train subjects:   7%|▋         | 32/456 [00:54<12:16,  1.74s/it]predicting train subjects:   7%|▋         | 33/456 [00:55<12:12,  1.73s/it]predicting train subjects:   7%|▋         | 34/456 [00:57<12:16,  1.74s/it]predicting train subjects:   8%|▊         | 35/456 [00:59<12:28,  1.78s/it]predicting train subjects:   8%|▊         | 36/456 [01:01<12:20,  1.76s/it]predicting train subjects:   8%|▊         | 37/456 [01:02<12:11,  1.75s/it]predicting train subjects:   8%|▊         | 38/456 [01:04<12:11,  1.75s/it]predicting train subjects:   9%|▊         | 39/456 [01:06<12:05,  1.74s/it]predicting train subjects:   9%|▉         | 40/456 [01:08<12:08,  1.75s/it]predicting train subjects:   9%|▉         | 41/456 [01:09<11:58,  1.73s/it]predicting train subjects:   9%|▉         | 42/456 [01:11<11:48,  1.71s/it]predicting train subjects:   9%|▉         | 43/456 [01:13<12:04,  1.76s/it]predicting train subjects:  10%|▉         | 44/456 [01:15<12:17,  1.79s/it]predicting train subjects:  10%|▉         | 45/456 [01:17<12:29,  1.82s/it]predicting train subjects:  10%|█         | 46/456 [01:18<12:22,  1.81s/it]predicting train subjects:  10%|█         | 47/456 [01:20<12:12,  1.79s/it]predicting train subjects:  11%|█         | 48/456 [01:22<12:04,  1.78s/it]predicting train subjects:  11%|█         | 49/456 [01:24<12:37,  1.86s/it]predicting train subjects:  11%|█         | 50/456 [01:26<12:18,  1.82s/it]predicting train subjects:  11%|█         | 51/456 [01:28<12:11,  1.81s/it]predicting train subjects:  11%|█▏        | 52/456 [01:29<12:10,  1.81s/it]predicting train subjects:  12%|█▏        | 53/456 [01:31<12:05,  1.80s/it]predicting train subjects:  12%|█▏        | 54/456 [01:33<12:03,  1.80s/it]predicting train subjects:  12%|█▏        | 55/456 [01:35<11:56,  1.79s/it]predicting train subjects:  12%|█▏        | 56/456 [01:37<12:00,  1.80s/it]predicting train subjects:  12%|█▎        | 57/456 [01:38<12:11,  1.83s/it]predicting train subjects:  13%|█▎        | 58/456 [01:40<12:07,  1.83s/it]predicting train subjects:  13%|█▎        | 59/456 [01:42<12:10,  1.84s/it]predicting train subjects:  13%|█▎        | 60/456 [01:44<12:08,  1.84s/it]predicting train subjects:  13%|█▎        | 61/456 [01:46<12:08,  1.84s/it]predicting train subjects:  14%|█▎        | 62/456 [01:48<12:07,  1.85s/it]predicting train subjects:  14%|█▍        | 63/456 [01:50<12:21,  1.89s/it]predicting train subjects:  14%|█▍        | 64/456 [01:52<12:20,  1.89s/it]predicting train subjects:  14%|█▍        | 65/456 [01:53<12:20,  1.89s/it]predicting train subjects:  14%|█▍        | 66/456 [01:55<12:06,  1.86s/it]predicting train subjects:  15%|█▍        | 67/456 [01:57<12:03,  1.86s/it]predicting train subjects:  15%|█▍        | 68/456 [01:59<11:54,  1.84s/it]predicting train subjects:  15%|█▌        | 69/456 [02:01<11:57,  1.86s/it]predicting train subjects:  15%|█▌        | 70/456 [02:03<11:56,  1.86s/it]predicting train subjects:  16%|█▌        | 71/456 [02:05<12:01,  1.87s/it]predicting train subjects:  16%|█▌        | 72/456 [02:06<12:05,  1.89s/it]predicting train subjects:  16%|█▌        | 73/456 [02:08<12:05,  1.90s/it]predicting train subjects:  16%|█▌        | 74/456 [02:10<12:03,  1.89s/it]predicting train subjects:  16%|█▋        | 75/456 [02:12<11:52,  1.87s/it]predicting train subjects:  17%|█▋        | 76/456 [02:14<11:43,  1.85s/it]predicting train subjects:  17%|█▋        | 77/456 [02:16<11:49,  1.87s/it]predicting train subjects:  17%|█▋        | 78/456 [02:18<11:42,  1.86s/it]predicting train subjects:  17%|█▋        | 79/456 [02:19<09:58,  1.59s/it]predicting train subjects:  18%|█▊        | 80/456 [02:19<08:36,  1.37s/it]predicting train subjects:  18%|█▊        | 81/456 [02:20<07:43,  1.24s/it]predicting train subjects:  18%|█▊        | 82/456 [02:21<07:07,  1.14s/it]predicting train subjects:  18%|█▊        | 83/456 [02:22<06:50,  1.10s/it]predicting train subjects:  18%|█▊        | 84/456 [02:23<06:33,  1.06s/it]predicting train subjects:  19%|█▊        | 85/456 [02:24<06:24,  1.04s/it]predicting train subjects:  19%|█▉        | 86/456 [02:25<06:17,  1.02s/it]predicting train subjects:  19%|█▉        | 87/456 [02:26<06:12,  1.01s/it]predicting train subjects:  19%|█▉        | 88/456 [02:27<06:05,  1.01it/s]predicting train subjects:  20%|█▉        | 89/456 [02:28<06:04,  1.01it/s]predicting train subjects:  20%|█▉        | 90/456 [02:29<06:00,  1.02it/s]predicting train subjects:  20%|█▉        | 91/456 [02:30<05:57,  1.02it/s]predicting train subjects:  20%|██        | 92/456 [02:31<05:53,  1.03it/s]predicting train subjects:  20%|██        | 93/456 [02:32<05:52,  1.03it/s]predicting train subjects:  21%|██        | 94/456 [02:33<05:46,  1.04it/s]predicting train subjects:  21%|██        | 95/456 [02:34<05:46,  1.04it/s]predicting train subjects:  21%|██        | 96/456 [02:35<05:44,  1.05it/s]predicting train subjects:  21%|██▏       | 97/456 [02:37<07:05,  1.19s/it]predicting train subjects:  21%|██▏       | 98/456 [02:38<08:03,  1.35s/it]predicting train subjects:  22%|██▏       | 99/456 [02:40<08:35,  1.44s/it]predicting train subjects:  22%|██▏       | 100/456 [02:42<09:04,  1.53s/it]predicting train subjects:  22%|██▏       | 101/456 [02:43<09:21,  1.58s/it]predicting train subjects:  22%|██▏       | 102/456 [02:45<09:29,  1.61s/it]predicting train subjects:  23%|██▎       | 103/456 [02:47<09:51,  1.68s/it]predicting train subjects:  23%|██▎       | 104/456 [02:49<10:04,  1.72s/it]predicting train subjects:  23%|██▎       | 105/456 [02:51<10:11,  1.74s/it]predicting train subjects:  23%|██▎       | 106/456 [02:52<10:05,  1.73s/it]predicting train subjects:  23%|██▎       | 107/456 [02:54<10:17,  1.77s/it]predicting train subjects:  24%|██▎       | 108/456 [02:56<10:14,  1.77s/it]predicting train subjects:  24%|██▍       | 109/456 [02:58<10:08,  1.75s/it]predicting train subjects:  24%|██▍       | 110/456 [02:59<10:04,  1.75s/it]predicting train subjects:  24%|██▍       | 111/456 [03:01<09:57,  1.73s/it]predicting train subjects:  25%|██▍       | 112/456 [03:03<09:57,  1.74s/it]predicting train subjects:  25%|██▍       | 113/456 [03:05<09:57,  1.74s/it]predicting train subjects:  25%|██▌       | 114/456 [03:06<09:51,  1.73s/it]predicting train subjects:  25%|██▌       | 115/456 [03:08<09:58,  1.75s/it]predicting train subjects:  25%|██▌       | 116/456 [03:10<10:04,  1.78s/it]predicting train subjects:  26%|██▌       | 117/456 [03:12<10:06,  1.79s/it]predicting train subjects:  26%|██▌       | 118/456 [03:13<10:04,  1.79s/it]predicting train subjects:  26%|██▌       | 119/456 [03:15<09:55,  1.77s/it]predicting train subjects:  26%|██▋       | 120/456 [03:17<09:48,  1.75s/it]predicting train subjects:  27%|██▋       | 121/456 [03:19<09:55,  1.78s/it]predicting train subjects:  27%|██▋       | 122/456 [03:21<10:11,  1.83s/it]predicting train subjects:  27%|██▋       | 123/456 [03:23<10:12,  1.84s/it]predicting train subjects:  27%|██▋       | 124/456 [03:24<10:14,  1.85s/it]predicting train subjects:  27%|██▋       | 125/456 [03:26<10:12,  1.85s/it]predicting train subjects:  28%|██▊       | 126/456 [03:28<10:18,  1.87s/it]predicting train subjects:  28%|██▊       | 127/456 [03:30<09:49,  1.79s/it]predicting train subjects:  28%|██▊       | 128/456 [03:31<09:31,  1.74s/it]predicting train subjects:  28%|██▊       | 129/456 [03:33<09:02,  1.66s/it]predicting train subjects:  29%|██▊       | 130/456 [03:34<08:38,  1.59s/it]predicting train subjects:  29%|██▊       | 131/456 [03:36<08:24,  1.55s/it]predicting train subjects:  29%|██▉       | 132/456 [03:37<08:13,  1.52s/it]predicting train subjects:  29%|██▉       | 133/456 [03:39<09:11,  1.71s/it]predicting train subjects:  29%|██▉       | 134/456 [03:42<10:17,  1.92s/it]predicting train subjects:  30%|██▉       | 135/456 [03:44<10:37,  1.98s/it]predicting train subjects:  30%|██▉       | 136/456 [03:46<10:55,  2.05s/it]predicting train subjects:  30%|███       | 137/456 [03:48<10:58,  2.06s/it]predicting train subjects:  30%|███       | 138/456 [03:50<10:59,  2.08s/it]predicting train subjects:  30%|███       | 139/456 [03:52<10:02,  1.90s/it]predicting train subjects:  31%|███       | 140/456 [03:53<09:18,  1.77s/it]predicting train subjects:  31%|███       | 141/456 [03:55<08:50,  1.68s/it]predicting train subjects:  31%|███       | 142/456 [03:56<08:34,  1.64s/it]predicting train subjects:  31%|███▏      | 143/456 [03:58<08:23,  1.61s/it]predicting train subjects:  32%|███▏      | 144/456 [03:59<08:11,  1.58s/it]predicting train subjects:  32%|███▏      | 145/456 [04:01<08:34,  1.66s/it]predicting train subjects:  32%|███▏      | 146/456 [04:03<08:39,  1.67s/it]predicting train subjects:  32%|███▏      | 147/456 [04:05<08:37,  1.67s/it]predicting train subjects:  32%|███▏      | 148/456 [04:06<08:42,  1.70s/it]predicting train subjects:  33%|███▎      | 149/456 [04:08<08:40,  1.69s/it]predicting train subjects:  33%|███▎      | 150/456 [04:10<08:31,  1.67s/it]predicting train subjects:  33%|███▎      | 151/456 [04:11<08:30,  1.67s/it]predicting train subjects:  33%|███▎      | 152/456 [04:13<08:27,  1.67s/it]predicting train subjects:  34%|███▎      | 153/456 [04:15<08:31,  1.69s/it]predicting train subjects:  34%|███▍      | 154/456 [04:16<08:37,  1.71s/it]predicting train subjects:  34%|███▍      | 155/456 [04:18<08:38,  1.72s/it]predicting train subjects:  34%|███▍      | 156/456 [04:20<08:38,  1.73s/it]predicting train subjects:  34%|███▍      | 157/456 [04:22<08:26,  1.70s/it]predicting train subjects:  35%|███▍      | 158/456 [04:23<08:13,  1.66s/it]predicting train subjects:  35%|███▍      | 159/456 [04:25<08:07,  1.64s/it]predicting train subjects:  35%|███▌      | 160/456 [04:26<08:04,  1.64s/it]predicting train subjects:  35%|███▌      | 161/456 [04:28<07:56,  1.61s/it]predicting train subjects:  36%|███▌      | 162/456 [04:30<07:53,  1.61s/it]predicting train subjects:  36%|███▌      | 163/456 [04:31<07:01,  1.44s/it]predicting train subjects:  36%|███▌      | 164/456 [04:32<06:25,  1.32s/it]predicting train subjects:  36%|███▌      | 165/456 [04:33<05:59,  1.24s/it]predicting train subjects:  36%|███▋      | 166/456 [04:34<05:43,  1.18s/it]predicting train subjects:  37%|███▋      | 167/456 [04:35<05:29,  1.14s/it]predicting train subjects:  37%|███▋      | 168/456 [04:36<05:17,  1.10s/it]predicting train subjects:  37%|███▋      | 169/456 [04:37<05:15,  1.10s/it]predicting train subjects:  37%|███▋      | 170/456 [04:38<05:09,  1.08s/it]predicting train subjects:  38%|███▊      | 171/456 [04:39<05:08,  1.08s/it]predicting train subjects:  38%|███▊      | 172/456 [04:40<05:12,  1.10s/it]predicting train subjects:  38%|███▊      | 173/456 [04:41<05:03,  1.07s/it]predicting train subjects:  38%|███▊      | 174/456 [04:42<04:58,  1.06s/it]predicting train subjects:  38%|███▊      | 175/456 [04:43<04:44,  1.01s/it]predicting train subjects:  39%|███▊      | 176/456 [04:44<04:38,  1.00it/s]predicting train subjects:  39%|███▉      | 177/456 [04:45<04:32,  1.02it/s]predicting train subjects:  39%|███▉      | 178/456 [04:46<04:27,  1.04it/s]predicting train subjects:  39%|███▉      | 179/456 [04:47<04:28,  1.03it/s]predicting train subjects:  39%|███▉      | 180/456 [04:48<04:23,  1.05it/s]predicting train subjects:  40%|███▉      | 181/456 [04:50<05:38,  1.23s/it]predicting train subjects:  40%|███▉      | 182/456 [04:52<06:33,  1.43s/it]predicting train subjects:  40%|████      | 183/456 [04:53<07:10,  1.58s/it]predicting train subjects:  40%|████      | 184/456 [04:55<07:37,  1.68s/it]predicting train subjects:  41%|████      | 185/456 [04:57<07:51,  1.74s/it]predicting train subjects:  41%|████      | 186/456 [04:59<08:10,  1.82s/it]predicting train subjects:  41%|████      | 187/456 [05:02<08:41,  1.94s/it]predicting train subjects:  41%|████      | 188/456 [05:04<09:08,  2.05s/it]predicting train subjects:  41%|████▏     | 189/456 [05:06<09:33,  2.15s/it]predicting train subjects:  42%|████▏     | 190/456 [05:09<09:46,  2.20s/it]predicting train subjects:  42%|████▏     | 191/456 [05:11<09:51,  2.23s/it]predicting train subjects:  42%|████▏     | 192/456 [05:13<09:51,  2.24s/it]predicting train subjects:  42%|████▏     | 193/456 [05:15<09:32,  2.18s/it]predicting train subjects:  43%|████▎     | 194/456 [05:17<09:17,  2.13s/it]predicting train subjects:  43%|████▎     | 195/456 [05:19<09:00,  2.07s/it]predicting train subjects:  43%|████▎     | 196/456 [05:21<08:48,  2.03s/it]predicting train subjects:  43%|████▎     | 197/456 [05:23<08:42,  2.02s/it]predicting train subjects:  43%|████▎     | 198/456 [05:25<08:46,  2.04s/it]predicting train subjects:  44%|████▎     | 199/456 [05:27<08:26,  1.97s/it]predicting train subjects:  44%|████▍     | 200/456 [05:29<08:12,  1.92s/it]predicting train subjects:  44%|████▍     | 201/456 [05:31<08:04,  1.90s/it]predicting train subjects:  44%|████▍     | 202/456 [05:32<07:54,  1.87s/it]predicting train subjects:  45%|████▍     | 203/456 [05:34<07:46,  1.85s/it]predicting train subjects:  45%|████▍     | 204/456 [05:36<07:43,  1.84s/it]predicting train subjects:  45%|████▍     | 205/456 [05:37<07:15,  1.73s/it]predicting train subjects:  45%|████▌     | 206/456 [05:39<06:55,  1.66s/it]predicting train subjects:  45%|████▌     | 207/456 [05:40<06:41,  1.61s/it]predicting train subjects:  46%|████▌     | 208/456 [05:42<06:32,  1.58s/it]predicting train subjects:  46%|████▌     | 209/456 [05:44<06:28,  1.57s/it]predicting train subjects:  46%|████▌     | 210/456 [05:45<06:21,  1.55s/it]predicting train subjects:  46%|████▋     | 211/456 [05:47<06:27,  1.58s/it]predicting train subjects:  46%|████▋     | 212/456 [05:48<06:36,  1.62s/it]predicting train subjects:  47%|████▋     | 213/456 [05:50<06:42,  1.66s/it]predicting train subjects:  47%|████▋     | 214/456 [05:52<06:42,  1.66s/it]predicting train subjects:  47%|████▋     | 215/456 [05:53<06:42,  1.67s/it]predicting train subjects:  47%|████▋     | 216/456 [05:55<06:43,  1.68s/it]predicting train subjects:  48%|████▊     | 217/456 [05:57<06:47,  1.70s/it]predicting train subjects:  48%|████▊     | 218/456 [05:59<06:43,  1.69s/it]predicting train subjects:  48%|████▊     | 219/456 [06:00<06:43,  1.70s/it]predicting train subjects:  48%|████▊     | 220/456 [06:02<06:37,  1.68s/it]predicting train subjects:  48%|████▊     | 221/456 [06:04<06:36,  1.69s/it]predicting train subjects:  49%|████▊     | 222/456 [06:05<06:37,  1.70s/it]predicting train subjects:  49%|████▉     | 223/456 [06:07<06:42,  1.73s/it]predicting train subjects:  49%|████▉     | 224/456 [06:09<06:39,  1.72s/it]predicting train subjects:  49%|████▉     | 225/456 [06:11<06:44,  1.75s/it]predicting train subjects:  50%|████▉     | 226/456 [06:12<06:39,  1.74s/it]predicting train subjects:  50%|████▉     | 227/456 [06:14<06:38,  1.74s/it]predicting train subjects:  50%|█████     | 228/456 [06:16<06:37,  1.74s/it]predicting train subjects:  50%|█████     | 229/456 [06:18<06:38,  1.76s/it]predicting train subjects:  50%|█████     | 230/456 [06:19<06:32,  1.74s/it]predicting train subjects:  51%|█████     | 231/456 [06:21<06:27,  1.72s/it]predicting train subjects:  51%|█████     | 232/456 [06:23<06:29,  1.74s/it]predicting train subjects:  51%|█████     | 233/456 [06:25<06:24,  1.72s/it]predicting train subjects:  51%|█████▏    | 234/456 [06:26<06:21,  1.72s/it]predicting train subjects:  52%|█████▏    | 235/456 [06:28<06:26,  1.75s/it]predicting train subjects:  52%|█████▏    | 236/456 [06:30<06:24,  1.75s/it]predicting train subjects:  52%|█████▏    | 237/456 [06:32<06:22,  1.74s/it]predicting train subjects:  52%|█████▏    | 238/456 [06:33<06:25,  1.77s/it]predicting train subjects:  52%|█████▏    | 239/456 [06:35<06:20,  1.75s/it]predicting train subjects:  53%|█████▎    | 240/456 [06:37<06:22,  1.77s/it]predicting train subjects:  53%|█████▎    | 241/456 [06:39<06:23,  1.78s/it]predicting train subjects:  53%|█████▎    | 242/456 [06:41<06:27,  1.81s/it]predicting train subjects:  53%|█████▎    | 243/456 [06:42<06:27,  1.82s/it]predicting train subjects:  54%|█████▎    | 244/456 [06:44<06:24,  1.81s/it]predicting train subjects:  54%|█████▎    | 245/456 [06:46<06:22,  1.81s/it]predicting train subjects:  54%|█████▍    | 246/456 [06:48<06:16,  1.79s/it]predicting train subjects:  54%|█████▍    | 247/456 [06:49<05:51,  1.68s/it]predicting train subjects:  54%|█████▍    | 248/456 [06:51<05:30,  1.59s/it]predicting train subjects:  55%|█████▍    | 249/456 [06:52<05:19,  1.55s/it]predicting train subjects:  55%|█████▍    | 250/456 [06:53<05:07,  1.49s/it]predicting train subjects:  55%|█████▌    | 251/456 [06:55<05:03,  1.48s/it]predicting train subjects:  55%|█████▌    | 252/456 [06:56<04:58,  1.46s/it]predicting train subjects:  55%|█████▌    | 253/456 [06:58<05:36,  1.66s/it]predicting train subjects:  56%|█████▌    | 254/456 [07:00<06:01,  1.79s/it]predicting train subjects:  56%|█████▌    | 255/456 [07:03<06:18,  1.88s/it]predicting train subjects:  56%|█████▌    | 256/456 [07:05<06:36,  1.98s/it]predicting train subjects:  56%|█████▋    | 257/456 [07:07<06:45,  2.04s/it]predicting train subjects:  57%|█████▋    | 258/456 [07:09<06:50,  2.07s/it]predicting train subjects:  57%|█████▋    | 259/456 [07:11<06:16,  1.91s/it]predicting train subjects:  57%|█████▋    | 260/456 [07:12<05:53,  1.80s/it]predicting train subjects:  57%|█████▋    | 261/456 [07:14<05:36,  1.73s/it]predicting train subjects:  57%|█████▋    | 262/456 [07:15<05:27,  1.69s/it]predicting train subjects:  58%|█████▊    | 263/456 [07:17<05:21,  1.66s/it]predicting train subjects:  58%|█████▊    | 264/456 [07:19<05:18,  1.66s/it]predicting train subjects:  58%|█████▊    | 265/456 [07:20<05:15,  1.65s/it]predicting train subjects:  58%|█████▊    | 266/456 [07:22<05:14,  1.65s/it]predicting train subjects:  59%|█████▊    | 267/456 [07:24<05:16,  1.67s/it]predicting train subjects:  59%|█████▉    | 268/456 [07:25<05:16,  1.68s/it]predicting train subjects:  59%|█████▉    | 269/456 [07:27<05:19,  1.71s/it]predicting train subjects:  59%|█████▉    | 270/456 [07:29<05:13,  1.69s/it]predicting train subjects:  59%|█████▉    | 271/456 [07:31<05:18,  1.72s/it]predicting train subjects:  60%|█████▉    | 272/456 [07:32<05:19,  1.74s/it]predicting train subjects:  60%|█████▉    | 273/456 [07:34<05:20,  1.75s/it]predicting train subjects:  60%|██████    | 274/456 [07:36<05:21,  1.77s/it]predicting train subjects:  60%|██████    | 275/456 [07:38<05:23,  1.79s/it]predicting train subjects:  61%|██████    | 276/456 [07:40<05:20,  1.78s/it]predicting train subjects:  61%|██████    | 277/456 [07:41<05:14,  1.76s/it]predicting train subjects:  61%|██████    | 278/456 [07:43<05:09,  1.74s/it]predicting train subjects:  61%|██████    | 279/456 [07:45<05:01,  1.71s/it]predicting train subjects:  61%|██████▏   | 280/456 [07:46<04:57,  1.69s/it]predicting train subjects:  62%|██████▏   | 281/456 [07:48<04:58,  1.70s/it]predicting train subjects:  62%|██████▏   | 282/456 [07:50<04:56,  1.70s/it]predicting train subjects:  62%|██████▏   | 283/456 [07:51<04:24,  1.53s/it]predicting train subjects:  62%|██████▏   | 284/456 [07:52<04:03,  1.42s/it]predicting train subjects:  62%|██████▎   | 285/456 [07:53<03:43,  1.31s/it]predicting train subjects:  63%|██████▎   | 286/456 [07:54<03:28,  1.23s/it]predicting train subjects:  63%|██████▎   | 287/456 [07:55<03:19,  1.18s/it]predicting train subjects:  63%|██████▎   | 288/456 [07:56<03:11,  1.14s/it]predicting train subjects:  63%|██████▎   | 289/456 [07:57<03:07,  1.12s/it]predicting train subjects:  64%|██████▎   | 290/456 [07:58<03:03,  1.11s/it]predicting train subjects:  64%|██████▍   | 291/456 [07:59<03:02,  1.11s/it]predicting train subjects:  64%|██████▍   | 292/456 [08:00<02:59,  1.10s/it]predicting train subjects:  64%|██████▍   | 293/456 [08:01<02:56,  1.08s/it]predicting train subjects:  64%|██████▍   | 294/456 [08:03<02:53,  1.07s/it]predicting train subjects:  65%|██████▍   | 295/456 [08:04<02:47,  1.04s/it]predicting train subjects:  65%|██████▍   | 296/456 [08:04<02:44,  1.03s/it]predicting train subjects:  65%|██████▌   | 297/456 [08:06<02:42,  1.02s/it]predicting train subjects:  65%|██████▌   | 298/456 [08:07<02:40,  1.02s/it]predicting train subjects:  66%|██████▌   | 299/456 [08:08<02:39,  1.01s/it]predicting train subjects:  66%|██████▌   | 300/456 [08:09<02:37,  1.01s/it]predicting train subjects:  66%|██████▌   | 301/456 [08:11<03:24,  1.32s/it]predicting train subjects:  66%|██████▌   | 302/456 [08:13<03:53,  1.51s/it]predicting train subjects:  66%|██████▋   | 303/456 [08:15<04:12,  1.65s/it]predicting train subjects:  67%|██████▋   | 304/456 [08:17<04:27,  1.76s/it]predicting train subjects:  67%|██████▋   | 305/456 [08:18<04:34,  1.82s/it]predicting train subjects:  67%|██████▋   | 306/456 [08:20<04:41,  1.87s/it]predicting train subjects:  67%|██████▋   | 307/456 [08:23<04:59,  2.01s/it]predicting train subjects:  68%|██████▊   | 308/456 [08:25<05:11,  2.10s/it]predicting train subjects:  68%|██████▊   | 309/456 [08:27<05:14,  2.14s/it]predicting train subjects:  68%|██████▊   | 310/456 [08:30<05:15,  2.16s/it]predicting train subjects:  68%|██████▊   | 311/456 [08:32<05:22,  2.22s/it]predicting train subjects:  68%|██████▊   | 312/456 [08:34<05:19,  2.22s/it]predicting train subjects:  69%|██████▊   | 313/456 [08:36<05:07,  2.15s/it]predicting train subjects:  69%|██████▉   | 314/456 [08:38<04:59,  2.11s/it]predicting train subjects:  69%|██████▉   | 315/456 [08:40<04:54,  2.09s/it]predicting train subjects:  69%|██████▉   | 316/456 [08:42<04:50,  2.07s/it]predicting train subjects:  70%|██████▉   | 317/456 [08:44<04:56,  2.13s/it]predicting train subjects:  70%|██████▉   | 318/456 [08:47<04:51,  2.11s/it]predicting train subjects:  70%|██████▉   | 319/456 [08:48<04:39,  2.04s/it]predicting train subjects:  70%|███████   | 320/456 [08:50<04:29,  1.98s/it]predicting train subjects:  70%|███████   | 321/456 [08:52<04:22,  1.94s/it]predicting train subjects:  71%|███████   | 322/456 [08:54<04:20,  1.94s/it]predicting train subjects:  71%|███████   | 323/456 [08:56<04:12,  1.90s/it]predicting train subjects:  71%|███████   | 324/456 [08:58<04:07,  1.87s/it]predicting train subjects:  71%|███████▏  | 325/456 [08:59<03:52,  1.77s/it]predicting train subjects:  71%|███████▏  | 326/456 [09:01<03:39,  1.69s/it]predicting train subjects:  72%|███████▏  | 327/456 [09:02<03:28,  1.62s/it]predicting train subjects:  72%|███████▏  | 328/456 [09:04<03:22,  1.58s/it]predicting train subjects:  72%|███████▏  | 329/456 [09:05<03:20,  1.58s/it]predicting train subjects:  72%|███████▏  | 330/456 [09:07<03:15,  1.55s/it]predicting train subjects:  73%|███████▎  | 331/456 [09:09<03:23,  1.62s/it]predicting train subjects:  73%|███████▎  | 332/456 [09:10<03:28,  1.68s/it]predicting train subjects:  73%|███████▎  | 333/456 [09:12<03:29,  1.70s/it]predicting train subjects:  73%|███████▎  | 334/456 [09:14<03:29,  1.72s/it]predicting train subjects:  73%|███████▎  | 335/456 [09:16<03:32,  1.76s/it]predicting train subjects:  74%|███████▎  | 336/456 [09:17<03:31,  1.76s/it]predicting train subjects:  74%|███████▍  | 337/456 [09:19<03:31,  1.78s/it]predicting train subjects:  74%|███████▍  | 338/456 [09:21<03:28,  1.77s/it]predicting train subjects:  74%|███████▍  | 339/456 [09:23<03:26,  1.76s/it]predicting train subjects:  75%|███████▍  | 340/456 [09:25<03:25,  1.77s/it]predicting train subjects:  75%|███████▍  | 341/456 [09:26<03:28,  1.81s/it]predicting train subjects:  75%|███████▌  | 342/456 [09:28<03:24,  1.80s/it]predicting train subjects:  75%|███████▌  | 343/456 [09:30<03:26,  1.83s/it]predicting train subjects:  75%|███████▌  | 344/456 [09:32<03:25,  1.84s/it]predicting train subjects:  76%|███████▌  | 345/456 [09:34<03:24,  1.84s/it]predicting train subjects:  76%|███████▌  | 346/456 [09:36<03:21,  1.84s/it]predicting train subjects:  76%|███████▌  | 347/456 [09:38<03:22,  1.86s/it]predicting train subjects:  76%|███████▋  | 348/456 [09:39<03:19,  1.85s/it]predicting train subjects:  77%|███████▋  | 349/456 [09:41<03:20,  1.87s/it]predicting train subjects:  77%|███████▋  | 350/456 [09:43<03:17,  1.86s/it]predicting train subjects:  77%|███████▋  | 351/456 [09:45<03:16,  1.87s/it]predicting train subjects:  77%|███████▋  | 352/456 [09:47<03:13,  1.86s/it]predicting train subjects:  77%|███████▋  | 353/456 [09:49<03:11,  1.86s/it]predicting train subjects:  78%|███████▊  | 354/456 [09:51<03:14,  1.91s/it]predicting train subjects:  78%|███████▊  | 355/456 [09:53<03:14,  1.92s/it]predicting train subjects:  78%|███████▊  | 356/456 [09:55<03:09,  1.90s/it]predicting train subjects:  78%|███████▊  | 357/456 [09:56<03:07,  1.89s/it]predicting train subjects:  79%|███████▊  | 358/456 [09:58<03:06,  1.91s/it]predicting train subjects:  79%|███████▊  | 359/456 [10:00<03:07,  1.94s/it]predicting train subjects:  79%|███████▉  | 360/456 [10:02<03:04,  1.92s/it]predicting train subjects:  79%|███████▉  | 361/456 [10:04<03:04,  1.94s/it]predicting train subjects:  79%|███████▉  | 362/456 [10:06<02:59,  1.91s/it]predicting train subjects:  80%|███████▉  | 363/456 [10:08<02:57,  1.91s/it]predicting train subjects:  80%|███████▉  | 364/456 [10:10<02:54,  1.90s/it]predicting train subjects:  80%|████████  | 365/456 [10:12<02:57,  1.96s/it]predicting train subjects:  80%|████████  | 366/456 [10:14<02:55,  1.95s/it]predicting train subjects:  80%|████████  | 367/456 [10:16<02:46,  1.87s/it]predicting train subjects:  81%|████████  | 368/456 [10:17<02:35,  1.76s/it]predicting train subjects:  81%|████████  | 369/456 [10:19<02:27,  1.69s/it]predicting train subjects:  81%|████████  | 370/456 [10:20<02:23,  1.66s/it]predicting train subjects:  81%|████████▏ | 371/456 [10:22<02:19,  1.64s/it]predicting train subjects:  82%|████████▏ | 372/456 [10:23<02:14,  1.61s/it]predicting train subjects:  82%|████████▏ | 373/456 [10:26<02:29,  1.80s/it]predicting train subjects:  82%|████████▏ | 374/456 [10:28<02:38,  1.94s/it]predicting train subjects:  82%|████████▏ | 375/456 [10:30<02:46,  2.06s/it]predicting train subjects:  82%|████████▏ | 376/456 [10:33<02:50,  2.14s/it]predicting train subjects:  83%|████████▎ | 377/456 [10:35<02:50,  2.16s/it]predicting train subjects:  83%|████████▎ | 378/456 [10:37<02:49,  2.18s/it]predicting train subjects:  83%|████████▎ | 379/456 [10:39<02:33,  2.00s/it]predicting train subjects:  83%|████████▎ | 380/456 [10:40<02:22,  1.88s/it]predicting train subjects:  84%|████████▎ | 381/456 [10:42<02:14,  1.79s/it]predicting train subjects:  84%|████████▍ | 382/456 [10:43<02:07,  1.73s/it]predicting train subjects:  84%|████████▍ | 383/456 [10:45<02:03,  1.69s/it]predicting train subjects:  84%|████████▍ | 384/456 [10:46<01:59,  1.66s/it]predicting train subjects:  84%|████████▍ | 385/456 [10:48<01:58,  1.67s/it]predicting train subjects:  85%|████████▍ | 386/456 [10:50<01:58,  1.70s/it]predicting train subjects:  85%|████████▍ | 387/456 [10:52<01:58,  1.72s/it]predicting train subjects:  85%|████████▌ | 388/456 [10:53<01:57,  1.73s/it]predicting train subjects:  85%|████████▌ | 389/456 [10:55<01:55,  1.72s/it]predicting train subjects:  86%|████████▌ | 390/456 [10:57<01:53,  1.72s/it]predicting train subjects:  86%|████████▌ | 391/456 [10:59<01:56,  1.78s/it]predicting train subjects:  86%|████████▌ | 392/456 [11:01<01:53,  1.78s/it]predicting train subjects:  86%|████████▌ | 393/456 [11:02<01:52,  1.78s/it]predicting train subjects:  86%|████████▋ | 394/456 [11:04<01:50,  1.79s/it]predicting train subjects:  87%|████████▋ | 395/456 [11:06<01:49,  1.79s/it]predicting train subjects:  87%|████████▋ | 396/456 [11:08<01:47,  1.80s/it]predicting train subjects:  87%|████████▋ | 397/456 [11:09<01:43,  1.76s/it]predicting train subjects:  87%|████████▋ | 398/456 [11:11<01:41,  1.75s/it]predicting train subjects:  88%|████████▊ | 399/456 [11:13<01:38,  1.73s/it]predicting train subjects:  88%|████████▊ | 400/456 [11:15<01:36,  1.71s/it]predicting train subjects:  88%|████████▊ | 401/456 [11:16<01:33,  1.69s/it]predicting train subjects:  88%|████████▊ | 402/456 [11:18<01:30,  1.68s/it]predicting train subjects:  88%|████████▊ | 403/456 [11:19<01:18,  1.49s/it]predicting train subjects:  89%|████████▊ | 404/456 [11:20<01:10,  1.35s/it]predicting train subjects:  89%|████████▉ | 405/456 [11:21<01:06,  1.30s/it]predicting train subjects:  89%|████████▉ | 406/456 [11:22<01:01,  1.23s/it]predicting train subjects:  89%|████████▉ | 407/456 [11:23<00:57,  1.17s/it]predicting train subjects:  89%|████████▉ | 408/456 [11:24<00:54,  1.13s/it]predicting train subjects:  90%|████████▉ | 409/456 [11:25<00:52,  1.12s/it]predicting train subjects:  90%|████████▉ | 410/456 [11:26<00:50,  1.10s/it]predicting train subjects:  90%|█████████ | 411/456 [11:27<00:48,  1.08s/it]predicting train subjects:  90%|█████████ | 412/456 [11:28<00:47,  1.08s/it]predicting train subjects:  91%|█████████ | 413/456 [11:30<00:46,  1.07s/it]predicting train subjects:  91%|█████████ | 414/456 [11:31<00:44,  1.06s/it]predicting train subjects:  91%|█████████ | 415/456 [11:32<00:42,  1.03s/it]predicting train subjects:  91%|█████████ | 416/456 [11:33<00:41,  1.04s/it]predicting train subjects:  91%|█████████▏| 417/456 [11:34<00:40,  1.03s/it]predicting train subjects:  92%|█████████▏| 418/456 [11:35<00:39,  1.03s/it]predicting train subjects:  92%|█████████▏| 419/456 [11:36<00:38,  1.05s/it]predicting train subjects:  92%|█████████▏| 420/456 [11:37<00:37,  1.03s/it]predicting train subjects:  92%|█████████▏| 421/456 [11:39<00:46,  1.33s/it]predicting train subjects:  93%|█████████▎| 422/456 [11:41<00:52,  1.53s/it]predicting train subjects:  93%|█████████▎| 423/456 [11:43<00:54,  1.65s/it]predicting train subjects:  93%|█████████▎| 424/456 [11:45<00:56,  1.77s/it]predicting train subjects:  93%|█████████▎| 425/456 [11:47<00:56,  1.82s/it]predicting train subjects:  93%|█████████▎| 426/456 [11:49<00:55,  1.85s/it]predicting train subjects:  94%|█████████▎| 427/456 [11:51<00:58,  2.01s/it]predicting train subjects:  94%|█████████▍| 428/456 [11:53<00:59,  2.11s/it]predicting train subjects:  94%|█████████▍| 429/456 [11:56<00:58,  2.15s/it]predicting train subjects:  94%|█████████▍| 430/456 [11:58<00:57,  2.21s/it]predicting train subjects:  95%|█████████▍| 431/456 [12:00<00:55,  2.24s/it]predicting train subjects:  95%|█████████▍| 432/456 [12:02<00:54,  2.26s/it]predicting train subjects:  95%|█████████▍| 433/456 [12:05<00:51,  2.22s/it]predicting train subjects:  95%|█████████▌| 434/456 [12:07<00:47,  2.16s/it]predicting train subjects:  95%|█████████▌| 435/456 [12:09<00:44,  2.12s/it]predicting train subjects:  96%|█████████▌| 436/456 [12:11<00:42,  2.10s/it]predicting train subjects:  96%|█████████▌| 437/456 [12:13<00:39,  2.07s/it]predicting train subjects:  96%|█████████▌| 438/456 [12:15<00:38,  2.15s/it]predicting train subjects:  96%|█████████▋| 439/456 [12:17<00:35,  2.07s/it]predicting train subjects:  96%|█████████▋| 440/456 [12:19<00:32,  2.03s/it]predicting train subjects:  97%|█████████▋| 441/456 [12:21<00:29,  1.97s/it]predicting train subjects:  97%|█████████▋| 442/456 [12:23<00:26,  1.93s/it]predicting train subjects:  97%|█████████▋| 443/456 [12:24<00:25,  1.92s/it]predicting train subjects:  97%|█████████▋| 444/456 [12:26<00:23,  1.92s/it]predicting train subjects:  98%|█████████▊| 445/456 [12:28<00:19,  1.81s/it]predicting train subjects:  98%|█████████▊| 446/456 [12:29<00:17,  1.71s/it]predicting train subjects:  98%|█████████▊| 447/456 [12:31<00:14,  1.66s/it]predicting train subjects:  98%|█████████▊| 448/456 [12:32<00:13,  1.63s/it]predicting train subjects:  98%|█████████▊| 449/456 [12:34<00:11,  1.60s/it]predicting train subjects:  99%|█████████▊| 450/456 [12:36<00:09,  1.58s/it]predicting train subjects:  99%|█████████▉| 451/456 [12:37<00:08,  1.64s/it]predicting train subjects:  99%|█████████▉| 452/456 [12:39<00:06,  1.70s/it]predicting train subjects:  99%|█████████▉| 453/456 [12:41<00:05,  1.72s/it]predicting train subjects: 100%|█████████▉| 454/456 [12:43<00:03,  1.74s/it]predicting train subjects: 100%|█████████▉| 455/456 [12:45<00:01,  1.77s/it]predicting train subjects: 100%|██████████| 456/456 [12:46<00:00,  1.80s/it]
Loading train:   0%|          | 0/456 [00:00<?, ?it/s]Loading train:   0%|          | 1/456 [00:01<13:13,  1.74s/it]Loading train:   0%|          | 2/456 [00:02<11:50,  1.57s/it]Loading train:   1%|          | 3/456 [00:04<11:10,  1.48s/it]Loading train:   1%|          | 4/456 [00:05<10:03,  1.34s/it]Loading train:   1%|          | 5/456 [00:06<10:14,  1.36s/it]Loading train:   1%|▏         | 6/456 [00:08<10:51,  1.45s/it]Loading train:   2%|▏         | 7/456 [00:09<10:27,  1.40s/it]Loading train:   2%|▏         | 8/456 [00:10<09:50,  1.32s/it]Loading train:   2%|▏         | 9/456 [00:12<10:04,  1.35s/it]Loading train:   2%|▏         | 10/456 [00:13<10:34,  1.42s/it]Loading train:   2%|▏         | 11/456 [00:15<10:53,  1.47s/it]Loading train:   3%|▎         | 12/456 [00:16<10:22,  1.40s/it]Loading train:   3%|▎         | 13/456 [00:17<09:52,  1.34s/it]Loading train:   3%|▎         | 14/456 [00:19<10:03,  1.37s/it]Loading train:   3%|▎         | 15/456 [00:20<09:47,  1.33s/it]Loading train:   4%|▎         | 16/456 [00:21<10:03,  1.37s/it]Loading train:   4%|▎         | 17/456 [00:23<10:41,  1.46s/it]Loading train:   4%|▍         | 18/456 [00:24<10:23,  1.42s/it]Loading train:   4%|▍         | 19/456 [00:25<09:45,  1.34s/it]Loading train:   4%|▍         | 20/456 [00:27<09:18,  1.28s/it]Loading train:   5%|▍         | 21/456 [00:28<09:12,  1.27s/it]Loading train:   5%|▍         | 22/456 [00:29<09:12,  1.27s/it]Loading train:   5%|▌         | 23/456 [00:30<09:08,  1.27s/it]Loading train:   5%|▌         | 24/456 [00:32<08:55,  1.24s/it]Loading train:   5%|▌         | 25/456 [00:33<09:32,  1.33s/it]Loading train:   6%|▌         | 26/456 [00:34<09:05,  1.27s/it]Loading train:   6%|▌         | 27/456 [00:35<08:35,  1.20s/it]Loading train:   6%|▌         | 28/456 [00:36<08:22,  1.17s/it]Loading train:   6%|▋         | 29/456 [00:38<08:15,  1.16s/it]Loading train:   7%|▋         | 30/456 [00:39<08:06,  1.14s/it]Loading train:   7%|▋         | 31/456 [00:40<07:55,  1.12s/it]Loading train:   7%|▋         | 32/456 [00:41<07:55,  1.12s/it]Loading train:   7%|▋         | 33/456 [00:42<07:53,  1.12s/it]Loading train:   7%|▋         | 34/456 [00:43<07:43,  1.10s/it]Loading train:   8%|▊         | 35/456 [00:44<07:31,  1.07s/it]Loading train:   8%|▊         | 36/456 [00:45<07:27,  1.07s/it]Loading train:   8%|▊         | 37/456 [00:46<07:40,  1.10s/it]Loading train:   8%|▊         | 38/456 [00:47<07:37,  1.10s/it]Loading train:   9%|▊         | 39/456 [00:49<07:59,  1.15s/it]Loading train:   9%|▉         | 40/456 [00:50<08:28,  1.22s/it]Loading train:   9%|▉         | 41/456 [00:51<08:30,  1.23s/it]Loading train:   9%|▉         | 42/456 [00:53<08:46,  1.27s/it]Loading train:   9%|▉         | 43/456 [00:54<09:06,  1.32s/it]Loading train:  10%|▉         | 44/456 [00:56<09:55,  1.45s/it]Loading train:  10%|▉         | 45/456 [00:57<10:06,  1.48s/it]Loading train:  10%|█         | 46/456 [00:59<10:05,  1.48s/it]Loading train:  10%|█         | 47/456 [01:00<09:52,  1.45s/it]Loading train:  11%|█         | 48/456 [01:01<09:23,  1.38s/it]Loading train:  11%|█         | 49/456 [01:03<09:09,  1.35s/it]Loading train:  11%|█         | 50/456 [01:04<08:42,  1.29s/it]Loading train:  11%|█         | 51/456 [01:05<08:49,  1.31s/it]Loading train:  11%|█▏        | 52/456 [01:07<09:03,  1.34s/it]Loading train:  12%|█▏        | 53/456 [01:08<09:02,  1.35s/it]Loading train:  12%|█▏        | 54/456 [01:09<09:18,  1.39s/it]Loading train:  12%|█▏        | 55/456 [01:11<09:03,  1.36s/it]Loading train:  12%|█▏        | 56/456 [01:12<09:03,  1.36s/it]Loading train:  12%|█▎        | 57/456 [01:13<08:42,  1.31s/it]Loading train:  13%|█▎        | 58/456 [01:14<08:27,  1.28s/it]Loading train:  13%|█▎        | 59/456 [01:16<08:21,  1.26s/it]Loading train:  13%|█▎        | 60/456 [01:17<08:14,  1.25s/it]Loading train:  13%|█▎        | 61/456 [01:18<08:26,  1.28s/it]Loading train:  14%|█▎        | 62/456 [01:20<08:35,  1.31s/it]Loading train:  14%|█▍        | 63/456 [01:21<08:25,  1.29s/it]Loading train:  14%|█▍        | 64/456 [01:22<08:59,  1.38s/it]Loading train:  14%|█▍        | 65/456 [01:24<08:42,  1.34s/it]Loading train:  14%|█▍        | 66/456 [01:25<08:32,  1.31s/it]Loading train:  15%|█▍        | 67/456 [01:26<08:15,  1.27s/it]Loading train:  15%|█▍        | 68/456 [01:27<07:19,  1.13s/it]Loading train:  15%|█▌        | 69/456 [01:28<06:46,  1.05s/it]Loading train:  15%|█▌        | 70/456 [01:29<06:20,  1.01it/s]Loading train:  16%|█▌        | 71/456 [01:30<06:14,  1.03it/s]Loading train:  16%|█▌        | 72/456 [01:31<06:30,  1.02s/it]Loading train:  16%|█▌        | 73/456 [01:32<06:38,  1.04s/it]Loading train:  16%|█▌        | 74/456 [01:33<07:15,  1.14s/it]Loading train:  16%|█▋        | 75/456 [01:34<07:13,  1.14s/it]Loading train:  17%|█▋        | 76/456 [01:35<06:51,  1.08s/it]Loading train:  17%|█▋        | 77/456 [01:36<06:16,  1.01it/s]Loading train:  17%|█▋        | 78/456 [01:37<06:03,  1.04it/s]Loading train:  17%|█▋        | 79/456 [01:38<05:25,  1.16it/s]Loading train:  18%|█▊        | 80/456 [01:38<05:21,  1.17it/s]Loading train:  18%|█▊        | 81/456 [01:39<05:08,  1.21it/s]Loading train:  18%|█▊        | 82/456 [01:40<05:02,  1.24it/s]Loading train:  18%|█▊        | 83/456 [01:41<04:54,  1.27it/s]Loading train:  18%|█▊        | 84/456 [01:41<04:34,  1.35it/s]Loading train:  19%|█▊        | 85/456 [01:42<04:19,  1.43it/s]Loading train:  19%|█▉        | 86/456 [01:43<04:07,  1.49it/s]Loading train:  19%|█▉        | 87/456 [01:43<04:05,  1.50it/s]Loading train:  19%|█▉        | 88/456 [01:44<03:51,  1.59it/s]Loading train:  20%|█▉        | 89/456 [01:44<03:40,  1.66it/s]Loading train:  20%|█▉        | 90/456 [01:45<03:36,  1.69it/s]Loading train:  20%|█▉        | 91/456 [01:45<03:40,  1.66it/s]Loading train:  20%|██        | 92/456 [01:46<03:37,  1.68it/s]Loading train:  20%|██        | 93/456 [01:47<03:41,  1.64it/s]Loading train:  21%|██        | 94/456 [01:47<03:49,  1.58it/s]Loading train:  21%|██        | 95/456 [01:48<03:57,  1.52it/s]Loading train:  21%|██        | 96/456 [01:49<04:04,  1.47it/s]Loading train:  21%|██▏       | 97/456 [01:50<04:30,  1.33it/s]Loading train:  21%|██▏       | 98/456 [01:50<04:27,  1.34it/s]Loading train:  22%|██▏       | 99/456 [01:51<04:20,  1.37it/s]Loading train:  22%|██▏       | 100/456 [01:52<04:22,  1.36it/s]Loading train:  22%|██▏       | 101/456 [01:53<04:24,  1.34it/s]Loading train:  22%|██▏       | 102/456 [01:53<04:20,  1.36it/s]Loading train:  23%|██▎       | 103/456 [01:54<04:47,  1.23it/s]Loading train:  23%|██▎       | 104/456 [01:55<04:52,  1.20it/s]Loading train:  23%|██▎       | 105/456 [01:56<04:55,  1.19it/s]Loading train:  23%|██▎       | 106/456 [01:57<04:42,  1.24it/s]Loading train:  23%|██▎       | 107/456 [01:58<04:48,  1.21it/s]Loading train:  24%|██▎       | 108/456 [01:59<04:46,  1.22it/s]Loading train:  24%|██▍       | 109/456 [02:00<05:07,  1.13it/s]Loading train:  24%|██▍       | 110/456 [02:00<04:54,  1.18it/s]Loading train:  24%|██▍       | 111/456 [02:01<04:53,  1.18it/s]Loading train:  25%|██▍       | 112/456 [02:02<04:49,  1.19it/s]Loading train:  25%|██▍       | 113/456 [02:03<04:48,  1.19it/s]Loading train:  25%|██▌       | 114/456 [02:04<04:43,  1.21it/s]Loading train:  25%|██▌       | 115/456 [02:05<04:58,  1.14it/s]Loading train:  25%|██▌       | 116/456 [02:05<04:52,  1.16it/s]Loading train:  26%|██▌       | 117/456 [02:06<04:31,  1.25it/s]Loading train:  26%|██▌       | 118/456 [02:07<04:21,  1.29it/s]Loading train:  26%|██▌       | 119/456 [02:08<04:21,  1.29it/s]Loading train:  26%|██▋       | 120/456 [02:08<04:15,  1.31it/s]Loading train:  27%|██▋       | 121/456 [02:09<04:36,  1.21it/s]Loading train:  27%|██▋       | 122/456 [02:10<04:29,  1.24it/s]Loading train:  27%|██▋       | 123/456 [02:11<04:26,  1.25it/s]Loading train:  27%|██▋       | 124/456 [02:12<04:37,  1.20it/s]Loading train:  27%|██▋       | 125/456 [02:13<04:38,  1.19it/s]Loading train:  28%|██▊       | 126/456 [02:14<04:48,  1.14it/s]Loading train:  28%|██▊       | 127/456 [02:14<04:46,  1.15it/s]Loading train:  28%|██▊       | 128/456 [02:15<04:25,  1.24it/s]Loading train:  28%|██▊       | 129/456 [02:16<04:07,  1.32it/s]Loading train:  29%|██▊       | 130/456 [02:17<04:13,  1.29it/s]Loading train:  29%|██▊       | 131/456 [02:17<04:14,  1.28it/s]Loading train:  29%|██▉       | 132/456 [02:18<04:12,  1.28it/s]Loading train:  29%|██▉       | 133/456 [02:19<04:36,  1.17it/s]Loading train:  29%|██▉       | 134/456 [02:20<04:57,  1.08it/s]Loading train:  30%|██▉       | 135/456 [02:21<05:21,  1.00s/it]Loading train:  30%|██▉       | 136/456 [02:22<05:22,  1.01s/it]Loading train:  30%|███       | 137/456 [02:23<05:22,  1.01s/it]Loading train:  30%|███       | 138/456 [02:25<05:28,  1.03s/it]Loading train:  30%|███       | 139/456 [02:25<04:58,  1.06it/s]Loading train:  31%|███       | 140/456 [02:26<04:39,  1.13it/s]Loading train:  31%|███       | 141/456 [02:27<04:25,  1.19it/s]Loading train:  31%|███       | 142/456 [02:28<04:15,  1.23it/s]Loading train:  31%|███▏      | 143/456 [02:28<04:12,  1.24it/s]Loading train:  32%|███▏      | 144/456 [02:29<04:01,  1.29it/s]Loading train:  32%|███▏      | 145/456 [02:30<03:52,  1.34it/s]Loading train:  32%|███▏      | 146/456 [02:31<04:01,  1.28it/s]Loading train:  32%|███▏      | 147/456 [02:31<03:54,  1.32it/s]Loading train:  32%|███▏      | 148/456 [02:32<03:46,  1.36it/s]Loading train:  33%|███▎      | 149/456 [02:33<03:42,  1.38it/s]Loading train:  33%|███▎      | 150/456 [02:33<03:36,  1.41it/s]Loading train:  33%|███▎      | 151/456 [02:34<03:45,  1.35it/s]Loading train:  33%|███▎      | 152/456 [02:35<03:45,  1.35it/s]Loading train:  34%|███▎      | 153/456 [02:36<03:43,  1.36it/s]Loading train:  34%|███▍      | 154/456 [02:36<03:45,  1.34it/s]Loading train:  34%|███▍      | 155/456 [02:37<03:51,  1.30it/s]Loading train:  34%|███▍      | 156/456 [02:38<03:47,  1.32it/s]Loading train:  34%|███▍      | 157/456 [02:39<03:42,  1.34it/s]Loading train:  35%|███▍      | 158/456 [02:39<03:38,  1.36it/s]Loading train:  35%|███▍      | 159/456 [02:40<03:32,  1.40it/s]Loading train:  35%|███▌      | 160/456 [02:41<03:34,  1.38it/s]Loading train:  35%|███▌      | 161/456 [02:41<03:31,  1.40it/s]Loading train:  36%|███▌      | 162/456 [02:42<03:27,  1.41it/s]Loading train:  36%|███▌      | 163/456 [02:43<03:18,  1.48it/s]Loading train:  36%|███▌      | 164/456 [02:43<03:10,  1.53it/s]Loading train:  36%|███▌      | 165/456 [02:44<02:59,  1.62it/s]Loading train:  36%|███▋      | 166/456 [02:44<02:53,  1.67it/s]Loading train:  37%|███▋      | 167/456 [02:45<02:56,  1.64it/s]Loading train:  37%|███▋      | 168/456 [02:46<02:58,  1.62it/s]Loading train:  37%|███▋      | 169/456 [02:46<03:00,  1.59it/s]Loading train:  37%|███▋      | 170/456 [02:47<03:01,  1.58it/s]Loading train:  38%|███▊      | 171/456 [02:48<03:00,  1.58it/s]Loading train:  38%|███▊      | 172/456 [02:48<02:56,  1.61it/s]Loading train:  38%|███▊      | 173/456 [02:49<02:55,  1.61it/s]Loading train:  38%|███▊      | 174/456 [02:50<02:56,  1.60it/s]Loading train:  38%|███▊      | 175/456 [02:50<02:53,  1.62it/s]Loading train:  39%|███▊      | 176/456 [02:51<02:53,  1.61it/s]Loading train:  39%|███▉      | 177/456 [02:51<02:46,  1.68it/s]Loading train:  39%|███▉      | 178/456 [02:52<02:47,  1.66it/s]Loading train:  39%|███▉      | 179/456 [02:53<02:51,  1.62it/s]Loading train:  39%|███▉      | 180/456 [02:53<02:55,  1.57it/s]Loading train:  40%|███▉      | 181/456 [02:54<03:22,  1.36it/s]Loading train:  40%|███▉      | 182/456 [02:55<03:37,  1.26it/s]Loading train:  40%|████      | 183/456 [02:56<03:52,  1.18it/s]Loading train:  40%|████      | 184/456 [02:57<03:55,  1.16it/s]Loading train:  41%|████      | 185/456 [02:58<03:54,  1.16it/s]Loading train:  41%|████      | 186/456 [02:59<04:01,  1.12it/s]Loading train:  41%|████      | 187/456 [03:00<04:38,  1.04s/it]Loading train:  41%|████      | 188/456 [03:01<04:44,  1.06s/it]Loading train:  41%|████▏     | 189/456 [03:02<04:43,  1.06s/it]Loading train:  42%|████▏     | 190/456 [03:03<04:36,  1.04s/it]Loading train:  42%|████▏     | 191/456 [03:04<04:34,  1.03s/it]Loading train:  42%|████▏     | 192/456 [03:05<04:32,  1.03s/it]Loading train:  42%|████▏     | 193/456 [03:07<04:37,  1.06s/it]Loading train:  43%|████▎     | 194/456 [03:07<04:26,  1.02s/it]Loading train:  43%|████▎     | 195/456 [03:08<04:26,  1.02s/it]Loading train:  43%|████▎     | 196/456 [03:09<04:23,  1.02s/it]Loading train:  43%|████▎     | 197/456 [03:10<04:20,  1.01s/it]Loading train:  43%|████▎     | 198/456 [03:11<04:16,  1.01it/s]Loading train:  44%|████▎     | 199/456 [03:12<04:09,  1.03it/s]Loading train:  44%|████▍     | 200/456 [03:13<04:06,  1.04it/s]Loading train:  44%|████▍     | 201/456 [03:14<03:57,  1.07it/s]Loading train:  44%|████▍     | 202/456 [03:15<03:49,  1.11it/s]Loading train:  45%|████▍     | 203/456 [03:16<03:53,  1.08it/s]Loading train:  45%|████▍     | 204/456 [03:17<03:58,  1.06it/s]Loading train:  45%|████▍     | 205/456 [03:18<03:43,  1.12it/s]Loading train:  45%|████▌     | 206/456 [03:18<03:30,  1.19it/s]Loading train:  45%|████▌     | 207/456 [03:19<03:24,  1.22it/s]Loading train:  46%|████▌     | 208/456 [03:20<03:14,  1.27it/s]Loading train:  46%|████▌     | 209/456 [03:21<03:11,  1.29it/s]Loading train:  46%|████▌     | 210/456 [03:21<03:04,  1.33it/s]Loading train:  46%|████▋     | 211/456 [03:22<03:12,  1.28it/s]Loading train:  46%|████▋     | 212/456 [03:23<03:12,  1.27it/s]Loading train:  47%|████▋     | 213/456 [03:24<03:16,  1.24it/s]Loading train:  47%|████▋     | 214/456 [03:25<03:13,  1.25it/s]Loading train:  47%|████▋     | 215/456 [03:26<03:19,  1.21it/s]Loading train:  47%|████▋     | 216/456 [03:26<03:26,  1.16it/s]Loading train:  48%|████▊     | 217/456 [03:27<03:28,  1.15it/s]Loading train:  48%|████▊     | 218/456 [03:28<03:26,  1.15it/s]Loading train:  48%|████▊     | 219/456 [03:29<03:19,  1.19it/s]Loading train:  48%|████▊     | 220/456 [03:30<03:19,  1.18it/s]Loading train:  48%|████▊     | 221/456 [03:31<03:21,  1.17it/s]Loading train:  49%|████▊     | 222/456 [03:32<03:24,  1.14it/s]Loading train:  49%|████▉     | 223/456 [03:33<03:22,  1.15it/s]Loading train:  49%|████▉     | 224/456 [03:33<03:15,  1.19it/s]Loading train:  49%|████▉     | 225/456 [03:34<03:12,  1.20it/s]Loading train:  50%|████▉     | 226/456 [03:35<03:04,  1.25it/s]Loading train:  50%|████▉     | 227/456 [03:36<03:04,  1.24it/s]Loading train:  50%|█████     | 228/456 [03:36<03:01,  1.26it/s]Loading train:  50%|█████     | 229/456 [03:37<03:04,  1.23it/s]Loading train:  50%|█████     | 230/456 [03:38<03:01,  1.24it/s]Loading train:  51%|█████     | 231/456 [03:39<03:19,  1.13it/s]Loading train:  51%|█████     | 232/456 [03:40<03:29,  1.07it/s]Loading train:  51%|█████     | 233/456 [03:41<03:41,  1.01it/s]Loading train:  51%|█████▏    | 234/456 [03:42<03:48,  1.03s/it]Loading train:  52%|█████▏    | 235/456 [03:43<03:39,  1.01it/s]Loading train:  52%|█████▏    | 236/456 [03:44<03:41,  1.00s/it]Loading train:  52%|█████▏    | 237/456 [03:45<03:34,  1.02it/s]Loading train:  52%|█████▏    | 238/456 [03:47<03:55,  1.08s/it]Loading train:  52%|█████▏    | 239/456 [03:48<04:00,  1.11s/it]Loading train:  53%|█████▎    | 240/456 [03:49<04:14,  1.18s/it]Loading train:  53%|█████▎    | 241/456 [03:50<04:07,  1.15s/it]Loading train:  53%|█████▎    | 242/456 [03:51<04:06,  1.15s/it]Loading train:  53%|█████▎    | 243/456 [03:53<04:05,  1.15s/it]Loading train:  54%|█████▎    | 244/456 [03:54<04:23,  1.25s/it]Loading train:  54%|█████▎    | 245/456 [03:55<04:17,  1.22s/it]Loading train:  54%|█████▍    | 246/456 [03:56<04:04,  1.16s/it]Loading train:  54%|█████▍    | 247/456 [03:57<03:49,  1.10s/it]Loading train:  54%|█████▍    | 248/456 [03:58<03:34,  1.03s/it]Loading train:  55%|█████▍    | 249/456 [03:59<03:34,  1.04s/it]Loading train:  55%|█████▍    | 250/456 [04:00<03:48,  1.11s/it]Loading train:  55%|█████▌    | 251/456 [04:01<03:35,  1.05s/it]Loading train:  55%|█████▌    | 252/456 [04:02<03:40,  1.08s/it]Loading train:  55%|█████▌    | 253/456 [04:04<03:52,  1.15s/it]Loading train:  56%|█████▌    | 254/456 [04:05<04:07,  1.23s/it]Loading train:  56%|█████▌    | 255/456 [04:06<04:14,  1.26s/it]Loading train:  56%|█████▌    | 256/456 [04:08<04:12,  1.26s/it]Loading train:  56%|█████▋    | 257/456 [04:09<04:15,  1.28s/it]Loading train:  57%|█████▋    | 258/456 [04:10<04:19,  1.31s/it]Loading train:  57%|█████▋    | 259/456 [04:11<04:01,  1.23s/it]Loading train:  57%|█████▋    | 260/456 [04:13<03:49,  1.17s/it]Loading train:  57%|█████▋    | 261/456 [04:13<03:34,  1.10s/it]Loading train:  57%|█████▋    | 262/456 [04:14<03:15,  1.01s/it]Loading train:  58%|█████▊    | 263/456 [04:15<03:04,  1.05it/s]Loading train:  58%|█████▊    | 264/456 [04:16<03:01,  1.06it/s]Loading train:  58%|█████▊    | 265/456 [04:17<03:05,  1.03it/s]Loading train:  58%|█████▊    | 266/456 [04:18<03:05,  1.02it/s]Loading train:  59%|█████▊    | 267/456 [04:19<02:57,  1.06it/s]Loading train:  59%|█████▉    | 268/456 [04:20<02:58,  1.05it/s]Loading train:  59%|█████▉    | 269/456 [04:21<02:59,  1.04it/s]Loading train:  59%|█████▉    | 270/456 [04:22<03:07,  1.01s/it]Loading train:  59%|█████▉    | 271/456 [04:23<03:12,  1.04s/it]Loading train:  60%|█████▉    | 272/456 [04:24<03:20,  1.09s/it]Loading train:  60%|█████▉    | 273/456 [04:25<03:22,  1.11s/it]Loading train:  60%|██████    | 274/456 [04:27<03:24,  1.12s/it]Loading train:  60%|██████    | 275/456 [04:28<03:20,  1.11s/it]Loading train:  61%|██████    | 276/456 [04:29<03:15,  1.09s/it]Loading train:  61%|██████    | 277/456 [04:30<03:12,  1.08s/it]Loading train:  61%|██████    | 278/456 [04:31<03:08,  1.06s/it]Loading train:  61%|██████    | 279/456 [04:32<03:02,  1.03s/it]Loading train:  61%|██████▏   | 280/456 [04:33<02:58,  1.02s/it]Loading train:  62%|██████▏   | 281/456 [04:34<02:56,  1.01s/it]Loading train:  62%|██████▏   | 282/456 [04:35<03:00,  1.04s/it]Loading train:  62%|██████▏   | 283/456 [04:36<02:52,  1.01it/s]Loading train:  62%|██████▏   | 284/456 [04:37<02:49,  1.02it/s]Loading train:  62%|██████▎   | 285/456 [04:37<02:33,  1.11it/s]Loading train:  63%|██████▎   | 286/456 [04:38<02:33,  1.11it/s]Loading train:  63%|██████▎   | 287/456 [04:39<02:42,  1.04it/s]Loading train:  63%|██████▎   | 288/456 [04:40<02:34,  1.09it/s]Loading train:  63%|██████▎   | 289/456 [04:41<02:33,  1.09it/s]Loading train:  64%|██████▎   | 290/456 [04:42<02:30,  1.10it/s]Loading train:  64%|██████▍   | 291/456 [04:43<02:32,  1.08it/s]Loading train:  64%|██████▍   | 292/456 [04:44<02:36,  1.05it/s]Loading train:  64%|██████▍   | 293/456 [04:45<02:27,  1.11it/s]Loading train:  64%|██████▍   | 294/456 [04:46<02:27,  1.09it/s]Loading train:  65%|██████▍   | 295/456 [04:47<02:22,  1.13it/s]Loading train:  65%|██████▍   | 296/456 [04:47<02:19,  1.15it/s]Loading train:  65%|██████▌   | 297/456 [04:48<02:15,  1.17it/s]Loading train:  65%|██████▌   | 298/456 [04:49<02:08,  1.23it/s]Loading train:  66%|██████▌   | 299/456 [04:50<02:12,  1.19it/s]Loading train:  66%|██████▌   | 300/456 [04:51<02:11,  1.19it/s]Loading train:  66%|██████▌   | 301/456 [04:52<02:27,  1.05it/s]Loading train:  66%|██████▌   | 302/456 [04:53<02:43,  1.06s/it]Loading train:  66%|██████▋   | 303/456 [04:54<02:53,  1.13s/it]Loading train:  67%|██████▋   | 304/456 [04:56<02:54,  1.15s/it]Loading train:  67%|██████▋   | 305/456 [04:57<02:52,  1.14s/it]Loading train:  67%|██████▋   | 306/456 [04:58<03:11,  1.27s/it]Loading train:  67%|██████▋   | 307/456 [05:00<03:17,  1.32s/it]Loading train:  68%|██████▊   | 308/456 [05:01<03:19,  1.35s/it]Loading train:  68%|██████▊   | 309/456 [05:02<03:15,  1.33s/it]Loading train:  68%|██████▊   | 310/456 [05:04<03:28,  1.43s/it]Loading train:  68%|██████▊   | 311/456 [05:06<03:24,  1.41s/it]Loading train:  68%|██████▊   | 312/456 [05:07<03:29,  1.45s/it]Loading train:  69%|██████▊   | 313/456 [05:08<03:18,  1.39s/it]Loading train:  69%|██████▉   | 314/456 [05:10<03:09,  1.34s/it]Loading train:  69%|██████▉   | 315/456 [05:11<03:00,  1.28s/it]Loading train:  69%|██████▉   | 316/456 [05:12<02:54,  1.25s/it]Loading train:  70%|██████▉   | 317/456 [05:13<02:53,  1.25s/it]Loading train:  70%|██████▉   | 318/456 [05:14<02:57,  1.29s/it]Loading train:  70%|██████▉   | 319/456 [05:16<03:04,  1.35s/it]Loading train:  70%|███████   | 320/456 [05:17<03:04,  1.36s/it]Loading train:  70%|███████   | 321/456 [05:19<03:01,  1.35s/it]Loading train:  71%|███████   | 322/456 [05:20<02:59,  1.34s/it]Loading train:  71%|███████   | 323/456 [05:21<02:51,  1.29s/it]Loading train:  71%|███████   | 324/456 [05:22<02:43,  1.24s/it]Loading train:  71%|███████▏  | 325/456 [05:23<02:36,  1.19s/it]Loading train:  71%|███████▏  | 326/456 [05:24<02:30,  1.16s/it]Loading train:  72%|███████▏  | 327/456 [05:25<02:23,  1.11s/it]Loading train:  72%|███████▏  | 328/456 [05:27<02:20,  1.10s/it]Loading train:  72%|███████▏  | 329/456 [05:28<02:17,  1.08s/it]Loading train:  72%|███████▏  | 330/456 [05:29<02:17,  1.09s/it]Loading train:  73%|███████▎  | 331/456 [05:30<02:18,  1.11s/it]Loading train:  73%|███████▎  | 332/456 [05:31<02:22,  1.15s/it]Loading train:  73%|███████▎  | 333/456 [05:32<02:21,  1.15s/it]Loading train:  73%|███████▎  | 334/456 [05:34<02:30,  1.23s/it]Loading train:  73%|███████▎  | 335/456 [05:35<02:31,  1.25s/it]Loading train:  74%|███████▎  | 336/456 [05:36<02:30,  1.25s/it]Loading train:  74%|███████▍  | 337/456 [05:37<02:29,  1.26s/it]Loading train:  74%|███████▍  | 338/456 [05:39<02:21,  1.20s/it]Loading train:  74%|███████▍  | 339/456 [05:40<02:16,  1.17s/it]Loading train:  75%|███████▍  | 340/456 [05:41<02:15,  1.17s/it]Loading train:  75%|███████▍  | 341/456 [05:42<02:15,  1.18s/it]Loading train:  75%|███████▌  | 342/456 [05:43<02:11,  1.15s/it]Loading train:  75%|███████▌  | 343/456 [05:44<02:09,  1.14s/it]Loading train:  75%|███████▌  | 344/456 [05:45<02:04,  1.12s/it]Loading train:  76%|███████▌  | 345/456 [05:46<01:59,  1.08s/it]Loading train:  76%|███████▌  | 346/456 [05:47<01:57,  1.06s/it]Loading train:  76%|███████▌  | 347/456 [05:49<02:01,  1.12s/it]Loading train:  76%|███████▋  | 348/456 [05:50<01:59,  1.11s/it]Loading train:  77%|███████▋  | 349/456 [05:51<02:05,  1.18s/it]Loading train:  77%|███████▋  | 350/456 [05:52<02:03,  1.17s/it]Loading train:  77%|███████▋  | 351/456 [05:53<01:58,  1.13s/it]Loading train:  77%|███████▋  | 352/456 [05:54<01:58,  1.14s/it]Loading train:  77%|███████▋  | 353/456 [05:55<01:50,  1.08s/it]Loading train:  78%|███████▊  | 354/456 [05:57<01:55,  1.13s/it]Loading train:  78%|███████▊  | 355/456 [05:58<01:53,  1.12s/it]Loading train:  78%|███████▊  | 356/456 [05:59<01:52,  1.13s/it]Loading train:  78%|███████▊  | 357/456 [06:00<01:47,  1.09s/it]Loading train:  79%|███████▊  | 358/456 [06:01<01:45,  1.08s/it]Loading train:  79%|███████▊  | 359/456 [06:02<01:39,  1.02s/it]Loading train:  79%|███████▉  | 360/456 [06:03<01:40,  1.05s/it]Loading train:  79%|███████▉  | 361/456 [06:04<01:43,  1.09s/it]Loading train:  79%|███████▉  | 362/456 [06:05<01:38,  1.05s/it]Loading train:  80%|███████▉  | 363/456 [06:06<01:36,  1.04s/it]Loading train:  80%|███████▉  | 364/456 [06:07<01:39,  1.08s/it]Loading train:  80%|████████  | 365/456 [06:08<01:38,  1.08s/it]Loading train:  80%|████████  | 366/456 [06:09<01:36,  1.07s/it]Loading train:  80%|████████  | 367/456 [06:10<01:33,  1.05s/it]Loading train:  81%|████████  | 368/456 [06:11<01:26,  1.02it/s]Loading train:  81%|████████  | 369/456 [06:12<01:25,  1.01it/s]Loading train:  81%|████████  | 370/456 [06:13<01:20,  1.07it/s]Loading train:  81%|████████▏ | 371/456 [06:14<01:16,  1.11it/s]Loading train:  82%|████████▏ | 372/456 [06:15<01:23,  1.01it/s]Loading train:  82%|████████▏ | 373/456 [06:16<01:32,  1.11s/it]Loading train:  82%|████████▏ | 374/456 [06:18<01:36,  1.18s/it]Loading train:  82%|████████▏ | 375/456 [06:19<01:36,  1.19s/it]Loading train:  82%|████████▏ | 376/456 [06:20<01:39,  1.24s/it]Loading train:  83%|████████▎ | 377/456 [06:22<01:41,  1.29s/it]Loading train:  83%|████████▎ | 378/456 [06:23<01:40,  1.29s/it]Loading train:  83%|████████▎ | 379/456 [06:24<01:29,  1.16s/it]Loading train:  83%|████████▎ | 380/456 [06:25<01:29,  1.18s/it]Loading train:  84%|████████▎ | 381/456 [06:26<01:25,  1.14s/it]Loading train:  84%|████████▍ | 382/456 [06:27<01:18,  1.06s/it]Loading train:  84%|████████▍ | 383/456 [06:28<01:16,  1.05s/it]Loading train:  84%|████████▍ | 384/456 [06:29<01:14,  1.04s/it]Loading train:  84%|████████▍ | 385/456 [06:30<01:12,  1.02s/it]Loading train:  85%|████████▍ | 386/456 [06:31<01:08,  1.02it/s]Loading train:  85%|████████▍ | 387/456 [06:32<01:05,  1.05it/s]Loading train:  85%|████████▌ | 388/456 [06:33<01:05,  1.04it/s]Loading train:  85%|████████▌ | 389/456 [06:34<01:05,  1.03it/s]Loading train:  86%|████████▌ | 390/456 [06:35<01:02,  1.06it/s]Loading train:  86%|████████▌ | 391/456 [06:36<01:05,  1.01s/it]Loading train:  86%|████████▌ | 392/456 [06:37<01:02,  1.03it/s]Loading train:  86%|████████▌ | 393/456 [06:38<01:03,  1.01s/it]Loading train:  86%|████████▋ | 394/456 [06:39<01:00,  1.03it/s]Loading train:  87%|████████▋ | 395/456 [06:40<01:00,  1.00it/s]Loading train:  87%|████████▋ | 396/456 [06:41<01:04,  1.08s/it]Loading train:  87%|████████▋ | 397/456 [06:42<01:05,  1.11s/it]Loading train:  87%|████████▋ | 398/456 [06:43<01:02,  1.08s/it]Loading train:  88%|████████▊ | 399/456 [06:44<01:00,  1.06s/it]Loading train:  88%|████████▊ | 400/456 [06:45<00:58,  1.04s/it]Loading train:  88%|████████▊ | 401/456 [06:46<00:55,  1.00s/it]Loading train:  88%|████████▊ | 402/456 [06:47<00:52,  1.02it/s]Loading train:  88%|████████▊ | 403/456 [06:48<00:50,  1.05it/s]Loading train:  89%|████████▊ | 404/456 [06:49<00:45,  1.13it/s]Loading train:  89%|████████▉ | 405/456 [06:49<00:45,  1.12it/s]Loading train:  89%|████████▉ | 406/456 [06:51<00:46,  1.07it/s]Loading train:  89%|████████▉ | 407/456 [06:52<00:50,  1.04s/it]Loading train:  89%|████████▉ | 408/456 [06:53<00:48,  1.02s/it]Loading train:  90%|████████▉ | 409/456 [06:54<00:47,  1.00s/it]Loading train:  90%|████████▉ | 410/456 [06:55<00:46,  1.00s/it]Loading train:  90%|█████████ | 411/456 [06:56<00:44,  1.00it/s]Loading train:  90%|█████████ | 412/456 [06:57<00:44,  1.01s/it]Loading train:  91%|█████████ | 413/456 [06:58<00:45,  1.06s/it]Loading train:  91%|█████████ | 414/456 [06:59<00:46,  1.10s/it]Loading train:  91%|█████████ | 415/456 [07:00<00:46,  1.13s/it]Loading train:  91%|█████████ | 416/456 [07:01<00:43,  1.08s/it]Loading train:  91%|█████████▏| 417/456 [07:02<00:41,  1.08s/it]Loading train:  92%|█████████▏| 418/456 [07:03<00:39,  1.03s/it]Loading train:  92%|█████████▏| 419/456 [07:04<00:37,  1.01s/it]Loading train:  92%|█████████▏| 420/456 [07:05<00:35,  1.00it/s]Loading train:  92%|█████████▏| 421/456 [07:07<00:38,  1.10s/it]Loading train:  93%|█████████▎| 422/456 [07:08<00:44,  1.31s/it]Loading train:  93%|█████████▎| 423/456 [07:10<00:44,  1.35s/it]Loading train:  93%|█████████▎| 424/456 [07:11<00:44,  1.40s/it]Loading train:  93%|█████████▎| 425/456 [07:13<00:43,  1.40s/it]Loading train:  93%|█████████▎| 426/456 [07:14<00:41,  1.38s/it]Loading train:  94%|█████████▎| 427/456 [07:15<00:39,  1.36s/it]Loading train:  94%|█████████▍| 428/456 [07:17<00:38,  1.38s/it]Loading train:  94%|█████████▍| 429/456 [07:18<00:37,  1.37s/it]Loading train:  94%|█████████▍| 430/456 [07:19<00:35,  1.35s/it]Loading train:  95%|█████████▍| 431/456 [07:21<00:33,  1.35s/it]Loading train:  95%|█████████▍| 432/456 [07:22<00:31,  1.32s/it]Loading train:  95%|█████████▍| 433/456 [07:24<00:31,  1.37s/it]Loading train:  95%|█████████▌| 434/456 [07:25<00:29,  1.33s/it]Loading train:  95%|█████████▌| 435/456 [07:26<00:28,  1.35s/it]Loading train:  96%|█████████▌| 436/456 [07:27<00:26,  1.32s/it]Loading train:  96%|█████████▌| 437/456 [07:29<00:24,  1.30s/it]Loading train:  96%|█████████▌| 438/456 [07:30<00:22,  1.27s/it]Loading train:  96%|█████████▋| 439/456 [07:31<00:21,  1.27s/it]Loading train:  96%|█████████▋| 440/456 [07:32<00:19,  1.25s/it]Loading train:  97%|█████████▋| 441/456 [07:34<00:18,  1.26s/it]Loading train:  97%|█████████▋| 442/456 [07:35<00:17,  1.25s/it]Loading train:  97%|█████████▋| 443/456 [07:36<00:15,  1.18s/it]Loading train:  97%|█████████▋| 444/456 [07:37<00:14,  1.20s/it]Loading train:  98%|█████████▊| 445/456 [07:38<00:13,  1.20s/it]Loading train:  98%|█████████▊| 446/456 [07:39<00:10,  1.08s/it]Loading train:  98%|█████████▊| 447/456 [07:40<00:08,  1.05it/s]Loading train:  98%|█████████▊| 448/456 [07:40<00:06,  1.18it/s]Loading train:  98%|█████████▊| 449/456 [07:41<00:05,  1.26it/s]Loading train:  99%|█████████▊| 450/456 [07:42<00:04,  1.34it/s]Loading train:  99%|█████████▉| 451/456 [07:43<00:04,  1.23it/s]Loading train:  99%|█████████▉| 452/456 [07:44<00:03,  1.12it/s]Loading train:  99%|█████████▉| 453/456 [07:45<00:02,  1.08it/s]Loading train: 100%|█████████▉| 454/456 [07:46<00:01,  1.05it/s]Loading train: 100%|█████████▉| 455/456 [07:47<00:01,  1.00s/it]Loading train: 100%|██████████| 456/456 [07:48<00:00,  1.01s/it]
concatenating: train:   0%|          | 0/456 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 7/456 [00:00<00:07, 63.52it/s]concatenating: train:   3%|▎         | 13/456 [00:00<00:07, 60.90it/s]concatenating: train:   4%|▍         | 19/456 [00:00<00:07, 58.50it/s]concatenating: train:   5%|▌         | 24/456 [00:00<00:08, 52.84it/s]concatenating: train:   7%|▋         | 33/456 [00:00<00:07, 60.27it/s]concatenating: train:  14%|█▎        | 62/456 [00:00<00:04, 78.91it/s]concatenating: train:  20%|██        | 92/456 [00:00<00:03, 101.23it/s]concatenating: train:  25%|██▌       | 114/456 [00:00<00:02, 120.29it/s]concatenating: train:  29%|██▉       | 133/456 [00:01<00:03, 94.35it/s] concatenating: train:  32%|███▏      | 148/456 [00:01<00:02, 105.38it/s]concatenating: train:  39%|███▉      | 178/456 [00:01<00:02, 130.38it/s]concatenating: train:  45%|████▍     | 205/456 [00:01<00:01, 153.81it/s]concatenating: train:  50%|████▉     | 227/456 [00:01<00:02, 91.56it/s] concatenating: train:  54%|█████▎    | 244/456 [00:02<00:02, 100.17it/s]concatenating: train:  57%|█████▋    | 260/456 [00:02<00:01, 106.52it/s]concatenating: train:  60%|██████    | 275/456 [00:02<00:01, 111.46it/s]concatenating: train:  63%|██████▎   | 289/456 [00:02<00:01, 112.92it/s]concatenating: train:  66%|██████▋   | 303/456 [00:02<00:01, 105.80it/s]concatenating: train:  69%|██████▉   | 316/456 [00:02<00:01, 110.92it/s]concatenating: train:  72%|███████▏  | 329/456 [00:02<00:01, 114.80it/s]concatenating: train:  77%|███████▋  | 350/456 [00:02<00:00, 121.77it/s]concatenating: train:  80%|███████▉  | 363/456 [00:03<00:01, 87.26it/s] concatenating: train:  84%|████████▎ | 381/456 [00:03<00:00, 103.13it/s]concatenating: train:  89%|████████▉ | 405/456 [00:03<00:00, 124.41it/s]concatenating: train:  93%|█████████▎| 422/456 [00:03<00:00, 131.52it/s]concatenating: train:  96%|█████████▌| 438/456 [00:03<00:00, 82.83it/s] concatenating: train: 100%|██████████| 456/456 [00:03<00:00, 115.79it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:01<00:03,  1.28s/it]Loading test:  50%|█████     | 2/4 [00:02<00:02,  1.21s/it]Loading test:  75%|███████▌  | 3/4 [00:03<00:01,  1.24s/it]Loading test: 100%|██████████| 4/4 [00:05<00:00,  1.30s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 65.04it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 88, 56, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 88, 56, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 88, 56, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 88, 56, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 88, 56, 10)   910         activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 88, 56, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 88, 56, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 88, 56, 11)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 44, 28, 11)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 44, 28, 11)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 44, 28, 20)   2000        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 44, 28, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 44, 28, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 44, 28, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 44, 28, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 44, 28, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 44, 28, 31)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 22, 14, 31)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 22, 14, 31)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 22, 14, 40)   11200       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 22, 14, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 14, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 22, 14, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 22, 14, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 22, 14, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 22, 14, 71)   0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 22, 14, 71)   0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 44, 28, 20)   5700        dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 44, 28, 51)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 44, 28, 20)   9200        concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 44, 28, 20)   80          conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 44, 28, 20)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 44, 28, 20)   3620        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 44, 28, 20)   80          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 44, 28, 20)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 44, 28, 71)   0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-07 15:47:15.461566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 15:47:15.461684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 15:47:15.461700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 15:47:15.461709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 15:47:15.462055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 44, 28, 71)   0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 88, 56, 10)   2850        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 88, 56, 21)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 88, 56, 10)   1900        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 88, 56, 10)   40          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 88, 56, 10)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 88, 56, 10)   910         activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 88, 56, 10)   40          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 88, 56, 10)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 88, 56, 31)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 88, 56, 31)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 88, 56, 13)   416         dropout_5[0][0]                  
==================================================================================================
Total params: 57,666
Trainable params: 57,266
Non-trainable params: 400
__________________________________________________________________________________________________
----- /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/model_weights.h5
 --- initialized from Model_3T /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0
------------------------------------------------------------------
class_weights [6.16770687e-02 2.82810291e-02 7.42489031e-02 1.01163433e-02
 2.48563371e-02 6.25843058e-03 7.67474865e-02 1.12146729e-01
 6.37696896e-02 1.30484325e-02 3.54233577e-01 1.74411942e-01
 2.04031629e-04]
Train on 16653 samples, validate on 146 samples
Epoch 1/300
 - 20s - loss: 2.5473 - acc: 0.9413 - mDice: 0.5435 - val_loss: 1.7769 - val_acc: 0.9637 - val_mDice: 0.6354

Epoch 00001: val_mDice improved from -inf to 0.63539, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 14s - loss: 2.2458 - acc: 0.9439 - mDice: 0.5712 - val_loss: 1.7826 - val_acc: 0.9638 - val_mDice: 0.6375

Epoch 00002: val_mDice improved from 0.63539 to 0.63751, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 12s - loss: 2.1607 - acc: 0.9449 - mDice: 0.5818 - val_loss: 1.7657 - val_acc: 0.9640 - val_mDice: 0.6445

Epoch 00003: val_mDice improved from 0.63751 to 0.64447, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 12s - loss: 2.1174 - acc: 0.9456 - mDice: 0.5879 - val_loss: 1.7550 - val_acc: 0.9646 - val_mDice: 0.6500

Epoch 00004: val_mDice improved from 0.64447 to 0.65005, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 12s - loss: 2.0763 - acc: 0.9461 - mDice: 0.5942 - val_loss: 1.7852 - val_acc: 0.9643 - val_mDice: 0.6463

Epoch 00005: val_mDice did not improve from 0.65005
Epoch 6/300
 - 13s - loss: 2.0554 - acc: 0.9464 - mDice: 0.5971 - val_loss: 1.7652 - val_acc: 0.9644 - val_mDice: 0.6479

Epoch 00006: val_mDice did not improve from 0.65005
Epoch 7/300
 - 13s - loss: 2.0300 - acc: 0.9468 - mDice: 0.6012 - val_loss: 1.7194 - val_acc: 0.9649 - val_mDice: 0.6562

Epoch 00007: val_mDice improved from 0.65005 to 0.65620, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 8/300
 - 12s - loss: 2.0088 - acc: 0.9471 - mDice: 0.6045 - val_loss: 1.7513 - val_acc: 0.9649 - val_mDice: 0.6544

Epoch 00008: val_mDice did not improve from 0.65620
Epoch 9/300
 - 12s - loss: 1.9914 - acc: 0.9473 - mDice: 0.6078 - val_loss: 1.7358 - val_acc: 0.9652 - val_mDice: 0.6542

Epoch 00009: val_mDice did not improve from 0.65620
Epoch 10/300
 - 12s - loss: 1.9793 - acc: 0.9476 - mDice: 0.6099 - val_loss: 1.7758 - val_acc: 0.9641 - val_mDice: 0.6511

Epoch 00010: val_mDice did not improve from 0.65620
Epoch 11/300
 - 12s - loss: 1.9655 - acc: 0.9477 - mDice: 0.6117 - val_loss: 1.7233 - val_acc: 0.9646 - val_mDice: 0.6533

Epoch 00011: val_mDice did not improve from 0.65620
Epoch 12/300
 - 13s - loss: 1.9552 - acc: 0.9479 - mDice: 0.6132 - val_loss: 1.7781 - val_acc: 0.9645 - val_mDice: 0.6542

Epoch 00012: val_mDice did not improve from 0.65620
Epoch 13/300
 - 13s - loss: 1.9495 - acc: 0.9480 - mDice: 0.6146 - val_loss: 1.7513 - val_acc: 0.9648 - val_mDice: 0.6560

Epoch 00013: val_mDice did not improve from 0.65620
Epoch 14/300
 - 12s - loss: 1.9404 - acc: 0.9481 - mDice: 0.6161 - val_loss: 1.7646 - val_acc: 0.9642 - val_mDice: 0.6556

Epoch 00014: val_mDice did not improve from 0.65620
Epoch 15/300
 - 12s - loss: 1.9317 - acc: 0.9483 - mDice: 0.6179 - val_loss: 1.7960 - val_acc: 0.9648 - val_mDice: 0.6565

Epoch 00015: val_mDice improved from 0.65620 to 0.65653, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 16/300
 - 12s - loss: 1.9208 - acc: 0.9485 - mDice: 0.6196 - val_loss: 1.7748 - val_acc: 0.9648 - val_mDice: 0.6603

Epoch 00016: val_mDice improved from 0.65653 to 0.66028, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 17/300
 - 12s - loss: 1.9169 - acc: 0.9485 - mDice: 0.6205 - val_loss: 1.7840 - val_acc: 0.9644 - val_mDice: 0.6543

Epoch 00017: val_mDice did not improve from 0.66028
Epoch 18/300
 - 12s - loss: 1.9066 - acc: 0.9486 - mDice: 0.6219 - val_loss: 1.7502 - val_acc: 0.9646 - val_mDice: 0.6533

Epoch 00018: val_mDice did not improve from 0.66028
Epoch 19/300
 - 12s - loss: 1.9033 - acc: 0.9487 - mDice: 0.6228 - val_loss: 1.7901 - val_acc: 0.9641 - val_mDice: 0.6527

Epoch 00019: val_mDice did not improve from 0.66028
Epoch 20/300
 - 13s - loss: 1.9013 - acc: 0.9487 - mDice: 0.6229 - val_loss: 1.8114 - val_acc: 0.9644 - val_mDice: 0.6553

Epoch 00020: val_mDice did not improve from 0.66028
Epoch 21/300
 - 12s - loss: 1.8939 - acc: 0.9489 - mDice: 0.6236 - val_loss: 1.8102 - val_acc: 0.9637 - val_mDice: 0.6542

Epoch 00021: val_mDice did not improve from 0.66028
Epoch 22/300
 - 12s - loss: 1.8898 - acc: 0.9489 - mDice: 0.6245 - val_loss: 1.7831 - val_acc: 0.9649 - val_mDice: 0.6557

Epoch 00022: val_mDice did not improve from 0.66028
Epoch 23/300
 - 13s - loss: 1.8805 - acc: 0.9490 - mDice: 0.6263 - val_loss: 1.7963 - val_acc: 0.9644 - val_mDice: 0.6588

Epoch 00023: val_mDice did not improve from 0.66028
Epoch 24/300
 - 12s - loss: 1.8784 - acc: 0.9491 - mDice: 0.6271 - val_loss: 1.8184 - val_acc: 0.9642 - val_mDice: 0.6561

Epoch 00024: val_mDice did not improve from 0.66028
Epoch 25/300
 - 12s - loss: 1.8726 - acc: 0.9492 - mDice: 0.6282 - val_loss: 1.7815 - val_acc: 0.9648 - val_mDice: 0.6602

Epoch 00025: val_mDice did not improve from 0.66028
Epoch 26/300
 - 12s - loss: 1.8697 - acc: 0.9493 - mDice: 0.6285 - val_loss: 1.8286 - val_acc: 0.9642 - val_mDice: 0.6535

Epoch 00026: val_mDice did not improve from 0.66028
Epoch 27/300
 - 13s - loss: 1.8638 - acc: 0.9493 - mDice: 0.6292 - val_loss: 1.7898 - val_acc: 0.9642 - val_mDice: 0.6590

Epoch 00027: val_mDice did not improve from 0.66028
Epoch 28/300
 - 12s - loss: 1.8576 - acc: 0.9493 - mDice: 0.6303 - val_loss: 1.7461 - val_acc: 0.9648 - val_mDice: 0.6602

Epoch 00028: val_mDice did not improve from 0.66028
Epoch 29/300
 - 12s - loss: 1.8625 - acc: 0.9493 - mDice: 0.6301 - val_loss: 1.7973 - val_acc: 0.9649 - val_mDice: 0.6634

Epoch 00029: val_mDice improved from 0.66028 to 0.66339, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 30/300
 - 12s - loss: 1.8526 - acc: 0.9494 - mDice: 0.6315 - val_loss: 1.7675 - val_acc: 0.9648 - val_mDice: 0.6589

Epoch 00030: val_mDice did not improve from 0.66339
Epoch 31/300
 - 12s - loss: 1.8523 - acc: 0.9495 - mDice: 0.6314 - val_loss: 1.8103 - val_acc: 0.9647 - val_mDice: 0.6576

Epoch 00031: val_mDice did not improve from 0.66339
Epoch 32/300
 - 13s - loss: 1.8445 - acc: 0.9496 - mDice: 0.6326 - val_loss: 1.7894 - val_acc: 0.9644 - val_mDice: 0.6637

Epoch 00032: val_mDice improved from 0.66339 to 0.66373, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 33/300
 - 12s - loss: 1.8402 - acc: 0.9496 - mDice: 0.6334 - val_loss: 1.8024 - val_acc: 0.9648 - val_mDice: 0.6590

Epoch 00033: val_mDice did not improve from 0.66373
Epoch 34/300
 - 12s - loss: 1.8396 - acc: 0.9497 - mDice: 0.6337 - val_loss: 1.7877 - val_acc: 0.9646 - val_mDice: 0.6577

Epoch 00034: val_mDice did not improve from 0.66373
Epoch 35/300
 - 13s - loss: 1.8347 - acc: 0.9497 - mDice: 0.6349 - val_loss: 1.8113 - val_acc: 0.9641 - val_mDice: 0.6583

Epoch 00035: val_mDice did not improve from 0.66373
Epoch 36/300
 - 13s - loss: 1.8348 - acc: 0.9497 - mDice: 0.6348 - val_loss: 1.8225 - val_acc: 0.9643 - val_mDice: 0.6601

Epoch 00036: val_mDice did not improve from 0.66373
Epoch 37/300
 - 12s - loss: 1.8341 - acc: 0.9498 - mDice: 0.6353 - val_loss: 1.7785 - val_acc: 0.9643 - val_mDice: 0.6615

Epoch 00037: val_mDice did not improve from 0.66373
Epoch 38/300
 - 13s - loss: 1.8270 - acc: 0.9498 - mDice: 0.6361 - val_loss: 1.8217 - val_acc: 0.9647 - val_mDice: 0.6640

Epoch 00038: val_mDice improved from 0.66373 to 0.66400, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 39/300
 - 13s - loss: 1.8285 - acc: 0.9499 - mDice: 0.6362 - val_loss: 1.7766 - val_acc: 0.9649 - val_mDice: 0.6653

Epoch 00039: val_mDice improved from 0.66400 to 0.66530, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 40/300
 - 12s - loss: 1.8251 - acc: 0.9499 - mDice: 0.6370 - val_loss: 1.8215 - val_acc: 0.9644 - val_mDice: 0.6659

Epoch 00040: val_mDice improved from 0.66530 to 0.66595, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 41/300
 - 12s - loss: 1.8189 - acc: 0.9500 - mDice: 0.6377 - val_loss: 1.8083 - val_acc: 0.9648 - val_mDice: 0.6621

Epoch 00041: val_mDice did not improve from 0.66595
Epoch 42/300
 - 13s - loss: 1.8194 - acc: 0.9500 - mDice: 0.6377 - val_loss: 1.8604 - val_acc: 0.9643 - val_mDice: 0.6562

Epoch 00042: val_mDice did not improve from 0.66595
Epoch 43/300
 - 12s - loss: 1.8145 - acc: 0.9500 - mDice: 0.6385 - val_loss: 1.8009 - val_acc: 0.9642 - val_mDice: 0.6629

Epoch 00043: val_mDice did not improve from 0.66595
Epoch 44/300
 - 12s - loss: 1.8168 - acc: 0.9500 - mDice: 0.6383 - val_loss: 1.8200 - val_acc: 0.9648 - val_mDice: 0.6623

Epoch 00044: val_mDice did not improve from 0.66595
Epoch 45/300
 - 12s - loss: 1.8135 - acc: 0.9501 - mDice: 0.6390 - val_loss: 1.7834 - val_acc: 0.9647 - val_mDice: 0.6636

Epoch 00045: val_mDice did not improve from 0.66595
Epoch 46/300
 - 12s - loss: 1.8083 - acc: 0.9501 - mDice: 0.6396 - val_loss: 1.8172 - val_acc: 0.9647 - val_mDice: 0.6627

Epoch 00046: val_mDice did not improve from 0.66595
Epoch 47/300
 - 12s - loss: 1.8074 - acc: 0.9502 - mDice: 0.6399 - val_loss: 1.8306 - val_acc: 0.9649 - val_mDice: 0.6625

Epoch 00047: val_mDice did not improve from 0.66595
Epoch 48/300
 - 12s - loss: 1.8017 - acc: 0.9502 - mDice: 0.6410 - val_loss: 1.8076 - val_acc: 0.9645 - val_mDice: 0.6626

Epoch 00048: val_mDice did not improve from 0.66595
Epoch 49/300
 - 13s - loss: 1.8058 - acc: 0.9501 - mDice: 0.6403 - val_loss: 1.8083 - val_acc: 0.9646 - val_mDice: 0.6639

Epoch 00049: val_mDice did not improve from 0.66595
Epoch 50/300
 - 12s - loss: 1.8033 - acc: 0.9502 - mDice: 0.6404 - val_loss: 1.8454 - val_acc: 0.9640 - val_mDice: 0.6631

Epoch 00050: val_mDice did not improve from 0.66595
Epoch 51/300
 - 12s - loss: 1.7979 - acc: 0.9502 - mDice: 0.6419 - val_loss: 1.8180 - val_acc: 0.9645 - val_mDice: 0.6650

Epoch 00051: val_mDice did not improve from 0.66595
Epoch 52/300
 - 12s - loss: 1.7967 - acc: 0.9503 - mDice: 0.6420 - val_loss: 1.8117 - val_acc: 0.9650 - val_mDice: 0.6644

Epoch 00052: val_mDice did not improve from 0.66595
Epoch 53/300
 - 12s - loss: 1.7965 - acc: 0.9502 - mDice: 0.6416 - val_loss: 1.7836 - val_acc: 0.9650 - val_mDice: 0.6651

Epoch 00053: val_mDice did not improve from 0.66595
Epoch 54/300
 - 12s - loss: 1.7952 - acc: 0.9502 - mDice: 0.6419 - val_loss: 1.8563 - val_acc: 0.9639 - val_mDice: 0.6602

Epoch 00054: val_mDice did not improve from 0.66595
Epoch 55/300
 - 12s - loss: 1.7895 - acc: 0.9504 - mDice: 0.6427 - val_loss: 1.8165 - val_acc: 0.9648 - val_mDice: 0.6658

Epoch 00055: val_mDice did not improve from 0.66595
Epoch 56/300
 - 13s - loss: 1.7860 - acc: 0.9504 - mDice: 0.6437 - val_loss: 1.8421 - val_acc: 0.9640 - val_mDice: 0.6582

Epoch 00056: val_mDice did not improve from 0.66595
Epoch 57/300
 - 12s - loss: 1.7892 - acc: 0.9504 - mDice: 0.6432 - val_loss: 1.8133 - val_acc: 0.9644 - val_mDice: 0.6638

Epoch 00057: val_mDice did not improve from 0.66595
Epoch 58/300
 - 12s - loss: 1.7860 - acc: 0.9505 - mDice: 0.6437 - val_loss: 1.8416 - val_acc: 0.9641 - val_mDice: 0.6580

Epoch 00058: val_mDice did not improve from 0.66595
Epoch 59/300
 - 12s - loss: 1.7850 - acc: 0.9505 - mDice: 0.6440 - val_loss: 1.8658 - val_acc: 0.9644 - val_mDice: 0.6585

Epoch 00059: val_mDice did not improve from 0.66595
Epoch 60/300
 - 12s - loss: 1.7791 - acc: 0.9505 - mDice: 0.6447 - val_loss: 1.8113 - val_acc: 0.9646 - val_mDice: 0.6638

Epoch 00060: val_mDice did not improve from 0.66595
Epoch 61/300
 - 13s - loss: 1.7768 - acc: 0.9505 - mDice: 0.6454 - val_loss: 1.8337 - val_acc: 0.9647 - val_mDice: 0.6650

Epoch 00061: val_mDice did not improve from 0.66595
Epoch 62/300
 - 12s - loss: 1.7823 - acc: 0.9505 - mDice: 0.6443 - val_loss: 1.8020 - val_acc: 0.9648 - val_mDice: 0.6635

Epoch 00062: val_mDice did not improve from 0.66595
Epoch 63/300
 - 12s - loss: 1.7798 - acc: 0.9504 - mDice: 0.6447 - val_loss: 1.7855 - val_acc: 0.9645 - val_mDice: 0.6616

Epoch 00063: val_mDice did not improve from 0.66595
Epoch 64/300
 - 12s - loss: 1.7775 - acc: 0.9505 - mDice: 0.6455 - val_loss: 1.8200 - val_acc: 0.9651 - val_mDice: 0.6646

Epoch 00064: val_mDice did not improve from 0.66595
Epoch 65/300
 - 13s - loss: 1.7719 - acc: 0.9506 - mDice: 0.6464 - val_loss: 1.8425 - val_acc: 0.9641 - val_mDice: 0.6620

Epoch 00065: val_mDice did not improve from 0.66595
Epoch 66/300
 - 12s - loss: 1.7759 - acc: 0.9505 - mDice: 0.6454 - val_loss: 1.8401 - val_acc: 0.9647 - val_mDice: 0.6600

Epoch 00066: val_mDice did not improve from 0.66595
Epoch 67/300
 - 12s - loss: 1.7732 - acc: 0.9507 - mDice: 0.6462 - val_loss: 1.8014 - val_acc: 0.9653 - val_mDice: 0.6644

Epoch 00067: val_mDice did not improve from 0.66595
Epoch 68/300
 - 12s - loss: 1.7702 - acc: 0.9506 - mDice: 0.6469 - val_loss: 1.8156 - val_acc: 0.9649 - val_mDice: 0.6650

Epoch 00068: val_mDice did not improve from 0.66595
Epoch 69/300
 - 12s - loss: 1.7727 - acc: 0.9506 - mDice: 0.6462 - val_loss: 1.8117 - val_acc: 0.9646 - val_mDice: 0.6680

Epoch 00069: val_mDice improved from 0.66595 to 0.66801, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 70/300
 - 12s - loss: 1.7676 - acc: 0.9506 - mDice: 0.6473 - val_loss: 1.8604 - val_acc: 0.9647 - val_mDice: 0.6647

Epoch 00070: val_mDice did not improve from 0.66801
Epoch 71/300
 - 12s - loss: 1.7642 - acc: 0.9507 - mDice: 0.6476 - val_loss: 1.8116 - val_acc: 0.9645 - val_mDice: 0.6637

Epoch 00071: val_mDice did not improve from 0.66801
Epoch 72/300
 - 13s - loss: 1.7615 - acc: 0.9508 - mDice: 0.6481 - val_loss: 1.8347 - val_acc: 0.9651 - val_mDice: 0.6687

Epoch 00072: val_mDice improved from 0.66801 to 0.66869, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 73/300
 - 12s - loss: 1.7629 - acc: 0.9508 - mDice: 0.6481 - val_loss: 1.8546 - val_acc: 0.9645 - val_mDice: 0.6640

Epoch 00073: val_mDice did not improve from 0.66869
Epoch 74/300
 - 12s - loss: 1.7654 - acc: 0.9507 - mDice: 0.6474 - val_loss: 1.8566 - val_acc: 0.9643 - val_mDice: 0.6696

Epoch 00074: val_mDice improved from 0.66869 to 0.66961, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 75/300
 - 12s - loss: 1.7625 - acc: 0.9508 - mDice: 0.6480 - val_loss: 1.8452 - val_acc: 0.9648 - val_mDice: 0.6638

Epoch 00075: val_mDice did not improve from 0.66961
Epoch 76/300
 - 12s - loss: 1.7641 - acc: 0.9508 - mDice: 0.6479 - val_loss: 1.8536 - val_acc: 0.9640 - val_mDice: 0.6590

Epoch 00076: val_mDice did not improve from 0.66961
Epoch 77/300
 - 13s - loss: 1.7632 - acc: 0.9507 - mDice: 0.6479 - val_loss: 1.8560 - val_acc: 0.9650 - val_mDice: 0.6684

Epoch 00077: val_mDice did not improve from 0.66961
Epoch 78/300
 - 13s - loss: 1.7573 - acc: 0.9508 - mDice: 0.6491 - val_loss: 1.8260 - val_acc: 0.9643 - val_mDice: 0.6633

Epoch 00078: val_mDice did not improve from 0.66961
Epoch 79/300
 - 12s - loss: 1.7579 - acc: 0.9508 - mDice: 0.6488 - val_loss: 1.8313 - val_acc: 0.9648 - val_mDice: 0.6663

Epoch 00079: val_mDice did not improve from 0.66961
Epoch 80/300
 - 12s - loss: 1.7537 - acc: 0.9508 - mDice: 0.6493 - val_loss: 1.8723 - val_acc: 0.9643 - val_mDice: 0.6598

Epoch 00080: val_mDice did not improve from 0.66961
Epoch 81/300
 - 13s - loss: 1.7564 - acc: 0.9508 - mDice: 0.6492 - val_loss: 1.8185 - val_acc: 0.9650 - val_mDice: 0.6684

Epoch 00081: val_mDice did not improve from 0.66961
Epoch 82/300
 - 13s - loss: 1.7542 - acc: 0.9509 - mDice: 0.6495 - val_loss: 1.7933 - val_acc: 0.9652 - val_mDice: 0.6702

Epoch 00082: val_mDice improved from 0.66961 to 0.67021, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 83/300
 - 12s - loss: 1.7546 - acc: 0.9509 - mDice: 0.6494 - val_loss: 1.8426 - val_acc: 0.9646 - val_mDice: 0.6682

Epoch 00083: val_mDice did not improve from 0.67021
Epoch 84/300
 - 12s - loss: 1.7516 - acc: 0.9509 - mDice: 0.6497 - val_loss: 1.8289 - val_acc: 0.9648 - val_mDice: 0.6668

Epoch 00084: val_mDice did not improve from 0.67021
Epoch 85/300
 - 13s - loss: 1.7572 - acc: 0.9509 - mDice: 0.6489 - val_loss: 1.8208 - val_acc: 0.9653 - val_mDice: 0.6686

Epoch 00085: val_mDice did not improve from 0.67021
Epoch 86/300
 - 12s - loss: 1.7526 - acc: 0.9509 - mDice: 0.6498 - val_loss: 1.8500 - val_acc: 0.9646 - val_mDice: 0.6625

Epoch 00086: val_mDice did not improve from 0.67021
Epoch 87/300
 - 13s - loss: 1.7456 - acc: 0.9510 - mDice: 0.6508 - val_loss: 1.8435 - val_acc: 0.9649 - val_mDice: 0.6688

Epoch 00087: val_mDice did not improve from 0.67021
Epoch 88/300
 - 13s - loss: 1.7503 - acc: 0.9509 - mDice: 0.6501 - val_loss: 1.8481 - val_acc: 0.9648 - val_mDice: 0.6663

Epoch 00088: val_mDice did not improve from 0.67021
Epoch 89/300
 - 12s - loss: 1.7469 - acc: 0.9510 - mDice: 0.6506 - val_loss: 1.8216 - val_acc: 0.9645 - val_mDice: 0.6697

Epoch 00089: val_mDice did not improve from 0.67021
Epoch 90/300
 - 13s - loss: 1.7472 - acc: 0.9510 - mDice: 0.6513 - val_loss: 1.8316 - val_acc: 0.9642 - val_mDice: 0.6639

Epoch 00090: val_mDice did not improve from 0.67021
Epoch 91/300
 - 13s - loss: 1.7444 - acc: 0.9511 - mDice: 0.6514 - val_loss: 1.8130 - val_acc: 0.9648 - val_mDice: 0.6680

Epoch 00091: val_mDice did not improve from 0.67021
Epoch 92/300
 - 12s - loss: 1.7444 - acc: 0.9510 - mDice: 0.6516 - val_loss: 1.8387 - val_acc: 0.9645 - val_mDice: 0.6684

Epoch 00092: val_mDice did not improve from 0.67021
Epoch 93/300
 - 12s - loss: 1.7451 - acc: 0.9510 - mDice: 0.6509 - val_loss: 1.8305 - val_acc: 0.9650 - val_mDice: 0.6651

Epoch 00093: val_mDice did not improve from 0.67021
Epoch 94/300
 - 12s - loss: 1.7405 - acc: 0.9512 - mDice: 0.6522 - val_loss: 1.8812 - val_acc: 0.9648 - val_mDice: 0.6674

Epoch 00094: val_mDice did not improve from 0.67021
Epoch 95/300
 - 13s - loss: 1.7428 - acc: 0.9511 - mDice: 0.6516 - val_loss: 1.8191 - val_acc: 0.9648 - val_mDice: 0.6692

Epoch 00095: val_mDice did not improve from 0.67021
Epoch 96/300
 - 13s - loss: 1.7391 - acc: 0.9511 - mDice: 0.6522 - val_loss: 1.8361 - val_acc: 0.9649 - val_mDice: 0.6679

Epoch 00096: val_mDice did not improve from 0.67021
Epoch 97/300
 - 12s - loss: 1.7394 - acc: 0.9512 - mDice: 0.6522 - val_loss: 1.8221 - val_acc: 0.9648 - val_mDice: 0.6665

Epoch 00097: val_mDice did not improve from 0.67021
Epoch 98/300
 - 12s - loss: 1.7365 - acc: 0.9512 - mDice: 0.6531 - val_loss: 1.8199 - val_acc: 0.9645 - val_mDice: 0.6693

Epoch 00098: val_mDice did not improve from 0.67021
Epoch 99/300
 - 12s - loss: 1.7379 - acc: 0.9511 - mDice: 0.6527 - val_loss: 1.8518 - val_acc: 0.9651 - val_mDice: 0.6713

Epoch 00099: val_mDice improved from 0.67021 to 0.67128, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 100/300
 - 13s - loss: 1.7390 - acc: 0.9512 - mDice: 0.6521 - val_loss: 1.8302 - val_acc: 0.9646 - val_mDice: 0.6728

Epoch 00100: val_mDice improved from 0.67128 to 0.67282, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 101/300
 - 13s - loss: 1.7367 - acc: 0.9512 - mDice: 0.6528 - val_loss: 1.8152 - val_acc: 0.9653 - val_mDice: 0.6724

Epoch 00101: val_mDice did not improve from 0.67282
Epoch 102/300
 - 12s - loss: 1.7354 - acc: 0.9512 - mDice: 0.6533 - val_loss: 1.7881 - val_acc: 0.9654 - val_mDice: 0.6684

Epoch 00102: val_mDice did not improve from 0.67282
Epoch 103/300
 - 12s - loss: 1.7346 - acc: 0.9512 - mDice: 0.6531 - val_loss: 1.8821 - val_acc: 0.9639 - val_mDice: 0.6634

Epoch 00103: val_mDice did not improve from 0.67282
Epoch 104/300
 - 12s - loss: 1.7350 - acc: 0.9512 - mDice: 0.6531 - val_loss: 1.8325 - val_acc: 0.9651 - val_mDice: 0.6677

Epoch 00104: val_mDice did not improve from 0.67282
Epoch 105/300
 - 12s - loss: 1.7328 - acc: 0.9513 - mDice: 0.6538 - val_loss: 1.8049 - val_acc: 0.9652 - val_mDice: 0.6722

Epoch 00105: val_mDice did not improve from 0.67282
Epoch 106/300
 - 12s - loss: 1.7339 - acc: 0.9513 - mDice: 0.6534 - val_loss: 1.8743 - val_acc: 0.9646 - val_mDice: 0.6668

Epoch 00106: val_mDice did not improve from 0.67282
Epoch 107/300
 - 13s - loss: 1.7316 - acc: 0.9514 - mDice: 0.6541 - val_loss: 1.8631 - val_acc: 0.9650 - val_mDice: 0.6726

Epoch 00107: val_mDice did not improve from 0.67282
Epoch 108/300
 - 12s - loss: 1.7314 - acc: 0.9514 - mDice: 0.6537 - val_loss: 1.8484 - val_acc: 0.9641 - val_mDice: 0.6681

Epoch 00108: val_mDice did not improve from 0.67282
Epoch 109/300
 - 12s - loss: 1.7260 - acc: 0.9514 - mDice: 0.6549 - val_loss: 1.8459 - val_acc: 0.9648 - val_mDice: 0.6718

Epoch 00109: val_mDice did not improve from 0.67282
Epoch 110/300
 - 12s - loss: 1.7296 - acc: 0.9513 - mDice: 0.6537 - val_loss: 1.8657 - val_acc: 0.9645 - val_mDice: 0.6630

Epoch 00110: val_mDice did not improve from 0.67282
Epoch 111/300
 - 12s - loss: 1.7335 - acc: 0.9513 - mDice: 0.6534 - val_loss: 1.8082 - val_acc: 0.9654 - val_mDice: 0.6731

Epoch 00111: val_mDice improved from 0.67282 to 0.67307, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 112/300
 - 12s - loss: 1.7295 - acc: 0.9513 - mDice: 0.6544 - val_loss: 1.8303 - val_acc: 0.9648 - val_mDice: 0.6693

Epoch 00112: val_mDice did not improve from 0.67307
Epoch 113/300
 - 12s - loss: 1.7259 - acc: 0.9513 - mDice: 0.6547 - val_loss: 1.8417 - val_acc: 0.9652 - val_mDice: 0.6711

Epoch 00113: val_mDice did not improve from 0.67307
Epoch 114/300
 - 13s - loss: 1.7280 - acc: 0.9514 - mDice: 0.6546 - val_loss: 1.8409 - val_acc: 0.9652 - val_mDice: 0.6693

Epoch 00114: val_mDice did not improve from 0.67307
Epoch 115/300
 - 12s - loss: 1.7278 - acc: 0.9514 - mDice: 0.6545 - val_loss: 1.8265 - val_acc: 0.9648 - val_mDice: 0.6644

Epoch 00115: val_mDice did not improve from 0.67307
Epoch 116/300
 - 12s - loss: 1.7245 - acc: 0.9514 - mDice: 0.6554 - val_loss: 1.8329 - val_acc: 0.9652 - val_mDice: 0.6701

Epoch 00116: val_mDice did not improve from 0.67307
Epoch 117/300
 - 12s - loss: 1.7275 - acc: 0.9514 - mDice: 0.6551 - val_loss: 1.8333 - val_acc: 0.9648 - val_mDice: 0.6717

Epoch 00117: val_mDice did not improve from 0.67307
Epoch 118/300
 - 12s - loss: 1.7254 - acc: 0.9514 - mDice: 0.6552 - val_loss: 1.8432 - val_acc: 0.9648 - val_mDice: 0.6677

Epoch 00118: val_mDice did not improve from 0.67307
Epoch 119/300
 - 12s - loss: 1.7206 - acc: 0.9515 - mDice: 0.6555 - val_loss: 1.8361 - val_acc: 0.9649 - val_mDice: 0.6708

Epoch 00119: val_mDice did not improve from 0.67307
Epoch 120/300
 - 13s - loss: 1.7248 - acc: 0.9514 - mDice: 0.6553 - val_loss: 1.8692 - val_acc: 0.9648 - val_mDice: 0.6671

Epoch 00120: val_mDice did not improve from 0.67307
Epoch 121/300
 - 12s - loss: 1.7259 - acc: 0.9514 - mDice: 0.6548 - val_loss: 1.8367 - val_acc: 0.9647 - val_mDice: 0.6706

Epoch 00121: val_mDice did not improve from 0.67307
Epoch 122/300
 - 12s - loss: 1.7196 - acc: 0.9515 - mDice: 0.6560 - val_loss: 1.8515 - val_acc: 0.9655 - val_mDice: 0.6717

Epoch 00122: val_mDice did not improve from 0.67307
Epoch 123/300
 - 12s - loss: 1.7208 - acc: 0.9515 - mDice: 0.6558 - val_loss: 1.8313 - val_acc: 0.9650 - val_mDice: 0.6710

Epoch 00123: val_mDice did not improve from 0.67307
Epoch 124/300
 - 12s - loss: 1.7195 - acc: 0.9515 - mDice: 0.6560 - val_loss: 1.8503 - val_acc: 0.9652 - val_mDice: 0.6715

Epoch 00124: val_mDice did not improve from 0.67307
Epoch 125/300
 - 12s - loss: 1.7196 - acc: 0.9515 - mDice: 0.6561 - val_loss: 1.8745 - val_acc: 0.9652 - val_mDice: 0.6678

Epoch 00125: val_mDice did not improve from 0.67307
Epoch 126/300
 - 12s - loss: 1.7180 - acc: 0.9515 - mDice: 0.6566 - val_loss: 1.8425 - val_acc: 0.9654 - val_mDice: 0.6719

Epoch 00126: val_mDice did not improve from 0.67307
Epoch 127/300
 - 12s - loss: 1.7214 - acc: 0.9515 - mDice: 0.6560 - val_loss: 1.8473 - val_acc: 0.9653 - val_mDice: 0.6738

Epoch 00127: val_mDice improved from 0.67307 to 0.67378, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 128/300
 - 13s - loss: 1.7115 - acc: 0.9517 - mDice: 0.6580 - val_loss: 1.8383 - val_acc: 0.9649 - val_mDice: 0.6723

Epoch 00128: val_mDice did not improve from 0.67378
Epoch 129/300
 - 12s - loss: 1.7203 - acc: 0.9516 - mDice: 0.6564 - val_loss: 1.8086 - val_acc: 0.9653 - val_mDice: 0.6710

Epoch 00129: val_mDice did not improve from 0.67378
Epoch 130/300
 - 12s - loss: 1.7143 - acc: 0.9517 - mDice: 0.6577 - val_loss: 1.9016 - val_acc: 0.9647 - val_mDice: 0.6637

Epoch 00130: val_mDice did not improve from 0.67378
Epoch 131/300
 - 12s - loss: 1.7159 - acc: 0.9516 - mDice: 0.6569 - val_loss: 1.8199 - val_acc: 0.9650 - val_mDice: 0.6717

Epoch 00131: val_mDice did not improve from 0.67378
Epoch 132/300
 - 12s - loss: 1.7170 - acc: 0.9516 - mDice: 0.6566 - val_loss: 1.8256 - val_acc: 0.9646 - val_mDice: 0.6674

Epoch 00132: val_mDice did not improve from 0.67378
Epoch 133/300
 - 13s - loss: 1.7143 - acc: 0.9516 - mDice: 0.6571 - val_loss: 1.8200 - val_acc: 0.9653 - val_mDice: 0.6704

Epoch 00133: val_mDice did not improve from 0.67378
Epoch 134/300
 - 14s - loss: 1.7108 - acc: 0.9516 - mDice: 0.6576 - val_loss: 1.8095 - val_acc: 0.9654 - val_mDice: 0.6719

Epoch 00134: val_mDice did not improve from 0.67378
Epoch 135/300
 - 13s - loss: 1.7137 - acc: 0.9516 - mDice: 0.6572 - val_loss: 1.8671 - val_acc: 0.9652 - val_mDice: 0.6683

Epoch 00135: val_mDice did not improve from 0.67378
Epoch 136/300
 - 14s - loss: 1.7130 - acc: 0.9516 - mDice: 0.6570 - val_loss: 1.8333 - val_acc: 0.9651 - val_mDice: 0.6710

Epoch 00136: val_mDice did not improve from 0.67378
Epoch 137/300
 - 12s - loss: 1.7137 - acc: 0.9516 - mDice: 0.6575 - val_loss: 1.8566 - val_acc: 0.9652 - val_mDice: 0.6693

Epoch 00137: val_mDice did not improve from 0.67378
Epoch 138/300
 - 13s - loss: 1.7094 - acc: 0.9517 - mDice: 0.6577 - val_loss: 1.8455 - val_acc: 0.9652 - val_mDice: 0.6682

Epoch 00138: val_mDice did not improve from 0.67378
Epoch 139/300
 - 13s - loss: 1.7113 - acc: 0.9517 - mDice: 0.6573 - val_loss: 1.8456 - val_acc: 0.9648 - val_mDice: 0.6677

Epoch 00139: val_mDice did not improve from 0.67378
Epoch 140/300
 - 13s - loss: 1.7104 - acc: 0.9517 - mDice: 0.6581 - val_loss: 1.7911 - val_acc: 0.9654 - val_mDice: 0.6744

Epoch 00140: val_mDice improved from 0.67378 to 0.67440, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 141/300
 - 14s - loss: 1.7065 - acc: 0.9518 - mDice: 0.6586 - val_loss: 1.8566 - val_acc: 0.9652 - val_mDice: 0.6691

Epoch 00141: val_mDice did not improve from 0.67440
Epoch 142/300
 - 13s - loss: 1.7114 - acc: 0.9517 - mDice: 0.6575 - val_loss: 1.8492 - val_acc: 0.9646 - val_mDice: 0.6686

Epoch 00142: val_mDice did not improve from 0.67440
Epoch 143/300
 - 14s - loss: 1.7108 - acc: 0.9517 - mDice: 0.6580 - val_loss: 1.8493 - val_acc: 0.9653 - val_mDice: 0.6723

Epoch 00143: val_mDice did not improve from 0.67440
Epoch 144/300
 - 13s - loss: 1.7123 - acc: 0.9517 - mDice: 0.6580 - val_loss: 1.8024 - val_acc: 0.9654 - val_mDice: 0.6744

Epoch 00144: val_mDice improved from 0.67440 to 0.67443, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 145/300
 - 14s - loss: 1.7095 - acc: 0.9517 - mDice: 0.6579 - val_loss: 1.8405 - val_acc: 0.9657 - val_mDice: 0.6767

Epoch 00145: val_mDice improved from 0.67443 to 0.67666, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 146/300
 - 13s - loss: 1.7077 - acc: 0.9518 - mDice: 0.6585 - val_loss: 1.8823 - val_acc: 0.9646 - val_mDice: 0.6680

Epoch 00146: val_mDice did not improve from 0.67666
Epoch 147/300
 - 14s - loss: 1.7095 - acc: 0.9517 - mDice: 0.6579 - val_loss: 1.8374 - val_acc: 0.9656 - val_mDice: 0.6734

Epoch 00147: val_mDice did not improve from 0.67666
Epoch 148/300
 - 13s - loss: 1.7018 - acc: 0.9518 - mDice: 0.6597 - val_loss: 1.8304 - val_acc: 0.9654 - val_mDice: 0.6722

Epoch 00148: val_mDice did not improve from 0.67666
Epoch 149/300
 - 14s - loss: 1.7030 - acc: 0.9518 - mDice: 0.6591 - val_loss: 1.7974 - val_acc: 0.9656 - val_mDice: 0.6758

Epoch 00149: val_mDice did not improve from 0.67666
Epoch 150/300
 - 13s - loss: 1.7073 - acc: 0.9517 - mDice: 0.6587 - val_loss: 1.8473 - val_acc: 0.9647 - val_mDice: 0.6624

Epoch 00150: val_mDice did not improve from 0.67666
Epoch 151/300
 - 14s - loss: 1.7053 - acc: 0.9518 - mDice: 0.6588 - val_loss: 1.8402 - val_acc: 0.9650 - val_mDice: 0.6729

Epoch 00151: val_mDice did not improve from 0.67666
Epoch 152/300
 - 13s - loss: 1.7052 - acc: 0.9518 - mDice: 0.6589 - val_loss: 1.8607 - val_acc: 0.9655 - val_mDice: 0.6708

Epoch 00152: val_mDice did not improve from 0.67666
Epoch 153/300
 - 14s - loss: 1.7020 - acc: 0.9519 - mDice: 0.6596 - val_loss: 1.8584 - val_acc: 0.9653 - val_mDice: 0.6657

Epoch 00153: val_mDice did not improve from 0.67666
Epoch 154/300
 - 13s - loss: 1.6988 - acc: 0.9519 - mDice: 0.6600 - val_loss: 1.8824 - val_acc: 0.9646 - val_mDice: 0.6699

Epoch 00154: val_mDice did not improve from 0.67666
Epoch 155/300
 - 14s - loss: 1.7041 - acc: 0.9518 - mDice: 0.6594 - val_loss: 1.8421 - val_acc: 0.9650 - val_mDice: 0.6699

Epoch 00155: val_mDice did not improve from 0.67666
Epoch 156/300
 - 13s - loss: 1.7016 - acc: 0.9519 - mDice: 0.6595 - val_loss: 1.8519 - val_acc: 0.9653 - val_mDice: 0.6714

Epoch 00156: val_mDice did not improve from 0.67666
Epoch 157/300
 - 14s - loss: 1.7045 - acc: 0.9518 - mDice: 0.6592 - val_loss: 1.8610 - val_acc: 0.9651 - val_mDice: 0.6688

Epoch 00157: val_mDice did not improve from 0.67666
Epoch 158/300
 - 13s - loss: 1.7034 - acc: 0.9518 - mDice: 0.6593 - val_loss: 1.8808 - val_acc: 0.9649 - val_mDice: 0.6686

Epoch 00158: val_mDice did not improve from 0.67666
Epoch 159/300
 - 14s - loss: 1.6994 - acc: 0.9519 - mDice: 0.6601 - val_loss: 1.8409 - val_acc: 0.9648 - val_mDice: 0.6671

Epoch 00159: val_mDice did not improve from 0.67666
Epoch 160/300
 - 13s - loss: 1.6984 - acc: 0.9519 - mDice: 0.6603 - val_loss: 1.8542 - val_acc: 0.9652 - val_mDice: 0.6717

Epoch 00160: val_mDice did not improve from 0.67666
Epoch 161/300
 - 14s - loss: 1.7003 - acc: 0.9519 - mDice: 0.6596 - val_loss: 1.8700 - val_acc: 0.9650 - val_mDice: 0.6726

Epoch 00161: val_mDice did not improve from 0.67666
Epoch 162/300
 - 13s - loss: 1.6981 - acc: 0.9520 - mDice: 0.6603 - val_loss: 1.9031 - val_acc: 0.9650 - val_mDice: 0.6692

Epoch 00162: val_mDice did not improve from 0.67666
Epoch 163/300
 - 14s - loss: 1.6965 - acc: 0.9519 - mDice: 0.6604 - val_loss: 1.8449 - val_acc: 0.9643 - val_mDice: 0.6664

Epoch 00163: val_mDice did not improve from 0.67666
Epoch 164/300
 - 13s - loss: 1.6998 - acc: 0.9519 - mDice: 0.6600 - val_loss: 1.8619 - val_acc: 0.9651 - val_mDice: 0.6704

Epoch 00164: val_mDice did not improve from 0.67666
Epoch 165/300
 - 14s - loss: 1.6994 - acc: 0.9519 - mDice: 0.6600 - val_loss: 1.8353 - val_acc: 0.9647 - val_mDice: 0.6636

Epoch 00165: val_mDice did not improve from 0.67666
Epoch 166/300
 - 14s - loss: 1.6976 - acc: 0.9519 - mDice: 0.6604 - val_loss: 1.8292 - val_acc: 0.9649 - val_mDice: 0.6666

Epoch 00166: val_mDice did not improve from 0.67666
Epoch 167/300
 - 14s - loss: 1.7008 - acc: 0.9519 - mDice: 0.6600 - val_loss: 1.8628 - val_acc: 0.9651 - val_mDice: 0.6704

Epoch 00167: val_mDice did not improve from 0.67666
Epoch 168/300
 - 14s - loss: 1.6985 - acc: 0.9519 - mDice: 0.6605 - val_loss: 1.8244 - val_acc: 0.9648 - val_mDice: 0.6754

Epoch 00168: val_mDice did not improve from 0.67666
Epoch 169/300
 - 13s - loss: 1.6966 - acc: 0.9519 - mDice: 0.6604 - val_loss: 1.8628 - val_acc: 0.9649 - val_mDice: 0.6700

Epoch 00169: val_mDice did not improve from 0.67666
Epoch 170/300
 - 14s - loss: 1.6991 - acc: 0.9519 - mDice: 0.6606 - val_loss: 1.8243 - val_acc: 0.9656 - val_mDice: 0.6734

Epoch 00170: val_mDice did not improve from 0.67666
Epoch 171/300
 - 14s - loss: 1.6935 - acc: 0.9520 - mDice: 0.6610 - val_loss: 1.8921 - val_acc: 0.9653 - val_mDice: 0.6684

Epoch 00171: val_mDice did not improve from 0.67666
Epoch 172/300
 - 14s - loss: 1.6930 - acc: 0.9520 - mDice: 0.6615 - val_loss: 1.8580 - val_acc: 0.9650 - val_mDice: 0.6692

Epoch 00172: val_mDice did not improve from 0.67666
Epoch 173/300
 - 13s - loss: 1.6938 - acc: 0.9520 - mDice: 0.6610 - val_loss: 1.8575 - val_acc: 0.9645 - val_mDice: 0.6697

Epoch 00173: val_mDice did not improve from 0.67666
Epoch 174/300
 - 14s - loss: 1.6915 - acc: 0.9520 - mDice: 0.6616 - val_loss: 1.8586 - val_acc: 0.9653 - val_mDice: 0.6755

Epoch 00174: val_mDice did not improve from 0.67666
Epoch 175/300
 - 14s - loss: 1.6906 - acc: 0.9521 - mDice: 0.6616 - val_loss: 1.8527 - val_acc: 0.9649 - val_mDice: 0.6720

Epoch 00175: val_mDice did not improve from 0.67666
Restoring model weights from the end of the best epoch
Epoch 00175: early stopping
{'val_loss': [1.776881698059709, 1.7826455782537591, 1.7656634392803663, 1.7549555481296697, 1.7852007052669787, 1.7652143729876166, 1.719417488738282, 1.751332900295519, 1.7357775952718029, 1.7758097599630487, 1.7233031710533246, 1.7780997671493113, 1.7513026978871593, 1.7645766669756746, 1.7959935256879624, 1.774792251521594, 1.784006605409596, 1.7501994910305494, 1.790119576127562, 1.8113568057752636, 1.8102091599817145, 1.7830635113258884, 1.7962800460318997, 1.8184060282903174, 1.7815124678285155, 1.8285949442484608, 1.789754289470307, 1.7461261928898015, 1.7973286827949628, 1.767502528347381, 1.8102646690525421, 1.7893865288120427, 1.802383447346622, 1.787732524414585, 1.8113270540759987, 1.822468589429986, 1.7785394665313095, 1.821715968928925, 1.776604765082059, 1.821505753961328, 1.8082688018067243, 1.8603938311746675, 1.8009122120190972, 1.8199822690388927, 1.7833862402667737, 1.817246085976901, 1.830601452148124, 1.807597864164065, 1.8082783646779517, 1.8453705800722724, 1.8180183825427538, 1.8117234086337155, 1.7835876451779717, 1.8562596448480266, 1.8164655149799505, 1.842074603250582, 1.8133146648537624, 1.841648573744787, 1.8657712446500176, 1.811310399068545, 1.8337065683652276, 1.8020287899121845, 1.7854636956567633, 1.819969061302812, 1.8425472729826626, 1.8400607468330696, 1.8013856966201574, 1.8156067933121773, 1.811746896129765, 1.8603589877690354, 1.811604566770057, 1.834670847409392, 1.85463791840697, 1.8566058612849614, 1.845183016502694, 1.85361928809179, 1.8560220688989717, 1.8260468995734438, 1.8313373408905447, 1.8723441819622093, 1.8184854053471187, 1.793339631328844, 1.8425583806756425, 1.8289153592227256, 1.8207639504785407, 1.8500236060521373, 1.8435347602791983, 1.848088599231145, 1.8216455195048085, 1.8315558400872636, 1.8130418437800995, 1.8387431396196967, 1.8305237407553685, 1.881216490105407, 1.8191226965760532, 1.8360636283273566, 1.8221256079739088, 1.8198543231781215, 1.8517775045682305, 1.8301666060539141, 1.8152315763578022, 1.7881021744584384, 1.8821469153443429, 1.8324729628758887, 1.80488617616157, 1.8743023104863623, 1.8630756907267114, 1.8484304473824698, 1.8459257981548571, 1.8657291098816755, 1.8081828878350454, 1.8302945453826696, 1.841672082469888, 1.8408825887392646, 1.8264786021350181, 1.8329400754954717, 1.8332544401900408, 1.8431899384276507, 1.8361428927068841, 1.8691897604563465, 1.836735576799471, 1.8514843885212728, 1.831330763150568, 1.850314092962709, 1.874529632803512, 1.8425483050411695, 1.8473400187818971, 1.838316167870613, 1.8086235588544035, 1.9016353610443741, 1.8198584938702518, 1.8255603215465808, 1.8200080198784396, 1.80950265714567, 1.8671113154659533, 1.8333238689866784, 1.8565990189983421, 1.8455162505580955, 1.8455614651719185, 1.7910934409050092, 1.8565582379902879, 1.8492211381050006, 1.8492674451984772, 1.8024078689209402, 1.8404844966653275, 1.882261820035438, 1.8374086455123064, 1.8303835555298689, 1.7973954644921708, 1.8472713444330922, 1.8401655089365292, 1.8606887043338933, 1.858386898693973, 1.8823704948164013, 1.8421464080679906, 1.851858916347974, 1.8609768838098604, 1.8807699810968685, 1.8409184086812687, 1.8541738480737764, 1.8699643350627324, 1.9031280426129902, 1.8448922634124756, 1.8619121623365846, 1.8352630562978247, 1.8292061972291502, 1.862817401755346, 1.8244185529343069, 1.8628454208374023, 1.824321111587629, 1.8920783392370564, 1.8579694114319265, 1.8574591221874708, 1.8585727459763828, 1.8526747422675565], 'val_acc': [0.9636908647132246, 0.963758940566076, 0.9640369398953164, 0.9645609267770427, 0.9642634816365699, 0.9643969192896804, 0.9648917105099927, 0.9648514136876145, 0.965248898284076, 0.964141161474463, 0.9646331716890204, 0.964471945207413, 0.964779111620498, 0.964193971189734, 0.9648444423936817, 0.9647763477612848, 0.9644413998682205, 0.9646081736643021, 0.9641342138590878, 0.9643677211787602, 0.9637269728804287, 0.9648611063826574, 0.9643732513466926, 0.9641522756994587, 0.9647513423880486, 0.9641773023017465, 0.9641800596289438, 0.9648041414887938, 0.9649027928914109, 0.96475409318323, 0.9646859928353192, 0.9644385853858843, 0.9648402733345555, 0.9646039939906499, 0.9641092084858516, 0.9643107293403312, 0.9643135274926277, 0.9646859854868014, 0.9649111571377271, 0.9643704981020053, 0.964847207069397, 0.964301005618213, 0.9642357001565907, 0.96478466220098, 0.9647499298396176, 0.964726307620741, 0.9648527600993849, 0.9645470021522209, 0.9645762141436747, 0.9639576926623306, 0.9645442301279878, 0.9650487434374143, 0.9650028682734868, 0.9638826479650524, 0.964758285104412, 0.9639563258380106, 0.9643649295584796, 0.9640980738483064, 0.9643760372514594, 0.9645817500271209, 0.9646971291058684, 0.96475409318323, 0.9645372800631066, 0.9651349423682853, 0.9641147647818474, 0.9646832371411258, 0.965316991283469, 0.9649153057843038, 0.9646443038770597, 0.9647151819647175, 0.9644858698322348, 0.9650821171394767, 0.9645400627018654, 0.9643399241852434, 0.9648472029868871, 0.9639952305245073, 0.9649667315287133, 0.9643135095295841, 0.964766604443119, 0.9642634922510958, 0.9649848105156258, 0.9651738699168375, 0.964613723428282, 0.964831920519267, 0.9652558369179295, 0.9646234798104796, 0.9648889139907001, 0.964834698259014, 0.9645470184822605, 0.964232914251824, 0.9648069126965249, 0.9644636258687058, 0.9650487769139956, 0.9648277808542121, 0.9648458230985354, 0.964895876303111, 0.9647749343963519, 0.9645317262166166, 0.96511826204927, 0.9646443095925736, 0.9652878111355925, 0.9653795418673998, 0.9639020962257908, 0.9650849054937494, 0.9652155368295434, 0.9645914761987451, 0.96504321245298, 0.9640925118367966, 0.9648389065102355, 0.964520610358617, 0.9654101353802093, 0.9648027616004421, 0.9652099976800892, 0.9652391590484201, 0.9647944349132173, 0.9652210792450056, 0.9647777268331345, 0.9647777203011186, 0.9649348030351612, 0.9647971799928848, 0.9647346473719975, 0.9654601747042513, 0.9649806471720134, 0.9652197042556658, 0.9651960665232515, 0.9654212267431495, 0.9652697574602415, 0.964891696629459, 0.9652961721159008, 0.964660987462083, 0.9649862295960727, 0.9646012268654288, 0.965280877400751, 0.9654073339619048, 0.9652141438771601, 0.9650710159785127, 0.9651919097116549, 0.9651752334751494, 0.9647624272189729, 0.9653767526966252, 0.9652071897297689, 0.9646095666166854, 0.9652628090283643, 0.9653962172874032, 0.9657353677161752, 0.9646137356758118, 0.9656283349207003, 0.9654365337058289, 0.9656478052269922, 0.9647374340932663, 0.964963970119006, 0.965460186135279, 0.9652864083851853, 0.9646151302611992, 0.9649667601062827, 0.9652641889167158, 0.9651488114709723, 0.9648903273556331, 0.9648472389129743, 0.9651655301655808, 0.9649820229778551, 0.9650181703371544, 0.964295453404727, 0.9650793459317456, 0.964736035425369, 0.9649459074621332, 0.9651404815177395, 0.9648055181111375, 0.9648916868314351, 0.9655713463482791, 0.9653281308200261, 0.9649570208706267, 0.9644719558219387, 0.9653100616311374, 0.964905609006751], 'val_mDice': [0.6353861852867962, 0.6375074288616441, 0.6444724177661008, 0.650045539418312, 0.646284770475675, 0.6479114841108453, 0.6561983464515373, 0.6544135286383432, 0.6541501528596225, 0.6510638839577976, 0.6532725054923803, 0.6542391858688773, 0.6559935301950534, 0.6555790672563526, 0.6565258870386097, 0.6602770400373903, 0.6542696724199268, 0.6533150852543034, 0.652734202881382, 0.6553310735584938, 0.6541565852622463, 0.655701607873995, 0.6588216693433997, 0.6561303481663743, 0.660185647337404, 0.6535168682059197, 0.65898188009654, 0.6602114986066949, 0.6633898142265947, 0.6589120193703534, 0.6575818143478812, 0.6637257549860706, 0.6590265492870383, 0.6576874917500639, 0.6583395461513571, 0.6600747451390305, 0.6615425511582257, 0.6640018404346623, 0.6653039226793263, 0.6659490261992363, 0.6621193110126339, 0.6562499689729246, 0.6629146753925167, 0.6623479838240637, 0.6636342741038701, 0.6626513951445279, 0.6625088477787906, 0.6625781304215732, 0.6639331579208374, 0.6631366014480591, 0.6650268729418924, 0.664362123567764, 0.6651391386985779, 0.6601611865709905, 0.6658446494847128, 0.6582131271492945, 0.6638042224596624, 0.6579616200434019, 0.6585128911553997, 0.6637935009721208, 0.6650004705337629, 0.6634544297440411, 0.6616168250776318, 0.664630895608092, 0.6619922592215342, 0.6600127220153809, 0.6644248978732383, 0.6650305325037813, 0.668008465472966, 0.6647147813888445, 0.6636567491374604, 0.6686903499577144, 0.6639820173995136, 0.6696060618309125, 0.6637886885094316, 0.6590015724913715, 0.6684074238555072, 0.6632595454176812, 0.6662957423353848, 0.6597907061446203, 0.6684107339545472, 0.6702072228470893, 0.6681877227678691, 0.6668311904554498, 0.6685880242961727, 0.6625305299889551, 0.6687850715362862, 0.666325665500066, 0.6697187725811788, 0.6638616127510594, 0.667958039943486, 0.6684421684643994, 0.6650779802505284, 0.6673737576563065, 0.6691631731921679, 0.6679250818409331, 0.6664832307867807, 0.6693054992858678, 0.6712807302605616, 0.6728153816641194, 0.6724152352711926, 0.6684243842347027, 0.663407662959948, 0.667660164506468, 0.6722293765577552, 0.6668068521643338, 0.6725604509654111, 0.6680700093099515, 0.6718100423682226, 0.6629746188856152, 0.6730731986973384, 0.669311181323169, 0.6711206975048536, 0.6692894566549014, 0.6644164715727715, 0.6701313681798439, 0.6717077583482821, 0.6676978452564919, 0.6708460531822623, 0.6670655003965718, 0.6706223128593132, 0.6716862623005697, 0.6710205127115119, 0.6715219959820786, 0.6677700852694577, 0.6718558122033942, 0.6737795210864446, 0.6723138126608443, 0.6710170654401387, 0.6637437188462035, 0.6716664637604804, 0.6674154147709885, 0.6704093291334909, 0.6719401617572732, 0.668253919033155, 0.6709882151590635, 0.6692646986817661, 0.6681733098748612, 0.6677171204188098, 0.6743974546863608, 0.6691314112650205, 0.6686041314307958, 0.672255814891972, 0.6744285095227908, 0.6766585405558756, 0.6680400943102902, 0.6733571895181316, 0.6721965891041167, 0.6757525205612183, 0.6623533947827065, 0.6729233166942857, 0.6707853176822401, 0.6656819704460771, 0.6699261959284952, 0.6699373428135702, 0.6713641392041559, 0.6688107154140733, 0.6685756738871744, 0.6670607450890215, 0.6717447140445448, 0.6726483637339449, 0.6691985905986942, 0.6663914918899536, 0.6704084693569027, 0.6635904655064622, 0.6665798050083526, 0.6704312260836771, 0.6753909767490544, 0.6700494501688709, 0.6733950205045204, 0.6683878425049455, 0.6691661346448611, 0.669685135148976, 0.6755130241994989, 0.6719838184853123], 'loss': [2.547267128588995, 2.245774725031396, 2.160720679650169, 2.1173765343717217, 2.076302233625946, 2.055415291568005, 2.0300285215528993, 2.0088436890956998, 1.991411351487564, 1.9793234373981556, 1.965457381632624, 1.955156927651946, 1.9495035647587153, 1.9404034264587477, 1.9316625168736845, 1.9207622086021812, 1.9169369836773578, 1.906553780911585, 1.9032651655152704, 1.9012786846493612, 1.8938733206878788, 1.8898009442140595, 1.880459169042094, 1.878374429062051, 1.872619837803475, 1.869687682636105, 1.8637557796606437, 1.8576033555415488, 1.8625451646924613, 1.8526476368434235, 1.8522577751780218, 1.8445187403920504, 1.8402414514174772, 1.8396442012801755, 1.8346507077473946, 1.834787061971379, 1.8340999460618346, 1.8269771455658999, 1.828533106180796, 1.825073880776481, 1.8188972563627053, 1.8194299047217888, 1.8145442379206027, 1.8167871533517959, 1.8134863556830838, 1.8083281843274133, 1.8073814697740371, 1.8016651039910103, 1.8058229562062684, 1.8033271029225586, 1.797888003243617, 1.7966880340701588, 1.7964662978085484, 1.7951778349472383, 1.7894774405496554, 1.785962997610731, 1.7891782445606366, 1.7860388746850306, 1.7850280574747788, 1.7791206914655713, 1.776818245293206, 1.7822745620384737, 1.7798177318401769, 1.7774581869307247, 1.7719362023849856, 1.7759064853796263, 1.7732119099274775, 1.77021653526346, 1.7727196973229016, 1.7676343027696246, 1.764246175756313, 1.7614963019330143, 1.7629264190391272, 1.7654081196682752, 1.762503619749668, 1.7641369595023981, 1.763199177109314, 1.7573198458851045, 1.7578662644168217, 1.7536928189815162, 1.7564134948040167, 1.7542449504929836, 1.7545779932406416, 1.7516287350478505, 1.757244667713115, 1.752602411191227, 1.7455654010854025, 1.7502593692269746, 1.7469002621915328, 1.7471607819352573, 1.7443700981828778, 1.7443633025518475, 1.7450609976899005, 1.7405164289788027, 1.742772412176269, 1.7390799671581527, 1.7393739191768391, 1.7364567573210974, 1.7378592946569047, 1.7390089880945532, 1.7367344586682993, 1.7354014205093649, 1.734645023085667, 1.73502342091275, 1.7328079839457995, 1.733947995875409, 1.7315813085735505, 1.7314199645555193, 1.7260345691447143, 1.7296188582581156, 1.733474487192615, 1.7294771201702337, 1.7259262297480327, 1.7280318485303934, 1.7278091706421, 1.7245437967944044, 1.7274500523638325, 1.72535196990929, 1.720555547364215, 1.7248243494362527, 1.725932077610449, 1.7196432807377808, 1.720819977699497, 1.7194658472667848, 1.7195990228484015, 1.7180229062712788, 1.7214035566079469, 1.7115076834293756, 1.7202844183265873, 1.7143348184446812, 1.7159015459856286, 1.7170228214798793, 1.7143198115141451, 1.7107686533452884, 1.7137423935419287, 1.7130426049504504, 1.7136789251861362, 1.7093853450734888, 1.711313015847838, 1.7103628297543043, 1.706466216343212, 1.7113814262672924, 1.7108236235204433, 1.712253721191426, 1.709545199014772, 1.7076903704565252, 1.7094646688839956, 1.7017786638526124, 1.7029903168428597, 1.7072705212945387, 1.7053203545253512, 1.705150023413257, 1.701993880100539, 1.698778406926435, 1.7040892959585965, 1.70156022630525, 1.7045216847595663, 1.703371473177055, 1.699382498182993, 1.6983976334678814, 1.700301300453537, 1.6980989295276787, 1.696514194071676, 1.699785124093772, 1.6993749064847399, 1.697627233186871, 1.700821549231846, 1.6984657503596041, 1.696649882397279, 1.6991464954048765, 1.6935027704177044, 1.6930225832229089, 1.6938429910528303, 1.6915065563348566, 1.6905660979247972], 'acc': [0.9413170882340258, 0.9439294980730959, 0.944949676824004, 0.9455600512004118, 0.9460910394700992, 0.9463919902151356, 0.9467828449977881, 0.9470907190014548, 0.9473469046109547, 0.9475905636205463, 0.9476988406494302, 0.947870106408741, 0.9479722574667294, 0.9481165307724805, 0.9482752820009914, 0.948457780370682, 0.9485047200037783, 0.9486213922071105, 0.9486697678600912, 0.9487481916594318, 0.9488944682904294, 0.9488582759907688, 0.9490178400229056, 0.9490705915831134, 0.9491739710164859, 0.9492610144427622, 0.9493006390543991, 0.9493357322276594, 0.9493002231533532, 0.9494132194828001, 0.9495010014046479, 0.9495716148408363, 0.9496173850052465, 0.949703862622272, 0.9496850116306015, 0.9497169998861366, 0.9497884800289083, 0.949840387488846, 0.9498573975262968, 0.9498711670117214, 0.9499743995255324, 0.9499787145574937, 0.9499946319576584, 0.9500243968557883, 0.9500743686018251, 0.9500787802546589, 0.950166990665647, 0.9501864862235854, 0.950135125162823, 0.9501552673307602, 0.9502132832413428, 0.9502668970520128, 0.9502235809360647, 0.950212941476549, 0.9503615535623439, 0.9503554857071402, 0.9503869231216959, 0.9504716948425491, 0.9504742793390316, 0.9504817741945013, 0.9505115053764386, 0.9504540522900429, 0.9504457639372257, 0.9504781548686123, 0.9506040018528121, 0.950523995908611, 0.9506750566167802, 0.9506453252093524, 0.9506447888212376, 0.9506268882181654, 0.9507107986799985, 0.9507949998061922, 0.9507559884570207, 0.9507051536874113, 0.9507796306986068, 0.9507844296116188, 0.9506884959734346, 0.9507841272575465, 0.950767995369425, 0.9508288588880641, 0.9508076336643957, 0.9508851292770002, 0.9509053100825487, 0.9508750278985673, 0.9508979591758933, 0.9509226744478332, 0.9510319785607052, 0.9509094513794799, 0.9509672986661494, 0.9510158469732378, 0.9510548101640898, 0.9510085809118417, 0.9510116511577243, 0.9511896888107206, 0.9511064204490772, 0.9510996535591325, 0.9511629701670044, 0.9511790148941152, 0.9511035638428776, 0.9511652113954233, 0.9512178624262575, 0.9511911040496906, 0.9512423428803072, 0.9512363233838591, 0.9512844203843202, 0.9512947541861493, 0.9513930651523512, 0.9514054951027536, 0.9513889695333445, 0.9513304904403038, 0.9512687612351574, 0.9513478562229568, 0.9513482475061714, 0.9514219082991712, 0.9513882637875779, 0.9514428029395092, 0.9513921498722596, 0.9513993524527224, 0.9514706353128175, 0.9513881057581371, 0.9513951364754987, 0.9514943836315584, 0.9514701615609414, 0.9515233271359496, 0.9515220579575299, 0.9515467464676893, 0.9514994656424733, 0.9516654418573246, 0.9515886029302054, 0.9516719497482118, 0.9515842159739458, 0.9515952302451349, 0.9515991780461974, 0.9516149214464702, 0.951628790047479, 0.9516393902788132, 0.9516470953450793, 0.9516748992242677, 0.9516664314096785, 0.9517213500548947, 0.951753054546793, 0.9516646986085574, 0.9516922497344161, 0.951724054938228, 0.9517373565309493, 0.9517548462080825, 0.9516737412770704, 0.951829079575047, 0.9517669336456355, 0.9517466209210097, 0.9517983952055663, 0.951816660938539, 0.9518668409697553, 0.9519143771933398, 0.9518208192725272, 0.9518694496330883, 0.9517911692599967, 0.9518026743666486, 0.951852658554032, 0.9518634192486722, 0.9518565831832655, 0.9519587542311619, 0.9519289739280966, 0.9519465701619991, 0.9518989979852136, 0.9519031307600371, 0.9518545456478948, 0.951905750311338, 0.9519257934961219, 0.9519400856004265, 0.9519936420577773, 0.952038373724087, 0.952002719720262, 0.9520171236857304, 0.9521068088759075], 'mDice': [0.543523596634931, 0.5712454838057807, 0.581758632671652, 0.5879303719527383, 0.5942276221370222, 0.5971216331378394, 0.6012196280194182, 0.604510964953147, 0.6078013379581123, 0.6098555353771192, 0.6117074160735356, 0.6132399508496816, 0.6145917062772858, 0.6161405417014764, 0.617911157748051, 0.6195758519491648, 0.6205356470072355, 0.6219389066569893, 0.6227663872242404, 0.6229071734954178, 0.6235995283250242, 0.6245412386080055, 0.6262882757686548, 0.6271358875800831, 0.6281996761643692, 0.6285235269903056, 0.6292195562227405, 0.6302956388582662, 0.630074679568774, 0.6314903464659781, 0.6314188098145814, 0.6326302368061211, 0.633419469076757, 0.6336721322675771, 0.6348768752387055, 0.6347969092313702, 0.6352773298338455, 0.6361366004218842, 0.6361845091592869, 0.6369711306119032, 0.6376873923623654, 0.6376841182301569, 0.638539616810211, 0.638275751532545, 0.6390417480135168, 0.6395558611534741, 0.6398804361760233, 0.6410470554608594, 0.640318003079057, 0.6404069402601127, 0.6418828832876258, 0.6420275442723232, 0.641648344261141, 0.6418889319152937, 0.6426839571611048, 0.6436957355333879, 0.643191887746378, 0.6437082992318457, 0.6439622596585414, 0.6446645227501087, 0.6453986355243757, 0.6443445781813021, 0.6447136504424053, 0.6455133705033788, 0.6464378794614155, 0.6454195029412148, 0.6461821619343172, 0.6468520953670562, 0.646166836321336, 0.6472545119475254, 0.6476455716365795, 0.648107257224644, 0.648108672681946, 0.6473627380656743, 0.6479889612215629, 0.6478938721811593, 0.6479204545534746, 0.6490803753113464, 0.64883941840046, 0.6493381251624802, 0.649225007884246, 0.6494911863432627, 0.6493711277564238, 0.6497365171784919, 0.6488775885485245, 0.6497975972395562, 0.6508181007432556, 0.6501488855083676, 0.6506197726712931, 0.6513009076897879, 0.6514332600558462, 0.651586632452834, 0.6509220458928195, 0.6522377639828176, 0.6516194776973875, 0.6522176954965724, 0.6522463789746717, 0.6530860672446334, 0.6527065042689749, 0.6521330731327252, 0.6528416587047546, 0.6532764832894594, 0.6531477744805665, 0.6531129346297309, 0.6537933351685319, 0.6533813306585644, 0.6540789237174445, 0.6536585323045914, 0.6548837650461483, 0.6537433889601844, 0.6533878704975126, 0.6544105136157556, 0.6546656479243079, 0.6546184054288908, 0.6544906635803553, 0.6553642153775722, 0.6550865844836115, 0.6551669165442844, 0.6555481441513609, 0.6552806186767653, 0.6547914505191001, 0.656042144125749, 0.6558411263176853, 0.6559876397959873, 0.6561216367856594, 0.6565874958298897, 0.6560288488503399, 0.6579653350381903, 0.656420431594938, 0.6576556123993114, 0.6568666481724059, 0.6565702673601888, 0.6571447461537467, 0.6576136235416826, 0.6572421238901006, 0.6570085175494235, 0.6575479586582703, 0.6577297398537649, 0.65733563285085, 0.658127780140452, 0.6586189536241442, 0.6575310092455402, 0.658014579384218, 0.657971538445373, 0.6579011612444434, 0.6584648726681278, 0.657902612748006, 0.6596665618112264, 0.6591123836373937, 0.6587466274031947, 0.658783530123075, 0.6588594443173994, 0.6595791689749559, 0.659975818246791, 0.6593921474205555, 0.659470856075193, 0.6592363857087635, 0.6592806230176642, 0.6600693832401298, 0.6602631902605938, 0.6595710548260459, 0.6603368333543821, 0.6603782906272008, 0.660038072311405, 0.6599681005781136, 0.6603760145121864, 0.6599799544003921, 0.6605278399050333, 0.6604257607713431, 0.6605694785294487, 0.6610195526652656, 0.6614910805289083, 0.66102584445755, 0.661646999131951, 0.6616206625657118]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:02<00:07,  2.36s/it]predicting test subjects:  50%|█████     | 2/4 [00:04<00:04,  2.15s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:05<00:02,  2.05s/it]predicting test subjects: 100%|██████████| 4/4 [00:07<00:00,  1.94s/it]
predicting train subjects:   0%|          | 0/456 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/456 [00:01<14:42,  1.94s/it]predicting train subjects:   0%|          | 2/456 [00:03<14:11,  1.88s/it]predicting train subjects:   1%|          | 3/456 [00:05<13:14,  1.75s/it]predicting train subjects:   1%|          | 4/456 [00:06<12:59,  1.72s/it]predicting train subjects:   1%|          | 5/456 [00:08<13:53,  1.85s/it]predicting train subjects:   1%|▏         | 6/456 [00:10<13:24,  1.79s/it]predicting train subjects:   2%|▏         | 7/456 [00:12<12:36,  1.68s/it]predicting train subjects:   2%|▏         | 8/456 [00:13<11:30,  1.54s/it]predicting train subjects:   2%|▏         | 9/456 [00:14<11:29,  1.54s/it]predicting train subjects:   2%|▏         | 10/456 [00:16<12:42,  1.71s/it]predicting train subjects:   2%|▏         | 11/456 [00:18<13:20,  1.80s/it]predicting train subjects:   3%|▎         | 12/456 [00:19<11:26,  1.55s/it]predicting train subjects:   3%|▎         | 13/456 [00:21<11:39,  1.58s/it]predicting train subjects:   3%|▎         | 14/456 [00:23<12:13,  1.66s/it]predicting train subjects:   3%|▎         | 15/456 [00:24<11:00,  1.50s/it]predicting train subjects:   4%|▎         | 16/456 [00:26<11:33,  1.58s/it]predicting train subjects:   4%|▎         | 17/456 [00:28<13:26,  1.84s/it]predicting train subjects:   4%|▍         | 18/456 [00:30<12:35,  1.73s/it]predicting train subjects:   4%|▍         | 19/456 [00:31<12:15,  1.68s/it]predicting train subjects:   4%|▍         | 20/456 [00:33<11:39,  1.61s/it]predicting train subjects:   5%|▍         | 21/456 [00:34<11:44,  1.62s/it]predicting train subjects:   5%|▍         | 22/456 [00:36<12:08,  1.68s/it]predicting train subjects:   5%|▌         | 23/456 [00:38<12:24,  1.72s/it]predicting train subjects:   5%|▌         | 24/456 [00:39<10:54,  1.51s/it]predicting train subjects:   5%|▌         | 25/456 [00:40<10:37,  1.48s/it]predicting train subjects:   6%|▌         | 26/456 [00:42<11:21,  1.58s/it]predicting train subjects:   6%|▌         | 27/456 [00:44<11:43,  1.64s/it]predicting train subjects:   6%|▌         | 28/456 [00:45<11:19,  1.59s/it]predicting train subjects:   6%|▋         | 29/456 [00:47<11:21,  1.60s/it]predicting train subjects:   7%|▋         | 30/456 [00:49<11:10,  1.57s/it]predicting train subjects:   7%|▋         | 31/456 [00:50<11:09,  1.57s/it]predicting train subjects:   7%|▋         | 32/456 [00:52<11:29,  1.63s/it]predicting train subjects:   7%|▋         | 33/456 [00:54<11:29,  1.63s/it]predicting train subjects:   7%|▋         | 34/456 [00:55<11:24,  1.62s/it]predicting train subjects:   8%|▊         | 35/456 [00:57<11:50,  1.69s/it]predicting train subjects:   8%|▊         | 36/456 [00:59<11:59,  1.71s/it]predicting train subjects:   8%|▊         | 37/456 [01:00<11:27,  1.64s/it]predicting train subjects:   8%|▊         | 38/456 [01:02<11:34,  1.66s/it]predicting train subjects:   9%|▊         | 39/456 [01:04<11:37,  1.67s/it]predicting train subjects:   9%|▉         | 40/456 [01:05<11:19,  1.63s/it]predicting train subjects:   9%|▉         | 41/456 [01:07<11:15,  1.63s/it]predicting train subjects:   9%|▉         | 42/456 [01:09<11:37,  1.68s/it]predicting train subjects:   9%|▉         | 43/456 [01:10<11:59,  1.74s/it]predicting train subjects:  10%|▉         | 44/456 [01:12<12:03,  1.75s/it]predicting train subjects:  10%|▉         | 45/456 [01:14<12:05,  1.76s/it]predicting train subjects:  10%|█         | 46/456 [01:16<11:55,  1.74s/it]predicting train subjects:  10%|█         | 47/456 [01:18<11:57,  1.76s/it]predicting train subjects:  11%|█         | 48/456 [01:19<11:49,  1.74s/it]predicting train subjects:  11%|█         | 49/456 [01:21<11:37,  1.71s/it]predicting train subjects:  11%|█         | 50/456 [01:23<11:54,  1.76s/it]predicting train subjects:  11%|█         | 51/456 [01:25<12:15,  1.82s/it]predicting train subjects:  11%|█▏        | 52/456 [01:26<12:11,  1.81s/it]predicting train subjects:  12%|█▏        | 53/456 [01:28<11:55,  1.77s/it]predicting train subjects:  12%|█▏        | 54/456 [01:30<12:08,  1.81s/it]predicting train subjects:  12%|█▏        | 55/456 [01:32<11:49,  1.77s/it]predicting train subjects:  12%|█▏        | 56/456 [01:34<12:03,  1.81s/it]predicting train subjects:  12%|█▎        | 57/456 [01:35<11:59,  1.80s/it]predicting train subjects:  13%|█▎        | 58/456 [01:37<11:31,  1.74s/it]predicting train subjects:  13%|█▎        | 59/456 [01:39<11:19,  1.71s/it]predicting train subjects:  13%|█▎        | 60/456 [01:40<11:18,  1.71s/it]predicting train subjects:  13%|█▎        | 61/456 [01:42<11:13,  1.70s/it]predicting train subjects:  14%|█▎        | 62/456 [01:44<11:20,  1.73s/it]predicting train subjects:  14%|█▍        | 63/456 [01:46<11:14,  1.72s/it]predicting train subjects:  14%|█▍        | 64/456 [01:47<10:54,  1.67s/it]predicting train subjects:  14%|█▍        | 65/456 [01:49<11:45,  1.80s/it]predicting train subjects:  14%|█▍        | 66/456 [01:51<11:31,  1.77s/it]predicting train subjects:  15%|█▍        | 67/456 [01:52<10:58,  1.69s/it]predicting train subjects:  15%|█▍        | 68/456 [01:54<11:16,  1.74s/it]predicting train subjects:  15%|█▌        | 69/456 [01:56<11:06,  1.72s/it]predicting train subjects:  15%|█▌        | 70/456 [01:57<10:37,  1.65s/it]predicting train subjects:  16%|█▌        | 71/456 [01:59<10:55,  1.70s/it]predicting train subjects:  16%|█▌        | 72/456 [02:01<11:23,  1.78s/it]predicting train subjects:  16%|█▌        | 73/456 [02:03<11:02,  1.73s/it]predicting train subjects:  16%|█▌        | 74/456 [02:05<11:09,  1.75s/it]predicting train subjects:  16%|█▋        | 75/456 [02:06<10:54,  1.72s/it]predicting train subjects:  17%|█▋        | 76/456 [02:08<10:46,  1.70s/it]predicting train subjects:  17%|█▋        | 77/456 [02:10<11:01,  1.75s/it]predicting train subjects:  17%|█▋        | 78/456 [02:12<10:58,  1.74s/it]predicting train subjects:  17%|█▋        | 79/456 [02:12<09:29,  1.51s/it]predicting train subjects:  18%|█▊        | 80/456 [02:13<08:17,  1.32s/it]predicting train subjects:  18%|█▊        | 81/456 [02:14<07:50,  1.25s/it]predicting train subjects:  18%|█▊        | 82/456 [02:15<07:22,  1.18s/it]predicting train subjects:  18%|█▊        | 83/456 [02:16<07:00,  1.13s/it]predicting train subjects:  18%|█▊        | 84/456 [02:17<06:35,  1.06s/it]predicting train subjects:  19%|█▊        | 85/456 [02:18<06:16,  1.01s/it]predicting train subjects:  19%|█▉        | 86/456 [02:19<06:12,  1.01s/it]predicting train subjects:  19%|█▉        | 87/456 [02:20<06:28,  1.05s/it]predicting train subjects:  19%|█▉        | 88/456 [02:22<06:36,  1.08s/it]predicting train subjects:  20%|█▉        | 89/456 [02:23<06:28,  1.06s/it]predicting train subjects:  20%|█▉        | 90/456 [02:24<06:14,  1.02s/it]predicting train subjects:  20%|█▉        | 91/456 [02:24<05:58,  1.02it/s]predicting train subjects:  20%|██        | 92/456 [02:25<05:51,  1.03it/s]predicting train subjects:  20%|██        | 93/456 [02:26<05:50,  1.04it/s]predicting train subjects:  21%|██        | 94/456 [02:27<06:06,  1.01s/it]predicting train subjects:  21%|██        | 95/456 [02:28<06:05,  1.01s/it]predicting train subjects:  21%|██        | 96/456 [02:29<06:02,  1.01s/it]predicting train subjects:  21%|██▏       | 97/456 [02:31<06:57,  1.16s/it]predicting train subjects:  21%|██▏       | 98/456 [02:32<07:34,  1.27s/it]predicting train subjects:  22%|██▏       | 99/456 [02:34<08:00,  1.35s/it]predicting train subjects:  22%|██▏       | 100/456 [02:36<08:24,  1.42s/it]predicting train subjects:  22%|██▏       | 101/456 [02:37<08:44,  1.48s/it]predicting train subjects:  22%|██▏       | 102/456 [02:39<09:01,  1.53s/it]predicting train subjects:  23%|██▎       | 103/456 [02:41<09:15,  1.57s/it]predicting train subjects:  23%|██▎       | 104/456 [02:42<09:28,  1.62s/it]predicting train subjects:  23%|██▎       | 105/456 [02:44<09:13,  1.58s/it]predicting train subjects:  23%|██▎       | 106/456 [02:45<09:08,  1.57s/it]predicting train subjects:  23%|██▎       | 107/456 [02:47<09:10,  1.58s/it]predicting train subjects:  24%|██▎       | 108/456 [02:48<09:06,  1.57s/it]predicting train subjects:  24%|██▍       | 109/456 [02:50<08:55,  1.54s/it]predicting train subjects:  24%|██▍       | 110/456 [02:51<08:51,  1.54s/it]predicting train subjects:  24%|██▍       | 111/456 [02:53<09:00,  1.57s/it]predicting train subjects:  25%|██▍       | 112/456 [02:55<09:09,  1.60s/it]predicting train subjects:  25%|██▍       | 113/456 [02:56<09:19,  1.63s/it]predicting train subjects:  25%|██▌       | 114/456 [02:58<09:30,  1.67s/it]predicting train subjects:  25%|██▌       | 115/456 [03:00<09:31,  1.68s/it]predicting train subjects:  25%|██▌       | 116/456 [03:01<09:14,  1.63s/it]predicting train subjects:  26%|██▌       | 117/456 [03:03<09:24,  1.67s/it]predicting train subjects:  26%|██▌       | 118/456 [03:05<09:22,  1.66s/it]predicting train subjects:  26%|██▌       | 119/456 [03:07<09:21,  1.67s/it]predicting train subjects:  26%|██▋       | 120/456 [03:08<09:19,  1.67s/it]predicting train subjects:  27%|██▋       | 121/456 [03:10<09:20,  1.67s/it]predicting train subjects:  27%|██▋       | 122/456 [03:12<09:25,  1.69s/it]predicting train subjects:  27%|██▋       | 123/456 [03:14<09:46,  1.76s/it]predicting train subjects:  27%|██▋       | 124/456 [03:15<10:04,  1.82s/it]predicting train subjects:  27%|██▋       | 125/456 [03:17<10:03,  1.82s/it]predicting train subjects:  28%|██▊       | 126/456 [03:19<09:48,  1.78s/it]predicting train subjects:  28%|██▊       | 127/456 [03:20<09:03,  1.65s/it]predicting train subjects:  28%|██▊       | 128/456 [03:22<08:32,  1.56s/it]predicting train subjects:  28%|██▊       | 129/456 [03:23<08:12,  1.51s/it]predicting train subjects:  29%|██▊       | 130/456 [03:24<08:00,  1.47s/it]predicting train subjects:  29%|██▊       | 131/456 [03:26<07:46,  1.44s/it]predicting train subjects:  29%|██▉       | 132/456 [03:27<07:42,  1.43s/it]predicting train subjects:  29%|██▉       | 133/456 [03:29<08:32,  1.59s/it]predicting train subjects:  29%|██▉       | 134/456 [03:31<09:17,  1.73s/it]predicting train subjects:  30%|██▉       | 135/456 [03:33<09:49,  1.84s/it]predicting train subjects:  30%|██▉       | 136/456 [03:35<10:02,  1.88s/it]predicting train subjects:  30%|███       | 137/456 [03:37<10:06,  1.90s/it]predicting train subjects:  30%|███       | 138/456 [03:39<10:16,  1.94s/it]predicting train subjects:  30%|███       | 139/456 [03:41<09:11,  1.74s/it]predicting train subjects:  31%|███       | 140/456 [03:42<08:34,  1.63s/it]predicting train subjects:  31%|███       | 141/456 [03:43<08:02,  1.53s/it]predicting train subjects:  31%|███       | 142/456 [03:45<07:44,  1.48s/it]predicting train subjects:  31%|███▏      | 143/456 [03:46<07:33,  1.45s/it]predicting train subjects:  32%|███▏      | 144/456 [03:47<07:18,  1.40s/it]predicting train subjects:  32%|███▏      | 145/456 [03:49<07:40,  1.48s/it]predicting train subjects:  32%|███▏      | 146/456 [03:51<07:49,  1.51s/it]predicting train subjects:  32%|███▏      | 147/456 [03:52<07:48,  1.52s/it]predicting train subjects:  32%|███▏      | 148/456 [03:54<07:50,  1.53s/it]predicting train subjects:  33%|███▎      | 149/456 [03:55<07:46,  1.52s/it]predicting train subjects:  33%|███▎      | 150/456 [03:57<07:33,  1.48s/it]predicting train subjects:  33%|███▎      | 151/456 [03:58<07:44,  1.52s/it]predicting train subjects:  33%|███▎      | 152/456 [04:00<07:39,  1.51s/it]predicting train subjects:  34%|███▎      | 153/456 [04:01<07:41,  1.52s/it]predicting train subjects:  34%|███▍      | 154/456 [04:03<07:43,  1.53s/it]predicting train subjects:  34%|███▍      | 155/456 [04:04<07:48,  1.56s/it]predicting train subjects:  34%|███▍      | 156/456 [04:06<07:36,  1.52s/it]predicting train subjects:  34%|███▍      | 157/456 [04:07<07:29,  1.50s/it]predicting train subjects:  35%|███▍      | 158/456 [04:09<07:27,  1.50s/it]predicting train subjects:  35%|███▍      | 159/456 [04:10<07:31,  1.52s/it]predicting train subjects:  35%|███▌      | 160/456 [04:12<07:41,  1.56s/it]predicting train subjects:  35%|███▌      | 161/456 [04:14<07:43,  1.57s/it]predicting train subjects:  36%|███▌      | 162/456 [04:15<07:22,  1.50s/it]predicting train subjects:  36%|███▌      | 163/456 [04:16<06:34,  1.35s/it]predicting train subjects:  36%|███▌      | 164/456 [04:17<06:00,  1.24s/it]predicting train subjects:  36%|███▌      | 165/456 [04:18<05:41,  1.17s/it]predicting train subjects:  36%|███▋      | 166/456 [04:19<05:31,  1.14s/it]predicting train subjects:  37%|███▋      | 167/456 [04:20<05:23,  1.12s/it]predicting train subjects:  37%|███▋      | 168/456 [04:21<05:12,  1.09s/it]predicting train subjects:  37%|███▋      | 169/456 [04:22<05:13,  1.09s/it]predicting train subjects:  37%|███▋      | 170/456 [04:23<05:16,  1.11s/it]predicting train subjects:  38%|███▊      | 171/456 [04:24<05:09,  1.09s/it]predicting train subjects:  38%|███▊      | 172/456 [04:25<05:06,  1.08s/it]predicting train subjects:  38%|███▊      | 173/456 [04:27<05:16,  1.12s/it]predicting train subjects:  38%|███▊      | 174/456 [04:28<05:13,  1.11s/it]predicting train subjects:  38%|███▊      | 175/456 [04:29<04:53,  1.05s/it]predicting train subjects:  39%|███▊      | 176/456 [04:30<04:53,  1.05s/it]predicting train subjects:  39%|███▉      | 177/456 [04:31<04:55,  1.06s/it]predicting train subjects:  39%|███▉      | 178/456 [04:32<04:53,  1.05s/it]predicting train subjects:  39%|███▉      | 179/456 [04:33<04:52,  1.06s/it]predicting train subjects:  39%|███▉      | 180/456 [04:34<04:48,  1.05s/it]predicting train subjects:  40%|███▉      | 181/456 [04:36<05:58,  1.30s/it]predicting train subjects:  40%|███▉      | 182/456 [04:38<06:44,  1.48s/it]predicting train subjects:  40%|████      | 183/456 [04:39<07:03,  1.55s/it]predicting train subjects:  40%|████      | 184/456 [04:41<07:25,  1.64s/it]predicting train subjects:  41%|████      | 185/456 [04:43<07:31,  1.67s/it]predicting train subjects:  41%|████      | 186/456 [04:45<07:39,  1.70s/it]predicting train subjects:  41%|████      | 187/456 [04:47<08:02,  1.79s/it]predicting train subjects:  41%|████      | 188/456 [04:49<08:23,  1.88s/it]predicting train subjects:  41%|████▏     | 189/456 [04:51<08:41,  1.95s/it]predicting train subjects:  42%|████▏     | 190/456 [04:53<08:38,  1.95s/it]predicting train subjects:  42%|████▏     | 191/456 [04:55<08:55,  2.02s/it]predicting train subjects:  42%|████▏     | 192/456 [04:57<09:00,  2.05s/it]predicting train subjects:  42%|████▏     | 193/456 [04:59<09:08,  2.09s/it]predicting train subjects:  43%|████▎     | 194/456 [05:01<08:40,  1.99s/it]predicting train subjects:  43%|████▎     | 195/456 [05:03<08:30,  1.96s/it]predicting train subjects:  43%|████▎     | 196/456 [05:05<08:17,  1.91s/it]predicting train subjects:  43%|████▎     | 197/456 [05:07<08:10,  1.89s/it]predicting train subjects:  43%|████▎     | 198/456 [05:09<08:07,  1.89s/it]predicting train subjects:  44%|████▎     | 199/456 [05:10<07:50,  1.83s/it]predicting train subjects:  44%|████▍     | 200/456 [05:12<08:06,  1.90s/it]predicting train subjects:  44%|████▍     | 201/456 [05:14<08:04,  1.90s/it]predicting train subjects:  44%|████▍     | 202/456 [05:16<07:43,  1.83s/it]predicting train subjects:  45%|████▍     | 203/456 [05:18<07:46,  1.85s/it]predicting train subjects:  45%|████▍     | 204/456 [05:19<07:30,  1.79s/it]predicting train subjects:  45%|████▍     | 205/456 [05:21<06:50,  1.64s/it]predicting train subjects:  45%|████▌     | 206/456 [05:22<06:34,  1.58s/it]predicting train subjects:  45%|████▌     | 207/456 [05:24<06:23,  1.54s/it]predicting train subjects:  46%|████▌     | 208/456 [05:25<06:01,  1.46s/it]predicting train subjects:  46%|████▌     | 209/456 [05:26<06:15,  1.52s/it]predicting train subjects:  46%|████▌     | 210/456 [05:28<06:03,  1.48s/it]predicting train subjects:  46%|████▋     | 211/456 [05:30<06:16,  1.54s/it]predicting train subjects:  46%|████▋     | 212/456 [05:31<06:31,  1.60s/it]predicting train subjects:  47%|████▋     | 213/456 [05:33<06:40,  1.65s/it]predicting train subjects:  47%|████▋     | 214/456 [05:35<06:43,  1.67s/it]predicting train subjects:  47%|████▋     | 215/456 [05:37<06:56,  1.73s/it]predicting train subjects:  47%|████▋     | 216/456 [05:38<06:51,  1.72s/it]predicting train subjects:  48%|████▊     | 217/456 [05:40<06:53,  1.73s/it]predicting train subjects:  48%|████▊     | 218/456 [05:42<07:00,  1.77s/it]predicting train subjects:  48%|████▊     | 219/456 [05:43<06:43,  1.70s/it]predicting train subjects:  48%|████▊     | 220/456 [05:45<06:46,  1.72s/it]predicting train subjects:  48%|████▊     | 221/456 [05:47<06:40,  1.70s/it]predicting train subjects:  49%|████▊     | 222/456 [05:48<06:25,  1.65s/it]predicting train subjects:  49%|████▉     | 223/456 [05:50<06:14,  1.61s/it]predicting train subjects:  49%|████▉     | 224/456 [05:52<06:15,  1.62s/it]predicting train subjects:  49%|████▉     | 225/456 [05:53<06:14,  1.62s/it]predicting train subjects:  50%|████▉     | 226/456 [05:55<06:04,  1.58s/it]predicting train subjects:  50%|████▉     | 227/456 [05:56<06:07,  1.60s/it]predicting train subjects:  50%|█████     | 228/456 [05:58<05:59,  1.57s/it]predicting train subjects:  50%|█████     | 229/456 [06:00<06:06,  1.62s/it]predicting train subjects:  50%|█████     | 230/456 [06:01<06:07,  1.63s/it]predicting train subjects:  51%|█████     | 231/456 [06:03<06:18,  1.68s/it]predicting train subjects:  51%|█████     | 232/456 [06:05<06:12,  1.66s/it]predicting train subjects:  51%|█████     | 233/456 [06:06<06:12,  1.67s/it]predicting train subjects:  51%|█████▏    | 234/456 [06:08<06:21,  1.72s/it]predicting train subjects:  52%|█████▏    | 235/456 [06:10<06:18,  1.71s/it]predicting train subjects:  52%|█████▏    | 236/456 [06:11<06:09,  1.68s/it]predicting train subjects:  52%|█████▏    | 237/456 [06:13<06:14,  1.71s/it]predicting train subjects:  52%|█████▏    | 238/456 [06:15<06:17,  1.73s/it]predicting train subjects:  52%|█████▏    | 239/456 [06:17<06:03,  1.67s/it]predicting train subjects:  53%|█████▎    | 240/456 [06:18<06:15,  1.74s/it]predicting train subjects:  53%|█████▎    | 241/456 [06:20<06:11,  1.73s/it]predicting train subjects:  53%|█████▎    | 242/456 [06:22<06:17,  1.76s/it]predicting train subjects:  53%|█████▎    | 243/456 [06:24<06:23,  1.80s/it]predicting train subjects:  54%|█████▎    | 244/456 [06:26<06:09,  1.74s/it]predicting train subjects:  54%|█████▎    | 245/456 [06:27<06:16,  1.79s/it]predicting train subjects:  54%|█████▍    | 246/456 [06:29<06:06,  1.75s/it]predicting train subjects:  54%|█████▍    | 247/456 [06:30<05:36,  1.61s/it]predicting train subjects:  54%|█████▍    | 248/456 [06:32<05:41,  1.64s/it]predicting train subjects:  55%|█████▍    | 249/456 [06:34<05:27,  1.58s/it]predicting train subjects:  55%|█████▍    | 250/456 [06:35<05:06,  1.49s/it]predicting train subjects:  55%|█████▌    | 251/456 [06:36<04:59,  1.46s/it]predicting train subjects:  55%|█████▌    | 252/456 [06:38<04:59,  1.47s/it]predicting train subjects:  55%|█████▌    | 253/456 [06:40<05:33,  1.64s/it]predicting train subjects:  56%|█████▌    | 254/456 [06:42<05:49,  1.73s/it]predicting train subjects:  56%|█████▌    | 255/456 [06:44<06:17,  1.88s/it]predicting train subjects:  56%|█████▌    | 256/456 [06:46<06:29,  1.95s/it]predicting train subjects:  56%|█████▋    | 257/456 [06:48<06:36,  1.99s/it]predicting train subjects:  57%|█████▋    | 258/456 [06:50<06:45,  2.05s/it]predicting train subjects:  57%|█████▋    | 259/456 [06:52<06:09,  1.88s/it]predicting train subjects:  57%|█████▋    | 260/456 [06:53<05:42,  1.75s/it]predicting train subjects:  57%|█████▋    | 261/456 [06:55<05:22,  1.65s/it]predicting train subjects:  57%|█████▋    | 262/456 [06:56<05:17,  1.64s/it]predicting train subjects:  58%|█████▊    | 263/456 [06:58<05:07,  1.59s/it]predicting train subjects:  58%|█████▊    | 264/456 [06:59<04:58,  1.55s/it]predicting train subjects:  58%|█████▊    | 265/456 [07:01<05:01,  1.58s/it]predicting train subjects:  58%|█████▊    | 266/456 [07:02<04:55,  1.56s/it]predicting train subjects:  59%|█████▊    | 267/456 [07:04<04:53,  1.56s/it]predicting train subjects:  59%|█████▉    | 268/456 [07:05<04:43,  1.51s/it]predicting train subjects:  59%|█████▉    | 269/456 [07:07<04:40,  1.50s/it]predicting train subjects:  59%|█████▉    | 270/456 [07:08<04:34,  1.47s/it]predicting train subjects:  59%|█████▉    | 271/456 [07:10<04:38,  1.51s/it]predicting train subjects:  60%|█████▉    | 272/456 [07:11<04:50,  1.58s/it]predicting train subjects:  60%|█████▉    | 273/456 [07:13<04:52,  1.60s/it]predicting train subjects:  60%|██████    | 274/456 [07:15<04:59,  1.65s/it]predicting train subjects:  60%|██████    | 275/456 [07:16<04:52,  1.61s/it]predicting train subjects:  61%|██████    | 276/456 [07:18<04:48,  1.61s/it]predicting train subjects:  61%|██████    | 277/456 [07:20<04:48,  1.61s/it]predicting train subjects:  61%|██████    | 278/456 [07:21<04:38,  1.56s/it]predicting train subjects:  61%|██████    | 279/456 [07:23<04:32,  1.54s/it]predicting train subjects:  61%|██████▏   | 280/456 [07:24<04:26,  1.51s/it]predicting train subjects:  62%|██████▏   | 281/456 [07:26<04:29,  1.54s/it]predicting train subjects:  62%|██████▏   | 282/456 [07:27<04:21,  1.50s/it]predicting train subjects:  62%|██████▏   | 283/456 [07:28<03:59,  1.39s/it]predicting train subjects:  62%|██████▏   | 284/456 [07:29<03:42,  1.29s/it]predicting train subjects:  62%|██████▎   | 285/456 [07:30<03:29,  1.23s/it]predicting train subjects:  63%|██████▎   | 286/456 [07:31<03:21,  1.18s/it]predicting train subjects:  63%|██████▎   | 287/456 [07:32<03:11,  1.13s/it]predicting train subjects:  63%|██████▎   | 288/456 [07:34<03:11,  1.14s/it]predicting train subjects:  63%|██████▎   | 289/456 [07:35<03:10,  1.14s/it]predicting train subjects:  64%|██████▎   | 290/456 [07:36<03:05,  1.12s/it]predicting train subjects:  64%|██████▍   | 291/456 [07:37<03:06,  1.13s/it]predicting train subjects:  64%|██████▍   | 292/456 [07:38<03:02,  1.12s/it]predicting train subjects:  64%|██████▍   | 293/456 [07:39<02:59,  1.10s/it]predicting train subjects:  64%|██████▍   | 294/456 [07:40<03:03,  1.14s/it]predicting train subjects:  65%|██████▍   | 295/456 [07:41<03:04,  1.15s/it]predicting train subjects:  65%|██████▍   | 296/456 [07:43<03:03,  1.14s/it]predicting train subjects:  65%|██████▌   | 297/456 [07:44<02:59,  1.13s/it]predicting train subjects:  65%|██████▌   | 298/456 [07:45<02:50,  1.08s/it]predicting train subjects:  66%|██████▌   | 299/456 [07:46<02:47,  1.06s/it]predicting train subjects:  66%|██████▌   | 300/456 [07:47<02:53,  1.11s/it]predicting train subjects:  66%|██████▌   | 301/456 [07:49<03:32,  1.37s/it]predicting train subjects:  66%|██████▌   | 302/456 [07:51<03:49,  1.49s/it]predicting train subjects:  66%|██████▋   | 303/456 [07:53<04:11,  1.65s/it]predicting train subjects:  67%|██████▋   | 304/456 [07:55<04:28,  1.77s/it]predicting train subjects:  67%|██████▋   | 305/456 [07:56<04:23,  1.74s/it]predicting train subjects:  67%|██████▋   | 306/456 [07:58<04:23,  1.76s/it]predicting train subjects:  67%|██████▋   | 307/456 [08:00<04:40,  1.89s/it]predicting train subjects:  68%|██████▊   | 308/456 [08:02<04:45,  1.93s/it]predicting train subjects:  68%|██████▊   | 309/456 [08:04<04:50,  1.97s/it]predicting train subjects:  68%|██████▊   | 310/456 [08:07<04:54,  2.01s/it]predicting train subjects:  68%|██████▊   | 311/456 [08:09<04:54,  2.03s/it]predicting train subjects:  68%|██████▊   | 312/456 [08:11<04:59,  2.08s/it]predicting train subjects:  69%|██████▊   | 313/456 [08:13<04:50,  2.03s/it]predicting train subjects:  69%|██████▉   | 314/456 [08:15<04:39,  1.97s/it]predicting train subjects:  69%|██████▉   | 315/456 [08:17<04:42,  2.00s/it]predicting train subjects:  69%|██████▉   | 316/456 [08:19<04:41,  2.01s/it]predicting train subjects:  70%|██████▉   | 317/456 [08:20<04:29,  1.94s/it]predicting train subjects:  70%|██████▉   | 318/456 [08:23<04:34,  1.99s/it]predicting train subjects:  70%|██████▉   | 319/456 [08:24<04:26,  1.94s/it]predicting train subjects:  70%|███████   | 320/456 [08:26<04:25,  1.96s/it]predicting train subjects:  70%|███████   | 321/456 [08:28<04:19,  1.92s/it]predicting train subjects:  71%|███████   | 322/456 [08:30<04:12,  1.89s/it]predicting train subjects:  71%|███████   | 323/456 [08:32<04:05,  1.84s/it]predicting train subjects:  71%|███████   | 324/456 [08:34<04:03,  1.84s/it]predicting train subjects:  71%|███████▏  | 325/456 [08:35<03:44,  1.71s/it]predicting train subjects:  71%|███████▏  | 326/456 [08:36<03:32,  1.63s/it]predicting train subjects:  72%|███████▏  | 327/456 [08:38<03:23,  1.58s/it]predicting train subjects:  72%|███████▏  | 328/456 [08:40<03:22,  1.58s/it]predicting train subjects:  72%|███████▏  | 329/456 [08:41<03:15,  1.54s/it]predicting train subjects:  72%|███████▏  | 330/456 [08:42<03:07,  1.49s/it]predicting train subjects:  73%|███████▎  | 331/456 [08:44<03:23,  1.63s/it]predicting train subjects:  73%|███████▎  | 332/456 [08:46<03:33,  1.72s/it]predicting train subjects:  73%|███████▎  | 333/456 [08:48<03:29,  1.70s/it]predicting train subjects:  73%|███████▎  | 334/456 [08:50<03:34,  1.76s/it]predicting train subjects:  73%|███████▎  | 335/456 [08:52<03:36,  1.79s/it]predicting train subjects:  74%|███████▎  | 336/456 [08:53<03:31,  1.76s/it]predicting train subjects:  74%|███████▍  | 337/456 [08:55<03:31,  1.77s/it]predicting train subjects:  74%|███████▍  | 338/456 [08:57<03:28,  1.77s/it]predicting train subjects:  74%|███████▍  | 339/456 [08:59<03:26,  1.76s/it]predicting train subjects:  75%|███████▍  | 340/456 [09:00<03:16,  1.70s/it]predicting train subjects:  75%|███████▍  | 341/456 [09:02<03:19,  1.74s/it]predicting train subjects:  75%|███████▌  | 342/456 [09:04<03:17,  1.73s/it]predicting train subjects:  75%|███████▌  | 343/456 [09:05<03:09,  1.67s/it]predicting train subjects:  75%|███████▌  | 344/456 [09:07<03:09,  1.69s/it]predicting train subjects:  76%|███████▌  | 345/456 [09:09<03:10,  1.72s/it]predicting train subjects:  76%|███████▌  | 346/456 [09:10<03:05,  1.68s/it]predicting train subjects:  76%|███████▌  | 347/456 [09:12<02:59,  1.65s/it]predicting train subjects:  76%|███████▋  | 348/456 [09:14<03:00,  1.67s/it]predicting train subjects:  77%|███████▋  | 349/456 [09:15<03:00,  1.69s/it]predicting train subjects:  77%|███████▋  | 350/456 [09:17<02:55,  1.65s/it]predicting train subjects:  77%|███████▋  | 351/456 [09:19<02:52,  1.65s/it]predicting train subjects:  77%|███████▋  | 352/456 [09:20<02:56,  1.70s/it]predicting train subjects:  77%|███████▋  | 353/456 [09:22<02:58,  1.73s/it]predicting train subjects:  78%|███████▊  | 354/456 [09:24<02:56,  1.73s/it]predicting train subjects:  78%|███████▊  | 355/456 [09:26<02:58,  1.77s/it]predicting train subjects:  78%|███████▊  | 356/456 [09:28<02:58,  1.78s/it]predicting train subjects:  78%|███████▊  | 357/456 [09:29<02:52,  1.74s/it]predicting train subjects:  79%|███████▊  | 358/456 [09:31<02:50,  1.74s/it]predicting train subjects:  79%|███████▊  | 359/456 [09:33<02:48,  1.73s/it]predicting train subjects:  79%|███████▉  | 360/456 [09:34<02:43,  1.70s/it]predicting train subjects:  79%|███████▉  | 361/456 [09:36<02:42,  1.72s/it]predicting train subjects:  79%|███████▉  | 362/456 [09:38<02:41,  1.72s/it]predicting train subjects:  80%|███████▉  | 363/456 [09:40<02:42,  1.75s/it]predicting train subjects:  80%|███████▉  | 364/456 [09:41<02:40,  1.75s/it]predicting train subjects:  80%|████████  | 365/456 [09:43<02:38,  1.74s/it]predicting train subjects:  80%|████████  | 366/456 [09:45<02:40,  1.78s/it]predicting train subjects:  80%|████████  | 367/456 [09:46<02:27,  1.66s/it]predicting train subjects:  81%|████████  | 368/456 [09:48<02:20,  1.60s/it]predicting train subjects:  81%|████████  | 369/456 [09:49<02:15,  1.56s/it]predicting train subjects:  81%|████████  | 370/456 [09:51<02:12,  1.54s/it]predicting train subjects:  81%|████████▏ | 371/456 [09:52<02:09,  1.52s/it]predicting train subjects:  82%|████████▏ | 372/456 [09:54<02:10,  1.56s/it]predicting train subjects:  82%|████████▏ | 373/456 [09:56<02:27,  1.78s/it]predicting train subjects:  82%|████████▏ | 374/456 [09:59<02:37,  1.93s/it]predicting train subjects:  82%|████████▏ | 375/456 [10:01<02:50,  2.10s/it]predicting train subjects:  82%|████████▏ | 376/456 [10:03<02:47,  2.09s/it]predicting train subjects:  83%|████████▎ | 377/456 [10:06<02:53,  2.19s/it]predicting train subjects:  83%|████████▎ | 378/456 [10:08<02:47,  2.15s/it]predicting train subjects:  83%|████████▎ | 379/456 [10:09<02:30,  1.95s/it]predicting train subjects:  83%|████████▎ | 380/456 [10:11<02:18,  1.82s/it]predicting train subjects:  84%|████████▎ | 381/456 [10:12<02:10,  1.73s/it]predicting train subjects:  84%|████████▍ | 382/456 [10:14<02:01,  1.64s/it]predicting train subjects:  84%|████████▍ | 383/456 [10:15<01:54,  1.57s/it]predicting train subjects:  84%|████████▍ | 384/456 [10:16<01:49,  1.52s/it]predicting train subjects:  84%|████████▍ | 385/456 [10:18<01:46,  1.50s/it]predicting train subjects:  85%|████████▍ | 386/456 [10:19<01:45,  1.50s/it]predicting train subjects:  85%|████████▍ | 387/456 [10:21<01:45,  1.53s/it]predicting train subjects:  85%|████████▌ | 388/456 [10:23<01:46,  1.57s/it]predicting train subjects:  85%|████████▌ | 389/456 [10:24<01:42,  1.53s/it]predicting train subjects:  86%|████████▌ | 390/456 [10:26<01:44,  1.59s/it]predicting train subjects:  86%|████████▌ | 391/456 [10:27<01:46,  1.64s/it]predicting train subjects:  86%|████████▌ | 392/456 [10:29<01:43,  1.61s/it]predicting train subjects:  86%|████████▌ | 393/456 [10:31<01:44,  1.66s/it]predicting train subjects:  86%|████████▋ | 394/456 [10:33<01:44,  1.68s/it]predicting train subjects:  87%|████████▋ | 395/456 [10:34<01:41,  1.66s/it]predicting train subjects:  87%|████████▋ | 396/456 [10:36<01:39,  1.66s/it]predicting train subjects:  87%|████████▋ | 397/456 [10:38<01:40,  1.70s/it]predicting train subjects:  87%|████████▋ | 398/456 [10:39<01:36,  1.66s/it]predicting train subjects:  88%|████████▊ | 399/456 [10:41<01:31,  1.61s/it]predicting train subjects:  88%|████████▊ | 400/456 [10:42<01:33,  1.68s/it]predicting train subjects:  88%|████████▊ | 401/456 [10:44<01:31,  1.66s/it]predicting train subjects:  88%|████████▊ | 402/456 [10:46<01:25,  1.58s/it]predicting train subjects:  88%|████████▊ | 403/456 [10:47<01:16,  1.44s/it]predicting train subjects:  89%|████████▊ | 404/456 [10:48<01:10,  1.36s/it]predicting train subjects:  89%|████████▉ | 405/456 [10:49<01:07,  1.33s/it]predicting train subjects:  89%|████████▉ | 406/456 [10:50<01:04,  1.29s/it]predicting train subjects:  89%|████████▉ | 407/456 [10:51<00:59,  1.22s/it]predicting train subjects:  89%|████████▉ | 408/456 [10:53<00:58,  1.22s/it]predicting train subjects:  90%|████████▉ | 409/456 [10:54<00:56,  1.19s/it]predicting train subjects:  90%|████████▉ | 410/456 [10:55<00:55,  1.20s/it]predicting train subjects:  90%|█████████ | 411/456 [10:56<00:52,  1.17s/it]predicting train subjects:  90%|█████████ | 412/456 [10:57<00:50,  1.16s/it]predicting train subjects:  91%|█████████ | 413/456 [10:58<00:50,  1.19s/it]predicting train subjects:  91%|█████████ | 414/456 [10:59<00:49,  1.18s/it]predicting train subjects:  91%|█████████ | 415/456 [11:01<00:46,  1.14s/it]predicting train subjects:  91%|█████████ | 416/456 [11:02<00:44,  1.11s/it]predicting train subjects:  91%|█████████▏| 417/456 [11:03<00:42,  1.08s/it]predicting train subjects:  92%|█████████▏| 418/456 [11:04<00:41,  1.10s/it]predicting train subjects:  92%|█████████▏| 419/456 [11:05<00:39,  1.07s/it]predicting train subjects:  92%|█████████▏| 420/456 [11:06<00:38,  1.07s/it]predicting train subjects:  92%|█████████▏| 421/456 [11:08<00:45,  1.29s/it]predicting train subjects:  93%|█████████▎| 422/456 [11:10<00:51,  1.52s/it]predicting train subjects:  93%|█████████▎| 423/456 [11:12<00:54,  1.66s/it]predicting train subjects:  93%|█████████▎| 424/456 [11:13<00:54,  1.69s/it]predicting train subjects:  93%|█████████▎| 425/456 [11:15<00:55,  1.79s/it]predicting train subjects:  93%|█████████▎| 426/456 [11:17<00:54,  1.82s/it]predicting train subjects:  94%|█████████▎| 427/456 [11:19<00:55,  1.92s/it]predicting train subjects:  94%|█████████▍| 428/456 [11:22<00:55,  1.98s/it]predicting train subjects:  94%|█████████▍| 429/456 [11:24<00:53,  1.97s/it]predicting train subjects:  94%|█████████▍| 430/456 [11:26<00:52,  2.03s/it]predicting train subjects:  95%|█████████▍| 431/456 [11:28<00:49,  2.00s/it]predicting train subjects:  95%|█████████▍| 432/456 [11:30<00:47,  1.99s/it]predicting train subjects:  95%|█████████▍| 433/456 [11:32<00:46,  2.01s/it]predicting train subjects:  95%|█████████▌| 434/456 [11:33<00:42,  1.95s/it]predicting train subjects:  95%|█████████▌| 435/456 [11:35<00:40,  1.92s/it]predicting train subjects:  96%|█████████▌| 436/456 [11:37<00:39,  1.96s/it]predicting train subjects:  96%|█████████▌| 437/456 [11:39<00:36,  1.94s/it]predicting train subjects:  96%|█████████▌| 438/456 [11:41<00:34,  1.91s/it]predicting train subjects:  96%|█████████▋| 439/456 [11:43<00:31,  1.87s/it]predicting train subjects:  96%|█████████▋| 440/456 [11:45<00:29,  1.86s/it]predicting train subjects:  97%|█████████▋| 441/456 [11:47<00:27,  1.86s/it]predicting train subjects:  97%|█████████▋| 442/456 [11:48<00:26,  1.87s/it]predicting train subjects:  97%|█████████▋| 443/456 [11:50<00:23,  1.81s/it]predicting train subjects:  97%|█████████▋| 444/456 [11:52<00:22,  1.85s/it]predicting train subjects:  98%|█████████▊| 445/456 [11:54<00:18,  1.72s/it]predicting train subjects:  98%|█████████▊| 446/456 [11:55<00:17,  1.70s/it]predicting train subjects:  98%|█████████▊| 447/456 [11:57<00:14,  1.60s/it]predicting train subjects:  98%|█████████▊| 448/456 [11:58<00:12,  1.57s/it]predicting train subjects:  98%|█████████▊| 449/456 [11:59<00:10,  1.51s/it]predicting train subjects:  99%|█████████▊| 450/456 [12:01<00:08,  1.46s/it]predicting train subjects:  99%|█████████▉| 451/456 [12:03<00:07,  1.54s/it]predicting train subjects:  99%|█████████▉| 452/456 [12:04<00:06,  1.57s/it]predicting train subjects:  99%|█████████▉| 453/456 [12:06<00:04,  1.60s/it]predicting train subjects: 100%|█████████▉| 454/456 [12:08<00:03,  1.67s/it]predicting train subjects: 100%|█████████▉| 455/456 [12:10<00:01,  1.73s/it]predicting train subjects: 100%|██████████| 456/456 [12:11<00:00,  1.73s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a’: File exists

Loading train:   0%|          | 0/456 [00:00<?, ?it/s]Loading train:   0%|          | 1/456 [00:01<10:51,  1.43s/it]Loading train:   0%|          | 2/456 [00:02<10:28,  1.38s/it]Loading train:   1%|          | 3/456 [00:03<10:01,  1.33s/it]Loading train:   1%|          | 4/456 [00:05<09:44,  1.29s/it]Loading train:   1%|          | 5/456 [00:06<09:49,  1.31s/it]Loading train:   1%|▏         | 6/456 [00:07<09:55,  1.32s/it]Loading train:   2%|▏         | 7/456 [00:08<08:48,  1.18s/it]Loading train:   2%|▏         | 8/456 [00:09<07:58,  1.07s/it]Loading train:   2%|▏         | 9/456 [00:10<08:03,  1.08s/it]Loading train:   2%|▏         | 10/456 [00:11<08:13,  1.11s/it]Loading train:   2%|▏         | 11/456 [00:13<08:47,  1.18s/it]Loading train:   3%|▎         | 12/456 [00:14<08:48,  1.19s/it]Loading train:   3%|▎         | 13/456 [00:15<09:19,  1.26s/it]Loading train:   3%|▎         | 14/456 [00:16<09:13,  1.25s/it]Loading train:   3%|▎         | 15/456 [00:17<08:22,  1.14s/it]Loading train:   4%|▎         | 16/456 [00:18<08:14,  1.12s/it]Loading train:   4%|▎         | 17/456 [00:20<08:55,  1.22s/it]Loading train:   4%|▍         | 18/456 [00:21<08:33,  1.17s/it]Loading train:   4%|▍         | 19/456 [00:22<07:55,  1.09s/it]Loading train:   4%|▍         | 20/456 [00:23<07:28,  1.03s/it]Loading train:   5%|▍         | 21/456 [00:24<07:55,  1.09s/it]Loading train:   5%|▍         | 22/456 [00:25<07:51,  1.09s/it]Loading train:   5%|▌         | 23/456 [00:26<08:00,  1.11s/it]Loading train:   5%|▌         | 24/456 [00:27<07:42,  1.07s/it]Loading train:   5%|▌         | 25/456 [00:28<07:31,  1.05s/it]Loading train:   6%|▌         | 26/456 [00:29<07:26,  1.04s/it]Loading train:   6%|▌         | 27/456 [00:30<07:23,  1.03s/it]Loading train:   6%|▌         | 28/456 [00:31<07:07,  1.00it/s]Loading train:   6%|▋         | 29/456 [00:32<06:52,  1.04it/s]Loading train:   7%|▋         | 30/456 [00:33<07:09,  1.01s/it]Loading train:   7%|▋         | 31/456 [00:34<06:54,  1.03it/s]Loading train:   7%|▋         | 32/456 [00:35<06:41,  1.06it/s]Loading train:   7%|▋         | 33/456 [00:36<06:51,  1.03it/s]Loading train:   7%|▋         | 34/456 [00:37<07:02,  1.00s/it]Loading train:   8%|▊         | 35/456 [00:38<07:20,  1.05s/it]Loading train:   8%|▊         | 36/456 [00:39<07:06,  1.01s/it]Loading train:   8%|▊         | 37/456 [00:40<06:32,  1.07it/s]Loading train:   8%|▊         | 38/456 [00:41<06:34,  1.06it/s]Loading train:   9%|▊         | 39/456 [00:42<06:28,  1.07it/s]Loading train:   9%|▉         | 40/456 [00:43<06:44,  1.03it/s]Loading train:   9%|▉         | 41/456 [00:44<06:40,  1.04it/s]Loading train:   9%|▉         | 42/456 [00:45<07:18,  1.06s/it]Loading train:   9%|▉         | 43/456 [00:46<07:02,  1.02s/it]Loading train:  10%|▉         | 44/456 [00:47<07:27,  1.09s/it]Loading train:  10%|▉         | 45/456 [00:48<07:43,  1.13s/it]Loading train:  10%|█         | 46/456 [00:50<07:38,  1.12s/it]Loading train:  10%|█         | 47/456 [00:51<08:08,  1.19s/it]Loading train:  11%|█         | 48/456 [00:52<07:52,  1.16s/it]Loading train:  11%|█         | 49/456 [00:53<07:23,  1.09s/it]Loading train:  11%|█         | 50/456 [00:54<07:01,  1.04s/it]Loading train:  11%|█         | 51/456 [00:55<06:58,  1.03s/it]Loading train:  11%|█▏        | 52/456 [00:56<07:10,  1.07s/it]Loading train:  12%|█▏        | 53/456 [00:57<07:03,  1.05s/it]Loading train:  12%|█▏        | 54/456 [00:58<06:43,  1.00s/it]Loading train:  12%|█▏        | 55/456 [00:59<06:28,  1.03it/s]Loading train:  12%|█▏        | 56/456 [01:00<06:48,  1.02s/it]Loading train:  12%|█▎        | 57/456 [01:01<07:03,  1.06s/it]Loading train:  13%|█▎        | 58/456 [01:02<06:55,  1.04s/it]Loading train:  13%|█▎        | 59/456 [01:03<07:10,  1.09s/it]Loading train:  13%|█▎        | 60/456 [01:04<07:03,  1.07s/it]Loading train:  13%|█▎        | 61/456 [01:06<07:29,  1.14s/it]Loading train:  14%|█▎        | 62/456 [01:07<07:14,  1.10s/it]Loading train:  14%|█▍        | 63/456 [01:08<07:04,  1.08s/it]Loading train:  14%|█▍        | 64/456 [01:09<06:57,  1.07s/it]Loading train:  14%|█▍        | 65/456 [01:10<06:48,  1.05s/it]Loading train:  14%|█▍        | 66/456 [01:11<06:51,  1.06s/it]Loading train:  15%|█▍        | 67/456 [01:12<07:11,  1.11s/it]Loading train:  15%|█▍        | 68/456 [01:13<07:08,  1.10s/it]Loading train:  15%|█▌        | 69/456 [01:14<07:11,  1.12s/it]Loading train:  15%|█▌        | 70/456 [01:15<07:16,  1.13s/it]Loading train:  16%|█▌        | 71/456 [01:16<07:09,  1.12s/it]Loading train:  16%|█▌        | 72/456 [01:17<06:53,  1.08s/it]Loading train:  16%|█▌        | 73/456 [01:19<07:03,  1.11s/it]Loading train:  16%|█▌        | 74/456 [01:20<06:42,  1.05s/it]Loading train:  16%|█▋        | 75/456 [01:21<06:46,  1.07s/it]Loading train:  17%|█▋        | 76/456 [01:22<06:28,  1.02s/it]Loading train:  17%|█▋        | 77/456 [01:23<06:37,  1.05s/it]Loading train:  17%|█▋        | 78/456 [01:24<07:04,  1.12s/it]Loading train:  17%|█▋        | 79/456 [01:25<06:32,  1.04s/it]Loading train:  18%|█▊        | 80/456 [01:26<06:19,  1.01s/it]Loading train:  18%|█▊        | 81/456 [01:27<05:58,  1.05it/s]Loading train:  18%|█▊        | 82/456 [01:27<05:49,  1.07it/s]Loading train:  18%|█▊        | 83/456 [01:28<05:39,  1.10it/s]Loading train:  18%|█▊        | 84/456 [01:29<05:30,  1.13it/s]Loading train:  19%|█▊        | 85/456 [01:30<05:13,  1.19it/s]Loading train:  19%|█▉        | 86/456 [01:31<04:52,  1.27it/s]Loading train:  19%|█▉        | 87/456 [01:31<04:50,  1.27it/s]Loading train:  19%|█▉        | 88/456 [01:32<04:37,  1.33it/s]Loading train:  20%|█▉        | 89/456 [01:33<04:23,  1.39it/s]Loading train:  20%|█▉        | 90/456 [01:33<04:30,  1.35it/s]Loading train:  20%|█▉        | 91/456 [01:34<04:36,  1.32it/s]Loading train:  20%|██        | 92/456 [01:35<04:41,  1.29it/s]Loading train:  20%|██        | 93/456 [01:36<04:34,  1.32it/s]Loading train:  21%|██        | 94/456 [01:37<04:38,  1.30it/s]Loading train:  21%|██        | 95/456 [01:37<04:44,  1.27it/s]Loading train:  21%|██        | 96/456 [01:38<04:41,  1.28it/s]Loading train:  21%|██▏       | 97/456 [01:39<05:28,  1.09it/s]Loading train:  21%|██▏       | 98/456 [01:41<06:01,  1.01s/it]Loading train:  22%|██▏       | 99/456 [01:42<06:11,  1.04s/it]Loading train:  22%|██▏       | 100/456 [01:43<06:16,  1.06s/it]Loading train:  22%|██▏       | 101/456 [01:44<06:07,  1.04s/it]Loading train:  22%|██▏       | 102/456 [01:45<05:48,  1.01it/s]Loading train:  23%|██▎       | 103/456 [01:46<06:35,  1.12s/it]Loading train:  23%|██▎       | 104/456 [01:47<06:26,  1.10s/it]Loading train:  23%|██▎       | 105/456 [01:48<06:12,  1.06s/it]Loading train:  23%|██▎       | 106/456 [01:49<06:18,  1.08s/it]Loading train:  23%|██▎       | 107/456 [01:50<06:05,  1.05s/it]Loading train:  24%|██▎       | 108/456 [01:51<05:51,  1.01s/it]Loading train:  24%|██▍       | 109/456 [01:52<05:52,  1.01s/it]Loading train:  24%|██▍       | 110/456 [01:53<05:47,  1.00s/it]Loading train:  24%|██▍       | 111/456 [01:54<05:38,  1.02it/s]Loading train:  25%|██▍       | 112/456 [01:55<05:44,  1.00s/it]Loading train:  25%|██▍       | 113/456 [01:56<05:24,  1.06it/s]Loading train:  25%|██▌       | 114/456 [01:57<05:33,  1.03it/s]Loading train:  25%|██▌       | 115/456 [01:58<05:39,  1.00it/s]Loading train:  25%|██▌       | 116/456 [01:59<06:01,  1.06s/it]Loading train:  26%|██▌       | 117/456 [02:00<06:05,  1.08s/it]Loading train:  26%|██▌       | 118/456 [02:01<05:57,  1.06s/it]Loading train:  26%|██▌       | 119/456 [02:03<06:14,  1.11s/it]Loading train:  26%|██▋       | 120/456 [02:04<05:51,  1.05s/it]Loading train:  27%|██▋       | 121/456 [02:05<05:48,  1.04s/it]Loading train:  27%|██▋       | 122/456 [02:06<06:00,  1.08s/it]Loading train:  27%|██▋       | 123/456 [02:07<05:46,  1.04s/it]Loading train:  27%|██▋       | 124/456 [02:08<05:38,  1.02s/it]Loading train:  27%|██▋       | 125/456 [02:09<05:24,  1.02it/s]Loading train:  28%|██▊       | 126/456 [02:10<05:29,  1.00it/s]Loading train:  28%|██▊       | 127/456 [02:11<05:26,  1.01it/s]Loading train:  28%|██▊       | 128/456 [02:12<05:41,  1.04s/it]Loading train:  28%|██▊       | 129/456 [02:13<05:32,  1.02s/it]Loading train:  29%|██▊       | 130/456 [02:14<05:27,  1.00s/it]Loading train:  29%|██▊       | 131/456 [02:15<05:12,  1.04it/s]Loading train:  29%|██▉       | 132/456 [02:15<05:07,  1.05it/s]Loading train:  29%|██▉       | 133/456 [02:17<05:49,  1.08s/it]Loading train:  29%|██▉       | 134/456 [02:18<06:21,  1.18s/it]Loading train:  30%|██▉       | 135/456 [02:20<06:33,  1.23s/it]Loading train:  30%|██▉       | 136/456 [02:21<06:34,  1.23s/it]Loading train:  30%|███       | 137/456 [02:22<06:36,  1.24s/it]Loading train:  30%|███       | 138/456 [02:23<06:50,  1.29s/it]Loading train:  30%|███       | 139/456 [02:25<06:29,  1.23s/it]Loading train:  31%|███       | 140/456 [02:26<06:00,  1.14s/it]Loading train:  31%|███       | 141/456 [02:27<05:51,  1.12s/it]Loading train:  31%|███       | 142/456 [02:27<05:31,  1.06s/it]Loading train:  31%|███▏      | 143/456 [02:29<05:48,  1.11s/it]Loading train:  32%|███▏      | 144/456 [02:30<05:38,  1.08s/it]Loading train:  32%|███▏      | 145/456 [02:31<05:44,  1.11s/it]Loading train:  32%|███▏      | 146/456 [02:32<05:21,  1.04s/it]Loading train:  32%|███▏      | 147/456 [02:32<04:50,  1.06it/s]Loading train:  32%|███▏      | 148/456 [02:33<04:47,  1.07it/s]Loading train:  33%|███▎      | 149/456 [02:34<04:57,  1.03it/s]Loading train:  33%|███▎      | 150/456 [02:35<04:40,  1.09it/s]Loading train:  33%|███▎      | 151/456 [02:36<05:07,  1.01s/it]Loading train:  33%|███▎      | 152/456 [02:37<04:57,  1.02it/s]Loading train:  34%|███▎      | 153/456 [02:38<04:54,  1.03it/s]Loading train:  34%|███▍      | 154/456 [02:39<04:55,  1.02it/s]Loading train:  34%|███▍      | 155/456 [02:40<05:09,  1.03s/it]Loading train:  34%|███▍      | 156/456 [02:41<04:51,  1.03it/s]Loading train:  34%|███▍      | 157/456 [02:42<04:53,  1.02it/s]Loading train:  35%|███▍      | 158/456 [02:43<04:29,  1.11it/s]Loading train:  35%|███▍      | 159/456 [02:44<04:30,  1.10it/s]Loading train:  35%|███▌      | 160/456 [02:45<04:29,  1.10it/s]Loading train:  35%|███▌      | 161/456 [02:46<04:31,  1.09it/s]Loading train:  36%|███▌      | 162/456 [02:47<04:33,  1.08it/s]Loading train:  36%|███▌      | 163/456 [02:48<04:40,  1.04it/s]Loading train:  36%|███▌      | 164/456 [02:49<04:44,  1.03it/s]Loading train:  36%|███▌      | 165/456 [02:50<04:55,  1.01s/it]Loading train:  36%|███▋      | 166/456 [02:51<04:42,  1.03it/s]Loading train:  37%|███▋      | 167/456 [02:52<04:55,  1.02s/it]Loading train:  37%|███▋      | 168/456 [02:53<04:42,  1.02it/s]Loading train:  37%|███▋      | 169/456 [02:54<04:32,  1.05it/s]Loading train:  37%|███▋      | 170/456 [02:54<04:08,  1.15it/s]Loading train:  38%|███▊      | 171/456 [02:55<03:56,  1.21it/s]Loading train:  38%|███▊      | 172/456 [02:56<03:53,  1.22it/s]Loading train:  38%|███▊      | 173/456 [02:57<03:50,  1.23it/s]Loading train:  38%|███▊      | 174/456 [02:58<03:51,  1.22it/s]Loading train:  38%|███▊      | 175/456 [02:58<03:43,  1.26it/s]Loading train:  39%|███▊      | 176/456 [02:59<03:33,  1.31it/s]Loading train:  39%|███▉      | 177/456 [03:00<03:32,  1.31it/s]Loading train:  39%|███▉      | 178/456 [03:01<03:38,  1.27it/s]Loading train:  39%|███▉      | 179/456 [03:01<03:48,  1.21it/s]Loading train:  39%|███▉      | 180/456 [03:02<03:49,  1.20it/s]Loading train:  40%|███▉      | 181/456 [03:04<04:29,  1.02it/s]Loading train:  40%|███▉      | 182/456 [03:05<04:45,  1.04s/it]Loading train:  40%|████      | 183/456 [03:06<04:43,  1.04s/it]Loading train:  40%|████      | 184/456 [03:07<04:38,  1.02s/it]Loading train:  41%|████      | 185/456 [03:08<04:46,  1.06s/it]Loading train:  41%|████      | 186/456 [03:09<05:01,  1.12s/it]Loading train:  41%|████      | 187/456 [03:11<05:12,  1.16s/it]Loading train:  41%|████      | 188/456 [03:12<05:25,  1.22s/it]Loading train:  41%|████▏     | 189/456 [03:13<05:22,  1.21s/it]Loading train:  42%|████▏     | 190/456 [03:14<05:34,  1.26s/it]Loading train:  42%|████▏     | 191/456 [03:16<05:38,  1.28s/it]Loading train:  42%|████▏     | 192/456 [03:17<05:42,  1.30s/it]Loading train:  42%|████▏     | 193/456 [03:18<05:34,  1.27s/it]Loading train:  43%|████▎     | 194/456 [03:19<05:12,  1.19s/it]Loading train:  43%|████▎     | 195/456 [03:21<05:19,  1.23s/it]Loading train:  43%|████▎     | 196/456 [03:22<05:19,  1.23s/it]Loading train:  43%|████▎     | 197/456 [03:23<05:12,  1.21s/it]Loading train:  43%|████▎     | 198/456 [03:24<05:00,  1.16s/it]Loading train:  44%|████▎     | 199/456 [03:25<04:58,  1.16s/it]Loading train:  44%|████▍     | 200/456 [03:26<04:46,  1.12s/it]Loading train:  44%|████▍     | 201/456 [03:27<04:19,  1.02s/it]Loading train:  44%|████▍     | 202/456 [03:28<04:12,  1.01it/s]Loading train:  45%|████▍     | 203/456 [03:29<04:13,  1.00s/it]Loading train:  45%|████▍     | 204/456 [03:30<04:02,  1.04it/s]Loading train:  45%|████▍     | 205/456 [03:31<03:51,  1.09it/s]Loading train:  45%|████▌     | 206/456 [03:32<04:16,  1.02s/it]Loading train:  45%|████▌     | 207/456 [03:33<04:24,  1.06s/it]Loading train:  46%|████▌     | 208/456 [03:34<04:48,  1.16s/it]Loading train:  46%|████▌     | 209/456 [03:36<04:37,  1.12s/it]Loading train:  46%|████▌     | 210/456 [03:36<04:12,  1.03s/it]Loading train:  46%|████▋     | 211/456 [03:38<04:49,  1.18s/it]Loading train:  46%|████▋     | 212/456 [03:39<04:36,  1.13s/it]Loading train:  47%|████▋     | 213/456 [03:40<04:40,  1.16s/it]Loading train:  47%|████▋     | 214/456 [03:41<04:37,  1.15s/it]Loading train:  47%|████▋     | 215/456 [03:42<04:37,  1.15s/it]Loading train:  47%|████▋     | 216/456 [03:43<04:27,  1.11s/it]Loading train:  48%|████▊     | 217/456 [03:45<04:58,  1.25s/it]Loading train:  48%|████▊     | 218/456 [03:46<04:55,  1.24s/it]Loading train:  48%|████▊     | 219/456 [03:47<04:50,  1.23s/it]Loading train:  48%|████▊     | 220/456 [03:48<04:31,  1.15s/it]Loading train:  48%|████▊     | 221/456 [03:49<04:17,  1.10s/it]Loading train:  49%|████▊     | 222/456 [03:51<04:37,  1.19s/it]Loading train:  49%|████▉     | 223/456 [03:52<04:57,  1.28s/it]Loading train:  49%|████▉     | 224/456 [03:53<04:50,  1.25s/it]Loading train:  49%|████▉     | 225/456 [03:55<04:42,  1.22s/it]Loading train:  50%|████▉     | 226/456 [03:55<04:17,  1.12s/it]Loading train:  50%|████▉     | 227/456 [03:57<04:21,  1.14s/it]Loading train:  50%|█████     | 228/456 [03:58<04:27,  1.17s/it]Loading train:  50%|█████     | 229/456 [03:59<04:43,  1.25s/it]Loading train:  50%|█████     | 230/456 [04:00<04:34,  1.22s/it]Loading train:  51%|█████     | 231/456 [04:02<04:28,  1.19s/it]Loading train:  51%|█████     | 232/456 [04:03<04:46,  1.28s/it]Loading train:  51%|█████     | 233/456 [04:05<04:59,  1.34s/it]Loading train:  51%|█████▏    | 234/456 [04:06<04:48,  1.30s/it]Loading train:  52%|█████▏    | 235/456 [04:07<04:25,  1.20s/it]Loading train:  52%|█████▏    | 236/456 [04:08<04:10,  1.14s/it]Loading train:  52%|█████▏    | 237/456 [04:09<04:08,  1.14s/it]Loading train:  52%|█████▏    | 238/456 [04:10<04:21,  1.20s/it]Loading train:  52%|█████▏    | 239/456 [04:11<04:10,  1.15s/it]Loading train:  53%|█████▎    | 240/456 [04:12<04:10,  1.16s/it]Loading train:  53%|█████▎    | 241/456 [04:13<03:56,  1.10s/it]Loading train:  53%|█████▎    | 242/456 [04:15<04:07,  1.16s/it]Loading train:  53%|█████▎    | 243/456 [04:16<04:20,  1.22s/it]Loading train:  54%|█████▎    | 244/456 [04:17<04:10,  1.18s/it]Loading train:  54%|█████▎    | 245/456 [04:18<04:19,  1.23s/it]Loading train:  54%|█████▍    | 246/456 [04:19<03:53,  1.11s/it]Loading train:  54%|█████▍    | 247/456 [04:20<03:47,  1.09s/it]Loading train:  54%|█████▍    | 248/456 [04:21<03:40,  1.06s/it]Loading train:  55%|█████▍    | 249/456 [04:22<03:35,  1.04s/it]Loading train:  55%|█████▍    | 250/456 [04:23<03:32,  1.03s/it]Loading train:  55%|█████▌    | 251/456 [04:24<03:21,  1.02it/s]Loading train:  55%|█████▌    | 252/456 [04:25<03:20,  1.02it/s]Loading train:  55%|█████▌    | 253/456 [04:26<03:25,  1.01s/it]Loading train:  56%|█████▌    | 254/456 [04:28<04:09,  1.24s/it]Loading train:  56%|█████▌    | 255/456 [04:30<04:21,  1.30s/it]Loading train:  56%|█████▌    | 256/456 [04:31<04:24,  1.32s/it]Loading train:  56%|█████▋    | 257/456 [04:32<04:22,  1.32s/it]Loading train:  57%|█████▋    | 258/456 [04:34<04:21,  1.32s/it]Loading train:  57%|█████▋    | 259/456 [04:35<04:05,  1.25s/it]Loading train:  57%|█████▋    | 260/456 [04:36<03:48,  1.17s/it]Loading train:  57%|█████▋    | 261/456 [04:37<03:52,  1.19s/it]Loading train:  57%|█████▋    | 262/456 [04:38<03:25,  1.06s/it]Loading train:  58%|█████▊    | 263/456 [04:38<03:09,  1.02it/s]Loading train:  58%|█████▊    | 264/456 [04:40<03:23,  1.06s/it]Loading train:  58%|█████▊    | 265/456 [04:41<03:27,  1.09s/it]Loading train:  58%|█████▊    | 266/456 [04:42<03:35,  1.13s/it]Loading train:  59%|█████▊    | 267/456 [04:43<03:32,  1.13s/it]Loading train:  59%|█████▉    | 268/456 [04:44<03:21,  1.07s/it]Loading train:  59%|█████▉    | 269/456 [04:45<03:22,  1.08s/it]Loading train:  59%|█████▉    | 270/456 [04:46<03:17,  1.06s/it]Loading train:  59%|█████▉    | 271/456 [04:48<03:37,  1.17s/it]Loading train:  60%|█████▉    | 272/456 [04:49<03:41,  1.20s/it]Loading train:  60%|█████▉    | 273/456 [04:50<03:32,  1.16s/it]Loading train:  60%|██████    | 274/456 [04:51<03:10,  1.05s/it]Loading train:  60%|██████    | 275/456 [04:52<03:22,  1.12s/it]Loading train:  61%|██████    | 276/456 [04:53<03:36,  1.20s/it]Loading train:  61%|██████    | 277/456 [04:55<03:35,  1.20s/it]Loading train:  61%|██████    | 278/456 [04:56<03:27,  1.17s/it]Loading train:  61%|██████    | 279/456 [04:56<03:05,  1.05s/it]Loading train:  61%|██████▏   | 280/456 [04:57<02:55,  1.00it/s]Loading train:  62%|██████▏   | 281/456 [04:58<02:56,  1.01s/it]Loading train:  62%|██████▏   | 282/456 [05:00<03:02,  1.05s/it]Loading train:  62%|██████▏   | 283/456 [05:00<02:56,  1.02s/it]Loading train:  62%|██████▏   | 284/456 [05:02<02:56,  1.02s/it]Loading train:  62%|██████▎   | 285/456 [05:02<02:48,  1.02it/s]Loading train:  63%|██████▎   | 286/456 [05:03<02:33,  1.10it/s]Loading train:  63%|██████▎   | 287/456 [05:04<02:25,  1.16it/s]Loading train:  63%|██████▎   | 288/456 [05:05<02:29,  1.12it/s]Loading train:  63%|██████▎   | 289/456 [05:06<02:34,  1.08it/s]Loading train:  64%|██████▎   | 290/456 [05:07<02:45,  1.01it/s]Loading train:  64%|██████▍   | 291/456 [05:08<02:40,  1.03it/s]Loading train:  64%|██████▍   | 292/456 [05:09<02:34,  1.06it/s]Loading train:  64%|██████▍   | 293/456 [05:10<02:22,  1.14it/s]Loading train:  64%|██████▍   | 294/456 [05:10<02:25,  1.11it/s]Loading train:  65%|██████▍   | 295/456 [05:12<02:34,  1.04it/s]Loading train:  65%|██████▍   | 296/456 [05:13<02:43,  1.02s/it]Loading train:  65%|██████▌   | 297/456 [05:14<02:50,  1.07s/it]Loading train:  65%|██████▌   | 298/456 [05:15<02:47,  1.06s/it]Loading train:  66%|██████▌   | 299/456 [05:16<02:30,  1.05it/s]Loading train:  66%|██████▌   | 300/456 [05:16<02:14,  1.16it/s]Loading train:  66%|██████▌   | 301/456 [05:18<02:55,  1.14s/it]Loading train:  66%|██████▌   | 302/456 [05:19<03:04,  1.20s/it]Loading train:  66%|██████▋   | 303/456 [05:21<02:58,  1.17s/it]Loading train:  67%|██████▋   | 304/456 [05:22<02:55,  1.15s/it]Loading train:  67%|██████▋   | 305/456 [05:23<02:49,  1.12s/it]Loading train:  67%|██████▋   | 306/456 [05:24<02:47,  1.11s/it]Loading train:  67%|██████▋   | 307/456 [05:26<03:14,  1.30s/it]Loading train:  68%|██████▊   | 308/456 [05:27<03:18,  1.34s/it]Loading train:  68%|██████▊   | 309/456 [05:28<03:16,  1.33s/it]Loading train:  68%|██████▊   | 310/456 [05:29<03:02,  1.25s/it]Loading train:  68%|██████▊   | 311/456 [05:30<02:52,  1.19s/it]Loading train:  68%|██████▊   | 312/456 [05:32<02:54,  1.21s/it]Loading train:  69%|██████▊   | 313/456 [05:33<03:00,  1.26s/it]Loading train:  69%|██████▉   | 314/456 [05:34<03:02,  1.29s/it]Loading train:  69%|██████▉   | 315/456 [05:36<02:56,  1.25s/it]Loading train:  69%|██████▉   | 316/456 [05:37<02:43,  1.17s/it]Loading train:  70%|██████▉   | 317/456 [05:38<02:36,  1.13s/it]Loading train:  70%|██████▉   | 318/456 [05:39<02:51,  1.24s/it]Loading train:  70%|██████▉   | 319/456 [05:40<02:47,  1.23s/it]Loading train:  70%|███████   | 320/456 [05:41<02:41,  1.19s/it]Loading train:  70%|███████   | 321/456 [05:42<02:34,  1.15s/it]Loading train:  71%|███████   | 322/456 [05:44<02:34,  1.15s/it]Loading train:  71%|███████   | 323/456 [05:44<02:18,  1.04s/it]Loading train:  71%|███████   | 324/456 [05:45<02:15,  1.02s/it]Loading train:  71%|███████▏  | 325/456 [05:47<02:19,  1.07s/it]Loading train:  71%|███████▏  | 326/456 [05:48<02:17,  1.06s/it]Loading train:  72%|███████▏  | 327/456 [05:49<02:20,  1.09s/it]Loading train:  72%|███████▏  | 328/456 [05:50<02:22,  1.11s/it]Loading train:  72%|███████▏  | 329/456 [05:51<02:11,  1.04s/it]Loading train:  72%|███████▏  | 330/456 [05:52<02:04,  1.01it/s]Loading train:  73%|███████▎  | 331/456 [05:53<02:13,  1.07s/it]Loading train:  73%|███████▎  | 332/456 [05:54<02:16,  1.10s/it]Loading train:  73%|███████▎  | 333/456 [05:55<02:13,  1.09s/it]Loading train:  73%|███████▎  | 334/456 [05:56<02:10,  1.07s/it]Loading train:  73%|███████▎  | 335/456 [05:57<02:12,  1.10s/it]Loading train:  74%|███████▎  | 336/456 [05:58<02:09,  1.08s/it]Loading train:  74%|███████▍  | 337/456 [05:59<02:05,  1.05s/it]Loading train:  74%|███████▍  | 338/456 [06:00<02:06,  1.07s/it]Loading train:  74%|███████▍  | 339/456 [06:02<02:12,  1.14s/it]Loading train:  75%|███████▍  | 340/456 [06:03<02:18,  1.19s/it]Loading train:  75%|███████▍  | 341/456 [06:04<02:13,  1.16s/it]Loading train:  75%|███████▌  | 342/456 [06:06<02:23,  1.26s/it]Loading train:  75%|███████▌  | 343/456 [06:07<02:12,  1.17s/it]Loading train:  75%|███████▌  | 344/456 [06:08<02:08,  1.15s/it]Loading train:  76%|███████▌  | 345/456 [06:09<02:10,  1.18s/it]Loading train:  76%|███████▌  | 346/456 [06:10<02:09,  1.18s/it]Loading train:  76%|███████▌  | 347/456 [06:11<02:07,  1.17s/it]Loading train:  76%|███████▋  | 348/456 [06:12<02:05,  1.17s/it]Loading train:  77%|███████▋  | 349/456 [06:14<02:04,  1.16s/it]Loading train:  77%|███████▋  | 350/456 [06:14<01:54,  1.08s/it]Loading train:  77%|███████▋  | 351/456 [06:16<01:56,  1.11s/it]Loading train:  77%|███████▋  | 352/456 [06:17<02:01,  1.17s/it]Loading train:  77%|███████▋  | 353/456 [06:18<01:57,  1.15s/it]Loading train:  78%|███████▊  | 354/456 [06:19<01:51,  1.09s/it]Loading train:  78%|███████▊  | 355/456 [06:20<01:53,  1.12s/it]Loading train:  78%|███████▊  | 356/456 [06:21<01:49,  1.09s/it]Loading train:  78%|███████▊  | 357/456 [06:22<01:42,  1.03s/it]Loading train:  79%|███████▊  | 358/456 [06:23<01:44,  1.07s/it]Loading train:  79%|███████▊  | 359/456 [06:24<01:41,  1.05s/it]Loading train:  79%|███████▉  | 360/456 [06:25<01:42,  1.07s/it]Loading train:  79%|███████▉  | 361/456 [06:26<01:42,  1.08s/it]Loading train:  79%|███████▉  | 362/456 [06:28<01:42,  1.09s/it]Loading train:  80%|███████▉  | 363/456 [06:29<01:40,  1.08s/it]Loading train:  80%|███████▉  | 364/456 [06:30<01:34,  1.03s/it]Loading train:  80%|████████  | 365/456 [06:31<01:34,  1.04s/it]Loading train:  80%|████████  | 366/456 [06:32<01:42,  1.14s/it]Loading train:  80%|████████  | 367/456 [06:33<01:42,  1.15s/it]Loading train:  81%|████████  | 368/456 [06:34<01:32,  1.05s/it]Loading train:  81%|████████  | 369/456 [06:35<01:29,  1.03s/it]Loading train:  81%|████████  | 370/456 [06:36<01:30,  1.05s/it]Loading train:  81%|████████▏ | 371/456 [06:37<01:23,  1.02it/s]Loading train:  82%|████████▏ | 372/456 [06:38<01:20,  1.04it/s]Loading train:  82%|████████▏ | 373/456 [06:39<01:37,  1.18s/it]Loading train:  82%|████████▏ | 374/456 [06:41<01:46,  1.29s/it]Loading train:  82%|████████▏ | 375/456 [06:42<01:46,  1.31s/it]Loading train:  82%|████████▏ | 376/456 [06:44<01:41,  1.26s/it]Loading train:  83%|████████▎ | 377/456 [06:45<01:38,  1.24s/it]Loading train:  83%|████████▎ | 378/456 [06:47<01:50,  1.42s/it]Loading train:  83%|████████▎ | 379/456 [06:48<01:44,  1.35s/it]Loading train:  83%|████████▎ | 380/456 [06:49<01:35,  1.25s/it]Loading train:  84%|████████▎ | 381/456 [06:50<01:29,  1.19s/it]Loading train:  84%|████████▍ | 382/456 [06:51<01:21,  1.10s/it]Loading train:  84%|████████▍ | 383/456 [06:52<01:14,  1.03s/it]Loading train:  84%|████████▍ | 384/456 [06:53<01:16,  1.06s/it]Loading train:  84%|████████▍ | 385/456 [06:54<01:17,  1.10s/it]Loading train:  85%|████████▍ | 386/456 [06:55<01:18,  1.11s/it]Loading train:  85%|████████▍ | 387/456 [06:56<01:19,  1.15s/it]Loading train:  85%|████████▌ | 388/456 [06:57<01:13,  1.08s/it]Loading train:  85%|████████▌ | 389/456 [06:58<01:10,  1.05s/it]Loading train:  86%|████████▌ | 390/456 [06:59<01:06,  1.01s/it]Loading train:  86%|████████▌ | 391/456 [07:00<01:07,  1.05s/it]Loading train:  86%|████████▌ | 392/456 [07:01<01:08,  1.07s/it]Loading train:  86%|████████▌ | 393/456 [07:03<01:09,  1.11s/it]Loading train:  86%|████████▋ | 394/456 [07:04<01:07,  1.09s/it]Loading train:  87%|████████▋ | 395/456 [07:05<01:08,  1.13s/it]Loading train:  87%|████████▋ | 396/456 [07:06<01:08,  1.13s/it]Loading train:  87%|████████▋ | 397/456 [07:07<01:00,  1.03s/it]Loading train:  87%|████████▋ | 398/456 [07:08<01:03,  1.10s/it]Loading train:  88%|████████▊ | 399/456 [07:09<01:01,  1.08s/it]Loading train:  88%|████████▊ | 400/456 [07:10<01:04,  1.15s/it]Loading train:  88%|████████▊ | 401/456 [07:11<01:02,  1.13s/it]Loading train:  88%|████████▊ | 402/456 [07:12<00:58,  1.09s/it]Loading train:  88%|████████▊ | 403/456 [07:14<00:59,  1.13s/it]Loading train:  89%|████████▊ | 404/456 [07:14<00:52,  1.01s/it]Loading train:  89%|████████▉ | 405/456 [07:15<00:50,  1.01it/s]Loading train:  89%|████████▉ | 406/456 [07:16<00:49,  1.01it/s]Loading train:  89%|████████▉ | 407/456 [07:17<00:50,  1.04s/it]Loading train:  89%|████████▉ | 408/456 [07:18<00:49,  1.03s/it]Loading train:  90%|████████▉ | 409/456 [07:20<00:50,  1.07s/it]Loading train:  90%|████████▉ | 410/456 [07:21<00:47,  1.03s/it]Loading train:  90%|█████████ | 411/456 [07:21<00:43,  1.03it/s]Loading train:  90%|█████████ | 412/456 [07:22<00:38,  1.13it/s]Loading train:  91%|█████████ | 413/456 [07:23<00:35,  1.23it/s]Loading train:  91%|█████████ | 414/456 [07:24<00:36,  1.15it/s]Loading train:  91%|█████████ | 415/456 [07:25<00:39,  1.04it/s]Loading train:  91%|█████████ | 416/456 [07:26<00:40,  1.02s/it]Loading train:  91%|█████████▏| 417/456 [07:27<00:39,  1.02s/it]Loading train:  92%|█████████▏| 418/456 [07:28<00:38,  1.01s/it]Loading train:  92%|█████████▏| 419/456 [07:29<00:34,  1.08it/s]Loading train:  92%|█████████▏| 420/456 [07:30<00:30,  1.16it/s]Loading train:  92%|█████████▏| 421/456 [07:31<00:35,  1.02s/it]Loading train:  93%|█████████▎| 422/456 [07:32<00:38,  1.12s/it]Loading train:  93%|█████████▎| 423/456 [07:33<00:37,  1.12s/it]Loading train:  93%|█████████▎| 424/456 [07:35<00:39,  1.25s/it]Loading train:  93%|█████████▎| 425/456 [07:36<00:39,  1.27s/it]Loading train:  93%|█████████▎| 426/456 [07:37<00:35,  1.18s/it]Loading train:  94%|█████████▎| 427/456 [07:39<00:36,  1.26s/it]Loading train:  94%|█████████▍| 428/456 [07:40<00:36,  1.30s/it]Loading train:  94%|█████████▍| 429/456 [07:42<00:36,  1.35s/it]Loading train:  94%|█████████▍| 430/456 [07:43<00:35,  1.36s/it]Loading train:  95%|█████████▍| 431/456 [07:44<00:31,  1.24s/it]Loading train:  95%|█████████▍| 432/456 [07:45<00:28,  1.19s/it]Loading train:  95%|█████████▍| 433/456 [07:47<00:29,  1.29s/it]Loading train:  95%|█████████▌| 434/456 [07:48<00:28,  1.28s/it]Loading train:  95%|█████████▌| 435/456 [07:49<00:29,  1.39s/it]Loading train:  96%|█████████▌| 436/456 [07:51<00:26,  1.33s/it]Loading train:  96%|█████████▌| 437/456 [07:52<00:24,  1.30s/it]Loading train:  96%|█████████▌| 438/456 [07:53<00:24,  1.38s/it]Loading train:  96%|█████████▋| 439/456 [07:55<00:22,  1.31s/it]Loading train:  96%|█████████▋| 440/456 [07:56<00:20,  1.25s/it]Loading train:  97%|█████████▋| 441/456 [07:57<00:18,  1.20s/it]Loading train:  97%|█████████▋| 442/456 [07:58<00:16,  1.17s/it]Loading train:  97%|█████████▋| 443/456 [07:59<00:14,  1.08s/it]Loading train:  97%|█████████▋| 444/456 [08:00<00:12,  1.08s/it]Loading train:  98%|█████████▊| 445/456 [08:01<00:12,  1.11s/it]Loading train:  98%|█████████▊| 446/456 [08:02<00:11,  1.14s/it]Loading train:  98%|█████████▊| 447/456 [08:03<00:10,  1.15s/it]Loading train:  98%|█████████▊| 448/456 [08:04<00:08,  1.08s/it]Loading train:  98%|█████████▊| 449/456 [08:05<00:07,  1.12s/it]Loading train:  99%|█████████▊| 450/456 [08:06<00:06,  1.07s/it]Loading train:  99%|█████████▉| 451/456 [08:08<00:05,  1.18s/it]Loading train:  99%|█████████▉| 452/456 [08:09<00:04,  1.18s/it]Loading train:  99%|█████████▉| 453/456 [08:10<00:03,  1.13s/it]Loading train: 100%|█████████▉| 454/456 [08:11<00:02,  1.10s/it]Loading train: 100%|█████████▉| 455/456 [08:12<00:01,  1.09s/it]Loading train: 100%|██████████| 456/456 [08:13<00:00,  1.03s/it]
concatenating: train:   0%|          | 0/456 [00:00<?, ?it/s]concatenating: train:   1%|▏         | 6/456 [00:00<00:07, 59.88it/s]concatenating: train:   5%|▌         | 24/456 [00:00<00:05, 74.79it/s]concatenating: train:   9%|▉         | 42/456 [00:00<00:04, 83.71it/s]concatenating: train:  11%|█         | 51/456 [00:00<00:05, 70.19it/s]concatenating: train:  16%|█▌        | 72/456 [00:00<00:04, 87.60it/s]concatenating: train:  19%|█▉        | 86/456 [00:00<00:03, 94.88it/s]concatenating: train:  21%|██▏       | 98/456 [00:00<00:04, 74.82it/s]concatenating: train:  24%|██▎       | 108/456 [00:01<00:04, 71.86it/s]concatenating: train:  26%|██▌       | 117/456 [00:01<00:05, 59.97it/s]concatenating: train:  27%|██▋       | 125/456 [00:01<00:05, 61.83it/s]concatenating: train:  29%|██▉       | 133/456 [00:01<00:05, 62.03it/s]concatenating: train:  31%|███       | 140/456 [00:01<00:05, 62.17it/s]concatenating: train:  32%|███▏      | 147/456 [00:01<00:05, 60.33it/s]concatenating: train:  34%|███▍      | 156/456 [00:01<00:04, 66.28it/s]concatenating: train:  37%|███▋      | 169/456 [00:02<00:03, 77.17it/s]concatenating: train:  40%|███▉      | 181/456 [00:02<00:03, 86.42it/s]concatenating: train:  42%|████▏     | 191/456 [00:02<00:02, 89.25it/s]concatenating: train:  44%|████▍     | 202/456 [00:02<00:02, 94.49it/s]concatenating: train:  48%|████▊     | 221/456 [00:02<00:02, 111.26it/s]concatenating: train:  53%|█████▎    | 243/456 [00:02<00:01, 130.52it/s]concatenating: train:  60%|█████▉    | 273/456 [00:02<00:01, 156.36it/s]concatenating: train:  64%|██████▍   | 293/456 [00:02<00:01, 154.96it/s]concatenating: train:  68%|██████▊   | 312/456 [00:03<00:01, 115.03it/s]concatenating: train:  73%|███████▎  | 335/456 [00:03<00:00, 134.35it/s]concatenating: train:  80%|███████▉  | 364/456 [00:03<00:00, 159.66it/s]concatenating: train:  86%|████████▌ | 390/456 [00:03<00:00, 180.13it/s]concatenating: train:  92%|█████████▏| 418/456 [00:03<00:00, 201.45it/s]concatenating: train:  97%|█████████▋| 442/456 [00:03<00:00, 209.27it/s]concatenating: train: 100%|██████████| 456/456 [00:03<00:00, 121.65it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:01<00:03,  1.22s/it]Loading test:  50%|█████     | 2/4 [00:02<00:02,  1.15s/it]Loading test:  75%|███████▌  | 3/4 [00:03<00:01,  1.21s/it]Loading test: 100%|██████████| 4/4 [00:04<00:00,  1.18s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 174.62it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 56, 88, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 56, 88, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 56, 88, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 56, 88, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 56, 88, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 88, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 56, 88, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 56, 88, 16)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 28, 44, 16)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28, 44, 16)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 44, 30)   4350        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 44, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 44, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 44, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 28, 44, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 28, 44, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 44, 46)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 22, 46)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 14, 22, 46)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 14, 22, 60)   24900       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 14, 22, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 14, 22, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 14, 22, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 14, 22, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 14, 22, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 14, 22, 106)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 14, 22, 106)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 28, 44, 30)   12750       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 28, 44, 76)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 28, 44, 30)   20550       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 28, 44, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________2019-07-07 16:46:01.299177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 16:46:01.299308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 16:46:01.299326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 16:46:01.299336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 16:46:01.299712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

activation_7 (Activation)       (None, 28, 44, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 28, 44, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 28, 44, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 28, 44, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 28, 44, 106)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 28, 44, 106)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 56, 88, 15)   6375        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 88, 31)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 56, 88, 15)   4200        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 56, 88, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 88, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 56, 88, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 56, 88, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 88, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 88, 46)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 56, 88, 46)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 56, 88, 13)   611         dropout_5[0][0]                  
==================================================================================================
Total params: 127,886
Trainable params: 127,286
Non-trainable params: 600
__________________________________________________________________________________________________
----- /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/model_weights.h5
 --- initialized from Model_3T /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2
------------------------------------------------------------------
class_weights [6.11551387e-02 2.80417065e-02 7.36205865e-02 1.00307357e-02
 2.46459952e-02 6.20541010e-03 7.62197172e-02 1.11197709e-01
 6.32300513e-02 1.29380128e-02 3.51235945e-01 1.81283761e-01
 1.95230038e-04]
Train on 17190 samples, validate on 142 samples
Epoch 1/300
 - 27s - loss: 1.3170 - acc: 0.9527 - mDice: 0.6066 - val_loss: 1.1861 - val_acc: 0.9673 - val_mDice: 0.6610

Epoch 00001: val_mDice improved from -inf to 0.66105, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 19s - loss: 1.1179 - acc: 0.9555 - mDice: 0.6416 - val_loss: 1.1423 - val_acc: 0.9668 - val_mDice: 0.6754

Epoch 00002: val_mDice improved from 0.66105 to 0.67537, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 17s - loss: 1.0609 - acc: 0.9566 - mDice: 0.6556 - val_loss: 1.1246 - val_acc: 0.9676 - val_mDice: 0.6724

Epoch 00003: val_mDice did not improve from 0.67537
Epoch 4/300
 - 18s - loss: 1.0249 - acc: 0.9574 - mDice: 0.6654 - val_loss: 1.1697 - val_acc: 0.9676 - val_mDice: 0.6759

Epoch 00004: val_mDice improved from 0.67537 to 0.67586, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 18s - loss: 1.0003 - acc: 0.9580 - mDice: 0.6732 - val_loss: 1.1896 - val_acc: 0.9673 - val_mDice: 0.6801

Epoch 00005: val_mDice improved from 0.67586 to 0.68006, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 17s - loss: 0.9779 - acc: 0.9585 - mDice: 0.6794 - val_loss: 1.1800 - val_acc: 0.9670 - val_mDice: 0.6800

Epoch 00006: val_mDice did not improve from 0.68006
Epoch 7/300
 - 18s - loss: 0.9621 - acc: 0.9589 - mDice: 0.6840 - val_loss: 1.1849 - val_acc: 0.9671 - val_mDice: 0.6842

Epoch 00007: val_mDice improved from 0.68006 to 0.68416, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 18s - loss: 0.9483 - acc: 0.9592 - mDice: 0.6885 - val_loss: 1.2417 - val_acc: 0.9670 - val_mDice: 0.6789

Epoch 00008: val_mDice did not improve from 0.68416
Epoch 9/300
 - 17s - loss: 0.9380 - acc: 0.9595 - mDice: 0.6916 - val_loss: 1.2111 - val_acc: 0.9671 - val_mDice: 0.6818

Epoch 00009: val_mDice did not improve from 0.68416
Epoch 10/300
 - 19s - loss: 0.9247 - acc: 0.9597 - mDice: 0.6958 - val_loss: 1.2276 - val_acc: 0.9668 - val_mDice: 0.6813

Epoch 00010: val_mDice did not improve from 0.68416
Epoch 11/300
 - 16s - loss: 0.9143 - acc: 0.9600 - mDice: 0.6990 - val_loss: 1.2211 - val_acc: 0.9670 - val_mDice: 0.6853

Epoch 00011: val_mDice improved from 0.68416 to 0.68530, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 12/300
 - 16s - loss: 0.9079 - acc: 0.9602 - mDice: 0.7009 - val_loss: 1.1932 - val_acc: 0.9676 - val_mDice: 0.6853

Epoch 00012: val_mDice improved from 0.68530 to 0.68531, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 13/300
 - 17s - loss: 0.8996 - acc: 0.9604 - mDice: 0.7039 - val_loss: 1.2418 - val_acc: 0.9671 - val_mDice: 0.6882

Epoch 00013: val_mDice improved from 0.68531 to 0.68822, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 14/300
 - 15s - loss: 0.8938 - acc: 0.9605 - mDice: 0.7057 - val_loss: 1.2395 - val_acc: 0.9663 - val_mDice: 0.6848

Epoch 00014: val_mDice did not improve from 0.68822
Epoch 15/300
 - 15s - loss: 0.8872 - acc: 0.9607 - mDice: 0.7076 - val_loss: 1.2783 - val_acc: 0.9664 - val_mDice: 0.6894

Epoch 00015: val_mDice improved from 0.68822 to 0.68941, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 16/300
 - 16s - loss: 0.8826 - acc: 0.9608 - mDice: 0.7093 - val_loss: 1.2520 - val_acc: 0.9664 - val_mDice: 0.6842

Epoch 00016: val_mDice did not improve from 0.68941
Epoch 17/300
 - 15s - loss: 0.8766 - acc: 0.9610 - mDice: 0.7112 - val_loss: 1.2654 - val_acc: 0.9665 - val_mDice: 0.6896

Epoch 00017: val_mDice improved from 0.68941 to 0.68958, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 18/300
 - 15s - loss: 0.8693 - acc: 0.9611 - mDice: 0.7132 - val_loss: 1.2702 - val_acc: 0.9667 - val_mDice: 0.6867

Epoch 00018: val_mDice did not improve from 0.68958
Epoch 19/300
 - 15s - loss: 0.8641 - acc: 0.9612 - mDice: 0.7150 - val_loss: 1.2912 - val_acc: 0.9665 - val_mDice: 0.6888

Epoch 00019: val_mDice did not improve from 0.68958
Epoch 20/300
 - 15s - loss: 0.8608 - acc: 0.9614 - mDice: 0.7162 - val_loss: 1.2937 - val_acc: 0.9665 - val_mDice: 0.6876

Epoch 00020: val_mDice did not improve from 0.68958
Epoch 21/300
 - 16s - loss: 0.8551 - acc: 0.9615 - mDice: 0.7181 - val_loss: 1.2743 - val_acc: 0.9668 - val_mDice: 0.6862

Epoch 00021: val_mDice did not improve from 0.68958
Epoch 22/300
 - 16s - loss: 0.8523 - acc: 0.9615 - mDice: 0.7187 - val_loss: 1.2608 - val_acc: 0.9665 - val_mDice: 0.6896

Epoch 00022: val_mDice improved from 0.68958 to 0.68964, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 23/300
 - 15s - loss: 0.8491 - acc: 0.9616 - mDice: 0.7199 - val_loss: 1.2948 - val_acc: 0.9665 - val_mDice: 0.6911

Epoch 00023: val_mDice improved from 0.68964 to 0.69114, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 24/300
 - 15s - loss: 0.8458 - acc: 0.9617 - mDice: 0.7211 - val_loss: 1.2965 - val_acc: 0.9666 - val_mDice: 0.6890

Epoch 00024: val_mDice did not improve from 0.69114
Epoch 25/300
 - 15s - loss: 0.8427 - acc: 0.9618 - mDice: 0.7218 - val_loss: 1.2758 - val_acc: 0.9663 - val_mDice: 0.6907

Epoch 00025: val_mDice did not improve from 0.69114
Epoch 26/300
 - 15s - loss: 0.8396 - acc: 0.9619 - mDice: 0.7231 - val_loss: 1.3238 - val_acc: 0.9664 - val_mDice: 0.6873

Epoch 00026: val_mDice did not improve from 0.69114
Epoch 27/300
 - 15s - loss: 0.8353 - acc: 0.9620 - mDice: 0.7245 - val_loss: 1.3040 - val_acc: 0.9666 - val_mDice: 0.6905

Epoch 00027: val_mDice did not improve from 0.69114
Epoch 28/300
 - 16s - loss: 0.8330 - acc: 0.9620 - mDice: 0.7250 - val_loss: 1.3132 - val_acc: 0.9663 - val_mDice: 0.6921

Epoch 00028: val_mDice improved from 0.69114 to 0.69214, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 29/300
 - 15s - loss: 0.8304 - acc: 0.9620 - mDice: 0.7260 - val_loss: 1.3253 - val_acc: 0.9663 - val_mDice: 0.6905

Epoch 00029: val_mDice did not improve from 0.69214
Epoch 30/300
 - 15s - loss: 0.8285 - acc: 0.9622 - mDice: 0.7268 - val_loss: 1.2970 - val_acc: 0.9663 - val_mDice: 0.6912

Epoch 00030: val_mDice did not improve from 0.69214
Epoch 31/300
 - 15s - loss: 0.8263 - acc: 0.9622 - mDice: 0.7277 - val_loss: 1.3376 - val_acc: 0.9656 - val_mDice: 0.6896

Epoch 00031: val_mDice did not improve from 0.69214
Epoch 32/300
 - 15s - loss: 0.8217 - acc: 0.9623 - mDice: 0.7289 - val_loss: 1.3445 - val_acc: 0.9664 - val_mDice: 0.6887

Epoch 00032: val_mDice did not improve from 0.69214
Epoch 33/300
 - 16s - loss: 0.8201 - acc: 0.9624 - mDice: 0.7293 - val_loss: 1.3207 - val_acc: 0.9664 - val_mDice: 0.6918

Epoch 00033: val_mDice did not improve from 0.69214
Epoch 34/300
 - 16s - loss: 0.8181 - acc: 0.9624 - mDice: 0.7301 - val_loss: 1.3277 - val_acc: 0.9665 - val_mDice: 0.6887

Epoch 00034: val_mDice did not improve from 0.69214
Epoch 35/300
 - 15s - loss: 0.8157 - acc: 0.9625 - mDice: 0.7307 - val_loss: 1.3592 - val_acc: 0.9661 - val_mDice: 0.6870

Epoch 00035: val_mDice did not improve from 0.69214
Epoch 36/300
 - 16s - loss: 0.8133 - acc: 0.9626 - mDice: 0.7316 - val_loss: 1.3336 - val_acc: 0.9666 - val_mDice: 0.6915

Epoch 00036: val_mDice did not improve from 0.69214
Epoch 37/300
 - 15s - loss: 0.8115 - acc: 0.9626 - mDice: 0.7322 - val_loss: 1.3085 - val_acc: 0.9664 - val_mDice: 0.6917

Epoch 00037: val_mDice did not improve from 0.69214
Epoch 38/300
 - 15s - loss: 0.8105 - acc: 0.9626 - mDice: 0.7324 - val_loss: 1.3842 - val_acc: 0.9658 - val_mDice: 0.6866

Epoch 00038: val_mDice did not improve from 0.69214
Epoch 39/300
 - 15s - loss: 0.8074 - acc: 0.9627 - mDice: 0.7335 - val_loss: 1.3348 - val_acc: 0.9662 - val_mDice: 0.6930

Epoch 00039: val_mDice improved from 0.69214 to 0.69300, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 40/300
 - 16s - loss: 0.8059 - acc: 0.9628 - mDice: 0.7341 - val_loss: 1.3556 - val_acc: 0.9658 - val_mDice: 0.6910

Epoch 00040: val_mDice did not improve from 0.69300
Epoch 41/300
 - 15s - loss: 0.8042 - acc: 0.9628 - mDice: 0.7346 - val_loss: 1.4039 - val_acc: 0.9658 - val_mDice: 0.6885

Epoch 00041: val_mDice did not improve from 0.69300
Epoch 42/300
 - 15s - loss: 0.8023 - acc: 0.9629 - mDice: 0.7351 - val_loss: 1.3901 - val_acc: 0.9663 - val_mDice: 0.6869

Epoch 00042: val_mDice did not improve from 0.69300
Epoch 43/300
 - 15s - loss: 0.8004 - acc: 0.9629 - mDice: 0.7353 - val_loss: 1.3297 - val_acc: 0.9661 - val_mDice: 0.6914

Epoch 00043: val_mDice did not improve from 0.69300
Epoch 44/300
 - 15s - loss: 0.7996 - acc: 0.9629 - mDice: 0.7362 - val_loss: 1.4009 - val_acc: 0.9660 - val_mDice: 0.6889

Epoch 00044: val_mDice did not improve from 0.69300
Epoch 45/300
 - 15s - loss: 0.7961 - acc: 0.9630 - mDice: 0.7371 - val_loss: 1.3711 - val_acc: 0.9663 - val_mDice: 0.6893

Epoch 00045: val_mDice did not improve from 0.69300
Epoch 46/300
 - 15s - loss: 0.7936 - acc: 0.9631 - mDice: 0.7382 - val_loss: 1.3567 - val_acc: 0.9664 - val_mDice: 0.6926

Epoch 00046: val_mDice did not improve from 0.69300
Epoch 47/300
 - 16s - loss: 0.7938 - acc: 0.9630 - mDice: 0.7376 - val_loss: 1.3538 - val_acc: 0.9661 - val_mDice: 0.6932

Epoch 00047: val_mDice improved from 0.69300 to 0.69325, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 48/300
 - 15s - loss: 0.7922 - acc: 0.9631 - mDice: 0.7386 - val_loss: 1.3269 - val_acc: 0.9662 - val_mDice: 0.6955

Epoch 00048: val_mDice improved from 0.69325 to 0.69549, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 49/300
 - 15s - loss: 0.7914 - acc: 0.9631 - mDice: 0.7389 - val_loss: 1.3851 - val_acc: 0.9667 - val_mDice: 0.6917

Epoch 00049: val_mDice did not improve from 0.69549
Epoch 50/300
 - 15s - loss: 0.7904 - acc: 0.9632 - mDice: 0.7389 - val_loss: 1.3589 - val_acc: 0.9657 - val_mDice: 0.6936

Epoch 00050: val_mDice did not improve from 0.69549
Epoch 51/300
 - 15s - loss: 0.7871 - acc: 0.9632 - mDice: 0.7401 - val_loss: 1.3518 - val_acc: 0.9667 - val_mDice: 0.6926

Epoch 00051: val_mDice did not improve from 0.69549
Epoch 52/300
 - 15s - loss: 0.7861 - acc: 0.9633 - mDice: 0.7404 - val_loss: 1.4122 - val_acc: 0.9655 - val_mDice: 0.6896

Epoch 00052: val_mDice did not improve from 0.69549
Epoch 53/300
 - 15s - loss: 0.7843 - acc: 0.9633 - mDice: 0.7411 - val_loss: 1.3242 - val_acc: 0.9667 - val_mDice: 0.6954

Epoch 00053: val_mDice did not improve from 0.69549
Epoch 54/300
 - 16s - loss: 0.7826 - acc: 0.9634 - mDice: 0.7417 - val_loss: 1.3614 - val_acc: 0.9664 - val_mDice: 0.6952

Epoch 00054: val_mDice did not improve from 0.69549
Epoch 55/300
 - 15s - loss: 0.7828 - acc: 0.9633 - mDice: 0.7416 - val_loss: 1.3642 - val_acc: 0.9661 - val_mDice: 0.6959

Epoch 00055: val_mDice improved from 0.69549 to 0.69586, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 56/300
 - 15s - loss: 0.7821 - acc: 0.9633 - mDice: 0.7420 - val_loss: 1.3657 - val_acc: 0.9661 - val_mDice: 0.6904

Epoch 00056: val_mDice did not improve from 0.69586
Epoch 57/300
 - 15s - loss: 0.7782 - acc: 0.9635 - mDice: 0.7430 - val_loss: 1.4415 - val_acc: 0.9658 - val_mDice: 0.6922

Epoch 00057: val_mDice did not improve from 0.69586
Epoch 58/300
 - 15s - loss: 0.7807 - acc: 0.9635 - mDice: 0.7424 - val_loss: 1.4056 - val_acc: 0.9665 - val_mDice: 0.6921

Epoch 00058: val_mDice did not improve from 0.69586
Epoch 59/300
 - 15s - loss: 0.7802 - acc: 0.9634 - mDice: 0.7428 - val_loss: 1.3931 - val_acc: 0.9662 - val_mDice: 0.6933

Epoch 00059: val_mDice did not improve from 0.69586
Epoch 60/300
 - 15s - loss: 0.7777 - acc: 0.9635 - mDice: 0.7432 - val_loss: 1.4166 - val_acc: 0.9661 - val_mDice: 0.6879

Epoch 00060: val_mDice did not improve from 0.69586
Epoch 61/300
 - 16s - loss: 0.7762 - acc: 0.9635 - mDice: 0.7437 - val_loss: 1.3999 - val_acc: 0.9665 - val_mDice: 0.6923

Epoch 00061: val_mDice did not improve from 0.69586
Epoch 62/300
 - 15s - loss: 0.7739 - acc: 0.9636 - mDice: 0.7443 - val_loss: 1.4066 - val_acc: 0.9658 - val_mDice: 0.6942

Epoch 00062: val_mDice did not improve from 0.69586
Epoch 63/300
 - 15s - loss: 0.7742 - acc: 0.9636 - mDice: 0.7444 - val_loss: 1.3724 - val_acc: 0.9667 - val_mDice: 0.6900

Epoch 00063: val_mDice did not improve from 0.69586
Epoch 64/300
 - 15s - loss: 0.7714 - acc: 0.9636 - mDice: 0.7452 - val_loss: 1.3986 - val_acc: 0.9653 - val_mDice: 0.6907

Epoch 00064: val_mDice did not improve from 0.69586
Epoch 65/300
 - 15s - loss: 0.7703 - acc: 0.9637 - mDice: 0.7456 - val_loss: 1.4232 - val_acc: 0.9663 - val_mDice: 0.6887

Epoch 00065: val_mDice did not improve from 0.69586
Epoch 66/300
 - 15s - loss: 0.7712 - acc: 0.9637 - mDice: 0.7454 - val_loss: 1.3824 - val_acc: 0.9658 - val_mDice: 0.6945

Epoch 00066: val_mDice did not improve from 0.69586
Epoch 67/300
 - 15s - loss: 0.7706 - acc: 0.9637 - mDice: 0.7456 - val_loss: 1.3999 - val_acc: 0.9662 - val_mDice: 0.6928

Epoch 00067: val_mDice did not improve from 0.69586
Epoch 68/300
 - 16s - loss: 0.7673 - acc: 0.9638 - mDice: 0.7465 - val_loss: 1.4268 - val_acc: 0.9654 - val_mDice: 0.6904

Epoch 00068: val_mDice did not improve from 0.69586
Epoch 69/300
 - 15s - loss: 0.7681 - acc: 0.9638 - mDice: 0.7464 - val_loss: 1.3613 - val_acc: 0.9662 - val_mDice: 0.6955

Epoch 00069: val_mDice did not improve from 0.69586
Epoch 70/300
 - 15s - loss: 0.7668 - acc: 0.9638 - mDice: 0.7468 - val_loss: 1.3850 - val_acc: 0.9663 - val_mDice: 0.6921

Epoch 00070: val_mDice did not improve from 0.69586
Epoch 71/300
 - 15s - loss: 0.7657 - acc: 0.9638 - mDice: 0.7470 - val_loss: 1.3897 - val_acc: 0.9659 - val_mDice: 0.6928

Epoch 00071: val_mDice did not improve from 0.69586
Epoch 72/300
 - 15s - loss: 0.7667 - acc: 0.9638 - mDice: 0.7471 - val_loss: 1.3858 - val_acc: 0.9663 - val_mDice: 0.6949

Epoch 00072: val_mDice did not improve from 0.69586
Epoch 73/300
 - 15s - loss: 0.7653 - acc: 0.9639 - mDice: 0.7471 - val_loss: 1.3686 - val_acc: 0.9659 - val_mDice: 0.6899

Epoch 00073: val_mDice did not improve from 0.69586
Epoch 74/300
 - 15s - loss: 0.7656 - acc: 0.9639 - mDice: 0.7471 - val_loss: 1.4168 - val_acc: 0.9662 - val_mDice: 0.6896

Epoch 00074: val_mDice did not improve from 0.69586
Epoch 75/300
 - 16s - loss: 0.7608 - acc: 0.9639 - mDice: 0.7487 - val_loss: 1.4309 - val_acc: 0.9662 - val_mDice: 0.6901

Epoch 00075: val_mDice did not improve from 0.69586
Epoch 76/300
 - 15s - loss: 0.7619 - acc: 0.9639 - mDice: 0.7486 - val_loss: 1.3766 - val_acc: 0.9660 - val_mDice: 0.6943

Epoch 00076: val_mDice did not improve from 0.69586
Epoch 77/300
 - 15s - loss: 0.7620 - acc: 0.9639 - mDice: 0.7486 - val_loss: 1.3953 - val_acc: 0.9658 - val_mDice: 0.6918

Epoch 00077: val_mDice did not improve from 0.69586
Epoch 78/300
 - 15s - loss: 0.7599 - acc: 0.9639 - mDice: 0.7491 - val_loss: 1.3928 - val_acc: 0.9658 - val_mDice: 0.6972

Epoch 00078: val_mDice improved from 0.69586 to 0.69720, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 79/300
 - 16s - loss: 0.7596 - acc: 0.9640 - mDice: 0.7492 - val_loss: 1.3795 - val_acc: 0.9652 - val_mDice: 0.6943

Epoch 00079: val_mDice did not improve from 0.69720
Epoch 80/300
 - 15s - loss: 0.7589 - acc: 0.9640 - mDice: 0.7494 - val_loss: 1.3714 - val_acc: 0.9661 - val_mDice: 0.6961

Epoch 00080: val_mDice did not improve from 0.69720
Epoch 81/300
 - 15s - loss: 0.7582 - acc: 0.9641 - mDice: 0.7498 - val_loss: 1.4192 - val_acc: 0.9659 - val_mDice: 0.6946

Epoch 00081: val_mDice did not improve from 0.69720
Epoch 82/300
 - 15s - loss: 0.7566 - acc: 0.9640 - mDice: 0.7501 - val_loss: 1.4039 - val_acc: 0.9660 - val_mDice: 0.6917

Epoch 00082: val_mDice did not improve from 0.69720
Epoch 83/300
 - 15s - loss: 0.7574 - acc: 0.9641 - mDice: 0.7499 - val_loss: 1.3828 - val_acc: 0.9657 - val_mDice: 0.6963

Epoch 00083: val_mDice did not improve from 0.69720
Epoch 84/300
 - 15s - loss: 0.7552 - acc: 0.9641 - mDice: 0.7507 - val_loss: 1.4077 - val_acc: 0.9660 - val_mDice: 0.6903

Epoch 00084: val_mDice did not improve from 0.69720
Epoch 85/300
 - 16s - loss: 0.7545 - acc: 0.9641 - mDice: 0.7509 - val_loss: 1.4120 - val_acc: 0.9656 - val_mDice: 0.6936

Epoch 00085: val_mDice did not improve from 0.69720
Epoch 86/300
 - 15s - loss: 0.7535 - acc: 0.9641 - mDice: 0.7512 - val_loss: 1.3774 - val_acc: 0.9662 - val_mDice: 0.6970

Epoch 00086: val_mDice did not improve from 0.69720
Epoch 87/300
 - 15s - loss: 0.7532 - acc: 0.9642 - mDice: 0.7512 - val_loss: 1.4212 - val_acc: 0.9662 - val_mDice: 0.6952

Epoch 00087: val_mDice did not improve from 0.69720
Epoch 88/300
 - 15s - loss: 0.7536 - acc: 0.9642 - mDice: 0.7511 - val_loss: 1.3930 - val_acc: 0.9662 - val_mDice: 0.6942

Epoch 00088: val_mDice did not improve from 0.69720
Epoch 89/300
 - 15s - loss: 0.7520 - acc: 0.9642 - mDice: 0.7518 - val_loss: 1.4294 - val_acc: 0.9659 - val_mDice: 0.6975

Epoch 00089: val_mDice improved from 0.69720 to 0.69749, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 90/300
 - 15s - loss: 0.7524 - acc: 0.9642 - mDice: 0.7514 - val_loss: 1.4257 - val_acc: 0.9661 - val_mDice: 0.6937

Epoch 00090: val_mDice did not improve from 0.69749
Epoch 91/300
 - 15s - loss: 0.7516 - acc: 0.9642 - mDice: 0.7517 - val_loss: 1.3963 - val_acc: 0.9659 - val_mDice: 0.6964

Epoch 00091: val_mDice did not improve from 0.69749
Epoch 92/300
 - 16s - loss: 0.7511 - acc: 0.9642 - mDice: 0.7520 - val_loss: 1.4148 - val_acc: 0.9658 - val_mDice: 0.6910

Epoch 00092: val_mDice did not improve from 0.69749
Epoch 93/300
 - 15s - loss: 0.7490 - acc: 0.9642 - mDice: 0.7528 - val_loss: 1.3945 - val_acc: 0.9661 - val_mDice: 0.6941

Epoch 00093: val_mDice did not improve from 0.69749
Epoch 94/300
 - 15s - loss: 0.7470 - acc: 0.9643 - mDice: 0.7533 - val_loss: 1.4060 - val_acc: 0.9661 - val_mDice: 0.6975

Epoch 00094: val_mDice improved from 0.69749 to 0.69755, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 95/300
 - 15s - loss: 0.7493 - acc: 0.9643 - mDice: 0.7527 - val_loss: 1.4619 - val_acc: 0.9658 - val_mDice: 0.6921

Epoch 00095: val_mDice did not improve from 0.69755
Epoch 96/300
 - 15s - loss: 0.7475 - acc: 0.9643 - mDice: 0.7532 - val_loss: 1.3918 - val_acc: 0.9657 - val_mDice: 0.6958

Epoch 00096: val_mDice did not improve from 0.69755
Epoch 97/300
 - 15s - loss: 0.7464 - acc: 0.9643 - mDice: 0.7534 - val_loss: 1.4305 - val_acc: 0.9659 - val_mDice: 0.6958

Epoch 00097: val_mDice did not improve from 0.69755
Epoch 98/300
 - 15s - loss: 0.7469 - acc: 0.9644 - mDice: 0.7534 - val_loss: 1.3993 - val_acc: 0.9660 - val_mDice: 0.6976

Epoch 00098: val_mDice improved from 0.69755 to 0.69758, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 99/300
 - 16s - loss: 0.7448 - acc: 0.9644 - mDice: 0.7541 - val_loss: 1.3801 - val_acc: 0.9660 - val_mDice: 0.6937

Epoch 00099: val_mDice did not improve from 0.69758
Epoch 100/300
 - 15s - loss: 0.7442 - acc: 0.9644 - mDice: 0.7542 - val_loss: 1.4576 - val_acc: 0.9660 - val_mDice: 0.6945

Epoch 00100: val_mDice did not improve from 0.69758
Epoch 101/300
 - 15s - loss: 0.7448 - acc: 0.9644 - mDice: 0.7540 - val_loss: 1.4445 - val_acc: 0.9657 - val_mDice: 0.6945

Epoch 00101: val_mDice did not improve from 0.69758
Epoch 102/300
 - 15s - loss: 0.7445 - acc: 0.9644 - mDice: 0.7541 - val_loss: 1.3906 - val_acc: 0.9660 - val_mDice: 0.6962

Epoch 00102: val_mDice did not improve from 0.69758
Epoch 103/300
 - 15s - loss: 0.7451 - acc: 0.9645 - mDice: 0.7540 - val_loss: 1.3682 - val_acc: 0.9664 - val_mDice: 0.7002

Epoch 00103: val_mDice improved from 0.69758 to 0.70018, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 104/300
 - 15s - loss: 0.7423 - acc: 0.9645 - mDice: 0.7546 - val_loss: 1.4453 - val_acc: 0.9661 - val_mDice: 0.6916

Epoch 00104: val_mDice did not improve from 0.70018
Epoch 105/300
 - 15s - loss: 0.7413 - acc: 0.9645 - mDice: 0.7553 - val_loss: 1.4047 - val_acc: 0.9662 - val_mDice: 0.6952

Epoch 00105: val_mDice did not improve from 0.70018
Epoch 106/300
 - 16s - loss: 0.7412 - acc: 0.9645 - mDice: 0.7553 - val_loss: 1.4422 - val_acc: 0.9654 - val_mDice: 0.6911

Epoch 00106: val_mDice did not improve from 0.70018
Epoch 107/300
 - 15s - loss: 0.7391 - acc: 0.9646 - mDice: 0.7556 - val_loss: 1.4204 - val_acc: 0.9660 - val_mDice: 0.6980

Epoch 00107: val_mDice did not improve from 0.70018
Epoch 108/300
 - 15s - loss: 0.7409 - acc: 0.9645 - mDice: 0.7552 - val_loss: 1.4115 - val_acc: 0.9658 - val_mDice: 0.6965

Epoch 00108: val_mDice did not improve from 0.70018
Epoch 109/300
 - 15s - loss: 0.7399 - acc: 0.9646 - mDice: 0.7558 - val_loss: 1.4144 - val_acc: 0.9657 - val_mDice: 0.6932

Epoch 00109: val_mDice did not improve from 0.70018
Epoch 110/300
 - 15s - loss: 0.7406 - acc: 0.9646 - mDice: 0.7554 - val_loss: 1.4353 - val_acc: 0.9658 - val_mDice: 0.6931

Epoch 00110: val_mDice did not improve from 0.70018
Epoch 111/300
 - 15s - loss: 0.7391 - acc: 0.9646 - mDice: 0.7559 - val_loss: 1.4383 - val_acc: 0.9657 - val_mDice: 0.6967

Epoch 00111: val_mDice did not improve from 0.70018
Epoch 112/300
 - 15s - loss: 0.7393 - acc: 0.9646 - mDice: 0.7558 - val_loss: 1.4848 - val_acc: 0.9656 - val_mDice: 0.6938

Epoch 00112: val_mDice did not improve from 0.70018
Epoch 113/300
 - 15s - loss: 0.7395 - acc: 0.9646 - mDice: 0.7561 - val_loss: 1.4346 - val_acc: 0.9656 - val_mDice: 0.6949

Epoch 00113: val_mDice did not improve from 0.70018
Epoch 114/300
 - 16s - loss: 0.7370 - acc: 0.9647 - mDice: 0.7569 - val_loss: 1.4671 - val_acc: 0.9658 - val_mDice: 0.6962

Epoch 00114: val_mDice did not improve from 0.70018
Epoch 115/300
 - 15s - loss: 0.7372 - acc: 0.9646 - mDice: 0.7562 - val_loss: 1.4798 - val_acc: 0.9657 - val_mDice: 0.6947

Epoch 00115: val_mDice did not improve from 0.70018
Epoch 116/300
 - 15s - loss: 0.7386 - acc: 0.9646 - mDice: 0.7563 - val_loss: 1.4227 - val_acc: 0.9661 - val_mDice: 0.6959

Epoch 00116: val_mDice did not improve from 0.70018
Epoch 117/300
 - 15s - loss: 0.7360 - acc: 0.9646 - mDice: 0.7568 - val_loss: 1.4262 - val_acc: 0.9659 - val_mDice: 0.6978

Epoch 00117: val_mDice did not improve from 0.70018
Epoch 118/300
 - 15s - loss: 0.7355 - acc: 0.9647 - mDice: 0.7570 - val_loss: 1.4516 - val_acc: 0.9666 - val_mDice: 0.6958

Epoch 00118: val_mDice did not improve from 0.70018
Epoch 119/300
 - 15s - loss: 0.7350 - acc: 0.9647 - mDice: 0.7574 - val_loss: 1.4232 - val_acc: 0.9662 - val_mDice: 0.6941

Epoch 00119: val_mDice did not improve from 0.70018
Epoch 120/300
 - 15s - loss: 0.7379 - acc: 0.9647 - mDice: 0.7560 - val_loss: 1.4288 - val_acc: 0.9662 - val_mDice: 0.6988

Epoch 00120: val_mDice did not improve from 0.70018
Epoch 121/300
 - 16s - loss: 0.7349 - acc: 0.9647 - mDice: 0.7575 - val_loss: 1.4316 - val_acc: 0.9656 - val_mDice: 0.6976

Epoch 00121: val_mDice did not improve from 0.70018
Epoch 122/300
 - 15s - loss: 0.7331 - acc: 0.9648 - mDice: 0.7579 - val_loss: 1.4573 - val_acc: 0.9660 - val_mDice: 0.6952

Epoch 00122: val_mDice did not improve from 0.70018
Epoch 123/300
 - 15s - loss: 0.7349 - acc: 0.9647 - mDice: 0.7573 - val_loss: 1.4404 - val_acc: 0.9661 - val_mDice: 0.6954

Epoch 00123: val_mDice did not improve from 0.70018
Epoch 124/300
 - 15s - loss: 0.7329 - acc: 0.9648 - mDice: 0.7579 - val_loss: 1.4274 - val_acc: 0.9661 - val_mDice: 0.6951

Epoch 00124: val_mDice did not improve from 0.70018
Epoch 125/300
 - 15s - loss: 0.7309 - acc: 0.9648 - mDice: 0.7583 - val_loss: 1.4385 - val_acc: 0.9662 - val_mDice: 0.6943

Epoch 00125: val_mDice did not improve from 0.70018
Epoch 126/300
 - 15s - loss: 0.7309 - acc: 0.9648 - mDice: 0.7585 - val_loss: 1.4616 - val_acc: 0.9656 - val_mDice: 0.6953

Epoch 00126: val_mDice did not improve from 0.70018
Epoch 127/300
 - 16s - loss: 0.7300 - acc: 0.9648 - mDice: 0.7590 - val_loss: 1.4429 - val_acc: 0.9662 - val_mDice: 0.6947

Epoch 00127: val_mDice did not improve from 0.70018
Epoch 128/300
 - 15s - loss: 0.7319 - acc: 0.9648 - mDice: 0.7585 - val_loss: 1.4476 - val_acc: 0.9660 - val_mDice: 0.6961

Epoch 00128: val_mDice did not improve from 0.70018
Epoch 129/300
 - 15s - loss: 0.7321 - acc: 0.9648 - mDice: 0.7582 - val_loss: 1.4427 - val_acc: 0.9662 - val_mDice: 0.6985

Epoch 00129: val_mDice did not improve from 0.70018
Epoch 130/300
 - 16s - loss: 0.7325 - acc: 0.9648 - mDice: 0.7581 - val_loss: 1.5019 - val_acc: 0.9660 - val_mDice: 0.6912

Epoch 00130: val_mDice did not improve from 0.70018
Epoch 131/300
 - 15s - loss: 0.7294 - acc: 0.9648 - mDice: 0.7589 - val_loss: 1.4004 - val_acc: 0.9659 - val_mDice: 0.6968

Epoch 00131: val_mDice did not improve from 0.70018
Epoch 132/300
 - 15s - loss: 0.7305 - acc: 0.9648 - mDice: 0.7589 - val_loss: 1.4467 - val_acc: 0.9663 - val_mDice: 0.6933

Epoch 00132: val_mDice did not improve from 0.70018
Epoch 133/300
 - 15s - loss: 0.7303 - acc: 0.9648 - mDice: 0.7587 - val_loss: 1.4542 - val_acc: 0.9658 - val_mDice: 0.6972

Epoch 00133: val_mDice did not improve from 0.70018
Restoring model weights from the end of the best epoch
Epoch 00133: early stopping
{'val_loss': [1.1860546637588822, 1.142344337114146, 1.1245976333886805, 1.1697278879058193, 1.1896126790785453, 1.1800465214420373, 1.18487256513515, 1.2416888567763316, 1.2110579215304953, 1.227592537940388, 1.2210893622586425, 1.1932024787849105, 1.2417850292904276, 1.2394703131326488, 1.2783482989794772, 1.2520060119494585, 1.2653725441073027, 1.2702343035751664, 1.2912473787724132, 1.2936954305205546, 1.2742891966457097, 1.2608412663701554, 1.2947905987081394, 1.2965054276963355, 1.2757695015047636, 1.3237629071087904, 1.3039938589216957, 1.3132263547937635, 1.3253030751792478, 1.2969730026285413, 1.337576602546262, 1.3445487484126024, 1.3206640087382895, 1.3276964073449793, 1.3592064716446568, 1.3335672784859025, 1.3084512873434684, 1.3842458112139098, 1.3347961424102246, 1.3556267946538791, 1.4039017675628125, 1.3901067644777432, 1.3297478976384016, 1.4008898432825652, 1.3711226213146264, 1.356657431159221, 1.3537936613593302, 1.3269273034283813, 1.3850741604684105, 1.3588879989906095, 1.3517844005369803, 1.4121671570858485, 1.3241607546806335, 1.3613799592139015, 1.3641582022250538, 1.3657049897690894, 1.441515843633195, 1.4055619374127455, 1.3931104952180888, 1.4166215062141418, 1.3999245653689747, 1.4066396993650516, 1.3723586671788928, 1.3985669898315214, 1.4231625879314584, 1.3824268243682216, 1.3999271753808142, 1.4267551109824381, 1.361346296861138, 1.3850078230172815, 1.3897445688784962, 1.3858036633948205, 1.3686046785032246, 1.416828455219806, 1.4309388944800472, 1.3766117129527347, 1.3952772600550047, 1.3928230623124351, 1.3795307009992466, 1.371427468850579, 1.4192365592634175, 1.4038967246740637, 1.3827938882397934, 1.4077251880941257, 1.4119757002508138, 1.3774102103542274, 1.4211704395186733, 1.392988168857467, 1.4293985106575657, 1.4256617317736988, 1.396298667074929, 1.4147675986021337, 1.3945023274757493, 1.406029570270592, 1.461884552324322, 1.391847872398269, 1.4304887946222868, 1.3992704379726464, 1.380082672750446, 1.457647335361427, 1.444457775270435, 1.390591258734045, 1.3681789972412755, 1.4453198380873238, 1.404677260089928, 1.442192040698629, 1.4204143185011098, 1.4115423459402272, 1.414444711846365, 1.4352990288129994, 1.438280333935375, 1.484831235778164, 1.4346318790610408, 1.4671296359787525, 1.4797620378749472, 1.4227496654214993, 1.4261585440434201, 1.4515781117157198, 1.423201126951567, 1.4288142659294774, 1.4316484726650613, 1.4572891517424247, 1.4404277683983386, 1.4273833506543872, 1.438479955767242, 1.4616344722223953, 1.4429215981926717, 1.4475628893140335, 1.4426830142316684, 1.5018631547269687, 1.4004097018443362, 1.4467036917176046, 1.4541859895410671], 'val_acc': [0.9673281043348178, 0.9667922375907361, 0.9676453815379613, 0.9676282204372783, 0.9672766638473725, 0.9670322915198097, 0.9671094677817653, 0.9669766014730427, 0.9670766247829921, 0.9668036598554799, 0.9669808795754339, 0.9676124822925514, 0.9671180609246375, 0.9663406484563586, 0.9664463921332024, 0.9664120917588892, 0.9665435678522352, 0.9667393380487469, 0.9664949909062452, 0.9665121637599569, 0.9667636584228193, 0.9665121301798754, 0.966536434603409, 0.9665778699055524, 0.966273480737713, 0.9664449716957522, 0.9665807485580444, 0.9662620677074916, 0.9663106203079224, 0.9662691808082688, 0.9656047216603454, 0.9663678222978619, 0.966362110325988, 0.9665121410934019, 0.9661348907040878, 0.9665764360360696, 0.9664478495087422, 0.9658362143476245, 0.966176343635774, 0.9658061971127148, 0.9658447940584639, 0.9663192210063128, 0.9660548702092238, 0.9660205639583964, 0.9663006596162286, 0.9663563723295507, 0.966072012840862, 0.9662034755021753, 0.9667236326445996, 0.9656675642644855, 0.9666735974835677, 0.9654532167273508, 0.9666636107673108, 0.9663606588269623, 0.966099158139296, 0.9660934402909077, 0.9657519006393325, 0.9665121427724059, 0.9661620460765462, 0.9660948590493538, 0.9664821507225574, 0.9658233372258468, 0.9667207699426463, 0.9653374603096868, 0.96632921192008, 0.9658018988622746, 0.9662363277354711, 0.9653846361267735, 0.9662191725113023, 0.9662820822756055, 0.9658676688100251, 0.9662735059227742, 0.9658990812973237, 0.9662163349944102, 0.9662234766382567, 0.9660191124593708, 0.9657590338881586, 0.965801908096797, 0.9652431540086236, 0.9661020015327024, 0.9658548000832679, 0.9659676728114276, 0.9656975865364075, 0.9659891178910162, 0.9655504050389142, 0.9661520249407056, 0.9661963195867942, 0.9661591674240542, 0.9659191134949805, 0.9660777004671769, 0.9658947947999121, 0.9657947731689668, 0.9661005878112685, 0.9661277255541841, 0.9657862043716539, 0.9657176061415337, 0.9658990712232993, 0.9660291050521421, 0.9660419956059523, 0.9659734200423872, 0.9657004492383607, 0.9660448549498974, 0.9663592400685163, 0.9661020283967676, 0.9662120283489496, 0.9653532144049524, 0.966041988889936, 0.9657747552428447, 0.9656904532875813, 0.9658190574444515, 0.965676164123374, 0.9656104176816805, 0.9656232956429602, 0.9657861791865926, 0.9656561428392437, 0.9661048566791374, 0.9659147959359935, 0.9666021642550616, 0.9661705997628225, 0.9662377607654518, 0.9655961268384692, 0.9660119943215814, 0.9661277138011556, 0.9660691534969169, 0.9662434903668685, 0.9655861426407183, 0.9662120434599863, 0.9660376956765081, 0.9662106087510015, 0.9659834084376483, 0.9659291128037681, 0.9662877724204265, 0.9658104617830733], 'val_mDice': [0.6610462967778595, 0.6753654689855979, 0.6723522686622512, 0.6758628353266649, 0.6800638286160751, 0.6800183343215728, 0.6841643864000347, 0.6788969182632338, 0.6817689823432708, 0.6813391581387587, 0.685297430401117, 0.6853148937225342, 0.6882152347497537, 0.6848308754638887, 0.6894083006281249, 0.6842356114320352, 0.6895771857718347, 0.6867420900035912, 0.6888097239212251, 0.6875712913526616, 0.686209242108842, 0.6896371195014094, 0.6911419932271393, 0.6889724756630373, 0.6906716630492412, 0.6873175736883996, 0.690513379976783, 0.6921406581368245, 0.6904569142301318, 0.6912084515665619, 0.6895800216097228, 0.6887020611427199, 0.6918401164068303, 0.688690613692915, 0.6870433041747187, 0.6914797870206161, 0.6917227607377818, 0.6865587973258864, 0.6929951654353612, 0.6909531002313318, 0.6885102945314326, 0.6868526331135925, 0.69142141308583, 0.6889002784876757, 0.6892566882388692, 0.692572017790566, 0.6932471721944674, 0.6954910016395677, 0.6916801157132001, 0.6936279291837988, 0.6925563661145492, 0.6896068428603697, 0.6953693535965932, 0.6952317315088191, 0.6958590653580679, 0.6904271673148786, 0.6922256333727232, 0.6921318845010139, 0.693324154531452, 0.6879468056517588, 0.69233887128427, 0.694158609484283, 0.689952680762385, 0.6906909951021973, 0.6887368383541913, 0.6945461143910046, 0.6928012438223395, 0.690429900733518, 0.6954633282943511, 0.6921356278406062, 0.6927923375452069, 0.6948893825772783, 0.6898500868971918, 0.6896273048830704, 0.6901266658809823, 0.6942696462214832, 0.6917585848082959, 0.6972018891656903, 0.6942664989283387, 0.6961013481650554, 0.6946400555086808, 0.6917137545599065, 0.6963028227779228, 0.6902643291043563, 0.6936482098740591, 0.6970050066289767, 0.6951738637937627, 0.6941801964397162, 0.697490802113439, 0.6936776159514844, 0.6963951184716023, 0.6909780116148398, 0.6940534559773727, 0.6975497393540933, 0.6920944259200298, 0.695809115826244, 0.6957926506727514, 0.6975801721425123, 0.693678938167196, 0.6945454100487938, 0.6944709260698775, 0.6962263575741943, 0.7001817033324443, 0.6916260282758256, 0.6951571652587031, 0.691140482123469, 0.6979889013397862, 0.6964721713267582, 0.6932114765677654, 0.693125133783045, 0.6967306263010267, 0.6938317384518368, 0.6948887932468468, 0.6961882685271787, 0.694684624671936, 0.6959201861435259, 0.6977521013206159, 0.6957983668421356, 0.6941177467225303, 0.6988106244046923, 0.6975792335792327, 0.6952330948601306, 0.6953727015307252, 0.6951225425156069, 0.6943244615071257, 0.695264328533495, 0.6947064987370666, 0.6961129668732764, 0.6984686028789466, 0.6911624787558972, 0.696795619709391, 0.6932514183957812, 0.6971584894287755], 'loss': [1.3169611275646838, 1.1179154445571633, 1.0608808413850075, 1.0249296012071762, 1.000284216444183, 0.9779029818660232, 0.9621009565218026, 0.9483416486160917, 0.9380425998400366, 0.9246742635566596, 0.9142620932091939, 0.9078949219338627, 0.8995952338517718, 0.8938261802075838, 0.8872328460251196, 0.8826338251778523, 0.8766036049233681, 0.8692852282607326, 0.8641173269528161, 0.8608277638753256, 0.855129631852743, 0.8522831411331181, 0.8491433385571052, 0.8457821578810283, 0.8427385315775802, 0.8395587775581032, 0.8352940494824177, 0.8330364011275762, 0.8303763221834481, 0.8284693616916441, 0.8263090486925934, 0.8216670709962828, 0.8201428456594946, 0.8180549461318699, 0.8156572378881454, 0.8132827579455018, 0.811481590913159, 0.8105348975870622, 0.8073681994119725, 0.8058602092153739, 0.8042366445376611, 0.8023153567744106, 0.8004055081445717, 0.7995767650249186, 0.79606222371295, 0.7936315015348464, 0.7938120725405917, 0.7921537244784548, 0.7914485717457765, 0.790350427074166, 0.7870804403256787, 0.7860780676622041, 0.7843374515980603, 0.7826137700144672, 0.7827918777083019, 0.7821134777524015, 0.7781513719242489, 0.7806954570743079, 0.7801757178520171, 0.7776949471204069, 0.7761852406637137, 0.7738719414388668, 0.7742024957613587, 0.7714161083683017, 0.7703188538135243, 0.7711508934618498, 0.7705510588077836, 0.7673447234052222, 0.7680940071186956, 0.7668175133527053, 0.7657030364883161, 0.7667398458653373, 0.76530677361014, 0.7655614538550585, 0.7608191379979297, 0.7618939755890798, 0.7620391248963196, 0.759934520880936, 0.7595582818693724, 0.7588567362059127, 0.7581977956582114, 0.7565565815216029, 0.7573946119048278, 0.7552162316249095, 0.7545157179643832, 0.7535471122163614, 0.7531570273474804, 0.7536101579111353, 0.7520471995760356, 0.752446950903599, 0.7516239820142483, 0.7510899981140328, 0.7490082158814897, 0.7470217352692924, 0.7493151345871575, 0.7474736781089787, 0.7464178237130019, 0.7468624519982818, 0.7447884881336929, 0.7442194271254082, 0.7448090543713661, 0.7445288603218438, 0.7451453166967773, 0.7423074350168429, 0.7412590585592668, 0.7412412619784934, 0.7391112364607539, 0.7409217382600795, 0.7399426782595827, 0.7405598856044967, 0.7391303904254884, 0.739265341513236, 0.7395285809019265, 0.7370175683893666, 0.7371649147466978, 0.7386034865445907, 0.7360458019308187, 0.735506400804037, 0.7349981637178569, 0.7379075786344806, 0.7348643321502757, 0.7331477484431219, 0.7348756065127321, 0.7328832549990576, 0.7309091541918299, 0.7309355146320425, 0.729993570260075, 0.7319335471134396, 0.7320642583310569, 0.7325064514250587, 0.7293931291573543, 0.7304725942742069, 0.7303330737744188], 'acc': [0.9527297437086988, 0.9555242258563439, 0.9566054015467512, 0.9573763157823462, 0.9579565743848014, 0.9584887549931258, 0.9588561262274427, 0.9591718191945185, 0.959450537691011, 0.9597294374979672, 0.9599987577740157, 0.9601833718054651, 0.9603518591570673, 0.9605214927278334, 0.9606588864270998, 0.9607997866409195, 0.9609987179230229, 0.9611018809071109, 0.9611980148773681, 0.9613525890000273, 0.9614928392146201, 0.9615417680052424, 0.9616039555526321, 0.9617225445932673, 0.9617780986187277, 0.9618928148137614, 0.961972650571782, 0.9620377265692728, 0.9620360425906933, 0.9621710019308581, 0.9622463299965983, 0.9623246860060323, 0.962362298756023, 0.9624005914289221, 0.9625069764272081, 0.9625959999690297, 0.9626059938545072, 0.962622790297774, 0.9626894877219075, 0.9627579446793157, 0.9628271915456318, 0.9628712913544807, 0.9628981258926037, 0.9629156076679263, 0.9630294267073005, 0.9631121550416308, 0.9630335702529961, 0.963107891073055, 0.9631290347718998, 0.9631562099129465, 0.9632298579529457, 0.963282766489181, 0.9633160691194718, 0.9633957101828556, 0.96334045522084, 0.9633458166222297, 0.9635000545108922, 0.9634744285704994, 0.9634490954175531, 0.963483503559705, 0.9635422448213188, 0.9635700099755332, 0.9636344872220024, 0.9636499140067042, 0.96371539440732, 0.9636553117117956, 0.9636647303205649, 0.9637553643667123, 0.9637517434625587, 0.9637906169946836, 0.9638173679337382, 0.9637735220774306, 0.9638526247225923, 0.9638535935841306, 0.9639413596725241, 0.9639106788144269, 0.9639137599133973, 0.9639383392530932, 0.9639822396169644, 0.9639948833952677, 0.964060140148438, 0.9640394456515553, 0.9640614596336924, 0.9640653211062145, 0.9641043595826647, 0.964133978375451, 0.9641636995606259, 0.9641697459820053, 0.9641645034084908, 0.9641742435841452, 0.9642079213873601, 0.9641848194384173, 0.9642418458962454, 0.9642610535710409, 0.9642937175405102, 0.9643223796770142, 0.9643054164863728, 0.9643997950495642, 0.9644162515140398, 0.9644208689496017, 0.9644242273367304, 0.964428633850213, 0.9644745988787573, 0.964501726655089, 0.9644801502244427, 0.9645155967148742, 0.9645672777907109, 0.9645140852048828, 0.9645766144994389, 0.964556404086585, 0.964584242160269, 0.9646191374377638, 0.9645991736265586, 0.9646587375293574, 0.9646368087066197, 0.9645626746408463, 0.9646315924160144, 0.9647046147632765, 0.96473628903212, 0.9646502886836511, 0.964719842727133, 0.9647554093630526, 0.9646729779077033, 0.9647687604914161, 0.964770624948283, 0.9648000282766931, 0.9648173376874497, 0.964811211134404, 0.9647851921292916, 0.9648037828492037, 0.964836588392707, 0.9648061356203302, 0.9648147147710133], 'mDice': [0.6066139790122769, 0.6415991759217015, 0.6555670224489897, 0.6653900223807445, 0.6731761970653167, 0.6794196109982547, 0.6840441597624529, 0.6885295990180526, 0.6916389950074867, 0.695819381019832, 0.6990131760073512, 0.7009159214902992, 0.7038797543033602, 0.7057422662349965, 0.707577367554299, 0.7092872991889212, 0.7112284572822123, 0.7131853275967588, 0.7149835492442554, 0.716161716462846, 0.7181049368629766, 0.7186763820917264, 0.7199278522397696, 0.7210911473193232, 0.7218309331245378, 0.7230946471553823, 0.7244538190823921, 0.7249956825155377, 0.7260337877648039, 0.7267622182090453, 0.7276772094577325, 0.7289344260275121, 0.7293155448529663, 0.7300549723715059, 0.7307038386246713, 0.7315766241329918, 0.7321522558685511, 0.7323563217839368, 0.7334555705804475, 0.7340620947203156, 0.7345794989939274, 0.7351460284864992, 0.73531771690919, 0.7361851594973747, 0.7370981788690733, 0.7381825439454235, 0.7375831305807312, 0.7385825684696107, 0.7388504403770628, 0.73892373463801, 0.7401481140762516, 0.7404441360542426, 0.7410718410635078, 0.7416796273031229, 0.7416096664293343, 0.7420211522089596, 0.7429820266208238, 0.7423811956780674, 0.7427952619677993, 0.7432097290545581, 0.7437310430322572, 0.744345810539574, 0.7444331826963974, 0.745238298659688, 0.7456193914102773, 0.7454376269246756, 0.7455977910198813, 0.7465036773210074, 0.7463946884423234, 0.7468147920688409, 0.7470420235600008, 0.747081925835701, 0.7471107213978437, 0.7471457762798644, 0.7487359129460209, 0.7485572484567319, 0.7486066648334594, 0.7490769688163544, 0.7492438358508826, 0.7493947439238108, 0.7498264966002726, 0.7501186559614988, 0.7499495429171595, 0.750749918040042, 0.75085271510917, 0.751215101675352, 0.7512477980650324, 0.7511101635200053, 0.7517518372366496, 0.7513874278226657, 0.7516778659654121, 0.7519763694245015, 0.7527969058618218, 0.7532591392232485, 0.7526580629617825, 0.7532261135690499, 0.7534499575122281, 0.753399490339247, 0.7540794127621299, 0.754183544503734, 0.7539648104365861, 0.7541130378955044, 0.7539797686712211, 0.7545575285595888, 0.755288152378475, 0.7553287548960608, 0.7555847188079683, 0.7552123557279941, 0.7557683545465452, 0.7554221240291074, 0.7559446055504941, 0.7558289391832201, 0.7560525372529043, 0.75686933718288, 0.7562359160569742, 0.7563469439762286, 0.7567812254291555, 0.7570163726182508, 0.7573771534997963, 0.7560327800988735, 0.7575053848313203, 0.757859231671183, 0.7572764546944695, 0.7578648620389657, 0.7582916838613758, 0.7584600320314515, 0.7589953816720675, 0.7584946958945198, 0.7581515627034949, 0.758122860691865, 0.7589065511258554, 0.7588854348541624, 0.7587499239889947]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:03<00:09,  3.22s/it]predicting test subjects:  50%|█████     | 2/4 [00:04<00:05,  2.71s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:06<00:02,  2.39s/it]predicting test subjects: 100%|██████████| 4/4 [00:08<00:00,  2.24s/it]
predicting train subjects:   0%|          | 0/456 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/456 [00:01<14:20,  1.89s/it]predicting train subjects:   0%|          | 2/456 [00:03<13:50,  1.83s/it]predicting train subjects:   1%|          | 3/456 [00:05<13:17,  1.76s/it]predicting train subjects:   1%|          | 4/456 [00:06<12:23,  1.64s/it]predicting train subjects:   1%|          | 5/456 [00:08<13:33,  1.80s/it]predicting train subjects:   1%|▏         | 6/456 [00:10<13:21,  1.78s/it]predicting train subjects:   2%|▏         | 7/456 [00:11<12:27,  1.67s/it]predicting train subjects:   2%|▏         | 8/456 [00:12<10:58,  1.47s/it]predicting train subjects:   2%|▏         | 9/456 [00:14<11:17,  1.52s/it]predicting train subjects:   2%|▏         | 10/456 [00:16<12:01,  1.62s/it]predicting train subjects:   2%|▏         | 11/456 [00:18<12:32,  1.69s/it]predicting train subjects:   3%|▎         | 12/456 [00:19<11:10,  1.51s/it]predicting train subjects:   3%|▎         | 13/456 [00:20<11:27,  1.55s/it]predicting train subjects:   3%|▎         | 14/456 [00:22<11:40,  1.58s/it]predicting train subjects:   3%|▎         | 15/456 [00:23<10:24,  1.42s/it]predicting train subjects:   4%|▎         | 16/456 [00:25<10:58,  1.50s/it]predicting train subjects:   4%|▎         | 17/456 [00:27<12:30,  1.71s/it]predicting train subjects:   4%|▍         | 18/456 [00:29<12:24,  1.70s/it]predicting train subjects:   4%|▍         | 19/456 [00:30<11:59,  1.65s/it]predicting train subjects:   4%|▍         | 20/456 [00:32<11:27,  1.58s/it]predicting train subjects:   5%|▍         | 21/456 [00:33<11:29,  1.59s/it]predicting train subjects:   5%|▍         | 22/456 [00:35<11:41,  1.62s/it]predicting train subjects:   5%|▌         | 23/456 [00:37<12:07,  1.68s/it]predicting train subjects:   5%|▌         | 24/456 [00:38<10:47,  1.50s/it]predicting train subjects:   5%|▌         | 25/456 [00:39<11:00,  1.53s/it]predicting train subjects:   6%|▌         | 26/456 [00:41<11:00,  1.54s/it]predicting train subjects:   6%|▌         | 27/456 [00:43<11:03,  1.55s/it]predicting train subjects:   6%|▌         | 28/456 [00:44<11:22,  1.59s/it]predicting train subjects:   6%|▋         | 29/456 [00:46<11:09,  1.57s/it]predicting train subjects:   7%|▋         | 30/456 [00:47<11:10,  1.57s/it]predicting train subjects:   7%|▋         | 31/456 [00:49<11:11,  1.58s/it]predicting train subjects:   7%|▋         | 32/456 [00:51<11:07,  1.57s/it]predicting train subjects:   7%|▋         | 33/456 [00:52<11:05,  1.57s/it]predicting train subjects:   7%|▋         | 34/456 [00:54<11:00,  1.56s/it]predicting train subjects:   8%|▊         | 35/456 [00:55<10:57,  1.56s/it]predicting train subjects:   8%|▊         | 36/456 [00:57<10:52,  1.55s/it]predicting train subjects:   8%|▊         | 37/456 [00:58<11:01,  1.58s/it]predicting train subjects:   8%|▊         | 38/456 [01:00<10:59,  1.58s/it]predicting train subjects:   9%|▊         | 39/456 [01:01<10:57,  1.58s/it]predicting train subjects:   9%|▉         | 40/456 [01:03<10:53,  1.57s/it]predicting train subjects:   9%|▉         | 41/456 [01:05<10:51,  1.57s/it]predicting train subjects:   9%|▉         | 42/456 [01:06<10:51,  1.57s/it]predicting train subjects:   9%|▉         | 43/456 [01:08<10:56,  1.59s/it]predicting train subjects:  10%|▉         | 44/456 [01:10<11:15,  1.64s/it]predicting train subjects:  10%|▉         | 45/456 [01:11<11:16,  1.65s/it]predicting train subjects:  10%|█         | 46/456 [01:13<11:16,  1.65s/it]predicting train subjects:  10%|█         | 47/456 [01:15<11:18,  1.66s/it]predicting train subjects:  11%|█         | 48/456 [01:16<11:28,  1.69s/it]predicting train subjects:  11%|█         | 49/456 [01:18<11:18,  1.67s/it]predicting train subjects:  11%|█         | 50/456 [01:20<11:20,  1.68s/it]predicting train subjects:  11%|█         | 51/456 [01:21<11:16,  1.67s/it]predicting train subjects:  11%|█▏        | 52/456 [01:23<11:33,  1.72s/it]predicting train subjects:  12%|█▏        | 53/456 [01:25<11:17,  1.68s/it]predicting train subjects:  12%|█▏        | 54/456 [01:26<11:10,  1.67s/it]predicting train subjects:  12%|█▏        | 55/456 [01:28<11:08,  1.67s/it]predicting train subjects:  12%|█▏        | 56/456 [01:30<11:10,  1.68s/it]predicting train subjects:  12%|█▎        | 57/456 [01:31<11:05,  1.67s/it]predicting train subjects:  13%|█▎        | 58/456 [01:33<11:01,  1.66s/it]predicting train subjects:  13%|█▎        | 59/456 [01:35<11:05,  1.68s/it]predicting train subjects:  13%|█▎        | 60/456 [01:36<11:05,  1.68s/it]predicting train subjects:  13%|█▎        | 61/456 [01:38<11:14,  1.71s/it]predicting train subjects:  14%|█▎        | 62/456 [01:40<11:23,  1.73s/it]predicting train subjects:  14%|█▍        | 63/456 [01:42<11:36,  1.77s/it]predicting train subjects:  14%|█▍        | 64/456 [01:44<11:37,  1.78s/it]predicting train subjects:  14%|█▍        | 65/456 [01:45<11:37,  1.78s/it]predicting train subjects:  14%|█▍        | 66/456 [01:47<11:34,  1.78s/it]predicting train subjects:  15%|█▍        | 67/456 [01:49<11:31,  1.78s/it]predicting train subjects:  15%|█▍        | 68/456 [01:51<11:31,  1.78s/it]predicting train subjects:  15%|█▌        | 69/456 [01:53<11:28,  1.78s/it]predicting train subjects:  15%|█▌        | 70/456 [01:54<11:28,  1.78s/it]predicting train subjects:  16%|█▌        | 71/456 [01:56<11:39,  1.82s/it]predicting train subjects:  16%|█▌        | 72/456 [01:58<11:31,  1.80s/it]predicting train subjects:  16%|█▌        | 73/456 [02:00<11:37,  1.82s/it]predicting train subjects:  16%|█▌        | 74/456 [02:02<11:31,  1.81s/it]predicting train subjects:  16%|█▋        | 75/456 [02:03<11:30,  1.81s/it]predicting train subjects:  17%|█▋        | 76/456 [02:05<11:26,  1.81s/it]predicting train subjects:  17%|█▋        | 77/456 [02:07<11:24,  1.81s/it]predicting train subjects:  17%|█▋        | 78/456 [02:09<11:24,  1.81s/it]predicting train subjects:  17%|█▋        | 79/456 [02:10<09:49,  1.56s/it]predicting train subjects:  18%|█▊        | 80/456 [02:11<08:41,  1.39s/it]predicting train subjects:  18%|█▊        | 81/456 [02:12<07:58,  1.28s/it]predicting train subjects:  18%|█▊        | 82/456 [02:13<07:28,  1.20s/it]predicting train subjects:  18%|█▊        | 83/456 [02:14<07:09,  1.15s/it]predicting train subjects:  18%|█▊        | 84/456 [02:15<06:50,  1.10s/it]predicting train subjects:  19%|█▊        | 85/456 [02:16<06:40,  1.08s/it]predicting train subjects:  19%|█▉        | 86/456 [02:17<06:31,  1.06s/it]predicting train subjects:  19%|█▉        | 87/456 [02:18<06:23,  1.04s/it]predicting train subjects:  19%|█▉        | 88/456 [02:19<06:15,  1.02s/it]predicting train subjects:  20%|█▉        | 89/456 [02:20<06:14,  1.02s/it]predicting train subjects:  20%|█▉        | 90/456 [02:21<06:10,  1.01s/it]predicting train subjects:  20%|█▉        | 91/456 [02:22<06:04,  1.00it/s]predicting train subjects:  20%|██        | 92/456 [02:23<06:03,  1.00it/s]predicting train subjects:  20%|██        | 93/456 [02:24<05:56,  1.02it/s]predicting train subjects:  21%|██        | 94/456 [02:25<05:53,  1.02it/s]predicting train subjects:  21%|██        | 95/456 [02:26<05:54,  1.02it/s]predicting train subjects:  21%|██        | 96/456 [02:27<05:47,  1.04it/s]predicting train subjects:  21%|██▏       | 97/456 [02:28<07:06,  1.19s/it]predicting train subjects:  21%|██▏       | 98/456 [02:30<07:57,  1.33s/it]predicting train subjects:  22%|██▏       | 99/456 [02:32<08:24,  1.41s/it]predicting train subjects:  22%|██▏       | 100/456 [02:34<09:05,  1.53s/it]predicting train subjects:  22%|██▏       | 101/456 [02:35<09:14,  1.56s/it]predicting train subjects:  22%|██▏       | 102/456 [02:37<09:23,  1.59s/it]predicting train subjects:  23%|██▎       | 103/456 [02:38<09:28,  1.61s/it]predicting train subjects:  23%|██▎       | 104/456 [02:40<09:45,  1.66s/it]predicting train subjects:  23%|██▎       | 105/456 [02:42<09:42,  1.66s/it]predicting train subjects:  23%|██▎       | 106/456 [02:44<09:40,  1.66s/it]predicting train subjects:  23%|██▎       | 107/456 [02:45<09:50,  1.69s/it]predicting train subjects:  24%|██▎       | 108/456 [02:47<09:51,  1.70s/it]predicting train subjects:  24%|██▍       | 109/456 [02:49<09:43,  1.68s/it]predicting train subjects:  24%|██▍       | 110/456 [02:50<09:40,  1.68s/it]predicting train subjects:  24%|██▍       | 111/456 [02:52<09:33,  1.66s/it]predicting train subjects:  25%|██▍       | 112/456 [02:54<09:24,  1.64s/it]predicting train subjects:  25%|██▍       | 113/456 [02:55<09:21,  1.64s/it]predicting train subjects:  25%|██▌       | 114/456 [02:57<09:24,  1.65s/it]predicting train subjects:  25%|██▌       | 115/456 [02:59<09:33,  1.68s/it]predicting train subjects:  25%|██▌       | 116/456 [03:00<09:46,  1.73s/it]predicting train subjects:  26%|██▌       | 117/456 [03:02<09:49,  1.74s/it]predicting train subjects:  26%|██▌       | 118/456 [03:04<09:42,  1.72s/it]predicting train subjects:  26%|██▌       | 119/456 [03:06<09:35,  1.71s/it]predicting train subjects:  26%|██▋       | 120/456 [03:07<09:38,  1.72s/it]predicting train subjects:  27%|██▋       | 121/456 [03:09<09:44,  1.74s/it]predicting train subjects:  27%|██▋       | 122/456 [03:11<09:48,  1.76s/it]predicting train subjects:  27%|██▋       | 123/456 [03:13<09:38,  1.74s/it]predicting train subjects:  27%|██▋       | 124/456 [03:14<09:39,  1.74s/it]predicting train subjects:  27%|██▋       | 125/456 [03:16<09:32,  1.73s/it]predicting train subjects:  28%|██▊       | 126/456 [03:18<09:40,  1.76s/it]predicting train subjects:  28%|██▊       | 127/456 [03:19<09:00,  1.64s/it]predicting train subjects:  28%|██▊       | 128/456 [03:21<08:30,  1.55s/it]predicting train subjects:  28%|██▊       | 129/456 [03:22<08:11,  1.50s/it]predicting train subjects:  29%|██▊       | 130/456 [03:23<08:02,  1.48s/it]predicting train subjects:  29%|██▊       | 131/456 [03:25<07:48,  1.44s/it]predicting train subjects:  29%|██▉       | 132/456 [03:26<07:45,  1.44s/it]predicting train subjects:  29%|██▉       | 133/456 [03:28<08:50,  1.64s/it]predicting train subjects:  29%|██▉       | 134/456 [03:30<09:33,  1.78s/it]predicting train subjects:  30%|██▉       | 135/456 [03:32<09:54,  1.85s/it]predicting train subjects:  30%|██▉       | 136/456 [03:34<10:02,  1.88s/it]predicting train subjects:  30%|███       | 137/456 [03:36<10:16,  1.93s/it]predicting train subjects:  30%|███       | 138/456 [03:39<10:24,  1.96s/it]predicting train subjects:  30%|███       | 139/456 [03:40<09:18,  1.76s/it]predicting train subjects:  31%|███       | 140/456 [03:41<08:37,  1.64s/it]predicting train subjects:  31%|███       | 141/456 [03:43<08:13,  1.57s/it]predicting train subjects:  31%|███       | 142/456 [03:44<07:56,  1.52s/it]predicting train subjects:  31%|███▏      | 143/456 [03:45<07:39,  1.47s/it]predicting train subjects:  32%|███▏      | 144/456 [03:47<07:29,  1.44s/it]predicting train subjects:  32%|███▏      | 145/456 [03:48<07:37,  1.47s/it]predicting train subjects:  32%|███▏      | 146/456 [03:50<07:48,  1.51s/it]predicting train subjects:  32%|███▏      | 147/456 [03:51<07:50,  1.52s/it]predicting train subjects:  32%|███▏      | 148/456 [03:53<07:56,  1.55s/it]predicting train subjects:  33%|███▎      | 149/456 [03:55<07:59,  1.56s/it]predicting train subjects:  33%|███▎      | 150/456 [03:56<08:04,  1.58s/it]predicting train subjects:  33%|███▎      | 151/456 [03:58<08:07,  1.60s/it]predicting train subjects:  33%|███▎      | 152/456 [04:00<08:10,  1.61s/it]predicting train subjects:  34%|███▎      | 153/456 [04:01<08:06,  1.61s/it]predicting train subjects:  34%|███▍      | 154/456 [04:03<08:07,  1.61s/it]predicting train subjects:  34%|███▍      | 155/456 [04:04<08:01,  1.60s/it]predicting train subjects:  34%|███▍      | 156/456 [04:06<07:59,  1.60s/it]predicting train subjects:  34%|███▍      | 157/456 [04:07<07:49,  1.57s/it]predicting train subjects:  35%|███▍      | 158/456 [04:09<07:39,  1.54s/it]predicting train subjects:  35%|███▍      | 159/456 [04:10<07:34,  1.53s/it]predicting train subjects:  35%|███▌      | 160/456 [04:12<07:27,  1.51s/it]predicting train subjects:  35%|███▌      | 161/456 [04:13<07:26,  1.52s/it]predicting train subjects:  36%|███▌      | 162/456 [04:15<07:25,  1.51s/it]predicting train subjects:  36%|███▌      | 163/456 [04:16<06:51,  1.41s/it]predicting train subjects:  36%|███▌      | 164/456 [04:17<06:28,  1.33s/it]predicting train subjects:  36%|███▌      | 165/456 [04:18<06:10,  1.27s/it]predicting train subjects:  36%|███▋      | 166/456 [04:19<05:55,  1.23s/it]predicting train subjects:  37%|███▋      | 167/456 [04:21<05:42,  1.19s/it]predicting train subjects:  37%|███▋      | 168/456 [04:22<05:36,  1.17s/it]predicting train subjects:  37%|███▋      | 169/456 [04:23<05:28,  1.15s/it]predicting train subjects:  37%|███▋      | 170/456 [04:24<05:20,  1.12s/it]predicting train subjects:  38%|███▊      | 171/456 [04:25<05:21,  1.13s/it]predicting train subjects:  38%|███▊      | 172/456 [04:26<05:23,  1.14s/it]predicting train subjects:  38%|███▊      | 173/456 [04:27<05:15,  1.11s/it]predicting train subjects:  38%|███▊      | 174/456 [04:28<05:17,  1.12s/it]predicting train subjects:  38%|███▊      | 175/456 [04:29<05:06,  1.09s/it]predicting train subjects:  39%|███▊      | 176/456 [04:30<05:03,  1.08s/it]predicting train subjects:  39%|███▉      | 177/456 [04:32<05:03,  1.09s/it]predicting train subjects:  39%|███▉      | 178/456 [04:33<05:02,  1.09s/it]predicting train subjects:  39%|███▉      | 179/456 [04:34<05:00,  1.09s/it]predicting train subjects:  39%|███▉      | 180/456 [04:35<05:04,  1.10s/it]predicting train subjects:  40%|███▉      | 181/456 [04:37<06:07,  1.34s/it]predicting train subjects:  40%|███▉      | 182/456 [04:39<06:49,  1.50s/it]predicting train subjects:  40%|████      | 183/456 [04:40<07:21,  1.62s/it]predicting train subjects:  40%|████      | 184/456 [04:42<07:44,  1.71s/it]predicting train subjects:  41%|████      | 185/456 [04:44<08:00,  1.77s/it]predicting train subjects:  41%|████      | 186/456 [04:46<08:08,  1.81s/it]predicting train subjects:  41%|████      | 187/456 [04:48<08:32,  1.91s/it]predicting train subjects:  41%|████      | 188/456 [04:51<08:59,  2.01s/it]predicting train subjects:  41%|████▏     | 189/456 [04:53<09:08,  2.06s/it]predicting train subjects:  42%|████▏     | 190/456 [04:55<09:09,  2.06s/it]predicting train subjects:  42%|████▏     | 191/456 [04:57<09:16,  2.10s/it]predicting train subjects:  42%|████▏     | 192/456 [04:59<09:15,  2.10s/it]predicting train subjects:  42%|████▏     | 193/456 [05:01<09:10,  2.09s/it]predicting train subjects:  43%|████▎     | 194/456 [05:03<08:52,  2.03s/it]predicting train subjects:  43%|████▎     | 195/456 [05:05<08:44,  2.01s/it]predicting train subjects:  43%|████▎     | 196/456 [05:07<08:33,  1.98s/it]predicting train subjects:  43%|████▎     | 197/456 [05:09<08:25,  1.95s/it]predicting train subjects:  43%|████▎     | 198/456 [05:11<08:31,  1.98s/it]predicting train subjects:  44%|████▎     | 199/456 [05:13<08:12,  1.92s/it]predicting train subjects:  44%|████▍     | 200/456 [05:14<07:56,  1.86s/it]predicting train subjects:  44%|████▍     | 201/456 [05:16<07:43,  1.82s/it]predicting train subjects:  44%|████▍     | 202/456 [05:18<07:31,  1.78s/it]predicting train subjects:  45%|████▍     | 203/456 [05:20<07:25,  1.76s/it]predicting train subjects:  45%|████▍     | 204/456 [05:21<07:23,  1.76s/it]predicting train subjects:  45%|████▍     | 205/456 [05:23<06:55,  1.66s/it]predicting train subjects:  45%|████▌     | 206/456 [05:24<06:34,  1.58s/it]predicting train subjects:  45%|████▌     | 207/456 [05:26<06:24,  1.54s/it]predicting train subjects:  46%|████▌     | 208/456 [05:27<06:14,  1.51s/it]predicting train subjects:  46%|████▌     | 209/456 [05:28<06:12,  1.51s/it]predicting train subjects:  46%|████▌     | 210/456 [05:30<06:01,  1.47s/it]predicting train subjects:  46%|████▋     | 211/456 [05:32<06:18,  1.54s/it]predicting train subjects:  46%|████▋     | 212/456 [05:33<06:31,  1.60s/it]predicting train subjects:  47%|████▋     | 213/456 [05:35<06:45,  1.67s/it]predicting train subjects:  47%|████▋     | 214/456 [05:37<06:49,  1.69s/it]predicting train subjects:  47%|████▋     | 215/456 [05:39<06:49,  1.70s/it]predicting train subjects:  47%|████▋     | 216/456 [05:40<06:50,  1.71s/it]predicting train subjects:  48%|████▊     | 217/456 [05:42<06:53,  1.73s/it]predicting train subjects:  48%|████▊     | 218/456 [05:44<06:47,  1.71s/it]predicting train subjects:  48%|████▊     | 219/456 [05:45<06:42,  1.70s/it]predicting train subjects:  48%|████▊     | 220/456 [05:47<06:39,  1.69s/it]predicting train subjects:  48%|████▊     | 221/456 [05:49<06:39,  1.70s/it]predicting train subjects:  49%|████▊     | 222/456 [05:51<06:37,  1.70s/it]predicting train subjects:  49%|████▉     | 223/456 [05:52<06:34,  1.69s/it]predicting train subjects:  49%|████▉     | 224/456 [05:54<06:30,  1.68s/it]predicting train subjects:  49%|████▉     | 225/456 [05:56<06:33,  1.71s/it]predicting train subjects:  50%|████▉     | 226/456 [05:57<06:26,  1.68s/it]predicting train subjects:  50%|████▉     | 227/456 [05:59<06:24,  1.68s/it]predicting train subjects:  50%|█████     | 228/456 [06:01<06:19,  1.66s/it]predicting train subjects:  50%|█████     | 229/456 [06:02<06:17,  1.66s/it]predicting train subjects:  50%|█████     | 230/456 [06:04<06:23,  1.70s/it]predicting train subjects:  51%|█████     | 231/456 [06:06<06:24,  1.71s/it]predicting train subjects:  51%|█████     | 232/456 [06:07<06:20,  1.70s/it]predicting train subjects:  51%|█████     | 233/456 [06:09<06:12,  1.67s/it]predicting train subjects:  51%|█████▏    | 234/456 [06:11<06:06,  1.65s/it]predicting train subjects:  52%|█████▏    | 235/456 [06:12<06:05,  1.65s/it]predicting train subjects:  52%|█████▏    | 236/456 [06:14<06:03,  1.65s/it]predicting train subjects:  52%|█████▏    | 237/456 [06:16<06:12,  1.70s/it]predicting train subjects:  52%|█████▏    | 238/456 [06:18<06:21,  1.75s/it]predicting train subjects:  52%|█████▏    | 239/456 [06:19<06:19,  1.75s/it]predicting train subjects:  53%|█████▎    | 240/456 [06:21<06:19,  1.76s/it]predicting train subjects:  53%|█████▎    | 241/456 [06:23<06:19,  1.77s/it]predicting train subjects:  53%|█████▎    | 242/456 [06:25<06:23,  1.79s/it]predicting train subjects:  53%|█████▎    | 243/456 [06:27<06:17,  1.77s/it]predicting train subjects:  54%|█████▎    | 244/456 [06:28<06:13,  1.76s/it]predicting train subjects:  54%|█████▎    | 245/456 [06:30<06:12,  1.76s/it]predicting train subjects:  54%|█████▍    | 246/456 [06:32<06:11,  1.77s/it]predicting train subjects:  54%|█████▍    | 247/456 [06:33<05:48,  1.67s/it]predicting train subjects:  54%|█████▍    | 248/456 [06:35<05:30,  1.59s/it]predicting train subjects:  55%|█████▍    | 249/456 [06:36<05:17,  1.54s/it]predicting train subjects:  55%|█████▍    | 250/456 [06:37<05:10,  1.51s/it]predicting train subjects:  55%|█████▌    | 251/456 [06:39<05:01,  1.47s/it]predicting train subjects:  55%|█████▌    | 252/456 [06:40<04:55,  1.45s/it]predicting train subjects:  55%|█████▌    | 253/456 [06:42<05:34,  1.65s/it]predicting train subjects:  56%|█████▌    | 254/456 [06:44<05:58,  1.78s/it]predicting train subjects:  56%|█████▌    | 255/456 [06:47<06:20,  1.89s/it]predicting train subjects:  56%|█████▌    | 256/456 [06:49<06:29,  1.95s/it]predicting train subjects:  56%|█████▋    | 257/456 [06:51<06:34,  1.98s/it]predicting train subjects:  57%|█████▋    | 258/456 [06:53<06:40,  2.02s/it]predicting train subjects:  57%|█████▋    | 259/456 [06:54<06:04,  1.85s/it]predicting train subjects:  57%|█████▋    | 260/456 [06:56<05:38,  1.73s/it]predicting train subjects:  57%|█████▋    | 261/456 [06:57<05:21,  1.65s/it]predicting train subjects:  57%|█████▋    | 262/456 [06:59<05:15,  1.62s/it]predicting train subjects:  58%|█████▊    | 263/456 [07:00<05:02,  1.57s/it]predicting train subjects:  58%|█████▊    | 264/456 [07:02<04:53,  1.53s/it]predicting train subjects:  58%|█████▊    | 265/456 [07:03<04:49,  1.52s/it]predicting train subjects:  58%|█████▊    | 266/456 [07:05<04:51,  1.54s/it]predicting train subjects:  59%|█████▊    | 267/456 [07:06<04:52,  1.55s/it]predicting train subjects:  59%|█████▉    | 268/456 [07:08<04:53,  1.56s/it]predicting train subjects:  59%|█████▉    | 269/456 [07:10<04:56,  1.59s/it]predicting train subjects:  59%|█████▉    | 270/456 [07:11<04:49,  1.56s/it]predicting train subjects:  59%|█████▉    | 271/456 [07:13<04:50,  1.57s/it]predicting train subjects:  60%|█████▉    | 272/456 [07:14<04:49,  1.58s/it]predicting train subjects:  60%|█████▉    | 273/456 [07:16<04:54,  1.61s/it]predicting train subjects:  60%|██████    | 274/456 [07:18<04:51,  1.60s/it]predicting train subjects:  60%|██████    | 275/456 [07:19<04:50,  1.60s/it]predicting train subjects:  61%|██████    | 276/456 [07:21<04:50,  1.61s/it]predicting train subjects:  61%|██████    | 277/456 [07:22<04:44,  1.59s/it]predicting train subjects:  61%|██████    | 278/456 [07:24<04:36,  1.55s/it]predicting train subjects:  61%|██████    | 279/456 [07:25<04:34,  1.55s/it]predicting train subjects:  61%|██████▏   | 280/456 [07:27<04:29,  1.53s/it]predicting train subjects:  62%|██████▏   | 281/456 [07:28<04:26,  1.52s/it]predicting train subjects:  62%|██████▏   | 282/456 [07:30<04:23,  1.52s/it]predicting train subjects:  62%|██████▏   | 283/456 [07:31<04:06,  1.42s/it]predicting train subjects:  62%|██████▏   | 284/456 [07:32<03:46,  1.31s/it]predicting train subjects:  62%|██████▎   | 285/456 [07:33<03:32,  1.24s/it]predicting train subjects:  63%|██████▎   | 286/456 [07:34<03:22,  1.19s/it]predicting train subjects:  63%|██████▎   | 287/456 [07:35<03:15,  1.16s/it]predicting train subjects:  63%|██████▎   | 288/456 [07:36<03:11,  1.14s/it]predicting train subjects:  63%|██████▎   | 289/456 [07:37<03:07,  1.12s/it]predicting train subjects:  64%|██████▎   | 290/456 [07:39<03:04,  1.11s/it]predicting train subjects:  64%|██████▍   | 291/456 [07:40<03:01,  1.10s/it]predicting train subjects:  64%|██████▍   | 292/456 [07:41<02:59,  1.09s/it]predicting train subjects:  64%|██████▍   | 293/456 [07:42<03:04,  1.13s/it]predicting train subjects:  64%|██████▍   | 294/456 [07:43<02:59,  1.11s/it]predicting train subjects:  65%|██████▍   | 295/456 [07:44<02:55,  1.09s/it]predicting train subjects:  65%|██████▍   | 296/456 [07:45<02:52,  1.08s/it]predicting train subjects:  65%|██████▌   | 297/456 [07:46<02:50,  1.07s/it]predicting train subjects:  65%|██████▌   | 298/456 [07:47<02:51,  1.09s/it]predicting train subjects:  66%|██████▌   | 299/456 [07:48<02:51,  1.10s/it]predicting train subjects:  66%|██████▌   | 300/456 [07:49<02:50,  1.09s/it]predicting train subjects:  66%|██████▌   | 301/456 [07:51<03:34,  1.39s/it]predicting train subjects:  66%|██████▌   | 302/456 [07:53<03:54,  1.52s/it]predicting train subjects:  66%|██████▋   | 303/456 [07:55<04:11,  1.65s/it]predicting train subjects:  67%|██████▋   | 304/456 [07:57<04:24,  1.74s/it]predicting train subjects:  67%|██████▋   | 305/456 [07:59<04:30,  1.79s/it]predicting train subjects:  67%|██████▋   | 306/456 [08:01<04:33,  1.83s/it]predicting train subjects:  67%|██████▋   | 307/456 [08:03<04:43,  1.90s/it]predicting train subjects:  68%|██████▊   | 308/456 [08:05<04:49,  1.95s/it]predicting train subjects:  68%|██████▊   | 309/456 [08:07<04:52,  1.99s/it]predicting train subjects:  68%|██████▊   | 310/456 [08:09<04:55,  2.03s/it]predicting train subjects:  68%|██████▊   | 311/456 [08:12<05:00,  2.07s/it]predicting train subjects:  68%|██████▊   | 312/456 [08:14<05:02,  2.10s/it]predicting train subjects:  69%|██████▊   | 313/456 [08:16<04:56,  2.07s/it]predicting train subjects:  69%|██████▉   | 314/456 [08:18<04:49,  2.04s/it]predicting train subjects:  69%|██████▉   | 315/456 [08:20<04:41,  2.00s/it]predicting train subjects:  69%|██████▉   | 316/456 [08:22<04:35,  1.97s/it]predicting train subjects:  70%|██████▉   | 317/456 [08:24<04:40,  2.02s/it]predicting train subjects:  70%|██████▉   | 318/456 [08:26<04:35,  2.00s/it]predicting train subjects:  70%|██████▉   | 319/456 [08:27<04:20,  1.90s/it]predicting train subjects:  70%|███████   | 320/456 [08:29<04:11,  1.85s/it]predicting train subjects:  70%|███████   | 321/456 [08:31<04:02,  1.80s/it]predicting train subjects:  71%|███████   | 322/456 [08:32<04:00,  1.80s/it]predicting train subjects:  71%|███████   | 323/456 [08:34<03:53,  1.75s/it]predicting train subjects:  71%|███████   | 324/456 [08:36<03:47,  1.72s/it]predicting train subjects:  71%|███████▏  | 325/456 [08:37<03:32,  1.62s/it]predicting train subjects:  71%|███████▏  | 326/456 [08:39<03:21,  1.55s/it]predicting train subjects:  72%|███████▏  | 327/456 [08:40<03:13,  1.50s/it]predicting train subjects:  72%|███████▏  | 328/456 [08:41<03:12,  1.50s/it]predicting train subjects:  72%|███████▏  | 329/456 [08:43<03:11,  1.51s/it]predicting train subjects:  72%|███████▏  | 330/456 [08:44<03:06,  1.48s/it]predicting train subjects:  73%|███████▎  | 331/456 [08:46<03:15,  1.57s/it]predicting train subjects:  73%|███████▎  | 332/456 [08:48<03:19,  1.61s/it]predicting train subjects:  73%|███████▎  | 333/456 [08:50<03:21,  1.64s/it]predicting train subjects:  73%|███████▎  | 334/456 [08:51<03:22,  1.66s/it]predicting train subjects:  73%|███████▎  | 335/456 [08:53<03:27,  1.72s/it]predicting train subjects:  74%|███████▎  | 336/456 [08:55<03:28,  1.74s/it]predicting train subjects:  74%|███████▍  | 337/456 [08:57<03:27,  1.75s/it]predicting train subjects:  74%|███████▍  | 338/456 [08:58<03:23,  1.73s/it]predicting train subjects:  74%|███████▍  | 339/456 [09:00<03:21,  1.72s/it]predicting train subjects:  75%|███████▍  | 340/456 [09:02<03:18,  1.71s/it]predicting train subjects:  75%|███████▍  | 341/456 [09:04<03:19,  1.74s/it]predicting train subjects:  75%|███████▌  | 342/456 [09:05<03:18,  1.75s/it]predicting train subjects:  75%|███████▌  | 343/456 [09:07<03:14,  1.72s/it]predicting train subjects:  75%|███████▌  | 344/456 [09:09<03:09,  1.70s/it]predicting train subjects:  76%|███████▌  | 345/456 [09:10<03:05,  1.67s/it]predicting train subjects:  76%|███████▌  | 346/456 [09:12<03:02,  1.66s/it]predicting train subjects:  76%|███████▌  | 347/456 [09:13<02:58,  1.64s/it]predicting train subjects:  76%|███████▋  | 348/456 [09:15<02:57,  1.65s/it]predicting train subjects:  77%|███████▋  | 349/456 [09:17<02:56,  1.65s/it]predicting train subjects:  77%|███████▋  | 350/456 [09:18<02:52,  1.63s/it]predicting train subjects:  77%|███████▋  | 351/456 [09:20<02:51,  1.64s/it]predicting train subjects:  77%|███████▋  | 352/456 [09:22<02:50,  1.64s/it]predicting train subjects:  77%|███████▋  | 353/456 [09:23<02:48,  1.63s/it]predicting train subjects:  78%|███████▊  | 354/456 [09:25<02:48,  1.65s/it]predicting train subjects:  78%|███████▊  | 355/456 [09:27<02:50,  1.69s/it]predicting train subjects:  78%|███████▊  | 356/456 [09:28<02:50,  1.71s/it]predicting train subjects:  78%|███████▊  | 357/456 [09:30<02:49,  1.71s/it]predicting train subjects:  79%|███████▊  | 358/456 [09:32<02:49,  1.72s/it]predicting train subjects:  79%|███████▊  | 359/456 [09:34<02:47,  1.73s/it]predicting train subjects:  79%|███████▉  | 360/456 [09:35<02:47,  1.74s/it]predicting train subjects:  79%|███████▉  | 361/456 [09:37<02:46,  1.76s/it]predicting train subjects:  79%|███████▉  | 362/456 [09:39<02:45,  1.76s/it]predicting train subjects:  80%|███████▉  | 363/456 [09:41<02:43,  1.76s/it]predicting train subjects:  80%|███████▉  | 364/456 [09:43<02:42,  1.77s/it]predicting train subjects:  80%|████████  | 365/456 [09:44<02:43,  1.80s/it]predicting train subjects:  80%|████████  | 366/456 [09:46<02:41,  1.80s/it]predicting train subjects:  80%|████████  | 367/456 [09:48<02:30,  1.69s/it]predicting train subjects:  81%|████████  | 368/456 [09:49<02:20,  1.60s/it]predicting train subjects:  81%|████████  | 369/456 [09:50<02:13,  1.53s/it]predicting train subjects:  81%|████████  | 370/456 [09:52<02:08,  1.49s/it]predicting train subjects:  81%|████████▏ | 371/456 [09:53<02:04,  1.47s/it]predicting train subjects:  82%|████████▏ | 372/456 [09:55<02:06,  1.50s/it]predicting train subjects:  82%|████████▏ | 373/456 [09:57<02:19,  1.68s/it]predicting train subjects:  82%|████████▏ | 374/456 [09:59<02:30,  1.84s/it]predicting train subjects:  82%|████████▏ | 375/456 [10:01<02:34,  1.91s/it]predicting train subjects:  82%|████████▏ | 376/456 [10:03<02:39,  1.99s/it]predicting train subjects:  83%|████████▎ | 377/456 [10:06<02:43,  2.08s/it]predicting train subjects:  83%|████████▎ | 378/456 [10:08<02:42,  2.09s/it]predicting train subjects:  83%|████████▎ | 379/456 [10:09<02:25,  1.89s/it]predicting train subjects:  83%|████████▎ | 380/456 [10:11<02:13,  1.75s/it]predicting train subjects:  84%|████████▎ | 381/456 [10:12<02:03,  1.65s/it]predicting train subjects:  84%|████████▍ | 382/456 [10:14<01:58,  1.60s/it]predicting train subjects:  84%|████████▍ | 383/456 [10:15<01:57,  1.61s/it]predicting train subjects:  84%|████████▍ | 384/456 [10:17<01:51,  1.55s/it]predicting train subjects:  84%|████████▍ | 385/456 [10:18<01:50,  1.55s/it]predicting train subjects:  85%|████████▍ | 386/456 [10:20<01:50,  1.57s/it]predicting train subjects:  85%|████████▍ | 387/456 [10:21<01:48,  1.57s/it]predicting train subjects:  85%|████████▌ | 388/456 [10:23<01:44,  1.54s/it]predicting train subjects:  85%|████████▌ | 389/456 [10:24<01:43,  1.54s/it]predicting train subjects:  86%|████████▌ | 390/456 [10:26<01:44,  1.58s/it]predicting train subjects:  86%|████████▌ | 391/456 [10:28<01:44,  1.60s/it]predicting train subjects:  86%|████████▌ | 392/456 [10:29<01:42,  1.61s/it]predicting train subjects:  86%|████████▌ | 393/456 [10:31<01:40,  1.60s/it]predicting train subjects:  86%|████████▋ | 394/456 [10:33<01:40,  1.62s/it]predicting train subjects:  87%|████████▋ | 395/456 [10:34<01:38,  1.62s/it]predicting train subjects:  87%|████████▋ | 396/456 [10:36<01:38,  1.64s/it]predicting train subjects:  87%|████████▋ | 397/456 [10:37<01:33,  1.59s/it]predicting train subjects:  87%|████████▋ | 398/456 [10:39<01:30,  1.56s/it]predicting train subjects:  88%|████████▊ | 399/456 [10:40<01:27,  1.54s/it]predicting train subjects:  88%|████████▊ | 400/456 [10:42<01:25,  1.53s/it]predicting train subjects:  88%|████████▊ | 401/456 [10:43<01:24,  1.53s/it]predicting train subjects:  88%|████████▊ | 402/456 [10:45<01:22,  1.54s/it]predicting train subjects:  88%|████████▊ | 403/456 [10:46<01:15,  1.43s/it]predicting train subjects:  89%|████████▊ | 404/456 [10:47<01:10,  1.35s/it]predicting train subjects:  89%|████████▉ | 405/456 [10:48<01:05,  1.28s/it]predicting train subjects:  89%|████████▉ | 406/456 [10:50<01:02,  1.24s/it]predicting train subjects:  89%|████████▉ | 407/456 [10:51<00:58,  1.19s/it]predicting train subjects:  89%|████████▉ | 408/456 [10:52<00:55,  1.17s/it]predicting train subjects:  90%|████████▉ | 409/456 [10:53<00:53,  1.14s/it]predicting train subjects:  90%|████████▉ | 410/456 [10:54<00:51,  1.12s/it]predicting train subjects:  90%|█████████ | 411/456 [10:55<00:50,  1.12s/it]predicting train subjects:  90%|█████████ | 412/456 [10:56<00:48,  1.10s/it]predicting train subjects:  91%|█████████ | 413/456 [10:57<00:46,  1.09s/it]predicting train subjects:  91%|█████████ | 414/456 [10:58<00:45,  1.07s/it]predicting train subjects:  91%|█████████ | 415/456 [10:59<00:43,  1.05s/it]predicting train subjects:  91%|█████████ | 416/456 [11:00<00:41,  1.04s/it]predicting train subjects:  91%|█████████▏| 417/456 [11:01<00:40,  1.03s/it]predicting train subjects:  92%|█████████▏| 418/456 [11:02<00:39,  1.03s/it]predicting train subjects:  92%|█████████▏| 419/456 [11:03<00:38,  1.05s/it]predicting train subjects:  92%|█████████▏| 420/456 [11:04<00:37,  1.03s/it]predicting train subjects:  92%|█████████▏| 421/456 [11:06<00:43,  1.25s/it]predicting train subjects:  93%|█████████▎| 422/456 [11:08<00:48,  1.42s/it]predicting train subjects:  93%|█████████▎| 423/456 [11:10<00:51,  1.56s/it]predicting train subjects:  93%|█████████▎| 424/456 [11:12<00:52,  1.64s/it]predicting train subjects:  93%|█████████▎| 425/456 [11:13<00:52,  1.68s/it]predicting train subjects:  93%|█████████▎| 426/456 [11:15<00:51,  1.72s/it]predicting train subjects:  94%|█████████▎| 427/456 [11:17<00:54,  1.88s/it]predicting train subjects:  94%|█████████▍| 428/456 [11:19<00:53,  1.91s/it]predicting train subjects:  94%|█████████▍| 429/456 [11:21<00:52,  1.93s/it]predicting train subjects:  94%|█████████▍| 430/456 [11:23<00:50,  1.93s/it]predicting train subjects:  95%|█████████▍| 431/456 [11:25<00:48,  1.94s/it]predicting train subjects:  95%|█████████▍| 432/456 [11:27<00:46,  1.96s/it]predicting train subjects:  95%|█████████▍| 433/456 [11:29<00:44,  1.95s/it]predicting train subjects:  95%|█████████▌| 434/456 [11:31<00:41,  1.89s/it]predicting train subjects:  95%|█████████▌| 435/456 [11:33<00:39,  1.86s/it]predicting train subjects:  96%|█████████▌| 436/456 [11:35<00:37,  1.89s/it]predicting train subjects:  96%|█████████▌| 437/456 [11:36<00:35,  1.87s/it]predicting train subjects:  96%|█████████▌| 438/456 [11:38<00:34,  1.89s/it]predicting train subjects:  96%|█████████▋| 439/456 [11:40<00:30,  1.81s/it]predicting train subjects:  96%|█████████▋| 440/456 [11:42<00:28,  1.77s/it]predicting train subjects:  97%|█████████▋| 441/456 [11:43<00:26,  1.75s/it]predicting train subjects:  97%|█████████▋| 442/456 [11:45<00:24,  1.72s/it]predicting train subjects:  97%|█████████▋| 443/456 [11:47<00:21,  1.67s/it]predicting train subjects:  97%|█████████▋| 444/456 [11:48<00:19,  1.65s/it]predicting train subjects:  98%|█████████▊| 445/456 [11:50<00:17,  1.57s/it]predicting train subjects:  98%|█████████▊| 446/456 [11:51<00:14,  1.49s/it]predicting train subjects:  98%|█████████▊| 447/456 [11:52<00:12,  1.44s/it]predicting train subjects:  98%|█████████▊| 448/456 [11:54<00:11,  1.40s/it]predicting train subjects:  98%|█████████▊| 449/456 [11:55<00:09,  1.39s/it]predicting train subjects:  99%|█████████▊| 450/456 [11:56<00:08,  1.35s/it]predicting train subjects:  99%|█████████▉| 451/456 [11:58<00:07,  1.45s/it]predicting train subjects:  99%|█████████▉| 452/456 [12:00<00:06,  1.51s/it]predicting train subjects:  99%|█████████▉| 453/456 [12:01<00:04,  1.56s/it]predicting train subjects: 100%|█████████▉| 454/456 [12:03<00:03,  1.58s/it]predicting train subjects: 100%|█████████▉| 455/456 [12:04<00:01,  1.61s/it]predicting train subjects: 100%|██████████| 456/456 [12:06<00:00,  1.65s/it]
Loading train:   0%|          | 0/456 [00:00<?, ?it/s]Loading train:   0%|          | 1/456 [00:01<09:59,  1.32s/it]Loading train:   0%|          | 2/456 [00:02<09:48,  1.30s/it]Loading train:   1%|          | 3/456 [00:03<09:12,  1.22s/it]Loading train:   1%|          | 4/456 [00:04<08:38,  1.15s/it]Loading train:   1%|          | 5/456 [00:05<08:58,  1.19s/it]Loading train:   1%|▏         | 6/456 [00:06<08:24,  1.12s/it]Loading train:   2%|▏         | 7/456 [00:07<08:01,  1.07s/it]Loading train:   2%|▏         | 8/456 [00:08<07:01,  1.06it/s]Loading train:   2%|▏         | 9/456 [00:09<07:24,  1.01it/s]Loading train:   2%|▏         | 10/456 [00:10<07:36,  1.02s/it]Loading train:   2%|▏         | 11/456 [00:11<07:59,  1.08s/it]Loading train:   3%|▎         | 12/456 [00:12<07:07,  1.04it/s]Loading train:   3%|▎         | 13/456 [00:13<07:25,  1.01s/it]Loading train:   3%|▎         | 14/456 [00:14<07:34,  1.03s/it]Loading train:   3%|▎         | 15/456 [00:15<07:06,  1.04it/s]Loading train:   4%|▎         | 16/456 [00:16<07:37,  1.04s/it]Loading train:   4%|▎         | 17/456 [00:18<08:07,  1.11s/it]Loading train:   4%|▍         | 18/456 [00:18<07:44,  1.06s/it]Loading train:   4%|▍         | 19/456 [00:19<07:26,  1.02s/it]Loading train:   4%|▍         | 20/456 [00:20<07:13,  1.01it/s]Loading train:   5%|▍         | 21/456 [00:21<07:06,  1.02it/s]Loading train:   5%|▍         | 22/456 [00:22<06:57,  1.04it/s]Loading train:   5%|▌         | 23/456 [00:23<06:49,  1.06it/s]Loading train:   5%|▌         | 24/456 [00:24<06:02,  1.19it/s]Loading train:   5%|▌         | 25/456 [00:25<06:22,  1.13it/s]Loading train:   6%|▌         | 26/456 [00:26<06:56,  1.03it/s]Loading train:   6%|▌         | 27/456 [00:27<06:59,  1.02it/s]Loading train:   6%|▌         | 28/456 [00:28<07:04,  1.01it/s]Loading train:   6%|▋         | 29/456 [00:29<07:15,  1.02s/it]Loading train:   7%|▋         | 30/456 [00:30<07:19,  1.03s/it]Loading train:   7%|▋         | 31/456 [00:31<07:14,  1.02s/it]Loading train:   7%|▋         | 32/456 [00:32<07:11,  1.02s/it]Loading train:   7%|▋         | 33/456 [00:33<07:13,  1.02s/it]Loading train:   7%|▋         | 34/456 [00:34<07:11,  1.02s/it]Loading train:   8%|▊         | 35/456 [00:35<07:07,  1.02s/it]Loading train:   8%|▊         | 36/456 [00:36<07:18,  1.05s/it]Loading train:   8%|▊         | 37/456 [00:37<07:25,  1.06s/it]Loading train:   8%|▊         | 38/456 [00:38<07:25,  1.07s/it]Loading train:   9%|▊         | 39/456 [00:39<07:18,  1.05s/it]Loading train:   9%|▉         | 40/456 [00:40<07:17,  1.05s/it]Loading train:   9%|▉         | 41/456 [00:41<07:08,  1.03s/it]Loading train:   9%|▉         | 42/456 [00:42<07:09,  1.04s/it]Loading train:   9%|▉         | 43/456 [00:44<07:25,  1.08s/it]Loading train:  10%|▉         | 44/456 [00:45<07:14,  1.05s/it]Loading train:  10%|▉         | 45/456 [00:46<07:11,  1.05s/it]Loading train:  10%|█         | 46/456 [00:47<07:07,  1.04s/it]Loading train:  10%|█         | 47/456 [00:48<07:06,  1.04s/it]Loading train:  11%|█         | 48/456 [00:49<06:59,  1.03s/it]Loading train:  11%|█         | 49/456 [00:50<06:58,  1.03s/it]Loading train:  11%|█         | 50/456 [00:51<06:51,  1.01s/it]Loading train:  11%|█         | 51/456 [00:52<06:48,  1.01s/it]Loading train:  11%|█▏        | 52/456 [00:53<06:29,  1.04it/s]Loading train:  12%|█▏        | 53/456 [00:53<06:14,  1.08it/s]Loading train:  12%|█▏        | 54/456 [00:54<06:00,  1.11it/s]Loading train:  12%|█▏        | 55/456 [00:55<06:02,  1.11it/s]Loading train:  12%|█▏        | 56/456 [00:56<06:05,  1.10it/s]Loading train:  12%|█▎        | 57/456 [00:57<06:27,  1.03it/s]Loading train:  13%|█▎        | 58/456 [00:58<06:12,  1.07it/s]Loading train:  13%|█▎        | 59/456 [00:59<06:07,  1.08it/s]Loading train:  13%|█▎        | 60/456 [01:00<06:06,  1.08it/s]Loading train:  13%|█▎        | 61/456 [01:01<06:24,  1.03it/s]Loading train:  14%|█▎        | 62/456 [01:02<06:30,  1.01it/s]Loading train:  14%|█▍        | 63/456 [01:03<06:36,  1.01s/it]Loading train:  14%|█▍        | 64/456 [01:04<06:32,  1.00s/it]Loading train:  14%|█▍        | 65/456 [01:05<06:36,  1.02s/it]Loading train:  14%|█▍        | 66/456 [01:06<06:41,  1.03s/it]Loading train:  15%|█▍        | 67/456 [01:07<06:24,  1.01it/s]Loading train:  15%|█▍        | 68/456 [01:08<06:19,  1.02it/s]Loading train:  15%|█▌        | 69/456 [01:09<06:15,  1.03it/s]Loading train:  15%|█▌        | 70/456 [01:10<06:31,  1.01s/it]Loading train:  16%|█▌        | 71/456 [01:11<06:29,  1.01s/it]Loading train:  16%|█▌        | 72/456 [01:12<06:32,  1.02s/it]Loading train:  16%|█▌        | 73/456 [01:13<06:40,  1.05s/it]Loading train:  16%|█▌        | 74/456 [01:14<06:56,  1.09s/it]Loading train:  16%|█▋        | 75/456 [01:15<06:38,  1.04s/it]Loading train:  17%|█▋        | 76/456 [01:16<06:34,  1.04s/it]Loading train:  17%|█▋        | 77/456 [01:18<06:38,  1.05s/it]Loading train:  17%|█▋        | 78/456 [01:19<06:38,  1.06s/it]Loading train:  17%|█▋        | 79/456 [01:19<05:37,  1.12it/s]Loading train:  18%|█▊        | 80/456 [01:20<04:48,  1.30it/s]Loading train:  18%|█▊        | 81/456 [01:20<04:16,  1.46it/s]Loading train:  18%|█▊        | 82/456 [01:21<03:53,  1.60it/s]Loading train:  18%|█▊        | 83/456 [01:21<03:45,  1.66it/s]Loading train:  18%|█▊        | 84/456 [01:22<03:31,  1.76it/s]Loading train:  19%|█▊        | 85/456 [01:22<03:28,  1.78it/s]Loading train:  19%|█▉        | 86/456 [01:23<03:20,  1.85it/s]Loading train:  19%|█▉        | 87/456 [01:23<03:19,  1.85it/s]Loading train:  19%|█▉        | 88/456 [01:24<03:14,  1.89it/s]Loading train:  20%|█▉        | 89/456 [01:24<03:10,  1.93it/s]Loading train:  20%|█▉        | 90/456 [01:25<03:07,  1.96it/s]Loading train:  20%|█▉        | 91/456 [01:26<04:06,  1.48it/s]Loading train:  20%|██        | 92/456 [01:26<03:43,  1.63it/s]Loading train:  20%|██        | 93/456 [01:27<03:27,  1.75it/s]Loading train:  21%|██        | 94/456 [01:27<03:18,  1.82it/s]Loading train:  21%|██        | 95/456 [01:28<03:26,  1.75it/s]Loading train:  21%|██        | 96/456 [01:28<03:22,  1.78it/s]Loading train:  21%|██▏       | 97/456 [01:29<04:04,  1.47it/s]Loading train:  21%|██▏       | 98/456 [01:30<04:52,  1.22it/s]Loading train:  22%|██▏       | 99/456 [01:31<05:02,  1.18it/s]Loading train:  22%|██▏       | 100/456 [01:32<05:23,  1.10it/s]Loading train:  22%|██▏       | 101/456 [01:33<05:23,  1.10it/s]Loading train:  22%|██▏       | 102/456 [01:34<05:21,  1.10it/s]Loading train:  23%|██▎       | 103/456 [01:35<05:45,  1.02it/s]Loading train:  23%|██▎       | 104/456 [01:36<05:43,  1.02it/s]Loading train:  23%|██▎       | 105/456 [01:37<05:51,  1.00s/it]Loading train:  23%|██▎       | 106/456 [01:38<05:54,  1.01s/it]Loading train:  23%|██▎       | 107/456 [01:39<06:00,  1.03s/it]Loading train:  24%|██▎       | 108/456 [01:41<06:09,  1.06s/it]Loading train:  24%|██▍       | 109/456 [01:42<06:10,  1.07s/it]Loading train:  24%|██▍       | 110/456 [01:43<06:03,  1.05s/it]Loading train:  24%|██▍       | 111/456 [01:44<06:14,  1.09s/it]Loading train:  25%|██▍       | 112/456 [01:45<06:14,  1.09s/it]Loading train:  25%|██▍       | 113/456 [01:46<06:05,  1.07s/it]Loading train:  25%|██▌       | 114/456 [01:47<05:50,  1.03s/it]Loading train:  25%|██▌       | 115/456 [01:48<05:58,  1.05s/it]Loading train:  25%|██▌       | 116/456 [01:49<05:40,  1.00s/it]Loading train:  26%|██▌       | 117/456 [01:50<05:23,  1.05it/s]Loading train:  26%|██▌       | 118/456 [01:51<05:11,  1.09it/s]Loading train:  26%|██▌       | 119/456 [01:51<05:05,  1.10it/s]Loading train:  26%|██▋       | 120/456 [01:52<05:13,  1.07it/s]Loading train:  27%|██▋       | 121/456 [01:54<05:47,  1.04s/it]Loading train:  27%|██▋       | 122/456 [01:55<05:46,  1.04s/it]Loading train:  27%|██▋       | 123/456 [01:56<05:58,  1.08s/it]Loading train:  27%|██▋       | 124/456 [01:57<05:40,  1.03s/it]Loading train:  27%|██▋       | 125/456 [01:58<05:39,  1.03s/it]Loading train:  28%|██▊       | 126/456 [01:59<05:35,  1.02s/it]Loading train:  28%|██▊       | 127/456 [02:00<05:11,  1.06it/s]Loading train:  28%|██▊       | 128/456 [02:00<04:52,  1.12it/s]Loading train:  28%|██▊       | 129/456 [02:02<05:08,  1.06it/s]Loading train:  29%|██▊       | 130/456 [02:03<05:25,  1.00it/s]Loading train:  29%|██▊       | 131/456 [02:04<05:20,  1.01it/s]Loading train:  29%|██▉       | 132/456 [02:05<05:26,  1.01s/it]Loading train:  29%|██▉       | 133/456 [02:06<05:50,  1.09s/it]Loading train:  29%|██▉       | 134/456 [02:07<06:09,  1.15s/it]Loading train:  30%|██▉       | 135/456 [02:09<06:24,  1.20s/it]Loading train:  30%|██▉       | 136/456 [02:10<06:37,  1.24s/it]Loading train:  30%|███       | 137/456 [02:11<06:38,  1.25s/it]Loading train:  30%|███       | 138/456 [02:12<06:16,  1.18s/it]Loading train:  30%|███       | 139/456 [02:13<05:34,  1.06s/it]Loading train:  31%|███       | 140/456 [02:14<05:06,  1.03it/s]Loading train:  31%|███       | 141/456 [02:15<04:51,  1.08it/s]Loading train:  31%|███       | 142/456 [02:15<04:38,  1.13it/s]Loading train:  31%|███▏      | 143/456 [02:16<04:24,  1.18it/s]Loading train:  32%|███▏      | 144/456 [02:17<04:17,  1.21it/s]Loading train:  32%|███▏      | 145/456 [02:18<04:19,  1.20it/s]Loading train:  32%|███▏      | 146/456 [02:19<04:23,  1.18it/s]Loading train:  32%|███▏      | 147/456 [02:19<04:17,  1.20it/s]Loading train:  32%|███▏      | 148/456 [02:20<04:15,  1.21it/s]Loading train:  33%|███▎      | 149/456 [02:21<04:14,  1.21it/s]Loading train:  33%|███▎      | 150/456 [02:22<04:20,  1.18it/s]Loading train:  33%|███▎      | 151/456 [02:23<04:25,  1.15it/s]Loading train:  33%|███▎      | 152/456 [02:24<04:42,  1.07it/s]Loading train:  34%|███▎      | 153/456 [02:25<04:39,  1.08it/s]Loading train:  34%|███▍      | 154/456 [02:26<04:34,  1.10it/s]Loading train:  34%|███▍      | 155/456 [02:27<04:32,  1.11it/s]Loading train:  34%|███▍      | 156/456 [02:28<04:45,  1.05it/s]Loading train:  34%|███▍      | 157/456 [02:29<04:47,  1.04it/s]Loading train:  35%|███▍      | 158/456 [02:30<04:38,  1.07it/s]Loading train:  35%|███▍      | 159/456 [02:31<04:43,  1.05it/s]Loading train:  35%|███▌      | 160/456 [02:31<04:41,  1.05it/s]Loading train:  35%|███▌      | 161/456 [02:33<05:02,  1.03s/it]Loading train:  36%|███▌      | 162/456 [02:34<04:58,  1.02s/it]Loading train:  36%|███▌      | 163/456 [02:34<04:28,  1.09it/s]Loading train:  36%|███▌      | 164/456 [02:35<04:08,  1.17it/s]Loading train:  36%|███▌      | 165/456 [02:36<03:45,  1.29it/s]Loading train:  36%|███▋      | 166/456 [02:36<03:32,  1.36it/s]Loading train:  37%|███▋      | 167/456 [02:37<03:23,  1.42it/s]Loading train:  37%|███▋      | 168/456 [02:38<03:34,  1.34it/s]Loading train:  37%|███▋      | 169/456 [02:38<03:24,  1.41it/s]Loading train:  37%|███▋      | 170/456 [02:39<03:16,  1.45it/s]Loading train:  38%|███▊      | 171/456 [02:40<03:08,  1.52it/s]Loading train:  38%|███▊      | 172/456 [02:40<03:00,  1.57it/s]Loading train:  38%|███▊      | 173/456 [02:41<02:58,  1.58it/s]Loading train:  38%|███▊      | 174/456 [02:42<03:12,  1.47it/s]Loading train:  38%|███▊      | 175/456 [02:42<03:07,  1.50it/s]Loading train:  39%|███▊      | 176/456 [02:43<02:54,  1.60it/s]Loading train:  39%|███▉      | 177/456 [02:43<02:50,  1.63it/s]Loading train:  39%|███▉      | 178/456 [02:44<02:50,  1.63it/s]Loading train:  39%|███▉      | 179/456 [02:45<02:53,  1.60it/s]Loading train:  39%|███▉      | 180/456 [02:45<02:55,  1.57it/s]Loading train:  40%|███▉      | 181/456 [02:46<03:36,  1.27it/s]Loading train:  40%|███▉      | 182/456 [02:48<04:04,  1.12it/s]Loading train:  40%|████      | 183/456 [02:49<04:23,  1.04it/s]Loading train:  40%|████      | 184/456 [02:50<04:33,  1.01s/it]Loading train:  41%|████      | 185/456 [02:51<04:38,  1.03s/it]Loading train:  41%|████      | 186/456 [02:52<04:38,  1.03s/it]Loading train:  41%|████      | 187/456 [02:53<04:48,  1.07s/it]Loading train:  41%|████      | 188/456 [02:55<05:22,  1.20s/it]Loading train:  41%|████▏     | 189/456 [02:56<05:18,  1.19s/it]Loading train:  42%|████▏     | 190/456 [02:57<05:15,  1.19s/it]Loading train:  42%|████▏     | 191/456 [02:58<05:15,  1.19s/it]Loading train:  42%|████▏     | 192/456 [02:59<05:05,  1.16s/it]Loading train:  42%|████▏     | 193/456 [03:00<05:04,  1.16s/it]Loading train:  43%|████▎     | 194/456 [03:01<05:00,  1.15s/it]Loading train:  43%|████▎     | 195/456 [03:03<04:57,  1.14s/it]Loading train:  43%|████▎     | 196/456 [03:04<04:50,  1.12s/it]Loading train:  43%|████▎     | 197/456 [03:05<04:47,  1.11s/it]Loading train:  43%|████▎     | 198/456 [03:06<04:47,  1.11s/it]Loading train:  44%|████▎     | 199/456 [03:07<04:48,  1.12s/it]Loading train:  44%|████▍     | 200/456 [03:08<04:40,  1.09s/it]Loading train:  44%|████▍     | 201/456 [03:09<04:34,  1.08s/it]Loading train:  44%|████▍     | 202/456 [03:10<04:50,  1.14s/it]Loading train:  45%|████▍     | 203/456 [03:11<04:39,  1.10s/it]Loading train:  45%|████▍     | 204/456 [03:12<04:35,  1.09s/it]Loading train:  45%|████▍     | 205/456 [03:13<04:18,  1.03s/it]Loading train:  45%|████▌     | 206/456 [03:14<04:11,  1.01s/it]Loading train:  45%|████▌     | 207/456 [03:15<04:00,  1.03it/s]Loading train:  46%|████▌     | 208/456 [03:16<03:50,  1.08it/s]Loading train:  46%|████▌     | 209/456 [03:17<03:46,  1.09it/s]Loading train:  46%|████▌     | 210/456 [03:18<03:48,  1.07it/s]Loading train:  46%|████▋     | 211/456 [03:19<03:48,  1.07it/s]Loading train:  46%|████▋     | 212/456 [03:20<03:48,  1.07it/s]Loading train:  47%|████▋     | 213/456 [03:21<03:47,  1.07it/s]Loading train:  47%|████▋     | 214/456 [03:22<03:44,  1.08it/s]Loading train:  47%|████▋     | 215/456 [03:23<03:43,  1.08it/s]Loading train:  47%|████▋     | 216/456 [03:24<03:52,  1.03it/s]Loading train:  48%|████▊     | 217/456 [03:25<03:49,  1.04it/s]Loading train:  48%|████▊     | 218/456 [03:25<03:45,  1.05it/s]Loading train:  48%|████▊     | 219/456 [03:27<03:55,  1.01it/s]Loading train:  48%|████▊     | 220/456 [03:27<03:46,  1.04it/s]Loading train:  48%|████▊     | 221/456 [03:28<03:35,  1.09it/s]Loading train:  49%|████▊     | 222/456 [03:29<03:32,  1.10it/s]Loading train:  49%|████▉     | 223/456 [03:30<03:32,  1.10it/s]Loading train:  49%|████▉     | 224/456 [03:31<03:26,  1.12it/s]Loading train:  49%|████▉     | 225/456 [03:32<03:25,  1.12it/s]Loading train:  50%|████▉     | 226/456 [03:33<03:26,  1.12it/s]Loading train:  50%|████▉     | 227/456 [03:34<03:24,  1.12it/s]Loading train:  50%|█████     | 228/456 [03:34<03:23,  1.12it/s]Loading train:  50%|█████     | 229/456 [03:35<03:26,  1.10it/s]Loading train:  50%|█████     | 230/456 [03:36<03:28,  1.08it/s]Loading train:  51%|█████     | 231/456 [03:38<03:45,  1.00s/it]Loading train:  51%|█████     | 232/456 [03:39<03:49,  1.03s/it]Loading train:  51%|█████     | 233/456 [03:40<03:45,  1.01s/it]Loading train:  51%|█████▏    | 234/456 [03:41<03:45,  1.01s/it]Loading train:  52%|█████▏    | 235/456 [03:42<03:42,  1.01s/it]Loading train:  52%|█████▏    | 236/456 [03:43<03:36,  1.02it/s]Loading train:  52%|█████▏    | 237/456 [03:43<03:28,  1.05it/s]Loading train:  52%|█████▏    | 238/456 [03:44<03:32,  1.03it/s]Loading train:  52%|█████▏    | 239/456 [03:45<03:26,  1.05it/s]Loading train:  53%|█████▎    | 240/456 [03:46<03:21,  1.07it/s]Loading train:  53%|█████▎    | 241/456 [03:47<03:22,  1.06it/s]Loading train:  53%|█████▎    | 242/456 [03:48<03:20,  1.07it/s]Loading train:  53%|█████▎    | 243/456 [03:49<03:21,  1.06it/s]Loading train:  54%|█████▎    | 244/456 [03:50<03:31,  1.00it/s]Loading train:  54%|█████▎    | 245/456 [03:51<03:31,  1.00s/it]Loading train:  54%|█████▍    | 246/456 [03:52<03:36,  1.03s/it]Loading train:  54%|█████▍    | 247/456 [03:53<03:30,  1.01s/it]Loading train:  54%|█████▍    | 248/456 [03:54<03:31,  1.02s/it]Loading train:  55%|█████▍    | 249/456 [03:55<03:36,  1.05s/it]Loading train:  55%|█████▍    | 250/456 [03:56<03:34,  1.04s/it]Loading train:  55%|█████▌    | 251/456 [03:58<03:35,  1.05s/it]Loading train:  55%|█████▌    | 252/456 [03:59<03:31,  1.04s/it]Loading train:  55%|█████▌    | 253/456 [04:00<03:52,  1.14s/it]Loading train:  56%|█████▌    | 254/456 [04:01<04:06,  1.22s/it]Loading train:  56%|█████▌    | 255/456 [04:03<04:09,  1.24s/it]Loading train:  56%|█████▌    | 256/456 [04:05<04:52,  1.46s/it]Loading train:  56%|█████▋    | 257/456 [04:06<04:59,  1.50s/it]Loading train:  57%|█████▋    | 258/456 [04:08<04:51,  1.47s/it]Loading train:  57%|█████▋    | 259/456 [04:09<04:26,  1.35s/it]Loading train:  57%|█████▋    | 260/456 [04:10<04:09,  1.27s/it]Loading train:  57%|█████▋    | 261/456 [04:11<03:55,  1.21s/it]Loading train:  57%|█████▋    | 262/456 [04:12<03:39,  1.13s/it]Loading train:  58%|█████▊    | 263/456 [04:13<03:23,  1.05s/it]Loading train:  58%|█████▊    | 264/456 [04:14<03:21,  1.05s/it]Loading train:  58%|█████▊    | 265/456 [04:15<03:32,  1.11s/it]Loading train:  58%|█████▊    | 266/456 [04:16<03:18,  1.05s/it]Loading train:  59%|█████▊    | 267/456 [04:17<03:16,  1.04s/it]Loading train:  59%|█████▉    | 268/456 [04:18<03:18,  1.06s/it]Loading train:  59%|█████▉    | 269/456 [04:19<03:25,  1.10s/it]Loading train:  59%|█████▉    | 270/456 [04:21<03:54,  1.26s/it]Loading train:  59%|█████▉    | 271/456 [04:22<03:58,  1.29s/it]Loading train:  60%|█████▉    | 272/456 [04:23<03:45,  1.23s/it]Loading train:  60%|█████▉    | 273/456 [04:24<03:27,  1.14s/it]Loading train:  60%|██████    | 274/456 [04:25<03:13,  1.06s/it]Loading train:  60%|██████    | 275/456 [04:26<03:04,  1.02s/it]Loading train:  61%|██████    | 276/456 [04:27<02:58,  1.01it/s]Loading train:  61%|██████    | 277/456 [04:28<02:56,  1.01it/s]Loading train:  61%|██████    | 278/456 [04:29<02:53,  1.02it/s]Loading train:  61%|██████    | 279/456 [04:30<02:50,  1.04it/s]Loading train:  61%|██████▏   | 280/456 [04:31<02:55,  1.00it/s]Loading train:  62%|██████▏   | 281/456 [04:32<03:09,  1.08s/it]Loading train:  62%|██████▏   | 282/456 [04:33<03:03,  1.06s/it]Loading train:  62%|██████▏   | 283/456 [04:34<02:58,  1.03s/it]Loading train:  62%|██████▏   | 284/456 [04:35<02:38,  1.08it/s]Loading train:  62%|██████▎   | 285/456 [04:35<02:23,  1.19it/s]Loading train:  63%|██████▎   | 286/456 [04:36<02:20,  1.21it/s]Loading train:  63%|██████▎   | 287/456 [04:37<02:19,  1.21it/s]Loading train:  63%|██████▎   | 288/456 [04:38<02:11,  1.27it/s]Loading train:  63%|██████▎   | 289/456 [04:39<02:24,  1.16it/s]Loading train:  64%|██████▎   | 290/456 [04:39<02:15,  1.23it/s]Loading train:  64%|██████▍   | 291/456 [04:40<02:10,  1.26it/s]Loading train:  64%|██████▍   | 292/456 [04:41<02:03,  1.33it/s]Loading train:  64%|██████▍   | 293/456 [04:42<01:58,  1.37it/s]Loading train:  64%|██████▍   | 294/456 [04:42<01:55,  1.40it/s]Loading train:  65%|██████▍   | 295/456 [04:43<01:49,  1.47it/s]Loading train:  65%|██████▍   | 296/456 [04:43<01:42,  1.56it/s]Loading train:  65%|██████▌   | 297/456 [04:44<01:42,  1.56it/s]Loading train:  65%|██████▌   | 298/456 [04:45<01:42,  1.55it/s]Loading train:  66%|██████▌   | 299/456 [04:45<01:35,  1.64it/s]Loading train:  66%|██████▌   | 300/456 [04:46<01:29,  1.74it/s]Loading train:  66%|██████▌   | 301/456 [04:47<01:53,  1.37it/s]Loading train:  66%|██████▌   | 302/456 [04:48<02:07,  1.20it/s]Loading train:  66%|██████▋   | 303/456 [04:49<02:14,  1.14it/s]Loading train:  67%|██████▋   | 304/456 [04:50<02:22,  1.07it/s]Loading train:  67%|██████▋   | 305/456 [04:51<02:24,  1.05it/s]Loading train:  67%|██████▋   | 306/456 [04:52<02:28,  1.01it/s]Loading train:  67%|██████▋   | 307/456 [04:53<02:40,  1.08s/it]Loading train:  68%|██████▊   | 308/456 [04:54<02:42,  1.10s/it]Loading train:  68%|██████▊   | 309/456 [04:56<02:43,  1.11s/it]Loading train:  68%|██████▊   | 310/456 [04:57<02:46,  1.14s/it]Loading train:  68%|██████▊   | 311/456 [04:58<02:47,  1.15s/it]Loading train:  68%|██████▊   | 312/456 [04:59<02:46,  1.15s/it]Loading train:  69%|██████▊   | 313/456 [05:00<02:44,  1.15s/it]Loading train:  69%|██████▉   | 314/456 [05:01<02:39,  1.12s/it]Loading train:  69%|██████▉   | 315/456 [05:02<02:38,  1.12s/it]Loading train:  69%|██████▉   | 316/456 [05:04<02:37,  1.13s/it]Loading train:  70%|██████▉   | 317/456 [05:05<02:38,  1.14s/it]Loading train:  70%|██████▉   | 318/456 [05:06<02:37,  1.14s/it]Loading train:  70%|██████▉   | 319/456 [05:07<02:31,  1.11s/it]Loading train:  70%|███████   | 320/456 [05:08<02:23,  1.06s/it]Loading train:  70%|███████   | 321/456 [05:09<02:17,  1.02s/it]Loading train:  71%|███████   | 322/456 [05:10<02:13,  1.01it/s]Loading train:  71%|███████   | 323/456 [05:11<02:07,  1.04it/s]Loading train:  71%|███████   | 324/456 [05:11<02:05,  1.06it/s]Loading train:  71%|███████▏  | 325/456 [05:12<01:59,  1.10it/s]Loading train:  71%|███████▏  | 326/456 [05:13<01:52,  1.15it/s]Loading train:  72%|███████▏  | 327/456 [05:14<01:46,  1.21it/s]Loading train:  72%|███████▏  | 328/456 [05:15<01:42,  1.25it/s]Loading train:  72%|███████▏  | 329/456 [05:15<01:41,  1.25it/s]Loading train:  72%|███████▏  | 330/456 [05:16<01:38,  1.27it/s]Loading train:  73%|███████▎  | 331/456 [05:17<01:40,  1.24it/s]Loading train:  73%|███████▎  | 332/456 [05:18<01:40,  1.24it/s]Loading train:  73%|███████▎  | 333/456 [05:19<01:39,  1.23it/s]Loading train:  73%|███████▎  | 334/456 [05:19<01:36,  1.26it/s]Loading train:  73%|███████▎  | 335/456 [05:21<01:50,  1.10it/s]Loading train:  74%|███████▎  | 336/456 [05:21<01:50,  1.09it/s]Loading train:  74%|███████▍  | 337/456 [05:22<01:51,  1.07it/s]Loading train:  74%|███████▍  | 338/456 [05:23<01:50,  1.07it/s]Loading train:  74%|███████▍  | 339/456 [05:24<01:48,  1.07it/s]Loading train:  75%|███████▍  | 340/456 [05:25<01:47,  1.08it/s]Loading train:  75%|███████▍  | 341/456 [05:26<01:43,  1.11it/s]Loading train:  75%|███████▌  | 342/456 [05:27<01:42,  1.12it/s]Loading train:  75%|███████▌  | 343/456 [05:28<01:41,  1.11it/s]Loading train:  75%|███████▌  | 344/456 [05:29<01:41,  1.10it/s]Loading train:  76%|███████▌  | 345/456 [05:30<01:39,  1.11it/s]Loading train:  76%|███████▌  | 346/456 [05:31<01:39,  1.11it/s]Loading train:  76%|███████▌  | 347/456 [05:31<01:37,  1.12it/s]Loading train:  76%|███████▋  | 348/456 [05:32<01:36,  1.12it/s]Loading train:  77%|███████▋  | 349/456 [05:33<01:35,  1.12it/s]Loading train:  77%|███████▋  | 350/456 [05:34<01:35,  1.11it/s]Loading train:  77%|███████▋  | 351/456 [05:35<01:33,  1.12it/s]Loading train:  77%|███████▋  | 352/456 [05:36<01:31,  1.13it/s]Loading train:  77%|███████▋  | 353/456 [05:37<01:30,  1.14it/s]Loading train:  78%|███████▊  | 354/456 [05:38<01:30,  1.13it/s]Loading train:  78%|███████▊  | 355/456 [05:39<01:28,  1.14it/s]Loading train:  78%|███████▊  | 356/456 [05:39<01:27,  1.14it/s]Loading train:  78%|███████▊  | 357/456 [05:40<01:26,  1.14it/s]Loading train:  79%|███████▊  | 358/456 [05:41<01:26,  1.13it/s]Loading train:  79%|███████▊  | 359/456 [05:42<01:27,  1.11it/s]Loading train:  79%|███████▉  | 360/456 [05:43<01:26,  1.11it/s]Loading train:  79%|███████▉  | 361/456 [05:44<01:28,  1.07it/s]Loading train:  79%|███████▉  | 362/456 [05:45<01:27,  1.07it/s]Loading train:  80%|███████▉  | 363/456 [05:46<01:27,  1.06it/s]Loading train:  80%|███████▉  | 364/456 [05:47<01:25,  1.08it/s]Loading train:  80%|████████  | 365/456 [05:48<01:26,  1.05it/s]Loading train:  80%|████████  | 366/456 [05:49<01:24,  1.06it/s]Loading train:  80%|████████  | 367/456 [05:50<01:19,  1.12it/s]Loading train:  81%|████████  | 368/456 [05:50<01:14,  1.18it/s]Loading train:  81%|████████  | 369/456 [05:51<01:11,  1.22it/s]Loading train:  81%|████████  | 370/456 [05:52<01:08,  1.25it/s]Loading train:  81%|████████▏ | 371/456 [05:53<01:08,  1.23it/s]Loading train:  82%|████████▏ | 372/456 [05:53<01:07,  1.25it/s]Loading train:  82%|████████▏ | 373/456 [05:55<01:15,  1.10it/s]Loading train:  82%|████████▏ | 374/456 [05:56<01:19,  1.03it/s]Loading train:  82%|████████▏ | 375/456 [05:57<01:21,  1.01s/it]Loading train:  82%|████████▏ | 376/456 [05:58<01:27,  1.10s/it]Loading train:  83%|████████▎ | 377/456 [05:59<01:26,  1.10s/it]Loading train:  83%|████████▎ | 378/456 [06:01<01:32,  1.18s/it]Loading train:  83%|████████▎ | 379/456 [06:02<01:27,  1.14s/it]Loading train:  83%|████████▎ | 380/456 [06:02<01:18,  1.04s/it]Loading train:  84%|████████▎ | 381/456 [06:03<01:11,  1.04it/s]Loading train:  84%|████████▍ | 382/456 [06:04<01:06,  1.11it/s]Loading train:  84%|████████▍ | 383/456 [06:05<01:02,  1.16it/s]Loading train:  84%|████████▍ | 384/456 [06:05<01:00,  1.19it/s]Loading train:  84%|████████▍ | 385/456 [06:06<01:02,  1.13it/s]Loading train:  85%|████████▍ | 386/456 [06:08<01:05,  1.07it/s]Loading train:  85%|████████▍ | 387/456 [06:09<01:07,  1.03it/s]Loading train:  85%|████████▌ | 388/456 [06:10<01:08,  1.01s/it]Loading train:  85%|████████▌ | 389/456 [06:11<01:09,  1.03s/it]Loading train:  86%|████████▌ | 390/456 [06:12<01:07,  1.02s/it]Loading train:  86%|████████▌ | 391/456 [06:13<01:04,  1.00it/s]Loading train:  86%|████████▌ | 392/456 [06:14<01:07,  1.06s/it]Loading train:  86%|████████▌ | 393/456 [06:15<01:08,  1.08s/it]Loading train:  86%|████████▋ | 394/456 [06:16<01:05,  1.06s/it]Loading train:  87%|████████▋ | 395/456 [06:17<01:03,  1.04s/it]Loading train:  87%|████████▋ | 396/456 [06:18<00:59,  1.00it/s]Loading train:  87%|████████▋ | 397/456 [06:19<00:57,  1.03it/s]Loading train:  87%|████████▋ | 398/456 [06:20<00:54,  1.07it/s]Loading train:  88%|████████▊ | 399/456 [06:21<00:53,  1.07it/s]Loading train:  88%|████████▊ | 400/456 [06:22<00:52,  1.06it/s]Loading train:  88%|████████▊ | 401/456 [06:22<00:50,  1.09it/s]Loading train:  88%|████████▊ | 402/456 [06:23<00:48,  1.12it/s]Loading train:  88%|████████▊ | 403/456 [06:24<00:45,  1.16it/s]Loading train:  89%|████████▊ | 404/456 [06:25<00:43,  1.20it/s]Loading train:  89%|████████▉ | 405/456 [06:25<00:38,  1.32it/s]Loading train:  89%|████████▉ | 406/456 [06:26<00:35,  1.41it/s]Loading train:  89%|████████▉ | 407/456 [06:27<00:32,  1.50it/s]Loading train:  89%|████████▉ | 408/456 [06:27<00:31,  1.54it/s]Loading train:  90%|████████▉ | 409/456 [06:28<00:29,  1.60it/s]Loading train:  90%|████████▉ | 410/456 [06:28<00:27,  1.67it/s]Loading train:  90%|█████████ | 411/456 [06:29<00:27,  1.63it/s]Loading train:  90%|█████████ | 412/456 [06:30<00:29,  1.51it/s]Loading train:  91%|█████████ | 413/456 [06:30<00:27,  1.55it/s]Loading train:  91%|█████████ | 414/456 [06:31<00:27,  1.55it/s]Loading train:  91%|█████████ | 415/456 [06:32<00:26,  1.55it/s]Loading train:  91%|█████████ | 416/456 [06:32<00:26,  1.52it/s]Loading train:  91%|█████████▏| 417/456 [06:33<00:24,  1.60it/s]Loading train:  92%|█████████▏| 418/456 [06:33<00:22,  1.69it/s]Loading train:  92%|█████████▏| 419/456 [06:34<00:21,  1.72it/s]Loading train:  92%|█████████▏| 420/456 [06:34<00:20,  1.74it/s]Loading train:  92%|█████████▏| 421/456 [06:36<00:25,  1.36it/s]Loading train:  93%|█████████▎| 422/456 [06:37<00:28,  1.18it/s]Loading train:  93%|█████████▎| 423/456 [06:38<00:29,  1.13it/s]Loading train:  93%|█████████▎| 424/456 [06:39<00:30,  1.05it/s]Loading train:  93%|█████████▎| 425/456 [06:40<00:30,  1.01it/s]Loading train:  93%|█████████▎| 426/456 [06:41<00:30,  1.03s/it]Loading train:  94%|█████████▎| 427/456 [06:42<00:31,  1.09s/it]Loading train:  94%|█████████▍| 428/456 [06:43<00:32,  1.14s/it]Loading train:  94%|█████████▍| 429/456 [06:45<00:32,  1.20s/it]Loading train:  94%|█████████▍| 430/456 [06:46<00:31,  1.22s/it]Loading train:  95%|█████████▍| 431/456 [06:47<00:30,  1.22s/it]Loading train:  95%|█████████▍| 432/456 [06:49<00:29,  1.23s/it]Loading train:  95%|█████████▍| 433/456 [06:50<00:27,  1.20s/it]Loading train:  95%|█████████▌| 434/456 [06:51<00:26,  1.19s/it]Loading train:  95%|█████████▌| 435/456 [06:52<00:24,  1.16s/it]Loading train:  96%|█████████▌| 436/456 [06:53<00:22,  1.14s/it]Loading train:  96%|█████████▌| 437/456 [06:54<00:21,  1.13s/it]Loading train:  96%|█████████▌| 438/456 [06:55<00:19,  1.10s/it]Loading train:  96%|█████████▋| 439/456 [06:56<00:19,  1.13s/it]Loading train:  96%|█████████▋| 440/456 [06:57<00:17,  1.12s/it]Loading train:  97%|█████████▋| 441/456 [06:59<00:16,  1.11s/it]Loading train:  97%|█████████▋| 442/456 [07:00<00:15,  1.13s/it]Loading train:  97%|█████████▋| 443/456 [07:01<00:14,  1.08s/it]Loading train:  97%|█████████▋| 444/456 [07:02<00:13,  1.13s/it]Loading train:  98%|█████████▊| 445/456 [07:03<00:11,  1.07s/it]Loading train:  98%|█████████▊| 446/456 [07:04<00:10,  1.02s/it]Loading train:  98%|█████████▊| 447/456 [07:05<00:08,  1.06it/s]Loading train:  98%|█████████▊| 448/456 [07:05<00:07,  1.11it/s]Loading train:  98%|█████████▊| 449/456 [07:06<00:05,  1.18it/s]Loading train:  99%|█████████▊| 450/456 [07:07<00:04,  1.21it/s]Loading train:  99%|█████████▉| 451/456 [07:08<00:04,  1.22it/s]Loading train:  99%|█████████▉| 452/456 [07:09<00:03,  1.17it/s]Loading train:  99%|█████████▉| 453/456 [07:10<00:02,  1.14it/s]Loading train: 100%|█████████▉| 454/456 [07:11<00:01,  1.09it/s]Loading train: 100%|█████████▉| 455/456 [07:11<00:00,  1.08it/s]Loading train: 100%|██████████| 456/456 [07:12<00:00,  1.09it/s]
concatenating: train:   0%|          | 0/456 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 9/456 [00:00<00:05, 81.56it/s]concatenating: train:   7%|▋         | 34/456 [00:00<00:04, 102.07it/s]concatenating: train:  13%|█▎        | 60/456 [00:00<00:03, 124.18it/s]concatenating: train:  20%|█▉        | 91/456 [00:00<00:02, 151.16it/s]concatenating: train:  26%|██▌       | 118/456 [00:00<00:01, 173.85it/s]concatenating: train:  32%|███▏      | 146/456 [00:00<00:01, 195.22it/s]concatenating: train:  40%|███▉      | 181/456 [00:00<00:01, 224.12it/s]concatenating: train:  46%|████▌     | 208/456 [00:00<00:01, 229.93it/s]concatenating: train:  52%|█████▏    | 235/456 [00:00<00:00, 240.27it/s]concatenating: train:  57%|█████▋    | 262/456 [00:01<00:00, 246.33it/s]concatenating: train:  63%|██████▎   | 289/456 [00:01<00:00, 252.82it/s]concatenating: train:  70%|██████▉   | 317/456 [00:01<00:00, 258.46it/s]concatenating: train:  76%|███████▌  | 345/456 [00:01<00:00, 263.20it/s]concatenating: train:  82%|████████▏ | 372/456 [00:01<00:00, 248.87it/s]concatenating: train:  87%|████████▋ | 398/456 [00:01<00:00, 228.19it/s]concatenating: train:  94%|█████████▍| 428/456 [00:01<00:00, 243.98it/s]concatenating: train: 100%|█████████▉| 455/456 [00:01<00:00, 251.20it/s]concatenating: train: 100%|██████████| 456/456 [00:01<00:00, 252.64it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:01<00:03,  1.07s/it]Loading test:  50%|█████     | 2/4 [00:01<00:02,  1.02s/it]Loading test:  75%|███████▌  | 3/4 [00:02<00:01,  1.01s/it]Loading test: 100%|██████████| 4/4 [00:04<00:00,  1.02s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 42.44it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 56, 56, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 56, 56, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 56, 56, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 56, 56, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 56, 56, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 56, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 56, 56, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 56, 56, 16)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 16)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28, 28, 16)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 28, 30)   4350        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 28, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 28, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 28, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 28, 28, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 28, 28, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 28, 46)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 46)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 14, 14, 46)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 14, 14, 60)   24900       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 14, 14, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 14, 14, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 14, 14, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 14, 14, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 14, 14, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 14, 14, 106)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 14, 14, 106)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 28, 28, 30)   12750       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 28, 28, 76)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 28, 28, 30)   20550       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 28, 28, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 28, 28, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 28, 28, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 28, 28, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 28, 28, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 28, 28, 106)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-07 17:40:34.321440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 17:40:34.321563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 17:40:34.321578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 17:40:34.321587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 17:40:34.373948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 28, 28, 106)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 56, 56, 15)   6375        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 56, 31)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 56, 56, 15)   4200        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 56, 56, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 56, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 56, 56, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 56, 56, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 56, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 56, 46)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 56, 56, 46)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 56, 56, 13)   611         dropout_5[0][0]                  
==================================================================================================
Total params: 127,886
Trainable params: 127,286
Non-trainable params: 600
__________________________________________________________________________________________________
----- /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/model_weights.h5
 --- initialized from Model_3T /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1
------------------------------------------------------------------
class_weights [6.20353721e-02 2.84453234e-02 7.46802407e-02 1.01751126e-02
 2.50007361e-02 6.29472736e-03 7.25125636e-02 1.12798228e-01
 6.41401498e-02 1.31242354e-02 3.56291442e-01 1.74306703e-01
 1.95165508e-04]
Train on 27379 samples, validate on 259 samples
Epoch 1/300
 - 24s - loss: 1.1987 - acc: 0.9540 - mDice: 0.6227 - val_loss: 1.0338 - val_acc: 0.9715 - val_mDice: 0.6529

Epoch 00001: val_mDice improved from -inf to 0.65290, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 18s - loss: 1.0730 - acc: 0.9562 - mDice: 0.6505 - val_loss: 1.0536 - val_acc: 0.9716 - val_mDice: 0.6542

Epoch 00002: val_mDice improved from 0.65290 to 0.65416, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 17s - loss: 1.0284 - acc: 0.9572 - mDice: 0.6630 - val_loss: 1.0474 - val_acc: 0.9719 - val_mDice: 0.6663

Epoch 00003: val_mDice improved from 0.65416 to 0.66632, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 18s - loss: 0.9960 - acc: 0.9579 - mDice: 0.6730 - val_loss: 1.1042 - val_acc: 0.9709 - val_mDice: 0.6657

Epoch 00004: val_mDice did not improve from 0.66632
Epoch 5/300
 - 17s - loss: 0.9752 - acc: 0.9584 - mDice: 0.6792 - val_loss: 1.1006 - val_acc: 0.9716 - val_mDice: 0.6639

Epoch 00005: val_mDice did not improve from 0.66632
Epoch 6/300
 - 17s - loss: 0.9599 - acc: 0.9588 - mDice: 0.6838 - val_loss: 1.1502 - val_acc: 0.9714 - val_mDice: 0.6650

Epoch 00006: val_mDice did not improve from 0.66632
Epoch 7/300
 - 18s - loss: 0.9449 - acc: 0.9591 - mDice: 0.6886 - val_loss: 1.1356 - val_acc: 0.9717 - val_mDice: 0.6704

Epoch 00007: val_mDice improved from 0.66632 to 0.67038, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 8/300
 - 17s - loss: 0.9341 - acc: 0.9594 - mDice: 0.6916 - val_loss: 1.1582 - val_acc: 0.9716 - val_mDice: 0.6660

Epoch 00008: val_mDice did not improve from 0.67038
Epoch 9/300
 - 18s - loss: 0.9235 - acc: 0.9596 - mDice: 0.6949 - val_loss: 1.1328 - val_acc: 0.9715 - val_mDice: 0.6752

Epoch 00009: val_mDice improved from 0.67038 to 0.67521, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 10/300
 - 18s - loss: 0.9142 - acc: 0.9598 - mDice: 0.6983 - val_loss: 1.1502 - val_acc: 0.9717 - val_mDice: 0.6721

Epoch 00010: val_mDice did not improve from 0.67521
Epoch 11/300
 - 17s - loss: 0.9059 - acc: 0.9601 - mDice: 0.7007 - val_loss: 1.1853 - val_acc: 0.9716 - val_mDice: 0.6713

Epoch 00011: val_mDice did not improve from 0.67521
Epoch 12/300
 - 18s - loss: 0.8990 - acc: 0.9602 - mDice: 0.7030 - val_loss: 1.1556 - val_acc: 0.9717 - val_mDice: 0.6723

Epoch 00012: val_mDice did not improve from 0.67521
Epoch 13/300
 - 17s - loss: 0.8938 - acc: 0.9604 - mDice: 0.7049 - val_loss: 1.1717 - val_acc: 0.9719 - val_mDice: 0.6722

Epoch 00013: val_mDice did not improve from 0.67521
Epoch 14/300
 - 18s - loss: 0.8886 - acc: 0.9605 - mDice: 0.7063 - val_loss: 1.1336 - val_acc: 0.9720 - val_mDice: 0.6756

Epoch 00014: val_mDice improved from 0.67521 to 0.67556, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 15/300
 - 17s - loss: 0.8814 - acc: 0.9606 - mDice: 0.7087 - val_loss: 1.1407 - val_acc: 0.9714 - val_mDice: 0.6758

Epoch 00015: val_mDice improved from 0.67556 to 0.67577, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 16/300
 - 18s - loss: 0.8738 - acc: 0.9608 - mDice: 0.7114 - val_loss: 1.1438 - val_acc: 0.9719 - val_mDice: 0.6751

Epoch 00016: val_mDice did not improve from 0.67577
Epoch 17/300
 - 18s - loss: 0.8708 - acc: 0.9609 - mDice: 0.7116 - val_loss: 1.1527 - val_acc: 0.9715 - val_mDice: 0.6723

Epoch 00017: val_mDice did not improve from 0.67577
Epoch 18/300
 - 17s - loss: 0.8672 - acc: 0.9609 - mDice: 0.7133 - val_loss: 1.1600 - val_acc: 0.9717 - val_mDice: 0.6816

Epoch 00018: val_mDice improved from 0.67577 to 0.68162, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 19/300
 - 18s - loss: 0.8609 - acc: 0.9611 - mDice: 0.7150 - val_loss: 1.1393 - val_acc: 0.9716 - val_mDice: 0.6802

Epoch 00019: val_mDice did not improve from 0.68162
Epoch 20/300
 - 17s - loss: 0.8601 - acc: 0.9612 - mDice: 0.7156 - val_loss: 1.1444 - val_acc: 0.9719 - val_mDice: 0.6843

Epoch 00020: val_mDice improved from 0.68162 to 0.68434, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 21/300
 - 18s - loss: 0.8540 - acc: 0.9613 - mDice: 0.7173 - val_loss: 1.1451 - val_acc: 0.9720 - val_mDice: 0.6818

Epoch 00021: val_mDice did not improve from 0.68434
Epoch 22/300
 - 17s - loss: 0.8525 - acc: 0.9613 - mDice: 0.7175 - val_loss: 1.1549 - val_acc: 0.9715 - val_mDice: 0.6808

Epoch 00022: val_mDice did not improve from 0.68434
Epoch 23/300
 - 17s - loss: 0.8488 - acc: 0.9614 - mDice: 0.7192 - val_loss: 1.1956 - val_acc: 0.9710 - val_mDice: 0.6708

Epoch 00023: val_mDice did not improve from 0.68434
Epoch 24/300
 - 17s - loss: 0.8430 - acc: 0.9616 - mDice: 0.7208 - val_loss: 1.1908 - val_acc: 0.9715 - val_mDice: 0.6736

Epoch 00024: val_mDice did not improve from 0.68434
Epoch 25/300
 - 17s - loss: 0.8421 - acc: 0.9616 - mDice: 0.7214 - val_loss: 1.1942 - val_acc: 0.9719 - val_mDice: 0.6743

Epoch 00025: val_mDice did not improve from 0.68434
Epoch 26/300
 - 17s - loss: 0.8410 - acc: 0.9617 - mDice: 0.7217 - val_loss: 1.1629 - val_acc: 0.9716 - val_mDice: 0.6757

Epoch 00026: val_mDice did not improve from 0.68434
Epoch 27/300
 - 18s - loss: 0.8368 - acc: 0.9617 - mDice: 0.7233 - val_loss: 1.2293 - val_acc: 0.9712 - val_mDice: 0.6654

Epoch 00027: val_mDice did not improve from 0.68434
Epoch 28/300
 - 17s - loss: 0.8346 - acc: 0.9618 - mDice: 0.7237 - val_loss: 1.1501 - val_acc: 0.9719 - val_mDice: 0.6767

Epoch 00028: val_mDice did not improve from 0.68434
Epoch 29/300
 - 18s - loss: 0.8333 - acc: 0.9619 - mDice: 0.7245 - val_loss: 1.1926 - val_acc: 0.9715 - val_mDice: 0.6766

Epoch 00029: val_mDice did not improve from 0.68434
Epoch 30/300
 - 17s - loss: 0.8282 - acc: 0.9619 - mDice: 0.7259 - val_loss: 1.1779 - val_acc: 0.9716 - val_mDice: 0.6770

Epoch 00030: val_mDice did not improve from 0.68434
Epoch 31/300
 - 18s - loss: 0.8276 - acc: 0.9620 - mDice: 0.7260 - val_loss: 1.1946 - val_acc: 0.9716 - val_mDice: 0.6784

Epoch 00031: val_mDice did not improve from 0.68434
Epoch 32/300
 - 17s - loss: 0.8239 - acc: 0.9620 - mDice: 0.7273 - val_loss: 1.2045 - val_acc: 0.9712 - val_mDice: 0.6803

Epoch 00032: val_mDice did not improve from 0.68434
Epoch 33/300
 - 17s - loss: 0.8234 - acc: 0.9621 - mDice: 0.7277 - val_loss: 1.2096 - val_acc: 0.9712 - val_mDice: 0.6754

Epoch 00033: val_mDice did not improve from 0.68434
Epoch 34/300
 - 18s - loss: 0.8203 - acc: 0.9622 - mDice: 0.7282 - val_loss: 1.1842 - val_acc: 0.9714 - val_mDice: 0.6787

Epoch 00034: val_mDice did not improve from 0.68434
Epoch 35/300
 - 17s - loss: 0.8181 - acc: 0.9622 - mDice: 0.7286 - val_loss: 1.2111 - val_acc: 0.9717 - val_mDice: 0.6735

Epoch 00035: val_mDice did not improve from 0.68434
Epoch 36/300
 - 17s - loss: 0.8162 - acc: 0.9623 - mDice: 0.7297 - val_loss: 1.2159 - val_acc: 0.9714 - val_mDice: 0.6792

Epoch 00036: val_mDice did not improve from 0.68434
Epoch 37/300
 - 17s - loss: 0.8148 - acc: 0.9623 - mDice: 0.7303 - val_loss: 1.2444 - val_acc: 0.9713 - val_mDice: 0.6735

Epoch 00037: val_mDice did not improve from 0.68434
Epoch 38/300
 - 18s - loss: 0.8142 - acc: 0.9623 - mDice: 0.7306 - val_loss: 1.2362 - val_acc: 0.9714 - val_mDice: 0.6781

Epoch 00038: val_mDice did not improve from 0.68434
Epoch 39/300
 - 17s - loss: 0.8105 - acc: 0.9624 - mDice: 0.7315 - val_loss: 1.2133 - val_acc: 0.9715 - val_mDice: 0.6778

Epoch 00039: val_mDice did not improve from 0.68434
Epoch 40/300
 - 17s - loss: 0.8083 - acc: 0.9624 - mDice: 0.7324 - val_loss: 1.2304 - val_acc: 0.9714 - val_mDice: 0.6799

Epoch 00040: val_mDice did not improve from 0.68434
Epoch 41/300
 - 17s - loss: 0.8107 - acc: 0.9624 - mDice: 0.7314 - val_loss: 1.2027 - val_acc: 0.9717 - val_mDice: 0.6782

Epoch 00041: val_mDice did not improve from 0.68434
Epoch 42/300
 - 18s - loss: 0.8062 - acc: 0.9626 - mDice: 0.7333 - val_loss: 1.2185 - val_acc: 0.9713 - val_mDice: 0.6809

Epoch 00042: val_mDice did not improve from 0.68434
Epoch 43/300
 - 17s - loss: 0.8061 - acc: 0.9626 - mDice: 0.7330 - val_loss: 1.2112 - val_acc: 0.9716 - val_mDice: 0.6789

Epoch 00043: val_mDice did not improve from 0.68434
Epoch 44/300
 - 18s - loss: 0.8049 - acc: 0.9626 - mDice: 0.7332 - val_loss: 1.2462 - val_acc: 0.9708 - val_mDice: 0.6793

Epoch 00044: val_mDice did not improve from 0.68434
Epoch 45/300
 - 17s - loss: 0.8020 - acc: 0.9627 - mDice: 0.7345 - val_loss: 1.2232 - val_acc: 0.9713 - val_mDice: 0.6816

Epoch 00045: val_mDice did not improve from 0.68434
Epoch 46/300
 - 17s - loss: 0.8021 - acc: 0.9626 - mDice: 0.7342 - val_loss: 1.2636 - val_acc: 0.9710 - val_mDice: 0.6711

Epoch 00046: val_mDice did not improve from 0.68434
Epoch 47/300
 - 18s - loss: 0.8001 - acc: 0.9627 - mDice: 0.7347 - val_loss: 1.2280 - val_acc: 0.9710 - val_mDice: 0.6749

Epoch 00047: val_mDice did not improve from 0.68434
Epoch 48/300
 - 17s - loss: 0.7982 - acc: 0.9627 - mDice: 0.7355 - val_loss: 1.1996 - val_acc: 0.9715 - val_mDice: 0.6831

Epoch 00048: val_mDice did not improve from 0.68434
Epoch 49/300
 - 18s - loss: 0.7988 - acc: 0.9628 - mDice: 0.7354 - val_loss: 1.2199 - val_acc: 0.9709 - val_mDice: 0.6783

Epoch 00049: val_mDice did not improve from 0.68434
Epoch 50/300
 - 17s - loss: 0.7963 - acc: 0.9628 - mDice: 0.7365 - val_loss: 1.2199 - val_acc: 0.9713 - val_mDice: 0.6795

predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:03<00:09,  3.24s/it]predicting test subjects:  50%|█████     | 2/4 [00:04<00:05,  2.76s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:06<00:02,  2.44s/it]predicting test subjects: 100%|██████████| 4/4 [00:08<00:00,  2.28s/it]
predicting train subjects:   0%|          | 0/456 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/456 [00:02<15:10,  2.00s/it]predicting train subjects:   0%|          | 2/456 [00:03<14:42,  1.94s/it]predicting train subjects:   1%|          | 3/456 [00:05<13:55,  1.84s/it]predicting train subjects:   1%|          | 4/456 [00:06<12:58,  1.72s/it]predicting train subjects:   1%|          | 5/456 [00:09<14:08,  1.88s/it]predicting train subjects:   1%|▏         | 6/456 [00:10<13:50,  1.85s/it]predicting train subjects:   2%|▏         | 7/456 [00:12<12:55,  1.73s/it]predicting train subjects:   2%|▏         | 8/456 [00:13<11:08,  1.49s/it]predicting train subjects:   2%|▏         | 9/456 [00:15<11:58,  1.61s/it]predicting train subjects:   2%|▏         | 10/456 [00:17<12:43,  1.71s/it]predicting train subjects:   2%|▏         | 11/456 [00:18<13:06,  1.77s/it]predicting train subjects:   3%|▎         | 12/456 [00:19<11:18,  1.53s/it]predicting train subjects:   3%|▎         | 13/456 [00:21<11:57,  1.62s/it]predicting train subjects:   3%|▎         | 14/456 [00:23<12:13,  1.66s/it]predicting train subjects:   3%|▎         | 15/456 [00:24<10:42,  1.46s/it]predicting train subjects:   4%|▎         | 16/456 [00:26<11:32,  1.57s/it]predicting train subjects:   4%|▎         | 17/456 [00:28<12:43,  1.74s/it]predicting train subjects:   4%|▍         | 18/456 [00:30<12:34,  1.72s/it]predicting train subjects:   4%|▍         | 19/456 [00:31<12:20,  1.70s/it]predicting train subjects:   4%|▍         | 20/456 [00:33<11:43,  1.61s/it]predicting train subjects:   5%|▍         | 21/456 [00:34<11:49,  1.63s/it]predicting train subjects:   5%|▍         | 22/456 [00:36<11:56,  1.65s/it]predicting train subjects:   5%|▌         | 23/456 [00:38<12:26,  1.72s/it]predicting train subjects:   5%|▌         | 24/456 [00:39<10:40,  1.48s/it]predicting train subjects:   5%|▌         | 25/456 [00:41<11:14,  1.56s/it]predicting train subjects:   6%|▌         | 26/456 [00:42<11:31,  1.61s/it]predicting train subjects:   6%|▌         | 27/456 [00:44<11:45,  1.64s/it]predicting train subjects:   6%|▌         | 28/456 [00:46<11:48,  1.66s/it]predicting train subjects:   6%|▋         | 29/456 [00:47<11:39,  1.64s/it]predicting train subjects:   7%|▋         | 30/456 [00:49<11:39,  1.64s/it]predicting train subjects:   7%|▋         | 31/456 [00:51<11:37,  1.64s/it]predicting train subjects:   7%|▋         | 32/456 [00:52<11:35,  1.64s/it]predicting train subjects:   7%|▋         | 33/456 [00:54<11:29,  1.63s/it]predicting train subjects:   7%|▋         | 34/456 [00:56<11:26,  1.63s/it]predicting train subjects:   8%|▊         | 35/456 [00:57<11:24,  1.63s/it]predicting train subjects:   8%|▊         | 36/456 [00:59<11:26,  1.63s/it]predicting train subjects:   8%|▊         | 37/456 [01:00<11:23,  1.63s/it]predicting train subjects:   8%|▊         | 38/456 [01:02<11:26,  1.64s/it]predicting train subjects:   9%|▊         | 39/456 [01:04<11:17,  1.62s/it]predicting train subjects:   9%|▉         | 40/456 [01:05<11:18,  1.63s/it]predicting train subjects:   9%|▉         | 41/456 [01:07<11:21,  1.64s/it]predicting train subjects:   9%|▉         | 42/456 [01:09<11:17,  1.64s/it]predicting train subjects:   9%|▉         | 43/456 [01:11<11:44,  1.71s/it]predicting train subjects:  10%|▉         | 44/456 [01:12<11:47,  1.72s/it]predicting train subjects:  10%|▉         | 45/456 [01:14<11:50,  1.73s/it]predicting train subjects:  10%|█         | 46/456 [01:16<11:48,  1.73s/it]predicting train subjects:  10%|█         | 47/456 [01:17<11:46,  1.73s/it]predicting train subjects:  11%|█         | 48/456 [01:19<11:51,  1.74s/it]predicting train subjects:  11%|█         | 49/456 [01:21<11:46,  1.74s/it]predicting train subjects:  11%|█         | 50/456 [01:23<11:45,  1.74s/it]predicting train subjects:  11%|█         | 51/456 [01:25<12:23,  1.83s/it]predicting train subjects:  11%|█▏        | 52/456 [01:26<12:05,  1.79s/it]predicting train subjects:  12%|█▏        | 53/456 [01:28<12:07,  1.81s/it]predicting train subjects:  12%|█▏        | 54/456 [01:30<11:43,  1.75s/it]predicting train subjects:  12%|█▏        | 55/456 [01:32<11:27,  1.71s/it]predicting train subjects:  12%|█▏        | 56/456 [01:33<11:32,  1.73s/it]predicting train subjects:  12%|█▎        | 57/456 [01:35<11:36,  1.75s/it]predicting train subjects:  13%|█▎        | 58/456 [01:37<11:26,  1.73s/it]predicting train subjects:  13%|█▎        | 59/456 [01:39<11:30,  1.74s/it]predicting train subjects:  13%|█▎        | 60/456 [01:40<11:39,  1.77s/it]predicting train subjects:  13%|█▎        | 61/456 [01:42<11:27,  1.74s/it]predicting train subjects:  14%|█▎        | 62/456 [01:44<11:20,  1.73s/it]predicting train subjects:  14%|█▍        | 63/456 [01:46<11:31,  1.76s/it]predicting train subjects:  14%|█▍        | 64/456 [01:47<11:31,  1.76s/it]predicting train subjects:  14%|█▍        | 65/456 [01:49<11:32,  1.77s/it]predicting train subjects:  14%|█▍        | 66/456 [01:51<11:32,  1.78s/it]predicting train subjects:  15%|█▍        | 67/456 [01:53<11:30,  1.77s/it]predicting train subjects:  15%|█▍        | 68/456 [01:54<11:22,  1.76s/it]predicting train subjects:  15%|█▌        | 69/456 [01:56<11:16,  1.75s/it]predicting train subjects:  15%|█▌        | 70/456 [01:58<11:16,  1.75s/it]predicting train subjects:  16%|█▌        | 71/456 [02:00<11:14,  1.75s/it]predicting train subjects:  16%|█▌        | 72/456 [02:01<11:09,  1.74s/it]predicting train subjects:  16%|█▌        | 73/456 [02:03<11:09,  1.75s/it]predicting train subjects:  16%|█▌        | 74/456 [02:05<11:08,  1.75s/it]predicting train subjects:  16%|█▋        | 75/456 [02:07<11:04,  1.74s/it]predicting train subjects:  17%|█▋        | 76/456 [02:08<11:10,  1.77s/it]predicting train subjects:  17%|█▋        | 77/456 [02:10<11:01,  1.75s/it]predicting train subjects:  17%|█▋        | 78/456 [02:12<10:59,  1.74s/it]predicting train subjects:  17%|█▋        | 79/456 [02:13<09:19,  1.48s/it]predicting train subjects:  18%|█▊        | 80/456 [02:14<08:13,  1.31s/it]predicting train subjects:  18%|█▊        | 81/456 [02:15<07:23,  1.18s/it]predicting train subjects:  18%|█▊        | 82/456 [02:16<06:54,  1.11s/it]predicting train subjects:  18%|█▊        | 83/456 [02:16<06:37,  1.07s/it]predicting train subjects:  18%|█▊        | 84/456 [02:17<06:21,  1.03s/it]predicting train subjects:  19%|█▊        | 85/456 [02:18<06:06,  1.01it/s]predicting train subjects:  19%|█▉        | 86/456 [02:19<05:49,  1.06it/s]predicting train subjects:  19%|█▉        | 87/456 [02:20<05:47,  1.06it/s]predicting train subjects:  19%|█▉        | 88/456 [02:21<05:42,  1.08it/s]predicting train subjects:  20%|█▉        | 89/456 [02:22<05:37,  1.09it/s]predicting train subjects:  20%|█▉        | 90/456 [02:23<05:33,  1.10it/s]predicting train subjects:  20%|█▉        | 91/456 [02:24<05:30,  1.10it/s]predicting train subjects:  20%|██        | 92/456 [02:25<05:28,  1.11it/s]predicting train subjects:  20%|██        | 93/456 [02:25<05:30,  1.10it/s]predicting train subjects:  21%|██        | 94/456 [02:26<05:33,  1.09it/s]predicting train subjects:  21%|██        | 95/456 [02:27<05:42,  1.05it/s]predicting train subjects:  21%|██        | 96/456 [02:28<05:38,  1.06it/s]predicting train subjects:  21%|██▏       | 97/456 [02:30<07:06,  1.19s/it]predicting train subjects:  21%|██▏       | 98/456 [02:32<07:58,  1.34s/it]predicting train subjects:  22%|██▏       | 99/456 [02:34<08:35,  1.44s/it]predicting train subjects:  22%|██▏       | 100/456 [02:35<09:02,  1.52s/it]predicting train subjects:  22%|██▏       | 101/456 [02:37<09:10,  1.55s/it]predicting train subjects:  22%|██▏       | 102/456 [02:38<09:16,  1.57s/it]predicting train subjects:  23%|██▎       | 103/456 [02:40<09:29,  1.61s/it]predicting train subjects:  23%|██▎       | 104/456 [02:42<09:48,  1.67s/it]predicting train subjects:  23%|██▎       | 105/456 [02:44<09:52,  1.69s/it]predicting train subjects:  23%|██▎       | 106/456 [02:45<09:47,  1.68s/it]predicting train subjects:  23%|██▎       | 107/456 [02:47<09:49,  1.69s/it]predicting train subjects:  24%|██▎       | 108/456 [02:49<09:47,  1.69s/it]predicting train subjects:  24%|██▍       | 109/456 [02:50<09:37,  1.67s/it]predicting train subjects:  24%|██▍       | 110/456 [02:52<09:32,  1.65s/it]predicting train subjects:  24%|██▍       | 111/456 [02:54<09:35,  1.67s/it]predicting train subjects:  25%|██▍       | 112/456 [02:55<09:25,  1.64s/it]predicting train subjects:  25%|██▍       | 113/456 [02:57<09:17,  1.63s/it]predicting train subjects:  25%|██▌       | 114/456 [02:59<09:28,  1.66s/it]predicting train subjects:  25%|██▌       | 115/456 [03:00<09:40,  1.70s/it]predicting train subjects:  25%|██▌       | 116/456 [03:02<09:42,  1.71s/it]predicting train subjects:  26%|██▌       | 117/456 [03:04<09:31,  1.69s/it]predicting train subjects:  26%|██▌       | 118/456 [03:06<09:34,  1.70s/it]predicting train subjects:  26%|██▌       | 119/456 [03:07<09:45,  1.74s/it]predicting train subjects:  26%|██▋       | 120/456 [03:09<09:45,  1.74s/it]predicting train subjects:  27%|██▋       | 121/456 [03:11<09:54,  1.77s/it]predicting train subjects:  27%|██▋       | 122/456 [03:13<10:03,  1.81s/it]predicting train subjects:  27%|██▋       | 123/456 [03:15<09:53,  1.78s/it]predicting train subjects:  27%|██▋       | 124/456 [03:17<10:11,  1.84s/it]predicting train subjects:  27%|██▋       | 125/456 [03:18<10:07,  1.84s/it]predicting train subjects:  28%|██▊       | 126/456 [03:20<10:17,  1.87s/it]predicting train subjects:  28%|██▊       | 127/456 [03:22<09:38,  1.76s/it]predicting train subjects:  28%|██▊       | 128/456 [03:23<09:13,  1.69s/it]predicting train subjects:  28%|██▊       | 129/456 [03:25<08:46,  1.61s/it]predicting train subjects:  29%|██▊       | 130/456 [03:26<08:28,  1.56s/it]predicting train subjects:  29%|██▊       | 131/456 [03:28<08:21,  1.54s/it]predicting train subjects:  29%|██▉       | 132/456 [03:29<08:13,  1.52s/it]predicting train subjects:  29%|██▉       | 133/456 [03:31<09:13,  1.71s/it]predicting train subjects:  29%|██▉       | 134/456 [03:33<09:53,  1.84s/it]predicting train subjects:  30%|██▉       | 135/456 [03:36<10:30,  1.96s/it]predicting train subjects:  30%|██▉       | 136/456 [03:38<10:57,  2.05s/it]predicting train subjects:  30%|███       | 137/456 [03:40<11:05,  2.09s/it]predicting train subjects:  30%|███       | 138/456 [03:42<11:13,  2.12s/it]predicting train subjects:  30%|███       | 139/456 [03:44<10:04,  1.91s/it]predicting train subjects:  31%|███       | 140/456 [03:45<09:24,  1.79s/it]predicting train subjects:  31%|███       | 141/456 [03:47<08:59,  1.71s/it]predicting train subjects:  31%|███       | 142/456 [03:48<08:37,  1.65s/it]predicting train subjects:  31%|███▏      | 143/456 [03:50<08:25,  1.62s/it]predicting train subjects:  32%|███▏      | 144/456 [03:51<08:09,  1.57s/it]predicting train subjects:  32%|███▏      | 145/456 [03:53<08:14,  1.59s/it]predicting train subjects:  32%|███▏      | 146/456 [03:55<08:14,  1.60s/it]predicting train subjects:  32%|███▏      | 147/456 [03:56<08:20,  1.62s/it]predicting train subjects:  32%|███▏      | 148/456 [03:58<08:17,  1.61s/it]predicting train subjects:  33%|███▎      | 149/456 [03:59<08:08,  1.59s/it]predicting train subjects:  33%|███▎      | 150/456 [04:01<08:02,  1.58s/it]predicting train subjects:  33%|███▎      | 151/456 [04:03<08:09,  1.61s/it]predicting train subjects:  33%|███▎      | 152/456 [04:04<08:17,  1.64s/it]predicting train subjects:  34%|███▎      | 153/456 [04:06<08:16,  1.64s/it]predicting train subjects:  34%|███▍      | 154/456 [04:08<08:15,  1.64s/it]predicting train subjects:  34%|███▍      | 155/456 [04:09<08:18,  1.66s/it]predicting train subjects:  34%|███▍      | 156/456 [04:11<08:14,  1.65s/it]predicting train subjects:  34%|███▍      | 157/456 [04:12<07:59,  1.60s/it]predicting train subjects:  35%|███▍      | 158/456 [04:14<07:57,  1.60s/it]predicting train subjects:  35%|███▍      | 159/456 [04:15<07:45,  1.57s/it]predicting train subjects:  35%|███▌      | 160/456 [04:17<07:36,  1.54s/it]predicting train subjects:  35%|███▌      | 161/456 [04:19<07:38,  1.55s/it]predicting train subjects:  36%|███▌      | 162/456 [04:20<07:38,  1.56s/it]predicting train subjects:  36%|███▌      | 163/456 [04:21<06:47,  1.39s/it]predicting train subjects:  36%|███▌      | 164/456 [04:22<06:11,  1.27s/it]predicting train subjects:  36%|███▌      | 165/456 [04:23<05:47,  1.19s/it]predicting train subjects:  36%|███▋      | 166/456 [04:24<05:32,  1.15s/it]predicting train subjects:  37%|███▋      | 167/456 [04:25<05:17,  1.10s/it]predicting train subjects:  37%|███▋      | 168/456 [04:26<05:06,  1.06s/it]predicting train subjects:  37%|███▋      | 169/456 [04:27<04:59,  1.04s/it]predicting train subjects:  37%|███▋      | 170/456 [04:28<04:50,  1.02s/it]predicting train subjects:  38%|███▊      | 171/456 [04:29<04:46,  1.01s/it]predicting train subjects:  38%|███▊      | 172/456 [04:30<04:46,  1.01s/it]predicting train subjects:  38%|███▊      | 173/456 [04:31<04:41,  1.00it/s]predicting train subjects:  38%|███▊      | 174/456 [04:32<04:35,  1.02it/s]predicting train subjects:  38%|███▊      | 175/456 [04:33<04:28,  1.05it/s]predicting train subjects:  39%|███▊      | 176/456 [04:34<04:24,  1.06it/s]predicting train subjects:  39%|███▉      | 177/456 [04:35<04:24,  1.05it/s]predicting train subjects:  39%|███▉      | 178/456 [04:36<04:23,  1.06it/s]predicting train subjects:  39%|███▉      | 179/456 [04:37<04:16,  1.08it/s]predicting train subjects:  39%|███▉      | 180/456 [04:38<04:17,  1.07it/s]predicting train subjects:  40%|███▉      | 181/456 [04:39<05:33,  1.21s/it]predicting train subjects:  40%|███▉      | 182/456 [04:41<06:27,  1.41s/it]predicting train subjects:  40%|████      | 183/456 [04:43<07:01,  1.55s/it]predicting train subjects:  40%|████      | 184/456 [04:45<07:27,  1.64s/it]predicting train subjects:  41%|████      | 185/456 [04:47<07:51,  1.74s/it]predicting train subjects:  41%|████      | 186/456 [04:49<07:59,  1.78s/it]predicting train subjects:  41%|████      | 187/456 [04:51<08:23,  1.87s/it]predicting train subjects:  41%|████      | 188/456 [04:53<08:43,  1.95s/it]predicting train subjects:  41%|████▏     | 189/456 [04:55<09:04,  2.04s/it]predicting train subjects:  42%|████▏     | 190/456 [04:57<09:11,  2.07s/it]predicting train subjects:  42%|████▏     | 191/456 [05:00<09:23,  2.13s/it]predicting train subjects:  42%|████▏     | 192/456 [05:02<09:31,  2.16s/it]predicting train subjects:  42%|████▏     | 193/456 [05:04<09:18,  2.12s/it]predicting train subjects:  43%|████▎     | 194/456 [05:06<09:07,  2.09s/it]predicting train subjects:  43%|████▎     | 195/456 [05:08<08:53,  2.04s/it]predicting train subjects:  43%|████▎     | 196/456 [05:10<08:35,  1.98s/it]predicting train subjects:  43%|████▎     | 197/456 [05:12<08:22,  1.94s/it]predicting train subjects:  43%|████▎     | 198/456 [05:14<08:28,  1.97s/it]predicting train subjects:  44%|████▎     | 199/456 [05:15<08:15,  1.93s/it]predicting train subjects:  44%|████▍     | 200/456 [05:17<08:05,  1.90s/it]predicting train subjects:  44%|████▍     | 201/456 [05:19<07:56,  1.87s/it]predicting train subjects:  44%|████▍     | 202/456 [05:21<07:46,  1.84s/it]predicting train subjects:  45%|████▍     | 203/456 [05:23<07:33,  1.79s/it]predicting train subjects:  45%|████▍     | 204/456 [05:24<07:34,  1.80s/it]predicting train subjects:  45%|████▍     | 205/456 [05:26<07:05,  1.69s/it]predicting train subjects:  45%|████▌     | 206/456 [05:27<06:44,  1.62s/it]predicting train subjects:  45%|████▌     | 207/456 [05:29<06:31,  1.57s/it]predicting train subjects:  46%|████▌     | 208/456 [05:30<06:26,  1.56s/it]predicting train subjects:  46%|████▌     | 209/456 [05:32<06:18,  1.53s/it]predicting train subjects:  46%|████▌     | 210/456 [05:33<06:08,  1.50s/it]predicting train subjects:  46%|████▋     | 211/456 [05:35<06:32,  1.60s/it]predicting train subjects:  46%|████▋     | 212/456 [05:37<06:38,  1.63s/it]predicting train subjects:  47%|████▋     | 213/456 [05:38<06:42,  1.66s/it]predicting train subjects:  47%|████▋     | 214/456 [05:40<06:47,  1.68s/it]predicting train subjects:  47%|████▋     | 215/456 [05:42<06:54,  1.72s/it]predicting train subjects:  47%|████▋     | 216/456 [05:44<06:53,  1.72s/it]predicting train subjects:  48%|████▊     | 217/456 [05:45<06:48,  1.71s/it]predicting train subjects:  48%|████▊     | 218/456 [05:47<06:46,  1.71s/it]predicting train subjects:  48%|████▊     | 219/456 [05:49<06:43,  1.70s/it]predicting train subjects:  48%|████▊     | 220/456 [05:50<06:42,  1.71s/it]predicting train subjects:  48%|████▊     | 221/456 [05:52<06:42,  1.71s/it]predicting train subjects:  49%|████▊     | 222/456 [05:54<06:37,  1.70s/it]predicting train subjects:  49%|████▉     | 223/456 [05:56<06:40,  1.72s/it]predicting train subjects:  49%|████▉     | 224/456 [05:57<06:40,  1.72s/it]predicting train subjects:  49%|████▉     | 225/456 [05:59<06:43,  1.75s/it]predicting train subjects:  50%|████▉     | 226/456 [06:01<06:45,  1.76s/it]predicting train subjects:  50%|████▉     | 227/456 [06:03<06:44,  1.77s/it]predicting train subjects:  50%|█████     | 228/456 [06:04<06:31,  1.72s/it]predicting train subjects:  50%|█████     | 229/456 [06:06<06:22,  1.68s/it]predicting train subjects:  50%|█████     | 230/456 [06:08<06:16,  1.67s/it]predicting train subjects:  51%|█████     | 231/456 [06:09<06:10,  1.65s/it]predicting train subjects:  51%|█████     | 232/456 [06:11<06:04,  1.63s/it]predicting train subjects:  51%|█████     | 233/456 [06:12<06:05,  1.64s/it]predicting train subjects:  51%|█████▏    | 234/456 [06:14<06:07,  1.66s/it]predicting train subjects:  52%|█████▏    | 235/456 [06:16<06:18,  1.71s/it]predicting train subjects:  52%|█████▏    | 236/456 [06:18<06:18,  1.72s/it]predicting train subjects:  52%|█████▏    | 237/456 [06:19<06:15,  1.71s/it]predicting train subjects:  52%|█████▏    | 238/456 [06:21<06:13,  1.72s/it]predicting train subjects:  52%|█████▏    | 239/456 [06:23<06:18,  1.74s/it]predicting train subjects:  53%|█████▎    | 240/456 [06:25<06:13,  1.73s/it]predicting train subjects:  53%|█████▎    | 241/456 [06:26<06:15,  1.75s/it]predicting train subjects:  53%|█████▎    | 242/456 [06:28<06:14,  1.75s/it]predicting train subjects:  53%|█████▎    | 243/456 [06:30<06:16,  1.77s/it]predicting train subjects:  54%|█████▎    | 244/456 [06:32<06:14,  1.77s/it]predicting train subjects:  54%|█████▎    | 245/456 [06:34<06:14,  1.77s/it]predicting train subjects:  54%|█████▍    | 246/456 [06:35<06:09,  1.76s/it]predicting train subjects:  54%|█████▍    | 247/456 [06:37<05:47,  1.66s/it]predicting train subjects:  54%|█████▍    | 248/456 [06:38<05:31,  1.59s/it]predicting train subjects:  55%|█████▍    | 249/456 [06:40<05:16,  1.53s/it]predicting train subjects:  55%|█████▍    | 250/456 [06:41<05:07,  1.49s/it]predicting train subjects:  55%|█████▌    | 251/456 [06:42<04:59,  1.46s/it]predicting train subjects:  55%|█████▌    | 252/456 [06:44<04:54,  1.44s/it]predicting train subjects:  55%|█████▌    | 253/456 [06:46<05:36,  1.66s/it]predicting train subjects:  56%|█████▌    | 254/456 [06:48<05:56,  1.77s/it]predicting train subjects:  56%|█████▌    | 255/456 [06:50<06:12,  1.85s/it]predicting train subjects:  56%|█████▌    | 256/456 [06:52<06:24,  1.92s/it]predicting train subjects:  56%|█████▋    | 257/456 [06:54<06:35,  1.99s/it]predicting train subjects:  57%|█████▋    | 258/456 [06:56<06:43,  2.04s/it]predicting train subjects:  57%|█████▋    | 259/456 [06:58<06:08,  1.87s/it]predicting train subjects:  57%|█████▋    | 260/456 [06:59<05:40,  1.74s/it]predicting train subjects:  57%|█████▋    | 261/456 [07:01<05:21,  1.65s/it]predicting train subjects:  57%|█████▋    | 262/456 [07:02<05:11,  1.60s/it]predicting train subjects:  58%|█████▊    | 263/456 [07:04<04:58,  1.55s/it]predicting train subjects:  58%|█████▊    | 264/456 [07:05<04:49,  1.51s/it]predicting train subjects:  58%|█████▊    | 265/456 [07:07<04:49,  1.52s/it]predicting train subjects:  58%|█████▊    | 266/456 [07:08<04:58,  1.57s/it]predicting train subjects:  59%|█████▊    | 267/456 [07:10<04:59,  1.59s/it]predicting train subjects:  59%|█████▉    | 268/456 [07:12<05:01,  1.60s/it]predicting train subjects:  59%|█████▉    | 269/456 [07:13<05:01,  1.61s/it]predicting train subjects:  59%|█████▉    | 270/456 [07:15<04:57,  1.60s/it]predicting train subjects:  59%|█████▉    | 271/456 [07:16<05:03,  1.64s/it]predicting train subjects:  60%|█████▉    | 272/456 [07:18<05:04,  1.66s/it]predicting train subjects:  60%|█████▉    | 273/456 [07:20<05:10,  1.70s/it]predicting train subjects:  60%|██████    | 274/456 [07:22<05:08,  1.70s/it]predicting train subjects:  60%|██████    | 275/456 [07:23<05:06,  1.69s/it]predicting train subjects:  61%|██████    | 276/456 [07:25<05:23,  1.79s/it]predicting train subjects:  61%|██████    | 277/456 [07:27<05:13,  1.75s/it]predicting train subjects:  61%|██████    | 278/456 [07:29<05:02,  1.70s/it]predicting train subjects:  61%|██████    | 279/456 [07:30<04:53,  1.66s/it]predicting train subjects:  61%|██████▏   | 280/456 [07:32<04:50,  1.65s/it]predicting train subjects:  62%|██████▏   | 281/456 [07:33<04:44,  1.62s/it]predicting train subjects:  62%|██████▏   | 282/456 [07:35<04:38,  1.60s/it]predicting train subjects:  62%|██████▏   | 283/456 [07:36<04:06,  1.42s/it]predicting train subjects:  62%|██████▏   | 284/456 [07:37<03:43,  1.30s/it]predicting train subjects:  62%|██████▎   | 285/456 [07:38<03:29,  1.23s/it]predicting train subjects:  63%|██████▎   | 286/456 [07:39<03:16,  1.16s/it]predicting train subjects:  63%|██████▎   | 287/456 [07:40<03:05,  1.10s/it]predicting train subjects:  63%|██████▎   | 288/456 [07:41<02:58,  1.06s/it]predicting train subjects:  63%|██████▎   | 289/456 [07:42<02:54,  1.04s/it]predicting train subjects:  64%|██████▎   | 290/456 [07:43<02:54,  1.05s/it]predicting train subjects:  64%|██████▍   | 291/456 [07:44<02:51,  1.04s/it]predicting train subjects:  64%|██████▍   | 292/456 [07:45<02:47,  1.02s/it]predicting train subjects:  64%|██████▍   | 293/456 [07:46<02:46,  1.02s/it]predicting train subjects:  64%|██████▍   | 294/456 [07:47<02:46,  1.03s/it]predicting train subjects:  65%|██████▍   | 295/456 [07:48<02:42,  1.01s/it]predicting train subjects:  65%|██████▍   | 296/456 [07:49<02:37,  1.02it/s]predicting train subjects:  65%|██████▌   | 297/456 [07:50<02:33,  1.04it/s]predicting train subjects:  65%|██████▌   | 298/456 [07:51<02:32,  1.03it/s]predicting train subjects:  66%|██████▌   | 299/456 [07:52<02:31,  1.03it/s]predicting train subjects:  66%|██████▌   | 300/456 [07:53<02:31,  1.03it/s]predicting train subjects:  66%|██████▌   | 301/456 [07:55<03:14,  1.25s/it]predicting train subjects:  66%|██████▌   | 302/456 [07:57<03:43,  1.45s/it]predicting train subjects:  66%|██████▋   | 303/456 [07:59<04:04,  1.60s/it]predicting train subjects:  67%|██████▋   | 304/456 [08:00<04:19,  1.71s/it]predicting train subjects:  67%|██████▋   | 305/456 [08:02<04:25,  1.76s/it]predicting train subjects:  67%|██████▋   | 306/456 [08:04<04:29,  1.79s/it]predicting train subjects:  67%|██████▋   | 307/456 [08:06<04:45,  1.92s/it]predicting train subjects:  68%|██████▊   | 308/456 [08:09<04:53,  1.98s/it]predicting train subjects:  68%|██████▊   | 309/456 [08:11<04:54,  2.00s/it]predicting train subjects:  68%|██████▊   | 310/456 [08:13<04:58,  2.04s/it]predicting train subjects:  68%|██████▊   | 311/456 [08:15<04:57,  2.05s/it]predicting train subjects:  68%|██████▊   | 312/456 [08:17<05:03,  2.11s/it]predicting train subjects:  69%|██████▊   | 313/456 [08:19<04:52,  2.04s/it]predicting train subjects:  69%|██████▉   | 314/456 [08:21<04:42,  1.99s/it]predicting train subjects:  69%|██████▉   | 315/456 [08:23<04:39,  1.98s/it]predicting train subjects:  69%|██████▉   | 316/456 [08:25<04:31,  1.94s/it]predicting train subjects:  70%|██████▉   | 317/456 [08:27<04:37,  1.99s/it]predicting train subjects:  70%|██████▉   | 318/456 [08:29<04:34,  1.99s/it]predicting train subjects:  70%|██████▉   | 319/456 [08:30<04:21,  1.91s/it]predicting train subjects:  70%|███████   | 320/456 [08:32<04:11,  1.85s/it]predicting train subjects:  70%|███████   | 321/456 [08:34<04:01,  1.79s/it]predicting train subjects:  71%|███████   | 322/456 [08:36<03:59,  1.79s/it]predicting train subjects:  71%|███████   | 323/456 [08:37<03:52,  1.74s/it]predicting train subjects:  71%|███████   | 324/456 [08:39<03:47,  1.72s/it]predicting train subjects:  71%|███████▏  | 325/456 [08:40<03:35,  1.64s/it]predicting train subjects:  71%|███████▏  | 326/456 [08:42<03:23,  1.56s/it]predicting train subjects:  72%|███████▏  | 327/456 [08:43<03:16,  1.52s/it]predicting train subjects:  72%|███████▏  | 328/456 [08:45<03:09,  1.48s/it]predicting train subjects:  72%|███████▏  | 329/456 [08:46<03:05,  1.46s/it]predicting train subjects:  72%|███████▏  | 330/456 [08:47<03:04,  1.46s/it]predicting train subjects:  73%|███████▎  | 331/456 [08:49<03:12,  1.54s/it]predicting train subjects:  73%|███████▎  | 332/456 [08:51<03:16,  1.58s/it]predicting train subjects:  73%|███████▎  | 333/456 [08:52<03:18,  1.61s/it]predicting train subjects:  73%|███████▎  | 334/456 [08:54<03:22,  1.66s/it]predicting train subjects:  73%|███████▎  | 335/456 [08:56<03:28,  1.72s/it]predicting train subjects:  74%|███████▎  | 336/456 [08:58<03:34,  1.79s/it]predicting train subjects:  74%|███████▍  | 337/456 [09:00<03:28,  1.75s/it]predicting train subjects:  74%|███████▍  | 338/456 [09:01<03:24,  1.73s/it]predicting train subjects:  74%|███████▍  | 339/456 [09:03<03:24,  1.75s/it]predicting train subjects:  75%|███████▍  | 340/456 [09:05<03:23,  1.75s/it]predicting train subjects:  75%|███████▍  | 341/456 [09:07<03:19,  1.74s/it]predicting train subjects:  75%|███████▌  | 342/456 [09:08<03:16,  1.72s/it]predicting train subjects:  75%|███████▌  | 343/456 [09:10<03:15,  1.73s/it]predicting train subjects:  75%|███████▌  | 344/456 [09:12<03:13,  1.73s/it]predicting train subjects:  76%|███████▌  | 345/456 [09:14<03:11,  1.72s/it]predicting train subjects:  76%|███████▌  | 346/456 [09:15<03:11,  1.74s/it]predicting train subjects:  76%|███████▌  | 347/456 [09:17<03:05,  1.71s/it]predicting train subjects:  76%|███████▋  | 348/456 [09:19<03:00,  1.68s/it]predicting train subjects:  77%|███████▋  | 349/456 [09:20<02:56,  1.65s/it]predicting train subjects:  77%|███████▋  | 350/456 [09:22<02:53,  1.64s/it]predicting train subjects:  77%|███████▋  | 351/456 [09:23<02:52,  1.64s/it]predicting train subjects:  77%|███████▋  | 352/456 [09:25<02:51,  1.65s/it]predicting train subjects:  77%|███████▋  | 353/456 [09:27<02:51,  1.67s/it]predicting train subjects:  78%|███████▊  | 354/456 [09:28<02:49,  1.66s/it]predicting train subjects:  78%|███████▊  | 355/456 [09:30<02:52,  1.71s/it]predicting train subjects:  78%|███████▊  | 356/456 [09:32<02:53,  1.73s/it]predicting train subjects:  78%|███████▊  | 357/456 [09:34<02:53,  1.76s/it]predicting train subjects:  79%|███████▊  | 358/456 [09:36<02:53,  1.77s/it]predicting train subjects:  79%|███████▊  | 359/456 [09:37<02:52,  1.78s/it]predicting train subjects:  79%|███████▉  | 360/456 [09:39<02:49,  1.77s/it]predicting train subjects:  79%|███████▉  | 361/456 [09:41<02:50,  1.80s/it]predicting train subjects:  79%|███████▉  | 362/456 [09:43<02:48,  1.80s/it]predicting train subjects:  80%|███████▉  | 363/456 [09:45<02:47,  1.80s/it]predicting train subjects:  80%|███████▉  | 364/456 [09:46<02:45,  1.80s/it]predicting train subjects:  80%|████████  | 365/456 [09:48<02:46,  1.83s/it]predicting train subjects:  80%|████████  | 366/456 [09:50<02:43,  1.82s/it]predicting train subjects:  80%|████████  | 367/456 [09:52<02:31,  1.70s/it]predicting train subjects:  81%|████████  | 368/456 [09:53<02:23,  1.63s/it]predicting train subjects:  81%|████████  | 369/456 [09:55<02:17,  1.58s/it]predicting train subjects:  81%|████████  | 370/456 [09:56<02:13,  1.55s/it]predicting train subjects:  81%|████████▏ | 371/456 [09:57<02:09,  1.52s/it]predicting train subjects:  82%|████████▏ | 372/456 [09:59<02:04,  1.48s/it]predicting train subjects:  82%|████████▏ | 373/456 [10:01<02:17,  1.65s/it]predicting train subjects:  82%|████████▏ | 374/456 [10:03<02:27,  1.79s/it]predicting train subjects:  82%|████████▏ | 375/456 [10:05<02:34,  1.91s/it]predicting train subjects:  82%|████████▏ | 376/456 [10:07<02:37,  1.97s/it]predicting train subjects:  83%|████████▎ | 377/456 [10:10<02:42,  2.05s/it]predicting train subjects:  83%|████████▎ | 378/456 [10:12<02:43,  2.09s/it]predicting train subjects:  83%|████████▎ | 379/456 [10:13<02:27,  1.92s/it]predicting train subjects:  83%|████████▎ | 380/456 [10:15<02:16,  1.79s/it]predicting train subjects:  84%|████████▎ | 381/456 [10:16<02:06,  1.69s/it]predicting train subjects:  84%|████████▍ | 382/456 [10:18<02:00,  1.63s/it]predicting train subjects:  84%|████████▍ | 383/456 [10:19<01:55,  1.58s/it]predicting train subjects:  84%|████████▍ | 384/456 [10:21<01:51,  1.55s/it]predicting train subjects:  84%|████████▍ | 385/456 [10:22<01:54,  1.61s/it]predicting train subjects:  85%|████████▍ | 386/456 [10:24<01:52,  1.60s/it]predicting train subjects:  85%|████████▍ | 387/456 [10:25<01:48,  1.58s/it]predicting train subjects:  85%|████████▌ | 388/456 [10:27<01:44,  1.54s/it]predicting train subjects:  85%|████████▌ | 389/456 [10:28<01:43,  1.55s/it]predicting train subjects:  86%|████████▌ | 390/456 [10:30<01:42,  1.56s/it]predicting train subjects:  86%|████████▌ | 391/456 [10:32<01:43,  1.59s/it]predicting train subjects:  86%|████████▌ | 392/456 [10:33<01:44,  1.63s/it]predicting train subjects:  86%|████████▌ | 393/456 [10:35<01:42,  1.63s/it]predicting train subjects:  86%|████████▋ | 394/456 [10:37<01:41,  1.63s/it]predicting train subjects:  87%|████████▋ | 395/456 [10:38<01:39,  1.63s/it]predicting train subjects:  87%|████████▋ | 396/456 [10:40<01:37,  1.63s/it]predicting train subjects:  87%|████████▋ | 397/456 [10:42<01:35,  1.62s/it]predicting train subjects:  87%|████████▋ | 398/456 [10:43<01:33,  1.62s/it]predicting train subjects:  88%|████████▊ | 399/456 [10:45<01:31,  1.60s/it]predicting train subjects:  88%|████████▊ | 400/456 [10:46<01:29,  1.60s/it]predicting train subjects:  88%|████████▊ | 401/456 [10:48<01:27,  1.59s/it]predicting train subjects:  88%|████████▊ | 402/456 [10:49<01:23,  1.54s/it]predicting train subjects:  88%|████████▊ | 403/456 [10:50<01:12,  1.37s/it]predicting train subjects:  89%|████████▊ | 404/456 [10:51<01:04,  1.24s/it]predicting train subjects:  89%|████████▉ | 405/456 [10:52<00:58,  1.16s/it]predicting train subjects:  89%|████████▉ | 406/456 [10:53<00:54,  1.09s/it]predicting train subjects:  89%|████████▉ | 407/456 [10:54<00:51,  1.04s/it]predicting train subjects:  89%|████████▉ | 408/456 [10:55<00:48,  1.00s/it]predicting train subjects:  90%|████████▉ | 409/456 [10:56<00:47,  1.00s/it]predicting train subjects:  90%|████████▉ | 410/456 [10:57<00:45,  1.01it/s]predicting train subjects:  90%|█████████ | 411/456 [10:58<00:45,  1.00s/it]predicting train subjects:  90%|█████████ | 412/456 [10:59<00:44,  1.01s/it]predicting train subjects:  91%|█████████ | 413/456 [11:00<00:43,  1.02s/it]predicting train subjects:  91%|█████████ | 414/456 [11:01<00:41,  1.00it/s]predicting train subjects:  91%|█████████ | 415/456 [11:02<00:39,  1.03it/s]predicting train subjects:  91%|█████████ | 416/456 [11:03<00:38,  1.03it/s]predicting train subjects:  91%|█████████▏| 417/456 [11:04<00:37,  1.05it/s]predicting train subjects:  92%|█████████▏| 418/456 [11:05<00:35,  1.06it/s]predicting train subjects:  92%|█████████▏| 419/456 [11:06<00:35,  1.06it/s]predicting train subjects:  92%|█████████▏| 420/456 [11:07<00:33,  1.06it/s]predicting train subjects:  92%|█████████▏| 421/456 [11:08<00:42,  1.22s/it]predicting train subjects:  93%|█████████▎| 422/456 [11:10<00:48,  1.42s/it]predicting train subjects:  93%|█████████▎| 423/456 [11:12<00:50,  1.54s/it]predicting train subjects:  93%|█████████▎| 424/456 [11:14<00:52,  1.63s/it]predicting train subjects:  93%|█████████▎| 425/456 [11:16<00:53,  1.72s/it]predicting train subjects:  93%|█████████▎| 426/456 [11:18<00:52,  1.76s/it]predicting train subjects:  94%|█████████▎| 427/456 [11:20<00:54,  1.89s/it]predicting train subjects:  94%|█████████▍| 428/456 [11:22<00:55,  2.00s/it]predicting train subjects:  94%|█████████▍| 429/456 [11:24<00:54,  2.02s/it]predicting train subjects:  94%|█████████▍| 430/456 [11:26<00:53,  2.07s/it]predicting train subjects:  95%|█████████▍| 431/456 [11:29<00:51,  2.08s/it]predicting train subjects:  95%|█████████▍| 432/456 [11:31<00:49,  2.06s/it]predicting train subjects:  95%|█████████▍| 433/456 [11:33<00:47,  2.05s/it]predicting train subjects:  95%|█████████▌| 434/456 [11:35<00:44,  2.01s/it]predicting train subjects:  95%|█████████▌| 435/456 [11:37<00:41,  2.00s/it]predicting train subjects:  96%|█████████▌| 436/456 [11:38<00:39,  1.97s/it]predicting train subjects:  96%|█████████▌| 437/456 [11:40<00:37,  1.97s/it]predicting train subjects:  96%|█████████▌| 438/456 [11:42<00:35,  1.96s/it]predicting train subjects:  96%|█████████▋| 439/456 [11:44<00:32,  1.91s/it]predicting train subjects:  96%|█████████▋| 440/456 [11:46<00:29,  1.86s/it]predicting train subjects:  97%|█████████▋| 441/456 [11:48<00:27,  1.81s/it]predicting train subjects:  97%|█████████▋| 442/456 [11:49<00:25,  1.82s/it]predicting train subjects:  97%|█████████▋| 443/456 [11:51<00:23,  1.81s/it]predicting train subjects:  97%|█████████▋| 444/456 [11:53<00:21,  1.79s/it]predicting train subjects:  98%|█████████▊| 445/456 [11:55<00:18,  1.72s/it]predicting train subjects:  98%|█████████▊| 446/456 [11:56<00:16,  1.63s/it]predicting train subjects:  98%|█████████▊| 447/456 [11:57<00:14,  1.58s/it]predicting train subjects:  98%|█████████▊| 448/456 [11:59<00:12,  1.56s/it]predicting train subjects:  98%|█████████▊| 449/456 [12:00<00:10,  1.52s/it]predicting train subjects:  99%|█████████▊| 450/456 [12:02<00:09,  1.57s/it]predicting train subjects:  99%|█████████▉| 451/456 [12:04<00:08,  1.62s/it]predicting train subjects:  99%|█████████▉| 452/456 [12:05<00:06,  1.63s/it]predicting train subjects:  99%|█████████▉| 453/456 [12:07<00:04,  1.63s/it]predicting train subjects: 100%|█████████▉| 454/456 [12:09<00:03,  1.63s/it]predicting train subjects: 100%|█████████▉| 455/456 [12:10<00:01,  1.63s/it]predicting train subjects: 100%|██████████| 456/456 [12:12<00:00,  1.63s/it]
Loading train:   0%|          | 0/456 [00:00<?, ?it/s]Loading train:   0%|          | 1/456 [00:01<09:19,  1.23s/it]Loading train:   0%|          | 2/456 [00:02<08:50,  1.17s/it]Loading train:   1%|          | 3/456 [00:03<07:58,  1.06s/it]Loading train:   1%|          | 4/456 [00:03<07:24,  1.02it/s]Loading train:   1%|          | 5/456 [00:04<07:35,  1.01s/it]Loading train:   1%|▏         | 6/456 [00:05<07:33,  1.01s/it]Loading train:   2%|▏         | 7/456 [00:06<07:02,  1.06it/s]Loading train:   2%|▏         | 8/456 [00:07<06:12,  1.20it/s]Loading train:   2%|▏         | 9/456 [00:08<06:19,  1.18it/s]Loading train:   2%|▏         | 10/456 [00:09<06:39,  1.12it/s]Loading train:   2%|▏         | 11/456 [00:10<06:50,  1.08it/s]Loading train:   3%|▎         | 12/456 [00:10<06:24,  1.15it/s]Loading train:   3%|▎         | 13/456 [00:11<06:37,  1.11it/s]Loading train:   3%|▎         | 14/456 [00:12<06:39,  1.11it/s]Loading train:   3%|▎         | 15/456 [00:13<06:18,  1.16it/s]Loading train:   4%|▎         | 16/456 [00:14<06:51,  1.07it/s]Loading train:   4%|▎         | 17/456 [00:15<07:03,  1.04it/s]Loading train:   4%|▍         | 18/456 [00:16<06:53,  1.06it/s]Loading train:   4%|▍         | 19/456 [00:17<06:45,  1.08it/s]Loading train:   4%|▍         | 20/456 [00:18<06:12,  1.17it/s]Loading train:   5%|▍         | 21/456 [00:18<06:04,  1.19it/s]Loading train:   5%|▍         | 22/456 [00:19<06:02,  1.20it/s]Loading train:   5%|▌         | 23/456 [00:20<05:57,  1.21it/s]Loading train:   5%|▌         | 24/456 [00:21<05:36,  1.28it/s]Loading train:   5%|▌         | 25/456 [00:22<05:42,  1.26it/s]Loading train:   6%|▌         | 26/456 [00:23<05:55,  1.21it/s]Loading train:   6%|▌         | 27/456 [00:23<05:45,  1.24it/s]Loading train:   6%|▌         | 28/456 [00:24<05:41,  1.25it/s]Loading train:   6%|▋         | 29/456 [00:25<05:40,  1.25it/s]Loading train:   7%|▋         | 30/456 [00:26<05:42,  1.24it/s]Loading train:   7%|▋         | 31/456 [00:26<05:44,  1.23it/s]Loading train:   7%|▋         | 32/456 [00:27<05:47,  1.22it/s]Loading train:   7%|▋         | 33/456 [00:28<05:40,  1.24it/s]Loading train:   7%|▋         | 34/456 [00:29<05:35,  1.26it/s]Loading train:   8%|▊         | 35/456 [00:30<05:36,  1.25it/s]Loading train:   8%|▊         | 36/456 [00:31<05:38,  1.24it/s]Loading train:   8%|▊         | 37/456 [00:31<05:36,  1.24it/s]Loading train:   8%|▊         | 38/456 [00:32<05:37,  1.24it/s]Loading train:   9%|▊         | 39/456 [00:33<05:43,  1.21it/s]Loading train:   9%|▉         | 40/456 [00:34<05:39,  1.23it/s]Loading train:   9%|▉         | 41/456 [00:35<05:40,  1.22it/s]Loading train:   9%|▉         | 42/456 [00:35<05:35,  1.24it/s]Loading train:   9%|▉         | 43/456 [00:36<05:47,  1.19it/s]Loading train:  10%|▉         | 44/456 [00:37<06:13,  1.10it/s]Loading train:  10%|▉         | 45/456 [00:38<06:09,  1.11it/s]Loading train:  10%|█         | 46/456 [00:39<06:10,  1.11it/s]Loading train:  10%|█         | 47/456 [00:40<06:06,  1.11it/s]Loading train:  11%|█         | 48/456 [00:41<05:43,  1.19it/s]Loading train:  11%|█         | 49/456 [00:42<05:39,  1.20it/s]Loading train:  11%|█         | 50/456 [00:42<05:32,  1.22it/s]Loading train:  11%|█         | 51/456 [00:43<05:31,  1.22it/s]Loading train:  11%|█▏        | 52/456 [00:44<05:26,  1.24it/s]Loading train:  12%|█▏        | 53/456 [00:45<05:15,  1.28it/s]Loading train:  12%|█▏        | 54/456 [00:45<05:12,  1.29it/s]Loading train:  12%|█▏        | 55/456 [00:46<05:06,  1.31it/s]Loading train:  12%|█▏        | 56/456 [00:47<05:03,  1.32it/s]Loading train:  12%|█▎        | 57/456 [00:48<05:01,  1.32it/s]Loading train:  13%|█▎        | 58/456 [00:49<05:09,  1.29it/s]Loading train:  13%|█▎        | 59/456 [00:49<05:07,  1.29it/s]Loading train:  13%|█▎        | 60/456 [00:50<05:07,  1.29it/s]Loading train:  13%|█▎        | 61/456 [00:51<05:08,  1.28it/s]Loading train:  14%|█▎        | 62/456 [00:52<05:07,  1.28it/s]Loading train:  14%|█▍        | 63/456 [00:52<05:15,  1.25it/s]Loading train:  14%|█▍        | 64/456 [00:54<05:40,  1.15it/s]Loading train:  14%|█▍        | 65/456 [00:54<05:32,  1.17it/s]Loading train:  14%|█▍        | 66/456 [00:55<05:33,  1.17it/s]Loading train:  15%|█▍        | 67/456 [00:56<05:28,  1.18it/s]Loading train:  15%|█▍        | 68/456 [00:57<05:27,  1.19it/s]Loading train:  15%|█▌        | 69/456 [00:58<05:31,  1.17it/s]Loading train:  15%|█▌        | 70/456 [00:59<05:46,  1.11it/s]Loading train:  16%|█▌        | 71/456 [01:00<05:41,  1.13it/s]Loading train:  16%|█▌        | 72/456 [01:00<05:33,  1.15it/s]Loading train:  16%|█▌        | 73/456 [01:01<05:23,  1.18it/s]Loading train:  16%|█▌        | 74/456 [01:02<05:22,  1.18it/s]Loading train:  16%|█▋        | 75/456 [01:03<05:20,  1.19it/s]Loading train:  17%|█▋        | 76/456 [01:04<05:20,  1.18it/s]Loading train:  17%|█▋        | 77/456 [01:05<05:17,  1.19it/s]Loading train:  17%|█▋        | 78/456 [01:06<05:44,  1.10it/s]Loading train:  17%|█▋        | 79/456 [01:06<05:36,  1.12it/s]Loading train:  18%|█▊        | 80/456 [01:07<05:15,  1.19it/s]Loading train:  18%|█▊        | 81/456 [01:08<05:00,  1.25it/s]Loading train:  18%|█▊        | 82/456 [01:09<04:49,  1.29it/s]Loading train:  18%|█▊        | 83/456 [01:09<04:33,  1.37it/s]Loading train:  18%|█▊        | 84/456 [01:10<04:27,  1.39it/s]Loading train:  19%|█▊        | 85/456 [01:11<04:28,  1.38it/s]Loading train:  19%|█▉        | 86/456 [01:11<04:21,  1.41it/s]Loading train:  19%|█▉        | 87/456 [01:12<04:15,  1.45it/s]Loading train:  19%|█▉        | 88/456 [01:13<04:12,  1.46it/s]Loading train:  20%|█▉        | 89/456 [01:13<04:10,  1.47it/s]Loading train:  20%|█▉        | 90/456 [01:14<03:57,  1.54it/s]Loading train:  20%|█▉        | 91/456 [01:15<04:03,  1.50it/s]Loading train:  20%|██        | 92/456 [01:15<04:07,  1.47it/s]Loading train:  20%|██        | 93/456 [01:16<04:14,  1.43it/s]Loading train:  21%|██        | 94/456 [01:17<04:16,  1.41it/s]Loading train:  21%|██        | 95/456 [01:18<04:15,  1.41it/s]Loading train:  21%|██        | 96/456 [01:18<04:10,  1.44it/s]Loading train:  21%|██▏       | 97/456 [01:19<04:24,  1.36it/s]Loading train:  21%|██▏       | 98/456 [01:20<04:37,  1.29it/s]Loading train:  22%|██▏       | 99/456 [01:21<04:34,  1.30it/s]Loading train:  22%|██▏       | 100/456 [01:21<04:35,  1.29it/s]Loading train:  22%|██▏       | 101/456 [01:22<04:45,  1.25it/s]Loading train:  22%|██▏       | 102/456 [01:23<04:44,  1.24it/s]Loading train:  23%|██▎       | 103/456 [01:24<05:02,  1.17it/s]Loading train:  23%|██▎       | 104/456 [01:25<05:03,  1.16it/s]Loading train:  23%|██▎       | 105/456 [01:26<05:04,  1.15it/s]Loading train:  23%|██▎       | 106/456 [01:27<04:58,  1.17it/s]Loading train:  23%|██▎       | 107/456 [01:28<04:57,  1.17it/s]Loading train:  24%|██▎       | 108/456 [01:28<04:49,  1.20it/s]Loading train:  24%|██▍       | 109/456 [01:29<04:53,  1.18it/s]Loading train:  24%|██▍       | 110/456 [01:30<04:42,  1.23it/s]Loading train:  24%|██▍       | 111/456 [01:31<04:37,  1.25it/s]Loading train:  25%|██▍       | 112/456 [01:31<04:29,  1.28it/s]Loading train:  25%|██▍       | 113/456 [01:32<04:22,  1.31it/s]Loading train:  25%|██▌       | 114/456 [01:33<04:33,  1.25it/s]Loading train:  25%|██▌       | 115/456 [01:34<04:49,  1.18it/s]Loading train:  25%|██▌       | 116/456 [01:35<04:42,  1.20it/s]Loading train:  26%|██▌       | 117/456 [01:36<04:38,  1.22it/s]Loading train:  26%|██▌       | 118/456 [01:36<04:42,  1.20it/s]Loading train:  26%|██▌       | 119/456 [01:37<04:34,  1.23it/s]Loading train:  26%|██▋       | 120/456 [01:38<04:38,  1.21it/s]Loading train:  27%|██▋       | 121/456 [01:39<04:50,  1.15it/s]Loading train:  27%|██▋       | 122/456 [01:40<04:52,  1.14it/s]Loading train:  27%|██▋       | 123/456 [01:41<04:48,  1.15it/s]Loading train:  27%|██▋       | 124/456 [01:42<05:10,  1.07it/s]Loading train:  27%|██▋       | 125/456 [01:43<05:14,  1.05it/s]Loading train:  28%|██▊       | 126/456 [01:44<05:10,  1.06it/s]Loading train:  28%|██▊       | 127/456 [01:45<04:58,  1.10it/s]Loading train:  28%|██▊       | 128/456 [01:45<04:44,  1.15it/s]Loading train:  28%|██▊       | 129/456 [01:46<04:32,  1.20it/s]Loading train:  29%|██▊       | 130/456 [01:47<04:16,  1.27it/s]Loading train:  29%|██▊       | 131/456 [01:48<04:15,  1.27it/s]Loading train:  29%|██▉       | 132/456 [01:48<04:12,  1.28it/s]Loading train:  29%|██▉       | 133/456 [01:49<04:38,  1.16it/s]Loading train:  29%|██▉       | 134/456 [01:50<04:49,  1.11it/s]Loading train:  30%|██▉       | 135/456 [01:51<04:53,  1.09it/s]Loading train:  30%|██▉       | 136/456 [01:52<04:51,  1.10it/s]Loading train:  30%|███       | 137/456 [01:53<04:49,  1.10it/s]Loading train:  30%|███       | 138/456 [01:54<04:49,  1.10it/s]Loading train:  30%|███       | 139/456 [01:55<04:36,  1.15it/s]Loading train:  31%|███       | 140/456 [01:56<04:32,  1.16it/s]Loading train:  31%|███       | 141/456 [01:56<04:14,  1.24it/s]Loading train:  31%|███       | 142/456 [01:57<04:07,  1.27it/s]Loading train:  31%|███▏      | 143/456 [01:58<04:00,  1.30it/s]Loading train:  32%|███▏      | 144/456 [01:59<04:07,  1.26it/s]Loading train:  32%|███▏      | 145/456 [02:00<04:10,  1.24it/s]Loading train:  32%|███▏      | 146/456 [02:00<04:13,  1.22it/s]Loading train:  32%|███▏      | 147/456 [02:01<04:00,  1.28it/s]Loading train:  32%|███▏      | 148/456 [02:02<03:54,  1.31it/s]Loading train:  33%|███▎      | 149/456 [02:03<03:54,  1.31it/s]Loading train:  33%|███▎      | 150/456 [02:03<03:51,  1.32it/s]Loading train:  33%|███▎      | 151/456 [02:04<03:59,  1.27it/s]Loading train:  33%|███▎      | 152/456 [02:05<04:00,  1.27it/s]Loading train:  34%|███▎      | 153/456 [02:06<04:03,  1.24it/s]Loading train:  34%|███▍      | 154/456 [02:07<04:03,  1.24it/s]Loading train:  34%|███▍      | 155/456 [02:07<04:07,  1.22it/s]Loading train:  34%|███▍      | 156/456 [02:08<04:07,  1.21it/s]Loading train:  34%|███▍      | 157/456 [02:09<04:10,  1.20it/s]Loading train:  35%|███▍      | 158/456 [02:10<04:04,  1.22it/s]Loading train:  35%|███▍      | 159/456 [02:11<04:02,  1.23it/s]Loading train:  35%|███▌      | 160/456 [02:11<03:54,  1.26it/s]Loading train:  35%|███▌      | 161/456 [02:12<03:50,  1.28it/s]Loading train:  36%|███▌      | 162/456 [02:13<03:48,  1.28it/s]Loading train:  36%|███▌      | 163/456 [02:14<03:48,  1.28it/s]Loading train:  36%|███▌      | 164/456 [02:14<03:38,  1.34it/s]Loading train:  36%|███▌      | 165/456 [02:15<03:24,  1.42it/s]Loading train:  36%|███▋      | 166/456 [02:16<03:27,  1.40it/s]Loading train:  37%|███▋      | 167/456 [02:16<03:18,  1.46it/s]Loading train:  37%|███▋      | 168/456 [02:17<03:12,  1.50it/s]Loading train:  37%|███▋      | 169/456 [02:18<03:14,  1.48it/s]Loading train:  37%|███▋      | 170/456 [02:18<03:15,  1.46it/s]Loading train:  38%|███▊      | 171/456 [02:19<03:32,  1.34it/s]Loading train:  38%|███▊      | 172/456 [02:20<03:31,  1.35it/s]Loading train:  38%|███▊      | 173/456 [02:21<03:34,  1.32it/s]Loading train:  38%|███▊      | 174/456 [02:22<03:53,  1.21it/s]Loading train:  38%|███▊      | 175/456 [02:22<03:29,  1.34it/s]Loading train:  39%|███▊      | 176/456 [02:23<03:17,  1.42it/s]Loading train:  39%|███▉      | 177/456 [02:24<03:05,  1.50it/s]Loading train:  39%|███▉      | 178/456 [02:24<02:56,  1.57it/s]Loading train:  39%|███▉      | 179/456 [02:25<02:51,  1.61it/s]Loading train:  39%|███▉      | 180/456 [02:25<02:52,  1.60it/s]Loading train:  40%|███▉      | 181/456 [02:26<03:14,  1.42it/s]Loading train:  40%|███▉      | 182/456 [02:27<03:22,  1.35it/s]Loading train:  40%|████      | 183/456 [02:28<03:32,  1.29it/s]Loading train:  40%|████      | 184/456 [02:29<03:34,  1.27it/s]Loading train:  41%|████      | 185/456 [02:30<03:32,  1.27it/s]Loading train:  41%|████      | 186/456 [02:31<03:50,  1.17it/s]Loading train:  41%|████      | 187/456 [02:32<04:23,  1.02it/s]Loading train:  41%|████      | 188/456 [02:33<04:21,  1.03it/s]Loading train:  41%|████▏     | 189/456 [02:34<04:24,  1.01it/s]Loading train:  42%|████▏     | 190/456 [02:35<04:27,  1.00s/it]Loading train:  42%|████▏     | 191/456 [02:36<04:23,  1.00it/s]Loading train:  42%|████▏     | 192/456 [02:37<04:25,  1.01s/it]Loading train:  42%|████▏     | 193/456 [02:38<04:22,  1.00it/s]Loading train:  43%|████▎     | 194/456 [02:39<04:11,  1.04it/s]Loading train:  43%|████▎     | 195/456 [02:40<04:07,  1.06it/s]Loading train:  43%|████▎     | 196/456 [02:40<03:57,  1.09it/s]Loading train:  43%|████▎     | 197/456 [02:41<03:49,  1.13it/s]Loading train:  43%|████▎     | 198/456 [02:42<03:45,  1.14it/s]Loading train:  44%|████▎     | 199/456 [02:43<03:47,  1.13it/s]Loading train:  44%|████▍     | 200/456 [02:44<03:39,  1.17it/s]Loading train:  44%|████▍     | 201/456 [02:45<03:35,  1.18it/s]Loading train:  44%|████▍     | 202/456 [02:45<03:31,  1.20it/s]Loading train:  45%|████▍     | 203/456 [02:46<03:27,  1.22it/s]Loading train:  45%|████▍     | 204/456 [02:47<03:28,  1.21it/s]Loading train:  45%|████▍     | 205/456 [02:48<03:17,  1.27it/s]Loading train:  45%|████▌     | 206/456 [02:48<03:08,  1.33it/s]Loading train:  45%|████▌     | 207/456 [02:49<03:21,  1.23it/s]Loading train:  46%|████▌     | 208/456 [02:50<03:18,  1.25it/s]Loading train:  46%|████▌     | 209/456 [02:51<03:31,  1.17it/s]Loading train:  46%|████▌     | 210/456 [02:52<03:42,  1.11it/s]Loading train:  46%|████▋     | 211/456 [02:53<03:49,  1.07it/s]Loading train:  46%|████▋     | 212/456 [02:54<04:02,  1.01it/s]Loading train:  47%|████▋     | 213/456 [02:55<04:13,  1.05s/it]Loading train:  47%|████▋     | 214/456 [02:56<04:07,  1.02s/it]Loading train:  47%|████▋     | 215/456 [02:57<04:05,  1.02s/it]Loading train:  47%|████▋     | 216/456 [02:59<04:14,  1.06s/it]Loading train:  48%|████▊     | 217/456 [03:00<04:05,  1.03s/it]Loading train:  48%|████▊     | 218/456 [03:00<03:55,  1.01it/s]Loading train:  48%|████▊     | 219/456 [03:01<03:52,  1.02it/s]Loading train:  48%|████▊     | 220/456 [03:02<03:37,  1.08it/s]Loading train:  48%|████▊     | 221/456 [03:03<03:28,  1.13it/s]Loading train:  49%|████▊     | 222/456 [03:04<03:21,  1.16it/s]Loading train:  49%|████▉     | 223/456 [03:05<03:53,  1.00s/it]Loading train:  49%|████▉     | 224/456 [03:06<03:44,  1.03it/s]Loading train:  49%|████▉     | 225/456 [03:07<03:48,  1.01it/s]Loading train:  50%|████▉     | 226/456 [03:08<03:38,  1.05it/s]Loading train:  50%|████▉     | 227/456 [03:09<03:46,  1.01it/s]Loading train:  50%|█████     | 228/456 [03:10<03:40,  1.03it/s]Loading train:  50%|█████     | 229/456 [03:11<03:43,  1.02it/s]Loading train:  50%|█████     | 230/456 [03:12<03:48,  1.01s/it]Loading train:  51%|█████     | 231/456 [03:13<03:38,  1.03it/s]Loading train:  51%|█████     | 232/456 [03:14<04:03,  1.09s/it]Loading train:  51%|█████     | 233/456 [03:15<03:51,  1.04s/it]Loading train:  51%|█████▏    | 234/456 [03:16<03:39,  1.01it/s]Loading train:  52%|█████▏    | 235/456 [03:17<03:41,  1.00s/it]Loading train:  52%|█████▏    | 236/456 [03:18<03:35,  1.02it/s]Loading train:  52%|█████▏    | 237/456 [03:19<03:24,  1.07it/s]Loading train:  52%|█████▏    | 238/456 [03:20<03:14,  1.12it/s]Loading train:  52%|█████▏    | 239/456 [03:20<03:05,  1.17it/s]Loading train:  53%|█████▎    | 240/456 [03:21<03:02,  1.19it/s]Loading train:  53%|█████▎    | 241/456 [03:22<02:59,  1.20it/s]Loading train:  53%|█████▎    | 242/456 [03:23<02:53,  1.23it/s]Loading train:  53%|█████▎    | 243/456 [03:24<02:53,  1.23it/s]Loading train:  54%|█████▎    | 244/456 [03:24<02:49,  1.25it/s]Loading train:  54%|█████▎    | 245/456 [03:25<02:48,  1.26it/s]Loading train:  54%|█████▍    | 246/456 [03:26<02:42,  1.29it/s]Loading train:  54%|█████▍    | 247/456 [03:27<02:35,  1.34it/s]Loading train:  54%|█████▍    | 248/456 [03:27<02:29,  1.39it/s]Loading train:  55%|█████▍    | 249/456 [03:28<02:24,  1.43it/s]Loading train:  55%|█████▍    | 250/456 [03:29<02:21,  1.46it/s]Loading train:  55%|█████▌    | 251/456 [03:29<02:18,  1.48it/s]Loading train:  55%|█████▌    | 252/456 [03:30<02:17,  1.48it/s]Loading train:  55%|█████▌    | 253/456 [03:31<02:34,  1.32it/s]Loading train:  56%|█████▌    | 254/456 [03:32<02:44,  1.23it/s]Loading train:  56%|█████▌    | 255/456 [03:33<02:49,  1.19it/s]Loading train:  56%|█████▌    | 256/456 [03:34<02:57,  1.13it/s]Loading train:  56%|█████▋    | 257/456 [03:35<02:59,  1.11it/s]Loading train:  57%|█████▋    | 258/456 [03:36<03:04,  1.07it/s]Loading train:  57%|█████▋    | 259/456 [03:36<02:53,  1.13it/s]Loading train:  57%|█████▋    | 260/456 [03:37<02:46,  1.17it/s]Loading train:  57%|█████▋    | 261/456 [03:38<02:41,  1.21it/s]Loading train:  57%|█████▋    | 262/456 [03:39<02:37,  1.23it/s]Loading train:  58%|█████▊    | 263/456 [03:39<02:33,  1.26it/s]Loading train:  58%|█████▊    | 264/456 [03:40<02:34,  1.24it/s]Loading train:  58%|█████▊    | 265/456 [03:41<02:29,  1.27it/s]Loading train:  58%|█████▊    | 266/456 [03:42<02:20,  1.35it/s]Loading train:  59%|█████▊    | 267/456 [03:42<02:24,  1.31it/s]Loading train:  59%|█████▉    | 268/456 [03:43<02:30,  1.25it/s]Loading train:  59%|█████▉    | 269/456 [03:44<02:26,  1.27it/s]Loading train:  59%|█████▉    | 270/456 [03:45<02:24,  1.28it/s]Loading train:  59%|█████▉    | 271/456 [03:46<02:39,  1.16it/s]Loading train:  60%|█████▉    | 272/456 [03:47<02:33,  1.20it/s]Loading train:  60%|█████▉    | 273/456 [03:48<02:34,  1.19it/s]Loading train:  60%|██████    | 274/456 [03:48<02:31,  1.20it/s]Loading train:  60%|██████    | 275/456 [03:49<02:33,  1.18it/s]Loading train:  61%|██████    | 276/456 [03:50<02:30,  1.20it/s]Loading train:  61%|██████    | 277/456 [03:51<02:29,  1.20it/s]Loading train:  61%|██████    | 278/456 [03:52<02:24,  1.23it/s]Loading train:  61%|██████    | 279/456 [03:52<02:18,  1.28it/s]Loading train:  61%|██████▏   | 280/456 [03:53<02:18,  1.27it/s]Loading train:  62%|██████▏   | 281/456 [03:54<02:13,  1.31it/s]Loading train:  62%|██████▏   | 282/456 [03:55<02:11,  1.32it/s]Loading train:  62%|██████▏   | 283/456 [03:55<02:03,  1.40it/s]Loading train:  62%|██████▏   | 284/456 [03:56<02:02,  1.40it/s]Loading train:  62%|██████▎   | 285/456 [03:57<01:54,  1.49it/s]Loading train:  63%|██████▎   | 286/456 [03:57<01:52,  1.51it/s]Loading train:  63%|██████▎   | 287/456 [03:58<02:00,  1.40it/s]Loading train:  63%|██████▎   | 288/456 [03:59<02:01,  1.38it/s]Loading train:  63%|██████▎   | 289/456 [04:00<02:05,  1.33it/s]Loading train:  64%|██████▎   | 290/456 [04:00<02:03,  1.34it/s]Loading train:  64%|██████▍   | 291/456 [04:01<01:56,  1.42it/s]Loading train:  64%|██████▍   | 292/456 [04:02<01:55,  1.42it/s]Loading train:  64%|██████▍   | 293/456 [04:02<01:51,  1.47it/s]Loading train:  64%|██████▍   | 294/456 [04:03<01:48,  1.49it/s]Loading train:  65%|██████▍   | 295/456 [04:03<01:40,  1.60it/s]Loading train:  65%|██████▍   | 296/456 [04:04<01:38,  1.62it/s]Loading train:  65%|██████▌   | 297/456 [04:05<01:38,  1.62it/s]Loading train:  65%|██████▌   | 298/456 [04:05<01:35,  1.66it/s]Loading train:  66%|██████▌   | 299/456 [04:06<01:32,  1.70it/s]Loading train:  66%|██████▌   | 300/456 [04:06<01:29,  1.74it/s]Loading train:  66%|██████▌   | 301/456 [04:07<01:54,  1.35it/s]Loading train:  66%|██████▌   | 302/456 [04:08<01:59,  1.28it/s]Loading train:  66%|██████▋   | 303/456 [04:09<02:11,  1.17it/s]Loading train:  67%|██████▋   | 304/456 [04:10<02:08,  1.18it/s]Loading train:  67%|██████▋   | 305/456 [04:11<02:05,  1.20it/s]Loading train:  67%|██████▋   | 306/456 [04:12<02:01,  1.24it/s]Loading train:  67%|██████▋   | 307/456 [04:13<02:09,  1.15it/s]Loading train:  68%|██████▊   | 308/456 [04:14<02:12,  1.12it/s]Loading train:  68%|██████▊   | 309/456 [04:15<02:12,  1.11it/s]Loading train:  68%|██████▊   | 310/456 [04:16<02:13,  1.10it/s]Loading train:  68%|██████▊   | 311/456 [04:17<02:17,  1.06it/s]Loading train:  68%|██████▊   | 312/456 [04:18<02:19,  1.03it/s]Loading train:  69%|██████▊   | 313/456 [04:19<02:24,  1.01s/it]Loading train:  69%|██████▉   | 314/456 [04:20<02:21,  1.00it/s]Loading train:  69%|██████▉   | 315/456 [04:21<02:22,  1.01s/it]Loading train:  69%|██████▉   | 316/456 [04:22<02:16,  1.03it/s]Loading train:  70%|██████▉   | 317/456 [04:23<02:17,  1.01it/s]Loading train:  70%|██████▉   | 318/456 [04:24<02:14,  1.02it/s]Loading train:  70%|██████▉   | 319/456 [04:24<02:12,  1.04it/s]Loading train:  70%|███████   | 320/456 [04:25<02:07,  1.06it/s]Loading train:  70%|███████   | 321/456 [04:26<02:04,  1.09it/s]Loading train:  71%|███████   | 322/456 [04:27<02:00,  1.11it/s]Loading train:  71%|███████   | 323/456 [04:28<01:57,  1.13it/s]Loading train:  71%|███████   | 324/456 [04:29<01:54,  1.15it/s]Loading train:  71%|███████▏  | 325/456 [04:29<01:47,  1.21it/s]Loading train:  71%|███████▏  | 326/456 [04:30<01:45,  1.23it/s]Loading train:  72%|███████▏  | 327/456 [04:31<01:39,  1.30it/s]Loading train:  72%|███████▏  | 328/456 [04:32<01:36,  1.32it/s]Loading train:  72%|███████▏  | 329/456 [04:32<01:34,  1.35it/s]Loading train:  72%|███████▏  | 330/456 [04:33<01:34,  1.33it/s]Loading train:  73%|███████▎  | 331/456 [04:34<01:49,  1.14it/s]Loading train:  73%|███████▎  | 332/456 [04:35<01:51,  1.11it/s]Loading train:  73%|███████▎  | 333/456 [04:36<01:48,  1.14it/s]Loading train:  73%|███████▎  | 334/456 [04:37<01:47,  1.14it/s]Loading train:  73%|███████▎  | 335/456 [04:38<01:44,  1.15it/s]Loading train:  74%|███████▎  | 336/456 [04:39<01:40,  1.20it/s]Loading train:  74%|███████▍  | 337/456 [04:39<01:37,  1.22it/s]Loading train:  74%|███████▍  | 338/456 [04:40<01:33,  1.26it/s]Loading train:  74%|███████▍  | 339/456 [04:41<01:29,  1.31it/s]Loading train:  75%|███████▍  | 340/456 [04:41<01:25,  1.35it/s]Loading train:  75%|███████▍  | 341/456 [04:42<01:25,  1.35it/s]Loading train:  75%|███████▌  | 342/456 [04:43<01:22,  1.39it/s]Loading train:  75%|███████▌  | 343/456 [04:44<01:19,  1.41it/s]Loading train:  75%|███████▌  | 344/456 [04:44<01:21,  1.37it/s]Loading train:  76%|███████▌  | 345/456 [04:45<01:20,  1.37it/s]Loading train:  76%|███████▌  | 346/456 [04:46<01:21,  1.35it/s]Loading train:  76%|███████▌  | 347/456 [04:47<01:19,  1.37it/s]Loading train:  76%|███████▋  | 348/456 [04:47<01:19,  1.35it/s]Loading train:  77%|███████▋  | 349/456 [04:48<01:23,  1.29it/s]Loading train:  77%|███████▋  | 350/456 [04:49<01:23,  1.26it/s]Loading train:  77%|███████▋  | 351/456 [04:50<01:24,  1.25it/s]Loading train:  77%|███████▋  | 352/456 [04:51<01:22,  1.26it/s]Loading train:  77%|███████▋  | 353/456 [04:52<01:26,  1.19it/s]Loading train:  78%|███████▊  | 354/456 [04:52<01:25,  1.19it/s]Loading train:  78%|███████▊  | 355/456 [04:53<01:26,  1.16it/s]Loading train:  78%|███████▊  | 356/456 [04:54<01:23,  1.19it/s]Loading train:  78%|███████▊  | 357/456 [04:55<01:20,  1.23it/s]Loading train:  79%|███████▊  | 358/456 [04:56<01:20,  1.22it/s]Loading train:  79%|███████▊  | 359/456 [04:56<01:18,  1.23it/s]Loading train:  79%|███████▉  | 360/456 [04:57<01:19,  1.20it/s]Loading train:  79%|███████▉  | 361/456 [04:58<01:23,  1.14it/s]Loading train:  79%|███████▉  | 362/456 [04:59<01:21,  1.15it/s]Loading train:  80%|███████▉  | 363/456 [05:00<01:21,  1.14it/s]Loading train:  80%|███████▉  | 364/456 [05:01<01:22,  1.12it/s]Loading train:  80%|████████  | 365/456 [05:02<01:20,  1.12it/s]Loading train:  80%|████████  | 366/456 [05:03<01:18,  1.14it/s]Loading train:  80%|████████  | 367/456 [05:04<01:15,  1.17it/s]Loading train:  81%|████████  | 368/456 [05:04<01:10,  1.24it/s]Loading train:  81%|████████  | 369/456 [05:05<01:06,  1.30it/s]Loading train:  81%|████████  | 370/456 [05:06<01:04,  1.33it/s]Loading train:  81%|████████▏ | 371/456 [05:06<01:02,  1.35it/s]Loading train:  82%|████████▏ | 372/456 [05:07<01:01,  1.37it/s]Loading train:  82%|████████▏ | 373/456 [05:08<01:06,  1.24it/s]Loading train:  82%|████████▏ | 374/456 [05:09<01:11,  1.14it/s]Loading train:  82%|████████▏ | 375/456 [05:10<01:16,  1.07it/s]Loading train:  82%|████████▏ | 376/456 [05:11<01:16,  1.05it/s]Loading train:  83%|████████▎ | 377/456 [05:12<01:15,  1.04it/s]Loading train:  83%|████████▎ | 378/456 [05:13<01:14,  1.04it/s]Loading train:  83%|████████▎ | 379/456 [05:14<01:06,  1.15it/s]Loading train:  83%|████████▎ | 380/456 [05:14<00:59,  1.27it/s]Loading train:  84%|████████▎ | 381/456 [05:15<00:56,  1.34it/s]Loading train:  84%|████████▍ | 382/456 [05:16<00:53,  1.38it/s]Loading train:  84%|████████▍ | 383/456 [05:16<00:52,  1.39it/s]Loading train:  84%|████████▍ | 384/456 [05:17<00:49,  1.44it/s]Loading train:  84%|████████▍ | 385/456 [05:18<00:50,  1.42it/s]Loading train:  85%|████████▍ | 386/456 [05:18<00:50,  1.39it/s]Loading train:  85%|████████▍ | 387/456 [05:19<00:51,  1.35it/s]Loading train:  85%|████████▌ | 388/456 [05:20<00:49,  1.37it/s]Loading train:  85%|████████▌ | 389/456 [05:21<00:49,  1.35it/s]Loading train:  86%|████████▌ | 390/456 [05:22<00:50,  1.30it/s]Loading train:  86%|████████▌ | 391/456 [05:23<00:55,  1.18it/s]Loading train:  86%|████████▌ | 392/456 [05:23<00:55,  1.16it/s]Loading train:  86%|████████▌ | 393/456 [05:24<00:55,  1.14it/s]Loading train:  86%|████████▋ | 394/456 [05:25<00:53,  1.15it/s]Loading train:  87%|████████▋ | 395/456 [05:26<00:53,  1.14it/s]Loading train:  87%|████████▋ | 396/456 [05:27<00:51,  1.16it/s]Loading train:  87%|████████▋ | 397/456 [05:28<00:50,  1.17it/s]Loading train:  87%|████████▋ | 398/456 [05:29<00:49,  1.17it/s]Loading train:  88%|████████▊ | 399/456 [05:29<00:46,  1.22it/s]Loading train:  88%|████████▊ | 400/456 [05:30<00:44,  1.26it/s]Loading train:  88%|████████▊ | 401/456 [05:31<00:43,  1.26it/s]Loading train:  88%|████████▊ | 402/456 [05:32<00:40,  1.33it/s]Loading train:  88%|████████▊ | 403/456 [05:32<00:38,  1.39it/s]Loading train:  89%|████████▊ | 404/456 [05:33<00:37,  1.40it/s]Loading train:  89%|████████▉ | 405/456 [05:34<00:34,  1.46it/s]Loading train:  89%|████████▉ | 406/456 [05:34<00:35,  1.40it/s]Loading train:  89%|████████▉ | 407/456 [05:35<00:32,  1.52it/s]Loading train:  89%|████████▉ | 408/456 [05:35<00:30,  1.57it/s]Loading train:  90%|████████▉ | 409/456 [05:36<00:29,  1.58it/s]Loading train:  90%|████████▉ | 410/456 [05:37<00:29,  1.58it/s]Loading train:  90%|█████████ | 411/456 [05:37<00:28,  1.59it/s]Loading train:  90%|█████████ | 412/456 [05:38<00:27,  1.61it/s]Loading train:  91%|█████████ | 413/456 [05:39<00:27,  1.59it/s]Loading train:  91%|█████████ | 414/456 [05:39<00:25,  1.62it/s]Loading train:  91%|█████████ | 415/456 [05:40<00:24,  1.67it/s]Loading train:  91%|█████████ | 416/456 [05:40<00:24,  1.61it/s]Loading train:  91%|█████████▏| 417/456 [05:41<00:24,  1.62it/s]Loading train:  92%|█████████▏| 418/456 [05:42<00:24,  1.56it/s]Loading train:  92%|█████████▏| 419/456 [05:42<00:23,  1.55it/s]Loading train:  92%|█████████▏| 420/456 [05:43<00:23,  1.50it/s]Loading train:  92%|█████████▏| 421/456 [05:44<00:26,  1.31it/s]Loading train:  93%|█████████▎| 422/456 [05:45<00:28,  1.20it/s]Loading train:  93%|█████████▎| 423/456 [05:46<00:29,  1.13it/s]Loading train:  93%|█████████▎| 424/456 [05:47<00:28,  1.12it/s]Loading train:  93%|█████████▎| 425/456 [05:48<00:28,  1.10it/s]Loading train:  93%|█████████▎| 426/456 [05:49<00:28,  1.07it/s]Loading train:  94%|█████████▎| 427/456 [05:50<00:28,  1.03it/s]Loading train:  94%|█████████▍| 428/456 [05:51<00:27,  1.01it/s]Loading train:  94%|█████████▍| 429/456 [05:52<00:26,  1.00it/s]Loading train:  94%|█████████▍| 430/456 [05:53<00:27,  1.05s/it]Loading train:  95%|█████████▍| 431/456 [05:54<00:26,  1.08s/it]Loading train:  95%|█████████▍| 432/456 [05:55<00:25,  1.05s/it]Loading train:  95%|█████████▍| 433/456 [05:56<00:24,  1.07s/it]Loading train:  95%|█████████▌| 434/456 [05:57<00:22,  1.01s/it]Loading train:  95%|█████████▌| 435/456 [05:58<00:20,  1.02it/s]Loading train:  96%|█████████▌| 436/456 [05:59<00:19,  1.03it/s]Loading train:  96%|█████████▌| 437/456 [06:00<00:17,  1.06it/s]Loading train:  96%|█████████▌| 438/456 [06:01<00:16,  1.07it/s]Loading train:  96%|█████████▋| 439/456 [06:02<00:15,  1.08it/s]Loading train:  96%|█████████▋| 440/456 [06:03<00:14,  1.10it/s]Loading train:  97%|█████████▋| 441/456 [06:04<00:13,  1.13it/s]Loading train:  97%|█████████▋| 442/456 [06:04<00:12,  1.14it/s]Loading train:  97%|█████████▋| 443/456 [06:05<00:11,  1.14it/s]Loading train:  97%|█████████▋| 444/456 [06:06<00:10,  1.14it/s]Loading train:  98%|█████████▊| 445/456 [06:07<00:09,  1.20it/s]Loading train:  98%|█████████▊| 446/456 [06:08<00:08,  1.21it/s]Loading train:  98%|█████████▊| 447/456 [06:08<00:07,  1.26it/s]Loading train:  98%|█████████▊| 448/456 [06:09<00:06,  1.31it/s]Loading train:  98%|█████████▊| 449/456 [06:10<00:05,  1.17it/s]Loading train:  99%|█████████▊| 450/456 [06:11<00:04,  1.25it/s]Loading train:  99%|█████████▉| 451/456 [06:12<00:04,  1.16it/s]Loading train:  99%|█████████▉| 452/456 [06:13<00:03,  1.16it/s]Loading train:  99%|█████████▉| 453/456 [06:13<00:02,  1.21it/s]Loading train: 100%|█████████▉| 454/456 [06:14<00:01,  1.21it/s]Loading train: 100%|█████████▉| 455/456 [06:15<00:00,  1.17it/s]Loading train: 100%|██████████| 456/456 [06:16<00:00,  1.15it/s]
concatenating: train:   0%|          | 0/456 [00:00<?, ?it/s]concatenating: train:   4%|▍         | 19/456 [00:00<00:02, 184.35it/s]concatenating: train:  10%|█         | 47/456 [00:00<00:02, 204.26it/s]concatenating: train:  16%|█▋        | 75/456 [00:00<00:01, 220.69it/s]concatenating: train:  23%|██▎       | 106/456 [00:00<00:01, 240.80it/s]concatenating: train:  30%|███       | 139/456 [00:00<00:01, 261.19it/s]concatenating: train:  37%|███▋      | 170/456 [00:00<00:01, 272.52it/s]concatenating: train:  43%|████▎     | 197/456 [00:00<00:00, 260.30it/s]concatenating: train:  49%|████▉     | 223/456 [00:00<00:00, 247.76it/s]concatenating: train:  54%|█████▍    | 248/456 [00:00<00:00, 239.25it/s]concatenating: train:  60%|██████    | 275/456 [00:01<00:00, 247.17it/s]concatenating: train:  67%|██████▋   | 305/456 [00:01<00:00, 259.10it/s]concatenating: train:  73%|███████▎  | 333/456 [00:01<00:00, 263.25it/s]concatenating: train:  80%|████████  | 365/456 [00:01<00:00, 277.07it/s]concatenating: train:  87%|████████▋ | 397/456 [00:01<00:00, 287.32it/s]concatenating: train:  94%|█████████▍| 428/456 [00:01<00:00, 292.21it/s]concatenating: train: 100%|██████████| 456/456 [00:01<00:00, 277.10it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:00<00:02,  1.15it/s]Loading test:  50%|█████     | 2/4 [00:01<00:01,  1.18it/s]Loading test:  75%|███████▌  | 3/4 [00:02<00:00,  1.19it/s]Loading test: 100%|██████████| 4/4 [00:03<00:00,  1.19it/s]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 302.10it/s]
Epoch 00050: val_mDice did not improve from 0.68434
Restoring model weights from the end of the best epoch
Epoch 00050: early stopping
{'val_loss': [1.0337795518540047, 1.0536114078691108, 1.0473549278546483, 1.1041770676388243, 1.1005610011259102, 1.15018983029951, 1.1355614786442643, 1.1582144349238126, 1.1328016535655872, 1.1501789916896452, 1.185293700013842, 1.1556420425190428, 1.1716928578711845, 1.1335544876150183, 1.1407429928024764, 1.1437623026748422, 1.152741845280047, 1.159984320747346, 1.1393169933304363, 1.1443538403418994, 1.1450573021840864, 1.154894264738532, 1.195648979956579, 1.1907858487261769, 1.194206304761894, 1.1629189915638634, 1.2292776924762947, 1.1500649459113486, 1.1926029287710154, 1.177900157379828, 1.194583983955236, 1.204531908265412, 1.2095970255987984, 1.1841924683007494, 1.2111173242215485, 1.2159234681184687, 1.2443912176551966, 1.2361792597531351, 1.2133397278178153, 1.2303694380756511, 1.2027437795083036, 1.2185167808330197, 1.2112379515953506, 1.2461938742965344, 1.2232299104160325, 1.263641459601266, 1.2279802882993542, 1.199627518193602, 1.2199119315644489, 1.219901888527005], 'val_acc': [0.9714955333116893, 0.971566958316965, 0.9719104504493212, 0.9709168730095087, 0.971627283740688, 0.9714327369417463, 0.9717454716965959, 0.971564499107567, 0.9715017112525733, 0.9716580620603672, 0.9715891130642541, 0.9717097731170506, 0.9718562721285581, 0.9720421953551097, 0.9714130570529511, 0.9718956747110286, 0.9714783140130945, 0.9717491821432666, 0.9716100621407556, 0.9719498643083462, 0.9720028095724039, 0.9714980116221895, 0.9709661361333486, 0.9714943218875576, 0.97185137925461, 0.9715891206586683, 0.9712074481842601, 0.9718735146706629, 0.9715337104318685, 0.9716075810686502, 0.9716001834188189, 0.9711926897059997, 0.9712099117661995, 0.9713748868367846, 0.9717208379484051, 0.9713847308085232, 0.97127763276855, 0.9714426124418104, 0.9715226294911506, 0.9714364384132003, 0.9716888500456644, 0.9713096464462723, 0.9715755740648071, 0.9707752979400075, 0.9713157859548178, 0.9710030847994977, 0.970996922967977, 0.9714524548026126, 0.9709328910098572, 0.9713157979217736], 'val_mDice': [0.6529012133716157, 0.6541566719879975, 0.6663212453996813, 0.6657238747622516, 0.6638821832921974, 0.6649688933346722, 0.6703777980620337, 0.6660110978086022, 0.6752121957112464, 0.6721309899823545, 0.6712982456656497, 0.6723219809845148, 0.6721872871446793, 0.6755560516850828, 0.6757698592992363, 0.6751461049764773, 0.6722749273749392, 0.6816200524223357, 0.6801804041770434, 0.6843443851213198, 0.681849925444393, 0.6808010869044595, 0.6707607174011732, 0.6736076066852996, 0.674288991335276, 0.6756956938611034, 0.6654305476479548, 0.6766523728039274, 0.6765699906698985, 0.6769857112044994, 0.6784240384819885, 0.6802987569087261, 0.6754031726752469, 0.6787224306102885, 0.6735072727369066, 0.679195549497273, 0.6734721349933432, 0.6781193915481273, 0.6777948141098022, 0.6799099615642002, 0.6781972052968147, 0.6808507364228885, 0.6789179902279239, 0.6792777130042263, 0.6815947733790718, 0.6711476155229517, 0.6749465686474068, 0.6831131796118836, 0.6783354328405903, 0.6794747017525338], 'loss': [1.198674779356891, 1.072950378263348, 1.0283920087107756, 0.9959787377317043, 0.9752004976107826, 0.9598866394819312, 0.9448904336389211, 0.9341186538903054, 0.9234804227121465, 0.9142223717832919, 0.9058775723779465, 0.8989909200703341, 0.8937994700956956, 0.8885873646657598, 0.8813526221513618, 0.8737833995441857, 0.8708450553114948, 0.8671529508672415, 0.8608959892180226, 0.8600680142681343, 0.8540421864105946, 0.8525479753765711, 0.8488181487464361, 0.8430239400821327, 0.8421195461758826, 0.8409971917466696, 0.8367742854651317, 0.83462029954794, 0.8332623535531604, 0.8282455311568164, 0.8275609126227372, 0.82393011645502, 0.8234206210827173, 0.8203363468607033, 0.8181125455565508, 0.8162192012700377, 0.8147931057052114, 0.8141700494645994, 0.8105329016893051, 0.8082907783867144, 0.8106552523759237, 0.8062423439792016, 0.806101441407309, 0.8048553529778079, 0.801989622012724, 0.8020928583394541, 0.8001121421123101, 0.7981925227425315, 0.798840820134054, 0.7963345522833356], 'acc': [0.9539534592476958, 0.9562429866256443, 0.9572107757873805, 0.9579130216783679, 0.9584268649786339, 0.9587779821452268, 0.9591270466231199, 0.9593829501885189, 0.9596377843731381, 0.9598292908900501, 0.9600828997604406, 0.9602119571549841, 0.9603535716626577, 0.9605180687002026, 0.9606228094395459, 0.9607560363617523, 0.9609031716345382, 0.9609399501756369, 0.9611392879817862, 0.9611873060944892, 0.9613081751488373, 0.9613165510349962, 0.9614059275891828, 0.9615818517094633, 0.9616183889060673, 0.9616572792114946, 0.961716233996052, 0.9617578365403151, 0.9618635304815614, 0.9618830372994697, 0.9619656737698297, 0.9619967948311045, 0.9621022446216766, 0.9621569828745211, 0.9622076712531045, 0.9622802992068918, 0.9622512163593072, 0.9623132478877771, 0.9623536155541604, 0.9624477817559505, 0.9624150762983286, 0.9625938764847702, 0.9625647727312575, 0.9626277450656755, 0.9626733899103453, 0.9626353293523416, 0.9627130234788789, 0.9627437262735555, 0.9627727959022716, 0.962823272300013], 'mDice': [0.6226540179235034, 0.6504503708680964, 0.6630439267905139, 0.6729753622550161, 0.6792171521851081, 0.6838442527171079, 0.6885660998140896, 0.6915707661822634, 0.6949249165554235, 0.6983272900447778, 0.7006998432183736, 0.7029662697853114, 0.7049259250479003, 0.7063152656487601, 0.7086833142490583, 0.71139122347447, 0.7115540977413274, 0.7132726037966866, 0.7149870512718793, 0.7156158736865956, 0.717318472224725, 0.7175364285090289, 0.7192017887998756, 0.720839324926737, 0.7213604074863952, 0.7217149740549187, 0.7232918086691636, 0.7237096293329858, 0.7244682017373761, 0.7259078865146362, 0.7260246102084261, 0.7272760669310536, 0.7276768866429663, 0.7281676996089068, 0.7286229356815871, 0.7297133618473262, 0.7303061126016831, 0.7305544557274988, 0.7315436433268027, 0.7323590544256824, 0.7313608764674701, 0.7332849425235708, 0.7329792434584298, 0.7332228710533055, 0.734515034393526, 0.7342406579055641, 0.7346635226148994, 0.7354805985836895, 0.73536078942702, 0.7364507755320086]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 88, 56, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 88, 56, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 88, 56, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 88, 56, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 88, 56, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 88, 56, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 88, 56, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 88, 56, 16)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 44, 28, 16)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 44, 28, 16)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 44, 28, 30)   4350        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 44, 28, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 44, 28, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 44, 28, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 44, 28, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 44, 28, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 44, 28, 46)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 22, 14, 46)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 22, 14, 46)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 22, 14, 60)   24900       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 22, 14, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 14, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 22, 14, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 22, 14, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 22, 14, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 22, 14, 106)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 22, 14, 106)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 44, 28, 30)   12750       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 44, 28, 76)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 44, 28, 30)   20550       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 44, 28, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 44, 28, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 44, 28, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 44, 28, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 44, 28, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 44, 28, 106)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 44, 28, 106)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 88, 56, 15)   6375        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 88, 56, 31)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 88, 56, 15)   4200        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 88, 56, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 88, 56, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 88, 56, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 88, 56, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 88, 56, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 88, 56, 46)   0           concatenate_6[0][0]              2019-07-07 18:14:31.779545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 18:14:31.779634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 18:14:31.779648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 18:14:31.779657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 18:14:31.999257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 88, 56, 46)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 88, 56, 13)   611         dropout_5[0][0]                  
==================================================================================================
Total params: 127,886
Trainable params: 127,286
Non-trainable params: 600
__________________________________________________________________________________________________
----- /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/model_weights.h5
 --- initialized from Model_3T /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0
------------------------------------------------------------------
class_weights [6.16770687e-02 2.82810291e-02 7.42489031e-02 1.01163433e-02
 2.48563371e-02 6.25843058e-03 7.67474865e-02 1.12146729e-01
 6.37696896e-02 1.30484325e-02 3.54233577e-01 1.74411942e-01
 2.04031629e-04]
Train on 16653 samples, validate on 146 samples
Epoch 1/300
 - 22s - loss: 2.2892 - acc: 0.9490 - mDice: 0.5906 - val_loss: 1.6635 - val_acc: 0.9673 - val_mDice: 0.6606

Epoch 00001: val_mDice improved from -inf to 0.66058, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 16s - loss: 1.9303 - acc: 0.9522 - mDice: 0.6240 - val_loss: 1.6646 - val_acc: 0.9675 - val_mDice: 0.6672

Epoch 00002: val_mDice improved from 0.66058 to 0.66715, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 14s - loss: 1.8335 - acc: 0.9535 - mDice: 0.6386 - val_loss: 1.6508 - val_acc: 0.9685 - val_mDice: 0.6712

Epoch 00003: val_mDice improved from 0.66715 to 0.67116, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 14s - loss: 1.7735 - acc: 0.9542 - mDice: 0.6484 - val_loss: 1.7137 - val_acc: 0.9675 - val_mDice: 0.6742

Epoch 00004: val_mDice improved from 0.67116 to 0.67420, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 15s - loss: 1.7305 - acc: 0.9548 - mDice: 0.6551 - val_loss: 1.7046 - val_acc: 0.9669 - val_mDice: 0.6782

Epoch 00005: val_mDice improved from 0.67420 to 0.67822, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 15s - loss: 1.6948 - acc: 0.9553 - mDice: 0.6617 - val_loss: 1.6978 - val_acc: 0.9681 - val_mDice: 0.6800

Epoch 00006: val_mDice improved from 0.67822 to 0.68000, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 7/300
 - 15s - loss: 1.6699 - acc: 0.9556 - mDice: 0.6659 - val_loss: 1.7744 - val_acc: 0.9673 - val_mDice: 0.6828

Epoch 00007: val_mDice improved from 0.68000 to 0.68276, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 8/300
 - 15s - loss: 1.6502 - acc: 0.9559 - mDice: 0.6691 - val_loss: 1.7929 - val_acc: 0.9669 - val_mDice: 0.6807

Epoch 00008: val_mDice did not improve from 0.68276
Epoch 9/300
 - 14s - loss: 1.6277 - acc: 0.9562 - mDice: 0.6735 - val_loss: 1.7738 - val_acc: 0.9675 - val_mDice: 0.6807

Epoch 00009: val_mDice did not improve from 0.68276
Epoch 10/300
 - 16s - loss: 1.6126 - acc: 0.9564 - mDice: 0.6763 - val_loss: 1.7746 - val_acc: 0.9676 - val_mDice: 0.6811

Epoch 00010: val_mDice did not improve from 0.68276
Epoch 11/300
 - 15s - loss: 1.5961 - acc: 0.9566 - mDice: 0.6791 - val_loss: 1.7365 - val_acc: 0.9677 - val_mDice: 0.6884

Epoch 00011: val_mDice improved from 0.68276 to 0.68841, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 12/300
 - 16s - loss: 1.5823 - acc: 0.9568 - mDice: 0.6815 - val_loss: 1.7770 - val_acc: 0.9665 - val_mDice: 0.6822

Epoch 00012: val_mDice did not improve from 0.68841
Epoch 13/300
 - 15s - loss: 1.5671 - acc: 0.9570 - mDice: 0.6846 - val_loss: 1.7918 - val_acc: 0.9671 - val_mDice: 0.6847

Epoch 00013: val_mDice did not improve from 0.68841
Epoch 14/300
 - 14s - loss: 1.5595 - acc: 0.9571 - mDice: 0.6859 - val_loss: 1.8663 - val_acc: 0.9656 - val_mDice: 0.6846

Epoch 00014: val_mDice did not improve from 0.68841
Epoch 15/300
 - 15s - loss: 1.5475 - acc: 0.9572 - mDice: 0.6883 - val_loss: 1.7729 - val_acc: 0.9674 - val_mDice: 0.6867

Epoch 00015: val_mDice did not improve from 0.68841
Epoch 16/300
 - 16s - loss: 1.5387 - acc: 0.9573 - mDice: 0.6902 - val_loss: 1.7542 - val_acc: 0.9675 - val_mDice: 0.6858

Epoch 00016: val_mDice did not improve from 0.68841
Epoch 17/300
 - 15s - loss: 1.5298 - acc: 0.9575 - mDice: 0.6915 - val_loss: 1.7996 - val_acc: 0.9673 - val_mDice: 0.6888

Epoch 00017: val_mDice improved from 0.68841 to 0.68877, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 18/300
 - 15s - loss: 1.5206 - acc: 0.9576 - mDice: 0.6933 - val_loss: 1.8017 - val_acc: 0.9673 - val_mDice: 0.6885

Epoch 00018: val_mDice did not improve from 0.68877
Epoch 19/300
 - 14s - loss: 1.5153 - acc: 0.9577 - mDice: 0.6947 - val_loss: 1.8172 - val_acc: 0.9675 - val_mDice: 0.6893

Epoch 00019: val_mDice improved from 0.68877 to 0.68927, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 20/300
 - 15s - loss: 1.5019 - acc: 0.9578 - mDice: 0.6970 - val_loss: 1.8355 - val_acc: 0.9665 - val_mDice: 0.6844

Epoch 00020: val_mDice did not improve from 0.68927
Epoch 21/300
 - 15s - loss: 1.5014 - acc: 0.9579 - mDice: 0.6974 - val_loss: 1.7606 - val_acc: 0.9673 - val_mDice: 0.6843

Epoch 00021: val_mDice did not improve from 0.68927
Epoch 22/300
 - 15s - loss: 1.4902 - acc: 0.9581 - mDice: 0.6992 - val_loss: 1.8188 - val_acc: 0.9670 - val_mDice: 0.6898

Epoch 00022: val_mDice improved from 0.68927 to 0.68984, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 23/300
 - 16s - loss: 1.4867 - acc: 0.9581 - mDice: 0.7001 - val_loss: 1.8112 - val_acc: 0.9670 - val_mDice: 0.6881

Epoch 00023: val_mDice did not improve from 0.68984
Epoch 24/300
 - 14s - loss: 1.4775 - acc: 0.9582 - mDice: 0.7020 - val_loss: 1.8214 - val_acc: 0.9673 - val_mDice: 0.6876

Epoch 00024: val_mDice did not improve from 0.68984
Epoch 25/300
 - 14s - loss: 1.4736 - acc: 0.9583 - mDice: 0.7027 - val_loss: 1.8682 - val_acc: 0.9660 - val_mDice: 0.6876

Epoch 00025: val_mDice did not improve from 0.68984
Epoch 26/300
 - 15s - loss: 1.4671 - acc: 0.9584 - mDice: 0.7040 - val_loss: 1.7976 - val_acc: 0.9668 - val_mDice: 0.6875

Epoch 00026: val_mDice did not improve from 0.68984
Epoch 27/300
 - 15s - loss: 1.4640 - acc: 0.9585 - mDice: 0.7046 - val_loss: 1.8056 - val_acc: 0.9676 - val_mDice: 0.6895

Epoch 00027: val_mDice did not improve from 0.68984
Epoch 28/300
 - 14s - loss: 1.4563 - acc: 0.9586 - mDice: 0.7060 - val_loss: 1.8332 - val_acc: 0.9670 - val_mDice: 0.6892

Epoch 00028: val_mDice did not improve from 0.68984
Epoch 29/300
 - 15s - loss: 1.4527 - acc: 0.9586 - mDice: 0.7065 - val_loss: 1.9641 - val_acc: 0.9664 - val_mDice: 0.6834

Epoch 00029: val_mDice did not improve from 0.68984
Epoch 30/300
 - 15s - loss: 1.4478 - acc: 0.9587 - mDice: 0.7078 - val_loss: 1.8366 - val_acc: 0.9666 - val_mDice: 0.6865

Epoch 00030: val_mDice did not improve from 0.68984
Epoch 31/300
 - 14s - loss: 1.4427 - acc: 0.9587 - mDice: 0.7086 - val_loss: 1.8709 - val_acc: 0.9671 - val_mDice: 0.6916

Epoch 00031: val_mDice improved from 0.68984 to 0.69158, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 32/300
 - 15s - loss: 1.4435 - acc: 0.9588 - mDice: 0.7085 - val_loss: 1.9245 - val_acc: 0.9662 - val_mDice: 0.6880

Epoch 00032: val_mDice did not improve from 0.69158
Epoch 33/300
 - 15s - loss: 1.4365 - acc: 0.9589 - mDice: 0.7097 - val_loss: 1.8633 - val_acc: 0.9674 - val_mDice: 0.6923

Epoch 00033: val_mDice improved from 0.69158 to 0.69228, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 34/300
 - 14s - loss: 1.4315 - acc: 0.9590 - mDice: 0.7109 - val_loss: 1.8391 - val_acc: 0.9672 - val_mDice: 0.6901

Epoch 00034: val_mDice did not improve from 0.69228
Epoch 35/300
 - 15s - loss: 1.4296 - acc: 0.9591 - mDice: 0.7116 - val_loss: 1.8559 - val_acc: 0.9671 - val_mDice: 0.6961

Epoch 00035: val_mDice improved from 0.69228 to 0.69614, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 36/300
 - 15s - loss: 1.4260 - acc: 0.9591 - mDice: 0.7118 - val_loss: 1.9098 - val_acc: 0.9669 - val_mDice: 0.6866

Epoch 00036: val_mDice did not improve from 0.69614
Epoch 37/300
 - 14s - loss: 1.4202 - acc: 0.9592 - mDice: 0.7130 - val_loss: 1.9292 - val_acc: 0.9670 - val_mDice: 0.6879

Epoch 00037: val_mDice did not improve from 0.69614
Epoch 38/300
 - 14s - loss: 1.4199 - acc: 0.9592 - mDice: 0.7129 - val_loss: 1.8958 - val_acc: 0.9679 - val_mDice: 0.6906

Epoch 00038: val_mDice did not improve from 0.69614
Epoch 39/300
 - 15s - loss: 1.4172 - acc: 0.9592 - mDice: 0.7139 - val_loss: 1.8517 - val_acc: 0.9671 - val_mDice: 0.6902

Epoch 00039: val_mDice did not improve from 0.69614
Epoch 40/300
 - 15s - loss: 1.4099 - acc: 0.9594 - mDice: 0.7150 - val_loss: 1.9063 - val_acc: 0.9664 - val_mDice: 0.6903

Epoch 00040: val_mDice did not improve from 0.69614
Epoch 41/300
 - 14s - loss: 1.4125 - acc: 0.9593 - mDice: 0.7144 - val_loss: 1.8865 - val_acc: 0.9668 - val_mDice: 0.6931

Epoch 00041: val_mDice did not improve from 0.69614
Epoch 42/300
 - 15s - loss: 1.4059 - acc: 0.9594 - mDice: 0.7159 - val_loss: 1.8770 - val_acc: 0.9673 - val_mDice: 0.6921

Epoch 00042: val_mDice did not improve from 0.69614
Epoch 43/300
 - 15s - loss: 1.4013 - acc: 0.9595 - mDice: 0.7168 - val_loss: 1.8734 - val_acc: 0.9675 - val_mDice: 0.6918

Epoch 00043: val_mDice did not improve from 0.69614
Epoch 44/300
 - 15s - loss: 1.4032 - acc: 0.9595 - mDice: 0.7164 - val_loss: 1.8682 - val_acc: 0.9670 - val_mDice: 0.6908

Epoch 00044: val_mDice did not improve from 0.69614
Epoch 45/300
 - 16s - loss: 1.3970 - acc: 0.9595 - mDice: 0.7178 - val_loss: 1.9025 - val_acc: 0.9667 - val_mDice: 0.6909

Epoch 00045: val_mDice did not improve from 0.69614
Epoch 46/300
 - 14s - loss: 1.3933 - acc: 0.9596 - mDice: 0.7190 - val_loss: 1.8543 - val_acc: 0.9679 - val_mDice: 0.6964

Epoch 00046: val_mDice improved from 0.69614 to 0.69636, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 47/300
 - 15s - loss: 1.3973 - acc: 0.9596 - mDice: 0.7179 - val_loss: 1.9370 - val_acc: 0.9669 - val_mDice: 0.6849

Epoch 00047: val_mDice did not improve from 0.69636
Epoch 48/300
 - 15s - loss: 1.3927 - acc: 0.9597 - mDice: 0.7185 - val_loss: 1.9722 - val_acc: 0.9655 - val_mDice: 0.6847

Epoch 00048: val_mDice did not improve from 0.69636
Epoch 49/300
 - 14s - loss: 1.3856 - acc: 0.9598 - mDice: 0.7199 - val_loss: 1.8853 - val_acc: 0.9677 - val_mDice: 0.6940

Epoch 00049: val_mDice did not improve from 0.69636
Epoch 50/300
 - 14s - loss: 1.3866 - acc: 0.9598 - mDice: 0.7197 - val_loss: 1.9125 - val_acc: 0.9672 - val_mDice: 0.6917

Epoch 00050: val_mDice did not improve from 0.69636
Epoch 51/300
 - 15s - loss: 1.3818 - acc: 0.9598 - mDice: 0.7206 - val_loss: 1.8370 - val_acc: 0.9669 - val_mDice: 0.6945

Epoch 00051: val_mDice did not improve from 0.69636
Epoch 52/300
 - 15s - loss: 1.3813 - acc: 0.9598 - mDice: 0.7210 - val_loss: 1.8852 - val_acc: 0.9675 - val_mDice: 0.6965

Epoch 00052: val_mDice improved from 0.69636 to 0.69648, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 53/300
 - 14s - loss: 1.3790 - acc: 0.9599 - mDice: 0.7214 - val_loss: 1.8992 - val_acc: 0.9671 - val_mDice: 0.6912

Epoch 00053: val_mDice did not improve from 0.69648
Epoch 54/300
 - 15s - loss: 1.3801 - acc: 0.9598 - mDice: 0.7211 - val_loss: 1.8689 - val_acc: 0.9673 - val_mDice: 0.6930

Epoch 00054: val_mDice did not improve from 0.69648
Epoch 55/300
 - 15s - loss: 1.3765 - acc: 0.9600 - mDice: 0.7217 - val_loss: 1.8874 - val_acc: 0.9668 - val_mDice: 0.6917

Epoch 00055: val_mDice did not improve from 0.69648
Epoch 56/300
 - 14s - loss: 1.3735 - acc: 0.9600 - mDice: 0.7226 - val_loss: 1.9381 - val_acc: 0.9672 - val_mDice: 0.6889

Epoch 00056: val_mDice did not improve from 0.69648
Epoch 57/300
 - 14s - loss: 1.3720 - acc: 0.9600 - mDice: 0.7229 - val_loss: 1.9251 - val_acc: 0.9675 - val_mDice: 0.6921

Epoch 00057: val_mDice did not improve from 0.69648
Epoch 58/300
 - 15s - loss: 1.3679 - acc: 0.9601 - mDice: 0.7235 - val_loss: 1.9362 - val_acc: 0.9669 - val_mDice: 0.6946

Epoch 00058: val_mDice did not improve from 0.69648
Epoch 59/300
 - 15s - loss: 1.3702 - acc: 0.9600 - mDice: 0.7232 - val_loss: 1.9250 - val_acc: 0.9677 - val_mDice: 0.6944

Epoch 00059: val_mDice did not improve from 0.69648
Epoch 60/300
 - 14s - loss: 1.3625 - acc: 0.9601 - mDice: 0.7246 - val_loss: 1.9069 - val_acc: 0.9673 - val_mDice: 0.6984

Epoch 00060: val_mDice improved from 0.69648 to 0.69840, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 61/300
 - 15s - loss: 1.3623 - acc: 0.9602 - mDice: 0.7248 - val_loss: 1.9254 - val_acc: 0.9668 - val_mDice: 0.6927

Epoch 00061: val_mDice did not improve from 0.69840
Epoch 62/300
 - 16s - loss: 1.3649 - acc: 0.9601 - mDice: 0.7242 - val_loss: 1.9206 - val_acc: 0.9669 - val_mDice: 0.6936

Epoch 00062: val_mDice did not improve from 0.69840
Epoch 63/300
 - 15s - loss: 1.3543 - acc: 0.9602 - mDice: 0.7258 - val_loss: 1.8989 - val_acc: 0.9674 - val_mDice: 0.6946

Epoch 00063: val_mDice did not improve from 0.69840
Epoch 64/300
 - 16s - loss: 1.3583 - acc: 0.9602 - mDice: 0.7254 - val_loss: 1.9761 - val_acc: 0.9669 - val_mDice: 0.6937

Epoch 00064: val_mDice did not improve from 0.69840
Epoch 65/300
 - 15s - loss: 1.3534 - acc: 0.9603 - mDice: 0.7267 - val_loss: 1.9373 - val_acc: 0.9673 - val_mDice: 0.6948

Epoch 00065: val_mDice did not improve from 0.69840
Epoch 66/300
 - 16s - loss: 1.3526 - acc: 0.9603 - mDice: 0.7263 - val_loss: 1.9501 - val_acc: 0.9668 - val_mDice: 0.6893

Epoch 00066: val_mDice did not improve from 0.69840
Epoch 67/300
 - 16s - loss: 1.3513 - acc: 0.9603 - mDice: 0.7268 - val_loss: 1.9240 - val_acc: 0.9675 - val_mDice: 0.6953

Epoch 00067: val_mDice did not improve from 0.69840
Epoch 68/300
 - 16s - loss: 1.3555 - acc: 0.9603 - mDice: 0.7260 - val_loss: 1.9288 - val_acc: 0.9674 - val_mDice: 0.6976

Epoch 00068: val_mDice did not improve from 0.69840
Epoch 69/300
 - 16s - loss: 1.3499 - acc: 0.9604 - mDice: 0.7273 - val_loss: 1.8965 - val_acc: 0.9672 - val_mDice: 0.6981

Epoch 00069: val_mDice did not improve from 0.69840
Epoch 70/300
 - 15s - loss: 1.3484 - acc: 0.9604 - mDice: 0.7270 - val_loss: 1.9548 - val_acc: 0.9671 - val_mDice: 0.6965

Epoch 00070: val_mDice did not improve from 0.69840
Epoch 71/300
 - 15s - loss: 1.3454 - acc: 0.9605 - mDice: 0.7278 - val_loss: 1.9321 - val_acc: 0.9670 - val_mDice: 0.6955

Epoch 00071: val_mDice did not improve from 0.69840
Epoch 72/300
 - 16s - loss: 1.3467 - acc: 0.9604 - mDice: 0.7281 - val_loss: 1.9509 - val_acc: 0.9676 - val_mDice: 0.6979

Epoch 00072: val_mDice did not improve from 0.69840
Epoch 73/300
 - 16s - loss: 1.3455 - acc: 0.9604 - mDice: 0.7282 - val_loss: 1.9560 - val_acc: 0.9672 - val_mDice: 0.6950

Epoch 00073: val_mDice did not improve from 0.69840
Epoch 74/300
 - 16s - loss: 1.3420 - acc: 0.9605 - mDice: 0.7286 - val_loss: 1.9467 - val_acc: 0.9674 - val_mDice: 0.6907

Epoch 00074: val_mDice did not improve from 0.69840
Epoch 75/300
 - 16s - loss: 1.3439 - acc: 0.9605 - mDice: 0.7283 - val_loss: 1.9515 - val_acc: 0.9668 - val_mDice: 0.6963

Epoch 00075: val_mDice did not improve from 0.69840
Epoch 76/300
 - 16s - loss: 1.3418 - acc: 0.9605 - mDice: 0.7288 - val_loss: 1.9047 - val_acc: 0.9673 - val_mDice: 0.6943

Epoch 00076: val_mDice did not improve from 0.69840
Epoch 77/300
 - 16s - loss: 1.3383 - acc: 0.9606 - mDice: 0.7293 - val_loss: 1.9452 - val_acc: 0.9681 - val_mDice: 0.6966

Epoch 00077: val_mDice did not improve from 0.69840
Epoch 78/300
 - 15s - loss: 1.3388 - acc: 0.9605 - mDice: 0.7292 - val_loss: 1.9661 - val_acc: 0.9671 - val_mDice: 0.6946

Epoch 00078: val_mDice did not improve from 0.69840
Epoch 79/300
 - 17s - loss: 1.3354 - acc: 0.9606 - mDice: 0.7301 - val_loss: 1.9191 - val_acc: 0.9671 - val_mDice: 0.6936

Epoch 00079: val_mDice did not improve from 0.69840
Epoch 80/300
 - 16s - loss: 1.3342 - acc: 0.9606 - mDice: 0.7302 - val_loss: 1.9248 - val_acc: 0.9674 - val_mDice: 0.6950

Epoch 00080: val_mDice did not improve from 0.69840
Epoch 81/300
 - 16s - loss: 1.3347 - acc: 0.9606 - mDice: 0.7301 - val_loss: 1.9515 - val_acc: 0.9675 - val_mDice: 0.6954

Epoch 00081: val_mDice did not improve from 0.69840
Epoch 82/300
 - 16s - loss: 1.3333 - acc: 0.9607 - mDice: 0.7302 - val_loss: 1.9563 - val_acc: 0.9673 - val_mDice: 0.6922

Epoch 00082: val_mDice did not improve from 0.69840
Epoch 83/300
 - 16s - loss: 1.3299 - acc: 0.9607 - mDice: 0.7311 - val_loss: 1.9137 - val_acc: 0.9671 - val_mDice: 0.6956

Epoch 00083: val_mDice did not improve from 0.69840
Epoch 84/300
 - 17s - loss: 1.3311 - acc: 0.9607 - mDice: 0.7309 - val_loss: 1.9514 - val_acc: 0.9677 - val_mDice: 0.6976

Epoch 00084: val_mDice did not improve from 0.69840
Epoch 85/300
 - 16s - loss: 1.3240 - acc: 0.9608 - mDice: 0.7324 - val_loss: 1.9811 - val_acc: 0.9669 - val_mDice: 0.6953

Epoch 00085: val_mDice did not improve from 0.69840
Epoch 86/300
 - 17s - loss: 1.3294 - acc: 0.9607 - mDice: 0.7312 - val_loss: 1.9215 - val_acc: 0.9672 - val_mDice: 0.6945

Epoch 00086: val_mDice did not improve from 0.69840
Epoch 87/300
 - 16s - loss: 1.3266 - acc: 0.9607 - mDice: 0.7319 - val_loss: 1.9686 - val_acc: 0.9663 - val_mDice: 0.6867

Epoch 00087: val_mDice did not improve from 0.69840
Epoch 88/300
 - 16s - loss: 1.3247 - acc: 0.9607 - mDice: 0.7321 - val_loss: 1.9308 - val_acc: 0.9680 - val_mDice: 0.6979

Epoch 00088: val_mDice did not improve from 0.69840
Epoch 89/300
 - 17s - loss: 1.3231 - acc: 0.9608 - mDice: 0.7325 - val_loss: 2.0091 - val_acc: 0.9674 - val_mDice: 0.6943

Epoch 00089: val_mDice did not improve from 0.69840
Epoch 90/300
 - 16s - loss: 1.3238 - acc: 0.9607 - mDice: 0.7323 - val_loss: 1.9819 - val_acc: 0.9670 - val_mDice: 0.6923

Epoch 00090: val_mDice did not improve from 0.69840
Restoring model weights from the end of the best epoch
Epoch 00090: early stopping
{'val_loss': [1.6634994500303921, 1.6646341101764, 1.6508108459106863, 1.7136709200192803, 1.7046405485231582, 1.6977829394275195, 1.7744278303564411, 1.7928544413553524, 1.7738295777203286, 1.7746420527157718, 1.7364690205822253, 1.7770244046433332, 1.7917674126690382, 1.866288319025954, 1.7729436665365141, 1.7541509883044517, 1.7995920115954256, 1.8017427545704254, 1.8171843861880368, 1.8354615626269823, 1.7606261135780648, 1.8187656484238088, 1.8111791659707892, 1.821393171401873, 1.8681884416162151, 1.797630976324212, 1.8056284858755869, 1.8331947163359759, 1.9640511976529473, 1.836631129865777, 1.870892049515084, 1.9245099106880084, 1.8632768882464057, 1.8391194163936457, 1.8559092070958385, 1.9097971067036668, 1.9291952178902823, 1.8957533297473437, 1.8516801220096955, 1.9063147045161626, 1.8865404047378123, 1.876985100850667, 1.8733796420162672, 1.8682348499559376, 1.902466315112702, 1.854339021525971, 1.936956480757831, 1.9721599278384692, 1.885258475395098, 1.9125038271080959, 1.8369976069829235, 1.8852192359427884, 1.8991799632163897, 1.8688713116188571, 1.8874366397727025, 1.9380727990032875, 1.9250533760410466, 1.9361597724156836, 1.9249933696772954, 1.9068560339000127, 1.9253889142650447, 1.9206049801552132, 1.8989080811200076, 1.9760628073182824, 1.9372715051860026, 1.9501049208314452, 1.9240156804045585, 1.9288007674151904, 1.8965334010450807, 1.9547521055561223, 1.9320886804632944, 1.950898773049655, 1.9560037083821753, 1.946708137041902, 1.95148202001232, 1.904663814257269, 1.9452063727052245, 1.9660829044368169, 1.9191034134120157, 1.924848102543452, 1.9515417781594682, 1.9563402639676446, 1.913665531432792, 1.951371044328768, 1.9811180650371394, 1.921469317723627, 1.9685996297287613, 1.9307764278699273, 2.0090877699525387, 1.9818826489252588], 'val_acc': [0.9672934208830742, 0.9675407948559278, 0.9685262335489874, 0.9674573940773533, 0.9668903497800435, 0.9680981293116531, 0.9672711540574896, 0.9668597660652579, 0.9674768578516294, 0.967560255364196, 0.9676811980874571, 0.9665359283146793, 0.967068222287583, 0.9656422440319845, 0.9674324058506587, 0.9674838185310364, 0.967314260463192, 0.9672670094934228, 0.9675310801153314, 0.9665150797530396, 0.9673434479595864, 0.9669515131271049, 0.9670223650866991, 0.9672864716346949, 0.9660494850106436, 0.9667833333146082, 0.9676061305281234, 0.9669598471628477, 0.9663816404669252, 0.9665581600306785, 0.9671057642322697, 0.9661731548505287, 0.9673782056325102, 0.9671891445982946, 0.9670960519411792, 0.9669473065088873, 0.9669751492265153, 0.9678660508704512, 0.9671377588624823, 0.9663705417554672, 0.9668013820909473, 0.9672892640714776, 0.9674546506306897, 0.9669681558870289, 0.9667291077848983, 0.9678660541364591, 0.9669056510272092, 0.9654754465573454, 0.9677187057390605, 0.9672475449026448, 0.9669056493942052, 0.9674977251928146, 0.9670835431307963, 0.9672614409498972, 0.9668305818348715, 0.9672447614473839, 0.9675185517089008, 0.9669181451405564, 0.9676714653838171, 0.9672948113859516, 0.9668444631850883, 0.9669181271775128, 0.9674240571178802, 0.9669334447547181, 0.9672767250505212, 0.9668333505930966, 0.9675366347783232, 0.9673976604252645, 0.9672155870150213, 0.9670890896287683, 0.9670460158831453, 0.9675811186228713, 0.9672239218672661, 0.9674018319338968, 0.9667888610330346, 0.9673100954865756, 0.9680661926530811, 0.9670765775523774, 0.9671266160599173, 0.9674254345567259, 0.9674949539850836, 0.9673073242788446, 0.9670863429160967, 0.9677298183310522, 0.9668736621125104, 0.9672475253065972, 0.9662746558450672, 0.9680119744718891, 0.9673907185254031, 0.9670029111104469], 'val_mDice': [0.6605823521744715, 0.6671501855327658, 0.6711595434032075, 0.6742003805016819, 0.6782187860305995, 0.6800003909084895, 0.6827630841568725, 0.6807354949925044, 0.6807350418339037, 0.6810939458951558, 0.6884075003127529, 0.6821686413190137, 0.6847050149146825, 0.6846002111696217, 0.6867039905835505, 0.6857951373270114, 0.68876810678064, 0.6884941891448139, 0.6892722028575532, 0.6843989393482469, 0.6843376812869555, 0.6898415725525111, 0.6880657231971009, 0.687576952045911, 0.687623776801645, 0.6875189085529275, 0.6895326106515649, 0.6892486149317598, 0.6834425550617583, 0.6864516245175715, 0.6915767944022401, 0.6880429550392987, 0.6922814111187033, 0.6901121588602458, 0.6961416740940042, 0.6866322853793837, 0.6879140938798042, 0.6905539664503646, 0.6902374910981688, 0.690302994153271, 0.6930517121537091, 0.6921259270955439, 0.6917539263424808, 0.6908166081938025, 0.6909014084567763, 0.6963590138579068, 0.6848558105834542, 0.6846794290085362, 0.694035579896953, 0.6916648165820396, 0.6944665827163278, 0.6964764595031738, 0.6912473031919296, 0.6929592824962041, 0.6916526449869757, 0.6888578493301183, 0.6920555634041355, 0.6945926432740198, 0.694435423367644, 0.698400857513898, 0.6927166491338651, 0.693580540892196, 0.6945967331324538, 0.6936698694751687, 0.6947788767618676, 0.6893265949536677, 0.695329775548961, 0.6976303139778033, 0.6980540629935591, 0.6964965103423759, 0.695501547153682, 0.6979034404232077, 0.6949577862269258, 0.6907438586835992, 0.6963427826149823, 0.6943310882947217, 0.696591952892199, 0.6946306106162398, 0.693561852794804, 0.6950141803859031, 0.6954083785618821, 0.6922477353109072, 0.6956152719994114, 0.6975683855683836, 0.6953498892588158, 0.6945491882219706, 0.6867387792835496, 0.6979432840869851, 0.6942671880330125, 0.6923026907933901], 'loss': [2.2891927134172483, 1.9302592279352255, 1.8335308952889329, 1.7734696839347242, 1.7304655014555899, 1.6948463983638276, 1.6698797502217333, 1.6501703716101808, 1.6276953695257497, 1.6126417660687427, 1.5960610280600724, 1.582314337884772, 1.5671283392435738, 1.5594603923078214, 1.5475333647485152, 1.5386789376074392, 1.5297509650242607, 1.5206370412863133, 1.5153104352684756, 1.5018725465355225, 1.5013831539432658, 1.4902086444769522, 1.486653253966707, 1.4774899866132416, 1.4736181979228633, 1.4671369369041596, 1.4640296723780628, 1.4563326272729396, 1.452726518478593, 1.4477591680662916, 1.442669346949177, 1.4434579836064498, 1.436513239053293, 1.431544264472584, 1.4295960984372924, 1.4260014878452945, 1.4201829515047233, 1.4198510605838073, 1.41719725117958, 1.4099096423984183, 1.4125428278868688, 1.4058801112200472, 1.401272819298907, 1.4031708259622033, 1.3970313838406854, 1.3933166699431532, 1.3973385937105234, 1.3927116220594276, 1.3855952105135314, 1.3865592733543641, 1.381827701035043, 1.3812801079557355, 1.379044207611478, 1.380052156719096, 1.3764848298928563, 1.3734975773522369, 1.3719756320733634, 1.3678608093398874, 1.370227906447391, 1.3625450095765006, 1.3622505926108035, 1.3648664295183017, 1.3543418003067786, 1.3582751514717946, 1.3533887880124653, 1.35264321021516, 1.3512808279161346, 1.3554706436116108, 1.349910344367685, 1.348360362188498, 1.3454406825528162, 1.3467283509754457, 1.3454600726313286, 1.342018978739475, 1.3439133007598125, 1.3417624477680714, 1.3382579746643202, 1.3388040152096015, 1.3353840067301728, 1.3342278365300582, 1.3347305941243848, 1.3332707531450891, 1.3298600085796854, 1.3310577927255376, 1.3240202722596397, 1.3294131453957978, 1.3265890471607273, 1.3246940796005757, 1.3231403552389915, 1.3238284663918398], 'acc': [0.949042822887595, 0.9521857443095213, 0.953505802750838, 0.9542149392962778, 0.9547893454103236, 0.955312240354966, 0.955637369740441, 0.9558969031745791, 0.9561508813863874, 0.9563634682437546, 0.9566002784101467, 0.9567555425897672, 0.9569534419077277, 0.9570822193802552, 0.9572410426475991, 0.9573309702471785, 0.957501040932109, 0.9575752381776493, 0.9576895216137971, 0.9578470899623085, 0.957882976679446, 0.9580605159877893, 0.9580640258040577, 0.9582036061128868, 0.9583435225886195, 0.9584081387946479, 0.9584645353651817, 0.9585683135659044, 0.9585895193150714, 0.9587419814034954, 0.9587417488763019, 0.9588381721330163, 0.9588927247141572, 0.9589631704319735, 0.9590979024775929, 0.9590755029676169, 0.959208506031136, 0.9591875002705312, 0.9592198149002416, 0.959380297999278, 0.9593308487396902, 0.9594022541091097, 0.9594567108031172, 0.9595133962519841, 0.9595449313039086, 0.9596419621392971, 0.959617862900134, 0.959663091307609, 0.9597716160073392, 0.9597844075728542, 0.9598358927464289, 0.9598312260960986, 0.9598601514288221, 0.959847649793929, 0.9599611207235256, 0.9599948144385688, 0.960011762430351, 0.9600846450307209, 0.9600159674444435, 0.9601350318724806, 0.9601531120053298, 0.9601236720604274, 0.9602325117166411, 0.9602232395596871, 0.9602989345379136, 0.9602707255633252, 0.9603079645360102, 0.9602834837741482, 0.9603544754043668, 0.9604094319713514, 0.9604566994890511, 0.96043726315994, 0.9604454964215008, 0.9604884293754702, 0.9604745007367318, 0.9604777539448573, 0.9605748222009245, 0.9605369038326436, 0.9605846078068131, 0.9605700586040135, 0.9606464344882638, 0.9606670905883296, 0.9607046795078908, 0.9606736588677093, 0.9607713363059381, 0.9607083983609735, 0.9607260923897305, 0.960715136681635, 0.9608154953982833, 0.9607382747014993], 'mDice': [0.5905534444231533, 0.6240174457746706, 0.6385865551512112, 0.6484097390033702, 0.6551374069800973, 0.6616769997785666, 0.6658831959886607, 0.6691155981703978, 0.6735022633968942, 0.6763147039434355, 0.6790802854822469, 0.6815481022844112, 0.6846483957049496, 0.6858551414250712, 0.6882778829492578, 0.6902385523804156, 0.6914627332519298, 0.6933021494585323, 0.6947047434031823, 0.6970161647758835, 0.6973721881689613, 0.6991570260813521, 0.7000576853358422, 0.7019688705134405, 0.7026780785393559, 0.703958217062435, 0.7046014218475556, 0.7060068585504278, 0.7064939919179791, 0.7078030998195849, 0.7086215589537976, 0.7084679454108699, 0.7096619037066266, 0.7108789809736727, 0.711647589897627, 0.7118225555902973, 0.7130164140832608, 0.7129390305680483, 0.7139012026713788, 0.7149769030683629, 0.714375065424303, 0.7159375993187403, 0.7167679824994032, 0.7164167328109357, 0.7178105187188438, 0.7189500357505831, 0.7179409105670507, 0.7184637306667567, 0.71992426901288, 0.7197285802029478, 0.7206412979999992, 0.7209746749280974, 0.7213769404657508, 0.7211314513791698, 0.7217225043084867, 0.7225760554992451, 0.7229323643775614, 0.7235251835987015, 0.723210243404087, 0.7245881170480021, 0.7247595183807672, 0.724209174872633, 0.7258153836777108, 0.7253667467715526, 0.7266506572704032, 0.7263216887416335, 0.7268204881086483, 0.7259819487125775, 0.7272887476169332, 0.7270318720638949, 0.7277731736744445, 0.7281214885723696, 0.7282394321374418, 0.7285500066076922, 0.7283245179199753, 0.728779311753648, 0.7293004558471948, 0.729242934122219, 0.7300705281040127, 0.7302278943737012, 0.7301070222996064, 0.7301630247879807, 0.7311401244062551, 0.7309488083323666, 0.7323936615191816, 0.7311926514817624, 0.7318705486219037, 0.7321085960329714, 0.73252316620202, 0.7322506096344026]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:03<00:09,  3.07s/it]predicting test subjects:  50%|█████     | 2/4 [00:04<00:05,  2.59s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:06<00:02,  2.34s/it]predicting test subjects: 100%|██████████| 4/4 [00:08<00:00,  2.20s/it]
predicting train subjects:   0%|          | 0/456 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/456 [00:01<13:25,  1.77s/it]predicting train subjects:   0%|          | 2/456 [00:03<13:05,  1.73s/it]predicting train subjects:   1%|          | 3/456 [00:04<12:21,  1.64s/it]predicting train subjects:   1%|          | 4/456 [00:06<11:46,  1.56s/it]predicting train subjects:   1%|          | 5/456 [00:08<12:50,  1.71s/it]predicting train subjects:   1%|▏         | 6/456 [00:10<12:59,  1.73s/it]predicting train subjects:   2%|▏         | 7/456 [00:11<12:32,  1.68s/it]predicting train subjects:   2%|▏         | 8/456 [00:12<11:02,  1.48s/it]predicting train subjects:   2%|▏         | 9/456 [00:14<11:19,  1.52s/it]predicting train subjects:   2%|▏         | 10/456 [00:16<12:41,  1.71s/it]predicting train subjects:   2%|▏         | 11/456 [00:18<13:39,  1.84s/it]predicting train subjects:   3%|▎         | 12/456 [00:19<11:41,  1.58s/it]predicting train subjects:   3%|▎         | 13/456 [00:21<12:22,  1.68s/it]predicting train subjects:   3%|▎         | 14/456 [00:23<12:48,  1.74s/it]predicting train subjects:   3%|▎         | 15/456 [00:24<11:20,  1.54s/it]predicting train subjects:   4%|▎         | 16/456 [00:26<12:03,  1.64s/it]predicting train subjects:   4%|▎         | 17/456 [00:28<13:26,  1.84s/it]predicting train subjects:   4%|▍         | 18/456 [00:30<13:00,  1.78s/it]predicting train subjects:   4%|▍         | 19/456 [00:31<12:31,  1.72s/it]predicting train subjects:   4%|▍         | 20/456 [00:33<11:59,  1.65s/it]predicting train subjects:   5%|▍         | 21/456 [00:34<11:40,  1.61s/it]predicting train subjects:   5%|▍         | 22/456 [00:36<11:40,  1.61s/it]predicting train subjects:   5%|▌         | 23/456 [00:38<11:44,  1.63s/it]predicting train subjects:   5%|▌         | 24/456 [00:39<10:22,  1.44s/it]predicting train subjects:   5%|▌         | 25/456 [00:40<10:40,  1.49s/it]predicting train subjects:   6%|▌         | 26/456 [00:42<11:00,  1.54s/it]predicting train subjects:   6%|▌         | 27/456 [00:44<11:34,  1.62s/it]predicting train subjects:   6%|▌         | 28/456 [00:45<11:25,  1.60s/it]predicting train subjects:   6%|▋         | 29/456 [00:47<11:19,  1.59s/it]predicting train subjects:   7%|▋         | 30/456 [00:48<11:24,  1.61s/it]predicting train subjects:   7%|▋         | 31/456 [00:50<11:38,  1.64s/it]predicting train subjects:   7%|▋         | 32/456 [00:52<11:37,  1.65s/it]predicting train subjects:   7%|▋         | 33/456 [00:53<11:31,  1.64s/it]predicting train subjects:   7%|▋         | 34/456 [00:55<11:42,  1.66s/it]predicting train subjects:   8%|▊         | 35/456 [00:57<11:59,  1.71s/it]predicting train subjects:   8%|▊         | 36/456 [00:58<11:30,  1.64s/it]predicting train subjects:   8%|▊         | 37/456 [01:00<11:50,  1.70s/it]predicting train subjects:   8%|▊         | 38/456 [01:02<11:35,  1.66s/it]predicting train subjects:   9%|▊         | 39/456 [01:03<11:11,  1.61s/it]predicting train subjects:   9%|▉         | 40/456 [01:05<11:07,  1.60s/it]predicting train subjects:   9%|▉         | 41/456 [01:07<11:13,  1.62s/it]predicting train subjects:   9%|▉         | 42/456 [01:08<11:18,  1.64s/it]predicting train subjects:   9%|▉         | 43/456 [01:10<11:20,  1.65s/it]predicting train subjects:  10%|▉         | 44/456 [01:12<11:54,  1.73s/it]predicting train subjects:  10%|▉         | 45/456 [01:14<12:04,  1.76s/it]predicting train subjects:  10%|█         | 46/456 [01:15<11:51,  1.73s/it]predicting train subjects:  10%|█         | 47/456 [01:17<12:14,  1.80s/it]predicting train subjects:  11%|█         | 48/456 [01:19<12:55,  1.90s/it]predicting train subjects:  11%|█         | 49/456 [01:21<12:23,  1.83s/it]predicting train subjects:  11%|█         | 50/456 [01:23<12:23,  1.83s/it]predicting train subjects:  11%|█         | 51/456 [01:25<12:22,  1.83s/it]predicting train subjects:  11%|█▏        | 52/456 [01:27<12:14,  1.82s/it]predicting train subjects:  12%|█▏        | 53/456 [01:28<11:54,  1.77s/it]predicting train subjects:  12%|█▏        | 54/456 [01:30<11:52,  1.77s/it]predicting train subjects:  12%|█▏        | 55/456 [01:32<11:28,  1.72s/it]predicting train subjects:  12%|█▏        | 56/456 [01:33<11:10,  1.68s/it]predicting train subjects:  12%|█▎        | 57/456 [01:35<11:29,  1.73s/it]predicting train subjects:  13%|█▎        | 58/456 [01:37<11:59,  1.81s/it]predicting train subjects:  13%|█▎        | 59/456 [01:39<11:52,  1.79s/it]predicting train subjects:  13%|█▎        | 60/456 [01:40<11:39,  1.77s/it]predicting train subjects:  13%|█▎        | 61/456 [01:42<11:41,  1.78s/it]predicting train subjects:  14%|█▎        | 62/456 [01:44<11:52,  1.81s/it]predicting train subjects:  14%|█▍        | 63/456 [01:46<11:53,  1.82s/it]predicting train subjects:  14%|█▍        | 64/456 [01:48<11:45,  1.80s/it]predicting train subjects:  14%|█▍        | 65/456 [01:50<11:44,  1.80s/it]predicting train subjects:  14%|█▍        | 66/456 [01:51<11:46,  1.81s/it]predicting train subjects:  15%|█▍        | 67/456 [01:53<11:41,  1.80s/it]predicting train subjects:  15%|█▍        | 68/456 [01:55<11:26,  1.77s/it]predicting train subjects:  15%|█▌        | 69/456 [01:57<11:32,  1.79s/it]predicting train subjects:  15%|█▌        | 70/456 [01:59<11:40,  1.81s/it]predicting train subjects:  16%|█▌        | 71/456 [02:00<11:30,  1.79s/it]predicting train subjects:  16%|█▌        | 72/456 [02:02<11:39,  1.82s/it]predicting train subjects:  16%|█▌        | 73/456 [02:04<11:47,  1.85s/it]predicting train subjects:  16%|█▌        | 74/456 [02:06<11:45,  1.85s/it]predicting train subjects:  16%|█▋        | 75/456 [02:08<11:50,  1.87s/it]predicting train subjects:  17%|█▋        | 76/456 [02:10<11:40,  1.84s/it]predicting train subjects:  17%|█▋        | 77/456 [02:11<11:21,  1.80s/it]predicting train subjects:  17%|█▋        | 78/456 [02:13<11:43,  1.86s/it]predicting train subjects:  17%|█▋        | 79/456 [02:14<10:07,  1.61s/it]predicting train subjects:  18%|█▊        | 80/456 [02:15<08:54,  1.42s/it]predicting train subjects:  18%|█▊        | 81/456 [02:16<08:09,  1.31s/it]predicting train subjects:  18%|█▊        | 82/456 [02:17<07:40,  1.23s/it]predicting train subjects:  18%|█▊        | 83/456 [02:18<07:16,  1.17s/it]predicting train subjects:  18%|█▊        | 84/456 [02:19<06:56,  1.12s/it]predicting train subjects:  19%|█▊        | 85/456 [02:20<06:38,  1.07s/it]predicting train subjects:  19%|█▉        | 86/456 [02:22<06:38,  1.08s/it]predicting train subjects:  19%|█▉        | 87/456 [02:23<06:26,  1.05s/it]predicting train subjects:  19%|█▉        | 88/456 [02:24<06:24,  1.04s/it]predicting train subjects:  20%|█▉        | 89/456 [02:25<06:16,  1.03s/it]predicting train subjects:  20%|█▉        | 90/456 [02:25<06:10,  1.01s/it]predicting train subjects:  20%|█▉        | 91/456 [02:27<06:24,  1.05s/it]predicting train subjects:  20%|██        | 92/456 [02:28<06:37,  1.09s/it]predicting train subjects:  20%|██        | 93/456 [02:29<06:31,  1.08s/it]predicting train subjects:  21%|██        | 94/456 [02:30<06:15,  1.04s/it]predicting train subjects:  21%|██        | 95/456 [02:31<06:13,  1.03s/it]predicting train subjects:  21%|██        | 96/456 [02:32<06:05,  1.01s/it]predicting train subjects:  21%|██▏       | 97/456 [02:33<07:14,  1.21s/it]predicting train subjects:  21%|██▏       | 98/456 [02:35<07:51,  1.32s/it]predicting train subjects:  22%|██▏       | 99/456 [02:37<08:31,  1.43s/it]predicting train subjects:  22%|██▏       | 100/456 [02:39<09:07,  1.54s/it]predicting train subjects:  22%|██▏       | 101/456 [02:40<09:07,  1.54s/it]predicting train subjects:  22%|██▏       | 102/456 [02:42<09:23,  1.59s/it]predicting train subjects:  23%|██▎       | 103/456 [02:44<09:48,  1.67s/it]predicting train subjects:  23%|██▎       | 104/456 [02:45<10:02,  1.71s/it]predicting train subjects:  23%|██▎       | 105/456 [02:47<09:59,  1.71s/it]predicting train subjects:  23%|██▎       | 106/456 [02:49<09:36,  1.65s/it]predicting train subjects:  23%|██▎       | 107/456 [02:50<09:49,  1.69s/it]predicting train subjects:  24%|██▎       | 108/456 [02:52<10:07,  1.75s/it]predicting train subjects:  24%|██▍       | 109/456 [02:54<09:48,  1.70s/it]predicting train subjects:  24%|██▍       | 110/456 [02:56<09:45,  1.69s/it]predicting train subjects:  24%|██▍       | 111/456 [02:57<09:56,  1.73s/it]predicting train subjects:  25%|██▍       | 112/456 [02:59<09:42,  1.69s/it]predicting train subjects:  25%|██▍       | 113/456 [03:01<09:32,  1.67s/it]predicting train subjects:  25%|██▌       | 114/456 [03:02<09:28,  1.66s/it]predicting train subjects:  25%|██▌       | 115/456 [03:04<09:38,  1.70s/it]predicting train subjects:  25%|██▌       | 116/456 [03:06<09:37,  1.70s/it]predicting train subjects:  26%|██▌       | 117/456 [03:08<09:53,  1.75s/it]predicting train subjects:  26%|██▌       | 118/456 [03:09<09:38,  1.71s/it]predicting train subjects:  26%|██▌       | 119/456 [03:11<09:40,  1.72s/it]predicting train subjects:  26%|██▋       | 120/456 [03:13<09:48,  1.75s/it]predicting train subjects:  27%|██▋       | 121/456 [03:15<09:57,  1.78s/it]predicting train subjects:  27%|██▋       | 122/456 [03:17<10:10,  1.83s/it]predicting train subjects:  27%|██▋       | 123/456 [03:18<10:07,  1.82s/it]predicting train subjects:  27%|██▋       | 124/456 [03:20<10:01,  1.81s/it]predicting train subjects:  27%|██▋       | 125/456 [03:22<10:13,  1.85s/it]predicting train subjects:  28%|██▊       | 126/456 [03:24<10:37,  1.93s/it]predicting train subjects:  28%|██▊       | 127/456 [03:25<09:23,  1.71s/it]predicting train subjects:  28%|██▊       | 128/456 [03:27<09:14,  1.69s/it]predicting train subjects:  28%|██▊       | 129/456 [03:29<08:49,  1.62s/it]predicting train subjects:  29%|██▊       | 130/456 [03:30<08:20,  1.53s/it]predicting train subjects:  29%|██▊       | 131/456 [03:31<07:57,  1.47s/it]predicting train subjects:  29%|██▉       | 132/456 [03:33<07:57,  1.47s/it]predicting train subjects:  29%|██▉       | 133/456 [03:35<09:06,  1.69s/it]predicting train subjects:  29%|██▉       | 134/456 [03:37<09:23,  1.75s/it]predicting train subjects:  30%|██▉       | 135/456 [03:39<09:31,  1.78s/it]predicting train subjects:  30%|██▉       | 136/456 [03:41<09:44,  1.83s/it]predicting train subjects:  30%|███       | 137/456 [03:43<10:16,  1.93s/it]predicting train subjects:  30%|███       | 138/456 [03:45<10:30,  1.98s/it]predicting train subjects:  30%|███       | 139/456 [03:46<09:35,  1.82s/it]predicting train subjects:  31%|███       | 140/456 [03:48<08:48,  1.67s/it]predicting train subjects:  31%|███       | 141/456 [03:49<08:25,  1.60s/it]predicting train subjects:  31%|███       | 142/456 [03:50<07:54,  1.51s/it]predicting train subjects:  31%|███▏      | 143/456 [03:52<07:37,  1.46s/it]predicting train subjects:  32%|███▏      | 144/456 [03:53<07:24,  1.42s/it]predicting train subjects:  32%|███▏      | 145/456 [03:55<07:32,  1.46s/it]predicting train subjects:  32%|███▏      | 146/456 [03:56<07:32,  1.46s/it]predicting train subjects:  32%|███▏      | 147/456 [03:58<07:41,  1.49s/it]predicting train subjects:  32%|███▏      | 148/456 [03:59<07:39,  1.49s/it]predicting train subjects:  33%|███▎      | 149/456 [04:01<07:33,  1.48s/it]predicting train subjects:  33%|███▎      | 150/456 [04:02<07:50,  1.54s/it]predicting train subjects:  33%|███▎      | 151/456 [04:04<07:50,  1.54s/it]predicting train subjects:  33%|███▎      | 152/456 [04:05<07:46,  1.53s/it]predicting train subjects:  34%|███▎      | 153/456 [04:07<08:11,  1.62s/it]predicting train subjects:  34%|███▍      | 154/456 [04:09<08:10,  1.62s/it]predicting train subjects:  34%|███▍      | 155/456 [04:10<08:02,  1.60s/it]predicting train subjects:  34%|███▍      | 156/456 [04:12<08:07,  1.62s/it]predicting train subjects:  34%|███▍      | 157/456 [04:13<07:55,  1.59s/it]predicting train subjects:  35%|███▍      | 158/456 [04:15<07:42,  1.55s/it]predicting train subjects:  35%|███▍      | 159/456 [04:17<07:49,  1.58s/it]predicting train subjects:  35%|███▌      | 160/456 [04:18<07:55,  1.61s/it]predicting train subjects:  35%|███▌      | 161/456 [04:20<07:40,  1.56s/it]predicting train subjects:  36%|███▌      | 162/456 [04:21<07:22,  1.50s/it]predicting train subjects:  36%|███▌      | 163/456 [04:22<06:41,  1.37s/it]predicting train subjects:  36%|███▌      | 164/456 [04:23<06:10,  1.27s/it]predicting train subjects:  36%|███▌      | 165/456 [04:24<05:50,  1.20s/it]predicting train subjects:  36%|███▋      | 166/456 [04:25<05:27,  1.13s/it]predicting train subjects:  37%|███▋      | 167/456 [04:26<05:18,  1.10s/it]predicting train subjects:  37%|███▋      | 168/456 [04:27<05:12,  1.08s/it]predicting train subjects:  37%|███▋      | 169/456 [04:28<05:14,  1.10s/it]predicting train subjects:  37%|███▋      | 170/456 [04:30<05:16,  1.11s/it]predicting train subjects:  38%|███▊      | 171/456 [04:31<05:07,  1.08s/it]predicting train subjects:  38%|███▊      | 172/456 [04:32<05:09,  1.09s/it]predicting train subjects:  38%|███▊      | 173/456 [04:33<05:20,  1.13s/it]predicting train subjects:  38%|███▊      | 174/456 [04:34<05:15,  1.12s/it]predicting train subjects:  38%|███▊      | 175/456 [04:35<05:09,  1.10s/it]predicting train subjects:  39%|███▊      | 176/456 [04:36<05:05,  1.09s/it]predicting train subjects:  39%|███▉      | 177/456 [04:37<04:56,  1.06s/it]predicting train subjects:  39%|███▉      | 178/456 [04:38<04:57,  1.07s/it]predicting train subjects:  39%|███▉      | 179/456 [04:39<04:53,  1.06s/it]predicting train subjects:  39%|███▉      | 180/456 [04:40<04:46,  1.04s/it]predicting train subjects:  40%|███▉      | 181/456 [04:42<05:52,  1.28s/it]predicting train subjects:  40%|███▉      | 182/456 [04:44<06:42,  1.47s/it]predicting train subjects:  40%|████      | 183/456 [04:46<07:30,  1.65s/it]predicting train subjects:  40%|████      | 184/456 [04:48<07:43,  1.70s/it]predicting train subjects:  41%|████      | 185/456 [04:50<07:43,  1.71s/it]predicting train subjects:  41%|████      | 186/456 [04:51<07:54,  1.76s/it]predicting train subjects:  41%|████      | 187/456 [04:54<08:25,  1.88s/it]predicting train subjects:  41%|████      | 188/456 [04:56<08:43,  1.95s/it]predicting train subjects:  41%|████▏     | 189/456 [04:58<08:48,  1.98s/it]predicting train subjects:  42%|████▏     | 190/456 [05:00<09:08,  2.06s/it]predicting train subjects:  42%|████▏     | 191/456 [05:02<09:13,  2.09s/it]predicting train subjects:  42%|████▏     | 192/456 [05:04<09:28,  2.15s/it]predicting train subjects:  42%|████▏     | 193/456 [05:07<09:17,  2.12s/it]predicting train subjects:  43%|████▎     | 194/456 [05:08<08:57,  2.05s/it]predicting train subjects:  43%|████▎     | 195/456 [05:10<08:45,  2.02s/it]predicting train subjects:  43%|████▎     | 196/456 [05:12<08:35,  1.98s/it]predicting train subjects:  43%|████▎     | 197/456 [05:14<08:31,  1.98s/it]predicting train subjects:  43%|████▎     | 198/456 [05:16<08:19,  1.94s/it]predicting train subjects:  44%|████▎     | 199/456 [05:18<07:53,  1.84s/it]predicting train subjects:  44%|████▍     | 200/456 [05:19<07:39,  1.80s/it]predicting train subjects:  44%|████▍     | 201/456 [05:21<07:25,  1.75s/it]predicting train subjects:  44%|████▍     | 202/456 [05:23<07:15,  1.71s/it]predicting train subjects:  45%|████▍     | 203/456 [05:24<07:06,  1.69s/it]predicting train subjects:  45%|████▍     | 204/456 [05:26<06:58,  1.66s/it]predicting train subjects:  45%|████▍     | 205/456 [05:27<06:28,  1.55s/it]predicting train subjects:  45%|████▌     | 206/456 [05:28<06:02,  1.45s/it]predicting train subjects:  45%|████▌     | 207/456 [05:30<05:48,  1.40s/it]predicting train subjects:  46%|████▌     | 208/456 [05:31<05:41,  1.38s/it]predicting train subjects:  46%|████▌     | 209/456 [05:32<05:34,  1.35s/it]predicting train subjects:  46%|████▌     | 210/456 [05:34<05:28,  1.34s/it]predicting train subjects:  46%|████▋     | 211/456 [05:35<05:46,  1.41s/it]predicting train subjects:  46%|████▋     | 212/456 [05:37<05:59,  1.47s/it]predicting train subjects:  47%|████▋     | 213/456 [05:38<06:04,  1.50s/it]predicting train subjects:  47%|████▋     | 214/456 [05:40<06:18,  1.56s/it]predicting train subjects:  47%|████▋     | 215/456 [05:42<06:26,  1.60s/it]predicting train subjects:  47%|████▋     | 216/456 [05:43<06:13,  1.56s/it]predicting train subjects:  48%|████▊     | 217/456 [05:45<06:22,  1.60s/it]predicting train subjects:  48%|████▊     | 218/456 [05:47<06:27,  1.63s/it]predicting train subjects:  48%|████▊     | 219/456 [05:48<06:32,  1.65s/it]predicting train subjects:  48%|████▊     | 220/456 [05:50<06:29,  1.65s/it]predicting train subjects:  48%|████▊     | 221/456 [05:52<06:25,  1.64s/it]predicting train subjects:  49%|████▊     | 222/456 [05:53<06:18,  1.62s/it]predicting train subjects:  49%|████▉     | 223/456 [05:55<06:18,  1.63s/it]predicting train subjects:  49%|████▉     | 224/456 [05:56<06:19,  1.64s/it]predicting train subjects:  49%|████▉     | 225/456 [05:58<06:35,  1.71s/it]predicting train subjects:  50%|████▉     | 226/456 [06:00<06:32,  1.71s/it]predicting train subjects:  50%|████▉     | 227/456 [06:02<06:18,  1.65s/it]predicting train subjects:  50%|█████     | 228/456 [06:03<06:18,  1.66s/it]predicting train subjects:  50%|█████     | 229/456 [06:05<06:16,  1.66s/it]predicting train subjects:  50%|█████     | 230/456 [06:07<06:13,  1.65s/it]predicting train subjects:  51%|█████     | 231/456 [06:08<06:11,  1.65s/it]predicting train subjects:  51%|█████     | 232/456 [06:10<06:09,  1.65s/it]predicting train subjects:  51%|█████     | 233/456 [06:11<05:52,  1.58s/it]predicting train subjects:  51%|█████▏    | 234/456 [06:13<05:56,  1.60s/it]predicting train subjects:  52%|█████▏    | 235/456 [06:15<06:04,  1.65s/it]predicting train subjects:  52%|█████▏    | 236/456 [06:16<06:10,  1.68s/it]predicting train subjects:  52%|█████▏    | 237/456 [06:18<06:06,  1.67s/it]predicting train subjects:  52%|█████▏    | 238/456 [06:20<06:02,  1.66s/it]predicting train subjects:  52%|█████▏    | 239/456 [06:21<05:52,  1.62s/it]predicting train subjects:  53%|█████▎    | 240/456 [06:23<05:58,  1.66s/it]predicting train subjects:  53%|█████▎    | 241/456 [06:25<05:54,  1.65s/it]predicting train subjects:  53%|█████▎    | 242/456 [06:26<05:58,  1.67s/it]predicting train subjects:  53%|█████▎    | 243/456 [06:28<05:58,  1.68s/it]predicting train subjects:  54%|█████▎    | 244/456 [06:30<05:55,  1.68s/it]predicting train subjects:  54%|█████▎    | 245/456 [06:31<05:58,  1.70s/it]predicting train subjects:  54%|█████▍    | 246/456 [06:33<05:58,  1.71s/it]predicting train subjects:  54%|█████▍    | 247/456 [06:35<05:39,  1.62s/it]predicting train subjects:  54%|█████▍    | 248/456 [06:36<05:18,  1.53s/it]predicting train subjects:  55%|█████▍    | 249/456 [06:37<05:03,  1.46s/it]predicting train subjects:  55%|█████▍    | 250/456 [06:39<04:51,  1.42s/it]predicting train subjects:  55%|█████▌    | 251/456 [06:40<04:49,  1.41s/it]predicting train subjects:  55%|█████▌    | 252/456 [06:41<04:37,  1.36s/it]predicting train subjects:  55%|█████▌    | 253/456 [06:43<05:10,  1.53s/it]predicting train subjects:  56%|█████▌    | 254/456 [06:45<05:38,  1.68s/it]predicting train subjects:  56%|█████▌    | 255/456 [06:47<05:54,  1.76s/it]predicting train subjects:  56%|█████▌    | 256/456 [06:49<06:09,  1.85s/it]predicting train subjects:  56%|█████▋    | 257/456 [06:51<06:32,  1.97s/it]predicting train subjects:  57%|█████▋    | 258/456 [06:53<06:38,  2.01s/it]predicting train subjects:  57%|█████▋    | 259/456 [06:55<05:59,  1.83s/it]predicting train subjects:  57%|█████▋    | 260/456 [06:56<05:26,  1.67s/it]predicting train subjects:  57%|█████▋    | 261/456 [06:58<05:06,  1.57s/it]predicting train subjects:  57%|█████▋    | 262/456 [06:59<04:56,  1.53s/it]predicting train subjects:  58%|█████▊    | 263/456 [07:00<04:43,  1.47s/it]predicting train subjects:  58%|█████▊    | 264/456 [07:02<04:32,  1.42s/it]predicting train subjects:  58%|█████▊    | 265/456 [07:03<04:27,  1.40s/it]predicting train subjects:  58%|█████▊    | 266/456 [07:04<04:29,  1.42s/it]predicting train subjects:  59%|█████▊    | 267/456 [07:06<04:28,  1.42s/it]predicting train subjects:  59%|█████▉    | 268/456 [07:07<04:33,  1.45s/it]predicting train subjects:  59%|█████▉    | 269/456 [07:09<04:30,  1.45s/it]predicting train subjects:  59%|█████▉    | 270/456 [07:10<04:28,  1.44s/it]predicting train subjects:  59%|█████▉    | 271/456 [07:12<04:38,  1.51s/it]predicting train subjects:  60%|█████▉    | 272/456 [07:14<04:45,  1.55s/it]predicting train subjects:  60%|█████▉    | 273/456 [07:15<04:48,  1.58s/it]predicting train subjects:  60%|██████    | 274/456 [07:17<04:58,  1.64s/it]predicting train subjects:  60%|██████    | 275/456 [07:19<04:59,  1.65s/it]predicting train subjects:  61%|██████    | 276/456 [07:20<05:05,  1.70s/it]predicting train subjects:  61%|██████    | 277/456 [07:22<05:00,  1.68s/it]predicting train subjects:  61%|██████    | 278/456 [07:24<04:45,  1.61s/it]predicting train subjects:  61%|██████    | 279/456 [07:25<04:35,  1.56s/it]predicting train subjects:  61%|██████▏   | 280/456 [07:27<04:33,  1.55s/it]predicting train subjects:  62%|██████▏   | 281/456 [07:28<04:27,  1.53s/it]predicting train subjects:  62%|██████▏   | 282/456 [07:29<04:25,  1.52s/it]predicting train subjects:  62%|██████▏   | 283/456 [07:30<03:56,  1.37s/it]predicting train subjects:  62%|██████▏   | 284/456 [07:32<03:38,  1.27s/it]predicting train subjects:  62%|██████▎   | 285/456 [07:33<03:24,  1.19s/it]predicting train subjects:  63%|██████▎   | 286/456 [07:34<03:20,  1.18s/it]predicting train subjects:  63%|██████▎   | 287/456 [07:35<03:21,  1.19s/it]predicting train subjects:  63%|██████▎   | 288/456 [07:36<03:18,  1.18s/it]predicting train subjects:  63%|██████▎   | 289/456 [07:37<03:13,  1.16s/it]predicting train subjects:  64%|██████▎   | 290/456 [07:38<03:17,  1.19s/it]predicting train subjects:  64%|██████▍   | 291/456 [07:40<03:14,  1.18s/it]predicting train subjects:  64%|██████▍   | 292/456 [07:41<03:10,  1.16s/it]predicting train subjects:  64%|██████▍   | 293/456 [07:42<03:03,  1.12s/it]predicting train subjects:  64%|██████▍   | 294/456 [07:43<03:02,  1.12s/it]predicting train subjects:  65%|██████▍   | 295/456 [07:44<02:58,  1.11s/it]predicting train subjects:  65%|██████▍   | 296/456 [07:45<02:56,  1.11s/it]predicting train subjects:  65%|██████▌   | 297/456 [07:46<02:48,  1.06s/it]predicting train subjects:  65%|██████▌   | 298/456 [07:47<02:46,  1.05s/it]predicting train subjects:  66%|██████▌   | 299/456 [07:48<02:41,  1.03s/it]predicting train subjects:  66%|██████▌   | 300/456 [07:49<02:43,  1.05s/it]predicting train subjects:  66%|██████▌   | 301/456 [07:51<03:16,  1.27s/it]predicting train subjects:  66%|██████▌   | 302/456 [07:53<03:38,  1.42s/it]predicting train subjects:  66%|██████▋   | 303/456 [07:54<03:54,  1.53s/it]predicting train subjects:  67%|██████▋   | 304/456 [07:56<04:06,  1.62s/it]predicting train subjects:  67%|██████▋   | 305/456 [07:58<04:21,  1.73s/it]predicting train subjects:  67%|██████▋   | 306/456 [08:00<04:22,  1.75s/it]predicting train subjects:  67%|██████▋   | 307/456 [08:02<04:40,  1.88s/it]predicting train subjects:  68%|██████▊   | 308/456 [08:04<04:49,  1.95s/it]predicting train subjects:  68%|██████▊   | 309/456 [08:07<05:01,  2.05s/it]predicting train subjects:  68%|██████▊   | 310/456 [08:09<04:57,  2.04s/it]predicting train subjects:  68%|██████▊   | 311/456 [08:11<05:01,  2.08s/it]predicting train subjects:  68%|██████▊   | 312/456 [08:13<05:01,  2.09s/it]predicting train subjects:  69%|██████▊   | 313/456 [08:15<04:57,  2.08s/it]predicting train subjects:  69%|██████▉   | 314/456 [08:17<04:46,  2.02s/it]predicting train subjects:  69%|██████▉   | 315/456 [08:19<04:41,  2.00s/it]predicting train subjects:  69%|██████▉   | 316/456 [08:21<04:40,  2.01s/it]predicting train subjects:  70%|██████▉   | 317/456 [08:23<04:39,  2.01s/it]predicting train subjects:  70%|██████▉   | 318/456 [08:25<04:50,  2.10s/it]predicting train subjects:  70%|██████▉   | 319/456 [08:27<04:34,  2.00s/it]predicting train subjects:  70%|███████   | 320/456 [08:29<04:36,  2.03s/it]predicting train subjects:  70%|███████   | 321/456 [08:31<04:29,  1.99s/it]predicting train subjects:  71%|███████   | 322/456 [08:33<04:26,  1.99s/it]predicting train subjects:  71%|███████   | 323/456 [08:35<04:14,  1.92s/it]predicting train subjects:  71%|███████   | 324/456 [08:36<03:59,  1.81s/it]predicting train subjects:  71%|███████▏  | 325/456 [08:38<03:43,  1.70s/it]predicting train subjects:  71%|███████▏  | 326/456 [08:39<03:32,  1.63s/it]predicting train subjects:  72%|███████▏  | 327/456 [08:41<03:20,  1.56s/it]predicting train subjects:  72%|███████▏  | 328/456 [08:42<03:08,  1.47s/it]predicting train subjects:  72%|███████▏  | 329/456 [08:43<03:04,  1.45s/it]predicting train subjects:  72%|███████▏  | 330/456 [08:45<02:57,  1.41s/it]predicting train subjects:  73%|███████▎  | 331/456 [08:46<03:04,  1.48s/it]predicting train subjects:  73%|███████▎  | 332/456 [08:48<03:07,  1.51s/it]predicting train subjects:  73%|███████▎  | 333/456 [08:49<03:11,  1.56s/it]predicting train subjects:  73%|███████▎  | 334/456 [08:51<03:18,  1.63s/it]predicting train subjects:  73%|███████▎  | 335/456 [08:53<03:15,  1.61s/it]predicting train subjects:  74%|███████▎  | 336/456 [08:55<03:20,  1.67s/it]predicting train subjects:  74%|███████▍  | 337/456 [08:57<03:27,  1.74s/it]predicting train subjects:  74%|███████▍  | 338/456 [08:58<03:20,  1.70s/it]predicting train subjects:  74%|███████▍  | 339/456 [09:00<03:14,  1.67s/it]predicting train subjects:  75%|███████▍  | 340/456 [09:01<03:16,  1.69s/it]predicting train subjects:  75%|███████▍  | 341/456 [09:03<03:10,  1.66s/it]predicting train subjects:  75%|███████▌  | 342/456 [09:05<03:11,  1.68s/it]predicting train subjects:  75%|███████▌  | 343/456 [09:06<03:09,  1.68s/it]predicting train subjects:  75%|███████▌  | 344/456 [09:08<03:08,  1.69s/it]predicting train subjects:  76%|███████▌  | 345/456 [09:10<03:04,  1.66s/it]predicting train subjects:  76%|███████▌  | 346/456 [09:11<03:02,  1.66s/it]predicting train subjects:  76%|███████▌  | 347/456 [09:13<02:53,  1.59s/it]predicting train subjects:  76%|███████▋  | 348/456 [09:14<02:51,  1.59s/it]predicting train subjects:  77%|███████▋  | 349/456 [09:16<02:52,  1.61s/it]predicting train subjects:  77%|███████▋  | 350/456 [09:18<02:59,  1.69s/it]predicting train subjects:  77%|███████▋  | 351/456 [09:20<02:57,  1.69s/it]predicting train subjects:  77%|███████▋  | 352/456 [09:21<02:55,  1.68s/it]predicting train subjects:  77%|███████▋  | 353/456 [09:23<02:51,  1.67s/it]predicting train subjects:  78%|███████▊  | 354/456 [09:25<02:53,  1.70s/it]predicting train subjects:  78%|███████▊  | 355/456 [09:26<02:47,  1.66s/it]predicting train subjects:  78%|███████▊  | 356/456 [09:28<02:42,  1.63s/it]predicting train subjects:  78%|███████▊  | 357/456 [09:29<02:39,  1.61s/it]predicting train subjects:  79%|███████▊  | 358/456 [09:31<02:37,  1.61s/it]predicting train subjects:  79%|███████▊  | 359/456 [09:33<02:32,  1.58s/it]predicting train subjects:  79%|███████▉  | 360/456 [09:34<02:31,  1.58s/it]predicting train subjects:  79%|███████▉  | 361/456 [09:36<02:32,  1.61s/it]predicting train subjects:  79%|███████▉  | 362/456 [09:37<02:28,  1.58s/it]predicting train subjects:  80%|███████▉  | 363/456 [09:39<02:39,  1.71s/it]predicting train subjects:  80%|███████▉  | 364/456 [09:41<02:42,  1.77s/it]predicting train subjects:  80%|████████  | 365/456 [09:43<02:35,  1.71s/it]predicting train subjects:  80%|████████  | 366/456 [09:45<02:38,  1.76s/it]predicting train subjects:  80%|████████  | 367/456 [09:46<02:30,  1.69s/it]predicting train subjects:  81%|████████  | 368/456 [09:48<02:21,  1.61s/it]predicting train subjects:  81%|████████  | 369/456 [09:49<02:13,  1.54s/it]predicting train subjects:  81%|████████  | 370/456 [09:51<02:12,  1.54s/it]predicting train subjects:  81%|████████▏ | 371/456 [09:52<02:11,  1.54s/it]predicting train subjects:  82%|████████▏ | 372/456 [09:53<02:03,  1.47s/it]predicting train subjects:  82%|████████▏ | 373/456 [09:55<02:16,  1.64s/it]predicting train subjects:  82%|████████▏ | 374/456 [09:58<02:33,  1.87s/it]predicting train subjects:  82%|████████▏ | 375/456 [10:00<02:37,  1.94s/it]predicting train subjects:  82%|████████▏ | 376/456 [10:02<02:42,  2.03s/it]predicting train subjects:  83%|████████▎ | 377/456 [10:04<02:44,  2.08s/it]predicting train subjects:  83%|████████▎ | 378/456 [10:06<02:40,  2.05s/it]predicting train subjects:  83%|████████▎ | 379/456 [10:08<02:21,  1.84s/it]predicting train subjects:  83%|████████▎ | 380/456 [10:09<02:09,  1.71s/it]predicting train subjects:  84%|████████▎ | 381/456 [10:10<02:00,  1.60s/it]predicting train subjects:  84%|████████▍ | 382/456 [10:12<01:53,  1.54s/it]predicting train subjects:  84%|████████▍ | 383/456 [10:13<01:53,  1.56s/it]predicting train subjects:  84%|████████▍ | 384/456 [10:15<01:49,  1.52s/it]predicting train subjects:  84%|████████▍ | 385/456 [10:16<01:47,  1.51s/it]predicting train subjects:  85%|████████▍ | 386/456 [10:18<01:46,  1.52s/it]predicting train subjects:  85%|████████▍ | 387/456 [10:19<01:43,  1.49s/it]predicting train subjects:  85%|████████▌ | 388/456 [10:21<01:40,  1.48s/it]predicting train subjects:  85%|████████▌ | 389/456 [10:22<01:37,  1.46s/it]predicting train subjects:  86%|████████▌ | 390/456 [10:24<01:37,  1.48s/it]predicting train subjects:  86%|████████▌ | 391/456 [10:26<01:42,  1.57s/it]predicting train subjects:  86%|████████▌ | 392/456 [10:27<01:40,  1.57s/it]predicting train subjects:  86%|████████▌ | 393/456 [10:29<01:38,  1.56s/it]predicting train subjects:  86%|████████▋ | 394/456 [10:30<01:36,  1.55s/it]predicting train subjects:  87%|████████▋ | 395/456 [10:32<01:36,  1.58s/it]predicting train subjects:  87%|████████▋ | 396/456 [10:33<01:33,  1.56s/it]predicting train subjects:  87%|████████▋ | 397/456 [10:35<01:32,  1.56s/it]predicting train subjects:  87%|████████▋ | 398/456 [10:36<01:29,  1.54s/it]predicting train subjects:  88%|████████▊ | 399/456 [10:38<01:24,  1.49s/it]predicting train subjects:  88%|████████▊ | 400/456 [10:39<01:25,  1.53s/it]predicting train subjects:  88%|████████▊ | 401/456 [10:41<01:23,  1.51s/it]predicting train subjects:  88%|████████▊ | 402/456 [10:42<01:20,  1.50s/it]predicting train subjects:  88%|████████▊ | 403/456 [10:43<01:11,  1.35s/it]predicting train subjects:  89%|████████▊ | 404/456 [10:44<01:07,  1.30s/it]predicting train subjects:  89%|████████▉ | 405/456 [10:46<01:04,  1.26s/it]predicting train subjects:  89%|████████▉ | 406/456 [10:47<01:02,  1.25s/it]predicting train subjects:  89%|████████▉ | 407/456 [10:48<00:58,  1.19s/it]predicting train subjects:  89%|████████▉ | 408/456 [10:49<00:54,  1.14s/it]predicting train subjects:  90%|████████▉ | 409/456 [10:50<00:53,  1.13s/it]predicting train subjects:  90%|████████▉ | 410/456 [10:51<00:53,  1.15s/it]predicting train subjects:  90%|█████████ | 411/456 [10:52<00:50,  1.12s/it]predicting train subjects:  90%|█████████ | 412/456 [10:53<00:47,  1.09s/it]predicting train subjects:  91%|█████████ | 413/456 [10:54<00:46,  1.07s/it]predicting train subjects:  91%|█████████ | 414/456 [10:56<00:46,  1.11s/it]predicting train subjects:  91%|█████████ | 415/456 [10:56<00:43,  1.07s/it]predicting train subjects:  91%|█████████ | 416/456 [10:58<00:42,  1.06s/it]predicting train subjects:  91%|█████████▏| 417/456 [10:59<00:40,  1.04s/it]predicting train subjects:  92%|█████████▏| 418/456 [10:59<00:38,  1.00s/it]predicting train subjects:  92%|█████████▏| 419/456 [11:01<00:38,  1.03s/it]predicting train subjects:  92%|█████████▏| 420/456 [11:02<00:37,  1.05s/it]predicting train subjects:  92%|█████████▏| 421/456 [11:03<00:45,  1.29s/it]predicting train subjects:  93%|█████████▎| 422/456 [11:05<00:50,  1.47s/it]predicting train subjects:  93%|█████████▎| 423/456 [11:07<00:51,  1.57s/it]predicting train subjects:  93%|█████████▎| 424/456 [11:09<00:52,  1.65s/it]predicting train subjects:  93%|█████████▎| 425/456 [11:11<00:51,  1.68s/it]predicting train subjects:  93%|█████████▎| 426/456 [11:13<00:51,  1.73s/it]predicting train subjects:  94%|█████████▎| 427/456 [11:15<00:52,  1.81s/it]predicting train subjects:  94%|█████████▍| 428/456 [11:17<00:52,  1.88s/it]predicting train subjects:  94%|█████████▍| 429/456 [11:19<00:51,  1.92s/it]predicting train subjects:  94%|█████████▍| 430/456 [11:21<00:50,  1.94s/it]predicting train subjects:  95%|█████████▍| 431/456 [11:23<00:50,  2.03s/it]predicting train subjects:  95%|█████████▍| 432/456 [11:25<00:49,  2.08s/it]predicting train subjects:  95%|█████████▍| 433/456 [11:27<00:46,  2.04s/it]predicting train subjects:  95%|█████████▌| 434/456 [11:29<00:43,  2.00s/it]predicting train subjects:  95%|█████████▌| 435/456 [11:31<00:40,  1.94s/it]predicting train subjects:  96%|█████████▌| 436/456 [11:33<00:38,  1.91s/it]predicting train subjects:  96%|█████████▌| 437/456 [11:34<00:35,  1.89s/it]predicting train subjects:  96%|█████████▌| 438/456 [11:36<00:33,  1.88s/it]predicting train subjects:  96%|█████████▋| 439/456 [11:38<00:30,  1.77s/it]predicting train subjects:  96%|█████████▋| 440/456 [11:40<00:28,  1.77s/it]predicting train subjects:  97%|█████████▋| 441/456 [11:41<00:26,  1.73s/it]predicting train subjects:  97%|█████████▋| 442/456 [11:43<00:23,  1.71s/it]predicting train subjects:  97%|█████████▋| 443/456 [11:45<00:22,  1.69s/it]predicting train subjects:  97%|█████████▋| 444/456 [11:46<00:20,  1.68s/it]predicting train subjects:  98%|█████████▊| 445/456 [11:48<00:17,  1.58s/it]predicting train subjects:  98%|█████████▊| 446/456 [11:49<00:15,  1.54s/it]predicting train subjects:  98%|█████████▊| 447/456 [11:50<00:13,  1.49s/it]predicting train subjects:  98%|█████████▊| 448/456 [11:52<00:11,  1.43s/it]predicting train subjects:  98%|█████████▊| 449/456 [11:53<00:10,  1.44s/it]predicting train subjects:  99%|█████████▊| 450/456 [11:54<00:08,  1.42s/it]predicting train subjects:  99%|█████████▉| 451/456 [11:56<00:07,  1.48s/it]predicting train subjects:  99%|█████████▉| 452/456 [11:58<00:06,  1.52s/it]predicting train subjects:  99%|█████████▉| 453/456 [11:59<00:04,  1.59s/it]predicting train subjects: 100%|█████████▉| 454/456 [12:01<00:03,  1.62s/it]predicting train subjects: 100%|█████████▉| 455/456 [12:03<00:01,  1.68s/it]predicting train subjects: 100%|██████████| 456/456 [12:05<00:00,  1.73s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a’: File exists

Loading train:   0%|          | 0/456 [00:00<?, ?it/s]Loading train:   0%|          | 1/456 [00:01<11:34,  1.53s/it]Loading train:   0%|          | 2/456 [00:02<11:06,  1.47s/it]Loading train:   1%|          | 3/456 [00:04<10:43,  1.42s/it]Loading train:   1%|          | 4/456 [00:05<10:04,  1.34s/it]Loading train:   1%|          | 5/456 [00:06<09:47,  1.30s/it]Loading train:   1%|▏         | 6/456 [00:07<09:43,  1.30s/it]Loading train:   2%|▏         | 7/456 [00:09<09:36,  1.28s/it]Loading train:   2%|▏         | 8/456 [00:10<09:07,  1.22s/it]Loading train:   2%|▏         | 9/456 [00:11<09:02,  1.21s/it]Loading train:   2%|▏         | 10/456 [00:12<09:02,  1.22s/it]Loading train:   2%|▏         | 11/456 [00:13<08:28,  1.14s/it]Loading train:   3%|▎         | 12/456 [00:14<07:46,  1.05s/it]Loading train:   3%|▎         | 13/456 [00:15<08:29,  1.15s/it]Loading train:   3%|▎         | 14/456 [00:17<08:41,  1.18s/it]Loading train:   3%|▎         | 15/456 [00:17<08:11,  1.11s/it]Loading train:   4%|▎         | 16/456 [00:19<08:19,  1.14s/it]Loading train:   4%|▎         | 17/456 [00:20<08:49,  1.21s/it]Loading train:   4%|▍         | 18/456 [00:22<09:25,  1.29s/it]Loading train:   4%|▍         | 19/456 [00:23<09:00,  1.24s/it]Loading train:   4%|▍         | 20/456 [00:24<08:57,  1.23s/it]Loading train:   5%|▍         | 21/456 [00:25<08:47,  1.21s/it]Loading train:   5%|▍         | 22/456 [00:26<08:07,  1.12s/it]Loading train:   5%|▌         | 23/456 [00:27<08:10,  1.13s/it]Loading train:   5%|▌         | 24/456 [00:28<07:49,  1.09s/it]Loading train:   5%|▌         | 25/456 [00:29<07:39,  1.07s/it]Loading train:   6%|▌         | 26/456 [00:30<07:22,  1.03s/it]Loading train:   6%|▌         | 27/456 [00:31<07:24,  1.04s/it]Loading train:   6%|▌         | 28/456 [00:32<07:38,  1.07s/it]Loading train:   6%|▋         | 29/456 [00:33<07:05,  1.00it/s]Loading train:   7%|▋         | 30/456 [00:34<07:22,  1.04s/it]Loading train:   7%|▋         | 31/456 [00:35<07:16,  1.03s/it]Loading train:   7%|▋         | 32/456 [00:36<07:09,  1.01s/it]Loading train:   7%|▋         | 33/456 [00:37<07:15,  1.03s/it]Loading train:   7%|▋         | 34/456 [00:38<07:04,  1.01s/it]Loading train:   8%|▊         | 35/456 [00:39<06:59,  1.00it/s]Loading train:   8%|▊         | 36/456 [00:40<06:33,  1.07it/s]Loading train:   8%|▊         | 37/456 [00:41<07:06,  1.02s/it]Loading train:   8%|▊         | 38/456 [00:42<07:06,  1.02s/it]Loading train:   9%|▊         | 39/456 [00:43<07:05,  1.02s/it]Loading train:   9%|▉         | 40/456 [00:44<06:53,  1.01it/s]Loading train:   9%|▉         | 41/456 [00:45<06:59,  1.01s/it]Loading train:   9%|▉         | 42/456 [00:46<06:23,  1.08it/s]Loading train:   9%|▉         | 43/456 [00:47<07:00,  1.02s/it]Loading train:  10%|▉         | 44/456 [00:48<07:23,  1.08s/it]Loading train:  10%|▉         | 45/456 [00:50<07:29,  1.09s/it]Loading train:  10%|█         | 46/456 [00:51<07:32,  1.10s/it]Loading train:  10%|█         | 47/456 [00:52<07:23,  1.08s/it]Loading train:  11%|█         | 48/456 [00:53<06:52,  1.01s/it]Loading train:  11%|█         | 49/456 [00:54<07:22,  1.09s/it]Loading train:  11%|█         | 50/456 [00:55<07:39,  1.13s/it]Loading train:  11%|█         | 51/456 [00:56<07:35,  1.13s/it]Loading train:  11%|█▏        | 52/456 [00:57<07:38,  1.13s/it]Loading train:  12%|█▏        | 53/456 [00:58<07:03,  1.05s/it]Loading train:  12%|█▏        | 54/456 [00:59<06:51,  1.02s/it]Loading train:  12%|█▏        | 55/456 [01:00<07:09,  1.07s/it]Loading train:  12%|█▏        | 56/456 [01:01<07:06,  1.07s/it]Loading train:  12%|█▎        | 57/456 [01:03<07:29,  1.13s/it]Loading train:  13%|█▎        | 58/456 [01:04<07:25,  1.12s/it]Loading train:  13%|█▎        | 59/456 [01:05<07:00,  1.06s/it]Loading train:  13%|█▎        | 60/456 [01:06<06:44,  1.02s/it]Loading train:  13%|█▎        | 61/456 [01:07<07:21,  1.12s/it]Loading train:  14%|█▎        | 62/456 [01:08<07:07,  1.09s/it]Loading train:  14%|█▍        | 63/456 [01:09<07:44,  1.18s/it]Loading train:  14%|█▍        | 64/456 [01:10<07:25,  1.14s/it]Loading train:  14%|█▍        | 65/456 [01:11<06:49,  1.05s/it]Loading train:  14%|█▍        | 66/456 [01:12<06:56,  1.07s/it]Loading train:  15%|█▍        | 67/456 [01:14<07:13,  1.11s/it]Loading train:  15%|█▍        | 68/456 [01:15<07:13,  1.12s/it]Loading train:  15%|█▌        | 69/456 [01:16<06:54,  1.07s/it]Loading train:  15%|█▌        | 70/456 [01:16<06:28,  1.01s/it]Loading train:  16%|█▌        | 71/456 [01:17<06:21,  1.01it/s]Loading train:  16%|█▌        | 72/456 [01:19<06:34,  1.03s/it]Loading train:  16%|█▌        | 73/456 [01:20<06:45,  1.06s/it]Loading train:  16%|█▌        | 74/456 [01:21<06:44,  1.06s/it]Loading train:  16%|█▋        | 75/456 [01:22<06:40,  1.05s/it]Loading train:  17%|█▋        | 76/456 [01:23<06:23,  1.01s/it]Loading train:  17%|█▋        | 77/456 [01:24<06:36,  1.05s/it]Loading train:  17%|█▋        | 78/456 [01:25<06:55,  1.10s/it]Loading train:  17%|█▋        | 79/456 [01:26<06:34,  1.05s/it]Loading train:  18%|█▊        | 80/456 [01:27<06:24,  1.02s/it]Loading train:  18%|█▊        | 81/456 [01:28<05:56,  1.05it/s]Loading train:  18%|█▊        | 82/456 [01:28<05:11,  1.20it/s]Loading train:  18%|█▊        | 83/456 [01:29<04:44,  1.31it/s]Loading train:  18%|█▊        | 84/456 [01:30<04:45,  1.30it/s]Loading train:  19%|█▊        | 85/456 [01:31<04:58,  1.24it/s]Loading train:  19%|█▉        | 86/456 [01:31<04:53,  1.26it/s]Loading train:  19%|█▉        | 87/456 [01:32<05:01,  1.22it/s]Loading train:  19%|█▉        | 88/456 [01:33<04:39,  1.32it/s]Loading train:  20%|█▉        | 89/456 [01:34<04:33,  1.34it/s]Loading train:  20%|█▉        | 90/456 [01:34<04:40,  1.31it/s]Loading train:  20%|█▉        | 91/456 [01:35<04:31,  1.35it/s]Loading train:  20%|██        | 92/456 [01:36<04:38,  1.31it/s]Loading train:  20%|██        | 93/456 [01:37<04:35,  1.32it/s]Loading train:  21%|██        | 94/456 [01:37<04:42,  1.28it/s]Loading train:  21%|██        | 95/456 [01:38<04:49,  1.25it/s]Loading train:  21%|██        | 96/456 [01:39<04:50,  1.24it/s]Loading train:  21%|██▏       | 97/456 [01:40<05:23,  1.11it/s]Loading train:  21%|██▏       | 98/456 [01:41<05:35,  1.07it/s]Loading train:  22%|██▏       | 99/456 [01:42<05:39,  1.05it/s]Loading train:  22%|██▏       | 100/456 [01:43<06:07,  1.03s/it]Loading train:  22%|██▏       | 101/456 [01:44<06:08,  1.04s/it]Loading train:  22%|██▏       | 102/456 [01:46<06:30,  1.10s/it]Loading train:  23%|██▎       | 103/456 [01:47<06:23,  1.09s/it]Loading train:  23%|██▎       | 104/456 [01:48<06:13,  1.06s/it]Loading train:  23%|██▎       | 105/456 [01:49<05:45,  1.01it/s]Loading train:  23%|██▎       | 106/456 [01:50<05:40,  1.03it/s]Loading train:  23%|██▎       | 107/456 [01:51<05:43,  1.02it/s]Loading train:  24%|██▎       | 108/456 [01:52<05:59,  1.03s/it]Loading train:  24%|██▍       | 109/456 [01:53<06:10,  1.07s/it]Loading train:  24%|██▍       | 110/456 [01:54<05:56,  1.03s/it]Loading train:  24%|██▍       | 111/456 [01:55<05:42,  1.01it/s]Loading train:  25%|██▍       | 112/456 [01:56<06:10,  1.08s/it]Loading train:  25%|██▍       | 113/456 [01:57<06:10,  1.08s/it]Loading train:  25%|██▌       | 114/456 [01:58<06:03,  1.06s/it]Loading train:  25%|██▌       | 115/456 [01:59<06:19,  1.11s/it]Loading train:  25%|██▌       | 116/456 [02:00<06:20,  1.12s/it]Loading train:  26%|██▌       | 117/456 [02:01<05:59,  1.06s/it]Loading train:  26%|██▌       | 118/456 [02:02<05:56,  1.06s/it]Loading train:  26%|██▌       | 119/456 [02:04<06:03,  1.08s/it]Loading train:  26%|██▋       | 120/456 [02:05<06:04,  1.08s/it]Loading train:  27%|██▋       | 121/456 [02:06<06:24,  1.15s/it]Loading train:  27%|██▋       | 122/456 [02:07<06:21,  1.14s/it]Loading train:  27%|██▋       | 123/456 [02:08<05:46,  1.04s/it]Loading train:  27%|██▋       | 124/456 [02:09<05:40,  1.03s/it]Loading train:  27%|██▋       | 125/456 [02:10<05:50,  1.06s/it]Loading train:  28%|██▊       | 126/456 [02:11<06:14,  1.13s/it]Loading train:  28%|██▊       | 127/456 [02:12<05:50,  1.06s/it]Loading train:  28%|██▊       | 128/456 [02:13<05:36,  1.03s/it]Loading train:  28%|██▊       | 129/456 [02:14<05:33,  1.02s/it]Loading train:  29%|██▊       | 130/456 [02:15<05:03,  1.07it/s]Loading train:  29%|██▊       | 131/456 [02:16<04:43,  1.15it/s]Loading train:  29%|██▉       | 132/456 [02:17<04:47,  1.13it/s]Loading train:  29%|██▉       | 133/456 [02:18<05:27,  1.01s/it]Loading train:  29%|██▉       | 134/456 [02:19<05:54,  1.10s/it]Loading train:  30%|██▉       | 135/456 [02:20<06:10,  1.15s/it]Loading train:  30%|██▉       | 136/456 [02:21<05:58,  1.12s/it]Loading train:  30%|███       | 137/456 [02:23<06:21,  1.20s/it]Loading train:  30%|███       | 138/456 [02:24<06:27,  1.22s/it]Loading train:  30%|███       | 139/456 [02:25<06:13,  1.18s/it]Loading train:  31%|███       | 140/456 [02:26<05:25,  1.03s/it]Loading train:  31%|███       | 141/456 [02:27<04:55,  1.07it/s]Loading train:  31%|███       | 142/456 [02:27<04:42,  1.11it/s]Loading train:  31%|███▏      | 143/456 [02:28<04:41,  1.11it/s]Loading train:  32%|███▏      | 144/456 [02:29<04:28,  1.16it/s]Loading train:  32%|███▏      | 145/456 [02:30<04:32,  1.14it/s]Loading train:  32%|███▏      | 146/456 [02:31<04:37,  1.12it/s]Loading train:  32%|███▏      | 147/456 [02:32<04:37,  1.11it/s]Loading train:  32%|███▏      | 148/456 [02:33<04:45,  1.08it/s]Loading train:  33%|███▎      | 149/456 [02:34<04:48,  1.06it/s]Loading train:  33%|███▎      | 150/456 [02:35<04:39,  1.09it/s]Loading train:  33%|███▎      | 151/456 [02:36<04:41,  1.08it/s]Loading train:  33%|███▎      | 152/456 [02:36<04:19,  1.17it/s]Loading train:  34%|███▎      | 153/456 [02:37<04:12,  1.20it/s]Loading train:  34%|███▍      | 154/456 [02:38<04:08,  1.21it/s]Loading train:  34%|███▍      | 155/456 [02:39<04:19,  1.16it/s]Loading train:  34%|███▍      | 156/456 [02:40<04:18,  1.16it/s]Loading train:  34%|███▍      | 157/456 [02:41<04:17,  1.16it/s]Loading train:  35%|███▍      | 158/456 [02:41<04:01,  1.23it/s]Loading train:  35%|███▍      | 159/456 [02:42<03:59,  1.24it/s]Loading train:  35%|███▌      | 160/456 [02:43<04:09,  1.19it/s]Loading train:  35%|███▌      | 161/456 [02:44<04:08,  1.19it/s]Loading train:  36%|███▌      | 162/456 [02:45<04:12,  1.17it/s]Loading train:  36%|███▌      | 163/456 [02:45<03:57,  1.23it/s]Loading train:  36%|███▌      | 164/456 [02:46<03:45,  1.29it/s]Loading train:  36%|███▌      | 165/456 [02:47<03:34,  1.35it/s]Loading train:  36%|███▋      | 166/456 [02:47<03:28,  1.39it/s]Loading train:  37%|███▋      | 167/456 [02:48<03:35,  1.34it/s]Loading train:  37%|███▋      | 168/456 [02:49<03:41,  1.30it/s]Loading train:  37%|███▋      | 169/456 [02:50<03:35,  1.33it/s]Loading train:  37%|███▋      | 170/456 [02:50<03:27,  1.38it/s]Loading train:  38%|███▊      | 171/456 [02:51<03:17,  1.44it/s]Loading train:  38%|███▊      | 172/456 [02:52<03:22,  1.40it/s]Loading train:  38%|███▊      | 173/456 [02:52<03:14,  1.45it/s]Loading train:  38%|███▊      | 174/456 [02:53<03:24,  1.38it/s]Loading train:  38%|███▊      | 175/456 [02:54<03:36,  1.30it/s]Loading train:  39%|███▊      | 176/456 [02:55<03:35,  1.30it/s]Loading train:  39%|███▉      | 177/456 [02:56<03:23,  1.37it/s]Loading train:  39%|███▉      | 178/456 [02:56<03:24,  1.36it/s]Loading train:  39%|███▉      | 179/456 [02:57<03:18,  1.39it/s]Loading train:  39%|███▉      | 180/456 [02:58<03:12,  1.43it/s]Loading train:  40%|███▉      | 181/456 [02:59<03:34,  1.28it/s]Loading train:  40%|███▉      | 182/456 [03:00<03:51,  1.19it/s]Loading train:  40%|████      | 183/456 [03:01<04:14,  1.07it/s]Loading train:  40%|████      | 184/456 [03:02<04:30,  1.01it/s]Loading train:  41%|████      | 185/456 [03:03<04:40,  1.04s/it]Loading train:  41%|████      | 186/456 [03:04<04:43,  1.05s/it]Loading train:  41%|████      | 187/456 [03:05<05:06,  1.14s/it]Loading train:  41%|████      | 188/456 [03:06<05:02,  1.13s/it]Loading train:  41%|████▏     | 189/456 [03:08<04:54,  1.10s/it]Loading train:  42%|████▏     | 190/456 [03:08<04:40,  1.06s/it]Loading train:  42%|████▏     | 191/456 [03:10<04:40,  1.06s/it]Loading train:  42%|████▏     | 192/456 [03:11<04:48,  1.09s/it]Loading train:  42%|████▏     | 193/456 [03:12<04:47,  1.09s/it]Loading train:  43%|████▎     | 194/456 [03:13<04:39,  1.07s/it]Loading train:  43%|████▎     | 195/456 [03:14<04:43,  1.09s/it]Loading train:  43%|████▎     | 196/456 [03:15<04:33,  1.05s/it]Loading train:  43%|████▎     | 197/456 [03:16<04:23,  1.02s/it]Loading train:  43%|████▎     | 198/456 [03:17<04:25,  1.03s/it]Loading train:  44%|████▎     | 199/456 [03:18<04:16,  1.00it/s]Loading train:  44%|████▍     | 200/456 [03:19<04:05,  1.04it/s]Loading train:  44%|████▍     | 201/456 [03:19<03:50,  1.11it/s]Loading train:  44%|████▍     | 202/456 [03:20<03:42,  1.14it/s]Loading train:  45%|████▍     | 203/456 [03:21<03:34,  1.18it/s]Loading train:  45%|████▍     | 204/456 [03:22<03:36,  1.16it/s]Loading train:  45%|████▍     | 205/456 [03:23<03:47,  1.10it/s]Loading train:  45%|████▌     | 206/456 [03:24<03:35,  1.16it/s]Loading train:  45%|████▌     | 207/456 [03:25<03:35,  1.16it/s]Loading train:  46%|████▌     | 208/456 [03:25<03:30,  1.18it/s]Loading train:  46%|████▌     | 209/456 [03:26<03:16,  1.26it/s]Loading train:  46%|████▌     | 210/456 [03:27<03:29,  1.17it/s]Loading train:  46%|████▋     | 211/456 [03:28<03:35,  1.14it/s]Loading train:  46%|████▋     | 212/456 [03:29<03:46,  1.08it/s]Loading train:  47%|████▋     | 213/456 [03:30<03:59,  1.02it/s]Loading train:  47%|████▋     | 214/456 [03:31<03:48,  1.06it/s]Loading train:  47%|████▋     | 215/456 [03:32<03:49,  1.05it/s]Loading train:  47%|████▋     | 216/456 [03:33<03:44,  1.07it/s]Loading train:  48%|████▊     | 217/456 [03:34<03:55,  1.01it/s]Loading train:  48%|████▊     | 218/456 [03:35<03:50,  1.03it/s]Loading train:  48%|████▊     | 219/456 [03:36<03:50,  1.03it/s]Loading train:  48%|████▊     | 220/456 [03:37<03:57,  1.01s/it]Loading train:  48%|████▊     | 221/456 [03:38<03:58,  1.02s/it]Loading train:  49%|████▊     | 222/456 [03:39<04:01,  1.03s/it]Loading train:  49%|████▉     | 223/456 [03:40<04:03,  1.04s/it]Loading train:  49%|████▉     | 224/456 [03:41<04:01,  1.04s/it]Loading train:  49%|████▉     | 225/456 [03:42<03:43,  1.03it/s]Loading train:  50%|████▉     | 226/456 [03:43<03:32,  1.08it/s]Loading train:  50%|████▉     | 227/456 [03:44<03:23,  1.12it/s]Loading train:  50%|█████     | 228/456 [03:44<03:19,  1.14it/s]Loading train:  50%|█████     | 229/456 [03:45<03:24,  1.11it/s]Loading train:  50%|█████     | 230/456 [03:46<03:23,  1.11it/s]Loading train:  51%|█████     | 231/456 [03:47<03:28,  1.08it/s]Loading train:  51%|█████     | 232/456 [03:48<03:35,  1.04it/s]Loading train:  51%|█████     | 233/456 [03:49<03:35,  1.04it/s]Loading train:  51%|█████▏    | 234/456 [03:50<03:32,  1.05it/s]Loading train:  52%|█████▏    | 235/456 [03:51<03:41,  1.00s/it]Loading train:  52%|█████▏    | 236/456 [03:52<03:33,  1.03it/s]Loading train:  52%|█████▏    | 237/456 [03:53<03:25,  1.07it/s]Loading train:  52%|█████▏    | 238/456 [03:54<03:18,  1.10it/s]Loading train:  52%|█████▏    | 239/456 [03:55<03:14,  1.12it/s]Loading train:  53%|█████▎    | 240/456 [03:56<03:15,  1.11it/s]Loading train:  53%|█████▎    | 241/456 [03:57<03:27,  1.04it/s]Loading train:  53%|█████▎    | 242/456 [03:58<03:32,  1.01it/s]Loading train:  53%|█████▎    | 243/456 [03:59<03:25,  1.04it/s]Loading train:  54%|█████▎    | 244/456 [04:00<03:20,  1.06it/s]Loading train:  54%|█████▎    | 245/456 [04:01<03:14,  1.09it/s]Loading train:  54%|█████▍    | 246/456 [04:01<03:05,  1.13it/s]Loading train:  54%|█████▍    | 247/456 [04:02<03:00,  1.16it/s]Loading train:  54%|█████▍    | 248/456 [04:03<02:59,  1.16it/s]Loading train:  55%|█████▍    | 249/456 [04:04<02:58,  1.16it/s]Loading train:  55%|█████▍    | 250/456 [04:05<02:50,  1.21it/s]Loading train:  55%|█████▌    | 251/456 [04:05<02:42,  1.26it/s]Loading train:  55%|█████▌    | 252/456 [04:06<02:34,  1.32it/s]Loading train:  55%|█████▌    | 253/456 [04:07<03:03,  1.11it/s]Loading train:  56%|█████▌    | 254/456 [04:08<03:17,  1.02it/s]Loading train:  56%|█████▌    | 255/456 [04:10<03:43,  1.11s/it]Loading train:  56%|█████▌    | 256/456 [04:11<03:46,  1.13s/it]Loading train:  56%|█████▋    | 257/456 [04:12<03:55,  1.18s/it]Loading train:  57%|█████▋    | 258/456 [04:14<03:52,  1.17s/it]Loading train:  57%|█████▋    | 259/456 [04:14<03:25,  1.04s/it]Loading train:  57%|█████▋    | 260/456 [04:15<03:10,  1.03it/s]Loading train:  57%|█████▋    | 261/456 [04:16<03:00,  1.08it/s]Loading train:  57%|█████▋    | 262/456 [04:17<02:54,  1.11it/s]Loading train:  58%|█████▊    | 263/456 [04:17<02:45,  1.16it/s]Loading train:  58%|█████▊    | 264/456 [04:18<02:41,  1.19it/s]Loading train:  58%|█████▊    | 265/456 [04:19<02:40,  1.19it/s]Loading train:  58%|█████▊    | 266/456 [04:20<02:37,  1.21it/s]Loading train:  59%|█████▊    | 267/456 [04:21<02:39,  1.19it/s]Loading train:  59%|█████▉    | 268/456 [04:22<02:36,  1.20it/s]Loading train:  59%|█████▉    | 269/456 [04:22<02:31,  1.23it/s]Loading train:  59%|█████▉    | 270/456 [04:23<02:29,  1.25it/s]Loading train:  59%|█████▉    | 271/456 [04:24<02:35,  1.19it/s]Loading train:  60%|█████▉    | 272/456 [04:25<02:41,  1.14it/s]Loading train:  60%|█████▉    | 273/456 [04:26<02:35,  1.17it/s]Loading train:  60%|██████    | 274/456 [04:27<02:30,  1.21it/s]Loading train:  60%|██████    | 275/456 [04:27<02:31,  1.19it/s]Loading train:  61%|██████    | 276/456 [04:28<02:26,  1.23it/s]Loading train:  61%|██████    | 277/456 [04:29<02:37,  1.14it/s]Loading train:  61%|██████    | 278/456 [04:30<02:35,  1.14it/s]Loading train:  61%|██████    | 279/456 [04:31<02:28,  1.19it/s]Loading train:  61%|██████▏   | 280/456 [04:32<02:27,  1.19it/s]Loading train:  62%|██████▏   | 281/456 [04:33<02:29,  1.17it/s]Loading train:  62%|██████▏   | 282/456 [04:34<02:36,  1.11it/s]Loading train:  62%|██████▏   | 283/456 [04:35<02:36,  1.10it/s]Loading train:  62%|██████▏   | 284/456 [04:35<02:31,  1.14it/s]Loading train:  62%|██████▎   | 285/456 [04:36<02:25,  1.18it/s]Loading train:  63%|██████▎   | 286/456 [04:37<02:28,  1.14it/s]Loading train:  63%|██████▎   | 287/456 [04:38<02:15,  1.25it/s]Loading train:  63%|██████▎   | 288/456 [04:38<02:04,  1.34it/s]Loading train:  63%|██████▎   | 289/456 [04:39<02:03,  1.35it/s]Loading train:  64%|██████▎   | 290/456 [04:40<02:07,  1.30it/s]Loading train:  64%|██████▍   | 291/456 [04:41<02:07,  1.30it/s]Loading train:  64%|██████▍   | 292/456 [04:41<01:59,  1.37it/s]Loading train:  64%|██████▍   | 293/456 [04:42<01:56,  1.40it/s]Loading train:  64%|██████▍   | 294/456 [04:43<01:59,  1.36it/s]Loading train:  65%|██████▍   | 295/456 [04:43<01:59,  1.34it/s]Loading train:  65%|██████▍   | 296/456 [04:44<02:01,  1.31it/s]Loading train:  65%|██████▌   | 297/456 [04:45<02:03,  1.29it/s]Loading train:  65%|██████▌   | 298/456 [04:46<01:57,  1.35it/s]Loading train:  66%|██████▌   | 299/456 [04:46<01:55,  1.36it/s]Loading train:  66%|██████▌   | 300/456 [04:47<02:06,  1.24it/s]Loading train:  66%|██████▌   | 301/456 [04:48<02:11,  1.18it/s]Loading train:  66%|██████▌   | 302/456 [04:49<02:12,  1.16it/s]Loading train:  66%|██████▋   | 303/456 [04:50<02:26,  1.04it/s]Loading train:  67%|██████▋   | 304/456 [04:52<02:41,  1.06s/it]Loading train:  67%|██████▋   | 305/456 [04:53<02:39,  1.05s/it]Loading train:  67%|██████▋   | 306/456 [04:54<02:44,  1.10s/it]Loading train:  67%|██████▋   | 307/456 [04:55<02:51,  1.15s/it]Loading train:  68%|██████▊   | 308/456 [04:56<02:52,  1.16s/it]Loading train:  68%|██████▊   | 309/456 [04:58<02:47,  1.14s/it]Loading train:  68%|██████▊   | 310/456 [04:59<02:40,  1.10s/it]Loading train:  68%|██████▊   | 311/456 [05:00<02:38,  1.09s/it]Loading train:  68%|██████▊   | 312/456 [05:01<02:38,  1.10s/it]Loading train:  69%|██████▊   | 313/456 [05:02<02:35,  1.09s/it]Loading train:  69%|██████▉   | 314/456 [05:03<02:32,  1.08s/it]Loading train:  69%|██████▉   | 315/456 [05:04<02:28,  1.05s/it]Loading train:  69%|██████▉   | 316/456 [05:05<02:21,  1.01s/it]Loading train:  70%|██████▉   | 317/456 [05:06<02:18,  1.00it/s]Loading train:  70%|██████▉   | 318/456 [05:07<02:19,  1.01s/it]Loading train:  70%|██████▉   | 319/456 [05:08<02:11,  1.04it/s]Loading train:  70%|███████   | 320/456 [05:08<02:02,  1.11it/s]Loading train:  70%|███████   | 321/456 [05:09<01:57,  1.15it/s]Loading train:  71%|███████   | 322/456 [05:10<01:50,  1.21it/s]Loading train:  71%|███████   | 323/456 [05:11<01:47,  1.24it/s]Loading train:  71%|███████   | 324/456 [05:12<01:51,  1.19it/s]Loading train:  71%|███████▏  | 325/456 [05:12<01:50,  1.18it/s]Loading train:  71%|███████▏  | 326/456 [05:13<01:43,  1.26it/s]Loading train:  72%|███████▏  | 327/456 [05:14<01:41,  1.28it/s]Loading train:  72%|███████▏  | 328/456 [05:15<01:41,  1.26it/s]Loading train:  72%|███████▏  | 329/456 [05:15<01:38,  1.28it/s]Loading train:  72%|███████▏  | 330/456 [05:16<01:39,  1.27it/s]Loading train:  73%|███████▎  | 331/456 [05:17<01:49,  1.14it/s]Loading train:  73%|███████▎  | 332/456 [05:18<01:54,  1.08it/s]Loading train:  73%|███████▎  | 333/456 [05:19<01:52,  1.09it/s]Loading train:  73%|███████▎  | 334/456 [05:20<01:54,  1.07it/s]Loading train:  73%|███████▎  | 335/456 [05:21<01:51,  1.09it/s]Loading train:  74%|███████▎  | 336/456 [05:22<01:49,  1.10it/s]Loading train:  74%|███████▍  | 337/456 [05:23<01:53,  1.05it/s]Loading train:  74%|███████▍  | 338/456 [05:24<01:51,  1.06it/s]Loading train:  74%|███████▍  | 339/456 [05:25<01:51,  1.05it/s]Loading train:  75%|███████▍  | 340/456 [05:26<01:45,  1.10it/s]Loading train:  75%|███████▍  | 341/456 [05:27<01:53,  1.02it/s]Loading train:  75%|███████▌  | 342/456 [05:28<01:52,  1.01it/s]Loading train:  75%|███████▌  | 343/456 [05:29<01:51,  1.02it/s]Loading train:  75%|███████▌  | 344/456 [05:30<01:57,  1.05s/it]Loading train:  76%|███████▌  | 345/456 [05:31<01:54,  1.04s/it]Loading train:  76%|███████▌  | 346/456 [05:32<01:45,  1.04it/s]Loading train:  76%|███████▌  | 347/456 [05:33<01:44,  1.05it/s]Loading train:  76%|███████▋  | 348/456 [05:34<01:54,  1.06s/it]Loading train:  77%|███████▋  | 349/456 [05:35<01:55,  1.08s/it]Loading train:  77%|███████▋  | 350/456 [05:36<01:49,  1.03s/it]Loading train:  77%|███████▋  | 351/456 [05:37<01:50,  1.06s/it]Loading train:  77%|███████▋  | 352/456 [05:38<01:43,  1.01it/s]Loading train:  77%|███████▋  | 353/456 [05:39<01:39,  1.04it/s]Loading train:  78%|███████▊  | 354/456 [05:40<01:45,  1.04s/it]Loading train:  78%|███████▊  | 355/456 [05:41<01:45,  1.05s/it]Loading train:  78%|███████▊  | 356/456 [05:43<01:50,  1.11s/it]Loading train:  78%|███████▊  | 357/456 [05:44<01:46,  1.08s/it]Loading train:  79%|███████▊  | 358/456 [05:44<01:36,  1.02it/s]Loading train:  79%|███████▊  | 359/456 [05:45<01:39,  1.03s/it]Loading train:  79%|███████▉  | 360/456 [05:47<01:39,  1.03s/it]Loading train:  79%|███████▉  | 361/456 [05:48<01:44,  1.10s/it]Loading train:  79%|███████▉  | 362/456 [05:49<01:43,  1.10s/it]Loading train:  80%|███████▉  | 363/456 [05:50<01:35,  1.03s/it]Loading train:  80%|███████▉  | 364/456 [05:51<01:29,  1.03it/s]Loading train:  80%|████████  | 365/456 [05:52<01:32,  1.01s/it]Loading train:  80%|████████  | 366/456 [05:53<01:35,  1.06s/it]Loading train:  80%|████████  | 367/456 [05:54<01:34,  1.06s/it]Loading train:  81%|████████  | 368/456 [05:55<01:28,  1.00s/it]Loading train:  81%|████████  | 369/456 [05:56<01:20,  1.08it/s]Loading train:  81%|████████  | 370/456 [05:56<01:18,  1.10it/s]Loading train:  81%|████████▏ | 371/456 [05:57<01:20,  1.05it/s]Loading train:  82%|████████▏ | 372/456 [05:58<01:19,  1.05it/s]Loading train:  82%|████████▏ | 373/456 [06:00<01:30,  1.09s/it]Loading train:  82%|████████▏ | 374/456 [06:01<01:35,  1.17s/it]Loading train:  82%|████████▏ | 375/456 [06:02<01:33,  1.15s/it]Loading train:  82%|████████▏ | 376/456 [06:04<01:35,  1.20s/it]Loading train:  83%|████████▎ | 377/456 [06:05<01:41,  1.29s/it]Loading train:  83%|████████▎ | 378/456 [06:06<01:43,  1.32s/it]Loading train:  83%|████████▎ | 379/456 [06:07<01:27,  1.14s/it]Loading train:  83%|████████▎ | 380/456 [06:08<01:19,  1.05s/it]Loading train:  84%|████████▎ | 381/456 [06:09<01:19,  1.06s/it]Loading train:  84%|████████▍ | 382/456 [06:10<01:16,  1.04s/it]Loading train:  84%|████████▍ | 383/456 [06:11<01:19,  1.08s/it]Loading train:  84%|████████▍ | 384/456 [06:12<01:14,  1.04s/it]Loading train:  84%|████████▍ | 385/456 [06:13<01:07,  1.06it/s]Loading train:  85%|████████▍ | 386/456 [06:14<01:02,  1.12it/s]Loading train:  85%|████████▍ | 387/456 [06:15<01:03,  1.08it/s]Loading train:  85%|████████▌ | 388/456 [06:16<01:04,  1.06it/s]Loading train:  85%|████████▌ | 389/456 [06:17<01:04,  1.05it/s]Loading train:  86%|████████▌ | 390/456 [06:18<01:05,  1.00it/s]Loading train:  86%|████████▌ | 391/456 [06:19<01:01,  1.06it/s]Loading train:  86%|████████▌ | 392/456 [06:20<01:01,  1.04it/s]Loading train:  86%|████████▌ | 393/456 [06:21<01:02,  1.01it/s]Loading train:  86%|████████▋ | 394/456 [06:22<01:02,  1.01s/it]Loading train:  87%|████████▋ | 395/456 [06:23<01:02,  1.02s/it]Loading train:  87%|████████▋ | 396/456 [06:24<00:59,  1.01it/s]Loading train:  87%|████████▋ | 397/456 [06:24<00:53,  1.10it/s]Loading train:  87%|████████▋ | 398/456 [06:25<00:52,  1.09it/s]Loading train:  88%|████████▊ | 399/456 [06:26<00:52,  1.08it/s]Loading train:  88%|████████▊ | 400/456 [06:27<00:52,  1.07it/s]Loading train:  88%|████████▊ | 401/456 [06:28<00:49,  1.11it/s]Loading train:  88%|████████▊ | 402/456 [06:29<00:49,  1.09it/s]Loading train:  88%|████████▊ | 403/456 [06:30<00:46,  1.15it/s]Loading train:  89%|████████▊ | 404/456 [06:31<00:44,  1.16it/s]Loading train:  89%|████████▉ | 405/456 [06:32<00:43,  1.16it/s]Loading train:  89%|████████▉ | 406/456 [06:32<00:42,  1.16it/s]Loading train:  89%|████████▉ | 407/456 [06:33<00:41,  1.19it/s]Loading train:  89%|████████▉ | 408/456 [06:34<00:43,  1.11it/s]Loading train:  90%|████████▉ | 409/456 [06:35<00:38,  1.22it/s]Loading train:  90%|████████▉ | 410/456 [06:35<00:34,  1.34it/s]Loading train:  90%|█████████ | 411/456 [06:36<00:34,  1.31it/s]Loading train:  90%|█████████ | 412/456 [06:37<00:35,  1.23it/s]Loading train:  91%|█████████ | 413/456 [06:38<00:34,  1.24it/s]Loading train:  91%|█████████ | 414/456 [06:39<00:37,  1.13it/s]Loading train:  91%|█████████ | 415/456 [06:40<00:35,  1.16it/s]Loading train:  91%|█████████ | 416/456 [06:40<00:32,  1.24it/s]Loading train:  91%|█████████▏| 417/456 [06:41<00:31,  1.22it/s]Loading train:  92%|█████████▏| 418/456 [06:42<00:32,  1.15it/s]Loading train:  92%|█████████▏| 419/456 [06:43<00:31,  1.18it/s]Loading train:  92%|█████████▏| 420/456 [06:44<00:29,  1.21it/s]Loading train:  92%|█████████▏| 421/456 [06:45<00:34,  1.00it/s]Loading train:  93%|█████████▎| 422/456 [06:46<00:32,  1.03it/s]Loading train:  93%|█████████▎| 423/456 [06:47<00:34,  1.04s/it]Loading train:  93%|█████████▎| 424/456 [06:49<00:35,  1.12s/it]Loading train:  93%|█████████▎| 425/456 [06:50<00:35,  1.16s/it]Loading train:  93%|█████████▎| 426/456 [06:51<00:33,  1.12s/it]Loading train:  94%|█████████▎| 427/456 [06:52<00:31,  1.10s/it]Loading train:  94%|█████████▍| 428/456 [06:53<00:31,  1.14s/it]Loading train:  94%|█████████▍| 429/456 [06:55<00:32,  1.20s/it]Loading train:  94%|█████████▍| 430/456 [06:56<00:32,  1.25s/it]Loading train:  95%|█████████▍| 431/456 [06:57<00:28,  1.16s/it]Loading train:  95%|█████████▍| 432/456 [06:58<00:30,  1.25s/it]Loading train:  95%|█████████▍| 433/456 [07:00<00:30,  1.31s/it]Loading train:  95%|█████████▌| 434/456 [07:01<00:27,  1.25s/it]Loading train:  95%|█████████▌| 435/456 [07:02<00:25,  1.22s/it]Loading train:  96%|█████████▌| 436/456 [07:03<00:22,  1.14s/it]Loading train:  96%|█████████▌| 437/456 [07:04<00:22,  1.18s/it]Loading train:  96%|█████████▌| 438/456 [07:06<00:21,  1.18s/it]Loading train:  96%|█████████▋| 439/456 [07:07<00:19,  1.17s/it]Loading train:  96%|█████████▋| 440/456 [07:08<00:17,  1.11s/it]Loading train:  97%|█████████▋| 441/456 [07:08<00:15,  1.02s/it]Loading train:  97%|█████████▋| 442/456 [07:10<00:15,  1.09s/it]Loading train:  97%|█████████▋| 443/456 [07:11<00:13,  1.06s/it]Loading train:  97%|█████████▋| 444/456 [07:12<00:12,  1.03s/it]Loading train:  98%|█████████▊| 445/456 [07:13<00:11,  1.04s/it]Loading train:  98%|█████████▊| 446/456 [07:14<00:09,  1.01it/s]Loading train:  98%|█████████▊| 447/456 [07:14<00:08,  1.10it/s]Loading train:  98%|█████████▊| 448/456 [07:15<00:07,  1.12it/s]Loading train:  98%|█████████▊| 449/456 [07:16<00:06,  1.04it/s]Loading train:  99%|█████████▊| 450/456 [07:17<00:05,  1.03it/s]Loading train:  99%|█████████▉| 451/456 [07:18<00:04,  1.02it/s]Loading train:  99%|█████████▉| 452/456 [07:19<00:03,  1.00it/s]Loading train:  99%|█████████▉| 453/456 [07:20<00:02,  1.03it/s]Loading train: 100%|█████████▉| 454/456 [07:21<00:01,  1.08it/s]Loading train: 100%|█████████▉| 455/456 [07:22<00:00,  1.01it/s]Loading train: 100%|██████████| 456/456 [07:23<00:00,  1.02s/it]
concatenating: train:   0%|          | 0/456 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 9/456 [00:00<00:05, 86.41it/s]concatenating: train:   4%|▍         | 18/456 [00:00<00:05, 79.17it/s]concatenating: train:   5%|▍         | 22/456 [00:00<00:07, 59.16it/s]concatenating: train:   9%|▊         | 39/456 [00:00<00:05, 73.39it/s]concatenating: train:  14%|█▍        | 65/456 [00:00<00:04, 93.35it/s]concatenating: train:  20%|██        | 92/456 [00:00<00:03, 115.69it/s]concatenating: train:  24%|██▍       | 109/456 [00:00<00:04, 83.72it/s]concatenating: train:  28%|██▊       | 127/456 [00:01<00:03, 99.45it/s]concatenating: train:  34%|███▍      | 155/456 [00:01<00:02, 122.73it/s]concatenating: train:  40%|████      | 183/456 [00:01<00:01, 147.50it/s]concatenating: train:  46%|████▌     | 210/456 [00:01<00:01, 170.12it/s]concatenating: train:  51%|█████     | 233/456 [00:01<00:01, 142.05it/s]concatenating: train:  55%|█████▌    | 253/456 [00:01<00:01, 115.84it/s]concatenating: train:  62%|██████▏   | 281/456 [00:01<00:01, 140.07it/s]concatenating: train:  68%|██████▊   | 308/456 [00:02<00:00, 162.70it/s]concatenating: train:  73%|███████▎  | 334/456 [00:02<00:00, 182.33it/s]concatenating: train:  78%|███████▊  | 357/456 [00:02<00:00, 126.21it/s]concatenating: train:  82%|████████▏ | 375/456 [00:02<00:00, 138.12it/s]concatenating: train:  88%|████████▊ | 401/456 [00:02<00:00, 160.23it/s]concatenating: train:  94%|█████████▍| 429/456 [00:02<00:00, 182.63it/s]concatenating: train: 100%|██████████| 456/456 [00:02<00:00, 157.68it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:01<00:03,  1.16s/it]Loading test:  50%|█████     | 2/4 [00:02<00:02,  1.07s/it]Loading test:  75%|███████▌  | 3/4 [00:02<00:01,  1.03s/it]Loading test: 100%|██████████| 4/4 [00:03<00:00,  1.03s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 246.11it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 56, 88, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 56, 88, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 56, 88, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 56, 88, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 56, 88, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 88, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 56, 88, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 56, 88, 21)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 28, 44, 21)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28, 44, 21)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 44, 40)   7600        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 44, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 44, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 44, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 28, 44, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 28, 44, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 44, 61)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 22, 61)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 14, 22, 61)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 14, 22, 80)   44000       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 14, 22, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 14, 22, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 14, 22, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 14, 22, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 14, 22, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 14, 22, 141)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 14, 22, 141)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 28, 44, 40)   22600       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 28, 44, 101)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 28, 44, 40)   36400       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 28, 44, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________2019-07-07 18:58:05.437316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 18:58:05.437435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 18:58:05.437450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 18:58:05.437458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 18:58:05.437786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

activation_7 (Activation)       (None, 28, 44, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 28, 44, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 28, 44, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 28, 44, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 28, 44, 141)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 28, 44, 141)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 56, 88, 20)   11300       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 88, 41)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 56, 88, 20)   7400        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 56, 88, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 88, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 56, 88, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 56, 88, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 88, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 88, 61)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 56, 88, 61)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 56, 88, 13)   806         dropout_5[0][0]                  
==================================================================================================
Total params: 225,706
Trainable params: 224,906
Non-trainable params: 800
__________________________________________________________________________________________________
----- /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/model_weights.h5
 --- initialized from Model_3T /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2
------------------------------------------------------------------
class_weights [6.11551387e-02 2.80417065e-02 7.36205865e-02 1.00307357e-02
 2.46459952e-02 6.20541010e-03 7.62197172e-02 1.11197709e-01
 6.32300513e-02 1.29380128e-02 3.51235945e-01 1.81283761e-01
 1.95230038e-04]
Train on 17190 samples, validate on 142 samples
Epoch 1/300
 - 27s - loss: 1.2265 - acc: 0.9543 - mDice: 0.6289 - val_loss: 1.1448 - val_acc: 0.9676 - val_mDice: 0.6808

Epoch 00001: val_mDice improved from -inf to 0.68076, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 20s - loss: 1.0141 - acc: 0.9579 - mDice: 0.6696 - val_loss: 1.1605 - val_acc: 0.9678 - val_mDice: 0.6826

Epoch 00002: val_mDice improved from 0.68076 to 0.68265, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 20s - loss: 0.9496 - acc: 0.9592 - mDice: 0.6882 - val_loss: 1.1823 - val_acc: 0.9672 - val_mDice: 0.6871

Epoch 00003: val_mDice improved from 0.68265 to 0.68711, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 20s - loss: 0.9118 - acc: 0.9601 - mDice: 0.7003 - val_loss: 1.1701 - val_acc: 0.9670 - val_mDice: 0.6933

Epoch 00004: val_mDice improved from 0.68711 to 0.69334, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 20s - loss: 0.8809 - acc: 0.9608 - mDice: 0.7095 - val_loss: 1.2237 - val_acc: 0.9674 - val_mDice: 0.6939

Epoch 00005: val_mDice improved from 0.69334 to 0.69385, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 19s - loss: 0.8584 - acc: 0.9614 - mDice: 0.7166 - val_loss: 1.2297 - val_acc: 0.9671 - val_mDice: 0.6956

Epoch 00006: val_mDice improved from 0.69385 to 0.69562, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 20s - loss: 0.8391 - acc: 0.9618 - mDice: 0.7228 - val_loss: 1.2211 - val_acc: 0.9670 - val_mDice: 0.6960

Epoch 00007: val_mDice improved from 0.69562 to 0.69596, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 19s - loss: 0.8233 - acc: 0.9622 - mDice: 0.7274 - val_loss: 1.2556 - val_acc: 0.9676 - val_mDice: 0.6956

Epoch 00008: val_mDice did not improve from 0.69596
Epoch 9/300
 - 19s - loss: 0.8109 - acc: 0.9625 - mDice: 0.7314 - val_loss: 1.2497 - val_acc: 0.9674 - val_mDice: 0.6981

Epoch 00009: val_mDice improved from 0.69596 to 0.69809, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 20s - loss: 0.7986 - acc: 0.9628 - mDice: 0.7355 - val_loss: 1.2592 - val_acc: 0.9672 - val_mDice: 0.7023

Epoch 00010: val_mDice improved from 0.69809 to 0.70230, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 11/300
 - 19s - loss: 0.7895 - acc: 0.9630 - mDice: 0.7381 - val_loss: 1.2830 - val_acc: 0.9674 - val_mDice: 0.6999

Epoch 00011: val_mDice did not improve from 0.70230
Epoch 12/300
 - 20s - loss: 0.7768 - acc: 0.9633 - mDice: 0.7423 - val_loss: 1.2546 - val_acc: 0.9670 - val_mDice: 0.7039

Epoch 00012: val_mDice improved from 0.70230 to 0.70393, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 13/300
 - 20s - loss: 0.7705 - acc: 0.9635 - mDice: 0.7444 - val_loss: 1.2857 - val_acc: 0.9668 - val_mDice: 0.7026

Epoch 00013: val_mDice did not improve from 0.70393
Epoch 14/300
 - 19s - loss: 0.7603 - acc: 0.9637 - mDice: 0.7477 - val_loss: 1.2945 - val_acc: 0.9669 - val_mDice: 0.7016

Epoch 00014: val_mDice did not improve from 0.70393
Epoch 15/300
 - 19s - loss: 0.7556 - acc: 0.9638 - mDice: 0.7494 - val_loss: 1.2678 - val_acc: 0.9673 - val_mDice: 0.7046

Epoch 00015: val_mDice improved from 0.70393 to 0.70460, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 16/300
 - 20s - loss: 0.7501 - acc: 0.9640 - mDice: 0.7511 - val_loss: 1.2980 - val_acc: 0.9673 - val_mDice: 0.7037

Epoch 00016: val_mDice did not improve from 0.70460
Epoch 17/300
 - 19s - loss: 0.7421 - acc: 0.9641 - mDice: 0.7536 - val_loss: 1.2971 - val_acc: 0.9672 - val_mDice: 0.7047

Epoch 00017: val_mDice improved from 0.70460 to 0.70475, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 18/300
 - 19s - loss: 0.7385 - acc: 0.9642 - mDice: 0.7548 - val_loss: 1.3549 - val_acc: 0.9666 - val_mDice: 0.7059

Epoch 00018: val_mDice improved from 0.70475 to 0.70587, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 19/300
 - 18s - loss: 0.7305 - acc: 0.9644 - mDice: 0.7574 - val_loss: 1.3560 - val_acc: 0.9665 - val_mDice: 0.7047

Epoch 00019: val_mDice did not improve from 0.70587
Epoch 20/300
 - 18s - loss: 0.7267 - acc: 0.9645 - mDice: 0.7587 - val_loss: 1.3304 - val_acc: 0.9671 - val_mDice: 0.7038

Epoch 00020: val_mDice did not improve from 0.70587
Epoch 21/300
 - 19s - loss: 0.7230 - acc: 0.9646 - mDice: 0.7601 - val_loss: 1.3115 - val_acc: 0.9675 - val_mDice: 0.7065

Epoch 00021: val_mDice improved from 0.70587 to 0.70647, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 22/300
 - 18s - loss: 0.7210 - acc: 0.9647 - mDice: 0.7608 - val_loss: 1.3687 - val_acc: 0.9667 - val_mDice: 0.7048

Epoch 00022: val_mDice did not improve from 0.70647
Epoch 23/300
 - 18s - loss: 0.7157 - acc: 0.9648 - mDice: 0.7622 - val_loss: 1.3292 - val_acc: 0.9665 - val_mDice: 0.7061

Epoch 00023: val_mDice did not improve from 0.70647
Epoch 24/300
 - 18s - loss: 0.7122 - acc: 0.9649 - mDice: 0.7635 - val_loss: 1.3211 - val_acc: 0.9670 - val_mDice: 0.7091

Epoch 00024: val_mDice improved from 0.70647 to 0.70911, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 25/300
 - 19s - loss: 0.7078 - acc: 0.9650 - mDice: 0.7650 - val_loss: 1.3517 - val_acc: 0.9673 - val_mDice: 0.7047

Epoch 00025: val_mDice did not improve from 0.70911
Epoch 26/300
 - 18s - loss: 0.7037 - acc: 0.9651 - mDice: 0.7663 - val_loss: 1.3866 - val_acc: 0.9667 - val_mDice: 0.7023

Epoch 00026: val_mDice did not improve from 0.70911
Epoch 27/300
 - 18s - loss: 0.7019 - acc: 0.9651 - mDice: 0.7667 - val_loss: 1.3692 - val_acc: 0.9670 - val_mDice: 0.7098

Epoch 00027: val_mDice improved from 0.70911 to 0.70983, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 28/300
 - 18s - loss: 0.6966 - acc: 0.9653 - mDice: 0.7684 - val_loss: 1.3394 - val_acc: 0.9670 - val_mDice: 0.7103

Epoch 00028: val_mDice improved from 0.70983 to 0.71027, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 29/300
 - 18s - loss: 0.6949 - acc: 0.9653 - mDice: 0.7690 - val_loss: 1.3589 - val_acc: 0.9668 - val_mDice: 0.7063

Epoch 00029: val_mDice did not improve from 0.71027
Epoch 30/300
 - 19s - loss: 0.6928 - acc: 0.9654 - mDice: 0.7698 - val_loss: 1.3814 - val_acc: 0.9668 - val_mDice: 0.7081

Epoch 00030: val_mDice did not improve from 0.71027
Epoch 31/300
 - 18s - loss: 0.6887 - acc: 0.9655 - mDice: 0.7713 - val_loss: 1.3679 - val_acc: 0.9672 - val_mDice: 0.7092

Epoch 00031: val_mDice did not improve from 0.71027
Epoch 32/300
 - 18s - loss: 0.6859 - acc: 0.9655 - mDice: 0.7720 - val_loss: 1.3629 - val_acc: 0.9671 - val_mDice: 0.7076

Epoch 00032: val_mDice did not improve from 0.71027
Epoch 33/300
 - 18s - loss: 0.6852 - acc: 0.9656 - mDice: 0.7723 - val_loss: 1.3594 - val_acc: 0.9669 - val_mDice: 0.7094

Epoch 00033: val_mDice did not improve from 0.71027
Epoch 34/300
 - 18s - loss: 0.6837 - acc: 0.9656 - mDice: 0.7728 - val_loss: 1.3932 - val_acc: 0.9673 - val_mDice: 0.7052

Epoch 00034: val_mDice did not improve from 0.71027
Epoch 35/300
 - 18s - loss: 0.6797 - acc: 0.9657 - mDice: 0.7742 - val_loss: 1.3723 - val_acc: 0.9673 - val_mDice: 0.7063

Epoch 00035: val_mDice did not improve from 0.71027
Epoch 36/300
 - 19s - loss: 0.6759 - acc: 0.9658 - mDice: 0.7753 - val_loss: 1.3833 - val_acc: 0.9667 - val_mDice: 0.7044

Epoch 00036: val_mDice did not improve from 0.71027
Epoch 37/300
 - 18s - loss: 0.6753 - acc: 0.9658 - mDice: 0.7761 - val_loss: 1.4032 - val_acc: 0.9673 - val_mDice: 0.7077

Epoch 00037: val_mDice did not improve from 0.71027
Epoch 38/300
 - 18s - loss: 0.6744 - acc: 0.9659 - mDice: 0.7757 - val_loss: 1.3951 - val_acc: 0.9674 - val_mDice: 0.7094

Epoch 00038: val_mDice did not improve from 0.71027
Epoch 39/300
 - 18s - loss: 0.6711 - acc: 0.9659 - mDice: 0.7770 - val_loss: 1.3842 - val_acc: 0.9670 - val_mDice: 0.7061

Epoch 00039: val_mDice did not improve from 0.71027
Epoch 40/300
 - 18s - loss: 0.6668 - acc: 0.9660 - mDice: 0.7785 - val_loss: 1.3779 - val_acc: 0.9672 - val_mDice: 0.7104

Epoch 00040: val_mDice improved from 0.71027 to 0.71039, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 41/300
 - 18s - loss: 0.6666 - acc: 0.9660 - mDice: 0.7786 - val_loss: 1.4284 - val_acc: 0.9666 - val_mDice: 0.7090

Epoch 00041: val_mDice did not improve from 0.71039
Epoch 42/300
 - 18s - loss: 0.6662 - acc: 0.9661 - mDice: 0.7787 - val_loss: 1.4082 - val_acc: 0.9667 - val_mDice: 0.7068

Epoch 00042: val_mDice did not improve from 0.71039
Epoch 43/300
 - 18s - loss: 0.6631 - acc: 0.9661 - mDice: 0.7795 - val_loss: 1.4112 - val_acc: 0.9671 - val_mDice: 0.7065

Epoch 00043: val_mDice did not improve from 0.71039
Epoch 44/300
 - 18s - loss: 0.6611 - acc: 0.9662 - mDice: 0.7799 - val_loss: 1.4319 - val_acc: 0.9665 - val_mDice: 0.7071

Epoch 00044: val_mDice did not improve from 0.71039
Epoch 45/300
 - 18s - loss: 0.6611 - acc: 0.9662 - mDice: 0.7801 - val_loss: 1.4489 - val_acc: 0.9668 - val_mDice: 0.7066

Epoch 00045: val_mDice did not improve from 0.71039
Epoch 46/300
 - 18s - loss: 0.6589 - acc: 0.9663 - mDice: 0.7812 - val_loss: 1.3847 - val_acc: 0.9664 - val_mDice: 0.7103

Epoch 00046: val_mDice did not improve from 0.71039
Epoch 47/300
 - 18s - loss: 0.6562 - acc: 0.9663 - mDice: 0.7815 - val_loss: 1.4577 - val_acc: 0.9669 - val_mDice: 0.7061

Epoch 00047: val_mDice did not improve from 0.71039
Epoch 48/300
 - 18s - loss: 0.6558 - acc: 0.9663 - mDice: 0.7819 - val_loss: 1.4290 - val_acc: 0.9671 - val_mDice: 0.7076

Epoch 00048: val_mDice did not improve from 0.71039
Epoch 49/300
 - 18s - loss: 0.6533 - acc: 0.9663 - mDice: 0.7830 - val_loss: 1.4397 - val_acc: 0.9673 - val_mDice: 0.7099

Epoch 00049: val_mDice did not improve from 0.71039
Epoch 50/300
 - 18s - loss: 0.6522 - acc: 0.9664 - mDice: 0.7832 - val_loss: 1.4346 - val_acc: 0.9672 - val_mDice: 0.7085

Epoch 00050: val_mDice did not improve from 0.71039
Epoch 51/300
 - 18s - loss: 0.6505 - acc: 0.9664 - mDice: 0.7837 - val_loss: 1.4489 - val_acc: 0.9669 - val_mDice: 0.7091

Epoch 00051: val_mDice did not improve from 0.71039
Epoch 52/300
 - 18s - loss: 0.6493 - acc: 0.9665 - mDice: 0.7842 - val_loss: 1.4741 - val_acc: 0.9669 - val_mDice: 0.7046

Epoch 00052: val_mDice did not improve from 0.71039
Epoch 53/300
 - 19s - loss: 0.6478 - acc: 0.9665 - mDice: 0.7846 - val_loss: 1.4519 - val_acc: 0.9660 - val_mDice: 0.7097

Epoch 00053: val_mDice did not improve from 0.71039
Epoch 54/300
 - 18s - loss: 0.6485 - acc: 0.9665 - mDice: 0.7846 - val_loss: 1.4360 - val_acc: 0.9671 - val_mDice: 0.7111

Epoch 00054: val_mDice improved from 0.71039 to 0.71107, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 55/300
 - 18s - loss: 0.6446 - acc: 0.9666 - mDice: 0.7856 - val_loss: 1.4549 - val_acc: 0.9670 - val_mDice: 0.7087

Epoch 00055: val_mDice did not improve from 0.71107
Epoch 56/300
 - 18s - loss: 0.6429 - acc: 0.9666 - mDice: 0.7861 - val_loss: 1.4223 - val_acc: 0.9667 - val_mDice: 0.7102

Epoch 00056: val_mDice did not improve from 0.71107
Epoch 57/300
 - 18s - loss: 0.6432 - acc: 0.9666 - mDice: 0.7863 - val_loss: 1.4317 - val_acc: 0.9669 - val_mDice: 0.7081

Epoch 00057: val_mDice did not improve from 0.71107
Epoch 58/300
 - 18s - loss: 0.6415 - acc: 0.9667 - mDice: 0.7869 - val_loss: 1.4229 - val_acc: 0.9667 - val_mDice: 0.7080

Epoch 00058: val_mDice did not improve from 0.71107
Epoch 59/300
 - 18s - loss: 0.6423 - acc: 0.9667 - mDice: 0.7864 - val_loss: 1.4436 - val_acc: 0.9671 - val_mDice: 0.7057

Epoch 00059: val_mDice did not improve from 0.71107
Epoch 60/300
 - 18s - loss: 0.6379 - acc: 0.9668 - mDice: 0.7877 - val_loss: 1.4516 - val_acc: 0.9668 - val_mDice: 0.7082

Epoch 00060: val_mDice did not improve from 0.71107
Epoch 61/300
 - 18s - loss: 0.6397 - acc: 0.9667 - mDice: 0.7875 - val_loss: 1.4351 - val_acc: 0.9667 - val_mDice: 0.7127

Epoch 00061: val_mDice improved from 0.71107 to 0.71266, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 62/300
 - 18s - loss: 0.6386 - acc: 0.9668 - mDice: 0.7877 - val_loss: 1.4833 - val_acc: 0.9667 - val_mDice: 0.7095

Epoch 00062: val_mDice did not improve from 0.71266
Epoch 63/300
 - 18s - loss: 0.6347 - acc: 0.9668 - mDice: 0.7889 - val_loss: 1.4512 - val_acc: 0.9667 - val_mDice: 0.7108

Epoch 00063: val_mDice did not improve from 0.71266
Epoch 64/300
 - 19s - loss: 0.6350 - acc: 0.9668 - mDice: 0.7890 - val_loss: 1.4751 - val_acc: 0.9669 - val_mDice: 0.7082

Epoch 00064: val_mDice did not improve from 0.71266
Epoch 65/300
 - 18s - loss: 0.6330 - acc: 0.9669 - mDice: 0.7897 - val_loss: 1.4810 - val_acc: 0.9666 - val_mDice: 0.7110

Epoch 00065: val_mDice did not improve from 0.71266
Epoch 66/300
 - 18s - loss: 0.6329 - acc: 0.9669 - mDice: 0.7899 - val_loss: 1.4473 - val_acc: 0.9668 - val_mDice: 0.7075

Epoch 00066: val_mDice did not improve from 0.71266
Epoch 67/300
 - 18s - loss: 0.6323 - acc: 0.9669 - mDice: 0.7899 - val_loss: 1.4568 - val_acc: 0.9670 - val_mDice: 0.7082

Epoch 00067: val_mDice did not improve from 0.71266
Epoch 68/300
 - 18s - loss: 0.6323 - acc: 0.9669 - mDice: 0.7897 - val_loss: 1.4973 - val_acc: 0.9671 - val_mDice: 0.7063

Epoch 00068: val_mDice did not improve from 0.71266
Epoch 69/300
 - 19s - loss: 0.6302 - acc: 0.9670 - mDice: 0.7906 - val_loss: 1.5048 - val_acc: 0.9668 - val_mDice: 0.7058

Epoch 00069: val_mDice did not improve from 0.71266
Epoch 70/300
 - 18s - loss: 0.6284 - acc: 0.9670 - mDice: 0.7912 - val_loss: 1.4824 - val_acc: 0.9667 - val_mDice: 0.7107

Epoch 00070: val_mDice did not improve from 0.71266
Epoch 71/300
 - 18s - loss: 0.6272 - acc: 0.9670 - mDice: 0.7914 - val_loss: 1.4942 - val_acc: 0.9667 - val_mDice: 0.7091

Epoch 00071: val_mDice did not improve from 0.71266
Epoch 72/300
 - 18s - loss: 0.6260 - acc: 0.9671 - mDice: 0.7920 - val_loss: 1.4555 - val_acc: 0.9667 - val_mDice: 0.7120

Epoch 00072: val_mDice did not improve from 0.71266
Epoch 73/300
 - 18s - loss: 0.6262 - acc: 0.9671 - mDice: 0.7916 - val_loss: 1.4920 - val_acc: 0.9663 - val_mDice: 0.7112

Epoch 00073: val_mDice did not improve from 0.71266
Epoch 74/300
 - 18s - loss: 0.6249 - acc: 0.9671 - mDice: 0.7924 - val_loss: 1.4999 - val_acc: 0.9669 - val_mDice: 0.7071

Epoch 00074: val_mDice did not improve from 0.71266
Epoch 75/300
 - 18s - loss: 0.6253 - acc: 0.9671 - mDice: 0.7921 - val_loss: 1.4935 - val_acc: 0.9668 - val_mDice: 0.7089

Epoch 00075: val_mDice did not improve from 0.71266
Epoch 76/300
 - 18s - loss: 0.6246 - acc: 0.9671 - mDice: 0.7927 - val_loss: 1.4787 - val_acc: 0.9665 - val_mDice: 0.7070

Epoch 00076: val_mDice did not improve from 0.71266
Epoch 77/300
 - 18s - loss: 0.6234 - acc: 0.9671 - mDice: 0.7930 - val_loss: 1.4700 - val_acc: 0.9669 - val_mDice: 0.7119

Epoch 00077: val_mDice did not improve from 0.71266
Epoch 78/300
 - 18s - loss: 0.6219 - acc: 0.9672 - mDice: 0.7932 - val_loss: 1.4824 - val_acc: 0.9668 - val_mDice: 0.7101

Epoch 00078: val_mDice did not improve from 0.71266
Epoch 79/300
 - 19s - loss: 0.6204 - acc: 0.9672 - mDice: 0.7937 - val_loss: 1.4589 - val_acc: 0.9668 - val_mDice: 0.7087

Epoch 00079: val_mDice did not improve from 0.71266
Epoch 80/300
 - 18s - loss: 0.6216 - acc: 0.9672 - mDice: 0.7933 - val_loss: 1.5138 - val_acc: 0.9666 - val_mDice: 0.7098

Epoch 00080: val_mDice did not improve from 0.71266
Epoch 81/300
 - 18s - loss: 0.6191 - acc: 0.9673 - mDice: 0.7942 - val_loss: 1.5393 - val_acc: 0.9670 - val_mDice: 0.7078

Epoch 00081: val_mDice did not improve from 0.71266
Epoch 82/300
 - 18s - loss: 0.6179 - acc: 0.9673 - mDice: 0.7947 - val_loss: 1.4903 - val_acc: 0.9665 - val_mDice: 0.7086

Epoch 00082: val_mDice did not improve from 0.71266
Epoch 83/300
 - 19s - loss: 0.6171 - acc: 0.9673 - mDice: 0.7948 - val_loss: 1.5088 - val_acc: 0.9671 - val_mDice: 0.7048

Epoch 00083: val_mDice did not improve from 0.71266
Epoch 84/300
 - 18s - loss: 0.6166 - acc: 0.9673 - mDice: 0.7951 - val_loss: 1.5130 - val_acc: 0.9671 - val_mDice: 0.7097

Epoch 00084: val_mDice did not improve from 0.71266
Epoch 85/300
 - 19s - loss: 0.6178 - acc: 0.9673 - mDice: 0.7947 - val_loss: 1.5475 - val_acc: 0.9668 - val_mDice: 0.7045

Epoch 00085: val_mDice did not improve from 0.71266
Epoch 86/300
 - 18s - loss: 0.6166 - acc: 0.9673 - mDice: 0.7950 - val_loss: 1.5092 - val_acc: 0.9668 - val_mDice: 0.7073

Epoch 00086: val_mDice did not improve from 0.71266
Epoch 87/300
 - 18s - loss: 0.6160 - acc: 0.9673 - mDice: 0.7953 - val_loss: 1.5002 - val_acc: 0.9665 - val_mDice: 0.7106

Epoch 00087: val_mDice did not improve from 0.71266
Epoch 88/300
 - 19s - loss: 0.6143 - acc: 0.9673 - mDice: 0.7956 - val_loss: 1.4883 - val_acc: 0.9669 - val_mDice: 0.7085

Epoch 00088: val_mDice did not improve from 0.71266
Epoch 89/300
 - 18s - loss: 0.6145 - acc: 0.9674 - mDice: 0.7956 - val_loss: 1.4886 - val_acc: 0.9667 - val_mDice: 0.7102

Epoch 00089: val_mDice did not improve from 0.71266
Epoch 90/300
 - 18s - loss: 0.6119 - acc: 0.9674 - mDice: 0.7967 - val_loss: 1.5105 - val_acc: 0.9661 - val_mDice: 0.7100

Epoch 00090: val_mDice did not improve from 0.71266
Epoch 91/300
 - 18s - loss: 0.6113 - acc: 0.9675 - mDice: 0.7969 - val_loss: 1.5261 - val_acc: 0.9668 - val_mDice: 0.7101

Epoch 00091: val_mDice did not improve from 0.71266
Restoring model weights from the end of the best epoch
Epoch 00091: early stopping
{'val_loss': [1.1447789484346416, 1.160490462477778, 1.1822715015478538, 1.1700687895358448, 1.223712596255289, 1.2296772171074235, 1.221074812009301, 1.2556071843899472, 1.249703138646945, 1.2592255674617392, 1.2829796201746229, 1.25464893982444, 1.2856814575866915, 1.2945107213208373, 1.2678478544866536, 1.2980408693703127, 1.297068374257692, 1.3548991042123715, 1.3560318686592747, 1.3303929668077281, 1.3114978713049015, 1.368742052937897, 1.3291879774818958, 1.3210718010512876, 1.3517305087035811, 1.386630956555756, 1.3692323112151992, 1.3393745598658708, 1.3588699287092183, 1.381375876950546, 1.3678509425109542, 1.3628807109846195, 1.3593710375503756, 1.3932169373606291, 1.3722589125095959, 1.3832825237596538, 1.4031933185080407, 1.395096350723589, 1.3841524695006895, 1.3778838574046819, 1.4283880104481335, 1.40816889178585, 1.4112444352096236, 1.4319355622143812, 1.4489145916952213, 1.384714014933143, 1.4577253125083278, 1.4289620560659488, 1.4396978700664682, 1.4346212685947688, 1.4488677332099056, 1.4741384084795561, 1.4519452754880342, 1.4359826856935527, 1.454908423020806, 1.4223283285826025, 1.431655785567324, 1.4229287941690902, 1.4435589850788386, 1.4515717012781493, 1.4350573395339536, 1.4833183615980015, 1.4512415805333096, 1.4750658047031349, 1.481009065265387, 1.4472525304471944, 1.456769693065697, 1.4973361131171106, 1.5048142260229085, 1.4824460207576482, 1.4941948601897335, 1.4554535864104687, 1.4920477917496586, 1.4999385257841835, 1.493467392216266, 1.4787301622645956, 1.4700185018525997, 1.4824438741509343, 1.4588779907831004, 1.5138006571313025, 1.5393028670633342, 1.4903192511746581, 1.508795551850762, 1.5129928059980904, 1.5475418827903102, 1.5091737374453478, 1.5001500047428507, 1.4882532626810208, 1.4886180120454708, 1.5104609031072804, 1.5261434803546314], 'val_acc': [0.9675582051277161, 0.9678311347961426, 0.967209496968229, 0.967035152542759, 0.9674353028686953, 0.9671466375740481, 0.9669708760691361, 0.9676253652908433, 0.9673638368996096, 0.9671937982800981, 0.9673824419438, 0.9669565743123981, 0.9667736627686192, 0.966929403828903, 0.9673381204336462, 0.9672580873462516, 0.9672280986544112, 0.9666493241216095, 0.966483582913036, 0.9670637476612145, 0.9674524278707908, 0.9667222164046596, 0.9664835501724566, 0.9669737110675221, 0.9673124115232011, 0.9667450861192085, 0.9670094218052608, 0.966997998701015, 0.9668479687731031, 0.9667607890048497, 0.9671580472462614, 0.9670980513935358, 0.9669222924071299, 0.9672695188455178, 0.967265246619641, 0.9666550419699977, 0.9672509221963479, 0.9673995795384259, 0.9670394398796727, 0.9672009189363936, 0.9666064499129712, 0.9666864578153046, 0.9670851960988112, 0.9664592474279269, 0.9668108031783306, 0.9664235534802289, 0.9669051397014672, 0.9670894750407044, 0.9673209819995182, 0.9671680767771224, 0.9669408470811979, 0.9668808394754437, 0.9660248378632774, 0.9671380410731678, 0.9669994426445222, 0.9666593368624298, 0.9668765580150444, 0.9666836177799064, 0.9670980329244909, 0.9667736442995744, 0.9666707641641858, 0.9666821881079338, 0.9666564733209745, 0.9669193978040991, 0.9665821723535027, 0.9668193946421986, 0.9669723049016066, 0.967132355125857, 0.9668336829669039, 0.9667065084820062, 0.9667221996146189, 0.9667307977945032, 0.966332087214564, 0.9669365689788066, 0.9668465155950734, 0.9664706856432096, 0.9669008414510271, 0.9667593417033343, 0.9668022402575318, 0.9666164425057424, 0.9669665517941327, 0.9664621311174312, 0.9670951912100886, 0.9670894506951453, 0.9667950986136853, 0.96684223245567, 0.9664506853466303, 0.9668765546570361, 0.9666679182522734, 0.9660534220682063, 0.9668336821274018], 'val_mDice': [0.6807591990685798, 0.6826464424670582, 0.6871065086042377, 0.6933414062983553, 0.6938503090764435, 0.6956243279954077, 0.6959600540953623, 0.695631484750291, 0.6980925294714915, 0.7022951749009145, 0.6998507388880555, 0.7039251881585994, 0.7026000442639203, 0.7016058060484873, 0.7046045602207452, 0.7036818282704957, 0.7047453279226599, 0.7058651783096959, 0.704727872996263, 0.7037811405222181, 0.7064650612817683, 0.704846440906256, 0.7060597446602834, 0.7091102054421331, 0.7046959652027613, 0.7023156772197132, 0.7098261873487016, 0.7102688676874402, 0.7062882168192259, 0.7081111510035017, 0.7091748353461145, 0.7076044653502989, 0.7093990294026656, 0.7051966584904094, 0.706343026228354, 0.7044002556465041, 0.7077390081445936, 0.7094438378240021, 0.7061059248279518, 0.7103945067231084, 0.7089913949160509, 0.7067832745296855, 0.7065112103878612, 0.7071466403947749, 0.7065638572397367, 0.7103256944199683, 0.7061057392980011, 0.7076064348220825, 0.709888112377113, 0.7084584571945836, 0.7091284511794507, 0.7045775937362456, 0.7097018856397816, 0.7110673407433739, 0.708749920549527, 0.7102261210831118, 0.7081473981830436, 0.7079914925803601, 0.7056808454889647, 0.7081961732515147, 0.7126551278879945, 0.709454680832339, 0.710768677818943, 0.7081813677935533, 0.7110218817079571, 0.7075085438473124, 0.7082449902950878, 0.7062698653046514, 0.7057710147239793, 0.710688205671982, 0.7091408120074743, 0.711989830917036, 0.7111831970617805, 0.7071375175261162, 0.7088648198356091, 0.7069671531798134, 0.7118586192668324, 0.710124005734081, 0.7087053043741576, 0.7097983712881384, 0.7077760276660113, 0.708569498968796, 0.704806967520378, 0.7096673837849792, 0.7045274972915649, 0.7072619762219173, 0.7105972515025609, 0.7084792113639939, 0.7101847050895154, 0.7099888736093548, 0.7101273032980906], 'loss': [1.2265233884653843, 1.014125054558049, 0.9495799139948208, 0.9118345344808644, 0.8808683593513107, 0.8583661380238558, 0.8390594219800828, 0.8232603524575891, 0.8108995077289628, 0.7986089964464974, 0.7895348828985914, 0.7768266583473756, 0.7704981608124511, 0.7603250828643675, 0.7555626779187897, 0.750051596921984, 0.7420514388234204, 0.7384801037163149, 0.7304745917752983, 0.7266528876178691, 0.7230350475730142, 0.7209998627885127, 0.7156724394789402, 0.7121692376125685, 0.7078495448311101, 0.7036962408600608, 0.7018707020813951, 0.6965570808705235, 0.6948986833285564, 0.6927536170520083, 0.6887189030577929, 0.6858609943559102, 0.6852257426496575, 0.6836819699713489, 0.6796704819550551, 0.6759064121950914, 0.6752515294095539, 0.6744168614703184, 0.6711468547842682, 0.6668254738980216, 0.6665693470528821, 0.6662084471007431, 0.6631349446539133, 0.6610711005761777, 0.661057835057976, 0.6588664255286456, 0.6562420486918433, 0.6558486208310995, 0.6532649338384088, 0.6522178459195219, 0.6504754317645904, 0.6493414050274772, 0.6477662881076718, 0.6485007524559705, 0.6446181956663459, 0.6429115957892031, 0.6432008325810902, 0.641528797121919, 0.642342732422847, 0.6379371954993913, 0.6397259684410672, 0.63855264227081, 0.634706303711337, 0.6350141842050425, 0.6330064862810504, 0.6329300455606005, 0.6323096821514793, 0.6322683446833115, 0.6302063315673371, 0.6284111812407365, 0.6271864619970737, 0.6259787356250157, 0.6262253514551159, 0.624904346160933, 0.6252895333588019, 0.6246072294547018, 0.6234432726561018, 0.621939529507156, 0.6204149598573238, 0.6216446635610771, 0.6191484129588364, 0.6178949787354594, 0.6170690284696272, 0.6165888491170638, 0.6177718950053022, 0.6166417001984437, 0.615983970328914, 0.6143165092054947, 0.6144644617687622, 0.6119363527786184, 0.6113063780771847], 'acc': [0.9543442450130034, 0.9578502406000466, 0.9592052123933562, 0.9600785103837303, 0.9607946502739361, 0.961351998224031, 0.961827522589066, 0.9621729148620086, 0.9624983945372771, 0.9627701497618857, 0.9630435919817136, 0.9633181789990704, 0.9634785459026339, 0.963683004466651, 0.9638277643152695, 0.964013642006797, 0.9641366342668828, 0.9642370662209321, 0.9644030528126795, 0.9645121992847959, 0.964628415998156, 0.9647362860848281, 0.9647851329754091, 0.9649077485022398, 0.965018771359087, 0.9651168677056509, 0.965143461120621, 0.965284965876024, 0.9652923346259277, 0.9653628534394132, 0.9654921154909317, 0.9655403358912732, 0.9656110325824944, 0.9656058769020804, 0.965744179199434, 0.9657889431545109, 0.9658186437433164, 0.9658532901306773, 0.9658970832477967, 0.9660393780161296, 0.9660493756117274, 0.9660729878582602, 0.9661184334005984, 0.9661746972726486, 0.9661971832722547, 0.966265322164854, 0.9662787541183641, 0.9663322866136352, 0.9663428068854492, 0.9663972142409835, 0.9664164307576546, 0.9664712653318209, 0.9664995724410079, 0.966506500692129, 0.9665616173741428, 0.9666475679653893, 0.9666265549876095, 0.966691432302951, 0.9666599121254638, 0.9667829175270041, 0.9667318172410452, 0.9667871205733223, 0.966843170090565, 0.9668383531060033, 0.9669073511168594, 0.9669325442907767, 0.9669171866114019, 0.9669232046694309, 0.9669712973653473, 0.9669950690777098, 0.9670415446812362, 0.967071600782795, 0.9670670702056596, 0.9671223166725398, 0.9670934046056813, 0.9670953640000219, 0.967135181428389, 0.9671700990359543, 0.9671938142643342, 0.9671604683608631, 0.9672690568586086, 0.9672563550706655, 0.9673122881872145, 0.9672915679275331, 0.9672719049481474, 0.967291309502043, 0.9673107783762503, 0.9673349864958607, 0.9673780304807227, 0.9674352322157349, 0.9674625835701641], 'mDice': [0.6288614583057051, 0.6696002985101026, 0.6882217183509769, 0.7002866216840405, 0.7094778761813778, 0.7165537552822462, 0.7227823933659077, 0.7274106201423747, 0.7314417397580638, 0.7354679092062706, 0.7381140104624475, 0.7423473000873169, 0.7444086031833314, 0.7476939079441117, 0.7493945731195757, 0.751105877464077, 0.7535912776284609, 0.7548271325731638, 0.7574456646180278, 0.7587001308443381, 0.7600726733865122, 0.7608242288725955, 0.7621764642613928, 0.7634932440751648, 0.7649865248925884, 0.7663099448163542, 0.7666635577452606, 0.7683959117526575, 0.7690264354825644, 0.769756220398149, 0.7713087858191197, 0.7719642436039732, 0.772306203634119, 0.7727994614385324, 0.7741741419115893, 0.7752951319790496, 0.7760570362045572, 0.7756618941294863, 0.7769652859564088, 0.7784550764867217, 0.7785781288022147, 0.77869428625767, 0.7794640589897683, 0.7799460586938419, 0.7801051225129638, 0.7811508701595198, 0.7814697572975536, 0.7819318008533809, 0.7829585929399594, 0.7832046680633519, 0.7836758118857472, 0.7842085964115225, 0.7845540183654284, 0.7845744413300404, 0.7855919243430869, 0.7860728214825913, 0.7862872824618954, 0.7869010442145138, 0.7864237723480899, 0.7877319304314792, 0.7875218299185557, 0.7877246121322783, 0.7888948341453401, 0.7890254707097869, 0.7896924959566095, 0.7898909722461889, 0.7898848991604861, 0.7896678807293003, 0.7905660945360851, 0.7911775564301353, 0.7914337984277039, 0.7920328221950786, 0.7916048777665143, 0.7923858343965443, 0.792061002258647, 0.792740488482326, 0.7929756437504687, 0.7932048367164106, 0.7936932650882883, 0.7932880782609488, 0.7942357981114834, 0.7946702737736105, 0.79481325189758, 0.7950705696913724, 0.7946598536750479, 0.7950074181021335, 0.7952740480554458, 0.7956398080572824, 0.7956169318362264, 0.7967022871333128, 0.7968837062309758]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:02<00:06,  2.26s/it]predicting test subjects:  50%|█████     | 2/4 [00:03<00:04,  2.05s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:05<00:01,  1.90s/it]predicting test subjects: 100%|██████████| 4/4 [00:07<00:00,  1.87s/it]
predicting train subjects:   0%|          | 0/456 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/456 [00:01<14:19,  1.89s/it]predicting train subjects:   0%|          | 2/456 [00:03<13:42,  1.81s/it]predicting train subjects:   1%|          | 3/456 [00:05<13:03,  1.73s/it]predicting train subjects:   1%|          | 4/456 [00:06<12:20,  1.64s/it]predicting train subjects:   1%|          | 5/456 [00:08<13:21,  1.78s/it]predicting train subjects:   1%|▏         | 6/456 [00:10<13:08,  1.75s/it]predicting train subjects:   2%|▏         | 7/456 [00:11<12:11,  1.63s/it]predicting train subjects:   2%|▏         | 8/456 [00:12<10:42,  1.43s/it]predicting train subjects:   2%|▏         | 9/456 [00:14<11:19,  1.52s/it]predicting train subjects:   2%|▏         | 10/456 [00:16<11:57,  1.61s/it]predicting train subjects:   2%|▏         | 11/456 [00:17<12:25,  1.68s/it]predicting train subjects:   3%|▎         | 12/456 [00:19<11:04,  1.50s/it]predicting train subjects:   3%|▎         | 13/456 [00:20<11:24,  1.55s/it]predicting train subjects:   3%|▎         | 14/456 [00:22<11:51,  1.61s/it]predicting train subjects:   3%|▎         | 15/456 [00:23<10:42,  1.46s/it]predicting train subjects:   4%|▎         | 16/456 [00:25<11:18,  1.54s/it]predicting train subjects:   4%|▎         | 17/456 [00:27<12:31,  1.71s/it]predicting train subjects:   4%|▍         | 18/456 [00:29<12:16,  1.68s/it]predicting train subjects:   4%|▍         | 19/456 [00:30<11:52,  1.63s/it]predicting train subjects:   4%|▍         | 20/456 [00:31<11:16,  1.55s/it]predicting train subjects:   5%|▍         | 21/456 [00:33<11:17,  1.56s/it]predicting train subjects:   5%|▍         | 22/456 [00:35<11:26,  1.58s/it]predicting train subjects:   5%|▌         | 23/456 [00:36<11:49,  1.64s/it]predicting train subjects:   5%|▌         | 24/456 [00:37<10:18,  1.43s/it]predicting train subjects:   5%|▌         | 25/456 [00:39<10:37,  1.48s/it]predicting train subjects:   6%|▌         | 26/456 [00:40<10:40,  1.49s/it]predicting train subjects:   6%|▌         | 27/456 [00:42<10:59,  1.54s/it]predicting train subjects:   6%|▌         | 28/456 [00:44<10:58,  1.54s/it]predicting train subjects:   6%|▋         | 29/456 [00:45<11:07,  1.56s/it]predicting train subjects:   7%|▋         | 30/456 [00:47<11:08,  1.57s/it]predicting train subjects:   7%|▋         | 31/456 [00:48<11:08,  1.57s/it]predicting train subjects:   7%|▋         | 32/456 [00:50<11:10,  1.58s/it]predicting train subjects:   7%|▋         | 33/456 [00:52<11:16,  1.60s/it]predicting train subjects:   7%|▋         | 34/456 [00:53<11:13,  1.60s/it]predicting train subjects:   8%|▊         | 35/456 [00:55<10:58,  1.57s/it]predicting train subjects:   8%|▊         | 36/456 [00:56<10:51,  1.55s/it]predicting train subjects:   8%|▊         | 37/456 [00:58<10:47,  1.55s/it]predicting train subjects:   8%|▊         | 38/456 [00:59<10:48,  1.55s/it]predicting train subjects:   9%|▊         | 39/456 [01:01<10:39,  1.53s/it]predicting train subjects:   9%|▉         | 40/456 [01:02<10:43,  1.55s/it]predicting train subjects:   9%|▉         | 41/456 [01:04<10:46,  1.56s/it]predicting train subjects:   9%|▉         | 42/456 [01:06<10:43,  1.56s/it]predicting train subjects:   9%|▉         | 43/456 [01:07<11:04,  1.61s/it]predicting train subjects:  10%|▉         | 44/456 [01:09<11:26,  1.67s/it]predicting train subjects:  10%|▉         | 45/456 [01:11<11:33,  1.69s/it]predicting train subjects:  10%|█         | 46/456 [01:12<11:25,  1.67s/it]predicting train subjects:  10%|█         | 47/456 [01:14<11:17,  1.66s/it]predicting train subjects:  11%|█         | 48/456 [01:16<11:27,  1.68s/it]predicting train subjects:  11%|█         | 49/456 [01:17<11:19,  1.67s/it]predicting train subjects:  11%|█         | 50/456 [01:19<11:15,  1.66s/it]predicting train subjects:  11%|█         | 51/456 [01:21<11:10,  1.66s/it]predicting train subjects:  11%|█▏        | 52/456 [01:22<11:09,  1.66s/it]predicting train subjects:  12%|█▏        | 53/456 [01:24<11:02,  1.64s/it]predicting train subjects:  12%|█▏        | 54/456 [01:26<10:54,  1.63s/it]predicting train subjects:  12%|█▏        | 55/456 [01:27<10:53,  1.63s/it]predicting train subjects:  12%|█▏        | 56/456 [01:29<10:59,  1.65s/it]predicting train subjects:  12%|█▎        | 57/456 [01:31<11:03,  1.66s/it]predicting train subjects:  13%|█▎        | 58/456 [01:32<10:56,  1.65s/it]predicting train subjects:  13%|█▎        | 59/456 [01:34<11:03,  1.67s/it]predicting train subjects:  13%|█▎        | 60/456 [01:36<11:00,  1.67s/it]predicting train subjects:  13%|█▎        | 61/456 [01:37<11:11,  1.70s/it]predicting train subjects:  14%|█▎        | 62/456 [01:39<11:13,  1.71s/it]predicting train subjects:  14%|█▍        | 63/456 [01:41<11:18,  1.73s/it]predicting train subjects:  14%|█▍        | 64/456 [01:43<11:22,  1.74s/it]predicting train subjects:  14%|█▍        | 65/456 [01:44<11:13,  1.72s/it]predicting train subjects:  14%|█▍        | 66/456 [01:46<11:11,  1.72s/it]predicting train subjects:  15%|█▍        | 67/456 [01:48<11:08,  1.72s/it]predicting train subjects:  15%|█▍        | 68/456 [01:50<11:04,  1.71s/it]predicting train subjects:  15%|█▌        | 69/456 [01:51<11:06,  1.72s/it]predicting train subjects:  15%|█▌        | 70/456 [01:53<11:10,  1.74s/it]predicting train subjects:  16%|█▌        | 71/456 [01:55<11:11,  1.74s/it]predicting train subjects:  16%|█▌        | 72/456 [01:57<11:08,  1.74s/it]predicting train subjects:  16%|█▌        | 73/456 [01:58<11:07,  1.74s/it]predicting train subjects:  16%|█▌        | 74/456 [02:00<11:05,  1.74s/it]predicting train subjects:  16%|█▋        | 75/456 [02:02<10:58,  1.73s/it]predicting train subjects:  17%|█▋        | 76/456 [02:03<10:56,  1.73s/it]predicting train subjects:  17%|█▋        | 77/456 [02:05<10:55,  1.73s/it]predicting train subjects:  17%|█▋        | 78/456 [02:07<10:52,  1.73s/it]predicting train subjects:  17%|█▋        | 79/456 [02:08<09:22,  1.49s/it]predicting train subjects:  18%|█▊        | 80/456 [02:09<08:20,  1.33s/it]predicting train subjects:  18%|█▊        | 81/456 [02:10<07:32,  1.21s/it]predicting train subjects:  18%|█▊        | 82/456 [02:11<07:05,  1.14s/it]predicting train subjects:  18%|█▊        | 83/456 [02:12<06:44,  1.08s/it]predicting train subjects:  18%|█▊        | 84/456 [02:13<06:28,  1.05s/it]predicting train subjects:  19%|█▊        | 85/456 [02:14<06:21,  1.03s/it]predicting train subjects:  19%|█▉        | 86/456 [02:15<06:12,  1.01s/it]predicting train subjects:  19%|█▉        | 87/456 [02:15<06:07,  1.01it/s]predicting train subjects:  19%|█▉        | 88/456 [02:16<06:00,  1.02it/s]predicting train subjects:  20%|█▉        | 89/456 [02:17<05:53,  1.04it/s]predicting train subjects:  20%|█▉        | 90/456 [02:18<05:51,  1.04it/s]predicting train subjects:  20%|█▉        | 91/456 [02:19<05:54,  1.03it/s]predicting train subjects:  20%|██        | 92/456 [02:20<05:51,  1.04it/s]predicting train subjects:  20%|██        | 93/456 [02:21<05:49,  1.04it/s]predicting train subjects:  21%|██        | 94/456 [02:22<05:46,  1.04it/s]predicting train subjects:  21%|██        | 95/456 [02:23<05:44,  1.05it/s]predicting train subjects:  21%|██        | 96/456 [02:24<05:40,  1.06it/s]predicting train subjects:  21%|██▏       | 97/456 [02:26<07:00,  1.17s/it]predicting train subjects:  21%|██▏       | 98/456 [02:27<07:48,  1.31s/it]predicting train subjects:  22%|██▏       | 99/456 [02:29<08:19,  1.40s/it]predicting train subjects:  22%|██▏       | 100/456 [02:31<08:39,  1.46s/it]predicting train subjects:  22%|██▏       | 101/456 [02:32<08:57,  1.51s/it]predicting train subjects:  22%|██▏       | 102/456 [02:34<09:06,  1.54s/it]predicting train subjects:  23%|██▎       | 103/456 [02:35<09:15,  1.57s/it]predicting train subjects:  23%|██▎       | 104/456 [02:37<09:27,  1.61s/it]predicting train subjects:  23%|██▎       | 105/456 [02:39<09:26,  1.61s/it]predicting train subjects:  23%|██▎       | 106/456 [02:40<09:29,  1.63s/it]predicting train subjects:  23%|██▎       | 107/456 [02:42<09:36,  1.65s/it]predicting train subjects:  24%|██▎       | 108/456 [02:44<09:30,  1.64s/it]predicting train subjects:  24%|██▍       | 109/456 [02:45<09:22,  1.62s/it]predicting train subjects:  24%|██▍       | 110/456 [02:47<09:26,  1.64s/it]predicting train subjects:  24%|██▍       | 111/456 [02:49<09:24,  1.64s/it]predicting train subjects:  25%|██▍       | 112/456 [02:50<09:11,  1.60s/it]predicting train subjects:  25%|██▍       | 113/456 [02:52<09:08,  1.60s/it]predicting train subjects:  25%|██▌       | 114/456 [02:53<09:01,  1.58s/it]predicting train subjects:  25%|██▌       | 115/456 [02:55<09:13,  1.62s/it]predicting train subjects:  25%|██▌       | 116/456 [02:57<09:18,  1.64s/it]predicting train subjects:  26%|██▌       | 117/456 [02:58<09:18,  1.65s/it]predicting train subjects:  26%|██▌       | 118/456 [03:00<09:28,  1.68s/it]predicting train subjects:  26%|██▌       | 119/456 [03:02<09:34,  1.70s/it]predicting train subjects:  26%|██▋       | 120/456 [03:04<09:31,  1.70s/it]predicting train subjects:  27%|██▋       | 121/456 [03:05<09:37,  1.73s/it]predicting train subjects:  27%|██▋       | 122/456 [03:07<09:46,  1.76s/it]predicting train subjects:  27%|██▋       | 123/456 [03:09<09:41,  1.74s/it]predicting train subjects:  27%|██▋       | 124/456 [03:11<09:41,  1.75s/it]predicting train subjects:  27%|██▋       | 125/456 [03:12<09:35,  1.74s/it]predicting train subjects:  28%|██▊       | 126/456 [03:14<09:42,  1.76s/it]predicting train subjects:  28%|██▊       | 127/456 [03:16<08:56,  1.63s/it]predicting train subjects:  28%|██▊       | 128/456 [03:17<08:28,  1.55s/it]predicting train subjects:  28%|██▊       | 129/456 [03:18<08:03,  1.48s/it]predicting train subjects:  29%|██▊       | 130/456 [03:20<07:50,  1.44s/it]predicting train subjects:  29%|██▊       | 131/456 [03:21<07:41,  1.42s/it]predicting train subjects:  29%|██▉       | 132/456 [03:22<07:30,  1.39s/it]predicting train subjects:  29%|██▉       | 133/456 [03:24<08:28,  1.57s/it]predicting train subjects:  29%|██▉       | 134/456 [03:26<09:22,  1.75s/it]predicting train subjects:  30%|██▉       | 135/456 [03:29<10:01,  1.87s/it]predicting train subjects:  30%|██▉       | 136/456 [03:31<10:14,  1.92s/it]predicting train subjects:  30%|███       | 137/456 [03:33<10:27,  1.97s/it]predicting train subjects:  30%|███       | 138/456 [03:35<10:32,  1.99s/it]predicting train subjects:  30%|███       | 139/456 [03:36<09:34,  1.81s/it]predicting train subjects:  31%|███       | 140/456 [03:38<08:52,  1.69s/it]predicting train subjects:  31%|███       | 141/456 [03:39<08:25,  1.61s/it]predicting train subjects:  31%|███       | 142/456 [03:40<08:03,  1.54s/it]predicting train subjects:  31%|███▏      | 143/456 [03:42<08:01,  1.54s/it]predicting train subjects:  32%|███▏      | 144/456 [03:43<07:39,  1.47s/it]predicting train subjects:  32%|███▏      | 145/456 [03:45<07:36,  1.47s/it]predicting train subjects:  32%|███▏      | 146/456 [03:46<07:42,  1.49s/it]predicting train subjects:  32%|███▏      | 147/456 [03:48<07:43,  1.50s/it]predicting train subjects:  32%|███▏      | 148/456 [03:49<07:39,  1.49s/it]predicting train subjects:  33%|███▎      | 149/456 [03:51<07:37,  1.49s/it]predicting train subjects:  33%|███▎      | 150/456 [03:52<07:37,  1.49s/it]predicting train subjects:  33%|███▎      | 151/456 [03:54<07:37,  1.50s/it]predicting train subjects:  33%|███▎      | 152/456 [03:55<07:40,  1.52s/it]predicting train subjects:  34%|███▎      | 153/456 [03:57<07:38,  1.51s/it]predicting train subjects:  34%|███▍      | 154/456 [03:58<07:52,  1.56s/it]predicting train subjects:  34%|███▍      | 155/456 [04:00<07:56,  1.58s/it]predicting train subjects:  34%|███▍      | 156/456 [04:02<07:53,  1.58s/it]predicting train subjects:  34%|███▍      | 157/456 [04:03<07:45,  1.56s/it]predicting train subjects:  35%|███▍      | 158/456 [04:05<07:35,  1.53s/it]predicting train subjects:  35%|███▍      | 159/456 [04:06<07:31,  1.52s/it]predicting train subjects:  35%|███▌      | 160/456 [04:08<07:22,  1.49s/it]predicting train subjects:  35%|███▌      | 161/456 [04:09<07:18,  1.49s/it]predicting train subjects:  36%|███▌      | 162/456 [04:10<07:13,  1.47s/it]predicting train subjects:  36%|███▌      | 163/456 [04:11<06:34,  1.35s/it]predicting train subjects:  36%|███▌      | 164/456 [04:13<06:07,  1.26s/it]predicting train subjects:  36%|███▌      | 165/456 [04:14<05:46,  1.19s/it]predicting train subjects:  36%|███▋      | 166/456 [04:15<05:26,  1.13s/it]predicting train subjects:  37%|███▋      | 167/456 [04:16<05:11,  1.08s/it]predicting train subjects:  37%|███▋      | 168/456 [04:16<05:01,  1.05s/it]predicting train subjects:  37%|███▋      | 169/456 [04:18<04:56,  1.03s/it]predicting train subjects:  37%|███▋      | 170/456 [04:19<04:54,  1.03s/it]predicting train subjects:  38%|███▊      | 171/456 [04:20<04:54,  1.03s/it]predicting train subjects:  38%|███▊      | 172/456 [04:21<04:51,  1.02s/it]predicting train subjects:  38%|███▊      | 173/456 [04:22<04:48,  1.02s/it]predicting train subjects:  38%|███▊      | 174/456 [04:23<04:47,  1.02s/it]predicting train subjects:  38%|███▊      | 175/456 [04:24<04:43,  1.01s/it]predicting train subjects:  39%|███▊      | 176/456 [04:25<04:53,  1.05s/it]predicting train subjects:  39%|███▉      | 177/456 [04:26<04:55,  1.06s/it]predicting train subjects:  39%|███▉      | 178/456 [04:27<04:54,  1.06s/it]predicting train subjects:  39%|███▉      | 179/456 [04:28<05:01,  1.09s/it]predicting train subjects:  39%|███▉      | 180/456 [04:29<05:03,  1.10s/it]predicting train subjects:  40%|███▉      | 181/456 [04:31<06:01,  1.31s/it]predicting train subjects:  40%|███▉      | 182/456 [04:33<06:47,  1.49s/it]predicting train subjects:  40%|████      | 183/456 [04:35<07:12,  1.58s/it]predicting train subjects:  40%|████      | 184/456 [04:36<07:27,  1.65s/it]predicting train subjects:  41%|████      | 185/456 [04:38<07:39,  1.70s/it]predicting train subjects:  41%|████      | 186/456 [04:40<07:50,  1.74s/it]predicting train subjects:  41%|████      | 187/456 [04:42<08:23,  1.87s/it]predicting train subjects:  41%|████      | 188/456 [04:44<08:42,  1.95s/it]predicting train subjects:  41%|████▏     | 189/456 [04:46<08:50,  1.99s/it]predicting train subjects:  42%|████▏     | 190/456 [04:49<08:59,  2.03s/it]predicting train subjects:  42%|████▏     | 191/456 [04:51<08:58,  2.03s/it]predicting train subjects:  42%|████▏     | 192/456 [04:53<08:58,  2.04s/it]predicting train subjects:  42%|████▏     | 193/456 [04:55<08:45,  2.00s/it]predicting train subjects:  43%|████▎     | 194/456 [04:57<08:36,  1.97s/it]predicting train subjects:  43%|████▎     | 195/456 [04:58<08:28,  1.95s/it]predicting train subjects:  43%|████▎     | 196/456 [05:00<08:26,  1.95s/it]predicting train subjects:  43%|████▎     | 197/456 [05:02<08:22,  1.94s/it]predicting train subjects:  43%|████▎     | 198/456 [05:04<08:23,  1.95s/it]predicting train subjects:  44%|████▎     | 199/456 [05:06<08:02,  1.88s/it]predicting train subjects:  44%|████▍     | 200/456 [05:08<07:45,  1.82s/it]predicting train subjects:  44%|████▍     | 201/456 [05:09<07:27,  1.75s/it]predicting train subjects:  44%|████▍     | 202/456 [05:11<07:15,  1.71s/it]predicting train subjects:  45%|████▍     | 203/456 [05:12<07:02,  1.67s/it]predicting train subjects:  45%|████▍     | 204/456 [05:14<06:56,  1.65s/it]predicting train subjects:  45%|████▍     | 205/456 [05:15<06:29,  1.55s/it]predicting train subjects:  45%|████▌     | 206/456 [05:17<06:06,  1.46s/it]predicting train subjects:  45%|████▌     | 207/456 [05:18<05:58,  1.44s/it]predicting train subjects:  46%|████▌     | 208/456 [05:19<05:52,  1.42s/it]predicting train subjects:  46%|████▌     | 209/456 [05:21<05:44,  1.40s/it]predicting train subjects:  46%|████▌     | 210/456 [05:22<05:36,  1.37s/it]predicting train subjects:  46%|████▋     | 211/456 [05:24<05:53,  1.44s/it]predicting train subjects:  46%|████▋     | 212/456 [05:25<06:05,  1.50s/it]predicting train subjects:  47%|████▋     | 213/456 [05:27<06:15,  1.55s/it]predicting train subjects:  47%|████▋     | 214/456 [05:29<06:20,  1.57s/it]predicting train subjects:  47%|████▋     | 215/456 [05:30<06:17,  1.57s/it]predicting train subjects:  47%|████▋     | 216/456 [05:32<06:18,  1.58s/it]predicting train subjects:  48%|████▊     | 217/456 [05:33<06:20,  1.59s/it]predicting train subjects:  48%|████▊     | 218/456 [05:35<06:16,  1.58s/it]predicting train subjects:  48%|████▊     | 219/456 [05:37<06:18,  1.60s/it]predicting train subjects:  48%|████▊     | 220/456 [05:38<06:19,  1.61s/it]predicting train subjects:  48%|████▊     | 221/456 [05:40<06:19,  1.61s/it]predicting train subjects:  49%|████▊     | 222/456 [05:41<06:17,  1.61s/it]predicting train subjects:  49%|████▉     | 223/456 [05:43<06:14,  1.61s/it]predicting train subjects:  49%|████▉     | 224/456 [05:45<06:09,  1.59s/it]predicting train subjects:  49%|████▉     | 225/456 [05:46<06:10,  1.60s/it]predicting train subjects:  50%|████▉     | 226/456 [05:48<06:15,  1.63s/it]predicting train subjects:  50%|████▉     | 227/456 [05:49<06:07,  1.61s/it]predicting train subjects:  50%|█████     | 228/456 [05:51<05:59,  1.58s/it]predicting train subjects:  50%|█████     | 229/456 [05:52<05:54,  1.56s/it]predicting train subjects:  50%|█████     | 230/456 [05:54<05:53,  1.56s/it]predicting train subjects:  51%|█████     | 231/456 [05:56<05:50,  1.56s/it]predicting train subjects:  51%|█████     | 232/456 [05:57<05:44,  1.54s/it]predicting train subjects:  51%|█████     | 233/456 [05:59<05:42,  1.54s/it]predicting train subjects:  51%|█████▏    | 234/456 [06:00<05:42,  1.54s/it]predicting train subjects:  52%|█████▏    | 235/456 [06:02<05:51,  1.59s/it]predicting train subjects:  52%|█████▏    | 236/456 [06:03<05:51,  1.60s/it]predicting train subjects:  52%|█████▏    | 237/456 [06:05<05:56,  1.63s/it]predicting train subjects:  52%|█████▏    | 238/456 [06:07<05:58,  1.65s/it]predicting train subjects:  52%|█████▏    | 239/456 [06:09<06:03,  1.68s/it]predicting train subjects:  53%|█████▎    | 240/456 [06:10<06:04,  1.69s/it]predicting train subjects:  53%|█████▎    | 241/456 [06:12<06:05,  1.70s/it]predicting train subjects:  53%|█████▎    | 242/456 [06:14<06:02,  1.70s/it]predicting train subjects:  53%|█████▎    | 243/456 [06:15<05:58,  1.69s/it]predicting train subjects:  54%|█████▎    | 244/456 [06:17<05:57,  1.69s/it]predicting train subjects:  54%|█████▎    | 245/456 [06:19<05:56,  1.69s/it]predicting train subjects:  54%|█████▍    | 246/456 [06:20<05:53,  1.68s/it]predicting train subjects:  54%|█████▍    | 247/456 [06:22<05:28,  1.57s/it]predicting train subjects:  54%|█████▍    | 248/456 [06:23<05:10,  1.49s/it]predicting train subjects:  55%|█████▍    | 249/456 [06:24<04:56,  1.43s/it]predicting train subjects:  55%|█████▍    | 250/456 [06:26<04:46,  1.39s/it]predicting train subjects:  55%|█████▌    | 251/456 [06:27<04:39,  1.36s/it]predicting train subjects:  55%|█████▌    | 252/456 [06:28<04:32,  1.34s/it]predicting train subjects:  55%|█████▌    | 253/456 [06:30<05:14,  1.55s/it]predicting train subjects:  56%|█████▌    | 254/456 [06:32<05:39,  1.68s/it]predicting train subjects:  56%|█████▌    | 255/456 [06:34<05:56,  1.78s/it]predicting train subjects:  56%|█████▌    | 256/456 [06:36<06:10,  1.85s/it]predicting train subjects:  56%|█████▋    | 257/456 [06:38<06:18,  1.90s/it]predicting train subjects:  57%|█████▋    | 258/456 [06:40<06:22,  1.93s/it]predicting train subjects:  57%|█████▋    | 259/456 [06:42<05:45,  1.75s/it]predicting train subjects:  57%|█████▋    | 260/456 [06:43<05:24,  1.66s/it]predicting train subjects:  57%|█████▋    | 261/456 [06:44<05:05,  1.57s/it]predicting train subjects:  57%|█████▋    | 262/456 [06:46<04:51,  1.50s/it]predicting train subjects:  58%|█████▊    | 263/456 [06:47<04:39,  1.45s/it]predicting train subjects:  58%|█████▊    | 264/456 [06:48<04:29,  1.40s/it]predicting train subjects:  58%|█████▊    | 265/456 [06:50<04:27,  1.40s/it]predicting train subjects:  58%|█████▊    | 266/456 [06:51<04:25,  1.40s/it]predicting train subjects:  59%|█████▊    | 267/456 [06:53<04:28,  1.42s/it]predicting train subjects:  59%|█████▉    | 268/456 [06:54<04:28,  1.43s/it]predicting train subjects:  59%|█████▉    | 269/456 [06:56<04:28,  1.43s/it]predicting train subjects:  59%|█████▉    | 270/456 [06:57<04:24,  1.42s/it]predicting train subjects:  59%|█████▉    | 271/456 [06:58<04:29,  1.46s/it]predicting train subjects:  60%|█████▉    | 272/456 [07:00<04:31,  1.47s/it]predicting train subjects:  60%|█████▉    | 273/456 [07:02<04:33,  1.50s/it]predicting train subjects:  60%|██████    | 274/456 [07:03<04:34,  1.51s/it]predicting train subjects:  60%|██████    | 275/456 [07:05<04:32,  1.51s/it]predicting train subjects:  61%|██████    | 276/456 [07:06<04:33,  1.52s/it]predicting train subjects:  61%|██████    | 277/456 [07:08<04:26,  1.49s/it]predicting train subjects:  61%|██████    | 278/456 [07:09<04:19,  1.46s/it]predicting train subjects:  61%|██████    | 279/456 [07:10<04:16,  1.45s/it]predicting train subjects:  61%|██████▏   | 280/456 [07:12<04:17,  1.46s/it]predicting train subjects:  62%|██████▏   | 281/456 [07:13<04:12,  1.44s/it]predicting train subjects:  62%|██████▏   | 282/456 [07:15<04:08,  1.43s/it]predicting train subjects:  62%|██████▏   | 283/456 [07:16<03:45,  1.31s/it]predicting train subjects:  62%|██████▏   | 284/456 [07:17<03:28,  1.21s/it]predicting train subjects:  62%|██████▎   | 285/456 [07:18<03:14,  1.14s/it]predicting train subjects:  63%|██████▎   | 286/456 [07:19<03:05,  1.09s/it]predicting train subjects:  63%|██████▎   | 287/456 [07:20<03:00,  1.07s/it]predicting train subjects:  63%|██████▎   | 288/456 [07:21<02:55,  1.05s/it]predicting train subjects:  63%|██████▎   | 289/456 [07:22<02:51,  1.03s/it]predicting train subjects:  64%|██████▎   | 290/456 [07:23<02:48,  1.01s/it]predicting train subjects:  64%|██████▍   | 291/456 [07:24<02:45,  1.00s/it]predicting train subjects:  64%|██████▍   | 292/456 [07:25<02:44,  1.00s/it]predicting train subjects:  64%|██████▍   | 293/456 [07:26<02:41,  1.01it/s]predicting train subjects:  64%|██████▍   | 294/456 [07:27<02:40,  1.01it/s]predicting train subjects:  65%|██████▍   | 295/456 [07:27<02:38,  1.02it/s]predicting train subjects:  65%|██████▍   | 296/456 [07:29<02:38,  1.01it/s]predicting train subjects:  65%|██████▌   | 297/456 [07:30<02:38,  1.00it/s]predicting train subjects:  65%|██████▌   | 298/456 [07:31<02:38,  1.00s/it]predicting train subjects:  66%|██████▌   | 299/456 [07:32<02:41,  1.03s/it]predicting train subjects:  66%|██████▌   | 300/456 [07:33<02:38,  1.01s/it]predicting train subjects:  66%|██████▌   | 301/456 [07:34<03:12,  1.24s/it]predicting train subjects:  66%|██████▌   | 302/456 [07:36<03:35,  1.40s/it]predicting train subjects:  66%|██████▋   | 303/456 [07:38<03:51,  1.51s/it]predicting train subjects:  67%|██████▋   | 304/456 [07:40<04:02,  1.59s/it]predicting train subjects:  67%|██████▋   | 305/456 [07:42<04:10,  1.66s/it]predicting train subjects:  67%|██████▋   | 306/456 [07:43<04:14,  1.70s/it]predicting train subjects:  67%|██████▋   | 307/456 [07:45<04:24,  1.78s/it]predicting train subjects:  68%|██████▊   | 308/456 [07:47<04:32,  1.84s/it]predicting train subjects:  68%|██████▊   | 309/456 [07:49<04:41,  1.91s/it]predicting train subjects:  68%|██████▊   | 310/456 [07:51<04:41,  1.93s/it]predicting train subjects:  68%|██████▊   | 311/456 [07:53<04:39,  1.93s/it]predicting train subjects:  68%|██████▊   | 312/456 [07:55<04:43,  1.97s/it]predicting train subjects:  69%|██████▊   | 313/456 [07:57<04:37,  1.94s/it]predicting train subjects:  69%|██████▉   | 314/456 [07:59<04:30,  1.90s/it]predicting train subjects:  69%|██████▉   | 315/456 [08:01<04:23,  1.87s/it]predicting train subjects:  69%|██████▉   | 316/456 [08:03<04:21,  1.87s/it]predicting train subjects:  70%|██████▉   | 317/456 [08:05<04:23,  1.89s/it]predicting train subjects:  70%|██████▉   | 318/456 [08:07<04:24,  1.92s/it]predicting train subjects:  70%|██████▉   | 319/456 [08:08<04:12,  1.84s/it]predicting train subjects:  70%|███████   | 320/456 [08:10<04:05,  1.80s/it]predicting train subjects:  70%|███████   | 321/456 [08:12<04:03,  1.80s/it]predicting train subjects:  71%|███████   | 322/456 [08:13<03:56,  1.77s/it]predicting train subjects:  71%|███████   | 323/456 [08:15<03:50,  1.73s/it]predicting train subjects:  71%|███████   | 324/456 [08:17<03:43,  1.70s/it]predicting train subjects:  71%|███████▏  | 325/456 [08:18<03:30,  1.60s/it]predicting train subjects:  71%|███████▏  | 326/456 [08:19<03:19,  1.54s/it]predicting train subjects:  72%|███████▏  | 327/456 [08:21<03:13,  1.50s/it]predicting train subjects:  72%|███████▏  | 328/456 [08:22<03:04,  1.44s/it]predicting train subjects:  72%|███████▏  | 329/456 [08:24<03:01,  1.43s/it]predicting train subjects:  72%|███████▏  | 330/456 [08:25<02:57,  1.41s/it]predicting train subjects:  73%|███████▎  | 331/456 [08:27<03:06,  1.49s/it]predicting train subjects:  73%|███████▎  | 332/456 [08:28<03:09,  1.53s/it]predicting train subjects:  73%|███████▎  | 333/456 [08:30<03:11,  1.56s/it]predicting train subjects:  73%|███████▎  | 334/456 [08:32<03:13,  1.59s/it]predicting train subjects:  73%|███████▎  | 335/456 [08:33<03:15,  1.62s/it]predicting train subjects:  74%|███████▎  | 336/456 [08:35<03:16,  1.64s/it]predicting train subjects:  74%|███████▍  | 337/456 [08:37<03:16,  1.65s/it]predicting train subjects:  74%|███████▍  | 338/456 [08:38<03:13,  1.64s/it]predicting train subjects:  74%|███████▍  | 339/456 [08:40<03:11,  1.63s/it]predicting train subjects:  75%|███████▍  | 340/456 [08:41<03:09,  1.63s/it]predicting train subjects:  75%|███████▍  | 341/456 [08:43<03:08,  1.64s/it]predicting train subjects:  75%|███████▌  | 342/456 [08:45<03:07,  1.64s/it]predicting train subjects:  75%|███████▌  | 343/456 [08:46<03:02,  1.62s/it]predicting train subjects:  75%|███████▌  | 344/456 [08:48<03:02,  1.63s/it]predicting train subjects:  76%|███████▌  | 345/456 [08:50<02:59,  1.62s/it]predicting train subjects:  76%|███████▌  | 346/456 [08:51<02:56,  1.61s/it]predicting train subjects:  76%|███████▌  | 347/456 [08:53<02:52,  1.58s/it]predicting train subjects:  76%|███████▋  | 348/456 [08:54<02:52,  1.60s/it]predicting train subjects:  77%|███████▋  | 349/456 [08:56<02:53,  1.62s/it]predicting train subjects:  77%|███████▋  | 350/456 [08:58<02:50,  1.61s/it]predicting train subjects:  77%|███████▋  | 351/456 [08:59<02:47,  1.60s/it]predicting train subjects:  77%|███████▋  | 352/456 [09:01<02:46,  1.60s/it]predicting train subjects:  77%|███████▋  | 353/456 [09:02<02:43,  1.59s/it]predicting train subjects:  78%|███████▊  | 354/456 [09:04<02:43,  1.60s/it]predicting train subjects:  78%|███████▊  | 355/456 [09:06<02:42,  1.61s/it]predicting train subjects:  78%|███████▊  | 356/456 [09:07<02:41,  1.62s/it]predicting train subjects:  78%|███████▊  | 357/456 [09:09<02:41,  1.63s/it]predicting train subjects:  79%|███████▊  | 358/456 [09:10<02:40,  1.64s/it]predicting train subjects:  79%|███████▊  | 359/456 [09:12<02:39,  1.64s/it]predicting train subjects:  79%|███████▉  | 360/456 [09:14<02:38,  1.65s/it]predicting train subjects:  79%|███████▉  | 361/456 [09:16<02:40,  1.69s/it]predicting train subjects:  79%|███████▉  | 362/456 [09:17<02:39,  1.70s/it]predicting train subjects:  80%|███████▉  | 363/456 [09:19<02:39,  1.72s/it]predicting train subjects:  80%|███████▉  | 364/456 [09:21<02:38,  1.72s/it]predicting train subjects:  80%|████████  | 365/456 [09:22<02:36,  1.72s/it]predicting train subjects:  80%|████████  | 366/456 [09:24<02:34,  1.71s/it]predicting train subjects:  80%|████████  | 367/456 [09:25<02:21,  1.59s/it]predicting train subjects:  81%|████████  | 368/456 [09:27<02:12,  1.51s/it]predicting train subjects:  81%|████████  | 369/456 [09:28<02:06,  1.45s/it]predicting train subjects:  81%|████████  | 370/456 [09:29<02:01,  1.41s/it]predicting train subjects:  81%|████████▏ | 371/456 [09:31<01:57,  1.39s/it]predicting train subjects:  82%|████████▏ | 372/456 [09:32<01:55,  1.38s/it]predicting train subjects:  82%|████████▏ | 373/456 [09:34<02:12,  1.60s/it]predicting train subjects:  82%|████████▏ | 374/456 [09:36<02:22,  1.74s/it]predicting train subjects:  82%|████████▏ | 375/456 [09:38<02:28,  1.83s/it]predicting train subjects:  82%|████████▏ | 376/456 [09:40<02:31,  1.89s/it]predicting train subjects:  83%|████████▎ | 377/456 [09:42<02:32,  1.93s/it]predicting train subjects:  83%|████████▎ | 378/456 [09:44<02:33,  1.97s/it]predicting train subjects:  83%|████████▎ | 379/456 [09:46<02:17,  1.79s/it]predicting train subjects:  83%|████████▎ | 380/456 [09:47<02:06,  1.66s/it]predicting train subjects:  84%|████████▎ | 381/456 [09:49<01:57,  1.57s/it]predicting train subjects:  84%|████████▍ | 382/456 [09:50<01:51,  1.51s/it]predicting train subjects:  84%|████████▍ | 383/456 [09:51<01:48,  1.49s/it]predicting train subjects:  84%|████████▍ | 384/456 [09:53<01:44,  1.45s/it]predicting train subjects:  84%|████████▍ | 385/456 [09:54<01:45,  1.48s/it]predicting train subjects:  85%|████████▍ | 386/456 [09:56<01:43,  1.48s/it]predicting train subjects:  85%|████████▍ | 387/456 [09:57<01:42,  1.49s/it]predicting train subjects:  85%|████████▌ | 388/456 [09:59<01:41,  1.49s/it]predicting train subjects:  85%|████████▌ | 389/456 [10:00<01:40,  1.51s/it]predicting train subjects:  86%|████████▌ | 390/456 [10:02<01:40,  1.52s/it]predicting train subjects:  86%|████████▌ | 391/456 [10:03<01:41,  1.56s/it]predicting train subjects:  86%|████████▌ | 392/456 [10:05<01:40,  1.58s/it]predicting train subjects:  86%|████████▌ | 393/456 [10:07<01:39,  1.58s/it]predicting train subjects:  86%|████████▋ | 394/456 [10:08<01:37,  1.58s/it]predicting train subjects:  87%|████████▋ | 395/456 [10:10<01:35,  1.57s/it]predicting train subjects:  87%|████████▋ | 396/456 [10:11<01:34,  1.58s/it]predicting train subjects:  87%|████████▋ | 397/456 [10:13<01:30,  1.54s/it]predicting train subjects:  87%|████████▋ | 398/456 [10:14<01:26,  1.50s/it]predicting train subjects:  88%|████████▊ | 399/456 [10:16<01:24,  1.48s/it]predicting train subjects:  88%|████████▊ | 400/456 [10:17<01:22,  1.47s/it]predicting train subjects:  88%|████████▊ | 401/456 [10:19<01:19,  1.45s/it]predicting train subjects:  88%|████████▊ | 402/456 [10:20<01:17,  1.44s/it]predicting train subjects:  88%|████████▊ | 403/456 [10:21<01:09,  1.32s/it]predicting train subjects:  89%|████████▊ | 404/456 [10:22<01:03,  1.22s/it]predicting train subjects:  89%|████████▉ | 405/456 [10:23<00:59,  1.16s/it]predicting train subjects:  89%|████████▉ | 406/456 [10:24<00:56,  1.12s/it]predicting train subjects:  89%|████████▉ | 407/456 [10:25<00:54,  1.10s/it]predicting train subjects:  89%|████████▉ | 408/456 [10:26<00:52,  1.10s/it]predicting train subjects:  90%|████████▉ | 409/456 [10:27<00:50,  1.07s/it]predicting train subjects:  90%|████████▉ | 410/456 [10:28<00:48,  1.05s/it]predicting train subjects:  90%|█████████ | 411/456 [10:29<00:47,  1.05s/it]predicting train subjects:  90%|█████████ | 412/456 [10:30<00:46,  1.05s/it]predicting train subjects:  91%|█████████ | 413/456 [10:31<00:44,  1.04s/it]predicting train subjects:  91%|█████████ | 414/456 [10:32<00:43,  1.05s/it]predicting train subjects:  91%|█████████ | 415/456 [10:33<00:42,  1.04s/it]predicting train subjects:  91%|█████████ | 416/456 [10:34<00:41,  1.03s/it]predicting train subjects:  91%|█████████▏| 417/456 [10:35<00:39,  1.03s/it]predicting train subjects:  92%|█████████▏| 418/456 [10:36<00:38,  1.03s/it]predicting train subjects:  92%|█████████▏| 419/456 [10:38<00:37,  1.03s/it]predicting train subjects:  92%|█████████▏| 420/456 [10:39<00:37,  1.04s/it]predicting train subjects:  92%|█████████▏| 421/456 [10:40<00:44,  1.28s/it]predicting train subjects:  93%|█████████▎| 422/456 [10:42<00:48,  1.44s/it]predicting train subjects:  93%|█████████▎| 423/456 [10:44<00:51,  1.55s/it]predicting train subjects:  93%|█████████▎| 424/456 [10:46<00:52,  1.63s/it]predicting train subjects:  93%|█████████▎| 425/456 [10:48<00:52,  1.69s/it]predicting train subjects:  93%|█████████▎| 426/456 [10:50<00:51,  1.73s/it]predicting train subjects:  94%|█████████▎| 427/456 [10:52<00:52,  1.82s/it]predicting train subjects:  94%|█████████▍| 428/456 [10:54<00:53,  1.90s/it]predicting train subjects:  94%|█████████▍| 429/456 [10:56<00:52,  1.94s/it]predicting train subjects:  94%|█████████▍| 430/456 [10:58<00:51,  2.00s/it]predicting train subjects:  95%|█████████▍| 431/456 [11:00<00:50,  2.02s/it]predicting train subjects:  95%|█████████▍| 432/456 [11:02<00:49,  2.04s/it]predicting train subjects:  95%|█████████▍| 433/456 [11:04<00:46,  2.03s/it]predicting train subjects:  95%|█████████▌| 434/456 [11:06<00:43,  1.97s/it]predicting train subjects:  95%|█████████▌| 435/456 [11:08<00:40,  1.93s/it]predicting train subjects:  96%|█████████▌| 436/456 [11:10<00:38,  1.93s/it]predicting train subjects:  96%|█████████▌| 437/456 [11:11<00:36,  1.90s/it]predicting train subjects:  96%|█████████▌| 438/456 [11:13<00:33,  1.89s/it]predicting train subjects:  96%|█████████▋| 439/456 [11:15<00:30,  1.78s/it]predicting train subjects:  96%|█████████▋| 440/456 [11:16<00:27,  1.72s/it]predicting train subjects:  97%|█████████▋| 441/456 [11:18<00:25,  1.68s/it]predicting train subjects:  97%|█████████▋| 442/456 [11:20<00:23,  1.65s/it]predicting train subjects:  97%|█████████▋| 443/456 [11:21<00:21,  1.63s/it]predicting train subjects:  97%|█████████▋| 444/456 [11:23<00:19,  1.63s/it]predicting train subjects:  98%|█████████▊| 445/456 [11:24<00:17,  1.57s/it]predicting train subjects:  98%|█████████▊| 446/456 [11:26<00:15,  1.52s/it]predicting train subjects:  98%|█████████▊| 447/456 [11:27<00:13,  1.45s/it]predicting train subjects:  98%|█████████▊| 448/456 [11:28<00:11,  1.42s/it]predicting train subjects:  98%|█████████▊| 449/456 [11:30<00:09,  1.41s/it]predicting train subjects:  99%|█████████▊| 450/456 [11:31<00:08,  1.38s/it]predicting train subjects:  99%|█████████▉| 451/456 [11:33<00:07,  1.47s/it]predicting train subjects:  99%|█████████▉| 452/456 [11:34<00:06,  1.52s/it]predicting train subjects:  99%|█████████▉| 453/456 [11:36<00:04,  1.57s/it]predicting train subjects: 100%|█████████▉| 454/456 [11:38<00:03,  1.61s/it]predicting train subjects: 100%|█████████▉| 455/456 [11:39<00:01,  1.64s/it]predicting train subjects: 100%|██████████| 456/456 [11:41<00:00,  1.67s/it]
Loading train:   0%|          | 0/456 [00:00<?, ?it/s]Loading train:   0%|          | 1/456 [00:01<08:28,  1.12s/it]Loading train:   0%|          | 2/456 [00:02<08:27,  1.12s/it]Loading train:   1%|          | 3/456 [00:03<08:43,  1.16s/it]Loading train:   1%|          | 4/456 [00:04<08:05,  1.07s/it]Loading train:   1%|          | 5/456 [00:05<08:17,  1.10s/it]Loading train:   1%|▏         | 6/456 [00:06<08:02,  1.07s/it]Loading train:   2%|▏         | 7/456 [00:07<07:38,  1.02s/it]Loading train:   2%|▏         | 8/456 [00:08<06:36,  1.13it/s]Loading train:   2%|▏         | 9/456 [00:09<07:15,  1.03it/s]Loading train:   2%|▏         | 10/456 [00:10<07:41,  1.04s/it]Loading train:   2%|▏         | 11/456 [00:11<07:54,  1.07s/it]Loading train:   3%|▎         | 12/456 [00:12<06:41,  1.11it/s]Loading train:   3%|▎         | 13/456 [00:12<06:35,  1.12it/s]Loading train:   3%|▎         | 14/456 [00:13<06:38,  1.11it/s]Loading train:   3%|▎         | 15/456 [00:14<05:52,  1.25it/s]Loading train:   4%|▎         | 16/456 [00:15<06:10,  1.19it/s]Loading train:   4%|▎         | 17/456 [00:16<07:07,  1.03it/s]Loading train:   4%|▍         | 18/456 [00:17<06:59,  1.04it/s]Loading train:   4%|▍         | 19/456 [00:18<07:03,  1.03it/s]Loading train:   4%|▍         | 20/456 [00:19<06:55,  1.05it/s]Loading train:   5%|▍         | 21/456 [00:20<07:20,  1.01s/it]Loading train:   5%|▍         | 22/456 [00:21<07:31,  1.04s/it]Loading train:   5%|▌         | 23/456 [00:22<07:40,  1.06s/it]Loading train:   5%|▌         | 24/456 [00:23<06:56,  1.04it/s]Loading train:   5%|▌         | 25/456 [00:24<07:24,  1.03s/it]Loading train:   6%|▌         | 26/456 [00:25<07:26,  1.04s/it]Loading train:   6%|▌         | 27/456 [00:26<07:34,  1.06s/it]Loading train:   6%|▌         | 28/456 [00:27<07:25,  1.04s/it]Loading train:   6%|▋         | 29/456 [00:28<07:21,  1.03s/it]Loading train:   7%|▋         | 30/456 [00:30<07:36,  1.07s/it]Loading train:   7%|▋         | 31/456 [00:31<07:30,  1.06s/it]Loading train:   7%|▋         | 32/456 [00:32<07:20,  1.04s/it]Loading train:   7%|▋         | 33/456 [00:33<07:19,  1.04s/it]Loading train:   7%|▋         | 34/456 [00:34<07:35,  1.08s/it]Loading train:   8%|▊         | 35/456 [00:35<07:26,  1.06s/it]Loading train:   8%|▊         | 36/456 [00:36<07:23,  1.06s/it]Loading train:   8%|▊         | 37/456 [00:37<07:19,  1.05s/it]Loading train:   8%|▊         | 38/456 [00:38<07:19,  1.05s/it]Loading train:   9%|▊         | 39/456 [00:39<07:03,  1.02s/it]Loading train:   9%|▉         | 40/456 [00:40<06:44,  1.03it/s]Loading train:   9%|▉         | 41/456 [00:41<06:28,  1.07it/s]Loading train:   9%|▉         | 42/456 [00:42<06:22,  1.08it/s]Loading train:   9%|▉         | 43/456 [00:42<06:20,  1.09it/s]Loading train:  10%|▉         | 44/456 [00:43<06:10,  1.11it/s]Loading train:  10%|▉         | 45/456 [00:44<06:06,  1.12it/s]Loading train:  10%|█         | 46/456 [00:45<06:05,  1.12it/s]Loading train:  10%|█         | 47/456 [00:46<06:01,  1.13it/s]Loading train:  11%|█         | 48/456 [00:47<05:55,  1.15it/s]Loading train:  11%|█         | 49/456 [00:48<06:07,  1.11it/s]Loading train:  11%|█         | 50/456 [00:49<06:03,  1.12it/s]Loading train:  11%|█         | 51/456 [00:49<05:56,  1.14it/s]Loading train:  11%|█▏        | 52/456 [00:50<05:56,  1.13it/s]Loading train:  12%|█▏        | 53/456 [00:51<06:18,  1.06it/s]Loading train:  12%|█▏        | 54/456 [00:52<06:16,  1.07it/s]Loading train:  12%|█▏        | 55/456 [00:53<06:20,  1.05it/s]Loading train:  12%|█▏        | 56/456 [00:54<06:16,  1.06it/s]Loading train:  12%|█▎        | 57/456 [00:55<06:25,  1.03it/s]Loading train:  13%|█▎        | 58/456 [00:56<06:24,  1.04it/s]Loading train:  13%|█▎        | 59/456 [00:57<06:18,  1.05it/s]Loading train:  13%|█▎        | 60/456 [00:58<06:22,  1.03it/s]Loading train:  13%|█▎        | 61/456 [00:59<06:22,  1.03it/s]Loading train:  14%|█▎        | 62/456 [01:00<06:26,  1.02it/s]Loading train:  14%|█▍        | 63/456 [01:01<06:29,  1.01it/s]Loading train:  14%|█▍        | 64/456 [01:02<06:40,  1.02s/it]Loading train:  14%|█▍        | 65/456 [01:03<06:41,  1.03s/it]Loading train:  14%|█▍        | 66/456 [01:04<06:38,  1.02s/it]Loading train:  15%|█▍        | 67/456 [01:05<06:34,  1.01s/it]Loading train:  15%|█▍        | 68/456 [01:06<06:34,  1.02s/it]Loading train:  15%|█▌        | 69/456 [01:07<06:25,  1.00it/s]Loading train:  15%|█▌        | 70/456 [01:08<06:22,  1.01it/s]Loading train:  16%|█▌        | 71/456 [01:09<06:23,  1.01it/s]Loading train:  16%|█▌        | 72/456 [01:10<06:17,  1.02it/s]Loading train:  16%|█▌        | 73/456 [01:11<06:08,  1.04it/s]Loading train:  16%|█▌        | 74/456 [01:12<06:11,  1.03it/s]Loading train:  16%|█▋        | 75/456 [01:13<06:06,  1.04it/s]Loading train:  17%|█▋        | 76/456 [01:14<06:02,  1.05it/s]Loading train:  17%|█▋        | 77/456 [01:15<05:55,  1.07it/s]Loading train:  17%|█▋        | 78/456 [01:16<06:08,  1.03it/s]Loading train:  17%|█▋        | 79/456 [01:17<05:21,  1.17it/s]Loading train:  18%|█▊        | 80/456 [01:17<04:42,  1.33it/s]Loading train:  18%|█▊        | 81/456 [01:18<04:23,  1.42it/s]Loading train:  18%|█▊        | 82/456 [01:18<04:08,  1.51it/s]Loading train:  18%|█▊        | 83/456 [01:19<03:47,  1.64it/s]Loading train:  18%|█▊        | 84/456 [01:19<03:38,  1.70it/s]Loading train:  19%|█▊        | 85/456 [01:20<03:31,  1.75it/s]Loading train:  19%|█▉        | 86/456 [01:20<03:27,  1.79it/s]Loading train:  19%|█▉        | 87/456 [01:21<03:20,  1.84it/s]Loading train:  19%|█▉        | 88/456 [01:21<03:18,  1.85it/s]Loading train:  20%|█▉        | 89/456 [01:22<03:11,  1.92it/s]Loading train:  20%|█▉        | 90/456 [01:22<03:15,  1.87it/s]Loading train:  20%|█▉        | 91/456 [01:23<03:11,  1.91it/s]Loading train:  20%|██        | 92/456 [01:23<03:12,  1.89it/s]Loading train:  20%|██        | 93/456 [01:24<03:27,  1.75it/s]Loading train:  21%|██        | 94/456 [01:25<03:39,  1.65it/s]Loading train:  21%|██        | 95/456 [01:25<03:34,  1.68it/s]Loading train:  21%|██        | 96/456 [01:26<03:26,  1.74it/s]Loading train:  21%|██▏       | 97/456 [01:27<04:25,  1.35it/s]Loading train:  21%|██▏       | 98/456 [01:28<04:54,  1.21it/s]Loading train:  22%|██▏       | 99/456 [01:29<05:00,  1.19it/s]Loading train:  22%|██▏       | 100/456 [01:30<04:57,  1.20it/s]Loading train:  22%|██▏       | 101/456 [01:31<04:57,  1.19it/s]Loading train:  22%|██▏       | 102/456 [01:31<04:59,  1.18it/s]Loading train:  23%|██▎       | 103/456 [01:33<06:24,  1.09s/it]Loading train:  23%|██▎       | 104/456 [01:34<06:13,  1.06s/it]Loading train:  23%|██▎       | 105/456 [01:35<06:03,  1.04s/it]Loading train:  23%|██▎       | 106/456 [01:36<05:54,  1.01s/it]Loading train:  23%|██▎       | 107/456 [01:37<05:47,  1.00it/s]Loading train:  24%|██▎       | 108/456 [01:38<05:45,  1.01it/s]Loading train:  24%|██▍       | 109/456 [01:39<05:48,  1.00s/it]Loading train:  24%|██▍       | 110/456 [01:40<05:48,  1.01s/it]Loading train:  24%|██▍       | 111/456 [01:41<05:38,  1.02it/s]Loading train:  25%|██▍       | 112/456 [01:42<05:40,  1.01it/s]Loading train:  25%|██▍       | 113/456 [01:43<05:39,  1.01it/s]Loading train:  25%|██▌       | 114/456 [01:44<05:37,  1.01it/s]Loading train:  25%|██▌       | 115/456 [01:45<05:58,  1.05s/it]Loading train:  25%|██▌       | 116/456 [01:46<05:46,  1.02s/it]Loading train:  26%|██▌       | 117/456 [01:47<05:28,  1.03it/s]Loading train:  26%|██▌       | 118/456 [01:48<05:18,  1.06it/s]Loading train:  26%|██▌       | 119/456 [01:49<05:10,  1.09it/s]Loading train:  26%|██▋       | 120/456 [01:49<05:02,  1.11it/s]Loading train:  27%|██▋       | 121/456 [01:50<05:11,  1.07it/s]Loading train:  27%|██▋       | 122/456 [01:51<05:08,  1.08it/s]Loading train:  27%|██▋       | 123/456 [01:52<05:04,  1.09it/s]Loading train:  27%|██▋       | 124/456 [01:53<05:04,  1.09it/s]Loading train:  27%|██▋       | 125/456 [01:54<05:05,  1.09it/s]Loading train:  28%|██▊       | 126/456 [01:55<05:02,  1.09it/s]Loading train:  28%|██▊       | 127/456 [01:56<04:52,  1.12it/s]Loading train:  28%|██▊       | 128/456 [01:57<04:38,  1.18it/s]Loading train:  28%|██▊       | 129/456 [01:57<04:34,  1.19it/s]Loading train:  29%|██▊       | 130/456 [01:58<04:33,  1.19it/s]Loading train:  29%|██▊       | 131/456 [01:59<04:27,  1.21it/s]Loading train:  29%|██▉       | 132/456 [02:00<04:20,  1.25it/s]Loading train:  29%|██▉       | 133/456 [02:01<04:57,  1.08it/s]Loading train:  29%|██▉       | 134/456 [02:02<05:15,  1.02it/s]Loading train:  30%|██▉       | 135/456 [02:03<05:25,  1.01s/it]Loading train:  30%|██▉       | 136/456 [02:04<05:34,  1.04s/it]Loading train:  30%|███       | 137/456 [02:06<05:49,  1.10s/it]Loading train:  30%|███       | 138/456 [02:07<05:58,  1.13s/it]Loading train:  30%|███       | 139/456 [02:08<05:34,  1.06s/it]Loading train:  31%|███       | 140/456 [02:09<05:20,  1.01s/it]Loading train:  31%|███       | 141/456 [02:09<05:02,  1.04it/s]Loading train:  31%|███       | 142/456 [02:10<04:49,  1.08it/s]Loading train:  31%|███▏      | 143/456 [02:11<04:41,  1.11it/s]Loading train:  32%|███▏      | 144/456 [02:12<04:54,  1.06it/s]Loading train:  32%|███▏      | 145/456 [02:13<05:07,  1.01it/s]Loading train:  32%|███▏      | 146/456 [02:14<04:58,  1.04it/s]Loading train:  32%|███▏      | 147/456 [02:15<04:52,  1.06it/s]Loading train:  32%|███▏      | 148/456 [02:16<04:48,  1.07it/s]Loading train:  33%|███▎      | 149/456 [02:17<04:41,  1.09it/s]Loading train:  33%|███▎      | 150/456 [02:18<04:37,  1.10it/s]Loading train:  33%|███▎      | 151/456 [02:19<04:36,  1.10it/s]Loading train:  33%|███▎      | 152/456 [02:19<04:32,  1.12it/s]Loading train:  34%|███▎      | 153/456 [02:20<04:26,  1.14it/s]Loading train:  34%|███▍      | 154/456 [02:21<04:18,  1.17it/s]Loading train:  34%|███▍      | 155/456 [02:22<04:20,  1.15it/s]Loading train:  34%|███▍      | 156/456 [02:23<04:19,  1.15it/s]Loading train:  34%|███▍      | 157/456 [02:24<04:22,  1.14it/s]Loading train:  35%|███▍      | 158/456 [02:25<04:28,  1.11it/s]Loading train:  35%|███▍      | 159/456 [02:26<04:21,  1.14it/s]Loading train:  35%|███▌      | 160/456 [02:26<04:16,  1.15it/s]Loading train:  35%|███▌      | 161/456 [02:27<04:22,  1.12it/s]Loading train:  36%|███▌      | 162/456 [02:28<04:20,  1.13it/s]Loading train:  36%|███▌      | 163/456 [02:29<03:54,  1.25it/s]Loading train:  36%|███▌      | 164/456 [02:29<03:27,  1.41it/s]Loading train:  36%|███▌      | 165/456 [02:30<03:17,  1.47it/s]Loading train:  36%|███▋      | 166/456 [02:30<03:02,  1.59it/s]Loading train:  37%|███▋      | 167/456 [02:31<02:53,  1.67it/s]Loading train:  37%|███▋      | 168/456 [02:32<02:46,  1.73it/s]Loading train:  37%|███▋      | 169/456 [02:32<02:45,  1.74it/s]Loading train:  37%|███▋      | 170/456 [02:33<02:45,  1.73it/s]Loading train:  38%|███▊      | 171/456 [02:33<02:46,  1.71it/s]Loading train:  38%|███▊      | 172/456 [02:34<02:43,  1.73it/s]Loading train:  38%|███▊      | 173/456 [02:34<02:46,  1.70it/s]Loading train:  38%|███▊      | 174/456 [02:35<02:43,  1.72it/s]Loading train:  38%|███▊      | 175/456 [02:36<02:42,  1.73it/s]Loading train:  39%|███▊      | 176/456 [02:36<02:40,  1.75it/s]Loading train:  39%|███▉      | 177/456 [02:37<02:38,  1.77it/s]Loading train:  39%|███▉      | 178/456 [02:37<02:37,  1.76it/s]Loading train:  39%|███▉      | 179/456 [02:38<02:40,  1.72it/s]Loading train:  39%|███▉      | 180/456 [02:38<02:36,  1.77it/s]Loading train:  40%|███▉      | 181/456 [02:40<03:24,  1.35it/s]Loading train:  40%|███▉      | 182/456 [02:41<03:48,  1.20it/s]Loading train:  40%|████      | 183/456 [02:42<04:05,  1.11it/s]Loading train:  40%|████      | 184/456 [02:43<04:23,  1.03it/s]Loading train:  41%|████      | 185/456 [02:44<04:25,  1.02it/s]Loading train:  41%|████      | 186/456 [02:45<04:30,  1.00s/it]Loading train:  41%|████      | 187/456 [02:46<04:43,  1.05s/it]Loading train:  41%|████      | 188/456 [02:47<04:50,  1.08s/it]Loading train:  41%|████▏     | 189/456 [02:48<05:02,  1.13s/it]Loading train:  42%|████▏     | 190/456 [02:50<05:04,  1.14s/it]Loading train:  42%|████▏     | 191/456 [02:51<05:04,  1.15s/it]Loading train:  42%|████▏     | 192/456 [02:52<05:05,  1.16s/it]Loading train:  42%|████▏     | 193/456 [02:53<05:08,  1.17s/it]Loading train:  43%|████▎     | 194/456 [02:54<04:56,  1.13s/it]Loading train:  43%|████▎     | 195/456 [02:55<04:48,  1.11s/it]Loading train:  43%|████▎     | 196/456 [02:56<04:41,  1.08s/it]Loading train:  43%|████▎     | 197/456 [02:57<04:35,  1.06s/it]Loading train:  43%|████▎     | 198/456 [02:58<04:27,  1.04s/it]Loading train:  44%|████▎     | 199/456 [02:59<04:29,  1.05s/it]Loading train:  44%|████▍     | 200/456 [03:00<04:19,  1.01s/it]Loading train:  44%|████▍     | 201/456 [03:01<04:13,  1.00it/s]Loading train:  44%|████▍     | 202/456 [03:02<04:11,  1.01it/s]Loading train:  45%|████▍     | 203/456 [03:03<04:03,  1.04it/s]Loading train:  45%|████▍     | 204/456 [03:04<03:56,  1.07it/s]Loading train:  45%|████▍     | 205/456 [03:05<03:46,  1.11it/s]Loading train:  45%|████▌     | 206/456 [03:06<03:51,  1.08it/s]Loading train:  45%|████▌     | 207/456 [03:07<03:44,  1.11it/s]Loading train:  46%|████▌     | 208/456 [03:07<03:42,  1.12it/s]Loading train:  46%|████▌     | 209/456 [03:08<03:39,  1.12it/s]Loading train:  46%|████▌     | 210/456 [03:09<03:46,  1.09it/s]Loading train:  46%|████▋     | 211/456 [03:10<03:55,  1.04it/s]Loading train:  46%|████▋     | 212/456 [03:11<03:48,  1.07it/s]Loading train:  47%|████▋     | 213/456 [03:12<03:48,  1.06it/s]Loading train:  47%|████▋     | 214/456 [03:13<03:41,  1.09it/s]Loading train:  47%|████▋     | 215/456 [03:14<03:37,  1.11it/s]Loading train:  47%|████▋     | 216/456 [03:15<03:35,  1.12it/s]Loading train:  48%|████▊     | 217/456 [03:16<03:36,  1.10it/s]Loading train:  48%|████▊     | 218/456 [03:17<03:26,  1.15it/s]Loading train:  48%|████▊     | 219/456 [03:17<03:27,  1.14it/s]Loading train:  48%|████▊     | 220/456 [03:18<03:25,  1.15it/s]Loading train:  48%|████▊     | 221/456 [03:19<03:24,  1.15it/s]Loading train:  49%|████▊     | 222/456 [03:20<03:22,  1.16it/s]Loading train:  49%|████▉     | 223/456 [03:21<03:47,  1.02it/s]Loading train:  49%|████▉     | 224/456 [03:22<03:51,  1.00it/s]Loading train:  49%|████▉     | 225/456 [03:23<03:58,  1.03s/it]Loading train:  50%|████▉     | 226/456 [03:25<04:05,  1.07s/it]Loading train:  50%|████▉     | 227/456 [03:26<03:59,  1.05s/it]Loading train:  50%|█████     | 228/456 [03:27<03:56,  1.04s/it]Loading train:  50%|█████     | 229/456 [03:28<03:58,  1.05s/it]Loading train:  50%|█████     | 230/456 [03:29<03:51,  1.02s/it]Loading train:  51%|█████     | 231/456 [03:30<03:53,  1.04s/it]Loading train:  51%|█████     | 232/456 [03:31<03:44,  1.00s/it]Loading train:  51%|█████     | 233/456 [03:32<03:42,  1.00it/s]Loading train:  51%|█████▏    | 234/456 [03:33<03:39,  1.01it/s]Loading train:  52%|█████▏    | 235/456 [03:34<03:55,  1.06s/it]Loading train:  52%|█████▏    | 236/456 [03:35<03:47,  1.03s/it]Loading train:  52%|█████▏    | 237/456 [03:36<03:47,  1.04s/it]Loading train:  52%|█████▏    | 238/456 [03:37<03:44,  1.03s/it]Loading train:  52%|█████▏    | 239/456 [03:38<03:36,  1.00it/s]Loading train:  53%|█████▎    | 240/456 [03:39<03:29,  1.03it/s]Loading train:  53%|█████▎    | 241/456 [03:40<03:37,  1.01s/it]Loading train:  53%|█████▎    | 242/456 [03:41<03:30,  1.01it/s]Loading train:  53%|█████▎    | 243/456 [03:42<03:25,  1.03it/s]Loading train:  54%|█████▎    | 244/456 [03:42<03:20,  1.06it/s]Loading train:  54%|█████▎    | 245/456 [03:43<03:13,  1.09it/s]Loading train:  54%|█████▍    | 246/456 [03:44<03:15,  1.07it/s]Loading train:  54%|█████▍    | 247/456 [03:45<03:13,  1.08it/s]Loading train:  54%|█████▍    | 248/456 [03:46<03:04,  1.13it/s]Loading train:  55%|█████▍    | 249/456 [03:47<03:09,  1.09it/s]Loading train:  55%|█████▍    | 250/456 [03:48<03:08,  1.09it/s]Loading train:  55%|█████▌    | 251/456 [03:49<03:16,  1.04it/s]Loading train:  55%|█████▌    | 252/456 [03:50<03:08,  1.08it/s]Loading train:  55%|█████▌    | 253/456 [03:51<03:25,  1.01s/it]Loading train:  56%|█████▌    | 254/456 [03:52<03:26,  1.02s/it]Loading train:  56%|█████▌    | 255/456 [03:53<03:31,  1.05s/it]Loading train:  56%|█████▌    | 256/456 [03:54<03:36,  1.08s/it]Loading train:  56%|█████▋    | 257/456 [03:55<03:38,  1.10s/it]Loading train:  57%|█████▋    | 258/456 [03:57<03:38,  1.10s/it]Loading train:  57%|█████▋    | 259/456 [03:57<03:21,  1.02s/it]Loading train:  57%|█████▋    | 260/456 [03:58<03:08,  1.04it/s]Loading train:  57%|█████▋    | 261/456 [03:59<03:02,  1.07it/s]Loading train:  57%|█████▋    | 262/456 [04:00<02:55,  1.11it/s]Loading train:  58%|█████▊    | 263/456 [04:01<02:48,  1.14it/s]Loading train:  58%|█████▊    | 264/456 [04:02<02:45,  1.16it/s]Loading train:  58%|█████▊    | 265/456 [04:02<02:45,  1.15it/s]Loading train:  58%|█████▊    | 266/456 [04:03<02:44,  1.16it/s]Loading train:  59%|█████▊    | 267/456 [04:04<02:43,  1.15it/s]Loading train:  59%|█████▉    | 268/456 [04:05<02:46,  1.13it/s]Loading train:  59%|█████▉    | 269/456 [04:06<02:47,  1.12it/s]Loading train:  59%|█████▉    | 270/456 [04:07<02:43,  1.14it/s]Loading train:  59%|█████▉    | 271/456 [04:08<02:43,  1.13it/s]Loading train:  60%|█████▉    | 272/456 [04:09<02:44,  1.12it/s]Loading train:  60%|█████▉    | 273/456 [04:10<02:55,  1.04it/s]Loading train:  60%|██████    | 274/456 [04:11<02:56,  1.03it/s]Loading train:  60%|██████    | 275/456 [04:12<02:57,  1.02it/s]Loading train:  61%|██████    | 276/456 [04:13<02:55,  1.03it/s]Loading train:  61%|██████    | 277/456 [04:14<03:01,  1.02s/it]Loading train:  61%|██████    | 278/456 [04:15<02:57,  1.00it/s]Loading train:  61%|██████    | 279/456 [04:16<02:51,  1.03it/s]Loading train:  61%|██████▏   | 280/456 [04:17<02:58,  1.01s/it]Loading train:  62%|██████▏   | 281/456 [04:18<02:48,  1.04it/s]Loading train:  62%|██████▏   | 282/456 [04:19<02:49,  1.03it/s]Loading train:  62%|██████▏   | 283/456 [04:19<02:32,  1.13it/s]Loading train:  62%|██████▏   | 284/456 [04:20<02:21,  1.22it/s]Loading train:  62%|██████▎   | 285/456 [04:21<02:13,  1.28it/s]Loading train:  63%|██████▎   | 286/456 [04:22<02:16,  1.25it/s]Loading train:  63%|██████▎   | 287/456 [04:22<02:11,  1.28it/s]Loading train:  63%|██████▎   | 288/456 [04:23<01:58,  1.41it/s]Loading train:  63%|██████▎   | 289/456 [04:23<01:49,  1.52it/s]Loading train:  64%|██████▎   | 290/456 [04:24<01:43,  1.61it/s]Loading train:  64%|██████▍   | 291/456 [04:24<01:39,  1.66it/s]Loading train:  64%|██████▍   | 292/456 [04:25<01:35,  1.71it/s]Loading train:  64%|██████▍   | 293/456 [04:26<01:31,  1.78it/s]Loading train:  64%|██████▍   | 294/456 [04:26<01:32,  1.75it/s]Loading train:  65%|██████▍   | 295/456 [04:27<01:30,  1.78it/s]Loading train:  65%|██████▍   | 296/456 [04:27<01:25,  1.87it/s]Loading train:  65%|██████▌   | 297/456 [04:28<01:31,  1.75it/s]Loading train:  65%|██████▌   | 298/456 [04:28<01:28,  1.78it/s]Loading train:  66%|██████▌   | 299/456 [04:29<01:34,  1.66it/s]Loading train:  66%|██████▌   | 300/456 [04:30<01:33,  1.66it/s]Loading train:  66%|██████▌   | 301/456 [04:31<01:56,  1.34it/s]Loading train:  66%|██████▌   | 302/456 [04:32<02:13,  1.15it/s]Loading train:  66%|██████▋   | 303/456 [04:33<02:25,  1.05it/s]Loading train:  67%|██████▋   | 304/456 [04:34<02:41,  1.06s/it]Loading train:  67%|██████▋   | 305/456 [04:35<02:40,  1.06s/it]Loading train:  67%|██████▋   | 306/456 [04:36<02:38,  1.05s/it]Loading train:  67%|██████▋   | 307/456 [04:38<02:42,  1.09s/it]Loading train:  68%|██████▊   | 308/456 [04:39<02:45,  1.12s/it]Loading train:  68%|██████▊   | 309/456 [04:40<02:46,  1.13s/it]Loading train:  68%|██████▊   | 310/456 [04:41<02:48,  1.16s/it]Loading train:  68%|██████▊   | 311/456 [04:42<02:48,  1.16s/it]Loading train:  68%|██████▊   | 312/456 [04:43<02:44,  1.14s/it]Loading train:  69%|██████▊   | 313/456 [04:44<02:38,  1.11s/it]Loading train:  69%|██████▉   | 314/456 [04:45<02:30,  1.06s/it]Loading train:  69%|██████▉   | 315/456 [04:46<02:25,  1.03s/it]Loading train:  69%|██████▉   | 316/456 [04:47<02:20,  1.00s/it]Loading train:  70%|██████▉   | 317/456 [04:48<02:17,  1.01it/s]Loading train:  70%|██████▉   | 318/456 [04:49<02:14,  1.03it/s]Loading train:  70%|██████▉   | 319/456 [04:50<02:08,  1.06it/s]Loading train:  70%|███████   | 320/456 [04:51<02:06,  1.08it/s]Loading train:  70%|███████   | 321/456 [04:52<02:03,  1.09it/s]Loading train:  71%|███████   | 322/456 [04:53<02:05,  1.07it/s]Loading train:  71%|███████   | 323/456 [04:54<02:06,  1.05it/s]Loading train:  71%|███████   | 324/456 [04:55<02:03,  1.07it/s]Loading train:  71%|███████▏  | 325/456 [04:56<01:58,  1.11it/s]Loading train:  71%|███████▏  | 326/456 [04:56<01:52,  1.16it/s]Loading train:  72%|███████▏  | 327/456 [04:57<01:47,  1.20it/s]Loading train:  72%|███████▏  | 328/456 [04:58<01:42,  1.25it/s]Loading train:  72%|███████▏  | 329/456 [04:59<01:45,  1.20it/s]Loading train:  72%|███████▏  | 330/456 [04:59<01:41,  1.24it/s]Loading train:  73%|███████▎  | 331/456 [05:00<01:47,  1.17it/s]Loading train:  73%|███████▎  | 332/456 [05:01<01:45,  1.17it/s]Loading train:  73%|███████▎  | 333/456 [05:02<01:43,  1.19it/s]Loading train:  73%|███████▎  | 334/456 [05:03<01:42,  1.18it/s]Loading train:  73%|███████▎  | 335/456 [05:04<01:41,  1.19it/s]Loading train:  74%|███████▎  | 336/456 [05:05<01:41,  1.18it/s]Loading train:  74%|███████▍  | 337/456 [05:06<01:44,  1.13it/s]Loading train:  74%|███████▍  | 338/456 [05:07<01:47,  1.10it/s]Loading train:  74%|███████▍  | 339/456 [05:07<01:44,  1.12it/s]Loading train:  75%|███████▍  | 340/456 [05:08<01:41,  1.14it/s]Loading train:  75%|███████▍  | 341/456 [05:09<01:40,  1.15it/s]Loading train:  75%|███████▌  | 342/456 [05:10<01:38,  1.16it/s]Loading train:  75%|███████▌  | 343/456 [05:11<01:39,  1.13it/s]Loading train:  75%|███████▌  | 344/456 [05:12<01:39,  1.13it/s]Loading train:  76%|███████▌  | 345/456 [05:13<01:38,  1.13it/s]Loading train:  76%|███████▌  | 346/456 [05:14<01:37,  1.13it/s]Loading train:  76%|███████▌  | 347/456 [05:14<01:37,  1.12it/s]Loading train:  76%|███████▋  | 348/456 [05:15<01:36,  1.11it/s]Loading train:  77%|███████▋  | 349/456 [05:16<01:38,  1.09it/s]Loading train:  77%|███████▋  | 350/456 [05:17<01:35,  1.11it/s]Loading train:  77%|███████▋  | 351/456 [05:18<01:34,  1.11it/s]Loading train:  77%|███████▋  | 352/456 [05:19<01:39,  1.04it/s]Loading train:  77%|███████▋  | 353/456 [05:20<01:38,  1.04it/s]Loading train:  78%|███████▊  | 354/456 [05:21<01:36,  1.05it/s]Loading train:  78%|███████▊  | 355/456 [05:22<01:38,  1.03it/s]Loading train:  78%|███████▊  | 356/456 [05:23<01:37,  1.03it/s]Loading train:  78%|███████▊  | 357/456 [05:24<01:36,  1.02it/s]Loading train:  79%|███████▊  | 358/456 [05:25<01:35,  1.03it/s]Loading train:  79%|███████▊  | 359/456 [05:26<01:33,  1.04it/s]Loading train:  79%|███████▉  | 360/456 [05:27<01:31,  1.05it/s]Loading train:  79%|███████▉  | 361/456 [05:28<01:28,  1.08it/s]Loading train:  79%|███████▉  | 362/456 [05:29<01:26,  1.08it/s]Loading train:  80%|███████▉  | 363/456 [05:30<01:25,  1.09it/s]Loading train:  80%|███████▉  | 364/456 [05:31<01:24,  1.09it/s]Loading train:  80%|████████  | 365/456 [05:32<01:29,  1.01it/s]Loading train:  80%|████████  | 366/456 [05:33<01:26,  1.03it/s]Loading train:  80%|████████  | 367/456 [05:33<01:23,  1.07it/s]Loading train:  81%|████████  | 368/456 [05:34<01:18,  1.13it/s]Loading train:  81%|████████  | 369/456 [05:35<01:13,  1.18it/s]Loading train:  81%|████████  | 370/456 [05:36<01:09,  1.24it/s]Loading train:  81%|████████▏ | 371/456 [05:36<01:07,  1.25it/s]Loading train:  82%|████████▏ | 372/456 [05:37<01:07,  1.25it/s]Loading train:  82%|████████▏ | 373/456 [05:38<01:15,  1.10it/s]Loading train:  82%|████████▏ | 374/456 [05:40<01:18,  1.04it/s]Loading train:  82%|████████▏ | 375/456 [05:41<01:22,  1.02s/it]Loading train:  82%|████████▏ | 376/456 [05:42<01:23,  1.05s/it]Loading train:  83%|████████▎ | 377/456 [05:43<01:26,  1.10s/it]Loading train:  83%|████████▎ | 378/456 [05:44<01:25,  1.10s/it]Loading train:  83%|████████▎ | 379/456 [05:45<01:19,  1.03s/it]Loading train:  83%|████████▎ | 380/456 [05:46<01:12,  1.05it/s]Loading train:  84%|████████▎ | 381/456 [05:47<01:10,  1.06it/s]Loading train:  84%|████████▍ | 382/456 [05:48<01:07,  1.09it/s]Loading train:  84%|████████▍ | 383/456 [05:48<01:05,  1.11it/s]Loading train:  84%|████████▍ | 384/456 [05:49<01:04,  1.12it/s]Loading train:  84%|████████▍ | 385/456 [05:50<01:06,  1.06it/s]Loading train:  85%|████████▍ | 386/456 [05:51<01:07,  1.03it/s]Loading train:  85%|████████▍ | 387/456 [05:52<01:06,  1.04it/s]Loading train:  85%|████████▌ | 388/456 [05:53<01:06,  1.03it/s]Loading train:  85%|████████▌ | 389/456 [05:54<01:03,  1.06it/s]Loading train:  86%|████████▌ | 390/456 [05:55<01:08,  1.04s/it]Loading train:  86%|████████▌ | 391/456 [05:57<01:18,  1.21s/it]Loading train:  86%|████████▌ | 392/456 [05:58<01:15,  1.19s/it]Loading train:  86%|████████▌ | 393/456 [05:59<01:12,  1.15s/it]Loading train:  86%|████████▋ | 394/456 [06:00<01:10,  1.13s/it]Loading train:  87%|████████▋ | 395/456 [06:01<01:08,  1.12s/it]Loading train:  87%|████████▋ | 396/456 [06:02<01:06,  1.10s/it]Loading train:  87%|████████▋ | 397/456 [06:04<01:04,  1.09s/it]Loading train:  87%|████████▋ | 398/456 [06:05<01:01,  1.05s/it]Loading train:  88%|████████▊ | 399/456 [06:05<00:57,  1.00s/it]Loading train:  88%|████████▊ | 400/456 [06:06<00:55,  1.01it/s]Loading train:  88%|████████▊ | 401/456 [06:07<00:55,  1.02s/it]Loading train:  88%|████████▊ | 402/456 [06:08<00:53,  1.01it/s]Loading train:  88%|████████▊ | 403/456 [06:09<00:47,  1.11it/s]Loading train:  89%|████████▊ | 404/456 [06:10<00:44,  1.17it/s]Loading train:  89%|████████▉ | 405/456 [06:11<00:42,  1.20it/s]Loading train:  89%|████████▉ | 406/456 [06:11<00:41,  1.20it/s]Loading train:  89%|████████▉ | 407/456 [06:12<00:37,  1.29it/s]Loading train:  89%|████████▉ | 408/456 [06:13<00:37,  1.27it/s]Loading train:  90%|████████▉ | 409/456 [06:14<00:34,  1.35it/s]Loading train:  90%|████████▉ | 410/456 [06:14<00:32,  1.42it/s]Loading train:  90%|█████████ | 411/456 [06:15<00:32,  1.39it/s]Loading train:  90%|█████████ | 412/456 [06:16<00:32,  1.35it/s]Loading train:  91%|█████████ | 413/456 [06:16<00:31,  1.37it/s]Loading train:  91%|█████████ | 414/456 [06:17<00:29,  1.44it/s]Loading train:  91%|█████████ | 415/456 [06:18<00:28,  1.42it/s]Loading train:  91%|█████████ | 416/456 [06:18<00:26,  1.49it/s]Loading train:  91%|█████████▏| 417/456 [06:19<00:23,  1.64it/s]Loading train:  92%|█████████▏| 418/456 [06:19<00:22,  1.73it/s]Loading train:  92%|█████████▏| 419/456 [06:20<00:20,  1.81it/s]Loading train:  92%|█████████▏| 420/456 [06:20<00:19,  1.82it/s]Loading train:  92%|█████████▏| 421/456 [06:22<00:26,  1.33it/s]Loading train:  93%|█████████▎| 422/456 [06:22<00:27,  1.24it/s]Loading train:  93%|█████████▎| 423/456 [06:23<00:27,  1.19it/s]Loading train:  93%|█████████▎| 424/456 [06:24<00:28,  1.13it/s]Loading train:  93%|█████████▎| 425/456 [06:25<00:28,  1.10it/s]Loading train:  93%|█████████▎| 426/456 [06:26<00:28,  1.07it/s]Loading train:  94%|█████████▎| 427/456 [06:28<00:29,  1.02s/it]Loading train:  94%|█████████▍| 428/456 [06:29<00:29,  1.06s/it]Loading train:  94%|█████████▍| 429/456 [06:30<00:30,  1.11s/it]Loading train:  94%|█████████▍| 430/456 [06:31<00:28,  1.11s/it]Loading train:  95%|█████████▍| 431/456 [06:32<00:27,  1.10s/it]Loading train:  95%|█████████▍| 432/456 [06:33<00:26,  1.10s/it]Loading train:  95%|█████████▍| 433/456 [06:34<00:25,  1.09s/it]Loading train:  95%|█████████▌| 434/456 [06:35<00:24,  1.11s/it]Loading train:  95%|█████████▌| 435/456 [06:37<00:23,  1.11s/it]Loading train:  96%|█████████▌| 436/456 [06:38<00:22,  1.11s/it]Loading train:  96%|█████████▌| 437/456 [06:39<00:21,  1.11s/it]Loading train:  96%|█████████▌| 438/456 [06:40<00:20,  1.15s/it]Loading train:  96%|█████████▋| 439/456 [06:41<00:19,  1.12s/it]Loading train:  96%|█████████▋| 440/456 [06:42<00:17,  1.10s/it]Loading train:  97%|█████████▋| 441/456 [06:43<00:16,  1.08s/it]Loading train:  97%|█████████▋| 442/456 [06:44<00:15,  1.07s/it]Loading train:  97%|█████████▋| 443/456 [06:45<00:14,  1.08s/it]Loading train:  97%|█████████▋| 444/456 [06:46<00:12,  1.06s/it]Loading train:  98%|█████████▊| 445/456 [06:47<00:11,  1.03s/it]Loading train:  98%|█████████▊| 446/456 [06:48<00:10,  1.01s/it]Loading train:  98%|█████████▊| 447/456 [06:49<00:08,  1.02it/s]Loading train:  98%|█████████▊| 448/456 [06:50<00:07,  1.06it/s]Loading train:  98%|█████████▊| 449/456 [06:51<00:06,  1.11it/s]Loading train:  99%|█████████▊| 450/456 [06:52<00:05,  1.17it/s]Loading train:  99%|█████████▉| 451/456 [06:52<00:04,  1.18it/s]Loading train:  99%|█████████▉| 452/456 [06:53<00:03,  1.11it/s]Loading train:  99%|█████████▉| 453/456 [06:54<00:02,  1.13it/s]Loading train: 100%|█████████▉| 454/456 [06:55<00:01,  1.14it/s]Loading train: 100%|█████████▉| 455/456 [06:56<00:00,  1.15it/s]Loading train: 100%|██████████| 456/456 [06:57<00:00,  1.15it/s]
concatenating: train:   0%|          | 0/456 [00:00<?, ?it/s]concatenating: train:   3%|▎         | 12/456 [00:00<00:03, 119.18it/s]concatenating: train:   5%|▌         | 25/456 [00:00<00:03, 121.92it/s]concatenating: train:   9%|▊         | 39/456 [00:00<00:03, 126.31it/s]concatenating: train:  12%|█▏        | 53/456 [00:00<00:03, 129.21it/s]concatenating: train:  15%|█▌        | 69/456 [00:00<00:02, 135.65it/s]concatenating: train:  21%|██        | 95/456 [00:00<00:02, 158.00it/s]concatenating: train:  25%|██▌       | 116/456 [00:00<00:02, 169.41it/s]concatenating: train:  30%|███       | 137/456 [00:00<00:01, 179.29it/s]concatenating: train:  34%|███▍      | 156/456 [00:00<00:01, 178.66it/s]concatenating: train:  41%|████▏     | 189/456 [00:01<00:01, 206.17it/s]concatenating: train:  47%|████▋     | 213/456 [00:01<00:01, 214.09it/s]concatenating: train:  52%|█████▏    | 236/456 [00:01<00:01, 208.39it/s]concatenating: train:  57%|█████▋    | 258/456 [00:01<00:00, 210.99it/s]concatenating: train:  61%|██████▏   | 280/456 [00:01<00:00, 209.48it/s]concatenating: train:  68%|██████▊   | 310/456 [00:01<00:00, 229.92it/s]concatenating: train:  74%|███████▍  | 337/456 [00:01<00:00, 239.81it/s]concatenating: train:  79%|███████▉  | 362/456 [00:01<00:00, 234.98it/s]concatenating: train:  85%|████████▍ | 387/456 [00:01<00:00, 228.96it/s]concatenating: train:  91%|█████████ | 414/456 [00:01<00:00, 235.51it/s]concatenating: train:  96%|█████████▌| 438/456 [00:02<00:00, 236.02it/s]concatenating: train: 100%|██████████| 456/456 [00:02<00:00, 212.31it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:01<00:03,  1.03s/it]Loading test:  50%|█████     | 2/4 [00:01<00:01,  1.01it/s]Loading test:  75%|███████▌  | 3/4 [00:02<00:00,  1.02it/s]Loading test: 100%|██████████| 4/4 [00:03<00:00,  1.00s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 105.05it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 56, 56, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 56, 56, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 56, 56, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 56, 56, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 56, 56, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 56, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 56, 56, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 56, 56, 21)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 21)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28, 28, 21)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 28, 40)   7600        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 28, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 28, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 28, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 28, 28, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 28, 28, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 28, 61)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 61)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 14, 14, 61)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 14, 14, 80)   44000       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 14, 14, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 14, 14, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 14, 14, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 14, 14, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 14, 14, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 14, 14, 141)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 14, 14, 141)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 28, 28, 40)   22600       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 28, 28, 101)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 28, 28, 40)   36400       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 28, 28, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 28, 28, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 28, 28, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 28, 28, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 28, 28, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 28, 28, 141)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-07 19:45:39.884289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 19:45:39.884397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 19:45:39.884414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 19:45:39.884422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 19:45:39.884780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 28, 28, 141)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 56, 56, 20)   11300       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 56, 41)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 56, 56, 20)   7400        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 56, 56, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 56, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 56, 56, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 56, 56, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 56, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 56, 61)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 56, 56, 61)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 56, 56, 13)   806         dropout_5[0][0]                  
==================================================================================================
Total params: 225,706
Trainable params: 224,906
Non-trainable params: 800
__________________________________________________________________________________________________
----- /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/model_weights.h5
 --- initialized from Model_3T /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1
------------------------------------------------------------------
class_weights [6.20353721e-02 2.84453234e-02 7.46802407e-02 1.01751126e-02
 2.50007361e-02 6.29472736e-03 7.25125636e-02 1.12798228e-01
 6.41401498e-02 1.31242354e-02 3.56291442e-01 1.74306703e-01
 1.95165508e-04]
Train on 27379 samples, validate on 259 samples
Epoch 1/300
 - 28s - loss: 1.1243 - acc: 0.9575 - mDice: 0.6468 - val_loss: 1.0455 - val_acc: 0.9716 - val_mDice: 0.6694

Epoch 00001: val_mDice improved from -inf to 0.66937, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 21s - loss: 0.9690 - acc: 0.9601 - mDice: 0.6813 - val_loss: 1.0933 - val_acc: 0.9719 - val_mDice: 0.6697

Epoch 00002: val_mDice improved from 0.66937 to 0.66972, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 21s - loss: 0.9160 - acc: 0.9612 - mDice: 0.6970 - val_loss: 1.0939 - val_acc: 0.9718 - val_mDice: 0.6767

Epoch 00003: val_mDice improved from 0.66972 to 0.67668, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 21s - loss: 0.8804 - acc: 0.9620 - mDice: 0.7078 - val_loss: 1.1367 - val_acc: 0.9716 - val_mDice: 0.6752

Epoch 00004: val_mDice did not improve from 0.67668
Epoch 5/300
 - 21s - loss: 0.8549 - acc: 0.9626 - mDice: 0.7158 - val_loss: 1.1531 - val_acc: 0.9713 - val_mDice: 0.6804

Epoch 00005: val_mDice improved from 0.67668 to 0.68039, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 20s - loss: 0.8343 - acc: 0.9631 - mDice: 0.7225 - val_loss: 1.1700 - val_acc: 0.9712 - val_mDice: 0.6854

Epoch 00006: val_mDice improved from 0.68039 to 0.68539, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 7/300
 - 21s - loss: 0.8186 - acc: 0.9634 - mDice: 0.7272 - val_loss: 1.1854 - val_acc: 0.9710 - val_mDice: 0.6801

Epoch 00007: val_mDice did not improve from 0.68539
Epoch 8/300
 - 21s - loss: 0.8057 - acc: 0.9638 - mDice: 0.7314 - val_loss: 1.1891 - val_acc: 0.9714 - val_mDice: 0.6795

Epoch 00008: val_mDice did not improve from 0.68539
Epoch 9/300
 - 21s - loss: 0.7944 - acc: 0.9640 - mDice: 0.7351 - val_loss: 1.1855 - val_acc: 0.9712 - val_mDice: 0.6852

Epoch 00009: val_mDice did not improve from 0.68539
Epoch 10/300
 - 21s - loss: 0.7830 - acc: 0.9643 - mDice: 0.7387 - val_loss: 1.2031 - val_acc: 0.9713 - val_mDice: 0.6789

Epoch 00010: val_mDice did not improve from 0.68539
Epoch 11/300
 - 21s - loss: 0.7745 - acc: 0.9645 - mDice: 0.7416 - val_loss: 1.2375 - val_acc: 0.9714 - val_mDice: 0.6824

Epoch 00011: val_mDice did not improve from 0.68539
Epoch 12/300
 - 21s - loss: 0.7672 - acc: 0.9647 - mDice: 0.7439 - val_loss: 1.2416 - val_acc: 0.9711 - val_mDice: 0.6827

Epoch 00012: val_mDice did not improve from 0.68539
Epoch 13/300
 - 21s - loss: 0.7604 - acc: 0.9649 - mDice: 0.7459 - val_loss: 1.2491 - val_acc: 0.9708 - val_mDice: 0.6805

Epoch 00013: val_mDice did not improve from 0.68539
Epoch 14/300
 - 21s - loss: 0.7535 - acc: 0.9650 - mDice: 0.7483 - val_loss: 1.2344 - val_acc: 0.9712 - val_mDice: 0.6905

Epoch 00014: val_mDice improved from 0.68539 to 0.69049, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 15/300
 - 21s - loss: 0.7478 - acc: 0.9651 - mDice: 0.7504 - val_loss: 1.2764 - val_acc: 0.9711 - val_mDice: 0.6870

Epoch 00015: val_mDice did not improve from 0.69049
Epoch 16/300
 - 21s - loss: 0.7418 - acc: 0.9653 - mDice: 0.7524 - val_loss: 1.2517 - val_acc: 0.9716 - val_mDice: 0.6863

Epoch 00016: val_mDice did not improve from 0.69049
Epoch 17/300
 - 21s - loss: 0.7360 - acc: 0.9654 - mDice: 0.7543 - val_loss: 1.2504 - val_acc: 0.9716 - val_mDice: 0.6864

Epoch 00017: val_mDice did not improve from 0.69049
Epoch 18/300
 - 21s - loss: 0.7305 - acc: 0.9655 - mDice: 0.7559 - val_loss: 1.2940 - val_acc: 0.9711 - val_mDice: 0.6880

Epoch 00018: val_mDice did not improve from 0.69049
Epoch 19/300
 - 20s - loss: 0.7263 - acc: 0.9656 - mDice: 0.7574 - val_loss: 1.2706 - val_acc: 0.9714 - val_mDice: 0.6879

Epoch 00019: val_mDice did not improve from 0.69049
Epoch 20/300
 - 21s - loss: 0.7234 - acc: 0.9657 - mDice: 0.7584 - val_loss: 1.2799 - val_acc: 0.9715 - val_mDice: 0.6900

Epoch 00020: val_mDice did not improve from 0.69049
Epoch 21/300
 - 21s - loss: 0.7197 - acc: 0.9658 - mDice: 0.7596 - val_loss: 1.3197 - val_acc: 0.9709 - val_mDice: 0.6894

Epoch 00021: val_mDice did not improve from 0.69049
Epoch 22/300
 - 21s - loss: 0.7157 - acc: 0.9659 - mDice: 0.7607 - val_loss: 1.2906 - val_acc: 0.9711 - val_mDice: 0.6861

Epoch 00022: val_mDice did not improve from 0.69049
Epoch 23/300
 - 21s - loss: 0.7121 - acc: 0.9659 - mDice: 0.7621 - val_loss: 1.2931 - val_acc: 0.9715 - val_mDice: 0.6854

Epoch 00023: val_mDice did not improve from 0.69049
Epoch 24/300
 - 20s - loss: 0.7100 - acc: 0.9660 - mDice: 0.7628 - val_loss: 1.3217 - val_acc: 0.9712 - val_mDice: 0.6878

Epoch 00024: val_mDice did not improve from 0.69049
Epoch 25/300
 - 20s - loss: 0.7059 - acc: 0.9661 - mDice: 0.7641 - val_loss: 1.3336 - val_acc: 0.9711 - val_mDice: 0.6890

Epoch 00025: val_mDice did not improve from 0.69049
Epoch 26/300
 - 20s - loss: 0.7030 - acc: 0.9662 - mDice: 0.7649 - val_loss: 1.3363 - val_acc: 0.9706 - val_mDice: 0.6850

Epoch 00026: val_mDice did not improve from 0.69049
Epoch 27/300
 - 20s - loss: 0.6989 - acc: 0.9663 - mDice: 0.7664 - val_loss: 1.3200 - val_acc: 0.9710 - val_mDice: 0.6859

Epoch 00027: val_mDice did not improve from 0.69049
Epoch 28/300
 - 21s - loss: 0.6971 - acc: 0.9663 - mDice: 0.7669 - val_loss: 1.3288 - val_acc: 0.9710 - val_mDice: 0.6910

Epoch 00028: val_mDice improved from 0.69049 to 0.69101, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 29/300
 - 20s - loss: 0.6941 - acc: 0.9664 - mDice: 0.7679 - val_loss: 1.3375 - val_acc: 0.9711 - val_mDice: 0.6880

Epoch 00029: val_mDice did not improve from 0.69101
Epoch 30/300
 - 21s - loss: 0.6920 - acc: 0.9664 - mDice: 0.7686 - val_loss: 1.3396 - val_acc: 0.9714 - val_mDice: 0.6876

Epoch 00030: val_mDice did not improve from 0.69101
Epoch 31/300
 - 20s - loss: 0.6911 - acc: 0.9665 - mDice: 0.7690 - val_loss: 1.3449 - val_acc: 0.9712 - val_mDice: 0.6902

Epoch 00031: val_mDice did not improve from 0.69101
Epoch 32/300
 - 21s - loss: 0.6866 - acc: 0.9666 - mDice: 0.7706 - val_loss: 1.3112 - val_acc: 0.9711 - val_mDice: 0.6922

Epoch 00032: val_mDice improved from 0.69101 to 0.69218, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 33/300
 - 20s - loss: 0.6853 - acc: 0.9666 - mDice: 0.7707 - val_loss: 1.3121 - val_acc: 0.9711 - val_mDice: 0.6914

Epoch 00033: val_mDice did not improve from 0.69218
Epoch 34/300
 - 21s - loss: 0.6831 - acc: 0.9667 - mDice: 0.7716 - val_loss: 1.3755 - val_acc: 0.9710 - val_mDice: 0.6869

Epoch 00034: val_mDice did not improve from 0.69218
Epoch 35/300
 - 20s - loss: 0.6812 - acc: 0.9667 - mDice: 0.7722 - val_loss: 1.3467 - val_acc: 0.9709 - val_mDice: 0.6902

Epoch 00035: val_mDice did not improve from 0.69218
Epoch 36/300
 - 21s - loss: 0.6789 - acc: 0.9668 - mDice: 0.7730 - val_loss: 1.3403 - val_acc: 0.9709 - val_mDice: 0.6909

Epoch 00036: val_mDice did not improve from 0.69218
Epoch 37/300
 - 20s - loss: 0.6779 - acc: 0.9668 - mDice: 0.7731 - val_loss: 1.3411 - val_acc: 0.9709 - val_mDice: 0.6880

Epoch 00037: val_mDice did not improve from 0.69218
Epoch 38/300
 - 21s - loss: 0.6761 - acc: 0.9668 - mDice: 0.7739 - val_loss: 1.3499 - val_acc: 0.9712 - val_mDice: 0.6887

Epoch 00038: val_mDice did not improve from 0.69218
Epoch 39/300
 - 21s - loss: 0.6727 - acc: 0.9669 - mDice: 0.7752 - val_loss: 1.3354 - val_acc: 0.9707 - val_mDice: 0.6916

Epoch 00039: val_mDice did not improve from 0.69218
Epoch 40/300
 - 21s - loss: 0.6719 - acc: 0.9670 - mDice: 0.7753 - val_loss: 1.3570 - val_acc: 0.9711 - val_mDice: 0.6873

Epoch 00040: val_mDice did not improve from 0.69218
Epoch 41/300
 - 21s - loss: 0.6705 - acc: 0.9670 - mDice: 0.7758 - val_loss: 1.3492 - val_acc: 0.9707 - val_mDice: 0.6886

Epoch 00041: val_mDice did not improve from 0.69218
Epoch 42/300
 - 21s - loss: 0.6690 - acc: 0.9671 - mDice: 0.7763 - val_loss: 1.3896 - val_acc: 0.9712 - val_mDice: 0.6920

Epoch 00042: val_mDice did not improve from 0.69218
Epoch 43/300
 - 20s - loss: 0.6670 - acc: 0.9671 - mDice: 0.7769 - val_loss: 1.3876 - val_acc: 0.9712 - val_mDice: 0.6900

Epoch 00043: val_mDice did not improve from 0.69218
Epoch 44/300
 - 21s - loss: 0.6657 - acc: 0.9671 - mDice: 0.7771 - val_loss: 1.3421 - val_acc: 0.9715 - val_mDice: 0.6905

Epoch 00044: val_mDice did not improve from 0.69218
Epoch 45/300
 - 21s - loss: 0.6641 - acc: 0.9671 - mDice: 0.7776 - val_loss: 1.3755 - val_acc: 0.9712 - val_mDice: 0.6918

Epoch 00045: val_mDice did not improve from 0.69218
Epoch 46/300
 - 21s - loss: 0.6631 - acc: 0.9672 - mDice: 0.7784 - val_loss: 1.3905 - val_acc: 0.9711 - val_mDice: 0.6894

Epoch 00046: val_mDice did not improve from 0.69218
Epoch 47/300
 - 21s - loss: 0.6604 - acc: 0.9673 - mDice: 0.7791 - val_loss: 1.3806 - val_acc: 0.9712 - val_mDice: 0.6881

Epoch 00047: val_mDice did not improve from 0.69218
Epoch 48/300
 - 20s - loss: 0.6591 - acc: 0.9673 - mDice: 0.7794 - val_loss: 1.4034 - val_acc: 0.9709 - val_mDice: 0.6894

Epoch 00048: val_mDice did not improve from 0.69218
Epoch 49/300
 - 21s - loss: 0.6580 - acc: 0.9673 - mDice: 0.7801 - val_loss: 1.4287 - val_acc: 0.9708 - val_mDice: 0.6867

Epoch 00049: val_mDice did not improve from 0.69218
Epoch 50/300
 - 21s - loss: 0.6565 - acc: 0.9673 - mDice: 0.7803 - val_loss: 1.3907 - val_acc: 0.9704 - val_mDice: 0.6852

Epoch 00050: val_mDice did not improve from 0.69218
Epoch 51/300
 - 21s - loss: 0.6561 - acc: 0.9674 - mDice: 0.7808 - val_loss: 1.4213 - val_acc: 0.9709 - val_mDice: 0.6871

Epoch 00051: val_mDice did not improve from 0.69218
Epoch 52/300
 - 21s - loss: 0.6551 - acc: 0.9674 - mDice: 0.7811 - val_loss: 1.4029 - val_acc: 0.9701 - val_mDice: 0.6907

Epoch 00052: val_mDice did not improve from 0.69218
Epoch 53/300
 - 21s - loss: 0.6520 - acc: 0.9674 - mDice: 0.7819 - val_loss: 1.3891 - val_acc: 0.9709 - val_mDice: 0.6939

Epoch 00053: val_mDice improved from 0.69218 to 0.69389, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 54/300
 - 21s - loss: 0.6527 - acc: 0.9674 - mDice: 0.7819 - val_loss: 1.3650 - val_acc: 0.9713 - val_mDice: 0.6917

Epoch 00054: val_mDice did not improve from 0.69389
Epoch 55/300
 - 21s - loss: 0.6500 - acc: 0.9675 - mDice: 0.7828 - val_loss: 1.4006 - val_acc: 0.9715 - val_mDice: 0.6942

Epoch 00055: val_mDice improved from 0.69389 to 0.69415, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 56/300
 - 21s - loss: 0.6499 - acc: 0.9675 - mDice: 0.7829 - val_loss: 1.3808 - val_acc: 0.9711 - val_mDice: 0.6905

Epoch 00056: val_mDice did not improve from 0.69415
Epoch 57/300
 - 21s - loss: 0.6489 - acc: 0.9675 - mDice: 0.7832 - val_loss: 1.3886 - val_acc: 0.9707 - val_mDice: 0.6959

Epoch 00057: val_mDice improved from 0.69415 to 0.69587, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 58/300
 - 20s - loss: 0.6493 - acc: 0.9675 - mDice: 0.7828 - val_loss: 1.4269 - val_acc: 0.9710 - val_mDice: 0.6907

Epoch 00058: val_mDice did not improve from 0.69587
Epoch 59/300
 - 21s - loss: 0.6462 - acc: 0.9676 - mDice: 0.7840 - val_loss: 1.4218 - val_acc: 0.9707 - val_mDice: 0.6928

Epoch 00059: val_mDice did not improve from 0.69587
Epoch 60/300
 - 20s - loss: 0.6448 - acc: 0.9676 - mDice: 0.7842 - val_loss: 1.4182 - val_acc: 0.9710 - val_mDice: 0.6911

Epoch 00060: val_mDice did not improve from 0.69587
Epoch 61/300
 - 21s - loss: 0.6447 - acc: 0.9676 - mDice: 0.7842 - val_loss: 1.4210 - val_acc: 0.9708 - val_mDice: 0.6890

Epoch 00061: val_mDice did not improve from 0.69587
Epoch 62/300
 - 20s - loss: 0.6429 - acc: 0.9677 - mDice: 0.7849 - val_loss: 1.4204 - val_acc: 0.9708 - val_mDice: 0.6903

Epoch 00062: val_mDice did not improve from 0.69587
Epoch 63/300
 - 21s - loss: 0.6431 - acc: 0.9677 - mDice: 0.7851 - val_loss: 1.4057 - val_acc: 0.9714 - val_mDice: 0.6914

Epoch 00063: val_mDice did not improve from 0.69587
Epoch 64/300
 - 21s - loss: 0.6417 - acc: 0.9677 - mDice: 0.7855 - val_loss: 1.4414 - val_acc: 0.9709 - val_mDice: 0.6920

Epoch 00064: val_mDice did not improve from 0.69587
Epoch 65/300
 - 20s - loss: 0.6406 - acc: 0.9677 - mDice: 0.7860 - val_loss: 1.4061 - val_acc: 0.9713 - val_mDice: 0.6897

Epoch 00065: val_mDice did not improve from 0.69587
Epoch 66/300
 - 21s - loss: 0.6404 - acc: 0.9677 - mDice: 0.7856 - val_loss: 1.4290 - val_acc: 0.9707 - val_mDice: 0.6926

Epoch 00066: val_mDice did not improve from 0.69587
Epoch 67/300
 - 21s - loss: 0.6379 - acc: 0.9678 - mDice: 0.7866 - val_loss: 1.4080 - val_acc: 0.9714 - val_mDice: 0.6939

Epoch 00067: val_mDice did not improve from 0.69587
Epoch 68/300
 - 21s - loss: 0.6394 - acc: 0.9678 - mDice: 0.7861 - val_loss: 1.4026 - val_acc: 0.9707 - val_mDice: 0.6878

Epoch 00068: val_mDice did not improve from 0.69587
Epoch 69/300
 - 21s - loss: 0.6363 - acc: 0.9678 - mDice: 0.7870 - val_loss: 1.4288 - val_acc: 0.9708 - val_mDice: 0.6899

Epoch 00069: val_mDice did not improve from 0.69587
Epoch 70/300
 - 21s - loss: 0.6364 - acc: 0.9678 - mDice: 0.7872 - val_loss: 1.4575 - val_acc: 0.9704 - val_mDice: 0.6915

Epoch 00070: val_mDice did not improve from 0.69587
Epoch 71/300
 - 20s - loss: 0.6356 - acc: 0.9678 - mDice: 0.7875 - val_loss: 1.4299 - val_acc: 0.9711 - val_mDice: 0.6916

Epoch 00071: val_mDice did not improve from 0.69587
Epoch 72/300
 - 20s - loss: 0.6338 - acc: 0.9679 - mDice: 0.7881 - val_loss: 1.4191 - val_acc: 0.9713 - val_mDice: 0.6947

Epoch 00072: val_mDice did not improve from 0.69587
Epoch 73/300
 - 20s - loss: 0.6340 - acc: 0.9679 - mDice: 0.7881 - val_loss: 1.4327 - val_acc: 0.9707 - val_mDice: 0.6914

Epoch 00073: val_mDice did not improve from 0.69587
Epoch 74/300
 - 21s - loss: 0.6334 - acc: 0.9679 - mDice: 0.7883 - val_loss: 1.4480 - val_acc: 0.9711 - val_mDice: 0.6924

Epoch 00074: val_mDice did not improve from 0.69587
Epoch 75/300
 - 21s - loss: 0.6330 - acc: 0.9679 - mDice: 0.7883 - val_loss: 1.4522 - val_acc: 0.9707 - val_mDice: 0.6895

Epoch 00075: val_mDice did not improve from 0.69587
Epoch 76/300
 - 21s - loss: 0.6325 - acc: 0.9679 - mDice: 0.7884 - val_loss: 1.3949 - val_acc: 0.9710 - val_mDice: 0.6907

Epoch 00076: val_mDice did not improve from 0.69587
Epoch 77/300
 - 21s - loss: 0.6309 - acc: 0.9680 - mDice: 0.7890 - val_loss: 1.4346 - val_acc: 0.9710 - val_mDice: 0.6923

Epoch 00077: val_mDice did not improve from 0.69587
Epoch 78/300
 - 20s - loss: 0.6310 - acc: 0.9680 - mDice: 0.7889 - val_loss: 1.4213 - val_acc: 0.9713 - val_mDice: 0.6876

Epoch 00078: val_mDice did not improve from 0.69587
Epoch 79/300
 - 21s - loss: 0.6294 - acc: 0.9680 - mDice: 0.7895 - val_loss: 1.4321 - val_acc: 0.9707 - val_mDice: 0.6948

Epoch 00079: val_mDice did not improve from 0.69587
Epoch 80/300
 - 20s - loss: 0.6279 - acc: 0.9680 - mDice: 0.7900 - val_loss: 1.4217 - val_acc: 0.9710 - val_mDice: 0.6954

Epoch 00080: val_mDice did not improve from 0.69587
Epoch 81/300
 - 21s - loss: 0.6288 - acc: 0.9680 - mDice: 0.7898 - val_loss: 1.4720 - val_acc: 0.9706 - val_mDice: 0.6931

Epoch 00081: val_mDice did not improve from 0.69587
Epoch 82/300
 - 20s - loss: 0.6280 - acc: 0.9680 - mDice: 0.7901 - val_loss: 1.4421 - val_acc: 0.9707 - val_mDice: 0.6891

Epoch 00082: val_mDice did not improve from 0.69587
Epoch 83/300
 - 21s - loss: 0.6272 - acc: 0.9681 - mDice: 0.7901 - val_loss: 1.4887 - val_acc: 0.9708 - val_mDice: 0.6872

Epoch 00083: val_mDice did not improve from 0.69587
Epoch 84/300
 - 20s - loss: 0.6269 - acc: 0.9681 - mDice: 0.7904 - val_loss: 1.4070 - val_acc: 0.9709 - val_mDice: 0.6932

Epoch 00084: val_mDice did not improve from 0.69587
Epoch 85/300
 - 21s - loss: 0.6264 - acc: 0.9681 - mDice: 0.7906 - val_loss: 1.4636 - val_acc: 0.9713 - val_mDice: 0.6949

Epoch 00085: val_mDice did not improve from 0.69587
Epoch 86/300
 - 20s - loss: 0.6251 - acc: 0.9681 - mDice: 0.7908 - val_loss: 1.4621 - val_acc: 0.9703 - val_mDice: 0.6907

Epoch 00086: val_mDice did not improve from 0.69587
Epoch 87/300
 - 20s - loss: 0.6240 - acc: 0.9681 - mDice: 0.7913 - val_loss: 1.4600 - val_acc: 0.9705 - val_mDice: 0.6921

Epoch 00087: val_mDice did not improve from 0.69587
Restoring model weights from the end of the best epoch
Epoch 00087: early stopping
{'val_loss': [1.045458732884823, 1.0932696507704305, 1.0939392454375632, 1.136665481858272, 1.153075064931597, 1.170023860158147, 1.185368762973653, 1.189095575606961, 1.1854620002871774, 1.2031076527470328, 1.2375146311682623, 1.2416092332265551, 1.2490825386121005, 1.2343618423321994, 1.276444595752996, 1.2516694183975574, 1.2504033103412644, 1.2939930330372225, 1.270562750492317, 1.2798717334924057, 1.3196893410332875, 1.290609242833259, 1.2930709109803424, 1.321652915486958, 1.3335545109045552, 1.3363474381936562, 1.3200460985360458, 1.3287782397509542, 1.3374769360862644, 1.3395513954309883, 1.3448539235877255, 1.3112239515459216, 1.3121173257533187, 1.3755283254454034, 1.3466636365905231, 1.3402663064279152, 1.341079347382181, 1.3498979415672627, 1.3353584848315558, 1.35697581639161, 1.3492420051088665, 1.3895666907652924, 1.3875770794378746, 1.3421405530804373, 1.3754791909663373, 1.3905096974612203, 1.3806174648314369, 1.40339174509969, 1.4287464503615979, 1.3907177922348257, 1.4212969458701528, 1.402865530901434, 1.3891061443159478, 1.3649695356840332, 1.4005908077748126, 1.3808146673740107, 1.3886131250720226, 1.4268628018242973, 1.4218076288009702, 1.4182283215541176, 1.4210363792176413, 1.4204256750902153, 1.4056573655154254, 1.4413969102513375, 1.4060546440507455, 1.4290170876676052, 1.408047478171389, 1.4025562463119683, 1.4288118249200945, 1.4575312851018427, 1.4298911683807962, 1.4190741017978623, 1.4327404489848605, 1.4480416811571157, 1.452171154003806, 1.3948899502919907, 1.43458016268535, 1.4212562361279049, 1.4321124369573408, 1.4217436350450552, 1.4719609077372606, 1.4420551940741226, 1.4887212441234514, 1.4070472399700562, 1.4635953834158113, 1.462072646295702, 1.4599887316751665], 'val_acc': [0.9715706593281513, 0.9718599701480055, 0.9717762767117917, 0.9716420675336624, 0.9712899414728967, 0.9711902201405823, 0.9710498433775884, 0.9713958430474329, 0.9712246932578363, 0.9712727051444036, 0.9714081287384033, 0.9710880331551246, 0.9707876031923478, 0.9712074534773366, 0.9710597168064485, 0.9716445083323593, 0.9715546703246569, 0.9711077415805065, 0.971384747608288, 0.971490630772123, 0.9709402778434016, 0.9710683265708128, 0.9715300257601793, 0.9712382525090545, 0.971078178597233, 0.9706226419297885, 0.9709956908318067, 0.9709981523425423, 0.9710683249598765, 0.9714426071487339, 0.9712246898058299, 0.9710609390468671, 0.971101561108151, 0.9709784639387977, 0.9708516206520404, 0.9709365869581009, 0.9708516547118374, 0.9711791373587944, 0.9707137284131584, 0.9710757127139559, 0.9706989752279745, 0.9711803856043282, 0.9711520609708366, 0.971457365857128, 0.971227139119476, 0.9711113981758766, 0.9712135876928057, 0.9708984284787565, 0.9707580712771323, 0.9704256363817163, 0.9708959628256131, 0.9701042920926363, 0.9708639417836105, 0.9712874804224286, 0.971488154993094, 0.9710991134054412, 0.9707396037330038, 0.970990746868163, 0.9707445173189907, 0.9709550524310255, 0.970802387215456, 0.9708405735409859, 0.9713539653763348, 0.970948898193919, 0.971256696809673, 0.9707408209104795, 0.9714130556721485, 0.9706669507339655, 0.9708454772312208, 0.9704059491286406, 0.9710831032296405, 0.9713477954901323, 0.9706977366480588, 0.9711446600991327, 0.9707334223401132, 0.9709969176749005, 0.9709710748039158, 0.9712763921174303, 0.9706915929971054, 0.9710350860499968, 0.9705623119033902, 0.9706854399106677, 0.9707531565404767, 0.9708541102390952, 0.9712850129282152, 0.9703123845649042, 0.9705056817375095], 'val_mDice': [0.669371534498502, 0.669720660765659, 0.6766781922012682, 0.6751764989727712, 0.6803926972808986, 0.685391007242976, 0.6800892274812381, 0.6795408148102778, 0.6851897198260981, 0.6788503479313206, 0.6824088004565146, 0.6826839870467609, 0.6804962206531215, 0.6904903880417577, 0.6869975494141745, 0.6862871748139959, 0.6863971594217662, 0.6880442553045206, 0.6879105717519075, 0.6899976999603183, 0.6893759823213673, 0.6861350642207967, 0.6854344668535652, 0.6878072681574288, 0.6889843439043258, 0.685040185120115, 0.6859424180966086, 0.6910110139018321, 0.6880449047420015, 0.6875552238184512, 0.6902063079322167, 0.6921802625692949, 0.6914196028212323, 0.6868744773294014, 0.6901529217318678, 0.6909454674334139, 0.6879770484209982, 0.6887353048821674, 0.6915919191588766, 0.6873124264842295, 0.6885601788414031, 0.6920386486071878, 0.6900490163375972, 0.6905161906393338, 0.6917998915013199, 0.689413055029615, 0.6881113452800913, 0.6894235647783317, 0.6866514475649388, 0.6852121198959793, 0.6871392084824993, 0.6906725285596369, 0.6938860803037077, 0.6916706152404137, 0.6941535113861201, 0.6905025970981848, 0.6958698356473768, 0.6906711028809713, 0.6927777885470151, 0.6910872850639019, 0.6890035432738226, 0.6902504632371733, 0.6913841092908705, 0.6920203152310433, 0.6897381935340557, 0.6925713576405205, 0.693931300897856, 0.6878492344300259, 0.689920381689624, 0.6915481417335598, 0.6916421373378356, 0.6947120968899672, 0.6913686067901523, 0.692380715521146, 0.689547505848196, 0.6906933117096948, 0.6923331489434114, 0.6876398545894844, 0.6948131055905552, 0.6953532005368973, 0.6930553540299758, 0.6890813533403699, 0.6871905264707145, 0.6932181154438888, 0.6948826260088034, 0.6906706854183241, 0.692054286426559], 'loss': [1.1243486192290066, 0.9689937474093769, 0.9160094321385821, 0.880370070093182, 0.8548580716231797, 0.8343163917069805, 0.8185506758559608, 0.8057497210231629, 0.7943790221023588, 0.7829637187807079, 0.774505578734449, 0.7671887103785616, 0.7603839564921671, 0.7535231934801909, 0.7478171269145361, 0.7417902961907243, 0.7359628642601146, 0.7305247465815893, 0.7262717920178854, 0.7233564166361065, 0.7197383265637416, 0.7157288922721559, 0.7121309477925287, 0.7099582243098062, 0.705911480689041, 0.7029612659624292, 0.6989149866130598, 0.697076941943725, 0.6941252697606558, 0.6919951413040805, 0.6910521213587469, 0.6866152131830463, 0.6853430611765312, 0.6831195785468193, 0.6811704571398012, 0.6789152355603197, 0.6779370728925477, 0.6760854460066346, 0.6726933817533167, 0.671939167024499, 0.6704566026300844, 0.6690359984340624, 0.6670341692224578, 0.6657018482678558, 0.6640918192143219, 0.6630658942250496, 0.6604212655566208, 0.6591056198858092, 0.6580178343490816, 0.6564801793728218, 0.6560649035632591, 0.6551319434544913, 0.6520204505164026, 0.6527126195911529, 0.6499577750507955, 0.6499052676322397, 0.6488572572520175, 0.6492761431602805, 0.6462245235700788, 0.6447829211762687, 0.6447072674447962, 0.6429365059522982, 0.6430874007348796, 0.6416784044035541, 0.6405646387056192, 0.6403708169611295, 0.637854832781559, 0.6393604491455289, 0.636280084207968, 0.6363508189920573, 0.6355529877028693, 0.6337891761187009, 0.634004558697781, 0.633408428370515, 0.6330343202725796, 0.6324569788319264, 0.6309208615549234, 0.63100887208316, 0.629444939069418, 0.6278918199871136, 0.628780895453939, 0.6279858031591691, 0.6271994039424477, 0.626893750000411, 0.626396247133144, 0.6251340514817898, 0.6239713175529986], 'acc': [0.9575368966961008, 0.9601388269037835, 0.961243236738481, 0.9620021494438338, 0.9625714227082047, 0.9630795717108759, 0.9634495328535857, 0.9637507757210019, 0.9640346808035399, 0.9643125019671209, 0.964514036781014, 0.9646787223833683, 0.9648514811092839, 0.9649692300121075, 0.9651460040477295, 0.9652868264704347, 0.965424897718292, 0.9655413338995131, 0.9656267834787777, 0.9656944866638291, 0.9658175838529605, 0.9658655071825442, 0.9659498754596644, 0.9660294267087941, 0.9661329424473997, 0.9662297621258878, 0.9663087275192028, 0.96633243017189, 0.9664012601413983, 0.9664440480559175, 0.9664812526486398, 0.9665780241823191, 0.9666230271542593, 0.9666643509070978, 0.9667254727370658, 0.9667596206209955, 0.9668254958511753, 0.966846321645266, 0.9669356872490392, 0.9670001026106227, 0.9670111920069976, 0.9670511758516014, 0.9670966211897569, 0.9671267635714578, 0.967132889635355, 0.9671578953850369, 0.9672583383593236, 0.9672776706825064, 0.9672926367189116, 0.967304237159968, 0.9673727438070971, 0.9673889315242837, 0.9674242692587779, 0.967425737704835, 0.9674779377955813, 0.9674972703016337, 0.9675454294068936, 0.967515962278178, 0.9675737316990104, 0.9676104899154456, 0.9676468510825246, 0.9676753155387229, 0.9676860201837304, 0.9677237077419237, 0.9677319073547312, 0.9677135645374457, 0.9677843767908101, 0.9677569368339368, 0.9678221587816224, 0.967837997422277, 0.9678460131312763, 0.9678789366218571, 0.9678785524974717, 0.9679367866947686, 0.9679102650878767, 0.9679476876395393, 0.9679558390008641, 0.9679976052679553, 0.9679697005346174, 0.9680071411468422, 0.9680118489602445, 0.9680377629302314, 0.9680556418483917, 0.9680762086075189, 0.9681173811118569, 0.9681002484567371, 0.9681365858594602], 'mDice': [0.6468107346712687, 0.6812747655163385, 0.6969839400712879, 0.7078083994516676, 0.7158090452867663, 0.7225026870001146, 0.727247834275292, 0.7314303840868633, 0.7351449336649106, 0.738662547480699, 0.7416186352578834, 0.7439154789878747, 0.7458737642275042, 0.748324174891257, 0.7504034694245423, 0.752444961154699, 0.7543404678844013, 0.7559318144216335, 0.7573513231953561, 0.7583951411674298, 0.7595952585257364, 0.7606998512105643, 0.7620800157004171, 0.762778746210513, 0.7640843634199785, 0.7649209144613638, 0.7663855601286208, 0.7669143424397594, 0.767925776413061, 0.7686476052022928, 0.7690338365582049, 0.7705748730677807, 0.7707201040550017, 0.7715843169003591, 0.7721511462131947, 0.7730045153367658, 0.773089597343532, 0.7738940719360109, 0.7752198600700249, 0.7752573924850279, 0.7758329915048573, 0.7763392211569815, 0.7769494505603292, 0.7770759005417516, 0.777586677253906, 0.7783886960540348, 0.7790923730813019, 0.7794381008725016, 0.7800909934449158, 0.7803195350495556, 0.7807725431354902, 0.7810514684991172, 0.7819134400408944, 0.7819250049007275, 0.7827522448166471, 0.7829292718068143, 0.7831763784698792, 0.7828347196301714, 0.7840231448469632, 0.7842190951090428, 0.7842405671908608, 0.784903852634997, 0.7851228656341754, 0.7855442519724171, 0.7859672182571757, 0.7856068305948513, 0.7865776707528781, 0.7861080116863216, 0.7870185741323164, 0.78716097591592, 0.7874879041509295, 0.7881405011274977, 0.7880786628727324, 0.7882834390698916, 0.7883453689946368, 0.7884400445560946, 0.789019027556211, 0.7889478931887137, 0.7894977873152528, 0.7899932087898045, 0.78975398554691, 0.7900645801542866, 0.7900932410082139, 0.7903956456012664, 0.7906224111882132, 0.7908358892999472, 0.7912686599555333]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:02<00:07,  2.65s/it]predicting test subjects:  50%|█████     | 2/4 [00:04<00:04,  2.33s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:05<00:02,  2.12s/it]predicting test subjects: 100%|██████████| 4/4 [00:07<00:00,  2.04s/it]
predicting train subjects:   0%|          | 0/456 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/456 [00:01<13:37,  1.80s/it]predicting train subjects:   0%|          | 2/456 [00:03<13:25,  1.77s/it]predicting train subjects:   1%|          | 3/456 [00:05<13:04,  1.73s/it]predicting train subjects:   1%|          | 4/456 [00:06<12:24,  1.65s/it]predicting train subjects:   1%|          | 5/456 [00:08<13:31,  1.80s/it]predicting train subjects:   1%|▏         | 6/456 [00:10<13:23,  1.79s/it]predicting train subjects:   2%|▏         | 7/456 [00:11<12:25,  1.66s/it]predicting train subjects:   2%|▏         | 8/456 [00:12<10:42,  1.43s/it]predicting train subjects:   2%|▏         | 9/456 [00:14<11:20,  1.52s/it]predicting train subjects:   2%|▏         | 10/456 [00:16<12:20,  1.66s/it]predicting train subjects:   2%|▏         | 11/456 [00:18<12:53,  1.74s/it]predicting train subjects:   3%|▎         | 12/456 [00:19<11:08,  1.51s/it]predicting train subjects:   3%|▎         | 13/456 [00:20<11:17,  1.53s/it]predicting train subjects:   3%|▎         | 14/456 [00:22<11:43,  1.59s/it]predicting train subjects:   3%|▎         | 15/456 [00:23<10:27,  1.42s/it]predicting train subjects:   4%|▎         | 16/456 [00:25<11:26,  1.56s/it]predicting train subjects:   4%|▎         | 17/456 [00:27<12:42,  1.74s/it]predicting train subjects:   4%|▍         | 18/456 [00:29<12:35,  1.72s/it]predicting train subjects:   4%|▍         | 19/456 [00:31<12:29,  1.72s/it]predicting train subjects:   4%|▍         | 20/456 [00:32<11:53,  1.64s/it]predicting train subjects:   5%|▍         | 21/456 [00:34<11:53,  1.64s/it]predicting train subjects:   5%|▍         | 22/456 [00:35<12:06,  1.67s/it]predicting train subjects:   5%|▌         | 23/456 [00:37<12:18,  1.71s/it]predicting train subjects:   5%|▌         | 24/456 [00:38<10:32,  1.46s/it]predicting train subjects:   5%|▌         | 25/456 [00:40<11:16,  1.57s/it]predicting train subjects:   6%|▌         | 26/456 [00:42<11:29,  1.60s/it]predicting train subjects:   6%|▌         | 27/456 [00:43<11:39,  1.63s/it]predicting train subjects:   6%|▌         | 28/456 [00:45<11:40,  1.64s/it]predicting train subjects:   6%|▋         | 29/456 [00:47<11:37,  1.63s/it]predicting train subjects:   7%|▋         | 30/456 [00:48<11:40,  1.64s/it]predicting train subjects:   7%|▋         | 31/456 [00:50<11:52,  1.68s/it]predicting train subjects:   7%|▋         | 32/456 [00:52<12:08,  1.72s/it]predicting train subjects:   7%|▋         | 33/456 [00:54<12:17,  1.74s/it]predicting train subjects:   7%|▋         | 34/456 [00:55<12:20,  1.76s/it]predicting train subjects:   8%|▊         | 35/456 [00:57<12:24,  1.77s/it]predicting train subjects:   8%|▊         | 36/456 [00:59<12:19,  1.76s/it]predicting train subjects:   8%|▊         | 37/456 [01:01<12:31,  1.79s/it]predicting train subjects:   8%|▊         | 38/456 [01:03<12:26,  1.79s/it]predicting train subjects:   9%|▊         | 39/456 [01:04<12:24,  1.78s/it]predicting train subjects:   9%|▉         | 40/456 [01:06<12:28,  1.80s/it]predicting train subjects:   9%|▉         | 41/456 [01:08<12:24,  1.79s/it]predicting train subjects:   9%|▉         | 42/456 [01:10<12:16,  1.78s/it]predicting train subjects:   9%|▉         | 43/456 [01:12<12:24,  1.80s/it]predicting train subjects:  10%|▉         | 44/456 [01:14<12:41,  1.85s/it]predicting train subjects:  10%|▉         | 45/456 [01:16<12:46,  1.87s/it]predicting train subjects:  10%|█         | 46/456 [01:17<12:36,  1.85s/it]predicting train subjects:  10%|█         | 47/456 [01:19<12:33,  1.84s/it]predicting train subjects:  11%|█         | 48/456 [01:21<12:30,  1.84s/it]predicting train subjects:  11%|█         | 49/456 [01:23<12:34,  1.85s/it]predicting train subjects:  11%|█         | 50/456 [01:25<12:32,  1.85s/it]predicting train subjects:  11%|█         | 51/456 [01:27<12:39,  1.88s/it]predicting train subjects:  11%|█▏        | 52/456 [01:29<12:40,  1.88s/it]predicting train subjects:  12%|█▏        | 53/456 [01:30<12:34,  1.87s/it]predicting train subjects:  12%|█▏        | 54/456 [01:32<12:31,  1.87s/it]predicting train subjects:  12%|█▏        | 55/456 [01:34<12:31,  1.87s/it]predicting train subjects:  12%|█▏        | 56/456 [01:36<12:23,  1.86s/it]predicting train subjects:  12%|█▎        | 57/456 [01:38<12:23,  1.86s/it]predicting train subjects:  13%|█▎        | 58/456 [01:40<12:10,  1.83s/it]predicting train subjects:  13%|█▎        | 59/456 [01:41<12:06,  1.83s/it]predicting train subjects:  13%|█▎        | 60/456 [01:43<12:17,  1.86s/it]predicting train subjects:  13%|█▎        | 61/456 [01:45<12:14,  1.86s/it]predicting train subjects:  14%|█▎        | 62/456 [01:47<12:16,  1.87s/it]predicting train subjects:  14%|█▍        | 63/456 [01:49<12:15,  1.87s/it]predicting train subjects:  14%|█▍        | 64/456 [01:51<12:21,  1.89s/it]predicting train subjects:  14%|█▍        | 65/456 [01:53<12:17,  1.89s/it]predicting train subjects:  14%|█▍        | 66/456 [01:55<12:09,  1.87s/it]predicting train subjects:  15%|█▍        | 67/456 [01:57<12:16,  1.89s/it]predicting train subjects:  15%|█▍        | 68/456 [01:58<12:15,  1.90s/it]predicting train subjects:  15%|█▌        | 69/456 [02:00<12:09,  1.88s/it]predicting train subjects:  15%|█▌        | 70/456 [02:02<12:11,  1.89s/it]predicting train subjects:  16%|█▌        | 71/456 [02:04<12:06,  1.89s/it]predicting train subjects:  16%|█▌        | 72/456 [02:06<12:08,  1.90s/it]predicting train subjects:  16%|█▌        | 73/456 [02:08<12:07,  1.90s/it]predicting train subjects:  16%|█▌        | 74/456 [02:10<12:05,  1.90s/it]predicting train subjects:  16%|█▋        | 75/456 [02:12<11:59,  1.89s/it]predicting train subjects:  17%|█▋        | 76/456 [02:14<11:51,  1.87s/it]predicting train subjects:  17%|█▋        | 77/456 [02:15<11:51,  1.88s/it]predicting train subjects:  17%|█▋        | 78/456 [02:17<11:55,  1.89s/it]predicting train subjects:  17%|█▋        | 79/456 [02:18<10:02,  1.60s/it]predicting train subjects:  18%|█▊        | 80/456 [02:19<08:50,  1.41s/it]predicting train subjects:  18%|█▊        | 81/456 [02:20<07:59,  1.28s/it]predicting train subjects:  18%|█▊        | 82/456 [02:21<07:25,  1.19s/it]predicting train subjects:  18%|█▊        | 83/456 [02:22<06:59,  1.12s/it]predicting train subjects:  18%|█▊        | 84/456 [02:23<06:40,  1.08s/it]predicting train subjects:  19%|█▊        | 85/456 [02:24<06:27,  1.04s/it]predicting train subjects:  19%|█▉        | 86/456 [02:25<06:16,  1.02s/it]predicting train subjects:  19%|█▉        | 87/456 [02:26<06:18,  1.02s/it]predicting train subjects:  19%|█▉        | 88/456 [02:27<06:12,  1.01s/it]predicting train subjects:  20%|█▉        | 89/456 [02:28<06:04,  1.01it/s]predicting train subjects:  20%|█▉        | 90/456 [02:29<05:59,  1.02it/s]predicting train subjects:  20%|█▉        | 91/456 [02:30<05:57,  1.02it/s]predicting train subjects:  20%|██        | 92/456 [02:31<05:58,  1.02it/s]predicting train subjects:  20%|██        | 93/456 [02:32<05:55,  1.02it/s]predicting train subjects:  21%|██        | 94/456 [02:33<05:50,  1.03it/s]predicting train subjects:  21%|██        | 95/456 [02:34<05:57,  1.01it/s]predicting train subjects:  21%|██        | 96/456 [02:35<05:55,  1.01it/s]predicting train subjects:  21%|██▏       | 97/456 [02:37<07:19,  1.22s/it]predicting train subjects:  21%|██▏       | 98/456 [02:38<08:14,  1.38s/it]predicting train subjects:  22%|██▏       | 99/456 [02:40<08:56,  1.50s/it]predicting train subjects:  22%|██▏       | 100/456 [02:42<09:17,  1.57s/it]predicting train subjects:  22%|██▏       | 101/456 [02:44<09:27,  1.60s/it]predicting train subjects:  22%|██▏       | 102/456 [02:45<09:37,  1.63s/it]predicting train subjects:  23%|██▎       | 103/456 [02:47<10:13,  1.74s/it]predicting train subjects:  23%|██▎       | 104/456 [02:49<10:27,  1.78s/it]predicting train subjects:  23%|██▎       | 105/456 [02:51<10:28,  1.79s/it]predicting train subjects:  23%|██▎       | 106/456 [02:53<10:28,  1.80s/it]predicting train subjects:  23%|██▎       | 107/456 [02:55<10:42,  1.84s/it]predicting train subjects:  24%|██▎       | 108/456 [02:57<10:37,  1.83s/it]predicting train subjects:  24%|██▍       | 109/456 [02:58<10:35,  1.83s/it]predicting train subjects:  24%|██▍       | 110/456 [03:00<10:29,  1.82s/it]predicting train subjects:  24%|██▍       | 111/456 [03:02<10:23,  1.81s/it]predicting train subjects:  25%|██▍       | 112/456 [03:04<10:18,  1.80s/it]predicting train subjects:  25%|██▍       | 113/456 [03:06<10:16,  1.80s/it]predicting train subjects:  25%|██▌       | 114/456 [03:07<10:17,  1.81s/it]predicting train subjects:  25%|██▌       | 115/456 [03:09<10:21,  1.82s/it]predicting train subjects:  25%|██▌       | 116/456 [03:11<10:20,  1.82s/it]predicting train subjects:  26%|██▌       | 117/456 [03:13<10:19,  1.83s/it]predicting train subjects:  26%|██▌       | 118/456 [03:15<10:15,  1.82s/it]predicting train subjects:  26%|██▌       | 119/456 [03:17<10:23,  1.85s/it]predicting train subjects:  26%|██▋       | 120/456 [03:18<10:17,  1.84s/it]predicting train subjects:  27%|██▋       | 121/456 [03:20<10:29,  1.88s/it]predicting train subjects:  27%|██▋       | 122/456 [03:22<10:40,  1.92s/it]predicting train subjects:  27%|██▋       | 123/456 [03:24<10:31,  1.90s/it]predicting train subjects:  27%|██▋       | 124/456 [03:26<10:35,  1.92s/it]predicting train subjects:  27%|██▋       | 125/456 [03:28<10:35,  1.92s/it]predicting train subjects:  28%|██▊       | 126/456 [03:30<10:35,  1.93s/it]predicting train subjects:  28%|██▊       | 127/456 [03:32<09:58,  1.82s/it]predicting train subjects:  28%|██▊       | 128/456 [03:33<09:27,  1.73s/it]predicting train subjects:  28%|██▊       | 129/456 [03:35<09:12,  1.69s/it]predicting train subjects:  29%|██▊       | 130/456 [03:36<08:58,  1.65s/it]predicting train subjects:  29%|██▊       | 131/456 [03:38<08:45,  1.62s/it]predicting train subjects:  29%|██▉       | 132/456 [03:39<08:34,  1.59s/it]predicting train subjects:  29%|██▉       | 133/456 [03:42<09:34,  1.78s/it]predicting train subjects:  29%|██▉       | 134/456 [03:44<10:24,  1.94s/it]predicting train subjects:  30%|██▉       | 135/456 [03:46<10:55,  2.04s/it]predicting train subjects:  30%|██▉       | 136/456 [03:48<11:06,  2.08s/it]predicting train subjects:  30%|███       | 137/456 [03:51<11:14,  2.12s/it]predicting train subjects:  30%|███       | 138/456 [03:53<11:17,  2.13s/it]predicting train subjects:  30%|███       | 139/456 [03:54<10:14,  1.94s/it]predicting train subjects:  31%|███       | 140/456 [03:56<09:41,  1.84s/it]predicting train subjects:  31%|███       | 141/456 [03:57<09:08,  1.74s/it]predicting train subjects:  31%|███       | 142/456 [03:59<08:55,  1.71s/it]predicting train subjects:  31%|███▏      | 143/456 [04:01<08:38,  1.66s/it]predicting train subjects:  32%|███▏      | 144/456 [04:02<08:22,  1.61s/it]predicting train subjects:  32%|███▏      | 145/456 [04:04<08:29,  1.64s/it]predicting train subjects:  32%|███▏      | 146/456 [04:05<08:38,  1.67s/it]predicting train subjects:  32%|███▏      | 147/456 [04:07<08:47,  1.71s/it]predicting train subjects:  32%|███▏      | 148/456 [04:09<08:46,  1.71s/it]predicting train subjects:  33%|███▎      | 149/456 [04:11<08:40,  1.70s/it]predicting train subjects:  33%|███▎      | 150/456 [04:12<08:39,  1.70s/it]predicting train subjects:  33%|███▎      | 151/456 [04:14<08:41,  1.71s/it]predicting train subjects:  33%|███▎      | 152/456 [04:16<08:40,  1.71s/it]predicting train subjects:  34%|███▎      | 153/456 [04:18<08:50,  1.75s/it]predicting train subjects:  34%|███▍      | 154/456 [04:19<08:46,  1.74s/it]predicting train subjects:  34%|███▍      | 155/456 [04:21<08:47,  1.75s/it]predicting train subjects:  34%|███▍      | 156/456 [04:23<08:49,  1.77s/it]predicting train subjects:  34%|███▍      | 157/456 [04:25<08:35,  1.72s/it]predicting train subjects:  35%|███▍      | 158/456 [04:26<08:18,  1.67s/it]predicting train subjects:  35%|███▍      | 159/456 [04:28<08:24,  1.70s/it]predicting train subjects:  35%|███▌      | 160/456 [04:29<08:14,  1.67s/it]predicting train subjects:  35%|███▌      | 161/456 [04:31<08:07,  1.65s/it]predicting train subjects:  36%|███▌      | 162/456 [04:33<08:00,  1.63s/it]predicting train subjects:  36%|███▌      | 163/456 [04:34<07:08,  1.46s/it]predicting train subjects:  36%|███▌      | 164/456 [04:35<06:26,  1.32s/it]predicting train subjects:  36%|███▌      | 165/456 [04:36<06:09,  1.27s/it]predicting train subjects:  36%|███▋      | 166/456 [04:37<05:52,  1.22s/it]predicting train subjects:  37%|███▋      | 167/456 [04:38<05:36,  1.16s/it]predicting train subjects:  37%|███▋      | 168/456 [04:39<05:21,  1.12s/it]predicting train subjects:  37%|███▋      | 169/456 [04:40<05:13,  1.09s/it]predicting train subjects:  37%|███▋      | 170/456 [04:41<05:07,  1.08s/it]predicting train subjects:  38%|███▊      | 171/456 [04:42<05:05,  1.07s/it]predicting train subjects:  38%|███▊      | 172/456 [04:43<05:02,  1.07s/it]predicting train subjects:  38%|███▊      | 173/456 [04:44<04:59,  1.06s/it]predicting train subjects:  38%|███▊      | 174/456 [04:45<04:58,  1.06s/it]predicting train subjects:  38%|███▊      | 175/456 [04:46<04:56,  1.05s/it]predicting train subjects:  39%|███▊      | 176/456 [04:47<04:50,  1.04s/it]predicting train subjects:  39%|███▉      | 177/456 [04:48<04:42,  1.01s/it]predicting train subjects:  39%|███▉      | 178/456 [04:49<04:40,  1.01s/it]predicting train subjects:  39%|███▉      | 179/456 [04:50<04:38,  1.00s/it]predicting train subjects:  39%|███▉      | 180/456 [04:51<04:39,  1.01s/it]predicting train subjects:  40%|███▉      | 181/456 [04:53<06:01,  1.32s/it]predicting train subjects:  40%|███▉      | 182/456 [04:55<06:51,  1.50s/it]predicting train subjects:  40%|████      | 183/456 [04:57<07:33,  1.66s/it]predicting train subjects:  40%|████      | 184/456 [04:59<07:53,  1.74s/it]predicting train subjects:  41%|████      | 185/456 [05:01<08:05,  1.79s/it]predicting train subjects:  41%|████      | 186/456 [05:03<08:13,  1.83s/it]predicting train subjects:  41%|████      | 187/456 [05:05<08:51,  1.97s/it]predicting train subjects:  41%|████      | 188/456 [05:08<09:10,  2.05s/it]predicting train subjects:  41%|████▏     | 189/456 [05:10<09:28,  2.13s/it]predicting train subjects:  42%|████▏     | 190/456 [05:12<09:35,  2.16s/it]predicting train subjects:  42%|████▏     | 191/456 [05:14<09:43,  2.20s/it]predicting train subjects:  42%|████▏     | 192/456 [05:17<09:53,  2.25s/it]predicting train subjects:  42%|████▏     | 193/456 [05:19<09:36,  2.19s/it]predicting train subjects:  43%|████▎     | 194/456 [05:21<09:19,  2.14s/it]predicting train subjects:  43%|████▎     | 195/456 [05:23<09:05,  2.09s/it]predicting train subjects:  43%|████▎     | 196/456 [05:25<09:06,  2.10s/it]predicting train subjects:  43%|████▎     | 197/456 [05:27<09:00,  2.09s/it]predicting train subjects:  43%|████▎     | 198/456 [05:29<08:55,  2.07s/it]predicting train subjects:  44%|████▎     | 199/456 [05:31<08:39,  2.02s/it]predicting train subjects:  44%|████▍     | 200/456 [05:33<08:27,  1.98s/it]predicting train subjects:  44%|████▍     | 201/456 [05:35<08:17,  1.95s/it]predicting train subjects:  44%|████▍     | 202/456 [05:37<08:08,  1.92s/it]predicting train subjects:  45%|████▍     | 203/456 [05:38<08:01,  1.90s/it]predicting train subjects:  45%|████▍     | 204/456 [05:40<07:54,  1.88s/it]predicting train subjects:  45%|████▍     | 205/456 [05:42<07:23,  1.77s/it]predicting train subjects:  45%|████▌     | 206/456 [05:43<06:58,  1.68s/it]predicting train subjects:  45%|████▌     | 207/456 [05:45<06:41,  1.61s/it]predicting train subjects:  46%|████▌     | 208/456 [05:46<06:33,  1.59s/it]predicting train subjects:  46%|████▌     | 209/456 [05:48<06:25,  1.56s/it]predicting train subjects:  46%|████▌     | 210/456 [05:49<06:21,  1.55s/it]predicting train subjects:  46%|████▋     | 211/456 [05:51<06:36,  1.62s/it]predicting train subjects:  46%|████▋     | 212/456 [05:53<06:42,  1.65s/it]predicting train subjects:  47%|████▋     | 213/456 [05:55<06:48,  1.68s/it]predicting train subjects:  47%|████▋     | 214/456 [05:56<06:49,  1.69s/it]predicting train subjects:  47%|████▋     | 215/456 [05:58<06:54,  1.72s/it]predicting train subjects:  47%|████▋     | 216/456 [06:00<07:00,  1.75s/it]predicting train subjects:  48%|████▊     | 217/456 [06:02<07:00,  1.76s/it]predicting train subjects:  48%|████▊     | 218/456 [06:03<06:51,  1.73s/it]predicting train subjects:  48%|████▊     | 219/456 [06:05<06:56,  1.76s/it]predicting train subjects:  48%|████▊     | 220/456 [06:07<07:00,  1.78s/it]predicting train subjects:  48%|████▊     | 221/456 [06:09<06:54,  1.77s/it]predicting train subjects:  49%|████▊     | 222/456 [06:10<06:49,  1.75s/it]predicting train subjects:  49%|████▉     | 223/456 [06:12<06:58,  1.80s/it]predicting train subjects:  49%|████▉     | 224/456 [06:14<06:56,  1.80s/it]predicting train subjects:  49%|████▉     | 225/456 [06:16<07:11,  1.87s/it]predicting train subjects:  50%|████▉     | 226/456 [06:18<07:02,  1.84s/it]predicting train subjects:  50%|████▉     | 227/456 [06:20<07:00,  1.84s/it]predicting train subjects:  50%|█████     | 228/456 [06:22<07:03,  1.86s/it]predicting train subjects:  50%|█████     | 229/456 [06:23<07:00,  1.85s/it]predicting train subjects:  50%|█████     | 230/456 [06:25<06:58,  1.85s/it]predicting train subjects:  51%|█████     | 231/456 [06:27<06:50,  1.82s/it]predicting train subjects:  51%|█████     | 232/456 [06:29<06:44,  1.80s/it]predicting train subjects:  51%|█████     | 233/456 [06:31<06:58,  1.88s/it]predicting train subjects:  51%|█████▏    | 234/456 [06:33<07:06,  1.92s/it]predicting train subjects:  52%|█████▏    | 235/456 [06:35<07:42,  2.09s/it]predicting train subjects:  52%|█████▏    | 236/456 [06:37<07:34,  2.06s/it]predicting train subjects:  52%|█████▏    | 237/456 [06:39<07:25,  2.04s/it]predicting train subjects:  52%|█████▏    | 238/456 [06:41<07:26,  2.05s/it]predicting train subjects:  52%|█████▏    | 239/456 [06:44<07:44,  2.14s/it]predicting train subjects:  53%|█████▎    | 240/456 [06:46<07:54,  2.20s/it]predicting train subjects:  53%|█████▎    | 241/456 [06:48<07:59,  2.23s/it]predicting train subjects:  53%|█████▎    | 242/456 [06:51<08:07,  2.28s/it]predicting train subjects:  53%|█████▎    | 243/456 [06:53<08:01,  2.26s/it]predicting train subjects:  54%|█████▎    | 244/456 [06:56<08:10,  2.31s/it]predicting train subjects:  54%|█████▎    | 245/456 [06:58<08:11,  2.33s/it]predicting train subjects:  54%|█████▍    | 246/456 [07:00<08:03,  2.30s/it]predicting train subjects:  54%|█████▍    | 247/456 [07:02<07:13,  2.08s/it]predicting train subjects:  54%|█████▍    | 248/456 [07:03<06:38,  1.91s/it]predicting train subjects:  55%|█████▍    | 249/456 [07:05<06:18,  1.83s/it]predicting train subjects:  55%|█████▍    | 250/456 [07:06<06:00,  1.75s/it]predicting train subjects:  55%|█████▌    | 251/456 [07:08<05:43,  1.67s/it]predicting train subjects:  55%|█████▌    | 252/456 [07:09<05:33,  1.64s/it]predicting train subjects:  55%|█████▌    | 253/456 [07:12<06:06,  1.81s/it]predicting train subjects:  56%|█████▌    | 254/456 [07:14<06:29,  1.93s/it]predicting train subjects:  56%|█████▌    | 255/456 [07:16<06:42,  2.00s/it]predicting train subjects:  56%|█████▌    | 256/456 [07:18<06:49,  2.05s/it]predicting train subjects:  56%|█████▋    | 257/456 [07:20<06:55,  2.09s/it]predicting train subjects:  57%|█████▋    | 258/456 [07:23<07:02,  2.14s/it]predicting train subjects:  57%|█████▋    | 259/456 [07:24<06:28,  1.97s/it]predicting train subjects:  57%|█████▋    | 260/456 [07:26<06:02,  1.85s/it]predicting train subjects:  57%|█████▋    | 261/456 [07:27<05:45,  1.77s/it]predicting train subjects:  57%|█████▋    | 262/456 [07:29<05:31,  1.71s/it]predicting train subjects:  58%|█████▊    | 263/456 [07:30<05:20,  1.66s/it]predicting train subjects:  58%|█████▊    | 264/456 [07:32<05:10,  1.62s/it]predicting train subjects:  58%|█████▊    | 265/456 [07:34<05:08,  1.61s/it]predicting train subjects:  58%|█████▊    | 266/456 [07:35<05:18,  1.68s/it]predicting train subjects:  59%|█████▊    | 267/456 [07:37<05:20,  1.69s/it]predicting train subjects:  59%|█████▉    | 268/456 [07:39<05:20,  1.70s/it]predicting train subjects:  59%|█████▉    | 269/456 [07:41<05:16,  1.69s/it]predicting train subjects:  59%|█████▉    | 270/456 [07:42<05:14,  1.69s/it]predicting train subjects:  59%|█████▉    | 271/456 [07:44<05:16,  1.71s/it]predicting train subjects:  60%|█████▉    | 272/456 [07:46<05:15,  1.72s/it]predicting train subjects:  60%|█████▉    | 273/456 [07:47<05:16,  1.73s/it]predicting train subjects:  60%|██████    | 274/456 [07:49<05:13,  1.72s/it]predicting train subjects:  60%|██████    | 275/456 [07:51<05:12,  1.73s/it]predicting train subjects:  61%|██████    | 276/456 [07:53<05:12,  1.74s/it]predicting train subjects:  61%|██████    | 277/456 [07:54<05:07,  1.72s/it]predicting train subjects:  61%|██████    | 278/456 [07:56<04:59,  1.68s/it]predicting train subjects:  61%|██████    | 279/456 [07:58<04:51,  1.65s/it]predicting train subjects:  61%|██████▏   | 280/456 [07:59<04:50,  1.65s/it]predicting train subjects:  62%|██████▏   | 281/456 [08:01<04:50,  1.66s/it]predicting train subjects:  62%|██████▏   | 282/456 [08:02<04:45,  1.64s/it]predicting train subjects:  62%|██████▏   | 283/456 [08:03<04:11,  1.46s/it]predicting train subjects:  62%|██████▏   | 284/456 [08:04<03:48,  1.33s/it]predicting train subjects:  62%|██████▎   | 285/456 [08:06<03:33,  1.25s/it]predicting train subjects:  63%|██████▎   | 286/456 [08:07<03:22,  1.19s/it]predicting train subjects:  63%|██████▎   | 287/456 [08:08<03:15,  1.15s/it]predicting train subjects:  63%|██████▎   | 288/456 [08:09<03:08,  1.12s/it]predicting train subjects:  63%|██████▎   | 289/456 [08:10<03:03,  1.10s/it]predicting train subjects:  64%|██████▎   | 290/456 [08:11<02:59,  1.08s/it]predicting train subjects:  64%|██████▍   | 291/456 [08:12<02:55,  1.06s/it]predicting train subjects:  64%|██████▍   | 292/456 [08:13<02:56,  1.07s/it]predicting train subjects:  64%|██████▍   | 293/456 [08:14<02:53,  1.07s/it]predicting train subjects:  64%|██████▍   | 294/456 [08:15<02:55,  1.08s/it]predicting train subjects:  65%|██████▍   | 295/456 [08:16<02:49,  1.05s/it]predicting train subjects:  65%|██████▍   | 296/456 [08:17<02:47,  1.04s/it]predicting train subjects:  65%|██████▌   | 297/456 [08:18<02:43,  1.03s/it]predicting train subjects:  65%|██████▌   | 298/456 [08:19<02:42,  1.03s/it]predicting train subjects:  66%|██████▌   | 299/456 [08:20<02:41,  1.03s/it]predicting train subjects:  66%|██████▌   | 300/456 [08:21<02:38,  1.02s/it]predicting train subjects:  66%|██████▌   | 301/456 [08:23<03:29,  1.35s/it]predicting train subjects:  66%|██████▌   | 302/456 [08:25<03:53,  1.52s/it]predicting train subjects:  66%|██████▋   | 303/456 [08:27<04:14,  1.66s/it]predicting train subjects:  67%|██████▋   | 304/456 [08:29<04:26,  1.75s/it]predicting train subjects:  67%|██████▋   | 305/456 [08:31<04:33,  1.81s/it]predicting train subjects:  67%|██████▋   | 306/456 [08:33<04:42,  1.88s/it]predicting train subjects:  67%|██████▋   | 307/456 [08:35<04:58,  2.01s/it]predicting train subjects:  68%|██████▊   | 308/456 [08:38<05:12,  2.11s/it]predicting train subjects:  68%|██████▊   | 309/456 [08:40<05:14,  2.14s/it]predicting train subjects:  68%|██████▊   | 310/456 [08:42<05:13,  2.15s/it]predicting train subjects:  68%|██████▊   | 311/456 [08:44<05:13,  2.16s/it]predicting train subjects:  68%|██████▊   | 312/456 [08:47<05:12,  2.17s/it]predicting train subjects:  69%|██████▊   | 313/456 [08:49<05:02,  2.11s/it]predicting train subjects:  69%|██████▉   | 314/456 [08:51<04:58,  2.10s/it]predicting train subjects:  69%|██████▉   | 315/456 [08:53<04:50,  2.06s/it]predicting train subjects:  69%|██████▉   | 316/456 [08:55<04:44,  2.03s/it]predicting train subjects:  70%|██████▉   | 317/456 [08:57<04:44,  2.05s/it]predicting train subjects:  70%|██████▉   | 318/456 [08:59<04:39,  2.02s/it]predicting train subjects:  70%|██████▉   | 319/456 [09:00<04:25,  1.94s/it]predicting train subjects:  70%|███████   | 320/456 [09:02<04:22,  1.93s/it]predicting train subjects:  70%|███████   | 321/456 [09:04<04:16,  1.90s/it]predicting train subjects:  71%|███████   | 322/456 [09:06<04:14,  1.90s/it]predicting train subjects:  71%|███████   | 323/456 [09:08<04:06,  1.86s/it]predicting train subjects:  71%|███████   | 324/456 [09:09<04:01,  1.83s/it]predicting train subjects:  71%|███████▏  | 325/456 [09:11<03:45,  1.72s/it]predicting train subjects:  71%|███████▏  | 326/456 [09:12<03:31,  1.62s/it]predicting train subjects:  72%|███████▏  | 327/456 [09:14<03:22,  1.57s/it]predicting train subjects:  72%|███████▏  | 328/456 [09:15<03:15,  1.53s/it]predicting train subjects:  72%|███████▏  | 329/456 [09:17<03:10,  1.50s/it]predicting train subjects:  72%|███████▏  | 330/456 [09:18<03:08,  1.49s/it]predicting train subjects:  73%|███████▎  | 331/456 [09:20<03:12,  1.54s/it]predicting train subjects:  73%|███████▎  | 332/456 [09:21<03:13,  1.56s/it]predicting train subjects:  73%|███████▎  | 333/456 [09:23<03:13,  1.57s/it]predicting train subjects:  73%|███████▎  | 334/456 [09:25<03:11,  1.57s/it]predicting train subjects:  73%|███████▎  | 335/456 [09:26<03:11,  1.58s/it]predicting train subjects:  74%|███████▎  | 336/456 [09:28<03:12,  1.61s/it]predicting train subjects:  74%|███████▍  | 337/456 [09:29<03:12,  1.62s/it]predicting train subjects:  74%|███████▍  | 338/456 [09:31<03:09,  1.61s/it]predicting train subjects:  74%|███████▍  | 339/456 [09:33<03:08,  1.62s/it]predicting train subjects:  75%|███████▍  | 340/456 [09:34<03:09,  1.63s/it]predicting train subjects:  75%|███████▍  | 341/456 [09:36<03:08,  1.64s/it]predicting train subjects:  75%|███████▌  | 342/456 [09:38<03:07,  1.65s/it]predicting train subjects:  75%|███████▌  | 343/456 [09:39<03:07,  1.66s/it]predicting train subjects:  75%|███████▌  | 344/456 [09:41<03:06,  1.66s/it]predicting train subjects:  76%|███████▌  | 345/456 [09:43<03:06,  1.68s/it]predicting train subjects:  76%|███████▌  | 346/456 [09:45<03:08,  1.71s/it]predicting train subjects:  76%|███████▌  | 347/456 [09:46<03:05,  1.70s/it]predicting train subjects:  76%|███████▋  | 348/456 [09:48<03:02,  1.69s/it]predicting train subjects:  77%|███████▋  | 349/456 [09:49<02:57,  1.66s/it]predicting train subjects:  77%|███████▋  | 350/456 [09:51<02:56,  1.67s/it]predicting train subjects:  77%|███████▋  | 351/456 [09:53<02:52,  1.64s/it]predicting train subjects:  77%|███████▋  | 352/456 [09:54<02:50,  1.64s/it]predicting train subjects:  77%|███████▋  | 353/456 [09:56<02:50,  1.66s/it]predicting train subjects:  78%|███████▊  | 354/456 [09:58<02:47,  1.64s/it]predicting train subjects:  78%|███████▊  | 355/456 [09:59<02:49,  1.68s/it]predicting train subjects:  78%|███████▊  | 356/456 [10:01<02:47,  1.67s/it]predicting train subjects:  78%|███████▊  | 357/456 [10:03<02:45,  1.68s/it]predicting train subjects:  79%|███████▊  | 358/456 [10:05<02:51,  1.75s/it]predicting train subjects:  79%|███████▊  | 359/456 [10:06<02:50,  1.76s/it]predicting train subjects:  79%|███████▉  | 360/456 [10:08<02:50,  1.78s/it]predicting train subjects:  79%|███████▉  | 361/456 [10:10<02:51,  1.80s/it]predicting train subjects:  79%|███████▉  | 362/456 [10:12<02:50,  1.81s/it]predicting train subjects:  80%|███████▉  | 363/456 [10:14<02:51,  1.85s/it]predicting train subjects:  80%|███████▉  | 364/456 [10:16<02:50,  1.86s/it]predicting train subjects:  80%|████████  | 365/456 [10:18<02:46,  1.83s/it]predicting train subjects:  80%|████████  | 366/456 [10:19<02:42,  1.81s/it]predicting train subjects:  80%|████████  | 367/456 [10:21<02:31,  1.70s/it]predicting train subjects:  81%|████████  | 368/456 [10:22<02:20,  1.60s/it]predicting train subjects:  81%|████████  | 369/456 [10:24<02:13,  1.53s/it]predicting train subjects:  81%|████████  | 370/456 [10:25<02:08,  1.50s/it]predicting train subjects:  81%|████████▏ | 371/456 [10:26<02:05,  1.48s/it]predicting train subjects:  82%|████████▏ | 372/456 [10:28<02:03,  1.47s/it]predicting train subjects:  82%|████████▏ | 373/456 [10:30<02:15,  1.64s/it]predicting train subjects:  82%|████████▏ | 374/456 [10:32<02:26,  1.78s/it]predicting train subjects:  82%|████████▏ | 375/456 [10:34<02:32,  1.88s/it]predicting train subjects:  82%|████████▏ | 376/456 [10:36<02:35,  1.95s/it]predicting train subjects:  83%|████████▎ | 377/456 [10:38<02:35,  1.97s/it]predicting train subjects:  83%|████████▎ | 378/456 [10:40<02:35,  2.00s/it]predicting train subjects:  83%|████████▎ | 379/456 [10:42<02:21,  1.84s/it]predicting train subjects:  83%|████████▎ | 380/456 [10:43<02:09,  1.71s/it]predicting train subjects:  84%|████████▎ | 381/456 [10:45<02:03,  1.64s/it]predicting train subjects:  84%|████████▍ | 382/456 [10:46<01:56,  1.58s/it]predicting train subjects:  84%|████████▍ | 383/456 [10:48<01:52,  1.55s/it]predicting train subjects:  84%|████████▍ | 384/456 [10:49<01:49,  1.53s/it]predicting train subjects:  84%|████████▍ | 385/456 [10:51<01:50,  1.56s/it]predicting train subjects:  85%|████████▍ | 386/456 [10:52<01:54,  1.63s/it]predicting train subjects:  85%|████████▍ | 387/456 [10:54<01:51,  1.61s/it]predicting train subjects:  85%|████████▌ | 388/456 [10:56<01:47,  1.59s/it]predicting train subjects:  85%|████████▌ | 389/456 [10:57<01:46,  1.59s/it]predicting train subjects:  86%|████████▌ | 390/456 [10:59<01:47,  1.64s/it]predicting train subjects:  86%|████████▌ | 391/456 [11:01<01:48,  1.67s/it]predicting train subjects:  86%|████████▌ | 392/456 [11:02<01:46,  1.67s/it]predicting train subjects:  86%|████████▌ | 393/456 [11:04<01:47,  1.70s/it]predicting train subjects:  86%|████████▋ | 394/456 [11:06<01:46,  1.72s/it]predicting train subjects:  87%|████████▋ | 395/456 [11:08<01:44,  1.72s/it]predicting train subjects:  87%|████████▋ | 396/456 [11:09<01:43,  1.72s/it]predicting train subjects:  87%|████████▋ | 397/456 [11:11<01:39,  1.68s/it]predicting train subjects:  87%|████████▋ | 398/456 [11:13<01:37,  1.68s/it]predicting train subjects:  88%|████████▊ | 399/456 [11:14<01:34,  1.66s/it]predicting train subjects:  88%|████████▊ | 400/456 [11:16<01:31,  1.63s/it]predicting train subjects:  88%|████████▊ | 401/456 [11:17<01:28,  1.61s/it]predicting train subjects:  88%|████████▊ | 402/456 [11:19<01:25,  1.58s/it]predicting train subjects:  88%|████████▊ | 403/456 [11:20<01:14,  1.40s/it]predicting train subjects:  89%|████████▊ | 404/456 [11:21<01:06,  1.27s/it]predicting train subjects:  89%|████████▉ | 405/456 [11:22<01:00,  1.18s/it]predicting train subjects:  89%|████████▉ | 406/456 [11:23<00:56,  1.12s/it]predicting train subjects:  89%|████████▉ | 407/456 [11:24<00:52,  1.08s/it]predicting train subjects:  89%|████████▉ | 408/456 [11:25<00:50,  1.04s/it]predicting train subjects:  90%|████████▉ | 409/456 [11:26<00:48,  1.03s/it]predicting train subjects:  90%|████████▉ | 410/456 [11:27<00:46,  1.01s/it]predicting train subjects:  90%|█████████ | 411/456 [11:28<00:44,  1.01it/s]predicting train subjects:  90%|█████████ | 412/456 [11:29<00:43,  1.01it/s]predicting train subjects:  91%|█████████ | 413/456 [11:29<00:42,  1.01it/s]predicting train subjects:  91%|█████████ | 414/456 [11:30<00:41,  1.02it/s]predicting train subjects:  91%|█████████ | 415/456 [11:31<00:39,  1.04it/s]predicting train subjects:  91%|█████████ | 416/456 [11:32<00:38,  1.03it/s]predicting train subjects:  91%|█████████▏| 417/456 [11:33<00:37,  1.03it/s]predicting train subjects:  92%|█████████▏| 418/456 [11:34<00:36,  1.04it/s]predicting train subjects:  92%|█████████▏| 419/456 [11:35<00:35,  1.05it/s]predicting train subjects:  92%|█████████▏| 420/456 [11:36<00:34,  1.05it/s]predicting train subjects:  92%|█████████▏| 421/456 [11:38<00:42,  1.21s/it]predicting train subjects:  93%|█████████▎| 422/456 [11:40<00:48,  1.42s/it]predicting train subjects:  93%|█████████▎| 423/456 [11:42<00:51,  1.55s/it]predicting train subjects:  93%|█████████▎| 424/456 [11:44<00:53,  1.66s/it]predicting train subjects:  93%|█████████▎| 425/456 [11:45<00:52,  1.70s/it]predicting train subjects:  93%|█████████▎| 426/456 [11:47<00:52,  1.74s/it]predicting train subjects:  94%|█████████▎| 427/456 [11:49<00:52,  1.83s/it]predicting train subjects:  94%|█████████▍| 428/456 [11:51<00:53,  1.92s/it]predicting train subjects:  94%|█████████▍| 429/456 [11:54<00:53,  1.99s/it]predicting train subjects:  94%|█████████▍| 430/456 [11:56<00:52,  2.03s/it]predicting train subjects:  95%|█████████▍| 431/456 [11:58<00:50,  2.04s/it]predicting train subjects:  95%|█████████▍| 432/456 [12:00<00:48,  2.04s/it]predicting train subjects:  95%|█████████▍| 433/456 [12:02<00:46,  2.01s/it]predicting train subjects:  95%|█████████▌| 434/456 [12:04<00:44,  2.00s/it]predicting train subjects:  95%|█████████▌| 435/456 [12:06<00:41,  1.99s/it]predicting train subjects:  96%|█████████▌| 436/456 [12:08<00:39,  1.99s/it]predicting train subjects:  96%|█████████▌| 437/456 [12:10<00:36,  1.94s/it]predicting train subjects:  96%|█████████▌| 438/456 [12:12<00:35,  1.95s/it]predicting train subjects:  96%|█████████▋| 439/456 [12:13<00:32,  1.89s/it]predicting train subjects:  96%|█████████▋| 440/456 [12:15<00:29,  1.86s/it]predicting train subjects:  97%|█████████▋| 441/456 [12:17<00:27,  1.82s/it]predicting train subjects:  97%|█████████▋| 442/456 [12:19<00:25,  1.80s/it]predicting train subjects:  97%|█████████▋| 443/456 [12:20<00:23,  1.81s/it]predicting train subjects:  97%|█████████▋| 444/456 [12:22<00:21,  1.79s/it]predicting train subjects:  98%|█████████▊| 445/456 [12:24<00:18,  1.68s/it]predicting train subjects:  98%|█████████▊| 446/456 [12:25<00:15,  1.59s/it]predicting train subjects:  98%|█████████▊| 447/456 [12:26<00:13,  1.54s/it]predicting train subjects:  98%|█████████▊| 448/456 [12:28<00:11,  1.47s/it]predicting train subjects:  98%|█████████▊| 449/456 [12:29<00:09,  1.42s/it]predicting train subjects:  99%|█████████▊| 450/456 [12:30<00:08,  1.40s/it]predicting train subjects:  99%|█████████▉| 451/456 [12:32<00:07,  1.48s/it]predicting train subjects:  99%|█████████▉| 452/456 [12:34<00:06,  1.52s/it]predicting train subjects:  99%|█████████▉| 453/456 [12:35<00:04,  1.60s/it]predicting train subjects: 100%|█████████▉| 454/456 [12:37<00:03,  1.62s/it]predicting train subjects: 100%|█████████▉| 455/456 [12:39<00:01,  1.63s/it]predicting train subjects: 100%|██████████| 456/456 [12:40<00:00,  1.64s/it]
Loading train:   0%|          | 0/456 [00:00<?, ?it/s]Loading train:   0%|          | 1/456 [00:01<08:41,  1.15s/it]Loading train:   0%|          | 2/456 [00:02<08:11,  1.08s/it]Loading train:   1%|          | 3/456 [00:02<07:47,  1.03s/it]Loading train:   1%|          | 4/456 [00:03<07:19,  1.03it/s]Loading train:   1%|          | 5/456 [00:05<07:56,  1.06s/it]Loading train:   1%|▏         | 6/456 [00:05<07:36,  1.02s/it]Loading train:   2%|▏         | 7/456 [00:06<07:16,  1.03it/s]Loading train:   2%|▏         | 8/456 [00:07<06:45,  1.11it/s]Loading train:   2%|▏         | 9/456 [00:08<06:53,  1.08it/s]Loading train:   2%|▏         | 10/456 [00:09<07:37,  1.03s/it]Loading train:   2%|▏         | 11/456 [00:10<07:41,  1.04s/it]Loading train:   3%|▎         | 12/456 [00:11<07:07,  1.04it/s]Loading train:   3%|▎         | 13/456 [00:12<06:57,  1.06it/s]Loading train:   3%|▎         | 14/456 [00:13<06:43,  1.10it/s]Loading train:   3%|▎         | 15/456 [00:14<06:18,  1.16it/s]Loading train:   4%|▎         | 16/456 [00:15<06:30,  1.13it/s]Loading train:   4%|▎         | 17/456 [00:16<07:10,  1.02it/s]Loading train:   4%|▍         | 18/456 [00:17<07:10,  1.02it/s]Loading train:   4%|▍         | 19/456 [00:18<07:08,  1.02it/s]Loading train:   4%|▍         | 20/456 [00:19<06:39,  1.09it/s]Loading train:   5%|▍         | 21/456 [00:19<06:23,  1.13it/s]Loading train:   5%|▍         | 22/456 [00:20<06:23,  1.13it/s]Loading train:   5%|▌         | 23/456 [00:21<06:22,  1.13it/s]Loading train:   5%|▌         | 24/456 [00:22<05:59,  1.20it/s]Loading train:   5%|▌         | 25/456 [00:23<06:07,  1.17it/s]Loading train:   6%|▌         | 26/456 [00:24<06:01,  1.19it/s]Loading train:   6%|▌         | 27/456 [00:24<05:56,  1.20it/s]Loading train:   6%|▌         | 28/456 [00:25<06:00,  1.19it/s]Loading train:   6%|▋         | 29/456 [00:26<06:00,  1.18it/s]Loading train:   7%|▋         | 30/456 [00:27<05:59,  1.19it/s]Loading train:   7%|▋         | 31/456 [00:28<05:59,  1.18it/s]Loading train:   7%|▋         | 32/456 [00:29<05:58,  1.18it/s]Loading train:   7%|▋         | 33/456 [00:30<06:08,  1.15it/s]Loading train:   7%|▋         | 34/456 [00:30<06:01,  1.17it/s]Loading train:   8%|▊         | 35/456 [00:31<06:13,  1.13it/s]Loading train:   8%|▊         | 36/456 [00:32<05:58,  1.17it/s]Loading train:   8%|▊         | 37/456 [00:33<06:01,  1.16it/s]Loading train:   8%|▊         | 38/456 [00:34<06:06,  1.14it/s]Loading train:   9%|▊         | 39/456 [00:35<05:53,  1.18it/s]Loading train:   9%|▉         | 40/456 [00:36<06:15,  1.11it/s]Loading train:   9%|▉         | 41/456 [00:37<06:22,  1.08it/s]Loading train:   9%|▉         | 42/456 [00:37<05:55,  1.16it/s]Loading train:   9%|▉         | 43/456 [00:38<05:54,  1.16it/s]Loading train:  10%|▉         | 44/456 [00:39<06:12,  1.11it/s]Loading train:  10%|▉         | 45/456 [00:40<06:21,  1.08it/s]Loading train:  10%|█         | 46/456 [00:41<06:15,  1.09it/s]Loading train:  10%|█         | 47/456 [00:42<06:14,  1.09it/s]Loading train:  11%|█         | 48/456 [00:43<06:19,  1.08it/s]Loading train:  11%|█         | 49/456 [00:44<06:25,  1.05it/s]Loading train:  11%|█         | 50/456 [00:45<06:25,  1.05it/s]Loading train:  11%|█         | 51/456 [00:46<06:35,  1.02it/s]Loading train:  11%|█▏        | 52/456 [00:47<06:59,  1.04s/it]Loading train:  12%|█▏        | 53/456 [00:48<06:36,  1.02it/s]Loading train:  12%|█▏        | 54/456 [00:49<06:27,  1.04it/s]Loading train:  12%|█▏        | 55/456 [00:50<06:26,  1.04it/s]Loading train:  12%|█▏        | 56/456 [00:51<06:11,  1.08it/s]Loading train:  12%|█▎        | 57/456 [00:52<05:59,  1.11it/s]Loading train:  13%|█▎        | 58/456 [00:52<05:52,  1.13it/s]Loading train:  13%|█▎        | 59/456 [00:53<05:41,  1.16it/s]Loading train:  13%|█▎        | 60/456 [00:54<05:54,  1.12it/s]Loading train:  13%|█▎        | 61/456 [00:55<05:54,  1.11it/s]Loading train:  14%|█▎        | 62/456 [00:56<05:53,  1.12it/s]Loading train:  14%|█▍        | 63/456 [00:57<05:37,  1.16it/s]Loading train:  14%|█▍        | 64/456 [00:58<05:39,  1.15it/s]Loading train:  14%|█▍        | 65/456 [00:59<05:51,  1.11it/s]Loading train:  14%|█▍        | 66/456 [01:00<05:47,  1.12it/s]Loading train:  15%|█▍        | 67/456 [01:00<05:49,  1.11it/s]Loading train:  15%|█▍        | 68/456 [01:01<05:44,  1.13it/s]Loading train:  15%|█▌        | 69/456 [01:02<05:36,  1.15it/s]Loading train:  15%|█▌        | 70/456 [01:03<06:00,  1.07it/s]Loading train:  16%|█▌        | 71/456 [01:04<05:59,  1.07it/s]Loading train:  16%|█▌        | 72/456 [01:05<05:53,  1.09it/s]Loading train:  16%|█▌        | 73/456 [01:06<05:42,  1.12it/s]Loading train:  16%|█▌        | 74/456 [01:07<05:35,  1.14it/s]Loading train:  16%|█▋        | 75/456 [01:07<05:21,  1.19it/s]Loading train:  17%|█▋        | 76/456 [01:08<05:28,  1.16it/s]Loading train:  17%|█▋        | 77/456 [01:09<05:22,  1.17it/s]Loading train:  17%|█▋        | 78/456 [01:10<05:35,  1.13it/s]Loading train:  17%|█▋        | 79/456 [01:11<05:17,  1.19it/s]Loading train:  18%|█▊        | 80/456 [01:12<04:49,  1.30it/s]Loading train:  18%|█▊        | 81/456 [01:12<04:45,  1.31it/s]Loading train:  18%|█▊        | 82/456 [01:13<04:47,  1.30it/s]Loading train:  18%|█▊        | 83/456 [01:14<04:59,  1.24it/s]Loading train:  18%|█▊        | 84/456 [01:15<04:47,  1.30it/s]Loading train:  19%|█▊        | 85/456 [01:15<04:49,  1.28it/s]Loading train:  19%|█▉        | 86/456 [01:16<04:47,  1.29it/s]Loading train:  19%|█▉        | 87/456 [01:17<04:37,  1.33it/s]Loading train:  19%|█▉        | 88/456 [01:18<04:30,  1.36it/s]Loading train:  20%|█▉        | 89/456 [01:18<04:18,  1.42it/s]Loading train:  20%|█▉        | 90/456 [01:19<04:05,  1.49it/s]Loading train:  20%|█▉        | 91/456 [01:20<04:10,  1.46it/s]Loading train:  20%|██        | 92/456 [01:20<04:15,  1.42it/s]Loading train:  20%|██        | 93/456 [01:21<04:18,  1.40it/s]Loading train:  21%|██        | 94/456 [01:22<04:18,  1.40it/s]Loading train:  21%|██        | 95/456 [01:22<04:15,  1.41it/s]Loading train:  21%|██        | 96/456 [01:23<04:09,  1.44it/s]Loading train:  21%|██▏       | 97/456 [01:24<04:49,  1.24it/s]Loading train:  21%|██▏       | 98/456 [01:25<04:42,  1.27it/s]Loading train:  22%|██▏       | 99/456 [01:26<05:07,  1.16it/s]Loading train:  22%|██▏       | 100/456 [01:27<05:00,  1.18it/s]Loading train:  22%|██▏       | 101/456 [01:28<05:12,  1.14it/s]Loading train:  22%|██▏       | 102/456 [01:29<05:10,  1.14it/s]Loading train:  23%|██▎       | 103/456 [01:30<05:24,  1.09it/s]Loading train:  23%|██▎       | 104/456 [01:31<05:23,  1.09it/s]Loading train:  23%|██▎       | 105/456 [01:31<05:03,  1.15it/s]Loading train:  23%|██▎       | 106/456 [01:32<04:51,  1.20it/s]Loading train:  23%|██▎       | 107/456 [01:33<05:03,  1.15it/s]Loading train:  24%|██▎       | 108/456 [01:34<04:56,  1.17it/s]Loading train:  24%|██▍       | 109/456 [01:35<04:59,  1.16it/s]Loading train:  24%|██▍       | 110/456 [01:35<04:41,  1.23it/s]Loading train:  24%|██▍       | 111/456 [01:36<04:30,  1.27it/s]Loading train:  25%|██▍       | 112/456 [01:37<04:31,  1.26it/s]Loading train:  25%|██▍       | 113/456 [01:38<04:24,  1.30it/s]Loading train:  25%|██▌       | 114/456 [01:38<04:18,  1.32it/s]Loading train:  25%|██▌       | 115/456 [01:39<04:41,  1.21it/s]Loading train:  25%|██▌       | 116/456 [01:40<04:37,  1.22it/s]Loading train:  26%|██▌       | 117/456 [01:41<04:37,  1.22it/s]Loading train:  26%|██▌       | 118/456 [01:42<04:45,  1.19it/s]Loading train:  26%|██▌       | 119/456 [01:43<04:41,  1.20it/s]Loading train:  26%|██▋       | 120/456 [01:43<04:40,  1.20it/s]Loading train:  27%|██▋       | 121/456 [01:44<04:53,  1.14it/s]Loading train:  27%|██▋       | 122/456 [01:45<04:57,  1.12it/s]Loading train:  27%|██▋       | 123/456 [01:46<05:10,  1.07it/s]Loading train:  27%|██▋       | 124/456 [01:47<05:20,  1.03it/s]Loading train:  27%|██▋       | 125/456 [01:48<05:21,  1.03it/s]Loading train:  28%|██▊       | 126/456 [01:49<05:23,  1.02it/s]Loading train:  28%|██▊       | 127/456 [01:50<05:10,  1.06it/s]Loading train:  28%|██▊       | 128/456 [01:51<05:01,  1.09it/s]Loading train:  28%|██▊       | 129/456 [01:52<04:47,  1.14it/s]Loading train:  29%|██▊       | 130/456 [01:53<04:47,  1.13it/s]Loading train:  29%|██▊       | 131/456 [01:54<04:45,  1.14it/s]Loading train:  29%|██▉       | 132/456 [01:54<04:33,  1.18it/s]Loading train:  29%|██▉       | 133/456 [01:56<04:58,  1.08it/s]Loading train:  29%|██▉       | 134/456 [01:57<05:03,  1.06it/s]Loading train:  30%|██▉       | 135/456 [01:58<05:20,  1.00it/s]Loading train:  30%|██▉       | 136/456 [01:59<05:34,  1.05s/it]Loading train:  30%|███       | 137/456 [02:00<05:39,  1.06s/it]Loading train:  30%|███       | 138/456 [02:01<05:37,  1.06s/it]Loading train:  30%|███       | 139/456 [02:02<05:06,  1.03it/s]Loading train:  31%|███       | 140/456 [02:03<04:48,  1.09it/s]Loading train:  31%|███       | 141/456 [02:03<04:23,  1.19it/s]Loading train:  31%|███       | 142/456 [02:04<04:10,  1.25it/s]Loading train:  31%|███▏      | 143/456 [02:05<03:57,  1.32it/s]Loading train:  32%|███▏      | 144/456 [02:05<03:53,  1.34it/s]Loading train:  32%|███▏      | 145/456 [02:06<04:11,  1.24it/s]Loading train:  32%|███▏      | 146/456 [02:07<04:30,  1.15it/s]Loading train:  32%|███▏      | 147/456 [02:08<04:19,  1.19it/s]Loading train:  32%|███▏      | 148/456 [02:09<04:10,  1.23it/s]Loading train:  33%|███▎      | 149/456 [02:10<04:06,  1.24it/s]Loading train:  33%|███▎      | 150/456 [02:10<04:06,  1.24it/s]Loading train:  33%|███▎      | 151/456 [02:11<04:08,  1.23it/s]Loading train:  33%|███▎      | 152/456 [02:12<04:10,  1.21it/s]Loading train:  34%|███▎      | 153/456 [02:13<04:26,  1.14it/s]Loading train:  34%|███▍      | 154/456 [02:14<04:13,  1.19it/s]Loading train:  34%|███▍      | 155/456 [02:15<04:22,  1.15it/s]Loading train:  34%|███▍      | 156/456 [02:16<04:27,  1.12it/s]Loading train:  34%|███▍      | 157/456 [02:17<04:28,  1.11it/s]Loading train:  35%|███▍      | 158/456 [02:17<04:22,  1.13it/s]Loading train:  35%|███▍      | 159/456 [02:18<04:11,  1.18it/s]Loading train:  35%|███▌      | 160/456 [02:19<03:59,  1.24it/s]Loading train:  35%|███▌      | 161/456 [02:20<03:58,  1.24it/s]Loading train:  36%|███▌      | 162/456 [02:21<04:24,  1.11it/s]Loading train:  36%|███▌      | 163/456 [02:21<04:00,  1.22it/s]Loading train:  36%|███▌      | 164/456 [02:22<03:40,  1.32it/s]Loading train:  36%|███▌      | 165/456 [02:23<03:24,  1.43it/s]Loading train:  36%|███▋      | 166/456 [02:23<03:14,  1.49it/s]Loading train:  37%|███▋      | 167/456 [02:24<03:03,  1.57it/s]Loading train:  37%|███▋      | 168/456 [02:24<02:54,  1.65it/s]Loading train:  37%|███▋      | 169/456 [02:25<03:06,  1.54it/s]Loading train:  37%|███▋      | 170/456 [02:26<03:08,  1.52it/s]Loading train:  38%|███▊      | 171/456 [02:27<03:20,  1.42it/s]Loading train:  38%|███▊      | 172/456 [02:27<03:20,  1.42it/s]Loading train:  38%|███▊      | 173/456 [02:28<03:20,  1.41it/s]Loading train:  38%|███▊      | 174/456 [02:29<03:18,  1.42it/s]Loading train:  38%|███▊      | 175/456 [02:30<03:30,  1.34it/s]Loading train:  39%|███▊      | 176/456 [02:30<03:21,  1.39it/s]Loading train:  39%|███▉      | 177/456 [02:31<03:16,  1.42it/s]Loading train:  39%|███▉      | 178/456 [02:32<03:15,  1.42it/s]Loading train:  39%|███▉      | 179/456 [02:32<03:14,  1.42it/s]Loading train:  39%|███▉      | 180/456 [02:33<03:17,  1.40it/s]Loading train:  40%|███▉      | 181/456 [02:34<03:33,  1.29it/s]Loading train:  40%|███▉      | 182/456 [02:35<03:42,  1.23it/s]Loading train:  40%|████      | 183/456 [02:36<04:10,  1.09it/s]Loading train:  40%|████      | 184/456 [02:37<04:14,  1.07it/s]Loading train:  41%|████      | 185/456 [02:38<04:12,  1.07it/s]Loading train:  41%|████      | 186/456 [02:39<04:07,  1.09it/s]Loading train:  41%|████      | 187/456 [02:40<04:22,  1.02it/s]Loading train:  41%|████      | 188/456 [02:41<04:25,  1.01it/s]Loading train:  41%|████▏     | 189/456 [02:42<04:37,  1.04s/it]Loading train:  42%|████▏     | 190/456 [02:43<04:37,  1.04s/it]Loading train:  42%|████▏     | 191/456 [02:44<04:48,  1.09s/it]Loading train:  42%|████▏     | 192/456 [02:46<04:54,  1.11s/it]Loading train:  42%|████▏     | 193/456 [02:47<04:47,  1.10s/it]Loading train:  43%|████▎     | 194/456 [02:48<04:36,  1.06s/it]Loading train:  43%|████▎     | 195/456 [02:49<04:38,  1.07s/it]Loading train:  43%|████▎     | 196/456 [02:50<04:32,  1.05s/it]Loading train:  43%|████▎     | 197/456 [02:51<04:23,  1.02s/it]Loading train:  43%|████▎     | 198/456 [02:52<04:24,  1.03s/it]Loading train:  44%|████▎     | 199/456 [02:53<04:15,  1.01it/s]Loading train:  44%|████▍     | 200/456 [02:53<04:02,  1.06it/s]Loading train:  44%|████▍     | 201/456 [02:54<04:06,  1.03it/s]Loading train:  44%|████▍     | 202/456 [02:55<04:07,  1.02it/s]Loading train:  45%|████▍     | 203/456 [02:56<04:02,  1.04it/s]Loading train:  45%|████▍     | 204/456 [02:57<03:56,  1.06it/s]Loading train:  45%|████▍     | 205/456 [02:58<03:41,  1.13it/s]Loading train:  45%|████▌     | 206/456 [02:59<03:26,  1.21it/s]Loading train:  45%|████▌     | 207/456 [02:59<03:10,  1.31it/s]Loading train:  46%|████▌     | 208/456 [03:00<03:00,  1.37it/s]Loading train:  46%|████▌     | 209/456 [03:01<03:03,  1.35it/s]Loading train:  46%|████▌     | 210/456 [03:01<02:57,  1.39it/s]Loading train:  46%|████▋     | 211/456 [03:02<03:16,  1.25it/s]Loading train:  46%|████▋     | 212/456 [03:03<03:22,  1.21it/s]Loading train:  47%|████▋     | 213/456 [03:04<03:28,  1.16it/s]Loading train:  47%|████▋     | 214/456 [03:05<03:31,  1.14it/s]Loading train:  47%|████▋     | 215/456 [03:06<03:24,  1.18it/s]Loading train:  47%|████▋     | 216/456 [03:07<03:19,  1.21it/s]Loading train:  48%|████▊     | 217/456 [03:08<03:21,  1.19it/s]Loading train:  48%|████▊     | 218/456 [03:09<03:36,  1.10it/s]Loading train:  48%|████▊     | 219/456 [03:09<03:33,  1.11it/s]Loading train:  48%|████▊     | 220/456 [03:10<03:27,  1.14it/s]Loading train:  48%|████▊     | 221/456 [03:11<03:17,  1.19it/s]Loading train:  49%|████▊     | 222/456 [03:12<03:06,  1.25it/s]Loading train:  49%|████▉     | 223/456 [03:13<03:08,  1.23it/s]Loading train:  49%|████▉     | 224/456 [03:13<03:01,  1.28it/s]Loading train:  49%|████▉     | 225/456 [03:14<03:11,  1.21it/s]Loading train:  50%|████▉     | 226/456 [03:15<03:04,  1.25it/s]Loading train:  50%|████▉     | 227/456 [03:16<03:04,  1.24it/s]Loading train:  50%|█████     | 228/456 [03:17<02:57,  1.29it/s]Loading train:  50%|█████     | 229/456 [03:17<02:54,  1.30it/s]Loading train:  50%|█████     | 230/456 [03:18<02:48,  1.34it/s]Loading train:  51%|█████     | 231/456 [03:19<02:48,  1.33it/s]Loading train:  51%|█████     | 232/456 [03:19<02:49,  1.32it/s]Loading train:  51%|█████     | 233/456 [03:20<02:58,  1.25it/s]Loading train:  51%|█████▏    | 234/456 [03:21<02:59,  1.24it/s]Loading train:  52%|█████▏    | 235/456 [03:22<03:06,  1.18it/s]Loading train:  52%|█████▏    | 236/456 [03:23<03:02,  1.21it/s]Loading train:  52%|█████▏    | 237/456 [03:24<03:00,  1.21it/s]Loading train:  52%|█████▏    | 238/456 [03:25<02:57,  1.23it/s]Loading train:  52%|█████▏    | 239/456 [03:25<02:59,  1.21it/s]Loading train:  53%|█████▎    | 240/456 [03:27<03:41,  1.03s/it]Loading train:  53%|█████▎    | 241/456 [03:28<04:11,  1.17s/it]Loading train:  53%|█████▎    | 242/456 [03:30<04:07,  1.16s/it]Loading train:  53%|█████▎    | 243/456 [03:31<04:00,  1.13s/it]Loading train:  54%|█████▎    | 244/456 [03:32<03:58,  1.13s/it]Loading train:  54%|█████▎    | 245/456 [03:33<03:57,  1.13s/it]Loading train:  54%|█████▍    | 246/456 [03:34<03:58,  1.14s/it]Loading train:  54%|█████▍    | 247/456 [03:35<03:51,  1.11s/it]Loading train:  54%|█████▍    | 248/456 [03:36<03:47,  1.09s/it]Loading train:  55%|█████▍    | 249/456 [03:37<03:38,  1.05s/it]Loading train:  55%|█████▍    | 250/456 [03:38<03:44,  1.09s/it]Loading train:  55%|█████▌    | 251/456 [03:39<03:45,  1.10s/it]Loading train:  55%|█████▌    | 252/456 [03:40<03:27,  1.02s/it]Loading train:  55%|█████▌    | 253/456 [03:41<03:26,  1.02s/it]Loading train:  56%|█████▌    | 254/456 [03:42<03:30,  1.04s/it]Loading train:  56%|█████▌    | 255/456 [03:43<03:37,  1.08s/it]Loading train:  56%|█████▌    | 256/456 [03:45<03:35,  1.08s/it]Loading train:  56%|█████▋    | 257/456 [03:46<03:33,  1.07s/it]Loading train:  57%|█████▋    | 258/456 [03:47<03:25,  1.04s/it]Loading train:  57%|█████▋    | 259/456 [03:47<03:09,  1.04it/s]Loading train:  57%|█████▋    | 260/456 [03:48<02:52,  1.14it/s]Loading train:  57%|█████▋    | 261/456 [03:49<02:45,  1.18it/s]Loading train:  57%|█████▋    | 262/456 [03:49<02:34,  1.25it/s]Loading train:  58%|█████▊    | 263/456 [03:50<02:24,  1.34it/s]Loading train:  58%|█████▊    | 264/456 [03:51<02:19,  1.38it/s]Loading train:  58%|█████▊    | 265/456 [03:51<02:12,  1.44it/s]Loading train:  58%|█████▊    | 266/456 [03:52<02:11,  1.45it/s]Loading train:  59%|█████▊    | 267/456 [03:53<02:13,  1.42it/s]Loading train:  59%|█████▉    | 268/456 [03:54<02:16,  1.37it/s]Loading train:  59%|█████▉    | 269/456 [03:54<02:17,  1.36it/s]Loading train:  59%|█████▉    | 270/456 [03:55<02:16,  1.36it/s]Loading train:  59%|█████▉    | 271/456 [03:56<02:28,  1.24it/s]Loading train:  60%|█████▉    | 272/456 [03:57<02:27,  1.25it/s]Loading train:  60%|█████▉    | 273/456 [03:58<02:29,  1.23it/s]Loading train:  60%|██████    | 274/456 [03:59<02:28,  1.23it/s]Loading train:  60%|██████    | 275/456 [03:59<02:28,  1.22it/s]Loading train:  61%|██████    | 276/456 [04:00<02:35,  1.16it/s]Loading train:  61%|██████    | 277/456 [04:01<02:28,  1.20it/s]Loading train:  61%|██████    | 278/456 [04:02<02:20,  1.27it/s]Loading train:  61%|██████    | 279/456 [04:02<02:15,  1.30it/s]Loading train:  61%|██████▏   | 280/456 [04:03<02:22,  1.23it/s]Loading train:  62%|██████▏   | 281/456 [04:05<02:39,  1.10it/s]Loading train:  62%|██████▏   | 282/456 [04:05<02:33,  1.14it/s]Loading train:  62%|██████▏   | 283/456 [04:06<02:32,  1.14it/s]Loading train:  62%|██████▏   | 284/456 [04:07<02:14,  1.28it/s]Loading train:  62%|██████▎   | 285/456 [04:07<02:06,  1.36it/s]Loading train:  63%|██████▎   | 286/456 [04:08<02:02,  1.38it/s]Loading train:  63%|██████▎   | 287/456 [04:09<02:02,  1.38it/s]Loading train:  63%|██████▎   | 288/456 [04:10<02:09,  1.30it/s]Loading train:  63%|██████▎   | 289/456 [04:10<02:09,  1.29it/s]Loading train:  64%|██████▎   | 290/456 [04:11<02:06,  1.31it/s]Loading train:  64%|██████▍   | 291/456 [04:12<01:59,  1.38it/s]Loading train:  64%|██████▍   | 292/456 [04:13<02:00,  1.37it/s]Loading train:  64%|██████▍   | 293/456 [04:13<01:55,  1.41it/s]Loading train:  64%|██████▍   | 294/456 [04:14<01:51,  1.45it/s]Loading train:  65%|██████▍   | 295/456 [04:14<01:45,  1.52it/s]Loading train:  65%|██████▍   | 296/456 [04:15<01:43,  1.55it/s]Loading train:  65%|██████▌   | 297/456 [04:16<01:38,  1.62it/s]Loading train:  65%|██████▌   | 298/456 [04:16<01:34,  1.66it/s]Loading train:  66%|██████▌   | 299/456 [04:17<01:30,  1.73it/s]Loading train:  66%|██████▌   | 300/456 [04:17<01:30,  1.72it/s]Loading train:  66%|██████▌   | 301/456 [04:18<01:43,  1.50it/s]Loading train:  66%|██████▌   | 302/456 [04:19<01:51,  1.38it/s]Loading train:  66%|██████▋   | 303/456 [04:20<01:57,  1.31it/s]Loading train:  67%|██████▋   | 304/456 [04:21<01:59,  1.27it/s]Loading train:  67%|██████▋   | 305/456 [04:22<01:58,  1.27it/s]Loading train:  67%|██████▋   | 306/456 [04:22<02:00,  1.25it/s]Loading train:  67%|██████▋   | 307/456 [04:23<02:12,  1.13it/s]Loading train:  68%|██████▊   | 308/456 [04:24<02:10,  1.13it/s]Loading train:  68%|██████▊   | 309/456 [04:25<02:11,  1.12it/s]Loading train:  68%|██████▊   | 310/456 [04:26<02:12,  1.10it/s]Loading train:  68%|██████▊   | 311/456 [04:27<02:20,  1.03it/s]Loading train:  68%|██████▊   | 312/456 [04:28<02:21,  1.02it/s]Loading train:  69%|██████▊   | 313/456 [04:29<02:22,  1.00it/s]Loading train:  69%|██████▉   | 314/456 [04:30<02:22,  1.00s/it]Loading train:  69%|██████▉   | 315/456 [04:31<02:24,  1.03s/it]Loading train:  69%|██████▉   | 316/456 [04:32<02:20,  1.01s/it]Loading train:  70%|██████▉   | 317/456 [04:33<02:18,  1.00it/s]Loading train:  70%|██████▉   | 318/456 [04:34<02:14,  1.03it/s]Loading train:  70%|██████▉   | 319/456 [04:35<02:08,  1.07it/s]Loading train:  70%|███████   | 320/456 [04:36<02:13,  1.02it/s]Loading train:  70%|███████   | 321/456 [04:37<02:13,  1.01it/s]Loading train:  71%|███████   | 322/456 [04:38<02:06,  1.06it/s]Loading train:  71%|███████   | 323/456 [04:39<02:01,  1.09it/s]Loading train:  71%|███████   | 324/456 [04:40<01:58,  1.11it/s]Loading train:  71%|███████▏  | 325/456 [04:41<01:54,  1.15it/s]Loading train:  71%|███████▏  | 326/456 [04:41<01:49,  1.19it/s]Loading train:  72%|███████▏  | 327/456 [04:42<01:45,  1.23it/s]Loading train:  72%|███████▏  | 328/456 [04:43<01:47,  1.19it/s]Loading train:  72%|███████▏  | 329/456 [04:44<01:39,  1.28it/s]Loading train:  72%|███████▏  | 330/456 [04:44<01:34,  1.33it/s]Loading train:  73%|███████▎  | 331/456 [04:45<01:36,  1.29it/s]Loading train:  73%|███████▎  | 332/456 [04:46<01:37,  1.27it/s]Loading train:  73%|███████▎  | 333/456 [04:47<01:40,  1.22it/s]Loading train:  73%|███████▎  | 334/456 [04:48<01:39,  1.22it/s]Loading train:  73%|███████▎  | 335/456 [04:49<01:42,  1.19it/s]Loading train:  74%|███████▎  | 336/456 [04:50<01:43,  1.16it/s]Loading train:  74%|███████▍  | 337/456 [04:51<01:48,  1.10it/s]Loading train:  74%|███████▍  | 338/456 [04:51<01:46,  1.11it/s]Loading train:  74%|███████▍  | 339/456 [04:52<01:42,  1.15it/s]Loading train:  75%|███████▍  | 340/456 [04:53<01:35,  1.21it/s]Loading train:  75%|███████▍  | 341/456 [04:54<01:37,  1.18it/s]Loading train:  75%|███████▌  | 342/456 [04:55<01:34,  1.21it/s]Loading train:  75%|███████▌  | 343/456 [04:55<01:30,  1.25it/s]Loading train:  75%|███████▌  | 344/456 [04:56<01:29,  1.26it/s]Loading train:  76%|███████▌  | 345/456 [04:57<01:26,  1.28it/s]Loading train:  76%|███████▌  | 346/456 [04:58<01:26,  1.28it/s]Loading train:  76%|███████▌  | 347/456 [04:58<01:26,  1.26it/s]Loading train:  76%|███████▋  | 348/456 [04:59<01:23,  1.29it/s]Loading train:  77%|███████▋  | 349/456 [05:00<01:25,  1.25it/s]Loading train:  77%|███████▋  | 350/456 [05:01<01:24,  1.25it/s]Loading train:  77%|███████▋  | 351/456 [05:02<01:29,  1.17it/s]Loading train:  77%|███████▋  | 352/456 [05:03<01:30,  1.15it/s]Loading train:  77%|███████▋  | 353/456 [05:04<01:26,  1.19it/s]Loading train:  78%|███████▊  | 354/456 [05:04<01:22,  1.23it/s]Loading train:  78%|███████▊  | 355/456 [05:05<01:23,  1.21it/s]Loading train:  78%|███████▊  | 356/456 [05:06<01:20,  1.24it/s]Loading train:  78%|███████▊  | 357/456 [05:07<01:17,  1.27it/s]Loading train:  79%|███████▊  | 358/456 [05:07<01:15,  1.30it/s]Loading train:  79%|███████▊  | 359/456 [05:08<01:13,  1.32it/s]Loading train:  79%|███████▉  | 360/456 [05:09<01:13,  1.30it/s]Loading train:  79%|███████▉  | 361/456 [05:10<01:14,  1.27it/s]Loading train:  79%|███████▉  | 362/456 [05:11<01:14,  1.26it/s]Loading train:  80%|███████▉  | 363/456 [05:11<01:15,  1.23it/s]Loading train:  80%|███████▉  | 364/456 [05:12<01:21,  1.13it/s]Loading train:  80%|████████  | 365/456 [05:13<01:19,  1.14it/s]Loading train:  80%|████████  | 366/456 [05:14<01:20,  1.12it/s]Loading train:  80%|████████  | 367/456 [05:15<01:20,  1.11it/s]Loading train:  81%|████████  | 368/456 [05:16<01:12,  1.21it/s]Loading train:  81%|████████  | 369/456 [05:17<01:13,  1.18it/s]Loading train:  81%|████████  | 370/456 [05:17<01:08,  1.25it/s]Loading train:  81%|████████▏ | 371/456 [05:18<01:04,  1.32it/s]Loading train:  82%|████████▏ | 372/456 [05:19<01:01,  1.36it/s]Loading train:  82%|████████▏ | 373/456 [05:20<01:08,  1.22it/s]Loading train:  82%|████████▏ | 374/456 [05:21<01:09,  1.18it/s]Loading train:  82%|████████▏ | 375/456 [05:22<01:10,  1.14it/s]Loading train:  82%|████████▏ | 376/456 [05:23<01:12,  1.10it/s]Loading train:  83%|████████▎ | 377/456 [05:24<01:13,  1.07it/s]Loading train:  83%|████████▎ | 378/456 [05:25<01:17,  1.00it/s]Loading train:  83%|████████▎ | 379/456 [05:25<01:10,  1.09it/s]Loading train:  83%|████████▎ | 380/456 [05:26<01:06,  1.14it/s]Loading train:  84%|████████▎ | 381/456 [05:27<01:01,  1.21it/s]Loading train:  84%|████████▍ | 382/456 [05:28<00:59,  1.24it/s]Loading train:  84%|████████▍ | 383/456 [05:29<01:01,  1.19it/s]Loading train:  84%|████████▍ | 384/456 [05:29<00:57,  1.24it/s]Loading train:  84%|████████▍ | 385/456 [05:30<00:59,  1.20it/s]Loading train:  85%|████████▍ | 386/456 [05:31<00:58,  1.19it/s]Loading train:  85%|████████▍ | 387/456 [05:32<00:56,  1.23it/s]Loading train:  85%|████████▌ | 388/456 [05:33<00:53,  1.28it/s]Loading train:  85%|████████▌ | 389/456 [05:33<00:49,  1.35it/s]Loading train:  86%|████████▌ | 390/456 [05:34<00:48,  1.36it/s]Loading train:  86%|████████▌ | 391/456 [05:35<00:49,  1.32it/s]Loading train:  86%|████████▌ | 392/456 [05:36<00:51,  1.25it/s]Loading train:  86%|████████▌ | 393/456 [05:37<00:52,  1.19it/s]Loading train:  86%|████████▋ | 394/456 [05:37<00:50,  1.23it/s]Loading train:  87%|████████▋ | 395/456 [05:38<00:48,  1.26it/s]Loading train:  87%|████████▋ | 396/456 [05:39<00:48,  1.24it/s]Loading train:  87%|████████▋ | 397/456 [05:40<00:48,  1.21it/s]Loading train:  87%|████████▋ | 398/456 [05:41<00:48,  1.20it/s]Loading train:  88%|████████▊ | 399/456 [05:41<00:46,  1.24it/s]Loading train:  88%|████████▊ | 400/456 [05:42<00:45,  1.22it/s]Loading train:  88%|████████▊ | 401/456 [05:43<00:44,  1.23it/s]Loading train:  88%|████████▊ | 402/456 [05:44<00:41,  1.30it/s]Loading train:  88%|████████▊ | 403/456 [05:44<00:37,  1.42it/s]Loading train:  89%|████████▊ | 404/456 [05:45<00:37,  1.40it/s]Loading train:  89%|████████▉ | 405/456 [05:46<00:35,  1.43it/s]Loading train:  89%|████████▉ | 406/456 [05:46<00:36,  1.36it/s]Loading train:  89%|████████▉ | 407/456 [05:47<00:34,  1.42it/s]Loading train:  89%|████████▉ | 408/456 [05:48<00:33,  1.43it/s]Loading train:  90%|████████▉ | 409/456 [05:49<00:34,  1.38it/s]Loading train:  90%|████████▉ | 410/456 [05:49<00:33,  1.38it/s]Loading train:  90%|█████████ | 411/456 [05:50<00:32,  1.37it/s]Loading train:  90%|█████████ | 412/456 [05:51<00:32,  1.34it/s]Loading train:  91%|█████████ | 413/456 [05:52<00:31,  1.36it/s]Loading train:  91%|█████████ | 414/456 [05:52<00:31,  1.33it/s]Loading train:  91%|█████████ | 415/456 [05:53<00:31,  1.30it/s]Loading train:  91%|█████████ | 416/456 [05:54<00:29,  1.37it/s]Loading train:  91%|█████████▏| 417/456 [05:54<00:26,  1.45it/s]Loading train:  92%|█████████▏| 418/456 [05:55<00:26,  1.45it/s]Loading train:  92%|█████████▏| 419/456 [05:56<00:25,  1.47it/s]Loading train:  92%|█████████▏| 420/456 [05:56<00:24,  1.44it/s]Loading train:  92%|█████████▏| 421/456 [05:57<00:26,  1.30it/s]Loading train:  93%|█████████▎| 422/456 [05:59<00:30,  1.13it/s]Loading train:  93%|█████████▎| 423/456 [05:59<00:29,  1.13it/s]Loading train:  93%|█████████▎| 424/456 [06:00<00:27,  1.14it/s]Loading train:  93%|█████████▎| 425/456 [06:01<00:26,  1.18it/s]Loading train:  93%|█████████▎| 426/456 [06:02<00:24,  1.20it/s]Loading train:  94%|█████████▎| 427/456 [06:03<00:26,  1.11it/s]Loading train:  94%|█████████▍| 428/456 [06:04<00:26,  1.04it/s]Loading train:  94%|█████████▍| 429/456 [06:05<00:25,  1.05it/s]Loading train:  94%|█████████▍| 430/456 [06:06<00:25,  1.03it/s]Loading train:  95%|█████████▍| 431/456 [06:07<00:24,  1.02it/s]Loading train:  95%|█████████▍| 432/456 [06:08<00:24,  1.02s/it]Loading train:  95%|█████████▍| 433/456 [06:09<00:23,  1.04s/it]Loading train:  95%|█████████▌| 434/456 [06:10<00:22,  1.01s/it]Loading train:  95%|█████████▌| 435/456 [06:11<00:20,  1.02it/s]Loading train:  96%|█████████▌| 436/456 [06:12<00:19,  1.03it/s]Loading train:  96%|█████████▌| 437/456 [06:13<00:18,  1.05it/s]Loading train:  96%|█████████▌| 438/456 [06:14<00:17,  1.02it/s]Loading train:  96%|█████████▋| 439/456 [06:15<00:16,  1.03it/s]Loading train:  96%|█████████▋| 440/456 [06:16<00:15,  1.07it/s]Loading train:  97%|█████████▋| 441/456 [06:17<00:13,  1.12it/s]Loading train:  97%|█████████▋| 442/456 [06:17<00:12,  1.15it/s]Loading train:  97%|█████████▋| 443/456 [06:18<00:11,  1.15it/s]Loading train:  97%|█████████▋| 444/456 [06:19<00:10,  1.16it/s]Loading train:  98%|█████████▊| 445/456 [06:20<00:08,  1.24it/s]Loading train:  98%|█████████▊| 446/456 [06:20<00:07,  1.31it/s]Loading train:  98%|█████████▊| 447/456 [06:21<00:06,  1.30it/s]Loading train:  98%|█████████▊| 448/456 [06:22<00:05,  1.35it/s]Loading train:  98%|█████████▊| 449/456 [06:23<00:05,  1.33it/s]Loading train:  99%|█████████▊| 450/456 [06:23<00:04,  1.43it/s]Loading train:  99%|█████████▉| 451/456 [06:24<00:03,  1.36it/s]Loading train:  99%|█████████▉| 452/456 [06:25<00:03,  1.28it/s]Loading train:  99%|█████████▉| 453/456 [06:26<00:02,  1.28it/s]Loading train: 100%|█████████▉| 454/456 [06:27<00:01,  1.25it/s]Loading train: 100%|█████████▉| 455/456 [06:27<00:00,  1.22it/s]Loading train: 100%|██████████| 456/456 [06:28<00:00,  1.23it/s]
concatenating: train:   0%|          | 0/456 [00:00<?, ?it/s]concatenating: train:   6%|▌         | 26/456 [00:00<00:01, 254.18it/s]concatenating: train:  11%|█         | 51/456 [00:00<00:01, 252.80it/s]concatenating: train:  17%|█▋        | 77/456 [00:00<00:01, 254.33it/s]concatenating: train:  22%|██▏       | 102/456 [00:00<00:01, 251.12it/s]concatenating: train:  27%|██▋       | 124/456 [00:00<00:01, 240.77it/s]concatenating: train:  32%|███▏      | 144/456 [00:00<00:01, 194.29it/s]concatenating: train:  36%|███▌      | 162/456 [00:00<00:02, 130.24it/s]concatenating: train:  40%|████      | 184/456 [00:01<00:01, 147.85it/s]concatenating: train:  45%|████▍     | 204/456 [00:01<00:01, 159.56it/s]concatenating: train:  51%|█████     | 231/456 [00:01<00:01, 180.97it/s]concatenating: train:  55%|█████▌    | 252/456 [00:01<00:01, 174.91it/s]concatenating: train:  60%|█████▉    | 272/456 [00:01<00:01, 115.15it/s]concatenating: train:  64%|██████▍   | 292/456 [00:01<00:01, 130.68it/s]concatenating: train:  68%|██████▊   | 311/456 [00:01<00:01, 142.45it/s]concatenating: train:  73%|███████▎  | 333/456 [00:01<00:00, 158.00it/s]concatenating: train:  79%|███████▉  | 360/456 [00:02<00:00, 180.27it/s]concatenating: train:  84%|████████▎ | 381/456 [00:02<00:00, 153.29it/s]concatenating: train:  88%|████████▊ | 399/456 [00:02<00:00, 117.80it/s]concatenating: train:  92%|█████████▏| 420/456 [00:02<00:00, 135.56it/s]concatenating: train:  98%|█████████▊| 447/456 [00:02<00:00, 158.99it/s]concatenating: train: 100%|██████████| 456/456 [00:02<00:00, 168.19it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:00<00:02,  1.00it/s]Loading test:  50%|█████     | 2/4 [00:01<00:01,  1.03it/s]Loading test:  75%|███████▌  | 3/4 [00:02<00:00,  1.11it/s]Loading test: 100%|██████████| 4/4 [00:03<00:00,  1.14it/s]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 591.29it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 88, 56, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 88, 56, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 88, 56, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 88, 56, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 88, 56, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 88, 56, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 88, 56, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 88, 56, 21)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 44, 28, 21)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 44, 28, 21)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 44, 28, 40)   7600        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 44, 28, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 44, 28, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 44, 28, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 44, 28, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 44, 28, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 44, 28, 61)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 22, 14, 61)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 22, 14, 61)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 22, 14, 80)   44000       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 22, 14, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 22, 14, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 22, 14, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 22, 14, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 22, 14, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 22, 14, 141)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 22, 14, 141)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 44, 28, 40)   22600       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 44, 28, 101)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 44, 28, 40)   36400       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 44, 28, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 44, 28, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 44, 28, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 44, 28, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 44, 28, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 44, 28, 141)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-07 20:35:53.759319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 20:35:53.759438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 20:35:53.759454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 20:35:53.759463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 20:35:53.926618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 44, 28, 141)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 88, 56, 20)   11300       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 88, 56, 41)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 88, 56, 20)   7400        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 88, 56, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 88, 56, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 88, 56, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 88, 56, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 88, 56, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 88, 56, 61)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 88, 56, 61)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 88, 56, 13)   806         dropout_5[0][0]                  
==================================================================================================
Total params: 225,706
Trainable params: 224,906
Non-trainable params: 800
__________________________________________________________________________________________________
----- /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/model_weights.h5
 --- initialized from Model_3T /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0
------------------------------------------------------------------
class_weights [6.16770687e-02 2.82810291e-02 7.42489031e-02 1.01163433e-02
 2.48563371e-02 6.25843058e-03 7.67474865e-02 1.12146729e-01
 6.37696896e-02 1.30484325e-02 3.54233577e-01 1.74411942e-01
 2.04031629e-04]
Train on 16653 samples, validate on 146 samples
Epoch 1/300
 - 24s - loss: 2.0422 - acc: 0.9529 - mDice: 0.6215 - val_loss: 1.6694 - val_acc: 0.9673 - val_mDice: 0.6660

Epoch 00001: val_mDice improved from -inf to 0.66603, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 19s - loss: 1.7052 - acc: 0.9562 - mDice: 0.6612 - val_loss: 1.7121 - val_acc: 0.9677 - val_mDice: 0.6712

Epoch 00002: val_mDice improved from 0.66603 to 0.67125, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 18s - loss: 1.6088 - acc: 0.9575 - mDice: 0.6775 - val_loss: 1.7112 - val_acc: 0.9676 - val_mDice: 0.6779

Epoch 00003: val_mDice improved from 0.67125 to 0.67787, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 18s - loss: 1.5486 - acc: 0.9583 - mDice: 0.6879 - val_loss: 1.7656 - val_acc: 0.9667 - val_mDice: 0.6779

Epoch 00004: val_mDice improved from 0.67787 to 0.67790, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 18s - loss: 1.5034 - acc: 0.9588 - mDice: 0.6964 - val_loss: 1.7564 - val_acc: 0.9671 - val_mDice: 0.6807

Epoch 00005: val_mDice improved from 0.67790 to 0.68067, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 18s - loss: 1.4679 - acc: 0.9594 - mDice: 0.7032 - val_loss: 1.7161 - val_acc: 0.9675 - val_mDice: 0.6845

Epoch 00006: val_mDice improved from 0.68067 to 0.68449, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 7/300
 - 19s - loss: 1.4446 - acc: 0.9596 - mDice: 0.7076 - val_loss: 1.7795 - val_acc: 0.9671 - val_mDice: 0.6846

Epoch 00007: val_mDice improved from 0.68449 to 0.68460, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 8/300
 - 17s - loss: 1.4147 - acc: 0.9601 - mDice: 0.7134 - val_loss: 1.7241 - val_acc: 0.9669 - val_mDice: 0.6854

Epoch 00008: val_mDice improved from 0.68460 to 0.68545, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 19s - loss: 1.3964 - acc: 0.9604 - mDice: 0.7170 - val_loss: 1.7836 - val_acc: 0.9668 - val_mDice: 0.6850

Epoch 00009: val_mDice did not improve from 0.68545
Epoch 10/300
 - 18s - loss: 1.3757 - acc: 0.9606 - mDice: 0.7209 - val_loss: 1.8392 - val_acc: 0.9663 - val_mDice: 0.6872

Epoch 00010: val_mDice improved from 0.68545 to 0.68723, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 11/300
 - 19s - loss: 1.3606 - acc: 0.9608 - mDice: 0.7240 - val_loss: 1.8655 - val_acc: 0.9662 - val_mDice: 0.6810

Epoch 00011: val_mDice did not improve from 0.68723
Epoch 12/300
 - 19s - loss: 1.3458 - acc: 0.9610 - mDice: 0.7266 - val_loss: 1.8987 - val_acc: 0.9657 - val_mDice: 0.6838

Epoch 00012: val_mDice did not improve from 0.68723
Epoch 13/300
 - 18s - loss: 1.3350 - acc: 0.9612 - mDice: 0.7289 - val_loss: 1.8549 - val_acc: 0.9669 - val_mDice: 0.6872

Epoch 00013: val_mDice improved from 0.68723 to 0.68725, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 14/300
 - 19s - loss: 1.3210 - acc: 0.9614 - mDice: 0.7313 - val_loss: 1.8660 - val_acc: 0.9665 - val_mDice: 0.6883

Epoch 00014: val_mDice improved from 0.68725 to 0.68828, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 15/300
 - 20s - loss: 1.3121 - acc: 0.9615 - mDice: 0.7333 - val_loss: 1.9069 - val_acc: 0.9667 - val_mDice: 0.6855

Epoch 00015: val_mDice did not improve from 0.68828
Epoch 16/300
 - 18s - loss: 1.3033 - acc: 0.9617 - mDice: 0.7349 - val_loss: 1.9344 - val_acc: 0.9668 - val_mDice: 0.6856

Epoch 00016: val_mDice did not improve from 0.68828
Epoch 17/300
 - 19s - loss: 1.2964 - acc: 0.9618 - mDice: 0.7365 - val_loss: 1.8726 - val_acc: 0.9668 - val_mDice: 0.6867

Epoch 00017: val_mDice did not improve from 0.68828
Epoch 18/300
 - 19s - loss: 1.2839 - acc: 0.9620 - mDice: 0.7388 - val_loss: 1.8947 - val_acc: 0.9666 - val_mDice: 0.6888

Epoch 00018: val_mDice improved from 0.68828 to 0.68884, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 19/300
 - 20s - loss: 1.2748 - acc: 0.9620 - mDice: 0.7407 - val_loss: 1.9450 - val_acc: 0.9667 - val_mDice: 0.6853

Epoch 00019: val_mDice did not improve from 0.68884
Epoch 20/300
 - 19s - loss: 1.2679 - acc: 0.9622 - mDice: 0.7422 - val_loss: 1.9096 - val_acc: 0.9657 - val_mDice: 0.6842

Epoch 00020: val_mDice did not improve from 0.68884
Epoch 21/300
 - 19s - loss: 1.2625 - acc: 0.9622 - mDice: 0.7432 - val_loss: 1.8996 - val_acc: 0.9663 - val_mDice: 0.6887

Epoch 00021: val_mDice did not improve from 0.68884
Epoch 22/300
 - 19s - loss: 1.2538 - acc: 0.9624 - mDice: 0.7450 - val_loss: 1.8897 - val_acc: 0.9662 - val_mDice: 0.6889

Epoch 00022: val_mDice improved from 0.68884 to 0.68888, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 23/300
 - 19s - loss: 1.2460 - acc: 0.9625 - mDice: 0.7467 - val_loss: 1.8835 - val_acc: 0.9668 - val_mDice: 0.6925

Epoch 00023: val_mDice improved from 0.68888 to 0.69253, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 24/300
 - 19s - loss: 1.2432 - acc: 0.9625 - mDice: 0.7471 - val_loss: 2.0002 - val_acc: 0.9658 - val_mDice: 0.6857

Epoch 00024: val_mDice did not improve from 0.69253
Epoch 25/300
 - 19s - loss: 1.2374 - acc: 0.9626 - mDice: 0.7483 - val_loss: 1.9191 - val_acc: 0.9666 - val_mDice: 0.6909

Epoch 00025: val_mDice did not improve from 0.69253
Epoch 26/300
 - 20s - loss: 1.2313 - acc: 0.9627 - mDice: 0.7491 - val_loss: 1.9513 - val_acc: 0.9662 - val_mDice: 0.6922

Epoch 00026: val_mDice did not improve from 0.69253
Epoch 27/300
 - 19s - loss: 1.2255 - acc: 0.9628 - mDice: 0.7505 - val_loss: 1.9677 - val_acc: 0.9661 - val_mDice: 0.6879

Epoch 00027: val_mDice did not improve from 0.69253
Epoch 28/300
 - 19s - loss: 1.2236 - acc: 0.9628 - mDice: 0.7511 - val_loss: 1.9765 - val_acc: 0.9658 - val_mDice: 0.6909

Epoch 00028: val_mDice did not improve from 0.69253
Epoch 29/300
 - 20s - loss: 1.2175 - acc: 0.9629 - mDice: 0.7518 - val_loss: 2.0174 - val_acc: 0.9651 - val_mDice: 0.6871

Epoch 00029: val_mDice did not improve from 0.69253
Epoch 30/300
 - 20s - loss: 1.2116 - acc: 0.9630 - mDice: 0.7534 - val_loss: 2.0295 - val_acc: 0.9661 - val_mDice: 0.6911

Epoch 00030: val_mDice did not improve from 0.69253
Epoch 31/300
 - 18s - loss: 1.2071 - acc: 0.9631 - mDice: 0.7544 - val_loss: 2.0069 - val_acc: 0.9662 - val_mDice: 0.6912

Epoch 00031: val_mDice did not improve from 0.69253
Epoch 32/300
 - 19s - loss: 1.2051 - acc: 0.9631 - mDice: 0.7546 - val_loss: 2.0003 - val_acc: 0.9658 - val_mDice: 0.6859

Epoch 00032: val_mDice did not improve from 0.69253
Epoch 33/300
 - 19s - loss: 1.1994 - acc: 0.9632 - mDice: 0.7559 - val_loss: 2.0118 - val_acc: 0.9663 - val_mDice: 0.6893

Epoch 00033: val_mDice did not improve from 0.69253
Epoch 34/300
 - 19s - loss: 1.1931 - acc: 0.9633 - mDice: 0.7571 - val_loss: 2.0508 - val_acc: 0.9662 - val_mDice: 0.6916

Epoch 00034: val_mDice did not improve from 0.69253
Epoch 35/300
 - 20s - loss: 1.1909 - acc: 0.9633 - mDice: 0.7575 - val_loss: 2.0469 - val_acc: 0.9656 - val_mDice: 0.6911

Epoch 00035: val_mDice did not improve from 0.69253
Epoch 36/300
 - 19s - loss: 1.1882 - acc: 0.9633 - mDice: 0.7581 - val_loss: 1.9975 - val_acc: 0.9667 - val_mDice: 0.6949

Epoch 00036: val_mDice improved from 0.69253 to 0.69488, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 37/300
 - 19s - loss: 1.1842 - acc: 0.9634 - mDice: 0.7586 - val_loss: 1.9899 - val_acc: 0.9662 - val_mDice: 0.6925

Epoch 00037: val_mDice did not improve from 0.69488
Epoch 38/300
 - 19s - loss: 1.1801 - acc: 0.9635 - mDice: 0.7594 - val_loss: 2.0493 - val_acc: 0.9658 - val_mDice: 0.6905

Epoch 00038: val_mDice did not improve from 0.69488
Epoch 39/300
 - 19s - loss: 1.1772 - acc: 0.9636 - mDice: 0.7602 - val_loss: 2.0547 - val_acc: 0.9657 - val_mDice: 0.6881

Epoch 00039: val_mDice did not improve from 0.69488
Epoch 40/300
 - 19s - loss: 1.1736 - acc: 0.9635 - mDice: 0.7610 - val_loss: 1.9510 - val_acc: 0.9668 - val_mDice: 0.6955

Epoch 00040: val_mDice improved from 0.69488 to 0.69550, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 41/300
 - 20s - loss: 1.1708 - acc: 0.9636 - mDice: 0.7614 - val_loss: 2.0307 - val_acc: 0.9661 - val_mDice: 0.6919

Epoch 00041: val_mDice did not improve from 0.69550
Epoch 42/300
 - 19s - loss: 1.1681 - acc: 0.9636 - mDice: 0.7620 - val_loss: 2.0184 - val_acc: 0.9661 - val_mDice: 0.6934

Epoch 00042: val_mDice did not improve from 0.69550
Epoch 43/300
 - 19s - loss: 1.1641 - acc: 0.9637 - mDice: 0.7629 - val_loss: 1.9849 - val_acc: 0.9670 - val_mDice: 0.6979

Epoch 00043: val_mDice improved from 0.69550 to 0.69787, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 44/300
 - 19s - loss: 1.1639 - acc: 0.9637 - mDice: 0.7631 - val_loss: 2.0957 - val_acc: 0.9657 - val_mDice: 0.6941

Epoch 00044: val_mDice did not improve from 0.69787
Epoch 45/300
 - 20s - loss: 1.1601 - acc: 0.9638 - mDice: 0.7635 - val_loss: 2.0364 - val_acc: 0.9665 - val_mDice: 0.6942

Epoch 00045: val_mDice did not improve from 0.69787
Epoch 46/300
 - 19s - loss: 1.1568 - acc: 0.9638 - mDice: 0.7646 - val_loss: 1.9812 - val_acc: 0.9665 - val_mDice: 0.6920

Epoch 00046: val_mDice did not improve from 0.69787
Epoch 47/300
 - 20s - loss: 1.1523 - acc: 0.9638 - mDice: 0.7652 - val_loss: 2.1699 - val_acc: 0.9650 - val_mDice: 0.6901

Epoch 00047: val_mDice did not improve from 0.69787
Epoch 48/300
 - 19s - loss: 1.1488 - acc: 0.9639 - mDice: 0.7657 - val_loss: 2.0123 - val_acc: 0.9660 - val_mDice: 0.6956

Epoch 00048: val_mDice did not improve from 0.69787
Epoch 49/300
 - 19s - loss: 1.1493 - acc: 0.9639 - mDice: 0.7660 - val_loss: 2.0863 - val_acc: 0.9665 - val_mDice: 0.6958

Epoch 00049: val_mDice did not improve from 0.69787
Epoch 50/300
 - 19s - loss: 1.1477 - acc: 0.9639 - mDice: 0.7663 - val_loss: 2.0361 - val_acc: 0.9661 - val_mDice: 0.6907

Epoch 00050: val_mDice did not improve from 0.69787
Epoch 51/300
 - 19s - loss: 1.1431 - acc: 0.9640 - mDice: 0.7670 - val_loss: 2.0443 - val_acc: 0.9660 - val_mDice: 0.6970

Epoch 00051: val_mDice did not improve from 0.69787
Epoch 52/300
 - 19s - loss: 1.1413 - acc: 0.9641 - mDice: 0.7675 - val_loss: 2.0690 - val_acc: 0.9659 - val_mDice: 0.6921

Epoch 00052: val_mDice did not improve from 0.69787
Epoch 53/300
 - 19s - loss: 1.1417 - acc: 0.9641 - mDice: 0.7675 - val_loss: 2.0528 - val_acc: 0.9663 - val_mDice: 0.6914

Epoch 00053: val_mDice did not improve from 0.69787
Epoch 54/300
 - 19s - loss: 1.1354 - acc: 0.9641 - mDice: 0.7688 - val_loss: 2.0795 - val_acc: 0.9659 - val_mDice: 0.6922

Epoch 00054: val_mDice did not improve from 0.69787
Epoch 55/300
 - 19s - loss: 1.1380 - acc: 0.9641 - mDice: 0.7683 - val_loss: 2.0536 - val_acc: 0.9661 - val_mDice: 0.6928

Epoch 00055: val_mDice did not improve from 0.69787
Epoch 56/300
 - 20s - loss: 1.1324 - acc: 0.9642 - mDice: 0.7690 - val_loss: 2.0952 - val_acc: 0.9654 - val_mDice: 0.6907

Epoch 00056: val_mDice did not improve from 0.69787
Epoch 57/300
 - 19s - loss: 1.1337 - acc: 0.9642 - mDice: 0.7690 - val_loss: 2.1291 - val_acc: 0.9655 - val_mDice: 0.6886

Epoch 00057: val_mDice did not improve from 0.69787
Epoch 58/300
 - 19s - loss: 1.1292 - acc: 0.9642 - mDice: 0.7700 - val_loss: 2.1249 - val_acc: 0.9657 - val_mDice: 0.6894

Epoch 00058: val_mDice did not improve from 0.69787
Epoch 59/300
 - 19s - loss: 1.1284 - acc: 0.9642 - mDice: 0.7702 - val_loss: 2.1196 - val_acc: 0.9655 - val_mDice: 0.6901

Epoch 00059: val_mDice did not improve from 0.69787
Epoch 60/300
 - 19s - loss: 1.1270 - acc: 0.9643 - mDice: 0.7704 - val_loss: 2.0879 - val_acc: 0.9663 - val_mDice: 0.6894

Epoch 00060: val_mDice did not improve from 0.69787
Epoch 61/300
 - 19s - loss: 1.1255 - acc: 0.9643 - mDice: 0.7708 - val_loss: 2.1148 - val_acc: 0.9655 - val_mDice: 0.6922

Epoch 00061: val_mDice did not improve from 0.69787
Epoch 62/300
 - 19s - loss: 1.1234 - acc: 0.9643 - mDice: 0.7711 - val_loss: 2.1237 - val_acc: 0.9663 - val_mDice: 0.6942

Epoch 00062: val_mDice did not improve from 0.69787
Epoch 63/300
 - 19s - loss: 1.1183 - acc: 0.9644 - mDice: 0.7722 - val_loss: 2.0554 - val_acc: 0.9659 - val_mDice: 0.6920

Epoch 00063: val_mDice did not improve from 0.69787
Epoch 64/300
 - 19s - loss: 1.1178 - acc: 0.9644 - mDice: 0.7724 - val_loss: 2.1018 - val_acc: 0.9656 - val_mDice: 0.6913

Epoch 00064: val_mDice did not improve from 0.69787
Epoch 65/300
 - 20s - loss: 1.1182 - acc: 0.9644 - mDice: 0.7720 - val_loss: 2.1620 - val_acc: 0.9654 - val_mDice: 0.6935

Epoch 00065: val_mDice did not improve from 0.69787
Epoch 66/300
 - 18s - loss: 1.1144 - acc: 0.9645 - mDice: 0.7728 - val_loss: 2.0695 - val_acc: 0.9661 - val_mDice: 0.6959

Epoch 00066: val_mDice did not improve from 0.69787
Epoch 67/300
 - 19s - loss: 1.1129 - acc: 0.9645 - mDice: 0.7732 - val_loss: 2.1067 - val_acc: 0.9661 - val_mDice: 0.6938

Epoch 00067: val_mDice did not improve from 0.69787
Epoch 68/300
 - 20s - loss: 1.1131 - acc: 0.9645 - mDice: 0.7730 - val_loss: 2.0355 - val_acc: 0.9658 - val_mDice: 0.6922

Epoch 00068: val_mDice did not improve from 0.69787
Epoch 69/300
 - 19s - loss: 1.1073 - acc: 0.9645 - mDice: 0.7743 - val_loss: 2.1514 - val_acc: 0.9662 - val_mDice: 0.6899

Epoch 00069: val_mDice did not improve from 0.69787
Epoch 70/300
 - 19s - loss: 1.1088 - acc: 0.9645 - mDice: 0.7740 - val_loss: 2.1145 - val_acc: 0.9661 - val_mDice: 0.6919

Epoch 00070: val_mDice did not improve from 0.69787
Epoch 71/300
 - 19s - loss: 1.1030 - acc: 0.9646 - mDice: 0.7753 - val_loss: 2.1001 - val_acc: 0.9661 - val_mDice: 0.6936

Epoch 00071: val_mDice did not improve from 0.69787
Epoch 72/300
 - 18s - loss: 1.1044 - acc: 0.9646 - mDice: 0.7747 - val_loss: 2.1411 - val_acc: 0.9659 - val_mDice: 0.6936

Epoch 00072: val_mDice did not improve from 0.69787
Epoch 73/300
 - 19s - loss: 1.1019 - acc: 0.9646 - mDice: 0.7757 - val_loss: 2.2101 - val_acc: 0.9656 - val_mDice: 0.6845

Epoch 00073: val_mDice did not improve from 0.69787
Restoring model weights from the end of the best epoch
Epoch 00073: early stopping
{'val_loss': [1.669403025548752, 1.7121340509963363, 1.7111514284186167, 1.7656240463256836, 1.7563626537584278, 1.7161051639138836, 1.7795003489272234, 1.7240806099486679, 1.783641798855507, 1.839198300283249, 1.8655497423590046, 1.8986625818357075, 1.8548797369003296, 1.8660145998001099, 1.9068650644119471, 1.9343572365094537, 1.8726400871799416, 1.8946909447238869, 1.9449771789655292, 1.9096149549092332, 1.8996051843852213, 1.889658418420243, 1.8834969572824976, 2.0001669044363988, 1.9190511801471448, 1.951254469074615, 1.9677372550311154, 1.9764949622219556, 2.0173707857523877, 2.029536328903616, 2.006945984004295, 2.0003448267505592, 2.0118261559368813, 2.050842917128785, 2.0468938040406734, 1.997485489061434, 1.9899145364761353, 2.0492548028083695, 2.0547046351106197, 1.9509969100560227, 2.03066008548214, 2.018365306397007, 1.984870329295119, 2.0956539715806097, 2.0364082757740807, 1.9811873648264637, 2.1698991109247077, 2.0123385288943982, 2.0863426695131277, 2.0360910255615026, 2.0443314166918194, 2.0689797303447985, 2.05275580817706, 2.0795111933799637, 2.053641913688346, 2.095217472886386, 2.1291233970694345, 2.1249120725344306, 2.1195987593637753, 2.087911950398798, 2.114838030240307, 2.1237187712159877, 2.055448107523461, 2.1017850506795597, 2.162036020461827, 2.069510861618878, 2.1067047592711776, 2.0355221278046907, 2.1514479656742043, 2.1144894508466328, 2.100056666217438, 2.141080487264346, 2.2101098005085777], 'val_acc': [0.9672892510074459, 0.967707583349045, 0.9676186556685461, 0.9666985452991642, 0.9670904727831279, 0.9675449900431176, 0.9670738022621364, 0.966880637488953, 0.9667569415210044, 0.9662968891940705, 0.9661634319449124, 0.9657311741619894, 0.966918119828995, 0.9664636466601123, 0.9667138293997882, 0.9667902858289954, 0.9667916746988688, 0.9665720495459151, 0.9666943835885558, 0.9656922768240106, 0.9662676853676365, 0.9661620438915409, 0.9667749813158218, 0.9657728786337866, 0.96657901757384, 0.9662260013083889, 0.966057834559924, 0.9657534295565462, 0.9650654433524772, 0.9660619660599591, 0.9662329317772225, 0.965793738626454, 0.9662885224982484, 0.9661856726424335, 0.9656338822351743, 0.966722162619029, 0.9661620512400588, 0.9658215119414133, 0.9656686448071101, 0.9667555404036012, 0.9661439567396085, 0.9661481739723519, 0.9669793093041198, 0.9656881020493704, 0.966483132479942, 0.9664900335547042, 0.965005681939321, 0.9660119528639807, 0.9664719937598869, 0.966118965246906, 0.9660035992321903, 0.9658715586139731, 0.9663163448033267, 0.9658924128911267, 0.9660758849692671, 0.9653614922745587, 0.965471284030235, 0.9656811528009911, 0.9655171355156049, 0.9662593652124274, 0.9655463270945092, 0.9662537738068463, 0.9658951930803795, 0.9655546701117738, 0.9653809454343091, 0.9660842271700297, 0.9660703025452079, 0.9658020653136788, 0.9661592653352921, 0.9660675484840184, 0.9660592087327617, 0.9658701779091194, 0.9656311069449334], 'val_mDice': [0.6660259635481116, 0.6712478636062309, 0.6778736588073103, 0.6778980289420037, 0.6806663111464618, 0.6844912163198811, 0.6846018882646953, 0.685448752690668, 0.6850069891916563, 0.6872340849001114, 0.6809884815999906, 0.6838221574482852, 0.6872494628984634, 0.6882806314180975, 0.6854608254889919, 0.6856485817530383, 0.6866654043328272, 0.6888371412068197, 0.6852887885211265, 0.6841758473278725, 0.6886576414108276, 0.6888809040801166, 0.6925338604678847, 0.685738835432758, 0.6909165243579917, 0.6922127686134757, 0.6879200127026807, 0.6908950095307337, 0.6870846029830305, 0.6910796777842796, 0.6912152522230801, 0.68588417605178, 0.6892835146760288, 0.6916290889047596, 0.691078878428838, 0.6948785079668646, 0.692541342075557, 0.6905357641716526, 0.6881486659180628, 0.6954977545019698, 0.6919149936062016, 0.6934208094257198, 0.6978666594583695, 0.6941470005740858, 0.6942437617746118, 0.6919511964876358, 0.6901457938429427, 0.6955538383901936, 0.6957728715792094, 0.6907398643558973, 0.6969776055584215, 0.6920809998904189, 0.691364733323659, 0.6921933873058999, 0.6928062096034011, 0.6906582476341561, 0.6885647692092477, 0.6893804008013582, 0.6901230142541128, 0.6894126346666519, 0.6921834472107561, 0.694161840497631, 0.6919873462964411, 0.6913273293678075, 0.6935061240849429, 0.695924022426344, 0.6938321231162712, 0.6921665897108105, 0.6898737247676066, 0.6918511055920222, 0.6935522850245646, 0.6936379205690671, 0.6845106784611532], 'loss': [2.0421573810875757, 1.705245954750007, 1.6088171031269907, 1.5486465115264565, 1.5034356787850003, 1.4678671097945846, 1.4445792581557884, 1.4146601150381324, 1.3963500740635053, 1.3757424493283543, 1.3605913198338553, 1.3458179916296393, 1.3349936209247255, 1.3209959725241815, 1.3121041882748947, 1.3033348761513692, 1.2963862872435825, 1.2839498737799988, 1.2747796628164942, 1.2678720575083928, 1.2625065045529125, 1.253773797738089, 1.2460150105319123, 1.2431880193866782, 1.2373883530219267, 1.231305084142328, 1.225539526037144, 1.223614689216151, 1.2175244286827287, 1.211648829425841, 1.207079224498295, 1.2051144053161034, 1.1993987512382338, 1.1930552003892314, 1.1908798044718458, 1.1882354957824182, 1.1842213237256265, 1.1801471688085539, 1.1772454350458383, 1.173608079158042, 1.1707514737458842, 1.1681434517364018, 1.1641303809392218, 1.1638548989192306, 1.1600919351422851, 1.15681600141531, 1.1523040426834734, 1.1488208757329903, 1.1493465162315706, 1.1477183318851103, 1.1431381484556362, 1.1412846017247498, 1.1416666683174, 1.1354226086624017, 1.1380351173056644, 1.1323677389956606, 1.1337010647730448, 1.1291977135560853, 1.128398792214532, 1.126956644791537, 1.1254563874892842, 1.1233508825688678, 1.1183021888141338, 1.1178079599740878, 1.1182170355634231, 1.11443662741861, 1.11294311029821, 1.1130777364850066, 1.10731772246006, 1.1087793860930564, 1.1029928706110772, 1.1043945809516764, 1.1019199346054325], 'acc': [0.9528787969963075, 0.9562295760033489, 0.9574920594824661, 0.9582912463873547, 0.9588259135267294, 0.9593622243591223, 0.9596174842121722, 0.9601136696866229, 0.960362688887193, 0.9605939648949277, 0.9608133005135225, 0.9610431882337658, 0.9611830901492575, 0.9613944330294483, 0.9614995653540682, 0.9616623709368318, 0.9617701138432431, 0.9619793151224267, 0.9620492591060748, 0.9621865365560052, 0.9622141990383588, 0.9623965515228805, 0.9625029201401051, 0.962531381309666, 0.962638819499724, 0.962729649780563, 0.9628173117629617, 0.9628166772757594, 0.9629033517960649, 0.9629746116847668, 0.963090481872223, 0.9631336532984597, 0.9631995640702701, 0.963314945322826, 0.9633101460697887, 0.963310681176545, 0.9634115421105554, 0.9634833218084544, 0.9635521676213521, 0.9635284806181201, 0.963607087787734, 0.9636248336291876, 0.963701612633112, 0.9637325630956517, 0.9637540067408326, 0.9638229767918151, 0.9638450206854404, 0.9638841095890132, 0.9639390662884287, 0.9639287100807221, 0.963996531311502, 0.9640727495027578, 0.9640596889629168, 0.96410902668347, 0.9641113420123489, 0.9641877058203325, 0.964176192073459, 0.964249998808895, 0.9642485243840482, 0.9642784517140516, 0.9642911966352543, 0.9643160544457983, 0.9644006453447783, 0.9643889227901602, 0.9644289511406751, 0.9644837249100605, 0.9644784728793391, 0.9644578313287769, 0.9645059504595159, 0.9645486859303727, 0.9646418316868385, 0.9646085643599371, 0.9646404515921673], 'mDice': [0.621489215933696, 0.661172980157089, 0.6774536368439292, 0.6879245682370589, 0.6964310245714924, 0.7031537597046122, 0.7076453236010829, 0.7134232418620035, 0.7170121940357839, 0.720874872621685, 0.7239626075228879, 0.7266496168538442, 0.7288520290480357, 0.731284588480514, 0.7332736299409169, 0.734941122324726, 0.7365182297140859, 0.7387735775617595, 0.7407261345155002, 0.7422304003043826, 0.7431820248122947, 0.7449885876352118, 0.7467396592604235, 0.7470627327921125, 0.748256368164056, 0.7491385487581541, 0.7504526396230957, 0.7510740773166571, 0.7518399344982131, 0.7533558442887118, 0.7544051182847735, 0.7546078912819397, 0.7559350830709899, 0.7571098284593095, 0.7574692544962618, 0.7581219529558687, 0.7585849188787618, 0.7593815792668498, 0.7602432068637103, 0.7610195992780807, 0.76141196831149, 0.7620164861351507, 0.7629117121218576, 0.763111991301919, 0.7634879925090229, 0.7645919680709933, 0.7652123277734109, 0.7657142044123046, 0.7660116447361855, 0.766257292364035, 0.7669812384499578, 0.7674733930963271, 0.7675257193135233, 0.7687879477378764, 0.7682931488865826, 0.7690103662799287, 0.7690048700215645, 0.7700284318022561, 0.7702447678214872, 0.7703651709255352, 0.7708011045904336, 0.7711180280631192, 0.7722085053975293, 0.7723758381844598, 0.7720041182788079, 0.772835628360569, 0.7731829276637817, 0.7730237824712252, 0.774309954456844, 0.774026923367034, 0.7752824783368146, 0.774743109152266, 0.7756737778474997]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:02<00:07,  2.43s/it]predicting test subjects:  50%|█████     | 2/4 [00:04<00:04,  2.17s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:05<00:02,  2.02s/it]predicting test subjects: 100%|██████████| 4/4 [00:07<00:00,  1.94s/it]
predicting train subjects:   0%|          | 0/456 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/456 [00:01<13:05,  1.73s/it]predicting train subjects:   0%|          | 2/456 [00:03<13:07,  1.73s/it]predicting train subjects:   1%|          | 3/456 [00:05<13:02,  1.73s/it]predicting train subjects:   1%|          | 4/456 [00:06<12:25,  1.65s/it]predicting train subjects:   1%|          | 5/456 [00:08<13:46,  1.83s/it]predicting train subjects:   1%|▏         | 6/456 [00:10<13:25,  1.79s/it]predicting train subjects:   2%|▏         | 7/456 [00:12<12:46,  1.71s/it]predicting train subjects:   2%|▏         | 8/456 [00:13<11:20,  1.52s/it]predicting train subjects:   2%|▏         | 9/456 [00:15<11:59,  1.61s/it]predicting train subjects:   2%|▏         | 10/456 [00:16<12:44,  1.71s/it]predicting train subjects:   2%|▏         | 11/456 [00:19<13:30,  1.82s/it]predicting train subjects:   3%|▎         | 12/456 [00:20<12:04,  1.63s/it]predicting train subjects:   3%|▎         | 13/456 [00:21<12:15,  1.66s/it]predicting train subjects:   3%|▎         | 14/456 [00:23<12:54,  1.75s/it]predicting train subjects:   3%|▎         | 15/456 [00:25<11:39,  1.59s/it]predicting train subjects:   4%|▎         | 16/456 [00:27<12:26,  1.70s/it]predicting train subjects:   4%|▎         | 17/456 [00:29<13:20,  1.82s/it]predicting train subjects:   4%|▍         | 18/456 [00:30<12:57,  1.78s/it]predicting train subjects:   4%|▍         | 19/456 [00:32<12:22,  1.70s/it]predicting train subjects:   4%|▍         | 20/456 [00:33<11:44,  1.62s/it]predicting train subjects:   5%|▍         | 21/456 [00:35<11:46,  1.62s/it]predicting train subjects:   5%|▍         | 22/456 [00:37<12:18,  1.70s/it]predicting train subjects:   5%|▌         | 23/456 [00:39<12:32,  1.74s/it]predicting train subjects:   5%|▌         | 24/456 [00:40<10:40,  1.48s/it]predicting train subjects:   5%|▌         | 25/456 [00:41<11:24,  1.59s/it]predicting train subjects:   6%|▌         | 26/456 [00:43<11:42,  1.63s/it]predicting train subjects:   6%|▌         | 27/456 [00:45<11:23,  1.59s/it]predicting train subjects:   6%|▌         | 28/456 [00:46<11:22,  1.59s/it]predicting train subjects:   6%|▋         | 29/456 [00:48<11:48,  1.66s/it]predicting train subjects:   7%|▋         | 30/456 [00:50<11:48,  1.66s/it]predicting train subjects:   7%|▋         | 31/456 [00:51<11:54,  1.68s/it]predicting train subjects:   7%|▋         | 32/456 [00:53<11:39,  1.65s/it]predicting train subjects:   7%|▋         | 33/456 [00:55<11:56,  1.69s/it]predicting train subjects:   7%|▋         | 34/456 [00:57<12:02,  1.71s/it]predicting train subjects:   8%|▊         | 35/456 [00:58<11:39,  1.66s/it]predicting train subjects:   8%|▊         | 36/456 [01:00<12:13,  1.75s/it]predicting train subjects:   8%|▊         | 37/456 [01:02<12:05,  1.73s/it]predicting train subjects:   8%|▊         | 38/456 [01:03<11:45,  1.69s/it]predicting train subjects:   9%|▊         | 39/456 [01:05<12:03,  1.74s/it]predicting train subjects:   9%|▉         | 40/456 [01:07<12:03,  1.74s/it]predicting train subjects:   9%|▉         | 41/456 [01:09<11:54,  1.72s/it]predicting train subjects:   9%|▉         | 42/456 [01:10<11:55,  1.73s/it]predicting train subjects:   9%|▉         | 43/456 [01:12<11:52,  1.72s/it]predicting train subjects:  10%|▉         | 44/456 [01:14<12:01,  1.75s/it]predicting train subjects:  10%|▉         | 45/456 [01:16<12:33,  1.83s/it]predicting train subjects:  10%|█         | 46/456 [01:18<12:11,  1.78s/it]predicting train subjects:  10%|█         | 47/456 [01:20<12:37,  1.85s/it]predicting train subjects:  11%|█         | 48/456 [01:21<12:08,  1.79s/it]predicting train subjects:  11%|█         | 49/456 [01:23<12:26,  1.83s/it]predicting train subjects:  11%|█         | 50/456 [01:25<12:03,  1.78s/it]predicting train subjects:  11%|█         | 51/456 [01:27<11:58,  1.77s/it]predicting train subjects:  11%|█▏        | 52/456 [01:28<12:03,  1.79s/it]predicting train subjects:  12%|█▏        | 53/456 [01:30<11:46,  1.75s/it]predicting train subjects:  12%|█▏        | 54/456 [01:32<11:34,  1.73s/it]predicting train subjects:  12%|█▏        | 55/456 [01:34<11:44,  1.76s/it]predicting train subjects:  12%|█▏        | 56/456 [01:35<11:36,  1.74s/it]predicting train subjects:  12%|█▎        | 57/456 [01:37<11:15,  1.69s/it]predicting train subjects:  13%|█▎        | 58/456 [01:39<11:51,  1.79s/it]predicting train subjects:  13%|█▎        | 59/456 [01:41<12:06,  1.83s/it]predicting train subjects:  13%|█▎        | 60/456 [01:42<11:50,  1.79s/it]predicting train subjects:  13%|█▎        | 61/456 [01:44<12:02,  1.83s/it]predicting train subjects:  14%|█▎        | 62/456 [01:46<12:01,  1.83s/it]predicting train subjects:  14%|█▍        | 63/456 [01:48<11:45,  1.80s/it]predicting train subjects:  14%|█▍        | 64/456 [01:50<11:52,  1.82s/it]predicting train subjects:  14%|█▍        | 65/456 [01:52<12:01,  1.85s/it]predicting train subjects:  14%|█▍        | 66/456 [01:53<11:45,  1.81s/it]predicting train subjects:  15%|█▍        | 67/456 [01:55<11:41,  1.80s/it]predicting train subjects:  15%|█▍        | 68/456 [01:57<11:45,  1.82s/it]predicting train subjects:  15%|█▌        | 69/456 [01:59<11:33,  1.79s/it]predicting train subjects:  15%|█▌        | 70/456 [02:01<11:28,  1.78s/it]predicting train subjects:  16%|█▌        | 71/456 [02:03<11:43,  1.83s/it]predicting train subjects:  16%|█▌        | 72/456 [02:04<11:33,  1.81s/it]predicting train subjects:  16%|█▌        | 73/456 [02:06<11:35,  1.82s/it]predicting train subjects:  16%|█▌        | 74/456 [02:08<11:54,  1.87s/it]predicting train subjects:  16%|█▋        | 75/456 [02:10<11:45,  1.85s/it]predicting train subjects:  17%|█▋        | 76/456 [02:12<11:27,  1.81s/it]predicting train subjects:  17%|█▋        | 77/456 [02:14<11:44,  1.86s/it]predicting train subjects:  17%|█▋        | 78/456 [02:15<11:44,  1.86s/it]predicting train subjects:  17%|█▋        | 79/456 [02:16<09:52,  1.57s/it]predicting train subjects:  18%|█▊        | 80/456 [02:17<08:57,  1.43s/it]predicting train subjects:  18%|█▊        | 81/456 [02:18<08:02,  1.29s/it]predicting train subjects:  18%|█▊        | 82/456 [02:19<07:31,  1.21s/it]predicting train subjects:  18%|█▊        | 83/456 [02:20<07:00,  1.13s/it]predicting train subjects:  18%|█▊        | 84/456 [02:21<06:41,  1.08s/it]predicting train subjects:  19%|█▊        | 85/456 [02:22<06:19,  1.02s/it]predicting train subjects:  19%|█▉        | 86/456 [02:23<06:33,  1.06s/it]predicting train subjects:  19%|█▉        | 87/456 [02:24<06:24,  1.04s/it]predicting train subjects:  19%|█▉        | 88/456 [02:26<06:32,  1.07s/it]predicting train subjects:  20%|█▉        | 89/456 [02:27<06:29,  1.06s/it]predicting train subjects:  20%|█▉        | 90/456 [02:27<06:11,  1.01s/it]predicting train subjects:  20%|█▉        | 91/456 [02:29<06:21,  1.04s/it]predicting train subjects:  20%|██        | 92/456 [02:30<06:08,  1.01s/it]predicting train subjects:  20%|██        | 93/456 [02:30<06:03,  1.00s/it]predicting train subjects:  21%|██        | 94/456 [02:32<06:15,  1.04s/it]predicting train subjects:  21%|██        | 95/456 [02:33<06:10,  1.03s/it]predicting train subjects:  21%|██        | 96/456 [02:34<06:01,  1.00s/it]predicting train subjects:  21%|██▏       | 97/456 [02:35<07:24,  1.24s/it]predicting train subjects:  21%|██▏       | 98/456 [02:37<08:07,  1.36s/it]predicting train subjects:  22%|██▏       | 99/456 [02:39<08:37,  1.45s/it]predicting train subjects:  22%|██▏       | 100/456 [02:40<09:09,  1.54s/it]predicting train subjects:  22%|██▏       | 101/456 [02:42<09:13,  1.56s/it]predicting train subjects:  22%|██▏       | 102/456 [02:44<09:15,  1.57s/it]predicting train subjects:  23%|██▎       | 103/456 [02:45<09:23,  1.60s/it]predicting train subjects:  23%|██▎       | 104/456 [02:47<09:49,  1.68s/it]predicting train subjects:  23%|██▎       | 105/456 [02:49<09:44,  1.66s/it]predicting train subjects:  23%|██▎       | 106/456 [02:50<09:33,  1.64s/it]predicting train subjects:  23%|██▎       | 107/456 [02:52<10:08,  1.74s/it]predicting train subjects:  24%|██▎       | 108/456 [02:54<10:02,  1.73s/it]predicting train subjects:  24%|██▍       | 109/456 [02:56<09:51,  1.71s/it]predicting train subjects:  24%|██▍       | 110/456 [02:57<09:51,  1.71s/it]predicting train subjects:  24%|██▍       | 111/456 [02:59<09:56,  1.73s/it]predicting train subjects:  25%|██▍       | 112/456 [03:01<09:47,  1.71s/it]predicting train subjects:  25%|██▍       | 113/456 [03:02<09:35,  1.68s/it]predicting train subjects:  25%|██▌       | 114/456 [03:04<09:56,  1.75s/it]predicting train subjects:  25%|██▌       | 115/456 [03:06<09:38,  1.70s/it]predicting train subjects:  25%|██▌       | 116/456 [03:08<09:31,  1.68s/it]predicting train subjects:  26%|██▌       | 117/456 [03:10<10:04,  1.78s/it]predicting train subjects:  26%|██▌       | 118/456 [03:12<10:26,  1.85s/it]predicting train subjects:  26%|██▌       | 119/456 [03:13<10:05,  1.80s/it]predicting train subjects:  26%|██▋       | 120/456 [03:15<10:14,  1.83s/it]predicting train subjects:  27%|██▋       | 121/456 [03:17<10:44,  1.93s/it]predicting train subjects:  27%|██▋       | 122/456 [03:19<10:46,  1.94s/it]predicting train subjects:  27%|██▋       | 123/456 [03:21<10:42,  1.93s/it]predicting train subjects:  27%|██▋       | 124/456 [03:23<10:34,  1.91s/it]predicting train subjects:  27%|██▋       | 125/456 [03:25<10:11,  1.85s/it]predicting train subjects:  28%|██▊       | 126/456 [03:27<10:09,  1.85s/it]predicting train subjects:  28%|██▊       | 127/456 [03:28<09:35,  1.75s/it]predicting train subjects:  28%|██▊       | 128/456 [03:30<09:07,  1.67s/it]predicting train subjects:  28%|██▊       | 129/456 [03:31<08:27,  1.55s/it]predicting train subjects:  29%|██▊       | 130/456 [03:32<08:15,  1.52s/it]predicting train subjects:  29%|██▊       | 131/456 [03:34<07:58,  1.47s/it]predicting train subjects:  29%|██▉       | 132/456 [03:35<07:47,  1.44s/it]predicting train subjects:  29%|██▉       | 133/456 [03:37<08:57,  1.66s/it]predicting train subjects:  29%|██▉       | 134/456 [03:39<09:38,  1.80s/it]predicting train subjects:  30%|██▉       | 135/456 [03:41<09:54,  1.85s/it]predicting train subjects:  30%|██▉       | 136/456 [03:43<10:21,  1.94s/it]predicting train subjects:  30%|███       | 137/456 [03:46<10:43,  2.02s/it]predicting train subjects:  30%|███       | 138/456 [03:48<10:39,  2.01s/it]predicting train subjects:  30%|███       | 139/456 [03:49<09:47,  1.85s/it]predicting train subjects:  31%|███       | 140/456 [03:51<09:00,  1.71s/it]predicting train subjects:  31%|███       | 141/456 [03:52<08:20,  1.59s/it]predicting train subjects:  31%|███       | 142/456 [03:53<08:02,  1.54s/it]predicting train subjects:  31%|███▏      | 143/456 [03:55<07:59,  1.53s/it]predicting train subjects:  32%|███▏      | 144/456 [03:56<07:58,  1.53s/it]predicting train subjects:  32%|███▏      | 145/456 [03:58<07:51,  1.52s/it]predicting train subjects:  32%|███▏      | 146/456 [03:59<08:05,  1.57s/it]predicting train subjects:  32%|███▏      | 147/456 [04:01<08:27,  1.64s/it]predicting train subjects:  32%|███▏      | 148/456 [04:03<08:15,  1.61s/it]predicting train subjects:  33%|███▎      | 149/456 [04:04<07:58,  1.56s/it]predicting train subjects:  33%|███▎      | 150/456 [04:06<07:58,  1.56s/it]predicting train subjects:  33%|███▎      | 151/456 [04:08<08:10,  1.61s/it]predicting train subjects:  33%|███▎      | 152/456 [04:09<08:03,  1.59s/it]predicting train subjects:  34%|███▎      | 153/456 [04:11<08:06,  1.61s/it]predicting train subjects:  34%|███▍      | 154/456 [04:13<08:18,  1.65s/it]predicting train subjects:  34%|███▍      | 155/456 [04:14<08:05,  1.61s/it]predicting train subjects:  34%|███▍      | 156/456 [04:16<07:58,  1.60s/it]predicting train subjects:  34%|███▍      | 157/456 [04:17<07:52,  1.58s/it]predicting train subjects:  35%|███▍      | 158/456 [04:19<07:45,  1.56s/it]predicting train subjects:  35%|███▍      | 159/456 [04:20<07:33,  1.53s/it]predicting train subjects:  35%|███▌      | 160/456 [04:22<07:25,  1.51s/it]predicting train subjects:  35%|███▌      | 161/456 [04:23<07:20,  1.49s/it]predicting train subjects:  36%|███▌      | 162/456 [04:24<07:13,  1.47s/it]predicting train subjects:  36%|███▌      | 163/456 [04:26<06:36,  1.35s/it]predicting train subjects:  36%|███▌      | 164/456 [04:27<06:17,  1.29s/it]predicting train subjects:  36%|███▌      | 165/456 [04:28<05:54,  1.22s/it]predicting train subjects:  36%|███▋      | 166/456 [04:29<05:46,  1.20s/it]predicting train subjects:  37%|███▋      | 167/456 [04:30<05:28,  1.14s/it]predicting train subjects:  37%|███▋      | 168/456 [04:31<05:10,  1.08s/it]predicting train subjects:  37%|███▋      | 169/456 [04:32<05:06,  1.07s/it]predicting train subjects:  37%|███▋      | 170/456 [04:33<05:07,  1.07s/it]predicting train subjects:  38%|███▊      | 171/456 [04:34<05:13,  1.10s/it]predicting train subjects:  38%|███▊      | 172/456 [04:35<05:11,  1.10s/it]predicting train subjects:  38%|███▊      | 173/456 [04:36<05:03,  1.07s/it]predicting train subjects:  38%|███▊      | 174/456 [04:37<05:09,  1.10s/it]predicting train subjects:  38%|███▊      | 175/456 [04:38<04:58,  1.06s/it]predicting train subjects:  39%|███▊      | 176/456 [04:39<04:54,  1.05s/it]predicting train subjects:  39%|███▉      | 177/456 [04:40<04:47,  1.03s/it]predicting train subjects:  39%|███▉      | 178/456 [04:41<04:47,  1.03s/it]predicting train subjects:  39%|███▉      | 179/456 [04:42<04:49,  1.05s/it]predicting train subjects:  39%|███▉      | 180/456 [04:44<04:55,  1.07s/it]predicting train subjects:  40%|███▉      | 181/456 [04:46<06:04,  1.32s/it]predicting train subjects:  40%|███▉      | 182/456 [04:47<06:52,  1.51s/it]predicting train subjects:  40%|████      | 183/456 [04:50<07:38,  1.68s/it]predicting train subjects:  40%|████      | 184/456 [04:51<07:50,  1.73s/it]predicting train subjects:  41%|████      | 185/456 [04:53<08:16,  1.83s/it]predicting train subjects:  41%|████      | 186/456 [04:55<08:18,  1.85s/it]predicting train subjects:  41%|████      | 187/456 [04:57<08:33,  1.91s/it]predicting train subjects:  41%|████      | 188/456 [05:00<08:59,  2.01s/it]predicting train subjects:  41%|████▏     | 189/456 [05:02<09:12,  2.07s/it]predicting train subjects:  42%|████▏     | 190/456 [05:04<09:23,  2.12s/it]predicting train subjects:  42%|████▏     | 191/456 [05:06<09:17,  2.10s/it]predicting train subjects:  42%|████▏     | 192/456 [05:08<09:28,  2.15s/it]predicting train subjects:  42%|████▏     | 193/456 [05:11<09:30,  2.17s/it]predicting train subjects:  43%|████▎     | 194/456 [05:13<09:12,  2.11s/it]predicting train subjects:  43%|████▎     | 195/456 [05:15<09:04,  2.09s/it]predicting train subjects:  43%|████▎     | 196/456 [05:16<08:37,  1.99s/it]predicting train subjects:  43%|████▎     | 197/456 [05:18<08:34,  1.98s/it]predicting train subjects:  43%|████▎     | 198/456 [05:20<08:27,  1.97s/it]predicting train subjects:  44%|████▎     | 199/456 [05:22<08:10,  1.91s/it]predicting train subjects:  44%|████▍     | 200/456 [05:24<08:09,  1.91s/it]predicting train subjects:  44%|████▍     | 201/456 [05:26<08:04,  1.90s/it]predicting train subjects:  44%|████▍     | 202/456 [05:28<07:50,  1.85s/it]predicting train subjects:  45%|████▍     | 203/456 [05:29<07:37,  1.81s/it]predicting train subjects:  45%|████▍     | 204/456 [05:31<07:32,  1.80s/it]predicting train subjects:  45%|████▍     | 205/456 [05:33<07:06,  1.70s/it]predicting train subjects:  45%|████▌     | 206/456 [05:34<06:43,  1.62s/it]predicting train subjects:  45%|████▌     | 207/456 [05:35<06:29,  1.57s/it]predicting train subjects:  46%|████▌     | 208/456 [05:37<06:04,  1.47s/it]predicting train subjects:  46%|████▌     | 209/456 [05:38<06:18,  1.53s/it]predicting train subjects:  46%|████▌     | 210/456 [05:40<06:11,  1.51s/it]predicting train subjects:  46%|████▋     | 211/456 [05:41<06:24,  1.57s/it]predicting train subjects:  46%|████▋     | 212/456 [05:43<06:36,  1.62s/it]predicting train subjects:  47%|████▋     | 213/456 [05:45<06:50,  1.69s/it]predicting train subjects:  47%|████▋     | 214/456 [05:47<06:45,  1.67s/it]predicting train subjects:  47%|████▋     | 215/456 [05:49<07:06,  1.77s/it]predicting train subjects:  47%|████▋     | 216/456 [05:50<07:03,  1.77s/it]predicting train subjects:  48%|████▊     | 217/456 [05:52<06:45,  1.70s/it]predicting train subjects:  48%|████▊     | 218/456 [05:54<06:52,  1.74s/it]predicting train subjects:  48%|████▊     | 219/456 [05:55<06:40,  1.69s/it]predicting train subjects:  48%|████▊     | 220/456 [05:57<06:32,  1.66s/it]predicting train subjects:  48%|████▊     | 221/456 [05:59<06:34,  1.68s/it]predicting train subjects:  49%|████▊     | 222/456 [06:01<06:43,  1.72s/it]predicting train subjects:  49%|████▉     | 223/456 [06:02<06:25,  1.66s/it]predicting train subjects:  49%|████▉     | 224/456 [06:04<06:13,  1.61s/it]predicting train subjects:  49%|████▉     | 225/456 [06:06<06:36,  1.72s/it]predicting train subjects:  50%|████▉     | 226/456 [06:07<06:26,  1.68s/it]predicting train subjects:  50%|████▉     | 227/456 [06:09<06:13,  1.63s/it]predicting train subjects:  50%|█████     | 228/456 [06:10<06:09,  1.62s/it]predicting train subjects:  50%|█████     | 229/456 [06:12<06:07,  1.62s/it]predicting train subjects:  50%|█████     | 230/456 [06:13<05:59,  1.59s/it]predicting train subjects:  51%|█████     | 231/456 [06:15<05:55,  1.58s/it]predicting train subjects:  51%|█████     | 232/456 [06:17<06:03,  1.62s/it]predicting train subjects:  51%|█████     | 233/456 [06:18<05:53,  1.59s/it]predicting train subjects:  51%|█████▏    | 234/456 [06:20<05:57,  1.61s/it]predicting train subjects:  52%|█████▏    | 235/456 [06:22<06:04,  1.65s/it]predicting train subjects:  52%|█████▏    | 236/456 [06:23<06:01,  1.65s/it]predicting train subjects:  52%|█████▏    | 237/456 [06:25<06:05,  1.67s/it]predicting train subjects:  52%|█████▏    | 238/456 [06:27<06:08,  1.69s/it]predicting train subjects:  52%|█████▏    | 239/456 [06:28<05:59,  1.65s/it]predicting train subjects:  53%|█████▎    | 240/456 [06:30<06:04,  1.69s/it]predicting train subjects:  53%|█████▎    | 241/456 [06:32<06:17,  1.75s/it]predicting train subjects:  53%|█████▎    | 242/456 [06:34<06:13,  1.75s/it]predicting train subjects:  53%|█████▎    | 243/456 [06:35<06:15,  1.76s/it]predicting train subjects:  54%|█████▎    | 244/456 [06:37<06:11,  1.75s/it]predicting train subjects:  54%|█████▎    | 245/456 [06:39<06:20,  1.80s/it]predicting train subjects:  54%|█████▍    | 246/456 [06:41<06:21,  1.82s/it]predicting train subjects:  54%|█████▍    | 247/456 [06:42<05:52,  1.69s/it]predicting train subjects:  54%|█████▍    | 248/456 [06:44<05:32,  1.60s/it]predicting train subjects:  55%|█████▍    | 249/456 [06:45<05:24,  1.57s/it]predicting train subjects:  55%|█████▍    | 250/456 [06:47<05:16,  1.53s/it]predicting train subjects:  55%|█████▌    | 251/456 [06:48<05:01,  1.47s/it]predicting train subjects:  55%|█████▌    | 252/456 [06:49<04:58,  1.46s/it]predicting train subjects:  55%|█████▌    | 253/456 [06:52<05:47,  1.71s/it]predicting train subjects:  56%|█████▌    | 254/456 [06:54<06:05,  1.81s/it]predicting train subjects:  56%|█████▌    | 255/456 [06:56<06:33,  1.96s/it]predicting train subjects:  56%|█████▌    | 256/456 [06:58<06:41,  2.01s/it]predicting train subjects:  56%|█████▋    | 257/456 [07:00<06:37,  2.00s/it]predicting train subjects:  57%|█████▋    | 258/456 [07:02<06:31,  1.98s/it]predicting train subjects:  57%|█████▋    | 259/456 [07:03<05:51,  1.78s/it]predicting train subjects:  57%|█████▋    | 260/456 [07:05<05:34,  1.71s/it]predicting train subjects:  57%|█████▋    | 261/456 [07:07<05:29,  1.69s/it]predicting train subjects:  57%|█████▋    | 262/456 [07:08<05:22,  1.66s/it]predicting train subjects:  58%|█████▊    | 263/456 [07:11<06:15,  1.95s/it]predicting train subjects:  58%|█████▊    | 264/456 [07:12<05:48,  1.81s/it]predicting train subjects:  58%|█████▊    | 265/456 [07:14<05:23,  1.69s/it]predicting train subjects:  58%|█████▊    | 266/456 [07:15<05:10,  1.63s/it]predicting train subjects:  59%|█████▊    | 267/456 [07:17<05:01,  1.59s/it]predicting train subjects:  59%|█████▉    | 268/456 [07:18<05:03,  1.62s/it]predicting train subjects:  59%|█████▉    | 269/456 [07:20<04:59,  1.60s/it]predicting train subjects:  59%|█████▉    | 270/456 [07:21<04:51,  1.57s/it]predicting train subjects:  59%|█████▉    | 271/456 [07:23<04:54,  1.59s/it]predicting train subjects:  60%|█████▉    | 272/456 [07:25<04:52,  1.59s/it]predicting train subjects:  60%|█████▉    | 273/456 [07:26<04:47,  1.57s/it]predicting train subjects:  60%|██████    | 274/456 [07:28<04:42,  1.55s/it]predicting train subjects:  60%|██████    | 275/456 [07:30<05:00,  1.66s/it]predicting train subjects:  61%|██████    | 276/456 [07:31<04:58,  1.66s/it]predicting train subjects:  61%|██████    | 277/456 [07:33<04:56,  1.66s/it]predicting train subjects:  61%|██████    | 278/456 [07:34<04:44,  1.60s/it]predicting train subjects:  61%|██████    | 279/456 [07:36<04:37,  1.57s/it]predicting train subjects:  61%|██████▏   | 280/456 [07:37<04:32,  1.55s/it]predicting train subjects:  62%|██████▏   | 281/456 [07:39<04:25,  1.52s/it]predicting train subjects:  62%|██████▏   | 282/456 [07:41<04:33,  1.57s/it]predicting train subjects:  62%|██████▏   | 283/456 [07:42<04:06,  1.42s/it]predicting train subjects:  62%|██████▏   | 284/456 [07:43<03:48,  1.33s/it]predicting train subjects:  62%|██████▎   | 285/456 [07:44<03:32,  1.24s/it]predicting train subjects:  63%|██████▎   | 286/456 [07:45<03:22,  1.19s/it]predicting train subjects:  63%|██████▎   | 287/456 [07:46<03:17,  1.17s/it]predicting train subjects:  63%|██████▎   | 288/456 [07:47<03:08,  1.12s/it]predicting train subjects:  63%|██████▎   | 289/456 [07:48<03:08,  1.13s/it]predicting train subjects:  64%|██████▎   | 290/456 [07:49<03:07,  1.13s/it]predicting train subjects:  64%|██████▍   | 291/456 [07:50<03:04,  1.12s/it]predicting train subjects:  64%|██████▍   | 292/456 [07:51<02:59,  1.10s/it]predicting train subjects:  64%|██████▍   | 293/456 [07:52<02:53,  1.07s/it]predicting train subjects:  64%|██████▍   | 294/456 [07:53<02:55,  1.08s/it]predicting train subjects:  65%|██████▍   | 295/456 [07:54<02:50,  1.06s/it]predicting train subjects:  65%|██████▍   | 296/456 [07:56<02:52,  1.08s/it]predicting train subjects:  65%|██████▌   | 297/456 [07:57<02:45,  1.04s/it]predicting train subjects:  65%|██████▌   | 298/456 [07:58<02:44,  1.04s/it]predicting train subjects:  66%|██████▌   | 299/456 [07:59<02:45,  1.05s/it]predicting train subjects:  66%|██████▌   | 300/456 [08:00<02:43,  1.05s/it]predicting train subjects:  66%|██████▌   | 301/456 [08:02<03:22,  1.31s/it]predicting train subjects:  66%|██████▌   | 302/456 [08:03<03:42,  1.45s/it]predicting train subjects:  66%|██████▋   | 303/456 [08:05<03:55,  1.54s/it]predicting train subjects:  67%|██████▋   | 304/456 [08:07<04:05,  1.62s/it]predicting train subjects:  67%|██████▋   | 305/456 [08:09<04:10,  1.66s/it]predicting train subjects:  67%|██████▋   | 306/456 [08:10<04:13,  1.69s/it]predicting train subjects:  67%|██████▋   | 307/456 [08:12<04:24,  1.78s/it]predicting train subjects:  68%|██████▊   | 308/456 [08:14<04:31,  1.83s/it]predicting train subjects:  68%|██████▊   | 309/456 [08:16<04:34,  1.87s/it]predicting train subjects:  68%|██████▊   | 310/456 [08:18<04:38,  1.91s/it]predicting train subjects:  68%|██████▊   | 311/456 [08:20<04:36,  1.90s/it]predicting train subjects:  68%|██████▊   | 312/456 [08:22<04:32,  1.89s/it]predicting train subjects:  69%|██████▊   | 313/456 [08:24<04:27,  1.87s/it]predicting train subjects:  69%|██████▉   | 314/456 [08:26<04:17,  1.81s/it]predicting train subjects:  69%|██████▉   | 315/456 [08:27<04:10,  1.78s/it]predicting train subjects:  69%|██████▉   | 316/456 [08:29<04:09,  1.78s/it]predicting train subjects:  70%|██████▉   | 317/456 [08:31<04:08,  1.79s/it]predicting train subjects:  70%|██████▉   | 318/456 [08:33<04:11,  1.82s/it]predicting train subjects:  70%|██████▉   | 319/456 [08:34<04:01,  1.77s/it]predicting train subjects:  70%|███████   | 320/456 [08:36<03:58,  1.75s/it]predicting train subjects:  70%|███████   | 321/456 [08:38<03:50,  1.71s/it]predicting train subjects:  71%|███████   | 322/456 [08:39<03:47,  1.70s/it]predicting train subjects:  71%|███████   | 323/456 [08:41<03:43,  1.68s/it]predicting train subjects:  71%|███████   | 324/456 [08:43<03:42,  1.68s/it]predicting train subjects:  71%|███████▏  | 325/456 [08:44<03:27,  1.59s/it]predicting train subjects:  71%|███████▏  | 326/456 [08:45<03:14,  1.50s/it]predicting train subjects:  72%|███████▏  | 327/456 [08:47<03:04,  1.43s/it]predicting train subjects:  72%|███████▏  | 328/456 [08:48<02:58,  1.39s/it]predicting train subjects:  72%|███████▏  | 329/456 [08:49<02:52,  1.36s/it]predicting train subjects:  72%|███████▏  | 330/456 [08:51<02:49,  1.34s/it]predicting train subjects:  73%|███████▎  | 331/456 [08:52<03:00,  1.44s/it]predicting train subjects:  73%|███████▎  | 332/456 [08:54<03:05,  1.50s/it]predicting train subjects:  73%|███████▎  | 333/456 [08:56<03:08,  1.53s/it]predicting train subjects:  73%|███████▎  | 334/456 [08:57<03:14,  1.59s/it]predicting train subjects:  73%|███████▎  | 335/456 [08:59<03:12,  1.59s/it]predicting train subjects:  74%|███████▎  | 336/456 [09:00<03:09,  1.58s/it]predicting train subjects:  74%|███████▍  | 337/456 [09:02<03:06,  1.57s/it]predicting train subjects:  74%|███████▍  | 338/456 [09:03<03:03,  1.56s/it]predicting train subjects:  74%|███████▍  | 339/456 [09:05<03:03,  1.56s/it]predicting train subjects:  75%|███████▍  | 340/456 [09:07<02:58,  1.54s/it]predicting train subjects:  75%|███████▍  | 341/456 [09:08<02:55,  1.52s/it]predicting train subjects:  75%|███████▌  | 342/456 [09:10<02:53,  1.52s/it]predicting train subjects:  75%|███████▌  | 343/456 [09:11<02:51,  1.52s/it]predicting train subjects:  75%|███████▌  | 344/456 [09:13<02:53,  1.55s/it]predicting train subjects:  76%|███████▌  | 345/456 [09:14<02:52,  1.56s/it]predicting train subjects:  76%|███████▌  | 346/456 [09:16<02:49,  1.54s/it]predicting train subjects:  76%|███████▌  | 347/456 [09:17<02:47,  1.54s/it]predicting train subjects:  76%|███████▋  | 348/456 [09:19<02:47,  1.55s/it]predicting train subjects:  77%|███████▋  | 349/456 [09:20<02:47,  1.57s/it]predicting train subjects:  77%|███████▋  | 350/456 [09:22<02:47,  1.58s/it]predicting train subjects:  77%|███████▋  | 351/456 [09:24<02:46,  1.59s/it]predicting train subjects:  77%|███████▋  | 352/456 [09:25<02:45,  1.59s/it]predicting train subjects:  77%|███████▋  | 353/456 [09:27<02:41,  1.57s/it]predicting train subjects:  78%|███████▊  | 354/456 [09:28<02:38,  1.55s/it]predicting train subjects:  78%|███████▊  | 355/456 [09:30<02:39,  1.58s/it]predicting train subjects:  78%|███████▊  | 356/456 [09:32<02:45,  1.66s/it]predicting train subjects:  78%|███████▊  | 357/456 [09:33<02:43,  1.65s/it]predicting train subjects:  79%|███████▊  | 358/456 [09:35<02:45,  1.69s/it]predicting train subjects:  79%|███████▊  | 359/456 [09:37<02:47,  1.73s/it]predicting train subjects:  79%|███████▉  | 360/456 [09:39<02:52,  1.80s/it]predicting train subjects:  79%|███████▉  | 361/456 [09:41<02:55,  1.85s/it]predicting train subjects:  79%|███████▉  | 362/456 [09:43<02:55,  1.87s/it]predicting train subjects:  80%|███████▉  | 363/456 [09:44<02:47,  1.80s/it]predicting train subjects:  80%|███████▉  | 364/456 [09:46<02:40,  1.74s/it]predicting train subjects:  80%|████████  | 365/456 [09:48<02:37,  1.73s/it]predicting train subjects:  80%|████████  | 366/456 [09:49<02:34,  1.72s/it]predicting train subjects:  80%|████████  | 367/456 [09:51<02:23,  1.62s/it]predicting train subjects:  81%|████████  | 368/456 [09:52<02:14,  1.52s/it]predicting train subjects:  81%|████████  | 369/456 [09:54<02:07,  1.46s/it]predicting train subjects:  81%|████████  | 370/456 [09:55<02:01,  1.41s/it]predicting train subjects:  81%|████████▏ | 371/456 [09:56<01:58,  1.39s/it]predicting train subjects:  82%|████████▏ | 372/456 [09:57<01:55,  1.38s/it]predicting train subjects:  82%|████████▏ | 373/456 [09:59<02:08,  1.55s/it]predicting train subjects:  82%|████████▏ | 374/456 [10:01<02:18,  1.68s/it]predicting train subjects:  82%|████████▏ | 375/456 [10:03<02:23,  1.77s/it]predicting train subjects:  82%|████████▏ | 376/456 [10:05<02:27,  1.85s/it]predicting train subjects:  83%|████████▎ | 377/456 [10:07<02:29,  1.90s/it]predicting train subjects:  83%|████████▎ | 378/456 [10:10<02:33,  1.97s/it]predicting train subjects:  83%|████████▎ | 379/456 [10:11<02:16,  1.78s/it]predicting train subjects:  83%|████████▎ | 380/456 [10:12<02:04,  1.64s/it]predicting train subjects:  84%|████████▎ | 381/456 [10:13<01:54,  1.52s/it]predicting train subjects:  84%|████████▍ | 382/456 [10:15<01:46,  1.44s/it]predicting train subjects:  84%|████████▍ | 383/456 [10:16<01:43,  1.41s/it]predicting train subjects:  84%|████████▍ | 384/456 [10:17<01:38,  1.36s/it]predicting train subjects:  84%|████████▍ | 385/456 [10:19<01:38,  1.39s/it]predicting train subjects:  85%|████████▍ | 386/456 [10:20<01:35,  1.37s/it]predicting train subjects:  85%|████████▍ | 387/456 [10:21<01:33,  1.36s/it]predicting train subjects:  85%|████████▌ | 388/456 [10:23<01:31,  1.34s/it]predicting train subjects:  85%|████████▌ | 389/456 [10:24<01:31,  1.36s/it]predicting train subjects:  86%|████████▌ | 390/456 [10:26<01:33,  1.42s/it]predicting train subjects:  86%|████████▌ | 391/456 [10:27<01:36,  1.48s/it]predicting train subjects:  86%|████████▌ | 392/456 [10:29<01:37,  1.52s/it]predicting train subjects:  86%|████████▌ | 393/456 [10:30<01:35,  1.52s/it]predicting train subjects:  86%|████████▋ | 394/456 [10:32<01:33,  1.51s/it]predicting train subjects:  87%|████████▋ | 395/456 [10:34<01:33,  1.53s/it]predicting train subjects:  87%|████████▋ | 396/456 [10:35<01:31,  1.53s/it]predicting train subjects:  87%|████████▋ | 397/456 [10:36<01:28,  1.50s/it]predicting train subjects:  87%|████████▋ | 398/456 [10:38<01:26,  1.48s/it]predicting train subjects:  88%|████████▊ | 399/456 [10:39<01:23,  1.46s/it]predicting train subjects:  88%|████████▊ | 400/456 [10:41<01:22,  1.48s/it]predicting train subjects:  88%|████████▊ | 401/456 [10:42<01:20,  1.47s/it]predicting train subjects:  88%|████████▊ | 402/456 [10:44<01:18,  1.46s/it]predicting train subjects:  88%|████████▊ | 403/456 [10:45<01:09,  1.32s/it]predicting train subjects:  89%|████████▊ | 404/456 [10:46<01:03,  1.22s/it]predicting train subjects:  89%|████████▉ | 405/456 [10:47<00:59,  1.17s/it]predicting train subjects:  89%|████████▉ | 406/456 [10:48<00:56,  1.13s/it]predicting train subjects:  89%|████████▉ | 407/456 [10:49<00:53,  1.09s/it]predicting train subjects:  89%|████████▉ | 408/456 [10:50<00:50,  1.05s/it]predicting train subjects:  90%|████████▉ | 409/456 [10:51<00:49,  1.05s/it]predicting train subjects:  90%|████████▉ | 410/456 [10:52<00:49,  1.07s/it]predicting train subjects:  90%|█████████ | 411/456 [10:53<00:49,  1.09s/it]predicting train subjects:  90%|█████████ | 412/456 [10:54<00:47,  1.08s/it]predicting train subjects:  91%|█████████ | 413/456 [10:55<00:46,  1.08s/it]predicting train subjects:  91%|█████████ | 414/456 [10:56<00:45,  1.08s/it]predicting train subjects:  91%|█████████ | 415/456 [10:57<00:43,  1.05s/it]predicting train subjects:  91%|█████████ | 416/456 [10:58<00:40,  1.02s/it]predicting train subjects:  91%|█████████▏| 417/456 [10:59<00:39,  1.00s/it]predicting train subjects:  92%|█████████▏| 418/456 [11:00<00:38,  1.00s/it]predicting train subjects:  92%|█████████▏| 419/456 [11:01<00:36,  1.02it/s]predicting train subjects:  92%|█████████▏| 420/456 [11:02<00:35,  1.02it/s]predicting train subjects:  92%|█████████▏| 421/456 [11:04<00:42,  1.20s/it]predicting train subjects:  93%|█████████▎| 422/456 [11:05<00:45,  1.34s/it]predicting train subjects:  93%|█████████▎| 423/456 [11:07<00:48,  1.47s/it]predicting train subjects:  93%|█████████▎| 424/456 [11:09<00:49,  1.55s/it]predicting train subjects:  93%|█████████▎| 425/456 [11:11<00:50,  1.62s/it]predicting train subjects:  93%|█████████▎| 426/456 [11:13<00:49,  1.66s/it]predicting train subjects:  94%|█████████▎| 427/456 [11:14<00:50,  1.75s/it]predicting train subjects:  94%|█████████▍| 428/456 [11:16<00:50,  1.80s/it]predicting train subjects:  94%|█████████▍| 429/456 [11:18<00:50,  1.89s/it]predicting train subjects:  94%|█████████▍| 430/456 [11:20<00:49,  1.89s/it]predicting train subjects:  95%|█████████▍| 431/456 [11:22<00:47,  1.92s/it]predicting train subjects:  95%|█████████▍| 432/456 [11:24<00:45,  1.91s/it]predicting train subjects:  95%|█████████▍| 433/456 [11:26<00:44,  1.92s/it]predicting train subjects:  95%|█████████▌| 434/456 [11:28<00:41,  1.90s/it]predicting train subjects:  95%|█████████▌| 435/456 [11:30<00:38,  1.84s/it]predicting train subjects:  96%|█████████▌| 436/456 [11:32<00:37,  1.86s/it]predicting train subjects:  96%|█████████▌| 437/456 [11:34<00:35,  1.87s/it]predicting train subjects:  96%|█████████▌| 438/456 [11:35<00:33,  1.87s/it]predicting train subjects:  96%|█████████▋| 439/456 [11:37<00:31,  1.83s/it]predicting train subjects:  96%|█████████▋| 440/456 [11:39<00:28,  1.80s/it]predicting train subjects:  97%|█████████▋| 441/456 [11:40<00:26,  1.74s/it]predicting train subjects:  97%|█████████▋| 442/456 [11:42<00:24,  1.75s/it]predicting train subjects:  97%|█████████▋| 443/456 [11:44<00:22,  1.74s/it]predicting train subjects:  97%|█████████▋| 444/456 [11:46<00:20,  1.70s/it]predicting train subjects:  98%|█████████▊| 445/456 [11:47<00:17,  1.58s/it]predicting train subjects:  98%|█████████▊| 446/456 [11:48<00:14,  1.49s/it]predicting train subjects:  98%|█████████▊| 447/456 [11:49<00:12,  1.43s/it]predicting train subjects:  98%|█████████▊| 448/456 [11:51<00:11,  1.39s/it]predicting train subjects:  98%|█████████▊| 449/456 [11:52<00:09,  1.35s/it]predicting train subjects:  99%|█████████▊| 450/456 [11:53<00:07,  1.31s/it]predicting train subjects:  99%|█████████▉| 451/456 [11:55<00:06,  1.36s/it]predicting train subjects:  99%|█████████▉| 452/456 [11:56<00:05,  1.41s/it]predicting train subjects:  99%|█████████▉| 453/456 [11:58<00:04,  1.46s/it]predicting train subjects: 100%|█████████▉| 454/456 [11:59<00:02,  1.49s/it]predicting train subjects: 100%|█████████▉| 455/456 [12:01<00:01,  1.54s/it]predicting train subjects: 100%|██████████| 456/456 [12:03<00:00,  1.57s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a’: File exists

Loading train:   0%|          | 0/456 [00:00<?, ?it/s]Loading train:   0%|          | 1/456 [00:01<09:55,  1.31s/it]Loading train:   0%|          | 2/456 [00:02<09:45,  1.29s/it]Loading train:   1%|          | 3/456 [00:03<09:02,  1.20s/it]Loading train:   1%|          | 4/456 [00:04<08:28,  1.13s/it]Loading train:   1%|          | 5/456 [00:05<08:35,  1.14s/it]Loading train:   1%|▏         | 6/456 [00:06<08:27,  1.13s/it]Loading train:   2%|▏         | 7/456 [00:07<07:32,  1.01s/it]Loading train:   2%|▏         | 8/456 [00:08<06:54,  1.08it/s]Loading train:   2%|▏         | 9/456 [00:09<06:45,  1.10it/s]Loading train:   2%|▏         | 10/456 [00:10<07:04,  1.05it/s]Loading train:   2%|▏         | 11/456 [00:11<07:16,  1.02it/s]Loading train:   3%|▎         | 12/456 [00:11<06:50,  1.08it/s]Loading train:   3%|▎         | 13/456 [00:12<06:40,  1.11it/s]Loading train:   3%|▎         | 14/456 [00:13<06:29,  1.14it/s]Loading train:   3%|▎         | 15/456 [00:14<06:07,  1.20it/s]Loading train:   4%|▎         | 16/456 [00:15<06:40,  1.10it/s]Loading train:   4%|▎         | 17/456 [00:16<07:25,  1.01s/it]Loading train:   4%|▍         | 18/456 [00:17<07:23,  1.01s/it]Loading train:   4%|▍         | 19/456 [00:18<07:15,  1.00it/s]Loading train:   4%|▍         | 20/456 [00:19<07:04,  1.03it/s]Loading train:   5%|▍         | 21/456 [00:20<06:43,  1.08it/s]Loading train:   5%|▍         | 22/456 [00:21<06:40,  1.08it/s]Loading train:   5%|▌         | 23/456 [00:22<06:35,  1.09it/s]Loading train:   5%|▌         | 24/456 [00:23<06:17,  1.14it/s]Loading train:   5%|▌         | 25/456 [00:23<06:16,  1.14it/s]Loading train:   6%|▌         | 26/456 [00:24<05:54,  1.21it/s]Loading train:   6%|▌         | 27/456 [00:25<05:46,  1.24it/s]Loading train:   6%|▌         | 28/456 [00:26<05:38,  1.26it/s]Loading train:   6%|▋         | 29/456 [00:26<05:20,  1.33it/s]Loading train:   7%|▋         | 30/456 [00:27<05:18,  1.34it/s]Loading train:   7%|▋         | 31/456 [00:28<05:25,  1.31it/s]Loading train:   7%|▋         | 32/456 [00:29<06:28,  1.09it/s]Loading train:   7%|▋         | 33/456 [00:30<06:14,  1.13it/s]Loading train:   7%|▋         | 34/456 [00:31<06:30,  1.08it/s]Loading train:   8%|▊         | 35/456 [00:32<07:03,  1.01s/it]Loading train:   8%|▊         | 36/456 [00:34<07:47,  1.11s/it]Loading train:   8%|▊         | 37/456 [00:35<07:55,  1.13s/it]Loading train:   8%|▊         | 38/456 [00:36<07:57,  1.14s/it]Loading train:   9%|▊         | 39/456 [00:37<08:16,  1.19s/it]Loading train:   9%|▉         | 40/456 [00:39<09:06,  1.31s/it]Loading train:   9%|▉         | 41/456 [00:40<08:42,  1.26s/it]Loading train:   9%|▉         | 42/456 [00:41<08:02,  1.17s/it]Loading train:   9%|▉         | 43/456 [00:42<07:53,  1.15s/it]Loading train:  10%|▉         | 44/456 [00:43<07:28,  1.09s/it]Loading train:  10%|▉         | 45/456 [00:44<07:07,  1.04s/it]Loading train:  10%|█         | 46/456 [00:45<06:41,  1.02it/s]Loading train:  10%|█         | 47/456 [00:46<06:35,  1.04it/s]Loading train:  11%|█         | 48/456 [00:47<06:38,  1.03it/s]Loading train:  11%|█         | 49/456 [00:47<06:25,  1.06it/s]Loading train:  11%|█         | 50/456 [00:48<06:13,  1.09it/s]Loading train:  11%|█         | 51/456 [00:49<06:25,  1.05it/s]Loading train:  11%|█▏        | 52/456 [00:50<06:20,  1.06it/s]Loading train:  12%|█▏        | 53/456 [00:51<06:09,  1.09it/s]Loading train:  12%|█▏        | 54/456 [00:52<05:59,  1.12it/s]Loading train:  12%|█▏        | 55/456 [00:53<05:49,  1.15it/s]Loading train:  12%|█▏        | 56/456 [00:54<05:53,  1.13it/s]Loading train:  12%|█▎        | 57/456 [00:55<05:51,  1.14it/s]Loading train:  13%|█▎        | 58/456 [00:55<05:43,  1.16it/s]Loading train:  13%|█▎        | 59/456 [00:56<05:48,  1.14it/s]Loading train:  13%|█▎        | 60/456 [00:57<05:47,  1.14it/s]Loading train:  13%|█▎        | 61/456 [00:58<05:52,  1.12it/s]Loading train:  14%|█▎        | 62/456 [00:59<05:56,  1.10it/s]Loading train:  14%|█▍        | 63/456 [01:00<06:15,  1.05it/s]Loading train:  14%|█▍        | 64/456 [01:01<06:20,  1.03it/s]Loading train:  14%|█▍        | 65/456 [01:02<06:13,  1.05it/s]Loading train:  14%|█▍        | 66/456 [01:03<06:07,  1.06it/s]Loading train:  15%|█▍        | 67/456 [01:04<06:03,  1.07it/s]Loading train:  15%|█▍        | 68/456 [01:05<06:21,  1.02it/s]Loading train:  15%|█▌        | 69/456 [01:06<06:13,  1.04it/s]Loading train:  15%|█▌        | 70/456 [01:07<06:03,  1.06it/s]Loading train:  16%|█▌        | 71/456 [01:08<06:03,  1.06it/s]Loading train:  16%|█▌        | 72/456 [01:09<05:55,  1.08it/s]Loading train:  16%|█▌        | 73/456 [01:10<05:57,  1.07it/s]Loading train:  16%|█▌        | 74/456 [01:10<05:48,  1.10it/s]Loading train:  16%|█▋        | 75/456 [01:11<05:52,  1.08it/s]Loading train:  17%|█▋        | 76/456 [01:12<05:55,  1.07it/s]Loading train:  17%|█▋        | 77/456 [01:13<06:00,  1.05it/s]Loading train:  17%|█▋        | 78/456 [01:14<06:07,  1.03it/s]Loading train:  17%|█▋        | 79/456 [01:15<05:47,  1.09it/s]Loading train:  18%|█▊        | 80/456 [01:16<05:13,  1.20it/s]Loading train:  18%|█▊        | 81/456 [01:16<04:49,  1.29it/s]Loading train:  18%|█▊        | 82/456 [01:17<04:39,  1.34it/s]Loading train:  18%|█▊        | 83/456 [01:18<04:28,  1.39it/s]Loading train:  18%|█▊        | 84/456 [01:18<04:25,  1.40it/s]Loading train:  19%|█▊        | 85/456 [01:19<04:15,  1.45it/s]Loading train:  19%|█▉        | 86/456 [01:20<04:12,  1.47it/s]Loading train:  19%|█▉        | 87/456 [01:20<04:11,  1.46it/s]Loading train:  19%|█▉        | 88/456 [01:21<04:09,  1.48it/s]Loading train:  20%|█▉        | 89/456 [01:22<04:05,  1.49it/s]Loading train:  20%|█▉        | 90/456 [01:22<04:13,  1.44it/s]Loading train:  20%|█▉        | 91/456 [01:23<04:06,  1.48it/s]Loading train:  20%|██        | 92/456 [01:24<04:12,  1.44it/s]Loading train:  20%|██        | 93/456 [01:24<04:00,  1.51it/s]Loading train:  21%|██        | 94/456 [01:25<03:51,  1.56it/s]Loading train:  21%|██        | 95/456 [01:26<03:48,  1.58it/s]Loading train:  21%|██        | 96/456 [01:26<03:49,  1.57it/s]Loading train:  21%|██▏       | 97/456 [01:27<04:30,  1.33it/s]Loading train:  21%|██▏       | 98/456 [01:28<04:47,  1.25it/s]Loading train:  22%|██▏       | 99/456 [01:29<05:05,  1.17it/s]Loading train:  22%|██▏       | 100/456 [01:30<05:05,  1.17it/s]Loading train:  22%|██▏       | 101/456 [01:31<05:04,  1.17it/s]Loading train:  22%|██▏       | 102/456 [01:32<05:10,  1.14it/s]Loading train:  23%|██▎       | 103/456 [01:33<05:08,  1.14it/s]Loading train:  23%|██▎       | 104/456 [01:34<05:14,  1.12it/s]Loading train:  23%|██▎       | 105/456 [01:34<05:03,  1.16it/s]Loading train:  23%|██▎       | 106/456 [01:35<04:53,  1.19it/s]Loading train:  23%|██▎       | 107/456 [01:36<04:53,  1.19it/s]Loading train:  24%|██▎       | 108/456 [01:37<04:53,  1.19it/s]Loading train:  24%|██▍       | 109/456 [01:38<05:03,  1.14it/s]Loading train:  24%|██▍       | 110/456 [01:39<05:02,  1.14it/s]Loading train:  24%|██▍       | 111/456 [01:40<04:55,  1.17it/s]Loading train:  25%|██▍       | 112/456 [01:40<04:43,  1.21it/s]Loading train:  25%|██▍       | 113/456 [01:41<04:43,  1.21it/s]Loading train:  25%|██▌       | 114/456 [01:42<04:39,  1.22it/s]Loading train:  25%|██▌       | 115/456 [01:43<05:03,  1.13it/s]Loading train:  25%|██▌       | 116/456 [01:44<05:06,  1.11it/s]Loading train:  26%|██▌       | 117/456 [01:45<05:00,  1.13it/s]Loading train:  26%|██▌       | 118/456 [01:46<04:59,  1.13it/s]Loading train:  26%|██▌       | 119/456 [01:47<04:57,  1.13it/s]Loading train:  26%|██▋       | 120/456 [01:47<04:53,  1.14it/s]Loading train:  27%|██▋       | 121/456 [01:48<04:59,  1.12it/s]Loading train:  27%|██▋       | 122/456 [01:49<05:03,  1.10it/s]Loading train:  27%|██▋       | 123/456 [01:50<05:04,  1.09it/s]Loading train:  27%|██▋       | 124/456 [01:51<05:07,  1.08it/s]Loading train:  27%|██▋       | 125/456 [01:52<04:57,  1.11it/s]Loading train:  28%|██▊       | 126/456 [01:53<04:54,  1.12it/s]Loading train:  28%|██▊       | 127/456 [01:54<04:54,  1.12it/s]Loading train:  28%|██▊       | 128/456 [01:55<04:44,  1.15it/s]Loading train:  28%|██▊       | 129/456 [01:55<04:38,  1.17it/s]Loading train:  29%|██▊       | 130/456 [01:56<04:24,  1.23it/s]Loading train:  29%|██▊       | 131/456 [01:57<04:14,  1.28it/s]Loading train:  29%|██▉       | 132/456 [01:58<04:06,  1.31it/s]Loading train:  29%|██▉       | 133/456 [01:59<04:40,  1.15it/s]Loading train:  29%|██▉       | 134/456 [02:00<05:09,  1.04it/s]Loading train:  30%|██▉       | 135/456 [02:01<05:21,  1.00s/it]Loading train:  30%|██▉       | 136/456 [02:02<05:20,  1.00s/it]Loading train:  30%|███       | 137/456 [02:03<05:19,  1.00s/it]Loading train:  30%|███       | 138/456 [02:04<05:14,  1.01it/s]Loading train:  30%|███       | 139/456 [02:05<04:43,  1.12it/s]Loading train:  31%|███       | 140/456 [02:05<04:29,  1.17it/s]Loading train:  31%|███       | 141/456 [02:06<04:16,  1.23it/s]Loading train:  31%|███       | 142/456 [02:07<04:05,  1.28it/s]Loading train:  31%|███▏      | 143/456 [02:07<03:54,  1.33it/s]Loading train:  32%|███▏      | 144/456 [02:08<03:48,  1.37it/s]Loading train:  32%|███▏      | 145/456 [02:09<03:49,  1.36it/s]Loading train:  32%|███▏      | 146/456 [02:10<03:48,  1.36it/s]Loading train:  32%|███▏      | 147/456 [02:10<03:59,  1.29it/s]Loading train:  32%|███▏      | 148/456 [02:11<03:55,  1.31it/s]Loading train:  33%|███▎      | 149/456 [02:12<03:54,  1.31it/s]Loading train:  33%|███▎      | 150/456 [02:13<03:57,  1.29it/s]Loading train:  33%|███▎      | 151/456 [02:14<04:02,  1.26it/s]Loading train:  33%|███▎      | 152/456 [02:14<03:56,  1.28it/s]Loading train:  34%|███▎      | 153/456 [02:15<03:54,  1.29it/s]Loading train:  34%|███▍      | 154/456 [02:16<03:55,  1.28it/s]Loading train:  34%|███▍      | 155/456 [02:17<03:58,  1.26it/s]Loading train:  34%|███▍      | 156/456 [02:18<03:53,  1.28it/s]Loading train:  34%|███▍      | 157/456 [02:18<03:44,  1.33it/s]Loading train:  35%|███▍      | 158/456 [02:19<03:34,  1.39it/s]Loading train:  35%|███▍      | 159/456 [02:20<03:30,  1.41it/s]Loading train:  35%|███▌      | 160/456 [02:20<03:23,  1.46it/s]Loading train:  35%|███▌      | 161/456 [02:21<03:23,  1.45it/s]Loading train:  36%|███▌      | 162/456 [02:22<03:29,  1.41it/s]Loading train:  36%|███▌      | 163/456 [02:22<03:27,  1.41it/s]Loading train:  36%|███▌      | 164/456 [02:23<03:16,  1.48it/s]Loading train:  36%|███▌      | 165/456 [02:24<03:15,  1.49it/s]Loading train:  36%|███▋      | 166/456 [02:24<03:13,  1.50it/s]Loading train:  37%|███▋      | 167/456 [02:25<03:10,  1.52it/s]Loading train:  37%|███▋      | 168/456 [02:26<03:08,  1.53it/s]Loading train:  37%|███▋      | 169/456 [02:26<03:03,  1.56it/s]Loading train:  37%|███▋      | 170/456 [02:27<02:57,  1.61it/s]Loading train:  38%|███▊      | 171/456 [02:27<02:51,  1.66it/s]Loading train:  38%|███▊      | 172/456 [02:28<02:50,  1.67it/s]Loading train:  38%|███▊      | 173/456 [02:29<02:57,  1.60it/s]Loading train:  38%|███▊      | 174/456 [02:29<03:02,  1.55it/s]Loading train:  38%|███▊      | 175/456 [02:30<03:01,  1.55it/s]Loading train:  39%|███▊      | 176/456 [02:31<03:17,  1.42it/s]Loading train:  39%|███▉      | 177/456 [02:31<03:12,  1.45it/s]Loading train:  39%|███▉      | 178/456 [02:32<03:32,  1.31it/s]Loading train:  39%|███▉      | 179/456 [02:33<03:24,  1.35it/s]Loading train:  39%|███▉      | 180/456 [02:34<03:29,  1.32it/s]Loading train:  40%|███▉      | 181/456 [02:35<03:48,  1.20it/s]Loading train:  40%|███▉      | 182/456 [02:36<03:53,  1.18it/s]Loading train:  40%|████      | 183/456 [02:37<04:09,  1.10it/s]Loading train:  40%|████      | 184/456 [02:38<04:14,  1.07it/s]Loading train:  41%|████      | 185/456 [02:39<04:18,  1.05it/s]Loading train:  41%|████      | 186/456 [02:40<04:14,  1.06it/s]Loading train:  41%|████      | 187/456 [02:41<04:18,  1.04it/s]Loading train:  41%|████      | 188/456 [02:42<04:19,  1.03it/s]Loading train:  41%|████▏     | 189/456 [02:43<04:19,  1.03it/s]Loading train:  42%|████▏     | 190/456 [02:44<04:18,  1.03it/s]Loading train:  42%|████▏     | 191/456 [02:45<04:24,  1.00it/s]Loading train:  42%|████▏     | 192/456 [02:46<04:24,  1.00s/it]Loading train:  42%|████▏     | 193/456 [02:47<04:19,  1.01it/s]Loading train:  43%|████▎     | 194/456 [02:48<04:15,  1.02it/s]Loading train:  43%|████▎     | 195/456 [02:48<04:06,  1.06it/s]Loading train:  43%|████▎     | 196/456 [02:49<04:00,  1.08it/s]Loading train:  43%|████▎     | 197/456 [02:50<03:54,  1.10it/s]Loading train:  43%|████▎     | 198/456 [02:51<04:01,  1.07it/s]Loading train:  44%|████▎     | 199/456 [02:52<04:02,  1.06it/s]Loading train:  44%|████▍     | 200/456 [02:53<03:44,  1.14it/s]Loading train:  44%|████▍     | 201/456 [02:54<03:36,  1.18it/s]Loading train:  44%|████▍     | 202/456 [02:54<03:25,  1.24it/s]Loading train:  45%|████▍     | 203/456 [02:55<03:18,  1.27it/s]Loading train:  45%|████▍     | 204/456 [02:56<03:15,  1.29it/s]Loading train:  45%|████▍     | 205/456 [02:57<03:10,  1.32it/s]Loading train:  45%|████▌     | 206/456 [02:57<03:03,  1.36it/s]Loading train:  45%|████▌     | 207/456 [02:58<03:06,  1.34it/s]Loading train:  46%|████▌     | 208/456 [02:59<03:03,  1.35it/s]Loading train:  46%|████▌     | 209/456 [02:59<02:59,  1.38it/s]Loading train:  46%|████▌     | 210/456 [03:00<02:56,  1.39it/s]Loading train:  46%|████▋     | 211/456 [03:01<03:06,  1.31it/s]Loading train:  46%|████▋     | 212/456 [03:02<03:05,  1.31it/s]Loading train:  47%|████▋     | 213/456 [03:03<03:14,  1.25it/s]Loading train:  47%|████▋     | 214/456 [03:03<03:12,  1.26it/s]Loading train:  47%|████▋     | 215/456 [03:04<03:12,  1.25it/s]Loading train:  47%|████▋     | 216/456 [03:05<03:14,  1.24it/s]Loading train:  48%|████▊     | 217/456 [03:06<03:22,  1.18it/s]Loading train:  48%|████▊     | 218/456 [03:07<03:21,  1.18it/s]Loading train:  48%|████▊     | 219/456 [03:08<03:22,  1.17it/s]Loading train:  48%|████▊     | 220/456 [03:09<03:19,  1.18it/s]Loading train:  48%|████▊     | 221/456 [03:10<03:31,  1.11it/s]Loading train:  49%|████▊     | 222/456 [03:11<03:37,  1.08it/s]Loading train:  49%|████▉     | 223/456 [03:12<03:48,  1.02it/s]Loading train:  49%|████▉     | 224/456 [03:13<03:37,  1.07it/s]Loading train:  49%|████▉     | 225/456 [03:13<03:28,  1.11it/s]Loading train:  50%|████▉     | 226/456 [03:14<03:20,  1.15it/s]Loading train:  50%|████▉     | 227/456 [03:15<03:13,  1.18it/s]Loading train:  50%|█████     | 228/456 [03:16<03:14,  1.17it/s]Loading train:  50%|█████     | 229/456 [03:17<03:26,  1.10it/s]Loading train:  50%|█████     | 230/456 [03:18<03:21,  1.12it/s]Loading train:  51%|█████     | 231/456 [03:19<03:15,  1.15it/s]Loading train:  51%|█████     | 232/456 [03:19<03:14,  1.15it/s]Loading train:  51%|█████     | 233/456 [03:20<03:08,  1.18it/s]Loading train:  51%|█████▏    | 234/456 [03:21<03:04,  1.21it/s]Loading train:  52%|█████▏    | 235/456 [03:22<03:10,  1.16it/s]Loading train:  52%|█████▏    | 236/456 [03:23<03:17,  1.11it/s]Loading train:  52%|█████▏    | 237/456 [03:24<03:09,  1.15it/s]Loading train:  52%|█████▏    | 238/456 [03:25<03:11,  1.14it/s]Loading train:  52%|█████▏    | 239/456 [03:25<03:06,  1.16it/s]Loading train:  53%|█████▎    | 240/456 [03:26<03:04,  1.17it/s]Loading train:  53%|█████▎    | 241/456 [03:27<03:11,  1.12it/s]Loading train:  53%|█████▎    | 242/456 [03:29<03:55,  1.10s/it]Loading train:  53%|█████▎    | 243/456 [03:30<04:03,  1.14s/it]Loading train:  54%|█████▎    | 244/456 [03:31<03:58,  1.12s/it]Loading train:  54%|█████▎    | 245/456 [03:32<03:52,  1.10s/it]Loading train:  54%|█████▍    | 246/456 [03:33<03:53,  1.11s/it]Loading train:  54%|█████▍    | 247/456 [03:34<03:38,  1.05s/it]Loading train:  54%|█████▍    | 248/456 [03:35<03:24,  1.02it/s]Loading train:  55%|█████▍    | 249/456 [03:36<03:07,  1.10it/s]Loading train:  55%|█████▍    | 250/456 [03:37<03:17,  1.04it/s]Loading train:  55%|█████▌    | 251/456 [03:38<03:12,  1.06it/s]Loading train:  55%|█████▌    | 252/456 [03:39<03:16,  1.04it/s]Loading train:  55%|█████▌    | 253/456 [03:40<03:57,  1.17s/it]Loading train:  56%|█████▌    | 254/456 [03:42<04:10,  1.24s/it]Loading train:  56%|█████▌    | 255/456 [03:43<03:55,  1.17s/it]Loading train:  56%|█████▌    | 256/456 [03:44<03:41,  1.11s/it]Loading train:  56%|█████▋    | 257/456 [03:45<03:33,  1.07s/it]Loading train:  57%|█████▋    | 258/456 [03:46<03:31,  1.07s/it]Loading train:  57%|█████▋    | 259/456 [03:47<03:09,  1.04it/s]Loading train:  57%|█████▋    | 260/456 [03:47<02:51,  1.15it/s]Loading train:  57%|█████▋    | 261/456 [03:48<02:40,  1.21it/s]Loading train:  57%|█████▋    | 262/456 [03:49<02:34,  1.26it/s]Loading train:  58%|█████▊    | 263/456 [03:49<02:30,  1.28it/s]Loading train:  58%|█████▊    | 264/456 [03:50<02:22,  1.34it/s]Loading train:  58%|█████▊    | 265/456 [03:51<02:21,  1.35it/s]Loading train:  58%|█████▊    | 266/456 [03:52<02:19,  1.36it/s]Loading train:  59%|█████▊    | 267/456 [03:52<02:17,  1.37it/s]Loading train:  59%|█████▉    | 268/456 [03:53<02:25,  1.30it/s]Loading train:  59%|█████▉    | 269/456 [03:54<02:21,  1.32it/s]Loading train:  59%|█████▉    | 270/456 [03:54<02:15,  1.37it/s]Loading train:  59%|█████▉    | 271/456 [03:55<02:24,  1.28it/s]Loading train:  60%|█████▉    | 272/456 [03:56<02:26,  1.26it/s]Loading train:  60%|█████▉    | 273/456 [03:57<02:25,  1.26it/s]Loading train:  60%|██████    | 274/456 [03:58<02:22,  1.28it/s]Loading train:  60%|██████    | 275/456 [03:59<02:32,  1.19it/s]Loading train:  61%|██████    | 276/456 [04:00<02:33,  1.17it/s]Loading train:  61%|██████    | 277/456 [04:00<02:33,  1.17it/s]Loading train:  61%|██████    | 278/456 [04:01<02:24,  1.23it/s]Loading train:  61%|██████    | 279/456 [04:02<02:17,  1.28it/s]Loading train:  61%|██████▏   | 280/456 [04:03<02:14,  1.31it/s]Loading train:  62%|██████▏   | 281/456 [04:04<02:22,  1.22it/s]Loading train:  62%|██████▏   | 282/456 [04:04<02:17,  1.27it/s]Loading train:  62%|██████▏   | 283/456 [04:05<02:19,  1.24it/s]Loading train:  62%|██████▏   | 284/456 [04:06<02:14,  1.28it/s]Loading train:  62%|██████▎   | 285/456 [04:07<02:08,  1.33it/s]Loading train:  63%|██████▎   | 286/456 [04:07<02:07,  1.33it/s]Loading train:  63%|██████▎   | 287/456 [04:08<02:03,  1.37it/s]Loading train:  63%|██████▎   | 288/456 [04:09<02:04,  1.35it/s]Loading train:  63%|██████▎   | 289/456 [04:10<02:07,  1.31it/s]Loading train:  64%|██████▎   | 290/456 [04:10<02:01,  1.36it/s]Loading train:  64%|██████▍   | 291/456 [04:11<01:58,  1.39it/s]Loading train:  64%|██████▍   | 292/456 [04:12<01:53,  1.44it/s]Loading train:  64%|██████▍   | 293/456 [04:12<01:53,  1.44it/s]Loading train:  64%|██████▍   | 294/456 [04:13<01:46,  1.51it/s]Loading train:  65%|██████▍   | 295/456 [04:13<01:46,  1.52it/s]Loading train:  65%|██████▍   | 296/456 [04:14<01:45,  1.51it/s]Loading train:  65%|██████▌   | 297/456 [04:15<01:46,  1.50it/s]Loading train:  65%|██████▌   | 298/456 [04:16<01:51,  1.42it/s]Loading train:  66%|██████▌   | 299/456 [04:16<01:47,  1.46it/s]Loading train:  66%|██████▌   | 300/456 [04:17<01:49,  1.43it/s]Loading train:  66%|██████▌   | 301/456 [04:18<02:15,  1.15it/s]Loading train:  66%|██████▌   | 302/456 [04:19<02:12,  1.16it/s]Loading train:  66%|██████▋   | 303/456 [04:20<02:16,  1.12it/s]Loading train:  67%|██████▋   | 304/456 [04:21<02:16,  1.11it/s]Loading train:  67%|██████▋   | 305/456 [04:22<02:18,  1.09it/s]Loading train:  67%|██████▋   | 306/456 [04:23<02:19,  1.08it/s]Loading train:  67%|██████▋   | 307/456 [04:24<02:22,  1.05it/s]Loading train:  68%|██████▊   | 308/456 [04:25<02:31,  1.03s/it]Loading train:  68%|██████▊   | 309/456 [04:26<02:33,  1.05s/it]Loading train:  68%|██████▊   | 310/456 [04:27<02:31,  1.03s/it]Loading train:  68%|██████▊   | 311/456 [04:28<02:23,  1.01it/s]Loading train:  68%|██████▊   | 312/456 [04:29<02:22,  1.01it/s]Loading train:  69%|██████▊   | 313/456 [04:30<02:18,  1.04it/s]Loading train:  69%|██████▉   | 314/456 [04:31<02:11,  1.08it/s]Loading train:  69%|██████▉   | 315/456 [04:32<02:06,  1.12it/s]Loading train:  69%|██████▉   | 316/456 [04:33<02:05,  1.12it/s]Loading train:  70%|██████▉   | 317/456 [04:33<02:05,  1.11it/s]Loading train:  70%|██████▉   | 318/456 [04:34<02:05,  1.10it/s]Loading train:  70%|██████▉   | 319/456 [04:35<01:56,  1.17it/s]Loading train:  70%|███████   | 320/456 [04:36<01:50,  1.23it/s]Loading train:  70%|███████   | 321/456 [04:37<01:46,  1.26it/s]Loading train:  71%|███████   | 322/456 [04:37<01:44,  1.29it/s]Loading train:  71%|███████   | 323/456 [04:38<01:41,  1.31it/s]Loading train:  71%|███████   | 324/456 [04:39<01:37,  1.36it/s]Loading train:  71%|███████▏  | 325/456 [04:39<01:35,  1.38it/s]Loading train:  71%|███████▏  | 326/456 [04:40<01:30,  1.44it/s]Loading train:  72%|███████▏  | 327/456 [04:41<01:28,  1.46it/s]Loading train:  72%|███████▏  | 328/456 [04:41<01:29,  1.44it/s]Loading train:  72%|███████▏  | 329/456 [04:42<01:30,  1.41it/s]Loading train:  72%|███████▏  | 330/456 [04:43<01:28,  1.42it/s]Loading train:  73%|███████▎  | 331/456 [04:44<01:33,  1.34it/s]Loading train:  73%|███████▎  | 332/456 [04:44<01:33,  1.33it/s]Loading train:  73%|███████▎  | 333/456 [04:45<01:35,  1.29it/s]Loading train:  73%|███████▎  | 334/456 [04:46<01:40,  1.22it/s]Loading train:  73%|███████▎  | 335/456 [04:47<01:39,  1.22it/s]Loading train:  74%|███████▎  | 336/456 [04:48<01:35,  1.25it/s]Loading train:  74%|███████▍  | 337/456 [04:49<01:38,  1.21it/s]Loading train:  74%|███████▍  | 338/456 [04:50<01:38,  1.19it/s]Loading train:  74%|███████▍  | 339/456 [04:50<01:38,  1.19it/s]Loading train:  75%|███████▍  | 340/456 [04:51<01:38,  1.18it/s]Loading train:  75%|███████▍  | 341/456 [04:52<01:38,  1.17it/s]Loading train:  75%|███████▌  | 342/456 [04:53<01:38,  1.15it/s]Loading train:  75%|███████▌  | 343/456 [04:54<01:37,  1.16it/s]Loading train:  75%|███████▌  | 344/456 [04:55<01:34,  1.18it/s]Loading train:  76%|███████▌  | 345/456 [04:56<01:37,  1.14it/s]Loading train:  76%|███████▌  | 346/456 [04:56<01:34,  1.16it/s]Loading train:  76%|███████▌  | 347/456 [04:57<01:34,  1.15it/s]Loading train:  76%|███████▋  | 348/456 [04:58<01:31,  1.18it/s]Loading train:  77%|███████▋  | 349/456 [04:59<01:31,  1.18it/s]Loading train:  77%|███████▋  | 350/456 [05:00<01:29,  1.19it/s]Loading train:  77%|███████▋  | 351/456 [05:01<01:26,  1.22it/s]Loading train:  77%|███████▋  | 352/456 [05:01<01:26,  1.21it/s]Loading train:  77%|███████▋  | 353/456 [05:02<01:30,  1.14it/s]Loading train:  78%|███████▊  | 354/456 [05:03<01:27,  1.16it/s]Loading train:  78%|███████▊  | 355/456 [05:04<01:26,  1.17it/s]Loading train:  78%|███████▊  | 356/456 [05:05<01:27,  1.15it/s]Loading train:  78%|███████▊  | 357/456 [05:06<01:24,  1.17it/s]Loading train:  79%|███████▊  | 358/456 [05:07<01:25,  1.15it/s]Loading train:  79%|███████▊  | 359/456 [05:08<01:36,  1.01it/s]Loading train:  79%|███████▉  | 360/456 [05:09<01:34,  1.02it/s]Loading train:  79%|███████▉  | 361/456 [05:10<01:31,  1.04it/s]Loading train:  79%|███████▉  | 362/456 [05:11<01:26,  1.09it/s]Loading train:  80%|███████▉  | 363/456 [05:12<01:24,  1.10it/s]Loading train:  80%|███████▉  | 364/456 [05:12<01:23,  1.11it/s]Loading train:  80%|████████  | 365/456 [05:14<01:26,  1.05it/s]Loading train:  80%|████████  | 366/456 [05:15<01:26,  1.04it/s]Loading train:  80%|████████  | 367/456 [05:15<01:21,  1.10it/s]Loading train:  81%|████████  | 368/456 [05:16<01:16,  1.15it/s]Loading train:  81%|████████  | 369/456 [05:17<01:11,  1.22it/s]Loading train:  81%|████████  | 370/456 [05:18<01:09,  1.24it/s]Loading train:  81%|████████▏ | 371/456 [05:19<01:15,  1.13it/s]Loading train:  82%|████████▏ | 372/456 [05:19<01:11,  1.18it/s]Loading train:  82%|████████▏ | 373/456 [05:20<01:15,  1.10it/s]Loading train:  82%|████████▏ | 374/456 [05:22<01:20,  1.02it/s]Loading train:  82%|████████▏ | 375/456 [05:23<01:20,  1.01it/s]Loading train:  82%|████████▏ | 376/456 [05:24<01:21,  1.02s/it]Loading train:  83%|████████▎ | 377/456 [05:25<01:20,  1.02s/it]Loading train:  83%|████████▎ | 378/456 [05:26<01:20,  1.03s/it]Loading train:  83%|████████▎ | 379/456 [05:27<01:14,  1.03it/s]Loading train:  83%|████████▎ | 380/456 [05:27<01:09,  1.10it/s]Loading train:  84%|████████▎ | 381/456 [05:28<01:03,  1.17it/s]Loading train:  84%|████████▍ | 382/456 [05:29<00:59,  1.25it/s]Loading train:  84%|████████▍ | 383/456 [05:30<00:58,  1.25it/s]Loading train:  84%|████████▍ | 384/456 [05:30<00:57,  1.24it/s]Loading train:  84%|████████▍ | 385/456 [05:31<00:57,  1.24it/s]Loading train:  85%|████████▍ | 386/456 [05:32<00:55,  1.26it/s]Loading train:  85%|████████▍ | 387/456 [05:33<00:54,  1.28it/s]Loading train:  85%|████████▌ | 388/456 [05:33<00:53,  1.27it/s]Loading train:  85%|████████▌ | 389/456 [05:34<00:53,  1.25it/s]Loading train:  86%|████████▌ | 390/456 [05:35<00:53,  1.24it/s]Loading train:  86%|████████▌ | 391/456 [05:36<00:54,  1.19it/s]Loading train:  86%|████████▌ | 392/456 [05:37<00:53,  1.19it/s]Loading train:  86%|████████▌ | 393/456 [05:38<00:50,  1.24it/s]Loading train:  86%|████████▋ | 394/456 [05:39<00:51,  1.20it/s]Loading train:  87%|████████▋ | 395/456 [05:39<00:50,  1.20it/s]Loading train:  87%|████████▋ | 396/456 [05:40<00:49,  1.21it/s]Loading train:  87%|████████▋ | 397/456 [05:41<00:48,  1.23it/s]Loading train:  87%|████████▋ | 398/456 [05:42<00:47,  1.23it/s]Loading train:  88%|████████▊ | 399/456 [05:42<00:44,  1.29it/s]Loading train:  88%|████████▊ | 400/456 [05:43<00:41,  1.36it/s]Loading train:  88%|████████▊ | 401/456 [05:44<00:43,  1.27it/s]Loading train:  88%|████████▊ | 402/456 [05:45<00:40,  1.32it/s]Loading train:  88%|████████▊ | 403/456 [05:46<00:41,  1.27it/s]Loading train:  89%|████████▊ | 404/456 [05:46<00:39,  1.33it/s]Loading train:  89%|████████▉ | 405/456 [05:47<00:38,  1.33it/s]Loading train:  89%|████████▉ | 406/456 [05:48<00:37,  1.33it/s]Loading train:  89%|████████▉ | 407/456 [05:48<00:36,  1.34it/s]Loading train:  89%|████████▉ | 408/456 [05:49<00:35,  1.36it/s]Loading train:  90%|████████▉ | 409/456 [05:50<00:33,  1.40it/s]Loading train:  90%|████████▉ | 410/456 [05:50<00:31,  1.45it/s]Loading train:  90%|█████████ | 411/456 [05:51<00:29,  1.53it/s]Loading train:  90%|█████████ | 412/456 [05:52<00:30,  1.45it/s]Loading train:  91%|█████████ | 413/456 [05:52<00:29,  1.47it/s]Loading train:  91%|█████████ | 414/456 [05:53<00:27,  1.52it/s]Loading train:  91%|█████████ | 415/456 [05:54<00:28,  1.46it/s]Loading train:  91%|█████████ | 416/456 [05:55<00:27,  1.45it/s]Loading train:  91%|█████████▏| 417/456 [05:55<00:26,  1.48it/s]Loading train:  92%|█████████▏| 418/456 [05:56<00:25,  1.48it/s]Loading train:  92%|█████████▏| 419/456 [05:57<00:25,  1.48it/s]Loading train:  92%|█████████▏| 420/456 [05:57<00:23,  1.52it/s]Loading train:  92%|█████████▏| 421/456 [05:58<00:25,  1.35it/s]Loading train:  93%|█████████▎| 422/456 [05:59<00:26,  1.28it/s]Loading train:  93%|█████████▎| 423/456 [06:00<00:27,  1.22it/s]Loading train:  93%|█████████▎| 424/456 [06:01<00:26,  1.19it/s]Loading train:  93%|█████████▎| 425/456 [06:02<00:27,  1.14it/s]Loading train:  93%|█████████▎| 426/456 [06:03<00:26,  1.12it/s]Loading train:  94%|█████████▎| 427/456 [06:04<00:28,  1.03it/s]Loading train:  94%|█████████▍| 428/456 [06:05<00:27,  1.02it/s]Loading train:  94%|█████████▍| 429/456 [06:06<00:26,  1.02it/s]Loading train:  94%|█████████▍| 430/456 [06:07<00:27,  1.06s/it]Loading train:  95%|█████████▍| 431/456 [06:08<00:26,  1.06s/it]Loading train:  95%|█████████▍| 432/456 [06:09<00:24,  1.04s/it]Loading train:  95%|█████████▍| 433/456 [06:10<00:22,  1.01it/s]Loading train:  95%|█████████▌| 434/456 [06:11<00:21,  1.03it/s]Loading train:  95%|█████████▌| 435/456 [06:12<00:19,  1.07it/s]Loading train:  96%|█████████▌| 436/456 [06:13<00:18,  1.09it/s]Loading train:  96%|█████████▌| 437/456 [06:13<00:17,  1.11it/s]Loading train:  96%|█████████▌| 438/456 [06:14<00:16,  1.11it/s]Loading train:  96%|█████████▋| 439/456 [06:15<00:14,  1.16it/s]Loading train:  96%|█████████▋| 440/456 [06:16<00:13,  1.18it/s]Loading train:  97%|█████████▋| 441/456 [06:17<00:12,  1.19it/s]Loading train:  97%|█████████▋| 442/456 [06:18<00:11,  1.20it/s]Loading train:  97%|█████████▋| 443/456 [06:18<00:10,  1.22it/s]Loading train:  97%|█████████▋| 444/456 [06:19<00:10,  1.20it/s]Loading train:  98%|█████████▊| 445/456 [06:20<00:08,  1.23it/s]Loading train:  98%|█████████▊| 446/456 [06:21<00:07,  1.28it/s]Loading train:  98%|█████████▊| 447/456 [06:21<00:06,  1.30it/s]Loading train:  98%|█████████▊| 448/456 [06:22<00:06,  1.28it/s]Loading train:  98%|█████████▊| 449/456 [06:23<00:05,  1.25it/s]Loading train:  99%|█████████▊| 450/456 [06:24<00:04,  1.23it/s]Loading train:  99%|█████████▉| 451/456 [06:25<00:04,  1.13it/s]Loading train:  99%|█████████▉| 452/456 [06:26<00:03,  1.12it/s]Loading train:  99%|█████████▉| 453/456 [06:27<00:02,  1.12it/s]Loading train: 100%|█████████▉| 454/456 [06:28<00:01,  1.13it/s]Loading train: 100%|█████████▉| 455/456 [06:29<00:00,  1.10it/s]Loading train: 100%|██████████| 456/456 [06:30<00:00,  1.10it/s]
concatenating: train:   0%|          | 0/456 [00:00<?, ?it/s]concatenating: train:   3%|▎         | 13/456 [00:00<00:03, 124.11it/s]concatenating: train:   8%|▊         | 36/456 [00:00<00:02, 143.71it/s]concatenating: train:  14%|█▎        | 62/456 [00:00<00:02, 164.80it/s]concatenating: train:  19%|█▊        | 85/456 [00:00<00:02, 180.11it/s]concatenating: train:  25%|██▍       | 113/456 [00:00<00:01, 200.47it/s]concatenating: train:  30%|███       | 139/456 [00:00<00:01, 214.90it/s]concatenating: train:  36%|███▌      | 165/456 [00:00<00:01, 224.66it/s]concatenating: train:  41%|████▏     | 189/456 [00:00<00:01, 228.96it/s]concatenating: train:  47%|████▋     | 213/456 [00:00<00:01, 231.73it/s]concatenating: train:  52%|█████▏    | 238/456 [00:01<00:00, 236.28it/s]concatenating: train:  57%|█████▋    | 262/456 [00:01<00:00, 235.47it/s]concatenating: train:  63%|██████▎   | 288/456 [00:01<00:00, 240.51it/s]concatenating: train:  69%|██████▊   | 313/456 [00:01<00:00, 238.31it/s]concatenating: train:  75%|███████▍  | 341/456 [00:01<00:00, 247.58it/s]concatenating: train:  80%|████████  | 367/456 [00:01<00:00, 249.08it/s]concatenating: train:  86%|████████▌ | 393/456 [00:01<00:00, 250.93it/s]concatenating: train:  92%|█████████▏| 419/456 [00:01<00:00, 251.49it/s]concatenating: train:  98%|█████████▊| 447/456 [00:01<00:00, 257.44it/s]concatenating: train: 100%|██████████| 456/456 [00:01<00:00, 244.16it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:00<00:02,  1.04it/s]Loading test:  50%|█████     | 2/4 [00:01<00:01,  1.10it/s]Loading test:  75%|███████▌  | 3/4 [00:02<00:00,  1.10it/s]Loading test: 100%|██████████| 4/4 [00:03<00:00,  1.10it/s]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 56.48it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 56, 88, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 56, 88, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 56, 88, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 56, 88, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 56, 88, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 88, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 56, 88, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 56, 88, 31)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 28, 44, 31)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28, 44, 31)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 44, 60)   16800       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 44, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 44, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 44, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 28, 44, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 28, 44, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 44, 91)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 22, 91)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 14, 22, 91)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 14, 22, 120)  98400       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 14, 22, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 14, 22, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 14, 22, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 14, 22, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 14, 22, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 14, 22, 211)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 14, 22, 211)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 28, 44, 60)   50700       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 28, 44, 151)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 28, 44, 60)   81600       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 28, 44, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________2019-07-07 21:18:50.235276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 21:18:50.235393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 21:18:50.235410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 21:18:50.235419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 21:18:50.240465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

activation_7 (Activation)       (None, 28, 44, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 28, 44, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 28, 44, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 28, 44, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 28, 44, 211)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 28, 44, 211)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 56, 88, 30)   25350       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 88, 61)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 56, 88, 30)   16500       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 56, 88, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 88, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 56, 88, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 56, 88, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 88, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 88, 91)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 56, 88, 91)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 56, 88, 13)   1196        dropout_5[0][0]                  
==================================================================================================
Total params: 504,146
Trainable params: 502,946
Non-trainable params: 1,200
__________________________________________________________________________________________________
----- /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/model_weights.h5
 --- initialized from Model_3T /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2
------------------------------------------------------------------
class_weights [6.11551387e-02 2.80417065e-02 7.36205865e-02 1.00307357e-02
 2.46459952e-02 6.20541010e-03 7.62197172e-02 1.11197709e-01
 6.32300513e-02 1.29380128e-02 3.51235945e-01 1.81283761e-01
 1.95230038e-04]
Train on 17190 samples, validate on 142 samples
Epoch 1/300
 - 30s - loss: 1.0810 - acc: 0.9589 - mDice: 0.6616 - val_loss: 1.1473 - val_acc: 0.9677 - val_mDice: 0.6768

Epoch 00001: val_mDice improved from -inf to 0.67680, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 23s - loss: 0.8710 - acc: 0.9626 - mDice: 0.7121 - val_loss: 1.1970 - val_acc: 0.9678 - val_mDice: 0.6838

Epoch 00002: val_mDice improved from 0.67680 to 0.68383, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 22s - loss: 0.7983 - acc: 0.9642 - mDice: 0.7348 - val_loss: 1.2418 - val_acc: 0.9671 - val_mDice: 0.6870

Epoch 00003: val_mDice improved from 0.68383 to 0.68696, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 23s - loss: 0.7544 - acc: 0.9651 - mDice: 0.7487 - val_loss: 1.2682 - val_acc: 0.9676 - val_mDice: 0.6985

Epoch 00004: val_mDice improved from 0.68696 to 0.69851, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 23s - loss: 0.7237 - acc: 0.9657 - mDice: 0.7590 - val_loss: 1.3406 - val_acc: 0.9667 - val_mDice: 0.6945

Epoch 00005: val_mDice did not improve from 0.69851
Epoch 6/300
 - 22s - loss: 0.6988 - acc: 0.9663 - mDice: 0.7668 - val_loss: 1.3152 - val_acc: 0.9673 - val_mDice: 0.6989

Epoch 00006: val_mDice improved from 0.69851 to 0.69895, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 23s - loss: 0.6781 - acc: 0.9668 - mDice: 0.7733 - val_loss: 1.3522 - val_acc: 0.9670 - val_mDice: 0.6961

Epoch 00007: val_mDice did not improve from 0.69895
Epoch 8/300
 - 23s - loss: 0.6639 - acc: 0.9671 - mDice: 0.7782 - val_loss: 1.3537 - val_acc: 0.9667 - val_mDice: 0.7024

Epoch 00008: val_mDice improved from 0.69895 to 0.70237, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 9/300
 - 23s - loss: 0.6483 - acc: 0.9675 - mDice: 0.7831 - val_loss: 1.3876 - val_acc: 0.9667 - val_mDice: 0.7010

Epoch 00009: val_mDice did not improve from 0.70237
Epoch 10/300
 - 22s - loss: 0.6384 - acc: 0.9677 - mDice: 0.7867 - val_loss: 1.4199 - val_acc: 0.9657 - val_mDice: 0.6968

Epoch 00010: val_mDice did not improve from 0.70237
Epoch 11/300
 - 23s - loss: 0.6263 - acc: 0.9680 - mDice: 0.7904 - val_loss: 1.4737 - val_acc: 0.9664 - val_mDice: 0.6990

Epoch 00011: val_mDice did not improve from 0.70237
Epoch 12/300
 - 23s - loss: 0.6184 - acc: 0.9682 - mDice: 0.7931 - val_loss: 1.4536 - val_acc: 0.9662 - val_mDice: 0.7034

Epoch 00012: val_mDice improved from 0.70237 to 0.70335, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 13/300
 - 22s - loss: 0.6101 - acc: 0.9684 - mDice: 0.7958 - val_loss: 1.4822 - val_acc: 0.9663 - val_mDice: 0.7009

Epoch 00013: val_mDice did not improve from 0.70335
Epoch 14/300
 - 22s - loss: 0.6030 - acc: 0.9686 - mDice: 0.7983 - val_loss: 1.4536 - val_acc: 0.9665 - val_mDice: 0.7018

Epoch 00014: val_mDice did not improve from 0.70335
Epoch 15/300
 - 23s - loss: 0.5955 - acc: 0.9688 - mDice: 0.8005 - val_loss: 1.4489 - val_acc: 0.9666 - val_mDice: 0.7037

Epoch 00015: val_mDice improved from 0.70335 to 0.70374, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 16/300
 - 23s - loss: 0.5908 - acc: 0.9689 - mDice: 0.8023 - val_loss: 1.4942 - val_acc: 0.9665 - val_mDice: 0.7037

Epoch 00016: val_mDice improved from 0.70374 to 0.70374, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 17/300
 - 22s - loss: 0.5828 - acc: 0.9691 - mDice: 0.8049 - val_loss: 1.5601 - val_acc: 0.9658 - val_mDice: 0.6988

Epoch 00017: val_mDice did not improve from 0.70374
Epoch 18/300
 - 22s - loss: 0.5775 - acc: 0.9692 - mDice: 0.8068 - val_loss: 1.5825 - val_acc: 0.9655 - val_mDice: 0.6957

Epoch 00018: val_mDice did not improve from 0.70374
Epoch 19/300
 - 23s - loss: 0.5729 - acc: 0.9693 - mDice: 0.8083 - val_loss: 1.5090 - val_acc: 0.9667 - val_mDice: 0.6967

Epoch 00019: val_mDice did not improve from 0.70374
Epoch 20/300
 - 23s - loss: 0.5695 - acc: 0.9694 - mDice: 0.8095 - val_loss: 1.5480 - val_acc: 0.9661 - val_mDice: 0.7068

Epoch 00020: val_mDice improved from 0.70374 to 0.70676, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 21/300
 - 23s - loss: 0.5640 - acc: 0.9696 - mDice: 0.8114 - val_loss: 1.5424 - val_acc: 0.9666 - val_mDice: 0.7046

Epoch 00021: val_mDice did not improve from 0.70676
Epoch 22/300
 - 23s - loss: 0.5606 - acc: 0.9696 - mDice: 0.8122 - val_loss: 1.6192 - val_acc: 0.9655 - val_mDice: 0.7007

Epoch 00022: val_mDice did not improve from 0.70676
Epoch 23/300
 - 23s - loss: 0.5564 - acc: 0.9697 - mDice: 0.8137 - val_loss: 1.5786 - val_acc: 0.9659 - val_mDice: 0.7053

Epoch 00023: val_mDice did not improve from 0.70676
Epoch 24/300
 - 23s - loss: 0.5526 - acc: 0.9698 - mDice: 0.8151 - val_loss: 1.5936 - val_acc: 0.9658 - val_mDice: 0.7046

Epoch 00024: val_mDice did not improve from 0.70676
Epoch 25/300
 - 22s - loss: 0.5495 - acc: 0.9699 - mDice: 0.8162 - val_loss: 1.5375 - val_acc: 0.9665 - val_mDice: 0.7043

Epoch 00025: val_mDice did not improve from 0.70676
Epoch 26/300
 - 22s - loss: 0.5446 - acc: 0.9700 - mDice: 0.8175 - val_loss: 1.6053 - val_acc: 0.9660 - val_mDice: 0.7062

Epoch 00026: val_mDice did not improve from 0.70676
Epoch 27/300
 - 23s - loss: 0.5419 - acc: 0.9701 - mDice: 0.8186 - val_loss: 1.6256 - val_acc: 0.9659 - val_mDice: 0.7015

Epoch 00027: val_mDice did not improve from 0.70676
Epoch 28/300
 - 23s - loss: 0.5395 - acc: 0.9701 - mDice: 0.8195 - val_loss: 1.5733 - val_acc: 0.9661 - val_mDice: 0.7061

Epoch 00028: val_mDice did not improve from 0.70676
Epoch 29/300
 - 22s - loss: 0.5359 - acc: 0.9702 - mDice: 0.8207 - val_loss: 1.6095 - val_acc: 0.9657 - val_mDice: 0.7097

Epoch 00029: val_mDice improved from 0.70676 to 0.70974, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 30/300
 - 23s - loss: 0.5341 - acc: 0.9702 - mDice: 0.8211 - val_loss: 1.5496 - val_acc: 0.9664 - val_mDice: 0.7102

Epoch 00030: val_mDice improved from 0.70974 to 0.71018, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 31/300
 - 24s - loss: 0.5302 - acc: 0.9703 - mDice: 0.8225 - val_loss: 1.5992 - val_acc: 0.9665 - val_mDice: 0.7050

Epoch 00031: val_mDice did not improve from 0.71018
Epoch 32/300
 - 25s - loss: 0.5271 - acc: 0.9704 - mDice: 0.8234 - val_loss: 1.6441 - val_acc: 0.9656 - val_mDice: 0.7051

Epoch 00032: val_mDice did not improve from 0.71018
Epoch 33/300
 - 25s - loss: 0.5255 - acc: 0.9705 - mDice: 0.8243 - val_loss: 1.5914 - val_acc: 0.9662 - val_mDice: 0.7080

Epoch 00033: val_mDice did not improve from 0.71018
Epoch 34/300
 - 26s - loss: 0.5225 - acc: 0.9705 - mDice: 0.8253 - val_loss: 1.6112 - val_acc: 0.9658 - val_mDice: 0.7098

Epoch 00034: val_mDice did not improve from 0.71018
Epoch 35/300
 - 25s - loss: 0.5210 - acc: 0.9706 - mDice: 0.8256 - val_loss: 1.6470 - val_acc: 0.9657 - val_mDice: 0.7089

Epoch 00035: val_mDice did not improve from 0.71018
Epoch 36/300
 - 26s - loss: 0.5183 - acc: 0.9706 - mDice: 0.8265 - val_loss: 1.6100 - val_acc: 0.9659 - val_mDice: 0.7079

Epoch 00036: val_mDice did not improve from 0.71018
Epoch 37/300
 - 26s - loss: 0.5147 - acc: 0.9707 - mDice: 0.8277 - val_loss: 1.6119 - val_acc: 0.9662 - val_mDice: 0.7067

Epoch 00037: val_mDice did not improve from 0.71018
Epoch 38/300
 - 26s - loss: 0.5144 - acc: 0.9707 - mDice: 0.8279 - val_loss: 1.6064 - val_acc: 0.9657 - val_mDice: 0.7087

Epoch 00038: val_mDice did not improve from 0.71018
Epoch 39/300
 - 25s - loss: 0.5113 - acc: 0.9708 - mDice: 0.8290 - val_loss: 1.6518 - val_acc: 0.9659 - val_mDice: 0.7055

Epoch 00039: val_mDice did not improve from 0.71018
Epoch 40/300
 - 25s - loss: 0.5108 - acc: 0.9708 - mDice: 0.8292 - val_loss: 1.6584 - val_acc: 0.9662 - val_mDice: 0.7094

Epoch 00040: val_mDice did not improve from 0.71018
Epoch 41/300
 - 25s - loss: 0.5089 - acc: 0.9708 - mDice: 0.8299 - val_loss: 1.6796 - val_acc: 0.9660 - val_mDice: 0.7030

Epoch 00041: val_mDice did not improve from 0.71018
Epoch 42/300
 - 24s - loss: 0.5071 - acc: 0.9709 - mDice: 0.8304 - val_loss: 1.7426 - val_acc: 0.9663 - val_mDice: 0.7051

Epoch 00042: val_mDice did not improve from 0.71018
Epoch 43/300
 - 24s - loss: 0.5026 - acc: 0.9710 - mDice: 0.8318 - val_loss: 1.6293 - val_acc: 0.9666 - val_mDice: 0.7087

Epoch 00043: val_mDice did not improve from 0.71018
Epoch 44/300
 - 23s - loss: 0.5055 - acc: 0.9709 - mDice: 0.8311 - val_loss: 1.6739 - val_acc: 0.9658 - val_mDice: 0.7073

Epoch 00044: val_mDice did not improve from 0.71018
Epoch 45/300
 - 23s - loss: 0.5025 - acc: 0.9710 - mDice: 0.8320 - val_loss: 1.6159 - val_acc: 0.9660 - val_mDice: 0.7053

Epoch 00045: val_mDice did not improve from 0.71018
Epoch 46/300
 - 22s - loss: 0.5013 - acc: 0.9710 - mDice: 0.8324 - val_loss: 1.6737 - val_acc: 0.9662 - val_mDice: 0.7048

Epoch 00046: val_mDice did not improve from 0.71018
Epoch 47/300
 - 24s - loss: 0.4976 - acc: 0.9711 - mDice: 0.8334 - val_loss: 1.6980 - val_acc: 0.9655 - val_mDice: 0.7036

Epoch 00047: val_mDice did not improve from 0.71018
Epoch 48/300
 - 23s - loss: 0.4979 - acc: 0.9711 - mDice: 0.8334 - val_loss: 1.7158 - val_acc: 0.9658 - val_mDice: 0.7047

Epoch 00048: val_mDice did not improve from 0.71018
Epoch 49/300
 - 23s - loss: 0.4962 - acc: 0.9712 - mDice: 0.8341 - val_loss: 1.6930 - val_acc: 0.9659 - val_mDice: 0.7061

Epoch 00049: val_mDice did not improve from 0.71018
Epoch 50/300
 - 24s - loss: 0.4941 - acc: 0.9712 - mDice: 0.8346 - val_loss: 1.7321 - val_acc: 0.9661 - val_mDice: 0.7034

Epoch 00050: val_mDice did not improve from 0.71018
Epoch 51/300
 - 24s - loss: 0.4929 - acc: 0.9712 - mDice: 0.8353 - val_loss: 1.6678 - val_acc: 0.9660 - val_mDice: 0.7062

Epoch 00051: val_mDice did not improve from 0.71018
Epoch 52/300
 - 23s - loss: 0.4905 - acc: 0.9713 - mDice: 0.8360 - val_loss: 1.7084 - val_acc: 0.9656 - val_mDice: 0.7032

Epoch 00052: val_mDice did not improve from 0.71018
Epoch 53/300
 - 23s - loss: 0.4903 - acc: 0.9713 - mDice: 0.8360 - val_loss: 1.7160 - val_acc: 0.9661 - val_mDice: 0.7030

Epoch 00053: val_mDice did not improve from 0.71018
Epoch 54/300
 - 23s - loss: 0.4891 - acc: 0.9713 - mDice: 0.8365 - val_loss: 1.6619 - val_acc: 0.9660 - val_mDice: 0.7087

Epoch 00054: val_mDice did not improve from 0.71018
Epoch 55/300
 - 23s - loss: 0.4868 - acc: 0.9713 - mDice: 0.8374 - val_loss: 1.7265 - val_acc: 0.9660 - val_mDice: 0.7021

Epoch 00055: val_mDice did not improve from 0.71018
Epoch 56/300
 - 23s - loss: 0.4863 - acc: 0.9714 - mDice: 0.8376 - val_loss: 1.6812 - val_acc: 0.9658 - val_mDice: 0.7128

Epoch 00056: val_mDice improved from 0.71018 to 0.71284, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 57/300
 - 23s - loss: 0.4860 - acc: 0.9714 - mDice: 0.8376 - val_loss: 1.6908 - val_acc: 0.9661 - val_mDice: 0.7091

Epoch 00057: val_mDice did not improve from 0.71284
Epoch 58/300
 - 23s - loss: 0.4820 - acc: 0.9714 - mDice: 0.8389 - val_loss: 1.6876 - val_acc: 0.9657 - val_mDice: 0.7111

Epoch 00058: val_mDice did not improve from 0.71284
Epoch 59/300
 - 23s - loss: 0.4821 - acc: 0.9715 - mDice: 0.8390 - val_loss: 1.7046 - val_acc: 0.9653 - val_mDice: 0.7059

Epoch 00059: val_mDice did not improve from 0.71284
Epoch 60/300
 - 22s - loss: 0.4810 - acc: 0.9715 - mDice: 0.8393 - val_loss: 1.6798 - val_acc: 0.9662 - val_mDice: 0.7076

Epoch 00060: val_mDice did not improve from 0.71284
Epoch 61/300
 - 23s - loss: 0.4817 - acc: 0.9714 - mDice: 0.8392 - val_loss: 1.7288 - val_acc: 0.9661 - val_mDice: 0.7043

Epoch 00061: val_mDice did not improve from 0.71284
Epoch 62/300
 - 23s - loss: 0.4803 - acc: 0.9715 - mDice: 0.8395 - val_loss: 1.7330 - val_acc: 0.9659 - val_mDice: 0.7062

Epoch 00062: val_mDice did not improve from 0.71284
Epoch 63/300
 - 23s - loss: 0.4779 - acc: 0.9716 - mDice: 0.8401 - val_loss: 1.6990 - val_acc: 0.9662 - val_mDice: 0.7095

Epoch 00063: val_mDice did not improve from 0.71284
Epoch 64/300
 - 23s - loss: 0.4775 - acc: 0.9716 - mDice: 0.8405 - val_loss: 1.7482 - val_acc: 0.9654 - val_mDice: 0.7056

Epoch 00064: val_mDice did not improve from 0.71284
Epoch 65/300
 - 23s - loss: 0.4747 - acc: 0.9716 - mDice: 0.8412 - val_loss: 1.7156 - val_acc: 0.9656 - val_mDice: 0.7120

Epoch 00065: val_mDice did not improve from 0.71284
Epoch 66/300
 - 23s - loss: 0.4736 - acc: 0.9717 - mDice: 0.8417 - val_loss: 1.7528 - val_acc: 0.9662 - val_mDice: 0.7052

Epoch 00066: val_mDice did not improve from 0.71284
Epoch 67/300
 - 23s - loss: 0.4737 - acc: 0.9717 - mDice: 0.8416 - val_loss: 1.7237 - val_acc: 0.9660 - val_mDice: 0.7103

Epoch 00067: val_mDice did not improve from 0.71284
Epoch 68/300
 - 23s - loss: 0.4732 - acc: 0.9716 - mDice: 0.8419 - val_loss: 1.7288 - val_acc: 0.9662 - val_mDice: 0.7109

Epoch 00068: val_mDice did not improve from 0.71284
Epoch 69/300
 - 23s - loss: 0.4719 - acc: 0.9717 - mDice: 0.8421 - val_loss: 1.7710 - val_acc: 0.9658 - val_mDice: 0.7074

Epoch 00069: val_mDice did not improve from 0.71284
Epoch 70/300
 - 24s - loss: 0.4699 - acc: 0.9717 - mDice: 0.8429 - val_loss: 1.7636 - val_acc: 0.9655 - val_mDice: 0.7052

Epoch 00070: val_mDice did not improve from 0.71284
Epoch 71/300
 - 24s - loss: 0.4701 - acc: 0.9717 - mDice: 0.8431 - val_loss: 1.7461 - val_acc: 0.9658 - val_mDice: 0.7100

Epoch 00071: val_mDice did not improve from 0.71284
Epoch 72/300
 - 23s - loss: 0.4695 - acc: 0.9717 - mDice: 0.8430 - val_loss: 1.7725 - val_acc: 0.9651 - val_mDice: 0.7088

Epoch 00072: val_mDice did not improve from 0.71284
Epoch 73/300
 - 24s - loss: 0.4687 - acc: 0.9718 - mDice: 0.8434 - val_loss: 1.7966 - val_acc: 0.9652 - val_mDice: 0.7038

Epoch 00073: val_mDice did not improve from 0.71284
Epoch 74/300
 - 23s - loss: 0.4670 - acc: 0.9718 - mDice: 0.8439 - val_loss: 1.7669 - val_acc: 0.9661 - val_mDice: 0.7117

Epoch 00074: val_mDice did not improve from 0.71284
Epoch 75/300
 - 24s - loss: 0.4662 - acc: 0.9718 - mDice: 0.8443 - val_loss: 1.7747 - val_acc: 0.9660 - val_mDice: 0.7075

Epoch 00075: val_mDice did not improve from 0.71284
Epoch 76/300
 - 24s - loss: 0.4669 - acc: 0.9718 - mDice: 0.8440 - val_loss: 1.8141 - val_acc: 0.9645 - val_mDice: 0.7097

Epoch 00076: val_mDice did not improve from 0.71284
Epoch 77/300
 - 24s - loss: 0.4641 - acc: 0.9718 - mDice: 0.8448 - val_loss: 1.7712 - val_acc: 0.9653 - val_mDice: 0.7101

Epoch 00077: val_mDice did not improve from 0.71284
Epoch 78/300
 - 24s - loss: 0.4643 - acc: 0.9718 - mDice: 0.8451 - val_loss: 1.7572 - val_acc: 0.9660 - val_mDice: 0.7083

Epoch 00078: val_mDice did not improve from 0.71284
Epoch 79/300
 - 24s - loss: 0.4632 - acc: 0.9719 - mDice: 0.8451 - val_loss: 1.7703 - val_acc: 0.9657 - val_mDice: 0.7127

Epoch 00079: val_mDice did not improve from 0.71284
Epoch 80/300
 - 24s - loss: 0.4620 - acc: 0.9719 - mDice: 0.8457 - val_loss: 1.8287 - val_acc: 0.9656 - val_mDice: 0.7062

Epoch 00080: val_mDice did not improve from 0.71284
Epoch 81/300
 - 24s - loss: 0.4610 - acc: 0.9719 - mDice: 0.8460 - val_loss: 1.7943 - val_acc: 0.9654 - val_mDice: 0.7080

Epoch 00081: val_mDice did not improve from 0.71284
Epoch 82/300
 - 24s - loss: 0.4606 - acc: 0.9719 - mDice: 0.8461 - val_loss: 1.7533 - val_acc: 0.9660 - val_mDice: 0.7068

Epoch 00082: val_mDice did not improve from 0.71284
Epoch 83/300
 - 23s - loss: 0.4608 - acc: 0.9719 - mDice: 0.8461 - val_loss: 1.8036 - val_acc: 0.9660 - val_mDice: 0.7064

Epoch 00083: val_mDice did not improve from 0.71284
Epoch 84/300
 - 24s - loss: 0.4586 - acc: 0.9720 - mDice: 0.8469 - val_loss: 1.7693 - val_acc: 0.9657 - val_mDice: 0.7091

Epoch 00084: val_mDice did not improve from 0.71284
Epoch 85/300
 - 24s - loss: 0.4598 - acc: 0.9720 - mDice: 0.8464 - val_loss: 1.7701 - val_acc: 0.9654 - val_mDice: 0.7065

Epoch 00085: val_mDice did not improve from 0.71284
Epoch 86/300
 - 24s - loss: 0.4579 - acc: 0.9720 - mDice: 0.8470 - val_loss: 1.8101 - val_acc: 0.9653 - val_mDice: 0.7070

Epoch 00086: val_mDice did not improve from 0.71284
Restoring model weights from the end of the best epoch
Epoch 00086: early stopping
{'val_loss': [1.1472642354562248, 1.1970201361347252, 1.241759029072775, 1.268195286603041, 1.3405900899793062, 1.3152113237851102, 1.3522228657359807, 1.3537384489892235, 1.387639042357324, 1.4199023498615748, 1.4737490323227895, 1.4536032181390575, 1.48215372377718, 1.4536300091676309, 1.4488587413035647, 1.4941803997671101, 1.5601141352049062, 1.582517580247261, 1.5089664929349658, 1.5480295738703769, 1.5423721897769982, 1.6191602256936086, 1.5786384134225442, 1.5935720541107823, 1.537526356502318, 1.6052784222952077, 1.6256482626350832, 1.5732699733384898, 1.6094777340620336, 1.549576567092412, 1.5992469930313002, 1.6440522393710177, 1.5913798876211678, 1.611222831296249, 1.6469633428143784, 1.6100205350929582, 1.6118775035294008, 1.6064231613991966, 1.6518170078035812, 1.6584086476916997, 1.6795916742002461, 1.7425938173079154, 1.6292927919978826, 1.6739291750209433, 1.6158710021368214, 1.6736884335396995, 1.6979779559122006, 1.715771087458436, 1.6929710566158025, 1.732107723262948, 1.6678316618355227, 1.708364290250859, 1.715980439118936, 1.6619013648637584, 1.7265205887002004, 1.681226889852067, 1.6908256780933326, 1.6875671207065313, 1.7046010888798135, 1.6798170376831376, 1.7287746348851163, 1.7330392078614572, 1.6990447564863822, 1.7481901544920155, 1.715569492796777, 1.7528339809095357, 1.7237216486057765, 1.7288494882449297, 1.7710218950056693, 1.7635626121306083, 1.7460535336548173, 1.7725450472092965, 1.7966181291660792, 1.7669477210917943, 1.7747133298658988, 1.814085172935271, 1.7712049333142563, 1.7572383628764623, 1.7702939846146275, 1.828702772167367, 1.794319960432993, 1.7532878408969288, 1.8036199623430278, 1.7693260202945118, 1.7700563081553284, 1.810130648210015], 'val_acc': [0.9676767805932274, 0.9677639922625582, 0.9671352052352797, 0.9675753444013461, 0.9667178946481624, 0.9672923826835524, 0.967039448274693, 0.9667336210398607, 0.9667150646867887, 0.9656647468956423, 0.9663620708693921, 0.9662448923352739, 0.9663135048369287, 0.9665078403244556, 0.966627879042021, 0.9664749771776334, 0.9658404848944973, 0.9655232479874517, 0.9667493432340487, 0.9661277104431475, 0.9665964497646815, 0.9654732455669994, 0.9659119525425871, 0.9658319454797557, 0.9665021392661082, 0.9660376948370061, 0.9658647851205208, 0.9661048591976434, 0.9657061536547163, 0.9663649570774024, 0.96646068969243, 0.9656004427184521, 0.9661891687084252, 0.96583191022067, 0.9657118857746393, 0.9659305038586469, 0.9662005926521731, 0.9657133036935833, 0.9658676318719354, 0.9662063113400634, 0.9660305515141554, 0.9663377807173931, 0.9666264544070606, 0.9657662065935807, 0.9660005342792457, 0.9662234900702893, 0.9654803720998092, 0.9657761865938214, 0.965944808973393, 0.9660605586750407, 0.965950545290826, 0.9656261348388564, 0.9661277448627311, 0.9659805541307154, 0.9660134063640111, 0.9657933258674514, 0.9660605620330488, 0.9656647292660995, 0.9652874671237569, 0.96623347007053, 0.966094863246864, 0.9658704937343866, 0.9661920582744438, 0.9654103693827777, 0.9656218634524816, 0.9662234590087139, 0.9659576709841339, 0.9661705955653124, 0.9658333566826833, 0.9655032569253948, 0.9657504592143314, 0.9651045522219698, 0.9651745918770911, 0.9660776954301646, 0.9659934119439461, 0.9645472353612873, 0.9653303262213586, 0.9659833740180647, 0.9656690098869969, 0.9656318728352936, 0.9654489512174902, 0.9660091358171382, 0.9660205480078576, 0.9657033010267876, 0.965378935907928, 0.9653160521681879], 'val_mDice': [0.6767963859396922, 0.6838276302310783, 0.6869621184510244, 0.6985105427218156, 0.6944788199075511, 0.6989487376011593, 0.6960642791130174, 0.7023716216355982, 0.7009643249108758, 0.6967918226416682, 0.6990474210658544, 0.7033531111730656, 0.7009177233131838, 0.7018330349049098, 0.7037370439986108, 0.7037418879253764, 0.6987501601098289, 0.695685412682278, 0.6966583762370365, 0.7067559118002233, 0.7046203965872107, 0.7006541322654402, 0.7052764220976494, 0.7045720647758161, 0.7043046271297294, 0.7061692157261809, 0.7015295884978603, 0.7060918472182582, 0.7097373671934638, 0.7101786665513482, 0.704961100934257, 0.7050799391639064, 0.708005042143271, 0.7098041369881428, 0.7089439806803851, 0.7078547267846658, 0.7066691274374304, 0.7087169491069417, 0.7055219957526301, 0.7093818926475417, 0.7030220560624566, 0.705140770321161, 0.70867146740497, 0.7072559578317992, 0.7052712423700682, 0.7047952161708348, 0.7035554429175148, 0.7047086551155842, 0.7060982274337554, 0.7033813486636524, 0.706181267617454, 0.7031938358091973, 0.7030490452135113, 0.7087479989293596, 0.7020980581431322, 0.7128394506347011, 0.7091190109790211, 0.7110583916516371, 0.7058885920215661, 0.7076098633484101, 0.704254534882559, 0.7062326644507932, 0.7094650562380401, 0.7056029707613126, 0.711957659519894, 0.7051502180771089, 0.7102965519461834, 0.7109046998158307, 0.707385928697989, 0.7051749968192946, 0.7100284779575509, 0.7087841168255873, 0.703829782109865, 0.7116883036116479, 0.7074813423022418, 0.7096629209921393, 0.7100745599034807, 0.7083382757616715, 0.7127452249258337, 0.7062074802291225, 0.7080185211880107, 0.7068219302405774, 0.7063762570770693, 0.709076185461501, 0.7065266958424743, 0.7069606713845696], 'loss': [1.0810170414976217, 0.8709700854452909, 0.7983256331913134, 0.7543642340946364, 0.723661282507745, 0.6988236496031042, 0.6780791661987615, 0.6639437104394923, 0.6483089954718523, 0.6383581444439047, 0.6262641541482128, 0.6184399100567727, 0.6100886728681749, 0.6030123181957502, 0.5954689445573276, 0.5908301855811828, 0.5828170507990252, 0.577546289575315, 0.5729373233515277, 0.5694879156132643, 0.5639591420230787, 0.5606440842116968, 0.5564368248956713, 0.5526216450370003, 0.5494682452684229, 0.5446014075240401, 0.5419247381350133, 0.5394950159730573, 0.5358823236856022, 0.5341393682345046, 0.5302252399498394, 0.527093952516264, 0.5254530269021971, 0.5225291998494566, 0.5209713980096103, 0.5182643058412362, 0.5147295053994122, 0.514438014865407, 0.511317854256322, 0.5108054420884228, 0.5088941826939652, 0.5071070425866856, 0.5026211588274538, 0.5055274294863752, 0.5025400749433172, 0.501320323013441, 0.4976277007759831, 0.4978968753691258, 0.49617035484993577, 0.49414011272599073, 0.49286777432953777, 0.49053092086779787, 0.4903101966504512, 0.48911207910885013, 0.48680554726499675, 0.48625924895501815, 0.4859813630511554, 0.48202401964798997, 0.4821180136936081, 0.48103764441694336, 0.4816642391293322, 0.48026177065188, 0.47793528567642024, 0.4774730556436997, 0.47473273893093354, 0.47362890123558155, 0.47367520511601124, 0.47319395714474666, 0.47189644261665853, 0.46992668384656855, 0.47009434696198066, 0.46948534460037233, 0.4686983958831563, 0.4669801822542243, 0.46623809842816477, 0.46686325957776503, 0.4641311156361376, 0.46431653627203673, 0.4631796739627068, 0.4619966676028542, 0.4610280574338945, 0.4606476077824016, 0.4607818829000794, 0.4585836964370623, 0.4598230785446988, 0.45793165874176067], 'acc': [0.9589399861484992, 0.9625834946787725, 0.9641701470564242, 0.965091959586873, 0.9657356084745384, 0.9663061645226537, 0.9667606671027072, 0.9670949991252826, 0.967468532245474, 0.9677231136347542, 0.968023068895168, 0.968207316491547, 0.9684313679934241, 0.9686320360973174, 0.9687627368780539, 0.9688921648100963, 0.9690600268850499, 0.9691964416326375, 0.9693102731893338, 0.9694056320564909, 0.9695598825318235, 0.9696468836766055, 0.9697294566713148, 0.9698282980932754, 0.9698933419826212, 0.970013335286496, 0.9700870325289332, 0.9701234375480443, 0.9701576241925403, 0.9702118421932373, 0.9703293458676185, 0.9703954510594468, 0.9704572276156471, 0.9704981381772493, 0.9705530666833426, 0.9706245082072424, 0.9706746655678319, 0.970684691214714, 0.9707837313188239, 0.9708170676175906, 0.9708371786893697, 0.9708970793116016, 0.9709658415737784, 0.9709392664320182, 0.9709751900716741, 0.9709805737684604, 0.9710785610305493, 0.9710803355083277, 0.9711672979569005, 0.9711925833290438, 0.971198108461168, 0.9712569096394927, 0.9712759593047674, 0.9713032184956447, 0.9713293876392748, 0.9713574713090605, 0.9713502122330901, 0.9714362442042677, 0.971464198331905, 0.9714740683964479, 0.9714382156998422, 0.9714807567033329, 0.9715627197126374, 0.971564619051571, 0.9716094327638702, 0.971690847438182, 0.9716688792257547, 0.971621669781215, 0.9716682529782333, 0.9717122374959571, 0.9717366024114976, 0.9717368625013408, 0.9717658058441677, 0.9717922843147531, 0.971781800554685, 0.9718244976952993, 0.9718455696189174, 0.9718462662893786, 0.9718881753588083, 0.9718787298776717, 0.971898383113657, 0.9719048319270681, 0.9719251688307562, 0.971962804847016, 0.9719602442744723, 0.97197066579467], 'mDice': [0.661625918952305, 0.7121436387179132, 0.7347538164010085, 0.7486532757003478, 0.7589696708149934, 0.766763646981271, 0.7732599484428131, 0.7782407507361057, 0.7831275427736745, 0.7867494007749153, 0.7904095365738993, 0.7931126422005521, 0.7958376941256499, 0.7983282869676298, 0.8005094928336463, 0.8022589118692888, 0.8049066500513965, 0.8067747137448065, 0.8082550949936623, 0.809452097453372, 0.8114017226655793, 0.812230326846424, 0.81365684883202, 0.8151347336899478, 0.8161902501875749, 0.8175175189278443, 0.8185791684625591, 0.8195457630479246, 0.8206886344347116, 0.8211339080035513, 0.822517460622782, 0.8234418113263559, 0.8242819595642046, 0.825285839958202, 0.8256298874338537, 0.8265435882194435, 0.8277492838726964, 0.827857838597944, 0.8289682648430181, 0.8292112103584827, 0.8299410392754019, 0.8303604622508566, 0.8318069762723123, 0.8310556896832739, 0.8319785153886619, 0.8324300129792245, 0.8334154419388585, 0.8334219738659018, 0.8341119863600007, 0.8346401197123902, 0.8353088771346837, 0.8359808771675448, 0.8360352955840923, 0.8365198362698868, 0.8373536540714372, 0.8376271627613665, 0.8375844647885756, 0.8389332897445364, 0.8389629440435218, 0.8393215358153272, 0.8391624226550712, 0.8395422735902166, 0.840077592960411, 0.8404654757514674, 0.8412105454616313, 0.841678423337842, 0.8415793205084254, 0.8418695545945493, 0.8420900282227348, 0.8429490397183128, 0.8430592155581369, 0.8430190718818917, 0.8434308008304372, 0.8439086585838202, 0.8442694765665699, 0.8440325907873095, 0.8447879586821728, 0.8450595078737393, 0.8451154577378411, 0.8457495929405674, 0.84596950547372, 0.8461465460745106, 0.846106641718369, 0.8469472138114694, 0.8464053577292167, 0.8469698262672358]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:03<00:09,  3.01s/it]predicting test subjects:  50%|█████     | 2/4 [00:04<00:05,  2.65s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:06<00:02,  2.40s/it]predicting test subjects: 100%|██████████| 4/4 [00:08<00:00,  2.26s/it]
predicting train subjects:   0%|          | 0/456 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/456 [00:02<15:38,  2.06s/it]predicting train subjects:   0%|          | 2/456 [00:03<15:14,  2.02s/it]predicting train subjects:   1%|          | 3/456 [00:05<14:42,  1.95s/it]predicting train subjects:   1%|          | 4/456 [00:07<13:40,  1.81s/it]predicting train subjects:   1%|          | 5/456 [00:09<14:50,  1.97s/it]predicting train subjects:   1%|▏         | 6/456 [00:11<15:06,  2.01s/it]predicting train subjects:   2%|▏         | 7/456 [00:13<14:17,  1.91s/it]predicting train subjects:   2%|▏         | 8/456 [00:14<12:49,  1.72s/it]predicting train subjects:   2%|▏         | 9/456 [00:16<13:17,  1.78s/it]predicting train subjects:   2%|▏         | 10/456 [00:19<14:54,  2.01s/it]predicting train subjects:   2%|▏         | 11/456 [00:21<15:28,  2.09s/it]predicting train subjects:   3%|▎         | 12/456 [00:22<13:53,  1.88s/it]predicting train subjects:   3%|▎         | 13/456 [00:24<14:18,  1.94s/it]predicting train subjects:   3%|▎         | 14/456 [00:26<14:37,  1.99s/it]predicting train subjects:   3%|▎         | 15/456 [00:28<12:58,  1.77s/it]predicting train subjects:   4%|▎         | 16/456 [00:30<13:31,  1.84s/it]predicting train subjects:   4%|▎         | 17/456 [00:32<14:36,  2.00s/it]predicting train subjects:   4%|▍         | 18/456 [00:34<14:14,  1.95s/it]predicting train subjects:   4%|▍         | 19/456 [00:36<13:34,  1.86s/it]predicting train subjects:   4%|▍         | 20/456 [00:37<13:00,  1.79s/it]predicting train subjects:   5%|▍         | 21/456 [00:39<12:52,  1.78s/it]predicting train subjects:   5%|▍         | 22/456 [00:41<12:53,  1.78s/it]predicting train subjects:   5%|▌         | 23/456 [00:43<13:17,  1.84s/it]predicting train subjects:   5%|▌         | 24/456 [00:44<11:40,  1.62s/it]predicting train subjects:   5%|▌         | 25/456 [00:46<11:49,  1.65s/it]predicting train subjects:   6%|▌         | 26/456 [00:47<12:10,  1.70s/it]predicting train subjects:   6%|▌         | 27/456 [00:49<12:52,  1.80s/it]predicting train subjects:   6%|▌         | 28/456 [00:51<13:23,  1.88s/it]predicting train subjects:   6%|▋         | 29/456 [00:53<13:09,  1.85s/it]predicting train subjects:   7%|▋         | 30/456 [00:55<12:59,  1.83s/it]predicting train subjects:   7%|▋         | 31/456 [00:57<13:03,  1.84s/it]predicting train subjects:   7%|▋         | 32/456 [00:59<13:00,  1.84s/it]predicting train subjects:   7%|▋         | 33/456 [01:00<12:29,  1.77s/it]predicting train subjects:   7%|▋         | 34/456 [01:02<12:46,  1.82s/it]predicting train subjects:   8%|▊         | 35/456 [01:04<12:50,  1.83s/it]predicting train subjects:   8%|▊         | 36/456 [01:06<13:13,  1.89s/it]predicting train subjects:   8%|▊         | 37/456 [01:08<13:15,  1.90s/it]predicting train subjects:   8%|▊         | 38/456 [01:10<13:19,  1.91s/it]predicting train subjects:   9%|▊         | 39/456 [01:12<13:02,  1.88s/it]predicting train subjects:   9%|▉         | 40/456 [01:14<13:14,  1.91s/it]predicting train subjects:   9%|▉         | 41/456 [01:16<13:07,  1.90s/it]predicting train subjects:   9%|▉         | 42/456 [01:18<13:03,  1.89s/it]predicting train subjects:   9%|▉         | 43/456 [01:19<13:07,  1.91s/it]predicting train subjects:  10%|▉         | 44/456 [01:22<13:32,  1.97s/it]predicting train subjects:  10%|▉         | 45/456 [01:24<13:44,  2.01s/it]predicting train subjects:  10%|█         | 46/456 [01:26<13:53,  2.03s/it]predicting train subjects:  10%|█         | 47/456 [01:28<14:10,  2.08s/it]predicting train subjects:  11%|█         | 48/456 [01:30<14:33,  2.14s/it]predicting train subjects:  11%|█         | 49/456 [01:32<14:13,  2.10s/it]predicting train subjects:  11%|█         | 50/456 [01:34<14:00,  2.07s/it]predicting train subjects:  11%|█         | 51/456 [01:37<14:18,  2.12s/it]predicting train subjects:  11%|█▏        | 52/456 [01:39<14:16,  2.12s/it]predicting train subjects:  12%|█▏        | 53/456 [01:41<14:25,  2.15s/it]predicting train subjects:  12%|█▏        | 54/456 [01:43<13:55,  2.08s/it]predicting train subjects:  12%|█▏        | 55/456 [01:45<13:50,  2.07s/it]predicting train subjects:  12%|█▏        | 56/456 [01:47<13:10,  1.98s/it]predicting train subjects:  12%|█▎        | 57/456 [01:48<12:29,  1.88s/it]predicting train subjects:  13%|█▎        | 58/456 [01:50<12:01,  1.81s/it]predicting train subjects:  13%|█▎        | 59/456 [01:52<11:52,  1.80s/it]predicting train subjects:  13%|█▎        | 60/456 [01:53<11:51,  1.80s/it]predicting train subjects:  13%|█▎        | 61/456 [01:55<11:58,  1.82s/it]predicting train subjects:  14%|█▎        | 62/456 [01:57<11:59,  1.83s/it]predicting train subjects:  14%|█▍        | 63/456 [01:59<11:50,  1.81s/it]predicting train subjects:  14%|█▍        | 64/456 [02:01<11:42,  1.79s/it]predicting train subjects:  14%|█▍        | 65/456 [02:02<11:41,  1.79s/it]predicting train subjects:  14%|█▍        | 66/456 [02:04<11:34,  1.78s/it]predicting train subjects:  15%|█▍        | 67/456 [02:06<11:29,  1.77s/it]predicting train subjects:  15%|█▍        | 68/456 [02:08<11:30,  1.78s/it]predicting train subjects:  15%|█▌        | 69/456 [02:10<11:27,  1.78s/it]predicting train subjects:  15%|█▌        | 70/456 [02:11<11:20,  1.76s/it]predicting train subjects:  16%|█▌        | 71/456 [02:13<11:17,  1.76s/it]predicting train subjects:  16%|█▌        | 72/456 [02:15<11:14,  1.76s/it]predicting train subjects:  16%|█▌        | 73/456 [02:16<11:05,  1.74s/it]predicting train subjects:  16%|█▌        | 74/456 [02:18<11:11,  1.76s/it]predicting train subjects:  16%|█▋        | 75/456 [02:20<11:12,  1.76s/it]predicting train subjects:  17%|█▋        | 76/456 [02:22<11:07,  1.76s/it]predicting train subjects:  17%|█▋        | 77/456 [02:24<11:08,  1.76s/it]predicting train subjects:  17%|█▋        | 78/456 [02:25<11:05,  1.76s/it]predicting train subjects:  17%|█▋        | 79/456 [02:26<09:43,  1.55s/it]predicting train subjects:  18%|█▊        | 80/456 [02:27<08:39,  1.38s/it]predicting train subjects:  18%|█▊        | 81/456 [02:28<07:50,  1.25s/it]predicting train subjects:  18%|█▊        | 82/456 [02:29<07:21,  1.18s/it]predicting train subjects:  18%|█▊        | 83/456 [02:30<06:58,  1.12s/it]predicting train subjects:  18%|█▊        | 84/456 [02:31<06:50,  1.10s/it]predicting train subjects:  19%|█▊        | 85/456 [02:32<06:33,  1.06s/it]predicting train subjects:  19%|█▉        | 86/456 [02:33<06:26,  1.04s/it]predicting train subjects:  19%|█▉        | 87/456 [02:34<06:13,  1.01s/it]predicting train subjects:  19%|█▉        | 88/456 [02:35<06:12,  1.01s/it]predicting train subjects:  20%|█▉        | 89/456 [02:36<06:10,  1.01s/it]predicting train subjects:  20%|█▉        | 90/456 [02:37<06:22,  1.05s/it]predicting train subjects:  20%|█▉        | 91/456 [02:38<06:15,  1.03s/it]predicting train subjects:  20%|██        | 92/456 [02:39<06:10,  1.02s/it]predicting train subjects:  20%|██        | 93/456 [02:40<05:57,  1.02it/s]predicting train subjects:  21%|██        | 94/456 [02:41<05:53,  1.02it/s]predicting train subjects:  21%|██        | 95/456 [02:42<05:46,  1.04it/s]predicting train subjects:  21%|██        | 96/456 [02:43<05:47,  1.04it/s]predicting train subjects:  21%|██▏       | 97/456 [02:45<06:54,  1.15s/it]predicting train subjects:  21%|██▏       | 98/456 [02:46<07:48,  1.31s/it]predicting train subjects:  22%|██▏       | 99/456 [02:48<08:15,  1.39s/it]predicting train subjects:  22%|██▏       | 100/456 [02:50<08:49,  1.49s/it]predicting train subjects:  22%|██▏       | 101/456 [02:51<09:17,  1.57s/it]predicting train subjects:  22%|██▏       | 102/456 [02:53<09:28,  1.61s/it]predicting train subjects:  23%|██▎       | 103/456 [02:55<09:34,  1.63s/it]predicting train subjects:  23%|██▎       | 104/456 [02:57<09:57,  1.70s/it]predicting train subjects:  23%|██▎       | 105/456 [02:58<09:52,  1.69s/it]predicting train subjects:  23%|██▎       | 106/456 [03:00<09:52,  1.69s/it]predicting train subjects:  23%|██▎       | 107/456 [03:02<10:19,  1.77s/it]predicting train subjects:  24%|██▎       | 108/456 [03:04<10:02,  1.73s/it]predicting train subjects:  24%|██▍       | 109/456 [03:05<09:53,  1.71s/it]predicting train subjects:  24%|██▍       | 110/456 [03:07<09:51,  1.71s/it]predicting train subjects:  24%|██▍       | 111/456 [03:09<09:48,  1.70s/it]predicting train subjects:  25%|██▍       | 112/456 [03:10<09:39,  1.68s/it]predicting train subjects:  25%|██▍       | 113/456 [03:12<09:27,  1.66s/it]predicting train subjects:  25%|██▌       | 114/456 [03:14<09:19,  1.64s/it]predicting train subjects:  25%|██▌       | 115/456 [03:15<09:25,  1.66s/it]predicting train subjects:  25%|██▌       | 116/456 [03:17<09:26,  1.67s/it]predicting train subjects:  26%|██▌       | 117/456 [03:19<09:19,  1.65s/it]predicting train subjects:  26%|██▌       | 118/456 [03:20<09:13,  1.64s/it]predicting train subjects:  26%|██▌       | 119/456 [03:22<09:21,  1.67s/it]predicting train subjects:  26%|██▋       | 120/456 [03:24<09:20,  1.67s/it]predicting train subjects:  27%|██▋       | 121/456 [03:25<09:33,  1.71s/it]predicting train subjects:  27%|██▋       | 122/456 [03:27<09:34,  1.72s/it]predicting train subjects:  27%|██▋       | 123/456 [03:29<09:24,  1.69s/it]predicting train subjects:  27%|██▋       | 124/456 [03:31<09:29,  1.72s/it]predicting train subjects:  27%|██▋       | 125/456 [03:32<09:23,  1.70s/it]predicting train subjects:  28%|██▊       | 126/456 [03:34<09:27,  1.72s/it]predicting train subjects:  28%|██▊       | 127/456 [03:35<08:48,  1.61s/it]predicting train subjects:  28%|██▊       | 128/456 [03:37<08:11,  1.50s/it]predicting train subjects:  28%|██▊       | 129/456 [03:38<07:57,  1.46s/it]predicting train subjects:  29%|██▊       | 130/456 [03:39<07:42,  1.42s/it]predicting train subjects:  29%|██▊       | 131/456 [03:41<07:32,  1.39s/it]predicting train subjects:  29%|██▉       | 132/456 [03:42<07:24,  1.37s/it]predicting train subjects:  29%|██▉       | 133/456 [03:44<08:43,  1.62s/it]predicting train subjects:  29%|██▉       | 134/456 [03:46<09:55,  1.85s/it]predicting train subjects:  30%|██▉       | 135/456 [03:49<10:32,  1.97s/it]predicting train subjects:  30%|██▉       | 136/456 [03:51<10:56,  2.05s/it]predicting train subjects:  30%|███       | 137/456 [03:53<11:06,  2.09s/it]predicting train subjects:  30%|███       | 138/456 [03:55<10:57,  2.07s/it]predicting train subjects:  30%|███       | 139/456 [03:56<09:43,  1.84s/it]predicting train subjects:  31%|███       | 140/456 [03:58<08:55,  1.69s/it]predicting train subjects:  31%|███       | 141/456 [03:59<08:27,  1.61s/it]predicting train subjects:  31%|███       | 142/456 [04:01<08:09,  1.56s/it]predicting train subjects:  31%|███▏      | 143/456 [04:02<07:49,  1.50s/it]predicting train subjects:  32%|███▏      | 144/456 [04:03<07:31,  1.45s/it]predicting train subjects:  32%|███▏      | 145/456 [04:05<07:33,  1.46s/it]predicting train subjects:  32%|███▏      | 146/456 [04:06<07:37,  1.48s/it]predicting train subjects:  32%|███▏      | 147/456 [04:08<07:43,  1.50s/it]predicting train subjects:  32%|███▏      | 148/456 [04:09<07:45,  1.51s/it]predicting train subjects:  33%|███▎      | 149/456 [04:11<07:45,  1.52s/it]predicting train subjects:  33%|███▎      | 150/456 [04:13<08:01,  1.57s/it]predicting train subjects:  33%|███▎      | 151/456 [04:14<07:57,  1.57s/it]predicting train subjects:  33%|███▎      | 152/456 [04:16<08:00,  1.58s/it]predicting train subjects:  34%|███▎      | 153/456 [04:17<07:54,  1.57s/it]predicting train subjects:  34%|███▍      | 154/456 [04:19<07:58,  1.59s/it]predicting train subjects:  34%|███▍      | 155/456 [04:21<07:57,  1.59s/it]predicting train subjects:  34%|███▍      | 156/456 [04:22<07:56,  1.59s/it]predicting train subjects:  34%|███▍      | 157/456 [04:24<07:48,  1.57s/it]predicting train subjects:  35%|███▍      | 158/456 [04:25<07:37,  1.54s/it]predicting train subjects:  35%|███▍      | 159/456 [04:27<07:30,  1.52s/it]predicting train subjects:  35%|███▌      | 160/456 [04:28<07:22,  1.49s/it]predicting train subjects:  35%|███▌      | 161/456 [04:30<07:15,  1.48s/it]predicting train subjects:  36%|███▌      | 162/456 [04:31<07:18,  1.49s/it]predicting train subjects:  36%|███▌      | 163/456 [04:32<06:34,  1.35s/it]predicting train subjects:  36%|███▌      | 164/456 [04:33<06:10,  1.27s/it]predicting train subjects:  36%|███▌      | 165/456 [04:34<05:50,  1.20s/it]predicting train subjects:  36%|███▋      | 166/456 [04:35<05:31,  1.14s/it]predicting train subjects:  37%|███▋      | 167/456 [04:36<05:25,  1.13s/it]predicting train subjects:  37%|███▋      | 168/456 [04:37<05:12,  1.09s/it]predicting train subjects:  37%|███▋      | 169/456 [04:38<05:09,  1.08s/it]predicting train subjects:  37%|███▋      | 170/456 [04:39<05:06,  1.07s/it]predicting train subjects:  38%|███▊      | 171/456 [04:40<05:01,  1.06s/it]predicting train subjects:  38%|███▊      | 172/456 [04:41<04:58,  1.05s/it]predicting train subjects:  38%|███▊      | 173/456 [04:43<04:56,  1.05s/it]predicting train subjects:  38%|███▊      | 174/456 [04:44<04:56,  1.05s/it]predicting train subjects:  38%|███▊      | 175/456 [04:45<04:59,  1.07s/it]predicting train subjects:  39%|███▊      | 176/456 [04:46<04:55,  1.05s/it]predicting train subjects:  39%|███▉      | 177/456 [04:47<04:50,  1.04s/it]predicting train subjects:  39%|███▉      | 178/456 [04:48<04:49,  1.04s/it]predicting train subjects:  39%|███▉      | 179/456 [04:49<04:50,  1.05s/it]predicting train subjects:  39%|███▉      | 180/456 [04:50<04:50,  1.05s/it]predicting train subjects:  40%|███▉      | 181/456 [04:52<05:52,  1.28s/it]predicting train subjects:  40%|███▉      | 182/456 [04:54<06:36,  1.45s/it]predicting train subjects:  40%|████      | 183/456 [04:55<07:06,  1.56s/it]predicting train subjects:  40%|████      | 184/456 [04:57<07:24,  1.64s/it]predicting train subjects:  41%|████      | 185/456 [04:59<07:32,  1.67s/it]predicting train subjects:  41%|████      | 186/456 [05:01<07:40,  1.71s/it]predicting train subjects:  41%|████      | 187/456 [05:03<08:07,  1.81s/it]predicting train subjects:  41%|████      | 188/456 [05:05<08:32,  1.91s/it]predicting train subjects:  41%|████▏     | 189/456 [05:07<08:48,  1.98s/it]predicting train subjects:  42%|████▏     | 190/456 [05:09<08:49,  1.99s/it]predicting train subjects:  42%|████▏     | 191/456 [05:11<08:58,  2.03s/it]predicting train subjects:  42%|████▏     | 192/456 [05:13<08:52,  2.02s/it]predicting train subjects:  42%|████▏     | 193/456 [05:15<08:45,  2.00s/it]predicting train subjects:  43%|████▎     | 194/456 [05:17<08:30,  1.95s/it]predicting train subjects:  43%|████▎     | 195/456 [05:19<08:23,  1.93s/it]predicting train subjects:  43%|████▎     | 196/456 [05:21<08:13,  1.90s/it]predicting train subjects:  43%|████▎     | 197/456 [05:22<08:01,  1.86s/it]predicting train subjects:  43%|████▎     | 198/456 [05:24<08:06,  1.89s/it]predicting train subjects:  44%|████▎     | 199/456 [05:26<07:47,  1.82s/it]predicting train subjects:  44%|████▍     | 200/456 [05:28<07:40,  1.80s/it]predicting train subjects:  44%|████▍     | 201/456 [05:29<07:29,  1.76s/it]predicting train subjects:  44%|████▍     | 202/456 [05:31<07:17,  1.72s/it]predicting train subjects:  45%|████▍     | 203/456 [05:33<07:09,  1.70s/it]predicting train subjects:  45%|████▍     | 204/456 [05:34<07:04,  1.69s/it]predicting train subjects:  45%|████▍     | 205/456 [05:36<06:34,  1.57s/it]predicting train subjects:  45%|████▌     | 206/456 [05:37<06:14,  1.50s/it]predicting train subjects:  45%|████▌     | 207/456 [05:38<06:04,  1.46s/it]predicting train subjects:  46%|████▌     | 208/456 [05:40<05:55,  1.43s/it]predicting train subjects:  46%|████▌     | 209/456 [05:41<05:45,  1.40s/it]predicting train subjects:  46%|████▌     | 210/456 [05:42<05:39,  1.38s/it]predicting train subjects:  46%|████▋     | 211/456 [05:44<05:57,  1.46s/it]predicting train subjects:  46%|████▋     | 212/456 [05:46<06:09,  1.52s/it]predicting train subjects:  47%|████▋     | 213/456 [05:47<06:18,  1.56s/it]predicting train subjects:  47%|████▋     | 214/456 [05:49<06:24,  1.59s/it]predicting train subjects:  47%|████▋     | 215/456 [05:51<06:28,  1.61s/it]predicting train subjects:  47%|████▋     | 216/456 [05:52<06:29,  1.62s/it]predicting train subjects:  48%|████▊     | 217/456 [05:54<06:27,  1.62s/it]predicting train subjects:  48%|████▊     | 218/456 [05:56<06:29,  1.64s/it]predicting train subjects:  48%|████▊     | 219/456 [05:57<06:28,  1.64s/it]predicting train subjects:  48%|████▊     | 220/456 [05:59<06:28,  1.65s/it]predicting train subjects:  48%|████▊     | 221/456 [06:01<06:23,  1.63s/it]predicting train subjects:  49%|████▊     | 222/456 [06:02<06:20,  1.63s/it]predicting train subjects:  49%|████▉     | 223/456 [06:04<06:20,  1.63s/it]predicting train subjects:  49%|████▉     | 224/456 [06:05<06:17,  1.63s/it]predicting train subjects:  49%|████▉     | 225/456 [06:07<06:25,  1.67s/it]predicting train subjects:  50%|████▉     | 226/456 [06:09<06:24,  1.67s/it]predicting train subjects:  50%|████▉     | 227/456 [06:11<06:25,  1.68s/it]predicting train subjects:  50%|█████     | 228/456 [06:12<06:19,  1.67s/it]predicting train subjects:  50%|█████     | 229/456 [06:14<06:14,  1.65s/it]predicting train subjects:  50%|█████     | 230/456 [06:15<06:10,  1.64s/it]predicting train subjects:  51%|█████     | 231/456 [06:17<06:08,  1.64s/it]predicting train subjects:  51%|█████     | 232/456 [06:19<06:04,  1.63s/it]predicting train subjects:  51%|█████     | 233/456 [06:20<06:03,  1.63s/it]predicting train subjects:  51%|█████▏    | 234/456 [06:22<06:00,  1.62s/it]predicting train subjects:  52%|█████▏    | 235/456 [06:24<06:04,  1.65s/it]predicting train subjects:  52%|█████▏    | 236/456 [06:25<06:10,  1.68s/it]predicting train subjects:  52%|█████▏    | 237/456 [06:27<06:09,  1.69s/it]predicting train subjects:  52%|█████▏    | 238/456 [06:29<06:07,  1.69s/it]predicting train subjects:  52%|█████▏    | 239/456 [06:30<06:02,  1.67s/it]predicting train subjects:  53%|█████▎    | 240/456 [06:32<06:02,  1.68s/it]predicting train subjects:  53%|█████▎    | 241/456 [06:34<06:23,  1.78s/it]predicting train subjects:  53%|█████▎    | 242/456 [06:36<06:36,  1.85s/it]predicting train subjects:  53%|█████▎    | 243/456 [06:38<06:50,  1.93s/it]predicting train subjects:  54%|█████▎    | 244/456 [06:40<06:45,  1.91s/it]predicting train subjects:  54%|█████▎    | 245/456 [06:42<06:41,  1.90s/it]predicting train subjects:  54%|█████▍    | 246/456 [06:44<06:42,  1.92s/it]predicting train subjects:  54%|█████▍    | 247/456 [06:45<06:09,  1.77s/it]predicting train subjects:  54%|█████▍    | 248/456 [06:47<05:44,  1.65s/it]predicting train subjects:  55%|█████▍    | 249/456 [06:48<05:25,  1.57s/it]predicting train subjects:  55%|█████▍    | 250/456 [06:50<05:14,  1.53s/it]predicting train subjects:  55%|█████▌    | 251/456 [06:51<04:58,  1.46s/it]predicting train subjects:  55%|█████▌    | 252/456 [06:52<04:50,  1.43s/it]predicting train subjects:  55%|█████▌    | 253/456 [06:54<05:31,  1.63s/it]predicting train subjects:  56%|█████▌    | 254/456 [06:57<06:02,  1.79s/it]predicting train subjects:  56%|█████▌    | 255/456 [06:59<06:15,  1.87s/it]predicting train subjects:  56%|█████▌    | 256/456 [07:01<06:19,  1.90s/it]predicting train subjects:  56%|█████▋    | 257/456 [07:03<06:26,  1.94s/it]predicting train subjects:  57%|█████▋    | 258/456 [07:05<06:33,  1.99s/it]predicting train subjects:  57%|█████▋    | 259/456 [07:06<05:55,  1.81s/it]predicting train subjects:  57%|█████▋    | 260/456 [07:07<05:29,  1.68s/it]predicting train subjects:  57%|█████▋    | 261/456 [07:09<05:21,  1.65s/it]predicting train subjects:  57%|█████▋    | 262/456 [07:11<05:12,  1.61s/it]predicting train subjects:  58%|█████▊    | 263/456 [07:12<05:06,  1.59s/it]predicting train subjects:  58%|█████▊    | 264/456 [07:14<04:57,  1.55s/it]predicting train subjects:  58%|█████▊    | 265/456 [07:15<04:57,  1.56s/it]predicting train subjects:  58%|█████▊    | 266/456 [07:17<04:55,  1.55s/it]predicting train subjects:  59%|█████▊    | 267/456 [07:18<04:55,  1.56s/it]predicting train subjects:  59%|█████▉    | 268/456 [07:20<04:58,  1.59s/it]predicting train subjects:  59%|█████▉    | 269/456 [07:21<04:56,  1.58s/it]predicting train subjects:  59%|█████▉    | 270/456 [07:23<04:54,  1.58s/it]predicting train subjects:  59%|█████▉    | 271/456 [07:25<05:03,  1.64s/it]predicting train subjects:  60%|█████▉    | 272/456 [07:26<05:03,  1.65s/it]predicting train subjects:  60%|█████▉    | 273/456 [07:28<05:05,  1.67s/it]predicting train subjects:  60%|██████    | 274/456 [07:30<05:04,  1.67s/it]predicting train subjects:  60%|██████    | 275/456 [07:31<05:00,  1.66s/it]predicting train subjects:  61%|██████    | 276/456 [07:33<05:00,  1.67s/it]predicting train subjects:  61%|██████    | 277/456 [07:35<04:49,  1.62s/it]predicting train subjects:  61%|██████    | 278/456 [07:36<04:44,  1.60s/it]predicting train subjects:  61%|██████    | 279/456 [07:38<04:36,  1.56s/it]predicting train subjects:  61%|██████▏   | 280/456 [07:39<04:32,  1.55s/it]predicting train subjects:  62%|██████▏   | 281/456 [07:41<04:32,  1.56s/it]predicting train subjects:  62%|██████▏   | 282/456 [07:42<04:32,  1.57s/it]predicting train subjects:  62%|██████▏   | 283/456 [07:44<04:12,  1.46s/it]predicting train subjects:  62%|██████▏   | 284/456 [07:45<03:48,  1.33s/it]predicting train subjects:  62%|██████▎   | 285/456 [07:46<03:36,  1.27s/it]predicting train subjects:  63%|██████▎   | 286/456 [07:47<03:24,  1.21s/it]predicting train subjects:  63%|██████▎   | 287/456 [07:48<03:25,  1.22s/it]predicting train subjects:  63%|██████▎   | 288/456 [07:49<03:23,  1.21s/it]predicting train subjects:  63%|██████▎   | 289/456 [07:50<03:19,  1.19s/it]predicting train subjects:  64%|██████▎   | 290/456 [07:51<03:12,  1.16s/it]predicting train subjects:  64%|██████▍   | 291/456 [07:53<03:15,  1.18s/it]predicting train subjects:  64%|██████▍   | 292/456 [07:54<03:10,  1.16s/it]predicting train subjects:  64%|██████▍   | 293/456 [07:55<03:05,  1.14s/it]predicting train subjects:  64%|██████▍   | 294/456 [07:56<03:03,  1.13s/it]predicting train subjects:  65%|██████▍   | 295/456 [07:57<02:57,  1.10s/it]predicting train subjects:  65%|██████▍   | 296/456 [07:58<02:55,  1.10s/it]predicting train subjects:  65%|██████▌   | 297/456 [07:59<02:53,  1.09s/it]predicting train subjects:  65%|██████▌   | 298/456 [08:00<02:57,  1.12s/it]predicting train subjects:  66%|██████▌   | 299/456 [08:02<02:54,  1.11s/it]predicting train subjects:  66%|██████▌   | 300/456 [08:03<02:53,  1.11s/it]predicting train subjects:  66%|██████▌   | 301/456 [08:04<03:26,  1.33s/it]predicting train subjects:  66%|██████▌   | 302/456 [08:06<03:48,  1.48s/it]predicting train subjects:  66%|██████▋   | 303/456 [08:08<04:04,  1.60s/it]predicting train subjects:  67%|██████▋   | 304/456 [08:10<04:18,  1.70s/it]predicting train subjects:  67%|██████▋   | 305/456 [08:12<04:28,  1.78s/it]predicting train subjects:  67%|██████▋   | 306/456 [08:14<04:31,  1.81s/it]predicting train subjects:  67%|██████▋   | 307/456 [08:16<04:44,  1.91s/it]predicting train subjects:  68%|██████▊   | 308/456 [08:18<04:50,  1.96s/it]predicting train subjects:  68%|██████▊   | 309/456 [08:20<04:57,  2.02s/it]predicting train subjects:  68%|██████▊   | 310/456 [08:23<05:03,  2.08s/it]predicting train subjects:  68%|██████▊   | 311/456 [08:25<05:04,  2.10s/it]predicting train subjects:  68%|██████▊   | 312/456 [08:27<05:03,  2.11s/it]predicting train subjects:  69%|██████▊   | 313/456 [08:29<04:53,  2.05s/it]predicting train subjects:  69%|██████▉   | 314/456 [08:31<04:42,  1.99s/it]predicting train subjects:  69%|██████▉   | 315/456 [08:32<04:32,  1.93s/it]predicting train subjects:  69%|██████▉   | 316/456 [08:34<04:35,  1.96s/it]predicting train subjects:  70%|██████▉   | 317/456 [08:36<04:36,  1.99s/it]predicting train subjects:  70%|██████▉   | 318/456 [08:38<04:34,  1.99s/it]predicting train subjects:  70%|██████▉   | 319/456 [08:40<04:17,  1.88s/it]predicting train subjects:  70%|███████   | 320/456 [08:42<04:08,  1.83s/it]predicting train subjects:  70%|███████   | 321/456 [08:43<03:58,  1.76s/it]predicting train subjects:  71%|███████   | 322/456 [08:45<03:53,  1.74s/it]predicting train subjects:  71%|███████   | 323/456 [08:47<03:46,  1.70s/it]predicting train subjects:  71%|███████   | 324/456 [08:48<03:40,  1.67s/it]predicting train subjects:  71%|███████▏  | 325/456 [08:50<03:25,  1.57s/it]predicting train subjects:  71%|███████▏  | 326/456 [08:51<03:15,  1.50s/it]predicting train subjects:  72%|███████▏  | 327/456 [08:52<03:10,  1.48s/it]predicting train subjects:  72%|███████▏  | 328/456 [08:54<03:07,  1.46s/it]predicting train subjects:  72%|███████▏  | 329/456 [08:55<03:01,  1.43s/it]predicting train subjects:  72%|███████▏  | 330/456 [08:57<02:55,  1.39s/it]predicting train subjects:  73%|███████▎  | 331/456 [08:58<03:05,  1.48s/it]predicting train subjects:  73%|███████▎  | 332/456 [09:00<03:08,  1.52s/it]predicting train subjects:  73%|███████▎  | 333/456 [09:01<03:13,  1.57s/it]predicting train subjects:  73%|███████▎  | 334/456 [09:03<03:13,  1.58s/it]predicting train subjects:  73%|███████▎  | 335/456 [09:05<03:13,  1.60s/it]predicting train subjects:  74%|███████▎  | 336/456 [09:06<03:13,  1.62s/it]predicting train subjects:  74%|███████▍  | 337/456 [09:08<03:14,  1.63s/it]predicting train subjects:  74%|███████▍  | 338/456 [09:10<03:14,  1.65s/it]predicting train subjects:  74%|███████▍  | 339/456 [09:11<03:12,  1.65s/it]predicting train subjects:  75%|███████▍  | 340/456 [09:13<03:11,  1.65s/it]predicting train subjects:  75%|███████▍  | 341/456 [09:15<03:17,  1.71s/it]predicting train subjects:  75%|███████▌  | 342/456 [09:17<03:16,  1.73s/it]predicting train subjects:  75%|███████▌  | 343/456 [09:18<03:17,  1.74s/it]predicting train subjects:  75%|███████▌  | 344/456 [09:20<03:11,  1.71s/it]predicting train subjects:  76%|███████▌  | 345/456 [09:22<03:08,  1.70s/it]predicting train subjects:  76%|███████▌  | 346/456 [09:23<03:05,  1.68s/it]predicting train subjects:  76%|███████▌  | 347/456 [09:25<03:02,  1.68s/it]predicting train subjects:  76%|███████▋  | 348/456 [09:27<02:58,  1.65s/it]predicting train subjects:  77%|███████▋  | 349/456 [09:28<03:00,  1.68s/it]predicting train subjects:  77%|███████▋  | 350/456 [09:30<03:05,  1.75s/it]predicting train subjects:  77%|███████▋  | 351/456 [09:32<03:13,  1.84s/it]predicting train subjects:  77%|███████▋  | 352/456 [09:34<03:18,  1.91s/it]predicting train subjects:  77%|███████▋  | 353/456 [09:36<03:18,  1.93s/it]predicting train subjects:  78%|███████▊  | 354/456 [09:38<03:18,  1.94s/it]predicting train subjects:  78%|███████▊  | 355/456 [09:40<03:17,  1.96s/it]predicting train subjects:  78%|███████▊  | 356/456 [09:42<03:17,  1.97s/it]predicting train subjects:  78%|███████▊  | 357/456 [09:45<03:21,  2.04s/it]predicting train subjects:  79%|███████▊  | 358/456 [09:47<03:26,  2.11s/it]predicting train subjects:  79%|███████▊  | 359/456 [09:49<03:24,  2.11s/it]predicting train subjects:  79%|███████▉  | 360/456 [09:51<03:17,  2.05s/it]predicting train subjects:  79%|███████▉  | 361/456 [09:53<03:08,  1.98s/it]predicting train subjects:  79%|███████▉  | 362/456 [09:55<03:06,  1.98s/it]predicting train subjects:  80%|███████▉  | 363/456 [09:57<03:08,  2.03s/it]predicting train subjects:  80%|███████▉  | 364/456 [09:59<03:10,  2.07s/it]predicting train subjects:  80%|████████  | 365/456 [10:01<03:08,  2.07s/it]predicting train subjects:  80%|████████  | 366/456 [10:04<03:16,  2.18s/it]predicting train subjects:  80%|████████  | 367/456 [10:05<02:58,  2.00s/it]predicting train subjects:  81%|████████  | 368/456 [10:07<02:42,  1.85s/it]predicting train subjects:  81%|████████  | 369/456 [10:08<02:35,  1.79s/it]predicting train subjects:  81%|████████  | 370/456 [10:10<02:28,  1.73s/it]predicting train subjects:  81%|████████▏ | 371/456 [10:11<02:23,  1.68s/it]predicting train subjects:  82%|████████▏ | 372/456 [10:13<02:21,  1.68s/it]predicting train subjects:  82%|████████▏ | 373/456 [10:16<02:42,  1.96s/it]predicting train subjects:  82%|████████▏ | 374/456 [10:18<02:54,  2.13s/it]predicting train subjects:  82%|████████▏ | 375/456 [10:21<03:10,  2.35s/it]predicting train subjects:  82%|████████▏ | 376/456 [10:24<03:10,  2.38s/it]predicting train subjects:  83%|████████▎ | 377/456 [10:26<03:13,  2.45s/it]predicting train subjects:  83%|████████▎ | 378/456 [10:29<03:12,  2.46s/it]predicting train subjects:  83%|████████▎ | 379/456 [10:30<02:55,  2.28s/it]predicting train subjects:  83%|████████▎ | 380/456 [10:32<02:40,  2.12s/it]predicting train subjects:  84%|████████▎ | 381/456 [10:34<02:30,  2.00s/it]predicting train subjects:  84%|████████▍ | 382/456 [10:36<02:20,  1.90s/it]predicting train subjects:  84%|████████▍ | 383/456 [10:37<02:11,  1.80s/it]predicting train subjects:  84%|████████▍ | 384/456 [10:39<02:06,  1.75s/it]predicting train subjects:  84%|████████▍ | 385/456 [10:41<02:07,  1.80s/it]predicting train subjects:  85%|████████▍ | 386/456 [10:42<02:02,  1.76s/it]predicting train subjects:  85%|████████▍ | 387/456 [10:44<02:04,  1.81s/it]predicting train subjects:  85%|████████▌ | 388/456 [10:46<02:01,  1.79s/it]predicting train subjects:  85%|████████▌ | 389/456 [10:48<01:57,  1.76s/it]predicting train subjects:  86%|████████▌ | 390/456 [10:50<01:58,  1.79s/it]predicting train subjects:  86%|████████▌ | 391/456 [10:52<02:07,  1.96s/it]predicting train subjects:  86%|████████▌ | 392/456 [10:54<02:03,  1.93s/it]predicting train subjects:  86%|████████▌ | 393/456 [10:56<02:05,  1.99s/it]predicting train subjects:  86%|████████▋ | 394/456 [10:58<02:02,  1.98s/it]predicting train subjects:  87%|████████▋ | 395/456 [11:00<02:00,  1.97s/it]predicting train subjects:  87%|████████▋ | 396/456 [11:02<02:00,  2.01s/it]predicting train subjects:  87%|████████▋ | 397/456 [11:04<01:53,  1.93s/it]predicting train subjects:  87%|████████▋ | 398/456 [11:06<01:52,  1.94s/it]predicting train subjects:  88%|████████▊ | 399/456 [11:08<01:50,  1.94s/it]predicting train subjects:  88%|████████▊ | 400/456 [11:09<01:45,  1.89s/it]predicting train subjects:  88%|████████▊ | 401/456 [11:11<01:40,  1.83s/it]predicting train subjects:  88%|████████▊ | 402/456 [11:13<01:40,  1.86s/it]predicting train subjects:  88%|████████▊ | 403/456 [11:14<01:31,  1.73s/it]predicting train subjects:  89%|████████▊ | 404/456 [11:16<01:24,  1.62s/it]predicting train subjects:  89%|████████▉ | 405/456 [11:17<01:18,  1.53s/it]predicting train subjects:  89%|████████▉ | 406/456 [11:18<01:11,  1.43s/it]predicting train subjects:  89%|████████▉ | 407/456 [11:19<01:05,  1.34s/it]predicting train subjects:  89%|████████▉ | 408/456 [11:21<01:01,  1.29s/it]predicting train subjects:  90%|████████▉ | 409/456 [11:22<00:57,  1.22s/it]predicting train subjects:  90%|████████▉ | 410/456 [11:23<00:52,  1.15s/it]predicting train subjects:  90%|█████████ | 411/456 [11:24<00:50,  1.13s/it]predicting train subjects:  90%|█████████ | 412/456 [11:25<00:48,  1.11s/it]predicting train subjects:  91%|█████████ | 413/456 [11:26<00:46,  1.08s/it]predicting train subjects:  91%|█████████ | 414/456 [11:27<00:45,  1.08s/it]predicting train subjects:  91%|█████████ | 415/456 [11:28<00:43,  1.06s/it]predicting train subjects:  91%|█████████ | 416/456 [11:29<00:42,  1.05s/it]predicting train subjects:  91%|█████████▏| 417/456 [11:30<00:40,  1.05s/it]predicting train subjects:  92%|█████████▏| 418/456 [11:31<00:39,  1.04s/it]predicting train subjects:  92%|█████████▏| 419/456 [11:32<00:38,  1.04s/it]predicting train subjects:  92%|█████████▏| 420/456 [11:33<00:37,  1.03s/it]predicting train subjects:  92%|█████████▏| 421/456 [11:35<00:44,  1.26s/it]predicting train subjects:  93%|█████████▎| 422/456 [11:37<00:48,  1.42s/it]predicting train subjects:  93%|█████████▎| 423/456 [11:38<00:50,  1.52s/it]predicting train subjects:  93%|█████████▎| 424/456 [11:40<00:50,  1.59s/it]predicting train subjects:  93%|█████████▎| 425/456 [11:42<00:50,  1.64s/it]predicting train subjects:  93%|█████████▎| 426/456 [11:44<00:50,  1.69s/it]predicting train subjects:  94%|█████████▎| 427/456 [11:46<00:52,  1.79s/it]predicting train subjects:  94%|█████████▍| 428/456 [11:48<00:51,  1.84s/it]predicting train subjects:  94%|█████████▍| 429/456 [11:50<00:50,  1.89s/it]predicting train subjects:  94%|█████████▍| 430/456 [11:52<00:49,  1.92s/it]predicting train subjects:  95%|█████████▍| 431/456 [11:54<00:48,  1.93s/it]predicting train subjects:  95%|█████████▍| 432/456 [11:56<00:46,  1.95s/it]predicting train subjects:  95%|█████████▍| 433/456 [11:58<00:45,  1.96s/it]predicting train subjects:  95%|█████████▌| 434/456 [11:59<00:42,  1.92s/it]predicting train subjects:  95%|█████████▌| 435/456 [12:01<00:39,  1.88s/it]predicting train subjects:  96%|█████████▌| 436/456 [12:03<00:38,  1.92s/it]predicting train subjects:  96%|█████████▌| 437/456 [12:05<00:36,  1.90s/it]predicting train subjects:  96%|█████████▌| 438/456 [12:07<00:34,  1.91s/it]predicting train subjects:  96%|█████████▋| 439/456 [12:09<00:30,  1.81s/it]predicting train subjects:  96%|█████████▋| 440/456 [12:10<00:28,  1.76s/it]predicting train subjects:  97%|█████████▋| 441/456 [12:12<00:25,  1.70s/it]predicting train subjects:  97%|█████████▋| 442/456 [12:13<00:23,  1.67s/it]predicting train subjects:  97%|█████████▋| 443/456 [12:15<00:21,  1.64s/it]predicting train subjects:  97%|█████████▋| 444/456 [12:17<00:19,  1.63s/it]predicting train subjects:  98%|█████████▊| 445/456 [12:18<00:16,  1.54s/it]predicting train subjects:  98%|█████████▊| 446/456 [12:19<00:14,  1.49s/it]predicting train subjects:  98%|█████████▊| 447/456 [12:21<00:12,  1.43s/it]predicting train subjects:  98%|█████████▊| 448/456 [12:22<00:11,  1.41s/it]predicting train subjects:  98%|█████████▊| 449/456 [12:23<00:09,  1.40s/it]predicting train subjects:  99%|█████████▊| 450/456 [12:25<00:08,  1.36s/it]predicting train subjects:  99%|█████████▉| 451/456 [12:26<00:07,  1.44s/it]predicting train subjects:  99%|█████████▉| 452/456 [12:28<00:06,  1.51s/it]predicting train subjects:  99%|█████████▉| 453/456 [12:30<00:04,  1.54s/it]predicting train subjects: 100%|█████████▉| 454/456 [12:31<00:03,  1.58s/it]predicting train subjects: 100%|█████████▉| 455/456 [12:33<00:01,  1.63s/it]predicting train subjects: 100%|██████████| 456/456 [12:35<00:00,  1.64s/it]
Loading train:   0%|          | 0/456 [00:00<?, ?it/s]Loading train:   0%|          | 1/456 [00:01<08:40,  1.14s/it]Loading train:   0%|          | 2/456 [00:02<08:30,  1.12s/it]Loading train:   1%|          | 3/456 [00:03<08:23,  1.11s/it]Loading train:   1%|          | 4/456 [00:04<08:06,  1.08s/it]Loading train:   1%|          | 5/456 [00:05<08:36,  1.15s/it]Loading train:   1%|▏         | 6/456 [00:06<08:10,  1.09s/it]Loading train:   2%|▏         | 7/456 [00:07<07:45,  1.04s/it]Loading train:   2%|▏         | 8/456 [00:08<06:47,  1.10it/s]Loading train:   2%|▏         | 9/456 [00:09<07:23,  1.01it/s]Loading train:   2%|▏         | 10/456 [00:10<07:28,  1.01s/it]Loading train:   2%|▏         | 11/456 [00:11<07:39,  1.03s/it]Loading train:   3%|▎         | 12/456 [00:11<06:34,  1.12it/s]Loading train:   3%|▎         | 13/456 [00:12<06:46,  1.09it/s]Loading train:   3%|▎         | 14/456 [00:13<06:55,  1.06it/s]Loading train:   3%|▎         | 15/456 [00:14<06:16,  1.17it/s]Loading train:   4%|▎         | 16/456 [00:15<06:42,  1.09it/s]Loading train:   4%|▎         | 17/456 [00:16<07:34,  1.03s/it]Loading train:   4%|▍         | 18/456 [00:17<07:31,  1.03s/it]Loading train:   4%|▍         | 19/456 [00:19<07:34,  1.04s/it]Loading train:   4%|▍         | 20/456 [00:20<07:35,  1.04s/it]Loading train:   5%|▍         | 21/456 [00:21<08:09,  1.13s/it]Loading train:   5%|▍         | 22/456 [00:22<08:09,  1.13s/it]Loading train:   5%|▌         | 23/456 [00:23<08:13,  1.14s/it]Loading train:   5%|▌         | 24/456 [00:24<06:53,  1.04it/s]Loading train:   5%|▌         | 25/456 [00:25<06:52,  1.04it/s]Loading train:   6%|▌         | 26/456 [00:26<07:10,  1.00s/it]Loading train:   6%|▌         | 27/456 [00:27<07:22,  1.03s/it]Loading train:   6%|▌         | 28/456 [00:28<07:33,  1.06s/it]Loading train:   6%|▋         | 29/456 [00:29<07:16,  1.02s/it]Loading train:   7%|▋         | 30/456 [00:30<07:39,  1.08s/it]Loading train:   7%|▋         | 31/456 [00:31<07:31,  1.06s/it]Loading train:   7%|▋         | 32/456 [00:32<07:28,  1.06s/it]Loading train:   7%|▋         | 33/456 [00:33<07:17,  1.03s/it]Loading train:   7%|▋         | 34/456 [00:34<07:04,  1.01s/it]Loading train:   8%|▊         | 35/456 [00:35<07:07,  1.01s/it]Loading train:   8%|▊         | 36/456 [00:36<07:08,  1.02s/it]Loading train:   8%|▊         | 37/456 [00:37<06:59,  1.00s/it]Loading train:   8%|▊         | 38/456 [00:38<06:55,  1.01it/s]Loading train:   9%|▊         | 39/456 [00:39<06:58,  1.00s/it]Loading train:   9%|▉         | 40/456 [00:40<07:07,  1.03s/it]Loading train:   9%|▉         | 41/456 [00:41<07:02,  1.02s/it]Loading train:   9%|▉         | 42/456 [00:42<06:50,  1.01it/s]Loading train:   9%|▉         | 43/456 [00:43<06:54,  1.00s/it]Loading train:  10%|▉         | 44/456 [00:44<06:46,  1.01it/s]Loading train:  10%|▉         | 45/456 [00:45<06:37,  1.03it/s]Loading train:  10%|█         | 46/456 [00:46<06:47,  1.01it/s]Loading train:  10%|█         | 47/456 [00:47<06:34,  1.04it/s]Loading train:  11%|█         | 48/456 [00:48<06:23,  1.06it/s]Loading train:  11%|█         | 49/456 [00:49<06:20,  1.07it/s]Loading train:  11%|█         | 50/456 [00:50<07:12,  1.07s/it]Loading train:  11%|█         | 51/456 [00:51<07:14,  1.07s/it]Loading train:  11%|█▏        | 52/456 [00:53<07:52,  1.17s/it]Loading train:  12%|█▏        | 53/456 [00:54<08:01,  1.19s/it]Loading train:  12%|█▏        | 54/456 [00:55<08:34,  1.28s/it]Loading train:  12%|█▏        | 55/456 [00:57<08:56,  1.34s/it]Loading train:  12%|█▏        | 56/456 [00:58<08:39,  1.30s/it]Loading train:  12%|█▎        | 57/456 [01:00<09:02,  1.36s/it]Loading train:  13%|█▎        | 58/456 [01:01<08:31,  1.29s/it]Loading train:  13%|█▎        | 59/456 [01:02<08:24,  1.27s/it]Loading train:  13%|█▎        | 60/456 [01:03<08:09,  1.24s/it]Loading train:  13%|█▎        | 61/456 [01:04<08:01,  1.22s/it]Loading train:  14%|█▎        | 62/456 [01:05<07:45,  1.18s/it]Loading train:  14%|█▍        | 63/456 [01:07<07:47,  1.19s/it]Loading train:  14%|█▍        | 64/456 [01:08<07:33,  1.16s/it]Loading train:  14%|█▍        | 65/456 [01:09<07:12,  1.11s/it]Loading train:  14%|█▍        | 66/456 [01:10<07:03,  1.08s/it]Loading train:  15%|█▍        | 67/456 [01:11<07:23,  1.14s/it]Loading train:  15%|█▍        | 68/456 [01:12<07:11,  1.11s/it]Loading train:  15%|█▌        | 69/456 [01:13<07:19,  1.14s/it]Loading train:  15%|█▌        | 70/456 [01:14<07:04,  1.10s/it]Loading train:  16%|█▌        | 71/456 [01:15<07:08,  1.11s/it]Loading train:  16%|█▌        | 72/456 [01:16<06:56,  1.08s/it]Loading train:  16%|█▌        | 73/456 [01:17<06:44,  1.06s/it]Loading train:  16%|█▌        | 74/456 [01:18<06:48,  1.07s/it]Loading train:  16%|█▋        | 75/456 [01:19<06:33,  1.03s/it]Loading train:  17%|█▋        | 76/456 [01:20<06:27,  1.02s/it]Loading train:  17%|█▋        | 77/456 [01:21<06:16,  1.01it/s]Loading train:  17%|█▋        | 78/456 [01:22<06:13,  1.01it/s]Loading train:  17%|█▋        | 79/456 [01:23<05:33,  1.13it/s]Loading train:  18%|█▊        | 80/456 [01:24<05:07,  1.22it/s]Loading train:  18%|█▊        | 81/456 [01:24<04:43,  1.32it/s]Loading train:  18%|█▊        | 82/456 [01:25<04:17,  1.45it/s]Loading train:  18%|█▊        | 83/456 [01:25<03:54,  1.59it/s]Loading train:  18%|█▊        | 84/456 [01:26<03:39,  1.69it/s]Loading train:  19%|█▊        | 85/456 [01:26<03:38,  1.70it/s]Loading train:  19%|█▉        | 86/456 [01:27<03:35,  1.71it/s]Loading train:  19%|█▉        | 87/456 [01:27<03:29,  1.76it/s]Loading train:  19%|█▉        | 88/456 [01:28<03:17,  1.86it/s]Loading train:  20%|█▉        | 89/456 [01:28<03:11,  1.92it/s]Loading train:  20%|█▉        | 90/456 [01:29<03:08,  1.94it/s]Loading train:  20%|█▉        | 91/456 [01:29<03:13,  1.88it/s]Loading train:  20%|██        | 92/456 [01:30<03:22,  1.80it/s]Loading train:  20%|██        | 93/456 [01:31<03:19,  1.82it/s]Loading train:  21%|██        | 94/456 [01:31<03:14,  1.86it/s]Loading train:  21%|██        | 95/456 [01:32<03:14,  1.86it/s]Loading train:  21%|██        | 96/456 [01:32<03:07,  1.92it/s]Loading train:  21%|██▏       | 97/456 [01:33<03:47,  1.57it/s]Loading train:  21%|██▏       | 98/456 [01:34<04:10,  1.43it/s]Loading train:  22%|██▏       | 99/456 [01:35<04:40,  1.27it/s]Loading train:  22%|██▏       | 100/456 [01:36<04:53,  1.21it/s]Loading train:  22%|██▏       | 101/456 [01:37<05:03,  1.17it/s]Loading train:  22%|██▏       | 102/456 [01:38<05:12,  1.13it/s]Loading train:  23%|██▎       | 103/456 [01:39<05:36,  1.05it/s]Loading train:  23%|██▎       | 104/456 [01:40<05:56,  1.01s/it]Loading train:  23%|██▎       | 105/456 [01:41<05:58,  1.02s/it]Loading train:  23%|██▎       | 106/456 [01:42<05:58,  1.02s/it]Loading train:  23%|██▎       | 107/456 [01:43<06:03,  1.04s/it]Loading train:  24%|██▎       | 108/456 [01:44<05:54,  1.02s/it]Loading train:  24%|██▍       | 109/456 [01:45<05:45,  1.01it/s]Loading train:  24%|██▍       | 110/456 [01:46<05:43,  1.01it/s]Loading train:  24%|██▍       | 111/456 [01:47<05:36,  1.02it/s]Loading train:  25%|██▍       | 112/456 [01:48<05:29,  1.04it/s]Loading train:  25%|██▍       | 113/456 [01:49<05:30,  1.04it/s]Loading train:  25%|██▌       | 114/456 [01:50<05:24,  1.05it/s]Loading train:  25%|██▌       | 115/456 [01:51<05:25,  1.05it/s]Loading train:  25%|██▌       | 116/456 [01:52<05:32,  1.02it/s]Loading train:  26%|██▌       | 117/456 [01:53<05:36,  1.01it/s]Loading train:  26%|██▌       | 118/456 [01:54<05:33,  1.01it/s]Loading train:  26%|██▌       | 119/456 [01:55<05:32,  1.01it/s]Loading train:  26%|██▋       | 120/456 [01:56<05:49,  1.04s/it]Loading train:  27%|██▋       | 121/456 [01:57<05:54,  1.06s/it]Loading train:  27%|██▋       | 122/456 [01:58<05:59,  1.08s/it]Loading train:  27%|██▋       | 123/456 [01:59<05:57,  1.07s/it]Loading train:  27%|██▋       | 124/456 [02:00<05:53,  1.07s/it]Loading train:  27%|██▋       | 125/456 [02:01<05:55,  1.07s/it]Loading train:  28%|██▊       | 126/456 [02:02<05:56,  1.08s/it]Loading train:  28%|██▊       | 127/456 [02:03<05:40,  1.04s/it]Loading train:  28%|██▊       | 128/456 [02:04<05:29,  1.00s/it]Loading train:  28%|██▊       | 129/456 [02:05<05:17,  1.03it/s]Loading train:  29%|██▊       | 130/456 [02:06<05:15,  1.03it/s]Loading train:  29%|██▊       | 131/456 [02:07<05:06,  1.06it/s]Loading train:  29%|██▉       | 132/456 [02:08<04:50,  1.11it/s]Loading train:  29%|██▉       | 133/456 [02:09<05:27,  1.01s/it]Loading train:  29%|██▉       | 134/456 [02:10<05:51,  1.09s/it]Loading train:  30%|██▉       | 135/456 [02:12<06:03,  1.13s/it]Loading train:  30%|██▉       | 136/456 [02:13<06:57,  1.31s/it]Loading train:  30%|███       | 137/456 [02:15<07:02,  1.32s/it]Loading train:  30%|███       | 138/456 [02:17<08:01,  1.51s/it]Loading train:  30%|███       | 139/456 [02:18<07:44,  1.47s/it]Loading train:  31%|███       | 140/456 [02:19<06:53,  1.31s/it]Loading train:  31%|███       | 141/456 [02:20<07:00,  1.33s/it]Loading train:  31%|███       | 142/456 [02:22<07:04,  1.35s/it]Loading train:  31%|███▏      | 143/456 [02:23<07:21,  1.41s/it]Loading train:  32%|███▏      | 144/456 [02:25<07:16,  1.40s/it]Loading train:  32%|███▏      | 145/456 [02:26<06:59,  1.35s/it]Loading train:  32%|███▏      | 146/456 [02:27<06:42,  1.30s/it]Loading train:  32%|███▏      | 147/456 [02:28<06:01,  1.17s/it]Loading train:  32%|███▏      | 148/456 [02:29<05:35,  1.09s/it]Loading train:  33%|███▎      | 149/456 [02:30<05:21,  1.05s/it]Loading train:  33%|███▎      | 150/456 [02:31<05:12,  1.02s/it]Loading train:  33%|███▎      | 151/456 [02:32<05:09,  1.02s/it]Loading train:  33%|███▎      | 152/456 [02:33<05:05,  1.00s/it]Loading train:  34%|███▎      | 153/456 [02:34<05:23,  1.07s/it]Loading train:  34%|███▍      | 154/456 [02:35<05:22,  1.07s/it]Loading train:  34%|███▍      | 155/456 [02:36<05:19,  1.06s/it]Loading train:  34%|███▍      | 156/456 [02:37<05:11,  1.04s/it]Loading train:  34%|███▍      | 157/456 [02:38<05:08,  1.03s/it]Loading train:  35%|███▍      | 158/456 [02:39<05:03,  1.02s/it]Loading train:  35%|███▍      | 159/456 [02:40<05:22,  1.08s/it]Loading train:  35%|███▌      | 160/456 [02:41<05:05,  1.03s/it]Loading train:  35%|███▌      | 161/456 [02:42<04:52,  1.01it/s]Loading train:  36%|███▌      | 162/456 [02:43<04:42,  1.04it/s]Loading train:  36%|███▌      | 163/456 [02:44<04:24,  1.11it/s]Loading train:  36%|███▌      | 164/456 [02:44<04:04,  1.20it/s]Loading train:  36%|███▌      | 165/456 [02:45<03:42,  1.31it/s]Loading train:  36%|███▋      | 166/456 [02:46<03:28,  1.39it/s]Loading train:  37%|███▋      | 167/456 [02:46<03:14,  1.48it/s]Loading train:  37%|███▋      | 168/456 [02:47<03:11,  1.50it/s]Loading train:  37%|███▋      | 169/456 [02:47<03:07,  1.53it/s]Loading train:  37%|███▋      | 170/456 [02:48<02:58,  1.60it/s]Loading train:  38%|███▊      | 171/456 [02:49<02:54,  1.63it/s]Loading train:  38%|███▊      | 172/456 [02:49<02:47,  1.70it/s]Loading train:  38%|███▊      | 173/456 [02:50<02:42,  1.74it/s]Loading train:  38%|███▊      | 174/456 [02:50<02:38,  1.77it/s]Loading train:  38%|███▊      | 175/456 [02:51<02:35,  1.81it/s]Loading train:  39%|███▊      | 176/456 [02:51<02:27,  1.90it/s]Loading train:  39%|███▉      | 177/456 [02:52<02:25,  1.92it/s]Loading train:  39%|███▉      | 178/456 [02:52<02:29,  1.86it/s]Loading train:  39%|███▉      | 179/456 [02:53<02:25,  1.90it/s]Loading train:  39%|███▉      | 180/456 [02:53<02:25,  1.90it/s]Loading train:  40%|███▉      | 181/456 [02:54<03:09,  1.45it/s]Loading train:  40%|███▉      | 182/456 [02:56<03:48,  1.20it/s]Loading train:  40%|████      | 183/456 [02:57<04:03,  1.12it/s]Loading train:  40%|████      | 184/456 [02:58<04:11,  1.08it/s]Loading train:  41%|████      | 185/456 [02:59<04:15,  1.06it/s]Loading train:  41%|████      | 186/456 [03:00<04:24,  1.02it/s]Loading train:  41%|████      | 187/456 [03:01<04:49,  1.08s/it]Loading train:  41%|████      | 188/456 [03:02<05:07,  1.15s/it]Loading train:  41%|████▏     | 189/456 [03:03<05:11,  1.17s/it]Loading train:  42%|████▏     | 190/456 [03:05<05:20,  1.20s/it]Loading train:  42%|████▏     | 191/456 [03:06<05:18,  1.20s/it]Loading train:  42%|████▏     | 192/456 [03:07<05:29,  1.25s/it]Loading train:  42%|████▏     | 193/456 [03:08<05:16,  1.20s/it]Loading train:  43%|████▎     | 194/456 [03:10<05:08,  1.18s/it]Loading train:  43%|████▎     | 195/456 [03:11<05:01,  1.16s/it]Loading train:  43%|████▎     | 196/456 [03:12<04:52,  1.12s/it]Loading train:  43%|████▎     | 197/456 [03:13<04:46,  1.10s/it]Loading train:  43%|████▎     | 198/456 [03:14<04:38,  1.08s/it]Loading train:  44%|████▎     | 199/456 [03:15<04:56,  1.15s/it]Loading train:  44%|████▍     | 200/456 [03:17<05:39,  1.33s/it]Loading train:  44%|████▍     | 201/456 [03:18<05:48,  1.37s/it]Loading train:  44%|████▍     | 202/456 [03:20<05:54,  1.40s/it]Loading train:  45%|████▍     | 203/456 [03:21<05:52,  1.39s/it]Loading train:  45%|████▍     | 204/456 [03:23<05:56,  1.41s/it]Loading train:  45%|████▍     | 205/456 [03:24<05:55,  1.42s/it]Loading train:  45%|████▌     | 206/456 [03:25<05:47,  1.39s/it]Loading train:  45%|████▌     | 207/456 [03:26<05:12,  1.25s/it]Loading train:  46%|████▌     | 208/456 [03:27<05:07,  1.24s/it]Loading train:  46%|████▌     | 209/456 [03:29<05:18,  1.29s/it]Loading train:  46%|████▌     | 210/456 [03:30<04:47,  1.17s/it]Loading train:  46%|████▋     | 211/456 [03:31<04:36,  1.13s/it]Loading train:  46%|████▋     | 212/456 [03:32<04:24,  1.08s/it]Loading train:  47%|████▋     | 213/456 [03:33<04:11,  1.03s/it]Loading train:  47%|████▋     | 214/456 [03:34<04:03,  1.01s/it]Loading train:  47%|████▋     | 215/456 [03:35<03:57,  1.01it/s]Loading train:  47%|████▋     | 216/456 [03:36<03:53,  1.03it/s]Loading train:  48%|████▊     | 217/456 [03:37<04:16,  1.07s/it]Loading train:  48%|████▊     | 218/456 [03:38<04:11,  1.06s/it]Loading train:  48%|████▊     | 219/456 [03:39<04:04,  1.03s/it]Loading train:  48%|████▊     | 220/456 [03:40<03:54,  1.01it/s]Loading train:  48%|████▊     | 221/456 [03:41<03:51,  1.02it/s]Loading train:  49%|████▊     | 222/456 [03:42<03:56,  1.01s/it]Loading train:  49%|████▉     | 223/456 [03:43<04:00,  1.03s/it]Loading train:  49%|████▉     | 224/456 [03:44<03:55,  1.02s/it]Loading train:  49%|████▉     | 225/456 [03:45<03:52,  1.00s/it]Loading train:  50%|████▉     | 226/456 [03:46<03:48,  1.01it/s]Loading train:  50%|████▉     | 227/456 [03:47<03:46,  1.01it/s]Loading train:  50%|█████     | 228/456 [03:48<03:45,  1.01it/s]Loading train:  50%|█████     | 229/456 [03:49<03:55,  1.04s/it]Loading train:  50%|█████     | 230/456 [03:50<03:55,  1.04s/it]Loading train:  51%|█████     | 231/456 [03:51<03:52,  1.04s/it]Loading train:  51%|█████     | 232/456 [03:52<03:52,  1.04s/it]Loading train:  51%|█████     | 233/456 [03:53<03:50,  1.04s/it]Loading train:  51%|█████▏    | 234/456 [03:54<03:45,  1.02s/it]Loading train:  52%|█████▏    | 235/456 [03:55<03:49,  1.04s/it]Loading train:  52%|█████▏    | 236/456 [03:56<03:42,  1.01s/it]Loading train:  52%|█████▏    | 237/456 [03:57<03:31,  1.04it/s]Loading train:  52%|█████▏    | 238/456 [03:58<03:23,  1.07it/s]Loading train:  52%|█████▏    | 239/456 [03:59<03:32,  1.02it/s]Loading train:  53%|█████▎    | 240/456 [04:00<03:26,  1.04it/s]Loading train:  53%|█████▎    | 241/456 [04:01<03:24,  1.05it/s]Loading train:  53%|█████▎    | 242/456 [04:02<03:21,  1.06it/s]Loading train:  53%|█████▎    | 243/456 [04:03<03:29,  1.02it/s]Loading train:  54%|█████▎    | 244/456 [04:04<03:28,  1.02it/s]Loading train:  54%|█████▎    | 245/456 [04:05<03:23,  1.04it/s]Loading train:  54%|█████▍    | 246/456 [04:06<03:23,  1.03it/s]Loading train:  54%|█████▍    | 247/456 [04:06<03:12,  1.09it/s]Loading train:  54%|█████▍    | 248/456 [04:07<03:07,  1.11it/s]Loading train:  55%|█████▍    | 249/456 [04:08<02:59,  1.15it/s]Loading train:  55%|█████▍    | 250/456 [04:09<02:57,  1.16it/s]Loading train:  55%|█████▌    | 251/456 [04:10<02:55,  1.17it/s]Loading train:  55%|█████▌    | 252/456 [04:11<02:52,  1.19it/s]Loading train:  55%|█████▌    | 253/456 [04:12<03:20,  1.01it/s]Loading train:  56%|█████▌    | 254/456 [04:13<03:43,  1.11s/it]Loading train:  56%|█████▌    | 255/456 [04:15<03:54,  1.16s/it]Loading train:  56%|█████▌    | 256/456 [04:16<04:05,  1.23s/it]Loading train:  56%|█████▋    | 257/456 [04:17<04:12,  1.27s/it]Loading train:  57%|█████▋    | 258/456 [04:19<04:07,  1.25s/it]Loading train:  57%|█████▋    | 259/456 [04:19<03:45,  1.14s/it]Loading train:  57%|█████▋    | 260/456 [04:20<03:30,  1.07s/it]Loading train:  57%|█████▋    | 261/456 [04:22<03:38,  1.12s/it]Loading train:  57%|█████▋    | 262/456 [04:23<03:35,  1.11s/it]Loading train:  58%|█████▊    | 263/456 [04:24<03:22,  1.05s/it]Loading train:  58%|█████▊    | 264/456 [04:25<03:16,  1.02s/it]Loading train:  58%|█████▊    | 265/456 [04:26<03:14,  1.02s/it]Loading train:  58%|█████▊    | 266/456 [04:26<03:06,  1.02it/s]Loading train:  59%|█████▊    | 267/456 [04:27<03:01,  1.04it/s]Loading train:  59%|█████▉    | 268/456 [04:28<02:57,  1.06it/s]Loading train:  59%|█████▉    | 269/456 [04:29<03:08,  1.01s/it]Loading train:  59%|█████▉    | 270/456 [04:30<03:07,  1.01s/it]Loading train:  59%|█████▉    | 271/456 [04:31<03:04,  1.00it/s]Loading train:  60%|█████▉    | 272/456 [04:33<03:13,  1.05s/it]Loading train:  60%|█████▉    | 273/456 [04:34<03:09,  1.04s/it]Loading train:  60%|██████    | 274/456 [04:35<03:15,  1.07s/it]Loading train:  60%|██████    | 275/456 [04:36<03:02,  1.01s/it]Loading train:  61%|██████    | 276/456 [04:37<02:59,  1.00it/s]Loading train:  61%|██████    | 277/456 [04:37<02:54,  1.02it/s]Loading train:  61%|██████    | 278/456 [04:39<03:01,  1.02s/it]Loading train:  61%|██████    | 279/456 [04:40<02:58,  1.01s/it]Loading train:  61%|██████▏   | 280/456 [04:41<03:00,  1.03s/it]Loading train:  62%|██████▏   | 281/456 [04:42<02:58,  1.02s/it]Loading train:  62%|██████▏   | 282/456 [04:43<02:52,  1.01it/s]Loading train:  62%|██████▏   | 283/456 [04:43<02:38,  1.09it/s]Loading train:  62%|██████▏   | 284/456 [04:44<02:22,  1.20it/s]Loading train:  62%|██████▎   | 285/456 [04:45<02:14,  1.27it/s]Loading train:  63%|██████▎   | 286/456 [04:45<02:09,  1.31it/s]Loading train:  63%|██████▎   | 287/456 [04:46<02:04,  1.36it/s]Loading train:  63%|██████▎   | 288/456 [04:47<01:53,  1.48it/s]Loading train:  63%|██████▎   | 289/456 [04:47<01:49,  1.53it/s]Loading train:  64%|██████▎   | 290/456 [04:48<01:50,  1.51it/s]Loading train:  64%|██████▍   | 291/456 [04:48<01:49,  1.51it/s]Loading train:  64%|██████▍   | 292/456 [04:49<01:48,  1.51it/s]Loading train:  64%|██████▍   | 293/456 [04:50<01:50,  1.47it/s]Loading train:  64%|██████▍   | 294/456 [04:50<01:45,  1.53it/s]Loading train:  65%|██████▍   | 295/456 [04:51<01:39,  1.62it/s]Loading train:  65%|██████▍   | 296/456 [04:52<01:40,  1.59it/s]Loading train:  65%|██████▌   | 297/456 [04:52<01:40,  1.59it/s]Loading train:  65%|██████▌   | 298/456 [04:53<01:37,  1.63it/s]Loading train:  66%|██████▌   | 299/456 [04:53<01:34,  1.66it/s]Loading train:  66%|██████▌   | 300/456 [04:54<01:33,  1.68it/s]Loading train:  66%|██████▌   | 301/456 [04:55<02:02,  1.26it/s]Loading train:  66%|██████▌   | 302/456 [04:56<02:15,  1.14it/s]Loading train:  66%|██████▋   | 303/456 [04:58<02:36,  1.02s/it]Loading train:  67%|██████▋   | 304/456 [04:59<02:44,  1.08s/it]Loading train:  67%|██████▋   | 305/456 [05:00<02:43,  1.08s/it]Loading train:  67%|██████▋   | 306/456 [05:01<02:45,  1.10s/it]Loading train:  67%|██████▋   | 307/456 [05:03<02:59,  1.20s/it]Loading train:  68%|██████▊   | 308/456 [05:04<03:01,  1.23s/it]Loading train:  68%|██████▊   | 309/456 [05:05<03:01,  1.24s/it]Loading train:  68%|██████▊   | 310/456 [05:06<03:03,  1.25s/it]Loading train:  68%|██████▊   | 311/456 [05:08<02:57,  1.22s/it]Loading train:  68%|██████▊   | 312/456 [05:09<02:52,  1.20s/it]Loading train:  69%|██████▊   | 313/456 [05:10<02:58,  1.25s/it]Loading train:  69%|██████▉   | 314/456 [05:11<02:53,  1.22s/it]Loading train:  69%|██████▉   | 315/456 [05:12<02:49,  1.20s/it]Loading train:  69%|██████▉   | 316/456 [05:14<02:50,  1.22s/it]Loading train:  70%|██████▉   | 317/456 [05:15<02:45,  1.19s/it]Loading train:  70%|██████▉   | 318/456 [05:16<02:46,  1.21s/it]Loading train:  70%|██████▉   | 319/456 [05:17<02:49,  1.24s/it]Loading train:  70%|███████   | 320/456 [05:18<02:39,  1.17s/it]Loading train:  70%|███████   | 321/456 [05:20<02:40,  1.19s/it]Loading train:  71%|███████   | 322/456 [05:21<02:30,  1.12s/it]Loading train:  71%|███████   | 323/456 [05:22<02:25,  1.09s/it]Loading train:  71%|███████   | 324/456 [05:23<02:20,  1.06s/it]Loading train:  71%|███████▏  | 325/456 [05:23<02:12,  1.01s/it]Loading train:  71%|███████▏  | 326/456 [05:25<02:29,  1.15s/it]Loading train:  72%|███████▏  | 327/456 [05:26<02:35,  1.21s/it]Loading train:  72%|███████▏  | 328/456 [05:27<02:26,  1.15s/it]Loading train:  72%|███████▏  | 329/456 [05:28<02:22,  1.12s/it]Loading train:  72%|███████▏  | 330/456 [05:30<02:35,  1.24s/it]Loading train:  73%|███████▎  | 331/456 [05:31<02:42,  1.30s/it]Loading train:  73%|███████▎  | 332/456 [05:33<02:56,  1.42s/it]Loading train:  73%|███████▎  | 333/456 [05:35<03:04,  1.50s/it]Loading train:  73%|███████▎  | 334/456 [05:36<03:08,  1.54s/it]Loading train:  73%|███████▎  | 335/456 [05:38<02:59,  1.48s/it]Loading train:  74%|███████▎  | 336/456 [05:39<02:41,  1.35s/it]Loading train:  74%|███████▍  | 337/456 [05:40<02:29,  1.26s/it]Loading train:  74%|███████▍  | 338/456 [05:41<02:21,  1.20s/it]Loading train:  74%|███████▍  | 339/456 [05:42<02:16,  1.16s/it]Loading train:  75%|███████▍  | 340/456 [05:43<02:10,  1.12s/it]Loading train:  75%|███████▍  | 341/456 [05:44<02:07,  1.11s/it]Loading train:  75%|███████▌  | 342/456 [05:45<02:04,  1.10s/it]Loading train:  75%|███████▌  | 343/456 [05:46<02:07,  1.12s/it]Loading train:  75%|███████▌  | 344/456 [05:47<02:01,  1.09s/it]Loading train:  76%|███████▌  | 345/456 [05:49<02:09,  1.17s/it]Loading train:  76%|███████▌  | 346/456 [05:50<02:02,  1.12s/it]Loading train:  76%|███████▌  | 347/456 [05:51<02:00,  1.11s/it]Loading train:  76%|███████▋  | 348/456 [05:52<01:58,  1.10s/it]Loading train:  77%|███████▋  | 349/456 [05:53<01:55,  1.08s/it]Loading train:  77%|███████▋  | 350/456 [05:54<01:58,  1.12s/it]Loading train:  77%|███████▋  | 351/456 [05:55<01:57,  1.12s/it]Loading train:  77%|███████▋  | 352/456 [05:56<01:52,  1.08s/it]Loading train:  77%|███████▋  | 353/456 [05:57<01:50,  1.07s/it]Loading train:  78%|███████▊  | 354/456 [05:58<01:45,  1.04s/it]Loading train:  78%|███████▊  | 355/456 [05:59<01:46,  1.06s/it]Loading train:  78%|███████▊  | 356/456 [06:00<01:49,  1.09s/it]Loading train:  78%|███████▊  | 357/456 [06:01<01:46,  1.08s/it]Loading train:  79%|███████▊  | 358/456 [06:03<01:46,  1.09s/it]Loading train:  79%|███████▊  | 359/456 [06:03<01:41,  1.04s/it]Loading train:  79%|███████▉  | 360/456 [06:05<01:43,  1.08s/it]Loading train:  79%|███████▉  | 361/456 [06:06<01:42,  1.07s/it]Loading train:  79%|███████▉  | 362/456 [06:07<01:43,  1.10s/it]Loading train:  80%|███████▉  | 363/456 [06:08<01:40,  1.08s/it]Loading train:  80%|███████▉  | 364/456 [06:09<01:36,  1.05s/it]Loading train:  80%|████████  | 365/456 [06:10<01:36,  1.06s/it]Loading train:  80%|████████  | 366/456 [06:11<01:34,  1.05s/it]Loading train:  80%|████████  | 367/456 [06:12<01:36,  1.09s/it]Loading train:  81%|████████  | 368/456 [06:13<01:30,  1.02s/it]Loading train:  81%|████████  | 369/456 [06:14<01:25,  1.02it/s]Loading train:  81%|████████  | 370/456 [06:15<01:22,  1.04it/s]Loading train:  81%|████████▏ | 371/456 [06:16<01:21,  1.05it/s]Loading train:  82%|████████▏ | 372/456 [06:17<01:20,  1.05it/s]Loading train:  82%|████████▏ | 373/456 [06:18<01:27,  1.05s/it]Loading train:  82%|████████▏ | 374/456 [06:19<01:32,  1.13s/it]Loading train:  82%|████████▏ | 375/456 [06:21<01:36,  1.19s/it]Loading train:  82%|████████▏ | 376/456 [06:22<01:39,  1.24s/it]Loading train:  83%|████████▎ | 377/456 [06:23<01:38,  1.25s/it]Loading train:  83%|████████▎ | 378/456 [06:24<01:36,  1.24s/it]Loading train:  83%|████████▎ | 379/456 [06:26<01:33,  1.21s/it]Loading train:  83%|████████▎ | 380/456 [06:27<01:27,  1.15s/it]Loading train:  84%|████████▎ | 381/456 [06:28<01:21,  1.08s/it]Loading train:  84%|████████▍ | 382/456 [06:29<01:19,  1.07s/it]Loading train:  84%|████████▍ | 383/456 [06:30<01:20,  1.10s/it]Loading train:  84%|████████▍ | 384/456 [06:31<01:19,  1.11s/it]Loading train:  84%|████████▍ | 385/456 [06:32<01:17,  1.09s/it]Loading train:  85%|████████▍ | 386/456 [06:33<01:13,  1.05s/it]Loading train:  85%|████████▍ | 387/456 [06:34<01:16,  1.10s/it]Loading train:  85%|████████▌ | 388/456 [06:35<01:15,  1.11s/it]Loading train:  85%|████████▌ | 389/456 [06:36<01:13,  1.10s/it]Loading train:  86%|████████▌ | 390/456 [06:37<01:13,  1.11s/it]Loading train:  86%|████████▌ | 391/456 [06:38<01:10,  1.08s/it]Loading train:  86%|████████▌ | 392/456 [06:40<01:10,  1.11s/it]Loading train:  86%|████████▌ | 393/456 [06:41<01:06,  1.05s/it]Loading train:  86%|████████▋ | 394/456 [06:42<01:03,  1.03s/it]Loading train:  87%|████████▋ | 395/456 [06:43<01:01,  1.01s/it]Loading train:  87%|████████▋ | 396/456 [06:44<01:00,  1.02s/it]Loading train:  87%|████████▋ | 397/456 [06:45<01:00,  1.03s/it]Loading train:  87%|████████▋ | 398/456 [06:46<00:57,  1.00it/s]Loading train:  88%|████████▊ | 399/456 [06:47<00:59,  1.04s/it]Loading train:  88%|████████▊ | 400/456 [06:48<00:59,  1.06s/it]Loading train:  88%|████████▊ | 401/456 [06:49<00:56,  1.03s/it]Loading train:  88%|████████▊ | 402/456 [06:50<00:55,  1.02s/it]Loading train:  88%|████████▊ | 403/456 [06:50<00:49,  1.06it/s]Loading train:  89%|████████▊ | 404/456 [06:51<00:45,  1.14it/s]Loading train:  89%|████████▉ | 405/456 [06:52<00:41,  1.24it/s]Loading train:  89%|████████▉ | 406/456 [06:53<00:38,  1.29it/s]Loading train:  89%|████████▉ | 407/456 [06:53<00:36,  1.35it/s]Loading train:  89%|████████▉ | 408/456 [06:54<00:34,  1.38it/s]Loading train:  90%|████████▉ | 409/456 [06:55<00:33,  1.38it/s]Loading train:  90%|████████▉ | 410/456 [06:55<00:30,  1.52it/s]Loading train:  90%|█████████ | 411/456 [06:56<00:28,  1.58it/s]Loading train:  90%|█████████ | 412/456 [06:56<00:28,  1.56it/s]Loading train:  91%|█████████ | 413/456 [06:57<00:25,  1.67it/s]Loading train:  91%|█████████ | 414/456 [06:58<00:26,  1.59it/s]Loading train:  91%|█████████ | 415/456 [06:58<00:27,  1.51it/s]Loading train:  91%|█████████ | 416/456 [06:59<00:25,  1.57it/s]Loading train:  91%|█████████▏| 417/456 [06:59<00:24,  1.59it/s]Loading train:  92%|█████████▏| 418/456 [07:00<00:23,  1.59it/s]Loading train:  92%|█████████▏| 419/456 [07:01<00:21,  1.70it/s]Loading train:  92%|█████████▏| 420/456 [07:01<00:20,  1.75it/s]Loading train:  92%|█████████▏| 421/456 [07:02<00:27,  1.26it/s]Loading train:  93%|█████████▎| 422/456 [07:04<00:31,  1.09it/s]Loading train:  93%|█████████▎| 423/456 [07:05<00:32,  1.03it/s]Loading train:  93%|█████████▎| 424/456 [07:06<00:34,  1.07s/it]Loading train:  93%|█████████▎| 425/456 [07:07<00:35,  1.13s/it]Loading train:  93%|█████████▎| 426/456 [07:09<00:34,  1.15s/it]Loading train:  94%|█████████▎| 427/456 [07:10<00:34,  1.18s/it]Loading train:  94%|█████████▍| 428/456 [07:11<00:33,  1.20s/it]Loading train:  94%|█████████▍| 429/456 [07:12<00:33,  1.24s/it]Loading train:  94%|█████████▍| 430/456 [07:14<00:31,  1.23s/it]Loading train:  95%|█████████▍| 431/456 [07:15<00:31,  1.27s/it]Loading train:  95%|█████████▍| 432/456 [07:16<00:29,  1.24s/it]Loading train:  95%|█████████▍| 433/456 [07:17<00:28,  1.23s/it]Loading train:  95%|█████████▌| 434/456 [07:18<00:26,  1.20s/it]Loading train:  95%|█████████▌| 435/456 [07:20<00:25,  1.19s/it]Loading train:  96%|█████████▌| 436/456 [07:21<00:22,  1.14s/it]Loading train:  96%|█████████▌| 437/456 [07:22<00:22,  1.17s/it]Loading train:  96%|█████████▌| 438/456 [07:23<00:20,  1.15s/it]Loading train:  96%|█████████▋| 439/456 [07:24<00:20,  1.18s/it]Loading train:  96%|█████████▋| 440/456 [07:25<00:18,  1.18s/it]Loading train:  97%|█████████▋| 441/456 [07:26<00:17,  1.14s/it]Loading train:  97%|█████████▋| 442/456 [07:28<00:15,  1.12s/it]Loading train:  97%|█████████▋| 443/456 [07:28<00:13,  1.07s/it]Loading train:  97%|█████████▋| 444/456 [07:30<00:13,  1.11s/it]Loading train:  98%|█████████▊| 445/456 [07:31<00:11,  1.05s/it]Loading train:  98%|█████████▊| 446/456 [07:32<00:10,  1.03s/it]Loading train:  98%|█████████▊| 447/456 [07:32<00:08,  1.02it/s]Loading train:  98%|█████████▊| 448/456 [07:33<00:07,  1.01it/s]Loading train:  98%|█████████▊| 449/456 [07:34<00:06,  1.03it/s]Loading train:  99%|█████████▊| 450/456 [07:35<00:05,  1.06it/s]Loading train:  99%|█████████▉| 451/456 [07:36<00:05,  1.01s/it]Loading train:  99%|█████████▉| 452/456 [07:37<00:03,  1.01it/s]Loading train:  99%|█████████▉| 453/456 [07:38<00:03,  1.02s/it]Loading train: 100%|█████████▉| 454/456 [07:39<00:02,  1.01s/it]Loading train: 100%|█████████▉| 455/456 [07:41<00:01,  1.02s/it]Loading train: 100%|██████████| 456/456 [07:41<00:00,  1.01s/it]
concatenating: train:   0%|          | 0/456 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 7/456 [00:00<00:06, 64.15it/s]concatenating: train:   5%|▌         | 23/456 [00:00<00:05, 78.13it/s]concatenating: train:  11%|█         | 49/456 [00:00<00:04, 98.52it/s]concatenating: train:  17%|█▋        | 76/456 [00:00<00:03, 121.31it/s]concatenating: train:  24%|██▍       | 110/456 [00:00<00:02, 150.09it/s]concatenating: train:  30%|██▉       | 135/456 [00:00<00:01, 169.50it/s]concatenating: train:  35%|███▍      | 159/456 [00:00<00:01, 185.57it/s]concatenating: train:  42%|████▏     | 190/456 [00:00<00:01, 209.95it/s]concatenating: train:  47%|████▋     | 216/456 [00:01<00:01, 159.75it/s]concatenating: train:  53%|█████▎    | 242/456 [00:01<00:01, 180.17it/s]concatenating: train:  59%|█████▊    | 267/456 [00:01<00:00, 194.97it/s]concatenating: train:  65%|██████▍   | 296/456 [00:01<00:00, 215.71it/s]concatenating: train:  70%|███████   | 321/456 [00:01<00:00, 223.90it/s]concatenating: train:  76%|███████▌  | 347/456 [00:01<00:00, 233.62it/s]concatenating: train:  82%|████████▏ | 372/456 [00:01<00:00, 234.99it/s]concatenating: train:  87%|████████▋ | 397/456 [00:01<00:00, 192.70it/s]concatenating: train:  92%|█████████▏| 419/456 [00:02<00:00, 165.64it/s]concatenating: train:  96%|█████████▌| 438/456 [00:02<00:00, 125.68it/s]concatenating: train: 100%|██████████| 456/456 [00:02<00:00, 193.12it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]Loading test:  50%|█████     | 2/4 [00:02<00:02,  1.20s/it]Loading test:  75%|███████▌  | 3/4 [00:03<00:01,  1.11s/it]Loading test: 100%|██████████| 4/4 [00:04<00:00,  1.11s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 62.18it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 56, 56, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 56, 56, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 56, 56, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 56, 56, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 56, 56, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 56, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 56, 56, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 56, 56, 31)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 31)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28, 28, 31)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 28, 60)   16800       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 28, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 28, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 28, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 28, 28, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 28, 28, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 28, 91)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 91)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 14, 14, 91)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 14, 14, 120)  98400       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 14, 14, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 14, 14, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 14, 14, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 14, 14, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 14, 14, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 14, 14, 211)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 14, 14, 211)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 28, 28, 60)   50700       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 28, 28, 151)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 28, 28, 60)   81600       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 28, 28, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 28, 28, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 28, 28, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 28, 28, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 28, 28, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 28, 28, 211)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-07 22:13:46.664631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 22:13:46.664780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 22:13:46.664797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 22:13:46.664806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 22:13:47.239325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 28, 28, 211)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 56, 56, 30)   25350       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 56, 61)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 56, 56, 30)   16500       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 56, 56, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 56, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 56, 56, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 56, 56, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 56, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 56, 91)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 56, 56, 91)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 56, 56, 13)   1196        dropout_5[0][0]                  
==================================================================================================
Total params: 504,146
Trainable params: 502,946
Non-trainable params: 1,200
__________________________________________________________________________________________________
----- /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/model_weights.h5
 --- initialized from Model_3T /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1
------------------------------------------------------------------
class_weights [6.20353721e-02 2.84453234e-02 7.46802407e-02 1.01751126e-02
 2.50007361e-02 6.29472736e-03 7.25125636e-02 1.12798228e-01
 6.41401498e-02 1.31242354e-02 3.56291442e-01 1.74306703e-01
 1.95165508e-04]
Train on 27379 samples, validate on 259 samples
Epoch 1/300
 - 38s - loss: 1.0330 - acc: 0.9600 - mDice: 0.6705 - val_loss: 1.0633 - val_acc: 0.9720 - val_mDice: 0.6719

Epoch 00001: val_mDice improved from -inf to 0.67188, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 29s - loss: 0.8513 - acc: 0.9633 - mDice: 0.7162 - val_loss: 1.0813 - val_acc: 0.9723 - val_mDice: 0.6824

Epoch 00002: val_mDice improved from 0.67188 to 0.68240, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 28s - loss: 0.7869 - acc: 0.9646 - mDice: 0.7364 - val_loss: 1.1378 - val_acc: 0.9720 - val_mDice: 0.6895

Epoch 00003: val_mDice improved from 0.68240 to 0.68950, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 28s - loss: 0.7468 - acc: 0.9656 - mDice: 0.7497 - val_loss: 1.1697 - val_acc: 0.9714 - val_mDice: 0.6923

Epoch 00004: val_mDice improved from 0.68950 to 0.69225, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 5/300
 - 28s - loss: 0.7211 - acc: 0.9661 - mDice: 0.7579 - val_loss: 1.1992 - val_acc: 0.9720 - val_mDice: 0.6885

Epoch 00005: val_mDice did not improve from 0.69225
Epoch 6/300
 - 28s - loss: 0.6980 - acc: 0.9666 - mDice: 0.7654 - val_loss: 1.1907 - val_acc: 0.9714 - val_mDice: 0.6894

Epoch 00006: val_mDice did not improve from 0.69225
Epoch 7/300
 - 28s - loss: 0.6811 - acc: 0.9670 - mDice: 0.7710 - val_loss: 1.2435 - val_acc: 0.9719 - val_mDice: 0.6902

Epoch 00007: val_mDice did not improve from 0.69225
Epoch 8/300
 - 29s - loss: 0.6671 - acc: 0.9673 - mDice: 0.7756 - val_loss: 1.2272 - val_acc: 0.9715 - val_mDice: 0.6966

Epoch 00008: val_mDice improved from 0.69225 to 0.69665, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 9/300
 - 27s - loss: 0.6544 - acc: 0.9676 - mDice: 0.7800 - val_loss: 1.2465 - val_acc: 0.9713 - val_mDice: 0.6936

Epoch 00009: val_mDice did not improve from 0.69665
Epoch 10/300
 - 26s - loss: 0.6439 - acc: 0.9679 - mDice: 0.7833 - val_loss: 1.2638 - val_acc: 0.9719 - val_mDice: 0.6931

Epoch 00010: val_mDice did not improve from 0.69665
Epoch 11/300
 - 26s - loss: 0.6339 - acc: 0.9681 - mDice: 0.7867 - val_loss: 1.3071 - val_acc: 0.9708 - val_mDice: 0.6912

Epoch 00011: val_mDice did not improve from 0.69665
Epoch 12/300
 - 26s - loss: 0.6243 - acc: 0.9683 - mDice: 0.7898 - val_loss: 1.3128 - val_acc: 0.9717 - val_mDice: 0.6869

Epoch 00012: val_mDice did not improve from 0.69665
Epoch 13/300
 - 26s - loss: 0.6178 - acc: 0.9685 - mDice: 0.7921 - val_loss: 1.3064 - val_acc: 0.9711 - val_mDice: 0.6955

Epoch 00013: val_mDice did not improve from 0.69665
Epoch 14/300
 - 25s - loss: 0.6118 - acc: 0.9687 - mDice: 0.7939 - val_loss: 1.3110 - val_acc: 0.9714 - val_mDice: 0.6997

Epoch 00014: val_mDice improved from 0.69665 to 0.69967, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyBCE_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 15/300
 - 26s - loss: 0.6044 - acc: 0.9688 - mDice: 0.7967 - val_loss: 1.3790 - val_acc: 0.9709 - val_mDice: 0.6937

Epoch 00015: val_mDice did not improve from 0.69967
Epoch 16/300
 - 28s - loss: 0.5992 - acc: 0.9689 - mDice: 0.7983 - val_loss: 1.3193 - val_acc: 0.9713 - val_mDice: 0.6963

Epoch 00016: val_mDice did not improve from 0.69967
Epoch 17/300
 - 26s - loss: 0.5934 - acc: 0.9690 - mDice: 0.8001 - val_loss: 1.3647 - val_acc: 0.9712 - val_mDice: 0.6954

Epoch 00017: val_mDice did not improve from 0.69967
Epoch 18/300
 - 28s - loss: 0.5879 - acc: 0.9692 - mDice: 0.8021 - val_loss: 1.4126 - val_acc: 0.9714 - val_mDice: 0.6895

Epoch 00018: val_mDice did not improve from 0.69967
Epoch 19/300
 - 27s - loss: 0.5828 - acc: 0.9693 - mDice: 0.8037 - val_loss: 1.3970 - val_acc: 0.9712 - val_mDice: 0.6899

Epoch 00019: val_mDice did not improve from 0.69967
Epoch 20/300
 - 27s - loss: 0.5785 - acc: 0.9694 - mDice: 0.8048 - val_loss: 1.3924 - val_acc: 0.9712 - val_mDice: 0.6963

Epoch 00020: val_mDice did not improve from 0.69967
Epoch 21/300
 - 28s - loss: 0.5747 - acc: 0.9695 - mDice: 0.8064 - val_loss: 1.4247 - val_acc: 0.9709 - val_mDice: 0.6967

Epoch 00021: val_mDice did not improve from 0.69967
Epoch 22/300
 - 28s - loss: 0.5721 - acc: 0.9695 - mDice: 0.8074 - val_loss: 1.4158 - val_acc: 0.9716 - val_mDice: 0.6919

Epoch 00022: val_mDice did not improve from 0.69967
Epoch 23/300
 - 27s - loss: 0.5662 - acc: 0.9697 - mDice: 0.8095 - val_loss: 1.4479 - val_acc: 0.9712 - val_mDice: 0.6936

Epoch 00023: val_mDice did not improve from 0.69967
Epoch 24/300
 - 28s - loss: 0.5635 - acc: 0.9698 - mDice: 0.8102 - val_loss: 1.4493 - val_acc: 0.9713 - val_mDice: 0.6953

Epoch 00024: val_mDice did not improve from 0.69967
Epoch 25/300
 - 28s - loss: 0.5609 - acc: 0.9698 - mDice: 0.8109 - val_loss: 1.4377 - val_acc: 0.9711 - val_mDice: 0.6915

Epoch 00025: val_mDice did not improve from 0.69967
Epoch 26/300
 - 28s - loss: 0.5556 - acc: 0.9699 - mDice: 0.8127 - val_loss: 1.4495 - val_acc: 0.9713 - val_mDice: 0.6976

Epoch 00026: val_mDice did not improve from 0.69967
Epoch 27/300
 - 29s - loss: 0.5549 - acc: 0.9699 - mDice: 0.8132 - val_loss: 1.4697 - val_acc: 0.9711 - val_mDice: 0.6940

Epoch 00027: val_mDice did not improve from 0.69967
Epoch 28/300
 - 30s - loss: 0.5501 - acc: 0.9700 - mDice: 0.8147 - val_loss: 1.4671 - val_acc: 0.9709 - val_mDice: 0.6950

Epoch 00028: val_mDice did not improve from 0.69967
Epoch 29/300
 - 28s - loss: 0.5493 - acc: 0.9701 - mDice: 0.8148 - val_loss: 1.4537 - val_acc: 0.9718 - val_mDice: 0.6966

Epoch 00029: val_mDice did not improve from 0.69967
Epoch 30/300
 - 29s - loss: 0.5464 - acc: 0.9701 - mDice: 0.8159 - val_loss: 1.4728 - val_acc: 0.9711 - val_mDice: 0.6982

Epoch 00030: val_mDice did not improve from 0.69967
Epoch 31/300
 - 31s - loss: 0.5435 - acc: 0.9702 - mDice: 0.8169 - val_loss: 1.4777 - val_acc: 0.9713 - val_mDice: 0.6943

Epoch 00031: val_mDice did not improve from 0.69967
Epoch 32/300
 - 29s - loss: 0.5405 - acc: 0.9702 - mDice: 0.8178 - val_loss: 1.5014 - val_acc: 0.9712 - val_mDice: 0.6928

Epoch 00032: val_mDice did not improve from 0.69967
Epoch 33/300
 - 28s - loss: 0.5386 - acc: 0.9703 - mDice: 0.8187 - val_loss: 1.4813 - val_acc: 0.9716 - val_mDice: 0.6963

Epoch 00033: val_mDice did not improve from 0.69967
Epoch 34/300
 - 30s - loss: 0.5357 - acc: 0.9704 - mDice: 0.8196 - val_loss: 1.5384 - val_acc: 0.9710 - val_mDice: 0.6897

Epoch 00034: val_mDice did not improve from 0.69967
Epoch 35/300
 - 30s - loss: 0.5344 - acc: 0.9704 - mDice: 0.8199 - val_loss: 1.5013 - val_acc: 0.9713 - val_mDice: 0.6958

Epoch 00035: val_mDice did not improve from 0.69967
Epoch 36/300
 - 29s - loss: 0.5323 - acc: 0.9704 - mDice: 0.8208 - val_loss: 1.4991 - val_acc: 0.9715 - val_mDice: 0.6961

Epoch 00036: val_mDice did not improve from 0.69967
Epoch 37/300
 - 29s - loss: 0.5302 - acc: 0.9705 - mDice: 0.8214 - val_loss: 1.5460 - val_acc: 0.9711 - val_mDice: 0.6890
