*** DATASET ALREADY EXIST; PLEASE REMOVE 'train' & 'test' SUBFOLDERS ***
(0/456) train vimp2_845_05312013_VZ
(1/456) train vimp2_823_05202013_AJ
(2/456) train vimp2_915_07112013_LC
(3/456) train vimp2_901_07052013_AS
(4/456) train vimp2_ctrl_911_07082013_TTO
(5/456) train vimp2_ctrl_925_07152013_LS
(6/456) train vimp2_869_06142013_BL
(7/456) train vimp2_ANON724_03272013
(8/456) train vimp2_819_05172013_DS
(9/456) train vimp2_ctrl_918_07112013_TQ
(10/456) train vimp2_ctrl_902_07052013_SI
(11/456) train vimp2_ANON606_20130110
(12/456) train vimp2_943_07242013_PA
(13/456) train vimp2_824_05212013_JS
(14/456) train vimp2_ANON624_20130117
(15/456) train vimp2_ctrl_920_07122013_SW
(16/456) train vimp2_884_06272013_TS
(17/456) train vimp2_668_02282013_CD
(18/456) train vimp2_964_08092013_TG
(19/456) train vimp2_ctrl_921_07122013_MP
(20/456) train vimp2_972_08152013_DC
(21/456) train vimp2_988_08302013_CB
(22/456) train vimp2_ANON702_03152013
(23/456) train vimp2_ANON714_03222013
(24/456) train vimp2_972_08152013_DC_Aug0_Rot_-1_sd0
(25/456) train vimp2_972_08152013_DC_Aug0_Rot_1_sd2
(26/456) train vimp2_972_08152013_DC_Aug0_Rot_-7_sd1
(27/456) train vimp2_972_08152013_DC_Aug1_Rot_2_sd0
(28/456) train vimp2_972_08152013_DC_Aug1_Rot_5_sd1
(29/456) train vimp2_972_08152013_DC_Aug1_Rot_6_sd2
(30/456) train vimp2_972_08152013_DC_Aug2_Rot_-3_sd1
(31/456) train vimp2_972_08152013_DC_Aug2_Rot_-3_sd2
(32/456) train vimp2_972_08152013_DC_Aug2_Rot_-5_sd0
(33/456) train vimp2_972_08152013_DC_Aug3_Rot_2_sd1
(34/456) train vimp2_972_08152013_DC_Aug3_Rot_-3_sd0
(35/456) train vimp2_972_08152013_DC_Aug3_Rot_-6_sd2
(36/456) train vimp2_972_08152013_DC_Aug4_Rot_-2_sd2
(37/456) train vimp2_972_08152013_DC_Aug4_Rot_3_sd0
(38/456) train vimp2_972_08152013_DC_Aug4_Rot_6_sd1
(39/456) train vimp2_972_08152013_DC_Aug5_Rot_-1_sd2
(40/456) train vimp2_972_08152013_DC_Aug5_Rot_7_sd0
(41/456) train vimp2_972_08152013_DC_Aug5_Rot_7_sd1
(42/456) train vimp2_988_08302013_CB_Aug0_Rot_-3_sd2
(43/456) train vimp2_988_08302013_CB_Aug0_Rot_4_sd0
(44/456) train vimp2_988_08302013_CB_Aug0_Rot_-5_sd1
(45/456) train vimp2_988_08302013_CB_Aug1_Rot_-2_sd2
(46/456) train vimp2_988_08302013_CB_Aug1_Rot_-3_sd0
(47/456) train vimp2_988_08302013_CB_Aug1_Rot_-6_sd1
(48/456) train vimp2_988_08302013_CB_Aug2_Rot_-2_sd0
(49/456) train vimp2_988_08302013_CB_Aug2_Rot_4_sd1
(50/456) train vimp2_988_08302013_CB_Aug2_Rot_-5_sd2
(51/456) train vimp2_988_08302013_CB_Aug3_Rot_2_sd2
(52/456) train vimp2_988_08302013_CB_Aug3_Rot_-3_sd0
(53/456) train vimp2_988_08302013_CB_Aug3_Rot_3_sd1
(54/456) train vimp2_988_08302013_CB_Aug4_Rot_-2_sd0
(55/456) train vimp2_988_08302013_CB_Aug4_Rot_-6_sd1
(56/456) train vimp2_988_08302013_CB_Aug4_Rot_7_sd2
(57/456) train vimp2_988_08302013_CB_Aug5_Rot_-1_sd0
(58/456) train vimp2_988_08302013_CB_Aug5_Rot_-6_sd1
(59/456) train vimp2_988_08302013_CB_Aug5_Rot_7_sd2
(60/456) train vimp2_ANON702_03152013_Aug0_Rot_-2_sd1
(61/456) train vimp2_ANON702_03152013_Aug0_Rot_-3_sd2
(62/456) train vimp2_ANON702_03152013_Aug0_Rot_-4_sd0
(63/456) train vimp2_ANON702_03152013_Aug1_Rot_-4_sd1
(64/456) train vimp2_ANON702_03152013_Aug1_Rot_-5_sd2
(65/456) train vimp2_ANON702_03152013_Aug1_Rot_-7_sd0
(66/456) train vimp2_ANON702_03152013_Aug2_Rot_6_sd0
(67/456) train vimp2_ANON702_03152013_Aug2_Rot_6_sd2
(68/456) train vimp2_ANON702_03152013_Aug2_Rot_-7_sd1
(69/456) train vimp2_ANON702_03152013_Aug3_Rot_-1_sd2
(70/456) train vimp2_ANON702_03152013_Aug3_Rot_-3_sd0
(71/456) train vimp2_ANON702_03152013_Aug3_Rot_-6_sd1
(72/456) train vimp2_ANON702_03152013_Aug4_Rot_-2_sd0
(73/456) train vimp2_ANON702_03152013_Aug4_Rot_-3_sd2
(74/456) train vimp2_ANON702_03152013_Aug4_Rot_-7_sd1
(75/456) train vimp2_ANON702_03152013_Aug5_Rot_3_sd0
(76/456) train vimp2_ANON702_03152013_Aug5_Rot_3_sd2
(77/456) train vimp2_ANON702_03152013_Aug5_Rot_4_sd1
(78/456) train vimp2_ANON714_03222013_Aug0_Rot_-1_sd2
(79/456) train vimp2_ANON714_03222013_Aug0_Rot_-2_sd1
(80/456) train vimp2_ANON714_03222013_Aug0_Rot_4_sd0
(81/456) train vimp2_ANON714_03222013_Aug1_Rot_0_sd0
(82/456) train vimp2_ANON714_03222013_Aug1_Rot_1_sd1
(83/456) train vimp2_ANON714_03222013_Aug1_Rot_-6_sd2
(84/456) train vimp2_ANON714_03222013_Aug2_Rot_-2_sd0
(85/456) train vimp2_ANON714_03222013_Aug2_Rot_4_sd1
(86/456) train vimp2_ANON714_03222013_Aug2_Rot_6_sd2
(87/456) train vimp2_ANON714_03222013_Aug3_Rot_2_sd0
(88/456) train vimp2_ANON714_03222013_Aug3_Rot_-3_sd2
(89/456) train vimp2_ANON714_03222013_Aug3_Rot_-7_sd1
(90/456) train vimp2_ANON714_03222013_Aug4_Rot_1_sd0
(91/456) train vimp2_ANON714_03222013_Aug4_Rot_-2_sd1
(92/456) train vimp2_ANON714_03222013_Aug4_Rot_4_sd2
(93/456) train vimp2_ANON714_03222013_Aug5_Rot_1_sd0
(94/456) train vimp2_ANON714_03222013_Aug5_Rot_6_sd1
(95/456) train vimp2_ANON714_03222013_Aug5_Rot_-7_sd2
(96/456) train vimp2_668_02282013_CD_Aug0_Rot_7_sd0
(97/456) train vimp2_668_02282013_CD_Aug1_Rot_-1_sd0
(98/456) train vimp2_668_02282013_CD_Aug2_Rot_-4_sd0
(99/456) train vimp2_668_02282013_CD_Aug3_Rot_3_sd0
(100/456) train vimp2_668_02282013_CD_Aug4_Rot_-5_sd0
(101/456) train vimp2_668_02282013_CD_Aug5_Rot_-6_sd0
(102/456) train vimp2_819_05172013_DS_Aug0_Rot_1_sd0
(103/456) train vimp2_819_05172013_DS_Aug1_Rot_5_sd0
(104/456) train vimp2_819_05172013_DS_Aug2_Rot_-4_sd0
(105/456) train vimp2_819_05172013_DS_Aug3_Rot_2_sd0
(106/456) train vimp2_819_05172013_DS_Aug4_Rot_5_sd0
(107/456) train vimp2_819_05172013_DS_Aug5_Rot_4_sd0
(108/456) train vimp2_823_05202013_AJ_Aug0_Rot_-7_sd0
(109/456) train vimp2_823_05202013_AJ_Aug1_Rot_7_sd0
(110/456) train vimp2_823_05202013_AJ_Aug2_Rot_3_sd0
(111/456) train vimp2_823_05202013_AJ_Aug3_Rot_-5_sd0
(112/456) train vimp2_823_05202013_AJ_Aug4_Rot_-3_sd0
(113/456) train vimp2_823_05202013_AJ_Aug5_Rot_1_sd0
(114/456) train vimp2_824_05212013_JS_Aug0_Rot_-2_sd0
(115/456) train vimp2_824_05212013_JS_Aug1_Rot_6_sd0
(116/456) train vimp2_824_05212013_JS_Aug2_Rot_1_sd0
(117/456) train vimp2_824_05212013_JS_Aug3_Rot_-4_sd0
(118/456) train vimp2_824_05212013_JS_Aug4_Rot_7_sd0
(119/456) train vimp2_824_05212013_JS_Aug5_Rot_2_sd0
(120/456) train vimp2_845_05312013_VZ_Aug0_Rot_1_sd0
(121/456) train vimp2_845_05312013_VZ_Aug1_Rot_5_sd0
(122/456) train vimp2_845_05312013_VZ_Aug2_Rot_-6_sd0
(123/456) train vimp2_845_05312013_VZ_Aug3_Rot_3_sd0
(124/456) train vimp2_845_05312013_VZ_Aug4_Rot_-2_sd0
(125/456) train vimp2_845_05312013_VZ_Aug5_Rot_5_sd0
(126/456) train vimp2_869_06142013_BL_Aug0_Rot_-2_sd0
(127/456) train vimp2_869_06142013_BL_Aug1_Rot_-4_sd0
(128/456) train vimp2_869_06142013_BL_Aug2_Rot_-1_sd0
(129/456) train vimp2_869_06142013_BL_Aug3_Rot_3_sd0
(130/456) train vimp2_869_06142013_BL_Aug4_Rot_3_sd0
(131/456) train vimp2_869_06142013_BL_Aug5_Rot_1_sd0
(132/456) train vimp2_884_06272013_TS_Aug0_Rot_-7_sd0
(133/456) train vimp2_884_06272013_TS_Aug1_Rot_7_sd0
(134/456) train vimp2_884_06272013_TS_Aug2_Rot_-5_sd0
(135/456) train vimp2_884_06272013_TS_Aug3_Rot_-2_sd0
(136/456) train vimp2_884_06272013_TS_Aug4_Rot_6_sd0
(137/456) train vimp2_884_06272013_TS_Aug5_Rot_-1_sd0
(138/456) train vimp2_901_07052013_AS_Aug0_Rot_-4_sd0
(139/456) train vimp2_901_07052013_AS_Aug1_Rot_-2_sd0
(140/456) train vimp2_901_07052013_AS_Aug2_Rot_1_sd0
(141/456) train vimp2_901_07052013_AS_Aug3_Rot_2_sd0
(142/456) train vimp2_901_07052013_AS_Aug4_Rot_-7_sd0
(143/456) train vimp2_901_07052013_AS_Aug5_Rot_-5_sd0
(144/456) train vimp2_915_07112013_LC_Aug0_Rot_-2_sd0
(145/456) train vimp2_915_07112013_LC_Aug1_Rot_4_sd0
(146/456) train vimp2_915_07112013_LC_Aug2_Rot_-2_sd0
(147/456) train vimp2_915_07112013_LC_Aug3_Rot_-1_sd0
(148/456) train vimp2_915_07112013_LC_Aug4_Rot_1_sd0
(149/456) train vimp2_915_07112013_LC_Aug5_Rot_4_sd0
(150/456) train vimp2_943_07242013_PA_Aug0_Rot_-5_sd0
(151/456) train vimp2_943_07242013_PA_Aug1_Rot_-7_sd0
(152/456) train vimp2_943_07242013_PA_Aug2_Rot_-4_sd0
(153/456) train vimp2_943_07242013_PA_Aug3_Rot_6_sd0
(154/456) train vimp2_943_07242013_PA_Aug4_Rot_6_sd0
(155/456) train vimp2_943_07242013_PA_Aug5_Rot_5_sd0
(156/456) train vimp2_964_08092013_TG_Aug0_Rot_5_sd0
(157/456) train vimp2_964_08092013_TG_Aug1_Rot_-4_sd0
(158/456) train vimp2_964_08092013_TG_Aug2_Rot_7_sd0
(159/456) train vimp2_964_08092013_TG_Aug3_Rot_-1_sd0
(160/456) train vimp2_964_08092013_TG_Aug4_Rot_-1_sd0
(161/456) train vimp2_964_08092013_TG_Aug5_Rot_2_sd0
(162/456) train vimp2_ANON606_20130110_Aug0_Rot_1_sd0
(163/456) train vimp2_ANON606_20130110_Aug1_Rot_2_sd0
(164/456) train vimp2_ANON606_20130110_Aug2_Rot_-5_sd0
(165/456) train vimp2_ANON606_20130110_Aug3_Rot_-5_sd0
(166/456) train vimp2_ANON606_20130110_Aug4_Rot_3_sd0
(167/456) train vimp2_ANON606_20130110_Aug5_Rot_-1_sd0
(168/456) train vimp2_ANON624_20130117_Aug0_Rot_1_sd0
(169/456) train vimp2_ANON624_20130117_Aug1_Rot_-2_sd0
(170/456) train vimp2_ANON624_20130117_Aug2_Rot_5_sd0
(171/456) train vimp2_ANON624_20130117_Aug3_Rot_1_sd0
(172/456) train vimp2_ANON624_20130117_Aug4_Rot_-5_sd0
(173/456) train vimp2_ANON624_20130117_Aug5_Rot_3_sd0
(174/456) train vimp2_ANON724_03272013_Aug0_Rot_-4_sd0
(175/456) train vimp2_ANON724_03272013_Aug1_Rot_-3_sd0
(176/456) train vimp2_ANON724_03272013_Aug2_Rot_-4_sd0
(177/456) train vimp2_ANON724_03272013_Aug3_Rot_5_sd0
(178/456) train vimp2_ANON724_03272013_Aug4_Rot_5_sd0
(179/456) train vimp2_ANON724_03272013_Aug5_Rot_-6_sd0
(180/456) train vimp2_ctrl_902_07052013_SI_Aug0_Rot_5_sd0
(181/456) train vimp2_ctrl_902_07052013_SI_Aug1_Rot_7_sd0
(182/456) train vimp2_ctrl_902_07052013_SI_Aug2_Rot_4_sd0
(183/456) train vimp2_ctrl_902_07052013_SI_Aug3_Rot_-4_sd0
(184/456) train vimp2_ctrl_902_07052013_SI_Aug4_Rot_3_sd0
(185/456) train vimp2_ctrl_902_07052013_SI_Aug5_Rot_-7_sd0
(186/456) train vimp2_ctrl_911_07082013_TTO_Aug0_Rot_6_sd0
(187/456) train vimp2_ctrl_911_07082013_TTO_Aug1_Rot_1_sd0
(188/456) train vimp2_ctrl_911_07082013_TTO_Aug2_Rot_4_sd0
(189/456) train vimp2_ctrl_911_07082013_TTO_Aug3_Rot_-2_sd0
(190/456) train vimp2_ctrl_911_07082013_TTO_Aug4_Rot_6_sd0
(191/456) train vimp2_ctrl_911_07082013_TTO_Aug5_Rot_-2_sd0
(192/456) train vimp2_ctrl_918_07112013_TQ_Aug0_Rot_5_sd0
(193/456) train vimp2_ctrl_918_07112013_TQ_Aug1_Rot_-3_sd0
(194/456) train vimp2_ctrl_918_07112013_TQ_Aug2_Rot_-4_sd0
(195/456) train vimp2_ctrl_918_07112013_TQ_Aug3_Rot_1_sd0
(196/456) train vimp2_ctrl_918_07112013_TQ_Aug4_Rot_3_sd0
(197/456) train vimp2_ctrl_918_07112013_TQ_Aug5_Rot_7_sd0
(198/456) train vimp2_ctrl_920_07122013_SW_Aug0_Rot_7_sd0
(199/456) train vimp2_ctrl_920_07122013_SW_Aug1_Rot_-6_sd0
(200/456) train vimp2_ctrl_920_07122013_SW_Aug2_Rot_-4_sd0
(201/456) train vimp2_ctrl_920_07122013_SW_Aug3_Rot_1_sd0
(202/456) train vimp2_ctrl_920_07122013_SW_Aug4_Rot_-2_sd0
(203/456) train vimp2_ctrl_920_07122013_SW_Aug5_Rot_4_sd0
(204/456) train vimp2_ctrl_921_07122013_MP_Aug0_Rot_-1_sd0
(205/456) train vimp2_ctrl_921_07122013_MP_Aug1_Rot_-3_sd0
(206/456) train vimp2_ctrl_921_07122013_MP_Aug2_Rot_6_sd0
(207/456) train vimp2_ctrl_921_07122013_MP_Aug3_Rot_3_sd0
(208/456) train vimp2_ctrl_921_07122013_MP_Aug4_Rot_1_sd0
(209/456) train vimp2_ctrl_921_07122013_MP_Aug5_Rot_-5_sd0
(210/456) train vimp2_ctrl_925_07152013_LS_Aug0_Rot_-5_sd0
(211/456) train vimp2_ctrl_925_07152013_LS_Aug1_Rot_-2_sd0
(212/456) train vimp2_ctrl_925_07152013_LS_Aug2_Rot_5_sd0
(213/456) train vimp2_ctrl_925_07152013_LS_Aug3_Rot_3_sd0
(214/456) train vimp2_ctrl_925_07152013_LS_Aug4_Rot_4_sd0
(215/456) train vimp2_ctrl_925_07152013_LS_Aug5_Rot_-7_sd0
(216/456) train vimp2_668_02282013_CD_Aug0_Rot_-5_sd1
(217/456) train vimp2_668_02282013_CD_Aug1_Rot_-6_sd1
(218/456) train vimp2_668_02282013_CD_Aug2_Rot_3_sd1
(219/456) train vimp2_668_02282013_CD_Aug3_Rot_4_sd1
(220/456) train vimp2_668_02282013_CD_Aug4_Rot_-6_sd1
(221/456) train vimp2_668_02282013_CD_Aug5_Rot_-2_sd1
(222/456) train vimp2_819_05172013_DS_Aug0_Rot_-1_sd1
(223/456) train vimp2_819_05172013_DS_Aug1_Rot_3_sd1
(224/456) train vimp2_819_05172013_DS_Aug2_Rot_6_sd1
(225/456) train vimp2_819_05172013_DS_Aug3_Rot_3_sd1
(226/456) train vimp2_819_05172013_DS_Aug4_Rot_-7_sd1
(227/456) train vimp2_819_05172013_DS_Aug5_Rot_-5_sd1
(228/456) train vimp2_823_05202013_AJ_Aug0_Rot_-7_sd1
(229/456) train vimp2_823_05202013_AJ_Aug1_Rot_3_sd1
(230/456) train vimp2_823_05202013_AJ_Aug2_Rot_6_sd1
(231/456) train vimp2_823_05202013_AJ_Aug3_Rot_-7_sd1
(232/456) train vimp2_823_05202013_AJ_Aug4_Rot_-4_sd1
(233/456) train vimp2_823_05202013_AJ_Aug5_Rot_-4_sd1
(234/456) train vimp2_824_05212013_JS_Aug0_Rot_7_sd1
(235/456) train vimp2_824_05212013_JS_Aug1_Rot_3_sd1
(236/456) train vimp2_824_05212013_JS_Aug2_Rot_3_sd1
(237/456) train vimp2_824_05212013_JS_Aug3_Rot_-4_sd1
(238/456) train vimp2_824_05212013_JS_Aug4_Rot_4_sd1
(239/456) train vimp2_824_05212013_JS_Aug5_Rot_6_sd1
(240/456) train vimp2_845_05312013_VZ_Aug0_Rot_5_sd1
(241/456) train vimp2_845_05312013_VZ_Aug1_Rot_6_sd1
(242/456) train vimp2_845_05312013_VZ_Aug2_Rot_1_sd1
(243/456) train vimp2_845_05312013_VZ_Aug3_Rot_-6_sd1
(244/456) train vimp2_845_05312013_VZ_Aug4_Rot_-2_sd1
(245/456) train vimp2_845_05312013_VZ_Aug5_Rot_-6_sd1
(246/456) train vimp2_869_06142013_BL_Aug0_Rot_-4_sd1
(247/456) train vimp2_869_06142013_BL_Aug1_Rot_-3_sd1
(248/456) train vimp2_869_06142013_BL_Aug2_Rot_-4_sd1
(249/456) train vimp2_869_06142013_BL_Aug3_Rot_1_sd1
(250/456) train vimp2_869_06142013_BL_Aug4_Rot_7_sd1
(251/456) train vimp2_869_06142013_BL_Aug5_Rot_5_sd1
(252/456) train vimp2_884_06272013_TS_Aug0_Rot_5_sd1
(253/456) train vimp2_884_06272013_TS_Aug1_Rot_-1_sd1
(254/456) train vimp2_884_06272013_TS_Aug2_Rot_-1_sd1
(255/456) train vimp2_884_06272013_TS_Aug3_Rot_3_sd1
(256/456) train vimp2_884_06272013_TS_Aug4_Rot_4_sd1
(257/456) train vimp2_884_06272013_TS_Aug5_Rot_3_sd1
(258/456) train vimp2_901_07052013_AS_Aug0_Rot_3_sd1
(259/456) train vimp2_901_07052013_AS_Aug1_Rot_5_sd1
(260/456) train vimp2_901_07052013_AS_Aug2_Rot_-5_sd1
(261/456) train vimp2_901_07052013_AS_Aug3_Rot_7_sd1
(262/456) train vimp2_901_07052013_AS_Aug4_Rot_7_sd1
(263/456) train vimp2_901_07052013_AS_Aug5_Rot_6_sd1
(264/456) train vimp2_915_07112013_LC_Aug0_Rot_-6_sd1
(265/456) train vimp2_915_07112013_LC_Aug1_Rot_-5_sd1
(266/456) train vimp2_915_07112013_LC_Aug2_Rot_7_sd1
(267/456) train vimp2_915_07112013_LC_Aug3_Rot_1_sd1
(268/456) train vimp2_915_07112013_LC_Aug4_Rot_6_sd1
(269/456) train vimp2_915_07112013_LC_Aug5_Rot_-7_sd1
(270/456) train vimp2_943_07242013_PA_Aug0_Rot_1_sd1
(271/456) train vimp2_943_07242013_PA_Aug1_Rot_6_sd1
(272/456) train vimp2_943_07242013_PA_Aug2_Rot_3_sd1
(273/456) train vimp2_943_07242013_PA_Aug3_Rot_6_sd1
(274/456) train vimp2_943_07242013_PA_Aug4_Rot_3_sd1
(275/456) train vimp2_943_07242013_PA_Aug5_Rot_3_sd1
(276/456) train vimp2_964_08092013_TG_Aug0_Rot_6_sd1
(277/456) train vimp2_964_08092013_TG_Aug1_Rot_-4_sd1
(278/456) train vimp2_964_08092013_TG_Aug2_Rot_5_sd1
(279/456) train vimp2_964_08092013_TG_Aug3_Rot_0_sd1
(280/456) train vimp2_964_08092013_TG_Aug4_Rot_3_sd1
(281/456) train vimp2_964_08092013_TG_Aug5_Rot_-1_sd1
(282/456) train vimp2_ANON606_20130110_Aug0_Rot_-6_sd1
(283/456) train vimp2_ANON606_20130110_Aug1_Rot_7_sd1
(284/456) train vimp2_ANON606_20130110_Aug2_Rot_1_sd1
(285/456) train vimp2_ANON606_20130110_Aug3_Rot_1_sd1
(286/456) train vimp2_ANON606_20130110_Aug4_Rot_4_sd1
(287/456) train vimp2_ANON606_20130110_Aug5_Rot_4_sd1
(288/456) train vimp2_ANON624_20130117_Aug0_Rot_7_sd1
(289/456) train vimp2_ANON624_20130117_Aug1_Rot_6_sd1
(290/456) train vimp2_ANON624_20130117_Aug2_Rot_-1_sd1
(291/456) train vimp2_ANON624_20130117_Aug3_Rot_1_sd1
(292/456) train vimp2_ANON624_20130117_Aug4_Rot_-5_sd1
(293/456) train vimp2_ANON624_20130117_Aug5_Rot_4_sd1
(294/456) train vimp2_ANON724_03272013_Aug0_Rot_-2_sd1
(295/456) train vimp2_ANON724_03272013_Aug1_Rot_4_sd1
(296/456) train vimp2_ANON724_03272013_Aug2_Rot_-1_sd1
(297/456) train vimp2_ANON724_03272013_Aug3_Rot_-6_sd1
(298/456) train vimp2_ANON724_03272013_Aug4_Rot_-5_sd1
(299/456) train vimp2_ANON724_03272013_Aug5_Rot_-4_sd1
(300/456) train vimp2_ctrl_902_07052013_SI_Aug0_Rot_-2_sd1
(301/456) train vimp2_ctrl_902_07052013_SI_Aug1_Rot_7_sd1
(302/456) train vimp2_ctrl_902_07052013_SI_Aug2_Rot_2_sd1
(303/456) train vimp2_ctrl_902_07052013_SI_Aug3_Rot_-4_sd1
(304/456) train vimp2_ctrl_902_07052013_SI_Aug4_Rot_-1_sd1
(305/456) train vimp2_ctrl_902_07052013_SI_Aug5_Rot_-4_sd1
(306/456) train vimp2_ctrl_911_07082013_TTO_Aug0_Rot_7_sd1
(307/456) train vimp2_ctrl_911_07082013_TTO_Aug1_Rot_-1_sd1
(308/456) train vimp2_ctrl_911_07082013_TTO_Aug2_Rot_-5_sd1
(309/456) train vimp2_ctrl_911_07082013_TTO_Aug3_Rot_-3_sd1
(310/456) train vimp2_ctrl_911_07082013_TTO_Aug4_Rot_6_sd1
(311/456) train vimp2_ctrl_911_07082013_TTO_Aug5_Rot_6_sd1
(312/456) train vimp2_ctrl_918_07112013_TQ_Aug0_Rot_1_sd1
(313/456) train vimp2_ctrl_918_07112013_TQ_Aug1_Rot_-2_sd1
(314/456) train vimp2_ctrl_918_07112013_TQ_Aug2_Rot_3_sd1
(315/456) train vimp2_ctrl_918_07112013_TQ_Aug3_Rot_-1_sd1
(316/456) train vimp2_ctrl_918_07112013_TQ_Aug4_Rot_7_sd1
(317/456) train vimp2_ctrl_918_07112013_TQ_Aug5_Rot_6_sd1
(318/456) train vimp2_ctrl_920_07122013_SW_Aug0_Rot_-3_sd1
(319/456) train vimp2_ctrl_920_07122013_SW_Aug1_Rot_7_sd1
(320/456) train vimp2_ctrl_920_07122013_SW_Aug2_Rot_-4_sd1
(321/456) train vimp2_ctrl_920_07122013_SW_Aug3_Rot_-1_sd1
(322/456) train vimp2_ctrl_920_07122013_SW_Aug4_Rot_-5_sd1
(323/456) train vimp2_ctrl_920_07122013_SW_Aug5_Rot_-5_sd1
(324/456) train vimp2_ctrl_921_07122013_MP_Aug0_Rot_4_sd1
(325/456) train vimp2_ctrl_921_07122013_MP_Aug1_Rot_3_sd1
(326/456) train vimp2_ctrl_921_07122013_MP_Aug2_Rot_-1_sd1
(327/456) train vimp2_ctrl_921_07122013_MP_Aug3_Rot_-2_sd1
(328/456) train vimp2_ctrl_921_07122013_MP_Aug4_Rot_2_sd1
(329/456) train vimp2_ctrl_921_07122013_MP_Aug5_Rot_4_sd1
(330/456) train vimp2_ctrl_925_07152013_LS_Aug0_Rot_-2_sd1
(331/456) train vimp2_ctrl_925_07152013_LS_Aug1_Rot_4_sd1
(332/456) train vimp2_ctrl_925_07152013_LS_Aug2_Rot_-2_sd1
(333/456) train vimp2_ctrl_925_07152013_LS_Aug3_Rot_2_sd1
(334/456) train vimp2_ctrl_925_07152013_LS_Aug4_Rot_3_sd1
(335/456) train vimp2_ctrl_925_07152013_LS_Aug5_Rot_-4_sd1
(336/456) train vimp2_668_02282013_CD_Aug0_Rot_-3_sd2
(337/456) train vimp2_668_02282013_CD_Aug1_Rot_6_sd2
(338/456) train vimp2_668_02282013_CD_Aug2_Rot_-6_sd2
(339/456) train vimp2_668_02282013_CD_Aug3_Rot_7_sd2
(340/456) train vimp2_668_02282013_CD_Aug4_Rot_1_sd2
(341/456) train vimp2_668_02282013_CD_Aug5_Rot_7_sd2
(342/456) train vimp2_819_05172013_DS_Aug0_Rot_3_sd2
(343/456) train vimp2_819_05172013_DS_Aug1_Rot_-1_sd2
(344/456) train vimp2_819_05172013_DS_Aug2_Rot_-2_sd2
(345/456) train vimp2_819_05172013_DS_Aug3_Rot_-1_sd2
(346/456) train vimp2_819_05172013_DS_Aug4_Rot_7_sd2
(347/456) train vimp2_819_05172013_DS_Aug5_Rot_3_sd2
(348/456) train vimp2_823_05202013_AJ_Aug0_Rot_-6_sd2
(349/456) train vimp2_823_05202013_AJ_Aug1_Rot_-7_sd2
(350/456) train vimp2_823_05202013_AJ_Aug2_Rot_7_sd2
(351/456) train vimp2_823_05202013_AJ_Aug3_Rot_-2_sd2
(352/456) train vimp2_823_05202013_AJ_Aug4_Rot_1_sd2
(353/456) train vimp2_823_05202013_AJ_Aug5_Rot_1_sd2
(354/456) train vimp2_824_05212013_JS_Aug0_Rot_-5_sd2
(355/456) train vimp2_824_05212013_JS_Aug1_Rot_3_sd2
(356/456) train vimp2_824_05212013_JS_Aug2_Rot_5_sd2
(357/456) train vimp2_824_05212013_JS_Aug3_Rot_2_sd2
(358/456) train vimp2_824_05212013_JS_Aug4_Rot_5_sd2
(359/456) train vimp2_824_05212013_JS_Aug5_Rot_-7_sd2
(360/456) train vimp2_845_05312013_VZ_Aug0_Rot_-5_sd2
(361/456) train vimp2_845_05312013_VZ_Aug1_Rot_3_sd2
(362/456) train vimp2_845_05312013_VZ_Aug2_Rot_-3_sd2
(363/456) train vimp2_845_05312013_VZ_Aug3_Rot_-1_sd2
(364/456) train vimp2_845_05312013_VZ_Aug4_Rot_4_sd2
(365/456) train vimp2_845_05312013_VZ_Aug5_Rot_-2_sd2
(366/456) train vimp2_869_06142013_BL_Aug0_Rot_3_sd2
(367/456) train vimp2_869_06142013_BL_Aug1_Rot_7_sd2
(368/456) train vimp2_869_06142013_BL_Aug2_Rot_4_sd2
(369/456) train vimp2_869_06142013_BL_Aug3_Rot_1_sd2
(370/456) train vimp2_869_06142013_BL_Aug4_Rot_1_sd2
(371/456) train vimp2_869_06142013_BL_Aug5_Rot_1_sd2
(372/456) train vimp2_884_06272013_TS_Aug0_Rot_3_sd2
(373/456) train vimp2_884_06272013_TS_Aug1_Rot_-5_sd2
(374/456) train vimp2_884_06272013_TS_Aug2_Rot_-7_sd2
(375/456) train vimp2_884_06272013_TS_Aug3_Rot_-6_sd2
(376/456) train vimp2_884_06272013_TS_Aug4_Rot_-2_sd2
(377/456) train vimp2_884_06272013_TS_Aug5_Rot_-6_sd2
(378/456) train vimp2_901_07052013_AS_Aug0_Rot_2_sd2
(379/456) train vimp2_901_07052013_AS_Aug1_Rot_-3_sd2
(380/456) train vimp2_901_07052013_AS_Aug2_Rot_-6_sd2
(381/456) train vimp2_901_07052013_AS_Aug3_Rot_6_sd2
(382/456) train vimp2_901_07052013_AS_Aug4_Rot_-5_sd2
(383/456) train vimp2_901_07052013_AS_Aug5_Rot_1_sd2
(384/456) train vimp2_915_07112013_LC_Aug0_Rot_1_sd2
(385/456) train vimp2_915_07112013_LC_Aug1_Rot_7_sd2
(386/456) train vimp2_915_07112013_LC_Aug2_Rot_3_sd2
(387/456) train vimp2_915_07112013_LC_Aug3_Rot_6_sd2
(388/456) train vimp2_915_07112013_LC_Aug4_Rot_4_sd2
(389/456) train vimp2_915_07112013_LC_Aug5_Rot_4_sd2
(390/456) train vimp2_943_07242013_PA_Aug0_Rot_3_sd2
(391/456) train vimp2_943_07242013_PA_Aug1_Rot_-4_sd2
(392/456) train vimp2_943_07242013_PA_Aug2_Rot_3_sd2
(393/456) train vimp2_943_07242013_PA_Aug3_Rot_2_sd2
(394/456) train vimp2_943_07242013_PA_Aug4_Rot_-1_sd2
(395/456) train vimp2_943_07242013_PA_Aug5_Rot_-3_sd2
(396/456) train vimp2_964_08092013_TG_Aug0_Rot_2_sd2
(397/456) train vimp2_964_08092013_TG_Aug1_Rot_-6_sd2
(398/456) train vimp2_964_08092013_TG_Aug2_Rot_5_sd2
(399/456) train vimp2_964_08092013_TG_Aug3_Rot_-7_sd2
(400/456) train vimp2_964_08092013_TG_Aug4_Rot_-6_sd2
(401/456) train vimp2_964_08092013_TG_Aug5_Rot_5_sd2
(402/456) train vimp2_ANON606_20130110_Aug0_Rot_-6_sd2
(403/456) train vimp2_ANON606_20130110_Aug1_Rot_-5_sd2
(404/456) train vimp2_ANON606_20130110_Aug2_Rot_-3_sd2
(405/456) train vimp2_ANON606_20130110_Aug3_Rot_3_sd2
(406/456) train vimp2_ANON606_20130110_Aug4_Rot_-2_sd2
(407/456) train vimp2_ANON606_20130110_Aug5_Rot_-3_sd2
(408/456) train vimp2_ANON624_20130117_Aug0_Rot_2_sd2
(409/456) train vimp2_ANON624_20130117_Aug1_Rot_-2_sd2
(410/456) train vimp2_ANON624_20130117_Aug2_Rot_-6_sd2
(411/456) train vimp2_ANON624_20130117_Aug3_Rot_1_sd2
(412/456) train vimp2_ANON624_20130117_Aug4_Rot_-5_sd2
(413/456) train vimp2_ANON624_20130117_Aug5_Rot_-7_sd2
(414/456) train vimp2_ANON724_03272013_Aug0_Rot_-5_sd2
(415/456) train vimp2_ANON724_03272013_Aug1_Rot_6_sd2
(416/456) train vimp2_ANON724_03272013_Aug2_Rot_-3_sd2
(417/456) train vimp2_ANON724_03272013_Aug3_Rot_-6_sd2
(418/456) train vimp2_ANON724_03272013_Aug4_Rot_-1_sd2
(419/456) train vimp2_ANON724_03272013_Aug5_Rot_-7_sd2
(420/456) train vimp2_ctrl_902_07052013_SI_Aug0_Rot_-4_sd2
(421/456) train vimp2_ctrl_902_07052013_SI_Aug1_Rot_-3_sd2
(422/456) train vimp2_ctrl_902_07052013_SI_Aug2_Rot_-5_sd2
(423/456) train vimp2_ctrl_902_07052013_SI_Aug3_Rot_5_sd2
(424/456) train vimp2_ctrl_902_07052013_SI_Aug4_Rot_-2_sd2
(425/456) train vimp2_ctrl_902_07052013_SI_Aug5_Rot_5_sd2
(426/456) train vimp2_ctrl_911_07082013_TTO_Aug0_Rot_-3_sd2
(427/456) train vimp2_ctrl_911_07082013_TTO_Aug1_Rot_7_sd2
(428/456) train vimp2_ctrl_911_07082013_TTO_Aug2_Rot_3_sd2
(429/456) train vimp2_ctrl_911_07082013_TTO_Aug3_Rot_5_sd2
(430/456) train vimp2_ctrl_911_07082013_TTO_Aug4_Rot_7_sd2
(431/456) train vimp2_ctrl_911_07082013_TTO_Aug5_Rot_2_sd2
(432/456) train vimp2_ctrl_918_07112013_TQ_Aug0_Rot_-7_sd2
(433/456) train vimp2_ctrl_918_07112013_TQ_Aug1_Rot_5_sd2
(434/456) train vimp2_ctrl_918_07112013_TQ_Aug2_Rot_5_sd2
(435/456) train vimp2_ctrl_918_07112013_TQ_Aug3_Rot_4_sd2
(436/456) train vimp2_ctrl_918_07112013_TQ_Aug4_Rot_5_sd2
(437/456) train vimp2_ctrl_918_07112013_TQ_Aug5_Rot_-4_sd2
(438/456) train vimp2_ctrl_920_07122013_SW_Aug0_Rot_7_sd2
(439/456) train vimp2_ctrl_920_07122013_SW_Aug1_Rot_-2_sd2
(440/456) train vimp2_ctrl_920_07122013_SW_Aug2_Rot_1_sd2
(441/456) train vimp2_ctrl_920_07122013_SW_Aug3_Rot_-7_sd2
(442/456) train vimp2_ctrl_920_07122013_SW_Aug4_Rot_-3_sd2
(443/456) train vimp2_ctrl_920_07122013_SW_Aug5_Rot_7_sd2
(444/456) train vimp2_ctrl_921_07122013_MP_Aug0_Rot_1_sd2
(445/456) train vimp2_ctrl_921_07122013_MP_Aug1_Rot_-7_sd2
(446/456) train vimp2_ctrl_921_07122013_MP_Aug2_Rot_6_sd2
(447/456) train vimp2_ctrl_921_07122013_MP_Aug3_Rot_-2_sd2
(448/456) train vimp2_ctrl_921_07122013_MP_Aug4_Rot_-5_sd2
(449/456) train vimp2_ctrl_921_07122013_MP_Aug5_Rot_6_sd2
(450/456) train vimp2_ctrl_925_07152013_LS_Aug0_Rot_2_sd2
(451/456) train vimp2_ctrl_925_07152013_LS_Aug1_Rot_5_sd2
(452/456) train vimp2_ctrl_925_07152013_LS_Aug2_Rot_2_sd2
(453/456) train vimp2_ctrl_925_07152013_LS_Aug3_Rot_5_sd2
(454/456) train vimp2_ctrl_925_07152013_LS_Aug4_Rot_-4_sd2
(455/456) train vimp2_ctrl_925_07152013_LS_Aug5_Rot_-3_sd22019-07-06 17:14:22.288796: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-06 17:14:24.635509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:05:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2019-07-06 17:14:24.635575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-06 17:14:25.010552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-06 17:14:25.010627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-06 17:14:25.010640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-06 17:14:25.011092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)
mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1’: File exists
mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1’: File exists
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using TensorFlow backend.
Loading train:   0%|          | 0/532 [00:00<?, ?it/s]Loading train:   0%|          | 1/532 [00:01<11:01,  1.25s/it]Loading train:   0%|          | 2/532 [00:02<10:01,  1.14s/it]Loading train:   1%|          | 3/532 [00:03<09:22,  1.06s/it]Loading train:   1%|          | 4/532 [00:03<08:36,  1.02it/s]Loading train:   1%|          | 5/532 [00:04<08:12,  1.07it/s]Loading train:   1%|          | 6/532 [00:05<07:37,  1.15it/s]Loading train:   1%|▏         | 7/532 [00:06<07:20,  1.19it/s]Loading train:   2%|▏         | 8/532 [00:06<07:02,  1.24it/s]Loading train:   2%|▏         | 9/532 [00:07<07:53,  1.10it/s]Loading train:   2%|▏         | 10/532 [00:08<07:34,  1.15it/s]Loading train:   2%|▏         | 11/532 [00:09<07:11,  1.21it/s]Loading train:   2%|▏         | 12/532 [00:10<07:51,  1.10it/s]Loading train:   2%|▏         | 13/532 [00:11<07:13,  1.20it/s]Loading train:   3%|▎         | 14/532 [00:11<06:53,  1.25it/s]Loading train:   3%|▎         | 15/532 [00:12<06:48,  1.27it/s]Loading train:   3%|▎         | 16/532 [00:13<07:08,  1.20it/s]Loading train:   3%|▎         | 17/532 [00:14<07:29,  1.15it/s]Loading train:   3%|▎         | 18/532 [00:15<07:49,  1.10it/s]Loading train:   4%|▎         | 19/532 [00:16<07:35,  1.13it/s]Loading train:   4%|▍         | 20/532 [00:17<07:53,  1.08it/s]Loading train:   4%|▍         | 21/532 [00:18<08:03,  1.06it/s]Loading train:   4%|▍         | 22/532 [00:19<07:34,  1.12it/s]Loading train:   4%|▍         | 23/532 [00:20<07:36,  1.12it/s]Loading train:   5%|▍         | 24/532 [00:20<07:23,  1.15it/s]Loading train:   5%|▍         | 25/532 [00:22<08:22,  1.01it/s]Loading train:   5%|▍         | 26/532 [00:23<08:13,  1.03it/s]Loading train:   5%|▌         | 27/532 [00:24<08:55,  1.06s/it]Loading train:   5%|▌         | 28/532 [00:25<08:24,  1.00s/it]Loading train:   5%|▌         | 29/532 [00:26<08:29,  1.01s/it]Loading train:   6%|▌         | 30/532 [00:27<07:56,  1.05it/s]Loading train:   6%|▌         | 31/532 [00:28<07:50,  1.06it/s]Loading train:   6%|▌         | 32/532 [00:29<08:04,  1.03it/s]Loading train:   6%|▌         | 33/532 [00:29<07:40,  1.08it/s]Loading train:   6%|▋         | 34/532 [00:30<07:52,  1.06it/s]Loading train:   7%|▋         | 35/532 [00:31<07:40,  1.08it/s]Loading train:   7%|▋         | 36/532 [00:32<07:39,  1.08it/s]Loading train:   7%|▋         | 37/532 [00:33<07:33,  1.09it/s]Loading train:   7%|▋         | 38/532 [00:34<07:46,  1.06it/s]Loading train:   7%|▋         | 39/532 [00:35<07:58,  1.03it/s]Loading train:   8%|▊         | 40/532 [00:36<07:29,  1.09it/s]Loading train:   8%|▊         | 41/532 [00:37<07:15,  1.13it/s]Loading train:   8%|▊         | 42/532 [00:38<07:12,  1.13it/s]Loading train:   8%|▊         | 43/532 [00:38<06:38,  1.23it/s]Loading train:   8%|▊         | 44/532 [00:39<06:04,  1.34it/s]Loading train:   8%|▊         | 45/532 [00:40<06:02,  1.34it/s]Loading train:   9%|▊         | 46/532 [00:41<06:41,  1.21it/s]Loading train:   9%|▉         | 47/532 [00:42<07:15,  1.11it/s]Loading train:   9%|▉         | 48/532 [00:43<07:30,  1.07it/s]Loading train:   9%|▉         | 49/532 [00:43<07:08,  1.13it/s]Loading train:   9%|▉         | 50/532 [00:45<07:30,  1.07it/s]Loading train:  10%|▉         | 51/532 [00:45<07:10,  1.12it/s]Loading train:  10%|▉         | 52/532 [00:46<07:13,  1.11it/s]Loading train:  10%|▉         | 53/532 [00:47<07:14,  1.10it/s]Loading train:  10%|█         | 54/532 [00:48<07:33,  1.05it/s]Loading train:  10%|█         | 55/532 [00:49<07:17,  1.09it/s]Loading train:  11%|█         | 56/532 [00:50<07:12,  1.10it/s]Loading train:  11%|█         | 57/532 [00:51<07:41,  1.03it/s]Loading train:  11%|█         | 58/532 [00:52<07:26,  1.06it/s]Loading train:  11%|█         | 59/532 [00:53<07:54,  1.00s/it]Loading train:  11%|█▏        | 60/532 [00:54<07:14,  1.09it/s]Loading train:  11%|█▏        | 61/532 [00:55<06:58,  1.13it/s]Loading train:  12%|█▏        | 62/532 [00:56<07:17,  1.07it/s]Loading train:  12%|█▏        | 63/532 [00:57<07:26,  1.05it/s]Loading train:  12%|█▏        | 64/532 [00:57<07:01,  1.11it/s]Loading train:  12%|█▏        | 65/532 [00:58<07:05,  1.10it/s]Loading train:  12%|█▏        | 66/532 [01:00<07:44,  1.00it/s]Loading train:  13%|█▎        | 67/532 [01:01<07:38,  1.01it/s]Loading train:  13%|█▎        | 68/532 [01:01<07:18,  1.06it/s]Loading train:  13%|█▎        | 69/532 [01:02<07:09,  1.08it/s]Loading train:  13%|█▎        | 70/532 [01:03<06:47,  1.13it/s]Loading train:  13%|█▎        | 71/532 [01:04<06:42,  1.15it/s]Loading train:  14%|█▎        | 72/532 [01:05<06:15,  1.23it/s]Loading train:  14%|█▎        | 73/532 [01:05<06:22,  1.20it/s]Loading train:  14%|█▍        | 74/532 [01:07<07:04,  1.08it/s]Loading train:  14%|█▍        | 75/532 [01:08<08:14,  1.08s/it]Loading train:  14%|█▍        | 76/532 [01:09<07:47,  1.03s/it]Loading train:  14%|█▍        | 77/532 [01:10<07:40,  1.01s/it]Loading train:  15%|█▍        | 78/532 [01:11<07:32,  1.00it/s]Loading train:  15%|█▍        | 79/532 [01:12<07:15,  1.04it/s]Loading train:  15%|█▌        | 80/532 [01:13<07:05,  1.06it/s]Loading train:  15%|█▌        | 81/532 [01:14<06:58,  1.08it/s]Loading train:  15%|█▌        | 82/532 [01:14<06:51,  1.09it/s]Loading train:  16%|█▌        | 83/532 [01:15<06:39,  1.12it/s]Loading train:  16%|█▌        | 84/532 [01:16<06:26,  1.16it/s]Loading train:  16%|█▌        | 85/532 [01:17<06:12,  1.20it/s]Loading train:  16%|█▌        | 86/532 [01:18<06:05,  1.22it/s]Loading train:  16%|█▋        | 87/532 [01:18<05:59,  1.24it/s]Loading train:  17%|█▋        | 88/532 [01:19<05:56,  1.25it/s]Loading train:  17%|█▋        | 89/532 [01:20<06:06,  1.21it/s]Loading train:  17%|█▋        | 90/532 [01:21<06:00,  1.23it/s]Loading train:  17%|█▋        | 91/532 [01:22<06:06,  1.20it/s]Loading train:  17%|█▋        | 92/532 [01:23<06:24,  1.14it/s]Loading train:  17%|█▋        | 93/532 [01:24<06:20,  1.15it/s]Loading train:  18%|█▊        | 94/532 [01:24<06:13,  1.17it/s]Loading train:  18%|█▊        | 95/532 [01:25<06:38,  1.10it/s]Loading train:  18%|█▊        | 96/532 [01:27<07:12,  1.01it/s]Loading train:  18%|█▊        | 97/532 [01:28<07:13,  1.00it/s]Loading train:  18%|█▊        | 98/532 [01:29<07:20,  1.01s/it]Loading train:  19%|█▊        | 99/532 [01:30<07:12,  1.00it/s]Loading train:  19%|█▉        | 100/532 [01:31<07:22,  1.02s/it]Loading train:  19%|█▉        | 101/532 [01:32<06:52,  1.04it/s]Loading train:  19%|█▉        | 102/532 [01:32<06:28,  1.11it/s]Loading train:  19%|█▉        | 103/532 [01:33<06:06,  1.17it/s]Loading train:  20%|█▉        | 104/532 [01:34<05:56,  1.20it/s]Loading train:  20%|█▉        | 105/532 [01:35<05:55,  1.20it/s]Loading train:  20%|█▉        | 106/532 [01:35<05:44,  1.24it/s]Loading train:  20%|██        | 107/532 [01:36<05:32,  1.28it/s]Loading train:  20%|██        | 108/532 [01:37<05:23,  1.31it/s]Loading train:  20%|██        | 109/532 [01:38<05:13,  1.35it/s]Loading train:  21%|██        | 110/532 [01:38<05:16,  1.34it/s]Loading train:  21%|██        | 111/532 [01:39<05:18,  1.32it/s]Loading train:  21%|██        | 112/532 [01:40<05:16,  1.33it/s]Loading train:  21%|██        | 113/532 [01:41<05:37,  1.24it/s]Loading train:  21%|██▏       | 114/532 [01:42<05:43,  1.22it/s]Loading train:  22%|██▏       | 115/532 [01:43<05:54,  1.18it/s]Loading train:  22%|██▏       | 116/532 [01:43<05:54,  1.17it/s]Loading train:  22%|██▏       | 117/532 [01:44<05:57,  1.16it/s]Loading train:  22%|██▏       | 118/532 [01:45<06:00,  1.15it/s]Loading train:  22%|██▏       | 119/532 [01:46<06:06,  1.13it/s]Loading train:  23%|██▎       | 120/532 [01:47<06:09,  1.11it/s]Loading train:  23%|██▎       | 121/532 [01:48<06:28,  1.06it/s]Loading train:  23%|██▎       | 122/532 [01:49<06:23,  1.07it/s]Loading train:  23%|██▎       | 123/532 [01:50<06:21,  1.07it/s]Loading train:  23%|██▎       | 124/532 [01:51<06:12,  1.10it/s]Loading train:  23%|██▎       | 125/532 [01:52<06:16,  1.08it/s]Loading train:  24%|██▎       | 126/532 [01:53<06:12,  1.09it/s]Loading train:  24%|██▍       | 127/532 [01:54<06:08,  1.10it/s]Loading train:  24%|██▍       | 128/532 [01:54<06:05,  1.11it/s]Loading train:  24%|██▍       | 129/532 [01:55<06:07,  1.10it/s]Loading train:  24%|██▍       | 130/532 [01:56<06:06,  1.10it/s]Loading train:  25%|██▍       | 131/532 [01:57<06:25,  1.04it/s]Loading train:  25%|██▍       | 132/532 [01:58<06:42,  1.01s/it]Loading train:  25%|██▌       | 133/532 [02:00<06:58,  1.05s/it]Loading train:  25%|██▌       | 134/532 [02:01<07:02,  1.06s/it]Loading train:  25%|██▌       | 135/532 [02:02<07:14,  1.10s/it]Loading train:  26%|██▌       | 136/532 [02:03<07:18,  1.11s/it]Loading train:  26%|██▌       | 137/532 [02:04<07:23,  1.12s/it]Loading train:  26%|██▌       | 138/532 [02:05<07:34,  1.15s/it]Loading train:  26%|██▌       | 139/532 [02:06<07:29,  1.14s/it]Loading train:  26%|██▋       | 140/532 [02:08<07:39,  1.17s/it]Loading train:  27%|██▋       | 141/532 [02:09<07:34,  1.16s/it]Loading train:  27%|██▋       | 142/532 [02:10<07:37,  1.17s/it]Loading train:  27%|██▋       | 143/532 [02:11<06:54,  1.07s/it]Loading train:  27%|██▋       | 144/532 [02:12<06:26,  1.00it/s]Loading train:  27%|██▋       | 145/532 [02:13<06:04,  1.06it/s]Loading train:  27%|██▋       | 146/532 [02:13<05:43,  1.12it/s]Loading train:  28%|██▊       | 147/532 [02:14<05:25,  1.18it/s]Loading train:  28%|██▊       | 148/532 [02:15<05:20,  1.20it/s]Loading train:  28%|██▊       | 149/532 [02:16<05:24,  1.18it/s]Loading train:  28%|██▊       | 150/532 [02:17<05:30,  1.16it/s]Loading train:  28%|██▊       | 151/532 [02:17<05:20,  1.19it/s]Loading train:  29%|██▊       | 152/532 [02:18<05:15,  1.20it/s]Loading train:  29%|██▉       | 153/532 [02:19<05:18,  1.19it/s]Loading train:  29%|██▉       | 154/532 [02:20<05:11,  1.21it/s]Loading train:  29%|██▉       | 155/532 [02:21<05:42,  1.10it/s]Loading train:  29%|██▉       | 156/532 [02:22<06:13,  1.01it/s]Loading train:  30%|██▉       | 157/532 [02:23<06:33,  1.05s/it]Loading train:  30%|██▉       | 158/532 [02:24<06:37,  1.06s/it]Loading train:  30%|██▉       | 159/532 [02:26<06:52,  1.10s/it]Loading train:  30%|███       | 160/532 [02:27<07:02,  1.14s/it]Loading train:  30%|███       | 161/532 [02:28<06:38,  1.07s/it]Loading train:  30%|███       | 162/532 [02:29<06:16,  1.02s/it]Loading train:  31%|███       | 163/532 [02:29<05:49,  1.05it/s]Loading train:  31%|███       | 164/532 [02:30<05:35,  1.10it/s]Loading train:  31%|███       | 165/532 [02:31<05:33,  1.10it/s]Loading train:  31%|███       | 166/532 [02:32<05:28,  1.11it/s]Loading train:  31%|███▏      | 167/532 [02:33<05:36,  1.08it/s]Loading train:  32%|███▏      | 168/532 [02:34<05:35,  1.09it/s]Loading train:  32%|███▏      | 169/532 [02:35<05:34,  1.08it/s]Loading train:  32%|███▏      | 170/532 [02:36<05:35,  1.08it/s]Loading train:  32%|███▏      | 171/532 [02:37<05:39,  1.06it/s]Loading train:  32%|███▏      | 172/532 [02:38<05:37,  1.07it/s]Loading train:  33%|███▎      | 173/532 [02:39<05:26,  1.10it/s]Loading train:  33%|███▎      | 174/532 [02:39<05:22,  1.11it/s]Loading train:  33%|███▎      | 175/532 [02:40<05:07,  1.16it/s]Loading train:  33%|███▎      | 176/532 [02:41<04:59,  1.19it/s]Loading train:  33%|███▎      | 177/532 [02:42<04:50,  1.22it/s]Loading train:  33%|███▎      | 178/532 [02:43<04:38,  1.27it/s]Loading train:  34%|███▎      | 179/532 [02:43<04:38,  1.27it/s]Loading train:  34%|███▍      | 180/532 [02:44<04:30,  1.30it/s]Loading train:  34%|███▍      | 181/532 [02:45<04:32,  1.29it/s]Loading train:  34%|███▍      | 182/532 [02:46<04:38,  1.26it/s]Loading train:  34%|███▍      | 183/532 [02:46<04:39,  1.25it/s]Loading train:  35%|███▍      | 184/532 [02:47<04:42,  1.23it/s]Loading train:  35%|███▍      | 185/532 [02:48<04:59,  1.16it/s]Loading train:  35%|███▍      | 186/532 [02:49<04:52,  1.18it/s]Loading train:  35%|███▌      | 187/532 [02:50<04:51,  1.18it/s]Loading train:  35%|███▌      | 188/532 [02:51<04:54,  1.17it/s]Loading train:  36%|███▌      | 189/532 [02:52<04:52,  1.17it/s]Loading train:  36%|███▌      | 190/532 [02:53<04:55,  1.16it/s]Loading train:  36%|███▌      | 191/532 [02:54<05:18,  1.07it/s]Loading train:  36%|███▌      | 192/532 [02:55<05:44,  1.01s/it]Loading train:  36%|███▋      | 193/532 [02:56<05:58,  1.06s/it]Loading train:  36%|███▋      | 194/532 [02:57<06:07,  1.09s/it]Loading train:  37%|███▋      | 195/532 [02:58<06:10,  1.10s/it]Loading train:  37%|███▋      | 196/532 [02:59<06:11,  1.11s/it]Loading train:  37%|███▋      | 197/532 [03:00<05:57,  1.07s/it]Loading train:  37%|███▋      | 198/532 [03:01<05:45,  1.03s/it]Loading train:  37%|███▋      | 199/532 [03:02<05:49,  1.05s/it]Loading train:  38%|███▊      | 200/532 [03:03<05:40,  1.03s/it]Loading train:  38%|███▊      | 201/532 [03:04<05:32,  1.00s/it]Loading train:  38%|███▊      | 202/532 [03:05<05:40,  1.03s/it]Loading train:  38%|███▊      | 203/532 [03:06<05:18,  1.03it/s]Loading train:  38%|███▊      | 204/532 [03:07<05:01,  1.09it/s]Loading train:  39%|███▊      | 205/532 [03:08<04:43,  1.15it/s]Loading train:  39%|███▊      | 206/532 [03:09<04:35,  1.18it/s]Loading train:  39%|███▉      | 207/532 [03:09<04:29,  1.21it/s]Loading train:  39%|███▉      | 208/532 [03:10<04:25,  1.22it/s]Loading train:  39%|███▉      | 209/532 [03:11<04:23,  1.22it/s]Loading train:  39%|███▉      | 210/532 [03:12<04:12,  1.28it/s]Loading train:  40%|███▉      | 211/532 [03:12<04:07,  1.30it/s]Loading train:  40%|███▉      | 212/532 [03:13<04:04,  1.31it/s]Loading train:  40%|████      | 213/532 [03:14<04:04,  1.31it/s]Loading train:  40%|████      | 214/532 [03:15<04:02,  1.31it/s]Loading train:  40%|████      | 215/532 [03:16<04:37,  1.14it/s]Loading train:  41%|████      | 216/532 [03:17<05:04,  1.04it/s]Loading train:  41%|████      | 217/532 [03:18<05:36,  1.07s/it]Loading train:  41%|████      | 218/532 [03:19<05:30,  1.05s/it]Loading train:  41%|████      | 219/532 [03:20<05:29,  1.05s/it]Loading train:  41%|████▏     | 220/532 [03:22<05:40,  1.09s/it]Loading train:  42%|████▏     | 221/532 [03:22<05:16,  1.02s/it]Loading train:  42%|████▏     | 222/532 [03:23<05:01,  1.03it/s]Loading train:  42%|████▏     | 223/532 [03:24<04:47,  1.07it/s]Loading train:  42%|████▏     | 224/532 [03:25<04:40,  1.10it/s]Loading train:  42%|████▏     | 225/532 [03:26<04:22,  1.17it/s]Loading train:  42%|████▏     | 226/532 [03:27<04:19,  1.18it/s]Loading train:  43%|████▎     | 227/532 [03:27<04:15,  1.19it/s]Loading train:  43%|████▎     | 228/532 [03:28<04:02,  1.26it/s]Loading train:  43%|████▎     | 229/532 [03:29<03:53,  1.30it/s]Loading train:  43%|████▎     | 230/532 [03:30<03:52,  1.30it/s]Loading train:  43%|████▎     | 231/532 [03:30<03:50,  1.31it/s]Loading train:  44%|████▎     | 232/532 [03:31<03:48,  1.31it/s]Loading train:  44%|████▍     | 233/532 [03:32<03:58,  1.25it/s]Loading train:  44%|████▍     | 234/532 [03:33<04:03,  1.22it/s]Loading train:  44%|████▍     | 235/532 [03:34<04:17,  1.15it/s]Loading train:  44%|████▍     | 236/532 [03:35<04:16,  1.15it/s]Loading train:  45%|████▍     | 237/532 [03:35<04:11,  1.17it/s]Loading train:  45%|████▍     | 238/532 [03:36<04:11,  1.17it/s]Loading train:  45%|████▍     | 239/532 [03:37<04:13,  1.15it/s]Loading train:  45%|████▌     | 240/532 [03:38<04:17,  1.13it/s]Loading train:  45%|████▌     | 241/532 [03:39<04:20,  1.12it/s]Loading train:  45%|████▌     | 242/532 [03:40<04:23,  1.10it/s]Loading train:  46%|████▌     | 243/532 [03:41<04:23,  1.10it/s]Loading train:  46%|████▌     | 244/532 [03:42<04:17,  1.12it/s]Loading train:  46%|████▌     | 245/532 [03:43<04:07,  1.16it/s]Loading train:  46%|████▌     | 246/532 [03:43<03:52,  1.23it/s]Loading train:  46%|████▋     | 247/532 [03:44<03:42,  1.28it/s]Loading train:  47%|████▋     | 248/532 [03:45<03:34,  1.33it/s]Loading train:  47%|████▋     | 249/532 [03:45<03:35,  1.31it/s]Loading train:  47%|████▋     | 250/532 [03:46<03:37,  1.30it/s]Loading train:  47%|████▋     | 251/532 [03:47<03:40,  1.27it/s]Loading train:  47%|████▋     | 252/532 [03:48<03:42,  1.26it/s]Loading train:  48%|████▊     | 253/532 [03:49<03:43,  1.25it/s]Loading train:  48%|████▊     | 254/532 [03:49<03:36,  1.28it/s]Loading train:  48%|████▊     | 255/532 [03:50<03:34,  1.29it/s]Loading train:  48%|████▊     | 256/532 [03:51<03:41,  1.25it/s]Loading train:  48%|████▊     | 257/532 [03:52<04:00,  1.14it/s]Loading train:  48%|████▊     | 258/532 [03:53<04:14,  1.08it/s]Loading train:  49%|████▊     | 259/532 [03:54<04:21,  1.04it/s]Loading train:  49%|████▉     | 260/532 [03:55<04:22,  1.03it/s]Loading train:  49%|████▉     | 261/532 [03:56<04:29,  1.01it/s]Loading train:  49%|████▉     | 262/532 [03:57<04:33,  1.01s/it]Loading train:  49%|████▉     | 263/532 [03:58<04:14,  1.06it/s]Loading train:  50%|████▉     | 264/532 [03:59<03:54,  1.14it/s]Loading train:  50%|████▉     | 265/532 [04:00<03:43,  1.20it/s]Loading train:  50%|█████     | 266/532 [04:00<03:30,  1.26it/s]Loading train:  50%|█████     | 267/532 [04:01<03:23,  1.30it/s]Loading train:  50%|█████     | 268/532 [04:02<03:14,  1.35it/s]Loading train:  51%|█████     | 269/532 [04:03<03:28,  1.26it/s]Loading train:  51%|█████     | 270/532 [04:03<03:31,  1.24it/s]Loading train:  51%|█████     | 271/532 [04:04<03:35,  1.21it/s]Loading train:  51%|█████     | 272/532 [04:05<03:35,  1.20it/s]Loading train:  51%|█████▏    | 273/532 [04:06<03:37,  1.19it/s]Loading train:  52%|█████▏    | 274/532 [04:07<03:36,  1.19it/s]Loading train:  52%|█████▏    | 275/532 [04:08<03:49,  1.12it/s]Loading train:  52%|█████▏    | 276/532 [04:09<04:12,  1.02it/s]Loading train:  52%|█████▏    | 277/532 [04:10<04:32,  1.07s/it]Loading train:  52%|█████▏    | 278/532 [04:11<04:31,  1.07s/it]Loading train:  52%|█████▏    | 279/532 [04:12<04:30,  1.07s/it]Loading train:  53%|█████▎    | 280/532 [04:13<04:28,  1.07s/it]Loading train:  53%|█████▎    | 281/532 [04:14<04:23,  1.05s/it]Loading train:  53%|█████▎    | 282/532 [04:15<04:20,  1.04s/it]Loading train:  53%|█████▎    | 283/532 [04:16<04:14,  1.02s/it]Loading train:  53%|█████▎    | 284/532 [04:17<04:09,  1.01s/it]Loading train:  54%|█████▎    | 285/532 [04:18<04:09,  1.01s/it]Loading train:  54%|█████▍    | 286/532 [04:19<04:10,  1.02s/it]Loading train:  54%|█████▍    | 287/532 [04:20<03:51,  1.06it/s]Loading train:  54%|█████▍    | 288/532 [04:21<03:39,  1.11it/s]Loading train:  54%|█████▍    | 289/532 [04:22<03:33,  1.14it/s]Loading train:  55%|█████▍    | 290/532 [04:23<03:25,  1.18it/s]Loading train:  55%|█████▍    | 291/532 [04:23<03:21,  1.20it/s]Loading train:  55%|█████▍    | 292/532 [04:24<03:16,  1.22it/s]Loading train:  55%|█████▌    | 293/532 [04:25<03:19,  1.20it/s]Loading train:  55%|█████▌    | 294/532 [04:26<03:24,  1.16it/s]Loading train:  55%|█████▌    | 295/532 [04:27<03:27,  1.14it/s]Loading train:  56%|█████▌    | 296/532 [04:28<03:29,  1.13it/s]Loading train:  56%|█████▌    | 297/532 [04:29<03:29,  1.12it/s]Loading train:  56%|█████▌    | 298/532 [04:30<03:32,  1.10it/s]Loading train:  56%|█████▌    | 299/532 [04:31<03:31,  1.10it/s]Loading train:  56%|█████▋    | 300/532 [04:31<03:21,  1.15it/s]Loading train:  57%|█████▋    | 301/532 [04:32<03:13,  1.19it/s]Loading train:  57%|█████▋    | 302/532 [04:33<03:10,  1.21it/s]Loading train:  57%|█████▋    | 303/532 [04:34<03:01,  1.26it/s]Loading train:  57%|█████▋    | 304/532 [04:34<02:58,  1.28it/s]Loading train:  57%|█████▋    | 305/532 [04:36<03:25,  1.11it/s]Loading train:  58%|█████▊    | 306/532 [04:37<03:39,  1.03it/s]Loading train:  58%|█████▊    | 307/532 [04:38<03:51,  1.03s/it]Loading train:  58%|█████▊    | 308/532 [04:39<04:00,  1.07s/it]Loading train:  58%|█████▊    | 309/532 [04:40<04:02,  1.09s/it]Loading train:  58%|█████▊    | 310/532 [04:41<04:04,  1.10s/it]Loading train:  58%|█████▊    | 311/532 [04:43<04:30,  1.22s/it]Loading train:  59%|█████▊    | 312/532 [04:44<04:40,  1.27s/it]Loading train:  59%|█████▉    | 313/532 [04:46<04:46,  1.31s/it]Loading train:  59%|█████▉    | 314/532 [04:47<04:48,  1.32s/it]Loading train:  59%|█████▉    | 315/532 [04:48<04:56,  1.36s/it]Loading train:  59%|█████▉    | 316/532 [04:50<04:54,  1.36s/it]Loading train:  60%|█████▉    | 317/532 [04:51<04:23,  1.23s/it]Loading train:  60%|█████▉    | 318/532 [04:52<03:54,  1.10s/it]Loading train:  60%|█████▉    | 319/532 [04:52<03:39,  1.03s/it]Loading train:  60%|██████    | 320/532 [04:53<03:24,  1.04it/s]Loading train:  60%|██████    | 321/532 [04:54<03:18,  1.06it/s]Loading train:  61%|██████    | 322/532 [04:55<03:19,  1.05it/s]Loading train:  61%|██████    | 323/532 [04:56<03:31,  1.01s/it]Loading train:  61%|██████    | 324/532 [04:57<03:37,  1.05s/it]Loading train:  61%|██████    | 325/532 [04:59<03:57,  1.15s/it]Loading train:  61%|██████▏   | 326/532 [05:00<03:58,  1.16s/it]Loading train:  61%|██████▏   | 327/532 [05:01<03:54,  1.14s/it]Loading train:  62%|██████▏   | 328/532 [05:02<03:51,  1.13s/it]Loading train:  62%|██████▏   | 329/532 [05:03<03:37,  1.07s/it]Loading train:  62%|██████▏   | 330/532 [05:04<03:23,  1.01s/it]Loading train:  62%|██████▏   | 331/532 [05:05<03:11,  1.05it/s]Loading train:  62%|██████▏   | 332/532 [05:06<03:05,  1.08it/s]Loading train:  63%|██████▎   | 333/532 [05:06<03:00,  1.10it/s]Loading train:  63%|██████▎   | 334/532 [05:07<02:52,  1.15it/s]Loading train:  63%|██████▎   | 335/532 [05:08<03:02,  1.08it/s]Loading train:  63%|██████▎   | 336/532 [05:09<03:09,  1.04it/s]Loading train:  63%|██████▎   | 337/532 [05:10<03:11,  1.02it/s]Loading train:  64%|██████▎   | 338/532 [05:11<03:12,  1.01it/s]Loading train:  64%|██████▎   | 339/532 [05:12<03:11,  1.01it/s]Loading train:  64%|██████▍   | 340/532 [05:13<03:09,  1.01it/s]Loading train:  64%|██████▍   | 341/532 [05:14<02:57,  1.07it/s]Loading train:  64%|██████▍   | 342/532 [05:15<02:49,  1.12it/s]Loading train:  64%|██████▍   | 343/532 [05:16<02:53,  1.09it/s]Loading train:  65%|██████▍   | 344/532 [05:17<02:48,  1.12it/s]Loading train:  65%|██████▍   | 345/532 [05:18<02:40,  1.16it/s]Loading train:  65%|██████▌   | 346/532 [05:18<02:37,  1.18it/s]Loading train:  65%|██████▌   | 347/532 [05:19<02:39,  1.16it/s]Loading train:  65%|██████▌   | 348/532 [05:20<02:37,  1.17it/s]Loading train:  66%|██████▌   | 349/532 [05:21<02:35,  1.17it/s]Loading train:  66%|██████▌   | 350/532 [05:22<02:33,  1.19it/s]Loading train:  66%|██████▌   | 351/532 [05:23<02:33,  1.18it/s]Loading train:  66%|██████▌   | 352/532 [05:23<02:29,  1.21it/s]Loading train:  66%|██████▋   | 353/532 [05:24<02:29,  1.20it/s]Loading train:  67%|██████▋   | 354/532 [05:25<02:25,  1.22it/s]Loading train:  67%|██████▋   | 355/532 [05:26<02:20,  1.26it/s]Loading train:  67%|██████▋   | 356/532 [05:27<02:17,  1.28it/s]Loading train:  67%|██████▋   | 357/532 [05:27<02:15,  1.29it/s]Loading train:  67%|██████▋   | 358/532 [05:28<02:14,  1.30it/s]Loading train:  67%|██████▋   | 359/532 [05:29<02:17,  1.25it/s]Loading train:  68%|██████▊   | 360/532 [05:30<02:13,  1.29it/s]Loading train:  68%|██████▊   | 361/532 [05:30<02:14,  1.27it/s]Loading train:  68%|██████▊   | 362/532 [05:31<02:21,  1.20it/s]Loading train:  68%|██████▊   | 363/532 [05:32<02:18,  1.22it/s]Loading train:  68%|██████▊   | 364/532 [05:33<02:17,  1.22it/s]Loading train:  69%|██████▊   | 365/532 [05:34<02:16,  1.23it/s]Loading train:  69%|██████▉   | 366/532 [05:35<02:15,  1.22it/s]Loading train:  69%|██████▉   | 367/532 [05:35<02:10,  1.27it/s]Loading train:  69%|██████▉   | 368/532 [05:36<02:11,  1.25it/s]Loading train:  69%|██████▉   | 369/532 [05:37<02:09,  1.26it/s]Loading train:  70%|██████▉   | 370/532 [05:38<02:06,  1.28it/s]Loading train:  70%|██████▉   | 371/532 [05:39<02:21,  1.14it/s]Loading train:  70%|██████▉   | 372/532 [05:40<02:28,  1.08it/s]Loading train:  70%|███████   | 373/532 [05:41<02:35,  1.03it/s]Loading train:  70%|███████   | 374/532 [05:42<02:38,  1.00s/it]Loading train:  70%|███████   | 375/532 [05:43<02:38,  1.01s/it]Loading train:  71%|███████   | 376/532 [05:44<02:37,  1.01s/it]Loading train:  71%|███████   | 377/532 [05:45<02:32,  1.02it/s]Loading train:  71%|███████   | 378/532 [05:46<02:26,  1.05it/s]Loading train:  71%|███████   | 379/532 [05:47<02:22,  1.07it/s]Loading train:  71%|███████▏  | 380/532 [05:48<02:18,  1.10it/s]Loading train:  72%|███████▏  | 381/532 [05:49<02:19,  1.08it/s]Loading train:  72%|███████▏  | 382/532 [05:49<02:14,  1.12it/s]Loading train:  72%|███████▏  | 383/532 [05:50<02:12,  1.13it/s]Loading train:  72%|███████▏  | 384/532 [05:51<02:10,  1.13it/s]Loading train:  72%|███████▏  | 385/532 [05:52<02:11,  1.12it/s]Loading train:  73%|███████▎  | 386/532 [05:53<02:08,  1.13it/s]Loading train:  73%|███████▎  | 387/532 [05:54<02:08,  1.12it/s]Loading train:  73%|███████▎  | 388/532 [05:55<02:05,  1.15it/s]Loading train:  73%|███████▎  | 389/532 [05:56<02:10,  1.09it/s]Loading train:  73%|███████▎  | 390/532 [05:57<02:13,  1.06it/s]Loading train:  73%|███████▎  | 391/532 [05:58<02:15,  1.04it/s]Loading train:  74%|███████▎  | 392/532 [05:59<02:16,  1.03it/s]Loading train:  74%|███████▍  | 393/532 [06:00<02:19,  1.00s/it]Loading train:  74%|███████▍  | 394/532 [06:01<02:16,  1.01it/s]Loading train:  74%|███████▍  | 395/532 [06:02<02:15,  1.01it/s]Loading train:  74%|███████▍  | 396/532 [06:03<02:15,  1.00it/s]Loading train:  75%|███████▍  | 397/532 [06:04<02:12,  1.02it/s]Loading train:  75%|███████▍  | 398/532 [06:05<02:10,  1.03it/s]Loading train:  75%|███████▌  | 399/532 [06:06<02:07,  1.05it/s]Loading train:  75%|███████▌  | 400/532 [06:06<02:07,  1.04it/s]Loading train:  75%|███████▌  | 401/532 [06:07<02:05,  1.04it/s]Loading train:  76%|███████▌  | 402/532 [06:08<02:04,  1.04it/s]Loading train:  76%|███████▌  | 403/532 [06:10<02:13,  1.03s/it]Loading train:  76%|███████▌  | 404/532 [06:11<02:10,  1.02s/it]Loading train:  76%|███████▌  | 405/532 [06:12<02:07,  1.01s/it]Loading train:  76%|███████▋  | 406/532 [06:13<02:05,  1.01it/s]Loading train:  77%|███████▋  | 407/532 [06:13<01:58,  1.05it/s]Loading train:  77%|███████▋  | 408/532 [06:14<01:53,  1.09it/s]Loading train:  77%|███████▋  | 409/532 [06:15<01:47,  1.14it/s]Loading train:  77%|███████▋  | 410/532 [06:16<01:45,  1.15it/s]Loading train:  77%|███████▋  | 411/532 [06:17<01:43,  1.17it/s]Loading train:  77%|███████▋  | 412/532 [06:18<01:42,  1.18it/s]Loading train:  78%|███████▊  | 413/532 [06:18<01:39,  1.19it/s]Loading train:  78%|███████▊  | 414/532 [06:19<01:35,  1.24it/s]Loading train:  78%|███████▊  | 415/532 [06:20<01:38,  1.18it/s]Loading train:  78%|███████▊  | 416/532 [06:21<01:36,  1.21it/s]Loading train:  78%|███████▊  | 417/532 [06:22<01:37,  1.17it/s]Loading train:  79%|███████▊  | 418/532 [06:23<01:38,  1.16it/s]Loading train:  79%|███████▉  | 419/532 [06:24<01:43,  1.10it/s]Loading train:  79%|███████▉  | 420/532 [06:25<01:42,  1.09it/s]Loading train:  79%|███████▉  | 421/532 [06:25<01:41,  1.09it/s]Loading train:  79%|███████▉  | 422/532 [06:26<01:41,  1.08it/s]Loading train:  80%|███████▉  | 423/532 [06:28<01:47,  1.01it/s]Loading train:  80%|███████▉  | 424/532 [06:28<01:43,  1.04it/s]Loading train:  80%|███████▉  | 425/532 [06:29<01:42,  1.04it/s]Loading train:  80%|████████  | 426/532 [06:30<01:40,  1.06it/s]Loading train:  80%|████████  | 427/532 [06:31<01:41,  1.04it/s]Loading train:  80%|████████  | 428/532 [06:32<01:38,  1.05it/s]Loading train:  81%|████████  | 429/532 [06:33<01:39,  1.04it/s]Loading train:  81%|████████  | 430/532 [06:34<01:39,  1.03it/s]Loading train:  81%|████████  | 431/532 [06:35<01:41,  1.01s/it]Loading train:  81%|████████  | 432/532 [06:36<01:39,  1.00it/s]Loading train:  81%|████████▏ | 433/532 [06:37<01:37,  1.02it/s]Loading train:  82%|████████▏ | 434/532 [06:38<01:35,  1.02it/s]Loading train:  82%|████████▏ | 435/532 [06:39<01:34,  1.03it/s]Loading train:  82%|████████▏ | 436/532 [06:40<01:34,  1.01it/s]Loading train:  82%|████████▏ | 437/532 [06:41<01:27,  1.09it/s]Loading train:  82%|████████▏ | 438/532 [06:42<01:23,  1.13it/s]Loading train:  83%|████████▎ | 439/532 [06:43<01:19,  1.16it/s]Loading train:  83%|████████▎ | 440/532 [06:43<01:14,  1.23it/s]Loading train:  83%|████████▎ | 441/532 [06:44<01:12,  1.26it/s]Loading train:  83%|████████▎ | 442/532 [06:45<01:09,  1.29it/s]Loading train:  83%|████████▎ | 443/532 [06:45<01:08,  1.29it/s]Loading train:  83%|████████▎ | 444/532 [06:46<01:07,  1.31it/s]Loading train:  84%|████████▎ | 445/532 [06:47<01:05,  1.32it/s]Loading train:  84%|████████▍ | 446/532 [06:48<01:05,  1.31it/s]Loading train:  84%|████████▍ | 447/532 [06:48<01:03,  1.34it/s]Loading train:  84%|████████▍ | 448/532 [06:49<01:02,  1.34it/s]Loading train:  84%|████████▍ | 449/532 [06:50<01:03,  1.30it/s]Loading train:  85%|████████▍ | 450/532 [06:51<01:03,  1.29it/s]Loading train:  85%|████████▍ | 451/532 [06:52<01:06,  1.23it/s]Loading train:  85%|████████▍ | 452/532 [06:53<01:08,  1.17it/s]Loading train:  85%|████████▌ | 453/532 [06:53<01:06,  1.19it/s]Loading train:  85%|████████▌ | 454/532 [06:54<01:06,  1.18it/s]Loading train:  86%|████████▌ | 455/532 [06:55<01:08,  1.13it/s]Loading train:  86%|████████▌ | 456/532 [06:56<01:08,  1.11it/s]Loading train:  86%|████████▌ | 457/532 [06:57<01:06,  1.13it/s]Loading train:  86%|████████▌ | 458/532 [06:58<01:04,  1.14it/s]Loading train:  86%|████████▋ | 459/532 [06:59<01:11,  1.03it/s]Loading train:  86%|████████▋ | 460/532 [07:00<01:11,  1.00it/s]Loading train:  87%|████████▋ | 461/532 [07:01<01:13,  1.03s/it]Loading train:  87%|████████▋ | 462/532 [07:02<01:12,  1.04s/it]Loading train:  87%|████████▋ | 463/532 [07:03<01:12,  1.06s/it]Loading train:  87%|████████▋ | 464/532 [07:04<01:11,  1.05s/it]Loading train:  87%|████████▋ | 465/532 [07:06<01:11,  1.07s/it]Loading train:  88%|████████▊ | 466/532 [07:07<01:13,  1.11s/it]Loading train:  88%|████████▊ | 467/532 [07:08<01:08,  1.05s/it]Loading train:  88%|████████▊ | 468/532 [07:09<01:04,  1.01s/it]Loading train:  88%|████████▊ | 469/532 [07:10<01:03,  1.01s/it]Loading train:  88%|████████▊ | 470/532 [07:11<01:01,  1.01it/s]Loading train:  89%|████████▊ | 471/532 [07:11<00:57,  1.06it/s]Loading train:  89%|████████▊ | 472/532 [07:12<00:55,  1.09it/s]Loading train:  89%|████████▉ | 473/532 [07:13<00:55,  1.07it/s]Loading train:  89%|████████▉ | 474/532 [07:14<00:55,  1.05it/s]Loading train:  89%|████████▉ | 475/532 [07:15<00:53,  1.07it/s]Loading train:  89%|████████▉ | 476/532 [07:16<00:51,  1.08it/s]Loading train:  90%|████████▉ | 477/532 [07:17<00:51,  1.06it/s]Loading train:  90%|████████▉ | 478/532 [07:18<00:51,  1.05it/s]Loading train:  90%|█████████ | 479/532 [07:19<00:48,  1.10it/s]Loading train:  90%|█████████ | 480/532 [07:20<00:45,  1.15it/s]Loading train:  90%|█████████ | 481/532 [07:20<00:43,  1.16it/s]Loading train:  91%|█████████ | 482/532 [07:21<00:42,  1.18it/s]Loading train:  91%|█████████ | 483/532 [07:22<00:40,  1.21it/s]Loading train:  91%|█████████ | 484/532 [07:23<00:38,  1.25it/s]Loading train:  91%|█████████ | 485/532 [07:24<00:43,  1.09it/s]Loading train:  91%|█████████▏| 486/532 [07:25<00:44,  1.03it/s]Loading train:  92%|█████████▏| 487/532 [07:26<00:43,  1.03it/s]Loading train:  92%|█████████▏| 488/532 [07:27<00:43,  1.02it/s]Loading train:  92%|█████████▏| 489/532 [07:28<00:42,  1.00it/s]Loading train:  92%|█████████▏| 490/532 [07:29<00:42,  1.02s/it]Loading train:  92%|█████████▏| 491/532 [07:30<00:39,  1.03it/s]Loading train:  92%|█████████▏| 492/532 [07:31<00:38,  1.04it/s]Loading train:  93%|█████████▎| 493/532 [07:32<00:36,  1.06it/s]Loading train:  93%|█████████▎| 494/532 [07:33<00:35,  1.07it/s]Loading train:  93%|█████████▎| 495/532 [07:34<00:32,  1.13it/s]Loading train:  93%|█████████▎| 496/532 [07:35<00:33,  1.09it/s]Loading train:  93%|█████████▎| 497/532 [07:35<00:32,  1.06it/s]Loading train:  94%|█████████▎| 498/532 [07:36<00:31,  1.07it/s]Loading train:  94%|█████████▍| 499/532 [07:37<00:30,  1.08it/s]Loading train:  94%|█████████▍| 500/532 [07:38<00:29,  1.09it/s]Loading train:  94%|█████████▍| 501/532 [07:39<00:27,  1.13it/s]Loading train:  94%|█████████▍| 502/532 [07:40<00:27,  1.07it/s]Loading train:  95%|█████████▍| 503/532 [07:41<00:26,  1.10it/s]Loading train:  95%|█████████▍| 504/532 [07:42<00:24,  1.14it/s]Loading train:  95%|█████████▍| 505/532 [07:43<00:23,  1.17it/s]Loading train:  95%|█████████▌| 506/532 [07:43<00:22,  1.17it/s]Loading train:  95%|█████████▌| 507/532 [07:44<00:20,  1.20it/s]Loading train:  95%|█████████▌| 508/532 [07:45<00:19,  1.21it/s]Loading train:  96%|█████████▌| 509/532 [07:46<00:20,  1.12it/s]Loading train:  96%|█████████▌| 510/532 [07:47<00:20,  1.08it/s]Loading train:  96%|█████████▌| 511/532 [07:48<00:20,  1.04it/s]Loading train:  96%|█████████▌| 512/532 [07:49<00:19,  1.02it/s]Loading train:  96%|█████████▋| 513/532 [07:50<00:18,  1.03it/s]Loading train:  97%|█████████▋| 514/532 [07:51<00:17,  1.02it/s]Loading train:  97%|█████████▋| 515/532 [07:52<00:17,  1.00s/it]Loading train:  97%|█████████▋| 516/532 [07:53<00:15,  1.02it/s]Loading train:  97%|█████████▋| 517/532 [07:54<00:14,  1.05it/s]Loading train:  97%|█████████▋| 518/532 [07:55<00:12,  1.09it/s]Loading train:  98%|█████████▊| 519/532 [07:56<00:11,  1.12it/s]Loading train:  98%|█████████▊| 520/532 [07:56<00:10,  1.14it/s]Loading train:  98%|█████████▊| 521/532 [07:57<00:09,  1.14it/s]Loading train:  98%|█████████▊| 522/532 [07:58<00:08,  1.14it/s]Loading train:  98%|█████████▊| 523/532 [07:59<00:07,  1.16it/s]Loading train:  98%|█████████▊| 524/532 [08:00<00:07,  1.13it/s]Loading train:  99%|█████████▊| 525/532 [08:01<00:06,  1.15it/s]Loading train:  99%|█████████▉| 526/532 [08:02<00:05,  1.14it/s]Loading train:  99%|█████████▉| 527/532 [08:03<00:04,  1.13it/s]Loading train:  99%|█████████▉| 528/532 [08:03<00:03,  1.16it/s]Loading train:  99%|█████████▉| 529/532 [08:04<00:02,  1.19it/s]Loading train: 100%|█████████▉| 530/532 [08:05<00:01,  1.25it/s]Loading train: 100%|█████████▉| 531/532 [08:06<00:00,  1.25it/s]Loading train: 100%|██████████| 532/532 [08:07<00:00,  1.24it/s]
concatenating: train:   0%|          | 0/532 [00:00<?, ?it/s]concatenating: train:   1%|          | 5/532 [00:00<00:12, 41.32it/s]concatenating: train:   3%|▎         | 17/532 [00:00<00:10, 51.03it/s]concatenating: train:   6%|▋         | 34/532 [00:00<00:07, 63.96it/s]concatenating: train:  10%|▉         | 52/532 [00:00<00:06, 78.62it/s]concatenating: train:  13%|█▎        | 71/532 [00:00<00:04, 95.32it/s]concatenating: train:  16%|█▋        | 87/532 [00:00<00:04, 108.32it/s]concatenating: train:  20%|█▉        | 106/532 [00:00<00:03, 123.78it/s]concatenating: train:  23%|██▎       | 123/532 [00:00<00:03, 133.42it/s]concatenating: train:  27%|██▋       | 142/532 [00:00<00:02, 143.02it/s]concatenating: train:  30%|██▉       | 159/532 [00:01<00:02, 148.52it/s]concatenating: train:  33%|███▎      | 176/532 [00:01<00:02, 143.72it/s]concatenating: train:  37%|███▋      | 197/532 [00:01<00:02, 157.90it/s]concatenating: train:  42%|████▏     | 223/532 [00:01<00:01, 177.60it/s]concatenating: train:  47%|████▋     | 248/532 [00:01<00:01, 193.31it/s]concatenating: train:  52%|█████▏    | 274/532 [00:01<00:01, 207.07it/s]concatenating: train:  56%|█████▌    | 299/532 [00:01<00:01, 218.12it/s]concatenating: train:  61%|██████    | 325/532 [00:01<00:00, 227.56it/s]concatenating: train:  66%|██████▌   | 350/532 [00:01<00:00, 231.20it/s]concatenating: train:  70%|███████   | 375/532 [00:02<00:00, 236.15it/s]concatenating: train:  75%|███████▌  | 400/532 [00:02<00:00, 235.14it/s]concatenating: train:  80%|████████  | 427/532 [00:02<00:00, 241.97it/s]concatenating: train:  85%|████████▌ | 453/532 [00:02<00:00, 245.24it/s]concatenating: train:  90%|█████████ | 479/532 [00:02<00:00, 247.83it/s]concatenating: train:  95%|█████████▍| 504/532 [00:02<00:00, 245.38it/s]concatenating: train: 100%|█████████▉| 530/532 [00:02<00:00, 248.65it/s]concatenating: train: 100%|██████████| 532/532 [00:02<00:00, 201.37it/s]
Loading test:   0%|          | 0/15 [00:00<?, ?it/s]Loading test:   7%|▋         | 1/15 [00:00<00:11,  1.23it/s]Loading test:  13%|█▎        | 2/15 [00:01<00:10,  1.24it/s]Loading test:  20%|██        | 3/15 [00:02<00:10,  1.16it/s]Loading test:  27%|██▋       | 4/15 [00:03<00:09,  1.15it/s]Loading test:  33%|███▎      | 5/15 [00:04<00:09,  1.05it/s]Loading test:  40%|████      | 6/15 [00:05<00:09,  1.02s/it]Loading test:  47%|████▋     | 7/15 [00:06<00:08,  1.00s/it]Loading test:  53%|█████▎    | 8/15 [00:08<00:07,  1.08s/it]Loading test:  60%|██████    | 9/15 [00:08<00:06,  1.03s/it]Loading test:  67%|██████▋   | 10/15 [00:09<00:04,  1.02it/s]Loading test:  73%|███████▎  | 11/15 [00:10<00:03,  1.06it/s]Loading test:  80%|████████  | 12/15 [00:11<00:02,  1.03it/s]Loading test:  87%|████████▋ | 13/15 [00:12<00:01,  1.00it/s]Loading test:  93%|█████████▎| 14/15 [00:13<00:00,  1.07it/s]Loading test: 100%|██████████| 15/15 [00:14<00:00,  1.08it/s]
concatenating: validation:   0%|          | 0/15 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 15/15 [00:00<00:00, 169.97it/s]
(0/4) test vimp2_ctrl_991_08302013_JF
(1/4) test vimp2_967_08132013_KW
(2/4) test vimp2_765_04162013_AW
(3/4) test vimp2_ANON695_03132013
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 56, 84, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 56, 84, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 56, 84, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 56, 84, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 56, 84, 10)   910         activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 84, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 56, 84, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 56, 84, 11)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 28, 42, 11)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28, 42, 11)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 42, 20)   2000        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 42, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 42, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 42, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 28, 42, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 28, 42, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 42, 31)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 21, 31)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 14, 21, 31)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 14, 21, 40)   11200       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 14, 21, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 14, 21, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 14, 21, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 14, 21, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 14, 21, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 14, 21, 71)   0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 14, 21, 71)   0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 28, 42, 20)   5700        dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 28, 42, 51)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 28, 42, 20)   9200        concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 28, 42, 20)   80          conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 28, 42, 20)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 28, 42, 20)   3620        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 28, 42, 20)   80          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 28, 42, 20)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 28, 42, 71)   0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 28, 42, 71)   0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 56, 84, 10)   2850        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 84, 21)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 56, 84, 10)   1900        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 56, 84, 10)   40          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 84, 10)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 56, 84, 10)   910         activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 56, 84, 10)   40          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 84, 10)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 84, 31)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 56, 84, 31)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 56, 84, 13)   416         dropout_5[0][0]                  
==================================================================================================
Total params: 57,666
Trainable params: 57,266
Non-trainable params: 400
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.53383120e-02 2.88786827e-02 1.16652967e-01 1.00133292e-02
 3.03165963e-02 5.79538965e-03 6.85058777e-02 1.28145429e-01
 7.55135052e-02 1.22435092e-02 2.73464902e-01 1.84941443e-01
 1.90056842e-04]
Train on 20749 samples, validate on 584 samples
Epoch 1/300
 - 26s - loss: 62.7980 - acc: 0.6741 - mDice: 0.0167 - val_loss: 4.7181 - val_acc: 0.9134 - val_mDice: 0.0220

Epoch 00001: val_mDice improved from -inf to 0.02197, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 16s - loss: 6.7406 - acc: 0.8978 - mDice: 0.0318 - val_loss: 3.9763 - val_acc: 0.9134 - val_mDice: 0.0399

Epoch 00002: val_mDice improved from 0.02197 to 0.03990, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 16s - loss: 5.1529 - acc: 0.8986 - mDice: 0.0468 - val_loss: 3.6039 - val_acc: 0.9129 - val_mDice: 0.0701

Epoch 00003: val_mDice improved from 0.03990 to 0.07006, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 16s - loss: 4.4989 - acc: 0.8993 - mDice: 0.0662 - val_loss: 3.2817 - val_acc: 0.9143 - val_mDice: 0.0939

Epoch 00004: val_mDice improved from 0.07006 to 0.09391, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 15s - loss: 4.0050 - acc: 0.9015 - mDice: 0.0952 - val_loss: 2.9519 - val_acc: 0.9149 - val_mDice: 0.1256

Epoch 00005: val_mDice improved from 0.09391 to 0.12558, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 16s - loss: 3.5703 - acc: 0.9066 - mDice: 0.1312 - val_loss: 2.5794 - val_acc: 0.9243 - val_mDice: 0.1780

Epoch 00006: val_mDice improved from 0.12558 to 0.17798, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 15s - loss: 3.1953 - acc: 0.9129 - mDice: 0.1741 - val_loss: 2.2686 - val_acc: 0.9328 - val_mDice: 0.2457

Epoch 00007: val_mDice improved from 0.17798 to 0.24565, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 16s - loss: 2.9081 - acc: 0.9190 - mDice: 0.2191 - val_loss: 1.9387 - val_acc: 0.9504 - val_mDice: 0.3158

Epoch 00008: val_mDice improved from 0.24565 to 0.31575, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 9/300
 - 15s - loss: 2.7071 - acc: 0.9240 - mDice: 0.2527 - val_loss: 1.7465 - val_acc: 0.9559 - val_mDice: 0.3709

Epoch 00009: val_mDice improved from 0.31575 to 0.37088, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 17s - loss: 2.5575 - acc: 0.9272 - mDice: 0.2780 - val_loss: 1.6531 - val_acc: 0.9574 - val_mDice: 0.3978

Epoch 00010: val_mDice improved from 0.37088 to 0.39776, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 11/300
 - 15s - loss: 2.4495 - acc: 0.9291 - mDice: 0.2977 - val_loss: 1.6261 - val_acc: 0.9578 - val_mDice: 0.4137

Epoch 00011: val_mDice improved from 0.39776 to 0.41373, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 12/300
 - 16s - loss: 2.3317 - acc: 0.9312 - mDice: 0.3187 - val_loss: 1.5228 - val_acc: 0.9601 - val_mDice: 0.4401

Epoch 00012: val_mDice improved from 0.41373 to 0.44013, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 13/300
 - 15s - loss: 2.2364 - acc: 0.9327 - mDice: 0.3366 - val_loss: 1.4346 - val_acc: 0.9631 - val_mDice: 0.4601

Epoch 00013: val_mDice improved from 0.44013 to 0.46014, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 14/300
 - 16s - loss: 2.1517 - acc: 0.9343 - mDice: 0.3532 - val_loss: 1.3703 - val_acc: 0.9630 - val_mDice: 0.4863

Epoch 00014: val_mDice improved from 0.46014 to 0.48631, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 15/300
 - 15s - loss: 2.0501 - acc: 0.9363 - mDice: 0.3748 - val_loss: 1.3313 - val_acc: 0.9647 - val_mDice: 0.5042

Epoch 00015: val_mDice improved from 0.48631 to 0.50419, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 16/300
 - 16s - loss: 1.9498 - acc: 0.9383 - mDice: 0.3993 - val_loss: 1.2274 - val_acc: 0.9656 - val_mDice: 0.5408

Epoch 00016: val_mDice improved from 0.50419 to 0.54084, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 17/300
 - 15s - loss: 1.8662 - acc: 0.9403 - mDice: 0.4200 - val_loss: 1.1446 - val_acc: 0.9679 - val_mDice: 0.5605

Epoch 00017: val_mDice improved from 0.54084 to 0.56046, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 18/300
 - 16s - loss: 1.7989 - acc: 0.9416 - mDice: 0.4355 - val_loss: 1.1616 - val_acc: 0.9675 - val_mDice: 0.5636

Epoch 00018: val_mDice improved from 0.56046 to 0.56357, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 19/300
 - 15s - loss: 1.7332 - acc: 0.9428 - mDice: 0.4526 - val_loss: 1.0787 - val_acc: 0.9692 - val_mDice: 0.5893

Epoch 00019: val_mDice improved from 0.56357 to 0.58933, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 20/300
 - 16s - loss: 1.6836 - acc: 0.9437 - mDice: 0.4649 - val_loss: 1.0603 - val_acc: 0.9701 - val_mDice: 0.5976

Epoch 00020: val_mDice improved from 0.58933 to 0.59758, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 21/300
 - 16s - loss: 1.6373 - acc: 0.9446 - mDice: 0.4766 - val_loss: 1.0351 - val_acc: 0.9690 - val_mDice: 0.6094

Epoch 00021: val_mDice improved from 0.59758 to 0.60935, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 22/300
 - 16s - loss: 1.5937 - acc: 0.9456 - mDice: 0.4875 - val_loss: 1.0163 - val_acc: 0.9697 - val_mDice: 0.6162

Epoch 00022: val_mDice improved from 0.60935 to 0.61623, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 23/300
 - 16s - loss: 1.5618 - acc: 0.9463 - mDice: 0.4965 - val_loss: 1.0016 - val_acc: 0.9715 - val_mDice: 0.6216

Epoch 00023: val_mDice improved from 0.61623 to 0.62158, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 24/300
 - 15s - loss: 1.5213 - acc: 0.9473 - mDice: 0.5066 - val_loss: 0.9868 - val_acc: 0.9703 - val_mDice: 0.6267

Epoch 00024: val_mDice improved from 0.62158 to 0.62673, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 25/300
 - 16s - loss: 1.4918 - acc: 0.9480 - mDice: 0.5149 - val_loss: 0.9754 - val_acc: 0.9717 - val_mDice: 0.6392

Epoch 00025: val_mDice improved from 0.62673 to 0.63919, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 26/300
 - 15s - loss: 1.4661 - acc: 0.9485 - mDice: 0.5222 - val_loss: 0.9699 - val_acc: 0.9715 - val_mDice: 0.6347

Epoch 00026: val_mDice did not improve from 0.63919
Epoch 27/300
 - 16s - loss: 1.4394 - acc: 0.9491 - mDice: 0.5293 - val_loss: 0.9473 - val_acc: 0.9711 - val_mDice: 0.6432

Epoch 00027: val_mDice improved from 0.63919 to 0.64321, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 28/300
 - 15s - loss: 1.4118 - acc: 0.9498 - mDice: 0.5365 - val_loss: 0.9311 - val_acc: 0.9725 - val_mDice: 0.6508

Epoch 00028: val_mDice improved from 0.64321 to 0.65078, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 29/300
 - 16s - loss: 1.3897 - acc: 0.9504 - mDice: 0.5431 - val_loss: 0.9229 - val_acc: 0.9723 - val_mDice: 0.6519

Epoch 00029: val_mDice improved from 0.65078 to 0.65194, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 30/300
 - 15s - loss: 1.3707 - acc: 0.9507 - mDice: 0.5485 - val_loss: 0.9119 - val_acc: 0.9720 - val_mDice: 0.6583

Epoch 00030: val_mDice improved from 0.65194 to 0.65833, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 31/300
 - 16s - loss: 1.3484 - acc: 0.9513 - mDice: 0.5555 - val_loss: 0.9039 - val_acc: 0.9722 - val_mDice: 0.6656

Epoch 00031: val_mDice improved from 0.65833 to 0.66565, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 32/300
 - 15s - loss: 1.3291 - acc: 0.9517 - mDice: 0.5609 - val_loss: 0.9076 - val_acc: 0.9730 - val_mDice: 0.6648

Epoch 00032: val_mDice did not improve from 0.66565
Epoch 33/300
 - 16s - loss: 1.3143 - acc: 0.9521 - mDice: 0.5656 - val_loss: 0.8683 - val_acc: 0.9736 - val_mDice: 0.6752

Epoch 00033: val_mDice improved from 0.66565 to 0.67519, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 34/300
 - 15s - loss: 1.3019 - acc: 0.9524 - mDice: 0.5698 - val_loss: 0.8755 - val_acc: 0.9733 - val_mDice: 0.6755

Epoch 00034: val_mDice improved from 0.67519 to 0.67547, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 35/300
 - 16s - loss: 1.2862 - acc: 0.9528 - mDice: 0.5747 - val_loss: 0.8839 - val_acc: 0.9728 - val_mDice: 0.6735

Epoch 00035: val_mDice did not improve from 0.67547
Epoch 36/300
 - 15s - loss: 1.2699 - acc: 0.9531 - mDice: 0.5796 - val_loss: 0.8644 - val_acc: 0.9741 - val_mDice: 0.6828

Epoch 00036: val_mDice improved from 0.67547 to 0.68284, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 37/300
 - 17s - loss: 1.2496 - acc: 0.9536 - mDice: 0.5855 - val_loss: 0.8508 - val_acc: 0.9738 - val_mDice: 0.6851

Epoch 00037: val_mDice improved from 0.68284 to 0.68514, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 38/300
 - 15s - loss: 1.2366 - acc: 0.9539 - mDice: 0.5900 - val_loss: 0.8532 - val_acc: 0.9736 - val_mDice: 0.6877

Epoch 00038: val_mDice improved from 0.68514 to 0.68774, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 39/300
 - 17s - loss: 1.2260 - acc: 0.9541 - mDice: 0.5934 - val_loss: 0.8719 - val_acc: 0.9731 - val_mDice: 0.6838

Epoch 00039: val_mDice did not improve from 0.68774
Epoch 40/300
 - 15s - loss: 1.2112 - acc: 0.9544 - mDice: 0.5982 - val_loss: 0.8610 - val_acc: 0.9739 - val_mDice: 0.6849

Epoch 00040: val_mDice did not improve from 0.68774
Epoch 41/300
 - 16s - loss: 1.2035 - acc: 0.9546 - mDice: 0.6004 - val_loss: 0.8338 - val_acc: 0.9746 - val_mDice: 0.6969

Epoch 00041: val_mDice improved from 0.68774 to 0.69694, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 42/300
 - 15s - loss: 1.1952 - acc: 0.9548 - mDice: 0.6033 - val_loss: 0.8520 - val_acc: 0.9739 - val_mDice: 0.6945

Epoch 00042: val_mDice did not improve from 0.69694
Epoch 43/300
 - 16s - loss: 1.1808 - acc: 0.9553 - mDice: 0.6080 - val_loss: 0.8360 - val_acc: 0.9753 - val_mDice: 0.6986

Epoch 00043: val_mDice improved from 0.69694 to 0.69855, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 44/300
 - 15s - loss: 1.1664 - acc: 0.9556 - mDice: 0.6123 - val_loss: 0.8247 - val_acc: 0.9750 - val_mDice: 0.7030

Epoch 00044: val_mDice improved from 0.69855 to 0.70296, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 45/300
 - 16s - loss: 1.1624 - acc: 0.9557 - mDice: 0.6143 - val_loss: 0.8360 - val_acc: 0.9749 - val_mDice: 0.6973

Epoch 00045: val_mDice did not improve from 0.70296
Epoch 46/300
 - 15s - loss: 1.1513 - acc: 0.9559 - mDice: 0.6172 - val_loss: 0.8220 - val_acc: 0.9751 - val_mDice: 0.7029

Epoch 00046: val_mDice did not improve from 0.70296
Epoch 47/300
 - 16s - loss: 1.1395 - acc: 0.9562 - mDice: 0.6210 - val_loss: 0.8249 - val_acc: 0.9750 - val_mDice: 0.7034

Epoch 00047: val_mDice improved from 0.70296 to 0.70344, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 48/300
 - 15s - loss: 1.1329 - acc: 0.9564 - mDice: 0.6231 - val_loss: 0.8194 - val_acc: 0.9752 - val_mDice: 0.7030

Epoch 00048: val_mDice did not improve from 0.70344
Epoch 49/300
 - 16s - loss: 1.1257 - acc: 0.9565 - mDice: 0.6251 - val_loss: 0.8025 - val_acc: 0.9748 - val_mDice: 0.7109

Epoch 00049: val_mDice improved from 0.70344 to 0.71087, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 50/300
 - 15s - loss: 1.1211 - acc: 0.9567 - mDice: 0.6268 - val_loss: 0.8201 - val_acc: 0.9745 - val_mDice: 0.7032

Epoch 00050: val_mDice did not improve from 0.71087
Epoch 51/300
 - 16s - loss: 1.1118 - acc: 0.9569 - mDice: 0.6296 - val_loss: 0.8130 - val_acc: 0.9761 - val_mDice: 0.7031

Epoch 00051: val_mDice did not improve from 0.71087
Epoch 52/300
 - 15s - loss: 1.1075 - acc: 0.9570 - mDice: 0.6314 - val_loss: 0.8210 - val_acc: 0.9758 - val_mDice: 0.7091

Epoch 00052: val_mDice did not improve from 0.71087
Epoch 53/300
 - 16s - loss: 1.0999 - acc: 0.9571 - mDice: 0.6330 - val_loss: 0.7963 - val_acc: 0.9762 - val_mDice: 0.7097

Epoch 00053: val_mDice did not improve from 0.71087
Epoch 54/300
 - 15s - loss: 1.0959 - acc: 0.9572 - mDice: 0.6349 - val_loss: 0.7974 - val_acc: 0.9760 - val_mDice: 0.7098

Epoch 00054: val_mDice did not improve from 0.71087
Epoch 55/300
 - 17s - loss: 1.0883 - acc: 0.9573 - mDice: 0.6368 - val_loss: 0.7953 - val_acc: 0.9753 - val_mDice: 0.7193

Epoch 00055: val_mDice improved from 0.71087 to 0.71926, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 56/300
 - 15s - loss: 1.0804 - acc: 0.9574 - mDice: 0.6391 - val_loss: 0.8099 - val_acc: 0.9760 - val_mDice: 0.7109

Epoch 00056: val_mDice did not improve from 0.71926
Epoch 57/300
 - 17s - loss: 1.0771 - acc: 0.9576 - mDice: 0.6405 - val_loss: 0.7882 - val_acc: 0.9755 - val_mDice: 0.7163

Epoch 00057: val_mDice did not improve from 0.71926
Epoch 58/300
 - 16s - loss: 1.0753 - acc: 0.9575 - mDice: 0.6412 - val_loss: 0.7868 - val_acc: 0.9753 - val_mDice: 0.7161

Epoch 00058: val_mDice did not improve from 0.71926
Epoch 59/300
 - 16s - loss: 1.0670 - acc: 0.9577 - mDice: 0.6439 - val_loss: 0.7969 - val_acc: 0.9765 - val_mDice: 0.7117

Epoch 00059: val_mDice did not improve from 0.71926
Epoch 60/300
 - 16s - loss: 1.0642 - acc: 0.9577 - mDice: 0.6443 - val_loss: 0.7965 - val_acc: 0.9764 - val_mDice: 0.7104

Epoch 00060: val_mDice did not improve from 0.71926
Epoch 61/300
 - 16s - loss: 1.0591 - acc: 0.9578 - mDice: 0.6464 - val_loss: 0.7987 - val_acc: 0.9761 - val_mDice: 0.7189

Epoch 00061: val_mDice did not improve from 0.71926
Epoch 62/300
 - 16s - loss: 1.0564 - acc: 0.9577 - mDice: 0.6467 - val_loss: 0.8006 - val_acc: 0.9761 - val_mDice: 0.7134

Epoch 00062: val_mDice did not improve from 0.71926
Epoch 63/300
 - 16s - loss: 1.0526 - acc: 0.9578 - mDice: 0.6479 - val_loss: 0.7955 - val_acc: 0.9761 - val_mDice: 0.7187

Epoch 00063: val_mDice did not improve from 0.71926
Epoch 64/300
 - 16s - loss: 1.0506 - acc: 0.9579 - mDice: 0.6490 - val_loss: 0.7788 - val_acc: 0.9764 - val_mDice: 0.7195

Epoch 00064: val_mDice improved from 0.71926 to 0.71952, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 65/300
 - 16s - loss: 1.0452 - acc: 0.9579 - mDice: 0.6499 - val_loss: 0.7920 - val_acc: 0.9763 - val_mDice: 0.7220

Epoch 00065: val_mDice improved from 0.71952 to 0.72202, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 66/300
 - 16s - loss: 1.0418 - acc: 0.9580 - mDice: 0.6514 - val_loss: 0.7738 - val_acc: 0.9764 - val_mDice: 0.7227

Epoch 00066: val_mDice improved from 0.72202 to 0.72272, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 67/300
 - 16s - loss: 1.0392 - acc: 0.9581 - mDice: 0.6522 - val_loss: 0.7782 - val_acc: 0.9762 - val_mDice: 0.7206

Epoch 00067: val_mDice did not improve from 0.72272
Epoch 68/300
 - 16s - loss: 1.0356 - acc: 0.9581 - mDice: 0.6532 - val_loss: 0.7936 - val_acc: 0.9756 - val_mDice: 0.7161

Epoch 00068: val_mDice did not improve from 0.72272
Epoch 69/300
 - 17s - loss: 1.0325 - acc: 0.9581 - mDice: 0.6539 - val_loss: 0.7749 - val_acc: 0.9769 - val_mDice: 0.7173

Epoch 00069: val_mDice did not improve from 0.72272
Epoch 70/300
 - 15s - loss: 1.0270 - acc: 0.9582 - mDice: 0.6557 - val_loss: 0.7880 - val_acc: 0.9758 - val_mDice: 0.7222

Epoch 00070: val_mDice did not improve from 0.72272
Epoch 71/300
 - 16s - loss: 1.0259 - acc: 0.9582 - mDice: 0.6561 - val_loss: 0.7678 - val_acc: 0.9768 - val_mDice: 0.7223

Epoch 00071: val_mDice did not improve from 0.72272
Epoch 72/300
 - 16s - loss: 1.0210 - acc: 0.9583 - mDice: 0.6578 - val_loss: 0.7870 - val_acc: 0.9763 - val_mDice: 0.7203

Epoch 00072: val_mDice did not improve from 0.72272
Epoch 73/300
 - 16s - loss: 1.0209 - acc: 0.9583 - mDice: 0.6578 - val_loss: 0.7748 - val_acc: 0.9758 - val_mDice: 0.7272

Epoch 00073: val_mDice improved from 0.72272 to 0.72722, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 74/300
 - 18s - loss: 1.0201 - acc: 0.9583 - mDice: 0.6582 - val_loss: 0.7720 - val_acc: 0.9764 - val_mDice: 0.7220

Epoch 00074: val_mDice did not improve from 0.72722
Epoch 75/300
 - 15s - loss: 1.0162 - acc: 0.9584 - mDice: 0.6591 - val_loss: 0.7832 - val_acc: 0.9764 - val_mDice: 0.7199

Epoch 00075: val_mDice did not improve from 0.72722
Epoch 76/300
 - 17s - loss: 1.0159 - acc: 0.9584 - mDice: 0.6596 - val_loss: 0.7756 - val_acc: 0.9762 - val_mDice: 0.7199

Epoch 00076: val_mDice did not improve from 0.72722
Epoch 77/300
 - 16s - loss: 1.0133 - acc: 0.9584 - mDice: 0.6604 - val_loss: 0.7723 - val_acc: 0.9758 - val_mDice: 0.7234

Epoch 00077: val_mDice did not improve from 0.72722
Epoch 78/300
 - 18s - loss: 1.0103 - acc: 0.9585 - mDice: 0.6612 - val_loss: 0.7706 - val_acc: 0.9770 - val_mDice: 0.7274

Epoch 00078: val_mDice improved from 0.72722 to 0.72743, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 79/300
 - 16s - loss: 1.0086 - acc: 0.9585 - mDice: 0.6613 - val_loss: 0.7797 - val_acc: 0.9760 - val_mDice: 0.7211

Epoch 00079: val_mDice did not improve from 0.72743
Epoch 80/300
 - 17s - loss: 1.0068 - acc: 0.9585 - mDice: 0.6620 - val_loss: 0.7759 - val_acc: 0.9768 - val_mDice: 0.7244

Epoch 00080: val_mDice did not improve from 0.72743
Epoch 81/300
 - 16s - loss: 1.0048 - acc: 0.9585 - mDice: 0.6628 - val_loss: 0.7847 - val_acc: 0.9764 - val_mDice: 0.7193

Epoch 00081: val_mDice did not improve from 0.72743
Epoch 82/300
 - 17s - loss: 1.0041 - acc: 0.9585 - mDice: 0.6629 - val_loss: 0.7606 - val_acc: 0.9770 - val_mDice: 0.7257

Epoch 00082: val_mDice did not improve from 0.72743
Epoch 83/300
 - 16s - loss: 1.0001 - acc: 0.9586 - mDice: 0.6642 - val_loss: 0.7706 - val_acc: 0.9772 - val_mDice: 0.7282

Epoch 00083: val_mDice improved from 0.72743 to 0.72821, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 84/300
 - 18s - loss: 0.9962 - acc: 0.9587 - mDice: 0.6657 - val_loss: 0.7622 - val_acc: 0.9770 - val_mDice: 0.7230

Epoch 00084: val_mDice did not improve from 0.72821
Epoch 85/300
 - 16s - loss: 0.9937 - acc: 0.9588 - mDice: 0.6661 - val_loss: 0.7566 - val_acc: 0.9772 - val_mDice: 0.7269

Epoch 00085: val_mDice did not improve from 0.72821
Epoch 86/300
 - 20s - loss: 0.9952 - acc: 0.9588 - mDice: 0.6656 - val_loss: 0.7635 - val_acc: 0.9767 - val_mDice: 0.7274

Epoch 00086: val_mDice did not improve from 0.72821
Epoch 87/300
 - 18s - loss: 0.9913 - acc: 0.9588 - mDice: 0.6666 - val_loss: 0.7570 - val_acc: 0.9768 - val_mDice: 0.7328

Epoch 00087: val_mDice improved from 0.72821 to 0.73282, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 88/300
 - 21s - loss: 0.9908 - acc: 0.9589 - mDice: 0.6671 - val_loss: 0.7630 - val_acc: 0.9768 - val_mDice: 0.7304

Epoch 00088: val_mDice did not improve from 0.73282
Epoch 89/300
 - 17s - loss: 0.9913 - acc: 0.9589 - mDice: 0.6671 - val_loss: 0.7714 - val_acc: 0.9765 - val_mDice: 0.7214

Epoch 00089: val_mDice did not improve from 0.73282
Epoch 90/300
 - 18s - loss: 0.9929 - acc: 0.9588 - mDice: 0.6666 - val_loss: 0.7700 - val_acc: 0.9769 - val_mDice: 0.7276

Epoch 00090: val_mDice did not improve from 0.73282
Epoch 91/300
 - 16s - loss: 0.9897 - acc: 0.9590 - mDice: 0.6675 - val_loss: 0.7626 - val_acc: 0.9761 - val_mDice: 0.7265

Epoch 00091: val_mDice did not improve from 0.73282
Epoch 92/300
 - 17s - loss: 0.9841 - acc: 0.9591 - mDice: 0.6689 - val_loss: 0.7560 - val_acc: 0.9772 - val_mDice: 0.7280

Epoch 00092: val_mDice did not improve from 0.73282
Epoch 93/300
 - 17s - loss: 0.9847 - acc: 0.9590 - mDice: 0.6688 - val_loss: 0.7675 - val_acc: 0.9769 - val_mDice: 0.7239

Epoch 00093: val_mDice did not improve from 0.73282
Epoch 94/300
 - 15s - loss: 0.9828 - acc: 0.9591 - mDice: 0.6699 - val_loss: 0.7822 - val_acc: 0.9768 - val_mDice: 0.7238

Epoch 00094: val_mDice did not improve from 0.73282
Epoch 95/300
 - 18s - loss: 0.9843 - acc: 0.9590 - mDice: 0.6691 - val_loss: 0.7547 - val_acc: 0.9767 - val_mDice: 0.7286

Epoch 00095: val_mDice did not improve from 0.73282
Epoch 96/300
 - 16s - loss: 0.9810 - acc: 0.9591 - mDice: 0.6702 - val_loss: 0.7639 - val_acc: 0.9755 - val_mDice: 0.7262

Epoch 00096: val_mDice did not improve from 0.73282
Epoch 97/300
 - 17s - loss: 0.9829 - acc: 0.9591 - mDice: 0.6697 - val_loss: 0.7655 - val_acc: 0.9771 - val_mDice: 0.7281

Epoch 00097: val_mDice did not improve from 0.73282
Epoch 98/300
 - 17s - loss: 0.9803 - acc: 0.9592 - mDice: 0.6705 - val_loss: 0.7557 - val_acc: 0.9769 - val_mDice: 0.7339

Epoch 00098: val_mDice improved from 0.73282 to 0.73388, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 99/300
 - 17s - loss: 0.9754 - acc: 0.9593 - mDice: 0.6716 - val_loss: 0.7586 - val_acc: 0.9768 - val_mDice: 0.7327

Epoch 00099: val_mDice did not improve from 0.73388
Epoch 100/300
 - 23s - loss: 0.9750 - acc: 0.9593 - mDice: 0.6718 - val_loss: 0.7658 - val_acc: 0.9768 - val_mDice: 0.7240

Epoch 00100: val_mDice did not improve from 0.73388
Epoch 101/300
 - 21s - loss: 0.9762 - acc: 0.9593 - mDice: 0.6714 - val_loss: 0.7561 - val_acc: 0.9775 - val_mDice: 0.7274

Epoch 00101: val_mDice did not improve from 0.73388
Epoch 102/300
 - 24s - loss: 0.9727 - acc: 0.9594 - mDice: 0.6727 - val_loss: 0.7543 - val_acc: 0.9765 - val_mDice: 0.7302

Epoch 00102: val_mDice did not improve from 0.73388
Epoch 103/300
 - 21s - loss: 0.9700 - acc: 0.9595 - mDice: 0.6732 - val_loss: 0.7561 - val_acc: 0.9766 - val_mDice: 0.7287

Epoch 00103: val_mDice did not improve from 0.73388
Epoch 104/300
 - 19s - loss: 0.9731 - acc: 0.9594 - mDice: 0.6727 - val_loss: 0.7540 - val_acc: 0.9769 - val_mDice: 0.7306

Epoch 00104: val_mDice did not improve from 0.73388
Epoch 105/300
 - 15s - loss: 0.9700 - acc: 0.9595 - mDice: 0.6737 - val_loss: 0.7468 - val_acc: 0.9768 - val_mDice: 0.7297

Epoch 00105: val_mDice did not improve from 0.73388
Epoch 106/300
 - 16s - loss: 0.9681 - acc: 0.9595 - mDice: 0.6741 - val_loss: 0.7554 - val_acc: 0.9774 - val_mDice: 0.7269

Epoch 00106: val_mDice did not improve from 0.73388
Epoch 107/300
 - 17s - loss: 0.9694 - acc: 0.9595 - mDice: 0.6738 - val_loss: 0.7526 - val_acc: 0.9763 - val_mDice: 0.7326

Epoch 00107: val_mDice did not improve from 0.73388
Epoch 108/300
 - 17s - loss: 0.9669 - acc: 0.9596 - mDice: 0.6745 - val_loss: 0.7586 - val_acc: 0.9771 - val_mDice: 0.7267

Epoch 00108: val_mDice did not improve from 0.73388
Epoch 109/300
 - 20s - loss: 0.9678 - acc: 0.9596 - mDice: 0.6744 - val_loss: 0.7524 - val_acc: 0.9766 - val_mDice: 0.7318

Epoch 00109: val_mDice did not improve from 0.73388
Epoch 110/300
 - 18s - loss: 0.9651 - acc: 0.9596 - mDice: 0.6751 - val_loss: 0.7481 - val_acc: 0.9774 - val_mDice: 0.7346

Epoch 00110: val_mDice improved from 0.73388 to 0.73456, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 111/300
 - 17s - loss: 0.9675 - acc: 0.9596 - mDice: 0.6744 - val_loss: 0.7459 - val_acc: 0.9766 - val_mDice: 0.7311

Epoch 00111: val_mDice did not improve from 0.73456
Epoch 112/300
 - 16s - loss: 0.9617 - acc: 0.9597 - mDice: 0.6761 - val_loss: 0.7441 - val_acc: 0.9770 - val_mDice: 0.7337

Epoch 00112: val_mDice did not improve from 0.73456
Epoch 113/300
 - 16s - loss: 0.9622 - acc: 0.9597 - mDice: 0.6763 - val_loss: 0.7374 - val_acc: 0.9771 - val_mDice: 0.7316

Epoch 00113: val_mDice did not improve from 0.73456
Epoch 114/300
 - 18s - loss: 0.9604 - acc: 0.9597 - mDice: 0.6766 - val_loss: 0.7625 - val_acc: 0.9767 - val_mDice: 0.7299

Epoch 00114: val_mDice did not improve from 0.73456
Epoch 115/300
 - 18s - loss: 0.9611 - acc: 0.9597 - mDice: 0.6762 - val_loss: 0.7418 - val_acc: 0.9771 - val_mDice: 0.7376

Epoch 00115: val_mDice improved from 0.73456 to 0.73762, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 116/300
 - 23s - loss: 0.9577 - acc: 0.9598 - mDice: 0.6776 - val_loss: 0.7504 - val_acc: 0.9772 - val_mDice: 0.7339

Epoch 00116: val_mDice did not improve from 0.73762
Epoch 117/300
 - 16s - loss: 0.9581 - acc: 0.9598 - mDice: 0.6774 - val_loss: 0.7608 - val_acc: 0.9772 - val_mDice: 0.7307

Epoch 00117: val_mDice did not improve from 0.73762
Epoch 118/300
 - 17s - loss: 0.9566 - acc: 0.9598 - mDice: 0.6778 - val_loss: 0.7483 - val_acc: 0.9766 - val_mDice: 0.7339

Epoch 00118: val_mDice did not improve from 0.73762
Epoch 119/300
 - 15s - loss: 0.9554 - acc: 0.9599 - mDice: 0.6780 - val_loss: 0.7500 - val_acc: 0.9769 - val_mDice: 0.7352

Epoch 00119: val_mDice did not improve from 0.73762
Epoch 120/300
 - 17s - loss: 0.9552 - acc: 0.9599 - mDice: 0.6780 - val_loss: 0.7544 - val_acc: 0.9773 - val_mDice: 0.7350

Epoch 00120: val_mDice did not improve from 0.73762
Epoch 121/300
 - 16s - loss: 0.9523 - acc: 0.9600 - mDice: 0.6789 - val_loss: 0.7597 - val_acc: 0.9772 - val_mDice: 0.7324

Epoch 00121: val_mDice did not improve from 0.73762
Epoch 122/300
 - 17s - loss: 0.9532 - acc: 0.9600 - mDice: 0.6788 - val_loss: 0.7562 - val_acc: 0.9767 - val_mDice: 0.7314

Epoch 00122: val_mDice did not improve from 0.73762
Epoch 123/300
 - 16s - loss: 0.9527 - acc: 0.9599 - mDice: 0.6792 - val_loss: 0.7474 - val_acc: 0.9765 - val_mDice: 0.7382

Epoch 00123: val_mDice improved from 0.73762 to 0.73816, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 124/300
 - 17s - loss: 0.9533 - acc: 0.9599 - mDice: 0.6790 - val_loss: 0.7614 - val_acc: 0.9772 - val_mDice: 0.7321

Epoch 00124: val_mDice did not improve from 0.73816
Epoch 125/300
 - 16s - loss: 0.9505 - acc: 0.9600 - mDice: 0.6796 - val_loss: 0.7486 - val_acc: 0.9768 - val_mDice: 0.7355

Epoch 00125: val_mDice did not improve from 0.73816
Epoch 126/300
 - 17s - loss: 0.9513 - acc: 0.9600 - mDice: 0.6798 - val_loss: 0.7453 - val_acc: 0.9768 - val_mDice: 0.7381

Epoch 00126: val_mDice did not improve from 0.73816
Epoch 127/300
 - 16s - loss: 0.9485 - acc: 0.9600 - mDice: 0.6804 - val_loss: 0.7506 - val_acc: 0.9764 - val_mDice: 0.7412

Epoch 00127: val_mDice improved from 0.73816 to 0.74120, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 128/300
 - 17s - loss: 0.9501 - acc: 0.9600 - mDice: 0.6805 - val_loss: 0.7501 - val_acc: 0.9772 - val_mDice: 0.7361

Epoch 00128: val_mDice did not improve from 0.74120
Epoch 129/300
 - 16s - loss: 0.9508 - acc: 0.9600 - mDice: 0.6797 - val_loss: 0.7420 - val_acc: 0.9772 - val_mDice: 0.7395

Epoch 00129: val_mDice did not improve from 0.74120
Epoch 130/300
 - 17s - loss: 0.9488 - acc: 0.9600 - mDice: 0.6806 - val_loss: 0.7539 - val_acc: 0.9772 - val_mDice: 0.7354

Epoch 00130: val_mDice did not improve from 0.74120
Epoch 131/300
 - 16s - loss: 0.9451 - acc: 0.9601 - mDice: 0.6815 - val_loss: 0.7427 - val_acc: 0.9771 - val_mDice: 0.7359

Epoch 00131: val_mDice did not improve from 0.74120
Epoch 132/300
 - 17s - loss: 0.9460 - acc: 0.9601 - mDice: 0.6812 - val_loss: 0.7437 - val_acc: 0.9772 - val_mDice: 0.7355

Epoch 00132: val_mDice did not improve from 0.74120
Epoch 133/300
 - 17s - loss: 0.9460 - acc: 0.9601 - mDice: 0.6816 - val_loss: 0.7402 - val_acc: 0.9773 - val_mDice: 0.7393

Epoch 00133: val_mDice did not improve from 0.74120
Epoch 134/300
 - 17s - loss: 0.9471 - acc: 0.9601 - mDice: 0.6811 - val_loss: 0.7398 - val_acc: 0.9774 - val_mDice: 0.7419

Epoch 00134: val_mDice improved from 0.74120 to 0.74192, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 135/300
 - 17s - loss: 0.9437 - acc: 0.9602 - mDice: 0.6822 - val_loss: 0.7557 - val_acc: 0.9775 - val_mDice: 0.7383

Epoch 00135: val_mDice did not improve from 0.74192
Epoch 136/300
 - 16s - loss: 0.9441 - acc: 0.9602 - mDice: 0.6819 - val_loss: 0.7431 - val_acc: 0.9769 - val_mDice: 0.7376

Epoch 00136: val_mDice did not improve from 0.74192
Epoch 137/300
 - 17s - loss: 0.9412 - acc: 0.9602 - mDice: 0.6830 - val_loss: 0.7324 - val_acc: 0.9773 - val_mDice: 0.7380

Epoch 00137: val_mDice did not improve from 0.74192
Epoch 138/300
 - 16s - loss: 0.9412 - acc: 0.9602 - mDice: 0.6824 - val_loss: 0.7434 - val_acc: 0.9771 - val_mDice: 0.7377

Epoch 00138: val_mDice did not improve from 0.74192
Epoch 139/300
 - 17s - loss: 0.9407 - acc: 0.9603 - mDice: 0.6832 - val_loss: 0.7331 - val_acc: 0.9774 - val_mDice: 0.7398

Epoch 00139: val_mDice did not improve from 0.74192
Epoch 140/300
 - 16s - loss: 0.9397 - acc: 0.9603 - mDice: 0.6833 - val_loss: 0.7445 - val_acc: 0.9775 - val_mDice: 0.7399

Epoch 00140: val_mDice did not improve from 0.74192
Epoch 141/300
 - 17s - loss: 0.9402 - acc: 0.9603 - mDice: 0.6831 - val_loss: 0.7374 - val_acc: 0.9773 - val_mDice: 0.7407

Epoch 00141: val_mDice did not improve from 0.74192
Epoch 142/300
 - 16s - loss: 0.9370 - acc: 0.9604 - mDice: 0.6842 - val_loss: 0.7285 - val_acc: 0.9777 - val_mDice: 0.7404

Epoch 00142: val_mDice did not improve from 0.74192
Epoch 143/300
 - 17s - loss: 0.9400 - acc: 0.9602 - mDice: 0.6834 - val_loss: 0.7424 - val_acc: 0.9776 - val_mDice: 0.7412

Epoch 00143: val_mDice did not improve from 0.74192
Epoch 144/300
 - 16s - loss: 0.9351 - acc: 0.9604 - mDice: 0.6848 - val_loss: 0.7393 - val_acc: 0.9777 - val_mDice: 0.7379

Epoch 00144: val_mDice did not improve from 0.74192
Epoch 145/300
 - 17s - loss: 0.9379 - acc: 0.9604 - mDice: 0.6838 - val_loss: 0.7338 - val_acc: 0.9775 - val_mDice: 0.7372

Epoch 00145: val_mDice did not improve from 0.74192
Epoch 146/300
 - 16s - loss: 0.9359 - acc: 0.9603 - mDice: 0.6845 - val_loss: 0.7431 - val_acc: 0.9773 - val_mDice: 0.7332

Epoch 00146: val_mDice did not improve from 0.74192
Epoch 147/300
 - 17s - loss: 0.9374 - acc: 0.9604 - mDice: 0.6843 - val_loss: 0.7367 - val_acc: 0.9768 - val_mDice: 0.7397

Epoch 00147: val_mDice did not improve from 0.74192
Epoch 148/300
 - 16s - loss: 0.9353 - acc: 0.9604 - mDice: 0.6852 - val_loss: 0.7366 - val_acc: 0.9775 - val_mDice: 0.7409

Epoch 00148: val_mDice did not improve from 0.74192
Epoch 149/300
 - 18s - loss: 0.9334 - acc: 0.9605 - mDice: 0.6854 - val_loss: 0.7304 - val_acc: 0.9779 - val_mDice: 0.7377

Epoch 00149: val_mDice did not improve from 0.74192
Epoch 150/300
 - 17s - loss: 0.9332 - acc: 0.9605 - mDice: 0.6856 - val_loss: 0.7431 - val_acc: 0.9773 - val_mDice: 0.7355

Epoch 00150: val_mDice did not improve from 0.74192
Epoch 151/300
 - 17s - loss: 0.9337 - acc: 0.9604 - mDice: 0.6853 - val_loss: 0.7371 - val_acc: 0.9770 - val_mDice: 0.7393

Epoch 00151: val_mDice did not improve from 0.74192
Epoch 152/300
 - 16s - loss: 0.9320 - acc: 0.9605 - mDice: 0.6857 - val_loss: 0.7383 - val_acc: 0.9773 - val_mDice: 0.7409

Epoch 00152: val_mDice did not improve from 0.74192
Epoch 153/300
 - 18s - loss: 0.9320 - acc: 0.9605 - mDice: 0.6859 - val_loss: 0.7351 - val_acc: 0.9781 - val_mDice: 0.7389

Epoch 00153: val_mDice did not improve from 0.74192
Epoch 154/300
 - 16s - loss: 0.9306 - acc: 0.9605 - mDice: 0.6859 - val_loss: 0.7345 - val_acc: 0.9774 - val_mDice: 0.7387

Epoch 00154: val_mDice did not improve from 0.74192
Epoch 155/300
 - 18s - loss: 0.9297 - acc: 0.9605 - mDice: 0.6866 - val_loss: 0.7411 - val_acc: 0.9763 - val_mDice: 0.7378

Epoch 00155: val_mDice did not improve from 0.74192
Epoch 156/300
 - 16s - loss: 0.9294 - acc: 0.9606 - mDice: 0.6866 - val_loss: 0.7315 - val_acc: 0.9775 - val_mDice: 0.7405

Epoch 00156: val_mDice did not improve from 0.74192
Epoch 157/300
 - 18s - loss: 0.9349 - acc: 0.9605 - mDice: 0.6851 - val_loss: 0.7340 - val_acc: 0.9776 - val_mDice: 0.7424

Epoch 00157: val_mDice improved from 0.74192 to 0.74236, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 158/300
 - 16s - loss: 0.9306 - acc: 0.9605 - mDice: 0.6863 - val_loss: 0.7410 - val_acc: 0.9778 - val_mDice: 0.7376

Epoch 00158: val_mDice did not improve from 0.74236
Epoch 159/300
 - 18s - loss: 0.9296 - acc: 0.9606 - mDice: 0.6867 - val_loss: 0.7433 - val_acc: 0.9768 - val_mDice: 0.7372

Epoch 00159: val_mDice did not improve from 0.74236
Epoch 160/300
 - 15s - loss: 0.9309 - acc: 0.9605 - mDice: 0.6863 - val_loss: 0.7348 - val_acc: 0.9781 - val_mDice: 0.7395

Epoch 00160: val_mDice did not improve from 0.74236
Epoch 161/300
 - 18s - loss: 0.9290 - acc: 0.9606 - mDice: 0.6868 - val_loss: 0.7238 - val_acc: 0.9779 - val_mDice: 0.7458

Epoch 00161: val_mDice improved from 0.74236 to 0.74578, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 162/300
 - 16s - loss: 0.9249 - acc: 0.9607 - mDice: 0.6878 - val_loss: 0.7299 - val_acc: 0.9778 - val_mDice: 0.7391

Epoch 00162: val_mDice did not improve from 0.74578
Epoch 163/300
 - 16s - loss: 0.9267 - acc: 0.9606 - mDice: 0.6875 - val_loss: 0.7268 - val_acc: 0.9769 - val_mDice: 0.7456

Epoch 00163: val_mDice did not improve from 0.74578
Epoch 164/300
 - 16s - loss: 0.9250 - acc: 0.9607 - mDice: 0.6880 - val_loss: 0.7245 - val_acc: 0.9780 - val_mDice: 0.7453

Epoch 00164: val_mDice did not improve from 0.74578
Epoch 165/300
 - 16s - loss: 0.9249 - acc: 0.9607 - mDice: 0.6882 - val_loss: 0.7332 - val_acc: 0.9769 - val_mDice: 0.7400

Epoch 00165: val_mDice did not improve from 0.74578
Epoch 166/300
 - 16s - loss: 0.9251 - acc: 0.9607 - mDice: 0.6881 - val_loss: 0.7230 - val_acc: 0.9777 - val_mDice: 0.7431

Epoch 00166: val_mDice did not improve from 0.74578
Epoch 167/300
 - 15s - loss: 0.9250 - acc: 0.9607 - mDice: 0.6879 - val_loss: 0.7332 - val_acc: 0.9771 - val_mDice: 0.7426

Epoch 00167: val_mDice did not improve from 0.74578
Epoch 168/300
 - 17s - loss: 0.9254 - acc: 0.9607 - mDice: 0.6880 - val_loss: 0.7269 - val_acc: 0.9779 - val_mDice: 0.7453

Epoch 00168: val_mDice did not improve from 0.74578
Epoch 169/300
 - 15s - loss: 0.9252 - acc: 0.9607 - mDice: 0.6883 - val_loss: 0.7341 - val_acc: 0.9771 - val_mDice: 0.7363

Epoch 00169: val_mDice did not improve from 0.74578
Epoch 170/300
 - 17s - loss: 0.9213 - acc: 0.9608 - mDice: 0.6893 - val_loss: 0.7260 - val_acc: 0.9779 - val_mDice: 0.7417

Epoch 00170: val_mDice did not improve from 0.74578
Epoch 171/300
 - 15s - loss: 0.9229 - acc: 0.9607 - mDice: 0.6888 - val_loss: 0.7360 - val_acc: 0.9780 - val_mDice: 0.7428

Epoch 00171: val_mDice did not improve from 0.74578
Epoch 172/300
 - 16s - loss: 0.9218 - acc: 0.9608 - mDice: 0.6890 - val_loss: 0.7275 - val_acc: 0.9776 - val_mDice: 0.7422

Epoch 00172: val_mDice did not improve from 0.74578
Epoch 173/300
 - 16s - loss: 0.9227 - acc: 0.9608 - mDice: 0.6891 - val_loss: 0.7279 - val_acc: 0.9774 - val_mDice: 0.7418

Epoch 00173: val_mDice did not improve from 0.74578
Epoch 174/300
 - 15s - loss: 0.9212 - acc: 0.9608 - mDice: 0.6893 - val_loss: 0.7285 - val_acc: 0.9777 - val_mDice: 0.7426

Epoch 00174: val_mDice did not improve from 0.74578
Epoch 175/300
 - 16s - loss: 0.9217 - acc: 0.9608 - mDice: 0.6890 - val_loss: 0.7310 - val_acc: 0.9778 - val_mDice: 0.7394

Epoch 00175: val_mDice did not improve from 0.74578
Epoch 176/300
 - 15s - loss: 0.9214 - acc: 0.9608 - mDice: 0.6892 - val_loss: 0.7390 - val_acc: 0.9775 - val_mDice: 0.7405

Epoch 00176: val_mDice did not improve from 0.74578
Epoch 177/300
 - 16s - loss: 0.9198 - acc: 0.9608 - mDice: 0.6897 - val_loss: 0.7269 - val_acc: 0.9779 - val_mDice: 0.7427

Epoch 00177: val_mDice did not improve from 0.74578
Epoch 178/300
 - 16s - loss: 0.9197 - acc: 0.9608 - mDice: 0.6898 - val_loss: 0.7244 - val_acc: 0.9774 - val_mDice: 0.7429

Epoch 00178: val_mDice did not improve from 0.74578
Epoch 179/300
 - 15s - loss: 0.9190 - acc: 0.9608 - mDice: 0.6901 - val_loss: 0.7262 - val_acc: 0.9773 - val_mDice: 0.7425

Epoch 00179: val_mDice did not improve from 0.74578
Epoch 180/300
 - 15s - loss: 0.9172 - acc: 0.9609 - mDice: 0.6904 - val_loss: 0.7214 - val_acc: 0.9773 - val_mDice: 0.7488

Epoch 00180: val_mDice improved from 0.74578 to 0.74876, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 181/300
 - 15s - loss: 0.9197 - acc: 0.9608 - mDice: 0.6900 - val_loss: 0.7311 - val_acc: 0.9780 - val_mDice: 0.7403

Epoch 00181: val_mDice did not improve from 0.74876
Epoch 182/300
 - 16s - loss: 0.9165 - acc: 0.9610 - mDice: 0.6908 - val_loss: 0.7290 - val_acc: 0.9780 - val_mDice: 0.7453

Epoch 00182: val_mDice did not improve from 0.74876
Epoch 183/300
 - 15s - loss: 0.9191 - acc: 0.9609 - mDice: 0.6902 - val_loss: 0.7322 - val_acc: 0.9776 - val_mDice: 0.7429

Epoch 00183: val_mDice did not improve from 0.74876
Epoch 184/300
 - 15s - loss: 0.9175 - acc: 0.9609 - mDice: 0.6905 - val_loss: 0.7341 - val_acc: 0.9769 - val_mDice: 0.7427

Epoch 00184: val_mDice did not improve from 0.74876
Epoch 185/300
 - 15s - loss: 0.9160 - acc: 0.9609 - mDice: 0.6909 - val_loss: 0.7262 - val_acc: 0.9780 - val_mDice: 0.7445

Epoch 00185: val_mDice did not improve from 0.74876
Epoch 186/300
 - 16s - loss: 0.9155 - acc: 0.9609 - mDice: 0.6913 - val_loss: 0.7220 - val_acc: 0.9779 - val_mDice: 0.7481

Epoch 00186: val_mDice did not improve from 0.74876
Epoch 187/300
 - 16s - loss: 0.9164 - acc: 0.9609 - mDice: 0.6909 - val_loss: 0.7244 - val_acc: 0.9780 - val_mDice: 0.7477

Epoch 00187: val_mDice did not improve from 0.74876
Epoch 188/300
 - 17s - loss: 0.9152 - acc: 0.9610 - mDice: 0.6913 - val_loss: 0.7277 - val_acc: 0.9772 - val_mDice: 0.7437

Epoch 00188: val_mDice did not improve from 0.74876
Epoch 189/300
 - 15s - loss: 0.9161 - acc: 0.9610 - mDice: 0.6909 - val_loss: 0.7299 - val_acc: 0.9780 - val_mDice: 0.7429

Epoch 00189: val_mDice did not improve from 0.74876
Epoch 190/300
 - 17s - loss: 0.9146 - acc: 0.9610 - mDice: 0.6912 - val_loss: 0.7244 - val_acc: 0.9777 - val_mDice: 0.7428

Epoch 00190: val_mDice did not improve from 0.74876
Epoch 191/300
 - 15s - loss: 0.9129 - acc: 0.9610 - mDice: 0.6921 - val_loss: 0.7237 - val_acc: 0.9774 - val_mDice: 0.7467

Epoch 00191: val_mDice did not improve from 0.74876
Epoch 192/300
 - 16s - loss: 0.9129 - acc: 0.9610 - mDice: 0.6925 - val_loss: 0.7374 - val_acc: 0.9783 - val_mDice: 0.7416

Epoch 00192: val_mDice did not improve from 0.74876
Epoch 193/300
 - 15s - loss: 0.9141 - acc: 0.9610 - mDice: 0.6919 - val_loss: 0.7357 - val_acc: 0.9773 - val_mDice: 0.7373

Epoch 00193: val_mDice did not improve from 0.74876
Epoch 194/300
 - 15s - loss: 0.9131 - acc: 0.9610 - mDice: 0.6917 - val_loss: 0.7249 - val_acc: 0.9777 - val_mDice: 0.7422

Epoch 00194: val_mDice did not improve from 0.74876
Epoch 195/300
 - 16s - loss: 0.9122 - acc: 0.9611 - mDice: 0.6925 - val_loss: 0.7299 - val_acc: 0.9778 - val_mDice: 0.7453

Epoch 00195: val_mDice did not improve from 0.74876
Epoch 196/300
 - 16s - loss: 0.9128 - acc: 0.9611 - mDice: 0.6923 - val_loss: 0.7287 - val_acc: 0.9772 - val_mDice: 0.7439

Epoch 00196: val_mDice did not improve from 0.74876
Epoch 197/300
 - 16s - loss: 0.9107 - acc: 0.9611 - mDice: 0.6928 - val_loss: 0.7330 - val_acc: 0.9773 - val_mDice: 0.7410

Epoch 00197: val_mDice did not improve from 0.74876
Epoch 198/300
 - 16s - loss: 0.9109 - acc: 0.9611 - mDice: 0.6925 - val_loss: 0.7273 - val_acc: 0.9776 - val_mDice: 0.7413

Epoch 00198: val_mDice did not improve from 0.74876
Epoch 199/300
 - 15s - loss: 0.9089 - acc: 0.9612 - mDice: 0.6936 - val_loss: 0.7229 - val_acc: 0.9777 - val_mDice: 0.7441

Epoch 00199: val_mDice did not improve from 0.74876
Epoch 200/300
 - 15s - loss: 0.9082 - acc: 0.9611 - mDice: 0.6935 - val_loss: 0.7238 - val_acc: 0.9781 - val_mDice: 0.7432

Epoch 00200: val_mDice did not improve from 0.74876
Epoch 201/300
 - 16s - loss: 0.9096 - acc: 0.9612 - mDice: 0.6933 - val_loss: 0.7236 - val_acc: 0.9777 - val_mDice: 0.7439

Epoch 00201: val_mDice did not improve from 0.74876
Epoch 202/300
 - 15s - loss: 0.9082 - acc: 0.9612 - mDice: 0.6936 - val_loss: 0.7228 - val_acc: 0.9779 - val_mDice: 0.7441

Epoch 00202: val_mDice did not improve from 0.74876
Epoch 203/300
 - 15s - loss: 0.9090 - acc: 0.9611 - mDice: 0.6932 - val_loss: 0.7226 - val_acc: 0.9778 - val_mDice: 0.7468

Epoch 00203: val_mDice did not improve from 0.74876
Epoch 204/300
 - 15s - loss: 0.9082 - acc: 0.9611 - mDice: 0.6938 - val_loss: 0.7389 - val_acc: 0.9778 - val_mDice: 0.7370

Epoch 00204: val_mDice did not improve from 0.74876
Epoch 205/300
 - 15s - loss: 0.9085 - acc: 0.9611 - mDice: 0.6933 - val_loss: 0.7221 - val_acc: 0.9780 - val_mDice: 0.7499

Epoch 00205: val_mDice improved from 0.74876 to 0.74990, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 206/300
 - 16s - loss: 0.9078 - acc: 0.9611 - mDice: 0.6935 - val_loss: 0.7254 - val_acc: 0.9775 - val_mDice: 0.7452

Epoch 00206: val_mDice did not improve from 0.74990
Epoch 207/300
 - 15s - loss: 0.9085 - acc: 0.9612 - mDice: 0.6938 - val_loss: 0.7311 - val_acc: 0.9780 - val_mDice: 0.7470

Epoch 00207: val_mDice did not improve from 0.74990
Epoch 208/300
 - 15s - loss: 0.9074 - acc: 0.9612 - mDice: 0.6941 - val_loss: 0.7241 - val_acc: 0.9780 - val_mDice: 0.7468

Epoch 00208: val_mDice did not improve from 0.74990
Epoch 209/300
 - 17s - loss: 0.9063 - acc: 0.9612 - mDice: 0.6941 - val_loss: 0.7243 - val_acc: 0.9782 - val_mDice: 0.7477

Epoch 00209: val_mDice did not improve from 0.74990
Epoch 210/300
 - 15s - loss: 0.9065 - acc: 0.9612 - mDice: 0.6942 - val_loss: 0.7305 - val_acc: 0.9783 - val_mDice: 0.7433

Epoch 00210: val_mDice did not improve from 0.74990
Epoch 211/300
 - 16s - loss: 0.9109 - acc: 0.9612 - mDice: 0.6933 - val_loss: 0.7239 - val_acc: 0.9776 - val_mDice: 0.7446

Epoch 00211: val_mDice did not improve from 0.74990
Epoch 212/300
 - 15s - loss: 0.9055 - acc: 0.9612 - mDice: 0.6942 - val_loss: 0.7181 - val_acc: 0.9778 - val_mDice: 0.7457

Epoch 00212: val_mDice did not improve from 0.74990
Epoch 213/300
 - 17s - loss: 0.9041 - acc: 0.9613 - mDice: 0.6948 - val_loss: 0.7197 - val_acc: 0.9775 - val_mDice: 0.7483

Epoch 00213: val_mDice did not improve from 0.74990
Epoch 214/300
 - 15s - loss: 0.9059 - acc: 0.9612 - mDice: 0.6945 - val_loss: 0.7249 - val_acc: 0.9770 - val_mDice: 0.7424

Epoch 00214: val_mDice did not improve from 0.74990
Epoch 215/300
 - 16s - loss: 0.9044 - acc: 0.9613 - mDice: 0.6952 - val_loss: 0.7238 - val_acc: 0.9770 - val_mDice: 0.7475

Epoch 00215: val_mDice did not improve from 0.74990
Epoch 216/300
 - 16s - loss: 0.9028 - acc: 0.9613 - mDice: 0.6955 - val_loss: 0.7217 - val_acc: 0.9779 - val_mDice: 0.7484

Epoch 00216: val_mDice did not improve from 0.74990
Epoch 217/300
 - 16s - loss: 0.9031 - acc: 0.9613 - mDice: 0.6952 - val_loss: 0.7227 - val_acc: 0.9780 - val_mDice: 0.7469

Epoch 00217: val_mDice did not improve from 0.74990
Epoch 218/300
 - 17s - loss: 0.9032 - acc: 0.9613 - mDice: 0.6952 - val_loss: 0.7253 - val_acc: 0.9775 - val_mDice: 0.7463

Epoch 00218: val_mDice did not improve from 0.74990
Epoch 219/300
 - 16s - loss: 0.9045 - acc: 0.9613 - mDice: 0.6950 - val_loss: 0.7275 - val_acc: 0.9778 - val_mDice: 0.7483

Epoch 00219: val_mDice did not improve from 0.74990
Epoch 220/300
 - 17s - loss: 0.9042 - acc: 0.9613 - mDice: 0.6951 - val_loss: 0.7222 - val_acc: 0.9779 - val_mDice: 0.7458

Epoch 00220: val_mDice did not improve from 0.74990
Epoch 221/300
 - 16s - loss: 0.9009 - acc: 0.9614 - mDice: 0.6962 - val_loss: 0.7174 - val_acc: 0.9778 - val_mDice: 0.7463

Epoch 00221: val_mDice did not improve from 0.74990
Epoch 222/300
 - 16s - loss: 0.9012 - acc: 0.9613 - mDice: 0.6962 - val_loss: 0.7258 - val_acc: 0.9778 - val_mDice: 0.7456

Epoch 00222: val_mDice did not improve from 0.74990
Epoch 223/300
 - 16s - loss: 0.9021 - acc: 0.9613 - mDice: 0.6959 - val_loss: 0.7305 - val_acc: 0.9781 - val_mDice: 0.7451

Epoch 00223: val_mDice did not improve from 0.74990
Epoch 224/300
 - 16s - loss: 0.8992 - acc: 0.9614 - mDice: 0.6967 - val_loss: 0.7237 - val_acc: 0.9774 - val_mDice: 0.7493

Epoch 00224: val_mDice did not improve from 0.74990
Epoch 225/300
 - 17s - loss: 0.9013 - acc: 0.9614 - mDice: 0.6959 - val_loss: 0.7342 - val_acc: 0.9776 - val_mDice: 0.7463

Epoch 00225: val_mDice did not improve from 0.74990
Epoch 226/300
 - 16s - loss: 0.9019 - acc: 0.9614 - mDice: 0.6959 - val_loss: 0.7286 - val_acc: 0.9776 - val_mDice: 0.7479

Epoch 00226: val_mDice did not improve from 0.74990
Epoch 227/300
 - 17s - loss: 0.9009 - acc: 0.9614 - mDice: 0.6961 - val_loss: 0.7170 - val_acc: 0.9775 - val_mDice: 0.7483

Epoch 00227: val_mDice did not improve from 0.74990
Epoch 228/300
 - 15s - loss: 0.8997 - acc: 0.9614 - mDice: 0.6965 - val_loss: 0.7243 - val_acc: 0.9770 - val_mDice: 0.7460

Epoch 00228: val_mDice did not improve from 0.74990
Epoch 229/300
 - 16s - loss: 0.8992 - acc: 0.9614 - mDice: 0.6968 - val_loss: 0.7223 - val_acc: 0.9771 - val_mDice: 0.7441

Epoch 00229: val_mDice did not improve from 0.74990
Epoch 230/300
 - 16s - loss: 0.9013 - acc: 0.9614 - mDice: 0.6960 - val_loss: 0.7312 - val_acc: 0.9769 - val_mDice: 0.7478

Epoch 00230: val_mDice did not improve from 0.74990
Epoch 231/300
 - 16s - loss: 0.8989 - acc: 0.9615 - mDice: 0.6966 - val_loss: 0.7269 - val_acc: 0.9777 - val_mDice: 0.7461

Epoch 00231: val_mDice did not improve from 0.74990
Epoch 232/300
 - 15s - loss: 0.8981 - acc: 0.9615 - mDice: 0.6970 - val_loss: 0.7197 - val_acc: 0.9765 - val_mDice: 0.7458

Epoch 00232: val_mDice did not improve from 0.74990
Epoch 233/300
 - 17s - loss: 0.8988 - acc: 0.9615 - mDice: 0.6969 - val_loss: 0.7291 - val_acc: 0.9774 - val_mDice: 0.7461

Epoch 00233: val_mDice did not improve from 0.74990
Epoch 234/300
 - 15s - loss: 0.8991 - acc: 0.9615 - mDice: 0.6969 - val_loss: 0.7266 - val_acc: 0.9771 - val_mDice: 0.7474

Epoch 00234: val_mDice did not improve from 0.74990
Epoch 235/300
 - 16s - loss: 0.9001 - acc: 0.9615 - mDice: 0.6963 - val_loss: 0.7236 - val_acc: 0.9775 - val_mDice: 0.7474

Epoch 00235: val_mDice did not improve from 0.74990
Restoring model weights from the end of the best epoch
Epoch 00235: early stopping
{'val_loss': [4.718061734552252, 3.9762671385725885, 3.6039076978213167, 3.2817367625563114, 2.9518752228723812, 2.5794126497556085, 2.2685833197750456, 1.93867095692517, 1.7464829030102247, 1.6530940565344405, 1.626061992286003, 1.5227580740027231, 1.4346267099249852, 1.3702580202115726, 1.3312536045296552, 1.2274196760295188, 1.1446129573534614, 1.1615607068963247, 1.0787499885853022, 1.060268905881333, 1.0350652577942365, 1.0163461888489658, 1.001627408070107, 0.9867570208360071, 0.9753771534521286, 0.9698599193194141, 0.9473054992826018, 0.9311154558234018, 0.922878188629673, 0.9118549456335094, 0.9038527742640613, 0.9076343701310354, 0.8683127997672722, 0.8755130857637484, 0.883861001631985, 0.8644208471252494, 0.8508454740863957, 0.8531544453477207, 0.8718783373702063, 0.8610002051477563, 0.8337853514168361, 0.85197889355764, 0.8360460510809128, 0.8247132154360209, 0.8360272074398929, 0.8220485187556645, 0.8248513169484596, 0.819442528567902, 0.8024637135740829, 0.8201066378044756, 0.8130215692193541, 0.8210265285348239, 0.7962554146165717, 0.7973963806073959, 0.7952544897386472, 0.8099203399599415, 0.7882127492395166, 0.7867936067385216, 0.7968958477451377, 0.7964875257178529, 0.7987219274860539, 0.8006145194785236, 0.7955355329872811, 0.7787831654287365, 0.7919961683554192, 0.7738389552456059, 0.7781562792928252, 0.7935662045054239, 0.7749041143345506, 0.7880443114123933, 0.7677557113235944, 0.7870347434527254, 0.7748180297139573, 0.7719541216549808, 0.7832268341763379, 0.7756116912789541, 0.772295109621466, 0.7706081646762483, 0.7797145439337377, 0.7759118018901512, 0.7847033326756464, 0.7606063117719677, 0.770561252554802, 0.762188196998753, 0.7566199470056246, 0.7634781374506754, 0.7569664190076801, 0.7630422364359033, 0.7713648240043692, 0.7699926373076765, 0.7626427252815194, 0.7559953891251185, 0.7675474992353623, 0.7822261060753913, 0.7546894301290381, 0.7639414423132596, 0.7655421932266183, 0.7557035133446732, 0.7586119587290777, 0.765776126352075, 0.7561324565377954, 0.7543311445680383, 0.756062871381028, 0.7539815367901161, 0.7467836051771085, 0.7553882545804325, 0.7525885872644921, 0.758571010746368, 0.7524434389316872, 0.7480920516464808, 0.7459399034715679, 0.7440713713430378, 0.737430358994497, 0.7625319402511805, 0.7418161520402725, 0.7503722183508416, 0.760811010043915, 0.7482995746070391, 0.7500283897739567, 0.7543837526073195, 0.7596845100187275, 0.7562048965937471, 0.7473588643008715, 0.7614153954264236, 0.748598868308002, 0.7452638733060393, 0.7506275605665494, 0.750114669538524, 0.7419928002030882, 0.7539490077593555, 0.742719151794094, 0.743720337952653, 0.7401508186777978, 0.7397543236817399, 0.7557079898167963, 0.743149213186682, 0.732435795134061, 0.7433609358251911, 0.7331405673941521, 0.7444543744603248, 0.7374489291073525, 0.7285141610119441, 0.7424133685353684, 0.7393101368048419, 0.7338277068856645, 0.7431344908394225, 0.7366528592697562, 0.7365527728649035, 0.7304382463024087, 0.7431343989829494, 0.737141779432558, 0.7382825915127584, 0.7350900573273228, 0.7344608302802256, 0.7410933167150576, 0.7315466261073335, 0.734009083411465, 0.7409930253682071, 0.7432647588318342, 0.7347558989916763, 0.7237937295273559, 0.7299210735379833, 0.7267772722734164, 0.7244909601668789, 0.7332371011988758, 0.722975056465358, 0.7331525071026528, 0.7269004240427932, 0.734056487883607, 0.7259910902748369, 0.7359575098508024, 0.7275048375946201, 0.7278799998433623, 0.7285114057260017, 0.7310415192009652, 0.7389890620969746, 0.7268757991594811, 0.7244085391906843, 0.7261561412517339, 0.7213711742668936, 0.7311192505980191, 0.7289971913376899, 0.7322011875779662, 0.7340588100152473, 0.7262048786633635, 0.7220198654965179, 0.7244495667823373, 0.7276535593483546, 0.7299230600873085, 0.7243666146716027, 0.723662404981378, 0.737390059722613, 0.7357239784443215, 0.724913337051052, 0.7299108725704558, 0.7286898934677856, 0.7330196340606637, 0.7272864159655897, 0.7228906636368738, 0.7238485172186813, 0.7235509683824566, 0.7228363274711452, 0.7225779429690479, 0.7389246400904982, 0.7220766021780771, 0.7253705254972798, 0.7311427764696617, 0.7241224960921562, 0.724288232522468, 0.7305345449545612, 0.7239025026968081, 0.7180725429972558, 0.7196717282680616, 0.7248925668736027, 0.7238131165504456, 0.7216846363185203, 0.7226653980882201, 0.72531152016496, 0.7275155084590389, 0.7222253378123453, 0.717385812981488, 0.7258324729253168, 0.7305274593503508, 0.7236734089786059, 0.7341714150285068, 0.7285981288511459, 0.7170192827917126, 0.7243344069343723, 0.7222827440255308, 0.7311652943696061, 0.7269209966267625, 0.7196803264421959, 0.7291091945889878, 0.7265779988406456, 0.7236072510889132], 'val_acc': [0.9134473159705123, 0.9134473159705123, 0.9128601530643359, 0.9143136715235776, 0.9149346747626997, 0.9243215412309725, 0.932823510202643, 0.9503977984598239, 0.9559231886308487, 0.957415272111762, 0.957808061005318, 0.960125013165278, 0.9631153900329381, 0.9630193077538112, 0.9647225268083076, 0.9656351204604319, 0.9679386248327282, 0.9674530192597272, 0.9691664200939544, 0.9701412671232876, 0.9690037226840241, 0.9696524028908716, 0.9715037790879811, 0.9702639420555063, 0.9716774057852079, 0.9714702902591392, 0.9710920844992547, 0.9724644197993082, 0.9722609262760371, 0.97198501147636, 0.9722256293035534, 0.9730027816067003, 0.9735651898057494, 0.9732725314081532, 0.9728044030601031, 0.9740755562096426, 0.9737821441807158, 0.9736387349971353, 0.9731258288638233, 0.9738534917570141, 0.9745731476235063, 0.9738789849901852, 0.9753022687892391, 0.9750205208993938, 0.974862911929823, 0.9751399371721973, 0.9749946863683936, 0.9752309228459449, 0.974843977248832, 0.9745258301088254, 0.9761023786786485, 0.975768942947257, 0.9761664581625429, 0.9760037338080472, 0.9752764240519641, 0.9759899014479494, 0.9755352425248656, 0.9753426815548988, 0.9765392080561756, 0.976361194293793, 0.9761111221901358, 0.9761173112751687, 0.976123864928337, 0.9763677405984434, 0.9762716570945635, 0.9764154467680682, 0.9762028521054411, 0.9756007725245333, 0.9768744576467226, 0.9758290191219278, 0.9767714555132879, 0.976265454537248, 0.9757573028949842, 0.976415069135901, 0.9764096128613982, 0.9761548042297363, 0.975802432592601, 0.9770419124054582, 0.976037958305176, 0.9767718151824115, 0.976449290367022, 0.9769698324268812, 0.9772144470312824, 0.9770091412818596, 0.9771940879625817, 0.9767496067367188, 0.9767903726394862, 0.9767703544603635, 0.9765151841183232, 0.9769319785784368, 0.9760929235856827, 0.9772024375118621, 0.9768875694438203, 0.9768103977588758, 0.9766535118018111, 0.9755319850902034, 0.9770990552967542, 0.976943265085351, 0.9767681682763034, 0.9768136662163146, 0.9775238657650882, 0.9765133653601555, 0.976626208791994, 0.9769079587230943, 0.9768369606096451, 0.9773818919919941, 0.9763258940553012, 0.9770674048221275, 0.97658143019023, 0.9773607805167159, 0.9765686911262877, 0.9769854843616486, 0.9771092627962975, 0.9766778945922852, 0.9771365511090788, 0.9771565729624605, 0.9772388441105412, 0.9765595895786808, 0.9768933890617058, 0.9772854333054529, 0.9771937017571436, 0.9766946357406981, 0.9764532875524808, 0.9771580238864847, 0.9768282342446993, 0.9768162092117414, 0.9763804939511704, 0.9771576589100981, 0.9771867945586166, 0.9772479456581481, 0.9771372769793419, 0.977160585253206, 0.9773265874549134, 0.9774408756870113, 0.9774539736035752, 0.9768970192295231, 0.9772570423067433, 0.9771245489381764, 0.9773928192380357, 0.9774983664081521, 0.9773054465855637, 0.9777488251254983, 0.97760394297234, 0.977737546783604, 0.9775311452885197, 0.97733931182182, 0.9768267771969102, 0.9774674299645097, 0.9778594840062808, 0.9772577632779944, 0.9770491813143639, 0.9773425872195257, 0.9780593310316948, 0.9774011859338577, 0.9762552670420033, 0.9774634491090906, 0.9776258039964388, 0.9778351048900656, 0.9768304232865164, 0.9780866279177469, 0.9779428631475527, 0.9778427530641425, 0.976946186121196, 0.9780040028160566, 0.9769170496561755, 0.9777218875003187, 0.9770768468510614, 0.9779362964303526, 0.9771329062442257, 0.977874413745044, 0.9780131039554125, 0.9776192344214818, 0.9773931833979201, 0.9776774799987061, 0.9777622880184487, 0.9774561557051253, 0.9778780586098972, 0.9774368691117796, 0.9773327638841656, 0.9772836141390343, 0.9779741494622949, 0.9780076374746349, 0.9775624414012857, 0.9769028498701853, 0.97795267709314, 0.9778620367997313, 0.9780149157733133, 0.9772071695491059, 0.9780171129801501, 0.977704403743352, 0.9774255781141046, 0.978311590135914, 0.977349145771706, 0.9777386225249669, 0.9777997936287971, 0.977186430398732, 0.977270881198857, 0.9775806591935354, 0.9777033271854871, 0.9780942818073377, 0.9777451810771471, 0.9778846065475516, 0.9778285373563635, 0.9777870447668311, 0.9779555801659414, 0.9774656222291189, 0.9780098297824599, 0.9780305705658378, 0.9781692701659791, 0.978269733794748, 0.9775919322281668, 0.9778311081128578, 0.9774830990458188, 0.9769691049236141, 0.9769610974886646, 0.9779443018240471, 0.9779501189924267, 0.9774881903439352, 0.9778179999900191, 0.9778543788276307, 0.9778259890536739, 0.9778114418460898, 0.9780910080426359, 0.9773804463752328, 0.9775973958511875, 0.9775620886724289, 0.9775107711145322, 0.9769924042159563, 0.9770932336376138, 0.9769345403534092, 0.9776873114990862, 0.9765049819260427, 0.9773862672178713, 0.977096872378702, 0.9774721762905382], 'val_mDice': [0.021969316259332714, 0.03989798641980511, 0.0700635666614526, 0.09390539323834524, 0.1255771102868531, 0.1779832351085258, 0.2456524819135666, 0.31575343890549384, 0.37088307881191984, 0.39776264029006436, 0.41373358564834073, 0.4401286624065817, 0.46014309623470045, 0.4863060369883498, 0.5041932677977705, 0.5408372515684938, 0.5604575153899519, 0.5635691558661526, 0.5893342829730412, 0.597582125500457, 0.6093517211202073, 0.6162320746950907, 0.6215776135660198, 0.6267261358156596, 0.639189406617047, 0.634724251619757, 0.643205657397231, 0.6507812926214035, 0.6519437391464025, 0.6583304878783552, 0.665648148484426, 0.6647686537814467, 0.675190417733911, 0.6754676299552395, 0.6734525393949796, 0.6828359655321461, 0.6851410694318275, 0.6877418409471643, 0.6837680633753946, 0.6849194634450625, 0.6969358337252107, 0.6944504514948963, 0.6985506345964458, 0.7029556521814163, 0.6973151209419721, 0.7028541838469571, 0.7034424543380737, 0.7029941469839175, 0.7108679601590927, 0.7031637352623351, 0.7030885252234054, 0.7090625460833719, 0.709651964576277, 0.7098050717621633, 0.7192553265454018, 0.7109307054787466, 0.7162708868719128, 0.7161020624311003, 0.7116823347464, 0.7104235442533885, 0.7189048067347644, 0.7133951297361557, 0.7187330392125535, 0.7195241279798011, 0.7220219879934232, 0.722722932492217, 0.7206499098914944, 0.7160748725068079, 0.7173191329387769, 0.7222474813461304, 0.7222648707971181, 0.720307515908594, 0.7272180233099689, 0.7220312642724547, 0.7198631506260127, 0.7199452878677681, 0.7233582171675277, 0.7274253486770473, 0.7210896419335718, 0.7243577033689578, 0.719308560433453, 0.7256696493658301, 0.7282059519258264, 0.7229621728805646, 0.7269002680909143, 0.7274198932190464, 0.7328224382171892, 0.7304080618570928, 0.721434670360121, 0.727556438886956, 0.7265465904588568, 0.7280191770971638, 0.7239017633542623, 0.7237943390460864, 0.7286139281645213, 0.7262172319301187, 0.7281445485271819, 0.7338777739707738, 0.7327329144902426, 0.724039761987451, 0.7274154975806197, 0.7301806305369286, 0.7286699271365388, 0.7305550085355158, 0.7296654422805734, 0.7268738681322908, 0.7326399753355, 0.7267203624934366, 0.7317827829759415, 0.7345568100883536, 0.7311359252015205, 0.7337150210387087, 0.7316442621897344, 0.7299197801988418, 0.7376213939222571, 0.7338791926429696, 0.7307047778612947, 0.7339391283792992, 0.7352414343455066, 0.7349605094896604, 0.7324296770847007, 0.7314034704476187, 0.7381622783125263, 0.7320763068656398, 0.735511792032686, 0.7380644005455382, 0.7411964523465666, 0.7360552475877005, 0.7394550626408564, 0.7354232207553028, 0.7359015966114932, 0.735492907974818, 0.7392881475899318, 0.741915084727823, 0.7382902445858472, 0.737554814717541, 0.737998365947645, 0.7376820779826543, 0.739820417884278, 0.7399291151190457, 0.7406719943431959, 0.7403975978289565, 0.7412092579554205, 0.7378671781657493, 0.7372108616241037, 0.7331789091025314, 0.7397199305769515, 0.7408609030997917, 0.7377369865162732, 0.7355008684609035, 0.7392926371260865, 0.7408988528872189, 0.7389210103309318, 0.7387006384869145, 0.7377942722954162, 0.7404598565134284, 0.7423571340025288, 0.7375881831123404, 0.7372197884402863, 0.7395280154600535, 0.7457805712745614, 0.7391126119110683, 0.7456435148846613, 0.7452751075568265, 0.739960835812843, 0.7430862731313053, 0.7426477021550479, 0.7453335148014434, 0.7363208973244445, 0.7416824841336028, 0.742822871224521, 0.7422270325765218, 0.741768238070893, 0.742561301548187, 0.7393919437715452, 0.740536382753555, 0.742721678867732, 0.7429430799124992, 0.7425441051999183, 0.7487587985927111, 0.740269224529397, 0.7452777228126787, 0.742914618286368, 0.7426991479037559, 0.7444763840877846, 0.7481224014334482, 0.7477155352291995, 0.7436534762382507, 0.7428813854308978, 0.7428411620936982, 0.7467372417449951, 0.7416324505250748, 0.7373167076339461, 0.742234910187656, 0.7452859784642311, 0.7438650792592192, 0.7410420501885349, 0.7413443175897206, 0.7441352805862688, 0.7432217185627924, 0.7439490152548437, 0.7440812057011748, 0.7468320898813744, 0.7370050373959215, 0.749903336371461, 0.7452219132691213, 0.7470119485299881, 0.7467959870214331, 0.7477471563097549, 0.7433245308595161, 0.7446132302284241, 0.7457326736352216, 0.7482896814607594, 0.7423713570588255, 0.7475214727120857, 0.7484204205748153, 0.7468596247777547, 0.7462836099814062, 0.748323722653193, 0.745809259071742, 0.7463059992822882, 0.7455760326287518, 0.7450506409553632, 0.7492603067665884, 0.7462534092060508, 0.7479313554829115, 0.7482994709112872, 0.7460483937230828, 0.7441106324326502, 0.7477963685172878, 0.7461045310921866, 0.7457823479828769, 0.7461106132154596, 0.7474053563320473, 0.7474251405833519], 'loss': [62.79803777171926, 6.740626416600947, 5.152893008436144, 4.49885365795679, 4.004975396211742, 3.570331955439809, 3.1953195092063207, 2.9080622089679595, 2.7070656736831595, 2.5575159582277514, 2.449466434649556, 2.3317020628399328, 2.2364457679878424, 2.151682910106114, 2.050098715219057, 1.949835589382584, 1.8662293454791685, 1.7989286987992608, 1.733153679154397, 1.6835930283842124, 1.637337054851354, 1.5937361989178034, 1.5618274436898332, 1.521255053309419, 1.4918052379272262, 1.4661063392240803, 1.4393790852558734, 1.4117837149962797, 1.389692750133499, 1.3706767891532192, 1.348369034369415, 1.3290683923844768, 1.3143294869293574, 1.3018655215000738, 1.2862459690038013, 1.2698544270647905, 1.2496256953268443, 1.2365687639145997, 1.226016346704725, 1.2111966997130796, 1.2035414419712414, 1.1951747772073027, 1.1808362552399083, 1.166391742991289, 1.162385294503939, 1.151327432618152, 1.1394891354789378, 1.1329149851293885, 1.125737101987239, 1.1211143454802606, 1.1118338684747522, 1.1074649792813962, 1.099883903589092, 1.095913742440506, 1.0883336414330906, 1.0804164650739088, 1.0771003697968613, 1.0752758790173642, 1.0670212008785447, 1.0642456772660767, 1.059136874144655, 1.056393849877853, 1.0526163900344938, 1.0506174839389222, 1.0452339882416646, 1.041807860227957, 1.0391503309716925, 1.0356264245401514, 1.0324906254022677, 1.0270354278524603, 1.0259328640089294, 1.0209979171999748, 1.020865272437758, 1.0201163675372666, 1.016164931669437, 1.0159011901881392, 1.013258179162886, 1.010342033311622, 1.0086309429814864, 1.0068314321914738, 1.004759783751764, 1.004148420371046, 1.0000643542579435, 0.9961734229647697, 0.9936539972223163, 0.995183547030955, 0.9913023563286006, 0.9908350664044847, 0.9913205723744357, 0.9928672703264811, 0.9897421472396867, 0.98414785424378, 0.9847215637869878, 0.9827656684694442, 0.9843139114483413, 0.9810029434059848, 0.9828631664892066, 0.9802778148525876, 0.975366996428416, 0.9750128301033153, 0.9761915034980991, 0.9726705685846087, 0.9700205744424552, 0.9731024172318815, 0.9700119220838184, 0.9681364981586591, 0.9693723251529013, 0.9668794581344762, 0.9678049553985555, 0.9651141702537048, 0.9674577492852688, 0.9616795311971391, 0.9622159891860721, 0.9604029468920922, 0.9611179842375073, 0.9576919581296731, 0.9581217633838498, 0.9566480815381887, 0.9553582064372568, 0.9552029106158958, 0.9522825810092175, 0.9532224943916036, 0.9527276648306618, 0.9533180342311658, 0.9505039114849592, 0.9513300940601951, 0.9484890353131555, 0.9501337132095872, 0.9507673349292705, 0.9487677954140556, 0.9451395262335632, 0.946038396082773, 0.9459912109630092, 0.9470585733070402, 0.9437315562350634, 0.9441084768250567, 0.9411542603691386, 0.9411571847225616, 0.9407217118362501, 0.9396890170117781, 0.9402413902681899, 0.936954244617221, 0.9400307765405858, 0.9351155741860294, 0.937912470369754, 0.9359208038456038, 0.9373926556399371, 0.9352505988221874, 0.9333649472452841, 0.9332454029815939, 0.9336977227664096, 0.9319919461864776, 0.9319703802972698, 0.9306251004713864, 0.9297493136476636, 0.9294076370724116, 0.934902133948947, 0.9305910705281968, 0.9296489713510735, 0.9309272248131136, 0.9289558568677705, 0.924897480090846, 0.9266871906897034, 0.9249859437238016, 0.9249455195687479, 0.9251218201786738, 0.9249746431338712, 0.9254490345266907, 0.9252241929974451, 0.9213015367277639, 0.9228772607198525, 0.921780031148747, 0.9226651779254825, 0.9211804933737914, 0.9216831312968855, 0.9213789051438224, 0.919796767318224, 0.9197287284237453, 0.9189983312322626, 0.9171864166177148, 0.9197314578692042, 0.9165362191117524, 0.9190970907941417, 0.9175362036560718, 0.9160459365113465, 0.915529150236968, 0.9164110837591615, 0.9151878451271467, 0.9161293627144406, 0.9146399534899411, 0.9128942227681301, 0.9129490244028924, 0.9140532781166699, 0.9131035323608145, 0.9121852204913868, 0.9127630440923035, 0.9107124579918575, 0.9109346733431545, 0.9089464701852532, 0.9082252142288477, 0.9096349630492458, 0.9081903097643795, 0.9089797527521534, 0.9082219806890774, 0.9085491561442663, 0.9077949945544833, 0.908520169768358, 0.9073531419028719, 0.9063150517635675, 0.9065148865948517, 0.9108504327993933, 0.9054696651241958, 0.9040698793067824, 0.905887344185545, 0.9043984510472404, 0.9028368155877787, 0.9031437306704249, 0.9032076002172725, 0.9044871047779051, 0.9042148561088474, 0.9009469464759527, 0.901198913855256, 0.9020942960039864, 0.8992096547494653, 0.9013105042153448, 0.9018540231987587, 0.9008597831946349, 0.899701832514153, 0.8991566889774047, 0.9013183925549859, 0.8989267091250338, 0.8981253367914361, 0.8988486165896721, 0.8991438265685386, 0.9001003140365941], 'acc': [0.6740863049620347, 0.8977630728123831, 0.8986207504600863, 0.8992690057305004, 0.901505293831882, 0.9066382072547458, 0.9128900022097418, 0.9189700525814358, 0.9239856312261029, 0.9272331864214833, 0.9291152636587399, 0.931219002221991, 0.9327335633813999, 0.9342929970942909, 0.9363028172573599, 0.9383271227050008, 0.9402677330794268, 0.9415960304076036, 0.9428259479068228, 0.943686174225466, 0.9446467893647253, 0.9455970841848141, 0.9463095172433211, 0.9473002230301208, 0.9480019919705326, 0.9485394018513018, 0.9491318921346745, 0.9497826992244547, 0.9504099742775279, 0.9507266126992852, 0.9512587286109286, 0.9517231044082608, 0.9520578266103628, 0.9523738820935808, 0.9527801625257147, 0.9530751193808995, 0.9535749586836517, 0.95388547362658, 0.9541157187424577, 0.9544338740218467, 0.9545933181529758, 0.9548189338962568, 0.9552883113187229, 0.9556029512483624, 0.9556728980990397, 0.9558866638678563, 0.9562345930562375, 0.9563994043171794, 0.9564983466199073, 0.9566837676353147, 0.9568960349601955, 0.9569979577795547, 0.9571418172911315, 0.9571979004157021, 0.9572860643377511, 0.9574239474473801, 0.9575664234699137, 0.957508977846764, 0.9577089379400143, 0.9577149218999079, 0.9577628906258411, 0.9577398817937595, 0.9578019778546589, 0.9579266784788528, 0.9579373108972394, 0.957989634430617, 0.9580755643692009, 0.958096425181912, 0.9581243752962113, 0.9582307037689455, 0.9582132029903384, 0.9583193701636942, 0.9583095205629342, 0.9583108545964101, 0.958404682464982, 0.9583798903598286, 0.958427017803933, 0.9584781766811091, 0.9584511477284572, 0.9584628696947007, 0.958534964182686, 0.9585325190995572, 0.9586121777901219, 0.9587348575442434, 0.9587750397933191, 0.958763666819754, 0.9588478042267106, 0.9589004242895333, 0.9589036421446268, 0.9588366669915407, 0.9589637753543948, 0.9590838609663767, 0.9590411873959743, 0.9590662168079908, 0.9590471708703899, 0.959116411637706, 0.9591025075565919, 0.9591642886341334, 0.9593261282491916, 0.959299837455927, 0.9593328085627761, 0.9593997431568964, 0.9594742570666154, 0.9593831353764619, 0.9595263964687809, 0.9594651378489751, 0.9594935609510797, 0.9596043954447577, 0.9595689244273542, 0.9596275293808098, 0.9595858839610851, 0.9596748767464907, 0.9596568537370872, 0.9597106630661165, 0.9597041265287367, 0.959784760484466, 0.9597781927931813, 0.9598380051680006, 0.9598744059736237, 0.9598886774812206, 0.9599642944833481, 0.959960052367147, 0.9598915196940482, 0.9599337194665575, 0.9599814457493269, 0.9600194152725582, 0.9600109918944042, 0.9599956329474766, 0.9600229983163389, 0.9600443716617749, 0.9601001707155898, 0.960147739602914, 0.960139491950594, 0.9600845761049558, 0.9601580770402146, 0.960237202762012, 0.9601654635578116, 0.9601911808262159, 0.960267550373969, 0.9602721075539624, 0.9602616899093609, 0.9603687765064098, 0.960242744057809, 0.9604042984702867, 0.9603931601147829, 0.960344412676242, 0.9603502239122225, 0.9604405983826461, 0.960468753739273, 0.9604854847507089, 0.9603945877392428, 0.9604642356589385, 0.9604937522903949, 0.9605188938938133, 0.9605196017065107, 0.9605676449404044, 0.9604797487063801, 0.9605459234468494, 0.9605666179100607, 0.9605434749136661, 0.960564251663978, 0.9607073927139385, 0.9606299792705051, 0.9606987967066687, 0.9606954365806399, 0.960690149816124, 0.9607187871548278, 0.9606664925777767, 0.9607211098055523, 0.9607543672985144, 0.9607352205193573, 0.9607542044134323, 0.9607855858409357, 0.9607863153450241, 0.96079761549113, 0.9607591736436758, 0.960782820382482, 0.9608418757447025, 0.9608165164689937, 0.9608932959871974, 0.9608464751497994, 0.9609711357809398, 0.9608606757775945, 0.9608954890267615, 0.9609016485372573, 0.9609349542246927, 0.9609129678324576, 0.9609509719366671, 0.960993009872612, 0.9610100460142117, 0.9610230046626465, 0.9609944128870671, 0.9609854661836367, 0.9610060096918873, 0.9610790068215362, 0.961058252202131, 0.9610627175262219, 0.9610664977057077, 0.9611651639983397, 0.9611061918826854, 0.9611765046545762, 0.9611719157001852, 0.9611409748368702, 0.9611469982698674, 0.9611218260468573, 0.9611198276840087, 0.9611543234735921, 0.9611608922047766, 0.9612118934710587, 0.9612087090220289, 0.9611684745050602, 0.9612119966997883, 0.9613132328290561, 0.9612240545364384, 0.9612916751225958, 0.9613377207319124, 0.961319841363699, 0.9613007931337224, 0.9612973599418042, 0.9613058446539391, 0.9613763336917224, 0.9613224131508651, 0.9613329643392868, 0.9614020108090774, 0.9614120530871875, 0.961360842283964, 0.9614423687954777, 0.961432316293601, 0.9614418357462761, 0.9614272948845167, 0.9614844683699048, 0.9615095988705253, 0.9614654101689549, 0.9615335441410148, 0.961505257173862], 'mDice': [0.016687446481367496, 0.03178826913264862, 0.04680856195930154, 0.06622534237747807, 0.0951934592597536, 0.1312105335024812, 0.17410551680100153, 0.21910617287572398, 0.252726283818706, 0.2780466744026923, 0.297734692597241, 0.31873050462918673, 0.33662154964926366, 0.3531665209977217, 0.37481544925434696, 0.399318223733765, 0.4199944095279149, 0.43546194963337076, 0.4525758975244119, 0.46492984260390813, 0.476555324225858, 0.48753302822320327, 0.4964945084549179, 0.5066093593811413, 0.51486645676359, 0.5221906260436595, 0.5292938690690214, 0.5365341997036297, 0.5431019403462329, 0.5485112983965921, 0.5555238949229294, 0.5609469092824705, 0.5656463203243338, 0.5698010647944401, 0.5746829684909392, 0.5796102302563587, 0.5855262967108348, 0.5899599760180468, 0.5933630162620839, 0.5982397998107233, 0.6003888236068176, 0.6033235759044292, 0.6080163877822387, 0.6123157861267344, 0.6142935128325502, 0.61722381827722, 0.6209957392808989, 0.6230905207790658, 0.6251024926442446, 0.6268227875672212, 0.6296086773004145, 0.6313540432486363, 0.6330184372334694, 0.6348742230828225, 0.6368254891441117, 0.6391385469593377, 0.640457336994773, 0.6412099425410861, 0.6438867055517753, 0.6443195343189937, 0.6464074347196036, 0.6467162596127448, 0.6479496168765086, 0.6489988265540135, 0.6499260709603911, 0.6514208374773085, 0.6522305251644389, 0.6532396191407114, 0.6538780657686298, 0.6557398798138362, 0.656102061300394, 0.6578287087358264, 0.6577712947894041, 0.6582396310394635, 0.6590982900567156, 0.6595927331584225, 0.6603756729186463, 0.6611978487052873, 0.6613423471864698, 0.6620175521875543, 0.6627882975625143, 0.6628662271725769, 0.664180352846521, 0.6656609878545094, 0.6660688099007852, 0.6656376039259657, 0.6665632360710846, 0.6671021592732516, 0.6671272625353912, 0.6665619473192134, 0.6674944826899233, 0.6689187785626446, 0.6687918041084374, 0.6699284286095474, 0.6690918324947288, 0.6701984830095461, 0.6696655654299374, 0.6705280023687713, 0.6715875794769305, 0.671805127608448, 0.6714292262552951, 0.672742875511488, 0.6731528008183524, 0.67272122015786, 0.6737173162596422, 0.6741492230091631, 0.6737537389146523, 0.6745170549063104, 0.674447421160277, 0.6750835054575366, 0.6743866398717255, 0.6760789185404761, 0.6763007618546848, 0.6766390821044258, 0.6761807774548313, 0.6775700287581283, 0.6774482127873144, 0.677771764172951, 0.6780217447661913, 0.6780428917897834, 0.6788748753226529, 0.6787700458770028, 0.6791625275480425, 0.6789951484613208, 0.6796328906432894, 0.679753212895679, 0.6803513133265586, 0.6805244016270448, 0.6796853642497237, 0.6805625723220565, 0.6814721800705411, 0.6811692822329412, 0.681566886743515, 0.6810933992721252, 0.6821808890352089, 0.6819231446475671, 0.6829685136963818, 0.6824374371703559, 0.6832364802820389, 0.6832625989000667, 0.6831021806643242, 0.684194448876251, 0.6833646551339768, 0.684834789150255, 0.6838482832315715, 0.6845029166155111, 0.6842936037752944, 0.6852123147378778, 0.6853929203879984, 0.6855544795863134, 0.685348087543177, 0.6857127983763486, 0.6859216021970931, 0.6858629805650233, 0.6865876729680611, 0.6865848883834941, 0.6851162839506935, 0.6862726143925637, 0.6867015907762022, 0.6863311848167488, 0.6867735954047778, 0.6878041690749154, 0.6875299870424934, 0.687960052586181, 0.6882119879986189, 0.6880847105601189, 0.6879460756574989, 0.6879716319080444, 0.6882601891306718, 0.6893062339075399, 0.6887553077162567, 0.68896711201856, 0.6891196998143875, 0.6892791056904174, 0.6889506886048951, 0.689196448511914, 0.6896939667151735, 0.6897984921940838, 0.6901231623309522, 0.6903703279268645, 0.6899957449541096, 0.6908222335931209, 0.6902045009452077, 0.6905399250279818, 0.6908994675992546, 0.6913131583517755, 0.6909029547769113, 0.6913438458759599, 0.6909402420080807, 0.6912316874145766, 0.6920604635459313, 0.692499929080211, 0.6919196062567401, 0.6916684837385892, 0.6924737967711264, 0.6922955586971263, 0.6928088756215228, 0.6925168025866492, 0.693573114277225, 0.6935177824745306, 0.6933484839855306, 0.6935913057963621, 0.6932375588568269, 0.6938434324584425, 0.6932969153016451, 0.693452772223649, 0.693794370297955, 0.6940985400077262, 0.6940828851834453, 0.694228697750412, 0.6933288345871687, 0.6942081245102188, 0.6948205554874278, 0.6944949907925372, 0.6952307536128722, 0.6954738345081373, 0.695241228179062, 0.6952456254385495, 0.6949754688066312, 0.6950740064877856, 0.6962331572356434, 0.6961595495153124, 0.695926981800418, 0.6967117306645954, 0.6959384612832806, 0.6959094213826943, 0.6961436518887864, 0.6965472970998651, 0.6967730679921779, 0.6959991531433201, 0.6965791305534362, 0.6969722928360368, 0.6968704811394534, 0.6969271725048771, 0.6962986186910143]}
predicting test subjects:   0%|          | 0/15 [00:00<?, ?it/s]predicting test subjects:   7%|▋         | 1/15 [00:02<00:28,  2.01s/it]predicting test subjects:  13%|█▎        | 2/15 [00:03<00:24,  1.88s/it]predicting test subjects:  20%|██        | 3/15 [00:05<00:22,  1.90s/it]predicting test subjects:  27%|██▋       | 4/15 [00:07<00:21,  1.93s/it]predicting test subjects:  33%|███▎      | 5/15 [00:09<00:20,  2.05s/it]predicting test subjects:  40%|████      | 6/15 [00:12<00:19,  2.15s/it]predicting test subjects:  47%|████▋     | 7/15 [00:13<00:15,  1.92s/it]predicting test subjects:  53%|█████▎    | 8/15 [00:16<00:14,  2.10s/it]predicting test subjects:  60%|██████    | 9/15 [00:18<00:12,  2.05s/it]predicting test subjects:  67%|██████▋   | 10/15 [00:19<00:09,  1.91s/it]predicting test subjects:  73%|███████▎  | 11/15 [00:21<00:07,  1.89s/it]predicting test subjects:  80%|████████  | 12/15 [00:23<00:05,  1.95s/it]predicting test subjects:  87%|████████▋ | 13/15 [00:25<00:04,  2.02s/it]predicting test subjects:  93%|█████████▎| 14/15 [00:27<00:01,  1.97s/it]predicting test subjects: 100%|██████████| 15/15 [00:29<00:00,  1.98s/it]
predicting train subjects:   0%|          | 0/532 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/532 [00:02<21:05,  2.38s/it]predicting train subjects:   0%|          | 2/532 [00:04<19:34,  2.22s/it]predicting train subjects:   1%|          | 3/532 [00:06<18:27,  2.09s/it]predicting train subjects:   1%|          | 4/532 [00:07<17:32,  1.99s/it]predicting train subjects:   1%|          | 5/532 [00:09<17:17,  1.97s/it]predicting train subjects:   1%|          | 6/532 [00:11<16:27,  1.88s/it]predicting train subjects:   1%|▏         | 7/532 [00:13<16:16,  1.86s/it]predicting train subjects:   2%|▏         | 8/532 [00:14<15:40,  1.80s/it]predicting train subjects:   2%|▏         | 9/532 [00:16<16:37,  1.91s/it]predicting train subjects:   2%|▏         | 10/532 [00:18<16:03,  1.85s/it]predicting train subjects:   2%|▏         | 11/532 [00:20<15:16,  1.76s/it]predicting train subjects:   2%|▏         | 12/532 [00:22<16:38,  1.92s/it]predicting train subjects:   2%|▏         | 13/532 [00:24<15:38,  1.81s/it]predicting train subjects:   3%|▎         | 14/532 [00:25<14:51,  1.72s/it]predicting train subjects:   3%|▎         | 15/532 [00:27<14:32,  1.69s/it]predicting train subjects:   3%|▎         | 16/532 [00:29<15:03,  1.75s/it]predicting train subjects:   3%|▎         | 17/532 [00:30<14:37,  1.70s/it]predicting train subjects:   3%|▎         | 18/532 [00:32<15:18,  1.79s/it]predicting train subjects:   4%|▎         | 19/532 [00:34<14:32,  1.70s/it]predicting train subjects:   4%|▍         | 20/532 [00:36<15:06,  1.77s/it]predicting train subjects:   4%|▍         | 21/532 [00:38<15:40,  1.84s/it]predicting train subjects:   4%|▍         | 22/532 [00:39<15:00,  1.76s/it]predicting train subjects:   4%|▍         | 23/532 [00:41<14:59,  1.77s/it]predicting train subjects:   5%|▍         | 24/532 [00:43<14:30,  1.71s/it]predicting train subjects:   5%|▍         | 25/532 [00:45<15:42,  1.86s/it]predicting train subjects:   5%|▍         | 26/532 [00:46<15:10,  1.80s/it]predicting train subjects:   5%|▌         | 27/532 [00:49<16:39,  1.98s/it]predicting train subjects:   5%|▌         | 28/532 [00:51<16:02,  1.91s/it]predicting train subjects:   5%|▌         | 29/532 [00:53<17:00,  2.03s/it]predicting train subjects:   6%|▌         | 30/532 [00:54<15:41,  1.88s/it]predicting train subjects:   6%|▌         | 31/532 [00:56<15:34,  1.86s/it]predicting train subjects:   6%|▌         | 32/532 [00:58<15:11,  1.82s/it]predicting train subjects:   6%|▌         | 33/532 [01:00<14:26,  1.74s/it]predicting train subjects:   6%|▋         | 34/532 [01:02<15:30,  1.87s/it]predicting train subjects:   7%|▋         | 35/532 [01:04<15:22,  1.86s/it]predicting train subjects:   7%|▋         | 36/532 [01:06<16:01,  1.94s/it]predicting train subjects:   7%|▋         | 37/532 [01:08<15:51,  1.92s/it]predicting train subjects:   7%|▋         | 38/532 [01:10<16:19,  1.98s/it]predicting train subjects:   7%|▋         | 39/532 [01:11<15:53,  1.93s/it]predicting train subjects:   8%|▊         | 40/532 [01:13<15:11,  1.85s/it]predicting train subjects:   8%|▊         | 41/532 [01:15<15:31,  1.90s/it]predicting train subjects:   8%|▊         | 42/532 [01:17<15:31,  1.90s/it]predicting train subjects:   8%|▊         | 43/532 [01:19<14:36,  1.79s/it]predicting train subjects:   8%|▊         | 44/532 [01:20<13:45,  1.69s/it]predicting train subjects:   8%|▊         | 45/532 [01:22<13:44,  1.69s/it]predicting train subjects:   9%|▊         | 46/532 [01:24<14:15,  1.76s/it]predicting train subjects:   9%|▉         | 47/532 [01:26<15:13,  1.88s/it]predicting train subjects:   9%|▉         | 48/532 [01:28<15:19,  1.90s/it]predicting train subjects:   9%|▉         | 49/532 [01:29<14:33,  1.81s/it]predicting train subjects:   9%|▉         | 50/532 [01:31<15:16,  1.90s/it]predicting train subjects:  10%|▉         | 51/532 [01:33<15:19,  1.91s/it]predicting train subjects:  10%|▉         | 52/532 [01:35<15:04,  1.88s/it]predicting train subjects:  10%|▉         | 53/532 [01:37<14:24,  1.81s/it]predicting train subjects:  10%|█         | 54/532 [01:39<14:58,  1.88s/it]predicting train subjects:  10%|█         | 55/532 [01:41<14:44,  1.85s/it]predicting train subjects:  11%|█         | 56/532 [01:43<14:39,  1.85s/it]predicting train subjects:  11%|█         | 57/532 [01:44<14:21,  1.81s/it]predicting train subjects:  11%|█         | 58/532 [01:46<14:41,  1.86s/it]predicting train subjects:  11%|█         | 59/532 [01:48<15:35,  1.98s/it]predicting train subjects:  11%|█▏        | 60/532 [01:50<14:15,  1.81s/it]predicting train subjects:  11%|█▏        | 61/532 [01:51<13:38,  1.74s/it]predicting train subjects:  12%|█▏        | 62/532 [01:54<14:19,  1.83s/it]predicting train subjects:  12%|█▏        | 63/532 [01:56<14:47,  1.89s/it]predicting train subjects:  12%|█▏        | 64/532 [01:57<14:00,  1.80s/it]predicting train subjects:  12%|█▏        | 65/532 [01:59<14:01,  1.80s/it]predicting train subjects:  12%|█▏        | 66/532 [02:01<15:31,  2.00s/it]predicting train subjects:  13%|█▎        | 67/532 [02:04<17:10,  2.22s/it]predicting train subjects:  13%|█▎        | 68/532 [02:06<16:46,  2.17s/it]predicting train subjects:  13%|█▎        | 69/532 [02:08<16:28,  2.14s/it]predicting train subjects:  13%|█▎        | 70/532 [02:10<15:59,  2.08s/it]predicting train subjects:  13%|█▎        | 71/532 [02:12<15:11,  1.98s/it]predicting train subjects:  14%|█▎        | 72/532 [02:14<14:49,  1.93s/it]predicting train subjects:  14%|█▎        | 73/532 [02:16<15:10,  1.98s/it]predicting train subjects:  14%|█▍        | 74/532 [02:19<16:56,  2.22s/it]predicting train subjects:  14%|█▍        | 75/532 [02:22<19:26,  2.55s/it]predicting train subjects:  14%|█▍        | 76/532 [02:24<18:25,  2.42s/it]predicting train subjects:  14%|█▍        | 77/532 [02:26<17:31,  2.31s/it]predicting train subjects:  15%|█▍        | 78/532 [02:28<16:59,  2.25s/it]predicting train subjects:  15%|█▍        | 79/532 [02:30<16:52,  2.24s/it]predicting train subjects:  15%|█▌        | 80/532 [02:33<17:04,  2.27s/it]predicting train subjects:  15%|█▌        | 81/532 [02:35<17:22,  2.31s/it]predicting train subjects:  15%|█▌        | 82/532 [02:37<16:52,  2.25s/it]predicting train subjects:  16%|█▌        | 83/532 [02:39<16:00,  2.14s/it]predicting train subjects:  16%|█▌        | 84/532 [02:41<15:25,  2.07s/it]predicting train subjects:  16%|█▌        | 85/532 [02:43<14:44,  1.98s/it]predicting train subjects:  16%|█▌        | 86/532 [02:45<14:36,  1.97s/it]predicting train subjects:  16%|█▋        | 87/532 [02:47<14:09,  1.91s/it]predicting train subjects:  17%|█▋        | 88/532 [02:49<14:11,  1.92s/it]predicting train subjects:  17%|█▋        | 89/532 [02:51<14:25,  1.95s/it]predicting train subjects:  17%|█▋        | 90/532 [02:53<15:00,  2.04s/it]predicting train subjects:  17%|█▋        | 91/532 [02:55<15:11,  2.07s/it]predicting train subjects:  17%|█▋        | 92/532 [02:57<15:03,  2.05s/it]predicting train subjects:  17%|█▋        | 93/532 [02:59<15:10,  2.08s/it]predicting train subjects:  18%|█▊        | 94/532 [03:01<14:58,  2.05s/it]predicting train subjects:  18%|█▊        | 95/532 [03:04<15:56,  2.19s/it]predicting train subjects:  18%|█▊        | 96/532 [03:06<16:25,  2.26s/it]predicting train subjects:  18%|█▊        | 97/532 [03:09<17:09,  2.37s/it]predicting train subjects:  18%|█▊        | 98/532 [03:11<17:32,  2.43s/it]predicting train subjects:  19%|█▊        | 99/532 [03:14<17:51,  2.47s/it]predicting train subjects:  19%|█▉        | 100/532 [03:16<18:06,  2.52s/it]predicting train subjects:  19%|█▉        | 101/532 [03:18<16:48,  2.34s/it]predicting train subjects:  19%|█▉        | 102/532 [03:20<15:46,  2.20s/it]predicting train subjects:  19%|█▉        | 103/532 [03:22<15:08,  2.12s/it]predicting train subjects:  20%|█▉        | 104/532 [03:24<14:25,  2.02s/it]predicting train subjects:  20%|█▉        | 105/532 [03:26<14:23,  2.02s/it]predicting train subjects:  20%|█▉        | 106/532 [03:28<13:57,  1.97s/it]predicting train subjects:  20%|██        | 107/532 [03:29<13:07,  1.85s/it]predicting train subjects:  20%|██        | 108/532 [03:31<13:12,  1.87s/it]predicting train subjects:  20%|██        | 109/532 [03:33<13:17,  1.89s/it]predicting train subjects:  21%|██        | 110/532 [03:35<12:53,  1.83s/it]predicting train subjects:  21%|██        | 111/532 [03:36<12:18,  1.75s/it]predicting train subjects:  21%|██        | 112/532 [03:38<12:30,  1.79s/it]predicting train subjects:  21%|██        | 113/532 [03:41<13:21,  1.91s/it]predicting train subjects:  21%|██▏       | 114/532 [03:43<13:56,  2.00s/it]predicting train subjects:  22%|██▏       | 115/532 [03:45<14:20,  2.06s/it]predicting train subjects:  22%|██▏       | 116/532 [03:47<14:39,  2.12s/it]predicting train subjects:  22%|██▏       | 117/532 [03:49<14:53,  2.15s/it]predicting train subjects:  22%|██▏       | 118/532 [03:52<15:12,  2.21s/it]predicting train subjects:  22%|██▏       | 119/532 [03:54<15:05,  2.19s/it]predicting train subjects:  23%|██▎       | 120/532 [03:56<14:44,  2.15s/it]predicting train subjects:  23%|██▎       | 121/532 [03:58<15:03,  2.20s/it]predicting train subjects:  23%|██▎       | 122/532 [04:00<14:44,  2.16s/it]predicting train subjects:  23%|██▎       | 123/532 [04:02<14:34,  2.14s/it]predicting train subjects:  23%|██▎       | 124/532 [04:05<14:35,  2.14s/it]predicting train subjects:  23%|██▎       | 125/532 [04:07<14:52,  2.19s/it]predicting train subjects:  24%|██▎       | 126/532 [04:09<14:51,  2.20s/it]predicting train subjects:  24%|██▍       | 127/532 [04:11<14:25,  2.14s/it]predicting train subjects:  24%|██▍       | 128/532 [04:13<14:36,  2.17s/it]predicting train subjects:  24%|██▍       | 129/532 [04:16<15:03,  2.24s/it]predicting train subjects:  24%|██▍       | 130/532 [04:18<15:10,  2.27s/it]predicting train subjects:  25%|██▍       | 131/532 [04:21<15:53,  2.38s/it]predicting train subjects:  25%|██▍       | 132/532 [04:23<16:21,  2.45s/it]predicting train subjects:  25%|██▌       | 133/532 [04:26<16:48,  2.53s/it]predicting train subjects:  25%|██▌       | 134/532 [04:29<17:22,  2.62s/it]predicting train subjects:  25%|██▌       | 135/532 [04:32<17:34,  2.66s/it]predicting train subjects:  26%|██▌       | 136/532 [04:34<17:53,  2.71s/it]predicting train subjects:  26%|██▌       | 137/532 [04:37<17:59,  2.73s/it]predicting train subjects:  26%|██▌       | 138/532 [04:40<17:30,  2.67s/it]predicting train subjects:  26%|██▌       | 139/532 [04:42<17:38,  2.69s/it]predicting train subjects:  26%|██▋       | 140/532 [04:45<17:57,  2.75s/it]predicting train subjects:  27%|██▋       | 141/532 [04:48<17:42,  2.72s/it]predicting train subjects:  27%|██▋       | 142/532 [04:51<17:41,  2.72s/it]predicting train subjects:  27%|██▋       | 143/532 [04:53<16:03,  2.48s/it]predicting train subjects:  27%|██▋       | 144/532 [04:54<14:40,  2.27s/it]predicting train subjects:  27%|██▋       | 145/532 [04:57<14:15,  2.21s/it]predicting train subjects:  27%|██▋       | 146/532 [04:59<13:47,  2.14s/it]predicting train subjects:  28%|██▊       | 147/532 [05:01<13:41,  2.13s/it]predicting train subjects:  28%|██▊       | 148/532 [05:03<13:28,  2.11s/it]predicting train subjects:  28%|██▊       | 149/532 [05:05<13:54,  2.18s/it]predicting train subjects:  28%|██▊       | 150/532 [05:07<13:40,  2.15s/it]predicting train subjects:  28%|██▊       | 151/532 [05:09<13:23,  2.11s/it]predicting train subjects:  29%|██▊       | 152/532 [05:11<13:15,  2.09s/it]predicting train subjects:  29%|██▉       | 153/532 [05:13<13:24,  2.12s/it]predicting train subjects:  29%|██▉       | 154/532 [05:15<13:15,  2.11s/it]predicting train subjects:  29%|██▉       | 155/532 [05:18<14:42,  2.34s/it]predicting train subjects:  29%|██▉       | 156/532 [05:21<15:06,  2.41s/it]predicting train subjects:  30%|██▉       | 157/532 [05:24<15:48,  2.53s/it]predicting train subjects:  30%|██▉       | 158/532 [05:26<16:17,  2.61s/it]predicting train subjects:  30%|██▉       | 159/532 [05:29<16:25,  2.64s/it]predicting train subjects:  30%|███       | 160/532 [05:32<16:30,  2.66s/it]predicting train subjects:  30%|███       | 161/532 [05:34<15:38,  2.53s/it]predicting train subjects:  30%|███       | 162/532 [05:36<14:53,  2.41s/it]predicting train subjects:  31%|███       | 163/532 [05:38<14:20,  2.33s/it]predicting train subjects:  31%|███       | 164/532 [05:41<13:58,  2.28s/it]predicting train subjects:  31%|███       | 165/532 [05:43<13:59,  2.29s/it]predicting train subjects:  31%|███       | 166/532 [05:45<13:35,  2.23s/it]predicting train subjects:  31%|███▏      | 167/532 [05:47<13:21,  2.20s/it]predicting train subjects:  32%|███▏      | 168/532 [05:49<13:19,  2.20s/it]predicting train subjects:  32%|███▏      | 169/532 [05:51<13:15,  2.19s/it]predicting train subjects:  32%|███▏      | 170/532 [05:54<13:12,  2.19s/it]predicting train subjects:  32%|███▏      | 171/532 [05:56<13:17,  2.21s/it]predicting train subjects:  32%|███▏      | 172/532 [05:58<13:29,  2.25s/it]predicting train subjects:  33%|███▎      | 173/532 [06:00<13:02,  2.18s/it]predicting train subjects:  33%|███▎      | 174/532 [06:02<12:51,  2.16s/it]predicting train subjects:  33%|███▎      | 175/532 [06:04<12:30,  2.10s/it]predicting train subjects:  33%|███▎      | 176/532 [06:06<12:14,  2.06s/it]predicting train subjects:  33%|███▎      | 177/532 [06:08<11:58,  2.02s/it]predicting train subjects:  33%|███▎      | 178/532 [06:10<11:47,  2.00s/it]predicting train subjects:  34%|███▎      | 179/532 [06:12<11:41,  1.99s/it]predicting train subjects:  34%|███▍      | 180/532 [06:14<11:43,  2.00s/it]predicting train subjects:  34%|███▍      | 181/532 [06:16<11:39,  1.99s/it]predicting train subjects:  34%|███▍      | 182/532 [06:18<11:49,  2.03s/it]predicting train subjects:  34%|███▍      | 183/532 [06:20<11:39,  2.00s/it]predicting train subjects:  35%|███▍      | 184/532 [06:22<11:46,  2.03s/it]predicting train subjects:  35%|███▍      | 185/532 [06:24<11:20,  1.96s/it]predicting train subjects:  35%|███▍      | 186/532 [06:26<11:20,  1.97s/it]predicting train subjects:  35%|███▌      | 187/532 [06:28<11:13,  1.95s/it]predicting train subjects:  35%|███▌      | 188/532 [06:30<11:15,  1.96s/it]predicting train subjects:  36%|███▌      | 189/532 [06:32<11:06,  1.94s/it]predicting train subjects:  36%|███▌      | 190/532 [06:34<10:49,  1.90s/it]predicting train subjects:  36%|███▌      | 191/532 [06:37<12:24,  2.18s/it]predicting train subjects:  36%|███▌      | 192/532 [06:39<13:37,  2.40s/it]predicting train subjects:  36%|███▋      | 193/532 [06:42<14:10,  2.51s/it]predicting train subjects:  36%|███▋      | 194/532 [06:45<14:41,  2.61s/it]predicting train subjects:  37%|███▋      | 195/532 [06:48<14:57,  2.66s/it]predicting train subjects:  37%|███▋      | 196/532 [06:51<15:08,  2.70s/it]predicting train subjects:  37%|███▋      | 197/532 [06:53<14:43,  2.64s/it]predicting train subjects:  37%|███▋      | 198/532 [06:56<14:16,  2.57s/it]predicting train subjects:  37%|███▋      | 199/532 [06:58<14:19,  2.58s/it]predicting train subjects:  38%|███▊      | 200/532 [07:00<13:53,  2.51s/it]predicting train subjects:  38%|███▊      | 201/532 [07:03<13:31,  2.45s/it]predicting train subjects:  38%|███▊      | 202/532 [07:05<13:26,  2.45s/it]predicting train subjects:  38%|███▊      | 203/532 [07:07<12:32,  2.29s/it]predicting train subjects:  38%|███▊      | 204/532 [07:09<11:37,  2.13s/it]predicting train subjects:  39%|███▊      | 205/532 [07:11<10:54,  2.00s/it]predicting train subjects:  39%|███▊      | 206/532 [07:12<10:30,  1.93s/it]predicting train subjects:  39%|███▉      | 207/532 [07:14<10:11,  1.88s/it]predicting train subjects:  39%|███▉      | 208/532 [07:16<09:58,  1.85s/it]predicting train subjects:  39%|███▉      | 209/532 [07:17<09:27,  1.76s/it]predicting train subjects:  39%|███▉      | 210/532 [07:19<09:06,  1.70s/it]predicting train subjects:  40%|███▉      | 211/532 [07:21<08:45,  1.64s/it]predicting train subjects:  40%|███▉      | 212/532 [07:22<08:35,  1.61s/it]predicting train subjects:  40%|████      | 213/532 [07:24<08:33,  1.61s/it]predicting train subjects:  40%|████      | 214/532 [07:25<08:48,  1.66s/it]predicting train subjects:  40%|████      | 215/532 [07:28<09:44,  1.84s/it]predicting train subjects:  41%|████      | 216/532 [07:30<10:25,  1.98s/it]predicting train subjects:  41%|████      | 217/532 [07:32<10:49,  2.06s/it]predicting train subjects:  41%|████      | 218/532 [07:35<11:10,  2.14s/it]predicting train subjects:  41%|████      | 219/532 [07:37<11:28,  2.20s/it]predicting train subjects:  41%|████▏     | 220/532 [07:39<11:32,  2.22s/it]predicting train subjects:  42%|████▏     | 221/532 [07:41<10:25,  2.01s/it]predicting train subjects:  42%|████▏     | 222/532 [07:42<09:32,  1.85s/it]predicting train subjects:  42%|████▏     | 223/532 [07:44<09:04,  1.76s/it]predicting train subjects:  42%|████▏     | 224/532 [07:45<08:41,  1.69s/it]predicting train subjects:  42%|████▏     | 225/532 [07:47<08:22,  1.64s/it]predicting train subjects:  42%|████▏     | 226/532 [07:48<08:10,  1.60s/it]predicting train subjects:  43%|████▎     | 227/532 [07:50<08:01,  1.58s/it]predicting train subjects:  43%|████▎     | 228/532 [07:51<07:52,  1.55s/it]predicting train subjects:  43%|████▎     | 229/532 [07:53<07:44,  1.53s/it]predicting train subjects:  43%|████▎     | 230/532 [07:54<07:37,  1.52s/it]predicting train subjects:  43%|████▎     | 231/532 [07:56<07:28,  1.49s/it]predicting train subjects:  44%|████▎     | 232/532 [07:57<07:23,  1.48s/it]predicting train subjects:  44%|████▍     | 233/532 [07:59<07:39,  1.54s/it]predicting train subjects:  44%|████▍     | 234/532 [08:01<07:54,  1.59s/it]predicting train subjects:  44%|████▍     | 235/532 [08:02<07:59,  1.61s/it]predicting train subjects:  44%|████▍     | 236/532 [08:04<08:13,  1.67s/it]predicting train subjects:  45%|████▍     | 237/532 [08:06<08:24,  1.71s/it]predicting train subjects:  45%|████▍     | 238/532 [08:08<08:28,  1.73s/it]predicting train subjects:  45%|████▍     | 239/532 [08:10<08:44,  1.79s/it]predicting train subjects:  45%|████▌     | 240/532 [08:11<08:45,  1.80s/it]predicting train subjects:  45%|████▌     | 241/532 [08:13<08:54,  1.84s/it]predicting train subjects:  45%|████▌     | 242/532 [08:15<08:59,  1.86s/it]predicting train subjects:  46%|████▌     | 243/532 [08:17<09:05,  1.89s/it]predicting train subjects:  46%|████▌     | 244/532 [08:19<09:02,  1.88s/it]predicting train subjects:  46%|████▌     | 245/532 [08:21<08:31,  1.78s/it]predicting train subjects:  46%|████▌     | 246/532 [08:22<08:00,  1.68s/it]predicting train subjects:  46%|████▋     | 247/532 [08:23<07:40,  1.61s/it]predicting train subjects:  47%|████▋     | 248/532 [08:25<07:24,  1.57s/it]predicting train subjects:  47%|████▋     | 249/532 [08:26<07:12,  1.53s/it]predicting train subjects:  47%|████▋     | 250/532 [08:28<07:10,  1.53s/it]predicting train subjects:  47%|████▋     | 251/532 [08:30<07:18,  1.56s/it]predicting train subjects:  47%|████▋     | 252/532 [08:31<07:16,  1.56s/it]predicting train subjects:  48%|████▊     | 253/532 [08:33<07:23,  1.59s/it]predicting train subjects:  48%|████▊     | 254/532 [08:34<07:21,  1.59s/it]predicting train subjects:  48%|████▊     | 255/532 [08:36<07:19,  1.59s/it]predicting train subjects:  48%|████▊     | 256/532 [08:38<07:20,  1.60s/it]predicting train subjects:  48%|████▊     | 257/532 [08:40<07:59,  1.74s/it]predicting train subjects:  48%|████▊     | 258/532 [08:42<08:29,  1.86s/it]predicting train subjects:  49%|████▊     | 259/532 [08:44<09:00,  1.98s/it]predicting train subjects:  49%|████▉     | 260/532 [08:46<09:09,  2.02s/it]predicting train subjects:  49%|████▉     | 261/532 [08:48<09:12,  2.04s/it]predicting train subjects:  49%|████▉     | 262/532 [08:50<09:14,  2.05s/it]predicting train subjects:  49%|████▉     | 263/532 [08:52<08:31,  1.90s/it]predicting train subjects:  50%|████▉     | 264/532 [08:53<07:53,  1.77s/it]predicting train subjects:  50%|████▉     | 265/532 [08:55<07:24,  1.66s/it]predicting train subjects:  50%|█████     | 266/532 [08:56<07:02,  1.59s/it]predicting train subjects:  50%|█████     | 267/532 [08:58<06:57,  1.57s/it]predicting train subjects:  50%|█████     | 268/532 [08:59<06:46,  1.54s/it]predicting train subjects:  51%|█████     | 269/532 [09:01<07:10,  1.64s/it]predicting train subjects:  51%|█████     | 270/532 [09:03<07:19,  1.68s/it]predicting train subjects:  51%|█████     | 271/532 [09:05<07:34,  1.74s/it]predicting train subjects:  51%|█████     | 272/532 [09:07<07:44,  1.78s/it]predicting train subjects:  51%|█████▏    | 273/532 [09:08<07:46,  1.80s/it]predicting train subjects:  52%|█████▏    | 274/532 [09:10<07:54,  1.84s/it]predicting train subjects:  52%|█████▏    | 275/532 [09:13<08:27,  1.97s/it]predicting train subjects:  52%|█████▏    | 276/532 [09:15<09:00,  2.11s/it]predicting train subjects:  52%|█████▏    | 277/532 [09:17<09:11,  2.16s/it]predicting train subjects:  52%|█████▏    | 278/532 [09:20<09:26,  2.23s/it]predicting train subjects:  52%|█████▏    | 279/532 [09:22<09:30,  2.25s/it]predicting train subjects:  53%|█████▎    | 280/532 [09:24<09:31,  2.27s/it]predicting train subjects:  53%|█████▎    | 281/532 [09:26<09:19,  2.23s/it]predicting train subjects:  53%|█████▎    | 282/532 [09:29<09:11,  2.21s/it]predicting train subjects:  53%|█████▎    | 283/532 [09:31<09:06,  2.20s/it]predicting train subjects:  53%|█████▎    | 284/532 [09:33<09:03,  2.19s/it]predicting train subjects:  54%|█████▎    | 285/532 [09:35<08:59,  2.19s/it]predicting train subjects:  54%|█████▍    | 286/532 [09:37<08:53,  2.17s/it]predicting train subjects:  54%|█████▍    | 287/532 [09:39<08:08,  1.99s/it]predicting train subjects:  54%|█████▍    | 288/532 [09:40<07:37,  1.88s/it]predicting train subjects:  54%|█████▍    | 289/532 [09:42<07:15,  1.79s/it]predicting train subjects:  55%|█████▍    | 290/532 [09:44<07:02,  1.75s/it]predicting train subjects:  55%|█████▍    | 291/532 [09:45<06:45,  1.68s/it]predicting train subjects:  55%|█████▍    | 292/532 [09:47<06:49,  1.71s/it]predicting train subjects:  55%|█████▌    | 293/532 [09:49<06:54,  1.74s/it]predicting train subjects:  55%|█████▌    | 294/532 [09:51<07:04,  1.79s/it]predicting train subjects:  55%|█████▌    | 295/532 [09:53<07:07,  1.81s/it]predicting train subjects:  56%|█████▌    | 296/532 [09:54<07:13,  1.84s/it]predicting train subjects:  56%|█████▌    | 297/532 [09:56<07:08,  1.82s/it]predicting train subjects:  56%|█████▌    | 298/532 [09:58<07:17,  1.87s/it]predicting train subjects:  56%|█████▌    | 299/532 [10:00<07:00,  1.81s/it]predicting train subjects:  56%|█████▋    | 300/532 [10:01<06:40,  1.73s/it]predicting train subjects:  57%|█████▋    | 301/532 [10:03<06:25,  1.67s/it]predicting train subjects:  57%|█████▋    | 302/532 [10:04<06:11,  1.61s/it]predicting train subjects:  57%|█████▋    | 303/532 [10:06<05:58,  1.57s/it]predicting train subjects:  57%|█████▋    | 304/532 [10:07<05:56,  1.56s/it]predicting train subjects:  57%|█████▋    | 305/532 [10:10<06:52,  1.82s/it]predicting train subjects:  58%|█████▊    | 306/532 [10:12<07:26,  1.97s/it]predicting train subjects:  58%|█████▊    | 307/532 [10:14<07:44,  2.06s/it]predicting train subjects:  58%|█████▊    | 308/532 [10:17<07:52,  2.11s/it]predicting train subjects:  58%|█████▊    | 309/532 [10:19<08:01,  2.16s/it]predicting train subjects:  58%|█████▊    | 310/532 [10:21<08:02,  2.17s/it]predicting train subjects:  58%|█████▊    | 311/532 [10:24<08:50,  2.40s/it]predicting train subjects:  59%|█████▊    | 312/532 [10:27<09:24,  2.57s/it]predicting train subjects:  59%|█████▉    | 313/532 [10:30<09:48,  2.69s/it]predicting train subjects:  59%|█████▉    | 314/532 [10:33<10:13,  2.81s/it]predicting train subjects:  59%|█████▉    | 315/532 [10:36<10:20,  2.86s/it]predicting train subjects:  59%|█████▉    | 316/532 [10:39<10:23,  2.89s/it]predicting train subjects:  60%|█████▉    | 317/532 [10:41<09:02,  2.52s/it]predicting train subjects:  60%|█████▉    | 318/532 [10:43<08:13,  2.30s/it]predicting train subjects:  60%|█████▉    | 319/532 [10:44<07:34,  2.14s/it]predicting train subjects:  60%|██████    | 320/532 [10:46<07:08,  2.02s/it]predicting train subjects:  60%|██████    | 321/532 [10:48<06:46,  1.92s/it]predicting train subjects:  61%|██████    | 322/532 [10:49<06:30,  1.86s/it]predicting train subjects:  61%|██████    | 323/532 [10:52<06:59,  2.01s/it]predicting train subjects:  61%|██████    | 324/532 [10:54<07:25,  2.14s/it]predicting train subjects:  61%|██████    | 325/532 [10:57<07:38,  2.22s/it]predicting train subjects:  61%|██████▏   | 326/532 [10:59<07:52,  2.30s/it]predicting train subjects:  61%|██████▏   | 327/532 [11:02<08:07,  2.38s/it]predicting train subjects:  62%|██████▏   | 328/532 [11:04<08:04,  2.38s/it]predicting train subjects:  62%|██████▏   | 329/532 [11:06<07:28,  2.21s/it]predicting train subjects:  62%|██████▏   | 330/532 [11:08<07:08,  2.12s/it]predicting train subjects:  62%|██████▏   | 331/532 [11:10<06:47,  2.03s/it]predicting train subjects:  62%|██████▏   | 332/532 [11:11<06:32,  1.96s/it]predicting train subjects:  63%|██████▎   | 333/532 [11:13<06:19,  1.90s/it]predicting train subjects:  63%|██████▎   | 334/532 [11:15<06:13,  1.89s/it]predicting train subjects:  63%|██████▎   | 335/532 [11:17<06:27,  1.97s/it]predicting train subjects:  63%|██████▎   | 336/532 [11:19<06:35,  2.02s/it]predicting train subjects:  63%|██████▎   | 337/532 [11:22<06:53,  2.12s/it]predicting train subjects:  64%|██████▎   | 338/532 [11:24<06:54,  2.13s/it]predicting train subjects:  64%|██████▎   | 339/532 [11:26<06:48,  2.12s/it]predicting train subjects:  64%|██████▍   | 340/532 [11:28<06:47,  2.12s/it]predicting train subjects:  64%|██████▍   | 341/532 [11:30<06:14,  1.96s/it]predicting train subjects:  64%|██████▍   | 342/532 [11:31<05:55,  1.87s/it]predicting train subjects:  64%|██████▍   | 343/532 [11:33<05:37,  1.79s/it]predicting train subjects:  65%|██████▍   | 344/532 [11:34<05:24,  1.73s/it]predicting train subjects:  65%|██████▍   | 345/532 [11:36<05:15,  1.69s/it]predicting train subjects:  65%|██████▌   | 346/532 [11:38<05:10,  1.67s/it]predicting train subjects:  65%|██████▌   | 347/532 [11:40<05:18,  1.72s/it]predicting train subjects:  65%|██████▌   | 348/532 [11:41<05:21,  1.75s/it]predicting train subjects:  66%|██████▌   | 349/532 [11:43<05:19,  1.75s/it]predicting train subjects:  66%|██████▌   | 350/532 [11:45<05:23,  1.78s/it]predicting train subjects:  66%|██████▌   | 351/532 [11:47<05:27,  1.81s/it]predicting train subjects:  66%|██████▌   | 352/532 [11:49<05:29,  1.83s/it]predicting train subjects:  66%|██████▋   | 353/532 [11:50<05:25,  1.82s/it]predicting train subjects:  67%|██████▋   | 354/532 [11:52<05:23,  1.82s/it]predicting train subjects:  67%|██████▋   | 355/532 [11:54<05:15,  1.78s/it]predicting train subjects:  67%|██████▋   | 356/532 [11:56<05:14,  1.79s/it]predicting train subjects:  67%|██████▋   | 357/532 [11:58<05:15,  1.80s/it]predicting train subjects:  67%|██████▋   | 358/532 [12:00<05:17,  1.83s/it]predicting train subjects:  67%|██████▋   | 359/532 [12:01<05:02,  1.75s/it]predicting train subjects:  68%|██████▊   | 360/532 [12:03<04:54,  1.71s/it]predicting train subjects:  68%|██████▊   | 361/532 [12:04<04:44,  1.66s/it]predicting train subjects:  68%|██████▊   | 362/532 [12:06<04:38,  1.64s/it]predicting train subjects:  68%|██████▊   | 363/532 [12:07<04:34,  1.62s/it]predicting train subjects:  68%|██████▊   | 364/532 [12:09<04:32,  1.62s/it]predicting train subjects:  69%|██████▊   | 365/532 [12:11<04:24,  1.59s/it]predicting train subjects:  69%|██████▉   | 366/532 [12:12<04:27,  1.61s/it]predicting train subjects:  69%|██████▉   | 367/532 [12:14<04:25,  1.61s/it]predicting train subjects:  69%|██████▉   | 368/532 [12:15<04:24,  1.61s/it]predicting train subjects:  69%|██████▉   | 369/532 [12:17<04:24,  1.62s/it]predicting train subjects:  70%|██████▉   | 370/532 [12:19<04:23,  1.63s/it]predicting train subjects:  70%|██████▉   | 371/532 [12:21<04:58,  1.85s/it]predicting train subjects:  70%|██████▉   | 372/532 [12:23<05:16,  1.98s/it]predicting train subjects:  70%|███████   | 373/532 [12:26<05:28,  2.07s/it]predicting train subjects:  70%|███████   | 374/532 [12:28<05:36,  2.13s/it]predicting train subjects:  70%|███████   | 375/532 [12:30<05:46,  2.21s/it]predicting train subjects:  71%|███████   | 376/532 [12:33<05:44,  2.21s/it]predicting train subjects:  71%|███████   | 377/532 [12:35<05:32,  2.14s/it]predicting train subjects:  71%|███████   | 378/532 [12:36<05:15,  2.05s/it]predicting train subjects:  71%|███████   | 379/532 [12:38<05:03,  1.99s/it]predicting train subjects:  71%|███████▏  | 380/532 [12:40<04:51,  1.92s/it]predicting train subjects:  72%|███████▏  | 381/532 [12:42<04:44,  1.88s/it]predicting train subjects:  72%|███████▏  | 382/532 [12:44<04:39,  1.86s/it]predicting train subjects:  72%|███████▏  | 383/532 [12:45<04:38,  1.87s/it]predicting train subjects:  72%|███████▏  | 384/532 [12:47<04:36,  1.87s/it]predicting train subjects:  72%|███████▏  | 385/532 [12:49<04:34,  1.87s/it]predicting train subjects:  73%|███████▎  | 386/532 [12:51<04:31,  1.86s/it]predicting train subjects:  73%|███████▎  | 387/532 [12:53<04:28,  1.85s/it]predicting train subjects:  73%|███████▎  | 388/532 [12:55<04:26,  1.85s/it]predicting train subjects:  73%|███████▎  | 389/532 [12:57<04:28,  1.88s/it]predicting train subjects:  73%|███████▎  | 390/532 [12:59<04:29,  1.90s/it]predicting train subjects:  73%|███████▎  | 391/532 [13:01<04:37,  1.96s/it]predicting train subjects:  74%|███████▎  | 392/532 [13:03<04:38,  1.99s/it]predicting train subjects:  74%|███████▍  | 393/532 [13:05<04:42,  2.03s/it]predicting train subjects:  74%|███████▍  | 394/532 [13:07<04:39,  2.03s/it]predicting train subjects:  74%|███████▍  | 395/532 [13:09<04:31,  1.98s/it]predicting train subjects:  74%|███████▍  | 396/532 [13:11<04:27,  1.96s/it]predicting train subjects:  75%|███████▍  | 397/532 [13:13<04:22,  1.94s/it]predicting train subjects:  75%|███████▍  | 398/532 [13:15<04:18,  1.93s/it]predicting train subjects:  75%|███████▌  | 399/532 [13:16<04:15,  1.92s/it]predicting train subjects:  75%|███████▌  | 400/532 [13:18<04:13,  1.92s/it]predicting train subjects:  75%|███████▌  | 401/532 [13:20<04:21,  1.99s/it]predicting train subjects:  76%|███████▌  | 402/532 [13:23<04:22,  2.02s/it]predicting train subjects:  76%|███████▌  | 403/532 [13:25<04:23,  2.04s/it]predicting train subjects:  76%|███████▌  | 404/532 [13:27<04:20,  2.04s/it]predicting train subjects:  76%|███████▌  | 405/532 [13:29<04:17,  2.02s/it]predicting train subjects:  76%|███████▋  | 406/532 [13:31<04:13,  2.01s/it]predicting train subjects:  77%|███████▋  | 407/532 [13:32<04:03,  1.95s/it]predicting train subjects:  77%|███████▋  | 408/532 [13:34<03:54,  1.89s/it]predicting train subjects:  77%|███████▋  | 409/532 [13:36<03:48,  1.86s/it]predicting train subjects:  77%|███████▋  | 410/532 [13:38<03:46,  1.86s/it]predicting train subjects:  77%|███████▋  | 411/532 [13:40<03:41,  1.83s/it]predicting train subjects:  77%|███████▋  | 412/532 [13:41<03:39,  1.83s/it]predicting train subjects:  78%|███████▊  | 413/532 [13:43<03:33,  1.79s/it]predicting train subjects:  78%|███████▊  | 414/532 [13:45<03:24,  1.74s/it]predicting train subjects:  78%|███████▊  | 415/532 [13:46<03:20,  1.72s/it]predicting train subjects:  78%|███████▊  | 416/532 [13:48<03:18,  1.71s/it]predicting train subjects:  78%|███████▊  | 417/532 [13:50<03:15,  1.70s/it]predicting train subjects:  79%|███████▊  | 418/532 [13:52<03:14,  1.70s/it]predicting train subjects:  79%|███████▉  | 419/532 [13:53<03:19,  1.76s/it]predicting train subjects:  79%|███████▉  | 420/532 [13:55<03:21,  1.80s/it]predicting train subjects:  79%|███████▉  | 421/532 [13:57<03:25,  1.85s/it]predicting train subjects:  79%|███████▉  | 422/532 [13:59<03:25,  1.87s/it]predicting train subjects:  80%|███████▉  | 423/532 [14:01<03:30,  1.93s/it]predicting train subjects:  80%|███████▉  | 424/532 [14:03<03:28,  1.93s/it]predicting train subjects:  80%|███████▉  | 425/532 [14:05<03:30,  1.96s/it]predicting train subjects:  80%|████████  | 426/532 [14:07<03:29,  1.98s/it]predicting train subjects:  80%|████████  | 427/532 [14:09<03:28,  1.98s/it]predicting train subjects:  80%|████████  | 428/532 [14:11<03:24,  1.97s/it]predicting train subjects:  81%|████████  | 429/532 [14:13<03:21,  1.96s/it]predicting train subjects:  81%|████████  | 430/532 [14:15<03:19,  1.96s/it]predicting train subjects:  81%|████████  | 431/532 [14:17<03:22,  2.00s/it]predicting train subjects:  81%|████████  | 432/532 [14:19<03:26,  2.07s/it]predicting train subjects:  81%|████████▏ | 433/532 [14:21<03:23,  2.05s/it]predicting train subjects:  82%|████████▏ | 434/532 [14:24<03:23,  2.08s/it]predicting train subjects:  82%|████████▏ | 435/532 [14:26<03:19,  2.06s/it]predicting train subjects:  82%|████████▏ | 436/532 [14:28<03:17,  2.06s/it]predicting train subjects:  82%|████████▏ | 437/532 [14:29<03:00,  1.90s/it]predicting train subjects:  82%|████████▏ | 438/532 [14:31<02:50,  1.82s/it]predicting train subjects:  83%|████████▎ | 439/532 [14:32<02:43,  1.76s/it]predicting train subjects:  83%|████████▎ | 440/532 [14:34<02:37,  1.71s/it]predicting train subjects:  83%|████████▎ | 441/532 [14:36<02:33,  1.69s/it]predicting train subjects:  83%|████████▎ | 442/532 [14:37<02:28,  1.65s/it]predicting train subjects:  83%|████████▎ | 443/532 [14:39<02:22,  1.60s/it]predicting train subjects:  83%|████████▎ | 444/532 [14:40<02:21,  1.61s/it]predicting train subjects:  84%|████████▎ | 445/532 [14:42<02:16,  1.57s/it]predicting train subjects:  84%|████████▍ | 446/532 [14:43<02:10,  1.52s/it]predicting train subjects:  84%|████████▍ | 447/532 [14:45<02:08,  1.51s/it]predicting train subjects:  84%|████████▍ | 448/532 [14:46<02:05,  1.50s/it]predicting train subjects:  84%|████████▍ | 449/532 [14:48<02:11,  1.58s/it]predicting train subjects:  85%|████████▍ | 450/532 [14:50<02:10,  1.59s/it]predicting train subjects:  85%|████████▍ | 451/532 [14:51<02:10,  1.61s/it]predicting train subjects:  85%|████████▍ | 452/532 [14:53<02:10,  1.63s/it]predicting train subjects:  85%|████████▌ | 453/532 [14:55<02:08,  1.63s/it]predicting train subjects:  85%|████████▌ | 454/532 [14:56<02:06,  1.62s/it]predicting train subjects:  86%|████████▌ | 455/532 [14:58<02:11,  1.70s/it]predicting train subjects:  86%|████████▌ | 456/532 [15:00<02:14,  1.77s/it]predicting train subjects:  86%|████████▌ | 457/532 [15:02<02:15,  1.81s/it]predicting train subjects:  86%|████████▌ | 458/532 [15:04<02:15,  1.84s/it]predicting train subjects:  86%|████████▋ | 459/532 [15:06<02:15,  1.85s/it]predicting train subjects:  86%|████████▋ | 460/532 [15:08<02:13,  1.86s/it]predicting train subjects:  87%|████████▋ | 461/532 [15:10<02:25,  2.05s/it]predicting train subjects:  87%|████████▋ | 462/532 [15:12<02:27,  2.11s/it]predicting train subjects:  87%|████████▋ | 463/532 [15:15<02:29,  2.17s/it]predicting train subjects:  87%|████████▋ | 464/532 [15:17<02:27,  2.17s/it]predicting train subjects:  87%|████████▋ | 465/532 [15:19<02:29,  2.23s/it]predicting train subjects:  88%|████████▊ | 466/532 [15:21<02:27,  2.24s/it]predicting train subjects:  88%|████████▊ | 467/532 [15:23<02:18,  2.12s/it]predicting train subjects:  88%|████████▊ | 468/532 [15:25<02:10,  2.04s/it]predicting train subjects:  88%|████████▊ | 469/532 [15:27<02:06,  2.01s/it]predicting train subjects:  88%|████████▊ | 470/532 [15:29<01:59,  1.93s/it]predicting train subjects:  89%|████████▊ | 471/532 [15:31<01:55,  1.89s/it]predicting train subjects:  89%|████████▊ | 472/532 [15:32<01:50,  1.84s/it]predicting train subjects:  89%|████████▉ | 473/532 [15:34<01:50,  1.88s/it]predicting train subjects:  89%|████████▉ | 474/532 [15:36<01:50,  1.90s/it]predicting train subjects:  89%|████████▉ | 475/532 [15:38<01:49,  1.92s/it]predicting train subjects:  89%|████████▉ | 476/532 [15:40<01:47,  1.93s/it]predicting train subjects:  90%|████████▉ | 477/532 [15:42<01:48,  1.97s/it]predicting train subjects:  90%|████████▉ | 478/532 [15:44<01:49,  2.03s/it]predicting train subjects:  90%|█████████ | 479/532 [15:46<01:41,  1.92s/it]predicting train subjects:  90%|█████████ | 480/532 [15:48<01:35,  1.84s/it]predicting train subjects:  90%|█████████ | 481/532 [15:49<01:33,  1.83s/it]predicting train subjects:  91%|█████████ | 482/532 [15:51<01:29,  1.78s/it]predicting train subjects:  91%|█████████ | 483/532 [15:53<01:24,  1.73s/it]predicting train subjects:  91%|█████████ | 484/532 [15:54<01:21,  1.70s/it]predicting train subjects:  91%|█████████ | 485/532 [15:57<01:26,  1.84s/it]predicting train subjects:  91%|█████████▏| 486/532 [15:59<01:27,  1.91s/it]predicting train subjects:  92%|█████████▏| 487/532 [16:01<01:29,  1.98s/it]predicting train subjects:  92%|█████████▏| 488/532 [16:03<01:29,  2.04s/it]predicting train subjects:  92%|█████████▏| 489/532 [16:05<01:29,  2.08s/it]predicting train subjects:  92%|█████████▏| 490/532 [16:07<01:29,  2.13s/it]predicting train subjects:  92%|█████████▏| 491/532 [16:09<01:23,  2.04s/it]predicting train subjects:  92%|█████████▏| 492/532 [16:11<01:18,  1.97s/it]predicting train subjects:  93%|█████████▎| 493/532 [16:13<01:14,  1.90s/it]predicting train subjects:  93%|█████████▎| 494/532 [16:15<01:11,  1.89s/it]predicting train subjects:  93%|█████████▎| 495/532 [16:16<01:08,  1.86s/it]predicting train subjects:  93%|█████████▎| 496/532 [16:18<01:08,  1.91s/it]predicting train subjects:  93%|█████████▎| 497/532 [16:20<01:07,  1.93s/it]predicting train subjects:  94%|█████████▎| 498/532 [16:22<01:05,  1.92s/it]predicting train subjects:  94%|█████████▍| 499/532 [16:24<01:03,  1.92s/it]predicting train subjects:  94%|█████████▍| 500/532 [16:26<01:02,  1.95s/it]predicting train subjects:  94%|█████████▍| 501/532 [16:28<01:00,  1.94s/it]predicting train subjects:  94%|█████████▍| 502/532 [16:30<00:57,  1.92s/it]predicting train subjects:  95%|█████████▍| 503/532 [16:32<00:53,  1.86s/it]predicting train subjects:  95%|█████████▍| 504/532 [16:33<00:50,  1.80s/it]predicting train subjects:  95%|█████████▍| 505/532 [16:35<00:47,  1.75s/it]predicting train subjects:  95%|█████████▌| 506/532 [16:37<00:46,  1.77s/it]predicting train subjects:  95%|█████████▌| 507/532 [16:39<00:43,  1.75s/it]predicting train subjects:  95%|█████████▌| 508/532 [16:40<00:40,  1.71s/it]predicting train subjects:  96%|█████████▌| 509/532 [16:42<00:41,  1.81s/it]predicting train subjects:  96%|█████████▌| 510/532 [16:44<00:41,  1.90s/it]predicting train subjects:  96%|█████████▌| 511/532 [16:46<00:41,  1.98s/it]predicting train subjects:  96%|█████████▌| 512/532 [16:49<00:40,  2.05s/it]predicting train subjects:  96%|█████████▋| 513/532 [16:51<00:39,  2.08s/it]predicting train subjects:  97%|█████████▋| 514/532 [16:53<00:37,  2.09s/it]predicting train subjects:  97%|█████████▋| 515/532 [16:55<00:33,  2.00s/it]predicting train subjects:  97%|█████████▋| 516/532 [16:56<00:30,  1.92s/it]predicting train subjects:  97%|█████████▋| 517/532 [16:58<00:28,  1.88s/it]predicting train subjects:  97%|█████████▋| 518/532 [17:00<00:26,  1.87s/it]predicting train subjects:  98%|█████████▊| 519/532 [17:02<00:23,  1.84s/it]predicting train subjects:  98%|█████████▊| 520/532 [17:04<00:22,  1.84s/it]predicting train subjects:  98%|█████████▊| 521/532 [17:06<00:20,  1.89s/it]predicting train subjects:  98%|█████████▊| 522/532 [17:08<00:19,  1.92s/it]predicting train subjects:  98%|█████████▊| 523/532 [17:10<00:17,  1.92s/it]predicting train subjects:  98%|█████████▊| 524/532 [17:12<00:15,  1.93s/it]predicting train subjects:  99%|█████████▊| 525/532 [17:14<00:13,  1.96s/it]predicting train subjects:  99%|█████████▉| 526/532 [17:15<00:11,  1.93s/it]predicting train subjects:  99%|█████████▉| 527/532 [17:17<00:09,  1.87s/it]predicting train subjects:  99%|█████████▉| 528/532 [17:19<00:07,  1.81s/it]predicting train subjects:  99%|█████████▉| 529/532 [17:21<00:05,  1.77s/it]predicting train subjects: 100%|█████████▉| 530/532 [17:22<00:03,  1.74s/it]predicting train subjects: 100%|█████████▉| 531/532 [17:24<00:01,  1.75s/it]predicting train subjects: 100%|██████████| 532/532 [17:26<00:00,  1.76s/it]
Loading train:   0%|          | 0/532 [00:00<?, ?it/s]Loading train:   0%|          | 1/532 [00:01<12:53,  1.46s/it]Loading train:   0%|          | 2/532 [00:02<11:49,  1.34s/it]Loading train:   1%|          | 3/532 [00:03<11:14,  1.28s/it]Loading train:   1%|          | 4/532 [00:04<11:21,  1.29s/it]Loading train:   1%|          | 5/532 [00:06<11:07,  1.27s/it]Loading train:   1%|          | 6/532 [00:07<10:26,  1.19s/it]Loading train:   1%|▏         | 7/532 [00:08<09:45,  1.12s/it]Loading train:   2%|▏         | 8/532 [00:09<10:28,  1.20s/it]Loading train:   2%|▏         | 9/532 [00:10<10:55,  1.25s/it]Loading train:   2%|▏         | 10/532 [00:12<10:43,  1.23s/it]Loading train:   2%|▏         | 11/532 [00:13<10:01,  1.15s/it]Loading train:   2%|▏         | 12/532 [00:14<10:26,  1.21s/it]Loading train:   2%|▏         | 13/532 [00:15<09:47,  1.13s/it]Loading train:   3%|▎         | 14/532 [00:16<09:30,  1.10s/it]Loading train:   3%|▎         | 15/532 [00:17<09:39,  1.12s/it]Loading train:   3%|▎         | 16/532 [00:18<10:03,  1.17s/it]Loading train:   3%|▎         | 17/532 [00:19<09:28,  1.10s/it]Loading train:   3%|▎         | 18/532 [00:21<09:48,  1.15s/it]Loading train:   4%|▎         | 19/532 [00:22<09:28,  1.11s/it]Loading train:   4%|▍         | 20/532 [00:23<09:39,  1.13s/it]Loading train:   4%|▍         | 21/532 [00:24<10:31,  1.24s/it]Loading train:   4%|▍         | 22/532 [00:25<10:26,  1.23s/it]Loading train:   4%|▍         | 23/532 [00:27<10:40,  1.26s/it]Loading train:   5%|▍         | 24/532 [00:28<10:31,  1.24s/it]Loading train:   5%|▍         | 25/532 [00:29<11:04,  1.31s/it]Loading train:   5%|▍         | 26/532 [00:31<10:43,  1.27s/it]Loading train:   5%|▌         | 27/532 [00:32<11:21,  1.35s/it]Loading train:   5%|▌         | 28/532 [00:33<10:41,  1.27s/it]Loading train:   5%|▌         | 29/532 [00:34<10:34,  1.26s/it]Loading train:   6%|▌         | 30/532 [00:35<09:55,  1.19s/it]Loading train:   6%|▌         | 31/532 [00:37<09:37,  1.15s/it]Loading train:   6%|▌         | 32/532 [00:38<09:28,  1.14s/it]Loading train:   6%|▌         | 33/532 [00:39<09:04,  1.09s/it]Loading train:   6%|▋         | 34/532 [00:41<11:09,  1.35s/it]Loading train:   7%|▋         | 35/532 [00:42<11:26,  1.38s/it]Loading train:   7%|▋         | 36/532 [00:44<11:45,  1.42s/it]Loading train:   7%|▋         | 37/532 [00:45<12:14,  1.48s/it]Loading train:   7%|▋         | 38/532 [00:47<13:05,  1.59s/it]Loading train:   7%|▋         | 39/532 [00:48<12:46,  1.55s/it]Loading train:   8%|▊         | 40/532 [00:50<12:57,  1.58s/it]Loading train:   8%|▊         | 41/532 [00:52<14:01,  1.71s/it]Loading train:   8%|▊         | 42/532 [00:54<14:45,  1.81s/it]Loading train:   8%|▊         | 43/532 [00:56<14:42,  1.80s/it]Loading train:   8%|▊         | 44/532 [00:57<13:32,  1.67s/it]Loading train:   8%|▊         | 45/532 [00:59<12:55,  1.59s/it]Loading train:   9%|▊         | 46/532 [01:01<13:49,  1.71s/it]Loading train:   9%|▉         | 47/532 [01:03<14:27,  1.79s/it]Loading train:   9%|▉         | 48/532 [01:05<15:26,  1.91s/it]Loading train:   9%|▉         | 49/532 [01:07<15:09,  1.88s/it]Loading train:   9%|▉         | 50/532 [01:09<16:04,  2.00s/it]Loading train:  10%|▉         | 51/532 [01:11<15:44,  1.96s/it]Loading train:  10%|▉         | 52/532 [01:13<15:41,  1.96s/it]Loading train:  10%|▉         | 53/532 [01:15<15:01,  1.88s/it]Loading train:  10%|█         | 54/532 [01:16<15:11,  1.91s/it]Loading train:  10%|█         | 55/532 [01:19<16:13,  2.04s/it]Loading train:  11%|█         | 56/532 [01:21<15:17,  1.93s/it]Loading train:  11%|█         | 57/532 [01:22<15:01,  1.90s/it]Loading train:  11%|█         | 58/532 [01:25<15:39,  1.98s/it]Loading train:  11%|█         | 59/532 [01:27<16:29,  2.09s/it]Loading train:  11%|█▏        | 60/532 [01:29<15:51,  2.02s/it]Loading train:  11%|█▏        | 61/532 [01:30<14:31,  1.85s/it]Loading train:  12%|█▏        | 62/532 [01:32<14:29,  1.85s/it]Loading train:  12%|█▏        | 63/532 [01:34<15:06,  1.93s/it]Loading train:  12%|█▏        | 64/532 [01:36<15:31,  1.99s/it]Loading train:  12%|█▏        | 65/532 [01:38<14:53,  1.91s/it]Loading train:  12%|█▏        | 66/532 [01:40<14:38,  1.88s/it]Loading train:  13%|█▎        | 67/532 [01:42<15:26,  1.99s/it]Loading train:  13%|█▎        | 68/532 [01:44<14:08,  1.83s/it]Loading train:  13%|█▎        | 69/532 [01:45<14:01,  1.82s/it]Loading train:  13%|█▎        | 70/532 [01:47<14:37,  1.90s/it]Loading train:  13%|█▎        | 71/532 [01:50<15:15,  1.99s/it]Loading train:  14%|█▎        | 72/532 [01:51<14:47,  1.93s/it]Loading train:  14%|█▎        | 73/532 [01:54<15:25,  2.02s/it]Loading train:  14%|█▍        | 74/532 [01:56<15:27,  2.02s/it]Loading train:  14%|█▍        | 75/532 [01:58<16:47,  2.20s/it]Loading train:  14%|█▍        | 76/532 [02:00<15:22,  2.02s/it]Loading train:  14%|█▍        | 77/532 [02:02<15:13,  2.01s/it]Loading train:  15%|█▍        | 78/532 [02:04<15:46,  2.08s/it]Loading train:  15%|█▍        | 79/532 [02:06<15:23,  2.04s/it]Loading train:  15%|█▌        | 80/532 [02:08<14:19,  1.90s/it]Loading train:  15%|█▌        | 81/532 [02:09<13:16,  1.77s/it]Loading train:  15%|█▌        | 82/532 [02:11<13:24,  1.79s/it]Loading train:  16%|█▌        | 83/532 [02:13<14:08,  1.89s/it]Loading train:  16%|█▌        | 84/532 [02:15<13:33,  1.81s/it]Loading train:  16%|█▌        | 85/532 [02:16<13:31,  1.81s/it]Loading train:  16%|█▌        | 86/532 [02:18<13:36,  1.83s/it]Loading train:  16%|█▋        | 87/532 [02:20<13:48,  1.86s/it]Loading train:  17%|█▋        | 88/532 [02:22<13:36,  1.84s/it]Loading train:  17%|█▋        | 89/532 [02:24<13:59,  1.89s/it]Loading train:  17%|█▋        | 90/532 [02:26<13:54,  1.89s/it]Loading train:  17%|█▋        | 91/532 [02:27<12:44,  1.73s/it]Loading train:  17%|█▋        | 92/532 [02:29<12:23,  1.69s/it]Loading train:  17%|█▋        | 93/532 [02:31<13:34,  1.86s/it]Loading train:  18%|█▊        | 94/532 [02:32<12:13,  1.67s/it]Loading train:  18%|█▊        | 95/532 [02:34<12:28,  1.71s/it]Loading train:  18%|█▊        | 96/532 [02:36<13:12,  1.82s/it]Loading train:  18%|█▊        | 97/532 [02:38<13:27,  1.86s/it]Loading train:  18%|█▊        | 98/532 [02:40<13:17,  1.84s/it]Loading train:  19%|█▊        | 99/532 [02:42<13:43,  1.90s/it]Loading train:  19%|█▉        | 100/532 [02:44<13:32,  1.88s/it]Loading train:  19%|█▉        | 101/532 [02:46<13:44,  1.91s/it]Loading train:  19%|█▉        | 102/532 [02:47<13:00,  1.81s/it]Loading train:  19%|█▉        | 103/532 [02:49<12:08,  1.70s/it]Loading train:  20%|█▉        | 104/532 [02:51<11:54,  1.67s/it]Loading train:  20%|█▉        | 105/532 [02:52<12:15,  1.72s/it]Loading train:  20%|█▉        | 106/532 [02:54<11:11,  1.58s/it]Loading train:  20%|██        | 107/532 [02:55<11:09,  1.58s/it]Loading train:  20%|██        | 108/532 [02:57<10:58,  1.55s/it]Loading train:  20%|██        | 109/532 [02:58<10:22,  1.47s/it]Loading train:  21%|██        | 110/532 [02:59<10:08,  1.44s/it]Loading train:  21%|██        | 111/532 [03:01<10:52,  1.55s/it]Loading train:  21%|██        | 112/532 [03:02<10:24,  1.49s/it]Loading train:  21%|██        | 113/532 [03:05<11:54,  1.70s/it]Loading train:  21%|██▏       | 114/532 [03:07<12:29,  1.79s/it]Loading train:  22%|██▏       | 115/532 [03:09<12:56,  1.86s/it]Loading train:  22%|██▏       | 116/532 [03:11<12:59,  1.87s/it]Loading train:  22%|██▏       | 117/532 [03:13<13:45,  1.99s/it]Loading train:  22%|██▏       | 118/532 [03:15<13:31,  1.96s/it]Loading train:  22%|██▏       | 119/532 [03:17<13:31,  1.97s/it]Loading train:  23%|██▎       | 120/532 [03:18<12:51,  1.87s/it]Loading train:  23%|██▎       | 121/532 [03:20<12:13,  1.78s/it]Loading train:  23%|██▎       | 122/532 [03:22<12:04,  1.77s/it]Loading train:  23%|██▎       | 123/532 [03:23<11:20,  1.66s/it]Loading train:  23%|██▎       | 124/532 [03:25<10:51,  1.60s/it]Loading train:  23%|██▎       | 125/532 [03:26<11:11,  1.65s/it]Loading train:  24%|██▎       | 126/532 [03:28<11:36,  1.71s/it]Loading train:  24%|██▍       | 127/532 [03:30<11:13,  1.66s/it]Loading train:  24%|██▍       | 128/532 [03:31<10:41,  1.59s/it]Loading train:  24%|██▍       | 129/532 [03:33<10:36,  1.58s/it]Loading train:  24%|██▍       | 130/532 [03:35<11:22,  1.70s/it]Loading train:  25%|██▍       | 131/532 [03:37<12:00,  1.80s/it]Loading train:  25%|██▍       | 132/532 [03:39<12:33,  1.88s/it]Loading train:  25%|██▌       | 133/532 [03:41<12:19,  1.85s/it]Loading train:  25%|██▌       | 134/532 [03:43<13:13,  1.99s/it]Loading train:  25%|██▌       | 135/532 [03:45<12:35,  1.90s/it]Loading train:  26%|██▌       | 136/532 [03:47<12:45,  1.93s/it]Loading train:  26%|██▌       | 137/532 [03:49<13:25,  2.04s/it]Loading train:  26%|██▌       | 138/532 [03:51<13:49,  2.11s/it]Loading train:  26%|██▌       | 139/532 [03:53<13:27,  2.05s/it]Loading train:  26%|██▋       | 140/532 [03:55<13:18,  2.04s/it]Loading train:  27%|██▋       | 141/532 [03:57<13:23,  2.06s/it]Loading train:  27%|██▋       | 142/532 [03:59<13:17,  2.04s/it]Loading train:  27%|██▋       | 143/532 [04:01<13:26,  2.07s/it]Loading train:  27%|██▋       | 144/532 [04:03<12:13,  1.89s/it]Loading train:  27%|██▋       | 145/532 [04:04<11:16,  1.75s/it]Loading train:  27%|██▋       | 146/532 [04:06<11:10,  1.74s/it]Loading train:  28%|██▊       | 147/532 [04:08<11:21,  1.77s/it]Loading train:  28%|██▊       | 148/532 [04:10<11:19,  1.77s/it]Loading train:  28%|██▊       | 149/532 [04:11<10:48,  1.69s/it]Loading train:  28%|██▊       | 150/532 [04:12<10:07,  1.59s/it]Loading train:  28%|██▊       | 151/532 [04:14<10:06,  1.59s/it]Loading train:  29%|██▊       | 152/532 [04:16<09:57,  1.57s/it]Loading train:  29%|██▉       | 153/532 [04:17<09:54,  1.57s/it]Loading train:  29%|██▉       | 154/532 [04:19<10:39,  1.69s/it]Loading train:  29%|██▉       | 155/532 [04:21<11:29,  1.83s/it]Loading train:  29%|██▉       | 156/532 [04:23<12:00,  1.92s/it]Loading train:  30%|██▉       | 157/532 [04:26<12:34,  2.01s/it]Loading train:  30%|██▉       | 158/532 [04:28<13:08,  2.11s/it]Loading train:  30%|██▉       | 159/532 [04:30<12:50,  2.06s/it]Loading train:  30%|███       | 160/532 [04:32<12:27,  2.01s/it]Loading train:  30%|███       | 161/532 [04:34<12:54,  2.09s/it]Loading train:  30%|███       | 162/532 [04:36<12:05,  1.96s/it]Loading train:  31%|███       | 163/532 [04:37<11:31,  1.87s/it]Loading train:  31%|███       | 164/532 [04:39<10:46,  1.76s/it]Loading train:  31%|███       | 165/532 [04:41<11:26,  1.87s/it]Loading train:  31%|███       | 166/532 [04:42<10:31,  1.72s/it]Loading train:  31%|███▏      | 167/532 [04:44<10:57,  1.80s/it]Loading train:  32%|███▏      | 168/532 [04:46<10:13,  1.69s/it]Loading train:  32%|███▏      | 169/532 [04:48<10:53,  1.80s/it]Loading train:  32%|███▏      | 170/532 [04:49<10:04,  1.67s/it]Loading train:  32%|███▏      | 171/532 [04:51<10:12,  1.70s/it]Loading train:  32%|███▏      | 172/532 [04:53<10:13,  1.70s/it]Loading train:  33%|███▎      | 173/532 [04:54<09:49,  1.64s/it]Loading train:  33%|███▎      | 174/532 [04:56<10:18,  1.73s/it]Loading train:  33%|███▎      | 175/532 [04:58<10:44,  1.81s/it]Loading train:  33%|███▎      | 176/532 [04:59<09:50,  1.66s/it]Loading train:  33%|███▎      | 177/532 [05:01<09:48,  1.66s/it]Loading train:  33%|███▎      | 178/532 [05:03<10:02,  1.70s/it]Loading train:  34%|███▎      | 179/532 [05:04<09:49,  1.67s/it]Loading train:  34%|███▍      | 180/532 [05:06<10:09,  1.73s/it]Loading train:  34%|███▍      | 181/532 [05:08<09:48,  1.68s/it]Loading train:  34%|███▍      | 182/532 [05:09<09:06,  1.56s/it]Loading train:  34%|███▍      | 183/532 [05:11<08:49,  1.52s/it]Loading train:  35%|███▍      | 184/532 [05:12<08:42,  1.50s/it]Loading train:  35%|███▍      | 185/532 [05:14<09:00,  1.56s/it]Loading train:  35%|███▍      | 186/532 [05:16<09:29,  1.65s/it]Loading train:  35%|███▌      | 187/532 [05:17<09:37,  1.67s/it]Loading train:  35%|███▌      | 188/532 [05:19<10:25,  1.82s/it]Loading train:  36%|███▌      | 189/532 [05:21<10:26,  1.83s/it]Loading train:  36%|███▌      | 190/532 [05:23<10:00,  1.76s/it]Loading train:  36%|███▌      | 191/532 [05:25<10:43,  1.89s/it]Loading train:  36%|███▌      | 192/532 [05:27<10:58,  1.94s/it]Loading train:  36%|███▋      | 193/532 [05:29<11:15,  1.99s/it]Loading train:  36%|███▋      | 194/532 [05:31<10:46,  1.91s/it]Loading train:  37%|███▋      | 195/532 [05:33<10:25,  1.86s/it]Loading train:  37%|███▋      | 196/532 [05:35<11:07,  1.99s/it]Loading train:  37%|███▋      | 197/532 [05:37<11:03,  1.98s/it]Loading train:  37%|███▋      | 198/532 [05:39<10:17,  1.85s/it]Loading train:  37%|███▋      | 199/532 [05:40<10:03,  1.81s/it]Loading train:  38%|███▊      | 200/532 [05:42<10:15,  1.85s/it]Loading train:  38%|███▊      | 201/532 [05:44<09:40,  1.75s/it]Loading train:  38%|███▊      | 202/532 [05:46<09:40,  1.76s/it]Loading train:  38%|███▊      | 203/532 [05:47<09:58,  1.82s/it]Loading train:  38%|███▊      | 204/532 [05:49<09:37,  1.76s/it]Loading train:  39%|███▊      | 205/532 [05:50<08:48,  1.62s/it]Loading train:  39%|███▊      | 206/532 [05:52<08:57,  1.65s/it]Loading train:  39%|███▉      | 207/532 [05:54<08:42,  1.61s/it]Loading train:  39%|███▉      | 208/532 [05:55<08:36,  1.59s/it]Loading train:  39%|███▉      | 209/532 [05:57<09:19,  1.73s/it]Loading train:  39%|███▉      | 210/532 [05:59<08:40,  1.62s/it]Loading train:  40%|███▉      | 211/532 [06:00<08:26,  1.58s/it]Loading train:  40%|███▉      | 212/532 [06:02<08:27,  1.59s/it]Loading train:  40%|████      | 213/532 [06:04<09:10,  1.72s/it]Loading train:  40%|████      | 214/532 [06:05<09:14,  1.74s/it]Loading train:  40%|████      | 215/532 [06:08<10:09,  1.92s/it]Loading train:  41%|████      | 216/532 [06:10<10:01,  1.90s/it]Loading train:  41%|████      | 217/532 [06:12<09:50,  1.88s/it]Loading train:  41%|████      | 218/532 [06:14<10:08,  1.94s/it]Loading train:  41%|████      | 219/532 [06:15<09:46,  1.87s/it]Loading train:  41%|████▏     | 220/532 [06:17<09:37,  1.85s/it]Loading train:  42%|████▏     | 221/532 [06:19<08:52,  1.71s/it]Loading train:  42%|████▏     | 222/532 [06:20<09:06,  1.76s/it]Loading train:  42%|████▏     | 223/532 [06:22<09:32,  1.85s/it]Loading train:  42%|████▏     | 224/532 [06:24<09:24,  1.83s/it]Loading train:  42%|████▏     | 225/532 [06:26<08:32,  1.67s/it]Loading train:  42%|████▏     | 226/532 [06:27<08:06,  1.59s/it]Loading train:  43%|████▎     | 227/532 [06:29<08:07,  1.60s/it]Loading train:  43%|████▎     | 228/532 [06:30<07:39,  1.51s/it]Loading train:  43%|████▎     | 229/532 [06:31<07:07,  1.41s/it]Loading train:  43%|████▎     | 230/532 [06:32<06:47,  1.35s/it]Loading train:  43%|████▎     | 231/532 [06:33<06:22,  1.27s/it]Loading train:  44%|████▎     | 232/532 [06:35<06:27,  1.29s/it]Loading train:  44%|████▍     | 233/532 [06:36<06:53,  1.38s/it]Loading train:  44%|████▍     | 234/532 [06:38<06:51,  1.38s/it]Loading train:  44%|████▍     | 235/532 [06:39<07:10,  1.45s/it]Loading train:  44%|████▍     | 236/532 [06:41<07:31,  1.53s/it]Loading train:  45%|████▍     | 237/532 [06:43<07:54,  1.61s/it]Loading train:  45%|████▍     | 238/532 [06:44<07:49,  1.60s/it]Loading train:  45%|████▍     | 239/532 [06:46<08:37,  1.77s/it]Loading train:  45%|████▌     | 240/532 [06:48<08:31,  1.75s/it]Loading train:  45%|████▌     | 241/532 [06:50<08:58,  1.85s/it]Loading train:  45%|████▌     | 242/532 [06:52<09:10,  1.90s/it]Loading train:  46%|████▌     | 243/532 [06:54<08:21,  1.73s/it]Loading train:  46%|████▌     | 244/532 [06:56<08:49,  1.84s/it]Loading train:  46%|████▌     | 245/532 [06:57<08:19,  1.74s/it]Loading train:  46%|████▌     | 246/532 [06:59<08:12,  1.72s/it]Loading train:  46%|████▋     | 247/532 [07:00<07:24,  1.56s/it]Loading train:  47%|████▋     | 248/532 [07:01<06:51,  1.45s/it]Loading train:  47%|████▋     | 249/532 [07:03<06:38,  1.41s/it]Loading train:  47%|████▋     | 250/532 [07:04<06:24,  1.37s/it]Loading train:  47%|████▋     | 251/532 [07:05<06:37,  1.42s/it]Loading train:  47%|████▋     | 252/532 [07:07<06:09,  1.32s/it]Loading train:  48%|████▊     | 253/532 [07:08<06:12,  1.34s/it]Loading train:  48%|████▊     | 254/532 [07:09<06:06,  1.32s/it]Loading train:  48%|████▊     | 255/532 [07:10<05:45,  1.25s/it]Loading train:  48%|████▊     | 256/532 [07:11<05:44,  1.25s/it]Loading train:  48%|████▊     | 257/532 [07:14<06:48,  1.49s/it]Loading train:  48%|████▊     | 258/532 [07:15<07:20,  1.61s/it]Loading train:  49%|████▊     | 259/532 [07:18<07:59,  1.75s/it]Loading train:  49%|████▉     | 260/532 [07:19<08:07,  1.79s/it]Loading train:  49%|████▉     | 261/532 [07:22<08:42,  1.93s/it]Loading train:  49%|████▉     | 262/532 [07:24<09:32,  2.12s/it]Loading train:  49%|████▉     | 263/532 [07:26<08:44,  1.95s/it]Loading train:  50%|████▉     | 264/532 [07:27<08:06,  1.81s/it]Loading train:  50%|████▉     | 265/532 [07:29<08:18,  1.87s/it]Loading train:  50%|█████     | 266/532 [07:31<07:48,  1.76s/it]Loading train:  50%|█████     | 267/532 [07:32<06:34,  1.49s/it]Loading train:  50%|█████     | 268/532 [07:33<05:52,  1.34s/it]Loading train:  51%|█████     | 269/532 [07:34<05:31,  1.26s/it]Loading train:  51%|█████     | 270/532 [07:35<05:14,  1.20s/it]Loading train:  51%|█████     | 271/532 [07:36<05:42,  1.31s/it]Loading train:  51%|█████     | 272/532 [07:38<06:20,  1.46s/it]Loading train:  51%|█████▏    | 273/532 [07:40<06:51,  1.59s/it]Loading train:  52%|█████▏    | 274/532 [07:41<06:02,  1.41s/it]Loading train:  52%|█████▏    | 275/532 [07:42<05:50,  1.36s/it]Loading train:  52%|█████▏    | 276/532 [07:43<05:36,  1.32s/it]Loading train:  52%|█████▏    | 277/532 [07:45<05:30,  1.30s/it]Loading train:  52%|█████▏    | 278/532 [07:46<05:24,  1.28s/it]Loading train:  52%|█████▏    | 279/532 [07:47<05:18,  1.26s/it]Loading train:  53%|█████▎    | 280/532 [07:48<05:12,  1.24s/it]Loading train:  53%|█████▎    | 281/532 [07:50<05:07,  1.22s/it]Loading train:  53%|█████▎    | 282/532 [07:51<04:55,  1.18s/it]Loading train:  53%|█████▎    | 283/532 [07:52<04:46,  1.15s/it]Loading train:  53%|█████▎    | 284/532 [07:53<04:43,  1.14s/it]Loading train:  54%|█████▎    | 285/532 [07:54<04:45,  1.15s/it]Loading train:  54%|█████▍    | 286/532 [07:55<04:42,  1.15s/it]Loading train:  54%|█████▍    | 287/532 [07:56<04:23,  1.08s/it]Loading train:  54%|█████▍    | 288/532 [07:57<04:13,  1.04s/it]Loading train:  54%|█████▍    | 289/532 [07:58<04:09,  1.03s/it]Loading train:  55%|█████▍    | 290/532 [07:59<04:05,  1.01s/it]Loading train:  55%|█████▍    | 291/532 [08:00<04:09,  1.03s/it]Loading train:  55%|█████▍    | 292/532 [08:01<04:08,  1.04s/it]Loading train:  55%|█████▌    | 293/532 [08:02<04:04,  1.02s/it]Loading train:  55%|█████▌    | 294/532 [08:03<04:00,  1.01s/it]Loading train:  55%|█████▌    | 295/532 [08:04<04:04,  1.03s/it]Loading train:  56%|█████▌    | 296/532 [08:05<04:04,  1.03s/it]Loading train:  56%|█████▌    | 297/532 [08:06<04:02,  1.03s/it]Loading train:  56%|█████▌    | 298/532 [08:07<04:03,  1.04s/it]Loading train:  56%|█████▌    | 299/532 [08:08<03:50,  1.01it/s]Loading train:  56%|█████▋    | 300/532 [08:09<03:39,  1.06it/s]Loading train:  57%|█████▋    | 301/532 [08:10<03:32,  1.09it/s]Loading train:  57%|█████▋    | 302/532 [08:11<03:30,  1.09it/s]Loading train:  57%|█████▋    | 303/532 [08:12<03:34,  1.07it/s]Loading train:  57%|█████▋    | 304/532 [08:13<03:31,  1.08it/s]Loading train:  57%|█████▋    | 305/532 [08:14<03:59,  1.05s/it]Loading train:  58%|█████▊    | 306/532 [08:15<04:11,  1.11s/it]Loading train:  58%|█████▊    | 307/532 [08:16<04:16,  1.14s/it]Loading train:  58%|█████▊    | 308/532 [08:18<04:22,  1.17s/it]Loading train:  58%|█████▊    | 309/532 [08:19<04:25,  1.19s/it]Loading train:  58%|█████▊    | 310/532 [08:20<04:29,  1.21s/it]Loading train:  58%|█████▊    | 311/532 [08:22<04:54,  1.33s/it]Loading train:  59%|█████▊    | 312/532 [08:23<05:12,  1.42s/it]Loading train:  59%|█████▉    | 313/532 [08:25<05:23,  1.48s/it]Loading train:  59%|█████▉    | 314/532 [08:27<05:26,  1.50s/it]Loading train:  59%|█████▉    | 315/532 [08:28<05:32,  1.53s/it]Loading train:  59%|█████▉    | 316/532 [08:30<05:28,  1.52s/it]Loading train:  60%|█████▉    | 317/532 [08:31<04:54,  1.37s/it]Loading train:  60%|█████▉    | 318/532 [08:32<04:28,  1.25s/it]Loading train:  60%|█████▉    | 319/532 [08:33<04:20,  1.22s/it]Loading train:  60%|██████    | 320/532 [08:34<04:07,  1.17s/it]Loading train:  60%|██████    | 321/532 [08:35<03:54,  1.11s/it]Loading train:  61%|██████    | 322/532 [08:36<03:42,  1.06s/it]Loading train:  61%|██████    | 323/532 [08:37<03:59,  1.15s/it]Loading train:  61%|██████    | 324/532 [08:38<04:08,  1.19s/it]Loading train:  61%|██████    | 325/532 [08:40<04:12,  1.22s/it]Loading train:  61%|██████▏   | 326/532 [08:41<04:18,  1.25s/it]Loading train:  61%|██████▏   | 327/532 [08:42<04:13,  1.23s/it]Loading train:  62%|██████▏   | 328/532 [08:44<04:11,  1.23s/it]Loading train:  62%|██████▏   | 329/532 [08:45<04:02,  1.20s/it]Loading train:  62%|██████▏   | 330/532 [08:46<03:52,  1.15s/it]Loading train:  62%|██████▏   | 331/532 [08:47<03:45,  1.12s/it]Loading train:  62%|██████▏   | 332/532 [08:48<03:36,  1.08s/it]Loading train:  63%|██████▎   | 333/532 [08:49<03:32,  1.07s/it]Loading train:  63%|██████▎   | 334/532 [08:50<03:28,  1.05s/it]Loading train:  63%|██████▎   | 335/532 [08:51<03:32,  1.08s/it]Loading train:  63%|██████▎   | 336/532 [08:52<03:32,  1.08s/it]Loading train:  63%|██████▎   | 337/532 [08:53<03:34,  1.10s/it]Loading train:  64%|██████▎   | 338/532 [08:54<03:34,  1.11s/it]Loading train:  64%|██████▎   | 339/532 [08:55<03:31,  1.10s/it]Loading train:  64%|██████▍   | 340/532 [08:56<03:23,  1.06s/it]Loading train:  64%|██████▍   | 341/532 [08:57<03:19,  1.04s/it]Loading train:  64%|██████▍   | 342/532 [08:58<03:07,  1.01it/s]Loading train:  64%|██████▍   | 343/532 [08:59<03:01,  1.04it/s]Loading train:  65%|██████▍   | 344/532 [09:00<02:58,  1.05it/s]Loading train:  65%|██████▍   | 345/532 [09:01<02:54,  1.07it/s]Loading train:  65%|██████▌   | 346/532 [09:02<02:53,  1.07it/s]Loading train:  65%|██████▌   | 347/532 [09:03<02:59,  1.03it/s]Loading train:  65%|██████▌   | 348/532 [09:04<03:00,  1.02it/s]Loading train:  66%|██████▌   | 349/532 [09:05<03:04,  1.01s/it]Loading train:  66%|██████▌   | 350/532 [09:06<03:03,  1.01s/it]Loading train:  66%|██████▌   | 351/532 [09:07<02:56,  1.03it/s]Loading train:  66%|██████▌   | 352/532 [09:08<02:53,  1.04it/s]Loading train:  66%|██████▋   | 353/532 [09:09<02:55,  1.02it/s]Loading train:  67%|██████▋   | 354/532 [09:10<02:55,  1.01it/s]Loading train:  67%|██████▋   | 355/532 [09:11<02:52,  1.03it/s]Loading train:  67%|██████▋   | 356/532 [09:12<02:52,  1.02it/s]Loading train:  67%|██████▋   | 357/532 [09:13<02:49,  1.03it/s]Loading train:  67%|██████▋   | 358/532 [09:14<02:45,  1.05it/s]Loading train:  67%|██████▋   | 359/532 [09:14<02:39,  1.09it/s]Loading train:  68%|██████▊   | 360/532 [09:15<02:37,  1.09it/s]Loading train:  68%|██████▊   | 361/532 [09:16<02:39,  1.07it/s]Loading train:  68%|██████▊   | 362/532 [09:17<02:36,  1.09it/s]Loading train:  68%|██████▊   | 363/532 [09:18<02:30,  1.12it/s]Loading train:  68%|██████▊   | 364/532 [09:19<02:31,  1.11it/s]Loading train:  69%|██████▊   | 365/532 [09:20<02:31,  1.10it/s]Loading train:  69%|██████▉   | 366/532 [09:21<02:35,  1.07it/s]Loading train:  69%|██████▉   | 367/532 [09:22<02:35,  1.06it/s]Loading train:  69%|██████▉   | 368/532 [09:23<02:34,  1.06it/s]Loading train:  69%|██████▉   | 369/532 [09:24<02:33,  1.06it/s]Loading train:  70%|██████▉   | 370/532 [09:25<02:31,  1.07it/s]Loading train:  70%|██████▉   | 371/532 [09:26<02:48,  1.05s/it]Loading train:  70%|██████▉   | 372/532 [09:27<02:59,  1.12s/it]Loading train:  70%|███████   | 373/532 [09:28<03:03,  1.16s/it]Loading train:  70%|███████   | 374/532 [09:30<03:08,  1.19s/it]Loading train:  70%|███████   | 375/532 [09:31<03:11,  1.22s/it]Loading train:  71%|███████   | 376/532 [09:32<03:11,  1.22s/it]Loading train:  71%|███████   | 377/532 [09:33<02:58,  1.15s/it]Loading train:  71%|███████   | 378/532 [09:34<02:51,  1.12s/it]Loading train:  71%|███████   | 379/532 [09:35<02:43,  1.07s/it]Loading train:  71%|███████▏  | 380/532 [09:36<02:39,  1.05s/it]Loading train:  72%|███████▏  | 381/532 [09:37<02:36,  1.04s/it]Loading train:  72%|███████▏  | 382/532 [09:38<02:31,  1.01s/it]Loading train:  72%|███████▏  | 383/532 [09:39<02:32,  1.02s/it]Loading train:  72%|███████▏  | 384/532 [09:40<02:31,  1.02s/it]Loading train:  72%|███████▏  | 385/532 [09:41<02:32,  1.04s/it]Loading train:  73%|███████▎  | 386/532 [09:42<02:27,  1.01s/it]Loading train:  73%|███████▎  | 387/532 [09:43<02:28,  1.02s/it]Loading train:  73%|███████▎  | 388/532 [09:44<02:28,  1.03s/it]Loading train:  73%|███████▎  | 389/532 [09:45<02:29,  1.04s/it]Loading train:  73%|███████▎  | 390/532 [09:47<02:29,  1.06s/it]Loading train:  73%|███████▎  | 391/532 [09:48<02:31,  1.07s/it]Loading train:  74%|███████▎  | 392/532 [09:49<02:30,  1.07s/it]Loading train:  74%|███████▍  | 393/532 [09:50<02:29,  1.07s/it]Loading train:  74%|███████▍  | 394/532 [09:51<02:30,  1.09s/it]Loading train:  74%|███████▍  | 395/532 [09:52<02:28,  1.08s/it]Loading train:  74%|███████▍  | 396/532 [09:53<02:26,  1.08s/it]Loading train:  75%|███████▍  | 397/532 [09:54<02:26,  1.08s/it]Loading train:  75%|███████▍  | 398/532 [09:55<02:24,  1.08s/it]Loading train:  75%|███████▌  | 399/532 [09:56<02:23,  1.08s/it]Loading train:  75%|███████▌  | 400/532 [09:57<02:22,  1.08s/it]Loading train:  75%|███████▌  | 401/532 [09:59<02:23,  1.09s/it]Loading train:  76%|███████▌  | 402/532 [10:00<02:20,  1.08s/it]Loading train:  76%|███████▌  | 403/532 [10:01<02:18,  1.07s/it]Loading train:  76%|███████▌  | 404/532 [10:02<02:18,  1.08s/it]Loading train:  76%|███████▌  | 405/532 [10:03<02:20,  1.11s/it]Loading train:  76%|███████▋  | 406/532 [10:04<02:21,  1.12s/it]Loading train:  77%|███████▋  | 407/532 [10:05<02:18,  1.11s/it]Loading train:  77%|███████▋  | 408/532 [10:06<02:16,  1.10s/it]Loading train:  77%|███████▋  | 409/532 [10:07<02:12,  1.08s/it]Loading train:  77%|███████▋  | 410/532 [10:08<02:09,  1.06s/it]Loading train:  77%|███████▋  | 411/532 [10:09<02:08,  1.06s/it]Loading train:  77%|███████▋  | 412/532 [10:10<02:05,  1.05s/it]Loading train:  78%|███████▊  | 413/532 [10:11<02:04,  1.05s/it]Loading train:  78%|███████▊  | 414/532 [10:12<01:58,  1.01s/it]Loading train:  78%|███████▊  | 415/532 [10:13<01:53,  1.03it/s]Loading train:  78%|███████▊  | 416/532 [10:14<01:51,  1.04it/s]Loading train:  78%|███████▊  | 417/532 [10:15<01:50,  1.04it/s]Loading train:  79%|███████▊  | 418/532 [10:16<01:49,  1.04it/s]Loading train:  79%|███████▉  | 419/532 [10:17<01:57,  1.04s/it]Loading train:  79%|███████▉  | 420/532 [10:18<01:59,  1.07s/it]Loading train:  79%|███████▉  | 421/532 [10:20<02:00,  1.08s/it]Loading train:  79%|███████▉  | 422/532 [10:21<02:03,  1.13s/it]Loading train:  80%|███████▉  | 423/532 [10:22<02:02,  1.13s/it]Loading train:  80%|███████▉  | 424/532 [10:23<02:01,  1.13s/it]Loading train:  80%|███████▉  | 425/532 [10:24<02:00,  1.12s/it]Loading train:  80%|████████  | 426/532 [10:25<01:58,  1.12s/it]Loading train:  80%|████████  | 427/532 [10:26<01:58,  1.13s/it]Loading train:  80%|████████  | 428/532 [10:27<01:56,  1.12s/it]Loading train:  81%|████████  | 429/532 [10:29<01:55,  1.12s/it]Loading train:  81%|████████  | 430/532 [10:30<01:54,  1.12s/it]Loading train:  81%|████████  | 431/532 [10:31<01:54,  1.13s/it]Loading train:  81%|████████  | 432/532 [10:32<01:51,  1.12s/it]Loading train:  81%|████████▏ | 433/532 [10:33<01:51,  1.13s/it]Loading train:  82%|████████▏ | 434/532 [10:34<01:49,  1.12s/it]Loading train:  82%|████████▏ | 435/532 [10:35<01:47,  1.11s/it]Loading train:  82%|████████▏ | 436/532 [10:36<01:48,  1.13s/it]Loading train:  82%|████████▏ | 437/532 [10:37<01:43,  1.09s/it]Loading train:  82%|████████▏ | 438/532 [10:38<01:36,  1.03s/it]Loading train:  83%|████████▎ | 439/532 [10:39<01:30,  1.02it/s]Loading train:  83%|████████▎ | 440/532 [10:40<01:26,  1.07it/s]Loading train:  83%|████████▎ | 441/532 [10:41<01:23,  1.09it/s]Loading train:  83%|████████▎ | 442/532 [10:42<01:21,  1.10it/s]Loading train:  83%|████████▎ | 443/532 [10:43<01:23,  1.06it/s]Loading train:  83%|████████▎ | 444/532 [10:44<01:20,  1.09it/s]Loading train:  84%|████████▎ | 445/532 [10:45<01:21,  1.07it/s]Loading train:  84%|████████▍ | 446/532 [10:46<01:19,  1.08it/s]Loading train:  84%|████████▍ | 447/532 [10:47<01:20,  1.06it/s]Loading train:  84%|████████▍ | 448/532 [10:48<01:19,  1.06it/s]Loading train:  84%|████████▍ | 449/532 [10:49<01:19,  1.04it/s]Loading train:  85%|████████▍ | 450/532 [10:50<01:19,  1.03it/s]Loading train:  85%|████████▍ | 451/532 [10:50<01:17,  1.04it/s]Loading train:  85%|████████▍ | 452/532 [10:51<01:16,  1.04it/s]Loading train:  85%|████████▌ | 453/532 [10:52<01:13,  1.07it/s]Loading train:  85%|████████▌ | 454/532 [10:53<01:15,  1.04it/s]Loading train:  86%|████████▌ | 455/532 [10:54<01:16,  1.01it/s]Loading train:  86%|████████▌ | 456/532 [10:55<01:18,  1.03s/it]Loading train:  86%|████████▌ | 457/532 [10:57<01:17,  1.04s/it]Loading train:  86%|████████▌ | 458/532 [10:58<01:17,  1.04s/it]Loading train:  86%|████████▋ | 459/532 [10:59<01:15,  1.03s/it]Loading train:  86%|████████▋ | 460/532 [11:00<01:15,  1.04s/it]Loading train:  87%|████████▋ | 461/532 [11:01<01:17,  1.10s/it]Loading train:  87%|████████▋ | 462/532 [11:02<01:19,  1.13s/it]Loading train:  87%|████████▋ | 463/532 [11:03<01:19,  1.16s/it]Loading train:  87%|████████▋ | 464/532 [11:05<01:20,  1.18s/it]Loading train:  87%|████████▋ | 465/532 [11:06<01:20,  1.20s/it]Loading train:  88%|████████▊ | 466/532 [11:07<01:20,  1.22s/it]Loading train:  88%|████████▊ | 467/532 [11:08<01:14,  1.15s/it]Loading train:  88%|████████▊ | 468/532 [11:09<01:12,  1.13s/it]Loading train:  88%|████████▊ | 469/532 [11:10<01:09,  1.10s/it]Loading train:  88%|████████▊ | 470/532 [11:11<01:06,  1.07s/it]Loading train:  89%|████████▊ | 471/532 [11:12<01:02,  1.03s/it]Loading train:  89%|████████▊ | 472/532 [11:13<01:00,  1.01s/it]Loading train:  89%|████████▉ | 473/532 [11:14<01:01,  1.04s/it]Loading train:  89%|████████▉ | 474/532 [11:15<01:00,  1.04s/it]Loading train:  89%|████████▉ | 475/532 [11:16<01:00,  1.06s/it]Loading train:  89%|████████▉ | 476/532 [11:17<00:59,  1.06s/it]Loading train:  90%|████████▉ | 477/532 [11:18<00:57,  1.05s/it]Loading train:  90%|████████▉ | 478/532 [11:19<00:56,  1.05s/it]Loading train:  90%|█████████ | 479/532 [11:20<00:55,  1.04s/it]Loading train:  90%|█████████ | 480/532 [11:21<00:51,  1.00it/s]Loading train:  90%|█████████ | 481/532 [11:22<00:50,  1.02it/s]Loading train:  91%|█████████ | 482/532 [11:23<00:48,  1.02it/s]Loading train:  91%|█████████ | 483/532 [11:24<00:46,  1.05it/s]Loading train:  91%|█████████ | 484/532 [11:25<00:45,  1.05it/s]Loading train:  91%|█████████ | 485/532 [11:26<00:46,  1.01it/s]Loading train:  91%|█████████▏| 486/532 [11:27<00:48,  1.05s/it]Loading train:  92%|█████████▏| 487/532 [11:29<00:49,  1.10s/it]Loading train:  92%|█████████▏| 488/532 [11:30<00:48,  1.09s/it]Loading train:  92%|█████████▏| 489/532 [11:31<00:47,  1.11s/it]Loading train:  92%|█████████▏| 490/532 [11:32<00:47,  1.12s/it]Loading train:  92%|█████████▏| 491/532 [11:33<00:43,  1.07s/it]Loading train:  92%|█████████▏| 492/532 [11:34<00:41,  1.04s/it]Loading train:  93%|█████████▎| 493/532 [11:35<00:41,  1.06s/it]Loading train:  93%|█████████▎| 494/532 [11:36<00:39,  1.04s/it]Loading train:  93%|█████████▎| 495/532 [11:37<00:38,  1.04s/it]Loading train:  93%|█████████▎| 496/532 [11:38<00:37,  1.03s/it]Loading train:  93%|█████████▎| 497/532 [11:39<00:36,  1.05s/it]Loading train:  94%|█████████▎| 498/532 [11:40<00:34,  1.03s/it]Loading train:  94%|█████████▍| 499/532 [11:41<00:33,  1.02s/it]Loading train:  94%|█████████▍| 500/532 [11:42<00:32,  1.02s/it]Loading train:  94%|█████████▍| 501/532 [11:43<00:31,  1.01s/it]Loading train:  94%|█████████▍| 502/532 [11:44<00:30,  1.02s/it]Loading train:  95%|█████████▍| 503/532 [11:45<00:29,  1.02s/it]Loading train:  95%|█████████▍| 504/532 [11:46<00:27,  1.02it/s]Loading train:  95%|█████████▍| 505/532 [11:47<00:26,  1.02it/s]Loading train:  95%|█████████▌| 506/532 [11:48<00:25,  1.03it/s]Loading train:  95%|█████████▌| 507/532 [11:49<00:24,  1.01it/s]Loading train:  95%|█████████▌| 508/532 [11:50<00:23,  1.02it/s]Loading train:  96%|█████████▌| 509/532 [11:51<00:23,  1.04s/it]Loading train:  96%|█████████▌| 510/532 [11:52<00:23,  1.07s/it]Loading train:  96%|█████████▌| 511/532 [11:54<00:23,  1.10s/it]Loading train:  96%|█████████▌| 512/532 [11:55<00:22,  1.13s/it]Loading train:  96%|█████████▋| 513/532 [11:56<00:21,  1.13s/it]Loading train:  97%|█████████▋| 514/532 [11:57<00:20,  1.14s/it]Loading train:  97%|█████████▋| 515/532 [11:58<00:18,  1.08s/it]Loading train:  97%|█████████▋| 516/532 [11:59<00:16,  1.05s/it]Loading train:  97%|█████████▋| 517/532 [12:00<00:15,  1.05s/it]Loading train:  97%|█████████▋| 518/532 [12:01<00:14,  1.06s/it]Loading train:  98%|█████████▊| 519/532 [12:02<00:13,  1.06s/it]Loading train:  98%|█████████▊| 520/532 [12:03<00:12,  1.04s/it]Loading train:  98%|█████████▊| 521/532 [12:04<00:11,  1.06s/it]Loading train:  98%|█████████▊| 522/532 [12:06<00:11,  1.13s/it]Loading train:  98%|█████████▊| 523/532 [12:07<00:10,  1.15s/it]Loading train:  98%|█████████▊| 524/532 [12:08<00:09,  1.14s/it]Loading train:  99%|█████████▊| 525/532 [12:09<00:07,  1.12s/it]Loading train:  99%|█████████▉| 526/532 [12:10<00:06,  1.12s/it]Loading train:  99%|█████████▉| 527/532 [12:11<00:05,  1.10s/it]Loading train:  99%|█████████▉| 528/532 [12:12<00:04,  1.06s/it]Loading train:  99%|█████████▉| 529/532 [12:13<00:03,  1.01s/it]Loading train: 100%|█████████▉| 530/532 [12:14<00:01,  1.03it/s]Loading train: 100%|█████████▉| 531/532 [12:15<00:00,  1.05it/s]Loading train: 100%|██████████| 532/532 [12:16<00:00,  1.05it/s]
concatenating: train:   0%|          | 0/532 [00:00<?, ?it/s]concatenating: train:   3%|▎         | 15/532 [00:00<00:03, 141.99it/s]concatenating: train:   5%|▌         | 28/532 [00:00<00:03, 137.46it/s]concatenating: train:   9%|▉         | 48/532 [00:00<00:03, 150.60it/s]concatenating: train:  11%|█▏        | 60/532 [00:00<00:03, 139.64it/s]concatenating: train:  16%|█▌        | 84/532 [00:00<00:02, 159.55it/s]concatenating: train:  20%|██        | 107/532 [00:00<00:02, 174.06it/s]concatenating: train:  25%|██▍       | 132/532 [00:00<00:02, 191.17it/s]concatenating: train:  30%|██▉       | 157/532 [00:00<00:01, 205.03it/s]concatenating: train:  33%|███▎      | 178/532 [00:00<00:01, 193.89it/s]concatenating: train:  37%|███▋      | 199/532 [00:01<00:01, 194.89it/s]concatenating: train:  41%|████      | 219/532 [00:01<00:01, 194.05it/s]concatenating: train:  45%|████▍     | 239/532 [00:01<00:01, 195.73it/s]concatenating: train:  49%|████▉     | 263/532 [00:01<00:01, 206.35it/s]concatenating: train:  54%|█████▍    | 288/532 [00:01<00:01, 217.44it/s]concatenating: train:  58%|█████▊    | 311/532 [00:01<00:01, 218.25it/s]concatenating: train:  63%|██████▎   | 334/532 [00:01<00:00, 219.26it/s]concatenating: train:  67%|██████▋   | 357/532 [00:01<00:00, 214.64it/s]concatenating: train:  72%|███████▏  | 381/532 [00:01<00:00, 220.38it/s]concatenating: train:  76%|███████▋  | 406/532 [00:01<00:00, 226.29it/s]concatenating: train:  81%|████████  | 430/532 [00:02<00:00, 228.32it/s]concatenating: train:  85%|████████▌ | 453/532 [00:02<00:00, 202.08it/s]concatenating: train:  89%|████████▉ | 474/532 [00:02<00:00, 192.05it/s]concatenating: train:  93%|█████████▎| 494/532 [00:02<00:00, 183.30it/s]concatenating: train:  96%|█████████▋| 513/532 [00:02<00:00, 174.16it/s]concatenating: train: 100%|██████████| 532/532 [00:02<00:00, 198.01it/s]
Loading test:   0%|          | 0/15 [00:00<?, ?it/s]Loading test:   7%|▋         | 1/15 [00:01<00:14,  1.02s/it]Loading test:  13%|█▎        | 2/15 [00:01<00:12,  1.00it/s]Loading test:  20%|██        | 3/15 [00:03<00:12,  1.07s/it]Loading test:  27%|██▋       | 4/15 [00:04<00:12,  1.10s/it]Loading test:  33%|███▎      | 5/15 [00:05<00:11,  1.14s/it]Loading test:  40%|████      | 6/15 [00:06<00:10,  1.17s/it]Loading test:  47%|████▋     | 7/15 [00:07<00:09,  1.13s/it]Loading test:  53%|█████▎    | 8/15 [00:09<00:08,  1.16s/it]Loading test:  60%|██████    | 9/15 [00:10<00:06,  1.15s/it]Loading test:  67%|██████▋   | 10/15 [00:11<00:05,  1.10s/it]Loading test:  73%|███████▎  | 11/15 [00:12<00:04,  1.08s/it]Loading test:  80%|████████  | 12/15 [00:13<00:03,  1.09s/it]Loading test:  87%|████████▋ | 13/15 [00:14<00:02,  1.11s/it]Loading test:  93%|█████████▎| 14/15 [00:15<00:01,  1.14s/it]Loading test: 100%|██████████| 15/15 [00:16<00:00,  1.12s/it]
concatenating: validation:   0%|          | 0/15 [00:00<?, ?it/s]concatenating: validation:  40%|████      | 6/15 [00:00<00:00, 55.05it/s]concatenating: validation: 100%|██████████| 15/15 [00:00<00:00, 103.36it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 56, 56, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 56, 56, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 56, 56, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 56, 56, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 56, 56, 10)   910         activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 56, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 56, 56, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 56, 56, 11)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 11)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28, 28, 11)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 28, 20)   2000        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 28, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 28, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 28, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 28, 28, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 28, 28, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 28, 31)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 31)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 14, 14, 31)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 14, 14, 40)   11200       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 14, 14, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 14, 14, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 14, 14, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 14, 14, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 14, 14, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 14, 14, 71)   0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 14, 14, 71)   0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 28, 28, 20)   5700        dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 28, 28, 51)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 28, 28, 20)   9200        concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 28, 28, 20)   80          conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 28, 28, 20)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 28, 28, 20)   3620        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 28, 28, 20)   80          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 28, 28, 20)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 28, 28, 71)   0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-06 18:59:11.952592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-06 18:59:11.952699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-06 18:59:11.952714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-06 18:59:11.952722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-06 18:59:11.953182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 28, 28, 71)   0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 56, 56, 10)   2850        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 56, 21)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 56, 56, 10)   1900        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 56, 56, 10)   40          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 56, 10)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 56, 56, 10)   910         activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 56, 56, 10)   40          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 56, 10)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 56, 31)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 56, 56, 31)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 56, 56, 13)   416         dropout_5[0][0]                  
==================================================================================================
Total params: 57,666
Trainable params: 57,266
Non-trainable params: 400
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.53974061e-02 2.89048015e-02 1.16758472e-01 1.00223856e-02
 3.03440156e-02 5.80063118e-03 6.84518755e-02 1.28261328e-01
 7.55818021e-02 1.22545826e-02 2.73712232e-01 1.84335085e-01
 1.75382711e-04]
Train on 33496 samples, validate on 969 samples
Epoch 1/300
 - 26s - loss: 60.8083 - acc: 0.7431 - mDice: 0.0146 - val_loss: 4.3706 - val_acc: 0.9217 - val_mDice: 0.0193

Epoch 00001: val_mDice improved from -inf to 0.01927, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 19s - loss: 7.1670 - acc: 0.9008 - mDice: 0.0331 - val_loss: 3.3611 - val_acc: 0.9217 - val_mDice: 0.0544

Epoch 00002: val_mDice improved from 0.01927 to 0.05436, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 18s - loss: 5.4859 - acc: 0.9027 - mDice: 0.0493 - val_loss: 3.0761 - val_acc: 0.9212 - val_mDice: 0.0755

Epoch 00003: val_mDice improved from 0.05436 to 0.07548, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 19s - loss: 4.6700 - acc: 0.9037 - mDice: 0.0647 - val_loss: 2.7833 - val_acc: 0.9196 - val_mDice: 0.1040

Epoch 00004: val_mDice improved from 0.07548 to 0.10403, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 5/300
 - 18s - loss: 4.0583 - acc: 0.9068 - mDice: 0.0864 - val_loss: 2.5109 - val_acc: 0.9204 - val_mDice: 0.1419

Epoch 00005: val_mDice improved from 0.10403 to 0.14194, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 18s - loss: 3.5442 - acc: 0.9134 - mDice: 0.1179 - val_loss: 2.2003 - val_acc: 0.9322 - val_mDice: 0.1881

Epoch 00006: val_mDice improved from 0.14194 to 0.18809, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 7/300
 - 19s - loss: 3.1174 - acc: 0.9192 - mDice: 0.1598 - val_loss: 1.9489 - val_acc: 0.9420 - val_mDice: 0.2488

Epoch 00007: val_mDice improved from 0.18809 to 0.24884, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 8/300
 - 18s - loss: 2.7863 - acc: 0.9244 - mDice: 0.2023 - val_loss: 1.7747 - val_acc: 0.9465 - val_mDice: 0.3053

Epoch 00008: val_mDice improved from 0.24884 to 0.30535, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 9/300
 - 18s - loss: 2.5279 - acc: 0.9285 - mDice: 0.2474 - val_loss: 1.5820 - val_acc: 0.9523 - val_mDice: 0.3635

Epoch 00009: val_mDice improved from 0.30535 to 0.36352, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 10/300
 - 19s - loss: 2.3201 - acc: 0.9315 - mDice: 0.2854 - val_loss: 1.4605 - val_acc: 0.9568 - val_mDice: 0.4065

Epoch 00010: val_mDice improved from 0.36352 to 0.40652, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 11/300
 - 18s - loss: 2.1516 - acc: 0.9345 - mDice: 0.3187 - val_loss: 1.3525 - val_acc: 0.9605 - val_mDice: 0.4446

Epoch 00011: val_mDice improved from 0.40652 to 0.44460, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 12/300
 - 18s - loss: 2.0198 - acc: 0.9374 - mDice: 0.3479 - val_loss: 1.2494 - val_acc: 0.9645 - val_mDice: 0.4815

Epoch 00012: val_mDice improved from 0.44460 to 0.48147, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 13/300
 - 19s - loss: 1.8995 - acc: 0.9400 - mDice: 0.3754 - val_loss: 1.2026 - val_acc: 0.9654 - val_mDice: 0.5013

Epoch 00013: val_mDice improved from 0.48147 to 0.50134, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 14/300
 - 18s - loss: 1.8043 - acc: 0.9423 - mDice: 0.3984 - val_loss: 1.1386 - val_acc: 0.9685 - val_mDice: 0.5244

Epoch 00014: val_mDice improved from 0.50134 to 0.52445, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 15/300
 - 19s - loss: 1.7078 - acc: 0.9446 - mDice: 0.4238 - val_loss: 1.0583 - val_acc: 0.9707 - val_mDice: 0.5552

Epoch 00015: val_mDice improved from 0.52445 to 0.55525, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 16/300
 - 19s - loss: 1.6199 - acc: 0.9464 - mDice: 0.4486 - val_loss: 1.0004 - val_acc: 0.9714 - val_mDice: 0.5800

Epoch 00016: val_mDice improved from 0.55525 to 0.58001, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 17/300
 - 18s - loss: 1.5313 - acc: 0.9483 - mDice: 0.4746 - val_loss: 0.9616 - val_acc: 0.9728 - val_mDice: 0.6033

Epoch 00017: val_mDice improved from 0.58001 to 0.60335, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 18/300
 - 18s - loss: 1.4568 - acc: 0.9499 - mDice: 0.4967 - val_loss: 0.9142 - val_acc: 0.9739 - val_mDice: 0.6244

Epoch 00018: val_mDice improved from 0.60335 to 0.62444, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 19/300
 - 19s - loss: 1.4024 - acc: 0.9509 - mDice: 0.5129 - val_loss: 0.9075 - val_acc: 0.9735 - val_mDice: 0.6329

Epoch 00019: val_mDice improved from 0.62444 to 0.63291, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 20/300
 - 18s - loss: 1.3532 - acc: 0.9519 - mDice: 0.5270 - val_loss: 0.8777 - val_acc: 0.9742 - val_mDice: 0.6395

Epoch 00020: val_mDice improved from 0.63291 to 0.63949, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 21/300
 - 18s - loss: 1.3119 - acc: 0.9528 - mDice: 0.5396 - val_loss: 0.8680 - val_acc: 0.9749 - val_mDice: 0.6409

Epoch 00021: val_mDice improved from 0.63949 to 0.64085, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 22/300
 - 18s - loss: 1.2787 - acc: 0.9538 - mDice: 0.5498 - val_loss: 0.8407 - val_acc: 0.9751 - val_mDice: 0.6554

Epoch 00022: val_mDice improved from 0.64085 to 0.65539, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 23/300
 - 19s - loss: 1.2415 - acc: 0.9549 - mDice: 0.5604 - val_loss: 0.8330 - val_acc: 0.9759 - val_mDice: 0.6594

Epoch 00023: val_mDice improved from 0.65539 to 0.65940, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 24/300
 - 18s - loss: 1.2186 - acc: 0.9555 - mDice: 0.5683 - val_loss: 0.8137 - val_acc: 0.9759 - val_mDice: 0.6660

Epoch 00024: val_mDice improved from 0.65940 to 0.66595, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 25/300
 - 18s - loss: 1.1962 - acc: 0.9561 - mDice: 0.5754 - val_loss: 0.8102 - val_acc: 0.9767 - val_mDice: 0.6710

Epoch 00025: val_mDice improved from 0.66595 to 0.67102, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 26/300
 - 19s - loss: 1.1726 - acc: 0.9567 - mDice: 0.5827 - val_loss: 0.8084 - val_acc: 0.9764 - val_mDice: 0.6701

Epoch 00026: val_mDice did not improve from 0.67102
Epoch 27/300
 - 19s - loss: 1.1576 - acc: 0.9569 - mDice: 0.5872 - val_loss: 0.7979 - val_acc: 0.9765 - val_mDice: 0.6774

Epoch 00027: val_mDice improved from 0.67102 to 0.67739, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 28/300
 - 19s - loss: 1.1367 - acc: 0.9575 - mDice: 0.5943 - val_loss: 0.7950 - val_acc: 0.9767 - val_mDice: 0.6747

Epoch 00028: val_mDice did not improve from 0.67739
Epoch 29/300
 - 19s - loss: 1.1240 - acc: 0.9579 - mDice: 0.5985 - val_loss: 0.7950 - val_acc: 0.9771 - val_mDice: 0.6794

Epoch 00029: val_mDice improved from 0.67739 to 0.67938, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 30/300
 - 18s - loss: 1.1079 - acc: 0.9583 - mDice: 0.6037 - val_loss: 0.7793 - val_acc: 0.9764 - val_mDice: 0.6829

Epoch 00030: val_mDice improved from 0.67938 to 0.68292, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 31/300
 - 20s - loss: 1.0938 - acc: 0.9586 - mDice: 0.6083 - val_loss: 0.7853 - val_acc: 0.9768 - val_mDice: 0.6830

Epoch 00031: val_mDice improved from 0.68292 to 0.68301, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 32/300
 - 19s - loss: 1.0869 - acc: 0.9587 - mDice: 0.6102 - val_loss: 0.7766 - val_acc: 0.9770 - val_mDice: 0.6852

Epoch 00032: val_mDice improved from 0.68301 to 0.68521, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 33/300
 - 20s - loss: 1.0733 - acc: 0.9591 - mDice: 0.6153 - val_loss: 0.7540 - val_acc: 0.9772 - val_mDice: 0.6901

Epoch 00033: val_mDice improved from 0.68521 to 0.69009, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 34/300
 - 19s - loss: 1.0637 - acc: 0.9593 - mDice: 0.6178 - val_loss: 0.7730 - val_acc: 0.9771 - val_mDice: 0.6893

Epoch 00034: val_mDice did not improve from 0.69009
Epoch 35/300
 - 20s - loss: 1.0607 - acc: 0.9593 - mDice: 0.6186 - val_loss: 0.7604 - val_acc: 0.9773 - val_mDice: 0.6884

Epoch 00035: val_mDice did not improve from 0.69009
Epoch 36/300
 - 19s - loss: 1.0444 - acc: 0.9598 - mDice: 0.6242 - val_loss: 0.7638 - val_acc: 0.9768 - val_mDice: 0.6906

Epoch 00036: val_mDice improved from 0.69009 to 0.69055, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 37/300
 - 20s - loss: 1.0408 - acc: 0.9598 - mDice: 0.6253 - val_loss: 0.7482 - val_acc: 0.9780 - val_mDice: 0.6932

Epoch 00037: val_mDice improved from 0.69055 to 0.69317, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 38/300
 - 20s - loss: 1.0317 - acc: 0.9601 - mDice: 0.6282 - val_loss: 0.7434 - val_acc: 0.9779 - val_mDice: 0.6962

Epoch 00038: val_mDice improved from 0.69317 to 0.69625, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 39/300
 - 19s - loss: 1.0231 - acc: 0.9603 - mDice: 0.6306 - val_loss: 0.7312 - val_acc: 0.9778 - val_mDice: 0.7023

Epoch 00039: val_mDice improved from 0.69625 to 0.70232, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 40/300
 - 19s - loss: 1.0200 - acc: 0.9603 - mDice: 0.6320 - val_loss: 0.7355 - val_acc: 0.9772 - val_mDice: 0.7022

Epoch 00040: val_mDice did not improve from 0.70232
Epoch 41/300
 - 19s - loss: 1.0123 - acc: 0.9605 - mDice: 0.6345 - val_loss: 0.7345 - val_acc: 0.9776 - val_mDice: 0.7024

Epoch 00041: val_mDice improved from 0.70232 to 0.70238, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 42/300
 - 18s - loss: 1.0073 - acc: 0.9606 - mDice: 0.6363 - val_loss: 0.7411 - val_acc: 0.9781 - val_mDice: 0.7057

Epoch 00042: val_mDice improved from 0.70238 to 0.70567, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 43/300
 - 20s - loss: 1.0031 - acc: 0.9607 - mDice: 0.6372 - val_loss: 0.7668 - val_acc: 0.9766 - val_mDice: 0.7010

Epoch 00043: val_mDice did not improve from 0.70567
Epoch 44/300
 - 19s - loss: 1.0009 - acc: 0.9607 - mDice: 0.6384 - val_loss: 0.7295 - val_acc: 0.9780 - val_mDice: 0.7068

Epoch 00044: val_mDice improved from 0.70567 to 0.70680, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 45/300
 - 20s - loss: 0.9920 - acc: 0.9610 - mDice: 0.6411 - val_loss: 0.7478 - val_acc: 0.9777 - val_mDice: 0.7017

Epoch 00045: val_mDice did not improve from 0.70680
Epoch 46/300
 - 19s - loss: 0.9868 - acc: 0.9610 - mDice: 0.6425 - val_loss: 0.7229 - val_acc: 0.9782 - val_mDice: 0.7074

Epoch 00046: val_mDice improved from 0.70680 to 0.70742, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 47/300
 - 20s - loss: 0.9812 - acc: 0.9612 - mDice: 0.6446 - val_loss: 0.7192 - val_acc: 0.9776 - val_mDice: 0.7071

Epoch 00047: val_mDice did not improve from 0.70742
Epoch 48/300
 - 18s - loss: 0.9763 - acc: 0.9613 - mDice: 0.6466 - val_loss: 0.7180 - val_acc: 0.9784 - val_mDice: 0.7096

Epoch 00048: val_mDice improved from 0.70742 to 0.70965, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 49/300
 - 19s - loss: 0.9751 - acc: 0.9615 - mDice: 0.6476 - val_loss: 0.7318 - val_acc: 0.9778 - val_mDice: 0.7060

Epoch 00049: val_mDice did not improve from 0.70965
Epoch 50/300
 - 19s - loss: 0.9719 - acc: 0.9615 - mDice: 0.6484 - val_loss: 0.7206 - val_acc: 0.9786 - val_mDice: 0.7093

Epoch 00050: val_mDice did not improve from 0.70965
Epoch 51/300
 - 19s - loss: 0.9632 - acc: 0.9616 - mDice: 0.6508 - val_loss: 0.7174 - val_acc: 0.9790 - val_mDice: 0.7097

Epoch 00051: val_mDice improved from 0.70965 to 0.70973, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 52/300
 - 20s - loss: 0.9621 - acc: 0.9617 - mDice: 0.6512 - val_loss: 0.7288 - val_acc: 0.9784 - val_mDice: 0.7087

Epoch 00052: val_mDice did not improve from 0.70973
Epoch 53/300
 - 19s - loss: 0.9592 - acc: 0.9618 - mDice: 0.6521 - val_loss: 0.7243 - val_acc: 0.9791 - val_mDice: 0.7099

Epoch 00053: val_mDice improved from 0.70973 to 0.70988, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 54/300
 - 19s - loss: 0.9554 - acc: 0.9619 - mDice: 0.6535 - val_loss: 0.7191 - val_acc: 0.9784 - val_mDice: 0.7139

Epoch 00054: val_mDice improved from 0.70988 to 0.71386, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 55/300
 - 19s - loss: 0.9537 - acc: 0.9619 - mDice: 0.6545 - val_loss: 0.7314 - val_acc: 0.9786 - val_mDice: 0.7106

Epoch 00055: val_mDice did not improve from 0.71386
Epoch 56/300
 - 20s - loss: 0.9484 - acc: 0.9621 - mDice: 0.6560 - val_loss: 0.7263 - val_acc: 0.9782 - val_mDice: 0.7104

Epoch 00056: val_mDice did not improve from 0.71386
Epoch 57/300
 - 22s - loss: 0.9464 - acc: 0.9622 - mDice: 0.6567 - val_loss: 0.7377 - val_acc: 0.9784 - val_mDice: 0.7105

Epoch 00057: val_mDice did not improve from 0.71386
Epoch 58/300
 - 21s - loss: 0.9438 - acc: 0.9622 - mDice: 0.6576 - val_loss: 0.7071 - val_acc: 0.9790 - val_mDice: 0.7159

Epoch 00058: val_mDice improved from 0.71386 to 0.71585, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 59/300
 - 21s - loss: 0.9413 - acc: 0.9623 - mDice: 0.6581 - val_loss: 0.7078 - val_acc: 0.9783 - val_mDice: 0.7195

Epoch 00059: val_mDice improved from 0.71585 to 0.71946, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 60/300
 - 22s - loss: 0.9398 - acc: 0.9624 - mDice: 0.6593 - val_loss: 0.7118 - val_acc: 0.9786 - val_mDice: 0.7148

Epoch 00060: val_mDice did not improve from 0.71946
Epoch 61/300
 - 22s - loss: 0.9351 - acc: 0.9625 - mDice: 0.6607 - val_loss: 0.7155 - val_acc: 0.9788 - val_mDice: 0.7149

Epoch 00061: val_mDice did not improve from 0.71946
Epoch 62/300
 - 21s - loss: 0.9354 - acc: 0.9624 - mDice: 0.6605 - val_loss: 0.7021 - val_acc: 0.9792 - val_mDice: 0.7188

Epoch 00062: val_mDice did not improve from 0.71946
Epoch 63/300
 - 23s - loss: 0.9329 - acc: 0.9626 - mDice: 0.6615 - val_loss: 0.6977 - val_acc: 0.9792 - val_mDice: 0.7201

Epoch 00063: val_mDice improved from 0.71946 to 0.72015, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 64/300
 - 22s - loss: 0.9312 - acc: 0.9626 - mDice: 0.6619 - val_loss: 0.7067 - val_acc: 0.9790 - val_mDice: 0.7185

Epoch 00064: val_mDice did not improve from 0.72015
Epoch 65/300
 - 21s - loss: 0.9264 - acc: 0.9627 - mDice: 0.6637 - val_loss: 0.7082 - val_acc: 0.9787 - val_mDice: 0.7196

Epoch 00065: val_mDice did not improve from 0.72015
Epoch 66/300
 - 22s - loss: 0.9257 - acc: 0.9628 - mDice: 0.6637 - val_loss: 0.7336 - val_acc: 0.9782 - val_mDice: 0.7131

Epoch 00066: val_mDice did not improve from 0.72015
Epoch 67/300
 - 22s - loss: 0.9245 - acc: 0.9627 - mDice: 0.6644 - val_loss: 0.7023 - val_acc: 0.9794 - val_mDice: 0.7230

Epoch 00067: val_mDice improved from 0.72015 to 0.72303, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 68/300
 - 20s - loss: 0.9213 - acc: 0.9628 - mDice: 0.6655 - val_loss: 0.7136 - val_acc: 0.9789 - val_mDice: 0.7168

Epoch 00068: val_mDice did not improve from 0.72303
Epoch 69/300
 - 20s - loss: 0.9214 - acc: 0.9629 - mDice: 0.6654 - val_loss: 0.7096 - val_acc: 0.9789 - val_mDice: 0.7196

Epoch 00069: val_mDice did not improve from 0.72303
Epoch 70/300
 - 18s - loss: 0.9186 - acc: 0.9628 - mDice: 0.6659 - val_loss: 0.6980 - val_acc: 0.9791 - val_mDice: 0.7216

Epoch 00070: val_mDice did not improve from 0.72303
Epoch 71/300
 - 19s - loss: 0.9169 - acc: 0.9630 - mDice: 0.6671 - val_loss: 0.6897 - val_acc: 0.9789 - val_mDice: 0.7257

Epoch 00071: val_mDice improved from 0.72303 to 0.72565, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 72/300
 - 18s - loss: 0.9153 - acc: 0.9630 - mDice: 0.6673 - val_loss: 0.6906 - val_acc: 0.9791 - val_mDice: 0.7258

Epoch 00072: val_mDice improved from 0.72565 to 0.72585, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 73/300
 - 18s - loss: 0.9156 - acc: 0.9631 - mDice: 0.6672 - val_loss: 0.7067 - val_acc: 0.9791 - val_mDice: 0.7206

Epoch 00073: val_mDice did not improve from 0.72585
Epoch 74/300
 - 18s - loss: 0.9108 - acc: 0.9631 - mDice: 0.6686 - val_loss: 0.6956 - val_acc: 0.9795 - val_mDice: 0.7260

Epoch 00074: val_mDice improved from 0.72585 to 0.72604, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 75/300
 - 19s - loss: 0.9097 - acc: 0.9632 - mDice: 0.6692 - val_loss: 0.6949 - val_acc: 0.9790 - val_mDice: 0.7242

Epoch 00075: val_mDice did not improve from 0.72604
Epoch 76/300
 - 18s - loss: 0.9094 - acc: 0.9631 - mDice: 0.6697 - val_loss: 0.7103 - val_acc: 0.9786 - val_mDice: 0.7257

Epoch 00076: val_mDice did not improve from 0.72604
Epoch 77/300
 - 18s - loss: 0.9073 - acc: 0.9632 - mDice: 0.6702 - val_loss: 0.7010 - val_acc: 0.9789 - val_mDice: 0.7256

Epoch 00077: val_mDice did not improve from 0.72604
Epoch 78/300
 - 18s - loss: 0.9031 - acc: 0.9633 - mDice: 0.6721 - val_loss: 0.6994 - val_acc: 0.9792 - val_mDice: 0.7268

Epoch 00078: val_mDice improved from 0.72604 to 0.72684, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 79/300
 - 18s - loss: 0.9029 - acc: 0.9634 - mDice: 0.6719 - val_loss: 0.7124 - val_acc: 0.9784 - val_mDice: 0.7246

Epoch 00079: val_mDice did not improve from 0.72684
Epoch 80/300
 - 19s - loss: 0.9010 - acc: 0.9634 - mDice: 0.6730 - val_loss: 0.7001 - val_acc: 0.9791 - val_mDice: 0.7218

Epoch 00080: val_mDice did not improve from 0.72684
Epoch 81/300
 - 19s - loss: 0.8979 - acc: 0.9635 - mDice: 0.6739 - val_loss: 0.7005 - val_acc: 0.9790 - val_mDice: 0.7252

Epoch 00081: val_mDice did not improve from 0.72684
Epoch 82/300
 - 18s - loss: 0.8984 - acc: 0.9635 - mDice: 0.6737 - val_loss: 0.7005 - val_acc: 0.9789 - val_mDice: 0.7256

Epoch 00082: val_mDice did not improve from 0.72684
Epoch 83/300
 - 18s - loss: 0.8930 - acc: 0.9636 - mDice: 0.6759 - val_loss: 0.6944 - val_acc: 0.9793 - val_mDice: 0.7247

Epoch 00083: val_mDice did not improve from 0.72684
Epoch 84/300
 - 18s - loss: 0.8942 - acc: 0.9635 - mDice: 0.6748 - val_loss: 0.6810 - val_acc: 0.9793 - val_mDice: 0.7331

Epoch 00084: val_mDice improved from 0.72684 to 0.73307, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 85/300
 - 20s - loss: 0.8918 - acc: 0.9636 - mDice: 0.6760 - val_loss: 0.7023 - val_acc: 0.9794 - val_mDice: 0.7248

Epoch 00085: val_mDice did not improve from 0.73307
Epoch 86/300
 - 20s - loss: 0.8909 - acc: 0.9636 - mDice: 0.6763 - val_loss: 0.6954 - val_acc: 0.9795 - val_mDice: 0.7273

Epoch 00086: val_mDice did not improve from 0.73307
Epoch 87/300
 - 19s - loss: 0.8909 - acc: 0.9636 - mDice: 0.6767 - val_loss: 0.6902 - val_acc: 0.9793 - val_mDice: 0.7282

Epoch 00087: val_mDice did not improve from 0.73307
Epoch 88/300
 - 20s - loss: 0.8892 - acc: 0.9636 - mDice: 0.6768 - val_loss: 0.6884 - val_acc: 0.9790 - val_mDice: 0.7260

Epoch 00088: val_mDice did not improve from 0.73307
Epoch 89/300
 - 21s - loss: 0.8887 - acc: 0.9637 - mDice: 0.6770 - val_loss: 0.6993 - val_acc: 0.9795 - val_mDice: 0.7224

Epoch 00089: val_mDice did not improve from 0.73307
Epoch 90/300
 - 20s - loss: 0.8876 - acc: 0.9636 - mDice: 0.6775 - val_loss: 0.6995 - val_acc: 0.9792 - val_mDice: 0.7287

Epoch 00090: val_mDice did not improve from 0.73307
Epoch 91/300
 - 20s - loss: 0.8874 - acc: 0.9637 - mDice: 0.6776 - val_loss: 0.6951 - val_acc: 0.9788 - val_mDice: 0.7253

Epoch 00091: val_mDice did not improve from 0.73307
Epoch 92/300
 - 20s - loss: 0.8846 - acc: 0.9638 - mDice: 0.6783 - val_loss: 0.7082 - val_acc: 0.9795 - val_mDice: 0.7272

Epoch 00092: val_mDice did not improve from 0.73307
Epoch 93/300
 - 22s - loss: 0.8840 - acc: 0.9637 - mDice: 0.6787 - val_loss: 0.6908 - val_acc: 0.9795 - val_mDice: 0.7304

Epoch 00093: val_mDice did not improve from 0.73307
Epoch 94/300
 - 20s - loss: 0.8847 - acc: 0.9638 - mDice: 0.6788 - val_loss: 0.7039 - val_acc: 0.9795 - val_mDice: 0.7263

Epoch 00094: val_mDice did not improve from 0.73307
Epoch 95/300
 - 20s - loss: 0.8816 - acc: 0.9638 - mDice: 0.6799 - val_loss: 0.7005 - val_acc: 0.9797 - val_mDice: 0.7241

Epoch 00095: val_mDice did not improve from 0.73307
Epoch 96/300
 - 20s - loss: 0.8808 - acc: 0.9638 - mDice: 0.6797 - val_loss: 0.6948 - val_acc: 0.9795 - val_mDice: 0.7298

Epoch 00096: val_mDice did not improve from 0.73307
Epoch 97/300
 - 21s - loss: 0.8797 - acc: 0.9639 - mDice: 0.6803 - val_loss: 0.6902 - val_acc: 0.9794 - val_mDice: 0.7292

Epoch 00097: val_mDice did not improve from 0.73307
Epoch 98/300
 - 20s - loss: 0.8810 - acc: 0.9639 - mDice: 0.6798 - val_loss: 0.6824 - val_acc: 0.9794 - val_mDice: 0.7318

Epoch 00098: val_mDice did not improve from 0.73307
Epoch 99/300
 - 20s - loss: 0.8799 - acc: 0.9639 - mDice: 0.6800 - val_loss: 0.6868 - val_acc: 0.9793 - val_mDice: 0.7281

Epoch 00099: val_mDice did not improve from 0.73307
Epoch 100/300
 - 20s - loss: 0.8755 - acc: 0.9640 - mDice: 0.6820 - val_loss: 0.6968 - val_acc: 0.9796 - val_mDice: 0.7296

Epoch 00100: val_mDice did not improve from 0.73307
Epoch 101/300
 - 21s - loss: 0.8774 - acc: 0.9639 - mDice: 0.6816 - val_loss: 0.6935 - val_acc: 0.9796 - val_mDice: 0.7297

Epoch 00101: val_mDice did not improve from 0.73307
Epoch 102/300
 - 21s - loss: 0.8762 - acc: 0.9639 - mDice: 0.6815 - val_loss: 0.6928 - val_acc: 0.9795 - val_mDice: 0.7309

Epoch 00102: val_mDice did not improve from 0.73307
Epoch 103/300
 - 19s - loss: 0.8787 - acc: 0.9639 - mDice: 0.6810 - val_loss: 0.7008 - val_acc: 0.9789 - val_mDice: 0.7286

Epoch 00103: val_mDice did not improve from 0.73307
Epoch 104/300
 - 20s - loss: 0.8748 - acc: 0.9640 - mDice: 0.6822 - val_loss: 0.7023 - val_acc: 0.9795 - val_mDice: 0.7266

Epoch 00104: val_mDice did not improve from 0.73307
Epoch 105/300
 - 21s - loss: 0.8741 - acc: 0.9640 - mDice: 0.6820 - val_loss: 0.7052 - val_acc: 0.9796 - val_mDice: 0.7304

Epoch 00105: val_mDice did not improve from 0.73307
Epoch 106/300
 - 21s - loss: 0.8723 - acc: 0.9640 - mDice: 0.6829 - val_loss: 0.6882 - val_acc: 0.9799 - val_mDice: 0.7329

Epoch 00106: val_mDice did not improve from 0.73307
Epoch 107/300
 - 19s - loss: 0.8734 - acc: 0.9640 - mDice: 0.6829 - val_loss: 0.7013 - val_acc: 0.9796 - val_mDice: 0.7287

Epoch 00107: val_mDice did not improve from 0.73307
Epoch 108/300
 - 20s - loss: 0.8715 - acc: 0.9640 - mDice: 0.6834 - val_loss: 0.7066 - val_acc: 0.9792 - val_mDice: 0.7262

Epoch 00108: val_mDice did not improve from 0.73307
Epoch 109/300
 - 21s - loss: 0.8699 - acc: 0.9640 - mDice: 0.6834 - val_loss: 0.6970 - val_acc: 0.9795 - val_mDice: 0.7282

Epoch 00109: val_mDice did not improve from 0.73307
Epoch 110/300
 - 20s - loss: 0.8730 - acc: 0.9640 - mDice: 0.6828 - val_loss: 0.6946 - val_acc: 0.9792 - val_mDice: 0.7279

Epoch 00110: val_mDice did not improve from 0.73307
Epoch 111/300
 - 19s - loss: 0.8698 - acc: 0.9641 - mDice: 0.6837 - val_loss: 0.6845 - val_acc: 0.9798 - val_mDice: 0.7305

Epoch 00111: val_mDice did not improve from 0.73307
Epoch 112/300
 - 22s - loss: 0.8695 - acc: 0.9641 - mDice: 0.6840 - val_loss: 0.6983 - val_acc: 0.9795 - val_mDice: 0.7289

Epoch 00112: val_mDice did not improve from 0.73307
Epoch 113/300
 - 21s - loss: 0.8687 - acc: 0.9642 - mDice: 0.6840 - val_loss: 0.7027 - val_acc: 0.9794 - val_mDice: 0.7305

Epoch 00113: val_mDice did not improve from 0.73307
Epoch 114/300
 - 26s - loss: 0.8677 - acc: 0.9642 - mDice: 0.6842 - val_loss: 0.6868 - val_acc: 0.9798 - val_mDice: 0.7309

Epoch 00114: val_mDice did not improve from 0.73307
Restoring model weights from the end of the best epoch
Epoch 00114: early stopping
{'val_loss': [4.370564208803285, 3.361142444167713, 3.0760523775905773, 2.7832607622609173, 2.510891836248069, 2.2003449731813003, 1.9488589799318028, 1.7747362171779353, 1.582010926353919, 1.4605204988928402, 1.3525212967481899, 1.2493853466306555, 1.2026180068282766, 1.1386286548047613, 1.0583394051090236, 1.0003745368267607, 0.9616028545318619, 0.9141998263335449, 0.907506736439448, 0.8777201279644135, 0.8679903609710827, 0.8407199900708824, 0.8330483449501888, 0.8137294570727983, 0.8102308830363586, 0.8084382606118579, 0.7978852057235529, 0.7949523312511582, 0.7950010242476921, 0.7792869854268644, 0.7852706724030069, 0.776625907581042, 0.7539503012771331, 0.7730356151597542, 0.7604165548080015, 0.7637554989326111, 0.7482383276409901, 0.7434495108661514, 0.7312132340343621, 0.7354968653682339, 0.7345345758739763, 0.7410531207319384, 0.7667896885989989, 0.7294606137386417, 0.7477526054539794, 0.7229487464769951, 0.7191758458151782, 0.7179903159508149, 0.7318330331175935, 0.7206349087757961, 0.7173777893108726, 0.7288229423041683, 0.7243187190701472, 0.719067995423995, 0.7313624066218996, 0.7262805892833123, 0.7377352323940541, 0.7070559821138687, 0.7078382197240803, 0.711837979170068, 0.7154830705578236, 0.7020802278575268, 0.697668042929672, 0.7066868668800783, 0.7081917297052771, 0.7335547533874295, 0.702313233978116, 0.7136097343405949, 0.7096073189202476, 0.6979965214205232, 0.6897104176451424, 0.6905558958449723, 0.7066504512716496, 0.6956172877051882, 0.6948526855654269, 0.7102514339305299, 0.7010234548519024, 0.6994415231594976, 0.7123612787639886, 0.7000808876672888, 0.700539336023685, 0.7005180531364968, 0.6943665108075452, 0.681039479986925, 0.7022905032639656, 0.6954342261556501, 0.6902426988409277, 0.6884326086263293, 0.6993284148882049, 0.699522851175322, 0.6951249932910636, 0.7081533874951157, 0.6907690624765075, 0.7039029786153721, 0.7005326593807977, 0.6948204276423952, 0.6902490535633728, 0.6824162611343789, 0.6868386250162273, 0.6968452059755138, 0.6935057392491891, 0.6927897518325762, 0.7008440599106905, 0.7023368779535264, 0.7051974698916554, 0.6881501417534024, 0.7013437311531221, 0.7065817646997509, 0.6970062150982266, 0.6945699882396603, 0.6844888807142728, 0.6983457328242291, 0.7027466296842101, 0.686769997218568], 'val_acc': [0.9217279151743287, 0.9217279151743287, 0.92117176391761, 0.9195592813078464, 0.9204020448513445, 0.9322136664538192, 0.9419741599798449, 0.9465249947227069, 0.9523335682964423, 0.9568393160315121, 0.9604730024180299, 0.9644877632582027, 0.9654460482307017, 0.9684956241687385, 0.9707050629198489, 0.9714425136676391, 0.9727953609052211, 0.9738981205858559, 0.97347458997132, 0.974167967113302, 0.9749498432511762, 0.9751318314865277, 0.9758949639012324, 0.9759370836557126, 0.9766824436753649, 0.9764254291852316, 0.9764810492379746, 0.9766735690420011, 0.9770747132222596, 0.9763872696642291, 0.9767821595395682, 0.9769693972894651, 0.9771997583539862, 0.9771155193371177, 0.9772708474421034, 0.9767917042792273, 0.9780004081711311, 0.9778773364513897, 0.9777914500950045, 0.9772464840281736, 0.9776157196092162, 0.978131726614831, 0.9765504829900798, 0.9779629014101806, 0.9776591513425081, 0.9782264860052812, 0.9776328313707444, 0.9783643689564016, 0.9778105324389887, 0.9785855057561853, 0.9790287811320633, 0.9783505512587918, 0.9791120357803762, 0.9784120872416856, 0.9785572171088219, 0.9782314299921995, 0.9784163657356711, 0.9790047602141728, 0.9782768286787689, 0.9786082214000178, 0.9788464783884054, 0.979219983175197, 0.9792308419850588, 0.9790462185969909, 0.9786931194511115, 0.9782166177766365, 0.97936015982869, 0.9789066958722684, 0.9789099741892426, 0.9790669649501088, 0.9788836671964057, 0.9790817703378951, 0.97914922514198, 0.9794914675693885, 0.9789511148036449, 0.9786052540851944, 0.9789475104142022, 0.9791923386762755, 0.9784282154343077, 0.9791261957279792, 0.9790442562570759, 0.9788764142522625, 0.9793354889187651, 0.9793022455814823, 0.979414471408777, 0.9794957535677773, 0.9793456844501082, 0.9790060831420315, 0.9795365465806857, 0.9791883863777814, 0.978847139575533, 0.9794710668493966, 0.9794572460762119, 0.979521419672282, 0.9796767444556466, 0.9794615406246993, 0.9793983390948844, 0.9793512863025331, 0.9793460057246796, 0.9795553098030012, 0.9795793344115817, 0.9794618506426659, 0.9789050471794987, 0.9794845513392036, 0.9795967769204524, 0.9798834048311531, 0.9795984198311412, 0.9791808169569639, 0.9795484016923344, 0.9792170082329473, 0.9797807313094321, 0.9794523084864897, 0.9794045887249296, 0.9798014556414326], 'val_mDice': [0.019271828893522115, 0.05436193710048871, 0.07548236676229413, 0.10402925243318635, 0.14194002298501746, 0.18808839261777877, 0.2488381684257027, 0.3053494458720165, 0.36351734673521713, 0.4065171873852441, 0.44460100415321324, 0.48146790518234145, 0.5013383067798319, 0.524448390408074, 0.555245507366271, 0.5800097859680837, 0.6033476090406609, 0.6244377927514422, 0.6329064434403852, 0.6394876108819117, 0.6408501997574687, 0.6553915331238195, 0.6594032442852685, 0.6659534561867807, 0.6710239627289944, 0.6700624023920735, 0.6773930175385608, 0.6747043515383521, 0.6793830296326471, 0.6829233609978014, 0.683008539787387, 0.6852115225373653, 0.6900923854918426, 0.6893219524615812, 0.68842786802719, 0.690554798941125, 0.6931745759350842, 0.6962482812357884, 0.7023189738931056, 0.7022204624856097, 0.7023808262296506, 0.7056657291172213, 0.7010241331699832, 0.7068049565065264, 0.7017295301514145, 0.70741797711458, 0.7070543000203537, 0.7096454186213151, 0.7059687024176551, 0.7093055077873639, 0.7097340988300902, 0.7087133518190453, 0.7098849525884701, 0.7138569764677585, 0.710618677400091, 0.7104418988813433, 0.7104990801575014, 0.7158537861978552, 0.7194626616127597, 0.7147865617730423, 0.7148990281103074, 0.7187710275837019, 0.7201497824814543, 0.7184598118036032, 0.7195531770171765, 0.7130622960957703, 0.7230328776642019, 0.7168365902698938, 0.719606082013763, 0.7215598544838259, 0.7256527584280638, 0.7258493283953829, 0.7206141566713528, 0.7260375677370557, 0.7242404432857737, 0.7257229262584257, 0.7255670184075402, 0.7268433223321834, 0.7246241807568553, 0.7218442244918477, 0.7251787127848134, 0.7256367368348735, 0.7247162689488492, 0.733067744164521, 0.7247956460351422, 0.7273233900129241, 0.7282207500577834, 0.7260225923929913, 0.7224197585762346, 0.7287478245202725, 0.7253081145301323, 0.7272388693348911, 0.7304456154628435, 0.7262718141140461, 0.7241328594239258, 0.7298401083001411, 0.7292133808382032, 0.7318463448523491, 0.7280787663809163, 0.7296200644982243, 0.7296891588298652, 0.7309059877144662, 0.7286001111700808, 0.7266149693106227, 0.7304423255201956, 0.732867887453152, 0.7286733252345224, 0.7262285205355862, 0.7281918165238404, 0.7279483494497797, 0.7305452133479872, 0.7288974049290636, 0.7304731586523223, 0.7309345469509239], 'loss': [60.80829949603321, 7.167028731197396, 5.485919693702441, 4.6699779315526655, 4.058292924717215, 3.544184316249517, 3.1173621385058214, 2.7863121091080987, 2.527943088554499, 2.3201305707656372, 2.1516266023882085, 2.019751672346722, 1.8994761259395807, 1.8043242800141792, 1.707783412657178, 1.6198852322168216, 1.531309094667036, 1.4568282264298802, 1.402437698223268, 1.3532270159930924, 1.3119129153319524, 1.2786729053136185, 1.2415331586508527, 1.2185853627606682, 1.1962459057832864, 1.1726365690160714, 1.1576133567919047, 1.1366894478754637, 1.1240186435896713, 1.1079327071271081, 1.093838848844473, 1.0868739038741415, 1.0732730343058823, 1.0637068435645827, 1.0607278080666467, 1.044361487191134, 1.040765717828476, 1.0317001030728103, 1.0231472742082055, 1.0199660235325931, 1.0122573567954287, 1.0073132444487172, 1.003094587123619, 1.0008966548576086, 0.9920315235490186, 0.986750143950043, 0.9812111234875605, 0.9763466388606388, 0.9751301013486665, 0.9719028949580957, 0.9631817739875954, 0.9621203404879951, 0.959231319947376, 0.9554274090654047, 0.9537446585637105, 0.9483814961106788, 0.9464084480268334, 0.9437892084221923, 0.9413293171020063, 0.9397759077114509, 0.9351161445186507, 0.9354083279678467, 0.9328850402107721, 0.9311674799488073, 0.9263602142149491, 0.9256845568241127, 0.9245250419098977, 0.9212827761574124, 0.9213736276083355, 0.9186264898175125, 0.9169149140355579, 0.9153035657913212, 0.9155837709917384, 0.9108106714602384, 0.9096932404147203, 0.9094182013084474, 0.9073344995718114, 0.9030767919013915, 0.9029015811511204, 0.9010355357398331, 0.8978899674481642, 0.8984197124550557, 0.8929516254773652, 0.8941696407417993, 0.8917931117418133, 0.8909119211434464, 0.8908759233189677, 0.8891820592486775, 0.8886934885595476, 0.8875812555885497, 0.8873812897352834, 0.8845870140019083, 0.88404170290109, 0.8847008889675824, 0.8816384329683661, 0.8807561197684037, 0.8796766432509776, 0.8810285041333383, 0.8799150598086176, 0.8755083540216505, 0.8773514981383153, 0.8762094676565777, 0.8787103380099498, 0.8748220772383918, 0.8741210482130194, 0.87225546009335, 0.8734408540431884, 0.871510628259407, 0.869893683677133, 0.8729729866935952, 0.8697649447266516, 0.8695268107607964, 0.8686817434741171, 0.8676659881442266], 'acc': [0.7431005213086246, 0.9007580249768496, 0.902650689243103, 0.9037226271324691, 0.9068497129661928, 0.9133685679845147, 0.9191752782664038, 0.9243776906439192, 0.9284608932249808, 0.9315279749973252, 0.9344990328968582, 0.9373824000928007, 0.9399968703436004, 0.9422807265985031, 0.9445817648069028, 0.9464141603996112, 0.948288583210268, 0.9499334277914793, 0.9509447973469775, 0.9519299874164507, 0.9528489253003927, 0.9537779302337388, 0.9549323934443332, 0.9555305955317187, 0.9561438851177707, 0.9566673524259581, 0.9568968782468773, 0.9575055122005361, 0.9579044310765304, 0.9582907476629026, 0.9585698232150801, 0.9587238743662806, 0.9590536878776346, 0.9592777851631796, 0.9592702373317753, 0.9597765053616863, 0.9598314912443887, 0.9600522863087633, 0.9603286193853237, 0.9603166907548848, 0.9604854388284831, 0.9606404896208971, 0.9607128332317203, 0.9607413992595354, 0.9609760647034172, 0.9610412741350849, 0.9612022574616412, 0.9613290623503025, 0.9614551802836884, 0.9615234861531632, 0.961615544195986, 0.9617242518147792, 0.9617541903082272, 0.9619121995594612, 0.96193823861085, 0.962114783070211, 0.9621994717467904, 0.962223149346713, 0.9623077512428019, 0.9623591699861017, 0.9624888013762736, 0.9624259779739129, 0.9625669667109801, 0.9626087700164714, 0.9627185530812865, 0.9627553665939765, 0.9626804828601092, 0.9628216065582068, 0.9628616937282463, 0.9628444257629837, 0.9629898123106809, 0.9629911820928948, 0.9630546912405011, 0.9631042611650217, 0.9631674528363954, 0.9631368755824474, 0.9632146241686524, 0.9633248828748316, 0.9633501684691305, 0.9633573369348365, 0.9634662827586741, 0.9634978299582805, 0.963596494393728, 0.9635466874955462, 0.9635794251367134, 0.9636239905203047, 0.9636417511954694, 0.9636447508949524, 0.9637077531183651, 0.9636410852733591, 0.9636699027738396, 0.9637668816662358, 0.9636911598372522, 0.9637610265526476, 0.963811444373526, 0.9638031131759418, 0.9638737040158812, 0.9638800612135436, 0.9638780362998383, 0.9639623135449296, 0.96391342065344, 0.9639449801811149, 0.9639330809686358, 0.9639622585739872, 0.9639970921931985, 0.9640374458260373, 0.9639973090447758, 0.9640398446318356, 0.9640284583154031, 0.9639983583256827, 0.964062100923628, 0.9641182212448643, 0.964158090666481, 0.9641607009356649], 'mDice': [0.014577207551676987, 0.0330982387721172, 0.04925765000205422, 0.06472222339820116, 0.08641107985849936, 0.11785056072607342, 0.15984496812006724, 0.20226655988205525, 0.24739132839532407, 0.2853885052744802, 0.3186829672925706, 0.34790171698849726, 0.37538417681592556, 0.39842583514182356, 0.42379227278837306, 0.44864774608358665, 0.47455764179130655, 0.49667470525849655, 0.5128901961960427, 0.527018296311458, 0.539603661218178, 0.5498197788992332, 0.5603577537470568, 0.5682619621909146, 0.5754454044857827, 0.5826986444745225, 0.5871664185796742, 0.5943318333237445, 0.5984676325622993, 0.6036742475939901, 0.608305732731834, 0.6101946841355067, 0.6152667342363749, 0.6178426480048421, 0.6186345572442578, 0.6242449576213532, 0.6253406270922071, 0.6282449806821297, 0.6305920972099787, 0.631990805656209, 0.6344922062304073, 0.6363292220229888, 0.6371705153477001, 0.6384307904405186, 0.6411379769547674, 0.6424641118631574, 0.6445695291648539, 0.6466452786496525, 0.6475753059941258, 0.6484155510771323, 0.6508281156260557, 0.651219239689326, 0.6520691259481869, 0.6534779143484333, 0.6544783282299899, 0.6560145564784803, 0.6567311313262213, 0.6576268283669409, 0.6581057552110332, 0.6593140667837788, 0.6606877962786172, 0.6604911263970734, 0.6615172354039583, 0.6618542206979237, 0.6636743333563475, 0.6637390139124574, 0.6643645616058294, 0.6654807339285165, 0.665447172143165, 0.6659316308449412, 0.6671289069387205, 0.6673334686133182, 0.6672470892617376, 0.6685680579692161, 0.6691834768803102, 0.6696854606430941, 0.6702065063470982, 0.6720870001264253, 0.6718808397960344, 0.6729669781681573, 0.6738867246723129, 0.6737126857789684, 0.6758838256219135, 0.6747930033667605, 0.6760498371063339, 0.6763382315037784, 0.6766574039418229, 0.6768052616195118, 0.6769785011458118, 0.677496527946448, 0.6775937983634963, 0.6783492554264761, 0.6786689580070508, 0.6787755998487202, 0.6799192935306644, 0.6796872497658357, 0.6802824380818033, 0.6798431712387569, 0.6800422867613702, 0.6820072760182233, 0.6816014349318246, 0.6815198806310457, 0.6809904441390483, 0.6822097528684046, 0.6819983021311011, 0.6828965900307029, 0.6828544263712171, 0.6833500886891604, 0.6833604977784021, 0.6828103910376242, 0.6836958368908741, 0.6840158384484609, 0.6840103426140762, 0.684188568338677]}
predicting test subjects:   0%|          | 0/15 [00:00<?, ?it/s]predicting test subjects:   7%|▋         | 1/15 [00:03<00:43,  3.09s/it]predicting test subjects:  13%|█▎        | 2/15 [00:05<00:39,  3.03s/it]predicting test subjects:  20%|██        | 3/15 [00:08<00:35,  2.98s/it]predicting test subjects:  27%|██▋       | 4/15 [00:11<00:32,  2.94s/it]predicting test subjects:  33%|███▎      | 5/15 [00:15<00:31,  3.15s/it]predicting test subjects:  40%|████      | 6/15 [00:18<00:29,  3.28s/it]predicting test subjects:  47%|████▋     | 7/15 [00:20<00:23,  2.91s/it]predicting test subjects:  53%|█████▎    | 8/15 [00:24<00:21,  3.09s/it]predicting test subjects:  60%|██████    | 9/15 [00:27<00:17,  2.96s/it]predicting test subjects:  67%|██████▋   | 10/15 [00:29<00:13,  2.77s/it]predicting test subjects:  73%|███████▎  | 11/15 [00:31<00:10,  2.68s/it]predicting test subjects:  80%|████████  | 12/15 [00:35<00:08,  2.81s/it]predicting test subjects:  87%|████████▋ | 13/15 [00:38<00:05,  2.86s/it]predicting test subjects:  93%|█████████▎| 14/15 [00:40<00:02,  2.86s/it]predicting test subjects: 100%|██████████| 15/15 [00:44<00:00,  3.00s/it]
predicting train subjects:   0%|          | 0/532 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/532 [00:04<35:43,  4.04s/it]predicting train subjects:   0%|          | 2/532 [00:06<31:34,  3.57s/it]predicting train subjects:   1%|          | 3/532 [00:09<29:44,  3.37s/it]predicting train subjects:   1%|          | 4/532 [00:12<27:59,  3.18s/it]predicting train subjects:   1%|          | 5/532 [00:14<26:38,  3.03s/it]predicting train subjects:   1%|          | 6/532 [00:17<25:58,  2.96s/it]predicting train subjects:   1%|▏         | 7/532 [00:20<26:47,  3.06s/it]predicting train subjects:   2%|▏         | 8/532 [00:23<25:04,  2.87s/it]predicting train subjects:   2%|▏         | 9/532 [00:26<26:39,  3.06s/it]predicting train subjects:   2%|▏         | 10/532 [00:29<25:56,  2.98s/it]predicting train subjects:   2%|▏         | 11/532 [00:32<24:37,  2.84s/it]predicting train subjects:   2%|▏         | 12/532 [00:35<26:09,  3.02s/it]predicting train subjects:   2%|▏         | 13/532 [00:38<26:57,  3.12s/it]predicting train subjects:   3%|▎         | 14/532 [00:41<24:42,  2.86s/it]predicting train subjects:   3%|▎         | 15/532 [00:44<25:37,  2.97s/it]predicting train subjects:   3%|▎         | 16/532 [00:48<27:47,  3.23s/it]predicting train subjects:   3%|▎         | 17/532 [00:50<25:42,  3.00s/it]predicting train subjects:   3%|▎         | 18/532 [00:53<24:38,  2.88s/it]predicting train subjects:   4%|▎         | 19/532 [00:55<21:56,  2.57s/it]predicting train subjects:   4%|▍         | 20/532 [00:58<22:52,  2.68s/it]predicting train subjects:   4%|▍         | 21/532 [01:00<23:17,  2.73s/it]predicting train subjects:   4%|▍         | 22/532 [01:03<23:50,  2.81s/it]predicting train subjects:   4%|▍         | 23/532 [01:06<23:46,  2.80s/it]predicting train subjects:   5%|▍         | 24/532 [01:09<23:25,  2.77s/it]predicting train subjects:   5%|▍         | 25/532 [01:12<24:42,  2.92s/it]predicting train subjects:   5%|▍         | 26/532 [01:15<23:38,  2.80s/it]predicting train subjects:   5%|▌         | 27/532 [01:18<23:44,  2.82s/it]predicting train subjects:   5%|▌         | 28/532 [01:20<23:45,  2.83s/it]predicting train subjects:   5%|▌         | 29/532 [01:23<23:33,  2.81s/it]predicting train subjects:   6%|▌         | 30/532 [01:25<21:01,  2.51s/it]predicting train subjects:   6%|▌         | 31/532 [01:27<20:21,  2.44s/it]predicting train subjects:   6%|▌         | 32/532 [01:29<19:41,  2.36s/it]predicting train subjects:   6%|▌         | 33/532 [01:31<18:30,  2.23s/it]predicting train subjects:   6%|▋         | 34/532 [01:34<19:21,  2.33s/it]predicting train subjects:   7%|▋         | 35/532 [01:36<18:50,  2.28s/it]predicting train subjects:   7%|▋         | 36/532 [01:39<19:07,  2.31s/it]predicting train subjects:   7%|▋         | 37/532 [01:41<18:35,  2.25s/it]predicting train subjects:   7%|▋         | 38/532 [01:43<18:34,  2.26s/it]predicting train subjects:   7%|▋         | 39/532 [01:45<18:22,  2.24s/it]predicting train subjects:   8%|▊         | 40/532 [01:47<17:48,  2.17s/it]predicting train subjects:   8%|▊         | 41/532 [01:49<18:00,  2.20s/it]predicting train subjects:   8%|▊         | 42/532 [01:52<18:13,  2.23s/it]predicting train subjects:   8%|▊         | 43/532 [01:53<17:03,  2.09s/it]predicting train subjects:   8%|▊         | 44/532 [01:55<16:20,  2.01s/it]predicting train subjects:   8%|▊         | 45/532 [01:57<16:29,  2.03s/it]predicting train subjects:   9%|▊         | 46/532 [02:00<16:54,  2.09s/it]predicting train subjects:   9%|▉         | 47/532 [02:02<18:24,  2.28s/it]predicting train subjects:   9%|▉         | 48/532 [02:05<18:39,  2.31s/it]predicting train subjects:   9%|▉         | 49/532 [02:07<18:00,  2.24s/it]predicting train subjects:   9%|▉         | 50/532 [02:09<18:27,  2.30s/it]predicting train subjects:  10%|▉         | 51/532 [02:11<18:04,  2.25s/it]predicting train subjects:  10%|▉         | 52/532 [02:14<17:55,  2.24s/it]predicting train subjects:  10%|▉         | 53/532 [02:16<17:27,  2.19s/it]predicting train subjects:  10%|█         | 54/532 [02:18<18:09,  2.28s/it]predicting train subjects:  10%|█         | 55/532 [02:20<18:21,  2.31s/it]predicting train subjects:  11%|█         | 56/532 [02:23<17:54,  2.26s/it]predicting train subjects:  11%|█         | 57/532 [02:25<17:37,  2.23s/it]predicting train subjects:  11%|█         | 58/532 [02:27<18:00,  2.28s/it]predicting train subjects:  11%|█         | 59/532 [02:30<18:52,  2.39s/it]predicting train subjects:  11%|█▏        | 60/532 [02:32<17:36,  2.24s/it]predicting train subjects:  11%|█▏        | 61/532 [02:34<17:00,  2.17s/it]predicting train subjects:  12%|█▏        | 62/532 [02:36<17:50,  2.28s/it]predicting train subjects:  12%|█▏        | 63/532 [02:39<18:28,  2.36s/it]predicting train subjects:  12%|█▏        | 64/532 [02:41<17:33,  2.25s/it]predicting train subjects:  12%|█▏        | 65/532 [02:43<17:34,  2.26s/it]predicting train subjects:  12%|█▏        | 66/532 [02:46<18:21,  2.36s/it]predicting train subjects:  13%|█▎        | 67/532 [02:48<19:04,  2.46s/it]predicting train subjects:  13%|█▎        | 68/532 [02:51<19:02,  2.46s/it]predicting train subjects:  13%|█▎        | 69/532 [02:53<18:18,  2.37s/it]predicting train subjects:  13%|█▎        | 70/532 [02:55<17:24,  2.26s/it]predicting train subjects:  13%|█▎        | 71/532 [02:57<16:48,  2.19s/it]predicting train subjects:  14%|█▎        | 72/532 [02:59<16:21,  2.13s/it]predicting train subjects:  14%|█▎        | 73/532 [03:02<17:33,  2.30s/it]predicting train subjects:  14%|█▍        | 74/532 [03:05<18:46,  2.46s/it]predicting train subjects:  14%|█▍        | 75/532 [03:08<20:46,  2.73s/it]predicting train subjects:  14%|█▍        | 76/532 [03:10<19:23,  2.55s/it]predicting train subjects:  14%|█▍        | 77/532 [03:12<18:55,  2.49s/it]predicting train subjects:  15%|█▍        | 78/532 [03:15<18:25,  2.44s/it]predicting train subjects:  15%|█▍        | 79/532 [03:17<17:51,  2.37s/it]predicting train subjects:  15%|█▌        | 80/532 [03:19<17:30,  2.32s/it]predicting train subjects:  15%|█▌        | 81/532 [03:21<17:29,  2.33s/it]predicting train subjects:  15%|█▌        | 82/532 [03:24<17:20,  2.31s/it]predicting train subjects:  16%|█▌        | 83/532 [03:26<16:46,  2.24s/it]predicting train subjects:  16%|█▌        | 84/532 [03:28<16:11,  2.17s/it]predicting train subjects:  16%|█▌        | 85/532 [03:30<16:03,  2.16s/it]predicting train subjects:  16%|█▌        | 86/532 [03:32<15:17,  2.06s/it]predicting train subjects:  16%|█▋        | 87/532 [03:34<15:07,  2.04s/it]predicting train subjects:  17%|█▋        | 88/532 [03:36<14:58,  2.02s/it]predicting train subjects:  17%|█▋        | 89/532 [03:38<14:43,  1.99s/it]predicting train subjects:  17%|█▋        | 90/532 [03:40<15:09,  2.06s/it]predicting train subjects:  17%|█▋        | 91/532 [03:42<15:26,  2.10s/it]predicting train subjects:  17%|█▋        | 92/532 [03:44<15:30,  2.12s/it]predicting train subjects:  17%|█▋        | 93/532 [03:47<15:50,  2.16s/it]predicting train subjects:  18%|█▊        | 94/532 [03:49<15:54,  2.18s/it]predicting train subjects:  18%|█▊        | 95/532 [03:51<16:57,  2.33s/it]predicting train subjects:  18%|█▊        | 96/532 [03:54<16:57,  2.33s/it]predicting train subjects:  18%|█▊        | 97/532 [03:56<17:02,  2.35s/it]predicting train subjects:  18%|█▊        | 98/532 [03:59<17:05,  2.36s/it]predicting train subjects:  19%|█▊        | 99/532 [04:01<16:29,  2.29s/it]predicting train subjects:  19%|█▉        | 100/532 [04:03<16:07,  2.24s/it]predicting train subjects:  19%|█▉        | 101/532 [04:04<14:46,  2.06s/it]predicting train subjects:  19%|█▉        | 102/532 [04:06<13:46,  1.92s/it]predicting train subjects:  19%|█▉        | 103/532 [04:08<13:15,  1.86s/it]predicting train subjects:  20%|█▉        | 104/532 [04:09<12:48,  1.80s/it]predicting train subjects:  20%|█▉        | 105/532 [04:11<12:35,  1.77s/it]predicting train subjects:  20%|█▉        | 106/532 [04:13<12:23,  1.74s/it]predicting train subjects:  20%|██        | 107/532 [04:14<12:07,  1.71s/it]predicting train subjects:  20%|██        | 108/532 [04:16<12:04,  1.71s/it]predicting train subjects:  20%|██        | 109/532 [04:18<11:52,  1.68s/it]predicting train subjects:  21%|██        | 110/532 [04:19<11:35,  1.65s/it]predicting train subjects:  21%|██        | 111/532 [04:21<11:27,  1.63s/it]predicting train subjects:  21%|██        | 112/532 [04:22<11:17,  1.61s/it]predicting train subjects:  21%|██        | 113/532 [04:24<11:43,  1.68s/it]predicting train subjects:  21%|██▏       | 114/532 [04:26<12:03,  1.73s/it]predicting train subjects:  22%|██▏       | 115/532 [04:28<12:27,  1.79s/it]predicting train subjects:  22%|██▏       | 116/532 [04:30<12:34,  1.81s/it]predicting train subjects:  22%|██▏       | 117/532 [04:32<12:48,  1.85s/it]predicting train subjects:  22%|██▏       | 118/532 [04:34<12:48,  1.86s/it]predicting train subjects:  22%|██▏       | 119/532 [04:35<12:34,  1.83s/it]predicting train subjects:  23%|██▎       | 120/532 [04:37<12:42,  1.85s/it]predicting train subjects:  23%|██▎       | 121/532 [04:39<12:38,  1.84s/it]predicting train subjects:  23%|██▎       | 122/532 [04:41<12:35,  1.84s/it]predicting train subjects:  23%|██▎       | 123/532 [04:43<12:28,  1.83s/it]predicting train subjects:  23%|██▎       | 124/532 [04:45<12:20,  1.81s/it]predicting train subjects:  23%|██▎       | 125/532 [04:47<12:41,  1.87s/it]predicting train subjects:  24%|██▎       | 126/532 [04:49<12:56,  1.91s/it]predicting train subjects:  24%|██▍       | 127/532 [04:51<13:08,  1.95s/it]predicting train subjects:  24%|██▍       | 128/532 [04:53<13:11,  1.96s/it]predicting train subjects:  24%|██▍       | 129/532 [04:55<13:11,  1.96s/it]predicting train subjects:  24%|██▍       | 130/532 [04:57<13:36,  2.03s/it]predicting train subjects:  25%|██▍       | 131/532 [04:59<14:20,  2.15s/it]predicting train subjects:  25%|██▍       | 132/532 [05:02<14:31,  2.18s/it]predicting train subjects:  25%|██▌       | 133/532 [05:04<14:33,  2.19s/it]predicting train subjects:  25%|██▌       | 134/532 [05:06<14:46,  2.23s/it]predicting train subjects:  25%|██▌       | 135/532 [05:08<14:53,  2.25s/it]predicting train subjects:  26%|██▌       | 136/532 [05:11<14:53,  2.26s/it]predicting train subjects:  26%|██▌       | 137/532 [05:13<14:57,  2.27s/it]predicting train subjects:  26%|██▌       | 138/532 [05:15<14:53,  2.27s/it]predicting train subjects:  26%|██▌       | 139/532 [05:17<14:46,  2.26s/it]predicting train subjects:  26%|██▋       | 140/532 [05:20<14:46,  2.26s/it]predicting train subjects:  27%|██▋       | 141/532 [05:22<14:43,  2.26s/it]predicting train subjects:  27%|██▋       | 142/532 [05:24<14:45,  2.27s/it]predicting train subjects:  27%|██▋       | 143/532 [05:26<13:30,  2.08s/it]predicting train subjects:  27%|██▋       | 144/532 [05:28<12:49,  1.98s/it]predicting train subjects:  27%|██▋       | 145/532 [05:29<12:19,  1.91s/it]predicting train subjects:  27%|██▋       | 146/532 [05:31<11:57,  1.86s/it]predicting train subjects:  28%|██▊       | 147/532 [05:33<11:41,  1.82s/it]predicting train subjects:  28%|██▊       | 148/532 [05:34<11:18,  1.77s/it]predicting train subjects:  28%|██▊       | 149/532 [05:36<11:18,  1.77s/it]predicting train subjects:  28%|██▊       | 150/532 [05:38<11:19,  1.78s/it]predicting train subjects:  28%|██▊       | 151/532 [05:40<11:22,  1.79s/it]predicting train subjects:  29%|██▊       | 152/532 [05:42<11:25,  1.80s/it]predicting train subjects:  29%|██▉       | 153/532 [05:44<11:26,  1.81s/it]predicting train subjects:  29%|██▉       | 154/532 [05:46<11:43,  1.86s/it]predicting train subjects:  29%|██▉       | 155/532 [05:48<12:48,  2.04s/it]predicting train subjects:  29%|██▉       | 156/532 [05:50<13:12,  2.11s/it]predicting train subjects:  30%|██▉       | 157/532 [05:53<13:27,  2.15s/it]predicting train subjects:  30%|██▉       | 158/532 [05:55<13:41,  2.20s/it]predicting train subjects:  30%|██▉       | 159/532 [05:57<13:53,  2.24s/it]predicting train subjects:  30%|███       | 160/532 [05:59<13:53,  2.24s/it]predicting train subjects:  30%|███       | 161/532 [06:01<13:03,  2.11s/it]predicting train subjects:  30%|███       | 162/532 [06:03<12:36,  2.04s/it]predicting train subjects:  31%|███       | 163/532 [06:05<12:04,  1.96s/it]predicting train subjects:  31%|███       | 164/532 [06:07<11:45,  1.92s/it]predicting train subjects:  31%|███       | 165/532 [06:09<11:41,  1.91s/it]predicting train subjects:  31%|███       | 166/532 [06:10<11:33,  1.90s/it]predicting train subjects:  31%|███▏      | 167/532 [06:12<11:23,  1.87s/it]predicting train subjects:  32%|███▏      | 168/532 [06:14<11:15,  1.86s/it]predicting train subjects:  32%|███▏      | 169/532 [06:16<11:08,  1.84s/it]predicting train subjects:  32%|███▏      | 170/532 [06:18<11:02,  1.83s/it]predicting train subjects:  32%|███▏      | 171/532 [06:19<11:00,  1.83s/it]predicting train subjects:  32%|███▏      | 172/532 [06:21<10:57,  1.83s/it]predicting train subjects:  33%|███▎      | 173/532 [06:23<10:40,  1.78s/it]predicting train subjects:  33%|███▎      | 174/532 [06:25<10:34,  1.77s/it]predicting train subjects:  33%|███▎      | 175/532 [06:26<10:22,  1.75s/it]predicting train subjects:  33%|███▎      | 176/532 [06:28<10:17,  1.73s/it]predicting train subjects:  33%|███▎      | 177/532 [06:30<10:17,  1.74s/it]predicting train subjects:  33%|███▎      | 178/532 [06:32<10:12,  1.73s/it]predicting train subjects:  34%|███▎      | 179/532 [06:33<10:05,  1.72s/it]predicting train subjects:  34%|███▍      | 180/532 [06:35<10:04,  1.72s/it]predicting train subjects:  34%|███▍      | 181/532 [06:37<09:59,  1.71s/it]predicting train subjects:  34%|███▍      | 182/532 [06:38<10:03,  1.73s/it]predicting train subjects:  34%|███▍      | 183/532 [06:40<10:06,  1.74s/it]predicting train subjects:  35%|███▍      | 184/532 [06:42<10:06,  1.74s/it]predicting train subjects:  35%|███▍      | 185/532 [06:44<09:57,  1.72s/it]predicting train subjects:  35%|███▍      | 186/532 [06:45<09:49,  1.70s/it]predicting train subjects:  35%|███▌      | 187/532 [06:47<09:48,  1.71s/it]predicting train subjects:  35%|███▌      | 188/532 [06:49<09:45,  1.70s/it]predicting train subjects:  36%|███▌      | 189/532 [06:50<09:44,  1.70s/it]predicting train subjects:  36%|███▌      | 190/532 [06:52<09:38,  1.69s/it]predicting train subjects:  36%|███▌      | 191/532 [06:54<10:37,  1.87s/it]predicting train subjects:  36%|███▌      | 192/532 [06:57<11:17,  1.99s/it]predicting train subjects:  36%|███▋      | 193/532 [06:59<11:40,  2.07s/it]predicting train subjects:  36%|███▋      | 194/532 [07:01<11:59,  2.13s/it]predicting train subjects:  37%|███▋      | 195/532 [07:03<12:08,  2.16s/it]predicting train subjects:  37%|███▋      | 196/532 [07:06<12:23,  2.21s/it]predicting train subjects:  37%|███▋      | 197/532 [07:08<11:56,  2.14s/it]predicting train subjects:  37%|███▋      | 198/532 [07:10<11:38,  2.09s/it]predicting train subjects:  37%|███▋      | 199/532 [07:12<11:27,  2.06s/it]predicting train subjects:  38%|███▊      | 200/532 [07:14<11:21,  2.05s/it]predicting train subjects:  38%|███▊      | 201/532 [07:16<11:14,  2.04s/it]predicting train subjects:  38%|███▊      | 202/532 [07:18<11:06,  2.02s/it]predicting train subjects:  38%|███▊      | 203/532 [07:19<10:36,  1.94s/it]predicting train subjects:  38%|███▊      | 204/532 [07:21<10:16,  1.88s/it]predicting train subjects:  39%|███▊      | 205/532 [07:23<10:06,  1.85s/it]predicting train subjects:  39%|███▊      | 206/532 [07:25<09:55,  1.83s/it]predicting train subjects:  39%|███▉      | 207/532 [07:27<09:53,  1.83s/it]predicting train subjects:  39%|███▉      | 208/532 [07:28<09:42,  1.80s/it]predicting train subjects:  39%|███▉      | 209/532 [07:30<09:22,  1.74s/it]predicting train subjects:  39%|███▉      | 210/532 [07:31<09:06,  1.70s/it]predicting train subjects:  40%|███▉      | 211/532 [07:33<08:54,  1.66s/it]predicting train subjects:  40%|███▉      | 212/532 [07:35<08:42,  1.63s/it]predicting train subjects:  40%|████      | 213/532 [07:36<08:29,  1.60s/it]predicting train subjects:  40%|████      | 214/532 [07:38<08:17,  1.56s/it]predicting train subjects:  40%|████      | 215/532 [07:40<09:05,  1.72s/it]predicting train subjects:  41%|████      | 216/532 [07:42<09:42,  1.84s/it]predicting train subjects:  41%|████      | 217/532 [07:44<10:04,  1.92s/it]predicting train subjects:  41%|████      | 218/532 [07:46<10:22,  1.98s/it]predicting train subjects:  41%|████      | 219/532 [07:48<10:29,  2.01s/it]predicting train subjects:  41%|████▏     | 220/532 [07:50<10:48,  2.08s/it]predicting train subjects:  42%|████▏     | 221/532 [07:52<10:01,  1.93s/it]predicting train subjects:  42%|████▏     | 222/532 [07:54<09:34,  1.85s/it]predicting train subjects:  42%|████▏     | 223/532 [07:55<09:13,  1.79s/it]predicting train subjects:  42%|████▏     | 224/532 [07:57<08:59,  1.75s/it]predicting train subjects:  42%|████▏     | 225/532 [07:59<08:40,  1.69s/it]predicting train subjects:  42%|████▏     | 226/532 [08:00<08:29,  1.66s/it]predicting train subjects:  43%|████▎     | 227/532 [08:02<08:17,  1.63s/it]predicting train subjects:  43%|████▎     | 228/532 [08:03<08:02,  1.59s/it]predicting train subjects:  43%|████▎     | 229/532 [08:05<07:47,  1.54s/it]predicting train subjects:  43%|████▎     | 230/532 [08:06<07:43,  1.53s/it]predicting train subjects:  43%|████▎     | 231/532 [08:08<07:33,  1.51s/it]predicting train subjects:  44%|████▎     | 232/532 [08:09<07:29,  1.50s/it]predicting train subjects:  44%|████▍     | 233/532 [08:11<07:55,  1.59s/it]predicting train subjects:  44%|████▍     | 234/532 [08:13<08:09,  1.64s/it]predicting train subjects:  44%|████▍     | 235/532 [08:14<08:16,  1.67s/it]predicting train subjects:  44%|████▍     | 236/532 [08:16<08:13,  1.67s/it]predicting train subjects:  45%|████▍     | 237/532 [08:18<08:17,  1.69s/it]predicting train subjects:  45%|████▍     | 238/532 [08:19<08:15,  1.68s/it]predicting train subjects:  45%|████▍     | 239/532 [08:21<08:34,  1.76s/it]predicting train subjects:  45%|████▌     | 240/532 [08:23<08:43,  1.79s/it]predicting train subjects:  45%|████▌     | 241/532 [08:25<08:48,  1.81s/it]predicting train subjects:  45%|████▌     | 242/532 [08:27<08:48,  1.82s/it]predicting train subjects:  46%|████▌     | 243/532 [08:29<09:00,  1.87s/it]predicting train subjects:  46%|████▌     | 244/532 [08:31<08:57,  1.87s/it]predicting train subjects:  46%|████▌     | 245/532 [08:32<08:19,  1.74s/it]predicting train subjects:  46%|████▌     | 246/532 [08:34<07:58,  1.67s/it]predicting train subjects:  46%|████▋     | 247/532 [08:35<07:46,  1.64s/it]predicting train subjects:  47%|████▋     | 248/532 [08:37<07:36,  1.61s/it]predicting train subjects:  47%|████▋     | 249/532 [08:39<08:09,  1.73s/it]predicting train subjects:  47%|████▋     | 250/532 [08:40<07:48,  1.66s/it]predicting train subjects:  47%|████▋     | 251/532 [08:42<07:34,  1.62s/it]predicting train subjects:  47%|████▋     | 252/532 [08:43<07:26,  1.59s/it]predicting train subjects:  48%|████▊     | 253/532 [08:45<07:24,  1.59s/it]predicting train subjects:  48%|████▊     | 254/532 [08:47<07:22,  1.59s/it]predicting train subjects:  48%|████▊     | 255/532 [08:48<07:26,  1.61s/it]predicting train subjects:  48%|████▊     | 256/532 [08:50<07:19,  1.59s/it]predicting train subjects:  48%|████▊     | 257/532 [08:52<07:48,  1.71s/it]predicting train subjects:  48%|████▊     | 258/532 [08:54<08:10,  1.79s/it]predicting train subjects:  49%|████▊     | 259/532 [08:56<08:21,  1.84s/it]predicting train subjects:  49%|████▉     | 260/532 [08:58<08:38,  1.90s/it]predicting train subjects:  49%|████▉     | 261/532 [09:00<08:36,  1.91s/it]predicting train subjects:  49%|████▉     | 262/532 [09:02<08:47,  1.95s/it]predicting train subjects:  49%|████▉     | 263/532 [09:03<08:07,  1.81s/it]predicting train subjects:  50%|████▉     | 264/532 [09:05<07:35,  1.70s/it]predicting train subjects:  50%|████▉     | 265/532 [09:06<07:15,  1.63s/it]predicting train subjects:  50%|█████     | 266/532 [09:08<07:00,  1.58s/it]predicting train subjects:  50%|█████     | 267/532 [09:09<06:52,  1.56s/it]predicting train subjects:  50%|█████     | 268/532 [09:11<06:45,  1.54s/it]predicting train subjects:  51%|█████     | 269/532 [09:12<07:05,  1.62s/it]predicting train subjects:  51%|█████     | 270/532 [09:14<07:11,  1.65s/it]predicting train subjects:  51%|█████     | 271/532 [09:16<07:18,  1.68s/it]predicting train subjects:  51%|█████     | 272/532 [09:18<07:27,  1.72s/it]predicting train subjects:  51%|█████▏    | 273/532 [09:19<07:34,  1.76s/it]predicting train subjects:  52%|█████▏    | 274/532 [09:21<07:36,  1.77s/it]predicting train subjects:  52%|█████▏    | 275/532 [09:23<08:07,  1.90s/it]predicting train subjects:  52%|█████▏    | 276/532 [09:26<08:28,  1.99s/it]predicting train subjects:  52%|█████▏    | 277/532 [09:28<08:48,  2.07s/it]predicting train subjects:  52%|█████▏    | 278/532 [09:30<09:03,  2.14s/it]predicting train subjects:  52%|█████▏    | 279/532 [09:33<09:12,  2.18s/it]predicting train subjects:  53%|█████▎    | 280/532 [09:35<09:14,  2.20s/it]predicting train subjects:  53%|█████▎    | 281/532 [09:37<08:58,  2.15s/it]predicting train subjects:  53%|█████▎    | 282/532 [09:39<08:45,  2.10s/it]predicting train subjects:  53%|█████▎    | 283/532 [09:41<09:00,  2.17s/it]predicting train subjects:  53%|█████▎    | 284/532 [09:43<08:48,  2.13s/it]predicting train subjects:  54%|█████▎    | 285/532 [09:45<08:36,  2.09s/it]predicting train subjects:  54%|█████▍    | 286/532 [09:47<08:27,  2.06s/it]predicting train subjects:  54%|█████▍    | 287/532 [09:49<07:55,  1.94s/it]predicting train subjects:  54%|█████▍    | 288/532 [09:50<07:34,  1.86s/it]predicting train subjects:  54%|█████▍    | 289/532 [09:52<07:18,  1.81s/it]predicting train subjects:  55%|█████▍    | 290/532 [09:54<07:11,  1.78s/it]predicting train subjects:  55%|█████▍    | 291/532 [09:56<07:01,  1.75s/it]predicting train subjects:  55%|█████▍    | 292/532 [09:57<06:58,  1.74s/it]predicting train subjects:  55%|█████▌    | 293/532 [09:59<07:04,  1.78s/it]predicting train subjects:  55%|█████▌    | 294/532 [10:01<07:02,  1.77s/it]predicting train subjects:  55%|█████▌    | 295/532 [10:03<07:00,  1.77s/it]predicting train subjects:  56%|█████▌    | 296/532 [10:04<06:58,  1.77s/it]predicting train subjects:  56%|█████▌    | 297/532 [10:06<07:01,  1.79s/it]predicting train subjects:  56%|█████▌    | 298/532 [10:08<07:00,  1.80s/it]predicting train subjects:  56%|█████▌    | 299/532 [10:10<06:37,  1.71s/it]predicting train subjects:  56%|█████▋    | 300/532 [10:11<06:21,  1.64s/it]predicting train subjects:  57%|█████▋    | 301/532 [10:13<06:14,  1.62s/it]predicting train subjects:  57%|█████▋    | 302/532 [10:14<06:03,  1.58s/it]predicting train subjects:  57%|█████▋    | 303/532 [10:16<05:57,  1.56s/it]predicting train subjects:  57%|█████▋    | 304/532 [10:17<05:53,  1.55s/it]predicting train subjects:  57%|█████▋    | 305/532 [10:19<06:34,  1.74s/it]predicting train subjects:  58%|█████▊    | 306/532 [10:22<06:59,  1.86s/it]predicting train subjects:  58%|█████▊    | 307/532 [10:24<07:18,  1.95s/it]predicting train subjects:  58%|█████▊    | 308/532 [10:26<07:31,  2.01s/it]predicting train subjects:  58%|█████▊    | 309/532 [10:28<07:41,  2.07s/it]predicting train subjects:  58%|█████▊    | 310/532 [10:30<07:45,  2.10s/it]predicting train subjects:  58%|█████▊    | 311/532 [10:33<08:33,  2.33s/it]predicting train subjects:  59%|█████▊    | 312/532 [10:36<09:08,  2.49s/it]predicting train subjects:  59%|█████▉    | 313/532 [10:39<09:30,  2.61s/it]predicting train subjects:  59%|█████▉    | 314/532 [10:42<09:43,  2.68s/it]predicting train subjects:  59%|█████▉    | 315/532 [10:44<09:51,  2.72s/it]predicting train subjects:  59%|█████▉    | 316/532 [10:47<09:57,  2.76s/it]predicting train subjects:  60%|█████▉    | 317/532 [10:49<08:44,  2.44s/it]predicting train subjects:  60%|█████▉    | 318/532 [10:51<07:53,  2.21s/it]predicting train subjects:  60%|█████▉    | 319/532 [10:52<07:20,  2.07s/it]predicting train subjects:  60%|██████    | 320/532 [10:54<06:55,  1.96s/it]predicting train subjects:  60%|██████    | 321/532 [10:56<06:36,  1.88s/it]predicting train subjects:  61%|██████    | 322/532 [10:58<06:24,  1.83s/it]predicting train subjects:  61%|██████    | 323/532 [11:00<06:51,  1.97s/it]predicting train subjects:  61%|██████    | 324/532 [11:02<07:08,  2.06s/it]predicting train subjects:  61%|██████    | 325/532 [11:04<07:18,  2.12s/it]predicting train subjects:  61%|██████▏   | 326/532 [11:07<07:23,  2.15s/it]predicting train subjects:  61%|██████▏   | 327/532 [11:09<07:33,  2.21s/it]predicting train subjects:  62%|██████▏   | 328/532 [11:11<07:35,  2.23s/it]predicting train subjects:  62%|██████▏   | 329/532 [11:13<07:11,  2.12s/it]predicting train subjects:  62%|██████▏   | 330/532 [11:15<06:48,  2.02s/it]predicting train subjects:  62%|██████▏   | 331/532 [11:17<06:29,  1.94s/it]predicting train subjects:  62%|██████▏   | 332/532 [11:18<06:16,  1.88s/it]predicting train subjects:  63%|██████▎   | 333/532 [11:20<06:09,  1.86s/it]predicting train subjects:  63%|██████▎   | 334/532 [11:22<06:01,  1.83s/it]predicting train subjects:  63%|██████▎   | 335/532 [11:24<06:07,  1.87s/it]predicting train subjects:  63%|██████▎   | 336/532 [11:26<06:10,  1.89s/it]predicting train subjects:  63%|██████▎   | 337/532 [11:28<06:12,  1.91s/it]predicting train subjects:  64%|██████▎   | 338/532 [11:30<06:09,  1.91s/it]predicting train subjects:  64%|██████▎   | 339/532 [11:32<06:10,  1.92s/it]predicting train subjects:  64%|██████▍   | 340/532 [11:34<06:14,  1.95s/it]predicting train subjects:  64%|██████▍   | 341/532 [11:35<05:49,  1.83s/it]predicting train subjects:  64%|██████▍   | 342/532 [11:37<05:35,  1.76s/it]predicting train subjects:  64%|██████▍   | 343/532 [11:38<05:23,  1.71s/it]predicting train subjects:  65%|██████▍   | 344/532 [11:40<05:16,  1.68s/it]predicting train subjects:  65%|██████▍   | 345/532 [11:42<05:10,  1.66s/it]predicting train subjects:  65%|██████▌   | 346/532 [11:43<05:06,  1.65s/it]predicting train subjects:  65%|██████▌   | 347/532 [11:45<05:10,  1.68s/it]predicting train subjects:  65%|██████▌   | 348/532 [11:47<05:15,  1.71s/it]predicting train subjects:  66%|██████▌   | 349/532 [11:49<05:20,  1.75s/it]predicting train subjects:  66%|██████▌   | 350/532 [11:50<05:23,  1.78s/it]predicting train subjects:  66%|██████▌   | 351/532 [11:52<05:23,  1.79s/it]predicting train subjects:  66%|██████▌   | 352/532 [11:54<05:21,  1.79s/it]predicting train subjects:  66%|██████▋   | 353/532 [11:56<05:16,  1.77s/it]predicting train subjects:  67%|██████▋   | 354/532 [11:58<05:14,  1.77s/it]predicting train subjects:  67%|██████▋   | 355/532 [11:59<05:09,  1.75s/it]predicting train subjects:  67%|██████▋   | 356/532 [12:01<05:13,  1.78s/it]predicting train subjects:  67%|██████▋   | 357/532 [12:03<05:12,  1.78s/it]predicting train subjects:  67%|██████▋   | 358/532 [12:05<05:11,  1.79s/it]predicting train subjects:  67%|██████▋   | 359/532 [12:06<04:57,  1.72s/it]predicting train subjects:  68%|██████▊   | 360/532 [12:08<04:43,  1.65s/it]predicting train subjects:  68%|██████▊   | 361/532 [12:09<04:33,  1.60s/it]predicting train subjects:  68%|██████▊   | 362/532 [12:11<04:24,  1.56s/it]predicting train subjects:  68%|██████▊   | 363/532 [12:12<04:21,  1.55s/it]predicting train subjects:  68%|██████▊   | 364/532 [12:14<04:22,  1.57s/it]predicting train subjects:  69%|██████▊   | 365/532 [12:15<04:22,  1.57s/it]predicting train subjects:  69%|██████▉   | 366/532 [12:17<04:23,  1.59s/it]predicting train subjects:  69%|██████▉   | 367/532 [12:19<04:26,  1.61s/it]predicting train subjects:  69%|██████▉   | 368/532 [12:20<04:24,  1.61s/it]predicting train subjects:  69%|██████▉   | 369/532 [12:22<04:23,  1.62s/it]predicting train subjects:  70%|██████▉   | 370/532 [12:24<04:21,  1.61s/it]predicting train subjects:  70%|██████▉   | 371/532 [12:26<04:49,  1.80s/it]predicting train subjects:  70%|██████▉   | 372/532 [12:28<05:08,  1.93s/it]predicting train subjects:  70%|███████   | 373/532 [12:30<05:16,  1.99s/it]predicting train subjects:  70%|███████   | 374/532 [12:32<05:21,  2.03s/it]predicting train subjects:  70%|███████   | 375/532 [12:34<05:20,  2.04s/it]predicting train subjects:  71%|███████   | 376/532 [12:37<05:27,  2.10s/it]predicting train subjects:  71%|███████   | 377/532 [12:38<05:10,  2.00s/it]predicting train subjects:  71%|███████   | 378/532 [12:40<04:59,  1.95s/it]predicting train subjects:  71%|███████   | 379/532 [12:42<04:52,  1.91s/it]predicting train subjects:  71%|███████▏  | 380/532 [12:44<04:45,  1.88s/it]predicting train subjects:  72%|███████▏  | 381/532 [12:46<04:36,  1.83s/it]predicting train subjects:  72%|███████▏  | 382/532 [12:47<04:31,  1.81s/it]predicting train subjects:  72%|███████▏  | 383/532 [12:49<04:30,  1.81s/it]predicting train subjects:  72%|███████▏  | 384/532 [12:51<04:31,  1.84s/it]predicting train subjects:  72%|███████▏  | 385/532 [12:53<04:28,  1.83s/it]predicting train subjects:  73%|███████▎  | 386/532 [12:55<04:25,  1.82s/it]predicting train subjects:  73%|███████▎  | 387/532 [12:56<04:25,  1.83s/it]predicting train subjects:  73%|███████▎  | 388/532 [12:58<04:26,  1.85s/it]predicting train subjects:  73%|███████▎  | 389/532 [13:00<04:27,  1.87s/it]predicting train subjects:  73%|███████▎  | 390/532 [13:02<04:26,  1.88s/it]predicting train subjects:  73%|███████▎  | 391/532 [13:04<04:24,  1.88s/it]predicting train subjects:  74%|███████▎  | 392/532 [13:06<04:26,  1.90s/it]predicting train subjects:  74%|███████▍  | 393/532 [13:08<04:25,  1.91s/it]predicting train subjects:  74%|███████▍  | 394/532 [13:10<04:23,  1.91s/it]predicting train subjects:  74%|███████▍  | 395/532 [13:12<04:25,  1.93s/it]predicting train subjects:  74%|███████▍  | 396/532 [13:14<04:23,  1.94s/it]predicting train subjects:  75%|███████▍  | 397/532 [13:16<04:26,  1.97s/it]predicting train subjects:  75%|███████▍  | 398/532 [13:18<04:27,  1.99s/it]predicting train subjects:  75%|███████▌  | 399/532 [13:20<04:20,  1.96s/it]predicting train subjects:  75%|███████▌  | 400/532 [13:22<04:19,  1.97s/it]predicting train subjects:  75%|███████▌  | 401/532 [13:24<04:21,  1.99s/it]predicting train subjects:  76%|███████▌  | 402/532 [13:26<04:20,  2.00s/it]predicting train subjects:  76%|███████▌  | 403/532 [13:28<04:22,  2.03s/it]predicting train subjects:  76%|███████▌  | 404/532 [13:30<04:25,  2.07s/it]predicting train subjects:  76%|███████▌  | 405/532 [13:32<04:19,  2.04s/it]predicting train subjects:  76%|███████▋  | 406/532 [13:34<04:13,  2.01s/it]predicting train subjects:  77%|███████▋  | 407/532 [13:36<04:01,  1.93s/it]predicting train subjects:  77%|███████▋  | 408/532 [13:38<03:56,  1.91s/it]predicting train subjects:  77%|███████▋  | 409/532 [13:39<03:51,  1.88s/it]predicting train subjects:  77%|███████▋  | 410/532 [13:41<03:49,  1.88s/it]predicting train subjects:  77%|███████▋  | 411/532 [13:43<03:42,  1.84s/it]predicting train subjects:  77%|███████▋  | 412/532 [13:45<03:36,  1.81s/it]predicting train subjects:  78%|███████▊  | 413/532 [13:46<03:30,  1.77s/it]predicting train subjects:  78%|███████▊  | 414/532 [13:48<03:23,  1.73s/it]predicting train subjects:  78%|███████▊  | 415/532 [13:50<03:21,  1.72s/it]predicting train subjects:  78%|███████▊  | 416/532 [13:52<03:20,  1.73s/it]predicting train subjects:  78%|███████▊  | 417/532 [13:53<03:16,  1.71s/it]predicting train subjects:  79%|███████▊  | 418/532 [13:55<03:16,  1.72s/it]predicting train subjects:  79%|███████▉  | 419/532 [13:57<03:22,  1.79s/it]predicting train subjects:  79%|███████▉  | 420/532 [13:59<03:23,  1.82s/it]predicting train subjects:  79%|███████▉  | 421/532 [14:01<03:25,  1.85s/it]predicting train subjects:  79%|███████▉  | 422/532 [14:03<03:26,  1.88s/it]predicting train subjects:  80%|███████▉  | 423/532 [14:05<03:24,  1.88s/it]predicting train subjects:  80%|███████▉  | 424/532 [14:06<03:22,  1.87s/it]predicting train subjects:  80%|███████▉  | 425/532 [14:08<03:22,  1.89s/it]predicting train subjects:  80%|████████  | 426/532 [14:10<03:21,  1.90s/it]predicting train subjects:  80%|████████  | 427/532 [14:12<03:22,  1.93s/it]predicting train subjects:  80%|████████  | 428/532 [14:14<03:21,  1.94s/it]predicting train subjects:  81%|████████  | 429/532 [14:16<03:19,  1.94s/it]predicting train subjects:  81%|████████  | 430/532 [14:18<03:17,  1.94s/it]predicting train subjects:  81%|████████  | 431/532 [14:20<03:21,  2.00s/it]predicting train subjects:  81%|████████  | 432/532 [14:22<03:21,  2.02s/it]predicting train subjects:  81%|████████▏ | 433/532 [14:24<03:22,  2.04s/it]predicting train subjects:  82%|████████▏ | 434/532 [14:27<03:24,  2.09s/it]predicting train subjects:  82%|████████▏ | 435/532 [14:29<03:24,  2.11s/it]predicting train subjects:  82%|████████▏ | 436/532 [14:31<03:23,  2.12s/it]predicting train subjects:  82%|████████▏ | 437/532 [14:33<03:08,  1.98s/it]predicting train subjects:  82%|████████▏ | 438/532 [14:34<02:56,  1.88s/it]predicting train subjects:  83%|████████▎ | 439/532 [14:36<02:48,  1.81s/it]predicting train subjects:  83%|████████▎ | 440/532 [14:37<02:41,  1.75s/it]predicting train subjects:  83%|████████▎ | 441/532 [14:39<02:36,  1.72s/it]predicting train subjects:  83%|████████▎ | 442/532 [14:41<02:32,  1.69s/it]predicting train subjects:  83%|████████▎ | 443/532 [14:42<02:30,  1.70s/it]predicting train subjects:  83%|████████▎ | 444/532 [14:44<02:28,  1.69s/it]predicting train subjects:  84%|████████▎ | 445/532 [14:46<02:25,  1.67s/it]predicting train subjects:  84%|████████▍ | 446/532 [14:47<02:22,  1.66s/it]predicting train subjects:  84%|████████▍ | 447/532 [14:49<02:19,  1.64s/it]predicting train subjects:  84%|████████▍ | 448/532 [14:51<02:16,  1.62s/it]predicting train subjects:  84%|████████▍ | 449/532 [14:52<02:18,  1.67s/it]predicting train subjects:  85%|████████▍ | 450/532 [14:54<02:18,  1.68s/it]predicting train subjects:  85%|████████▍ | 451/532 [14:56<02:17,  1.70s/it]predicting train subjects:  85%|████████▍ | 452/532 [14:57<02:16,  1.70s/it]predicting train subjects:  85%|████████▌ | 453/532 [14:59<02:16,  1.73s/it]predicting train subjects:  85%|████████▌ | 454/532 [15:01<02:14,  1.72s/it]predicting train subjects:  86%|████████▌ | 455/532 [15:03<02:17,  1.78s/it]predicting train subjects:  86%|████████▌ | 456/532 [15:05<02:17,  1.81s/it]predicting train subjects:  86%|████████▌ | 457/532 [15:07<02:18,  1.85s/it]predicting train subjects:  86%|████████▌ | 458/532 [15:09<02:18,  1.87s/it]predicting train subjects:  86%|████████▋ | 459/532 [15:11<02:19,  1.91s/it]predicting train subjects:  86%|████████▋ | 460/532 [15:13<02:18,  1.93s/it]predicting train subjects:  87%|████████▋ | 461/532 [15:15<02:25,  2.04s/it]predicting train subjects:  87%|████████▋ | 462/532 [15:18<02:34,  2.20s/it]predicting train subjects:  87%|████████▋ | 463/532 [15:20<02:33,  2.23s/it]predicting train subjects:  87%|████████▋ | 464/532 [15:22<02:31,  2.22s/it]predicting train subjects:  87%|████████▋ | 465/532 [15:24<02:29,  2.23s/it]predicting train subjects:  88%|████████▊ | 466/532 [15:26<02:27,  2.23s/it]predicting train subjects:  88%|████████▊ | 467/532 [15:28<02:17,  2.12s/it]predicting train subjects:  88%|████████▊ | 468/532 [15:30<02:07,  1.99s/it]predicting train subjects:  88%|████████▊ | 469/532 [15:32<02:01,  1.93s/it]predicting train subjects:  88%|████████▊ | 470/532 [15:34<01:55,  1.86s/it]predicting train subjects:  89%|████████▊ | 471/532 [15:35<01:51,  1.83s/it]predicting train subjects:  89%|████████▊ | 472/532 [15:37<01:47,  1.80s/it]predicting train subjects:  89%|████████▉ | 473/532 [15:39<01:48,  1.84s/it]predicting train subjects:  89%|████████▉ | 474/532 [15:41<01:49,  1.89s/it]predicting train subjects:  89%|████████▉ | 475/532 [15:43<01:50,  1.95s/it]predicting train subjects:  89%|████████▉ | 476/532 [15:45<01:49,  1.96s/it]predicting train subjects:  90%|████████▉ | 477/532 [15:47<01:50,  2.01s/it]predicting train subjects:  90%|████████▉ | 478/532 [15:49<01:48,  2.01s/it]predicting train subjects:  90%|█████████ | 479/532 [15:51<01:41,  1.92s/it]predicting train subjects:  90%|█████████ | 480/532 [15:53<01:36,  1.85s/it]predicting train subjects:  90%|█████████ | 481/532 [15:54<01:32,  1.81s/it]predicting train subjects:  91%|█████████ | 482/532 [15:56<01:29,  1.79s/it]predicting train subjects:  91%|█████████ | 483/532 [15:58<01:26,  1.77s/it]predicting train subjects:  91%|█████████ | 484/532 [15:59<01:24,  1.76s/it]predicting train subjects:  91%|█████████ | 485/532 [16:02<01:30,  1.92s/it]predicting train subjects:  91%|█████████▏| 486/532 [16:04<01:31,  2.00s/it]predicting train subjects:  92%|█████████▏| 487/532 [16:06<01:32,  2.05s/it]predicting train subjects:  92%|█████████▏| 488/532 [16:08<01:31,  2.09s/it]predicting train subjects:  92%|█████████▏| 489/532 [16:10<01:31,  2.13s/it]predicting train subjects:  92%|█████████▏| 490/532 [16:13<01:30,  2.15s/it]predicting train subjects:  92%|█████████▏| 491/532 [16:15<01:24,  2.06s/it]predicting train subjects:  92%|█████████▏| 492/532 [16:16<01:19,  1.99s/it]predicting train subjects:  93%|█████████▎| 493/532 [16:18<01:15,  1.92s/it]predicting train subjects:  93%|█████████▎| 494/532 [16:20<01:11,  1.87s/it]predicting train subjects:  93%|█████████▎| 495/532 [16:22<01:08,  1.86s/it]predicting train subjects:  93%|█████████▎| 496/532 [16:24<01:06,  1.85s/it]predicting train subjects:  93%|█████████▎| 497/532 [16:25<01:05,  1.86s/it]predicting train subjects:  94%|█████████▎| 498/532 [16:27<01:03,  1.87s/it]predicting train subjects:  94%|█████████▍| 499/532 [16:29<01:01,  1.87s/it]predicting train subjects:  94%|█████████▍| 500/532 [16:31<00:59,  1.87s/it]predicting train subjects:  94%|█████████▍| 501/532 [16:33<00:57,  1.86s/it]predicting train subjects:  94%|█████████▍| 502/532 [16:35<00:55,  1.85s/it]predicting train subjects:  95%|█████████▍| 503/532 [16:36<00:52,  1.83s/it]predicting train subjects:  95%|█████████▍| 504/532 [16:38<00:50,  1.81s/it]predicting train subjects:  95%|█████████▍| 505/532 [16:40<00:48,  1.80s/it]predicting train subjects:  95%|█████████▌| 506/532 [16:42<00:46,  1.79s/it]predicting train subjects:  95%|█████████▌| 507/532 [16:43<00:43,  1.76s/it]predicting train subjects:  95%|█████████▌| 508/532 [16:45<00:41,  1.74s/it]predicting train subjects:  96%|█████████▌| 509/532 [16:47<00:42,  1.86s/it]predicting train subjects:  96%|█████████▌| 510/532 [16:49<00:42,  1.94s/it]predicting train subjects:  96%|█████████▌| 511/532 [16:52<00:41,  1.98s/it]predicting train subjects:  96%|█████████▌| 512/532 [16:54<00:41,  2.05s/it]predicting train subjects:  96%|█████████▋| 513/532 [16:56<00:39,  2.08s/it]predicting train subjects:  97%|█████████▋| 514/532 [16:58<00:37,  2.10s/it]predicting train subjects:  97%|█████████▋| 515/532 [17:00<00:34,  2.04s/it]predicting train subjects:  97%|█████████▋| 516/532 [17:02<00:31,  1.96s/it]predicting train subjects:  97%|█████████▋| 517/532 [17:04<00:28,  1.93s/it]predicting train subjects:  97%|█████████▋| 518/532 [17:05<00:26,  1.92s/it]predicting train subjects:  98%|█████████▊| 519/532 [17:07<00:24,  1.88s/it]predicting train subjects:  98%|█████████▊| 520/532 [17:09<00:22,  1.88s/it]predicting train subjects:  98%|█████████▊| 521/532 [17:11<00:20,  1.90s/it]predicting train subjects:  98%|█████████▊| 522/532 [17:13<00:19,  1.94s/it]predicting train subjects:  98%|█████████▊| 523/532 [17:15<00:17,  1.94s/it]predicting train subjects:  98%|█████████▊| 524/532 [17:17<00:15,  1.95s/it]predicting train subjects:  99%|█████████▊| 525/532 [17:19<00:13,  2.00s/it]predicting train subjects:  99%|█████████▉| 526/532 [17:21<00:11,  2.00s/it]predicting train subjects:  99%|█████████▉| 527/532 [17:23<00:09,  1.95s/it]predicting train subjects:  99%|█████████▉| 528/532 [17:25<00:07,  1.92s/it]predicting train subjects:  99%|█████████▉| 529/532 [17:27<00:05,  1.87s/it]predicting train subjects: 100%|█████████▉| 530/532 [17:28<00:03,  1.86s/it]predicting train subjects: 100%|█████████▉| 531/532 [17:30<00:01,  1.84s/it]predicting train subjects: 100%|██████████| 532/532 [17:32<00:00,  1.84s/it]
Loading train:   0%|          | 0/532 [00:00<?, ?it/s]Loading train:   0%|          | 1/532 [00:01<12:13,  1.38s/it]Loading train:   0%|          | 2/532 [00:02<10:47,  1.22s/it]Loading train:   1%|          | 3/532 [00:03<09:59,  1.13s/it]Loading train:   1%|          | 4/532 [00:04<09:29,  1.08s/it]Loading train:   1%|          | 5/532 [00:05<09:29,  1.08s/it]Loading train:   1%|          | 6/532 [00:06<09:09,  1.04s/it]Loading train:   1%|▏         | 7/532 [00:07<09:34,  1.09s/it]Loading train:   2%|▏         | 8/532 [00:08<08:53,  1.02s/it]Loading train:   2%|▏         | 9/532 [00:09<09:14,  1.06s/it]Loading train:   2%|▏         | 10/532 [00:10<09:13,  1.06s/it]Loading train:   2%|▏         | 11/532 [00:11<08:33,  1.01it/s]Loading train:   2%|▏         | 12/532 [00:12<09:03,  1.04s/it]Loading train:   2%|▏         | 13/532 [00:13<08:34,  1.01it/s]Loading train:   3%|▎         | 14/532 [00:14<08:00,  1.08it/s]Loading train:   3%|▎         | 15/532 [00:14<07:58,  1.08it/s]Loading train:   3%|▎         | 16/532 [00:16<08:27,  1.02it/s]Loading train:   3%|▎         | 17/532 [00:17<08:16,  1.04it/s]Loading train:   3%|▎         | 18/532 [00:18<08:24,  1.02it/s]Loading train:   4%|▎         | 19/532 [00:18<08:03,  1.06it/s]Loading train:   4%|▍         | 20/532 [00:19<08:12,  1.04it/s]Loading train:   4%|▍         | 21/532 [00:20<08:30,  1.00it/s]Loading train:   4%|▍         | 22/532 [00:21<08:12,  1.04it/s]Loading train:   4%|▍         | 23/532 [00:22<07:59,  1.06it/s]Loading train:   5%|▍         | 24/532 [00:23<07:44,  1.09it/s]Loading train:   5%|▍         | 25/532 [00:24<08:21,  1.01it/s]Loading train:   5%|▍         | 26/532 [00:25<07:55,  1.06it/s]Loading train:   5%|▌         | 27/532 [00:26<08:51,  1.05s/it]Loading train:   5%|▌         | 28/532 [00:27<08:26,  1.01s/it]Loading train:   5%|▌         | 29/532 [00:28<08:36,  1.03s/it]Loading train:   6%|▌         | 30/532 [00:29<07:50,  1.07it/s]Loading train:   6%|▌         | 31/532 [00:30<07:46,  1.07it/s]Loading train:   6%|▌         | 32/532 [00:31<07:50,  1.06it/s]Loading train:   6%|▌         | 33/532 [00:32<07:35,  1.10it/s]Loading train:   6%|▋         | 34/532 [00:33<07:54,  1.05it/s]Loading train:   7%|▋         | 35/532 [00:34<07:25,  1.12it/s]Loading train:   7%|▋         | 36/532 [00:35<07:32,  1.10it/s]Loading train:   7%|▋         | 37/532 [00:36<07:44,  1.07it/s]Loading train:   7%|▋         | 38/532 [00:37<08:09,  1.01it/s]Loading train:   7%|▋         | 39/532 [00:38<07:58,  1.03it/s]Loading train:   8%|▊         | 40/532 [00:39<07:47,  1.05it/s]Loading train:   8%|▊         | 41/532 [00:40<07:57,  1.03it/s]Loading train:   8%|▊         | 42/532 [00:40<07:49,  1.04it/s]Loading train:   8%|▊         | 43/532 [00:41<07:34,  1.08it/s]Loading train:   8%|▊         | 44/532 [00:42<07:02,  1.15it/s]Loading train:   8%|▊         | 45/532 [00:43<07:13,  1.12it/s]Loading train:   9%|▊         | 46/532 [00:44<07:31,  1.08it/s]Loading train:   9%|▉         | 47/532 [00:45<07:54,  1.02it/s]Loading train:   9%|▉         | 48/532 [00:46<07:51,  1.03it/s]Loading train:   9%|▉         | 49/532 [00:47<07:28,  1.08it/s]Loading train:   9%|▉         | 50/532 [00:48<07:43,  1.04it/s]Loading train:  10%|▉         | 51/532 [00:49<07:35,  1.06it/s]Loading train:  10%|▉         | 52/532 [00:50<07:17,  1.10it/s]Loading train:  10%|▉         | 53/532 [00:51<07:10,  1.11it/s]Loading train:  10%|█         | 54/532 [00:52<07:42,  1.03it/s]Loading train:  10%|█         | 55/532 [00:53<07:43,  1.03it/s]Loading train:  11%|█         | 56/532 [00:54<07:32,  1.05it/s]Loading train:  11%|█         | 57/532 [00:55<07:31,  1.05it/s]Loading train:  11%|█         | 58/532 [00:56<07:36,  1.04it/s]Loading train:  11%|█         | 59/532 [00:57<08:07,  1.03s/it]Loading train:  11%|█▏        | 60/532 [00:58<07:32,  1.04it/s]Loading train:  11%|█▏        | 61/532 [00:58<06:58,  1.13it/s]Loading train:  12%|█▏        | 62/532 [00:59<07:45,  1.01it/s]Loading train:  12%|█▏        | 63/532 [01:01<08:01,  1.03s/it]Loading train:  12%|█▏        | 64/532 [01:01<07:30,  1.04it/s]Loading train:  12%|█▏        | 65/532 [01:02<07:24,  1.05it/s]Loading train:  12%|█▏        | 66/532 [01:04<08:18,  1.07s/it]Loading train:  13%|█▎        | 67/532 [01:05<08:22,  1.08s/it]Loading train:  13%|█▎        | 68/532 [01:06<08:14,  1.07s/it]Loading train:  13%|█▎        | 69/532 [01:07<07:48,  1.01s/it]Loading train:  13%|█▎        | 70/532 [01:08<07:40,  1.00it/s]Loading train:  13%|█▎        | 71/532 [01:08<07:17,  1.05it/s]Loading train:  14%|█▎        | 72/532 [01:09<06:57,  1.10it/s]Loading train:  14%|█▎        | 73/532 [01:10<07:11,  1.06it/s]Loading train:  14%|█▍        | 74/532 [01:12<07:56,  1.04s/it]Loading train:  14%|█▍        | 75/532 [01:13<09:00,  1.18s/it]Loading train:  14%|█▍        | 76/532 [01:14<08:14,  1.09s/it]Loading train:  14%|█▍        | 77/532 [01:15<08:01,  1.06s/it]Loading train:  15%|█▍        | 78/532 [01:16<07:43,  1.02s/it]Loading train:  15%|█▍        | 79/532 [01:17<07:25,  1.02it/s]Loading train:  15%|█▌        | 80/532 [01:18<07:26,  1.01it/s]Loading train:  15%|█▌        | 81/532 [01:19<07:15,  1.04it/s]Loading train:  15%|█▌        | 82/532 [01:20<07:17,  1.03it/s]Loading train:  16%|█▌        | 83/532 [01:21<07:00,  1.07it/s]Loading train:  16%|█▌        | 84/532 [01:21<06:56,  1.07it/s]Loading train:  16%|█▌        | 85/532 [01:22<06:32,  1.14it/s]Loading train:  16%|█▌        | 86/532 [01:23<06:07,  1.21it/s]Loading train:  16%|█▋        | 87/532 [01:24<05:55,  1.25it/s]Loading train:  17%|█▋        | 88/532 [01:24<05:49,  1.27it/s]Loading train:  17%|█▋        | 89/532 [01:25<06:02,  1.22it/s]Loading train:  17%|█▋        | 90/532 [01:26<06:06,  1.21it/s]Loading train:  17%|█▋        | 91/532 [01:27<06:14,  1.18it/s]Loading train:  17%|█▋        | 92/532 [01:28<06:17,  1.16it/s]Loading train:  17%|█▋        | 93/532 [01:29<06:06,  1.20it/s]Loading train:  18%|█▊        | 94/532 [01:29<06:01,  1.21it/s]Loading train:  18%|█▊        | 95/532 [01:31<06:41,  1.09it/s]Loading train:  18%|█▊        | 96/532 [01:32<07:02,  1.03it/s]Loading train:  18%|█▊        | 97/532 [01:33<07:27,  1.03s/it]Loading train:  18%|█▊        | 98/532 [01:34<07:33,  1.04s/it]Loading train:  19%|█▊        | 99/532 [01:35<07:53,  1.09s/it]Loading train:  19%|█▉        | 100/532 [01:36<07:48,  1.08s/it]Loading train:  19%|█▉        | 101/532 [01:37<07:17,  1.02s/it]Loading train:  19%|█▉        | 102/532 [01:38<06:55,  1.03it/s]Loading train:  19%|█▉        | 103/532 [01:39<06:29,  1.10it/s]Loading train:  20%|█▉        | 104/532 [01:40<06:19,  1.13it/s]Loading train:  20%|█▉        | 105/532 [01:40<05:58,  1.19it/s]Loading train:  20%|█▉        | 106/532 [01:41<05:43,  1.24it/s]Loading train:  20%|██        | 107/532 [01:42<05:48,  1.22it/s]Loading train:  20%|██        | 108/532 [01:43<05:49,  1.21it/s]Loading train:  20%|██        | 109/532 [01:44<05:47,  1.22it/s]Loading train:  21%|██        | 110/532 [01:44<05:31,  1.27it/s]Loading train:  21%|██        | 111/532 [01:45<05:35,  1.25it/s]Loading train:  21%|██        | 112/532 [01:46<05:35,  1.25it/s]Loading train:  21%|██        | 113/532 [01:47<06:05,  1.15it/s]Loading train:  21%|██▏       | 114/532 [01:48<06:05,  1.14it/s]Loading train:  22%|██▏       | 115/532 [01:49<06:05,  1.14it/s]Loading train:  22%|██▏       | 116/532 [01:49<05:55,  1.17it/s]Loading train:  22%|██▏       | 117/532 [01:50<06:11,  1.12it/s]Loading train:  22%|██▏       | 118/532 [01:51<06:17,  1.10it/s]Loading train:  22%|██▏       | 119/532 [01:52<06:16,  1.10it/s]Loading train:  23%|██▎       | 120/532 [01:53<06:09,  1.11it/s]Loading train:  23%|██▎       | 121/532 [01:54<06:07,  1.12it/s]Loading train:  23%|██▎       | 122/532 [01:55<06:02,  1.13it/s]Loading train:  23%|██▎       | 123/532 [01:56<06:05,  1.12it/s]Loading train:  23%|██▎       | 124/532 [01:57<06:03,  1.12it/s]Loading train:  23%|██▎       | 125/532 [01:58<06:19,  1.07it/s]Loading train:  24%|██▎       | 126/532 [01:59<06:21,  1.06it/s]Loading train:  24%|██▍       | 127/532 [02:00<06:14,  1.08it/s]Loading train:  24%|██▍       | 128/532 [02:01<06:13,  1.08it/s]Loading train:  24%|██▍       | 129/532 [02:01<06:14,  1.08it/s]Loading train:  24%|██▍       | 130/532 [02:02<06:26,  1.04it/s]Loading train:  25%|██▍       | 131/532 [02:04<06:52,  1.03s/it]Loading train:  25%|██▍       | 132/532 [02:05<07:09,  1.07s/it]Loading train:  25%|██▌       | 133/532 [02:06<07:14,  1.09s/it]Loading train:  25%|██▌       | 134/532 [02:07<07:20,  1.11s/it]Loading train:  25%|██▌       | 135/532 [02:08<07:31,  1.14s/it]Loading train:  26%|██▌       | 136/532 [02:09<07:29,  1.14s/it]Loading train:  26%|██▌       | 137/532 [02:11<07:38,  1.16s/it]Loading train:  26%|██▌       | 138/532 [02:12<07:29,  1.14s/it]Loading train:  26%|██▌       | 139/532 [02:13<07:38,  1.17s/it]Loading train:  26%|██▋       | 140/532 [02:14<07:35,  1.16s/it]Loading train:  27%|██▋       | 141/532 [02:15<07:31,  1.15s/it]Loading train:  27%|██▋       | 142/532 [02:17<07:49,  1.20s/it]Loading train:  27%|██▋       | 143/532 [02:17<07:10,  1.11s/it]Loading train:  27%|██▋       | 144/532 [02:18<06:35,  1.02s/it]Loading train:  27%|██▋       | 145/532 [02:19<06:12,  1.04it/s]Loading train:  27%|██▋       | 146/532 [02:20<05:50,  1.10it/s]Loading train:  28%|██▊       | 147/532 [02:21<05:39,  1.14it/s]Loading train:  28%|██▊       | 148/532 [02:22<05:31,  1.16it/s]Loading train:  28%|██▊       | 149/532 [02:22<05:35,  1.14it/s]Loading train:  28%|██▊       | 150/532 [02:23<05:35,  1.14it/s]Loading train:  28%|██▊       | 151/532 [02:24<05:29,  1.16it/s]Loading train:  29%|██▊       | 152/532 [02:25<05:31,  1.15it/s]Loading train:  29%|██▉       | 153/532 [02:26<05:36,  1.12it/s]Loading train:  29%|██▉       | 154/532 [02:27<05:43,  1.10it/s]Loading train:  29%|██▉       | 155/532 [02:28<06:20,  1.01s/it]Loading train:  29%|██▉       | 156/532 [02:29<06:50,  1.09s/it]Loading train:  30%|██▉       | 157/532 [02:31<07:03,  1.13s/it]Loading train:  30%|██▉       | 158/532 [02:32<06:58,  1.12s/it]Loading train:  30%|██▉       | 159/532 [02:33<07:11,  1.16s/it]Loading train:  30%|███       | 160/532 [02:34<07:25,  1.20s/it]Loading train:  30%|███       | 161/532 [02:35<06:45,  1.09s/it]Loading train:  30%|███       | 162/532 [02:36<06:14,  1.01s/it]Loading train:  31%|███       | 163/532 [02:37<05:55,  1.04it/s]Loading train:  31%|███       | 164/532 [02:38<05:36,  1.09it/s]Loading train:  31%|███       | 165/532 [02:38<05:20,  1.14it/s]Loading train:  31%|███       | 166/532 [02:39<05:11,  1.18it/s]Loading train:  31%|███▏      | 167/532 [02:40<05:20,  1.14it/s]Loading train:  32%|███▏      | 168/532 [02:41<05:22,  1.13it/s]Loading train:  32%|███▏      | 169/532 [02:42<05:23,  1.12it/s]Loading train:  32%|███▏      | 170/532 [02:43<05:22,  1.12it/s]Loading train:  32%|███▏      | 171/532 [02:44<05:24,  1.11it/s]Loading train:  32%|███▏      | 172/532 [02:45<05:13,  1.15it/s]Loading train:  33%|███▎      | 173/532 [02:45<05:02,  1.19it/s]Loading train:  33%|███▎      | 174/532 [02:46<05:02,  1.18it/s]Loading train:  33%|███▎      | 175/532 [02:47<04:50,  1.23it/s]Loading train:  33%|███▎      | 176/532 [02:48<04:51,  1.22it/s]Loading train:  33%|███▎      | 177/532 [02:49<04:48,  1.23it/s]Loading train:  33%|███▎      | 178/532 [02:50<05:00,  1.18it/s]Loading train:  34%|███▎      | 179/532 [02:50<05:02,  1.17it/s]Loading train:  34%|███▍      | 180/532 [02:51<05:11,  1.13it/s]Loading train:  34%|███▍      | 181/532 [02:52<05:07,  1.14it/s]Loading train:  34%|███▍      | 182/532 [02:53<05:06,  1.14it/s]Loading train:  34%|███▍      | 183/532 [02:54<05:03,  1.15it/s]Loading train:  35%|███▍      | 184/532 [02:55<05:09,  1.12it/s]Loading train:  35%|███▍      | 185/532 [02:56<05:05,  1.14it/s]Loading train:  35%|███▍      | 186/532 [02:57<05:04,  1.14it/s]Loading train:  35%|███▌      | 187/532 [02:57<04:56,  1.16it/s]Loading train:  35%|███▌      | 188/532 [02:58<04:44,  1.21it/s]Loading train:  36%|███▌      | 189/532 [02:59<04:38,  1.23it/s]Loading train:  36%|███▌      | 190/532 [03:00<04:25,  1.29it/s]Loading train:  36%|███▌      | 191/532 [03:01<05:07,  1.11it/s]Loading train:  36%|███▌      | 192/532 [03:02<05:40,  1.00s/it]Loading train:  36%|███▋      | 193/532 [03:03<05:51,  1.04s/it]Loading train:  36%|███▋      | 194/532 [03:04<06:09,  1.09s/it]Loading train:  37%|███▋      | 195/532 [03:06<06:22,  1.14s/it]Loading train:  37%|███▋      | 196/532 [03:07<06:32,  1.17s/it]Loading train:  37%|███▋      | 197/532 [03:08<06:25,  1.15s/it]Loading train:  37%|███▋      | 198/532 [03:09<06:09,  1.11s/it]Loading train:  37%|███▋      | 199/532 [03:10<06:00,  1.08s/it]Loading train:  38%|███▊      | 200/532 [03:11<05:54,  1.07s/it]Loading train:  38%|███▊      | 201/532 [03:12<05:53,  1.07s/it]Loading train:  38%|███▊      | 202/532 [03:13<05:46,  1.05s/it]Loading train:  38%|███▊      | 203/532 [03:14<05:32,  1.01s/it]Loading train:  38%|███▊      | 204/532 [03:15<05:09,  1.06it/s]Loading train:  39%|███▊      | 205/532 [03:16<04:57,  1.10it/s]Loading train:  39%|███▊      | 206/532 [03:17<04:46,  1.14it/s]Loading train:  39%|███▉      | 207/532 [03:17<04:39,  1.16it/s]Loading train:  39%|███▉      | 208/532 [03:18<04:32,  1.19it/s]Loading train:  39%|███▉      | 209/532 [03:19<04:19,  1.25it/s]Loading train:  39%|███▉      | 210/532 [03:20<04:12,  1.27it/s]Loading train:  40%|███▉      | 211/532 [03:20<04:03,  1.32it/s]Loading train:  40%|███▉      | 212/532 [03:21<04:08,  1.29it/s]Loading train:  40%|████      | 213/532 [03:22<04:05,  1.30it/s]Loading train:  40%|████      | 214/532 [03:23<04:18,  1.23it/s]Loading train:  40%|████      | 215/532 [03:24<04:55,  1.07it/s]Loading train:  41%|████      | 216/532 [03:25<05:19,  1.01s/it]Loading train:  41%|████      | 217/532 [03:26<05:27,  1.04s/it]Loading train:  41%|████      | 218/532 [03:28<05:51,  1.12s/it]Loading train:  41%|████      | 219/532 [03:29<06:05,  1.17s/it]Loading train:  41%|████▏     | 220/532 [03:30<05:59,  1.15s/it]Loading train:  42%|████▏     | 221/532 [03:31<05:33,  1.07s/it]Loading train:  42%|████▏     | 222/532 [03:32<05:00,  1.03it/s]Loading train:  42%|████▏     | 223/532 [03:33<04:55,  1.05it/s]Loading train:  42%|████▏     | 224/532 [03:33<04:31,  1.13it/s]Loading train:  42%|████▏     | 225/532 [03:34<04:26,  1.15it/s]Loading train:  42%|████▏     | 226/532 [03:35<04:10,  1.22it/s]Loading train:  43%|████▎     | 227/532 [03:36<04:16,  1.19it/s]Loading train:  43%|████▎     | 228/532 [03:36<04:13,  1.20it/s]Loading train:  43%|████▎     | 229/532 [03:37<03:59,  1.26it/s]Loading train:  43%|████▎     | 230/532 [03:38<03:47,  1.33it/s]Loading train:  43%|████▎     | 231/532 [03:38<03:39,  1.37it/s]Loading train:  44%|████▎     | 232/532 [03:39<03:34,  1.40it/s]Loading train:  44%|████▍     | 233/532 [03:40<03:55,  1.27it/s]Loading train:  44%|████▍     | 234/532 [03:41<04:05,  1.22it/s]Loading train:  44%|████▍     | 235/532 [03:42<04:23,  1.13it/s]Loading train:  44%|████▍     | 236/532 [03:43<04:16,  1.15it/s]Loading train:  45%|████▍     | 237/532 [03:44<04:16,  1.15it/s]Loading train:  45%|████▍     | 238/532 [03:45<04:22,  1.12it/s]Loading train:  45%|████▍     | 239/532 [03:46<04:17,  1.14it/s]Loading train:  45%|████▌     | 240/532 [03:47<04:22,  1.11it/s]Loading train:  45%|████▌     | 241/532 [03:47<04:20,  1.12it/s]Loading train:  45%|████▌     | 242/532 [03:48<04:20,  1.11it/s]Loading train:  46%|████▌     | 243/532 [03:49<04:15,  1.13it/s]Loading train:  46%|████▌     | 244/532 [03:50<04:13,  1.14it/s]Loading train:  46%|████▌     | 245/532 [03:51<04:15,  1.12it/s]Loading train:  46%|████▌     | 246/532 [03:52<04:01,  1.18it/s]Loading train:  46%|████▋     | 247/532 [03:52<03:47,  1.25it/s]Loading train:  47%|████▋     | 248/532 [03:53<03:57,  1.20it/s]Loading train:  47%|████▋     | 249/532 [03:54<03:51,  1.22it/s]Loading train:  47%|████▋     | 250/532 [03:55<03:54,  1.20it/s]Loading train:  47%|████▋     | 251/532 [03:56<03:57,  1.18it/s]Loading train:  47%|████▋     | 252/532 [03:57<03:50,  1.21it/s]Loading train:  48%|████▊     | 253/532 [03:58<04:00,  1.16it/s]Loading train:  48%|████▊     | 254/532 [03:58<03:55,  1.18it/s]Loading train:  48%|████▊     | 255/532 [03:59<03:49,  1.21it/s]Loading train:  48%|████▊     | 256/532 [04:00<03:57,  1.16it/s]Loading train:  48%|████▊     | 257/532 [04:01<04:12,  1.09it/s]Loading train:  48%|████▊     | 258/532 [04:02<04:25,  1.03it/s]Loading train:  49%|████▊     | 259/532 [04:03<04:29,  1.01it/s]Loading train:  49%|████▉     | 260/532 [04:04<04:29,  1.01it/s]Loading train:  49%|████▉     | 261/532 [04:05<04:19,  1.04it/s]Loading train:  49%|████▉     | 262/532 [04:06<04:15,  1.06it/s]Loading train:  49%|████▉     | 263/532 [04:07<04:17,  1.05it/s]Loading train:  50%|████▉     | 264/532 [04:08<03:57,  1.13it/s]Loading train:  50%|████▉     | 265/532 [04:09<03:47,  1.17it/s]Loading train:  50%|█████     | 266/532 [04:09<03:46,  1.18it/s]Loading train:  50%|█████     | 267/532 [04:10<03:42,  1.19it/s]Loading train:  50%|█████     | 268/532 [04:11<03:35,  1.22it/s]Loading train:  51%|█████     | 269/532 [04:12<03:58,  1.10it/s]Loading train:  51%|█████     | 270/532 [04:13<03:57,  1.10it/s]Loading train:  51%|█████     | 271/532 [04:14<04:02,  1.08it/s]Loading train:  51%|█████     | 272/532 [04:15<04:01,  1.08it/s]Loading train:  51%|█████▏    | 273/532 [04:16<03:53,  1.11it/s]Loading train:  52%|█████▏    | 274/532 [04:17<03:56,  1.09it/s]Loading train:  52%|█████▏    | 275/532 [04:18<04:04,  1.05it/s]Loading train:  52%|█████▏    | 276/532 [04:19<04:22,  1.03s/it]Loading train:  52%|█████▏    | 277/532 [04:20<04:28,  1.05s/it]Loading train:  52%|█████▏    | 278/532 [04:21<04:40,  1.10s/it]Loading train:  52%|█████▏    | 279/532 [04:22<04:36,  1.09s/it]Loading train:  53%|█████▎    | 280/532 [04:23<04:42,  1.12s/it]Loading train:  53%|█████▎    | 281/532 [04:25<04:44,  1.13s/it]Loading train:  53%|█████▎    | 282/532 [04:26<04:44,  1.14s/it]Loading train:  53%|█████▎    | 283/532 [04:27<04:31,  1.09s/it]Loading train:  53%|█████▎    | 284/532 [04:28<04:32,  1.10s/it]Loading train:  54%|█████▎    | 285/532 [04:29<04:27,  1.08s/it]Loading train:  54%|█████▍    | 286/532 [04:30<04:25,  1.08s/it]Loading train:  54%|█████▍    | 287/532 [04:31<04:06,  1.01s/it]Loading train:  54%|█████▍    | 288/532 [04:32<03:54,  1.04it/s]Loading train:  54%|█████▍    | 289/532 [04:33<03:43,  1.09it/s]Loading train:  55%|█████▍    | 290/532 [04:33<03:35,  1.12it/s]Loading train:  55%|█████▍    | 291/532 [04:34<03:28,  1.15it/s]Loading train:  55%|█████▍    | 292/532 [04:35<03:24,  1.17it/s]Loading train:  55%|█████▌    | 293/532 [04:36<03:29,  1.14it/s]Loading train:  55%|█████▌    | 294/532 [04:37<03:38,  1.09it/s]Loading train:  55%|█████▌    | 295/532 [04:38<03:35,  1.10it/s]Loading train:  56%|█████▌    | 296/532 [04:39<03:39,  1.07it/s]Loading train:  56%|█████▌    | 297/532 [04:40<03:43,  1.05it/s]Loading train:  56%|█████▌    | 298/532 [04:41<03:43,  1.05it/s]Loading train:  56%|█████▌    | 299/532 [04:41<03:24,  1.14it/s]Loading train:  56%|█████▋    | 300/532 [04:42<03:15,  1.19it/s]Loading train:  57%|█████▋    | 301/532 [04:43<03:11,  1.21it/s]Loading train:  57%|█████▋    | 302/532 [04:44<03:04,  1.24it/s]Loading train:  57%|█████▋    | 303/532 [04:45<03:00,  1.27it/s]Loading train:  57%|█████▋    | 304/532 [04:46<03:17,  1.15it/s]Loading train:  57%|█████▋    | 305/532 [04:47<03:43,  1.02it/s]Loading train:  58%|█████▊    | 306/532 [04:48<03:58,  1.06s/it]Loading train:  58%|█████▊    | 307/532 [04:49<03:59,  1.06s/it]Loading train:  58%|█████▊    | 308/532 [04:50<04:02,  1.08s/it]Loading train:  58%|█████▊    | 309/532 [04:51<04:01,  1.08s/it]Loading train:  58%|█████▊    | 310/532 [04:53<04:10,  1.13s/it]Loading train:  58%|█████▊    | 311/532 [04:54<04:41,  1.28s/it]Loading train:  59%|█████▊    | 312/532 [04:56<04:56,  1.35s/it]Loading train:  59%|█████▉    | 313/532 [04:57<05:20,  1.46s/it]Loading train:  59%|█████▉    | 314/532 [04:59<05:27,  1.50s/it]Loading train:  59%|█████▉    | 315/532 [05:00<05:22,  1.48s/it]Loading train:  59%|█████▉    | 316/532 [05:02<05:19,  1.48s/it]Loading train:  60%|█████▉    | 317/532 [05:03<04:38,  1.29s/it]Loading train:  60%|█████▉    | 318/532 [05:04<04:03,  1.14s/it]Loading train:  60%|█████▉    | 319/532 [05:04<03:38,  1.03s/it]Loading train:  60%|██████    | 320/532 [05:05<03:18,  1.07it/s]Loading train:  60%|██████    | 321/532 [05:06<03:07,  1.13it/s]Loading train:  61%|██████    | 322/532 [05:07<03:01,  1.16it/s]Loading train:  61%|██████    | 323/532 [05:08<03:37,  1.04s/it]Loading train:  61%|██████    | 324/532 [05:09<03:42,  1.07s/it]Loading train:  61%|██████    | 325/532 [05:11<03:54,  1.13s/it]Loading train:  61%|██████▏   | 326/532 [05:12<04:09,  1.21s/it]Loading train:  61%|██████▏   | 327/532 [05:13<04:04,  1.19s/it]Loading train:  62%|██████▏   | 328/532 [05:14<04:03,  1.19s/it]Loading train:  62%|██████▏   | 329/532 [05:15<03:56,  1.17s/it]Loading train:  62%|██████▏   | 330/532 [05:16<03:32,  1.05s/it]Loading train:  62%|██████▏   | 331/532 [05:17<03:22,  1.01s/it]Loading train:  62%|██████▏   | 332/532 [05:18<03:10,  1.05it/s]Loading train:  63%|██████▎   | 333/532 [05:19<03:04,  1.08it/s]Loading train:  63%|██████▎   | 334/532 [05:20<02:56,  1.12it/s]Loading train:  63%|██████▎   | 335/532 [05:21<03:16,  1.00it/s]Loading train:  63%|██████▎   | 336/532 [05:22<03:16,  1.00s/it]Loading train:  63%|██████▎   | 337/532 [05:23<03:18,  1.02s/it]Loading train:  64%|██████▎   | 338/532 [05:24<03:17,  1.02s/it]Loading train:  64%|██████▎   | 339/532 [05:25<03:21,  1.05s/it]Loading train:  64%|██████▍   | 340/532 [05:26<03:22,  1.06s/it]Loading train:  64%|██████▍   | 341/532 [05:27<03:06,  1.02it/s]Loading train:  64%|██████▍   | 342/532 [05:28<02:59,  1.06it/s]Loading train:  64%|██████▍   | 343/532 [05:29<02:50,  1.11it/s]Loading train:  65%|██████▍   | 344/532 [05:29<02:41,  1.17it/s]Loading train:  65%|██████▍   | 345/532 [05:30<02:38,  1.18it/s]Loading train:  65%|██████▌   | 346/532 [05:31<02:34,  1.20it/s]Loading train:  65%|██████▌   | 347/532 [05:32<02:43,  1.13it/s]Loading train:  65%|██████▌   | 348/532 [05:33<02:40,  1.14it/s]Loading train:  66%|██████▌   | 349/532 [05:34<02:40,  1.14it/s]Loading train:  66%|██████▌   | 350/532 [05:35<02:43,  1.11it/s]Loading train:  66%|██████▌   | 351/532 [05:35<02:40,  1.13it/s]Loading train:  66%|██████▌   | 352/532 [05:36<02:39,  1.13it/s]Loading train:  66%|██████▋   | 353/532 [05:37<02:36,  1.14it/s]Loading train:  67%|██████▋   | 354/532 [05:38<02:38,  1.12it/s]Loading train:  67%|██████▋   | 355/532 [05:39<02:34,  1.15it/s]Loading train:  67%|██████▋   | 356/532 [05:40<02:34,  1.14it/s]Loading train:  67%|██████▋   | 357/532 [05:41<02:36,  1.12it/s]Loading train:  67%|██████▋   | 358/532 [05:42<02:42,  1.07it/s]Loading train:  67%|██████▋   | 359/532 [05:43<02:42,  1.07it/s]Loading train:  68%|██████▊   | 360/532 [05:44<02:42,  1.06it/s]Loading train:  68%|██████▊   | 361/532 [05:45<02:35,  1.10it/s]Loading train:  68%|██████▊   | 362/532 [05:45<02:34,  1.10it/s]Loading train:  68%|██████▊   | 363/532 [05:46<02:35,  1.09it/s]Loading train:  68%|██████▊   | 364/532 [05:47<02:28,  1.13it/s]Loading train:  69%|██████▊   | 365/532 [05:48<02:25,  1.15it/s]Loading train:  69%|██████▉   | 366/532 [05:49<02:20,  1.18it/s]Loading train:  69%|██████▉   | 367/532 [05:50<02:22,  1.16it/s]Loading train:  69%|██████▉   | 368/532 [05:51<02:24,  1.13it/s]Loading train:  69%|██████▉   | 369/532 [05:52<02:31,  1.08it/s]Loading train:  70%|██████▉   | 370/532 [05:53<02:26,  1.11it/s]Loading train:  70%|██████▉   | 371/532 [05:54<02:38,  1.01it/s]Loading train:  70%|██████▉   | 372/532 [05:55<02:44,  1.03s/it]Loading train:  70%|███████   | 373/532 [05:56<02:50,  1.07s/it]Loading train:  70%|███████   | 374/532 [05:57<02:50,  1.08s/it]Loading train:  70%|███████   | 375/532 [05:58<02:53,  1.11s/it]Loading train:  71%|███████   | 376/532 [05:59<02:52,  1.11s/it]Loading train:  71%|███████   | 377/532 [06:00<02:40,  1.04s/it]Loading train:  71%|███████   | 378/532 [06:01<02:30,  1.02it/s]Loading train:  71%|███████   | 379/532 [06:02<02:25,  1.05it/s]Loading train:  71%|███████▏  | 380/532 [06:03<02:20,  1.08it/s]Loading train:  72%|███████▏  | 381/532 [06:04<02:21,  1.06it/s]Loading train:  72%|███████▏  | 382/532 [06:05<02:15,  1.11it/s]Loading train:  72%|███████▏  | 383/532 [06:06<02:25,  1.03it/s]Loading train:  72%|███████▏  | 384/532 [06:07<02:22,  1.04it/s]Loading train:  72%|███████▏  | 385/532 [06:08<02:25,  1.01it/s]Loading train:  73%|███████▎  | 386/532 [06:09<02:23,  1.02it/s]Loading train:  73%|███████▎  | 387/532 [06:10<02:26,  1.01s/it]Loading train:  73%|███████▎  | 388/532 [06:11<02:22,  1.01it/s]Loading train:  73%|███████▎  | 389/532 [06:12<02:24,  1.01s/it]Loading train:  73%|███████▎  | 390/532 [06:13<02:21,  1.00it/s]Loading train:  73%|███████▎  | 391/532 [06:14<02:21,  1.00s/it]Loading train:  74%|███████▎  | 392/532 [06:15<02:17,  1.02it/s]Loading train:  74%|███████▍  | 393/532 [06:16<02:20,  1.01s/it]Loading train:  74%|███████▍  | 394/532 [06:17<02:15,  1.02it/s]Loading train:  74%|███████▍  | 395/532 [06:18<02:20,  1.03s/it]Loading train:  74%|███████▍  | 396/532 [06:19<02:16,  1.00s/it]Loading train:  75%|███████▍  | 397/532 [06:20<02:17,  1.02s/it]Loading train:  75%|███████▍  | 398/532 [06:21<02:12,  1.01it/s]Loading train:  75%|███████▌  | 399/532 [06:22<02:10,  1.02it/s]Loading train:  75%|███████▌  | 400/532 [06:23<02:07,  1.03it/s]Loading train:  75%|███████▌  | 401/532 [06:24<02:15,  1.04s/it]Loading train:  76%|███████▌  | 402/532 [06:25<02:14,  1.04s/it]Loading train:  76%|███████▌  | 403/532 [06:26<02:14,  1.04s/it]Loading train:  76%|███████▌  | 404/532 [06:27<02:12,  1.03s/it]Loading train:  76%|███████▌  | 405/532 [06:28<02:13,  1.05s/it]Loading train:  76%|███████▋  | 406/532 [06:29<02:11,  1.04s/it]Loading train:  77%|███████▋  | 407/532 [06:30<02:14,  1.08s/it]Loading train:  77%|███████▋  | 408/532 [06:31<02:06,  1.02s/it]Loading train:  77%|███████▋  | 409/532 [06:32<02:05,  1.02s/it]Loading train:  77%|███████▋  | 410/532 [06:33<01:59,  1.02it/s]Loading train:  77%|███████▋  | 411/532 [06:34<01:59,  1.01it/s]Loading train:  77%|███████▋  | 412/532 [06:35<01:54,  1.04it/s]Loading train:  78%|███████▊  | 413/532 [06:36<01:51,  1.07it/s]Loading train:  78%|███████▊  | 414/532 [06:37<01:48,  1.09it/s]Loading train:  78%|███████▊  | 415/532 [06:38<01:44,  1.12it/s]Loading train:  78%|███████▊  | 416/532 [06:38<01:43,  1.12it/s]Loading train:  78%|███████▊  | 417/532 [06:39<01:38,  1.17it/s]Loading train:  79%|███████▊  | 418/532 [06:40<01:33,  1.21it/s]Loading train:  79%|███████▉  | 419/532 [06:41<01:42,  1.11it/s]Loading train:  79%|███████▉  | 420/532 [06:42<01:43,  1.08it/s]Loading train:  79%|███████▉  | 421/532 [06:43<01:43,  1.07it/s]Loading train:  79%|███████▉  | 422/532 [06:44<01:43,  1.06it/s]Loading train:  80%|███████▉  | 423/532 [06:45<01:43,  1.06it/s]Loading train:  80%|███████▉  | 424/532 [06:46<01:43,  1.04it/s]Loading train:  80%|███████▉  | 425/532 [06:47<01:43,  1.04it/s]Loading train:  80%|████████  | 426/532 [06:48<01:46,  1.00s/it]Loading train:  80%|████████  | 427/532 [06:49<01:44,  1.01it/s]Loading train:  80%|████████  | 428/532 [06:50<01:42,  1.01it/s]Loading train:  81%|████████  | 429/532 [06:51<01:39,  1.04it/s]Loading train:  81%|████████  | 430/532 [06:52<01:36,  1.05it/s]Loading train:  81%|████████  | 431/532 [06:53<01:43,  1.02s/it]Loading train:  81%|████████  | 432/532 [06:54<01:41,  1.02s/it]Loading train:  81%|████████▏ | 433/532 [06:55<01:40,  1.01s/it]Loading train:  82%|████████▏ | 434/532 [06:56<01:39,  1.01s/it]Loading train:  82%|████████▏ | 435/532 [06:57<01:41,  1.05s/it]Loading train:  82%|████████▏ | 436/532 [06:58<01:37,  1.02s/it]Loading train:  82%|████████▏ | 437/532 [06:59<01:36,  1.01s/it]Loading train:  82%|████████▏ | 438/532 [07:00<01:29,  1.04it/s]Loading train:  83%|████████▎ | 439/532 [07:01<01:26,  1.08it/s]Loading train:  83%|████████▎ | 440/532 [07:01<01:21,  1.13it/s]Loading train:  83%|████████▎ | 441/532 [07:02<01:20,  1.12it/s]Loading train:  83%|████████▎ | 442/532 [07:03<01:20,  1.12it/s]Loading train:  83%|████████▎ | 443/532 [07:04<01:16,  1.16it/s]Loading train:  83%|████████▎ | 444/532 [07:05<01:14,  1.18it/s]Loading train:  84%|████████▎ | 445/532 [07:06<01:14,  1.16it/s]Loading train:  84%|████████▍ | 446/532 [07:06<01:10,  1.22it/s]Loading train:  84%|████████▍ | 447/532 [07:07<01:09,  1.23it/s]Loading train:  84%|████████▍ | 448/532 [07:08<01:06,  1.26it/s]Loading train:  84%|████████▍ | 449/532 [07:09<01:06,  1.24it/s]Loading train:  85%|████████▍ | 450/532 [07:10<01:09,  1.18it/s]Loading train:  85%|████████▍ | 451/532 [07:11<01:08,  1.19it/s]Loading train:  85%|████████▍ | 452/532 [07:11<01:05,  1.22it/s]Loading train:  85%|████████▌ | 453/532 [07:12<01:06,  1.19it/s]Loading train:  85%|████████▌ | 454/532 [07:13<01:05,  1.18it/s]Loading train:  86%|████████▌ | 455/532 [07:14<01:11,  1.07it/s]Loading train:  86%|████████▌ | 456/532 [07:15<01:11,  1.07it/s]Loading train:  86%|████████▌ | 457/532 [07:16<01:12,  1.03it/s]Loading train:  86%|████████▌ | 458/532 [07:17<01:11,  1.03it/s]Loading train:  86%|████████▋ | 459/532 [07:18<01:11,  1.01it/s]Loading train:  86%|████████▋ | 460/532 [07:19<01:10,  1.02it/s]Loading train:  87%|████████▋ | 461/532 [07:20<01:12,  1.02s/it]Loading train:  87%|████████▋ | 462/532 [07:21<01:12,  1.04s/it]Loading train:  87%|████████▋ | 463/532 [07:23<01:15,  1.09s/it]Loading train:  87%|████████▋ | 464/532 [07:24<01:15,  1.10s/it]Loading train:  87%|████████▋ | 465/532 [07:25<01:14,  1.10s/it]Loading train:  88%|████████▊ | 466/532 [07:26<01:12,  1.10s/it]Loading train:  88%|████████▊ | 467/532 [07:27<01:10,  1.08s/it]Loading train:  88%|████████▊ | 468/532 [07:28<01:03,  1.00it/s]Loading train:  88%|████████▊ | 469/532 [07:29<00:58,  1.08it/s]Loading train:  88%|████████▊ | 470/532 [07:29<00:56,  1.10it/s]Loading train:  89%|████████▊ | 471/532 [07:30<00:53,  1.14it/s]Loading train:  89%|████████▊ | 472/532 [07:31<00:53,  1.13it/s]Loading train:  89%|████████▉ | 473/532 [07:32<00:53,  1.10it/s]Loading train:  89%|████████▉ | 474/532 [07:33<00:55,  1.04it/s]Loading train:  89%|████████▉ | 475/532 [07:34<00:54,  1.04it/s]Loading train:  89%|████████▉ | 476/532 [07:35<00:52,  1.06it/s]Loading train:  90%|████████▉ | 477/532 [07:36<00:52,  1.04it/s]Loading train:  90%|████████▉ | 478/532 [07:37<00:52,  1.03it/s]Loading train:  90%|█████████ | 479/532 [07:38<00:52,  1.01it/s]Loading train:  90%|█████████ | 480/532 [07:39<00:48,  1.06it/s]Loading train:  90%|█████████ | 481/532 [07:40<00:48,  1.06it/s]Loading train:  91%|█████████ | 482/532 [07:41<00:45,  1.10it/s]Loading train:  91%|█████████ | 483/532 [07:42<00:43,  1.14it/s]Loading train:  91%|█████████ | 484/532 [07:42<00:42,  1.14it/s]Loading train:  91%|█████████ | 485/532 [07:43<00:43,  1.08it/s]Loading train:  91%|█████████▏| 486/532 [07:45<00:45,  1.01it/s]Loading train:  92%|█████████▏| 487/532 [07:46<00:45,  1.00s/it]Loading train:  92%|█████████▏| 488/532 [07:47<00:44,  1.02s/it]Loading train:  92%|█████████▏| 489/532 [07:48<00:45,  1.05s/it]Loading train:  92%|█████████▏| 490/532 [07:49<00:43,  1.04s/it]Loading train:  92%|█████████▏| 491/532 [07:50<00:41,  1.02s/it]Loading train:  92%|█████████▏| 492/532 [07:51<00:38,  1.04it/s]Loading train:  93%|█████████▎| 493/532 [07:52<00:38,  1.02it/s]Loading train:  93%|█████████▎| 494/532 [07:52<00:35,  1.08it/s]Loading train:  93%|█████████▎| 495/532 [07:53<00:33,  1.09it/s]Loading train:  93%|█████████▎| 496/532 [07:54<00:33,  1.08it/s]Loading train:  93%|█████████▎| 497/532 [07:55<00:33,  1.04it/s]Loading train:  94%|█████████▎| 498/532 [07:56<00:32,  1.06it/s]Loading train:  94%|█████████▍| 499/532 [07:57<00:32,  1.03it/s]Loading train:  94%|█████████▍| 500/532 [07:58<00:30,  1.06it/s]Loading train:  94%|█████████▍| 501/532 [07:59<00:29,  1.07it/s]Loading train:  94%|█████████▍| 502/532 [08:00<00:27,  1.09it/s]Loading train:  95%|█████████▍| 503/532 [08:01<00:27,  1.07it/s]Loading train:  95%|█████████▍| 504/532 [08:02<00:25,  1.11it/s]Loading train:  95%|█████████▍| 505/532 [08:03<00:24,  1.12it/s]Loading train:  95%|█████████▌| 506/532 [08:03<00:22,  1.13it/s]Loading train:  95%|█████████▌| 507/532 [08:04<00:21,  1.14it/s]Loading train:  95%|█████████▌| 508/532 [08:05<00:21,  1.11it/s]Loading train:  96%|█████████▌| 509/532 [08:06<00:22,  1.04it/s]Loading train:  96%|█████████▌| 510/532 [08:07<00:21,  1.03it/s]Loading train:  96%|█████████▌| 511/532 [08:08<00:20,  1.02it/s]Loading train:  96%|█████████▌| 512/532 [08:09<00:20,  1.00s/it]Loading train:  96%|█████████▋| 513/532 [08:10<00:18,  1.00it/s]Loading train:  97%|█████████▋| 514/532 [08:12<00:18,  1.03s/it]Loading train:  97%|█████████▋| 515/532 [08:12<00:17,  1.01s/it]Loading train:  97%|█████████▋| 516/532 [08:13<00:15,  1.01it/s]Loading train:  97%|█████████▋| 517/532 [08:14<00:14,  1.04it/s]Loading train:  97%|█████████▋| 518/532 [08:15<00:13,  1.05it/s]Loading train:  98%|█████████▊| 519/532 [08:16<00:11,  1.09it/s]Loading train:  98%|█████████▊| 520/532 [08:17<00:10,  1.10it/s]Loading train:  98%|█████████▊| 521/532 [08:18<00:10,  1.10it/s]Loading train:  98%|█████████▊| 522/532 [08:19<00:09,  1.07it/s]Loading train:  98%|█████████▊| 523/532 [08:20<00:08,  1.06it/s]Loading train:  98%|█████████▊| 524/532 [08:21<00:07,  1.09it/s]Loading train:  99%|█████████▊| 525/532 [08:22<00:06,  1.05it/s]Loading train:  99%|█████████▉| 526/532 [08:23<00:05,  1.05it/s]Loading train:  99%|█████████▉| 527/532 [08:24<00:04,  1.08it/s]Loading train:  99%|█████████▉| 528/532 [08:25<00:03,  1.05it/s]Loading train:  99%|█████████▉| 529/532 [08:25<00:02,  1.08it/s]Loading train: 100%|█████████▉| 530/532 [08:26<00:01,  1.11it/s]Loading train: 100%|█████████▉| 531/532 [08:27<00:00,  1.11it/s]Loading train: 100%|██████████| 532/532 [08:28<00:00,  1.13it/s]
concatenating: train:   0%|          | 0/532 [00:00<?, ?it/s]concatenating: train:   1%|          | 5/532 [00:00<00:10, 49.62it/s]concatenating: train:   4%|▍         | 22/532 [00:00<00:08, 62.93it/s]concatenating: train:   9%|▉         | 49/532 [00:00<00:05, 81.26it/s]concatenating: train:  13%|█▎        | 71/532 [00:00<00:04, 99.45it/s]concatenating: train:  18%|█▊        | 94/532 [00:00<00:03, 119.31it/s]concatenating: train:  22%|██▏       | 118/532 [00:00<00:02, 139.51it/s]concatenating: train:  28%|██▊       | 148/532 [00:00<00:02, 165.38it/s]concatenating: train:  33%|███▎      | 174/532 [00:00<00:01, 184.39it/s]concatenating: train:  38%|███▊      | 200/532 [00:00<00:01, 198.93it/s]concatenating: train:  43%|████▎     | 229/532 [00:01<00:01, 217.03it/s]concatenating: train:  48%|████▊     | 254/532 [00:01<00:01, 220.54it/s]concatenating: train:  53%|█████▎    | 282/532 [00:01<00:01, 235.43it/s]concatenating: train:  58%|█████▊    | 310/532 [00:01<00:00, 246.88it/s]concatenating: train:  63%|██████▎   | 337/532 [00:01<00:00, 250.21it/s]concatenating: train:  68%|██████▊   | 363/532 [00:01<00:00, 245.19it/s]concatenating: train:  73%|███████▎  | 389/532 [00:01<00:00, 245.07it/s]concatenating: train:  78%|███████▊  | 415/532 [00:01<00:00, 248.65it/s]concatenating: train:  84%|████████▎ | 445/532 [00:01<00:00, 259.93it/s]concatenating: train:  89%|████████▊ | 472/532 [00:01<00:00, 255.60it/s]concatenating: train:  94%|█████████▎| 498/532 [00:02<00:00, 159.02it/s]concatenating: train:  99%|█████████▊| 525/532 [00:02<00:00, 181.13it/s]concatenating: train: 100%|██████████| 532/532 [00:02<00:00, 220.52it/s]
Loading test:   0%|          | 0/15 [00:00<?, ?it/s]Loading test:   7%|▋         | 1/15 [00:00<00:09,  1.45it/s]Loading test:  13%|█▎        | 2/15 [00:01<00:09,  1.35it/s]Loading test:  20%|██        | 3/15 [00:02<00:09,  1.24it/s]Loading test:  27%|██▋       | 4/15 [00:03<00:09,  1.11it/s]Loading test:  33%|███▎      | 5/15 [00:04<00:10,  1.03s/it]Loading test:  40%|████      | 6/15 [00:06<00:09,  1.11s/it]Loading test:  47%|████▋     | 7/15 [00:07<00:08,  1.00s/it]Loading test:  53%|█████▎    | 8/15 [00:08<00:07,  1.10s/it]Loading test:  60%|██████    | 9/15 [00:09<00:06,  1.05s/it]Loading test:  67%|██████▋   | 10/15 [00:10<00:04,  1.02it/s]Loading test:  73%|███████▎  | 11/15 [00:11<00:03,  1.03it/s]Loading test:  80%|████████  | 12/15 [00:12<00:03,  1.03s/it]Loading test:  87%|████████▋ | 13/15 [00:13<00:02,  1.14s/it]Loading test:  93%|█████████▎| 14/15 [00:14<00:01,  1.06s/it]Loading test: 100%|██████████| 15/15 [00:15<00:00,  1.08s/it]
concatenating: validation:   0%|          | 0/15 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 15/15 [00:00<00:00, 396.67it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 84, 56, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 84, 56, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 84, 56, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 84, 56, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 84, 56, 10)   910         activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 84, 56, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 84, 56, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 84, 56, 11)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 42, 28, 11)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 42, 28, 11)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 42, 28, 20)   2000        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 42, 28, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 42, 28, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 42, 28, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 42, 28, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 42, 28, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 42, 28, 31)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 21, 14, 31)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 21, 14, 31)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 21, 14, 40)   11200       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 21, 14, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 21, 14, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 21, 14, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 21, 14, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 21, 14, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 21, 14, 71)   0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 21, 14, 71)   0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 42, 28, 20)   5700        dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 42, 28, 51)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 42, 28, 20)   9200        concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 42, 28, 20)   80          conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 42, 28, 20)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 42, 28, 20)   3620        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 42, 28, 20)   80          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 42, 28, 20)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 42, 28, 71)   0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-06 20:04:22.779948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-06 20:04:22.780045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-06 20:04:22.780064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-06 20:04:22.780072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-06 20:04:22.780493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 42, 28, 71)   0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 84, 56, 10)   2850        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 56, 21)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 84, 56, 10)   1900        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 84, 56, 10)   40          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 84, 56, 10)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 84, 56, 10)   910         activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 84, 56, 10)   40          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 56, 10)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 84, 56, 31)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 84, 56, 31)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 84, 56, 13)   416         dropout_5[0][0]                  
==================================================================================================
Total params: 57,666
Trainable params: 57,266
Non-trainable params: 400
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.53807809e-02 2.88974534e-02 1.16728790e-01 1.00198377e-02
 3.03363016e-02 5.79915656e-03 6.86746312e-02 1.28228722e-01
 7.55625878e-02 1.22514673e-02 2.73642650e-01 1.84278063e-01
 1.99559502e-04]
Train on 19871 samples, validate on 569 samples
Epoch 1/300
 - 23s - loss: 96.7971 - acc: 0.7812 - mDice: 0.0160 - val_loss: 9.0534 - val_acc: 0.9112 - val_mDice: 0.0081

Epoch 00001: val_mDice improved from -inf to 0.00805, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 16s - loss: 11.0019 - acc: 0.8916 - mDice: 0.0292 - val_loss: 5.7879 - val_acc: 0.9112 - val_mDice: 0.0455

Epoch 00002: val_mDice improved from 0.00805 to 0.04552, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 14s - loss: 8.3111 - acc: 0.8944 - mDice: 0.0432 - val_loss: 5.3845 - val_acc: 0.9112 - val_mDice: 0.0673

Epoch 00003: val_mDice improved from 0.04552 to 0.06732, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 16s - loss: 7.1574 - acc: 0.8957 - mDice: 0.0616 - val_loss: 4.7537 - val_acc: 0.9111 - val_mDice: 0.0971

Epoch 00004: val_mDice improved from 0.06732 to 0.09714, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 14s - loss: 6.2962 - acc: 0.8987 - mDice: 0.0902 - val_loss: 4.1811 - val_acc: 0.9142 - val_mDice: 0.1374

Epoch 00005: val_mDice improved from 0.09714 to 0.13739, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 15s - loss: 5.6795 - acc: 0.9029 - mDice: 0.1214 - val_loss: 3.7846 - val_acc: 0.9185 - val_mDice: 0.1827

Epoch 00006: val_mDice improved from 0.13739 to 0.18268, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 7/300
 - 15s - loss: 5.2156 - acc: 0.9068 - mDice: 0.1541 - val_loss: 3.4182 - val_acc: 0.9257 - val_mDice: 0.2345

Epoch 00007: val_mDice improved from 0.18268 to 0.23455, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 8/300
 - 14s - loss: 4.8175 - acc: 0.9114 - mDice: 0.1907 - val_loss: 3.0569 - val_acc: 0.9402 - val_mDice: 0.2936

Epoch 00008: val_mDice improved from 0.23455 to 0.29363, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 16s - loss: 4.4808 - acc: 0.9158 - mDice: 0.2264 - val_loss: 2.8648 - val_acc: 0.9362 - val_mDice: 0.3225

Epoch 00009: val_mDice improved from 0.29363 to 0.32250, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 10/300
 - 15s - loss: 4.2491 - acc: 0.9186 - mDice: 0.2517 - val_loss: 2.6876 - val_acc: 0.9363 - val_mDice: 0.3525

Epoch 00010: val_mDice improved from 0.32250 to 0.35253, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 11/300
 - 14s - loss: 4.0370 - acc: 0.9207 - mDice: 0.2772 - val_loss: 2.5126 - val_acc: 0.9420 - val_mDice: 0.3943

Epoch 00011: val_mDice improved from 0.35253 to 0.39426, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 12/300
 - 17s - loss: 3.8293 - acc: 0.9232 - mDice: 0.3034 - val_loss: 2.2872 - val_acc: 0.9544 - val_mDice: 0.4395

Epoch 00012: val_mDice improved from 0.39426 to 0.43946, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 13/300
 - 15s - loss: 3.6547 - acc: 0.9258 - mDice: 0.3260 - val_loss: 2.1568 - val_acc: 0.9585 - val_mDice: 0.4620

Epoch 00013: val_mDice improved from 0.43946 to 0.46199, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 14/300
 - 17s - loss: 3.5019 - acc: 0.9283 - mDice: 0.3459 - val_loss: 2.0749 - val_acc: 0.9618 - val_mDice: 0.4848

Epoch 00014: val_mDice improved from 0.46199 to 0.48485, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 15/300
 - 15s - loss: 3.3627 - acc: 0.9302 - mDice: 0.3636 - val_loss: 2.0279 - val_acc: 0.9631 - val_mDice: 0.4998

Epoch 00015: val_mDice improved from 0.48485 to 0.49975, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 16/300
 - 17s - loss: 3.2413 - acc: 0.9321 - mDice: 0.3799 - val_loss: 1.9370 - val_acc: 0.9652 - val_mDice: 0.5214

Epoch 00016: val_mDice improved from 0.49975 to 0.52136, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 17/300
 - 16s - loss: 3.1276 - acc: 0.9337 - mDice: 0.3949 - val_loss: 1.8335 - val_acc: 0.9661 - val_mDice: 0.5413

Epoch 00017: val_mDice improved from 0.52136 to 0.54131, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 18/300
 - 16s - loss: 3.0143 - acc: 0.9354 - mDice: 0.4099 - val_loss: 1.7773 - val_acc: 0.9673 - val_mDice: 0.5527

Epoch 00018: val_mDice improved from 0.54131 to 0.55266, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 19/300
 - 16s - loss: 2.9141 - acc: 0.9369 - mDice: 0.4243 - val_loss: 1.7167 - val_acc: 0.9677 - val_mDice: 0.5691

Epoch 00019: val_mDice improved from 0.55266 to 0.56914, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 20/300
 - 16s - loss: 2.8248 - acc: 0.9378 - mDice: 0.4379 - val_loss: 1.6684 - val_acc: 0.9679 - val_mDice: 0.5832

Epoch 00020: val_mDice improved from 0.56914 to 0.58318, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 21/300
 - 17s - loss: 2.7337 - acc: 0.9387 - mDice: 0.4525 - val_loss: 1.6256 - val_acc: 0.9678 - val_mDice: 0.5937

Epoch 00021: val_mDice improved from 0.58318 to 0.59367, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 22/300
 - 15s - loss: 2.6452 - acc: 0.9398 - mDice: 0.4686 - val_loss: 1.5977 - val_acc: 0.9688 - val_mDice: 0.6032

Epoch 00022: val_mDice improved from 0.59367 to 0.60324, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 23/300
 - 17s - loss: 2.5711 - acc: 0.9408 - mDice: 0.4805 - val_loss: 1.5578 - val_acc: 0.9695 - val_mDice: 0.6138

Epoch 00023: val_mDice improved from 0.60324 to 0.61378, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 24/300
 - 16s - loss: 2.4949 - acc: 0.9420 - mDice: 0.4930 - val_loss: 1.5313 - val_acc: 0.9692 - val_mDice: 0.6266

Epoch 00024: val_mDice improved from 0.61378 to 0.62663, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 25/300
 - 17s - loss: 2.4499 - acc: 0.9424 - mDice: 0.4991 - val_loss: 1.5275 - val_acc: 0.9696 - val_mDice: 0.6240

Epoch 00025: val_mDice did not improve from 0.62663
Epoch 26/300
 - 16s - loss: 2.3915 - acc: 0.9431 - mDice: 0.5093 - val_loss: 1.5129 - val_acc: 0.9698 - val_mDice: 0.6286

Epoch 00026: val_mDice improved from 0.62663 to 0.62864, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 27/300
 - 17s - loss: 2.3457 - acc: 0.9438 - mDice: 0.5168 - val_loss: 1.4668 - val_acc: 0.9708 - val_mDice: 0.6356

Epoch 00027: val_mDice improved from 0.62864 to 0.63561, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 28/300
 - 15s - loss: 2.2999 - acc: 0.9443 - mDice: 0.5239 - val_loss: 1.4800 - val_acc: 0.9696 - val_mDice: 0.6429

Epoch 00028: val_mDice improved from 0.63561 to 0.64287, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 29/300
 - 17s - loss: 2.2684 - acc: 0.9447 - mDice: 0.5300 - val_loss: 1.4609 - val_acc: 0.9705 - val_mDice: 0.6439

Epoch 00029: val_mDice improved from 0.64287 to 0.64387, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 30/300
 - 14s - loss: 2.2260 - acc: 0.9454 - mDice: 0.5369 - val_loss: 1.4454 - val_acc: 0.9712 - val_mDice: 0.6486

Epoch 00030: val_mDice improved from 0.64387 to 0.64861, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 31/300
 - 16s - loss: 2.1937 - acc: 0.9459 - mDice: 0.5429 - val_loss: 1.4177 - val_acc: 0.9721 - val_mDice: 0.6550

Epoch 00031: val_mDice improved from 0.64861 to 0.65495, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 32/300
 - 14s - loss: 2.1659 - acc: 0.9463 - mDice: 0.5480 - val_loss: 1.4189 - val_acc: 0.9720 - val_mDice: 0.6580

Epoch 00032: val_mDice improved from 0.65495 to 0.65802, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 33/300
 - 14s - loss: 2.1379 - acc: 0.9467 - mDice: 0.5529 - val_loss: 1.3917 - val_acc: 0.9715 - val_mDice: 0.6606

Epoch 00033: val_mDice improved from 0.65802 to 0.66059, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 34/300
 - 15s - loss: 2.1087 - acc: 0.9473 - mDice: 0.5588 - val_loss: 1.4067 - val_acc: 0.9716 - val_mDice: 0.6607

Epoch 00034: val_mDice improved from 0.66059 to 0.66075, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 35/300
 - 15s - loss: 2.0872 - acc: 0.9475 - mDice: 0.5630 - val_loss: 1.3806 - val_acc: 0.9711 - val_mDice: 0.6649

Epoch 00035: val_mDice improved from 0.66075 to 0.66488, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 36/300
 - 14s - loss: 2.0609 - acc: 0.9478 - mDice: 0.5673 - val_loss: 1.3785 - val_acc: 0.9718 - val_mDice: 0.6672

Epoch 00036: val_mDice improved from 0.66488 to 0.66723, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 37/300
 - 14s - loss: 2.0320 - acc: 0.9483 - mDice: 0.5733 - val_loss: 1.3658 - val_acc: 0.9721 - val_mDice: 0.6728

Epoch 00037: val_mDice improved from 0.66723 to 0.67285, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 38/300
 - 14s - loss: 2.0168 - acc: 0.9485 - mDice: 0.5761 - val_loss: 1.3519 - val_acc: 0.9724 - val_mDice: 0.6744

Epoch 00038: val_mDice improved from 0.67285 to 0.67436, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 39/300
 - 15s - loss: 1.9963 - acc: 0.9487 - mDice: 0.5805 - val_loss: 1.3477 - val_acc: 0.9724 - val_mDice: 0.6799

Epoch 00039: val_mDice improved from 0.67436 to 0.67987, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 40/300
 - 15s - loss: 1.9795 - acc: 0.9489 - mDice: 0.5830 - val_loss: 1.3284 - val_acc: 0.9724 - val_mDice: 0.6790

Epoch 00040: val_mDice did not improve from 0.67987
Epoch 41/300
 - 14s - loss: 1.9553 - acc: 0.9493 - mDice: 0.5881 - val_loss: 1.3317 - val_acc: 0.9729 - val_mDice: 0.6779

Epoch 00041: val_mDice did not improve from 0.67987
Epoch 42/300
 - 14s - loss: 1.9435 - acc: 0.9494 - mDice: 0.5903 - val_loss: 1.3336 - val_acc: 0.9729 - val_mDice: 0.6799

Epoch 00042: val_mDice improved from 0.67987 to 0.67987, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 43/300
 - 14s - loss: 1.9340 - acc: 0.9494 - mDice: 0.5922 - val_loss: 1.3113 - val_acc: 0.9728 - val_mDice: 0.6839

Epoch 00043: val_mDice improved from 0.67987 to 0.68393, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 44/300
 - 15s - loss: 1.9111 - acc: 0.9498 - mDice: 0.5964 - val_loss: 1.3101 - val_acc: 0.9725 - val_mDice: 0.6857

Epoch 00044: val_mDice improved from 0.68393 to 0.68570, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 45/300
 - 14s - loss: 1.8926 - acc: 0.9502 - mDice: 0.5996 - val_loss: 1.2995 - val_acc: 0.9725 - val_mDice: 0.6878

Epoch 00045: val_mDice improved from 0.68570 to 0.68784, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 46/300
 - 14s - loss: 1.8766 - acc: 0.9505 - mDice: 0.6034 - val_loss: 1.3194 - val_acc: 0.9728 - val_mDice: 0.6860

Epoch 00046: val_mDice did not improve from 0.68784
Epoch 47/300
 - 14s - loss: 1.8617 - acc: 0.9508 - mDice: 0.6065 - val_loss: 1.2983 - val_acc: 0.9723 - val_mDice: 0.6892

Epoch 00047: val_mDice improved from 0.68784 to 0.68921, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 48/300
 - 14s - loss: 1.8617 - acc: 0.9509 - mDice: 0.6067 - val_loss: 1.2941 - val_acc: 0.9722 - val_mDice: 0.6917

Epoch 00048: val_mDice improved from 0.68921 to 0.69168, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 49/300
 - 14s - loss: 1.8368 - acc: 0.9512 - mDice: 0.6113 - val_loss: 1.3156 - val_acc: 0.9725 - val_mDice: 0.6904

Epoch 00049: val_mDice did not improve from 0.69168
Epoch 50/300
 - 15s - loss: 1.8250 - acc: 0.9515 - mDice: 0.6134 - val_loss: 1.2848 - val_acc: 0.9726 - val_mDice: 0.6972

Epoch 00050: val_mDice improved from 0.69168 to 0.69723, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 51/300
 - 15s - loss: 1.8151 - acc: 0.9516 - mDice: 0.6154 - val_loss: 1.2885 - val_acc: 0.9730 - val_mDice: 0.6996

Epoch 00051: val_mDice improved from 0.69723 to 0.69958, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 52/300
 - 14s - loss: 1.8069 - acc: 0.9518 - mDice: 0.6173 - val_loss: 1.2738 - val_acc: 0.9734 - val_mDice: 0.6951

Epoch 00052: val_mDice did not improve from 0.69958
Epoch 53/300
 - 14s - loss: 1.7979 - acc: 0.9519 - mDice: 0.6190 - val_loss: 1.2704 - val_acc: 0.9734 - val_mDice: 0.6954

Epoch 00053: val_mDice did not improve from 0.69958
Epoch 54/300
 - 16s - loss: 1.7906 - acc: 0.9520 - mDice: 0.6204 - val_loss: 1.2982 - val_acc: 0.9723 - val_mDice: 0.6966

Epoch 00054: val_mDice did not improve from 0.69958
Epoch 55/300
 - 14s - loss: 1.7739 - acc: 0.9524 - mDice: 0.6234 - val_loss: 1.2782 - val_acc: 0.9736 - val_mDice: 0.6966

Epoch 00055: val_mDice did not improve from 0.69958
Epoch 56/300
 - 15s - loss: 1.7712 - acc: 0.9525 - mDice: 0.6244 - val_loss: 1.2619 - val_acc: 0.9734 - val_mDice: 0.6993

Epoch 00056: val_mDice did not improve from 0.69958
Epoch 57/300
 - 15s - loss: 1.7598 - acc: 0.9526 - mDice: 0.6265 - val_loss: 1.2557 - val_acc: 0.9737 - val_mDice: 0.7029

Epoch 00057: val_mDice improved from 0.69958 to 0.70289, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 58/300
 - 15s - loss: 1.7508 - acc: 0.9528 - mDice: 0.6284 - val_loss: 1.2545 - val_acc: 0.9736 - val_mDice: 0.6998

Epoch 00058: val_mDice did not improve from 0.70289
Epoch 59/300
 - 16s - loss: 1.7427 - acc: 0.9529 - mDice: 0.6296 - val_loss: 1.2613 - val_acc: 0.9743 - val_mDice: 0.7022

Epoch 00059: val_mDice did not improve from 0.70289
Epoch 60/300
 - 14s - loss: 1.7393 - acc: 0.9530 - mDice: 0.6307 - val_loss: 1.2644 - val_acc: 0.9735 - val_mDice: 0.6984

Epoch 00060: val_mDice did not improve from 0.70289
Epoch 61/300
 - 16s - loss: 1.7264 - acc: 0.9532 - mDice: 0.6328 - val_loss: 1.2411 - val_acc: 0.9742 - val_mDice: 0.7010

Epoch 00061: val_mDice did not improve from 0.70289
Epoch 62/300
 - 14s - loss: 1.7288 - acc: 0.9531 - mDice: 0.6326 - val_loss: 1.2331 - val_acc: 0.9745 - val_mDice: 0.7052

Epoch 00062: val_mDice improved from 0.70289 to 0.70521, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 63/300
 - 15s - loss: 1.7195 - acc: 0.9533 - mDice: 0.6346 - val_loss: 1.2485 - val_acc: 0.9741 - val_mDice: 0.7054

Epoch 00063: val_mDice improved from 0.70521 to 0.70541, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 64/300
 - 16s - loss: 1.7065 - acc: 0.9534 - mDice: 0.6369 - val_loss: 1.2451 - val_acc: 0.9741 - val_mDice: 0.7042

Epoch 00064: val_mDice did not improve from 0.70541
Epoch 65/300
 - 14s - loss: 1.6998 - acc: 0.9536 - mDice: 0.6385 - val_loss: 1.2506 - val_acc: 0.9744 - val_mDice: 0.7025

Epoch 00065: val_mDice did not improve from 0.70541
Epoch 66/300
 - 16s - loss: 1.6970 - acc: 0.9537 - mDice: 0.6388 - val_loss: 1.2174 - val_acc: 0.9745 - val_mDice: 0.7064

Epoch 00066: val_mDice improved from 0.70541 to 0.70643, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 67/300
 - 14s - loss: 1.6962 - acc: 0.9537 - mDice: 0.6389 - val_loss: 1.2519 - val_acc: 0.9744 - val_mDice: 0.7051

Epoch 00067: val_mDice did not improve from 0.70643
Epoch 68/300
 - 16s - loss: 1.6842 - acc: 0.9539 - mDice: 0.6412 - val_loss: 1.2326 - val_acc: 0.9743 - val_mDice: 0.7095

Epoch 00068: val_mDice improved from 0.70643 to 0.70946, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 69/300
 - 15s - loss: 1.6837 - acc: 0.9540 - mDice: 0.6414 - val_loss: 1.2496 - val_acc: 0.9740 - val_mDice: 0.7095

Epoch 00069: val_mDice improved from 0.70946 to 0.70949, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 70/300
 - 15s - loss: 1.6761 - acc: 0.9541 - mDice: 0.6429 - val_loss: 1.2336 - val_acc: 0.9743 - val_mDice: 0.7094

Epoch 00070: val_mDice did not improve from 0.70949
Epoch 71/300
 - 16s - loss: 1.6767 - acc: 0.9541 - mDice: 0.6433 - val_loss: 1.2191 - val_acc: 0.9752 - val_mDice: 0.7077

Epoch 00071: val_mDice did not improve from 0.70949
Epoch 72/300
 - 15s - loss: 1.6650 - acc: 0.9543 - mDice: 0.6455 - val_loss: 1.2246 - val_acc: 0.9745 - val_mDice: 0.7105

Epoch 00072: val_mDice improved from 0.70949 to 0.71054, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 73/300
 - 16s - loss: 1.6621 - acc: 0.9544 - mDice: 0.6459 - val_loss: 1.2271 - val_acc: 0.9746 - val_mDice: 0.7106

Epoch 00073: val_mDice improved from 0.71054 to 0.71056, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 74/300
 - 14s - loss: 1.6635 - acc: 0.9543 - mDice: 0.6456 - val_loss: 1.2296 - val_acc: 0.9751 - val_mDice: 0.7123

Epoch 00074: val_mDice improved from 0.71056 to 0.71233, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 75/300
 - 16s - loss: 1.6552 - acc: 0.9545 - mDice: 0.6473 - val_loss: 1.2109 - val_acc: 0.9751 - val_mDice: 0.7111

Epoch 00075: val_mDice did not improve from 0.71233
Epoch 76/300
 - 14s - loss: 1.6548 - acc: 0.9545 - mDice: 0.6476 - val_loss: 1.2186 - val_acc: 0.9752 - val_mDice: 0.7116

Epoch 00076: val_mDice did not improve from 0.71233
Epoch 77/300
 - 16s - loss: 1.6422 - acc: 0.9547 - mDice: 0.6497 - val_loss: 1.2296 - val_acc: 0.9750 - val_mDice: 0.7083

Epoch 00077: val_mDice did not improve from 0.71233
Epoch 78/300
 - 14s - loss: 1.6388 - acc: 0.9547 - mDice: 0.6504 - val_loss: 1.2124 - val_acc: 0.9755 - val_mDice: 0.7128

Epoch 00078: val_mDice improved from 0.71233 to 0.71280, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 79/300
 - 16s - loss: 1.6376 - acc: 0.9548 - mDice: 0.6510 - val_loss: 1.2129 - val_acc: 0.9752 - val_mDice: 0.7152

Epoch 00079: val_mDice improved from 0.71280 to 0.71519, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 80/300
 - 15s - loss: 1.6394 - acc: 0.9547 - mDice: 0.6504 - val_loss: 1.1990 - val_acc: 0.9750 - val_mDice: 0.7172

Epoch 00080: val_mDice improved from 0.71519 to 0.71723, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 81/300
 - 15s - loss: 1.6267 - acc: 0.9549 - mDice: 0.6530 - val_loss: 1.2209 - val_acc: 0.9753 - val_mDice: 0.7106

Epoch 00081: val_mDice did not improve from 0.71723
Epoch 82/300
 - 16s - loss: 1.6307 - acc: 0.9548 - mDice: 0.6522 - val_loss: 1.1908 - val_acc: 0.9750 - val_mDice: 0.7158

Epoch 00082: val_mDice did not improve from 0.71723
Epoch 83/300
 - 14s - loss: 1.6208 - acc: 0.9549 - mDice: 0.6540 - val_loss: 1.2060 - val_acc: 0.9746 - val_mDice: 0.7156

Epoch 00083: val_mDice did not improve from 0.71723
Epoch 84/300
 - 17s - loss: 1.6177 - acc: 0.9550 - mDice: 0.6552 - val_loss: 1.2142 - val_acc: 0.9751 - val_mDice: 0.7126

Epoch 00084: val_mDice did not improve from 0.71723
Epoch 85/300
 - 15s - loss: 1.6151 - acc: 0.9551 - mDice: 0.6553 - val_loss: 1.2400 - val_acc: 0.9746 - val_mDice: 0.7132

Epoch 00085: val_mDice did not improve from 0.71723
Epoch 86/300
 - 18s - loss: 1.6094 - acc: 0.9552 - mDice: 0.6565 - val_loss: 1.1875 - val_acc: 0.9751 - val_mDice: 0.7202

Epoch 00086: val_mDice improved from 0.71723 to 0.72025, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 87/300
 - 15s - loss: 1.6060 - acc: 0.9552 - mDice: 0.6575 - val_loss: 1.2064 - val_acc: 0.9743 - val_mDice: 0.7158

Epoch 00087: val_mDice did not improve from 0.72025
Epoch 88/300
 - 17s - loss: 1.6074 - acc: 0.9552 - mDice: 0.6570 - val_loss: 1.1955 - val_acc: 0.9751 - val_mDice: 0.7170

Epoch 00088: val_mDice did not improve from 0.72025
Epoch 89/300
 - 16s - loss: 1.6083 - acc: 0.9551 - mDice: 0.6565 - val_loss: 1.2158 - val_acc: 0.9753 - val_mDice: 0.7202

Epoch 00089: val_mDice did not improve from 0.72025
Epoch 90/300
 - 18s - loss: 1.5946 - acc: 0.9553 - mDice: 0.6590 - val_loss: 1.1980 - val_acc: 0.9755 - val_mDice: 0.7148

Epoch 00090: val_mDice did not improve from 0.72025
Epoch 91/300
 - 16s - loss: 1.5978 - acc: 0.9553 - mDice: 0.6590 - val_loss: 1.2160 - val_acc: 0.9752 - val_mDice: 0.7112

Epoch 00091: val_mDice did not improve from 0.72025
Epoch 92/300
 - 17s - loss: 1.5924 - acc: 0.9555 - mDice: 0.6602 - val_loss: 1.1934 - val_acc: 0.9754 - val_mDice: 0.7203

Epoch 00092: val_mDice improved from 0.72025 to 0.72034, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 93/300
 - 17s - loss: 1.5881 - acc: 0.9555 - mDice: 0.6608 - val_loss: 1.2261 - val_acc: 0.9749 - val_mDice: 0.7140

Epoch 00093: val_mDice did not improve from 0.72034
Epoch 94/300
 - 16s - loss: 1.5834 - acc: 0.9556 - mDice: 0.6621 - val_loss: 1.1932 - val_acc: 0.9754 - val_mDice: 0.7185

Epoch 00094: val_mDice did not improve from 0.72034
Epoch 95/300
 - 18s - loss: 1.5808 - acc: 0.9556 - mDice: 0.6621 - val_loss: 1.2019 - val_acc: 0.9755 - val_mDice: 0.7155

Epoch 00095: val_mDice did not improve from 0.72034
Epoch 96/300
 - 16s - loss: 1.5824 - acc: 0.9556 - mDice: 0.6623 - val_loss: 1.1837 - val_acc: 0.9754 - val_mDice: 0.7209

Epoch 00096: val_mDice improved from 0.72034 to 0.72090, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 97/300
 - 18s - loss: 1.5781 - acc: 0.9557 - mDice: 0.6629 - val_loss: 1.2265 - val_acc: 0.9748 - val_mDice: 0.7119

Epoch 00097: val_mDice did not improve from 0.72090
Epoch 98/300
 - 16s - loss: 1.5798 - acc: 0.9557 - mDice: 0.6627 - val_loss: 1.2141 - val_acc: 0.9751 - val_mDice: 0.7190

Epoch 00098: val_mDice did not improve from 0.72090
Epoch 99/300
 - 18s - loss: 1.5788 - acc: 0.9557 - mDice: 0.6629 - val_loss: 1.1923 - val_acc: 0.9753 - val_mDice: 0.7209

Epoch 00099: val_mDice did not improve from 0.72090
Epoch 100/300
 - 16s - loss: 1.5699 - acc: 0.9559 - mDice: 0.6647 - val_loss: 1.2100 - val_acc: 0.9753 - val_mDice: 0.7185

Epoch 00100: val_mDice did not improve from 0.72090
Epoch 101/300
 - 17s - loss: 1.5687 - acc: 0.9559 - mDice: 0.6647 - val_loss: 1.1787 - val_acc: 0.9755 - val_mDice: 0.7238

Epoch 00101: val_mDice improved from 0.72090 to 0.72383, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 102/300
 - 16s - loss: 1.5698 - acc: 0.9559 - mDice: 0.6643 - val_loss: 1.1827 - val_acc: 0.9757 - val_mDice: 0.7202

Epoch 00102: val_mDice did not improve from 0.72383
Epoch 103/300
 - 15s - loss: 1.5662 - acc: 0.9559 - mDice: 0.6656 - val_loss: 1.1919 - val_acc: 0.9758 - val_mDice: 0.7180

Epoch 00103: val_mDice did not improve from 0.72383
Epoch 104/300
 - 15s - loss: 1.5633 - acc: 0.9560 - mDice: 0.6658 - val_loss: 1.2038 - val_acc: 0.9750 - val_mDice: 0.7198

Epoch 00104: val_mDice did not improve from 0.72383
Epoch 105/300
 - 16s - loss: 1.5590 - acc: 0.9560 - mDice: 0.6666 - val_loss: 1.2175 - val_acc: 0.9752 - val_mDice: 0.7167

Epoch 00105: val_mDice did not improve from 0.72383
Epoch 106/300
 - 14s - loss: 1.5584 - acc: 0.9561 - mDice: 0.6671 - val_loss: 1.1895 - val_acc: 0.9757 - val_mDice: 0.7217

Epoch 00106: val_mDice did not improve from 0.72383
Epoch 107/300
 - 15s - loss: 1.5579 - acc: 0.9561 - mDice: 0.6672 - val_loss: 1.1623 - val_acc: 0.9757 - val_mDice: 0.7215

Epoch 00107: val_mDice did not improve from 0.72383
Epoch 108/300
 - 16s - loss: 1.5515 - acc: 0.9562 - mDice: 0.6681 - val_loss: 1.1939 - val_acc: 0.9757 - val_mDice: 0.7204

Epoch 00108: val_mDice did not improve from 0.72383
Epoch 109/300
 - 14s - loss: 1.5495 - acc: 0.9562 - mDice: 0.6686 - val_loss: 1.2236 - val_acc: 0.9754 - val_mDice: 0.7209

Epoch 00109: val_mDice did not improve from 0.72383
Epoch 110/300
 - 15s - loss: 1.5513 - acc: 0.9562 - mDice: 0.6689 - val_loss: 1.1996 - val_acc: 0.9752 - val_mDice: 0.7156

Epoch 00110: val_mDice did not improve from 0.72383
Epoch 111/300
 - 14s - loss: 1.5479 - acc: 0.9562 - mDice: 0.6691 - val_loss: 1.1828 - val_acc: 0.9754 - val_mDice: 0.7231

Epoch 00111: val_mDice did not improve from 0.72383
Epoch 112/300
 - 14s - loss: 1.5499 - acc: 0.9562 - mDice: 0.6687 - val_loss: 1.1885 - val_acc: 0.9754 - val_mDice: 0.7231

Epoch 00112: val_mDice did not improve from 0.72383
Epoch 113/300
 - 14s - loss: 1.5460 - acc: 0.9563 - mDice: 0.6693 - val_loss: 1.1868 - val_acc: 0.9756 - val_mDice: 0.7213

Epoch 00113: val_mDice did not improve from 0.72383
Epoch 114/300
 - 15s - loss: 1.5435 - acc: 0.9563 - mDice: 0.6699 - val_loss: 1.1664 - val_acc: 0.9757 - val_mDice: 0.7234

Epoch 00114: val_mDice did not improve from 0.72383
Epoch 115/300
 - 14s - loss: 1.5448 - acc: 0.9563 - mDice: 0.6699 - val_loss: 1.1807 - val_acc: 0.9757 - val_mDice: 0.7239

Epoch 00115: val_mDice improved from 0.72383 to 0.72390, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 116/300
 - 14s - loss: 1.5374 - acc: 0.9565 - mDice: 0.6711 - val_loss: 1.1843 - val_acc: 0.9756 - val_mDice: 0.7234

Epoch 00116: val_mDice did not improve from 0.72390
Epoch 117/300
 - 14s - loss: 1.5385 - acc: 0.9564 - mDice: 0.6710 - val_loss: 1.1880 - val_acc: 0.9751 - val_mDice: 0.7191

Epoch 00117: val_mDice did not improve from 0.72390
Epoch 118/300
 - 15s - loss: 1.5358 - acc: 0.9565 - mDice: 0.6713 - val_loss: 1.1782 - val_acc: 0.9753 - val_mDice: 0.7268

Epoch 00118: val_mDice improved from 0.72390 to 0.72681, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 119/300
 - 15s - loss: 1.5346 - acc: 0.9565 - mDice: 0.6718 - val_loss: 1.1854 - val_acc: 0.9755 - val_mDice: 0.7194

Epoch 00119: val_mDice did not improve from 0.72681
Epoch 120/300
 - 14s - loss: 1.5387 - acc: 0.9564 - mDice: 0.6712 - val_loss: 1.1810 - val_acc: 0.9760 - val_mDice: 0.7260

Epoch 00120: val_mDice did not improve from 0.72681
Epoch 121/300
 - 14s - loss: 1.5354 - acc: 0.9565 - mDice: 0.6717 - val_loss: 1.1676 - val_acc: 0.9760 - val_mDice: 0.7281

Epoch 00121: val_mDice improved from 0.72681 to 0.72807, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 122/300
 - 15s - loss: 1.5294 - acc: 0.9565 - mDice: 0.6731 - val_loss: 1.1595 - val_acc: 0.9760 - val_mDice: 0.7302

Epoch 00122: val_mDice improved from 0.72807 to 0.73024, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 123/300
 - 15s - loss: 1.5255 - acc: 0.9566 - mDice: 0.6737 - val_loss: 1.1667 - val_acc: 0.9759 - val_mDice: 0.7258

Epoch 00123: val_mDice did not improve from 0.73024
Epoch 124/300
 - 14s - loss: 1.5250 - acc: 0.9566 - mDice: 0.6739 - val_loss: 1.1667 - val_acc: 0.9759 - val_mDice: 0.7250

Epoch 00124: val_mDice did not improve from 0.73024
Epoch 125/300
 - 14s - loss: 1.5330 - acc: 0.9565 - mDice: 0.6724 - val_loss: 1.1731 - val_acc: 0.9756 - val_mDice: 0.7215

Epoch 00125: val_mDice did not improve from 0.73024
Epoch 126/300
 - 14s - loss: 1.5255 - acc: 0.9566 - mDice: 0.6735 - val_loss: 1.1721 - val_acc: 0.9753 - val_mDice: 0.7257

Epoch 00126: val_mDice did not improve from 0.73024
Epoch 127/300
 - 15s - loss: 1.5270 - acc: 0.9565 - mDice: 0.6734 - val_loss: 1.1965 - val_acc: 0.9750 - val_mDice: 0.7211

Epoch 00127: val_mDice did not improve from 0.73024
Epoch 128/300
 - 15s - loss: 1.5226 - acc: 0.9566 - mDice: 0.6743 - val_loss: 1.1712 - val_acc: 0.9759 - val_mDice: 0.7263

Epoch 00128: val_mDice did not improve from 0.73024
Epoch 129/300
 - 14s - loss: 1.5192 - acc: 0.9567 - mDice: 0.6747 - val_loss: 1.1918 - val_acc: 0.9758 - val_mDice: 0.7219

Epoch 00129: val_mDice did not improve from 0.73024
Epoch 130/300
 - 14s - loss: 1.5190 - acc: 0.9568 - mDice: 0.6753 - val_loss: 1.1597 - val_acc: 0.9758 - val_mDice: 0.7265

Epoch 00130: val_mDice did not improve from 0.73024
Epoch 131/300
 - 14s - loss: 1.5208 - acc: 0.9567 - mDice: 0.6748 - val_loss: 1.1757 - val_acc: 0.9757 - val_mDice: 0.7245

Epoch 00131: val_mDice did not improve from 0.73024
Epoch 132/300
 - 14s - loss: 1.5184 - acc: 0.9568 - mDice: 0.6753 - val_loss: 1.1773 - val_acc: 0.9761 - val_mDice: 0.7241

Epoch 00132: val_mDice did not improve from 0.73024
Epoch 133/300
 - 15s - loss: 1.5175 - acc: 0.9568 - mDice: 0.6752 - val_loss: 1.1832 - val_acc: 0.9756 - val_mDice: 0.7224

Epoch 00133: val_mDice did not improve from 0.73024
Epoch 134/300
 - 15s - loss: 1.5183 - acc: 0.9568 - mDice: 0.6753 - val_loss: 1.1576 - val_acc: 0.9760 - val_mDice: 0.7274

Epoch 00134: val_mDice did not improve from 0.73024
Epoch 135/300
 - 14s - loss: 1.5154 - acc: 0.9568 - mDice: 0.6755 - val_loss: 1.1753 - val_acc: 0.9757 - val_mDice: 0.7215

Epoch 00135: val_mDice did not improve from 0.73024
Epoch 136/300
 - 14s - loss: 1.5123 - acc: 0.9568 - mDice: 0.6762 - val_loss: 1.1740 - val_acc: 0.9757 - val_mDice: 0.7265

Epoch 00136: val_mDice did not improve from 0.73024
Epoch 137/300
 - 14s - loss: 1.5099 - acc: 0.9569 - mDice: 0.6771 - val_loss: 1.1621 - val_acc: 0.9759 - val_mDice: 0.7296

Epoch 00137: val_mDice did not improve from 0.73024
Epoch 138/300
 - 14s - loss: 1.5131 - acc: 0.9568 - mDice: 0.6762 - val_loss: 1.1853 - val_acc: 0.9757 - val_mDice: 0.7230

Epoch 00138: val_mDice did not improve from 0.73024
Epoch 139/300
 - 14s - loss: 1.5105 - acc: 0.9568 - mDice: 0.6769 - val_loss: 1.1832 - val_acc: 0.9758 - val_mDice: 0.7238

Epoch 00139: val_mDice did not improve from 0.73024
Epoch 140/300
 - 16s - loss: 1.5116 - acc: 0.9569 - mDice: 0.6764 - val_loss: 1.1622 - val_acc: 0.9756 - val_mDice: 0.7246

Epoch 00140: val_mDice did not improve from 0.73024
Epoch 141/300
 - 14s - loss: 1.5085 - acc: 0.9569 - mDice: 0.6775 - val_loss: 1.1569 - val_acc: 0.9758 - val_mDice: 0.7263

Epoch 00141: val_mDice did not improve from 0.73024
Epoch 142/300
 - 15s - loss: 1.5040 - acc: 0.9570 - mDice: 0.6780 - val_loss: 1.1567 - val_acc: 0.9757 - val_mDice: 0.7271

Epoch 00142: val_mDice did not improve from 0.73024
Epoch 143/300
 - 15s - loss: 1.5068 - acc: 0.9569 - mDice: 0.6773 - val_loss: 1.1457 - val_acc: 0.9760 - val_mDice: 0.7302

Epoch 00143: val_mDice did not improve from 0.73024
Epoch 144/300
 - 14s - loss: 1.5071 - acc: 0.9569 - mDice: 0.6778 - val_loss: 1.1556 - val_acc: 0.9758 - val_mDice: 0.7307

Epoch 00144: val_mDice improved from 0.73024 to 0.73068, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 145/300
 - 14s - loss: 1.5040 - acc: 0.9569 - mDice: 0.6778 - val_loss: 1.1640 - val_acc: 0.9759 - val_mDice: 0.7291

Epoch 00145: val_mDice did not improve from 0.73068
Epoch 146/300
 - 14s - loss: 1.5062 - acc: 0.9569 - mDice: 0.6777 - val_loss: 1.1590 - val_acc: 0.9760 - val_mDice: 0.7285

Epoch 00146: val_mDice did not improve from 0.73068
Epoch 147/300
 - 15s - loss: 1.5010 - acc: 0.9570 - mDice: 0.6784 - val_loss: 1.1527 - val_acc: 0.9759 - val_mDice: 0.7289

Epoch 00147: val_mDice did not improve from 0.73068
Epoch 148/300
 - 15s - loss: 1.5009 - acc: 0.9571 - mDice: 0.6789 - val_loss: 1.1544 - val_acc: 0.9760 - val_mDice: 0.7302

Epoch 00148: val_mDice did not improve from 0.73068
Epoch 149/300
 - 14s - loss: 1.4985 - acc: 0.9571 - mDice: 0.6791 - val_loss: 1.1607 - val_acc: 0.9759 - val_mDice: 0.7258

Epoch 00149: val_mDice did not improve from 0.73068
Epoch 150/300
 - 14s - loss: 1.4975 - acc: 0.9571 - mDice: 0.6794 - val_loss: 1.1642 - val_acc: 0.9758 - val_mDice: 0.7291

Epoch 00150: val_mDice did not improve from 0.73068
Epoch 151/300
 - 14s - loss: 1.4937 - acc: 0.9571 - mDice: 0.6803 - val_loss: 1.1469 - val_acc: 0.9760 - val_mDice: 0.7283

Epoch 00151: val_mDice did not improve from 0.73068
Epoch 152/300
 - 14s - loss: 1.4988 - acc: 0.9570 - mDice: 0.6788 - val_loss: 1.1577 - val_acc: 0.9761 - val_mDice: 0.7298

Epoch 00152: val_mDice did not improve from 0.73068
Epoch 153/300
 - 15s - loss: 1.4939 - acc: 0.9571 - mDice: 0.6799 - val_loss: 1.1415 - val_acc: 0.9759 - val_mDice: 0.7337

Epoch 00153: val_mDice improved from 0.73068 to 0.73375, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 154/300
 - 16s - loss: 1.4954 - acc: 0.9571 - mDice: 0.6800 - val_loss: 1.1565 - val_acc: 0.9759 - val_mDice: 0.7309

Epoch 00154: val_mDice did not improve from 0.73375
Epoch 155/300
 - 15s - loss: 1.4893 - acc: 0.9572 - mDice: 0.6811 - val_loss: 1.1615 - val_acc: 0.9755 - val_mDice: 0.7304

Epoch 00155: val_mDice did not improve from 0.73375
Epoch 156/300
 - 15s - loss: 1.4936 - acc: 0.9571 - mDice: 0.6801 - val_loss: 1.1518 - val_acc: 0.9760 - val_mDice: 0.7292

Epoch 00156: val_mDice did not improve from 0.73375
Epoch 157/300
 - 15s - loss: 1.4889 - acc: 0.9572 - mDice: 0.6812 - val_loss: 1.1658 - val_acc: 0.9758 - val_mDice: 0.7290

Epoch 00157: val_mDice did not improve from 0.73375
Epoch 158/300
 - 15s - loss: 1.4946 - acc: 0.9571 - mDice: 0.6801 - val_loss: 1.1520 - val_acc: 0.9762 - val_mDice: 0.7268

Epoch 00158: val_mDice did not improve from 0.73375
Epoch 159/300
 - 15s - loss: 1.4931 - acc: 0.9572 - mDice: 0.6802 - val_loss: 1.1421 - val_acc: 0.9761 - val_mDice: 0.7325

Epoch 00159: val_mDice did not improve from 0.73375
Epoch 160/300
 - 15s - loss: 1.4942 - acc: 0.9570 - mDice: 0.6803 - val_loss: 1.1678 - val_acc: 0.9761 - val_mDice: 0.7323

Epoch 00160: val_mDice did not improve from 0.73375
Epoch 161/300
 - 17s - loss: 1.4872 - acc: 0.9571 - mDice: 0.6814 - val_loss: 1.1625 - val_acc: 0.9754 - val_mDice: 0.7312

Epoch 00161: val_mDice did not improve from 0.73375
Epoch 162/300
 - 15s - loss: 1.4883 - acc: 0.9572 - mDice: 0.6812 - val_loss: 1.1578 - val_acc: 0.9755 - val_mDice: 0.7306

Epoch 00162: val_mDice did not improve from 0.73375
Epoch 163/300
 - 15s - loss: 1.4853 - acc: 0.9572 - mDice: 0.6819 - val_loss: 1.1574 - val_acc: 0.9758 - val_mDice: 0.7327

Epoch 00163: val_mDice did not improve from 0.73375
Epoch 164/300
 - 15s - loss: 1.4862 - acc: 0.9572 - mDice: 0.6817 - val_loss: 1.1539 - val_acc: 0.9756 - val_mDice: 0.7305

Epoch 00164: val_mDice did not improve from 0.73375
Epoch 165/300
 - 15s - loss: 1.4845 - acc: 0.9572 - mDice: 0.6821 - val_loss: 1.1637 - val_acc: 0.9760 - val_mDice: 0.7297

Epoch 00165: val_mDice did not improve from 0.73375
Epoch 166/300
 - 15s - loss: 1.4833 - acc: 0.9572 - mDice: 0.6824 - val_loss: 1.1866 - val_acc: 0.9756 - val_mDice: 0.7256

Epoch 00166: val_mDice did not improve from 0.73375
Epoch 167/300
 - 16s - loss: 1.4853 - acc: 0.9572 - mDice: 0.6821 - val_loss: 1.1564 - val_acc: 0.9762 - val_mDice: 0.7303

Epoch 00167: val_mDice did not improve from 0.73375
Epoch 168/300
 - 15s - loss: 1.4796 - acc: 0.9573 - mDice: 0.6829 - val_loss: 1.1659 - val_acc: 0.9755 - val_mDice: 0.7296

Epoch 00168: val_mDice did not improve from 0.73375
Epoch 169/300
 - 15s - loss: 1.4807 - acc: 0.9573 - mDice: 0.6824 - val_loss: 1.1587 - val_acc: 0.9756 - val_mDice: 0.7349

Epoch 00169: val_mDice improved from 0.73375 to 0.73495, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 170/300
 - 15s - loss: 1.4790 - acc: 0.9574 - mDice: 0.6835 - val_loss: 1.1410 - val_acc: 0.9762 - val_mDice: 0.7324

Epoch 00170: val_mDice did not improve from 0.73495
Epoch 171/300
 - 15s - loss: 1.4787 - acc: 0.9573 - mDice: 0.6835 - val_loss: 1.1489 - val_acc: 0.9762 - val_mDice: 0.7338

Epoch 00171: val_mDice did not improve from 0.73495
Epoch 172/300
 - 16s - loss: 1.4811 - acc: 0.9573 - mDice: 0.6824 - val_loss: 1.1479 - val_acc: 0.9762 - val_mDice: 0.7353

Epoch 00172: val_mDice improved from 0.73495 to 0.73529, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 173/300
 - 15s - loss: 1.4841 - acc: 0.9572 - mDice: 0.6820 - val_loss: 1.1674 - val_acc: 0.9755 - val_mDice: 0.7324

Epoch 00173: val_mDice did not improve from 0.73529
Epoch 174/300
 - 15s - loss: 1.4759 - acc: 0.9574 - mDice: 0.6840 - val_loss: 1.1547 - val_acc: 0.9760 - val_mDice: 0.7326

Epoch 00174: val_mDice did not improve from 0.73529
Epoch 175/300
 - 15s - loss: 1.4752 - acc: 0.9574 - mDice: 0.6840 - val_loss: 1.1507 - val_acc: 0.9761 - val_mDice: 0.7334

Epoch 00175: val_mDice did not improve from 0.73529
Epoch 176/300
 - 15s - loss: 1.4744 - acc: 0.9574 - mDice: 0.6839 - val_loss: 1.1443 - val_acc: 0.9761 - val_mDice: 0.7319

Epoch 00176: val_mDice did not improve from 0.73529
Epoch 177/300
 - 15s - loss: 1.4777 - acc: 0.9574 - mDice: 0.6833 - val_loss: 1.1358 - val_acc: 0.9762 - val_mDice: 0.7390

Epoch 00177: val_mDice improved from 0.73529 to 0.73897, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 178/300
 - 16s - loss: 1.4742 - acc: 0.9574 - mDice: 0.6841 - val_loss: 1.1482 - val_acc: 0.9760 - val_mDice: 0.7316

Epoch 00178: val_mDice did not improve from 0.73897
Epoch 179/300
 - 15s - loss: 1.4742 - acc: 0.9574 - mDice: 0.6839 - val_loss: 1.1662 - val_acc: 0.9758 - val_mDice: 0.7329

Epoch 00179: val_mDice did not improve from 0.73897
Epoch 180/300
 - 15s - loss: 1.4716 - acc: 0.9574 - mDice: 0.6846 - val_loss: 1.1462 - val_acc: 0.9758 - val_mDice: 0.7333

Epoch 00180: val_mDice did not improve from 0.73897
Epoch 181/300
 - 15s - loss: 1.4719 - acc: 0.9574 - mDice: 0.6852 - val_loss: 1.1733 - val_acc: 0.9761 - val_mDice: 0.7325

Epoch 00181: val_mDice did not improve from 0.73897
Epoch 182/300
 - 15s - loss: 1.4705 - acc: 0.9575 - mDice: 0.6847 - val_loss: 1.1540 - val_acc: 0.9758 - val_mDice: 0.7327

Epoch 00182: val_mDice did not improve from 0.73897
Epoch 183/300
 - 16s - loss: 1.4714 - acc: 0.9574 - mDice: 0.6848 - val_loss: 1.1418 - val_acc: 0.9760 - val_mDice: 0.7330

Epoch 00183: val_mDice did not improve from 0.73897
Epoch 184/300
 - 16s - loss: 1.4674 - acc: 0.9575 - mDice: 0.6856 - val_loss: 1.1605 - val_acc: 0.9759 - val_mDice: 0.7323

Epoch 00184: val_mDice did not improve from 0.73897
Epoch 185/300
 - 14s - loss: 1.4679 - acc: 0.9575 - mDice: 0.6855 - val_loss: 1.1375 - val_acc: 0.9762 - val_mDice: 0.7327

Epoch 00185: val_mDice did not improve from 0.73897
Epoch 186/300
 - 14s - loss: 1.4696 - acc: 0.9574 - mDice: 0.6850 - val_loss: 1.1629 - val_acc: 0.9758 - val_mDice: 0.7323

Epoch 00186: val_mDice did not improve from 0.73897
Epoch 187/300
 - 14s - loss: 1.4657 - acc: 0.9575 - mDice: 0.6859 - val_loss: 1.1612 - val_acc: 0.9758 - val_mDice: 0.7329

Epoch 00187: val_mDice did not improve from 0.73897
Epoch 188/300
 - 14s - loss: 1.4662 - acc: 0.9575 - mDice: 0.6863 - val_loss: 1.1513 - val_acc: 0.9761 - val_mDice: 0.7347

Epoch 00188: val_mDice did not improve from 0.73897
Epoch 189/300
 - 15s - loss: 1.4658 - acc: 0.9575 - mDice: 0.6860 - val_loss: 1.1465 - val_acc: 0.9759 - val_mDice: 0.7343

Epoch 00189: val_mDice did not improve from 0.73897
Epoch 190/300
 - 15s - loss: 1.4650 - acc: 0.9575 - mDice: 0.6864 - val_loss: 1.1662 - val_acc: 0.9759 - val_mDice: 0.7327

Epoch 00190: val_mDice did not improve from 0.73897
Epoch 191/300
 - 14s - loss: 1.4599 - acc: 0.9576 - mDice: 0.6869 - val_loss: 1.1362 - val_acc: 0.9761 - val_mDice: 0.7341

Epoch 00191: val_mDice did not improve from 0.73897
Epoch 192/300
 - 14s - loss: 1.4645 - acc: 0.9575 - mDice: 0.6859 - val_loss: 1.1363 - val_acc: 0.9761 - val_mDice: 0.7362

Epoch 00192: val_mDice did not improve from 0.73897
Epoch 193/300
 - 14s - loss: 1.4613 - acc: 0.9576 - mDice: 0.6870 - val_loss: 1.1441 - val_acc: 0.9759 - val_mDice: 0.7326

Epoch 00193: val_mDice did not improve from 0.73897
Epoch 194/300
 - 14s - loss: 1.4648 - acc: 0.9575 - mDice: 0.6862 - val_loss: 1.1459 - val_acc: 0.9756 - val_mDice: 0.7380

Epoch 00194: val_mDice did not improve from 0.73897
Epoch 195/300
 - 14s - loss: 1.4639 - acc: 0.9576 - mDice: 0.6865 - val_loss: 1.1369 - val_acc: 0.9763 - val_mDice: 0.7356

Epoch 00195: val_mDice did not improve from 0.73897
Epoch 196/300
 - 15s - loss: 1.4637 - acc: 0.9575 - mDice: 0.6864 - val_loss: 1.1337 - val_acc: 0.9762 - val_mDice: 0.7366

Epoch 00196: val_mDice did not improve from 0.73897
Epoch 197/300
 - 15s - loss: 1.4611 - acc: 0.9576 - mDice: 0.6867 - val_loss: 1.1428 - val_acc: 0.9759 - val_mDice: 0.7333

Epoch 00197: val_mDice did not improve from 0.73897
Epoch 198/300
 - 14s - loss: 1.4597 - acc: 0.9576 - mDice: 0.6874 - val_loss: 1.1284 - val_acc: 0.9759 - val_mDice: 0.7355

Epoch 00198: val_mDice did not improve from 0.73897
Epoch 199/300
 - 14s - loss: 1.4609 - acc: 0.9576 - mDice: 0.6868 - val_loss: 1.1343 - val_acc: 0.9762 - val_mDice: 0.7326

Epoch 00199: val_mDice did not improve from 0.73897
Epoch 200/300
 - 14s - loss: 1.4587 - acc: 0.9576 - mDice: 0.6873 - val_loss: 1.1396 - val_acc: 0.9760 - val_mDice: 0.7377

Epoch 00200: val_mDice did not improve from 0.73897
Epoch 201/300
 - 14s - loss: 1.4598 - acc: 0.9576 - mDice: 0.6874 - val_loss: 1.1678 - val_acc: 0.9755 - val_mDice: 0.7324

Epoch 00201: val_mDice did not improve from 0.73897
Epoch 202/300
 - 15s - loss: 1.4566 - acc: 0.9577 - mDice: 0.6874 - val_loss: 1.1498 - val_acc: 0.9760 - val_mDice: 0.7328

Epoch 00202: val_mDice did not improve from 0.73897
Epoch 203/300
 - 14s - loss: 1.4559 - acc: 0.9577 - mDice: 0.6880 - val_loss: 1.1382 - val_acc: 0.9763 - val_mDice: 0.7357

Epoch 00203: val_mDice did not improve from 0.73897
Epoch 204/300
 - 14s - loss: 1.4554 - acc: 0.9577 - mDice: 0.6882 - val_loss: 1.1385 - val_acc: 0.9757 - val_mDice: 0.7361

Epoch 00204: val_mDice did not improve from 0.73897
Epoch 205/300
 - 14s - loss: 1.4566 - acc: 0.9576 - mDice: 0.6878 - val_loss: 1.1317 - val_acc: 0.9760 - val_mDice: 0.7345

Epoch 00205: val_mDice did not improve from 0.73897
Epoch 206/300
 - 14s - loss: 1.4560 - acc: 0.9577 - mDice: 0.6879 - val_loss: 1.1608 - val_acc: 0.9758 - val_mDice: 0.7348

Epoch 00206: val_mDice did not improve from 0.73897
Epoch 207/300
 - 16s - loss: 1.4542 - acc: 0.9577 - mDice: 0.6883 - val_loss: 1.1281 - val_acc: 0.9760 - val_mDice: 0.7392

Epoch 00207: val_mDice improved from 0.73897 to 0.73920, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 208/300
 - 14s - loss: 1.4523 - acc: 0.9577 - mDice: 0.6889 - val_loss: 1.1508 - val_acc: 0.9758 - val_mDice: 0.7347

Epoch 00208: val_mDice did not improve from 0.73920
Epoch 209/300
 - 16s - loss: 1.4526 - acc: 0.9577 - mDice: 0.6885 - val_loss: 1.1233 - val_acc: 0.9763 - val_mDice: 0.7397

Epoch 00209: val_mDice improved from 0.73920 to 0.73971, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 210/300
 - 14s - loss: 1.4545 - acc: 0.9577 - mDice: 0.6881 - val_loss: 1.1529 - val_acc: 0.9758 - val_mDice: 0.7380

Epoch 00210: val_mDice did not improve from 0.73971
Epoch 211/300
 - 15s - loss: 1.4549 - acc: 0.9577 - mDice: 0.6886 - val_loss: 1.1350 - val_acc: 0.9760 - val_mDice: 0.7333

Epoch 00211: val_mDice did not improve from 0.73971
Epoch 212/300
 - 15s - loss: 1.4487 - acc: 0.9578 - mDice: 0.6892 - val_loss: 1.1250 - val_acc: 0.9761 - val_mDice: 0.7376

Epoch 00212: val_mDice did not improve from 0.73971
Epoch 213/300
 - 15s - loss: 1.4495 - acc: 0.9578 - mDice: 0.6892 - val_loss: 1.1362 - val_acc: 0.9761 - val_mDice: 0.7372

Epoch 00213: val_mDice did not improve from 0.73971
Epoch 214/300
 - 15s - loss: 1.4550 - acc: 0.9577 - mDice: 0.6880 - val_loss: 1.1533 - val_acc: 0.9760 - val_mDice: 0.7368

Epoch 00214: val_mDice did not improve from 0.73971
Epoch 215/300
 - 15s - loss: 1.4472 - acc: 0.9578 - mDice: 0.6900 - val_loss: 1.1319 - val_acc: 0.9761 - val_mDice: 0.7353

Epoch 00215: val_mDice did not improve from 0.73971
Epoch 216/300
 - 15s - loss: 1.4498 - acc: 0.9578 - mDice: 0.6893 - val_loss: 1.1415 - val_acc: 0.9762 - val_mDice: 0.7369

Epoch 00216: val_mDice did not improve from 0.73971
Epoch 217/300
 - 14s - loss: 1.4504 - acc: 0.9578 - mDice: 0.6894 - val_loss: 1.1326 - val_acc: 0.9761 - val_mDice: 0.7384

Epoch 00217: val_mDice did not improve from 0.73971
Epoch 218/300
 - 16s - loss: 1.4519 - acc: 0.9577 - mDice: 0.6890 - val_loss: 1.1383 - val_acc: 0.9760 - val_mDice: 0.7357

Epoch 00218: val_mDice did not improve from 0.73971
Epoch 219/300
 - 14s - loss: 1.4505 - acc: 0.9577 - mDice: 0.6892 - val_loss: 1.1543 - val_acc: 0.9759 - val_mDice: 0.7337

Epoch 00219: val_mDice did not improve from 0.73971
Epoch 220/300
 - 16s - loss: 1.4476 - acc: 0.9578 - mDice: 0.6894 - val_loss: 1.1400 - val_acc: 0.9759 - val_mDice: 0.7418

Epoch 00220: val_mDice improved from 0.73971 to 0.74182, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM10_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 221/300
 - 14s - loss: 1.4480 - acc: 0.9578 - mDice: 0.6901 - val_loss: 1.1389 - val_acc: 0.9760 - val_mDice: 0.7381

Epoch 00221: val_mDice did not improve from 0.74182
Epoch 222/300
 - 16s - loss: 1.4412 - acc: 0.9579 - mDice: 0.6908 - val_loss: 1.1350 - val_acc: 0.9762 - val_mDice: 0.7398

Epoch 00222: val_mDice did not improve from 0.74182
Epoch 223/300
 - 14s - loss: 1.4489 - acc: 0.9577 - mDice: 0.6894 - val_loss: 1.1347 - val_acc: 0.9758 - val_mDice: 0.7373

Epoch 00223: val_mDice did not improve from 0.74182
Epoch 224/300
 - 15s - loss: 1.4481 - acc: 0.9578 - mDice: 0.6894 - val_loss: 1.1267 - val_acc: 0.9758 - val_mDice: 0.7363

Epoch 00224: val_mDice did not improve from 0.74182
Epoch 225/300
 - 15s - loss: 1.4437 - acc: 0.9578 - mDice: 0.6906 - val_loss: 1.1331 - val_acc: 0.9759 - val_mDice: 0.7383

Epoch 00225: val_mDice did not improve from 0.74182
Epoch 226/300
 - 14s - loss: 1.4458 - acc: 0.9578 - mDice: 0.6903 - val_loss: 1.1521 - val_acc: 0.9763 - val_mDice: 0.7381

Epoch 00226: val_mDice did not improve from 0.74182
Epoch 227/300
 - 16s - loss: 1.4452 - acc: 0.9579 - mDice: 0.6901 - val_loss: 1.1366 - val_acc: 0.9754 - val_mDice: 0.7372

Epoch 00227: val_mDice did not improve from 0.74182
Epoch 228/300
 - 14s - loss: 1.4451 - acc: 0.9579 - mDice: 0.6903 - val_loss: 1.1261 - val_acc: 0.9763 - val_mDice: 0.7376

Epoch 00228: val_mDice did not improve from 0.74182
Epoch 229/300
 - 16s - loss: 1.4415 - acc: 0.9578 - mDice: 0.6910 - val_loss: 1.1423 - val_acc: 0.9758 - val_mDice: 0.7392

Epoch 00229: val_mDice did not improve from 0.74182
Epoch 230/300
 - 15s - loss: 1.4419 - acc: 0.9579 - mDice: 0.6909 - val_loss: 1.1398 - val_acc: 0.9763 - val_mDice: 0.7372

Epoch 00230: val_mDice did not improve from 0.74182
Epoch 231/300
 - 16s - loss: 1.4436 - acc: 0.9578 - mDice: 0.6907 - val_loss: 1.1490 - val_acc: 0.9761 - val_mDice: 0.7341

Epoch 00231: val_mDice did not improve from 0.74182
Epoch 232/300
 - 15s - loss: 1.4409 - acc: 0.9578 - mDice: 0.6910 - val_loss: 1.1404 - val_acc: 0.9763 - val_mDice: 0.7354

Epoch 00232: val_mDice did not improve from 0.74182
Epoch 233/300
 - 15s - loss: 1.4429 - acc: 0.9579 - mDice: 0.6908 - val_loss: 1.1280 - val_acc: 0.9758 - val_mDice: 0.7379

Epoch 00233: val_mDice did not improve from 0.74182
Epoch 234/300
 - 15s - loss: 1.4396 - acc: 0.9579 - mDice: 0.6914 - val_loss: 1.1196 - val_acc: 0.9763 - val_mDice: 0.7364

Epoch 00234: val_mDice did not improve from 0.74182
Epoch 235/300
 - 15s - loss: 1.4390 - acc: 0.9579 - mDice: 0.6915 - val_loss: 1.1261 - val_acc: 0.9765 - val_mDice: 0.7397

Epoch 00235: val_mDice did not improve from 0.74182
Epoch 236/300
 - 15s - loss: 1.4377 - acc: 0.9580 - mDice: 0.6918 - val_loss: 1.1412 - val_acc: 0.9762 - val_mDice: 0.7365

Epoch 00236: val_mDice did not improve from 0.74182
Epoch 237/300
 - 15s - loss: 1.4409 - acc: 0.9579 - mDice: 0.6914 - val_loss: 1.1460 - val_acc: 0.9761 - val_mDice: 0.7386

Epoch 00237: val_mDice did not improve from 0.74182
Epoch 238/300
 - 15s - loss: 1.4392 - acc: 0.9579 - mDice: 0.6915 - val_loss: 1.1299 - val_acc: 0.9761 - val_mDice: 0.7402

Epoch 00238: val_mDice did not improve from 0.74182
Epoch 239/300
 - 15s - loss: 1.4423 - acc: 0.9579 - mDice: 0.6907 - val_loss: 1.1384 - val_acc: 0.9758 - val_mDice: 0.7402

Epoch 00239: val_mDice did not improve from 0.74182
Epoch 240/300
 - 16s - loss: 1.4397 - acc: 0.9579 - mDice: 0.6917 - val_loss: 1.1379 - val_acc: 0.9760 - val_mDice: 0.7342

Epoch 00240: val_mDice did not improve from 0.74182
Epoch 241/300
 - 17s - loss: 1.4406 - acc: 0.9579 - mDice: 0.6907 - val_loss: 1.1328 - val_acc: 0.9761 - val_mDice: 0.7398

Epoch 00241: val_mDice did not improve from 0.74182
Epoch 242/300
 - 16s - loss: 1.4348 - acc: 0.9580 - mDice: 0.6920 - val_loss: 1.1304 - val_acc: 0.9762 - val_mDice: 0.7386

Epoch 00242: val_mDice did not improve from 0.74182
Epoch 243/300
 - 16s - loss: 1.4371 - acc: 0.9580 - mDice: 0.6923 - val_loss: 1.1242 - val_acc: 0.9761 - val_mDice: 0.7393

Epoch 00243: val_mDice did not improve from 0.74182
Epoch 244/300
 - 16s - loss: 1.4384 - acc: 0.9579 - mDice: 0.6916 - val_loss: 1.1486 - val_acc: 0.9757 - val_mDice: 0.7364

Epoch 00244: val_mDice did not improve from 0.74182
Epoch 245/300
 - 17s - loss: 1.4396 - acc: 0.9579 - mDice: 0.6914 - val_loss: 1.1312 - val_acc: 0.9763 - val_mDice: 0.7415

Epoch 00245: val_mDice did not improve from 0.74182
Epoch 246/300
 - 16s - loss: 1.4341 - acc: 0.9580 - mDice: 0.6928 - val_loss: 1.1264 - val_acc: 0.9761 - val_mDice: 0.7391

Epoch 00246: val_mDice did not improve from 0.74182
Epoch 247/300
 - 17s - loss: 1.4348 - acc: 0.9580 - mDice: 0.6923 - val_loss: 1.1323 - val_acc: 0.9759 - val_mDice: 0.7390

Epoch 00247: val_mDice did not improve from 0.74182
Epoch 248/300
 - 15s - loss: 1.4348 - acc: 0.9580 - mDice: 0.6924 - val_loss: 1.1243 - val_acc: 0.9760 - val_mDice: 0.7413

Epoch 00248: val_mDice did not improve from 0.74182
Epoch 249/300
 - 18s - loss: 1.4304 - acc: 0.9581 - mDice: 0.6930 - val_loss: 1.1516 - val_acc: 0.9765 - val_mDice: 0.7401

Epoch 00249: val_mDice did not improve from 0.74182
Epoch 250/300
 - 16s - loss: 1.4370 - acc: 0.9580 - mDice: 0.6919 - val_loss: 1.1328 - val_acc: 0.9759 - val_mDice: 0.7364

Epoch 00250: val_mDice did not improve from 0.74182
Restoring model weights from the end of the best epoch
Epoch 00250: early stopping
{'val_loss': [9.053437483541156, 5.787866203562865, 5.3844970056168435, 4.7536531219582985, 4.181149310512576, 3.7846202808440466, 3.418215171733514, 3.0568664128415826, 2.8648128283254293, 2.6875585654917415, 2.5125515029384298, 2.2871958392366163, 2.1568367527323153, 2.0748890361802648, 2.02785692378381, 1.936973727440792, 1.8334735380534757, 1.7773150995452291, 1.7166542941949907, 1.6683632124915901, 1.6256018049478111, 1.5977450910896744, 1.5578353486706378, 1.531266156315594, 1.5274844081623902, 1.5128808228957003, 1.4668067842460055, 1.4800475676575109, 1.46088297966285, 1.4454350326936987, 1.4176978071879838, 1.4189135774786736, 1.3917488368827136, 1.4067337261561979, 1.3806305028013688, 1.3784721146987486, 1.365837090254249, 1.3519152979021123, 1.347736323654966, 1.3283694322582706, 1.3316576962730797, 1.333644711279911, 1.3112967042596144, 1.31014095636998, 1.299470772642662, 1.3194411957410601, 1.2982666434847827, 1.2940609371305978, 1.3155837945234168, 1.2847635817234462, 1.2884642220968103, 1.2737918295005504, 1.270431808826165, 1.2981831104558466, 1.2781545180428007, 1.261944861843632, 1.2557109736809622, 1.2544555439890375, 1.2612723567783308, 1.2643635654281857, 1.2410929031237985, 1.2330708569717743, 1.2484810706391696, 1.2450615835944043, 1.2505793408056973, 1.217351099099761, 1.2518538746766759, 1.2326317847508328, 1.249612621242845, 1.2335585884762983, 1.219061206535212, 1.224576222456612, 1.2270613065503393, 1.2295600434598268, 1.2109202390605411, 1.2185995182798282, 1.2296326601442427, 1.2124035420233419, 1.21289913861739, 1.1989744285707524, 1.220949304124802, 1.1907706657696273, 1.2060172440507082, 1.21424579767016, 1.2399863720149693, 1.1875375559543684, 1.206443113161935, 1.1955230993420043, 1.2157570266137014, 1.1980444611899672, 1.2159995441906062, 1.1933745233790527, 1.2260822419122988, 1.1931931210946953, 1.201907041621753, 1.1836503216168583, 1.226481153173061, 1.2141267843740895, 1.192312700572458, 1.2100172031323813, 1.1787033528351407, 1.182717469434118, 1.1918621574428672, 1.203802605085926, 1.217539097701309, 1.1895068943605271, 1.1622629474671737, 1.1939458353657715, 1.2236254542070868, 1.1996271526457345, 1.1828376511488312, 1.1884700830875257, 1.1867793600462861, 1.1663609323057433, 1.180663274335945, 1.1843085231387134, 1.1880193877513463, 1.1782229607679304, 1.1854028663023495, 1.1810383467766439, 1.1675897383103262, 1.159538566856686, 1.166696631636058, 1.1666701784871374, 1.1731202400212548, 1.1720700207410253, 1.196466842833219, 1.1712463304321878, 1.1918374146015656, 1.1597336018441642, 1.1756718418510181, 1.1773204535298272, 1.1832420877287384, 1.1576094624237772, 1.1752943040406976, 1.1739545036074566, 1.1620855047539373, 1.185344168821412, 1.1831864536541836, 1.1622295413159738, 1.1568757541778847, 1.1567334024684082, 1.145657128106102, 1.1555681076745368, 1.1640289268719919, 1.1589554228765893, 1.1527351651124669, 1.154437627754647, 1.1606822536574097, 1.164168556880448, 1.146928455791909, 1.1577290393975161, 1.1415467709564786, 1.1565487216143282, 1.161534469345542, 1.1517882610037793, 1.1657993150302102, 1.1520216965717256, 1.14211212059316, 1.167786973222488, 1.1625247970616253, 1.1578067108491183, 1.1573799127853608, 1.153897761041544, 1.1637064387173979, 1.1865876303406298, 1.1564143746305644, 1.165909053571195, 1.1587456375727125, 1.1409761467801247, 1.1488623205303936, 1.1479397025384885, 1.1674144111953426, 1.1546871358355235, 1.1507073504644034, 1.1443165985896844, 1.135792696203624, 1.1482430169578177, 1.166195630503455, 1.1461521115789095, 1.1732615742616368, 1.1540389726157767, 1.1417683940151664, 1.1604966943419042, 1.137541157185298, 1.1628771957487969, 1.1612210850933524, 1.1513187522837902, 1.146459887233057, 1.1661902237650799, 1.1362216749174523, 1.1363096204709084, 1.144127341272123, 1.1459209540816309, 1.136860303908115, 1.1336856658303676, 1.1427739644930526, 1.1284236727783257, 1.1343379736156163, 1.1396452200014688, 1.1678069343885344, 1.1498231815537585, 1.1381702862012155, 1.1384641367856982, 1.1317220565933335, 1.1608174499811732, 1.1281466446358626, 1.1508467918121124, 1.1232502329538074, 1.1529496552026544, 1.1349901575824288, 1.1249989193646477, 1.1362133702829558, 1.1533464596644436, 1.1318833506379689, 1.141462102401445, 1.1326190422834117, 1.1383072665789424, 1.1542884377477878, 1.1400244249610365, 1.1389097180643064, 1.135015109197117, 1.1347334886686664, 1.1266548036481459, 1.1330832903959211, 1.152062490975291, 1.1365538446890657, 1.1260868078375952, 1.1423471785806814, 1.1397527874249356, 1.149027129992031, 1.1404420698883244, 1.1280490936210579, 1.1195551965693389, 1.1260767671261604, 1.1412089568659376, 1.1459961019207598, 1.1299270201860707, 1.1383948584851564, 1.1378643337787768, 1.1327729174877093, 1.130398123146989, 1.1241591086706084, 1.1486319831469356, 1.1311550939648767, 1.1263792420523029, 1.1323341495751915, 1.1242882867060562, 1.1516315577738314, 1.132801017777991], 'val_acc': [0.911152898532016, 0.911152898532016, 0.911152898532016, 0.9110505350444773, 0.9142221197721618, 0.9185440677540583, 0.9257020884322785, 0.9401896342451836, 0.9361505101979931, 0.9363111737323352, 0.9420038867080568, 0.9544481486343961, 0.9585492727207593, 0.9618202577785364, 0.9630569139976702, 0.9652477492347543, 0.9661421899426801, 0.9672929073679007, 0.9677281586063767, 0.9678794864191951, 0.9678111233484975, 0.968758981236255, 0.969539812034379, 0.9691505097965784, 0.9696216345461894, 0.9698308531345509, 0.9707562851151599, 0.9696220149055307, 0.9704955258981205, 0.9712434747307078, 0.9720822502523399, 0.9720419003171535, 0.9715378961160858, 0.9715532102149065, 0.9711291673732348, 0.9718255678253979, 0.9720512282869309, 0.9724326966517001, 0.9724375543778726, 0.9723829931869239, 0.9728675762253612, 0.9729348278632273, 0.9727917293672612, 0.9724532437031215, 0.9725156347864751, 0.9727921197829221, 0.9722720487256041, 0.972195817737043, 0.972466327813053, 0.9725974323669929, 0.9730203702705397, 0.9734081942293472, 0.9733543963759143, 0.9723482578207193, 0.9736002230057608, 0.9734250093386336, 0.9736630022002021, 0.9736271180042274, 0.97425629751125, 0.9735411930377538, 0.9741531714194688, 0.9744599086538559, 0.9740664908672259, 0.9740758496344822, 0.9743620245234619, 0.9745290135876366, 0.974365379144102, 0.974255171308199, 0.9740093093764803, 0.9742921477671457, 0.9752004054392998, 0.9744516822700969, 0.9745764867492636, 0.9750875793986664, 0.9751141081794913, 0.9752190892432402, 0.9749594190418196, 0.9754787483408078, 0.9751836025861529, 0.974999392493538, 0.9753106274169023, 0.974982963819286, 0.9746018719379848, 0.9750991555844124, 0.9745831926384374, 0.9750886937645911, 0.9742723426835608, 0.9750501940874726, 0.9752762423458334, 0.9754981677226316, 0.9752389001930116, 0.9753913145073688, 0.9749026216815352, 0.9753857185844796, 0.9754821138557943, 0.9753517065400189, 0.9748417422934869, 0.975069650761482, 0.9753012938951985, 0.975311363099539, 0.975546007311407, 0.9757383989533557, 0.9757929602490578, 0.9750404901579939, 0.9751970454762396, 0.9756633199371646, 0.9757174920742457, 0.9756987993662722, 0.9754118640728701, 0.9752104906708997, 0.9753700123939447, 0.9754051482321299, 0.9756498767328179, 0.9757193476747336, 0.9756920773450855, 0.9756386451855276, 0.9750744906795884, 0.9753188370401286, 0.9754645354089921, 0.975967811155403, 0.9760055414193125, 0.97602684080915, 0.9758762747625475, 0.9759394116896108, 0.975599794689507, 0.97533938346303, 0.9750479642033367, 0.9758661781128345, 0.9757570759483297, 0.9758052971534863, 0.9757365338203149, 0.9761086556739673, 0.9756136226528349, 0.9759954430935462, 0.9757290611367653, 0.9757238312220112, 0.9759046646957866, 0.9756973122879994, 0.9757862260764848, 0.9755669072767972, 0.9757922026729752, 0.9757159872926602, 0.9759980652789031, 0.9757813689788323, 0.9758706717164319, 0.9760144976195216, 0.9758841052834724, 0.9760216052377161, 0.9758736375974645, 0.9757705390558092, 0.9760428935237007, 0.9760739120322497, 0.9758852366194365, 0.975922228581876, 0.975452973783959, 0.9760025585682405, 0.9757634422272077, 0.9761949555526089, 0.9760529843072271, 0.9761355507771873, 0.9754481182576064, 0.9755198487288503, 0.9757977995386442, 0.9756136193007283, 0.9759756477520211, 0.9755665452492887, 0.9761605807473663, 0.9754649235200799, 0.9756476197175694, 0.9761770230395513, 0.9761901007595297, 0.9761740407122459, 0.9755318111401241, 0.9760346719585948, 0.9761295676859905, 0.976131827005812, 0.9762031750226482, 0.9759711720612431, 0.9758082695292253, 0.9758183671217182, 0.9761407931575876, 0.9757918468259131, 0.9760492522603389, 0.9759453839912147, 0.9761994483181797, 0.9757525978482251, 0.9758321861810131, 0.9760697927123004, 0.975928565006055, 0.9759117695903946, 0.976058597619169, 0.9760746624851059, 0.9759207275714104, 0.9756438693388485, 0.9763466599536487, 0.9762465152463929, 0.975933050229386, 0.9758867379441621, 0.9761957074720118, 0.975984621027023, 0.9755489897434657, 0.975980135489432, 0.9762950950221981, 0.9757017883977906, 0.9759898517798037, 0.9757634330089147, 0.976018612539831, 0.9757772525919761, 0.9762928416733163, 0.975800422038261, 0.9760294319875211, 0.9760668150988949, 0.9761109076610558, 0.9760253402176976, 0.9761206083431814, 0.9761908454509527, 0.9761486298589589, 0.9760328118537138, 0.9758859811013528, 0.9759330545242725, 0.9759644448023899, 0.9762405384403959, 0.9757944459655373, 0.9757933279332461, 0.9758942017236787, 0.9762887285338135, 0.9754357874288709, 0.9762790127672085, 0.9758026651213165, 0.9762969638216056, 0.976091079426985, 0.9762865004304843, 0.975752611780418, 0.976320121745024, 0.9764908539599401, 0.9762084125843953, 0.9761228493311702, 0.9761015523506593, 0.9758172479371404, 0.9759566012920521, 0.9760727852006789, 0.9762476385163507, 0.976107165243588, 0.9757002917869648, 0.9763372982532991, 0.9761228573971766, 0.9758572035807926, 0.9760223524432191, 0.97645723641652, 0.9759364160586326], 'val_mDice': [0.008054865952188342, 0.04552140482987796, 0.06731670465065012, 0.09714018888706064, 0.1373945338445305, 0.1826796451802832, 0.2345479705840716, 0.2936325235609849, 0.3224997168999355, 0.3525301630760957, 0.39425616099880534, 0.4394564804062902, 0.461992284011338, 0.48484854832265417, 0.49975006159244395, 0.5213574799586265, 0.5413123170185592, 0.5526556735089039, 0.569140174057865, 0.5831835100227584, 0.5936723725447964, 0.6032358814417164, 0.613776760277304, 0.6266300655207441, 0.6239635906655256, 0.6286394119472202, 0.6356072763148007, 0.6428681456979842, 0.6438738380039932, 0.6486098887840767, 0.6549523768190341, 0.6580244788805085, 0.6605930850040724, 0.660748562934319, 0.6648833682541269, 0.6672340836801512, 0.6728498722002669, 0.6743559493750386, 0.6798654468910137, 0.6790208639495192, 0.6779033549012116, 0.6798659847993633, 0.6839329143609648, 0.685698949913568, 0.6878430683080676, 0.6859936696364297, 0.689213385481407, 0.6916831686752333, 0.690402713308016, 0.6972306447205099, 0.6995792717841471, 0.6951260778313152, 0.6953979132464565, 0.6965778611456364, 0.6966108249235237, 0.6992501529532702, 0.7028929749356423, 0.6998002202313898, 0.702217896814296, 0.6984289936943926, 0.7009529345693404, 0.7052069581874855, 0.7054079257750553, 0.7041565791584277, 0.7024679157771628, 0.7064253600913317, 0.705132783402039, 0.7094641531079432, 0.7094867383449065, 0.709448315766239, 0.7077308004895497, 0.7105393732369261, 0.7105587893713966, 0.7123300752656531, 0.7110929195826419, 0.7115957070737815, 0.7082711128233187, 0.712804325330865, 0.715193667814057, 0.717225403484016, 0.7105676857574543, 0.7157574018401295, 0.7155891586690879, 0.7126052848903073, 0.7132287409896382, 0.7202488866966932, 0.7158025784945027, 0.7170063179699943, 0.7201662883817207, 0.714773461563097, 0.7112192977710852, 0.7203359298002112, 0.713977240405728, 0.7185075151061341, 0.7154912939180599, 0.7208971694399896, 0.7119305852427424, 0.7189998344922527, 0.7208642699806468, 0.7185386723080922, 0.7238257814375504, 0.7202406715215405, 0.7180200380474486, 0.7197883885438916, 0.7167460766534185, 0.7216669922344295, 0.7214882767682336, 0.7203689289847242, 0.7209059620154973, 0.7156090621160497, 0.7230516085515751, 0.7230981112783529, 0.7213379685195762, 0.7233841295611041, 0.7239028944491502, 0.7234094647824869, 0.7191054961383867, 0.7268079587361516, 0.7194489379968291, 0.726036273113244, 0.7280655602788674, 0.7302448410141447, 0.7258475906819577, 0.72498020828294, 0.7214952525019855, 0.7256989883412795, 0.7210892162339758, 0.7262962256248889, 0.7219140435354572, 0.7264577160820181, 0.7244567561023894, 0.7240902221056196, 0.7223568778674925, 0.7273789025149152, 0.7214816905073625, 0.7264922594353688, 0.7296129495481615, 0.7229568847243941, 0.7237765364780996, 0.724582008192535, 0.7262719423364462, 0.7270719504314483, 0.7302210548850061, 0.7306838236709889, 0.7290808111167331, 0.728528640706007, 0.7289248147622562, 0.7302480510751895, 0.7258001620404959, 0.7291186722175518, 0.7283016813031818, 0.7297799019486707, 0.7337495654245253, 0.7309078447429074, 0.7304383346611251, 0.7291579485358588, 0.7289885931987126, 0.7267677154398551, 0.732455923603373, 0.732295697518937, 0.7311762380683778, 0.7306341270151792, 0.7326783445681755, 0.7304621524257694, 0.7296553623906757, 0.7255923089117912, 0.7302632537164672, 0.7296321499955256, 0.7349495661489155, 0.7323639135159591, 0.7337900521675605, 0.7352863525045358, 0.7323945479988004, 0.7326177440334917, 0.733432820371249, 0.7319108244614358, 0.7389683855438903, 0.7316193846700899, 0.7328917223875049, 0.7333089181325139, 0.7325394261490901, 0.7327375067348849, 0.7329561463139808, 0.7322510945985523, 0.7326758955400732, 0.732292293454725, 0.7328931747924254, 0.7347346703490809, 0.7342552124720676, 0.7326543259913976, 0.7340590806124709, 0.7361646359540875, 0.7325738111154056, 0.7380132461474105, 0.7355525928348146, 0.7365650937930143, 0.7332844733144361, 0.7355373323696988, 0.7326161483260156, 0.7376871856947566, 0.7324223199921459, 0.7327961602194238, 0.7357033889197298, 0.7360643523439163, 0.7345086718485518, 0.7347726465738093, 0.7392032012369595, 0.7347406083963458, 0.7397053953004847, 0.7379850151249729, 0.7333391126513691, 0.7375752942633336, 0.7372494736958053, 0.7368139813151636, 0.7353292770670671, 0.7369206688106584, 0.7384091003917432, 0.7356564891778312, 0.733712981476306, 0.7418231062185157, 0.738129931195968, 0.7397829859872694, 0.7373355455264475, 0.7363229811924832, 0.7382834192319578, 0.7380682863753374, 0.7372242736062182, 0.7376221156497412, 0.7391896208057505, 0.737193922900148, 0.7340814123463756, 0.7354412212941684, 0.7379448814006597, 0.7363752510090913, 0.7396788092195883, 0.7364967173138905, 0.7385563102464056, 0.7401874859429411, 0.74022103487293, 0.7341869605446533, 0.7398179871126721, 0.738606986345851, 0.7393133354312715, 0.7363992972407484, 0.7415464852522463, 0.7390572943042159, 0.739013349025237, 0.7412602773659678, 0.7401391205972024, 0.7364218179496604], 'loss': [96.79710884745987, 11.001945087374693, 8.311115226737927, 7.157441598420822, 6.296228848695815, 5.679475067690211, 5.21559814089144, 4.81750243912705, 4.480828844074946, 4.249086895620605, 4.036953485820141, 3.829271231460245, 3.654727568702473, 3.5018740625987625, 3.3627149870492725, 3.241260936663247, 3.127554665249647, 3.014301785356799, 2.9140503001341456, 2.82476091810828, 2.733714893691991, 2.6452139820043974, 2.5711405399755023, 2.4948919946489503, 2.4498895588737506, 2.3915345193299378, 2.3457128503507256, 2.2998633291657633, 2.268447351596069, 2.225995229280539, 2.1937033947841984, 2.1658651350032976, 2.1379232356163285, 2.1087457156194533, 2.08721697757615, 2.0608730456662414, 2.0319995668236657, 2.016794051691364, 1.9962614799780465, 1.9795142064594393, 1.9552711117016244, 1.9434705705049022, 1.9340200615687493, 1.9110720386671183, 1.8925696807696903, 1.8765888412683494, 1.8616931965352184, 1.8616756870176572, 1.8367602485432417, 1.8250362746015203, 1.8151064642445982, 1.8068777335967314, 1.797851241820952, 1.790610782387788, 1.7738850732483422, 1.7712210855692299, 1.7598406135702966, 1.7507808720253835, 1.7426916698967707, 1.7393085121190588, 1.7264364655991755, 1.7287978206125505, 1.7194944758952986, 1.7065253643617375, 1.6998443700582018, 1.6970421464386454, 1.6962203215739249, 1.684182720349663, 1.6836836107555522, 1.6761313662076176, 1.6767350723396568, 1.6649936918859352, 1.6620990460618839, 1.663534563372788, 1.655219459658474, 1.6548406626172614, 1.6422267417099987, 1.638826235858095, 1.6375928424749826, 1.6394075821944725, 1.6266932417477606, 1.630695964260494, 1.6207987375020874, 1.6176820159660337, 1.6150522654096504, 1.6094224820180938, 1.6059721713816957, 1.6073958960676593, 1.6082698352611284, 1.5945803365435756, 1.5977829061416704, 1.5923599223354838, 1.588089072898088, 1.5834083597563238, 1.5807736696723507, 1.5823887520842845, 1.5781378461252635, 1.5798003933677003, 1.5787591569365245, 1.5699169001241653, 1.5687116178915044, 1.5698145306300555, 1.5662388885682916, 1.5632611482962047, 1.5590345861387327, 1.5583595384541675, 1.5578678694940478, 1.5514806984931233, 1.5494660740979491, 1.5513069532362829, 1.5479496617866964, 1.5499015192663739, 1.545992734285721, 1.5434930698721994, 1.5448312242451878, 1.537386584069551, 1.538454198254162, 1.5357735559556511, 1.5346215545942161, 1.5386710471808416, 1.5353907708894696, 1.5294356612493034, 1.5254968412448822, 1.5249711902912704, 1.533037274438502, 1.5255360073606774, 1.5269525099530157, 1.5226355793251616, 1.5192400042840695, 1.518953368891876, 1.5208216106565877, 1.5183792182228284, 1.5175253047022124, 1.5183124521719205, 1.5154314136464333, 1.512340256191873, 1.50991106063321, 1.5130714743746034, 1.51047362182684, 1.5116380976626356, 1.5084912857815687, 1.504049861600898, 1.5067610798373532, 1.5070724581731452, 1.5039744465563836, 1.5061584728802344, 1.5010476288291061, 1.5008904986962008, 1.4985231182624539, 1.497515321875739, 1.4936583415952376, 1.4987715601315166, 1.4939457322515604, 1.4953740285786834, 1.4893117449158937, 1.493553154842044, 1.4889495813230476, 1.4946387374198922, 1.4930714545315449, 1.4941562448364518, 1.4871984100696947, 1.4883285593682953, 1.485287974551594, 1.4862439606499405, 1.484537370059386, 1.4832771371915627, 1.4853305596241286, 1.4796489748139607, 1.4807487356303402, 1.4790170599341506, 1.4787043949647156, 1.4811366807172033, 1.4840511504083964, 1.475937186018893, 1.4751890772668388, 1.4744423808128122, 1.4777110458158245, 1.4742485793953928, 1.4742017334501358, 1.4716186203382364, 1.4719396437860017, 1.4705478658818207, 1.4714037312288348, 1.4673875476890335, 1.4679235960371655, 1.469571877723311, 1.4657027262109412, 1.4661898382728349, 1.4657984215206208, 1.46497215250287, 1.4599003896734375, 1.4645112531785427, 1.4612905480146443, 1.464806603087158, 1.4639062678218218, 1.463671768463334, 1.4611458448607575, 1.459724980354861, 1.4608634870189479, 1.4587070235344095, 1.4598458537901362, 1.4566005851564814, 1.4558699789959593, 1.4554443604440648, 1.4566076645691077, 1.4559697591810317, 1.4542227912564671, 1.4522622095957225, 1.4525612143240147, 1.4545474250461439, 1.4549020616171087, 1.4486525029890382, 1.4494984075243331, 1.4550147054599867, 1.4472055437310365, 1.4498283276469854, 1.450446155511477, 1.4518684749424258, 1.4504827665974298, 1.4475882196215222, 1.4479759498725004, 1.4412272221476603, 1.448876712379947, 1.4480746985381685, 1.443729493015816, 1.445808012144392, 1.445211175427416, 1.445082083456194, 1.4415387635135992, 1.441923947316532, 1.4436404833879548, 1.440941303885941, 1.4428919497124653, 1.439585538762582, 1.4390197230611603, 1.4377076415253491, 1.4408549360657583, 1.4391622336843906, 1.4422797060451955, 1.43974074231655, 1.4405562774649467, 1.4348385785421616, 1.4370626519103216, 1.4383909785989295, 1.4396236291991633, 1.4340653194886115, 1.434753869903399, 1.4348081672421387, 1.430434820738516, 1.436952575632529], 'acc': [0.7812257350933917, 0.8915737775898167, 0.8944110664560176, 0.8956658968441464, 0.8987144270790799, 0.9028578812034206, 0.9068403399696732, 0.9113679060721924, 0.9158434672136323, 0.9185662606805015, 0.920736603111525, 0.9232108748065322, 0.9257527386636453, 0.928257306633799, 0.9302488713474196, 0.9320564931846758, 0.9336622042382623, 0.9354038469792972, 0.9369267055009369, 0.9378297519572254, 0.9387027298454478, 0.9398148254547678, 0.9408246530487532, 0.9419757020226914, 0.9424202882777426, 0.9431152580926753, 0.9438094455992699, 0.9442854859611659, 0.9447455745561393, 0.9453740885246803, 0.9459227029783281, 0.946267297337984, 0.9467220130291171, 0.9472586150726334, 0.9474633043668187, 0.9478387620901283, 0.9483014722396189, 0.9485082150159524, 0.9487322555635291, 0.9489336184410029, 0.949252900074931, 0.9493854926094532, 0.9494192474327896, 0.9497661302796512, 0.950158679514117, 0.9504815307916618, 0.9508386914158112, 0.9508725944423728, 0.9512182451129577, 0.951500421744169, 0.9515787031628826, 0.9517803838278097, 0.9518651363354229, 0.9520096384334934, 0.9523627211622716, 0.9524509531761366, 0.9526208836967167, 0.9528052134228535, 0.9528727823532159, 0.952976760662806, 0.9531518459608028, 0.9531147688991692, 0.9532667800396415, 0.9534248463803117, 0.9535917817067503, 0.9536844372695337, 0.9536800315051223, 0.9538908707682209, 0.9540079316959235, 0.9540751831717859, 0.9541255717464461, 0.9542514560393122, 0.9543805180597327, 0.9543112372243406, 0.9544843563399518, 0.9545099037497821, 0.9546544275318128, 0.9546817182912649, 0.9547598493920497, 0.9546955615007597, 0.9548704782733799, 0.9548415602510333, 0.9549287207011073, 0.9549835376240132, 0.9550509591760348, 0.9551543889315197, 0.9551746185577832, 0.9551740209365561, 0.9551461930843924, 0.9553220837454954, 0.9553379055736325, 0.9554585722028972, 0.9555368393736081, 0.955607601233394, 0.9556289755022044, 0.9556182235903795, 0.9557211747899472, 0.9557215765716265, 0.9557424830200147, 0.9558833911418795, 0.9558664433315796, 0.9558601955013842, 0.955935030865157, 0.9560004814444644, 0.956006934148941, 0.956070609502095, 0.956079983209113, 0.9561526889014176, 0.9561829308781756, 0.9562319827472118, 0.9561576610734314, 0.9562029246954942, 0.9562822730916417, 0.9563405043099404, 0.9563296450161681, 0.9564508779210537, 0.9564099386338168, 0.9564635874364668, 0.956455744858819, 0.9564428335586915, 0.956477764334186, 0.9565192845649877, 0.956622338044218, 0.9566190546924698, 0.9565122950347619, 0.9566062066234788, 0.9565209855455487, 0.9566482288279151, 0.9567087712282384, 0.9567738566867275, 0.9566762060231444, 0.9567709390617126, 0.9567709059763504, 0.9567900788327491, 0.9567745425645829, 0.9568284624032397, 0.9569120180276288, 0.9568022502475917, 0.9568327967476625, 0.9568692219916662, 0.9569191448186137, 0.9569576986452383, 0.9569377985137871, 0.9569416264601955, 0.9569400675967129, 0.9568701551218625, 0.957045531895001, 0.9570663916489347, 0.9570779255151473, 0.9571263558803043, 0.9571479647522285, 0.9570215890592456, 0.9571315981374582, 0.9571303562245463, 0.9571903746583178, 0.9571104701041312, 0.957157946543007, 0.9571142555884917, 0.9571650091279922, 0.95704612985818, 0.957149847549303, 0.9572142189908811, 0.9571883961776562, 0.9571604299788854, 0.9571957352128893, 0.957231102910137, 0.9572426036099988, 0.9573040426716304, 0.9573489117499993, 0.9573579522277286, 0.9573036365045658, 0.9572847329384188, 0.9572470560208713, 0.9573893521111743, 0.9573665412177462, 0.9573607218174947, 0.9573551927795408, 0.9573877459743183, 0.9574372786789522, 0.9574191889527232, 0.9574255218689913, 0.9574617465101151, 0.9574181725811954, 0.9574876575409739, 0.9575157653468945, 0.9574219474920382, 0.9574847675270886, 0.9575315962877543, 0.9575210265043991, 0.9575003448295027, 0.9575703550756478, 0.9575060696710093, 0.9576066007258266, 0.9575110559500456, 0.9576118126542319, 0.957529563208746, 0.9575649298531415, 0.9576179728427127, 0.9576233970903557, 0.9575567998587831, 0.9576256651984182, 0.9577045959991032, 0.9576671628123903, 0.9576957505120406, 0.9576185506997102, 0.9576591374643627, 0.9576926890781845, 0.9577174131034347, 0.9576824728072748, 0.9577108779075215, 0.9577307861828311, 0.957751571580188, 0.9577868021666557, 0.9577366051301461, 0.9578270718337581, 0.9577850691805812, 0.9577717736733109, 0.9577466506169958, 0.9577398584830995, 0.9577903325007826, 0.9578433855059498, 0.9578852566155662, 0.957731992868681, 0.9577849530638581, 0.9578427109425084, 0.9577740933651425, 0.9578676182660644, 0.9578850454091726, 0.957831081731661, 0.9578724546201167, 0.9578264490010652, 0.9578478164428326, 0.957852564309289, 0.9579112341141078, 0.95788307549531, 0.9579533108538995, 0.9578766671546146, 0.9578948227606088, 0.9578634653122147, 0.9578822741696378, 0.9579381073920814, 0.9580179998159685, 0.9579629599523138, 0.9579486246258028, 0.9578718653557183, 0.9580260147314583, 0.9579940058223843, 0.9579802380673125, 0.9580999413396181, 0.958039292601201], 'mDice': [0.01602288564232823, 0.029228309806166152, 0.04321363932923608, 0.06158900625149237, 0.09020004364668012, 0.12144236346176854, 0.1540675546847774, 0.19073403029951522, 0.22643553916554068, 0.2516610800401055, 0.27722616669402306, 0.3033557879469438, 0.32600470454252145, 0.34589150286567905, 0.3635998146654309, 0.3798681551701265, 0.39493962113159325, 0.40993864725798834, 0.4243245659881891, 0.43786827833169806, 0.4525275370503077, 0.46864004843572526, 0.4805233325642576, 0.4930167108463729, 0.4990599712657914, 0.5093453655688778, 0.5167764530322985, 0.5239012138837897, 0.5299528784741333, 0.5369005674660988, 0.542934608599853, 0.5479530422888262, 0.5529051125574518, 0.5587607074033439, 0.5629981123898963, 0.5672969506758879, 0.5732547721429174, 0.5761097312381515, 0.58048528882783, 0.5830183287768556, 0.5880690034853663, 0.5902637636275784, 0.5922093410645762, 0.5963731693919139, 0.5996372121598591, 0.6034405893752994, 0.606461961003256, 0.6066916185994494, 0.6113408970176517, 0.6133993678955396, 0.6154487292243804, 0.6173105816387349, 0.6190455347475051, 0.620428407044051, 0.6234017547318791, 0.6244142764972024, 0.6265336710669651, 0.6283891328801375, 0.6296230146997822, 0.6306882971462501, 0.6327908236285376, 0.6326248264355938, 0.6346117182062554, 0.6369084840895671, 0.6384950509057432, 0.6387771617801721, 0.6388735568827565, 0.6411607143389525, 0.641394221121577, 0.6428713586812627, 0.6433238997432296, 0.645536510812145, 0.6459407019756753, 0.6456208372864783, 0.647297525953607, 0.6476155631999702, 0.649729235333889, 0.6504351393570929, 0.650996790553284, 0.6504343657595337, 0.6530421560552494, 0.6521685989902145, 0.6540351953295779, 0.6551757735782754, 0.6552505894777765, 0.6565087956286996, 0.6574721060133467, 0.6570315258497321, 0.6565421994202426, 0.6589722036865432, 0.6589614185723726, 0.6602302830302417, 0.6607512488506033, 0.6620777103076745, 0.662055601555822, 0.6622782877452492, 0.6628790986831292, 0.6626598012266782, 0.662884518188437, 0.664689572709573, 0.6646965666521802, 0.6643280947516161, 0.6655960033094809, 0.665847247538716, 0.6666035043485967, 0.6670924193377608, 0.6672402897806654, 0.6680620573444183, 0.6686182935046752, 0.6688696301089614, 0.6690983845347589, 0.6686984323710166, 0.6693059381664288, 0.6698598024241728, 0.6698972124991255, 0.6710629161708063, 0.670988557614196, 0.6713158324526575, 0.6717686688322275, 0.6711685590850563, 0.6716533282683688, 0.6730793882619752, 0.6737381992405599, 0.6738842074455081, 0.6723960055257958, 0.6735232718175289, 0.6734387018403292, 0.674293375127443, 0.6746911734431063, 0.6753411582219248, 0.6748413291336708, 0.6752810726395659, 0.6751717710721763, 0.6752714904677699, 0.6755222922680236, 0.676168186838197, 0.677087681539813, 0.6761586565351302, 0.6769201907572368, 0.6763508587117272, 0.6774740546100375, 0.6779940865083139, 0.6772544838259009, 0.6777915637024359, 0.6777909134565857, 0.6776837960690234, 0.6784422107884139, 0.6789367906154957, 0.6791216063755015, 0.6794204873921352, 0.6803084922259194, 0.6788044235353698, 0.6799305831352361, 0.6799573000991215, 0.6811043527362559, 0.6801213804137682, 0.6811772490488398, 0.6801120498467029, 0.680245497513355, 0.6803374330210737, 0.6814314486407999, 0.6812497489879862, 0.6818581666075814, 0.6816641121066382, 0.6820524881040976, 0.6823677063396224, 0.6821383233639334, 0.6828785234456045, 0.6823593929959654, 0.6835327885794139, 0.6835127720912734, 0.682434883950839, 0.6819875859979067, 0.6840209977435188, 0.6840112985401279, 0.6839011664011657, 0.6832936861891672, 0.6841258796014518, 0.6839000935325577, 0.684619818130429, 0.6851869981186084, 0.6847037166307547, 0.684791664167497, 0.6856048516919776, 0.6855231166623822, 0.6850069290642218, 0.6859183960331445, 0.686258198054578, 0.6859609413672499, 0.6863814556366495, 0.6869054319490082, 0.685932879340912, 0.6870143320946681, 0.686201335817379, 0.6865259995638565, 0.6863613302997671, 0.6866915604919548, 0.6873878501998683, 0.6867588071564916, 0.6872612065874416, 0.6874132046137522, 0.6874300215164024, 0.687996470594039, 0.6882159867618316, 0.6878081922334116, 0.6879107513849355, 0.6882524585173154, 0.6888509784513425, 0.6885359670548235, 0.6880876453244016, 0.6885969362653176, 0.6891654031121085, 0.6892479891674093, 0.6879960545193633, 0.6900212507046113, 0.6892661413568825, 0.6893671249102696, 0.6889712555492106, 0.6891715270536702, 0.6894315948220445, 0.6900846388480256, 0.6908126231450739, 0.689395219128095, 0.6894364134965753, 0.6906169616913893, 0.6902913660115477, 0.6901401198088484, 0.6903213853325171, 0.6909919345326683, 0.6908940563959718, 0.6906678048043334, 0.690992646068927, 0.6907568994522767, 0.6914134866595838, 0.6914908899273944, 0.6917989723731957, 0.6913760740199907, 0.6915044444573555, 0.6907267854675769, 0.6917191182419408, 0.690744882791741, 0.6919956522891149, 0.6922785227740634, 0.6916312231618453, 0.6913949872807788, 0.6927798000983074, 0.6923466948028851, 0.6924093289449935, 0.6930056520709633, 0.6919133098566635]}
predicting test subjects:   0%|          | 0/15 [00:00<?, ?it/s]predicting test subjects:   7%|▋         | 1/15 [00:02<00:36,  2.58s/it]predicting test subjects:  13%|█▎        | 2/15 [00:04<00:31,  2.42s/it]predicting test subjects:  20%|██        | 3/15 [00:06<00:28,  2.38s/it]predicting test subjects:  27%|██▋       | 4/15 [00:09<00:25,  2.29s/it]predicting test subjects:  33%|███▎      | 5/15 [00:11<00:24,  2.45s/it]predicting test subjects:  40%|████      | 6/15 [00:14<00:22,  2.51s/it]predicting test subjects:  47%|████▋     | 7/15 [00:16<00:17,  2.25s/it]predicting test subjects:  53%|█████▎    | 8/15 [00:18<00:16,  2.34s/it]predicting test subjects:  60%|██████    | 9/15 [00:20<00:13,  2.32s/it]predicting test subjects:  67%|██████▋   | 10/15 [00:22<00:11,  2.23s/it]predicting test subjects:  73%|███████▎  | 11/15 [00:24<00:08,  2.16s/it]predicting test subjects:  80%|████████  | 12/15 [00:27<00:06,  2.18s/it]predicting test subjects:  87%|████████▋ | 13/15 [00:29<00:04,  2.28s/it]predicting test subjects:  93%|█████████▎| 14/15 [00:31<00:02,  2.22s/it]predicting test subjects: 100%|██████████| 15/15 [00:34<00:00,  2.25s/it]
predicting train subjects:   0%|          | 0/532 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/532 [00:02<23:59,  2.71s/it]predicting train subjects:   0%|          | 2/532 [00:04<22:02,  2.50s/it]predicting train subjects:   1%|          | 3/532 [00:06<20:54,  2.37s/it]predicting train subjects:   1%|          | 4/532 [00:08<19:36,  2.23s/it]predicting train subjects:   1%|          | 5/532 [00:10<18:49,  2.14s/it]predicting train subjects:   1%|          | 6/532 [00:12<18:36,  2.12s/it]predicting train subjects:   1%|▏         | 7/532 [00:14<18:26,  2.11s/it]predicting train subjects:   2%|▏         | 8/532 [00:16<17:54,  2.05s/it]predicting train subjects:   2%|▏         | 9/532 [00:19<18:39,  2.14s/it]predicting train subjects:   2%|▏         | 10/532 [00:21<18:18,  2.10s/it]predicting train subjects:   2%|▏         | 11/532 [00:22<17:02,  1.96s/it]predicting train subjects:   2%|▏         | 12/532 [00:25<17:58,  2.07s/it]predicting train subjects:   2%|▏         | 13/532 [00:26<17:06,  1.98s/it]predicting train subjects:   3%|▎         | 14/532 [00:28<16:15,  1.88s/it]predicting train subjects:   3%|▎         | 15/532 [00:30<15:28,  1.80s/it]predicting train subjects:   3%|▎         | 16/532 [00:31<15:18,  1.78s/it]predicting train subjects:   3%|▎         | 17/532 [00:33<14:18,  1.67s/it]predicting train subjects:   3%|▎         | 18/532 [00:35<14:50,  1.73s/it]predicting train subjects:   4%|▎         | 19/532 [00:36<13:49,  1.62s/it]predicting train subjects:   4%|▍         | 20/532 [00:38<14:10,  1.66s/it]predicting train subjects:   4%|▍         | 21/532 [00:40<15:13,  1.79s/it]predicting train subjects:   4%|▍         | 22/532 [00:41<14:52,  1.75s/it]predicting train subjects:   4%|▍         | 23/532 [00:43<14:59,  1.77s/it]predicting train subjects:   5%|▍         | 24/532 [00:45<14:04,  1.66s/it]predicting train subjects:   5%|▍         | 25/532 [00:47<15:23,  1.82s/it]predicting train subjects:   5%|▍         | 26/532 [00:49<15:02,  1.78s/it]predicting train subjects:   5%|▌         | 27/532 [00:51<16:46,  1.99s/it]predicting train subjects:   5%|▌         | 28/532 [00:53<16:09,  1.92s/it]predicting train subjects:   5%|▌         | 29/532 [00:55<16:25,  1.96s/it]predicting train subjects:   6%|▌         | 30/532 [00:56<15:14,  1.82s/it]predicting train subjects:   6%|▌         | 31/532 [00:58<15:09,  1.82s/it]predicting train subjects:   6%|▌         | 32/532 [01:00<15:35,  1.87s/it]predicting train subjects:   6%|▌         | 33/532 [01:02<14:37,  1.76s/it]predicting train subjects:   6%|▋         | 34/532 [01:04<15:27,  1.86s/it]predicting train subjects:   7%|▋         | 35/532 [01:05<14:58,  1.81s/it]predicting train subjects:   7%|▋         | 36/532 [01:07<15:05,  1.82s/it]predicting train subjects:   7%|▋         | 37/532 [01:09<15:06,  1.83s/it]predicting train subjects:   7%|▋         | 38/532 [01:11<15:36,  1.90s/it]predicting train subjects:   7%|▋         | 39/532 [01:13<15:12,  1.85s/it]predicting train subjects:   8%|▊         | 40/532 [01:15<14:42,  1.79s/it]predicting train subjects:   8%|▊         | 41/532 [01:17<15:01,  1.84s/it]predicting train subjects:   8%|▊         | 42/532 [01:18<14:59,  1.84s/it]predicting train subjects:   8%|▊         | 43/532 [01:20<14:15,  1.75s/it]predicting train subjects:   8%|▊         | 44/532 [01:21<13:24,  1.65s/it]predicting train subjects:   8%|▊         | 45/532 [01:23<13:11,  1.63s/it]predicting train subjects:   9%|▊         | 46/532 [01:25<13:33,  1.67s/it]predicting train subjects:   9%|▉         | 47/532 [01:27<15:32,  1.92s/it]predicting train subjects:   9%|▉         | 48/532 [01:29<15:26,  1.91s/it]predicting train subjects:   9%|▉         | 49/532 [01:31<14:44,  1.83s/it]predicting train subjects:   9%|▉         | 50/532 [01:33<15:15,  1.90s/it]predicting train subjects:  10%|▉         | 51/532 [01:34<14:34,  1.82s/it]predicting train subjects:  10%|▉         | 52/532 [01:36<14:16,  1.78s/it]predicting train subjects:  10%|▉         | 53/532 [01:38<13:50,  1.73s/it]predicting train subjects:  10%|█         | 54/532 [01:40<14:29,  1.82s/it]predicting train subjects:  10%|█         | 55/532 [01:42<14:35,  1.83s/it]predicting train subjects:  11%|█         | 56/532 [01:43<14:27,  1.82s/it]predicting train subjects:  11%|█         | 57/532 [01:45<14:26,  1.83s/it]predicting train subjects:  11%|█         | 58/532 [01:47<14:22,  1.82s/it]predicting train subjects:  11%|█         | 59/532 [01:50<16:05,  2.04s/it]predicting train subjects:  11%|█▏        | 60/532 [01:51<14:39,  1.86s/it]predicting train subjects:  11%|█▏        | 61/532 [01:53<13:53,  1.77s/it]predicting train subjects:  12%|█▏        | 62/532 [01:55<14:28,  1.85s/it]predicting train subjects:  12%|█▏        | 63/532 [01:57<14:57,  1.91s/it]predicting train subjects:  12%|█▏        | 64/532 [01:58<14:12,  1.82s/it]predicting train subjects:  12%|█▏        | 65/532 [02:00<14:02,  1.80s/it]predicting train subjects:  12%|█▏        | 66/532 [02:02<15:28,  1.99s/it]predicting train subjects:  13%|█▎        | 67/532 [02:05<15:52,  2.05s/it]predicting train subjects:  13%|█▎        | 68/532 [02:07<15:37,  2.02s/it]predicting train subjects:  13%|█▎        | 69/532 [02:08<15:15,  1.98s/it]predicting train subjects:  13%|█▎        | 70/532 [02:10<14:27,  1.88s/it]predicting train subjects:  13%|█▎        | 71/532 [02:12<13:50,  1.80s/it]predicting train subjects:  14%|█▎        | 72/532 [02:13<13:24,  1.75s/it]predicting train subjects:  14%|█▎        | 73/532 [02:15<14:01,  1.83s/it]predicting train subjects:  14%|█▍        | 74/532 [02:18<15:15,  2.00s/it]predicting train subjects:  14%|█▍        | 75/532 [02:21<17:16,  2.27s/it]predicting train subjects:  14%|█▍        | 76/532 [02:22<15:56,  2.10s/it]predicting train subjects:  14%|█▍        | 77/532 [02:24<15:18,  2.02s/it]predicting train subjects:  15%|█▍        | 78/532 [02:27<15:53,  2.10s/it]predicting train subjects:  15%|█▍        | 79/532 [02:28<15:11,  2.01s/it]predicting train subjects:  15%|█▌        | 80/532 [02:30<14:41,  1.95s/it]predicting train subjects:  15%|█▌        | 81/532 [02:32<14:23,  1.91s/it]predicting train subjects:  15%|█▌        | 82/532 [02:34<14:03,  1.87s/it]predicting train subjects:  16%|█▌        | 83/532 [02:35<13:19,  1.78s/it]predicting train subjects:  16%|█▌        | 84/532 [02:37<12:48,  1.71s/it]predicting train subjects:  16%|█▌        | 85/532 [02:38<12:28,  1.67s/it]predicting train subjects:  16%|█▌        | 86/532 [02:40<12:08,  1.63s/it]predicting train subjects:  16%|█▋        | 87/532 [02:42<11:58,  1.61s/it]predicting train subjects:  17%|█▋        | 88/532 [02:43<11:45,  1.59s/it]predicting train subjects:  17%|█▋        | 89/532 [02:45<12:24,  1.68s/it]predicting train subjects:  17%|█▋        | 90/532 [02:47<12:28,  1.69s/it]predicting train subjects:  17%|█▋        | 91/532 [02:48<12:33,  1.71s/it]predicting train subjects:  17%|█▋        | 92/532 [02:50<12:39,  1.73s/it]predicting train subjects:  17%|█▋        | 93/532 [02:52<12:37,  1.73s/it]predicting train subjects:  18%|█▊        | 94/532 [02:54<12:38,  1.73s/it]predicting train subjects:  18%|█▊        | 95/532 [02:56<13:28,  1.85s/it]predicting train subjects:  18%|█▊        | 96/532 [02:58<13:39,  1.88s/it]predicting train subjects:  18%|█▊        | 97/532 [03:00<13:57,  1.93s/it]predicting train subjects:  18%|█▊        | 98/532 [03:02<14:02,  1.94s/it]predicting train subjects:  19%|█▊        | 99/532 [03:04<14:22,  1.99s/it]predicting train subjects:  19%|█▉        | 100/532 [03:06<14:22,  2.00s/it]predicting train subjects:  19%|█▉        | 101/532 [03:07<13:22,  1.86s/it]predicting train subjects:  19%|█▉        | 102/532 [03:09<12:45,  1.78s/it]predicting train subjects:  19%|█▉        | 103/532 [03:11<12:12,  1.71s/it]predicting train subjects:  20%|█▉        | 104/532 [03:12<11:50,  1.66s/it]predicting train subjects:  20%|█▉        | 105/532 [03:14<11:38,  1.64s/it]predicting train subjects:  20%|█▉        | 106/532 [03:15<11:18,  1.59s/it]predicting train subjects:  20%|██        | 107/532 [03:17<11:13,  1.58s/it]predicting train subjects:  20%|██        | 108/532 [03:18<11:09,  1.58s/it]predicting train subjects:  20%|██        | 109/532 [03:20<11:00,  1.56s/it]predicting train subjects:  21%|██        | 110/532 [03:22<11:12,  1.59s/it]predicting train subjects:  21%|██        | 111/532 [03:23<11:07,  1.59s/it]predicting train subjects:  21%|██        | 112/532 [03:25<11:07,  1.59s/it]predicting train subjects:  21%|██        | 113/532 [03:27<11:36,  1.66s/it]predicting train subjects:  21%|██▏       | 114/532 [03:28<11:50,  1.70s/it]predicting train subjects:  22%|██▏       | 115/532 [03:30<11:59,  1.72s/it]predicting train subjects:  22%|██▏       | 116/532 [03:32<12:06,  1.75s/it]predicting train subjects:  22%|██▏       | 117/532 [03:34<12:09,  1.76s/it]predicting train subjects:  22%|██▏       | 118/532 [03:35<12:14,  1.77s/it]predicting train subjects:  22%|██▏       | 119/532 [03:37<12:13,  1.78s/it]predicting train subjects:  23%|██▎       | 120/532 [03:39<12:25,  1.81s/it]predicting train subjects:  23%|██▎       | 121/532 [03:41<12:17,  1.80s/it]predicting train subjects:  23%|██▎       | 122/532 [03:43<12:12,  1.79s/it]predicting train subjects:  23%|██▎       | 123/532 [03:44<12:01,  1.76s/it]predicting train subjects:  23%|██▎       | 124/532 [03:46<11:59,  1.76s/it]predicting train subjects:  23%|██▎       | 125/532 [03:48<12:13,  1.80s/it]predicting train subjects:  24%|██▎       | 126/532 [03:50<12:37,  1.87s/it]predicting train subjects:  24%|██▍       | 127/532 [03:52<12:40,  1.88s/it]predicting train subjects:  24%|██▍       | 128/532 [03:54<12:37,  1.88s/it]predicting train subjects:  24%|██▍       | 129/532 [03:56<12:58,  1.93s/it]predicting train subjects:  24%|██▍       | 130/532 [03:58<13:03,  1.95s/it]predicting train subjects:  25%|██▍       | 131/532 [04:00<14:08,  2.12s/it]predicting train subjects:  25%|██▍       | 132/532 [04:03<14:40,  2.20s/it]predicting train subjects:  25%|██▌       | 133/532 [04:05<14:39,  2.21s/it]predicting train subjects:  25%|██▌       | 134/532 [04:07<14:42,  2.22s/it]predicting train subjects:  25%|██▌       | 135/532 [04:10<14:46,  2.23s/it]predicting train subjects:  26%|██▌       | 136/532 [04:12<14:39,  2.22s/it]predicting train subjects:  26%|██▌       | 137/532 [04:14<14:39,  2.23s/it]predicting train subjects:  26%|██▌       | 138/532 [04:16<14:43,  2.24s/it]predicting train subjects:  26%|██▌       | 139/532 [04:18<14:43,  2.25s/it]predicting train subjects:  26%|██▋       | 140/532 [04:21<14:48,  2.27s/it]predicting train subjects:  27%|██▋       | 141/532 [04:23<14:40,  2.25s/it]predicting train subjects:  27%|██▋       | 142/532 [04:25<14:35,  2.25s/it]predicting train subjects:  27%|██▋       | 143/532 [04:27<13:26,  2.07s/it]predicting train subjects:  27%|██▋       | 144/532 [04:29<12:37,  1.95s/it]predicting train subjects:  27%|██▋       | 145/532 [04:30<12:05,  1.88s/it]predicting train subjects:  27%|██▋       | 146/532 [04:32<11:31,  1.79s/it]predicting train subjects:  28%|██▊       | 147/532 [04:34<11:23,  1.78s/it]predicting train subjects:  28%|██▊       | 148/532 [04:35<11:11,  1.75s/it]predicting train subjects:  28%|██▊       | 149/532 [04:37<11:18,  1.77s/it]predicting train subjects:  28%|██▊       | 150/532 [04:39<11:19,  1.78s/it]predicting train subjects:  28%|██▊       | 151/532 [04:41<11:19,  1.78s/it]predicting train subjects:  29%|██▊       | 152/532 [04:43<11:23,  1.80s/it]predicting train subjects:  29%|██▉       | 153/532 [04:44<11:15,  1.78s/it]predicting train subjects:  29%|██▉       | 154/532 [04:46<11:11,  1.78s/it]predicting train subjects:  29%|██▉       | 155/532 [04:48<12:15,  1.95s/it]predicting train subjects:  29%|██▉       | 156/532 [04:51<12:56,  2.07s/it]predicting train subjects:  30%|██▉       | 157/532 [04:53<13:28,  2.16s/it]predicting train subjects:  30%|██▉       | 158/532 [04:55<13:44,  2.20s/it]predicting train subjects:  30%|██▉       | 159/532 [04:58<14:01,  2.26s/it]predicting train subjects:  30%|███       | 160/532 [05:00<14:10,  2.29s/it]predicting train subjects:  30%|███       | 161/532 [05:02<12:59,  2.10s/it]predicting train subjects:  30%|███       | 162/532 [05:04<12:09,  1.97s/it]predicting train subjects:  31%|███       | 163/532 [05:05<11:38,  1.89s/it]predicting train subjects:  31%|███       | 164/532 [05:07<11:12,  1.83s/it]predicting train subjects:  31%|███       | 165/532 [05:09<10:54,  1.78s/it]predicting train subjects:  31%|███       | 166/532 [05:10<10:40,  1.75s/it]predicting train subjects:  31%|███▏      | 167/532 [05:12<10:52,  1.79s/it]predicting train subjects:  32%|███▏      | 168/532 [05:14<10:45,  1.77s/it]predicting train subjects:  32%|███▏      | 169/532 [05:16<10:39,  1.76s/it]predicting train subjects:  32%|███▏      | 170/532 [05:17<10:35,  1.75s/it]predicting train subjects:  32%|███▏      | 171/532 [05:19<10:32,  1.75s/it]predicting train subjects:  32%|███▏      | 172/532 [05:21<10:23,  1.73s/it]predicting train subjects:  33%|███▎      | 173/532 [05:22<10:08,  1.70s/it]predicting train subjects:  33%|███▎      | 174/532 [05:24<10:00,  1.68s/it]predicting train subjects:  33%|███▎      | 175/532 [05:26<09:52,  1.66s/it]predicting train subjects:  33%|███▎      | 176/532 [05:27<09:49,  1.66s/it]predicting train subjects:  33%|███▎      | 177/532 [05:29<09:40,  1.63s/it]predicting train subjects:  33%|███▎      | 178/532 [05:31<09:53,  1.68s/it]predicting train subjects:  34%|███▎      | 179/532 [05:32<09:53,  1.68s/it]predicting train subjects:  34%|███▍      | 180/532 [05:34<09:54,  1.69s/it]predicting train subjects:  34%|███▍      | 181/532 [05:36<09:55,  1.70s/it]predicting train subjects:  34%|███▍      | 182/532 [05:38<10:22,  1.78s/it]predicting train subjects:  34%|███▍      | 183/532 [05:39<10:09,  1.75s/it]predicting train subjects:  35%|███▍      | 184/532 [05:41<10:15,  1.77s/it]predicting train subjects:  35%|███▍      | 185/532 [05:43<09:52,  1.71s/it]predicting train subjects:  35%|███▍      | 186/532 [05:44<09:42,  1.68s/it]predicting train subjects:  35%|███▌      | 187/532 [05:46<09:26,  1.64s/it]predicting train subjects:  35%|███▌      | 188/532 [05:48<09:18,  1.62s/it]predicting train subjects:  36%|███▌      | 189/532 [05:49<09:12,  1.61s/it]predicting train subjects:  36%|███▌      | 190/532 [05:51<09:05,  1.60s/it]predicting train subjects:  36%|███▌      | 191/532 [05:53<10:17,  1.81s/it]predicting train subjects:  36%|███▌      | 192/532 [05:56<11:36,  2.05s/it]predicting train subjects:  36%|███▋      | 193/532 [05:58<11:59,  2.12s/it]predicting train subjects:  36%|███▋      | 194/532 [06:00<12:18,  2.19s/it]predicting train subjects:  37%|███▋      | 195/532 [06:02<12:21,  2.20s/it]predicting train subjects:  37%|███▋      | 196/532 [06:05<12:28,  2.23s/it]predicting train subjects:  37%|███▋      | 197/532 [06:07<12:07,  2.17s/it]predicting train subjects:  37%|███▋      | 198/532 [06:09<11:52,  2.13s/it]predicting train subjects:  37%|███▋      | 199/532 [06:11<11:34,  2.09s/it]predicting train subjects:  38%|███▊      | 200/532 [06:13<11:23,  2.06s/it]predicting train subjects:  38%|███▊      | 201/532 [06:15<11:12,  2.03s/it]predicting train subjects:  38%|███▊      | 202/532 [06:17<11:11,  2.03s/it]predicting train subjects:  38%|███▊      | 203/532 [06:18<10:27,  1.91s/it]predicting train subjects:  38%|███▊      | 204/532 [06:20<10:00,  1.83s/it]predicting train subjects:  39%|███▊      | 205/532 [06:22<09:55,  1.82s/it]predicting train subjects:  39%|███▊      | 206/532 [06:24<09:35,  1.77s/it]predicting train subjects:  39%|███▉      | 207/532 [06:25<09:23,  1.73s/it]predicting train subjects:  39%|███▉      | 208/532 [06:27<09:20,  1.73s/it]predicting train subjects:  39%|███▉      | 209/532 [06:28<08:55,  1.66s/it]predicting train subjects:  39%|███▉      | 210/532 [06:30<08:29,  1.58s/it]predicting train subjects:  40%|███▉      | 211/532 [06:31<08:16,  1.55s/it]predicting train subjects:  40%|███▉      | 212/532 [06:33<08:07,  1.52s/it]predicting train subjects:  40%|████      | 213/532 [06:34<08:07,  1.53s/it]predicting train subjects:  40%|████      | 214/532 [06:36<08:00,  1.51s/it]predicting train subjects:  40%|████      | 215/532 [06:38<08:56,  1.69s/it]predicting train subjects:  41%|████      | 216/532 [06:40<09:35,  1.82s/it]predicting train subjects:  41%|████      | 217/532 [06:42<10:07,  1.93s/it]predicting train subjects:  41%|████      | 218/532 [06:44<10:26,  2.00s/it]predicting train subjects:  41%|████      | 219/532 [06:46<10:40,  2.05s/it]predicting train subjects:  41%|████▏     | 220/532 [06:49<10:46,  2.07s/it]predicting train subjects:  42%|████▏     | 221/532 [06:50<09:46,  1.89s/it]predicting train subjects:  42%|████▏     | 222/532 [06:51<09:01,  1.75s/it]predicting train subjects:  42%|████▏     | 223/532 [06:53<08:33,  1.66s/it]predicting train subjects:  42%|████▏     | 224/532 [06:55<08:50,  1.72s/it]predicting train subjects:  42%|████▏     | 225/532 [06:56<08:20,  1.63s/it]predicting train subjects:  42%|████▏     | 226/532 [06:58<08:02,  1.58s/it]predicting train subjects:  43%|████▎     | 227/532 [06:59<07:45,  1.53s/it]predicting train subjects:  43%|████▎     | 228/532 [07:00<07:32,  1.49s/it]predicting train subjects:  43%|████▎     | 229/532 [07:02<07:20,  1.45s/it]predicting train subjects:  43%|████▎     | 230/532 [07:03<07:11,  1.43s/it]predicting train subjects:  43%|████▎     | 231/532 [07:05<07:09,  1.43s/it]predicting train subjects:  44%|████▎     | 232/532 [07:06<07:05,  1.42s/it]predicting train subjects:  44%|████▍     | 233/532 [07:08<07:25,  1.49s/it]predicting train subjects:  44%|████▍     | 234/532 [07:09<07:37,  1.53s/it]predicting train subjects:  44%|████▍     | 235/532 [07:11<07:42,  1.56s/it]predicting train subjects:  44%|████▍     | 236/532 [07:13<07:46,  1.58s/it]predicting train subjects:  45%|████▍     | 237/532 [07:14<07:57,  1.62s/it]predicting train subjects:  45%|████▍     | 238/532 [07:16<08:02,  1.64s/it]predicting train subjects:  45%|████▍     | 239/532 [07:18<08:13,  1.69s/it]predicting train subjects:  45%|████▌     | 240/532 [07:20<08:28,  1.74s/it]predicting train subjects:  45%|████▌     | 241/532 [07:21<08:33,  1.76s/it]predicting train subjects:  45%|████▌     | 242/532 [07:23<08:34,  1.77s/it]predicting train subjects:  46%|████▌     | 243/532 [07:25<08:35,  1.78s/it]predicting train subjects:  46%|████▌     | 244/532 [07:27<08:29,  1.77s/it]predicting train subjects:  46%|████▌     | 245/532 [07:28<08:01,  1.68s/it]predicting train subjects:  46%|████▌     | 246/532 [07:30<07:40,  1.61s/it]predicting train subjects:  46%|████▋     | 247/532 [07:31<07:22,  1.55s/it]predicting train subjects:  47%|████▋     | 248/532 [07:33<07:08,  1.51s/it]predicting train subjects:  47%|████▋     | 249/532 [07:34<06:57,  1.48s/it]predicting train subjects:  47%|████▋     | 250/532 [07:35<06:52,  1.46s/it]predicting train subjects:  47%|████▋     | 251/532 [07:37<07:01,  1.50s/it]predicting train subjects:  47%|████▋     | 252/532 [07:39<07:06,  1.52s/it]predicting train subjects:  48%|████▊     | 253/532 [07:40<07:28,  1.61s/it]predicting train subjects:  48%|████▊     | 254/532 [07:42<07:16,  1.57s/it]predicting train subjects:  48%|████▊     | 255/532 [07:43<07:15,  1.57s/it]predicting train subjects:  48%|████▊     | 256/532 [07:45<07:12,  1.57s/it]predicting train subjects:  48%|████▊     | 257/532 [07:47<07:45,  1.69s/it]predicting train subjects:  48%|████▊     | 258/532 [07:49<08:05,  1.77s/it]predicting train subjects:  49%|████▊     | 259/532 [07:51<08:18,  1.83s/it]predicting train subjects:  49%|████▉     | 260/532 [07:53<08:25,  1.86s/it]predicting train subjects:  49%|████▉     | 261/532 [07:55<08:50,  1.96s/it]predicting train subjects:  49%|████▉     | 262/532 [07:57<08:45,  1.95s/it]predicting train subjects:  49%|████▉     | 263/532 [07:58<08:06,  1.81s/it]predicting train subjects:  50%|████▉     | 264/532 [08:00<07:31,  1.68s/it]predicting train subjects:  50%|████▉     | 265/532 [08:01<07:06,  1.60s/it]predicting train subjects:  50%|█████     | 266/532 [08:03<06:50,  1.54s/it]predicting train subjects:  50%|█████     | 267/532 [08:04<06:38,  1.51s/it]predicting train subjects:  50%|█████     | 268/532 [08:05<06:27,  1.47s/it]predicting train subjects:  51%|█████     | 269/532 [08:07<06:46,  1.54s/it]predicting train subjects:  51%|█████     | 270/532 [08:09<07:23,  1.69s/it]predicting train subjects:  51%|█████     | 271/532 [08:11<07:27,  1.72s/it]predicting train subjects:  51%|█████     | 272/532 [08:13<07:28,  1.72s/it]predicting train subjects:  51%|█████▏    | 273/532 [08:14<07:28,  1.73s/it]predicting train subjects:  52%|█████▏    | 274/532 [08:16<07:29,  1.74s/it]predicting train subjects:  52%|█████▏    | 275/532 [08:18<07:56,  1.86s/it]predicting train subjects:  52%|█████▏    | 276/532 [08:20<08:21,  1.96s/it]predicting train subjects:  52%|█████▏    | 277/532 [08:23<08:32,  2.01s/it]predicting train subjects:  52%|█████▏    | 278/532 [08:25<08:35,  2.03s/it]predicting train subjects:  52%|█████▏    | 279/532 [08:27<08:41,  2.06s/it]predicting train subjects:  53%|█████▎    | 280/532 [08:29<09:17,  2.21s/it]predicting train subjects:  53%|█████▎    | 281/532 [08:31<09:02,  2.16s/it]predicting train subjects:  53%|█████▎    | 282/532 [08:33<08:53,  2.13s/it]predicting train subjects:  53%|█████▎    | 283/532 [08:36<08:50,  2.13s/it]predicting train subjects:  53%|█████▎    | 284/532 [08:38<08:42,  2.11s/it]predicting train subjects:  54%|█████▎    | 285/532 [08:40<08:38,  2.10s/it]predicting train subjects:  54%|█████▍    | 286/532 [08:42<08:30,  2.08s/it]predicting train subjects:  54%|█████▍    | 287/532 [08:43<07:50,  1.92s/it]predicting train subjects:  54%|█████▍    | 288/532 [08:45<07:17,  1.79s/it]predicting train subjects:  54%|█████▍    | 289/532 [08:46<07:00,  1.73s/it]predicting train subjects:  55%|█████▍    | 290/532 [08:48<06:42,  1.66s/it]predicting train subjects:  55%|█████▍    | 291/532 [08:49<06:32,  1.63s/it]predicting train subjects:  55%|█████▍    | 292/532 [08:51<06:31,  1.63s/it]predicting train subjects:  55%|█████▌    | 293/532 [08:53<06:45,  1.70s/it]predicting train subjects:  55%|█████▌    | 294/532 [08:55<06:46,  1.71s/it]predicting train subjects:  55%|█████▌    | 295/532 [08:56<06:51,  1.74s/it]predicting train subjects:  56%|█████▌    | 296/532 [08:58<06:50,  1.74s/it]predicting train subjects:  56%|█████▌    | 297/532 [09:00<06:48,  1.74s/it]predicting train subjects:  56%|█████▌    | 298/532 [09:02<06:45,  1.73s/it]predicting train subjects:  56%|█████▌    | 299/532 [09:03<06:22,  1.64s/it]predicting train subjects:  56%|█████▋    | 300/532 [09:05<06:04,  1.57s/it]predicting train subjects:  57%|█████▋    | 301/532 [09:06<05:51,  1.52s/it]predicting train subjects:  57%|█████▋    | 302/532 [09:07<05:49,  1.52s/it]predicting train subjects:  57%|█████▋    | 303/532 [09:09<05:41,  1.49s/it]predicting train subjects:  57%|█████▋    | 304/532 [09:10<05:35,  1.47s/it]predicting train subjects:  57%|█████▋    | 305/532 [09:12<06:23,  1.69s/it]predicting train subjects:  58%|█████▊    | 306/532 [09:15<06:49,  1.81s/it]predicting train subjects:  58%|█████▊    | 307/532 [09:17<07:07,  1.90s/it]predicting train subjects:  58%|█████▊    | 308/532 [09:19<07:44,  2.08s/it]predicting train subjects:  58%|█████▊    | 309/532 [09:21<07:46,  2.09s/it]predicting train subjects:  58%|█████▊    | 310/532 [09:23<07:46,  2.10s/it]predicting train subjects:  58%|█████▊    | 311/532 [09:26<08:35,  2.33s/it]predicting train subjects:  59%|█████▊    | 312/532 [09:29<09:06,  2.48s/it]predicting train subjects:  59%|█████▉    | 313/532 [09:32<09:48,  2.69s/it]predicting train subjects:  59%|█████▉    | 314/532 [09:35<09:56,  2.74s/it]predicting train subjects:  59%|█████▉    | 315/532 [09:38<10:00,  2.77s/it]predicting train subjects:  59%|█████▉    | 316/532 [09:41<10:03,  2.79s/it]predicting train subjects:  60%|█████▉    | 317/532 [09:42<08:41,  2.43s/it]predicting train subjects:  60%|█████▉    | 318/532 [09:44<07:44,  2.17s/it]predicting train subjects:  60%|█████▉    | 319/532 [09:46<07:14,  2.04s/it]predicting train subjects:  60%|██████    | 320/532 [09:47<06:45,  1.91s/it]predicting train subjects:  60%|██████    | 321/532 [09:49<06:20,  1.80s/it]predicting train subjects:  61%|██████    | 322/532 [09:50<06:05,  1.74s/it]predicting train subjects:  61%|██████    | 323/532 [09:53<06:37,  1.90s/it]predicting train subjects:  61%|██████    | 324/532 [09:55<07:00,  2.02s/it]predicting train subjects:  61%|██████    | 325/532 [09:57<07:12,  2.09s/it]predicting train subjects:  61%|██████▏   | 326/532 [10:00<07:18,  2.13s/it]predicting train subjects:  61%|██████▏   | 327/532 [10:02<07:26,  2.18s/it]predicting train subjects:  62%|██████▏   | 328/532 [10:04<07:30,  2.21s/it]predicting train subjects:  62%|██████▏   | 329/532 [10:06<06:54,  2.04s/it]predicting train subjects:  62%|██████▏   | 330/532 [10:08<06:34,  1.95s/it]predicting train subjects:  62%|██████▏   | 331/532 [10:09<06:15,  1.87s/it]predicting train subjects:  62%|██████▏   | 332/532 [10:11<06:04,  1.82s/it]predicting train subjects:  63%|██████▎   | 333/532 [10:13<05:51,  1.77s/it]predicting train subjects:  63%|██████▎   | 334/532 [10:14<05:47,  1.76s/it]predicting train subjects:  63%|██████▎   | 335/532 [10:16<06:03,  1.84s/it]predicting train subjects:  63%|██████▎   | 336/532 [10:18<06:10,  1.89s/it]predicting train subjects:  63%|██████▎   | 337/532 [10:20<06:13,  1.91s/it]predicting train subjects:  64%|██████▎   | 338/532 [10:22<06:15,  1.94s/it]predicting train subjects:  64%|██████▎   | 339/532 [10:24<06:13,  1.94s/it]predicting train subjects:  64%|██████▍   | 340/532 [10:26<06:18,  1.97s/it]predicting train subjects:  64%|██████▍   | 341/532 [10:28<05:45,  1.81s/it]predicting train subjects:  64%|██████▍   | 342/532 [10:29<05:29,  1.73s/it]predicting train subjects:  64%|██████▍   | 343/532 [10:31<05:11,  1.65s/it]predicting train subjects:  65%|██████▍   | 344/532 [10:32<04:56,  1.58s/it]predicting train subjects:  65%|██████▍   | 345/532 [10:34<04:50,  1.55s/it]predicting train subjects:  65%|██████▌   | 346/532 [10:35<04:50,  1.56s/it]predicting train subjects:  65%|██████▌   | 347/532 [10:37<05:01,  1.63s/it]predicting train subjects:  65%|██████▌   | 348/532 [10:39<05:03,  1.65s/it]predicting train subjects:  66%|██████▌   | 349/532 [10:40<05:07,  1.68s/it]predicting train subjects:  66%|██████▌   | 350/532 [10:42<05:06,  1.68s/it]predicting train subjects:  66%|██████▌   | 351/532 [10:44<05:05,  1.69s/it]predicting train subjects:  66%|██████▌   | 352/532 [10:45<05:00,  1.67s/it]predicting train subjects:  66%|██████▋   | 353/532 [10:47<04:57,  1.66s/it]predicting train subjects:  67%|██████▋   | 354/532 [10:49<04:53,  1.65s/it]predicting train subjects:  67%|██████▋   | 355/532 [10:50<04:53,  1.66s/it]predicting train subjects:  67%|██████▋   | 356/532 [10:52<04:49,  1.64s/it]predicting train subjects:  67%|██████▋   | 357/532 [10:54<04:50,  1.66s/it]predicting train subjects:  67%|██████▋   | 358/532 [10:55<04:48,  1.66s/it]predicting train subjects:  67%|██████▋   | 359/532 [10:57<04:41,  1.63s/it]predicting train subjects:  68%|██████▊   | 360/532 [10:58<04:34,  1.60s/it]predicting train subjects:  68%|██████▊   | 361/532 [11:00<04:27,  1.56s/it]predicting train subjects:  68%|██████▊   | 362/532 [11:01<04:20,  1.53s/it]predicting train subjects:  68%|██████▊   | 363/532 [11:03<04:17,  1.52s/it]predicting train subjects:  68%|██████▊   | 364/532 [11:04<04:15,  1.52s/it]predicting train subjects:  69%|██████▊   | 365/532 [11:06<04:12,  1.51s/it]predicting train subjects:  69%|██████▉   | 366/532 [11:07<04:11,  1.51s/it]predicting train subjects:  69%|██████▉   | 367/532 [11:09<04:09,  1.51s/it]predicting train subjects:  69%|██████▉   | 368/532 [11:10<04:05,  1.50s/it]predicting train subjects:  69%|██████▉   | 369/532 [11:12<04:03,  1.49s/it]predicting train subjects:  70%|██████▉   | 370/532 [11:13<03:58,  1.47s/it]predicting train subjects:  70%|██████▉   | 371/532 [11:15<04:23,  1.63s/it]predicting train subjects:  70%|██████▉   | 372/532 [11:17<04:40,  1.75s/it]predicting train subjects:  70%|███████   | 373/532 [11:19<04:52,  1.84s/it]predicting train subjects:  70%|███████   | 374/532 [11:21<05:04,  1.93s/it]predicting train subjects:  70%|███████   | 375/532 [11:24<05:12,  1.99s/it]predicting train subjects:  71%|███████   | 376/532 [11:26<05:15,  2.03s/it]predicting train subjects:  71%|███████   | 377/532 [11:27<04:58,  1.92s/it]predicting train subjects:  71%|███████   | 378/532 [11:29<04:45,  1.85s/it]predicting train subjects:  71%|███████   | 379/532 [11:31<04:36,  1.81s/it]predicting train subjects:  71%|███████▏  | 380/532 [11:33<04:30,  1.78s/it]predicting train subjects:  72%|███████▏  | 381/532 [11:34<04:26,  1.77s/it]predicting train subjects:  72%|███████▏  | 382/532 [11:36<04:22,  1.75s/it]predicting train subjects:  72%|███████▏  | 383/532 [11:38<04:27,  1.80s/it]predicting train subjects:  72%|███████▏  | 384/532 [11:40<04:28,  1.81s/it]predicting train subjects:  72%|███████▏  | 385/532 [11:42<04:26,  1.82s/it]predicting train subjects:  73%|███████▎  | 386/532 [11:43<04:25,  1.82s/it]predicting train subjects:  73%|███████▎  | 387/532 [11:45<04:25,  1.83s/it]predicting train subjects:  73%|███████▎  | 388/532 [11:47<04:18,  1.79s/it]predicting train subjects:  73%|███████▎  | 389/532 [11:49<04:16,  1.80s/it]predicting train subjects:  73%|███████▎  | 390/532 [11:51<04:18,  1.82s/it]predicting train subjects:  73%|███████▎  | 391/532 [11:52<04:15,  1.81s/it]predicting train subjects:  74%|███████▎  | 392/532 [11:54<04:14,  1.82s/it]predicting train subjects:  74%|███████▍  | 393/532 [11:56<04:16,  1.84s/it]predicting train subjects:  74%|███████▍  | 394/532 [11:58<04:16,  1.86s/it]predicting train subjects:  74%|███████▍  | 395/532 [12:00<04:18,  1.89s/it]predicting train subjects:  74%|███████▍  | 396/532 [12:02<04:14,  1.87s/it]predicting train subjects:  75%|███████▍  | 397/532 [12:04<04:12,  1.87s/it]predicting train subjects:  75%|███████▍  | 398/532 [12:05<04:07,  1.85s/it]predicting train subjects:  75%|███████▌  | 399/532 [12:07<04:01,  1.82s/it]predicting train subjects:  75%|███████▌  | 400/532 [12:09<04:02,  1.83s/it]predicting train subjects:  75%|███████▌  | 401/532 [12:11<04:05,  1.88s/it]predicting train subjects:  76%|███████▌  | 402/532 [12:13<04:07,  1.90s/it]predicting train subjects:  76%|███████▌  | 403/532 [12:15<04:15,  1.98s/it]predicting train subjects:  76%|███████▌  | 404/532 [12:17<04:14,  1.99s/it]predicting train subjects:  76%|███████▌  | 405/532 [12:19<04:11,  1.98s/it]predicting train subjects:  76%|███████▋  | 406/532 [12:21<04:09,  1.98s/it]predicting train subjects:  77%|███████▋  | 407/532 [12:23<04:00,  1.92s/it]predicting train subjects:  77%|███████▋  | 408/532 [12:25<03:49,  1.85s/it]predicting train subjects:  77%|███████▋  | 409/532 [12:26<03:42,  1.81s/it]predicting train subjects:  77%|███████▋  | 410/532 [12:28<03:37,  1.78s/it]predicting train subjects:  77%|███████▋  | 411/532 [12:30<03:35,  1.78s/it]predicting train subjects:  77%|███████▋  | 412/532 [12:32<03:32,  1.77s/it]predicting train subjects:  78%|███████▊  | 413/532 [12:33<03:29,  1.76s/it]predicting train subjects:  78%|███████▊  | 414/532 [12:35<03:22,  1.72s/it]predicting train subjects:  78%|███████▊  | 415/532 [12:37<03:16,  1.68s/it]predicting train subjects:  78%|███████▊  | 416/532 [12:38<03:10,  1.65s/it]predicting train subjects:  78%|███████▊  | 417/532 [12:40<03:08,  1.64s/it]predicting train subjects:  79%|███████▊  | 418/532 [12:41<03:07,  1.65s/it]predicting train subjects:  79%|███████▉  | 419/532 [12:43<03:12,  1.70s/it]predicting train subjects:  79%|███████▉  | 420/532 [12:45<03:17,  1.76s/it]predicting train subjects:  79%|███████▉  | 421/532 [12:47<03:22,  1.82s/it]predicting train subjects:  79%|███████▉  | 422/532 [12:49<03:24,  1.86s/it]predicting train subjects:  80%|███████▉  | 423/532 [12:51<03:25,  1.89s/it]predicting train subjects:  80%|███████▉  | 424/532 [12:53<03:20,  1.86s/it]predicting train subjects:  80%|███████▉  | 425/532 [12:55<03:18,  1.86s/it]predicting train subjects:  80%|████████  | 426/532 [12:56<03:15,  1.84s/it]predicting train subjects:  80%|████████  | 427/532 [12:58<03:13,  1.84s/it]predicting train subjects:  80%|████████  | 428/532 [13:00<03:12,  1.85s/it]predicting train subjects:  81%|████████  | 429/532 [13:02<03:09,  1.84s/it]predicting train subjects:  81%|████████  | 430/532 [13:04<03:08,  1.85s/it]predicting train subjects:  81%|████████  | 431/532 [13:06<03:15,  1.93s/it]predicting train subjects:  81%|████████  | 432/532 [13:08<03:17,  1.97s/it]predicting train subjects:  81%|████████▏ | 433/532 [13:10<03:15,  1.98s/it]predicting train subjects:  82%|████████▏ | 434/532 [13:12<03:14,  1.99s/it]predicting train subjects:  82%|████████▏ | 435/532 [13:14<03:23,  2.10s/it]predicting train subjects:  82%|████████▏ | 436/532 [13:16<03:18,  2.07s/it]predicting train subjects:  82%|████████▏ | 437/532 [13:18<03:02,  1.92s/it]predicting train subjects:  82%|████████▏ | 438/532 [13:19<02:49,  1.81s/it]predicting train subjects:  83%|████████▎ | 439/532 [13:21<02:42,  1.75s/it]predicting train subjects:  83%|████████▎ | 440/532 [13:23<02:34,  1.68s/it]predicting train subjects:  83%|████████▎ | 441/532 [13:24<02:28,  1.63s/it]predicting train subjects:  83%|████████▎ | 442/532 [13:26<02:22,  1.59s/it]predicting train subjects:  83%|████████▎ | 443/532 [13:27<02:18,  1.55s/it]predicting train subjects:  83%|████████▎ | 444/532 [13:29<02:14,  1.53s/it]predicting train subjects:  84%|████████▎ | 445/532 [13:30<02:08,  1.48s/it]predicting train subjects:  84%|████████▍ | 446/532 [13:31<02:05,  1.46s/it]predicting train subjects:  84%|████████▍ | 447/532 [13:33<02:02,  1.44s/it]predicting train subjects:  84%|████████▍ | 448/532 [13:34<01:59,  1.42s/it]predicting train subjects:  84%|████████▍ | 449/532 [13:36<02:02,  1.48s/it]predicting train subjects:  85%|████████▍ | 450/532 [13:37<02:03,  1.50s/it]predicting train subjects:  85%|████████▍ | 451/532 [13:39<02:03,  1.53s/it]predicting train subjects:  85%|████████▍ | 452/532 [13:40<02:02,  1.54s/it]predicting train subjects:  85%|████████▌ | 453/532 [13:42<02:02,  1.55s/it]predicting train subjects:  85%|████████▌ | 454/532 [13:44<02:04,  1.59s/it]predicting train subjects:  86%|████████▌ | 455/532 [13:46<02:08,  1.67s/it]predicting train subjects:  86%|████████▌ | 456/532 [13:47<02:11,  1.73s/it]predicting train subjects:  86%|████████▌ | 457/532 [13:49<02:11,  1.75s/it]predicting train subjects:  86%|████████▌ | 458/532 [13:51<02:11,  1.77s/it]predicting train subjects:  86%|████████▋ | 459/532 [13:53<02:11,  1.80s/it]predicting train subjects:  86%|████████▋ | 460/532 [13:55<02:12,  1.84s/it]predicting train subjects:  87%|████████▋ | 461/532 [13:57<02:14,  1.90s/it]predicting train subjects:  87%|████████▋ | 462/532 [13:59<02:16,  1.95s/it]predicting train subjects:  87%|████████▋ | 463/532 [14:01<02:17,  1.99s/it]predicting train subjects:  87%|████████▋ | 464/532 [14:03<02:18,  2.04s/it]predicting train subjects:  87%|████████▋ | 465/532 [14:05<02:19,  2.08s/it]predicting train subjects:  88%|████████▊ | 466/532 [14:07<02:17,  2.08s/it]predicting train subjects:  88%|████████▊ | 467/532 [14:09<02:07,  1.97s/it]predicting train subjects:  88%|████████▊ | 468/532 [14:11<01:59,  1.87s/it]predicting train subjects:  88%|████████▊ | 469/532 [14:12<01:54,  1.81s/it]predicting train subjects:  88%|████████▊ | 470/532 [14:14<01:49,  1.77s/it]predicting train subjects:  89%|████████▊ | 471/532 [14:16<01:46,  1.75s/it]predicting train subjects:  89%|████████▊ | 472/532 [14:17<01:42,  1.71s/it]predicting train subjects:  89%|████████▉ | 473/532 [14:19<01:43,  1.75s/it]predicting train subjects:  89%|████████▉ | 474/532 [14:21<01:44,  1.81s/it]predicting train subjects:  89%|████████▉ | 475/532 [14:23<01:44,  1.83s/it]predicting train subjects:  89%|████████▉ | 476/532 [14:25<01:44,  1.87s/it]predicting train subjects:  90%|████████▉ | 477/532 [14:27<01:42,  1.86s/it]predicting train subjects:  90%|████████▉ | 478/532 [14:29<01:40,  1.85s/it]predicting train subjects:  90%|█████████ | 479/532 [14:30<01:34,  1.79s/it]predicting train subjects:  90%|█████████ | 480/532 [14:32<01:29,  1.73s/it]predicting train subjects:  90%|█████████ | 481/532 [14:34<01:27,  1.71s/it]predicting train subjects:  91%|█████████ | 482/532 [14:35<01:23,  1.68s/it]predicting train subjects:  91%|█████████ | 483/532 [14:37<01:20,  1.65s/it]predicting train subjects:  91%|█████████ | 484/532 [14:38<01:17,  1.62s/it]predicting train subjects:  91%|█████████ | 485/532 [14:40<01:21,  1.74s/it]predicting train subjects:  91%|█████████▏| 486/532 [14:42<01:23,  1.82s/it]predicting train subjects:  92%|█████████▏| 487/532 [14:44<01:24,  1.87s/it]predicting train subjects:  92%|█████████▏| 488/532 [14:46<01:23,  1.89s/it]predicting train subjects:  92%|█████████▏| 489/532 [14:48<01:22,  1.93s/it]predicting train subjects:  92%|█████████▏| 490/532 [14:50<01:21,  1.94s/it]predicting train subjects:  92%|█████████▏| 491/532 [14:52<01:17,  1.89s/it]predicting train subjects:  92%|█████████▏| 492/532 [14:54<01:14,  1.85s/it]predicting train subjects:  93%|█████████▎| 493/532 [14:56<01:10,  1.82s/it]predicting train subjects:  93%|█████████▎| 494/532 [14:57<01:07,  1.79s/it]predicting train subjects:  93%|█████████▎| 495/532 [14:59<01:06,  1.79s/it]predicting train subjects:  93%|█████████▎| 496/532 [15:01<01:03,  1.76s/it]predicting train subjects:  93%|█████████▎| 497/532 [15:03<01:01,  1.77s/it]predicting train subjects:  94%|█████████▎| 498/532 [15:04<01:00,  1.77s/it]predicting train subjects:  94%|█████████▍| 499/532 [15:06<00:58,  1.78s/it]predicting train subjects:  94%|█████████▍| 500/532 [15:08<00:56,  1.77s/it]predicting train subjects:  94%|█████████▍| 501/532 [15:10<00:54,  1.76s/it]predicting train subjects:  94%|█████████▍| 502/532 [15:11<00:52,  1.76s/it]predicting train subjects:  95%|█████████▍| 503/532 [15:13<00:50,  1.73s/it]predicting train subjects:  95%|█████████▍| 504/532 [15:15<00:48,  1.72s/it]predicting train subjects:  95%|█████████▍| 505/532 [15:16<00:45,  1.69s/it]predicting train subjects:  95%|█████████▌| 506/532 [15:18<00:45,  1.75s/it]predicting train subjects:  95%|█████████▌| 507/532 [15:20<00:43,  1.72s/it]predicting train subjects:  95%|█████████▌| 508/532 [15:21<00:39,  1.66s/it]predicting train subjects:  96%|█████████▌| 509/532 [15:23<00:40,  1.77s/it]predicting train subjects:  96%|█████████▌| 510/532 [15:26<00:41,  1.87s/it]predicting train subjects:  96%|█████████▌| 511/532 [15:28<00:40,  1.91s/it]predicting train subjects:  96%|█████████▌| 512/532 [15:30<00:39,  1.95s/it]predicting train subjects:  96%|█████████▋| 513/532 [15:32<00:36,  1.93s/it]predicting train subjects:  97%|█████████▋| 514/532 [15:33<00:34,  1.94s/it]predicting train subjects:  97%|█████████▋| 515/532 [15:35<00:31,  1.86s/it]predicting train subjects:  97%|█████████▋| 516/532 [15:37<00:29,  1.82s/it]predicting train subjects:  97%|█████████▋| 517/532 [15:39<00:28,  1.90s/it]predicting train subjects:  97%|█████████▋| 518/532 [15:41<00:25,  1.85s/it]predicting train subjects:  98%|█████████▊| 519/532 [15:42<00:23,  1.80s/it]predicting train subjects:  98%|█████████▊| 520/532 [15:44<00:21,  1.76s/it]predicting train subjects:  98%|█████████▊| 521/532 [15:46<00:19,  1.79s/it]predicting train subjects:  98%|█████████▊| 522/532 [15:48<00:18,  1.81s/it]predicting train subjects:  98%|█████████▊| 523/532 [15:50<00:16,  1.81s/it]predicting train subjects:  98%|█████████▊| 524/532 [15:51<00:14,  1.82s/it]predicting train subjects:  99%|█████████▊| 525/532 [15:53<00:12,  1.84s/it]predicting train subjects:  99%|█████████▉| 526/532 [15:55<00:11,  1.84s/it]predicting train subjects:  99%|█████████▉| 527/532 [15:57<00:09,  1.82s/it]predicting train subjects:  99%|█████████▉| 528/532 [15:59<00:07,  1.78s/it]predicting train subjects:  99%|█████████▉| 529/532 [16:00<00:05,  1.76s/it]predicting train subjects: 100%|█████████▉| 530/532 [16:02<00:03,  1.80s/it]predicting train subjects: 100%|█████████▉| 531/532 [16:04<00:01,  1.78s/it]predicting train subjects: 100%|██████████| 532/532 [16:06<00:00,  1.75s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1’: File exists

Loading train:   0%|          | 0/532 [00:00<?, ?it/s]Loading train:   0%|          | 1/532 [00:01<12:58,  1.47s/it]Loading train:   0%|          | 2/532 [00:02<11:52,  1.34s/it]Loading train:   1%|          | 3/532 [00:03<11:26,  1.30s/it]Loading train:   1%|          | 4/532 [00:04<11:15,  1.28s/it]Loading train:   1%|          | 5/532 [00:06<10:49,  1.23s/it]Loading train:   1%|          | 6/532 [00:07<10:27,  1.19s/it]Loading train:   1%|▏         | 7/532 [00:08<09:47,  1.12s/it]Loading train:   2%|▏         | 8/532 [00:09<09:50,  1.13s/it]Loading train:   2%|▏         | 9/532 [00:10<09:58,  1.14s/it]Loading train:   2%|▏         | 10/532 [00:11<09:27,  1.09s/it]Loading train:   2%|▏         | 11/532 [00:12<09:04,  1.05s/it]Loading train:   2%|▏         | 12/532 [00:13<09:37,  1.11s/it]Loading train:   2%|▏         | 13/532 [00:14<10:00,  1.16s/it]Loading train:   3%|▎         | 14/532 [00:15<09:28,  1.10s/it]Loading train:   3%|▎         | 15/532 [00:16<09:24,  1.09s/it]Loading train:   3%|▎         | 16/532 [00:18<09:43,  1.13s/it]Loading train:   3%|▎         | 17/532 [00:19<09:27,  1.10s/it]Loading train:   3%|▎         | 18/532 [00:20<09:50,  1.15s/it]Loading train:   4%|▎         | 19/532 [00:21<09:16,  1.09s/it]Loading train:   4%|▍         | 20/532 [00:22<08:57,  1.05s/it]Loading train:   4%|▍         | 21/532 [00:23<09:08,  1.07s/it]Loading train:   4%|▍         | 22/532 [00:24<08:45,  1.03s/it]Loading train:   4%|▍         | 23/532 [00:25<08:41,  1.02s/it]Loading train:   5%|▍         | 24/532 [00:26<08:41,  1.03s/it]Loading train:   5%|▍         | 25/532 [00:27<09:26,  1.12s/it]Loading train:   5%|▍         | 26/532 [00:28<09:14,  1.10s/it]Loading train:   5%|▌         | 27/532 [00:30<09:34,  1.14s/it]Loading train:   5%|▌         | 28/532 [00:31<09:27,  1.13s/it]Loading train:   5%|▌         | 29/532 [00:32<09:28,  1.13s/it]Loading train:   6%|▌         | 30/532 [00:33<09:23,  1.12s/it]Loading train:   6%|▌         | 31/532 [00:34<08:50,  1.06s/it]Loading train:   6%|▌         | 32/532 [00:35<09:14,  1.11s/it]Loading train:   6%|▌         | 33/532 [00:36<08:32,  1.03s/it]Loading train:   6%|▋         | 34/532 [00:37<09:02,  1.09s/it]Loading train:   7%|▋         | 35/532 [00:38<08:51,  1.07s/it]Loading train:   7%|▋         | 36/532 [00:39<09:16,  1.12s/it]Loading train:   7%|▋         | 37/532 [00:40<08:46,  1.06s/it]Loading train:   7%|▋         | 38/532 [00:41<09:04,  1.10s/it]Loading train:   7%|▋         | 39/532 [00:42<08:37,  1.05s/it]Loading train:   8%|▊         | 40/532 [00:43<08:22,  1.02s/it]Loading train:   8%|▊         | 41/532 [00:44<08:32,  1.04s/it]Loading train:   8%|▊         | 42/532 [00:46<08:37,  1.06s/it]Loading train:   8%|▊         | 43/532 [00:46<08:12,  1.01s/it]Loading train:   8%|▊         | 44/532 [00:47<07:34,  1.07it/s]Loading train:   8%|▊         | 45/532 [00:48<07:51,  1.03it/s]Loading train:   9%|▊         | 46/532 [00:49<08:04,  1.00it/s]Loading train:   9%|▉         | 47/532 [00:51<08:46,  1.08s/it]Loading train:   9%|▉         | 48/532 [00:52<09:14,  1.15s/it]Loading train:   9%|▉         | 49/532 [00:53<08:35,  1.07s/it]Loading train:   9%|▉         | 50/532 [00:54<09:39,  1.20s/it]Loading train:  10%|▉         | 51/532 [00:55<08:54,  1.11s/it]Loading train:  10%|▉         | 52/532 [00:56<08:46,  1.10s/it]Loading train:  10%|▉         | 53/532 [00:57<08:25,  1.06s/it]Loading train:  10%|█         | 54/532 [00:58<08:56,  1.12s/it]Loading train:  10%|█         | 55/532 [01:00<08:39,  1.09s/it]Loading train:  11%|█         | 56/532 [01:01<08:38,  1.09s/it]Loading train:  11%|█         | 57/532 [01:01<08:09,  1.03s/it]Loading train:  11%|█         | 58/532 [01:03<08:18,  1.05s/it]Loading train:  11%|█         | 59/532 [01:04<08:51,  1.12s/it]Loading train:  11%|█▏        | 60/532 [01:05<08:26,  1.07s/it]Loading train:  11%|█▏        | 61/532 [01:06<08:03,  1.03s/it]Loading train:  12%|█▏        | 62/532 [01:07<08:37,  1.10s/it]Loading train:  12%|█▏        | 63/532 [01:08<08:44,  1.12s/it]Loading train:  12%|█▏        | 64/532 [01:09<08:33,  1.10s/it]Loading train:  12%|█▏        | 65/532 [01:10<08:18,  1.07s/it]Loading train:  12%|█▏        | 66/532 [01:12<08:57,  1.15s/it]Loading train:  13%|█▎        | 67/532 [01:13<09:15,  1.19s/it]Loading train:  13%|█▎        | 68/532 [01:14<08:39,  1.12s/it]Loading train:  13%|█▎        | 69/532 [01:15<08:42,  1.13s/it]Loading train:  13%|█▎        | 70/532 [01:16<08:03,  1.05s/it]Loading train:  13%|█▎        | 71/532 [01:17<08:11,  1.07s/it]Loading train:  14%|█▎        | 72/532 [01:18<07:44,  1.01s/it]Loading train:  14%|█▎        | 73/532 [01:19<08:16,  1.08s/it]Loading train:  14%|█▍        | 74/532 [01:20<08:49,  1.16s/it]Loading train:  14%|█▍        | 75/532 [01:22<09:52,  1.30s/it]Loading train:  14%|█▍        | 76/532 [01:23<09:32,  1.26s/it]Loading train:  14%|█▍        | 77/532 [01:24<08:39,  1.14s/it]Loading train:  15%|█▍        | 78/532 [01:25<08:15,  1.09s/it]Loading train:  15%|█▍        | 79/532 [01:26<07:51,  1.04s/it]Loading train:  15%|█▌        | 80/532 [01:27<07:57,  1.06s/it]Loading train:  15%|█▌        | 81/532 [01:28<07:36,  1.01s/it]Loading train:  15%|█▌        | 82/532 [01:29<07:48,  1.04s/it]Loading train:  16%|█▌        | 83/532 [01:30<07:22,  1.02it/s]Loading train:  16%|█▌        | 84/532 [01:31<07:13,  1.03it/s]Loading train:  16%|█▌        | 85/532 [01:32<07:03,  1.05it/s]Loading train:  16%|█▌        | 86/532 [01:33<06:58,  1.07it/s]Loading train:  16%|█▋        | 87/532 [01:33<06:41,  1.11it/s]Loading train:  17%|█▋        | 88/532 [01:35<07:11,  1.03it/s]Loading train:  17%|█▋        | 89/532 [01:36<07:15,  1.02it/s]Loading train:  17%|█▋        | 90/532 [01:37<07:21,  1.00it/s]Loading train:  17%|█▋        | 91/532 [01:38<07:12,  1.02it/s]Loading train:  17%|█▋        | 92/532 [01:39<07:19,  1.00it/s]Loading train:  17%|█▋        | 93/532 [01:40<07:03,  1.04it/s]Loading train:  18%|█▊        | 94/532 [01:40<06:57,  1.05it/s]Loading train:  18%|█▊        | 95/532 [01:42<07:45,  1.06s/it]Loading train:  18%|█▊        | 96/532 [01:43<07:47,  1.07s/it]Loading train:  18%|█▊        | 97/532 [01:44<07:56,  1.09s/it]Loading train:  18%|█▊        | 98/532 [01:45<07:54,  1.09s/it]Loading train:  19%|█▊        | 99/532 [01:46<07:56,  1.10s/it]Loading train:  19%|█▉        | 100/532 [01:47<08:10,  1.13s/it]Loading train:  19%|█▉        | 101/532 [01:49<08:00,  1.11s/it]Loading train:  19%|█▉        | 102/532 [01:49<07:27,  1.04s/it]Loading train:  19%|█▉        | 103/532 [01:50<07:00,  1.02it/s]Loading train:  20%|█▉        | 104/532 [01:51<06:41,  1.07it/s]Loading train:  20%|█▉        | 105/532 [01:52<06:20,  1.12it/s]Loading train:  20%|█▉        | 106/532 [01:53<06:15,  1.13it/s]Loading train:  20%|██        | 107/532 [01:53<05:59,  1.18it/s]Loading train:  20%|██        | 108/532 [01:54<05:59,  1.18it/s]Loading train:  20%|██        | 109/532 [01:55<05:48,  1.21it/s]Loading train:  21%|██        | 110/532 [01:56<05:52,  1.20it/s]Loading train:  21%|██        | 111/532 [01:57<05:40,  1.24it/s]Loading train:  21%|██        | 112/532 [01:57<05:38,  1.24it/s]Loading train:  21%|██        | 113/532 [01:58<05:55,  1.18it/s]Loading train:  21%|██▏       | 114/532 [01:59<06:19,  1.10it/s]Loading train:  22%|██▏       | 115/532 [02:00<06:16,  1.11it/s]Loading train:  22%|██▏       | 116/532 [02:01<06:22,  1.09it/s]Loading train:  22%|██▏       | 117/532 [02:02<06:14,  1.11it/s]Loading train:  22%|██▏       | 118/532 [02:03<06:24,  1.08it/s]Loading train:  22%|██▏       | 119/532 [02:04<06:51,  1.00it/s]Loading train:  23%|██▎       | 120/532 [02:05<06:59,  1.02s/it]Loading train:  23%|██▎       | 121/532 [02:06<06:54,  1.01s/it]Loading train:  23%|██▎       | 122/532 [02:07<06:57,  1.02s/it]Loading train:  23%|██▎       | 123/532 [02:09<07:04,  1.04s/it]Loading train:  23%|██▎       | 124/532 [02:09<06:53,  1.01s/it]Loading train:  23%|██▎       | 125/532 [02:11<07:09,  1.05s/it]Loading train:  24%|██▎       | 126/532 [02:11<06:42,  1.01it/s]Loading train:  24%|██▍       | 127/532 [02:12<06:42,  1.01it/s]Loading train:  24%|██▍       | 128/532 [02:14<06:52,  1.02s/it]Loading train:  24%|██▍       | 129/532 [02:15<06:52,  1.02s/it]Loading train:  24%|██▍       | 130/532 [02:16<06:41,  1.00it/s]Loading train:  25%|██▍       | 131/532 [02:17<07:07,  1.07s/it]Loading train:  25%|██▍       | 132/532 [02:18<07:02,  1.06s/it]Loading train:  25%|██▌       | 133/532 [02:19<07:30,  1.13s/it]Loading train:  25%|██▌       | 134/532 [02:20<07:45,  1.17s/it]Loading train:  25%|██▌       | 135/532 [02:22<07:49,  1.18s/it]Loading train:  26%|██▌       | 136/532 [02:23<07:36,  1.15s/it]Loading train:  26%|██▌       | 137/532 [02:24<07:49,  1.19s/it]Loading train:  26%|██▌       | 138/532 [02:25<07:44,  1.18s/it]Loading train:  26%|██▌       | 139/532 [02:26<07:57,  1.21s/it]Loading train:  26%|██▋       | 140/532 [02:28<08:17,  1.27s/it]Loading train:  27%|██▋       | 141/532 [02:29<07:56,  1.22s/it]Loading train:  27%|██▋       | 142/532 [02:30<07:51,  1.21s/it]Loading train:  27%|██▋       | 143/532 [02:31<07:35,  1.17s/it]Loading train:  27%|██▋       | 144/532 [02:32<06:51,  1.06s/it]Loading train:  27%|██▋       | 145/532 [02:33<06:29,  1.01s/it]Loading train:  27%|██▋       | 146/532 [02:34<06:16,  1.03it/s]Loading train:  28%|██▊       | 147/532 [02:35<05:55,  1.08it/s]Loading train:  28%|██▊       | 148/532 [02:35<05:46,  1.11it/s]Loading train:  28%|██▊       | 149/532 [02:36<05:47,  1.10it/s]Loading train:  28%|██▊       | 150/532 [02:37<05:42,  1.12it/s]Loading train:  28%|██▊       | 151/532 [02:38<05:40,  1.12it/s]Loading train:  29%|██▊       | 152/532 [02:39<05:35,  1.13it/s]Loading train:  29%|██▉       | 153/532 [02:40<05:34,  1.13it/s]Loading train:  29%|██▉       | 154/532 [02:41<05:29,  1.15it/s]Loading train:  29%|██▉       | 155/532 [02:42<06:21,  1.01s/it]Loading train:  29%|██▉       | 156/532 [02:43<06:45,  1.08s/it]Loading train:  30%|██▉       | 157/532 [02:45<07:12,  1.15s/it]Loading train:  30%|██▉       | 158/532 [02:46<07:31,  1.21s/it]Loading train:  30%|██▉       | 159/532 [02:47<07:38,  1.23s/it]Loading train:  30%|███       | 160/532 [02:48<07:38,  1.23s/it]Loading train:  30%|███       | 161/532 [02:50<07:38,  1.24s/it]Loading train:  30%|███       | 162/532 [02:51<07:03,  1.14s/it]Loading train:  31%|███       | 163/532 [02:52<06:51,  1.12s/it]Loading train:  31%|███       | 164/532 [02:53<06:27,  1.05s/it]Loading train:  31%|███       | 165/532 [02:54<06:44,  1.10s/it]Loading train:  31%|███       | 166/532 [02:55<06:47,  1.11s/it]Loading train:  31%|███▏      | 167/532 [02:56<06:39,  1.10s/it]Loading train:  32%|███▏      | 168/532 [02:57<06:39,  1.10s/it]Loading train:  32%|███▏      | 169/532 [02:58<06:29,  1.07s/it]Loading train:  32%|███▏      | 170/532 [02:59<06:24,  1.06s/it]Loading train:  32%|███▏      | 171/532 [03:00<06:18,  1.05s/it]Loading train:  32%|███▏      | 172/532 [03:01<06:16,  1.05s/it]Loading train:  33%|███▎      | 173/532 [03:02<06:00,  1.00s/it]Loading train:  33%|███▎      | 174/532 [03:03<05:43,  1.04it/s]Loading train:  33%|███▎      | 175/532 [03:04<05:45,  1.03it/s]Loading train:  33%|███▎      | 176/532 [03:05<05:43,  1.04it/s]Loading train:  33%|███▎      | 177/532 [03:06<05:30,  1.07it/s]Loading train:  33%|███▎      | 178/532 [03:07<05:38,  1.05it/s]Loading train:  34%|███▎      | 179/532 [03:08<05:42,  1.03it/s]Loading train:  34%|███▍      | 180/532 [03:09<05:50,  1.01it/s]Loading train:  34%|███▍      | 181/532 [03:10<05:48,  1.01it/s]Loading train:  34%|███▍      | 182/532 [03:11<05:42,  1.02it/s]Loading train:  34%|███▍      | 183/532 [03:12<05:32,  1.05it/s]Loading train:  35%|███▍      | 184/532 [03:13<05:28,  1.06it/s]Loading train:  35%|███▍      | 185/532 [03:14<05:35,  1.03it/s]Loading train:  35%|███▍      | 186/532 [03:15<05:40,  1.02it/s]Loading train:  35%|███▌      | 187/532 [03:15<05:30,  1.04it/s]Loading train:  35%|███▌      | 188/532 [03:16<05:20,  1.07it/s]Loading train:  36%|███▌      | 189/532 [03:17<05:25,  1.05it/s]Loading train:  36%|███▌      | 190/532 [03:18<05:22,  1.06it/s]Loading train:  36%|███▌      | 191/532 [03:20<06:05,  1.07s/it]Loading train:  36%|███▌      | 192/532 [03:21<06:26,  1.14s/it]Loading train:  36%|███▋      | 193/532 [03:22<06:29,  1.15s/it]Loading train:  36%|███▋      | 194/532 [03:23<06:37,  1.18s/it]Loading train:  37%|███▋      | 195/532 [03:25<06:40,  1.19s/it]Loading train:  37%|███▋      | 196/532 [03:26<06:53,  1.23s/it]Loading train:  37%|███▋      | 197/532 [03:27<06:38,  1.19s/it]Loading train:  37%|███▋      | 198/532 [03:28<06:16,  1.13s/it]Loading train:  37%|███▋      | 199/532 [03:29<06:07,  1.10s/it]Loading train:  38%|███▊      | 200/532 [03:30<05:57,  1.08s/it]Loading train:  38%|███▊      | 201/532 [03:31<05:53,  1.07s/it]Loading train:  38%|███▊      | 202/532 [03:32<05:48,  1.06s/it]Loading train:  38%|███▊      | 203/532 [03:33<05:54,  1.08s/it]Loading train:  38%|███▊      | 204/532 [03:34<05:34,  1.02s/it]Loading train:  39%|███▊      | 205/532 [03:35<05:21,  1.02it/s]Loading train:  39%|███▊      | 206/532 [03:36<05:16,  1.03it/s]Loading train:  39%|███▉      | 207/532 [03:37<05:04,  1.07it/s]Loading train:  39%|███▉      | 208/532 [03:38<05:13,  1.03it/s]Loading train:  39%|███▉      | 209/532 [03:39<05:01,  1.07it/s]Loading train:  39%|███▉      | 210/532 [03:40<05:39,  1.05s/it]Loading train:  40%|███▉      | 211/532 [03:41<05:18,  1.01it/s]Loading train:  40%|███▉      | 212/532 [03:42<05:08,  1.04it/s]Loading train:  40%|████      | 213/532 [03:43<04:54,  1.08it/s]Loading train:  40%|████      | 214/532 [03:44<04:58,  1.07it/s]Loading train:  40%|████      | 215/532 [03:45<05:32,  1.05s/it]Loading train:  41%|████      | 216/532 [03:46<05:38,  1.07s/it]Loading train:  41%|████      | 217/532 [03:47<06:02,  1.15s/it]Loading train:  41%|████      | 218/532 [03:49<06:06,  1.17s/it]Loading train:  41%|████      | 219/532 [03:50<06:00,  1.15s/it]Loading train:  41%|████▏     | 220/532 [03:51<06:08,  1.18s/it]Loading train:  42%|████▏     | 221/532 [03:52<05:34,  1.08s/it]Loading train:  42%|████▏     | 222/532 [03:53<05:20,  1.03s/it]Loading train:  42%|████▏     | 223/532 [03:53<04:58,  1.03it/s]Loading train:  42%|████▏     | 224/532 [03:54<05:00,  1.02it/s]Loading train:  42%|████▏     | 225/532 [03:55<04:40,  1.10it/s]Loading train:  42%|████▏     | 226/532 [03:56<04:27,  1.14it/s]Loading train:  43%|████▎     | 227/532 [03:57<04:21,  1.16it/s]Loading train:  43%|████▎     | 228/532 [03:58<04:09,  1.22it/s]Loading train:  43%|████▎     | 229/532 [03:58<04:08,  1.22it/s]Loading train:  43%|████▎     | 230/532 [03:59<03:57,  1.27it/s]Loading train:  43%|████▎     | 231/532 [04:00<04:07,  1.22it/s]Loading train:  44%|████▎     | 232/532 [04:01<03:54,  1.28it/s]Loading train:  44%|████▍     | 233/532 [04:02<04:03,  1.23it/s]Loading train:  44%|████▍     | 234/532 [04:02<04:06,  1.21it/s]Loading train:  44%|████▍     | 235/532 [04:03<04:05,  1.21it/s]Loading train:  44%|████▍     | 236/532 [04:04<04:09,  1.19it/s]Loading train:  45%|████▍     | 237/532 [04:05<04:14,  1.16it/s]Loading train:  45%|████▍     | 238/532 [04:06<04:14,  1.15it/s]Loading train:  45%|████▍     | 239/532 [04:07<04:22,  1.12it/s]Loading train:  45%|████▌     | 240/532 [04:08<04:24,  1.10it/s]Loading train:  45%|████▌     | 241/532 [04:09<04:22,  1.11it/s]Loading train:  45%|████▌     | 242/532 [04:10<04:27,  1.08it/s]Loading train:  46%|████▌     | 243/532 [04:11<04:37,  1.04it/s]Loading train:  46%|████▌     | 244/532 [04:12<04:32,  1.06it/s]Loading train:  46%|████▌     | 245/532 [04:13<04:34,  1.05it/s]Loading train:  46%|████▌     | 246/532 [04:13<04:17,  1.11it/s]Loading train:  46%|████▋     | 247/532 [04:14<04:07,  1.15it/s]Loading train:  47%|████▋     | 248/532 [04:15<04:00,  1.18it/s]Loading train:  47%|████▋     | 249/532 [04:16<03:49,  1.23it/s]Loading train:  47%|████▋     | 250/532 [04:16<03:42,  1.27it/s]Loading train:  47%|████▋     | 251/532 [04:17<04:00,  1.17it/s]Loading train:  47%|████▋     | 252/532 [04:18<04:00,  1.16it/s]Loading train:  48%|████▊     | 253/532 [04:19<04:14,  1.10it/s]Loading train:  48%|████▊     | 254/532 [04:20<04:10,  1.11it/s]Loading train:  48%|████▊     | 255/532 [04:21<04:10,  1.11it/s]Loading train:  48%|████▊     | 256/532 [04:22<04:01,  1.14it/s]Loading train:  48%|████▊     | 257/532 [04:23<04:31,  1.01it/s]Loading train:  48%|████▊     | 258/532 [04:24<04:35,  1.00s/it]Loading train:  49%|████▊     | 259/532 [04:25<04:39,  1.02s/it]Loading train:  49%|████▉     | 260/532 [04:26<04:39,  1.03s/it]Loading train:  49%|████▉     | 261/532 [04:27<04:34,  1.01s/it]Loading train:  49%|████▉     | 262/532 [04:29<04:44,  1.05s/it]Loading train:  49%|████▉     | 263/532 [04:29<04:23,  1.02it/s]Loading train:  50%|████▉     | 264/532 [04:30<04:28,  1.00s/it]Loading train:  50%|████▉     | 265/532 [04:31<04:21,  1.02it/s]Loading train:  50%|█████     | 266/532 [04:32<04:03,  1.09it/s]Loading train:  50%|█████     | 267/532 [04:33<03:47,  1.17it/s]Loading train:  50%|█████     | 268/532 [04:34<03:38,  1.21it/s]Loading train:  51%|█████     | 269/532 [04:35<04:00,  1.09it/s]Loading train:  51%|█████     | 270/532 [04:36<04:02,  1.08it/s]Loading train:  51%|█████     | 271/532 [04:37<04:01,  1.08it/s]Loading train:  51%|█████     | 272/532 [04:37<04:01,  1.08it/s]Loading train:  51%|█████▏    | 273/532 [04:38<03:59,  1.08it/s]Loading train:  52%|█████▏    | 274/532 [04:39<04:05,  1.05it/s]Loading train:  52%|█████▏    | 275/532 [04:41<04:29,  1.05s/it]Loading train:  52%|█████▏    | 276/532 [04:42<04:38,  1.09s/it]Loading train:  52%|█████▏    | 277/532 [04:43<04:38,  1.09s/it]Loading train:  52%|█████▏    | 278/532 [04:44<04:48,  1.13s/it]Loading train:  52%|█████▏    | 279/532 [04:45<04:46,  1.13s/it]Loading train:  53%|█████▎    | 280/532 [04:47<04:57,  1.18s/it]Loading train:  53%|█████▎    | 281/532 [04:48<04:55,  1.18s/it]Loading train:  53%|█████▎    | 282/532 [04:49<04:53,  1.17s/it]Loading train:  53%|█████▎    | 283/532 [04:50<04:47,  1.16s/it]Loading train:  53%|█████▎    | 284/532 [04:51<04:37,  1.12s/it]Loading train:  54%|█████▎    | 285/532 [04:52<04:36,  1.12s/it]Loading train:  54%|█████▍    | 286/532 [04:53<04:37,  1.13s/it]Loading train:  54%|█████▍    | 287/532 [04:54<04:21,  1.07s/it]Loading train:  54%|█████▍    | 288/532 [04:55<04:05,  1.00s/it]Loading train:  54%|█████▍    | 289/532 [04:56<03:51,  1.05it/s]Loading train:  55%|█████▍    | 290/532 [04:57<03:38,  1.11it/s]Loading train:  55%|█████▍    | 291/532 [04:58<03:30,  1.14it/s]Loading train:  55%|█████▍    | 292/532 [04:58<03:31,  1.13it/s]Loading train:  55%|█████▌    | 293/532 [05:00<03:47,  1.05it/s]Loading train:  55%|█████▌    | 294/532 [05:01<03:49,  1.04it/s]Loading train:  55%|█████▌    | 295/532 [05:02<03:59,  1.01s/it]Loading train:  56%|█████▌    | 296/532 [05:03<03:56,  1.00s/it]Loading train:  56%|█████▌    | 297/532 [05:04<04:03,  1.04s/it]Loading train:  56%|█████▌    | 298/532 [05:05<03:58,  1.02s/it]Loading train:  56%|█████▌    | 299/532 [05:06<03:45,  1.03it/s]Loading train:  56%|█████▋    | 300/532 [05:06<03:31,  1.10it/s]Loading train:  57%|█████▋    | 301/532 [05:07<03:27,  1.11it/s]Loading train:  57%|█████▋    | 302/532 [05:08<03:24,  1.12it/s]Loading train:  57%|█████▋    | 303/532 [05:09<03:19,  1.15it/s]Loading train:  57%|█████▋    | 304/532 [05:10<03:17,  1.15it/s]Loading train:  57%|█████▋    | 305/532 [05:11<03:44,  1.01it/s]Loading train:  58%|█████▊    | 306/532 [05:12<03:52,  1.03s/it]Loading train:  58%|█████▊    | 307/532 [05:13<03:58,  1.06s/it]Loading train:  58%|█████▊    | 308/532 [05:15<04:11,  1.12s/it]Loading train:  58%|█████▊    | 309/532 [05:16<04:16,  1.15s/it]Loading train:  58%|█████▊    | 310/532 [05:17<04:12,  1.14s/it]Loading train:  58%|█████▊    | 311/532 [05:19<04:52,  1.32s/it]Loading train:  59%|█████▊    | 312/532 [05:20<05:12,  1.42s/it]Loading train:  59%|█████▉    | 313/532 [05:22<05:25,  1.49s/it]Loading train:  59%|█████▉    | 314/532 [05:24<05:38,  1.55s/it]Loading train:  59%|█████▉    | 315/532 [05:25<05:41,  1.57s/it]Loading train:  59%|█████▉    | 316/532 [05:27<05:36,  1.56s/it]Loading train:  60%|█████▉    | 317/532 [05:28<05:05,  1.42s/it]Loading train:  60%|█████▉    | 318/532 [05:29<04:23,  1.23s/it]Loading train:  60%|█████▉    | 319/532 [05:30<03:59,  1.12s/it]Loading train:  60%|██████    | 320/532 [05:31<03:51,  1.09s/it]Loading train:  60%|██████    | 321/532 [05:31<03:30,  1.00it/s]Loading train:  61%|██████    | 322/532 [05:32<03:23,  1.03it/s]Loading train:  61%|██████    | 323/532 [05:34<03:38,  1.05s/it]Loading train:  61%|██████    | 324/532 [05:35<03:55,  1.13s/it]Loading train:  61%|██████    | 325/532 [05:36<03:57,  1.15s/it]Loading train:  61%|██████▏   | 326/532 [05:37<04:10,  1.22s/it]Loading train:  61%|██████▏   | 327/532 [05:39<04:09,  1.22s/it]Loading train:  62%|██████▏   | 328/532 [05:40<04:15,  1.25s/it]Loading train:  62%|██████▏   | 329/532 [05:41<04:05,  1.21s/it]Loading train:  62%|██████▏   | 330/532 [05:42<03:50,  1.14s/it]Loading train:  62%|██████▏   | 331/532 [05:43<03:35,  1.07s/it]Loading train:  62%|██████▏   | 332/532 [05:44<03:41,  1.11s/it]Loading train:  63%|██████▎   | 333/532 [05:45<03:24,  1.03s/it]Loading train:  63%|██████▎   | 334/532 [05:46<03:19,  1.01s/it]Loading train:  63%|██████▎   | 335/532 [05:47<03:24,  1.04s/it]Loading train:  63%|██████▎   | 336/532 [05:48<03:30,  1.08s/it]Loading train:  63%|██████▎   | 337/532 [05:49<03:26,  1.06s/it]Loading train:  64%|██████▎   | 338/532 [05:50<03:26,  1.07s/it]Loading train:  64%|██████▎   | 339/532 [05:51<03:22,  1.05s/it]Loading train:  64%|██████▍   | 340/532 [05:52<03:26,  1.08s/it]Loading train:  64%|██████▍   | 341/532 [05:53<03:16,  1.03s/it]Loading train:  64%|██████▍   | 342/532 [05:54<03:03,  1.04it/s]Loading train:  64%|██████▍   | 343/532 [05:55<02:59,  1.05it/s]Loading train:  65%|██████▍   | 344/532 [05:56<02:51,  1.09it/s]Loading train:  65%|██████▍   | 345/532 [05:57<02:50,  1.09it/s]Loading train:  65%|██████▌   | 346/532 [05:58<02:53,  1.07it/s]Loading train:  65%|██████▌   | 347/532 [05:59<02:45,  1.11it/s]Loading train:  65%|██████▌   | 348/532 [06:00<02:51,  1.07it/s]Loading train:  66%|██████▌   | 349/532 [06:00<02:43,  1.12it/s]Loading train:  66%|██████▌   | 350/532 [06:01<02:41,  1.13it/s]Loading train:  66%|██████▌   | 351/532 [06:02<02:48,  1.08it/s]Loading train:  66%|██████▌   | 352/532 [06:03<02:45,  1.08it/s]Loading train:  66%|██████▋   | 353/532 [06:04<02:56,  1.02it/s]Loading train:  67%|██████▋   | 354/532 [06:05<02:49,  1.05it/s]Loading train:  67%|██████▋   | 355/532 [06:06<02:45,  1.07it/s]Loading train:  67%|██████▋   | 356/532 [06:07<02:40,  1.10it/s]Loading train:  67%|██████▋   | 357/532 [06:08<02:37,  1.11it/s]Loading train:  67%|██████▋   | 358/532 [06:09<02:43,  1.06it/s]Loading train:  67%|██████▋   | 359/532 [06:10<03:05,  1.07s/it]Loading train:  68%|██████▊   | 360/532 [06:12<03:23,  1.18s/it]Loading train:  68%|██████▊   | 361/532 [06:13<03:36,  1.27s/it]Loading train:  68%|██████▊   | 362/532 [06:14<03:22,  1.19s/it]Loading train:  68%|██████▊   | 363/532 [06:16<03:37,  1.29s/it]Loading train:  68%|██████▊   | 364/532 [06:17<03:52,  1.38s/it]Loading train:  69%|██████▊   | 365/532 [06:19<03:50,  1.38s/it]Loading train:  69%|██████▉   | 366/532 [06:20<03:24,  1.23s/it]Loading train:  69%|██████▉   | 367/532 [06:21<03:30,  1.28s/it]Loading train:  69%|██████▉   | 368/532 [06:22<03:18,  1.21s/it]Loading train:  69%|██████▉   | 369/532 [06:23<03:18,  1.22s/it]Loading train:  70%|██████▉   | 370/532 [06:24<03:07,  1.15s/it]Loading train:  70%|██████▉   | 371/532 [06:26<03:37,  1.35s/it]Loading train:  70%|██████▉   | 372/532 [06:28<04:04,  1.53s/it]Loading train:  70%|███████   | 373/532 [06:30<04:21,  1.64s/it]Loading train:  70%|███████   | 374/532 [06:32<04:29,  1.70s/it]Loading train:  70%|███████   | 375/532 [06:33<04:15,  1.63s/it]Loading train:  71%|███████   | 376/532 [06:35<04:07,  1.59s/it]Loading train:  71%|███████   | 377/532 [06:36<03:58,  1.54s/it]Loading train:  71%|███████   | 378/532 [06:37<03:40,  1.43s/it]Loading train:  71%|███████   | 379/532 [06:39<03:34,  1.40s/it]Loading train:  71%|███████▏  | 380/532 [06:40<03:42,  1.46s/it]Loading train:  72%|███████▏  | 381/532 [06:42<03:29,  1.39s/it]Loading train:  72%|███████▏  | 382/532 [06:43<03:32,  1.41s/it]Loading train:  72%|███████▏  | 383/532 [06:45<03:46,  1.52s/it]Loading train:  72%|███████▏  | 384/532 [06:46<03:32,  1.43s/it]Loading train:  72%|███████▏  | 385/532 [06:47<03:25,  1.40s/it]Loading train:  73%|███████▎  | 386/532 [06:49<03:28,  1.43s/it]Loading train:  73%|███████▎  | 387/532 [06:50<03:16,  1.36s/it]Loading train:  73%|███████▎  | 388/532 [06:52<03:31,  1.47s/it]Loading train:  73%|███████▎  | 389/532 [06:53<03:39,  1.54s/it]Loading train:  73%|███████▎  | 390/532 [06:55<03:37,  1.53s/it]Loading train:  73%|███████▎  | 391/532 [06:57<03:49,  1.63s/it]Loading train:  74%|███████▎  | 392/532 [06:58<03:35,  1.54s/it]Loading train:  74%|███████▍  | 393/532 [06:59<03:25,  1.48s/it]Loading train:  74%|███████▍  | 394/532 [07:01<03:18,  1.44s/it]Loading train:  74%|███████▍  | 395/532 [07:02<03:12,  1.40s/it]Loading train:  74%|███████▍  | 396/532 [07:04<03:14,  1.43s/it]Loading train:  75%|███████▍  | 397/532 [07:05<03:03,  1.36s/it]Loading train:  75%|███████▍  | 398/532 [07:06<02:52,  1.29s/it]Loading train:  75%|███████▌  | 399/532 [07:08<03:03,  1.38s/it]Loading train:  75%|███████▌  | 400/532 [07:09<03:06,  1.41s/it]Loading train:  75%|███████▌  | 401/532 [07:11<03:22,  1.55s/it]Loading train:  76%|███████▌  | 402/532 [07:12<03:22,  1.56s/it]Loading train:  76%|███████▌  | 403/532 [07:14<03:19,  1.54s/it]Loading train:  76%|███████▌  | 404/532 [07:15<03:11,  1.50s/it]Loading train:  76%|███████▌  | 405/532 [07:17<03:14,  1.53s/it]Loading train:  76%|███████▋  | 406/532 [07:18<03:09,  1.50s/it]Loading train:  77%|███████▋  | 407/532 [07:20<03:06,  1.49s/it]Loading train:  77%|███████▋  | 408/532 [07:21<02:58,  1.44s/it]Loading train:  77%|███████▋  | 409/532 [07:23<02:52,  1.41s/it]Loading train:  77%|███████▋  | 410/532 [07:24<02:48,  1.38s/it]Loading train:  77%|███████▋  | 411/532 [07:25<02:50,  1.41s/it]Loading train:  77%|███████▋  | 412/532 [07:27<02:52,  1.44s/it]Loading train:  78%|███████▊  | 413/532 [07:29<03:05,  1.56s/it]Loading train:  78%|███████▊  | 414/532 [07:30<02:55,  1.49s/it]Loading train:  78%|███████▊  | 415/532 [07:31<02:43,  1.40s/it]Loading train:  78%|███████▊  | 416/532 [07:32<02:31,  1.31s/it]Loading train:  78%|███████▊  | 417/532 [07:34<02:34,  1.34s/it]Loading train:  79%|███████▊  | 418/532 [07:35<02:27,  1.29s/it]Loading train:  79%|███████▉  | 419/532 [07:37<02:40,  1.42s/it]Loading train:  79%|███████▉  | 420/532 [07:38<02:31,  1.35s/it]Loading train:  79%|███████▉  | 421/532 [07:39<02:30,  1.35s/it]Loading train:  79%|███████▉  | 422/532 [07:40<02:25,  1.32s/it]Loading train:  80%|███████▉  | 423/532 [07:42<02:20,  1.29s/it]Loading train:  80%|███████▉  | 424/532 [07:43<02:12,  1.22s/it]Loading train:  80%|███████▉  | 425/532 [07:44<02:21,  1.32s/it]Loading train:  80%|████████  | 426/532 [07:46<02:22,  1.34s/it]Loading train:  80%|████████  | 427/532 [07:47<02:35,  1.48s/it]Loading train:  80%|████████  | 428/532 [07:49<02:38,  1.52s/it]Loading train:  81%|████████  | 429/532 [07:51<02:37,  1.53s/it]Loading train:  81%|████████  | 430/532 [07:52<02:38,  1.55s/it]Loading train:  81%|████████  | 431/532 [07:54<02:54,  1.73s/it]Loading train:  81%|████████  | 432/532 [07:56<02:49,  1.69s/it]Loading train:  81%|████████▏ | 433/532 [07:58<02:47,  1.70s/it]Loading train:  82%|████████▏ | 434/532 [07:59<02:45,  1.69s/it]Loading train:  82%|████████▏ | 435/532 [08:01<02:42,  1.68s/it]Loading train:  82%|████████▏ | 436/532 [08:02<02:35,  1.62s/it]Loading train:  82%|████████▏ | 437/532 [08:04<02:19,  1.47s/it]Loading train:  82%|████████▏ | 438/532 [08:05<02:15,  1.44s/it]Loading train:  83%|████████▎ | 439/532 [08:06<02:14,  1.45s/it]Loading train:  83%|████████▎ | 440/532 [08:08<02:04,  1.35s/it]Loading train:  83%|████████▎ | 441/532 [08:09<02:01,  1.33s/it]Loading train:  83%|████████▎ | 442/532 [08:10<01:52,  1.25s/it]Loading train:  83%|████████▎ | 443/532 [08:11<01:53,  1.28s/it]Loading train:  83%|████████▎ | 444/532 [08:12<01:51,  1.27s/it]Loading train:  84%|████████▎ | 445/532 [08:14<01:49,  1.26s/it]Loading train:  84%|████████▍ | 446/532 [08:15<01:54,  1.33s/it]Loading train:  84%|████████▍ | 447/532 [08:17<01:52,  1.33s/it]Loading train:  84%|████████▍ | 448/532 [08:18<01:57,  1.40s/it]Loading train:  84%|████████▍ | 449/532 [08:19<01:55,  1.39s/it]Loading train:  85%|████████▍ | 450/532 [08:21<01:51,  1.36s/it]Loading train:  85%|████████▍ | 451/532 [08:22<01:46,  1.32s/it]Loading train:  85%|████████▍ | 452/532 [08:23<01:39,  1.24s/it]Loading train:  85%|████████▌ | 453/532 [08:24<01:39,  1.25s/it]Loading train:  85%|████████▌ | 454/532 [08:26<01:38,  1.26s/it]Loading train:  86%|████████▌ | 455/532 [08:27<01:45,  1.37s/it]Loading train:  86%|████████▌ | 456/532 [08:29<01:51,  1.47s/it]Loading train:  86%|████████▌ | 457/532 [08:30<01:50,  1.47s/it]Loading train:  86%|████████▌ | 458/532 [08:32<01:42,  1.38s/it]Loading train:  86%|████████▋ | 459/532 [08:33<01:36,  1.32s/it]Loading train:  86%|████████▋ | 460/532 [08:34<01:34,  1.31s/it]Loading train:  87%|████████▋ | 461/532 [08:36<01:49,  1.54s/it]Loading train:  87%|████████▋ | 462/532 [08:38<02:02,  1.75s/it]Loading train:  87%|████████▋ | 463/532 [08:41<02:11,  1.90s/it]Loading train:  87%|████████▋ | 464/532 [08:43<02:12,  1.95s/it]Loading train:  87%|████████▋ | 465/532 [08:44<02:05,  1.88s/it]Loading train:  88%|████████▊ | 466/532 [08:46<02:01,  1.83s/it]Loading train:  88%|████████▊ | 467/532 [08:48<01:55,  1.78s/it]Loading train:  88%|████████▊ | 468/532 [08:49<01:43,  1.61s/it]Loading train:  88%|████████▊ | 469/532 [08:51<01:40,  1.60s/it]Loading train:  88%|████████▊ | 470/532 [08:52<01:28,  1.42s/it]Loading train:  89%|████████▊ | 471/532 [08:53<01:25,  1.40s/it]Loading train:  89%|████████▊ | 472/532 [08:54<01:19,  1.33s/it]Loading train:  89%|████████▉ | 473/532 [08:56<01:24,  1.44s/it]Loading train:  89%|████████▉ | 474/532 [08:57<01:20,  1.38s/it]Loading train:  89%|████████▉ | 475/532 [08:58<01:19,  1.40s/it]Loading train:  89%|████████▉ | 476/532 [09:00<01:13,  1.32s/it]Loading train:  90%|████████▉ | 477/532 [09:01<01:09,  1.27s/it]Loading train:  90%|████████▉ | 478/532 [09:02<01:10,  1.30s/it]Loading train:  90%|█████████ | 479/532 [09:03<01:08,  1.29s/it]Loading train:  90%|█████████ | 480/532 [09:04<01:03,  1.21s/it]Loading train:  90%|█████████ | 481/532 [09:06<01:03,  1.24s/it]Loading train:  91%|█████████ | 482/532 [09:07<01:00,  1.21s/it]Loading train:  91%|█████████ | 483/532 [09:08<00:58,  1.19s/it]Loading train:  91%|█████████ | 484/532 [09:09<00:59,  1.23s/it]Loading train:  91%|█████████ | 485/532 [09:11<01:07,  1.44s/it]Loading train:  91%|█████████▏| 486/532 [09:13<01:07,  1.48s/it]Loading train:  92%|█████████▏| 487/532 [09:14<01:06,  1.48s/it]Loading train:  92%|█████████▏| 488/532 [09:16<01:07,  1.54s/it]Loading train:  92%|█████████▏| 489/532 [09:18<01:10,  1.63s/it]Loading train:  92%|█████████▏| 490/532 [09:19<01:08,  1.63s/it]Loading train:  92%|█████████▏| 491/532 [09:21<01:03,  1.54s/it]Loading train:  92%|█████████▏| 492/532 [09:22<00:58,  1.47s/it]Loading train:  93%|█████████▎| 493/532 [09:23<00:53,  1.37s/it]Loading train:  93%|█████████▎| 494/532 [09:25<00:52,  1.38s/it]Loading train:  93%|█████████▎| 495/532 [09:26<00:51,  1.39s/it]Loading train:  93%|█████████▎| 496/532 [09:28<00:51,  1.43s/it]Loading train:  93%|█████████▎| 497/532 [09:29<00:49,  1.41s/it]Loading train:  94%|█████████▎| 498/532 [09:30<00:45,  1.34s/it]Loading train:  94%|█████████▍| 499/532 [09:32<00:44,  1.36s/it]Loading train:  94%|█████████▍| 500/532 [09:33<00:45,  1.41s/it]Loading train:  94%|█████████▍| 501/532 [09:35<00:47,  1.53s/it]Loading train:  94%|█████████▍| 502/532 [09:37<00:46,  1.57s/it]Loading train:  95%|█████████▍| 503/532 [09:38<00:43,  1.51s/it]Loading train:  95%|█████████▍| 504/532 [09:39<00:41,  1.49s/it]Loading train:  95%|█████████▍| 505/532 [09:41<00:39,  1.48s/it]Loading train:  95%|█████████▌| 506/532 [09:42<00:37,  1.45s/it]Loading train:  95%|█████████▌| 507/532 [09:43<00:33,  1.35s/it]Loading train:  95%|█████████▌| 508/532 [09:45<00:31,  1.32s/it]Loading train:  96%|█████████▌| 509/532 [09:46<00:32,  1.43s/it]Loading train:  96%|█████████▌| 510/532 [09:48<00:32,  1.49s/it]Loading train:  96%|█████████▌| 511/532 [09:50<00:32,  1.57s/it]Loading train:  96%|█████████▌| 512/532 [09:51<00:30,  1.51s/it]Loading train:  96%|█████████▋| 513/532 [09:53<00:29,  1.55s/it]Loading train:  97%|█████████▋| 514/532 [09:55<00:30,  1.67s/it]Loading train:  97%|█████████▋| 515/532 [09:57<00:29,  1.74s/it]Loading train:  97%|█████████▋| 516/532 [09:58<00:26,  1.63s/it]Loading train:  97%|█████████▋| 517/532 [09:59<00:22,  1.51s/it]Loading train:  97%|█████████▋| 518/532 [10:00<00:20,  1.43s/it]Loading train:  98%|█████████▊| 519/532 [10:01<00:16,  1.31s/it]Loading train:  98%|█████████▊| 520/532 [10:03<00:15,  1.30s/it]Loading train:  98%|█████████▊| 521/532 [10:04<00:15,  1.37s/it]Loading train:  98%|█████████▊| 522/532 [10:06<00:14,  1.49s/it]Loading train:  98%|█████████▊| 523/532 [10:08<00:13,  1.53s/it]Loading train:  98%|█████████▊| 524/532 [10:09<00:11,  1.49s/it]Loading train:  99%|█████████▊| 525/532 [10:11<00:10,  1.51s/it]Loading train:  99%|█████████▉| 526/532 [10:12<00:09,  1.53s/it]Loading train:  99%|█████████▉| 527/532 [10:13<00:07,  1.48s/it]Loading train:  99%|█████████▉| 528/532 [10:15<00:05,  1.38s/it]Loading train:  99%|█████████▉| 529/532 [10:16<00:04,  1.37s/it]Loading train: 100%|█████████▉| 530/532 [10:17<00:02,  1.32s/it]Loading train: 100%|█████████▉| 531/532 [10:19<00:01,  1.33s/it]Loading train: 100%|██████████| 532/532 [10:20<00:00,  1.31s/it]
concatenating: train:   0%|          | 0/532 [00:00<?, ?it/s]concatenating: train:   1%|          | 3/532 [00:00<00:22, 23.68it/s]concatenating: train:   2%|▏         | 9/532 [00:00<00:18, 27.97it/s]concatenating: train:   4%|▍         | 22/532 [00:00<00:13, 36.54it/s]concatenating: train:   8%|▊         | 40/532 [00:00<00:10, 47.90it/s]concatenating: train:   9%|▉         | 49/532 [00:00<00:10, 46.81it/s]concatenating: train:  11%|█         | 57/532 [00:00<00:12, 39.23it/s]concatenating: train:  12%|█▏        | 64/532 [00:01<00:15, 30.04it/s]concatenating: train:  13%|█▎        | 69/532 [00:01<00:16, 28.32it/s]concatenating: train:  14%|█▍        | 74/532 [00:01<00:15, 30.42it/s]concatenating: train:  15%|█▍        | 79/532 [00:01<00:15, 29.71it/s]concatenating: train:  16%|█▌        | 83/532 [00:01<00:15, 29.49it/s]concatenating: train:  17%|█▋        | 88/532 [00:02<00:13, 32.83it/s]concatenating: train:  18%|█▊        | 94/532 [00:02<00:12, 36.07it/s]concatenating: train:  19%|█▉        | 100/532 [00:02<00:10, 40.97it/s]concatenating: train:  20%|█▉        | 106/532 [00:02<00:09, 43.70it/s]concatenating: train:  21%|██        | 112/532 [00:02<00:08, 47.53it/s]concatenating: train:  23%|██▎       | 124/532 [00:02<00:07, 57.60it/s]concatenating: train:  26%|██▌       | 138/532 [00:02<00:05, 69.66it/s]concatenating: train:  29%|██▉       | 155/532 [00:02<00:04, 83.73it/s]concatenating: train:  31%|███▏      | 167/532 [00:02<00:04, 83.50it/s]concatenating: train:  34%|███▎      | 179/532 [00:03<00:03, 91.05it/s]concatenating: train:  36%|███▌      | 190/532 [00:03<00:03, 91.18it/s]concatenating: train:  38%|███▊      | 201/532 [00:03<00:03, 87.14it/s]concatenating: train:  40%|███▉      | 211/532 [00:03<00:04, 80.17it/s]concatenating: train:  41%|████▏     | 220/532 [00:03<00:04, 71.78it/s]concatenating: train:  43%|████▎     | 228/532 [00:03<00:04, 70.81it/s]concatenating: train:  44%|████▍     | 236/532 [00:03<00:05, 58.60it/s]concatenating: train:  46%|████▌     | 243/532 [00:04<00:04, 60.20it/s]concatenating: train:  47%|████▋     | 250/532 [00:04<00:04, 61.66it/s]concatenating: train:  48%|████▊     | 257/532 [00:04<00:04, 56.51it/s]concatenating: train:  49%|████▉     | 263/532 [00:04<00:04, 56.86it/s]concatenating: train:  51%|█████     | 271/532 [00:04<00:04, 61.12it/s]concatenating: train:  53%|█████▎    | 283/532 [00:04<00:03, 71.61it/s]concatenating: train:  56%|█████▌    | 296/532 [00:04<00:02, 82.13it/s]concatenating: train:  58%|█████▊    | 307/532 [00:04<00:02, 87.30it/s]concatenating: train:  60%|█████▉    | 318/532 [00:04<00:02, 92.01it/s]concatenating: train:  62%|██████▏   | 330/532 [00:05<00:02, 97.97it/s]concatenating: train:  64%|██████▍   | 342/532 [00:05<00:01, 102.61it/s]concatenating: train:  66%|██████▋   | 353/532 [00:05<00:01, 103.53it/s]concatenating: train:  68%|██████▊   | 364/532 [00:05<00:01, 105.34it/s]concatenating: train:  70%|███████   | 375/532 [00:05<00:01, 104.33it/s]concatenating: train:  73%|███████▎  | 386/532 [00:05<00:01, 104.74it/s]concatenating: train:  75%|███████▍  | 398/532 [00:05<00:01, 107.33it/s]concatenating: train:  77%|███████▋  | 409/532 [00:05<00:01, 106.03it/s]concatenating: train:  79%|███████▉  | 422/532 [00:05<00:01, 109.02it/s]concatenating: train:  81%|████████▏ | 433/532 [00:05<00:00, 105.22it/s]concatenating: train:  84%|████████▍ | 448/532 [00:06<00:00, 114.96it/s]concatenating: train:  86%|████████▋ | 460/532 [00:06<00:00, 107.99it/s]concatenating: train:  89%|████████▊ | 472/532 [00:06<00:00, 107.20it/s]concatenating: train:  91%|█████████ | 483/532 [00:06<00:00, 87.32it/s] concatenating: train:  93%|█████████▎| 493/532 [00:06<00:00, 79.50it/s]concatenating: train:  94%|█████████▍| 502/532 [00:06<00:00, 61.53it/s]concatenating: train:  96%|█████████▌| 510/532 [00:07<00:00, 50.89it/s]concatenating: train:  97%|█████████▋| 517/532 [00:07<00:00, 52.52it/s]concatenating: train:  98%|█████████▊| 524/532 [00:07<00:00, 56.22it/s]concatenating: train: 100%|█████████▉| 531/532 [00:07<00:00, 55.23it/s]concatenating: train: 100%|██████████| 532/532 [00:07<00:00, 70.87it/s]
Loading test:   0%|          | 0/15 [00:00<?, ?it/s]Loading test:   7%|▋         | 1/15 [00:01<00:17,  1.25s/it]Loading test:  13%|█▎        | 2/15 [00:02<00:16,  1.29s/it]Loading test:  20%|██        | 3/15 [00:04<00:17,  1.45s/it]Loading test:  27%|██▋       | 4/15 [00:06<00:18,  1.66s/it]Loading test:  33%|███▎      | 5/15 [00:08<00:17,  1.76s/it]Loading test:  40%|████      | 6/15 [00:10<00:15,  1.76s/it]Loading test:  47%|████▋     | 7/15 [00:11<00:12,  1.58s/it]Loading test:  53%|█████▎    | 8/15 [00:13<00:11,  1.65s/it]Loading test:  60%|██████    | 9/15 [00:15<00:10,  1.68s/it]Loading test:  67%|██████▋   | 10/15 [00:16<00:08,  1.60s/it]Loading test:  73%|███████▎  | 11/15 [00:18<00:06,  1.62s/it]Loading test:  80%|████████  | 12/15 [00:19<00:04,  1.65s/it]Loading test:  87%|████████▋ | 13/15 [00:21<00:03,  1.74s/it]Loading test:  93%|█████████▎| 14/15 [00:23<00:01,  1.67s/it]Loading test: 100%|██████████| 15/15 [00:24<00:00,  1.66s/it]
concatenating: validation:   0%|          | 0/15 [00:00<?, ?it/s]concatenating: validation:  27%|██▋       | 4/15 [00:00<00:00, 36.26it/s]concatenating: validation:  53%|█████▎    | 8/15 [00:00<00:00, 35.38it/s]concatenating: validation:  93%|█████████▎| 14/15 [00:00<00:00, 39.39it/s]concatenating: validation: 100%|██████████| 15/15 [00:00<00:00, 41.43it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 56, 84, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 56, 84, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 56, 84, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 56, 84, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 56, 84, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 84, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 56, 84, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 56, 84, 16)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 28, 42, 16)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28, 42, 16)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 42, 30)   4350        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 42, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 42, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 42, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 28, 42, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 28, 42, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 42, 46)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 21, 46)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 14, 21, 46)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 14, 21, 60)   24900       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 14, 21, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 14, 21, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 14, 21, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 14, 21, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 14, 21, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 14, 21, 106)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 14, 21, 106)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 28, 42, 30)   12750       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 28, 42, 76)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 28, 42, 30)   20550       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 28, 42, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________2019-07-06 21:37:21.223602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-06 21:37:21.223719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-06 21:37:21.223753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-06 21:37:21.223767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-06 21:37:21.224361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

activation_7 (Activation)       (None, 28, 42, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 28, 42, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 28, 42, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 28, 42, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 28, 42, 106)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 28, 42, 106)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 56, 84, 15)   6375        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 84, 31)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 56, 84, 15)   4200        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 56, 84, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 84, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 56, 84, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 56, 84, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 84, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 84, 46)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 56, 84, 46)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 56, 84, 13)   611         dropout_5[0][0]                  
==================================================================================================
Total params: 127,886
Trainable params: 127,286
Non-trainable params: 600
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.53383120e-02 2.88786827e-02 1.16652967e-01 1.00133292e-02
 3.03165963e-02 5.79538965e-03 6.85058777e-02 1.28145429e-01
 7.55135052e-02 1.22435092e-02 2.73464902e-01 1.84941443e-01
 1.90056842e-04]
Train on 20749 samples, validate on 584 samples
Epoch 1/300
 - 30s - loss: 46.3449 - acc: 0.7478 - mDice: 0.0150 - val_loss: 5.6633 - val_acc: 0.9134 - val_mDice: 0.0069

Epoch 00001: val_mDice improved from -inf to 0.00686, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 20s - loss: 5.7704 - acc: 0.8962 - mDice: 0.0380 - val_loss: 4.1396 - val_acc: 0.9134 - val_mDice: 0.0371

Epoch 00002: val_mDice improved from 0.00686 to 0.03714, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 18s - loss: 4.3004 - acc: 0.9042 - mDice: 0.0916 - val_loss: 2.7769 - val_acc: 0.9187 - val_mDice: 0.1434

Epoch 00003: val_mDice improved from 0.03714 to 0.14345, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 19s - loss: 3.4496 - acc: 0.9130 - mDice: 0.1676 - val_loss: 2.3616 - val_acc: 0.9194 - val_mDice: 0.2232

Epoch 00004: val_mDice improved from 0.14345 to 0.22317, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 18s - loss: 2.8463 - acc: 0.9216 - mDice: 0.2519 - val_loss: 1.7675 - val_acc: 0.9457 - val_mDice: 0.3760

Epoch 00005: val_mDice improved from 0.22317 to 0.37597, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 19s - loss: 2.4522 - acc: 0.9292 - mDice: 0.3203 - val_loss: 1.5403 - val_acc: 0.9525 - val_mDice: 0.4510

Epoch 00006: val_mDice improved from 0.37597 to 0.45095, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 18s - loss: 2.1560 - acc: 0.9356 - mDice: 0.3786 - val_loss: 1.2386 - val_acc: 0.9619 - val_mDice: 0.5431

Epoch 00007: val_mDice improved from 0.45095 to 0.54313, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 18s - loss: 1.9472 - acc: 0.9407 - mDice: 0.4242 - val_loss: 1.1182 - val_acc: 0.9680 - val_mDice: 0.5883

Epoch 00008: val_mDice improved from 0.54313 to 0.58828, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 9/300
 - 19s - loss: 1.7931 - acc: 0.9445 - mDice: 0.4601 - val_loss: 1.0817 - val_acc: 0.9676 - val_mDice: 0.6167

Epoch 00009: val_mDice improved from 0.58828 to 0.61674, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 18s - loss: 1.6649 - acc: 0.9475 - mDice: 0.4920 - val_loss: 0.9802 - val_acc: 0.9714 - val_mDice: 0.6519

Epoch 00010: val_mDice improved from 0.61674 to 0.65189, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 11/300
 - 18s - loss: 1.5705 - acc: 0.9495 - mDice: 0.5162 - val_loss: 0.9674 - val_acc: 0.9718 - val_mDice: 0.6565

Epoch 00011: val_mDice improved from 0.65189 to 0.65655, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 12/300
 - 18s - loss: 1.4998 - acc: 0.9510 - mDice: 0.5347 - val_loss: 0.9356 - val_acc: 0.9734 - val_mDice: 0.6658

Epoch 00012: val_mDice improved from 0.65655 to 0.66576, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 13/300
 - 19s - loss: 1.4419 - acc: 0.9523 - mDice: 0.5493 - val_loss: 0.9032 - val_acc: 0.9738 - val_mDice: 0.6811

Epoch 00013: val_mDice improved from 0.66576 to 0.68111, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 14/300
 - 18s - loss: 1.3914 - acc: 0.9534 - mDice: 0.5629 - val_loss: 0.8901 - val_acc: 0.9740 - val_mDice: 0.6899

Epoch 00014: val_mDice improved from 0.68111 to 0.68987, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 15/300
 - 18s - loss: 1.3408 - acc: 0.9544 - mDice: 0.5761 - val_loss: 0.8796 - val_acc: 0.9748 - val_mDice: 0.6948

Epoch 00015: val_mDice improved from 0.68987 to 0.69483, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 16/300
 - 18s - loss: 1.2986 - acc: 0.9553 - mDice: 0.5869 - val_loss: 0.8828 - val_acc: 0.9750 - val_mDice: 0.6993

Epoch 00016: val_mDice improved from 0.69483 to 0.69933, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 17/300
 - 18s - loss: 1.2629 - acc: 0.9560 - mDice: 0.5963 - val_loss: 0.8411 - val_acc: 0.9737 - val_mDice: 0.7087

Epoch 00017: val_mDice improved from 0.69933 to 0.70866, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 18/300
 - 19s - loss: 1.2339 - acc: 0.9566 - mDice: 0.6041 - val_loss: 0.8393 - val_acc: 0.9739 - val_mDice: 0.7113

Epoch 00018: val_mDice improved from 0.70866 to 0.71127, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 19/300
 - 18s - loss: 1.1995 - acc: 0.9574 - mDice: 0.6129 - val_loss: 0.8137 - val_acc: 0.9746 - val_mDice: 0.7157

Epoch 00019: val_mDice improved from 0.71127 to 0.71568, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 20/300
 - 18s - loss: 1.1707 - acc: 0.9579 - mDice: 0.6207 - val_loss: 0.8240 - val_acc: 0.9750 - val_mDice: 0.7157

Epoch 00020: val_mDice did not improve from 0.71568
Epoch 21/300
 - 20s - loss: 1.1448 - acc: 0.9584 - mDice: 0.6281 - val_loss: 0.8289 - val_acc: 0.9737 - val_mDice: 0.7161

Epoch 00021: val_mDice improved from 0.71568 to 0.71612, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 22/300
 - 19s - loss: 1.1263 - acc: 0.9587 - mDice: 0.6336 - val_loss: 0.8153 - val_acc: 0.9756 - val_mDice: 0.7186

Epoch 00022: val_mDice improved from 0.71612 to 0.71862, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 23/300
 - 19s - loss: 1.1048 - acc: 0.9591 - mDice: 0.6389 - val_loss: 0.7910 - val_acc: 0.9755 - val_mDice: 0.7275

Epoch 00023: val_mDice improved from 0.71862 to 0.72754, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 24/300
 - 19s - loss: 1.0859 - acc: 0.9595 - mDice: 0.6448 - val_loss: 0.7872 - val_acc: 0.9756 - val_mDice: 0.7307

Epoch 00024: val_mDice improved from 0.72754 to 0.73074, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 25/300
 - 19s - loss: 1.0662 - acc: 0.9598 - mDice: 0.6503 - val_loss: 0.7764 - val_acc: 0.9762 - val_mDice: 0.7291

Epoch 00025: val_mDice did not improve from 0.73074
Epoch 26/300
 - 19s - loss: 1.0517 - acc: 0.9600 - mDice: 0.6542 - val_loss: 0.7834 - val_acc: 0.9764 - val_mDice: 0.7301

Epoch 00026: val_mDice did not improve from 0.73074
Epoch 27/300
 - 19s - loss: 1.0387 - acc: 0.9603 - mDice: 0.6580 - val_loss: 0.7835 - val_acc: 0.9760 - val_mDice: 0.7291

Epoch 00027: val_mDice did not improve from 0.73074
Epoch 28/300
 - 19s - loss: 1.0178 - acc: 0.9607 - mDice: 0.6643 - val_loss: 0.7816 - val_acc: 0.9753 - val_mDice: 0.7318

Epoch 00028: val_mDice improved from 0.73074 to 0.73181, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 29/300
 - 19s - loss: 1.0036 - acc: 0.9610 - mDice: 0.6681 - val_loss: 0.7828 - val_acc: 0.9759 - val_mDice: 0.7377

Epoch 00029: val_mDice improved from 0.73181 to 0.73774, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 30/300
 - 19s - loss: 0.9914 - acc: 0.9611 - mDice: 0.6719 - val_loss: 0.7660 - val_acc: 0.9767 - val_mDice: 0.7390

Epoch 00030: val_mDice improved from 0.73774 to 0.73901, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 31/300
 - 19s - loss: 0.9813 - acc: 0.9615 - mDice: 0.6752 - val_loss: 0.7603 - val_acc: 0.9763 - val_mDice: 0.7391

Epoch 00031: val_mDice improved from 0.73901 to 0.73907, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 32/300
 - 20s - loss: 0.9693 - acc: 0.9618 - mDice: 0.6786 - val_loss: 0.7582 - val_acc: 0.9762 - val_mDice: 0.7407

Epoch 00032: val_mDice improved from 0.73907 to 0.74074, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 33/300
 - 19s - loss: 0.9520 - acc: 0.9622 - mDice: 0.6834 - val_loss: 0.7528 - val_acc: 0.9768 - val_mDice: 0.7428

Epoch 00033: val_mDice improved from 0.74074 to 0.74277, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 34/300
 - 20s - loss: 0.9485 - acc: 0.9622 - mDice: 0.6851 - val_loss: 0.7537 - val_acc: 0.9771 - val_mDice: 0.7450

Epoch 00034: val_mDice improved from 0.74277 to 0.74505, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 35/300
 - 18s - loss: 0.9375 - acc: 0.9626 - mDice: 0.6885 - val_loss: 0.7379 - val_acc: 0.9771 - val_mDice: 0.7430

Epoch 00035: val_mDice did not improve from 0.74505
Epoch 36/300
 - 20s - loss: 0.9317 - acc: 0.9627 - mDice: 0.6902 - val_loss: 0.7530 - val_acc: 0.9770 - val_mDice: 0.7458

Epoch 00036: val_mDice improved from 0.74505 to 0.74581, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 37/300
 - 19s - loss: 0.9242 - acc: 0.9628 - mDice: 0.6926 - val_loss: 0.7467 - val_acc: 0.9763 - val_mDice: 0.7502

Epoch 00037: val_mDice improved from 0.74581 to 0.75025, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 38/300
 - 19s - loss: 0.9168 - acc: 0.9630 - mDice: 0.6946 - val_loss: 0.7513 - val_acc: 0.9770 - val_mDice: 0.7445

Epoch 00038: val_mDice did not improve from 0.75025
Epoch 39/300
 - 20s - loss: 0.9088 - acc: 0.9632 - mDice: 0.6971 - val_loss: 0.7360 - val_acc: 0.9772 - val_mDice: 0.7511

Epoch 00039: val_mDice improved from 0.75025 to 0.75114, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 40/300
 - 19s - loss: 0.9025 - acc: 0.9633 - mDice: 0.6991 - val_loss: 0.7431 - val_acc: 0.9775 - val_mDice: 0.7487

Epoch 00040: val_mDice did not improve from 0.75114
Epoch 41/300
 - 20s - loss: 0.8948 - acc: 0.9635 - mDice: 0.7014 - val_loss: 0.7320 - val_acc: 0.9774 - val_mDice: 0.7482

Epoch 00041: val_mDice did not improve from 0.75114
Epoch 42/300
 - 19s - loss: 0.8887 - acc: 0.9635 - mDice: 0.7031 - val_loss: 0.7316 - val_acc: 0.9767 - val_mDice: 0.7544

Epoch 00042: val_mDice improved from 0.75114 to 0.75441, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 43/300
 - 19s - loss: 0.8849 - acc: 0.9636 - mDice: 0.7045 - val_loss: 0.7338 - val_acc: 0.9776 - val_mDice: 0.7453

Epoch 00043: val_mDice did not improve from 0.75441
Epoch 44/300
 - 19s - loss: 0.8772 - acc: 0.9638 - mDice: 0.7068 - val_loss: 0.7421 - val_acc: 0.9776 - val_mDice: 0.7536

Epoch 00044: val_mDice did not improve from 0.75441
Epoch 45/300
 - 19s - loss: 0.8738 - acc: 0.9638 - mDice: 0.7081 - val_loss: 0.7444 - val_acc: 0.9778 - val_mDice: 0.7455

Epoch 00045: val_mDice did not improve from 0.75441
Epoch 46/300
 - 21s - loss: 0.8682 - acc: 0.9640 - mDice: 0.7095 - val_loss: 0.7299 - val_acc: 0.9776 - val_mDice: 0.7523

Epoch 00046: val_mDice did not improve from 0.75441
Epoch 47/300
 - 24s - loss: 0.8653 - acc: 0.9639 - mDice: 0.7107 - val_loss: 0.7235 - val_acc: 0.9778 - val_mDice: 0.7531

Epoch 00047: val_mDice did not improve from 0.75441
Epoch 48/300
 - 24s - loss: 0.8595 - acc: 0.9641 - mDice: 0.7121 - val_loss: 0.7343 - val_acc: 0.9776 - val_mDice: 0.7513

Epoch 00048: val_mDice did not improve from 0.75441
Epoch 49/300
 - 24s - loss: 0.8541 - acc: 0.9642 - mDice: 0.7138 - val_loss: 0.7262 - val_acc: 0.9781 - val_mDice: 0.7528

Epoch 00049: val_mDice did not improve from 0.75441
Epoch 50/300
 - 24s - loss: 0.8493 - acc: 0.9643 - mDice: 0.7151 - val_loss: 0.7168 - val_acc: 0.9778 - val_mDice: 0.7572

Epoch 00050: val_mDice improved from 0.75441 to 0.75717, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 51/300
 - 24s - loss: 0.8499 - acc: 0.9643 - mDice: 0.7151 - val_loss: 0.7264 - val_acc: 0.9776 - val_mDice: 0.7569

Epoch 00051: val_mDice did not improve from 0.75717
Epoch 52/300
 - 23s - loss: 0.8429 - acc: 0.9644 - mDice: 0.7169 - val_loss: 0.7268 - val_acc: 0.9779 - val_mDice: 0.7533

Epoch 00052: val_mDice did not improve from 0.75717
Epoch 53/300
 - 25s - loss: 0.8406 - acc: 0.9645 - mDice: 0.7181 - val_loss: 0.7205 - val_acc: 0.9783 - val_mDice: 0.7586

Epoch 00053: val_mDice improved from 0.75717 to 0.75862, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 54/300
 - 26s - loss: 0.8357 - acc: 0.9646 - mDice: 0.7197 - val_loss: 0.7252 - val_acc: 0.9777 - val_mDice: 0.7545

Epoch 00054: val_mDice did not improve from 0.75862
Epoch 55/300
 - 24s - loss: 0.8326 - acc: 0.9646 - mDice: 0.7203 - val_loss: 0.7276 - val_acc: 0.9781 - val_mDice: 0.7561

Epoch 00055: val_mDice did not improve from 0.75862
Epoch 56/300
 - 23s - loss: 0.8269 - acc: 0.9647 - mDice: 0.7220 - val_loss: 0.7150 - val_acc: 0.9785 - val_mDice: 0.7576

Epoch 00056: val_mDice did not improve from 0.75862
Epoch 57/300
 - 26s - loss: 0.8230 - acc: 0.9648 - mDice: 0.7231 - val_loss: 0.7337 - val_acc: 0.9784 - val_mDice: 0.7561

Epoch 00057: val_mDice did not improve from 0.75862
Epoch 58/300
 - 25s - loss: 0.8226 - acc: 0.9647 - mDice: 0.7233 - val_loss: 0.7159 - val_acc: 0.9784 - val_mDice: 0.7567

Epoch 00058: val_mDice did not improve from 0.75862
Epoch 59/300
 - 23s - loss: 0.8205 - acc: 0.9648 - mDice: 0.7239 - val_loss: 0.7205 - val_acc: 0.9779 - val_mDice: 0.7608

Epoch 00059: val_mDice improved from 0.75862 to 0.76077, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 60/300
 - 24s - loss: 0.8163 - acc: 0.9649 - mDice: 0.7252 - val_loss: 0.7160 - val_acc: 0.9783 - val_mDice: 0.7590

Epoch 00060: val_mDice did not improve from 0.76077
Epoch 61/300
 - 26s - loss: 0.8150 - acc: 0.9649 - mDice: 0.7256 - val_loss: 0.7190 - val_acc: 0.9785 - val_mDice: 0.7547

Epoch 00061: val_mDice did not improve from 0.76077
Epoch 62/300
 - 19s - loss: 0.8090 - acc: 0.9650 - mDice: 0.7274 - val_loss: 0.7049 - val_acc: 0.9783 - val_mDice: 0.7571

Epoch 00062: val_mDice did not improve from 0.76077
Epoch 63/300
 - 19s - loss: 0.8094 - acc: 0.9650 - mDice: 0.7274 - val_loss: 0.7155 - val_acc: 0.9782 - val_mDice: 0.7599

Epoch 00063: val_mDice did not improve from 0.76077
Epoch 64/300
 - 18s - loss: 0.8051 - acc: 0.9650 - mDice: 0.7286 - val_loss: 0.7063 - val_acc: 0.9785 - val_mDice: 0.7623

Epoch 00064: val_mDice improved from 0.76077 to 0.76233, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 65/300
 - 18s - loss: 0.8018 - acc: 0.9651 - mDice: 0.7296 - val_loss: 0.7092 - val_acc: 0.9789 - val_mDice: 0.7598

Epoch 00065: val_mDice did not improve from 0.76233
Epoch 66/300
 - 19s - loss: 0.8007 - acc: 0.9651 - mDice: 0.7299 - val_loss: 0.7128 - val_acc: 0.9782 - val_mDice: 0.7599

Epoch 00066: val_mDice did not improve from 0.76233
Epoch 67/300
 - 18s - loss: 0.7998 - acc: 0.9651 - mDice: 0.7301 - val_loss: 0.7072 - val_acc: 0.9784 - val_mDice: 0.7617

Epoch 00067: val_mDice did not improve from 0.76233
Epoch 68/300
 - 18s - loss: 0.7973 - acc: 0.9652 - mDice: 0.7306 - val_loss: 0.7127 - val_acc: 0.9785 - val_mDice: 0.7594

Epoch 00068: val_mDice did not improve from 0.76233
Epoch 69/300
 - 18s - loss: 0.7924 - acc: 0.9653 - mDice: 0.7322 - val_loss: 0.7204 - val_acc: 0.9782 - val_mDice: 0.7604

Epoch 00069: val_mDice did not improve from 0.76233
Epoch 70/300
 - 18s - loss: 0.7914 - acc: 0.9653 - mDice: 0.7329 - val_loss: 0.7092 - val_acc: 0.9789 - val_mDice: 0.7581

Epoch 00070: val_mDice did not improve from 0.76233
Epoch 71/300
 - 19s - loss: 0.7893 - acc: 0.9654 - mDice: 0.7334 - val_loss: 0.7164 - val_acc: 0.9785 - val_mDice: 0.7600

Epoch 00071: val_mDice did not improve from 0.76233
Epoch 72/300
 - 18s - loss: 0.7881 - acc: 0.9653 - mDice: 0.7338 - val_loss: 0.7095 - val_acc: 0.9781 - val_mDice: 0.7586

Epoch 00072: val_mDice did not improve from 0.76233
Epoch 73/300
 - 18s - loss: 0.7861 - acc: 0.9654 - mDice: 0.7344 - val_loss: 0.6945 - val_acc: 0.9793 - val_mDice: 0.7623

Epoch 00073: val_mDice improved from 0.76233 to 0.76235, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 74/300
 - 18s - loss: 0.7831 - acc: 0.9655 - mDice: 0.7351 - val_loss: 0.7081 - val_acc: 0.9786 - val_mDice: 0.7586

Epoch 00074: val_mDice did not improve from 0.76235
Epoch 75/300
 - 19s - loss: 0.7847 - acc: 0.9655 - mDice: 0.7346 - val_loss: 0.7264 - val_acc: 0.9788 - val_mDice: 0.7583

Epoch 00075: val_mDice did not improve from 0.76235
Epoch 76/300
 - 18s - loss: 0.7817 - acc: 0.9655 - mDice: 0.7356 - val_loss: 0.6945 - val_acc: 0.9789 - val_mDice: 0.7627

Epoch 00076: val_mDice improved from 0.76235 to 0.76267, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 77/300
 - 18s - loss: 0.7792 - acc: 0.9656 - mDice: 0.7363 - val_loss: 0.7005 - val_acc: 0.9789 - val_mDice: 0.7607

Epoch 00077: val_mDice did not improve from 0.76267
Epoch 78/300
 - 18s - loss: 0.7780 - acc: 0.9656 - mDice: 0.7367 - val_loss: 0.7052 - val_acc: 0.9782 - val_mDice: 0.7630

Epoch 00078: val_mDice improved from 0.76267 to 0.76295, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 79/300
 - 18s - loss: 0.7754 - acc: 0.9657 - mDice: 0.7376 - val_loss: 0.6909 - val_acc: 0.9789 - val_mDice: 0.7677

Epoch 00079: val_mDice improved from 0.76295 to 0.76770, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 80/300
 - 19s - loss: 0.7747 - acc: 0.9657 - mDice: 0.7375 - val_loss: 0.6998 - val_acc: 0.9782 - val_mDice: 0.7605

Epoch 00080: val_mDice did not improve from 0.76770
Epoch 81/300
 - 18s - loss: 0.7719 - acc: 0.9658 - mDice: 0.7383 - val_loss: 0.7023 - val_acc: 0.9781 - val_mDice: 0.7655

Epoch 00081: val_mDice did not improve from 0.76770
Epoch 82/300
 - 18s - loss: 0.7740 - acc: 0.9657 - mDice: 0.7382 - val_loss: 0.7156 - val_acc: 0.9782 - val_mDice: 0.7622

Epoch 00082: val_mDice did not improve from 0.76770
Epoch 83/300
 - 18s - loss: 0.7671 - acc: 0.9659 - mDice: 0.7402 - val_loss: 0.6993 - val_acc: 0.9785 - val_mDice: 0.7668

Epoch 00083: val_mDice did not improve from 0.76770
Epoch 84/300
 - 18s - loss: 0.7709 - acc: 0.9658 - mDice: 0.7389 - val_loss: 0.7038 - val_acc: 0.9780 - val_mDice: 0.7641

Epoch 00084: val_mDice did not improve from 0.76770
Epoch 85/300
 - 18s - loss: 0.7677 - acc: 0.9658 - mDice: 0.7400 - val_loss: 0.7002 - val_acc: 0.9786 - val_mDice: 0.7635

Epoch 00085: val_mDice did not improve from 0.76770
Epoch 86/300
 - 19s - loss: 0.7663 - acc: 0.9659 - mDice: 0.7405 - val_loss: 0.7035 - val_acc: 0.9786 - val_mDice: 0.7667

Epoch 00086: val_mDice did not improve from 0.76770
Epoch 87/300
 - 18s - loss: 0.7651 - acc: 0.9659 - mDice: 0.7406 - val_loss: 0.7011 - val_acc: 0.9785 - val_mDice: 0.7656

Epoch 00087: val_mDice did not improve from 0.76770
Epoch 88/300
 - 18s - loss: 0.7625 - acc: 0.9660 - mDice: 0.7414 - val_loss: 0.6989 - val_acc: 0.9786 - val_mDice: 0.7652

Epoch 00088: val_mDice did not improve from 0.76770
Epoch 89/300
 - 18s - loss: 0.7619 - acc: 0.9660 - mDice: 0.7415 - val_loss: 0.7005 - val_acc: 0.9784 - val_mDice: 0.7646

Epoch 00089: val_mDice did not improve from 0.76770
Epoch 90/300
 - 19s - loss: 0.7591 - acc: 0.9661 - mDice: 0.7427 - val_loss: 0.7025 - val_acc: 0.9786 - val_mDice: 0.7671

Epoch 00090: val_mDice did not improve from 0.76770
Epoch 91/300
 - 18s - loss: 0.7607 - acc: 0.9660 - mDice: 0.7421 - val_loss: 0.7076 - val_acc: 0.9788 - val_mDice: 0.7646

Epoch 00091: val_mDice did not improve from 0.76770
Epoch 92/300
 - 18s - loss: 0.7600 - acc: 0.9660 - mDice: 0.7424 - val_loss: 0.6976 - val_acc: 0.9788 - val_mDice: 0.7612

Epoch 00092: val_mDice did not improve from 0.76770
Epoch 93/300
 - 18s - loss: 0.7594 - acc: 0.9661 - mDice: 0.7423 - val_loss: 0.6928 - val_acc: 0.9790 - val_mDice: 0.7650

Epoch 00093: val_mDice did not improve from 0.76770
Epoch 94/300
 - 18s - loss: 0.7558 - acc: 0.9661 - mDice: 0.7435 - val_loss: 0.6967 - val_acc: 0.9788 - val_mDice: 0.7661

Epoch 00094: val_mDice did not improve from 0.76770
Epoch 95/300
 - 19s - loss: 0.7541 - acc: 0.9662 - mDice: 0.7437 - val_loss: 0.7102 - val_acc: 0.9776 - val_mDice: 0.7686

Epoch 00095: val_mDice improved from 0.76770 to 0.76858, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 96/300
 - 18s - loss: 0.7539 - acc: 0.9662 - mDice: 0.7443 - val_loss: 0.6981 - val_acc: 0.9786 - val_mDice: 0.7652

Epoch 00096: val_mDice did not improve from 0.76858
Epoch 97/300
 - 18s - loss: 0.7532 - acc: 0.9663 - mDice: 0.7445 - val_loss: 0.6931 - val_acc: 0.9792 - val_mDice: 0.7650

Epoch 00097: val_mDice did not improve from 0.76858
Epoch 98/300
 - 18s - loss: 0.7527 - acc: 0.9662 - mDice: 0.7447 - val_loss: 0.7047 - val_acc: 0.9790 - val_mDice: 0.7668

Epoch 00098: val_mDice did not improve from 0.76858
Epoch 99/300
 - 18s - loss: 0.7502 - acc: 0.9663 - mDice: 0.7452 - val_loss: 0.6896 - val_acc: 0.9787 - val_mDice: 0.7684

Epoch 00099: val_mDice did not improve from 0.76858
Epoch 100/300
 - 19s - loss: 0.7532 - acc: 0.9663 - mDice: 0.7446 - val_loss: 0.6871 - val_acc: 0.9796 - val_mDice: 0.7681

Epoch 00100: val_mDice did not improve from 0.76858
Epoch 101/300
 - 18s - loss: 0.7495 - acc: 0.9663 - mDice: 0.7457 - val_loss: 0.7042 - val_acc: 0.9783 - val_mDice: 0.7689

Epoch 00101: val_mDice improved from 0.76858 to 0.76891, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 102/300
 - 18s - loss: 0.7476 - acc: 0.9664 - mDice: 0.7459 - val_loss: 0.7046 - val_acc: 0.9790 - val_mDice: 0.7644

Epoch 00102: val_mDice did not improve from 0.76891
Epoch 103/300
 - 18s - loss: 0.7462 - acc: 0.9664 - mDice: 0.7466 - val_loss: 0.6898 - val_acc: 0.9788 - val_mDice: 0.7673

Epoch 00103: val_mDice did not improve from 0.76891
Epoch 104/300
 - 18s - loss: 0.7465 - acc: 0.9665 - mDice: 0.7466 - val_loss: 0.6881 - val_acc: 0.9785 - val_mDice: 0.7695

Epoch 00104: val_mDice improved from 0.76891 to 0.76947, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 105/300
 - 19s - loss: 0.7455 - acc: 0.9664 - mDice: 0.7468 - val_loss: 0.6931 - val_acc: 0.9787 - val_mDice: 0.7693

Epoch 00105: val_mDice did not improve from 0.76947
Epoch 106/300
 - 18s - loss: 0.7447 - acc: 0.9665 - mDice: 0.7470 - val_loss: 0.6979 - val_acc: 0.9791 - val_mDice: 0.7664

Epoch 00106: val_mDice did not improve from 0.76947
Epoch 107/300
 - 18s - loss: 0.7431 - acc: 0.9665 - mDice: 0.7476 - val_loss: 0.6977 - val_acc: 0.9791 - val_mDice: 0.7663

Epoch 00107: val_mDice did not improve from 0.76947
Epoch 108/300
 - 18s - loss: 0.7429 - acc: 0.9665 - mDice: 0.7479 - val_loss: 0.6886 - val_acc: 0.9794 - val_mDice: 0.7655

Epoch 00108: val_mDice did not improve from 0.76947
Epoch 109/300
 - 18s - loss: 0.7424 - acc: 0.9665 - mDice: 0.7478 - val_loss: 0.6937 - val_acc: 0.9793 - val_mDice: 0.7691

Epoch 00109: val_mDice did not improve from 0.76947
Epoch 110/300
 - 19s - loss: 0.7428 - acc: 0.9666 - mDice: 0.7479 - val_loss: 0.6913 - val_acc: 0.9789 - val_mDice: 0.7648

Epoch 00110: val_mDice did not improve from 0.76947
Epoch 111/300
 - 19s - loss: 0.7413 - acc: 0.9666 - mDice: 0.7482 - val_loss: 0.7095 - val_acc: 0.9780 - val_mDice: 0.7643

Epoch 00111: val_mDice did not improve from 0.76947
Epoch 112/300
 - 18s - loss: 0.7394 - acc: 0.9666 - mDice: 0.7488 - val_loss: 0.6966 - val_acc: 0.9791 - val_mDice: 0.7690

Epoch 00112: val_mDice did not improve from 0.76947
Epoch 113/300
 - 18s - loss: 0.7404 - acc: 0.9666 - mDice: 0.7485 - val_loss: 0.6934 - val_acc: 0.9792 - val_mDice: 0.7683

Epoch 00113: val_mDice did not improve from 0.76947
Epoch 114/300
 - 18s - loss: 0.7385 - acc: 0.9667 - mDice: 0.7490 - val_loss: 0.6905 - val_acc: 0.9792 - val_mDice: 0.7645

Epoch 00114: val_mDice did not improve from 0.76947
Epoch 115/300
 - 18s - loss: 0.7371 - acc: 0.9667 - mDice: 0.7494 - val_loss: 0.6958 - val_acc: 0.9787 - val_mDice: 0.7687

Epoch 00115: val_mDice did not improve from 0.76947
Epoch 116/300
 - 19s - loss: 0.7367 - acc: 0.9668 - mDice: 0.7497 - val_loss: 0.6946 - val_acc: 0.9786 - val_mDice: 0.7671

Epoch 00116: val_mDice did not improve from 0.76947
Epoch 117/300
 - 18s - loss: 0.7359 - acc: 0.9668 - mDice: 0.7500 - val_loss: 0.6929 - val_acc: 0.9787 - val_mDice: 0.7672

Epoch 00117: val_mDice did not improve from 0.76947
Epoch 118/300
 - 18s - loss: 0.7337 - acc: 0.9668 - mDice: 0.7506 - val_loss: 0.6858 - val_acc: 0.9786 - val_mDice: 0.7683

Epoch 00118: val_mDice did not improve from 0.76947
Epoch 119/300
 - 18s - loss: 0.7335 - acc: 0.9668 - mDice: 0.7507 - val_loss: 0.6913 - val_acc: 0.9786 - val_mDice: 0.7656

Epoch 00119: val_mDice did not improve from 0.76947
Epoch 120/300
 - 18s - loss: 0.7335 - acc: 0.9668 - mDice: 0.7505 - val_loss: 0.6933 - val_acc: 0.9785 - val_mDice: 0.7703

Epoch 00120: val_mDice improved from 0.76947 to 0.77029, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 121/300
 - 19s - loss: 0.7326 - acc: 0.9669 - mDice: 0.7510 - val_loss: 0.7042 - val_acc: 0.9790 - val_mDice: 0.7672

Epoch 00121: val_mDice did not improve from 0.77029
Epoch 122/300
 - 18s - loss: 0.7301 - acc: 0.9669 - mDice: 0.7518 - val_loss: 0.6905 - val_acc: 0.9794 - val_mDice: 0.7682

Epoch 00122: val_mDice did not improve from 0.77029
Epoch 123/300
 - 18s - loss: 0.7300 - acc: 0.9669 - mDice: 0.7517 - val_loss: 0.6958 - val_acc: 0.9782 - val_mDice: 0.7701

Epoch 00123: val_mDice did not improve from 0.77029
Epoch 124/300
 - 18s - loss: 0.7304 - acc: 0.9669 - mDice: 0.7517 - val_loss: 0.7024 - val_acc: 0.9786 - val_mDice: 0.7642

Epoch 00124: val_mDice did not improve from 0.77029
Epoch 125/300
 - 18s - loss: 0.7302 - acc: 0.9669 - mDice: 0.7516 - val_loss: 0.6887 - val_acc: 0.9789 - val_mDice: 0.7700

Epoch 00125: val_mDice did not improve from 0.77029
Epoch 126/300
 - 18s - loss: 0.7296 - acc: 0.9669 - mDice: 0.7522 - val_loss: 0.6927 - val_acc: 0.9789 - val_mDice: 0.7683

Epoch 00126: val_mDice did not improve from 0.77029
Epoch 127/300
 - 19s - loss: 0.7303 - acc: 0.9669 - mDice: 0.7515 - val_loss: 0.6875 - val_acc: 0.9795 - val_mDice: 0.7694

Epoch 00127: val_mDice did not improve from 0.77029
Epoch 128/300
 - 18s - loss: 0.7291 - acc: 0.9669 - mDice: 0.7522 - val_loss: 0.6921 - val_acc: 0.9789 - val_mDice: 0.7710

Epoch 00128: val_mDice improved from 0.77029 to 0.77100, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 129/300
 - 18s - loss: 0.7274 - acc: 0.9670 - mDice: 0.7526 - val_loss: 0.6935 - val_acc: 0.9793 - val_mDice: 0.7648

Epoch 00129: val_mDice did not improve from 0.77100
Epoch 130/300
 - 18s - loss: 0.7260 - acc: 0.9670 - mDice: 0.7531 - val_loss: 0.6923 - val_acc: 0.9787 - val_mDice: 0.7709

Epoch 00130: val_mDice did not improve from 0.77100
Epoch 131/300
 - 18s - loss: 0.7267 - acc: 0.9670 - mDice: 0.7528 - val_loss: 0.7090 - val_acc: 0.9792 - val_mDice: 0.7656

Epoch 00131: val_mDice did not improve from 0.77100
Epoch 132/300
 - 19s - loss: 0.7263 - acc: 0.9670 - mDice: 0.7528 - val_loss: 0.6948 - val_acc: 0.9789 - val_mDice: 0.7694

Epoch 00132: val_mDice did not improve from 0.77100
Epoch 133/300
 - 18s - loss: 0.7252 - acc: 0.9671 - mDice: 0.7532 - val_loss: 0.6858 - val_acc: 0.9793 - val_mDice: 0.7692

Epoch 00133: val_mDice did not improve from 0.77100
Epoch 134/300
 - 18s - loss: 0.7230 - acc: 0.9671 - mDice: 0.7540 - val_loss: 0.6964 - val_acc: 0.9789 - val_mDice: 0.7685

Epoch 00134: val_mDice did not improve from 0.77100
Epoch 135/300
 - 18s - loss: 0.7232 - acc: 0.9672 - mDice: 0.7537 - val_loss: 0.6903 - val_acc: 0.9787 - val_mDice: 0.7715

Epoch 00135: val_mDice improved from 0.77100 to 0.77153, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 136/300
 - 18s - loss: 0.7225 - acc: 0.9671 - mDice: 0.7542 - val_loss: 0.7006 - val_acc: 0.9780 - val_mDice: 0.7677

Epoch 00136: val_mDice did not improve from 0.77153
Epoch 137/300
 - 19s - loss: 0.7233 - acc: 0.9671 - mDice: 0.7541 - val_loss: 0.6835 - val_acc: 0.9793 - val_mDice: 0.7701

Epoch 00137: val_mDice did not improve from 0.77153
Epoch 138/300
 - 18s - loss: 0.7226 - acc: 0.9671 - mDice: 0.7540 - val_loss: 0.7001 - val_acc: 0.9783 - val_mDice: 0.7675

Epoch 00138: val_mDice did not improve from 0.77153
Epoch 139/300
 - 18s - loss: 0.7219 - acc: 0.9671 - mDice: 0.7544 - val_loss: 0.6887 - val_acc: 0.9787 - val_mDice: 0.7730

Epoch 00139: val_mDice improved from 0.77153 to 0.77296, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 140/300
 - 18s - loss: 0.7187 - acc: 0.9672 - mDice: 0.7552 - val_loss: 0.6909 - val_acc: 0.9786 - val_mDice: 0.7727

Epoch 00140: val_mDice did not improve from 0.77296
Epoch 141/300
 - 19s - loss: 0.7199 - acc: 0.9672 - mDice: 0.7549 - val_loss: 0.7004 - val_acc: 0.9780 - val_mDice: 0.7717

Epoch 00141: val_mDice did not improve from 0.77296
Epoch 142/300
 - 18s - loss: 0.7199 - acc: 0.9672 - mDice: 0.7552 - val_loss: 0.6930 - val_acc: 0.9787 - val_mDice: 0.7721

Epoch 00142: val_mDice did not improve from 0.77296
Epoch 143/300
 - 18s - loss: 0.7189 - acc: 0.9672 - mDice: 0.7550 - val_loss: 0.6866 - val_acc: 0.9791 - val_mDice: 0.7708

Epoch 00143: val_mDice did not improve from 0.77296
Epoch 144/300
 - 19s - loss: 0.7185 - acc: 0.9672 - mDice: 0.7559 - val_loss: 0.6864 - val_acc: 0.9792 - val_mDice: 0.7737

Epoch 00144: val_mDice improved from 0.77296 to 0.77371, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 145/300
 - 18s - loss: 0.7192 - acc: 0.9672 - mDice: 0.7554 - val_loss: 0.6838 - val_acc: 0.9785 - val_mDice: 0.7724

Epoch 00145: val_mDice did not improve from 0.77371
Epoch 146/300
 - 19s - loss: 0.7187 - acc: 0.9672 - mDice: 0.7557 - val_loss: 0.6909 - val_acc: 0.9785 - val_mDice: 0.7739

Epoch 00146: val_mDice improved from 0.77371 to 0.77387, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 147/300
 - 18s - loss: 0.7174 - acc: 0.9673 - mDice: 0.7557 - val_loss: 0.6845 - val_acc: 0.9795 - val_mDice: 0.7737

Epoch 00147: val_mDice did not improve from 0.77387
Epoch 148/300
 - 18s - loss: 0.7159 - acc: 0.9673 - mDice: 0.7563 - val_loss: 0.6775 - val_acc: 0.9795 - val_mDice: 0.7721

Epoch 00148: val_mDice did not improve from 0.77387
Epoch 149/300
 - 18s - loss: 0.7156 - acc: 0.9673 - mDice: 0.7566 - val_loss: 0.6879 - val_acc: 0.9793 - val_mDice: 0.7707

Epoch 00149: val_mDice did not improve from 0.77387
Epoch 150/300
 - 19s - loss: 0.7160 - acc: 0.9673 - mDice: 0.7563 - val_loss: 0.7013 - val_acc: 0.9789 - val_mDice: 0.7756

Epoch 00150: val_mDice improved from 0.77387 to 0.77564, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 151/300
 - 18s - loss: 0.7140 - acc: 0.9673 - mDice: 0.7571 - val_loss: 0.6803 - val_acc: 0.9795 - val_mDice: 0.7722

Epoch 00151: val_mDice did not improve from 0.77564
Epoch 152/300
 - 18s - loss: 0.7152 - acc: 0.9673 - mDice: 0.7567 - val_loss: 0.6919 - val_acc: 0.9791 - val_mDice: 0.7719

Epoch 00152: val_mDice did not improve from 0.77564
Epoch 153/300
 - 18s - loss: 0.7122 - acc: 0.9674 - mDice: 0.7573 - val_loss: 0.6824 - val_acc: 0.9790 - val_mDice: 0.7740

Epoch 00153: val_mDice did not improve from 0.77564
Epoch 154/300
 - 18s - loss: 0.7142 - acc: 0.9674 - mDice: 0.7569 - val_loss: 0.6755 - val_acc: 0.9794 - val_mDice: 0.7742

Epoch 00154: val_mDice did not improve from 0.77564
Epoch 155/300
 - 18s - loss: 0.7118 - acc: 0.9674 - mDice: 0.7576 - val_loss: 0.6796 - val_acc: 0.9793 - val_mDice: 0.7750

Epoch 00155: val_mDice did not improve from 0.77564
Epoch 156/300
 - 19s - loss: 0.7118 - acc: 0.9674 - mDice: 0.7577 - val_loss: 0.6942 - val_acc: 0.9789 - val_mDice: 0.7729

Epoch 00156: val_mDice did not improve from 0.77564
Epoch 157/300
 - 18s - loss: 0.7117 - acc: 0.9674 - mDice: 0.7578 - val_loss: 0.6941 - val_acc: 0.9785 - val_mDice: 0.7711

Epoch 00157: val_mDice did not improve from 0.77564
Epoch 158/300
 - 18s - loss: 0.7111 - acc: 0.9674 - mDice: 0.7582 - val_loss: 0.6758 - val_acc: 0.9795 - val_mDice: 0.7746

Epoch 00158: val_mDice did not improve from 0.77564
Epoch 159/300
 - 18s - loss: 0.7109 - acc: 0.9674 - mDice: 0.7582 - val_loss: 0.6887 - val_acc: 0.9793 - val_mDice: 0.7686

Epoch 00159: val_mDice did not improve from 0.77564
Epoch 160/300
 - 18s - loss: 0.7095 - acc: 0.9674 - mDice: 0.7587 - val_loss: 0.6861 - val_acc: 0.9788 - val_mDice: 0.7758

Epoch 00160: val_mDice improved from 0.77564 to 0.77579, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 161/300
 - 20s - loss: 0.7103 - acc: 0.9674 - mDice: 0.7581 - val_loss: 0.6799 - val_acc: 0.9792 - val_mDice: 0.7743

Epoch 00161: val_mDice did not improve from 0.77579
Epoch 162/300
 - 18s - loss: 0.7105 - acc: 0.9674 - mDice: 0.7581 - val_loss: 0.6830 - val_acc: 0.9790 - val_mDice: 0.7735

Epoch 00162: val_mDice did not improve from 0.77579
Epoch 163/300
 - 19s - loss: 0.7102 - acc: 0.9674 - mDice: 0.7582 - val_loss: 0.6878 - val_acc: 0.9783 - val_mDice: 0.7734

Epoch 00163: val_mDice did not improve from 0.77579
Epoch 164/300
 - 19s - loss: 0.7078 - acc: 0.9675 - mDice: 0.7591 - val_loss: 0.6801 - val_acc: 0.9789 - val_mDice: 0.7741

Epoch 00164: val_mDice did not improve from 0.77579
Epoch 165/300
 - 18s - loss: 0.7085 - acc: 0.9674 - mDice: 0.7587 - val_loss: 0.6939 - val_acc: 0.9783 - val_mDice: 0.7733

Epoch 00165: val_mDice did not improve from 0.77579
Epoch 166/300
 - 19s - loss: 0.7064 - acc: 0.9675 - mDice: 0.7596 - val_loss: 0.6881 - val_acc: 0.9793 - val_mDice: 0.7757

Epoch 00166: val_mDice did not improve from 0.77579
Epoch 167/300
 - 19s - loss: 0.7065 - acc: 0.9676 - mDice: 0.7597 - val_loss: 0.6876 - val_acc: 0.9789 - val_mDice: 0.7734

Epoch 00167: val_mDice did not improve from 0.77579
Epoch 168/300
 - 18s - loss: 0.7076 - acc: 0.9675 - mDice: 0.7591 - val_loss: 0.6905 - val_acc: 0.9790 - val_mDice: 0.7734

Epoch 00168: val_mDice did not improve from 0.77579
Epoch 169/300
 - 19s - loss: 0.7064 - acc: 0.9675 - mDice: 0.7595 - val_loss: 0.6823 - val_acc: 0.9797 - val_mDice: 0.7730

Epoch 00169: val_mDice did not improve from 0.77579
Epoch 170/300
 - 19s - loss: 0.7064 - acc: 0.9675 - mDice: 0.7596 - val_loss: 0.6888 - val_acc: 0.9790 - val_mDice: 0.7708

Epoch 00170: val_mDice did not improve from 0.77579
Epoch 171/300
 - 18s - loss: 0.7069 - acc: 0.9675 - mDice: 0.7597 - val_loss: 0.6884 - val_acc: 0.9792 - val_mDice: 0.7702

Epoch 00171: val_mDice did not improve from 0.77579
Epoch 172/300
 - 19s - loss: 0.7029 - acc: 0.9676 - mDice: 0.7605 - val_loss: 0.6800 - val_acc: 0.9789 - val_mDice: 0.7727

Epoch 00172: val_mDice did not improve from 0.77579
Epoch 173/300
 - 20s - loss: 0.7047 - acc: 0.9676 - mDice: 0.7599 - val_loss: 0.6952 - val_acc: 0.9783 - val_mDice: 0.7732

Epoch 00173: val_mDice did not improve from 0.77579
Epoch 174/300
 - 18s - loss: 0.7037 - acc: 0.9676 - mDice: 0.7605 - val_loss: 0.6881 - val_acc: 0.9788 - val_mDice: 0.7751

Epoch 00174: val_mDice did not improve from 0.77579
Epoch 175/300
 - 18s - loss: 0.7033 - acc: 0.9676 - mDice: 0.7605 - val_loss: 0.6772 - val_acc: 0.9793 - val_mDice: 0.7754

Epoch 00175: val_mDice did not improve from 0.77579
Epoch 176/300
 - 19s - loss: 0.7029 - acc: 0.9676 - mDice: 0.7609 - val_loss: 0.6805 - val_acc: 0.9793 - val_mDice: 0.7725

Epoch 00176: val_mDice did not improve from 0.77579
Epoch 177/300
 - 19s - loss: 0.7039 - acc: 0.9676 - mDice: 0.7603 - val_loss: 0.6887 - val_acc: 0.9784 - val_mDice: 0.7753

Epoch 00177: val_mDice did not improve from 0.77579
Epoch 178/300
 - 20s - loss: 0.7022 - acc: 0.9676 - mDice: 0.7610 - val_loss: 0.6852 - val_acc: 0.9785 - val_mDice: 0.7754

Epoch 00178: val_mDice did not improve from 0.77579
Epoch 179/300
 - 18s - loss: 0.7033 - acc: 0.9676 - mDice: 0.7608 - val_loss: 0.6819 - val_acc: 0.9793 - val_mDice: 0.7761

Epoch 00179: val_mDice improved from 0.77579 to 0.77607, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 180/300
 - 19s - loss: 0.7018 - acc: 0.9676 - mDice: 0.7613 - val_loss: 0.6786 - val_acc: 0.9790 - val_mDice: 0.7715

Epoch 00180: val_mDice did not improve from 0.77607
Epoch 181/300
 - 19s - loss: 0.7021 - acc: 0.9676 - mDice: 0.7609 - val_loss: 0.6803 - val_acc: 0.9792 - val_mDice: 0.7752

Epoch 00181: val_mDice did not improve from 0.77607
Epoch 182/300
 - 19s - loss: 0.7005 - acc: 0.9676 - mDice: 0.7619 - val_loss: 0.6807 - val_acc: 0.9789 - val_mDice: 0.7729

Epoch 00182: val_mDice did not improve from 0.77607
Epoch 183/300
 - 20s - loss: 0.7014 - acc: 0.9676 - mDice: 0.7615 - val_loss: 0.6828 - val_acc: 0.9791 - val_mDice: 0.7763

Epoch 00183: val_mDice improved from 0.77607 to 0.77632, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 184/300
 - 19s - loss: 0.6997 - acc: 0.9677 - mDice: 0.7617 - val_loss: 0.6819 - val_acc: 0.9791 - val_mDice: 0.7776

Epoch 00184: val_mDice improved from 0.77632 to 0.77765, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 185/300
 - 21s - loss: 0.6989 - acc: 0.9677 - mDice: 0.7623 - val_loss: 0.6871 - val_acc: 0.9782 - val_mDice: 0.7751

Epoch 00185: val_mDice did not improve from 0.77765
Epoch 186/300
 - 20s - loss: 0.6990 - acc: 0.9677 - mDice: 0.7621 - val_loss: 0.6826 - val_acc: 0.9789 - val_mDice: 0.7744

Epoch 00186: val_mDice did not improve from 0.77765
Epoch 187/300
 - 20s - loss: 0.6995 - acc: 0.9677 - mDice: 0.7620 - val_loss: 0.6916 - val_acc: 0.9786 - val_mDice: 0.7738

Epoch 00187: val_mDice did not improve from 0.77765
Epoch 188/300
 - 21s - loss: 0.6991 - acc: 0.9676 - mDice: 0.7622 - val_loss: 0.6840 - val_acc: 0.9789 - val_mDice: 0.7726

Epoch 00188: val_mDice did not improve from 0.77765
Epoch 189/300
 - 20s - loss: 0.6987 - acc: 0.9677 - mDice: 0.7619 - val_loss: 0.6815 - val_acc: 0.9788 - val_mDice: 0.7742

Epoch 00189: val_mDice did not improve from 0.77765
Epoch 190/300
 - 21s - loss: 0.6970 - acc: 0.9677 - mDice: 0.7630 - val_loss: 0.6885 - val_acc: 0.9791 - val_mDice: 0.7744

Epoch 00190: val_mDice did not improve from 0.77765
Epoch 191/300
 - 21s - loss: 0.6944 - acc: 0.9678 - mDice: 0.7638 - val_loss: 0.6893 - val_acc: 0.9789 - val_mDice: 0.7762

Epoch 00191: val_mDice did not improve from 0.77765
Epoch 192/300
 - 20s - loss: 0.6965 - acc: 0.9677 - mDice: 0.7632 - val_loss: 0.6789 - val_acc: 0.9789 - val_mDice: 0.7769

Epoch 00192: val_mDice did not improve from 0.77765
Epoch 193/300
 - 22s - loss: 0.6963 - acc: 0.9677 - mDice: 0.7631 - val_loss: 0.6755 - val_acc: 0.9791 - val_mDice: 0.7713

Epoch 00193: val_mDice did not improve from 0.77765
Epoch 194/300
 - 20s - loss: 0.6950 - acc: 0.9678 - mDice: 0.7636 - val_loss: 0.6725 - val_acc: 0.9792 - val_mDice: 0.7792

Epoch 00194: val_mDice improved from 0.77765 to 0.77916, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 195/300
 - 21s - loss: 0.6953 - acc: 0.9677 - mDice: 0.7635 - val_loss: 0.6871 - val_acc: 0.9792 - val_mDice: 0.7737

Epoch 00195: val_mDice did not improve from 0.77916
Epoch 196/300
 - 21s - loss: 0.6958 - acc: 0.9678 - mDice: 0.7631 - val_loss: 0.6731 - val_acc: 0.9793 - val_mDice: 0.7799

Epoch 00196: val_mDice improved from 0.77916 to 0.77991, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 197/300
 - 19s - loss: 0.6928 - acc: 0.9678 - mDice: 0.7642 - val_loss: 0.6871 - val_acc: 0.9784 - val_mDice: 0.7760

Epoch 00197: val_mDice did not improve from 0.77991
Epoch 198/300
 - 20s - loss: 0.6935 - acc: 0.9678 - mDice: 0.7640 - val_loss: 0.6764 - val_acc: 0.9790 - val_mDice: 0.7753

Epoch 00198: val_mDice did not improve from 0.77991
Epoch 199/300
 - 19s - loss: 0.6924 - acc: 0.9678 - mDice: 0.7642 - val_loss: 0.6807 - val_acc: 0.9796 - val_mDice: 0.7762

Epoch 00199: val_mDice did not improve from 0.77991
Epoch 200/300
 - 19s - loss: 0.6923 - acc: 0.9678 - mDice: 0.7645 - val_loss: 0.6795 - val_acc: 0.9796 - val_mDice: 0.7749

Epoch 00200: val_mDice did not improve from 0.77991
Epoch 201/300
 - 20s - loss: 0.6926 - acc: 0.9678 - mDice: 0.7643 - val_loss: 0.6765 - val_acc: 0.9791 - val_mDice: 0.7773

Epoch 00201: val_mDice did not improve from 0.77991
Epoch 202/300
 - 18s - loss: 0.6914 - acc: 0.9679 - mDice: 0.7647 - val_loss: 0.6718 - val_acc: 0.9796 - val_mDice: 0.7792

Epoch 00202: val_mDice did not improve from 0.77991
Epoch 203/300
 - 19s - loss: 0.6917 - acc: 0.9678 - mDice: 0.7648 - val_loss: 0.6823 - val_acc: 0.9791 - val_mDice: 0.7763

Epoch 00203: val_mDice did not improve from 0.77991
Epoch 204/300
 - 19s - loss: 0.6916 - acc: 0.9678 - mDice: 0.7648 - val_loss: 0.6762 - val_acc: 0.9795 - val_mDice: 0.7776

Epoch 00204: val_mDice did not improve from 0.77991
Epoch 205/300
 - 20s - loss: 0.6906 - acc: 0.9679 - mDice: 0.7651 - val_loss: 0.6869 - val_acc: 0.9787 - val_mDice: 0.7781

Epoch 00205: val_mDice did not improve from 0.77991
Epoch 206/300
 - 18s - loss: 0.6906 - acc: 0.9678 - mDice: 0.7651 - val_loss: 0.6841 - val_acc: 0.9795 - val_mDice: 0.7778

Epoch 00206: val_mDice did not improve from 0.77991
Epoch 207/300
 - 20s - loss: 0.6890 - acc: 0.9679 - mDice: 0.7657 - val_loss: 0.6779 - val_acc: 0.9783 - val_mDice: 0.7799

Epoch 00207: val_mDice did not improve from 0.77991
Epoch 208/300
 - 20s - loss: 0.6898 - acc: 0.9679 - mDice: 0.7655 - val_loss: 0.6758 - val_acc: 0.9793 - val_mDice: 0.7777

Epoch 00208: val_mDice did not improve from 0.77991
Epoch 209/300
 - 20s - loss: 0.6876 - acc: 0.9679 - mDice: 0.7660 - val_loss: 0.6747 - val_acc: 0.9789 - val_mDice: 0.7784

Epoch 00209: val_mDice did not improve from 0.77991
Epoch 210/300
 - 20s - loss: 0.6892 - acc: 0.9679 - mDice: 0.7655 - val_loss: 0.6830 - val_acc: 0.9788 - val_mDice: 0.7801

Epoch 00210: val_mDice improved from 0.77991 to 0.78005, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 211/300
 - 19s - loss: 0.6889 - acc: 0.9678 - mDice: 0.7659 - val_loss: 0.6802 - val_acc: 0.9790 - val_mDice: 0.7768

Epoch 00211: val_mDice did not improve from 0.78005
Epoch 212/300
 - 21s - loss: 0.6877 - acc: 0.9679 - mDice: 0.7661 - val_loss: 0.6794 - val_acc: 0.9792 - val_mDice: 0.7797

Epoch 00212: val_mDice did not improve from 0.78005
Epoch 213/300
 - 20s - loss: 0.6866 - acc: 0.9680 - mDice: 0.7665 - val_loss: 0.6754 - val_acc: 0.9788 - val_mDice: 0.7784

Epoch 00213: val_mDice did not improve from 0.78005
Epoch 214/300
 - 20s - loss: 0.6863 - acc: 0.9679 - mDice: 0.7665 - val_loss: 0.6851 - val_acc: 0.9788 - val_mDice: 0.7777

Epoch 00214: val_mDice did not improve from 0.78005
Epoch 215/300
 - 21s - loss: 0.6887 - acc: 0.9679 - mDice: 0.7660 - val_loss: 0.6719 - val_acc: 0.9788 - val_mDice: 0.7766

Epoch 00215: val_mDice did not improve from 0.78005
Epoch 216/300
 - 20s - loss: 0.6868 - acc: 0.9680 - mDice: 0.7665 - val_loss: 0.6816 - val_acc: 0.9793 - val_mDice: 0.7769

Epoch 00216: val_mDice did not improve from 0.78005
Epoch 217/300
 - 20s - loss: 0.6874 - acc: 0.9679 - mDice: 0.7664 - val_loss: 0.6732 - val_acc: 0.9797 - val_mDice: 0.7778

Epoch 00217: val_mDice did not improve from 0.78005
Epoch 218/300
 - 21s - loss: 0.6866 - acc: 0.9679 - mDice: 0.7667 - val_loss: 0.6736 - val_acc: 0.9794 - val_mDice: 0.7788

Epoch 00218: val_mDice did not improve from 0.78005
Epoch 219/300
 - 19s - loss: 0.6857 - acc: 0.9680 - mDice: 0.7666 - val_loss: 0.6712 - val_acc: 0.9796 - val_mDice: 0.7801

Epoch 00219: val_mDice improved from 0.78005 to 0.78007, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 220/300
 - 20s - loss: 0.6848 - acc: 0.9679 - mDice: 0.7671 - val_loss: 0.6746 - val_acc: 0.9790 - val_mDice: 0.7784

Epoch 00220: val_mDice did not improve from 0.78007
Epoch 221/300
 - 18s - loss: 0.6849 - acc: 0.9680 - mDice: 0.7670 - val_loss: 0.6773 - val_acc: 0.9793 - val_mDice: 0.7792

Epoch 00221: val_mDice did not improve from 0.78007
Epoch 222/300
 - 19s - loss: 0.6841 - acc: 0.9680 - mDice: 0.7672 - val_loss: 0.6691 - val_acc: 0.9796 - val_mDice: 0.7769

Epoch 00222: val_mDice did not improve from 0.78007
Epoch 223/300
 - 18s - loss: 0.6841 - acc: 0.9680 - mDice: 0.7675 - val_loss: 0.6887 - val_acc: 0.9798 - val_mDice: 0.7755

Epoch 00223: val_mDice did not improve from 0.78007
Epoch 224/300
 - 18s - loss: 0.6830 - acc: 0.9680 - mDice: 0.7678 - val_loss: 0.6901 - val_acc: 0.9793 - val_mDice: 0.7786

Epoch 00224: val_mDice did not improve from 0.78007
Epoch 225/300
 - 19s - loss: 0.6842 - acc: 0.9680 - mDice: 0.7674 - val_loss: 0.6695 - val_acc: 0.9796 - val_mDice: 0.7826

Epoch 00225: val_mDice improved from 0.78007 to 0.78263, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 226/300
 - 18s - loss: 0.6836 - acc: 0.9680 - mDice: 0.7678 - val_loss: 0.6845 - val_acc: 0.9795 - val_mDice: 0.7753

Epoch 00226: val_mDice did not improve from 0.78263
Epoch 227/300
 - 17s - loss: 0.6830 - acc: 0.9680 - mDice: 0.7677 - val_loss: 0.6809 - val_acc: 0.9784 - val_mDice: 0.7795

Epoch 00227: val_mDice did not improve from 0.78263
Epoch 228/300
 - 17s - loss: 0.6830 - acc: 0.9681 - mDice: 0.7678 - val_loss: 0.6839 - val_acc: 0.9794 - val_mDice: 0.7752

Epoch 00228: val_mDice did not improve from 0.78263
Epoch 229/300
 - 18s - loss: 0.6832 - acc: 0.9681 - mDice: 0.7679 - val_loss: 0.6714 - val_acc: 0.9791 - val_mDice: 0.7787

Epoch 00229: val_mDice did not improve from 0.78263
Epoch 230/300
 - 19s - loss: 0.6824 - acc: 0.9680 - mDice: 0.7680 - val_loss: 0.6690 - val_acc: 0.9792 - val_mDice: 0.7800

Epoch 00230: val_mDice did not improve from 0.78263
Epoch 231/300
 - 17s - loss: 0.6813 - acc: 0.9681 - mDice: 0.7685 - val_loss: 0.6742 - val_acc: 0.9797 - val_mDice: 0.7783

Epoch 00231: val_mDice did not improve from 0.78263
Epoch 232/300
 - 17s - loss: 0.6814 - acc: 0.9681 - mDice: 0.7684 - val_loss: 0.6712 - val_acc: 0.9792 - val_mDice: 0.7776

Epoch 00232: val_mDice did not improve from 0.78263
Epoch 233/300
 - 18s - loss: 0.6800 - acc: 0.9681 - mDice: 0.7688 - val_loss: 0.6728 - val_acc: 0.9794 - val_mDice: 0.7794

Epoch 00233: val_mDice did not improve from 0.78263
Epoch 234/300
 - 18s - loss: 0.6826 - acc: 0.9681 - mDice: 0.7680 - val_loss: 0.6717 - val_acc: 0.9792 - val_mDice: 0.7779

Epoch 00234: val_mDice did not improve from 0.78263
Epoch 235/300
 - 19s - loss: 0.6808 - acc: 0.9681 - mDice: 0.7684 - val_loss: 0.6843 - val_acc: 0.9795 - val_mDice: 0.7792

Epoch 00235: val_mDice did not improve from 0.78263
Epoch 236/300
 - 18s - loss: 0.6796 - acc: 0.9682 - mDice: 0.7691 - val_loss: 0.6737 - val_acc: 0.9789 - val_mDice: 0.7794

Epoch 00236: val_mDice did not improve from 0.78263
Epoch 237/300
 - 18s - loss: 0.6800 - acc: 0.9682 - mDice: 0.7691 - val_loss: 0.6684 - val_acc: 0.9798 - val_mDice: 0.7790

Epoch 00237: val_mDice did not improve from 0.78263
Epoch 238/300
 - 18s - loss: 0.6789 - acc: 0.9681 - mDice: 0.7691 - val_loss: 0.6754 - val_acc: 0.9795 - val_mDice: 0.7810

Epoch 00238: val_mDice did not improve from 0.78263
Epoch 239/300
 - 18s - loss: 0.6801 - acc: 0.9681 - mDice: 0.7689 - val_loss: 0.6708 - val_acc: 0.9796 - val_mDice: 0.7801

Epoch 00239: val_mDice did not improve from 0.78263
Epoch 240/300
 - 19s - loss: 0.6795 - acc: 0.9682 - mDice: 0.7691 - val_loss: 0.6662 - val_acc: 0.9791 - val_mDice: 0.7816

Epoch 00240: val_mDice did not improve from 0.78263
Epoch 241/300
 - 18s - loss: 0.6789 - acc: 0.9682 - mDice: 0.7692 - val_loss: 0.6755 - val_acc: 0.9796 - val_mDice: 0.7820

Epoch 00241: val_mDice did not improve from 0.78263
Epoch 242/300
 - 18s - loss: 0.6794 - acc: 0.9682 - mDice: 0.7691 - val_loss: 0.6739 - val_acc: 0.9790 - val_mDice: 0.7807

Epoch 00242: val_mDice did not improve from 0.78263
Epoch 243/300
 - 18s - loss: 0.6784 - acc: 0.9682 - mDice: 0.7693 - val_loss: 0.6802 - val_acc: 0.9789 - val_mDice: 0.7797

Epoch 00243: val_mDice did not improve from 0.78263
Epoch 244/300
 - 18s - loss: 0.6765 - acc: 0.9682 - mDice: 0.7700 - val_loss: 0.6780 - val_acc: 0.9797 - val_mDice: 0.7815

Epoch 00244: val_mDice did not improve from 0.78263
Epoch 245/300
 - 19s - loss: 0.6765 - acc: 0.9682 - mDice: 0.7699 - val_loss: 0.6848 - val_acc: 0.9794 - val_mDice: 0.7774

Epoch 00245: val_mDice did not improve from 0.78263
Epoch 246/300
 - 18s - loss: 0.6753 - acc: 0.9683 - mDice: 0.7702 - val_loss: 0.6629 - val_acc: 0.9798 - val_mDice: 0.7829

Epoch 00246: val_mDice improved from 0.78263 to 0.78287, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 247/300
 - 18s - loss: 0.6775 - acc: 0.9683 - mDice: 0.7700 - val_loss: 0.6718 - val_acc: 0.9794 - val_mDice: 0.7802

Epoch 00247: val_mDice did not improve from 0.78287
Epoch 248/300
 - 18s - loss: 0.6765 - acc: 0.9683 - mDice: 0.7700 - val_loss: 0.6731 - val_acc: 0.9799 - val_mDice: 0.7797

Epoch 00248: val_mDice did not improve from 0.78287
Epoch 249/300
 - 19s - loss: 0.6754 - acc: 0.9683 - mDice: 0.7705 - val_loss: 0.6760 - val_acc: 0.9795 - val_mDice: 0.7793

Epoch 00249: val_mDice did not improve from 0.78287
Epoch 250/300
 - 18s - loss: 0.6772 - acc: 0.9683 - mDice: 0.7698 - val_loss: 0.6704 - val_acc: 0.9797 - val_mDice: 0.7792

Epoch 00250: val_mDice did not improve from 0.78287
Epoch 251/300
 - 18s - loss: 0.6756 - acc: 0.9683 - mDice: 0.7701 - val_loss: 0.6636 - val_acc: 0.9791 - val_mDice: 0.7801

Epoch 00251: val_mDice did not improve from 0.78287
Epoch 252/300
 - 18s - loss: 0.6749 - acc: 0.9683 - mDice: 0.7705 - val_loss: 0.6762 - val_acc: 0.9792 - val_mDice: 0.7798

Epoch 00252: val_mDice did not improve from 0.78287
Epoch 253/300
 - 18s - loss: 0.6759 - acc: 0.9683 - mDice: 0.7701 - val_loss: 0.6696 - val_acc: 0.9797 - val_mDice: 0.7800

Epoch 00253: val_mDice did not improve from 0.78287
Epoch 254/300
 - 19s - loss: 0.6762 - acc: 0.9683 - mDice: 0.7702 - val_loss: 0.6686 - val_acc: 0.9794 - val_mDice: 0.7823

Epoch 00254: val_mDice did not improve from 0.78287
Epoch 255/300
 - 18s - loss: 0.6765 - acc: 0.9683 - mDice: 0.7699 - val_loss: 0.6709 - val_acc: 0.9794 - val_mDice: 0.7813

Epoch 00255: val_mDice did not improve from 0.78287
Epoch 256/300
 - 18s - loss: 0.6751 - acc: 0.9683 - mDice: 0.7706 - val_loss: 0.6803 - val_acc: 0.9789 - val_mDice: 0.7814

Epoch 00256: val_mDice did not improve from 0.78287
Epoch 257/300
 - 17s - loss: 0.6752 - acc: 0.9684 - mDice: 0.7706 - val_loss: 0.6663 - val_acc: 0.9798 - val_mDice: 0.7805

Epoch 00257: val_mDice did not improve from 0.78287
Epoch 258/300
 - 18s - loss: 0.6749 - acc: 0.9684 - mDice: 0.7706 - val_loss: 0.6728 - val_acc: 0.9798 - val_mDice: 0.7805

Epoch 00258: val_mDice did not improve from 0.78287
Epoch 259/300
 - 19s - loss: 0.6720 - acc: 0.9684 - mDice: 0.7715 - val_loss: 0.6693 - val_acc: 0.9791 - val_mDice: 0.7826

Epoch 00259: val_mDice did not improve from 0.78287
Epoch 260/300
 - 18s - loss: 0.6718 - acc: 0.9684 - mDice: 0.7714 - val_loss: 0.6689 - val_acc: 0.9795 - val_mDice: 0.7815

Epoch 00260: val_mDice did not improve from 0.78287
Epoch 261/300
 - 18s - loss: 0.6732 - acc: 0.9684 - mDice: 0.7716 - val_loss: 0.6632 - val_acc: 0.9794 - val_mDice: 0.7822

Epoch 00261: val_mDice did not improve from 0.78287
Epoch 262/300
 - 17s - loss: 0.6727 - acc: 0.9684 - mDice: 0.7714 - val_loss: 0.6652 - val_acc: 0.9798 - val_mDice: 0.7831

Epoch 00262: val_mDice improved from 0.78287 to 0.78312, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 263/300
 - 18s - loss: 0.6730 - acc: 0.9684 - mDice: 0.7712 - val_loss: 0.6680 - val_acc: 0.9798 - val_mDice: 0.7817

Epoch 00263: val_mDice did not improve from 0.78312
Epoch 264/300
 - 19s - loss: 0.6737 - acc: 0.9684 - mDice: 0.7712 - val_loss: 0.6684 - val_acc: 0.9795 - val_mDice: 0.7813

Epoch 00264: val_mDice did not improve from 0.78312
Epoch 265/300
 - 18s - loss: 0.6708 - acc: 0.9684 - mDice: 0.7721 - val_loss: 0.6726 - val_acc: 0.9795 - val_mDice: 0.7812

Epoch 00265: val_mDice did not improve from 0.78312
Epoch 266/300
 - 18s - loss: 0.6716 - acc: 0.9684 - mDice: 0.7719 - val_loss: 0.6666 - val_acc: 0.9796 - val_mDice: 0.7803

Epoch 00266: val_mDice did not improve from 0.78312
Epoch 267/300
 - 19s - loss: 0.6716 - acc: 0.9685 - mDice: 0.7716 - val_loss: 0.6739 - val_acc: 0.9791 - val_mDice: 0.7821

Epoch 00267: val_mDice did not improve from 0.78312
Epoch 268/300
 - 18s - loss: 0.6722 - acc: 0.9684 - mDice: 0.7715 - val_loss: 0.6761 - val_acc: 0.9791 - val_mDice: 0.7794

Epoch 00268: val_mDice did not improve from 0.78312
Epoch 269/300
 - 17s - loss: 0.6730 - acc: 0.9684 - mDice: 0.7714 - val_loss: 0.6792 - val_acc: 0.9792 - val_mDice: 0.7809

Epoch 00269: val_mDice did not improve from 0.78312
Epoch 270/300
 - 18s - loss: 0.6730 - acc: 0.9684 - mDice: 0.7714 - val_loss: 0.6699 - val_acc: 0.9795 - val_mDice: 0.7793

Epoch 00270: val_mDice did not improve from 0.78312
Epoch 271/300
 - 19s - loss: 0.6710 - acc: 0.9685 - mDice: 0.7719 - val_loss: 0.6684 - val_acc: 0.9796 - val_mDice: 0.7817

Epoch 00271: val_mDice did not improve from 0.78312
Epoch 272/300
 - 18s - loss: 0.6700 - acc: 0.9685 - mDice: 0.7722 - val_loss: 0.6823 - val_acc: 0.9796 - val_mDice: 0.7819

Epoch 00272: val_mDice did not improve from 0.78312
Epoch 273/300
 - 17s - loss: 0.6693 - acc: 0.9685 - mDice: 0.7725 - val_loss: 0.6674 - val_acc: 0.9798 - val_mDice: 0.7812

Epoch 00273: val_mDice did not improve from 0.78312
Epoch 274/300
 - 18s - loss: 0.6705 - acc: 0.9685 - mDice: 0.7720 - val_loss: 0.6698 - val_acc: 0.9795 - val_mDice: 0.7822

Epoch 00274: val_mDice did not improve from 0.78312
Epoch 275/300
 - 18s - loss: 0.6697 - acc: 0.9685 - mDice: 0.7723 - val_loss: 0.6681 - val_acc: 0.9797 - val_mDice: 0.7805

Epoch 00275: val_mDice did not improve from 0.78312
Epoch 276/300
 - 19s - loss: 0.6686 - acc: 0.9685 - mDice: 0.7729 - val_loss: 0.6716 - val_acc: 0.9789 - val_mDice: 0.7809

Epoch 00276: val_mDice did not improve from 0.78312
Epoch 277/300
 - 18s - loss: 0.6696 - acc: 0.9685 - mDice: 0.7724 - val_loss: 0.6743 - val_acc: 0.9797 - val_mDice: 0.7802

Epoch 00277: val_mDice did not improve from 0.78312
Epoch 278/300
 - 18s - loss: 0.6687 - acc: 0.9685 - mDice: 0.7728 - val_loss: 0.6615 - val_acc: 0.9799 - val_mDice: 0.7834

Epoch 00278: val_mDice improved from 0.78312 to 0.78336, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 279/300
 - 17s - loss: 0.6689 - acc: 0.9686 - mDice: 0.7725 - val_loss: 0.6675 - val_acc: 0.9794 - val_mDice: 0.7825

Epoch 00279: val_mDice did not improve from 0.78336
Epoch 280/300
 - 18s - loss: 0.6692 - acc: 0.9685 - mDice: 0.7723 - val_loss: 0.6746 - val_acc: 0.9789 - val_mDice: 0.7805

Epoch 00280: val_mDice did not improve from 0.78336
Epoch 281/300
 - 19s - loss: 0.6700 - acc: 0.9686 - mDice: 0.7723 - val_loss: 0.6591 - val_acc: 0.9798 - val_mDice: 0.7836

Epoch 00281: val_mDice improved from 0.78336 to 0.78359, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 282/300
 - 18s - loss: 0.6674 - acc: 0.9686 - mDice: 0.7729 - val_loss: 0.6640 - val_acc: 0.9796 - val_mDice: 0.7820

Epoch 00282: val_mDice did not improve from 0.78359
Epoch 283/300
 - 18s - loss: 0.6685 - acc: 0.9686 - mDice: 0.7727 - val_loss: 0.6693 - val_acc: 0.9795 - val_mDice: 0.7814

Epoch 00283: val_mDice did not improve from 0.78359
Epoch 284/300
 - 18s - loss: 0.6667 - acc: 0.9686 - mDice: 0.7734 - val_loss: 0.6697 - val_acc: 0.9793 - val_mDice: 0.7824

Epoch 00284: val_mDice did not improve from 0.78359
Epoch 285/300
 - 17s - loss: 0.6679 - acc: 0.9686 - mDice: 0.7730 - val_loss: 0.6764 - val_acc: 0.9791 - val_mDice: 0.7820

Epoch 00285: val_mDice did not improve from 0.78359
Epoch 286/300
 - 19s - loss: 0.6664 - acc: 0.9686 - mDice: 0.7735 - val_loss: 0.6633 - val_acc: 0.9793 - val_mDice: 0.7820

Epoch 00286: val_mDice did not improve from 0.78359
Epoch 287/300
 - 18s - loss: 0.6700 - acc: 0.9685 - mDice: 0.7722 - val_loss: 0.6680 - val_acc: 0.9793 - val_mDice: 0.7832

Epoch 00287: val_mDice did not improve from 0.78359
Epoch 288/300
 - 18s - loss: 0.6663 - acc: 0.9686 - mDice: 0.7732 - val_loss: 0.6671 - val_acc: 0.9794 - val_mDice: 0.7832

Epoch 00288: val_mDice did not improve from 0.78359
Epoch 289/300
 - 18s - loss: 0.6660 - acc: 0.9686 - mDice: 0.7736 - val_loss: 0.6625 - val_acc: 0.9798 - val_mDice: 0.7844

Epoch 00289: val_mDice improved from 0.78359 to 0.78438, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 290/300
 - 18s - loss: 0.6663 - acc: 0.9686 - mDice: 0.7734 - val_loss: 0.6605 - val_acc: 0.9794 - val_mDice: 0.7840

Epoch 00290: val_mDice did not improve from 0.78438
Epoch 291/300
 - 18s - loss: 0.6678 - acc: 0.9686 - mDice: 0.7732 - val_loss: 0.6705 - val_acc: 0.9798 - val_mDice: 0.7856

Epoch 00291: val_mDice improved from 0.78438 to 0.78561, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 292/300
 - 19s - loss: 0.6657 - acc: 0.9686 - mDice: 0.7736 - val_loss: 0.6646 - val_acc: 0.9793 - val_mDice: 0.7824

Epoch 00292: val_mDice did not improve from 0.78561
Epoch 293/300
 - 18s - loss: 0.6677 - acc: 0.9686 - mDice: 0.7730 - val_loss: 0.6674 - val_acc: 0.9800 - val_mDice: 0.7843

Epoch 00293: val_mDice did not improve from 0.78561
Epoch 294/300
 - 19s - loss: 0.6655 - acc: 0.9686 - mDice: 0.7736 - val_loss: 0.6631 - val_acc: 0.9796 - val_mDice: 0.7845

Epoch 00294: val_mDice did not improve from 0.78561
Epoch 295/300
 - 19s - loss: 0.6660 - acc: 0.9687 - mDice: 0.7735 - val_loss: 0.6777 - val_acc: 0.9799 - val_mDice: 0.7823

Epoch 00295: val_mDice did not improve from 0.78561
Epoch 296/300
 - 18s - loss: 0.6667 - acc: 0.9686 - mDice: 0.7733 - val_loss: 0.6672 - val_acc: 0.9797 - val_mDice: 0.7841

Epoch 00296: val_mDice did not improve from 0.78561
Epoch 297/300
 - 20s - loss: 0.6656 - acc: 0.9687 - mDice: 0.7737 - val_loss: 0.6785 - val_acc: 0.9799 - val_mDice: 0.7818

Epoch 00297: val_mDice did not improve from 0.78561
Epoch 298/300
 - 18s - loss: 0.6648 - acc: 0.9686 - mDice: 0.7739 - val_loss: 0.6609 - val_acc: 0.9801 - val_mDice: 0.7824

Epoch 00298: val_mDice did not improve from 0.78561
Epoch 299/300
 - 20s - loss: 0.6649 - acc: 0.9687 - mDice: 0.7743 - val_loss: 0.6633 - val_acc: 0.9795 - val_mDice: 0.7844

Epoch 00299: val_mDice did not improve from 0.78561
Epoch 300/300
 - 18s - loss: 0.6628 - acc: 0.9687 - mDice: 0.7746 - val_loss: 0.6740 - val_acc: 0.9794 - val_mDice: 0.7787

Epoch 00300: val_mDice did not improve from 0.78561
{'val_loss': [5.663280098405603, 4.139637788681135, 2.7769381314107817, 2.361591745729316, 1.7674513320400291, 1.5402595262004906, 1.2385653690116045, 1.1182057971823705, 1.0817440601244366, 0.9802286996416849, 0.9674357290137304, 0.9355940067604797, 0.9032094948095818, 0.8901313506577113, 0.8795509138335921, 0.8828343859274094, 0.8411192412245764, 0.8393025026745993, 0.8136949384049194, 0.8239824702478435, 0.8289378334398139, 0.815319105778655, 0.7909661800894019, 0.7872337262107901, 0.7764436418879522, 0.7833886244525649, 0.7834576547962345, 0.781551428445398, 0.7828093252769889, 0.7660004178138629, 0.7602649910809243, 0.758214387991657, 0.7528418718952022, 0.7536982902108806, 0.7379492292665455, 0.7530382508284426, 0.7466983897228764, 0.7512846536015811, 0.735981038580202, 0.7430556914577745, 0.7320447445732273, 0.7315676355198638, 0.7338476662766443, 0.7421304359011454, 0.7443917116073713, 0.7298616032077841, 0.7234736783047245, 0.7343332620516215, 0.7262484516999493, 0.7168438124330077, 0.7264491809557562, 0.7267886110364574, 0.7205417854328678, 0.7252396773802091, 0.7275570978040564, 0.715001743950256, 0.7336964354123154, 0.7158729593231253, 0.7205256913622765, 0.7160221272951937, 0.7189782208775821, 0.704852965188353, 0.7154613059677489, 0.7063389612387304, 0.7092149290319991, 0.7127654732090153, 0.7072136610338132, 0.7127315504093693, 0.7203692899991389, 0.7092047027529103, 0.716377753917485, 0.7094653297777045, 0.694531939617575, 0.7081120459184255, 0.7264289570181337, 0.6944981939988594, 0.7005360853182127, 0.7052101260178709, 0.6908767002902619, 0.6997887479932341, 0.7023196146912771, 0.7155616577357462, 0.6993230189362617, 0.7037527414217387, 0.7001797695682473, 0.7034511243643826, 0.7011341403608453, 0.6989277466519238, 0.7005360808274518, 0.7024696808155269, 0.7076100564166291, 0.6976404312538774, 0.6927855251586601, 0.6966895318194611, 0.7102249991403867, 0.6981433748382412, 0.6931141843534496, 0.7046780071846427, 0.6895817959145324, 0.6870978519524613, 0.7042298047509912, 0.7046052025605555, 0.6897886179081382, 0.6881133064831773, 0.6930568593822114, 0.697892914487891, 0.697678609253609, 0.6886275206526665, 0.6937099711535728, 0.6913247663680822, 0.7094675224937804, 0.6965550184249878, 0.693448300639244, 0.690512384045614, 0.6958397251285918, 0.6946371352835877, 0.692850457070625, 0.685800360081947, 0.6912543046964358, 0.6932707526912428, 0.7042370961137014, 0.6905236138056402, 0.6958462489794378, 0.7023588949686861, 0.6886741400581516, 0.6926854661066238, 0.6874748435738969, 0.6921112365918617, 0.6935410568975422, 0.6923096571883111, 0.7089658069283995, 0.6947573031464668, 0.6857592171593888, 0.6963532346568696, 0.6902625148426996, 0.7006116386962263, 0.6834682299666208, 0.7001092168566299, 0.6886841205701436, 0.6908708263749945, 0.7003899192156857, 0.692987227684831, 0.6865716172407751, 0.6864313924149291, 0.6837972933298921, 0.6908977325648478, 0.6844622717328268, 0.6775231271573942, 0.6878736758068816, 0.7012664234801514, 0.6802565475849256, 0.6918937225047856, 0.6823841125181277, 0.6755009095554483, 0.6795521288701932, 0.6942059442605057, 0.6940936846275853, 0.6757822004083085, 0.6887095439923953, 0.686138391903002, 0.6799003138934097, 0.6829981440550661, 0.68780458708332, 0.6800928585333367, 0.6939247275052005, 0.6881215443758115, 0.6875647134976844, 0.6904931962490082, 0.6823082394795875, 0.6888349672702894, 0.6883789892882517, 0.6799961446899258, 0.6951810819645451, 0.6881086136380287, 0.6771685350431155, 0.680461487133209, 0.6886752517256018, 0.6851809494299431, 0.6818539739063342, 0.6785584512638719, 0.6803131866944979, 0.6806812494584958, 0.6828264324632409, 0.6818841771311956, 0.6871432592607525, 0.6826001924194701, 0.6916327766359669, 0.6840146306442888, 0.6815404724584867, 0.6884793402397469, 0.6893369555473328, 0.6788787229420388, 0.6754818074915507, 0.672456974852575, 0.6871257673387658, 0.6730645841931644, 0.6870626235661441, 0.676396344418395, 0.6806879174219419, 0.6794963593352331, 0.6764510661771853, 0.6717590977476068, 0.6822813373722442, 0.6762194872310717, 0.6868697249726073, 0.6841148182953873, 0.6779117069832267, 0.6758231494116457, 0.6746825861604246, 0.6830328423274706, 0.6802247532018243, 0.6794126288939829, 0.6754277675119165, 0.6850528514956775, 0.6718618935101652, 0.68163561045307, 0.6732329371040815, 0.6736491653200698, 0.6711677549636528, 0.6745616056739467, 0.6772552814385663, 0.6690773108642395, 0.6887284505040678, 0.6901253923161389, 0.669508939328259, 0.6845304602629518, 0.6808715938297036, 0.6838588753383453, 0.6714137886485009, 0.6690414323382181, 0.6741547282427958, 0.6712075198349887, 0.672843437897016, 0.6716761305315854, 0.6843424000560421, 0.6737047599194801, 0.6683600945015477, 0.6754097179190753, 0.6708024499351031, 0.6662199862607537, 0.6754764228650968, 0.6738993558165145, 0.6802146879777516, 0.6779708639807898, 0.6847619473525922, 0.6628932420113315, 0.6718160614167175, 0.6730829918221252, 0.675999690408576, 0.6704310058322671, 0.6636347962568884, 0.6762317582352521, 0.6696018668478483, 0.6685602595544842, 0.6709305944099818, 0.680301210243408, 0.6663033825485674, 0.6727980910098716, 0.6693105903798586, 0.6688919316415918, 0.6632120774625099, 0.665216961135603, 0.6680258818685192, 0.6683883752724896, 0.6725721281685241, 0.6665878875614846, 0.673881323370215, 0.676083895033353, 0.6792346916786612, 0.6699388008819868, 0.6683835460715097, 0.6823002467416737, 0.6673522518105703, 0.6697552894076256, 0.6680532012083759, 0.6715682263243689, 0.6742690038191129, 0.6614949201067833, 0.6675027325137021, 0.6745862093282072, 0.6590849308118428, 0.6639611863926665, 0.6692772713834292, 0.6696534038406529, 0.6764264849767293, 0.6632740460846522, 0.6679820873557705, 0.6670961406541197, 0.6625362706102736, 0.660544825130946, 0.670536854495741, 0.6645889069936047, 0.6673806762858613, 0.6631157275748579, 0.6777481308130369, 0.6671662204069634, 0.6785102627457005, 0.6608901868944299, 0.6632637808175936, 0.6739703651568661], 'val_acc': [0.9134473159705123, 0.9134480446985324, 0.9187004186519204, 0.9194000485825212, 0.9457151101876612, 0.9524916238980751, 0.961880671243145, 0.9680012048107304, 0.9675975250054712, 0.9713847371813369, 0.9717585787381211, 0.973364626299845, 0.973803996223293, 0.97399619915714, 0.9748356199427827, 0.9750285295590962, 0.9737340877317402, 0.973924115096053, 0.9745909971733616, 0.9749743052541393, 0.9736714930567023, 0.9755833144873789, 0.9755195865075882, 0.9756160562169062, 0.9761966683276712, 0.9763946900629017, 0.9760459526760937, 0.9752502245445774, 0.9759232891749029, 0.9766545997907038, 0.9762785638848396, 0.9762345164606016, 0.9767517978197908, 0.9770855968945646, 0.9770910617423384, 0.9769607325122781, 0.9762876760469724, 0.9769771119503126, 0.97717148882069, 0.9774922014099278, 0.9774132105585647, 0.9766767980301216, 0.9775937518028364, 0.9776432587675852, 0.9778201816833183, 0.9776469146552151, 0.9778376421699785, 0.9776247037600164, 0.9780706281531347, 0.9778463864979678, 0.9776163203259037, 0.977942850900023, 0.978318505907712, 0.9777320852018383, 0.9780957376303738, 0.9785092603670408, 0.9783960535918197, 0.9784488339130193, 0.9779402976983214, 0.9782904925411695, 0.9785019788023543, 0.9782839282734753, 0.9782467913137723, 0.978492161182508, 0.9788565313162869, 0.9782289670754786, 0.978354178062857, 0.9784717563896963, 0.9781805456501164, 0.9788641782656108, 0.9785460111213057, 0.9781095679492167, 0.979258755706761, 0.9785798653347851, 0.978759327979937, 0.978942433856938, 0.978855794423247, 0.9781958366910072, 0.9789133075981924, 0.9781827228526546, 0.9781448783939832, 0.9782333386270967, 0.9784994325409196, 0.9780232992074261, 0.9786140853411531, 0.9785591265926622, 0.9785077992367418, 0.9786180837513649, 0.9784015082333186, 0.9786173664543727, 0.9788011937108758, 0.978805566078996, 0.9789700895956118, 0.9788255769096009, 0.9776137822294888, 0.9785591123038775, 0.9791506475781742, 0.9789955885442969, 0.9787043594334224, 0.9795830882575414, 0.9783097746437543, 0.9789668223629259, 0.9788485116338077, 0.9785066965508135, 0.9787323932125144, 0.9790822124644502, 0.9791273523683417, 0.9793879834756459, 0.9793494013074326, 0.978852148333641, 0.9779941802971983, 0.9790836686957373, 0.9791866838932037, 0.9791637499854989, 0.9786621434231327, 0.9786210088697198, 0.978669773225915, 0.97862464842731, 0.9785864332767382, 0.9784524755118644, 0.978956990046044, 0.9793956296084678, 0.9782493498227368, 0.978596620363732, 0.9788772798564336, 0.9788659949825235, 0.9794509704798868, 0.9789176795580615, 0.9793217386284919, 0.978722919340003, 0.9791888692607619, 0.978936983297949, 0.9793082692035256, 0.9789125805031763, 0.9786759692512147, 0.977958866586424, 0.9793344772841832, 0.9783327020194432, 0.9787120051579933, 0.9785656843283405, 0.9780225590483783, 0.978715282188703, 0.9790702086605437, 0.9792205364736792, 0.97849469397166, 0.9785394856374557, 0.9794640659469448, 0.9795448767812285, 0.9792842371006535, 0.9788958450702772, 0.9795226740510496, 0.979084406405279, 0.9790028635769674, 0.979366512739495, 0.9793086300974023, 0.9788619737102561, 0.9784976076589872, 0.9794662517227538, 0.9792671428151327, 0.9788132171108298, 0.9792431107122604, 0.9789934060344957, 0.978335976600647, 0.978916586670157, 0.9782682800129668, 0.979319545504165, 0.9788863662987539, 0.9789548054949878, 0.9796624522503108, 0.9790399866561367, 0.9792285504406446, 0.9789318748532909, 0.9783312568109329, 0.9787633361881727, 0.9793464908861134, 0.979317743484288, 0.9783774700066815, 0.9785074338521043, 0.9792573068239917, 0.9789970390600701, 0.9792121787593789, 0.978878722615438, 0.9790909494439216, 0.9790607392787933, 0.9781787399559805, 0.9789173100909142, 0.9785634940617705, 0.978864894746101, 0.9787957488674007, 0.9790902317386784, 0.978931140001506, 0.9788856490017617, 0.979080026688641, 0.9792325582406293, 0.9791553787989159, 0.9792824175259839, 0.9784164257245521, 0.9790185228602527, 0.9796169559433036, 0.9796107648170158, 0.9790851281930323, 0.9796031199089469, 0.9791477302165881, 0.9794870096526734, 0.9787225580378754, 0.9794917351579013, 0.9783378092393483, 0.9792521991958357, 0.9788645318109696, 0.9788237634586961, 0.9789712004465599, 0.9792336445965178, 0.9787833600828092, 0.9788343134808214, 0.9788073885114226, 0.9792809719092226, 0.9797261626753089, 0.9793996361836995, 0.979586372228518, 0.9789963070660421, 0.979301343225453, 0.9795896521169846, 0.9797538233129945, 0.9792638592524071, 0.97957035776687, 0.9794585982414141, 0.9783898694057988, 0.9793585212263343, 0.9791127782161921, 0.9791710384904522, 0.9797236139643682, 0.9791630281977457, 0.9794065478729875, 0.9792223687041296, 0.9795059378016485, 0.9789122204258017, 0.9798324500044732, 0.9795426893724154, 0.9795736425543484, 0.9790556418569121, 0.9796344323517525, 0.978960641034662, 0.9789012968540192, 0.979689749952865, 0.9793781548330228, 0.9798451907014194, 0.9793595912521833, 0.9798655767146855, 0.9794640573736739, 0.9796985044871291, 0.9790953209955399, 0.979193241628882, 0.9796573601356925, 0.9794378509260204, 0.9793836311118244, 0.9789464408404207, 0.979760370025896, 0.9797585582079953, 0.9791389960948735, 0.9794578817609239, 0.9793654084205627, 0.9797618372799599, 0.9798211659470649, 0.9795022774232577, 0.9794637066860722, 0.9796184060508257, 0.979143010426874, 0.9790818499375696, 0.9792245675439704, 0.9795164817000088, 0.9795714543290335, 0.9796082026337924, 0.9797607415342984, 0.9795477859777947, 0.9796551853826602, 0.978897654438672, 0.9796555417857759, 0.9799179851192318, 0.9794233020854323, 0.978897651989166, 0.9797570999354532, 0.9795550683589831, 0.9795397707860763, 0.979251844833975, 0.9791440853517349, 0.9793464990511332, 0.9793133609098931, 0.9793672308529893, 0.9798342675378878, 0.97944259357779, 0.9798309900989272, 0.9793472159398745, 0.980034497502732, 0.9796413358760206, 0.9799365552320872, 0.979713064758745, 0.9799059686595446, 0.9800592317973098, 0.9794779023895525, 0.9793894511379607], 'val_mDice': [0.006863864132343498, 0.03714353292670152, 0.14344791874085386, 0.22316508689155318, 0.3759679369730492, 0.4509526907581173, 0.5431341696275424, 0.5882786981863518, 0.6167396098783572, 0.6518877748757193, 0.6565497995239414, 0.6657573074510653, 0.6811130830686386, 0.6898677536886032, 0.6948287780970743, 0.6993257660571843, 0.7086565698662849, 0.711269055327324, 0.7156768420787707, 0.7156590402942814, 0.7161200389470139, 0.7186183006796119, 0.7275443101582462, 0.730737467334695, 0.7290859120349361, 0.7301083084655134, 0.7290772473158902, 0.7318087873393542, 0.7377379063057573, 0.739014495725501, 0.7390726800650766, 0.7407400893838438, 0.7427737320939155, 0.7450493027086127, 0.7430215902524452, 0.7458075868756804, 0.7502495221895714, 0.7445470090598276, 0.7511440691066115, 0.7486959495773055, 0.748243263323013, 0.7544074140182914, 0.7452654736499263, 0.7536154532269256, 0.7454676656690362, 0.7523377545892376, 0.7531449774356738, 0.7512659977560174, 0.7528146435953167, 0.7571744208466517, 0.7568603770373619, 0.7532826592660931, 0.7586161379944788, 0.7544771616589533, 0.7561106877784206, 0.7575768473213667, 0.7560671396451454, 0.7567013979774632, 0.7607653251249497, 0.7589833842564936, 0.7546531692759632, 0.7571479882279487, 0.7599138168439473, 0.7623345909053332, 0.7598052502494969, 0.7599477947574772, 0.761660588930731, 0.759402482068702, 0.760382838445167, 0.758139678060192, 0.7600093855433268, 0.7585742044938754, 0.7623485583965093, 0.7585967685261817, 0.7583092402105462, 0.7626659192451058, 0.7607372268422009, 0.7629524604098438, 0.7677019083336608, 0.760534307319824, 0.7655454510695314, 0.7622037121694382, 0.7668415512124153, 0.7641205440645349, 0.7635123031596615, 0.7667034717455302, 0.7655823732892127, 0.7652354460873015, 0.7645712996998878, 0.7670759166756721, 0.7646368778731725, 0.7612030257100928, 0.7649620877553339, 0.7660503905929931, 0.7685846469990195, 0.7651765260794391, 0.7649841688267173, 0.7667906268002236, 0.7684257802081434, 0.7680634680676134, 0.7689138005857599, 0.7644055502055442, 0.7672674345643553, 0.7694707900693972, 0.7693176943145387, 0.7663540003234393, 0.7663149609141153, 0.7655104982526335, 0.769115195698934, 0.7648141098349062, 0.7643122346433875, 0.7689882055537341, 0.7682516480961891, 0.764473169225536, 0.7687348204932801, 0.7670546908901162, 0.7671890997723357, 0.7683307977571879, 0.7655750990730442, 0.7702888078885536, 0.7671500330101954, 0.7682096076338258, 0.7700781928349848, 0.7642288089615025, 0.7700227237727544, 0.7682561511046266, 0.7693821485728434, 0.7710025261526239, 0.7647904819005156, 0.7708707958051603, 0.7656263533520372, 0.7693649081334676, 0.7692470619939777, 0.7685254759167972, 0.7715314479723369, 0.7677314481506609, 0.7701166435463788, 0.7675076347507842, 0.7729562014749606, 0.7726703567864144, 0.7717480218573792, 0.7721174147031079, 0.7707842441454326, 0.7737147142625835, 0.7724436162269279, 0.773871998672616, 0.7737312602670225, 0.7720605861650754, 0.7706903905084689, 0.775635691129998, 0.7722336176323564, 0.7718856220376001, 0.773982188473009, 0.7741684868727645, 0.7749787360838015, 0.7729401184271459, 0.7710823914776109, 0.7745642551820572, 0.7686303449820165, 0.7757948935031891, 0.7743161083900765, 0.7735241226954003, 0.773424404124691, 0.7741344183275144, 0.773253857272945, 0.7757376612049259, 0.7734303588736547, 0.7733629794969951, 0.773010399243603, 0.7707800122156535, 0.7702221286623445, 0.7727144180911861, 0.7732138576572889, 0.7751280469437168, 0.7753533386204341, 0.7724534052692048, 0.7752965525405048, 0.7754164648382631, 0.7760718272973414, 0.7714882493019104, 0.7752454778919481, 0.7729188322204433, 0.7763180495941475, 0.7776466746852823, 0.7751021577070837, 0.7743648629482478, 0.7738116371305022, 0.7725986426007257, 0.7741640557165015, 0.7744211987273334, 0.7762005733300562, 0.77693377904696, 0.7713456268179907, 0.7791629886790498, 0.7736504179974125, 0.7799149404649866, 0.7760294247163485, 0.7752650122936457, 0.7761971464712326, 0.7748519321010537, 0.7772586860068856, 0.7791946085348521, 0.7762636060584082, 0.7775777390558426, 0.7781093279792838, 0.777762966204996, 0.7799079491667551, 0.7777230306847455, 0.7783989326594627, 0.7800543863479406, 0.7768091551245075, 0.7796945139153363, 0.7784174852175255, 0.7777163933401239, 0.7765592459129961, 0.7768843516911546, 0.7777512028609237, 0.7787622384829064, 0.7800659214797085, 0.7784451217684027, 0.7792477195393549, 0.7769258312166554, 0.77546791834374, 0.7786365829101981, 0.7826317148665859, 0.7753256653269677, 0.7795136297402316, 0.7752314287505738, 0.7787337886960539, 0.7800035860440503, 0.7782970164736657, 0.7775662418914168, 0.7794032349978408, 0.7778524895236917, 0.7792083743500383, 0.7794443458726962, 0.7789600226160598, 0.7809816913245475, 0.7801172843534653, 0.7815659940242767, 0.7820488647238849, 0.7807101423609747, 0.7797337398953634, 0.7814524573822544, 0.7774367442686264, 0.7828659880651186, 0.7801539081416718, 0.779715849112158, 0.7793029522242612, 0.7792027400781031, 0.7801125474172096, 0.7797768079254725, 0.7800008327993628, 0.7822742870409195, 0.781267374345701, 0.7813644543902515, 0.7804794940229964, 0.7805030427566947, 0.7826203303794338, 0.7815007751118647, 0.7822456751784234, 0.7831151024119495, 0.7816630246704572, 0.7812895109392193, 0.7812129348924716, 0.7802959590742032, 0.7820668898216666, 0.7794125729227719, 0.780942922585631, 0.7793432992615111, 0.7817063282613885, 0.7819257603116232, 0.7811755836009979, 0.7822449309368656, 0.7805233393629937, 0.7809022501723407, 0.7802374905919376, 0.7833570560363874, 0.782537484413957, 0.7805436531158343, 0.7835859097030065, 0.7819853363788292, 0.7813723609872061, 0.7823949007138814, 0.7820460984151657, 0.7820436350286823, 0.7831944815100056, 0.7832375021829997, 0.784375009471423, 0.7839981472655518, 0.7856121687856439, 0.7824445583232461, 0.7842524337441954, 0.7845338313546899, 0.7822735476983737, 0.784135928300962, 0.7818084302013868, 0.7824373763718017, 0.7843561115330213, 0.7787305279953839], 'loss': [46.344898201929894, 5.7704307401236, 4.300353125845865, 3.449579241517205, 2.8463411313825944, 2.4521851127213976, 2.1559989955305876, 1.9472221003549002, 1.7931308297198838, 1.6649257910987592, 1.5704761757880064, 1.4997887111346724, 1.441918143137799, 1.391365970819621, 1.340812771321722, 1.298585893065161, 1.2628512710047042, 1.2339141789537045, 1.1995234902126024, 1.170669935299314, 1.144818320418675, 1.1263209881595924, 1.1048332497731044, 1.0858791395134912, 1.0662172105784726, 1.0516604330417443, 1.0386824223517084, 1.0178426270014038, 1.0035981596797408, 0.9914392126750426, 0.9812999925295574, 0.9692685164048348, 0.951981281448809, 0.9484611061735208, 0.9375151817373691, 0.9317016473356066, 0.9241624906888221, 0.9168437106364364, 0.9088203463734096, 0.9025461779349603, 0.8948445381733404, 0.888688527585179, 0.8848880912055221, 0.8771628263490885, 0.8737558368599738, 0.8682253919177368, 0.8653413984978238, 0.8595101197051211, 0.8541307712604962, 0.8492953217002569, 0.8499051161967529, 0.8429048038518907, 0.8406159221505515, 0.8357320261079723, 0.8325820067666101, 0.8269056867887281, 0.8229761574922042, 0.8225802815938905, 0.8204650137302554, 0.8163489484015393, 0.8149680503248117, 0.8089976151599454, 0.8094197423051677, 0.805073670411295, 0.8018316983547525, 0.8006655280417928, 0.7997576578984037, 0.7973235043923684, 0.7924063185509891, 0.7914314208602243, 0.789272079159423, 0.7881259795493221, 0.7860736900613684, 0.7830976911010877, 0.7847264968557205, 0.7817275263661735, 0.7791593331254542, 0.7779971301840026, 0.775439608013195, 0.7746735453588416, 0.7719024521648766, 0.7740314664786233, 0.7670701404721876, 0.7709473660939733, 0.7677439479944166, 0.7663082401432688, 0.7650850090806907, 0.7625063170673841, 0.7619353516029217, 0.7590834380985829, 0.7606708032793927, 0.7599835150718367, 0.7594370016336867, 0.755784229994613, 0.7540666625608197, 0.753915004465596, 0.7532138847573372, 0.7526758248529996, 0.7501912677501781, 0.7532477657980755, 0.7494627294758612, 0.7475610771571718, 0.7461888237389388, 0.746504462812658, 0.7455006377861536, 0.744680069087126, 0.7430970175975007, 0.7428651817666864, 0.7423541446086372, 0.7428487105420472, 0.7412817028006724, 0.7393734065002576, 0.7404335654438579, 0.7384717521311157, 0.7370947606190468, 0.736681053873039, 0.735931742467951, 0.733744158637777, 0.733535370641033, 0.7334881856505385, 0.73255061994398, 0.7301040497410584, 0.7299919151470997, 0.7303934121219225, 0.730246940317358, 0.7295952700633268, 0.7303143800930882, 0.7291064059494765, 0.7273635605230832, 0.7260161898608288, 0.7266970725296561, 0.7262787241003037, 0.7252354683965204, 0.7230280748453075, 0.7232009093958738, 0.7224561162506611, 0.7232763897186819, 0.7226118265238088, 0.7219494950013526, 0.7187063497726335, 0.7199167934844187, 0.7199428222775086, 0.7188954896622723, 0.7185095518136566, 0.7191543321410365, 0.718743144042452, 0.7173739407710485, 0.7158773639723907, 0.715576499624421, 0.7159549494704095, 0.7139708060024158, 0.7152040654222352, 0.7122392394587622, 0.7142086290492742, 0.7118294346107908, 0.7117963649992874, 0.7117364173312033, 0.7110815385682502, 0.710931745483086, 0.70946696763171, 0.7102788672317246, 0.7105358858497248, 0.7102484332175937, 0.7077894395857273, 0.7084531784273066, 0.7064291372894522, 0.7064723103981407, 0.7076258528283708, 0.7063730501647145, 0.7063572048218809, 0.7068705947748224, 0.7028732829923785, 0.7046704557069646, 0.7036867942245411, 0.7032861709537274, 0.7029046957145467, 0.7039079442760319, 0.7021701760614135, 0.7032635241504164, 0.7017510817897676, 0.7021044375862097, 0.7004950491513015, 0.701426023343677, 0.6997103044337966, 0.6988908687515876, 0.6989850340346163, 0.6995157311666936, 0.6991314167180425, 0.6987176665590897, 0.696951209392839, 0.694431425176521, 0.6964817811402421, 0.6962866471430682, 0.6949901674272262, 0.6952919291886337, 0.6957730852590652, 0.692761808389629, 0.6934818428328793, 0.692392933370981, 0.6922888785171201, 0.6926139477629438, 0.691365005131302, 0.6917077726533921, 0.6915831859958989, 0.6905983056187417, 0.6906096766159227, 0.6890241362079436, 0.6897710176371765, 0.6876464409824509, 0.6891535705351256, 0.6889341794928561, 0.6877273994659228, 0.6865608299951724, 0.6863086239516784, 0.6886570308273272, 0.6867744909122114, 0.6874467710729587, 0.6866217894742929, 0.6856735132146649, 0.6848310573361651, 0.68492277286657, 0.684147556032972, 0.6840741757390194, 0.6830297598359533, 0.684155439313874, 0.6836033256288103, 0.6829773348017459, 0.6830329040764809, 0.6831797660201467, 0.6824459684223168, 0.6813430255410459, 0.6813623935703806, 0.6799577841144441, 0.6825629391809953, 0.6807973534292506, 0.6796472372276317, 0.6800338583723011, 0.6789294156208229, 0.6801286596890858, 0.679475245876389, 0.6789265246591003, 0.6793822779288446, 0.6784016586000979, 0.6765174710441483, 0.6764763157145592, 0.6753390485596683, 0.6774587040177552, 0.6765209355709484, 0.6753737225225848, 0.6771949146981928, 0.6755955377910975, 0.6748814620858612, 0.675856964948051, 0.6762030241437588, 0.6764676377189447, 0.6750846501746645, 0.6752368540004096, 0.674941606181542, 0.6719866942351649, 0.6717832057445824, 0.6732183244422094, 0.6726662834596447, 0.6730253367293249, 0.6736560492631849, 0.6707683795963151, 0.6715727924591053, 0.6715889631598776, 0.6721680662612914, 0.672974095590902, 0.6730002152488297, 0.6709510418135113, 0.6699625625858089, 0.6693297617377657, 0.6704686488037862, 0.6697064823782917, 0.6686442886767856, 0.6695586250063207, 0.6687342036163395, 0.6688824976672378, 0.6692073062730873, 0.6700163459891589, 0.6674273883103118, 0.6684503048964309, 0.6666962191282257, 0.667902959106089, 0.6664287294515432, 0.6699536067760734, 0.6663361515511753, 0.6660024237173702, 0.6662699350437904, 0.6677519551782334, 0.6656915219546893, 0.6676638265797429, 0.6654680724117898, 0.6659571639118014, 0.6667071929253281, 0.6655885112277571, 0.6647863759136273, 0.6649464705394397, 0.6627559635207029], 'acc': [0.7477909546469176, 0.8961977806170134, 0.904203879930317, 0.912995182233774, 0.921579472808598, 0.9292126656342738, 0.9355771252434365, 0.9406736008034734, 0.9445481933888553, 0.9474775720299902, 0.9495149623877146, 0.9510364083963634, 0.9523064077138912, 0.9533686870477005, 0.9544335799284099, 0.9552814089463093, 0.9560379475345094, 0.9566290055627081, 0.9573503234419882, 0.9578747421702716, 0.9583814775715668, 0.9587054486400887, 0.959134669716177, 0.9594956213430909, 0.9598079155718506, 0.9600453541171862, 0.9603460837923835, 0.9607349841863232, 0.9609876594300316, 0.9611383112167828, 0.9614609640629023, 0.9617830912741335, 0.9622254686715477, 0.9622360588504674, 0.9625819182159229, 0.9627005216948836, 0.9628359701720897, 0.9630002866475471, 0.9631658646392676, 0.9633334284891846, 0.9634542366936555, 0.9635448296608204, 0.9636234819007164, 0.9637704029692944, 0.9638062537598365, 0.9639735216720747, 0.9639498161932918, 0.9641105976154836, 0.9642167003552674, 0.9642623644247648, 0.964272098955726, 0.9644070821754317, 0.964453003298398, 0.9645544660080484, 0.9645822499566977, 0.9647388247485517, 0.9647651044074194, 0.9647277182306437, 0.964792520780208, 0.9648920448149616, 0.9649306844042504, 0.9649973499400913, 0.9649695523377297, 0.9650257600290849, 0.9650895491388196, 0.9650684450412579, 0.9650793973351278, 0.9651656637703564, 0.9652928209826483, 0.9653421040098146, 0.9653855124274371, 0.965340186308146, 0.9654408387060228, 0.9654982547408627, 0.9654609095596958, 0.9655191039049721, 0.9655772588891784, 0.9656075152312539, 0.9657127267539091, 0.9657033830127048, 0.9657574078221913, 0.9656818773644339, 0.9658579979036405, 0.965827095976243, 0.9658030806676389, 0.9658936328690071, 0.965882714136324, 0.9659594621472867, 0.9660019871815009, 0.9660579093830104, 0.9660396606550199, 0.9660150828381735, 0.9660923441689677, 0.9661401501821779, 0.9661723402754255, 0.9662130778884593, 0.9662744778168622, 0.96620905119239, 0.9663075219235298, 0.9662956685650819, 0.9663295784371865, 0.9664056721902926, 0.9664088491618108, 0.9664966323167837, 0.9664069542115415, 0.9664862138563491, 0.9665428512302892, 0.9665270932605855, 0.9665213077693073, 0.9665781372403218, 0.9665842317915507, 0.9666180032851627, 0.9666465078068271, 0.9667145470646963, 0.9667046194053787, 0.9667550372102989, 0.9668081186898869, 0.9668109988820393, 0.9668022384384557, 0.9668225649638523, 0.9668505368959392, 0.9669117321450542, 0.9669160553217336, 0.966936527444596, 0.9669130437287591, 0.9669341488920744, 0.9669291307951572, 0.9669431120787789, 0.9669827438359134, 0.9669785844463286, 0.9670235754162485, 0.9669877040919939, 0.9670502829393126, 0.9671248599008581, 0.9671505467392656, 0.9671430663089475, 0.9671155773442569, 0.9671346948510957, 0.9671434682905544, 0.9671942773506012, 0.9671814259353722, 0.9672455937323832, 0.9672223175368865, 0.9672090074683828, 0.9672158288751156, 0.9672466382830279, 0.9672737599418872, 0.9672796606724506, 0.9672961856458346, 0.967288892839873, 0.9673138382354526, 0.9672965239551223, 0.9673619618949686, 0.9673697054831399, 0.9673879671610431, 0.9674178818644279, 0.9674140507585773, 0.9674090688886674, 0.9674286405530813, 0.9674379955349707, 0.967433321822999, 0.9674084352507029, 0.9674378503770207, 0.9674528723188444, 0.9674390079205373, 0.9675319146245892, 0.967561454964038, 0.9674954850005267, 0.96752106634081, 0.9675327333503588, 0.9675220805102931, 0.9675709315222817, 0.9675923021817886, 0.9676015651325437, 0.9676217475485082, 0.9676103235164363, 0.967592312621004, 0.9675733901126177, 0.9675763706551028, 0.9675833592788761, 0.967598400364049, 0.9676354283010812, 0.9675828487684976, 0.9676602320778174, 0.9676947151386822, 0.9676784580429179, 0.9676814999481105, 0.967649207278225, 0.9676545345499991, 0.9676752089678485, 0.9677550627746446, 0.9677485283285551, 0.9677243497642967, 0.9677791622806626, 0.9677332719266659, 0.9677710386665593, 0.9677801139326324, 0.9678033532289213, 0.9678187316811523, 0.967835094562306, 0.9678229491385134, 0.9678516284322916, 0.9678044384994003, 0.9677943699307842, 0.9678719249470986, 0.9678300420854964, 0.9678891979416823, 0.9678936256713836, 0.9678818238712839, 0.9678683399269337, 0.9678445993529681, 0.9679189831545579, 0.9679755074695551, 0.9678864231241302, 0.9679270543140459, 0.967978600140244, 0.9679396277284317, 0.9678969342563002, 0.9679705798238138, 0.9679470665311577, 0.9679717982991402, 0.9680419881301671, 0.968020301895536, 0.968006304263655, 0.9680167359670125, 0.9680300933538307, 0.9680225553153606, 0.9680675972116454, 0.9680693388427618, 0.9680429256027294, 0.9680892631395035, 0.9680791113731563, 0.9681125202232501, 0.9681118659194311, 0.96807939635167, 0.9681611477372112, 0.9681536155733133, 0.968140420686642, 0.9681337929856686, 0.9681757979694289, 0.9681859438497133, 0.9681684909093707, 0.9681942808041487, 0.9682008573805443, 0.9682127543946761, 0.968254022505997, 0.9682597099278276, 0.9683015512853618, 0.9682894395232988, 0.9682605994357287, 0.9682880386633324, 0.9682887576132994, 0.9682958772385963, 0.9682755792415012, 0.9683027510482367, 0.9683163875160151, 0.9683620203425554, 0.9683559551153523, 0.968378689850524, 0.9684237415224416, 0.9684176775505873, 0.9683989037450029, 0.968393557335625, 0.9684066823910125, 0.9684440095836361, 0.9684184035586589, 0.9684558207485795, 0.9684229829959556, 0.9684016621482247, 0.9684365554984044, 0.9684643234866023, 0.9685115746127145, 0.9684953563753063, 0.9684770481403411, 0.9684825509540994, 0.9685103587515009, 0.9685167371695275, 0.968544743093699, 0.9685587750451468, 0.9685471794755667, 0.9685920755503189, 0.9685977614668801, 0.9685599463745177, 0.9686022876021293, 0.9686195242030918, 0.9685861118569812, 0.9685431121199888, 0.9686225568583468, 0.9685900875548695, 0.968643682931692, 0.9686294404177661, 0.9686212440365292, 0.9685936552443282, 0.9686303523955468, 0.9686712118722001, 0.9686431265594333, 0.9686854454291988, 0.9686256900219304, 0.9686864562692789, 0.9687157080853621], 'mDice': [0.01499170344237638, 0.03795083260016531, 0.09162830293452896, 0.16760187299445517, 0.2519010407556148, 0.3202874784102135, 0.3785920288311245, 0.4241804027420635, 0.4601082390325892, 0.4919779522975466, 0.5161919249207768, 0.5347349013619908, 0.5493218960018122, 0.562904872809946, 0.5761439816234393, 0.5869267486228651, 0.5962509643176049, 0.6040883094490312, 0.6128989230570112, 0.6207285249334937, 0.628093570713549, 0.6335506780077804, 0.6389496761940492, 0.6447647921814621, 0.650274666388458, 0.6541953841699647, 0.6579770905677712, 0.6643387833740793, 0.6680725453054941, 0.671949878836995, 0.6751636952065555, 0.6785851366991388, 0.6834379907136734, 0.6850632812047363, 0.6884622059935196, 0.6902321015009162, 0.6925718873671736, 0.6946071965233999, 0.6971200021601704, 0.6990803105353481, 0.7014476317107818, 0.7031066113652663, 0.704484127827096, 0.7068345490964247, 0.7080628605910201, 0.709501291437088, 0.7106949673818619, 0.7121370155568054, 0.713821471662451, 0.7151460389504002, 0.7151257169178304, 0.7168893625353714, 0.7180909041560031, 0.7196539924962762, 0.7203317708529945, 0.7220489324859909, 0.723104843042392, 0.7232858115687153, 0.7238937277863747, 0.7251671806830281, 0.7255926145014174, 0.7273975708288275, 0.7273778611248939, 0.7285606248320496, 0.7295628018888015, 0.72989831459, 0.7301204930736884, 0.7306411288273962, 0.732246615210581, 0.7328929120221479, 0.7333899811438075, 0.7337821883071479, 0.7344018076981652, 0.7350519112152814, 0.7346284841421374, 0.7356352243855968, 0.7363415510115885, 0.7367413277867111, 0.7376207734965217, 0.7375400071603958, 0.7383425949515995, 0.738154435273831, 0.7402240292607367, 0.7389082688068194, 0.7399824595381262, 0.7404835375655249, 0.7406226202599243, 0.7413538833360591, 0.741515533637642, 0.742701454411714, 0.7421122673126731, 0.7423908018716543, 0.7423358696260488, 0.7435298726624067, 0.7437228244312402, 0.7442903986344412, 0.7444911204830377, 0.7446896436702912, 0.7452405399859995, 0.7445674913119934, 0.7457159522114171, 0.7459088931417366, 0.7466474405926011, 0.7466185536693221, 0.746825125793232, 0.7470072457242158, 0.7476205125223431, 0.7478697011657977, 0.7478168031796931, 0.7478574508241564, 0.7481906517964512, 0.7487995448592335, 0.7484676135126967, 0.7489790671779147, 0.7493935372549181, 0.7496838906143504, 0.7499515963690018, 0.7505712092505908, 0.7507460025386515, 0.7504816533192146, 0.7510152371672356, 0.7517665411611426, 0.7517043077530324, 0.7516928989345225, 0.7516255916138777, 0.7521793099074566, 0.7515074964764434, 0.7521519094549022, 0.7526299666281728, 0.7531315553699082, 0.7527745674676715, 0.7528216118002243, 0.7532341690044861, 0.7540207066026456, 0.7537078748031308, 0.7541553230795598, 0.7540856484039886, 0.7539961119951515, 0.7544088003934047, 0.7551688911472552, 0.7549398877866711, 0.7551545640595982, 0.7549904527603973, 0.7558687389330713, 0.7553644572816944, 0.7556664875498323, 0.7557262933721335, 0.7562710518342649, 0.7565550155953112, 0.7563163955830179, 0.7570695068452541, 0.7567176769552958, 0.7573331065813118, 0.7568966599221781, 0.7575643985258469, 0.7577142530340443, 0.75775993262735, 0.7581856380233339, 0.7582251182136331, 0.7586919102612918, 0.7581401217919705, 0.7580603920750988, 0.7581881593609955, 0.759091896481431, 0.7587096633793469, 0.7596458085870575, 0.7596731209124109, 0.7591051594987767, 0.7594876138093851, 0.7596281195952005, 0.7596888646825986, 0.7605403208423508, 0.759853652548667, 0.7605101649109338, 0.7604931087756801, 0.7608791816705129, 0.7603450847468357, 0.760974405926333, 0.7608072875212392, 0.7612691164315479, 0.7608910074457615, 0.761893840219677, 0.7614653434711592, 0.7616594061919756, 0.7622856354246922, 0.7620906992311149, 0.7619773012579789, 0.7621692705340567, 0.7619330423804064, 0.763010467619567, 0.7637547734208989, 0.7631741575381458, 0.7631284301295569, 0.7636095145345165, 0.7634601658514031, 0.7630752420544917, 0.764182657573624, 0.7639575678559118, 0.7642493890483062, 0.7645252883747414, 0.764327632880474, 0.7646815603259352, 0.7647547151526576, 0.7647797301899262, 0.7650503452855241, 0.7651267765665567, 0.7656957388004628, 0.7655019546119304, 0.766047040590798, 0.765450841955716, 0.7658731394707137, 0.766094452774986, 0.766487134448637, 0.7664861220716884, 0.7660243503156527, 0.7665040771486306, 0.7663603707206491, 0.766739998913896, 0.7666102039468703, 0.7671058442547922, 0.7669706424176937, 0.7671611351509302, 0.767460694375788, 0.7677947684272903, 0.7674096204199339, 0.7677645846196638, 0.7677336820574104, 0.7678050286879372, 0.7679226832640557, 0.7679844453447531, 0.7684779751788589, 0.7683607028750857, 0.7687600599213608, 0.7679842896642809, 0.7684314226298695, 0.7691107798762549, 0.7690595602367555, 0.7690979574748054, 0.7688712732459477, 0.7691265215350436, 0.7691952953298865, 0.769129183770513, 0.7693302257330229, 0.7700011600522606, 0.769883548086181, 0.770242592307009, 0.7700143348476077, 0.7699607101841038, 0.7705165604188233, 0.7698201205369748, 0.7701410569020413, 0.7704548489858435, 0.7700615963296285, 0.770209992883912, 0.7699281287610408, 0.7706036680698096, 0.770628828727525, 0.7705955168638892, 0.7714771004784646, 0.7714083450800816, 0.7715626751016643, 0.7714270020721676, 0.7712123523253039, 0.7711586261135716, 0.7721198988372179, 0.7719091823591807, 0.7716118478448691, 0.7714649643161002, 0.7713728989111129, 0.7713997859375478, 0.7719374124449623, 0.7722435615236107, 0.7725164260000854, 0.7719641798197192, 0.7723197090728604, 0.7728672086362339, 0.7723910323056412, 0.7728434097014816, 0.772484549899131, 0.772345856595507, 0.772335909580264, 0.7728886035811362, 0.772741980420876, 0.7734338364271814, 0.7729671826890718, 0.7734663618507773, 0.7722282097583116, 0.7731577050134908, 0.7735952963811344, 0.7733803710723085, 0.7731981169511579, 0.7735511032528082, 0.7730210770686923, 0.7736398235758424, 0.773517381415849, 0.773288262953867, 0.7737266704101862, 0.7739003572735628, 0.7742546841497162, 0.774622774151723]}
predicting test subjects:   0%|          | 0/15 [00:00<?, ?it/s]predicting test subjects:   7%|▋         | 1/15 [00:02<00:29,  2.10s/it]predicting test subjects:  13%|█▎        | 2/15 [00:03<00:25,  1.99s/it]predicting test subjects:  20%|██        | 3/15 [00:05<00:24,  2.00s/it]predicting test subjects:  27%|██▋       | 4/15 [00:07<00:22,  2.00s/it]predicting test subjects:  33%|███▎      | 5/15 [00:10<00:20,  2.09s/it]predicting test subjects:  40%|████      | 6/15 [00:12<00:19,  2.18s/it]predicting test subjects:  47%|████▋     | 7/15 [00:14<00:15,  1.98s/it]predicting test subjects:  53%|█████▎    | 8/15 [00:16<00:14,  2.11s/it]predicting test subjects:  60%|██████    | 9/15 [00:18<00:12,  2.06s/it]predicting test subjects:  67%|██████▋   | 10/15 [00:20<00:09,  1.94s/it]predicting test subjects:  73%|███████▎  | 11/15 [00:21<00:07,  1.89s/it]predicting test subjects:  80%|████████  | 12/15 [00:24<00:05,  2.00s/it]predicting test subjects:  87%|████████▋ | 13/15 [00:26<00:04,  2.05s/it]predicting test subjects:  93%|█████████▎| 14/15 [00:28<00:02,  2.00s/it]predicting test subjects: 100%|██████████| 15/15 [00:30<00:00,  2.01s/it]
predicting train subjects:   0%|          | 0/532 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/532 [00:02<21:16,  2.40s/it]predicting train subjects:   0%|          | 2/532 [00:04<19:17,  2.18s/it]predicting train subjects:   1%|          | 3/532 [00:05<18:16,  2.07s/it]predicting train subjects:   1%|          | 4/532 [00:07<17:21,  1.97s/it]predicting train subjects:   1%|          | 5/532 [00:09<17:13,  1.96s/it]predicting train subjects:   1%|          | 6/532 [00:11<16:30,  1.88s/it]predicting train subjects:   1%|▏         | 7/532 [00:12<16:01,  1.83s/it]predicting train subjects:   2%|▏         | 8/532 [00:14<15:32,  1.78s/it]predicting train subjects:   2%|▏         | 9/532 [00:16<16:30,  1.89s/it]predicting train subjects:   2%|▏         | 10/532 [00:18<16:14,  1.87s/it]predicting train subjects:   2%|▏         | 11/532 [00:20<15:27,  1.78s/it]predicting train subjects:   2%|▏         | 12/532 [00:22<16:48,  1.94s/it]predicting train subjects:   2%|▏         | 13/532 [00:24<15:55,  1.84s/it]predicting train subjects:   3%|▎         | 14/532 [00:25<14:51,  1.72s/it]predicting train subjects:   3%|▎         | 15/532 [00:27<14:48,  1.72s/it]predicting train subjects:   3%|▎         | 16/532 [00:29<15:31,  1.80s/it]predicting train subjects:   3%|▎         | 17/532 [00:30<15:02,  1.75s/it]predicting train subjects:   3%|▎         | 18/532 [00:32<15:41,  1.83s/it]predicting train subjects:   4%|▎         | 19/532 [00:34<14:49,  1.73s/it]predicting train subjects:   4%|▍         | 20/532 [00:36<15:12,  1.78s/it]predicting train subjects:   4%|▍         | 21/532 [00:38<16:25,  1.93s/it]predicting train subjects:   4%|▍         | 22/532 [00:40<15:25,  1.82s/it]predicting train subjects:   4%|▍         | 23/532 [00:42<15:39,  1.85s/it]predicting train subjects:   5%|▍         | 24/532 [00:43<15:02,  1.78s/it]predicting train subjects:   5%|▍         | 25/532 [00:45<16:13,  1.92s/it]predicting train subjects:   5%|▍         | 26/532 [00:47<15:59,  1.90s/it]predicting train subjects:   5%|▌         | 27/532 [00:50<17:07,  2.03s/it]predicting train subjects:   5%|▌         | 28/532 [00:51<16:34,  1.97s/it]predicting train subjects:   5%|▌         | 29/532 [00:54<17:00,  2.03s/it]predicting train subjects:   6%|▌         | 30/532 [00:55<15:51,  1.90s/it]predicting train subjects:   6%|▌         | 31/532 [00:57<15:40,  1.88s/it]predicting train subjects:   6%|▌         | 32/532 [00:59<15:37,  1.87s/it]predicting train subjects:   6%|▌         | 33/532 [01:01<14:57,  1.80s/it]predicting train subjects:   6%|▋         | 34/532 [01:03<16:00,  1.93s/it]predicting train subjects:   7%|▋         | 35/532 [01:05<15:47,  1.91s/it]predicting train subjects:   7%|▋         | 36/532 [01:07<15:57,  1.93s/it]predicting train subjects:   7%|▋         | 37/532 [01:08<15:41,  1.90s/it]predicting train subjects:   7%|▋         | 38/532 [01:10<16:04,  1.95s/it]predicting train subjects:   7%|▋         | 39/532 [01:12<15:26,  1.88s/it]predicting train subjects:   8%|▊         | 40/532 [01:14<15:09,  1.85s/it]predicting train subjects:   8%|▊         | 41/532 [01:16<15:42,  1.92s/it]predicting train subjects:   8%|▊         | 42/532 [01:18<15:30,  1.90s/it]predicting train subjects:   8%|▊         | 43/532 [01:19<14:38,  1.80s/it]predicting train subjects:   8%|▊         | 44/532 [01:21<13:48,  1.70s/it]predicting train subjects:   8%|▊         | 45/532 [01:23<13:35,  1.68s/it]predicting train subjects:   9%|▊         | 46/532 [01:24<13:59,  1.73s/it]predicting train subjects:   9%|▉         | 47/532 [01:27<15:18,  1.89s/it]predicting train subjects:   9%|▉         | 48/532 [01:29<15:31,  1.92s/it]predicting train subjects:   9%|▉         | 49/532 [01:30<14:56,  1.86s/it]predicting train subjects:   9%|▉         | 50/532 [01:33<15:53,  1.98s/it]predicting train subjects:  10%|▉         | 51/532 [01:34<15:31,  1.94s/it]predicting train subjects:  10%|▉         | 52/532 [01:36<15:23,  1.92s/it]predicting train subjects:  10%|▉         | 53/532 [01:38<14:55,  1.87s/it]predicting train subjects:  10%|█         | 54/532 [01:40<15:29,  1.94s/it]predicting train subjects:  10%|█         | 55/532 [01:42<15:28,  1.95s/it]predicting train subjects:  11%|█         | 56/532 [01:44<15:23,  1.94s/it]predicting train subjects:  11%|█         | 57/532 [01:46<15:05,  1.91s/it]predicting train subjects:  11%|█         | 58/532 [01:48<15:44,  1.99s/it]predicting train subjects:  11%|█         | 59/532 [01:50<16:24,  2.08s/it]predicting train subjects:  11%|█▏        | 60/532 [01:52<15:07,  1.92s/it]predicting train subjects:  11%|█▏        | 61/532 [01:54<14:27,  1.84s/it]predicting train subjects:  12%|█▏        | 62/532 [01:56<15:09,  1.93s/it]predicting train subjects:  12%|█▏        | 63/532 [01:58<15:49,  2.02s/it]predicting train subjects:  12%|█▏        | 64/532 [02:00<15:01,  1.93s/it]predicting train subjects:  12%|█▏        | 65/532 [02:02<14:48,  1.90s/it]predicting train subjects:  12%|█▏        | 66/532 [02:04<15:52,  2.04s/it]predicting train subjects:  13%|█▎        | 67/532 [02:06<16:16,  2.10s/it]predicting train subjects:  13%|█▎        | 68/532 [02:08<15:35,  2.02s/it]predicting train subjects:  13%|█▎        | 69/532 [02:10<15:12,  1.97s/it]predicting train subjects:  13%|█▎        | 70/532 [02:12<14:42,  1.91s/it]predicting train subjects:  13%|█▎        | 71/532 [02:13<14:14,  1.85s/it]predicting train subjects:  14%|█▎        | 72/532 [02:15<13:41,  1.78s/it]predicting train subjects:  14%|█▎        | 73/532 [02:17<14:00,  1.83s/it]predicting train subjects:  14%|█▍        | 74/532 [02:19<15:23,  2.02s/it]predicting train subjects:  14%|█▍        | 75/532 [02:22<17:36,  2.31s/it]predicting train subjects:  14%|█▍        | 76/532 [02:24<16:15,  2.14s/it]predicting train subjects:  14%|█▍        | 77/532 [02:26<15:39,  2.06s/it]predicting train subjects:  15%|█▍        | 78/532 [02:28<15:26,  2.04s/it]predicting train subjects:  15%|█▍        | 79/532 [02:30<15:14,  2.02s/it]predicting train subjects:  15%|█▌        | 80/532 [02:32<14:58,  1.99s/it]predicting train subjects:  15%|█▌        | 81/532 [02:34<14:42,  1.96s/it]predicting train subjects:  15%|█▌        | 82/532 [02:36<14:34,  1.94s/it]predicting train subjects:  16%|█▌        | 83/532 [02:37<13:51,  1.85s/it]predicting train subjects:  16%|█▌        | 84/532 [02:39<13:27,  1.80s/it]predicting train subjects:  16%|█▌        | 85/532 [02:41<13:19,  1.79s/it]predicting train subjects:  16%|█▌        | 86/532 [02:42<13:03,  1.76s/it]predicting train subjects:  16%|█▋        | 87/532 [02:44<12:42,  1.71s/it]predicting train subjects:  17%|█▋        | 88/532 [02:46<12:44,  1.72s/it]predicting train subjects:  17%|█▋        | 89/532 [02:48<13:04,  1.77s/it]predicting train subjects:  17%|█▋        | 90/532 [02:49<13:11,  1.79s/it]predicting train subjects:  17%|█▋        | 91/532 [02:51<13:18,  1.81s/it]predicting train subjects:  17%|█▋        | 92/532 [02:53<13:24,  1.83s/it]predicting train subjects:  17%|█▋        | 93/532 [02:55<13:22,  1.83s/it]predicting train subjects:  18%|█▊        | 94/532 [02:57<13:09,  1.80s/it]predicting train subjects:  18%|█▊        | 95/532 [02:59<13:52,  1.90s/it]predicting train subjects:  18%|█▊        | 96/532 [03:01<14:18,  1.97s/it]predicting train subjects:  18%|█▊        | 97/532 [03:03<14:42,  2.03s/it]predicting train subjects:  18%|█▊        | 98/532 [03:05<15:00,  2.07s/it]predicting train subjects:  19%|█▊        | 99/532 [03:07<15:02,  2.08s/it]predicting train subjects:  19%|█▉        | 100/532 [03:10<15:02,  2.09s/it]predicting train subjects:  19%|█▉        | 101/532 [03:11<13:51,  1.93s/it]predicting train subjects:  19%|█▉        | 102/532 [03:13<13:05,  1.83s/it]predicting train subjects:  19%|█▉        | 103/532 [03:14<12:30,  1.75s/it]predicting train subjects:  20%|█▉        | 104/532 [03:16<12:30,  1.75s/it]predicting train subjects:  20%|█▉        | 105/532 [03:18<12:31,  1.76s/it]predicting train subjects:  20%|█▉        | 106/532 [03:20<12:17,  1.73s/it]predicting train subjects:  20%|██        | 107/532 [03:21<11:56,  1.69s/it]predicting train subjects:  20%|██        | 108/532 [03:23<11:40,  1.65s/it]predicting train subjects:  20%|██        | 109/532 [03:24<11:27,  1.63s/it]predicting train subjects:  21%|██        | 110/532 [03:26<11:10,  1.59s/it]predicting train subjects:  21%|██        | 111/532 [03:27<11:05,  1.58s/it]predicting train subjects:  21%|██        | 112/532 [03:29<11:05,  1.58s/it]predicting train subjects:  21%|██        | 113/532 [03:31<11:44,  1.68s/it]predicting train subjects:  21%|██▏       | 114/532 [03:33<12:15,  1.76s/it]predicting train subjects:  22%|██▏       | 115/532 [03:35<12:30,  1.80s/it]predicting train subjects:  22%|██▏       | 116/532 [03:37<12:37,  1.82s/it]predicting train subjects:  22%|██▏       | 117/532 [03:38<12:56,  1.87s/it]predicting train subjects:  22%|██▏       | 118/532 [03:40<12:58,  1.88s/it]predicting train subjects:  22%|██▏       | 119/532 [03:42<13:07,  1.91s/it]predicting train subjects:  23%|██▎       | 120/532 [03:44<12:55,  1.88s/it]predicting train subjects:  23%|██▎       | 121/532 [03:46<12:41,  1.85s/it]predicting train subjects:  23%|██▎       | 122/532 [03:48<12:35,  1.84s/it]predicting train subjects:  23%|██▎       | 123/532 [03:50<12:38,  1.85s/it]predicting train subjects:  23%|██▎       | 124/532 [03:52<12:39,  1.86s/it]predicting train subjects:  23%|██▎       | 125/532 [03:53<12:48,  1.89s/it]predicting train subjects:  24%|██▎       | 126/532 [03:55<12:54,  1.91s/it]predicting train subjects:  24%|██▍       | 127/532 [03:57<12:46,  1.89s/it]predicting train subjects:  24%|██▍       | 128/532 [03:59<12:49,  1.90s/it]predicting train subjects:  24%|██▍       | 129/532 [04:01<12:49,  1.91s/it]predicting train subjects:  24%|██▍       | 130/532 [04:03<12:58,  1.94s/it]predicting train subjects:  25%|██▍       | 131/532 [04:05<13:37,  2.04s/it]predicting train subjects:  25%|██▍       | 132/532 [04:08<14:06,  2.12s/it]predicting train subjects:  25%|██▌       | 133/532 [04:10<14:26,  2.17s/it]predicting train subjects:  25%|██▌       | 134/532 [04:12<14:33,  2.19s/it]predicting train subjects:  25%|██▌       | 135/532 [04:15<14:47,  2.24s/it]predicting train subjects:  26%|██▌       | 136/532 [04:17<14:58,  2.27s/it]predicting train subjects:  26%|██▌       | 137/532 [04:19<15:07,  2.30s/it]predicting train subjects:  26%|██▌       | 138/532 [04:22<15:19,  2.33s/it]predicting train subjects:  26%|██▌       | 139/532 [04:24<15:13,  2.33s/it]predicting train subjects:  26%|██▋       | 140/532 [04:26<15:10,  2.32s/it]predicting train subjects:  27%|██▋       | 141/532 [04:29<15:14,  2.34s/it]predicting train subjects:  27%|██▋       | 142/532 [04:31<15:19,  2.36s/it]predicting train subjects:  27%|██▋       | 143/532 [04:33<14:13,  2.20s/it]predicting train subjects:  27%|██▋       | 144/532 [04:35<13:14,  2.05s/it]predicting train subjects:  27%|██▋       | 145/532 [04:36<12:32,  1.94s/it]predicting train subjects:  27%|██▋       | 146/532 [04:38<11:58,  1.86s/it]predicting train subjects:  28%|██▊       | 147/532 [04:40<11:32,  1.80s/it]predicting train subjects:  28%|██▊       | 148/532 [04:41<11:16,  1.76s/it]predicting train subjects:  28%|██▊       | 149/532 [04:43<11:30,  1.80s/it]predicting train subjects:  28%|██▊       | 150/532 [04:45<11:27,  1.80s/it]predicting train subjects:  28%|██▊       | 151/532 [04:47<11:37,  1.83s/it]predicting train subjects:  29%|██▊       | 152/532 [04:49<11:35,  1.83s/it]predicting train subjects:  29%|██▉       | 153/532 [04:51<11:29,  1.82s/it]predicting train subjects:  29%|██▉       | 154/532 [04:52<11:28,  1.82s/it]predicting train subjects:  29%|██▉       | 155/532 [04:55<12:21,  1.97s/it]predicting train subjects:  29%|██▉       | 156/532 [04:57<13:03,  2.08s/it]predicting train subjects:  30%|██▉       | 157/532 [04:59<13:34,  2.17s/it]predicting train subjects:  30%|██▉       | 158/532 [05:02<14:10,  2.28s/it]predicting train subjects:  30%|██▉       | 159/532 [05:04<14:19,  2.31s/it]predicting train subjects:  30%|███       | 160/532 [05:07<14:37,  2.36s/it]predicting train subjects:  30%|███       | 161/532 [05:09<13:30,  2.18s/it]predicting train subjects:  30%|███       | 162/532 [05:10<12:50,  2.08s/it]predicting train subjects:  31%|███       | 163/532 [05:12<12:18,  2.00s/it]predicting train subjects:  31%|███       | 164/532 [05:14<11:47,  1.92s/it]predicting train subjects:  31%|███       | 165/532 [05:16<11:34,  1.89s/it]predicting train subjects:  31%|███       | 166/532 [05:18<11:17,  1.85s/it]predicting train subjects:  31%|███▏      | 167/532 [05:19<11:16,  1.85s/it]predicting train subjects:  32%|███▏      | 168/532 [05:21<11:10,  1.84s/it]predicting train subjects:  32%|███▏      | 169/532 [05:23<11:08,  1.84s/it]predicting train subjects:  32%|███▏      | 170/532 [05:25<11:23,  1.89s/it]predicting train subjects:  32%|███▏      | 171/532 [05:27<11:29,  1.91s/it]predicting train subjects:  32%|███▏      | 172/532 [05:29<11:22,  1.90s/it]predicting train subjects:  33%|███▎      | 173/532 [05:31<10:51,  1.82s/it]predicting train subjects:  33%|███▎      | 174/532 [05:33<11:16,  1.89s/it]predicting train subjects:  33%|███▎      | 175/532 [05:35<11:27,  1.93s/it]predicting train subjects:  33%|███▎      | 176/532 [05:37<11:23,  1.92s/it]predicting train subjects:  33%|███▎      | 177/532 [05:39<11:33,  1.95s/it]predicting train subjects:  33%|███▎      | 178/532 [05:40<11:30,  1.95s/it]predicting train subjects:  34%|███▎      | 179/532 [05:43<11:40,  1.99s/it]predicting train subjects:  34%|███▍      | 180/532 [05:45<11:56,  2.04s/it]predicting train subjects:  34%|███▍      | 181/532 [05:47<11:50,  2.02s/it]predicting train subjects:  34%|███▍      | 182/532 [05:49<12:06,  2.07s/it]predicting train subjects:  34%|███▍      | 183/532 [05:51<11:54,  2.05s/it]predicting train subjects:  35%|███▍      | 184/532 [05:53<11:47,  2.03s/it]predicting train subjects:  35%|███▍      | 185/532 [05:55<11:38,  2.01s/it]predicting train subjects:  35%|███▍      | 186/532 [05:57<11:17,  1.96s/it]predicting train subjects:  35%|███▌      | 187/532 [05:59<11:13,  1.95s/it]predicting train subjects:  35%|███▌      | 188/532 [06:01<11:20,  1.98s/it]predicting train subjects:  36%|███▌      | 189/532 [06:03<11:10,  1.95s/it]predicting train subjects:  36%|███▌      | 190/532 [06:04<10:58,  1.92s/it]predicting train subjects:  36%|███▌      | 191/532 [06:07<12:22,  2.18s/it]predicting train subjects:  36%|███▌      | 192/532 [06:10<13:16,  2.34s/it]predicting train subjects:  36%|███▋      | 193/532 [06:12<13:32,  2.40s/it]predicting train subjects:  36%|███▋      | 194/532 [06:15<14:13,  2.53s/it]predicting train subjects:  37%|███▋      | 195/532 [06:18<14:46,  2.63s/it]predicting train subjects:  37%|███▋      | 196/532 [06:21<15:06,  2.70s/it]predicting train subjects:  37%|███▋      | 197/532 [06:23<14:28,  2.59s/it]predicting train subjects:  37%|███▋      | 198/532 [06:26<14:01,  2.52s/it]predicting train subjects:  37%|███▋      | 199/532 [06:28<13:54,  2.51s/it]predicting train subjects:  38%|███▊      | 200/532 [06:30<13:33,  2.45s/it]predicting train subjects:  38%|███▊      | 201/532 [06:33<13:47,  2.50s/it]predicting train subjects:  38%|███▊      | 202/532 [06:35<13:35,  2.47s/it]predicting train subjects:  38%|███▊      | 203/532 [06:37<12:41,  2.32s/it]predicting train subjects:  38%|███▊      | 204/532 [06:40<12:16,  2.24s/it]predicting train subjects:  39%|███▊      | 205/532 [06:42<11:49,  2.17s/it]predicting train subjects:  39%|███▊      | 206/532 [06:43<11:27,  2.11s/it]predicting train subjects:  39%|███▉      | 207/532 [06:46<11:19,  2.09s/it]predicting train subjects:  39%|███▉      | 208/532 [06:48<11:15,  2.08s/it]predicting train subjects:  39%|███▉      | 209/532 [06:49<10:54,  2.03s/it]predicting train subjects:  39%|███▉      | 210/532 [06:51<10:42,  1.99s/it]predicting train subjects:  40%|███▉      | 211/532 [06:53<10:16,  1.92s/it]predicting train subjects:  40%|███▉      | 212/532 [06:55<10:01,  1.88s/it]predicting train subjects:  40%|████      | 213/532 [06:57<09:43,  1.83s/it]predicting train subjects:  40%|████      | 214/532 [06:58<09:37,  1.82s/it]predicting train subjects:  40%|████      | 215/532 [07:01<10:53,  2.06s/it]predicting train subjects:  41%|████      | 216/532 [07:04<11:37,  2.21s/it]predicting train subjects:  41%|████      | 217/532 [07:06<12:13,  2.33s/it]predicting train subjects:  41%|████      | 218/532 [07:09<12:38,  2.41s/it]predicting train subjects:  41%|████      | 219/532 [07:11<12:52,  2.47s/it]predicting train subjects:  41%|████▏     | 220/532 [07:14<12:55,  2.49s/it]predicting train subjects:  42%|████▏     | 221/532 [07:16<11:44,  2.26s/it]predicting train subjects:  42%|████▏     | 222/532 [07:17<10:53,  2.11s/it]predicting train subjects:  42%|████▏     | 223/532 [07:19<10:14,  1.99s/it]predicting train subjects:  42%|████▏     | 224/532 [07:21<09:55,  1.93s/it]predicting train subjects:  42%|████▏     | 225/532 [07:23<09:23,  1.84s/it]predicting train subjects:  42%|████▏     | 226/532 [07:24<09:11,  1.80s/it]predicting train subjects:  43%|████▎     | 227/532 [07:26<09:01,  1.78s/it]predicting train subjects:  43%|████▎     | 228/532 [07:28<08:56,  1.76s/it]predicting train subjects:  43%|████▎     | 229/532 [07:29<08:43,  1.73s/it]predicting train subjects:  43%|████▎     | 230/532 [07:31<08:40,  1.72s/it]predicting train subjects:  43%|████▎     | 231/532 [07:33<08:35,  1.71s/it]predicting train subjects:  44%|████▎     | 232/532 [07:35<08:44,  1.75s/it]predicting train subjects:  44%|████▍     | 233/532 [07:37<09:02,  1.81s/it]predicting train subjects:  44%|████▍     | 234/532 [07:39<09:29,  1.91s/it]predicting train subjects:  44%|████▍     | 235/532 [07:41<09:29,  1.92s/it]predicting train subjects:  44%|████▍     | 236/532 [07:43<09:49,  1.99s/it]predicting train subjects:  45%|████▍     | 237/532 [07:45<09:52,  2.01s/it]predicting train subjects:  45%|████▍     | 238/532 [07:47<09:47,  2.00s/it]predicting train subjects:  45%|████▍     | 239/532 [07:49<09:57,  2.04s/it]predicting train subjects:  45%|████▌     | 240/532 [07:51<10:05,  2.07s/it]predicting train subjects:  45%|████▌     | 241/532 [07:53<10:08,  2.09s/it]predicting train subjects:  45%|████▌     | 242/532 [07:56<10:38,  2.20s/it]predicting train subjects:  46%|████▌     | 243/532 [07:58<10:36,  2.20s/it]predicting train subjects:  46%|████▌     | 244/532 [08:00<10:24,  2.17s/it]predicting train subjects:  46%|████▌     | 245/532 [08:02<09:34,  2.00s/it]predicting train subjects:  46%|████▌     | 246/532 [08:03<09:01,  1.89s/it]predicting train subjects:  46%|████▋     | 247/532 [08:05<08:43,  1.84s/it]predicting train subjects:  47%|████▋     | 248/532 [08:07<08:21,  1.77s/it]predicting train subjects:  47%|████▋     | 249/532 [08:08<08:13,  1.75s/it]predicting train subjects:  47%|████▋     | 250/532 [08:10<08:15,  1.76s/it]predicting train subjects:  47%|████▋     | 251/532 [08:12<08:23,  1.79s/it]predicting train subjects:  47%|████▋     | 252/532 [08:14<08:15,  1.77s/it]predicting train subjects:  48%|████▊     | 253/532 [08:15<08:14,  1.77s/it]predicting train subjects:  48%|████▊     | 254/532 [08:17<08:35,  1.85s/it]predicting train subjects:  48%|████▊     | 255/532 [08:20<08:50,  1.92s/it]predicting train subjects:  48%|████▊     | 256/532 [08:21<08:42,  1.89s/it]predicting train subjects:  48%|████▊     | 257/532 [08:24<09:16,  2.02s/it]predicting train subjects:  48%|████▊     | 258/532 [08:26<09:52,  2.16s/it]predicting train subjects:  49%|████▊     | 259/532 [08:28<09:58,  2.19s/it]predicting train subjects:  49%|████▉     | 260/532 [08:31<10:19,  2.28s/it]predicting train subjects:  49%|████▉     | 261/532 [08:33<10:18,  2.28s/it]predicting train subjects:  49%|████▉     | 262/532 [08:36<10:21,  2.30s/it]predicting train subjects:  49%|████▉     | 263/532 [08:37<09:42,  2.16s/it]predicting train subjects:  50%|████▉     | 264/532 [08:39<09:10,  2.05s/it]predicting train subjects:  50%|████▉     | 265/532 [08:41<08:43,  1.96s/it]predicting train subjects:  50%|█████     | 266/532 [08:43<08:23,  1.89s/it]predicting train subjects:  50%|█████     | 267/532 [08:44<07:58,  1.81s/it]predicting train subjects:  50%|█████     | 268/532 [08:46<07:53,  1.79s/it]predicting train subjects:  51%|█████     | 269/532 [08:48<08:26,  1.93s/it]predicting train subjects:  51%|█████     | 270/532 [08:50<08:32,  1.96s/it]predicting train subjects:  51%|█████     | 271/532 [08:53<08:51,  2.04s/it]predicting train subjects:  51%|█████     | 272/532 [08:55<09:03,  2.09s/it]predicting train subjects:  51%|█████▏    | 273/532 [08:57<09:10,  2.12s/it]predicting train subjects:  52%|█████▏    | 274/532 [08:59<09:17,  2.16s/it]predicting train subjects:  52%|█████▏    | 275/532 [09:02<09:48,  2.29s/it]predicting train subjects:  52%|█████▏    | 276/532 [09:04<10:14,  2.40s/it]predicting train subjects:  52%|█████▏    | 277/532 [09:07<10:25,  2.45s/it]predicting train subjects:  52%|█████▏    | 278/532 [09:10<10:36,  2.51s/it]predicting train subjects:  52%|█████▏    | 279/532 [09:12<10:36,  2.52s/it]predicting train subjects:  53%|█████▎    | 280/532 [09:15<10:45,  2.56s/it]predicting train subjects:  53%|█████▎    | 281/532 [09:18<10:58,  2.62s/it]predicting train subjects:  53%|█████▎    | 282/532 [09:20<10:46,  2.59s/it]predicting train subjects:  53%|█████▎    | 283/532 [09:23<10:45,  2.59s/it]predicting train subjects:  53%|█████▎    | 284/532 [09:25<10:24,  2.52s/it]predicting train subjects:  54%|█████▎    | 285/532 [09:28<10:27,  2.54s/it]predicting train subjects:  54%|█████▍    | 286/532 [09:30<10:39,  2.60s/it]predicting train subjects:  54%|█████▍    | 287/532 [09:32<09:47,  2.40s/it]predicting train subjects:  54%|█████▍    | 288/532 [09:34<09:10,  2.26s/it]predicting train subjects:  54%|█████▍    | 289/532 [09:36<08:31,  2.11s/it]predicting train subjects:  55%|█████▍    | 290/532 [09:38<08:07,  2.02s/it]predicting train subjects:  55%|█████▍    | 291/532 [09:40<08:08,  2.03s/it]predicting train subjects:  55%|█████▍    | 292/532 [09:42<07:45,  1.94s/it]predicting train subjects:  55%|█████▌    | 293/532 [09:44<07:50,  1.97s/it]predicting train subjects:  55%|█████▌    | 294/532 [09:46<08:07,  2.05s/it]predicting train subjects:  55%|█████▌    | 295/532 [09:48<08:28,  2.15s/it]predicting train subjects:  56%|█████▌    | 296/532 [09:50<08:24,  2.14s/it]predicting train subjects:  56%|█████▌    | 297/532 [09:53<08:27,  2.16s/it]predicting train subjects:  56%|█████▌    | 298/532 [09:55<08:22,  2.15s/it]predicting train subjects:  56%|█████▌    | 299/532 [09:56<07:51,  2.02s/it]predicting train subjects:  56%|█████▋    | 300/532 [09:58<07:32,  1.95s/it]predicting train subjects:  57%|█████▋    | 301/532 [10:00<07:16,  1.89s/it]predicting train subjects:  57%|█████▋    | 302/532 [10:02<06:50,  1.78s/it]predicting train subjects:  57%|█████▋    | 303/532 [10:03<06:37,  1.74s/it]predicting train subjects:  57%|█████▋    | 304/532 [10:05<06:40,  1.76s/it]predicting train subjects:  57%|█████▋    | 305/532 [10:07<07:12,  1.91s/it]predicting train subjects:  58%|█████▊    | 306/532 [10:09<07:28,  1.98s/it]predicting train subjects:  58%|█████▊    | 307/532 [10:12<07:37,  2.03s/it]predicting train subjects:  58%|█████▊    | 308/532 [10:14<07:42,  2.07s/it]predicting train subjects:  58%|█████▊    | 309/532 [10:16<07:58,  2.14s/it]predicting train subjects:  58%|█████▊    | 310/532 [10:18<08:02,  2.17s/it]predicting train subjects:  58%|█████▊    | 311/532 [10:21<08:45,  2.38s/it]predicting train subjects:  59%|█████▊    | 312/532 [10:24<09:17,  2.53s/it]predicting train subjects:  59%|█████▉    | 313/532 [10:27<09:39,  2.64s/it]predicting train subjects:  59%|█████▉    | 314/532 [10:30<09:53,  2.72s/it]predicting train subjects:  59%|█████▉    | 315/532 [10:33<10:04,  2.78s/it]predicting train subjects:  59%|█████▉    | 316/532 [10:36<10:08,  2.82s/it]predicting train subjects:  60%|█████▉    | 317/532 [10:37<08:53,  2.48s/it]predicting train subjects:  60%|█████▉    | 318/532 [10:39<08:00,  2.24s/it]predicting train subjects:  60%|█████▉    | 319/532 [10:41<07:22,  2.08s/it]predicting train subjects:  60%|██████    | 320/532 [10:42<06:55,  1.96s/it]predicting train subjects:  60%|██████    | 321/532 [10:44<06:34,  1.87s/it]predicting train subjects:  61%|██████    | 322/532 [10:46<06:17,  1.80s/it]predicting train subjects:  61%|██████    | 323/532 [10:48<06:49,  1.96s/it]predicting train subjects:  61%|██████    | 324/532 [10:50<07:05,  2.04s/it]predicting train subjects:  61%|██████    | 325/532 [10:53<07:42,  2.24s/it]predicting train subjects:  61%|██████▏   | 326/532 [10:55<07:48,  2.27s/it]predicting train subjects:  61%|██████▏   | 327/532 [10:58<07:52,  2.30s/it]predicting train subjects:  62%|██████▏   | 328/532 [11:00<07:53,  2.32s/it]predicting train subjects:  62%|██████▏   | 329/532 [11:02<07:22,  2.18s/it]predicting train subjects:  62%|██████▏   | 330/532 [11:04<06:57,  2.07s/it]predicting train subjects:  62%|██████▏   | 331/532 [11:06<06:42,  2.00s/it]predicting train subjects:  62%|██████▏   | 332/532 [11:07<06:27,  1.94s/it]predicting train subjects:  63%|██████▎   | 333/532 [11:09<06:24,  1.93s/it]predicting train subjects:  63%|██████▎   | 334/532 [11:11<06:14,  1.89s/it]predicting train subjects:  63%|██████▎   | 335/532 [11:13<06:28,  1.97s/it]predicting train subjects:  63%|██████▎   | 336/532 [11:15<06:34,  2.01s/it]predicting train subjects:  63%|██████▎   | 337/532 [11:17<06:38,  2.04s/it]predicting train subjects:  64%|██████▎   | 338/532 [11:19<06:36,  2.04s/it]predicting train subjects:  64%|██████▎   | 339/532 [11:22<06:38,  2.06s/it]predicting train subjects:  64%|██████▍   | 340/532 [11:24<06:35,  2.06s/it]predicting train subjects:  64%|██████▍   | 341/532 [11:25<06:02,  1.90s/it]predicting train subjects:  64%|██████▍   | 342/532 [11:27<05:38,  1.78s/it]predicting train subjects:  64%|██████▍   | 343/532 [11:28<05:21,  1.70s/it]predicting train subjects:  65%|██████▍   | 344/532 [11:30<05:09,  1.65s/it]predicting train subjects:  65%|██████▍   | 345/532 [11:31<05:00,  1.61s/it]predicting train subjects:  65%|██████▌   | 346/532 [11:33<04:56,  1.60s/it]predicting train subjects:  65%|██████▌   | 347/532 [11:35<05:04,  1.65s/it]predicting train subjects:  65%|██████▌   | 348/532 [11:36<05:08,  1.68s/it]predicting train subjects:  66%|██████▌   | 349/532 [11:38<05:10,  1.70s/it]predicting train subjects:  66%|██████▌   | 350/532 [11:40<05:11,  1.71s/it]predicting train subjects:  66%|██████▌   | 351/532 [11:41<05:10,  1.71s/it]predicting train subjects:  66%|██████▌   | 352/532 [11:43<05:08,  1.71s/it]predicting train subjects:  66%|██████▋   | 353/532 [11:45<05:12,  1.74s/it]predicting train subjects:  67%|██████▋   | 354/532 [11:47<05:07,  1.73s/it]predicting train subjects:  67%|██████▋   | 355/532 [11:49<05:11,  1.76s/it]predicting train subjects:  67%|██████▋   | 356/532 [11:50<05:06,  1.74s/it]predicting train subjects:  67%|██████▋   | 357/532 [11:52<05:06,  1.75s/it]predicting train subjects:  67%|██████▋   | 358/532 [11:54<05:05,  1.76s/it]predicting train subjects:  67%|██████▋   | 359/532 [11:55<04:56,  1.71s/it]predicting train subjects:  68%|██████▊   | 360/532 [11:57<04:46,  1.66s/it]predicting train subjects:  68%|██████▊   | 361/532 [11:58<04:37,  1.63s/it]predicting train subjects:  68%|██████▊   | 362/532 [12:00<04:32,  1.60s/it]predicting train subjects:  68%|██████▊   | 363/532 [12:02<04:27,  1.58s/it]predicting train subjects:  68%|██████▊   | 364/532 [12:03<04:27,  1.59s/it]predicting train subjects:  69%|██████▊   | 365/532 [12:05<04:22,  1.57s/it]predicting train subjects:  69%|██████▉   | 366/532 [12:06<04:19,  1.56s/it]predicting train subjects:  69%|██████▉   | 367/532 [12:08<04:15,  1.55s/it]predicting train subjects:  69%|██████▉   | 368/532 [12:09<04:13,  1.55s/it]predicting train subjects:  69%|██████▉   | 369/532 [12:11<04:11,  1.55s/it]predicting train subjects:  70%|██████▉   | 370/532 [12:12<04:08,  1.53s/it]predicting train subjects:  70%|██████▉   | 371/532 [12:14<04:34,  1.71s/it]predicting train subjects:  70%|██████▉   | 372/532 [12:17<04:55,  1.85s/it]predicting train subjects:  70%|███████   | 373/532 [12:19<05:06,  1.93s/it]predicting train subjects:  70%|███████   | 374/532 [12:21<05:21,  2.03s/it]predicting train subjects:  70%|███████   | 375/532 [12:23<05:27,  2.09s/it]predicting train subjects:  71%|███████   | 376/532 [12:25<05:27,  2.10s/it]predicting train subjects:  71%|███████   | 377/532 [12:27<05:11,  2.01s/it]predicting train subjects:  71%|███████   | 378/532 [12:29<05:03,  1.97s/it]predicting train subjects:  71%|███████   | 379/532 [12:31<04:55,  1.93s/it]predicting train subjects:  71%|███████▏  | 380/532 [12:33<04:59,  1.97s/it]predicting train subjects:  72%|███████▏  | 381/532 [12:35<04:55,  1.96s/it]predicting train subjects:  72%|███████▏  | 382/532 [12:37<04:52,  1.95s/it]predicting train subjects:  72%|███████▏  | 383/532 [12:39<04:47,  1.93s/it]predicting train subjects:  72%|███████▏  | 384/532 [12:41<04:41,  1.90s/it]predicting train subjects:  72%|███████▏  | 385/532 [12:42<04:35,  1.87s/it]predicting train subjects:  73%|███████▎  | 386/532 [12:44<04:32,  1.87s/it]predicting train subjects:  73%|███████▎  | 387/532 [12:46<04:27,  1.85s/it]predicting train subjects:  73%|███████▎  | 388/532 [12:48<04:26,  1.85s/it]predicting train subjects:  73%|███████▎  | 389/532 [12:50<04:24,  1.85s/it]predicting train subjects:  73%|███████▎  | 390/532 [12:52<04:25,  1.87s/it]predicting train subjects:  73%|███████▎  | 391/532 [12:54<04:26,  1.89s/it]predicting train subjects:  74%|███████▎  | 392/532 [12:55<04:23,  1.88s/it]predicting train subjects:  74%|███████▍  | 393/532 [12:57<04:28,  1.93s/it]predicting train subjects:  74%|███████▍  | 394/532 [12:59<04:25,  1.92s/it]predicting train subjects:  74%|███████▍  | 395/532 [13:01<04:21,  1.91s/it]predicting train subjects:  74%|███████▍  | 396/532 [13:03<04:18,  1.90s/it]predicting train subjects:  75%|███████▍  | 397/532 [13:05<04:14,  1.88s/it]predicting train subjects:  75%|███████▍  | 398/532 [13:07<04:12,  1.89s/it]predicting train subjects:  75%|███████▌  | 399/532 [13:09<04:07,  1.86s/it]predicting train subjects:  75%|███████▌  | 400/532 [13:11<04:10,  1.90s/it]predicting train subjects:  75%|███████▌  | 401/532 [13:13<04:14,  1.94s/it]predicting train subjects:  76%|███████▌  | 402/532 [13:15<04:19,  2.00s/it]predicting train subjects:  76%|███████▌  | 403/532 [13:17<04:20,  2.02s/it]predicting train subjects:  76%|███████▌  | 404/532 [13:19<04:26,  2.08s/it]predicting train subjects:  76%|███████▌  | 405/532 [13:21<04:25,  2.09s/it]predicting train subjects:  76%|███████▋  | 406/532 [13:23<04:22,  2.08s/it]predicting train subjects:  77%|███████▋  | 407/532 [13:25<04:09,  1.99s/it]predicting train subjects:  77%|███████▋  | 408/532 [13:27<04:00,  1.94s/it]predicting train subjects:  77%|███████▋  | 409/532 [13:29<03:57,  1.93s/it]predicting train subjects:  77%|███████▋  | 410/532 [13:31<03:49,  1.88s/it]predicting train subjects:  77%|███████▋  | 411/532 [13:32<03:46,  1.87s/it]predicting train subjects:  77%|███████▋  | 412/532 [13:34<03:40,  1.84s/it]predicting train subjects:  78%|███████▊  | 413/532 [13:36<03:34,  1.80s/it]predicting train subjects:  78%|███████▊  | 414/532 [13:38<03:32,  1.80s/it]predicting train subjects:  78%|███████▊  | 415/532 [13:39<03:27,  1.78s/it]predicting train subjects:  78%|███████▊  | 416/532 [13:41<03:24,  1.76s/it]predicting train subjects:  78%|███████▊  | 417/532 [13:43<03:26,  1.80s/it]predicting train subjects:  79%|███████▊  | 418/532 [13:45<03:22,  1.78s/it]predicting train subjects:  79%|███████▉  | 419/532 [13:47<03:28,  1.84s/it]predicting train subjects:  79%|███████▉  | 420/532 [13:49<03:33,  1.90s/it]predicting train subjects:  79%|███████▉  | 421/532 [13:51<03:34,  1.94s/it]predicting train subjects:  79%|███████▉  | 422/532 [13:53<03:34,  1.95s/it]predicting train subjects:  80%|███████▉  | 423/532 [13:55<03:32,  1.95s/it]predicting train subjects:  80%|███████▉  | 424/532 [13:57<03:29,  1.94s/it]predicting train subjects:  80%|███████▉  | 425/532 [13:59<03:29,  1.96s/it]predicting train subjects:  80%|████████  | 426/532 [14:01<03:27,  1.96s/it]predicting train subjects:  80%|████████  | 427/532 [14:03<03:32,  2.03s/it]predicting train subjects:  80%|████████  | 428/532 [14:05<03:31,  2.04s/it]predicting train subjects:  81%|████████  | 429/532 [14:07<03:34,  2.08s/it]predicting train subjects:  81%|████████  | 430/532 [14:09<03:29,  2.05s/it]predicting train subjects:  81%|████████  | 431/532 [14:11<03:28,  2.07s/it]predicting train subjects:  81%|████████  | 432/532 [14:13<03:30,  2.10s/it]predicting train subjects:  81%|████████▏ | 433/532 [14:16<03:33,  2.16s/it]predicting train subjects:  82%|████████▏ | 434/532 [14:18<03:31,  2.15s/it]predicting train subjects:  82%|████████▏ | 435/532 [14:20<03:26,  2.13s/it]predicting train subjects:  82%|████████▏ | 436/532 [14:22<03:25,  2.15s/it]predicting train subjects:  82%|████████▏ | 437/532 [14:24<03:08,  1.98s/it]predicting train subjects:  82%|████████▏ | 438/532 [14:25<02:55,  1.87s/it]predicting train subjects:  83%|████████▎ | 439/532 [14:27<02:48,  1.82s/it]predicting train subjects:  83%|████████▎ | 440/532 [14:28<02:40,  1.74s/it]predicting train subjects:  83%|████████▎ | 441/532 [14:30<02:31,  1.67s/it]predicting train subjects:  83%|████████▎ | 442/532 [14:32<02:27,  1.64s/it]predicting train subjects:  83%|████████▎ | 443/532 [14:33<02:22,  1.60s/it]predicting train subjects:  83%|████████▎ | 444/532 [14:35<02:19,  1.59s/it]predicting train subjects:  84%|████████▎ | 445/532 [14:36<02:17,  1.58s/it]predicting train subjects:  84%|████████▍ | 446/532 [14:38<02:11,  1.53s/it]predicting train subjects:  84%|████████▍ | 447/532 [14:39<02:09,  1.52s/it]predicting train subjects:  84%|████████▍ | 448/532 [14:41<02:06,  1.51s/it]predicting train subjects:  84%|████████▍ | 449/532 [14:42<02:10,  1.57s/it]predicting train subjects:  85%|████████▍ | 450/532 [14:44<02:13,  1.63s/it]predicting train subjects:  85%|████████▍ | 451/532 [14:46<02:15,  1.67s/it]predicting train subjects:  85%|████████▍ | 452/532 [14:47<02:13,  1.66s/it]predicting train subjects:  85%|████████▌ | 453/532 [14:49<02:10,  1.66s/it]predicting train subjects:  85%|████████▌ | 454/532 [14:51<02:09,  1.66s/it]predicting train subjects:  86%|████████▌ | 455/532 [14:53<02:13,  1.73s/it]predicting train subjects:  86%|████████▌ | 456/532 [14:55<02:22,  1.88s/it]predicting train subjects:  86%|████████▌ | 457/532 [14:57<02:22,  1.90s/it]predicting train subjects:  86%|████████▌ | 458/532 [14:59<02:22,  1.92s/it]predicting train subjects:  86%|████████▋ | 459/532 [15:01<02:22,  1.95s/it]predicting train subjects:  86%|████████▋ | 460/532 [15:03<02:20,  1.95s/it]predicting train subjects:  87%|████████▋ | 461/532 [15:05<02:26,  2.06s/it]predicting train subjects:  87%|████████▋ | 462/532 [15:07<02:28,  2.13s/it]predicting train subjects:  87%|████████▋ | 463/532 [15:10<02:29,  2.17s/it]predicting train subjects:  87%|████████▋ | 464/532 [15:12<02:31,  2.23s/it]predicting train subjects:  87%|████████▋ | 465/532 [15:14<02:33,  2.29s/it]predicting train subjects:  88%|████████▊ | 466/532 [15:17<02:32,  2.30s/it]predicting train subjects:  88%|████████▊ | 467/532 [15:19<02:21,  2.17s/it]predicting train subjects:  88%|████████▊ | 468/532 [15:21<02:13,  2.09s/it]predicting train subjects:  88%|████████▊ | 469/532 [15:22<02:06,  2.01s/it]predicting train subjects:  88%|████████▊ | 470/532 [15:24<02:00,  1.95s/it]predicting train subjects:  89%|████████▊ | 471/532 [15:26<01:55,  1.90s/it]predicting train subjects:  89%|████████▊ | 472/532 [15:28<01:52,  1.87s/it]predicting train subjects:  89%|████████▉ | 473/532 [15:30<01:53,  1.92s/it]predicting train subjects:  89%|████████▉ | 474/532 [15:32<01:51,  1.93s/it]predicting train subjects:  89%|████████▉ | 475/532 [15:34<01:50,  1.93s/it]predicting train subjects:  89%|████████▉ | 476/532 [15:36<01:48,  1.94s/it]predicting train subjects:  90%|████████▉ | 477/532 [15:38<01:45,  1.92s/it]predicting train subjects:  90%|████████▉ | 478/532 [15:39<01:44,  1.93s/it]predicting train subjects:  90%|█████████ | 479/532 [15:41<01:39,  1.88s/it]predicting train subjects:  90%|█████████ | 480/532 [15:43<01:35,  1.83s/it]predicting train subjects:  90%|█████████ | 481/532 [15:45<01:32,  1.82s/it]predicting train subjects:  91%|█████████ | 482/532 [15:46<01:28,  1.77s/it]predicting train subjects:  91%|█████████ | 483/532 [15:48<01:26,  1.76s/it]predicting train subjects:  91%|█████████ | 484/532 [15:50<01:23,  1.73s/it]predicting train subjects:  91%|█████████ | 485/532 [15:52<01:27,  1.87s/it]predicting train subjects:  91%|█████████▏| 486/532 [15:54<01:32,  2.00s/it]predicting train subjects:  92%|█████████▏| 487/532 [15:57<01:34,  2.10s/it]predicting train subjects:  92%|█████████▏| 488/532 [15:59<01:34,  2.14s/it]predicting train subjects:  92%|█████████▏| 489/532 [16:01<01:34,  2.19s/it]predicting train subjects:  92%|█████████▏| 490/532 [16:03<01:31,  2.19s/it]predicting train subjects:  92%|█████████▏| 491/532 [16:05<01:25,  2.09s/it]predicting train subjects:  92%|█████████▏| 492/532 [16:07<01:20,  2.01s/it]predicting train subjects:  93%|█████████▎| 493/532 [16:09<01:15,  1.94s/it]predicting train subjects:  93%|█████████▎| 494/532 [16:11<01:13,  1.92s/it]predicting train subjects:  93%|█████████▎| 495/532 [16:13<01:09,  1.89s/it]predicting train subjects:  93%|█████████▎| 496/532 [16:14<01:08,  1.89s/it]predicting train subjects:  93%|█████████▎| 497/532 [16:16<01:06,  1.91s/it]predicting train subjects:  94%|█████████▎| 498/532 [16:18<01:05,  1.94s/it]predicting train subjects:  94%|█████████▍| 499/532 [16:21<01:06,  2.00s/it]predicting train subjects:  94%|█████████▍| 500/532 [16:23<01:07,  2.11s/it]predicting train subjects:  94%|█████████▍| 501/532 [16:25<01:06,  2.14s/it]predicting train subjects:  94%|█████████▍| 502/532 [16:27<01:04,  2.16s/it]predicting train subjects:  95%|█████████▍| 503/532 [16:29<01:02,  2.15s/it]predicting train subjects:  95%|█████████▍| 504/532 [16:31<00:58,  2.08s/it]predicting train subjects:  95%|█████████▍| 505/532 [16:33<00:54,  2.01s/it]predicting train subjects:  95%|█████████▌| 506/532 [16:35<00:51,  2.00s/it]predicting train subjects:  95%|█████████▌| 507/532 [16:37<00:49,  2.00s/it]predicting train subjects:  95%|█████████▌| 508/532 [16:39<00:48,  2.00s/it]predicting train subjects:  96%|█████████▌| 509/532 [16:42<00:49,  2.17s/it]predicting train subjects:  96%|█████████▌| 510/532 [16:44<00:50,  2.29s/it]predicting train subjects:  96%|█████████▌| 511/532 [16:47<00:48,  2.31s/it]predicting train subjects:  96%|█████████▌| 512/532 [16:49<00:48,  2.42s/it]predicting train subjects:  96%|█████████▋| 513/532 [16:52<00:45,  2.38s/it]predicting train subjects:  97%|█████████▋| 514/532 [16:54<00:42,  2.39s/it]predicting train subjects:  97%|█████████▋| 515/532 [16:56<00:38,  2.29s/it]predicting train subjects:  97%|█████████▋| 516/532 [16:58<00:35,  2.21s/it]predicting train subjects:  97%|█████████▋| 517/532 [17:00<00:32,  2.17s/it]predicting train subjects:  97%|█████████▋| 518/532 [17:02<00:30,  2.16s/it]predicting train subjects:  98%|█████████▊| 519/532 [17:04<00:27,  2.10s/it]predicting train subjects:  98%|█████████▊| 520/532 [17:06<00:25,  2.09s/it]predicting train subjects:  98%|█████████▊| 521/532 [17:09<00:23,  2.17s/it]predicting train subjects:  98%|█████████▊| 522/532 [17:11<00:21,  2.17s/it]predicting train subjects:  98%|█████████▊| 523/532 [17:13<00:19,  2.18s/it]predicting train subjects:  98%|█████████▊| 524/532 [17:15<00:17,  2.19s/it]predicting train subjects:  99%|█████████▊| 525/532 [17:18<00:15,  2.22s/it]predicting train subjects:  99%|█████████▉| 526/532 [17:20<00:12,  2.16s/it]predicting train subjects:  99%|█████████▉| 527/532 [17:22<00:10,  2.11s/it]predicting train subjects:  99%|█████████▉| 528/532 [17:24<00:08,  2.05s/it]predicting train subjects:  99%|█████████▉| 529/532 [17:26<00:06,  2.04s/it]predicting train subjects: 100%|█████████▉| 530/532 [17:28<00:04,  2.06s/it]predicting train subjects: 100%|█████████▉| 531/532 [17:30<00:02,  2.01s/it]predicting train subjects: 100%|██████████| 532/532 [17:32<00:00,  2.00s/it]
Loading train:   0%|          | 0/532 [00:00<?, ?it/s]Loading train:   0%|          | 1/532 [00:01<15:18,  1.73s/it]Loading train:   0%|          | 2/532 [00:03<14:21,  1.63s/it]Loading train:   1%|          | 3/532 [00:04<14:17,  1.62s/it]Loading train:   1%|          | 4/532 [00:06<14:12,  1.62s/it]Loading train:   1%|          | 5/532 [00:08<14:21,  1.63s/it]Loading train:   1%|          | 6/532 [00:10<15:40,  1.79s/it]Loading train:   1%|▏         | 7/532 [00:11<15:06,  1.73s/it]Loading train:   2%|▏         | 8/532 [00:13<14:49,  1.70s/it]Loading train:   2%|▏         | 9/532 [00:15<14:46,  1.70s/it]Loading train:   2%|▏         | 10/532 [00:16<14:12,  1.63s/it]Loading train:   2%|▏         | 11/532 [00:18<13:51,  1.60s/it]Loading train:   2%|▏         | 12/532 [00:19<14:28,  1.67s/it]Loading train:   2%|▏         | 13/532 [00:21<15:04,  1.74s/it]Loading train:   3%|▎         | 14/532 [00:23<15:09,  1.76s/it]Loading train:   3%|▎         | 15/532 [00:25<14:25,  1.67s/it]Loading train:   3%|▎         | 16/532 [00:26<14:09,  1.65s/it]Loading train:   3%|▎         | 17/532 [00:28<13:40,  1.59s/it]Loading train:   3%|▎         | 18/532 [00:29<13:27,  1.57s/it]Loading train:   4%|▎         | 19/532 [00:31<13:02,  1.53s/it]Loading train:   4%|▍         | 20/532 [00:32<13:13,  1.55s/it]Loading train:   4%|▍         | 21/532 [00:35<15:12,  1.79s/it]Loading train:   4%|▍         | 22/532 [00:36<14:47,  1.74s/it]Loading train:   4%|▍         | 23/532 [00:38<14:33,  1.72s/it]Loading train:   5%|▍         | 24/532 [00:40<14:40,  1.73s/it]Loading train:   5%|▍         | 25/532 [00:42<15:11,  1.80s/it]Loading train:   5%|▍         | 26/532 [00:43<15:25,  1.83s/it]Loading train:   5%|▌         | 27/532 [00:45<15:49,  1.88s/it]Loading train:   5%|▌         | 28/532 [00:47<14:36,  1.74s/it]Loading train:   5%|▌         | 29/532 [00:48<13:57,  1.66s/it]Loading train:   6%|▌         | 30/532 [00:50<13:41,  1.64s/it]Loading train:   6%|▌         | 31/532 [00:51<13:17,  1.59s/it]Loading train:   6%|▌         | 32/532 [00:53<13:39,  1.64s/it]Loading train:   6%|▌         | 33/532 [00:55<14:12,  1.71s/it]Loading train:   6%|▋         | 34/532 [00:58<16:19,  1.97s/it]Loading train:   7%|▋         | 35/532 [00:59<15:42,  1.90s/it]Loading train:   7%|▋         | 36/532 [01:01<15:30,  1.88s/it]Loading train:   7%|▋         | 37/532 [01:03<14:30,  1.76s/it]Loading train:   7%|▋         | 38/532 [01:05<14:56,  1.82s/it]Loading train:   7%|▋         | 39/532 [01:06<14:56,  1.82s/it]Loading train:   8%|▊         | 40/532 [01:08<13:31,  1.65s/it]Loading train:   8%|▊         | 41/532 [01:10<14:04,  1.72s/it]Loading train:   8%|▊         | 42/532 [01:11<14:39,  1.80s/it]Loading train:   8%|▊         | 43/532 [01:13<14:30,  1.78s/it]Loading train:   8%|▊         | 44/532 [01:15<14:26,  1.78s/it]Loading train:   8%|▊         | 45/532 [01:17<14:13,  1.75s/it]Loading train:   9%|▊         | 46/532 [01:18<13:47,  1.70s/it]Loading train:   9%|▉         | 47/532 [01:21<15:43,  1.94s/it]Loading train:   9%|▉         | 48/532 [01:23<15:36,  1.93s/it]Loading train:   9%|▉         | 49/532 [01:24<14:15,  1.77s/it]Loading train:   9%|▉         | 50/532 [01:26<13:40,  1.70s/it]Loading train:  10%|▉         | 51/532 [01:27<13:15,  1.65s/it]Loading train:  10%|▉         | 52/532 [01:29<13:36,  1.70s/it]Loading train:  10%|▉         | 53/532 [01:31<13:25,  1.68s/it]Loading train:  10%|█         | 54/532 [01:33<14:59,  1.88s/it]Loading train:  10%|█         | 55/532 [01:35<15:37,  1.96s/it]Loading train:  11%|█         | 56/532 [01:37<14:33,  1.84s/it]Loading train:  11%|█         | 57/532 [01:38<13:30,  1.71s/it]Loading train:  11%|█         | 58/532 [01:40<14:03,  1.78s/it]Loading train:  11%|█         | 59/532 [01:42<15:18,  1.94s/it]Loading train:  11%|█▏        | 60/532 [01:44<14:23,  1.83s/it]Loading train:  11%|█▏        | 61/532 [01:45<13:32,  1.72s/it]Loading train:  12%|█▏        | 62/532 [01:47<14:15,  1.82s/it]Loading train:  12%|█▏        | 63/532 [01:49<14:36,  1.87s/it]Loading train:  12%|█▏        | 64/532 [01:51<14:17,  1.83s/it]Loading train:  12%|█▏        | 65/532 [01:53<13:21,  1.72s/it]Loading train:  12%|█▏        | 66/532 [01:55<14:05,  1.81s/it]Loading train:  13%|█▎        | 67/532 [01:56<14:05,  1.82s/it]Loading train:  13%|█▎        | 68/532 [01:58<14:18,  1.85s/it]Loading train:  13%|█▎        | 69/532 [02:00<13:36,  1.76s/it]Loading train:  13%|█▎        | 70/532 [02:02<13:19,  1.73s/it]Loading train:  13%|█▎        | 71/532 [02:03<12:16,  1.60s/it]Loading train:  14%|█▎        | 72/532 [02:04<11:30,  1.50s/it]Loading train:  14%|█▎        | 73/532 [02:06<12:38,  1.65s/it]Loading train:  14%|█▍        | 74/532 [02:08<13:45,  1.80s/it]Loading train:  14%|█▍        | 75/532 [02:11<14:52,  1.95s/it]Loading train:  14%|█▍        | 76/532 [02:13<14:37,  1.92s/it]Loading train:  14%|█▍        | 77/532 [02:14<14:20,  1.89s/it]Loading train:  15%|█▍        | 78/532 [02:16<14:02,  1.86s/it]Loading train:  15%|█▍        | 79/532 [02:17<12:51,  1.70s/it]Loading train:  15%|█▌        | 80/532 [02:19<12:45,  1.69s/it]Loading train:  15%|█▌        | 81/532 [02:21<12:31,  1.67s/it]Loading train:  15%|█▌        | 82/532 [02:22<12:31,  1.67s/it]Loading train:  16%|█▌        | 83/532 [02:24<12:01,  1.61s/it]Loading train:  16%|█▌        | 84/532 [02:25<11:24,  1.53s/it]Loading train:  16%|█▌        | 85/532 [02:27<11:07,  1.49s/it]Loading train:  16%|█▌        | 86/532 [02:28<11:12,  1.51s/it]Loading train:  16%|█▋        | 87/532 [02:30<11:23,  1.54s/it]Loading train:  17%|█▋        | 88/532 [02:31<10:58,  1.48s/it]Loading train:  17%|█▋        | 89/532 [02:33<10:59,  1.49s/it]Loading train:  17%|█▋        | 90/532 [02:34<11:12,  1.52s/it]Loading train:  17%|█▋        | 91/532 [02:36<11:21,  1.55s/it]Loading train:  17%|█▋        | 92/532 [02:37<10:51,  1.48s/it]Loading train:  17%|█▋        | 93/532 [02:39<11:05,  1.52s/it]Loading train:  18%|█▊        | 94/532 [02:41<11:40,  1.60s/it]Loading train:  18%|█▊        | 95/532 [02:42<11:56,  1.64s/it]Loading train:  18%|█▊        | 96/532 [02:44<12:49,  1.76s/it]Loading train:  18%|█▊        | 97/532 [02:46<13:13,  1.82s/it]Loading train:  18%|█▊        | 98/532 [02:48<13:01,  1.80s/it]Loading train:  19%|█▊        | 99/532 [02:50<12:47,  1.77s/it]Loading train:  19%|█▉        | 100/532 [02:51<12:36,  1.75s/it]Loading train:  19%|█▉        | 101/532 [02:53<13:13,  1.84s/it]Loading train:  19%|█▉        | 102/532 [02:56<14:05,  1.97s/it]Loading train:  19%|█▉        | 103/532 [02:58<14:12,  1.99s/it]Loading train:  20%|█▉        | 104/532 [02:59<12:50,  1.80s/it]Loading train:  20%|█▉        | 105/532 [03:01<12:24,  1.74s/it]Loading train:  20%|█▉        | 106/532 [03:02<11:50,  1.67s/it]Loading train:  20%|██        | 107/532 [03:04<11:47,  1.66s/it]Loading train:  20%|██        | 108/532 [03:06<12:12,  1.73s/it]Loading train:  20%|██        | 109/532 [03:07<11:54,  1.69s/it]Loading train:  21%|██        | 110/532 [03:09<11:54,  1.69s/it]Loading train:  21%|██        | 111/532 [03:11<11:24,  1.63s/it]Loading train:  21%|██        | 112/532 [03:12<11:28,  1.64s/it]Loading train:  21%|██        | 113/532 [03:14<11:37,  1.66s/it]Loading train:  21%|██▏       | 114/532 [03:16<11:47,  1.69s/it]Loading train:  22%|██▏       | 115/532 [03:17<11:34,  1.67s/it]Loading train:  22%|██▏       | 116/532 [03:19<11:42,  1.69s/it]Loading train:  22%|██▏       | 117/532 [03:21<12:17,  1.78s/it]Loading train:  22%|██▏       | 118/532 [03:22<11:35,  1.68s/it]Loading train:  22%|██▏       | 119/532 [03:24<11:26,  1.66s/it]Loading train:  23%|██▎       | 120/532 [03:25<10:50,  1.58s/it]Loading train:  23%|██▎       | 121/532 [03:28<12:01,  1.76s/it]Loading train:  23%|██▎       | 122/532 [03:29<11:42,  1.71s/it]Loading train:  23%|██▎       | 123/532 [03:31<11:18,  1.66s/it]Loading train:  23%|██▎       | 124/532 [03:33<11:24,  1.68s/it]Loading train:  23%|██▎       | 125/532 [03:35<11:58,  1.77s/it]Loading train:  24%|██▎       | 126/532 [03:37<12:53,  1.91s/it]Loading train:  24%|██▍       | 127/532 [03:38<12:23,  1.84s/it]Loading train:  24%|██▍       | 128/532 [03:40<11:48,  1.75s/it]Loading train:  24%|██▍       | 129/532 [03:42<11:25,  1.70s/it]Loading train:  24%|██▍       | 130/532 [03:43<11:40,  1.74s/it]Loading train:  25%|██▍       | 131/532 [03:45<12:01,  1.80s/it]Loading train:  25%|██▍       | 132/532 [03:47<12:30,  1.88s/it]Loading train:  25%|██▌       | 133/532 [03:49<12:14,  1.84s/it]Loading train:  25%|██▌       | 134/532 [03:51<11:50,  1.78s/it]Loading train:  25%|██▌       | 135/532 [03:53<11:59,  1.81s/it]Loading train:  26%|██▌       | 136/532 [03:55<12:41,  1.92s/it]Loading train:  26%|██▌       | 137/532 [03:57<12:21,  1.88s/it]Loading train:  26%|██▌       | 138/532 [03:59<12:48,  1.95s/it]Loading train:  26%|██▌       | 139/532 [04:01<12:24,  1.90s/it]Loading train:  26%|██▋       | 140/532 [04:03<13:06,  2.01s/it]Loading train:  27%|██▋       | 141/532 [04:05<12:47,  1.96s/it]Loading train:  27%|██▋       | 142/532 [04:07<12:39,  1.95s/it]Loading train:  27%|██▋       | 143/532 [04:08<11:51,  1.83s/it]Loading train:  27%|██▋       | 144/532 [04:10<11:26,  1.77s/it]Loading train:  27%|██▋       | 145/532 [04:11<10:50,  1.68s/it]Loading train:  27%|██▋       | 146/532 [04:13<10:57,  1.70s/it]Loading train:  28%|██▊       | 147/532 [04:15<11:00,  1.72s/it]Loading train:  28%|██▊       | 148/532 [04:16<10:56,  1.71s/it]Loading train:  28%|██▊       | 149/532 [04:18<11:11,  1.75s/it]Loading train:  28%|██▊       | 150/532 [04:20<11:03,  1.74s/it]Loading train:  28%|██▊       | 151/532 [04:21<10:23,  1.64s/it]Loading train:  29%|██▊       | 152/532 [04:23<10:11,  1.61s/it]Loading train:  29%|██▉       | 153/532 [04:25<10:36,  1.68s/it]Loading train:  29%|██▉       | 154/532 [04:27<10:46,  1.71s/it]Loading train:  29%|██▉       | 155/532 [04:28<11:05,  1.77s/it]Loading train:  29%|██▉       | 156/532 [04:30<10:53,  1.74s/it]Loading train:  30%|██▉       | 157/532 [04:32<11:08,  1.78s/it]Loading train:  30%|██▉       | 158/532 [04:34<11:55,  1.91s/it]Loading train:  30%|██▉       | 159/532 [04:36<12:10,  1.96s/it]Loading train:  30%|███       | 160/532 [04:38<11:40,  1.88s/it]Loading train:  30%|███       | 161/532 [04:40<11:09,  1.80s/it]Loading train:  30%|███       | 162/532 [04:41<10:32,  1.71s/it]Loading train:  31%|███       | 163/532 [04:43<10:20,  1.68s/it]Loading train:  31%|███       | 164/532 [04:44<09:53,  1.61s/it]Loading train:  31%|███       | 165/532 [04:46<10:09,  1.66s/it]Loading train:  31%|███       | 166/532 [04:48<10:04,  1.65s/it]Loading train:  31%|███▏      | 167/532 [04:49<10:23,  1.71s/it]Loading train:  32%|███▏      | 168/532 [04:51<10:44,  1.77s/it]Loading train:  32%|███▏      | 169/532 [04:53<10:34,  1.75s/it]Loading train:  32%|███▏      | 170/532 [04:55<10:24,  1.73s/it]Loading train:  32%|███▏      | 171/532 [04:56<09:43,  1.62s/it]Loading train:  32%|███▏      | 172/532 [04:58<09:39,  1.61s/it]Loading train:  33%|███▎      | 173/532 [05:00<10:08,  1.69s/it]Loading train:  33%|███▎      | 174/532 [05:01<09:41,  1.62s/it]Loading train:  33%|███▎      | 175/532 [05:03<10:09,  1.71s/it]Loading train:  33%|███▎      | 176/532 [05:05<10:27,  1.76s/it]Loading train:  33%|███▎      | 177/532 [05:07<10:56,  1.85s/it]Loading train:  33%|███▎      | 178/532 [05:09<10:46,  1.83s/it]Loading train:  34%|███▎      | 179/532 [05:10<10:23,  1.77s/it]Loading train:  34%|███▍      | 180/532 [05:12<10:26,  1.78s/it]Loading train:  34%|███▍      | 181/532 [05:14<10:37,  1.82s/it]Loading train:  34%|███▍      | 182/532 [05:16<10:15,  1.76s/it]Loading train:  34%|███▍      | 183/532 [05:18<10:37,  1.83s/it]Loading train:  35%|███▍      | 184/532 [05:20<11:03,  1.91s/it]Loading train:  35%|███▍      | 185/532 [05:22<12:13,  2.11s/it]Loading train:  35%|███▍      | 186/532 [05:24<11:31,  2.00s/it]Loading train:  35%|███▌      | 187/532 [05:26<12:05,  2.10s/it]Loading train:  35%|███▌      | 188/532 [05:28<12:11,  2.13s/it]Loading train:  36%|███▌      | 189/532 [05:31<12:14,  2.14s/it]Loading train:  36%|███▌      | 190/532 [05:33<12:03,  2.12s/it]Loading train:  36%|███▌      | 191/532 [05:36<13:15,  2.33s/it]Loading train:  36%|███▌      | 192/532 [05:38<14:12,  2.51s/it]Loading train:  36%|███▋      | 193/532 [05:42<15:29,  2.74s/it]Loading train:  36%|███▋      | 194/532 [05:45<15:44,  2.80s/it]Loading train:  37%|███▋      | 195/532 [05:47<15:26,  2.75s/it]Loading train:  37%|███▋      | 196/532 [05:49<14:23,  2.57s/it]Loading train:  37%|███▋      | 197/532 [05:51<13:14,  2.37s/it]Loading train:  37%|███▋      | 198/532 [05:54<12:47,  2.30s/it]Loading train:  37%|███▋      | 199/532 [05:56<12:34,  2.27s/it]Loading train:  38%|███▊      | 200/532 [05:58<12:41,  2.29s/it]Loading train:  38%|███▊      | 201/532 [06:00<12:49,  2.33s/it]Loading train:  38%|███▊      | 202/532 [06:03<13:53,  2.53s/it]Loading train:  38%|███▊      | 203/532 [06:05<12:49,  2.34s/it]Loading train:  38%|███▊      | 204/532 [06:08<12:47,  2.34s/it]Loading train:  39%|███▊      | 205/532 [06:10<13:10,  2.42s/it]Loading train:  39%|███▊      | 206/532 [06:13<13:12,  2.43s/it]Loading train:  39%|███▉      | 207/532 [06:15<13:08,  2.43s/it]Loading train:  39%|███▉      | 208/532 [06:17<12:32,  2.32s/it]Loading train:  39%|███▉      | 209/532 [06:19<11:48,  2.19s/it]Loading train:  39%|███▉      | 210/532 [06:21<11:02,  2.06s/it]Loading train:  40%|███▉      | 211/532 [06:22<10:02,  1.88s/it]Loading train:  40%|███▉      | 212/532 [06:25<10:42,  2.01s/it]Loading train:  40%|████      | 213/532 [06:27<10:40,  2.01s/it]Loading train:  40%|████      | 214/532 [06:28<10:13,  1.93s/it]Loading train:  40%|████      | 215/532 [06:31<11:29,  2.17s/it]Loading train:  41%|████      | 216/532 [06:34<12:13,  2.32s/it]Loading train:  41%|████      | 217/532 [06:36<12:41,  2.42s/it]Loading train:  41%|████      | 218/532 [06:40<13:50,  2.64s/it]Loading train:  41%|████      | 219/532 [06:42<13:55,  2.67s/it]Loading train:  41%|████▏     | 220/532 [06:45<13:19,  2.56s/it]Loading train:  42%|████▏     | 221/532 [06:47<13:12,  2.55s/it]Loading train:  42%|████▏     | 222/532 [06:50<12:49,  2.48s/it]Loading train:  42%|████▏     | 223/532 [06:52<13:03,  2.53s/it]Loading train:  42%|████▏     | 224/532 [06:55<12:52,  2.51s/it]Loading train:  42%|████▏     | 225/532 [06:57<12:41,  2.48s/it]Loading train:  42%|████▏     | 226/532 [07:00<12:45,  2.50s/it]Loading train:  43%|████▎     | 227/532 [07:02<12:37,  2.48s/it]Loading train:  43%|████▎     | 228/532 [07:04<12:00,  2.37s/it]Loading train:  43%|████▎     | 229/532 [07:07<12:41,  2.51s/it]Loading train:  43%|████▎     | 230/532 [07:09<12:25,  2.47s/it]Loading train:  43%|████▎     | 231/532 [07:11<11:50,  2.36s/it]Loading train:  44%|████▎     | 232/532 [07:13<11:12,  2.24s/it]Loading train:  44%|████▍     | 233/532 [07:16<12:00,  2.41s/it]Loading train:  44%|████▍     | 234/532 [07:18<11:02,  2.22s/it]Loading train:  44%|████▍     | 235/532 [07:20<10:57,  2.21s/it]Loading train:  44%|████▍     | 236/532 [07:23<11:35,  2.35s/it]Loading train:  45%|████▍     | 237/532 [07:26<12:33,  2.56s/it]Loading train:  45%|████▍     | 238/532 [07:28<11:52,  2.42s/it]Loading train:  45%|████▍     | 239/532 [07:31<12:03,  2.47s/it]Loading train:  45%|████▌     | 240/532 [07:33<11:36,  2.39s/it]Loading train:  45%|████▌     | 241/532 [07:35<11:41,  2.41s/it]Loading train:  45%|████▌     | 242/532 [07:38<11:36,  2.40s/it]Loading train:  46%|████▌     | 243/532 [07:40<11:37,  2.41s/it]Loading train:  46%|████▌     | 244/532 [07:42<11:02,  2.30s/it]Loading train:  46%|████▌     | 245/532 [07:45<11:17,  2.36s/it]Loading train:  46%|████▌     | 246/532 [07:47<10:33,  2.22s/it]Loading train:  46%|████▋     | 247/532 [07:49<10:30,  2.21s/it]Loading train:  47%|████▋     | 248/532 [07:51<10:04,  2.13s/it]Loading train:  47%|████▋     | 249/532 [07:53<10:24,  2.21s/it]Loading train:  47%|████▋     | 250/532 [07:56<10:55,  2.32s/it]Loading train:  47%|████▋     | 251/532 [07:58<10:42,  2.29s/it]Loading train:  47%|████▋     | 252/532 [08:00<10:07,  2.17s/it]Loading train:  48%|████▊     | 253/532 [08:02<10:32,  2.27s/it]Loading train:  48%|████▊     | 254/532 [08:05<10:51,  2.34s/it]Loading train:  48%|████▊     | 255/532 [08:07<11:10,  2.42s/it]Loading train:  48%|████▊     | 256/532 [08:10<10:45,  2.34s/it]Loading train:  48%|████▊     | 257/532 [08:12<11:07,  2.43s/it]Loading train:  48%|████▊     | 258/532 [08:14<10:53,  2.38s/it]Loading train:  49%|████▊     | 259/532 [08:17<10:57,  2.41s/it]Loading train:  49%|████▉     | 260/532 [08:19<10:53,  2.40s/it]Loading train:  49%|████▉     | 261/532 [08:21<10:26,  2.31s/it]Loading train:  49%|████▉     | 262/532 [08:24<10:34,  2.35s/it]Loading train:  49%|████▉     | 263/532 [08:26<10:48,  2.41s/it]Loading train:  50%|████▉     | 264/532 [08:28<10:00,  2.24s/it]Loading train:  50%|████▉     | 265/532 [08:30<09:57,  2.24s/it]Loading train:  50%|█████     | 266/532 [08:32<09:13,  2.08s/it]Loading train:  50%|█████     | 267/532 [08:34<08:49,  2.00s/it]Loading train:  50%|█████     | 268/532 [08:36<09:10,  2.08s/it]Loading train:  51%|█████     | 269/532 [08:38<09:17,  2.12s/it]Loading train:  51%|█████     | 270/532 [08:41<09:13,  2.11s/it]Loading train:  51%|█████     | 271/532 [08:43<09:40,  2.22s/it]Loading train:  51%|█████     | 272/532 [08:46<10:16,  2.37s/it]Loading train:  51%|█████▏    | 273/532 [08:48<10:27,  2.42s/it]Loading train:  52%|█████▏    | 274/532 [08:50<10:05,  2.35s/it]Loading train:  52%|█████▏    | 275/532 [08:53<10:01,  2.34s/it]Loading train:  52%|█████▏    | 276/532 [08:55<10:12,  2.39s/it]Loading train:  52%|█████▏    | 277/532 [08:58<10:34,  2.49s/it]Loading train:  52%|█████▏    | 278/532 [09:00<10:14,  2.42s/it]Loading train:  52%|█████▏    | 279/532 [09:02<09:46,  2.32s/it]Loading train:  53%|█████▎    | 280/532 [09:05<09:54,  2.36s/it]Loading train:  53%|█████▎    | 281/532 [09:07<09:50,  2.35s/it]Loading train:  53%|█████▎    | 282/532 [09:09<09:17,  2.23s/it]Loading train:  53%|█████▎    | 283/532 [09:11<08:23,  2.02s/it]Loading train:  53%|█████▎    | 284/532 [09:13<09:02,  2.19s/it]Loading train:  54%|█████▎    | 285/532 [09:16<09:26,  2.29s/it]Loading train:  54%|█████▍    | 286/532 [09:18<09:49,  2.40s/it]Loading train:  54%|█████▍    | 287/532 [09:21<09:33,  2.34s/it]Loading train:  54%|█████▍    | 288/532 [09:23<09:37,  2.37s/it]Loading train:  54%|█████▍    | 289/532 [09:25<09:25,  2.33s/it]Loading train:  55%|█████▍    | 290/532 [09:27<09:17,  2.31s/it]Loading train:  55%|█████▍    | 291/532 [09:30<09:05,  2.26s/it]Loading train:  55%|█████▍    | 292/532 [09:32<09:15,  2.32s/it]Loading train:  55%|█████▌    | 293/532 [09:35<09:26,  2.37s/it]Loading train:  55%|█████▌    | 294/532 [09:37<09:31,  2.40s/it]Loading train:  55%|█████▌    | 295/532 [09:39<08:44,  2.21s/it]Loading train:  56%|█████▌    | 296/532 [09:41<08:33,  2.17s/it]Loading train:  56%|█████▌    | 297/532 [09:43<08:52,  2.27s/it]Loading train:  56%|█████▌    | 298/532 [09:45<08:33,  2.20s/it]Loading train:  56%|█████▌    | 299/532 [09:48<08:35,  2.21s/it]Loading train:  56%|█████▋    | 300/532 [09:50<08:45,  2.26s/it]Loading train:  57%|█████▋    | 301/532 [09:52<08:38,  2.25s/it]Loading train:  57%|█████▋    | 302/532 [09:54<08:19,  2.17s/it]Loading train:  57%|█████▋    | 303/532 [09:56<07:39,  2.01s/it]Loading train:  57%|█████▋    | 304/532 [09:57<07:04,  1.86s/it]Loading train:  57%|█████▋    | 305/532 [10:00<08:22,  2.21s/it]Loading train:  58%|█████▊    | 306/532 [10:03<08:48,  2.34s/it]Loading train:  58%|█████▊    | 307/532 [10:06<09:13,  2.46s/it]Loading train:  58%|█████▊    | 308/532 [10:08<09:15,  2.48s/it]Loading train:  58%|█████▊    | 309/532 [10:11<09:45,  2.63s/it]Loading train:  58%|█████▊    | 310/532 [10:14<09:16,  2.51s/it]Loading train:  58%|█████▊    | 311/532 [10:17<10:09,  2.76s/it]Loading train:  59%|█████▊    | 312/532 [10:19<09:56,  2.71s/it]Loading train:  59%|█████▉    | 313/532 [10:23<10:17,  2.82s/it]Loading train:  59%|█████▉    | 314/532 [10:26<11:18,  3.11s/it]Loading train:  59%|█████▉    | 315/532 [10:29<10:59,  3.04s/it]Loading train:  59%|█████▉    | 316/532 [10:32<11:05,  3.08s/it]Loading train:  60%|█████▉    | 317/532 [10:35<10:34,  2.95s/it]Loading train:  60%|█████▉    | 318/532 [10:37<09:37,  2.70s/it]Loading train:  60%|█████▉    | 319/532 [10:39<08:27,  2.38s/it]Loading train:  60%|██████    | 320/532 [10:40<07:36,  2.15s/it]Loading train:  60%|██████    | 321/532 [10:43<07:34,  2.16s/it]Loading train:  61%|██████    | 322/532 [10:45<07:20,  2.10s/it]Loading train:  61%|██████    | 323/532 [10:47<07:47,  2.24s/it]Loading train:  61%|██████    | 324/532 [10:50<07:57,  2.30s/it]Loading train:  61%|██████    | 325/532 [10:53<08:41,  2.52s/it]Loading train:  61%|██████▏   | 326/532 [10:56<10:00,  2.91s/it]Loading train:  61%|██████▏   | 327/532 [10:59<09:08,  2.68s/it]Loading train:  62%|██████▏   | 328/532 [11:01<09:10,  2.70s/it]Loading train:  62%|██████▏   | 329/532 [11:04<08:44,  2.59s/it]Loading train:  62%|██████▏   | 330/532 [11:06<08:18,  2.47s/it]Loading train:  62%|██████▏   | 331/532 [11:08<07:40,  2.29s/it]Loading train:  62%|██████▏   | 332/532 [11:10<07:13,  2.17s/it]Loading train:  63%|██████▎   | 333/532 [11:12<07:18,  2.20s/it]Loading train:  63%|██████▎   | 334/532 [11:14<07:18,  2.21s/it]Loading train:  63%|██████▎   | 335/532 [11:17<07:32,  2.29s/it]Loading train:  63%|██████▎   | 336/532 [11:18<07:06,  2.17s/it]Loading train:  63%|██████▎   | 337/532 [11:21<06:56,  2.13s/it]Loading train:  64%|██████▎   | 338/532 [11:23<07:07,  2.20s/it]Loading train:  64%|██████▎   | 339/532 [11:25<07:13,  2.24s/it]Loading train:  64%|██████▍   | 340/532 [11:27<06:47,  2.12s/it]Loading train:  64%|██████▍   | 341/532 [11:30<07:24,  2.33s/it]Loading train:  64%|██████▍   | 342/532 [11:32<06:58,  2.20s/it]Loading train:  64%|██████▍   | 343/532 [11:34<07:18,  2.32s/it]Loading train:  65%|██████▍   | 344/532 [11:37<07:13,  2.30s/it]Loading train:  65%|██████▍   | 345/532 [11:39<06:59,  2.24s/it]Loading train:  65%|██████▌   | 346/532 [11:41<07:02,  2.27s/it]Loading train:  65%|██████▌   | 347/532 [11:43<06:58,  2.26s/it]Loading train:  65%|██████▌   | 348/532 [11:46<07:01,  2.29s/it]Loading train:  66%|██████▌   | 349/532 [11:47<06:22,  2.09s/it]Loading train:  66%|██████▌   | 350/532 [11:49<05:57,  1.96s/it]Loading train:  66%|██████▌   | 351/532 [11:51<06:00,  1.99s/it]Loading train:  66%|██████▌   | 352/532 [11:53<06:02,  2.02s/it]Loading train:  66%|██████▋   | 353/532 [11:55<05:57,  2.00s/it]Loading train:  67%|██████▋   | 354/532 [11:57<06:00,  2.03s/it]Loading train:  67%|██████▋   | 355/532 [11:59<05:57,  2.02s/it]Loading train:  67%|██████▋   | 356/532 [12:01<05:45,  1.96s/it]Loading train:  67%|██████▋   | 357/532 [12:03<05:45,  1.97s/it]Loading train:  67%|██████▋   | 358/532 [12:05<05:59,  2.06s/it]Loading train:  67%|██████▋   | 359/532 [12:07<05:46,  2.01s/it]Loading train:  68%|██████▊   | 360/532 [12:09<05:42,  1.99s/it]Loading train:  68%|██████▊   | 361/532 [12:11<05:36,  1.97s/it]Loading train:  68%|██████▊   | 362/532 [12:13<05:41,  2.01s/it]Loading train:  68%|██████▊   | 363/532 [12:15<05:30,  1.96s/it]Loading train:  68%|██████▊   | 364/532 [12:17<05:44,  2.05s/it]Loading train:  69%|██████▊   | 365/532 [12:19<05:19,  1.91s/it]Loading train:  69%|██████▉   | 366/532 [12:21<05:12,  1.88s/it]Loading train:  69%|██████▉   | 367/532 [12:23<05:21,  1.95s/it]Loading train:  69%|██████▉   | 368/532 [12:24<04:59,  1.83s/it]Loading train:  69%|██████▉   | 369/532 [12:26<04:58,  1.83s/it]Loading train:  70%|██████▉   | 370/532 [12:27<04:24,  1.63s/it]Loading train:  70%|██████▉   | 371/532 [12:29<04:38,  1.73s/it]Loading train:  70%|██████▉   | 372/532 [12:31<04:46,  1.79s/it]Loading train:  70%|███████   | 373/532 [12:34<05:14,  1.98s/it]Loading train:  70%|███████   | 374/532 [12:36<05:32,  2.10s/it]Loading train:  70%|███████   | 375/532 [12:39<05:59,  2.29s/it]Loading train:  71%|███████   | 376/532 [12:42<06:31,  2.51s/it]Loading train:  71%|███████   | 377/532 [12:44<06:04,  2.35s/it]Loading train:  71%|███████   | 378/532 [12:46<06:04,  2.36s/it]Loading train:  71%|███████   | 379/532 [12:48<05:59,  2.35s/it]Loading train:  71%|███████▏  | 380/532 [12:50<05:44,  2.27s/it]Loading train:  72%|███████▏  | 381/532 [12:52<05:06,  2.03s/it]Loading train:  72%|███████▏  | 382/532 [12:53<04:33,  1.82s/it]Loading train:  72%|███████▏  | 383/532 [12:55<04:20,  1.75s/it]Loading train:  72%|███████▏  | 384/532 [12:57<04:27,  1.81s/it]Loading train:  72%|███████▏  | 385/532 [12:59<04:43,  1.93s/it]Loading train:  73%|███████▎  | 386/532 [13:01<04:56,  2.03s/it]Loading train:  73%|███████▎  | 387/532 [13:03<04:44,  1.96s/it]Loading train:  73%|███████▎  | 388/532 [13:05<04:42,  1.96s/it]Loading train:  73%|███████▎  | 389/532 [13:07<04:52,  2.05s/it]Loading train:  73%|███████▎  | 390/532 [13:10<04:57,  2.10s/it]Loading train:  73%|███████▎  | 391/532 [13:11<04:33,  1.94s/it]Loading train:  74%|███████▎  | 392/532 [13:13<04:14,  1.82s/it]Loading train:  74%|███████▍  | 393/532 [13:14<03:54,  1.68s/it]Loading train:  74%|███████▍  | 394/532 [13:16<04:05,  1.78s/it]Loading train:  74%|███████▍  | 395/532 [13:18<04:01,  1.76s/it]Loading train:  74%|███████▍  | 396/532 [13:20<04:15,  1.88s/it]Loading train:  75%|███████▍  | 397/532 [13:22<04:09,  1.85s/it]Loading train:  75%|███████▍  | 398/532 [13:23<03:49,  1.71s/it]Loading train:  75%|███████▌  | 399/532 [13:24<03:35,  1.62s/it]Loading train:  75%|███████▌  | 400/532 [13:26<03:30,  1.60s/it]Loading train:  75%|███████▌  | 401/532 [13:28<03:26,  1.58s/it]Loading train:  76%|███████▌  | 402/532 [13:29<03:22,  1.56s/it]Loading train:  76%|███████▌  | 403/532 [13:31<03:35,  1.67s/it]Loading train:  76%|███████▌  | 404/532 [13:33<03:42,  1.74s/it]Loading train:  76%|███████▌  | 405/532 [13:34<03:25,  1.62s/it]Loading train:  76%|███████▋  | 406/532 [13:36<03:14,  1.55s/it]Loading train:  77%|███████▋  | 407/532 [13:37<03:01,  1.45s/it]Loading train:  77%|███████▋  | 408/532 [13:38<02:57,  1.43s/it]Loading train:  77%|███████▋  | 409/532 [13:40<02:56,  1.44s/it]Loading train:  77%|███████▋  | 410/532 [13:41<02:56,  1.45s/it]Loading train:  77%|███████▋  | 411/532 [13:43<02:54,  1.44s/it]Loading train:  77%|███████▋  | 412/532 [13:44<03:03,  1.53s/it]Loading train:  78%|███████▊  | 413/532 [13:46<03:23,  1.71s/it]Loading train:  78%|███████▊  | 414/532 [13:48<03:13,  1.64s/it]Loading train:  78%|███████▊  | 415/532 [13:49<02:49,  1.45s/it]Loading train:  78%|███████▊  | 416/532 [13:50<02:34,  1.33s/it]Loading train:  78%|███████▊  | 417/532 [13:51<02:37,  1.37s/it]Loading train:  79%|███████▊  | 418/532 [13:53<02:38,  1.39s/it]Loading train:  79%|███████▉  | 419/532 [13:55<02:54,  1.55s/it]Loading train:  79%|███████▉  | 420/532 [13:56<02:40,  1.43s/it]Loading train:  79%|███████▉  | 421/532 [13:57<02:27,  1.33s/it]Loading train:  79%|███████▉  | 422/532 [13:58<02:21,  1.28s/it]Loading train:  80%|███████▉  | 423/532 [13:59<02:14,  1.23s/it]Loading train:  80%|███████▉  | 424/532 [14:00<02:08,  1.19s/it]Loading train:  80%|███████▉  | 425/532 [14:01<02:04,  1.16s/it]Loading train:  80%|████████  | 426/532 [14:03<01:59,  1.13s/it]Loading train:  80%|████████  | 427/532 [14:04<01:53,  1.08s/it]Loading train:  80%|████████  | 428/532 [14:05<01:51,  1.08s/it]Loading train:  81%|████████  | 429/532 [14:06<01:52,  1.09s/it]Loading train:  81%|████████  | 430/532 [14:07<01:51,  1.09s/it]Loading train:  81%|████████  | 431/532 [14:08<01:53,  1.13s/it]Loading train:  81%|████████  | 432/532 [14:09<01:52,  1.12s/it]Loading train:  81%|████████▏ | 433/532 [14:10<01:54,  1.16s/it]Loading train:  82%|████████▏ | 434/532 [14:12<01:53,  1.16s/it]Loading train:  82%|████████▏ | 435/532 [14:13<01:52,  1.16s/it]Loading train:  82%|████████▏ | 436/532 [14:14<01:51,  1.16s/it]Loading train:  82%|████████▏ | 437/532 [14:15<01:43,  1.09s/it]Loading train:  82%|████████▏ | 438/532 [14:16<01:38,  1.05s/it]Loading train:  83%|████████▎ | 439/532 [14:17<01:32,  1.01it/s]Loading train:  83%|████████▎ | 440/532 [14:18<01:31,  1.01it/s]Loading train:  83%|████████▎ | 441/532 [14:19<01:29,  1.01it/s]Loading train:  83%|████████▎ | 442/532 [14:19<01:25,  1.05it/s]Loading train:  83%|████████▎ | 443/532 [14:20<01:23,  1.07it/s]Loading train:  83%|████████▎ | 444/532 [14:21<01:22,  1.06it/s]Loading train:  84%|████████▎ | 445/532 [14:22<01:22,  1.05it/s]Loading train:  84%|████████▍ | 446/532 [14:24<01:30,  1.05s/it]Loading train:  84%|████████▍ | 447/532 [14:25<01:27,  1.03s/it]Loading train:  84%|████████▍ | 448/532 [14:25<01:23,  1.01it/s]Loading train:  84%|████████▍ | 449/532 [14:26<01:21,  1.01it/s]Loading train:  85%|████████▍ | 450/532 [14:27<01:19,  1.03it/s]Loading train:  85%|████████▍ | 451/532 [14:28<01:18,  1.04it/s]Loading train:  85%|████████▍ | 452/532 [14:29<01:17,  1.03it/s]Loading train:  85%|████████▌ | 453/532 [14:30<01:16,  1.04it/s]Loading train:  85%|████████▌ | 454/532 [14:31<01:14,  1.05it/s]Loading train:  86%|████████▌ | 455/532 [14:32<01:15,  1.01it/s]Loading train:  86%|████████▌ | 456/532 [14:33<01:18,  1.03s/it]Loading train:  86%|████████▌ | 457/532 [14:34<01:18,  1.04s/it]Loading train:  86%|████████▌ | 458/532 [14:35<01:15,  1.02s/it]Loading train:  86%|████████▋ | 459/532 [14:36<01:15,  1.03s/it]Loading train:  86%|████████▋ | 460/532 [14:38<01:15,  1.05s/it]Loading train:  87%|████████▋ | 461/532 [14:39<01:17,  1.10s/it]Loading train:  87%|████████▋ | 462/532 [14:40<01:17,  1.11s/it]Loading train:  87%|████████▋ | 463/532 [14:41<01:17,  1.12s/it]Loading train:  87%|████████▋ | 464/532 [14:42<01:15,  1.12s/it]Loading train:  87%|████████▋ | 465/532 [14:43<01:14,  1.11s/it]Loading train:  88%|████████▊ | 466/532 [14:44<01:15,  1.14s/it]Loading train:  88%|████████▊ | 467/532 [14:45<01:10,  1.08s/it]Loading train:  88%|████████▊ | 468/532 [14:46<01:07,  1.05s/it]Loading train:  88%|████████▊ | 469/532 [14:47<01:03,  1.01s/it]Loading train:  88%|████████▊ | 470/532 [14:48<01:00,  1.02it/s]Loading train:  89%|████████▊ | 471/532 [14:49<00:58,  1.05it/s]Loading train:  89%|████████▊ | 472/532 [14:50<00:56,  1.05it/s]Loading train:  89%|████████▉ | 473/532 [14:51<00:58,  1.01it/s]Loading train:  89%|████████▉ | 474/532 [14:52<00:58,  1.01s/it]Loading train:  89%|████████▉ | 475/532 [14:53<00:59,  1.05s/it]Loading train:  89%|████████▉ | 476/532 [14:54<00:58,  1.05s/it]Loading train:  90%|████████▉ | 477/532 [14:55<00:57,  1.05s/it]Loading train:  90%|████████▉ | 478/532 [14:56<00:56,  1.05s/it]Loading train:  90%|█████████ | 479/532 [14:57<00:54,  1.02s/it]Loading train:  90%|█████████ | 480/532 [14:58<00:51,  1.01it/s]Loading train:  90%|█████████ | 481/532 [14:59<00:49,  1.04it/s]Loading train:  91%|█████████ | 482/532 [15:00<00:47,  1.05it/s]Loading train:  91%|█████████ | 483/532 [15:01<00:48,  1.00it/s]Loading train:  91%|█████████ | 484/532 [15:02<00:47,  1.01it/s]Loading train:  91%|█████████ | 485/532 [15:03<00:48,  1.02s/it]Loading train:  91%|█████████▏| 486/532 [15:04<00:48,  1.05s/it]Loading train:  92%|█████████▏| 487/532 [15:06<00:47,  1.06s/it]Loading train:  92%|█████████▏| 488/532 [15:07<00:46,  1.06s/it]Loading train:  92%|█████████▏| 489/532 [15:08<00:47,  1.10s/it]Loading train:  92%|█████████▏| 490/532 [15:09<00:45,  1.09s/it]Loading train:  92%|█████████▏| 491/532 [15:10<00:42,  1.04s/it]Loading train:  92%|█████████▏| 492/532 [15:11<00:40,  1.01s/it]Loading train:  93%|█████████▎| 493/532 [15:12<00:38,  1.02it/s]Loading train:  93%|█████████▎| 494/532 [15:13<00:37,  1.03it/s]Loading train:  93%|█████████▎| 495/532 [15:14<00:36,  1.02it/s]Loading train:  93%|█████████▎| 496/532 [15:14<00:34,  1.06it/s]Loading train:  93%|█████████▎| 497/532 [15:15<00:34,  1.03it/s]Loading train:  94%|█████████▎| 498/532 [15:16<00:33,  1.02it/s]Loading train:  94%|█████████▍| 499/532 [15:17<00:32,  1.03it/s]Loading train:  94%|█████████▍| 500/532 [15:18<00:30,  1.04it/s]Loading train:  94%|█████████▍| 501/532 [15:19<00:30,  1.03it/s]Loading train:  94%|█████████▍| 502/532 [15:20<00:29,  1.03it/s]Loading train:  95%|█████████▍| 503/532 [15:21<00:27,  1.06it/s]Loading train:  95%|█████████▍| 504/532 [15:22<00:26,  1.06it/s]Loading train:  95%|█████████▍| 505/532 [15:23<00:25,  1.04it/s]Loading train:  95%|█████████▌| 506/532 [15:24<00:24,  1.06it/s]Loading train:  95%|█████████▌| 507/532 [15:25<00:23,  1.05it/s]Loading train:  95%|█████████▌| 508/532 [15:26<00:22,  1.07it/s]Loading train:  96%|█████████▌| 509/532 [15:27<00:22,  1.03it/s]Loading train:  96%|█████████▌| 510/532 [15:28<00:22,  1.01s/it]Loading train:  96%|█████████▌| 511/532 [15:29<00:21,  1.03s/it]Loading train:  96%|█████████▌| 512/532 [15:30<00:21,  1.07s/it]Loading train:  96%|█████████▋| 513/532 [15:31<00:20,  1.10s/it]Loading train:  97%|█████████▋| 514/532 [15:33<00:19,  1.10s/it]Loading train:  97%|█████████▋| 515/532 [15:34<00:18,  1.08s/it]Loading train:  97%|█████████▋| 516/532 [15:35<00:17,  1.07s/it]Loading train:  97%|█████████▋| 517/532 [15:36<00:15,  1.04s/it]Loading train:  97%|█████████▋| 518/532 [15:37<00:14,  1.02s/it]Loading train:  98%|█████████▊| 519/532 [15:38<00:13,  1.02s/it]Loading train:  98%|█████████▊| 520/532 [15:39<00:12,  1.01s/it]Loading train:  98%|█████████▊| 521/532 [15:40<00:11,  1.05s/it]Loading train:  98%|█████████▊| 522/532 [15:41<00:10,  1.07s/it]Loading train:  98%|█████████▊| 523/532 [15:42<00:09,  1.09s/it]Loading train:  98%|█████████▊| 524/532 [15:43<00:08,  1.09s/it]Loading train:  99%|█████████▊| 525/532 [15:44<00:07,  1.10s/it]Loading train:  99%|█████████▉| 526/532 [15:45<00:06,  1.11s/it]Loading train:  99%|█████████▉| 527/532 [15:46<00:05,  1.06s/it]Loading train:  99%|█████████▉| 528/532 [15:47<00:04,  1.04s/it]Loading train:  99%|█████████▉| 529/532 [15:48<00:03,  1.01s/it]Loading train: 100%|█████████▉| 530/532 [15:49<00:01,  1.02it/s]Loading train: 100%|█████████▉| 531/532 [15:50<00:00,  1.03it/s]Loading train: 100%|██████████| 532/532 [15:51<00:00,  1.06it/s]
concatenating: train:   0%|          | 0/532 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 10/532 [00:00<00:05, 98.72it/s]concatenating: train:   7%|▋         | 36/532 [00:00<00:04, 120.98it/s]concatenating: train:  12%|█▏        | 64/532 [00:00<00:03, 145.76it/s]concatenating: train:  17%|█▋        | 90/532 [00:00<00:02, 167.80it/s]concatenating: train:  21%|██▏       | 114/532 [00:00<00:02, 182.84it/s]concatenating: train:  26%|██▌       | 138/532 [00:00<00:02, 196.53it/s]concatenating: train:  31%|███       | 163/532 [00:00<00:01, 208.91it/s]concatenating: train:  35%|███▌      | 188/532 [00:00<00:01, 217.54it/s]concatenating: train:  40%|████      | 213/532 [00:00<00:01, 224.78it/s]concatenating: train:  45%|████▍     | 237/532 [00:01<00:01, 228.98it/s]concatenating: train:  49%|████▉     | 261/532 [00:01<00:01, 231.92it/s]concatenating: train:  54%|█████▎    | 285/532 [00:01<00:01, 232.85it/s]concatenating: train:  58%|█████▊    | 309/532 [00:01<00:00, 234.38it/s]concatenating: train:  63%|██████▎   | 334/532 [00:01<00:00, 236.44it/s]concatenating: train:  67%|██████▋   | 358/532 [00:01<00:00, 236.97it/s]concatenating: train:  72%|███████▏  | 383/532 [00:01<00:00, 238.05it/s]concatenating: train:  77%|███████▋  | 407/532 [00:01<00:00, 236.38it/s]concatenating: train:  81%|████████  | 432/532 [00:01<00:00, 237.98it/s]concatenating: train:  86%|████████▌ | 457/532 [00:01<00:00, 241.25it/s]concatenating: train:  91%|█████████ | 482/532 [00:02<00:00, 239.97it/s]concatenating: train:  95%|█████████▌| 508/532 [00:02<00:00, 243.05it/s]concatenating: train: 100%|██████████| 532/532 [00:02<00:00, 237.69it/s]
Loading test:   0%|          | 0/15 [00:00<?, ?it/s]Loading test:   7%|▋         | 1/15 [00:00<00:12,  1.10it/s]Loading test:  13%|█▎        | 2/15 [00:01<00:12,  1.04it/s]Loading test:  20%|██        | 3/15 [00:03<00:12,  1.01s/it]Loading test:  27%|██▋       | 4/15 [00:04<00:11,  1.03s/it]Loading test:  33%|███▎      | 5/15 [00:05<00:10,  1.09s/it]Loading test:  40%|████      | 6/15 [00:07<00:11,  1.33s/it]Loading test:  47%|████▋     | 7/15 [00:08<00:09,  1.21s/it]Loading test:  53%|█████▎    | 8/15 [00:09<00:08,  1.24s/it]Loading test:  60%|██████    | 9/15 [00:10<00:07,  1.19s/it]Loading test:  67%|██████▋   | 10/15 [00:11<00:05,  1.10s/it]Loading test:  73%|███████▎  | 11/15 [00:12<00:04,  1.06s/it]Loading test:  80%|████████  | 12/15 [00:13<00:03,  1.10s/it]Loading test:  87%|████████▋ | 13/15 [00:14<00:02,  1.12s/it]Loading test:  93%|█████████▎| 14/15 [00:15<00:01,  1.11s/it]Loading test: 100%|██████████| 15/15 [00:16<00:00,  1.10s/it]
concatenating: validation:   0%|          | 0/15 [00:00<?, ?it/s]concatenating: validation:  53%|█████▎    | 8/15 [00:00<00:00, 74.76it/s]concatenating: validation: 100%|██████████| 15/15 [00:00<00:00, 126.14it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 56, 56, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 56, 56, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 56, 56, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 56, 56, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 56, 56, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 56, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 56, 56, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 56, 56, 16)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 16)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28, 28, 16)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 28, 30)   4350        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 28, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 28, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 28, 28, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 28, 28, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 28, 28, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 28, 46)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 46)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 14, 14, 46)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 14, 14, 60)   24900       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 14, 14, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 14, 14, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 14, 14, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 14, 14, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 14, 14, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 14, 14, 106)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 14, 14, 106)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 28, 28, 30)   12750       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 28, 28, 76)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 28, 28, 30)   20550       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 28, 28, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 28, 28, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 28, 28, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 28, 28, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 28, 28, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 28, 28, 106)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-06 23:46:42.214516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-06 23:46:42.214624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-06 23:46:42.214639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-06 23:46:42.214648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-06 23:46:42.215087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 28, 28, 106)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 56, 56, 15)   6375        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 56, 31)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 56, 56, 15)   4200        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 56, 56, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 56, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 56, 56, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 56, 56, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 56, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 56, 46)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 56, 56, 46)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 56, 56, 13)   611         dropout_5[0][0]                  
==================================================================================================
Total params: 127,886
Trainable params: 127,286
Non-trainable params: 600
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.53974061e-02 2.89048015e-02 1.16758472e-01 1.00223856e-02
 3.03440156e-02 5.80063118e-03 6.84518755e-02 1.28261328e-01
 7.55818021e-02 1.22545826e-02 2.73712232e-01 1.84335085e-01
 1.75382711e-04]
Train on 33496 samples, validate on 969 samples
Epoch 1/300
 - 30s - loss: 48.0647 - acc: 0.8060 - mDice: 0.0232 - val_loss: 3.6064 - val_acc: 0.9217 - val_mDice: 0.0380

Epoch 00001: val_mDice improved from -inf to 0.03800, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 21s - loss: 4.5855 - acc: 0.9056 - mDice: 0.0645 - val_loss: 2.8615 - val_acc: 0.9189 - val_mDice: 0.1000

Epoch 00002: val_mDice improved from 0.03800 to 0.09996, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 21s - loss: 3.4389 - acc: 0.9133 - mDice: 0.1353 - val_loss: 2.1160 - val_acc: 0.9305 - val_mDice: 0.2270

Epoch 00003: val_mDice improved from 0.09996 to 0.22696, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 22s - loss: 2.7007 - acc: 0.9245 - mDice: 0.2240 - val_loss: 1.6167 - val_acc: 0.9534 - val_mDice: 0.3775

Epoch 00004: val_mDice improved from 0.22696 to 0.37750, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 5/300
 - 21s - loss: 2.2097 - acc: 0.9361 - mDice: 0.3181 - val_loss: 1.3007 - val_acc: 0.9628 - val_mDice: 0.4728

Epoch 00005: val_mDice improved from 0.37750 to 0.47277, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 21s - loss: 1.9350 - acc: 0.9419 - mDice: 0.3798 - val_loss: 1.1167 - val_acc: 0.9698 - val_mDice: 0.5446

Epoch 00006: val_mDice improved from 0.47277 to 0.54464, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 7/300
 - 21s - loss: 1.7400 - acc: 0.9460 - mDice: 0.4280 - val_loss: 1.0223 - val_acc: 0.9725 - val_mDice: 0.5863

Epoch 00007: val_mDice improved from 0.54464 to 0.58634, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 8/300
 - 22s - loss: 1.5911 - acc: 0.9494 - mDice: 0.4669 - val_loss: 0.9485 - val_acc: 0.9741 - val_mDice: 0.6111

Epoch 00008: val_mDice improved from 0.58634 to 0.61114, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 9/300
 - 22s - loss: 1.4798 - acc: 0.9519 - mDice: 0.4980 - val_loss: 0.8872 - val_acc: 0.9752 - val_mDice: 0.6392

Epoch 00009: val_mDice improved from 0.61114 to 0.63923, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 10/300
 - 21s - loss: 1.3852 - acc: 0.9541 - mDice: 0.5242 - val_loss: 0.8408 - val_acc: 0.9757 - val_mDice: 0.6568

Epoch 00010: val_mDice improved from 0.63923 to 0.65676, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 11/300
 - 21s - loss: 1.3013 - acc: 0.9561 - mDice: 0.5498 - val_loss: 0.8307 - val_acc: 0.9765 - val_mDice: 0.6706

Epoch 00011: val_mDice improved from 0.65676 to 0.67056, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 12/300
 - 21s - loss: 1.2263 - acc: 0.9577 - mDice: 0.5725 - val_loss: 0.7939 - val_acc: 0.9770 - val_mDice: 0.6857

Epoch 00012: val_mDice improved from 0.67056 to 0.68572, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 13/300
 - 22s - loss: 1.1648 - acc: 0.9590 - mDice: 0.5900 - val_loss: 0.7860 - val_acc: 0.9773 - val_mDice: 0.6900

Epoch 00013: val_mDice improved from 0.68572 to 0.68995, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 14/300
 - 21s - loss: 1.1172 - acc: 0.9601 - mDice: 0.6044 - val_loss: 0.7743 - val_acc: 0.9777 - val_mDice: 0.6984

Epoch 00014: val_mDice improved from 0.68995 to 0.69845, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 15/300
 - 21s - loss: 1.0838 - acc: 0.9608 - mDice: 0.6149 - val_loss: 0.7791 - val_acc: 0.9775 - val_mDice: 0.6983

Epoch 00015: val_mDice did not improve from 0.69845
Epoch 16/300
 - 21s - loss: 1.0520 - acc: 0.9614 - mDice: 0.6260 - val_loss: 0.7488 - val_acc: 0.9776 - val_mDice: 0.7077

Epoch 00016: val_mDice improved from 0.69845 to 0.70768, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 17/300
 - 22s - loss: 1.0194 - acc: 0.9622 - mDice: 0.6364 - val_loss: 0.7348 - val_acc: 0.9778 - val_mDice: 0.7146

Epoch 00017: val_mDice improved from 0.70768 to 0.71456, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 18/300
 - 21s - loss: 0.9975 - acc: 0.9627 - mDice: 0.6433 - val_loss: 0.7176 - val_acc: 0.9782 - val_mDice: 0.7164

Epoch 00018: val_mDice improved from 0.71456 to 0.71635, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 19/300
 - 21s - loss: 0.9760 - acc: 0.9632 - mDice: 0.6503 - val_loss: 0.7341 - val_acc: 0.9771 - val_mDice: 0.7143

Epoch 00019: val_mDice did not improve from 0.71635
Epoch 20/300
 - 21s - loss: 0.9537 - acc: 0.9636 - mDice: 0.6585 - val_loss: 0.7028 - val_acc: 0.9790 - val_mDice: 0.7263

Epoch 00020: val_mDice improved from 0.71635 to 0.72633, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 21/300
 - 21s - loss: 0.9373 - acc: 0.9640 - mDice: 0.6637 - val_loss: 0.7125 - val_acc: 0.9792 - val_mDice: 0.7274

Epoch 00021: val_mDice improved from 0.72633 to 0.72736, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 22/300
 - 22s - loss: 0.9182 - acc: 0.9643 - mDice: 0.6698 - val_loss: 0.7063 - val_acc: 0.9787 - val_mDice: 0.7268

Epoch 00022: val_mDice did not improve from 0.72736
Epoch 23/300
 - 21s - loss: 0.8999 - acc: 0.9646 - mDice: 0.6764 - val_loss: 0.7031 - val_acc: 0.9789 - val_mDice: 0.7267

Epoch 00023: val_mDice did not improve from 0.72736
Epoch 24/300
 - 21s - loss: 0.8849 - acc: 0.9650 - mDice: 0.6814 - val_loss: 0.6967 - val_acc: 0.9795 - val_mDice: 0.7322

Epoch 00024: val_mDice improved from 0.72736 to 0.73222, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 25/300
 - 21s - loss: 0.8733 - acc: 0.9652 - mDice: 0.6852 - val_loss: 0.6975 - val_acc: 0.9797 - val_mDice: 0.7317

Epoch 00025: val_mDice did not improve from 0.73222
Epoch 26/300
 - 22s - loss: 0.8609 - acc: 0.9655 - mDice: 0.6894 - val_loss: 0.6905 - val_acc: 0.9796 - val_mDice: 0.7365

Epoch 00026: val_mDice improved from 0.73222 to 0.73653, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 27/300
 - 22s - loss: 0.8527 - acc: 0.9657 - mDice: 0.6921 - val_loss: 0.6719 - val_acc: 0.9801 - val_mDice: 0.7424

Epoch 00027: val_mDice improved from 0.73653 to 0.74237, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 28/300
 - 21s - loss: 0.8416 - acc: 0.9659 - mDice: 0.6959 - val_loss: 0.6848 - val_acc: 0.9791 - val_mDice: 0.7393

Epoch 00028: val_mDice did not improve from 0.74237
Epoch 29/300
 - 21s - loss: 0.8319 - acc: 0.9660 - mDice: 0.6992 - val_loss: 0.6796 - val_acc: 0.9794 - val_mDice: 0.7380

Epoch 00029: val_mDice did not improve from 0.74237
Epoch 30/300
 - 21s - loss: 0.8278 - acc: 0.9662 - mDice: 0.7003 - val_loss: 0.6821 - val_acc: 0.9798 - val_mDice: 0.7412

Epoch 00030: val_mDice did not improve from 0.74237
Epoch 31/300
 - 22s - loss: 0.8192 - acc: 0.9664 - mDice: 0.7030 - val_loss: 0.6706 - val_acc: 0.9794 - val_mDice: 0.7429

Epoch 00031: val_mDice improved from 0.74237 to 0.74289, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 32/300
 - 21s - loss: 0.8110 - acc: 0.9666 - mDice: 0.7061 - val_loss: 0.6622 - val_acc: 0.9799 - val_mDice: 0.7426

Epoch 00032: val_mDice did not improve from 0.74289
Epoch 33/300
 - 21s - loss: 0.8056 - acc: 0.9667 - mDice: 0.7076 - val_loss: 0.6658 - val_acc: 0.9799 - val_mDice: 0.7454

Epoch 00033: val_mDice improved from 0.74289 to 0.74536, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 34/300
 - 21s - loss: 0.7978 - acc: 0.9668 - mDice: 0.7102 - val_loss: 0.6672 - val_acc: 0.9800 - val_mDice: 0.7446

Epoch 00034: val_mDice did not improve from 0.74536
Epoch 35/300
 - 22s - loss: 0.7904 - acc: 0.9670 - mDice: 0.7129 - val_loss: 0.6668 - val_acc: 0.9797 - val_mDice: 0.7455

Epoch 00035: val_mDice improved from 0.74536 to 0.74551, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 36/300
 - 22s - loss: 0.7849 - acc: 0.9671 - mDice: 0.7149 - val_loss: 0.6839 - val_acc: 0.9795 - val_mDice: 0.7406

Epoch 00036: val_mDice did not improve from 0.74551
Epoch 37/300
 - 21s - loss: 0.7824 - acc: 0.9672 - mDice: 0.7154 - val_loss: 0.6725 - val_acc: 0.9803 - val_mDice: 0.7480

Epoch 00037: val_mDice improved from 0.74551 to 0.74796, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 38/300
 - 21s - loss: 0.7789 - acc: 0.9673 - mDice: 0.7166 - val_loss: 0.6766 - val_acc: 0.9807 - val_mDice: 0.7435

Epoch 00038: val_mDice did not improve from 0.74796
Epoch 39/300
 - 21s - loss: 0.7750 - acc: 0.9674 - mDice: 0.7180 - val_loss: 0.6643 - val_acc: 0.9805 - val_mDice: 0.7435

Epoch 00039: val_mDice did not improve from 0.74796
Epoch 40/300
 - 22s - loss: 0.7705 - acc: 0.9675 - mDice: 0.7195 - val_loss: 0.6571 - val_acc: 0.9803 - val_mDice: 0.7474

Epoch 00040: val_mDice did not improve from 0.74796
Epoch 41/300
 - 21s - loss: 0.7641 - acc: 0.9675 - mDice: 0.7216 - val_loss: 0.6657 - val_acc: 0.9801 - val_mDice: 0.7481

Epoch 00041: val_mDice improved from 0.74796 to 0.74811, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 42/300
 - 21s - loss: 0.7630 - acc: 0.9676 - mDice: 0.7218 - val_loss: 0.6546 - val_acc: 0.9806 - val_mDice: 0.7494

Epoch 00042: val_mDice improved from 0.74811 to 0.74937, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 43/300
 - 21s - loss: 0.7587 - acc: 0.9676 - mDice: 0.7232 - val_loss: 0.6547 - val_acc: 0.9809 - val_mDice: 0.7509

Epoch 00043: val_mDice improved from 0.74937 to 0.75093, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 44/300
 - 22s - loss: 0.7568 - acc: 0.9677 - mDice: 0.7238 - val_loss: 0.6415 - val_acc: 0.9804 - val_mDice: 0.7516

Epoch 00044: val_mDice improved from 0.75093 to 0.75164, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 45/300
 - 22s - loss: 0.7506 - acc: 0.9678 - mDice: 0.7263 - val_loss: 0.6495 - val_acc: 0.9807 - val_mDice: 0.7499

Epoch 00045: val_mDice did not improve from 0.75164
Epoch 46/300
 - 21s - loss: 0.7487 - acc: 0.9679 - mDice: 0.7264 - val_loss: 0.6495 - val_acc: 0.9805 - val_mDice: 0.7482

Epoch 00046: val_mDice did not improve from 0.75164
Epoch 47/300
 - 21s - loss: 0.7447 - acc: 0.9680 - mDice: 0.7282 - val_loss: 0.6717 - val_acc: 0.9805 - val_mDice: 0.7433

Epoch 00047: val_mDice did not improve from 0.75164
Epoch 48/300
 - 24s - loss: 0.7440 - acc: 0.9680 - mDice: 0.7281 - val_loss: 0.6442 - val_acc: 0.9811 - val_mDice: 0.7554

Epoch 00048: val_mDice improved from 0.75164 to 0.75539, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 49/300
 - 21s - loss: 0.7405 - acc: 0.9681 - mDice: 0.7295 - val_loss: 0.6448 - val_acc: 0.9803 - val_mDice: 0.7540

Epoch 00049: val_mDice did not improve from 0.75539
Epoch 50/300
 - 21s - loss: 0.7375 - acc: 0.9681 - mDice: 0.7306 - val_loss: 0.6457 - val_acc: 0.9805 - val_mDice: 0.7479

Epoch 00050: val_mDice did not improve from 0.75539
Epoch 51/300
 - 22s - loss: 0.7355 - acc: 0.9681 - mDice: 0.7308 - val_loss: 0.6547 - val_acc: 0.9809 - val_mDice: 0.7511

Epoch 00051: val_mDice did not improve from 0.75539
Epoch 52/300
 - 22s - loss: 0.7324 - acc: 0.9682 - mDice: 0.7323 - val_loss: 0.6543 - val_acc: 0.9810 - val_mDice: 0.7487

Epoch 00052: val_mDice did not improve from 0.75539
Epoch 53/300
 - 22s - loss: 0.7311 - acc: 0.9682 - mDice: 0.7323 - val_loss: 0.6581 - val_acc: 0.9801 - val_mDice: 0.7478

Epoch 00053: val_mDice did not improve from 0.75539
Epoch 54/300
 - 22s - loss: 0.7267 - acc: 0.9683 - mDice: 0.7339 - val_loss: 0.6460 - val_acc: 0.9813 - val_mDice: 0.7534

Epoch 00054: val_mDice did not improve from 0.75539
Epoch 55/300
 - 23s - loss: 0.7259 - acc: 0.9683 - mDice: 0.7342 - val_loss: 0.6392 - val_acc: 0.9812 - val_mDice: 0.7517

Epoch 00055: val_mDice did not improve from 0.75539
Epoch 56/300
 - 22s - loss: 0.7248 - acc: 0.9684 - mDice: 0.7347 - val_loss: 0.6385 - val_acc: 0.9810 - val_mDice: 0.7569

Epoch 00056: val_mDice improved from 0.75539 to 0.75687, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 57/300
 - 22s - loss: 0.7227 - acc: 0.9684 - mDice: 0.7355 - val_loss: 0.6488 - val_acc: 0.9805 - val_mDice: 0.7539

Epoch 00057: val_mDice did not improve from 0.75687
Epoch 58/300
 - 23s - loss: 0.7192 - acc: 0.9684 - mDice: 0.7366 - val_loss: 0.6412 - val_acc: 0.9812 - val_mDice: 0.7520

Epoch 00058: val_mDice did not improve from 0.75687
Epoch 59/300
 - 22s - loss: 0.7196 - acc: 0.9685 - mDice: 0.7365 - val_loss: 0.6469 - val_acc: 0.9808 - val_mDice: 0.7497

Epoch 00059: val_mDice did not improve from 0.75687
Epoch 60/300
 - 23s - loss: 0.7184 - acc: 0.9685 - mDice: 0.7371 - val_loss: 0.6469 - val_acc: 0.9804 - val_mDice: 0.7515

Epoch 00060: val_mDice did not improve from 0.75687
Epoch 61/300
 - 23s - loss: 0.7173 - acc: 0.9685 - mDice: 0.7373 - val_loss: 0.6405 - val_acc: 0.9804 - val_mDice: 0.7538

Epoch 00061: val_mDice did not improve from 0.75687
Epoch 62/300
 - 22s - loss: 0.7118 - acc: 0.9686 - mDice: 0.7394 - val_loss: 0.6559 - val_acc: 0.9803 - val_mDice: 0.7496

Epoch 00062: val_mDice did not improve from 0.75687
Epoch 63/300
 - 23s - loss: 0.7117 - acc: 0.9687 - mDice: 0.7393 - val_loss: 0.6546 - val_acc: 0.9812 - val_mDice: 0.7501

Epoch 00063: val_mDice did not improve from 0.75687
Epoch 64/300
 - 21s - loss: 0.7109 - acc: 0.9687 - mDice: 0.7395 - val_loss: 0.6478 - val_acc: 0.9808 - val_mDice: 0.7510

Epoch 00064: val_mDice did not improve from 0.75687
Epoch 65/300
 - 23s - loss: 0.7111 - acc: 0.9687 - mDice: 0.7398 - val_loss: 0.6399 - val_acc: 0.9808 - val_mDice: 0.7553

Epoch 00065: val_mDice did not improve from 0.75687
Epoch 66/300
 - 22s - loss: 0.7074 - acc: 0.9687 - mDice: 0.7409 - val_loss: 0.6330 - val_acc: 0.9812 - val_mDice: 0.7560

Epoch 00066: val_mDice did not improve from 0.75687
Epoch 67/300
 - 22s - loss: 0.7066 - acc: 0.9687 - mDice: 0.7408 - val_loss: 0.6424 - val_acc: 0.9815 - val_mDice: 0.7525

Epoch 00067: val_mDice did not improve from 0.75687
Epoch 68/300
 - 23s - loss: 0.7047 - acc: 0.9688 - mDice: 0.7416 - val_loss: 0.6484 - val_acc: 0.9814 - val_mDice: 0.7524

Epoch 00068: val_mDice did not improve from 0.75687
Epoch 69/300
 - 22s - loss: 0.7025 - acc: 0.9689 - mDice: 0.7425 - val_loss: 0.6498 - val_acc: 0.9806 - val_mDice: 0.7556

Epoch 00069: val_mDice did not improve from 0.75687
Epoch 70/300
 - 22s - loss: 0.7023 - acc: 0.9688 - mDice: 0.7423 - val_loss: 0.6473 - val_acc: 0.9808 - val_mDice: 0.7534

Epoch 00070: val_mDice did not improve from 0.75687
Epoch 71/300
 - 22s - loss: 0.7027 - acc: 0.9689 - mDice: 0.7423 - val_loss: 0.6571 - val_acc: 0.9810 - val_mDice: 0.7546

Epoch 00071: val_mDice did not improve from 0.75687
Epoch 72/300
 - 21s - loss: 0.7002 - acc: 0.9689 - mDice: 0.7431 - val_loss: 0.6392 - val_acc: 0.9812 - val_mDice: 0.7522

Epoch 00072: val_mDice did not improve from 0.75687
Epoch 73/300
 - 23s - loss: 0.6986 - acc: 0.9690 - mDice: 0.7439 - val_loss: 0.6362 - val_acc: 0.9815 - val_mDice: 0.7568

Epoch 00073: val_mDice did not improve from 0.75687
Epoch 74/300
 - 24s - loss: 0.6957 - acc: 0.9690 - mDice: 0.7447 - val_loss: 0.6349 - val_acc: 0.9810 - val_mDice: 0.7591

Epoch 00074: val_mDice improved from 0.75687 to 0.75914, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 75/300
 - 24s - loss: 0.6943 - acc: 0.9690 - mDice: 0.7456 - val_loss: 0.6328 - val_acc: 0.9810 - val_mDice: 0.7584

Epoch 00075: val_mDice did not improve from 0.75914
Epoch 76/300
 - 25s - loss: 0.6940 - acc: 0.9690 - mDice: 0.7455 - val_loss: 0.6337 - val_acc: 0.9816 - val_mDice: 0.7574

Epoch 00076: val_mDice did not improve from 0.75914
Epoch 77/300
 - 24s - loss: 0.6935 - acc: 0.9690 - mDice: 0.7455 - val_loss: 0.6335 - val_acc: 0.9811 - val_mDice: 0.7612

Epoch 00077: val_mDice improved from 0.75914 to 0.76122, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 78/300
 - 24s - loss: 0.6923 - acc: 0.9691 - mDice: 0.7458 - val_loss: 0.6501 - val_acc: 0.9810 - val_mDice: 0.7519

Epoch 00078: val_mDice did not improve from 0.76122
Epoch 79/300
 - 24s - loss: 0.6908 - acc: 0.9691 - mDice: 0.7464 - val_loss: 0.6314 - val_acc: 0.9812 - val_mDice: 0.7588

Epoch 00079: val_mDice did not improve from 0.76122
Epoch 80/300
 - 25s - loss: 0.6892 - acc: 0.9691 - mDice: 0.7471 - val_loss: 0.6308 - val_acc: 0.9818 - val_mDice: 0.7574

Epoch 00080: val_mDice did not improve from 0.76122
Epoch 81/300
 - 25s - loss: 0.6885 - acc: 0.9691 - mDice: 0.7475 - val_loss: 0.6373 - val_acc: 0.9815 - val_mDice: 0.7560

Epoch 00081: val_mDice did not improve from 0.76122
Epoch 82/300
 - 24s - loss: 0.6868 - acc: 0.9691 - mDice: 0.7479 - val_loss: 0.6253 - val_acc: 0.9813 - val_mDice: 0.7574

Epoch 00082: val_mDice did not improve from 0.76122
Epoch 83/300
 - 23s - loss: 0.6863 - acc: 0.9692 - mDice: 0.7480 - val_loss: 0.6332 - val_acc: 0.9810 - val_mDice: 0.7553

Epoch 00083: val_mDice did not improve from 0.76122
Epoch 84/300
 - 24s - loss: 0.6857 - acc: 0.9692 - mDice: 0.7482 - val_loss: 0.6367 - val_acc: 0.9813 - val_mDice: 0.7611

Epoch 00084: val_mDice did not improve from 0.76122
Epoch 85/300
 - 21s - loss: 0.6844 - acc: 0.9692 - mDice: 0.7488 - val_loss: 0.6336 - val_acc: 0.9815 - val_mDice: 0.7571

Epoch 00085: val_mDice did not improve from 0.76122
Epoch 86/300
 - 22s - loss: 0.6844 - acc: 0.9692 - mDice: 0.7485 - val_loss: 0.6341 - val_acc: 0.9816 - val_mDice: 0.7584

Epoch 00086: val_mDice did not improve from 0.76122
Epoch 87/300
 - 22s - loss: 0.6827 - acc: 0.9693 - mDice: 0.7493 - val_loss: 0.6289 - val_acc: 0.9815 - val_mDice: 0.7587

Epoch 00087: val_mDice did not improve from 0.76122
Epoch 88/300
 - 21s - loss: 0.6827 - acc: 0.9693 - mDice: 0.7494 - val_loss: 0.6317 - val_acc: 0.9815 - val_mDice: 0.7577

Epoch 00088: val_mDice did not improve from 0.76122
Epoch 89/300
 - 21s - loss: 0.6824 - acc: 0.9693 - mDice: 0.7495 - val_loss: 0.6452 - val_acc: 0.9809 - val_mDice: 0.7586

Epoch 00089: val_mDice did not improve from 0.76122
Epoch 90/300
 - 22s - loss: 0.6812 - acc: 0.9693 - mDice: 0.7498 - val_loss: 0.6312 - val_acc: 0.9814 - val_mDice: 0.7556

Epoch 00090: val_mDice did not improve from 0.76122
Epoch 91/300
 - 21s - loss: 0.6790 - acc: 0.9694 - mDice: 0.7505 - val_loss: 0.6309 - val_acc: 0.9820 - val_mDice: 0.7593

Epoch 00091: val_mDice did not improve from 0.76122
Epoch 92/300
 - 21s - loss: 0.6793 - acc: 0.9694 - mDice: 0.7503 - val_loss: 0.6453 - val_acc: 0.9807 - val_mDice: 0.7587

Epoch 00092: val_mDice did not improve from 0.76122
Epoch 93/300
 - 21s - loss: 0.6786 - acc: 0.9694 - mDice: 0.7508 - val_loss: 0.6445 - val_acc: 0.9809 - val_mDice: 0.7579

Epoch 00093: val_mDice did not improve from 0.76122
Epoch 94/300
 - 22s - loss: 0.6777 - acc: 0.9693 - mDice: 0.7509 - val_loss: 0.6311 - val_acc: 0.9820 - val_mDice: 0.7559

Epoch 00094: val_mDice did not improve from 0.76122
Epoch 95/300
 - 21s - loss: 0.6755 - acc: 0.9694 - mDice: 0.7518 - val_loss: 0.6412 - val_acc: 0.9817 - val_mDice: 0.7586

Epoch 00095: val_mDice did not improve from 0.76122
Epoch 96/300
 - 21s - loss: 0.6759 - acc: 0.9694 - mDice: 0.7514 - val_loss: 0.6440 - val_acc: 0.9813 - val_mDice: 0.7590

Epoch 00096: val_mDice did not improve from 0.76122
Epoch 97/300
 - 21s - loss: 0.6744 - acc: 0.9695 - mDice: 0.7520 - val_loss: 0.6295 - val_acc: 0.9816 - val_mDice: 0.7601

Epoch 00097: val_mDice did not improve from 0.76122
Epoch 98/300
 - 22s - loss: 0.6736 - acc: 0.9695 - mDice: 0.7524 - val_loss: 0.6435 - val_acc: 0.9809 - val_mDice: 0.7572

Epoch 00098: val_mDice did not improve from 0.76122
Epoch 99/300
 - 22s - loss: 0.6752 - acc: 0.9694 - mDice: 0.7519 - val_loss: 0.6303 - val_acc: 0.9815 - val_mDice: 0.7581

Epoch 00099: val_mDice did not improve from 0.76122
Epoch 100/300
 - 21s - loss: 0.6734 - acc: 0.9695 - mDice: 0.7525 - val_loss: 0.6377 - val_acc: 0.9815 - val_mDice: 0.7567

Epoch 00100: val_mDice did not improve from 0.76122
Epoch 101/300
 - 21s - loss: 0.6708 - acc: 0.9695 - mDice: 0.7535 - val_loss: 0.6478 - val_acc: 0.9806 - val_mDice: 0.7570

Epoch 00101: val_mDice did not improve from 0.76122
Epoch 102/300
 - 21s - loss: 0.6730 - acc: 0.9695 - mDice: 0.7525 - val_loss: 0.6364 - val_acc: 0.9817 - val_mDice: 0.7596

Epoch 00102: val_mDice did not improve from 0.76122
Epoch 103/300
 - 22s - loss: 0.6716 - acc: 0.9696 - mDice: 0.7532 - val_loss: 0.6280 - val_acc: 0.9816 - val_mDice: 0.7560

Epoch 00103: val_mDice did not improve from 0.76122
Epoch 104/300
 - 21s - loss: 0.6708 - acc: 0.9696 - mDice: 0.7534 - val_loss: 0.6361 - val_acc: 0.9819 - val_mDice: 0.7584

Epoch 00104: val_mDice did not improve from 0.76122
Epoch 105/300
 - 21s - loss: 0.6699 - acc: 0.9695 - mDice: 0.7538 - val_loss: 0.6404 - val_acc: 0.9812 - val_mDice: 0.7597

Epoch 00105: val_mDice did not improve from 0.76122
Epoch 106/300
 - 21s - loss: 0.6708 - acc: 0.9695 - mDice: 0.7536 - val_loss: 0.6276 - val_acc: 0.9816 - val_mDice: 0.7582

Epoch 00106: val_mDice did not improve from 0.76122
Epoch 107/300
 - 21s - loss: 0.6680 - acc: 0.9696 - mDice: 0.7543 - val_loss: 0.6311 - val_acc: 0.9818 - val_mDice: 0.7595

Epoch 00107: val_mDice did not improve from 0.76122
Restoring model weights from the end of the best epoch
Epoch 00107: early stopping
{'val_loss': [3.606372002600639, 2.861461086292877, 2.115966929247751, 1.6167068618000846, 1.3007426666647535, 1.116737120660835, 1.0223112918890174, 0.9485436371605462, 0.8872235026767995, 0.8408478997317138, 0.830663870301163, 0.7939059456004939, 0.7860248715023753, 0.7742658061877862, 0.7791151718089455, 0.7487722357852294, 0.7348357479331171, 0.7176096767217874, 0.7341013115872047, 0.7027984751759422, 0.7125356144149729, 0.7063299999702087, 0.703122478643561, 0.6966680805934103, 0.6975185482679137, 0.6905361806399067, 0.6718591051512581, 0.6848427683760876, 0.67959458167954, 0.6820846358381435, 0.6706400209167055, 0.6622167613791731, 0.6657927074422532, 0.6671541766547074, 0.6668342518917179, 0.6838810988870075, 0.6724936983656711, 0.6765968210925997, 0.6642607209667701, 0.6571047835982375, 0.6657397746117122, 0.6546436240675526, 0.6546722482293998, 0.6414949236393467, 0.6495135231529842, 0.649492228178786, 0.6716671671537668, 0.6442191902205917, 0.6448342498426467, 0.6457072340482529, 0.6546527292767791, 0.6542889818749068, 0.6580975715712989, 0.6459513583419493, 0.6391581749337869, 0.6384723381791937, 0.6488483391002482, 0.6412300450883045, 0.6468971597090348, 0.6468584175203361, 0.6405248653654959, 0.6558598338388929, 0.6546206853830162, 0.6477626534130797, 0.6399434092305639, 0.632987410998812, 0.6423699911164794, 0.6483500084087207, 0.6498180026240393, 0.6473483963339937, 0.657115311014886, 0.6392312960235942, 0.6362191907392567, 0.6349102944227933, 0.632796777475729, 0.6337184825425792, 0.6334720126000474, 0.6500590925861315, 0.6313768408738915, 0.6308484818359646, 0.6373122578680945, 0.6253325135530702, 0.6332397897976717, 0.6367343361840283, 0.6335662246611589, 0.6340576406910446, 0.6289243784236219, 0.6316602472427336, 0.6452359966203278, 0.6311506513040993, 0.6308738078126228, 0.64527257215866, 0.6444740842862517, 0.6310567749727621, 0.6411660766946027, 0.6439779699156282, 0.6294636588901189, 0.6435073896765832, 0.6302600690270356, 0.6376980994938574, 0.6478338150540126, 0.6363688032878073, 0.6280365877537781, 0.6361211186161474, 0.6403891543547312, 0.6275629321242019, 0.6311422078971154], 'val_acc': [0.9217147453773624, 0.9189277754479518, 0.9305488686812552, 0.9533579855757478, 0.9628486216867918, 0.9697836283190701, 0.9725383630847045, 0.9740932466937047, 0.9751746004949045, 0.9757333794614479, 0.9764711787334045, 0.9769710493653674, 0.9772721518550003, 0.9776683669956353, 0.9774666461167074, 0.9775591165411706, 0.9778493606515221, 0.9781596735658046, 0.9771227653919727, 0.9789915967528912, 0.9792328128750726, 0.9786608774595585, 0.9788839876713276, 0.9794582401020732, 0.9797438720800559, 0.97956124000382, 0.9800788731889951, 0.979096908072323, 0.9794101957443205, 0.9797827032451413, 0.979416762835224, 0.9798830772208971, 0.9799383643733951, 0.9800334602317574, 0.9797283980622503, 0.9794957503076678, 0.9802552643698189, 0.9807041243133899, 0.9804967940776341, 0.9802509820621204, 0.9801078251148772, 0.9806185680277207, 0.9809038752249766, 0.9804359294927772, 0.9806725361275845, 0.9804599506567138, 0.9805073377025632, 0.981105930787983, 0.9802980361462131, 0.980464545811908, 0.9808568180653087, 0.9810302469137406, 0.980133500323084, 0.9812708038786739, 0.9812398679608285, 0.9809835178564208, 0.9805079985206219, 0.9812313107268114, 0.9808439755710409, 0.9803681275177789, 0.9804000472505764, 0.9802891572685557, 0.981190512792983, 0.9807613820483441, 0.9807557838250978, 0.9812230804264238, 0.9815209019540879, 0.9813619561116639, 0.9806050693902684, 0.9807505201629072, 0.9809578451701854, 0.9811622053846117, 0.9815488661282817, 0.9810368236619499, 0.981029259961702, 0.9816110711102638, 0.981125015776962, 0.9810081941793578, 0.9811756976248679, 0.9817709926481217, 0.9815370223962608, 0.9813372649644551, 0.9809571897036274, 0.9813323402921482, 0.9815090449355827, 0.9815916442403606, 0.9815080594598201, 0.9814761441558507, 0.9808686574300131, 0.9814103278336264, 0.9819681135739582, 0.9807149829387173, 0.9809147429540062, 0.981989507766208, 0.9817203199654295, 0.981335298564781, 0.9815580840573346, 0.9808772222299448, 0.9815406432092744, 0.9814531131425509, 0.9806386422446638, 0.98171078709749, 0.9816373961874821, 0.9818996717563232, 0.9811855678833921, 0.9816308054761621, 0.9818101626185564], 'val_mDice': [0.038000678057302756, 0.09996465008448276, 0.22695668163191302, 0.3774953606635547, 0.47277108865133627, 0.5446405827199465, 0.5863411106684383, 0.6111427731927335, 0.6392274151399532, 0.6567566767565606, 0.670564614090265, 0.685723555653949, 0.6899538184713161, 0.6984452680906644, 0.6982567683708065, 0.7076776662478137, 0.7145593142976948, 0.7163544172965091, 0.7142694402405352, 0.7263281349058122, 0.7273605726082628, 0.7267575541393921, 0.7266844850575592, 0.7322171920347263, 0.7317275105369103, 0.7365316788601556, 0.7423703249147925, 0.7392929180979851, 0.7380048979546633, 0.7411666970750004, 0.7428893705885723, 0.7426346279642284, 0.7453633015984967, 0.7445682892489359, 0.7455093254737932, 0.7406172390692743, 0.7479578520491397, 0.7435282644103555, 0.7434762648630684, 0.7473593143855825, 0.7481088164667103, 0.7493668009745201, 0.7509329364518755, 0.7516430059084582, 0.7499008695407549, 0.7482381523332113, 0.7432580518279651, 0.7553865970472803, 0.7539887436895302, 0.7479116353211142, 0.7511357995378712, 0.7487024655037005, 0.7478190145010304, 0.753425865596539, 0.7517307160808575, 0.7568704333344726, 0.7538799657664186, 0.7520318410221883, 0.7496892334383953, 0.7514680783938082, 0.75383633750388, 0.7495896484091555, 0.7500671748652423, 0.7509554516297253, 0.7553062322708106, 0.7560426538696722, 0.7525489441012451, 0.7523769635411116, 0.7556317417245162, 0.7534314098741987, 0.7546200188197834, 0.7522261486580005, 0.7568337201334006, 0.7591385134602479, 0.7584366107011604, 0.7573768614000335, 0.7612198380862966, 0.7518791972176087, 0.7588389706562424, 0.7574076747869682, 0.7559951640381041, 0.7574083361586305, 0.755303677329092, 0.7611058008067995, 0.7570922371649766, 0.7584200102232312, 0.758681756793161, 0.7576552981931728, 0.7586176247173542, 0.755572729620033, 0.7592892326314629, 0.75865839017311, 0.7579114502920578, 0.7558697910500753, 0.7585672093987834, 0.7589658897973681, 0.7600945218305716, 0.757184016323188, 0.7581300805596745, 0.7567402850855738, 0.7570469684522095, 0.7595545644607583, 0.7559710395348453, 0.7583624312137056, 0.7597486435813431, 0.7582339245837539, 0.759541717968243], 'loss': [48.06472372097647, 4.58550228940464, 3.4388641837618645, 2.700732522785792, 2.209692079354107, 1.9349655315532643, 1.740040583871901, 1.5911314565041539, 1.479755162509438, 1.3852253023126628, 1.301294878869003, 1.2262959520501342, 1.1647903712731942, 1.117180363870561, 1.0838452500077858, 1.0520178200252193, 1.019351360847422, 0.997519619842973, 0.9760251588957504, 0.953715640554173, 0.9372904334712888, 0.9182177536422664, 0.8999389712099304, 0.8848550865822143, 0.8733381845799043, 0.8609430040013741, 0.8526754223178615, 0.8415899659956957, 0.8318745915548654, 0.827816777584346, 0.819201386292339, 0.8109784824041868, 0.80559206414627, 0.797770824791396, 0.790410004098859, 0.7848764355395613, 0.782384609262158, 0.7789090303025725, 0.7749597231926655, 0.7704838662876956, 0.7640805328364927, 0.7629836228146085, 0.7587351383259224, 0.7568364824048938, 0.7506413949626369, 0.748721309833661, 0.7446587803485087, 0.7439889521125623, 0.7405266409091685, 0.7374808033098604, 0.7355286949270803, 0.7324114488208667, 0.7311294207090064, 0.7267312178940314, 0.7259313495340796, 0.7247680654980159, 0.7227232380758358, 0.719238281613009, 0.7196017199237961, 0.7183967601692076, 0.717275041461361, 0.711778029931141, 0.7116803056888544, 0.7108641712113785, 0.711057100477952, 0.7073644280134707, 0.7065519861910774, 0.7046919208823396, 0.7025230986664283, 0.7023470878942729, 0.7027245953639937, 0.7001950556462608, 0.6986054256576213, 0.6956819068397575, 0.6943042075930104, 0.6939615232650664, 0.6935476649838186, 0.6923215251664202, 0.6907897831781799, 0.6892431757103893, 0.6884825067429603, 0.6867950464778337, 0.6863476863005921, 0.6857460898589427, 0.6844045017666426, 0.6843983269062366, 0.682700134174961, 0.6826701606618267, 0.682418595101744, 0.6811576605925048, 0.6790153260145034, 0.6793309699629211, 0.6786395766896225, 0.677749172475875, 0.6755192950955148, 0.675901084853608, 0.674413770380298, 0.6735570096787388, 0.6752019604863316, 0.6734113138047157, 0.6708399104579468, 0.6730051475477185, 0.6716217877103515, 0.6707939204777913, 0.6699221078310885, 0.6708356480710057, 0.6679829665761533], 'acc': [0.8059507969874512, 0.9055729373374872, 0.9133221576186504, 0.9244945736155751, 0.9361022934299794, 0.9419147441786914, 0.9460434063767259, 0.9494138772003059, 0.9519245252920728, 0.954111640133606, 0.956078778766407, 0.9577452026846758, 0.9589556057156484, 0.9600568653960943, 0.960802862139969, 0.9613631252517044, 0.9622301836343492, 0.9627279682662796, 0.9631745175456045, 0.9636410190491395, 0.9639855721684724, 0.9642644287408437, 0.9646214523348456, 0.9649786457814434, 0.9652174532071828, 0.9654541158622052, 0.9656756531802173, 0.965905386663605, 0.966019073227638, 0.9661511619605795, 0.9664099781545102, 0.9666077140936682, 0.966691794054076, 0.9667935324207764, 0.9670027981289594, 0.9671329542378807, 0.9672019075943059, 0.9672511156131466, 0.9673824601919918, 0.9674549462304413, 0.9675379866898302, 0.9675933262855989, 0.9676428581297697, 0.9677116954087471, 0.967827094862505, 0.9678672715106897, 0.9679635635332244, 0.9679951407842771, 0.9680704140125039, 0.9681233262101818, 0.968133036927161, 0.968242744293935, 0.9682282835835911, 0.9683484720719695, 0.9683494501746523, 0.9683520489770244, 0.9683930527944681, 0.9684343108534101, 0.9685002570722278, 0.9684988291872296, 0.9685373258229113, 0.9686151888565827, 0.968654477641837, 0.968650413393718, 0.9686886734899257, 0.9687204779988119, 0.9687044385341064, 0.9687994007267643, 0.9688807268657461, 0.9688471116255484, 0.9688696086065053, 0.9688930074440314, 0.9689515632278515, 0.9689716887069768, 0.9690101493976553, 0.9690237157607323, 0.9690402520707948, 0.9690645943258553, 0.9690668300409889, 0.9691167537639896, 0.9691223415891111, 0.9691476944610672, 0.9691792127053721, 0.9691566028215164, 0.9692436051605026, 0.969241921311493, 0.9692731746945086, 0.9692817422109143, 0.9692739543024782, 0.9693100357328989, 0.969365345455167, 0.9693914119315256, 0.9693569197186657, 0.9693476300707061, 0.96943460227995, 0.96941408807519, 0.9694577823867939, 0.969462314418201, 0.9694384958284522, 0.9694707597429496, 0.9695146551543897, 0.9694990422536628, 0.9695590557675103, 0.9695627091962739, 0.9695079504432842, 0.9695430628889524, 0.9695943926167653], 'mDice': [0.023227042180793203, 0.06446733399789673, 0.13532337888537885, 0.22400677332964666, 0.31807115164026883, 0.37977855608974065, 0.4280339903668626, 0.4668960617199017, 0.4980401421877317, 0.5242105569429776, 0.5498352087224501, 0.5725469202450929, 0.5900077090532135, 0.6043752061386851, 0.614868202135732, 0.6260093711272099, 0.6364378299139724, 0.6432812345007993, 0.6503495836360431, 0.6585017871338512, 0.6637060093102434, 0.66984696532167, 0.6764262728241824, 0.6813664119597235, 0.6852037101265124, 0.6894346548487698, 0.6920987311612743, 0.6958994859723222, 0.6992314165493227, 0.7003061318699317, 0.7030109662499439, 0.7061068645120379, 0.7075812521230244, 0.7102283118859891, 0.7128871302488512, 0.7148579700781219, 0.71536093517508, 0.7165745366636085, 0.7180420908234357, 0.7195010048650687, 0.7215514043535115, 0.7218454076590674, 0.7231855626418877, 0.7238430703899187, 0.7262564291169942, 0.7263804508872723, 0.7281815568530136, 0.728065431936561, 0.7294976622941017, 0.7305869479039303, 0.730843067389842, 0.7322859739257921, 0.7322932205380703, 0.7338564193331315, 0.7341661620942966, 0.7346516422890011, 0.7355111541783921, 0.7365801433817083, 0.7365012799808055, 0.7371070390459972, 0.7372725623901573, 0.7394468915513742, 0.7392913919090798, 0.7395199237759255, 0.7397826347853308, 0.7408587828239394, 0.7408460801659036, 0.7415786468885894, 0.7425123700413409, 0.7422585112968264, 0.7423229189698611, 0.7430938567128988, 0.7438636571418024, 0.7446598338289309, 0.7455500500823422, 0.7454503238315027, 0.7455032310965296, 0.7457946882502459, 0.7463712885580799, 0.747132428917533, 0.7475094816366983, 0.747867267079703, 0.7480200704410477, 0.748238754537244, 0.748769525912772, 0.7484593559683779, 0.7493395481782681, 0.7494109099851407, 0.74951187737779, 0.7498225995086103, 0.750518328276004, 0.7502767562453377, 0.7507724381159392, 0.7509325163330814, 0.7517811013187689, 0.7514047873014478, 0.7520339938615995, 0.7524300193712595, 0.7518639159937135, 0.7524874492579324, 0.7534861608410838, 0.7524980005683836, 0.7531878707059847, 0.753425278177061, 0.7537920453652637, 0.7536111190107235, 0.7543294151970444]}
predicting test subjects:   0%|          | 0/15 [00:00<?, ?it/s]predicting test subjects:   7%|▋         | 1/15 [00:01<00:27,  1.95s/it]predicting test subjects:  13%|█▎        | 2/15 [00:03<00:24,  1.88s/it]predicting test subjects:  20%|██        | 3/15 [00:05<00:22,  1.89s/it]predicting test subjects:  27%|██▋       | 4/15 [00:07<00:21,  1.92s/it]predicting test subjects:  33%|███▎      | 5/15 [00:09<00:20,  2.03s/it]predicting test subjects:  40%|████      | 6/15 [00:12<00:19,  2.11s/it]predicting test subjects:  47%|████▋     | 7/15 [00:13<00:15,  1.94s/it]predicting test subjects:  53%|█████▎    | 8/15 [00:15<00:14,  2.05s/it]predicting test subjects:  60%|██████    | 9/15 [00:17<00:11,  2.00s/it]predicting test subjects:  67%|██████▋   | 10/15 [00:19<00:09,  1.87s/it]predicting test subjects:  73%|███████▎  | 11/15 [00:21<00:07,  1.83s/it]predicting test subjects:  80%|████████  | 12/15 [00:23<00:05,  1.90s/it]predicting test subjects:  87%|████████▋ | 13/15 [00:25<00:03,  1.94s/it]predicting test subjects:  93%|█████████▎| 14/15 [00:27<00:01,  1.91s/it]predicting test subjects: 100%|██████████| 15/15 [00:29<00:00,  1.92s/it]
predicting train subjects:   0%|          | 0/532 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/532 [00:02<19:52,  2.25s/it]predicting train subjects:   0%|          | 2/532 [00:03<18:26,  2.09s/it]predicting train subjects:   1%|          | 3/532 [00:05<17:28,  1.98s/it]predicting train subjects:   1%|          | 4/532 [00:07<16:59,  1.93s/it]predicting train subjects:   1%|          | 5/532 [00:09<16:40,  1.90s/it]predicting train subjects:   1%|          | 6/532 [00:11<16:04,  1.83s/it]predicting train subjects:   1%|▏         | 7/532 [00:12<15:43,  1.80s/it]predicting train subjects:   2%|▏         | 8/532 [00:14<15:23,  1.76s/it]predicting train subjects:   2%|▏         | 9/532 [00:16<15:58,  1.83s/it]predicting train subjects:   2%|▏         | 10/532 [00:18<15:38,  1.80s/it]predicting train subjects:   2%|▏         | 11/532 [00:19<15:00,  1.73s/it]predicting train subjects:   2%|▏         | 12/532 [00:21<16:10,  1.87s/it]predicting train subjects:   2%|▏         | 13/532 [00:23<15:30,  1.79s/it]predicting train subjects:   3%|▎         | 14/532 [00:25<14:43,  1.71s/it]predicting train subjects:   3%|▎         | 15/532 [00:26<14:49,  1.72s/it]predicting train subjects:   3%|▎         | 16/532 [00:28<15:08,  1.76s/it]predicting train subjects:   3%|▎         | 17/532 [00:30<14:36,  1.70s/it]predicting train subjects:   3%|▎         | 18/532 [00:32<15:22,  1.79s/it]predicting train subjects:   4%|▎         | 19/532 [00:33<14:29,  1.69s/it]predicting train subjects:   4%|▍         | 20/532 [00:35<14:33,  1.71s/it]predicting train subjects:   4%|▍         | 21/532 [00:37<15:28,  1.82s/it]predicting train subjects:   4%|▍         | 22/532 [00:39<15:00,  1.77s/it]predicting train subjects:   4%|▍         | 23/532 [00:40<15:00,  1.77s/it]predicting train subjects:   5%|▍         | 24/532 [00:42<14:16,  1.69s/it]predicting train subjects:   5%|▍         | 25/532 [00:44<15:30,  1.83s/it]predicting train subjects:   5%|▍         | 26/532 [00:46<14:58,  1.78s/it]predicting train subjects:   5%|▌         | 27/532 [00:48<16:11,  1.92s/it]predicting train subjects:   5%|▌         | 28/532 [00:50<15:48,  1.88s/it]predicting train subjects:   5%|▌         | 29/532 [00:52<16:08,  1.93s/it]predicting train subjects:   6%|▌         | 30/532 [00:53<15:10,  1.81s/it]predicting train subjects:   6%|▌         | 31/532 [00:55<14:58,  1.79s/it]predicting train subjects:   6%|▌         | 32/532 [00:57<14:57,  1.80s/it]predicting train subjects:   6%|▌         | 33/532 [00:58<14:14,  1.71s/it]predicting train subjects:   6%|▋         | 34/532 [01:01<15:15,  1.84s/it]predicting train subjects:   7%|▋         | 35/532 [01:02<14:52,  1.80s/it]predicting train subjects:   7%|▋         | 36/532 [01:04<15:01,  1.82s/it]predicting train subjects:   7%|▋         | 37/532 [01:06<15:07,  1.83s/it]predicting train subjects:   7%|▋         | 38/532 [01:08<15:24,  1.87s/it]predicting train subjects:   7%|▋         | 39/532 [01:10<15:12,  1.85s/it]predicting train subjects:   8%|▊         | 40/532 [01:11<14:43,  1.80s/it]predicting train subjects:   8%|▊         | 41/532 [01:13<15:01,  1.84s/it]predicting train subjects:   8%|▊         | 42/532 [01:15<14:59,  1.84s/it]predicting train subjects:   8%|▊         | 43/532 [01:17<14:07,  1.73s/it]predicting train subjects:   8%|▊         | 44/532 [01:18<13:31,  1.66s/it]predicting train subjects:   8%|▊         | 45/532 [01:20<13:20,  1.64s/it]predicting train subjects:   9%|▊         | 46/532 [01:22<13:54,  1.72s/it]predicting train subjects:   9%|▉         | 47/532 [01:24<14:53,  1.84s/it]predicting train subjects:   9%|▉         | 48/532 [01:26<15:13,  1.89s/it]predicting train subjects:   9%|▉         | 49/532 [01:27<14:33,  1.81s/it]predicting train subjects:   9%|▉         | 50/532 [01:29<15:11,  1.89s/it]predicting train subjects:  10%|▉         | 51/532 [01:31<14:36,  1.82s/it]predicting train subjects:  10%|▉         | 52/532 [01:33<14:24,  1.80s/it]predicting train subjects:  10%|▉         | 53/532 [01:35<14:00,  1.75s/it]predicting train subjects:  10%|█         | 54/532 [01:37<14:46,  1.85s/it]predicting train subjects:  10%|█         | 55/532 [01:38<14:43,  1.85s/it]predicting train subjects:  11%|█         | 56/532 [01:40<14:37,  1.84s/it]predicting train subjects:  11%|█         | 57/532 [01:42<14:24,  1.82s/it]predicting train subjects:  11%|█         | 58/532 [01:44<14:24,  1.82s/it]predicting train subjects:  11%|█         | 59/532 [01:46<15:36,  1.98s/it]predicting train subjects:  11%|█▏        | 60/532 [01:48<14:35,  1.86s/it]predicting train subjects:  11%|█▏        | 61/532 [01:49<14:10,  1.81s/it]predicting train subjects:  12%|█▏        | 62/532 [01:51<14:35,  1.86s/it]predicting train subjects:  12%|█▏        | 63/532 [01:54<15:01,  1.92s/it]predicting train subjects:  12%|█▏        | 64/532 [01:55<14:28,  1.85s/it]predicting train subjects:  12%|█▏        | 65/532 [01:57<14:15,  1.83s/it]predicting train subjects:  12%|█▏        | 66/532 [01:59<15:24,  1.98s/it]predicting train subjects:  13%|█▎        | 67/532 [02:02<15:45,  2.03s/it]predicting train subjects:  13%|█▎        | 68/532 [02:03<15:36,  2.02s/it]predicting train subjects:  13%|█▎        | 69/532 [02:05<14:51,  1.92s/it]predicting train subjects:  13%|█▎        | 70/532 [02:07<14:13,  1.85s/it]predicting train subjects:  13%|█▎        | 71/532 [02:09<13:45,  1.79s/it]predicting train subjects:  14%|█▎        | 72/532 [02:10<13:28,  1.76s/it]predicting train subjects:  14%|█▎        | 73/532 [02:12<13:56,  1.82s/it]predicting train subjects:  14%|█▍        | 74/532 [02:14<14:59,  1.96s/it]predicting train subjects:  14%|█▍        | 75/532 [02:17<17:04,  2.24s/it]predicting train subjects:  14%|█▍        | 76/532 [02:19<15:59,  2.11s/it]predicting train subjects:  14%|█▍        | 77/532 [02:21<15:41,  2.07s/it]predicting train subjects:  15%|█▍        | 78/532 [02:23<15:12,  2.01s/it]predicting train subjects:  15%|█▍        | 79/532 [02:25<14:44,  1.95s/it]predicting train subjects:  15%|█▌        | 80/532 [02:27<14:29,  1.92s/it]predicting train subjects:  15%|█▌        | 81/532 [02:29<14:15,  1.90s/it]predicting train subjects:  15%|█▌        | 82/532 [02:30<14:08,  1.89s/it]predicting train subjects:  16%|█▌        | 83/532 [02:32<13:37,  1.82s/it]predicting train subjects:  16%|█▌        | 84/532 [02:34<13:08,  1.76s/it]predicting train subjects:  16%|█▌        | 85/532 [02:35<12:46,  1.71s/it]predicting train subjects:  16%|█▌        | 86/532 [02:37<12:38,  1.70s/it]predicting train subjects:  16%|█▋        | 87/532 [02:39<12:31,  1.69s/it]predicting train subjects:  17%|█▋        | 88/532 [02:40<12:23,  1.67s/it]predicting train subjects:  17%|█▋        | 89/532 [02:42<12:35,  1.70s/it]predicting train subjects:  17%|█▋        | 90/532 [02:44<12:36,  1.71s/it]predicting train subjects:  17%|█▋        | 91/532 [02:46<12:48,  1.74s/it]predicting train subjects:  17%|█▋        | 92/532 [02:47<12:58,  1.77s/it]predicting train subjects:  17%|█▋        | 93/532 [02:49<13:01,  1.78s/it]predicting train subjects:  18%|█▊        | 94/532 [02:51<13:08,  1.80s/it]predicting train subjects:  18%|█▊        | 95/532 [02:53<13:47,  1.89s/it]predicting train subjects:  18%|█▊        | 96/532 [02:55<14:01,  1.93s/it]predicting train subjects:  18%|█▊        | 97/532 [02:57<14:08,  1.95s/it]predicting train subjects:  18%|█▊        | 98/532 [02:59<14:22,  1.99s/it]predicting train subjects:  19%|█▊        | 99/532 [03:01<14:41,  2.03s/it]predicting train subjects:  19%|█▉        | 100/532 [03:04<15:12,  2.11s/it]predicting train subjects:  19%|█▉        | 101/532 [03:05<14:21,  2.00s/it]predicting train subjects:  19%|█▉        | 102/532 [03:07<13:42,  1.91s/it]predicting train subjects:  19%|█▉        | 103/532 [03:09<13:06,  1.83s/it]predicting train subjects:  20%|█▉        | 104/532 [03:10<12:39,  1.77s/it]predicting train subjects:  20%|█▉        | 105/532 [03:12<12:15,  1.72s/it]predicting train subjects:  20%|█▉        | 106/532 [03:14<12:06,  1.70s/it]predicting train subjects:  20%|██        | 107/532 [03:15<11:46,  1.66s/it]predicting train subjects:  20%|██        | 108/532 [03:17<11:39,  1.65s/it]predicting train subjects:  20%|██        | 109/532 [03:18<11:30,  1.63s/it]predicting train subjects:  21%|██        | 110/532 [03:20<11:24,  1.62s/it]predicting train subjects:  21%|██        | 111/532 [03:22<11:16,  1.61s/it]predicting train subjects:  21%|██        | 112/532 [03:23<11:09,  1.59s/it]predicting train subjects:  21%|██        | 113/532 [03:25<11:45,  1.68s/it]predicting train subjects:  21%|██▏       | 114/532 [03:27<12:15,  1.76s/it]predicting train subjects:  22%|██▏       | 115/532 [03:29<12:41,  1.83s/it]predicting train subjects:  22%|██▏       | 116/532 [03:31<12:45,  1.84s/it]predicting train subjects:  22%|██▏       | 117/532 [03:33<12:57,  1.87s/it]predicting train subjects:  22%|██▏       | 118/532 [03:35<13:03,  1.89s/it]predicting train subjects:  22%|██▏       | 119/532 [03:37<12:45,  1.85s/it]predicting train subjects:  23%|██▎       | 120/532 [03:38<12:34,  1.83s/it]predicting train subjects:  23%|██▎       | 121/532 [03:40<12:19,  1.80s/it]predicting train subjects:  23%|██▎       | 122/532 [03:42<12:18,  1.80s/it]predicting train subjects:  23%|██▎       | 123/532 [03:44<12:23,  1.82s/it]predicting train subjects:  23%|██▎       | 124/532 [03:46<12:28,  1.83s/it]predicting train subjects:  23%|██▎       | 125/532 [03:48<13:03,  1.92s/it]predicting train subjects:  24%|██▎       | 126/532 [03:50<13:10,  1.95s/it]predicting train subjects:  24%|██▍       | 127/532 [03:52<13:08,  1.95s/it]predicting train subjects:  24%|██▍       | 128/532 [03:54<13:05,  1.95s/it]predicting train subjects:  24%|██▍       | 129/532 [03:56<13:03,  1.94s/it]predicting train subjects:  24%|██▍       | 130/532 [03:57<13:03,  1.95s/it]predicting train subjects:  25%|██▍       | 131/532 [04:00<13:34,  2.03s/it]predicting train subjects:  25%|██▍       | 132/532 [04:02<13:49,  2.07s/it]predicting train subjects:  25%|██▌       | 133/532 [04:04<14:14,  2.14s/it]predicting train subjects:  25%|██▌       | 134/532 [04:06<14:21,  2.17s/it]predicting train subjects:  25%|██▌       | 135/532 [04:09<14:22,  2.17s/it]predicting train subjects:  26%|██▌       | 136/532 [04:11<14:25,  2.19s/it]predicting train subjects:  26%|██▌       | 137/532 [04:13<14:33,  2.21s/it]predicting train subjects:  26%|██▌       | 138/532 [04:15<14:42,  2.24s/it]predicting train subjects:  26%|██▌       | 139/532 [04:18<14:39,  2.24s/it]predicting train subjects:  26%|██▋       | 140/532 [04:20<14:38,  2.24s/it]predicting train subjects:  27%|██▋       | 141/532 [04:22<14:38,  2.25s/it]predicting train subjects:  27%|██▋       | 142/532 [04:24<14:27,  2.22s/it]predicting train subjects:  27%|██▋       | 143/532 [04:26<13:23,  2.07s/it]predicting train subjects:  27%|██▋       | 144/532 [04:28<12:41,  1.96s/it]predicting train subjects:  27%|██▋       | 145/532 [04:29<12:10,  1.89s/it]predicting train subjects:  27%|██▋       | 146/532 [04:31<11:56,  1.86s/it]predicting train subjects:  28%|██▊       | 147/532 [04:33<11:40,  1.82s/it]predicting train subjects:  28%|██▊       | 148/532 [04:35<11:30,  1.80s/it]predicting train subjects:  28%|██▊       | 149/532 [04:36<11:24,  1.79s/it]predicting train subjects:  28%|██▊       | 150/532 [04:38<11:28,  1.80s/it]predicting train subjects:  28%|██▊       | 151/532 [04:40<11:29,  1.81s/it]predicting train subjects:  29%|██▊       | 152/532 [04:42<11:32,  1.82s/it]predicting train subjects:  29%|██▉       | 153/532 [04:44<11:35,  1.83s/it]predicting train subjects:  29%|██▉       | 154/532 [04:46<11:25,  1.81s/it]predicting train subjects:  29%|██▉       | 155/532 [04:48<12:12,  1.94s/it]predicting train subjects:  29%|██▉       | 156/532 [04:50<12:40,  2.02s/it]predicting train subjects:  30%|██▉       | 157/532 [04:52<13:04,  2.09s/it]predicting train subjects:  30%|██▉       | 158/532 [04:55<13:24,  2.15s/it]predicting train subjects:  30%|██▉       | 159/532 [04:57<13:40,  2.20s/it]predicting train subjects:  30%|███       | 160/532 [04:59<13:52,  2.24s/it]predicting train subjects:  30%|███       | 161/532 [05:01<13:15,  2.14s/it]predicting train subjects:  30%|███       | 162/532 [05:03<12:31,  2.03s/it]predicting train subjects:  31%|███       | 163/532 [05:05<11:58,  1.95s/it]predicting train subjects:  31%|███       | 164/532 [05:06<11:35,  1.89s/it]predicting train subjects:  31%|███       | 165/532 [05:08<11:24,  1.86s/it]predicting train subjects:  31%|███       | 166/532 [05:10<11:11,  1.83s/it]predicting train subjects:  31%|███▏      | 167/532 [05:12<11:09,  1.83s/it]predicting train subjects:  32%|███▏      | 168/532 [05:14<11:06,  1.83s/it]predicting train subjects:  32%|███▏      | 169/532 [05:16<11:06,  1.84s/it]predicting train subjects:  32%|███▏      | 170/532 [05:17<11:01,  1.83s/it]predicting train subjects:  32%|███▏      | 171/532 [05:19<11:01,  1.83s/it]predicting train subjects:  32%|███▏      | 172/532 [05:21<10:59,  1.83s/it]predicting train subjects:  33%|███▎      | 173/532 [05:23<10:47,  1.80s/it]predicting train subjects:  33%|███▎      | 174/532 [05:25<10:45,  1.80s/it]predicting train subjects:  33%|███▎      | 175/532 [05:26<10:37,  1.79s/it]predicting train subjects:  33%|███▎      | 176/532 [05:28<10:24,  1.75s/it]predicting train subjects:  33%|███▎      | 177/532 [05:30<10:11,  1.72s/it]predicting train subjects:  33%|███▎      | 178/532 [05:31<10:05,  1.71s/it]predicting train subjects:  34%|███▎      | 179/532 [05:33<10:06,  1.72s/it]predicting train subjects:  34%|███▍      | 180/532 [05:35<10:06,  1.72s/it]predicting train subjects:  34%|███▍      | 181/532 [05:37<10:08,  1.73s/it]predicting train subjects:  34%|███▍      | 182/532 [05:38<10:07,  1.73s/it]predicting train subjects:  34%|███▍      | 183/532 [05:40<10:06,  1.74s/it]predicting train subjects:  35%|███▍      | 184/532 [05:42<10:06,  1.74s/it]predicting train subjects:  35%|███▍      | 185/532 [05:43<09:55,  1.72s/it]predicting train subjects:  35%|███▍      | 186/532 [05:45<09:47,  1.70s/it]predicting train subjects:  35%|███▌      | 187/532 [05:47<09:40,  1.68s/it]predicting train subjects:  35%|███▌      | 188/532 [05:48<09:46,  1.70s/it]predicting train subjects:  36%|███▌      | 189/532 [05:50<09:52,  1.73s/it]predicting train subjects:  36%|███▌      | 190/532 [05:52<09:49,  1.72s/it]predicting train subjects:  36%|███▌      | 191/532 [05:54<11:02,  1.94s/it]predicting train subjects:  36%|███▌      | 192/532 [05:57<11:48,  2.08s/it]predicting train subjects:  36%|███▋      | 193/532 [05:59<12:23,  2.19s/it]predicting train subjects:  36%|███▋      | 194/532 [06:02<12:51,  2.28s/it]predicting train subjects:  37%|███▋      | 195/532 [06:04<13:00,  2.31s/it]predicting train subjects:  37%|███▋      | 196/532 [06:07<13:06,  2.34s/it]predicting train subjects:  37%|███▋      | 197/532 [06:09<12:48,  2.29s/it]predicting train subjects:  37%|███▋      | 198/532 [06:11<12:27,  2.24s/it]predicting train subjects:  37%|███▋      | 199/532 [06:13<12:03,  2.17s/it]predicting train subjects:  38%|███▊      | 200/532 [06:15<11:49,  2.14s/it]predicting train subjects:  38%|███▊      | 201/532 [06:17<11:27,  2.08s/it]predicting train subjects:  38%|███▊      | 202/532 [06:19<11:13,  2.04s/it]predicting train subjects:  38%|███▊      | 203/532 [06:21<10:53,  1.99s/it]predicting train subjects:  38%|███▊      | 204/532 [06:22<10:26,  1.91s/it]predicting train subjects:  39%|███▊      | 205/532 [06:24<10:09,  1.87s/it]predicting train subjects:  39%|███▊      | 206/532 [06:26<09:59,  1.84s/it]predicting train subjects:  39%|███▉      | 207/532 [06:28<09:46,  1.80s/it]predicting train subjects:  39%|███▉      | 208/532 [06:30<09:53,  1.83s/it]predicting train subjects:  39%|███▉      | 209/532 [06:31<09:28,  1.76s/it]predicting train subjects:  39%|███▉      | 210/532 [06:33<09:00,  1.68s/it]predicting train subjects:  40%|███▉      | 211/532 [06:34<08:52,  1.66s/it]predicting train subjects:  40%|███▉      | 212/532 [06:36<08:41,  1.63s/it]predicting train subjects:  40%|████      | 213/532 [06:37<08:34,  1.61s/it]predicting train subjects:  40%|████      | 214/532 [06:39<08:26,  1.59s/it]predicting train subjects:  40%|████      | 215/532 [06:41<09:20,  1.77s/it]predicting train subjects:  41%|████      | 216/532 [06:43<09:55,  1.89s/it]predicting train subjects:  41%|████      | 217/532 [06:45<10:18,  1.96s/it]predicting train subjects:  41%|████      | 218/532 [06:48<10:42,  2.05s/it]predicting train subjects:  41%|████      | 219/532 [06:50<10:54,  2.09s/it]predicting train subjects:  41%|████▏     | 220/532 [06:52<11:03,  2.13s/it]predicting train subjects:  42%|████▏     | 221/532 [06:54<10:16,  1.98s/it]predicting train subjects:  42%|████▏     | 222/532 [06:55<09:38,  1.87s/it]predicting train subjects:  42%|████▏     | 223/532 [06:57<09:18,  1.81s/it]predicting train subjects:  42%|████▏     | 224/532 [06:59<09:00,  1.76s/it]predicting train subjects:  42%|████▏     | 225/532 [07:00<08:47,  1.72s/it]predicting train subjects:  42%|████▏     | 226/532 [07:02<08:34,  1.68s/it]predicting train subjects:  43%|████▎     | 227/532 [07:03<08:16,  1.63s/it]predicting train subjects:  43%|████▎     | 228/532 [07:05<08:07,  1.60s/it]predicting train subjects:  43%|████▎     | 229/532 [07:06<07:56,  1.57s/it]predicting train subjects:  43%|████▎     | 230/532 [07:08<07:51,  1.56s/it]predicting train subjects:  43%|████▎     | 231/532 [07:09<07:40,  1.53s/it]predicting train subjects:  44%|████▎     | 232/532 [07:11<07:35,  1.52s/it]predicting train subjects:  44%|████▍     | 233/532 [07:13<07:52,  1.58s/it]predicting train subjects:  44%|████▍     | 234/532 [07:14<08:08,  1.64s/it]predicting train subjects:  44%|████▍     | 235/532 [07:16<08:18,  1.68s/it]predicting train subjects:  44%|████▍     | 236/532 [07:18<08:24,  1.70s/it]predicting train subjects:  45%|████▍     | 237/532 [07:20<08:27,  1.72s/it]predicting train subjects:  45%|████▍     | 238/532 [07:21<08:35,  1.75s/it]predicting train subjects:  45%|████▍     | 239/532 [07:23<08:48,  1.80s/it]predicting train subjects:  45%|████▌     | 240/532 [07:25<08:50,  1.82s/it]predicting train subjects:  45%|████▌     | 241/532 [07:27<09:01,  1.86s/it]predicting train subjects:  45%|████▌     | 242/532 [07:29<09:03,  1.87s/it]predicting train subjects:  46%|████▌     | 243/532 [07:31<09:03,  1.88s/it]predicting train subjects:  46%|████▌     | 244/532 [07:33<08:57,  1.87s/it]predicting train subjects:  46%|████▌     | 245/532 [07:34<08:35,  1.80s/it]predicting train subjects:  46%|████▌     | 246/532 [07:36<08:09,  1.71s/it]predicting train subjects:  46%|████▋     | 247/532 [07:37<07:47,  1.64s/it]predicting train subjects:  47%|████▋     | 248/532 [07:39<07:30,  1.59s/it]predicting train subjects:  47%|████▋     | 249/532 [07:40<07:23,  1.57s/it]predicting train subjects:  47%|████▋     | 250/532 [07:42<07:19,  1.56s/it]predicting train subjects:  47%|████▋     | 251/532 [07:44<07:25,  1.59s/it]predicting train subjects:  47%|████▋     | 252/532 [07:45<07:26,  1.59s/it]predicting train subjects:  48%|████▊     | 253/532 [07:47<07:23,  1.59s/it]predicting train subjects:  48%|████▊     | 254/532 [07:48<07:24,  1.60s/it]predicting train subjects:  48%|████▊     | 255/532 [07:50<07:27,  1.62s/it]predicting train subjects:  48%|████▊     | 256/532 [07:52<07:28,  1.63s/it]predicting train subjects:  48%|████▊     | 257/532 [07:54<08:01,  1.75s/it]predicting train subjects:  48%|████▊     | 258/532 [07:56<08:29,  1.86s/it]predicting train subjects:  49%|████▊     | 259/532 [07:58<08:44,  1.92s/it]predicting train subjects:  49%|████▉     | 260/532 [08:00<08:47,  1.94s/it]predicting train subjects:  49%|████▉     | 261/532 [08:02<09:00,  1.99s/it]predicting train subjects:  49%|████▉     | 262/532 [08:04<09:03,  2.01s/it]predicting train subjects:  49%|████▉     | 263/532 [08:06<08:14,  1.84s/it]predicting train subjects:  50%|████▉     | 264/532 [08:07<07:46,  1.74s/it]predicting train subjects:  50%|████▉     | 265/532 [08:09<07:20,  1.65s/it]predicting train subjects:  50%|█████     | 266/532 [08:10<06:58,  1.57s/it]predicting train subjects:  50%|█████     | 267/532 [08:11<06:48,  1.54s/it]predicting train subjects:  50%|█████     | 268/532 [08:13<06:39,  1.51s/it]predicting train subjects:  51%|█████     | 269/532 [08:15<07:01,  1.60s/it]predicting train subjects:  51%|█████     | 270/532 [08:16<07:19,  1.68s/it]predicting train subjects:  51%|█████     | 271/532 [08:18<07:28,  1.72s/it]predicting train subjects:  51%|█████     | 272/532 [08:20<07:31,  1.74s/it]predicting train subjects:  51%|█████▏    | 273/532 [08:22<07:31,  1.74s/it]predicting train subjects:  52%|█████▏    | 274/532 [08:24<07:33,  1.76s/it]predicting train subjects:  52%|█████▏    | 275/532 [08:26<08:10,  1.91s/it]predicting train subjects:  52%|█████▏    | 276/532 [08:28<08:39,  2.03s/it]predicting train subjects:  52%|█████▏    | 277/532 [08:31<08:57,  2.11s/it]predicting train subjects:  52%|█████▏    | 278/532 [08:33<09:10,  2.17s/it]predicting train subjects:  52%|█████▏    | 279/532 [08:35<09:12,  2.18s/it]predicting train subjects:  53%|█████▎    | 280/532 [08:37<09:18,  2.22s/it]predicting train subjects:  53%|█████▎    | 281/532 [08:39<09:10,  2.19s/it]predicting train subjects:  53%|█████▎    | 282/532 [08:42<08:59,  2.16s/it]predicting train subjects:  53%|█████▎    | 283/532 [08:44<08:45,  2.11s/it]predicting train subjects:  53%|█████▎    | 284/532 [08:46<08:49,  2.14s/it]predicting train subjects:  54%|█████▎    | 285/532 [08:48<08:48,  2.14s/it]predicting train subjects:  54%|█████▍    | 286/532 [08:50<08:37,  2.10s/it]predicting train subjects:  54%|█████▍    | 287/532 [08:52<08:08,  1.99s/it]predicting train subjects:  54%|█████▍    | 288/532 [08:53<07:45,  1.91s/it]predicting train subjects:  54%|█████▍    | 289/532 [08:55<07:23,  1.83s/it]predicting train subjects:  55%|█████▍    | 290/532 [08:57<07:07,  1.77s/it]predicting train subjects:  55%|█████▍    | 291/532 [08:58<06:58,  1.74s/it]predicting train subjects:  55%|█████▍    | 292/532 [09:00<06:52,  1.72s/it]predicting train subjects:  55%|█████▌    | 293/532 [09:02<06:58,  1.75s/it]predicting train subjects:  55%|█████▌    | 294/532 [09:04<06:57,  1.76s/it]predicting train subjects:  55%|█████▌    | 295/532 [09:05<07:04,  1.79s/it]predicting train subjects:  56%|█████▌    | 296/532 [09:07<07:04,  1.80s/it]predicting train subjects:  56%|█████▌    | 297/532 [09:09<07:07,  1.82s/it]predicting train subjects:  56%|█████▌    | 298/532 [09:11<07:11,  1.85s/it]predicting train subjects:  56%|█████▌    | 299/532 [09:13<06:51,  1.77s/it]predicting train subjects:  56%|█████▋    | 300/532 [09:14<06:33,  1.70s/it]predicting train subjects:  57%|█████▋    | 301/532 [09:16<06:25,  1.67s/it]predicting train subjects:  57%|█████▋    | 302/532 [09:17<06:16,  1.64s/it]predicting train subjects:  57%|█████▋    | 303/532 [09:19<06:12,  1.63s/it]predicting train subjects:  57%|█████▋    | 304/532 [09:20<06:08,  1.62s/it]predicting train subjects:  57%|█████▋    | 305/532 [09:23<06:52,  1.82s/it]predicting train subjects:  58%|█████▊    | 306/532 [09:25<07:15,  1.93s/it]predicting train subjects:  58%|█████▊    | 307/532 [09:27<07:39,  2.04s/it]predicting train subjects:  58%|█████▊    | 308/532 [09:29<07:46,  2.08s/it]predicting train subjects:  58%|█████▊    | 309/532 [09:32<07:58,  2.15s/it]predicting train subjects:  58%|█████▊    | 310/532 [09:34<08:01,  2.17s/it]predicting train subjects:  58%|█████▊    | 311/532 [09:37<08:43,  2.37s/it]predicting train subjects:  59%|█████▊    | 312/532 [09:40<09:13,  2.51s/it]predicting train subjects:  59%|█████▉    | 313/532 [09:43<09:41,  2.65s/it]predicting train subjects:  59%|█████▉    | 314/532 [09:45<09:52,  2.72s/it]predicting train subjects:  59%|█████▉    | 315/532 [09:48<10:00,  2.77s/it]predicting train subjects:  59%|█████▉    | 316/532 [09:51<10:02,  2.79s/it]predicting train subjects:  60%|█████▉    | 317/532 [09:53<08:56,  2.50s/it]predicting train subjects:  60%|█████▉    | 318/532 [09:55<08:03,  2.26s/it]predicting train subjects:  60%|█████▉    | 319/532 [09:56<07:24,  2.09s/it]predicting train subjects:  60%|██████    | 320/532 [09:58<06:57,  1.97s/it]predicting train subjects:  60%|██████    | 321/532 [10:00<06:41,  1.90s/it]predicting train subjects:  61%|██████    | 322/532 [10:02<06:29,  1.86s/it]predicting train subjects:  61%|██████    | 323/532 [10:04<06:59,  2.01s/it]predicting train subjects:  61%|██████    | 324/532 [10:06<07:17,  2.10s/it]predicting train subjects:  61%|██████    | 325/532 [10:09<07:28,  2.17s/it]predicting train subjects:  61%|██████▏   | 326/532 [10:11<07:40,  2.23s/it]predicting train subjects:  61%|██████▏   | 327/532 [10:13<07:45,  2.27s/it]predicting train subjects:  62%|██████▏   | 328/532 [10:16<07:45,  2.28s/it]predicting train subjects:  62%|██████▏   | 329/532 [10:17<07:12,  2.13s/it]predicting train subjects:  62%|██████▏   | 330/532 [10:19<06:56,  2.06s/it]predicting train subjects:  62%|██████▏   | 331/532 [10:21<06:39,  1.99s/it]predicting train subjects:  62%|██████▏   | 332/532 [10:23<06:27,  1.94s/it]predicting train subjects:  63%|██████▎   | 333/532 [10:25<06:20,  1.91s/it]predicting train subjects:  63%|██████▎   | 334/532 [10:27<06:10,  1.87s/it]predicting train subjects:  63%|██████▎   | 335/532 [10:29<06:24,  1.95s/it]predicting train subjects:  63%|██████▎   | 336/532 [10:31<06:25,  1.97s/it]predicting train subjects:  63%|██████▎   | 337/532 [10:33<06:21,  1.96s/it]predicting train subjects:  64%|██████▎   | 338/532 [10:35<06:22,  1.97s/it]predicting train subjects:  64%|██████▎   | 339/532 [10:37<06:15,  1.95s/it]predicting train subjects:  64%|██████▍   | 340/532 [10:39<06:12,  1.94s/it]predicting train subjects:  64%|██████▍   | 341/532 [10:40<05:54,  1.86s/it]predicting train subjects:  64%|██████▍   | 342/532 [10:42<05:35,  1.77s/it]predicting train subjects:  64%|██████▍   | 343/532 [10:43<05:21,  1.70s/it]predicting train subjects:  65%|██████▍   | 344/532 [10:45<05:17,  1.69s/it]predicting train subjects:  65%|██████▍   | 345/532 [10:47<05:12,  1.67s/it]predicting train subjects:  65%|██████▌   | 346/532 [10:48<05:03,  1.63s/it]predicting train subjects:  65%|██████▌   | 347/532 [10:50<05:12,  1.69s/it]predicting train subjects:  65%|██████▌   | 348/532 [10:52<05:18,  1.73s/it]predicting train subjects:  66%|██████▌   | 349/532 [10:54<05:24,  1.78s/it]predicting train subjects:  66%|██████▌   | 350/532 [10:55<05:22,  1.77s/it]predicting train subjects:  66%|██████▌   | 351/532 [10:57<05:25,  1.80s/it]predicting train subjects:  66%|██████▌   | 352/532 [10:59<05:21,  1.79s/it]predicting train subjects:  66%|██████▋   | 353/532 [11:01<05:19,  1.79s/it]predicting train subjects:  67%|██████▋   | 354/532 [11:03<05:21,  1.80s/it]predicting train subjects:  67%|██████▋   | 355/532 [11:04<05:18,  1.80s/it]predicting train subjects:  67%|██████▋   | 356/532 [11:06<05:14,  1.79s/it]predicting train subjects:  67%|██████▋   | 357/532 [11:08<05:16,  1.81s/it]predicting train subjects:  67%|██████▋   | 358/532 [11:10<05:12,  1.80s/it]predicting train subjects:  67%|██████▋   | 359/532 [11:11<04:58,  1.72s/it]predicting train subjects:  68%|██████▊   | 360/532 [11:13<04:46,  1.66s/it]predicting train subjects:  68%|██████▊   | 361/532 [11:14<04:37,  1.62s/it]predicting train subjects:  68%|██████▊   | 362/532 [11:16<04:29,  1.59s/it]predicting train subjects:  68%|██████▊   | 363/532 [11:17<04:27,  1.58s/it]predicting train subjects:  68%|██████▊   | 364/532 [11:19<04:25,  1.58s/it]predicting train subjects:  69%|██████▊   | 365/532 [11:21<04:24,  1.59s/it]predicting train subjects:  69%|██████▉   | 366/532 [11:22<04:26,  1.61s/it]predicting train subjects:  69%|██████▉   | 367/532 [11:24<04:26,  1.62s/it]predicting train subjects:  69%|██████▉   | 368/532 [11:26<04:27,  1.63s/it]predicting train subjects:  69%|██████▉   | 369/532 [11:27<04:25,  1.63s/it]predicting train subjects:  70%|██████▉   | 370/532 [11:29<04:24,  1.63s/it]predicting train subjects:  70%|██████▉   | 371/532 [11:31<04:52,  1.82s/it]predicting train subjects:  70%|██████▉   | 372/532 [11:33<05:09,  1.93s/it]predicting train subjects:  70%|███████   | 373/532 [11:36<05:23,  2.04s/it]predicting train subjects:  70%|███████   | 374/532 [11:38<05:29,  2.09s/it]predicting train subjects:  70%|███████   | 375/532 [11:40<05:34,  2.13s/it]predicting train subjects:  71%|███████   | 376/532 [11:42<05:40,  2.18s/it]predicting train subjects:  71%|███████   | 377/532 [11:44<05:27,  2.11s/it]predicting train subjects:  71%|███████   | 378/532 [11:46<05:11,  2.03s/it]predicting train subjects:  71%|███████   | 379/532 [11:48<04:58,  1.95s/it]predicting train subjects:  71%|███████▏  | 380/532 [11:50<04:50,  1.91s/it]predicting train subjects:  72%|███████▏  | 381/532 [11:52<04:53,  1.94s/it]predicting train subjects:  72%|███████▏  | 382/532 [11:54<04:44,  1.90s/it]predicting train subjects:  72%|███████▏  | 383/532 [11:56<04:46,  1.92s/it]predicting train subjects:  72%|███████▏  | 384/532 [11:57<04:44,  1.92s/it]predicting train subjects:  72%|███████▏  | 385/532 [11:59<04:43,  1.93s/it]predicting train subjects:  73%|███████▎  | 386/532 [12:01<04:45,  1.96s/it]predicting train subjects:  73%|███████▎  | 387/532 [12:03<04:46,  1.98s/it]predicting train subjects:  73%|███████▎  | 388/532 [12:05<04:46,  1.99s/it]predicting train subjects:  73%|███████▎  | 389/532 [12:07<04:42,  1.98s/it]predicting train subjects:  73%|███████▎  | 390/532 [12:09<04:39,  1.97s/it]predicting train subjects:  73%|███████▎  | 391/532 [12:11<04:39,  1.98s/it]predicting train subjects:  74%|███████▎  | 392/532 [12:13<04:37,  1.98s/it]predicting train subjects:  74%|███████▍  | 393/532 [12:15<04:37,  2.00s/it]predicting train subjects:  74%|███████▍  | 394/532 [12:17<04:37,  2.01s/it]predicting train subjects:  74%|███████▍  | 395/532 [12:19<04:35,  2.01s/it]predicting train subjects:  74%|███████▍  | 396/532 [12:21<04:33,  2.01s/it]predicting train subjects:  75%|███████▍  | 397/532 [12:23<04:31,  2.01s/it]predicting train subjects:  75%|███████▍  | 398/532 [12:25<04:26,  1.99s/it]predicting train subjects:  75%|███████▌  | 399/532 [12:27<04:21,  1.97s/it]predicting train subjects:  75%|███████▌  | 400/532 [12:29<04:18,  1.96s/it]predicting train subjects:  75%|███████▌  | 401/532 [12:31<04:21,  1.99s/it]predicting train subjects:  76%|███████▌  | 402/532 [12:33<04:20,  2.00s/it]predicting train subjects:  76%|███████▌  | 403/532 [12:35<04:23,  2.04s/it]predicting train subjects:  76%|███████▌  | 404/532 [12:38<04:25,  2.07s/it]predicting train subjects:  76%|███████▌  | 405/532 [12:40<04:22,  2.07s/it]predicting train subjects:  76%|███████▋  | 406/532 [12:42<04:19,  2.06s/it]predicting train subjects:  77%|███████▋  | 407/532 [12:44<04:09,  1.99s/it]predicting train subjects:  77%|███████▋  | 408/532 [12:45<04:05,  1.98s/it]predicting train subjects:  77%|███████▋  | 409/532 [12:47<03:59,  1.95s/it]predicting train subjects:  77%|███████▋  | 410/532 [12:49<03:57,  1.95s/it]predicting train subjects:  77%|███████▋  | 411/532 [12:51<03:50,  1.91s/it]predicting train subjects:  77%|███████▋  | 412/532 [12:53<03:42,  1.85s/it]predicting train subjects:  78%|███████▊  | 413/532 [12:55<03:38,  1.84s/it]predicting train subjects:  78%|███████▊  | 414/532 [12:56<03:35,  1.83s/it]predicting train subjects:  78%|███████▊  | 415/532 [12:58<03:28,  1.78s/it]predicting train subjects:  78%|███████▊  | 416/532 [13:00<03:25,  1.77s/it]predicting train subjects:  78%|███████▊  | 417/532 [13:02<03:22,  1.76s/it]predicting train subjects:  79%|███████▊  | 418/532 [13:03<03:20,  1.76s/it]predicting train subjects:  79%|███████▉  | 419/532 [13:05<03:27,  1.84s/it]predicting train subjects:  79%|███████▉  | 420/532 [13:07<03:32,  1.89s/it]predicting train subjects:  79%|███████▉  | 421/532 [13:09<03:34,  1.93s/it]predicting train subjects:  79%|███████▉  | 422/532 [13:12<03:40,  2.00s/it]predicting train subjects:  80%|███████▉  | 423/532 [13:14<03:40,  2.02s/it]predicting train subjects:  80%|███████▉  | 424/532 [13:16<03:36,  2.00s/it]predicting train subjects:  80%|███████▉  | 425/532 [13:18<03:35,  2.02s/it]predicting train subjects:  80%|████████  | 426/532 [13:20<03:36,  2.04s/it]predicting train subjects:  80%|████████  | 427/532 [13:22<03:33,  2.03s/it]predicting train subjects:  80%|████████  | 428/532 [13:24<03:32,  2.05s/it]predicting train subjects:  81%|████████  | 429/532 [13:26<03:31,  2.05s/it]predicting train subjects:  81%|████████  | 430/532 [13:28<03:26,  2.03s/it]predicting train subjects:  81%|████████  | 431/532 [13:30<03:29,  2.07s/it]predicting train subjects:  81%|████████  | 432/532 [13:32<03:31,  2.11s/it]predicting train subjects:  81%|████████▏ | 433/532 [13:34<03:31,  2.14s/it]predicting train subjects:  82%|████████▏ | 434/532 [13:37<03:27,  2.12s/it]predicting train subjects:  82%|████████▏ | 435/532 [13:39<03:25,  2.12s/it]predicting train subjects:  82%|████████▏ | 436/532 [13:41<03:33,  2.23s/it]predicting train subjects:  82%|████████▏ | 437/532 [13:43<03:22,  2.13s/it]predicting train subjects:  82%|████████▏ | 438/532 [13:45<03:14,  2.07s/it]predicting train subjects:  83%|████████▎ | 439/532 [13:47<03:06,  2.01s/it]predicting train subjects:  83%|████████▎ | 440/532 [13:49<03:00,  1.96s/it]predicting train subjects:  83%|████████▎ | 441/532 [13:51<02:59,  1.97s/it]predicting train subjects:  83%|████████▎ | 442/532 [13:53<02:57,  1.97s/it]predicting train subjects:  83%|████████▎ | 443/532 [13:54<02:52,  1.94s/it]predicting train subjects:  83%|████████▎ | 444/532 [13:56<02:45,  1.88s/it]predicting train subjects:  84%|████████▎ | 445/532 [13:58<02:45,  1.90s/it]predicting train subjects:  84%|████████▍ | 446/532 [14:00<02:43,  1.90s/it]predicting train subjects:  84%|████████▍ | 447/532 [14:02<02:39,  1.88s/it]predicting train subjects:  84%|████████▍ | 448/532 [14:04<02:37,  1.88s/it]predicting train subjects:  84%|████████▍ | 449/532 [14:06<02:40,  1.93s/it]predicting train subjects:  85%|████████▍ | 450/532 [14:08<02:41,  1.97s/it]predicting train subjects:  85%|████████▍ | 451/532 [14:10<02:41,  1.99s/it]predicting train subjects:  85%|████████▍ | 452/532 [14:12<02:39,  1.99s/it]predicting train subjects:  85%|████████▌ | 453/532 [14:14<02:44,  2.08s/it]predicting train subjects:  85%|████████▌ | 454/532 [14:17<02:46,  2.14s/it]predicting train subjects:  86%|████████▌ | 455/532 [14:19<02:49,  2.20s/it]predicting train subjects:  86%|████████▌ | 456/532 [14:21<02:46,  2.19s/it]predicting train subjects:  86%|████████▌ | 457/532 [14:23<02:47,  2.24s/it]predicting train subjects:  86%|████████▌ | 458/532 [14:26<02:44,  2.22s/it]predicting train subjects:  86%|████████▋ | 459/532 [14:28<02:41,  2.21s/it]predicting train subjects:  86%|████████▋ | 460/532 [14:30<02:43,  2.27s/it]predicting train subjects:  87%|████████▋ | 461/532 [14:33<02:50,  2.41s/it]predicting train subjects:  87%|████████▋ | 462/532 [14:36<02:57,  2.54s/it]predicting train subjects:  87%|████████▋ | 463/532 [14:39<03:00,  2.62s/it]predicting train subjects:  87%|████████▋ | 464/532 [14:41<02:57,  2.61s/it]predicting train subjects:  87%|████████▋ | 465/532 [14:44<02:57,  2.66s/it]predicting train subjects:  88%|████████▊ | 466/532 [14:47<02:56,  2.67s/it]predicting train subjects:  88%|████████▊ | 467/532 [14:49<02:44,  2.53s/it]predicting train subjects:  88%|████████▊ | 468/532 [14:51<02:32,  2.39s/it]predicting train subjects:  88%|████████▊ | 469/532 [14:53<02:26,  2.32s/it]predicting train subjects:  88%|████████▊ | 470/532 [14:55<02:21,  2.29s/it]predicting train subjects:  89%|████████▊ | 471/532 [14:57<02:18,  2.28s/it]predicting train subjects:  89%|████████▊ | 472/532 [15:00<02:15,  2.26s/it]predicting train subjects:  89%|████████▉ | 473/532 [15:02<02:16,  2.31s/it]predicting train subjects:  89%|████████▉ | 474/532 [15:05<02:16,  2.36s/it]predicting train subjects:  89%|████████▉ | 475/532 [15:07<02:17,  2.42s/it]predicting train subjects:  89%|████████▉ | 476/532 [15:10<02:16,  2.44s/it]predicting train subjects:  90%|████████▉ | 477/532 [15:12<02:11,  2.39s/it]predicting train subjects:  90%|████████▉ | 478/532 [15:14<02:07,  2.37s/it]predicting train subjects:  90%|█████████ | 479/532 [15:16<02:02,  2.32s/it]predicting train subjects:  90%|█████████ | 480/532 [15:18<01:56,  2.24s/it]predicting train subjects:  90%|█████████ | 481/532 [15:21<01:51,  2.18s/it]predicting train subjects:  91%|█████████ | 482/532 [15:22<01:45,  2.11s/it]predicting train subjects:  91%|█████████ | 483/532 [15:25<01:42,  2.09s/it]predicting train subjects:  91%|█████████ | 484/532 [15:27<01:43,  2.15s/it]predicting train subjects:  91%|█████████ | 485/532 [15:29<01:46,  2.27s/it]predicting train subjects:  91%|█████████▏| 486/532 [15:32<01:47,  2.34s/it]predicting train subjects:  92%|█████████▏| 487/532 [15:34<01:47,  2.40s/it]predicting train subjects:  92%|█████████▏| 488/532 [15:37<01:47,  2.44s/it]predicting train subjects:  92%|█████████▏| 489/532 [15:39<01:45,  2.45s/it]predicting train subjects:  92%|█████████▏| 490/532 [15:42<01:41,  2.41s/it]predicting train subjects:  92%|█████████▏| 491/532 [15:44<01:35,  2.34s/it]predicting train subjects:  92%|█████████▏| 492/532 [15:46<01:31,  2.29s/it]predicting train subjects:  93%|█████████▎| 493/532 [15:48<01:27,  2.25s/it]predicting train subjects:  93%|█████████▎| 494/532 [15:50<01:25,  2.24s/it]predicting train subjects:  93%|█████████▎| 495/532 [15:53<01:22,  2.22s/it]predicting train subjects:  93%|█████████▎| 496/532 [15:55<01:20,  2.24s/it]predicting train subjects:  93%|█████████▎| 497/532 [15:57<01:18,  2.25s/it]predicting train subjects:  94%|█████████▎| 498/532 [15:59<01:16,  2.24s/it]predicting train subjects:  94%|█████████▍| 499/532 [16:02<01:14,  2.25s/it]predicting train subjects:  94%|█████████▍| 500/532 [16:04<01:12,  2.26s/it]predicting train subjects:  94%|█████████▍| 501/532 [16:06<01:09,  2.24s/it]predicting train subjects:  94%|█████████▍| 502/532 [16:08<01:06,  2.22s/it]predicting train subjects:  95%|█████████▍| 503/532 [16:10<01:02,  2.16s/it]predicting train subjects:  95%|█████████▍| 504/532 [16:12<01:00,  2.16s/it]predicting train subjects:  95%|█████████▍| 505/532 [16:15<00:58,  2.17s/it]predicting train subjects:  95%|█████████▌| 506/532 [16:17<00:55,  2.14s/it]predicting train subjects:  95%|█████████▌| 507/532 [16:19<00:52,  2.09s/it]predicting train subjects:  95%|█████████▌| 508/532 [16:21<00:50,  2.11s/it]predicting train subjects:  96%|█████████▌| 509/532 [16:24<00:52,  2.30s/it]predicting train subjects:  96%|█████████▌| 510/532 [16:26<00:53,  2.41s/it]predicting train subjects:  96%|█████████▌| 511/532 [16:29<00:52,  2.48s/it]predicting train subjects:  96%|█████████▌| 512/532 [16:32<00:50,  2.51s/it]predicting train subjects:  96%|█████████▋| 513/532 [16:34<00:49,  2.59s/it]predicting train subjects:  97%|█████████▋| 514/532 [16:37<00:46,  2.60s/it]predicting train subjects:  97%|█████████▋| 515/532 [16:39<00:42,  2.49s/it]predicting train subjects:  97%|█████████▋| 516/532 [16:41<00:38,  2.39s/it]predicting train subjects:  97%|█████████▋| 517/532 [16:43<00:34,  2.32s/it]predicting train subjects:  97%|█████████▋| 518/532 [16:46<00:31,  2.24s/it]predicting train subjects:  98%|█████████▊| 519/532 [16:48<00:29,  2.28s/it]predicting train subjects:  98%|█████████▊| 520/532 [16:50<00:27,  2.30s/it]predicting train subjects:  98%|█████████▊| 521/532 [16:53<00:25,  2.30s/it]predicting train subjects:  98%|█████████▊| 522/532 [16:55<00:23,  2.37s/it]predicting train subjects:  98%|█████████▊| 523/532 [16:58<00:21,  2.44s/it]predicting train subjects:  98%|█████████▊| 524/532 [17:00<00:19,  2.40s/it]predicting train subjects:  99%|█████████▊| 525/532 [17:02<00:16,  2.35s/it]predicting train subjects:  99%|█████████▉| 526/532 [17:05<00:14,  2.36s/it]predicting train subjects:  99%|█████████▉| 527/532 [17:07<00:11,  2.30s/it]predicting train subjects:  99%|█████████▉| 528/532 [17:09<00:08,  2.23s/it]predicting train subjects:  99%|█████████▉| 529/532 [17:11<00:06,  2.17s/it]predicting train subjects: 100%|█████████▉| 530/532 [17:13<00:04,  2.16s/it]predicting train subjects: 100%|█████████▉| 531/532 [17:15<00:02,  2.14s/it]predicting train subjects: 100%|██████████| 532/532 [17:17<00:00,  2.11s/it]
Loading train:   0%|          | 0/532 [00:00<?, ?it/s]Loading train:   0%|          | 1/532 [00:02<20:07,  2.27s/it]Loading train:   0%|          | 2/532 [00:03<18:01,  2.04s/it]Loading train:   1%|          | 3/532 [00:05<17:05,  1.94s/it]Loading train:   1%|          | 4/532 [00:07<16:17,  1.85s/it]Loading train:   1%|          | 5/532 [00:09<16:38,  1.89s/it]Loading train:   1%|          | 6/532 [00:10<16:08,  1.84s/it]Loading train:   1%|▏         | 7/532 [00:12<16:39,  1.90s/it]Loading train:   2%|▏         | 8/532 [00:14<17:02,  1.95s/it]Loading train:   2%|▏         | 9/532 [00:17<17:55,  2.06s/it]Loading train:   2%|▏         | 10/532 [00:18<16:52,  1.94s/it]Loading train:   2%|▏         | 11/532 [00:20<17:07,  1.97s/it]Loading train:   2%|▏         | 12/532 [00:22<16:39,  1.92s/it]Loading train:   2%|▏         | 13/532 [00:24<16:19,  1.89s/it]Loading train:   3%|▎         | 14/532 [00:26<15:52,  1.84s/it]Loading train:   3%|▎         | 15/532 [00:28<15:51,  1.84s/it]Loading train:   3%|▎         | 16/532 [00:29<15:46,  1.83s/it]Loading train:   3%|▎         | 17/532 [00:31<15:58,  1.86s/it]Loading train:   3%|▎         | 18/532 [00:34<16:44,  1.95s/it]Loading train:   4%|▎         | 19/532 [00:35<15:41,  1.83s/it]Loading train:   4%|▍         | 20/532 [00:37<15:20,  1.80s/it]Loading train:   4%|▍         | 21/532 [00:39<15:39,  1.84s/it]Loading train:   4%|▍         | 22/532 [00:40<14:17,  1.68s/it]Loading train:   4%|▍         | 23/532 [00:41<13:34,  1.60s/it]Loading train:   5%|▍         | 24/532 [00:43<12:46,  1.51s/it]Loading train:   5%|▍         | 25/532 [00:45<14:32,  1.72s/it]Loading train:   5%|▍         | 26/532 [00:47<13:59,  1.66s/it]Loading train:   5%|▌         | 27/532 [00:49<15:55,  1.89s/it]Loading train:   5%|▌         | 28/532 [00:51<15:53,  1.89s/it]Loading train:   5%|▌         | 29/532 [00:53<16:42,  1.99s/it]Loading train:   6%|▌         | 30/532 [00:54<14:57,  1.79s/it]Loading train:   6%|▌         | 31/532 [00:56<14:26,  1.73s/it]Loading train:   6%|▌         | 32/532 [00:58<14:16,  1.71s/it]Loading train:   6%|▌         | 33/532 [01:00<14:48,  1.78s/it]Loading train:   6%|▋         | 34/532 [01:02<15:41,  1.89s/it]Loading train:   7%|▋         | 35/532 [01:04<15:23,  1.86s/it]Loading train:   7%|▋         | 36/532 [01:05<15:38,  1.89s/it]Loading train:   7%|▋         | 37/532 [01:07<15:44,  1.91s/it]Loading train:   7%|▋         | 38/532 [01:10<16:16,  1.98s/it]Loading train:   7%|▋         | 39/532 [01:12<17:40,  2.15s/it]Loading train:   8%|▊         | 40/532 [01:14<17:30,  2.14s/it]Loading train:   8%|▊         | 41/532 [01:15<14:57,  1.83s/it]Loading train:   8%|▊         | 42/532 [01:16<12:47,  1.57s/it]Loading train:   8%|▊         | 43/532 [01:17<11:05,  1.36s/it]Loading train:   8%|▊         | 44/532 [01:18<10:27,  1.29s/it]Loading train:   8%|▊         | 45/532 [01:20<10:41,  1.32s/it]Loading train:   9%|▊         | 46/532 [01:21<11:53,  1.47s/it]Loading train:   9%|▉         | 47/532 [01:23<12:34,  1.56s/it]Loading train:   9%|▉         | 48/532 [01:24<11:06,  1.38s/it]Loading train:   9%|▉         | 49/532 [01:25<10:12,  1.27s/it]Loading train:   9%|▉         | 50/532 [01:26<09:52,  1.23s/it]Loading train:  10%|▉         | 51/532 [01:27<09:11,  1.15s/it]Loading train:  10%|▉         | 52/532 [01:28<08:34,  1.07s/it]Loading train:  10%|▉         | 53/532 [01:29<08:06,  1.02s/it]Loading train:  10%|█         | 54/532 [01:30<08:04,  1.01s/it]Loading train:  10%|█         | 55/532 [01:31<07:53,  1.01it/s]Loading train:  11%|█         | 56/532 [01:32<07:49,  1.01it/s]Loading train:  11%|█         | 57/532 [01:33<07:51,  1.01it/s]Loading train:  11%|█         | 58/532 [01:34<07:57,  1.01s/it]Loading train:  11%|█         | 59/532 [01:35<08:19,  1.06s/it]Loading train:  11%|█▏        | 60/532 [01:36<07:43,  1.02it/s]Loading train:  11%|█▏        | 61/532 [01:37<07:16,  1.08it/s]Loading train:  12%|█▏        | 62/532 [01:38<07:54,  1.01s/it]Loading train:  12%|█▏        | 63/532 [01:39<08:19,  1.06s/it]Loading train:  12%|█▏        | 64/532 [01:40<07:42,  1.01it/s]Loading train:  12%|█▏        | 65/532 [01:41<07:45,  1.00it/s]Loading train:  12%|█▏        | 66/532 [01:42<08:29,  1.09s/it]Loading train:  13%|█▎        | 67/532 [01:44<08:56,  1.15s/it]Loading train:  13%|█▎        | 68/532 [01:45<08:14,  1.06s/it]Loading train:  13%|█▎        | 69/532 [01:45<07:42,  1.00it/s]Loading train:  13%|█▎        | 70/532 [01:46<07:35,  1.01it/s]Loading train:  13%|█▎        | 71/532 [01:47<07:10,  1.07it/s]Loading train:  14%|█▎        | 72/532 [01:48<06:59,  1.10it/s]Loading train:  14%|█▎        | 73/532 [01:49<07:23,  1.04it/s]Loading train:  14%|█▍        | 74/532 [01:50<08:07,  1.06s/it]Loading train:  14%|█▍        | 75/532 [01:52<09:26,  1.24s/it]Loading train:  14%|█▍        | 76/532 [01:53<09:15,  1.22s/it]Loading train:  14%|█▍        | 77/532 [01:54<09:13,  1.22s/it]Loading train:  15%|█▍        | 78/532 [01:56<08:53,  1.18s/it]Loading train:  15%|█▍        | 79/532 [01:56<08:17,  1.10s/it]Loading train:  15%|█▌        | 80/532 [01:57<07:56,  1.05s/it]Loading train:  15%|█▌        | 81/532 [01:58<07:33,  1.01s/it]Loading train:  15%|█▌        | 82/532 [01:59<07:16,  1.03it/s]Loading train:  16%|█▌        | 83/532 [02:00<07:02,  1.06it/s]Loading train:  16%|█▌        | 84/532 [02:01<06:36,  1.13it/s]Loading train:  16%|█▌        | 85/532 [02:02<06:17,  1.18it/s]Loading train:  16%|█▌        | 86/532 [02:02<06:15,  1.19it/s]Loading train:  16%|█▋        | 87/532 [02:03<06:00,  1.24it/s]Loading train:  17%|█▋        | 88/532 [02:04<05:56,  1.25it/s]Loading train:  17%|█▋        | 89/532 [02:05<06:36,  1.12it/s]Loading train:  17%|█▋        | 90/532 [02:06<06:29,  1.13it/s]Loading train:  17%|█▋        | 91/532 [02:07<06:46,  1.09it/s]Loading train:  17%|█▋        | 92/532 [02:08<06:35,  1.11it/s]Loading train:  17%|█▋        | 93/532 [02:09<06:37,  1.10it/s]Loading train:  18%|█▊        | 94/532 [02:10<06:34,  1.11it/s]Loading train:  18%|█▊        | 95/532 [02:11<07:10,  1.01it/s]Loading train:  18%|█▊        | 96/532 [02:12<07:23,  1.02s/it]Loading train:  18%|█▊        | 97/532 [02:13<07:38,  1.05s/it]Loading train:  18%|█▊        | 98/532 [02:14<07:36,  1.05s/it]Loading train:  19%|█▊        | 99/532 [02:15<07:44,  1.07s/it]Loading train:  19%|█▉        | 100/532 [02:16<07:41,  1.07s/it]Loading train:  19%|█▉        | 101/532 [02:17<07:23,  1.03s/it]Loading train:  19%|█▉        | 102/532 [02:18<07:09,  1.00it/s]Loading train:  19%|█▉        | 103/532 [02:19<06:42,  1.07it/s]Loading train:  20%|█▉        | 104/532 [02:20<06:25,  1.11it/s]Loading train:  20%|█▉        | 105/532 [02:20<05:59,  1.19it/s]Loading train:  20%|█▉        | 106/532 [02:21<05:55,  1.20it/s]Loading train:  20%|██        | 107/532 [02:22<05:50,  1.21it/s]Loading train:  20%|██        | 108/532 [02:23<05:58,  1.18it/s]Loading train:  20%|██        | 109/532 [02:24<05:50,  1.21it/s]Loading train:  21%|██        | 110/532 [02:25<06:00,  1.17it/s]Loading train:  21%|██        | 111/532 [02:25<06:04,  1.16it/s]Loading train:  21%|██        | 112/532 [02:26<05:57,  1.18it/s]Loading train:  21%|██        | 113/532 [02:27<06:14,  1.12it/s]Loading train:  21%|██▏       | 114/532 [02:28<06:13,  1.12it/s]Loading train:  22%|██▏       | 115/532 [02:29<06:21,  1.09it/s]Loading train:  22%|██▏       | 116/532 [02:30<06:20,  1.09it/s]Loading train:  22%|██▏       | 117/532 [02:31<06:23,  1.08it/s]Loading train:  22%|██▏       | 118/532 [02:32<06:15,  1.10it/s]Loading train:  22%|██▏       | 119/532 [02:33<06:41,  1.03it/s]Loading train:  23%|██▎       | 120/532 [02:34<06:43,  1.02it/s]Loading train:  23%|██▎       | 121/532 [02:35<06:43,  1.02it/s]Loading train:  23%|██▎       | 122/532 [02:36<06:21,  1.08it/s]Loading train:  23%|██▎       | 123/532 [02:37<06:26,  1.06it/s]Loading train:  23%|██▎       | 124/532 [02:38<06:15,  1.09it/s]Loading train:  23%|██▎       | 125/532 [02:39<06:32,  1.04it/s]Loading train:  24%|██▎       | 126/532 [02:40<06:15,  1.08it/s]Loading train:  24%|██▍       | 127/532 [02:40<06:12,  1.09it/s]Loading train:  24%|██▍       | 128/532 [02:41<06:15,  1.08it/s]Loading train:  24%|██▍       | 129/532 [02:42<06:16,  1.07it/s]Loading train:  24%|██▍       | 130/532 [02:43<06:09,  1.09it/s]Loading train:  25%|██▍       | 131/532 [02:44<06:31,  1.02it/s]Loading train:  25%|██▍       | 132/532 [02:45<06:45,  1.01s/it]Loading train:  25%|██▌       | 133/532 [02:47<06:56,  1.04s/it]Loading train:  25%|██▌       | 134/532 [02:48<07:09,  1.08s/it]Loading train:  25%|██▌       | 135/532 [02:49<07:27,  1.13s/it]Loading train:  26%|██▌       | 136/532 [02:50<07:35,  1.15s/it]Loading train:  26%|██▌       | 137/532 [02:51<07:38,  1.16s/it]Loading train:  26%|██▌       | 138/532 [02:52<07:31,  1.15s/it]Loading train:  26%|██▌       | 139/532 [02:54<07:41,  1.17s/it]Loading train:  26%|██▋       | 140/532 [02:55<07:38,  1.17s/it]Loading train:  27%|██▋       | 141/532 [02:56<07:37,  1.17s/it]Loading train:  27%|██▋       | 142/532 [02:57<07:37,  1.17s/it]Loading train:  27%|██▋       | 143/532 [02:58<07:06,  1.10s/it]Loading train:  27%|██▋       | 144/532 [02:59<06:31,  1.01s/it]Loading train:  27%|██▋       | 145/532 [03:00<06:14,  1.03it/s]Loading train:  27%|██▋       | 146/532 [03:01<06:03,  1.06it/s]Loading train:  28%|██▊       | 147/532 [03:02<05:54,  1.09it/s]Loading train:  28%|██▊       | 148/532 [03:02<05:45,  1.11it/s]Loading train:  28%|██▊       | 149/532 [03:03<06:01,  1.06it/s]Loading train:  28%|██▊       | 150/532 [03:04<05:49,  1.09it/s]Loading train:  28%|██▊       | 151/532 [03:05<05:41,  1.12it/s]Loading train:  29%|██▊       | 152/532 [03:06<05:34,  1.14it/s]Loading train:  29%|██▉       | 153/532 [03:07<05:39,  1.12it/s]Loading train:  29%|██▉       | 154/532 [03:08<05:39,  1.11it/s]Loading train:  29%|██▉       | 155/532 [03:09<06:22,  1.01s/it]Loading train:  29%|██▉       | 156/532 [03:10<06:56,  1.11s/it]Loading train:  30%|██▉       | 157/532 [03:12<07:14,  1.16s/it]Loading train:  30%|██▉       | 158/532 [03:13<07:19,  1.17s/it]Loading train:  30%|██▉       | 159/532 [03:14<07:27,  1.20s/it]Loading train:  30%|███       | 160/532 [03:15<07:21,  1.19s/it]Loading train:  30%|███       | 161/532 [03:16<06:52,  1.11s/it]Loading train:  30%|███       | 162/532 [03:17<06:25,  1.04s/it]Loading train:  31%|███       | 163/532 [03:18<06:08,  1.00it/s]Loading train:  31%|███       | 164/532 [03:19<05:50,  1.05it/s]Loading train:  31%|███       | 165/532 [03:20<05:31,  1.11it/s]Loading train:  31%|███       | 166/532 [03:20<05:17,  1.15it/s]Loading train:  31%|███▏      | 167/532 [03:21<05:28,  1.11it/s]Loading train:  32%|███▏      | 168/532 [03:22<05:38,  1.08it/s]Loading train:  32%|███▏      | 169/532 [03:23<05:35,  1.08it/s]Loading train:  32%|███▏      | 170/532 [03:24<05:41,  1.06it/s]Loading train:  32%|███▏      | 171/532 [03:25<05:36,  1.07it/s]Loading train:  32%|███▏      | 172/532 [03:26<05:30,  1.09it/s]Loading train:  33%|███▎      | 173/532 [03:27<05:34,  1.07it/s]Loading train:  33%|███▎      | 174/532 [03:28<05:44,  1.04it/s]Loading train:  33%|███▎      | 175/532 [03:29<05:29,  1.08it/s]Loading train:  33%|███▎      | 176/532 [03:30<05:24,  1.10it/s]Loading train:  33%|███▎      | 177/532 [03:31<05:18,  1.11it/s]Loading train:  33%|███▎      | 178/532 [03:32<05:15,  1.12it/s]Loading train:  34%|███▎      | 179/532 [03:33<05:30,  1.07it/s]Loading train:  34%|███▍      | 180/532 [03:33<05:23,  1.09it/s]Loading train:  34%|███▍      | 181/532 [03:34<05:24,  1.08it/s]Loading train:  34%|███▍      | 182/532 [03:35<05:12,  1.12it/s]Loading train:  34%|███▍      | 183/532 [03:36<05:07,  1.14it/s]Loading train:  35%|███▍      | 184/532 [03:37<05:06,  1.14it/s]Loading train:  35%|███▍      | 185/532 [03:38<05:03,  1.14it/s]Loading train:  35%|███▍      | 186/532 [03:39<04:54,  1.18it/s]Loading train:  35%|███▌      | 187/532 [03:39<04:40,  1.23it/s]Loading train:  35%|███▌      | 188/532 [03:40<04:40,  1.23it/s]Loading train:  36%|███▌      | 189/532 [03:41<04:29,  1.27it/s]Loading train:  36%|███▌      | 190/532 [03:42<04:41,  1.21it/s]Loading train:  36%|███▌      | 191/532 [03:43<05:20,  1.06it/s]Loading train:  36%|███▌      | 192/532 [03:44<05:53,  1.04s/it]Loading train:  36%|███▋      | 193/532 [03:45<06:07,  1.08s/it]Loading train:  36%|███▋      | 194/532 [03:47<06:21,  1.13s/it]Loading train:  37%|███▋      | 195/532 [03:48<06:44,  1.20s/it]Loading train:  37%|███▋      | 196/532 [03:49<06:42,  1.20s/it]Loading train:  37%|███▋      | 197/532 [03:50<06:32,  1.17s/it]Loading train:  37%|███▋      | 198/532 [03:51<06:11,  1.11s/it]Loading train:  37%|███▋      | 199/532 [03:52<06:00,  1.08s/it]Loading train:  38%|███▊      | 200/532 [03:53<05:51,  1.06s/it]Loading train:  38%|███▊      | 201/532 [03:54<05:48,  1.05s/it]Loading train:  38%|███▊      | 202/532 [03:55<05:50,  1.06s/it]Loading train:  38%|███▊      | 203/532 [03:57<05:49,  1.06s/it]Loading train:  38%|███▊      | 204/532 [03:57<05:37,  1.03s/it]Loading train:  39%|███▊      | 205/532 [03:58<05:13,  1.04it/s]Loading train:  39%|███▊      | 206/532 [03:59<04:57,  1.09it/s]Loading train:  39%|███▉      | 207/532 [04:00<04:52,  1.11it/s]Loading train:  39%|███▉      | 208/532 [04:01<04:42,  1.15it/s]Loading train:  39%|███▉      | 209/532 [04:02<04:35,  1.17it/s]Loading train:  39%|███▉      | 210/532 [04:02<04:28,  1.20it/s]Loading train:  40%|███▉      | 211/532 [04:03<04:26,  1.20it/s]Loading train:  40%|███▉      | 212/532 [04:04<04:22,  1.22it/s]Loading train:  40%|████      | 213/532 [04:05<04:15,  1.25it/s]Loading train:  40%|████      | 214/532 [04:05<04:06,  1.29it/s]Loading train:  40%|████      | 215/532 [04:07<04:50,  1.09it/s]Loading train:  41%|████      | 216/532 [04:08<05:05,  1.03it/s]Loading train:  41%|████      | 217/532 [04:09<05:17,  1.01s/it]Loading train:  41%|████      | 218/532 [04:10<05:19,  1.02s/it]Loading train:  41%|████      | 219/532 [04:11<05:28,  1.05s/it]Loading train:  41%|████▏     | 220/532 [04:12<05:32,  1.07s/it]Loading train:  42%|████▏     | 221/532 [04:13<05:19,  1.03s/it]Loading train:  42%|████▏     | 222/532 [04:14<04:47,  1.08it/s]Loading train:  42%|████▏     | 223/532 [04:15<04:32,  1.14it/s]Loading train:  42%|████▏     | 224/532 [04:15<04:17,  1.20it/s]Loading train:  42%|████▏     | 225/532 [04:16<04:14,  1.21it/s]Loading train:  42%|████▏     | 226/532 [04:17<04:08,  1.23it/s]Loading train:  43%|████▎     | 227/532 [04:18<04:04,  1.25it/s]Loading train:  43%|████▎     | 228/532 [04:18<04:02,  1.26it/s]Loading train:  43%|████▎     | 229/532 [04:19<03:54,  1.29it/s]Loading train:  43%|████▎     | 230/532 [04:20<03:55,  1.28it/s]Loading train:  43%|████▎     | 231/532 [04:21<04:00,  1.25it/s]Loading train:  44%|████▎     | 232/532 [04:22<03:56,  1.27it/s]Loading train:  44%|████▍     | 233/532 [04:23<04:17,  1.16it/s]Loading train:  44%|████▍     | 234/532 [04:23<04:15,  1.17it/s]Loading train:  44%|████▍     | 235/532 [04:24<04:15,  1.16it/s]Loading train:  44%|████▍     | 236/532 [04:25<04:07,  1.20it/s]Loading train:  45%|████▍     | 237/532 [04:26<04:10,  1.18it/s]Loading train:  45%|████▍     | 238/532 [04:27<04:10,  1.17it/s]Loading train:  45%|████▍     | 239/532 [04:28<04:17,  1.14it/s]Loading train:  45%|████▌     | 240/532 [04:29<04:14,  1.15it/s]Loading train:  45%|████▌     | 241/532 [04:30<04:12,  1.15it/s]Loading train:  45%|████▌     | 242/532 [04:30<04:13,  1.14it/s]Loading train:  46%|████▌     | 243/532 [04:31<04:22,  1.10it/s]Loading train:  46%|████▌     | 244/532 [04:32<04:18,  1.12it/s]Loading train:  46%|████▌     | 245/532 [04:33<04:15,  1.12it/s]Loading train:  46%|████▌     | 246/532 [04:34<04:09,  1.15it/s]Loading train:  46%|████▋     | 247/532 [04:35<03:58,  1.20it/s]Loading train:  47%|████▋     | 248/532 [04:36<03:54,  1.21it/s]Loading train:  47%|████▋     | 249/532 [04:36<03:54,  1.21it/s]Loading train:  47%|████▋     | 250/532 [04:37<03:55,  1.20it/s]Loading train:  47%|████▋     | 251/532 [04:38<03:57,  1.18it/s]Loading train:  47%|████▋     | 252/532 [04:39<03:48,  1.23it/s]Loading train:  48%|████▊     | 253/532 [04:40<03:48,  1.22it/s]Loading train:  48%|████▊     | 254/532 [04:40<03:40,  1.26it/s]Loading train:  48%|████▊     | 255/532 [04:41<03:40,  1.25it/s]Loading train:  48%|████▊     | 256/532 [04:42<03:38,  1.26it/s]Loading train:  48%|████▊     | 257/532 [04:43<03:58,  1.15it/s]Loading train:  48%|████▊     | 258/532 [04:44<04:03,  1.13it/s]Loading train:  49%|████▊     | 259/532 [04:45<04:15,  1.07it/s]Loading train:  49%|████▉     | 260/532 [04:46<04:25,  1.02it/s]Loading train:  49%|████▉     | 261/532 [04:47<04:20,  1.04it/s]Loading train:  49%|████▉     | 262/532 [04:48<04:19,  1.04it/s]Loading train:  49%|████▉     | 263/532 [04:49<03:58,  1.13it/s]Loading train:  50%|████▉     | 264/532 [04:49<03:50,  1.16it/s]Loading train:  50%|████▉     | 265/532 [04:50<03:52,  1.15it/s]Loading train:  50%|█████     | 266/532 [04:51<03:36,  1.23it/s]Loading train:  50%|█████     | 267/532 [04:52<03:27,  1.28it/s]Loading train:  50%|█████     | 268/532 [04:53<03:28,  1.26it/s]Loading train:  51%|█████     | 269/532 [04:54<03:48,  1.15it/s]Loading train:  51%|█████     | 270/532 [04:55<03:56,  1.11it/s]Loading train:  51%|█████     | 271/532 [04:55<03:50,  1.13it/s]Loading train:  51%|█████     | 272/532 [04:56<03:46,  1.15it/s]Loading train:  51%|█████▏    | 273/532 [04:57<03:51,  1.12it/s]Loading train:  52%|█████▏    | 274/532 [04:58<03:45,  1.14it/s]Loading train:  52%|█████▏    | 275/532 [04:59<04:14,  1.01it/s]Loading train:  52%|█████▏    | 276/532 [05:00<04:19,  1.01s/it]Loading train:  52%|█████▏    | 277/532 [05:01<04:24,  1.04s/it]Loading train:  52%|█████▏    | 278/532 [05:02<04:21,  1.03s/it]Loading train:  52%|█████▏    | 279/532 [05:04<04:22,  1.04s/it]Loading train:  53%|█████▎    | 280/532 [05:05<04:28,  1.07s/it]Loading train:  53%|█████▎    | 281/532 [05:06<04:37,  1.10s/it]Loading train:  53%|█████▎    | 282/532 [05:07<04:31,  1.09s/it]Loading train:  53%|█████▎    | 283/532 [05:08<04:34,  1.10s/it]Loading train:  53%|█████▎    | 284/532 [05:09<04:30,  1.09s/it]Loading train:  54%|█████▎    | 285/532 [05:10<04:26,  1.08s/it]Loading train:  54%|█████▍    | 286/532 [05:11<04:24,  1.07s/it]Loading train:  54%|█████▍    | 287/532 [05:12<04:03,  1.00it/s]Loading train:  54%|█████▍    | 288/532 [05:13<03:47,  1.07it/s]Loading train:  54%|█████▍    | 289/532 [05:14<03:44,  1.08it/s]Loading train:  55%|█████▍    | 290/532 [05:15<03:34,  1.13it/s]Loading train:  55%|█████▍    | 291/532 [05:15<03:34,  1.12it/s]Loading train:  55%|█████▍    | 292/532 [05:16<03:33,  1.13it/s]Loading train:  55%|█████▌    | 293/532 [05:17<03:41,  1.08it/s]Loading train:  55%|█████▌    | 294/532 [05:18<03:35,  1.10it/s]Loading train:  55%|█████▌    | 295/532 [05:19<03:35,  1.10it/s]Loading train:  56%|█████▌    | 296/532 [05:20<03:31,  1.11it/s]Loading train:  56%|█████▌    | 297/532 [05:21<03:31,  1.11it/s]Loading train:  56%|█████▌    | 298/532 [05:22<03:35,  1.09it/s]Loading train:  56%|█████▌    | 299/532 [05:23<03:31,  1.10it/s]Loading train:  56%|█████▋    | 300/532 [05:23<03:17,  1.17it/s]Loading train:  57%|█████▋    | 301/532 [05:24<03:08,  1.22it/s]Loading train:  57%|█████▋    | 302/532 [05:25<03:11,  1.20it/s]Loading train:  57%|█████▋    | 303/532 [05:26<03:01,  1.26it/s]Loading train:  57%|█████▋    | 304/532 [05:27<03:00,  1.26it/s]Loading train:  57%|█████▋    | 305/532 [05:28<03:37,  1.05it/s]Loading train:  58%|█████▊    | 306/532 [05:29<03:56,  1.05s/it]Loading train:  58%|█████▊    | 307/532 [05:30<04:12,  1.12s/it]Loading train:  58%|█████▊    | 308/532 [05:32<04:15,  1.14s/it]Loading train:  58%|█████▊    | 309/532 [05:33<04:09,  1.12s/it]Loading train:  58%|█████▊    | 310/532 [05:34<04:09,  1.13s/it]Loading train:  58%|█████▊    | 311/532 [05:35<04:40,  1.27s/it]Loading train:  59%|█████▊    | 312/532 [05:37<04:58,  1.35s/it]Loading train:  59%|█████▉    | 313/532 [05:39<05:11,  1.42s/it]Loading train:  59%|█████▉    | 314/532 [05:40<05:17,  1.46s/it]Loading train:  59%|█████▉    | 315/532 [05:42<05:28,  1.51s/it]Loading train:  59%|█████▉    | 316/532 [05:43<05:39,  1.57s/it]Loading train:  60%|█████▉    | 317/532 [05:44<04:50,  1.35s/it]Loading train:  60%|█████▉    | 318/532 [05:45<04:26,  1.25s/it]Loading train:  60%|█████▉    | 319/532 [05:46<03:59,  1.13s/it]Loading train:  60%|██████    | 320/532 [05:47<03:43,  1.05s/it]Loading train:  60%|██████    | 321/532 [05:48<03:24,  1.03it/s]Loading train:  61%|██████    | 322/532 [05:49<03:10,  1.10it/s]Loading train:  61%|██████    | 323/532 [05:50<03:39,  1.05s/it]Loading train:  61%|██████    | 324/532 [05:51<03:58,  1.14s/it]Loading train:  61%|██████    | 325/532 [05:52<03:57,  1.15s/it]Loading train:  61%|██████▏   | 326/532 [05:54<04:09,  1.21s/it]Loading train:  61%|██████▏   | 327/532 [05:55<04:03,  1.19s/it]Loading train:  62%|██████▏   | 328/532 [05:56<04:08,  1.22s/it]Loading train:  62%|██████▏   | 329/532 [05:57<03:55,  1.16s/it]Loading train:  62%|██████▏   | 330/532 [05:58<03:39,  1.09s/it]Loading train:  62%|██████▏   | 331/532 [05:59<03:33,  1.06s/it]Loading train:  62%|██████▏   | 332/532 [06:00<03:19,  1.00it/s]Loading train:  63%|██████▎   | 333/532 [06:01<03:21,  1.01s/it]Loading train:  63%|██████▎   | 334/532 [06:02<03:09,  1.04it/s]Loading train:  63%|██████▎   | 335/532 [06:03<03:27,  1.05s/it]Loading train:  63%|██████▎   | 336/532 [06:04<03:24,  1.04s/it]Loading train:  63%|██████▎   | 337/532 [06:05<03:26,  1.06s/it]Loading train:  64%|██████▎   | 338/532 [06:06<03:25,  1.06s/it]Loading train:  64%|██████▎   | 339/532 [06:07<03:22,  1.05s/it]Loading train:  64%|██████▍   | 340/532 [06:08<03:23,  1.06s/it]Loading train:  64%|██████▍   | 341/532 [06:09<03:06,  1.03it/s]Loading train:  64%|██████▍   | 342/532 [06:10<03:05,  1.03it/s]Loading train:  64%|██████▍   | 343/532 [06:11<02:51,  1.10it/s]Loading train:  65%|██████▍   | 344/532 [06:12<02:54,  1.08it/s]Loading train:  65%|██████▍   | 345/532 [06:13<02:46,  1.12it/s]Loading train:  65%|██████▌   | 346/532 [06:14<02:42,  1.14it/s]Loading train:  65%|██████▌   | 347/532 [06:15<02:52,  1.07it/s]Loading train:  65%|██████▌   | 348/532 [06:16<02:59,  1.03it/s]Loading train:  66%|██████▌   | 349/532 [06:17<03:01,  1.01it/s]Loading train:  66%|██████▌   | 350/532 [06:18<02:51,  1.06it/s]Loading train:  66%|██████▌   | 351/532 [06:18<02:43,  1.11it/s]Loading train:  66%|██████▌   | 352/532 [06:20<02:54,  1.03it/s]Loading train:  66%|██████▋   | 353/532 [06:20<02:51,  1.04it/s]Loading train:  67%|██████▋   | 354/532 [06:21<02:49,  1.05it/s]Loading train:  67%|██████▋   | 355/532 [06:22<02:42,  1.09it/s]Loading train:  67%|██████▋   | 356/532 [06:23<02:40,  1.10it/s]Loading train:  67%|██████▋   | 357/532 [06:24<02:40,  1.09it/s]Loading train:  67%|██████▋   | 358/532 [06:25<02:36,  1.11it/s]Loading train:  67%|██████▋   | 359/532 [06:26<02:35,  1.11it/s]Loading train:  68%|██████▊   | 360/532 [06:27<02:37,  1.09it/s]Loading train:  68%|██████▊   | 361/532 [06:28<02:34,  1.11it/s]Loading train:  68%|██████▊   | 362/532 [06:29<02:32,  1.11it/s]Loading train:  68%|██████▊   | 363/532 [06:29<02:27,  1.15it/s]Loading train:  68%|██████▊   | 364/532 [06:30<02:20,  1.20it/s]Loading train:  69%|██████▊   | 365/532 [06:31<02:27,  1.14it/s]Loading train:  69%|██████▉   | 366/532 [06:32<02:21,  1.18it/s]Loading train:  69%|██████▉   | 367/532 [06:33<02:21,  1.17it/s]Loading train:  69%|██████▉   | 368/532 [06:33<02:15,  1.21it/s]Loading train:  69%|██████▉   | 369/532 [06:34<02:11,  1.24it/s]Loading train:  70%|██████▉   | 370/532 [06:35<02:26,  1.11it/s]Loading train:  70%|██████▉   | 371/532 [06:36<02:32,  1.06it/s]Loading train:  70%|██████▉   | 372/532 [06:38<02:50,  1.07s/it]Loading train:  70%|███████   | 373/532 [06:39<02:50,  1.08s/it]Loading train:  70%|███████   | 374/532 [06:40<02:51,  1.08s/it]Loading train:  70%|███████   | 375/532 [06:41<02:53,  1.10s/it]Loading train:  71%|███████   | 376/532 [06:42<02:58,  1.14s/it]Loading train:  71%|███████   | 377/532 [06:43<02:53,  1.12s/it]Loading train:  71%|███████   | 378/532 [06:44<02:47,  1.09s/it]Loading train:  71%|███████   | 379/532 [06:45<02:34,  1.01s/it]Loading train:  71%|███████▏  | 380/532 [06:46<02:27,  1.03it/s]Loading train:  72%|███████▏  | 381/532 [06:47<02:25,  1.03it/s]Loading train:  72%|███████▏  | 382/532 [06:48<02:19,  1.08it/s]Loading train:  72%|███████▏  | 383/532 [06:49<02:25,  1.02it/s]Loading train:  72%|███████▏  | 384/532 [06:50<02:27,  1.00it/s]Loading train:  72%|███████▏  | 385/532 [06:51<02:25,  1.01it/s]Loading train:  73%|███████▎  | 386/532 [06:52<02:29,  1.02s/it]Loading train:  73%|███████▎  | 387/532 [06:53<02:24,  1.00it/s]Loading train:  73%|███████▎  | 388/532 [06:54<02:24,  1.00s/it]Loading train:  73%|███████▎  | 389/532 [06:55<02:27,  1.03s/it]Loading train:  73%|███████▎  | 390/532 [06:56<02:24,  1.01s/it]Loading train:  73%|███████▎  | 391/532 [06:57<02:24,  1.02s/it]Loading train:  74%|███████▎  | 392/532 [06:58<02:28,  1.06s/it]Loading train:  74%|███████▍  | 393/532 [06:59<02:21,  1.01s/it]Loading train:  74%|███████▍  | 394/532 [07:00<02:18,  1.01s/it]Loading train:  74%|███████▍  | 395/532 [07:01<02:14,  1.02it/s]Loading train:  74%|███████▍  | 396/532 [07:02<02:12,  1.02it/s]Loading train:  75%|███████▍  | 397/532 [07:03<02:13,  1.01it/s]Loading train:  75%|███████▍  | 398/532 [07:04<02:09,  1.04it/s]Loading train:  75%|███████▌  | 399/532 [07:05<02:10,  1.02it/s]Loading train:  75%|███████▌  | 400/532 [07:06<02:11,  1.01it/s]Loading train:  75%|███████▌  | 401/532 [07:07<02:20,  1.08s/it]Loading train:  76%|███████▌  | 402/532 [07:08<02:19,  1.08s/it]Loading train:  76%|███████▌  | 403/532 [07:09<02:16,  1.06s/it]Loading train:  76%|███████▌  | 404/532 [07:11<02:18,  1.08s/it]Loading train:  76%|███████▌  | 405/532 [07:12<02:16,  1.07s/it]Loading train:  76%|███████▋  | 406/532 [07:13<02:14,  1.07s/it]Loading train:  77%|███████▋  | 407/532 [07:14<02:09,  1.04s/it]Loading train:  77%|███████▋  | 408/532 [07:15<02:03,  1.00it/s]Loading train:  77%|███████▋  | 409/532 [07:15<01:58,  1.03it/s]Loading train:  77%|███████▋  | 410/532 [07:16<01:56,  1.05it/s]Loading train:  77%|███████▋  | 411/532 [07:17<01:54,  1.05it/s]Loading train:  77%|███████▋  | 412/532 [07:18<01:53,  1.06it/s]Loading train:  78%|███████▊  | 413/532 [07:19<01:55,  1.03it/s]Loading train:  78%|███████▊  | 414/532 [07:20<01:52,  1.05it/s]Loading train:  78%|███████▊  | 415/532 [07:21<01:46,  1.10it/s]Loading train:  78%|███████▊  | 416/532 [07:22<01:45,  1.10it/s]Loading train:  78%|███████▊  | 417/532 [07:23<01:41,  1.13it/s]Loading train:  79%|███████▊  | 418/532 [07:24<01:44,  1.09it/s]Loading train:  79%|███████▉  | 419/532 [07:25<01:46,  1.06it/s]Loading train:  79%|███████▉  | 420/532 [07:26<01:49,  1.03it/s]Loading train:  79%|███████▉  | 421/532 [07:27<01:51,  1.00s/it]Loading train:  79%|███████▉  | 422/532 [07:28<01:52,  1.02s/it]Loading train:  80%|███████▉  | 423/532 [07:29<01:56,  1.07s/it]Loading train:  80%|███████▉  | 424/532 [07:30<01:54,  1.06s/it]Loading train:  80%|███████▉  | 425/532 [07:31<01:52,  1.05s/it]Loading train:  80%|████████  | 426/532 [07:32<01:48,  1.02s/it]Loading train:  80%|████████  | 427/532 [07:33<01:47,  1.02s/it]Loading train:  80%|████████  | 428/532 [07:34<01:47,  1.04s/it]Loading train:  81%|████████  | 429/532 [07:35<01:46,  1.03s/it]Loading train:  81%|████████  | 430/532 [07:36<01:44,  1.03s/it]Loading train:  81%|████████  | 431/532 [07:37<01:49,  1.08s/it]Loading train:  81%|████████  | 432/532 [07:39<01:47,  1.08s/it]Loading train:  81%|████████▏ | 433/532 [07:40<01:48,  1.10s/it]Loading train:  82%|████████▏ | 434/532 [07:41<01:47,  1.10s/it]Loading train:  82%|████████▏ | 435/532 [07:42<01:47,  1.11s/it]Loading train:  82%|████████▏ | 436/532 [07:43<01:45,  1.10s/it]Loading train:  82%|████████▏ | 437/532 [07:44<01:38,  1.04s/it]Loading train:  82%|████████▏ | 438/532 [07:45<01:33,  1.00it/s]Loading train:  83%|████████▎ | 439/532 [07:46<01:27,  1.06it/s]Loading train:  83%|████████▎ | 440/532 [07:47<01:27,  1.06it/s]Loading train:  83%|████████▎ | 441/532 [07:47<01:23,  1.09it/s]Loading train:  83%|████████▎ | 442/532 [07:48<01:22,  1.09it/s]Loading train:  83%|████████▎ | 443/532 [07:49<01:19,  1.12it/s]Loading train:  83%|████████▎ | 444/532 [07:50<01:13,  1.20it/s]Loading train:  84%|████████▎ | 445/532 [07:51<01:18,  1.11it/s]Loading train:  84%|████████▍ | 446/532 [07:52<01:14,  1.16it/s]Loading train:  84%|████████▍ | 447/532 [07:53<01:12,  1.17it/s]Loading train:  84%|████████▍ | 448/532 [07:53<01:12,  1.16it/s]Loading train:  84%|████████▍ | 449/532 [07:54<01:13,  1.14it/s]Loading train:  85%|████████▍ | 450/532 [07:55<01:09,  1.17it/s]Loading train:  85%|████████▍ | 451/532 [07:56<01:09,  1.16it/s]Loading train:  85%|████████▍ | 452/532 [07:57<01:11,  1.12it/s]Loading train:  85%|████████▌ | 453/532 [07:58<01:11,  1.10it/s]Loading train:  85%|████████▌ | 454/532 [07:59<01:11,  1.10it/s]Loading train:  86%|████████▌ | 455/532 [08:00<01:20,  1.04s/it]Loading train:  86%|████████▌ | 456/532 [08:01<01:20,  1.06s/it]Loading train:  86%|████████▌ | 457/532 [08:02<01:16,  1.02s/it]Loading train:  86%|████████▌ | 458/532 [08:03<01:14,  1.01s/it]Loading train:  86%|████████▋ | 459/532 [08:04<01:11,  1.02it/s]Loading train:  86%|████████▋ | 460/532 [08:05<01:10,  1.02it/s]Loading train:  87%|████████▋ | 461/532 [08:06<01:13,  1.04s/it]Loading train:  87%|████████▋ | 462/532 [08:08<01:19,  1.13s/it]Loading train:  87%|████████▋ | 463/532 [08:09<01:16,  1.10s/it]Loading train:  87%|████████▋ | 464/532 [08:10<01:16,  1.12s/it]Loading train:  87%|████████▋ | 465/532 [08:11<01:14,  1.11s/it]Loading train:  88%|████████▊ | 466/532 [08:12<01:14,  1.13s/it]Loading train:  88%|████████▊ | 467/532 [08:13<01:07,  1.03s/it]Loading train:  88%|████████▊ | 468/532 [08:14<01:04,  1.00s/it]Loading train:  88%|████████▊ | 469/532 [08:15<00:59,  1.06it/s]Loading train:  88%|████████▊ | 470/532 [08:15<00:56,  1.09it/s]Loading train:  89%|████████▊ | 471/532 [08:16<00:55,  1.10it/s]Loading train:  89%|████████▊ | 472/532 [08:17<00:53,  1.13it/s]Loading train:  89%|████████▉ | 473/532 [08:18<00:59,  1.00s/it]Loading train:  89%|████████▉ | 474/532 [08:19<00:56,  1.02it/s]Loading train:  89%|████████▉ | 475/532 [08:20<00:56,  1.01it/s]Loading train:  89%|████████▉ | 476/532 [08:21<00:55,  1.01it/s]Loading train:  90%|████████▉ | 477/532 [08:22<00:54,  1.01it/s]Loading train:  90%|████████▉ | 478/532 [08:23<00:54,  1.00s/it]Loading train:  90%|█████████ | 479/532 [08:24<00:50,  1.05it/s]Loading train:  90%|█████████ | 480/532 [08:25<00:48,  1.08it/s]Loading train:  90%|█████████ | 481/532 [08:26<00:48,  1.06it/s]Loading train:  91%|█████████ | 482/532 [08:27<00:46,  1.08it/s]Loading train:  91%|█████████ | 483/532 [08:28<00:45,  1.07it/s]Loading train:  91%|█████████ | 484/532 [08:29<00:44,  1.09it/s]Loading train:  91%|█████████ | 485/532 [08:30<00:47,  1.01s/it]Loading train:  91%|█████████▏| 486/532 [08:31<00:47,  1.04s/it]Loading train:  92%|█████████▏| 487/532 [08:32<00:48,  1.08s/it]Loading train:  92%|█████████▏| 488/532 [08:33<00:46,  1.05s/it]Loading train:  92%|█████████▏| 489/532 [08:34<00:43,  1.02s/it]Loading train:  92%|█████████▏| 490/532 [08:35<00:41,  1.00it/s]Loading train:  92%|█████████▏| 491/532 [08:36<00:38,  1.06it/s]Loading train:  92%|█████████▏| 492/532 [08:37<00:36,  1.10it/s]Loading train:  93%|█████████▎| 493/532 [08:38<00:35,  1.10it/s]Loading train:  93%|█████████▎| 494/532 [08:39<00:36,  1.04it/s]Loading train:  93%|█████████▎| 495/532 [08:40<00:34,  1.08it/s]Loading train:  93%|█████████▎| 496/532 [08:41<00:32,  1.10it/s]Loading train:  93%|█████████▎| 497/532 [08:41<00:32,  1.09it/s]Loading train:  94%|█████████▎| 498/532 [08:42<00:31,  1.10it/s]Loading train:  94%|█████████▍| 499/532 [08:43<00:30,  1.07it/s]Loading train:  94%|█████████▍| 500/532 [08:44<00:29,  1.08it/s]Loading train:  94%|█████████▍| 501/532 [08:45<00:30,  1.02it/s]Loading train:  94%|█████████▍| 502/532 [08:46<00:28,  1.06it/s]Loading train:  95%|█████████▍| 503/532 [08:47<00:26,  1.10it/s]Loading train:  95%|█████████▍| 504/532 [08:48<00:26,  1.07it/s]Loading train:  95%|█████████▍| 505/532 [08:49<00:24,  1.10it/s]Loading train:  95%|█████████▌| 506/532 [08:50<00:25,  1.03it/s]Loading train:  95%|█████████▌| 507/532 [08:51<00:23,  1.08it/s]Loading train:  95%|█████████▌| 508/532 [08:52<00:21,  1.12it/s]Loading train:  96%|█████████▌| 509/532 [08:53<00:21,  1.09it/s]Loading train:  96%|█████████▌| 510/532 [08:54<00:20,  1.06it/s]Loading train:  96%|█████████▌| 511/532 [08:55<00:20,  1.04it/s]Loading train:  96%|█████████▌| 512/532 [08:56<00:19,  1.05it/s]Loading train:  96%|█████████▋| 513/532 [08:57<00:19,  1.02s/it]Loading train:  97%|█████████▋| 514/532 [08:58<00:17,  1.01it/s]Loading train:  97%|█████████▋| 515/532 [08:59<00:17,  1.04s/it]Loading train:  97%|█████████▋| 516/532 [09:00<00:15,  1.00it/s]Loading train:  97%|█████████▋| 517/532 [09:01<00:14,  1.01it/s]Loading train:  97%|█████████▋| 518/532 [09:02<00:13,  1.05it/s]Loading train:  98%|█████████▊| 519/532 [09:03<00:12,  1.02it/s]Loading train:  98%|█████████▊| 520/532 [09:04<00:11,  1.01it/s]Loading train:  98%|█████████▊| 521/532 [09:05<00:11,  1.03s/it]Loading train:  98%|█████████▊| 522/532 [09:06<00:10,  1.07s/it]Loading train:  98%|█████████▊| 523/532 [09:07<00:09,  1.06s/it]Loading train:  98%|█████████▊| 524/532 [09:08<00:08,  1.06s/it]Loading train:  99%|█████████▊| 525/532 [09:09<00:07,  1.05s/it]Loading train:  99%|█████████▉| 526/532 [09:10<00:06,  1.02s/it]Loading train:  99%|█████████▉| 527/532 [09:11<00:04,  1.02it/s]Loading train:  99%|█████████▉| 528/532 [09:12<00:03,  1.08it/s]Loading train:  99%|█████████▉| 529/532 [09:13<00:02,  1.10it/s]Loading train: 100%|█████████▉| 530/532 [09:13<00:01,  1.12it/s]Loading train: 100%|█████████▉| 531/532 [09:14<00:00,  1.13it/s]Loading train: 100%|██████████| 532/532 [09:15<00:00,  1.12it/s]
concatenating: train:   0%|          | 0/532 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 11/532 [00:00<00:05, 100.10it/s]concatenating: train:   5%|▍         | 25/532 [00:00<00:04, 108.93it/s]concatenating: train:  10%|▉         | 53/532 [00:00<00:03, 132.76it/s]concatenating: train:  15%|█▌        | 82/532 [00:00<00:02, 157.87it/s]concatenating: train:  21%|██        | 111/532 [00:00<00:02, 182.10it/s]concatenating: train:  26%|██▌       | 138/532 [00:00<00:01, 201.00it/s]concatenating: train:  32%|███▏      | 169/532 [00:00<00:01, 224.56it/s]concatenating: train:  37%|███▋      | 199/532 [00:00<00:01, 241.47it/s]concatenating: train:  42%|████▏     | 226/532 [00:00<00:01, 247.60it/s]concatenating: train:  48%|████▊     | 255/532 [00:01<00:01, 257.35it/s]concatenating: train:  53%|█████▎    | 282/532 [00:01<00:00, 260.99it/s]concatenating: train:  58%|█████▊    | 309/532 [00:01<00:00, 252.40it/s]concatenating: train:  63%|██████▎   | 335/532 [00:01<00:00, 244.20it/s]concatenating: train:  68%|██████▊   | 360/532 [00:01<00:01, 148.18it/s]concatenating: train:  71%|███████▏  | 380/532 [00:01<00:01, 143.41it/s]concatenating: train:  75%|███████▍  | 398/532 [00:01<00:00, 134.37it/s]concatenating: train:  80%|███████▉  | 425/532 [00:02<00:00, 157.45it/s]concatenating: train:  85%|████████▍ | 450/532 [00:02<00:00, 175.30it/s]concatenating: train:  89%|████████▉ | 476/532 [00:02<00:00, 194.23it/s]concatenating: train:  94%|█████████▍| 500/532 [00:02<00:00, 205.18it/s]concatenating: train: 100%|█████████▉| 531/532 [00:02<00:00, 228.12it/s]concatenating: train: 100%|██████████| 532/532 [00:02<00:00, 212.62it/s]
Loading test:   0%|          | 0/15 [00:00<?, ?it/s]Loading test:   7%|▋         | 1/15 [00:00<00:12,  1.10it/s]Loading test:  13%|█▎        | 2/15 [00:01<00:12,  1.04it/s]Loading test:  20%|██        | 3/15 [00:03<00:11,  1.01it/s]Loading test:  27%|██▋       | 4/15 [00:04<00:10,  1.01it/s]Loading test:  33%|███▎      | 5/15 [00:05<00:11,  1.11s/it]Loading test:  40%|████      | 6/15 [00:06<00:10,  1.15s/it]Loading test:  47%|████▋     | 7/15 [00:07<00:08,  1.05s/it]Loading test:  53%|█████▎    | 8/15 [00:08<00:07,  1.11s/it]Loading test:  60%|██████    | 9/15 [00:09<00:06,  1.08s/it]Loading test:  67%|██████▋   | 10/15 [00:10<00:05,  1.00s/it]Loading test:  73%|███████▎  | 11/15 [00:11<00:03,  1.04it/s]Loading test:  80%|████████  | 12/15 [00:12<00:03,  1.02s/it]Loading test:  87%|████████▋ | 13/15 [00:13<00:02,  1.08s/it]Loading test:  93%|█████████▎| 14/15 [00:14<00:01,  1.05s/it]Loading test: 100%|██████████| 15/15 [00:15<00:00,  1.05s/it]
concatenating: validation:   0%|          | 0/15 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 15/15 [00:00<00:00, 342.71it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 84, 56, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 84, 56, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 84, 56, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 84, 56, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 84, 56, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 84, 56, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 84, 56, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 84, 56, 16)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 42, 28, 16)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 42, 28, 16)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 42, 28, 30)   4350        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 42, 28, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 42, 28, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 42, 28, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 42, 28, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 42, 28, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 42, 28, 46)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 21, 14, 46)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 21, 14, 46)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 21, 14, 60)   24900       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 21, 14, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 21, 14, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 21, 14, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 21, 14, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 21, 14, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 21, 14, 106)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 21, 14, 106)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 42, 28, 30)   12750       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 42, 28, 76)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 42, 28, 30)   20550       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 42, 28, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 42, 28, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 42, 28, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 42, 28, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 42, 28, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 42, 28, 106)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-07 00:53:53.304302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 00:53:53.304403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 00:53:53.304419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 00:53:53.304427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 00:53:53.304849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 42, 28, 106)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 84, 56, 15)   6375        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 56, 31)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 84, 56, 15)   4200        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 84, 56, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 84, 56, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 84, 56, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 84, 56, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 56, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 84, 56, 46)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 84, 56, 46)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 84, 56, 13)   611         dropout_5[0][0]                  
==================================================================================================
Total params: 127,886
Trainable params: 127,286
Non-trainable params: 600
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.53807809e-02 2.88974534e-02 1.16728790e-01 1.00198377e-02
 3.03363016e-02 5.79915656e-03 6.86746312e-02 1.28228722e-01
 7.55625878e-02 1.22514673e-02 2.73642650e-01 1.84278063e-01
 1.99559502e-04]
Train on 19871 samples, validate on 569 samples
Epoch 1/300
 - 27s - loss: 82.9479 - acc: 0.5625 - mDice: 0.0194 - val_loss: 9.6795 - val_acc: 0.9112 - val_mDice: 0.0072

Epoch 00001: val_mDice improved from -inf to 0.00723, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 18s - loss: 9.7551 - acc: 0.8937 - mDice: 0.0453 - val_loss: 7.1366 - val_acc: 0.9111 - val_mDice: 0.0317

Epoch 00002: val_mDice improved from 0.00723 to 0.03166, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 19s - loss: 7.8448 - acc: 0.8955 - mDice: 0.0643 - val_loss: 5.4594 - val_acc: 0.9150 - val_mDice: 0.0769

Epoch 00003: val_mDice improved from 0.03166 to 0.07694, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 17s - loss: 6.8831 - acc: 0.8978 - mDice: 0.0837 - val_loss: 4.6565 - val_acc: 0.9183 - val_mDice: 0.1165

Epoch 00004: val_mDice improved from 0.07694 to 0.11650, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 19s - loss: 6.0752 - acc: 0.9029 - mDice: 0.1126 - val_loss: 4.0627 - val_acc: 0.9219 - val_mDice: 0.1624

Epoch 00005: val_mDice improved from 0.11650 to 0.16236, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 17s - loss: 5.3188 - acc: 0.9113 - mDice: 0.1602 - val_loss: 3.6781 - val_acc: 0.9357 - val_mDice: 0.2290

Epoch 00006: val_mDice improved from 0.16236 to 0.22903, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 7/300
 - 19s - loss: 4.6990 - acc: 0.9191 - mDice: 0.2170 - val_loss: 3.1895 - val_acc: 0.9448 - val_mDice: 0.3249

Epoch 00007: val_mDice improved from 0.22903 to 0.32488, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 8/300
 - 18s - loss: 4.2041 - acc: 0.9253 - mDice: 0.2693 - val_loss: 2.5394 - val_acc: 0.9516 - val_mDice: 0.4053

Epoch 00008: val_mDice improved from 0.32488 to 0.40526, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 18s - loss: 3.7652 - acc: 0.9304 - mDice: 0.3211 - val_loss: 2.1744 - val_acc: 0.9583 - val_mDice: 0.4885

Epoch 00009: val_mDice improved from 0.40526 to 0.48849, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 10/300
 - 18s - loss: 3.3986 - acc: 0.9352 - mDice: 0.3722 - val_loss: 1.9599 - val_acc: 0.9618 - val_mDice: 0.5437

Epoch 00010: val_mDice improved from 0.48849 to 0.54368, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 11/300
 - 17s - loss: 3.1289 - acc: 0.9390 - mDice: 0.4111 - val_loss: 1.7931 - val_acc: 0.9657 - val_mDice: 0.5770

Epoch 00011: val_mDice improved from 0.54368 to 0.57696, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 12/300
 - 18s - loss: 2.9048 - acc: 0.9418 - mDice: 0.4445 - val_loss: 1.6347 - val_acc: 0.9670 - val_mDice: 0.6134

Epoch 00012: val_mDice improved from 0.57696 to 0.61342, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 13/300
 - 18s - loss: 2.7191 - acc: 0.9443 - mDice: 0.4720 - val_loss: 1.6176 - val_acc: 0.9689 - val_mDice: 0.6234

Epoch 00013: val_mDice improved from 0.61342 to 0.62342, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 14/300
 - 20s - loss: 2.5875 - acc: 0.9461 - mDice: 0.4930 - val_loss: 1.5664 - val_acc: 0.9692 - val_mDice: 0.6355

Epoch 00014: val_mDice improved from 0.62342 to 0.63554, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 15/300
 - 21s - loss: 2.4678 - acc: 0.9473 - mDice: 0.5125 - val_loss: 1.5342 - val_acc: 0.9694 - val_mDice: 0.6442

Epoch 00015: val_mDice improved from 0.63554 to 0.64415, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 16/300
 - 23s - loss: 2.3738 - acc: 0.9487 - mDice: 0.5278 - val_loss: 1.5025 - val_acc: 0.9696 - val_mDice: 0.6528

Epoch 00016: val_mDice improved from 0.64415 to 0.65276, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 17/300
 - 21s - loss: 2.2816 - acc: 0.9498 - mDice: 0.5432 - val_loss: 1.4341 - val_acc: 0.9710 - val_mDice: 0.6655

Epoch 00017: val_mDice improved from 0.65276 to 0.66550, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 18/300
 - 23s - loss: 2.2041 - acc: 0.9508 - mDice: 0.5558 - val_loss: 1.4017 - val_acc: 0.9710 - val_mDice: 0.6741

Epoch 00018: val_mDice improved from 0.66550 to 0.67407, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 19/300
 - 22s - loss: 2.1453 - acc: 0.9514 - mDice: 0.5654 - val_loss: 1.3846 - val_acc: 0.9707 - val_mDice: 0.6812

Epoch 00019: val_mDice improved from 0.67407 to 0.68119, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 20/300
 - 23s - loss: 2.0773 - acc: 0.9523 - mDice: 0.5768 - val_loss: 1.3642 - val_acc: 0.9716 - val_mDice: 0.6850

Epoch 00020: val_mDice improved from 0.68119 to 0.68503, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 21/300
 - 22s - loss: 2.0281 - acc: 0.9527 - mDice: 0.5845 - val_loss: 1.3488 - val_acc: 0.9714 - val_mDice: 0.6906

Epoch 00021: val_mDice improved from 0.68503 to 0.69064, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 22/300
 - 22s - loss: 1.9691 - acc: 0.9535 - mDice: 0.5943 - val_loss: 1.3216 - val_acc: 0.9729 - val_mDice: 0.6946

Epoch 00022: val_mDice improved from 0.69064 to 0.69463, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 23/300
 - 22s - loss: 1.9185 - acc: 0.9540 - mDice: 0.6028 - val_loss: 1.3283 - val_acc: 0.9730 - val_mDice: 0.6969

Epoch 00023: val_mDice improved from 0.69463 to 0.69690, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 24/300
 - 22s - loss: 1.8635 - acc: 0.9548 - mDice: 0.6125 - val_loss: 1.2740 - val_acc: 0.9733 - val_mDice: 0.7050

Epoch 00024: val_mDice improved from 0.69690 to 0.70497, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 25/300
 - 23s - loss: 1.8306 - acc: 0.9552 - mDice: 0.6185 - val_loss: 1.3105 - val_acc: 0.9719 - val_mDice: 0.7042

Epoch 00025: val_mDice did not improve from 0.70497
Epoch 26/300
 - 20s - loss: 1.8005 - acc: 0.9555 - mDice: 0.6242 - val_loss: 1.2967 - val_acc: 0.9728 - val_mDice: 0.7058

Epoch 00026: val_mDice improved from 0.70497 to 0.70583, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 27/300
 - 24s - loss: 1.7660 - acc: 0.9561 - mDice: 0.6308 - val_loss: 1.2524 - val_acc: 0.9746 - val_mDice: 0.7103

Epoch 00027: val_mDice improved from 0.70583 to 0.71030, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 28/300
 - 21s - loss: 1.7354 - acc: 0.9565 - mDice: 0.6359 - val_loss: 1.2548 - val_acc: 0.9723 - val_mDice: 0.7147

Epoch 00028: val_mDice improved from 0.71030 to 0.71475, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 29/300
 - 23s - loss: 1.7172 - acc: 0.9567 - mDice: 0.6392 - val_loss: 1.2422 - val_acc: 0.9740 - val_mDice: 0.7187

Epoch 00029: val_mDice improved from 0.71475 to 0.71870, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 30/300
 - 22s - loss: 1.6915 - acc: 0.9571 - mDice: 0.6442 - val_loss: 1.2165 - val_acc: 0.9746 - val_mDice: 0.7193

Epoch 00030: val_mDice improved from 0.71870 to 0.71927, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 31/300
 - 23s - loss: 1.6695 - acc: 0.9573 - mDice: 0.6480 - val_loss: 1.2342 - val_acc: 0.9740 - val_mDice: 0.7165

Epoch 00031: val_mDice did not improve from 0.71927
Epoch 32/300
 - 21s - loss: 1.6557 - acc: 0.9576 - mDice: 0.6508 - val_loss: 1.2435 - val_acc: 0.9744 - val_mDice: 0.7220

Epoch 00032: val_mDice improved from 0.71927 to 0.72203, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 33/300
 - 17s - loss: 1.6247 - acc: 0.9581 - mDice: 0.6565 - val_loss: 1.2014 - val_acc: 0.9736 - val_mDice: 0.7295

Epoch 00033: val_mDice improved from 0.72203 to 0.72952, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 34/300
 - 18s - loss: 1.6150 - acc: 0.9583 - mDice: 0.6589 - val_loss: 1.1853 - val_acc: 0.9754 - val_mDice: 0.7291

Epoch 00034: val_mDice did not improve from 0.72952
Epoch 35/300
 - 17s - loss: 1.5942 - acc: 0.9585 - mDice: 0.6626 - val_loss: 1.1779 - val_acc: 0.9748 - val_mDice: 0.7303

Epoch 00035: val_mDice improved from 0.72952 to 0.73027, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 36/300
 - 17s - loss: 1.5688 - acc: 0.9589 - mDice: 0.6675 - val_loss: 1.1726 - val_acc: 0.9746 - val_mDice: 0.7316

Epoch 00036: val_mDice improved from 0.73027 to 0.73155, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 37/300
 - 17s - loss: 1.5561 - acc: 0.9591 - mDice: 0.6699 - val_loss: 1.1816 - val_acc: 0.9754 - val_mDice: 0.7325

Epoch 00037: val_mDice improved from 0.73155 to 0.73246, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 38/300
 - 18s - loss: 1.5476 - acc: 0.9591 - mDice: 0.6720 - val_loss: 1.1879 - val_acc: 0.9755 - val_mDice: 0.7336

Epoch 00038: val_mDice improved from 0.73246 to 0.73355, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 39/300
 - 17s - loss: 1.5296 - acc: 0.9595 - mDice: 0.6748 - val_loss: 1.1558 - val_acc: 0.9761 - val_mDice: 0.7359

Epoch 00039: val_mDice improved from 0.73355 to 0.73586, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 40/300
 - 17s - loss: 1.5207 - acc: 0.9597 - mDice: 0.6775 - val_loss: 1.1820 - val_acc: 0.9760 - val_mDice: 0.7351

Epoch 00040: val_mDice did not improve from 0.73586
Epoch 41/300
 - 18s - loss: 1.5024 - acc: 0.9599 - mDice: 0.6804 - val_loss: 1.1456 - val_acc: 0.9766 - val_mDice: 0.7358

Epoch 00041: val_mDice did not improve from 0.73586
Epoch 42/300
 - 17s - loss: 1.4940 - acc: 0.9600 - mDice: 0.6818 - val_loss: 1.1464 - val_acc: 0.9753 - val_mDice: 0.7412

Epoch 00042: val_mDice improved from 0.73586 to 0.74118, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 43/300
 - 17s - loss: 1.4778 - acc: 0.9603 - mDice: 0.6848 - val_loss: 1.1735 - val_acc: 0.9745 - val_mDice: 0.7378

Epoch 00043: val_mDice did not improve from 0.74118
Epoch 44/300
 - 17s - loss: 1.4677 - acc: 0.9605 - mDice: 0.6873 - val_loss: 1.1754 - val_acc: 0.9755 - val_mDice: 0.7388

Epoch 00044: val_mDice did not improve from 0.74118
Epoch 45/300
 - 18s - loss: 1.4568 - acc: 0.9606 - mDice: 0.6888 - val_loss: 1.1456 - val_acc: 0.9758 - val_mDice: 0.7431

Epoch 00045: val_mDice improved from 0.74118 to 0.74310, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 46/300
 - 17s - loss: 1.4482 - acc: 0.9607 - mDice: 0.6910 - val_loss: 1.1188 - val_acc: 0.9758 - val_mDice: 0.7444

Epoch 00046: val_mDice improved from 0.74310 to 0.74444, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 47/300
 - 17s - loss: 1.4382 - acc: 0.9608 - mDice: 0.6927 - val_loss: 1.1439 - val_acc: 0.9752 - val_mDice: 0.7400

Epoch 00047: val_mDice did not improve from 0.74444
Epoch 48/300
 - 17s - loss: 1.4277 - acc: 0.9610 - mDice: 0.6949 - val_loss: 1.1234 - val_acc: 0.9766 - val_mDice: 0.7441

Epoch 00048: val_mDice did not improve from 0.74444
Epoch 49/300
 - 17s - loss: 1.4222 - acc: 0.9611 - mDice: 0.6966 - val_loss: 1.1585 - val_acc: 0.9758 - val_mDice: 0.7432

Epoch 00049: val_mDice did not improve from 0.74444
Epoch 50/300
 - 18s - loss: 1.4153 - acc: 0.9611 - mDice: 0.6975 - val_loss: 1.1351 - val_acc: 0.9765 - val_mDice: 0.7490

Epoch 00050: val_mDice improved from 0.74444 to 0.74904, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 51/300
 - 17s - loss: 1.4058 - acc: 0.9613 - mDice: 0.6997 - val_loss: 1.1142 - val_acc: 0.9766 - val_mDice: 0.7497

Epoch 00051: val_mDice improved from 0.74904 to 0.74974, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 52/300
 - 17s - loss: 1.3977 - acc: 0.9614 - mDice: 0.7008 - val_loss: 1.1131 - val_acc: 0.9761 - val_mDice: 0.7460

Epoch 00052: val_mDice did not improve from 0.74974
Epoch 53/300
 - 19s - loss: 1.3888 - acc: 0.9615 - mDice: 0.7032 - val_loss: 1.1155 - val_acc: 0.9769 - val_mDice: 0.7492

Epoch 00053: val_mDice did not improve from 0.74974
Epoch 54/300
 - 17s - loss: 1.3825 - acc: 0.9616 - mDice: 0.7042 - val_loss: 1.1669 - val_acc: 0.9764 - val_mDice: 0.7423

Epoch 00054: val_mDice did not improve from 0.74974
Epoch 55/300
 - 19s - loss: 1.3738 - acc: 0.9618 - mDice: 0.7057 - val_loss: 1.1258 - val_acc: 0.9769 - val_mDice: 0.7524

Epoch 00055: val_mDice improved from 0.74974 to 0.75244, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 56/300
 - 18s - loss: 1.3685 - acc: 0.9619 - mDice: 0.7069 - val_loss: 1.1126 - val_acc: 0.9766 - val_mDice: 0.7484

Epoch 00056: val_mDice did not improve from 0.75244
Epoch 57/300
 - 18s - loss: 1.3674 - acc: 0.9618 - mDice: 0.7066 - val_loss: 1.0904 - val_acc: 0.9774 - val_mDice: 0.7566

Epoch 00057: val_mDice improved from 0.75244 to 0.75662, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 58/300
 - 18s - loss: 1.3554 - acc: 0.9620 - mDice: 0.7093 - val_loss: 1.1133 - val_acc: 0.9765 - val_mDice: 0.7501

Epoch 00058: val_mDice did not improve from 0.75662
Epoch 59/300
 - 18s - loss: 1.3535 - acc: 0.9620 - mDice: 0.7098 - val_loss: 1.1602 - val_acc: 0.9767 - val_mDice: 0.7459

Epoch 00059: val_mDice did not improve from 0.75662
Epoch 60/300
 - 18s - loss: 1.3489 - acc: 0.9620 - mDice: 0.7104 - val_loss: 1.1057 - val_acc: 0.9767 - val_mDice: 0.7533

Epoch 00060: val_mDice did not improve from 0.75662
Epoch 61/300
 - 18s - loss: 1.3425 - acc: 0.9622 - mDice: 0.7119 - val_loss: 1.0996 - val_acc: 0.9769 - val_mDice: 0.7524

Epoch 00061: val_mDice did not improve from 0.75662
Epoch 62/300
 - 17s - loss: 1.3372 - acc: 0.9622 - mDice: 0.7130 - val_loss: 1.1265 - val_acc: 0.9770 - val_mDice: 0.7514

Epoch 00062: val_mDice did not improve from 0.75662
Epoch 63/300
 - 18s - loss: 1.3370 - acc: 0.9622 - mDice: 0.7126 - val_loss: 1.1064 - val_acc: 0.9772 - val_mDice: 0.7539

Epoch 00063: val_mDice did not improve from 0.75662
Epoch 64/300
 - 17s - loss: 1.3282 - acc: 0.9624 - mDice: 0.7146 - val_loss: 1.1008 - val_acc: 0.9775 - val_mDice: 0.7514

Epoch 00064: val_mDice did not improve from 0.75662
Epoch 65/300
 - 18s - loss: 1.3210 - acc: 0.9624 - mDice: 0.7156 - val_loss: 1.1054 - val_acc: 0.9765 - val_mDice: 0.7545

Epoch 00065: val_mDice did not improve from 0.75662
Epoch 66/300
 - 17s - loss: 1.3214 - acc: 0.9624 - mDice: 0.7161 - val_loss: 1.1205 - val_acc: 0.9778 - val_mDice: 0.7561

Epoch 00066: val_mDice did not improve from 0.75662
Epoch 67/300
 - 18s - loss: 1.3143 - acc: 0.9626 - mDice: 0.7171 - val_loss: 1.0778 - val_acc: 0.9778 - val_mDice: 0.7549

Epoch 00067: val_mDice did not improve from 0.75662
Epoch 68/300
 - 17s - loss: 1.3129 - acc: 0.9626 - mDice: 0.7174 - val_loss: 1.0890 - val_acc: 0.9770 - val_mDice: 0.7554

Epoch 00068: val_mDice did not improve from 0.75662
Epoch 69/300
 - 18s - loss: 1.3052 - acc: 0.9627 - mDice: 0.7190 - val_loss: 1.0937 - val_acc: 0.9774 - val_mDice: 0.7549

Epoch 00069: val_mDice did not improve from 0.75662
Epoch 70/300
 - 18s - loss: 1.3007 - acc: 0.9628 - mDice: 0.7197 - val_loss: 1.1111 - val_acc: 0.9772 - val_mDice: 0.7578

Epoch 00070: val_mDice improved from 0.75662 to 0.75777, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 71/300
 - 19s - loss: 1.2994 - acc: 0.9628 - mDice: 0.7205 - val_loss: 1.1009 - val_acc: 0.9771 - val_mDice: 0.7542

Epoch 00071: val_mDice did not improve from 0.75777
Epoch 72/300
 - 17s - loss: 1.2972 - acc: 0.9628 - mDice: 0.7209 - val_loss: 1.1087 - val_acc: 0.9776 - val_mDice: 0.7536

Epoch 00072: val_mDice did not improve from 0.75777
Epoch 73/300
 - 19s - loss: 1.2948 - acc: 0.9629 - mDice: 0.7213 - val_loss: 1.0919 - val_acc: 0.9776 - val_mDice: 0.7609

Epoch 00073: val_mDice improved from 0.75777 to 0.76090, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 74/300
 - 17s - loss: 1.2844 - acc: 0.9631 - mDice: 0.7231 - val_loss: 1.0973 - val_acc: 0.9775 - val_mDice: 0.7565

Epoch 00074: val_mDice did not improve from 0.76090
Epoch 75/300
 - 19s - loss: 1.2852 - acc: 0.9631 - mDice: 0.7229 - val_loss: 1.1026 - val_acc: 0.9775 - val_mDice: 0.7521

Epoch 00075: val_mDice did not improve from 0.76090
Epoch 76/300
 - 17s - loss: 1.2854 - acc: 0.9631 - mDice: 0.7229 - val_loss: 1.1064 - val_acc: 0.9769 - val_mDice: 0.7544

Epoch 00076: val_mDice did not improve from 0.76090
Epoch 77/300
 - 19s - loss: 1.2796 - acc: 0.9632 - mDice: 0.7240 - val_loss: 1.0850 - val_acc: 0.9775 - val_mDice: 0.7574

Epoch 00077: val_mDice did not improve from 0.76090
Epoch 78/300
 - 17s - loss: 1.2772 - acc: 0.9631 - mDice: 0.7245 - val_loss: 1.1086 - val_acc: 0.9775 - val_mDice: 0.7573

Epoch 00078: val_mDice did not improve from 0.76090
Epoch 79/300
 - 19s - loss: 1.2737 - acc: 0.9632 - mDice: 0.7251 - val_loss: 1.0843 - val_acc: 0.9772 - val_mDice: 0.7567

Epoch 00079: val_mDice did not improve from 0.76090
Epoch 80/300
 - 18s - loss: 1.2715 - acc: 0.9633 - mDice: 0.7256 - val_loss: 1.0920 - val_acc: 0.9775 - val_mDice: 0.7610

Epoch 00080: val_mDice improved from 0.76090 to 0.76102, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 81/300
 - 19s - loss: 1.2700 - acc: 0.9633 - mDice: 0.7259 - val_loss: 1.0966 - val_acc: 0.9775 - val_mDice: 0.7570

Epoch 00081: val_mDice did not improve from 0.76102
Epoch 82/300
 - 19s - loss: 1.2647 - acc: 0.9634 - mDice: 0.7268 - val_loss: 1.1002 - val_acc: 0.9776 - val_mDice: 0.7554

Epoch 00082: val_mDice did not improve from 0.76102
Epoch 83/300
 - 19s - loss: 1.2611 - acc: 0.9634 - mDice: 0.7276 - val_loss: 1.0849 - val_acc: 0.9775 - val_mDice: 0.7606

Epoch 00083: val_mDice did not improve from 0.76102
Epoch 84/300
 - 19s - loss: 1.2644 - acc: 0.9634 - mDice: 0.7270 - val_loss: 1.0746 - val_acc: 0.9777 - val_mDice: 0.7599

Epoch 00084: val_mDice did not improve from 0.76102
Epoch 85/300
 - 18s - loss: 1.2553 - acc: 0.9636 - mDice: 0.7290 - val_loss: 1.1031 - val_acc: 0.9781 - val_mDice: 0.7517

Epoch 00085: val_mDice did not improve from 0.76102
Epoch 86/300
 - 20s - loss: 1.2568 - acc: 0.9636 - mDice: 0.7281 - val_loss: 1.0905 - val_acc: 0.9781 - val_mDice: 0.7629

Epoch 00086: val_mDice improved from 0.76102 to 0.76286, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 87/300
 - 18s - loss: 1.2508 - acc: 0.9636 - mDice: 0.7296 - val_loss: 1.0922 - val_acc: 0.9777 - val_mDice: 0.7578

Epoch 00087: val_mDice did not improve from 0.76286
Epoch 88/300
 - 20s - loss: 1.2522 - acc: 0.9637 - mDice: 0.7295 - val_loss: 1.0728 - val_acc: 0.9781 - val_mDice: 0.7602

Epoch 00088: val_mDice did not improve from 0.76286
Epoch 89/300
 - 19s - loss: 1.2457 - acc: 0.9637 - mDice: 0.7304 - val_loss: 1.0686 - val_acc: 0.9778 - val_mDice: 0.7641

Epoch 00089: val_mDice improved from 0.76286 to 0.76406, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 90/300
 - 19s - loss: 1.2450 - acc: 0.9637 - mDice: 0.7309 - val_loss: 1.0999 - val_acc: 0.9772 - val_mDice: 0.7560

Epoch 00090: val_mDice did not improve from 0.76406
Epoch 91/300
 - 20s - loss: 1.2476 - acc: 0.9637 - mDice: 0.7305 - val_loss: 1.0911 - val_acc: 0.9776 - val_mDice: 0.7607

Epoch 00091: val_mDice did not improve from 0.76406
Epoch 92/300
 - 18s - loss: 1.2404 - acc: 0.9638 - mDice: 0.7317 - val_loss: 1.0886 - val_acc: 0.9781 - val_mDice: 0.7607

Epoch 00092: val_mDice did not improve from 0.76406
Epoch 93/300
 - 19s - loss: 1.2408 - acc: 0.9638 - mDice: 0.7318 - val_loss: 1.0668 - val_acc: 0.9781 - val_mDice: 0.7624

Epoch 00093: val_mDice did not improve from 0.76406
Epoch 94/300
 - 17s - loss: 1.2359 - acc: 0.9639 - mDice: 0.7326 - val_loss: 1.0751 - val_acc: 0.9779 - val_mDice: 0.7603

Epoch 00094: val_mDice did not improve from 0.76406
Epoch 95/300
 - 18s - loss: 1.2323 - acc: 0.9640 - mDice: 0.7333 - val_loss: 1.0607 - val_acc: 0.9778 - val_mDice: 0.7620

Epoch 00095: val_mDice did not improve from 0.76406
Epoch 96/300
 - 17s - loss: 1.2327 - acc: 0.9639 - mDice: 0.7332 - val_loss: 1.0862 - val_acc: 0.9776 - val_mDice: 0.7646

Epoch 00096: val_mDice improved from 0.76406 to 0.76461, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 97/300
 - 17s - loss: 1.2314 - acc: 0.9640 - mDice: 0.7335 - val_loss: 1.0858 - val_acc: 0.9781 - val_mDice: 0.7582

Epoch 00097: val_mDice did not improve from 0.76461
Epoch 98/300
 - 18s - loss: 1.2330 - acc: 0.9640 - mDice: 0.7330 - val_loss: 1.0706 - val_acc: 0.9774 - val_mDice: 0.7624

Epoch 00098: val_mDice did not improve from 0.76461
Epoch 99/300
 - 17s - loss: 1.2302 - acc: 0.9640 - mDice: 0.7338 - val_loss: 1.0781 - val_acc: 0.9776 - val_mDice: 0.7604

Epoch 00099: val_mDice did not improve from 0.76461
Epoch 100/300
 - 18s - loss: 1.2233 - acc: 0.9642 - mDice: 0.7351 - val_loss: 1.0809 - val_acc: 0.9774 - val_mDice: 0.7587

Epoch 00100: val_mDice did not improve from 0.76461
Epoch 101/300
 - 17s - loss: 1.2246 - acc: 0.9641 - mDice: 0.7349 - val_loss: 1.0685 - val_acc: 0.9783 - val_mDice: 0.7665

Epoch 00101: val_mDice improved from 0.76461 to 0.76646, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 102/300
 - 17s - loss: 1.2246 - acc: 0.9641 - mDice: 0.7348 - val_loss: 1.0742 - val_acc: 0.9777 - val_mDice: 0.7642

Epoch 00102: val_mDice did not improve from 0.76646
Epoch 103/300
 - 18s - loss: 1.2178 - acc: 0.9643 - mDice: 0.7362 - val_loss: 1.0803 - val_acc: 0.9776 - val_mDice: 0.7622

Epoch 00103: val_mDice did not improve from 0.76646
Epoch 104/300
 - 17s - loss: 1.2139 - acc: 0.9643 - mDice: 0.7373 - val_loss: 1.1002 - val_acc: 0.9777 - val_mDice: 0.7613

Epoch 00104: val_mDice did not improve from 0.76646
Epoch 105/300
 - 17s - loss: 1.2153 - acc: 0.9644 - mDice: 0.7369 - val_loss: 1.0653 - val_acc: 0.9785 - val_mDice: 0.7609

Epoch 00105: val_mDice did not improve from 0.76646
Epoch 106/300
 - 17s - loss: 1.2152 - acc: 0.9643 - mDice: 0.7369 - val_loss: 1.0616 - val_acc: 0.9783 - val_mDice: 0.7646

Epoch 00106: val_mDice did not improve from 0.76646
Epoch 107/300
 - 17s - loss: 1.2108 - acc: 0.9644 - mDice: 0.7377 - val_loss: 1.0899 - val_acc: 0.9779 - val_mDice: 0.7657

Epoch 00107: val_mDice did not improve from 0.76646
Epoch 108/300
 - 17s - loss: 1.2115 - acc: 0.9644 - mDice: 0.7376 - val_loss: 1.0623 - val_acc: 0.9783 - val_mDice: 0.7658

Epoch 00108: val_mDice did not improve from 0.76646
Epoch 109/300
 - 18s - loss: 1.2080 - acc: 0.9645 - mDice: 0.7384 - val_loss: 1.0621 - val_acc: 0.9788 - val_mDice: 0.7661

Epoch 00109: val_mDice did not improve from 0.76646
Epoch 110/300
 - 17s - loss: 1.2053 - acc: 0.9645 - mDice: 0.7388 - val_loss: 1.0604 - val_acc: 0.9787 - val_mDice: 0.7636

Epoch 00110: val_mDice did not improve from 0.76646
Epoch 111/300
 - 17s - loss: 1.2054 - acc: 0.9645 - mDice: 0.7387 - val_loss: 1.0633 - val_acc: 0.9782 - val_mDice: 0.7648

Epoch 00111: val_mDice did not improve from 0.76646
Epoch 112/300
 - 17s - loss: 1.2051 - acc: 0.9645 - mDice: 0.7389 - val_loss: 1.0663 - val_acc: 0.9779 - val_mDice: 0.7661

Epoch 00112: val_mDice did not improve from 0.76646
Epoch 113/300
 - 17s - loss: 1.2007 - acc: 0.9646 - mDice: 0.7400 - val_loss: 1.0538 - val_acc: 0.9781 - val_mDice: 0.7666

Epoch 00113: val_mDice improved from 0.76646 to 0.76660, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 114/300
 - 18s - loss: 1.2006 - acc: 0.9646 - mDice: 0.7401 - val_loss: 1.0571 - val_acc: 0.9788 - val_mDice: 0.7668

Epoch 00114: val_mDice improved from 0.76660 to 0.76684, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 115/300
 - 17s - loss: 1.1984 - acc: 0.9647 - mDice: 0.7401 - val_loss: 1.0727 - val_acc: 0.9784 - val_mDice: 0.7646

Epoch 00115: val_mDice did not improve from 0.76684
Epoch 116/300
 - 17s - loss: 1.1997 - acc: 0.9646 - mDice: 0.7401 - val_loss: 1.0580 - val_acc: 0.9789 - val_mDice: 0.7671

Epoch 00116: val_mDice improved from 0.76684 to 0.76714, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 117/300
 - 17s - loss: 1.1961 - acc: 0.9647 - mDice: 0.7409 - val_loss: 1.0573 - val_acc: 0.9787 - val_mDice: 0.7665

Epoch 00117: val_mDice did not improve from 0.76714
Epoch 118/300
 - 17s - loss: 1.1952 - acc: 0.9647 - mDice: 0.7408 - val_loss: 1.0716 - val_acc: 0.9781 - val_mDice: 0.7657

Epoch 00118: val_mDice did not improve from 0.76714
Epoch 119/300
 - 18s - loss: 1.1937 - acc: 0.9647 - mDice: 0.7411 - val_loss: 1.0627 - val_acc: 0.9787 - val_mDice: 0.7656

Epoch 00119: val_mDice did not improve from 0.76714
Epoch 120/300
 - 17s - loss: 1.1912 - acc: 0.9648 - mDice: 0.7421 - val_loss: 1.0698 - val_acc: 0.9779 - val_mDice: 0.7629

Epoch 00120: val_mDice did not improve from 0.76714
Epoch 121/300
 - 17s - loss: 1.1902 - acc: 0.9649 - mDice: 0.7421 - val_loss: 1.0660 - val_acc: 0.9784 - val_mDice: 0.7695

Epoch 00121: val_mDice improved from 0.76714 to 0.76947, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 122/300
 - 18s - loss: 1.1916 - acc: 0.9648 - mDice: 0.7416 - val_loss: 1.0565 - val_acc: 0.9784 - val_mDice: 0.7695

Epoch 00122: val_mDice improved from 0.76947 to 0.76953, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 123/300
 - 18s - loss: 1.1885 - acc: 0.9649 - mDice: 0.7423 - val_loss: 1.0542 - val_acc: 0.9789 - val_mDice: 0.7704

Epoch 00123: val_mDice improved from 0.76953 to 0.77035, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 124/300
 - 17s - loss: 1.1848 - acc: 0.9649 - mDice: 0.7432 - val_loss: 1.0475 - val_acc: 0.9788 - val_mDice: 0.7663

Epoch 00124: val_mDice did not improve from 0.77035
Epoch 125/300
 - 18s - loss: 1.1823 - acc: 0.9649 - mDice: 0.7436 - val_loss: 1.0549 - val_acc: 0.9777 - val_mDice: 0.7706

Epoch 00125: val_mDice improved from 0.77035 to 0.77063, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 126/300
 - 17s - loss: 1.1847 - acc: 0.9650 - mDice: 0.7435 - val_loss: 1.0455 - val_acc: 0.9787 - val_mDice: 0.7671

Epoch 00126: val_mDice did not improve from 0.77063
Epoch 127/300
 - 17s - loss: 1.1831 - acc: 0.9649 - mDice: 0.7434 - val_loss: 1.0617 - val_acc: 0.9782 - val_mDice: 0.7650

Epoch 00127: val_mDice did not improve from 0.77063
Epoch 128/300
 - 17s - loss: 1.1812 - acc: 0.9650 - mDice: 0.7438 - val_loss: 1.0700 - val_acc: 0.9783 - val_mDice: 0.7668

Epoch 00128: val_mDice did not improve from 0.77063
Epoch 129/300
 - 18s - loss: 1.1814 - acc: 0.9650 - mDice: 0.7438 - val_loss: 1.0595 - val_acc: 0.9781 - val_mDice: 0.7693

Epoch 00129: val_mDice did not improve from 0.77063
Epoch 130/300
 - 17s - loss: 1.1791 - acc: 0.9650 - mDice: 0.7445 - val_loss: 1.0409 - val_acc: 0.9787 - val_mDice: 0.7686

Epoch 00130: val_mDice did not improve from 0.77063
Epoch 131/300
 - 17s - loss: 1.1792 - acc: 0.9650 - mDice: 0.7444 - val_loss: 1.0505 - val_acc: 0.9781 - val_mDice: 0.7690

Epoch 00131: val_mDice did not improve from 0.77063
Epoch 132/300
 - 17s - loss: 1.1814 - acc: 0.9650 - mDice: 0.7438 - val_loss: 1.0682 - val_acc: 0.9774 - val_mDice: 0.7697

Epoch 00132: val_mDice did not improve from 0.77063
Epoch 133/300
 - 17s - loss: 1.1773 - acc: 0.9650 - mDice: 0.7447 - val_loss: 1.0867 - val_acc: 0.9783 - val_mDice: 0.7626

Epoch 00133: val_mDice did not improve from 0.77063
Epoch 134/300
 - 18s - loss: 1.1763 - acc: 0.9650 - mDice: 0.7450 - val_loss: 1.0589 - val_acc: 0.9785 - val_mDice: 0.7667

Epoch 00134: val_mDice did not improve from 0.77063
Epoch 135/300
 - 17s - loss: 1.1766 - acc: 0.9651 - mDice: 0.7449 - val_loss: 1.0443 - val_acc: 0.9791 - val_mDice: 0.7696

Epoch 00135: val_mDice did not improve from 0.77063
Epoch 136/300
 - 17s - loss: 1.1721 - acc: 0.9651 - mDice: 0.7461 - val_loss: 1.0678 - val_acc: 0.9789 - val_mDice: 0.7665

Epoch 00136: val_mDice did not improve from 0.77063
Epoch 137/300
 - 17s - loss: 1.1697 - acc: 0.9651 - mDice: 0.7462 - val_loss: 1.0576 - val_acc: 0.9782 - val_mDice: 0.7700

Epoch 00137: val_mDice did not improve from 0.77063
Epoch 138/300
 - 18s - loss: 1.1708 - acc: 0.9651 - mDice: 0.7461 - val_loss: 1.0528 - val_acc: 0.9787 - val_mDice: 0.7720

Epoch 00138: val_mDice improved from 0.77063 to 0.77205, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE8_Cascade_FM15_Res_Unet_NL3_LS_MyBCE_US1/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 139/300
 - 17s - loss: 1.1682 - acc: 0.9652 - mDice: 0.7467 - val_loss: 1.0436 - val_acc: 0.9790 - val_mDice: 0.7719

Epoch 00139: val_mDice did not improve from 0.77205
Epoch 140/300
 - 19s - loss: 1.1674 - acc: 0.9652 - mDice: 0.7469 - val_loss: 1.0520 - val_acc: 0.9782 - val_mDice: 0.7708

Epoch 00140: val_mDice did not improve from 0.77205
Epoch 141/300
 - 17s - loss: 1.1690 - acc: 0.9652 - mDice: 0.7465 - val_loss: 1.0554 - val_acc: 0.9786 - val_mDice: 0.7687

Epoch 00141: val_mDice did not improve from 0.77205
Epoch 142/300
 - 18s - loss: 1.1666 - acc: 0.9652 - mDice: 0.7468 - val_loss: 1.0645 - val_acc: 0.9787 - val_mDice: 0.7675

Epoch 00142: val_mDice did not improve from 0.77205
Epoch 143/300
 - 18s - loss: 1.1651 - acc: 0.9652 - mDice: 0.7475 - val_loss: 1.0486 - val_acc: 0.9785 - val_mDice: 0.7699

Epoch 00143: val_mDice did not improve from 0.77205
Epoch 144/300
 - 18s - loss: 1.1648 - acc: 0.9653 - mDice: 0.7471 - val_loss: 1.0576 - val_acc: 0.9778 - val_mDice: 0.7697

Epoch 00144: val_mDice did not improve from 0.77205
Epoch 145/300
 - 19s - loss: 1.1613 - acc: 0.9653 - mDice: 0.7479 - val_loss: 1.0483 - val_acc: 0.9788 - val_mDice: 0.7720

Epoch 00145: val_mDice did not improve from 0.77205
Epoch 146/300
 - 20s - loss: 1.1620 - acc: 0.9653 - mDice: 0.7480 - val_loss: 1.0413 - val_acc: 0.9790 - val_mDice: 0.7706
